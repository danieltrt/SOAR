file_path,api_count,code
setup.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# coding=utf-8\n""""""Install trax.""""""\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\nsetup(\n    name=\'trax\',\n    version=\'1.2.4\',\n    description=\'Trax\',\n    long_description=(\n        \'Trax helps you understand deep learning. We start with basic maths and\'\n        \' go through layers, models, supervised and reinforcement learning. We \'\n        \'get to advanced deep learning results, including recent papers and \'\n        \'state-of-the-art models.\'\n    ),\n    author=\'Google Inc.\',\n    author_email=\'no-reply@google.com\',\n    url=\'http://github.com/google/trax\',\n    license=\'Apache 2.0\',\n    packages=find_packages(),\n    install_requires=[\n        \'absl-py\',\n        \'funcsigs\',\n        \'gin-config\',\n        \'gym==0.14.0\',\n        \'jax\',\n        \'jaxlib\',\n        \'numpy\',\n        \'scipy\',\n        \'six\',\n        \'t5\',\n        \'tensor2tensor\',\n        \'tensorflow-datasets\',\n        \'tensorflow-text\',\n    ],\n    extras_require={\n        \'tensorflow\': [\'tensorflow>=1.15.0\'],\n        \'tensorflow_gpu\': [\'tensorflow-gpu>=1.15.0\'],\n        \'tests\': [\n            \'attrs\',\n            \'jupyter\',\n            \'matplotlib\',\n            \'mock\',\n            \'parameterized\',\n            \'pylint\',\n            \'pytest\',\n            \'wrapt==1.11.*\',\n        ],\n    },\n    classifiers=[\n        \'Development Status :: 4 - Beta\',\n        \'Intended Audience :: Developers\',\n        \'Intended Audience :: Science/Research\',\n        \'License :: OSI Approved :: Apache Software License\',\n        \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\n    ],\n    keywords=\'tensorflow machine learning jax\',\n)\n'"
trax/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Trax top level import.""""""\n\nfrom trax import layers\nfrom trax import lr_schedules as lr\nfrom trax import math\nfrom trax import optimizers\nfrom trax import shapes\nfrom trax import supervised\n'"
trax/history.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Trax history.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\n\nfrom absl import logging\n\n\nclass History(object):\n  """"""History of metrics.\n\n  History contains the metrics recorded during training and evaluation.\n  Save data with history.append and get a sequence of data by calling\n  history.get.\n\n  For example:\n  history.append(\'train\', \'metrics/accuracy\', 1, 0.04)\n  history.append(\'train\', \'metrics/accuracy\', 1000, 0.31)\n  history.get(\'train\', \'metrics/accuracy\')\n  # returns [(1, 0.04), (1000, 0.31)]\n  """"""\n\n  def __init__(self):\n    # Structure is\n    # values = {\n    #   \'mode1\': {\n    #     \'metric1\': [val1, val2],\n    #     ...\n    #   },\n    #   \'mode2\': ...\n    # }\n    self._values = {}\n\n  def append(self, mode, metric, step, value):\n    """"""Append (step, value) pair to history for the given mode and metric.""""""\n    if mode not in self._values:\n      self._values[mode] = collections.defaultdict(list)\n    self._values[mode][metric].append((step, value))\n\n  def get(self, mode, metric):\n    """"""Get the history for the given metric and mode.""""""\n    if mode not in self._values:\n      logging.info(\'Metric %s not found for mode %s\', metric, mode)\n      return []\n    return list(self._values[mode][metric])\n\n  @property\n  def modes(self):\n    """"""Current tracked modes.""""""\n    return sorted(list(self._values.keys()))\n\n  def metrics_for_mode(self, mode):\n    """"""Metrics available for a given mode.""""""\n    if mode not in self._values:\n      logging.info(\'Mode %s not found\', mode)\n      return []\n    return sorted(list(self._values[mode].keys()))\n\n  def __str__(self):\n    return str(self._values)\n'"
trax/import_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for importing Trax.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import absltest\n\n\nclass ImportTest(absltest.TestCase):\n\n  def test_import_trax(self):\n    try:\n      # Import trax\n      import trax  # pylint: disable=g-import-not-at-top\n      # Access a few symbols.\n      dir(trax.math)\n      dir(trax.layers)\n      dir(trax.models)\n    except ImportError as e:\n      raise e\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/jaxboard.py,31,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Write Summaries from JAX for use with Tensorboard.\n\nSee jaxboard_demo.py for example usage.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport io\nimport struct\nimport time\nimport warnings\nimport wave\nimport matplotlib as mpl\n# Necessary to prevent attempted Tk import:\nwith warnings.catch_warnings():\n  warnings.simplefilter(\'ignore\')\n  mpl.use(\'Agg\')\n# pylint: disable=g-import-not-at-top\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\n# pylint: disable=g-direct-tensorflow-import\nfrom tensorflow.core.util import event_pb2\nfrom tensorflow.python.summary.writer.event_file_writer import EventFileWriter\n# pylint: enable=g-direct-tensorflow-import\n\n\ndef _pack_images(images, rows, cols):\n  """"""Helper utility to make a tiled field of images from numpy arrays.\n\n  Args:\n    images: Image tensor in shape [N, W, H, C].\n    rows: Number of images per row in tiled image.\n    cols: Number of images per column in tiled image.\n\n  Returns:\n    A tiled image of shape [W * rows, H * cols, C].\n    Truncates incomplete rows.\n  """"""\n  shape = np.shape(images)\n  width, height, depth = shape[-3:]\n  images = np.reshape(images, (-1, width, height, depth))\n  batch = np.shape(images)[0]\n  rows = np.minimum(rows, batch)\n  cols = np.minimum(batch // rows, cols)\n  images = images[:rows * cols]\n  images = np.reshape(images, (rows, cols, width, height, depth))\n  images = np.transpose(images, [0, 2, 1, 3, 4])\n  images = np.reshape(images, [rows * width, cols * height, depth])\n  return images\n\n\nclass SummaryWriter(object):\n  """"""Saves data in event and summary protos for tensorboard.""""""\n\n  def __init__(self, log_dir, enable=True):\n    """"""Create a new SummaryWriter.\n\n    Args:\n      log_dir: path to record tfevents files in.\n      enable: bool: if False don\'t actually write or flush data.  Used in\n        multihost training.\n    """"""\n    # If needed, create log_dir directory as well as missing parent directories.\n    if not tf.io.gfile.isdir(log_dir):\n      tf.io.gfile.makedirs(log_dir)\n\n    self._event_writer = EventFileWriter(log_dir, 10, 120, None)\n    self._step = 0\n    self._closed = False\n    self._enabled = enable\n\n  def add_summary(self, summary, step):\n    if not self._enabled:\n      return\n    event = event_pb2.Event(summary=summary)\n    event.wall_time = time.time()\n    if step is not None:\n      event.step = int(step)\n    self._event_writer.add_event(event)\n\n  def close(self):\n    """"""Close SummaryWriter. Final!""""""\n    if not self._closed:\n      self._event_writer.close()\n      self._closed = True\n      del self._event_writer\n\n  def __del__(self):  # safe?\n    # TODO(afrozm): Sometimes this complains with\n    #  `TypeError: \'NoneType\' object is not callable`\n    try:\n      self.close()\n    except Exception:  # pylint: disable=broad-except\n      pass\n\n  def flush(self):\n    if not self._enabled:\n      return\n    self._event_writer.flush()\n\n  def scalar(self, tag, value, step=None):\n    """"""Saves scalar value.\n\n    Args:\n      tag: str: label for this data\n      value: int/float: number to log\n      step: int: training step\n    """"""\n    value = float(np.array(value))\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    summary = tf.compat.v1.Summary(\n        value=[tf.compat.v1.Summary.Value(tag=tag, simple_value=value)])\n    self.add_summary(summary, step)\n\n  def image(self, tag, image, step=None):\n    """"""Saves RGB image summary from np.ndarray [H,W], [H,W,1], or [H,W,3].\n\n    Args:\n      tag: str: label for this data\n      image: ndarray: [H,W], [H,W,1], [H,W,3] save image in greyscale or colors/\n      step: int: training step\n    """"""\n    image = np.array(image)\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    if len(np.shape(image)) == 2:\n      image = image[:, :, np.newaxis]\n    if np.shape(image)[-1] == 1:\n      image = np.repeat(image, 3, axis=-1)\n    image_strio = io.BytesIO()\n    plt.imsave(image_strio, image, format=\'png\')\n    image_summary = tf.compat.v1.Summary.Image(\n        encoded_image_string=image_strio.getvalue(),\n        colorspace=3,\n        height=image.shape[0],\n        width=image.shape[1])\n    summary = tf.compat.v1.Summary(\n        value=[tf.compat.v1.Summary.Value(tag=tag, image=image_summary)])\n    self.add_summary(summary, step)\n\n  def images(self, tag, images, step=None, rows=None, cols=None):\n    """"""Saves (rows, cols) tiled images from np.ndarray.\n\n    If either rows or cols aren\'t given, they are determined automatically\n    from the size of the image batch, if neither are given a long column\n    of images is produced. This truncates the image batch rather than padding\n    if it doesn\'t fill the final row.\n\n    Args:\n      tag: str: label for this data\n      images: ndarray: [N,H,W,1] or [N,H,W,3] to tile in 2d\n      step: int: training step\n      rows: int: number of rows in tile\n      cols: int: number of columns in tile\n    """"""\n    images = np.array(images)\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    n_images = np.shape(images)[0]\n    if rows is None and cols is None:\n      rows = 1\n      cols = n_images\n    elif rows is None:\n      rows = n_images // cols\n    elif cols is None:\n      cols = n_images // rows\n    tiled_images = _pack_images(images, rows, cols)\n    self.image(tag, tiled_images, step=step)\n\n  def plot(self, tag, mpl_plt, step=None, close_plot=True):\n    """"""Saves matplotlib plot output to summary image.\n\n    Args:\n      tag: str: label for this data\n      mpl_plt: matplotlib stateful pyplot object with prepared plotting state\n      step: int: training step\n      close_plot: bool: automatically closes plot\n    """"""\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    fig = mpl_plt.get_current_fig_manager()\n    img_w, img_h = fig.canvas.get_width_height()\n    image_buf = io.BytesIO()\n    mpl_plt.savefig(image_buf, format=\'png\')\n    image_summary = tf.compat.v1.Summary.Image(\n        encoded_image_string=image_buf.getvalue(),\n        colorspace=4,  # RGBA\n        height=img_h,\n        width=img_w)\n    summary = tf.compat.v1.Summary(\n        value=[tf.compat.v1.Summary.Value(tag=tag, image=image_summary)])\n    self.add_summary(summary, step)\n    if close_plot:\n      mpl_plt.close()\n\n  def audio(self, tag, audiodata, step=None, sample_rate=44100):\n    """"""Saves audio.\n\n    NB: single channel only right now.\n\n    Args:\n      tag: str: label for this data\n      audiodata: ndarray [Nsamples,]: data between (-1.0,1.0) to save as wave\n      step: int: training step\n      sample_rate: sample rate of passed in audio buffer\n    """"""\n    audiodata = np.array(audiodata)\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    audiodata = np.clip(np.squeeze(audiodata), -1, 1)\n    if audiodata.ndim != 1:\n      raise ValueError(\'Audio data must be 1D.\')\n    sample_list = (32767.0 * audiodata).astype(int).tolist()\n    wio = io.BytesIO()\n    wav_buf = wave.open(wio, \'wb\')\n    wav_buf.setnchannels(1)\n    wav_buf.setsampwidth(2)\n    wav_buf.setframerate(sample_rate)\n    enc = b\'\'.join([struct.pack(\'<h\', v) for v in sample_list])\n    wav_buf.writeframes(enc)\n    wav_buf.close()\n    encoded_audio_bytes = wio.getvalue()\n    wio.close()\n    audio = tf.compat.v1.Summary.Audio(\n        sample_rate=sample_rate,\n        num_channels=1,\n        length_frames=len(sample_list),\n        encoded_audio_string=encoded_audio_bytes,\n        content_type=\'audio/wav\')\n    summary = tf.compat.v1.Summary(\n        value=[tf.compat.v1.Summary.Value(tag=tag, audio=audio)])\n    self.add_summary(summary, step)\n\n  def histogram(self, tag, values, bins, step=None):\n    """"""Saves histogram of values.\n\n    Args:\n      tag: str: label for this data\n      values: ndarray: will be flattened by this routine\n      bins: number of bins in histogram, or array of bins for np.histogram\n      step: int: training step\n    """"""\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    values = np.array(values)\n    bins = np.array(bins)\n    values = np.reshape(values, -1)\n    counts, limits = np.histogram(values, bins=bins)\n    # boundary logic\n    cum_counts = np.cumsum(np.greater(counts, 0, dtype=np.int32))\n    start, end = np.searchsorted(\n        cum_counts, [0, cum_counts[-1] - 1], side=\'right\')\n    start, end = int(start), int(end) + 1\n    counts = (\n        counts[start -\n               1:end] if start > 0 else np.concatenate([[0], counts[:end]]))\n    limits = limits[start:end + 1]\n    sum_sq = values.dot(values)\n    histo = tf.compat.v1.HistogramProto(\n        min=values.min(),\n        max=values.max(),\n        num=len(values),\n        sum=values.sum(),\n        sum_squares=sum_sq,\n        bucket_limit=limits.tolist(),\n        bucket=counts.tolist())\n    summary = tf.compat.v1.Summary(\n        value=[tf.compat.v1.Summary.Value(tag=tag, histo=histo)])\n    self.add_summary(summary, step)\n\n  def text(self, tag, textdata, step=None):\n    """"""Saves a text summary.\n\n    Args:\n      tag: str: label for this data\n      textdata: string, or 1D/2D list/numpy array of strings\n      step: int: training step\n    Note: markdown formatting is rendered by tensorboard.\n    """"""\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    smd = tf.compat.v1.SummaryMetadata(\n        plugin_data=tf.compat.v1.SummaryMetadata.PluginData(plugin_name=\'text\'))\n    if isinstance(textdata, (str, bytes)):\n      tensor = tf.make_tensor_proto(\n          values=[textdata.encode(encoding=\'utf_8\')], shape=(1,))\n    else:\n      textdata = np.array(textdata)  # convert lists, jax arrays, etc.\n      datashape = np.shape(textdata)\n      if len(datashape) == 1:\n        tensor = tf.make_tensor_proto(\n            values=[td.encode(encoding=\'utf_8\') for td in textdata],\n            shape=(datashape[0],))\n      elif len(datashape) == 2:\n        tensor = tf.make_tensor_proto(\n            values=[\n                td.encode(encoding=\'utf_8\') for td in np.reshape(textdata, -1)\n            ],\n            shape=(datashape[0], datashape[1]))\n    summary = tf.compat.v1.Summary(\n        value=[tf.compat.v1.Summary.Value(\n            tag=tag, metadata=smd, tensor=tensor)])\n    self.add_summary(summary, step)\n\n\n# Copied from gin/tf/utils.py:GinConfigSaverHook\ndef markdownify_operative_config_str(string):\n  """"""Convert an operative config string to markdown format.""""""\n\n  # TODO(b/37527917): Total hack below. Implement more principled formatting.\n  def process(line):\n    """"""Convert a single line to markdown format.""""""\n    if not line.startswith(\'#\'):\n      return \'    \' + line\n\n    line = line[2:]\n    if line.startswith(\'====\'):\n      return \'\'\n    if line.startswith(\'None\'):\n      return \'    # None.\'\n    if line.endswith(\':\'):\n      return \'#### \' + line\n    return line\n\n  output_lines = []\n  for line in string.splitlines():\n    procd_line = process(line)\n    if procd_line is not None:\n      output_lines.append(procd_line)\n\n  return \'\\n\'.join(output_lines)\n'"
trax/lr_schedules.py,9,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Trax learning rate schedules.\n\nThe learning rate schedules here all have the signature:\n  lr: history -> (step -> {\'learning_rate\': lr})\n\nThat is, they are functions that take a trax.history.History and return a\nfunction that takes a step and returns a dict with entry \'learning_rate\'.\n""""""\n\n# TODO(pkozakowski): Revisit the decision to control nontrainable parameters\n# using LR schedules, or at least rename the module.\n\nimport random\nimport time\n\nfrom absl import logging\nimport gin\nimport gym\n\nfrom trax import layers as tl\nfrom trax import models as trax_models\nfrom trax.math import numpy as np\nfrom trax.math import random as jax_random\n\n\n# We use a mix of CamelCase and not in this module.\n# pylint: disable=invalid-name\n\n\n@gin.configurable(blacklist=[\'history\'])\ndef MultifactorSchedule(history=None,\n                        factors=\'constant * linear_warmup * rsqrt_decay\',\n                        constant=0.1,  # pylint: disable=redefined-outer-name\n                        warmup_steps=400,\n                        decay_factor=0.5,\n                        steps_per_decay=20000,\n                        steps_per_cycle=100000):\n  """"""Factor-based learning rate schedule.\n\n  Interprets factors in the factors string which can consist of:\n  * constant: interpreted as the constant value,\n  * linear_warmup: interpreted as linear warmup until warmup_steps,\n  * rsqrt_decay: divide by square root of max(step, warmup_steps)\n  * decay_every: Every k steps decay the learning rate by decay_factor.\n  * cosine_deay: Cyclic cosine decay, uses steps_per_cycle parameter.\n\n  Args:\n    history: the history of training and evaluation (History object).\n    factors: a string with factors separated by \'*\' that defines the schedule.\n    constant: float, the starting constant for the learning rate schedule.\n    warmup_steps: how many steps to warm up for in the warmup schedule.\n    decay_factor: The amount to decay the learning rate by.\n    steps_per_decay: How often to decay the learning rate.\n    steps_per_cycle: Steps per cycle when using cosine decay.\n\n  Returns:\n    a function learning_rate(step): float -> {\'learning_rate\': float}, the\n    step-dependent lr.\n  """"""\n  del history\n\n  factors = [n.strip() for n in factors.split(\'*\')]\n\n  def learning_rate(step):\n    """"""Step to learning rate function.""""""\n    ret = 1.0\n    for name in factors:\n      if name == \'constant\':\n        ret *= constant\n      elif name == \'linear_warmup\':\n        ret *= np.minimum(1.0, step / warmup_steps)\n      elif name == \'rsqrt_decay\':\n        ret /= np.sqrt(np.maximum(step, warmup_steps))\n      elif name == \'rsqrt_normalized_decay\':\n        ret *= np.sqrt(warmup_steps)\n        ret /= np.sqrt(np.maximum(step, warmup_steps))\n      elif name == \'decay_every\':\n        ret *= (decay_factor ** (step//steps_per_decay))\n      elif name == \'cosine_decay\':\n        progress = np.maximum(\n            0.0, (step - warmup_steps) / float(steps_per_cycle))\n        ret *= (0.5 * (1.0 + np.cos(np.pi * (progress % 1.0))))\n      else:\n        raise ValueError(\'Unknown factor %s.\' % name)\n    ret = np.asarray(ret, dtype=np.float32)\n    return {\'learning_rate\': ret}\n\n  return learning_rate\n\n\n@gin.configurable(blacklist=[\'history\'])\ndef EvalAdjustingSchedule(history,\n                          constant=0.1,  # pylint: disable=redefined-outer-name\n                          steps_to_decrease=20,\n                          improvement_margin=0.001,\n                          decrease_rate=1.5,\n                          history_mode=\'eval\',\n                          metric=\'metrics/accuracy\'):\n  """"""Learning rate that decreases when eval metric stalls.\n\n  If the chosen metric does not improve by improvement_margin for as many as\n  steps_to_decrease steps, then the constant gets decreased by decrease rate.\n  Finally, the MultifactorSchedule gets called with the adjusted constant.\n\n  Args:\n    history: trax.history.History, the history of training and evaluation.\n    constant: float, the starting constant for the learning rate schedule.\n    steps_to_decrease: int, after how many steps without improvement\n      should we decrease the constant.\n    improvement_margin: how much we need to improve to consider the metric\n      improved.\n    decrease_rate: by what fraction to decrease (i.e. lr /= decrease_rate).\n    history_mode: str, which mode of the history to use.\n    metric: which evaluation metric to use for adjustments.\n\n  Returns:\n    a function learning_rate(step): float -> {\'learning_rate\': float}, the\n    step-dependent lr.\n  """"""\n  metrics = history.get(history_mode, metric)\n  adjusted = constant\n  if len(metrics) < 2:\n    return MultifactorSchedule(history, constant=adjusted)\n\n  steps_without_improvement = 0\n  cur = metrics.pop()[1]  # The most-recent value of the metric.\n  while len(metrics) > 1:\n    # The one-before value of metrics as .pop() removes one element each time.\n    prev = metrics.pop()[1]\n    if cur < prev * (1 + improvement_margin):\n      steps_without_improvement += 1\n    else:\n      cur = prev\n      steps_without_improvement = 0\n    if steps_without_improvement >= steps_to_decrease:\n      adjusted /= decrease_rate\n      cur = prev\n      steps_without_improvement = 0\n\n  return MultifactorSchedule(history, constant=adjusted)\n\n\n@gin.configurable(blacklist=[\'history\'])\ndef PolicySchedule(\n    history,\n    observation_metrics=(\n        (\'train\', \'metrics/accuracy\'),\n        (\'train\', \'metrics/loss\'),\n        (\'eval\', \'metrics/accuracy\'),\n        (\'eval\', \'metrics/loss\'),\n    ),\n    include_controls_in_observation=False,\n    control_configs=(\n        # (name, start, (low, high), flip)\n        (\'learning_rate\', 1e-3, (1e-9, 10.0), False),\n    ),\n    observation_range=(0.0, 10.0),\n    action_multipliers=(1.0 / 1.5, 1.0 / 1.25, 1.0, 1.25, 1.5),\n    policy_and_value_model=trax_models.FrameStackMLP,\n    policy_and_value_two_towers=False,\n    policy_and_value_vocab_size=None,\n    policy_dir=gin.REQUIRED,\n    temperature=1.0,\n):\n  """"""Learning rate schedule controlled by a learned policy.\n\n  Args:\n    history: the history of training and evaluation (History object).\n    observation_metrics: list of pairs (mode, metric), as in the History object.\n    include_controls_in_observation: bool, whether to include the controls in\n      observations.\n    control_configs: control configs, see trax.rl.envs.OnlineTuneEnv.\n    observation_range: tuple (low, high), range to clip the metrics to.\n    action_multipliers: sequence of LR multipliers that policy actions\n      correspond to.\n    policy_and_value_model: Trax model to use as the policy.\n    policy_and_value_two_towers: bool, whether the action distribution and value\n      prediction is computed by separate model towers.\n    policy_and_value_vocab_size: vocabulary size of a policy and value network\n      operating on serialized representation. If None, use raw continuous\n      representation.\n    policy_dir: directory with the policy checkpoint.\n    temperature: temperature for sampling from the policy.\n\n  Returns:\n    a function nontrainable_params(step): float -> {\'name\': float}, the\n    step-dependent schedule for nontrainable parameters.\n  """"""\n\n  # Turn the history into observations for the policy. If we don\'t have any,\n  # return the initial learning rate.\n  start_time = time.time()\n  observations = online_tune.history_to_observations(\n      history, observation_metrics, observation_range,\n      control_configs if include_controls_in_observation else None\n  )\n  logging.vlog(\n      1, \'Building observations took %0.2f sec.\', time.time() - start_time)\n  if observations.shape[0] == 0:\n    controls = {\n        name: start_value\n        for (name, start_value, _, _) in control_configs\n    }\n    return lambda _: controls\n\n  # Build the policy network and load its parameters.\n  start_time = time.time()\n  (low, high) = observation_range\n  observation_space = gym.spaces.Box(\n      shape=observations.shape[1:], low=low, high=high\n  )\n  action_space = gym.spaces.MultiDiscrete(\n      nvec=(len(action_multipliers),) * len(control_configs)\n  )\n  (net, _) = policy_based_utils.policy_and_value_net(\n      bottom_layers_fn=policy_and_value_model,\n      observation_space=observation_space,\n      action_space=action_space,\n      vocab_size=policy_and_value_vocab_size,\n      two_towers=policy_and_value_two_towers,\n  )\n  logging.vlog(\n      1, \'Building the policy network took %0.2f sec.\', time.time() - start_time\n  )\n  start_time = time.time()\n  # (opt_state, state, epoch, opt_step, history)\n  (opt_state, state, _, _, _) = policy_based_utils.maybe_restore_opt_state(\n      policy_dir\n  )\n  assert opt_state is not None, \'Policy checkpoint not found.\'\n  (params, _, _) = opt_state\n  logging.vlog(\n      1, \'Restoring the policy parameters took %0.2f sec.\',\n      time.time() - start_time\n  )\n\n  # Run the policy and sample an action.\n  seed = random.randint(0, 2**31 - 1)\n  rng = jax_random.get_prng(seed=seed)\n  start_time = time.time()\n\n  n_timesteps = observations.shape[0]\n  # (log_probs, value_preds, state, rng)\n  (log_probs, _, _, _) = policy_based_utils.run_policy(\n      policy_and_value_net_apply=net,\n      observations=np.array([observations]),\n      lengths=np.array([n_timesteps]),\n      weights=params,\n      state=state,\n      rng=rng,\n      action_space=action_space,\n  )\n\n  logging.vlog(\n      1, \'Running the policy took %0.2f sec.\', time.time() - start_time\n  )\n  # Sample from the action distribution for the last timestep.\n  assert log_probs.shape == (1, len(control_configs), len(action_multipliers))\n  action = tl.gumbel_sample(log_probs[0], temperature)\n\n  # Get new controls.\n  controls = {\n      # name: value\n      control_config[0]: online_tune.update_control(  # pylint: disable=g-complex-comprehension\n          control_config, control_action, history, action_multipliers)\n      for (control_action, control_config) in zip(action, control_configs)\n  }\n  return lambda _: controls\n\n\n# pylint: disable=g-import-not-at-top\n# These dependencies are here to break the circular dependency from this\n# module, to itself via online_tune/policy_based_utils -> trainer_lib ->\n# lr_schedules.\nfrom trax.rl import online_tune\nfrom trax.rl import policy_based_utils\nfrom trax.supervised import lr_functions\n# pylint: enable=g-import-not-at-top\n\n\ndef _from_lr_function(lr_fn, *args):\n  """"""Compatibility layer: creates a learning rate from lr_functions function.""""""\n  def learning_rate(step):\n    return {\'learning_rate\': lr_fn(*args)(step)}\n  return learning_rate\n\n\n@gin.configurable(blacklist=[\'history\'])\ndef constant(history, value):\n  del history\n  return _from_lr_function(lr_functions.constant, value)\n\n\n@gin.configurable(blacklist=[\'history\'])\ndef warmup(history, n_warmup_steps, max_value):\n  del history\n  return _from_lr_function(lr_functions.warmup, n_warmup_steps, max_value)\n\n\n@gin.configurable(blacklist=[\'history\'])\ndef warmup_and_rsqrt_decay(history, n_warmup_steps, max_value):\n  del history\n  return _from_lr_function(lr_functions.warmup_and_rsqrt_decay,\n                           n_warmup_steps, max_value)\n'"
trax/lr_schedules_test.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for trax.lr_schedules.""""""\n\nimport functools\n\nimport gym\nimport numpy as np\nfrom tensorflow import test\nfrom trax import history as trax_history\nfrom trax import lr_schedules\nfrom trax import shapes\nfrom trax.models import transformer\nfrom trax.rl import online_tune\nfrom trax.rl import policy_based_utils\n\n\nclass PolicyScheduleTest(test.TestCase):\n\n  def _make_schedule(\n      self,\n      history,\n      control_configs,\n      observation_metrics=((\'eval\', \'metrics/accuracy\'),),\n      action_multipliers=(1.0,),\n      vocab_size=None,\n  ):\n    policy_and_value_model = functools.partial(\n        transformer.TransformerDecoder,\n        d_model=2,\n        d_ff=2,\n        n_layers=0,\n        vocab_size=vocab_size,\n    )\n    observation_space = gym.spaces.Box(\n        shape=(len(observation_metrics),),\n        low=0.0,\n        high=1.0,\n    )\n    action_space = gym.spaces.MultiDiscrete(\n        nvec=(len(action_multipliers),) * len(control_configs)\n    )\n    (net, _) = policy_based_utils.policy_and_value_net(\n        bottom_layers_fn=policy_and_value_model,\n        observation_space=observation_space,\n        action_space=action_space,\n        vocab_size=vocab_size,\n        two_towers=False,\n    )\n    input_signature = (\n        shapes.ShapeDtype(\n            (1, 2) + observation_space.shape, observation_space.dtype\n        ),\n        shapes.ShapeDtype((1, 1) + action_space.shape, action_space.dtype),\n    )\n    (params, state) = net.init(input_signature)\n    policy_dir = self.get_temp_dir()\n    # Optimizer slots and parameters should not be used for anything.\n    slots = None\n    opt_params = None\n    opt_state = (params, slots, opt_params)\n    policy_based_utils.save_opt_state(\n        policy_dir, opt_state, state, epoch=0, total_opt_step=0, history=history\n    )\n    return lr_schedules.PolicySchedule(\n        history,\n        observation_metrics=observation_metrics,\n        include_controls_in_observation=False,\n        action_multipliers=action_multipliers,\n        control_configs=control_configs,\n        policy_and_value_model=policy_and_value_model,\n        policy_and_value_two_towers=False,\n        policy_and_value_vocab_size=vocab_size,\n        policy_dir=policy_dir,\n    )\n\n  def test_returns_start_lr_when_there_are_no_metrics(self):\n    history = trax_history.History()\n    start_lr = 1e-3\n    schedule = self._make_schedule(\n        history,\n        control_configs=((\'learning_rate\', start_lr, (1e-9, 1.0), False),),\n    )\n    self.assertEqual(schedule(0)[\'learning_rate\'], start_lr)\n\n  def test_changes_lr_when_there_are_some_metrics(self):\n    history = trax_history.History()\n    history.append(\'eval\', \'metrics/accuracy\', step=0, value=0.8)\n    history.append(\n        *online_tune.control_metric(\'learning_rate\'), step=0, value=1e-4\n    )\n    schedule = self._make_schedule(\n        history,\n        control_configs=((\'learning_rate\', 1e-3, (1e-9, 1.0), False),),\n        observation_metrics=((\'eval\', \'metrics/accuracy\'),),\n        action_multipliers=(0.5, 2.0),\n    )\n    new_lr = schedule(123)[\'learning_rate\']\n    self.assertTrue(\n        np.allclose(new_lr, 5e-5) or np.allclose(new_lr, 2e-4)\n    )\n\n  def test_works_with_multiple_controls(self):\n    history = trax_history.History()\n    history.append(\'eval\', \'metrics/accuracy\', step=0, value=0.8)\n    history.append(\n        *online_tune.control_metric(\'learning_rate\'), step=0, value=1e-4\n    )\n    history.append(\n        *online_tune.control_metric(\'weight_decay_rate\'), step=0, value=1e-5\n    )\n    schedule = self._make_schedule(\n        history,\n        observation_metrics=((\'eval\', \'metrics/accuracy\'),),\n        control_configs=(\n            (\'learning_rate\', 1e-3, (1e-9, 1.0), False),\n            (\'weight_decay_rate\', 1e-5, (1e-9, 1.0), False),\n        ),\n        action_multipliers=(1.0,),\n    )\n    new_controls = schedule(123)\n    self.assertIn(\'learning_rate\', new_controls)\n    self.assertIn(\'weight_decay_rate\', new_controls)\n\n  def test_works_with_serialized_policy(self):\n    history = trax_history.History()\n    history.append(\'eval\', \'metrics/accuracy\', step=0, value=0.8)\n    history.append(\n        *online_tune.control_metric(\'learning_rate\'), step=0, value=1e-4\n    )\n    schedule = self._make_schedule(\n        history,\n        control_configs=((\'learning_rate\', 1e-3, (1e-9, 1.0), False),),\n        observation_metrics=((\'eval\', \'metrics/accuracy\'),),\n        action_multipliers=(0.5, 2.0),\n        vocab_size=16,\n    )\n    new_lr = schedule(123)[\'learning_rate\']\n    self.assertTrue(\n        np.allclose(new_lr, 5e-5) or np.allclose(new_lr, 2e-4)\n    )\n\n  def test_schedule_from_lr_function(self):\n    history = trax_history.History()\n    schedule = lr_schedules.constant(history, 0.1)\n    value = schedule(10)\n    self.assertEqual(value[\'learning_rate\'], 0.1)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl_trainer.py,1,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nr""""""Trainer for RL environments.\n\nFor now we only support PPO as RL algorithm.\n\nSample invocation:\n\nTRAIN_BATCH_SIZE=32\npython trax/rl_trainer.py \\\n  --config_file=trax/rl/configs/ppo_acrobot.gin \\\n  --train_batch_size=${TRAIN_BATCH_SIZE} \\\n  --output_dir=${HOME}/ppo_acrobot \\\n  --alsologtostderr\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport multiprocessing\nimport os\n\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\nimport faulthandler\nimport gin\nimport jax\nfrom jax.config import config\nfrom tensor2tensor import envs  # pylint: disable=unused-import\nfrom tensor2tensor.envs import env_problem_utils\nfrom trax import math\nfrom trax import rl  # pylint: disable=unused-import\nfrom trax import trainer_flags  # pylint: disable=unused-import\nfrom trax.rl import envs as rl_envs  # pylint: disable=unused-import\nfrom trax.rl import task as rl_task\nfrom trax.rl import trainers as rl_trainers\nfrom trax.rl import training as light_trainers\nfrom trax.tf_numpy import numpy as tf_np\n\n\nFLAGS = flags.FLAGS\n\n\n# Not just \'train\' to avoid a conflict with trax.train in GIN files.\n@gin.configurable(blacklist=[\n    \'output_dir\', \'train_batch_size\', \'eval_batch_size\', \'trajectory_dump_dir\'\n])\ndef train_rl(\n    output_dir,\n    train_batch_size,\n    eval_batch_size,\n    env_name=\'Acrobot-v1\',\n    max_timestep=None,\n    clip_rewards=False,\n    rendered_env=False,\n    resize=False,\n    resize_dims=(105, 80),\n    trainer_class=rl_trainers.PPO,\n    n_epochs=10000,\n    trajectory_dump_dir=None,\n    num_actions=None,\n    light_rl=False,\n    light_rl_trainer=light_trainers.RLTrainer,\n):\n  """"""Train the RL agent.\n\n  Args:\n    output_dir: Output directory.\n    train_batch_size: Number of parallel environments to use for training.\n    eval_batch_size: Number of parallel environments to use for evaluation.\n    env_name: Name of the environment.\n    max_timestep: Int or None, the maximum number of timesteps in a trajectory.\n      The environment is wrapped in a TimeLimit wrapper.\n    clip_rewards: Whether to clip and discretize the rewards.\n    rendered_env: Whether the environment has visual input. If so, a\n      RenderedEnvProblem will be used.\n    resize: whether to do resize or not\n    resize_dims: Pair (height, width), dimensions to resize the visual\n      observations to.\n    trainer_class: RLTrainer class to use.\n    n_epochs: Number epochs to run the training for.\n    trajectory_dump_dir: Directory to dump trajectories to.\n    num_actions: None unless one wants to use the discretization wrapper. Then\n      num_actions specifies the number of discrete actions.\n    light_rl: whether to use the light RL setting (experimental).\n    light_rl_trainer: whichh light RL trainer to use (experimental).\n  """"""\n  tf_np.set_allow_float64(FLAGS.tf_allow_float64)\n\n  if light_rl:\n    task = rl_task.RLTask()\n    env_name = task.env_name\n\n\n  if FLAGS.jax_debug_nans:\n    config.update(\'jax_debug_nans\', True)\n\n  if FLAGS.use_tpu:\n    config.update(\'jax_platform_name\', \'tpu\')\n  else:\n    config.update(\'jax_platform_name\', \'\')\n\n\n  if light_rl:\n    trainer = light_rl_trainer(task=task, output_dir=output_dir)\n    def light_training_loop():\n      """"""Run the trainer for n_epochs and call close on it.""""""\n      try:\n        logging.info(\'Starting RL training for %d epochs.\', n_epochs)\n        trainer.run(n_epochs, n_epochs_is_total_epochs=True)\n        logging.info(\'Completed RL training for %d epochs.\', n_epochs)\n        trainer.close()\n        logging.info(\'Trainer is now closed.\')\n      except Exception as e:\n        raise e\n      finally:\n        logging.info(\'Encountered an exception, still calling trainer.close()\')\n        trainer.close()\n        logging.info(\'Trainer is now closed.\')\n\n    if FLAGS.jax_debug_nans or FLAGS.disable_jit:\n      math.disable_jit()\n      with jax.disable_jit():\n        light_training_loop()\n    else:\n      light_training_loop()\n    return\n\n  # TODO(pkozakowski): Find a better way to determine this.\n  train_env_kwargs = {}\n  eval_env_kwargs = {}\n  if \'OnlineTuneEnv\' in env_name:\n    envs_output_dir = FLAGS.envs_output_dir or os.path.join(output_dir, \'envs\')\n    train_env_output_dir = os.path.join(envs_output_dir, \'train\')\n    eval_env_output_dir = os.path.join(envs_output_dir, \'eval\')\n    train_env_kwargs = {\'output_dir\': train_env_output_dir}\n    eval_env_kwargs = {\'output_dir\': eval_env_output_dir}\n\n  parallelism = multiprocessing.cpu_count() if FLAGS.parallelize_envs else 1\n\n  logging.info(\'Num discretized actions %s\', num_actions)\n  logging.info(\'Resize %d\', resize)\n\n  train_env = env_problem_utils.make_env(\n      batch_size=train_batch_size,\n      env_problem_name=env_name,\n      rendered_env=rendered_env,\n      resize=resize,\n      resize_dims=resize_dims,\n      max_timestep=max_timestep,\n      clip_rewards=clip_rewards,\n      parallelism=parallelism,\n      use_tpu=FLAGS.use_tpu,\n      num_actions=num_actions,\n      **train_env_kwargs)\n  assert train_env\n\n  eval_env = env_problem_utils.make_env(\n      batch_size=eval_batch_size,\n      env_problem_name=env_name,\n      rendered_env=rendered_env,\n      resize=resize,\n      resize_dims=resize_dims,\n      max_timestep=max_timestep,\n      clip_rewards=clip_rewards,\n      parallelism=parallelism,\n      use_tpu=FLAGS.use_tpu,\n      num_actions=num_actions,\n      **eval_env_kwargs)\n  assert eval_env\n\n  def run_training_loop():\n    """"""Runs the training loop.""""""\n    logging.info(\'Starting the training loop.\')\n\n    trainer = trainer_class(\n        output_dir=output_dir,\n        train_env=train_env,\n        eval_env=eval_env,\n        trajectory_dump_dir=trajectory_dump_dir,\n        async_mode=FLAGS.async_mode,\n    )\n    trainer.training_loop(n_epochs=n_epochs)\n\n  if FLAGS.jax_debug_nans or FLAGS.disable_jit:\n    math.disable_jit()\n    with jax.disable_jit():\n      run_training_loop()\n  else:\n    run_training_loop()\n\n\ndef main(argv):\n  del argv\n  logging.info(\'Starting RL training.\')\n\n  gin_configs = FLAGS.config or []\n  gin.parse_config_files_and_bindings(FLAGS.config_file, gin_configs)\n\n  logging.info(\'Gin cofig:\')\n  logging.info(gin_configs)\n\n  train_rl(\n      output_dir=FLAGS.output_dir,\n      train_batch_size=FLAGS.train_batch_size,\n      eval_batch_size=FLAGS.eval_batch_size,\n      trajectory_dump_dir=(FLAGS.trajectory_dump_dir or None),\n  )\n\n  # TODO(afrozm): This is for debugging.\n  logging.info(\'Dumping stack traces of all stacks.\')\n  faulthandler.dump_traceback(all_threads=True)\n\n  logging.info(\'Training is done, should exit.\')\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
trax/shapes.py,1,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Core class and functions for handling data abstractly as shapes/dtypes.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow as tf\n\n\nclass ShapeDtype(object):\n  """"""A NumPy ndarray-like object abstracted as shape and dtype.\n\n  Main use is for representing input and output signatures.\n  """"""\n  __slots__ = [\'shape\', \'dtype\']\n\n  def __init__(self, shape, dtype=np.float32):\n    """"""Creates a `ShapeDtype` instance, with canonicalized `shape` and `dtype`.\n\n    Args:\n      shape: A tuple or list, each element of which is an int or, less often,\n          `None`.\n      dtype: A `dtype` object, either from NumPy or TensorFlow.\n\n    Returns:\n      A `ShapeDtype` instance whose `shape` is a tuple and `dtype` is a NumPy\n      `dtype` object.\n    """"""\n    # Canonicalize shape and dtype.\n    if isinstance(shape, list):\n      shape = tuple(shape)\n    if not isinstance(shape, tuple):\n      raise TypeError(\'shape must be tuple or list; got: {}\'.format(shape))\n    if isinstance(dtype, tf.DType):\n      dtype = dtype.as_numpy_dtype\n\n    self.shape = shape\n    self.dtype = dtype\n\n  def __eq__(self, other):\n    return (isinstance(other, self.__class__)\n            and self.shape == other.shape\n            and self.dtype == other.dtype)\n\n  def __ne__(self, other):\n    return not self == other\n\n  def __repr__(self):\n    return \'ShapeDtype{{shape:{}, dtype:{}}}\'.format(self.shape, self.dtype)\n\n  def __len__(self):\n    """"""Returns length of 1; relevant to input and output signatures.""""""\n    return 1\n\n  def as_tuple(self):\n    return self.shape, self.dtype\n\n  def replace(self, **kwargs):\n    """"""Creates a copy of the object with some parameters replaced.""""""\n    return type(self)(\n        shape=kwargs.pop(\'shape\', self.shape),\n        dtype=kwargs.pop(\'dtype\', self.dtype),\n    )\n\n\ndef signature(obj):\n  """"""Returns a `ShapeDtype` signature for the given `obj`.\n\n  A signature is either a `ShapeDtype` instance or a tuple of `ShapeDtype`\n  instances. Note that this function is permissive with respect to its inputs\n  (accepts lists or tuples, and underlying objects can be any type as long as\n  they have shape and dtype attributes), but strict with respect to its outputs\n  (only `ShapeDtype`, and only tuples).\n\n  Args:\n    obj: An object that has `shape` and `dtype` attributes, or a list/tuple\n        of such objects.\n\n  Returns:\n    A single `ShapeDtype` instance if the signature has one element, else a\n    tuple of `ShapeDtype` instances.\n  """"""\n  if isinstance(obj, (list, tuple)):\n    output = tuple(signature(x) for x in obj)\n    return output[0] if len(output) == 1 else output\n  else:\n    return ShapeDtype(obj.shape, obj.dtype)\n\n\ndef splice_signatures(*sigs):\n  """"""Creates a new signature by splicing together any number of signatures.\n\n  The splicing effectively flattens the top level input signatures. For\n  instance, it would perform the following mapping:\n\n    - `*sigs: sd1, (sd2, sd3, sd4), (), sd5`\n    - return: `(sd1, sd2, sd3, sd4, sd5)`\n\n  Args:\n    *sigs: Any number of signatures. A signature is either a `ShapeDtype`\n        instance or a tuple of `ShapeDtype` instances.\n\n  Returns:\n    A single `ShapeDtype` instance if the spliced signature has one element,\n    else a tuple of `ShapeDtype` instances.\n  """"""\n  result_sigs = []\n  for sig in sigs:\n    if isinstance(sig, (list, tuple)):\n      result_sigs.extend(sig)\n    else:\n      result_sigs.append(sig)\n  return result_sigs[0] if len(result_sigs) == 1 else tuple(result_sigs)\n\n\ndef assert_shape_equals(array, shape):\n  """"""Asserts that an array has the given shape.""""""\n  assert array.shape == shape, (\n      \'Invalid shape {}; expected {}.\'.format(array.shape, shape)\n  )\n\n\ndef assert_same_shape(array1, array2):\n  """"""Asserts that two arrays have the same shapes.""""""\n  assert_shape_equals(array1, array2.shape)\n'"
trax/shapes_test.py,8,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.shapes.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import absltest\nimport numpy as np\n\nfrom trax import shapes\nfrom trax.shapes import ShapeDtype\n\n\nclass ShapesTest(absltest.TestCase):\n\n  def test_constructor_and_read_properties(self):\n    sd = ShapeDtype((2, 3), np.int32)\n    self.assertEqual(sd.shape, (2, 3))\n    self.assertEqual(sd.dtype, np.int32)\n\n  def test_default_dtype_is_float32(self):\n    sd = ShapeDtype((2, 3))\n    self.assertEqual(sd.shape, (2, 3))\n    self.assertEqual(sd.dtype, np.float32)\n\n  def test_signature_on_ndarray(self):\n    array = np.array([[2, 3, 5, 7],\n                      [11, 13, 17, 19]],\n                     dtype=np.int16)\n    sd = shapes.signature(array)\n    self.assertEqual(sd.shape, (2, 4))\n    self.assertEqual(sd.dtype, np.int16)\n\n  def test_shape_dtype_repr(self):\n    sd = ShapeDtype((2, 3))\n    repr_string = \'{}\'.format(sd)\n    self.assertEqual(repr_string,\n                     ""ShapeDtype{shape:(2, 3), dtype:<class \'numpy.float32\'>}"")\n\n  def test_splice_signatures(self):\n    sd1 = ShapeDtype((1,))\n    sd2 = ShapeDtype((2,))\n    sd3 = ShapeDtype((3,))\n    sd4 = ShapeDtype((4,))\n    sd5 = ShapeDtype((5,))\n\n    # Signatures can be ShapeDtype instances, tuples of 2+ ShapeDtype instances,\n    # or empty tuples.\n    sig1 = sd1\n    sig2 = (sd2, sd3, sd4)\n    sig3 = ()\n    sig4 = sd5\n    spliced = shapes.splice_signatures(sig1, sig2, sig3, sig4)\n    self.assertEqual(spliced, (sd1, sd2, sd3, sd4, sd5))\n\n  def test_len_signature(self):\n    """"""Signatures of all sizes should give correct length when asked.""""""\n    x1 = np.array([1, 2, 3])\n    x2 = np.array([10, 20, 30])\n    inputs0 = ()\n    inputs1 = x1  # NOT in a tuple\n    inputs2 = (x1, x2)\n\n    sig0 = shapes.signature(inputs0)\n    sig1 = shapes.signature(inputs1)\n    sig2 = shapes.signature(inputs2)\n\n    # pylint: disable=g-generic-assert\n    self.assertEqual(len(sig0), 0)\n    self.assertEqual(len(sig1), 1)\n    self.assertEqual(len(sig2), 2)\n    # pylint: enable=g-generic-assert\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/test_utils.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""A few utilities for tests.""""""\n\nimport sys\n\nfrom absl import flags\n\nFLAGS = flags.FLAGS\n\n\n# pytest doesn\'t run the test as a main, so it doesn\'t parse the flags\n# so if flags are required in tests, this will ensure that flags are manually\n# parsed and the desired flag exists.\ndef ensure_flag(flag_str):\n  try:\n    getattr(FLAGS, flag_str)\n  except flags.UnparsedFlagAccessError:\n    # Manually parse flags.\n    FLAGS(sys.argv)\n  finally:\n    assert getattr(FLAGS, flag_str)\n'"
trax/trainer.py,1,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Trax trainer.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport os\n\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\n\nimport gin\nimport jax\nimport tensorflow.compat.v2 as tf\nfrom trax import math\nfrom trax import trainer_flags  # pylint: disable=unused-import\nfrom trax.supervised import trainer_lib\nfrom trax.tf_numpy import numpy as tf_np\n\nFLAGS = flags.FLAGS\n\n\n# TODO(afrozm): Share between trainer.py and rl_trainer.py\ndef _tf_setup_from_flags():\n  """"""Processes TensorFlow-relevant flags.""""""\n  if FLAGS.enable_eager_execution:\n    tf.compat.v1.enable_eager_execution()\n  if FLAGS.tf_xla:\n    tf.config.optimizer.set_jit(True)\n    math.tf_math.set_tf_xla_forced_compile(FLAGS.tf_xla_forced_compile)\n  tf.config.optimizer.set_experimental_options({\n      \'pin_to_host_optimization\': FLAGS.tf_opt_pin_to_host,\n      \'layout_optimizer\': FLAGS.tf_opt_layout,\n  })\n  tf_np.set_allow_float64(FLAGS.tf_allow_float64)\n\n\n# TODO(afrozm): Share between trainer.py and rl_trainer.py\ndef _gin_parse_configs():\n  """"""Initializes gin-controlled bindings.""""""\n  # Imports for configurables\n  # pylint: disable=g-import-not-at-top,unused-import,g-bad-import-order,reimported,unused-variable\n  from trax import models as _trax_models\n  from trax import optimizers as _trax_opt\n  # pylint: disable=g-import-not-at-top,unused-import,g-bad-import-order,reimported,unused-variable\n\n  configs = FLAGS.config or []\n  # Override with --dataset and --model\n  if FLAGS.dataset:\n    configs.append(""data_streams.dataset_name=\'%s\'"" % FLAGS.dataset)\n  if FLAGS.data_dir:\n    configs.append(""data_streams.data_dir=\'%s\'"" % FLAGS.data_dir)\n  if FLAGS.model:\n    configs.append(\'train.model=@trax.models.%s\' % FLAGS.model)\n  gin.parse_config_files_and_bindings(FLAGS.config_file, configs)\n\n\ndef _output_dir_or_default():\n  """"""Returns a path to the output directory.""""""\n  if FLAGS.output_dir:\n    output_dir = FLAGS.output_dir\n    trainer_lib.log(\'Using --output_dir {}\'.format(output_dir))\n    return os.path.expanduser(output_dir)\n\n  # Else, generate a default output dir (under the user\'s home directory).\n  try:\n    dataset_name = gin.query_parameter(\'data_streams.dataset_name\')\n  except ValueError:\n    dataset_name = \'random\'\n  output_name = \'{model_name}_{dataset_name}_{timestamp}\'.format(\n      model_name=gin.query_parameter(\'train.model\').configurable.name,\n      dataset_name=dataset_name,\n      timestamp=datetime.datetime.now().strftime(\'%Y%m%d_%H%M\'),\n  )\n  output_dir = os.path.join(\'~\', \'trax\', output_name)\n  output_dir = os.path.expanduser(output_dir)\n  print()\n  trainer_lib.log(\'No --output_dir specified\')\n  trainer_lib.log(\'Using default output_dir: {}\'.format(output_dir))\n  return output_dir\n\n\n# TODO(afrozm): Share between trainer.py and rl_trainer.py\ndef _jax_and_tf_configure_for_devices():\n  if FLAGS.use_tpu:\n    jax.config.update(\'jax_platform_name\', \'tpu\')\n    jax.config.update(\'jax_xla_backend\', FLAGS.jax_xla_backend)\n    jax.config.update(\'jax_backend_target\', FLAGS.jax_backend_target)\n  if FLAGS.enable_eager_execution and math.backend_name() in (\'numpy\', \'jax\'):\n    # Numpy backend doesn\'t benefit from having the input pipeline run on GPU,\n    # and jax backend has GPU memory contention if TF uses the GPU. Gin must be\n    # set up first before determining the backend.\n    tf.config.experimental.set_visible_devices([], \'GPU\')\n\n\ndef _train_using_tf(output_dir):\n  worker_cpu = tf_init_tpu()\n  with tf.device(worker_cpu):\n    if trainer_lib.num_devices() == 1:\n      # TF\'s device priority is GPU > CPU > TPU, so we need to explicitly make\n      # the TPU core the default device here.\n      with tf.device(\'/device:TPU:0\'):\n        trainer_lib.train(output_dir=output_dir)\n    else:\n      trainer_lib.train(output_dir=output_dir)\n\n\n@gin.configurable\ndef tf_init_tpu(worker=\'\', protocol=None):\n  """"""Initializes TPU for TensorFlow.\n\n  Args:\n    worker: The BNS address of the remote TPU worker. If it\'s empty (the default\n      value), TF will assume the TPU devices are connected to the local host.\n    protocol: The network protocol used to connect to the TPU worker.\n  Returns:\n    The device name of the TPU worker\'s CPU.\n  """"""\n  protocol = protocol or \'grpc\'\n  is_local = (worker in (\'\', \'local\'))\n  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=worker)\n  if not is_local:\n    tf.config.experimental_connect_to_cluster(resolver, protocol=protocol)\n  tf.tpu.experimental.initialize_tpu_system(resolver)\n  if is_local:\n    return \'\'\n  else:\n    return \'/job:worker\'\n\n\ndef main(_):\n  logging.set_verbosity(FLAGS.log_level)\n\n  _tf_setup_from_flags()\n  _gin_parse_configs()\n  _jax_and_tf_configure_for_devices()\n\n  output_dir = _output_dir_or_default()\n  if FLAGS.use_tpu and math.backend_name() == \'tf\':\n    _train_using_tf(output_dir)\n  else:\n    trainer_lib.train(output_dir=output_dir)\n\n  trainer_lib.log(\'Finished training.\')\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
trax/trainer_flags.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Flags for trainer.py and rl_trainer.py.\n\nWe keep these flags in sync across the trainer and the rl_trainer binaries.\n""""""\n\nfrom absl import flags\nfrom absl import logging\n\n# Common flags.\nflags.DEFINE_string(\'output_dir\',\n                    None,\n                    \'Path to the directory to save logs and checkpoints.\')\nflags.DEFINE_multi_string(\'config_file\',\n                          None,\n                          \'Configuration file with parameters (.gin).\')\nflags.DEFINE_multi_string(\'config\',\n                          None,\n                          \'Configuration parameters (gin string).\')\n\n# TPU Flags\nflags.DEFINE_bool(\'use_tpu\', False, ""Whether we\'re running on TPU."")\nflags.DEFINE_string(\'jax_xla_backend\',\n                    \'xla\',\n                    \'Either ""xla"" for the XLA service directly, or ""tpu_driver""\'\n                    \'for a TPU Driver backend.\')\nflags.DEFINE_string(\'jax_backend_target\',\n                    \'local\',\n                    \'Either ""local"" or ""rpc:address"" to connect to a \'\n                    \'remote service target.\')\n\n# trainer.py flags.\nflags.DEFINE_string(\'dataset\', None, \'Which dataset to use.\')\nflags.DEFINE_string(\'model\', None, \'Which model to train.\')\nflags.DEFINE_string(\'data_dir\', None, \'Path to the directory with data.\')\nflags.DEFINE_integer(\'log_level\', logging.INFO, \'Log level.\')\n\n# TensorFlow Flags\nflags.DEFINE_bool(\'enable_eager_execution\',\n                  True,\n                  ""Whether we\'re running TF in eager mode."")\nflags.DEFINE_bool(\'tf_xla\', True, \'Whether to turn on XLA for TF.\')\nflags.DEFINE_bool(\'tf_opt_pin_to_host\',\n                  False,\n                  \'Whether to turn on TF pin-to-host optimization.\')\nflags.DEFINE_bool(\'tf_opt_layout\',\n                  False,\n                  \'Whether to turn on TF layout optimization.\')\nflags.DEFINE_bool(\'tf_xla_forced_compile\',\n                  False,\n                  \'Use forced-compilation instead of auto-clustering for XLA.\'\n                  \'This flag only has effects when --tf_xla is on.\')\nflags.DEFINE_bool(\'tf_allow_float64\', False, \'Whether to allow float64 for TF.\')\n\n# rl_trainer.py flags.\nflags.DEFINE_boolean(\'jax_debug_nans\',\n                     False,\n                     \'Setting to true will help to debug nans and disable jit.\')\nflags.DEFINE_boolean(\'disable_jit\', False, \'Setting to true will disable jit.\')\nflags.DEFINE_string(\'envs_output_dir\', \'\', \'Output dir for the envs.\')\nflags.DEFINE_bool(\'xm\', False, \'Copy atari roms?\')\nflags.DEFINE_integer(\'train_batch_size\',\n                     32,\n                     \'Number of parallel environments during training.\')\nflags.DEFINE_integer(\'eval_batch_size\', 4, \'Batch size for evaluation.\')\nflags.DEFINE_boolean(\'parallelize_envs\',\n                     False,\n                     \'If true, sets parallelism to number of cpu cores.\')\nflags.DEFINE_string(\'trajectory_dump_dir\',\n                    \'\',\n                    \'Directory to dump trajectories to.\')\nflags.DEFINE_bool(\'async_mode\', False, \'Async mode.\')\n'"
trax/trax2keras.py,1,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Trax-to-Keras converter.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\n\nimport tensorflow.compat.v2 as tf\n\nfrom trax import math as math_lib\nfrom trax import shapes as shapes_lib\nfrom trax.layers import base\nfrom trax.math import numpy as np\n\n\ndef _replace_none_batch(x, batch_size=None):\n  if batch_size is None:\n    return x\n  if isinstance(x, tf.Tensor) and x.shape[0] is None:\n    x.set_shape([batch_size] + x.shape[1:])\n    return x\n  elif isinstance(x, tf.TensorShape) and x[0] is None:\n    return [batch_size] + x[1:]\n  return x\n\n\ndef tensor_shapes_to_shape_dtypes(shapes, dtype):\n  return math_lib.nested_map(\n      lambda s: shapes_lib.ShapeDtype(s.as_list(), dtype), shapes)\n\n\ndef read_values(variables):\n  return math_lib.nested_map(lambda v: v.read_value(), variables)\n\n\ndef to_tensors(args):\n  return math_lib.nested_map(tf.convert_to_tensor, args)\n\n\ndef to_arrays(args):\n  return math_lib.nested_map(np.asarray, args)\n\n\nclass TraxKerasLayer(tf.keras.layers.Layer):\n  """"""A Keras layer built from a Trax layer.\n\n  This subclass of `tf.keras.layers.Layer` takes in a Trax layer as a\n  constructor argument and wraps it to be a Keras layer. It uses\n  `tf.Variable` to store weights and state (initialized according to the Trax\n  layer), and uses the Trax layer\'s forward function as its forward function.\n\n  Consider this code snippet:\n\n  ```\n  keras_layer = TraxKerasLayer(trax_layer, initializer_rng=initializer_rng,\n                               rng=rng, rng_updater=rng_updater)\n  keras_layer.build(...)  # optional\n  outputs = keras_layer(inputs)\n  ```\n\n  (Note that in Keras calling `Layer.build` is optional. If omitted, it will be\n  called automatically by `Layer.__call__`.)\n\n  If `trax_layer` already has weights at `build` time, the snippet is roughly\n  equivalent to:\n\n  ```\n  weights = trax_layer.weights\n  state = trax_layer.state\n  keras_layer = tf.keras.layers.Layer()\n  keras_layer._weights = tf.Variable(weights)\n  keras_layer._state = tf.Variable(state)\n  keras_layer._rng = tf.Variable(rng)\n  outputs, new_state = trax_layer(inputs, keras_layer._weights,\n                                  keras_layer._state, keras_layer._rng)\n  keras_layer._state.assign(new_state)\n  keras_layer._rng.assign(rng_updater(rng))\n  ```\n\n  If `trax_layer` doesn\'t have weights at `build` time, the snippet is roughly\n  equivalent to:\n\n  ```\n  weights, state = trax_layer.init(..., rng=initializer_rng)\n  keras_layer = ...\n  ...\n  ```\n\n  `TraxKeraLayer` uses `tf.Variable` to store weights, not shared with the\n  original Trax layer (which uses tensors to store weights), so using\n  `TraxKeraLayer` may double the memory footprint. This problem can be solved by\n  making sure that the Trax layer\'s weights/state are cleared whenever\n  `tf.Variable.assign` (and `tf.Variable.assign_add` etc.) is called, because\n  `tf.Variable` is copy-on-write by default.\n\n  Mutations in those `tf.Variable`s won\'t affect the Trax layer\'s weights, but\n  `TraxKeraLayer`\'s forward function calls the Trax layer\'s forward function,\n  which caches the weights in the Trax layer object, so a forward pass may\n  change the weights cached in the original Trax layer.\n\n  Note that this class is not thread-safe. If the same `TraxKerasLayer` object\n  is used in multiple threads, the `tf.Variable` updates may happen in a\n  non-deterministic order.\n  """"""\n\n  def __init__(self, trax_layer, batch_size=None, initializer_rng=None,\n               rng=None, rng_updater=None, dtype=None):\n    """"""Creates a Keras layer wrapping around a Trax layer.\n\n    Args:\n      trax_layer: an object of class `trax.layers.Layer`, the trax layer to\n        wrap.\n      batch_size: (optional) an integer, the batch size that this Keras layer\n        will be used on. Keras sometimes needs to generate a TF graph for a\n        layer (e.g. for acceleration or checkpointing). The inputs used to trace\n        the graph will have `None` as the length of their batch dimensions, so\n        as to generate a graph that can handle any batch size. Some Trax layers\n        can\'t handle tensors whose shapes contain `None`. If `batch_size` is set\n        to an integer, the graph will be traced with `batch_size` as the batch\n        size instead of `None`. Note that in this case the graph (and the Keras\n        layer) can only be used on a specific batch size. If you want to use a\n        different batch size, you need to create another `TraxKerasLayer` object\n        with a different `batch_size`.\n      initializer_rng: (optional) an RNG key used to create the weights and\n        state if `trax_layer` doesn\'t have them. If `None`,\n        `trax.math.random.get_prng(0)` will be used.\n      rng: (optional) an RNG key for the forward function (aka the ""forward\n        key""). If `None`, `trax.math.random.get_prng(0)` will be used.\n      rng_updater: (optional) a function of type rng_key -> rng_key, used to\n        update the forward key after each forward pass. If `None`, the function\n        `lambda x: trax.math.random.split(x, 1)[0]` will be used, which advances\n        the RNG key.\n      dtype: (optional) the dtype of the inputs. See the `dtype` argument of\n        `tf.keras.layers.Layer.__init__` for details.\n    """"""\n    super(TraxKerasLayer, self).__init__(dtype=dtype)\n    with math_lib.use_backend(""tf""):\n      if initializer_rng is None:\n        initializer_rng = math_lib.random.get_prng(0)\n      if rng is None:\n        rng = math_lib.random.get_prng(0)\n      if rng_updater is None:\n        rng_updater = lambda x: math_lib.random.split(x, 1)[0]\n      self._trax_layer = trax_layer\n      self._batch_size = batch_size\n      self._initializer_rng = initializer_rng\n      self._forward_rng_init = rng\n      self._rng_updater = rng_updater\n\n  def build(self, input_shape):\n    with math_lib.use_backend(""tf""):\n      # Using `is` instead of `==` following Trax\'s practice\n      if self._trax_layer.weights is base.EMPTY_WEIGHTS:\n        sanitized_input_shape = math_lib.nested_map(\n            functools.partial(_replace_none_batch, batch_size=self._batch_size),\n            input_shape)\n        weights, state = self._trax_layer.init(\n            tensor_shapes_to_shape_dtypes(sanitized_input_shape, self.dtype),\n            rng=self._initializer_rng)\n      else:\n        weights = self._trax_layer.weights\n        state = self._trax_layer.state\n      # Note: `weights` may contain `EMPTY_WEIGHTS`\n      self._weights = math_lib.nested_map(\n          functools.partial(tf.Variable, trainable=True), weights)\n      self._state = math_lib.nested_map(\n          functools.partial(tf.Variable, trainable=False), state)\n      self._rng = tf.Variable(self._forward_rng_init, trainable=False)\n    super(TraxKerasLayer, self).build(input_shape)\n\n  def call(self, inputs):\n    with math_lib.use_backend(""tf""):\n      inputs = math_lib.nested_map(\n          functools.partial(_replace_none_batch, batch_size=self._batch_size),\n          inputs)\n      weights, state, rng = read_values([self._weights, self._state, self._rng])\n      inputs, weights, state, rng = to_arrays([inputs, weights, state, rng])\n      outputs, new_state = self._trax_layer.pure_fn(inputs, weights=weights,\n                                                    state=state, rng=rng)\n      tf.nest.map_structure(lambda v, t: v.assign(t), self._state, new_state)\n      self._rng.assign(self._rng_updater(rng))\n      outputs = to_tensors(outputs)\n      return outputs\n'"
trax/trax2keras_test.py,5,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax2keras.""""""\n\nimport os\n\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\nimport numpy as onp\n\nimport tensorflow.compat.v2 as tf\n\nfrom trax import layers\nfrom trax import math as math_lib\nfrom trax import trax2keras\nfrom trax.math import numpy as np\nfrom trax.models import mlp\nfrom trax.models import transformer\nfrom trax.trax2keras import read_values\nfrom trax.trax2keras import to_arrays\nfrom trax.trax2keras import to_tensors\n\n\ntf.enable_v2_behavior()\n\n\ndef dummy_inputs(rng, input_sig):\n  def f(sig):\n    shape = sig.shape\n    if shape and shape[0] is None:\n      shape = (2,) + tuple(shape[1:])\n    if onp.issubdtype(sig.dtype, onp.integer):\n      minval = None\n    else:\n      minval = 0\n    return rng.uniform(shape=shape, dtype=sig.dtype, minval=minval)\n  return math_lib.nested_map(f, input_sig)\n\n\ndef Mod(n):  # pylint: disable=invalid-name\n  return layers.Fn(""Mod"", lambda x: x % n)\n\n\n# Format:\n#   (trax-layer maker, input shapes, input dtype, can handle None batch size?)\n_LAYERS = [\n    (lambda: layers.Dense(3), tf.TensorShape([4]), onp.float32, True),\n    (mlp.PureMLP, tf.TensorShape([4]), onp.float32, False),\n    (lambda: layers.Serial(Mod(8), transformer.TransformerLM(8)),\n     tf.TensorShape([4]), onp.int32, False),\n]\n\n\n_RNG_UPDATERS = [\n    lambda x: x,\n    lambda rng: math_lib.random.split(rng, 1)[0],\n]\n\n\n# Needs tf.test.TestCase for `assertAllClose` and `get_temp_dir`\nclass Trax2KerasTest(tf.test.TestCase, parameterized.TestCase):\n\n  @parameterized.named_parameters(\n      [{""testcase_name"": ""_%s_%s_%s_%s_%s_%s"" % (  # pylint: disable=g-complex-comprehension\n          layer_id, rng_updater_id, batch_size, trax_has_weights,\n          explicit_build, use_model),\n        ""layer_id"": layer_id,\n        ""rng_updater_id"": rng_updater_id,\n        ""batch_size"": batch_size,\n        ""trax_has_weights"": trax_has_weights,\n        ""explicit_build"": explicit_build,\n        ""use_model"": use_model,}\n       for use_model in [True, False]\n       for explicit_build in [True, False]\n       for trax_has_weights in [True, False]\n       for batch_size in [2, None]\n       for rng_updater_id in [1]\n       for layer_id in range(len(_LAYERS))\n      ])\n  def testTrain(self, layer_id, rng_updater_id, batch_size, trax_has_weights,\n                explicit_build, use_model):\n    """"""Tests training (forward and backward pass) for TraxKerasLayer.\n\n    Args:\n      layer_id: an integer, the index into `_LAYERS`.\n      rng_updater_id: an integer, the index into `_RNG_UPDATERS`.\n      batch_size: an integer or `None`, the value for the `batch_size` argument\n        in `TraxKerasLayer.__init__`.\n      trax_has_weights: bool, whether to make the trax layer contain weights at\n        the time when `TraxKerasLayer.build` is called.\n      explicit_build: bool, whether to explicitly call `TraxKerasLayer.build`.\n      use_model: bool, whether to build a `tf.keras.Model` out of the\n        `TraxKerasLayer` layer and use the model to do the training instead of\n        the bare layer. If `True`, we will also test checkpointing and restoring\n        using the model.\n    """"""\n    with math_lib.use_backend(""tf""):\n      make_trax_layer, input_shapes_no_batch, dtype, allow_none_batch = (\n          _LAYERS[layer_id])\n      # We make a fresh trax layer for each test case, so that different test\n      # cases won\'t interfere with each other.\n      trax_layer = make_trax_layer()\n      if not allow_none_batch and batch_size is None:\n        self.skipTest(""This Trax layer can\'t handle None batch size."")\n      rng_updater = _RNG_UPDATERS[rng_updater_id]\n      input_shapes = math_lib.nested_map(\n          lambda s: [batch_size] + s, input_shapes_no_batch)\n      input_sig = trax2keras.tensor_shapes_to_shape_dtypes(input_shapes, dtype)\n      initializer_rng = math_lib.random.get_prng(765)\n      weights, state = trax_layer.init(input_sig, rng=initializer_rng)\n      generator = tf.random.Generator.from_seed(567)\n      def get_inputs():\n        return dummy_inputs(generator, input_sig)\n      if trax_has_weights:\n        trax_layer(to_arrays(get_inputs()), weights=weights, state=state)\n      rng = math_lib.random.get_prng(1234)\n      keras_layer = trax2keras.TraxKerasLayer(\n          trax_layer, batch_size=batch_size, initializer_rng=initializer_rng,\n          rng=rng, rng_updater=rng_updater)\n      if explicit_build:\n        keras_layer.build(input_shapes)\n      if use_model:\n        x = tf.keras.Input(shape=input_shapes_no_batch, dtype=dtype)\n        y = keras_layer(x)\n        keras_model = tf.keras.Model(inputs=x, outputs=y)\n      lr = 0.1  # learning rate\n      for _ in range(3):\n        inputs = get_inputs()\n        with tf.GradientTape() as trax_tape:\n          trax_tape.watch([x.data for x in tf.nest.flatten(weights)])\n          trax_outputs, state = trax_layer.pure_fn(\n              to_arrays(inputs), weights=weights, state=state, rng=rng)\n        trax_grads = trax_tape.gradient(*to_tensors([trax_outputs, weights]))\n        # `g` may be `tf.IndexedSlices`, so we need to `convert_to_tensor`\n        # before multiplication.\n        weights = tf.nest.map_structure(\n            lambda w, g: w + np.asarray(lr * tf.convert_to_tensor(g), w.dtype),\n            weights, trax_grads)\n        rng = rng_updater(rng)\n        with tf.GradientTape() as keras_tape:\n          if use_model:\n            keras_outputs = keras_model(inputs)\n          else:\n            keras_outputs = keras_layer(inputs)\n        if isinstance(keras_outputs, tuple) and len(keras_outputs) == 1:\n          keras_outputs = keras_outputs[0]\n        self.assertAllClose(to_tensors(trax_outputs), keras_outputs)\n        keras_grads = keras_tape.gradient(keras_outputs,\n                                          keras_layer.trainable_variables)\n        tf.nest.map_structure(\n            lambda v, g: v.assign_add(  # pylint: disable=g-long-lambda\n                tf.cast(lr * tf.convert_to_tensor(g), v.dtype)),\n            keras_layer.trainable_variables, keras_grads)\n        self.assertAllClose(\n            to_tensors(weights), read_values(keras_layer._weights),\n            rtol=2e-6, atol=1e-6)\n        self.assertAllClose(to_tensors(state), read_values(keras_layer._state))\n        self.assertAllClose(to_tensors(rng), read_values(keras_layer._rng))\n      if use_model:\n        fname = os.path.join(self.get_temp_dir(), ""checkpoint"")\n        keras_model.save(fname)\n        loaded_model = tf.keras.models.load_model(fname)\n        for _ in range(2):\n          inputs = get_inputs()\n          self.assertAllClose(keras_model(inputs), loaded_model(inputs))\n\n\nif __name__ == ""__main__"":\n  absltest.main()\n'"
trax/utils.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Utility functions.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport pickle\nimport sys\n\nimport cloudpickle\n\n\ndef get_pickle_module():\n  """"""Returns the appropriate pickle module based on Python version.""""""\n  # TODO(gilmer, lukaszkaiser): figure out how to use cloudpickle in python3.\n  # Currently the code throws an error when run in python3.\n  if sys.version_info[0] < 3:\n    return cloudpickle\n  else:\n    return pickle\n'"
docs/source/conf.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n""""""Configuration file for Sphinx autodoc API documentation builder.""""""\n\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath(\'../..\'))\n\n\n# -- Project information -----------------------------------------------------\n\nproject = \'Trax\'\ncopyright = \'2020, Google LLC.\'  # pylint: disable=redefined-builtin\nauthor = \'The Trax authors\'\n\n# The short X.Y version\nversion = \'\'\n# The full version, including alpha/beta/rc tags\nrelease = \'\'\n\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.napoleon\',\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = []\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = None\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don\'t match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``[\'localtoc.html\', \'relations.html\', \'sourcelink.html\',\n# \'searchbox.html\']``.\n#\n# html_sidebars = {}\n\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'Traxdoc\'\n\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'Trax.tex\', \'Trax Documentation\',\n     \'Trax authors\', \'manual\'),\n]\n\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'trax\', \'Trax Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'Trax\', \'Trax Documentation\',\n     author, \'Trax\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n\n# -- Options for Epub output -------------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = project\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#\n# epub_identifier = \'\'\n\n# A unique identification for the text.\n#\n# epub_uid = \'\'\n\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = [\'search.html\']\n\n\n# -- Extension configuration -------------------------------------------------\n\nautodoc_member_order = \'bysource\'\n\nautodoc_default_options = {\n    \'special-members\': \'__call__, __init__\',\n}\n\nautodoc_mock_imports = [\n    \'gin\',\n    \'jax\',\n    \'numpy\',\n    \'tensorflow\',\n    \'tensorflow_datasets\',\n    \'funcsigs\',\n    \'trax.tf_numpy\',\n    \'absl\',\n    \'gym\',\n    \'tensor2tensor\',\n    \'tensorflow_text\',\n    \'matplotlib\',\n    \'cloudpickle\',\n    \'t5\',\n    # \'setup\',\n]\n\n'"
trax/layers/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Layers defined in trax.""""""\n\nimport gin\n# We create a flat layers.* namespace for uniform calling conventions as we\n# upstream changes.\n# pylint: disable=wildcard-import\nfrom trax.layers.activation_fns import *\nfrom trax.layers.attention import *\nfrom trax.layers.base import *\nfrom trax.layers.combinators import *\nfrom trax.layers.convolution import *\nfrom trax.layers.core import *\nfrom trax.layers.initializers import *\nfrom trax.layers.metrics import *\nfrom trax.layers.normalization import *\nfrom trax.layers.pooling import *\nfrom trax.layers.research.efficient_attention import *\nfrom trax.layers.research.position_encodings import *\nfrom trax.layers.reversible import *\nfrom trax.layers.rnn import *\n\n\n# Ginify\ndef layer_configure(*args, **kwargs):\n  kwargs[\'module\'] = \'trax.layers\'\n  return gin.external_configurable(*args, **kwargs)\n\n# pylint: disable=used-before-assignment\n# pylint: disable=invalid-name\nRelu = layer_configure(Relu)\nGelu = layer_configure(Gelu)\nFastGelu = layer_configure(FastGelu)\nSigmoid = layer_configure(Sigmoid)\nTanh = layer_configure(Tanh)\nHardSigmoid = layer_configure(HardSigmoid)\nHardTanh = layer_configure(HardTanh)\nExp = layer_configure(Exp)\nLogSoftmax = layer_configure(LogSoftmax)\nSoftmax = layer_configure(Softmax)\nSoftplus = layer_configure(Softplus)\nL2Loss = layer_configure(L2Loss)\nLSTMCell = layer_configure(LSTMCell)\nGRUCell = layer_configure(GRUCell)\n\nBatchNorm = layer_configure(BatchNorm)\nFilterResponseNorm = layer_configure(FilterResponseNorm)\nThresholdedLinearUnit = layer_configure(ThresholdedLinearUnit)\n\nDotProductCausalAttention = layer_configure(\n    DotProductCausalAttention, blacklist=[\'mode\'])\nSelfAttention = layer_configure(SelfAttention, blacklist=[\'mode\'])\nLSHSelfAttention = layer_configure(LSHSelfAttention, blacklist=[\'mode\'])\nEncDecAttention = layer_configure(EncDecAttention, blacklist=[\'mode\'])\n\nInfinitePositionalEncoding = layer_configure(\n    InfinitePositionalEncoding, blacklist=[\'mode\'])\nTimeBinPositionalEncoding = layer_configure(\n    TimeBinPositionalEncoding, blacklist=[\'mode\'])\n\nAtariConvInit = layer_configure(AtariConvInit)\n'"
trax/layers/activation_fns.py,13,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Layers that compute activation functions.\n\nAn activation layer computes element-wise a nonlinear function of the preceding\nlayer\'s output. Historically, an activation function was considered part of\neach node in each layer of the neural network. Trax follows the common current\npractice of separating the activation function as its own layer, which enables\neasier experimentation across different activation functions.\n""""""\n\nfrom trax import math\nfrom trax.layers import base\nfrom trax.layers.base import Fn\nfrom trax.math import numpy as np\n\n\ndef Relu():\n  return Fn(\'Relu\', lambda x: np.maximum(x, np.zeros_like(x)))\n\n\ndef ParametricRelu(a=1.):\n  return Fn(\'ParametricRelu\', lambda x: np.maximum(a * x, np.zeros_like(x)))\n\n\ndef LeakyRelu(a=0.01):\n  return Fn(\'LeakyRelu\', lambda x: np.where(x >= 0, x, a * x))\n\n\ndef Elu(a=1.):\n  return Fn(\'Elu\', lambda x: np.where(x > 0, x, a * np.expm1(x)))\n\n\ndef Selu(alpha=1.6732632423543772848170429916717,\n         lmbda=1.0507009873554804934193349852946):\n  return Fn(\'Selu\', lambda x: lmbda * np.where(x > 0, x, alpha * np.expm1(x)))\n\n\ndef Gelu():\n  return Fn(\'Gelu\', lambda x: x * 0.5 * (1.0 + math.erf(x / np.sqrt(2.0))))\n\n\ndef FastGelu():\n  def f(x):  # pylint: disable=invalid-name\n    return 0.5 * x * (1 + np.tanh(x * 0.7978845608 * (1 + 0.044715 * x * x)))\n  return Fn(\'FastGelu\', f)\n\n\n# pylint: disable=unnecessary-lambda\ndef Sigmoid():\n  return Fn(\'Sigmoid\', lambda x: math.expit(x))\n\n\ndef Tanh():\n  return Fn(\'Tanh\', lambda x: np.tanh(x))\n# pylint: enable=unnecessary-lambda\n\n\ndef HardSigmoid():\n  """"""Computes a linear approximation to sigmoid.""""""\n  return Fn(\'HardSigmoid\', lambda x: np.maximum(0, np.minimum(1, (1 + x))))\n\n\ndef HardTanh():\n  """"""Computes a linear approximation to tanh.""""""\n  return Fn(\'HardTanh\', lambda x: np.maximum(-1, np.minimum(1, x)))\n\n\ndef Softplus():\n  return Fn(\'Softplus\', lambda x: np.logaddexp(x, 0.))\n\n\nclass ThresholdedLinearUnit(base.Layer):\n  """"""Thresholded Linear Unit, c.f. https://arxiv.org/pdf/1911.09737.pdf .""""""\n\n  def new_weights(self, input_signature):\n    del input_signature\n    return (np.zeros((), dtype=np.float32),)\n\n  def forward(self, inputs, weights):\n    threshold = weights[0]\n    return np.maximum(inputs, threshold)\n'"
trax/layers/activation_fns_test.py,5,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for activation function layers.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\n\nimport trax.layers as tl\n\n\nclass ActivationFnsTest(absltest.TestCase):\n\n  def test_relu(self):\n    layer = tl.Relu()\n    x = np.array([-2.0, -1.0, 0.0, 2.0, 3.0, 5.0])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [0.0, 0.0, 0.0, 2.0, 3.0, 5.0])\n\n  def test_parametric_relu(self):\n    layer = tl.ParametricRelu(a=.25)\n    x = np.array([-2.0, -1.0, 0.0, 2.0, 3.0, 5.0])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [0.0, 0.0, 0.0, .5, .75, 1.25])\n\n  def test_leaky_relu(self):\n    layer = tl.LeakyRelu(a=.125)\n    x = np.array([-2.0, -1.0, 0.0, 2.0, 3.0, 5.0])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [-.25, -.125, 0.0, 2.0, 3.0, 5.0])\n\n  def test_hard_sigmoid(self):\n    layer = tl.HardSigmoid()\n    x = np.array([-1.5, -.5, -.25, 0.0, .25, .5, 1.5])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [0.0, 0.5, 0.75, 1.0, 1.0, 1.0, 1.0])\n\n  def test_hard_tanh(self):\n    layer = tl.HardTanh()\n    x = np.array([-1.5, -.5, -.25, 0.0, .25, .5, 1.5])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [-1.0, -.5, -.25, 0.0, .25, .5, 1.0])\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/layers/attention.py,30,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Attention Layers.""""""\n\nimport jax\nimport numpy as np\n\nfrom trax import math\nfrom trax.layers import base\nfrom trax.layers import combinators as cb\nfrom trax.layers import core\nfrom trax.layers.base import Fn\nfrom trax.math import numpy as jnp\n\n\n# Layers are always CamelCase, but functions in general are snake_case\n# pylint: disable=invalid-name\n\n\ndef Attention(d_feature, n_heads=1, dropout=0.0, mode=\'train\'):\n  """"""Returns a layer that maps (activations, mask) to (new_activations, mask).\n\n  This layer type represents one pass of multi-head self-attention, best\n  known for its central role in Transformer models. Internally, it:\n\n    - maps activations to `(queries, keys, values)` triples,\n    - splits `queries`, `keys`, and `values` into multiple \'heads\',\n    - computes per-head attention weights from per-head `(queries, keys)`,\n    - applies `mask` to screen out positions that come from padding tokens,\n    - optionally applies dropout to attention weights,\n    - uses attention weights to combine per-head `values` vectors, and\n    - fuses per-head results into activations matching original input shapes.\n\n  Args:\n    d_feature: Depth/dimensionality of feature embedding.\n    n_heads: Number of attention heads.\n    dropout: Probababilistic rate for internal dropout applied to attention\n        activations (based on query-key pairs) before dotting them with values.\n    mode: Either \'train\' or \'eval\'.\n  """"""\n  return cb.Serial(\n      cb.Dup(), cb.Dup(),  # TODO(jonni): replace with Select([0, 0, 0])\n      AttentionQKV(d_feature, n_heads=n_heads, dropout=dropout, mode=mode),\n  )\n\n\ndef AttentionQKV(d_feature, n_heads=1, dropout=0.0, mode=\'train\'):\n  """"""Returns a layer that maps (q, k, v, mask) to (activations, mask).\n\n  See `Attention` above for further context/details.\n\n  Args:\n    d_feature: Depth/dimensionality of feature embedding.\n    n_heads: Number of attention heads.\n    dropout: Probababilistic rate for internal dropout applied to attention\n        activations (based on query-key pairs) before dotting them with values.\n    mode: Either \'train\' or \'eval\'.\n  """"""\n  return cb.Serial(\n      cb.Parallel(\n          core.Dense(d_feature),\n          core.Dense(d_feature),\n          core.Dense(d_feature),\n      ),\n      PureAttention(  # pylint: disable=no-value-for-parameter\n          n_heads=n_heads, dropout=dropout, mode=mode),\n      core.Dense(d_feature),\n  )\n\n\nclass PureAttention(base.Layer):\n  """"""Layer that maps from (queries, keys, values, mask) to (activations, mask).\n\n  This layer type performs the inner workings of one pass of multi-head\n  self-attention. It:\n\n    - splits `queries`, `keys`, and `values` into multiple \'heads\',\n    - computes per-head attention weights from per-head `(queries, keys)`,\n    - applies `mask` to screen out positions that come from padding tokens,\n    - optionally applies dropout to attention weights,\n    - uses attention weights to combine per-head `values` vectors, and\n    - merges per-head results into activations matching original input shapes.\n  """"""\n\n  def __init__(self, n_heads=1, dropout=0.0, mode=\'train\'):\n    super(PureAttention, self).__init__(n_in=4, n_out=2)\n    self._n_heads = n_heads\n    self._dropout = dropout\n    self._mode = mode\n\n  def forward(self, inputs, weights):\n    """"""Returns attention-computed activations, unmodified mask, and state.\n\n    Args:\n      inputs: Tuple of (queries, keys, values, mask).\n      weights: Not used; should be empty tuple or list.\n\n    Returns:\n      The pair (activations, mask).\n    """"""\n    del weights\n    q, k, v, mask = inputs\n\n    batch_size = q.shape[0]\n    d_feature = q.shape[-1]\n    n_heads = self._n_heads\n    if d_feature % n_heads != 0:\n      raise ValueError(\n          f\'Dimensionality of feature embedding ({d_feature}) is not a \'\n          f\'multiple of the requested number of attention heads ({n_heads}).\')\n\n    d_head = d_feature // n_heads\n\n    def _split_into_heads(x):\n      """"""Reshapes tensors to prepare for multi-head computation.""""""\n      # (b_size, seq_len, d_feature) --> (b_size, n_heads, seq_len, d_head)\n      x = x.reshape((batch_size, -1, n_heads, d_head))\n      x = x.transpose((0, 2, 1, 3))\n      return x\n\n    def _merge_heads(x):\n      """"""Undoes splitting, after multi-head computation.""""""\n      # (b_size, n_heads, seq_len, d_head) --> (b_size, seq_len, d_feature)\n      x = x.transpose((0, 2, 1, 3))\n      x = x.reshape((batch_size, -1, n_heads * d_head))\n      return x\n\n    per_head_results = DotProductAttention(_split_into_heads(q),\n                                           _split_into_heads(k),\n                                           _split_into_heads(v),\n                                           mask,\n                                           dropout=self._dropout,\n                                           mode=self._mode,\n                                           rng=self.rng)\n    merged_results = _merge_heads(per_head_results)\n    return (merged_results, mask)\n\n\ndef DotProductAttention(queries, keys, values, mask, dropout, mode, rng):\n  """"""Computes new activations via masked attention-weighted sum of values.\n\n  This function is the core of the attention mechanism. It:\n    - computes per-head attention weights from per-head `(queries, keys)`,\n    - applies `mask` to screen out positions that come from padding tokens,\n    - optionally applies dropout to attention weights, and\n    - uses attention weights to combine per-head `values` vectors.\n\n  Args:\n    queries: Per-head activations representing attention queries.\n    keys: Per-head activations representing attention keys.\n    values: Per-head activations to be combined by computed attention weights.\n    mask: Mask that distinguishes positions with real content vs. padding.\n    dropout: Probababilistic rate for dropout applied to attention activations\n        (based on query-key pairs) before dotting them with values.\n    mode: Either \'train\' or eval\'. Dropout applies only in \'train\' mode.\n    rng: Single-use random number generator (JAX PRNG key).\n\n  Returns:\n    Per-head activations resulting from masked per-head attention-weighted\n    sum of per-head values.\n  """"""\n  d_feature = queries.shape[-1]\n  dots = jnp.matmul(queries, jnp.swapaxes(keys, -1, -2)) / jnp.sqrt(d_feature)\n  if mask is not None:\n    # TODO(kitaev): workaround for https://github.com/google/jax/issues/850\n    # We must ensure that both mask and the -1e9 constant have a data dependency\n    # on the input. Broadcasted copies of these use a lot of memory, so they\n    # should be computed at runtime (rather than being global constants).\n    if math.backend_name() == \'jax\':\n      mask = jax.lax.tie_in(dots, mask)\n    # JAX\'s `full_like` already ties in -1e9 to dots.\n    dots = jnp.where(mask, dots, jnp.full_like(dots, -1e9))\n  # Softmax.\n  dots = jnp.exp(dots - math.logsumexp(dots, axis=-1, keepdims=True))\n  if dropout >= 1.0:\n    raise ValueError(\'Dropout rates must be lower than 1.\')\n  if dropout is not None and dropout > 0.0 and mode == \'train\':\n    keep = math.random.bernoulli(rng, 1.0 - dropout, dots.shape)\n    dots = jnp.where(keep, dots / (1.0 - dropout), jnp.zeros_like(dots))\n  out = jnp.matmul(dots, values)\n  return out\n\n\ndef CausalAttention(d_feature, n_heads=1, dropout=0.0, mode=\'train\'):\n  """"""Returns a layer that maps activations to activations, with causal masking.\n\n  Like `Attention`, this layer type represents one pass of multi-head\n  self-attention, but with causal masking in place of padding-based masking.\n\n  Args:\n    d_feature: Depth/dimensionality of feature embedding.\n    n_heads: Number of attention heads.\n    dropout: Probababilistic rate for internal dropout applied to attention\n        activations (based on query-key pairs) before dotting them with values.\n    mode: Either \'train\' or \'eval\'.\n  """"""\n  if d_feature % n_heads != 0:\n    raise ValueError(\n        f\'Dimensionality of feature embedding ({d_feature}) is not a multiple \'\n        f\'of the requested number of attention heads ({n_heads}).\')\n\n  d_head = d_feature // n_heads\n\n  def _split_into_heads():\n    """"""Layer that reshapes tensors to prepare for multi-headed computation.""""""\n    def f(x):\n      batch_size = x.shape[0]\n      seq_len = x.shape[1]\n\n      # (b_size, seq_len, d_feature) --> (b_size*n_heads, seq_len, d_head)\n      x = x.reshape((batch_size, seq_len, n_heads, d_head))\n      x = x.transpose((0, 2, 1, 3))\n      x = x.reshape((-1, seq_len, d_head))\n      return x\n    return Fn(\'SplitIntoHeads\', f)\n\n  def _merge_heads():\n    """"""Layer that undoes splitting, after multi-head computation.""""""\n    def f(x):\n      seq_len = x.shape[1]\n\n      # (b_size*n_heads, seq_len, d_head) --> (b_size, seq_len, d_feature)\n      x = x.reshape((-1, n_heads, seq_len, d_head))\n      x = x.transpose((0, 2, 1, 3))\n      x = x.reshape((-1, seq_len, n_heads * d_head))\n      return x\n    return Fn(\'MergeHeads\', f)\n\n  return cb.Serial(\n      cb.Branch(\n          [core.Dense(d_feature), _split_into_heads()],\n          [core.Dense(d_feature), _split_into_heads()],\n          [core.Dense(d_feature), _split_into_heads()],\n      ),\n      DotProductCausalAttention(dropout=dropout, mode=mode),\n      _merge_heads(),\n      core.Dense(d_feature),\n  )\n\n\nclass DotProductCausalAttention(base.Layer):\n  """"""Computes new activations via causally masked attention-weighted values.""""""\n\n  def __init__(self, dropout=0.0, mode=\'train\'):\n    super(DotProductCausalAttention, self).__init__(n_in=3, n_out=1)\n    self._dropout = dropout\n    self._mode = mode\n\n  def forward(self, inputs, weights):\n    del weights\n    q, k, v = inputs\n\n    if self._mode == \'predict\':\n      self.state = _fast_inference_update_state(inputs, self.state)\n      (k, v, mask, _) = self.state\n    else:\n      mask_size = q.shape[-2]\n      # Not all backends define jnp.tril. However, using np.tril is inefficient\n      # in that it creates a large global constant. TODO(kitaev): try to find an\n      # alternative that works across all backends.\n      if math.backend_name() == \'jax\':\n        mask = jnp.tril(\n            jnp.ones((1, mask_size, mask_size), dtype=np.bool_), k=0)\n      else:\n        mask = np.tril(\n            np.ones((1, mask_size, mask_size), dtype=np.bool_), k=0)\n\n    res = DotProductAttention(\n        q, k, v, mask, dropout=self._dropout, mode=self._mode, rng=self.rng)\n    return res\n\n  def new_weights(self, input_signature):\n    if self._mode == \'predict\':\n      max_len = 2048  # Hardcoded.  TODO(pkozakowski): Pass it from the model.\n      self.state = _fast_inference_init_state(input_signature, max_len)\n    return base.EMPTY_WEIGHTS\n\n\ndef zero_pad(x, pad, axis):\n  """"""Helper for jnp.pad with 0s for single-axis case.""""""\n  pad_widths = [(0, 0)] * len(x.shape)\n  pad_widths[axis] = pad  # Padding on axis.\n  return jnp.pad(x, pad_widths, mode=\'constant\',\n                 constant_values=x.dtype.type(0))\n\n\ndef ShiftRight(n_shifts=1, mode=\'train\'):\n  """"""Layer to shift the tensor to the right by padding on axis 1.""""""\n  def f(x):\n    if mode == \'predict\':\n      # Do nothing in predict mode, as then the sequence length is 1.\n      return x\n    padded = zero_pad(x, (n_shifts, 0), 1)\n    return padded[:, :-n_shifts]\n  return Fn(f\'ShiftRight({n_shifts})\', f)\n\n\ndef PaddingMask(pad=0):\n  """"""Layer to distinguish positions with real content/tokens vs. padding.""""""\n  def f(x):\n    # TODO(jonni): Check/require that len(x.shape) == 2?\n    batch_size = x.shape[0]\n    d_feature = x.shape[-1]\n    content_positions = (x != pad)\n    return content_positions.reshape((batch_size, 1, 1, d_feature))\n  return Fn(f\'PaddingMask({pad})\', f)\n\n\ndef EncoderDecoderMask():\n  """"""Makes encoder-decoder mask from decoder input and a padding mask.""""""\n  def f(decoder_input, mask):\n    batch_size = mask.shape[0]\n    d_feature = mask.shape[-1]\n    mask = mask.reshape((batch_size, 1, 1, d_feature))\n    # Final mask shape is [batch, 1 for heads, decoder-len, encoder-len].\n    return mask + jnp.zeros((1, 1, decoder_input.shape[1], 1))\n  return Fn(\'EncoderDecoderMask\', f)\n\n\nclass PositionalEncoding(base.Layer):\n  """"""Implements bare positional encoding.""""""\n\n  def __init__(self, max_len=2048, dropout=0.0, dropout_broadcast_dims=(-2,),\n               mode=\'train\'):\n    super(PositionalEncoding, self).__init__()\n    self._max_len = max_len\n    if dropout >= 1.0:\n      raise ValueError(\'Dropout rates must be lower than 1.\')\n    if mode == \'train\':\n      self._dropout = dropout\n    else:\n      self._dropout = 0.0\n    self._dropout_broadcast_dims = dropout_broadcast_dims\n    self._mode = mode\n\n  def forward(self, inputs, weights):\n    if self._mode != \'predict\':\n      x = inputs\n      symbol_size = jnp.shape(x)[1]\n      px = weights[:, :symbol_size, :]\n      if self._dropout == 0:\n        return x + px\n      else:\n        noise_shape = list(px.shape)\n        for dim in self._dropout_broadcast_dims:\n          noise_shape[dim] = 1\n        keep_prob = 1.0 - self._dropout\n        if math.backend_name() == \'jax\':\n          keep_prob = jax.lax.tie_in(x, jnp.full((), keep_prob, dtype=x.dtype))\n        keep = math.random.bernoulli(self.rng, keep_prob, tuple(noise_shape))\n        multiplier = keep.astype(x.dtype) / keep_prob\n        return x + px * multiplier\n    else:\n      if self._dropout != 0:\n        raise ValueError(f\'In predict mode, but dropout rate \'\n                         f\'({self._dropout}) is not zero.\')\n\n      # State in this class is only used for fast inference. In that case,\n      # the model is called with consecutive elements position-by-position.\n      # This positional encoding layer needs to store the index of the current\n      # position then and increment it on each call -- that\'s how state is used\n      # and updated below.\n      state = self.state\n      if inputs.shape[1] == 1:\n        self.state = state + 1\n        return inputs + jnp.expand_dims(weights[0, state, :], 1)\n      else:\n        emb = []\n        for i in range(inputs.shape[0]):\n          emb.append(jax.lax.dynamic_slice_in_dim(\n              weights[0], state[i], inputs.shape[1], axis=0))\n        self.state = state + inputs.shape[1]\n        return inputs + jnp.stack(emb, 0)\n\n  def new_weights(self, input_signature):\n    d_feature = input_signature.shape[-1]\n    pe = np.zeros((self._max_len, d_feature), dtype=np.float32)\n    position = np.arange(0, self._max_len)[:, np.newaxis]\n    div_term = np.exp(\n        np.arange(0, d_feature, 2) * -(np.log(10000.0) / d_feature))\n    pe[:, 0::2] = np.sin(position * div_term)\n    pe[:, 1::2] = np.cos(position * div_term)\n    pe = pe[np.newaxis, :, :]  # [1, self._max_len, d_feature]\n    weights = jnp.array(pe)  # Trainable parameters, initialized above.\n    if self._mode == \'predict\':\n      batch_size = input_signature.shape[0]\n      self.state = jnp.zeros((batch_size,), dtype=jnp.int32)\n    return weights\n\n\ndef _fast_inference_init_state(input_signature, buffer_length):\n  """"""Returns an initial state for causal attention layer fast inference.""""""\n  def zeros_for(batch_size, shape_dtype):\n    shape, dtype = shape_dtype.as_tuple()\n    d_feature = shape[-1]\n    return jnp.zeros((batch_size, buffer_length, d_feature), dtype=dtype)\n\n  batch_size = input_signature[0].shape[0]\n  k = zeros_for(batch_size, input_signature[1])\n  v = zeros_for(batch_size, input_signature[2])\n  mask = jnp.zeros((batch_size, 1, buffer_length))\n  seq_indices = jnp.zeros((batch_size,), dtype=jnp.int32)\n  return (k, v, mask, seq_indices)\n\n\ndef _fast_inference_update_state(inputs, state):\n  """"""Updates state of a causal attention layer for fast inference.""""""\n  if math.backend_name() != \'jax\':\n    raise ValueError(f\'JAX backend is required in predict mode, but found \'\n                     f\'backend ({math.backend_nameO()}).\')\n  for x in inputs:\n    if x.shape[1] != 1:\n      raise ValueError(f\'In predict mode, input sequence must have length 1, \'\n                       f\'instead has length {x.shape[1]}.\')\n  # Fast inference: run with only 1 query in each step, storing the sequence\n  # of keys and values calculated so far in state.\n  (_, new_k, new_v) = inputs\n  (ks, vs, mask, seq_indices) = state\n  batch_indices = jnp.arange(ks.shape[0])\n  ks = jax.ops.index_update(\n      ks, jax.ops.index[batch_indices, seq_indices, :], new_k[:, 0, :])\n  vs = jax.ops.index_update(\n      vs, jax.ops.index[batch_indices, seq_indices, :], new_v[:, 0, :])\n  mask = jax.ops.index_update(\n      mask, jax.ops.index[batch_indices, :, seq_indices], 1)\n  return (ks, vs, mask, seq_indices + 1)\n'"
trax/layers/attention_test.py,7,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for trax.layers.attention.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\n\nimport trax.layers as tl\n\n\nclass AttentionTest(absltest.TestCase):\n\n  def test_shift_right(self):\n    # Test shifts right on axis=1\n    layer = tl.ShiftRight()\n    x = np.array([[[9, 9, 9],\n                   [8, 8, 8],\n                   [7, 7, 7],\n                   [6, 6, 6]],\n                  [[99, 98, 97],\n                   [96, 95, 94],\n                   [93, 92, 91],\n                   [90, 89, 88]]])\n    y = layer(x)\n    self.assertEqual(x.shape, y.shape)\n    self.assertEqual(tl.to_list(y), [[[0, 0, 0],\n                                      [9, 9, 9],\n                                      [8, 8, 8],\n                                      [7, 7, 7]],\n                                     [[0, 0, 0],\n                                      [99, 98, 97],\n                                      [96, 95, 94],\n                                      [93, 92, 91]]])\n\n  def test_shift_right_float(self):\n    layer = tl.ShiftRight()\n    x = np.array([[[9, 9, 9],\n                   [8, 8, 8],\n                   [7, 7, 7],\n                   [6, 6, 6]],\n                  [[99, 98, 97],\n                   [96, 95, 94],\n                   [93, 92, 91],\n                   [90, 89, 88]]]).astype(np.float32)\n    x /= 2.0\n    self.assertEqual(x.dtype, np.float32)\n\n    y = layer(x)\n    self.assertEqual(y.dtype, np.float32)\n    self.assertEqual(tl.to_list(y), [[[0.0, 0.0, 0.0],\n                                      [4.5, 4.5, 4.5],\n                                      [4.0, 4.0, 4.0],\n                                      [3.5, 3.5, 3.5]],\n                                     [[0.0, 0.0, 0.0],\n                                      [49.5, 49.0, 48.5],\n                                      [48.0, 47.5, 47.0],\n                                      [46.5, 46.0, 45.5]]])\n\n  def test_padding_mask(self):\n    layer = tl.PaddingMask()\n    x = np.array([\n        [1., 2., 3., 4., 0.],\n        [1., 2., 3., 0., 0.],\n        [1., 2., 0., 0., 0.],\n    ])\n    y = layer(x)\n    self.assertEqual(x.shape, (3, 5))\n    self.assertEqual(y.shape, (3, 1, 1, 5))\n    np.testing.assert_equal(y, [[[[True, True, True, True, False]]],\n                                [[[True, True, True, False, False]]],\n                                [[[True, True, False, False, False]]]])\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/layers/base.py,7,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Base layer class.""""""\n\nimport copy\nimport inspect\nimport pickle\nimport random\nimport traceback\n\nimport jax\nimport numpy as np\nimport tensorflow as tf\n\nfrom trax import math\nfrom trax.math import nested_map\nfrom trax.math import numpy as jnp\nfrom trax.shapes import ShapeDtype\nfrom trax.shapes import signature\n\n\n# TODO(lukaszkaiser): distinguish the 2 kinds below and add more tests.\nEMPTY_WEIGHTS = ()    # Used for layers that have no trainable weights.\nEMPTY_STATE = ()      # Used for layers that have no non-trainable state.\nGET_WEIGHTS_FROM_CACHE = ()  # Used to mark that the weights are shared.\nGET_STATE_FROM_CACHE = ()    # Used to mark that the state is shared.\n\n\nclass Layer:\n  """"""Base class for composable layers in a deep learning network.\n\n  Layers are the basic building blocks for deep learning models. A Trax layer\n  computes a function from zero or more inputs to zero or more outputs,\n  optionally using trainable weights (common) and non-parameter state (not\n  common). Authors of new layer subclasses typically override at most two\n  methods of the base `Layer` class:\n\n    `forward(inputs, weights)`:\n      Computes this layer\'s output as part of a forward pass through the model.\n\n    `new_weights(self, input_signature)`:\n      Returns new weights suitable for inputs with the given signature.\n\n  A small subset of layer types are combinators -- they organize the computation\n  of their sublayers, e.g., applying their sublayers in series or in parallel.\n\n  All layers have the following properties, with default values implemented\n  in the base `Layer` class:\n\n    - `n_in`: int (default 1)\n    - `n_out`: int (default 1)\n    - `weights`: tuple (default empty -- the layer has no weights)\n    - `state`: tuple (default empty -- the layer has no non-parameter state)\n    - `sublayers`: tuple (default empty -- the layer has no sublayers)\n\n  The inputs to a layer are tensors, packaged according to how many there are:\n\n    - `n_in = 0`: an empty tuple\n    - `n_in = 1`: one tensor (NOT wrapped in a tuple)\n    - `n_in > 1`: a tuple of tensors\n\n  (The special treatment of the single-input case is meant to simplify the\n  work of layer writers; this design choice may be revisited in the future.)\n\n  The outputs from a layer are also tensors, packaged the same as layer inputs:\n\n    - `n_out = 0`: an empty tuple\n    - `n_out = 1`: the tensor (NOT wrapped in a tuple)\n    - `n_out > 1`: a tuple of tensors\n\n  The Trax runtime maintains a data stack with which layer calls are composed.\n  For more complex data network architectures, possibly involving multiple data\n  flows, one can view each layer as a function from stack state to stack state,\n  where the function\'s inputs are a slice from the stack, and the function\'s\n  outputs are spliced back into the stack.\n  """"""\n\n  def __init__(self, n_in=1, n_out=1, name=None):\n    """"""Creates a partially initialized, unconnected layer instance.\n\n    Args:\n      n_in: Number of inputs expected by this layer.\n      n_out: Number of outputs promised by this layer.\n      name: Class-like name for this layer; for use in debugging.\n    """"""\n    self._n_in = n_in\n    self._n_out = n_out\n    self._name = name or self.__class__.__name__\n    self._sublayers = ()  # Default is no sublayers.\n    # This may run before some backends (e.g. JAX) are initialized, so we use\n    # Python `int` here instead of `math.random.get_prng` (also note that\n    # different backends\' `get_prng` may return different shapes so they can\'t\n    # be used interchangeably).\n    self._rng = random.randint(0, 2**31 - 1)\n    self._weights = EMPTY_WEIGHTS  # cached weights\n    self._state = EMPTY_STATE\n    # record root call site for custom error messages:\n    frame = _find_frame(inspect.currentframe())\n    # Turns out that frame can mutate in time, so we just copy what we need.\n    self._caller = {\'filename\': copy.copy(frame.f_code.co_filename),\n                    \'lineno\': int(frame.f_lineno)}\n    del frame  # Just in case.\n    self._init_cached = False\n    self._jit_cache = {}\n\n  def __repr__(self):\n    def indent_string(x):\n      return \'  \' + x.replace(\'\\n\', \'\\n  \')\n    name_str = self._name\n    n_in, n_out = self.n_in, self.n_out\n    if n_in != 1: name_str += f\'_in{n_in}\'\n    if n_out != 1: name_str += f\'_out{n_out}\'\n    objs = self.sublayers\n    if objs:\n      objs_str = \'\\n\'.join(indent_string(str(x)) for x in objs)\n      return f\'{name_str}[\\n{objs_str}\\n]\'\n    else:\n      return name_str\n\n  def __call__(self, x, weights=None, state=None, rng=None, n_accelerators=0):\n    """"""Makes layers callable; for use in tests or interactive settings.\n\n    This convenience method helps library users play with, test, or otherwise\n    probe the behavior of layers outside of a full training environment. It\n    presents the layer as callable function from inputs to outputs, with the\n    option of manually specifying weights and non-parameter state per individual\n    call. For convenience, weights and non-parameter state are cached per layer\n    instance, starting from default values of `EMPTY_WEIGHTS` and `EMPTY_STATE`,\n    and acquiring non-empty values either by initialization or from values\n    explicitly provided via the weights and state keyword arguments.\n\n    Args:\n      x: Zero or more input tensors, packaged as described in the `Layer` class\n          docstring.\n      weights: Weights or `None`; if `None`, use self\'s cached weights value.\n      state: State or `None`; if `None`, use self\'s cached state value.\n      rng: Single-use random number generator (JAX PRNG key), or `None`;\n          if `None`, use a default computed from an integer 0 seed.\n      n_accelerators: Number of accelerators to target.\n\n    Returns:\n      Zero or more output tensors, packaged as described in the `Layer` class\n      docstring.\n    """"""\n    weights = self.weights if weights is None else weights\n    state = self.state if state is None else state\n    rng = self.rng if rng is None else rng\n    rng = math.random.get_prng(0) if rng is None else rng\n\n    forward_w_s_r = self.pure_fn\n    # TODO(lukaszkaiser): n_accelerators is experimental, to decide on API\n    if n_accelerators:\n      if n_accelerators not in self._jit_cache:\n        self._jit_cache[n_accelerators] = (\n            jit_forward(forward_w_s_r, n_accelerators))\n      forward_w_s_r = self._jit_cache[n_accelerators]\n    outputs, new_state = forward_w_s_r(x, weights, state, rng)\n    self.state = new_state\n    self.weights = weights\n    return outputs\n\n  def forward(self, inputs, weights):\n    """"""Computes this layer\'s output as part of a forward pass through the model.\n\n    Authors of new layer subclasses should override this method to define the\n    forward computation that their layer performs. If you need to use\n    local non-trainable state or randomness, use `self.rng` for the random seed\n    (no need to set it) and use `self.state` for non-trainable state (and set it\n    to the new value).\n\n    Args:\n      inputs: Zero or more input tensors, packaged as described in the `Layer`\n          class docstring.\n      weights: A tuple or list of trainable weights, with one element for this\n          layer if this layer has no sublayers, or one for each sublayer if\n          this layer has sublayers. If a layer (or sublayer) has no trainable\n          weights, the corresponding weights element is an empty tuple.\n\n    Returns:\n      Zero or more output tensors, packaged as described in the `Layer` class\n      docstring.\n    """"""\n    raise NotImplementedError\n\n  def new_weights(self, input_signature):\n    """"""Returns new weights suitable for inputs with the given signature.\n\n    Authors of new layer subclasses should override this method if their layer\n    uses trainable weights or non-trainable state. To initialize non-trainable\n    state, set `self.state` to the intended value.\n\n    Args:\n      input_signature: A `ShapeDtype` instance (if this layer takes one input)\n          or a list/tuple of `ShapeDtype` instances; signatures of inputs.\n    """"""\n    del input_signature\n    return EMPTY_WEIGHTS\n\n  @property\n  def has_backward(self):\n    """"""Returns `True` if this layer provides its own custom backward pass code.\n\n    A layer subclass that provides custom backward pass code (for custom\n    gradients) must override this method to return `True`.\n    """"""\n    return False\n\n  def backward(self, inputs, output, grad, weights, state, new_state, rng):\n    """"""Custom backward pass to propagate gradients in a custom way.\n\n    Args:\n      inputs: Input tensors; can be a (possibly nested) tuple.\n      output: The result of running this layer on inputs.\n      grad: Gradient signal computed based on subsequent layers; its structure\n          and shape must match output.\n      weights: This layer\'s weights.\n      state: This layer\'s state prior to the current forward pass.\n      new_state: This layer\'s state after the current forward pass.\n      rng: Single-use random number generator (JAX PRNG key).\n\n    Returns:\n      The custom gradient signal for the input. Note that we need to return\n      a gradient for each argument of forward, so it will usually be a tuple\n      of signals: the gradient for inputs and weights.\n    """"""\n    raise NotImplementedError\n\n  # End of public subclassing interface.\n  # Begin public callable interface.\n\n  def init(self, input_signature, rng=None, use_cache=False):\n    """"""Initializes this layer and its sublayers recursively.\n\n    This method is designed to initialize each layer instance once, even if the\n    same layer instance occurs in multiple places in the network. This enables\n    weight sharing to be implemented as layer sharing.\n\n    Args:\n      input_signature: `ShapeDtype` instance (if this layer takes one input)\n          or list/tuple of `ShapeDtype` instances.\n      rng: Single-use random number generator (JAX PRNG key), or `None`;\n          if `None`, use a default computed from an integer 0 seed.\n      use_cache: If `True`, and if this layer instance has already been\n          initialized elsewhere in the network, then return special marker\n          values -- tuple `(GET_WEIGHTS_FROM_CACHE, GET_STATE_FROM_CACHE)`.\n          Else return this layer\'s newly initialized weights and state.\n\n    Returns:\n      A `(weights, state)` tuple.\n    """"""\n    try:\n      if self._init_cached and use_cache:\n        return (GET_WEIGHTS_FROM_CACHE, GET_STATE_FROM_CACHE)\n\n      if rng is not None:\n        self.rng = rng\n      weights = self.new_weights(input_signature)\n      self._weights = weights\n\n      if use_cache:\n        self._init_cached = True\n      else:\n        self._clear_init_cache()\n\n      return (weights, self.state)\n\n    except Exception as e:\n      name, trace = self._name, _short_traceback(skip=3)\n      raise LayerError(name, \'init\', self._caller,\n                       input_signature, trace) from e\n\n  def init_from_file(self, file_name, weights_only=False):\n    """"""Initializes this layer and its sublayers from a pickled checkpoint.\n\n    In the common case (`weights_only=False`), the file must be a pickled\n    dictionary containing items with keys `\'weights\' and `\'state\'`, whose\n    values have the correct structure for this layer\'s weights and state.\n    If `weights_only` is `True`, the dictionary only needs to have a\n    `\'weights\'` item.\n\n    Args:\n      file_name: Name/path of the pickeled weights/state file.\n      weights_only: If `True`, initialize only the layer\'s weights. Else\n          initialize both weights and state.\n    """"""\n    with tf.io.gfile.GFile(file_name, \'rb\') as f:\n      dictionary = pickle.load(f)\n    self.weights = dictionary[\'weights\']\n    if not weights_only:\n      self.state = dictionary[\'state\']\n\n  # End of public callable methods.\n  # Methods and properties below are reserved for internal use.\n\n  @property\n  def n_in(self):\n    """"""Returns how many tensors this layer expects as input.""""""\n    return self._n_in\n\n  @property\n  def n_out(self):\n    """"""Returns how many tensors this layer promises as output.""""""\n    return self._n_out\n\n  @property\n  def sublayers(self):\n    """"""Returns a tuple containing this layer\'s sublayers; may be empty.""""""\n    return self._sublayers\n\n  @property\n  def weights(self):\n    """"""Returns this layer\'s weights.\n\n    Depending on the layer, the weights can be in the form of:\n\n      - an empty tuple\n      - a tensor (ndarray)\n      - a nested structure of tuples and tensors\n\n    TODO(jonni): Simplify this picture (and underlying implementation).\n    """"""\n    return self._weights\n\n  @weights.setter\n  def weights(self, weights):\n    self._weights = weights\n\n  @property\n  def state(self):\n    """"""Returns a tuple containing this layer\'s state; may be empty.""""""\n    return self._state\n\n  @state.setter\n  def state(self, state):\n    self._state = state\n\n  @property\n  def rng(self):\n    """"""Returns a single-use random number generator without advancing it.""""""\n    # TODO(lukaszkaiser, jonni): be even more explicit that we\'re not advancing.\n    if isinstance(self._rng, int):\n      self._rng = math.random.get_prng(self._rng)\n    return self._rng\n\n  @rng.setter\n  def rng(self, rng):\n    """"""Sets the rng (JAX PRNG key) for this layer and sublayers, recursively.""""""\n    self._rng = rng\n    sublayers = self.sublayers\n    if sublayers:\n      rngs = math.random.split(rng, len(sublayers))\n      for sublayer, rng in zip(sublayers, rngs):\n        sublayer.rng = rng\n\n  def _clear_init_cache(self):\n    self._init_cached = False\n    for sublayer in self.sublayers:\n      sublayer._clear_init_cache()  # pylint: disable=protected-access\n\n  def pure_fn(self, x, weights, state, rng, use_cache=False):\n    """"""Applies this layer as a pure function with no optional args.\n\n    This method exposes the layer\'s computation as a pure function. This is\n    especially useful for JIT compilation. Do not override, use `forward`\n    instead.\n\n    Args:\n      x: Zero or more input tensors, packaged as described in the `Layer` class\n          docstring.\n      weights: A tuple or list of trainable weights, with one element for this\n          layer if this layer has no sublayers, or one for each sublayer if\n          this layer has sublayers. If a layer (or sublayer) has no trainable\n          weights, the corresponding weights element is an empty tuple.\n      state: Layer-specific non-parameter state that can update between batches.\n      rng: Single-use random number generator (JAX PRNG key).\n      use_cache: if `True`, cache weights and state in the layer object; used\n        to implement layer sharing in combinators.\n\n    Returns:\n      A tuple of `(tensors, state)`. The tensors match the number (`n_out`)\n      promised by this layer, and are packaged as described in the `Layer`\n      class docstring.\n    """"""\n    try:\n      old_weights, old_state, old_rng = self.weights, self.state, self.rng\n      self._rng = rng\n      if weights is GET_WEIGHTS_FROM_CACHE and state is GET_STATE_FROM_CACHE:  # pylint: disable=literal-comparison\n        weights = self._weights\n        state = self._state\n      else:\n        # In this case, we\'re called for the first time: cache weights.\n        self._weights, self._state = weights, state\n\n      if not self.has_backward:\n        outputs = self.forward(x, weights)\n        s = self.state\n      else:\n        outputs, s = self._do_custom_gradients(x, weights, state, rng=rng)\n        self._state = s\n      self._rng = old_rng\n      if not use_cache:\n        self.weights, self.state = old_weights, old_state\n      return outputs, s\n\n    except Exception as e:\n      name, trace = self._name, _short_traceback()\n      raise LayerError(name, \'pure_fn\',\n                       self._caller, signature(x), trace) from e\n\n  def output_signature(self, input_signature):\n    """"""Returns output signature this layer would give for `input_signature`.""""""\n    return self._forward_abstract(input_signature)[0]  # output only, not state\n\n  def _forward_abstract(self, input_signature):\n    """"""Computes shapes and dtypes this layer would produce in a forward pass.\n\n    Args:\n      input_signature: `ShapeDtype` instance (if this layer takes one input)\n          or list/tuple of `ShapeDtype` instances.\n\n    Returns:\n      Tuple of (output, state).\n\n      The output part of the tuple is a `ShapeDtype` instance representing the\n      shape and type of the output (if this layer has one output) or a tuple\n      of `ShapeDtype` instances (if this layer has more than one output).\n    """"""\n    try:\n      # Note: By using rng_signature in place of an rng, we avoid computing and\n      # permanently storing in global memory a large number of dropout masks.\n      # TODO(jonni): Check if using an rng still carries this cost.\n      dummy_rng = math.random.get_prng(0)\n      rng_signature = ShapeDtype(dummy_rng.shape, dummy_rng.dtype)\n      weight_signature = nested_map(signature, self.weights)\n      forward_infer_shapes = math.abstract_eval(self.pure_fn)\n      return forward_infer_shapes(\n          input_signature, weight_signature, self.state, rng_signature)\n    except Exception as e:\n      name, trace = self._name, _short_traceback(skip=3)\n      raise LayerError(name, \'_forward_abstract\', self._caller, input_signature,\n                       trace) from e\n\n  # pylint: disable=protected-access\n  def _do_custom_gradients(self, x, weights, state, rng):\n    """"""Calls this layer for a forward pass, but with custom gradients.""""""\n\n    def _do_forward(y, weights):\n      old_weights, old_state, old_rng = self._weights, self._state, self._rng\n      res = self.forward(y, weights)\n      s = self._state\n      self._weights, self._state, self._rng = old_weights, old_state, old_rng\n      return res, s\n\n    def do_forward_vjp(y, weights):\n      """"""Custom gradient (vjp) function.""""""\n      old_weights, old_state, old_rng = self._weights, self._state, self._rng\n      output = self.forward(y, weights)\n      new_state = self._state\n      self._weights, self._state, self._rng = old_weights, old_state, old_rng\n      def vjpfun(grad):\n        grad = grad[0]  # Ignore dummy gradient wrt state.\n        res = self.backward(y, output, grad, weights, state, new_state, rng)\n        return res\n      return (output, new_state), vjpfun\n\n    do_forward = math.custom_grad(do_forward_vjp, _do_forward)\n\n    output, state = do_forward(x, weights)\n    # TODO(lukaszkaiser): Investigate why we need this stop_gradient\n    state = math.stop_gradient(state)\n    return output, state\n\n\ndef layer(n_in=1, n_out=1, name=None):\n  """"""Decorator for creating simple layers.  DEPRECATED; use base.Fn instead.""""""\n\n  def _build_layer_class(raw_fn):\n    """"""Returns a layer class whose callable instances execute the function.""""""\n\n    def _init(self, **kwargs):\n      self._kwargs = kwargs  # pylint: disable=protected-access\n      Layer.__init__(self, n_in=n_in, n_out=n_out, name=name)\n\n    def _forward(self, inputs, weights):\n      """"""Uses this layer as part of a forward pass through the model.""""""\n      del weights\n      _validate_forward_input(inputs, n_in)\n      raw_output = raw_fn(inputs, **self._kwargs)  # pylint: disable=protected-access\n      output = () if _is_empty(raw_output) else raw_output\n      return output\n\n    # Set docstrings and create the class.\n    _forward.__doc__ = raw_fn.__doc__\n    # Note: None.__doc__ is None\n    cls = type(raw_fn.__name__, (Layer,),\n               {\'__init__\': _init,\n                \'forward\': _forward})\n    return cls\n\n  return _build_layer_class\n\n\nclass PureLayer(Layer):\n  """"""Pure function from inputs to outputs, packaged as neural network layer.\n\n  The `PureLayer` class represents the simplest kinds of layers: layers with\n  no trainable weights and no randomness, hence pure functions from inputs to\n  outputs.\n  """"""\n\n  def __init__(self, forward_fn, n_in=1, n_out=1, name=\'PureLayer\'):\n    """"""Creates an unconnected `PureLayer` instance.\n\n    Args:\n      forward_fn: Pure function from input tensors to output tensors, where\n          inputs and outputs are packaged as specified for `forward`.\n      n_in: Number of inputs expected by this layer.\n      n_out: Number of outputs promised by this layer.\n      name: Class-like name for this layer; for use only in debugging.\n    """"""\n    super().__init__(n_in, n_out, name)\n    self._forward_fn = forward_fn\n\n  def forward(self, inputs, weights):\n    """"""Overrides `Layer.forward`.\n\n    Args:\n      inputs: Zero or more input tensors, packaged as described in the `Layer`\n          class docstring.\n      weights: Trainable weights in general, but this subclass doesn\'t use\n          weights, so the only acceptable value is an empty tuple/list.\n\n    Returns:\n      Zero or more output tensors, packaged as described in the `Layer` class\n      docstring.\n\n    Raises:\n      ValueError: If weights is other than an empty tuple/list.\n    """"""\n    _validate_forward_input(inputs, self.n_in)\n    raw_output = self._forward_fn(inputs)\n    output = () if _is_empty(raw_output) else raw_output\n    return output\n\n\ndef Fn(name, f, n_out=1):  # pylint: disable=invalid-name\n  """"""Returns a layer with no weights that applies the function `f`.\n\n  `f` can take and return any number of arguments, and takes only positional\n  arguments -- no default or keyword arguments. It often uses JAX-numpy (`jnp`).\n  The following, for example, would create a layer that takes two inputs and\n  returns two outputs -- element-wise sums and maxima:\n\n      `Fn(\'SumAndMax\', lambda x0, x1: (x0 + x1, jnp.maximum(x0, x1)), n_out=2)`\n\n  The layer\'s number of inputs (`n_in`) is automatically set to number of\n  positional arguments in `f`, but you must explicitly set the number of\n  outputs (`n_out`) whenever it\'s not the default value 1.\n\n  Args:\n    name: Class-like name for the resulting layer; for use in debugging.\n    f: Pure function from input tensors to output tensors, where each input\n        tensor is a separate positional arg, e.g., `f(x0, x1) --> x0 + x1`.\n        Output tensors must be packaged as specified in the `Layer` class\n        docstring.\n    n_out: Number of outputs promised by the layer; default value 1.\n\n  Returns:\n    Layer executing the function `f`.\n  """"""\n  # Inspect the function f to restrict to no-defaults and no-kwargs functions.\n  argspec = inspect.getfullargspec(f)\n  if argspec.defaults is not None:\n    raise ValueError(\'Function has default arguments (not allowed).\')\n  if argspec.varkw is not None:\n    raise ValueError(\'Function has keyword arguments (not allowed).\')\n  if argspec.varargs is not None:\n    raise ValueError(\'Function has variable args (not allowed).\')\n\n  def _forward(xs):  # pylint: disable=invalid-name\n    if not isinstance(xs, (tuple, list)):\n      xs = (xs,)\n    return f(*xs)\n\n  n_in = len(argspec.args)\n  name = name or \'Fn\'\n  return PureLayer(_forward, n_in=n_in, n_out=n_out, name=name)\n\n\nclass LayerError(Exception):\n  """"""Exception raised in the layer stack.""""""\n\n  def __init__(self, layer_name, function_name, caller,\n               input_signature, traceback_string):\n    self._layer_name = layer_name\n    self._function_name = function_name\n    self._caller = caller  # Python inspect object with init caller info.\n    self._traceback = traceback_string\n    self._input_signature = input_signature\n    super(LayerError, self).__init__(self.message)\n\n  @property\n  def message(self):\n    """"""Assembles current layer context into an error message.""""""\n    prefix = \'Exception passing through layer \'\n    prefix += \'%s (in %s):\\n\' % (self._layer_name, self._function_name)\n    short_path = \'[...]/\' + \'/\'.join(\n        self._caller[\'filename\'].split(\'/\')[-3:])\n    caller = \'  layer created in file %s, line %d\\n\' % (short_path,\n                                                        self._caller[\'lineno\'])\n    shapes_str = \'  layer input shapes: %s\\n\\n\' % str(self._input_signature)\n    return prefix + caller + shapes_str + self._traceback\n\n\ndef to_list(outputs):\n  """"""Converts layer outputs to a nested list, for easier equality testing.\n\n  Args:\n    outputs: A tensor or tuple/list of tensors coming from the forward\n        application of a layer. Each tensor is NumPy ndarray-like, which\n        complicates simple equality testing (e.g., via `assertEquals`):\n        such tensors require equality testing to use either `all` (all\n        elements match) or `any` (at least one element matches), which is not\n        directly supported in `absltest`.\n\n  Returns:\n    A nested list structure containing all the output values, but now directly\n    testable using `assertEquals`.\n  """"""\n  if isinstance(outputs, (list, tuple)):\n    return [y.tolist() for y in outputs]\n  else:\n    return outputs.tolist()\n\n\ndef _validate_forward_input(x, n_in):\n  if n_in != 1:\n    if not isinstance(x, (tuple, list)):\n      raise TypeError(\n          f\'Expected input to be a tuple or list; instead got {type(x)}.\')\n    if len(x) != n_in:\n      raise ValueError(f\'Input tuple length ({len(x)}) does not equal required \'\n                       f\'number of inputs ({n_in}).\')\n\n\ndef _is_empty(container):\n  if container is None:\n    raise ValueError(\'Argument ""container"" is None.\')\n  return isinstance(container, (list, tuple)) and len(container) == 0  # pylint: disable=g-explicit-length-test\n\n\ndef _find_frame(frame):\n  """"""Find the frame with the caller on the stack.""""""\n  # TODO(lukaszkaiser): rewrite this function in a systematic way.\n  # We want to find the first place where the layer was called\n  # that is *not* an __init__ function of an inheriting layer.\n  # We also need to exclude a few decorator functions.\n  while frame.f_code.co_name in [\'__init__\', \'gin_wrapper\', \'_validate\',\n                                 \'_validate_forward_inputs\', \'_init\']:\n    # We only skip __init__ in internal layers, return otherwise.\n    try:\n      dirname = frame.f_code.co_filename.split(\'/\')[-2]\n    except IndexError:\n      # Notebook cells have dummy filenames that do not contain any slashes\n      dirname = frame.f_code.co_filename\n    if dirname != \'layers\' and frame.f_code.co_name == \'__init__\':\n      return frame\n    # If we are in an init, move up.\n    frame = frame.f_back\n  return frame\n\n\ndef _shorten_file_path(line):\n  """"""Shorten file path in error lines for more readable tracebacks.""""""\n  start = line.lower().find(\'file\')\n  if start < 0:\n    return line\n  first_quote = line.find(\'""\', start)\n  if first_quote < 0:\n    return line\n  second_quote = line.find(\'""\', first_quote + 1)\n  if second_quote < 0:\n    return line\n  path = line[first_quote + 1:second_quote]\n  new_path = \'/\'.join(path.split(\'/\')[-3:])\n  return line[:first_quote] + \'[...]/\' + new_path + line[second_quote + 1:]\n\n\ndef _short_traceback(skip=3):\n  """"""Cleaned-up form of traceback.""""""\n  counter, res = 0, []\n  # Skipping 3 lines by default: the top (useless) and self-call.\n  # In python 3, we need to set chain to False (it doesn\'t exist in python 2).\n  lines = traceback.format_exc(chain=False).splitlines()[skip:]  # pylint: disable=unexpected-keyword-arg\n  for l in lines:\n    if l.startswith(\'trax.layers.base.LayerError\'):\n      l = l[len(\'trax.layers.base.\'):]  # Remove the trax.layers.base prefix.\n    res.append(_shorten_file_path(l))\n    if counter % 2 == 1:\n      res.append(\'\')\n    counter += 1\n    # If we see a LayerError, the traceback has already been processed.\n    if l.startswith(\'LayerError\'):\n      # Skip 4 back except last as these are internal base-layer calls.\n      res = res[:-4] + [res[-1]]\n      res += lines[counter:]\n      break\n  return \'\\n\'.join(res)\n\n\ndef _random_values(input_signature, rng):\n  """"""Creates random floats or ints of the given shape.\n\n  Args:\n    input_signature: A `ShapeDtype` instance (if `layer_obj` takes one input)\n        or a list/tuple of ShapeDtype instances.\n    rng: Single-use random number generator (JAX PRNG key).\n\n  Returns:\n    Random values with the shape and type specified.\n  """"""\n  if isinstance(input_signature, ShapeDtype):\n    shape, dtype = input_signature.shape, input_signature.dtype\n    if np.issubdtype(dtype, np.integer):\n      return math.random.bernoulli(rng, 0.5, shape).astype(np.int32)\n    else:\n      return math.random.uniform(rng, shape, minval=-1.0, maxval=1.0)\n  elif isinstance(input_signature, (list, tuple)):\n    return tuple(_random_values(x, rng) for x in input_signature)\n  else:\n    raise TypeError(type(input_signature))\n\n\ndef _shapes(x):\n  """"""Gets a structure of shapes for a structure of nested arrays.""""""\n  def shape(x):\n    try:\n      return tuple([int(i) for i in x.shape])\n    except Exception:  # pylint: disable=broad-except\n      return ()\n  return tuple(nested_map(shape, x))\n\n\ndef jit_forward(forward, n_devices, do_mean=True):\n  """"""Returns a JIT-compiled forward function running on `n_devices`.""""""\n  model_predict = _accelerate(forward, n_devices)\n  if n_devices == 1:\n    return model_predict\n\n  def predict(x, weights, state, rng):\n    """"""Predict function JIT-compileds and parallelized as requested.""""""\n    res, state = _combine_devices(model_predict(\n        reshape_by_device(x, n_devices),\n        weights,\n        state,\n        jnp.stack(math.random.split(rng, n_devices))))\n    if do_mean:\n      return math.nested_map(lambda y: jnp.mean(y, axis=0), res), state\n    else:\n      return res, state\n\n  return predict\n\n\ndef _combine_devices(x_tuple):\n  """"""Combines multi-device tensors into a single batch.""""""\n  def f(x):\n    if len(x.shape) < 2:\n      return x  # No extra batch dimension: use devices as batch, so return.\n    batch_size = x.shape[0] * x.shape[1]\n    return math.numpy.reshape(x, [batch_size] + list(x.shape[2:]))\n  return math.nested_map(f, x_tuple)\n\n\ndef _accelerate(f, n_devices):\n  """"""JIT-compiled version of `f` running on `n_devices`.""""""\n  if n_devices == 1:\n    return math.jit(f)\n\n  return math.pmap(f, axis_name=\'batch\')\n\n\ndef reshape_by_device(x, n_devices):\n  """"""Reshapes possibly nested `x` into a shape `(n_devices, ...)`.""""""\n  def f(x):\n    x_shape = list(x.shape)\n    batch_size = x_shape[0]\n    batch_size_per_device = batch_size // n_devices\n    if batch_size_per_device * n_devices != batch_size:\n      raise ValueError(f\'Number of devices ({n_devices}) does not evenly \'\n                       f\'divide batch size ({batch_size}).\')\n    new_shape_prefix = [n_devices, batch_size_per_device]\n    return math.numpy.reshape(x, new_shape_prefix + x_shape[1:])\n  return math.nested_map(f, x)\n\n\ndef for_n_devices(x, n_devices):\n  """"""Replicates/broadcasts `x` for `n_devices`.""""""\n  def f(x):\n    if n_devices > 1 and math.backend_name() == \'jax\':\n      return _multi_device_put(x)\n    elif n_devices > 1:\n      return jnp.broadcast_to(x, (n_devices,) + x.shape)\n    else:\n      return x\n  return math.nested_map(f, x)\n\n\ndef _multi_device_put(x, devices=None):\n  """"""Memory efficient multi-device replication / broadcast in JAX.\n\n  JAX uses a ShardedDeviceArray class that holds a list of device buffers\n  on separate devices for use with pmap\'d computations.  Sharded arrays\n  are explicitly used to eliminate unnecessary inter-device transfer of\n  memory buffers between use in pmap\'d computations.  The JAX API currently\n  does not have a multi-device \'put\' function that copies a buffer onto\n  N devices in a memory-efficient fashion, so we implement our own here.\n\n  Args:\n    x: jax DeviceArray or numpy ndarray to be replicated.\n    devices: a jax.devices() list or subset thereof of devices to\n      replicate onto.  Should match the list passed to any pmaps\n      ingesting the replicated array.\n\n  Returns:\n    A ShardedDeviceArray with\n    dtype = x.dtype and shape = (n_devices,) + x.shape\n    that\'s backed by replicated device_buffers on each local device.\n  """"""\n  # Convert _FilledConstants that don\'t have device_buffer, etc.\n  if type(x) != jax.xla.DeviceArray:  # pylint: disable=unidiomatic-typecheck\n    x = jnp.array(x)\n  # Calculate the abstract shape of the replicated array.\n  if not devices:\n    devices = jax.local_devices()\n  n_devices = len(devices)\n  x_aval = jax.xla.abstractify(x)\n  broadcast_x_aval = jax.abstract_arrays.ShapedArray(\n      (n_devices,) + x_aval.shape,\n      x_aval.dtype)\n  # Create copies of the underlying device buffer for each local device.\n  broadcast_buffers = [\n      jax.interpreters.xla.device_put(x, dv)\n      for dv in devices\n  ]\n  return jax.pxla.ShardedDeviceArray(broadcast_x_aval, broadcast_buffers)\n'"
trax/layers/base_test.py,12,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Trax base layer classes and generic layer-creating functions.""""""\n\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\n\nimport numpy as np\n\nfrom trax import math\nfrom trax import shapes\nfrom trax.layers import base\nfrom trax.math import numpy as jnp\n\n\nBACKENDS = [\'jax\', \'tf\']\n\n\nclass BaseLayerTest(parameterized.TestCase):\n\n  def test_call_raises_error(self):\n    layer = base.Layer()\n    x = np.array([[1, 2, 3, 4, 5],\n                  [10, 20, 30, 40, 50]])\n    with self.assertRaisesRegex(base.LayerError, \'NotImplementedError\'):\n      _ = layer(x)\n\n  def test_forward_raises_error(self):\n    layer = base.Layer()\n    x = np.array([[1, 2, 3, 4, 5],\n                  [10, 20, 30, 40, 50]])\n    with self.assertRaises(NotImplementedError):\n      _ = layer.forward(x, base.EMPTY_WEIGHTS)\n\n  def test_new_weights_returns_empty(self):\n    layer = base.Layer()\n    input_signature = shapes.ShapeDtype((2, 5))\n    weights = layer.new_weights(input_signature)\n    self.assertEmpty(weights)\n\n  def test_init_returns_empty_weights_and_state(self):\n    layer = base.Layer()\n    input_signature = shapes.ShapeDtype((2, 5))\n    weights, state = layer.init(input_signature)\n    self.assertEmpty(weights)\n    self.assertEmpty(state)\n\n  def test_output_signature(self):\n    input_signature = (shapes.ShapeDtype((2, 3, 5)),\n                       shapes.ShapeDtype((2, 3, 5)))\n    layer = base.Fn(\'2in1out\', lambda x, y: x + y)\n    output_signature = layer.output_signature(input_signature)\n    self.assertEqual(output_signature, shapes.ShapeDtype((2, 3, 5)))\n\n    input_signature = shapes.ShapeDtype((5, 7))\n    layer = base.Fn(\'1in3out\', lambda x: (x, 2 * x, 3 * x), n_out=3)\n    output_signature = layer.output_signature(input_signature)\n    self.assertEqual(output_signature, (shapes.ShapeDtype((5, 7)),) * 3)\n    self.assertNotEqual(output_signature, (shapes.ShapeDtype((4, 7)),) * 3)\n    self.assertNotEqual(output_signature, (shapes.ShapeDtype((5, 7)),) * 2)\n\n  @parameterized.named_parameters([(\'_\' + b, b) for b in BACKENDS])\n  def test_custom_zero_grad(self, backend_name):\n\n    class IdWithZeroGrad(base.Layer):\n\n      def forward(self, x, weights):\n        return x\n\n      @property\n      def has_backward(self):\n        return True\n\n      def backward(self, inputs, output, grad, weights, state, new_state, rng):\n        return (jnp.zeros_like(grad), ())\n\n    with math.use_backend(backend_name):\n      layer = IdWithZeroGrad()\n      rng = math.random.get_prng(0)\n      input_signature = shapes.ShapeDtype((9, 17))\n      random_input = math.random.uniform(rng, input_signature.shape,\n                                         minval=-1.0, maxval=1.0)\n      layer.init(input_signature)\n      f = lambda x: jnp.mean(layer(x))\n      grad = math.grad(f)(random_input)\n      self.assertEqual(grad.shape, (9, 17))  # Gradient for each input.\n      self.assertEqual(sum(sum(grad * grad)), 0.0)  # Each one is 0.\n\n  @parameterized.named_parameters([(\'_\' + b, b) for b in BACKENDS])\n  def test_custom_id_grad(self, backend_name):\n\n    class IdWithIdGrad(base.Layer):\n\n      def forward(self, x, weights):\n        return x\n\n      @property\n      def has_backward(self):\n        return True\n\n      def backward(self, inputs, output, grad, weights, state, new_state, rng):\n        return (inputs, ())\n\n    with math.use_backend(backend_name):\n      layer = IdWithIdGrad()\n      rng = math.random.get_prng(0)\n      input_signature = shapes.ShapeDtype((9, 17))\n      random_input = math.random.uniform(rng, input_signature.shape,\n                                         minval=-1.0, maxval=1.0)\n      layer.init(input_signature)\n      f = lambda x: jnp.mean(layer(x))\n      grad = math.grad(f)(random_input)\n      self.assertEqual(grad.shape, (9, 17))  # Gradient for each input.\n      self.assertEqual(sum(sum(grad)), sum(sum(random_input)))  # Same as input.\n\n  def test_accelerated_forward_called_twice(self):\n\n    class Constant(base.Layer):\n\n      def new_weights(self, input_signature):\n        return 123\n\n      def forward(self, inputs, weights):\n        return weights\n\n    layer = Constant()\n    layer.init(input_signature=shapes.ShapeDtype(()))\n    layer(0, n_accelerators=1)\n    layer(0, n_accelerators=1)\n\n  def test_custom_name(self):\n    layer = base.Layer()\n    self.assertIn(\'Layer\', str(layer))\n    self.assertNotIn(\'CustomLayer\', str(layer))\n\n    layer = base.Layer(name=\'CustomLayer\')\n    self.assertIn(\'CustomLayer\', str(layer))\n\n\nclass PureLayerTest(absltest.TestCase):\n\n  def test_forward(self):\n    layer = base.PureLayer(lambda x: 2 * x)\n\n    # Use Layer.__call__.\n    in_0 = np.array([1, 2])\n    out_0 = layer(in_0)\n    self.assertEqual(out_0.tolist(), [2, 4])\n\n    # Use PureLayer.forward.\n    in_1 = np.array([3, 4])\n    out_1 = layer.forward(in_1, base.EMPTY_WEIGHTS)\n    self.assertEqual(out_1.tolist(), [6, 8])\n\n    # Use Layer.pure_fn\n    in_2 = np.array([5, 6])\n    out_2, _ = layer.pure_fn(\n        in_2, base.EMPTY_WEIGHTS, base.EMPTY_WEIGHTS, None)\n    self.assertEqual(out_2.tolist(), [10, 12])\n\n\nclass FnTest(absltest.TestCase):\n\n  def test_bad_f_has_default_arg(self):\n    with self.assertRaisesRegex(ValueError, \'default arg\'):\n      _ = base.Fn(\'\', lambda x, sth=None: x)\n\n  def test_bad_f_has_keyword_arg(self):\n    with self.assertRaisesRegex(ValueError, \'keyword arg\'):\n      _ = base.Fn(\'\', lambda x, **kwargs: x)\n\n  def test_bad_f_has_variable_arg(self):\n    with self.assertRaisesRegex(ValueError, \'variable arg\'):\n      _ = base.Fn(\'\', lambda *args: args[0])\n\n  def test_forward(self):\n    layer = base.Fn(\'SumAndMax\',\n                    lambda x0, x1: (x0 + x1, jnp.maximum(x0, x1)),\n                    n_out=2)\n\n    x0 = np.array([1, 2, 3, 4, 5])\n    x1 = np.array([10, 20, 30, 40, 50])\n\n    y0, y1 = layer((x0, x1))\n    self.assertEqual(y0.tolist(), [11, 22, 33, 44, 55])\n    self.assertEqual(y1.tolist(), [10, 20, 30, 40, 50])\n\n    y2, y3 = layer.forward((x0, x1), base.EMPTY_WEIGHTS)\n    self.assertEqual(y2.tolist(), [11, 22, 33, 44, 55])\n    self.assertEqual(y3.tolist(), [10, 20, 30, 40, 50])\n\n    (y4, y5), state = layer.pure_fn(\n        (x0, x1), base.EMPTY_WEIGHTS, base.EMPTY_STATE, None)\n    self.assertEqual(y4.tolist(), [11, 22, 33, 44, 55])\n    self.assertEqual(y5.tolist(), [10, 20, 30, 40, 50])\n    self.assertEqual(state, base.EMPTY_STATE)\n\n  def test_weights_state(self):\n    layer = base.Fn(\n        \'2in2out\',\n        lambda x, y: (x + y, jnp.concatenate([x, y], axis=0)), n_out=2)\n    weights = layer.new_weights(None)\n    self.assertEmpty(weights)\n    self.assertEmpty(layer.state)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/layers/combinators.py,5,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Combinators for composing layers.""""""\n\nfrom trax import math\nfrom trax.layers import base\nfrom trax.layers.base import Fn\nfrom trax.math import numpy as jnp\nfrom trax.shapes import ShapeDtype\n\n\nclass Serial(base.Layer):\n  """"""Combinator that applies layers serially (by function composition).\n\n  A Serial combinator uses stack semantics to manage data for its sublayers.\n  Each sublayer sees only the inputs it needs and returns only the outputs it\n  has generated. The sublayers interact via the data stack. For instance, a\n  sublayer k, following sublayer j, gets called with the data stack in the\n  state left after layer j has applied. The Serial combinator then:\n\n    - takes n_in items off the top of the stack (n_in = k.n_in) and calls\n      layer k, passing those items as arguments; and\n\n    - takes layer k\'s n_out return values (n_out = k.n_out) and pushes\n      them onto the data stack.\n\n  A Serial instance with no sublayers acts as a special-case (but useful)\n  1-input 1-output no-op.\n  """"""\n\n  def __init__(self, *sublayers, name=None):\n    super(Serial, self).__init__(name=name)\n\n    sublayers = _ensure_flat(sublayers)\n    self._sublayers = sublayers\n    self._n_layers = len(sublayers)\n\n    if sublayers:\n      self._n_in, self._n_out = self._n_inputs_n_outputs(sublayers)\n      self._weights = tuple(l.weights for l in sublayers)\n      self._state = tuple(l.state for l in sublayers)\n\n  def forward(self, xs, weights):\n    self._validate_forward_inputs(xs)\n    state = self.state\n    rngs = _split_rngs(self.rng, self._n_layers)\n    if not self.sublayers:  # No-op: leave args unchanged.\n      return xs\n\n    stack = xs\n    new_state = []\n    n_layers = self._n_layers\n    if len(weights) != n_layers:\n      raise ValueError(\n          f\'Number of weight elements ({len(weights)}) does not equal \'\n          f\'number of sublayers ({n_layers}).\')\n    if len(state) != n_layers:\n      raise ValueError(\n          f\'Number of state elements ({len(state)}) does not equal \'\n          f\'number of sublayers ({n_layers}).\')\n\n    for layer, w, s, rng in zip(self.sublayers, weights, state, rngs):\n      inputs = _inputs_from_stack(layer, stack)\n      outputs, s = layer.pure_fn(inputs, w, s, rng, use_cache=True)\n      stack = _outputs_onto_stack(layer, outputs, stack)\n      new_state.append(s)\n    self._state = new_state\n    return stack\n\n  # pylint: disable=protected-access\n  def new_weights(self, input_signature):\n    weights = []\n    states = []\n    # In the code below, stack, inputs, and outputs are abstract (shapes and\n    # dtypes), but weights and states are non-abstract actual values.\n    stack = input_signature\n    for sublayer in self.sublayers:\n      inputs = _inputs_from_stack(sublayer, stack)\n      weights_or_empty, state = sublayer.init(inputs, use_cache=True)\n      outputs, _ = sublayer._forward_abstract(inputs)\n      stack = _outputs_onto_stack(sublayer, outputs, stack)\n\n      weights.append(weights_or_empty)\n      states.append(state)\n    self._state = states\n    return weights\n  # pylint: enable=protected-access\n\n  @base.Layer.weights.setter\n  def weights(self, weights):\n    """"""Recursively sets weights on this layer and all sublayers.""""""\n    self._weights = weights\n    n_layers = self._n_layers\n    if len(weights) != n_layers:\n      raise ValueError(\n          f\'Number of weight elements ({len(weights)}) does not equal \'\n          f\'number of sublayers ({n_layers}).\')\n    for layer, sublayer_weights in zip(self.sublayers, weights):\n      if sublayer_weights is not base.GET_WEIGHTS_FROM_CACHE:\n        layer.weights = sublayer_weights\n\n  @base.Layer.state.setter\n  def state(self, state):\n    """"""Recursively sets non-param state on this layer and all sublayers.""""""\n    self._state = state\n    n_layers = self._n_layers\n    if n_layers != 1 and len(state) != n_layers:\n      raise ValueError(\n          f\'Number of state elements ({len(state)}) does not equal \'\n          f\'number of sublayers ({n_layers}).\')\n    for layer, sublayer_state in zip(self.sublayers, state):\n      if sublayer_state is not base.GET_STATE_FROM_CACHE:\n        layer.state = sublayer_state\n\n  def _n_inputs_n_outputs(self, layers):\n    del self\n    running_max = 0\n    running_total = 0\n    for layer in layers:\n      running_total += layer.n_in\n      running_max = max(running_max, running_total)\n      running_total -= layer.n_out\n    return running_max, (running_max - running_total)\n\n  def _validate_forward_inputs(self, xs):\n    if not isinstance(xs, (tuple, list)) and self._n_in != 1:\n      raise TypeError(f\'Serial.forward input must be a tuple or list; \'\n                      f\'instead got {type(xs)}.\')\n      # TODO(jonni): Include full xs (or shape) in error message?\n    len_xs = 1 if isinstance(xs, jnp.ndarray) else len(xs)\n    if len_xs < self.n_in:\n      raise ValueError(\n          f\'Number of inputs ({len(xs)}) to Serial.forward less than n_in \'\n          f\'({self.n_in}).\')\n\n\nclass Parallel(base.Layer):\n  """"""Combinator that applies a list of layers in parallel to its inputs.\n\n  Layers in the list apply to successive spans of inputs, where the spans are\n  determined how many inputs each layer takes. The resulting output is the\n  (flattened) concatenation of the respective layer outputs.\n\n  For example, suppose one has three layers:\n\n    - F: 1 input, 1 output\n    - G: 3 inputs, 1 output\n    - H: 2 inputs, 2 outputs (h1, h2)\n\n  Then Parallel(F, G, H) will take 6 inputs and give 4 outputs:\n\n    - inputs: a, b, c, d, e, f\n    - outputs: F(a), G(b, c, d), h1, h2\n\n  As an important special case, a None argument to Parallel acts as if it takes\n  one argument, which it leaves unchanged. (It acts as a one-arg no-op.) For\n  example:\n\n    Parallel(None, F)\n\n  creates a layer that passes its first input unchanged and applies F to the\n  following input(s).\n  """"""\n\n  def __init__(self, *sublayers, name=None):\n    """"""The constructor.\n\n    Args:\n      *sublayers: A list of sublayers.\n      name: Descriptive name for this layer.\n\n    Returns:\n      A new layer in which each of the given sublayers applies to its\n      corresponding span of elements in the dataflow stack.\n    """"""\n    super(Parallel, self).__init__(name=name)\n    sublayers = self._validate(sublayers)\n    self._n_layers = len(sublayers)\n    self._sublayers = sublayers\n    self._n_in = sum(l.n_in for l in sublayers)\n    self._n_out = sum(l.n_out for l in sublayers)\n    self._weights = tuple(l.weights for l in sublayers)\n    self._state = tuple(l.state for l in sublayers)\n\n  def forward(self, inputs, weights):\n    n_layers, layers = self._n_layers, self.sublayers\n    sublayer_inputs = self._allot_to_sublayers(inputs)\n    state = self.state\n    rngs = _split_rngs(self.rng, n_layers)\n    if len(sublayer_inputs) != n_layers:\n      raise ValueError(\n          f\'Number of inputs for sublayers ({len(sublayer_inputs)}) does not equal \'\n          f\'number of sublayers ({n_layers}).\')\n    if len(weights) != n_layers:\n      raise ValueError(\n          f\'Number of weight elements ({len(weights)}) does not equal \'\n          f\'number of sublayers ({n_layers}).\')\n    if len(state) != n_layers:\n      raise ValueError(\n          f\'Number of state elements ({len(state)}) does not equal \'\n          f\'number of sublayers ({n_layers}).\')\n    if len(rngs) != n_layers:\n      raise ValueError(\n          f\'Number of rngs ({len(rngs)}) does not equal \'\n          f\'number of sublayers ({n_layers}).\')\n    outputs = []\n    new_state = []\n    for layer, x, w, s, r in zip(layers, sublayer_inputs, weights, state, rngs):\n      # Note that zip silently truncates its result if lengths don\'t match.\n      sub_outputs, sub_state = layer.pure_fn(x, w, s, r, use_cache=True)\n      if layer.n_out == 1:\n        outputs.append(sub_outputs)\n      else:\n        outputs.extend(sub_outputs)\n      new_state.append(sub_state)\n    output = outputs[0] if self.n_out == 1 else tuple(outputs)\n    self._state = tuple(new_state)\n    return output\n\n  def new_weights(self, input_signature):\n    sublayer_signatures = self._allot_to_sublayers(input_signature)\n    inits = [layer.init(signature, use_cache=True)\n             for layer, signature\n             in zip(self.sublayers, sublayer_signatures)]\n    if inits:\n      weights, state = tuple(zip(*inits))\n      self._state = state\n      return weights\n    else:\n      return base.EMPTY_WEIGHTS\n\n  @base.Layer.weights.setter\n  def weights(self, weights):\n    """"""Recursively sets weights on this layer and all sublayers.""""""\n    if weights == base.EMPTY_WEIGHTS:\n      return\n    self._weights = weights\n    assert len(weights) == self._n_layers\n    for layer, sublayer_weights in zip(self.sublayers, weights):\n      layer.weights = sublayer_weights\n\n  @base.Layer.state.setter\n  def state(self, state):\n    """"""Recursively sets non-param state on this layer and all sublayers.""""""\n    self._state = state\n    assert len(state) == self._n_layers\n    for layer, sublayer_state in zip(self.sublayers, state):\n      layer.state = sublayer_state\n\n  def _validate(self, layers):\n    if not layers or len(layers) < 2:\n      raise ValueError(\n          f\'layers ({layers}) must be a list with at least two elements\')\n    layers = list(layers)  # Ensure we can modify layers.\n    for i, obj in enumerate(layers):\n      if obj is None or obj == []:  # pylint: disable=g-explicit-bool-comparison\n        layers[i] = Serial(None)\n      elif isinstance(obj, (list, tuple)):\n        layers[i] = Serial(obj)\n      else:\n        if not isinstance(obj, base.Layer):\n          raise ValueError(\n              f\'Found nonlayer object ({obj}) in layers list: [{layers}]\')\n      if layers[i].n_in == 0:\n        raise ValueError(\n            f\'Sublayer with n_in = 0 not allowed in Parallel: {layers[i]}\')\n    return layers\n\n  def _allot_to_sublayers(self, inputs):\n    """"""Divides Parallel\'s inputs for use by the sublayers.\n\n    Args:\n      inputs: Tuple of ndarrays or ShapeDtype instances.\n\n    Returns:\n      A tuple that partitions this layer\'s inputs among its sublayers.\n      Sublayers that take one argument get that argument directly. All other\n      sublayers get a tuple of items.\n    """"""\n    start, end = 0, 0\n    sub_inputs = []\n    for layer in self.sublayers:\n      n_in = layer.n_in\n      end = start + n_in\n      if n_in == 1:\n        sub_inputs.append(inputs[start])\n      else:\n        sub_inputs.append(inputs[start:end])\n      start = end\n    return tuple(sub_inputs)\n\n\nclass Concatenate(base.Layer):\n  """"""Concatenates n tensors into a single tensor.""""""\n\n  def __init__(self, n_items=2, axis=-1):\n    name = \'Concatenate\' if axis == -1 else f\'Concatenate_axis{axis}\'\n    super(Concatenate, self).__init__(n_in=n_items, name=name)\n    self._n_items = n_items\n    self._axis = axis\n\n  def forward(self, xs, weights):\n    del weights\n    return jnp.concatenate(xs, self._axis)\n\n\nclass Split(base.Layer):\n  """"""Splits the input into n items along an axis.""""""\n\n  def __init__(self, n_items=2, axis=-1):\n    super(Split, self).__init__(n_out=n_items)\n    self._n_items = n_items\n    self._axis = axis\n\n  def forward(self, inputs, weights):\n    del weights\n    return tuple(jnp.split(inputs, self._n_items, self._axis))\n\n\nclass Scan(base.Layer):\n  """"""Applies a layer progressively/cumulatively to an axis-derived sequence.\n\n  Conceptually, this is a function from a list to a same-length list of partial\n  (cumulative) results. For instance, a list of values (`[1, 2, 3, 4, 5]`) can\n  transform to a list of cumulative sums (`[1, 3, 6, 10, 15]`). Functions for\n  the same concept are called `scan` in Scala, `scanl` in Haskell, and\n  `accumulate*` in Factor.\n\n  In more detail, we assume the layer takes a tuple of inputs of the following\n  form:\n\n    (input1, ..., inputN, carry1, ..., carryM)\n\n  and returns:\n\n    (output1, ..., outputK, new_carry1, ..., new_carryM)\n\n  The scanned version applies the layer iteratively to a tensor treating values\n  at the given axis as if they were a list. For example, to calculate all\n  sums of prefixes of a tensor, we can do this::\n\n    def add(x, carry):\n      def f(input, carry):\n        res = input + carry\n        return res, res  # output and carry are the same\n      return tl.Fn(\'add\', f, n_out=2)\n\n    Scan(add)([1, 2, 3], 0) = [1, 3, 6], 6\n  """"""\n\n  def __init__(self, layer, axis=0, n_carry=1, remat=False):\n    super(Scan, self).__init__(n_in=layer.n_in, n_out=layer.n_out)\n    self._sublayers = [layer]\n    self._n_carry = n_carry\n    self._axis = axis\n    self._remat = remat\n\n  @property\n  def sublayer(self):\n    """"""Returns the unique sublayer managed by this layer.""""""\n    return self._sublayers[0]\n\n  def forward(self, inputs, weights):\n    if isinstance(inputs, list):\n      inputs = tuple(inputs)  # so that inputs structure matches outputs\n    n_carry = self._n_carry\n    def scannable_fn(x, carry_and_state):  # pylint: disable=invalid-name\n      carry, state = carry_and_state\n      x_and_carry = x + carry if n_carry > 0 else x\n      res, new_state = self.sublayer.pure_fn(\n          x_and_carry, weights, state, self.rng, use_cache=True)\n      if n_carry > 0:\n        return (res[:-n_carry], (res[-n_carry:], new_state))\n      else:\n        return (res, ([], new_state))\n\n    if n_carry > 0:\n      xs = inputs[:-n_carry]  # Split input stack into inputs and carry.\n      init = (inputs[-n_carry:], self.state)\n    else:\n      xs, init = inputs, ([], self.state)\n    ys, (carry, new_state) = math.scan(scannable_fn, xs, init,\n                                       axis=self._axis, remat=self._remat)\n    res = ys + carry if n_carry > 0 else ys\n    self.state = new_state\n    return res  # Put outputs and carry back on stack.\n\n  def new_weights(self, input_signature):\n    n_carry = self._n_carry\n    if n_carry == 0:\n      if isinstance(input_signature, (list, tuple)):\n        layer_sig = [ShapeDtype(_shape_without_axis(x, self._axis), x.dtype)\n                     for x in input_signature]\n        layer_sig = tuple(layer_sig)\n      else:\n        layer_sig = ShapeDtype(_shape_without_axis(input_signature, self._axis),\n                               input_signature.dtype)\n      weights, state = self.sublayer.init(layer_sig)\n      self.state = state\n      return weights\n    xs = input_signature[:-n_carry]\n    init = input_signature[-n_carry:]\n    xs_slices = [ShapeDtype(_shape_without_axis(x, self._axis), x.dtype)\n                 for x in xs]\n    layer_signature = tuple(xs_slices + list(init))\n    weights, state = self.sublayer.init(layer_signature, use_cache=True)\n    self.state = state\n    return weights\n\n\ndef Branch(*layers, name=\'Branch\'):\n  """"""Combinator that applies a list of layers in parallel to copies of inputs.\n\n  Each layer in the input list is applied to as many inputs from the stack\n  as it needs, and their outputs are successively combined on stack.\n\n  For example, suppose one has three layers:\n\n    - F: 1 input, 1 output\n    - G: 3 inputs, 1 output\n    - H: 2 inputs, 2 outputs (h1, h2)\n\n  Then Branch(F, G, H) will take 3 inputs and give 4 outputs:\n\n    - inputs: a, b, c\n    - outputs: F(a), G(a, b, c), h1, h2    where h1, h2 = H(a, b)\n\n  As an important special case, a None argument to Branch acts as if it takes\n  one argument, which it leaves unchanged. (It acts as a one-arg no-op.)\n\n  Args:\n    *layers: list of layers\n    name: Descriptive name for this layer.\n\n  Returns:\n    the branch layer\n  """"""\n  if len(layers) == 1:\n    return layers[0]\n  parallel_layer = Parallel(*layers)\n  indices = [list(range(layer.n_in)) for layer in parallel_layer.sublayers]\n  return Serial(Select(_deep_flatten(indices)), parallel_layer, name=name)\n\n\ndef Residual(*layers, shortcut=None):\n  """"""Wraps a series of layers with a residual connection.\n\n  Args:\n    *layers: One or more layers, to be applied in series.\n    shortcut: If None (the usual case), the Residual layer computes the\n        element-wise sum of the stack-top input with the output of the layer\n        series. If specified, the `shortcut` layer applies to a copy of the\n        inputs and (elementwise) adds its output to the output from the main\n        layer series.\n\n  Returns:\n      A layer representing a residual connection paired with a layer series.\n  """"""\n  layers = _ensure_flat(layers)\n  layer = layers[0] if len(layers) == 1 else Serial(layers)\n  # TODO(jonni): Should we require layer.n_out = 1 and shortcut.n_out = 1?\n  return Serial(\n      Branch(shortcut, layer),\n      Add(),  # pylint: disable=no-value-for-parameter\n  )\n\n\ndef Select(indices, n_in=None, name=None):\n  """"""Copies, reorders, or deletes stack elements according to `indices`.\n\n  Args:\n    indices: A list or tuple of 0-based indices to select elements relative to\n        the top of the stack.\n    n_in: Number of input elements to pop from the stack, and replace with\n        those specified by `indices`. If not specified, its value will be\n        calculated as `max(indices) + 1`.\n    name: Descriptive name for this layer.\n\n  Returns:\n    Tensors, matching the number selected (`n_out = len(indices)`).\n    Specifically:\n\n      - n_out = 0: an empty tuple\n      - n_out = 1: one tensor (NOT wrapped in a tuple)\n      - n_out > 1: a tuple of tensors, with n_out items\n  """"""\n  if n_in is None:\n    n_in = max(indices) + 1\n  if name is None:\n    name = f\'Select{indices}\'.replace(\' \', \'\')\n\n  def select(xs):  # pylint: disable=invalid-name\n    if not isinstance(xs, (tuple, list)):\n      xs = (xs,)\n    selected = tuple(xs[i] for i in indices)\n    return selected[0] if len(selected) == 1 else selected\n\n  return base.PureLayer(select, n_in=n_in, n_out=len(indices), name=name)\n\n\ndef Drop():\n  """"""Drops the top stack element.""""""\n  return Fn(\'Drop\', lambda x: (), n_out=0)\n\n\ndef Dup():\n  """"""Duplicates (copies) the top element on the data stack.""""""\n  return Fn(\'Dup\', lambda x: (x, x), n_out=2)\n\n\ndef Swap():\n  """"""Swaps the top two stack elements.""""""\n  return Fn(\'Swap\', lambda x0, x1: (x1, x0), n_out=2)\n\n\ndef SerialWithSideOutputs(layers, n_side_outputs=1):\n  """"""Serial layer with side outputs.\n\n  This layer makes it easier to manage the stack when layers have side outputs.\n\n  In the simplest case of layers with n_in=1, n_out=2 and with\n  n_side_outputs=1, this layer runs the following computation on x::\n\n    side_outputs = []\n    for i in range(len(layers)):\n      x, side_output = layers[i](x)\n      side_outputs.append(side_output)\n    return [x] + side_outputs\n\n  In the general case of layers with variable n_in and n_out and\n  n_side_outputs being a list of N integers, it does the following::\n\n    side_outputs = []\n    for i in range(N):\n      res = layer[i](cur_stack)  # remove n_in from stack\n      cur_stack.append(res[:n_side_outputs[i]])  # put back some on stack\n      side_outputs.extend(res[n_side_outputs:])\n    return cur_stack + side_outputs\n\n  Args:\n    layers: a list of layers to execute\n    n_side_outputs: an int or a list of ints, how many outputs of each layer\n        to put aside\n\n  Returns:\n    A layer that performs the above computation.\n  """"""\n  if isinstance(n_side_outputs, int):\n    n_side_outputs = [n_side_outputs] * len(layers)\n\n  # Calculate the n_in for this layer.\n  running_max = 0\n  running_total = 0\n  for layer, n_side_output in zip(layers, n_side_outputs):\n    running_total += layer.n_in\n    running_max = max(running_max, running_total)\n    running_total -= layer.n_out - n_side_output\n  n_in = running_max\n\n  # Create the list of layers to run serially.\n  cur_stack_size = n_in\n  serial_layers = []\n  for layer, n_side_output in zip(layers, n_side_outputs):\n    serial_layers.append(layer)\n    cur_stack_size += layer.n_out - layer.n_in\n    # Indices to move n_side_outputs to the back of the stack.\n    # Don\'t touch first n_out - n_side_outputs.\n    move_back_indices = list(range(layer.n_out - n_side_output))\n    # Then comes the rest of the stack that we\'re not moving.\n    move_back_indices += [i + layer.n_out\n                          for i in range(cur_stack_size - layer.n_out)]\n    # Finally the indices we move.\n    move_back_indices += [i + layer.n_out - n_side_output\n                          for i in range(n_side_output)]\n    # Swap them on stack.\n    serial_layers.append(Select(move_back_indices))\n\n  return Serial(serial_layers)\n\n\ndef FlattenList():\n  """"""Flatten lists.""""""\n  # TODO(jonni): Consider renaming layer to DeepFlatten.\n  return Fn(\'FlattenList\', lambda x: tuple(_deep_flatten(x)))\n\n\ndef Add():\n  """"""Adds two tensors.""""""\n  return Fn(\'Add\', lambda x0, x1: x0 + x1)\n\n\ndef SubtractTop():\n  """"""Subtracts the first tensor from the second.""""""\n  return Fn(\'SubtractTop\', lambda x0, x1: x1 - x0)\n\n\ndef Multiply():\n  """"""Multiplies two tensors.""""""\n  return Fn(\'Multiply\', lambda x0, x1: x0 * x1)\n\n\ndef Gate():\n  """"""Returns a gating layer on a (memory, gate, candidate) tuple.\n\n  Final update is memory * gate + (1 - gate) * candidate\n\n  This gating equation may also be referred to as Highway Network.\n  Highway Networks: https://arxiv.org/abs/1505.00387\n  """"""\n  return Fn(\'Gate\', lambda m, g, c: g * m + (1.0 - g) * c)\n\n\nclass Cache(base.Layer):\n  """"""Applies a layer on the first run and returns the outputs on next calls.""""""\n\n  def __init__(self, layer):\n    super(Cache, self).__init__(n_in=layer.n_in, n_out=layer.n_out)\n    self._sublayers = [layer]\n\n  @property\n  def sublayer(self):\n    """"""Returns the unique sublayer managed by this layer.""""""\n    return self._sublayers[0]\n\n  def forward(self, inputs, weights):\n    state = self.state\n    if state[0] is ():  # pylint: disable=literal-comparison\n      res, layer_state = self.sublayer.pure_fn(\n          inputs, weights, state[1], self.rng)\n      self.state = (res, layer_state)\n      return res\n    else:\n      return state[0]\n\n  def new_weights(self, input_signature):\n    weights, layer_state = self.sublayer.init(input_signature, use_cache=True)\n    self.state = ((), layer_state)\n    return weights\n\n\nclass BatchLeadingAxes(base.Layer):\n  """"""Applies a layer after flattening all but n_last_axes_to_keep to batch.\n\n  This can be used to make layers accept an arbitrary number of leading\n  axes (dimensions) as batch. For example, a Convolution layer may normally\n  only operate on tensors of shape [B, W, H, C]. In this case, the layer\n\n      BatchLeadingAxes(Convolution(), n_last_axes_to_keep=3)\n\n  will operate on any tensor [..., W, H, C] and treat the leading axes as batch.\n  """"""\n\n  def __init__(self, layer, n_last_axes_to_keep=1):\n    super(BatchLeadingAxes, self).__init__(n_in=layer.n_in, n_out=layer.n_out)\n    self._sublayers = [layer]\n    self._n_last_axes_to_keep = n_last_axes_to_keep\n\n  @property\n  def sublayer(self):\n    """"""Returns the unique sublayer managed by this layer.""""""\n    return self._sublayers[0]\n\n  def forward(self, inputs, weights):\n    batched_axes_shape = list(inputs.shape[:-self._n_last_axes_to_keep])\n    batched_shape = [-1] + list(inputs.shape[-self._n_last_axes_to_keep:])\n    inputs = jnp.reshape(inputs, batched_shape)\n    res, layer_state = self.sublayer.pure_fn(\n        inputs, weights, self.state, self.rng)\n    self.state = layer_state\n    return jnp.reshape(res, batched_axes_shape + list(res.shape[1:]))\n\n  def new_weights(self, input_signature):\n    weights, layer_state = self.sublayer.init(input_signature, use_cache=True)\n    self.state = layer_state\n    return weights\n\n\n# All module-private helper functions are below.\n# pylint: disable=invalid-name\n\n\ndef _deep_flatten(items):\n  """"""Returns a list of objects, flattening sublists/subtuples along the way.\n\n  Example: _deep_flatten([1, (2, 3, (4, 5), [6, 7]), [[[8]]]]) would return\n  the list [1, 2, 3, 4, 5, 6, 7, 8].\n\n  Args:\n    items: An iterable. If elements of this iterable are lists or tuples, they\n        will be (recursively) flattened until non-list non-tuple objects are\n        reached.\n\n  Returns:\n    A list of non-list, non-tuple objects.\n  """"""\n  def _flat_gen(xs):\n    for x in xs:\n      if isinstance(x, (list, tuple)):\n        for y in _flat_gen(x):\n          yield y\n      else:\n        yield x\n  return list(_flat_gen(items))\n\n\ndef _ensure_sublayers(layers):\n  """"""Ensures that elements in a layer list are layers.\n\n  Args:\n    layers: A tuple or list whose elements can each be a layer, tuple, or list,\n        and so on recursively.\n\n  Returns:\n    An analogous collection of layers in which embedded layer lists are\n    wrapped in Serial layer instances.\n  """"""\n  if not layers:  # None or an empty list can signal a no-op.\n    return Serial(None)  # no-op, but still handles shapes and initialization\n  elif isinstance(layers, (list, tuple)):\n    sublayers_not_lists = []\n    for layer in layers:\n      sublayers_not_lists.append(\n          Serial(layer) if isinstance(layer, (list, tuple)) else layer)\n    return sublayers_not_lists\n  else:\n    raise TypeError(type(layers))\n\n\ndef _split_rngs(rng, n_copies):\n  if rng is None:\n    return (None,) * n_copies\n  return math.random.split(rng, n_copies)\n\n\ndef _inputs_from_stack(layer, stack, n_in=None):\n  """"""Returns the correct number/format of inputs for the given layer.""""""\n  is_stack_just_one_item = (_count_items(stack) == 1)\n  if isinstance(stack, (list, tuple)) and is_stack_just_one_item:\n    stack = stack[0]\n  if n_in is None:\n    n_in = layer.n_in\n  if n_in == 1 and is_stack_just_one_item:\n    return stack\n  elif n_in == 1:\n    return stack[0]\n  else:\n    return stack[:n_in]\n\n\ndef _outputs_onto_stack(layer, outputs, stack, n_in=None, n_out=None):\n  """"""""Returns the new stack after outputs have been pushed onto it.""""""\n  if n_in is None:\n    n_in = layer.n_in\n  if n_out is None:\n    n_out = layer.n_out\n  if n_in < _count_items(stack):\n    if n_out == 1:\n      outputs = (outputs,)\n    return outputs + tuple(stack[n_in:])\n  else:\n    return outputs  # NOTE: can be single value or tuple.\n\n\ndef _count_items(xs):\n  return len(xs) if isinstance(xs, (list, tuple)) else 1\n\n\ndef _shape_without_axis(x, axis):\n  return x.shape[:axis] + x.shape[axis + 1:]\n\n\ndef _ensure_flat(layers):\n  """"""Ensures that layers is a single flat list of Layer instances.""""""\n  if len(layers) == 1 and layers[0] is None:\n    layers = ()\n  else:\n    layers = _deep_flatten(layers)\n  for obj in layers:\n    if not isinstance(obj, base.Layer):\n      raise ValueError(\n          f\'Found nonlayer object ({obj}) in layers: {layers}\')\n  return layers\n'"
trax/layers/combinators_test.py,58,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for combinator layers.""""""\n\nfrom absl.testing import absltest\n\nimport numpy as np\n\nfrom trax import shapes\nimport trax.layers as tl\n\n\ndef DivideBy(val):  # pylint: disable=invalid-name\n  """"""Returns a simple division layer with n_in == 1 and n_out == 1.""""""\n  return tl.Fn(\'DivideBy\', lambda x: x / val)\n\n\n# TODO(jonni): Consider a more generic home for this utiliity function.\ndef as_list(outputs):\n  """"""Converts layer outputs to a nested list, for easier equality testing.\n\n  Args:\n    outputs: A tensor or tuple/list of tensors coming from the forward\n        application of a layer. Each tensor is NumPy ndarray-like, which\n        complicates simple equality testing (e.g., via `assertEquals`):\n        such tensors require equality testing to use either `all` (all\n        elements match) or `any` (at least one element matches), which is not\n        directly supported in absltest.\n\n  Returns:\n    A nested list structure containing all the output values, but now directly\n    testable using `assertEquals`.\n  """"""\n  if isinstance(outputs, (list, tuple)):\n    return [y.tolist() for y in outputs]\n  else:\n    return outputs.tolist()\n\n\nclass SerialTest(absltest.TestCase):\n\n  def test_none_is_no_op(self):\n    layer = tl.Serial(None)\n    xs = [np.array([1, 2, 3, 4]),\n          np.array([10, 20, 30])]\n    ys = layer(xs)\n    self.assertEqual(as_list(ys), [[1, 2, 3, 4],\n                                   [10, 20, 30]])\n\n  def test_empty_list_is_no_op(self):\n    layer = tl.Serial([])\n    xs = [np.array([1, 2, 3, 4]),\n          np.array([10, 20, 30])]\n    ys = layer(xs)\n    self.assertEqual(as_list(ys), [[1, 2, 3, 4],\n                                   [10, 20, 30]])\n\n  def test_one_in_one_out(self):\n    layer = tl.Serial(DivideBy(3))\n    x = np.array([3, 6, 9, 12])\n    y = layer(x)\n    self.assertEqual(as_list(y), [1, 2, 3, 4])\n\n  def test_div_div(self):\n    layer = tl.Serial(DivideBy(2.0), DivideBy(5.0))\n    x = np.array([10, 20, 30])\n    y = layer(x)\n    self.assertEqual(as_list(y), [1, 2, 3])\n\n  def test_dup_dup(self):\n    layer = tl.Serial(tl.Dup(), tl.Dup())\n    x = np.array([1, 2, 3])\n    ys = layer(x)\n    self.assertEqual(as_list(ys), [[1, 2, 3],\n                                   [1, 2, 3],\n                                   [1, 2, 3]])\n\n  def test_default_name(self):\n    layer = tl.Serial(tl.Dup(), tl.Dup())\n    self.assertIn(\'Serial\', str(layer))\n\n  def test_custom_name(self):\n    layer = tl.Serial(tl.Dup(), tl.Dup(), name=\'Branch\')\n    self.assertIn(\'Branch\', str(layer))\n\n  def test_weights(self):\n    model = tl.Serial(tl.Dense(4), tl.Dense(5), tl.Dense(7))\n    self.assertIsInstance(model.weights, tuple)\n    self.assertLen(model.weights, 3)\n\n  def test_shared_weights(self):\n    layer = tl.Dense(5)\n    model = tl.Serial(layer, layer)\n    sample_input = np.array([1, 2, 3, 4, 5])\n    weights, _ = model.init(shapes.signature(sample_input))\n    self.assertIs(weights[1], tl.GET_WEIGHTS_FROM_CACHE)\n\n  def test_shared_weights_nested(self):\n    layer = tl.Dense(5)\n    model = tl.Serial(layer, tl.Serial(layer))\n    sample_input = np.array([1, 2, 3, 4, 5])\n    weights, _ = model.init(shapes.signature(sample_input))\n    self.assertIs(weights[1][0], tl.GET_WEIGHTS_FROM_CACHE)\n\n  def test_shared_weights_double_nested(self):\n    layer = tl.Dense(5)\n    model = tl.Serial(tl.Serial(layer), tl.Serial(layer))\n    sample_input = np.array([1, 2, 3, 4, 5])\n    weights, _ = model.init(shapes.signature(sample_input))\n    self.assertIs(weights[1][0], tl.GET_WEIGHTS_FROM_CACHE)\n\n  def test_state(self):\n    model = tl.Serial(tl.Dense(4), tl.Dense(5), tl.Dense(7))\n    self.assertIsInstance(model.state, tuple)\n    self.assertLen(model.state, 3)\n\n  def test_set_rng_recurse_two_levels(self):\n    dense_00 = tl.Dense(2)\n    dense_01 = tl.Dense(2)\n    dense_10 = tl.Dense(2)\n    dense_11 = tl.Dense(2)\n    layer = tl.Serial(\n        tl.Serial(dense_00, dense_01),\n        tl.Serial(dense_10, dense_11),\n    )\n    input_signature = shapes.ShapeDtype((1, 2))\n\n    _, _ = layer.init(input_signature)\n    weights = layer.weights\n    dense_00_w, dense_00_b = weights[0][0]\n    dense_01_w, dense_01_b = weights[0][1]\n    dense_10_w, dense_10_b = weights[1][0]\n    dense_11_w, dense_11_b = weights[1][1]\n\n    # Setting rng\'s recursively during init should yield differing weights.\n    self.assertFalse(np.array_equal(dense_00_w, dense_01_w))\n    self.assertFalse(np.array_equal(dense_00_b, dense_01_b))\n    self.assertFalse(np.array_equal(dense_10_w, dense_11_w))\n    self.assertFalse(np.array_equal(dense_10_b, dense_11_b))\n\n\nclass ParallelTest(absltest.TestCase):\n\n  def test_dup_dup(self):\n    layer = tl.Parallel(tl.Dup(), tl.Dup())\n    xs = [np.array([1, 2, 3]),\n          np.array([10, 20])]\n    ys = layer(xs)\n    self.assertEqual(as_list(ys), [[1, 2, 3],\n                                   [1, 2, 3],\n                                   [10, 20],\n                                   [10, 20]])\n\n  def test_div_div(self):\n    layer = tl.Parallel(DivideBy(0.5), DivideBy(3.0))\n    xs = [np.array([1, 2, 3]),\n          np.array([30, 60])]\n    ys = layer(xs)\n    self.assertEqual(as_list(ys), [[2, 4, 6],\n                                   [10, 20]])\n\n  def test_two_no_ops(self):\n    layer = tl.Parallel([], None)\n    xs = [np.array([1, 2, 3]),\n          np.array([10, 20])]\n    ys = layer(xs)\n    self.assertEqual(as_list(ys), [[1, 2, 3],\n                                   [10, 20]])\n\n  def test_default_name(self):\n    layer = tl.Parallel(tl.Dup(), tl.Dup())\n    self.assertIn(\'Parallel\', str(layer))\n\n  def test_custom_name(self):\n    layer = tl.Parallel(tl.Dup(), tl.Dup(), name=\'DupDup\')\n    self.assertIn(\'DupDup\', str(layer))\n\n  def test_weights(self):\n    model = tl.Parallel(tl.Dense(3), tl.Dense(5))\n    self.assertIsInstance(model.weights, tuple)\n    self.assertLen(model.weights, 2)\n\n  def test_shared_weights(self):\n    layer = tl.Dense(5)\n    model = tl.Parallel(layer, layer)\n    sample_input = (np.array([1, 2, 3, 4, 5]), np.array([1, 2, 3, 4, 5]))\n    weights, _ = model.init(shapes.signature(sample_input))\n    self.assertIs(weights[1], tl.GET_WEIGHTS_FROM_CACHE)\n\n  def test_shared_weights_nested(self):\n    layer = tl.Dense(5)\n    model = tl.Parallel([layer, tl.Dense(2)],\n                        [layer, tl.Dense(2)])\n    sample_input = (np.array([1, 2, 3, 4, 5]), np.array([1, 2, 3, 4, 5]))\n    weights, _ = model.init(shapes.signature(sample_input))\n    self.assertIs(weights[1][0], tl.GET_WEIGHTS_FROM_CACHE)\n\n  def test_state(self):\n    model = tl.Parallel(tl.Dense(3), tl.Dense(5))\n    self.assertIsInstance(model.state, tuple)\n    self.assertLen(model.state, 2)\n\n\nclass ConcatenateTest(absltest.TestCase):\n\n  def test_n_in_n_out(self):\n    layer = tl.Concatenate()\n    self.assertEqual(layer.n_in, 2)\n    self.assertEqual(layer.n_out, 1)\n\n  def test_with_defaults(self):\n    layer = tl.Concatenate()  # Default n_items=2, axis=-1\n    xs = [np.array([[1, 2, 3],\n                    [4, 5, 6]]),\n          np.array([[10, 20, 30],\n                    [40, 50, 60]])]\n    ys = layer(xs)\n    self.assertEqual(as_list(ys), [[1, 2, 3, 10, 20, 30],\n                                   [4, 5, 6, 40, 50, 60]])\n\n  def test_axis_0(self):\n    layer = tl.Concatenate(axis=0)\n    xs = [np.array([[1, 2, 3],\n                    [4, 5, 6]]),\n          np.array([[10, 20, 30],\n                    [40, 50, 60]])]\n    y = layer(xs)\n    self.assertEqual(as_list(y), [[1, 2, 3],\n                                  [4, 5, 6],\n                                  [10, 20, 30],\n                                  [40, 50, 60]])\n\n  def test_axis_1(self):\n    layer = tl.Concatenate(axis=1)\n    xs = [np.array([[1, 2, 3],\n                    [4, 5, 6]]),\n          np.array([[10, 20, 30],\n                    [40, 50, 60]])]\n    y = layer(xs)\n    self.assertEqual(as_list(y), [[1, 2, 3, 10, 20, 30],\n                                  [4, 5, 6, 40, 50, 60]])\n\n  def test_n_items_is_not_default(self):\n    layer = tl.Concatenate(n_items=3)\n    xs = [np.array([[1, 2, 3],\n                    [4, 5, 6]]),\n          np.array([[10, 20, 30],\n                    [40, 50, 60]]),\n          np.array([[100, 200, 300],\n                    [400, 500, 600]])]\n    y = layer(xs)\n    self.assertEqual(y.shape, (2, 9))\n    self.assertEqual(as_list(y), [[1, 2, 3, 10, 20, 30, 100, 200, 300],\n                                  [4, 5, 6, 40, 50, 60, 400, 500, 600]])\n\n  def test_repr(self):\n    layer = tl.Concatenate()\n    self.assertEqual(repr(layer), \'Concatenate_in2\')\n\n    layer = tl.Concatenate(axis=0)\n    self.assertEqual(repr(layer), \'Concatenate_axis0_in2\')\n\n    layer = tl.Concatenate(axis=1)\n    self.assertEqual(repr(layer), \'Concatenate_axis1_in2\')\n\n    layer = tl.Concatenate(n_items=3)\n    self.assertEqual(repr(layer), \'Concatenate_in3\')\n\n\nclass BranchTest(absltest.TestCase):\n\n  def test_noop_dup(self):\n    layer = tl.Branch([], tl.Dup())\n    x = np.array([1, 2, 3])\n    ys = layer(x)\n    self.assertEqual(as_list(ys), [[1, 2, 3],\n                                   [1, 2, 3],\n                                   [1, 2, 3]])\n\n  def test_add_div(self):\n    layer = tl.Branch(tl.Add(), DivideBy(0.5))\n    xs = [np.array([1, 2, 3]),\n          np.array([10, 20, 30])]\n    ys = layer(xs)\n    self.assertEqual(as_list(ys), [[11, 22, 33],\n                                   [2, 4, 6]])\n\n  def test_one_sublayer(self):\n    layer = tl.Branch(DivideBy(0.5))\n    x = np.array([1, 2, 3])\n    ys = layer(x)\n    self.assertEqual(as_list(ys), [2, 4, 6])\n\n  def test_default_name(self):\n    layer = tl.Branch(tl.Add(), DivideBy(0.5))\n    self.assertIn(\'Branch\', str(layer))\n\n\nclass SelectTest(absltest.TestCase):\n\n  def test_computes_n_in(self):\n    layer = tl.Select([0, 0])\n    self.assertEqual(layer.n_in, 1)\n\n    layer = tl.Select([1, 0])\n    self.assertEqual(layer.n_in, 2)\n\n    layer = tl.Select([2])\n    self.assertEqual(layer.n_in, 3)\n\n  def test_given_n_in(self):\n    layer = tl.Select([0], n_in=2)\n    self.assertEqual(layer.n_in, 2)\n\n    layer = tl.Select([0], n_in=3)\n    self.assertEqual(layer.n_in, 3)\n\n  def test_first_of_3(self):\n    layer = tl.Select([0], n_in=3)\n    xs = [np.array([1, 2, 3]),\n          np.array([10, 20]),\n          np.array([100])]\n    y = layer(xs)\n    self.assertEqual(as_list(y), [1, 2, 3])\n\n  def test_second_of_3(self):\n    layer = tl.Select([1], n_in=3)\n    xs = [np.array([1, 2, 3]),\n          np.array([10, 20]),\n          np.array([100])]\n    y = layer(xs)\n    self.assertEqual(as_list(y), [10, 20])\n\n\nclass DropTest(absltest.TestCase):\n\n  def test_drop(self):\n    layer = tl.Drop()\n    x = np.array([1, 2, 3])\n    y = layer(x)\n    self.assertEqual(as_list(y), [])\n\n\nclass SwapTest(absltest.TestCase):\n\n  def test_swap(self):\n    layer = tl.Swap()\n    xs = [np.array([1, 2, 3]),\n          np.array([10, 20, 30])]\n    ys = layer(xs)\n    self.assertEqual(as_list(ys), [[10, 20, 30],\n                                   [1, 2, 3]])\n\n\nclass SerialWithSideOutputsTest(absltest.TestCase):\n\n  def test_serial_with_side_outputs_div_div(self):\n    def some_layer():\n      return tl.Parallel(DivideBy(2.0), DivideBy(5.0))\n    layer = tl.SerialWithSideOutputs([some_layer(), some_layer()])\n    xs = (np.array([1, 2, 3]),\n          np.array([10, 20, 30, 40, 50]),\n          np.array([100, 200]))\n    ys = layer(xs)\n    output_shapes = [y.shape for y in ys]\n    self.assertEqual(output_shapes, [(3,), (5,), (2,)])\n\n\nclass ScanTest(absltest.TestCase):\n\n  def _AddWithCarry(self):  # pylint: disable=invalid-name\n    del self\n    def f(x, carry):\n      res = x + carry\n      return res, res  # output and carry are the same\n    return tl.Fn(\'AddWithCarry\', f, n_out=2)\n\n  def test_default_axis(self):\n    layer = tl.Scan(self._AddWithCarry())\n    xs = [\n        np.array([[0, 1, 2, 3],\n                  [0, 10, 20, 30],\n                  [0, 100, 200, 300]]),\n        np.array([9000, 8000, 7000, 6000])\n    ]\n    ys = layer(xs)\n    self.assertEqual(as_list(ys),\n                     [[[9000, 8001, 7002, 6003],\n                       [9000, 8011, 7022, 6033],\n                       [9000, 8111, 7222, 6333]\n                      ],\n                      [9000, 8111, 7222, 6333]\n                     ])\n\n  def test_axis_1(self):\n    layer = tl.Scan(self._AddWithCarry(), axis=1)\n    xs = [\n        np.array([[0, 1, 2, 3],\n                  [0, 10, 20, 30],\n                  [0, 100, 200, 300]]),\n        np.array([9000,\n                  8000,\n                  7000])\n    ]\n    ys = layer(xs)\n    self.assertEqual(as_list(ys),\n                     [[[9000, 9001, 9003, 9006],\n                       [8000, 8010, 8030, 8060],\n                       [7000, 7100, 7300, 7600]\n                      ],\n                      [9006,\n                       8060,\n                       7600]\n                     ])\n\n  def test_multi_input(self):\n    def _MultiInputFn():  # pylint: disable=invalid-name\n      def f(a, b, carry):\n        return a + b, b, carry + 1\n      return tl.Fn(\'MultiInputFn\', f, n_out=2)\n\n    layer = tl.Scan(_MultiInputFn(), axis=1)\n    xs = [\n        np.array([[0, 1, 2],\n                  [0, 10, 20]]),\n        np.array([[4, 5, 6],\n                  [40, 50, 60]]),\n        np.array([9000,\n                  8000])\n    ]\n    ys = layer(xs)\n    self.assertEqual(as_list(ys),\n                     [[[4, 6, 8],\n                       [40, 60, 80]],\n                      [[4, 5, 6],\n                       [40, 50, 60]],\n                      [9003,\n                       8003]\n                     ])\n\n  def test_no_carry(self):\n    def _AddOne():  # pylint: disable=invalid-name\n      return tl.Fn(\'AddOne\', lambda x: x + 1)\n\n    layer = tl.Scan(_AddOne(), n_carry=0)\n    x = np.array([[1, 3, 7],\n                  [10, 30, 70]])\n    y = layer(x)\n    self.assertEqual(as_list(y), [[2, 4, 8],\n                                  [11, 31, 71]])\n\n\nclass BatchLeadingAxesTest(absltest.TestCase):\n\n  def _Id3Dim(self):  # pylint: disable=invalid-name\n    del self\n    def f(x):\n      assert len(x.shape) == 3\n      return x\n    return tl.Fn(\'Id3Dim\', f, n_out=2)\n\n  def test_2axes(self):\n    layer = tl.BatchLeadingAxes(self._Id3Dim(), n_last_axes_to_keep=2)\n    ys = layer(np.zeros((3, 4, 5)))\n    self.assertEqual(ys.shape, (3, 4, 5))\n    ys = layer(np.zeros((2, 3, 4, 5)))\n    self.assertEqual(ys.shape, (2, 3, 4, 5))\n    ys = layer(np.zeros((1, 2, 3, 4, 5)))\n    self.assertEqual(ys.shape, (1, 2, 3, 4, 5))\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/layers/convolution.py,3,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Trax convolution layers.""""""\n\nimport functools\nimport itertools\nimport operator\n\nfrom trax import math\nfrom trax.layers import base\nfrom trax.layers import initializers as init\nfrom trax.math import numpy as np\n\n\nclass Conv(base.Layer):\n  """"""Layer constructor function for a general convolution layer.""""""\n\n  def __init__(self, filters, kernel_size, strides=None, padding=\'VALID\',\n               dimension_numbers=(\'NHWC\', \'HWIO\', \'NHWC\'),\n               kernel_initializer=None,\n               bias_initializer=init.RandomNormalInitializer(1e-6)):\n    super(Conv, self).__init__()\n    self._filters = filters\n    self._kernel_size = kernel_size\n    self._padding = padding\n    self._dimension_numbers = dimension_numbers\n    self._lhs_spec, self._rhs_spec, self._out_spec = dimension_numbers\n    self._one = (1,) * len(kernel_size)\n    self._strides = strides or self._one\n    self._bias_initializer = bias_initializer\n    rhs_spec = self._rhs_spec\n    self._kernel_initializer = kernel_initializer\n    if kernel_initializer is None:\n      self._kernel_initializer = init.GlorotNormalInitializer(\n          rhs_spec.index(\'O\'), rhs_spec.index(\'I\'))\n\n  def _check_nhwc(self):\n    msg = \'Convolutions on more than 4 dimensions only supported in NHWC.\'\n    assert self._lhs_spec == self._out_spec == \'NHWC\', msg\n\n  def forward(self, x, weights):\n    w, b = weights\n    x_shape = list(x.shape)\n    if len(x_shape) > 4:\n      self._check_nhwc()\n      new_batch_dim = functools.reduce(operator.mul, x_shape[:-3])\n      x = np.reshape(x, [new_batch_dim] + x_shape[-3:])\n    res = math.conv(\n        x, w, self._strides, self._padding, self._dimension_numbers,\n        self._one) + b\n    if len(x_shape) > 4:\n      res = np.reshape(res, x_shape[:-3] + list(res.shape[-3:]))\n    return res\n\n  def _kernel_shape(self, input_shape):\n    """"""Helper to calculate the kernel shape.""""""\n    kernel_size_iter = iter(self._kernel_size)\n    return [self._filters if c == \'O\' else\n            input_shape[self._lhs_spec.index(\'C\')] if c == \'I\' else\n            next(kernel_size_iter) for c in self._rhs_spec]\n\n  def new_weights(self, input_signature):\n    input_shape = input_signature.shape\n    if len(input_shape) > 4:\n      self._check_nhwc()\n      new_batch_dim = functools.reduce(operator.mul, input_shape[:-3])\n      input_shape = [new_batch_dim] + list(input_shape[-3:])\n    kernel_shape = self._kernel_shape(input_shape)\n    bias_shape = [self._filters if c == \'C\' else 1 for c in self._out_spec]\n    bias_shape = tuple(itertools.dropwhile(lambda x: x == 1, bias_shape))\n    rng1, rng2 = math.random.split(self.rng, 2)\n    w = self._kernel_initializer(kernel_shape, rng1)\n    b = self._bias_initializer(bias_shape, rng2)\n    return (w, b)\n\n\nclass CausalConv(Conv):\n  """"""Causal (masked) convolution for [batch x time x depth] sequences.\n\n  Maintains causality along time axis. Used in language modeling tasks.\n  """"""\n\n  def __init__(self,\n               filters,\n               kernel_width=3,\n               kernel_initializer=None,\n               bias_initializer=init.RandomNormalInitializer(1e-6)):\n    super(CausalConv, self).__init__(\n        filters=filters,\n        kernel_size=(kernel_width,),\n        strides=None,\n        padding=\'VALID\',\n        dimension_numbers=(\'NWC\', \'WIO\', \'NWC\'),\n        kernel_initializer=kernel_initializer,\n        bias_initializer=bias_initializer)\n\n  def forward(self, x, weights):\n    assert self._padding == \'VALID\'\n    # Left pad with 0s. Applying an unmasked valid convolution on top of this\n    # yields a causal convolution.\n    # TODO(ddohan): Support strided and dilated convolutions.\n    rate = 1\n    effective_kernel_size = int((self._kernel_size[0] - 1) * rate + 1)\n    pad = effective_kernel_size - 1\n    x_leftpad = np.pad(x, pad_width=[[0, 0], [pad, 0], [0, 0]], mode=\'constant\')\n    return super(CausalConv, self).forward(x_leftpad, weights)\n\n\ndef Conv1d(filters, kernel_size, stride=1, padding=\'VALID\',\n           kernel_initializer=None,\n           bias_initializer=init.RandomNormalInitializer(1e-6)):\n  return Conv(filters, (kernel_size,), strides=(stride,), padding=padding,\n              dimension_numbers=(\'NWC\', \'WIO\', \'NWC\'),\n              kernel_initializer=kernel_initializer,\n              bias_initializer=bias_initializer)\n'"
trax/layers/convolution_test.py,3,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for convolution layers.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\n\nfrom trax import shapes\nimport trax.layers as tl\n\n\nclass ConvolutionTest(absltest.TestCase):\n\n  def test_call(self):\n    layer = tl.Conv(30, (3, 3))\n    x = np.ones((9, 5, 5, 20))\n    layer.init(shapes.signature(x))\n\n    y = layer(x)\n    self.assertEqual(y.shape, (9, 3, 3, 30))\n\n  def test_call_rebatch(self):\n    layer = tl.Conv(30, (3, 3))\n    x = np.ones((2, 9, 5, 5, 20))\n    layer.init(shapes.signature(x))\n\n    y = layer(x)\n    self.assertEqual(y.shape, (2, 9, 3, 3, 30))\n\n\nclass CausalConvolutionTest(absltest.TestCase):\n\n  def test_causal_conv(self):\n    layer = tl.CausalConv(filters=30, kernel_width=3)\n    x = np.ones((9, 5, 20))\n    layer.init(shapes.signature(x))\n\n    y = layer(x)\n    self.assertEqual(y.shape, (9, 5, 30))\n\n    # TODO(ddohan): How to test for causality? Gradient check between positions?\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/layers/core.py,30,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Core layer types, such as `Dense`, `Embedding`, and `Dropout`.""""""\n\nimport numpy as np\n\nfrom trax import math\nfrom trax.layers import base\nfrom trax.layers import initializers as init\nfrom trax.layers.base import Fn\nfrom trax.math import numpy as jnp\n\n\nclass Dense(base.Layer):\n  """"""A dense (a.k.a. fully-connected, affine) layer.\n\n  Dense layers are the prototypical example of a trainable layer, i.e., a layer\n  with trainable weights. Each node in a dense layer computes a weighted sum of\n  all node values from the preceding layer and adds to that sum a node-specific\n  bias term. The full layer computation is expressed compactly in linear\n  algebra as an affine map `y = Wx + b`, where `W` is a matrix and `y`, `x`,\n  and `b` are vectors. The layer is trained, or ""learns"", by updating the\n  values in `W` and `b`.\n\n  Less commonly, a dense layer can omit the bias term and be a pure linear map:\n  `y = Wx`.\n  """"""\n\n  def __init__(self,\n               n_units,\n               kernel_initializer=init.GlorotUniformInitializer(),\n               bias_initializer=init.RandomNormalInitializer(1e-6),\n               use_bias=True):\n    """"""Returns a dense (fully connected) layer of width `n_units`.\n\n    A dense layer maps collections of `R^m` vectors to `R^n`, where `n`\n    (`= n_units`) is fixed at layer creation time, and `m` is set at layer\n    initialization time.\n\n    Args:\n      n_units: Number of nodes in the layer, also known as the width of the\n          layer.\n      kernel_initializer: Function that creates a matrix of (random) initial\n          connection weights `W` for the layer.\n      bias_initializer: Function that creates a vector of (random) initial\n          bias weights `b` for the layer.\n      use_bias: If `True`, compute an affine map `y = Wx + b`; else compute\n          a linear map `y = Wx`.\n    """"""\n    super().__init__(name=f\'Dense_{n_units}\')\n    self._n_units = n_units\n    self._kernel_initializer = kernel_initializer\n    self._bias_initializer = bias_initializer\n    self._use_bias = use_bias\n\n  def forward(self, x, weights):\n    """"""Executes this layer as part of a forward pass through the model.\n\n    Args:\n      x: Tensor of same shape and dtype as the input signature used to\n          initialize this layer.\n      weights: Tuple `(w, b)` for layers created with `use_bias=True`, or\n          tensor `w` for layers created with `use_bias=False`.\n\n    Returns:\n      Tensor of same shape and dtype as the input, except the final dimension\n      is the layer\'s `n_units` value.\n    """"""\n    if self._use_bias:\n      if not isinstance(weights, (tuple, list)):\n        raise ValueError(f\'Weights should be a (w, b) tuple or list; \'\n                         f\'instead got: {weights}\')\n      w, b = weights\n      return jnp.dot(x, w) + b  # Affine map.\n    else:\n      w = weights\n      return jnp.dot(x, w)  # Linear map.\n\n  def new_weights(self, input_signature):\n    """"""Returns newly initialized weights for this layer.\n\n    Weights are a `(w, b)` tuple for layers created with `use_bias=True` (the\n    default case), or a `w` tensor for layers created with `use_bias=False`.\n\n    Args:\n      input_signature: `ShapeDtype` instance characterizing the input this layer\n          should compute on.\n    """"""\n    shape_w = (input_signature.shape[-1], self._n_units)\n    shape_b = (self._n_units,)\n    rng_w, rng_b = math.random.split(self.rng, 2)\n    w = self._kernel_initializer(shape_w, rng_w)\n\n    if self._use_bias:\n      b = self._bias_initializer(shape_b, rng_b)\n      return (w, b)\n    else:\n      return w\n\n\nclass Embedding(base.Layer):\n  """"""Trainable layer that maps discrete tokens/ids to vectors.""""""\n\n  # TODO(jonni): Consider reversing param order to: vocab_size, d_feature\n  def __init__(self,\n               d_feature,\n               vocab_size,\n               kernel_initializer=init.RandomNormalInitializer(1.0)):\n    """"""Returns an embedding layer with given vocabulary size and vector size.\n\n    The layer clips input values (token ids) to the range `[0, vocab_size)`.\n    That is, negative token ids all clip to `0` before being mapped to a\n    vector, and token ids with value `vocab_size` or greater all clip to\n    `vocab_size - 1` before being mapped to a vector. In effect, both id `0`\n    and id `vocab_size - 1` are potentially overloaded as out-of-vocabulary\n    token ids.\n\n    TODO(jonni): Is this the behavior we want going forward?\n\n    Args:\n      d_feature: Dimensionality/depth of the output vectors.\n      vocab_size: Size of the input vocabulary. The layer will assign a unique\n          vector to each id in `range(vocab_size)`.\n      kernel_initializer: Function that creates (random) initial vectors for\n          the embedding.\n    """"""\n    super().__init__()\n    self._d_feature = d_feature  # feature dimensionality\n    self._vocab_size = vocab_size\n    self._kernel_initializer = kernel_initializer\n\n  def forward(self, x, weights):\n    """"""Returns embedding vectors corresponding to input token id\'s.\n\n    Args:\n      x: Tensor of token id\'s.\n      weights: Tensor of shape `(vocab_size, d_feature)`, where row `i`\n          contains the vector for token id `i`.\n\n    Returns:\n      Tensor of embedding vectors.\n    """"""\n    return jnp.take(weights, x, axis=0)\n\n  def new_weights(self, input_signature):\n    """"""Returns tensor of newly initialized embedding vectors.""""""\n    del input_signature\n    shape_w = (self._vocab_size, self._d_feature)\n    # TODO(lukaszkaiser): do we split self.rng for consistency? Add a method?\n    w = self._kernel_initializer(shape_w, self.rng)\n    return w\n\n\nclass Dropout(base.Layer):\n  """"""A layer that stochastically ignores a subset of inputs each training step.\n\n  In training, to compensate for the fraction of input values dropped (`rate`),\n  all surviving values are multiplied by `1 / (1 - rate)`.\n\n  This layer is active only during training (`mode=\'train\'`). In other\n  circumstances it is a no-op.\n  """"""\n\n  def __init__(self, rate=0.0, name=\'dropout\', mode=\'train\'):\n    """"""Creates a dropout layer with the given target drop rate.\n\n    Args:\n      rate: Stochastic rate (probability) for dropping an activation value\n          from the preceding layer (setting it to zero).\n      name: **DEPRECATED** Custom name for this instance.\n      mode: If `\'train\'`, this layer will perform dropout; else, it will pass\n          all values through unaltered.\n    """"""\n    super(Dropout, self).__init__()\n    self._initial_rate = rate\n    # TODO(lukaszkaiser): remove the name property by the end of September\'19.\n    # It\'s only needed for a specific purpose in the short term, will go.\n    self._name = \'dropout_\' + name\n    self._mode = mode\n\n  def new_weights(self, input_signature):\n    """"""Sets layer-specific internal state.""""""\n    del input_signature\n    self.state = {self._name: jnp.array(self._initial_rate)}\n    return base.EMPTY_WEIGHTS\n\n  def forward(self, x, weights):\n    """"""Executes this layer as part of a forward pass through the model.\n\n    Args:\n      x: Tensor of activations.\n      weights: Ignored/not used.\n\n    Returns:\n      Tensor of same shape and dtype as the input.\n    """"""\n    if self._mode != \'train\':\n      return x\n    state, rng = self.state, self.rng\n    rate = self._initial_rate\n    if isinstance(state, dict) and self._name in state:\n      rate = state[self._name]\n    keep = math.random.bernoulli(rng, 1.0 - rate, x.shape)\n    return jnp.where(keep, x / (1.0 - rate), jnp.zeros_like(x))\n\n\ndef Flatten(n_axes_to_keep=1):\n  """"""Returns a layer that combines one or more trailing axes of a tensor.\n\n  Flattening keeps all the values of the input tensor, but reshapes it by\n  collapsing one or more trailing axes into a single axis. For example, a\n  `Flatten(n_axes_to_keep=2)` layer would map a tensor with shape `(2, 3, 5, 7,\n  11)` to the same values with shape `(2, 3, 385)`.\n\n  Args:\n    n_axes_to_keep: Number of leading axes to leave unchanged when reshaping;\n        collapse only the axes after these.\n  """"""\n  layer_name = f\'Flatten_keep{n_axes_to_keep}\'\n  def f(x):  # pylint: disable=invalid-name\n    in_rank = len(x.shape)\n    if in_rank <= n_axes_to_keep:\n      raise ValueError(f\'Input rank ({in_rank}) must exceed the number of \'\n                       f\'axes to keep ({n_axes_to_keep}) after flattening.\')\n    return jnp.reshape(x, (x.shape[:n_axes_to_keep] + (-1,)))\n  return Fn(layer_name, f)\n\n\ndef Exp():\n  """"""Returns a layer that computes the element-wise exponential of a tensor.""""""\n  return Fn(\'Exp\', lambda x: jnp.exp(x))  # pylint: disable=unnecessary-lambda\n\n\ndef LogSoftmax(axis=-1):\n  """"""Returns a layer that applies log softmax along one tensor axis.\n\n  `LogSoftmax` acts on a group of values and normalizes them to look like a set\n  of log probability values. (Probability values must be non-negative, and as\n  a set must sum to 1. A group of log probability values can be seen as the\n  natural logarithm function applied to a set of probability values.)\n\n  Args:\n    axis: Axis along which values are grouped for computing log softmax.\n  """"""\n  return Fn(\'LogSoftmax\',\n            lambda x: x - math.logsumexp(x, axis, keepdims=True))\n\n\ndef Softmax(axis=-1):\n  """"""Returns a layer that applies softmax along one tensor axis.\n\n  `Softmax` acts on a group of values and normalizes them to look like a set\n  of probability values. (Probability values must be non-negative, and as a\n  set must sum to 1.)\n\n  Args:\n    axis: Axis along which values are grouped for computing softmax.\n  """"""\n  return Fn(\'Softmax\',\n            lambda x: jnp.exp(x - math.logsumexp(x, axis, keepdims=True)))\n\n\ndef ToFloat():\n  """"""Returns a layer that changes the dtype of a tensor to `float32`.""""""\n  return Fn(\'ToFloat\', lambda x: x.astype(np.float32))\n\n\ndef Mean(axis=-1, keepdims=False):\n  """"""Returns a layer that computes mean values using one tensor axis.\n\n  `Mean` uses one tensor axis to form groups of values and replaces each group\n  with the mean value of that group. The resulting values can either remain\n  in their own size 1 axis (`keepdims=True`), or that axis can be removed from\n  the overall tensor (default `keepdims=False`), lowering the rank of the\n  tensor by one.\n\n  Args:\n    axis: Axis along which values are grouped for computing a mean.\n    keepdims: If `True`, keep the resulting size 1 axis as a separate tensor\n        axis; else, remove that axis.\n  """"""\n  return Fn(\'Mean\', lambda x: jnp.mean(x, axis=axis, keepdims=keepdims))\n\n\ndef Sum(axis=-1, keepdims=False):\n  """"""Returns a layer that computes sums using one tensor axis.\n\n  `Sum` uses one tensor axis to form groups of values and replaces each group\n  with the sum of that group. The resulting sum values can either remain in\n  their own size 1 axis (`keepdims=True`), or that axis can be removed from the\n  overall tensor (default `keepdims=False`), lowering the rank of the tensor by\n  one.\n\n  Args:\n    axis: Axis along which values are grouped for computing a sum.\n    keepdims: If `True`, keep the resulting size 1 axis as a separate tensor\n        axis; else, remove that axis.\n  """"""\n  return Fn(\'Sum\', lambda x: jnp.sum(x, axis=axis, keepdims=keepdims))\n\n\ndef Negate():\n  """"""Returns a layer that computes the element-wise negation of a tensor.""""""\n  return Fn(\'Negate\', lambda x: -x)\n\n\ndef log_gaussian_pdf(x, mu, sigma):  # pylint: disable=invalid-name\n  """"""Returns `log N(x | mu, sigma)`.\n\n  Args:\n    x: <tbd>\n    mu: <tbd>\n    sigma: <tbd>\n  """"""\n  a = mu.shape[-1] * jnp.log(2 * jnp.pi)\n  _, b = jnp.linalg.slogdet(sigma)\n  y = jnp.linalg.solve(sigma, x - mu)\n  y = jnp.expand_dims(y, axis=-1)\n  xm = jnp.expand_dims(x - mu, axis=-2)\n  c = jnp.matmul(xm, y)\n  c = jnp.squeeze(jnp.squeeze(c, axis=-1), axis=-1)\n  return -0.5 * (a + b + c)\n\n\ndef log_gaussian_diag_pdf(x, mu, diag_sigma):  # pylint: disable=invalid-name\n  """"""Returns `log N(x | mu, eye(diag_sigma))`.\n\n  Args:\n    x: <tbd>\n    mu: <tbd>\n    diag_sigma: <tbd>\n  """"""\n  a = mu.shape[-1] * jnp.log(2 * jnp.pi)\n  b = jnp.sum(jnp.log(diag_sigma), axis=-1)\n  y = x - mu / diag_sigma\n  y = jnp.expand_dims(y, axis=-1)\n  xm = jnp.expand_dims(x - mu, axis=-2)\n  c = jnp.matmul(xm, y)\n  c = jnp.squeeze(jnp.squeeze(c, axis=-1), axis=-1)\n  return -0.5 * (a + b + c)\n\n\ndef multigaussian_loss(preds, targets, ngauss=1):  # pylint: disable=invalid-name\n  """"""Returns a mixture of gaussians loss.\n\n  Args:\n    preds: <tbd>\n    targets: <tbd>\n    ngauss: <tbd>\n  """"""\n  ndims = targets.shape[-1]\n  logits = preds[:, :ngauss]\n  mus = preds[:, ngauss:ngauss*(ndims + 1)]\n  sigmas = preds[:, ngauss(ndims + 1):]\n  sigmas = sigmas * sigmas + 1e-6  # Make positive.\n  loglogits = logits - math.logsumexp(logits, axis=-1, keepdims=True)\n  mus = jnp.reshape(mus, [-1, ngauss, ndims])\n  sigmas = jnp.reshape(sigmas, [-1, ngauss, ndims])\n  targets = jnp.reshape(targets, [-1, 1, ndims])\n  glogprobs = log_gaussian_diag_pdf(targets, mus, sigmas)\n  return math.logsumexp(loglogits + glogprobs, axis=-1)\n\n\ndef gumbel_sample(log_probs, temperature=1.0):  # pylint: disable=invalid-name\n  """"""Returns a Gumbel sample from a categorical distribution, with temperature.\n\n  Args:\n    log_probs: <tbd>\n    temperature: <tbd>\n  """"""\n  # This is equivalent to sampling from a softmax with temperature.\n  u = np.random.uniform(low=1e-6, high=1.0 - 1e-6, size=log_probs.shape)\n  g = -np.log(-np.log(u))\n  return np.argmax(log_probs + g * temperature, axis=-1)\n'"
trax/layers/core_test.py,33,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for core layers.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\n\nfrom trax import shapes\nimport trax.layers as tl  # Flattened view for API users (hides subpackaging).\n\n\nclass DenseTest(absltest.TestCase):\n  """"""Test Dense layer per se and as a key example of trainable layers.""""""\n\n  def test_call_before_init_raises_error(self):\n    layer = tl.Dense(5)\n    x = np.array([1, 2, 3])\n\n    # Without init, layer lacks the weights it needs for forward computation.\n    with self.assertRaises(tl.LayerError):\n      _ = layer(x)\n\n  def test_call_uses_and_caches_supplied_weights(self):\n    layer = tl.Dense(4)\n    x = np.array([2, 3])\n\n    # Weights from random initialization are cached in the layer.\n    _, _ = layer.init(shapes.signature(x))\n    w_init, b_init = layer.weights\n\n    # Call the layer with externally specified weights.\n    w = np.array([[10000, 20000, 30000, 40000],\n                  [100, 200, 100, 200]])\n    b = np.array([9, 8, 7, 6])\n    y = layer(x, weights=(w, b))\n\n    # Using weights keyword arg overrides any previous cached weights ...\n    self.assertEqual(y.tolist(), [20309, 40608, 60307, 80606])\n    self.assertNotEqual(w.tolist(), w_init.tolist())\n    self.assertNotEqual(b.tolist(), b_init.tolist())\n\n    # ... and the provided values become the new cached weights.\n    w_cached, b_cached = layer.weights\n    self.assertEqual(w.tolist(), w_cached.tolist())\n    self.assertEqual(b.tolist(), b_cached.tolist())\n\n  def test_separate_instances_have_separate_weights(self):\n    # Two dense layer instances: each will get its own initial weights (w, b).\n    model = tl.Serial(tl.Dense(5), tl.Dense(5))\n\n    sample_input = np.array([1, 2, 3, 4, 5])\n    _, _ = model.init(shapes.signature(sample_input))\n    weights_0 = model.sublayers[0].weights\n    weights_1 = model.sublayers[1].weights\n\n    w0, b0 = weights_0\n    w1, b1 = weights_1\n    self.assertNotEqual(w0.tolist(), w1.tolist())\n    self.assertNotEqual(b0.tolist(), b1.tolist())\n\n  def test_shared_instance_means_shared_weights(self):\n    # Same dense layer instance in two places --> shared weights.\n    layer = tl.Dense(5)\n    model = tl.Serial(layer, layer)\n    sample_input = np.array([1, 2, 3, 4, 5])\n    weights, _ = model.init(shapes.signature(sample_input))\n    self.assertIs(weights[1], tl.EMPTY_WEIGHTS)\n\n  def test_call_no_bias(self):\n    layer = tl.Dense(4, use_bias=False)\n    x = np.array([2, 5, 3])\n    _, _ = layer.init(shapes.signature(x))\n\n    w = np.array([[100, 200, 300, 400],\n                  [10, 10, 10, 10],\n                  [1, 2, 1, 2]])\n    y = layer(x, weights=w)\n    self.assertEqual(y.tolist(), [253, 456, 653, 856])\n\n  def test_new_weights_use_bias(self):\n    layer = tl.Dense(4)\n    x = np.array([1, 2])\n    _, _ = layer.init(shapes.signature(x))\n    self.assertLen(layer.weights, 2)\n    self.assertEqual(layer.weights[0].shape, (2, 4))\n    self.assertEqual(layer.weights[1].shape, (4,))\n\n  def test_new_weights_no_bias(self):\n    layer = tl.Dense(4, use_bias=False)\n    x = np.array([1, 2])\n    _, _ = layer.init(shapes.signature(x))\n    self.assertEqual(layer.weights.shape, (2, 4))\n\n  def test_init_twice_weights_same_shape(self):\n    layer = tl.Dense(4, use_bias=False)\n    x = np.array([1, 2])\n    w1, _ = layer.init(shapes.signature(x))\n    w2, _ = layer.init(shapes.signature(x))\n    self.assertEqual(w1.shape, (2, 4))\n    self.assertEqual(w2.shape, (2, 4))\n\n\nclass EmbeddingTest(absltest.TestCase):\n\n  def test_forward(self):\n    layer = tl.Embedding(3, 10)  # d_feature=3, vocab_size=10\n    _, _ = layer.init(None)  # Embedding init doesn\'t use input signature.\n    x = np.array([2, 3, 5, 3, 2])\n    y = layer(x)\n    self.assertEqual(y.shape, (5, 3))\n\n    # For distinct in-domain token ids, resulting vectors should be distinct.\n    self.assertNotEqual(y[0].tolist(), y[1].tolist())\n    self.assertNotEqual(y[0].tolist(), y[2].tolist())\n    self.assertNotEqual(y[1].tolist(), y[2].tolist())\n\n    # For repeats of a token id, resulting vectors should match.\n    self.assertEqual(y[0].tolist(), y[4].tolist())\n    self.assertEqual(y[1].tolist(), y[3].tolist())\n\n  def test_negative_inputs_clip_to_zero(self):\n    layer = tl.Embedding(3, 10)\n    _, _ = layer.init(None)\n    x = np.array([0, 2, 3, -2, -3])\n    y = layer(x)\n    self.assertNotEqual(y[0].tolist(), y[1].tolist())\n    self.assertNotEqual(y[0].tolist(), y[2].tolist())\n    self.assertEqual(y[0].tolist(), y[3].tolist())\n    self.assertEqual(y[0].tolist(), y[4].tolist())\n\n  def test_large_inputs_clip_to_upper_bound(self):\n    layer = tl.Embedding(3, 10)\n    _, _ = layer.init(None)\n    x = np.array([2, 3, 9, 10, 20])\n    y = layer(x)\n\n    # vocab_size of 10 means max valid token id is 9.\n    self.assertNotEqual(y[2].tolist(), y[0].tolist())\n    self.assertNotEqual(y[2].tolist(), y[1].tolist())\n    self.assertEqual(y[2].tolist(), y[3].tolist())\n    self.assertEqual(y[2].tolist(), y[4].tolist())\n\n  def test_new_weights(self):\n    layer = tl.Embedding(5, 20)\n    _, _ = layer.init(None)\n\n    # Default weights sampled from Gaussian, mu = 0, sigma = 1.\n    w = layer.new_weights(None)\n    self.assertEqual(w.shape, (20, 5))\n    self.assertLess(np.abs(np.mean(w)), .4)  # .4 is 4 sigma deviation\n\n  def test_explicit_kernel_initializer(self):\n    def f(shape, rng):\n      del rng\n      n_elements = np.prod(shape)\n      return np.arange(n_elements).reshape(shape)\n\n    layer = tl.Embedding(2, 5, kernel_initializer=f)\n    _, _ = layer.init(None)\n    x = np.array([0, 1, 2, 3, 4])\n    y = layer(x)\n    self.assertEqual(y.tolist(), [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]])\n\n\nclass DropoutTest(absltest.TestCase):\n\n  def test_call_in_train_mode(self):\n    layer = tl.Dropout(rate=0.1, mode=\'train\')\n    x = np.ones((2, 5, 1000))  # 10,000 values\n    y = layer(x)\n    self.assertEqual(y.shape, (2, 5, 1000))\n\n    # Dropout is stochastic; test it nonflakily at 4 sigmas (.99994).\n    n_remaining = np.count_nonzero(y)\n    mu_of_remaining = 9000  # N * q:  10000 * .9\n    sigma_of_remaining = 30  # sqrt(N * p * q):  sqrt(10000 * .1 * .9)\n    self.assertLess(np.abs(n_remaining - mu_of_remaining),\n                    4 * sigma_of_remaining)\n\n  def test_call_in_eval_mode_does_no_dropout(self):\n    layer = tl.Dropout(rate=0.1, mode=\'eval\')\n    x = np.ones((2, 5, 1000))\n    y = layer(x)\n    self.assertEqual(np.count_nonzero(y), 10_000)\n\n  def test_new_weights(self):\n    layer = tl.Dropout(rate=0.1, mode=\'train\')\n    w = layer.new_weights(None)\n    self.assertEmpty(w)\n\n\nclass FlattenTest(absltest.TestCase):\n\n  def test_keep_default(self):\n    layer = tl.Flatten()\n    x = np.ones((1, 2, 3, 4, 5))\n    y = layer(x)\n    # Default is leave first axis untouched, flatten the rest.\n    self.assertEqual(y.shape, (1, 2 * 3 * 4 * 5))\n\n  def test_keep_3(self):\n    layer = tl.Flatten(n_axes_to_keep=3)\n    x = np.ones((1, 2, 3, 4, 5))\n    y = layer(x)\n    self.assertEqual(y.shape, (1, 2, 3, 4 * 5))\n\n  def test_keep_max_number(self):\n    layer = tl.Flatten(n_axes_to_keep=4)\n    x = np.ones((1, 2, 3, 4, 5))\n    y = layer(x)\n    self.assertEqual(y.shape, (1, 2, 3, 4, 5))\n\n  def test_keep_too_many_raises_error(self):\n    layer = tl.Flatten(n_axes_to_keep=5)\n    with self.assertRaises(tl.LayerError):\n      x = np.ones((1, 2, 3, 4, 5))\n      _ = layer(x)\n\n\nclass LogGaussianTest(absltest.TestCase):\n  # TODO(jonni): Find a more fitting home for this test.\n\n  def test_log_gaussian_pdf(self):\n    x = np.zeros((2, 5), dtype=np.float32)\n    mu = x\n    dsigma = np.eye(5)[None, :, :]\n    sigma = np.concatenate([dsigma, 2*dsigma], axis=0)\n    prob = tl.log_gaussian_pdf(x, mu, sigma)\n    self.assertEqual(prob.shape, (2,))\n    self.assertEqual(int(prob[0]), -4)\n    self.assertEqual(int(prob[1]), -6)\n\n  def test_log_gaussian_diag_pdf(self):\n    x = np.zeros((2, 5), dtype=np.float32)\n    mu = x\n    sigma = np.ones((5,))[None, :]\n    sigma = np.concatenate([sigma, 2*sigma], axis=0)\n    prob = tl.log_gaussian_diag_pdf(x, mu, sigma)\n    self.assertEqual(prob.shape, (2,))\n    self.assertEqual(int(prob[0]), -4)\n    self.assertEqual(int(prob[1]), -6)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/layers/initializers.py,19,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Trax initializers.""""""\n\nfrom absl import logging\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\nfrom trax.math import numpy as jnp\nfrom trax.math import random\n\n\ndef _GetFans(shape, out_dim=-1, in_dim=-2):\n  """"""Get the fan-in and fan-out sizes for the given shape and dims.""""""\n  # Temporary fix until numpy.delete supports negative indices.\n  if out_dim < 0:\n    out_dim += len(shape)\n  if in_dim < 0:\n    in_dim += len(shape)\n\n  receptive_field = jnp.prod(np.delete(shape, [in_dim, out_dim]))\n  if len(shape) >= 2:\n    fan_in, fan_out = shape[in_dim], shape[out_dim]\n  elif len(shape) == 1:\n    fan_in = shape[0]\n    fan_out = shape[0]\n  else:\n    fan_in = 1.\n    fan_out = 1.\n    fan_in *= receptive_field\n    fan_out *= receptive_field\n  return fan_in, fan_out\n\n\ndef InitializerFromFile(path):\n  """"""Loads parameters from .npy file.""""""\n\n  def Initializer(shape, rng):\n    del rng\n    logging.info(\'Loading pretrained embeddings from %s\', path)\n    with tf.io.gfile.GFile(path, \'rb\') as f:\n      parameters = jnp.load(f)\n    assert jnp.shape(parameters) == shape, (\n        \'Expected shape %s, got %s\' % (shape, jnp.shape(parameters)))\n    return parameters\n\n  return Initializer\n\n\ndef _PureShape(shape):\n  """"""Make sure shape does not contain int tensors by calling int().""""""\n  return [int(x) for x in shape]\n\n\ndef RandomNormalInitializer(stddev=1e-2):\n  """"""Returns an initializer for random normal coefficients.""""""\n  return lambda shape, rng: (stddev * random.normal(  # pylint: disable=g-long-lambda\n      rng, _PureShape(shape)).astype(\'float32\'))\n\n\ndef RandomUniformInitializer(lim=1.0):\n  """"""Returns an initializer for random uniform coefficients.""""""\n  # Make sure shape does not contain int tensors by calling int() below.\n  return lambda shape, rng: random.uniform(  # pylint: disable=g-long-lambda\n      rng, _PureShape(shape), jnp.float32, -lim, lim)\n\n\ndef ScaledInitializer(out_dim, in_dim, scale, mode, distribution):\n  """"""Returns an initializer that adjusts its scale based on weight shapes.""""""\n  if scale <= 0.:\n    raise ValueError(\'scale must be positive float, {} given\'.format(scale))\n  if mode not in {\'fan_in\', \'fan_out\', \'fan_avg\'}:\n    raise ValueError(\n        \'Invalid mode argument:, {}, must be either fan_in, fan_out or fan_avg\'\n        .format(mode))\n\n  def Init(shape, rng):\n    """"""Returns random values for initializing weights of the given `shape`.""""""\n    shape = _PureShape(shape)\n    fan_in, fan_out = _GetFans(shape, out_dim, in_dim)\n    gain = scale\n    if mode == \'fan_in\':\n      gain /= fan_in\n    elif mode == \'fan_out\':\n      gain /= fan_out\n    elif mode == \'fan_avg\':\n      gain /= (fan_in + fan_out) / 2\n    if distribution == \'truncated_normal\':\n      # constant from scipy.stats.truncnorm.std(a=-2, b=2, loc=0., scale=1.)\n      stddev = jnp.sqrt(gain) / .87962566103423978\n      new_weights = random.truncated_normal(rng, -2, 2, shape) * stddev\n      return new_weights.astype(\'float32\')\n    elif distribution == \'normal\':\n      new_weights = random.normal(rng, shape) * jnp.sqrt(gain)\n      return new_weights.astype(\'float32\')\n    elif distribution == \'uniform\':\n      lim = jnp.sqrt(3. * gain)\n      return random.uniform(rng, shape, jnp.float32, -lim, lim)\n    else:\n      raise ValueError(\'invalid distribution for ScaleInitializer\')\n\n  return Init\n\n\ndef GlorotNormalInitializer(out_dim=-1, in_dim=-2, scale=1.):\n  """"""Returns an initializer for random Glorot-scaled coefficients.""""""\n  return ScaledInitializer(out_dim, in_dim, scale, \'fan_avg\', \'normal\')\n\n\ndef GlorotUniformInitializer(out_dim=-1, in_dim=-2, scale=1.):\n  """"""Returns an initializer for random uniform Glorot-scaled coefficients.""""""\n  return ScaledInitializer(out_dim, in_dim, scale, \'fan_avg\', \'uniform\')\n\n\ndef LeCunNormalInitializer(out_dim=-1, in_dim=-2, scale=1.):\n  """"""Returns an initializer for random LeCun-scaled coefficients.""""""\n  return ScaledInitializer(out_dim, in_dim, scale, \'fan_in\', \'normal\')\n\n\ndef LeCunUniformInitializer(out_dim=-1, in_dim=-2, scale=1.):\n  """"""Returns an initializer for random uniform LeCun-scaled coefficients.""""""\n  return ScaledInitializer(out_dim, in_dim, scale, \'fan_in\', \'uniform\')\n\n\ndef KaimingNormalInitializer(out_dim=-1, in_dim=-2, param=0.):\n  """"""Returns an initializer for random Kaiming-scaled coefficients.""""""\n  return ScaledInitializer(\n      out_dim, in_dim, 2.0 / jnp.sqrt(1 + param**2), \'fan_in\', \'normal\')\n\n\ndef KaimingUniformInitializer(out_dim=-1, in_dim=-2, param=0.):\n  """"""Returns an initializer for random uniform Kaiming-scaled coefficients.""""""\n  return ScaledInitializer(\n      out_dim, in_dim, 2.0 / jnp.sqrt(1 + param**2), \'fan_in\', \'uniform\')\n\n\ndef OrthogonalInitializer(stddev=1.0):\n  """"""Returns an orthogonal initializer.""""""\n  def Init(shape, rng):\n    """"""Returns orthogonalized random normal values with the given `shape`.""""""\n    # Have at least 2 elements in shape.\n    cur_shape = list(shape)\n    while len(cur_shape) < 2:\n      cur_shape = [1] + cur_shape\n\n    # Flatten the input shape with the last dimension remaining.\n    n_rows = 1\n    for dim in cur_shape[:-1]:\n      n_rows *= dim\n    n_cols = cur_shape[-1]\n    flat_shape = (n_cols, n_rows) if n_rows < n_cols else (n_rows, n_cols)\n\n    # Generate a random matrix\n    a = random.normal(rng, flat_shape, dtype=jnp.float32)\n\n    # Compute the qr factorization\n    q, r = jnp.linalg.qr(a)\n\n    # Make Q uniform\n    d = jnp.diag(r)\n    q *= jnp.sign(d)\n\n    # Transpose and reshape back q if needed.\n    if n_rows < n_cols:\n      q = jnp.transpose(q)\n    q = jnp.reshape(q, shape)\n\n    # Return scaled as requested.\n    return stddev * q\n\n  return Init\n\n\ndef AtariConvInit(kernel_shape, rng, dtype=jnp.float32):\n  """"""The standard init for Conv laters and Atari.""""""\n  filter_height, filter_width, fan_in, _ = kernel_shape\n  std = 1 / jnp.sqrt(fan_in * filter_height * filter_width)\n  return random.uniform(rng, kernel_shape, dtype, minval=-std, maxval=std)\n'"
trax/layers/initializers_test.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for initializers.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\n\nfrom trax import math\nfrom trax import test_utils\nimport trax.layers as tl\n\n\nINPUT_SHAPE = (5, 7, 20)\n\n\ndef rng():  # Can\'t be a constant, because JAX has to init itself in main first.\n  return math.random.get_prng(0)\n\n\nclass InitializersTest(absltest.TestCase):\n\n  def test_random_normal(self):\n    f = tl.RandomNormalInitializer()\n    init_value = f(INPUT_SHAPE, rng())\n    self.assertEqual(init_value.shape, INPUT_SHAPE)\n\n  def test_lecun_uniform(self):\n    f = tl.LeCunUniformInitializer()\n    init_value = f(INPUT_SHAPE, rng())\n    self.assertEqual(init_value.shape, INPUT_SHAPE)\n\n  def test_random_uniform(self):\n    f = tl.RandomUniformInitializer()\n    init_value = f(INPUT_SHAPE, rng())\n    self.assertEqual(init_value.shape, INPUT_SHAPE)\n\n  def test_glorot_normal(self):\n    f = tl.GlorotNormalInitializer()\n    init_value = f(INPUT_SHAPE, rng())\n    self.assertEqual(init_value.shape, INPUT_SHAPE)\n\n  def test_glorot_uniform(self):\n    f = tl.GlorotUniformInitializer()\n    init_value = f(INPUT_SHAPE, rng())\n    self.assertEqual(init_value.shape, INPUT_SHAPE)\n\n  def test_lecun_normal(self):\n    f = tl.LeCunNormalInitializer()\n    init_value = f(INPUT_SHAPE, rng())\n    self.assertEqual(init_value.shape, INPUT_SHAPE)\n\n  def test_kaiming_normal(self):\n    f = tl.KaimingNormalInitializer()\n    init_value = f(INPUT_SHAPE, rng())\n    self.assertEqual(init_value.shape, INPUT_SHAPE)\n\n  def test_kaiming_uniform(self):\n    f = tl.KaimingUniformInitializer()\n    init_value = f(INPUT_SHAPE, rng())\n    self.assertEqual(init_value.shape, INPUT_SHAPE)\n\n  def test_orthogonal(self):\n    f = tl.OrthogonalInitializer()\n    init_value = f(INPUT_SHAPE, rng())\n    self.assertEqual(init_value.shape, INPUT_SHAPE)\n\n  def test_from_file(self):\n    params = np.array([[0.0, 0.1], [0.2, 0.3], [0.4, 0.5]])\n    # `create_tempfile` needs access to --test_tmpdir, however in the OSS world\n    # pytest doesn\'t run `absltest.main`, so we need to manually parse the flags\n    test_utils.ensure_flag(\'test_tmpdir\')\n    filename = self.create_tempfile(\'params.npy\').full_path\n    with open(filename, \'wb\') as f:\n      np.save(f, params)\n    f = tl.InitializerFromFile(filename)\n    init_value = f(params.shape, rng())\n    self.assertEqual(tl.to_list(init_value), tl.to_list(params))\n    # self.assertEqual(\'%s\' % init_value, \'%s\' % params)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/layers/metrics.py,12,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Trax metrics layers.\n\nTrax computes metrics (loss functions and evaluation metrics) using layers.\nA metrics layer takes 2 or 3 batch inputs:\n\n  - output values (vectors)\n  - target values (vectors or scalars)\n  - weights [optional]\n\nand gives a single scalar as output. Trax reduces batch values to a scalar by\ntaking the weighted (and often also masked) mean of those values:\n\n  - `L2Loss`: weighted masked mean of L2 of (prediction_vector - target_vector)\n\n  - `AccuracyScalar`: weighted masked mean of category predictions\n    (argmax(prediction_vector) vs. target_category)\n\n  - `CrossEntropyLoss`: weighted masked mean of pairwise cross entropy of\n    (prediction_vector, target_vector)\n\n\nTODO(jonni): Explain masks and weighting.\n""""""\n\nimport jax\n\nfrom trax import math\nfrom trax import shapes\nfrom trax.layers import combinators as cb\nfrom trax.layers import core\nfrom trax.layers.base import Fn\nfrom trax.math import numpy as np\n\n\ndef L2Loss():\n  def f(y_hat, y, mask):  # pylint: disable=invalid-name\n    shapes.assert_same_shape(y_hat, y)\n    shapes.assert_same_shape(y, mask)\n    l2 = mask * (y_hat - y)**2\n    return np.sum(l2) / np.sum(mask)\n  return Fn(\'L2Loss\', f)\n\n\ndef AccuracyScalar():\n  """"""Computes weighted masked mean of category prediction accuracy.""""""\n  return _WeightedMaskedMean(_Accuracy())\n\n\ndef SequenceAccuracyScalar():\n  """"""Computes weighted masked mean of sequence prediction accuracy.""""""\n  return _WeightedMaskedMean(_Accuracy(),\n                             final_layer_override=_WeightedSequenceMean())\n\n\ndef CrossEntropyLoss():\n  """"""Computes weighted masked mean of prediction-target cross entropies.""""""\n  return _WeightedMaskedMean(_CrossEntropy())\n\n\ndef CrossEntropySum():\n  """"""Computes weighted masked sum of prediction-target cross entropies.""""""\n  return _WeightedMaskedMean(_CrossEntropy(),\n                             final_layer_override=WeightedSum())\n\n\ndef SumOfWeights():\n  """"""Returns a layer to compute sum of weights of all non-masked elements.""""""\n  return cb.Serial(\n      cb.Drop(),  # Drop inputs.\n      cb.Drop(),  # Drop targets.\n      core.Sum(axis=None)  # Sum weights.\n  )\n# pylint: enable=no-value-for-parameter\n\n\ndef _Accuracy(axis=-1):\n  """"""Returns a layer to score matches of predicted versus target categories.""""""\n  def f(y_hat, target_category):  # pylint: disable=invalid-name\n    predicted_category = np.argmax(y_hat, axis=axis)\n    # TODO(pkozakowski): This assertion breaks some tests. Fix and uncomment.\n    # shapes.assert_same_shape(predicted_category, target_category)\n    return np.equal(predicted_category, target_category).astype(np.float32)\n  return Fn(\'_Accuracy\', f)\n\n\ndef _CrossEntropy():\n  """"""Returns a layer to compute prediction-target cross entropies.""""""\n  def f(y_hat, target_category):  # pylint: disable=invalid-name\n    # TODO(pkozakowski): This assertion breaks some tests. Fix and uncomment.\n    # shapes.assert_shape_equals(target_category, y_hat.shape[:-1])\n    return -1.0 * np.sum(y_hat * one_hot(target_category, y_hat.shape[-1]),\n                         axis=-1)\n  return Fn(\'_CrossEntropy\', f)\n\n\ndef _WeightedMean():\n  """"""Returns a layer to compute weighted mean over all values in the input.""""""\n  def f(values, weights):  # pylint: disable=invalid-name\n    return np.sum(values * weights) / np.sum(weights)\n  return Fn(\'_WeightedMean\', f)\n\n\ndef WeightedSum():\n  """"""Returns a layer to compute weighted sum over all values in the input.""""""\n  def f(values, weights):  # pylint: disable=invalid-name\n    return np.sum(values * weights)\n  return Fn(\'WeightedSum\', f)\n\n\ndef _WeightedSequenceMean():\n  """"""Returns a layer to compute weighted seqeunce accuracy mean.""""""\n  def f(values, weights):  # pylint: disable=invalid-name\n    # This function assumes weights are 0 or 1.\n    # Then compute 1: not-correct, 0: correct or masked\n    not_correct = (1.0 - values) * weights\n    axis_to_sum = list(range(1, len(not_correct.shape)))\n    # Summing not-correct on all axes but batch. We\'re summing 0s and 1s,\n    # so the sum is 0 if it\'s all 0 and >=1 in all other cases.\n    not_correct_seq = np.sum(not_correct, axis=axis_to_sum)\n    # Sequence is correct if not_correct_seq is 0, reverting here.\n    correct_seq = 1.0 - np.minimum(1.0, not_correct_seq)\n    return np.mean(correct_seq)  # Mean over batch.\n  return Fn(\'_WeightedSequenceMean\', f)\n\n\n# pylint: disable=no-value-for-parameter\ndef _WeightedMaskedMean(metric_layer, final_layer_override=None):\n  """"""Computes weighted masked mean of metric_layer(predictions, targets).""""""\n  final_layer = final_layer_override or _WeightedMean()  # For sequence acc.\n  return cb.Serial(\n      metric_layer,\n      final_layer\n  )\n# pylint: enable=no-value-for-parameter\n\n\n# TODO(jonni): Figure out the right name and home for this function.\ndef one_hot(x, n_categories, dtype=np.float32):  # pylint: disable=invalid-name\n  """"""Makes a one-hot array (n+1 dims) from an int-categorical array (n dims).""""""\n  indices_less_than_n = np.arange(n_categories)\n  if math.backend_name() == \'jax\':\n    # Work around a jax broadcasting issue.\n    indices_less_than_n = jax.lax.tie_in(x, indices_less_than_n)\n  return np.array(x[..., np.newaxis] == indices_less_than_n, dtype)\n'"
trax/layers/metrics_test.py,37,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for metrics layers.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\n\nfrom trax import shapes\nimport trax.layers as tl\nfrom trax.layers import metrics\n\n\nclass MetricsTest(absltest.TestCase):\n\n  def test_cross_entropy(self):\n    layer = metrics._CrossEntropy()\n    xs = [np.ones((9, 4, 4, 20)),\n          np.ones((9, 4, 4))]\n    y = layer(xs)\n    self.assertEqual(y.shape, (9, 4, 4))\n\n  def test_accuracy(self):\n    layer = metrics._Accuracy()\n    xs = [np.ones((9, 4, 4, 20)),\n          np.ones((9, 4, 4))]\n    y = layer(xs)\n    self.assertEqual(y.shape, (9, 4, 4))\n\n  def test_weighted_mean_shape(self):\n    layer = metrics._WeightedMean()\n    xs = [np.ones((9, 4, 4, 20)),\n          np.ones((9, 4, 4, 20))]\n    y = layer(xs)\n    self.assertEqual(y.shape, ())\n\n  def test_weighted_mean_semantics(self):\n    layer = metrics._WeightedMean()\n    sample_input = np.ones((3,))\n    sample_weights = np.ones((3,))\n    layer.init(shapes.signature([sample_input, sample_weights]))\n\n    x = np.array([1., 2., 3.])\n    weights = np.array([1., 1., 1.])\n    mean = layer((x, weights))\n    np.testing.assert_allclose(mean, 2.)\n\n    weights = np.array([0., 0., 1.])\n    mean = layer((x, weights))\n    np.testing.assert_allclose(mean, 3.)\n\n    weights = np.array([1., 0., 0.])\n    mean = layer((x, weights))\n    np.testing.assert_allclose(mean, 1.)\n\n  def test_weighted_sequence_mean_semantics(self):\n    layer = metrics._WeightedSequenceMean()\n    sample_input = np.ones((2, 3))\n    sample_weights = np.ones((3,))\n    full_signature = shapes.signature([sample_input, sample_weights])\n    layer.init(full_signature)\n\n    x = np.array([[1., 1., 1.], [1., 1., 0.]])\n    weights = np.array([1., 1., 1.])\n    mean = layer((x, weights))\n    np.testing.assert_allclose(mean, 0.5)\n\n    weights = np.array([1., 1., 0.])\n    mean = layer((x, weights))\n    np.testing.assert_allclose(mean, 1.)\n\n  def test_cross_entropy_loss(self):\n    layer = tl.CrossEntropyLoss()\n    xs = [np.ones((9, 4, 4, 20)),\n          np.ones((9, 4, 4)),\n          np.ones((9, 4, 4))]\n    y = layer(xs)\n    self.assertEqual(y.shape, ())\n\n  def test_accuracy_scalar(self):\n    layer = tl.AccuracyScalar()\n    xs = [np.ones((9, 4, 4, 20)),\n          np.ones((9, 4, 4)),\n          np.ones((9, 4, 4))]\n    y = layer(xs)\n    self.assertEqual(y.shape, ())\n\n  def test_l2_loss(self):\n    layer = tl.L2Loss()\n    sample_input = np.ones((2, 2))\n    sample_target = np.ones((2, 2))\n    sample_weights = np.ones((2, 2))\n    full_signature = shapes.signature([sample_input,\n                                       sample_target,\n                                       sample_weights])\n    layer.init(full_signature)\n\n    x = np.array([[1., 1.], [1., 1.]])\n    target = np.array([[1., 1.], [1., 0.]])\n    weights = np.array([[1., 1.], [1., 0.]])\n    loss = layer((x, target, weights))\n    np.testing.assert_allclose(loss, 0.0)\n\n    weights = np.array([[1., 0.], [0., 1.]])\n    loss = layer((x, target, weights))\n    np.testing.assert_allclose(loss, 0.5)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/layers/normalization.py,26,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Trax normalization layers.""""""\n\nfrom trax.layers import base\nfrom trax.math import numpy as jnp\n\n\nclass BatchNorm(base.Layer):\n  """"""Batch normalization.""""""\n\n  def __init__(self, axis=(0, 1, 2), epsilon=1e-5, center=True, scale=True,\n               momentum=0.999, mode=\'train\'):\n    super(BatchNorm, self).__init__()\n    self._axis = axis\n    self._epsilon = epsilon\n    self._center = center\n    self._scale = scale\n    self._momentum = momentum\n    self._mode = mode\n\n  def forward(self, x, weights):\n    """"""Computes batch normalization as part of a forward pass in the model.""""""\n    running_mean, running_var, n_batches = self.state\n    if self._mode == \'train\':\n      n_batches += 1\n      mean, var = self._fast_mean_and_variance(x)\n      running_mean = self._exponential_smoothing(mean, running_mean)\n      running_var = self._exponential_smoothing(var, running_var)\n      self.state = (running_mean, running_var, n_batches)\n    else:\n      mean = running_mean\n      var = running_var\n\n    z = self._z_score(x, mean, var)\n    beta, gamma = self._beta_gamma_with_correct_axes(x, weights)\n\n    # Return the z rescaled by the parameters if requested.\n    if self._center and self._scale:\n      output = gamma * z + beta\n    elif self._center:\n      output = z + beta\n    elif self._scale:\n      output = gamma * z\n    else:\n      output = z\n    if output.dtype != x.dtype:\n      raise TypeError(f\'The dtype of the output ({output.dtype}) of batch \'\n                      f\'norm is not the same as the input ({x.dtype}). \'\n                      f\'Batch norm should not change the dtype.\')\n    return output\n\n  def new_weights(self, input_signature):\n    """"""Helper to initialize batch norm weights.""""""\n    axis = self._axis\n    axis = (axis,) if jnp.isscalar(axis) else axis\n    input_shape = input_signature.shape\n    shape = tuple(d for i, d in enumerate(input_shape) if i not in axis)\n    # TODO(jonni): Should beta and gamma match the dtype in the input signature?\n    beta = jnp.zeros(shape, dtype=\'float32\') if self._center else ()\n    gamma = jnp.ones(shape, dtype=\'float32\') if self._scale else ()\n    def get_stats_axis(i, d):\n      if i in axis:\n        return 1\n      else:\n        return d\n    stats_shape = tuple(get_stats_axis(i, d) for i, d in enumerate(input_shape))\n    running_mean = jnp.zeros(stats_shape, dtype=jnp.float32)\n    running_var = jnp.ones(stats_shape, dtype=jnp.float32)\n    n_batches = jnp.zeros((), dtype=jnp.int64)\n    weights = (beta, gamma)\n    self.state = (running_mean, running_var, n_batches)\n    return weights\n\n  def _fast_mean_and_variance(self, x):\n    mean = jnp.mean(x, self._axis, keepdims=True)\n    # Fast but less numerically-stable variance calculation than jnp.var.\n    m1 = jnp.mean(x**2, self._axis, keepdims=True)\n    variance = m1 - mean**2\n    return mean, variance\n\n  def _exponential_smoothing(self, new, old):\n    smoothed_value = self._momentum * old + (1 - self._momentum) * new\n    return smoothed_value.astype(old.dtype)\n\n  def _z_score(self, x, mean, variance):\n    mu = mean.astype(x.dtype)\n    sigma = jnp.sqrt(variance + self._epsilon).astype(x.dtype)\n    return (x - mu) / sigma\n\n  def _beta_gamma_with_correct_axes(self, x, weights):\n    # Expand the parameters to have the right axes.\n    beta, gamma = weights\n    # TODO(phawkins): jnp.expand_dims should accept an axis tuple.\n    # (https://github.com/numpy/numpy/issues/12290)\n    ed = tuple(None if i in self._axis else slice(None)\n               for i in range(jnp.ndim(x)))\n    beta = beta[ed]\n    gamma = gamma[ed]\n    return beta, gamma\n\n\nclass LayerNorm(base.Layer):\n  """"""Layer normalization.""""""\n\n  def __init__(self, epsilon=1e-6):\n    super().__init__()\n    self._epsilon = epsilon\n\n  def forward(self, x, weights):\n    scale, bias = weights\n    mean = jnp.mean(x, axis=-1, keepdims=True)\n    sub = x - mean\n    variance = jnp.mean(sub * sub, axis=-1, keepdims=True)\n    norm_inputs = sub / jnp.sqrt(variance + self._epsilon)\n    return norm_inputs * scale + bias\n\n  def new_weights(self, input_signature):\n    features = input_signature.shape[-1]\n    scale = jnp.ones(features, dtype=input_signature.dtype)\n    bias = jnp.zeros(features, dtype=input_signature.dtype)\n    return scale, bias\n\n\nclass FilterResponseNorm(base.Layer):\n  """"""Filter Response Normalization layer without Threshold Linear Unit.\n\n  c.f. https://arxiv.org/pdf/1911.09737.pdf\n  """"""\n\n  def __init__(self,\n               mode=None,\n               learn_epsilon=False,\n               init_epsilon=1e-6,\n               init_learnt_epsilon=1e-4):\n    super(FilterResponseNorm, self).__init__()\n\n    del mode\n\n    # If we learn epsilon then epsilon = init_epsilon + |learnt_value|\n    # where learnt_value is initialized to init_learnt_epsilon.\n    # If learn_epsilon is false then epsilon is just init_epsilon.\n    #\n    # NOTE: I (afrozm) haven\'t been able to train with `learn_epsilon = True`.\n    self._learn_epsilon = learn_epsilon\n\n    # TODO(jonni): Replace asserts with ValueError.\n    assert init_epsilon > 0\n    assert init_learnt_epsilon > 0\n\n    self._init_epsilon = jnp.array(init_epsilon, dtype=jnp.float32)\n    self._init_learnt_epsilon = jnp.array(init_learnt_epsilon,\n                                          dtype=jnp.float32)\n\n  def forward(self, inputs, weights):\n    gamma, beta, epsilon_l = weights\n\n    epsilon = self._init_epsilon\n    if epsilon_l is not base.EMPTY_WEIGHTS:\n      epsilon += jnp.abs(epsilon_l[0])\n\n    # Omit B and C\n    axis = tuple(range(1, len(jnp.shape(inputs)) - 1))\n    # (B, 1, 1, C)\n    nu2 = jnp.mean(inputs**2, axis=axis, keepdims=True)\n    # (B, W, H, C)\n    xhat = inputs / jnp.sqrt(nu2 + epsilon)\n\n    return gamma * xhat + beta\n\n  def new_weights(self, input_signature):\n    # Usually (B, W, H, C)\n    shape = input_signature.shape\n    num_channels = shape[-1]\n\n    gamma = jnp.ones((num_channels,), dtype=jnp.float32)\n    beta = jnp.zeros((num_channels,), dtype=jnp.float32)\n\n    epsilon_l = base.EMPTY_WEIGHTS\n    if self._learn_epsilon:\n      epsilon_l = (self._init_learnt_epsilon,)\n\n    return gamma, beta, epsilon_l\n'"
trax/layers/normalization_test.py,20,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for normalization layers.""""""\n\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\nimport numpy as np\n\nfrom trax import math\nfrom trax import shapes\nimport trax.layers as tl\n\n\nclass BatchNormTest(parameterized.TestCase):\n\n  def test_forward_shape(self):\n    layer = tl.BatchNorm()\n    x = np.ones((30, 20, 70)).astype(np.float32)\n    _, _ = layer.init(shapes.signature(x))\n    y = layer(x)\n    self.assertEqual(y.shape, x.shape)\n\n  @parameterized.named_parameters(\n      (\'jax32\', \'jax\', np.float32),\n      (\'tf32\', \'tf\', np.float32),\n      (\'tf64\', \'tf\', np.float64),\n  )\n  def test_forward_dtype(self, backend, dtype):\n    with math.use_backend(backend):\n      layer = tl.BatchNorm()\n      x = np.ones((3, 2, 7)).astype(dtype)\n      _, _ = layer.init(shapes.signature(x))\n      y = layer(x)\n      self.assertEqual(y.dtype, dtype)\n\n  @parameterized.named_parameters(\n      (\'momentum_999\', .999),\n      (\'momentum_900\', .900),\n      (\'momentum_800\', .800),\n  )\n  def test_forward(self, momentum):\n    layer = tl.BatchNorm(momentum=momentum)\n    x = np.array([[[0, 1, 2, 3],\n                   [4, 5, 6, 7],\n                   [8, 9, 10, 11]],\n                  [[12, 13, 14, 15],\n                   [16, 17, 18, 19],\n                   [20, 21, 22, 23]]]).astype(np.float32)\n    _, _ = layer.init(shapes.signature(x))\n    y = layer(x)\n    running_mean, running_var, n_batches = layer.state\n\n    fraction_old = momentum\n    fraction_new = 1.0 - momentum\n    mean_of_x = 11.5  # mean of range(24)\n    var_of_x = 47.9167  # variance of range(24)\n    np.testing.assert_allclose(\n        running_mean, 0.0 * fraction_old + mean_of_x * fraction_new)\n    np.testing.assert_allclose(\n        running_var, 1.0 * fraction_old + var_of_x * fraction_new, rtol=1e-6)\n    self.assertEqual(n_batches, 1)\n    eps = 1e-5\n    np.testing.assert_allclose(\n        y, (x - mean_of_x) / np.sqrt(var_of_x + eps), rtol=1e-6)\n\n  def test_new_weights_and_state(self):\n    layer = tl.BatchNorm()\n    x = np.ones((3, 2, 7)).astype(np.float32)\n    _, _ = layer.init(shapes.signature(x))\n\n    running_mean, running_var, n_batches = layer.state\n    np.testing.assert_allclose(running_mean, 0.0)\n    np.testing.assert_allclose(running_var, 1.0)\n    self.assertEqual(n_batches, 0)\n\n\nclass LayerNormTest(parameterized.TestCase):\n\n  def test_forward_shape(self):\n    layer = tl.LayerNorm()\n    x = np.ones((3, 2, 7)).astype(np.float32)\n    _, _ = layer.init(shapes.signature(x))\n    y = layer(x)\n    self.assertEqual(y.shape, x.shape)\n\n  @parameterized.named_parameters(\n      (\'jax32\', \'jax\', np.float32),\n      (\'tf32\', \'tf\', np.float32),\n      (\'tf64\', \'tf\', np.float64),\n  )\n  def test_forward_dtype(self, backend, dtype):\n    with math.use_backend(backend):\n      layer = tl.LayerNorm()\n      x = np.ones((3, 2, 7)).astype(dtype)\n      _, _ = layer.init(shapes.signature(x))\n      y = layer(x)\n      self.assertEqual(y.dtype, dtype)\n\n\nclass FilterResponseNormTest(parameterized.TestCase):\n\n  @parameterized.named_parameters(\n      (\'learn_epsilon_false\', False),\n      (\'learn_epsilon_true\', True),\n  )\n  def test_forward_shape(self, learn_epsilon):\n    layer = tl.FilterResponseNorm(learn_epsilon=learn_epsilon)\n\n    B, H, W, C = 64, 5, 7, 3  # pylint: disable=invalid-name\n    x = np.ones((B, H, W, C)).astype(np.float32)\n    _, _ = layer.init(shapes.signature(x))\n    y = layer(x)\n    self.assertEqual(y.shape, x.shape)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/layers/pooling.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Trax pooling layers.""""""\n\nfrom trax import math\nfrom trax.layers.base import Fn\n\n\n# pylint: disable=invalid-name\ndef MaxPool(pool_size=(2, 2), strides=None, padding=\'VALID\'):\n  """"""Reduces each multi-dimensional window to the max of the window\'s values.\n\n  Windows, as specified by `pool_size` and `strides`, involve all axes of an\n  n-dimensional array except the first and last: :math:`(d_1, ..., d_{n-2})`\n  from shape :math:`(d_0, d_1, ..., d_{n-2}, d_{n-1})`.\n\n  Args:\n    pool_size: Shape of window that gets reduced to a single vector value.\n        If the layer inputs are :math:`n`-dimensional arrays, then `pool_size`\n        must be a tuple of length :math:`n-2`.\n    strides: Offsets from the location of one window to the locations of\n        neighboring windows along each axis. If specified, must be a tuple of\n        the same length as `pool_size`. If None, then offsets of 1 along each\n        window axis, :math:`(1, ..., 1)`, will be used.\n    padding: \'VALID\' or \'SAME\'. If \'VALID\', no padding is done, and only\n        full windows get reduced; partial windows are discarded. If \'SAME\',\n        padding is added at array edges as needed to avoid partial windows\n        but does not otherwise affect the selection of max values.\n\n  Returns:\n    N-dimensional array in which each valid (or padded-valid) window position\n    in the input is reduced to / replaced by the max value from that window.\n    An output array has the same number of dimensions as its input, but has\n    fewer elements.\n  """"""\n  layer_name = f\'MaxPool{pool_size}\'.replace(\' \', \'\')\n  def f(x):\n    return math.max_pool(\n        x, pool_size=pool_size, strides=strides, padding=padding)\n  return Fn(layer_name, f)\n\n\ndef SumPool(pool_size=(2, 2), strides=None, padding=\'VALID\'):\n  """"""Reduces each multi-dimensional window to the sum of the window\'s values.\n\n  Windows, as specified by `pool_size` and `strides`, involve all axes of an\n  n-dimensional array except the first and last: :math:`(d_1, ..., d_{n-2})`\n  from shape :math:`(d_0, d_1, ..., d_{n-2}, d_{n-1})`.\n\n  Args:\n    pool_size: Shape of window that gets reduced to a single vector value.\n        If the layer inputs are :math:`n`-dimensional arrays, then `pool_size`\n        must be a tuple of length :math:`n-2`.\n    strides: Offsets from the location of one window to the locations of\n        neighboring windows along each axis. If specified, must be a tuple of\n        the same length as `pool_size`. If None, then offsets of 1 along each\n        window axis, :math:`(1, ..., 1)`, will be used.\n    padding: \'VALID\' or \'SAME\'. If \'VALID\', no padding is done, and only\n        full windows get reduced; partial windows are discarded. If \'SAME\',\n        padding is added at array edges as needed to avoid partial\n        windows but does not otherwise affect the computation of sums.\n\n  Returns:\n    N-dimensional array in which each valid (or padded-valid) window position\n    in the input is reduced to / replaced by the sum of values in that window.\n    An output array has the same number of dimensions as its input, but has\n    fewer elements.\n  """"""\n  layer_name = f\'SumPool{pool_size}\'.replace(\' \', \'\')\n  def f(x):\n    return math.sum_pool(\n        x, pool_size=pool_size, strides=strides, padding=padding)\n  return Fn(layer_name, f)\n\n\ndef AvgPool(pool_size=(2, 2), strides=None, padding=\'VALID\'):\n  """"""Reduces each multi-dimensional window to the mean of the window\'s values.\n\n  Windows, as specified by `pool_size` and `strides`, involve all axes of an\n  n-dimensional array except the first and last: :math:`(d_1, ..., d_{n-2})`\n  from shape :math:`(d_0, d_1, ..., d_{n-2}, d_{n-1})`.\n\n  Args:\n    pool_size: Shape of window that gets reduced to a single vector value.\n        If the layer inputs are :math:`n`-dimensional arrays, then `pool_size`\n        must be a tuple of length :math:`n-2`.\n    strides: Offsets from the location of one window to the locations of\n        neighboring windows along each axis. If specified, must be a tuple of\n        the same length as `pool_size`. If None, then offsets of 1 along each\n        window axis, :math:`(1, ..., 1)`, will be used.\n    padding: \'VALID\' or \'SAME\'. If \'VALID\', no padding is done, and only\n        full windows get reduced; partial windows are discarded. If \'SAME\',\n        padding is added at array edges as needed but is not counted in the\n        computation of averages.\n\n  Returns:\n    N-dimensional array in which each valid (or padded-valid) window position\n    in the input is reduced to / replaced by the mean of values in that window.\n    An output array has the same number of dimensions as its input, but has\n    fewer elements.\n  """"""\n  layer_name = f\'AvgPool{pool_size}\'.replace(\' \', \'\')\n  def f(x):\n    return math.avg_pool(\n        x, pool_size=pool_size, strides=strides, padding=padding)\n  return Fn(layer_name, f)\n'"
trax/layers/pooling_test.py,13,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for conv layers.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\n\nimport trax.layers as tl\n\n\nclass MaxPoolTest(absltest.TestCase):\n\n  def test_forward_shape(self):\n    layer = tl.MaxPool(pool_size=(2, 2), strides=(1, 2))\n    x = np.ones((11, 6, 4, 17))\n    y = layer(x)\n    self.assertEqual(y.shape, (11, 5, 2, 17))\n\n  def test_forward(self):\n    layer = tl.MaxPool(pool_size=(2, 2), strides=(2, 2))\n    x = np.array([[\n        [[1, 2, 3], [4, 5, 6], [10, 20, 30], [40, 50, 60]],\n        [[4, 2, 3], [7, 1, 2], [40, 20, 30], [70, 10, 20]],\n    ]])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [[[[7, 5, 6], [70, 50, 60]]]])\n\n  def test_padding_default(self):\n    layer = tl.MaxPool(pool_size=(3,), strides=(3,))\n\n    # Discard incomplete window at end: [[3, 6], [4, 5]].\n    x = np.array([[\n        [0, 9], [1, 8], [2, 7], [3, 6], [4, 5]\n    ]])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [[[2, 9]]])\n\n  def test_padding_same(self):\n    layer = tl.MaxPool(pool_size=(3,), strides=(3,), padding=\'SAME\')\n\n    # One padding position needed; add at end.\n    x = np.array([[\n        [0, 9], [1, 8], [2, 7], [3, 6], [4, 5]\n    ]])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [[[2, 9], [4, 6]]])\n\n    # Two padding positions needed; add one at end and one at start.\n    x = np.array([[\n        [0, 9], [1, 8], [2, 7], [3, 6]\n    ]])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [[[1, 9], [3, 7]]])\n\n\nclass SumPoolTest(absltest.TestCase):\n\n  def test_forward_shape(self):\n    layer = tl.SumPool(pool_size=(2, 2), strides=(1, 2))\n    x = np.ones((11, 6, 4, 17))\n    y = layer(x)\n    self.assertEqual(y.shape, (11, 5, 2, 17))\n\n  def test_forward(self):\n    layer = tl.SumPool(pool_size=(2, 2), strides=(2, 2))\n    x = np.array([[\n        [[1, 2, 3], [4, 5, 6], [10, 20, 30], [40, 50, 60]],\n        [[4, 2, 3], [7, 1, 2], [40, 20, 30], [70, 10, 20]],\n    ]])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [[[[16, 10, 14], [160, 100, 140]]]])\n\n  def test_padding_same(self):\n    layer = tl.SumPool(pool_size=(3,), strides=(3,), padding=\'SAME\')\n\n    # One padding position needed; add at end.\n    x = np.array([[\n        [0, 9], [1, 8], [2, 7], [3, 6], [4, 5]\n    ]])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [[[3, 24], [7, 11]]])\n\n    # Two padding positions needed; add one at end and one at start.\n    x = np.array([[\n        [0, 9], [1, 8], [2, 7], [3, 6]\n    ]])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [[[1, 17], [5, 13]]])\n\n\nclass AvgPoolTest(absltest.TestCase):\n\n  def test_forward_shape(self):\n    layer = tl.AvgPool(pool_size=(2, 2), strides=(1, 2))\n    x = np.ones((11, 6, 4, 17))\n    y = layer(x)\n    self.assertEqual(y.shape, (11, 5, 2, 17))\n\n  def test_forward(self):\n    layer = tl.AvgPool(pool_size=(2, 2), strides=(2, 2))\n    x = np.array([[\n        [[1, 2, 3], [4, 5, 6], [10, 20, 30], [40, 50, 60]],\n        [[4, 2, 3], [7, 1, 2], [40, 20, 30], [70, 10, 20]],\n    ]])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [[[[4.0, 2.5, 3.5], [40, 25, 35]]]])\n\n  def test_padding_same(self):\n    layer = tl.AvgPool(pool_size=(3,), strides=(3,), padding=\'SAME\')\n\n    # One padding position needed; add at end.\n    x = np.array([[\n        [0, 9], [1, 8], [2, 7], [3, 6], [4, 5]\n    ]])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [[[1, 8], [3.5, 5.5]]])\n\n    # Two padding positions needed; add one at end and one at start.\n    x = np.array([[\n        [0, 9], [1, 8], [2, 7], [3, 6]\n    ]])\n    y = layer(x)\n    self.assertEqual(tl.to_list(y), [[[.5, 8.5], [2.5, 6.5]]])\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/layers/reversible.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Implementations of reversible layers.""""""\n\nfrom trax import math\nfrom trax.layers import base\nfrom trax.layers import combinators as cb\n\n# pylint: disable=protected-access\n_inputs_from_stack = cb._inputs_from_stack\n_outputs_onto_stack = cb._outputs_onto_stack\n# pylint: enable=protected-access\n\n\nclass ReversibleLayer(base.Layer):\n  """"""Reversible Layer.""""""\n\n  def reverse(self, output, weights=(), state=(), new_state=(), rng=None):\n    """"""Reverse this layer: compute input given output.""""""\n    raise NotImplementedError\n\n  def reverse_and_grad(self, output, grad, weights=(), state=(), new_state=(),\n                       rng=None):\n    """"""Backward pass: computes the inverse of a layer and propagates gradients.\n\n    While you may choose to only implement reverse, some layers implement this\n    function directly as computation may be shared between reversing and\n    computing gradients.\n\n    Args:\n      output: Output activations; can be a (possibly nested) tuple.\n      grad: gradient signal (cotangent) computed based on subsequent layers.\n        The structure and shape must match the output.\n      weights: layer weights\n      state: start state\n      new_state: updated state computed by the forward pass\n      rng: Single-use random number generator (JAX PRNG key).\n\n    Returns:\n      A tuple (x, (x_grad, weights_grad)), where x is the reconstructed input,\n      x_grad is the gradient signal for the input, and weights_grad is the\n      gradient signal for the weights.\n    """"""\n    def _do_forward(x, weights):\n      old_state, old_rng = self._state, self._rng\n      self._state, self._rng = state, rng\n      res = self.forward(x, weights)\n      self._state, self._rng = old_state, old_rng\n      return res\n\n    reconstructed_x = self.reverse(output, weights, state, new_state, rng)\n    _, vjpfun = math.vjp(_do_forward, reconstructed_x, weights)\n    x_weights_grad = vjpfun(grad)\n    return reconstructed_x, x_weights_grad\n\n  @property\n  def has_backward(self):\n    return True\n\n  def backward(self, inputs, output, grad, weights, state, new_state, rng):\n    del inputs\n    _, inputs_weights_grad = (\n        self.reverse_and_grad(output, grad, weights, state, new_state, rng))\n    return inputs_weights_grad\n\n\nclass ReversibleSwap(ReversibleLayer):\n  """"""Swap the first two element on the stack.""""""\n\n  def __init__(self):\n    super().__init__(n_in=2, n_out=2)\n\n  def forward(self, inputs, weights):\n    del weights\n    x0, x1 = inputs\n    return x1, x0\n\n  def reverse(self, output, weights=(), state=(), new_state=(), rng=None):\n    del state, new_state, rng\n    # Swap is its own inverse, except that reverse doesn\'t return the state.\n    return self.forward(output, weights)\n\n\nclass ReversibleSerial(ReversibleLayer, cb.Serial):\n  """"""A reversible version of tl.Serial (requires reversible sub-layers).""""""\n\n  def __init__(self, *layers):\n    super().__init__(*layers)\n  # def __init__(self, *layers):  # pylint: disable=super-init-not-called\n  #   cb.Serial.__init__(self, layers)\n\n    # Note that sublayers has already been flattened to remove nested lists.\n    for i, layer in enumerate(self.sublayers):\n      if not isinstance(layer, ReversibleLayer):\n        raise ValueError(\n            \'Sub-layer {} of ReversibleSerial is not reversible: {}\'.format(\n                i, layer))\n\n  def reverse(self, output, weights=(), state=(), new_state=(), rng=None):\n    rngs = (None,) * self._n_layers\n    if rng is not None:\n      rngs = math.random.split(rng, self._n_layers)\n\n    stack = output\n    for layer, p, s, ns, rng in reversed(list(zip(\n        self.sublayers, weights, state, new_state, rngs))):\n      layer_val = _inputs_from_stack(layer, stack, layer.n_out)\n      layer_val = layer.reverse(layer_val, p, s, ns, rng=rng)\n      stack = _outputs_onto_stack(\n          layer, layer_val, stack, layer.n_out, layer.n_in)\n\n    return stack\n\n  def reverse_and_grad(self, output, grad, weights=(), state=(), new_state=(),\n                       rng=None):\n    rngs = (None,) * self._n_layers\n    if rng is not None:\n      rngs = math.random.split(rng, self._n_layers)\n\n    stack = output\n    stack_grad = grad\n    weights_grad = []\n    for layer, p, s, ns, rng in reversed(list(zip(\n        self.sublayers, weights, state, new_state, rngs))):\n      layer_val = _inputs_from_stack(layer, stack, layer.n_out)\n      layer_ct = _inputs_from_stack(layer, stack_grad, layer.n_out)\n      layer_val, layer_ct = layer.reverse_and_grad(\n          layer_val, layer_ct, p, s, ns, rng=rng)\n      layer_ct, p_ct = layer_ct\n      weights_grad.insert(0, p_ct)\n      stack = _outputs_onto_stack(\n          layer, layer_val, stack, layer.n_out, layer.n_in)\n      stack_grad = _outputs_onto_stack(\n          layer, layer_ct, stack_grad, layer.n_out, layer.n_in)\n\n    return stack, (stack_grad, weights_grad)\n'"
trax/layers/reversible_test.py,1,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for reversible layers.""""""\n\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\nimport numpy as np\n\nfrom trax import math\nimport trax.layers as tl\n\n\nBACKENDS = [\'jax\', \'tf\']\n\n\nclass ReversibleLayerTest(parameterized.TestCase):\n\n  @parameterized.named_parameters([(\'_\' + b, b) for b in BACKENDS])\n  def test_reversible_swap(self, backend_name):\n    with math.use_backend(backend_name):\n      layer = tl.ReversibleSwap()\n      xs = [np.array([1, 2]), np.array([10, 20])]\n      ys = layer(xs)\n      self.assertEqual(tl.to_list(ys), [[10, 20], [1, 2]])\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/layers/rnn.py,12,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Implementations of common recurrent neural network cells (RNNs).""""""\n\nfrom trax import math\nfrom trax.layers import activation_fns\nfrom trax.layers import base\nfrom trax.layers import combinators as cb\nfrom trax.layers import convolution\nfrom trax.layers import core\nfrom trax.layers import initializers\nfrom trax.math import numpy as jnp\n\n\nclass LSTMCell(base.Layer):\n  """"""LSTM Cell.\n\n  For a nice overview of the motivation and (i, o, f) gates, see this tutorial:\n  https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n\n  See this paper for a description and detailed study of all gate types:\n  https://arxiv.org/pdf/1503.04069.pdf\n  """"""\n\n  def __init__(self,\n               n_units,\n               forget_bias=1.0,\n               kernel_initializer=initializers.GlorotUniformInitializer(),\n               bias_initializer=initializers.RandomNormalInitializer(1e-6)):\n    super(LSTMCell, self).__init__(n_in=2, n_out=2)\n    self._n_units = n_units\n    self._forget_bias = forget_bias\n    self._kernel_initializer = kernel_initializer\n    self._bias_initializer = bias_initializer\n\n  def forward(self, inputs, weights):\n    x, lstm_state = inputs\n\n    # LSTM state consists of c and h.\n    c, h = jnp.split(lstm_state, 2, axis=-1)\n\n    # Dense layer on the concatenation of x and h.\n    w, b = weights\n    y = jnp.dot(jnp.concatenate([x, h], axis=-1), w) + b\n\n    # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n    i, j, f, o = jnp.split(y, 4, axis=-1)\n\n    new_c = c * math.sigmoid(f) + math.sigmoid(i) * jnp.tanh(j)\n    new_h = jnp.tanh(new_c) * math.sigmoid(o)\n    return new_h, jnp.concatenate([new_c, new_h], axis=-1)\n\n  def new_weights(self, input_signature):\n    # LSTM state last dimension must be twice n_units.\n    assert input_signature[1].shape[-1] == 2 * self._n_units\n    # The dense layer input is the input and half of the lstm state.\n    input_shape = input_signature[0].shape[-1] + self._n_units\n    rng1, rng2 = math.random.split(self.rng, 2)\n    w = self._kernel_initializer((input_shape, 4 * self._n_units), rng1)\n    b = self._bias_initializer((4 * self._n_units,), rng2) + self._forget_bias\n    return (w, b)\n\n\ndef MakeZeroState(depth_multiplier=1):\n  """"""Makes zeros of shape like x but removing the length (axis 1).""""""\n  def f(x):  # pylint: disable=invalid-name\n    assert len(x.shape) == 3, \'Expecting x of shape [batch, length, depth].\'\n    return jnp.zeros((x.shape[0], depth_multiplier * x.shape[-1]),\n                     dtype=jnp.float32)\n  return base.Fn(\'MakeZeroState\', f)\n\n\ndef LSTM(n_units):\n  """"""LSTM running on axis 1.""""""\n  zero_state = MakeZeroState(depth_multiplier=2)  # pylint: disable=no-value-for-parameter\n  return cb.Serial(\n      cb.Branch([], zero_state),\n      cb.Scan(LSTMCell(n_units=n_units), axis=1),\n      cb.Select([0], n_in=2)  # Drop RNN state.\n  )\n\n\nclass GRUCell(base.Layer):\n  """"""Builds a traditional GRU cell with dense internal transformations.\n\n  Gated Recurrent Unit paper: https://arxiv.org/abs/1412.3555\n  """"""\n\n  def __init__(self,\n               n_units,\n               forget_bias=0.0,\n               kernel_initializer=initializers.RandomUniformInitializer(0.01),\n               bias_initializer=initializers.RandomNormalInitializer(1e-6)):\n    super(GRUCell, self).__init__(n_in=2, n_out=2)\n    self._n_units = n_units\n    self._forget_bias = forget_bias\n    self._kernel_initializer = kernel_initializer\n    self._bias_initializer = bias_initializer\n\n  def forward(self, inputs, weights):\n    x, gru_state = inputs\n\n    # Dense layer on the concatenation of x and h.\n    w1, b1, w2, b2 = weights\n    y = jnp.dot(jnp.concatenate([x, gru_state], axis=-1), w1) + b1\n\n    # Update and reset gates.\n    u, r = jnp.split(math.sigmoid(y), 2, axis=-1)\n\n    # Candidate.\n    c = jnp.dot(jnp.concatenate([x, r * gru_state], axis=-1), w2) + b2\n\n    new_gru_state = u * gru_state + (1 - u) * jnp.tanh(c)\n    return new_gru_state, new_gru_state\n\n  def new_weights(self, input_signature):\n    # State last dimension must be n_units.\n    assert input_signature[1].shape[-1] == self._n_units\n    # The dense layer input is the input and half of the GRU state.\n    input_shape = input_signature[0].shape[-1] + self._n_units\n    rng1, rng2, rng3, rng4 = math.random.split(self.rng, 4)\n    w1 = self._kernel_initializer((input_shape, 2 * self._n_units), rng1)\n    b1 = self._bias_initializer((2 * self._n_units,), rng2) + self._forget_bias\n    w2 = self._kernel_initializer((input_shape, self._n_units), rng3)\n    b2 = self._bias_initializer((self._n_units,), rng4)\n    return (w1, b1, w2, b2)\n\n\ndef GRU(n_units):\n  """"""GRU running on axis 1.""""""\n  zero_state = MakeZeroState(depth_multiplier=1)  # pylint: disable=no-value-for-parameter\n  return cb.Serial(\n      cb.Branch([], zero_state),\n      cb.Scan(GRUCell(n_units=n_units), axis=1),\n      cb.Select([0], n_in=2)  # Drop RNN state.\n  )\n\n\ndef ConvGRUCell(n_units, kernel_size=(3, 3)):\n  """"""Builds a convolutional GRU.\n\n  Paper: https://arxiv.org/abs/1511.06432.\n\n  Args:\n    n_units: Number of hidden units\n    kernel_size: Kernel size for convolution\n\n  Returns:\n    A Stax model representing a GRU cell with convolution transforms.\n  """"""\n\n  def BuildConv():\n    return convolution.Conv(\n        filters=n_units, kernel_size=kernel_size, padding=\'SAME\')\n\n  return GeneralGRUCell(\n      candidate_transform=BuildConv,\n      memory_transform_fn=None,\n      gate_nonlinearity=activation_fns.Sigmoid,\n      candidate_nonlinearity=activation_fns.Tanh)\n\n\ndef GeneralGRUCell(candidate_transform,\n                   memory_transform_fn=None,\n                   gate_nonlinearity=activation_fns.Sigmoid,\n                   candidate_nonlinearity=activation_fns.Tanh,\n                   dropout_rate_c=0.1,\n                   sigmoid_bias=0.5):\n  r""""""Parametrized Gated Recurrent Unit (GRU) cell construction.\n\n  GRU update equations for update gate, reset gate, candidate memory, and new\n  state:\n\n  .. math::\n    u_t &= \\sigma(U\' \\times s_{t-1} + B\') \\\\\n    r_t &= \\sigma(U\'\' \\times s_{t-1} + B\'\') \\\\\n    c_t &= \\tanh(U \\times (r_t \\odot s_{t-1}) + B) \\\\\n    s_t &= u_t \\odot s_{t-1} + (1 - u_t) \\odot c_t\n\n  See `combinators.Gate` for details on the gating function.\n\n\n  Args:\n    candidate_transform: Transform to apply inside the Candidate branch. Applied\n      before nonlinearities.\n    memory_transform_fn: Optional transformation on the memory before gating.\n    gate_nonlinearity: Function to use as gate activation; allows trying\n      alternatives to `Sigmoid`, such as `HardSigmoid`.\n    candidate_nonlinearity: Nonlinearity to apply after candidate branch; allows\n      trying alternatives to traditional `Tanh`, such as `HardTanh`.\n    dropout_rate_c: Amount of dropout on the transform (c) gate. Dropout works\n      best in a GRU when applied exclusively to this branch.\n    sigmoid_bias: Constant to add before sigmoid gates. Generally want to start\n      off with a positive bias.\n\n  Returns:\n    A model representing a GRU cell with specified transforms.\n  """"""\n  gate_block = [  # u_t\n      candidate_transform(),\n      _AddSigmoidBias(sigmoid_bias),\n      gate_nonlinearity(),\n  ]\n  reset_block = [  # r_t\n      candidate_transform(),\n      _AddSigmoidBias(sigmoid_bias),  # Want bias to start positive.\n      gate_nonlinearity(),\n  ]\n  candidate_block = [\n      cb.Dup(),\n      reset_block,\n      cb.Multiply(),  # Gate S{t-1} with sigmoid(candidate_transform(S{t-1}))\n      candidate_transform(),  # Final projection + tanh to get Ct\n      candidate_nonlinearity(),  # Candidate gate\n\n      # Only apply dropout on the C gate. Paper reports 0.1 as a good default.\n      core.Dropout(rate=dropout_rate_c)\n  ]\n  memory_transform = memory_transform_fn() if memory_transform_fn else []\n  return cb.Serial(\n      cb.Branch(memory_transform, gate_block, candidate_block),\n      cb.Gate(),\n  )\n\n\ndef InnerSRUCell():\n  """"""The inner (non-parallel) computation of an SRU.""""""\n  def f(cur_x_times_one_minus_f, cur_f, cur_state):  # pylint: disable=invalid-name\n    res = cur_f * cur_state + cur_x_times_one_minus_f\n    return res, res\n  return base.Fn(\'InnerSRUCell\', f, n_out=2)\n\n\ndef SRU(n_units, activation=None):\n  r""""""SRU (Simple Recurrent Unit) layer as in https://arxiv.org/abs/1709.02755.\n\n  As defined in the paper:\n\n  .. math::\n    y_t &= W x_t + B \\quad \\hbox{(include $B$ optionally)} \\\\\n    f_t &= \\sigma(Wf x_t + bf) \\\\\n    r_t &= \\sigma(Wr x_t + br) \\\\\n    c_t &= f_t \\times c_{t-1} + (1 - f_t) \\times y_t \\\\\n    h_t &= r_t \\times \\hbox{activation}(c_t) + (1 - r_t) \\times x_t\n\n  We assume the input is of shape [batch, length, depth] and recurrence\n  happens on the length dimension. This returns a single layer. It\'s best\n  to use at least 2, they say in the paper, except inside a Transformer.\n\n  Args:\n    n_units: output depth of the SRU layer.\n    activation: Optional activation function.\n\n  Returns:\n    The SRU layer.\n  """"""\n  sigmoid_activation = activation_fns.Sigmoid()\n  return cb.Serial(                                         # x\n      cb.Branch(core.Dense(3 * n_units), []),               # r_f_y, x\n      cb.Split(n_items=3),                                  # r, f, y, x\n      cb.Parallel(sigmoid_activation, sigmoid_activation),  # r, f, y, x\n      base.Fn(\'\',\n              lambda r, f, y: (y * (1.0 - f), f, r),    # y * (1 - f), f, r, x\n              n_out=3),\n      cb.Parallel([], [], cb.Branch(MakeZeroState(), [])),\n      cb.Scan(InnerSRUCell(), axis=1),\n      cb.Select([0], n_in=2),                               # act(c), r, x\n      activation or [],\n      base.Fn(\'FinalSRUGate\', lambda c, r, x: c * r + x * (1 - r) * (3**0.5))\n  )\n\n\ndef _AddSigmoidBias(sigmoid_bias):\n  return base.Fn(\'AddSigmoidBias({sigmoid_bias})\',\n                 lambda x: x + sigmoid_bias)\n'"
trax/layers/rnn_test.py,4,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for rnn layers.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\n\nfrom trax import shapes\nimport trax.layers as tl\n\n\nclass RnnTest(absltest.TestCase):\n\n  def test_conv_gru_cell(self):\n    layer = tl.ConvGRUCell(9, kernel_size=(3, 3))\n    x = np.ones((8, 1, 7, 9))\n    _, _ = layer.init(shapes.signature(x))\n    y = layer(x)\n    self.assertEqual(y.shape, x.shape)\n\n  def test_gru_cell(self):\n    layer = tl.GRUCell(9)\n    xs = [np.ones((8, 7, 9)), np.ones((8, 7, 9))]\n    _, _ = layer.init(shapes.signature(xs))\n    ys = layer(xs)\n    self.assertEqual([y.shape for y in ys], [(8, 7, 9), (8, 7, 9)])\n\n  def test_lstm_cell(self):\n    layer = tl.LSTMCell(9)\n    xs = [np.ones((8, 9)), np.ones((8, 18))]\n    _, _ = layer.init(shapes.signature(xs))\n    ys = layer(xs)\n    self.assertEqual([y.shape for y in ys], [(8, 9), (8, 18)])\n\n  def test_sru(self):\n    layer = tl.SRU(7)\n    x = np.ones((8, 9, 7))\n    _, _ = layer.init(shapes.signature(x))\n    y = layer(x)\n    self.assertEqual(y.shape, x.shape)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/math/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Trax math.""""""\n\nfrom trax.math import jax as jax_math\nfrom trax.math import numpy as numpy_math\nfrom trax.math import tf as tf_math\nfrom trax.math.backend import *  # pylint: disable=wildcard-import\nfrom trax.math.jax import nested_map\nfrom trax.math.jax import nested_map_multiarg\nfrom trax.math.jax import nested_stack\nfrom trax.math.jax import nested_zip\nfrom trax.math.jax import tree_flatten\nfrom trax.math.jax import tree_leaves\nfrom trax.math.jax import tree_unflatten\n'"
trax/math/backend.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Trax math: all the primitive functions needed.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport contextlib\n\nimport gin\nfrom trax.math.jax import JAX_BACKEND\nfrom trax.math.numpy import NUMPY_BACKEND\nfrom trax.math.tf import TF_BACKEND\n\n\ndef backend_name():\n  return backend()[\'name\']\n\n\ndef logsumexp(*args, **kwargs):\n  return backend()[\'logsumexp\'](*args, **kwargs)\n\n\ndef expit(*args, **kwargs):\n  return backend()[\'expit\'](*args, **kwargs)\n\n\ndef sigmoid(*args, **kwargs):\n  return backend()[\'expit\'](*args, **kwargs)\n\n\ndef erf(*args, **kwargs):\n  return backend()[\'erf\'](*args, **kwargs)\n\n\ndef conv(*args, **kwargs):\n  return backend()[\'conv\'](*args, **kwargs)\n\n\ndef avg_pool(*args, **kwargs):\n  return backend()[\'avg_pool\'](*args, **kwargs)\n\n\ndef max_pool(*args, **kwargs):\n  return backend()[\'max_pool\'](*args, **kwargs)\n\n\ndef sum_pool(*args, **kwargs):\n  return backend()[\'sum_pool\'](*args, **kwargs)\n\n\ndef scan(*args, **kwargs):\n  return backend()[\'scan\'](*args, **kwargs)\n\n\ndef cond(*args, **kwargs):\n  return backend()[\'cond\'](*args, **kwargs)\n\n\ndef lt(*args, **kwargs):\n  return backend()[\'lt\'](*args, **kwargs)\n\n\ndef stop_gradient(*args, **kwargs):\n  return backend()[\'stop_gradient\'](*args, **kwargs)\n\n\n_disable_jit = False\n\n\ndef disable_jit():\n  global _disable_jit\n  _disable_jit = True\n\n\ndef jit(*args, **kwargs):\n  global _disable_jit\n  if _disable_jit:\n    return args[0]  # jit(f, **unused_now_jit_kwargs) = f\n  return backend()[\'jit\'](*args, **kwargs)\n\n\ndef grad(*args, **kwargs):\n  return backend()[\'grad\'](*args, **kwargs)\n\n\ndef vjp(*args, **kwargs):\n  return backend()[\'vjp\'](*args, **kwargs)\n\n\ndef custom_grad(*args, **kwargs):\n  return backend()[\'custom_grad\'](*args, **kwargs)\n\n\ndef pmap(*args, **kwargs):\n  return backend()[\'pmap\'](*args, **kwargs)\n\n\ndef psum(*args, **kwargs):\n  return backend()[\'psum\'](*args, **kwargs)\n\n\ndef abstract_eval(*args, **kwargs):\n  return backend()[\'abstract_eval\'](*args, **kwargs)\n\n\ndef dataset_as_numpy(*args, **kwargs):\n  return backend()[\'dataset_as_numpy\'](*args, **kwargs)\n\n\ndef device_count(*args, **kwargs):\n  return backend()[\'device_count\'](*args, **kwargs)\n\n\ndef sort_key_val(*args, **kwargs):\n  return backend()[\'sort_key_val\'](*args, **kwargs)\n\n\n# For numpy and random modules, we need to call ""backend()"" lazily, only when\n# the function is called -- so that it can be set by gin configs.\n# (Otherwise, backend() is called on import before gin-config is parsed.)\n# To do that, we make objects to encapsulated these modules.\n\n\nclass RandomBackend(object):\n  """"""Backend providing random functions.""""""\n\n  def get_prng(self, seed):\n    return backend()[\'random_get_prng\'](seed)\n\n  def split(self, prng, num=2):\n    return backend()[\'random_split\'](prng, num)\n\n  def uniform(self, *args, **kwargs):\n    return backend()[\'random_uniform\'](*args, **kwargs)\n\n  def randint(self, *args, **kwargs):\n    return backend()[\'random_randint\'](*args, **kwargs)\n\n  def normal(self, *args, **kwargs):\n    return backend()[\'random_normal\'](*args, **kwargs)\n\n  def bernoulli(self, *args, **kwargs):\n    return backend()[\'random_bernoulli\'](*args, **kwargs)\n\n\nrandom = RandomBackend()\n\n\n# A class that just forwards attribute accesses to backend\'s numpy object.\nclass NumpyBackend(object):\n\n  def __getattr__(self, attr):\n    return getattr(backend()[\'np\'], attr)\n\n\nnumpy = NumpyBackend()\n\n\noverride_backend_name = None\n\n\n@gin.configurable()\ndef backend(name=\'jax\'):\n  name = name if not override_backend_name else override_backend_name\n  if name == \'numpy\':\n    return NUMPY_BACKEND\n  elif name == \'tf\':\n    return TF_BACKEND\n  return JAX_BACKEND\n\n\n@contextlib.contextmanager\ndef use_backend(name):\n  global override_backend_name\n  prev_name = override_backend_name\n  override_backend_name = name\n  # Run the decorated function in try-finally in case it throws, e.g. for tests.\n  try:\n    yield\n  finally:\n    override_backend_name = prev_name\n'"
trax/math/backend_test.py,5,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.math.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\n\nimport gin\nimport jax.numpy as jnp\nimport numpy as onp\nfrom tensorflow import test\nimport trax.math as math\n\n\n_TestNamedtuple = collections.namedtuple(\'_TestNamedtuple\', [\'x\'])\n\n\nclass BackendTest(test.TestCase):\n\n  def setUp(self):\n    super(BackendTest, self).setUp()\n    gin.clear_config()\n\n  def override_gin(self, bindings):\n    gin.parse_config_files_and_bindings(None, bindings)\n\n  def test_backend_imports_correctly(self):\n    backend = math.backend()\n    self.assertEqual(jnp, backend[\'np\'])\n    self.assertNotEqual(onp, backend[\'np\'])\n\n    self.override_gin(""backend.name = \'numpy\'"")\n\n    backend = math.backend()\n    self.assertNotEqual(jnp, backend[\'np\'])\n    self.assertEqual(onp, backend[\'np\'])\n\n  def test_numpy_backend_delegation(self):\n    # Assert that we are getting JAX\'s numpy backend.\n    backend = math.backend()\n    numpy = math.numpy\n    self.assertEqual(jnp, backend[\'np\'])\n\n    # Assert that `numpy` calls the appropriate gin configured functions and\n    # properties.\n    self.assertTrue(numpy.isinf(numpy.inf))\n    self.assertEqual(jnp.isinf, numpy.isinf)\n    self.assertEqual(jnp.inf, numpy.inf)\n\n    # Assert that we will now get the pure numpy backend.\n\n    self.override_gin(""backend.name = \'numpy\'"")\n\n    backend = math.backend()\n    numpy = math.numpy\n    self.assertEqual(onp, backend[\'np\'])\n\n    # Assert that `numpy` calls the appropriate gin configured functions and\n    # properties.\n    self.assertTrue(numpy.isinf(numpy.inf))\n    self.assertEqual(onp.isinf, numpy.isinf)\n    self.assertEqual(onp.inf, numpy.inf)\n\n  def test_nested_map(self):\n    inp = {\'a\': ([0, 1], 2), \'b\': _TestNamedtuple(3)}\n    out = {\'a\': ([1, 2], 3), \'b\': _TestNamedtuple(4)}\n    self.assertEqual(math.nested_map(lambda x: x + 1, inp), out)\n\n  def test_nested_stack(self):\n    inp = [\n        {\'a\': ([0, 1], 2), \'b\': _TestNamedtuple(3)},\n        {\'a\': ([1, 2], 3), \'b\': _TestNamedtuple(4)},\n    ]\n    out = {\'a\': ([[0, 1], [1, 2]], [2, 3]), \'b\': _TestNamedtuple([3, 4])}\n    onp.testing.assert_equal(math.nested_stack(inp), out)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/math/jax.py,7,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Trax math: JAX backend.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport jax\nfrom jax import lax\nfrom jax import random as jax_random\nimport jax.numpy as jnp\nimport jax.scipy.special as jax_special\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nfrom trax.shapes import signature\n\n\ndef jax_conv(inp, fltr, window_strides, padding, dimension_numbers,\n             filter_dilation=None):\n  """"""A wrapper around `lax.conv_general_dilated`.\n\n  It requires `dimension_numbers` and disallows `inp_dilation`.\n\n  Args:\n    inp: an (N+2)-D array. The input of the convolution.\n    fltr: an (N+2)-D array. The filter (i.e. kernel) of the convolution.\n    window_strides: the strides for moving the convolution window.\n    padding: a string, either \'VALID\' or \'SAME\'. The padding algorithm.\n    dimension_numbers: a tuple of three strings encoding the data format of\n      input, filter and output. \'I\' means input; \'O\' means output; \'C\' means\n      channel; other characters such as \'W\', \'H\' and \'D\' means spatial\n      dimensions.\n    filter_dilation: the dilation rates for the filter. Dilating the filter\n      means adding ""holes"" to the filter.\n\n  Returns:\n    An (N+2)-D array. The convolution result.\n  """"""\n  return lax.conv_general_dilated(inp, fltr, window_strides, padding,\n                                  lhs_dilation=None,\n                                  rhs_dilation=filter_dilation,\n                                  dimension_numbers=dimension_numbers)\n\n\ndef _pooling_general(inputs, reducer, init_val, rescaler=None,\n                     pool_size=(2, 2), strides=None, padding=\'VALID\'):\n  """"""Helper: general pooling computation used in pooling layers later.""""""\n  spatial_strides = strides or (1,) * len(pool_size)\n  rescale = rescaler(pool_size, spatial_strides, padding) if rescaler else None\n  dims = (1,) + pool_size + (1,)  # NHWC\n  strides = (1,) + spatial_strides + (1,)\n  out = lax.reduce_window(inputs, init_val, reducer, dims, strides, padding)\n  return rescale(out, inputs) if rescale else out\n\n\ndef jax_max_pool(x, pool_size, strides, padding):\n  return _pooling_general(x, lax.max, -jnp.inf, pool_size=pool_size,\n                          strides=strides, padding=padding)\n\n\ndef jax_sum_pool(x, pool_size, strides, padding):\n  return _pooling_general(x, lax.add, 0., pool_size=pool_size,\n                          strides=strides, padding=padding)\n\n\ndef _normalize_by_window_size(dims, spatial_strides, padding):  # pylint: disable=invalid-name\n  def rescale(outputs, inputs):\n    one = jnp.ones(inputs.shape[1:-1], dtype=inputs.dtype)\n    window_sizes = lax.reduce_window(\n        one, 0., lax.add, dims, spatial_strides, padding)\n    return outputs / window_sizes[..., jnp.newaxis]\n  return rescale\n\n\ndef jax_avg_pool(x, pool_size, strides, padding):\n  return _pooling_general(x, lax.add, 0., _normalize_by_window_size,\n                          pool_size, strides=strides, padding=padding)\n\n\ndef _jax_scan(f, xs, init_value, axis=0, remat=False):\n  """"""Scans the f over the given axis of xs.\n\n  In pseudo-python, the scan function would look as follows:\n\n  def scan(f, xs, init_value, axis):\n    xs  = [xs[..., i, ...] for i in range(xs.shape[axis])]\n    cur_value = init_value\n    ys = []\n    for x in xs:\n      y, cur_value = f(x, cur_value)\n      ys.append(y)\n    return np.stack(ys, axis), cur_value\n\n  Args:\n    f: function (x, carry) -> (y, new_carry)\n    xs: tensor, x will be xs slices on axis\n    init_value: tensor, initial value of the carry-over\n    axis: int, the axis on which to slice xs\n    remat: whether to re-materialize f\n\n  Returns:\n    A pair (ys, last_value) as described above.\n  """"""\n  def swapaxes(x):\n    transposed_axes = list(range(len(x.shape)))\n    transposed_axes[axis] = 0\n    transposed_axes[0] = axis\n    return jnp.transpose(x, axes=transposed_axes)\n  if axis != 0:\n    xs = nested_map(swapaxes, xs)\n  def transposed_f(c, x):\n    y, d = f(x, c)\n    return d, y\n  if remat:\n    last_value, ys = lax.scan(jax.remat(transposed_f), init_value, xs)\n  else:\n    last_value, ys = lax.scan(transposed_f, init_value, xs)\n  if axis != 0:\n    ys = nested_map(swapaxes, ys)\n  return ys, last_value\n\n\ndef _is_namedtuple_instance(x):\n  """"""Checks if `x` is an instance of a `namedtuple` type.""""""\n  if not isinstance(x, tuple):\n    return False\n  return hasattr(x, \'_fields\')\n\n\ndef _is_at_level(obj, level):\n  """"""Checks if `obj` is an at level `level`.""""""\n  is_leaf = not isinstance(obj, (list, tuple, dict))\n  if level == 0 or is_leaf:\n    return (level == 0) == is_leaf\n\n  if isinstance(obj, dict):\n    elems = obj.values()\n  else:\n    elems = obj\n  return elems and all(_is_at_level(x, level - 1) for x in elems)\n\n\ndef _is_made_of_nones(obj):\n  """"""Checks if `obj` is a nested structure of `None`s.""""""\n  elems = tree_flatten(obj)\n  # Returning False for an empty list, because it doesn\'t have any Nones inside.\n  return elems and all(x is None for x in elems)\n\n\ndef nested_map(f, obj, level=0, ignore_nones=True):\n  """"""Maps `f` recursively inside any dicts/lists/tuples in `obj`.\n\n  Args:\n    f: A function taking a single object as input. f\'s input must NOT be a\n        dict, list, or tuple, or any subclass of those.\n    obj: Either an input object to f or some nested structure of collections\n        of (collections of ...) input objects to f.\n    level: Level in the nested structure to stop at, counted from the leaves -\n        so level 0 is the leaf, level 1 is such that all of its children are at\n        level 0 etc.\n    ignore_nones: Whether to ignore Nones in the structure, i.e. return None\n        without calling `f`.\n\n  Returns:\n    An object with the same nested structure as `obj`, but with each input\n    object `x` replaced by `f(x)`.\n  """"""\n  if _is_at_level(obj, level):\n    if ignore_nones and _is_made_of_nones(obj):\n      return None\n    else:\n      return f(obj)\n\n  if _is_namedtuple_instance(obj):\n    return type(obj)(*nested_map(f, list(obj), level=level))\n  if isinstance(obj, list):\n    return [nested_map(f, y, level=level) for y in obj]\n  if isinstance(obj, tuple):\n    return tuple([nested_map(f, y, level=level) for y in obj])\n  if isinstance(obj, dict):\n    return {k: nested_map(f, v, level=level) for (k, v) in obj.items()}\n\n  raise ValueError(\'Non-exhaustive pattern match for {}.\'.format(obj))\n\n\ndef nested_map_multiarg(f, *objs, ignore_nones=True):\n  """"""Maps multi-arg `f` recursively inside any dicts/lists/tuples in `objs`.\n\n  Args:\n    f: A function taking len(objs) inputs. f\'s input must NOT be a\n        dict, list, or tuple, or any subclass of those.\n    *objs: Either input objects to f or some nested structure of collections\n        of (collections of ...) input objects to f.\n    ignore_nones: Whether to ignore Nones in the structure, i.e. return None\n        without calling `f`.\n\n  Returns:\n    An object with the same nested structure as `objs[0]`, but with each input\n    object `x` replaced by `f(*xs)`.\n  """"""\n  if isinstance(objs[0], list):\n    return [nested_map_multiarg(f, *[o[i] for o in objs])\n            for i in range(len(objs[0]))]\n  if isinstance(objs[0], tuple):\n    return tuple([nested_map_multiarg(f, *[o[i] for o in objs])\n                  for i in range(len(objs[0]))])\n  if isinstance(objs[0], dict):\n    return {k: nested_map_multiarg(f, *[o[k] for o in objs])\n            for k in objs[0].keys()}\n  if ignore_nones and _is_made_of_nones(objs):\n    return None\n  return f(*objs)\n\n\ndef nested_zip(objs):\n  """"""Zips the leaves of each nested structure in `objs`.\n\n  Args:\n    objs: List of nested structures to zip.\n\n  Returns:\n    An object with the same nested structure as each element of `objs`, with\n    leaves zipped together into tuples.\n  """"""\n  assert isinstance(objs, (list, tuple))\n  assert objs, \'Cannot zip an empty sequence.\'\n\n  if _is_at_level(objs, 1):\n    return tuple(objs)\n\n  if _is_namedtuple_instance(objs[0]):\n    return type(objs[0])(*nested_zip(list(map(list, objs))))\n  if isinstance(objs[0], list):\n    return [nested_zip([obj[i] for obj in objs]) for i in range(len(objs[0]))]\n  if isinstance(objs[0], tuple):\n    return nested_zip(list(map(list, objs)))\n  if isinstance(objs[0], dict):\n    return {k: nested_zip([obj[k] for obj in objs]) for k in objs[0].keys()}\n\n  raise ValueError(\'Non-exhaustive pattern match for {}.\'.format(objs[0]))\n\n\ndef nested_stack(objs, axis=0, np_module=np):\n  """"""Stacks the numpy arrays inside any dicts/lists/tuples in `objs`.\n\n  Args:\n    objs: List of nested structures to stack.\n    axis: Axis to stack along.\n    np_module: numpy module to use - typically numpy or jax.numpy.\n\n  Returns:\n    An object with the same nested structure as each element of `objs`, with\n    leaves stacked together into numpy arrays. Nones are propagated, i.e. if\n    each element of the stacked sequence is None, the output will be None.\n  """"""\n  # nested_map the stacking operation, but stopping at level 1 so at tuples of\n  # numpy arrays.\n  return nested_map(\n      lambda x: np_module.stack(x, axis=axis),\n      nested_zip(objs),\n      level=1,\n  )\n\n\ndef tree_flatten(tree):\n  """"""Flatten a tree into a list.""""""\n  if isinstance(tree, (list, tuple)):\n    # In python, sum of lists starting from [] is the concatenation.\n    return sum([tree_flatten(t) for t in tree], [])\n  if isinstance(tree, dict):\n    # Only use the values in case of a dictionary node.\n    return sum([tree_flatten(v) for v in tree.values()], [])\n  return [tree]\n\n\ndef tree_leaves(tree, ignore_nones=True):\n  """"""Gets the leaves of a tree.""""""\n\n  # Right now this is just `tree_flatten`, but we keep this separate since\n  # JAX\'s tree_flatten returns the structure of the tree as well.\n  flattened = tree_flatten(tree)\n  return [flat for flat in flattened if (not ignore_nones) or flat is not None]\n\n\ndef tree_unflatten(flat, tree):\n  """"""Unflatten a list into a tree given the tree shape as second argument.\n\n  Args:\n    flat: a flat list of elements to be assembled into a tree.\n    tree: a tree with the structure we want to have in the new tree.\n\n  Returns:\n    A pair (new_tree, rest_of_flat) where the new tree that has the structure\n    of tree but with leaves from flat, and the remaining elements of flat if\n    more were provided than the number of leaves of tree (useful for recursion).\n  """"""\n  if isinstance(tree, (list, tuple)):\n    new_tree, rest = [], flat\n    for t in tree:\n      new_t, rest = tree_unflatten(rest, t)\n      new_tree.append(new_t)\n    new_tree = tuple(new_tree) if isinstance(tree, tuple) else new_tree\n    return new_tree, rest\n  if isinstance(tree, dict):\n    new_tree, rest = {}, flat\n    for k in tree:\n      new_v, rest = tree_unflatten(rest, tree[k])\n      new_tree[k] = new_v\n    return new_tree, rest\n  return flat[0], flat[1:]\n\n\ndef jax_abstract_eval(f):\n  """"""Returns a function that evaluates `f` given input shapes and dtypes.\n\n  It transforms function `f` to a function that performs the same computation as\n  `f` but only on shapes and dtypes (a.k.a. shape inference).\n\n  Args:\n    f: the function to be transformed.\n\n  Returns:\n    A function whose input arguments can be either the same as `f`\'s or only\n    their shapes/dtypes represented by `ShapeDtype`, and whose return values are\n    `ShapeDtype`s with the same nested structure as `f`\'s return values.\n  """"""\n  def shape_fun(*args, **kwargs):\n    jax_shapes = jax.eval_shape(f, *args, **kwargs)\n    return nested_map(signature, jax_shapes)\n  return shape_fun\n\n\n# The default value of dtype is different from jax_random.randint\ndef jax_randint(key, shape, minval, maxval, dtype=np.int32):\n  """"""Sample uniform random values in [minval, maxval) with given shape/dtype.\n\n  Args:\n    key: a PRNGKey used as the random key.\n    shape: a tuple of nonnegative integers representing the shape.\n    minval: int or array of ints broadcast-compatible with ``shape``, a minimum\n      (inclusive) value for the range.\n    maxval: int or array of ints broadcast-compatible with  ``shape``, a maximum\n      (exclusive) value for the range.\n    dtype: optional, an int dtype for the returned values (default int32).\n\n  Returns:\n    A random array with the specified shape and dtype.\n  """"""\n  return jax_random.randint(key, shape, minval=minval, maxval=maxval,\n                            dtype=dtype)\n\n\ndef _to_numpy(x):\n  """"""Converts non-NumPy tensors to NumPy arrays.""""""\n  return x if isinstance(x, np.ndarray) else x.numpy()\n\n\ndef _dataset_as_numpy(ds, batch_size=None):\n  """"""Speed up tfds.as_numpy by batching and then iterating over the batches.""""""\n  batch_size = batch_size or 1\n  try:  # Check that dense_to_ragged_batch exists.\n    if batch_size < 2:  # Fall back to default if no batching requested.\n      raise AttributeError\n    ds_batch = ds.apply(tf.data.experimental.dense_to_ragged_batch(batch_size))\n    for example in tfds.as_numpy(ds_batch):\n      flat_example = tree_flatten(example)\n      np_flat_example = [_to_numpy(x) for x in flat_example]\n      for single_example_flat in zip(*np_flat_example):\n        single_example, _ = tree_unflatten(single_example_flat, example)\n        yield single_example\n  except AttributeError:\n    # In TF 1.X there is not dense_to_ragged_batch: fallback.\n    for example in tfds.as_numpy(ds):\n      yield example\n\n\ndef _custom_grad(f_vjp, f_original):\n  f_ = jax.custom_transforms(f_original)\n  jax.defvjp_all(f_, f_vjp)\n  return f_\n\n\nJAX_BACKEND = {\n    \'name\': \'jax\',\n    \'np\': jnp,\n    \'abstract_eval\': jax_abstract_eval,\n    \'avg_pool\': jax_avg_pool,\n    \'cond\': lax.cond,\n    \'conv\': jax_conv,\n    \'custom_grad\': _custom_grad,\n    \'dataset_as_numpy\': _dataset_as_numpy,\n    \'device_count\': jax.local_device_count,\n    \'erf\': jax_special.erf,\n    \'expit\': jax_special.expit,\n    \'grad\': jax.grad,\n    \'jit\': jax.jit,\n    \'logsumexp\': jax_special.logsumexp,\n    \'lt\': lax.lt,\n    \'max_pool\': jax_max_pool,\n    \'pmap\': jax.pmap,\n    \'psum\': lax.psum,\n    \'random_bernoulli\': jax_random.bernoulli,\n    \'random_get_prng\': jax.jit(jax_random.PRNGKey),\n    \'random_normal\': jax_random.normal,\n    \'random_randint\': jax_randint,\n    \'random_split\': jax_random.split,\n    \'random_uniform\': jax_random.uniform,\n    \'scan\': _jax_scan,\n    \'sort_key_val\': jax.lax.sort_key_val,\n    \'stop_gradient\': lax.stop_gradient,\n    \'sum_pool\': jax_sum_pool,\n    \'vjp\': jax.vjp,\n}\n'"
trax/math/numpy.py,6,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Trax math: pure numpy backend.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\n\ndef get_prng(seed):\n  """"""JAX-compatible way of getting PRNG seeds.""""""\n  if np.shape(seed):\n    raise TypeError(\'PRNGKey seed must be a scalar.\')\n  convert = lambda k: np.reshape(np.asarray(k, np.uint32), [1])\n  k1 = convert(np.bitwise_and(np.right_shift(seed, 32), 0xFFFFFFFF))\n  k2 = convert(np.bitwise_and(seed, 0xFFFFFFFF))\n  return np.concatenate([k1, k2], 0)\n\n\nNUMPY_BACKEND = {\n    \'name\': \'numpy\',\n    \'np\': np,\n    \'jit\': lambda f: f,\n    \'random_get_prng\': get_prng,\n    \'random_split\': lambda prng, num=2: (None,) * num,\n    \'expit\': lambda x: 1. / (1. + np.exp(-x)),\n}\n'"
trax/math/tf.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Trax math: TF backend.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom trax.shapes import ShapeDtype\nfrom trax.tf_numpy import extensions as tf_np_extensions\nfrom trax.tf_numpy import numpy as tf_np\n\n\ndef tf_abstract_eval(f):\n  """"""Returns a function that evaluates `f` given input shapes and dtypes.\n\n  It transforms function `f` to a function that performs the same computation as\n  `f` but only on shapes and dtypes (a.k.a. shape inference).\n\n  Args:\n    f: the function to be transformed.\n\n  Returns:\n    A function whose input arguments can be either the same as `f`\'s or only\n    their shapes/dtypes represented by `ShapeDtype`, and whose return values are\n    `ShapeDtype`s with the same nested structure as `f`\'s return values.\n  """"""\n  f_shape = tf_np_extensions.eval_on_shapes(f)\n  def from_shape_type(x):\n    if isinstance(x, ShapeDtype):\n      return tf.TensorSpec(x.shape, x.dtype)\n    else:\n      return x\n  def to_shape_type(x):  # pylint: disable=missing-docstring\n    # TODO(wangpeng): handle partial output shapes using `tf.shape`.\n    def to_numpy_shape(s):\n      if s.is_fully_defined():\n        return tuple(s.as_list())\n      else:\n        raise ValueError(""The output shapes (%s) of the dry-run\'ed function are""\n                         \' not fully defined.\' % s)\n    def to_numpy_dtype(t):\n      return np.dtype(t.as_numpy_dtype)\n    if isinstance(x, tf.TensorSpec):\n      return ShapeDtype(to_numpy_shape(x.shape), to_numpy_dtype(x.dtype))\n    else:\n      return x\n  def f_return(*args):\n    args = tf.nest.map_structure(from_shape_type, args)\n    res = f_shape(*args)\n    return tf.nest.map_structure(to_shape_type, res)\n  return f_return\n\n\n# The arguments order is different from tf_np_extensions.uniform\ndef tf_randint(key, shape, minval, maxval, dtype=np.int32):\n  """"""Sample uniform random values in [minval, maxval) with given shape/dtype.\n\n  Args:\n    key: a PRNGKey used as the random key.\n    shape: a tuple of nonnegative integers representing the shape.\n    minval: int or array of ints broadcast-compatible with ``shape``, a minimum\n      (inclusive) value for the range.\n    maxval: int or array of ints broadcast-compatible with  ``shape``, a maximum\n      (exclusive) value for the range.\n    dtype: optional, an int dtype for the returned values (default int32).\n\n  Returns:\n    A random array with the specified shape and dtype.\n  """"""\n  return tf_np_extensions.uniform(key, shape, minval=minval, maxval=maxval,\n                                  dtype=dtype)\n\n\n_tf_xla_forced_compile_enabled = False\n\n\ndef tf_xla_forced_compile_enabled():\n  return _tf_xla_forced_compile_enabled\n\n\ndef set_tf_xla_forced_compile(b):\n  global _tf_xla_forced_compile_enabled\n  _tf_xla_forced_compile_enabled = b\n\n\ndef _tf_jit(*args, **kwargs):\n  kwargs[\'xla_forced_compile\'] = tf_xla_forced_compile_enabled()\n  return tf_np_extensions.jit(*args, **kwargs)\n\n\nTF_BACKEND = {\n    \'name\': \'tf\',\n    \'np\': tf_np,\n    \'jit\': _tf_jit,\n    \'stop_gradient\': tf_np_extensions.stop_gradient,\n    \'grad\': tf_np_extensions.grad,\n    \'vjp\': tf_np_extensions.vjp,\n    \'custom_grad\': tf_np_extensions.custom_grad,\n    \'abstract_eval\': tf_abstract_eval,\n    \'expit\': tf_np_extensions.expit,\n    \'erf\': tf_np_extensions.erf,\n    \'logsumexp\': tf_np_extensions.logsumexp,\n    \'conv\': tf_np_extensions.conv,\n    \'lt\': lambda x, y: x < y,\n    \'avg_pool\': tf_np_extensions.avg_pool,\n    \'max_pool\': tf_np_extensions.max_pool,\n    \'sort_key_val\': tf_np_extensions.sort_key_val,\n    \'random_uniform\': tf_np_extensions.uniform,\n    \'random_randint\': tf_randint,\n    \'random_normal\': tf_np_extensions.normal,\n    \'random_bernoulli\': tf_np_extensions.bernoulli,\n    \'random_get_prng\': tf_np_extensions.prng,\n    \'random_split\': tf_np_extensions.split,\n    \'dataset_as_numpy\': tf_np_extensions.dataset_as_numpy,\n    \'device_count\': lambda: max(len(tf_np_extensions.accelerators()), 1),\n    \'pmap\': tf_np_extensions.pmap,\n    \'psum\': tf_np_extensions.psum,\n}\n'"
trax/models/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Models defined in trax.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport gin\nimport six\n\nfrom trax.models import atari_cnn\nfrom trax.models import mlp\nfrom trax.models import neural_gpu\nfrom trax.models import resnet\nfrom trax.models import rl\nfrom trax.models import rnn\nfrom trax.models import transformer\nfrom trax.models.reformer import reformer\nfrom trax.models.research import bert\nfrom trax.models.research import skipping_transformer\n\n\n# Ginify\ndef model_configure(*args, **kwargs):\n  kwargs[\'module\'] = \'trax.models\'\n  return gin.external_configurable(*args, **kwargs)\n\n\n# pylint: disable=invalid-name\nAtariCnn = model_configure(atari_cnn.AtariCnn)\nAtariCnnBody = model_configure(atari_cnn.AtariCnnBody)\nFrameStackMLP = model_configure(atari_cnn.FrameStackMLP)\nBERT = model_configure(bert.BERT)\nBERTClassifierHead = model_configure(bert.BERTClassifierHead)\nBERTRegressionHead = model_configure(bert.BERTRegressionHead)\nMLP = model_configure(mlp.MLP)\nPureMLP = model_configure(mlp.PureMLP)\nNeuralGPU = model_configure(neural_gpu.NeuralGPU)\nReformer = model_configure(reformer.Reformer)\nReformerLM = model_configure(reformer.ReformerLM)\nReformerShortenLM = model_configure(reformer.ReformerShortenLM)\nReformerNoEncDecAttention = model_configure(reformer.ReformerNoEncDecAttention)\nResnet50 = model_configure(resnet.Resnet50)\nSkippingTransformerLM = model_configure(\n    skipping_transformer.SkippingTransformerLM)\nTransformer = model_configure(transformer.Transformer)\nTransformerDecoder = model_configure(transformer.TransformerDecoder)\nTransformerEncoder = model_configure(transformer.TransformerEncoder)\nTransformerLM = model_configure(transformer.TransformerLM)\nTransformerNoEncDecAttention = model_configure(\n    transformer.TransformerNoEncDecAttention)\nWideResnet = model_configure(resnet.WideResnet)\nPolicy = model_configure(rl.Policy)\nPolicyAndValue = model_configure(rl.PolicyAndValue)\nValue = model_configure(rl.Value)\nRNNLM = model_configure(rnn.RNNLM)\nGRULM = model_configure(rnn.GRULM)\nLSTMSeq2SeqAttn = model_configure(rnn.LSTMSeq2SeqAttn)\n'"
trax/models/atari_cnn.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Simple net for playing Atari games using PPO.""""""\n\nfrom trax import layers as tl\n\n\ndef _FrameStack(n_frames):\n  """"""Stacks successive game frames along their last dimension.""""""\n  # Input shape: (B, T, ..., C).\n  # Output shape: (B, T, ..., C * n_frames).\n  assert n_frames >= 1\n  if n_frames == 1:\n    return []  # No-op; just let the data flow through.\n  return [\n      # Create copies of input sequence, shift right by [0, ..., n_frames - 1]\n      # frames, and concatenate along the channel dimension.\n      tl.Branch(*map(_shift_right, range(n_frames))),\n      tl.Concatenate(n_items=n_frames, axis=-1)\n  ]\n\n\ndef _BytesToFloats():\n  """"""Layer that converts unsigned bytes to floats.""""""\n  return tl.Fn(\'BytesToFloats\', lambda x: x / 255.0)\n\n\ndef AtariCnn(n_frames=4, hidden_sizes=(32, 32), output_size=128, mode=\'train\'):\n  """"""An Atari CNN.""""""\n  del mode\n\n  # TODO(jonni): Include link to paper?\n  # Input shape: (B, T, H, W, C)\n  # Output shape: (B, T, output_size)\n  return tl.Serial(\n      _BytesToFloats(),\n      _FrameStack(n_frames=n_frames),  # (B, T, H, W, 4C)\n      tl.Conv(hidden_sizes[0], (5, 5), (2, 2), \'SAME\'),\n      tl.Relu(),\n      tl.Conv(hidden_sizes[1], (5, 5), (2, 2), \'SAME\'),\n      tl.Relu(),\n      tl.Flatten(n_axes_to_keep=2),  # B, T and rest.\n      tl.Dense(output_size),\n      tl.Relu(),\n  )\n\n\ndef AtariCnnBody(n_frames=4, hidden_sizes=(32, 64, 64),\n                 output_size=512, mode=\'train\',\n                 kernel_initializer=None, padding=\'VALID\'):\n  """"""An Atari CNN.""""""\n  del mode\n\n  # TODO(jonni): Include link to paper?\n  # Input shape: (B, T, H, W, C)\n  # Output shape: (B, T, output_size)\n  return tl.Serial(\n      _BytesToFloats(),\n      _FrameStack(n_frames=n_frames),  # (B, T, H, W, 4C)\n      tl.Conv(hidden_sizes[0], (8, 8), (4, 4), padding=padding,\n              kernel_initializer=kernel_initializer),\n      tl.Relu(),\n      tl.Conv(hidden_sizes[1], (4, 4), (2, 2), padding=padding,\n              kernel_initializer=kernel_initializer),\n      tl.Relu(),\n      tl.Conv(hidden_sizes[2], (3, 3), (1, 1), padding=padding,\n              kernel_initializer=kernel_initializer),\n      tl.Relu(),\n      tl.Flatten(n_axes_to_keep=2),  # B, T and rest.\n      tl.Dense(output_size),\n      tl.Relu(),\n  )\n\n\ndef FrameStackMLP(n_frames=4, hidden_sizes=(64,), output_size=64,\n                  mode=\'train\'):\n  """"""MLP operating on a fixed number of last frames.""""""\n  del mode\n\n  return tl.Serial(\n      _FrameStack(n_frames=n_frames),\n      [[tl.Dense(d_hidden), tl.Relu()] for d_hidden in hidden_sizes],\n      tl.Dense(output_size),\n  )\n\n\ndef _shift_right(n):  # pylint: disable=invalid-name\n  return [tl.ShiftRight()] * n\n'"
trax/models/atari_cnn_test.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for trax.models.atari_cnn.""""""\n\nimport functools\nimport operator as op\nimport numpy as np\nfrom tensorflow import test\nfrom trax.models import atari_cnn\nfrom trax.shapes import ShapeDtype\n\n\nclass AtariCnnTest(test.TestCase):\n\n  def test_computes(self):\n    hidden_size = (4, 4)\n    output_size = 6\n    model = atari_cnn.AtariCnn(\n        hidden_sizes=hidden_size, output_size=output_size)\n    B, T, OBS = 2, 2, (28, 28, 3)  # pylint: disable=invalid-name\n    input_signature = ShapeDtype((1, 1) + OBS)\n    _, _ = model.init(input_signature)\n    x = np.arange(B * (T + 1) * functools.reduce(op.mul, OBS)).reshape(\n        B, T + 1, *OBS)\n    y = model(x)\n    self.assertEqual((B, T + 1, output_size), y.shape)\n\n\nclass FrameStackMLPTest(test.TestCase):\n\n  def test_computes(self):\n    hidden_size = (4, 4)\n    output_size = 6\n    model = atari_cnn.FrameStackMLP(\n        hidden_sizes=hidden_size, output_size=output_size)\n    B, T, OBS = 2, 2, 3  # pylint: disable=invalid-name\n    input_signature = ShapeDtype((1, 1, OBS))\n    _, _ = model.init(input_signature)\n    x = np.arange(B * (T + 1) * OBS).reshape(B, T + 1, OBS)\n    y = model(x)\n    self.assertEqual((B, T + 1, output_size), y.shape)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/models/beam_search.py,41,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Inference methods for autoregressive models (see the Search class).""""""\n# TODO(kitaev): this file needs style cleanup.\n\nimport collections\nimport functools\n\nimport jax\nfrom jax import lax\nfrom jax import numpy as jnp\nimport numpy as onp\n\nfrom trax import layers as tl\nimport trax.math\nfrom trax.math import numpy as np  # TODO(jonni): Avoid 3 numpy\'s: jnp, onp, np\nfrom trax.shapes import ShapeDtype\n\n# Constants\n# ""Effective negative infinity"" constant for masking in beam search.\nNEG_INF = onp.array(-1.0e7)\n\n\n# Beam Search\n#\n# We try to match the logic of the original t2t implementation and the mlperf\n# reference tensorflow implementation at:\n# https://github.com/mlperf/training/blob/master/translation/tensorflow/transformer/model/beam_search.py\n#\n# Using JAX we are directly programming with the XLA computation model,\n# so here we initialize and update static-sized arrays inside an XLA while loop\n# rather than concatenating onto a growing chain of sequences.\n\n\ndef brevity_penalty(alpha, length):\n  """"""Brevity penalty function for beam search penalizing short sequences.\n\n  Args:\n    alpha: float: brevity-penalty scaling parameter.\n    length: int: length of considered sequence.\n\n  Returns:\n    Brevity penalty score as jax scalar.\n  """"""\n  return jnp.power(((5.0 + length) / 6.0), alpha)\n\n\ndef top_k(x, k):\n  """"""Select the top k slices from the last dimension.""""""\n  bcast_idxs = jnp.broadcast_to(np.arange(x.shape[-1]), x.shape)\n  sorted_vals, sorted_idxs = lax.sort_key_val(x, bcast_idxs)\n  # TODO(levskaya): use lax.slice here instead to benefit from XLA optimization\n  return sorted_vals[..., -k:], sorted_idxs[..., -k:]\n\n\n# Beam handling utility functions:\n\n\ndef add_beam_dim(x, beam_size):\n  """"""Creates new beam dimension in non-scalar array and tiles into it.""""""\n  if isinstance(x, int):\n    return jnp.array(x)\n  if x.ndim == 0:  # ignore scalars (e.g. cache index)\n    return x\n  x = jnp.expand_dims(x, axis=1)\n  tile_dims = [1] * x.ndim\n  tile_dims[1] = beam_size\n  return jnp.tile(x, tile_dims)\n\n\ndef flatten_beam_dim(x, batch_size=None):\n  """"""Flattens the first two dimensions of a non-scalar array.""""""\n  if x.ndim == 0:  # ignore scalars (e.g. cache index)\n    return x\n  if batch_size is not None and x.shape[0] != batch_size:\n    assert x.shape[0] % batch_size == 0\n    res = x.reshape((batch_size, -1, x.shape[1]) + x.shape[2:])\n    res = np.swapaxes(res, 1, 2)\n    res = res.reshape(\n        (res.shape[0] * res.shape[1] * res.shape[2],) + res.shape[3:])\n    return res\n  return x.reshape((x.shape[0] * x.shape[1],) + x.shape[2:])\n\n\ndef unflatten_beam_dim(x, batch_size, beam_size):\n  """"""Unflattens the first, flat batch*beam dimension of a non-scalar array.""""""\n  if x.ndim == 0:  # ignore scalars (e.g. cache index)\n    return x\n  if batch_size * beam_size == x.shape[0]:\n    return x.reshape((batch_size, beam_size) + x.shape[1:])\n  else:\n    assert x.shape[0] % (batch_size * beam_size) == 0\n    res = x.reshape((batch_size, beam_size, -1) + x.shape[1:])\n    res = np.swapaxes(res, 1, 2)\n    res = res.reshape((-1, beam_size) + res.shape[3:])\n    return res\n\n\ndef gather_beams(nested, beam_indices, batch_size, new_beam_size):\n  """"""Gathers the beam slices indexed by beam_indices into new beam array.\n\n  Args:\n    nested: pytree of arrays or scalars (the latter ignored).\n    beam_indices: array of beam_indices\n    batch_size: int: size of batch.\n    new_beam_size: int: size of _new_ beam dimension.\n\n  Returns:\n    New pytree with new beam arrays.\n    [batch_size, old_beam_size, ...] --> [batch_size, new_beam_size, ...]\n  """"""\n  batch_indices = jnp.reshape(\n      jnp.arange(batch_size * new_beam_size) // new_beam_size,\n      (batch_size, new_beam_size))\n  def gather_fn(x):\n    """"""Gather slices for a single tensor.""""""\n    if x.ndim == 0:  # ignore scalars (e.g. cache index)\n      return x\n    elif x.shape[0] != batch_size:\n      assert x.shape[0] % batch_size == 0\n      res = x.reshape((batch_size, -1,) + x.shape[1:])\n      res = np.swapaxes(res, 1, 2)\n      res = res[batch_indices, beam_indices]\n      res = np.swapaxes(res, 1, 2)\n      res = res.reshape((-1,) + res.shape[2:])\n      return res\n    else:\n      return x[batch_indices, beam_indices]\n  return jax.tree_map(gather_fn, nested)\n\n\ndef gather_topk_beams(nested, score_or_log_prob, batch_size, new_beam_size):\n  """"""Gathers the top-k beam slices given by score_or_log_prob array.\n\n  Args:\n    nested: pytree of arrays or scalars (the latter ignored).\n    score_or_log_prob: [batch_size, old_beam_size] array of values to sort by\n      for top-k selection of beam slices.\n    batch_size: int: size of batch.\n    new_beam_size: int: size of _new_ top-k selected beam dimension\n\n  Returns:\n    New pytree with new beam arrays containing top k new_beam_size slices.\n    [batch_size, old_beam_size, ...] --> [batch_size, new_beam_size, ...]\n  """"""\n  _, topk_indexes = top_k(score_or_log_prob, k=new_beam_size)\n  return gather_beams(nested, topk_indexes, batch_size, new_beam_size)\n\n\n# Beam search state:\n\nBeamState = collections.namedtuple(\'BeamState\', [\n    # The position of the decoding loop in the length dimension.\n    \'cur_index\',  # scalar int32: current decoded length index\n    # The active sequence log probabilities and finished sequence scores.\n    \'live_logprobs\',  # float32: [batch_size, beam_size]\n    \'finished_scores\',  # float32: [batch_size, beam_size]\n    # The current active-beam-searching and finished sequences.\n    \'live_seqs\',  # int32: [batch_size, beam_size, max_decode_len]\n    \'finished_seqs\',  # int32: [batch_size, beam_size, max_decode_len]\n    # Records which of the \'finished_seqs\' is occupied and not a filler slot.\n    \'finished_flags\',  # bool: [batch_size, beam_size]\n    # The current state of the autoregressive decoding caches.\n    \'cache\',  # Any pytree of arrays, e.g. flax attention Cache object\n])\n\n\ndef beam_init(batch_size, beam_size, max_decode_len, cache, start_tokens=None):\n  """"""Initializes the beam search state data structure.""""""\n  cur_index0 = jnp.array(0)\n  live_logprobs0 = jnp.tile(\n      jnp.array([0.0] + [NEG_INF] * (beam_size - 1)),\n      [batch_size, 1])\n  finished_scores0 = jnp.ones((batch_size, beam_size)) * NEG_INF\n  if start_tokens is None:\n    live_seqs0 = jnp.zeros(\n        (batch_size, beam_size, max_decode_len), jnp.int32)\n  else:\n    live_seqs0 = add_beam_dim(\n        np.pad(start_tokens[:, None],\n               ((0, 0), (0, max_decode_len - 1)), mode=\'constant\'),\n        beam_size)\n  finished_seqs0 = jnp.zeros(\n      (batch_size, beam_size, max_decode_len), jnp.int32)\n  finished_flags0 = jnp.zeros((batch_size, beam_size), jnp.bool_)\n  # add beam dimension to attention cache pytree elements\n  beam_cache0 = jax.tree_map(lambda x: add_beam_dim(x, beam_size), cache)\n  return BeamState(cur_index=cur_index0,\n                   live_logprobs=live_logprobs0,\n                   finished_scores=finished_scores0,\n                   live_seqs=live_seqs0,\n                   finished_seqs=finished_seqs0,\n                   finished_flags=finished_flags0,\n                   cache=beam_cache0)\n\n\n# Beam search routine:\n\n\ndef beam_search(batch_size,\n                cache,\n                tokens_to_logits,\n                max_decode_len,\n                beam_size=4,\n                alpha=0.6,\n                eos_token=-1,\n                start_tokens=None):\n  """"""Beam search for transformer machine translation.\n\n  Args:\n    batch_size: int: batch size for decoding\n    cache: flax attention cache.\n    tokens_to_logits: fast autoregressive decoder function taking single token\n      slices and cache and returning next-token logits and updated cache.\n    max_decode_len: int: maximum length of decoded translations.\n    beam_size: int: number of beams to use in beam search.\n    alpha: float: scaling factor for brevity penalty.\n    eos_token: int: end-of-sentence token for target vocabulary.\n    start_tokens: (optional) array: [batch_size] int32 start tokens\n\n  Returns:\n     Tuple of:\n       [batch_size, beam_size, max_decode_len] top-scoring sequences\n       [batch_size, beam_size] beam-search scores.\n  """"""\n  # We liberally annotate shape information for clarity below.\n\n  end_marker = jnp.array(eos_token)\n\n  # initialize beam search state\n  beam_search_init_state = beam_init(batch_size,\n                                     beam_size,\n                                     max_decode_len,\n                                     cache,\n                                     start_tokens)\n\n  def beam_search_loop_cond_fn(state):\n    """"""Beam search loop termination condition.""""""\n    # Have we reached max decoding length?\n    not_at_end = (state.cur_index < max_decode_len - 1)\n\n    # Is no further progress in the beam search possible?\n    # Get the best possible scores from alive sequences.\n    min_brevity_penalty = brevity_penalty(alpha, max_decode_len)\n    best_live_scores = state.live_logprobs[:, -1:] / min_brevity_penalty\n    # Get the worst scores from finished sequences.\n    worst_finished_scores = jnp.min(\n        state.finished_scores, axis=1, keepdims=True)\n    # Mask out scores from slots without any actual finished sequences.\n    worst_finished_scores = jnp.where(\n        state.finished_flags, worst_finished_scores, NEG_INF)\n    # If no best possible live score is better than current worst finished\n    # scores, the search cannot improve the finished set further.\n    search_terminated = jnp.all(worst_finished_scores > best_live_scores)\n\n    # If we\'re not at the max decode length, and the search hasn\'t terminated,\n    # continue looping.\n    return not_at_end & (~search_terminated)\n\n  def beam_search_loop_body_fn(state):\n    """"""Beam search loop state update function.""""""\n    # Collect the current position slice along length to feed the fast\n    # autoregressive decoder model.  Flatten the beam dimension into batch\n    # dimension for feeding into the model.\n    # --> [batch * beam, 1]\n    flat_ids = flatten_beam_dim(lax.dynamic_slice(\n        state.live_seqs,\n        (0, 0, state.cur_index),\n        (batch_size, beam_size, 1)))\n    # Flatten beam dimension into batch to be compatible with model.\n    # {[batch, beam, ...], ...} --> {[batch * beam, ...], ...}\n    flat_cache = jax.tree_map(\n        lambda x: flatten_beam_dim(x, batch_size), state.cache)\n\n    # Call fast-decoder model on current tokens to get next-position logits.\n    # --> [batch * beam, vocab]\n    flat_logits, new_flat_cache = tokens_to_logits(\n        flat_ids, flat_cache, jax.random.PRNGKey(state.cur_index))\n\n    # unflatten beam dimension\n    # [batch * beam, vocab] --> [batch, beam, vocab]\n    logits = unflatten_beam_dim(flat_logits, batch_size, beam_size)\n    # Unflatten beam dimension in attention cache arrays\n    # {[batch * beam, ...], ...} --> {[batch, beam, ...], ...}\n    new_cache = jax.tree_map(\n        lambda x: unflatten_beam_dim(x, batch_size, beam_size), new_flat_cache)\n\n    # Gather log probabilities from logits\n    candidate_log_probs = jax.nn.log_softmax(logits)\n    # Add new logprobs to existing prefix logprobs.\n    # --> [batch, beam, vocab]\n    log_probs = (candidate_log_probs +\n                 jnp.expand_dims(state.live_logprobs, axis=2))\n\n    # We\'ll need the vocab size, gather it from the log probability dimension.\n    vocab_size = log_probs.shape[2]\n\n    # Each item in batch has beam_size * vocab_size candidate sequences.\n    # For each item, get the top 2*k candidates with the highest log-\n    # probabilities. We gather the top 2*K beams here so that even if the best\n    # K sequences reach EOS simultaneously, we have another K sequences\n    # remaining to continue the live beam search.\n    beams_to_keep = 2 * beam_size\n    # Flatten beam and vocab dimensions.\n    flat_log_probs = log_probs.reshape((batch_size, beam_size * vocab_size))\n    # Gather the top 2*K scores from _all_ beams.\n    # --> [batch, 2*beams], [batch, 2*beams]\n    topk_log_probs, topk_indices = top_k(flat_log_probs, k=beams_to_keep)\n    # Recover the beam index by floor division.\n    topk_beam_indices = topk_indices // vocab_size\n    # Gather 2*k top beams and beam-associated caches.\n    # --> [batch, 2*beams, length], {[batch, 2*beams, ...], ...}\n    topk_seq, new_cache = gather_beams([state.live_seqs, new_cache],\n                                       topk_beam_indices,\n                                       batch_size, beams_to_keep)\n\n    # Append the most probable 2*K token IDs to the top 2*K sequences\n    # Recover token id by modulo division and expand Id array for broadcasting.\n    # --> [batch, 2*beams, 1]\n    topk_ids = jnp.expand_dims(topk_indices % vocab_size, axis=2)\n    # Update sequences for the 2*K top-k new sequences.\n    # --> [batch, 2*beams, length]\n    topk_seq = lax.dynamic_update_slice(\n        topk_seq, topk_ids, (0, 0, state.cur_index + 1))\n\n    # Update LIVE (in-progress) sequences:\n    # Did any of these sequences reach an end marker?\n    # --> [batch, 2*beams]\n    newly_finished = (topk_seq[:, :, state.cur_index + 1] == end_marker)\n    # To prevent these newly finished sequences from being added to the LIVE\n    # set of active beam search sequences, set their log probs to a very large\n    # negative value.\n    new_log_probs = topk_log_probs + newly_finished * NEG_INF\n    # --> [batch, beams, length], [batch, beams], {[batch, beams, ...], ...}\n    top_alive_seq, top_alive_log_probs, top_alive_cache = gather_topk_beams(\n        [topk_seq, new_log_probs, new_cache],\n        new_log_probs,\n        batch_size, beam_size)\n\n    # Update FINISHED (reached end of sentence) sequences:\n    # Calculate new seq scores from log probabilities.\n    new_scores = topk_log_probs / brevity_penalty(alpha, state.cur_index + 1)\n    # Mask out the still unfinished sequences by adding large negative value.\n    # --> [batch, 2*beams]\n    new_scores += (~newly_finished) * NEG_INF\n\n    # Combine sequences, scores, and flags along the beam dimension and compare\n    # new finished sequence scores to existing finished scores and select the\n    # best from the new set of beams.\n    finished_seqs = jnp.concatenate(  # --> [batch, 3*beams, length]\n        [state.finished_seqs, topk_seq], axis=1)\n    finished_scores = jnp.concatenate(  # --> [batch, 3*beams]\n        [state.finished_scores, new_scores], axis=1)\n    finished_flags = jnp.concatenate(  # --> [batch, 3*beams]\n        [state.finished_flags, newly_finished], axis=1)\n    # --> [batch, beams, length], [batch, beams], [batch, beams]\n    top_finished_seq, top_finished_scores, top_finished_flags = (\n        gather_topk_beams([finished_seqs, finished_scores, finished_flags],\n                          finished_scores, batch_size, beam_size))\n\n    return BeamState(cur_index=state.cur_index + 1,\n                     live_logprobs=top_alive_log_probs,\n                     finished_scores=top_finished_scores,\n                     live_seqs=top_alive_seq,\n                     finished_seqs=top_finished_seq,\n                     finished_flags=top_finished_flags,\n                     cache=top_alive_cache)\n\n  # Run while loop and get final beam search state.\n  final_state = lax.while_loop(beam_search_loop_cond_fn,\n                               beam_search_loop_body_fn,\n                               beam_search_init_state)\n\n  # Account for the edge-case where there are no finished sequences for a\n  # particular batch item. If so, return live sequences for that batch item.\n  # --> [batch]\n  none_finished = jnp.any(final_state.finished_flags, axis=1)\n  # --> [batch, beams, length]\n  finished_seqs = jnp.where(none_finished[:, None, None],\n                            final_state.finished_seqs,\n                            final_state.live_seqs)\n  # --> [batch, beams]\n  finished_scores = jnp.where(none_finished[:, None],\n                              final_state.finished_scores,\n                              final_state.live_logprobs)\n\n  return finished_seqs, finished_scores\n\n\nclass Search:\n  """"""Provides inference for autoregressive models.""""""\n\n  def __init__(self, model, weights, max_decode_len, beam_size=1, temperature=0,\n               alpha=0.0, eos_id=None):\n    """"""Construct an inference wrapper for an autoregressive model.\n\n    The default behavior is to do greedy decoding:\n      s = Search(model, weights, max_decode_len, eos_id=eos_id)\n    Passing a temperature parameter will switch to sampling:\n      s = Search(model, weights, max_decode_len, temperature=1, eos_id=eos_id)\n    Passing a beam_size parameter will switch to beam search. For machine\n    translation with Transformer models, Vaswani et al. (2017) recommend a beam\n    size of 4 and length normalization with alpha=0.6.\n      s = Search(model, weights, max_decode_len, beam_size=4, alpha=0.6,\n                 eos_id=eos_id)\n\n    After constructing the class, see Search.decode for how to decode a batch\n    of examples.\n\n    Args:\n      model: function to construct a model (e.g. trax.models.Reformer)\n      weights: model weights\n      max_decode_len: maximum length to decode\n      beam_size: beam size, for beam search\n      temperature: temperature parameter for sampling; set to nonzero to switch\n        from greedy/beam-search behavior to sampling.\n      alpha: length penalty alpha coefficient for beam search.\n      eos_id: end-of-sentence token for target vocabulary.\n    """"""\n    # TODO(kitaev): k and p parameters for top-k and nucleus sampling.\n    self.model = model\n    self.model_infer = model(mode=\'predict\')\n    # Weights are stored on device, but not replicated.\n    self.model_weights = jax.tree_map(jax.jit(lambda x: x), weights)\n\n    self.sample = (temperature != 0)\n    self.temperature = temperature\n\n    if self.sample and beam_size > 1:\n      # TODO(kitaev): perform stochastic beam search in this case\n      # (https://arxiv.org/abs/1903.06059)\n      raise ValueError(\'beam_size parameter is not supported when sampling\')\n\n    is_cache = [isinstance(l, tl.Cache) for l in self.model_infer.sublayers]\n    if any(is_cache):\n      assert sum([int(x) for x in is_cache]) == 1, (\n          \'At most one usage of tl.Cache currently supported\')\n      self.encoder_idx = is_cache.index(True) + 1\n    else:\n      self.encoder_idx = None\n\n    beam_search_partial = functools.partial(\n        self._unreplicated_beam_search,\n        beam_size=beam_size, alpha=alpha,\n        eos_token=eos_id if eos_id is not None else -1,\n        max_decode_len=max_decode_len + 1)  # Add 1 to account for start token.\n\n    self._jit_beam_search = jax.pmap(beam_search_partial, axis_name=\'batch\',\n                                     static_broadcasted_argnums=(2,))\n\n  def _get_initial_state(self, inputs, targets_prefix, batch_size):\n    """"""Get initial state for beam search.""""""\n    if targets_prefix is None:\n      prompt = np.zeros((batch_size, 1), dtype=np.int32)\n    else:\n      prompt = np.pad(\n          targets_prefix[:, :-1], ((0, 0), (1, 0)), mode=\'constant\')\n\n    # Get state prior to running the encoder or incorporating targets_prefix\n    if inputs is None:\n      signature = ShapeDtype((batch_size, 1), prompt.dtype)\n    else:\n      signature = (ShapeDtype(inputs.shape, inputs.dtype),\n                   ShapeDtype((batch_size, 1), prompt.dtype))\n    # Trax\'s model.init is stateful as opposed to functional. Calling it on an\n    # already-existing model instance doesn\'t work.\n    # TODO(lukaszkaiser): add purely functional init to Trax.\n    _, initial_state = self.model(mode=\'predict\').init(signature)\n\n    # Incorporate encoder and prompt into state\n    _, prompted_state = self.model_infer.pure_fn(\n        prompt if inputs is None else (inputs, prompt),\n        self.model_weights,\n        initial_state,\n        jax.random.PRNGKey(0))\n    state_structure = jax.tree_structure(prompted_state)\n\n    if targets_prefix is not None:\n      initial_state = prompted_state\n    elif self.encoder_idx is not None:\n      initial_state = (tuple(prompted_state[:self.encoder_idx])\n                       + tuple(initial_state[self.encoder_idx:]))\n\n    # Fix tree structure of the state (there\'s a tuple vs. list mismatch)\n    initial_state = jax.tree_unflatten(\n        state_structure, trax.math.tree_leaves(initial_state))\n\n    return initial_state\n\n  def _unreplicated_beam_search(self, inputs, targets_prefix, batch_size, dummy,\n                                beam_size, alpha, eos_token, max_decode_len):\n    """"""Beam search, on one device.""""""\n    del dummy  # Used to signal pmap axis size in the fully unconditional case\n    def tokens_to_logits(flat_ids, flat_cache, rng):\n      """"""Autoregressive decoding step: map from previous tokens to logits.""""""\n      rng, subrng = jax.random.split(rng)\n      tiled_inputs = flatten_beam_dim(add_beam_dim(inputs, beam_size))\n      flat_logits, new_flat_cache = self.model_infer.pure_fn(\n          flat_ids if tiled_inputs is None else (tiled_inputs, flat_ids),\n          self.model_weights,\n          flat_cache,\n          rng)\n      if isinstance(flat_logits, (list, tuple)):\n        flat_logits = flat_logits[0]  # Keep only logits from output stack\n      flat_logits = flat_logits[:, 0, :]  # Squeeze along seqlen dim\n\n      if self.sample:\n        flat_logits = (flat_logits / self.temperature\n                       + jax.random.gumbel(subrng, flat_logits.shape))\n\n      return flat_logits, new_flat_cache\n    return beam_search(\n        batch_size,\n        self._get_initial_state(inputs, targets_prefix, batch_size),\n        tokens_to_logits,\n        max_decode_len,\n        start_tokens=None if targets_prefix is None else targets_prefix[:, -1],\n        beam_size=beam_size, alpha=alpha, eos_token=eos_token)\n\n  def decode(self, inputs=None, targets_prefix=None, batch_size=None):\n    """"""Performs decoding for a batch of examples.\n\n    Args:\n      inputs: [batch_size, encoder_input_length] int32 numpy array: Inputs to\n        the encoder portion of the model. If the model does not have an encoder,\n        leave this set to None.\n      targets_prefix: [batch_size, target_prefix_length] int32 numpy array:\n        Optional prefix to initialize the decoder with. The start token should\n        never be included in the prefix. Note that all examples in the batch\n        must use the same prefix length.\n      batch_size: If both inputs and targets_prefix are None, the batch_size\n        argument is required and will determine the batch size for decoding.\n        Otherwise, this argument serves as an optional hint for the batch size\n        that the inputs should be padded out to before running inference. The\n        XLA computation for inference needs to be re-jitted every time a new\n        batch size is encountered, so passing a constant batch_size argument can\n        speed up inference by avoiding recompilation.\n\n    Returns:\n      Tuple of:\n        [batch_size, beam_size, max_decode_len] top-scoring sequences\n        [batch_size, beam_size] beam-search scores.\n      The highest-scoring sequence will be at index -1 along the beam_size axis.\n    """"""\n    n_devices = trax.math.device_count()\n    if inputs is not None and targets_prefix is not None:\n      pad_to = batch_size\n      batch_size = inputs.shape[0]\n      assert targets_prefix.shape[0] == batch_size\n    elif inputs is not None:\n      pad_to = batch_size\n      batch_size = inputs.shape[0]\n    elif targets_prefix is not None:\n      pad_to = batch_size\n      batch_size = targets_prefix.shape[0]\n    else:\n      pad_to = None\n\n    if pad_to is None:\n      pad_amount = (n_devices - (batch_size % n_devices)) % n_devices\n    else:\n      assert pad_to % n_devices == 0, (\n          \'When specifying batch_size for the purposes of padding,\'\n          \'batch_size must be divisible by the number of devices.\')\n      pad_amount = pad_to - batch_size\n      assert pad_amount >= 0\n\n    if inputs is not None:\n      if pad_amount:\n        inputs = onp.concatenate([inputs] + [inputs[0:1]] * pad_amount, 0)\n      inputs = inputs.reshape((n_devices, -1) + inputs.shape[1:])\n    if targets_prefix is not None:\n      if pad_amount:\n        targets_prefix = onp.concatenate(\n            [targets_prefix] + [targets_prefix[0:1]] * pad_amount, 0)\n      targets_prefix = targets_prefix.reshape(\n          (n_devices, -1) + targets_prefix.shape[1:])\n\n    seqs, scores = self._jit_beam_search(\n        inputs, targets_prefix, (batch_size + pad_amount) // n_devices,\n        dummy=np.zeros(n_devices))\n    seqs = onp.asarray(seqs)\n    scores = onp.asarray(scores)\n    seqs = seqs.reshape((-1,) + seqs.shape[2:])\n    scores = scores.reshape((-1,) + scores.shape[2:])\n    seqs = seqs[:, :, 1:]  # Strip start token\n    if pad_amount:\n      seqs = seqs[:batch_size]\n      scores = scores[:batch_size]\n    return seqs, scores\n'"
trax/models/mlp.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""mlp -- functions that assemble ""multilayer perceptron"" networks.""""""\n\nfrom trax import layers as tl\n\n\ndef PureMLP(\n    layer_widths=(128, 64),\n    activation_fn=tl.Relu,\n    out_activation=False,\n    flatten=True,\n    mode=\'train\'):\n  """"""A ""multilayer perceptron"" (MLP) network.\n\n  This is a classic fully connected feedforward network, with one or more\n  layers and a (nonlinear) activation function between each layer. For\n  historical reasons, such networks are often called multilayer perceptrons;\n  but they are more accurately described as multilayer networks, where\n  each layer + activation function is a perceptron-like unit (see, e.g.,\n  [https://en.wikipedia.org/wiki/Multilayer_perceptron#Terminology]).\n\n  Args:\n    layer_widths: Tuple of ints telling the number of layers and the width of\n        each layer. For example, setting `layer_widths=(128, 64, 32)` would\n        yield 3 layers with successive widths of 128, 64, and 32.\n    activation_fn: Layer that computes a nonlinear activation between pairs\n        of fully connnected layers. An activation function typically acts\n        elementwise, and its output has the same shape and dtype as its input.\n    out_activation: If True, include a copy of the activation function as the\n        last layer in the network.\n    flatten: If True, insert a layer at the head of the network to flatten the\n        input tensor into a matrix of shape (batch_size. -1).\n    mode: Ignored.\n\n  Returns:\n    An assembled MLP network with the specified layers. This network can either\n    be initialized and trained as a full model, or can be used as a building\n    block in a larger network.\n  """"""\n  del mode\n\n  layers = []\n  for width in layer_widths:\n    layers.append(tl.Dense(width))\n    layers.append(activation_fn())\n\n  if not out_activation:\n    # Don\'t need the last activation.\n    layers.pop()\n\n  return tl.Serial(\n      [tl.Flatten()] if flatten else [],\n      layers,\n  )\n\n\ndef MLP(d_hidden=512,\n        n_hidden_layers=2,\n        activation_fn=tl.Relu,\n        n_output_classes=10,\n        flatten=True,\n        mode=\'train\'):\n  """"""An MLP network, with a final layer for n-way classification.""""""\n  # TODO(jonni): Revisit naming of PureMLP vs. MLP.\n  # TODO(jonni): Redo params for MLP to align with PureMLP?\n\n  return tl.Serial(\n      PureMLP(\n          layer_widths=[d_hidden] * n_hidden_layers + [n_output_classes],\n          activation_fn=activation_fn,\n          flatten=flatten,\n          mode=mode),\n      tl.LogSoftmax(),\n  )\n'"
trax/models/mlp_test.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for MLP.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\n\nfrom trax import math\nfrom trax import shapes\nfrom trax.models import mlp\n\n\nclass MLPTest(absltest.TestCase):\n\n  def test_pure_mlp_forward_shape(self):\n    model = mlp.PureMLP(layer_widths=(32, 16, 8))\n    x = np.ones((7, 28, 28, 3)).astype(np.float32)\n    _, _ = model.init(shapes.signature(x))\n    y = model(x)\n    self.assertEqual(y.shape, (7, 8))\n\n  def test_mlp_forward_shape(self):\n    model = mlp.MLP(d_hidden=32, n_output_classes=10)\n    x = np.ones((3, 28, 28, 1)).astype(np.float32)\n    _, _ = model.init(shapes.signature(x))\n    y = model(x)\n    self.assertEqual(y.shape, (3, 10))\n\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/models/neural_gpu.py,3,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Implementation of the improved Neural GPU (NGPU).""""""\n\nfrom trax import layers as tl\nfrom trax.math import numpy as np\n\n\n# TODO(ddohan): Combinator to add saturation costs to loss\ndef SaturationCost(x, limit=0.9):\n  return np.minimum(0, np.abs(x) - limit)\n\n\ndef DiagonalGate():\n  """"""Split channels in 3 parts. Shifts 1st and 3rd sections to left/right.""""""\n\n  def f(x):  # pylint: disable=invalid-name\n    # x : [batch, 1, length, depth]\n    x = np.pad(x, [(0, 0), (0, 0), (1, 1), (0, 0)],\n               mode=\'constant\', constant_values=0.0)\n    depth = x.shape[-1] // 3\n    assert 3 * depth == x.shape[-1], (\'Depth must be divisible by 3\', depth,\n                                      x.shape)\n    xs = [\n        x[:, :, :-2, :depth], x[:, :, 1:-1, depth:2 * depth],\n        x[:, :, 2:, 2 * depth:3 * depth]\n    ]\n    return np.concatenate(xs, axis=3)\n  return tl.Fn(\'DiagonalGate\', f)\n\n\ndef ConvDiagonalGRU(units, kernel_size=(3, 3)):\n  """"""Build convolutional GRU with diagonal gating as in ImprovedNGPU.""""""\n\n  def BuildConv():\n    return tl.Conv(filters=units, kernel_size=kernel_size, padding=\'SAME\')\n\n  return tl.GeneralGRUCell(\n      candidate_transform=BuildConv,\n      memory_transform_fn=DiagonalGate,\n      gate_nonlinearity=tl.HardSigmoid,\n      candidate_nonlinearity=tl.HardTanh)\n\n\ndef NeuralGPU(d_feature=96, steps=16, vocab_size=2, mode=\'train\'):\n  """"""Implementation of Neural GPU: https://arxiv.org/abs/1702.08727.\n\n  Args:\n    d_feature: Number of memory channels (dimensionality of feature embedding).\n    steps: Number of times depthwise recurrence steps.\n    vocab_size: Vocabulary size.\n    mode: Whether we are training or evaluating or doing inference.\n\n  Returns:\n    A NeuralGPU Stax model.\n  """"""\n  del mode\n\n  core = ConvDiagonalGRU(units=d_feature)\n  return tl.Serial(\n      tl.Embedding(d_feature=d_feature, vocab_size=vocab_size),\n      [core] * steps,\n      tl.Dense(vocab_size),\n      tl.LogSoftmax(),\n  )\n'"
trax/models/neural_gpu_test.py,1,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for trax.models.neural_gpu.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\n\nfrom trax import shapes\nfrom trax.models import neural_gpu\n\n\nclass NeuralGPUTest(absltest.TestCase):\n\n  def test_ngpu(self):\n    model = neural_gpu.NeuralGPU(d_feature=30, steps=4, vocab_size=22)\n    x = np.ones((3, 5, 7)).astype(np.int32)\n    _, _ = model.init(shapes.signature(x))\n    y = model(x)\n    self.assertEqual(y.shape, (3, 5, 7, 22))\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/models/resnet.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""ResNet.""""""\n\nfrom trax import layers as tl\n\n\ndef ConvBlock(kernel_size, filters, strides, norm, non_linearity,\n              mode=\'train\'):\n  """"""ResNet convolutional striding block.""""""\n  # TODO(jonni): Use good defaults so Resnet50 code is cleaner / less redundant.\n  ks = kernel_size\n  filters1, filters2, filters3 = filters\n  main = [\n      tl.Conv(filters1, (1, 1), strides),\n      norm(mode=mode),\n      non_linearity(),\n      tl.Conv(filters2, (ks, ks), padding=\'SAME\'),\n      norm(mode=mode),\n      non_linearity(),\n      tl.Conv(filters3, (1, 1)),\n      norm(mode=mode),\n  ]\n  shortcut = [\n      tl.Conv(filters3, (1, 1), strides),\n      norm(mode=mode),\n  ]\n  return [\n      tl.Residual(main, shortcut=shortcut),\n      non_linearity()\n  ]\n\n\ndef IdentityBlock(kernel_size, filters, norm, non_linearity,\n                  mode=\'train\'):\n  """"""ResNet identical size block.""""""\n  # TODO(jonni): Use good defaults so Resnet50 code is cleaner / less redundant.\n  ks = kernel_size\n  filters1, filters2, filters3 = filters\n  main = [\n      tl.Conv(filters1, (1, 1)),\n      norm(mode=mode),\n      non_linearity(),\n      tl.Conv(filters2, (ks, ks), padding=\'SAME\'),\n      norm(mode=mode),\n      non_linearity(),\n      tl.Conv(filters3, (1, 1)),\n      norm(mode=mode),\n  ]\n  return [\n      tl.Residual(main),\n      non_linearity(),\n  ]\n\n\ndef Resnet50(d_hidden=64, n_output_classes=1001, mode=\'train\',\n             norm=tl.BatchNorm,\n             non_linearity=tl.Relu):\n  """"""ResNet.\n\n  Args:\n    d_hidden: Dimensionality of the first hidden layer (multiplied later).\n    n_output_classes: Number of distinct output classes.\n    mode: Whether we are training or evaluating or doing inference.\n    norm: `Layer` used for normalization, Ex: BatchNorm or\n      FilterResponseNorm.\n    non_linearity: `Layer` used as a non-linearity, Ex: If norm is\n      BatchNorm then this is a Relu, otherwise for FilterResponseNorm this\n      should be ThresholdedLinearUnit.\n\n  Returns:\n    The list of layers comprising a ResNet model with the given parameters.\n  """"""\n\n  # A ConvBlock configured with the given norm, non-linearity and mode.\n  def Resnet50ConvBlock(filter_multiplier=1, strides=(2, 2)):\n    filters = (\n        [filter_multiplier * dim for dim in [d_hidden, d_hidden, 4 * d_hidden]])\n    return ConvBlock(3, filters, strides, norm, non_linearity, mode)\n\n  # Same as above for IdentityBlock.\n  def Resnet50IdentityBlock(filter_multiplier=1):\n    filters = (\n        [filter_multiplier * dim for dim in [d_hidden, d_hidden, 4 * d_hidden]])\n    return IdentityBlock(3, filters, norm, non_linearity, mode)\n\n  return tl.Serial(\n      tl.ToFloat(),\n      tl.Conv(d_hidden, (7, 7), (2, 2), \'SAME\'),\n      norm(mode=mode),\n      non_linearity(),\n      tl.MaxPool(pool_size=(3, 3), strides=(2, 2)),\n      Resnet50ConvBlock(strides=(1, 1)),\n      [Resnet50IdentityBlock() for _ in range(2)],\n      Resnet50ConvBlock(2),\n      [Resnet50IdentityBlock(2) for _ in range(3)],\n      Resnet50ConvBlock(4),\n      [Resnet50IdentityBlock(4) for _ in range(5)],\n      Resnet50ConvBlock(8),\n      [Resnet50IdentityBlock(8) for _ in range(2)],\n      tl.AvgPool(pool_size=(7, 7)),\n      tl.Flatten(),\n      tl.Dense(n_output_classes),\n      tl.LogSoftmax(),\n  )\n\n\ndef WideResnetBlock(channels, strides=(1, 1), bn_momentum=0.9, mode=\'train\'):\n  """"""WideResnet convolutional block.""""""\n  return [\n      tl.BatchNorm(momentum=bn_momentum, mode=mode),\n      tl.Relu(),\n      tl.Conv(channels, (3, 3), strides, padding=\'SAME\'),\n      tl.BatchNorm(momentum=bn_momentum, mode=mode),\n      tl.Relu(),\n      tl.Conv(channels, (3, 3), padding=\'SAME\'),\n  ]\n\n\ndef WideResnetGroup(n, channels, strides=(1, 1), bn_momentum=0.9, mode=\'train\'):\n  shortcut = [\n      tl.Conv(channels, (3, 3), strides, padding=\'SAME\'),\n  ]\n  return [\n      tl.Residual(WideResnetBlock(channels, strides, bn_momentum=bn_momentum,\n                                  mode=mode),\n                  shortcut=shortcut),\n      tl.Residual([WideResnetBlock(channels, (1, 1), bn_momentum=bn_momentum,\n                                   mode=mode)\n                   for _ in range(n - 1)]),\n  ]\n\n\ndef WideResnet(n_blocks=3, widen_factor=1, n_output_classes=10, bn_momentum=0.9,\n               mode=\'train\'):\n  """"""WideResnet from https://arxiv.org/pdf/1605.07146.pdf.\n\n  Args:\n    n_blocks: int, number of blocks in a group. total layers = 6n + 4.\n    widen_factor: int, widening factor of each group. k=1 is vanilla resnet.\n    n_output_classes: int, number of distinct output classes.\n    bn_momentum: float, momentum in BatchNorm.\n    mode: Whether we are training or evaluating or doing inference.\n\n  Returns:\n    The list of layers comprising a WideResnet model with the given parameters.\n  """"""\n  return tl.Serial(\n      tl.ToFloat(),\n      tl.Conv(16, (3, 3), padding=\'SAME\'),\n      WideResnetGroup(n_blocks, 16 * widen_factor, bn_momentum=bn_momentum,\n                      mode=mode),\n      WideResnetGroup(n_blocks, 32 * widen_factor, (2, 2),\n                      bn_momentum=bn_momentum, mode=mode),\n      WideResnetGroup(n_blocks, 64 * widen_factor, (2, 2),\n                      bn_momentum=bn_momentum, mode=mode),\n      tl.BatchNorm(momentum=bn_momentum, mode=mode),\n      tl.Relu(),\n      tl.AvgPool(pool_size=(8, 8)),\n      tl.Flatten(),\n      tl.Dense(n_output_classes),\n      tl.LogSoftmax(),\n  )\n'"
trax/models/resnet_test.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Resnet models.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\n\nfrom trax import math\nfrom trax import shapes\nfrom trax.models import resnet\n\n\nclass ResnetTest(absltest.TestCase):\n\n  def test_resnet(self):\n    model = resnet.Resnet50(d_hidden=8, n_output_classes=10)\n    x = np.ones((3, 256, 256, 3)).astype(np.float32)\n    _, _ = model.init(shapes.signature(x))\n    y = model(x)\n    self.assertEqual(y.shape, (3, 10))\n\n  def test_wide_resnet(self):\n    model = resnet.WideResnet(n_blocks=1, n_output_classes=10)\n    x = np.ones((3, 32, 32, 3)).astype(np.float32)\n    _, _ = model.init(shapes.signature(x))\n    y = model(x)\n    self.assertEqual(y.shape, (3, 10))\n\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/models/rl.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Policy networks.""""""\n\nfrom trax import layers as tl\nfrom trax import models\n\n\ndef Policy(\n    policy_distribution,\n    body=None,\n    normalizer=None,\n    head_init_range=None,\n    batch_axes=None,\n    mode=\'train\',\n):\n  """"""Attaches a policy head to a model body.""""""\n  if body is None:\n    body = lambda mode: []\n  if normalizer is None:\n    normalizer = lambda mode: []\n  if batch_axes is None:\n    batch = lambda x: x\n  else:\n    batch = lambda x: tl.BatchLeadingAxes(x, n_last_axes_to_keep=batch_axes)\n\n  head_kwargs = {}\n  if head_init_range is not None:\n    head_kwargs[\'kernel_initializer\'] = tl.RandomUniformInitializer(\n        lim=head_init_range\n    )\n\n  return tl.Serial(\n      batch(normalizer(mode=mode)),\n      batch(body(mode=mode)),\n      tl.Dense(policy_distribution.n_inputs, **head_kwargs),\n  )\n\n\ndef Value(\n    body=None,\n    normalizer=None,\n    inject_actions=False,\n    inject_actions_n_layers=1,\n    inject_actions_dim=64,\n    batch_axes=None,\n    mode=\'train\',\n    is_discrete=False,\n    vocab_size=2\n):\n  """"""Attaches a value head to a model body.""""""\n  if body is None:\n    body = lambda mode: []\n  if normalizer is None:\n    normalizer = lambda mode: []\n  if batch_axes is None:\n    batch = lambda x: x\n  else:\n    batch = lambda x: tl.BatchLeadingAxes(x, n_last_axes_to_keep=batch_axes)\n\n  def ActionInjector(mode):\n    if inject_actions:\n      if is_discrete:\n        encode_layer = tl.Parallel(\n            tl.Dense(inject_actions_dim),\n            tl.Embedding(inject_actions_dim, vocab_size=vocab_size))\n      else:\n        encode_layer = tl.Parallel(\n            tl.Dense(inject_actions_dim),\n            tl.Dense(inject_actions_dim),\n        )\n      return tl.Serial(\n          # Input: (body output, actions).\n          encode_layer,\n          tl.Add(),\n          models.PureMLP(\n              layer_widths=(inject_actions_dim,) * inject_actions_n_layers,\n              out_activation=True,\n              flatten=False,\n              mode=mode,\n          )\n      )\n    else:\n      return []\n\n  return tl.Serial(\n      batch(normalizer(mode=mode)),\n      batch(body(mode=mode)),\n      ActionInjector(mode=mode),\n      tl.Dense(1),\n  )\n\n\ndef PolicyAndValue(\n    policy_distribution,\n    body=None,\n    policy_top=Policy,\n    value_top=Value,\n    normalizer=None,\n    head_init_range=None,\n    mode=\'train\',\n):\n  """"""Attaches policy and value heads to a model body.""""""\n\n  head_kwargs = {}\n  if head_init_range is not None:\n    head_kwargs[\'kernel_initializer\'] = tl.RandomUniformInitializer(\n        lim=head_init_range\n    )\n\n  if normalizer is None:\n    normalizer = lambda mode: []\n  if body is None:\n    body = lambda mode: []\n  return tl.Serial(\n      normalizer(mode=mode),\n      body(mode=mode),\n      tl.Branch(\n          policy_top(policy_distribution=policy_distribution, mode=mode),\n          value_top(mode=mode),\n      ),\n  )\n'"
trax/models/rl_test.py,3,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for RL.""""""\n\nfrom unittest import mock\nfrom absl.testing import absltest\nimport numpy as np\n\nfrom trax import shapes\nfrom trax.models import rl\n\n\nclass RLTest(absltest.TestCase):\n\n  def test_policy_forward_shape(self):\n    mock_dist = mock.MagicMock()\n    mock_dist.n_inputs = 4\n    model = rl.Policy(policy_distribution=mock_dist)\n    x = np.ones((2, 3))\n    _, _ = model.init(shapes.signature(x))\n    y = model(x)\n    self.assertEqual(y.shape, (2, 4))\n\n  def test_value_forward_shape(self):\n    model = rl.Value()\n    x = np.ones((2, 3))\n    _, _ = model.init(shapes.signature(x))\n    y = model(x)\n    self.assertEqual(y.shape, (2, 1))\n\n  def test_policy_and_value_forward_shape(self):\n    mock_dist = mock.MagicMock()\n    mock_dist.n_inputs = 4\n    model = rl.PolicyAndValue(policy_distribution=mock_dist)\n    x = np.ones((2, 3))\n    _, _ = model.init(shapes.signature(x))\n    ys = model(x)\n    self.assertEqual([y.shape for y in ys], [(2, 4), (2, 1)])\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/models/rnn.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""RNNs.""""""\n\nfrom trax import layers as tl\nfrom trax.math import numpy as jnp\n\n\ndef RNNLM(vocab_size,\n          d_model=512,\n          n_layers=2,\n          rnn_cell=tl.LSTMCell,\n          rnn_cell_d_state_multiplier=2,\n          dropout=0.1,\n          mode=\'train\'):\n  """"""Returns an RNN language model.\n\n  The input to the model is a tensor of tokens (ints).\n\n  Args:\n    vocab_size: int: vocab size\n    d_model: int:  depth of embedding (n_units in the RNN cell)\n    n_layers: int: number of RNN layers\n    rnn_cell: the RNN cell\n    rnn_cell_d_state_multiplier: how many times is RNN cell state larger\n    dropout: float: dropout rate (how much to drop out)\n    mode: str: \'train\', \'eval\' or \'predict\', predict mode is for fast inference\n\n  Returns:\n    An RNN language model as a layer that maps from a tensor of tokens\n    to activations over a vocab set.\n  """"""\n  def MultiRNNCell():\n    """"""Multi-layer RNN cell.""""""\n    assert n_layers == 2\n    return tl.Serial(\n        tl.Parallel([], tl.Split(n_items=n_layers)),\n        tl.SerialWithSideOutputs(\n            [rnn_cell(n_units=d_model) for _ in range(n_layers)]),\n        tl.Parallel([], tl.Concatenate(n_items=n_layers))\n    )\n\n  zero_state = tl.MakeZeroState(  # pylint: disable=no-value-for-parameter\n      depth_multiplier=n_layers * rnn_cell_d_state_multiplier\n  )\n\n  return tl.Serial(\n      tl.ShiftRight(mode=mode),\n      tl.Embedding(d_model, vocab_size),\n      tl.Dropout(rate=dropout, name=\'embedding\', mode=mode),\n      tl.Branch([], zero_state),\n      tl.Scan(MultiRNNCell(), axis=1),\n      tl.Select([0], n_in=2),  # Drop RNN state.\n      tl.Dense(vocab_size),\n      tl.LogSoftmax()\n  )\n\n\ndef GRULM(vocab_size=256,\n          d_model=512,\n          n_layers=1,\n          mode=\'train\'):\n  """"""Returns an GRU language model.\n\n  The input to the model is a tensor of tokens (ints).\n\n  Args:\n    vocab_size: int: vocab size\n    d_model: int:  depth of embedding (n_units in the RNN cell)\n    n_layers: int: number of RNN layers\n    mode: str: \'train\', \'eval\' or \'predict\', predict mode is for fast inference\n\n  Returns:\n    An RNN language model as a layer that maps from a tensor of tokens\n    to activations over a vocab set.\n  """"""\n  return tl.Serial(\n      tl.ShiftRight(mode=mode),\n      tl.Embedding(d_model, vocab_size),\n      [tl.GRU(d_model) for _ in range(n_layers)],\n      tl.Dense(vocab_size),\n      tl.LogSoftmax()\n  )\n\n\ndef LSTMSeq2SeqAttn(input_vocab_size=256,\n                    target_vocab_size=256,\n                    d_model=512,\n                    n_encoder_layers=2,\n                    n_decoder_layers=2,\n                    n_attention_heads=1,\n                    attention_dropout=0.0,\n                    mode=\'train\'):\n  """"""Returns an LSTM sequence-to-sequence model with attention.\n\n  The input to the model is a pair (input tokens, target tokens), e.g.,\n  an English sentence (tokenized) and its translation into German (tokenized).\n\n  The model works as follows:\n  * Input encoder runs on the input tokens and creates activations that\n    are used as both keys and values in attention.\n  * Pre-attention decoder runs on the targets and creates\n    activations that are used as queries in attention.\n  * Attention runs on the queries, keys and values masking out input padding.\n  * Decoder runs on the result, followed by a cross-entropy loss.\n\n  Args:\n    input_vocab_size: int: vocab size of the input\n    target_vocab_size: int: vocab size of the target\n    d_model: int:  depth of embedding (n_units in the LSTM cell)\n    n_encoder_layers: int: number of LSTM layers in the encoder\n    n_decoder_layers: int: number of LSTM layers in the decoder after attention\n    n_attention_heads: int: number of attention heads\n    attention_dropout: float, dropout for the attention layer\n    mode: str: \'train\', \'eval\' or \'predict\', predict mode is for fast inference\n\n  Returns:\n    An LSTM sequence-to-sequence model with attention.\n  """"""\n  input_encoder = tl.Serial(\n      tl.Embedding(d_model, input_vocab_size),\n      [tl.LSTM(d_model) for _ in range(n_encoder_layers)],\n  )\n\n  pre_attention_decoder = tl.Serial(\n      tl.ShiftRight(mode=mode),\n      tl.Embedding(d_model, target_vocab_size),\n      tl.LSTM(d_model),\n  )\n\n  def PrepareAttentionInputs():\n    """"""Layer that prepares queries, keys, values and mask for attention.""""""\n    def F(encoder_activations, decoder_activations, input_tokens):\n      keys = values = encoder_activations\n      queries = decoder_activations\n      # Mask is 1 where inputs are not padding (0) and 0 where they are padding.\n      mask = (input_tokens != 0)\n      # We need to add axes to the mask for attention heads and decoder length.\n      mask = jnp.reshape(mask, (mask.shape[0], 1, 1, mask.shape[1]))\n      # Broadcast so mask is [batch, 1 for heads, decoder-len, encoder-len].\n      mask = mask + jnp.zeros((1, 1, decoder_activations.shape[1], 1))\n      return queries, keys, values, mask\n    return tl.Fn(\'PrepareAttentionInputs\', F, n_out=4)\n\n  return tl.Serial(              # in-toks, target-toks\n      tl.Select([0, 1, 0, 1]),   # in-toks, target-toks, in-toks, target-toks\n      tl.Parallel(input_encoder, pre_attention_decoder),\n      PrepareAttentionInputs(),  # q, k, v, mask, target-toks\n      tl.Residual(\n          tl.AttentionQKV(d_model, n_heads=n_attention_heads,\n                          dropout=attention_dropout, mode=mode)\n      ),                         # decoder-vecs, mask, target-toks\n      tl.Select([0, 2]),         # decoder-vecs, target-toks\n      [tl.LSTM(d_model) for _ in range(n_decoder_layers)],\n      tl.Dense(target_vocab_size),\n      tl.LogSoftmax()\n  )\n'"
trax/models/rnn_test.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for RNNs.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\n\nfrom trax import shapes\nfrom trax.models import rnn\n\n\nclass RNNTest(absltest.TestCase):\n\n  def test_rnnlm_forward_shape(self):\n    model = rnn.RNNLM(vocab_size=20, d_model=16)\n    x = np.ones((3, 28)).astype(np.int32)\n    _, _ = model.init(shapes.signature(x))\n    y = model(x)\n    self.assertEqual(y.shape, (3, 28, 20))\n\n  def test_grulm_forward_shape(self):\n    model = rnn.GRULM(vocab_size=20, d_model=16)\n    x = np.ones((3, 28)).astype(np.int32)\n    _, _ = model.init(shapes.signature(x))\n    y = model(x)\n    self.assertEqual(y.shape, (3, 28, 20))\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/models/transformer.py,5,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Transformer Models.""""""\n\nimport jax\n\nfrom trax import layers as tl\nfrom trax.math import numpy as jnp\n\n\ndef TransformerEncoder(vocab_size,\n                       n_classes=10,\n                       d_model=512,\n                       d_ff=2048,\n                       n_layers=6,\n                       n_heads=8,\n                       dropout=0.1,\n                       max_len=2048,\n                       mode=\'train\',\n                       ff_activation=tl.Relu):\n  """"""Returns a Transformer encoder model.\n\n  The input to the model is a tensor of tokens.\n\n  Args:\n    vocab_size: int: vocab size\n    n_classes: how many classes on output\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    n_layers: int: number of encoder/decoder layers\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    max_len: int: maximum symbol length for positional encoding\n    mode: str: \'train\' or \'eval\'\n    ff_activation: the non-linearity in feed-forward layer\n\n  Returns:\n    A Transformer model as a layer that maps from a tensor of tokens to\n    activations over a set of output classes.\n  """"""\n  positional_encoder = [\n      tl.Embedding(d_model, vocab_size),\n      tl.Dropout(rate=dropout, name=\'emb_dropout\', mode=mode),\n      tl.PositionalEncoding(max_len=max_len)]\n\n  encoder_blocks = [\n      _EncoderBlock(d_model, d_ff, n_heads, dropout, i, mode, ff_activation)\n      for i in range(n_layers)]\n\n  # Assemble and return the model.\n  return tl.Serial(                               # toks\n      # Encode.\n      tl.Branch(\n          positional_encoder, tl.PaddingMask()),  # vecs masks\n      encoder_blocks,                             # vecs masks\n      tl.Select([0], n_in=2),                     # vecs\n      tl.LayerNorm(),                             # vecs\n\n      # Map to output categories.\n      tl.Mean(axis=1),                            # vecs\n      tl.Dense(n_classes),                        # vecs\n      tl.LogSoftmax(),                            # vecs\n  )\n\n\ndef TransformerDecoder(vocab_size=None,\n                       d_model=512,\n                       d_ff=2048,\n                       n_layers=6,\n                       n_heads=8,\n                       dropout=0.1,\n                       max_len=2048,\n                       mode=\'train\',\n                       ff_activation=tl.Relu):\n  """"""Returns a Transformer decoder model.\n\n  The input to the model is either continuous or discrete - controlled by\n  vocab_size. Does not shift the input to the right, i.e. the output for\n  timestep t is based on inputs up to timestep t inclusively.\n\n  Args:\n    vocab_size: int or None: vocab size if running on discrete input, None\n      otherwise.\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    n_layers: int: number of encoder/decoder layers\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    max_len: int: maximum symbol length for positional encoding\n    mode: str: \'train\' or \'eval\'\n    ff_activation: the non-linearity in feed-forward layer\n\n  Returns:\n    A Transformer decoder as a layer that maps from a continuous or discrete\n    tensor to a continuous tensor.\n  """"""\n  positional_encoder = [\n      (tl.Embedding(d_model, vocab_size) if vocab_size is not None\n       else tl.Dense(d_model)),\n      tl.Dropout(rate=dropout, mode=mode),\n      tl.PositionalEncoding(max_len=max_len)]\n\n  decoder_blocks = [\n      # pylint: disable=g-complex-comprehension\n      _DecoderBlock(d_model, d_ff, n_heads,\n                    dropout, i, mode, ff_activation)\n      for i in range(n_layers)]\n\n  # Assemble and return the model.\n  return tl.Serial(        # toks\n      positional_encoder,  # vecs\n      decoder_blocks,      # vecs\n      tl.LayerNorm(),      # vecs\n  )\n\n\ndef TransformerLM(vocab_size,\n                  d_model=512,\n                  d_ff=2048,\n                  n_layers=6,\n                  n_heads=8,\n                  dropout=0.1,\n                  max_len=2048,\n                  mode=\'train\',\n                  ff_activation=tl.Relu):\n  """"""Returns a Transformer language model.\n\n  The input to the model is a tensor of tokens. (This model uses only the\n  decoder part of the overall Transformer.)\n\n  Args:\n    vocab_size: int: vocab size\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    n_layers: int: number of encoder/decoder layers\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    max_len: int: maximum symbol length for positional encoding\n    mode: str: \'train\', \'eval\' or \'predict\', predict mode is for fast inference\n    ff_activation: the non-linearity in feed-forward layer\n\n  Returns:\n    A Transformer language model as a layer that maps from a tensor of tokens\n    to activations over a vocab set.\n  """"""\n  positional_encoder = [\n      tl.Embedding(d_model, vocab_size),\n      tl.Dropout(rate=dropout, name=\'embedding\', mode=mode),\n      tl.PositionalEncoding(max_len=max_len, mode=mode)]\n\n  decoder_blocks = [\n      # pylint: disable=g-complex-comprehension\n      _DecoderBlock(d_model, d_ff, n_heads,\n                    dropout, i, mode, ff_activation)\n      for i in range(n_layers)]\n\n  # Assemble and return the model.\n  return tl.Serial(              # tokens (or chunked tuple of tokens)\n      tl.ShiftRight(mode=mode),  # toks\n      positional_encoder,        # vecs\n      decoder_blocks,            # vecs\n      tl.LayerNorm(),            # vecs\n      tl.Dense(vocab_size),      # vecs\n      tl.LogSoftmax(),           # vecs\n  )\n\n\ndef Transformer(input_vocab_size,\n                output_vocab_size=None,\n                d_model=512,\n                d_ff=2048,\n                n_encoder_layers=6,\n                n_decoder_layers=6,\n                n_heads=8,\n                dropout=0.1,\n                max_len=2048,\n                mode=\'train\',\n                ff_activation=tl.Relu):\n  """"""Returns a Transformer model.\n\n  This model expects an input pair: source, target.\n\n  Args:\n    input_vocab_size: int: vocab size of the source.\n    output_vocab_size: int (optional): vocab size of the target. If None, the\n      source and target are assumed to have the same vocab.\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    n_encoder_layers: int: number of encoder layers\n    n_decoder_layers: int: number of decoder layers\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    max_len: int: maximum symbol length for positional encoding\n    mode: str: \'train\' or \'eval\'\n    ff_activation: the non-linearity in feed-forward layer\n\n  Returns:\n    A Transformer model as a layer that maps from a source, target pair to\n    activations over a vocab set.\n  """"""\n  def PositionalEncoder(vocab_size):  # tokens --> vectors\n    return [\n        tl.Embedding(d_model, vocab_size),\n        tl.Dropout(rate=dropout, mode=mode),\n        tl.PositionalEncoding(max_len=max_len),\n    ]\n\n  in_encoder = PositionalEncoder(input_vocab_size)\n  out_encoder = (in_encoder if output_vocab_size is None\n                 else PositionalEncoder(output_vocab_size))\n  if output_vocab_size is None:\n    output_vocab_size = input_vocab_size\n\n  encoder_blocks = [\n      _EncoderBlock(\n          d_model, d_ff, n_heads, dropout, i, mode, ff_activation)\n      for i in range(n_encoder_layers)]\n\n  encoder = tl.Serial(\n      in_encoder,\n      encoder_blocks,\n      tl.LayerNorm()\n  )\n  if mode == \'predict\':\n    encoder = tl.Cache(encoder)\n\n  encoder_decoder_blocks = [\n      _EncoderDecoderBlock(\n          d_model, d_ff, n_heads, dropout, i, mode, ff_activation)\n      for i in range(n_decoder_layers)]\n\n  # Assemble and return the model.\n  return tl.Serial(\n      # Input: encoder_side_tokens, decoder_side_tokens\n      # Copy decoder tokens for use in loss.\n      tl.Select([0, 1, 1]),               # tok_e tok_d tok_d\n\n      # Encode.\n      tl.Branch([], tl.PaddingMask()),    # tok_e masks ..... .....\n      encoder,                            # vec_e ..... ..... .....\n\n      # Decode.\n      tl.Select([2, 1, 0]),               # tok_d masks vec_e .....\n      tl.ShiftRight(),                    # tok_d ..... ..... .....\n      out_encoder,                        # vec_d ..... ..... .....\n      tl.Branch(\n          [], tl.EncoderDecoderMask()),   # vec_d masks ..... .....\n      encoder_decoder_blocks,             # vec_d masks ..... .....\n      tl.LayerNorm(),                     # vec_d ..... ..... .....\n\n      # Map to output vocab.\n      tl.Select([0], n_in=3),             # vec_d tok_d\n      tl.Dense(output_vocab_size),        # vec_d .....\n      tl.LogSoftmax(),                    # vec_d .....\n  )\n\n\ndef TransformerNoEncDecAttention(input_vocab_size,\n                                 output_vocab_size=None,\n                                 d_model=512,\n                                 d_ff=2048,\n                                 n_encoder_layers=6,\n                                 n_decoder_layers=6,\n                                 n_heads=8,\n                                 dropout=0.1,\n                                 max_len=2048,\n                                 mode=\'train\',\n                                 ff_activation=tl.Relu):\n  """"""Returns a Transformer model.\n\n  This model expects an input pair: target, source.\n\n  Args:\n    input_vocab_size: int: vocab size of the source.\n    output_vocab_size: int (optional): vocab size of the target. If None, the\n      source and target are assumed to have the same vocab.\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    n_encoder_layers: int: number of encoder layers\n    n_decoder_layers: int: number of decoder layers\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    max_len: int: maximum symbol length for positional encoding\n    mode: str: \'train\' or \'eval\'\n    ff_activation: the non-linearity in feed-forward layer\n\n  Returns:\n    A Transformer model as a layer that maps from a target, source pair to\n    activations over a vocab set.\n  """"""\n  def PositionalEncoder(vocab_size):  # tokens --> vectors\n    return [\n        tl.Embedding(d_model, vocab_size),\n        tl.Dropout(rate=dropout, mode=mode),\n        tl.PositionalEncoding(max_len=max_len),\n    ]\n\n  in_encoder = PositionalEncoder(input_vocab_size)\n  out_encoder = (in_encoder if output_vocab_size is None\n                 else PositionalEncoder(output_vocab_size))\n  if output_vocab_size is None:\n    output_vocab_size = input_vocab_size\n\n  encoder_blocks = [\n      _EncoderBlock(\n          d_model, d_ff, n_heads, dropout, i, mode, ff_activation)\n      for i in range(n_encoder_layers)]\n\n  encoder = tl.Serial(\n      in_encoder,\n      encoder_blocks,\n      tl.LayerNorm()\n  )\n  if mode == \'predict\':\n    encoder = tl.Cache(encoder)\n\n  decoder_blocks = [\n      # pylint: disable=g-complex-comprehension\n      _DecoderBlock(d_model, d_ff, n_heads,\n                    dropout, i, mode, ff_activation)\n      for i in range(n_decoder_layers)]\n\n  # Assemble and return the model.\n  return tl.Serial(\n      # Input: encoder_side_tokens, decoder_side_tokens\n      # Copy decoder tokens for use in loss.\n      tl.Select([0, 0, 1, 1]),            # tok_e tok_e tok_d tok_d\n\n      # Encode.\n      tl.Branch([], tl.PaddingMask()),    # tok_e mask_e tok_e tok_d tok_d\n      encoder,                            # vec_e mask_e tok_e tok_d tok_d\n\n      # Simple encoder mask, doesn\'t contain extra dims.\n      tl.Select([2, 0, 2], n_in=3),       # tok_e vec_e tok_e tok_d tok_d\n      _MaskOfRightShiftedArray(\n          n_shifts=0),                    # mask_e vec_e tok_e tok_d tok_d\n\n      # Decode.\n      tl.Select([3, 1, 0, 2]),          #  tok_d vec_e mask_e tok_e tok_d\n      tl.ShiftRight(),                  # stok_d vec_e mask_e tok_e tok_d\n      tl.Branch(\n          [],\n          _MaskOfRightShiftedArray()\n      ),                                # stok_d mask_d vec_e mask_e tok_e tok_d\n      out_encoder,                      # svec_d mask_d vec_e mask_e tok_e tok_d\n\n      # Concat encoder and decoder.\n      tl.Select([2, 0, 3, 1]),          # vec_e svec_d mask_e mask_d tok_e tok_d\n      _ConcatWithPadding(),             # vec_ed tok_e tok_d\n\n      # Decoder blocks with causal attention\n      decoder_blocks,                     # vec_ed tok_e tok_d\n      tl.LayerNorm(),                     # vec_ed tok_e tok_d\n\n      # Separate out the encoder part from the concatenated vector.\n      tl.Select([0, 1, 2, 2]),               # vec_ed tok_e tok_d tok_d\n      _StripFromConcatenateWithPadding(),    # vec_d tok_d\n\n      # Map to output vocab.\n      tl.Dense(output_vocab_size),        # vec_d tok_d\n      tl.LogSoftmax(),                    # vec_d tok_d\n  )\n\n\ndef _EncoderBlock(d_model, d_ff, n_heads, dropout, layer_idx, mode,\n                  ff_activation):\n  """"""Returns a list of layers that implements a Transformer encoder block.\n\n  The input to the layer is a pair, (activations, mask), where the mask was\n  created from the original source tokens to prevent attending to the padding\n  part of the input.\n\n  Args:\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    layer_idx: which layer are we at (for bookkeeping)\n    mode: str: \'train\' or \'eval\'\n    ff_activation: the non-linearity in feed-forward layer\n\n  Returns:\n    A list of layers that maps (activations, mask) to (activations, mask).\n  """"""\n  attention = tl.Attention(\n      d_model, n_heads=n_heads, dropout=dropout, mode=mode)\n\n  dropout_ = tl.Dropout(\n      rate=dropout, name=\'dropout_enc_attn\', mode=mode)\n\n  feed_forward = _FeedForwardBlock(\n      d_model, d_ff, dropout, layer_idx, mode, ff_activation)\n\n  return [\n      tl.Residual(\n          tl.LayerNorm(),\n          attention,\n          dropout_,\n      ),\n      tl.Residual(\n          feed_forward\n      ),\n  ]\n\n\ndef _DecoderBlock(d_model, d_ff, n_heads,\n                  dropout, layer_idx, mode, ff_activation):\n  """"""Returns a list of layers that implements a Transformer decoder block.\n\n  The input is an activation tensor.\n\n  Args:\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    layer_idx: which layer are we at (for bookkeeping)\n    mode: str: \'train\' or \'eval\'\n    ff_activation: the non-linearity in feed-forward layer\n\n  Returns:\n    A list of layers that maps an activation tensor to an activation tensor.\n  """"""\n  causal_attention = tl.CausalAttention(\n      d_model, n_heads=n_heads, dropout=dropout, mode=mode),\n\n  dropout_ = tl.Dropout(\n      rate=dropout, name=\'attention_%d\' % layer_idx, mode=mode)\n\n  feed_forward = _FeedForwardBlock(\n      d_model, d_ff, dropout, layer_idx, mode, ff_activation)\n\n  return [\n      tl.Residual(\n          tl.LayerNorm(),\n          causal_attention,\n          dropout_,\n      ),\n      tl.Residual(\n          feed_forward\n      ),\n  ]\n\n\ndef _EncoderDecoderBlock(d_model, d_ff, n_heads, dropout, layer_idx, mode,\n                         ff_activation):\n  """"""Returns a list of layers implementing a Transformer encoder-decoder block.\n\n  The input is a triple (decoder_input, mask, encoder) where the mask is\n  created from the original source to prevent attending to the padding part\n  of the encoder.\n\n  Args:\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    layer_idx: which layer are we at (for bookkeeping)\n    mode: str: \'train\' or \'eval\'\n    ff_activation: the non-linearity in feed-forward layer\n\n  Returns:\n    A list of layers which maps triples (decoder_activations, mask,\n    encoder_activations) to triples of the same sort.\n  """"""\n  def _Dropout():\n    return tl.Dropout(rate=dropout, mode=mode)\n\n  attention_qkv = tl.AttentionQKV(\n      d_model, n_heads=n_heads, dropout=dropout, mode=mode)\n\n  causal_attention = tl.CausalAttention(\n      d_model, n_heads=n_heads, mode=mode)\n\n  feed_forward = _FeedForwardBlock(\n      d_model, d_ff, dropout, layer_idx, mode, ff_activation)\n\n  return [                             # vec_d masks vec_e\n      tl.Residual(\n          tl.LayerNorm(),              # vec_d ..... .....\n          causal_attention,            # vec_d ..... .....\n          _Dropout(),                  # vec_d ..... .....\n      ),\n      tl.Residual(\n          tl.LayerNorm(),              # vec_d ..... .....\n          tl.Select([0, 2, 2, 1, 2]),  # vec_d vec_e vec_e masks vec_e\n          attention_qkv,               # vec_d masks vec_e\n          _Dropout(),                  # vec_d masks vec_e\n      ),\n      tl.Residual(\n          feed_forward                 # vec_d masks vec_e\n      ),\n  ]\n\n\ndef _FeedForwardBlock(d_model, d_ff, dropout, layer_idx, mode, activation):\n  """"""Returns a list of layers implementing a feed-forward block.\n\n  Args:\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    dropout: float: dropout rate (how much to drop out)\n    layer_idx: which layer are we at (for bookkeeping)\n    mode: str: \'train\' or \'eval\'\n    activation: the non-linearity in feed-forward layer\n\n  Returns:\n    A list of layers which maps vectors to vectors.\n  """"""\n  dropout_middle = tl.Dropout(\n      rate=dropout, name=\'ff_middle_%d\' % layer_idx, mode=mode)\n  dropout_final = tl.Dropout(\n      rate=dropout, name=\'ff_final_%d\' % layer_idx, mode=mode)\n\n  return [\n      tl.LayerNorm(),\n      tl.Dense(d_ff),\n      activation(),\n      dropout_middle,\n      tl.Dense(d_model),\n      dropout_final,\n  ]\n\n\ndef _ConcatWithPadding():\n  """"""Concatenates two length padded (B, L, H) arrays (of different lenghts).""""""\n\n  # Arg shapes: (B, L1, H), (B, L2, H), (B, L1) & (B, L2)\n  def __ConcatWithPadding(vec_e, vec_d, mask_e, mask_d):\n    # pylint: disable=invalid-name\n    B, L1, H = vec_e.shape\n    L2 = vec_d.shape[1]\n    # pylint: enable=invalid-name\n\n    assert (B, L2, H) == vec_d.shape, f\'{(B, L2, H)} != {vec_e.shape}\'\n    assert (B, L1) == mask_e.shape, f\'{(B, L1)} != {mask_e.shape}\'\n    assert (B, L2) == mask_d.shape, f\'{(B, L2)} != {mask_d.shape}\'\n\n    def _UpdateRow(x):\n      # row_e - (L1, H), row_d - (L2, H), row_mask_e - (L1,)\n      row_e, row_d, row_mask_e = x\n      # final_row - (L1+L2, H)\n      final_row = jnp.concatenate([row_e, jnp.zeros_like(row_d)], axis=0)\n      # Find the last real token/vector of the encoder.\n      e_idx = jnp.sum(row_mask_e, dtype=jnp.int32)\n      # Starting after that index, update with the decoder row.\n      return jax.lax.dynamic_update_slice(final_row, row_d, (e_idx, 0))\n\n    return jax.lax.map(_UpdateRow, [vec_e, vec_d, mask_e])\n\n  return tl.Fn(\'ConcatWithPadding\', __ConcatWithPadding, n_out=1)\n\n\ndef _MaskOfRightShiftedArray(n_shifts=1, mode=\'train\'):\n  """"""Gives us the mask of a right shifted by n_shifts array.""""""\n\n  def F(x):\n    # TODO(afrozm): What to do in this case?\n    if mode == \'predict\':\n      raise ValueError(\'MaskOfRightShiftedArray not implemented for predict.\')\n\n    mask = x != 0\n\n    if n_shifts == 0:\n      return mask\n\n    # Need to set (B, n_shifts, ...) section to True.\n    trues_shape = (x.shape[0], n_shifts) + mask.shape[2:]\n    trues = jnp.full(trues_shape, True)\n    return jnp.concatenate([trues, mask[:, n_shifts:, ...]], axis=1)\n  return tl.Fn(f\'MaskOfRightShiftedArray({n_shifts})\', F)\n\n\ndef _StripFromConcatenateWithPadding():\n  """"""Strip out the leading encoder tokens from the concatenated array.""""""\n\n  def _StripEncToks(vec_ed, tok_e, tok_d):\n    # pylint: disable=invalid-name\n    B, L, H = vec_ed.shape\n    L1 = tok_e.shape[1]\n    L2 = tok_d.shape[1]\n    # pylint: enable=invalid-name\n    assert L == L1 + L2\n    assert (B, L1) == tok_e.shape\n    assert (B, L2) == tok_d.shape\n\n    def _UpdateRow(x):\n      # (L, H), (L1, H) & (L2, H)\n      row_ed, row_e, _ = x\n      mask_e = row_e != 0\n      len_e = jnp.sum(mask_e, dtype=jnp.int32)\n      # In `row_ed` start where encoder tokens/vecs end, i.e. are index `len_e`\n      # and pick up (L2, H) tensor slice from there.\n      return jax.lax.dynamic_slice(row_ed, (len_e, 0), (L2, H))\n\n    return jax.lax.map(_UpdateRow, [vec_ed, tok_e, tok_d])\n\n  return tl.Fn(\'StripFromConcatenateWithPadding\', _StripEncToks, n_out=1)\n\n\n'"
trax/models/transformer_test.py,29,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Transformer models.""""""\n\nimport functools\n\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\nimport numpy as np\n\nfrom trax import math\nfrom trax import shapes\nfrom trax.models import transformer\n\n\nclass TransformerTest(parameterized.TestCase):\n\n  def test_transformer_lm_forward_shape(self):\n    vocab_size = 16\n    model = transformer.TransformerLM(\n        vocab_size, d_model=32, d_ff=64, n_layers=2, n_heads=2)\n    x = np.ones((3, 5)).astype(np.int32)\n    _, _ = model.init(shapes.signature(x))\n    y = model(x)\n    self.assertEqual(y.shape, (3, 5, vocab_size))\n\n  def _test_transformer_forward_shape(self, input_vocab_size,\n                                      output_vocab_size):\n    model = transformer.Transformer(\n        input_vocab_size, output_vocab_size, d_model=32, d_ff=64,\n        n_encoder_layers=2, n_decoder_layers=2, n_heads=2)\n    xs = [np.ones((3, 5)).astype(np.int32), np.ones((3, 5)).astype(np.int32)]\n    _, _ = model.init(shapes.signature(xs))\n    y, _ = model(xs)\n\n    vocab_size = output_vocab_size or input_vocab_size\n    self.assertEqual(y.shape, (3, 5, vocab_size))\n\n  def test_transformer_noencdec_forward_shape(self):\n    input_vocab_size = 16\n    output_vocab_size = 16\n\n    model = transformer.TransformerNoEncDecAttention(\n        input_vocab_size, output_vocab_size, d_model=32, d_ff=64,\n        n_encoder_layers=2, n_decoder_layers=2, n_heads=2)\n\n    enc_toks = np.array(\n        [[6, 2, 0, 0, 0, 0],\n         [6, 3, 7, 0, 0, 0]])\n    dec_toks = np.array(\n        [[4, 2, 0, 0],\n         [8, 5, 0, 0]])\n\n    xs = [enc_toks, dec_toks]\n    _, _ = model.init(shapes.signature(xs))\n\n    # decoder output, decoder mask\n    ys = model(xs)\n\n    # (B, L2, H)\n    self.assertEqual(ys[0].shape,\n                     (dec_toks.shape[0], dec_toks.shape[1], output_vocab_size))\n\n    self.assertEqual(ys[1].shape, dec_toks.shape)\n\n  @parameterized.named_parameters(\n      (\'same_vocab\', 16, None),\n      (\'same_size\', 16, 16),\n      (\'different_size\', 16, 50))\n  def test_transformer_forward_shape(self, input_vocab_size, output_vocab_size):\n    """"""Run the Transformer forward and check output shape.""""""\n    self._test_transformer_forward_shape(input_vocab_size, output_vocab_size)\n\n\n  def _test_fast_inference(self, length):\n    with math.use_backend(\'jax\'):\n      vocab_size = 16\n      model_fn = functools.partial(\n          transformer.TransformerLM,\n          vocab_size=vocab_size, d_model=4, d_ff=8, n_layers=2, n_heads=2,\n      )\n      model_slow = model_fn(mode=\'eval\')\n      model_fast = model_fn(mode=\'predict\')\n      rng = math.random.get_prng(0)\n      batch_size = 2\n      input_signature = shapes.ShapeDtype((batch_size, 1), np.int32)\n      # Given the same rng, both models initialize with the same parameters.\n      model_slow.init(input_signature, rng)\n      model_fast.init(input_signature, rng)\n\n      buf = np.zeros((batch_size, length), dtype=np.int32)\n      next_sym = np.zeros((batch_size, 1), dtype=np.int32)\n\n      for index in range(length):\n        logits_slow = model_slow(buf, rng=rng)\n        logits_fast = model_fast(next_sym, rng=rng)\n        np.testing.assert_array_almost_equal(\n            logits_slow[:, index, :], logits_fast[:, 0, :],\n            decimal=5,\n        )\n        next_sym = np.random.randint(vocab_size, size=(batch_size, 1))\n        buf[:, index] = next_sym[:, 0]\n\n  def test_dot_product_causal_attention_fast_inference(self):\n    self._test_fast_inference(length=5)\n\n  def test_concat_with_padding(self):\n    vec_e = np.array(\n        [[[7, 5, 2, 8, 8, 8, 6, 7],\n          [8, 2, 6, 2, 1, 1, 4, 2],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0]],\n\n         [[4, 3, 1, 7, 5, 6, 2, 1],\n          [6, 9, 9, 4, 1, 3, 2, 1],\n          [3, 8, 2, 4, 7, 9, 4, 1],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0]]]\n    )\n\n    # vec_e[:,:,0] != 0\n    mask_e = np.array([[True, True, False, False, False, False],\n                       [True, True, True, False, False, False]])\n\n    vec_d = np.array(\n        [[[4, 7, 7, 4, 8, 9, 9, 9],\n          [6, 8, 2, 9, 3, 6, 6, 8],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0]],\n\n         [[3, 7, 5, 6, 2, 9, 3, 1],\n          [4, 7, 3, 2, 1, 1, 1, 6],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0]]]\n    )\n\n    mask_d = np.array(\n        [[True, True, False, False],\n         [True, True, False, False]])\n\n    layer = transformer._ConcatWithPadding()\n    y = layer((vec_e, vec_d, mask_e, mask_d))\n\n    np.testing.assert_equal(\n        y,\n        np.array(\n            [[[7, 5, 2, 8, 8, 8, 6, 7],\n              [8, 2, 6, 2, 1, 1, 4, 2],\n              [4, 7, 7, 4, 8, 9, 9, 9],\n              [6, 8, 2, 9, 3, 6, 6, 8],\n              [0, 0, 0, 0, 0, 0, 0, 0],\n              [0, 0, 0, 0, 0, 0, 0, 0],\n              [0, 0, 0, 0, 0, 0, 0, 0],\n              [0, 0, 0, 0, 0, 0, 0, 0],\n              [0, 0, 0, 0, 0, 0, 0, 0],\n              [0, 0, 0, 0, 0, 0, 0, 0]],\n\n             [[4, 3, 1, 7, 5, 6, 2, 1],\n              [6, 9, 9, 4, 1, 3, 2, 1],\n              [3, 8, 2, 4, 7, 9, 4, 1],\n              [3, 7, 5, 6, 2, 9, 3, 1],\n              [4, 7, 3, 2, 1, 1, 1, 6],\n              [0, 0, 0, 0, 0, 0, 0, 0],\n              [0, 0, 0, 0, 0, 0, 0, 0],\n              [0, 0, 0, 0, 0, 0, 0, 0],\n              [0, 0, 0, 0, 0, 0, 0, 0],\n              [0, 0, 0, 0, 0, 0, 0, 0]]]\n        )\n    )\n\n  def test_strip_from_concatenate_with_padding(self):\n    enc_dec = np.array(\n        [[[7, 5, 2, 8, 8, 8, 6, 7],\n          [8, 2, 6, 2, 1, 1, 4, 2],\n          [4, 7, 7, 4, 8, 9, 9, 9],\n          [6, 8, 2, 9, 3, 6, 6, 8],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0]],\n\n         [[4, 3, 1, 7, 5, 6, 2, 1],\n          [6, 9, 9, 4, 1, 3, 2, 1],\n          [3, 8, 2, 4, 7, 9, 4, 1],\n          [3, 7, 5, 6, 2, 9, 3, 1],\n          [4, 7, 3, 2, 1, 1, 1, 6],\n          [4, 7, 3, 2, 1, 1, 1, 6],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 0, 0, 0, 0]]]\n    )\n\n    tok_e = np.array([[7, 8, 0, 0, 0, 0], [4, 6, 3, 0, 0, 0]])\n    tok_d = np.array([[4, 6, 0, 0], [3, 4, 1, 0]])\n\n    layer = transformer._StripFromConcatenateWithPadding()\n    y = layer((enc_dec, tok_e, tok_d))\n\n    np.testing.assert_equal(\n        y,\n        np.array([[[4, 7, 7, 4, 8, 9, 9, 9],\n                   [6, 8, 2, 9, 3, 6, 6, 8],\n                   [0, 0, 0, 0, 0, 0, 0, 0],\n                   [0, 0, 0, 0, 0, 0, 0, 0]],\n                  [[3, 7, 5, 6, 2, 9, 3, 1],\n                   [4, 7, 3, 2, 1, 1, 1, 6],\n                   [4, 7, 3, 2, 1, 1, 1, 6],\n                   [0, 0, 0, 0, 0, 0, 0, 0]]]))\n\n  def test_mask_of_right_shift_unshifted(self):\n    layer = transformer._MaskOfRightShiftedArray(n_shifts=0)\n    x = np.array(\n        [[9, 8, 7, 0],\n         [1, 2, 0, 0]]\n        )\n    y = layer(x)\n    np.testing.assert_equal(\n        y,\n        np.array([[True, True, True, False],\n                  [True, True, False, False]]))\n\n  def test_mask_of_right_shift(self):\n    layer = transformer._MaskOfRightShiftedArray(n_shifts=2)\n    x = np.array(\n        [[0, 0, 9, 8, 7, 0],\n         [0, 0, 1, 2, 0, 0]]\n        )\n    y = layer(x)\n    np.testing.assert_equal(\n        y,\n        np.array([[True, True, True, True, True, False],\n                  [True, True, True, True, False, False]]))\n\n  def test_mask_of_right_shift_3dims(self):\n    layer = transformer._MaskOfRightShiftedArray(n_shifts=2)\n\n    # pylint: disable=bad-whitespace\n    x = np.array(\n        [[[ 0,  0],\n          [ 0,  0],\n          [ 1,  2],\n          [ 3,  4],\n          [ 5,  6],\n          [ 7,  8],\n          [ 9, 10],\n          [ 0,  0],\n          [ 0,  0]],\n\n         [[ 0,  0],\n          [ 0,  0],\n          [11, 12],\n          [13, 14],\n          [15, 16],\n          [17, 18],\n          [19, 20],\n          [ 0,  0],\n          [ 0,  0]]]\n    )\n    # pylint: enable=bad-whitespace\n\n    y = layer(x)\n    np.testing.assert_equal(\n        y,\n        # pylint: disable=bad-whitespace\n        np.array(\n            [[[ True,  True],\n              [ True,  True],\n              [ True,  True],\n              [ True,  True],\n              [ True,  True],\n              [ True,  True],\n              [ True,  True],\n              [ False, False],\n              [ False, False]],\n\n             [[ True,  True],\n              [ True,  True],\n              [ True,  True],\n              [ True,  True],\n              [ True,  True],\n              [ True,  True],\n              [ True,  True],\n              [ False, False],\n              [ False, False]]]\n        )\n        # pylint: enable=bad-whitespace\n    )\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/optimizers/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Optimizers for use with Trax layers.""""""\n\nimport gin\n\nfrom trax.optimizers import adafactor\nfrom trax.optimizers import adam\nfrom trax.optimizers import base\nfrom trax.optimizers import momentum\nfrom trax.optimizers import rms_prop\nfrom trax.optimizers import sm3\n\n\ndef opt_configure(*args, **kwargs):\n  kwargs[\'module\'] = \'trax.optimizers\'\n  return gin.external_configurable(*args, **kwargs)\n\n# Optimizers (using upper-case names).\n# pylint: disable=invalid-name\nSGD = opt_configure(base.SGD)\nMomentum = opt_configure(momentum.Momentum)\nRMSProp = opt_configure(rms_prop.RMSProp)\nAdam = opt_configure(adam.Adam)\nAdafactor = opt_configure(adafactor.Adafactor)\nSM3 = opt_configure(sm3.SM3)\n'"
trax/optimizers/adafactor.py,13,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Adafactor optimizer class.""""""\n\nfrom trax.math import numpy as np\nfrom trax.optimizers import base as opt_base\n\n\nclass Adafactor(opt_base.Optimizer):\n  """"""Adafactor optimizer.""""""\n\n  def __init__(self,\n               learning_rate,\n               factored=True,\n               multiply_by_parameter_scale=True,\n               do_clipping=True,\n               do_momentum=False,\n               beta1=0.0,\n               decay_rate=0.8,\n               clipping_threshold=1.0,\n               weight_decay_rate=1e-5,\n               epsilon1=1e-30,\n               epsilon2=1e-3):\n    """"""Create the Adafactor optimizer.\n\n    Adafactor is described in https://arxiv.org/abs/1804.04235.\n\n    Args:\n      learning_rate: float: trax-provided learning rate.\n      factored: boolean: whether to use factored second-moment estimator for 2d\n        variables.\n      multiply_by_parameter_scale: boolean: if True, then scale provided\n        learning_rate by parameter norm. if False, provided learning_rate is\n        absolute step size.\n      do_clipping: whether to clip gradients; if True, set clipping_theshold.\n      do_momentum: whether to use momentum; if True, set beta1.\n      beta1: a float value between 0 and 1, enables momentum and uses extra\n        memory if nonzero!  Off by default.\n      decay_rate: float: controls second-moment exponential decay schedule.\n      clipping_threshold: an optional float >= 1, if None no update clipping.\n      weight_decay_rate: rate at which to decay weights.\n      epsilon1: Regularization constant for squared gradient.\n      epsilon2: Regularization constant for parameter scale.\n    """"""\n    # These 4 parameters are not configurable once the class is created.\n    self._factored = factored\n    self._multiply_by_parameter_scale = multiply_by_parameter_scale\n    self._do_clipping = do_clipping\n    self._do_momentum = do_momentum\n    # Dynamically configurable parameters will be passed to the update function.\n    super(Adafactor, self).__init__(\n        learning_rate=learning_rate,\n        beta1=beta1,\n        decay_rate=decay_rate,\n        clipping_threshold=clipping_threshold,\n        weight_decay_rate=weight_decay_rate,\n        epsilon1=epsilon1,\n        epsilon2=epsilon2,\n    )\n\n  @staticmethod\n  def _decay_rate_pow(i, exponent=0.8):\n    """"""Default Adafactor second-moment decay schedule.""""""\n    t = np.array(i, np.float32) + 1.0\n    return 1.0 - t**(-exponent)\n\n  def init(self, weights):\n    shape = weights.shape\n    slots = []\n    if self._factored and len(shape) >= 2:\n      v_row = np.zeros(shape[:-1], dtype=np.float32)\n      v_col = np.zeros(shape[:-2] + shape[-1:], dtype=np.float32)\n      slots.extend([v_row, v_col])\n    else:\n      v = np.zeros_like(weights)\n      slots.append(v)\n    if self._do_momentum:\n      m = np.zeros_like(weights)\n      slots.append(m)\n    return slots\n\n  def update(self, step, grads, weights, slots, opt_params):\n    updates = []\n    learning_rate = opt_params[\'learning_rate\']\n    beta1 = opt_params[\'beta1\']\n    decay_rate = opt_params[\'decay_rate\']\n    clipping_threshold = opt_params[\'clipping_threshold\']\n    weight_decay_rate = opt_params[\'weight_decay_rate\']\n    epsilon1 = opt_params[\'epsilon1\']\n    epsilon2 = opt_params[\'epsilon2\']\n    decay_rate = self._decay_rate_pow(step, exponent=decay_rate)\n    update_scale = learning_rate\n    if self._multiply_by_parameter_scale:\n      update_scale *= np.maximum(\n          np.sqrt(np.mean(weights * weights)), epsilon2)\n    mixing_rate = 1.0 - decay_rate\n\n    grads_sqr = grads * grads + epsilon1\n    if self._factored and len(weights.shape) >= 2:\n      v_row = slots.pop(0)\n      v_col = slots.pop(0)\n      new_v_row = decay_rate * v_row + mixing_rate * np.mean(grads_sqr, axis=-1)\n      new_v_col = decay_rate * v_col + mixing_rate * np.mean(grads_sqr, axis=-2)\n      updates.extend([new_v_row, new_v_col])\n      row_col_mean = np.mean(new_v_row, axis=-1, keepdims=True)\n      row_factor = (new_v_row / row_col_mean)**-0.5\n      col_factor = (new_v_col)**-0.5\n      y = (\n          grads * np.expand_dims(row_factor, axis=-1) *\n          np.expand_dims(col_factor, axis=-2))\n    else:\n      v = slots.pop(0)\n      new_v = decay_rate * v + mixing_rate * grads_sqr\n      updates.append(new_v)\n      y = grads * (new_v)**-0.5\n\n    if self._do_clipping:\n      clipping_denom = (\n          np.maximum(1.0, np.sqrt(np.mean(y * y)) / clipping_threshold))\n      y /= clipping_denom\n\n    subtrahend = update_scale * y\n    if self._do_momentum:\n      m = slots.pop(0)\n      new_m = beta1 * m + (1.0 - beta1) * subtrahend\n      subtrahend = new_m\n      updates.append(new_m)\n\n    new_weights = (1 - weight_decay_rate) * weights - subtrahend\n    # TODO(lukaszkaiser): why is the astype needed here? Check and correct.\n    return new_weights.astype(weights.dtype), updates\n'"
trax/optimizers/adam.py,3,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Adam optimizer class.""""""\n\nfrom trax.math import numpy as np\nfrom trax.optimizers import base as opt_base\n\n\nclass Adam(opt_base.Optimizer):\n  """"""Adam optimizer.""""""\n\n  def __init__(self, learning_rate, weight_decay_rate=1e-5,  # pylint: disable=useless-super-delegation\n               b1=0.9, b2=0.999, eps=1e-5, clip_grad_norm=None):\n    """"""Create the Adam optimizer.\n\n    Args:\n      learning_rate: a postitive scalar value for the initial learning rate.\n      weight_decay_rate: rate at which to decay weights.\n      b1: optional, a positive scalar value for beta_1, the exponential decay\n        rate for the first moment estimates (default 0.9).\n      b2: optional, a positive scalar value for beta_2, the exponential decay\n         rate for the second moment estimates (default 0.999).\n      eps: optional, a positive scalar value for epsilon, a small constant for\n        numerical stability (default 1e-5).\n      clip_grad_norm: the number used for gradient clipping.\n    """"""\n    super(Adam, self).__init__(\n        learning_rate=learning_rate,\n        weight_decay_rate=weight_decay_rate,\n        b1=b1,\n        b2=b2,\n        eps=eps,\n        clip_grad_norm=clip_grad_norm\n    )\n\n  def init(self, weights):\n    m = np.zeros_like(weights)\n    v = np.zeros_like(weights)\n    return m, v\n\n  def update(self, step, grads, weights, slots, opt_params):\n    m, v = slots\n    learning_rate = opt_params[\'learning_rate\']\n    weight_decay_rate = opt_params[\'weight_decay_rate\']\n    b1 = opt_params[\'b1\']\n    b2 = opt_params[\'b2\']\n    eps = opt_params[\'eps\']\n    m = (1 - b1) * grads + b1 * m  # First  moment estimate.\n    v = (1 - b2) * (grads ** 2) + b2 * v  # Second moment estimate.\n    mhat = m / (1 - b1 ** (step + 1))  # Bias correction.\n    vhat = v / (1 - b2 ** (step + 1))\n    new_weights = (1 - weight_decay_rate) * weights - (\n        learning_rate * mhat / (np.sqrt(vhat) + eps)).astype(weights.dtype)\n    return new_weights, (m, v)\n'"
trax/optimizers/base.py,9,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Trax base optimizer class.""""""\n\nfrom trax import math\nfrom trax.layers import base as layers\nfrom trax.math import numpy as np\n\n\nclass Optimizer(object):\n  """"""Base class for optimizers that work hand in hand with Trax layers.\n\n  To define an optimizer subclass, specify its behavior with respect to a\n  single level/node in the network (e.g., a single dense layer):\n\n    - `init`: how to create/initialize optimizer-internal weights (""slots"")\n        whose shape matches the node\'s weight shape.\n    - `update`: how to use gradient information to update node weights and\n        optimizer slots.\n\n  The Trax runtime combines these node-local computations into weight updates\n  and slot updates for the whole tree of layers in the model.\n  """"""\n\n  def __init__(self, learning_rate, clip_grad_norm=None, **init_opt_params):\n    """"""Sets initial hyperparameter values for this optimizer.\n\n    Takes initial optimizer parameters as keyword arguments. These values can\n    be changed between training steps, e.g., for learning rate schedules.\n\n    If you want your subclass to expose hyperparameters for gin configuration,\n    override this constructor and use explicitly named keyword arguments. See\n    `momentum.Momentum.__init__` for one such example.\n\n    Args:\n      learning_rate: The initial learning rate.\n      clip_grad_norm: float; the value to which gradients will be clipped.\n      **init_opt_params: Initial values of any additional optimizer parameters.\n    """"""\n    init_opt_params[\'learning_rate\'] = learning_rate\n    self._init_opt_params = {\n        name: np.array(value) for (name, value) in init_opt_params.items()\n    }\n    self._slots = None\n    # Gradient clipping happens with respect to the norm of the whole gradient\n    # tree, so it is not passed to single-slot updates, but done in this class\n    # for the whole gradient tree.\n    self._clip_grad_norm = clip_grad_norm\n\n  def init(self, weights):\n    """"""Creates optimizer slots for the given parameters.\n\n    Args:\n      weights: Trainable weights for one layer. Optimizer slots typically match\n          the data shape and type of the given layer weights.\n    """"""\n    raise NotImplementedError\n\n  def update(self, step, grads, weights, slots, opt_params):\n    """"""Computes one step\'s worth of updates.\n\n    The update computes both new weights for the layer/node and new slot values\n    for the optimizer.\n\n    Args:\n      step: Current step number in the training process.\n      grads: Gradients for the weights of the sublayer.\n      weights: Current weights for the sublayer.\n      slots: Optimizer slots.\n      opt_params: Optimizer hyperparameters (e.g. learning rate, momentum).\n\n    Returns:\n      Tuple of (new_weights, new_slots).\n    """"""\n    raise NotImplementedError\n\n  @property\n  def slots(self):\n    return self._slots\n\n  @slots.setter\n  def slots(self, slots):\n    self._slots = slots\n\n  def _l2_norm(self, flat_list):\n    """"""Helper: calculate joint L2 norm of a list of tensors.""""""\n    if math.backend_name() == \'jax\':\n      norm = np.sqrt(sum(np.vdot(x, x) for x in flat_list))\n    else:  # TODO(lukaszkaiser): add vdot to TF-numpy\n      norm = np.sqrt(sum(np.sum(x*x) for x in flat_list))\n    return norm\n\n  def tree_init(self, weight_tree):\n    """"""Assembles node-local initializations into full-tree initialization.""""""\n    self._slots = [self.init(weight)\n                   for weight in math.tree_flatten(weight_tree)]\n    return (\n        self._slots,\n        self._init_opt_params,\n    )\n\n  def _update_and_check(self, step, grads, weights, slots, opt_params):\n    """"""Update a single weight array and check types.""""""\n    new_weights, new_slots = self.update(\n        step, grads, weights, slots, opt_params)\n    if isinstance(weights, np.ndarray):\n      if not isinstance(new_weights, np.ndarray):\n        raise ValueError(\n            f\'New weight values should be of type np.ndarray or a subclass; \'\n            f\'instead got {type(new_weights)}.\')\n      if new_weights.dtype != weights.dtype:\n        raise ValueError(\n            f\'New weight values dtype ({new_weights.dtype}) does not match \'\n            f\'the old one ({weights.dtype}).\')\n    return new_weights, new_slots\n\n  def tree_update(self, step, grad_tree, weight_tree, slots, opt_params):\n    """"""Assembles node-local weight and slot updates for the full layer tree.""""""\n    grads_flat = math.tree_flatten(grad_tree)\n    grads_norm = self._l2_norm(grads_flat)\n    if self._clip_grad_norm is not None:\n      max_norm = self._clip_grad_norm\n      grads_flat = [np.where(grads_norm < max_norm,  # pylint: disable=g-complex-comprehension\n                             g,\n                             g * (max_norm / grads_norm))\n                    for g in grads_flat]\n    weights_flat = math.tree_flatten(weight_tree)\n    weights_norm = self._l2_norm(weights_flat)\n    updated_pairs = [\n        self._update_and_check(step, grad, weight, slot, opt_params)\n        for (grad, weight, slot) in zip(grads_flat, weights_flat, slots)\n    ]\n    new_weights_flat, self.slots = zip(*updated_pairs)\n    new_weights, _ = math.tree_unflatten(new_weights_flat, weight_tree)\n    metrics = {\'gradients_l2\': grads_norm, \'weights_l2\': weights_norm}\n    return new_weights, self.slots, metrics\n\n\nclass SGD(Optimizer):\n  """"""Stochastic gradient descent (SGD) optimizer.\n\n  A simple optimizer with no weights (""slots"") of its own.\n  """"""\n\n  def init(self, weights):\n    return None\n\n  def update(self, step, grads, weights, slots, opt_params):\n    del step, slots\n    lr = opt_params[\'learning_rate\']\n    new_weights = weights - (lr * grads).astype(weights.dtype)\n    return new_weights, None\n\n\n# Utilities.\n\n\ndef l2_norm(tree):\n  """"""Compute the l2 norm of a pytree of arrays. Useful for weight decay.""""""\n  leaves = math.tree_flatten(tree)\n  return np.sqrt(sum(np.vdot(x, x) for x in leaves))\n\n\ndef clip_grads(grad_tree, max_norm):\n  """"""Clip gradients stored as a pytree of arrays to maximum norm `max_norm`.""""""\n  norm = l2_norm(grad_tree)\n  normalize = lambda g: np.where(norm < max_norm, g, g * (max_norm / norm))\n  return layers.nested_map(grad_tree, normalize)\n'"
trax/optimizers/momentum.py,1,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Nesterov momentum optimizer (also known as Nesterov Accelerated Gradient).""""""\n\nfrom trax.math import numpy as np\nfrom trax.optimizers import base\n\n\n# TODO(jonni): Consider renaming this class to NesterovMomentum.\nclass Momentum(base.Optimizer):\n  r""""""A momentum optimizer.\n\n  This class implements two variants of momentum stochastic gradient descent\n  (SGD): with and without the Nesterov correction. The implementation of the\n  Nesterov update is based on the concepts in Sutskever et al. (2013)\n  [http://jmlr.org/proceedings/papers/v28/sutskever13.pdf], reformulated in\n  Bengio et al. (2012) [https://arxiv.org/abs/1212.0901], to work well with\n  backpropagation (equations 6 and 7):\n\n  .. math::\n      v_t      &= \\mu_{t-1}v_{t-1} - \\epsilon_{t-1}\\nabla f(\\Theta_{t-1}) \\\\\n      \\Theta_t &= \\Theta_{t-1} - \\mu_{t-1} v_{t-1} + \\mu_t v_t + v_t\n\n  where :math:`\\mu_{t-1}` is the momentum (decay) coefficient at time step\n  :math:`t-1` and :math:`\\epsilon_{t-1}` is the learning rate at :math:`t-1`.\n\n  Note that the implementation below also includes a weight decay rate\n  (:math:`\\alpha`) on the parameters, independent of the Nesterov momentum.\n  """"""\n\n  def __init__(\n      self, learning_rate, mass=0.9, weight_decay_rate=1e-5, nesterov=True\n  ):  # pylint: disable=useless-super-delegation\n    super(Momentum, self).__init__(\n        learning_rate=learning_rate,\n        mass=mass,\n        weight_decay_rate=weight_decay_rate,\n    )\n    self._nesterov = nesterov\n\n  def init(self, weights):\n    return np.zeros_like(weights)\n\n  def update(self, step, grads, weights, velocity, opt_params):\n    del step\n    v = velocity\n    mu = opt_params[\'mass\']\n    alpha = opt_params[\'weight_decay_rate\']\n    epsilon = opt_params[\'learning_rate\']\n\n    new_v = mu * v + grads\n    if self._nesterov:\n      weight_update = mu * new_v + grads\n    else:\n      weight_update = new_v\n    new_weights = (1 - alpha) * weights - epsilon * weight_update\n\n    new_weights = new_weights.astype(weights.dtype)\n    return (new_weights, new_v)\n'"
trax/optimizers/optimizers_test.py,1,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for supervised training optimizers.""""""\n\nfrom absl.testing import absltest\n\nimport numpy as np\n\nfrom trax import optimizers\nfrom trax.optimizers import momentum\n\n\nclass OptimizersTest(absltest.TestCase):\n\n  def test_slots(self):\n    weights_shape = (3, 5)\n    weight_tree = np.arange(15).reshape(weights_shape)\n\n    # SGD - an optimizer that doesn\'t use slots.\n    opt_1 = optimizers.SGD(.01)\n    self.assertIsNone(opt_1.slots)\n    opt_1.tree_init(weight_tree)\n    self.assertIsInstance(opt_1.slots, list)\n    self.assertLen(opt_1.slots, 1)\n    self.assertIsNone(opt_1.slots[0])\n\n    # Momentum - an optimizer with slots\n    opt_2 = momentum.Momentum(.01)\n    self.assertIsNone(opt_2.slots)\n    opt_2.tree_init(weight_tree)\n    self.assertIsInstance(opt_2.slots, list)\n    self.assertLen(opt_2.slots, 1)\n    self.assertEqual(weights_shape, opt_2.slots[0].shape)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/optimizers/rms_prop.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""RMSProp optimizer class.""""""\n\nfrom trax.math import numpy as np\nfrom trax.optimizers import base as opt_base\n\n\nclass RMSProp(opt_base.Optimizer):\n  """"""RMSProp optimizer.\n\n  Uses optimizer weights (""slots"") to maintain a root-mean-square exponentially\n  decaying average of gradients from prior training batches.\n  """"""\n\n  def __init__(self, learning_rate, gamma=0.9,\n               eps=1e-8, clip_grad_norm=None):  # pylint: disable=useless-super-delegation\n    super(RMSProp, self).__init__(\n        learning_rate=learning_rate,\n        gamma=gamma,\n        eps=eps,\n        clip_grad_norm=clip_grad_norm\n    )\n\n  def init(self, weights):\n    return np.ones_like(weights)\n\n  def update(self, step, grads, weights, avg_sq_grad, opt_params):\n    del step\n    lr = opt_params[\'learning_rate\']\n    gamma = opt_params[\'gamma\']\n    eps = opt_params[\'eps\']\n    avg_sq_grad = avg_sq_grad * gamma + grads**2 * (1. - gamma)\n    weights = weights - (lr * grads /\n                         (np.sqrt(avg_sq_grad) + eps)).astype(weights.dtype)\n    return weights, avg_sq_grad\n'"
trax/optimizers/sm3.py,10,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""SM3 optimizer class.""""""\n\nfrom trax.math import numpy as np\nfrom trax.optimizers import base as opt_base\n\n\nclass SM3(opt_base.Optimizer):\n  """"""SM3 optimizer.""""""\n\n  def __init__(self, learning_rate, momentum=0.9):  # pylint: disable=useless-super-delegation\n    """"""Create the SM3 optimizer.\n\n    Memory-Efficient Adaptive Optimization for Large-Scale Learning.\n    https://arxiv.org/abs/1901.11150\n\n    Args:\n      learning_rate: a postitive scalar value for the initial learning rate.\n      momentum: optional, a positive scalar value for momentum\n    """"""\n    super(SM3, self).__init__(\n        learning_rate=learning_rate,\n        momentum=momentum,\n    )\n\n  def init(self, weights):\n    vs = [np.zeros(sz, dtype=weights.dtype) for sz in weights.shape]\n    return (np.zeros_like(weights), vs)\n\n  def _update_diagonal(self, grads, weights, m, v, opt_params):\n    learning_rate = opt_params[\'learning_rate\']\n    momentum = opt_params[\'momentum\']\n    v[0] += grads * grads\n    preconditioner = np.where(v[0] > 0, 1.0 / np.sqrt(v[0]),\n                              np.zeros_like(v[0]))\n    preconditioned_grads = preconditioner * grads\n    m = (1 - momentum) * preconditioned_grads + momentum * m\n    weights = weights - (learning_rate * m).astype(weights.dtype)\n    return weights, (m, v)\n\n  def _expanded_shape(self, shape, axis):\n    # Replaces a `shape` of [M, N, K] with 1 in all dimensions except for i.\n    # For eg: i = 1 returns [1, N, 1].\n    rank = len(shape)\n    return [1] * axis + [shape[axis]] + [1] * (rank - axis - 1)\n\n  def _minimum(self, tensor_list):\n    minimum = tensor_list[0]\n    for i in range(1, len(tensor_list)):\n      minimum = np.minimum(minimum, tensor_list[i])\n    return minimum\n\n  def _update_sketched(self, grads, weights, m, v, opt_params):\n    """"""Update for higher-rank parameters.""""""\n    learning_rate = opt_params[\'learning_rate\']\n    momentum = opt_params[\'momentum\']\n    shape = weights.shape\n    rank = len(shape)\n    reshaped_accumulators = [np.reshape(v[i], self._expanded_shape(shape, i))\n                             for i in range(rank)]\n    current_accumulator = self._minimum(reshaped_accumulators)\n    current_accumulator += grads * grads\n    accumulator_inv_sqrt = np.where(current_accumulator > 0.0,\n                                    1.0 / np.sqrt(current_accumulator),\n                                    np.zeros_like(current_accumulator))\n    preconditioned_gradient = grads * accumulator_inv_sqrt\n    m = (1.0 - momentum) * preconditioned_gradient + momentum * m\n    weights = weights - (learning_rate * m).astype(weights.dtype)\n    for i in range(len(v)):\n      axes = list(range(int(i))) + list(range(int(i) + 1, rank))\n      dim_accumulator = np.amax(current_accumulator, axis=axes)\n      v[i] = dim_accumulator\n    return weights, (m, v)\n\n  def update(self, step, grads, weights, slots, opt_params):\n    del step\n    m, v = slots\n    shape = weights.shape\n    rank = len(shape)\n    if rank > 1:\n      return self._update_sketched(grads, weights, m, v, opt_params)\n    else:\n      return self._update_diagonal(grads, weights, m, v, opt_params)\n'"
trax/rl/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Trax RL library.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport gin\n\nfrom trax.rl import actor_critic\nfrom trax.rl import actor_critic_joint\nfrom trax.rl import simulated_env_problem\nfrom trax.rl import training\n\n\ndef configure_rl(*args, **kwargs):\n  kwargs[\'module\'] = \'trax.rl\'\n  return gin.external_configurable(*args, **kwargs)\n\n\ndef configure_simulated_env_problem(*args, **kwargs):\n  kwargs[\'blacklist\'] = [\n      \'batch_size\', \'observation_space\', \'action_space\', \'reward_range\',\n      \'discrete_rewards\', \'history_stream\', \'output_dir\']\n  return configure_rl(*args, **kwargs)\n\n\n# pylint: disable=invalid-name\nRawSimulatedEnvProblem = configure_simulated_env_problem(\n    simulated_env_problem.RawSimulatedEnvProblem)\nSerializedSequenceSimulatedEnvProblem = configure_simulated_env_problem(\n    simulated_env_problem.SerializedSequenceSimulatedEnvProblem)\n\ncartpole_done_fn = configure_rl(simulated_env_problem.cartpole_done_fn)\ncartpole_reward_fn = configure_rl(simulated_env_problem.cartpole_reward_fn)\nacrobot_done_fn = configure_rl(simulated_env_problem.acrobot_done_fn)\nacrobot_reward_fn = configure_rl(simulated_env_problem.acrobot_reward_fn)\nonlinetune_done_fn = configure_rl(simulated_env_problem.onlinetune_done_fn)\nonlinetune_reward_fn = configure_rl(simulated_env_problem.onlinetune_reward_fn)\n\n\nPolicyGradientTrainer = configure_rl(\n    training.PolicyGradientTrainer, blacklist=[\'task\', \'output_dir\'])\nActorCriticTrainer = configure_rl(\n    actor_critic.ActorCriticTrainer, blacklist=[\'task\'])\nA2CTrainer = configure_rl(\n    actor_critic.A2CTrainer,\n    blacklist=[\'task\', \'output_dir\'])\nAWRTrainer = configure_rl(\n    actor_critic.AWRTrainer, blacklist=[\'task\', \'output_dir\'])\nSamplingAWRTrainer = configure_rl(\n    actor_critic.SamplingAWRTrainer, blacklist=[\'task\', \'output_dir\'])\nAWRJointTrainer = configure_rl(\n    actor_critic_joint.AWRJointTrainer, blacklist=[\'task\', \'output_dir\'])\nPPOTrainer = configure_rl(\n    actor_critic.PPOTrainer, blacklist=[\'task\', \'output_dir\'])\nPPOJointTrainer = configure_rl(\n    actor_critic_joint.PPOJointTrainer, blacklist=[\'task\', \'output_dir\'])\nA2CJointTrainer = configure_rl(\n    actor_critic_joint.A2CJointTrainer, blacklist=[\'task\', \'output_dir\'])\n'"
trax/rl/actor_critic.py,44,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Classes for RL training in Trax.""""""\n\nimport functools\nimport os\n\nimport gym\nimport numpy as np\nimport tensorflow as tf\n\nfrom trax import layers as tl\nfrom trax import lr_schedules as lr\nfrom trax import math\nfrom trax import shapes\nfrom trax import supervised\nfrom trax.math import numpy as jnp\nfrom trax.rl import advantages as rl_advantages\nfrom trax.rl import training as rl_training\n\n\nclass ActorCriticTrainer(rl_training.PolicyTrainer):\n  """"""Trains policy and value models using actor-critic methods.\n\n  Attrs:\n    on_policy (bool): Whether the algorithm is on-policy. Used in the data\n      generators. Should be set in derived classes.\n  """"""\n\n  on_policy = None\n\n  def __init__(self, task,\n               value_model=None,\n               value_optimizer=None,\n               value_lr_schedule=lr.MultifactorSchedule,\n               value_batch_size=64,\n               value_train_steps_per_epoch=500,\n               value_evals_per_epoch=1,\n               value_eval_steps=1,\n               n_shared_layers=0,\n               added_policy_slice_length=0,\n               n_replay_epochs=1,\n               scale_value_targets=False,\n               q_value=False,\n               q_value_aggregate_max=True,\n               q_value_n_samples=1,\n               vocab_size=2,\n               **kwargs):  # Arguments of PolicyTrainer come here.\n    """"""Configures the actor-critic trainer.\n\n    Args:\n      task: `RLTask` instance to use.\n      value_model: Model to use for the value function.\n      value_optimizer: Optimizer to train the value model.\n      value_lr_schedule: lr schedule for value model training.\n      value_batch_size: Batch size for value model training.\n      value_train_steps_per_epoch: Number of steps are we using to train the\n          value model in each epoch.\n      value_evals_per_epoch: Number of value trainer evaluations per RL epoch;\n          only affects metric reporting.\n      value_eval_steps: Number of value trainer steps per evaluation; only\n          affects metric reporting.\n      n_shared_layers: Number of layers to share between value and policy\n          models.\n      added_policy_slice_length: How much longer should slices of\n          trajectories be for policy than for value training; this\n          is useful for TD calculations and only affect the length\n          of elements produced for policy batches; value batches\n          have maximum length set by `max_slice_length` in `**kwargs`.\n      n_replay_epochs: Number of last epochs to take into the replay buffer;\n          only makes sense for off-policy algorithms.\n      scale_value_targets: If `True`, scale value function targets by\n          `1 / (1 - gamma)`.\n      q_value: If `True`, use Q-values as baselines.\n      q_value_aggregate_max: If `True`, aggregate Q-values with max (or mean).\n      q_value_n_samples: Number of samples to average over when calculating\n          baselines based on Q-values.\n      vocab_size: Embedding vocabulary size (passed to `tl.Embedding`); used\n          only with discrete actions and when `q_value` is `True`.\n      **kwargs: Arguments for `PolicyTrainer` superclass.\n    """"""\n    self._n_shared_layers = n_shared_layers\n    self._value_batch_size = value_batch_size\n    self._value_train_steps_per_epoch = value_train_steps_per_epoch\n    self._value_evals_per_epoch = value_evals_per_epoch\n    self._value_eval_steps = value_eval_steps\n\n    # The 2 below will be initalized in super.__init__ anyway, but are needed\n    # to construct value batches which are needed before PolicyTrainer init\n    # since policy input creation calls the value model -- hence this code.\n    self._task = task\n    self._max_slice_length = kwargs.get(\'max_slice_length\', 1)\n    self._added_policy_slice_length = added_policy_slice_length\n    self._n_replay_epochs = n_replay_epochs\n    task.set_n_replay_epochs(n_replay_epochs)\n\n    if scale_value_targets:\n      self._value_network_scale = 1 / (1 - self._task.gamma)\n    else:\n      self._value_network_scale = 1\n\n    self._q_value = q_value\n    self._q_value_aggregate_max = q_value_aggregate_max\n    self._q_value_n_samples = q_value_n_samples\n    self._vocab_size = vocab_size\n\n    is_discrete = isinstance(self._task.action_space, gym.spaces.Discrete)\n    # TODO(henrykm) handle the case other than Discrete/Gaussian\n\n    if q_value:\n      value_model = functools.partial(value_model,\n                                      inject_actions=True,\n                                      is_discrete=is_discrete,\n                                      vocab_size=self._vocab_size)\n    self._value_eval_model = value_model(mode=\'eval\')\n    self._value_eval_model.init(self._value_model_signature)\n    self._value_eval_jit = tl.jit_forward(self._value_eval_model.pure_fn,\n                                          math.device_count(), do_mean=False)\n\n    # Initialize policy training.\n    super(ActorCriticTrainer, self).__init__(task, **kwargs)\n\n    # Initialize training of the value function.\n    value_output_dir = kwargs.get(\'output_dir\', None)\n    if value_output_dir is not None:\n      value_output_dir = os.path.join(value_output_dir, \'value\')\n      # If needed, create value_output_dir and missing parent directories.\n      if not tf.io.gfile.isdir(value_output_dir):\n        tf.io.gfile.makedirs(value_output_dir)\n    self._value_inputs = supervised.Inputs(\n        train_stream=lambda _: self.value_batches_stream())\n    self._value_trainer = supervised.Trainer(\n        model=value_model,\n        optimizer=value_optimizer,\n        lr_schedule=value_lr_schedule,\n        loss_fn=tl.L2Loss(),\n        inputs=self._value_inputs,\n        output_dir=value_output_dir,\n        metrics={\'value_loss\': tl.L2Loss()})\n\n  @property\n  def _value_model_signature(self):\n    obs_sig = shapes.signature(self._task.observation_space)\n    target_sig = mask_sig = shapes.ShapeDtype(\n        shape=(1, 1, 1),\n    )\n    inputs_sig = (obs_sig.replace(shape=(1, 1) + obs_sig.shape),)\n    if self._q_value:\n      act_sig = shapes.signature(self._task.action_space)\n      inputs_sig += (act_sig.replace(shape=(1, 1) + act_sig.shape),)\n    return (*inputs_sig, target_sig, mask_sig)\n\n  @property\n  def _replay_epochs(self):\n    if self.on_policy:\n      assert self._n_replay_epochs == 1, (\n          \'Non-unit replay buffer size only makes sense for off-policy \'\n          \'algorithms.\'\n      )\n    return [-(ep + 1) for ep in range(self._n_replay_epochs)]\n\n  def _run_value_model(self, observations, dist_inputs):\n    if dist_inputs is None:\n      dist_inputs = jnp.zeros(\n          observations.shape[:2] + (self._policy_dist.n_inputs,)\n      )\n\n    actions = None\n    if self._q_value:\n      dist_inputs = jnp.broadcast_to(\n          dist_inputs, (self._q_value_n_samples,) + dist_inputs.shape\n      )\n      # Swapping the n_samples and batch_size axes, so the input is split\n      # between accelerators along the batch_size axis.\n      dist_inputs = jnp.swapaxes(dist_inputs, 0, 1)\n      actions = self._policy_dist.sample(dist_inputs)\n      log_probs = self._policy_dist.log_prob(dist_inputs, actions)\n      obs = observations\n      obs = jnp.reshape(obs, [obs.shape[0], 1] + list(obs.shape[1:]))\n      inputs = (obs, actions)\n    else:\n      log_probs = None\n      inputs = (observations,)\n\n    n_devices = math.device_count()\n    weights = tl.for_n_devices(self._value_eval_model.weights, n_devices)\n    state = tl.for_n_devices(self._value_eval_model.state, n_devices)\n    rng = self._value_eval_model.rng\n    values, _ = self._value_eval_jit(inputs, weights, state, rng)\n    values *= self._value_network_scale\n    values = jnp.squeeze(values, axis=-1)  # Remove the singleton depth dim.\n    return (values, actions, log_probs)\n\n  def _aggregate_values(self, values, aggregate_max):\n    if self._q_value:\n      if aggregate_max:\n        values = jnp.max(values, axis=1)\n      else:\n        values = jnp.mean(values, axis=1)\n    return np.array(values)  # Move the values to CPU.\n\n  def value_batches_stream(self):\n    """"""Use the RLTask self._task to create inputs to the value model.""""""\n    max_slice_length = self._max_slice_length + self._added_policy_slice_length\n    for np_trajectory in self._task.trajectory_batch_stream(\n        self._value_batch_size,\n        max_slice_length=max_slice_length,\n        min_slice_length=(1 + self._added_policy_slice_length),\n        margin=self._added_policy_slice_length,\n        epochs=self._replay_epochs,\n    ):\n      (values, _, _) = self._run_value_model(\n          np_trajectory.observations, np_trajectory.dist_inputs\n      )\n      values = self._aggregate_values(values, self._q_value_aggregate_max)\n\n      # TODO(pkozakowski): Add some shape assertions and docs.\n      # Calculate targets based on the advantages over the target network - this\n      # allows TD learning for value networks.\n      advantages = self._advantage_estimator(\n          rewards=np_trajectory.rewards,\n          returns=np_trajectory.returns,\n          values=values,\n          dones=np_trajectory.dones,\n          gamma=self._task.gamma,\n          n_extra_steps=self._added_policy_slice_length,\n      )\n      length = advantages.shape[1]\n      values = values[:, :length]\n      target_returns = values + advantages\n\n      inputs = (np_trajectory.observations[:, :length],)\n      if self._q_value:\n        inputs += (np_trajectory.actions[:, :length],)\n\n      # Insert an extra depth dimension, so the target shape is consistent with\n      # the network output shape.\n      yield (\n          # Inputs: observations and maybe actions.\n          *inputs,\n          # Targets: computed returns.\n          target_returns[:, :, None] / self._value_network_scale,\n          # Mask to zero-out padding.\n          np_trajectory.mask[:, :length, None],\n      )\n\n  def policy_inputs(self, trajectory, values):\n    """"""Create inputs to policy model from a TrajectoryNp and values.\n\n    Args:\n      trajectory: a TrajectoryNp, the trajectory to create inputs from\n      values: a numpy array: value function computed on trajectory\n\n    Returns:\n      a tuple of numpy arrays of the form (inputs, x1, x2, ...) that will be\n      passed to the policy model; policy model will compute outputs from\n      inputs and (outputs, x1, x2, ...) will be passed to self.policy_loss\n      which should be overridden accordingly.\n    """"""\n    return NotImplementedError\n\n  def policy_batches_stream(self):\n    """"""Use the RLTask self._task to create inputs to the policy model.""""""\n    # Maximum slice length for policy is max_slice_len + the added policy len.\n    max_slice_length = self._max_slice_length + self._added_policy_slice_length\n    for np_trajectory in self._task.trajectory_batch_stream(\n        self._policy_batch_size,\n        epochs=self._replay_epochs,\n        max_slice_length=max_slice_length,\n        margin=self._added_policy_slice_length,\n        include_final_state=False):\n      (values, _, _) = self._run_value_model(\n          np_trajectory.observations, np_trajectory.dist_inputs\n      )\n      values = self._aggregate_values(values, False)\n      if len(values.shape) != 2:\n        raise ValueError(\'Values are expected to have shape \' +\n                         \'[batch_size, length], got: %s\' % str(values.shape))\n      if values.shape[0] != self._policy_batch_size:\n        raise ValueError(\'Values first dimension should = policy batch size, \' +\n                         \'%d != %d\' %(values.shape[0], self._policy_batch_size))\n      yield self.policy_inputs(np_trajectory, values)\n\n  def train_epoch(self):\n    """"""Trains RL for one epoch.""""""\n    # Copy policy state accumulated during data collection to the trainer.\n    self._policy_trainer.model_state = self._policy_collect_model.state\n\n    # Copy policy weights and state to value trainer.\n    if self._n_shared_layers > 0:\n      _copy_model_weights_and_state(\n          0, self._n_shared_layers, self._policy_trainer, self._value_trainer\n      )\n\n    # Update the target value network.\n    self._value_eval_model.weights = self._value_trainer.model_weights\n    self._value_eval_model.state = self._value_trainer.model_state\n\n    n_value_evals = rl_training.remaining_evals(\n        self._value_trainer.step,\n        self._epoch,\n        self._value_train_steps_per_epoch,\n        self._value_evals_per_epoch)\n    for _ in range(n_value_evals):\n      self._value_trainer.train_epoch(\n          self._value_train_steps_per_epoch // self._value_evals_per_epoch,\n          self._value_eval_steps,\n      )\n    # Copy value weights and state to policy trainer.\n    if self._n_shared_layers > 0:\n      _copy_model_weights_and_state(\n          0, self._n_shared_layers, self._value_trainer, self._policy_trainer\n      )\n    n_policy_evals = rl_training.remaining_evals(\n        self._policy_trainer.step,\n        self._epoch,\n        self._policy_train_steps_per_epoch,\n        self._policy_evals_per_epoch)\n    # Check if there was a restart after value training finishes and policy not.\n    stopped_after_value = (n_value_evals == 0 and\n                           n_policy_evals < self._policy_evals_per_epoch)\n    should_copy_weights = self._n_shared_layers > 0 and not stopped_after_value\n    if should_copy_weights:\n      _copy_model_weights_and_state(\n          0, self._n_shared_layers, self._value_trainer, self._policy_trainer\n      )\n\n    # Update the target value network.\n    self._value_eval_model.weights = self._value_trainer.model_weights\n    self._value_eval_model.state = self._value_trainer.model_state\n\n    for _ in range(n_policy_evals):\n      self._policy_trainer.train_epoch(\n          self._policy_train_steps_per_epoch // self._policy_evals_per_epoch,\n          self._policy_eval_steps,\n      )\n\n  def close(self):\n    self._value_trainer.close()\n    super().close()\n\n\ndef _copy_model_weights_and_state(  # pylint: disable=invalid-name\n    start, end, from_trainer, to_trainer, copy_optimizer_slots=False\n):\n  """"""Copy model weights[start:end] from from_trainer to to_trainer.""""""\n  from_weights = from_trainer.model_weights\n  to_weights = to_trainer.model_weights\n  shared_weights = from_weights[start:end]\n  to_weights[start:end] = shared_weights\n  to_trainer.model_weights = to_weights\n\n  from_state = from_trainer.model_state\n  to_state = to_trainer.model_state\n  shared_state = from_state[start:end]\n  to_state[start:end] = shared_state\n  to_trainer.model_state = to_state\n\n  if copy_optimizer_slots:\n    # TODO(lukaszkaiser): make a nicer API in Trainer to support this.\n    # Currently we use the hack below. Note [0] since that\'s the model w/o loss.\n    # pylint: disable=protected-access\n    from_slots = from_trainer._opt_state.slots[0][start:end]\n    to_slots = to_trainer._opt_state.slots[0]\n    # The lines below do to_slots[start:end] = from_slots, but on tuples.\n    new_slots = to_slots[:start] + from_slots[start:end] + to_slots[end:]\n    new_slots = tuple([new_slots] + list(to_trainer._opt_state.slots[1:]))\n    to_trainer._opt_state = to_trainer._opt_state._replace(slots=new_slots)\n    # pylint: enable=protected-access\n\n\n### Implementations of common actor-critic algorithms.\n\n\nclass AdvantageBasedActorCriticTrainer(ActorCriticTrainer):\n  """"""Base class for advantage-based actor-critic algorithms.""""""\n\n  def __init__(\n      self,\n      task,\n      advantage_estimator=rl_advantages.td_lambda,\n      advantage_normalization=True,\n      advantage_normalization_epsilon=1e-5,\n      **kwargs\n  ):\n    self._advantage_estimator = advantage_estimator\n    self._advantage_normalization = advantage_normalization\n    self._advantage_normalization_epsilon = advantage_normalization_epsilon\n    super(AdvantageBasedActorCriticTrainer, self).__init__(task, **kwargs)\n\n  def policy_inputs(self, trajectory, values):\n    """"""Create inputs to policy model from a TrajectoryNp and values.""""""\n    # How much TD to use is determined by the added policy slice length,\n    # as the policy batches need to be this much longer to calculate TD.\n    advantages = self._advantage_estimator(\n        rewards=trajectory.rewards,\n        returns=trajectory.returns,\n        values=values,\n        dones=trajectory.dones,\n        gamma=self._task.gamma,\n        n_extra_steps=self._added_policy_slice_length,\n    )\n    # Observations should be the same length as advantages - so if we are\n    # using n_extra_steps, we need to trim the length to match.\n    obs = trajectory.observations[:, :advantages.shape[1]]\n    act = trajectory.actions[:, :advantages.shape[1]]\n    mask = trajectory.mask[:, :advantages.shape[1]]  # Mask to zero-out padding.\n    if trajectory.dist_inputs is not None:\n      dist_inputs = trajectory.dist_inputs[:, :advantages.shape[1]]\n    else:\n      dist_inputs = jnp.zeros(advantages.shape + (self._policy_dist.n_inputs,))\n    # Shape checks to help debugging.\n    if len(advantages.shape) != 2:\n      raise ValueError(\'Advantages are expected to have shape \' +\n                       \'[batch_size, length], got: %s\' % str(advantages.shape))\n    if act.shape[0:2] != advantages.shape:\n      raise ValueError(\'First 2 dimensions of actions should be the same as in \'\n                       \'advantages, %s != %s\' % (act.shape[0:2],\n                                                 advantages.shape))\n    if obs.shape[0:2] != advantages.shape:\n      raise ValueError(\'First 2 dimensions of observations should be the same \'\n                       \'as in advantages, %s != %s\' % (obs.shape[0:2],\n                                                       advantages.shape))\n    if dist_inputs.shape[:2] != advantages.shape:\n      raise ValueError(\'First 2 dimensions of dist_inputs should be the same \'\n                       \'as in advantages, %s != %s\' % (dist_inputs.shape[:2],\n                                                       advantages.shape))\n    if mask.shape != advantages.shape:\n      raise ValueError(\'Mask and advantages shapes should be the same\'\n                       \', %s != %s\' % (mask.shape, advantages.shape))\n    return (obs, act, advantages, dist_inputs, mask)\n\n  @property\n  def policy_loss_given_log_probs(self):\n    """"""Policy loss given action log-probabilities.""""""\n    raise NotImplementedError\n\n  def _preprocess_advantages(self, advantages):\n    if self._advantage_normalization:\n      advantages = (\n          (advantages - jnp.mean(advantages)) /\n          (jnp.std(advantages) + self._advantage_normalization_epsilon)\n      )\n    return advantages\n\n  @property\n  def policy_loss(self, **unused_kwargs):\n    """"""Policy loss.""""""\n    def LossInput(dist_inputs, actions, advantages, old_dist_inputs):  # pylint: disable=invalid-name\n      """"""Calculates action log probabilities and normalizes advantages.""""""\n      advantages = self._preprocess_advantages(advantages)\n      log_probs = self._policy_dist.log_prob(dist_inputs, actions)\n      old_log_probs = self._policy_dist.log_prob(old_dist_inputs, actions)\n      return (log_probs, advantages, old_log_probs)\n\n    return tl.Serial(\n        tl.Fn(\'LossInput\', LossInput, n_out=3),\n        # Policy loss is expected to consume\n        # (log_probs, advantages, old_log_probs, mask).\n        self.policy_loss_given_log_probs,\n    )\n\n  @property\n  def policy_metrics(self):\n    metrics = super(AdvantageBasedActorCriticTrainer, self).policy_metrics\n    metrics.update({\n        \'advantage_mean\': self.advantage_mean,\n        \'advantage_std\': self.advantage_std,\n    })\n    return metrics\n\n  @property\n  def advantage_mean(self):\n    return tl.Serial([\n        # (dist_inputs, advantages, old_dist_inputs, mask)\n        tl.Select([1]),  # Select just the advantages.\n        tl.Fn(\'AdvantageMean\', lambda x: jnp.mean(x)),  # pylint: disable=unnecessary-lambda\n    ])\n\n  @property\n  def advantage_std(self):\n    return tl.Serial([\n        # (dist_inputs, advantages, old_dist_inputs, mask)\n        tl.Select([1]),  # Select just the advantages.\n        tl.Fn(\'AdvantageStd\', lambda x: jnp.std(x)),  # pylint: disable=unnecessary-lambda\n    ])\n\n\nclass A2CTrainer(AdvantageBasedActorCriticTrainer):\n  """"""Trains policy and value models using the A2C algortithm.""""""\n\n  on_policy = True\n\n  def __init__(self, task, entropy_coeff=0.01, **kwargs):\n    """"""Configures the A2C Trainer.""""""\n    self._entropy_coeff = entropy_coeff\n    super(A2CTrainer, self).__init__(task, **kwargs)\n\n  @property\n  def policy_loss_given_log_probs(self):\n    """"""Definition of the Advantage Actor Critic (A2C) loss.""""""\n    # A2C is one of the most basic actor-critic RL algorithms.\n    # TODO(henrykm) re-factor f into rl_layers and finally share code between\n    # actor_critic.py and actor_critic_joint.py - requires change of inputs\n    # in actor_critic_joint.py from dist_inputs to log_probs.\n    def f(log_probs, advantages, old_log_probs, mask):\n      del old_log_probs  # Not used in A2C.\n      # log_probs of the shape float32[128,1]\n      # advantages of the shape int32[128,1]\n      # mask of the shape int32[128,1]\n      if log_probs.shape != advantages.shape:\n        raise ValueError(\'New log-probs and advantages shapes \'\n                         \'should be the same, %s != %s\' % (log_probs.shape,\n                                                           advantages.shape))\n      if log_probs.shape != mask.shape:\n        raise ValueError(\'New log-probs and mask shapes should be the same\'\n                         \', %s != %s\' % (log_probs.shape, mask.shape))\n\n      a2c_objective = -jnp.sum(log_probs * advantages * mask) / jnp.sum(mask)\n\n      entropy_vec = self._policy_dist.entropy(log_probs) * self._entropy_coeff\n      entropy_loss = jnp.mean(entropy_vec)\n\n      combined_loss = a2c_objective - entropy_loss\n\n      return combined_loss\n\n    return tl.Fn(\'A2CLoss\', f)\n\n\nclass PPOTrainer(AdvantageBasedActorCriticTrainer):\n  """"""The Proximal Policy Optimization Algorithm aka PPO.\n\n  Trains policy and value models using the PPO algortithm.\n  """"""\n\n  on_policy = True\n\n  def __init__(self, task, epsilon=0.2, entropy_coeff=0.01, **kwargs):\n    """"""Configures the PPO Trainer.""""""\n    self._entropy_coeff = entropy_coeff\n    self._epsilon = epsilon\n    super(PPOTrainer, self).__init__(task, **kwargs)\n\n  @property\n  def policy_loss_given_log_probs(self):\n    """"""Definition of the Proximal Policy Optimization loss.""""""\n    def f(new_log_probs, advantages, old_log_probs, mask):\n      # new_log_probs of the shape float32[128,1]\n      # advantages of the shape int32[128,1]\n      # old_log_probs of the shape int32[128,1]\n      # mask of the shape int32[128,1]\n      if new_log_probs.shape != advantages.shape:\n        raise ValueError(\'New log-probs and advantages shapes \'\n                         \'should be the same, %s != %s\' % (new_log_probs.shape,\n                                                           advantages.shape))\n      if new_log_probs.shape != old_log_probs.shape:\n        raise ValueError(\'New log-probs and old log-probs shapes \'\n                         \'should be the same, %s != %s\' % (new_log_probs.shape,\n                                                           old_log_probs.shape))\n      if new_log_probs.shape != mask.shape:\n        raise ValueError(\'New log-probs and mask shapes should be the same\'\n                         \', %s != %s\' % (new_log_probs.shape, mask.shape))\n\n      # The ratio between new_probs and old_probs expressed\n      # using log_probs and exponentaion\n      probs_ratio = jnp.exp(new_log_probs - old_log_probs)\n      if advantages.shape != probs_ratio.shape:\n        raise ValueError(\'New log-probs and old log probs shapes \'\n                         \'should be the same, %s != %s\' % (advantages.shape,\n                                                           probs_ratio.shape))\n      unclipped_objective = probs_ratio * advantages\n      clipped_objective = jnp.clip(probs_ratio,\n                                   1 - self._epsilon,\n                                   1 + self._epsilon) * advantages\n\n      if unclipped_objective.shape != probs_ratio.shape:\n        raise ValueError(\'unclipped_objective and clipped_objective shapes \'\n                         \'should be the same, %s != %s\' % (\n                             unclipped_objective.shape,\n                             clipped_objective.shape))\n\n      ppo_objective = jnp.minimum(unclipped_objective, clipped_objective)\n\n      if ppo_objective.shape != mask.shape:\n        raise ValueError(\'ppo_objective and mask shapes \'\n                         \'should be the same, %s != %s\' % (\n                             ppo_objective.shape,\n                             mask.shape))\n\n      ppo_loss = -jnp.sum(ppo_objective * mask) / jnp.sum(mask)\n      entropy_vec = self._policy_dist.entropy(\n          new_log_probs) * self._entropy_coeff\n      entropy_loss = jnp.mean(entropy_vec)\n      combined_loss = ppo_loss - entropy_loss\n\n      return combined_loss\n    return tl.Fn(\'PPOLoss\', f)\n\n\n# AWR is an off-policy actor-critic RL algorithm.\ndef awr_weights(advantages, beta):\n  return jnp.exp(advantages / beta)\n\n\n# Helper functions for computing AWR metrics.\ndef awr_metrics(beta, preprocess_layer=None):\n  return {  # pylint: disable=g-complex-comprehension\n      \'awr_weight_\' + name: awr_weight_stat(name, fn, beta, preprocess_layer)\n      for (name, fn) in [\n          (\'mean\', jnp.mean),\n          (\'std\', jnp.std),\n          (\'min\', jnp.min),\n          (\'max\', jnp.max),\n      ]\n  }\n\n\ndef awr_weight_stat(stat_name, stat_fn, beta, preprocess_layer):\n  # Select just the advantages if preprocess layer is not given.\n  preprocess = tl.Select([1]) if preprocess_layer is None else preprocess_layer\n  return tl.Serial([\n      preprocess,\n      tl.Fn(\n          \'AWRWeight\' + stat_name.capitalize(),\n          lambda x: stat_fn(awr_weights(x, beta)),\n      ),\n  ])\n\n\ndef AWRLoss(beta, w_max):  # pylint: disable=invalid-name\n  """"""Definition of the Advantage Weighted Regression (AWR) loss.""""""\n  def f(log_probs, advantages, old_log_probs, mask):\n    del old_log_probs  # Not used in AWR.\n    weights = jnp.minimum(awr_weights(advantages, beta), w_max)\n    return -jnp.sum(log_probs * weights * mask) / jnp.sum(mask)\n  return tl.Fn(\'AWRLoss\', f)\n\n\nclass AWRTrainer(AdvantageBasedActorCriticTrainer):\n  """"""Trains policy and value models using AWR.""""""\n\n  on_policy = False\n\n  def __init__(self, task, beta=1.0, w_max=20.0, **kwargs):\n    """"""Configures the AWR Trainer.""""""\n    self._beta = beta\n    self._w_max = w_max\n    super(AWRTrainer, self).__init__(task, **kwargs)\n\n  @property\n  def policy_loss_given_log_probs(self):\n    """"""Policy loss.""""""\n    return AWRLoss(beta=self._beta, w_max=self._w_max)  # pylint: disable=no-value-for-parameter\n\n  @property\n  def policy_metrics(self):\n    metrics = super(AWRTrainer, self).policy_metrics\n    metrics.update(awr_metrics(self._beta))\n    return metrics\n\n\ndef SamplingAWRLoss(beta, w_max, reweight=False):  # pylint: disable=invalid-name\n  """"""Definition of the Advantage Weighted Regression (AWR) loss.""""""\n  def f(log_probs, advantages, old_log_probs, mask):\n    if reweight:  # Use new policy weights for sampled actions instead.\n      mask *= jnp.exp(math.stop_gradient(log_probs) - old_log_probs)\n    weights = jnp.minimum(awr_weights(advantages, beta), w_max)\n    return -jnp.sum(log_probs * weights * mask) / jnp.sum(mask)\n  return tl.Fn(\'SamplingAWRLoss\', f)\n\n\nclass SamplingAWRTrainer(AdvantageBasedActorCriticTrainer):\n  """"""Trains policy and value models using Sampling AWR.""""""\n\n  on_policy = False\n\n  def __init__(self, task, beta=1.0, w_max=20.0, reweight=False, **kwargs):\n    """"""Configures the AWR Trainer.""""""\n    self._beta = beta\n    self._w_max = w_max\n    self._reweight = reweight\n    super(SamplingAWRTrainer, self).__init__(task, q_value=True, **kwargs)\n\n  def _policy_inputs_to_advantages(self, preprocess):\n    """"""A layer that computes advantages from policy inputs.""""""\n    def fn(dist_inputs, actions, q_values, act_log_probs, mask):\n      del dist_inputs, actions, mask\n      q_values = jnp.swapaxes(q_values, 0, 1)\n      act_log_probs = jnp.swapaxes(act_log_probs, 0, 1)\n      values = jnp.mean(q_values, axis=0)\n      advantages = q_values - values  # Broadcasting values over n_samples\n      if preprocess:\n        advantages = self._preprocess_advantages(advantages)\n      return advantages\n    return tl.Fn(\'PolicyInputsToAdvantages\', fn)\n\n  @property\n  def policy_metrics(self):\n    metrics = {\n        \'policy_loss\': self.policy_loss,\n        \'advantage_mean\': tl.Serial(\n            self._policy_inputs_to_advantages(False),\n            tl.Fn(\'Mean\', lambda x: jnp.mean(x))  # pylint: disable=unnecessary-lambda\n        ),\n        \'advantage_std\': tl.Serial(\n            self._policy_inputs_to_advantages(False),\n            tl.Fn(\'Std\', lambda x: jnp.std(x))  # pylint: disable=unnecessary-lambda\n        )\n    }\n    metrics.update(awr_metrics(\n        self._beta, preprocess_layer=self._policy_inputs_to_advantages(True)))\n    return metrics\n\n  @property\n  def policy_loss(self, **unused_kwargs):\n    """"""Policy loss.""""""\n    def LossInput(dist_inputs, actions, q_values, act_log_probs, mask):  # pylint: disable=invalid-name\n      """"""Calculates action log probabilities and normalizes advantages.""""""\n      # (batch_size, n_samples, ...) -> (n_samples, batch_size, ...)\n      q_values = jnp.swapaxes(q_values, 0, 1)\n      mask = jnp.swapaxes(mask, 0, 1)\n      actions = jnp.swapaxes(actions, 0, 1)\n      act_log_probs = jnp.swapaxes(act_log_probs, 0, 1)\n\n      # TODO(pkozakowski,lukaszkaiser): Try max here, or reweighting?\n      # Reweight: values = jnp.sum(q_values * jnp.exp(act_log_probs), axis=0)\n      values = jnp.mean(q_values, axis=0)\n      advantages = q_values - values  # Broadcasting values over n_samples\n      advantages = self._preprocess_advantages(advantages)\n\n      # Broadcast inputs and calculate log-probs\n      dist_inputs = jnp.broadcast_to(\n          dist_inputs, (self._q_value_n_samples,) + dist_inputs.shape)\n      log_probs = self._policy_dist.log_prob(dist_inputs, actions)\n      return (log_probs, advantages, act_log_probs, mask)\n\n    return tl.Serial(\n        tl.Fn(\'LossInput\', LossInput, n_out=4),\n        # Policy loss is expected to consume\n        # (log_probs, advantages, old_log_probs, mask).\n        SamplingAWRLoss(beta=self._beta, w_max=self._w_max,\n                        reweight=self._reweight),  # pylint: disable=no-value-for-parameter\n    )\n\n  def policy_batches_stream(self):\n    """"""Use the RLTask self._task to create inputs to the policy model.""""""\n    # For now TD-0 estimation of the value. TODO(pkozakowski): Support others?\n    for np_trajectory in self._task.trajectory_batch_stream(\n        self._policy_batch_size,\n        epochs=self._replay_epochs,\n        max_slice_length=self._max_slice_length,\n        include_final_state=False,\n    ):\n      (q_values, actions, act_log_probs) = self._run_value_model(\n          np_trajectory.observations, np_trajectory.dist_inputs)\n      shapes.assert_same_shape(q_values, act_log_probs)\n\n      # q_values shape: (batch_size, n_samples, length)\n      if len(q_values.shape) != 3:\n        raise ValueError(\'Q-values are expected to have shape [batch_size, \' +\n                         \'n_samples, length], got: %s\' % str(q_values.shape))\n      if q_values.shape[1] != self._q_value_n_samples:\n        raise ValueError(\'Q-values dimension 1 should = n_samples, %d != %d\'\n                         % (q_values.shape[1], self._q_value_n_samples))\n      if q_values.shape[0] != self._policy_batch_size:\n        raise ValueError(\'Q-values dimension 0 should = policy batch size, \' +\n                         \'%d!=%d\' %(q_values.shape[1], self._policy_batch_size))\n\n      mask = np_trajectory.mask\n      mask = np.reshape(mask, [mask.shape[0], 1] + list(mask.shape[1:]))\n      mask = jnp.broadcast_to(mask, q_values.shape)\n      shapes.assert_same_shape(mask, q_values)\n\n      yield (np_trajectory.observations, actions, q_values, act_log_probs, mask)\n'"
trax/rl/actor_critic_joint.py,20,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Classes for RL training in Trax.""""""\n\nimport functools\n\nfrom trax import layers as tl\nfrom trax import lr_schedules as lr\nfrom trax import supervised\nfrom trax.math import numpy as jnp\nfrom trax.math import stop_gradient\nfrom trax.rl import actor_critic\nfrom trax.rl import distributions\nfrom trax.rl import rl_layers\nfrom trax.rl import training as rl_training\n\n\n# pylint: disable=g-long-lambda\nclass ActorCriticJointTrainer(rl_training.RLTrainer):\n  """"""Trains a joint policy-and-value model using actor-critic methods.""""""\n\n  def __init__(self, task,\n               joint_model=None,\n               optimizer=None,\n               lr_schedule=lr.MultifactorSchedule,\n               batch_size=64,\n               train_steps_per_epoch=500,\n               supervised_evals_per_epoch=1,\n               supervised_eval_steps=1,\n               n_trajectories_per_epoch=50,\n               max_slice_length=1,\n               normalize_advantages=True,\n               output_dir=None,\n               n_replay_epochs=1):\n    """"""Configures the joint trainer.\n\n    Args:\n      task: RLTask instance, which defines the environment to train on.\n      joint_model: Trax layer, representing the joint policy and value model.\n      optimizer: the optimizer to use to train the joint model.\n      lr_schedule: learning rate schedule to use to train the joint model/.\n      batch_size: batch size used to train the joint model.\n      train_steps_per_epoch: how long to train the joint model in each RL epoch.\n      supervised_evals_per_epoch: number of value trainer evaluations per RL\n          epoch - only affects metric reporting.\n      supervised_eval_steps: number of value trainer steps per evaluation -\n          only affects metric reporting.\n      n_trajectories_per_epoch: how many trajectories to collect per epoch.\n      max_slice_length: the maximum length of trajectory slices to use.\n      normalize_advantages: if True, then normalize advantages - currently\n          implemented only in PPO.\n      output_dir: Path telling where to save outputs (evals and checkpoints).\n      n_replay_epochs: how many last epochs to take into the replay buffer;\n           > 1 only makes sense for off-policy algorithms.\n    """"""\n    super(ActorCriticJointTrainer, self).__init__(\n        task,\n        n_trajectories_per_epoch=n_trajectories_per_epoch,\n        output_dir=output_dir,\n    )\n    self._batch_size = batch_size\n    self._train_steps_per_epoch = train_steps_per_epoch\n    self._supervised_evals_per_epoch = supervised_evals_per_epoch\n    self._supervised_eval_steps = supervised_eval_steps\n    self._n_trajectories_per_epoch = n_trajectories_per_epoch\n    self._max_slice_length = max_slice_length\n    self._policy_dist = distributions.create_distribution(task.action_space)\n    self._lr_schedule = lr_schedule\n    self._optimizer = optimizer\n    self._normalize_advantages = normalize_advantages\n    self._n_replay_epochs = n_replay_epochs\n    self._task.set_n_replay_epochs(n_replay_epochs)\n\n    # Inputs to the joint model are produced by self.batches_stream.\n    self._inputs = supervised.Inputs(\n        train_stream=lambda _: self.batches_stream())\n\n    self._joint_model = functools.partial(\n        joint_model,\n        policy_distribution=self._policy_dist,\n    )\n\n    # This is the joint Trainer that will be used to train the policy model.\n    # * inputs to the trainer come from self.batches_stream\n    # * outputs are passed to self._joint_loss\n    self._trainer = supervised.Trainer(\n        model=self._joint_model,\n        optimizer=self._optimizer,\n        lr_schedule=self._lr_schedule,\n        loss_fn=self.joint_loss,\n        inputs=self._inputs,\n        output_dir=output_dir,\n        metrics={\'joint_loss\': self.joint_loss,\n                 \'advantage_mean\': self.advantage_mean,\n                 \'advantage_norm\': self.advantage_norm,\n                 \'value_loss\': self.value_loss,\n                 \'explained_variance\': self.explained_variance,\n                 \'log_probs_mean\': self.log_probs_mean,\n                 \'preferred_move\': self.preferred_move})\n    self._eval_model = self._joint_model(mode=\'eval\')\n    example_batch = next(self.batches_stream())\n    self._eval_model.init(example_batch)\n\n  def close(self):\n    self._trainer.close()\n    super().close()\n\n  def batches_stream(self):\n    """"""Use self.task to create inputs to the policy model.""""""\n    return NotImplementedError\n\n  @property\n  def joint_loss(self):\n    """"""Joint policy and value loss layer.""""""\n    return NotImplementedError\n\n  @property\n  def advantage_mean(self):\n    """"""Mean of advantages.""""""\n    def f(dist_inputs, values, returns):\n      del dist_inputs\n      return jnp.mean(returns - values)\n    return tl.Fn(\'AdvantageMean\', f)\n\n  @property\n  def advantage_norm(self):\n    """"""Norm of advantages.""""""\n    def f(dist_inputs, values, returns):\n      del dist_inputs\n      return jnp.linalg.norm(returns - values)\n    return tl.Fn(\'AdvantageNorm\', f)\n\n  @property\n  def value_loss(self):\n    """"""Value loss - so far generic for all A2C.""""""\n    def f(dist_inputs, values, returns):\n      del dist_inputs\n      return rl_layers.ValueLoss(values, returns, self._value_loss_coeff)\n    return tl.Fn(\'ValueLoss\', f)\n\n  @property\n  def explained_variance(self):\n    """"""Explained variance metric.""""""\n    def f(dist_inputs, values, returns):\n      del dist_inputs\n      return rl_layers.ExplainedVariance(values, returns)\n    return tl.Fn(\'ExplainedVariance\', f)\n\n  @property\n  def log_probs_mean(self):\n    """"""Mean of log_probs aka dist_inputs.""""""\n    def f(dist_inputs, values):\n      del values\n      return jnp.mean(dist_inputs)\n    return tl.Fn(\'LogProbsMean\', f)\n\n  @property\n  def preferred_move(self):\n    """"""Preferred move - the mean of selected moves.""""""\n    def f(dist_inputs, values):\n      del values\n      return rl_layers.PreferredMove(dist_inputs, self._policy_dist.sample)\n    return tl.Fn(\'PreferredMove\', f)\n\n  def policy(self, trajectory, temperature=1.0):\n    """"""Chooses an action to play after a trajectory.""""""\n    model = self._eval_model\n    model.weights = self._trainer.model_weights\n    # The two lines below along with the copying\n    # before return make the TPU happy\n    tr_slice = trajectory[-self._max_slice_length:]\n    trajectory_np = tr_slice.to_np(timestep_to_np=self.task.timestep_to_np)\n    # Add batch dimension to trajectory_np and run the model.\n    pred = model(trajectory_np.observations[None, ...], n_accelerators=1)[0]\n    # Pick element 0 from the batch (the only one), last (current) timestep.\n    pred = pred[0, -1, :]\n    sample = self._policy_dist.sample(pred, temperature=temperature)\n    return (sample.copy(), pred.copy())\n\n  def train_epoch(self):\n    """"""Trains RL for one epoch.""""""\n    n_evals = rl_training.remaining_evals(\n        self._trainer.step,\n        self._epoch,\n        self._train_steps_per_epoch,\n        self._supervised_evals_per_epoch)\n    for _ in range(n_evals):\n      self._trainer.train_epoch(\n          self._train_steps_per_epoch // self._supervised_evals_per_epoch,\n          self._supervised_eval_steps)\n\n\nclass PPOJointTrainer(ActorCriticJointTrainer):\n  """"""The Proximal Policy Optimization Algorithm aka PPO.\n\n  Trains policy and value models using the PPO algortithm.\n  """"""\n\n  # TODO(henrykm): make on_policy more generic\n  # (currently epochs are passed manually)\n  on_policy = True\n\n  def __init__(self, task, epsilon=0.2, value_loss_coeff=0.1,\n               entropy_coeff=0.01, **kwargs):\n    """"""Configures the PPO Trainer.""""""\n    self._epsilon = epsilon\n    self._value_loss_coeff = value_loss_coeff\n    self._entropy_coeff = entropy_coeff\n    super(PPOJointTrainer, self).__init__(task, **kwargs)\n    self._trainer = supervised.Trainer(\n        model=self._joint_model,\n        optimizer=self._optimizer,\n        lr_schedule=self._lr_schedule,\n        loss_fn=self.joint_loss,\n        inputs=self._inputs,\n        output_dir=self._output_dir,\n        metrics={\'joint_loss\': self.joint_loss,\n                 \'advantage_mean\': self.advantage_mean,\n                 \'advantage_norm\': self.advantage_norm,\n                 \'value_loss\': self.value_loss,\n                 \'explained_variance\': self.explained_variance,\n                 \'log_probs_mean\': self.log_probs_mean,\n                 \'entropy_loss\': self.entropy_loss,\n                 \'probs_ratio_mean\': self.probs_ratio_mean,\n                 \'unclipped_objective_mean\': self.unclipped_objective_mean,\n                 \'clipped_objective_mean\': self.clipped_objective_mean,\n                 \'ppo_objective_mean\': self.ppo_objective_mean,\n                 \'clip_fraction\': self.clip_fraction,\n                 \'preferred_move\': self.preferred_move,\n                 \'approximate_kl_divergence\': self.approximate_kl_divergence})\n\n  def batches_stream(self):\n    """"""Use the RLTask self._task to create inputs to the value model.""""""\n    for np_trajectory in self._task.trajectory_batch_stream(\n        self._batch_size, max_slice_length=self._max_slice_length, epochs=[-1]):\n      if np_trajectory.dist_inputs is not None:\n        old_dist_inputs = np_trajectory.dist_inputs\n      else:\n        old_dist_inputs = jnp.zeros(\n            np_trajectory.rewards.shape + (self._policy_dist.n_inputs,)\n        )\n      old_log_probs = self._policy_dist.log_prob(\n          old_dist_inputs, np_trajectory.actions\n      )\n      # Insert an extra depth dimension, so the target shape is consistent with\n      # the network output shape.\n      yield (np_trajectory.observations,         # Inputs to the value model.\n             np_trajectory.returns[:, :, None],\n             np_trajectory.actions,\n             old_log_probs,\n             np_trajectory.mask)\n\n  @property\n  def joint_loss(self):\n    """"""Joint policy and value loss.""""""\n    def f(dist_inputs, values, returns, actions, old_log_probs, mask):\n      """"""Definition of the Proximal Policy Optimization loss.""""""\n      del mask  # TODO(lukaszkaiser): make PPO work with Transformer\n      # We have dist_inputs of the shape float32[128,1,18]\n      assert len(dist_inputs.shape) == 3, (\n          f\'dist_inputs.shape was {dist_inputs.shape}\'\n          f\'but expected length of the tensor shape is 3\')\n      # values of the shape float32[128,1,1]\n      # returns of the shape float32[128,1,1]\n      # and old_log_probs of the shape float32[128,1]\n      assert values.shape == returns.shape, (\n          f\'values.shape was {values.shape}\'\n          f\'returns.shape was {returns.shape}\')\n      assert returns.shape[0:2] == old_log_probs.shape, (\n          f\'returns.shape was {returns.shape}\'\n          f\'old_log_probs.shape was {old_log_probs.shape}\')\n\n      # actions is a tensor of the shape int32[128,1] in the case\n      # of discrete actions and float32[128,1,6] in the case of\n      # half-cheetah and other continuous actions\n      # actions agree with returns/values on the first two coordinates\n      # meaning batch and time\n      assert actions.shape[0:2] == returns.shape[0:2], (\n          f\'actions.shape was {actions.shape} and \'\n          f\'returns.shape was {returns.shape}\')\n\n      ppo_objective = rl_layers.PPOObjective(\n          dist_inputs, stop_gradient(values), returns, actions, old_log_probs,\n          log_prob_fun=self._policy_dist.log_prob,\n          epsilon=self._epsilon,\n          normalize_advantages=self._normalize_advantages)\n\n      # we insist that ppo_objective is a vector of shape [128,1]\n      assert len(ppo_objective.shape) == 2, (\n          f\'ppo_objective was {ppo_objective}\')\n      # which agrees with returns/values/actions on the first two coordinates\n      assert ppo_objective.shape[0:2] == values.shape[0:2], (\n          f\'ppo_objective.shape was {ppo_objective.shape} and \'\n          f\'values.shape was {values.shape}\')\n\n      entropy_loss = rl_layers.EntropyLoss(\n          dist_inputs, actions,\n          log_prob_fun=self._policy_dist.log_prob,\n          entropy_coeff=self._entropy_coeff,\n          entropy_fun=self._policy_dist.entropy)\n\n      assert jnp.ndim(entropy_loss) == 0, f\'entropy_loss was {entropy_loss}\'\n\n      l2_value_loss = rl_layers.ValueLoss(\n          values, returns, value_loss_coeff=self._value_loss_coeff)\n\n      assert jnp.ndim(l2_value_loss) == 0, f\'l2_value_loss was {l2_value_loss}\'\n\n      return -ppo_objective.mean() + l2_value_loss - entropy_loss\n\n    return tl.Fn(\'PPOJointLoss\', f)\n\n  # pylint: disable=invalid-name\n  @property\n  def probs_ratio_mean(self):\n    """"""Joint policy and value loss layer.""""""\n    def ProbsRatioMean(dist_inputs, actions, old_log_probs):\n      """"""Probability Ratio Mean from the PPO algorithm.""""""\n      probs_ratio = rl_layers.ProbsRatio(\n          dist_inputs, actions, old_log_probs,\n          log_prob_fun=self._policy_dist.log_prob)\n      return jnp.mean(probs_ratio)\n\n    def f(dist_inputs, values, returns, actions, old_log_probs):\n      del values, returns\n      return ProbsRatioMean(dist_inputs, actions, old_log_probs)\n    return tl.Fn(\'ProbsRatioMean\', f)\n\n  @property\n  def clip_fraction(self):\n    """"""Joint policy and value loss layer.""""""\n    def ClipFraction(dist_inputs, actions, old_log_probs):\n      """"""Probability Ratio Mean from the PPO algorithm.""""""\n      probs_ratio = rl_layers.ProbsRatio(\n          dist_inputs, actions, old_log_probs,\n          log_prob_fun=self._policy_dist.log_prob)\n      return jnp.mean(jnp.abs(probs_ratio - 1) > self._epsilon)\n\n    def f(dist_inputs, values, returns, actions, old_log_probs):\n      del values, returns\n      return ClipFraction(dist_inputs, actions, old_log_probs)\n    return tl.Fn(\'ClipFraction\', f)\n  # pylint: enable=invalid-name\n\n  @property\n  def entropy_loss(self):\n    """"""Entropy layer.""""""\n    def f(dist_inputs, values, returns, actions):\n      del values, returns\n      return rl_layers.EntropyLoss(\n          dist_inputs, actions, log_prob_fun=self._policy_dist.log_prob,\n          entropy_coeff=self._entropy_coeff,\n          entropy_fun=self._policy_dist.entropy)\n    return tl.Fn(\'EntropyLoss\', f)\n\n  @property\n  def approximate_kl_divergence(self):\n    """"""Approximate KL divergence.""""""\n    def f(dist_inputs, values, returns, actions, old_log_probs):\n      del values, returns\n      return rl_layers.ApproximateKLDivergence(\n          dist_inputs,\n          actions,\n          old_log_probs,\n          log_prob_fun=self._policy_dist.log_prob)\n    return tl.Fn(\'ApproximateKLDivergence\', f)\n\n  @property\n  def unclipped_objective_mean(self):\n    def f(dist_inputs, values, returns, actions, old_log_probs):\n      """"""Unclipped objective Mean from the PPO algorithm.""""""\n      advantages = returns - values\n      probs_ratio = rl_layers.ProbsRatio(\n          dist_inputs, actions, old_log_probs,\n          log_prob_fun=self._policy_dist.log_prob)\n      # advantages are of the shape [128,1,1]\n      # and probs_ratio are of the shape [128,1]\n      advantages = advantages.squeeze(axis=2)\n      unclipped_objective = rl_layers.UnclippedObjective(\n          probs_ratio, advantages)\n      return jnp.mean(unclipped_objective)\n\n    return tl.Fn(\'UnclippedObjectiveMean\', f)\n\n  @property\n  def clipped_objective_mean(self):\n    def f(dist_inputs, values, returns, actions, old_log_probs):\n      """"""Clipped objective from the PPO algorithm.""""""\n      advantages = returns - values\n      probs_ratio = rl_layers.ProbsRatio(\n          dist_inputs, actions, old_log_probs,\n          log_prob_fun=self._policy_dist.log_prob)\n      # advantages are of the shape [128,1,1]\n      # and probs_ratio are of the shape [128,1]\n      advantages = advantages.squeeze(axis=2)\n      clipped_objective = rl_layers.ClippedObjective(\n          probs_ratio, advantages, epsilon=self._epsilon)\n      return jnp.mean(clipped_objective)\n\n    return tl.Fn(\'ClippedObjectiveMean\', f)\n\n  @property\n  def ppo_objective(self):\n    """"""PPO objective with local parameters.""""""\n    def f(dist_inputs, values, returns, actions, old_log_probs):\n      return rl_layers.PPOObjective(\n          dist_inputs, values, returns, actions, old_log_probs,\n          log_prob_fun=self._policy_dist.log_prob,\n          epsilon=self._epsilon,\n          normalize_advantages=self._normalize_advantages)\n    return tl.Fn(\'PPOObjective\', f)\n\n  @property\n  def ppo_objective_mean(self):\n    """"""PPO objective mean.""""""\n    def f(dist_inputs, values, returns, actions, old_log_probs):\n      """"""Clipped objective from the PPO algorithm.""""""\n      ppo_objective = rl_layers.PPOObjective(\n          dist_inputs, values, returns, actions, old_log_probs,\n          log_prob_fun=self._policy_dist.log_prob,\n          epsilon=self._epsilon,\n          normalize_advantages=self._normalize_advantages)\n      return jnp.mean(ppo_objective)\n    return tl.Fn(\'PPOObjectiveMean\', f)\n\n\nclass A2CJointTrainer(ActorCriticJointTrainer):\n  """"""The A2C algorithm.\n\n  Trains policy and value models using the A2C algortithm.\n  """"""\n\n  on_policy = True\n\n  def __init__(self, task, value_loss_coeff=0.1,\n               entropy_coeff=0.01, **kwargs):\n    """"""Configures the A2C Trainer.""""""\n    self._value_loss_coeff = value_loss_coeff\n    self._entropy_coeff = entropy_coeff\n    super(A2CJointTrainer, self).__init__(task, **kwargs)\n    self._trainer = supervised.Trainer(\n        model=self._joint_model,\n        optimizer=self._optimizer,\n        lr_schedule=self._lr_schedule,\n        loss_fn=self.joint_loss,\n        inputs=self._inputs,\n        output_dir=self._output_dir,\n        metrics={\'joint_loss\': self.joint_loss,\n                 \'advantage_mean\': self.advantage_mean,\n                 \'advantage_norm\': self.advantage_norm,\n                 \'value_loss\': self.value_loss,\n                 \'explained_variance\': self.explained_variance,\n                 \'log_probs_mean\': self.log_probs_mean,\n                 \'entropy_loss\': self.entropy_loss,\n                 \'a2c_objective_mean\': self.a2c_objective_mean,\n                 \'approximate_kl_divergence\': self.approximate_kl_divergence,\n                 \'preferred_move\': self.preferred_move})\n\n  def batches_stream(self):\n    """"""Use the RLTask self._task to create inputs to the value model.""""""\n    for np_trajectory in self._task.trajectory_batch_stream(\n        self._batch_size, max_slice_length=self._max_slice_length, epochs=[-1]):\n      # Insert an extra depth dimension, so the target shape is consistent with\n      # the network output shape.\n      yield (np_trajectory.observations,         # Inputs to the value model.\n             np_trajectory.returns[:, :, None],\n             np_trajectory.actions,\n             jnp.zeros_like(np_trajectory.mask),\n             np_trajectory.mask)\n\n  @property\n  def joint_loss(self):\n    """"""Joint policy and value loss.""""""\n    def f(dist_inputs, values, returns, actions, old_log_probs, mask):\n      """"""Definition of the A2C loss.""""""\n      del old_log_probs\n\n      # Typically we have dist_inputs of the shape float32[128,1,18]\n      assert len(dist_inputs.shape) == 3, (\n          f\'dist_inputs.shape was {dist_inputs.shape} \'\n          f\'but expected length of the tensor shape is 3\')\n      # values of the shape float32[128,1,1]\n      # returns of the shape float32[128,1,1]\n      assert values.shape == returns.shape, (\n          f\'values.shape was {values.shape}\'\n          f\'returns.shape was (returns.shape)\')\n      # actions of the shape int32[128,1] in the case of discrete actions\n      # and float32[128,1,6] in the case of of half-cheetah\n      # actions agree with returns/values on the first two coordinates\n      assert actions.shape[0:2] == returns.shape[0:2], (\n          f\'actions.shape was {actions.shape}\'\n          f\'returns.shape was (returns.shape)\')\n      # and mask of the shape float32[128,1]\n      assert len(mask.shape) == 2, f\'mask.shape was {mask.shape}\'\n      # which agrees with returns/values/actions on the first two coordinates\n      assert mask.shape[0:2] == returns.shape[0:2], (\n          f\'mask.shape was {mask.shape}\'\n          f\'returns.shape was (returns.shape)\')\n\n      a2c_objective = rl_layers.A2CObjective(\n          dist_inputs,\n          stop_gradient(values),\n          returns, actions, mask,\n          log_prob_fun=self._policy_dist.log_prob,\n          normalize_advantages=self._normalize_advantages)\n\n      # we insist that a2c_objective is a scalar\n      assert jnp.ndim(a2c_objective) == 0, f\'a2c_objective was {a2c_objective}\'\n\n      entropy_loss = rl_layers.EntropyLoss(\n          dist_inputs, actions,\n          log_prob_fun=self._policy_dist.log_prob,\n          entropy_coeff=self._entropy_coeff,\n          entropy_fun=self._policy_dist.entropy)\n\n      assert jnp.ndim(entropy_loss) == 0, f\'entropy_loss was {entropy_loss}\'\n\n      l2_value_loss = rl_layers.ValueLoss(\n          values, returns, value_loss_coeff=self._value_loss_coeff)\n\n      assert jnp.ndim(l2_value_loss) == 0, f\'l2_value_loss was {l2_value_loss}\'\n\n      combined_loss = a2c_objective + l2_value_loss - entropy_loss\n\n      return combined_loss\n\n    return tl.Fn(\'A2CJointLoss\', f, n_out=1)\n\n  @property\n  def entropy_loss(self):\n    """"""Entropy layer.""""""\n    def f(dist_inputs, values, returns, actions):\n      del values, returns\n      return rl_layers.EntropyLoss(\n          dist_inputs, actions, log_prob_fun=self._policy_dist.log_prob,\n          entropy_coeff=self._entropy_coeff,\n          entropy_fun=self._policy_dist.entropy)\n    return tl.Fn(\'EntropyLoss\', f)\n\n  @property\n  def approximate_kl_divergence(self):\n    """"""Approximate KL divergence.""""""\n    def f(dist_inputs, values, returns, actions, old_log_probs):\n      del values, returns\n      return rl_layers.ApproximateKLDivergence(\n          dist_inputs,\n          actions,\n          old_log_probs,\n          log_prob_fun=self._policy_dist.log_prob)\n    return tl.Fn(\'ApproximateKLDivergence\', f)\n\n  @property\n  def a2c_objective(self):\n    """"""A2C objective with local parameters.""""""\n    return tl.Fn(\n        \'A2CObjective\',\n        lambda dist_inputs, values, returns, actions, old_log_probs, mask:\n        rl_layers.A2CObjective(\n            dist_inputs, values, returns, actions, mask,\n            log_prob_fun=self._policy_dist.log_prob,\n            normalize_advantages=self._normalize_advantages),\n        n_out=1)\n\n  @property\n  def a2c_objective_mean(self):\n    """"""PPO objective mean.""""""\n    def f(dist_inputs, values, returns, actions, old_log_probs, mask):\n      """"""A2C objective mean.""""""\n      del old_log_probs\n      a2c_objective = rl_layers.A2CObjective(\n          dist_inputs, values, returns, actions, mask,\n          log_prob_fun=self._policy_dist.log_prob,\n          normalize_advantages=self._normalize_advantages)\n      return jnp.mean(a2c_objective)\n    return tl.Fn(\'A2CObjectiveMean\', f, n_out=1)\n\n\nclass AWRJointTrainer(ActorCriticJointTrainer):\n  """"""Trains a joint policy-and-value model using AWR.""""""\n\n  # TODO(henrykm): value_loss_coeff looks like a common parameter\n  def __init__(self, task, value_loss_coeff=0.1, beta=1.0, w_max=20.0,\n               **kwargs):\n    """"""Configures the joint AWR Trainer.""""""\n    self._beta = beta\n    self._w_max = w_max\n    self._value_loss_coeff = value_loss_coeff\n    super(AWRJointTrainer, self).__init__(task, **kwargs)\n\n  def batches_stream(self):\n    """"""Use the RLTask self._task to create inputs to the value model.""""""\n    for np_trajectory in self._task.trajectory_batch_stream(\n        self._batch_size, max_slice_length=self._max_slice_length):\n      # Insert an extra depth dimension, so the target shape is consistent with\n      # the network output shape.\n      yield (np_trajectory.observations,         # Inputs to the value model.\n             np_trajectory.returns[:, :, None],  # Targets: regress to returns.\n             np_trajectory.actions,              # Policy targets: actions.\n             np_trajectory.mask)                 # Padding mask.\n\n  @property\n  def joint_loss(self):\n    """"""Joint policy and value loss.""""""\n\n    def f(preds, values, returns, actions, mask):\n      advantages = jnp.squeeze(returns - stop_gradient(values), axis=-1)\n      logps = self._policy_dist.log_prob(preds, actions)\n      awr_loss = actor_critic.AWRLoss(beta=self._beta, w_max=self._w_max)(\n          (logps, advantages, jnp.zeros_like(logps), mask))\n      l2_value_loss = jnp.mean((returns - values)**2) * self._value_loss_coeff\n      return awr_loss + l2_value_loss\n    return tl.Fn(\'AWRJointLoss\', f)\n'"
trax/rl/actor_critic_joint_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for RL training.""""""\n\nimport functools\n\nfrom absl.testing import absltest\n\nfrom trax import layers as tl\nfrom trax import lr_schedules\nfrom trax import models\nfrom trax import optimizers as opt\nfrom trax import test_utils\nfrom trax.rl import actor_critic_joint\nfrom trax.rl import task as rl_task\n\n\n\nclass ActorCriticJointTest(absltest.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    test_utils.ensure_flag(\'test_tmpdir\')\n\n  def test_awrjoint_save_restore(self):\n    """"""Check save and restore of joint AWR trainer.""""""\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=100,\n                          max_steps=200)\n    joint_model = functools.partial(\n        models.PolicyAndValue,\n        body=lambda mode: tl.Serial(tl.Dense(64), tl.Relu()),\n    )\n    tmp_dir = self.create_tempdir().full_path\n    trainer1 = actor_critic_joint.AWRJointTrainer(\n        task,\n        joint_model=joint_model,\n        optimizer=opt.Adam,\n        batch_size=4,\n        train_steps_per_epoch=1,\n        n_trajectories_per_epoch=2,\n        output_dir=tmp_dir)\n    trainer1.run(2)\n    self.assertEqual(trainer1.current_epoch, 2)\n    self.assertEqual(trainer1._trainer.step, 2)\n    # Trainer 2 starts where trainer 1 stopped.\n    trainer2 = actor_critic_joint.AWRJointTrainer(\n        task,\n        joint_model=joint_model,\n        optimizer=opt.Adam,\n        batch_size=4,\n        train_steps_per_epoch=1,\n        n_trajectories_per_epoch=2,\n        output_dir=tmp_dir)\n    trainer2.run(1)\n    self.assertEqual(trainer2.current_epoch, 3)\n    self.assertEqual(trainer2._trainer.step, 3)\n    trainer1.close()\n    trainer2.close()\n\n\n  def test_jointppotrainer_cartpole(self):\n    """"""Test-runs joint PPO on CartPole.""""""\n\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=0,\n                          max_steps=2)\n    joint_model = functools.partial(\n        models.PolicyAndValue,\n        body=lambda mode: tl.Serial(tl.Dense(2), tl.Relu()),\n    )\n    lr = lambda h: lr_schedules.MultifactorSchedule(  # pylint: disable=g-long-lambda\n        h, constant=1e-2, warmup_steps=100, factors=\'constant * linear_warmup\')\n\n    trainer = actor_critic_joint.PPOJointTrainer(\n        task,\n        joint_model=joint_model,\n        optimizer=opt.Adam,\n        lr_schedule=lr,\n        batch_size=4,\n        train_steps_per_epoch=2,\n        n_trajectories_per_epoch=5)\n    trainer.run(2)\n    self.assertEqual(2, trainer.current_epoch)\n\n  def test_jointawrtrainer_cartpole(self):\n    """"""Test-runs joint AWR on cartpole.""""""\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=100,\n                          max_steps=200)\n    joint_model = functools.partial(\n        models.PolicyAndValue,\n        body=lambda mode: tl.Serial(tl.Dense(64), tl.Relu()),\n    )\n    lr = lambda h: lr_schedules.MultifactorSchedule(  # pylint: disable=g-long-lambda\n        h, constant=1e-2, warmup_steps=100, factors=\'constant * linear_warmup\')\n    trainer = actor_critic_joint.AWRJointTrainer(\n        task,\n        joint_model=joint_model,\n        optimizer=opt.Adam,\n        lr_schedule=lr,\n        batch_size=4,\n        train_steps_per_epoch=2,\n        n_trajectories_per_epoch=5)\n    trainer.run(2)\n    self.assertEqual(2, trainer.current_epoch)\n\n  def test_jointa2ctrainer_cartpole(self):\n    """"""Test-runs joint A2C on cartpole.""""""\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=100,\n                          max_steps=200)\n    joint_model = functools.partial(\n        models.PolicyAndValue,\n        body=lambda mode: tl.Serial(tl.Dense(64), tl.Relu()),\n    )\n    lr = lambda h: lr_schedules.MultifactorSchedule(  # pylint: disable=g-long-lambda\n        h, constant=1e-2, warmup_steps=100, factors=\'constant * linear_warmup\')\n    trainer = actor_critic_joint.A2CJointTrainer(\n        task,\n        joint_model=joint_model,\n        optimizer=opt.RMSProp,\n        lr_schedule=lr,\n        batch_size=2,\n        train_steps_per_epoch=1,\n        n_trajectories_per_epoch=1)\n    trainer.run(2)\n    self.assertEqual(2, trainer.current_epoch)\n\n  def test_jointawrtrainer_cartpole_transformer(self):\n    """"""Test-runs joint AWR on cartpole with Transformer.""""""\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=1,\n                          max_steps=2)\n    body = lambda mode: models.TransformerDecoder(  # pylint: disable=g-long-lambda\n        d_model=32, d_ff=32, n_layers=1, n_heads=1, mode=mode)\n    joint_model = functools.partial(models.PolicyAndValue, body=body)\n    trainer = actor_critic_joint.AWRJointTrainer(\n        task,\n        joint_model=joint_model,\n        optimizer=opt.Adam,\n        batch_size=4,\n        train_steps_per_epoch=2,\n        n_trajectories_per_epoch=2,\n        max_slice_length=2)\n    trainer.run(2)\n    self.assertEqual(2, trainer.current_epoch)\n\n  def test_jointa2ctrainer_cartpole_transformer(self):\n    """"""Test-runs joint A2C on cartpole with Transformer.""""""\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=100,\n                          max_steps=200)\n    body = lambda mode: models.TransformerDecoder(  # pylint: disable=g-long-lambda\n        d_model=32, d_ff=32, n_layers=1, n_heads=1, mode=mode)\n    joint_model = functools.partial(models.PolicyAndValue, body=body)\n    trainer = actor_critic_joint.A2CJointTrainer(\n        task,\n        joint_model=joint_model,\n        optimizer=opt.RMSProp,\n        batch_size=4,\n        train_steps_per_epoch=2,\n        n_trajectories_per_epoch=2)\n    trainer.run(2)\n    self.assertEqual(2, trainer.current_epoch)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/rl/actor_critic_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for RL training.""""""\n\nimport functools\nimport math\n\nfrom absl.testing import absltest\n\nfrom trax import layers as tl\nfrom trax import lr_schedules\nfrom trax import models\nfrom trax import optimizers as opt\nfrom trax import test_utils\nfrom trax.rl import actor_critic\nfrom trax.rl import advantages\nfrom trax.rl import task as rl_task\n\n\nclass ActorCriticTest(absltest.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    test_utils.ensure_flag(\'test_tmpdir\')\n\n  def test_a2ctrainer_save_restore(self):\n    """"""Check save and restore of A2C trainer.""""""\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=0,\n                          max_steps=20)\n    body = lambda mode: tl.Serial(tl.Dense(64), tl.Relu())\n    policy_model = functools.partial(models.Policy, body=body)\n    value_model = functools.partial(models.Value, body=body)\n    tmp_dir = self.create_tempdir().full_path\n    trainer1 = actor_critic.A2CTrainer(\n        task,\n        value_model=value_model,\n        value_optimizer=opt.Adam,\n        value_batch_size=2,\n        value_train_steps_per_epoch=1,\n        policy_model=policy_model,\n        policy_optimizer=opt.Adam,\n        policy_batch_size=2,\n        policy_train_steps_per_epoch=2,\n        n_trajectories_per_epoch=2,\n        n_shared_layers=1,\n        output_dir=tmp_dir)\n    trainer1.run(2)\n    self.assertEqual(trainer1.current_epoch, 2)\n    self.assertEqual(trainer1._value_trainer.step, 2)\n    self.assertEqual(trainer1._policy_trainer.step, 4)\n    # Trainer 2 starts where trainer 1 stopped.\n    trainer2 = actor_critic.A2CTrainer(\n        task,\n        value_model=value_model,\n        value_optimizer=opt.Adam,\n        value_batch_size=2,\n        value_train_steps_per_epoch=1,\n        policy_model=policy_model,\n        policy_optimizer=opt.Adam,\n        policy_batch_size=2,\n        policy_train_steps_per_epoch=2,\n        n_trajectories_per_epoch=2,\n        n_shared_layers=1,\n        output_dir=tmp_dir)\n    trainer2.run(1)\n    self.assertEqual(trainer2.current_epoch, 3)\n    self.assertEqual(trainer2._value_trainer.step, 3)\n    self.assertEqual(trainer2._policy_trainer.step, 6)\n    trainer1.close()\n    trainer2.close()\n\n  def test_sanity_a2ctrainer_cartpole(self):\n    """"""Test-runs a2c on cartpole.""""""\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=0,\n                          max_steps=2)\n    body = lambda mode: tl.Serial(tl.Dense(64), tl.Relu())\n    policy_model = functools.partial(models.Policy, body=body)\n    value_model = functools.partial(models.Value, body=body)\n    lr = lambda h: lr_schedules.MultifactorSchedule(  # pylint: disable=g-long-lambda\n        h, constant=1e-4, warmup_steps=100, factors=\'constant * linear_warmup\')\n    trainer = actor_critic.A2CTrainer(\n        task,\n        n_shared_layers=1,\n        value_model=value_model,\n        value_optimizer=opt.Adam,\n        value_lr_schedule=lr,\n        value_batch_size=2,\n        value_train_steps_per_epoch=2,\n        policy_model=policy_model,\n        policy_optimizer=opt.Adam,\n        policy_lr_schedule=lr,\n        policy_batch_size=2,\n        policy_train_steps_per_epoch=2,\n        n_trajectories_per_epoch=2)\n    trainer.run(2)\n    self.assertEqual(2, trainer.current_epoch)\n\n  def test_sanity_ppo_cartpole(self):\n    """"""Run PPO and check whether it correctly runs for 2 epochs.s.""""""\n    task = rl_task.RLTask(\n        \'CartPole-v1\', initial_trajectories=0, max_steps=200)\n\n    lr = lambda h: lr_schedules.MultifactorSchedule(  # pylint: disable=g-long-lambda\n        h, constant=1e-3,\n        warmup_steps=100,\n        factors=\'constant * linear_warmup\')\n\n    body = lambda mode: tl.Serial(tl.Dense(64), tl.Relu())\n    policy_model = functools.partial(models.Policy, body=body)\n    value_model = functools.partial(models.Value, body=body)\n    trainer = actor_critic.PPOTrainer(\n        task,\n        n_shared_layers=1,\n        value_model=value_model,\n        value_optimizer=opt.Adam,\n        value_lr_schedule=lr,\n        value_batch_size=128,\n        value_train_steps_per_epoch=10,\n        policy_model=policy_model,\n        policy_optimizer=opt.Adam,\n        policy_lr_schedule=lr,\n        policy_batch_size=128,\n        policy_train_steps_per_epoch=10,\n        n_trajectories_per_epoch=10)\n\n    trainer.run(2)\n    self.assertEqual(2, trainer.current_epoch)\n\n  def test_awrtrainer_cartpole(self):\n    """"""Test-runs AWR on cartpole.""""""\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=1000,\n                          max_steps=200)\n    body = lambda mode: tl.Serial(tl.Dense(64), tl.Relu())\n    policy_model = functools.partial(models.Policy, body=body)\n    value_model = functools.partial(models.Value, body=body)\n    lr = lambda h: lr_schedules.MultifactorSchedule(  # pylint: disable=g-long-lambda\n        h, constant=1e-2, warmup_steps=100, factors=\'constant * linear_warmup\')\n    trainer = actor_critic.AWRTrainer(\n        task,\n        n_shared_layers=0,\n        added_policy_slice_length=1,\n        value_model=value_model,\n        value_optimizer=opt.Adam,\n        value_lr_schedule=lr,\n        value_batch_size=32,\n        value_train_steps_per_epoch=200,\n        policy_model=policy_model,\n        policy_optimizer=opt.Adam,\n        policy_lr_schedule=lr,\n        policy_batch_size=32,\n        policy_train_steps_per_epoch=200,\n        n_trajectories_per_epoch=10,\n        advantage_estimator=advantages.monte_carlo,\n        advantage_normalization=False,\n    )\n    trainer.run(1)\n    self.assertEqual(1, trainer.current_epoch)\n    self.assertGreater(trainer.avg_returns[-1], 35.0)\n\n  def test_awrtrainer_cartpole_shared(self):\n    """"""Test-runs AWR on cartpole with shared layers.""""""\n    # This test is flaky, and this is the simplest way to retry in OSS.\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=1000,\n                          max_steps=200)\n    body = lambda mode: tl.Serial(tl.Dense(64), tl.Relu())\n    policy_model = functools.partial(models.Policy, body=body)\n    value_model = functools.partial(models.Value, body=body)\n    # pylint: disable=g-long-lambda\n    lr = (\n        lambda h: lr_schedules.MultifactorSchedule(\n            h, constant=1e-2, warmup_steps=100,\n            factors=\'constant * linear_warmup\')\n    )\n    # pylint: enable=g-long-lambda\n    max_avg_returns = -math.inf\n    for _ in range(5):\n      trainer = actor_critic.AWRTrainer(\n          task,\n          n_shared_layers=1,\n          added_policy_slice_length=1,\n          value_model=value_model,\n          value_optimizer=opt.Adam,\n          value_lr_schedule=lr,\n          value_batch_size=32,\n          value_train_steps_per_epoch=200,\n          policy_model=policy_model,\n          policy_optimizer=opt.Adam,\n          policy_lr_schedule=lr,\n          policy_batch_size=32,\n          policy_train_steps_per_epoch=200,\n          n_trajectories_per_epoch=10,\n          advantage_estimator=advantages.monte_carlo,\n          advantage_normalization=False,\n      )\n      trainer.run(1)\n      self.assertEqual(1, trainer.current_epoch)\n      max_avg_returns = (\n          max_avg_returns if max_avg_returns > trainer.avg_returns[-1]\n          else trainer.avg_returns[-1])\n      if trainer.avg_returns[-1] > 35.0:\n        return\n    self.fail(f\'We did not reach a score > 35.0, max was {max_avg_returns}.\')\n\n  def test_sanity_awrtrainer_transformer_cartpole(self):\n    """"""Test-runs AWR on cartpole with Transformer.""""""\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=2,\n                          max_steps=2)\n    body = lambda mode: models.TransformerDecoder(  # pylint: disable=g-long-lambda\n        d_model=2, d_ff=2, n_layers=1, n_heads=1, mode=mode)\n    policy_model = functools.partial(models.Policy, body=body)\n    value_model = functools.partial(models.Value, body=body)\n    lr = lambda h: lr_schedules.MultifactorSchedule(  # pylint: disable=g-long-lambda\n        h, constant=1e-2, warmup_steps=100, factors=\'constant * linear_warmup\')\n    trainer = actor_critic.AWRTrainer(\n        task,\n        n_shared_layers=0,\n        max_slice_length=2,\n        added_policy_slice_length=1,\n        value_model=value_model,\n        value_optimizer=opt.Adam,\n        value_lr_schedule=lr,\n        value_batch_size=2,\n        value_train_steps_per_epoch=2,\n        policy_model=policy_model,\n        policy_optimizer=opt.Adam,\n        policy_lr_schedule=lr,\n        policy_batch_size=2,\n        policy_train_steps_per_epoch=2,\n        n_trajectories_per_epoch=1,\n        n_eval_episodes=1)\n    trainer.run(2)\n    self.assertEqual(2, trainer.current_epoch)\n\n  def test_sampling_awrtrainer_cartpole(self):\n    """"""Test-runs AWR on cartpole with Transformer.""""""\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=0,\n                          max_steps=20)\n    body = lambda mode: tl.Serial(tl.Dense(2), tl.Relu())\n    policy_model = functools.partial(models.Policy, body=body)\n    value_model = functools.partial(models.Value, body=body)\n    lr = lambda h: lr_schedules.MultifactorSchedule(  # pylint: disable=g-long-lambda\n        h, constant=1e-2, warmup_steps=100, factors=\'constant * linear_warmup\')\n    trainer = actor_critic.SamplingAWRTrainer(\n        task,\n        n_shared_layers=0,\n        added_policy_slice_length=1,\n        value_model=value_model,\n        value_optimizer=opt.Adam,\n        value_lr_schedule=lr,\n        value_batch_size=2,\n        value_train_steps_per_epoch=2,\n        policy_model=policy_model,\n        policy_optimizer=opt.Adam,\n        policy_lr_schedule=lr,\n        policy_batch_size=2,\n        policy_train_steps_per_epoch=2,\n        n_trajectories_per_epoch=2,\n        advantage_estimator=advantages.monte_carlo,\n        advantage_normalization=False,\n        q_value_n_samples=3,\n        q_value_aggregate_max=True,\n        reweight=False,\n        vocab_size=16\n    )\n    trainer.run(1)\n    self.assertEqual(1, trainer.current_epoch)\n\n  def test_sampling_awrtrainer_mountain_acr(self):\n    """"""Test-runs Sampling AWR on MountainCarContinuous.""""""\n    task = rl_task.RLTask(\'MountainCarContinuous-v0\', initial_trajectories=0,\n                          max_steps=2)\n    body = lambda mode: tl.Serial(tl.Dense(2), tl.Relu())\n    policy_model = functools.partial(models.Policy, body=body)\n    value_model = functools.partial(models.Value, body=body)\n    lr = lambda h: lr_schedules.MultifactorSchedule(  # pylint: disable=g-long-lambda\n        h, constant=1e-2, warmup_steps=100, factors=\'constant * linear_warmup\')\n    trainer = actor_critic.SamplingAWRTrainer(\n        task,\n        n_shared_layers=0,\n        added_policy_slice_length=1,\n        value_model=value_model,\n        value_optimizer=opt.Adam,\n        value_lr_schedule=lr,\n        value_batch_size=2,\n        value_train_steps_per_epoch=2,\n        policy_model=policy_model,\n        policy_optimizer=opt.Adam,\n        policy_lr_schedule=lr,\n        policy_batch_size=2,\n        policy_train_steps_per_epoch=2,\n        n_trajectories_per_epoch=2,\n        advantage_estimator=advantages.monte_carlo,\n        advantage_normalization=False,\n        q_value_n_samples=3,\n    )\n    trainer.run(1)\n    self.assertEqual(1, trainer.current_epoch)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/rl/advantages.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""RL advantage estimators.""""""\n\nimport gin\nimport numpy as np\n\n\ncommon_args = [\n    \'rewards\', \'returns\', \'values\', \'dones\', \'gamma\', \'n_extra_steps\'\n]\n\n\n@gin.configurable(blacklist=common_args)\ndef monte_carlo(rewards, returns, values, dones, gamma, n_extra_steps):\n  """"""Calculate Monte Carlo advantage.\n\n  We assume the values are a tensor of shape [batch_size, length] and this\n  is the same shape as rewards and returns.\n\n  Args:\n    rewards: the rewards, tensor of shape [batch_size, length]\n    returns: discounted returns, tensor of shape [batch_size, length]\n    values: the value function computed for this trajectory (shape as above)\n    dones: trajectory termination flags\n    gamma: float, gamma parameter for TD from the underlying task\n    n_extra_steps: number of extra steps in the sequence\n\n  Returns:\n    the advantages, a tensor of shape [batch_size, length - n_extra_steps].\n  """"""\n  del gamma\n  (_, length) = returns.shape\n  # Make sure that the future returns and the values at ""done"" states are zero.\n  returns[dones] = rewards[dones]\n  values[dones] = 0\n  return (returns - values)[:, :(length - n_extra_steps)]\n\n\n@gin.configurable(blacklist=common_args)\ndef td_k(rewards, returns, values, dones, gamma, n_extra_steps):\n  """"""Calculate TD-k advantage.\n\n  The k parameter is assumed to be the same as n_extra_steps.\n\n  We calculate advantage(s_i) as:\n\n    gamma^n_steps * value(s_{i + n_steps}) - value(s_i) + discounted_rewards\n\n  where discounted_rewards is the sum of rewards in these steps with\n  discounting by powers of gamma.\n\n  Args:\n    rewards: the rewards, tensor of shape [batch_size, length]\n    returns: discounted returns, tensor of shape [batch_size, length]\n    values: the value function computed for this trajectory (shape as above)\n    dones: trajectory termination flags\n    gamma: float, gamma parameter for TD from the underlying task\n    n_extra_steps: number of extra steps in the sequence, also controls the\n      number of steps k\n\n  Returns:\n    the advantages, a tensor of shape [batch_size, length - n_extra_steps].\n  """"""\n  del returns\n  # Here we calculate advantage with TD-k, where k=n_extra_steps.\n  k = n_extra_steps\n  assert k > 0\n  advantages = (gamma ** k) * values[:, k:]\n  discount = 1.0\n  for i in range(n_extra_steps):\n    advantages += discount * rewards[:, i:-(n_extra_steps - i)]\n    discount *= gamma\n  # Zero out the future returns at ""done"" states.\n  dones = dones[:, :-k]\n  advantages[dones] = rewards[:, :-k][dones]\n  # Subtract the baseline (value).\n  advantages -= values[:, :-k]\n  return advantages\n\n\n@gin.configurable(blacklist=common_args)\ndef td_lambda(\n    rewards, returns, values, dones, gamma, n_extra_steps, lambda_=0.95\n):\n  """"""Calculate TD-lambda advantage.\n\n  The estimated return is an exponentially-weighted average of different TD-k\n  returns.\n\n  Args:\n    rewards: the rewards, tensor of shape [batch_size, length]\n    returns: discounted returns, tensor of shape [batch_size, length]\n    values: the value function computed for this trajectory (shape as above)\n    dones: trajectory termination flags\n    gamma: float, gamma parameter for TD from the underlying task\n    n_extra_steps: number of extra steps in the sequence\n    lambda_: discount parameter of the exponentially-weighted average\n\n  Returns:\n    the advantages, a tensor of shape [batch_size, length - n_extra_steps].\n  """"""\n  td_returns = np.zeros_like(returns)\n  (_, length) = returns.shape\n  td_returns[:, -1] = values[:, -1]\n  for i in reversed(range(length - 1)):\n    td_returns[:, i] = rewards[:, i] + (1 - dones[:, i]) * gamma * (\n        (1 - lambda_) * values[:, i + 1] + lambda_ * td_returns[:, i + 1]\n    )\n  return (td_returns - values)[:, :(returns.shape[1] - n_extra_steps)]\n\n\ncommon_args = [\'rewards\', \'values\', \'gamma\', \'gae_lambda\', \'n_extra_steps\']\n\n\n@gin.configurable(blacklist=common_args)\ndef discount_gae(rewards, values, gamma, n_extra_steps, gae_lambda=0.95):\n  """"""Calculate Generalized Advantage Estimation.\n\n  Calculate state values bootstrapping off the following state values -\n  Generalized Advantage Estimation https://arxiv.org/abs/1506.02438\n\n  Args:\n    rewards: the rewards, tensor of shape [batch_size, length]\n    values: the value function computed for this trajectory (shape as above)\n    gamma: float, gamma parameter for TD from the underlying task\n    n_extra_steps: number of extra steps in the sequence\n    gae_lambda: discount parameter of the exponentially-weighted average\n\n  Returns:\n    the advantages, a tensor of shape [batch_size, length - n_extra_steps].\n  """"""\n\n  advantages = np.zeros_like(rewards)\n  (_, length) = rewards.shape\n\n  # Accmulate sums\n  sum_accumulator = 0\n\n  for i in reversed(range(length-1)):\n    bellman_delta = (rewards[:, i] + gamma * values[:, i + 1] - values[:, i])\n\n    advantages[:, i] = sum_accumulator = (\n        bellman_delta + gamma * gae_lambda * sum_accumulator)\n\n  return advantages[:, :(rewards.shape[1] - n_extra_steps)]\n'"
trax/rl/advantages_test.py,21,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for trax.rl.advantages.""""""\n\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\nimport numpy as np\n\nfrom trax.rl import advantages\n\n\ndef calc_bias_and_variance(x, true_mean):\n  sample_mean = np.mean(x)\n  bias = np.abs(sample_mean - true_mean)\n  variance = np.mean((x - sample_mean) ** 2)\n  return (bias, variance)\n\n\ndef calc_returns(rewards, gamma):\n  returns = np.zeros_like(rewards)\n  current_return = np.zeros_like(rewards[:, 0])\n  for t in reversed(range(rewards.shape[1])):\n    current_return = gamma * current_return + rewards[:, t]\n    returns[:, t] = current_return\n  return returns\n\n\ndef estimate_advantage_bias_and_variance(\n    advantage_fn,\n    mean_reward=1.23,\n    reward_noise=0.45,\n    n_samples=10000,\n    length=5,\n    gamma=0.9,\n    n_extra_steps=0,\n    gae=False,\n    **advantage_kwargs\n):\n  rewards = np.random.normal(\n      loc=mean_reward, scale=reward_noise, size=(n_samples, length)\n  )\n  returns = calc_returns(rewards, gamma=gamma)\n  values = np.zeros_like(returns)\n  dones = np.zeros_like(returns, dtype=np.bool)\n  if gae:\n    adv = advantage_fn(\n        rewards, values, gamma=gamma, n_extra_steps=n_extra_steps,\n        **advantage_kwargs\n    )\n  else:\n    adv = advantage_fn(\n        rewards=rewards,\n        returns=returns,\n        values=values,\n        dones=dones,\n        gamma=gamma,\n        n_extra_steps=n_extra_steps,\n        **advantage_kwargs\n    )\n  mean_return = calc_returns(\n      np.full((1, length), fill_value=mean_reward), gamma=gamma\n  )[0, 0]\n  return calc_bias_and_variance(adv[:, 0], mean_return)\n\n\nclass AdvantagesTest(parameterized.TestCase):\n\n  @parameterized.named_parameters(\n      (\'monte_carlo\', advantages.monte_carlo),\n      (\'td_k\', advantages.td_k),\n      (\'td_lambda\', advantages.td_lambda),\n  )\n  def test_shapes(self, advantage_fn):\n    rewards = np.array([[1, 1, 1]], dtype=np.float32)\n    returns = np.array([[3, 2, 1]], dtype=np.float32)\n    values = np.array([[2, 2, 2]], dtype=np.float32)\n    dones = np.array([[False, False, True]])\n    adv1 = advantage_fn(\n        rewards, returns, values, dones, gamma=1, n_extra_steps=1\n    )\n    self.assertEqual(adv1.shape, (1, 2))\n    adv2 = advantage_fn(\n        rewards, returns, values, dones, gamma=1, n_extra_steps=2\n    )\n    self.assertEqual(adv2.shape, (1, 1))\n\n  def test_shapes_gae(self):\n    rewards = np.array([[1, 1, 1]], dtype=np.float32)\n    values = np.array([[2, 2, 2]], dtype=np.float32)\n    adv1 = advantages.discount_gae(rewards, values, gamma=1, n_extra_steps=1)\n    self.assertEqual(adv1.shape, (1, 2))\n    adv2 = advantages.discount_gae(rewards, values, gamma=1, n_extra_steps=2)\n    self.assertEqual(adv2.shape, (1, 1))\n\n  def test_monte_carlo_bias_is_zero(self):\n    (bias, _) = estimate_advantage_bias_and_variance(\n        advantages.monte_carlo, n_extra_steps=3\n    )\n    np.testing.assert_allclose(bias, 0, atol=0.1)\n\n  def test_td_k_variance_lower_than_monte_carlo(self):\n    (_, var_td_3) = estimate_advantage_bias_and_variance(\n        advantages.td_k, n_extra_steps=3\n    )\n    (_, var_mc) = estimate_advantage_bias_and_variance(advantages.monte_carlo)\n    self.assertLess(var_td_3, var_mc)\n\n  @parameterized.named_parameters((\'1_2\', 1, 2), (\'2_3\', 2, 3))\n  def test_td_k_bias_decreases_with_k(self, k1, k2):\n    (bias1, _) = estimate_advantage_bias_and_variance(\n        advantages.td_k, n_extra_steps=k1\n    )\n    (bias2, _) = estimate_advantage_bias_and_variance(\n        advantages.td_k, n_extra_steps=k2\n    )\n    self.assertGreater(bias1, bias2)\n\n  @parameterized.named_parameters((\'1_2\', 1, 2), (\'2_3\', 2, 3))\n  def test_td_k_variance_increases_with_k(self, k1, k2):\n    (_, var1) = estimate_advantage_bias_and_variance(\n        advantages.td_k, n_extra_steps=k1\n    )\n    (_, var2) = estimate_advantage_bias_and_variance(\n        advantages.td_k, n_extra_steps=k2\n    )\n    self.assertLess(var1, var2)\n\n  def test_td_lambda_variance_lower_than_monte_carlo(self):\n    (_, var_td_095) = estimate_advantage_bias_and_variance(\n        advantages.td_lambda, lambda_=0.95\n    )\n    (_, var_mc) = estimate_advantage_bias_and_variance(advantages.monte_carlo)\n    self.assertLess(var_td_095, var_mc)\n\n  @parameterized.named_parameters((\'0.5_0.7\', 0.5, 0.7), (\'0.7_0.9\', 0.7, 0.9))\n  def test_td_lambda_bias_decreases_with_lambda(self, lambda1, lambda2):\n    (bias1, _) = estimate_advantage_bias_and_variance(\n        advantages.td_lambda, lambda_=lambda1\n    )\n    (bias2, _) = estimate_advantage_bias_and_variance(\n        advantages.td_lambda, lambda_=lambda2\n    )\n    self.assertGreater(bias1, bias2)\n\n  @parameterized.named_parameters((\'0.5_0.7\', 0.5, 0.7), (\'0.7_0.9\', 0.7, 0.9))\n  def test_td_lambda_variance_increases_with_lambda(self, lambda1, lambda2):\n    (_, var1) = estimate_advantage_bias_and_variance(\n        advantages.td_lambda, lambda_=lambda1\n    )\n    (_, var2) = estimate_advantage_bias_and_variance(\n        advantages.td_lambda, lambda_=lambda2\n    )\n    self.assertLess(var1, var2)\n\n  @parameterized.named_parameters((\'0.5_0.7\', 0.5, 0.7), (\'0.7_0.9\', 0.7, 0.9))\n  def test_gae_bias_decreases_with_gae_lambda(self, gae_lambda1, gae_lambda2):\n    (bias1, _) = estimate_advantage_bias_and_variance(\n        advantages.discount_gae, gae_lambda=gae_lambda1, gae=True,\n    )\n    (bias2, _) = estimate_advantage_bias_and_variance(\n        advantages.discount_gae, gae_lambda=gae_lambda2, gae=True,\n    )\n    self.assertGreater(bias1, bias2)\n\n  @parameterized.named_parameters((\'0.5_0.7\', 0.5, 0.7), (\'0.7_0.9\', 0.7, 0.9))\n  def test_gae_variance_increases_with_gae_lambda(self, gae_lambda1,\n                                                  gae_lambda2):\n    (_, var1) = estimate_advantage_bias_and_variance(\n        advantages.discount_gae, gae_lambda=gae_lambda1, gae=True,\n    )\n    (_, var2) = estimate_advantage_bias_and_variance(\n        advantages.discount_gae, gae_lambda=gae_lambda2, gae=True,\n    )\n    self.assertLess(var1, var2)\n\n  @parameterized.named_parameters(\n      (\'monte_carlo\', advantages.monte_carlo),\n      (\'td_k\', advantages.td_k),\n      (\'td_lambda\', advantages.td_lambda),\n  )\n  def test_advantage_future_return_is_zero_at_done(self, advantage_fn):\n    rewards = np.array([[1, 1, 1]], dtype=np.float32)\n    returns = np.array([[3, 2, 1]], dtype=np.float32)\n    values = np.array([[2, 2, 2]], dtype=np.float32)\n    dones = np.array([[False, True, False]])\n    adv = advantage_fn(\n        rewards, returns, values, dones, gamma=0.9, n_extra_steps=1\n    )\n    target_returns = values[:, :-1] + adv\n    # Assert that in the ""done"" state the future return in the advantage is\n    # zero, i.e. the advantage is equal to the reward.\n    np.testing.assert_almost_equal(target_returns[0, 1], rewards[0, 1])\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/rl/atari_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for RL training.""""""\n\nimport functools\n\nfrom absl.testing import absltest\n\nfrom trax import lr_schedules\nfrom trax import models\nfrom trax import optimizers as opt\nfrom trax.models import atari_cnn\nfrom trax.rl import actor_critic\nfrom trax.rl import task as rl_task\n\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/rl/awr_trainer.py,31,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Trainer for Advantage Weighted Regression (AWR).""""""\n\nimport functools\nimport os\nimport time\nfrom absl import logging\nfrom jax.api import grad\nfrom jax.api import jit\nimport numpy as np\nfrom tensor2tensor.envs import env_problem\nfrom trax import jaxboard\nfrom trax.math import numpy as jnp\nfrom trax.rl import awr_utils\nfrom trax.rl import policy_based_trainer\nfrom trax.rl import policy_based_utils\nfrom trax.rl.trajectory import replay_buffer\n\n\nclass AwrTrainer(policy_based_trainer.PolicyBasedTrainer):\n  """"""Trainer for AWR.""""""\n\n  ADV_EPS = 1e-5\n\n  def __init__(self,\n               train_env: env_problem.EnvProblem,\n               eval_env: env_problem.EnvProblem,\n               td_lambda=0.95,\n               gamma=0.99,\n               replay_buffer_sample_size=50000,\n               num_samples_to_collect=2048,\n               temperature=0.05,\n               weight_clip=20,\n               actor_batch_size=256,\n               critic_batch_size=256,\n               actor_optimization_steps=1000,\n               critic_optimization_steps=500,\n               actor_momentum=0.9,\n               critic_momentum=0.9,\n               actor_learning_rate=5e-5,\n               critic_learning_rate=1e-4,\n               actor_loss_weight=1.0,\n               entropy_bonus=0.01,\n               **kwargs):\n    super(AwrTrainer, self).__init__(train_env, eval_env, **kwargs)\n\n    self._td_lambda = td_lambda\n    self._gamma = gamma\n    self._replay_buffer_sample_size = replay_buffer_sample_size\n    self._num_samples_to_collect = num_samples_to_collect\n    self._temperature = temperature\n    self._weight_clip = weight_clip\n    self._actor_batch_size = actor_batch_size\n    self._critic_batch_size = critic_batch_size\n    self._actor_optimization_steps = actor_optimization_steps\n    self._critic_optimization_steps = critic_optimization_steps\n    self._actor_momentum = actor_momentum\n    self._critic_momentum = critic_momentum\n    self._actor_learning_rate = actor_learning_rate\n    self._critic_learning_rate = critic_learning_rate\n    self._actor_loss_weight = actor_loss_weight\n    self._entropy_bonus = entropy_bonus\n\n    # Unified loss.\n    self._optimization_batch_size = critic_batch_size\n    self._optimization_steps = critic_optimization_steps\n    self._momentum = critic_momentum\n    self._learning_rate = critic_learning_rate\n\n    self._replay_buffer = replay_buffer.ReplayBuffer(\n        buffer_size=replay_buffer_sample_size)\n\n    # self._action_space and _observation_space were set in the base class.\n    self._action_shape = self._action_space.shape\n    self._action_dtype = self._action_space.dtype\n    self._observation_shape = self._observation_space.shape\n    self._observation_dtype = self._observation_space.dtype\n\n    # TODO(afrozm): Offload all these to `trainer_lib.Trainer`.\n    self._total_opt_step = 0\n    # TODO(afrozm): Ensure that this is updated.\n    self._n_observations_seen = 0\n    self._opt_sw = None\n\n  def reset(self, output_dir=None):\n    super(AwrTrainer, self).reset(output_dir=output_dir)\n\n    if self._should_write_summaries:\n      self._opt_sw = jaxboard.SummaryWriter(\n          os.path.join(self._output_dir, \'opt\'))\n\n    # Reset the replay buffer.\n    self._replay_buffer.clear()\n    self._replay_buffer.buffers = None\n\n    # TODO(afrozm): Ensure that this is updated.\n    self._n_observations_seen = 0\n\n  def collect_trajectories(self, train=True, **kwargs):\n    env = self.train_env if train else self.eval_env\n    # Get a specific number of `samples` if train, else complete trajectories.\n    n_trajectories = None if train else env.batch_size\n    n_observations = self._num_samples_to_collect if train else None\n\n    return super(AwrTrainer, self).collect_trajectories(\n        train=train,\n        n_trajectories=n_trajectories,\n        n_observations=n_observations,\n        **kwargs)\n\n  def train_epoch(self, evaluate=True):\n    epoch_start_time = time.time()\n\n    # Evaluate the policy.\n    policy_eval_start_time = time.time()\n    if evaluate and (self.epoch + 1) % self._eval_every_n == 0:\n      self.evaluate()\n    policy_eval_time = policy_based_utils.get_time(policy_eval_start_time)\n\n    def write_metric(key, value):\n      self._train_sw.scalar(key, value, step=self.epoch)\n      self._history.append(\'train\', key, self.epoch, value)\n\n    # Get fresh trajectories every time.\n    self._should_reset_train_env = True\n\n    trajectory_collection_start_time = time.time()\n    logging.vlog(1, \'AWR epoch [% 6d]: collecting trajectories.\', self._epoch)\n    trajs, _, timing_info, self._model_state = self.collect_trajectories(\n        train=True, temperature=1.0, raw_trajectory=True)\n    del timing_info\n    trajectory_collection_time = policy_based_utils.get_time(\n        trajectory_collection_start_time\n    )\n\n    logging.vlog(1, \'AWR epoch [% 6d]: n_trajectories [%s].\',\n                 self._epoch, len(trajs))\n\n    # Convert these into numpy now.\n    def extract_obs_act_rew_dones(traj_np):\n      return traj_np[0], traj_np[1], traj_np[2], traj_np[4]\n\n    trajs_np = [extract_obs_act_rew_dones(traj.as_numpy) for traj in trajs]\n\n    # number of new actions.\n    new_sample_count = sum(traj[1].shape[0] for traj in trajs_np)\n    self._n_observations_seen += new_sample_count\n    logging.vlog(1, \'AWR epoch [% 6d]: new_sample_count [%d].\',\n                 self._epoch, new_sample_count)\n\n    if self._should_write_summaries:\n      write_metric(\'trajs/batch\', len(trajs))\n      write_metric(\'trajs/new_sample_count\', new_sample_count)\n\n    # The number of trajectories, i.e. `B`can keep changing from iteration to\n    # iteration, since we are capped on the number of observations requested.\n    # So let\'s operate on each trajectory on this own?\n\n    # TODO(afrozm): So should our batches look like (B, T+1, *OBS) or B\n    # different examples of (T+1, *OBS) each. Since B can keep changing?\n\n    # Add these to the replay buffer.\n    for traj in trajs:\n      _ = self._replay_buffer.store(traj)\n\n    rewards = jnp.array([jnp.sum(traj[2]) for traj in trajs_np])\n    avg_reward = jnp.mean(rewards)\n    std_reward = jnp.std(rewards)\n    max_reward = jnp.max(rewards)\n    min_reward = jnp.min(rewards)\n\n    self._log(\'train\', \'train/reward_mean_truncated\', avg_reward)\n    if evaluate and not self._separate_eval and self._should_write_summaries:\n      metrics = {\'raw\': {1.0: {\'mean\': avg_reward, \'std\': std_reward}}}\n      policy_based_utils.write_eval_reward_summaries(metrics, self._log,\n                                                     self.epoch)\n\n    logging.vlog(\n        1, \'AWR epoch [% 6d]: Rewards avg=[%0.2f], max=[%0.2f], \'\n        \'min=[%0.2f].\', self.epoch, avg_reward, max_reward, min_reward)\n\n    if self._should_write_summaries:\n      write_metric(\'reward/avg\', avg_reward)\n      write_metric(\'reward/std\', std_reward)\n      write_metric(\'reward/max\', max_reward)\n      write_metric(\'reward/min\', min_reward)\n\n    # Wrap these observations/rewards inside ReplayBuffer.\n    idx, valid_mask, valid_idx = self._replay_buffer.get_valid_indices()\n\n    # pylint: disable=g-complex-comprehension\n    observations = [\n        self._replay_buffer.get(replay_buffer.ReplayBuffer.OBSERVATIONS_KEY,\n                                idx[start_idx:end_plus_1_idx])\n        for (start_idx,\n             end_plus_1_idx) in self._replay_buffer.iterate_over_paths(idx)\n    ]\n\n    rewards = [\n        self._replay_buffer.get(replay_buffer.ReplayBuffer.REWARDS_KEY,\n                                idx[start_idx:end_plus_1_idx][:-1])\n        for (start_idx,\n             end_plus_1_idx) in self._replay_buffer.iterate_over_paths(idx)\n    ]\n    # pylint: enable=g-complex-comprehension\n\n    t_final = awr_utils.padding_length(rewards, boundary=self._boundary)\n    logging.vlog(1, \'AWR epoch [% 6d]: t_final [%s].\', self._epoch, t_final)\n\n    if self._should_write_summaries:\n      write_metric(\'trajs/t_final\', t_final)\n\n    # These padded observations are over *all* the non-final observations in\n    # the entire replay buffer.\n    # Shapes:\n    # padded_observations      = (B, T + 1, *OBS)\n    # padded_observations_mask = (B, T + 1)\n    padded_observations, padded_observations_mask = (\n        awr_utils.pad_array_to_length(observations, t_final + 1)\n    )\n\n    batch = len(observations)\n    self._check_shapes(\'padded_observations\', \'(batch, t_final + 1)\',\n                       padded_observations, (batch, t_final + 1),\n                       array_prefix=2)\n    self._check_shapes(\'padded_observations_mask\', \'(batch, t_final + 1)\',\n                       padded_observations_mask, (batch, t_final + 1))\n\n    # Shapes:\n    # padded_rewards      = (B, T)\n    # padded_rewards_mask = (B, T)\n    padded_rewards, padded_rewards_mask = awr_utils.pad_array_to_length(\n        rewards, t_final)\n    self._check_shapes(\'padded_rewards\', \'(batch, t_final)\',\n                       padded_rewards, (batch, t_final))\n    self._check_shapes(\'padded_rewards_mask\', \'(batch, t_final)\',\n                       padded_rewards_mask, (batch, t_final))\n\n    # Shapes:\n    # lengths = (B,)\n    lengths = jnp.sum(padded_rewards_mask, axis=1, dtype=jnp.int32)\n    self._check_shapes(\'lengths\', \'(batch,)\', lengths, (batch,))\n\n    # TODO(pkozakowski): Pass the actual actions here, to enable autoregressive\n    # action sampling.\n    dummy_actions = jnp.zeros(\n        (batch, t_final + 1) + self._action_shape,\n        self._action_dtype,\n    )\n\n    # Shapes:\n    # log_probabs_traj       = (B, T + 1, #controls, #actions)\n    # value_predictions_traj = (B, T + 1)\n    log_probabs_traj, value_predictions_traj, self._model_state, unused_rng = (\n        self._policy_fun_all_timesteps(\n            padded_observations, lengths, self._model_state, self._get_rng())\n    )\n    self._check_shapes(\'log_probabs_traj\',\n                       \'(batch, t_final + 1, n_controls, n_actions)\',\n                       log_probabs_traj,\n                       (batch, t_final + 1, self._n_controls, self._n_actions))\n    self._check_shapes(\'value_predictions_traj\',\n                       \'(batch, t_final + 1)\',\n                       value_predictions_traj,\n                       (batch, t_final + 1))\n\n    # Zero out the padding\'s value predictions, since the net may give some\n    # prediction to the padding observations.\n    value_predictions_traj *= padded_observations_mask\n\n    # Compute td-lambda returns, and reshape to match value_predictions_traj.\n    list_td_lambda_returns = awr_utils.batched_compute_td_lambda_return(\n        padded_rewards, padded_rewards_mask, value_predictions_traj,\n        padded_observations_mask, self._gamma, self._td_lambda)\n\n    if logging.vlog_is_on(1) and list_td_lambda_returns:\n      l = len(list_td_lambda_returns)\n      logging.vlog(1, f\'Len of list_td_lambda_returns: {l}.\')\n      self._log_shape(\'td_lambda_returns[0]\', list_td_lambda_returns[0])\n\n    # pad an extra 0 for each to match lengths of value predictions.\n    list_target_values = [\n        np.pad(l, (0, 1), \'constant\') for l in list_td_lambda_returns\n    ]\n\n    if batch != len(list_target_values):\n      raise ValueError(f\'batch != len(list_target_values) : \'\n                       f\'{batch} vs {len(list_target_values)}\')\n\n    # Shape: (len(idx),)\n    target_values = np.concatenate(list_target_values)\n    self._check_shapes(\'target_values\', \'(len(idx),)\',\n                       target_values, (len(idx),))\n\n    # Shape: (len(idx),)\n    vals = self.flatten_vals(value_predictions_traj, padded_observations_mask)\n    self._check_shapes(\'vals\', \'(len(idx),)\', vals, (len(idx),))\n\n    # Calculate advantages.\n    adv, norm_adv, adv_mean, adv_std = self._calc_adv(\n        target_values, vals, valid_mask)\n    self._check_shapes(\'norm_adv\', \'(len(idx),)\', norm_adv, (len(idx),))\n\n    adv_weights, adv_weights_mean, adv_weights_min, adv_weights_max = (\n        self._calc_adv_weights(norm_adv, valid_mask)\n    )\n    self._check_shapes(\'adv_weights\', \'(len(idx),)\', adv_weights, (len(idx),))\n\n    del adv, adv_mean, adv_std\n    del adv_weights_min, adv_weights_max, adv_weights_mean\n\n    combined_steps = int(\n        jnp.ceil(self._optimization_steps * new_sample_count /\n                 self._num_samples_to_collect))\n    optimization_start_time = time.time()\n    combined_losses = self._update_combined(combined_steps, valid_idx,\n                                            target_values, adv_weights)\n    optimization_time = policy_based_utils.get_time(optimization_start_time)\n\n    self._epoch += 1\n\n    if self._should_write_summaries:\n      write_metric(\'combined/optimization_steps\', combined_steps)\n      epoch_time = policy_based_utils.get_time(epoch_start_time)\n      timing_dict = {\n          \'epoch\': epoch_time,\n          \'trajectory_collection\': trajectory_collection_time,\n          \'optimization\': optimization_time,\n          \'policy_eval\': policy_eval_time,\n      }\n\n      if self._should_write_summaries:\n        for k, v in timing_dict.items():\n          write_metric(\'timing/{}\'.format(k), v)\n\n      # Only dump the average post losses.\n      if combined_losses:\n        for k, v in combined_losses.items():\n          if \'post_entropy\' in k:\n            write_metric(k.replace(\'post_entropy\', \'entropy\'), v)\n          if \'post_loss\' in k:\n            write_metric(k.replace(\'post_loss\', \'loss\'), v)\n\n    self.flush_summaries()\n\n  def maybe_save(self):\n    # MuJoCo envs don\'t seem to be returning `done` and we just cut them to\n    # `max_timestep` anyways.\n    # TODO(afrozm): Refactor to trax.save_trainer_state.\n    if (self.epoch % self._save_every_n == 0) or self._async_mode:\n      self.save()\n\n  def flatten_vals(self, value_predictions_traj, padded_observations_mask):\n    batch = len(padded_observations_mask)\n    lens = jnp.sum(padded_observations_mask, axis=1)\n    return jnp.concatenate(\n        [value_predictions_traj[b][:int(lens[b])] for b in range(batch)])\n\n  def _step_combined(self, observations, actions, critic_target,\n                     advantage_weights):\n    key = self._get_rng()\n\n    pre_c_loss, pre_a_loss, pre_ent_val, self._model_state = combined_loss(\n        self._policy_and_value_net_weights,\n        observations,\n        actions,\n        critic_target,\n        advantage_weights,\n        self._policy_and_value_net_apply,\n        self.train_env.action_space,\n        state=self._model_state,\n        rng=key,\n    )\n\n    key = self._get_rng()\n\n    self._policy_and_value_opt_state, self._model_state = (\n        combined_opt_step(\n            self._total_opt_step,\n            self._policy_and_value_opt_state,\n            self._policy_and_value_opt_update,\n            self._policy_and_value_get_params,\n            self._policy_and_value_net_apply,\n            observations,\n            actions,\n            critic_target,\n            advantage_weights,\n            self._actor_loss_weight,\n            self._entropy_bonus,\n            self.train_env.action_space,\n            state=self._model_state,\n            rng=key,\n        ))\n\n    key = self._get_rng()\n\n    post_c_loss, post_a_loss, post_ent_val, self._model_state = combined_loss(\n        self._policy_and_value_net_weights,\n        observations,\n        actions,\n        critic_target,\n        advantage_weights,\n        self._policy_and_value_net_apply,\n        self.train_env.action_space,\n        state=self._model_state,\n        rng=key,\n    )\n\n    combined_pre_loss = combine_loss_components(\n        pre_c_loss, pre_a_loss, pre_ent_val, self._actor_loss_weight,\n        self._entropy_bonus)\n    combined_post_loss = combine_loss_components(\n        post_c_loss, post_a_loss, post_ent_val, self._actor_loss_weight,\n        self._entropy_bonus)\n\n    loss_dict = {\n        \'critic/loss_pre\': pre_c_loss,\n        \'critic/loss_post\': post_c_loss,\n        \'critic/loss_reduction\': 1 - (post_c_loss/pre_c_loss),\n        \'actor/loss_pre\': pre_a_loss,\n        \'actor/loss_post\': post_a_loss,\n        \'actor/loss_reduction\': 1 - (post_a_loss/pre_a_loss),\n        \'combined/loss_pre\': combined_pre_loss,\n        \'combined/loss_post\': combined_post_loss,\n        \'combined/loss_reduction\': 1 - (combined_post_loss/combined_pre_loss),\n        \'combined/entropy_pre\': pre_ent_val,\n        \'combined/entropy_post\': post_ent_val,\n        \'combined/entropy_reduction\': 1 - (post_ent_val/pre_ent_val),\n    }\n\n    for k, v in loss_dict.items():\n      self._opt_sw.scalar(k, v, step=self._total_opt_step)\n\n    self._total_opt_step += 1\n\n    return loss_dict\n\n  def _calc_adv(self, new_vals, vals, valid_mask):\n    adv = new_vals - vals\n\n    valid_adv = adv[valid_mask]\n    adv_mean = jnp.mean(valid_adv)\n    adv_std = jnp.std(valid_adv)\n\n    norm_adv = (adv - adv_mean) / (adv_std + self.ADV_EPS)\n    return adv, norm_adv, adv_mean, adv_std\n\n  def _calc_adv_weights(self, adv, valid_mask):\n    weights = jnp.exp(adv / self._temperature)\n\n    valid_weights = weights[valid_mask]\n    weights_mean = jnp.mean(valid_weights)\n    weights_min = jnp.min(valid_weights)\n    weights_max = jnp.max(valid_weights)\n\n    weights = jnp.minimum(weights, self._weight_clip)\n    return weights, weights_mean, weights_min, weights_max\n\n  def _update_combined(self, steps, valid_idx, target_val_preds, adv_weights):\n    num_idx = valid_idx.shape[0]\n    steps_per_shuffle = int(np.ceil(num_idx / self._optimization_batch_size))\n    losses = None\n\n    for b in range(steps):\n      if b % steps_per_shuffle == 0:\n        np.random.shuffle(valid_idx)\n\n      batch_idx_beg = b * self._optimization_batch_size\n      batch_idx_end = batch_idx_beg + self._optimization_batch_size\n      batch_idx = np.array(\n          range(batch_idx_beg, batch_idx_end), dtype=np.int32)\n      batch_idx = np.mod(batch_idx, num_idx)\n\n      batch = valid_idx[batch_idx]\n      critic_batch_vals = target_val_preds[batch[:, 1]]\n\n      actor_batch_adv = adv_weights[batch[:, 1]]\n\n      # Shape: (_critic_batch_size, *OBS)\n      critic_s = self._replay_buffer.get(\n          replay_buffer.ReplayBuffer.OBSERVATIONS_KEY, batch[:, 0])\n      # Shape: (_critic_batch_size, #C)\n      actor_a = self._replay_buffer.get(\n          replay_buffer.ReplayBuffer.ACTIONS_KEY, batch[:, 0])\n\n      curr_losses = self._step_combined(critic_s, actor_a, critic_batch_vals,\n                                        actor_batch_adv)\n\n      if losses is None:\n        losses = curr_losses\n      else:\n        for key, val in curr_losses.items():\n          losses[key] += val  # pylint: disable=unsupported-assignment-operation\n\n    if losses:\n      for key in losses.keys():\n        losses[key] /= steps\n\n    return losses\n\n\n@functools.partial(jit, static_argnums=(5, 6))\ndef combined_loss(new_weights,\n                  observations,\n                  actions,\n                  target_values,\n                  advantage_weights,\n                  policy_and_value_net_apply,\n                  action_space,\n                  state=None,\n                  rng=None):\n  """"""Returns the loss components.""""""\n\n  # TODO(afrozm): This is where we need to eventually feed the earlier\n  #  observations than this observation, currently the replay buffer just gives\n  #  the observation as is, for transformer like policies, we should also get\n  #  all the earlier observations as well, and then the extra dimension will\n  #  just be time. For now we reshape as (batch, 1, *obs_shape).\n  observations = jnp.expand_dims(observations, axis=1)\n\n  (log_probab_actions_new, value_predictions_new, state_new, unused_rng_new) = (\n      policy_based_utils.run_policy_all_timesteps(\n          policy_and_value_net_apply,\n          observations,\n          new_weights,\n          state,\n          rng,\n          action_space,\n      )\n  )\n\n  critic_loss_val, intermediate_state = critic_loss(\n      observations,\n      target_values,\n      value_predictions_new,\n      state=state_new)\n  actor_loss_val, final_state = actor_loss(\n      actions,\n      advantage_weights,\n      log_probab_actions_new,\n      state=intermediate_state)\n  entropy_val = entropy(log_probab_actions_new)\n\n  return critic_loss_val, actor_loss_val, entropy_val, final_state\n\n\n@jit\ndef entropy(log_probab_actions_new):\n  """"""Entropy.""""""\n  # log_probab_actions_new\'s shape is (B, 1, A)\n  lp = log_probab_actions_new\n  p = jnp.exp(lp)\n  return -jnp.mean(lp * p)\n\n\n@jit\ndef actor_loss(actions,\n               advantage_weights,\n               log_probab_actions_new,\n               state=None):\n  """"""Actor loss.""""""\n\n  # log_probab_actions_new\'s shape is (AB, 1, #C, #A), AB is actor batch.\n  lp = jnp.squeeze(log_probab_actions_new, axis=1)\n  AB, NC = actions.shape  # pylint: disable=invalid-name\n  log_probs = lp[jnp.arange(AB)[:, None], jnp.arange(NC)[None, :], actions]\n\n  # TODO(afrozm): Clarify this.\n  #   log_probs are shaped (AB, #C), however advantage_weights are (AB,)\n  return -1.0 * jnp.mean(log_probs * advantage_weights[:, None]), state\n\n\n@jit\ndef critic_loss(observations,\n                target_values,\n                value_predictions_new,\n                state=None):\n  """"""Critic loss.""""""\n  # There is no padding involved here, these are all observations.\n  (batch, *obs_shape) = observations.shape\n  del obs_shape\n  if (batch,) != target_values.shape:\n    raise ValueError(f\'batch dimension is not the same: obs batch {batch}\'\n                     f\' vs target values batch {target_values.shape[0]}\')\n\n  # TODO(afrozm): In the reference implementation, they pass the target through\n  #  a trained normalizer before subtracting.\n\n  loss = 0.5 * jnp.mean(jnp.square(target_values - value_predictions_new))\n  return loss, state\n\n\ndef combine_loss_components(critic_loss_val, actor_loss_val, entropy_val,\n                            actor_loss_weight, entropy_bonus):\n  """"""Combine the components in the combined AWR loss.""""""\n  return critic_loss_val + (actor_loss_val * actor_loss_weight) - (\n      entropy_val * entropy_bonus)\n\n\n@functools.partial(jit, static_argnums=(2, 3, 4, 11))\ndef combined_opt_step(i,\n                      opt_state,\n                      opt_update,\n                      get_params,\n                      policy_and_value_net_apply,\n                      observations,\n                      actions,\n                      target_values,\n                      advantage_weights,\n                      actor_loss_weight,\n                      entropy_bonus,\n                      action_space,\n                      state=None,\n                      rng=None):\n  """"""Optimization step for combined loss.""""""\n\n  def _combined_loss(params, in_state):  # pylint: disable=missing-docstring\n    critic_loss_val, actor_loss_val, entropy_val, final_state = combined_loss(\n        params,\n        observations,\n        actions,\n        target_values,\n        advantage_weights,\n        policy_and_value_net_apply,\n        action_space,\n        state=in_state,\n        rng=rng,\n    )\n    return combine_loss_components(critic_loss_val, actor_loss_val, entropy_val,\n                                   actor_loss_weight,\n                                   entropy_bonus), final_state\n\n  new_weights = get_params(opt_state)\n  g, state = grad(_combined_loss, has_aux=True)(new_weights, state)\n  return opt_update(i, g, opt_state), state\n'"
trax/rl/awr_trainer_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for trax.rl.awr_trainer.""""""\n\nimport contextlib\nimport functools\nimport tempfile\nfrom absl.testing import absltest\nfrom tensor2tensor.envs import gym_env_problem\nfrom tensor2tensor.rl import gym_utils\nfrom tensorflow.compat.v1 import test\nfrom tensorflow.compat.v1.io import gfile\nfrom trax import layers\nfrom trax import optimizers\nfrom trax.rl import awr_trainer\n\n\nclass AwrTrainerTest(absltest.TestCase):\n\n  def get_wrapped_env(self,\n                      name=\'CartPole-v0\',\n                      max_episode_steps=10,\n                      batch_size=2):\n    wrapper_fn = functools.partial(\n        gym_utils.gym_env_wrapper,\n        **{\n            \'rl_env_max_episode_steps\': max_episode_steps,\n            \'maxskip_env\': False,\n            \'rendered_env\': False,\n            \'rendered_env_resize_to\': None,  # Do not resize frames\n            \'sticky_actions\': False,\n            \'output_dtype\': None,\n            \'num_actions\': None,\n        })\n\n    return gym_env_problem.GymEnvProblem(\n        base_env_name=name,\n        batch_size=batch_size,\n        env_wrapper_fn=wrapper_fn,\n        discrete_rewards=False)\n\n  @contextlib.contextmanager\n  def tmp_dir(self):\n    tmp = tempfile.mkdtemp(dir=test.get_temp_dir())\n    yield tmp\n    gfile.rmtree(tmp)\n\n  def _make_trainer(self,\n                    train_env,\n                    eval_env,\n                    output_dir,\n                    num_samples_to_collect=20,\n                    replay_buffer_sample_size=50,\n                    model=None,\n                    optimizer=None,\n                    max_timestep=None,\n                    **kwargs):\n    if model is None:\n      # pylint: disable=g-long-lambda\n      model = lambda: layers.Serial(\n          layers.Dense(32),\n          layers.Relu(),\n      )\n      # pylint: enable=g-long-lambda\n\n    if optimizer is None:\n      optimizer = functools.partial(optimizers.SGD, 5e-5)\n    return awr_trainer.AwrTrainer(\n        train_env=train_env,\n        eval_env=eval_env,\n        policy_and_value_model=model,\n        policy_and_value_optimizer=optimizer,\n        num_samples_to_collect=num_samples_to_collect,\n        replay_buffer_sample_size=replay_buffer_sample_size,\n        actor_optimization_steps=2,\n        critic_optimization_steps=2,\n        output_dir=output_dir,\n        random_seed=0,\n        max_timestep=max_timestep,\n        boundary=20,\n        actor_loss_weight=1.0,\n        entropy_bonus=0.01,\n        **kwargs)\n\n  def test_training_loop_cartpole(self):\n    with self.tmp_dir() as output_dir:\n      trainer = self._make_trainer(\n          train_env=self.get_wrapped_env(\'CartPole-v0\', 10),\n          eval_env=self.get_wrapped_env(\'CartPole-v0\', 10),\n          output_dir=output_dir,\n          num_samples_to_collect=20,\n          max_timestep=20,\n          replay_buffer_sample_size=50,\n      )\n      trainer.training_loop(n_epochs=2)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/rl/awr_utils.py,17,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Utilities for AWR.""""""\n\nfrom typing import List, Optional, Union\n\nimport numpy as np\nfrom trax.rl.trajectory import replay_buffer\n\n\ndef pad_array_to_length(list_of_ndarrays: List[np.ndarray],\n                        t_final: int,\n                        back: bool = True):\n  """"""Pads list of `(t_variable, *SHAPE)` elements to `(t_final, *SHAPE)`.""""""\n  # Each element of `list_of_ndarrays` is of shape: (t, *underlying_shape)\n  # where `t` changes but `underlying_shape` doesn\'t.\n  underlying_shape = list_of_ndarrays[0].shape[1:]\n  batch = len(list_of_ndarrays)\n  padded_objs = np.zeros(shape=(batch, t_final, *underlying_shape))\n  mask = np.ones(shape=(batch, t_final))\n  padding_config = [(0, 0)] * len(list_of_ndarrays[0].shape)\n  for i, obs in enumerate(list_of_ndarrays):\n    cfg = (0, t_final - obs.shape[0]) if back else (t_final - obs.shape[0], 0)\n    padding_config[0] = cfg\n    padded_objs[i] = np.pad(obs, padding_config, \'constant\')\n    if back:\n      mask[i, obs.shape[0]:] = 0\n    else:\n      mask[i, :t_final - obs.shape[0]] = 0\n\n  return padded_objs, mask\n\n\ndef replay_buffer_to_padded_observations(rb: replay_buffer.ReplayBuffer,\n                                         idx: Union[List[int],\n                                                    np.ndarray] = None,\n                                         boundary: Optional[int] = None):\n  """"""Gets the trajectories in the buffer at indices pads them.""""""\n  if idx is None:\n    idx = rb.get_unrolled_indices()\n\n  idx = np.asarray(idx)\n  assert len(idx.shape) == 1\n\n  observations = [\n      rb.get(replay_buffer.ReplayBuffer.OBSERVATIONS_KEY,\n             idx[start_idx:end_plus_1_idx])\n      for (start_idx, end_plus_1_idx) in rb.iterate_over_paths(idx)\n  ]\n\n  # Every element in observations is [t, *OBS] where the `t` can vary.\n  t_max = max(len(o) for o in observations)  # ex: t_max: 1500\n  if boundary is None:\n    # e such that 10^e <= t_max < 10^(e+1)\n    e = np.floor(np.log10(t_max))  # ex: e: 3\n    # we will deal in integer multiples of boundary\n    boundary = 10**e  # ex: boundary: 1000\n\n  # m (int) such that (m-1) * boundary < t_max <= m * boundary\n  m = np.ceil(t_max / boundary).astype(np.int32)  # ex: m: 2\n  t_final = int(m * boundary)  # t_final: 2000\n\n  # observations[0]\'s shape is (t,) + OBS, where OBS is the core observation\'s\n  # shape.\n  return pad_array_to_length(observations, t_final)\n\n\ndef padding_length(observations, boundary=None):\n  """"""Returns the padding length optionally given a boundary.""""""\n  # Every element in observations is [t, *OBS] where the `t` can vary.\n  t_max = max(len(o) for o in observations)  # ex: t_max: 1500\n  if boundary is None:\n    # e such that 10^e <= t_max < 10^(e+1)\n    e = np.floor(np.log10(t_max))  # ex: e: 3\n    # we will deal in integer multiples of boundary\n    boundary = 10**e  # ex: boundary: 1000\n\n  # m (int) such that (m-1) * boundary < t_max <= m * boundary\n  m = np.ceil(t_max / boundary).astype(np.int32)  # ex: m: 2\n  t_final = int(m * boundary)  # t_final: 2000\n  return t_final\n\n\ndef replay_buffer_to_padded_rewards(rb, idx, t_final):\n  """"""Pad replay buffer\'s rewards at indices to specified size.""""""\n  rewards = [\n      rb.get(\'rewards\', idx[start_idx:end_plus_1_idx][:-1])\n      for (start_idx, end_plus_1_idx) in rb.iterate_over_paths(idx)\n  ]\n  return pad_array_to_length(rewards, t_final)\n\n\ndef compute_td_lambda_return(rewards: np.ndarray, value_preds: np.ndarray,\n                             gamma: float, td_lambda: float) -> np.ndarray:\n  """"""Computes td-lambda returns.""""""\n  (t_final,) = rewards.shape\n  if value_preds.shape != (t_final + 1,):\n    raise ValueError(\n        f\'Shapes are not as expected: rewards.shape {rewards.shape}\'\n        f\'value_preds.shape = {value_preds.shape}\'\n    )\n\n  td_lambda_return = np.zeros_like(rewards)\n  td_lambda_return[-1] = rewards[-1] + (gamma * value_preds[-1])\n\n  for i in reversed(range(0, t_final - 1)):\n    td_lambda_return[i] = rewards[i] + (\n        gamma * ((1 - td_lambda) * value_preds[i + 1] +\n                 td_lambda * td_lambda_return[i + 1]))\n\n  return td_lambda_return\n\n\ndef batched_compute_td_lambda_return(padded_rewards: np.ndarray,\n                                     padded_rewards_mask: np.ndarray,\n                                     value_preds: np.ndarray,\n                                     value_preds_mask: np.ndarray,\n                                     gamma: float, td_lambda: float):\n  """"""Computes td-lambda returns, in a batched manner.""""""\n  batch, t = padded_rewards.shape\n  if ((batch, t) != padded_rewards_mask.shape or\n      ((batch, t + 1) != value_preds.shape) or\n      ((batch, t + 1) != value_preds_mask.shape)):\n    raise ValueError(\n        f\'Shapes are not as expected: batch {batch}, t {t}\'\n        f\'padded_rewards_mask.shape = {padded_rewards_mask.shape}\'\n        f\'value_preds.shape = {value_preds.shape}\'\n        f\'value_preds_mask.shape = {value_preds_mask.shape}\'\n    )\n\n  bool_padded_rewards_mask = padded_rewards_mask == 1\n  bool_value_preds_mask = value_preds_mask == 1\n\n  td_lambda_returns = []\n  for b in range(batch):\n    td_lambda_returns.append(\n        compute_td_lambda_return(\n            padded_rewards[b][bool_padded_rewards_mask[b]],\n            value_preds[b][bool_value_preds_mask[b]],\n            gamma,\n            td_lambda,\n        ))\n  return td_lambda_returns\n'"
trax/rl/awr_utils_test.py,27,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for trax.rl.awr_utils.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\nfrom tensor2tensor.envs import trajectory\nfrom trax.rl import awr_utils\nfrom trax.rl.trajectory import replay_buffer\n\n\nclass AwrUtilsTest(absltest.TestCase):\n\n  def get_random_trajectory(self,\n                            max_time_step=None,\n                            obs_shape=(2, 2)) -> trajectory.Trajectory:\n    t = trajectory.Trajectory()\n    max_time_step = max_time_step or np.random.randint(2, 10)\n    for i in range(max_time_step):\n      r = float(i)\n      t.add_time_step(\n          observation=np.random.uniform(size=obs_shape),\n          done=False,\n          raw_reward=r,\n          processed_reward=r,\n          action=int(np.random.choice(10, ())),\n          info={\n              replay_buffer.ReplayBuffer.LOGPS_KEY_TRAJ:\n                  float(np.random.uniform(low=-10, high=0))\n          })\n    t.change_last_time_step(done=True)\n    return t\n\n  def test_padding(self):\n    l = [np.ones(n) for n in [2, 3, 4]]\n    pad_back, pad_back_mask = awr_utils.pad_array_to_length(l, 5)\n    np.testing.assert_array_equal(\n        pad_back,\n        np.array([\n            [1., 1., 0., 0., 0.],\n            [1., 1., 1., 0., 0.],\n            [1., 1., 1., 1., 0.],\n        ]))\n    np.testing.assert_array_equal(pad_back, pad_back_mask)\n\n    pad_front, pad_front_mask = awr_utils.pad_array_to_length(l, 5, False)\n    np.testing.assert_array_equal(\n        pad_front,\n        np.array([\n            [0., 0., 0., 1., 1.],\n            [0., 0., 1., 1., 1.],\n            [0., 1., 1., 1., 1.],\n        ]))\n    np.testing.assert_array_equal(pad_front, pad_front_mask)\n\n  def test_replay_buffer_to_padded_observations(self):\n    traj_lengths = [10, 15, 17]\n    obs_shape = (3, 4)\n    t_final = 20  # lowest multiple of 10 that is sufficient.\n    trajs = [\n        self.get_random_trajectory(max_time_step=l, obs_shape=obs_shape)\n        for l in traj_lengths\n    ]\n    rb = replay_buffer.ReplayBuffer(2 * sum(traj_lengths))\n    for traj in trajs:\n      rb.store(traj)\n\n    padded_obs, mask = awr_utils.replay_buffer_to_padded_observations(\n        rb, None, None)\n    self.assertEqual((len(traj_lengths), t_final) + obs_shape, padded_obs.shape)\n    # pylint: disable=line-too-long\n    self.assertTrue(\n        all((mask == np.array([[\n            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n            0., 0., 0.\n        ],\n                               [\n                                   1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                                   1., 1., 1., 1., 0., 0., 0., 0., 0.\n                               ],\n                               [\n                                   1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                                   1., 1., 1., 1., 1., 1., 0., 0., 0.\n                               ]])).flatten()))\n    # pylint: enable=line-too-long\n\n    t_final = 6 * 3  # 18 is enough to cover everything.\n    padded_obs, mask = awr_utils.replay_buffer_to_padded_observations(\n        rb, None, 6)\n    self.assertEqual((len(traj_lengths), t_final) + obs_shape, padded_obs.shape)\n    # pylint: disable=line-too-long\n    self.assertTrue(\n        all((mask == np.array([[\n            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n            0.\n        ],\n                               [\n                                   1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                                   1., 1., 1., 1., 0., 0., 0.\n                               ],\n                               [\n                                   1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                                   1., 1., 1., 1., 1., 1., 0.\n                               ]])).flatten()))\n    # pylint: enable=line-too-long\n\n  def test_replay_buffer_to_padded_rewards(self):\n    traj_lengths = [10, 15, 17]\n    obs_shape = (3, 4)\n    t_final = 20  # lowest multiple of 10 that is sufficient.\n    trajs = [\n        self.get_random_trajectory(max_time_step=l, obs_shape=obs_shape)\n        for l in traj_lengths\n    ]\n    rb = replay_buffer.ReplayBuffer(2 * sum(traj_lengths))\n    for traj in trajs:\n      rb.store(traj)\n\n    idx = rb.get_unrolled_indices()\n    padded_rewards, mask = awr_utils.replay_buffer_to_padded_rewards(\n        rb, idx, t_final - 1)\n    # pylint: disable=line-too-long\n    self.assertTrue(\n        all((padded_rewards == np.array([[\n            1., 2., 3., 4., 5., 6., 7., 8., 9., 0., 0., 0., 0., 0., 0., 0., 0.,\n            0., 0.\n        ],\n                                         [\n                                             1., 2., 3., 4., 5., 6., 7., 8.,\n                                             9., 10., 11., 12., 13., 14., 0.,\n                                             0., 0., 0., 0.\n                                         ],\n                                         [\n                                             1., 2., 3., 4., 5., 6., 7., 8.,\n                                             9., 10., 11., 12., 13., 14., 15.,\n                                             16., 0., 0., 0.\n                                         ]])).flatten()))\n    self.assertTrue(\n        all((mask == np.array([[\n            1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n            0., 0.\n        ],\n                               [\n                                   1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                                   1., 1., 1., 0., 0., 0., 0., 0.\n                               ],\n                               [\n                                   1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n                                   1., 1., 1., 1., 1., 0., 0., 0.\n                               ]])).flatten()))\n    # pylint: enable=line-too-long\n\n    # import pdb; pdb.set_trace()\n\n  def test_compute_td_lambda_return(self):\n    rewards = np.array([1, 2, 4, 8, 16])\n    value_preds = np.array([1, 2, 4, 8, 16, 32])\n    gamma = 0.5\n    td_lambda = 0.5\n    td_lambda_returns = awr_utils.compute_td_lambda_return(\n        rewards, value_preds, gamma, td_lambda)\n    np.testing.assert_array_equal(\n        np.array([2, 5, 11, 20, 32]), td_lambda_returns)\n\n  def test_batched_compute_td_lambda_return(self):\n    rewards = np.array([\n        [1, 2, 4, 8, 16, 0, 0],\n        [1, 2, 4, 8, 0, 0, 0],\n    ])\n    rewards_mask = np.array(rewards > 0).astype(np.int32)\n    value_preds = np.array([\n        [1, 2, 4, 8, 16, 32, 0, 0],\n        [1, 2, 4, 8, 16, 0, 0, 0],\n    ])\n    value_preds_mask = np.array(value_preds > 0).astype(np.int32)\n    gamma = 0.5\n    td_lambda = 0.5\n    list_td_lambda_returns = awr_utils.batched_compute_td_lambda_return(\n        rewards, rewards_mask, value_preds, value_preds_mask, gamma, td_lambda)\n    np.testing.assert_array_equal(\n        np.array([2, 5, 11, 20, 32]), list_td_lambda_returns[0])\n    np.testing.assert_array_equal(\n        np.array([2, 5, 10, 16]), list_td_lambda_returns[1])\n\n  def test_critic_loss(self):\n    pass\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/rl/base_trainer.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Base class for RL trainers.""""""\n\nimport os\n\nfrom absl import logging\nimport tensorflow as tf\nfrom trax import utils\n\n\nclass BaseTrainer(object):\n  """"""Base class for RL trainers.""""""\n\n  def __init__(\n      self,\n      train_env,\n      eval_env,\n      output_dir=None,\n      trajectory_dump_dir=None,\n      trajectory_dump_min_count_per_shard=16,\n      async_mode=False,\n  ):\n    """"""Base class constructor.\n\n    Args:\n      train_env: EnvProblem to use for training. Settable.\n      eval_env: EnvProblem to use for evaluation. Settable.\n      output_dir: Directory to save checkpoints and metrics to.\n      trajectory_dump_dir: Directory to dump trajectories to. Trajectories are\n        saved in shards of name <epoch>.pkl under this directory. Settable.\n      trajectory_dump_min_count_per_shard: Minimum number of trajectories to\n        collect before dumping in a new shard. Sharding is for efficient\n        shuffling for model training in SimPLe.\n      async_mode: (bool) If True, this means we are in async mode and we read\n        trajectories from a location rather than interact with the environment.\n    """"""\n    self._train_env = None\n    self._action_space = None\n    self._observation_space = None\n\n    # A setter that sets the above three fields.\n    self.train_env = train_env\n    # Should we reset the train_env? Ex: After we set the env.\n    self._should_reset_train_env = True\n\n    self._eval_env = eval_env\n    self.trajectory_dump_dir = trajectory_dump_dir\n    self._trajectory_dump_min_count_per_shard = (\n        trajectory_dump_min_count_per_shard)\n    self._trajectory_buffer = []\n    self._async_mode = async_mode\n    self._output_dir = output_dir\n    self._trainer_reset_called = False\n\n  def reset(self, output_dir=None):\n    self._trainer_reset_called = True\n    if output_dir is not None:\n      self._output_dir = output_dir\n    assert self._output_dir is not None\n    tf.io.gfile.makedirs(self._output_dir)\n\n  @property\n  def async_mode(self):\n    return self._async_mode\n\n  @async_mode.setter\n  def async_mode(self, async_mode):\n    logging.vlog(1, \'Changing async mode from %s to: %s\', self._async_mode,\n                 async_mode)\n    self._async_mode = async_mode\n\n  def _assert_env_compatible(self, new_env):\n\n    def assert_same_space(space1, space2):\n      assert space1.shape == space2.shape\n      assert space1.dtype == space2.dtype\n\n    assert_same_space(new_env.observation_space, self._observation_space)\n    assert_same_space(new_env.action_space, self._action_space)\n\n  @property\n  def eval_env(self):\n    return self._eval_env\n\n  @property\n  def train_env(self):\n    return self._train_env\n\n  @train_env.setter\n  def train_env(self, new_train_env):\n    if self._train_env is None:\n      self._action_space = new_train_env.action_space\n      self._observation_space = new_train_env.observation_space\n    else:\n      self._assert_env_compatible(new_train_env)\n    self._train_env = new_train_env\n    self._should_reset_train_env = True\n\n  @property\n  def epoch(self):\n    raise NotImplementedError\n\n  def train_epoch(self, evaluate=True):\n    raise NotImplementedError\n\n  def evaluate(self):\n    raise NotImplementedError\n\n  def save(self):\n    raise NotImplementedError\n\n  def maybe_save(self):\n    raise NotImplementedError\n\n  def flush_summaries(self):\n    raise NotImplementedError\n\n  def dump_trajectories(self, force=False):\n    """"""Dumps trajectories in a new shard.\n\n    Should be called at most once per epoch.\n\n    Args:\n      force: (bool) Whether to complete unfinished trajectories and create a new\n        shard even if we have not reached the minimum size.\n    """"""\n    pkl_module = utils.get_pickle_module()\n    if self.trajectory_dump_dir is None:\n      return\n    tf.io.gfile.makedirs(self.trajectory_dump_dir)\n\n    trajectories = self.train_env.trajectories\n    if force:\n      trajectories.complete_all_trajectories()\n\n    # complete_all_trajectories() also adds trajectories that were just reset.\n    # We don\'t want them since they have just the initial observation and no\n    # actions, so we filter them out.\n    def has_any_action(trajectory):\n      return (trajectory.time_steps and\n              trajectory.time_steps[0].action is not None)\n\n    self._trajectory_buffer.extend(\n        filter(has_any_action, trajectories.completed_trajectories))\n\n    trajectories.clear_completed_trajectories()\n    ready = (\n        len(self._trajectory_buffer) >=\n        self._trajectory_dump_min_count_per_shard)\n    if ready or force:\n      shard_path = os.path.join(self.trajectory_dump_dir,\n                                \'{}.pkl\'.format(self.epoch))\n      if tf.io.gfile.exists(shard_path):\n        # Since we do an extra dump at the end of the training loop, we\n        # sometimes dump 2 times in the same epoch. When this happens, merge the\n        # two sets of trajectories.\n        with tf.io.gfile.GFile(shard_path, \'rb\') as f:\n          self._trajectory_buffer = pkl_module.load(f) + self._trajectory_buffer\n      with tf.io.gfile.GFile(shard_path, \'wb\') as f:\n        pkl_module.dump(self._trajectory_buffer, f)\n      self._trajectory_buffer = []\n\n  def training_loop(self, n_epochs, evaluate=True):\n    """"""RL training loop.""""""\n    if not self._trainer_reset_called:\n      logging.info(\'Calling trainer reset.\')\n      self.reset(output_dir=self._output_dir)\n\n    logging.info(\'Starting the RL training loop.\')\n    for _ in range(self.epoch, n_epochs):\n      self.train_epoch(evaluate=evaluate)\n      self.maybe_save()\n      self.dump_trajectories()\n    self.save()\n    self.dump_trajectories(force=True)\n    if evaluate:\n      self.evaluate()\n    self.flush_summaries()\n    self.indicate_done()\n\n  def indicate_done(self):\n    """"""If in async mode, workers need to know we are done.""""""\n    if not self.async_mode:\n      return\n    with tf.io.gfile.GFile(os.path.join(self._output_dir, \'__done__\'),\n                           \'wb\') as f:\n      f.write(\'\')\n'"
trax/rl/base_trainer_test.py,7,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.rl.base_trainer.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport cloudpickle as pickle\nimport numpy as np\n\nfrom tensor2tensor.envs import gym_env_problem\nfrom tensorflow import test\nfrom trax.rl import base_trainer\n\n\nclass FakeTrainer(base_trainer.BaseTrainer):\n  """"""Fake Trainer.\n\n  Adds one complete and one incomplete trajectory every epoch.\n  """"""\n\n  def __init__(self, *args, **kwargs):\n    super(FakeTrainer, self).__init__(*args, **kwargs)\n    self._epoch = 0\n    self._should_reset = True\n\n  @property\n  def epoch(self):\n    return self._epoch\n\n  def train_epoch(self):\n    trajectories = self.train_env.trajectories\n    if self._should_reset:\n      trajectories.reset(indices=np.arange(2), observations=np.zeros(2))\n    self._should_reset = False\n    trajectories.step(\n        observations=np.zeros(2),\n        raw_rewards=np.zeros(2),\n        processed_rewards=np.zeros(2),\n        dones=np.array([False, True]),\n        actions=np.zeros(2),\n    )\n    # Reset the trajectories that are done, as\n    # env_problem_utils.play_env_problem_with_policy does.\n    trajectories.reset(indices=np.array([1]), observations=np.zeros(1))\n    self._epoch += 1\n\n  def evaluate(self):\n    pass\n\n  def save(self):\n    pass\n\n  def flush_summaries(self):\n    pass\n\n\nclass BaseTrainerTest(test.TestCase):\n\n  def _make_trainer(self, min_count_per_shard):\n    train_env = gym_env_problem.GymEnvProblem(\n        base_env_name=\'Acrobot-v1\', batch_size=2)\n    eval_env = gym_env_problem.GymEnvProblem(\n        base_env_name=\'Acrobot-v1\', batch_size=1)\n    temp_dir = self.get_temp_dir()\n    return FakeTrainer(\n        train_env, eval_env,\n        output_dir=temp_dir,\n        trajectory_dump_dir=temp_dir,\n        trajectory_dump_min_count_per_shard=min_count_per_shard,\n    )\n\n  def _assert_no_shard_exists(self, trajectory_dir):\n    self.assertFalse(os.listdir(trajectory_dir))\n\n  def _assert_single_shard_exists_and_has_trajectories(\n      self, trajectory_dir, expected_trajectory_lengths):\n    shard_filenames = os.listdir(trajectory_dir)\n    self.assertEqual(len(shard_filenames), 1)\n    shard_path = os.path.join(trajectory_dir, shard_filenames[0])\n    with open(shard_path, \'rb\') as f:\n      trajectories = pickle.load(f)\n    actual_trajectory_lengths = [\n        len(trajectory.time_steps) for trajectory in trajectories]\n    self.assertEqual(\n        list(sorted(actual_trajectory_lengths)),\n        list(sorted(expected_trajectory_lengths)),\n    )\n\n  def test_dumps_full_shard(self):\n    trainer = self._make_trainer(min_count_per_shard=2)\n    trajectory_dir = self.get_temp_dir()\n\n    # Add one complete trajectory to the buffer. Should not dump yet.\n    trainer.train_epoch()\n    trainer.dump_trajectories()\n    self._assert_no_shard_exists(trajectory_dir)\n\n    # Add the second complete trajectory. Now we should dump.\n    trainer.train_epoch()\n    trainer.dump_trajectories()\n    self._assert_single_shard_exists_and_has_trajectories(\n        trajectory_dir, [2, 2])\n\n  def test_dumps_incomplete_trajectories_when_force_is_true(self):\n    trainer = self._make_trainer(min_count_per_shard=2)\n    trajectory_dir = self.get_temp_dir()\n\n    # Add one complete and one incomplete trajectory to the buffer. Should dump.\n    trainer.train_epoch()\n    trainer.dump_trajectories(force=True)\n    self._assert_single_shard_exists_and_has_trajectories(\n        trajectory_dir, [2, 2])\n\n  def test_dumps_incomplete_shard_when_force_is_true(self):\n    trainer = self._make_trainer(min_count_per_shard=4)\n    trajectory_dir = self.get_temp_dir()\n\n    # Add one complete and one incomplete trajectory to the buffer. Should dump,\n    # even though we don\'t have a full shard yet.\n    trainer.train_epoch()\n    trainer.dump_trajectories(force=True)\n    self._assert_single_shard_exists_and_has_trajectories(\n        trajectory_dir, [2, 2])\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/distributions.py,17,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Probability distributions for RL training in Trax.""""""\n\nimport gin\nimport gym\nimport numpy as np\n\nfrom trax import layers as tl\nfrom trax.math import numpy as jnp\n\n\nclass Distribution:\n  """"""Abstract class for parametrized probability distributions.""""""\n\n  @property\n  def n_inputs(self):\n    """"""Returns the number of inputs to the distribution (i.e. parameters).""""""\n    raise NotImplementedError\n\n  def sample(self, inputs, temperature=1.0):\n    """"""Samples a point from the distribution.\n\n    Args:\n      inputs (jnp.ndarray): Distribution inputs. Shape is subclass-specific.\n        Broadcasts along the first dimensions. For example, in the categorical\n        distribution parameter shape is (C,), where C is the number of\n        categories. If (B, C) is passed, the object will represent a batch of B\n        categorical distributions with different parameters.\n      temperature: sampling temperature; 1.0 is default, at 0.0 chooses\n        the most probable (preferred) action.\n\n    Returns:\n      Sampled point of shape dependent on the subclass and on the shape of\n      inputs.\n    """"""\n    raise NotImplementedError\n\n  def log_prob(self, inputs, point):\n    """"""Retrieves log probability (or log probability density) of a point.\n\n    Args:\n      inputs (jnp.ndarray): Distribution parameters.\n      point (jnp.ndarray): Point from the distribution. Shape should be\n        consistent with inputs.\n\n    Returns:\n      Array of log probabilities of points in the distribution.\n    """"""\n    raise NotImplementedError\n\n  def LogProb(self):  # pylint: disable=invalid-name\n    """"""Builds a log probability layer for this distribution.""""""\n    return tl.Fn(\'LogProb\',\n                 lambda inputs, point: self.log_prob(inputs, point))  # pylint: disable=unnecessary-lambda\n\n\n@gin.configurable(blacklist=[\'n_categories\', \'shape\'])\nclass Categorical(Distribution):\n  """"""Categorical distribution parametrized by logits.""""""\n\n  def __init__(self, n_categories, shape=()):\n    """"""Initializes Categorical distribution.\n\n    Args:\n      n_categories (int): Number of categories.\n      shape (tuple): Shape of the sample.\n    """"""\n    self._n_categories = n_categories\n    self._shape = shape\n\n  @property\n  def n_inputs(self):\n    return jnp.prod(self._shape, dtype=jnp.int32) * self._n_categories\n\n  def _unflatten_inputs(self, inputs):\n    return jnp.reshape(\n        inputs, inputs.shape[:-1] + self._shape + (self._n_categories,)\n    )\n\n  def sample(self, inputs, temperature=1.0):\n    # No need for LogSoftmax with Gumbel sampling - softmax normalization is\n    # subtracting a constant from every logit, and Gumbel sampling is taking\n    # a max over logits plus noise, so invariant to adding a constant.\n    if temperature == 0.0:\n      return jnp.argmax(self._unflatten_inputs(inputs), axis=-1)\n    return tl.gumbel_sample(self._unflatten_inputs(inputs), temperature)\n\n  def log_prob(self, inputs, point):\n    inputs = tl.LogSoftmax()(self._unflatten_inputs(inputs))\n    return jnp.sum(\n        # Select the logits specified by point.\n        inputs * tl.one_hot(point, self._n_categories),\n        # Sum over the parameter dimensions.\n        axis=[-a for a in range(1, len(self._shape) + 2)],\n    )\n\n  def entropy(self, log_probs):\n    probs = jnp.exp(log_probs)\n    return -jnp.sum(probs * log_probs, axis=-1)\n\n\n@gin.configurable(blacklist=[\'shape\'])\nclass Gaussian(Distribution):\n  """"""Independent multivariate Gaussian distribution parametrized by mean.""""""\n\n  def __init__(self, shape=(), std=1.0):\n    """"""Initializes Gaussian distribution.\n\n    Args:\n      shape (tuple): Shape of the sample.\n      std (float): Standard deviation, shared across the whole sample.\n    """"""\n    self._shape = shape\n    self._std = std\n\n  @property\n  def n_inputs(self):\n    return jnp.prod(self._shape, dtype=jnp.int32)\n\n  def sample(self, inputs, temperature=1.0):\n    if temperature == 0:\n      # this seemingly strange if solves the problem\n      # of calling np/jnp.random in the metric PreferredMove\n      return inputs\n    else:\n      return np.random.normal(\n          loc=jnp.reshape(inputs, inputs.shape[:-1] + self._shape),\n          scale=self._std * temperature,\n      )\n\n  def log_prob(self, inputs, point):\n    point = point.reshape(inputs.shape[:-1] + (-1,))\n    return (\n        # L2 term.\n        -jnp.sum((point - inputs) ** 2, axis=-1) / (2 * self._std ** 2) -\n        # Normalizing constant.\n        ((jnp.log(self._std) + jnp.log(jnp.sqrt(2 * jnp.pi)))\n         * jnp.prod(self._shape))\n    )\n\n  # At that point self._std is not learnable, hence\n  # we return a constant\n  def entropy(self, log_probs):\n    del log_probs  # would be helpful if self._std was learnable\n    return jnp.exp(self._std) + .5 * jnp.log(2.0 * jnp.pi * jnp.e)\n\n\n# TODO(pkozakowski): Implement GaussianMixture.\n\n\ndef create_distribution(space):\n  """"""Creates a Distribution for the given Gym space.""""""\n  if isinstance(space, gym.spaces.Discrete):\n    return Categorical(shape=(), n_categories=space.n)\n  elif isinstance(space, gym.spaces.MultiDiscrete):\n    assert space.nvec.size\n    assert min(space.nvec) == max(space.nvec), (\n        \'Every dimension must have the same number of categories, got \'\n        \'{}.\'.format(space.nvec)\n    )\n    return Categorical(shape=(len(space.nvec),), n_categories=space.nvec[0])\n  elif isinstance(space, gym.spaces.Box):\n    return Gaussian(shape=space.shape)\n  else:\n    raise TypeError(\'Space {} unavailable as a distribution support.\')\n\n\ndef LogLoss(distribution, **unused_kwargs):  # pylint: disable=invalid-name\n  """"""Builds a log loss layer for a Distribution.""""""\n  return tl.Serial(\n      distribution.LogProb(),\n      tl.Negate(),\n      tl.WeightedSum()\n  )\n'"
trax/rl/distributions_test.py,8,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for initializers.""""""\n\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\nimport gym\nimport numpy as np\n\nfrom trax.rl import distributions\n\n\nclass DistributionsTest(parameterized.TestCase):\n\n  @parameterized.named_parameters(\n      (\'discrete\', gym.spaces.Discrete(n=4)),\n      (\'multi_discrete\', gym.spaces.MultiDiscrete(nvec=[5, 5])),\n      (\'gaussian\', gym.spaces.Box(low=-np.inf, high=+np.inf, shape=(4, 5))),\n  )\n  def test_shapes(self, space):\n    batch_shape = (2, 3)\n    distribution = distributions.create_distribution(space)\n    inputs = np.random.random(batch_shape + (distribution.n_inputs,))\n    point = distribution.sample(inputs)\n    self.assertEqual(point.shape, batch_shape + space.shape)\n    # Check if the datatypes are compatible, i.e. either both floating or both\n    # integral.\n    self.assertEqual(\n        isinstance(point.dtype, float), isinstance(space.dtype, float)\n    )\n    log_prob = distribution.log_prob(inputs, point)\n    self.assertEqual(log_prob.shape, batch_shape)\n\n  @parameterized.named_parameters((\'1d\', 1), (\'2d\', 2))\n  def test_gaussian_probability_sums_to_one(self, n_dims):\n    std = 1.0\n    n_samples = 10000\n\n    distribution = distributions.Gaussian(shape=(n_dims,), std=std)\n    means = np.random.random((3, n_dims))\n    # Monte carlo integration over [mean - 3 * std, mean + 3 * std] across\n    # all dimensions.\n    means = np.broadcast_to(means, (n_samples,) + means.shape)\n    probs = (6 * std) ** n_dims * np.mean(\n        np.exp(distribution.log_prob(\n            means, np.random.uniform(means - 3 * std, means + 3 * std)\n        )),\n        axis=0,\n    )\n    # Should sum to one. High tolerance because of variance and cutting off the\n    # tails.\n    np.testing.assert_allclose(probs, np.ones_like(probs), atol=0.05)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/rl/normalization.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Normalization helpers.""""""\n\nimport gin\nimport numpy as np\n\nfrom trax import layers as tl\nfrom trax import math\n\n\ndef running_mean_init(shape, fill_value=0):\n  return (np.full(shape, fill_value), np.array(0))\n\n\ndef running_mean_update(x, state):\n  (mean, n) = state\n  mean = n.astype(np.float32) / (n + 1) * mean + x / (n + 1)\n  return (mean, n + 1)\n\n\ndef running_mean_get_mean(state):\n  (mean, _) = state\n  return mean\n\n\ndef running_mean_get_count(state):\n  (_, count) = state\n  return count\n\n\ndef running_mean_and_variance_init(shape):\n  mean_state = running_mean_init(shape, fill_value=0.0)\n  var_state = running_mean_init(shape, fill_value=1.0)\n  return (mean_state, var_state)\n\n\ndef running_mean_and_variance_update(x, state):\n  (mean_state, var_state) = state\n  old_mean = running_mean_get_mean(mean_state)\n  mean_state = running_mean_update(x, mean_state)\n  new_mean = running_mean_get_mean(mean_state)\n\n  var_state = running_mean_update((x - new_mean) * (x - old_mean), var_state)\n\n  return (mean_state, var_state)\n\n\ndef running_mean_and_variance_get_mean(state):\n  (mean_state, _) = state\n  return running_mean_get_mean(mean_state)\n\n\ndef running_mean_and_variance_get_count(state):\n  (mean_state, _) = state\n  return running_mean_get_count(mean_state)\n\n\ndef running_mean_and_variance_get_variance(state):\n  (_, var_state) = state\n  return running_mean_get_mean(var_state)\n\n\n@gin.configurable(blacklist=[\'mode\'])\nclass Normalize(tl.Layer):\n  """"""Numerically stable normalization layer.""""""\n\n  def __init__(self, sample_limit=float(\'+inf\'), epsilon=1e-5, mode=\'train\'):\n    super(Normalize, self).__init__()\n    self._sample_limit = sample_limit\n    self._epsilon = epsilon\n    self._mode = mode\n\n  def new_weights(self, input_signature):\n    self.state = running_mean_and_variance_init(input_signature.shape[2:])\n    return tl.EMPTY_WEIGHTS\n\n  def forward(self, inputs, weights):\n    del weights\n    state = self.state\n    observations = inputs\n    if self._mode == \'collect\':\n      # Accumulate statistics only in the collect mode, i.e. when collecting\n      # data using the agent.\n      for observation in observations[:, -1]:  # (batch_size, time, ...)\n        # Update statistics for each observation separately for simplicity.\n        # Currently during data collection the batch size is 1 anyway.\n        count = running_mean_and_variance_get_count(state)\n        state = math.cond(\n            count < self._sample_limit,\n            true_operand=(observation, state),\n            true_fun=lambda args: running_mean_and_variance_update(*args),\n            false_operand=None,\n            false_fun=lambda _: state,\n        )\n\n    mean = running_mean_and_variance_get_mean(state)\n    var = running_mean_and_variance_get_variance(state)\n    norm_observations = (observations - mean) / (var ** 0.5 + self._epsilon)\n    self.state = state\n    return norm_observations\n'"
trax/rl/normalization_test.py,12,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for trax.rl.normalization.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\n\nfrom trax import shapes\nfrom trax.rl import normalization\n\n\nclass NormalizationTest(absltest.TestCase):\n\n  def test_running_mean(self):\n    x = np.random.uniform(size=10)\n    state = normalization.running_mean_init(shape=())\n    for i in range(len(x)):\n      state = normalization.running_mean_update(x[i], state)\n      np.testing.assert_almost_equal(\n          normalization.running_mean_get_mean(state), np.mean(x[:i + 1])\n      )\n\n  def test_running_variance(self):\n    x = np.random.uniform(size=10)\n    state = normalization.running_mean_and_variance_init(shape=())\n    for i in range(len(x)):\n      state = normalization.running_mean_and_variance_update(x[i], state)\n      np.testing.assert_almost_equal(\n          normalization.running_mean_and_variance_get_variance(state),\n          np.var(x[:i + 1]),\n      )\n\n  def test_normalize_collect(self):\n    x = np.random.uniform(size=(2, 3, 4, 5))\n    normalize = normalization.Normalize(mode=\'collect\')\n    normalize.init(shapes.signature(x))\n    old_state = normalize.state\n    y = normalize(x)\n    with self.assertRaises(AssertionError):\n      np.testing.assert_equal(normalize.state, old_state)\n    with self.assertRaises(AssertionError):\n      np.testing.assert_almost_equal(x, y)\n\n  def test_normalize_train(self):\n    x = np.random.uniform(size=(2, 3, 4, 5))\n    normalize = normalization.Normalize(mode=\'train\', epsilon=0.0)\n    normalize.init(shapes.signature(x))\n    old_state = normalize.state\n    y = normalize(x)\n    np.testing.assert_equal(normalize.state, old_state)\n    np.testing.assert_almost_equal(x, y)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/rl/online_tune.py,8,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Utility functions for OnlineTuneEnv.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\n\ndef historical_metric_values(history, metric):\n  """"""Converts a metric stream from a trax History object into a numpy array.""""""\n  metric_sequence = history.get(*metric)\n  metric_values = np.array([\n      metric_value for (_, metric_value) in metric_sequence\n  ])\n  if np.any(np.isnan(metric_values)):\n    # Zero out all observations if any element is NaN. This way the agent\n    # doesn\'t get any rewards, so it learns to avoid those regions.\n    metric_values[:] = 0.0\n  return metric_values\n\n\ndef control_to_observation(control_values, control_config, observation_range):\n  """"""Flips, logarithms, clips and scales the control to observation_range.""""""\n  (_, _, (low, high), flip) = control_config\n  def transform(x):\n    return np.log(maybe_flip(x, flip))\n  (log_control_values, log_low, log_high) = map(\n      transform, (control_values, low, high)\n  )\n  if flip:\n    (log_low, log_high) = (log_high, log_low)\n  log_control_values = np.clip(log_control_values, log_low, log_high)\n  # Rescale the log control values to the observation range.\n  (obs_low, obs_high) = observation_range\n  return (\n      (log_control_values - log_low) / (log_high - log_low) *\n      (obs_high - obs_low) + obs_low\n  )\n\n\ndef control_metric(name):\n  """"""Returns the (mode, metric) pair in History for the given control.""""""\n  return (\'train\', \'training/{}\'.format(name))\n\n\ndef maybe_flip(value, flip):\n  """"""Flips a control (or not).\n\n  Meant to translate controls that naturally take values close to 1\n  (e.g. momentum) to a space where multiplication makes sense (i.e. close to 0).\n\n  Args:\n    value: float or numpy array, value of the control.\n    flip: bool, whether to flip or not.\n\n  Returns:\n    Either value or 1 - value based on flip.\n  """"""\n  if flip:\n    value = 1 - value\n  return value\n\n\ndef history_to_observations(\n    history, metrics, observation_range, control_configs=None):\n  """"""Converts a trax History object into a sequence of observations.""""""\n  (obs_low, obs_high) = observation_range\n  observation_dimensions = [\n      np.clip(historical_metric_values(history, metric), obs_low, obs_high)\n      for metric in metrics\n  ]\n  if control_configs is not None:\n    for control_config in control_configs:\n      (control_name, _, _, _) = control_config\n      observation_dimensions.append(control_to_observation(\n          historical_metric_values(history, control_metric(control_name)),\n          control_config,\n          observation_range,\n      ))\n  return np.stack(observation_dimensions, axis=1)\n\n\ndef update_control(control_config, action, history, action_multipliers):\n  """"""Calculates a new value of a control based on an action.""""""\n  (name, _, (low, high), flip) = control_config\n  metric = control_metric(name)\n  control_values = historical_metric_values(history, metric)\n  assert control_values.shape[0] > 0, (\n      \'No last control {} found in history.\'.format(name))\n  current_control = control_values[-1]\n  (current_control, low, high) = maybe_flip(\n      np.array([current_control, low, high]), flip\n  )\n  if flip:\n    (low, high) = (high, low)\n  new_control = np.clip(\n      current_control * action_multipliers[action], low, high\n  )\n  return maybe_flip(new_control, flip)\n'"
trax/rl/online_tune_test.py,18,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.online_tune.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom tensorflow import test\nfrom trax import history as trax_history\nfrom trax.rl import online_tune\n\n\nclass OnlineTuneTest(test.TestCase):\n\n  def _append_metrics(self, h, metric, values):\n    for (i, value) in enumerate(values):\n      h.append(*metric, step=i, value=value)\n\n  def test_retrieves_historical_metric_values(self):\n    history = trax_history.History()\n    self._append_metrics(history, (\'train\', \'accuracy\'), [0.1, 0.73])\n    metric_values = online_tune.historical_metric_values(\n        history, metric=(\'train\', \'accuracy\')\n    )\n    np.testing.assert_array_equal(metric_values, [0.1, 0.73])\n\n  def test_converts_control_to_log_scale_without_flipping(self):\n    config = (\'weight_decay\', None, (1e-5, 0.1), False)\n    controls = np.array([0.01, 0.02, 0.04])\n    obs_range = (-1, 1)\n    obs = online_tune.control_to_observation(controls, config, obs_range)\n    np.testing.assert_almost_equal(obs[1] - obs[0], obs[2] - obs[1])\n\n  def test_converts_control_to_log_scale_with_flipping(self):\n    config = (\'momentum\', None, (0.5, 0.99), True)\n    controls = np.array([0.98, 0.96, 0.92])\n    obs_range = (-1, 1)\n    obs = online_tune.control_to_observation(controls, config, obs_range)\n    np.testing.assert_almost_equal(obs[1] - obs[0], obs[2] - obs[1])\n\n  def test_clips_control_without_flipping(self):\n    config = (\'weight_decay\', None, (1e-5, 0.1), False)\n    controls = np.array([0.0, 0.2])\n    obs_range = (-1, 1)\n    obs = online_tune.control_to_observation(controls, config, obs_range)\n    np.testing.assert_equal(obs, [-1, 1])\n\n  def test_clips_control_with_flipping(self):\n    config = (\'momentum\', None, (0.5, 0.99), True)\n    controls = np.array([0.4, 1.0])\n    obs_range = (-1, 1)\n    obs = online_tune.control_to_observation(controls, config, obs_range)\n    np.testing.assert_equal(obs, [1, -1])\n\n  def test_rescales_control(self):\n    config = (\'weight_decay\', None, (1e-5, 0.1), False)\n    controls = np.array([4e-4, 3e-3, 2e-2])\n    (obs_low, obs_high) = (103, 104)\n    obs = online_tune.control_to_observation(\n        controls, config, observation_range=(obs_low, obs_high),\n    )\n    np.testing.assert_array_less(obs, [obs_high] * 3)\n    np.testing.assert_array_less([obs_low] * 3, obs)\n\n  def test_converts_history_to_observations_without_controls(self):\n    history = trax_history.History()\n    self._append_metrics(history, (\'train\', \'loss\'), [1.0, 0.07])\n    self._append_metrics(history, (\'eval\', \'accuracy\'), [0.12, 0.68])\n    observations = online_tune.history_to_observations(\n        history,\n        metrics=((\'eval\', \'accuracy\'), (\'train\', \'loss\')),\n        observation_range=(-1, 1),\n        control_configs=None,\n    )\n    np.testing.assert_array_almost_equal(\n        observations, [[0.12, 1.0], [0.68, 0.07]]\n    )\n\n  def test_converts_history_to_observations_with_controls(self):\n    history = trax_history.History()\n    self._append_metrics(\n        history, (\'train\', \'training/learning_rate\'), [1e-3, 1e-4])\n    observations = online_tune.history_to_observations(\n        history,\n        metrics=(),\n        observation_range=(0, 5),\n        control_configs=(\n            (\'learning_rate\', None, (1e-9, 10.0), False),\n        ),\n    )\n    self.assertEqual(observations.shape, (2, 1))\n    ((log_lr_1,), (log_lr_2,)) = observations\n    self.assertGreater(log_lr_1, log_lr_2)\n\n  def test_clips_observations(self):\n    history = trax_history.History()\n    self._append_metrics(history, (\'eval\', \'loss\'), [-10, 10])\n    observations = online_tune.history_to_observations(\n        history,\n        metrics=((\'eval\', \'loss\'),),\n        observation_range=(-2, 2),\n        control_configs=None,\n    )\n    np.testing.assert_array_equal(observations, [[-2], [2]])\n\n  def test_updates_control_without_flipping(self):\n    config = (\'learning_rate\', None, (1e-9, 10.0), False)\n    history = trax_history.History()\n    self._append_metrics(\n        history, online_tune.control_metric(\'learning_rate\'), [1e-2, 1e-3])\n    new_control = online_tune.update_control(\n        control_config=config,\n        action=2,\n        history=history,\n        action_multipliers=(0.5, 1.0, 2.0),\n    )\n    np.testing.assert_almost_equal(new_control, 2e-3)\n\n  def test_updates_control_with_flipping(self):\n    config = (\'momentum\', None, (0.5, 0.99), True)\n    history = trax_history.History()\n    self._append_metrics(\n        history, online_tune.control_metric(\'momentum\'), [0.96, 0.98])\n    new_control = online_tune.update_control(\n        control_config=config,\n        action=0,\n        history=history,\n        action_multipliers=(0.5, 1.0, 2.0),\n    )\n    np.testing.assert_almost_equal(new_control, 0.99)\n\n  def test_clips_updated_control_without_flipping(self):\n    config = (\'learning_rate\', None, (1e-9, 10.0), False)\n    history = trax_history.History()\n    self._append_metrics(\n        history, online_tune.control_metric(\'learning_rate\'), [7.0])\n    new_control = online_tune.update_control(\n        control_config=config,\n        action=2,\n        history=history,\n        action_multipliers=(0.5, 1.0, 2.0),\n    )\n    np.testing.assert_almost_equal(new_control, 10.0)\n\n  def test_clips_updated_control_with_flipping(self):\n    config = (\'momentum\', None, (0.5, 0.99), True)\n    history = trax_history.History()\n    self._append_metrics(\n        history, online_tune.control_metric(\'momentum\'), [0.985])\n    new_control = online_tune.update_control(\n        control_config=config,\n        action=0,\n        history=history,\n        action_multipliers=(0.5, 1.0, 2.0),\n    )\n    np.testing.assert_almost_equal(new_control, 0.99)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/policy_based_trainer.py,3,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Base class for policy based algorithms.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport functools\nimport os\n\nfrom absl import logging\nimport jax\nfrom jax import numpy as jnp\nfrom jax import random as jax_random\nimport numpy as np\nfrom tensor2tensor.envs import env_problem_utils\nfrom tensor2tensor.envs import trajectory\nfrom trax import jaxboard\nfrom trax.rl import base_trainer\nfrom trax.rl import policy_based_utils\nfrom trax.rl import serialization_utils\nfrom trax.shapes import ShapeDtype\nfrom trax.supervised import trainer_lib\n\nDEBUG_LOGGING = False\nGAMMA = 0.99\nLAMBDA = 0.95\nEPSILON = 0.1\nEPOCHS = 50  # 100\nN_OPTIMIZER_STEPS = 100\nPRINT_EVERY_OPTIMIZER_STEP = 20\nBATCH_TRAJECTORIES = 32\n\n\nclass PolicyBasedTrainer(base_trainer.BaseTrainer):\n  """"""Base trainer for policy based algorithms.""""""\n\n  def __init__(\n      self,\n      train_env,\n      eval_env,\n      output_dir=None,\n      random_seed=None,\n      controller=None,\n      # Policy and Value model arguments.\n      policy_and_value_model=None,\n      policy_and_value_optimizer=None,\n      policy_and_value_two_towers=False,\n      policy_and_value_vocab_size=None,\n      init_policy_from_world_model_output_dir=None,\n      # Trajectory collection arguments.\n      boundary=20,\n      max_timestep=100,\n      max_timestep_eval=20000,\n      len_history_for_policy=4,\n      # Save / Restore arguments.\n      should_save_checkpoints=True,\n      should_write_summaries=True,\n      eval_every_n=1000,\n      save_every_n=1000,\n      done_frac_for_policy_save=0.5,\n      # Eval arguments.\n      n_evals=1,\n      eval_temperatures=(1.0, 0.5),\n      separate_eval=True,\n      # Optimization arguments.\n      n_optimizer_steps=N_OPTIMIZER_STEPS,\n      optimizer_batch_size=64,\n      **kwargs):\n    """"""Creates the PolicyBasedTrainer.\n\n    Args:\n      train_env: gym.Env to use for training.\n      eval_env: gym.Env to use for evaluation.\n      output_dir: Output dir.\n      random_seed: Random seed.\n      controller: Function history -> (step -> {\'name\': value}) controlling\n        nontrainable parameters.\n      policy_and_value_model: Function defining the policy and value network,\n        without the policy and value heads.\n      policy_and_value_optimizer: Function defining the optimizer.\n      policy_and_value_two_towers: Whether to use two separate models as the\n        policy and value networks. If False, share their parameters.\n      policy_and_value_vocab_size: Vocabulary size of a policy and value network\n        operating on serialized representation. If None, use raw continuous\n        representation.\n      init_policy_from_world_model_output_dir: Model output dir for initializing\n        the policy. If None, initialize randomly.\n      boundary: We pad trajectories at integer multiples of this number.\n      max_timestep: If set to an integer, maximum number of time-steps in a\n        trajectory. Used in the collect procedure.\n      max_timestep_eval: If set to an integer, maximum number of time-steps in\n        an evaluation trajectory. Used in the collect procedure.\n      len_history_for_policy: How much of history to give to the policy.\n      should_save_checkpoints: Whether to save policy checkpoints.\n      should_write_summaries: Whether to save summaries.\n      eval_every_n: How frequently to eval the policy.\n      save_every_n: How frequently to save the policy.\n      done_frac_for_policy_save: Fraction of the trajectories that should be\n        done to checkpoint the policy.\n      n_evals: Number of times to evaluate.\n      eval_temperatures: Sequence of temperatures to try for categorical\n        sampling during evaluation.\n      separate_eval: Whether to run separate evaluation using a set of\n        temperatures. If False, the training reward is reported as evaluation\n        reward with temperature 1.0.\n      n_optimizer_steps: Number of optimizer steps.\n      optimizer_batch_size: Batch size of an optimizer step.\n      **kwargs: Additional keyword arguments passed to the base class.\n    """"""\n    super(PolicyBasedTrainer, self).__init__(train_env, eval_env, output_dir,\n                                             **kwargs)\n\n    self._rng = trainer_lib.init_random_number_generators(random_seed)\n    self._controller = controller\n    self._history = None\n    self._epoch = 0\n\n    # Trajectory collection arguments.\n    self._boundary = boundary\n    self._max_timestep = max_timestep\n    self._max_timestep_eval = max_timestep_eval\n    self._len_history_for_policy = len_history_for_policy\n\n    # Save / Restore arguments.\n    self._should_save_checkpoints = should_save_checkpoints\n    self._should_write_summaries = should_write_summaries\n    self._train_sw, self._eval_sw, self._timing_sw = None, None, None\n    self._eval_every_n = eval_every_n\n    self._save_every_n = save_every_n\n    self._done_frac_for_policy_save = done_frac_for_policy_save\n    self._n_trajectories_done_since_last_save = 0\n    self._last_saved_at_epoch = self._epoch\n\n    # Eval arguments.\n    self._n_evals = n_evals\n    self._eval_temperatures = eval_temperatures\n    self._separate_eval = separate_eval\n\n    # Optimization arguments.\n    self._n_optimizer_steps = n_optimizer_steps\n    self._optimizer_batch_size = optimizer_batch_size\n    self._total_opt_step = 0\n\n    # Policy and Value model arguments.\n    self._policy_and_value_vocab_size = policy_and_value_vocab_size\n\n    self.init_policy_from_world_model_output_dir = (\n        init_policy_from_world_model_output_dir\n    )\n\n    (self._n_controls, self._n_actions) = (\n        serialization_utils.analyze_action_space(train_env.action_space)\n    )\n\n    self._policy_and_value_net_fn = functools.partial(\n        policy_based_utils.policy_and_value_net,\n        bottom_layers_fn=policy_and_value_model,\n        observation_space=train_env.observation_space,\n        action_space=train_env.action_space,\n        vocab_size=self._policy_and_value_vocab_size,\n        two_towers=policy_and_value_two_towers,\n    )\n    (policy_and_value_net, self._substitute_fn) = (\n        self._policy_and_value_net_fn()\n    )\n    self._policy_and_value_net_apply = jax.jit(policy_and_value_net)\n    self._policy_and_value_optimizer = policy_and_value_optimizer()\n    self._model_state = None\n    self._policy_and_value_opt_state = None\n\n  def _get_rng(self):\n    self._rng, key = jax_random.split(self._rng)\n    return key\n\n  def reset(self, output_dir=None):\n    super(PolicyBasedTrainer, self).reset(output_dir)\n\n    # Create summary writers and history.\n    if self._should_write_summaries:\n      self._train_sw = jaxboard.SummaryWriter(\n          os.path.join(self._output_dir, \'train\'))\n      self._timing_sw = jaxboard.SummaryWriter(\n          os.path.join(self._output_dir, \'timing\'))\n      self._eval_sw = jaxboard.SummaryWriter(\n          os.path.join(self._output_dir, \'eval\'))\n\n    # Try to initialize from a saved checkpoint, or initialize from scratch if\n    # there is no saved checkpoint.\n    self.update_optimization_state(output_dir)\n\n    # If uninitialized, i.e. _policy_and_value_opt_state is None, then\n    # initialize.\n    if self._policy_and_value_opt_state is None:\n      (policy_and_value_net, _) = self._policy_and_value_net_fn()\n      obs_space = self.train_env.observation_space\n      act_space = self.train_env.action_space\n      input_signature = (\n          ShapeDtype(\n              (1, self._max_timestep + 1) + obs_space.shape, obs_space.dtype\n          ),\n          ShapeDtype(\n              (1, self._max_timestep) + act_space.shape, act_space.dtype\n          ),\n      )\n      weights, self._model_state = policy_and_value_net.init(\n          input_signature, rng=self._get_rng()\n      )\n\n      # Initialize the optimizer.\n      self._init_state_from_weights(weights)\n\n    # If we need to initialize from the world model, do that here.\n    if self.init_policy_from_world_model_output_dir is not None:\n      weights = policy_based_utils.init_policy_from_world_model_checkpoint(\n          self._policy_and_value_net_weights,\n          self.init_policy_from_world_model_output_dir,\n          self._substitute_fn,\n      )\n      # Initialize the optimizer.\n      self._init_state_from_weights(weights)\n\n    self._n_trajectories_done_since_last_save = 0\n    self._last_saved_at_epoch = self.epoch\n\n    if self._async_mode:\n      logging.info(\'Saving model on startup to have a model policy file.\')\n      self.save()\n\n  def _init_state_from_weights(self, weights):\n    # Initialize the optimizer.\n    (init_slots, init_opt_params) = (\n        self._policy_and_value_optimizer.tree_init(weights)\n    )\n    self._policy_and_value_opt_state = (weights, init_slots, init_opt_params)\n\n  def _policy_and_value_opt_update(self, step, grads, opt_state):\n    (params, slots, opt_params) = opt_state\n    (params, slots, _) = self._policy_and_value_optimizer.tree_update(\n        step, grads, params, slots, opt_params)\n    return (params, slots, opt_params)\n\n  # Maybe restore the optimization state. If there is nothing to restore, then\n  # epoch = 0 and policy_and_value_opt_state is returned as is.\n  def update_optimization_state(self, output_dir=None):\n    if output_dir is None:\n      output_dir = self._output_dir\n    (self._policy_and_value_opt_state, self._model_state, self._epoch,\n     self._total_opt_step, self._history) = (\n         policy_based_utils.maybe_restore_opt_state(\n             output_dir, self._policy_and_value_opt_state, self._model_state\n         )\n     )\n\n    if self.epoch > 0:\n      logging.info(\'Restored parameters from epoch [%d]\', self.epoch)\n\n  @property\n  def epoch(self):\n    return self._epoch\n\n  @property\n  def history(self):\n    return self._history\n\n  def collect_trajectories_async(self,\n                                 env,\n                                 train=True,\n                                 n_trajectories=1,\n                                 n_observations=None,\n                                 temperature=1.0):\n    """"""Collects trajectories in an async manner.""""""\n\n    assert self._async_mode\n\n    # TODO(afrozm): Make this work, should be easy.\n    # NOTE: We still collect whole trajectories, however the async trajectory\n    # collectors now will poll not on the amount of trajectories collected but\n    # on the amount of observations in the completed trajectories and bail out.\n    assert n_observations is None\n\n    # trajectories/train and trajectories/eval are the two subdirectories.\n    trajectory_dir = os.path.join(self._output_dir, \'trajectories\',\n                                  \'train\' if train else \'eval\')\n    epoch = self.epoch\n\n    logging.info(\n        \'Loading [%s] trajectories from dir [%s] for epoch [%s] and temperature\'\n        \' [%s]\', n_trajectories, trajectory_dir, epoch, temperature)\n\n    bt = trajectory.BatchTrajectory.load_from_directory(\n        trajectory_dir,\n        epoch=epoch,\n        temperature=temperature,\n        wait_forever=True,\n        n_trajectories=n_trajectories)\n\n    if bt is None:\n      logging.error(\n          \'Couldn\\\'t load [%s] trajectories from dir [%s] for epoch [%s] and \'\n          \'temperature [%s]\', n_trajectories, trajectory_dir, epoch,\n          temperature)\n      assert bt\n\n    # Doing this is important, since we want to modify `env` so that it looks\n    # like `env` was actually played and the trajectories came from it.\n    env.trajectories = bt\n\n    trajs = env_problem_utils.get_completed_trajectories_from_env(\n        env, n_trajectories)\n    n_done = len(trajs)\n    timing_info = {}\n    return trajs, n_done, timing_info, self._model_state\n\n  def collect_trajectories(self,\n                           train=True,\n                           n_trajectories=1,\n                           n_observations=None,\n                           temperature=1.0,\n                           abort_fn=None,\n                           raw_trajectory=False):\n    key = self._get_rng()\n\n    env = self.train_env\n    max_timestep = self._max_timestep\n    should_reset = self._should_reset_train_env\n    if not train:  # eval\n      env = self.eval_env\n      max_timestep = self._max_timestep_eval\n      should_reset = True\n\n    # If async, read the required trajectories for the epoch.\n    if self._async_mode:\n      trajs, n_done, timing_info, self._model_state = self.collect_trajectories_async(\n          env,\n          train=train,\n          n_trajectories=n_trajectories,\n          n_observations=n_observations,\n          temperature=temperature)\n    else:\n      trajs, n_done, timing_info, self._model_state = (\n          policy_based_utils.collect_trajectories(\n              env,\n              policy_fn=self._policy_fun,\n              n_trajectories=n_trajectories,\n              n_observations=n_observations,\n              max_timestep=max_timestep,\n              state=self._model_state,\n              rng=key,\n              len_history_for_policy=self._len_history_for_policy,\n              boundary=self._boundary,\n              reset=should_reset,\n              temperature=temperature,\n              abort_fn=abort_fn,\n              raw_trajectory=raw_trajectory,\n          )\n      )\n\n    if train:\n      self._n_trajectories_done_since_last_save += n_done\n\n    return trajs, n_done, timing_info, self._model_state\n\n  def train_epoch(self, evaluate=True):\n    raise NotImplementedError\n\n  def evaluate(self):\n    """"""Evaluate the agent.""""""\n    if not self._separate_eval:\n      return\n\n    logging.vlog(1, \'PolicyBasedTrainer epoch [% 6d]: evaluating policy.\',\n                 self.epoch)\n\n    processed_reward_sums = collections.defaultdict(list)\n    raw_reward_sums = collections.defaultdict(list)\n    for _ in range(self._n_evals):\n      for temperature in self._eval_temperatures:\n        trajs, _, _, self._model_state = self.collect_trajectories(\n            train=False, temperature=temperature)\n\n        processed_reward_sums[temperature].extend(\n            sum(traj[2]) for traj in trajs)\n        raw_reward_sums[temperature].extend(sum(traj[3]) for traj in trajs)\n\n    # Return the mean and standard deviation for each temperature.\n    def compute_stats(reward_dict):\n      # pylint: disable=g-complex-comprehension\n      return {\n          temperature: {\n              \'mean\': np.mean(rewards),\n              \'std\': np.std(rewards)\n          } for (temperature, rewards) in reward_dict.items()\n      }\n      # pylint: enable=g-complex-comprehension\n\n    reward_stats = {\n        \'processed\': compute_stats(processed_reward_sums),\n        \'raw\': compute_stats(raw_reward_sums),\n    }\n\n    policy_based_utils.write_eval_reward_summaries(\n        reward_stats, self._log, epoch=self.epoch\n    )\n\n  def maybe_save(self):\n    # Save parameters every time we see the end of at least a fraction of batch\n    # number of trajectories that are done (not completed -- completed includes\n    # truncated and done).\n    # Also don\'t save too frequently, enforce a minimum gap.\n    min_done_trajs_to_save = (\n        self._done_frac_for_policy_save *\n        getattr(self.train_env, \'batch_size\', 10))\n    # TODO(afrozm): Refactor to trax.save_trainer_state.\n    if (self._n_trajectories_done_since_last_save >= min_done_trajs_to_save and\n        self.epoch % self._save_every_n == 0) or self._async_mode:\n      self.save()\n\n  def save(self):\n    """"""Save the agent parameters.""""""\n    if not self._should_save_checkpoints:\n      return\n\n    logging.vlog(1, \'PolicyBasedTrainer epoch [% 6d]: saving model.\',\n                 self.epoch)\n    policy_based_utils.save_opt_state(\n        self._output_dir,\n        self._policy_and_value_opt_state,\n        self._model_state,\n        self.epoch,\n        self._total_opt_step,\n        self._history,\n    )\n    # Reset this number.\n    self._n_trajectories_done_since_last_save = 0\n    self._last_saved_at_epoch = self.epoch\n\n  def flush_summaries(self):\n    if self._should_write_summaries:\n      self._train_sw.flush()\n      self._timing_sw.flush()\n      self._eval_sw.flush()\n\n  def _log(self, mode, metric, value):\n    if self._should_write_summaries:\n      summary_writer = {\n          \'train\': self._train_sw,\n          \'eval\': self._eval_sw,\n      }[mode]\n      summary_writer.scalar(metric, value, step=self.epoch)\n    self._history.append(mode, metric, self.epoch, value)\n\n  def _policy_and_value_get_params(self, opt_state):\n    # (params, slots, opt_params)\n    (params, _, _) = opt_state\n    return params\n\n  @property\n  def _policy_and_value_net_weights(self):\n    return self._policy_and_value_get_params(self._policy_and_value_opt_state)\n\n  # Prepares the trajectories for policy training.\n  def _preprocess_trajectories(self, trajectories):\n    (_, reward_mask, observations, actions, rewards, infos) = (\n        policy_based_utils.pad_trajectories(\n            trajectories, boundary=self._max_timestep)\n    )\n    if actions.ndim == 2:\n      # Add the control dimension.\n      actions = actions[:, :, None]\n    (low, high) = self.train_env.reward_range\n    outside = jnp.logical_or(rewards < low, rewards > high)\n    rewards = jax.ops.index_update(rewards, jax.ops.index[outside], 0)\n    assert self.train_env.observation_space.shape == observations.shape[2:]\n    return (observations, actions, rewards, reward_mask, infos)\n\n  def _policy_fun(self, observations, lengths, state, rng):\n    return policy_based_utils.run_policy(\n        self._policy_and_value_net_apply,\n        observations,\n        lengths,\n        self._policy_and_value_net_weights,\n        state,\n        rng,\n        self.train_env.action_space,\n    )\n\n  def _policy_fun_all_timesteps(self, observations, lengths, state, rng):\n    return policy_based_utils.run_policy_all_timesteps(\n        self._policy_and_value_net_apply,\n        observations,\n        self._policy_and_value_net_weights,\n        state,\n        rng,\n        self.train_env.action_space,\n    )\n\n  @staticmethod\n  def _log_shape(array_name, array):\n    logging.vlog(1, f\'Shape of {array_name} is {array.shape}.\')\n\n  @staticmethod\n  def _check_shapes(array_name,\n                    expected_shape_string,\n                    array,\n                    expected_shape,\n                    array_prefix=None):\n    actual_shape = array.shape[:array_prefix]\n    prefix = \'\' if not array_prefix else f\'[:{array_prefix}]\'\n    logging.vlog(1, f\'Shape of {array_name}{prefix} is {actual_shape}.\')\n    if array_prefix:\n      logging.vlog(1, f\'Shape of {array_name} is {array.shape}.\')\n    if actual_shape != expected_shape:\n      raise ValueError(\n          f\'Shape of {array_name}{prefix} is expected to be \'\n          f\'{expected_shape_string} which is {expected_shape}, but is \'\n          f\'{actual_shape} instead.\')\n'"
trax/rl/policy_based_utils.py,18,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Utilities for policy-based trainers.""""""\n\nimport collections\nimport functools\nimport os\nimport re\nimport time\n\nfrom absl import logging\nimport gym\nfrom jax import lax\nimport numpy as np\nfrom tensor2tensor.envs import env_problem\nfrom tensor2tensor.envs import env_problem_utils\nimport tensorflow as tf\n\nfrom trax import history as trax_history\nfrom trax import layers as tl\nfrom trax import utils\nfrom trax.math import numpy as jnp\nfrom trax.math import random as trax_random\nfrom trax.rl import serialization_utils\n\n\ndef policy_and_value_net(\n    bottom_layers_fn, observation_space, action_space, vocab_size, two_towers\n):\n  """"""A policy and value net function.\n\n  Runs bottom_layers_fn either as a single network or as two separate towers.\n  Attaches action and value heads and wraps the network in a policy wrapper.\n\n  Args:\n    bottom_layers_fn: Trax model to use as a policy network.\n    observation_space (gym.Space): Observation space.\n    action_space (gym.Space): Action space.\n    vocab_size (int or None): Vocabulary size to use with a SerializedPolicy\n      wrapper. If None, RawPolicy will be used.\n    two_towers (bool): Whether to run bottom_layers_fn as two separate towers\n      for action and value prediction.\n\n  Returns:\n    Pair (network, substitute_fn), where network is the final network and\n      substitute_fn is a function (wrapped_tree, inner_tree) -> wrapped_tree\n      for substituting weights or state of the constructed model based on the\n      weights or state of a model returned from bottom_layers_fn. substitute_fn\n      is used for initializing the policy from parameters of a world model.\n  """"""\n  kwargs = {}\n  if vocab_size is not None:\n    kwargs[\'vocab_size\'] = vocab_size\n\n  def wrapped_policy_fn():\n    return serialization_utils.wrap_policy(\n        bottom_layers_fn(**kwargs),\n        observation_space,\n        action_space,\n        vocab_size,\n    )\n\n  # Now, with the current logits, one head computes action probabilities and the\n  # other computes the value function.\n  # NOTE: The LogSoftmax instead of the Softmax because of numerical stability.\n  if two_towers:\n    # Two towers: run two two-head networks in parallel and drop one head from\n    # each.\n    net = tl.Serial([             # (obs, act)\n        tl.Select([0, 1, 0, 1]),  # (obs, act, obs, act)\n        tl.Parallel(\n            wrapped_policy_fn(),\n            wrapped_policy_fn(),\n        ),                        # (act_logits_1, vals_1, act_logits_2, vals_2)\n        tl.Select([0, 3]),        # (act_logits_1, vals_2)\n    ])\n    def substitute_fn(wrapped_policy, inner_policy):\n      return (\n          wrapped_policy[:1] + [tuple(\n              # Substitute in both towers.\n              serialization_utils.substitute_inner_policy(  # pylint: disable=g-complex-comprehension\n                  tower, inner_policy, vocab_size\n              )\n              for tower in wrapped_policy[1]\n          )] +\n          [wrapped_policy[2:]]\n      )\n  else:\n    # One tower: run one two-headed network.\n    net = wrapped_policy_fn()\n    substitute_fn = functools.partial(\n        serialization_utils.substitute_inner_policy,\n        vocab_size=vocab_size,\n    )\n  return (net, substitute_fn)\n\n\n# Should this be collect \'n\' trajectories, or\n# Run the env for \'n\' steps and take completed trajectories, or\n# Any other option?\ndef collect_trajectories(env,\n                         policy_fn,\n                         n_trajectories=1,\n                         n_observations=None,\n                         max_timestep=None,\n                         reset=True,\n                         len_history_for_policy=32,\n                         boundary=32,\n                         state=None,\n                         temperature=1.0,\n                         rng=None,\n                         abort_fn=None,\n                         raw_trajectory=False,):\n  """"""Collect trajectories with the given policy net and behaviour.\n\n  Args:\n    env: A gym env interface, for now this is not-batched.\n    policy_fn: Callable\n      (observations(B,T+1), actions(B, T+1, C)) -> log-probabs(B, T+1, C, A).\n    n_trajectories: int, number of trajectories.\n    n_observations: int, number of non-terminal observations. NOTE: Exactly one\n      of `n_trajectories` and `n_observations` should be None.\n    max_timestep: int or None, the index of the maximum time-step at which we\n      return the trajectory, None for ending a trajectory only when env returns\n      done.\n    reset: bool, true if we want to reset the envs. The envs are also reset if\n      max_max_timestep is None or < 0\n    len_history_for_policy: int or None, the maximum history to keep for\n      applying the policy on. If None, use the full history.\n    boundary: int, pad the sequences to the multiples of this number.\n    state: state for `policy_fn`.\n    temperature: (float) temperature to sample action from policy_fn.\n    rng: jax rng, splittable.\n    abort_fn: callable, If not None, then at every env step call and abort the\n      trajectory collection if it returns True, if so reset the env and return\n      None.\n    raw_trajectory: bool, if True a list of trajectory.Trajectory objects is\n      returned, otherwise a list of numpy representations of\n      `trajectory.Trajectory` is returned.\n\n  Returns:\n    A tuple (trajectory, number of trajectories that are done)\n    trajectory: list of (observation, action, reward) tuples, where each element\n    `i` is a tuple of numpy arrays with shapes as follows:\n    observation[i] = (B, T_i + 1)\n    action[i] = (B, T_i)\n    reward[i] = (B, T_i)\n  """"""\n\n  assert isinstance(env, env_problem.EnvProblem)\n\n  # We need to reset all environments, if we\'re coming here the first time.\n  if reset or max_timestep is None or max_timestep <= 0:\n    env.reset()\n  else:\n    # Clear completed trajectories held internally.\n    env.trajectories.clear_completed_trajectories()\n\n  num_done_trajectories = 0\n\n  # The stopping criterion, returns True if we should stop.\n  def should_stop():\n    if n_trajectories is not None:\n      assert n_observations is None\n      return env.trajectories.num_completed_trajectories >= n_trajectories\n    assert n_observations is not None\n    # The number of non-terminal observations is what we want.\n    return (env.trajectories.num_completed_time_steps -\n            env.trajectories.num_completed_trajectories) >= n_observations\n\n  policy_application_total_time = 0\n  env_actions_total_time = 0\n  bare_env_run_time = 0\n  while not should_stop():\n    # Check if we should abort and return nothing.\n    if abort_fn and abort_fn():\n      # We should also reset the environment, since it will have some\n      # trajectories (complete and incomplete) that we want to discard.\n      env.reset()\n      return None, 0, {}, state\n\n    # Get all the observations for all the active trajectories.\n    # Shape is (B, T+1) + OBS\n    # Bucket on whatever length is needed.\n    padded_observations, lengths = env.trajectories.observations_np(\n        boundary=boundary,\n        len_history_for_policy=len_history_for_policy)\n\n    B = padded_observations.shape[0]  # pylint: disable=invalid-name\n\n    assert B == env.batch_size\n    assert (B,) == lengths.shape\n\n    t1 = time.time()\n    log_probs, value_preds, state, rng = policy_fn(\n        padded_observations, lengths, state=state, rng=rng)\n    policy_application_total_time += (time.time() - t1)\n\n    assert B == log_probs.shape[0]\n\n    actions = tl.gumbel_sample(log_probs, temperature)\n    if (isinstance(env.action_space, gym.spaces.Discrete) and\n        (actions.shape[1] == 1)):\n      actions = np.squeeze(actions, axis=1)\n\n    # Step through the env.\n    t1 = time.time()\n    _, _, dones, env_infos = env.step(\n        actions,\n        infos={\n            \'log_prob_actions\': log_probs.copy(),\n            \'value_predictions\': value_preds.copy(),\n        })\n    env_actions_total_time += (time.time() - t1)\n    bare_env_run_time += sum(\n        info[\'__bare_env_run_time__\'] for info in env_infos)\n\n    # Count the number of done trajectories, the others could just have been\n    # truncated.\n    num_done_trajectories += np.sum(dones)\n\n    # Get the indices where we are done ...\n    done_idxs = env_problem_utils.done_indices(dones)\n\n    # ... and reset those.\n    t1 = time.time()\n    if done_idxs.size:\n      env.reset(indices=done_idxs)\n    env_actions_total_time += (time.time() - t1)\n\n    if max_timestep is None or max_timestep < 1:\n      continue\n\n    # Are there any trajectories that have exceeded the time-limit we want.\n    lengths = env.trajectories.trajectory_lengths\n    exceeded_time_limit_idxs = env_problem_utils.done_indices(\n        lengths > max_timestep\n    )\n\n    # If so, reset these as well.\n    t1 = time.time()\n    if exceeded_time_limit_idxs.size:\n      # This just cuts the trajectory, doesn\'t reset the env, so it continues\n      # from where it left off.\n      env.truncate(indices=exceeded_time_limit_idxs, num_to_keep=1)\n    env_actions_total_time += (time.time() - t1)\n\n  # We have the trajectories we need, return a list of triples:\n  # (observations, actions, rewards)\n  completed_trajectories = (\n      env_problem_utils.get_completed_trajectories_from_env(\n          env, env.trajectories.num_completed_trajectories,\n          raw_trajectory=raw_trajectory))\n\n  timing_info = {\n      \'trajectory_collection/policy_application\': policy_application_total_time,\n      \'trajectory_collection/env_actions\': env_actions_total_time,\n      \'trajectory_collection/env_actions/bare_env\': bare_env_run_time,\n  }\n  timing_info = {k: round(1000 * v, 2) for k, v in timing_info.items()}\n\n  return completed_trajectories, num_done_trajectories, timing_info, state\n\n\n# This function can probably be simplified, ask how?\n# Can we do something much simpler than lax.pad, maybe jnp.pad?\n# Others?\n\n\ndef get_padding_value(dtype):\n  """"""Returns the padding value given a dtype.""""""\n  padding_value = None\n  if dtype == jnp.uint8:\n    padding_value = jnp.uint8(0)\n  elif dtype == jnp.uint16:\n    padding_value = jnp.uint16(0)\n  elif dtype == jnp.float32 or dtype == jnp.float64:\n    padding_value = 0.0\n  else:\n    padding_value = 0\n  assert padding_value is not None\n  return padding_value\n\n\n# TODO(afrozm): Use jnp.pad instead and make jittable?\ndef pad_trajectories(trajectories, boundary=20):\n  """"""Pad trajectories to a bucket length that is a multiple of boundary.\n\n  Args:\n    trajectories: list[(observation, actions, rewards)], where each observation\n      is shaped (t+1,) + OBS and actions & rewards are shaped (t,), with the\n      length of the list being B (batch size).\n    boundary: int, bucket length, the actions and rewards are padded to integer\n      multiples of boundary.\n\n  Returns:\n    tuple: (padding lengths, reward_mask, padded_observations, padded_actions,\n        padded_rewards) where padded_observations is shaped (B, T+1) + OBS and\n        padded_actions, padded_rewards & reward_mask are shaped (B, T).\n        Where T is max(t) rounded up to an integer multiple of boundary.\n        padded_length is how much padding we\'ve added and\n        reward_mask is 1s for actual rewards and 0s for the padding.\n  """"""\n\n  # Let\'s compute max(t) over all trajectories.\n  t_max = max(r.shape[0] for (_, _, r, _) in trajectories)\n\n  # t_max is rounded to the next multiple of `boundary`\n  boundary = int(boundary)\n  bucket_length = boundary * int(jnp.ceil(float(t_max) / boundary))\n\n  # So all obs will be padded to t_max + 1 and actions and rewards to t_max.\n  padded_observations = []\n  padded_actions = []\n  padded_rewards = []\n  padded_infos = collections.defaultdict(list)\n  padded_lengths = []\n  reward_masks = []\n\n  for (o, a, r, i) in trajectories:\n    # Determine the amount to pad, this holds true for obs, actions and rewards.\n    num_to_pad = bucket_length + 1 - o.shape[0]\n    padded_lengths.append(num_to_pad)\n    if num_to_pad == 0:\n      padded_observations.append(o)\n      padded_actions.append(a)\n      padded_rewards.append(r)\n      reward_masks.append(np.ones_like(r, dtype=jnp.int32))\n      if i:\n        for k, v in i.items():\n          padded_infos[k].append(v)\n      continue\n\n    # First pad observations.\n    padding_config = tuple([(0, num_to_pad, 0)] + [(0, 0, 0)] * (o.ndim - 1))\n\n    padding_value = get_padding_value(o.dtype)\n    action_padding_value = get_padding_value(a.dtype)\n    reward_padding_value = get_padding_value(r.dtype)\n\n    padded_obs = lax.pad(o, padding_value, padding_config)\n    padded_observations.append(padded_obs)\n\n    # Now pad actions and rewards.\n    padding_config = tuple([(0, num_to_pad, 0)] + [(0, 0, 0)] * (a.ndim - 1))\n    padded_action = lax.pad(a, action_padding_value, padding_config)\n    padded_actions.append(padded_action)\n\n    assert r.ndim == 1\n    padding_config = ((0, num_to_pad, 0),)\n    padded_reward = lax.pad(r, reward_padding_value, padding_config)\n    padded_rewards.append(padded_reward)\n\n    # Also create the mask to use later.\n    reward_mask = np.ones_like(r, dtype=jnp.int64)\n    reward_masks.append(lax.pad(reward_mask, 0, padding_config))\n\n    if i:\n      for k, v in i.items():\n        # Create a padding configuration for this value.\n        padding_config = [(0, num_to_pad, 0)] + [(0, 0, 0)] * (v.ndim - 1)\n        padded_infos[k].append(lax.pad(v, 0.0, tuple(padding_config)))\n\n  # Now stack these padded_infos if they exist.\n  stacked_padded_infos = None\n  if padded_infos:\n    stacked_padded_infos = {k: jnp.stack(v) for k, v in padded_infos.items()}\n\n  return padded_lengths, jnp.stack(reward_masks), jnp.stack(\n      padded_observations), jnp.stack(padded_actions), jnp.stack(\n          padded_rewards), stacked_padded_infos\n\n\ndef get_time(t1, t2=None):\n  if t2 is None:\n    t2 = time.time()\n  return round((t2 - t1) * 1000, 2)\n\n\ndef get_policy_model_files(output_dir):\n  return list(\n      reversed(\n          sorted(\n              tf.io.gfile.glob(os.path.join(output_dir, \'model-??????.pkl\')))))\n\n\ndef get_epoch_from_policy_model_file(policy_model_file):\n  base_name = os.path.basename(policy_model_file)\n  return int(re.match(r\'model-(\\d+).pkl\', base_name).groups()[0])\n\n\ndef get_policy_model_file_from_epoch(output_dir, epoch):\n  return os.path.join(output_dir, \'model-%06d.pkl\' % epoch)\n\n\ndef maybe_restore_opt_state(output_dir,\n                            policy_and_value_opt_state=None,\n                            policy_and_value_state=None):\n  """"""Maybe restore the optimization state from the checkpoint dir.\n\n  Optimization state includes parameters and optimizer slots.\n\n  Args:\n    output_dir: Directory where saved model checkpoints are stored.\n    policy_and_value_opt_state: Default optimization state, returned if model\n      isn\'t found.\n    policy_and_value_state: state of the policy and value network.\n\n  Returns:\n    tuple (opt_state, state, epoch (int), opt_step (int)) where epoch is the\n    epoch from which we restored the optimization state, 0 if no checkpoint was\n    found, and opt_step is the total optimization step (sum of all optimization\n    steps made up to the current epoch).\n  """"""\n  pkl_module = utils.get_pickle_module()\n  epoch = 0\n  total_opt_step = 0\n  history = trax_history.History()\n  for model_file in get_policy_model_files(output_dir):\n    logging.info(\'Trying to restore model from %s\', model_file)\n    try:\n      with tf.io.gfile.GFile(model_file, \'rb\') as f:\n        (policy_and_value_opt_state, policy_and_value_state, total_opt_step,\n         history) = pkl_module.load(f)\n      epoch = get_epoch_from_policy_model_file(model_file)\n      break\n    except EOFError as e:\n      logging.error(\'Unable to load model from: %s with %s\', model_file, e)\n      # Try an older version.\n      continue\n  return (\n      policy_and_value_opt_state,\n      policy_and_value_state,\n      epoch,\n      total_opt_step,\n      history,\n  )\n\n\nLAST_N_POLICY_MODELS_TO_KEEP = 5\n\n\ndef save_opt_state(output_dir,\n                   policy_and_value_opt_state,\n                   policy_and_value_state,\n                   epoch,\n                   total_opt_step,\n                   history):\n  """"""Saves the policy and value network optimization state etc.""""""\n  pkl_module = utils.get_pickle_module()\n  old_model_files = get_policy_model_files(output_dir)\n  params_file = os.path.join(output_dir, \'model-%06d.pkl\' % epoch)\n  with tf.io.gfile.GFile(params_file, \'wb\') as f:\n    pkl_module.dump((policy_and_value_opt_state, policy_and_value_state,\n                     total_opt_step, history), f)\n  # Keep the last k model files lying around (note k > 1 because the latest\n  # model file might be in the process of getting read async).\n  for path in old_model_files[LAST_N_POLICY_MODELS_TO_KEEP:]:\n    if path != params_file:\n      tf.io.gfile.remove(path)\n\n\ndef init_policy_from_world_model_checkpoint(\n    policy_weights, model_output_dir, substitute_fn\n):\n  """"""Initializes policy parameters from world model parameters.""""""\n  pkl_module = utils.get_pickle_module()\n  weights_file = os.path.join(model_output_dir, \'model.pkl\')\n  # Don\'t use trax.load_trainer_state to avoid a circular import.\n  with tf.io.gfile.GFile(weights_file, \'rb\') as f:\n    model_weights = pkl_module.load(f)[\'weights\']\n  model_weights = serialization_utils.extract_inner_model(model_weights)\n  # TODO(pkozakowski): The following, brittle line of code is hardcoded for\n  # transplanting parameters from TransformerLM to TransformerDecoder-based\n  # policy network of the same configuration. Figure out a more general method.\n  return substitute_fn(policy_weights, model_weights[1:-2])\n\n\ndef write_eval_reward_summaries(reward_stats_by_mode, log_fn, epoch):\n  """"""Writes evaluation reward statistics to summary and logs them.\n\n  Args:\n    reward_stats_by_mode: Nested dict of structure: {\n          \'raw\': {\n              <temperature 1>: {\n                  \'mean\': <reward mean>,\n                  \'std\': <reward std>, },\n              <temperature 2>: ... },\n          \'processed\': ... }\n    log_fn: Function mode, metric_name, value -> None for logging the summaries.\n    epoch: Current epoch number.\n  """"""\n  for (reward_mode, reward_stats_by_temp) in reward_stats_by_mode.items():\n    for (temperature, reward_stats) in reward_stats_by_temp.items():\n      for (stat_name, stat) in reward_stats.items():\n        metric_name = \'eval/{}_reward_{}/temperature_{}\'.format(\n            reward_mode, stat_name, temperature\n        )\n        log_fn(\'eval\', metric_name, stat)\n      logging.info(\n          \'Epoch [% 6d] Policy Evaluation (%s reward) \'\n          \'[temperature %.2f] = %10.2f (+/- %.2f)\', epoch, reward_mode,\n          temperature, reward_stats[\'mean\'], reward_stats[\'std\'])\n\n\ndef run_policy_all_timesteps(\n    policy_and_value_net_apply,\n    observations,\n    weights,\n    state,\n    rng,\n    action_space,\n):\n  """"""Runs the policy network.""""""\n  # TODO(pkozakowski): Pass the actual actions here, to enable autoregressive\n  # action sampling.\n  (B, T_plus_1) = observations.shape[:2]  # pylint: disable=invalid-name\n  dummy_actions = np.zeros(\n      (B, T_plus_1 - 1) + action_space.shape, dtype=action_space.dtype\n  )\n  policy_input = (observations, dummy_actions)\n  (rng, subrng) = trax_random.split(rng)\n  (log_probs, value_preds) = policy_and_value_net_apply(\n      policy_input, weights=weights, state=state, rng=subrng\n  )\n  return log_probs, value_preds, state, rng\n\n\ndef run_policy(\n    policy_and_value_net_apply,\n    observations,\n    lengths,\n    weights,\n    state,\n    rng,\n    action_space,\n):\n  """"""Runs the policy network and returns lps, vps for the last timestep.""""""\n  log_probs, value_preds, state, rng = run_policy_all_timesteps(\n      policy_and_value_net_apply,\n      observations,\n      weights,\n      state,\n      rng,\n      action_space,\n  )\n\n  # We need the log_probs of those actions that correspond to the last actual\n  # time-step.\n  (B, unused_T_plus_1) = observations.shape[:2]  # pylint: disable=invalid-name\n  index = lengths - 1  # Since we want to index using lengths.\n  log_probs = log_probs[jnp.arange(B), index]\n  value_preds = value_preds[jnp.arange(B), index]\n  return (log_probs, value_preds, state, rng)\n'"
trax/rl/policy_based_utils_test.py,12,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.rl.policy_based_utils.""""""\n\nimport gym\nimport numpy as np\nfrom tensorflow import test\nfrom tensorflow.compat.v1.io import gfile\nfrom trax import layers\nfrom trax import shapes\nfrom trax.rl import policy_based_utils\nfrom trax.supervised import trainer_lib\n\n\nclass PolicyBasedUtilsTest(test.TestCase):\n\n  def setUp(self):\n    super(PolicyBasedUtilsTest, self).setUp()\n    self.rng_key = trainer_lib.init_random_number_generators(0)\n\n  def test_get_policy_model_files(self):\n    output_dir = self.get_temp_dir()\n\n    def write_policy_model_file(epoch):\n      with gfile.GFile(policy_based_utils.get_policy_model_file_from_epoch(\n          output_dir, epoch\n      ), \'w\') as f:\n        f.write(\'some data\')\n\n    epochs = [200, 100, 300]\n\n    # 300, 200, 100\n    expected_policy_model_files = [\n        output_dir + \'/model-000300.pkl\',\n        output_dir + \'/model-000200.pkl\',\n        output_dir + \'/model-000100.pkl\',\n    ]\n\n    for epoch in epochs:\n      write_policy_model_file(epoch)\n\n    policy_model_files = policy_based_utils.get_policy_model_files(output_dir)\n\n    self.assertEqual(expected_policy_model_files, policy_model_files)\n\n    gfile.rmtree(output_dir)\n\n  def test_get_epoch_from_policy_model_file(self):\n    self.assertEqual(\n        policy_based_utils.get_epoch_from_policy_model_file(\'model-000000.pkl\'),\n        0,\n    )\n    self.assertEqual(\n        policy_based_utils.get_epoch_from_policy_model_file(\'model-123456.pkl\'),\n        123456,\n    )\n\n  def test_get_policy_model_file_from_epoch(self):\n    self.assertEqual(\n        policy_based_utils.get_policy_model_file_from_epoch(\'/tmp\', 0),\n        \'/tmp/model-000000.pkl\',\n    )\n    self.assertEqual(\n        policy_based_utils.get_policy_model_file_from_epoch(\'/tmp\', 123456),\n        \'/tmp/model-123456.pkl\',\n    )\n\n  def test_policy_and_value_net(self):\n    observation_shape = (3, 4, 5)\n    n_actions = 2\n    n_controls = 3\n    batch = 2\n    time_steps = 10\n    observations = np.random.uniform(\n        size=(batch, time_steps) + observation_shape)\n    actions = np.random.randint(\n        n_actions, size=(batch, time_steps - 1, n_controls))\n    (pnv_model, _) = policy_based_utils.policy_and_value_net(\n        bottom_layers_fn=lambda: [layers.Flatten(n_axes_to_keep=2)],\n        observation_space=gym.spaces.Box(\n            shape=observation_shape, low=0, high=1\n        ),\n        action_space=gym.spaces.MultiDiscrete((n_actions,) * n_controls),\n        vocab_size=None,\n        two_towers=True,\n    )\n    input_signature = shapes.signature((observations, actions))\n    _, _ = pnv_model.init(input_signature)\n\n    (action_logits, values) = pnv_model((observations, actions))\n\n    # Output is a list, first is probab of actions and the next is value output.\n    self.assertEqual(\n        (batch, time_steps, n_controls, n_actions), action_logits.shape)\n    self.assertEqual((batch, time_steps), values.shape)\n\n  def test_pad_trajectories(self):\n    observation_shape = (2, 3, 4)\n    trajectories = []\n    n_trajectories = 7\n    n_actions = 10\n\n    # Time-steps are between [min_allowable_time_step, max_allowable_time_step]\n    max_allowable_time_step = 19\n    min_allowable_time_step = 5\n\n    # The actual max we see in the data.\n    max_time_step = -1\n\n    # Bucket length.\n    bucket_length = 15\n\n    # Make `n_trajectories` random trajectories.\n    for i in range(n_trajectories):\n      time_steps = np.random.randint(min_allowable_time_step,\n                                     max_allowable_time_step + 1)\n      if time_steps > max_time_step:\n        max_time_step = time_steps\n      observations = np.random.randint(\n          0, 255, size=(time_steps + 1,) + observation_shape).astype(np.uint8)\n      rewards = np.random.uniform(size=(time_steps,)).astype(np.float32)\n      actions = np.random.randint(\n          0, n_actions, size=(time_steps,)).astype(np.int32)\n      infos = {\n          \'a\': np.random.uniform(size=(time_steps,)).astype(np.float32),\n          \'b\': np.random.uniform(size=(time_steps,)).astype(np.float32)\n      }\n      trajectories.append((observations, rewards, actions, infos))\n\n    # Now pad these trajectories.\n    padded_trajectories = policy_based_utils.pad_trajectories(\n        trajectories, boundary=bucket_length)\n\n    # Expected padding.\n    i = 1\n    while i * bucket_length < max_time_step:\n      i += 1\n    expected_padding = i * bucket_length\n\n    # Get the padded objects.\n    (pad_lengths, reward_mask, padded_observations, padded_actions,\n     padded_rewards, padded_infos) = padded_trajectories\n\n    # Expectations on the padded shapes.\n    self.assertEqual(padded_observations.shape, (\n        n_trajectories,\n        expected_padding + 1,\n    ) + observation_shape)\n    self.assertEqual(padded_actions.shape, (n_trajectories, expected_padding))\n    self.assertEqual(padded_rewards.shape, (n_trajectories, expected_padding))\n    self.assertEqual(reward_mask.shape, (n_trajectories, expected_padding))\n\n    self.assertEqual(padded_infos[\'a\'].shape,\n                     (n_trajectories, expected_padding))\n    self.assertEqual(padded_infos[\'b\'].shape,\n                     (n_trajectories, expected_padding))\n\n    # Assert that the padding lengths and reward mask are consistent.\n    self.assertAllEqual(\n        np.full((n_trajectories,), expected_padding),\n        np.array(np.sum(reward_mask, axis=1)) + pad_lengths)\n\n  def test_saves_and_restores_opt_state(self):\n    opt_state = 123\n    state = 456\n    epoch = 7\n    opt_step = 89\n    history = 0\n    output_dir = self.get_temp_dir()\n    policy_based_utils.save_opt_state(\n        output_dir, opt_state, state, epoch, opt_step, history\n    )\n    restored_data = policy_based_utils.maybe_restore_opt_state(output_dir)\n    self.assertEqual(\n        restored_data, (opt_state, state, epoch, opt_step, history)\n    )\n\n  def _make_run_policy_kwargs(self, action_space):\n    return {\n        \'weights\': None,\n        \'state\': None,\n        \'rng\': self.rng_key,\n        \'action_space\': action_space,\n    }\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/ppo.py,33,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""PPO in JAX.\n\nNotation:\n\nB, scalar   - batch size\nT, scalar   - number of actions in a trajectory\nC, scalar   - number of controls (dimensions) in an action\nOBS, tuple  - shape of a singular observation from the environment.\n             Ex: For CartPole-v0 this is (4,) and Pong-v0 it\'s (210, 160, 3)\nA, scalar   - Number of actions, assuming a discrete space.\n\nPolicy and Value function signatures:\n\nPolicy            :: ([B, T + 1] + OBS, [B, T + 1, C]) ->  [B, T + 1, C, A]\nValue             :: ([B, T + 1] + OBS, [B, T + 1, C]) ->  [B, T + 1]\nPolicy and Value  :: ([B, T + 1] + OBS, [B, T + 1, C]) -> ([B, T + 1, C, A],\n                                                           [B, T + 1])\n\ni.e. the policy net should take a batch of *trajectories* and at each time-step\nin each batch deliver a probability distribution over actions.\n\nNOTE: It doesn\'t return logits, rather the expectation is that it returns\nlog-probabilities instead.\n\nNOTE: The policy and value functions need to take care to not take into account\nfuture time-steps while deciding the actions (or value) for the current\ntime-step.\n\nPolicy and Value Function produces a tuple of the expected output of a policy\nfunction and a value function.\n\n""""""\n\nimport functools\nimport itertools\n\nimport jax\nfrom jax import numpy as jnp\nimport numpy as np\n\n\ndef rewards_to_go(rewards, mask, gamma):\n  r""""""Computes rewards to go.\n\n  Reward to go is defined as follows, the discounted reward that we have to\n  yet collect, going forward from this point, i.e.:\n\n  r2g_t = \\sum_{l=0}^{\\infty} (\\gamma^{l} * reward_{t+l})\n\n  Args:\n    rewards: jnp.ndarray of shape (B, T) of rewards.\n    mask: jnp.ndarray of shape (B, T) of mask for the rewards.\n    gamma: float, discount factor.\n\n  Returns:\n    rewards to go, jnp.ndarray of shape (B, T).\n  """"""\n  B, T = rewards.shape  # pylint: disable=invalid-name,unused-variable\n\n  masked_rewards = rewards * mask  # (B, T)\n\n  # The lax.scan version of this is slow, but we still show it here for\n  # completeness.\n  #   rewards_rev = jnp.flip(masked_rewards, axis=1)  # (B, T) flipped on time.\n  #   rrt = jnp.transpose(rewards_rev)  # (T, B) transpose to scan over time.\n  #\n  #   def discounting_add(carry, reward):\n  #     x = reward + (gamma * carry)\n  #     return x, x\n  #\n  #   _, ys = lax.scan(discounting_add,\n  #                    jnp.zeros_like(rrt[0], dtype=jnp.float32),\n  #                    rrt.astype(jnp.float32))\n  #\n  #   # ys is (T, B) and T is in reverse order.\n  #   return jnp.flip(jnp.transpose(ys), axis=1)\n\n  # We use the following recurrence relation, derived from the equation above:\n  #\n  # r2g[t+1] = (r2g[t] - r[t]) / gamma\n  #\n  # This means we\'ll need to calculate r2g[0] first and then r2g[1] and so on ..\n  #\n  # **However** this leads to overflows for long sequences: r2g[t] - r[t] > 0\n  # and gamma < 1.0, so the division keeps increasing.\n  #\n  # So we just run the recurrence in reverse, i.e.\n  #\n  # r2g[t] = r[t] + (gamma*r2g[t+1])\n  #\n  # This is much better, but might have lost updates since the (small) rewards\n  # at earlier time-steps may get added to a (very?) large sum.\n\n  # Compute r2g_{T-1} at the start and then compute backwards in time.\n  r2gs = [masked_rewards[:, -1]]\n\n  # Go from T-2 down to 0.\n  for t in reversed(range(T - 1)):\n    r2gs.append(masked_rewards[:, t] + (gamma * r2gs[-1]))\n\n  # The list should have length T.\n  assert T == len(r2gs)\n\n  # First we stack them in the correct way to make it (B, T), but these are\n  # still from newest (T-1) to oldest (0), so then we flip it on time axis.\n  return jnp.flip(jnp.stack(r2gs, axis=1), axis=1)\n\n\n@jax.jit\ndef value_loss_given_predictions(value_prediction,\n                                 rewards,\n                                 reward_mask,\n                                 gamma,\n                                 epsilon,\n                                 value_prediction_old=None):\n  """"""Computes the value loss given the prediction of the value function.\n\n  Args:\n    value_prediction: `jnp.ndarray` of shape `(B, T+1, 1)`.\n    rewards: `jnp.ndarray` of shape `(B, T)` of rewards.\n    reward_mask: `jnp.ndarray` of shape `(B, T)`, the mask over rewards.\n    gamma: `float`, discount factor.\n    epsilon: `float`, clip-fraction, used if `value_value_prediction_old` isn\'t\n        `None`.\n    value_prediction_old: `jnp.ndarray` of shape `(B, T+1, 1)` of value\n        predictions using the old parameters. If provided, we incorporate this\n        in the loss as well. This is from the OpenAI baselines implementation.\n\n  Returns:\n    `(value_loss, summaries)` pair, where `value_loss` is the average L2 value\n    loss, averaged over instances where `reward_mask` is 1. Summaries is a dict\n    of summaries collected during value loss computation.\n  """"""\n\n  B, T = rewards.shape  # pylint: disable=invalid-name\n  assert (B, T) == reward_mask.shape\n  assert (B, T + 1) == value_prediction.shape\n\n  value_prediction = value_prediction[:, :-1] * reward_mask  # (B, T)\n  r2g = rewards_to_go(rewards, reward_mask, gamma=gamma)  # (B, T)\n  loss = (value_prediction - r2g)**2\n\n  # From the baselines implementation.\n  if value_prediction_old is not None:\n    value_prediction_old = value_prediction_old[:, :-1] * reward_mask  # (B, T)\n\n    v_clipped = value_prediction_old + jnp.clip(\n        value_prediction - value_prediction_old, -epsilon, epsilon)\n    v_clipped_loss = (v_clipped - r2g)**2\n    loss = jnp.maximum(v_clipped_loss, loss)\n\n  # Take an average on only the points where mask != 0.\n  value_loss = jnp.sum(loss) / jnp.sum(reward_mask)\n\n  summaries = {\n      \'value_loss\': value_loss,\n  }\n\n  return (value_loss, summaries)\n\n\ndef deltas(predicted_values, rewards, mask, gamma):\n  r""""""Computes TD-residuals from `V(s)` and `rewards`.\n\n  Where a `delta`, i.e. a td-residual is defined as:\n\n  `delta_{b,t} = r_{b,t} + \\gamma * v_{b,t+1} - v_{b,t}`.\n\n  Args:\n    predicted_values: `ndarray` of shape `(B, T+1)`. NOTE: Expects axis 2 was\n        squeezed. These represent `V(s_bt)` for `b < B` and `t < T+1`.\n    rewards: `ndarray` of shape `(B, T)` of rewards.\n    mask: `ndarray` of shape `(B, T)` of mask for rewards.\n    gamma: `float`, discount factor.\n\n  Returns:\n    `ndarray` of shape `(B, T)` of one-step TD-residuals.\n  """"""\n\n  # Predicted values at time t, cutting off the last to have shape (B, T).\n  predicted_values_bt = predicted_values[:, :-1]\n  # Predicted values at time t+1, by cutting off the first to have shape (B, T)\n  predicted_values_btplus1 = predicted_values[:, 1:]\n  # Return the deltas as defined above.\n  return (rewards +\n          (gamma * predicted_values_btplus1) - predicted_values_bt) * mask\n\n\ndef gae_advantages(td_deltas, mask, lambda_, gamma):\n  r""""""Computes the GAE advantages given the one step TD-residuals.\n\n  The formula for a GAE advantage estimator is as follows:\n\n  `A_{bt} = \\sum_{l=0}^{\\infty}(\\gamma * \\lambda)^{l}(\\delta_{b,t+l})`.\n\n  Internally we just call rewards_to_go, since it is the same computation.\n\n  Args:\n    td_deltas: `jnp.ndarray` of shape `(B, T)` of one step TD-residuals.\n    mask: `jnp.ndarray` of shape `(B, T)` of mask for the residuals. It may be\n        the case that the `td_deltas` are already masked correctly since they\n        are produced by `deltas(...)`.\n    lambda_: `float`, lambda parameter for GAE estimators.\n    gamma: `float`, lambda parameter for GAE estimators.\n\n  Returns:\n    GAE advantage estimates.\n  """"""\n\n  return rewards_to_go(td_deltas, mask, lambda_ * gamma)\n\n\ndef chosen_probabs(probab_actions, actions):\n  """"""Picks out the probabilities of the actions along batch and time-steps.\n\n  Args:\n    probab_actions: `ndarray` of shape `(B, T, C, A)`, where\n      `probab_actions[b, t, i]` contains the log-probability of `action = i`\n      at the `t^th` time-step in the `b^th` trajectory.\n    actions: `ndarray` of shape `(B, T)`, with each entry in `(0, A)` denoting\n      which action was chosen in the `b^th` trajectory\'s `t^th` time-step.\n\n  Returns:\n    `ndarray` of shape `(B, T, C, A)` with the log-probabilities of the chosen\n    actions.\n  """"""\n  B, T, C = actions.shape  # pylint: disable=invalid-name\n  assert (B, T, C) == probab_actions.shape[:3]\n  return probab_actions[jnp.arange(B)[:, None, None],\n                        jnp.arange(T)[:, None],\n                        jnp.arange(C),\n                        actions]\n\n\ndef compute_probab_ratios(p_new, p_old, actions, action_mask):\n  """"""Computes the probability ratios for each time-step in a trajectory.\n\n  Args:\n    p_new: `ndarray` of shape `(B, T, A)` of the log-probabilities that the\n      policy network assigns to all the actions at each time-step in each batch\n      using the old parameters.\n    p_old: `ndarray` of shape `(B, T, A)`, same as above, but using old policy\n      network parameters.\n    actions: `ndarray` of shape `(B, T)` where each element is from `(0, A)`.\n    action_mask: `ndarray` of shape `(B, T)` masking over probabilities.\n\n  Returns:\n    `ndarray` of shape `(B, T)`, where `probab_ratios_{b,t,} =\n    p_new_{b,t,action_{b,t}} / p_old_{b,t,action_{b,t}}`\n  """"""\n\n  B, T, C = actions.shape  # pylint: disable=invalid-name\n  assert (B, T, C) == p_old.shape[:3]\n  assert (B, T, C) == p_new.shape[:3]\n\n  logp_old = chosen_probabs(p_old, actions)\n  logp_new = chosen_probabs(p_new, actions)\n\n  assert (B, T, C) == logp_old.shape\n  assert (B, T, C) == logp_new.shape\n\n  # Since these are log-probabilities, we just subtract them.\n  probab_ratios = jnp.exp(logp_new - logp_old) * action_mask\n  assert (B, T, C) == probab_ratios.shape\n  return probab_ratios\n\n\ndef clipped_probab_ratios(probab_ratios, epsilon):\n  return jnp.clip(probab_ratios, 1 - epsilon, 1 + epsilon)\n\n\ndef clipped_objective(probab_ratios, advantages, action_mask, epsilon):\n  advantages = advantages\n  return jnp.minimum(\n      probab_ratios * advantages,\n      clipped_probab_ratios(probab_ratios, epsilon=epsilon) *\n      advantages) * action_mask\n\n\n@jax.jit\ndef ppo_loss_given_predictions(log_probab_actions_new,\n                               log_probab_actions_old,\n                               value_predictions_old,\n                               padded_actions,\n                               padded_rewards,\n                               reward_mask,\n                               gamma,\n                               lambda_,\n                               epsilon):\n  """"""PPO objective, with an eventual minus sign, given predictions.""""""\n  # The last timestep has been cut here.\n  B, T, C, A = log_probab_actions_old.shape  # pylint: disable=invalid-name\n\n  assert (B, T) == padded_rewards.shape  # pylint: disable=invalid-name\n  assert (B, T) == padded_rewards.shape\n  assert (B, T, C) == padded_actions.shape\n  assert (B, T) == reward_mask.shape\n\n  assert (B, T + 1) == value_predictions_old.shape\n  assert (B, T, C, A) == log_probab_actions_old.shape\n  assert (B, T, C, A) == log_probab_actions_new.shape\n\n  # (B, T)\n  td_deltas = deltas(\n      value_predictions_old,  # (B, T+1)\n      padded_rewards,\n      reward_mask,\n      gamma=gamma)\n\n  # (B, T)\n  advantages = gae_advantages(\n      td_deltas, reward_mask, lambda_=lambda_, gamma=gamma)\n\n  # Normalize the advantages.\n  advantage_mean = jnp.mean(advantages)\n  advantage_std = jnp.std(advantages)\n  advantages = (advantages - advantage_mean) / (advantage_std + 1e-8)\n\n  # Broadcast advantages and reward action over controls.\n  advantages = advantages[:, :, None]\n  action_mask = reward_mask[:, :, None]\n\n  # (B, T, C)\n  ratios = compute_probab_ratios(log_probab_actions_new, log_probab_actions_old,\n                                 padded_actions, action_mask)\n  assert (B, T, C) == ratios.shape\n\n  # (B, T, C)\n  objective = clipped_objective(\n      ratios, advantages, action_mask, epsilon=epsilon)\n  assert (B, T, C) == objective.shape\n\n  # ()\n  average_objective = jnp.sum(objective) / jnp.sum(reward_mask)\n\n  # Loss is negative objective.\n  ppo_loss = -average_objective\n\n  summaries = {\n      \'ppo_loss\': ppo_loss,\n      \'advantage_mean\': advantage_mean,\n      \'advantage_std\': advantage_std,\n  }\n\n  return (ppo_loss, summaries)\n\n\n@jax.jit\ndef combined_loss_given_predictions(log_probab_actions_new,\n                                    log_probab_actions_old,\n                                    value_prediction_new,\n                                    value_prediction_old,\n                                    padded_actions,\n                                    padded_rewards,\n                                    reward_mask,\n                                    gamma,\n                                    lambda_,\n                                    value_weight,\n                                    entropy_weight,\n                                    epsilon):\n  """"""Computes the combined (clipped loss + value loss) given predictions.""""""\n  (value_loss, value_summaries) = value_loss_given_predictions(\n      value_prediction_new,\n      padded_rewards,\n      reward_mask,\n      gamma=gamma,\n      value_prediction_old=value_prediction_old,\n      epsilon=epsilon)\n  (ppo_loss, ppo_summaries) = ppo_loss_given_predictions(\n      log_probab_actions_new,\n      log_probab_actions_old,\n      value_prediction_old,\n      padded_actions,\n      padded_rewards,\n      reward_mask,\n      gamma=gamma,\n      lambda_=lambda_,\n      epsilon=epsilon)\n  entropy_bonus = masked_entropy(log_probab_actions_new, reward_mask)\n  combined_loss_ = ppo_loss + (value_weight * value_loss) - (\n      entropy_weight * entropy_bonus)\n\n  summaries = {\n      \'combined_loss\': combined_loss_,\n      \'entropy_bonus\': entropy_bonus,\n  }\n  for loss_summaries in (value_summaries, ppo_summaries):\n    summaries.update(loss_summaries)\n\n  return (combined_loss_, (ppo_loss, value_loss, entropy_bonus), summaries)\n\n\n@functools.partial(jax.jit, static_argnums=(3,))\ndef combined_loss(new_weights,\n                  log_probab_actions_old,\n                  value_predictions_old,\n                  policy_and_value_net_apply,\n                  padded_observations,\n                  padded_actions,\n                  padded_rewards,\n                  reward_mask,\n                  nontrainable_params,\n                  state=None,\n                  rng=None):\n  """"""Computes the combined (clipped loss + value loss) given observations.""""""\n  gamma = nontrainable_params[\'gamma\']\n  lambda_ = nontrainable_params[\'lambda\']\n  value_weight = nontrainable_params[\'value_weight\']\n  entropy_weight = nontrainable_params[\'entropy_weight\']\n  epsilon = nontrainable_params[\'epsilon\']\n\n  # TODO(pkozakowski): Pass the actual actions here, to enable autoregressive\n  # action sampling.\n  dummy_actions = jnp.zeros_like(padded_actions)\n  (log_probab_actions_new, value_predictions_new) = (\n      policy_and_value_net_apply(\n          (padded_observations, dummy_actions),\n          weights=new_weights,\n          state=state,\n          rng=rng,\n      )\n  )\n  # Cut off the last extra action to obtain shape (B, T, C, A).\n  log_probab_actions_new = log_probab_actions_new[:, :-1]\n\n  (loss, component_losses, summaries) = combined_loss_given_predictions(\n      log_probab_actions_new,\n      log_probab_actions_old,\n      value_predictions_new,\n      value_predictions_old,\n      padded_actions,\n      padded_rewards,\n      reward_mask,\n      gamma=gamma,\n      lambda_=lambda_,\n      value_weight=value_weight,\n      entropy_weight=entropy_weight,\n      epsilon=epsilon,\n  )\n  return (loss, component_losses, summaries, state)\n\n\n@functools.partial(jax.jit, static_argnums=(2, 3, 4))\ndef policy_and_value_opt_step(i,\n                              opt_state,\n                              opt_update,\n                              get_params,\n                              policy_and_value_net_apply,\n                              log_probab_actions_old,\n                              value_predictions_old,\n                              padded_observations,\n                              padded_actions,\n                              padded_rewards,\n                              reward_mask,\n                              nontrainable_params,\n                              state=None,\n                              rng=None):\n  """"""Policy and Value optimizer step.""""""\n\n  # Combined loss function given the new params.\n  def policy_and_value_loss(params, state):\n    """"""Returns the combined loss given just parameters.""""""\n    (loss, _, _, state) = combined_loss(\n        params,\n        log_probab_actions_old,\n        value_predictions_old,\n        policy_and_value_net_apply,\n        padded_observations,\n        padded_actions,\n        padded_rewards,\n        reward_mask,\n        nontrainable_params,\n        state=state,\n        rng=rng)\n    return loss, state\n\n  new_weights = get_params(opt_state)\n  g, state = jax.grad(policy_and_value_loss, has_aux=True)(new_weights, state)\n  # TODO(afrozm): Maybe clip gradients?\n  return opt_update(i, g, opt_state), state\n\n\ndef approximate_kl(log_prob_new, log_prob_old, mask):\n  """"""Computes the approximate KL divergence between the old and new log-probs.\n\n  Args:\n    log_prob_new: (B, T, C, A) log probs new\n    log_prob_old: (B, T, C, A) log probs old\n    mask: (B, T)\n\n  Returns:\n    Approximate KL.\n  """"""\n  diff = log_prob_old - log_prob_new\n  # Mask out the irrelevant part.\n  diff *= mask[:, :, None, None]  # make mask (B, T, 1, 1)\n  # Average on non-masked part.\n  return jnp.sum(diff) / jnp.sum(mask)\n\n\ndef masked_entropy(log_probs, mask):\n  """"""Computes the entropy for the given log-probs.\n\n  Args:\n    log_probs: (B, T, C, A) log probs\n    mask: (B, T) mask.\n\n  Returns:\n    Entropy.\n  """"""\n  # Mask out the irrelevant part.\n  lp = log_probs * mask[:, :, None, None]  # make mask (B, T, 1, 1)\n  p = jnp.exp(lp) * mask[:, :, None, None]  # (B, T, 1, 1)\n  # Average on non-masked part and take negative.\n  return -(jnp.sum(lp * p) / jnp.sum(mask))\n\n\ndef shuffled_index_batches(dataset_size, batch_size):\n  """"""Generates batches of shuffled indices over a dataset.""""""\n  def shuffled_indices():\n    while True:\n      perm = np.random.permutation(dataset_size)\n      for x in perm:\n        yield x\n\n  indices = shuffled_indices()\n  while True:\n    yield np.array(list(itertools.islice(indices, int(batch_size))))\n'"
trax/rl/ppo_test.py,74,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.rl.ppo.""""""\n\nimport itertools\n\nimport gym\nimport jax\nimport numpy as np\nfrom tensorflow import test\nfrom trax import layers\nfrom trax import shapes\nfrom trax.rl import policy_based_utils\nfrom trax.rl import ppo\n\n\nclass PpoTest(test.TestCase):\n\n  def test_rewards_to_go(self):\n    rewards = np.array([\n        [1, 2, 4, 8, 16, 32, 64, 128],\n        [1, 1, 1, 1, 1, 1, 1, 1],\n    ])\n\n    rewards_mask = np.array([\n        [1, 1, 1, 1, 1, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 0],\n    ])\n\n    gamma = 0.5\n\n    rewards_to_go = ppo.rewards_to_go(rewards, rewards_mask, gamma)\n\n    self.assertAllEqual(\n        np.array([\n            [5, 8, 12, 16, 16, 0, 0, 0],\n            [1.984375, 1.96875, 1.9375, 1.875, 1.75, 1.5, 1.0, 0],\n        ]), rewards_to_go)\n\n  def test_rewards_to_go_really_long_sequences(self):\n    T = 1200  # pylint: disable=invalid-name\n\n    rewards = np.random.uniform(1e-3, 1e-2, (1, T))\n\n    # Make a mask, clear out a fixed number `L` of 1s from the end.\n    L = 36  # pylint: disable=invalid-name\n    assert L < T\n    rewards_mask = np.ones_like(rewards)\n    rewards_mask[0, L:] = 0\n\n    gamma = 0.94\n\n    actual_r2g = ppo.rewards_to_go(rewards, rewards_mask, gamma).reshape(-1)\n\n    # Let\'s compute r2g the slow way.\n    masked_rewards = (rewards_mask * rewards).reshape(-1)\n    expected_r2g = np.zeros_like(masked_rewards)\n    for t in range(T):\n      for j in range(t, T):\n        expected_r2g[t] += (gamma**(j - t)) * masked_rewards[j]\n\n    self.assertAllClose(expected_r2g, actual_r2g)\n\n  def test_value_loss(self):\n    rewards = np.array([\n        [1, 2, 4, 8, 16, 32, 64, 128],\n        [1, 1, 1, 1, 1, 1, 1, 1],\n    ])\n\n    rewards_mask = np.array([\n        [1, 1, 1, 1, 1, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 0],\n    ])\n\n    gamma = 0.5\n    epsilon = 0.1\n\n    # Random observations and a value function that returns a constant value.\n    # NOTE: Observations have an extra time-step.\n    B, T = rewards.shape  # pylint: disable=invalid-name\n    observation_shape = (210, 160, 3)  # atari pong\n    random_observations = np.random.uniform(size=(B, T + 1) + observation_shape)\n\n    def value_net_apply(observations, params, rng=None):\n      del params, rng\n      # pylint: disable=invalid-name\n      B, T_p_1, OBS = (observations.shape[0], observations.shape[1],\n                       observations.shape[2:])\n      del OBS\n      return np.ones((B, T_p_1))\n      # pylint: enable=invalid-name\n\n    value_prediction = value_net_apply(random_observations, [])\n\n    with jax.disable_jit():\n      (value_loss, _) = ppo.value_loss_given_predictions(\n          value_prediction,\n          rewards,\n          rewards_mask,\n          gamma,\n          epsilon)\n\n    self.assertNear(53.3637084961, value_loss, 1e-6)\n\n  def test_deltas(self):\n    rewards = np.array([\n        [1, 2, 4, 8, 16, 32, 64, 128],\n        [1, 1, 1, 1, 1, 1, 1, 1],\n    ])\n\n    rewards_mask = np.array([\n        [1, 1, 1, 1, 1, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 0],\n    ])\n\n    B, T = rewards.shape  # pylint: disable=invalid-name\n\n    # Say, all predicted values are 1.\n    predicted_values = np.ones((B, T + 1))\n\n    gamma = 1.0\n\n    td_residuals = ppo.deltas(predicted_values, rewards, rewards_mask, gamma)\n\n    # With V(s) being the same for all s, td_residuals should be\n    # equal to the rewards + (\\gamma - 1)*v(s), masked in the right places.\n    truncated_pv = predicted_values[:, :-1]\n    masked_rewards = rewards * rewards_mask\n    expected_residuals = (masked_rewards +\n                          (gamma - 1) * truncated_pv) * rewards_mask\n    self.assertAllEqual(expected_residuals, td_residuals)\n\n    gamma = 0.5\n    td_residuals = ppo.deltas(predicted_values, rewards, rewards_mask, gamma)\n    expected_residuals = (masked_rewards +\n                          (gamma - 1) * truncated_pv) * rewards_mask\n    self.assertAllEqual(expected_residuals, td_residuals)\n\n  def test_gae_advantages(self):\n    td_deltas = np.array([\n        [1, 2, 4, 8, 16, 32, 64, 128],\n        [1, 1, 1, 1, 1, 1, 1, 1],\n    ])\n\n    rewards_mask = np.array([\n        [1, 1, 1, 1, 1, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 0],\n    ])\n\n    gamma = 0.5\n    lambda_ = 1.0\n\n    expected_gae_advantages = np.array([\n        [5, 8, 12, 16, 16, 0, 0, 0],\n        [1.984375, 1.96875, 1.9375, 1.875, 1.75, 1.5, 1.0, 0],\n    ])\n\n    gae_advantages = ppo.gae_advantages(td_deltas * rewards_mask, rewards_mask,\n                                        lambda_, gamma)\n    self.assertAllEqual(expected_gae_advantages, gae_advantages)\n\n    gamma = 1.0\n    lambda_ = 0.5\n\n    gae_advantages = ppo.gae_advantages(td_deltas * rewards_mask, rewards_mask,\n                                        lambda_, gamma)\n    self.assertAllEqual(expected_gae_advantages, gae_advantages)\n\n  def test_chosen_probabs(self):\n    # Shape (2, 2, 1, 3)\n    probab_observations = np.array(\n        [[[0.1, 0.2, 0.7], [0.4, 0.1, 0.5]],\n         [[0.3, 0.1, 0.6], [0.1, 0.1, 0.8]]]\n    )[:, :, None, :]\n\n    # Shape (2, 2, 1)\n    actions = np.array([[1, 2], [0, 1]])[:, :, None]\n\n    chosen_probabs = ppo.chosen_probabs(probab_observations, actions)\n\n    self.assertAllEqual(\n        np.array([[0.2, 0.5], [0.3, 0.1]])[:, :, None], chosen_probabs)\n\n  def test_compute_probab_ratios(self):\n    p_old = np.array([[\n        [np.log(0.1), np.log(0.2), np.log(0.6), np.log(0.1)],\n        [np.log(0.4), np.log(0.1), np.log(0.4), np.log(0.1)],\n        [np.log(0.3), np.log(0.1), np.log(0.5), np.log(0.1)],\n        [np.log(0.1), np.log(0.2), np.log(0.6), np.log(0.1)],\n    ], [\n        [np.log(0.3), np.log(0.1), np.log(0.5), np.log(0.1)],\n        [np.log(0.1), np.log(0.1), np.log(0.4), np.log(0.4)],\n        [np.log(0.3), np.log(0.1), np.log(0.5), np.log(0.1)],\n        [np.log(0.1), np.log(0.2), np.log(0.6), np.log(0.1)],\n    ]])[:, :, None, :]\n\n    p_new = np.array([[\n        [np.log(0.3), np.log(0.1), np.log(0.5), np.log(0.1)],\n        [np.log(0.4), np.log(0.1), np.log(0.1), np.log(0.3)],\n        [np.log(0.1), np.log(0.2), np.log(0.1), np.log(0.6)],\n        [np.log(0.3), np.log(0.1), np.log(0.5), np.log(0.1)],\n    ], [\n        [np.log(0.1), np.log(0.2), np.log(0.1), np.log(0.6)],\n        [np.log(0.1), np.log(0.1), np.log(0.2), np.log(0.6)],\n        [np.log(0.3), np.log(0.1), np.log(0.3), np.log(0.3)],\n        [np.log(0.1), np.log(0.2), np.log(0.1), np.log(0.6)],\n    ]])[:, :, None, :]\n\n    actions = np.array([[1, 2, 0, 1], [0, 3, 3, 0]])[:, :, None]\n\n    mask = np.array([[1, 1, 0, 0], [1, 1, 1, 0]])[:, :, None]\n\n    probab_ratios = ppo.compute_probab_ratios(p_new, p_old, actions, mask)\n\n    self.assertAllClose(\n        np.array([\n            [0.1 / 0.2, 0.1 / 0.4, 0.0, 0.0],\n            [0.1 / 0.3, 0.6 / 0.4, 0.3 / 0.1, 0.0],\n        ])[:, :, None], probab_ratios)\n\n  def test_clipped_probab_ratios(self):\n    probab_ratios = np.array([\n        [1.5, 1.0, 0.5, 0.7],\n        [2.5, 2.0, 0.1, 1.0],\n    ])\n\n    clipped_probab_ratios = ppo.clipped_probab_ratios(probab_ratios, 0.1)\n\n    self.assertAllClose(\n        np.array([\n            [1.1, 1.0, 0.9, 0.9],\n            [1.1, 1.1, 0.9, 1.0],\n        ]), clipped_probab_ratios)\n\n  def test_clipped_objective(self):\n    probab_ratios = np.array([\n        [1.5, 2.0, 0.5, 0.7],\n        [2.5, 2.0, 0.1, 1.0],\n    ])\n\n    advantages = np.array([\n        [0.1, -0.1, 0.5, 0.7],\n        [2.0, -2.0, 2.0, 2.0],\n    ])\n\n    mask = np.array([[1, 1, 0, 0], [1, 1, 1, 0]])\n\n    epsilon = 0.1\n\n    clipped_probab_ratios = np.array([\n        [1.1, 1.1, 0.9, 0.9],\n        [1.1, 1.1, 0.9, 1.0],\n    ])\n\n    unused_advantages_x_probab_ratios = np.array([\n        [0.15, -0.2, 0.25, 0.49],\n        [5.00, -4.0, 0.20, 2.00]\n    ])\n\n    unused_advantages_x_clipped_probab_ratios = np.array([\n        [0.11, -0.11, 0.45, 0.63],\n        [2.20, -2.20, .80, 2.00]\n    ])\n\n    unused_minimums = np.array([\n        [0.11, -0.2, 0.25, 0.49],\n        [2.20, -4.0, 0.20, 2.00]\n    ])\n\n    # minimums * mask\n    objective = np.array([\n        [0.11, -0.2, 0.0, 0.],\n        [2.20, -4.0, 0.2, 0.]\n    ])\n\n    # Assert that we computed things correctly in this test.\n    self.assertAllClose(\n        np.minimum(probab_ratios * advantages,\n                   clipped_probab_ratios * advantages) * mask,\n        objective)\n\n    self.assertAllClose(\n        objective,\n        ppo.clipped_objective(probab_ratios, advantages, mask, epsilon))\n\n  def test_combined_loss(self):\n    B, T, C, A, OBS = 2, 10, 1, 2, (28, 28, 3)  # pylint: disable=invalid-name\n\n    make_net = lambda: policy_based_utils.policy_and_value_net(  # pylint: disable=g-long-lambda\n        bottom_layers_fn=lambda: [layers.Flatten(n_axes_to_keep=2)],\n        observation_space=gym.spaces.Box(shape=OBS, low=0, high=1),\n        action_space=gym.spaces.Discrete(A),\n        vocab_size=None,\n        two_towers=True,\n    )[0]\n    net = make_net()\n\n    observations = np.random.uniform(size=(B, T + 1) + OBS)\n    actions = np.random.randint(0, A, size=(B, T, C))\n    input_signature = shapes.signature((observations, actions))\n    old_params, _ = net.init(input_signature)\n    new_params, state = make_net().init(input_signature)\n\n    # Generate a batch of observations.\n\n    rewards = np.random.uniform(0, 1, size=(B, T))\n    mask = np.ones_like(rewards)\n\n    # Just test that this computes at all.\n    (new_log_probabs, value_predictions_new) = (\n        net((observations, actions), weights=new_params, state=state))\n    (old_log_probabs, value_predictions_old) = (\n        net((observations, actions), weights=old_params, state=state))\n\n    gamma = 0.99\n    lambda_ = 0.95\n    epsilon = 0.2\n    value_weight = 1.0\n    entropy_weight = 0.01\n\n    nontrainable_params = {\n        \'gamma\': gamma,\n        \'lambda\': lambda_,\n        \'epsilon\': epsilon,\n        \'value_weight\': value_weight,\n        \'entropy_weight\': entropy_weight,\n    }\n\n    (value_loss_1, _) = ppo.value_loss_given_predictions(\n        value_predictions_new, rewards, mask, gamma=gamma,\n        value_prediction_old=value_predictions_old, epsilon=epsilon)\n    (ppo_loss_1, _) = ppo.ppo_loss_given_predictions(\n        new_log_probabs[:, :-1],\n        old_log_probabs[:, :-1],\n        value_predictions_old,\n        actions,\n        rewards,\n        mask,\n        gamma=gamma,\n        lambda_=lambda_,\n        epsilon=epsilon)\n\n    (combined_loss, (ppo_loss_2, value_loss_2, entropy_bonus), _, state) = (\n        ppo.combined_loss(new_params,\n                          old_log_probabs[:, :-1],\n                          value_predictions_old,\n                          net,\n                          observations,\n                          actions,\n                          rewards,\n                          mask,\n                          nontrainable_params=nontrainable_params,\n                          state=state)\n    )\n\n    # Test that these compute at all and are self consistent.\n    self.assertGreater(entropy_bonus, 0.0)\n    self.assertNear(value_loss_1, value_loss_2, 1e-5)\n    self.assertNear(ppo_loss_1, ppo_loss_2, 1e-5)\n    self.assertNear(\n        combined_loss,\n        ppo_loss_2 + (value_weight * value_loss_2) -\n        (entropy_weight * entropy_bonus),\n        1e-5\n    )\n\n  def test_masked_entropy(self):\n    # (2, 4+1, 4)\n    log_probs = np.array([[\n        [np.log(0.1), np.log(0.2), np.log(0.6), np.log(0.1)],\n        [np.log(0.4), np.log(0.1), np.log(0.4), np.log(0.1)],\n        [np.log(0.3), np.log(0.1), np.log(0.5), np.log(0.1)],\n        [np.log(0.1), np.log(0.2), np.log(0.6), np.log(0.1)],\n        [np.log(0.3), np.log(0.1), np.log(0.5), np.log(0.1)],\n    ], [\n        [np.log(0.3), np.log(0.1), np.log(0.5), np.log(0.1)],\n        [np.log(0.1), np.log(0.1), np.log(0.4), np.log(0.4)],\n        [np.log(0.3), np.log(0.1), np.log(0.5), np.log(0.1)],\n        [np.log(0.1), np.log(0.2), np.log(0.6), np.log(0.1)],\n        [np.log(0.3), np.log(0.1), np.log(0.5), np.log(0.1)],\n    ]])[:, :, None, :]\n\n    # (2, 4)\n    mask = np.array([\n        [1, 1, 0, 0, 0],\n        [1, 1, 1, 0, 0]\n    ])\n\n    def plp(p):\n      return p * np.log(p)\n\n    # Removing the last time-step and the masked stuff, gets us this.\n    filtered_log_probs = np.array([[\n        [plp(0.1), plp(0.2), plp(0.6), plp(0.1)],\n        [plp(0.4), plp(0.1), plp(0.4), plp(0.1)],\n        [plp(0.3), plp(0.1), plp(0.5), plp(0.1)],\n        [plp(0.1), plp(0.1), plp(0.4), plp(0.4)],\n        [plp(0.3), plp(0.1), plp(0.5), plp(0.1)],\n    ]])\n\n    self.assertNear(ppo.masked_entropy(log_probs, mask),\n                    -np.sum(filtered_log_probs) / 5.0,\n                    1e-6)\n\n  def test_shuffled_index_batches_generates_valid_batch(self):\n    dataset_size = 16\n    batch_size = 4\n    stream = ppo.shuffled_index_batches(dataset_size, batch_size)\n    batch = next(stream)\n    self.assertEqual(batch.shape, (batch_size,))\n    # Assert that all indices are different.\n    self.assertEqual(len(set(batch)), batch_size)\n\n  def test_shuffled_index_batches_generates_all_indices(self):\n    dataset_size = 16\n    batch_size = 4\n    stream = ppo.shuffled_index_batches(dataset_size, batch_size)\n    indices = np.reshape(\n        list(itertools.islice(stream, dataset_size // batch_size)), -1\n    )\n    self.assertEqual(set(indices), set(range(dataset_size)))\n\n  def test_shuffled_index_batches_gives_different_permutations(self):\n    dataset_size = 256\n    batch_size = 8\n    stream1 = ppo.shuffled_index_batches(dataset_size, batch_size)\n    stream2 = ppo.shuffled_index_batches(dataset_size, batch_size)\n    self.assertFalse(np.array_equal(next(stream1), next(stream2)))\n\n  def _make_log_prob_and_value_seqs(\n      self, log_probs, values, start_indices, n_symbols\n  ):\n    (batch_size, n_controls, n_actions) = log_probs.shape\n    log_prob_seq = np.zeros((batch_size, n_symbols * n_controls, n_actions))\n    value_seq = np.zeros((batch_size, n_symbols * n_controls))\n    for (x, x_seq) in ((log_probs, log_prob_seq), (values, value_seq)):\n      for (i, start_index) in enumerate(start_indices):\n        x_seq[i, start_index:(start_index + n_controls)] = x[i]\n    return (log_prob_seq, value_seq)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/ppo_trainer.py,16,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""PPO trainer.""""""\n\nimport functools\nimport time\n\nfrom absl import logging\nfrom jax import numpy as np\nfrom jax import random as jax_random\nfrom trax import models as trax_models\nfrom trax import optimizers as trax_opt\nfrom trax.rl import policy_based_trainer\nfrom trax.rl import policy_based_utils\nfrom trax.rl import ppo\n\nDEBUG_LOGGING = False\nGAMMA = 0.99\nLAMBDA = 0.95\nEPSILON = 0.1\nEPOCHS = 50  # 100\nN_OPTIMIZER_STEPS = 100\nPRINT_EVERY_OPTIMIZER_STEP = 20\nBATCH_TRAJECTORIES = 32\n\n\nclass PPO(policy_based_trainer.PolicyBasedTrainer):\n  """"""PPO trainer.""""""\n\n  def __init__(self,\n               train_env,\n               eval_env,\n               policy_and_value_model=trax_models.FrameStackMLP,\n               policy_and_value_optimizer=functools.partial(\n                   trax_opt.Adam, learning_rate=1e-3),\n               print_every_optimizer_steps=PRINT_EVERY_OPTIMIZER_STEP,\n               target_kl=0.01,\n               gamma=GAMMA,\n               lambda_=LAMBDA,\n               value_weight=1.0,\n               entropy_weight=0.01,\n               epsilon=0.1,\n               **kwargs):\n    """"""Creates the PPO trainer.\n\n    Args:\n      train_env: gym.Env to use for training.\n      eval_env: gym.Env to use for evaluation.\n      policy_and_value_model: Function defining the policy and value network,\n        without the policy and value heads.\n      policy_and_value_optimizer: Function defining the optimizer.\n      print_every_optimizer_steps: How often to log during the policy\n        optimization process.\n      target_kl: Policy iteration early stopping. Set to infinity to disable\n        early stopping.\n      gamma: Reward discount factor.\n      lambda_: N-step TD-error discount factor in GAE.\n      value_weight: Value loss coefficient.\n      entropy_weight: Entropy loss coefficient.\n      epsilon: Clipping coefficient.\n      **kwargs: Additional keyword arguments passed to the base class.\n    """"""\n    super(PPO, self).__init__(\n        train_env,\n        eval_env,\n        policy_and_value_model=policy_and_value_model,\n        policy_and_value_optimizer=policy_and_value_optimizer,\n        **kwargs)\n\n    self._print_every_optimizer_steps = print_every_optimizer_steps\n    self._target_kl = target_kl\n    self._nontrainable_params = {\n        \'gamma\': np.array(gamma),\n        \'lambda\': np.array(lambda_),\n        \'value_weight\': np.array(value_weight),\n        \'entropy_weight\': np.array(entropy_weight),\n        \'epsilon\': np.array(epsilon),\n    }\n\n  def collect_trajectories(self, train=True, **kwargs):\n    # We specialize this function to get a specific number of trajectories based\n    # on the environment\'s batch size.\n\n    env = self.train_env if train else self.eval_env\n    n_trajectories = env.batch_size\n\n    return super(PPO, self).collect_trajectories(\n        train=train, n_trajectories=n_trajectories, **kwargs)\n\n  def train_epoch(self, evaluate=True):\n    """"""Train one PPO epoch.""""""\n    epoch_start_time = time.time()\n\n    # Evaluate the policy.\n    policy_eval_start_time = time.time()\n    if evaluate and (self.epoch + 1) % self._eval_every_n == 0:\n      self.evaluate()\n\n    policy_eval_time = policy_based_utils.get_time(policy_eval_start_time)\n\n    trajectory_collection_start_time = time.time()\n    logging.vlog(1, \'PPO epoch [% 6d]: collecting trajectories.\', self.epoch)\n    key = self._get_rng()\n    trajs, _, timing_info, self._model_state = self.collect_trajectories(\n        train=True, temperature=1.0)\n    trajs = [(t[0], t[1], t[2], t[4]) for t in trajs]\n    self._should_reset_train_env = False\n    trajectory_collection_time = policy_based_utils.get_time(\n        trajectory_collection_start_time\n    )\n\n    logging.vlog(1, \'Collecting trajectories took %0.2f msec.\',\n                 trajectory_collection_time)\n\n    rewards = np.array([np.sum(traj[2]) for traj in trajs])\n    avg_reward = np.mean(rewards)\n    std_reward = np.std(rewards)\n    max_reward = np.max(rewards)\n    min_reward = np.min(rewards)\n\n    self._log(\'train\', \'train/reward_mean_truncated\', avg_reward)\n    if evaluate and not self._separate_eval:\n      metrics = {\'raw\': {1.0: {\'mean\': avg_reward, \'std\': std_reward}}}\n      policy_based_utils.write_eval_reward_summaries(\n          metrics, self._log, self.epoch\n      )\n\n    logging.vlog(1, \'Rewards avg=[%0.2f], max=[%0.2f], min=[%0.2f], all=%s\',\n                 avg_reward, max_reward, min_reward,\n                 [float(np.sum(traj[2])) for traj in trajs])\n\n    logging.vlog(1,\n                 \'Trajectory Length average=[%0.2f], max=[%0.2f], min=[%0.2f]\',\n                 float(sum(len(traj[0]) for traj in trajs)) / len(trajs),\n                 max(len(traj[0]) for traj in trajs),\n                 min(len(traj[0]) for traj in trajs))\n    logging.vlog(2, \'Trajectory Lengths: %s\', [len(traj[0]) for traj in trajs])\n\n    preprocessing_start_time = time.time()\n    (padded_observations, padded_actions, padded_rewards, reward_mask,\n     padded_infos) = self._preprocess_trajectories(trajs)\n    preprocessing_time = policy_based_utils.get_time(preprocessing_start_time)\n\n    logging.vlog(1, \'Preprocessing trajectories took %0.2f msec.\',\n                 policy_based_utils.get_time(preprocessing_start_time))\n    logging.vlog(1, \'Padded Observations\\\' shape [%s]\',\n                 str(padded_observations.shape))\n    logging.vlog(1, \'Padded Actions\\\' shape [%s]\', str(padded_actions.shape))\n    logging.vlog(1, \'Padded Rewards\\\' shape [%s]\', str(padded_rewards.shape))\n\n    # Some assertions.\n    (B, T) = reward_mask.shape  # pylint: disable=invalid-name\n    assert (B, T) == padded_rewards.shape\n    assert B == padded_observations.shape[0]\n\n    log_prob_recompute_start_time = time.time()\n    # TODO(pkozakowski): The following commented out code collects the network\n    # predictions made while stepping the environment and uses them in PPO\n    # training, so that we can use non-deterministic networks (e.g. with\n    # dropout). This does not work well with serialization, so instead we\n    # recompute all network predictions. Let\'s figure out a solution that will\n    # work with both serialized sequences and non-deterministic networks.\n\n    # assert (\'log_prob_actions\' in padded_infos and\n    #         \'value_predictions\' in padded_infos)\n    # These are the actual log-probabs and value predictions seen while picking\n    # the actions.\n    # actual_log_probabs_traj = padded_infos[\'log_prob_actions\']\n    # actual_value_predictions_traj = padded_infos[\'value_predictions\']\n\n    # assert (B, T, C) == actual_log_probabs_traj.shape[:3]\n    # A = actual_log_probabs_traj.shape[3]  # pylint: disable=invalid-name\n    # assert (B, T, 1) == actual_value_predictions_traj.shape\n\n    del padded_infos\n\n    # NOTE: We don\'t have the log-probabs and value-predictions for the last\n    # observation, so we re-calculate for everything, but use the original ones\n    # for all but the last time-step.\n    key = self._get_rng()\n\n    # TODO(pkozakowski): Pass the actual actions here, to enable autoregressive\n    # action sampling.\n    dummy_actions = np.zeros_like(padded_actions)\n    (log_probabs_traj, value_predictions_traj) = (\n        self._policy_and_value_net_apply(\n            (padded_observations, dummy_actions),\n            weights=self._policy_and_value_net_weights,\n            state=self._model_state,\n            rng=key,\n        ))\n    # Cut off the last extra action to obtain shape (B, T, C, A).\n    log_probabs_traj_cut = log_probabs_traj[:, :-1]\n\n    assert (B, T) == log_probabs_traj_cut.shape[:2]\n    assert (B, T + 1) == value_predictions_traj.shape\n\n    # TODO(pkozakowski): Commented out for the same reason as before.\n\n    # Concatenate the last time-step\'s log-probabs and value predictions to the\n    # actual log-probabs and value predictions and use those going forward.\n    # log_probabs_traj = np.concatenate(\n    #     (actual_log_probabs_traj, log_probabs_traj[:, -1:, :]), axis=1)\n    # value_predictions_traj = np.concatenate(\n    #     (actual_value_predictions_traj, value_predictions_traj[:, -1:, :]),\n    #     axis=1)\n\n    log_prob_recompute_time = policy_based_utils.get_time(\n        log_prob_recompute_start_time\n    )\n\n    # Compute value and ppo losses.\n    key1 = self._get_rng()\n    logging.vlog(2, \'Starting to compute P&V loss.\')\n    loss_compute_start_time = time.time()\n    (cur_combined_loss, component_losses, summaries, self._model_state) = (\n        ppo.combined_loss(\n            self._policy_and_value_net_weights,\n            log_probabs_traj_cut,\n            value_predictions_traj,\n            self._policy_and_value_net_apply,\n            padded_observations,\n            padded_actions,\n            padded_rewards,\n            reward_mask,\n            nontrainable_params=self._nontrainable_params,\n            state=self._model_state,\n            rng=key1))\n    loss_compute_time = policy_based_utils.get_time(loss_compute_start_time)\n    (cur_ppo_loss, cur_value_loss, cur_entropy_bonus) = component_losses\n    logging.vlog(\n        1,\n        \'Calculating P&V loss [%10.2f(%10.2f, %10.2f, %10.2f)] took %0.2f msec.\',\n        cur_combined_loss, cur_ppo_loss, cur_value_loss, cur_entropy_bonus,\n        policy_based_utils.get_time(loss_compute_start_time))\n\n    key1 = self._get_rng()\n    logging.vlog(1, \'Policy and Value Optimization\')\n    optimization_start_time = time.time()\n    keys = jax_random.split(key1, num=self._n_optimizer_steps)\n    opt_step = 0\n    opt_batch_size = min(self._optimizer_batch_size, B)\n    index_batches = ppo.shuffled_index_batches(\n        dataset_size=B, batch_size=opt_batch_size)\n    for (index_batch, key) in zip(index_batches, keys):\n      k1, k2, k3 = jax_random.split(key, num=3)\n      t = time.time()\n      # Update the optimizer state on the sampled minibatch.\n      self._policy_and_value_opt_state, self._model_state = (\n          ppo.policy_and_value_opt_step(\n              # We pass the optimizer slots between PPO epochs, so we need to\n              # pass the optimization step as well, so for example the\n              # bias-correction in Adam is calculated properly. Alternatively we\n              # could reset the slots and the step in every PPO epoch, but then\n              # the moment estimates in adaptive optimizers would never have\n              # enough time to warm up. So it makes sense to reuse the slots,\n              # even though we\'re optimizing a different loss in every new\n              # epoch.\n              self._total_opt_step,\n              self._policy_and_value_opt_state,\n              self._policy_and_value_opt_update,\n              self._policy_and_value_get_params,\n              self._policy_and_value_net_apply,\n              log_probabs_traj_cut[index_batch],\n              value_predictions_traj[index_batch],\n              padded_observations[index_batch],\n              padded_actions[index_batch],\n              padded_rewards[index_batch],\n              reward_mask[index_batch],\n              nontrainable_params=self._nontrainable_params,\n              state=self._model_state,\n              rng=k1))\n      opt_step += 1\n      self._total_opt_step += 1\n\n      # Compute the approx KL for early stopping. Use the whole dataset - as we\n      # only do inference, it should fit in the memory.\n      # TODO(pkozakowski): Pass the actual actions here, to enable\n      # autoregressive action sampling.\n      dummy_actions = np.zeros_like(padded_actions)\n      (log_probab_actions_new, _) = (\n          self._policy_and_value_net_apply(\n              (padded_observations, dummy_actions),\n              weights=self._policy_and_value_net_weights,\n              state=self._model_state,\n              rng=k2))\n      # Cut off the last extra action to obtain shape (B, T, C, A).\n      log_probab_actions_new_cut = log_probab_actions_new[:, :-1]\n\n      approx_kl = ppo.approximate_kl(log_probab_actions_new_cut,\n                                     log_probabs_traj_cut, reward_mask)\n\n      early_stopping = approx_kl > 1.5 * self._target_kl\n      if early_stopping:\n        logging.vlog(\n            1, \'Early stopping policy and value optimization after %d steps, \'\n            \'with approx_kl: %0.2f\', opt_step, approx_kl)\n        # We don\'t return right-away, we want the below to execute on the last\n        # iteration.\n\n      t2 = time.time()\n      if (opt_step % self._print_every_optimizer_steps == 0 or\n          opt_step == self._n_optimizer_steps or early_stopping):\n        # Compute and log the loss.\n        (combined_loss, component_losses, _, self._model_state) = (\n            ppo.combined_loss(\n                self._policy_and_value_net_weights,\n                log_probabs_traj_cut,\n                value_predictions_traj,\n                self._policy_and_value_net_apply,\n                padded_observations,\n                padded_actions,\n                padded_rewards,\n                reward_mask,\n                nontrainable_params=self._nontrainable_params,\n                state=self._model_state,\n                rng=k3))\n        logging.vlog(1, \'One Policy and Value grad desc took: %0.2f msec\',\n                     policy_based_utils.get_time(t, t2))\n        (ppo_loss, value_loss, entropy_bonus) = component_losses\n        logging.vlog(\n            1, \'Combined Loss(value, ppo, entropy_bonus) [%10.2f] ->\'\n            \' [%10.2f(%10.2f,%10.2f,%10.2f)]\', cur_combined_loss, combined_loss,\n            ppo_loss, value_loss, entropy_bonus)\n\n      if early_stopping:\n        break\n\n    optimization_time = policy_based_utils.get_time(optimization_start_time)\n\n    logging.vlog(\n        1, \'Total Combined Loss reduction [%0.2f]%%\',\n        (100 * (cur_combined_loss - combined_loss) / np.abs(cur_combined_loss)))\n\n    summaries.update({\n        \'n_optimizer_steps\': opt_step,\n        \'approx_kl\': approx_kl,\n    })\n    for (name, value) in summaries.items():\n      self._log(\'train\', \'train/{}\'.format(name), value)\n\n    logging.info(\n        \'PPO epoch [% 6d], Reward[min, max, avg] [%5.2f,%5.2f,%5.2f], Combined\'\n        \' Loss(ppo, value, entropy) [%2.5f(%2.5f,%2.5f,%2.5f)]\', self.epoch,\n        min_reward, max_reward, avg_reward, combined_loss, ppo_loss, value_loss,\n        entropy_bonus)\n\n    # Bump the epoch counter before saving a checkpoint, so that a call to\n    # save() after the training loop is a no-op if a checkpoint was saved last\n    # epoch - otherwise it would bump the epoch counter on the checkpoint.\n    last_epoch = self.epoch\n    self._epoch += 1\n\n    epoch_time = policy_based_utils.get_time(epoch_start_time)\n\n    timing_dict = {\n        \'epoch\': epoch_time,\n        \'policy_eval\': policy_eval_time,\n        \'trajectory_collection\': trajectory_collection_time,\n        \'preprocessing\': preprocessing_time,\n        \'log_prob_recompute\': log_prob_recompute_time,\n        \'loss_compute\': loss_compute_time,\n        \'optimization\': optimization_time,\n    }\n\n    timing_dict.update(timing_info)\n\n    if self._should_write_summaries:\n      for k, v in timing_dict.items():\n        self._timing_sw.scalar(\'timing/%s\' % k, v, step=last_epoch)\n\n    max_key_len = max(len(k) for k in timing_dict)\n    timing_info_list = [\n        \'%s : % 10.2f\' % (k.rjust(max_key_len + 1), v)\n        for k, v in sorted(timing_dict.items())\n    ]\n    logging.info(\'PPO epoch [% 6d], Timings: \\n%s\', last_epoch,\n                 \'\\n\'.join(timing_info_list))\n\n    # Flush summary writers once in a while.\n    if self.epoch % 1000 == 0:\n      self.flush_summaries()\n\n  def evaluate(self):\n    """"""Evaluate the agent.""""""\n    if not self._separate_eval:\n      return\n\n    logging.vlog(1, \'PPO epoch [% 6d]: evaluating policy.\', self.epoch)\n\n    if self._controller is not None:\n      ntp_updates = self._controller(self._history)(self.epoch)\n      self._nontrainable_params.update(ntp_updates)\n      (_, _, opt_params) = self._policy_and_value_opt_state\n      opt_params.update(ntp_updates)\n      for (name, value) in self._nontrainable_params.items():\n        self._log(\'train\', \'training/{}\'.format(name), value)\n\n    super(PPO, self).evaluate()\n'"
trax/rl/ppo_trainer_test.py,14,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.rl.ppo\'s training_loop.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport contextlib\nimport functools\nimport itertools\nimport os\nimport tempfile\n\nfrom absl.testing import parameterized\nimport gin\nimport gym\nimport numpy as np\n\nfrom tensor2tensor.envs import gym_env_problem\nfrom tensor2tensor.rl import gym_utils\nfrom tensorflow import test\nfrom tensorflow.compat.v1.io import gfile\nfrom trax import layers\nfrom trax import lr_schedules as lr\nfrom trax import math\nfrom trax import models\nfrom trax import optimizers as trax_opt\nfrom trax.rl import envs  # pylint: disable=unused-import\nfrom trax.rl import ppo_trainer\nfrom trax.rl import serialization_utils\nfrom trax.rl import simulated_env_problem\nfrom trax.rl import space_serializer\nfrom trax.supervised import inputs as trax_inputs\nfrom trax.supervised import trainer_lib\n\n\nclass PpoTrainerTest(parameterized.TestCase):\n\n  def get_wrapped_env(\n      self, name=\'CartPole-v0\', max_episode_steps=2, batch_size=1\n  ):\n    wrapper_fn = functools.partial(\n        gym_utils.gym_env_wrapper,\n        **{\n            \'rl_env_max_episode_steps\': max_episode_steps,\n            \'maxskip_env\': False,\n            \'rendered_env\': False,\n            \'rendered_env_resize_to\': None,  # Do not resize frames\n            \'sticky_actions\': False,\n            \'output_dtype\': None,\n            \'num_actions\': None,\n        })\n\n    return gym_env_problem.GymEnvProblem(base_env_name=name,\n                                         batch_size=batch_size,\n                                         env_wrapper_fn=wrapper_fn,\n                                         discrete_rewards=False)\n\n  @contextlib.contextmanager\n  def tmp_dir(self):\n    tmp = tempfile.mkdtemp()\n    yield tmp\n    gfile.rmtree(tmp)\n\n  def _make_trainer(\n      self, train_env, eval_env, output_dir, model=None, **kwargs):\n    if model is None:\n      model = lambda: layers.Serial(layers.Dense(1))\n    return ppo_trainer.PPO(\n        train_env=train_env,\n        eval_env=eval_env,\n        policy_and_value_model=model,\n        n_optimizer_steps=1,\n        output_dir=output_dir,\n        random_seed=0,\n        max_timestep=3,\n        boundary=2,\n        save_every_n=1,\n        **kwargs\n    )\n\n  def test_training_loop_cartpole(self):\n    with self.tmp_dir() as output_dir:\n      trainer = self._make_trainer(\n          train_env=self.get_wrapped_env(\'CartPole-v0\', 2),\n          eval_env=self.get_wrapped_env(\'CartPole-v0\', 2),\n          output_dir=output_dir,\n      )\n      trainer.training_loop(n_epochs=2)\n\n  def test_training_loop_cartpole_transformer(self):\n    with self.tmp_dir() as output_dir:\n      trainer = self._make_trainer(\n          train_env=self.get_wrapped_env(\'CartPole-v0\', 2),\n          eval_env=self.get_wrapped_env(\'CartPole-v0\', 2),\n          output_dir=output_dir,\n          model=functools.partial(\n              models.TransformerDecoder,\n              d_model=1,\n              d_ff=1,\n              n_layers=1,\n              n_heads=1,\n              max_len=128,\n              mode=\'train\',\n          ),\n      )\n      trainer.training_loop(n_epochs=2)\n\n  def test_training_loop_onlinetune(self):\n    with self.tmp_dir() as output_dir:\n      gin.bind_parameter(\'OnlineTuneEnv.model\', functools.partial(\n          models.MLP,\n          n_hidden_layers=0,\n          n_output_classes=1,\n      ))\n      gin.bind_parameter(\'OnlineTuneEnv.inputs\', functools.partial(\n          trax_inputs.random_inputs,\n          input_shape=(1, 1),\n          input_dtype=np.float32,\n          output_shape=(1, 1),\n          output_dtype=np.float32,\n      ))\n      gin.bind_parameter(\'OnlineTuneEnv.train_steps\', 1)\n      gin.bind_parameter(\'OnlineTuneEnv.eval_steps\', 1)\n      gin.bind_parameter(\n          \'OnlineTuneEnv.output_dir\', os.path.join(output_dir, \'envs\'))\n      trainer = self._make_trainer(\n          train_env=self.get_wrapped_env(\'OnlineTuneEnv-v0\', 1),\n          eval_env=self.get_wrapped_env(\'OnlineTuneEnv-v0\', 1),\n          output_dir=output_dir,\n      )\n      trainer.training_loop(n_epochs=1)\n\n  def test_training_loop_simulated(self):\n    n_actions = 5\n    history_shape = (3, 2, 3)\n    action_shape = (3,)\n    obs_shape = (3, 3)\n    reward_shape = (3, 1)\n\n    def model(mode):\n      del mode\n      return layers.Serial(\n          layers.Parallel(\n              layers.Flatten(),  # Observation stack.\n              layers.Embedding(d_feature=1, vocab_size=n_actions),  # Action.\n          ),\n          layers.Concatenate(),\n          layers.Dense(n_units=1),\n          layers.Dup(),\n          layers.Parallel(\n              layers.Dense(n_units=obs_shape[1]),  # New observation.\n              None,  # Reward.\n          )\n      )\n\n    stream = itertools.repeat(\n        (np.zeros(history_shape), np.zeros(action_shape, dtype=np.int32),\n         np.zeros(obs_shape), np.zeros(reward_shape))\n    )\n    inp = trax_inputs.Inputs(lambda _: stream)\n    inp._input_shape = (history_shape[1:], action_shape[1:])\n    inp._input_dtype = (np.float32, np.int32)\n    inp._target_shape = (obs_shape[1:], reward_shape[1:])\n    inp._target_dtype = (np.float32, np.float32)\n    inputs = inp\n\n    def loss():\n      """"""Cross-entropy loss as scalar compatible with Trax masking.""""""\n      ones = layers.Fn(\'Ones\', lambda x: math.numpy.ones_like(x))  # pylint: disable=unnecessary-lambda\n      return layers.Serial(\n          # Swap from (pred-obs, pred-reward, target-obs, target-reward)\n          # to (pred-obs, target-obs, pred-reward, target-reward).\n          layers.Parallel([], layers.Swap()),\n          # Duplicate target-obs and target-reward and make 1 to add weights.\n          layers.Parallel([], layers.Branch([], ones)),\n          layers.Parallel([], [], [], [], layers.Branch([], ones)),\n          # Cross-entropy loss for obs, L2 loss on reward.\n          layers.Parallel(layers.CrossEntropyLoss(),\n                          layers.L2Loss()),\n          # Add both losses.\n          layers.Add(),\n          # Zero out in this test.\n          layers.Fn(\'TimesZero\', lambda x: x * 0.0),\n      )\n\n    with self.tmp_dir() as output_dir:\n      # Run fake training just to save the parameters.\n      trainer = trainer_lib.Trainer(\n          model=model,\n          loss_fn=loss(),\n          inputs=inputs,\n          optimizer=trax_opt.SM3,\n          lr_schedule=lr.MultifactorSchedule,\n          output_dir=output_dir,\n      )\n      trainer.train_epoch(n_steps=1, n_eval_steps=1)\n\n      # Repeat the history over and over again.\n      stream = itertools.repeat(np.zeros(history_shape))\n      env_fn = functools.partial(\n          simulated_env_problem.RawSimulatedEnvProblem,\n          model=model,\n          history_length=history_shape[1],\n          trajectory_length=3,\n          batch_size=history_shape[0],\n          observation_space=gym.spaces.Box(\n              low=-np.inf, high=np.inf, shape=(obs_shape[1],)),\n          action_space=gym.spaces.Discrete(n=n_actions),\n          reward_range=(-1, 1),\n          discrete_rewards=False,\n          history_stream=stream,\n          output_dir=output_dir,\n      )\n\n      trainer = self._make_trainer(\n          train_env=env_fn(),\n          eval_env=env_fn(),\n          output_dir=output_dir,\n      )\n      trainer.training_loop(n_epochs=2)\n\n  def test_restarts(self):\n    with self.tmp_dir() as output_dir:\n      train_env = self.get_wrapped_env(\'CartPole-v0\', 2)\n      eval_env = self.get_wrapped_env(\'CartPole-v0\', 2)\n\n      # Train for 1 epoch and save.\n      trainer = self._make_trainer(\n          train_env=train_env,\n          eval_env=eval_env,\n          output_dir=output_dir,\n      )\n      self.assertEqual(trainer.epoch, 0)\n      trainer.training_loop(n_epochs=1)\n      self.assertEqual(trainer.epoch, 1)\n\n      # Initialize with the same `output_dir`.\n      trainer = self._make_trainer(\n          train_env=train_env,\n          eval_env=eval_env,\n          output_dir=output_dir,\n      )\n      # reset the trainer manually and check that it initializes.\n      trainer.reset()\n      self.assertEqual(trainer.epoch, 1)\n      # Check that we can continue training from the restored checkpoint.\n      trainer.training_loop(n_epochs=2)\n      self.assertEqual(trainer.epoch, 2)\n\n  def test_training_loop_multi_control(self):\n    gym.register(\n        \'FakeEnv-v0\',\n        entry_point=\'trax.rl.envs.fake_env:FakeEnv\',\n        kwargs={\'n_actions\': 3, \'n_controls\': 2},\n    )\n    with self.tmp_dir() as output_dir:\n      trainer = self._make_trainer(\n          train_env=self.get_wrapped_env(\'FakeEnv-v0\', 2),\n          eval_env=self.get_wrapped_env(\'FakeEnv-v0\', 2),\n          output_dir=output_dir,\n      )\n      trainer.training_loop(n_epochs=2)\n\n  def test_training_loop_cartpole_serialized(self):\n    gin.bind_parameter(\'BoxSpaceSerializer.precision\', 1)\n    with self.tmp_dir() as output_dir:\n      trainer = self._make_trainer(\n          train_env=self.get_wrapped_env(\'CartPole-v0\', 2),\n          eval_env=self.get_wrapped_env(\'CartPole-v0\', 2),\n          output_dir=output_dir,\n          model=functools.partial(\n              models.TransformerDecoder,\n              d_model=1,\n              d_ff=1,\n              n_layers=1,\n              n_heads=1,\n              max_len=1024,\n              mode=\'train\',\n          ),\n          policy_and_value_vocab_size=4,\n      )\n      trainer.training_loop(n_epochs=2)\n\n  @parameterized.named_parameters((\'two_towers\', True), (\'one_tower\', False))\n  def test_training_loop_cartpole_serialized_init_from_world_model(\n      self, two_towers\n  ):\n    gin.bind_parameter(\'BoxSpaceSerializer.precision\', 1)\n\n    transformer_kwargs = {\n        \'d_model\': 1,\n        \'d_ff\': 1,\n        \'n_layers\': 1,\n        \'n_heads\': 1,\n        \'max_len\': 128,\n    }\n    obs_serializer = space_serializer.create(\n        gym.spaces.MultiDiscrete([2, 2]), vocab_size=4\n    )\n    act_serializer = space_serializer.create(\n        gym.spaces.Discrete(2), vocab_size=4\n    )\n    model_fn = lambda mode: serialization_utils.SerializedModel(  # pylint: disable=g-long-lambda\n        seq_model=models.TransformerLM(\n            mode=mode, vocab_size=4, **transformer_kwargs\n        ),\n        observation_serializer=obs_serializer,\n        action_serializer=act_serializer,\n        significance_decay=0.9,\n    )\n    with self.tmp_dir() as output_dir:\n      model_dir = os.path.join(output_dir, \'model\')\n\n      def dummy_stream(_):\n        while True:\n          obs = np.zeros((1, 2, 2), dtype=np.int32)\n          act = np.zeros((1, 1), dtype=np.int32)\n          mask = np.ones_like(obs)\n          yield (obs, act, obs, mask)\n\n      inputs = trax_inputs.Inputs(\n          train_stream=dummy_stream, eval_stream=dummy_stream\n      )\n      inputs._input_shape = ((2, 2), (1,))  # pylint: disable=protected-access\n      inputs._input_dtype = (np.int32, np.int32)  # pylint: disable=protected-access\n\n      # Initialize a world model checkpoint by running the trainer.\n      trainer_lib.train(\n          model_dir,\n          model=model_fn,\n          inputs=inputs,\n          steps=1,\n          eval_steps=1,\n      )\n\n      policy_dir = os.path.join(output_dir, \'policy\')\n      trainer = self._make_trainer(\n          train_env=self.get_wrapped_env(\'CartPole-v0\', 2),\n          eval_env=self.get_wrapped_env(\'CartPole-v0\', 2),\n          output_dir=policy_dir,\n          model=functools.partial(\n              models.TransformerDecoder, **transformer_kwargs\n          ),\n          policy_and_value_vocab_size=4,\n          init_policy_from_world_model_output_dir=model_dir,\n          policy_and_value_two_towers=two_towers,\n      )\n      trainer.training_loop(n_epochs=2)\n\n  def test_training_loop_cartpole_minibatch(self):\n    with self.tmp_dir() as output_dir:\n      trainer = self._make_trainer(\n          train_env=self.get_wrapped_env(\'CartPole-v0\', 2, batch_size=4),\n          eval_env=self.get_wrapped_env(\'CartPole-v0\', 2),\n          output_dir=output_dir,\n          optimizer_batch_size=2,\n      )\n      trainer.training_loop(n_epochs=2)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/rl_layers.py,15,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""A number of RL functions intended to be later wrapped as Trax layers.\n\n  Wrapping happens with help of the function tl.Fn.\n""""""\n\nfrom trax.math import numpy as jnp\n\n\ndef ValueLoss(values, returns, value_loss_coeff):\n  """"""Definition of the loss of the value function.""""""\n  advantages = returns - values\n  l2_value_loss = jnp.mean(advantages**2) * value_loss_coeff\n  return l2_value_loss\n\n\ndef ExplainedVariance(values, returns):\n  """"""Definition of explained variance - an approach from OpenAI baselines.""""""\n  assert returns.shape == values.shape, (\n      f\'returns.shape was {returns.shape} and values.shape was {values.shape}\')\n  # TODO(henrykm): it would be good to explain the relation with the time dim.\n  returns_variance = jnp.var(returns)\n  explained_variance = 1 - jnp.var(returns-values)/returns_variance\n  return explained_variance\n\n\ndef PreferredMove(dist_inputs, sample):\n  """"""Definition of the preferred move.""""""\n  preferred_moves = sample(dist_inputs, temperature=0.0)\n  return jnp.mean(preferred_moves)\n\n\ndef NewLogProbs(dist_inputs, actions, log_prob_fun):\n  """"""Given distribution and actions calculate log probs.""""""\n  new_log_probs = log_prob_fun(dist_inputs,\n                               actions)\n  return new_log_probs\n\n\n# TODO(henrykm): Clarify how jnp.mean is applied.\ndef EntropyLoss(dist_inputs, actions, log_prob_fun,\n                entropy_coeff, entropy_fun):\n  """"""Definition of the Entropy Layer.""""""\n  new_log_probs = NewLogProbs(dist_inputs, actions, log_prob_fun)\n  entropy_loss = entropy_fun(new_log_probs) * entropy_coeff\n  return jnp.mean(entropy_loss)\n\n\ndef ProbsRatio(dist_inputs, actions, old_log_probs, log_prob_fun):\n  """"""Probability Ratio from the PPO algorithm.""""""\n  # dist_inputs of the shape float32[128,1,18]\n  # actions of the shape int32[128,1]\n  # and old_log_probs of the shape float32[128,1]\n  new_log_probs = NewLogProbs(dist_inputs, actions, log_prob_fun)\n  assert new_log_probs.shape == old_log_probs.shape, (\n      f\'new_log_probs.shape was {new_log_probs.shape} and\'\n      f\'old_log_probs.shape was {old_log_probs.shape}\')\n  # The ratio between new_probs and old_probs expressed\n  # using log_probs and exponentaion\n  probs_ratio = jnp.exp(new_log_probs - old_log_probs)\n  return probs_ratio\n\n\ndef ApproximateKLDivergence(dist_inputs, actions, old_log_probs, log_prob_fun):\n  """"""Probability Ratio from the PPO algorithm.""""""\n  new_log_probs = NewLogProbs(dist_inputs, actions, log_prob_fun)\n  assert new_log_probs.shape == old_log_probs.shape, (\n      f\'new_log_probs.shape was {new_log_probs.shape} and\'\n      f\'old_log_probs.shape was {old_log_probs.shape}\')\n  approximate_kl_divergence = 0.5 * \\\n      jnp.mean(new_log_probs - old_log_probs) ** 2\n  return approximate_kl_divergence\n\n\ndef UnclippedObjective(probs_ratio, advantages):\n  """"""Unclipped Objective from the PPO algorithm.""""""\n  assert probs_ratio.shape == advantages.shape, (\n      f\'probs_ratio.shape was {probs_ratio.shape} and\'\n      f\'advantages.shape was {advantages.shape}\')\n  unclipped_objective = probs_ratio * advantages\n  return unclipped_objective\n\n\ndef ClippedObjective(probs_ratio, advantages, epsilon):\n  """"""Clipped Objective from the PPO algorithm.""""""\n  assert probs_ratio.shape == advantages.shape, (\n      f\'probs_ratio.shape was {probs_ratio.shape} and\'\n      f\'advantages.shape was {advantages.shape}\')\n  clipped_objective = jnp.clip(probs_ratio, 1 - epsilon,\n                               1 + epsilon) * advantages\n  assert probs_ratio.shape == clipped_objective.shape, (\n      f\'probs_ratio.shape was {probs_ratio.shape} and\'\n      f\'clipped_objective.shape was {clipped_objective.shape}\')\n  return clipped_objective\n\n\ndef PPOObjective(dist_inputs, values, returns, actions, old_log_probs,\n                 log_prob_fun, epsilon, normalize_advantages):\n  """"""PPO Objective.""""""\n  # dist_inputs of the shape float32[128,1,18]\n  # values of the shape float32[128,1,1]\n  # returns of the shape float32[128,1,1]\n  # actions of the shape int32[128,1]\n  # and old_log_probs of the shape float32[128,1]\n  returns = returns.squeeze(axis=2)\n  values = values.squeeze(axis=2)\n  assert returns.shape == values.shape, (\n      f\'returns.shape was {returns.shape} and values.shape was {values.shape}\')\n  assert returns.shape == old_log_probs.shape, (\n      f\'returns.shape was {returns.shape} and\'\n      f\'old_log_probs.shape was {old_log_probs.shape}\')\n\n  probs_ratio = ProbsRatio(dist_inputs, actions, old_log_probs, log_prob_fun)\n  assert probs_ratio.shape == old_log_probs.shape, (\n      f\'probs_ratio.shape was {probs_ratio.shape} and\'\n      f\'old_log_probs.shape was {old_log_probs.shape}\')\n\n  advantages = returns - values\n  if normalize_advantages:\n    advantages = advantages - jnp.mean(advantages)\n    advantages /= jnp.std(advantages) + 1e-8\n  assert old_log_probs.shape == advantages.shape, (\n      f\'old_log_probs.shape was {old_log_probs.shape} and advantages.shape was \'\n      f\'{advantages.shape}\')\n\n  unclipped_objective = UnclippedObjective(probs_ratio, advantages)\n  assert unclipped_objective.shape == advantages.shape, (\n      f\'old_log_probs.shape was {old_log_probs.shape} and\'\n      f\'unclipped_objective.shape was {unclipped_objective.shape}\')\n\n  clipped_objective = ClippedObjective(probs_ratio, advantages, epsilon)\n  assert clipped_objective.shape == advantages.shape, (\n      f\'old_log_probs.shape was {old_log_probs.shape} and\'\n      f\'clipped_objective.shape was {clipped_objective.shape}\')\n\n  ppo_objective = jnp.minimum(unclipped_objective, clipped_objective)\n  assert ppo_objective.shape == advantages.shape, (\n      f\'old_log_probs.shape was {old_log_probs.shape} and\'\n      f\'ppo_objective.shape was {ppo_objective.shape}\')\n\n  return ppo_objective\n\n\ndef A2CObjective(dist_inputs, values, returns,\n                 actions, mask, log_prob_fun, normalize_advantages):\n  """"""Definition of the Advantage Actor Critic (A2C) loss.""""""\n  # dist_inputs of the shape float32[128,1,18]\n  # values of the shape float32[128,1,1]\n  # returns of the shape float32[128,1,1]\n  # actions of the shape int32[128,1]\n  # and mask of the shape float32[128,1]\n  # We have to squeeze values and returns, because we\n  # are planning to compute (return - values) * new_log_probs * mask\n  # and all of them should be of the same dimension\n  values = values.squeeze(axis=2)\n  returns = returns.squeeze(axis=2)\n\n  assert returns.shape == values.shape, (\n      f\'returns.shape was {returns.shape} and values.shape was {values.shape}\')\n  assert values.shape == mask.shape, (\n      f\'values.shape was {values.shape} and mask.shape was {mask.shape}\')\n  assert returns.shape[0] == dist_inputs.shape[0], (\n      f\'returns.shape[0] was {returns.shape[0]} and dist_inputs.shape[0] was \'\n      f\'{dist_inputs.shape[0]}\')\n\n  new_log_probs = NewLogProbs(dist_inputs, actions, log_prob_fun)\n  assert new_log_probs.shape == mask.shape, (\n      f\'new_log_probs.shape was {new_log_probs.shape} and mask.shape was \'\n      f\'{mask.shape}\')\n\n  advantages = returns - values\n  if normalize_advantages:\n    advantages = advantages - jnp.mean(advantages)\n    advantages /= jnp.std(advantages) + 1e-8\n  assert new_log_probs.shape == advantages.shape, (\n      f\'new_log_probs.shape was {new_log_probs.shape} and advantages.shape was \'\n      f\'{advantages.shape}\')\n\n  # One of the motivation to the squeezes and assertions is to\n  # avoid [128,1] * [128,1,1] * [128] multiplications in the definition\n  # of the a2c objective - we insist on the same shapes\n  a2c_objective = -jnp.sum(new_log_probs * advantages * mask) / jnp.sum(mask)\n  return a2c_objective\n'"
trax/rl/serialization_utils.py,14,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Utilities for serializing trajectories into discrete sequences.""""""\n\nimport functools\n\nimport gym\nimport numpy as np\n\nfrom trax import layers as tl\nfrom trax.math import numpy as jnp\nfrom trax.rl import space_serializer\n\n\n# pylint: disable=invalid-name\n# TODO(pkozakowski): Move the layers to trax.layers and remove this module.\ndef Serialize(serializer):\n  """"""Layer that serializes a given array.""""""\n  def serialize(x):\n    (batch_size, length) = x.shape[:2]\n    shape_suffix = x.shape[2:]\n    x = jnp.reshape(x, (batch_size * length,) + shape_suffix)\n    x = serializer.serialize(x)\n    return jnp.reshape(x, (batch_size, -1, serializer.representation_length,))\n  return tl.Fn(\'Serialize\', serialize)\n\n\ndef Interleave():\n  """"""Layer that interleaves and flattens two serialized sequences.\n\n  The first sequence can be longer by 1 than the second one. This is so we can\n  interleave sequences of observations and actions, when there\'s 1 extra\n  observation at the end.\n\n  For serialized sequences [[x_1_1, ..., x_1_R1], ..., [x_L1_1, ..., x_L1_R1]]\n  and [[y_1_1, ..., y_1_R2], ..., [y_L2_1, ..., y_L2_R2]], where L1 = L2 + 1,\n  the result is [x_1_1, ..., x_1_R1, y_1_1, ..., y_1_R2, ..., x_L2_1, ...,\n  x_L2_R1, y_L2_1, ..., y_L2_R2, x_L1_1, ..., x_L1_R1] (batch dimension omitted\n  for clarity).\n\n  The layer inputs are a sequence pair of shapes (B, L1, R1) and (B, L2, R2),\n  where B is batch size, L* is the length of the sequence and R* is the\n  representation length of each element in the sequence.\n\n  Returns:\n    Layer that interleaves sequence of shape (B, L1 * R1 + L2 * R2).\n  """"""\n  def interleave(x, y):\n    (batch_size, _, _) = x.shape\n    (_, length, _) = y.shape\n    assert x.shape[1] in (length, length + 1)\n\n    reprs = jnp.concatenate((x[:, :length], y), axis=2)\n    reprs = jnp.reshape(reprs, (batch_size, -1))\n    remainder = jnp.reshape(x[:, length:], (batch_size, -1))\n    return jnp.concatenate((reprs, remainder), axis=1)\n  return tl.Fn(\'Interleave\', interleave)\n\n\ndef Deinterleave(x_size, y_size):\n  """"""Layer that does the inverse of Interleave.""""""\n  def deinterleave(inputs):\n    reprs = inputs\n    (batch_size, length) = reprs.shape[:2]\n    shape_suffix = reprs.shape[2:]\n    remainder_length = length % (x_size + y_size)\n    if remainder_length > 0:\n      remainder = reprs[:, None, -remainder_length:]\n      reprs = reprs[:, :-remainder_length]\n    reprs = jnp.reshape(reprs, (batch_size, -1, x_size + y_size) + shape_suffix)\n    x_reprs = reprs[:, :, :x_size]\n    y_reprs = reprs[:, :, x_size:]\n    if remainder_length > 0:\n      x_reprs = jnp.concatenate((x_reprs, remainder), axis=1)\n    return (x_reprs, y_reprs)\n  return tl.Fn(\'Deinterleave\', deinterleave, n_out=2)\n\n\ndef RepresentationMask(serializer):\n  """"""Upsamples a mask to cover the serialized representation.""""""\n  # Trax enforces the mask to be of the same size as the target. Get rid of the\n  # extra dimensions.\n  def representation_mask(mask):\n    mask = jnp.amax(mask, axis=tuple(range(2, mask.ndim)))\n    return jnp.broadcast_to(\n        mask[:, :, None], mask.shape + (serializer.representation_length,)\n    )\n  return tl.Fn(\'RepresentationMask\', representation_mask)\n\n\ndef SignificanceWeights(serializer, decay):\n  """"""Multiplies a binary mask with a symbol significance mask.""""""\n  def significance_weights(mask):\n    # (repr,) -> (batch, length, repr)\n    significance = serializer.significance_map[None, None]\n    return mask * decay ** jnp.broadcast_to(significance, mask.shape)\n  return tl.Fn(\'SignificanceWeights\', significance_weights)\n\n\ndef SerializedModel(\n    seq_model,\n    observation_serializer,\n    action_serializer,\n    significance_decay,\n):\n  """"""Wraps a world model in serialization machinery for training.\n\n  The resulting model takes as input the observation and action sequences,\n  serializes them and interleaves into one sequence, which is fed into a given\n  autoregressive model. The resulting logit sequence is deinterleaved into\n  observations and actions, and the observation logits are returned together\n  with computed symbol significance weights.\n\n  Args:\n    seq_model: Trax autoregressive model taking as input a sequence of symbols\n      and outputting a sequence of symbol logits.\n    observation_serializer: Serializer to use for observations.\n    action_serializer: Serializer to use for actions.\n    significance_decay: Float from (0, 1) for exponential weighting of symbols\n      in the representation.\n\n  Returns:\n    A model of signature\n    (obs, act, obs, mask) -> (obs_logits, obs_repr, weights), where obs are\n    observations (the second occurrence is the target), act are actions, mask is\n    the observation mask, obs_logits are logits of the output observation\n    representation, obs_repr is the target observation representation and\n    weights are the target weights.\n  """"""\n  weigh_by_significance = [\n      # (mask,)\n      RepresentationMask(serializer=observation_serializer),\n      # (repr_mask)\n      SignificanceWeights(serializer=observation_serializer,\n                          decay=significance_decay),\n      # (mask, sig_weights)\n  ]\n  return tl.Serial(\n      # (obs, act, obs, mask)\n      tl.Parallel(Serialize(serializer=observation_serializer),\n                  Serialize(serializer=action_serializer),\n                  Serialize(serializer=observation_serializer)),\n      # (obs_repr, act_repr, obs_repr, mask)\n      Interleave(),\n      # (obs_act_repr, obs_repr, mask)\n      seq_model,\n      # (obs_act_logits, obs_repr, mask)\n      Deinterleave(x_size=observation_serializer.representation_length,\n                   y_size=action_serializer.representation_length),\n      # (obs_logits, act_logits, obs_repr, mask)\n      tl.Parallel(None, tl.Drop(), None, weigh_by_significance),\n      # (obs_logits, obs_repr, weights)\n  )\n\n\n# TODO(pkozakowski): Figure out a more generic way to do this (submodel tags\n# inside the model?).\ndef extract_inner_model(serialized_model):  # pylint: disable=invalid-name\n  """"""Extracts the weights/state of the inner model from a SerializedModel.""""""\n  return serialized_model[2]\n\n\ndef RawPolicy(seq_model, n_controls, n_actions):\n  """"""Wraps a sequence model in a policy interface.\n\n  The resulting model takes as input observation anc action sequences, but only\n  uses the observations. Adds output heads for action logits and value\n  predictions.\n\n  Args:\n    seq_model: Trax sequence model taking as input and outputting a sequence of\n      continuous vectors.\n    n_controls: Number of controls.\n    n_actions: Number of action categories in each control.\n\n  Returns:\n    A model of signature (obs, act) -> (act_logits, values), with shapes:\n      obs: (batch_size, length + 1, obs_depth)\n      act: (batch_size, length, n_controls)\n      act_logits: (batch_size, length, n_controls, n_actions)\n      values: (batch_size, length)\n  """"""\n\n  def SplitControls():  # pylint: disable=invalid-name\n    """"""Splits logits for actions in different controls.""""""\n    def f(x):\n      return jnp.reshape(x, x.shape[:2] + (n_controls, n_actions))\n    return tl.Fn(\'SplitControls\', f)\n\n  action_head = [\n      # Predict all action logits at the same time.\n      tl.Dense(n_controls * n_actions),\n      # Then group them into separate controls, adding a new dimension.\n      SplitControls(),\n      tl.LogSoftmax(),\n  ]\n  return tl.Serial(                             # (obs, act)\n      tl.Select([0], n_in=2),                   # (obs,)\n      seq_model,                                # (obs_hidden,)\n      tl.Dup(),                                 # (obs_hidden, obs_hidden)\n      tl.Parallel(action_head, [tl.Dense(1),\n                                tl.Flatten()])  # (act_logits, values)\n  )\n\n\ndef substitute_inner_policy_raw(raw_policy, inner_policy):  # pylint: disable=invalid-name\n  """"""Substitutes the weights/state of the inner model in a RawPolicy.""""""\n  return raw_policy[:1] + [inner_policy] + raw_policy[2:]\n\n\ndef SerializedPolicy(\n    seq_model, n_controls, n_actions, observation_serializer, action_serializer\n):\n  """"""Wraps a policy in serialization machinery for training.\n\n  The resulting model takes as input observation and action sequences, and\n  serializes them into one sequence similar to SerializedModel, before passing\n  to the given sequence model. Adds output heads for action logits and value\n  predictions.\n\n  Args:\n    seq_model: Trax sequence model taking as input a sequence of symbols and\n      outputting a sequence of continuous vectors.\n    n_controls: Number of controls.\n    n_actions: Number of action categories in each control.\n    observation_serializer: Serializer to use for observations.\n    action_serializer: Serializer to use for actions.\n\n  Returns:\n    A model of signature (obs, act) -> (act_logits, values), same as in\n    RawPolicy.\n  """"""\n  if action_serializer.representation_length != n_controls:\n    raise ValueError(\n        \'Action symbols should correspond 1-1 to controls, but got {} \'\n        \'controls and {} symbols.\'.format(\n            n_controls, action_serializer.representation_length\n        )\n    )\n\n  def FirstSymbol():\n    return tl.Fn(\'FirstSymbol\', lambda x: x[:, :, 0])\n\n  def PadRight(n_to_pad):\n    def pad_right(x):\n      pad_widths = [(0, 0), (0, n_to_pad)] + [(0, 0)] * (x.ndim - 2)\n      return jnp.pad(\n          x, pad_widths, mode=\'constant\', constant_values=x.dtype.type(0))\n    return tl.Fn(f\'PadRight({n_to_pad})\', pad_right)\n\n  action_head = [\n      tl.Dense(n_actions),\n      tl.LogSoftmax(),\n  ]\n  value_head = [\n      # Take just the vectors corresponding to the first action symbol.\n      FirstSymbol(),\n      # Predict values.\n      tl.Dense(1),\n      # Get rid of the singleton dimension.\n      tl.Flatten(),\n  ]\n  return tl.Serial(\n      # (obs, act)\n      tl.Parallel(Serialize(observation_serializer),\n                  Serialize(action_serializer)),\n      # (obs_repr, act_repr)\n      Interleave(),\n      # (obs_act_repr,)\n\n      # Add one dummy action to the right - we\'ll use the output at its first\n      # symbol to predict the value for the last observation.\n      PadRight(action_serializer.representation_length),\n\n      # Shift one symbol to the right, so we predict the n-th action symbol\n      # based on action symbols 1..n-1 instead of 1..n.\n      tl.ShiftRight(),\n      seq_model,\n      # (obs_act_hidden,)\n      Deinterleave(observation_serializer.representation_length,\n                   action_serializer.representation_length),\n      # (obs_hidden, act_hidden)\n      tl.Select([1, 1]),\n      # (act_hidden, act_hidden)\n      tl.Parallel(action_head, value_head),\n      # (act_logits, values)\n  )\n\n\ndef substitute_inner_policy_serialized(serialized_policy, inner_policy):  # pylint: disable=invalid-name\n  """"""Substitutes the weights/state of the inner model in a SerializedPolicy.""""""\n  return serialized_policy[:4] + [inner_policy] + serialized_policy[5:]\n\n\ndef analyze_action_space(action_space):  # pylint: disable=invalid-name\n  """"""Returns the number of controls and actions for an action space.""""""\n  assert isinstance(\n      action_space, (gym.spaces.Discrete, gym.spaces.MultiDiscrete)\n  ), \'Action space expected to be Discrete of MultiDiscrete, got {}.\'.format(\n      type(action_space)\n  )\n  if isinstance(action_space, gym.spaces.Discrete):\n    n_actions = action_space.n\n    n_controls = 1\n  else:\n    (n_controls,) = action_space.nvec.shape\n    assert n_controls > 0\n    assert np.min(action_space.nvec) == np.max(action_space.nvec), (\n        \'Every control must have the same number of actions.\'\n    )\n    n_actions = action_space.nvec[0]\n  return (n_controls, n_actions)\n\n\ndef wrap_policy(seq_model, observation_space, action_space, vocab_size):  # pylint: disable=invalid-name\n  """"""Wraps a sequence model in either RawPolicy or SerializedPolicy.\n\n  Args:\n    seq_model: Trax sequence model.\n    observation_space: Gym observation space.\n    action_space: Gym action space.\n    vocab_size: Either the number of symbols for a serialized policy, or None.\n\n  Returns:\n    RawPolicy if vocab_size is None, else SerializedPolicy.\n  """"""\n  (n_controls, n_actions) = analyze_action_space(action_space)\n  if vocab_size is None:\n    policy_wrapper = RawPolicy\n  else:\n    obs_serializer = space_serializer.create(observation_space, vocab_size)\n    act_serializer = space_serializer.create(action_space, vocab_size)\n    policy_wrapper = functools.partial(SerializedPolicy,\n                                       observation_serializer=obs_serializer,\n                                       action_serializer=act_serializer)\n  return policy_wrapper(seq_model, n_controls, n_actions)\n\n\ndef substitute_inner_policy(wrapped_policy, inner_policy, vocab_size):  # pylint: disable=invalid-name\n  """"""Substitutes the inner weights/state in a {Raw,Serialized}Policy.\n\n  Args:\n    wrapped_policy (pytree): Weights or state of a wrapped policy.\n    inner_policy (pytree): Weights or state of an inner policy.\n    vocab_size (int or None): Vocabulary size of a serialized policy, or None\n      in case of a raw policy.\n\n  Returns:\n    New weights or state of wrapped_policy, with the inner weights/state\n      copied from inner_policy.\n  """"""\n  if vocab_size is None:\n    substitute_fn = substitute_inner_policy_raw\n  else:\n    substitute_fn = substitute_inner_policy_serialized\n  return substitute_fn(wrapped_policy, inner_policy)\n'"
trax/rl/serialization_utils_test.py,19,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.rl.serialization_utils.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\nimport gin\nimport gym\nfrom jax import numpy as jnp\nimport numpy as np\nfrom tensorflow import test\n\nfrom trax import shapes\nfrom trax.layers import base as layers_base\nfrom trax.models import transformer\nfrom trax.rl import serialization_utils\nfrom trax.rl import space_serializer\n\n\n# pylint: disable=invalid-name\ndef TestModel(extra_dim):\n  """"""Dummy sequence model for testing.""""""\n  def f(inputs):\n    # Cast the input to float32 - this is for simulating discrete-input models.\n    inputs = inputs.astype(np.float32)\n    # Add an extra dimension if requested, e.g. the logit dimension for output\n    # symbols.\n    if extra_dim is not None:\n      return jnp.broadcast_to(inputs[:, :, None], inputs.shape + (extra_dim,))\n    else:\n      return inputs\n  return layers_base.Fn(\'TestModel\', f)\n  # pylint: enable=invalid-name\n\n\nclass SerializationTest(parameterized.TestCase):\n\n  def setUp(self):\n    super(SerializationTest, self).setUp()\n    self._serializer = space_serializer.create(\n        gym.spaces.Discrete(2), vocab_size=2\n    )\n    self._repr_length = 100\n    self._serialization_utils_kwargs = {\n        \'observation_serializer\': self._serializer,\n        \'action_serializer\': self._serializer,\n        \'representation_length\': self._repr_length,\n    }\n\n  def test_serialized_model_discrete(self):\n    vocab_size = 3\n    obs = np.array([[[0, 1], [1, 1], [1, 0], [0, 0]]])\n    act = np.array([[1, 0, 0]])\n    mask = np.array([[1, 1, 1, 0]])\n\n    test_model_inputs = []\n\n    # pylint: disable=invalid-name\n    def TestModelSavingInputs():\n      def f(inputs):\n        # Save the inputs for a later check.\n        test_model_inputs.append(inputs)\n        # Change type to np.float32 and add the logit dimension.\n        return jnp.broadcast_to(\n            inputs.astype(np.float32)[:, :, None], inputs.shape + (vocab_size,)\n        )\n      return layers_base.Fn(\'TestModelSavingInputs\', f)\n      # pylint: enable=invalid-name\n\n    obs_serializer = space_serializer.create(\n        gym.spaces.MultiDiscrete([2, 2]), vocab_size=vocab_size\n    )\n    act_serializer = space_serializer.create(\n        gym.spaces.Discrete(2), vocab_size=vocab_size\n    )\n    serialized_model = serialization_utils.SerializedModel(\n        TestModelSavingInputs(),  # pylint: disable=no-value-for-parameter\n        observation_serializer=obs_serializer,\n        action_serializer=act_serializer,\n        significance_decay=0.9,\n    )\n\n    example = (obs, act, obs, mask)\n    serialized_model.init(shapes.signature(example))\n    (obs_logits, obs_repr, weights) = serialized_model(example)\n    # Check that the model has been called with the correct input.\n    np.testing.assert_array_equal(\n        # The model is called multiple times for determining shapes etc.\n        # Check the last saved input - that should be the actual concrete array\n        # calculated during the forward pass.\n        test_model_inputs[-1],\n        # Should be serialized observations and actions interleaved.\n        [[0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0]],\n    )\n    # Check the output shape.\n    self.assertEqual(obs_logits.shape, obs_repr.shape + (vocab_size,))\n    # Check that obs_logits are the same as obs_repr, just broadcasted over the\n    # logit dimension.\n    np.testing.assert_array_equal(np.min(obs_logits, axis=-1), obs_repr)\n    np.testing.assert_array_equal(np.max(obs_logits, axis=-1), obs_repr)\n    # Check that the observations are correct.\n    np.testing.assert_array_equal(obs_repr, obs)\n    # Check weights.\n    np.testing.assert_array_equal(weights, [[[1, 1], [1, 1], [1, 1], [0, 0]]])\n\n  def test_serialized_model_continuous(self):\n    precision = 3\n    gin.bind_parameter(\'BoxSpaceSerializer.precision\', precision)\n\n    vocab_size = 32\n    obs = np.array([[[1.5, 2], [-0.3, 1.23], [0.84, 0.07], [0, 0]]])\n    act = np.array([[0, 1, 0]])\n    mask = np.array([[1, 1, 1, 0]])\n\n    obs_serializer = space_serializer.create(\n        gym.spaces.Box(shape=(2,), low=-2, high=2), vocab_size=vocab_size\n    )\n    act_serializer = space_serializer.create(\n        gym.spaces.Discrete(2), vocab_size=vocab_size\n    )\n    serialized_model = serialization_utils.SerializedModel(\n        TestModel(extra_dim=vocab_size),  # pylint: disable=no-value-for-parameter\n        observation_serializer=obs_serializer,\n        action_serializer=act_serializer,\n        significance_decay=0.9,\n    )\n\n    example = (obs, act, obs, mask)\n    serialized_model.init(shapes.signature(example))\n    (obs_logits, obs_repr, weights) = serialized_model(example)\n    self.assertEqual(obs_logits.shape, obs_repr.shape + (vocab_size,))\n    self.assertEqual(\n        obs_repr.shape, (1, obs.shape[1], obs.shape[2] * precision)\n    )\n    self.assertEqual(obs_repr.shape, weights.shape)\n\n  def test_extract_inner_model(self):\n    vocab_size = 3\n\n    inner_model = transformer.TransformerLM(\n        vocab_size=vocab_size, d_model=2, d_ff=2, n_layers=0\n    )\n    obs_serializer = space_serializer.create(\n        gym.spaces.Discrete(2), vocab_size=vocab_size\n    )\n    act_serializer = space_serializer.create(\n        gym.spaces.Discrete(2), vocab_size=vocab_size\n    )\n    serialized_model = serialization_utils.SerializedModel(\n        inner_model,\n        observation_serializer=obs_serializer,\n        action_serializer=act_serializer,\n        significance_decay=0.9,\n    )\n\n    obs_sig = shapes.ShapeDtype((1, 2))\n    act_sig = shapes.ShapeDtype((1, 1))\n    (weights, state) = serialized_model.init(\n        input_signature=(obs_sig, act_sig, obs_sig, obs_sig),\n    )\n    (inner_weights, inner_state) = map(\n        serialization_utils.extract_inner_model, (weights, state)\n    )\n    inner_model(jnp.array([[0]]), weights=inner_weights, state=inner_state)\n\n  @parameterized.named_parameters((\'raw\', None), (\'serialized\', 32))\n  def test_wrapped_policy_continuous(self, vocab_size):\n    precision = 3\n    n_controls = 2\n    n_actions = 4\n    gin.bind_parameter(\'BoxSpaceSerializer.precision\', precision)\n\n    obs = np.array([[[1.5, 2], [-0.3, 1.23], [0.84, 0.07], [0.01, 0.66]]])\n    act = np.array([[[0, 1], [2, 0], [1, 3]]])\n\n    wrapped_policy = serialization_utils.wrap_policy(\n        TestModel(extra_dim=vocab_size),  # pylint: disable=no-value-for-parameter\n        observation_space=gym.spaces.Box(shape=(2,), low=-2, high=2),\n        action_space=gym.spaces.MultiDiscrete([n_actions] * n_controls),\n        vocab_size=vocab_size,\n    )\n\n    example = (obs, act)\n    wrapped_policy.init(shapes.signature(example))\n    (act_logits, values) = wrapped_policy(example)\n    self.assertEqual(act_logits.shape, obs.shape[:2] + (n_controls, n_actions))\n    self.assertEqual(values.shape, obs.shape[:2])\n\n  def test_analyzes_discrete_action_space(self):\n    space = gym.spaces.Discrete(n=5)\n    (n_controls, n_actions) = serialization_utils.analyze_action_space(space)\n    self.assertEqual(n_controls, 1)\n    self.assertEqual(n_actions, 5)\n\n  def test_analyzes_multi_discrete_action_space_with_equal_categories(self):\n    space = gym.spaces.MultiDiscrete(nvec=(3, 3))\n    (n_controls, n_actions) = serialization_utils.analyze_action_space(space)\n    self.assertEqual(n_controls, 2)\n    self.assertEqual(n_actions, 3)\n\n  def test_doesnt_analyze_multi_disccrete_action_space_with_inequal_categories(\n      self\n  ):\n    space = gym.spaces.MultiDiscrete(nvec=(2, 3))\n    with self.assertRaises(AssertionError):\n      serialization_utils.analyze_action_space(space)\n\n  def test_doesnt_analyze_box_action_space(self):\n    space = gym.spaces.Box(shape=(2, 3), low=0, high=1)\n    with self.assertRaises(AssertionError):\n      serialization_utils.analyze_action_space(space)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/simple.py,9,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""SimPLe helper functions.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport itertools\nimport os\nimport random\n\nfrom absl import logging\nimport numpy as np\nfrom tensor2tensor.envs import env_problem_utils\nfrom tensor2tensor.envs import trajectory\nimport tensorflow as tf\nfrom trax import utils\n\n\ndef load_trajectories(trajectory_dir, eval_frac):\n  """"""Loads trajectories from a possibly nested directory of pickles.""""""\n  pkl_module = utils.get_pickle_module()\n  train_trajectories = []\n  eval_trajectories = []\n  # Search the entire directory subtree for trajectories.\n  for (subdir, _, filenames) in tf.io.gfile.walk(trajectory_dir):\n    for filename in filenames:\n      shard_path = os.path.join(subdir, filename)\n      try:\n        with tf.io.gfile.GFile(shard_path, \'rb\') as f:\n          trajectories = pkl_module.load(f)\n        pivot = int(len(trajectories) * (1 - eval_frac))\n        train_trajectories.extend(trajectories[:pivot])\n        eval_trajectories.extend(trajectories[pivot:])\n      except EOFError:\n        logging.warning(\n            \'Could not load trajectories from a corrupted shard %s.\',\n            shard_path,\n        )\n  assert train_trajectories, ""Can\'t find training data in %s"" % trajectory_dir\n  assert eval_trajectories, ""Can\'t find evaluation data in %s"" % trajectory_dir\n  return train_trajectories, eval_trajectories\n\n\ndef generate_examples(trajectories, trajectory_to_training_examples_fn):\n  """"""Generates an infinite stream of shuffled examples out of trajectories.""""""\n  examples = [\n      example  # pylint: disable=g-complex-comprehension\n      for trajectory_examples in map(\n          trajectory_to_training_examples_fn, trajectories)\n      for example in trajectory_examples\n  ]\n  assert examples\n  while True:\n    random.shuffle(examples)\n    for example in examples:\n      yield example\n\n\ndef mix_streams(stream1, stream2, mix_prob):\n  """"""Mixes two streams together with a fixed probability.""""""\n  while True:\n    # In the corner cases (mix_prob = 0 or 1) mixing the other stream never\n    # happens, because random() samples from the semi-open interval [0, 1).\n    if random.random() < mix_prob:\n      yield next(stream1)\n    else:\n      yield next(stream2)\n\n\ndef batch_stream(stream, batch_size):\n  """"""Batches a stream of training examples.""""""\n  def make_batch(examples):\n    """"""Stacks a structure of numpy arrays nested in lists/tuples.""""""\n    assert examples\n    if isinstance(examples[0], (list, tuple)):\n      return type(examples[0])(\n          make_batch([example[i] for example in examples])\n          for i in range(len(examples[0]))\n      )\n    else:\n      return np.stack(examples, axis=0)\n\n  # Take consecutive batches from an infinite stream. This way there are no\n  # incomplete batches. We might get duplicate examples in the same batch, but\n  # that should be very rare.\n  while True:\n    yield make_batch(list(itertools.islice(stream, batch_size)))\n\n\n# TODO(pkozakowski): This is mostly a simplified version of\n# env_problem_utils.play_env_problem_with_policy, generalized to work with\n# policies not being neural networks. Another difference is that it always\n# collects exactly one trajectory from each environment in the batch. Unify if\n# possible.\ndef play_env_problem(env, policy_fn):\n  """"""Plays an EnvProblem using a given policy function.""""""\n  trajectories = [trajectory.Trajectory() for _ in range(env.batch_size)]\n  observations = env.reset()\n  for (traj, observation) in zip(trajectories, observations):\n    traj.add_time_step(observation=observation)\n\n  done_so_far = np.array([False] * env.batch_size)\n  while not np.all(done_so_far):\n    padded_observations, _ = env.trajectories.observations_np(\n        len_history_for_policy=None)\n    actions = policy_fn(padded_observations)\n    (observations, rewards, dones, _) = env.step(actions)\n    for (traj, observation, action, reward, done) in zip(\n        trajectories, observations, actions, rewards, dones\n    ):\n      if not traj.done:\n        traj.change_last_time_step(action=action)\n        traj.add_time_step(\n            observation=observation, raw_reward=reward, done=done)\n    env.reset(env_problem_utils.done_indices(dones))\n    done_so_far = np.logical_or(done_so_far, dones)\n  return trajectories\n\n\ndef calculate_observation_error(real_trajectories, sim_trajectories):\n  """"""Calculates MSE of observations in two trajectories.""""""\n  def pad_or_truncate(observations, desired_length):\n    (current_length, _) = observations.shape\n    if current_length < desired_length:\n      return np.pad(\n          observations,\n          pad_width=((0, desired_length - current_length), (0, 0)),\n          mode=\'edge\',\n      )\n    else:\n      return observations[:desired_length, :]\n\n  def calculate_for_single_pair(real_trajectory, sim_trajectory):\n    real_obs = real_trajectory.observations_np\n    sim_obs = pad_or_truncate(\n        sim_trajectory.observations_np, real_trajectory.num_time_steps)\n    return np.sum((real_obs - sim_obs) ** 2, axis=0)\n\n  return np.mean([\n      calculate_for_single_pair(real_traj, sim_traj)\n      for (real_traj, sim_traj) in zip(real_trajectories, sim_trajectories)\n  ], axis=0)\n\n\ndef plot_observation_error(real_trajectories, sim_trajectories, mpl_plt):\n  """"""Plots observations from two trajectories on the same graph.""""""\n  assert len(real_trajectories) == len(sim_trajectories)\n  assert real_trajectories\n  obs_dim = real_trajectories[0].last_time_step.observation.shape[0]\n  (w, h) = mpl_plt.rcParams[\'figure.figsize\']\n  ncols = len(real_trajectories)\n  nrows = obs_dim\n  (_, axes) = mpl_plt.subplots(\n      nrows, ncols, figsize=(w * ncols, h * nrows))\n  for (traj_index, (real_traj, sim_traj)) in enumerate(\n      zip(real_trajectories, sim_trajectories)\n  ):\n    for dim_index in range(obs_dim):\n      for (traj, label) in ((real_traj, \'real\'), (sim_traj, \'simulated\')):\n        obs = traj.observations_np\n        ax = axes[dim_index, traj_index]\n        ax.set_title(\'trajectory {}, observation dimension {}\'.format(\n            traj_index, dim_index))\n        ax.plot(np.arange(obs.shape[0]), obs[:, dim_index], label=label)\n        ax.legend()\n\n\nclass ReplayPolicy(object):\n  """"""Policy function repeating actions from a given batch of trajectories.""""""\n\n  def __init__(self, trajectories, out_of_bounds_action):\n    """"""Creates ReplayPolicy.\n\n    Args:\n      trajectories: Batch of trajectories to repeat actions from.\n      out_of_bounds_action: Action to play after the replayed trajectory ends.\n    """"""\n    self._trajectories = trajectories\n    self._out_of_bounds_action = out_of_bounds_action\n    self._step = 0\n\n  def __call__(self, observations):\n    del observations\n\n    def get_action(traj):\n      action = None\n      if self._step < traj.num_time_steps:\n        action = traj.time_steps[self._step].action\n        # PS: action can still be None, if this is the last time-step in traj.\n      return action if action is not None else self._out_of_bounds_action\n    actions = np.array(list(map(get_action, self._trajectories)))\n    self._step += 1\n    return actions\n\n\ndef evaluate_model(sim_env, real_trajectories, mpl_plt, n_to_plot=3):\n  """"""Reports the observation error metric and the corresponding plot.""""""\n  if len(sim_env.observation_space.shape) != 1:\n    logging.warning(\n        \'Could not evaluate the model - only environments with vector \'\n        \'observation spaces are supported.\'\n    )\n    return\n\n  assert len(real_trajectories) == sim_env.batch_size\n\n  policy_fn = ReplayPolicy(\n      real_trajectories,\n      # Does not matter which action we play after the real trajetory ends, we\n      # cut the simulated one to match the real one anyway.\n      out_of_bounds_action=sim_env.action_space.sample(),\n  )\n\n  sim_trajectories = play_env_problem(sim_env, policy_fn)\n  obs_errors = calculate_observation_error(real_trajectories, sim_trajectories)\n  plot_observation_error(\n      real_trajectories[:n_to_plot], sim_trajectories[:n_to_plot], mpl_plt)\n  return {\n      \'observation_error/{}\'.format(i): obs_error\n      for (i, obs_error) in enumerate(obs_errors)\n  }\n'"
trax/rl/simple_test.py,42,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.rl.simple.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport itertools\nimport os\n\nimport gin\nimport gym\nfrom matplotlib import pyplot as plt\nimport mock\nimport numpy as np\n\nfrom tensor2tensor.envs import trajectory\nfrom tensorflow import test\nfrom tensorflow.compat.v1.io import gfile\nfrom trax import math\nfrom trax import utils\nfrom trax.layers import base\nfrom trax.rl import simple\nfrom trax.rl import simulated_env_problem\nfrom trax.rl import space_serializer  # pylint: disable=unused-import\nfrom trax.supervised import trainer_lib\n\n\nclass SimpleTest(test.TestCase):\n\n  def _make_singleton_trajectory(self, observation):\n    t = trajectory.Trajectory()\n    t.add_time_step(observation=observation)\n    return t\n\n  def _dump_trajectory_pickle(self, observations, path):\n    pkl_module = utils.get_pickle_module()\n    trajectories = list(map(self._make_singleton_trajectory, observations))\n    with gfile.GFile(path, \'wb\') as f:\n      pkl_module.dump(trajectories, f)\n\n  def test_loads_trajectories(self):\n    temp_dir = self.get_temp_dir()\n    # Dump two trajectory pickles with given observations.\n    self._dump_trajectory_pickle(\n        observations=[0, 1, 2, 3], path=os.path.join(temp_dir, \'0.pkl\'))\n    self._dump_trajectory_pickle(\n        observations=[4, 5, 6, 7], path=os.path.join(temp_dir, \'1.pkl\'))\n    (train_trajs, eval_trajs) = simple.load_trajectories(\n        temp_dir, eval_frac=0.25)\n    extract_obs = lambda t: t.last_time_step.observation\n    # The order of pickles is undefined, so we compare sets.\n    actual_train_obs = set(map(extract_obs, train_trajs))\n    actual_eval_obs = set(map(extract_obs, eval_trajs))\n\n    # First 3 trajectories from each pickle go to train, the last one to eval.\n    expected_train_obs = {0, 1, 2, 4, 5, 6}\n    expected_eval_obs = {3, 7}\n    self.assertEqual(actual_train_obs, expected_train_obs)\n    self.assertEqual(actual_eval_obs, expected_eval_obs)\n\n  def test_generates_examples(self):\n    observations = [0, 1, 2, 3]\n    trajectories = map(self._make_singleton_trajectory, observations)\n    trajectory_to_training_examples = lambda t: [t.last_time_step.observation]\n    stream = simple.generate_examples(\n        trajectories, trajectory_to_training_examples)\n\n    # The examples are shuffled, so we compare sets.\n    self.assertEqual(\n        set(itertools.islice(stream, len(observations))), set(observations))\n    # The stream is infinite, so we should be able to take a next element.\n    self.assertIn(next(stream), observations)\n\n  def test_mixes_streams_with_prob_one(self):\n    # Mix infinite streams of 0s and 1s.\n    stream = simple.mix_streams(\n        itertools.repeat(0), itertools.repeat(1), mix_prob=1.0)\n    # Mixed stream should have only 0s.\n    self.assertEqual(set(itertools.islice(stream, 100)), {0})\n\n  def test_mixes_streams_with_prob_zero(self):\n    stream = simple.mix_streams(\n        itertools.repeat(0), itertools.repeat(1), mix_prob=0.0)\n    # Mixed stream should have only 1s.\n    self.assertEqual(set(itertools.islice(stream, 100)), {1})\n\n  def test_mixes_streams_with_prob_half(self):\n    stream = simple.mix_streams(\n        itertools.repeat(0), itertools.repeat(1), mix_prob=0.5)\n    # Mixed stream should have both 0s and 1s.\n    self.assertEqual(set(itertools.islice(stream, 100)), {0, 1})\n\n  def test_batches_stream(self):\n    stream = iter([(0, 1), (2, 3), (4, 5), (6, 7)])\n    batched_stream = simple.batch_stream(stream, batch_size=2)\n    np.testing.assert_equal(\n        next(batched_stream), (np.array([0, 2]), np.array([1, 3])))\n    np.testing.assert_equal(\n        next(batched_stream), (np.array([4, 6]), np.array([5, 7])))\n\n  def test_plays_env_problem(self):\n    # Shape: (time, trajectory).\n    observations = np.array([[0, 1], [2, 3], [4, 5]])\n    rewards = np.array([[0, 1], [1, 0]])\n    actions = np.array([[1, 2], [2, 0]])\n    # We end the second environment 2 times, but we shouldn\'t collect the second\n    # trajectory.\n    dones = np.array([[False, True], [True, True]])\n    infos = [{}, {}]\n\n    mock_env = mock.MagicMock()\n    mock_env.batch_size = 2\n    # (observations, lengths)\n    mock_env.trajectories.observations_np.return_value = (None, None)\n    mock_env.reset.return_value = observations[0]\n    mock_env.step.side_effect = zip(observations[1:], rewards, dones, infos)\n\n    mock_policy_fn = mock.MagicMock()\n    mock_policy_fn.side_effect = actions\n\n    trajectories = simple.play_env_problem(mock_env, mock_policy_fn)\n    self.assertEqual(len(trajectories), 2)\n    expected_lengths = [3, 2]\n    for (i, (traj, expected_length)) in enumerate(\n        zip(trajectories, expected_lengths)):\n      self.assertEqual(traj.num_time_steps, expected_length)\n      np.testing.assert_array_equal(\n          traj.observations_np, observations[:expected_length, i])\n      np.testing.assert_array_equal(\n          traj.raw_rewards_np, rewards[:(expected_length - 1), i])\n      np.testing.assert_array_equal(\n          traj.actions_np, actions[:(expected_length - 1), i])\n\n  def _make_trajectory(self, observations=None, actions=None):\n    t = trajectory.Trajectory()\n    if observations is None:\n      observations = itertools.repeat(None)\n    if actions is None:\n      actions = itertools.repeat(None)\n    for (observation, action) in zip(observations, actions):\n      t.add_time_step(observation=observation, action=action)\n    return t\n\n  def test_replay_policy(self):\n    trajectories = [\n        self._make_trajectory(actions=actions)\n        for actions in map(np.array, [[1, 2], [3]])\n    ]\n    policy_fn = simple.ReplayPolicy(trajectories, out_of_bounds_action=0)\n    np.testing.assert_array_equal(policy_fn(None), [1, 3])\n    np.testing.assert_array_equal(policy_fn(None), [2, 0])\n\n  def test_observation_error_zero_for_same_trajectories(self):\n    observations = np.array([[0], [2], [1]])\n    (traj1, traj2) = map(self._make_trajectory, (observations, observations))\n    error = simple.calculate_observation_error([traj1], [traj2])\n    np.testing.assert_array_almost_equal(error, [0])\n\n  def test_observation_error_positive_for_different_trajectories(self):\n    observations1 = np.array([[1], [2], [3]])\n    observations2 = np.array([[0], [2], [3]])\n    (traj1, traj2) = map(self._make_trajectory, (observations1, observations2))\n    error = simple.calculate_observation_error([traj1], [traj2])\n    np.testing.assert_array_less([0], error)\n\n  def test_observation_error_dims_correspond_to_observation_dims(self):\n    observations1 = np.array([[0, 1, 0], [0, 2, 0], [0, 3, 0]])\n    observations2 = np.array([[0, 0, 0], [0, 0, 0], [0, 0, 0]])\n    (traj1, traj2) = map(self._make_trajectory, (observations1, observations2))\n    error = simple.calculate_observation_error([traj1], [traj2])\n    self.assertEqual(error.shape, (3,))\n    np.testing.assert_array_almost_equal(error[0], 0)\n    self.assertFalse(np.allclose(error[1], 0))\n    np.testing.assert_array_almost_equal(error[2], 0)\n\n  def test_observation_error_increases_with_distance(self):\n    observations_zero = np.array([[0], [0], [0]])\n    observations_positive = np.array([[3], [2], [1]])\n    (traj_zero, traj_positive, traj_negative) = map(\n        self._make_trajectory,\n        (observations_zero, observations_positive, -observations_positive),\n    )\n    error_small = simple.calculate_observation_error(\n        [traj_zero], [traj_positive])\n    error_big = simple.calculate_observation_error(\n        [traj_positive], [traj_negative])\n    np.testing.assert_array_less(error_small, error_big)\n\n  def test_observation_error_increases_with_real_trajectory_length(self):\n    observations_real_short = np.array([[1], [2]])\n    observations_real_long = np.array([[1], [2], [3]])\n    observations_sim = np.array([[0], [1]])\n    (traj_real_short, traj_real_long, traj_sim) = map(\n        self._make_trajectory,\n        (observations_real_short, observations_real_long, observations_sim),\n    )\n    error_small = simple.calculate_observation_error(\n        real_trajectories=[traj_real_short], sim_trajectories=[traj_sim])\n    error_big = simple.calculate_observation_error(\n        real_trajectories=[traj_real_long], sim_trajectories=[traj_sim])\n    np.testing.assert_array_less(error_small, error_big)\n\n  def test_observation_error_same_when_sim_trajectory_longer(self):\n    observations_real = np.array([[0], [1]])\n    observations_sim_short = np.array([[1], [2]])\n    observations_sim_long = np.array([[1], [2], [3]])\n    (traj_real, traj_sim_short, traj_sim_long) = map(\n        self._make_trajectory,\n        (observations_real, observations_sim_short, observations_sim_long),\n    )\n    error1 = simple.calculate_observation_error(\n        real_trajectories=[traj_real], sim_trajectories=[traj_sim_short])\n    error2 = simple.calculate_observation_error(\n        real_trajectories=[traj_real], sim_trajectories=[traj_sim_long])\n    np.testing.assert_array_almost_equal(error1, error2)\n\n  def test_observation_error_reduces_over_trajectories(self):\n    observations1 = np.array([[1], [2], [3]])\n    observations2 = np.array([[0], [2], [3]])\n    (traj1, traj2) = map(self._make_trajectory, (observations1, observations2))\n    error = simple.calculate_observation_error([traj1, traj1], [traj2, traj2])\n    self.assertEqual(error.shape, (1,))\n\n  @staticmethod\n  @mock.patch.object(trainer_lib, \'load_trainer_state\', autospec=True)\n  def _make_env(\n      mock_restore_state, observation_space, action_space,\n      max_trajectory_length, batch_size,\n  ):\n    # (model_params, opt_state)\n    mock_restore_state.return_value.params = (None, None)\n\n    gin.bind_parameter(\'BoxSpaceSerializer.precision\', 1)\n\n    predict_output = (np.array([[[0.0]]] * batch_size))\n    mock_model_fn = mock.MagicMock()\n    mock_model_fn.return_value.side_effect = itertools.repeat(predict_output)\n    mock_model_fn.return_value.init.return_value = (\n        base.EMPTY_WEIGHTS, base.EMPTY_STATE)\n\n    return simulated_env_problem.SerializedSequenceSimulatedEnvProblem(\n        model=mock_model_fn,\n        reward_fn=(lambda _1, _2: np.zeros(batch_size)),\n        done_fn=(lambda _1, _2: np.full((batch_size,), False)),\n        vocab_size=1,\n        max_trajectory_length=max_trajectory_length,\n        batch_size=batch_size,\n        observation_space=observation_space,\n        action_space=action_space,\n        reward_range=(-1, 1),\n        discrete_rewards=False,\n        history_stream=itertools.repeat(None),\n        output_dir=None,\n    )\n\n  def test_fails_to_evaluate_model_with_matrix_observation_space(self):\n    with math.use_backend(\'numpy\'):\n      env = self._make_env(  # pylint: disable=no-value-for-parameter\n          observation_space=gym.spaces.Box(shape=(2, 2), low=0, high=1),\n          action_space=gym.spaces.Discrete(n=1),\n          max_trajectory_length=2,\n          batch_size=1,\n      )\n      trajectories = [\n          self._make_trajectory(np.array([[0, 1], [2, 3]]), np.array([0]))]\n      metrics = simple.evaluate_model(env, trajectories, plt)\n      self.assertIsNone(metrics)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/simple_trainer.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""SimPLe trainer.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nimport itertools\nimport os\nimport random\nimport time\n\nfrom absl import logging\nimport gin\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom trax import jaxboard\nfrom trax.rl import base_trainer\nfrom trax.rl import simple\nfrom trax.rl import simulated_env_problem\nfrom trax.supervised import inputs as trax_inputs\nfrom trax.supervised import trainer_lib\n\n\nclass SimPLe(base_trainer.BaseTrainer):\n  """"""SimPLe trainer.""""""\n\n  def __init__(self,\n               train_env,\n               eval_env,\n               output_dir,\n               policy_trainer_class,\n               n_real_epochs=10,\n               data_eval_frac=0.125,\n               model_train_batch_size=64,\n               n_model_initial_train_steps=1000,\n               n_model_train_steps_per_epoch=1000,\n               simulated_env_problem_class=(\n                   simulated_env_problem.SerializedSequenceSimulatedEnvProblem),\n               simulated_batch_size=16,\n               n_simulated_epochs=1000,\n               trajectory_dump_dir=None,\n               initial_trajectory_dir=None,\n               initial_trajectory_mix_prob=0.5,\n               initial_model=None,\n               init_policy_from_world_model=False,\n               **kwargs):\n    super(SimPLe, self).__init__(train_env, eval_env, output_dir, **kwargs)\n    self._policy_dir = os.path.join(output_dir, \'policy\')\n    self._model_dir = os.path.join(output_dir, \'model\')\n    # Initialize the policy trainer lazily, so in case of initializing the\n    # policy from world model checkpoint, the trainer will try to load the\n    # checkpoint _after_ it\'s been created in train_model().\n    self._policy_trainer_fn = functools.partial(\n        policy_trainer_class,\n        train_env=train_env,\n        eval_env=eval_env,\n        output_dir=self._policy_dir,\n        async_mode=self._async_mode,\n    )\n    self._policy_trainer = None\n    self._n_real_epochs = n_real_epochs\n    self._model_train_batch_size = model_train_batch_size\n    self._n_model_initial_train_steps = n_model_initial_train_steps\n    self._n_model_train_steps_per_epoch = n_model_train_steps_per_epoch\n    self._data_eval_frac = data_eval_frac\n\n    tf.io.gfile.makedirs(self._model_dir)\n    if initial_model is not None:\n      tf.io.gfile.copy(\n          initial_model,\n          os.path.join(self._model_dir, \'model.pkl\'),\n          overwrite=True,\n      )\n    self._initial_model = initial_model\n    self._initial_trajectories = None\n    self._init_policy_from_world_model = init_policy_from_world_model\n\n    self._sim_env = simulated_env_problem_class(\n        batch_size=None,\n        observation_space=train_env.observation_space,\n        action_space=train_env.action_space,\n        reward_range=train_env.reward_range,\n        discrete_rewards=train_env.discrete_rewards,\n        history_stream=None,  # TODO(pkozakowski): Support this.\n        output_dir=self._model_dir,\n    )\n    self._simulated_batch_size = simulated_batch_size\n    self._n_simulated_epochs = n_simulated_epochs\n\n    # If trajectory_dump_dir is not provided explicitly, save the trajectories\n    # in output_dir.\n    if trajectory_dump_dir is None:\n      trajectory_dump_dir = os.path.join(output_dir, \'trajectories\')\n    self._trajectory_dump_root_dir = trajectory_dump_dir\n\n    self._initial_trajectory_dir = initial_trajectory_dir\n    self._initial_trajectory_mix_prob = initial_trajectory_mix_prob\n\n    self._summary_writer = jaxboard.SummaryWriter(self._output_dir)\n\n    self._simple_epoch = 0\n    self._policy_epoch = 0\n    self._model_train_step = 0\n\n  @property\n  def policy_trainer(self):\n    if self._policy_trainer is None:\n      self._policy_trainer = self._policy_trainer_fn()\n    return self._policy_trainer\n\n  @property\n  def epoch(self):\n    return self._simple_epoch\n\n  def train_epoch(self, evaluate=True):\n    if self._simple_epoch > 0 or not self._has_initial_data:\n      logging.info(\n          \'Collect trajectories by running the policy in the real environment.\')\n      self.collect_trajectories(evaluate=evaluate)\n    if self._simple_epoch > 0 or not self._initial_model:\n      logging.info(\n          \'Train the model of the environment on the collected trajectories.\')\n      skipped = self.train_model()\n      if evaluate and not skipped:\n        logging.info(\'Evaluate the trained model.\')\n        self.evaluate_model()\n    logging.info(\'Train the policy inside the simulated environment generated \'\n                 \'by the model.\')\n    self.train_policy()\n\n    self._simple_epoch += 1\n\n  def evaluate(self):\n    self.policy_trainer.evaluate()\n\n  def maybe_save(self):\n    return True\n\n  def save(self):\n    # Nothing to do, as we save stuff continuously.\n    pass\n\n  def flush_summaries(self):\n    self._summary_writer.flush()\n\n  def collect_trajectories(self, evaluate):\n    logging.info(\'SimPLe epoch [% 6d]: collecting data.\', self._simple_epoch)\n    start_time = time.time()\n\n    self.policy_trainer.train_env = self.train_env\n    self.policy_trainer.trajectory_dump_dir = os.path.join(\n        self._trajectory_dump_root_dir, str(self.epoch))\n    self._policy_epoch += self._n_real_epochs\n    self.policy_trainer.training_loop(self._policy_epoch, evaluate=evaluate)\n\n    logging.vlog(\n        1, \'Collecting trajectories took %0.2f sec.\', time.time() - start_time)\n\n  def train_model(self):\n    """"""Train the model.\n\n    Returns:\n      whether the training was skipped due to a restart.\n    """"""\n    logging.info(\'SimPLe epoch [% 6d]: training model.\', self._simple_epoch)\n    start_time = time.time()\n\n    (train_stream, eval_stream) = self._make_input_streams()\n    # Ignore n_devices for now.\n    inputs = trax_inputs.Inputs(\n        train_stream=(lambda _: train_stream),\n        eval_stream=(lambda _: eval_stream)\n    )\n    (obs, act, _, _) = next(train_stream)\n    # TODO(pkozakowski): Refactor Inputs so this can be inferred correctly.\n    inputs._input_shape = (tuple(obs.shape)[1:], tuple(act.shape)[1:])  # pylint: disable=protected-access\n    inputs._input_dtype = (obs.dtype, act.dtype)  # pylint: disable=protected-access\n\n    if self._simple_epoch == 0:\n      train_steps = self._n_model_initial_train_steps\n    else:\n      train_steps = self._n_model_train_steps_per_epoch\n    self._model_train_step += train_steps\n    with gin.config_scope(\'world_model\'):\n      state = trainer_lib.train(\n          model=self._sim_env.model,\n          inputs=inputs,\n          steps=self._model_train_step,\n          output_dir=self._model_dir,\n      )\n\n    logging.vlog(\n        1, \'Training model took %0.2f sec.\', time.time() - start_time)\n    return state.step > self._model_train_step\n\n  def train_policy(self):\n    logging.info(\'SimPLe epoch [% 6d]: training policy.\', self._simple_epoch)\n    start_time = time.time()\n\n    self._sim_env.initialize(\n        batch_size=self._simulated_batch_size,\n        history_stream=itertools.repeat(None),\n    )\n    # We never want async mode in the simulated env.\n    original_async_mode = self.policy_trainer.async_mode\n    self.policy_trainer.async_mode = False\n    self.policy_trainer.train_env = self._sim_env\n    # Don\'t dump trajectories from the simulated environment.\n    self.policy_trainer.trajectory_dump_dir = None\n    self._policy_epoch += self._n_simulated_epochs\n\n    # After the first world model training, reinitialize the policy from the\n    # world model parameters if requested.\n    if self._simple_epoch == 0 and self._init_policy_from_world_model:\n      self.policy_trainer.init_policy_from_world_model_output_dir = (\n          self._model_dir\n      )\n      self.policy_trainer.reset(output_dir=self._policy_dir)\n\n    self.policy_trainer.training_loop(self._policy_epoch, evaluate=False)\n    # Revert back to the original async mode in the policy trainer.\n    self.policy_trainer.async_mode = original_async_mode\n\n    logging.vlog(\n        1, \'Training policy took %0.2f sec.\', time.time() - start_time)\n\n  @property\n  def _has_own_data(self):\n    return self._simple_epoch > 0 or self._initial_trajectory_dir is None\n\n  @property\n  def _has_initial_data(self):\n    return self._initial_trajectory_dir is not None\n\n  def _load_trajectories(self, initial):\n    # Cache the initial trajectories in memory, as loading them can take a lot\n    # of time and they don\'t change.\n    if initial:\n      if self._initial_trajectories is not None:\n        return self._initial_trajectories\n      trajectory_dir = self._initial_trajectory_dir\n    else:\n      trajectory_dir = self._trajectory_dump_root_dir\n\n    trajectories = simple.load_trajectories(\n        trajectory_dir, self._data_eval_frac\n    )\n\n    if initial:\n      self._initial_trajectories = trajectories\n    return trajectories\n\n  def _make_input_streams(self):\n    def make_example_streams(initial):\n      (train_trajs, eval_trajs) = self._load_trajectories(initial)\n      generate_examples = functools.partial(\n          simple.generate_examples,\n          trajectory_to_training_examples_fn=(\n              self._sim_env.trajectory_to_training_examples),\n      )\n      return tuple(map(generate_examples, (train_trajs, eval_trajs)))\n\n    # We mix two data sources: trajectories collected in this SimPLe training\n    # loop (""own"" data) and trajectories collected before, outside of this\n    # training loop (""initial"" data).\n    mix_prob = self._initial_trajectory_mix_prob\n\n    if self._has_initial_data:\n      start_time = time.time()\n      # Load the initial, precollected data.\n      (init_train_stream, init_eval_stream) = make_example_streams(initial=True)\n      logging.vlog(\n          1, \'Loading initial trajectories took %0.2f sec.\',\n          time.time() - start_time\n      )\n    else:\n      (init_train_stream, init_eval_stream) = (None, None)\n      mix_prob = 0.0  # Take just our own collected data.\n\n    if self._has_own_data:\n      start_time = time.time()\n      # Load trajectories collected in all epochs so far.\n      (own_train_stream, own_eval_stream) = make_example_streams(initial=False)\n      logging.vlog(\n          1, \'Loading own trajectories took %0.2f sec.\',\n          time.time() - start_time\n      )\n    else:\n      # We start the loop with training the model, so we don\'t have our own\n      # collected data yet.\n      (own_train_stream, own_eval_stream) = (None, None)\n      mix_prob = 1.0  # Take just the initial data.\n\n    def mix_and_batch(streams):\n      (init_stream, own_stream) = streams\n      mixed_stream = simple.mix_streams(init_stream, own_stream, mix_prob)\n      return simple.batch_stream(mixed_stream, self._model_train_batch_size)\n\n    return tuple(\n        map(mix_and_batch, (\n            (init_train_stream, own_train_stream),\n            (init_eval_stream, own_eval_stream),\n        )))\n\n  def evaluate_model(self):\n    logging.info(\'SimPLe epoch [% 6d]: evaluating model.\', self._simple_epoch)\n    start_time = time.time()\n\n    self._sim_env.initialize(\n        batch_size=self._simulated_batch_size,\n        history_stream=itertools.repeat(None),\n    )\n\n    (_, eval_trajectories) = self._load_trajectories(\n        # If we have any trajectories collected in this run, evaluate on them.\n        # Otherwise, use the initial dataset.\n        initial=(not self._has_own_data)\n    )\n    chosen_trajectories = [\n        random.choice(eval_trajectories)\n        for _ in range(self._sim_env.batch_size)\n    ]\n    summaries = simple.evaluate_model(self._sim_env, chosen_trajectories, plt)\n    if summaries is not None:\n      for (name, value) in summaries.items():\n        self._summary_writer.scalar(\n            \'simple/{}\'.format(name), value, step=self._simple_epoch)\n      self._summary_writer.plot(\n          \'simple/model_eval_plot\', plt, step=self._simple_epoch)\n      self.flush_summaries()\n\n    logging.vlog(\n        1, \'Evaluating model took %0.2f sec.\', time.time() - start_time)\n'"
trax/rl/simple_trainer_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.rl.simple_trainer.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\n\nimport gin\n\nfrom tensor2tensor.envs import gym_env_problem\nfrom tensor2tensor.rl import gym_utils\nfrom tensorflow import test\nfrom trax import models\nfrom trax.rl import envs  # pylint: disable=unused-import\nfrom trax.rl import simulated_env_problem\nfrom trax.rl import trainers\n\n\nclass SimpleTrainerTest(test.TestCase):\n\n  def _make_wrapped_env(self, name, max_episode_steps=2):\n    wrapper_fn = functools.partial(\n        gym_utils.gym_env_wrapper,\n        **{\n            \'rl_env_max_episode_steps\': max_episode_steps,\n            \'maxskip_env\': False,\n            \'rendered_env\': False,\n            \'rendered_env_resize_to\': None,  # Do not resize frames\n            \'sticky_actions\': False,\n            \'output_dtype\': None,\n            \'num_actions\': None,\n        })\n\n    return gym_env_problem.GymEnvProblem(base_env_name=name,\n                                         batch_size=2,\n                                         env_wrapper_fn=wrapper_fn,\n                                         discrete_rewards=False)\n\n  def test_training_loop_acrobot(self):\n    gin.bind_parameter(\'BoxSpaceSerializer.precision\', 2)\n    gin.bind_parameter(\'trainer_lib.train.eval_steps\', 1)\n    trainer = trainers.SimPLe(\n        train_env=self._make_wrapped_env(\'Acrobot-v1\'),\n        eval_env=self._make_wrapped_env(\'Acrobot-v1\'),\n        output_dir=self.get_temp_dir(),\n        policy_trainer_class=functools.partial(\n            trainers.PPO,\n            policy_and_value_model=functools.partial(\n                models.FrameStackMLP,\n                n_frames=1,\n                hidden_sizes=(),\n                output_size=1,\n            ),\n            n_optimizer_steps=1,\n        ),\n        n_real_epochs=1,\n        data_eval_frac=0.5,\n        model_train_batch_size=2,\n        n_model_initial_train_steps=1,\n        n_model_train_steps_per_epoch=1,\n        simulated_env_problem_class=functools.partial(\n            simulated_env_problem.SerializedSequenceSimulatedEnvProblem,\n            model=functools.partial(\n                models.TransformerLM,\n                d_model=2,\n                n_layers=0,\n                max_len=64,\n            ),\n            reward_fn=simulated_env_problem.acrobot_reward_fn,\n            done_fn=simulated_env_problem.acrobot_done_fn,\n            vocab_size=4,\n            max_trajectory_length=4,\n        ),\n        simulated_batch_size=2,\n        n_simulated_epochs=1,\n    )\n    trainer.training_loop(n_epochs=1)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/simulated_env_problem.py,25,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""EnvProblem for environments simulated by a Trax model.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nimport random\n\nimport jax\nimport numpy as np\n\nfrom tensor2tensor.envs import env_problem\nfrom trax import layers as tl\nfrom trax import math\nfrom trax.math import random as jax_random\nfrom trax.rl import serialization_utils\nfrom trax.rl import space_serializer\nfrom trax.shapes import ShapeDtype\nfrom trax.supervised import trainer_lib\n\n\nclass SimulatedEnvProblem(env_problem.EnvProblem):\n  """"""EnvProblem base class for environments simulated by Trax models.\n\n  The initial observations to start the model are taken from\n  initial_observation_stream. This iterator in incremented in every reset().\n\n  A checkpoint saved by the Trax trainer should be available in output_dir.\n  """"""\n\n  def __init__(self, model, batch_size, observation_space, action_space,\n               reward_range, discrete_rewards, history_stream, output_dir,\n               model_predict_kwargs=None):\n    """"""Initializes the env.\n\n    Args:\n      model: Trax model.\n      batch_size: (int) Number of simulated environments run in parallel.\n      observation_space: (gym.Space) Observation space.\n      action_space: (gym.Space) Action space.\n      reward_range: (tuple) Pair (min_reward, max_reward).\n      discrete_rewards: (bool) Whether to discretize the rewards.\n      history_stream: Iterator yielding batches of initial input data for the\n        model. The format is implementation-specific.\n      output_dir: (str) Output dir.\n      model_predict_kwargs: (dict) Additional model keyword arguments for\n        inference. Useful when different config is needed for training and\n        inference, e.g. train with memory efficient attention and predict with\n        the regular one.\n    """"""\n    self._model = model\n    if model_predict_kwargs is None:\n      model_predict_kwargs = {}\n    model_predict = self._model(mode=\'predict\', **model_predict_kwargs)\n    # NOTE: can set non-default PRNG key: model_predict.rng = given_prng_key\n    self._model_predict = math.jit(model_predict.pure_fn)\n    self._model_initialize = model_predict.init\n    self._init_model_weights = None\n    self._init_model_state = None\n\n    self._observation_space = observation_space\n    self._action_space = action_space\n    self._reward_range = reward_range\n    self._output_dir = output_dir\n\n    self._predict_fn = None\n    self._rng = None\n    self._model_state = None\n    self._history_stream = None\n\n    # Call the super\'s ctor. It will use some of the member fields, so we call\n    # it in the end.\n    super(SimulatedEnvProblem, self).__init__(\n        batch_size=batch_size,\n        discrete_rewards=discrete_rewards,\n        history_stream=history_stream,\n    )\n\n    self.seed()\n\n  def initialize_environments(self,\n                              history_stream,\n                              batch_size=1,\n                              parallelism=1):\n    """"""Initializes the environments.\n\n    Args:\n      history_stream: Iterator yielding batches of initial input data for the\n        model. The format is implementation-specific.\n      batch_size: (int) Number of environments in a batch.\n      parallelism: (int) Unused.\n    """"""\n    del parallelism\n\n    if self._output_dir is None:\n      model_weights = self._init_model_weights\n      self._model_state = None\n    else:\n      trax_state = trainer_lib.load_trainer_state(self._output_dir)\n      # TODO(lukaszkaiser): both model state and parameters by default include\n      # the loss layer. Currently, we access the pure-model parameters by just\n      # indexing, [0] here. But we should make it more explicit in a better API.\n      model_weights = self._extract_weights(trax_state.opt_state.weights[0])\n      self._model_state = trax_state.model_state[0]\n\n    def predict_fn(inputs, rng):\n      (output, self._model_state) = self._model_predict(\n          inputs, model_weights, self._model_state, rng)\n      return output\n\n    self._predict_fn = predict_fn\n    self._history_stream = history_stream\n    self._steps = np.zeros(batch_size, dtype=np.int32)\n\n  def _extract_weights(self, weights):\n    return weights\n\n  @property\n  def observation_space(self):\n    return self._observation_space\n\n  @property\n  def action_space(self):\n    return self._action_space\n\n  @property\n  def reward_range(self):\n    return self._reward_range\n\n  def seed(self, seed=None):\n    if seed is None:\n      seed = random.randint(0, 2**31 - 1)\n    self._rng = jax_random.get_prng(seed)\n    return super(SimulatedEnvProblem, self).seed(seed=seed)\n\n  def _reset_model(self, predict_fn, indices, history, rng):\n    """"""Resets the environments at the given indices.\n\n    Should be implemented in subclasses.\n\n    Args:\n      predict_fn: Function running prediction with the model.\n      indices: List of indices of underlying envs to call reset on.\n      history: Initial input data for the model.\n      rng: Jax RNG.\n\n    Returns:\n      np.ndarray of batched observations from the reset envs.\n    """"""\n    raise NotImplementedError\n\n  def _step_model(self, predict_fn, actions, rng):\n    """"""Takes a step in all environments.\n\n    Should be implemented in subclasses.\n\n    Args:\n      predict_fn: Function running prediction with the model.\n      actions: (np.ndarray) with first dimension equal to the batch size.\n      rng: Jax RNG.\n\n    Returns:\n      a tuple of batched raw observations, rewards and dones.\n    """"""\n    raise NotImplementedError\n\n  def trajectory_to_training_examples(self, trajectory):\n    raise NotImplementedError\n\n  def _reset(self, indices):\n    """"""Resets environments at the given indices.\n\n    Args:\n      indices: list of indices of underlying envs to call reset on.\n\n    Returns:\n      np.ndarray of batched observations from the reset envs.\n    """"""\n    history = next(self._history_stream)\n    (subrng, self._rng) = jax_random.split(self._rng)\n    return self._reset_model(self._predict_fn, indices, history, subrng)\n\n  def _step(self, actions):\n    """"""Takes a step in all environments.\n\n    Args:\n      actions: (np.ndarray) with first dimension equal to the batch size.\n\n    Returns:\n      a tuple of batched raw observations, raw rewards, dones and infos.\n    """"""\n    # Predict the next observation.\n    (subrng, self._rng) = jax_random.split(self._rng)\n    (observation, reward, done) = self._step_model(\n        self._predict_fn, actions, subrng)\n    return (observation, reward, done, {})\n\n  @property\n  def model(self):\n    return lambda mode: serialization_utils.SerializedModel(  # pylint: disable=g-long-lambda\n        seq_model=self._model(mode=mode),\n        observation_serializer=self._obs_serializer,\n        action_serializer=self._action_serializer,\n        significance_decay=self._significance_decay,\n    )\n\n\nclass RawSimulatedEnvProblem(SimulatedEnvProblem):\n  """"""SimulatedEnvProblem running a model operating on raw tensors.\n\n  Wraps an autoregressive trax model of signature\n  (observation_history, action) -> (observation, reward) in an EnvProblem.\n  The model is assumed to take a fixed number of last observations as input\n  and produce a single observation, which is fed back into the model in the\n  next environment step.\n\n  Shape requirements (without the batch dimension):\n    observation: Consistent with observation_space.\n    observation_history: (history_length,) + observation.shape.\n    action: Consistent with action_space.\n    reward: (1,). The singleton dimension is removed in step().\n  """"""\n\n  def __init__(self, history_length, trajectory_length, *args, **kwargs):\n    """"""Initializes the env.\n\n    Args:\n      history_length: (int) Number of last observations fed into the model.\n      trajectory_length: (int) Length of each trajectory unrolled from the\n        model.\n      *args: (tuple) Positional arguments passed to the base class.\n      **kwargs: (dict) Keyword arguments passed to the base class.\n    """"""\n    self._history_length = history_length\n    self._trajectory_length = trajectory_length\n    self._history = None\n    self._steps = None\n\n    super(RawSimulatedEnvProblem, self).__init__(*args, **kwargs)\n\n  def initialize_environments(self, batch_size=1, **kwargs):\n    """"""Initializes the environments.""""""\n    self._history = None\n    self._steps = np.zeros(batch_size)\n    return super(RawSimulatedEnvProblem, self).initialize_environments(\n        batch_size=batch_size, **kwargs)\n\n  def _reset_model(self, predict_fn, indices, history, rng):\n    del predict_fn\n    del rng\n    assert history.shape == ((self._batch_size, self._history_length) +\n                             self.observation_space.shape)\n\n    if self._history is None:\n      # At the first reset, all indices should be triggered.\n      assert set(indices) == set(range(self._batch_size))\n      self._history = np.array(history)\n    else:\n      history = history[indices, ...]\n      self._history[indices, ...] = history\n\n    # Reset the step counters.\n    self._steps[indices] = 0\n\n    # Return just the last timestep at the given indices.\n    return history[:, -1, ...]\n\n  def _step_model(self, predict_fn, actions, rng):\n    (observation, reward) = predict_fn((self._history, actions), rng=rng)\n\n    # Roll the history one timestep back and append the new observation.\n    self._history = np.roll(self._history, shift=-1, axis=1)\n    self._history[:, -1, ...] = observation\n\n    # Increment the step counters and determine which envs are done.\n    self._steps += 1\n    done = self._steps == self._trajectory_length\n\n    # Call copy() to get the data as numpy arrays.\n    observation = observation.copy()\n    # Reshape the rewards to get rid of the extra dimension.\n    reward = np.squeeze(reward.copy(), axis=1)\n    return (observation, reward, done)\n\n\nclass SerializedSequenceSimulatedEnvProblem(SimulatedEnvProblem):\n  """"""SimulatedEnvProblem running a model operating on sequences of symbols.\n\n  Wraps an autoregressive trax model of signature past_symbols -> symbol_probs\n  in an EnvProblem. The model is assumed to take a sequence of symbols as input\n  and produce distributions over all symbols in the sequence. The next symbol\n  is sampled and fed back to the model in the next decoding step.\n\n  Shape requirements (without the batch dimension):\n    past_symbols: (max_trajectory_length * L,)\n    symbol_probs: (max_trajectory_length * L, vocab_size)\n  where L is the representation length of one environment step.\n\n  Observations, actions, rewards and done flags are (de)serialized from/to\n  sequences of symbols using an EnvSerializer passed to the constructor.\n  """"""\n\n  def __init__(self, model, reward_fn, done_fn, vocab_size,\n               max_trajectory_length, observation_space, action_space,\n               significance_decay=1.0, **kwargs):\n    """"""Initializes the env.\n\n    Args:\n      model: trax model to use for simulation. It\'s assumed to take keyword\n        arguments vocab_size and mode, where vocab_size is the number of symbols\n        in the vocabulary and mode is either \'train\' or \'eval\'.\n\n      reward_fn: Function (previous_observation, current_observation) -> reward.\n      done_fn: Function (previous_observation, current_observation) -> done.\n      vocab_size: (int) Number of symbols in the vocabulary.\n      max_trajectory_length: (int) Maximum length of a trajectory unrolled from\n        the model.\n      observation_space: (gym.Space) Observation space.\n      action_space: (gym.Space) Action space.\n      significance_decay: (float) Decay for training weights of progressively\n        less significant symbols in the representation.\n      **kwargs: (dict) Keyword arguments passed to the base class.\n    """"""\n    self._reward_fn = reward_fn\n    self._done_fn = done_fn\n    self._vocab_size = vocab_size\n    self._max_trajectory_length = max_trajectory_length\n    self._significance_decay = significance_decay\n    self._steps = None\n    self._observation_space = None\n    self._action_space = None\n    self._last_observations = None\n\n    self._obs_serializer = space_serializer.create(\n        observation_space, self._vocab_size)\n    self._action_serializer = space_serializer.create(\n        action_space, self._vocab_size)\n    self._obs_repr_length = self._obs_serializer.representation_length\n    self._act_repr_length = self._action_serializer.representation_length\n    self._step_repr_length = self._obs_repr_length + self._act_repr_length\n\n    # We assume that the model takes vocab_size as an argument (e.g.\n    # TransformerLM).\n    model = functools.partial(model, vocab_size=vocab_size)\n    super(SerializedSequenceSimulatedEnvProblem, self).__init__(\n        model=model,\n        observation_space=observation_space,\n        action_space=action_space,\n        **kwargs\n    )\n\n  def initialize_environments(self, batch_size=1, **kwargs):\n    """"""Initializes the environments.""""""\n    self._steps = np.zeros(batch_size, dtype=np.int32)\n    self._last_observations = np.full(\n        (batch_size,) + self._observation_space.shape, np.nan)\n    self._last_symbols = np.zeros((batch_size, 1), dtype=np.int32)\n    input_signature = ShapeDtype((batch_size, 1), np.int32)\n    (self._init_model_weights, self._init_model_state) = self._model_initialize(\n        input_signature\n    )\n    super(SerializedSequenceSimulatedEnvProblem, self).initialize_environments(\n        batch_size=batch_size, **kwargs)\n    self._model_state = self._init_model_state\n\n  def _extract_weights(self, weights):\n    return serialization_utils.extract_inner_model(weights)\n\n  def _predict_obs(self, predict_fn, rng):\n    obs_repr = np.zeros(\n        (self._steps.shape[0], self._obs_repr_length), dtype=np.int32,\n    )\n    for (i, subrng) in enumerate(jax_random.split(rng, self._obs_repr_length)):\n      log_probs = predict_fn(self._last_symbols, rng=subrng)\n      self._last_symbols = tl.gumbel_sample(log_probs)\n      obs_repr[:, i] = self._last_symbols[:, 0]\n    return np.array(self._obs_serializer.deserialize(obs_repr))\n\n  def _consume_act(self, actions, predict_fn, rng):\n    act_repr = self._action_serializer.serialize(actions)\n    for (i, subrng) in enumerate(jax_random.split(rng, self._act_repr_length)):\n      # Run the network to update the inference buffers, but ignore the result.\n      predict_fn(self._last_symbols, rng=subrng)\n      self._last_symbols = act_repr[:, i:(i + 1)]\n\n  def _reset_model(self, predict_fn, indices, history, rng):\n    # TODO(pkozakowski): Random starts.\n    del history\n\n    indices = np.array(indices)\n\n    # During reset, we need to predict the first observation for a subset of\n    # indices, however inference only works for the full set of indices. To\n    # workaround that:\n    # 1. Save prior inference state.\n    old_model_state = self._model_state\n    old_last_symbols = self._last_symbols\n    # 2. Reset the entire inference state.\n    self._model_state = self._init_model_state\n    self._last_symbols[:] = 0\n    # 3. Predict the next observation.\n    observation = self._predict_obs(predict_fn, rng)[indices]\n    self._last_observations[indices] = observation\n\n    # TODO(pkozakowski): Abstract out this primitive e.g. as\n    # trax.math.nested_zip_with?\n    def reset_recursively(current_state, init_state):\n      """"""Resets the initial state, assuming it\'s batched by trajectories.""""""\n      if isinstance(current_state, (list, tuple)):\n        return [\n            reset_recursively(current, init)\n            for (current, init) in zip(current_state, init_state)\n        ]\n      elif isinstance(current_state, dict):\n        return {\n            key: reset_recursively(current_state[key], init_state[key])\n            for key in current_state\n        }\n      else:\n        # current_state might just be a scalar primitive, check.\n        if (getattr(current_state, \'shape\', ()) and\n            current_state.shape[0] == self._batch_size):\n          # If the state component is batched, substitute it on appropriate\n          # indices.\n          # This doesn\'t work with more than one head in attention layers,\n          # because the batch dimension gets multiplied by the number of heads.\n          # TODO(pkozakowski): Fix that in trax.layes.attention.\n          return jax.ops.index_update(\n              current_state, jax.ops.index[indices], init_state[indices]\n          )\n        else:\n          # Otherwise, leave as it is.\n          return current_state\n\n    # 4. Assign back the old inference state, updated on the appropriate\n    # indices.\n    self._model_state = reset_recursively(old_model_state, self._model_state)\n    old_last_symbols[indices] = self._last_symbols[indices]\n    self._last_symbols = old_last_symbols\n    self._steps[indices] = 0\n    return observation\n\n  def _step_model(self, predict_fn, actions, rng):\n    self._consume_act(actions, predict_fn, rng)\n    self._steps += 1\n    observation = self._predict_obs(predict_fn, rng)\n    reward = self._reward_fn(self._last_observations, observation)\n    done = self._done_fn(self._last_observations, observation)\n    # Copy the last observations, so that we don\'t overwrite data stored in a\n    # trajectory when resetting the environment (see _reset_model).\n    self._last_observations = np.copy(observation)\n    done = np.logical_or(done, self._steps == self._max_trajectory_length - 1)\n    return (observation, reward, done)\n\n  def trajectory_to_training_examples(self, trajectory):\n    padding_length = self._max_trajectory_length - trajectory.num_time_steps\n    def pad(x):\n      pad_width = [(0, padding_length)] + [(0, 0)] * (x.ndim - 1)\n      return np.pad(x, pad_width=pad_width, mode=\'constant\')\n    obs = pad(trajectory.observations_np)\n    act = pad(trajectory.actions_np)\n    mask = np.zeros_like(obs)\n    mask[:trajectory.num_time_steps, ...] = 1\n    return [(obs, act, obs, mask)]\n\n\ndef cartpole_done_fn(previous_observation, current_observation):\n  del previous_observation\n  x_threshold = 2.4\n  theta_threshold = 12 * 2 * np.pi / 360\n  x = current_observation[:, 0]\n  theta = current_observation[:, 2]\n  return np.logical_or(np.abs(x) > x_threshold, np.abs(theta) > theta_threshold)\n\n\ndef cartpole_reward_fn(previous_observation, current_observation):\n  done = cartpole_done_fn(previous_observation, current_observation)\n  return 1.0 - done  # Unit reward for every timestep until the end.\n\n\ndef acrobot_done_fn(previous_observation, current_observation):\n  del previous_observation\n  theta1 = current_observation[:, 0]\n  theta2 = current_observation[:, 1]\n  return -np.cos(theta1) - np.cos(theta2 + theta1) > 1.0\n\n\ndef acrobot_reward_fn(previous_observation, current_observation):\n  done = acrobot_done_fn(previous_observation, current_observation)\n  return -1.0 + done  # -1 reward for every timestep until the end.\n\n\ndef onlinetune_done_fn(previous_observation, current_observation):\n  del previous_observation\n  del current_observation\n  # Never return ""done"" from the environment, rely on max_trajectory_length\n  # instead.\n  return False\n\n\ndef onlinetune_reward_fn(\n    previous_observation,\n    current_observation,\n    # 2 is the evaluation accuracy metric in the default settings of\n    # OnlineTuneEnv.\n    dim_index=2,\n):\n  prev = previous_observation[:, dim_index]\n  cur = current_observation[:, dim_index]\n  return cur - prev\n'"
trax/rl/simulated_env_problem_test.py,14,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.rl.simulated_env_problem.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nimport itertools\n\nimport gym\nimport mock\nimport numpy as np\n\nfrom tensor2tensor.envs import trajectory\nfrom tensorflow import test\nfrom trax import math\nfrom trax.layers import base\nfrom trax.models import transformer\nfrom trax.rl import simulated_env_problem\nfrom trax.supervised import trainer_lib\n\n\nclass RawSimulatedEnvProblemTest(test.TestCase):\n\n  @staticmethod\n  @mock.patch.object(trainer_lib, \'load_trainer_state\', autospec=True)\n  def _create_env(mock_restore_state, model, histories,\n                  trajectory_length):\n    # (model_params, opt_state)\n    mock_restore_state.return_value.params = (None, None)\n    space = gym.spaces.Discrete(100)\n    return simulated_env_problem.RawSimulatedEnvProblem(\n        model=model,\n        history_length=histories.shape[2],\n        trajectory_length=trajectory_length,\n        batch_size=1,\n        observation_space=space,\n        action_space=space,\n        reward_range=(-1, 1),\n        discrete_rewards=True,\n        history_stream=iter(histories),\n        output_dir=None,\n    )\n\n  def test_takes_new_history(self):\n    histories = np.array([[[0, 1, 2]], [[3, 4, 5]]])\n\n    mock_model_fn = mock.MagicMock()\n    mock_model_fn.return_value.init.return_value = (None, None)\n\n    with math.use_backend(\'numpy\'):\n      env = self._create_env(  # pylint: disable=no-value-for-parameter\n          model=mock_model_fn,\n          histories=histories,\n          trajectory_length=2,\n      )\n      env.reset()\n      observation = env.reset()\n      np.testing.assert_array_equal(observation, [5])\n\n\nclass SerializedSequenceSimulatedEnvProblemTest(test.TestCase):\n\n  def _make_env(\n      self, observation_space, action_space, vocab_size,\n      predict_fn=None, reward_fn=None, done_fn=None,\n      batch_size=None, max_trajectory_length=None,\n  ):\n    mock_model_fn = mock.MagicMock()\n    mock_model_fn.return_value.init.return_value = (None, None)\n    if predict_fn is not None:\n      mock_model_fn.return_value = predict_fn\n      mock_model_fn.return_value.init.return_value = (\n          base.EMPTY_WEIGHTS, base.EMPTY_STATE)\n    return simulated_env_problem.SerializedSequenceSimulatedEnvProblem(\n        model=mock_model_fn,\n        reward_fn=reward_fn,\n        done_fn=done_fn,\n        vocab_size=vocab_size,\n        max_trajectory_length=max_trajectory_length,\n        batch_size=batch_size,\n        observation_space=observation_space,\n        action_space=action_space,\n        reward_range=(-1, 1),\n        discrete_rewards=False,\n        history_stream=itertools.repeat(None),\n        output_dir=None,\n    )\n\n  def _make_trajectory(self, observations, actions):\n    assert len(observations) == len(actions) + 1\n    t = trajectory.Trajectory()\n    for (obs, act) in zip(observations, actions):\n      t.add_time_step(observation=obs, action=act, done=False)\n    t.add_time_step(observation=observations[-1], done=True)\n    return t\n\n  def test_runs_with_transformer(self):\n    env = simulated_env_problem.SerializedSequenceSimulatedEnvProblem(\n        model=functools.partial(\n            transformer.TransformerLM, d_model=2, d_ff=2, n_heads=1, n_layers=1\n        ),\n        reward_fn=(lambda _1, _2: np.array([0.5])),\n        done_fn=(lambda _1, _2: np.array([False])),\n        vocab_size=4,\n        max_trajectory_length=3,\n        batch_size=1,\n        observation_space=gym.spaces.Box(low=0, high=5, shape=(4,)),\n        action_space=gym.spaces.Discrete(n=2),\n        reward_range=(-1, 1),\n        discrete_rewards=False,\n        history_stream=itertools.repeat(None),\n        output_dir=None,\n    )\n\n    env.reset()\n    for expected_done in [False, True]:\n      (_, _, dones, _) = env.step(np.array([0]))\n      np.testing.assert_array_equal(dones, [expected_done])\n\n  def test_makes_training_example(self):\n    env = self._make_env(\n        vocab_size=2,\n        observation_space=gym.spaces.Discrete(2),\n        action_space=gym.spaces.Discrete(2),\n        max_trajectory_length=3,\n    )\n    t = self._make_trajectory(observations=[0, 1, 0], actions=[1, 0])\n    examples = env.trajectory_to_training_examples(t)\n\n    # There should be 1 example with the whole trajectory.\n    self.assertEqual(len(examples), 1)\n    [(input_obs, input_act, target_obs, weights)] = examples\n    np.testing.assert_array_equal(input_obs, [0, 1, 0])\n    np.testing.assert_array_equal(input_act, [1, 0])\n    # inputs == targets for autoregressive sequence prediction.\n    np.testing.assert_array_equal(input_obs, target_obs)\n    np.testing.assert_array_equal(weights, [1.0, 1.0, 1.0])\n\n  def test_makes_training_example_padded(self):\n    env = self._make_env(\n        vocab_size=2,\n        observation_space=gym.spaces.Discrete(2),\n        action_space=gym.spaces.Discrete(2),\n        max_trajectory_length=4,\n    )\n    t = self._make_trajectory(observations=[0, 1, 0], actions=[1, 0])\n    examples = env.trajectory_to_training_examples(t)\n    [(input_obs, input_act, target_obs, weights)] = examples\n    # Should pad by 1 on the right.\n    np.testing.assert_array_equal(input_obs, [0, 1, 0, 0])\n    np.testing.assert_array_equal(input_act, [1, 0, 0])\n    # inputs == targets for autoregressive sequence prediction.\n    np.testing.assert_array_equal(input_obs, target_obs)\n    # The last timestep should be masked out.\n    np.testing.assert_array_equal(weights, [1.0, 1.0, 1.0, 0.0])\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/space_serializer.py,21,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Serialization of elements of Gym spaces into discrete sequences.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport copy\n\nfrom absl import logging\nimport gin\nimport gym\nfrom jax import numpy as np\n\n\nclass SpaceSerializer(object):\n  """"""Base class for Gym space serializers.\n\n  Attrs:\n    space_type: (type) Gym space class that this SpaceSerializer corresponds\n      to. Should be defined in subclasses.\n    representation_length: (int) Number of symbols in the representation of\n      every element of the space.\n    significance_map: (np.ndarray) Integer array of the same size as the\n      discrete representation, where elements describe the significance of\n      symbols, e.g. in fixed-precision encoding. 0 is the most significant\n      symbol, 1 the second most significant etc.\n  """"""\n\n  space_type = None\n  representation_length = None\n  significance_map = None\n\n  def __init__(self, space, vocab_size):\n    """"""Creates a SpaceSerializer.\n\n    Subclasses should retain the signature.\n\n    Args:\n      space: (gym.Space) Gym space of type self.space_type.\n      vocab_size: (int) Number of symbols in the vocabulary.\n    """"""\n    assert isinstance(space, self.space_type)\n    self._space = space\n    self._vocab_size = vocab_size\n\n  def serialize(self, data):\n    """"""Serializes a batch of space elements into discrete sequences.\n\n    Should be defined in subclasses.\n\n    Args:\n      data: A batch of batch_size elements of the Gym space to be serialized.\n\n    Returns:\n      int32 array of shape (batch_size, self.representation_length).\n    """"""\n    raise NotImplementedError\n\n  def deserialize(self, representation):\n    """"""Deserializes a batch of discrete sequences into space elements.\n\n    Should be defined in subclasses.\n\n    Args:\n      representation: int32 Numpy array of shape\n        (batch_size, self.representation_length) to be deserialized.\n\n    Returns:\n      A batch of batch_size deserialized elements of the Gym space.\n    """"""\n    raise NotImplementedError\n\n\ndef create(space, vocab_size):\n  """"""Creates a SpaceSerializer for the given Gym space.""""""\n  return {\n      gym.spaces.Box: BoxSpaceSerializer,\n      gym.spaces.Discrete: DiscreteSpaceSerializer,\n      gym.spaces.MultiDiscrete: MultiDiscreteSpaceSerializer,\n  }[type(space)](space, vocab_size)\n\n\n@gin.configurable(blacklist=[\'space\', \'vocab_size\'])\nclass BoxSpaceSerializer(SpaceSerializer):\n  """"""Serializer for gym.spaces.Box.\n\n  Assumes that the space is bounded. Internally rescales it to the [0, 1]\n  interval and uses a fixed-precision encoding.\n  """"""\n\n  space_type = gym.spaces.Box\n\n  def __init__(self, space, vocab_size, precision=2, max_range=(-100.0, 100.0)):\n    self._precision = precision\n\n    # Some gym envs (e.g. CartPole) have unreasonably high bounds for\n    # observations. We clip so we can represent them.\n    bounded_space = copy.copy(space)\n    (min_low, max_high) = max_range\n    bounded_space.low = np.maximum(space.low, min_low)\n    bounded_space.high = np.minimum(space.high, max_high)\n    if (not np.allclose(bounded_space.low, space.low) or\n        not np.allclose(bounded_space.high, space.high)):\n      logging.warning(\n          \'Space limits %s, %s out of bounds %s. Clipping to %s, %s.\',\n          str(space.low), str(space.high), str(max_range),\n          str(bounded_space.low), str(bounded_space.high)\n      )\n\n    super(BoxSpaceSerializer, self).__init__(bounded_space, vocab_size)\n\n  def serialize(self, data):\n    array = data\n    batch_size = array.shape[0]\n    array = (array - self._space.low) / (self._space.high - self._space.low)\n    array = np.clip(array, 0, 1)\n    digits = []\n    for digit_index in range(-1, -self._precision - 1, -1):\n      threshold = self._vocab_size ** digit_index\n      digit = np.array(array / threshold).astype(np.int32)\n      # For the corner case of x == high.\n      digit = np.where(digit == self._vocab_size, digit - 1, digit)\n      digits.append(digit)\n      array -= digit * threshold\n    digits = np.stack(digits, axis=-1)\n    return np.reshape(digits, (batch_size, -1))\n\n  def deserialize(self, representation):\n    digits = representation\n    batch_size = digits.shape[0]\n    digits = np.reshape(digits, (batch_size, -1, self._precision))\n    array = np.zeros(digits.shape[:-1])\n    for digit_index_in_seq in range(self._precision):\n      digit_index = -digit_index_in_seq - 1\n      array += self._vocab_size ** digit_index * digits[..., digit_index_in_seq]\n    array = np.reshape(array, (batch_size,) + self._space.shape)\n    return array * (self._space.high - self._space.low) + self._space.low\n\n  @property\n  def representation_length(self):\n    return self._precision * self._space.low.size\n\n  @property\n  def significance_map(self):\n    return np.reshape(np.broadcast_to(\n        np.arange(self._precision), self._space.shape + (self._precision,)), -1)\n\n\nclass DiscreteSpaceSerializer(SpaceSerializer):\n  """"""Serializer for gym.spaces.Discrete.\n\n  Assumes that the size of the space fits in the number of symbols.\n  """"""\n\n  space_type = gym.spaces.Discrete\n  representation_length = 1\n\n  def __init__(self, space, vocab_size):\n    super(DiscreteSpaceSerializer, self).__init__(space, vocab_size)\n    assert space.n <= vocab_size, (\n        \'Discrete space size should fit in the number of symbols.\')\n\n  def serialize(self, data):\n    return np.reshape(data, (-1, 1)).astype(np.int32)\n\n  def deserialize(self, representation):\n    return np.reshape(representation, -1)\n\n  @property\n  def significance_map(self):\n    return np.zeros(1, dtype=np.int32)\n\n\nclass MultiDiscreteSpaceSerializer(SpaceSerializer):\n  """"""Serializer for gym.spaces.MultiDiscrete.\n\n  Assumes that the number of categories in each dimension fits in the number of\n  symbols.\n  """"""\n\n  space_type = gym.spaces.MultiDiscrete\n\n  def __init__(self, space, vocab_size):\n    super(MultiDiscreteSpaceSerializer, self).__init__(space, vocab_size)\n    assert np.max(space.nvec) <= vocab_size, (\n        \'MultiDiscrete maximum number of categories should fit in the number \'\n        \'of symbols.\'\n    )\n\n  def serialize(self, data):\n    return data.astype(np.int32)\n\n  def deserialize(self, representation):\n    return representation\n\n  @property\n  def representation_length(self):\n    return len(self._space.nvec)\n\n  @property\n  def significance_map(self):\n    return np.zeros(self.representation_length, dtype=np.int32)\n'"
trax/rl/space_serializer_test.py,16,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.rl.space_serializer.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport gin\nimport gym\nimport numpy as np\nfrom tensorflow import test\nfrom trax.rl import space_serializer\n\n\nclass BoxSpaceSerializerTest(test.TestCase):\n\n  def _make_space_and_serializer(\n      self, low=-10, high=10, shape=(2,),\n      # Weird vocab_size to test that it doesn\'t only work with powers of 2.\n      vocab_size=257,\n      # Enough precision to represent float32s accurately.\n      precision=4,\n  ):\n    gin.bind_parameter(\'BoxSpaceSerializer.precision\', precision)\n    space = gym.spaces.Box(low=low, high=high, shape=shape)\n    serializer = space_serializer.create(space, vocab_size=vocab_size)\n    return (space, serializer)\n\n  def _sample_batch(self, space):\n    return np.reshape(space.sample(), (1,) + space.shape)\n\n  def test_representation_length(self):\n    (space, serializer) = self._make_space_and_serializer()\n    input_array = self._sample_batch(space)\n    representation = serializer.serialize(input_array)\n    self.assertEqual(\n        representation.shape, (1, serializer.representation_length))\n\n  def test_commutes(self):\n    (space, serializer) = self._make_space_and_serializer()\n    input_array = self._sample_batch(space)\n    representation = serializer.serialize(input_array)\n    output_array = serializer.deserialize(representation)\n    # Testing till 5 decimals to reduce flakyness.\n    np.testing.assert_array_almost_equal(input_array, output_array, decimal=5)\n\n  def test_representation_changes(self):\n    (space, serializer) = self._make_space_and_serializer()\n    array1 = self._sample_batch(space)\n    array2 = -array1\n    (repr1, repr2) = tuple(map(serializer.serialize, (array1, array2)))\n    self.assertFalse(np.array_equal(repr1, repr2))\n\n  def test_bounds_space(self):\n    gin.bind_parameter(\'BoxSpaceSerializer.max_range\', (-10.0, 10.0))\n    (_, serializer) = self._make_space_and_serializer(\n        # Too wide range to represent, need to clip.\n        low=-1e18, high=1e18,\n        shape=(1,))\n    input_array = np.array([[1.2345]])\n    representation = serializer.serialize(input_array)\n    output_array = serializer.deserialize(representation)\n    np.testing.assert_array_almost_equal(input_array, output_array)\n\n  def test_significance_map(self):\n    (_, serializer) = self._make_space_and_serializer(shape=(2,))\n    np.testing.assert_array_equal(\n        serializer.significance_map, [0, 1, 2, 3, 0, 1, 2, 3])\n\n  def test_serializes_boundaries(self):\n    vocab_size = 256\n    precision = 4\n    (_, serializer) = self._make_space_and_serializer(\n        low=-1, high=1, shape=(1,), vocab_size=vocab_size, precision=precision,\n    )\n    input_array = np.array([[-1, 1]])\n    representation = serializer.serialize(input_array)\n    np.testing.assert_array_equal(\n        representation, [[0] * precision + [vocab_size - 1] * precision]\n    )\n\n\nclass DiscreteSpaceSerializerTest(test.TestCase):\n\n  def setUp(self):\n    super(DiscreteSpaceSerializerTest, self).setUp()\n    self._space = gym.spaces.Discrete(n=2)\n    self._serializer = space_serializer.create(self._space, vocab_size=2)\n\n  def _sample_batch(self):\n    return np.reshape(self._space.sample(), (1,) + self._space.shape)\n\n  def test_representation_length(self):\n    input_array = self._sample_batch()\n    representation = self._serializer.serialize(input_array)\n    self.assertEqual(\n        representation.shape, (1, self._serializer.representation_length))\n\n  def test_commutes(self):\n    input_array = self._sample_batch()\n    representation = self._serializer.serialize(input_array)\n    output_array = self._serializer.deserialize(representation)\n    np.testing.assert_array_almost_equal(input_array, output_array)\n\n  def test_representation_changes(self):\n    array1 = self._sample_batch()\n    array2 = 1 - array1\n    (repr1, repr2) = tuple(map(self._serializer.serialize, (array1, array2)))\n    self.assertFalse(np.array_equal(repr1, repr2))\n\n  def test_significance_map(self):\n    np.testing.assert_array_equal(self._serializer.significance_map, [0])\n\n\nclass MultiDiscreteSpaceSerializerTest(test.TestCase):\n\n  def setUp(self):\n    super(MultiDiscreteSpaceSerializerTest, self).setUp()\n    self._space = gym.spaces.MultiDiscrete(nvec=[2, 2])\n    self._serializer = space_serializer.create(self._space, vocab_size=2)\n\n  def _sample_batch(self):\n    return np.reshape(self._space.sample(), (1,) + self._space.shape)\n\n  def test_representation_length(self):\n    input_array = self._sample_batch()\n    representation = self._serializer.serialize(input_array)\n    self.assertEqual(\n        representation.shape, (1, self._serializer.representation_length))\n\n  def test_commutes(self):\n    input_array = self._sample_batch()\n    representation = self._serializer.serialize(input_array)\n    output_array = self._serializer.deserialize(representation)\n    np.testing.assert_array_almost_equal(input_array, output_array)\n\n  def test_representation_changes(self):\n    array1 = self._sample_batch()\n    array2 = 1 - array1\n    (repr1, repr2) = tuple(map(self._serializer.serialize, (array1, array2)))\n    self.assertFalse(np.array_equal(repr1, repr2))\n\n  def test_significance_map(self):\n    np.testing.assert_array_equal(self._serializer.significance_map, [0, 0])\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/task.py,20,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Classes for defining RL tasks in Trax.""""""\n\nimport collections\nimport os\n\nimport gin\nimport gym\nimport numpy as np\n\nfrom trax import math\nfrom trax.supervised import trainer_lib\n\n\nclass _TimeStep(object):\n  """"""A single step of interaction with a RL environment.\n\n  TimeStep stores a single step in the trajectory of an RL run:\n  * observation (same as observation) at the beginning of the step\n  * action that was takes (or None if none taken yet)\n  * reward gotten when the action was taken (or None if action wasn\'t taken)\n  * log-probability of the action taken (or None if not specified)\n  * discounted return from that state (includes the reward from this step)\n  """"""\n\n  def __init__(\n      self, observation, action=None, reward=None, dist_inputs=None, done=None,\n      mask=None\n  ):\n    self.observation = observation\n    self.action = action\n    self.reward = reward\n    self.dist_inputs = dist_inputs\n    self.done = done\n    self.mask = mask\n    self.discounted_return = 0.0\n\n\n# Tuple for representing trajectories and batches of them in numpy; immutable.\nTrajectoryNp = collections.namedtuple(\'TrajectoryNp\', [\n    \'observations\',\n    \'actions\',\n    \'dist_inputs\',\n    \'rewards\',\n    \'returns\',\n    \'dones\',\n    \'mask\',\n])\n\n\n# Same as TrajectoryNp, for timesteps. This is separate for documentation\n# purposes, but it\'s functionally redundant.\n# TODO(pkozakowski): Consider merging with TrajectoryNp and finding a common\n# name. At the very least it should be merged with _TimeStep - I\'m not doing it\n# for now to keep backward compatibility with batch RL experiments.\nTimeStepNp = collections.namedtuple(\'TimeStepNp\', [\n    \'observation\',\n    \'action\',\n    \'dist_inputs\',\n    \'reward\',\n    \'return_\',\n    \'done\',\n    \'mask\',\n])\n\n\nclass Trajectory(object):\n  """"""A trajectory of interactions with a RL environment.\n\n  Trajectories are created when interacting with a RL environment. They can\n  be prolonged and sliced and when completed, allow to re-calculate returns.\n  """"""\n\n  def __init__(self, observation):\n    # TODO(lukaszkaiser): add support for saving and loading trajectories,\n    # reuse code from base_trainer.dump_trajectories and related functions.\n    if observation is not None:\n      self._timesteps = [_TimeStep(observation)]\n\n  def __len__(self):\n    return len(self._timesteps)\n\n  def __str__(self):\n    return str([(ts.observation, ts.action, ts.reward)\n                for ts in self._timesteps])\n\n  def __repr__(self):\n    return repr([(ts.observation, ts.action, ts.reward)\n                 for ts in self._timesteps])\n\n  def __getitem__(self, key):\n    t = Trajectory(None)\n    t._timesteps = self._timesteps[key]  # pylint: disable=protected-access\n    return t\n\n  @property\n  def timesteps(self):\n    return self._timesteps\n\n  @property\n  def total_return(self):\n    """"""Sum of all rewards in this trajectory.""""""\n    return sum([t.reward or 0.0 for t in self._timesteps])\n\n  @property\n  def last_observation(self):\n    """"""Return the last observation in this trajectory.""""""\n    last_timestep = self._timesteps[-1]\n    return last_timestep.observation\n\n  def extend(self, action, dist_inputs, reward, done, new_observation, mask=1):\n    """"""Take action in the last state, getting reward and going to new state.""""""\n    last_timestep = self._timesteps[-1]\n    last_timestep.action = action\n    last_timestep.dist_inputs = dist_inputs\n    last_timestep.reward = reward\n    last_timestep.done = done\n    last_timestep.mask = mask\n    new_timestep = _TimeStep(new_observation)\n    self._timesteps.append(new_timestep)\n\n  def calculate_returns(self, gamma):\n    """"""Calculate discounted returns.""""""\n    ret = 0.0\n    for timestep in reversed(self._timesteps):\n      cur_reward = timestep.reward or 0.0\n      ret = gamma * ret + cur_reward\n      timestep.discounted_return = ret\n\n  def _default_timestep_to_np(self, ts):\n    """"""Default way to convert timestep to numpy.""""""\n    return math.nested_map(np.array, TimeStepNp(\n        observation=ts.observation,\n        action=ts.action,\n        dist_inputs=ts.dist_inputs,\n        reward=ts.reward,\n        done=ts.done,\n        return_=ts.discounted_return,\n        mask=ts.mask,\n    ))\n\n  def to_np(self, timestep_to_np=None):\n    """"""Create a tuple of numpy arrays from a given trajectory.""""""\n    observations, actions, dist_inputs, rewards, returns, dones, masks = (\n        [], [], [], [], [], [], []\n    )\n    timestep_to_np = timestep_to_np or self._default_timestep_to_np\n    for timestep in self._timesteps:\n      if timestep.action is None:\n        obs = timestep_to_np(timestep).observation\n        observations.append(obs)\n      else:\n        timestep_np = timestep_to_np(timestep)\n        observations.append(timestep_np.observation)\n        actions.append(timestep_np.action)\n        dist_inputs.append(timestep_np.dist_inputs)\n        rewards.append(timestep_np.reward)\n        dones.append(timestep_np.done)\n        returns.append(timestep_np.return_)\n        masks.append(timestep_np.mask)\n\n    def stack(x):\n      if not x:\n        return None\n      return math.nested_stack(x)\n\n    return TrajectoryNp(**{  # pylint: disable=g-complex-comprehension\n        key: stack(value) for (key, value) in [\n            (\'observations\', observations),\n            (\'actions\', actions),\n            (\'dist_inputs\', dist_inputs),\n            (\'rewards\', rewards),\n            (\'dones\', dones),\n            (\'returns\', returns),\n            (\'mask\', masks),\n        ]\n    })\n\n\ndef play(env, policy, dm_suite=False, max_steps=None):\n  """"""Play an episode in env taking actions according to the given policy.\n\n  Environment is first reset and an from then on, a game proceeds. At each\n  step, the policy is asked to choose an action and the environment moves\n  forward. A Trajectory is created in that way and returns when the episode\n  finished, which is either when env returns `done` or max_steps is reached.\n\n  Args:\n    env: the environment to play in, conforming to gym.Env or\n      DeepMind suite interfaces.\n    policy: a function taking a Trajectory and returning a pair consisting\n      of an action (int or float) and the confidence in that action (float,\n      defined as the log of the probability of taking that action).\n    dm_suite: whether we are using the DeepMind suite or the gym interface\n    max_steps: for how many steps to play.\n\n  Returns:\n    a completed trajectory that was just played.\n  """"""\n  terminal = False\n  cur_step = 0\n  if dm_suite:\n    cur_trajectory = Trajectory(env.reset().observation)\n    while not terminal and (max_steps is None or cur_step < max_steps):\n      action, dist_inputs = policy(cur_trajectory)\n      observation = env.step(action)\n      cur_trajectory.extend(action, dist_inputs,\n                            observation.reward,\n                            observation.step_type.last(),\n                            observation.observation)\n      cur_step += 1\n      terminal = observation.step_type.last()\n  else:\n    cur_trajectory = Trajectory(env.reset())\n    while not terminal and (max_steps is None or cur_step < max_steps):\n      action, dist_inputs = policy(cur_trajectory)\n      observation, reward, terminal, _ = env.step(action)\n      cur_trajectory.extend(action, dist_inputs, reward, terminal, observation)\n      cur_step += 1\n  return cur_trajectory\n\n\ndef _zero_pad(x, pad, axis):\n  """"""Helper for np.pad with 0s for single-axis case.""""""\n  pad_widths = [(0, 0)] * len(x.shape)\n  pad_widths[axis] = pad  # Padding on axis.\n  return np.pad(x, pad_widths, mode=\'constant\',\n                constant_values=x.dtype.type(0))\n\n\ndef _random_policy(action_space):\n  return lambda _: (action_space.sample(), None)\n\n\ndef _sample_proportionally(inputs, weights):\n  """"""Sample an element from the inputs list proportionally to weights.\n\n  Args:\n    inputs: a list, we will return one element of this list.\n    weights: a list of numbers of the same length as inputs; we will sample\n      the k-th input with probability weights[k] / sum(weights).\n\n  Returns:\n    an element from inputs.\n  """"""\n  l = len(inputs)\n  if l != len(weights):\n    raise ValueError(f\'Inputs and weights must have the same length, but do not\'\n                     f\': {l} != {len(weights)}\')\n  weights_sum = float(sum(weights))\n  norm_weights = [w / weights_sum for w in weights]\n  idx = np.random.choice(l, p=norm_weights)\n  return inputs[int(idx)]\n\n\n@gin.configurable()\nclass RLTask:\n  """"""A RL task: environment and a collection of trajectories.""""""\n\n  def __init__(self, env=gin.REQUIRED,\n               initial_trajectories=1,\n               gamma=0.99,\n               dm_suite=False,\n               max_steps=None,\n               timestep_to_np=None,\n               num_stacked_frames=1,\n               n_replay_epochs=1):\n    r""""""Configures a RL task.\n\n    Args:\n      env: Environment confirming to the gym.Env interface or a string,\n        in which case `gym.make` will be called on this string to create an env.\n      initial_trajectories: either a dict or list of Trajectories to use\n        at start or an int, in which case that many trajectories are\n        collected using a random policy to play in env. It can be also a string\n        and then it should direct to the location where previously recorded\n        trajectories are stored.\n      gamma: float: discount factor for calculating returns.\n      dm_suite: whether we are using the DeepMind suite or the gym interface\n      max_steps: Optional int: stop all trajectories at that many steps.\n      timestep_to_np: a function that turns a timestep into a numpy array\n        (ie., a tensor); if None, we just use the state of the timestep to\n        represent it, but other representations (such as embeddings that include\n        actions or serialized representations) can be passed here.\n      num_stacked_frames: the number of stacked frames for Atari.\n      n_replay_epochs: the size of the replay buffer expressed in epochs.\n    """"""\n    if isinstance(env, str):\n      self._env_name = env\n      if dm_suite:\n        env = environments.load_from_settings(\n            platform=\'atari\',\n            settings={\n                \'levelName\': env,\n                \'interleaved_pixels\': True,\n                \'zero_indexed_actions\': True\n            })\n        env = atari_wrapper.AtariWrapper(environment=env,\n                                         num_stacked_frames=num_stacked_frames)\n      else:\n        env = gym.make(env)\n    else:\n      self._env_name = type(env).__name__\n    self._env = env\n    self._dm_suite = dm_suite\n    self._max_steps = max_steps\n    self._gamma = gamma\n    self._initial_trajectories = initial_trajectories\n    # TODO(lukaszkaiser): find a better way to pass initial trajectories,\n    # whether they are an explicit list, a file, or a number of random ones.\n    if isinstance(initial_trajectories, int):\n      if self._initial_trajectories > 0:\n        initial_trajectories = [\n            self.play(_random_policy(self.action_space))\n            for _ in range(initial_trajectories)\n        ]\n      else:\n        initial_trajectories = [\n            # Whatever we gather here is intended to be removed\n            # in PolicyTrainer. Here we just gather some example inputs.\n            self.play(_random_policy(self.action_space))\n        ]\n    if isinstance(initial_trajectories, str):\n      initial_trajectories = self.load_initial_trajectories_from_path(\n          initial_trajectories_path=initial_trajectories)\n    if isinstance(initial_trajectories, list):\n      initial_trajectories = {0: initial_trajectories}\n    self._timestep_to_np = timestep_to_np\n    # Stored trajectories are indexed by epoch and within each epoch they\n    # are stored in the order of generation so we can implement replay buffers.\n    # TODO(lukaszkaiser): use dump_trajectories from BaseTrainer to allow\n    # saving and reading trajectories from disk.\n    self._trajectories = collections.defaultdict(list)\n    self._trajectories.update(initial_trajectories)\n    # When we repeatedly save, trajectories for many epochs do not change, so\n    # we don\'t need to save them again. This keeps track which are unchanged.\n    self._saved_epochs_unchanged = []\n    self._n_replay_epochs = n_replay_epochs\n    self._n_trajectories = 0\n    self._n_interactions = 0\n\n  @property\n  def env(self):\n    return self._env\n\n  @property\n  def env_name(self):\n    return self._env_name\n\n  @property\n  def max_steps(self):\n    return self._max_steps\n\n  @property\n  def gamma(self):\n    return self._gamma\n\n  @property\n  def action_space(self):\n    if self._dm_suite:\n      return gym.spaces.Discrete(self._env.action_spec().num_values)\n    else:\n      return self._env.action_space\n\n  @property\n  def observation_space(self):\n    """"""Returns the env\'s observation space in a Gym interface.""""""\n    if self._dm_suite:\n      return gym.spaces.Box(\n          shape=self._env.observation_spec().shape,\n          dtype=self._env.observation_spec().dtype,\n          low=float(\'-inf\'),\n          high=float(\'+inf\'),\n      )\n    else:\n      return self._env.observation_space\n\n  @property\n  def trajectories(self):\n    return self._trajectories\n\n  @property\n  def timestep_to_np(self):\n    return self._timestep_to_np\n\n  @timestep_to_np.setter\n  def timestep_to_np(self, ts):\n    self._timestep_to_np = ts\n\n  def _epoch_filename(self, base_filename, epoch):\n    """"""Helper function: file name for saving the given epoch.""""""\n    # If base is /foo/task.pkl, we save epoch 1 under /foo/task_epoch1.pkl.\n    filename, ext = os.path.splitext(base_filename)\n    return filename + \'_epoch\' + str(epoch) + ext\n\n  def set_n_replay_epochs(self, n_replay_epochs):\n    self._n_replay_epochs = n_replay_epochs\n\n  def load_initial_trajectories_from_path(self,\n                                          initial_trajectories_path,\n                                          dictionary_file=\'trajectories.pkl\',\n                                          start_epoch_to_load=0):\n    """"""Initialize trajectories task from file.""""""\n    # We assume that this is a dump generated by Trax\n    dictionary_file = os.path.join(initial_trajectories_path, dictionary_file)\n    dictionary = trainer_lib.unpickle_from_file(dictionary_file, gzip=False)\n    # TODO(henrykm): as currently implemented this accesses only\n    # at most the last n_replay_epochs - this should be more flexible\n    epochs_to_load = dictionary[\'all_epochs\'][start_epoch_to_load:]\n\n    all_trajectories = []\n    for epoch in epochs_to_load:\n      trajectories = trainer_lib.unpickle_from_file(\n          self._epoch_filename(dictionary_file, epoch), gzip=True)\n      all_trajectories += trajectories\n    return all_trajectories\n\n  def init_from_file(self, file_name):\n    """"""Initialize this task from file.""""""\n    dictionary = trainer_lib.unpickle_from_file(file_name, gzip=False)\n    self._n_trajectories = dictionary[\'n_trajectories\']\n    self._n_interactions = dictionary[\'n_interactions\']\n    self._max_steps = dictionary[\'max_steps\']\n    self._gamma = dictionary[\'gamma\']\n    epochs_to_load = dictionary[\'all_epochs\'][-self._n_replay_epochs:]\n\n    for epoch in epochs_to_load:\n      trajectories = trainer_lib.unpickle_from_file(\n          self._epoch_filename(file_name, epoch), gzip=True)\n      self._trajectories[epoch] = trajectories\n    self._saved_epochs_unchanged = epochs_to_load\n\n  def save_to_file(self, file_name):\n    """"""Save this task to file.""""""\n    # Save trajectories from new epochs first.\n    epochs_to_save = [e for e in self._trajectories.keys()\n                      if e not in self._saved_epochs_unchanged]\n    for epoch in epochs_to_save:\n      trainer_lib.pickle_to_file(self._trajectories[epoch],\n                                 self._epoch_filename(file_name, epoch),\n                                 gzip=True)\n    # Now save the list of epochs (so the trajectories are already there,\n    # even in case of preemption).\n    dictionary = {\'n_interactions\': self._n_interactions,\n                  \'n_trajectories\': self._n_trajectories,\n                  \'max_steps\': self._max_steps,\n                  \'gamma\': self._gamma,\n                  \'all_epochs\': list(self._trajectories.keys())}\n    trainer_lib.pickle_to_file(dictionary, file_name, gzip=False)\n\n  def play(self, policy, max_steps=None):\n    """"""Play an episode in env taking actions according to the given policy.""""""\n    if max_steps is None:\n      max_steps = self._max_steps\n    cur_trajectory = play(self._env, policy, self._dm_suite, max_steps)\n    cur_trajectory.calculate_returns(self._gamma)\n    return cur_trajectory\n\n  def collect_trajectories(\n      self, policy,\n      n_trajectories=None,\n      n_interactions=None,\n      only_eval=False,\n      max_steps=None,\n      epoch_id=1,\n  ):\n    """"""Collect experience in env playing the given policy.""""""\n    max_steps = max_steps or self.max_steps\n    if n_trajectories:\n      new_trajectories = [self.play(policy, max_steps=max_steps)\n                          for _ in range(n_trajectories)]\n    elif n_interactions:\n      # TODO(pkozakowski): Test this mode of experience collection.\n      new_trajectories = []\n      while n_interactions > 0:\n        traj = self.play(policy, max_steps=max_steps)\n        new_trajectories.append(traj)\n        n_interactions -= len(traj)\n    else:\n      raise ValueError(\n          \'Either n_trajectories or n_interactions must be defined.\'\n      )\n\n    # Calculate returns.\n    returns = [t.total_return for t in new_trajectories]\n\n    # If we\'re only evaluating, we\'re done, return the average.\n    if only_eval:\n      return sum(returns) / float(len(returns))\n\n    # Store new trajectories.\n    self._trajectories[epoch_id].extend(new_trajectories)\n\n    # Mark that epoch epoch_id has changed.\n    if epoch_id in self._saved_epochs_unchanged:\n      self._saved_epochs_unchanged = [e for e in self._saved_epochs_unchanged\n                                      if e != epoch_id]\n\n    # Remove epochs not intended to be in the buffer\n    current_trajectories = {\n        key: value for key, value in self._trajectories.items()\n        if key >= epoch_id - self._n_replay_epochs}\n    self._trajectories = collections.defaultdict(list)\n    self._trajectories.update(current_trajectories)\n\n    # Update statistics.\n    self._n_trajectories += len(new_trajectories)\n    self._n_interactions += sum([len(traj) for traj in new_trajectories])\n\n    return sum(returns) / float(len(returns))\n\n  def n_trajectories(self, epochs=None):\n    # TODO(henrykm) support selection of epochs if really necessary (will\n    # require a dump of a list of lengths in save_to_file\n    del epochs\n    return self._n_trajectories\n\n  def n_interactions(self, epochs=None):\n    # TODO(henrykm) support selection of epochs if really necessary (will\n    # require a dump of a list of lengths in save_to_file\n    del epochs\n    return self._n_interactions\n\n  def remove_epoch(self, epoch):\n    """"""Useful when we need to remove an unwanted trajectory.""""""\n    if epoch in self._trajectories.keys():\n      self._trajectories.pop(epoch)\n\n  def trajectory_stream(self, epochs=None, max_slice_length=None,\n                        include_final_state=False,\n                        sample_trajectories_uniformly=False, margin=0):\n    """"""Return a stream of random trajectory slices from the specified epochs.\n\n    Args:\n      epochs: a list of epochs to use; we use all epochs if None\n      max_slice_length: maximum length of the slices of trajectories to return\n      include_final_state: whether to include slices with the final state of\n        the trajectory which may have no action and reward\n      sample_trajectories_uniformly: whether to sample trajectories uniformly,\n        or proportionally to the number of slices in each trajectory (default)\n      margin: number of extra steps after ""done"" that should be included in\n        slices, so that networks see the terminal states in the training data\n\n    Yields:\n      random trajectory slices sampled uniformly from all slices of length\n      up to max_slice_length in all specified epochs\n    """"""\n    # TODO(lukaszkaiser): add option to sample from n last trajectories.\n    end_offset = 0 if include_final_state else 1\n    def n_slices(t):\n      """"""How many slices of length upto max_slice_length in a trajectory.""""""\n      if not max_slice_length:\n        return 1\n      # A trajectory [a, b, c, end_state] will have 2 slices of length 2:\n      # the slice [a, b] and the one [b, c], with end_offset; 3 without.\n      return max(1, len(t) + margin - max_slice_length + 1 - end_offset)\n\n    def extend_trajectory(t):\n      # TODO(pkozakowski) Refactor.\n      if len(t) == 1:\n        return t\n      else:\n        ts = t.timesteps[0]\n        extend_kwargs = {\n            \'action\': np.zeros_like(ts.action),\n            \'dist_inputs\': (\n                np.zeros_like(ts.dist_inputs)\n                if ts.dist_inputs is not None else None\n            ),\n            \'reward\': 0.0,\n            \'done\': True,\n            \'mask\': 0,\n            \'new_observation\': np.zeros_like(ts.observation),\n        }\n        t = t[:]  # Make a shallow copy of the timestep list.\n        for _ in range(margin):\n          t.extend(**extend_kwargs)\n        return t\n\n    while True:\n      all_epochs = list(self._trajectories.keys())\n      max_epoch = max(all_epochs) + 1\n      # Bind the epoch indices to a new name so they can be recalculated every\n      # epoch.\n      epoch_indices = epochs or all_epochs\n      epoch_indices = [\n          # So -1 means ""last"".\n          ep % max_epoch for ep in epoch_indices\n      ]\n      # Remove duplicates and consider only epochs where some trajectories\n      # were recorded.\n      epoch_indices = [epoch_id for epoch_id in list(set(epoch_indices))\n                       if self._trajectories[epoch_id]]\n\n      # Sample an epoch proportionally to number of slices in each epoch.\n      if len(epoch_indices) == 1:  # Skip this step if there\'s just 1 epoch.\n        epoch_id = epoch_indices[0]\n      else:\n        slices_per_epoch = [sum([n_slices(t) for t in self._trajectories[ep]])\n                            for ep in epoch_indices]\n        epoch_id = _sample_proportionally(epoch_indices, slices_per_epoch)\n      epoch = self._trajectories[epoch_id]\n\n      # Sample a trajectory proportionally to number of slices in each one.\n      if sample_trajectories_uniformly:\n        slices_per_trajectory = [1] * len(epoch)\n      else:\n        slices_per_trajectory = [n_slices(t) for t in epoch]\n      trajectory = _sample_proportionally(epoch, slices_per_trajectory)\n\n      # Sample a slice from the trajectory.\n      slice_start = np.random.randint(n_slices(trajectory))\n      # Extend the trajectory with a given margin - this is to make sure that\n      # the networks always ""see"" the ""done"" states in the training data, even\n      # when a suffix is added to the trajectory slice for better estimation of\n      # returns.\n      extended_trajectory = extend_trajectory(trajectory)\n      slice_end = slice_start + (max_slice_length or len(extended_trajectory))\n      slice_end = min(slice_end, len(extended_trajectory) - end_offset)\n      yield extended_trajectory[slice_start:slice_end]\n\n  def trajectory_batch_stream(self, batch_size, epochs=None,\n                              max_slice_length=None,\n                              min_slice_length=None,\n                              margin=0,\n                              include_final_state=False,\n                              sample_trajectories_uniformly=False):\n    """"""Return a stream of trajectory batches from the specified epochs.\n\n    This function returns a stream of tuples of numpy arrays (tensors).\n    If tensors have different lengths, they will be padded by 0.\n\n    Args:\n      batch_size: the size of the batches to return\n      epochs: a list of epochs to use; we use all epochs if None\n      max_slice_length: maximum length of the slices of trajectories to return\n      min_slice_length: minimum length of the slices of trajectories to return\n      margin: number of extra steps after ""done"" that should be included in\n        slices, so that networks see the terminal states in the training data\n      include_final_state: whether to include slices with the final state of\n        the trajectory which may have no action and reward\n      sample_trajectories_uniformly: whether to sample trajectories uniformly,\n       or proportionally to the number of slices in each trajectory (default)\n\n    Yields:\n      batches of trajectory slices sampled uniformly from all slices of length\n      at least min_slice_length and up to max_slice_length in all specified\n      epochs\n    """"""\n    def pad(tensor_list):\n      # Replace Nones with valid tensors.\n      not_none_tensors = [t for t in tensor_list if t is not None]\n      assert not_none_tensors, \'All tensors to pad are None.\'\n      prototype = np.zeros_like(not_none_tensors[0])\n      tensor_list = [t if t is not None else prototype for t in tensor_list]\n\n      max_len = max([t.shape[0] for t in tensor_list])\n      min_len = min([t.shape[0] for t in tensor_list])\n      if max_len == min_len:  # No padding needed.\n        return np.array(tensor_list)\n\n      pad_len = 2**int(np.ceil(np.log2(max_len)))\n      return np.array([_zero_pad(t, (0, pad_len - t.shape[0]), axis=0)\n                       for t in tensor_list])\n    cur_batch = []\n    for t in self.trajectory_stream(\n        epochs, max_slice_length,\n        include_final_state, sample_trajectories_uniformly,\n        margin=margin\n    ):\n      # TODO(pkozakowski): Instead sample the trajectories out of those with\n      # the minimum length.\n      if min_slice_length is not None and len(t) < min_slice_length:\n        continue\n\n      cur_batch.append(t)\n      if len(cur_batch) == batch_size:\n        # TODO(pkozakowski): Unpack based on name instead of position in the\n        # tuple (how?).\n        obs, act, dinp, rew, ret, done, mask = zip(*[\n            t.to_np(self._timestep_to_np) for t in cur_batch\n        ])\n        # Where act, rew and ret will usually have the following shape:\n        # [batch_size, trajectory_length-1], which we call [B, L-1].\n        # Observations are more complex and will usuall be [B, L] + S where S\n        # is the shape of the observation space (self.observation_space.shape).\n        # We stop the recursion at level 1, so we pass lists of arrays into\n        # pad().\n        yield math.nested_map(pad, TrajectoryNp(\n            observations=obs,\n            actions=act,\n            dist_inputs=dinp,\n            rewards=rew,\n            dones=done,\n            returns=ret,\n            mask=mask,\n        ), level=1)\n        cur_batch = []\n'"
trax/rl/task_test.py,5,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for RL training.""""""\n\nimport os\nfrom absl.testing import absltest\nimport gym\nimport numpy as np\nfrom trax import test_utils\nfrom trax.rl import task as rl_task\n\n\nclass DummyEnv(object):\n  """"""Dummy Env class for testing.""""""\n\n  @property\n  def action_space(self):\n    return gym.spaces.Discrete(2)\n\n  @property\n  def observation_space(self):\n    return gym.spaces.Box(-2, 2, shape=(2,))\n\n  def reset(self):\n    return np.ones((2,))\n\n  def step(self, action):\n    del action\n    return np.ones((2,)), 0.0, False, None\n\n\nclass TaskTest(absltest.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    test_utils.ensure_flag(\'test_tmpdir\')\n\n  def test_task_random_initial_trajectories_and_max_steps(self):\n    """"""Test generating initial random trajectories, stop at max steps.""""""\n    task = rl_task.RLTask(DummyEnv(), initial_trajectories=1, max_steps=9)\n    stream = task.trajectory_stream(max_slice_length=1)\n    next_slice = next(stream)\n    self.assertLen(next_slice, 1)\n    self.assertEqual(next_slice.last_observation.shape, (2,))\n\n  def test_task_save_init(self):\n    """"""Test saving and re-initialization.""""""\n    task1 = rl_task.RLTask(DummyEnv(), initial_trajectories=13,\n                           max_steps=9, gamma=0.9)\n    self.assertLen(task1.trajectories[0], 13)\n    self.assertEqual(task1.max_steps, 9)\n    self.assertEqual(task1.gamma, 0.9)\n    temp_file = os.path.join(self.create_tempdir().full_path, \'task.pkl\')\n    task1.save_to_file(temp_file)\n    task2 = rl_task.RLTask(DummyEnv(), initial_trajectories=3,\n                           max_steps=19, gamma=1.0)\n    self.assertLen(task2.trajectories[0], 3)\n    self.assertEqual(task2.max_steps, 19)\n    self.assertEqual(task2.gamma, 1.0)\n    task2.init_from_file(temp_file)\n    self.assertLen(task2.trajectories[0], 13)\n    self.assertEqual(task2.max_steps, 9)\n    self.assertEqual(task2.gamma, 0.9)\n\n  def test_task_epochs_index_minusone(self):\n    """"""Test that the epoch index -1 means last epoch and updates to it.""""""\n    elem = np.zeros((2,))\n    tr1 = rl_task.Trajectory(elem)\n    tr1.extend(0, 0, 0, True, elem)\n    task = rl_task.RLTask(DummyEnv(), initial_trajectories=[tr1], max_steps=9)\n    stream = task.trajectory_stream(epochs=[-1], max_slice_length=1)\n    next_slice = next(stream)\n    self.assertLen(next_slice, 1)\n    self.assertEqual(next_slice.last_observation[0], 0)\n    task.collect_trajectories((lambda _: (0, 0)), 1)\n    next_slice = next(stream)\n    self.assertLen(next_slice, 1)\n    self.assertEqual(next_slice.last_observation[0], 1)\n\n  def test_trajectory_stream_shape(self):\n    """"""Test the shape yielded by trajectory stream.""""""\n    elem = np.zeros((12, 13))\n    tr1 = rl_task.Trajectory(elem)\n    tr1.extend(0, 0, 0, True, elem)\n    task = rl_task.RLTask(DummyEnv(), initial_trajectories=[tr1], max_steps=9)\n    stream = task.trajectory_stream(max_slice_length=1)\n    next_slice = next(stream)\n    self.assertLen(next_slice, 1)\n    self.assertEqual(next_slice.last_observation.shape, (12, 13))\n\n  def test_trajectory_stream_long_slice(self):\n    """"""Test trajectory stream with slices of longer length.""""""\n    elem = np.zeros((12, 13))\n    tr1 = rl_task.Trajectory(elem)\n    tr1.extend(0, 0, 0, False, elem)\n    tr1.extend(0, 0, 0, True, elem)\n    task = rl_task.RLTask(DummyEnv(), initial_trajectories=[tr1], max_steps=9)\n    stream = task.trajectory_stream(max_slice_length=2)\n    next_slice = next(stream)\n    self.assertLen(next_slice, 2)\n    self.assertEqual(next_slice.last_observation.shape, (12, 13))\n\n  def test_trajectory_stream_final_state(self):\n    """"""Test trajectory stream with and without the final state.""""""\n    tr1 = rl_task.Trajectory(0)\n    tr1.extend(0, 0, 0, True, 1)\n    task = rl_task.RLTask(DummyEnv(), initial_trajectories=[tr1], max_steps=9)\n\n    # Stream of slices without the final state.\n    stream1 = task.trajectory_stream(\n        max_slice_length=1, include_final_state=False)\n    for _ in range(10):\n      next_slice = next(stream1)\n      self.assertLen(next_slice, 1)\n      self.assertEqual(next_slice.last_observation, 0)\n\n    # Stream of slices with the final state.\n    stream2 = task.trajectory_stream(\n        max_slice_length=1, include_final_state=True)\n    all_sum = 0\n    for _ in range(100):\n      next_slice = next(stream2)\n      self.assertLen(next_slice, 1)\n      all_sum += next_slice.last_observation\n    self.assertEqual(min(all_sum, 1), 1)  # We\'ve seen the end at least once.\n\n  def test_trajectory_stream_sampling_uniform(self):\n    """"""Test if the trajectory stream samples uniformly.""""""\n    # Long trajectory of 0s.\n    tr1 = rl_task.Trajectory(0)\n    for _ in range(100):\n      tr1.extend(0, 0, 0, False, 0)\n    tr1.extend(0, 0, 0, True, 200)\n    # Short trajectory of 101.\n    tr2 = rl_task.Trajectory(101)\n    tr2.extend(0, 0, 0, True, 200)\n    task = rl_task.RLTask(\n        DummyEnv(), initial_trajectories=[tr1, tr2], max_steps=9)\n\n    # Stream of both. Check that we\'re sampling by slice, not by trajectory.\n    stream = task.trajectory_stream(max_slice_length=1)\n    slices = []\n    for _ in range(10):\n      next_slice = next(stream)\n      assert len(next_slice) == 1\n      slices.append(next_slice.last_observation)\n    mean_obs = sum(slices) / float(len(slices))\n    # Average should be around 1 sampling from 0x100, 101 uniformly.\n    self.assertLess(mean_obs, 31)  # Sampling 101 even 3 times is unlikely.\n    self.assertLen(slices, 10)\n\n  def test_trajectory_stream_sampling_by_trajectory(self):\n    """"""Test if the trajectory stream samples by trajectory.""""""\n    # Long trajectory of 0s.\n    tr1 = rl_task.Trajectory(0)\n    for _ in range(100):\n      tr1.extend(0, 0, 0, False, 0)\n    tr1.extend(0, 0, 0, True, 200)\n    # Short trajectory of 101.\n    tr2 = rl_task.Trajectory(101)\n    tr2.extend(0, 0, 0, True, 200)\n    task = rl_task.RLTask(\n        DummyEnv(), initial_trajectories=[tr1, tr2], max_steps=9)\n\n    # Stream of both. Check that we\'re sampling by trajectory.\n    stream = task.trajectory_stream(\n        max_slice_length=1, sample_trajectories_uniformly=True)\n    slices = []\n    for _ in range(10):\n      next_slice = next(stream)\n      assert len(next_slice) == 1\n      slices.append(next_slice.last_observation)\n    mean_obs = sum(slices) / float(len(slices))\n    # Average should be around 50, sampling from {0, 101} uniformly.\n    # Sampling 101 < 2 times has low probability (but it possible, flaky test).\n    self.assertGreater(mean_obs, 20)\n    self.assertLen(slices, 10)\n\n  def test_trajectory_stream_margin(self):\n    """"""Test trajectory stream with an added margin.""""""\n    tr1 = rl_task.Trajectory(0)\n    tr1.extend(0, 0, 0, False, 1)\n    tr1.extend(1, 2, 3, True, 1)\n    task = rl_task.RLTask(DummyEnv(), initial_trajectories=[tr1], max_steps=9)\n\n    # Stream of slices without the final state.\n    stream1 = task.trajectory_stream(\n        max_slice_length=3, margin=2, include_final_state=False)\n    got_done = False\n    for _ in range(10):\n      next_slice = next(stream1)\n      self.assertLen(next_slice, 3)\n      if next_slice.timesteps[0].done:\n        for i in range(1, 3):\n          self.assertTrue(next_slice.timesteps[i].done)\n          self.assertFalse(next_slice.timesteps[i].mask)\n        got_done = True\n    # Assert that we got a done somewhere, otherwise the test is not trigerred.\n    # Not getting done has low probability (1/2^10) but is possible, flaky test.\n    self.assertTrue(got_done)\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/rl/trainers.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Trainers defined in trax.rl.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport gin\n\nfrom trax.rl import awr_trainer\nfrom trax.rl import ppo_trainer\nfrom trax.rl import simple_trainer\n\n\n# Ginify\ndef trainer_configure(*args, **kwargs):\n  kwargs[\'module\'] = \'trax.rl.trainers\'\n  kwargs[\'blacklist\'] = [\'train_env\', \'eval_env\', \'output_dir\']\n  return gin.external_configurable(*args, **kwargs)\n\n\n# pylint: disable=invalid-name\nAwrTrainer = trainer_configure(awr_trainer.AwrTrainer)\nPPO = trainer_configure(ppo_trainer.PPO)\nSimPLe = trainer_configure(simple_trainer.SimPLe)\n'"
trax/rl/training.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Classes for RL training in Trax.""""""\n\nimport functools\nimport os\nimport pickle\nimport time\n\nfrom absl import logging\nimport gin\nimport numpy as np\nimport tensorflow as tf\n\nfrom trax import jaxboard\nfrom trax import lr_schedules as lr\nfrom trax import math\nfrom trax import shapes\nfrom trax import supervised\nfrom trax.rl import distributions\nfrom trax.rl import normalization  # So gin files see it. # pylint: disable=unused-import\nfrom trax.rl import task as rl_task\n\n\nclass RLTrainer:\n  """"""Abstract class for RL Trainers, presenting the required API.""""""\n\n  def __init__(self, task: rl_task.RLTask,\n               n_trajectories_per_epoch=None,\n               n_interactions_per_epoch=None,\n               n_eval_episodes=0,\n               eval_steps=None,\n               only_eval=False,\n               output_dir=None,\n               timestep_to_np=None):\n    """"""Configures the RL Trainer.\n\n    Note that subclasses can have many more arguments, which will be configured\n    using defaults and gin. But task and output_dir are passed explicitly.\n\n    Args:\n      task: RLTask instance, which defines the environment to train on.\n      n_trajectories_per_epoch: How many new trajectories to collect in each\n        epoch.\n      n_interactions_per_epoch: How many interactions to collect in each epoch.\n      n_eval_episodes: Number of episodes to play with policy at\n        temperature 0 in each epoch -- used for evaluation only.\n      eval_steps: an optional list of max_steps to use for evaluation\n        (defaults to task.max_steps).\n      only_eval: If set to True, then trajectories are collected only for\n        for evaluation purposes, but they are not recorded.\n      output_dir: Path telling where to save outputs such as checkpoints.\n      timestep_to_np: Timestep-to-numpy function to override in the task.\n    """"""\n    assert bool(n_trajectories_per_epoch) != bool(n_interactions_per_epoch), (\n        \'Exactly one of n_trajectories_per_epoch or n_interactions_per_epoch \'\n        \'should be specified.\'\n    )\n    self._epoch = 0\n    self._task = task\n    self._eval_steps = eval_steps or [task.max_steps]\n    if timestep_to_np is not None:\n      self._task.timestep_to_np = timestep_to_np\n    self._n_trajectories_per_epoch = n_trajectories_per_epoch\n    self._n_interactions_per_epoch = n_interactions_per_epoch\n    self._only_eval = only_eval\n    self._output_dir = output_dir\n    self._avg_returns = []\n    self._n_eval_episodes = n_eval_episodes\n    self._avg_returns_temperature0 = {step: [] for step in self._eval_steps}\n    self._sw = None\n    if output_dir is not None:\n      self._sw = jaxboard.SummaryWriter(os.path.join(output_dir, \'rl\'))\n\n  @property\n  def current_epoch(self):\n    """"""Returns current step number in this training session.""""""\n    return self._epoch\n\n  @property\n  def task(self):\n    """"""Returns the task.""""""\n    return self._task\n\n  @property\n  def avg_returns(self):\n    return self._avg_returns\n\n  def save_gin(self):\n    assert self._output_dir is not None\n    config_path = os.path.join(self._output_dir, \'config.gin\')\n    config_str = gin.operative_config_str()\n    with tf.io.gfile.GFile(config_path, \'w\') as f:\n      f.write(config_str)\n    if self._sw:\n      self._sw.text(\'gin_config\',\n                    jaxboard.markdownify_operative_config_str(config_str))\n\n  def save_to_file(self, file_name=\'rl.pkl\',\n                   task_file_name=\'trajectories.pkl\'):\n    """"""Save current epoch number and average returns to file.""""""\n    assert self._output_dir is not None\n    task_path = os.path.join(self._output_dir, task_file_name)\n    self._task.save_to_file(task_path)\n    file_path = os.path.join(self._output_dir, file_name)\n    dictionary = {\'epoch\': self._epoch,\n                  \'avg_returns\': self._avg_returns,\n                  \'avg_returns_temperature0\': self._avg_returns_temperature0}\n    with tf.io.gfile.GFile(file_path, \'wb\') as f:\n      pickle.dump(dictionary, f)\n\n  def init_from_file(self, file_name=\'rl.pkl\',\n                     task_file_name=\'trajectories.pkl\'):\n    """"""Initialize epoch number and average returns from file.""""""\n    assert self._output_dir is not None\n    task_path = os.path.join(self._output_dir, task_file_name)\n    if tf.io.gfile.exists(task_path):\n      self._task.init_from_file(task_path)\n    file_path = os.path.join(self._output_dir, file_name)\n    if not tf.io.gfile.exists(file_path):\n      return\n    with tf.io.gfile.GFile(file_path, \'rb\') as f:\n      dictionary = pickle.load(f)\n    self._epoch = dictionary[\'epoch\']\n    self._avg_returns = dictionary[\'avg_returns\']\n    self._avg_returns_temperature0 = dictionary[\'avg_returns_temperature0\']\n\n  def _collect_trajectories(self):\n    return self.task.collect_trajectories(\n        self.policy,\n        n_trajectories=self._n_trajectories_per_epoch,\n        n_interactions=self._n_interactions_per_epoch,\n        only_eval=self._only_eval,\n        epoch_id=self._epoch\n    )\n\n  def policy(self, trajectory, temperature=1.0):\n    """"""Policy function that allows to play using this trainer.\n\n    Args:\n      trajectory: an instance of trax.rl.task.Trajectory\n      temperature: temperature used to sample from the policy (default=1.0)\n\n    Returns:\n      a pair (action, dist_inputs) where action is the action taken and\n      dist_inputs is the parameters of the policy distribution, that will later\n      be used for training.\n    """"""\n    raise NotImplementedError\n\n  def train_epoch(self):\n    """"""Trains this RL Trainer for one epoch -- main RL logic goes here.""""""\n    raise NotImplementedError\n\n  def run(self, n_epochs=1, n_epochs_is_total_epochs=False):\n    """"""Runs this loop for n epochs.\n\n    Args:\n      n_epochs: Stop training after completing n steps.\n      n_epochs_is_total_epochs: if True, consider n_epochs as the total\n        number of epochs to train, including previously trained ones\n    """"""\n    if self._output_dir is not None:\n      self.init_from_file()\n    n_epochs_to_run = n_epochs\n    if n_epochs_is_total_epochs:\n      n_epochs_to_run -= self._epoch\n    cur_n_interactions = 0\n    for _ in range(n_epochs_to_run):\n      self._epoch += 1\n      cur_time = time.time()\n      self.train_epoch()\n      supervised.trainer_lib.log(\n          \'RL training took %.2f seconds.\' % (time.time() - cur_time))\n      cur_time = time.time()\n      avg_return = self._collect_trajectories()\n      self._avg_returns.append(avg_return)\n      if self._n_trajectories_per_epoch:\n        supervised.trainer_lib.log(\n            \'Collecting %d episodes took %.2f seconds.\'\n            % (self._n_trajectories_per_epoch, time.time() - cur_time))\n      else:\n        supervised.trainer_lib.log(\n            \'Collecting %d interactions took %.2f seconds.\'\n            % (self._n_interactions_per_epoch, time.time() - cur_time))\n      supervised.trainer_lib.log(\n          \'Average return in epoch %d was %.2f.\' % (self._epoch, avg_return))\n      if self._n_eval_episodes > 0:\n        for steps in self._eval_steps:\n          avg_return_temperature0 = self.task.collect_trajectories(\n              lambda x: self.policy(x, temperature=0.0),\n              n_trajectories=self._n_eval_episodes,\n              max_steps=steps, only_eval=True)\n          self._avg_returns_temperature0[steps].append(avg_return_temperature0)\n          supervised.trainer_lib.log(\n              \'Avg return with temperature 0 at %d steps in epoch %d was %.2f.\'\n              % (steps, self._epoch, avg_return_temperature0))\n      if self._sw is not None:\n        self._sw.scalar(\'timing/collect\', time.time() - cur_time,\n                        step=self._epoch)\n        self._sw.scalar(\'rl/avg_return\', avg_return, step=self._epoch)\n        if self._n_eval_episodes > 0:\n          for steps in self._eval_steps:\n            self._sw.scalar(\'rl/avg_return_temperature0_steps%d\' % steps,\n                            self._avg_returns_temperature0[steps][-1],\n                            step=self._epoch)\n        self._sw.scalar(\'rl/n_interactions\', self.task.n_interactions(),\n                        step=self._epoch)\n        self._sw.scalar(\'rl/n_interactions_per_second\',\n                        (self.task.n_interactions() - cur_n_interactions)/ \\\n                        (time.time() - cur_time),\n                        step=self._epoch)\n        cur_n_interactions = self.task.n_interactions()\n        self._sw.scalar(\'rl/n_trajectories\', self.task.n_trajectories(),\n                        step=self._epoch)\n        self._sw.flush()\n      if self._output_dir is not None and self._epoch == 1:\n        self.save_gin()\n      if self._output_dir is not None:\n        self.save_to_file()\n\n  def close(self):\n    if self._sw is None:\n      logging.info(\'Asked to close non-existent SummaryWriter, no-op.\')\n      return\n    logging.info(\'Closing SummaryWriter.\')\n    self._sw.close()\n    logging.info(\'Closed SummaryWriter.\')\n    self._sw = None\n\n\nclass PolicyTrainer(RLTrainer):\n  """"""Trainer that uses a deep learning model for policy.\n\n  Many deep RL methods, such as policy gradeints (reinforce) or actor-critic\n  ones fall into this category, so a lot of classes will be subclasses of this\n  one. But some methods only have a value or Q function, these are different.\n  """"""\n\n  def __init__(self, task, policy_model=None, policy_optimizer=None,\n               policy_lr_schedule=lr.MultifactorSchedule, policy_batch_size=64,\n               policy_train_steps_per_epoch=500, policy_evals_per_epoch=1,\n               policy_eval_steps=1, n_eval_episodes=0,\n               only_eval=False, max_slice_length=1, output_dir=None, **kwargs):\n    """"""Configures the policy trainer.\n\n    Args:\n      task: RLTask instance, which defines the environment to train on.\n      policy_model: Trax layer, representing the policy model.\n          functions and eval functions (a.k.a. metrics) are considered to be\n          outside the core model, taking core model output and data labels as\n          their two inputs.\n      policy_optimizer: the optimizer to use to train the policy model.\n      policy_lr_schedule: learning rate schedule to use to train the policy.\n      policy_batch_size: batch size used to train the policy model.\n      policy_train_steps_per_epoch: how long to train policy in each RL epoch.\n      policy_evals_per_epoch: number of policy trainer evaluations per RL epoch\n          - only affects metric reporting.\n      policy_eval_steps: number of policy trainer steps per evaluation - only\n          affects metric reporting.\n      n_eval_episodes: number of episodes to play with policy at\n        temperature 0 in each epoch -- used for evaluation only\n      only_eval: If set to True, then trajectories are collected only for\n        for evaluation purposes, but they are not recorded.\n      max_slice_length: the maximum length of trajectory slices to use.\n      output_dir: Path telling where to save outputs (evals and checkpoints).\n      **kwargs: arguments for the superclass RLTrainer.\n    """"""\n    super(PolicyTrainer, self).__init__(\n        task,\n        n_eval_episodes=n_eval_episodes,\n        output_dir=output_dir,\n        **kwargs\n    )\n    self._policy_batch_size = policy_batch_size\n    self._policy_train_steps_per_epoch = policy_train_steps_per_epoch\n    self._policy_evals_per_epoch = policy_evals_per_epoch\n    self._policy_eval_steps = policy_eval_steps\n    self._only_eval = only_eval\n    self._max_slice_length = max_slice_length\n    self._policy_dist = distributions.create_distribution(task.action_space)\n\n    # Inputs to the policy model are produced by self._policy_batches_stream.\n    self._policy_inputs = supervised.Inputs(\n        train_stream=lambda _: self.policy_batches_stream())\n\n    policy_model = functools.partial(\n        policy_model,\n        policy_distribution=self._policy_dist,\n    )\n\n    # This is the policy Trainer that will be used to train the policy model.\n    # * inputs to the trainer come from self.policy_batches_stream\n    # * outputs, targets and weights are passed to self.policy_loss\n    self._policy_trainer = supervised.Trainer(\n        model=policy_model,\n        optimizer=policy_optimizer,\n        lr_schedule=policy_lr_schedule,\n        loss_fn=self.policy_loss,\n        inputs=self._policy_inputs,\n        output_dir=output_dir,\n        metrics=self.policy_metrics,\n    )\n    self._policy_collect_model = policy_model(mode=\'collect\')\n    policy_batch = next(self.policy_batches_stream())\n    self._policy_collect_model.init(shapes.signature(policy_batch))\n    self._policy_eval_model = policy_model(mode=\'eval\')  # Not collecting stats\n    self._policy_eval_model.init(shapes.signature(policy_batch))\n    if self._task._initial_trajectories == 0:\n      self._task.remove_epoch(0)\n      self._collect_trajectories()\n\n  @property\n  def policy_loss(self):\n    """"""Policy loss.""""""\n    return NotImplementedError\n\n  @property\n  def policy_metrics(self):\n    return {\'policy_loss\': self.policy_loss}\n\n  def policy_batches_stream(self):\n    """"""Use self.task to create inputs to the policy model.""""""\n    return NotImplementedError\n\n  def policy(self, trajectory, temperature=1.0):\n    """"""Chooses an action to play after a trajectory.""""""\n    model = self._policy_collect_model\n    if temperature != 1.0:  # When evaluating (t != 1.0), don\'t collect stats\n      model = self._policy_eval_model\n      model.state = self._policy_collect_model.state\n    model.weights = self._policy_trainer.model_weights\n    tr_slice = trajectory[-self._max_slice_length:]\n    trajectory_np = tr_slice.to_np(timestep_to_np=self.task.timestep_to_np)\n    # Add batch dimension to trajectory_np and run the model.\n    pred = model(trajectory_np.observations[None, ...], n_accelerators=1)\n    # Pick element 0 from the batch (the only one), last (current) timestep.\n    pred = pred[0, -1, :]\n    sample = self._policy_dist.sample(pred, temperature=temperature)\n    result = (sample, pred)\n    if math.backend_name() == \'jax\':\n      result = math.nested_map(lambda x: x.copy(), result)\n    return result\n\n  def train_epoch(self):\n    """"""Trains RL for one epoch.""""""\n    # When restoring, calculate how many evals are remaining.\n    n_evals = remaining_evals(\n        self._policy_trainer.step,\n        self._epoch,\n        self._policy_train_steps_per_epoch,\n        self._policy_evals_per_epoch)\n    for _ in range(n_evals):\n      self._policy_trainer.train_epoch(\n          self._policy_train_steps_per_epoch // self._policy_evals_per_epoch,\n          self._policy_eval_steps)\n\n  def close(self):\n    self._policy_trainer.close()\n    super().close()\n\n\ndef remaining_evals(cur_step, epoch, train_steps_per_epoch, evals_per_epoch):\n  """"""Helper function to calculate remaining evaluations for a trainer.\n\n  Args:\n    cur_step: current step of the supervised trainer\n    epoch: current epoch of the RL trainer\n    train_steps_per_epoch: supervised trainer steps per RL epoch\n    evals_per_epoch: supervised trainer evals per RL epoch\n\n  Returns:\n    number of remaining evals to do this epoch\n\n  Raises:\n    ValueError if the provided numbers indicate a step mismatch\n  """"""\n  if epoch < 1:\n    raise ValueError(\'Epoch must be at least 1, got %d\' % epoch)\n  prev_steps = (epoch - 1) * train_steps_per_epoch\n  done_steps_this_epoch = cur_step - prev_steps\n  if done_steps_this_epoch < 0:\n    raise ValueError(\'Current step (%d) < previously done steps (%d).\'\n                     % (cur_step, prev_steps))\n  train_steps_per_eval = train_steps_per_epoch // evals_per_epoch\n  if done_steps_this_epoch % train_steps_per_eval != 0:\n    raise ValueError(\'Done steps (%d) must divide train steps per eval (%d).\'\n                     % (done_steps_this_epoch, train_steps_per_eval))\n  return evals_per_epoch - (done_steps_this_epoch // train_steps_per_eval)\n\n\nclass PolicyGradientTrainer(PolicyTrainer):\n  """"""Trains a policy model using policy gradient on the given RLTask.""""""\n\n  @property\n  def policy_loss(self):\n    """"""Policy loss.""""""\n    return distributions.LogLoss(distribution=self._policy_dist)\n\n  def policy_batches_stream(self):\n    """"""Use self.task to create inputs to the policy model.""""""\n    for np_trajectory in self._task.trajectory_batch_stream(\n        self._policy_batch_size,\n        epochs=[-1],\n        max_slice_length=self._max_slice_length,\n        sample_trajectories_uniformly=True):\n      ret = np_trajectory.returns\n      ret = (ret - np.mean(ret)) / np.std(ret)  # Normalize returns.\n      # We return a triple (observations, actions, normalized returns) which is\n      # later used by the model as (inputs, targets, loss weights).\n      yield (np_trajectory.observations, np_trajectory.actions, ret)\n'"
trax/rl/training_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for RL training.""""""\n\nimport functools\nimport os\nimport pickle\n\nfrom absl.testing import absltest\nimport tensorflow as tf\n\nfrom trax import layers as tl\nfrom trax import lr_schedules\nfrom trax import models\nfrom trax import optimizers as opt\nfrom trax import test_utils\nfrom trax.rl import task as rl_task\nfrom trax.rl import training\n\n\nclass TrainingTest(absltest.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    test_utils.ensure_flag(\'test_tmpdir\')\n\n  def test_policytrainer_save_restore(self):\n    """"""Check save and restore of policy trainer.""""""\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=10,\n                          max_steps=200)\n    model = functools.partial(\n        models.Policy,\n        body=lambda mode: tl.Serial(  # pylint: disable=g-long-lambda\n            tl.Dense(64), tl.Relu(), tl.Dense(64), tl.Relu()\n        ),\n    )\n    tmp_dir = self.create_tempdir().full_path\n    trainer1 = training.PolicyGradientTrainer(\n        task,\n        policy_model=model,\n        policy_optimizer=opt.Adam,\n        policy_batch_size=128,\n        policy_train_steps_per_epoch=1,\n        n_trajectories_per_epoch=2,\n        n_eval_episodes=1,\n        output_dir=tmp_dir)\n    trainer1.run(1)\n    trainer1.run(1)\n    self.assertEqual(trainer1.current_epoch, 2)\n    self.assertEqual(trainer1._policy_trainer.step, 2)\n    # Trainer 2 starts where trainer 1 stopped.\n    trainer2 = training.PolicyGradientTrainer(\n        task,\n        policy_model=model,\n        policy_optimizer=opt.Adam,\n        policy_batch_size=128,\n        policy_train_steps_per_epoch=1,\n        n_trajectories_per_epoch=2,\n        n_eval_episodes=1,\n        output_dir=tmp_dir)\n    trainer2.run(1)\n    self.assertEqual(trainer2.current_epoch, 3)\n    self.assertEqual(trainer2._policy_trainer.step, 3)\n    # Trainer 3 has 2x steps-per-epoch, but epoch 3, should raise an error.\n    trainer3 = training.PolicyGradientTrainer(\n        task,\n        policy_model=model,\n        policy_optimizer=opt.Adam,\n        policy_batch_size=128,\n        policy_train_steps_per_epoch=2,\n        n_trajectories_per_epoch=2,\n        n_eval_episodes=1,\n        output_dir=tmp_dir)\n    self.assertRaises(ValueError, trainer3.run)\n    # Manually set saved epoch to 1.\n    dictionary = {\'epoch\': 1, \'avg_returns\': [0.0],\n                  \'avg_returns_temperature0\': {200: [0.0]}}\n    with tf.io.gfile.GFile(os.path.join(tmp_dir, \'rl.pkl\'), \'wb\') as f:\n      pickle.dump(dictionary, f)\n    # Trainer 3 still should fail as steps between evals are 2, cannot do 1.\n    self.assertRaises(ValueError, trainer3.run)\n    # Trainer 4 does 1 step per eval, should train 1 step in epoch 2.\n    trainer4 = training.PolicyGradientTrainer(\n        task,\n        policy_model=model,\n        policy_optimizer=opt.Adam,\n        policy_batch_size=128,\n        policy_train_steps_per_epoch=2,\n        policy_evals_per_epoch=2,\n        n_trajectories_per_epoch=2,\n        n_eval_episodes=1,\n        output_dir=tmp_dir)\n    trainer4.run(1)\n    self.assertEqual(trainer4.current_epoch, 2)\n    self.assertEqual(trainer4._policy_trainer.step, 4)\n    trainer1.close()\n    trainer2.close()\n    trainer3.close()\n    trainer4.close()\n\n  def test_policytrainer_cartpole(self):\n    """"""Trains a policy on cartpole.""""""\n    task = rl_task.RLTask(\'CartPole-v0\', initial_trajectories=1,\n                          max_steps=200)\n    model = functools.partial(\n        models.Policy,\n        body=lambda mode: tl.Serial(  # pylint: disable=g-long-lambda\n            tl.Dense(64), tl.Relu(), tl.Dense(64), tl.Relu()\n        ),\n    )\n    lr = lambda h: lr_schedules.MultifactorSchedule(  # pylint: disable=g-long-lambda\n        h, constant=1e-2, warmup_steps=100, factors=\'constant * linear_warmup\')\n    trainer = training.PolicyGradientTrainer(\n        task,\n        policy_model=model,\n        policy_optimizer=opt.Adam,\n        policy_lr_schedule=lr,\n        policy_batch_size=128,\n        policy_train_steps_per_epoch=1,\n        n_trajectories_per_epoch=2)\n    # Assert that we get to 200 at some point and then exit so the test is as\n    # fast as possible.\n    for ep in range(200):\n      trainer.run(1)\n      self.assertEqual(trainer.current_epoch, ep + 1)\n      if trainer.avg_returns[-1] == 200.0:\n        return\n    self.fail(\n        \'The expected score of 200 has not been reached. \'\n        \'Maximum was {}.\'.format(max(trainer.avg_returns))\n    )\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/supervised/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Supervised learning imports in Trax.""""""\n\nfrom trax.supervised import inputs\nfrom trax.supervised import tf_inputs\nfrom trax.supervised import trainer_lib\nfrom trax.supervised.inputs import Inputs\nfrom trax.supervised.trainer_lib import train\nfrom trax.supervised.trainer_lib import Trainer\n'"
trax/supervised/inputs.py,31,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Trax input pipeline.""""""\n\nimport math\nimport random\n\nfrom absl import logging\n\nimport gin\nimport numpy as np\n\nfrom trax.math import numpy as jnp\n\n\nclass Inputs(object):\n  """"""Inputs bundle.\n\n  Inputs bundle holds input streams and shapes for a training run.\n  It contains stream-creating functions that return python generators\n  of (input_batch, target_batch) tuples.\n\n  * train_stream: training data that will be used for training\n      may include all the augmentation or selection the training wants\n      the shape of examples is [batch_fn.batch_size, ...]\n  * train_eval_stream: training data used for evaluation\n      examples from training data but usually without augmentation\n      the shape of examples is [batch_fn.eval_batch_size, ...]\n  * eval_stream: evaluation data stream\n      examples from evaluation data, usually without augmentation\n      the shape of examples is [batch_fn.eval_batch_size, ...]\n  * input_shape: the shape of inputs\n      the [...] above, without batch size\n  * input_dtype: the data type of inputs\n  * target_shape: the shape of targets\n      the [...] above, without batch size\n  * target_dtype: the data type of targets\n  """"""\n\n  def __init__(self, train_stream, eval_stream=None, train_eval_stream=None):\n    """"""Initialize a new set of inputs.\n\n    Args:\n      train_stream: a function taking n_devices (an int) and returning\n        a python generator of training batches.\n      eval_stream: a function taking n_devices (an int) and returning\n        a python generator of validation batches;\n        if None, then the training generator will be used for evaluation.\n      train_eval_stream: a function taking n_devices (an int) and returning\n        a python generator of batches from\n        the training set used for evaluation (if None, use train_stream).\n    """"""\n    self._train_stream = train_stream\n    self._eval_stream = eval_stream or self._train_stream\n\n    # TODO(lukaszkaiser): should we get rid of this one day?\n    self._train_eval_stream = train_eval_stream or self._train_stream\n\n    # Peek into the train stream to get an example shape.\n    example_train_batch = next(train_stream(1))\n    self._input_shape = tuple(example_train_batch[0].shape)[1:]\n    self._input_dtype = example_train_batch[0].dtype\n    self._target_shape = tuple(example_train_batch[-1].shape)[1:]\n    self._target_dtype = example_train_batch[-1].dtype\n    self._example_shape = [x.shape for x in example_train_batch]\n    self._example_dtype = [x.dtype for x in example_train_batch]\n\n  def train_stream(self, n_devices):\n    return self._train_stream(n_devices)\n\n  def eval_stream(self, n_devices):\n    return self._eval_stream(n_devices)\n\n  def train_eval_stream(self, n_devices):\n    return self._train_stream(n_devices)\n\n  @property\n  def input_shape(self):\n    """"""Example input shape, without batch dimension.""""""\n    return self._input_shape\n\n  @property\n  def target_shape(self):\n    """"""Example target shape, without batch dimension.""""""\n    return self._target_shape\n\n  @property\n  def input_dtype(self):\n    """"""Dtype of the input.""""""\n    return self._input_dtype\n\n  @property\n  def target_dtype(self):\n    """"""Dtype of the target.""""""\n    return self._target_dtype\n\n  @property\n  def example_shape_dtype(self):\n    """"""Shape and Dtype of an example batch.""""""\n    return self._example_shape, self._example_dtype\n\n\n# Batching and input pipeline creation helpers.\n\n\n@gin.configurable()\ndef batcher(data_streams=gin.REQUIRED, variable_shapes=True,\n            batch_size_per_device=32, batch_size=None, eval_batch_size=32,\n            bucket_length=32, buckets=None,\n            buckets_include_inputs_in_length=False,\n            batch_shuffle_size=None, max_eval_length=None,\n            # TODO(afrozm): Unify padding logic.\n            strict_pad_on_len=False):\n  """"""Batcher: create trax Inputs from single-example data-streams.""""""\n  # TODO(lukaszkaiser, jonni): revisit arguments, their semantics and naming.\n  # For now leaving the arguments as in batch_fn to reduce gin config changes.\n  if callable(data_streams):  # If we pass a function, e.g., through gin, call.\n    train_stream, eval_stream = data_streams()\n  else:\n    train_stream, eval_stream = data_streams\n  # pylint: disable=g-long-lambda\n  batch_train_stream = lambda n_devices: batch_fn(\n      train_stream(), True, n_devices, variable_shapes,\n      batch_size_per_device, batch_size, eval_batch_size,\n      bucket_length, buckets, buckets_include_inputs_in_length,\n      batch_shuffle_size, max_eval_length, strict_pad_on_len)\n  batch_eval_stream = lambda n_devices: batch_fn(\n      eval_stream(), False, n_devices, variable_shapes,\n      batch_size_per_device, batch_size, eval_batch_size,\n      bucket_length, buckets, buckets_include_inputs_in_length,\n      batch_shuffle_size, max_eval_length, strict_pad_on_len)\n  batch_train_eval_stream = lambda n_devices: batch_fn(\n      train_stream(), False, n_devices, variable_shapes,\n      batch_size_per_device, batch_size, eval_batch_size,\n      bucket_length, buckets, buckets_include_inputs_in_length,\n      batch_shuffle_size, max_eval_length, strict_pad_on_len)\n  # pylint: enable=g-long-lambda\n  return Inputs(train_stream=batch_train_stream,\n                eval_stream=batch_eval_stream,\n                train_eval_stream=batch_train_eval_stream)\n\n\ndef batch_fn(dataset, training, n_devices, variable_shapes,\n             batch_size_per_device=32, batch_size=None, eval_batch_size=32,\n             bucket_length=32, buckets=None,\n             buckets_include_inputs_in_length=False,\n             batch_shuffle_size=None, max_eval_length=None,\n             strict_pad_on_len=False):\n  """"""Batching function.""""""\n  # TODO(lukaszkaiser, jonni): revisit arguments, their semantics and naming.\n  # After that, create a proper doc-string; we may also not need to pass both\n  # training and eval arguments here, as batcher calls the function separately\n  # now and it\'s not under gin-config any more -- consider reducing args.\n  batch_size = batch_size or batch_size_per_device * n_devices\n  # If bucketing is not specified, check if target shapes are variable.\n  cur_batch_size = batch_size if training else eval_batch_size\n  # Make cur_batch_size divisible by n_devices.\n  cur_batch_size = max(cur_batch_size // n_devices, 1) * n_devices\n  # Create heuristic buckets if none are specified.\n  if buckets is None:\n    logging.info(\'Heuristically setting bucketing to %s based on shapes \'\n                 \'of target tensors.\', variable_shapes)\n    if variable_shapes:\n      bucket_boundaries = [bucket_length // 4, bucket_length // 2,\n                           bucket_length, bucket_length * 2,\n                           bucket_length * 4, bucket_length * 8,\n                           bucket_length * 16]\n      if not training:\n        max_eval_length = max_eval_length or bucket_length * 32\n        bucket_boundaries[-1] = max_eval_length\n      # We will pad to boundaries which pads to bucket_boundary - 1: add 1 here.\n      bucket_boundaries = [b + 1 for b in bucket_boundaries]\n      bucket_batch_sizes = [cur_batch_size * 4, cur_batch_size * 2,\n                            cur_batch_size, cur_batch_size // 2,\n                            cur_batch_size // 4, cur_batch_size // 8,\n                            cur_batch_size // 16, 1]\n      if not training:\n        # The last bucket batch size is always 1, but the one-but-last is\n        # sized to accomodate the final length = bucket_boundaries[-1], which\n        # we changed for eval above -- so adjusting here too.\n        bucket_batch_sizes[-2] = cur_batch_size // max_eval_length\n      # Make batch sizes divisible by n_devices.\n      bucket_batch_sizes = [max(b // n_devices, 1) * n_devices\n                            for b in bucket_batch_sizes]\n      buckets = (bucket_boundaries, bucket_batch_sizes)\n\n  if buckets:\n    logging.info(\'Bucketing with buckets %s.\', str(buckets))\n    def example_length(x):\n      """"""The length function used by bucket_by_sequence_length to bucket.""""""\n      # The input x is a tuple to go on the stack, typically either\n      # (input, target) or (input, target, mask).\n      example_inputs, target = x[0], x[1]\n      # Length is the shape of axis 0 here (no batch yet).\n      other_length = 0  # We include input length only if asked.\n      if buckets_include_inputs_in_length:\n        other_length = example_inputs.shape[0]\n      return max(target.shape[0], other_length)\n    boundaries, batch_sizes = buckets\n    dataset = bucket_by_length(\n        dataset, example_length, boundaries, batch_sizes, strict_pad_on_len)\n  else:\n    logging.info(\'Not Bucketing cur_batch_size %d.\', cur_batch_size)\n    dataset = batch_data(dataset, cur_batch_size)\n  if training and batch_shuffle_size is not None:\n    dataset = shuffle_data(dataset, batch_shuffle_size)\n  return dataset\n\n\ndef shuffle_data(samples, queue_size):\n  """"""Shuffles a sample stream using a random-out next-in queue of given size.\n\n  Args:\n    samples: Stream of samples for eventual use as training data or eval data.\n    queue_size: Minimum number of samples within which the streamed shuffling\n        takes place.\n\n  Yields:\n    Shuffled stream of samples, ready for further processing, e.g., grouping\n    into batches.\n  """"""\n  if queue_size < 1:\n    raise ValueError(f\'Arg queue_size ({queue_size}) is less than 1.\')\n  if queue_size == 1:\n    logging.warning(\'Queue size of 1 results in no shuffling.\')\n  queue = []\n  try:\n    # Prep: fill the queue.\n    for _ in range(queue_size):\n      queue.append(next(samples))\n\n    # Core streaming shuffle: yield sample from random location in queue, then\n    # fill that location with new sample from input stream.\n    for sample in samples:\n      i = np.random.randint(queue_size)\n      yield queue[i]\n      queue[i] = sample\n  except StopIteration:\n    # Only get here if the initial queue fill fails.\n    logging.warning(\n        \'Not enough samples (%d) to fill initial queue (size %d).\',\n        len(queue), queue_size)\n\n  # No new samples coming in; shuffle and drain the queue.\n  np.random.shuffle(queue)\n  for sample in queue:\n    yield sample\n\n\ndef batch_data(generator, batch_size):\n  """"""Batch and pad generator as in tf.data.Dataset.padded_batch.""""""\n  buf = []\n  # TODO(lukaszkaiser): convert to ValueError\n  assert batch_size > 0, f\'Batch size must be positive, but is {batch_size}\'\n  for example in generator:\n    buf.append(example)  # Examples are tuples of tensors.\n    if len(buf) == batch_size:\n      # buf is a list of tuples, e.g., [(in1, tgt1), (in2, tgt2), (in3, tgt3)]\n      # batch is a tuple of arrays: ([in1, in2, in3], [tgt1, tgt2, tgt3])\n      batch = tuple(np.stack(x) for x in zip(*buf))\n      # Note that it\'s the same shape as each example with added batch dim.\n      yield batch\n      buf = []\n\n\ndef pad_to_max_dims(tensors, boundary=None, strict_pad_on_len=False):\n  """"""Pad a tuple of tensors to a joint dimension and return their batch.\n\n  For example, a pair of tensors of shape (2, 10) and (3, 9) will be padded\n  to (3, 10) both and the returned tensor will have shape (2, 3, 10).\n\n  When boundary is specified, we try to pad all unknown dimensions to boundary\n  if possible, which can help reduce the number of different shapes occuring\n  in the tensors and speed up XLA compilation. So, for example, a pair of\n  tensors of shapes (8, 10), (8, 9) with boundary=12 will be padded to (8, 12).\n\n  One special case occurs when boundary is much higher than the padding length\n  that we\'d use without boundary. For example, tensors (2, 10) and (3, 9) with\n  boundary=12 could end up padded to (12, 12), but this is very wasteful in\n  the first dimension. In that case, we will use the closest power-of-2 instead\n  of the boundary, so the we will end up padding to (4, 12) instead of (12, 12).\n\n  Args:\n    tensors: a tuple or list of tensors to pad\n    boundary: int or None; if given, expand the padded dimensions to this size\n    strict_pad_on_len: bool; if true we pad on the length dimension, dim[0]\n      strictly as a multiple of boundary.\n\n  Returns:\n    a tensor, the tensors padded together\n  """"""\n  # TODO(afrozm): Unify this later.\n  if strict_pad_on_len or isinstance(boundary, (list, tuple)):\n    ndim = tensors[0].ndim\n    if not isinstance(boundary, (list, tuple)):\n      boundary = [boundary] * ndim\n\n    if ndim != len(boundary):\n      raise ValueError(f\'ndim != len(boundary) - \'\n                       f\'ndim({ndim}) vs boundary({boundary}) \'\n                       f\'len(boundary) = {len(boundary)}.\')\n\n    max_len_per_dim = [0] * ndim\n    for tensor in tensors:\n      max_len_per_dim = [\n          max(e, s) for e, s in zip(tensor.shape, max_len_per_dim)]\n\n    # Round everything up to a multiple of boundary in the respective dimension.\n    len_per_dim = [\n        max_len_per_dim[i] if not b else b * math.ceil(max_len_per_dim[i] / b)\n        for i, b in enumerate(boundary)]\n\n    padded_tensors = [\n        np.pad(t, [(0, len_per_dim[i] - t.shape[i]) for i in range(ndim)],\n               mode=\'constant\', constant_values=t.dtype.type(0))\n        for t in tensors]\n\n    return np.stack(padded_tensors)\n\n  max_len_to_pad = []\n  padding_needed = False\n  dim = len(tensors[0].shape)\n  for i in range(dim):\n    max_len = max([t.shape[i] for t in tensors])\n    min_len = min([t.shape[i] for t in tensors])\n    if max_len == min_len:  # No padding needed.\n      max_len_to_pad.append(max_len)\n    elif boundary is None:\n      max_len_to_pad.append(max_len)\n      padding_needed = True\n    else:\n      padding_needed = True\n      cur_boundary = max(max_len, boundary)\n      if 2 * max_len < cur_boundary:\n        cur_boundary = 2**int(np.ceil(np.log2(max_len)))\n      max_len_to_pad.append(cur_boundary)\n  if not padding_needed:\n    return np.stack(tensors)\n  padded_tensors = []\n  for t in tensors:\n    pad_widths = [(0, max_len_to_pad[i] - t.shape[i]) for i in range(dim)]\n    padded_t = np.pad(t, pad_widths, mode=\'constant\',\n                      constant_values=t.dtype.type(0))\n    padded_tensors.append(padded_t)\n  return np.stack(padded_tensors)\n\n\ndef bucket_by_length(generator, length_fn, boundaries, batch_sizes,\n                     strict_pad_on_len=False):\n  """"""Bucket by length, like tf.data.experimental.bucket_by_sequence_length.\n\n  Args:\n    generator: python generator to draw data from.\n    length_fn: a function taking the example and returning the length.\n    boundaries: a list of bucket boundaries.\n    batch_sizes: a list of batch sizes.\n    strict_pad_on_len: bool; if true we pad on the length dimension, dim[0]\n      strictly as a multiple of boundary.\n\n  Yields:\n    An input batch, which comes from one of the buckets.\n  """"""\n  buckets = [[] for _ in range(len(batch_sizes))]\n  boundaries = boundaries + [math.inf]  # Max boundary is unlimited.\n  max_idx = len(boundaries)\n  for example in generator:\n    length = length_fn(example)\n    bucket_idx = min([i for i, b in enumerate(boundaries) if length < b])\n    buckets[bucket_idx].append(example)\n    if len(buckets[bucket_idx]) == batch_sizes[bucket_idx]:\n      batch = zip(*buckets[bucket_idx])\n      boundary = boundaries[bucket_idx] - 1 if bucket_idx < max_idx else None\n      padded_batch = tuple(\n          pad_to_max_dims(x, boundary, strict_pad_on_len) for x in batch)\n      yield padded_batch\n      buckets[bucket_idx] = []\n\n\n# Example input functions.\n\n\n@gin.configurable()\ndef random_inputs(\n    input_shape=gin.REQUIRED, input_dtype=jnp.int32, input_range=(0, 255),\n    output_shape=gin.REQUIRED, output_dtype=jnp.int32, output_range=(0, 9)):\n  """"""Make random Inputs for debugging.\n\n  Args:\n    input_shape: the shape of inputs (including batch dimension).\n    input_dtype: the type of the inputs (int32 by default).\n    input_range: the range of inputs (defaults to (0, 255)).\n    output_shape: the shape of outputs (including batch dimension).\n    output_dtype: the type of the outputs (int32 by default).\n    output_range: the range of outputs (defaults to (0, 9)).\n\n  Returns:\n    trax.inputs.Inputs\n  """"""\n  def random_minibatches(n_devices):\n    """"""Generate a stream of random mini-batches.""""""\n    assert input_range[0] % n_devices == 0\n    if input_dtype in [jnp.float16, jnp.float32, jnp.float64]:\n      rand = np.random.uniform\n    else:\n      rand = np.random.random_integers\n    while True:\n      inp = rand(input_range[0], input_range[1], input_shape)\n      inp = inp.astype(input_dtype)\n      out = rand(output_range[0], output_range[1], output_shape)\n      out = out.astype(output_dtype)\n      yield inp, out\n\n  return Inputs(random_minibatches)\n\n\ndef _pad_to_multiple_of(x, y, axis):\n  """"""Pads x to multiple of y on the given axis.""""""\n  pad_len = np.ceil(x.shape[axis] / float(y)) * y\n  pad_widths = [(0, 0)] * len(x.shape)\n  pad_widths[axis] = (0, int(pad_len - x.shape[axis]))\n  return np.pad(x, pad_widths, mode=\'constant\',\n                constant_values=x.dtype.type(0))\n\n\n@gin.configurable()\ndef sequence_copy_inputs(\n    vocab_size=gin.REQUIRED, batch_size=gin.REQUIRED, train_length=gin.REQUIRED,\n    eval_min_length=gin.REQUIRED, eval_max_length=gin.REQUIRED, reverse=False,\n    pad_to_multiple=32):\n  """"""Inputs for the sequence copy problem: 0w0w for w in [1..vocab_size-1]*.\n\n  Args:\n    vocab_size: how many symbols to use.\n    batch_size: how large are the batches.\n    train_length: maximum length of w for training.\n    eval_min_length: minimum length of w for eval.\n    eval_max_length : maximum length of w for eval.\n    reverse: bool (optional, false by default): reverse the second sequence.\n    pad_to_multiple: int, pad length to be multiple of this number.\n\n  Returns:\n    trax.inputs.Inputs\n  """"""\n  def random_minibatches(length_list):\n    """"""Generate a stream of random mini-batches.""""""\n    while True:\n      length = random.choice(length_list)\n      assert length % 2 == 0\n      w_length = (length // 2) - 1\n      w = np.random.randint(low=1, high=vocab_size-1,\n                            size=(batch_size, w_length))\n      zero = np.zeros([batch_size, 1], np.int32)\n      loss_weights = np.concatenate([np.zeros((batch_size, w_length+2)),\n                                     np.ones((batch_size, w_length))], axis=1)\n      if reverse:\n        x = np.concatenate([zero, w, zero, jnp.flip(w, axis=1)], axis=1)\n      else:\n        x = np.concatenate([zero, w, zero, w], axis=1)\n      x = _pad_to_multiple_of(x, pad_to_multiple, 1)\n      loss_weights = _pad_to_multiple_of(loss_weights, pad_to_multiple, 1)\n      yield (x, x, loss_weights)  # Here inputs and targets are the same.\n\n  train_lengths = [2*(i+2) for i in range(train_length - 1)]\n  eval_lengths = [2*(i+1) for i in range(eval_min_length, eval_max_length)]\n  return Inputs(\n      train_stream=lambda _: random_minibatches(train_lengths),\n      eval_stream=lambda _: random_minibatches(eval_lengths)\n  )\n\n\ndef lower_endian_to_number(l, base):\n  """"""Helper function: convert a list of digits in the given base to a number.""""""\n  return sum([d * (base**i) for i, d in enumerate(l)])\n\n\ndef number_to_lower_endian(n, base):\n  """"""Helper function: convert a number to a list of digits in the given base.""""""\n  if n < base:\n    return [n]\n  return [n % base] + number_to_lower_endian(n // base, base)\n\n\ndef random_number_lower_endian(length, base):\n  """"""Helper function: generate a random number as a lower-endian digits list.""""""\n  if length == 1:  # Last digit can be 0 only if length is 1.\n    return [np.random.randint(base)]\n  prefix = [np.random.randint(base) for _ in range(length - 1)]\n  return prefix + [np.random.randint(base - 1) + 1]  # Last digit is not 0.\n\n\n@gin.configurable()\ndef addition_inputs(\n    vocab_size=gin.REQUIRED, batch_size=gin.REQUIRED, train_length=gin.REQUIRED,\n    eval_min_length=gin.REQUIRED, eval_max_length=gin.REQUIRED,\n    pad_to_multiple=32):\n  """"""Inputs for the add problem: <S>x+y<S>(x+y).\n\n  Args:\n    vocab_size: how many symbols to use.\n    batch_size: how large are the batches.\n    train_length: maximal length of w for training.\n    eval_min_length: minimal length of w for eval.\n    eval_max_length: maximal length of w for eval.\n    pad_to_multiple: int, pad length to be multiple of this number.\n\n  Returns:\n    trax.inputs.Inputs\n  """"""\n  base = vocab_size - 3  # We use 0 to pad, base+1 as ""+"" and base+2 as ""<S>"".\n  def single_example(max_length, min_length):\n    """"""Generate a stream of random mini-batches.""""""\n    add_len = (min_length - 1) // 2\n    l1 = np.random.randint((max_length - add_len + 1) // 2) + add_len\n    l2 = np.random.randint(max_length - l1 - 1) + 1\n    n1 = random_number_lower_endian(l1, base)\n    n2 = random_number_lower_endian(l2, base)\n    result = lower_endian_to_number(n1, base) + lower_endian_to_number(\n        n2, base)\n    inp = n1 + [base] + n2\n    tgt = number_to_lower_endian(result, base)\n    x = [base+2] + [i+1 for i in inp] + [base+2] + [i+1 for i in tgt]\n    weights = ([0] * (len(inp) + 2)) + ([1] * len(tgt))\n    return (x, weights)\n\n  def batches(max_length, min_length):\n    """"""Batches of examples.""""""\n    if max_length < 3:\n      raise ValueError(\'Maximum length must be at least 3.\')\n    while True:\n      res = [single_example(max_length, min_length) for _ in range(batch_size)]\n      l = max([len(x[0]) for x in res])\n      xs = np.array([x[0] + [0] * (l - len(x[0])) for x in res])\n      ws = np.array([x[1] + [0] * (l - len(x[1])) for x in res],\n                    dtype=np.float32)\n      xs = _pad_to_multiple_of(xs, pad_to_multiple, 1)\n      ws = _pad_to_multiple_of(ws, pad_to_multiple, 1)\n      yield (xs, xs, ws)\n\n  return Inputs(\n      train_stream=lambda _: batches(train_length, 3),\n      eval_stream=lambda _: batches(eval_max_length, eval_min_length)\n  )\n'"
trax/supervised/inputs_test.py,7,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for trax.supervised.inputs.""""""\n\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\nimport numpy as np\nfrom trax.supervised import inputs\n\n\nclass InputsTest(parameterized.TestCase):\n\n  @parameterized.named_parameters(\n      (\'zero\', 0),\n      (\'negative\', -5),\n  )\n  def test_shuffle_data_raises_error_queue_size(self, queue_size):\n    samples = iter(range(10))\n    with self.assertRaises(ValueError):\n      _ = list(inputs.shuffle_data(samples, queue_size))\n\n  @parameterized.named_parameters(\n      (\'one\', 1),\n      (\'two\', 2),\n      (\'twenty\', 20),\n  )\n  def test_shuffle_data_queue_size(self, queue_size):\n    samples = iter(range(100, 200))\n    shuffled_stream = inputs.shuffle_data(samples, queue_size)\n    first_ten = [next(shuffled_stream) for _ in range(10)]\n\n    # Queue size limits how far ahead/upstream the current sample can reach.\n    self.assertLess(first_ten[0], 100 + queue_size)\n    self.assertLess(first_ten[3], 103 + queue_size)\n    self.assertLess(first_ten[9], 109 + queue_size)\n\n    unshuffled_first_ten = list(range(100, 110))\n    if queue_size == 1:  # Degenerate case: no shuffling can happen.\n      self.assertEqual(first_ten, unshuffled_first_ten)\n    if queue_size > 1:\n      self.assertNotEqual(first_ten, unshuffled_first_ten)\n\n  @parameterized.named_parameters(\n      (\'qsize_100_n_001\', 100, 1),\n      (\'qsize_100_n_099\', 100, 99),\n      (\'qsize_100_n_100\', 100, 100),\n      (\'qsize_100_n_101\', 100, 101),\n      (\'qsize_100_n_199\', 100, 199),\n  )\n  def test_shuffle_data_yields_all_samples(self, queue_size, n_samples):\n    samples = iter(range(n_samples))\n    shuffled_stream = inputs.shuffle_data(samples, queue_size)\n    self.assertLen(list(shuffled_stream), n_samples)\n\n  def test_batch_data(self):\n    dataset = ((i, i+1) for i in range(10))\n    batches = inputs.batch_data(dataset, 10)\n    batch = next(batches)\n    self.assertLen(batch, 2)\n    self.assertEqual(batch[0].shape, (10,))\n\n  def test_pad_to_max_dims(self):\n    tensors1 = [np.zeros((3, 10)), np.ones((3, 10))]\n    padded1 = inputs.pad_to_max_dims(tensors1)\n    self.assertEqual(padded1.shape, (2, 3, 10))\n    tensors2 = [np.zeros((2, 10)), np.ones((3, 9))]\n    padded2 = inputs.pad_to_max_dims(tensors2)\n    self.assertEqual(padded2.shape, (2, 3, 10))\n    tensors3 = [np.zeros((8, 10)), np.ones((8, 9))]\n    padded3 = inputs.pad_to_max_dims(tensors3, 12)\n    self.assertEqual(padded3.shape, (2, 8, 12))\n    tensors4 = [np.zeros((2, 10)), np.ones((3, 9))]\n    padded4 = inputs.pad_to_max_dims(tensors4, 12)\n    self.assertEqual(padded4.shape, (2, 4, 12))\n\n  def test_pad_to_max_dims_boundary_list(self):\n    tensors = [np.zeros((1, 15, 31)), np.ones((2, 10, 35)), np.ones((4, 2, 3))]\n    padded_tensors = inputs.pad_to_max_dims(tensors, boundary=(None, 15, 20))\n    # no boundary, only max in the first dim, 15 is already the max len in\n    # second dim, last dim padded to multiple of 20.\n    # The outer dim is the batch here.\n    self.assertEqual(padded_tensors.shape, (3, 4, 15, 40))\n\n  def test_pad_to_max_dims_strict_pad_on_len(self):\n    tensors = [np.ones((15,)), np.ones((12,)), np.ones((14,))]\n    padded_tensors = inputs.pad_to_max_dims(\n        tensors, boundary=10, strict_pad_on_len=True)\n    self.assertEqual(padded_tensors.shape, (3, 20))\n\n  def test_bucket_by_length(self):\n    def fake_generator(length, num_examples=1):\n      for _ in range(num_examples):\n        yield (np.ones((length,)), np.ones((length,)))\n\n    def length_function(example):\n      return max(example[0].shape[0], example[1].shape[0])\n\n    batches = list(inputs.bucket_by_length(fake_generator(5, 6),\n                                           length_function,\n                                           [20 + 1],\n                                           [2],\n                                           strict_pad_on_len=True))\n\n    # We\'ll get three batches of 2 examples each.\n    self.assertLen(batches, 3)\n    self.assertIsInstance(batches[0], tuple)\n    self.assertLen(batches[0], 2)\n    self.assertEqual((2, 20), batches[0][0].shape)\n    self.assertEqual((2, 20), batches[0][1].shape)\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/supervised/lr_functions.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Learning rate (LR) schedules as functions of time (step number).\n\nThis is work in progress, intertwined with ongoing changes in supervised\ntraining and optimizers. When complete, the learning rate schedules in this\nfile are intended to replace the prior ones in trax/lr_schedules.py. The\ncurrent package location/name (trax/supervised/lr_functions.py) is\ncorrespondingly temporary.\n""""""\n\nimport math\n\n\ndef constant(value):\n  """"""Returns an LR schedule that is constant from time (step) 1 to infinity.""""""\n  return _BodyAndTail(value, body_start=1)\n\n\ndef warmup(n_warmup_steps, max_value):\n  """"""Returns an LR schedule with linear warm-up followed by constant value.\n\n  Args:\n    n_warmup_steps: Number of steps during which the learning rate rises on\n        a line connecting (0, 0) and (n_warmup_steps, max_value).\n    max_value: Value for learning rate after warm-up has finished.\n  """"""\n  return _BodyAndTail(max_value, body_start=n_warmup_steps + 1)\n\n\ndef warmup_and_rsqrt_decay(n_warmup_steps, max_value):\n  """"""Returns an LR schedule with warm-up + reciprocal square root decay.""""""\n  return _BodyAndTail(max_value, tail_start=n_warmup_steps + 1, tail_fn=_rsqrt)\n\n\nclass _BodyAndTail:\n  """"""Defines a curve over time as a linear ramp + constant body + curvy tail.\n\n  The body is a span of constant learning rate, and can be the entire curve.\n  The warm-up, if present, is based on the line connecting points (0, 0) and\n  (body_start, body_value). The tail, if defined, is a function from time to\n  learning rate that is used for all training steps from tail_start on.\n  """"""\n\n  def __init__(\n      self, body_value, body_start=None, tail_start=None, tail_fn=None):\n    """"""Specifies a body-and-tail time curve.\n\n    Args:\n      body_value: Constant learning rate for the body of the curve (after\n          warm-up and before tail). Also is the reference (maximum) value for\n          calculating warm-up values and tail values.\n      body_start: Training step number at which the body starts. If None, takes\n          its value from tail_start, which amounts to there being no body. All\n          steps from 1 to body_start - 1 are computed using a linear warm-up.\n      tail_start: Training step number at which the tail starts. If None, the\n          body value remains until the end of training.\n      tail_fn: Function returning a floating point learning rate, given inputs:\n            - step_number (absolute step number from the start of training)\n            - tail_start (step number at which the tail starts)\n            - body_value (value relative to which the tail should be computed)\n    """"""\n    if body_start is None and tail_start is None:\n      raise ValueError(\'Both body start and tail start are None.\')\n    if tail_start is not None and tail_fn is None:\n      raise ValueError(\n          f\'Tail start has value ({tail_start}) but tail_fn is None.\')\n    if body_start is None:\n      body_start = tail_start if tail_start is not None else 1\n\n    self._body_value = body_value\n    self._body_start = body_start\n    self._tail_start = tail_start\n    self._tail_fn = tail_fn\n\n  def __call__(self, step_number):\n    """"""Returns the learning rate for the given step number.""""""\n    if step_number < self._body_start:\n      return (step_number / self._body_start) * self._body_value\n    elif self._tail_start is not None and step_number >= self._tail_start:\n      return self._tail_fn(step_number, self._tail_start, self._body_value)\n    else:\n      return self._body_value\n\n\ndef _rsqrt(step_number, tail_start, body_value):\n  """"""Computes a tail using a scaled reciprocal square root of step number.\n\n  Args:\n    step_number: Absolute step number from the start of training.\n    tail_start: Step number at which the tail of the curve starts.\n    body_value: Value relative to which the tail should be computed.\n\n  Returns:\n    A learning rate value that falls as the reciprocal square root of the step\n    number, scaled so that it joins smoothly with the body of a BodyAndTail\n    instance.\n  """"""\n  return body_value * (math.sqrt(tail_start) / math.sqrt(step_number))\n\n\nclass _CosineSawtoothTail:\n  """"""Cosine-sawtooth-shaped tail that simulates warm restarts.\n\n  Creates a cyclic learning rate curve; each cycle is half of a cosine, falling\n  from maximum value to minimum value. For motivation and further details, see\n  Loshchilov & Hutter (2017) [https://arxiv.org/abs/1608.03983].\n  """"""\n\n  def __init__(self, steps_per_cycle, min_value=1e-5):\n    """"""Configures the periodic behavior of this learning rate function.\n\n    Args:\n      steps_per_cycle: Number of training steps per sawtooth cycle. The\n          learning rate will be highest at the start of each cycle, and lowest\n          at the end.\n      min_value: Minimum value, reached at the end of each cycle.\n    """"""\n    self._steps_per_cycle = steps_per_cycle\n    self._min_value = min_value\n\n  def __call__(self, step_number, tail_start, body_value):\n    """"""Returns the learning rate for the given step number, when in the tail.\n\n    Args:\n      step_number: Absolute step number from the start of training.\n      tail_start: Step number at which the tail of the curve starts.\n      body_value: Value relative to which the tail should be computed.\n    """"""\n    max_value = body_value\n    min_value = self._min_value\n    position_in_cycle = (\n        ((step_number - tail_start) / self._steps_per_cycle) % 1.0)\n    theta = math.pi * position_in_cycle\n    return min_value + (max_value - min_value) * .5 * (1 + math.cos(theta))\n'"
trax/supervised/lr_functions_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests of learning rate schedules.""""""\n\nimport math\n\nfrom absl.testing import absltest\n\nfrom trax.supervised import lr_functions\n\n\nclass LRFunctionsTest(absltest.TestCase):\n\n  def test_warmup(self):\n    lr_fn = lr_functions.warmup(9, .01)\n\n    # Linear warm-up.\n    self.assertAlmostEqual(.001, lr_fn(1))\n    self.assertAlmostEqual(.002, lr_fn(2))\n    self.assertAlmostEqual(.005, lr_fn(5))\n    self.assertAlmostEqual(.009, lr_fn(9))\n\n    # Constant thereafter.\n    self.assertAlmostEqual(.01, lr_fn(10))\n    self.assertAlmostEqual(.01, lr_fn(11))\n    self.assertAlmostEqual(.01, lr_fn(20))\n    self.assertAlmostEqual(.01, lr_fn(300))\n    self.assertAlmostEqual(.01, lr_fn(4000))\n\n  def test_constant(self):\n    lr_fn = lr_functions.constant(.02)\n    self.assertEqual(.02, lr_fn(1))\n    self.assertEqual(.02, lr_fn(20))\n    self.assertEqual(.02, lr_fn(300))\n    self.assertEqual(.02, lr_fn(4000))\n    self.assertEqual(.02, lr_fn(50000))\n    self.assertEqual(.02, lr_fn(600000))\n    self.assertEqual(.02, lr_fn(7000000))\n    self.assertEqual(.02, lr_fn(80000000))\n    self.assertEqual(.02, lr_fn(900000000))\n\n  def test_warmup_and_rsqrt_decay(self):\n    lr_fn = lr_functions.warmup_and_rsqrt_decay(24, .25)\n\n    # Warm-up.\n    self.assertAlmostEqual(.01, lr_fn(1))\n    self.assertAlmostEqual(.02, lr_fn(2))\n    self.assertAlmostEqual(.23, lr_fn(23))\n    self.assertAlmostEqual(.24, lr_fn(24))\n\n    # Reciprocal square-root decay.\n    self.assertAlmostEqual(.25 * (5 / math.sqrt(25)), lr_fn(25))\n    self.assertAlmostEqual(.25 * (5 / math.sqrt(26)), lr_fn(26))\n    self.assertAlmostEqual(.25 * (5 / math.sqrt(27)), lr_fn(27))\n    self.assertAlmostEqual(.25 * (5 / math.sqrt(300)), lr_fn(300))\n    self.assertAlmostEqual(.25 * (5 / math.sqrt(4000)), lr_fn(4000))\n    self.assertAlmostEqual(.25 * (5 / math.sqrt(50000)), lr_fn(50000))\n\n  def test_cosine_sawtooth(self):\n    tail_fn = lr_functions._CosineSawtoothTail(180, min_value=.1)\n    lr_fn = lr_functions._BodyAndTail(.3, tail_start=0, tail_fn=tail_fn)\n\n    # First cycle\n    self.assertAlmostEqual(.29998477, lr_fn(1))\n    self.assertAlmostEqual(.28660254, lr_fn(30))\n    self.assertAlmostEqual(.25, lr_fn(60))\n    self.assertAlmostEqual(.20, lr_fn(90))\n    self.assertAlmostEqual(.15, lr_fn(120))\n    self.assertAlmostEqual(.10001523, lr_fn(179))\n\n    # Second cycle\n    self.assertEqual(.3, lr_fn(180))\n    self.assertAlmostEqual(.29998477, lr_fn(181))\n    self.assertAlmostEqual(.28660254, lr_fn(210))\n    self.assertAlmostEqual(.25, lr_fn(240))\n    self.assertAlmostEqual(.20, lr_fn(270))\n    self.assertAlmostEqual(.15, lr_fn(300))\n    self.assertAlmostEqual(.10001523, lr_fn(359))\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/supervised/mnist_test.py,1,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test training an MNIST model 1000 steps (saves time vs. 2000 steps).""""""\n\nimport itertools\n\nfrom absl.testing import absltest\n\nimport numpy as np\n\nfrom trax import layers as tl\nfrom trax.optimizers import adafactor\nfrom trax.supervised import inputs\nfrom trax.supervised import tf_inputs\nfrom trax.supervised import training\n\n\nclass MnistTest(absltest.TestCase):\n\n  def test_train_mnist(self):\n    """"""Train MNIST model (almost) fully, to compare to other implementations.\n\n    Evals for cross-entropy loss and accuracy are run every 50 steps;\n    their values are visible in the test log.\n    """"""\n    mnist_model = tl.Serial(\n        tl.Flatten(),\n        tl.Dense(512),\n        tl.Relu(),\n        tl.Dense(512),\n        tl.Relu(),\n        tl.Dense(10),\n        tl.LogSoftmax(),\n    )\n    task = training.TrainTask(\n        itertools.cycle(_mnist_dataset().train_stream(1)),\n        tl.CrossEntropyLoss(),\n        adafactor.Adafactor(.02))\n    eval_task = training.EvalTask(\n        itertools.cycle(_mnist_dataset().eval_stream(1)),\n        [tl.CrossEntropyLoss(), tl.AccuracyScalar()],\n        names=[\'CrossEntropyLoss\', \'AccuracyScalar\'],\n        eval_at=lambda step_n: step_n % 50 == 0,\n        eval_N=10)\n\n    training_session = training.Loop(mnist_model, task, eval_task=eval_task)\n    training_session.run(n_steps=1000)\n    self.assertEqual(training_session.current_step(), 1000)\n\n\ndef _mnist_dataset():\n  """"""Loads (and caches) the standard MNIST data set.""""""\n  streams = tf_inputs.data_streams(\'mnist\')\n  return _add_weights(inputs.batcher(streams, variable_shapes=False,\n                                     batch_size_per_device=256,\n                                     eval_batch_size=256))\n\n\ndef _add_weights(trax_inputs):\n  """"""Add weights to inputs.""""""\n  def _weight_stream(input_stream):\n    """"""Add weights to the given stream.""""""\n    for example in input_stream:\n      inp, targets = example\n      weights = np.ones_like(targets).astype(np.float32)\n      yield (inp, targets, weights)\n  return inputs.Inputs(\n      train_stream=lambda n: _weight_stream(trax_inputs.train_stream(n)),\n      eval_stream=lambda n: _weight_stream(trax_inputs.eval_stream(n)),\n      train_eval_stream=lambda n: _weight_stream(  # pylint: disable=g-long-lambda\n          trax_inputs.train_eval_stream(n)))\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/supervised/pretrain_finetune.py,17,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Inputs and training loops for pre-training and fine-tuning.\n\nFor now, this file only supports fine-tuning bert-base-uncased on GLUE.\n""""""\nimport functools\nimport os\n\nimport gin\nimport jax\nimport numpy as np\n\nimport tensorflow.compat.v2 as tf\nimport tensorflow_datasets as tfds\nimport trax.layers as tl\nimport trax.layers.base\nfrom trax.math import numpy as jnp\nimport trax.models\nimport trax.optimizers\nfrom trax.supervised.inputs import Inputs\nfrom trax.supervised.trainer_lib import Trainer\n\n\nclass MultiInputs(Inputs):\n  """"""Supports tuples and not just single tensors for model input.""""""\n\n  def __init__(self, train_stream, eval_stream=None, train_eval_stream=None,\n               extra_streams=None):\n    self._train_stream = train_stream\n    self._eval_stream = eval_stream or self._train_stream\n    self._extra_streams = extra_streams\n\n    # TODO(lukaszkaiser): should we get rid of this one day?\n    self._train_eval_stream = train_eval_stream or self._train_stream\n\n    # Peek into the train stream to get an example shape.\n    example_train_batch = next(train_stream(1))\n    def get_shape(x):\n      return tuple(x.shape)[1:]\n    def get_dtype(x):\n      return x.dtype\n\n    self._input_shape = jax.tree_map(get_shape, example_train_batch[:-1])\n    self._input_dtype = jax.tree_map(get_dtype, example_train_batch[:-1])\n    self._target_shape = jax.tree_map(get_shape, example_train_batch[-1])\n    self._target_dtype = jax.tree_map(get_dtype, example_train_batch[-1])\n\n  def extra_streams(self, n_devices):\n    return [stream(n_devices) for stream in self._extra_streams]\n\n\ndef _tfds_stream(n_devices, dataset_name, split, batch_size, data_dir,\n                 shuffle_files, shuffle_buffer_size, batch_shuffle_size,\n                 preprocess_fun, repeat=True):\n  """"""Streams batches of examples from tfds, with pure-python preprocessing.""""""\n  if batch_size % n_devices != 0:\n    raise ValueError(f\'Batch size ({batch_size}) not divisible\'\n                     \' by number of devices ({n_devices})\')\n  ds = tfds.load(\n      name=dataset_name, split=split, data_dir=data_dir,\n      shuffle_files=shuffle_files)\n  if repeat:\n    ds = ds.repeat()\n  if shuffle_buffer_size is not None:\n    ds = ds.shuffle(shuffle_buffer_size)\n  ds = ds.batch(batch_size)\n  if batch_shuffle_size is not None:\n    ds = ds.shuffle(batch_shuffle_size)\n\n  for batch in tfds.as_numpy(ds):\n    if preprocess_fun is not None:\n      yield preprocess_fun(batch)\n    else:\n      yield batch\n\n\n@gin.configurable()\ndef tfds_inputs(\n    dataset_name,\n    preprocess_fun,\n    batch_size,\n    eval_batch_size=None,\n    data_dir=None,\n    train_split=tfds.Split.TRAIN,\n    eval_split=tfds.Split.VALIDATION,\n    extra_splits=(tfds.Split.VALIDATION, tfds.Split.TEST,),\n    shuffle_buffer_size=1024,\n    batch_shuffle_size=128,\n    ):\n  """"""Tensorflow Datasets input pipeline, with pure-python preprocessing.""""""\n  if eval_batch_size is None:\n    eval_batch_size = batch_size\n  return MultiInputs(\n      train_stream=functools.partial(\n          _tfds_stream,\n          dataset_name=dataset_name,\n          split=train_split,\n          batch_size=batch_size,\n          data_dir=data_dir,\n          shuffle_files=True,\n          shuffle_buffer_size=shuffle_buffer_size,\n          batch_shuffle_size=batch_shuffle_size,\n          preprocess_fun=preprocess_fun,\n          ),\n      eval_stream=functools.partial(\n          _tfds_stream,\n          dataset_name=dataset_name,\n          split=eval_split,\n          batch_size=eval_batch_size,\n          data_dir=data_dir,\n          shuffle_files=False,\n          shuffle_buffer_size=None,\n          batch_shuffle_size=None,\n          preprocess_fun=preprocess_fun,\n          ),\n      extra_streams=[functools.partial(  # pylint: disable=g-complex-comprehension\n          _tfds_stream,\n          dataset_name=dataset_name,\n          split=split,\n          batch_size=eval_batch_size,\n          data_dir=data_dir,\n          shuffle_files=False,\n          shuffle_buffer_size=None,\n          batch_shuffle_size=None,\n          preprocess_fun=preprocess_fun,\n          repeat=False,\n          ) for split in extra_splits]\n  )\n\n\n@gin.configurable()\ndef bert_tokenizer(vocab_path=None):\n  """"""Constructs a BERT tokenizer.""""""\n\n  # This import is from https://github.com/google-research/bert which is not\n  # listed as a dependency in trax.\n  from bert.tokenization import FullTokenizer\n  if vocab_path is None:\n    raise ValueError(\'vocab_path is required to construct the BERT tokenizer.\')\n  tokenizer = FullTokenizer(vocab_path, do_lower_case=True)\n  return tokenizer\n\n\n@gin.configurable()\ndef glue_inputs(dataset_name, batch_size, eval_batch_size=None, data_dir=None,\n                max_len=128, tokenizer=bert_tokenizer):\n  """"""Input pipeline for fine-tuning BERT on GLUE tasks.""""""\n  if callable(tokenizer):  # If we pass a function, e.g., through gin, call it.\n    tokenizer = bert_tokenizer()\n\n  eval_split = tfds.Split.VALIDATION\n  extra_splits = (tfds.Split.VALIDATION, tfds.Split.TEST,)\n  if dataset_name == \'glue/mnli\':\n    eval_split = \'validation_matched\'\n    # TODO(kitaev): Support diagnostic dataset (AX)\n    extra_splits = [\'validation_matched\', \'validation_mismatched\',\n                    \'test_matched\', \'test_mismatched\']\n\n  keys_lookup = {\n      \'glue/cola\': (\'sentence\', None),\n      \'glue/sst2\': (\'sentence\', None),\n      \'glue/mrpc\': (\'sentence1\', \'sentence2\'),\n      \'glue/qqp\': (\'question1\', \'question2\'),\n      \'glue/stsb\': (\'sentence1\', \'sentence2\'),\n      \'glue/mnli\': (\'premise\', \'hypothesis\'),   # TODO(kitaev): swap the two?\n      \'glue/qnli\': (\'question\', \'sentence\'),  # TODO(kitaev) swap the two?\n      \'glue/rte\': (\'sentence1\', \'sentence2\'),\n      \'glue/wnli\': (\'sentence1\', \'sentence2\'),\n  }\n\n  key_a, key_b = keys_lookup[dataset_name]\n\n  if key_b is None:\n    def preprocess(batch):\n      """"""Tokenize and convert text to model inputs.""""""\n      batch_size = batch[\'idx\'].shape[0]\n      input_ids = np.zeros((batch_size, max_len), dtype=np.int32)\n      type_ids = np.zeros((batch_size, max_len), dtype=np.int32)\n\n      for i in range(batch_size):\n        sentence_a = batch[key_a][i]\n        tokens_a = [101] + tokenizer.convert_tokens_to_ids(\n            tokenizer.tokenize(sentence_a)) + [102]\n        input_ids[i, :len(tokens_a)] = tokens_a[:max_len]\n\n      return input_ids, type_ids, batch[\'idx\'].astype(jnp.int32), batch[\'label\']\n  else:\n    def preprocess(batch):\n      """"""Tokenize and convert text to model inputs.""""""\n      batch_size = batch[\'idx\'].shape[0]\n      input_ids = np.zeros((batch_size, max_len), dtype=np.int32)\n      type_ids = np.zeros((batch_size, max_len), dtype=np.int32)\n\n      for i in range(batch_size):\n        sentence_a = batch[key_a][i]\n        sentence_b = batch[key_b][i]\n        tokens_a = [101] + tokenizer.convert_tokens_to_ids(\n            tokenizer.tokenize(sentence_a)) + [102]\n        tokens_b = tokenizer.convert_tokens_to_ids(\n            tokenizer.tokenize(sentence_b)) + [102]\n\n        ex_input_ids = (tokens_a + tokens_b)[:max_len]\n        ex_type_ids = ([0] * len(tokens_a) + [1] * len(tokens_b))[:max_len]\n\n        input_ids[i, :len(ex_input_ids)] = ex_input_ids\n        type_ids[i, :len(ex_type_ids)] = ex_type_ids\n\n      return input_ids, type_ids, batch[\'idx\'].astype(jnp.int32), batch[\'label\']\n\n  return tfds_inputs(\n      dataset_name=dataset_name,\n      preprocess_fun=preprocess,\n      batch_size=batch_size,\n      eval_batch_size=eval_batch_size,\n      data_dir=data_dir,\n      train_split=tfds.Split.TRAIN,\n      eval_split=eval_split,\n      extra_splits=extra_splits,\n      )\n\n\ndef get_accuracy(guess, gold):\n  return (guess == gold).mean()\n\n\ndef get_mcc(guess, gold):\n  tp = ((guess == 1) & (gold == 1)).sum()\n  tn = ((guess == 0) & (gold == 0)).sum()\n  fp = ((guess == 1) & (gold == 0)).sum()\n  fn = ((guess == 0) & (gold == 1)).sum()\n  mcc_denom = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n  mcc = (tp * tn - fp * fn) / (mcc_denom + 1e-6)\n  return mcc\n\n\ndef get_f1(guess, gold):\n  tp = ((guess == 1) & (gold == 1)).sum()\n  fp = ((guess == 1) & (gold == 0)).sum()\n  fn = ((guess == 0) & (gold == 1)).sum()\n  f1 = (2 * tp) / (2 * tp + fp + fn + 1e-6)\n  return f1\n\n\ndef get_f1_accuracy_mean(guess, gold):\n  return (get_f1(guess, gold) + get_accuracy(guess, gold)) / 2.0\n\n\ndef get_pearsonr(x, y):\n  return np.corrcoef(x, y)[0, 1]\n\n\n@gin.configurable(blacklist=[\'output_dir\'])\ndef finetune(output_dir, model=gin.REQUIRED, dataset_name=gin.REQUIRED,\n             batch_size=16, num_train_epochs=3.0):\n  """"""Fine-tuning loop for GLUE, largely following the BERT recipe.""""""\n  ds_info = tfds.builder(dataset_name).info\n  is_regression_task = (ds_info.features.dtype[\'label\'] == np.float32)\n\n  if is_regression_task:\n    # Regression task\n    loss_fn = tl.L2Loss()\n    metrics = {\n        \'loss\': tl.L2Loss(),\n        \'weights_per_batch_per_core\': tl.SumOfWeights(),\n    }\n    model = functools.partial(model, head=trax.models.BERTRegressionHead)\n  else:\n    # Classification task\n    loss_fn = tl.CrossEntropyLoss()\n    metrics = {\n        \'loss\': tl.CrossEntropyLoss(),\n        \'accuracy\': tl.AccuracyScalar(),\n        \'weights_per_batch_per_core\': tl.SumOfWeights(),\n    }\n    n_classes = ds_info.features[\'label\'].num_classes\n    with gin.unlock_config():\n      gin.parse_config(f\'BERTClassifierHead.n_classes = {n_classes}\')\n    model = functools.partial(model, head=trax.models.BERTClassifierHead)\n\n  num_train_examples = ds_info.splits[tfds.Split.TRAIN].num_examples\n  total_steps = int(num_train_examples * num_train_epochs // batch_size)\n  warmup_steps = int(0.1 * total_steps)\n  cooldown_steps = total_steps - warmup_steps\n\n  # TODO(kitaev): Re-think how configuration works for this setup.\n  with gin.unlock_config():\n    gin.parse_config(f""""""\n    # TODO(kitaev): Devlin et al. use linear decay, not cosine decay\n    MultifactorSchedule.factors = \'constant * linear_warmup * cosine_decay\'\n    MultifactorSchedule.warmup_steps = {warmup_steps}\n    MultifactorSchedule.steps_per_cycle = {cooldown_steps}\n\n    # TODO(kitaev): Devlin et al. use 0.01, but exclude biases from weight decay\n    Adam.weight_decay_rate=0.0\n    Adam.b1 = 0.9\n    Adam.b2 = 0.999\n    Adam.eps = 1e-6\n\n    glue_inputs.dataset_name = \'{dataset_name}\'\n    glue_inputs.batch_size = {batch_size}\n    glue_inputs.tokenizer = @bert_tokenizer\n    """""")\n\n  trainer = Trainer(\n      model, loss_fn,\n      optimizer=trax.optimizers.Adam,\n      lr_schedule=trax.lr_schedules.MultifactorSchedule,\n      inputs=glue_inputs,\n      output_dir=output_dir,\n      random_seed=None,\n      n_devices=None,  # Use all available.\n      checkpoints_at=None,\n      nontrainable_param_map=None,\n      metrics=metrics,\n      id_to_mask=None,\n      checkpoint_lowest=None,\n      checkpoint_highest=None,\n      )\n\n  trainer.log_step(\'Starting training using %d devices\' % trainer.n_devices)\n  trainer.print_n_weights()\n\n  trainer.train_epoch(n_steps=1, n_eval_steps=10)\n  trainer.save_gin()\n  trainer.train_epoch(n_steps=warmup_steps - 1, n_eval_steps=10)\n  trainer.train_epoch(n_steps=cooldown_steps, n_eval_steps=10)\n\n  trainer.log_step(\'Training done\')\n\n  # Evaluation\n  # pylint: disable=protected-access\n  def my_jit(forward, n_devices):\n    """"""Returns a JIT-compiled forward function running on n_devices.""""""\n    model_predict = trax.layers.base._accelerate(forward, n_devices)\n    if n_devices == 1:\n      def predict1(x, weights, state):\n        res, state = model_predict(x, weights, state, rng=jax.random.PRNGKey(0))\n        return res\n      return predict1\n\n    def predict(x, weights, state):\n      """"""Predict function jited and parallelized as requested.""""""\n      res, state = trax.layers.base._combine_devices(model_predict(\n          trax.layers.base.reshape_by_device(x, n_devices),\n          weights,\n          state,\n          jnp.broadcast_to(jax.random.PRNGKey(0)[None, :], (8, 2))))\n      return res\n\n    return predict\n\n  fwd = functools.partial(\n      my_jit(trainer._model_predict_eval.pure_fn, trainer._n_devices),\n      weights=trainer._opt_state[0][0],\n      state=trainer._model_state[0])\n\n  def run_model(stream):\n    """"""Run forward pass on a dataset.""""""\n    all_out = []\n    all_idx = []\n    all_labels = []\n    for input_ids, type_ids, idx, labels in stream:\n      remainder = labels.shape[0] % trainer._n_devices\n      if remainder:\n        pad_amount = trainer._n_devices - remainder\n        input_ids = np.pad(\n            input_ids, ((0, pad_amount), (0, 0)), mode=\'constant\')\n        type_ids = np.pad(type_ids, ((0, pad_amount), (0, 0)), mode=\'constant\')\n        padded_idx = np.pad(idx, ((0, pad_amount),), mode=\'constant\')\n      else:\n        padded_idx = idx\n      out = np.array(fwd((input_ids, type_ids, padded_idx)))\n      if remainder:\n        out = out[:-pad_amount]\n      all_out.append(out)\n      all_idx.append(idx)\n      all_labels.append(labels)\n    all_out = np.concatenate(all_out, axis=0)\n    all_idx = np.concatenate(all_idx, axis=0)\n    all_labels = np.concatenate(all_labels, axis=0)\n\n    return all_out, all_labels, all_idx\n\n  eval_metrics = {}\n  if is_regression_task:\n    eval_metrics[\'pearsonr\'] = get_pearsonr\n  else:\n    eval_metrics[\'accuracy\'] = get_accuracy\n\n  if dataset_name == \'glue/cola\':\n    eval_metrics[\'mcc\'] = get_mcc\n  elif dataset_name in (\'glue/mrpc\', \'glue/qqp\'):\n    eval_metrics[\'f1_accuracy_mean\'] = get_f1_accuracy_mean\n\n  preds_labels_idxs = [\n      run_model(stream) for stream in trainer._inputs.extra_streams(\n          trainer._n_devices)]\n\n  # Log results on development data\n  eval_results_path = os.path.join(trainer._output_dir, \'eval_results.txt\')\n  with tf.io.gfile.GFile(eval_results_path, \'w\') as f:\n    guess, gold, _ = preds_labels_idxs[0]\n    if is_regression_task:\n      guess = guess[:, 0]\n    else:\n      guess = guess.argmax(-1)\n    for name, fn in sorted(eval_metrics.items()):\n      val = fn(guess, gold)\n      f.write(f\'eval_{name} = {val:.06f}\\n\')\n      trainer.log_step(f\'eval_{name} = {val:.06f}\\n\')\n\n    if dataset_name == \'glue/mnli\':\n      guess, gold, _ = preds_labels_idxs[1]\n      guess = guess.argmax(-1)\n      for name, fn in sorted(eval_metrics.items()):\n        val = fn(guess, gold)\n        f.write(f\'eval_mismatched_{name} = {val:.06f}\\n\')\n        trainer.log_step(f\'eval_mismatched_{name} = {val:.06f}\\n\')\n\n    f.write(f\'global_step = {trainer.step}\\n\')\n\n  # Write predictions for test data\n  path_map = {\n      \'glue/cola\': \'CoLA.tsv\',\n      \'glue/mrpc\': \'MRPC.tsv\',\n      \'glue/qqp\': \'QQP.tsv\',\n      \'glue/sst2\': \'SST-2.tsv\',\n      \'glue/mnli\': \'MNLI-mm.tsv\',\n      \'glue/qnli\': \'QNLI.tsv\',\n      \'glue/rte\': \'RTE.tsv\',\n      # No eval on WNLI for now. BERT accuracy on WNLI is below baseline, unless\n      # special training recipe is used.\n      # \'glue/wnli\': \'WNLI.tsv\',\n  }\n\n  if dataset_name == \'glue/stsb\':\n    test_results_path = os.path.join(trainer._output_dir, \'STS-B.tsv\')\n    idxs = preds_labels_idxs[-1][2]\n    guess = preds_labels_idxs[-1][0][:, 0]\n    with tf.io.gfile.GFile(test_results_path, \'w\') as f:\n      f.write(\'index\\tprediction\\n\')\n      for idx, val in zip(idxs, guess):\n        f.write(f\'{idx}\\t{val:.06f}\\n\')\n  elif dataset_name in path_map:\n    if dataset_name in (\'glue/cola\', \'glue/mrpc\', \'glue/qqp\', \'glue/sst2\'):\n      label_set = [\'0\', \'1\']\n    elif dataset_name in (\'glue/qnli\', \'glue/rte\'):\n      label_set = [\'entailment\', \'not_entailment\']\n    elif dataset_name == \'glue/mnli\':\n      label_set = [\'entailment\', \'neutral\', \'contradiction\']\n    else:\n      assert False, f\'Unexpected dataset_name {dataset_name}\'\n\n    test_results_path = os.path.join(\n        trainer._output_dir, path_map[dataset_name])\n\n    idxs = preds_labels_idxs[-1][2]\n    guess = preds_labels_idxs[-1][0].argmax(-1)\n    with tf.io.gfile.GFile(test_results_path, \'w\') as f:\n      f.write(\'index\\tprediction\\n\')\n      for idx, val in zip(idxs, guess):\n        f.write(f\'{idx}\\t{label_set[val]}\\n\')\n\n    trainer.log_step(f\'Predictions written to {test_results_path}\')\n\n    if dataset_name == \'glue/mnli\':\n      test_results_path = os.path.join(trainer._output_dir, \'MNLI-m.tsv\')\n      idxs = preds_labels_idxs[-2][2]\n      guess = preds_labels_idxs[-2][0].argmax(-1)\n      with tf.io.gfile.GFile(test_results_path, \'w\') as f:\n        f.write(\'index\\tprediction\\n\')\n        for idx, val in zip(idxs, guess):\n          f.write(f\'{idx}\\t{label_set[val]}\\n\')\n      trainer.log_step(f\'Predictions written to {test_results_path}\')\n\n  return trainer, preds_labels_idxs\n'"
trax/supervised/tf_inputs.py,4,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Trax TF input pipeline.""""""\n\nimport functools\nimport os\nimport random\n\nfrom absl import logging\n\nimport gin\nimport numpy as np\n\nfrom t5.data import preprocessors as t5_processors\nfrom t5.data import sentencepiece_vocabulary as t5_spc_vocab\nfrom t5.data import utils as t5_utils\nfrom tensor2tensor import problems_colab as t2t_problems\nimport tensorflow as tf   # pylint: disable=g-explicit-tensorflow-version-import\nimport tensorflow_datasets as tfds\nimport tensorflow_text as tf_text\nfrom trax import math\n\n\n# How many examples from the stream to skip at random during training.\n# For now, we skip at most 100K examples for efficiency.\n# TODO(lukaszkaiser): can we improve efficiency, should that be changed?\n_MAX_SKIP_EXAMPLES = 1e5\n\n\ndef no_preprocess(dataset, training):\n  del training\n  return dataset\n\n\n@gin.configurable()\ndef data_streams(dataset_name, data_dir=None, preprocess_fn=no_preprocess,\n                 bare_preprocess_fn=None,\n                 shuffle_buffer_size=1024, eval_holdout_size=0,\n                 input_name=None, target_name=None):\n  """"""Make data streams for TF datasets.\n\n  Args:\n    dataset_name: a TFDS or T2T dataset name. If it\'s a T2T dataset name, prefix\n      with \'t2t_\'.\n    data_dir: data directory.\n    preprocess_fn: function to use for pre-processing after appending targets to\n      inputs.\n    bare_preprocess_fn: function to use for pre-processing before appending\n      targets to inputs.\n    shuffle_buffer_size: size of the shuffle buffer.\n    eval_holdout_size: float from 0 to <1; if >0 use this much of training data\n      for evaluation (instead of looking for a pre-specified VALIDATION split).\n    input_name: optional, name of the inputs from the dictionary.\n    target_name: optional, name of the outputs either from the dictionary or as\n      a result of post-processing.\n\n  Returns:\n    A pair of python streams, one for training and one for eval.\n  """"""\n  data_dir = download_and_prepare(dataset_name, data_dir)\n\n  cache = []\n  def stream(which):\n    """"""Create the stream, cache TF streams if needed.""""""\n    if not cache:\n      cache.append(_train_and_eval_streams(\n          dataset_name, data_dir, preprocess_fn, bare_preprocess_fn,\n          shuffle_buffer_size, eval_holdout_size, input_name, target_name))\n\n    (train_ds, eval_ds, input_name_c) = cache[0]\n    dataset = eval_ds if which == \'eval\' else train_ds\n    return dataset_to_stream(dataset, input_name_c)\n\n  train_stream = lambda: stream(\'train\')\n  eval_stream = lambda: stream(\'eval\')\n  return train_stream, eval_stream\n\n\ndef dataset_to_stream(dataset, input_name):\n  """"""Takes a tf.Dataset and creates a numpy stream of ready batches.""""""\n  # All input-pipeline processing should be on CPU.\n  for example in math.dataset_as_numpy(dataset):\n    features = example[0]\n    inp, out = features[input_name], example[1]\n    mask = features[\'mask\'] if \'mask\' in features else None\n    # Some accelerators don\'t handle uint8 well, cast to int.\n    if isinstance(inp, np.uint8):\n      inp = inp.astype(np.int32)\n    if isinstance(out, np.uint8):\n      out = out.astype(np.int32)\n    yield (inp, out) if mask is None else (inp, out, mask)\n\n\ndef _train_and_eval_streams(dataset, data_dir, preprocess_fn,\n                            bare_preprocess_fn, shuffle_buffer_size,\n                            eval_holdout_size, input_name, target_name):\n  """"""Return train and eval batches with input name and shape.""""""\n  (train_data, eval_data, keys) = _train_and_eval_dataset(\n      dataset, data_dir, eval_holdout_size)\n  if keys is not None:\n    input_names, target_names = keys[0], keys[1]\n  else:\n    input_names, target_names = [input_name], [target_name]\n  train_batches = _shuffle_data(\n      train_data, target_names, True, shuffle_buffer_size, preprocess_fn,\n      bare_preprocess_fn)\n  eval_batches = _shuffle_data(\n      eval_data, target_names, False, shuffle_buffer_size, preprocess_fn,\n      bare_preprocess_fn)\n  input_name = input_name or input_names[0]\n  return (train_batches, eval_batches, input_name)\n\n\ndef _shuffle_data(dataset,\n                  target_names,\n                  training,\n                  shuffle_buffer_size,\n                  preprocess_fn,\n                  bare_preprocess_fn):\n  """"""Shuffle the given dataset and run pre-processing.""""""\n  def append_targets(example):\n    """"""Append targets to the example dictionary. Needed for Keras.""""""\n    if len(target_names) == 1:\n      return (example, example[target_names[0]])\n    targets = {}\n    for name in target_names:\n      targets[name] = example[name]\n    return (example, targets)\n  # `bare_preprocess_fn` is called before appending targets etc.\n  if bare_preprocess_fn is not None:\n    dataset = bare_preprocess_fn(dataset)\n  dataset = dataset.map(append_targets)\n  # TODO(pkozakowski): Repeat both the training and evaluation set, so we don\'t\n  # have incomplete batches during evaluation. This will be a problem when we\n  # add an option to evaluate on the whole dataset, then we\'ll need to think of\n  # a different solution.\n  dataset = dataset.repeat()\n  if training:\n    # Skip a random fraction at the beginning of the stream.  The skip is\n    # essential for synchronous highly-parallel training to avoid multiple\n    # replicas reading the same data in lock-step.\n    dataset = dataset.skip(random.randint(0, _MAX_SKIP_EXAMPLES))\n  dataset = preprocess_fn(dataset, training)\n  dataset = dataset.shuffle(shuffle_buffer_size)\n  return dataset.prefetch(8)\n\n\ndef _train_and_eval_dataset(dataset_name, data_dir, eval_holdout_size,\n                            train_shuffle_files=True, eval_shuffle_files=False):\n  """"""Return train and evaluation datasets, feature info and supervised keys.\n\n  Args:\n    dataset_name: a string, the name of the dataset; if it starts with \'t2t_\'\n      then we\'ll search T2T Problem registry for it, otherwise we assume it\n      is a dataset from TFDS and load it from there.\n    data_dir: directory where the data is located.\n    eval_holdout_size: float from 0 to <1; if >0 use this much of training data\n      for evaluation (instead of looking for a pre-specified VALIDATION split).\n    train_shuffle_files: Boolean determining whether or not to shuffle the train\n      files at startup. Set to False if you want data determinism.\n    eval_shuffle_files: Boolean determining whether or not to shuffle the test\n      files at startup. Set to False if you want data determinism.\n\n  Returns:\n    a 4-tuple consisting of:\n     * the train tf.Dataset\n     * the eval tf.Dataset\n     * information about features: a python dictionary with feature names\n         as keys and an object as value that provides .shape and .n_classes.\n     * supervised_keys: information what\'s the input and what\'s the target,\n         ie., a pair of lists with input and target feature names.\n  """"""\n  if dataset_name.startswith(\'t2t_\'):\n    return _train_and_eval_dataset_v1(dataset_name[4:], data_dir,\n                                      train_shuffle_files, eval_shuffle_files)\n  dataset_builder = tfds.builder(dataset_name, data_dir=data_dir)\n  info = dataset_builder.info\n  splits = dataset_builder.info.splits\n  if tfds.Split.TRAIN not in splits:\n    raise ValueError(\'To train we require a train split in the dataset.\')\n  train_split = tfds.Split.TRAIN\n  if eval_holdout_size > 0:\n    holdout_percentage = int(eval_holdout_size * 100.0)\n    train_percentage = 100 - holdout_percentage\n    train_split = tfds.Split.TRAIN.subsplit(tfds.percent[:train_percentage])\n    eval_split = tfds.Split.TRAIN.subsplit(tfds.percent[train_percentage:])\n  else:\n    if tfds.Split.VALIDATION not in splits and \'test\' not in splits:\n      raise ValueError(\'We require a validation or test split in the dataset.\')\n    eval_split = tfds.Split.VALIDATION\n    if tfds.Split.VALIDATION not in splits:\n      eval_split = tfds.Split.TEST\n  train = tfds.load(\n      name=dataset_name, split=train_split, data_dir=data_dir,\n      shuffle_files=train_shuffle_files)\n  valid = tfds.load(\n      name=dataset_name, split=eval_split, data_dir=data_dir,\n      shuffle_files=eval_shuffle_files)\n  keys = None\n  if info.supervised_keys:\n    keys = ([info.supervised_keys[0]], [info.supervised_keys[1]])\n  return train, valid, keys\n\n\ndef _select_features(example, feature_list=None):\n  """"""Select a subset of features from the example dict.""""""\n  feature_list = feature_list or [\'inputs\', \'targets\']\n  return {f: example[f] for f in feature_list if f in example}\n\n\ndef _eager_dataset_iterator(dataset):\n  for item in dataset:\n    flat = tf.nest.flatten(item)\n    flat = [el.numpy() for el in flat]\n    yield tf.nest.pack_sequence_as(item, flat)\n\n\ndef _train_and_eval_dataset_v1(problem_name, data_dir,\n                               train_shuffle_files, eval_shuffle_files):\n  """"""Return train and evaluation datasets, feature info and supervised keys.""""""\n  with tf.device(\'cpu:0\'):\n    problem = t2t_problems.problem(problem_name)\n    hparams = None\n    if problem_name == \'video_bair_robot_pushing\':\n      hparams = problem.get_hparams()\n      bair_robot_pushing_hparams(hparams)\n    train_dataset = problem.dataset(tf.estimator.ModeKeys.TRAIN, data_dir,\n                                    shuffle_files=train_shuffle_files,\n                                    hparams=hparams)\n    train_dataset = train_dataset.map(_select_features)\n    eval_dataset = problem.dataset(tf.estimator.ModeKeys.EVAL, data_dir,\n                                   shuffle_files=eval_shuffle_files,\n                                   hparams=hparams)\n    eval_dataset = eval_dataset.map(_select_features)\n    # TODO(lukaszkaiser): remove this need for one example, just input_key.\n    examples = list(tfds.as_numpy(train_dataset.take(1)))\n  # We use \'inputs\' as input except for purely auto-regressive tasks like\n  # language models where \'targets\' are used as input_key.\n  input_key = \'inputs\' if \'inputs\' in examples[0] else \'targets\'\n  supervised_keys = ([input_key], [\'targets\'])\n  return train_dataset, eval_dataset, supervised_keys\n\n\n# Makes the function accessible in gin configs, even with all args blacklisted.\n@gin.configurable(blacklist=[\'dataset\', \'training\'])\ndef cifar10_no_augmentation_preprocess(dataset, training):\n  del training\n\n  def cast_image(features, targets):\n    features[\'image\'] = tf.cast(features[\'image\'], tf.float32) / 255.0\n    return features, targets\n\n  dataset = dataset.map(cast_image)\n  return dataset\n\n\ndef _cifar_augment_image(image):\n  """"""Image augmentation suitable for CIFAR-10/100.\n\n  As described in https://arxiv.org/pdf/1608.06993v3.pdf (page 5).\n\n  Args:\n    image: a Tensor.\n  Returns:\n    Tensor of the same shape as image.\n  """"""\n  image = tf.image.resize_with_crop_or_pad(image, 40, 40)\n  image = tf.image.random_crop(image, [32, 32, 3])\n  image = tf.image.random_flip_left_right(image)\n  return image\n\n\n# Makes the function accessible in gin configs, even with all args blacklisted.\n@gin.configurable(blacklist=[\'dataset\', \'training\'])\ndef cifar10_augmentation_preprocess(dataset, training):\n  """"""Preprocessing for cifar10 with augmentation (see below).""""""\n\n  def augment(features, targets):\n    features[\'image\'] = _cifar_augment_image(features[\'image\'])\n    return features, targets\n\n  def cast_image(features, targets):\n    features[\'image\'] = tf.cast(features[\'image\'], tf.float32) / 255.0\n    return features, targets\n\n  if training:\n    dataset = dataset.map(augment)\n  dataset = dataset.map(cast_image)\n  return dataset\n\n\n@gin.configurable(blacklist=[\'dataset\', \'training\'])\ndef cifar10_augmentation_flatten_preprocess(dataset, training,\n                                            predict_image_train_weight=0.01):\n  """"""Preprocessing for cifar10 that flattens it and appends targets.""""""\n\n  def augment(features, targets):\n    features[\'image\'] = _cifar_augment_image(features[\'image\'])\n    return features, targets\n\n  def flatten_image(features, targets):\n    """"""Flatten the image.""""""\n    img = features[\'image\']\n    flat = tf.cast(tf.reshape(img, [-1]), tf.int64)\n    tgt = tf.expand_dims(targets, axis=0)\n    flat_with_target = tf.concat([flat, tgt], axis=0)\n    new_features = {}\n    new_features[\'image\'] = flat_with_target\n    predict_image_weight = predict_image_train_weight if training else 0.0\n    mask_begin = tf.ones_like(flat)\n    mask_begin = tf.cast(mask_begin, tf.float32) * predict_image_weight\n    mask_end = tf.cast(tf.ones_like(tgt), tf.float32)\n    new_features[\'mask\'] = tf.concat([mask_begin, mask_end], axis=0)\n    return new_features, flat_with_target\n\n  if training:\n    dataset = dataset.map(augment)\n  dataset = dataset.map(flatten_image)\n\n  return dataset\n\n\n@gin.configurable(blacklist=[\'dataset\', \'training\'])\ndef concat_preprocess(dataset, training, pad_symbol=0):\n  """"""Pre-processing function that concatenates input and target for LM.""""""\n  del training\n\n  def concat(features, targets):\n    inp = features[\'inputs\']\n    pad = tf.expand_dims(tf.zeros_like(inp[0]) + pad_symbol, axis=0)\n    concat = tf.concat([pad, inp, pad, targets], axis=0)\n    # Note: we\'re updating existing features dictionary here, so make sure\n    # it is not re-used in some other ways outside of this function.\n    features[\'inputs\'] = concat\n    return features, concat\n\n  dataset = dataset.map(concat)\n  return dataset\n\n\n@gin.configurable(blacklist=[\'dataset\', \'training\'])\ndef squeeze_targets_preprocess(dataset, training):\n  """"""Pre-processing function that squeezes last axis of targets.""""""\n  del training\n\n  def squeeze(features, targets):\n    if targets.shape[-1] == 1:\n      targets = tf.squeeze(targets, axis=-1)\n    return features, targets\n\n  dataset = dataset.map(squeeze)\n  return dataset\n\n\n@gin.configurable(blacklist=[\'dataset\', \'training\'])\ndef lm1b_preprocess(dataset, training,\n                    max_target_length=-1, max_eval_target_length=-1):\n  """"""Preprocessing for LM1B: filter out targets exceeding maximum length.""""""\n\n  def target_right_length(_, target):\n    return tf.less(tf.shape(target)[0], max_target_length + 1)\n\n  def eval_target_right_length(_, target):\n    return tf.less(tf.shape(target)[0], max_eval_target_length + 1)\n\n  if max_target_length > 0 and training:\n    dataset = dataset.filter(target_right_length)\n\n  if max_eval_target_length > 0 and not training:\n    dataset = dataset.filter(eval_target_right_length)\n\n  return dataset\n\n\n# TODO(lukaszkaiser): find a single more abstract way of text pre-processing.\n@gin.configurable(blacklist=[\'dataset\', \'training\'])\ndef wmt_preprocess(dataset, training,\n                   max_length=-1, max_eval_length=-1):\n  """"""Preprocessing for LM1B: filter out targets exceeding maximum length.""""""\n\n  def train_right_length(example, target):\n    l = tf.maximum(tf.shape(example[\'inputs\'])[0], tf.shape(target)[0])\n    return tf.less(l, max_length + 1)\n\n  def eval_right_length(example, target):\n    l = tf.maximum(tf.shape(example[\'inputs\'])[0], tf.shape(target)[0])\n    return tf.less(l, max_eval_length + 1)\n\n  if max_length > 0 and training:\n    dataset = dataset.filter(train_right_length)\n\n  if max_eval_length > 0 and not training:\n    dataset = dataset.filter(eval_right_length)\n\n  return dataset\n\n\n@gin.configurable(blacklist=[\'dataset\', \'training\'])\ndef wmt_concat_preprocess(dataset, training,\n                          max_length=-1, max_eval_length=-1):\n  """"""Preprocessing for WMT: filter exceeding maximum length and concatenate.""""""\n  dataset = wmt_preprocess(dataset, training, max_length, max_eval_length)\n\n  def concat_and_add_mask(features, targets):\n    inp = features[\'inputs\']\n    pad = tf.expand_dims(tf.zeros_like(inp[0]), axis=0)\n    concat = tf.concat([inp, pad, targets], axis=0)\n    mask = tf.concat([tf.zeros_like(inp), pad, tf.ones_like(targets)], axis=0)\n    features[\'inputs\'] = concat\n    features[\'mask\'] = mask\n    return features, concat\n\n  dataset = dataset.map(concat_and_add_mask)\n  return dataset\n\n\n@gin.configurable(blacklist=[\'hparams\'])\ndef bair_robot_pushing_hparams(\n    hparams=None, video_num_input_frames=1, video_num_target_frames=15\n    ):\n  if hparams is not None:\n    hparams.video_num_input_frames = video_num_input_frames\n    hparams.video_num_target_frames = video_num_target_frames\n  else:\n    return video_num_input_frames, video_num_target_frames\n\n\n@gin.configurable(blacklist=[\'dataset\', \'training\'])\ndef bair_robot_pushing_preprocess(dataset, training):\n  """"""Pre-processing function that concatenates input and target frames.""""""\n  del training\n\n  def concat_and_add_mask(features, targets):\n    """"""Concatenate input and output frames to form a language modeling setup.""""""\n    inp = features[\'inputs\']\n    concat = tf.concat([inp, targets], axis=0)\n    mask = tf.concat([tf.zeros_like(inp), tf.ones_like(targets)], axis=0)\n    concat = tf.reshape(concat, (-1,))\n    mask = tf.reshape(mask, (-1,))\n    concat = tf.cast(concat, tf.int32)\n    mask = tf.cast(mask, tf.float32)\n    features[\'inputs\'] = features[\'targets\'] = concat\n    features[\'mask\'] = mask\n    return features, concat\n\n  dataset = dataset.map(concat_and_add_mask)\n  return dataset\n\n\nDEFAULT_SPM_PATH = \'gs://t5-data/vocabs/cc_all.32000/sentencepiece.model\'  # GCS\n\n\n@gin.configurable(blacklist=[\'dataset\', \'training\'])\ndef c4_preprocess(dataset, training, max_target_length=-1,\n                  tokenization=None, spm_path=None):\n  """"""Pre-processing function for C4 dataset.""""""\n  del training\n  def unicode_decode_chars(features, targets):\n    targets = tf.strings.unicode_decode(features[\'text\'], \'UTF-8\')\n    targets = tf.cast(targets, tf.int64)\n    features[\'targets\'] = targets\n    features[\'inputs\'] = targets\n    return (features, targets)\n\n  def spc_tokenize(tokenizer, features, targets):\n    del targets\n    tokenized_text = tokenizer.tokenize(features[\'text\'])\n    features[\'targets\'] = tf.cast(tokenized_text, tf.int64)\n    features[\'inputs\'] = features[\'targets\']\n    return features, features[\'targets\']\n\n  if tokenization == \'spc\':\n    spm_path = spm_path or t5_utils.DEFAULT_SPM_PATH\n    with tf.compat.v1.gfile.GFile(spm_path, \'rb\') as f:\n      spc_model = f.read()\n    tokenizer = tf_text.SentencepieceTokenizer(model=spc_model)\n    dataset = dataset.map(functools.partial(spc_tokenize, tokenizer))\n  else:\n    dataset = dataset.map(unicode_decode_chars)\n\n  def target_right_length(_, target):\n    return tf.less(tf.shape(target)[0], max_target_length + 1)\n\n  if max_target_length > 0:\n    dataset = dataset.filter(target_right_length)\n\n  return dataset\n\n\n@gin.configurable(blacklist=[\'dataset\'])\ndef c4_bare_preprocess_fn(dataset,\n                          spm_path=None,\n                          copy_plaintext=True,\n                          sequence_length=None):\n  """"""Returns a dataset that contains \'inputs\' and \'targets\' from C4.""""""\n  # Set target key to be equal to the text content.\n  dataset = t5_processors.rekey(\n      dataset, key_map={\'targets\': \'text\', \'inputs\': None})\n\n  # Vocabulary for tokenization.\n  vocab = t5_spc_vocab.SentencePieceVocabulary(\n      sentencepiece_model_file=spm_path or t5_utils.DEFAULT_SPM_PATH)\n  feature = t5_utils.Feature(vocab)\n  output_features = {\'targets\': feature, \'inputs\': feature}\n\n  # Tokenize the targets.\n  dataset = t5_utils.encode_string_features(\n      dataset, output_features, keys=output_features,\n      copy_plaintext=copy_plaintext)\n\n  # Preprocess the tokens - the exact preprocessors are set via\n  dataset = t5_processors.unsupervised(dataset,\n                                       sequence_length=sequence_length,\n                                       output_features=output_features)\n\n  return dataset\n\n\ndef download_and_prepare(dataset_name, data_dir):\n  """"""Downloads and prepares T2T or TFDS dataset.\n\n  Args:\n    dataset_name: tfds dataset or t2t problem name prefixed by \'t2t_\'.\n    data_dir: location of existing dataset or None.\n\n  Returns:\n    data_dir: path string of downloaded data.\n  """"""\n  if not data_dir:\n    data_dir = os.path.expanduser(\'~/tensorflow_datasets/\')\n    dl_dir = os.path.join(data_dir, \'download\')\n    logging.info(\n        \'No dataset directory provided. \'\n        \'Downloading and generating dataset for %s inside data directory %s \'\n        \'For large datasets it is better to prepare datasets manually!\',\n        dataset_name, data_dir)\n    if dataset_name.startswith(\'t2t_\'):\n      # Download and run dataset generator for T2T problem.\n      data_dir = os.path.join(data_dir, dataset_name)\n      tf.io.gfile.makedirs(data_dir)\n      tf.io.gfile.makedirs(dl_dir)\n      t2t_problems.problem(\n          dataset_name[len(\'t2t_\'):]).generate_data(data_dir, dl_dir)\n    else:\n      # Download and prepare TFDS dataset.\n      tfds_builder = tfds.builder(dataset_name)\n      tfds_builder.download_and_prepare(download_dir=dl_dir)\n  else:\n    data_dir = os.path.expanduser(data_dir)\n  return data_dir\n'"
trax/supervised/tf_inputs_test.py,8,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for trax.supervised.tf_inputs.""""""\n\nimport collections\nimport os\n\nimport gin\nimport numpy as np\nfrom t5.data import preprocessors as t5_processors\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom trax.supervised import inputs  # pylint: disable=unused-import\nfrom trax.supervised import tf_inputs\n\n\npkg_dir, _ = os.path.split(__file__)\n_TESTDATA = os.path.join(pkg_dir, \'testdata\')\n\n\ndef _test_dataset_ints(lengths):\n  """"""Create a test dataset of int64 tensors of shape [length].""""""\n  def generator():\n    """"""Sample generator of sequences of shape [length] of type int64.""""""\n    for length in lengths:\n      x = np.zeros([length], dtype=np.int64)\n      yield (x, x)  # Inputs and targets are the same here.\n  types = (tf.int64, tf.int64)\n  shapes = (tf.TensorShape([None]), tf.TensorShape([None]))\n  return tf.data.Dataset.from_generator(\n      generator, output_types=types, output_shapes=shapes)\n\n\ndef _c4_dataset(split=\'train\'):\n  return tfds.load(\n      name=\'c4\', split=split, data_dir=_TESTDATA, shuffle_files=False)\n\n\ndef _spm_path():\n  return os.path.join(_TESTDATA, \'sentencepiece.model\')\n\n\ndef _t5_gin_config():\n  # The following pages worth of gin configuration are required because a lot\n  # of T5 functions have `gin.REQUIRED` in code, i.e. you cannot use these\n  # functions at all without having configured gin.\n\n  noise_density = 0.15\n  max_input_length = 50\n\n  # What preprocessors to apply - we select a random chunk of the document if\n  # it exceeds a certain lengths (`select_random_chunk`), the concat multiple\n  # documents together to reduce padding (`reduce_concat_tokens`), then split\n  # up long examples (`split_tokens`) and finally the denoising objective\n  # (`denoise`).\n  gin.bind_parameter(\'unsupervised.preprocessors\', [\n      t5_processors.select_random_chunk,\n      t5_processors.reduce_concat_tokens,\n      t5_processors.split_tokens,\n      t5_processors.denoise,\n  ])\n\n  # select_random_chunk\n  gin.bind_parameter(\'select_random_chunk.feature_key\', \'targets\')\n  gin.bind_parameter(\'select_random_chunk.max_length\', max_input_length)\n\n  # reduce_concat_tokens\n  gin.bind_parameter(\'random_spans_helper.extra_tokens_per_span_inputs\', 1)\n  gin.bind_parameter(\'random_spans_helper.extra_tokens_per_span_targets\', 1)\n  gin.bind_parameter(\'random_spans_helper.inputs_length\', max_input_length)\n  gin.bind_parameter(\'random_spans_helper.mean_noise_span_length\', 3.0)\n  gin.bind_parameter(\'random_spans_helper.noise_density\', noise_density)\n\n  # split_tokens\n  gin.bind_parameter(\'split_tokens.max_tokens_per_segment\',\n                     t5_processors.random_spans_tokens_length())\n\n  # denoise\n  gin.bind_parameter(\'denoise.inputs_fn\',\n                     t5_processors.noise_span_to_unique_sentinel)\n  gin.bind_parameter(\'denoise.noise_density\', noise_density)\n  gin.bind_parameter(\'denoise.noise_mask_fn\',\n                     t5_processors.random_spans_noise_mask)\n  gin.bind_parameter(\'denoise.targets_fn\',\n                     t5_processors.nonnoise_span_to_unique_sentinel)\n\n\nclass TFInputsTest(tf.test.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    gin.clear_config()\n\n  def test_c4_bare_preprocess_fn(self):\n    dataset = _c4_dataset()\n\n    example = list(tfds.as_numpy(dataset.take(1)))[0]\n\n    # Targets are NOT in the example.\n    self.assertNotIn(\'targets\', example)\n    self.assertIn(\'text\', example)\n    text = example[\'text\']\n\n    # This should convert the dataset to an inputs/targets that are tokenized.\n    dataset = tf_inputs.c4_bare_preprocess_fn(\n        dataset, spm_path=os.path.join(_TESTDATA, \'sentencepiece.model\'))\n\n    example = list(tfds.as_numpy(dataset.take(1)))[0]\n\n    # Earlier text is now stored in targets_plaintext\n    self.assertIn(\'targets_plaintext\', example)\n    self.assertEqual(example[\'targets_plaintext\'], text)\n\n    # Targets are now tokenized.\n    self.assertIn(\'targets\', example)\n    self.assertIsInstance(example[\'targets\'], np.ndarray)\n    self.assertEqual(example[\'targets\'].dtype, np.int64)\n    self.assertGreater(len(example[\'targets\']), 0)\n\n    # Inputs exist but is empty because t5 preprocessors\' unsupervised wasn\'t\n    # gin configured with any.\n    self.assertIn(\'inputs\', example)\n    self.assertEqual(len(example[\'inputs\']), 0)\n\n  def test_c4_preprocess(self):\n    def load_c4_dataset(split=\'train\'):\n      dataset = _c4_dataset(split=split)\n      return dataset.map(lambda example: (example, example[\'text\']))\n\n    def examine_processed_dataset(proc_dataset):\n      count = 0\n      lengths = []\n      for example in tfds.as_numpy(proc_dataset):\n        count += 1\n        ex = example[0]\n        # Targets are in the example.\n        self.assertIn(\'targets\', ex)\n        self.assertEqual(ex[\'targets\'].dtype, np.int64)\n        lengths.append(len(ex[\'targets\']))\n      return count, lengths\n\n    unfiltered_count = 0\n    for example in tfds.as_numpy(load_c4_dataset()):\n      unfiltered_count += 1\n      # Targets are NOT in the example.\n      self.assertNotIn(\'targets\', example[0])\n\n    proc_dataset = tf_inputs.c4_preprocess(load_c4_dataset(), False, 2048)\n\n    # `examine_processed_dataset` has some asserts in it.\n    proc_count, char_lengths = examine_processed_dataset(proc_dataset)\n\n    # Both the original and filtered datasets have examples.\n    self.assertGreater(unfiltered_count, 0)\n    self.assertGreater(proc_count, 0)\n\n    # Because we filter out some entries on length.\n    self.assertLess(proc_count, unfiltered_count)\n\n    # Preprocess using the sentencepiece model in testdata.\n    spc_proc_dataset = tf_inputs.c4_preprocess(\n        load_c4_dataset(), False, 2048,\n        tokenization=\'spc\',\n        spm_path=os.path.join(_TESTDATA, \'sentencepiece.model\'))\n\n    spc_proc_count, spc_lengths = examine_processed_dataset(spc_proc_dataset)\n\n    # spc shortens the target sequence a lot, should be almost equal to\n    # unfiltered\n    self.assertLessEqual(proc_count, spc_proc_count)\n    self.assertEqual(unfiltered_count, spc_proc_count)\n\n    # Assert all spc_lengths are lesser than their char counterparts.\n    for spc_len, char_len in zip(spc_lengths, char_lengths):\n      self.assertLessEqual(spc_len, char_len)\n\n  def test_c4(self):\n    gin.bind_parameter(\'c4_preprocess.max_target_length\', 2048)\n    gin.bind_parameter(\'c4_preprocess.tokenization\', \'spc\')\n    gin.bind_parameter(\'c4_preprocess.spm_path\',\n                       os.path.join(_TESTDATA, \'sentencepiece.model\'))\n\n    # Just make sure this doesn\'t throw.\n    _ = tf_inputs.data_streams(\n        \'c4\', data_dir=_TESTDATA, input_name=\'targets\', target_name=\'text\',\n        preprocess_fn=tf_inputs.c4_preprocess)\n\n  def test_c4_bare_preprocess_fn_denoising_objective(self):\n    _t5_gin_config()\n\n    dataset = _c4_dataset()\n    dataset = tf_inputs.c4_bare_preprocess_fn(dataset, spm_path=_spm_path())\n\n    example = list(tfds.as_numpy(dataset.take(1)))[0]\n\n    # Assertions now.\n\n    self.assertIn(\'targets\', example)\n    targets = example[\'targets\']\n    self.assertIsInstance(targets, np.ndarray)\n    self.assertEqual(targets.dtype, np.int64)\n    self.assertGreater(len(targets), 0)\n\n    self.assertIn(\'inputs\', example)\n    _inputs = example[\'inputs\']  # pylint: disable=invalid-name\n    self.assertIsInstance(_inputs, np.ndarray)\n    self.assertEqual(_inputs.dtype, np.int64)\n    self.assertGreater(len(_inputs), 0)\n\n    # WHP inputs will have the bulk of the text.\n    self.assertGreater(len(_inputs), len(targets))\n\n    # WHP there will be two sentinel tokens in the inputs and targets.\n    inputs_counter = collections.Counter(_inputs.tolist())\n    targets_counter = collections.Counter(targets.tolist())\n    self.assertEqual(1, inputs_counter[31999])\n    self.assertEqual(1, inputs_counter[31998])\n    self.assertEqual(1, targets_counter[31999])\n    self.assertEqual(1, targets_counter[31998])\n\n  def test_c4_pretrain(self):\n    _t5_gin_config()\n\n    gin.bind_parameter(\'c4_bare_preprocess_fn.spm_path\',\n                       os.path.join(_TESTDATA, \'sentencepiece.model\'))\n\n    gin.bind_parameter(\'batcher.batch_size_per_device\', 8)\n    gin.bind_parameter(\'batcher.eval_batch_size\', 8)\n    gin.bind_parameter(\'batcher.max_eval_length\', 50)\n    gin.bind_parameter(\'batcher.buckets\', ([51], [8, 1]))\n\n    # Just make sure this doesn\'t throw.\n    _ = tf_inputs.data_streams(\n        \'c4\', data_dir=_TESTDATA, input_name=\'inputs\', target_name=\'targets\',\n        bare_preprocess_fn=tf_inputs.c4_bare_preprocess_fn)\n\n\nif __name__ == \'__main__\':\n  tf.test.main()\n'"
trax/supervised/trainer_lib.py,7,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Trax main training functions.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport functools\nimport gzip as gzip_lib\nimport itertools\nimport os\nimport pickle\nimport random\nimport sys\nimport time\n\nfrom absl import logging\n\nimport gin\n\nimport jax\nimport numpy\nimport six\nimport tensorflow.compat.v2 as tf\nfrom trax import history as trax_history\nfrom trax import jaxboard\nfrom trax import layers as tl\nfrom trax import lr_schedules as lr\nfrom trax import math\nfrom trax import optimizers as trax_opt\nfrom trax.math import numpy as np\nfrom trax.math import random as jax_random\nfrom trax.shapes import ShapeDtype\nfrom trax.supervised import inputs as trax_inputs\n\n\n# TODO(afrozm): Maybe flatten everything from OptState into TrainerState.\nTrainerState = collections.namedtuple(\'_TrainerState\', [\n    \'step\',         # Current training step number.\n    \'opt_state\',    # OptState.\n    \'history\',      # trax.history.History.\n    \'model_state\',  # Auxilliary state of the model.\n])\n\n\nOptState = collections.namedtuple(\'_OptState\', [\n    \'weights\',     # Model weights.\n    \'slots\',       # Per-parameter optimizer state, e.g. gradient moments.\n    \'opt_params\',  # Optimizer (hyper)parameters, e.g. learning rate, momentum.\n])\n\n\n_DEFAULT_METRICS = {\n    \'loss\': tl.CrossEntropyLoss(),\n    \'accuracy\': tl.AccuracyScalar(),\n    \'sequence_accuracy\': tl.SequenceAccuracyScalar(),\n    \'neg_log_perplexity\': tl.Serial(tl.CrossEntropyLoss(), tl.Negate()),\n    \'weights_per_batch_per_core\': tl.SumOfWeights(),\n}\n\n\nclass Trainer(object):\n  """"""Trax trainer.\n\n  A trainer allows to make training steps, train for full epochs,\n  save the training state and access evaluation data.\n  """"""\n\n  def __init__(self, model, loss_fn, optimizer, lr_schedule, inputs,\n               output_dir=None, random_seed=None, n_devices=None,\n               checkpoints_at=None, should_save_checkpoints=True,\n               should_write_summaries=True, nontrainable_param_map=None,\n               id_to_mask=None,\n               metrics=None, checkpoint_highest=None, checkpoint_lowest=None):\n\n    self._is_chief, self._n_devices, rng = (\n        self._init_host_and_devices(n_devices, random_seed))\n    self._should_save_checkpoints = should_save_checkpoints and self._is_chief\n    self._checkpoints_at = checkpoints_at or []\n    self._should_write_summaries = should_write_summaries\n    if not output_dir:\n      self._should_save_checkpoints = False\n      self._should_write_summaries = False\n    self._checkpoint_highest = checkpoint_highest\n    self._checkpoint_lowest = checkpoint_lowest\n    self._id_to_mask = id_to_mask\n    self._metrics_dict = metrics if metrics is not None else _DEFAULT_METRICS\n    # Inputs is either an Inputs instance or a function that returns it.\n    self._inputs = inputs\n    if callable(inputs):  # If we pass a function, e.g., through gin, call it.\n      self._inputs = inputs()\n    # Mask id_to_mask and add weights if needed.\n    # TODO(lukaszkaiser, jonni): move this out of Trainer to input processing.\n    self._inputs = _add_weights_and_mask(self._inputs, id_to_mask)\n    # Initialize the learning rate to a dummy value. It will be set in reset().\n    opt = optimizer(learning_rate=0.0)\n\n    # Setup the model.\n    model_train = model(mode=\'train\')\n    model_predict_eval = model(mode=\'eval\')\n\n    # Setup state.\n    rng, init_rng = jax_random.split(rng)\n    self._rngs = np.stack(jax_random.split(rng, self._n_devices))\n\n    def new_opt_state_and_model_state(shape_dtype, rng):\n      """"""Returns optimizer and model states suitable for training a model.""""""\n      # Combine inputs and targets on the stack.\n      shapes, dtypes = shape_dtype\n      input_signature = tuple(ShapeDtype(s, d)\n                              for (s, d) in zip(shapes, dtypes))\n      # We need to create a new model instance and not reuse `model_train` here,\n      # because `m.init` puts cached parameter values in `m` hence the\n      # next call of `m.init` will give wrong results.\n      m = tl.Serial(model(mode=\'train\'), loss_fn)\n      weights, state = m.init(input_signature, rng=rng)\n      (slots, opt_params) = opt.tree_init(weights)\n      return (OptState(weights, slots, opt_params), state)\n\n    if _is_jit_init():\n      # JIT parameter initialization to avoid memory fragmentation\n      new_opt_state_and_model_state = math.jit(new_opt_state_and_model_state,\n                                               static_argnums=(0,))\n    self._new_opt_state_and_model_state = (\n        lambda: new_opt_state_and_model_state(  # pylint: disable=g-long-lambda\n            self._inputs.example_shape_dtype, init_rng))\n\n    # Arrange and initialize metrics layers.\n    self._metrics = list(sorted(self._metrics_dict.keys()))\n    metrics_layers = [self._metrics_dict[m] for m in self._metrics]\n    metrics_in_parallel = tl.Branch(*metrics_layers)\n    metrics_in_parallel.rng = init_rng\n    example_signature = tuple(\n        ShapeDtype(s, d) for (s, d) in zip(*self._inputs.example_shape_dtype)\n    )\n    model_predict_eval.init(example_signature)\n    output_signature = model_predict_eval.output_signature(example_signature)\n    m_weights, m_state = metrics_in_parallel.init(output_signature)\n    self._metrics_weights = self._for_n_devices(m_weights)\n    self._metrics_state = self._for_n_devices(m_state)\n\n    # Jit model_predict and update so they\'re fast.\n    self._jit_eval = _jit_predict_fn(\n        model_predict_eval, metrics_in_parallel, self._n_devices)\n    self._jit_update_fn = _jit_update_fn(\n        model_train, loss_fn, opt, self._n_devices)\n\n    self._model_train = model_train\n    self._model_predict_eval = model_predict_eval\n    self._loss_fn = loss_fn\n    # TODO(pkozakowski): ""Learning rate schedules"" are currently able to control\n    # control all optimizer parameters and model state, so let\'s rename them\n    # accordingly.\n    self._lr_schedule = lr_schedule\n\n    if nontrainable_param_map is None:\n      nontrainable_param_map = {}\n    self._nontrainable_param_map = nontrainable_param_map\n\n    # Those fields will be set in reset().\n    self._output_dir = None\n    self._train_sw = None\n    self._eval_sw = None\n    self._history = None\n    self._lr_fn = None\n    self._opt_state = None\n    self._step = None\n    self._model_state = None\n    self.reset(output_dir)\n\n  @property\n  def n_devices(self):\n    return self._n_devices\n\n  @property\n  def step(self):\n    return self._step\n\n  @property\n  def model_weights(self):\n    # Currently we need to pick [0] as we ignore loss weights (empty).\n    weights = self._opt_state.weights[0]\n    if self.n_devices > 1:\n      unreplicate = lambda x: x[0]\n      weights = math.nested_map(unreplicate, weights)\n    return weights\n\n  @model_weights.setter\n  def model_weights(self, weights):\n    new_model_weights = self._for_n_devices(weights)\n    if isinstance(self._opt_state.weights, list):\n      self._opt_state.weights[0] = new_model_weights\n    else:  # weights are a tuple, need to re-create\n      new_weights = [new_model_weights] + list(self._opt_state.weights[1:])\n      self._opt_state = self._opt_state._replace(weights=new_weights)\n\n  @property\n  def model_state(self):\n    # Currently we need to pick [0] as we ignore loss state (empty).\n    state = self._model_state[0]\n    if self.n_devices > 1:\n      unreplicate = lambda x: x[0]\n      state = math.nested_map(unreplicate, state)\n    return state\n\n  @model_state.setter\n  def model_state(self, state):\n    new_model_state = self._for_n_devices(state)\n    if isinstance(self._model_state, list):\n      self._model_state[0] = new_model_state\n    else:  # weights are a tuple, need to re-create\n      self._model_state = [new_model_state] + list(self._model_state[1:])\n\n  @property\n  def state(self):\n    return TrainerState(\n        opt_state=self._opt_state, step=self._step, history=self._history,\n        model_state=self._model_state)\n\n  @property\n  def nontrainable_params(self):\n    # TODO(afrozm): Give further thought to this name.\n    # TODO(lukaszkaiser): it makes no sense to use an accelerator (e.g. TPU)\n    # in op-by-op mode just to compute the learning rate. However, there\n    # should be a cleaner approach that forceably swapping out the backend.\n    with math.use_backend(\'numpy\'):\n      return self._lr_fn(self._step)\n\n  def reset(self, output_dir, init_checkpoint=None):\n    """"""Reset the model parameters.\n\n    Restores the parameters from the given output_dir if a checkpoint exists,\n    otherwise randomly initializes them.\n\n    Does not re-jit the model.\n\n    Args:\n      output_dir: Output directory.\n      init_checkpoint: Initial checkpoint to use (default $output_dir/model.pkl)\n    """"""\n    self.close()\n    self._output_dir = output_dir\n    if output_dir is not None:\n      tf.io.gfile.makedirs(output_dir)\n    else:\n      assert not self._should_save_checkpoints\n      assert not self._should_write_summaries\n\n    # Create summary writers and history.\n    if self._should_write_summaries:\n      self._train_sw = jaxboard.SummaryWriter(os.path.join(output_dir, \'train\'),\n                                              enable=self._is_chief)\n      self._eval_sw = jaxboard.SummaryWriter(os.path.join(output_dir, \'eval\'),\n                                             enable=self._is_chief)\n\n    # Reset the train and eval streams.\n    self._train_stream = _repeat_stream(self._inputs.train_stream,\n                                        self._n_devices)\n    # TODO(lukaszkaiser): add an option to evaluate exactly on the full eval\n    #   set by adding a padding and stopping the stream when too large.\n    self._eval_stream = _repeat_stream(\n        self._inputs.eval_stream, self._n_devices)\n    self._train_eval_stream = _repeat_stream(\n        self._inputs.train_eval_stream, self._n_devices)\n\n    # Restore the training state.\n    if output_dir is not None:\n      state = load_trainer_state(output_dir, init_checkpoint)\n    else:\n      state = TrainerState(step=None, opt_state=None,\n                           history=trax_history.History(), model_state=None)\n    self._step = state.step or 0\n    history = state.history\n    self._lr_fn = self._lr_schedule(history)\n    self._history = history\n    if state.opt_state:\n      opt_state = state.opt_state\n      model_state = state.model_state\n    else:\n      opt_state, model_state = self._new_opt_state_and_model_state()\n      model_state = self._for_n_devices(model_state)\n    self._opt_state = OptState(*self._for_n_devices(opt_state))\n    self._model_state = model_state\n    if not state.opt_state and self._should_save_checkpoints:\n      self.save_state(keep=False)\n\n    self.update_nontrainable_params()\n\n  def train_epoch(self, n_steps, n_eval_steps):\n    """"""Runs `n_steps` of training, with periodic logging, saving, and evals.""""""\n    # TODO(jonni): Clarify how this method relates to the stricter notion of\n    # epoch (training for as many steps as needed for a full pass through the\n    # training data).\n    print()  # Add visual separator in logs for start of training epoch.\n    start_time = time.time()\n\n    for _ in range(n_steps):\n      batch = next(self._train_stream)\n      if self.n_devices > 1:  # TODO(lukaszkaiser): use everywhere if possible.\n        batch = _reshape_by_device(batch, self.n_devices)\n      self.train_step(batch)\n      if self._should_save_now():\n        self.save_state(keep=True)\n      if self._should_log_now():\n        for (name, value) in self.nontrainable_params.items():\n          self._train_sw.scalar(\'training/{}\'.format(name), value)\n\n    # At end of n_steps, do bookkeeping, run evals, and save state.\n    elapsed_time = time.time() - start_time\n    self.log_step(\'Ran %d train steps in %0.2f secs\' % (n_steps, elapsed_time))\n    if self._train_sw and n_steps > 1:\n      self._train_sw.scalar(\'training/steps per second\',\n                            n_steps / elapsed_time, step=self._step)\n      self._train_sw.flush()\n    self.evaluate(n_eval_steps)\n    if self._eval_sw:\n      self._eval_sw.flush()\n    if self._should_save_checkpoints:\n      self.save_state(keep=False)\n    if self._should_save_checkpoints and self._current_step_is_best(high=True):\n      self.save_state(keep=False, prefix=\'highest_\' + self._checkpoint_highest)\n    if self._should_save_checkpoints and self._current_step_is_best(high=False):\n      self.save_state(keep=False, prefix=\'lowest_\' + self._checkpoint_lowest)\n\n  def train_step(self, batch):\n    """"""Run one training step and update self._opt_state.""""""\n    # Calculate the current optimizer parameters.\n    # TODO(pkozakowski): Optimizer parameters get polluted with model state,\n    # which doesn\'t break anything but is weird. Filter it out.\n    opt_param_updates = self._for_n_devices(\n        math.nested_map(np.array, self.nontrainable_params))\n    opt_state = self._opt_state\n    opt_state.opt_params.update(opt_param_updates)\n\n    # Run the update.\n    (weights, slots, stat), self._model_state, self._rngs = self._jit_update_fn(\n        self._step, opt_state, batch, self._model_state, self._rngs)\n    self._model_state = self._map_to_state_dicts(self._state_dicts_update)\n    self._opt_state = opt_state._replace(weights=weights, slots=slots)\n    if self._should_log_now():\n      for name, value in stat.items():\n        scalar_value = np.mean(value)  # On  multiple devices, take the mean.\n        self._train_sw.scalar(\'training/\' + name, scalar_value, step=self._step)\n    self._step += 1\n\n  def evaluate(self, n_eval_steps):\n    """"""Evaluate the model and log metrics.""""""\n    _, rng = jax_random.split(self._rngs[0])\n    # TODO(lukaszkaiser): both model state and parameters by default include\n    # the loss layer. Currently, we access the pure-model parameters by just\n    # indexing, [0] here. But we should make it more explicit in a better API.\n    weights = (self._opt_state[0][0], self._metrics_weights)\n    state = (self._model_state[0], self._metrics_state)\n    self.log_step(\'Evaluation\')\n    train_eval_slice = itertools.islice(self._train_eval_stream, n_eval_steps)\n    train_metrics, _ = self.evaluation_round(train_eval_slice, weights, state,\n                                             rng)\n    self.log_metrics(train_metrics, self._train_sw, \'train\')\n    eval_slice = itertools.islice(self._eval_stream, n_eval_steps)\n    eval_metrics, _ = self.evaluation_round(eval_slice, weights, state, rng)\n    self.log_metrics(eval_metrics, self._eval_sw, \'eval\')\n    self.log_step(\'Finished evaluation\')\n\n    # Save the optimizer weights in the history\n    for (name, value) in self.nontrainable_params.items():\n      self._history.append(\'train\', \'training/{}\'.format(name), self._step,\n                           value)\n\n  def evaluation_round(self, inputs_stream, weights, state, rng):\n    """"""Evaluate.\n\n    Args:\n      inputs_stream: iterable of inputs to evaluate on.\n      weights: weights for each f in eval_fns.\n      state: state for each f in eval_fns.\n      rng: random number generator.\n\n    Returns:\n      metrics: dict from metric name to metric value averaged over the number of\n        inputs.\n      state: end state for `predict_fn`.\n    """"""\n    metrics = collections.defaultdict(float)\n    count = 0\n    for inp in inputs_stream:\n      count += 1\n      rng, subrng = jax_random.split(rng)\n      metric_values, _ = self._jit_eval(inp, weights, state, subrng)\n      try:\n        metric_values = list(metric_values)\n      except (TypeError, IndexError):\n        metric_values = [float(metric_values)]\n      for m, v in zip(self._metrics, metric_values):\n        metrics[m] += v\n    return {m: v / count for (m, v) in six.iteritems(metrics)}, state\n\n  def update_model_state(self, key, value):\n    """"""Updates model state based on nontrainable_params.""""""\n    # Translate model state keys to nontrainable param names.\n    if key in self._nontrainable_param_map:\n      p_name = self._nontrainable_param_map[key]\n    else:\n      # If a key is not in mapping, it stays the same.\n      p_name = key\n    if p_name in self.nontrainable_params:\n      if self._step == 0:\n        log(\'Mapping model state key {} to nontrainable param {}.\'\n            \'\'.format(key, p_name))\n        return self._for_n_devices(np.array(self.nontrainable_params[p_name]))\n    return value\n\n  def update_nontrainable_params(self):\n    self._lr_fn = self._lr_schedule(self._history)\n\n  def save_gin(self):\n    assert self._output_dir is not None\n    config_path = os.path.join(self._output_dir, \'config.gin\')\n    config_str = gin.operative_config_str()\n    with tf.io.gfile.GFile(config_path, \'w\') as f:\n      f.write(config_str)\n    sw = self._train_sw\n    if sw:\n      sw.text(\'gin_config\',\n              jaxboard.markdownify_operative_config_str(config_str))\n\n  def _save_state_dict(self, trainer_state_dict, weights_file):\n    pickle_to_file(trainer_state_dict, weights_file)\n    log(\'Model saved to %s\' % weights_file, stdout=False)\n\n  def save_state(self, keep, prefix=\'model\'):\n    """"""Save trainer state given a possibly replicated opt_state.""""""\n    opt_state = self._opt_state\n    if self.n_devices > 1:\n      first_replica = lambda x: x[0]\n      opt_state = OptState(*math.nested_map(first_replica, opt_state))\n    # This line, while optional, allows JAX to transfer arrays from the device\n    # to the host in parallel, which is particularly important for cloud TPU.\n    if math.backend_name() == \'jax\':\n      opt_state = jax.device_get(opt_state)\n    step, history, model_state = self._step, self._history, self._model_state\n    output_dir = self._output_dir\n\n    weights_file = os.path.join(output_dir, prefix + \'.pkl\')\n\n    # This dict will be stored as the model.\n    trainer_state_dict = make_trainer_state_dict(step,\n                                                 opt_state,\n                                                 history,\n                                                 model_state)\n    self._save_state_dict(trainer_state_dict, weights_file)\n\n    if keep:\n      weights_file = os.path.join(output_dir, \'{}_{}.pkl\'.format(prefix, step))\n      self._save_state_dict(trainer_state_dict, weights_file)\n\n  def save_computation_graphs(self, save_backward_graph):\n    """"""Dump computation graphs to files.""""""\n    if self.n_devices != 1:\n      return  # TODO(lukaszkaiser): make this work with more devices.\n    batch = next(self._train_stream)\n    output_dir = self._output_dir\n    if self.n_devices > 1:\n      batch = _reshape_by_device(batch, self.n_devices)\n    weights = self._opt_state[0][0]\n    forward_computation = jax.xla_computation(self._model_predict_eval)(\n        batch, weights=weights, state=self._model_state[0],\n        rng=self._rngs[0])\n    with tf.io.gfile.GFile(os.path.join(output_dir, \'forward.txt\'), \'w\') as f:\n      f.write(forward_computation.as_hlo_text())\n    with tf.io.gfile.GFile(os.path.join(output_dir, \'forward.dot\'), \'w\') as f:\n      f.write(forward_computation.as_hlo_dot_graph())\n    backward_computation = jax.xla_computation(self._jit_update_fn)(\n        self._step, self._opt_state, batch, self._model_state,\n        self._rngs)\n    with tf.io.gfile.GFile(os.path.join(output_dir, \'backward.txt\'), \'w\') as f:\n      f.write(backward_computation.as_hlo_text())\n    if save_backward_graph:  # Backward graphs can be large so we guard it.\n      with tf.io.gfile.GFile(\n          os.path.join(output_dir, \'backward.dot\'), \'w\') as f:\n        f.write(backward_computation.as_hlo_dot_graph())\n\n  def log_step(self, step_message):\n    log(\'Step % 6d: %s\' % (self.step, step_message))\n\n  def log_metrics(self, metrics, summ_writer, log_prefix):\n    """"""Log metrics to summary writer and history.""""""\n    history = self._history\n    rjust_len = max([0] + [len(name) for name in metrics])\n    for name, value in six.iteritems(metrics):\n      self.log_step(\'%s %s | % .8f\' % (\n          log_prefix.ljust(5), name.rjust(rjust_len), value))\n      full_name = \'metrics/\' + name\n      if history:\n        history.append(log_prefix, full_name, self.step, value)\n      if summ_writer:\n        summ_writer.scalar(full_name, value, self.step)\n\n  def print_n_weights(self):\n    """"""Prints the total count of trainable weights.""""""\n    opt_state = self._opt_state\n    sizes = _sizes(opt_state.weights)\n    if self.n_devices > 1:\n      unreplicate = lambda x: x[0]\n      single_weights = math.nested_map(unreplicate, opt_state.weights)\n      sizes = _sizes(single_weights)\n    total_size = _nested_reduce(sum, sizes)\n    self.log_step(\'Total number of trainable weights: %d\' % total_size)\n\n  def _init_host_and_devices(self, n_devices=None, random_seed=None):\n    """"""Initializes host and device attributes for this trainer.\n\n    Args:\n      n_devices: Number of devices this trainer will use. If `None`, get the\n          number from the backend.\n      random_seed: Random seed as the starting point for all random numbers used\n          by the trainer. If `None`, calculate one from system time and host id.\n\n    Returns:\n      is_chief: True if this trainer has special chief responsibilities.\n      n_devices: The passed in value of n_devices or a computed default.\n      random_seed: The passed in value of random_seed or a computed default.\n    """"""\n    if math.backend_name() == \'jax\':\n      host_id = jax.host_id()\n      host_count = jax.host_count()\n    else:\n      host_id = 0\n      host_count = 1\n    is_chief = (host_id == 0)\n\n    device_count = math.device_count()\n    n_devices = n_devices or device_count\n    # TODO(lukaszkaiser): remove this restriction when possible.\n    if n_devices != device_count and math.backend_name() == \'jax\':\n      raise ValueError(\'JAX cannot work yet with n_devices != all devices: \'\n                       \'%d != %d\' % (n_devices, device_count))\n\n    if random_seed is None and host_count > 1:\n      random_seed = int(1e6 * (host_id + time.time())) % 2**32\n    return is_chief, n_devices, init_random_number_generators(random_seed)\n\n  def _map_to_state_dicts(self, f):\n    """"""Map the function f to all dicts in model state.""""""\n    # TODO(jonni): Can we replace _nested_map with math.nested_map?\n    def _nested_map(f, x):\n      if isinstance(x, list):\n        return [_nested_map(f, y) for y in x]\n      if isinstance(x, tuple):\n        return tuple([_nested_map(f, y) for y in x])\n      if isinstance(x, dict) and len(x) == 1:\n        return f(x)\n      return x\n    return _nested_map(f, self._model_state)\n\n  def _state_dicts_update(self, state_dict):\n    assert len(state_dict.keys()) == 1\n    key = list(state_dict.keys())[0]\n    value = state_dict[key]\n    return {key: self.update_model_state(key, value)}\n\n  def _should_save_now(self):\n    return self._should_save_checkpoints and self._step in self._checkpoints_at\n\n  def _current_step_is_best(self, high):\n    """"""Is the current step the best (highest if high, else lowest).""""""\n    metric = self._checkpoint_highest if high else self._checkpoint_lowest\n    if metric is None:\n      return False\n    # History is a list of pairs (step, value).\n    history = self._history.get(\'eval\', \'metrics/\' + metric)\n    sequence = [float(i[1]) for i in history]  # Just the values.\n    best = max(sequence) if high else min(sequence)  # Best value.\n    last_is_best = float(history[-1][1]) == best  # Is last the best?\n    cur_step = history[-1][0] == self._step  # Is last the current step?\n    return cur_step and last_is_best\n\n  def _should_log_now(self):\n    return (self._train_sw is not None\n            and (self._step == 1 or self._step % 10 == 0))\n\n  def _for_n_devices(self, x):\n    """"""Replicates/broadcasts `x` for n devices if `self.n_devicess > 1`.""""""\n    return tl.for_n_devices(x, self.n_devices)  # pylint: disable=protected-access\n\n  def close(self):\n    if self._train_sw is not None:\n      self._train_sw.close()\n      self._train_sw = None\n    if self._eval_sw is not None:\n      self._eval_sw.close()\n      self._eval_sw = None\n\n\n@gin.configurable(blacklist=[\'output_dir\'])\ndef train(output_dir,\n          model=gin.REQUIRED,\n          loss_fn=tl.CrossEntropyLoss(),\n          inputs=trax_inputs.batcher,\n          optimizer=trax_opt.Adafactor,\n          lr_schedule=lr.MultifactorSchedule,\n          trainer_class=Trainer,\n          steps=1000,\n          checkpoints_at=None,\n          eval_steps=10,\n          eval_frequency=100,\n          random_seed=None,\n          save_graphs=True,\n          save_backward_graph=False,\n          nontrainable_param_map=None,\n          id_to_mask=None,\n          metrics=None,\n          checkpoint_highest=None,\n          checkpoint_lowest=None,\n          custom_train_fn=None):\n  """"""Train the model on the inputs.\n\n  Args:\n    output_dir: Directory where to put the logs and checkpoints.\n    model: The model to train as a callable returning 2 callables, an init_fn\n      and apply_fn.\n    loss_fn: callable with signature: weights, trax.inputs.Inputs, model, state,\n      rng -> loss.\n    inputs: callable returning trax.inputs.Inputs.\n    optimizer: The optimizer (see optimizers/base.py for signature).\n    lr_schedule: A learning rate schedule as a function that takes history and\n      returns a function from step to learning rate (a float).\n    trainer_class: The trainer class to use.\n    steps: int, total number of training steps.\n    checkpoints_at: list of integers. Save a checkpoint for each training step\n      in the list.\n    eval_steps: int, num of steps per evaluation. If None or 0, eval disabled.\n    eval_frequency: int, how often to run evaluation (every eval_frequency\n      steps). If None or 0, eval disabled.\n    random_seed: the random seed to use; time/os dependent if None (default).\n    save_graphs: bool, if True, save computation graph to file.\n    save_backward_graph: bool, if True, save backward graph to file too.\n    nontrainable_param_map: dict, mapping from model nontrainable parameter\n      names to control names in PolicySchedule.\n    id_to_mask: id to mask out (None by default).\n    metrics: optionally override the default metrics dictionary.\n    checkpoint_highest: save the checkpoint highest at this metric.\n    checkpoint_lowest: save the checkpoint lowest at this metric.\n    custom_train_fn: custom train function to call, entirely bypassing this one\n\n  Returns:\n    trax.TrainerState\n  """"""\n  if custom_train_fn is not None:\n    return custom_train_fn(output_dir, model=model)\n\n  n_devices = num_devices()\n  # TODO(lukaszkaiser): remove has_weights and id_to_mask (configure loss).\n  trainer = trainer_class(model, loss_fn, optimizer, lr_schedule, inputs,\n                          output_dir,\n                          random_seed=random_seed, n_devices=n_devices,\n                          checkpoints_at=checkpoints_at,\n                          nontrainable_param_map=nontrainable_param_map,\n                          metrics=metrics, id_to_mask=id_to_mask,\n                          checkpoint_lowest=checkpoint_lowest,\n                          checkpoint_highest=checkpoint_highest)\n\n  epoch_steps = [steps]  # Only training if eval_frequency is 0 or None\n  if eval_frequency and eval_steps > 0:\n    epoch_steps = itertools.chain([1,  # first epoch only 1 step\n                                   eval_frequency - 1],\n                                  itertools.repeat(eval_frequency))\n  trainer.log_step(\'Starting training using %d devices\' % trainer.n_devices)\n  trainer.print_n_weights()\n\n  try:\n    for epoch_steps in epochs(steps, trainer.step, epoch_steps):\n      trainer.train_epoch(epoch_steps, eval_steps)\n\n      # Update nontrainable parameters with new history\n      trainer.update_nontrainable_params()\n\n      # Bookkeeping we do at the first step\n      if trainer.step == 1:\n        # Save computation graph (single-device only for now)\n        if (save_graphs and math.backend_name() == \'jax\'):\n          trainer.save_computation_graphs(save_backward_graph)\n\n        # Save Gin config\n        trainer.save_gin()\n\n    trainer.log_step(\'Training done\')\n  except Exception as e:\n    raise e\n  finally:\n    trainer.close()\n  return trainer.state\n\n\n@gin.configurable\ndef num_devices(value=None):\n  """"""Returns how many devices to use (if None, default, use all available).""""""\n  return value\n\n\n@gin.configurable\ndef _is_jit_init(value=None):\n  if value is None:\n    value = math.backend_name() == \'jax\'\n  return value\n\n\n@gin.configurable\ndef _jit_update_fn(predict_fn, loss_fn, optimizer, n_devices, jit=True):\n  """"""Returns a (JIT-compiled) function that computes updates for one step.""""""\n  model_and_loss = tl.Serial(predict_fn, loss_fn)\n  # Gradients are always wrt. the first argument, so putting weights first.\n  def model_and_loss_call(weights, batch, state, rng):\n    res = model_and_loss(batch, weights=weights, state=state, rng=rng)\n    return res, model_and_loss.state\n  if n_devices == 1:  # TODO(lukaszkaiser): remove branch when not needed.\n    def single_update(i, opt_state, batch, state, rng):\n      weights, slots, opt_params = opt_state\n      rng, subrng = jax_random.split(rng[0])\n      grad_fn = math.grad(model_and_loss_call, has_aux=True)\n      grads, state = grad_fn(weights, batch, state, rng)\n      return optimizer.tree_update(\n          i, grads, weights, slots, opt_params), state, [subrng]\n    return math.jit(single_update) if jit else single_update\n\n  # Else, for n_devices > 1:\n  @functools.partial(math.pmap, axis_name=\'batch\')\n  def mapped_update(i, opt_state, batch, state, rng):\n    """"""This is a multi-device version of the update function above.""""""\n    # We assume all tensors have the first dimension = n_devices.\n    weights, slots, opt_params = opt_state\n    rng, subrng = jax_random.split(rng)\n    grad_fn = math.grad(model_and_loss_call, has_aux=True)\n    grads, state = grad_fn(weights, batch, state, rng)\n    # We do a psum(1.0) here instead of `n_devices` since `n_devices` is just\n    # the number of devices on this host machine, however psum goes over all\n    # devices of all hosts (ex: a TPU pod) and we need to be averaging over all\n    # of them.\n    grads = jax.tree_util.tree_map(\n        lambda g: math.psum(g, \'batch\') / math.psum(np.array(1.0), \'batch\'),\n        grads)\n    return optimizer.tree_update(\n        i, grads, weights, slots, opt_params), state, subrng\n\n  def update(i, opt_state, batch, state, rng):\n    return mapped_update(np.repeat(i, n_devices), opt_state, batch, state, rng)\n\n  return update\n\n\n@gin.configurable\ndef _jit_predict_fn(model_predict, metric_fn, n_devices, jit=True):\n  """"""Returns a JIT-compiled predict function (unless jit=False).""""""\n  model = tl.Serial(model_predict, metric_fn)\n  if not jit:\n    return model.pure_fn\n\n  return tl.jit_forward(model.pure_fn, n_devices)\n\n\n@gin.configurable\ndef _jit_compute_loss_fn(predict_fn, loss_fn, n_devices, jit=True):\n  """"""Returns a (JIT-compiled) function that computes the loss for one step.""""""\n  if n_devices == 1:  # TODO(lukaszkaiser): remove branch when not needed.\n    def single_compute_loss(opt_state, batch, state, rng):\n      rng, subrng = jax_random.split(rng[0])\n      loss_val, state = loss_fn(opt_state[0], batch, predict_fn, state, rng)\n      return loss_val, state, [subrng]\n    return math.jit(single_compute_loss) if jit else single_compute_loss\n\n  # Else, for n_devices > 1:\n  @functools.partial(math.pmap, axis_name=\'batch\')\n  def mapped_compute_loss(opt_state, batch, state, rng):\n    """"""This is a multi-device version of the update function above.""""""\n    # We assume all tensors have the first dimension = n_devices.\n    rng, subrng = jax_random.split(rng)\n    loss_val, state = loss_fn(opt_state[0], batch, predict_fn, state, rng)\n    return loss_val, state, subrng\n\n  def compute_loss(opt_state, batch, state, rng):\n    return mapped_compute_loss(\n        opt_state, _reshape_by_device(batch, n_devices), state, rng)\n\n  return compute_loss\n\n\ndef log(s, stdout=True):\n  logging.info(s)\n  if stdout:\n    print(s)\n    sys.stdout.flush()\n\n\ndef epochs(total_steps, steps_to_skip, epoch_steps):\n  """"""Generates the number of steps in each epoch before reaching total_steps.\n\n  Args:\n    total_steps: int, total number of steps.\n    steps_to_skip: int, number of steps to skip because of a restart.\n    epoch_steps: iterable of int, numbers of steps in each epoch.\n\n  Yields:\n    epoch_steps: int, number of steps in this epoch\n  """"""\n  steps_to_go = total_steps - steps_to_skip\n  epoch_steps = iter(epoch_steps)\n\n  # Remove the desired number of steps from the stream.\n  for steps_this_epoch in epoch_steps:\n    if steps_this_epoch > steps_to_skip:\n      # Put back the number of steps left in the unfinished epoch.\n      epoch_steps = itertools.chain(\n          [steps_this_epoch - steps_to_skip], epoch_steps)\n    if steps_this_epoch >= steps_to_skip:\n      break\n    steps_to_skip -= steps_this_epoch\n\n  # Yield the remaining steps per epoch up to total_steps.\n  for steps_this_epoch in epoch_steps:\n    steps_this_epoch = min(steps_this_epoch, steps_to_go)\n    yield steps_this_epoch\n    steps_to_go -= steps_this_epoch\n    if steps_to_go == 0:\n      break\n\n\ndef make_trainer_state_dict(step,\n                            opt_state,\n                            history,\n                            model_state):\n  """"""Creates a trainer state dictionary to save to disk.\n\n  Args:\n    step: int, a step number\n    opt_state: OptState namedtuple\n    history: `trax.history.History`, the history object.\n    model_state: A nested structure of the model state.\n\n  Returns:\n    A dictionary with the fields of TrainerState and OptState flattened.\n  """"""\n\n  return {\n      \'step\': step,\n      \'weights\': opt_state.weights[0],\n      \'loss_weights\': opt_state.weights[1],\n      \'slots\': opt_state.slots,\n      \'opt_params\': opt_state.opt_params,\n      \'history\': history,\n      \'state\': model_state[0],\n      \'loss_state\': model_state[1],\n      \'version_timestamp\': \'Jan-13-2020\'  # To update in the future if needed.\n  }\n\n\ndef trainer_state_from_dict(trainer_state_dict):\n  """"""Given the trainer state dictionary, returns `TrainerState`.""""""\n  # TODO(afrozm): This becomes simpler if OptState is flattened into\n  # TrainerState.\n  step = trainer_state_dict[\'step\']\n  history = trainer_state_dict[\'history\']\n  # TODO(lukaszkaiser): remove the first branch after everyone ports to \'state\'.\n  if \'model_state\' in trainer_state_dict:\n    model_state = trainer_state_dict[\'model_state\']\n  else:\n    model_state = (trainer_state_dict[\'state\'],\n                   trainer_state_dict[\'loss_state\'])\n  weights = trainer_state_dict[\'weights\']\n  # TODO(lukaszkaiser): remove the next 2 lines after \'loss_weights\' is in use.\n  if \'loss_weights\' in trainer_state_dict:\n    weights = (weights, trainer_state_dict[\'loss_weights\'])\n  opt_state = OptState(\n      weights=weights,\n      slots=trainer_state_dict[\'slots\'],\n      opt_params=trainer_state_dict[\'opt_params\'])\n  return TrainerState(step=step, opt_state=OptState(*opt_state),\n                      history=history, model_state=model_state)\n\n\ndef load_trainer_state(output_dir, weights_file=None):\n  """"""Returns a TrainerState instance loaded from the given `output_dir`.""""""\n  if weights_file is None:\n    weights_file = os.path.join(output_dir, \'model.pkl\')\n    if not tf.io.gfile.exists(weights_file):\n      return TrainerState(step=None, opt_state=None,\n                          history=trax_history.History(), model_state=None)\n  elif not tf.io.gfile.exists(weights_file):\n    raise ValueError(\'File not found: %s\' % weights_file)\n\n  with tf.io.gfile.GFile(weights_file, \'rb\') as f:\n    trainer_state_dict = pickle.load(f)\n  trainer_state = trainer_state_from_dict(trainer_state_dict)\n  log(\'Model loaded from %s at step %d\' % (weights_file, trainer_state.step))\n  logging.debug(\'From loaded model : history = %s\', trainer_state.history)\n  return trainer_state\n\n\ndef init_random_number_generators(seed=None):\n  """"""Initializes random generators for Python, NumPy, TensorFlow, and JAX.""""""\n  # Seed Python random (None as seed is okay), then use it to seed the others.\n  random.seed(seed)\n  if seed is None:\n    seed = random.randint(0, 2**31 - 1)\n  numpy.random.seed(seed)\n  tf.random.set_seed(seed)\n  return jax_random.get_prng(seed)\n\n\ndef _reshape_by_device(x, n_devices):\n  """"""Reshapes possibly nested x into a shape (n_devices, ...).""""""\n  return tl.reshape_by_device(x, n_devices)  # pylint: disable=protected-access\n\n\ndef _nested_reduce(f, x):\n  """"""Fold the function f to the nested structure x (dicts, tuples, lists).""""""\n  if isinstance(x, list):\n    return f([_nested_reduce(f, y) for y in x])\n  if isinstance(x, tuple):\n    return f([_nested_reduce(f, y) for y in x])\n  return x\n\n\ndef _sizes(x):\n  """"""Get a structure of sizes for a structure of nested arrays.""""""\n  def size(x):\n    try:\n      return x.size\n    except Exception:  # pylint: disable=broad-except\n      return 0\n  return math.nested_map(size, x)\n\n\ndef _repeat_stream(stream, n_devices):\n  """"""Repeat a stream indefinitely.""""""\n  while True:\n    for example in stream(n_devices):\n      yield example\n\n\ndef pickle_to_file(obj, file_path, gzip=False):\n  """"""Pickle obj to file_path with gzipping and failure protection.""""""\n  # Pickle to tmp file and overwrite to prevent writing partial files.\n  tmp_file_path = file_path + \'._tmp_\'\n  with tf.io.gfile.GFile(tmp_file_path, \'wb\') as f:\n    if not gzip:\n      pickle.dump(obj, f)\n    else:\n      with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:\n        pickle.dump(obj, gzipf)\n  # Moving a file is much less error-prone than pickling large files.\n  tf.io.gfile.rename(tmp_file_path, file_path, overwrite=True)\n\n\ndef unpickle_from_file(file_path, gzip=False):\n  """"""Unpickle obj from file_path with gzipping.""""""\n  with tf.io.gfile.GFile(file_path, \'rb\') as f:\n    if not gzip:\n      obj = pickle.load(f)\n    else:\n      with gzip_lib.GzipFile(fileobj=f, compresslevel=2) as gzipf:\n        obj = pickle.load(gzipf)\n  return obj\n\n\ndef _add_weights_and_mask(inputs, id_to_mask):\n  """"""Add weights to inputs without weights and masks by id if requested.\n\n  Each of the (train, eval, train_eval) streams of inputs is augmented in\n  the following way:\n  * if the stream consists of pairs (inputs, targets), a loss mask is added\n    that is creates as a tensor of ones of the same shape as targets\n  * if id_to_mask is not None, and the stream (after the previous point) has\n    triples (inputs, targets, weights), the weights are multipled by a 0/1 mask\n    that is 0 iff targets is equal to id_to_mask (1 otherwise).\n\n  Args:\n    inputs: a trax_inputs.Inputs object to operate on\n    id_to_mask: int or None, id to pad in targets if not None\n\n  Returns:\n    a trax_inputs.Inputs object with augmented streams\n  """"""\n  def _with_masks(input_stream):\n    """"""Create masks for the given stream.""""""\n    for example in input_stream:\n      if len(example) > 3 or len(example) < 2:\n        assert id_to_mask is None, \'Cannot automatically mask this stream.\'\n        yield example\n      else:\n        if len(example) == 2:\n          weights = numpy.ones_like(example[1]).astype(numpy.float32)\n        else:\n          weights = example[2].astype(numpy.float32)\n        mask = 1.0 - numpy.equal(example[1], id_to_mask).astype(np.float32)\n        weights *= mask\n        yield (example[0], example[1], weights)\n  return trax_inputs.Inputs(\n      train_stream=lambda n: _with_masks(inputs.train_stream(n)),\n      eval_stream=lambda n: _with_masks(inputs.eval_stream(n)),\n      train_eval_stream=lambda n: _with_masks(inputs.train_eval_stream(n)))\n'"
trax/supervised/trainer_lib_test.py,3,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.supervised.trainer_lib.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport contextlib\nimport functools\nimport os\nimport tempfile\nfrom absl.testing import parameterized\n\nfrom jax import test_util  # pylint: disable=unused-import\nfrom jax.config import config\nfrom jax.lib import xla_bridge\n\nimport tensorflow.compat.v2 as tf\nfrom tensorflow.compat.v2 import test\nfrom tensorflow.compat.v2.io import gfile\n\nfrom trax import layers\nfrom trax import lr_schedules as lr\nfrom trax import math\nfrom trax import models\nfrom trax import optimizers as trax_opt\nfrom trax.math import numpy as np\nfrom trax.supervised import inputs as inputs_lib\nfrom trax.supervised import trainer_lib\nfrom trax.tf_numpy import numpy as tf_np\n\n\n\ndef _test_inputs(n_classes, with_weights=False, input_shape=(6, 6, 3)):\n  """"""Make trainer_lib.inputs.Inputs.""""""\n  batch_size = 2 * xla_bridge.device_count()\n\n  def input_stream(n_devices):\n    del n_devices\n    key = math.random.get_prng(0)\n    while True:\n      keys = math.random.split(key, 4)\n      key = keys[0]\n      inputs = math.random.uniform(keys[1], [batch_size] + list(input_shape))\n      targets = math.random.randint(\n          keys[2], [batch_size], dtype=np.int32, minval=0, maxval=n_classes)\n      weights = math.random.uniform(keys[3], [batch_size])\n      if with_weights:\n        yield inputs, targets, weights\n      else:\n        yield inputs, targets\n\n  return inputs_lib.Inputs(input_stream)\n\n\n\nBACKENDS = [\'jax\', \'tf\']\n\n\nclass TraxTest(test.TestCase, parameterized.TestCase):\n\n  @contextlib.contextmanager\n  def tmp_dir(self):\n    tmp = tempfile.mkdtemp(dir=self.get_temp_dir())\n    yield tmp\n    gfile.rmtree(tmp)\n\n  # TODO(wangpeng): Remove `skipTest`\'s when tf-numpy\'s `pmap` is in place\n\n  def _test_train_eval_predict(self, backend_name):\n    if xla_bridge.device_count() > 1 and backend_name == \'tf\':\n      self.skipTest(""tf-numpy backend does\'t support multi-devices yet."")\n    with math.use_backend(backend_name), self.tmp_dir() as output_dir:\n      # Prepare model and inputs\n      n_classes = 4\n      steps = 2\n      eval_steps = 2\n\n      # Adds Dropout and BatchNorm to test state handling.\n      def model_fn(mode=\'train\'):\n        return layers.Serial(\n            layers.Dropout(mode=mode, rate=0.1), layers.BatchNorm(mode=mode),\n            models.MLP(d_hidden=16, n_output_classes=n_classes, mode=mode))\n\n      inputs = _test_inputs(n_classes)\n\n      # Train and evaluate\n      state = trainer_lib.train(\n          output_dir,\n          model=model_fn,\n          inputs=inputs,\n          steps=steps,\n          eval_steps=eval_steps)\n\n      # Assert total train steps\n      self.assertEqual(steps, state.step)\n\n      # Assert 2 evaluations ran\n      train_acc = state.history.get(\'train\', \'metrics/accuracy\')\n      eval_acc = state.history.get(\'eval\', \'metrics/accuracy\')\n      self.assertEqual(len(train_acc), len(eval_acc))\n      self.assertLen(eval_acc, 2)\n\n      # Predict with final weights\n      inputs = inputs.train_stream(1)\n      model = model_fn()\n      weights = state.opt_state.weights[0]\n      state = state.model_state[0]\n      if xla_bridge.device_count() > 1:\n        unreplicate = lambda x: x[0]\n        weights = math.nested_map(unreplicate, weights)\n        state = math.nested_map(unreplicate, state)\n      model(next(inputs)[0], weights=weights, state=state)\n\n  @parameterized.parameters(BACKENDS)\n  def test_train_eval_predict(self, backend_name):\n    self._test_train_eval_predict(backend_name)\n\n  @parameterized.parameters(BACKENDS)\n  def test_train_eval_predict_sm3(self, backend_name):\n    if xla_bridge.device_count() > 1 and backend_name == \'tf\':\n      self.skipTest(""tf-numpy backend doesn\'t support multi-devices yet."")\n    with math.use_backend(backend_name), self.tmp_dir() as output_dir:\n      # Prepare model and inputs\n      n_classes = 4\n      steps = 2\n      eval_steps = 2\n      model_fn = functools.partial(\n          models.MLP, d_hidden=16, n_output_classes=n_classes)\n      inputs = _test_inputs(n_classes)\n\n      # Train and evaluate\n      state = trainer_lib.train(\n          output_dir,\n          model=model_fn,\n          inputs=inputs,\n          steps=steps,\n          eval_steps=eval_steps,\n          optimizer=trax_opt.SM3)\n\n      # Assert total train steps\n      self.assertEqual(steps, state.step)\n\n      # Assert 2 evaluations ran\n      train_acc = state.history.get(\'train\', \'metrics/accuracy\')\n      eval_acc = state.history.get(\'eval\', \'metrics/accuracy\')\n      self.assertEqual(len(train_acc), len(eval_acc))\n      self.assertLen(eval_acc, 2)\n\n      # Predict with weights loaded from file.\n      inputs = inputs.train_stream(1)\n      model = model_fn()\n      model.init_from_file(os.path.join(output_dir, \'model.pkl\'))\n      model(next(inputs)[0])\n\n  @parameterized.parameters(BACKENDS)\n  def test_train_restart(self, backend_name):\n    if xla_bridge.device_count() > 1 and backend_name == \'tf\':\n      self.skipTest(""tf-numpy backend doesn\'t support multi-devices yet."")\n    with math.use_backend(backend_name), self.tmp_dir() as output_dir:\n      # Prepare model and inputs\n      n_classes = 4\n      steps = 2\n      eval_steps = 2\n      model_fn = functools.partial(\n          models.MLP, d_hidden=16, n_output_classes=n_classes)\n      inputs = _test_inputs(n_classes)\n\n      # Train and evaluate\n      trainer_lib.train(\n          output_dir,\n          model=model_fn,\n          inputs=inputs,\n          steps=steps,\n          eval_steps=eval_steps)\n\n      # Restart training\n      state = trainer_lib.train(\n          output_dir,\n          model=model_fn,\n          inputs=inputs,\n          steps=(2 * steps),\n          eval_steps=eval_steps)\n\n      # Assert total train steps\n      self.assertEqual(state.step, 2 * steps)\n\n  @parameterized.parameters(BACKENDS)\n  def test_train_with_weights(self, backend_name):\n    if xla_bridge.device_count() > 1 and backend_name == \'tf\':\n      self.skipTest(""tf-numpy backend doesn\'t support multi-devices yet."")\n    with math.use_backend(backend_name), self.tmp_dir() as output_dir:\n      # Prepare model and inputs\n      n_classes = 4\n      steps = 2\n      eval_steps = 2\n      model_fn = functools.partial(\n          models.MLP, d_hidden=16, n_output_classes=n_classes)\n      inputs = _test_inputs(n_classes, with_weights=True)\n\n      # Train and evaluate\n      state = trainer_lib.train(\n          output_dir,\n          model=model_fn,\n          inputs=inputs,\n          steps=steps,\n          eval_steps=eval_steps)\n\n      # Assert total train steps\n      self.assertEqual(state.step, steps)\n\n  @parameterized.parameters(BACKENDS)\n  def test_reset_twice(self, backend_name):\n    if xla_bridge.device_count() > 1 and backend_name == \'tf\':\n      self.skipTest(""tf-numpy backend doesn\'t support multi-devices yet."")\n    with math.use_backend(backend_name), self.tmp_dir() as output_dir1, \\\n          self.tmp_dir() as output_dir2:\n      n_classes = 4\n      model_fn = functools.partial(\n          models.MLP, d_hidden=16, n_output_classes=n_classes)\n      inputs = _test_inputs(n_classes)\n\n      trainer = trainer_lib.Trainer(\n          model=model_fn,\n          loss_fn=layers.CrossEntropyLoss(),\n          optimizer=trax_opt.SM3,\n          lr_schedule=lr.MultifactorSchedule,\n          inputs=inputs,\n      )\n\n      trainer.reset(output_dir1)\n      trainer.evaluate(1)\n      trainer.reset(output_dir2)\n      trainer.evaluate(1)\n\n  def test_tf_xla_forced_compile(self):\n    # TODO(wangpeng): re-enable this test\n    self.skipTest(\'Needs --config=cuda to pass this test\')\n    old_flag = math.tf_math.tf_xla_forced_compile_enabled()\n    math.tf_math.set_tf_xla_forced_compile(True)\n    self._test_train_eval_predict(\'tf\')\n    math.tf_math.set_tf_xla_forced_compile(old_flag)\n\n  def test_no_int32_or_uint32_returned(self):\n    """"""Tests that Trainer._jit_update_fn doesn\'t return int32 or uint32.\n\n    TF pins int32/uint32 tensors to CPU, which will cause XLA-forced-compiled\n    computation to copy int32/uint32 outputs to CPU. This test makes sure that\n    won\'t happen.\n    """"""\n    if xla_bridge.device_count() > 1:\n      self.skipTest(""tf-numpy backend doesn\'t support multi-devices yet."")\n    with math.use_backend(\'tf\'), self.tmp_dir() as output_dir:\n      n_classes = 1001\n      model_fn = functools.partial(models.Resnet50,\n                                   n_output_classes=n_classes)\n      inputs = _test_inputs(n_classes, input_shape=(224, 224, 3))\n      trainer = trainer_lib.Trainer(\n          model=model_fn,\n          loss_fn=layers.CrossEntropyLoss(),\n          optimizer=trax_opt.SM3,\n          lr_schedule=lr.MultifactorSchedule,\n          inputs=inputs,\n      )\n      trainer.reset(output_dir)\n      trainer.train_epoch(1, 0)\n      # Those are the things returned by Trainer._jit_update_fn\n      arrays = (trainer._opt_state.weights, trainer._opt_state.slots,\n                trainer._model_state, trainer._rngs)\n      arrays = tf.nest.flatten(arrays)\n      for x in arrays:\n        if isinstance(x, np.ndarray) and (x.dtype == np.int32 or\n                                          x.dtype == np.uint32):\n          raise ValueError(\'Found an array of int32 or uint32: %s\' % x)\n\n\n\nclass EpochsTest(test.TestCase):\n\n  def test_cuts_epoch_when_total_steps_reached(self):\n    epoch_steps = trainer_lib.epochs(\n        total_steps=5, steps_to_skip=0, epoch_steps=[1, 2, 3])\n    self.assertEqual(list(epoch_steps), [1, 2, 2])\n\n  def test_skips_full_epoch(self):\n    epoch_steps = trainer_lib.epochs(\n        total_steps=4, steps_to_skip=2, epoch_steps=[2, 2])\n    self.assertEqual(list(epoch_steps), [2])\n\n  def test_skips_part_of_epoch(self):\n    epoch_steps = trainer_lib.epochs(\n        total_steps=4, steps_to_skip=1, epoch_steps=[2, 2])\n    self.assertEqual(list(epoch_steps), [1, 2])\n\n\nif __name__ == \'__main__\':\n  config.config_with_absl()\n  tf.compat.v1.enable_eager_execution()\n  test.main()\n'"
trax/supervised/training.py,1,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Classes for supervised learning/training in Trax.\n\nTrax provides classes for training supervised models:\n\n  - Loop: Core training loop for an n-step training session, starting from\n    random initialization.\n\n  - TrainTask: Labeled data + feedback mechanism (loss function w/ optimizer)\n    for modifying a model\'s weights.\n\n  - Optimizer: How to compute model weight updates using loss-derived gradients.\n    May contain state (""slots"", 1-1 with model weights) that accumulates across\n    training steps. (This class is defined in the optimizers package.)\n\n  - EvalTask: How and when to measure model performance as a function of\n    training step number.\n""""""\n\nfrom absl import logging\nimport numpy as np\n\nfrom trax import layers as tl\nfrom trax import math\nfrom trax import shapes\n\n\nclass Loop:\n  """"""Loop that can run for a given number of steps to train a supervised model.\n\n  The typical supervised training process randomly initializes a model and\n  updates its weights via feedback (loss-derived gradients) from a training\n  task, by looping through batches of labeled data. A training loop can also\n  be configured to run periodic evals and save intermediate checkpoints.\n\n  For speed, the implementation takes advantage of JAX\'s composable function\n  transformations (specifically, `jit` and `grad`). It creates JIT-compiled\n  pure functions derived from variants of the core model; schematically:\n\n    - training variant: jit(grad(pure_function(model+loss)))\n    - evals variant: jit(pure_function(model+evals))\n\n  In training or during evals, these variants are called with explicit\n  arguments for all relevant input data, model weights/state, optimizer slots,\n  and random number seeds:\n\n    - batch: labeled data\n    - model weights/state: trainable weights and input-related state (e.g., as\n      used by batch norm)\n    - optimizer slots: weights in the optimizer that evolve during the training\n      process\n    - random number seeds: JAX PRNG keys that enable high-quality, distributed,\n      repeatable generation of pseudo-random numbers\n  """"""\n\n  def __init__(self, model, task, eval_task=None, output_dir=None,\n               checkpoint_at=None):\n    """"""Configures a training `Loop`, including a random initialization.\n\n    Args:\n      model: Trax layer, representing the core model to be trained. Loss\n          functions and eval functions (a.k.a. metrics) are considered to be\n          outside the core model, taking core model output and data labels as\n          their two inputs.\n      task: TrainTask instance, which defines the training data, loss function,\n          and optimizer to be used in this training loop.\n      eval_task: EvalTask instance or None. If None, don\'t do any evals.\n      output_dir: Path telling where to save outputs (evals and checkpoints).\n          Can be None if both `eval_task` and `checkpoint_at` are None.\n      checkpoint_at: Function (integer --> boolean) telling, for step n, whether\n          that step should have its checkpoint saved. If None, don\'t save any\n          checkpoints.\n    """"""\n    self._task = task\n    self._model_in_training = tl.Serial(model, task.loss_layer)\n    self._eval_task = eval_task\n    self._output_dir = output_dir\n    self._checkpoint_at = checkpoint_at or _never\n    self._step = None\n\n    batch_signature = shapes.signature(task.sample_batch)\n    # Initialize the model and the optimizer; discard the return values\n    # (model weights/state, optimizer slots/params), since they\'re available\n    # from the model and optimizer objects.\n    _, _ = self._model_in_training.init(batch_signature)\n    _, _ = task.optimizer.tree_init(self._model_in_training.weights)\n\n    self._gradients_and_state_fn = (\n        math.jit(math.grad(self._model_in_training.pure_fn,\n                           argnums=1,  # arg1 of pure_fn: weights\n                           has_aux=True)))  # return (gradients, state)\n\n    if eval_task is not None:\n      model_with_metrics = _model_with_metrics(model, eval_task)\n      self._eval_weights = model_with_metrics.weights[1]  # just the eval part\n      self._eval_state = model_with_metrics.state[1]  # just the eval part\n      self._metrics_fn = math.jit(model_with_metrics.pure_fn)\n\n  def run(self, n_steps=1):\n    """"""Runs this training loop for n steps.\n\n    Optionally runs evals and saves checkpoints at specified points.\n\n    Args:\n      n_steps: Stop training after completing n steps.\n    """"""\n    # Extract key values (weights, state, slots) and update them in each loop.\n    weights = self._model_in_training.weights\n    state = self._model_in_training.state\n    slots = self._task.optimizer.slots\n    for step_i in range(1, n_steps + 1):\n      self._step = step_i\n      weights, state, slots = self._run_one_step(weights, state, slots)\n      if self._eval_at(step_i):\n        self._run_evals(weights, state)\n      if self._checkpoint_at(step_i):\n        self._save_checkpoint(weights, state, slots)\n\n    # Store the final values back into their respective objects, for testing\n    # or other inspection/use.\n    self._model_in_training.weights = weights\n    self._model_in_training.state = state\n    self._task.optimizer.slots = slots\n\n  def current_step(self):\n    """"""Returns current step number in this training session.""""""\n    return self._step\n\n  def new_rng(self):\n    """"""Returns a new single-use random number generator (JAX PRNG key).""""""\n    rng = self._model_in_training.rng\n    rng1, rng2 = math.random.split(rng)\n    self._model_in_training.rng = rng1\n    return rng2\n\n  def _run_one_step(self, weights, state, slots):\n    """"""Updates model weights/state and optimizer slots by running one step.\n\n    Args:\n      weights: Weights from model being trained.\n      state: State (non-weight parameters) from model being trained.\n      slots: Updatable weights for the optimizer in this training loop.\n\n    Returns:\n      Tuple (weights, state, slots) with new values from one step of training.\n    """"""\n    step = self.current_step()\n    batch = self._task.next_batch()\n    optimizer = self._task.optimizer\n    opt_params = optimizer._init_opt_params  # pylint: disable=protected-access\n\n    gradients, state = (\n        self._gradients_and_state_fn(batch, weights, state, self.new_rng()))\n    weights, slots, _ = (\n        optimizer.tree_update(step, gradients, weights, slots, opt_params))\n    return weights, state, slots\n\n  def _run_evals(self, weights, state):\n    """"""Runs and records evals for this training session.\n\n    Args:\n      weights: Current weights from model in training.\n      state: Current state from model in training.\n    """"""\n    eval_task = self._eval_task\n    model_weights = weights[0]  # exclude weights from the loss layer\n    model_state = state[0]  # exclude state from the loss layer\n    metrics_weights = (model_weights, self._eval_weights)\n    metrics_state = (model_state, self._eval_state)\n\n    n_batches = eval_task._eval_N  # pylint: disable=protected-access\n    n_metrics = len(eval_task.metrics)\n    sums = np.zeros((n_metrics,))\n    for _ in range(n_batches):\n      rng = self.new_rng()\n      batch = eval_task.next_batch()\n      metric_values, _ = (\n          self._metrics_fn(batch, metrics_weights, metrics_state, rng))\n      sums += metric_values\n    averages = sums / n_batches\n    for name, average_value in zip(eval_task.names, averages):\n      logging.info(\'Eval at step %d: %s = %f\',\n                   self.current_step(), name, average_value)\n\n  def _eval_at(self, step_n):\n    """"""Returns True for training step n if evals should be run for that step.""""""\n    return self._eval_task is not None and self._eval_task.eval_at(step_n)\n\n  def _log_step(self, msg):\n    """"""Logs message, labeled with the current training step number.""""""\n    # TODO(jonni): Is direct print() is better for command-line use?\n    logging.info(\'Step %d: %s\', self.current_step(), msg)\n\n  def _save_checkpoint(self, weights, state, slots):\n    """"""Saves checkpoint to disk for the current training step.\n\n    Args:\n      weights: Weights from model being trained.\n      state: State (non-weight parameters) from model being trained.\n      slots: Updatable weights for the optimizer in this training loop.\n    """"""\n    raise NotImplementedError\n\n\ndef _model_with_metrics(model, eval_task):\n  """"""Returns a model+metrics layer built on an already initialized model.\n\n  Args:\n    model: Layer with initialized weights and state.\n    eval_task: EvalTask instance.\n\n  Returns:\n    An initialized, combined model+metrics layer, preserving the initialization\n    of `model`.\n  """"""\n  # TODO(jonni): Redo this function as part of an initialization refactor?\n  metrics_layer = tl.Branch(*eval_task.metrics)\n  data_signature = shapes.signature(eval_task.sample_batch[:-1])\n  label_signature = shapes.signature(eval_task.sample_batch[-1])\n  metrics_input_signature = (\n      shapes.splice_signatures(model.output_signature(data_signature),\n                               label_signature))\n  _, _ = metrics_layer.init(metrics_input_signature)\n\n  model_with_metrics = tl.Serial(model, metrics_layer)\n  model_with_metrics._rng = model.rng  # pylint: disable=protected-access\n  return model_with_metrics\n\n\nclass TrainTask:\n  """"""A supervised task (labeled data + feedback mechanism) for training.""""""\n\n  def __init__(self, labeled_data, loss_layer, optimizer):\n    r""""""Configures a training task.\n\n    Args:\n      labeled_data: Iterator of batches of labeled data tuples. Each tuple has\n          1+ data (input value) tensors followed by 1 label (target value)\n          tensor.  All tensors are NumPy ndarrays or their JAX counterparts.\n      loss_layer: Layer that computes a scalar value (the ""loss"") by comparing\n          model output :math:`\\hat{y}=f(x)` to the target :math:`y`.\n      optimizer: Optimizer object that computes model weight updates from\n          loss-function gradients.\n    """"""\n    self._labeled_data = labeled_data\n    self._loss_layer = loss_layer\n    self._optimizer = optimizer\n    self._sample_batch = next(labeled_data)\n\n  @property\n  def labeled_data(self):\n    return self._labeled_data\n\n  @property\n  def sample_batch(self):\n    return self._sample_batch\n\n  def next_batch(self):\n    """"""Returns one batch of labeled data: a tuple of input(s) plus label.""""""\n    return next(self._labeled_data)\n\n  @property\n  def loss_layer(self):\n    return self._loss_layer\n\n  @property\n  def optimizer(self):\n    return self._optimizer\n\n\nclass EvalTask:\n  """"""Labeled data plus scalar functions for (periodically) measuring a model.\n\n  An eval task specifies how (`labeled_data` + `metrics`) and when (`eval_at`)\n  to measure a model as it is training. The variance of each scalar output is\n  reduced by measuring over multiple (`eval_N`) batches and reporting the\n  average from those measurements.\n  """"""\n\n  def __init__(self, labeled_data, metrics,\n               names=None, eval_at=None, eval_N=10):\n    r""""""Configures an eval task: named metrics run with a given data source.\n\n    Args:\n      labeled_data: Iterator of batches of labeled data tuples. Each tuple has\n          1+ data tensors (NumPy ndarrays) followed by 1 label (target value)\n          tensor.\n      metrics: List of layers; each computes a scalar value per batch by\n          comparing model output :math:`\\hat{y}=f(x)` to the target :math:`y`.\n      names: List of names, one for each item in `metrics`, in matching order,\n          to be used when recording/reporting eval output. If None, generate\n          default names: \'metric_0\', \'metric_1\', ...\n      eval_at: Function (integer --> boolean) that says, for training step n,\n          whether that step should run the evals. If None, run evals just once,\n          on step 1.\n      eval_N: Integer N that specifies how many eval batches to run; the eval\n          output is then the average of the scalar outputs from the N batches.\n    """"""\n    self._labeled_data = labeled_data\n    self._metrics = metrics\n    self._names = names or self._default_names()\n    self._eval_at = eval_at if eval_at is not None else _step_1_only\n    self._eval_N = eval_N  # pylint: disable=invalid-name\n\n    self._sample_batch = next(labeled_data)\n    self._check_init_values()\n\n  @property\n  def labeled_data(self):\n    return self._labeled_data\n\n  @property\n  def sample_batch(self):\n    return self._sample_batch\n\n  def next_batch(self):\n    """"""Returns one batch of labeled data: a tuple of input(s) plus label.""""""\n    return next(self._labeled_data)\n\n  @property\n  def metrics(self):\n    return self._metrics\n\n  @property\n  def names(self):\n    return self._names\n\n  @property\n  def eval_at(self):\n    return self._eval_at\n\n  def _default_names(self):\n    return [f\'metric_{i}\' for i in range(len(self._metrics))]\n\n  def _check_init_values(self):\n    if len(self._metrics) != len(self._names):\n      raise ValueError(\n          f\'Number of metrics ({len(self._metrics)}) does not equal \'\n          f\'number of names ({len(self._names)}).\')\n\n\ndef _never(*args):\n  """"""Returns False for all step numbers.""""""\n  del args\n  return False\n\n\ndef _step_1_only(step_n):\n  """"""Returns true for step 1 only.""""""\n  return step_n == 1\n'"
trax/supervised/training_test.py,3,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for supervised training: core classes and flows.""""""\n\nfrom jax import test_util  # pylint: disable=unused-import\nfrom jax.config import config\n\nimport numpy as np\n\nfrom tensorflow.compat.v2 import test\n\nfrom trax import layers as tl\nfrom trax import optimizers\nfrom trax.supervised import training\n\n\nclass TrainingTest(test.TestCase):\n\n  def test_train_dense_layer(self):\n    """"""Trains a very simple network on a very simple task.""""""\n    model = tl.Serial(tl.Dense(1))\n    task = training.TrainTask(\n        _very_simple_data(), tl.L2Loss(), optimizers.SGD(.01))\n    eval_task = training.EvalTask(\n        _very_simple_data(),  # deliberately re-using training data\n        [tl.L2Loss()],\n        names=[\'SGD.L2Loss\'],\n        eval_at=lambda step_n: step_n % 2 == 0,\n        eval_N=1)\n    training_session = training.Loop(model, task, eval_task=eval_task)\n    self.assertIsNone(training_session.current_step())\n    training_session.run(n_steps=20)\n    self.assertEqual(20, training_session.current_step())\n\n  def test_train_dense_layer_with_momentum(self):\n    """"""Trains with an optimizer that has slots / requires initialization.""""""\n    model = tl.Serial(tl.Dense(1))\n    task = training.TrainTask(\n        _very_simple_data(), tl.L2Loss(), optimizers.Momentum(.01))\n    eval_task = training.EvalTask(\n        _very_simple_data(),  # deliberately re-using training data\n        [tl.L2Loss()],\n        names=[\'Momentum.L2Loss\'],\n        eval_at=lambda step_n: step_n % 2 == 0,\n        eval_N=1)\n    training_session = training.Loop(model, task, eval_task=eval_task)\n    self.assertIsNone(training_session.current_step())\n    training_session.run(n_steps=20)\n    self.assertEqual(20, training_session.current_step())\n\n\ndef _very_simple_data():\n  """"""""Returns stream of labeled data that maps small integers to constant pi.""""""\n  inputs_batch = np.arange(7).reshape((7, 1))  # 7 items per batch\n  targets_batch = np.pi * np.ones_like(inputs_batch)\n  labeled_batch = (inputs_batch, targets_batch, np.ones_like(targets_batch))\n  while True:\n    yield labeled_batch\n\n\nif __name__ == \'__main__\':\n  config.config_with_absl()\n  test.main()\n'"
trax/tf_numpy/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n'"
trax/layers/research/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n'"
trax/layers/research/efficient_attention.py,140,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Attention Layers optimized for efficiency (second-pass implementation).\n\nThe approach taken in the first round of efficient attention implementations\nrevealed several limitations, which this code attempts to address:\n\n1. Simultaneously instantiating queries, keys, and values for all heads can\n   exceed the memory budget. Transformers are typically tuned such that\n   n_heads * d_attention_key == d_model. Since attention involves queries, keys,\n   AND values, the memory to store them can be ~3x the memory needed to store\n   the input activations. Once the O(n^2) dot-product bottleneck is removed\n   -- as is the case in all of our efficient attention implementations -- this\n   becomes the next critical bottleneck for scaling up Transformer models.\n\n2. Attention masking is implemented by associating an integer (typically, the\n   sequence position) with each query and key vector, and defining a function\n   to compute attention masks from this information. The standard attention API\n   (attention.py) is unscalable because it instantiates O(n^2)-size attention\n   masks, and the previous efficient implementations (efficient_attention.py)\n   only supported causal masking.\n""""""\nimport functools\nimport jax\n\nfrom trax import math\nfrom trax.layers import base\nfrom trax.math import numpy as np\n\n\n####################################################### Functions\n\n\ndef tie_in(x, y):\n  if math.backend_name() == \'jax\':\n    return jax.lax.tie_in(x, y)\n  return y\n\n\ndef length_normalized(x, epsilon=1e-6):\n  variance = np.mean(x**2, axis=-1, keepdims=True)\n  norm_inputs = x / np.sqrt(variance + epsilon)\n  return norm_inputs\n\n\ndef look_adjacent(x, n_chunks_before, n_chunks_after):\n  """"""Used to implement attention between consecutive chunks.\n\n  Args:\n    x: array of shape [n_chunks, chunk_len, ...]\n    n_chunks_before: Number of previous chunks to attend to.\n    n_chunks_after: Number of subsequent chunks to attend to.\n  Returns:\n    array of shape [n_chunks, N * chunk_len, ...], where\n    N = (1 + n_chunks_before + n_chunks_after).\n  """"""\n  if n_chunks_before == 0 and n_chunks_after == 0:\n    return x\n\n  slices = []\n  for i in range(-n_chunks_before, n_chunks_after + 1):\n    if i == 0:\n      slices.append(x)\n    else:\n      slices.append(np.concatenate([x[i:, ...], x[:i, ...]], axis=0))\n  return np.concatenate(slices, axis=1)\n\n\ndef mask_self_attention(\n    dots, q_info, kv_info, causal=True, exclude_self=True, masked=False):\n  """"""Performs masking for self-attention.""""""\n  if causal:\n    mask = math.lt(q_info, kv_info).astype(np.float32)\n    dots = dots - 1e9 * mask\n  if exclude_self:\n    mask = np.equal(q_info, kv_info).astype(np.float32)\n    dots = dots - 1e5 * mask\n  if masked:\n    zeros_like_kv_info = tie_in(kv_info, np.zeros_like(kv_info))\n    mask = math.lt(kv_info, zeros_like_kv_info).astype(np.float32)\n    dots = dots - 1e9 * mask\n  return dots\n\n\ndef attend(\n    q, k=None, v=None,\n    q_chunk_len=None, kv_chunk_len=None,\n    n_chunks_before=0, n_chunks_after=0,\n    mask_fn=None, q_info=None, kv_info=None,\n    dropout=0.0, rng=None,\n    ):\n  """"""Dot-product attention, with optional chunking and/or masking.\n\n  Args:\n    q: Query vectors, shape [q_len, d_qk]\n    k: Key vectors, shape [kv_len, d_qk]; or None\n    v: Value vectors, shape [kv_len, d_v]\n    q_chunk_len: Set to non-zero to enable chunking for query vectors\n    kv_chunk_len: Set to non-zero to enable chunking for key/value vectors\n    n_chunks_before: Number of adjacent previous chunks to attend to\n    n_chunks_after: Number of adjacent subsequent chunks to attend to\n    mask_fn: TODO(kitaev) doc\n    q_info: Query-associated metadata for masking\n    kv_info: Key-associated metadata for masking\n    dropout: Dropout rate\n    rng: RNG for dropout\n\n  Returns:\n    A tuple (output, dots_logsumexp). The output has shape [q_len, d_v], and\n    dots_logsumexp has shape [q_len]. The logsumexp of the attention\n    probabilities is useful for combining multiple rounds of attention (as in\n    LSH attention).\n  """"""\n  assert v is not None\n  share_qk = (k is None)\n\n  if q_info is None:\n    q_info = np.arange(q.shape[-2])\n\n  if kv_info is None and not share_qk:\n    kv_info = np.arange(v.shape[-2])\n\n  # Split q/k/v into chunks along the time axis, if desired.\n  if q_chunk_len is not None:\n    q = np.reshape(q, (-1, q_chunk_len, q.shape[-1]))\n    q_info = np.reshape(q_info, (-1, q_chunk_len))\n\n  if share_qk:\n    assert kv_chunk_len is None or kv_chunk_len == q_chunk_len\n    k = q\n    kv_chunk_len = q_chunk_len\n    if kv_info is None:\n      kv_info = q_info\n    elif kv_chunk_len is not None:\n      # kv_info is not None, but reshape as required.\n      kv_info = np.reshape(kv_info, (-1, kv_chunk_len))\n  elif kv_chunk_len is not None:\n    k = np.reshape(k, (-1, kv_chunk_len, k.shape[-1]))\n    kv_info = np.reshape(kv_info, (-1, kv_chunk_len))\n\n  if kv_chunk_len is not None:\n    v = np.reshape(v, (-1, kv_chunk_len, v.shape[-1]))\n\n  if share_qk:\n    k = length_normalized(k)\n  k = k / np.sqrt(k.shape[-1])\n\n  # Optionally include adjacent chunks.\n  if q_chunk_len is not None or kv_chunk_len is not None:\n    assert q_chunk_len is not None and kv_chunk_len is not None\n  else:\n    assert n_chunks_before == 0 and n_chunks_after == 0\n\n  k = look_adjacent(k, n_chunks_before, n_chunks_after)\n  v = look_adjacent(v, n_chunks_before, n_chunks_after)\n  kv_info = look_adjacent(kv_info, n_chunks_before, n_chunks_after)\n\n  # Dot-product attention.\n  dots = np.matmul(q, np.swapaxes(k, -1, -2))\n\n  # Masking\n  if mask_fn is not None:\n    dots = mask_fn(dots, q_info[..., :, None], kv_info[..., None, :])\n\n  # Softmax.\n  dots_logsumexp = math.logsumexp(dots, axis=-1, keepdims=True)\n  dots = np.exp(dots - dots_logsumexp)\n\n  if dropout > 0.0:\n    assert rng is not None\n    # Dropout is broadcast across the bin dimension\n    dropout_shape = (dots.shape[-2], dots.shape[-1])\n    # TODO(kitaev): verify that tie-in is safe to remove (in light of jax fix)\n    keep_prob = tie_in(dots, 1.0 - dropout)\n    keep = math.random.bernoulli(rng, keep_prob, dropout_shape)\n    multiplier = keep.astype(dots.dtype) / tie_in(keep, keep_prob)\n    dots = dots * multiplier\n\n  # The softmax normalizer (dots_logsumexp) is used by multi-round LSH attn.\n  out = np.matmul(dots, v)\n  out = np.reshape(out, (-1, out.shape[-1]))\n  dots_logsumexp = np.reshape(dots_logsumexp, (-1,))\n  return out, dots_logsumexp\n\n\ndef apply_broadcasted_dropout(vecs, dropout_rate, rng):\n  """"""Apply dropout, broadcasted across all but the last dimension of `vecs`.""""""\n  if dropout_rate > 0.0:\n    assert rng is not None\n    keep_prob = tie_in(vecs, 1.0 - dropout_rate)\n    keep = math.random.bernoulli(rng, keep_prob, (vecs.shape[-1],))\n    multiplier = keep.astype(vecs.dtype) / tie_in(keep, keep_prob)\n    return vecs * multiplier\n  else:\n    return vecs\n\n\ndef permute_via_gather(val, permutation, inverse_permutation, axis=0):\n  """"""Permutation helper for LSH attention.""""""\n  def permute_impl(val):\n    return np.take(val, permutation, axis=axis)\n  def permute_vjp(val):\n    permuted = permute_impl(math.stop_gradient(val))\n    def vjpfun(permuted_grad):\n      # JAX autodiff would synthesize a scatter operation because it doesn\'t\n      # know that the indices are a permutatation. However on TPU, gathers are\n      # faster than scatters (at least in the regime the LSH attention uses).\n      return (np.take(permuted_grad, inverse_permutation, axis=axis),)\n    return permuted, vjpfun\n  permute = jax.custom_transforms(permute_impl)\n  jax.defvjp_all(permute, permute_vjp)\n  return permute(val)\n\n\ndef permute_via_sort(val, keys, inverse_keys, axis=0):\n  """"""Permutation helper for LSH attention.""""""\n  def permute_impl(val):\n    # On TPU, sorting scalars by key is faster than a gather.\n    _, permuted = jax.lax.sort_key_val(keys, val, dimension=axis)\n    return permuted\n  def permute_vjp(val):\n    permuted = permute_impl(math.stop_gradient(val))\n    def vjpfun(permuted_grad):\n      _, val_grad = jax.lax.sort_key_val(\n          inverse_keys, permuted_grad, dimension=axis)\n      return (val_grad,)\n    return permuted, vjpfun\n  permute = jax.custom_transforms(permute_impl)\n  jax.defvjp_all(permute, permute_vjp)\n  return permute(val)\n\n\n####################################################### Classes\n\n\nclass EfficientAttentionBase(base.Layer):\n  """"""Base class for efficient attention.\n\n  This is a base class that implements memory-efficient batching for both the\n  forward and backward passes. Subclasses should override\n  `create_weights_unbatched`, `create_state_unbatched`, `forward_unbatched`, and\n  optionally `incremental_forward_unbatched` to define the actual attention\n  mechanism.\n  """"""\n\n  def __init__(self, n_heads, n_in=1, n_parallel_heads=None,\n               incremental=False, predict_mem_len=None, predict_drop_len=None,\n               use_python_loop=False, use_reference_code=False):\n    """"""Construct an EfficientAttentionBase instance.\n\n    Args:\n      n_heads: int: Number of attention heads\n      n_in: int: Number of inputs to the layer (default 1)\n      n_parallel_heads: int: Number of attention heads to compute in parallel.\n        if n_parallel_heads is None (default): The entire layer is computed with\n          maximum parallelism. This mode is the fastest, but also uses the most\n          memory. Start with this mode, but switch to one of the others if\n          memory runs out.\n        if n_parallel_heads is 1: Attention is computed one head at a time, and\n          one example at a time. This mode uses the least memory but is not as\n          fast as batched attention. Use this mode when working with very long\n          sequences, such that any amount of parallelism won\'t fit in memory.\n        if n_parallel_heads is a multiple of n_heads: Attention is computed for\n          sub-batches of (n_parallel_heads // n_heads) examples at a time.\n        if 1 < n_parallel_heads < n_heads: Attention is computed for several\n          heads at a time, but only within a single example. It must be the case\n          that n_heads is a multiple of n_parallel_heads. Use this mode for long\n          sequences, to strike a balance between parallelism and memory usage.\n      incremental: bool: Enables fast inference for self-attention types. Note\n        that this flag should *not* be set when doing encoder-decoder attention,\n        but only when doing self-attention.\n      predict_mem_len: int: Number of input positions to remember in a cache\n        when doing fast inference. Whenever the cache fills up, some input\n        elements will be forgotten.\n      predict_drop_len: int: Number of input elements to drop once the fast\n        inference input cache fills up.\n      use_python_loop: bool: Set to True to use a Python loop when iterating\n        over sub-batches of examples/heads (as opposed to a JAX/XLA loop). This\n        option will increase compilation time and jitted code size, potentially\n        drastically. Using it is not recommended except for testing/debugging.\n        In particular, note that enabling this option on TPU can decrease the\n        maximum model size that will fit in memory.\n      use_reference_code: bool: Set to True to fall back to the reference\n        implementation of batched attention. This option will increase\n        compilation time and jitted code size, potentially drastically. Using it\n        is not recommended except for testing/debugging.\n    """"""\n    super().__init__(n_in=n_in, n_out=1)\n    self.n_heads = n_heads\n    self.incremental = incremental\n    if self.incremental:\n      if predict_mem_len is None or predict_drop_len is None:\n        raise ValueError(\'This configuration does not support fast inference.\')\n      if not 0 < predict_drop_len <= predict_mem_len:\n        raise ValueError(\n            \'Bad parameter values: (predict_mem_len, predict_drop_len) = \',\n            predict_mem_len, predict_drop_len)\n      self.predict_mem_len = predict_mem_len\n      self.predict_drop_len = predict_drop_len\n\n    if n_parallel_heads:\n      if ((n_parallel_heads > n_heads and n_parallel_heads % n_heads != 0)\n          or (n_parallel_heads < n_heads and n_heads % n_parallel_heads != 0)):\n        raise ValueError(\n            \'n_parallel_heads must be a multiple or fraction of n_heads\')\n      self.n_parallel_heads = n_parallel_heads\n    else:\n      self.n_parallel_heads = None\n    self.use_python_loop = use_python_loop\n    self.use_reference_code = use_reference_code\n\n  def new_weights(self, input_signature):\n    if not isinstance(input_signature, (tuple, list)):\n      input_signature = (input_signature,)\n    input_signature_unbatched = math.nested_map(\n        lambda x: type(x)(shape=x.shape[1:], dtype=x.dtype),\n        input_signature)\n    batch_size = int(input_signature[0].shape[0])\n\n    weights = []\n    weight_rngs = math.random.split(self.rng, self.n_heads)\n    for i in range(self.n_heads):\n      weights.append(self.create_weights_unbatched(input_signature_unbatched,\n                                                   weight_rngs[i]))\n    state = []\n    state_rngs = math.random.split(self.rng, self.n_heads * batch_size)\n    for i in range(self.n_heads * batch_size):\n      state.append(self.create_state_unbatched(input_signature_unbatched,\n                                               state_rngs[i]))\n\n    stack_along_axis_0 = lambda *x: np.stack(x, axis=0)\n    weights = math.nested_map_multiarg(stack_along_axis_0, *weights)\n    state = math.nested_map_multiarg(stack_along_axis_0, *state)\n\n    if self.incremental:\n      mem = math.nested_map(\n          lambda x: np.zeros(  # pylint: disable=g-long-lambda\n              x.shape[:1] + (self.predict_mem_len,) + x.shape[2:],\n              dtype=x.dtype),\n          input_signature)\n      mem_end = np.zeros((), dtype=np.int32)\n      state = (mem_end, mem, state)\n\n    self.state = state\n    return weights\n\n  def create_weights_unbatched(self, input_signature, rng):\n    raise NotImplementedError(\n        \'Subclasses should override create_weights_unbatched\')\n\n  def create_state_unbatched(self, input_signature, rng):\n    return ()\n\n  def forward_unbatched(self, *inputs, weights, state):\n    """"""Perform attention for a single batch element and head.\n\n    Subclasses should override this method.\n\n    Args:\n      *inputs: Inputs for a single example (subclasses may use different inputs)\n      weights: Weights for a single attention head\n      state: State for a single example & attention head pair.\n\n    Returns:\n      A tuple (output, new_state) -- output and new state for a single example\n      and attention head.\n    """"""\n    raise NotImplementedError(\'Subclasses should override forward_unbatched\')\n\n  def incremental_forward_unbatched(self, *inputs, q_start, q_len,\n                                    weights, state):\n    """"""Perform fast inference for a single batch element and head.\n\n    Subclasses should override this method.\n\n    Args:\n      *inputs: Inputs for a single example (subclasses may use different inputs)\n      q_start: Index along the sequence-length dimension that points to the\n        first input element that should be used as a query (and not just a key).\n      q_len: Number of new query elements in this call to the attention\n        mechanism. This is typically 1 for autoregressive decoding, but may be\n        longer if initializing a language model with a prefix.\n      weights: Weights for a single attention head\n      state: State for a single example & attention head pair.\n\n    Returns:\n      A tuple (output, new_state) -- output and new state for a single example\n      and attention head.\n    """"""\n    raise NotImplementedError(\n        \'Fast inference is not implemented for this attention type.\')\n\n  def forward(self, inputs, weights):\n    """"""Computes this layer\'s output as part of a forward pass through the model.\n\n    Args:\n      inputs: Layer inputs (subclasses may use different inputs)\n      weights: Layer weights\n\n    Returns:\n      A tuple (output, new_state).\n    """"""\n    state, rng = self.state, self.rng\n    if not self.use_reference_code:\n      # By default, an efficient, batched implementation is used.\n      output, new_state, _, _ = self.forward_and_or_backward(\n          inputs, weights, state, rng, compute_output=True, update_state=True)\n      self.state = new_state\n      return output\n\n    # The reference implementation below provides a more readable overview of\n    # what this class does. It\'s not optimized, however, and should only be used\n    # when testing this class for correctness.\n    if not isinstance(inputs, (tuple, list)):\n      inputs = (inputs,)\n    batch_size = int(inputs[0].shape[0])\n    seqlen = inputs[0].shape[-2]\n    d_model = inputs[0].shape[-1]\n\n    if self.incremental:\n      inputs, state, q_start, new_mem, new_mem_end = self.use_predict_mem(\n          inputs, state)\n\n    output_accum = [np.zeros((seqlen, d_model)) for _ in range(batch_size)]\n    new_state = []\n    for example_idx in range(batch_size):\n      for head_idx in range(self.n_heads):\n        # pylint: disable=cell-var-from-loop\n        single_inputs = math.nested_map(lambda x: x[example_idx], inputs)\n        single_weights = math.nested_map(lambda w: w[head_idx], weights)\n        single_state = math.nested_map(\n            lambda s: s[example_idx * self.n_heads + head_idx], state)\n        # pylint: enable=cell-var-from-loop\n        if self.incremental:\n          single_out, single_new_state = self.incremental_forward_unbatched(\n              *single_inputs, q_start=q_start, q_len=seqlen,\n              weights=single_weights, rng=rng,\n              state=single_state, update_state=True)\n        else:\n          single_out, single_new_state = self.forward_unbatched(\n              *single_inputs, weights=single_weights, rng=rng,\n              state=single_state, update_state=True)\n        new_state.append(single_new_state)\n        output_accum[example_idx] = output_accum[example_idx] + single_out\n\n    output = np.stack(output_accum, 0)\n    if new_state and math.tree_leaves(new_state[0]):\n      new_state = math.nested_map_multiarg(\n          lambda *s: np.stack(s, 0), *new_state)\n    else:\n      new_state = state\n    if self.incremental:\n      new_state = (new_mem_end, new_mem, new_state)\n    self.state = new_state\n    return output\n\n  def use_predict_mem(self, inputs, state):\n    """"""Update input cache for fast inference.""""""\n    mem_end, mem, state = state\n    seqlen = inputs[0].shape[-2]\n\n    if seqlen <= self.predict_drop_len and seqlen < self.predict_mem_len:\n      # This branch is called when only a small number of tokens are appended to\n      # the sequence, e.g. when generating one token at a time. A fixed number\n      # of tokens (self.predict_drop_tokens) will be dropped from memory if\n      # needed, and then new values will be inserted into the memory.\n      def roll_mem(buf):\n        return np.concatenate(\n            [buf[:, self.predict_drop_len:],\n             np.zeros_like(buf[:, :self.predict_drop_len])], axis=1)\n\n      do_roll_mem = (mem_end + seqlen > self.predict_mem_len)\n      mem = jax.lax.cond(\n          pred=do_roll_mem,\n          true_operand=mem,\n          true_fun=lambda x: math.nested_map(roll_mem, x),\n          false_operand=mem,\n          false_fun=lambda x: x,\n      )\n      mem_end = np.where(do_roll_mem, mem_end - self.predict_drop_len, mem_end)\n      def update_mem(mem_element, new_vals):\n        assert new_vals.shape[1] == seqlen\n        if seqlen == 1:\n          return jax.ops.index_update(\n              mem_element, jax.ops.index[:, mem_end], new_vals[:, 0, ...])\n        else:\n          return jax.lax.dynamic_update_slice_in_dim(\n              mem_element, new_vals, mem_end, axis=1)\n      inputs = math.nested_map_multiarg(update_mem, mem, inputs)\n      return inputs, state, mem_end, inputs, mem_end + seqlen\n    else:\n      assert seqlen > self.predict_drop_len or seqlen == self.predict_mem_len\n      # This branch handles the case where a large number of tokens are being\n      # introduced all at once. The code here assumes that we are at the start\n      # of the sequence, which matches the typical use case of decoding from a\n      # language model given a long prefix. Note that if we\'re not at the start\n      # of the sequence, the code here won\'t work.\n      new_flat_mem = []\n      for inp in math.tree_leaves(inputs):\n        assert inp.shape[1] == seqlen\n        if seqlen == self.predict_mem_len:\n          new_mem_val = inp\n        elif seqlen > self.predict_mem_len:\n          new_mem_val = inp[:, -self.predict_mem_len:]  # pylint: disable=invalid-unary-operand-type\n        else:\n          new_mem_val = np.concatenate([\n              inp,\n              np.zeros(inp.shape[:1]\n                       + (self.predict_mem_len - inp.shape[1],)\n                       + inp.shape[2:],\n                       dtype=inp.dtype)\n          ], axis=1)\n        new_flat_mem.append(new_mem_val)\n      mem = jax.tree_unflatten(jax.tree_structure(mem), new_flat_mem)\n\n      # This code only works at the start of the sequence. There\'s no ""assert""\n      # primitive we can use to signal an error, so we instead signal the error\n      # by introducing NaNs into the computation.\n      def replace_with_nan_if_not_seq_start(x):\n        if x.dtype != np.float32:\n          return x\n        return jax.lax.cond(\n            pred=jax.lax.eq(mem_end, 0), true_operand=x, true_fun=lambda x: x,\n            false_operand=x, false_fun=lambda x: x * np.nan)\n      inputs = math.nested_map(replace_with_nan_if_not_seq_start, inputs)\n      return inputs, state, 0, mem, np.minimum(seqlen, self.predict_mem_len)\n\n  @property\n  def has_backward(self):\n    # Use an efficient backward pass, unless we\'re running the reference code.\n    return not self.use_reference_code\n\n  def backward(self, inputs, output, grad, weights, state, new_state, rng=None,\n               **kwargs):\n    """"""Custom backward pass, for efficiency (see forward_and_or_backward).""""""\n    assert not self.use_reference_code\n    del output, state, kwargs\n    _, _, inputs_grad, weights_grad = self.forward_and_or_backward(\n        inputs, weights, new_state, rng, output_grad=grad,\n        compute_output=False, update_state=False)\n    return inputs_grad, weights_grad\n\n  def forward_and_or_backward(\n      self, inputs, weights, state, rng, output_grad=None,\n      compute_output=True, update_state=True):\n    """"""Performs batched forward and/or backward passes.\n\n    See `forward` for a reference implementation of what this layer does. The\n    reference implementation is not very efficient, however, and this method\n    provides a more performant version.\n\n    Args:\n      inputs: inputs to the attention layer\n      weights: weights for the attention layer\n      state: state of the attention layer\n      rng: PRNG key for the layer (shared across all examples and heads)\n      output_grad: gradient of the loss wrt the output of the layer, or None.\n          This function performs the backward pass iff `output_grad` is not\n          None.\n      compute_output: bool: whether to return the output of the forward pass\n          (for example, a pure backwards pass does not need to return the\n          output).\n      update_state: bool: whether to return an updated layer state.\n\n    Returns:\n      A tuple (output, new_state, inputs_grad, weights_grad).\n\n      - output is not None iff compute_output is True\n      - new_state is not None iff update_state is True\n      - inputs_grad & weights_grad are not None iff output_grad is not None\n    """"""\n    # TODO(kitaev): profile ~4% speed drop compared to previous implementation\n    #     in some conditions. Other conditions (e.g. the enwik8 model) appear\n    #     to have the same overall training speed.\n    # TODO(b/148460708): reduce memory usage further\n    # TODO(kitaev): there should be a higher-level API (like vmap) that does\n    #     batching, instead of needing 3 separate manual implementations here.\n\n    # Notes regarding the implementation:\n    # (a) Multiple heads or examples are batched together. There are three\n    #     different regimes possible: one head at a time (for long sequences and\n    #     expensive attention types), several attention heads at a time (for\n    #     long sequences but less-expensive attention types), and several\n    #     examples at a time (for large batches of shorter sequences). For the\n    #     time being, each of these regimes has its own code.\n    # (b) Python loops produce large computation graphs when jitted, so the\n    #     default is to use a JAX loop instead.\n    # (c) No intermediate quantities are cached for the backward pass. Instead,\n    #     the forward pass is re-computed when doing backprop. This approach is\n    #     often called ""checkpointing"" or ""rematerialization"". When not all\n    #     examples or heads fit in memory simultaneously, the implementation\n    #     should be [FW-BW-1] and NOT [FW-BW-2], because the latter has worse\n    #     memory locality. I don\'t think JAX autodiff can synthesize [FW-BW-1]\n    #     automatically, so the looping for the backward pass is done manually.\n    #\n    #     [FW-BW-1] for example, head in zip(examples, heads):\n    #                 forward(example, head)\n    #                 backward(example, head)  # uses intermediates from forward\n    #\n    #     [FW-BW-2] for example, head in zip(examples, heads):\n    #                 forward(example, head)\n    #               for example, head in zip(examples, heads):\n    #                 backward(example, head)\n\n    have_single_input = not isinstance(inputs, (tuple, list))\n    if have_single_input:\n      inputs = (inputs,)\n    batch_size = int(inputs[0].shape[0])\n    seqlen = inputs[0].shape[-2]\n    d_model = inputs[0].shape[-1]\n\n    compute_grad = (output_grad is not None)\n    assert compute_output or compute_grad, \'No work to perform!\'\n\n    if not self.incremental:\n      forward_unbatched = functools.partial(\n          self.forward_unbatched, rng=rng, update_state=update_state)\n    else:\n      if update_state:\n        inputs, state, q_start, new_mem, new_mem_end = self.use_predict_mem(\n            inputs, state)\n      else:\n        # This assumes that the memory stores all of the inputs, which would not\n        # be valid if doing backprop in mode \'predict\' with long lengths.\n        new_mem_end, inputs, state = state\n        q_start = new_mem_end - seqlen\n\n      forward_unbatched = functools.partial(\n          self.incremental_forward_unbatched,\n          q_start=math.stop_gradient(q_start),\n          q_len=math.stop_gradient(seqlen),\n          rng=rng, update_state=update_state)\n\n    # Adjust degree of parallelism based on the batch size.\n    n_parallel_heads = batch_size * self.n_heads\n    if self.n_parallel_heads and self.n_parallel_heads < n_parallel_heads:\n      n_parallel_heads = self.n_parallel_heads\n\n    def tree_update(tree, indices, new_values):\n      return math.nested_map_multiarg(\n          lambda x, y: jax.ops.index_update(x, jax.ops.index[indices], y),\n          tree, new_values)\n\n    def tree_add(tree, indices, new_values):\n      return math.nested_map_multiarg(\n          lambda x, y: jax.ops.index_add(x, jax.ops.index[indices], y),\n          tree, new_values)\n\n    if compute_grad:\n      inputs_is_differentiable = math.nested_map(\n          lambda x: np.issubdtype(x.dtype, np.inexact), inputs)\n      def split_differentiable(xs):\n        differentiable_xs = math.nested_map_multiarg(\n            lambda x, is_differentiable: x if is_differentiable else None,\n            xs, inputs_is_differentiable)\n        non_differentiable_xs = math.nested_map_multiarg(\n            lambda x, is_differentiable: None if is_differentiable else x,\n            xs, inputs_is_differentiable)\n        return differentiable_xs, non_differentiable_xs\n      def join_differentiable(differentiable_xs, non_differentiable_xs):\n        """"""Reconstitute inputs pytree from differentiable/non-d. partitions.""""""\n        differentiable_leaves = math.tree_leaves(differentiable_xs)\n        non_differentiable_leaves = math.tree_leaves(non_differentiable_xs)\n        leaves = []\n        for is_differentiable in math.tree_leaves(inputs_is_differentiable):\n          if is_differentiable:\n            leaves.append(differentiable_leaves.pop(0))\n          else:\n            leaves.append(non_differentiable_leaves.pop(0))\n        assert not differentiable_leaves\n        assert not non_differentiable_leaves\n        return jax.tree_unflatten(jax.tree_structure(inputs), leaves)\n\n      def vjp(fn, inp, *args, has_aux=False):\n        d_inp, nd_inp = split_differentiable(inp)\n        def fn_closed_over_nd_inp(d_inp, *args):\n          inp = join_differentiable(d_inp, nd_inp)\n          return fn(inp, *args)\n        return jax.vjp(fn_closed_over_nd_inp, d_inp, *args, has_aux=has_aux)\n\n    if n_parallel_heads == 1:\n      def run_inner(idx, loop_val):\n        """"""Runs one slice of attention (for a single head).""""""\n        o_all, s_all, i_ct_all, w_ct_all = loop_val\n        example_idx = idx // self.n_heads\n        head_idx = idx % self.n_heads\n\n        i_h = math.nested_map(lambda x: x[example_idx], inputs)\n        w_h = math.nested_map(lambda w: w[head_idx], weights)\n        s_h = math.nested_map(lambda s: s[idx], state)\n\n        def forward_fn(i_h, w_h):\n          return forward_unbatched(\n              *i_h, weights=w_h, state=math.stop_gradient(s_h))\n\n        if compute_grad:\n          o_h, backward_fn, s_h = vjp(forward_fn, i_h, w_h, has_aux=True)\n          ct_h = output_grad[example_idx]\n          assert o_h.shape == ct_h.shape\n          i_ct_h, w_ct_h = backward_fn(ct_h)\n        else:\n          o_h, s_h = forward_fn(i_h, w_h)\n\n        if compute_output:\n          o_all = jax.ops.index_add(o_all, example_idx, o_h)\n        if update_state:\n          s_all = tree_update(s_all, idx, s_h)\n        if compute_grad:\n          i_ct_all = tree_add(i_ct_all, example_idx, i_ct_h)\n          w_ct_all = tree_add(w_ct_all, head_idx, w_ct_h)\n        return (o_all, s_all, i_ct_all, w_ct_all)\n    elif n_parallel_heads < self.n_heads:\n      assert self.n_heads % n_parallel_heads == 0\n      def run_inner(idx, loop_val):\n        """"""Runs one slice of attention (multiple heads, but one example).""""""\n        o_all, s_all, i_ct_all, w_ct_all = loop_val\n        idx = idx * self.n_parallel_heads\n        example_idx = idx // self.n_heads\n        head_idx_lo = idx % self.n_heads\n        # Use iota here instead of np.arange, because np.arange will fail to\n        # infer that the slice size is a compile-time constant.\n        head_range = head_idx_lo + jax.lax.iota(np.int32, n_parallel_heads)\n        state_range = idx + jax.lax.iota(np.int32, n_parallel_heads)\n\n        i_mh = math.nested_map(lambda x: x[example_idx], inputs)\n        w_mh = math.nested_map(lambda w: w[head_range], weights)\n        s_mh = math.nested_map(lambda s: s[state_range], state)\n        def forward_unbatched_h(i_h, w_h, s_h):\n          return forward_unbatched(*i_h, weights=w_h, state=s_h)\n        def forward_fn(i_mh, w_mh):\n          o_mh, new_s_mh = jax.vmap(\n              forward_unbatched_h, in_axes=(None, 0, 0), out_axes=0)(\n                  i_mh, w_mh, s_mh)\n          o_mh = o_mh.sum(0)\n          return o_mh, new_s_mh\n\n        if compute_grad:\n          o_mh, backward_fn, s_mh = vjp(forward_fn, i_mh, w_mh, has_aux=True)\n          ct_mh = output_grad[example_idx]\n          assert o_mh.shape == ct_mh.shape\n          i_ct_mh, w_ct_mh = backward_fn(ct_mh)\n        else:\n          o_mh, s_mh = forward_fn(i_mh, w_mh)\n\n        if compute_output:\n          o_all = jax.ops.index_add(o_all, example_idx, o_mh)\n        if update_state:\n          s_all = tree_update(s_all, state_range, s_mh)\n        if compute_grad:\n          i_ct_all = tree_add(i_ct_all, example_idx, i_ct_mh)\n          w_ct_all = tree_add(w_ct_all, head_range, w_ct_mh)\n        return (o_all, s_all, i_ct_all, w_ct_all)\n    else:\n      assert n_parallel_heads % self.n_heads == 0\n      def forward_single_example(i_x, w_all, s_x):\n        def forward_unbatched_h(i_h, w_h, s_h):\n          return forward_unbatched(*i_h, weights=w_h, state=s_h)\n        o_x, s_x = jax.vmap(\n            forward_unbatched_h, in_axes=(None, 0, 0), out_axes=(0, 0))(\n                i_x, w_all, s_x)\n        o_x = o_x.sum(0)\n        return o_x, s_x\n      def run_inner(idx, loop_val):\n        """"""Runs one slice of attention (all heads for one or more examples).""""""\n        o_all, s_all, i_ct_all, w_ct_all = loop_val\n        idx = idx * n_parallel_heads\n        example_idx_lo = idx // self.n_heads\n        # Use iota here instead of np.arange, because np.arange will fail to\n        # infer that the slice size is a compile-time constant.\n        example_range = example_idx_lo + jax.lax.iota(\n            np.int32, n_parallel_heads // self.n_heads)\n        state_range = idx + jax.lax.iota(np.int32, n_parallel_heads)\n\n        i_mex = math.nested_map(lambda x: x[example_range], inputs)\n        s_mex = math.nested_map(\n            lambda s: np.reshape(s[state_range],  # pylint: disable=g-long-lambda\n                                 (-1, self.n_heads) + s.shape[1:]),\n            state)\n        def forward_fn(i_mex, w_all):\n          o_mex, new_s_mex = jax.vmap(\n              forward_single_example, in_axes=(0, None, 0), out_axes=(0, 0))(\n                  i_mex, w_all, s_mex)\n          new_s_mex = math.nested_map(\n              lambda s: np.reshape(s, (n_parallel_heads,) + s.shape[2:]),\n              new_s_mex)\n          return o_mex, new_s_mex\n\n        if compute_grad:\n          o_mex, backward_fn, s_mex = vjp(forward_fn, i_mex, weights,\n                                          has_aux=True)\n          ct_mex = output_grad[example_range]\n          assert o_mex.shape == ct_mex.shape\n          i_ct_mex, w_ct_mex = backward_fn(ct_mex)\n        else:\n          o_mex, s_mex = forward_fn(i_mex, weights)\n\n        if compute_output:\n          o_all = jax.ops.index_add(o_all, jax.ops.index[example_range], o_mex)\n        if update_state:\n          s_all = tree_update(s_all, state_range, s_mex)\n        if compute_grad:\n          i_ct_all = tree_update(i_ct_all, example_range, i_ct_mex)\n          w_ct_all = math.nested_map_multiarg(\n              lambda old_all, delta_all: old_all + delta_all,\n              w_ct_all, w_ct_mex)\n        return (o_all, s_all, i_ct_all, w_ct_all)\n\n    o_all = s_all = i_ct_all = w_ct_all = None\n    if compute_output:\n      o_all = np.zeros(\n          (batch_size, seqlen, d_model), dtype=inputs[0].dtype)\n    if update_state:\n      s_all = state\n    if compute_grad:\n      i_ct_all = math.nested_map(np.zeros_like, inputs)\n      i_ct_all, i_nondifferentiable_dummy_ct = split_differentiable(i_ct_all)\n      w_ct_all = math.nested_map(np.zeros_like, weights)\n\n    loop_val = (o_all, s_all, i_ct_all, w_ct_all)\n\n    assert (batch_size * self.n_heads) % n_parallel_heads == 0\n    loop_hi = (batch_size * self.n_heads) // n_parallel_heads\n    if self.use_python_loop or loop_hi == 1:\n      for idx in range(loop_hi):\n        loop_val = run_inner(idx, loop_val)\n    else:\n      loop_val = jax.lax.fori_loop(\n          0, loop_hi, run_inner, loop_val)\n\n    (o_all, s_all, i_ct_all, w_ct_all) = loop_val\n\n    if compute_grad:\n      i_ct_all = join_differentiable(i_ct_all, i_nondifferentiable_dummy_ct)\n\n    if self.incremental and update_state:\n      s_all = (new_mem_end, new_mem, s_all)\n\n    if have_single_input and compute_grad:\n      assert isinstance(i_ct_all, tuple) and len(i_ct_all) == 1\n      return (o_all, s_all, i_ct_all[0], w_ct_all)\n    else:\n      return (o_all, s_all, i_ct_all, w_ct_all)\n\n\nclass SelfAttention(EfficientAttentionBase):\n  """"""Memory-efficient self-attention (second attempt).""""""\n\n  def __init__(self,\n               n_heads=2, d_qk=64, d_v=64, share_qk=False,\n               causal=False, masked=False,\n               chunk_len=None, n_chunks_before=0, n_chunks_after=0,\n               bias=False,\n               mode=\'train\',\n               predict_mem_len=None, predict_drop_len=None,\n               attention_dropout=0.0,\n               output_dropout=0.0,\n               n_parallel_heads=None,\n               use_python_loop=False,\n               use_reference_code=False,\n              ):\n    """"""Construct a self-attention layer.\n\n    Args:\n      n_heads: int: Number of attention heads\n      d_qk: int: Depth of query ond key vectors\n      d_v: int: Depth of value vectors\n      share_qk: bool: Set to True to share query and key projection weights\n      causal: bool: Set to True to mask out attention to future items\n      masked: bool: Set to True to accept an additional mask argument, that\n        allows masking out attention to padding tokens.\n      chunk_len (optional): Number of tokens per chunk. Setting this option will\n        enable chunked attention.\n      n_chunks_before: Number of previous chunks to attend to, when using\n        chunked attention.\n      n_chunks_after: Number of subsequent chunks to attend to, when using\n        chunked attention. Don\'t use this option for causal attention, because\n        attention to future tokens will be masked out anyway. However, note that\n        cross-chunk attention ""wraps around"" in both directions, so this option\n        is never a strict no-op.\n      bias: bool: Set to True to add bias vectors when computing query/key/value\n      mode: \'train\', \'eval\', or \'predict\'\n      predict_mem_len: int: Number of input positions to remember in a cache\n        when doing fast inference. Whenever the cache fills up, some input\n        elements will be forgotten. When chunking is enabled, the default is to\n        store chunk_len * (1 + n_chunks_before) elements.\n      predict_drop_len: int: Number of input elements to drop once the fast\n        inference input cache fills up. When chunking is enabled, the default is\n        to drop exactly chunk_len elements.\n      attention_dropout: Dropout probability for attention mask.\n      output_dropout: Dropout probability for the layer output.\n      n_parallel_heads: see EfficientAttentionBase. This option controls the\n        trade-off between parallelism and memory usage.\n      use_python_loop: For testing/debugging (see EfficientAttentionBase)\n      use_reference_code: For testing/debugging (see EfficientAttentionBase)\n    """"""\n    if mode == \'predict\':\n      assert causal, \'Only causal attention supports fast inference\'\n      assert chunk_len is not None or (predict_mem_len and predict_drop_len)\n      predict_mem_len = predict_mem_len or (chunk_len * (1 + n_chunks_before))\n      predict_drop_len = predict_drop_len or chunk_len\n    super().__init__(\n        n_heads=n_heads,\n        n_in=(2 if masked else 1),\n        n_parallel_heads=n_parallel_heads,\n        incremental=(mode == \'predict\'),\n        predict_mem_len=predict_mem_len,\n        predict_drop_len=predict_drop_len,\n        use_python_loop=use_python_loop,\n        use_reference_code=use_reference_code,\n        )\n    self.d_qk = d_qk\n    self.d_v = d_v\n    self.share_qk = share_qk\n    self.causal = causal\n    self.masked = masked\n    self.chunk_len = chunk_len\n    self.n_chunks_before = n_chunks_before\n    self.n_chunks_after = n_chunks_after\n    self.bias = bias\n    self.mode = mode\n    if mode == \'train\':\n      self.attention_dropout = attention_dropout\n      self.output_dropout = output_dropout\n    else:\n      self.attention_dropout = 0.0\n      self.output_dropout = 0.0\n\n  def _kernel_initializer(self, shape, rng):\n    # Attention uses Glorot uniform initalization with respect to the *total*\n    # dimension of queries/key/values across all heads. We initialize one head\n    # at a time in this class, so init.GlorotUniformInitializer won\'t work.\n    # This initialization type is for parity with previous Trax & tensor2tensor\n    # Transformers; it\'s not clear if it\'s strictly needed for model accuracy.\n    lim = np.sqrt(6.0 / (shape[0] + shape[1] * self.n_heads))\n    return math.random.uniform(rng, shape, np.float32, -lim, lim)\n\n  def create_weights_unbatched(self, input_signature, rng):\n    if isinstance(input_signature, (tuple, list)):\n      input_signature = input_signature[0]\n    d_model = input_signature.shape[-1]\n    rng_q, rng_k, rng_v, rng_o = math.random.split(rng, 4)\n    w_q = self._kernel_initializer((d_model, self.d_qk), rng_q)\n    if not self.share_qk:\n      w_k = self._kernel_initializer((d_model, self.d_qk), rng_k)\n    w_v = self._kernel_initializer((d_model, self.d_v), rng_v)\n    w_o = np.transpose(self._kernel_initializer((d_model, self.d_v), rng_o))\n\n    if self.bias:\n      b_q = np.zeros(self.d_qk)\n      b_v = np.zeros(self.d_v)\n      if self.share_qk:\n        return (w_q, w_v, w_o, b_q, b_v)\n      else:\n        b_k = np.zeros(self.d_qk)\n        return (w_q, w_k, w_v, w_o, b_q, b_k, b_v)\n\n    if self.share_qk:\n      return (w_q, w_v, w_o)\n    else:\n      return (w_q, w_k, w_v, w_o)\n\n  def forward_unbatched(self, x, mask=None, *,\n                        weights, state, rng, update_state):\n    del update_state\n    attend_rng, output_rng = math.random.split(rng)\n    if self.bias:\n      if self.share_qk:\n        w_q, w_v, w_o, b_q, b_v = weights\n      else:\n        w_q, w_k, w_v, w_o, b_q, b_k, b_v = weights\n    else:\n      if self.share_qk:\n        w_q, w_v, w_o = weights\n      else:\n        w_q, w_k, w_v, w_o = weights\n\n    q = np.matmul(x, w_q)\n    k = None\n    if not self.share_qk:\n      k = np.matmul(x, w_k)\n    v = np.matmul(x, w_v)\n\n    if self.bias:\n      q = q + b_q\n      if not self.share_qk:\n        k = k + b_k\n      v = v + b_v\n\n    mask_fn = functools.partial(\n        mask_self_attention,\n        causal=self.causal, exclude_self=self.share_qk, masked=self.masked)\n    q_info = kv_info = tie_in(x, np.arange(q.shape[-2]))\n\n    assert (mask is not None) == self.masked\n    if self.masked:\n      # mask is a boolean array (True means ""is valid token"")\n      ones_like_mask = tie_in(x, np.ones_like(mask, dtype=np.int32))\n      kv_info = kv_info * np.where(mask, ones_like_mask, -ones_like_mask)\n\n    o, _ = attend(\n        q, k, v,\n        q_chunk_len=self.chunk_len,\n        kv_chunk_len=self.chunk_len,\n        n_chunks_before=self.n_chunks_before,\n        n_chunks_after=self.n_chunks_after,\n        mask_fn=mask_fn, q_info=q_info, kv_info=kv_info,\n        dropout=self.attention_dropout, rng=attend_rng,\n        )\n\n    out = np.matmul(o, w_o)\n    out = apply_broadcasted_dropout(out, self.output_dropout, output_rng)\n    return out, state\n\n  def incremental_forward_unbatched(self, x, mask=None, *,\n                                    q_start, q_len,\n                                    weights, state, rng, update_state):\n    del update_state\n    attend_rng, output_rng = math.random.split(rng)\n    if self.share_qk:\n      w_q, w_v, w_o = weights\n    else:\n      w_q, w_k, w_v, w_o = weights\n\n    q_range = q_start + tie_in(x, jax.lax.iota(np.int32, q_len))\n    if q_len == 1:\n      # On TPU, np.matmul(a[:1], b) and np.matmul(a, b)[:1] are not\n      # floating-point equivalent, at least in non-jitted code. We correct the\n      # discrepancy by duplicating the slice. Floating-point noise may not be\n      # an issue when using models, but it makes it harder to write tests that\n      # compare fast and slow inference code for equivalence.\n      q = np.matmul(np.concatenate([x[q_range]] * 2, 0), w_q)\n    else:\n      q = np.matmul(x[q_range], w_q)\n    if self.share_qk:\n      k = length_normalized(np.matmul(x, w_q))\n    else:\n      k = np.matmul(x, w_k)\n    v = np.matmul(x, w_v)\n\n    mask_fn = functools.partial(\n        mask_self_attention,\n        causal=self.causal, exclude_self=self.share_qk, masked=self.masked)\n    q_info = q_range\n    kv_info = tie_in(x, np.arange(k.shape[-2]))\n\n    if self.chunk_len is not None and q_len > self.chunk_len:\n      assert q_start == 0\n      assert q_len % self.chunk_len == 0\n      o, _ = attend(\n          q, k, v,\n          q_chunk_len=self.chunk_len,\n          kv_chunk_len=self.chunk_len,\n          n_chunks_before=self.n_chunks_before,\n          n_chunks_after=self.n_chunks_after,\n          mask_fn=mask_fn, q_info=q_info, kv_info=kv_info,\n          dropout=self.attention_dropout, rng=attend_rng,\n          )\n    else:\n      o, _ = attend(\n          q, k, v,\n          mask_fn=mask_fn, q_info=q_info, kv_info=kv_info,\n          dropout=self.attention_dropout, rng=attend_rng,\n          )\n\n    out = np.matmul(o, w_o)\n    if q_len == 1:\n      out = out[:1]\n    out = apply_broadcasted_dropout(out, self.output_dropout, output_rng)\n    return out, state\n\n\nclass LSHSelfAttention(SelfAttention):\n  """"""LSH self-attention (second implementation).""""""\n\n  def __init__(self,\n               n_heads=2, d_qk=64, d_v=64, share_qk=\'unused\',\n               causal=False,\n               masked=False,\n               chunk_len=None, n_chunks_before=1, n_chunks_after=0,\n               n_hashes=1,\n               n_buckets=256,\n               mode=\'train\',\n               predict_mem_len=2048, predict_drop_len=256,\n               attention_dropout=0.0,\n               output_dropout=0.0,\n               n_parallel_heads=1,\n               use_python_loop=False,\n               use_reference_code=False,\n              ):\n    """"""Construct an LSH self-attention layer.""""""\n    super().__init__(\n        n_heads=n_heads, d_qk=d_qk, d_v=d_v, share_qk=True,\n        causal=causal,\n        masked=masked,\n        chunk_len=chunk_len,\n        n_chunks_before=n_chunks_before, n_chunks_after=n_chunks_after,\n        mode=mode,\n        predict_mem_len=predict_mem_len, predict_drop_len=predict_drop_len,\n        attention_dropout=attention_dropout,\n        output_dropout=output_dropout,\n        n_parallel_heads=n_parallel_heads,\n        use_python_loop=use_python_loop,\n        use_reference_code=use_reference_code,\n        )\n    self.n_hashes = n_hashes\n    self.n_buckets = n_buckets\n\n  def create_state_unbatched(self, input_signature, rng):\n    if isinstance(input_signature, (tuple, list)):\n      input_signature = input_signature[0]\n    # The `rng` argument passed to forward_unbatched is shared across all\n    # examples and heads. This facilitates using broadcasted dropout, which\n    # saves memory and hasn\'t been shown to hurt model quality. Even though the\n    # same sharing is likely to be safe when selecting random hash functions\n    # for LSH, we haven\'t run experiments to demonstrate this. To be on the safe\n    # side we include a per-head RNG in the state for the purpose of doing LSH.\n    if not self.incremental:\n      buckets = np.zeros(\n          self.n_hashes * input_signature.shape[0], dtype=np.int32)\n      return (buckets, rng)\n    else:\n      buckets = np.zeros(\n          self.n_hashes * self.predict_mem_len, dtype=np.int32)\n      buckets_idx = np.zeros((), dtype=np.int32)\n      return (buckets, buckets_idx, rng)\n\n  def hash_vectors(self, vecs, rng, mask=None):\n    # See https://arxiv.org/pdf/1509.02897.pdf\n    # We sample a different random rotation for each round of hashing to\n    # decrease the probability of hash misses.\n    if isinstance(self.n_buckets, int):\n      assert self.n_buckets % 2 == 0\n      rot_size = self.n_buckets\n      n_buckets = self.n_buckets\n    else:\n      # Factorize the hash if self.n_buckets is a list or tuple\n      rot_size, n_buckets = 0, 1\n      for factor in self.n_buckets:\n        assert factor % 2 == 0\n        rot_size += factor\n        n_buckets *= factor\n\n    rotations_shape = (vecs.shape[-1], self.n_hashes, rot_size // 2)\n\n    rng = math.stop_gradient(tie_in(vecs, rng))\n    random_rotations = math.random.normal(rng, rotations_shape).astype(\n        np.float32)\n    rotated_vecs = np.einsum(\'tf,fhb->htb\', vecs, random_rotations)\n\n    if isinstance(self.n_buckets, int) or len(self.n_buckets) == 1:\n      rotated_vecs = np.concatenate([rotated_vecs, -rotated_vecs], axis=-1)\n      buckets = np.argmax(rotated_vecs, axis=-1)\n    else:\n      # Get the buckets for them and combine.\n      buckets, cur_sum, cur_product = None, 0, 1\n      for factor in self.n_buckets:\n        rv = rotated_vecs[..., cur_sum:cur_sum + (factor // 2)]\n        cur_sum += factor // 2\n        rv = np.concatenate([rv, -rv], axis=-1)\n        if buckets is None:\n          buckets = np.argmax(rv, axis=-1)\n        else:\n          buckets += cur_product * np.argmax(rv, axis=-1)\n        cur_product *= factor\n\n    if mask is not None:\n      n_buckets += 1  # Create an extra bucket for padding tokens only\n      buckets = np.where(mask[None, :], buckets, n_buckets - 1)\n\n    # buckets is now (self.n_hashes, seqlen). Next we add offsets so that\n    # bucket numbers from different hashing rounds don\'t overlap.\n    offsets = tie_in(buckets, np.arange(self.n_hashes))\n    offsets = np.reshape(offsets * n_buckets, (-1, 1))\n    buckets = np.reshape(buckets + offsets, (-1,))\n\n    return buckets\n\n  def forward_unbatched(self, x, mask=None, *, weights, state, rng,\n                        update_state):\n    attend_rng, output_rng = math.random.split(rng)\n    w_q, w_v, w_o = weights\n\n    q = np.matmul(x, w_q)\n    v = np.matmul(x, w_v)\n\n    if update_state:\n      _, old_hash_rng = state\n      hash_rng, hash_subrng = math.random.split(old_hash_rng)\n      buckets = self.hash_vectors(q, hash_subrng, mask)\n      state = (buckets, hash_rng)\n    else:\n      buckets, _ = state\n\n    seqlen = x.shape[0]\n    assert int(buckets.shape[0]) == self.n_hashes * seqlen\n\n    ticker = tie_in(x, np.arange(self.n_hashes * seqlen))\n    buckets_and_t = seqlen * buckets + (ticker % seqlen)\n    buckets_and_t = math.stop_gradient(buckets_and_t)\n\n    # Hash-based sort (""s"" at the start of variable names means ""sorted"")\n    sbuckets_and_t, sticker = jax.lax.sort_key_val(\n        buckets_and_t, ticker, dimension=-1)\n    _, undo_sort = jax.lax.sort_key_val(sticker, ticker, dimension=-1)\n    sbuckets_and_t = math.stop_gradient(sbuckets_and_t)\n    sticker = math.stop_gradient(sticker)\n    undo_sort = math.stop_gradient(undo_sort)\n\n    st = (sticker % seqlen)\n    sq = np.take(q, st, axis=0)\n    sv = np.take(v, st, axis=0)\n\n    mask_fn = functools.partial(mask_self_attention, causal=self.causal,\n                                exclude_self=True, masked=self.masked)\n    q_info = st\n\n    assert (mask is not None) == self.masked\n    kv_info = None\n    if self.masked:\n      # mask is a boolean array (True means ""is valid token"")\n      smask = np.take(mask, st, axis=0)\n      ones_like_mask = tie_in(x, np.ones_like(smask, dtype=np.int32))\n      kv_info = q_info * np.where(smask, ones_like_mask, -ones_like_mask)\n\n    so, slogits = attend(\n        sq, k=None, v=sv,\n        q_chunk_len=self.chunk_len,\n        n_chunks_before=self.n_chunks_before,\n        n_chunks_after=self.n_chunks_after,\n        mask_fn=mask_fn, q_info=q_info, kv_info=kv_info,\n        dropout=self.attention_dropout, rng=attend_rng,\n        )\n\n    # np.take(so, undo_sort, axis=0); np.take(slogits, undo_sort, axis=0) would\n    # also work, but these helpers include performance optimizations for TPU.\n    o = permute_via_gather(so, undo_sort, sticker, axis=0)\n    logits = permute_via_sort(slogits, sticker, buckets_and_t, axis=-1)\n\n    if self.n_hashes > 1:\n      o = np.reshape(o, (self.n_hashes, seqlen, o.shape[-1]))\n      logits = np.reshape(logits, (self.n_hashes, seqlen, 1))\n      probs = np.exp(logits - math.logsumexp(logits, axis=0, keepdims=True))\n      o = np.sum(o * probs, axis=0)\n\n    assert o.shape == (seqlen, w_v.shape[-1])\n    out = np.matmul(o, w_o)\n    out = apply_broadcasted_dropout(out, self.output_dropout, output_rng)\n    return out, state\n\n  def incremental_forward_unbatched(self, x, *,\n                                    q_start, q_len,\n                                    weights, state, rng, update_state):\n    assert update_state, (\n        \'This setting not supported (e.g. no backprop for fast inference)\')\n    if isinstance(q_start, int) and q_start == 0 and q_len > 1:\n      if x.shape[0] % self.chunk_len == 0:\n        x_padded = x\n      else:\n        pad_amount = self.chunk_len - (x.shape[0] % self.chunk_len)\n        x_padded = np.pad(x, ((0, pad_amount), (0, 0)), mode=\'constant\')\n      buckets, buckets_idx, hash_rng = state\n      q = np.matmul(x_padded, weights[0])\n      buckets_update = self.hash_vectors(q, hash_rng)\n\n      out, _ = self.forward_unbatched(\n          x_padded, weights=weights, state=(buckets_update, hash_rng),\n          rng=rng, update_state=False)\n\n      out = out[:q_len]\n      buckets = np.reshape(buckets, (self.n_hashes, -1))\n      buckets_update = np.reshape(\n          buckets_update, (self.n_hashes, -1))[:, :q_len]\n      if q_len > self.predict_mem_len:\n        buckets_update = buckets_update[:, -self.predict_mem_len:]  # pylint: disable=invalid-unary-operand-type\n      buckets = jax.lax.dynamic_update_slice_in_dim(\n          buckets, buckets_update, q_start, axis=1)\n      buckets = np.reshape(buckets, (-1,))\n\n      return out, (buckets, buckets_idx + q_len, hash_rng)\n\n    # This codepath is for handling one token at a time.\n    assert q_len == 1\n    buckets, buckets_idx, hash_rng = state\n\n    def roll_buckets(buckets):\n      buckets = np.reshape(buckets, (self.n_hashes, -1))\n      new_buckets = np.concatenate(\n          [buckets, np.zeros((self.n_hashes, self.predict_drop_len),\n                             dtype=buckets.dtype)\n          ], axis=1)\n      new_buckets = jax.lax.dynamic_slice_in_dim(\n          new_buckets, buckets_idx - q_start, buckets.shape[-1], axis=1)\n      new_buckets = np.reshape(new_buckets, (-1,))\n      return new_buckets\n\n    buckets = jax.lax.cond(\n        pred=buckets_idx > q_start,\n        true_operand=buckets,\n        true_fun=roll_buckets,\n        false_operand=buckets,\n        false_fun=lambda x: x,\n    )\n\n    attend_rng, output_rng = math.random.split(rng)\n    w_q, w_v, w_o = weights\n\n    q_range = q_start + tie_in(x, jax.lax.iota(np.int32, q_len))\n    # On TPU, np.matmul(a[:1], b) and np.matmul(a, b)[:1] are not\n    # floating-point equivalent, at least in non-jitted code. We correct the\n    # discrepancy by duplicating the slice. Floating-point noise may not be\n    # an issue when using models, but it makes it harder to write tests that\n    # compare fast and slow inference code for equivalence.\n    q = np.matmul(np.concatenate([x[q_range]] * 2, 0), w_q)\n\n    q_buckets = self.hash_vectors(q, hash_rng)\n    q_buckets = np.reshape(q_buckets, (self.n_hashes, 2))[:, :q_len]\n\n    unflattened_buckets = jax.lax.dynamic_update_slice_in_dim(\n        np.reshape(buckets, (self.n_hashes, -1)),\n        q_buckets, q_start, axis=1)\n    buckets = np.reshape(unflattened_buckets, (-1,))\n    is_valid_target = np.any(unflattened_buckets == q_buckets, axis=0)\n\n    assert q_buckets.shape[-1] == 1  # Is true when q_len == 1\n    seqlen = x.shape[0]\n    arange_seqlen = np.arange(seqlen)\n    kv_priorities = np.where(\n        arange_seqlen > (q_start + q_len),\n        -(seqlen + arange_seqlen), arange_seqlen)\n    kv_priorities = kv_priorities + seqlen * is_valid_target.astype(np.int32)\n    _, kv_indices = jax.lax.sort_key_val(kv_priorities, arange_seqlen)\n    kv_indices = kv_indices[\n        -self.n_hashes * self.chunk_len * (1 + self.n_chunks_before):]\n    assert self.n_chunks_after == 0\n\n    x_attend_to = x[kv_indices]\n    k = length_normalized(np.matmul(x_attend_to, w_q))\n    v = np.matmul(x_attend_to, w_v)\n\n    mask_fn = functools.partial(\n        mask_self_attention, causal=True, masked=True, exclude_self=True)\n    q_info = q_start + np.arange(q_len)\n    kv_info = kv_indices\n    # TODO(kitaev): is it better to mask out attention across buckets?\n    # kv_info = np.where(is_valid_target[kv_indices], kv_indices, -kv_indices)\n    o, _ = attend(\n        q, k, v,\n        mask_fn=mask_fn, q_info=q_info, kv_info=kv_info,\n        dropout=self.attention_dropout, rng=attend_rng,\n        )\n\n    out = np.matmul(o, w_o)\n    if q_len == 1:\n      out = out[:1]\n    out = apply_broadcasted_dropout(out, self.output_dropout, output_rng)\n    buckets_idx = np.array(q_start + q_len, dtype=buckets_idx.dtype)\n    return out, (buckets, buckets_idx, hash_rng)\n\n\nclass EncDecAttention(EfficientAttentionBase):\n  """"""Memory-efficient encoder-decoder attention.""""""\n\n  def __init__(self,\n               n_heads=2, d_qk=64, d_v=64,\n               masked=True,\n               mode=\'train\',\n               attention_dropout=0.0,\n               output_dropout=0.0,\n               n_parallel_heads=None,\n               use_python_loop=False,\n               use_reference_code=False,\n              ):\n    super().__init__(\n        n_heads=n_heads,\n        n_in=(3 if masked else 2),\n        n_parallel_heads=n_parallel_heads,\n        use_python_loop=use_python_loop,\n        use_reference_code=use_reference_code,\n        )\n    self.d_qk = d_qk\n    self.d_v = d_v\n    self.masked = masked\n    self.mode = mode\n    if mode == \'train\':\n      self.attention_dropout = attention_dropout\n      self.output_dropout = output_dropout\n    else:\n      self.attention_dropout = 0.0\n      self.output_dropout = 0.0\n\n  def _kernel_initializer(self, shape, rng):\n    # Attention uses Glorot uniform initalization with respect to the *total*\n    # dimension of queries/key/values across all heads. We initialize one head\n    # at a time in this class, so init.GlorotUniformInitializer won\'t work.\n    # This initialization type is for parity with previous Trax & tensor2tensor\n    # Transformers; it\'s not clear if it\'s strictly needed for model accuracy.\n    lim = np.sqrt(6.0 / (shape[0] + shape[1] * self.n_heads))\n    return math.random.uniform(rng, shape, np.float32, -lim, lim)\n\n  def create_weights_unbatched(self, input_signature, rng):\n    d_model = input_signature[0].shape[-1]\n    d_kv_antecedent = input_signature[1].shape[-1]\n    rng_q, rng_k, rng_v, rng_o = math.random.split(rng, 4)\n    w_q = self._kernel_initializer((d_model, self.d_qk), rng_q)\n    w_k = self._kernel_initializer((d_kv_antecedent, self.d_qk), rng_k)\n    w_v = self._kernel_initializer((d_kv_antecedent, self.d_v), rng_v)\n    w_o = np.transpose(self._kernel_initializer((d_model, self.d_v), rng_o))\n    return (w_q, w_k, w_v, w_o)\n\n  def forward_unbatched(self, q_antecedent, kv_antecedent, mask=None, *,\n                        weights, state, rng, update_state):\n    del update_state\n    attend_rng, output_rng = math.random.split(rng)\n    w_q, w_k, w_v, w_o = weights\n\n    q = np.matmul(q_antecedent, w_q)\n    k = np.matmul(kv_antecedent, w_k)\n    v = np.matmul(kv_antecedent, w_v)\n\n    if not self.masked:\n      assert mask is None\n      q_info = kv_info = mask_fn = None\n    else:\n      # mask is a boolean array (True means ""is valid token"")\n      assert mask is not None\n      q_info = None\n      kv_info = (~mask).astype(np.int32)  # pylint: disable=invalid-unary-operand-type\n      def mask_fn(dots, q_info, kv_info):\n        del q_info\n        mask = kv_info.astype(np.float32)\n        dots = dots - 1e9 * mask\n        return dots\n\n    o, _ = attend(\n        q, k, v,\n        mask_fn=mask_fn, q_info=q_info, kv_info=kv_info,\n        dropout=self.attention_dropout, rng=attend_rng,\n        )\n\n    out = np.matmul(o, w_o)\n    out = apply_broadcasted_dropout(out, self.output_dropout, output_rng)\n    return out, state\n'"
trax/layers/research/efficient_attention_test.py,15,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for trax.layers.research.efficient_attention.""""""\n\nimport jax\nimport numpy as np\nfrom tensorflow import test\n\nfrom trax import math\nfrom trax import shapes\nfrom trax.layers.research import efficient_attention\nfrom trax.math import numpy as jnp\n\n\nclass EfficientAttentionTest(test.TestCase):\n\n  def test_self_attention(self):\n    with math.use_backend(\'jax\'):\n      layer = efficient_attention.SelfAttention(\n          n_heads=5, d_qk=7, d_v=17, share_qk=False, causal=True,\n          chunk_len=8, n_chunks_before=1, n_chunks_after=0,\n          use_reference_code=True, attention_dropout=0.0, mode=\'train\')\n      x = np.ones((3, 32, 8)).astype(np.float32)\n      _, _ = layer.init(shapes.signature(x))\n      y = layer(x)\n      self.assertEqual(y.shape, x.shape)\n\n  def test_self_attention_tf(self):\n    with math.use_backend(\'tf\'):\n      layer = efficient_attention.SelfAttention(\n          n_heads=5, d_qk=7, d_v=17, share_qk=False, causal=True,\n          chunk_len=8, n_chunks_before=1, n_chunks_after=0,\n          use_reference_code=True, attention_dropout=0.0, mode=\'train\')\n      x = np.ones((3, 32, 8)).astype(np.float32)\n      _, _ = layer.init(shapes.signature(x))\n      y = layer(x)\n      self.assertEqual(y.shape, x.shape)\n\n  def test_lsh_self_attention(self):\n    with math.use_backend(\'jax\'):\n      layer = efficient_attention.LSHSelfAttention(\n          n_heads=5, d_qk=7, d_v=17, causal=True,\n          chunk_len=8, n_chunks_before=1, n_chunks_after=0,\n          n_hashes=2, n_buckets=4,\n          use_reference_code=True, attention_dropout=0.0, mode=\'train\')\n      x = np.ones((3, 32, 8)).astype(np.float32)\n      _, _ = layer.init(shapes.signature(x))\n      y = layer(x)\n      self.assertEqual(y.shape, x.shape)\n\n  def _run_forward_and_backward(self, model, inp, weights, state):\n    def forward(inp, weights):\n      return model.pure_fn(\n          inp, weights, state, rng=jax.random.PRNGKey(0))\n    out, vjpfun, new_state = jax.vjp(forward, inp, weights, has_aux=True)\n    inp_grad, weights_grad = vjpfun(np.ones_like(inp))\n    return out, new_state, inp_grad, weights_grad\n\n  def _test_equivalence_to_reference_code(\n      self, model_cls, inp, input_signature, common_kwargs, *test_kwargs):\n    ref_model = model_cls(use_reference_code=True, **common_kwargs)\n    rng = math.random.get_prng(123)\n    weights, state = ref_model.init(input_signature, rng)\n\n    ref_all = self._run_forward_and_backward(ref_model, inp, weights, state)\n    ref_out, ref_state, ref_inp_grad, ref_weights_grad = ref_all\n\n    for kwargs in test_kwargs:\n      test_model = model_cls(**common_kwargs, **kwargs)\n      state = test_model.init(input_signature, rng)[1]\n      test_all = self._run_forward_and_backward(test_model, inp, weights, state)\n      test_out, test_state, test_inp_grad, test_weights_grad = test_all\n\n      self.assertEqual(jax.tree_structure(ref_out),\n                       jax.tree_structure(test_out))\n      self.assertEqual(jax.tree_structure(ref_state),\n                       jax.tree_structure(test_state))\n      self.assertEqual(jax.tree_structure(ref_inp_grad),\n                       jax.tree_structure(test_inp_grad))\n      self.assertEqual(jax.tree_structure(ref_weights_grad),\n                       jax.tree_structure(test_weights_grad))\n\n      check_close = lambda x, y: self.assertAllClose(x, y, rtol=1e-3, atol=1e-3)\n      math.nested_map_multiarg(check_close, ref_out, test_out)\n      math.nested_map_multiarg(check_close, ref_state, test_state)\n      math.nested_map_multiarg(check_close, ref_inp_grad, test_inp_grad)\n      math.nested_map_multiarg(check_close, ref_weights_grad, test_weights_grad)\n\n  def test_batching_self_attention(self):\n    with math.use_backend(\'jax\'):\n      common_kwargs = dict(\n          n_heads=6, d_qk=7, d_v=17, share_qk=False, causal=True,\n          chunk_len=5, n_chunks_before=1, n_chunks_after=0,\n          attention_dropout=0.2, output_dropout=0.1, mode=\'train\',\n      )\n      test_kwargs = []\n      for n_parallel_heads in [1, 3, 6, 12]:\n        for use_python_loop in [True, False]:\n          test_kwargs.append(dict(n_parallel_heads=n_parallel_heads,\n                                  use_python_loop=use_python_loop))\n\n      x = jax.random.uniform(\n          jax.random.PRNGKey(0), (2, 10, 13), dtype=jnp.float32)\n      input_signature = shapes.signature(x)\n      self._test_equivalence_to_reference_code(\n          efficient_attention.SelfAttention,\n          x, input_signature,\n          common_kwargs, *test_kwargs)\n\n  def test_batching_lsh_self_attention(self):\n    with math.use_backend(\'jax\'):\n      common_kwargs = dict(\n          n_heads=6, d_qk=7, d_v=17, causal=True,\n          chunk_len=5, n_chunks_before=1, n_chunks_after=0,\n          n_hashes=2, n_buckets=4,\n          attention_dropout=0.2, output_dropout=0.1, mode=\'train\',\n      )\n      test_kwargs = []\n      for n_parallel_heads in [1, 3, 6, 12]:\n        for use_python_loop in [True, False]:\n          test_kwargs.append(dict(n_parallel_heads=n_parallel_heads,\n                                  use_python_loop=use_python_loop))\n\n      x = jax.random.uniform(\n          jax.random.PRNGKey(0), (2, 10, 13), dtype=jnp.float32)\n      input_signature = shapes.signature(x)\n      self._test_equivalence_to_reference_code(\n          efficient_attention.LSHSelfAttention,\n          x, input_signature,\n          common_kwargs, *test_kwargs)\n\n  def _test_fast_inference(\n      self, model_cls, x, input_signature, common_kwargs, *test_kwargs):\n    ref_model = model_cls(use_reference_code=True, mode=\'eval\', **common_kwargs)\n    weights, state = ref_model.init(input_signature)\n\n    ref_out, _ = ref_model.pure_fn(\n        x, weights, state, rng=jax.random.PRNGKey(0))\n\n    def get_slice(pytree, i):\n      def get_slice_for_val(x):\n        if isinstance(x, shapes.ShapeDtype):\n          return shapes.ShapeDtype(shape=x.shape[:1] + (1,) + x.shape[2:],\n                                   dtype=x.dtype)\n        else:\n          return x[:, i:i+1]\n      return jax.tree_map(get_slice_for_val, pytree)\n\n    seqlen = x[0].shape[1] if isinstance(x, (tuple, list)) else x.shape[1]\n\n    for kwargs in test_kwargs:\n      test_model = model_cls(mode=\'predict\', **common_kwargs, **kwargs)\n      cur_state = test_model.init(get_slice(input_signature, 0))[1]\n      out = []\n      for i in range(seqlen):\n        cur_out, cur_state = test_model.pure_fn(\n            get_slice(x, i), weights, cur_state, jax.random.PRNGKey(0))\n        out.append(cur_out)\n      out = jnp.concatenate(out, axis=1)\n\n      self.assertAllClose(out, ref_out, rtol=1e-3, atol=1e-3)\n\n  def test_fast_inference_self_attention(self):\n    with math.use_backend(\'jax\'):\n      common_kwargs = dict(\n          n_heads=6, d_qk=7, d_v=17, share_qk=False, causal=True,\n          chunk_len=5, n_chunks_before=1, n_chunks_after=0,\n          attention_dropout=0.0, output_dropout=0.0,\n      )\n      test_kwargs = []\n      for n_parallel_heads in [1, 3, 6, 12]:\n        for use_python_loop in [True, False]:\n          test_kwargs.append(dict(n_parallel_heads=n_parallel_heads,\n                                  use_python_loop=use_python_loop))\n\n      x = jax.random.uniform(\n          jax.random.PRNGKey(0), (2, 10, 13), dtype=jnp.float32)\n      input_signature = shapes.signature(x)\n      self._test_fast_inference(\n          efficient_attention.SelfAttention,\n          x, input_signature,\n          common_kwargs, *test_kwargs)\n\n  def _test_lsh_self_attention_deterministic_given_seed(self, causal=False):\n    # Once the initialization and the call seeds are pinned down we have\n    # deterministic output.\n    with math.use_backend(\'jax\'):\n      layer = efficient_attention.LSHSelfAttention(\n          n_heads=5, d_qk=7, d_v=17, causal=causal,\n          chunk_len=8, n_chunks_before=1, n_chunks_after=0,\n          n_hashes=2, n_buckets=4,\n          use_reference_code=True, attention_dropout=0.0, mode=\'train\')\n      x = np.ones((3, 32, 8)).astype(np.float32)\n\n      def get_output():\n        _, _ = layer.init(shapes.signature(x), jax.random.PRNGKey(0))\n        return layer(x, rng=jax.random.PRNGKey(1))\n\n      ys = [get_output() for _ in range(10)]\n\n      self.assertEqual(ys[0].shape, x.shape)\n\n      for y in ys[1:]:\n        np.testing.assert_array_almost_equal(ys[0], y, decimal=6)\n\n  def test_lsh_determinism_causal(self):\n    self._test_lsh_self_attention_deterministic_given_seed(causal=True)\n\n  def test_lsh_determinism_non_causal(self):\n    self._test_lsh_self_attention_deterministic_given_seed(causal=False)\n\n  def test_lsh_self_attention_masked_non_causal(self):\n    # Test that when the input that is in the masked area changes the attention\n    # for the un-masked outputs doesn\'t change, but the masked region does\n    # change.\n    with math.use_backend(\'jax\'):\n      layer = efficient_attention.LSHSelfAttention(\n          n_heads=5, d_qk=7, d_v=17, causal=False, masked=True,\n          chunk_len=8, n_chunks_before=1, n_chunks_after=0,\n          n_hashes=2, n_buckets=4,\n          use_reference_code=True, attention_dropout=0.0, mode=\'train\')\n\n      batch = 5\n      max_len = 32\n      hidden = 8\n\n      x = np.random.uniform(size=(batch, max_len, hidden))\n      mask = np.ones((batch, max_len)).astype(np.bool)\n      rngs = jax.random.randint(\n          jax.random.PRNGKey(0), (batch,), minval=1, maxval=max_len - 1)\n\n      # Set some suffix of each mask[b] to 0.\n      for i in range(batch):\n        mask[i, rngs[i]:] = 0\n\n      # Fix rngs and get the output for the LSH layer.\n      def get_output(x, mask):\n        xs = [x, mask]\n        _, _ = layer.init(shapes.signature(xs), jax.random.PRNGKey(0))\n        return layer(xs, rng=jax.random.PRNGKey(1))\n\n      # Get the attention output for masked x.\n      y = get_output(x, mask)\n\n      # Change x, but only in the masked regions.\n      for i in range(batch):\n        x[i, rngs[i]:] = np.random.uniform(size=(max_len - rngs[i], hidden))\n\n      y2 = get_output(x, mask)\n\n      for i in range(batch):\n        # y and y2 should be identical in the non-masked part.\n        np.testing.assert_array_almost_equal(y[i, :rngs[i]], y2[i, :rngs[i]],\n                                             decimal=6)\n\n        # In the masked out part, they should be different.\n        self.assertGreater(\n            np.mean(np.abs(y[i, rngs[i]:] - y2[i, rngs[i]:])), 1e-5)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/layers/research/position_encodings.py,47,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Experimenting with position encodings.""""""\n\nimport logging\nimport jax\nimport numpy as np\nimport trax\nfrom trax import math\nfrom trax.layers import base as layer_base\nfrom trax.layers import initializers as init\nfrom trax.math import numpy as jnp\n\n\nclass AxialPositionalEncoding(layer_base.Layer):\n  """"""Axial positional encoding.""""""\n  # TODO(kitaev): support variable-length sequences.\n\n  def __init__(self, shape=(64, 64, 3), d_embs=(384, 384, 256),\n               kernel_initializer=init.RandomNormalInitializer(1.0),\n               dropout=0.0, dropout_broadcast_dims=(), mode=\'train\'):\n    super(AxialPositionalEncoding, self).__init__()\n    self._kernel_initializer = kernel_initializer\n    assert len(shape) == len(d_embs)\n    self._shape = shape\n    self._d_embs = d_embs\n\n    if dropout >= 1.0:\n      raise ValueError(\'Dropout rates must be lower than 1.\')\n    if mode == \'train\':\n      self._dropout = dropout\n    else:\n      self._dropout = 0.0\n    self._dropout_broadcast_dims = dropout_broadcast_dims\n    self._mode = mode\n\n  def forward(self, inputs, weights):\n    rng, state = self.rng, self.state\n    embs = []\n    for ax_emb in weights:\n      ax_emb = jnp.broadcast_to(\n          ax_emb, (inputs.shape[0],) + self._shape + (ax_emb.shape[-1],))\n      embs.append(ax_emb)\n\n    if self._mode == \'predict\':\n      assert self._dropout == 0.0\n      emb = jnp.concatenate(embs, -1)\n      emb = jnp.reshape(emb, (inputs.shape[0], -1, emb.shape[-1]))\n      emb = jax.lax.dynamic_slice_in_dim(emb, state, inputs.shape[1], axis=1)\n      self.state = state + inputs.shape[1]\n      return inputs + emb\n    elif self._dropout == 0:\n      # TODO(kitaev): concat-then-reshape (as is the case with dropout enabled)\n      # leads to memory blow-up on TPU.\n      # emb = jnp.concatenate(embs, -1)\n      # return inputs + jnp.reshape(emb, inputs.shape), state\n      return inputs + jnp.concatenate(\n          [jnp.reshape(emb, inputs.shape[:-1] + (emb.shape[-1],))\n           for emb in embs\n          ], -1)\n    else:\n      emb = jnp.concatenate(embs, -1)\n      noise_shape = list(emb.shape)\n      for dim in self._dropout_broadcast_dims:\n        noise_shape[dim] = 1\n      keep_prob = 1.0 - self._dropout\n      if math.backend_name() == \'jax\':\n        keep_prob = jax.lax.tie_in(\n            inputs, jnp.full((), keep_prob, dtype=inputs.dtype))\n      keep = math.random.bernoulli(rng, keep_prob, tuple(noise_shape))\n      multiplier = keep.astype(inputs.dtype) / keep_prob\n      return inputs + jnp.reshape(emb * multiplier, inputs.shape)\n\n  def new_weights(self, input_signature):\n    d_feature = input_signature.shape[-1]\n    if sum(self._d_embs) != d_feature:\n      raise ValueError(\n          f\'sum(self._d_embs) != d_feature: \'\n          f\'sum({self._d_embs}) vs d_feature: {d_feature}\')\n\n    rngs = math.random.split(self.rng, len(self._d_embs))\n    weights = []\n    for ax, (ax_rng, d_emb) in enumerate(zip(rngs, self._d_embs)):\n      ax_shape = [1] * len(self._shape)\n      ax_shape[ax] = self._shape[ax]\n      ax_shape = (1,) + tuple(ax_shape) + (d_emb,)\n      ax_emb = self._kernel_initializer(ax_shape, ax_rng)\n      weights.append(ax_emb)\n\n    self.state = 0 if self._mode == \'predict\' else layer_base.EMPTY_STATE\n    return tuple(weights)\n\n\nclass FixedBasePositionalEncoding(layer_base.Layer):\n  """"""Implements fixed-base positional encoding.""""""\n\n  def __init__(self, bases=[11, 13, 14, 15], n_digits=8,  #  pylint: disable=dangerous-default-value\n               start_from_zero_one_in=100, base_dropout_one_in=100,\n               mode=\'train\', initializer=init.RandomUniformInitializer(1e-4)):\n    super(FixedBasePositionalEncoding, self).__init__()\n    self._bases = bases\n    self._n_digits = n_digits\n    self._mode = mode\n    self._initializer = initializer\n    self._start_from_zero_one_in = start_from_zero_one_in\n    self._base_dropout_one_in = base_dropout_one_in\n\n  def forward(self, x, weights):\n    rng = self.rng\n    batch_size, length = x.shape[0], x.shape[1]\n    max_pos = min(self._bases)**self._n_digits\n    rng1, rng2, rng3 = math.random.split(rng, 3)\n    assert length < max_pos, \'length (%d) >= max_pos (%d)\' % (length, max_pos)\n    positions = jnp.arange(0, length)[None, :]\n    if self._mode == \'train\':\n      # In 1% of training cases still start from 0 to be exactly as in eval.\n      start_from_nonzero = jax.random.randint(\n          rng1, (batch_size,), 0, self._start_from_zero_one_in)\n      start_from_nonzero = jnp.minimum(1, start_from_nonzero)\n      random_start = jax.random.randint(rng2, (batch_size,), 0, max_pos-length)\n      random_start *= start_from_nonzero\n      positions += random_start[:, None]\n    res = []\n    for bn, base in enumerate(self._bases):\n      pos_embeddings = []\n      cur_positions = positions\n      for i in range(self._n_digits):\n        cur_indices = jnp.mod(cur_positions, base)\n        cur_positions = cur_positions // base\n        s = weights[bn][i]\n        pos_embeddings.append(cur_indices.astype(jnp.float32)[:, :, None] * s)\n      embeddings = jnp.concatenate(pos_embeddings, axis=-1)\n      if self._mode == \'train\':\n        base_dropout = jax.random.randint(\n            rng3, (batch_size,), 0, self._base_dropout_one_in)\n        base_dropout = jnp.minimum(1, base_dropout).astype(jnp.float32)\n        embeddings *= base_dropout[:, None, None]\n      res.append(embeddings)\n    res = sum(res) + jnp.zeros_like(x)\n    return jnp.concatenate([x, res], axis=-1)\n\n  def new_weights(self, input_signature):\n    d_feature = input_signature.shape[-1]\n    assert d_feature % self._n_digits == 0\n    d_weight = d_feature // self._n_digits\n    return [[self._initializer((1, d_weight), rng)\n             for rng in math.random.split(self.rng, self._n_digits)]\n            for _ in self._bases]\n\n\ndef threefry_2x32_prf(key, x: jnp.ndarray) -> jnp.ndarray:\n  """"""Apply the threefry PRF to an array of inputs.\n\n  This function is vectorized over x.\n  For threefry_2x32: K = X = uint32[2]\n\n  Args:\n    key: uint32[2] the key of the PRF\n    x: uint32[..., 2] the inputs\n\n  Returns:\n    y: uint32[..., 2] the outputs\n  """"""\n  if not (key.shape == (2,) and key.dtype == jnp.uint32):\n    raise TypeError(\'key must be uint32[2]\', key)\n  if not (x.shape[-1:] == (2,) and x.dtype == jnp.uint32):\n    raise TypeError(\'x must be uint32[..., 2]\', x)\n  # Threefry-2x32 expects this weird format:\n  x_3f = jnp.moveaxis(x, source=-1, destination=0).flatten()\n  y_3f = jax.random.threefry_2x32(key, x_3f)\n  y = jnp.moveaxis(\n      jnp.reshape(y_3f, (2,) + x.shape[:-1]), source=0, destination=-1)\n  return y\n\n\ndef threefry_2x32_prange(key, lo: int = 0, hi: int = 2):\n  """"""Splits a key into a stream of random keys.\n\n  This uses the little-endian counter mode.\n\n  Args:\n    key: uint32[2] the key to split\n    lo: the range to start extracting from\n    hi: the range to stop extracting from\n\n  Returns:\n    keys: uint32[hi - lo, 2] the split keys\n  """"""\n  if not (key.shape == (2,) and key.dtype == jnp.uint32):\n    raise ValueError(\'key must be uint32[2]\')\n  if not hi < 2**32:\n    # You shouldn\'t really be using more than half the key size anyways.\n    raise NotImplementedError(\'only 32-bit sizes are supported\')\n  # Create a 64-bit counter:\n  i_lo = jnp.arange(lo, hi, dtype=jnp.uint32)\n  i_hi = jnp.zeros_like(i_lo)\n  i = jnp.stack([i_lo, i_hi], axis=-1)\n  return threefry_2x32_prf(key, i)\n\n\nclass InfinitePositionalEncoding(layer_base.Layer):\n  """"""Infinite positional encoding.""""""\n\n  def __init__(\n      self, drift=.03, affine=True, transform=\'any\',\n      time_bin_length=None,\n      mode=\'train\'):\n    """"""Initializes the encoding.\n\n    The encoding tries to roughly evenly traverse the latent space.\n    The recurrence time is dependent on how many bits per dimension you use.\n\n    There are two parameters to control randomization:\n    - randomizing the origin every 1/drift steps by letting it drift\n    - randomizing the origin per call\n\n    Args:\n      drift: variance in position difference per unit of difference\n      affine: whether to randomize the origin every call\n      transform: learnable transform after encoding (any/diag/none)\n      time_bin_length: Add features AxialPositionalEncoding learns if\n        TimeBinCausalAttention is the first layer.\n        bin_length should match TBCA.bin_length\n        If you set transform=\'diag\', this flag increases your model capacity to\n        close to transform=\'any\', though it will still train slower.\n      mode: if \'predict\', allow evaluating one token at a time\n    """"""\n    super().__init__()\n    if transform not in (\'any\', \'diag\', \'none\'):\n      raise ValueError(transform)\n    self._noise_rng = jax.random.split(jax.random.PRNGKey(234234535))[0]\n    assert self._noise_rng is not None\n    self._noise = None\n    self._drift = drift\n    self._affine = affine\n    self._transform = transform\n    self._time_bin_length = time_bin_length\n    self._mode = mode\n\n  def _get_noise(self, lo: int, hi: int, depth: int):\n    """"""Return pseudorandom noise with shape float[length, depth].\n\n    Args:\n      lo: where to start sampling\n      hi: where to stop sampling\n      depth: noise depth\n\n    Returns:\n      noise[lo:hi, :]: the noise, where noise.diff(axis=0) is i.i.d. U(-1,1)\n    """"""\n    if self._noise is None or self._noise.shape[0] < hi:\n      # Resize the noise:\n      new_length = 1\n      while new_length < hi:\n        new_length *= 2\n      noise = threefry_2x32_prange(self._noise_rng, 0, new_length * depth)\n      noise = noise.reshape((new_length, depth, 2))[:, :, 0]\n      # Normalize to [-sqrt(3), sqrt(3)]:\n      noise = noise.astype(jnp.float32) / 2**31 - 1\n      noise = noise * 3**.5\n      # TODO(tying): use multiscale noise for memory-efficient sampling\n      noise = noise.cumsum(axis=0)\n      self._noise = noise\n    assert self._noise.shape[0] >= hi\n    assert self._noise.shape[1] == depth\n    return self._noise[lo:hi, :]\n\n  def _get_embeddings(self, lo: int, hi: int, depth, rng=None):\n    """"""Get embeddings float[length, depth].\n\n    Args:\n      lo: where to start sampling\n      hi: where to stop sampling\n      depth: embedding depth\n      rng: rng for random phase\n\n    Returns:\n      embeddings: float[length, depth]\n    """"""\n    noise = self._get_noise(lo, hi, (depth + 1) // 2)\n    # Make the stddev around 1 after 1/drift.\n    noise = noise * self._drift**.5\n\n    t, c = np.mgrid[lo:hi, :depth]\n    # Make even channels cos, odd channels sin:\n    c_div_2, c_mod_2 = divmod(c, 2)\n    # Off-by-one correction for odd depth:\n    drift = self._drift\n    if depth > 2:\n      drift = drift**(((depth+1)//2)/(depth//2))\n    # Spend roughly half the frequencies on noise:\n    freq = jnp.geomspace(.5, .5 * drift**2, num=(depth + 1) // 2)[c_div_2]\n    cycles = c_mod_2 / 4 + freq * t + noise[:, c_div_2[0, :]] / 4\n    assert cycles.shape == (hi - lo, depth), cycles.shape\n\n    # Get random phases:\n    if self._affine:\n      assert rng is not None\n      cycles = cycles + trax.math.random.uniform(\n          rng, (1, depth,), minval=0, maxval=1)\n\n    # Convert from cycles to radians:\n    embeddings = jnp.cos(jnp.pi * 2 * cycles)\n\n    # Set the last channels to the time bin features:\n    if self._time_bin_length is not None:\n      inter_bin_idx, intra_bin_idx = divmod(t[:, -1:], self._time_bin_length)\n      bin_parity = inter_bin_idx % 2\n      bin_fraction = intra_bin_idx / self._time_bin_length\n      embeddings = jnp.concatenate(\n          [\n              embeddings[:, :-3],\n              1 / (1 + inter_bin_idx),\n              bin_fraction,\n              bin_parity.astype(jnp.float32),\n          ], -1)\n\n    assert embeddings.shape == (hi - lo, depth), embeddings.shape\n    return embeddings\n\n  def forward(self, inputs, weights):\n    rng, state = self.rng, self.state\n    d_feature = inputs.shape[-1]\n    input_len = inputs.shape[-2]\n\n    if self._mode == \'predict\':\n      # Assume all the positions are pretty close to each other.\n      index, predict_rng = state\n      lo = index.min()\n      hi = index.max() + 1\n      emb = self._get_embeddings(lo=lo, hi=hi, depth=d_feature, rng=predict_rng)\n      emb = emb[index - lo, jnp.newaxis, :]\n      index = index + 1\n      state = index, predict_rng\n    else:\n      emb = self._get_embeddings(lo=0, hi=input_len, depth=d_feature, rng=rng)\n      emb = emb[jnp.newaxis, :input_len, :]\n    # TODO(tying): check that XLA swaps matmul(slice(x)) -> slice(matmul(x)),\n    # or inline this code into get_embeddings/get_noise\n    if self._transform == \'diag\':\n      emb = emb * jax.nn.softplus(weights)\n    elif self._transform == \'any\':\n      emb = emb @ weights\n    self.state = state\n    return inputs + emb\n\n  def new_weights(self, input_signature):\n    d_feature = input_signature.shape[-1]\n    if self._transform == \'diag\':\n      # Initialize it to a small value because JAX has a bug in softplus.\n      scale_isoftplus = jnp.zeros((d_feature,), dtype=jnp.float32) + 1e-4\n      weights = scale_isoftplus\n    elif self._transform == \'any\':\n      ortho = trax.layers.initializers.OrthogonalInitializer()\n      weights = ortho((d_feature, d_feature), self.rng)\n    else:\n      weights = layer_base.EMPTY_WEIGHTS\n    if self._mode == \'predict\':\n      batch_size = input_signature.shape[0]\n      self.state = jnp.zeros((batch_size,), dtype=jnp.int32), self.rng\n    return weights\n\n\nclass TimeBinPositionalEncoding(layer_base.Layer):\n  """"""Just the engineered features from InfinitePositionalEncoding.""""""\n  num_features = 3\n\n  def __init__(self, time_bin_length, mode=\'train\'):\n    """"""Initializes the encoding.\n\n    Args:\n      time_bin_length: TimeBinCausalAttention.bin_length of the first layer.\n      mode: if \'predict\', allow evaluating one token at a time\n    """"""\n    super().__init__()\n    self._time_bin_length = time_bin_length\n    self._mode = mode\n\n  def _get_embeddings(self, t):\n    """"""Get embeddings float[..., num_features].\n\n    Args:\n      t: int[...] position (i.e. jnp.arange(..., jnp.int32))\n\n    Returns:\n      embeddings: float[..., num_features]\n    """"""\n    inter_bin_idx, intra_bin_idx = divmod(t, self._time_bin_length)\n    bin_parity = inter_bin_idx % 2\n    bin_fraction = intra_bin_idx / self._time_bin_length\n    embeddings = jnp.stack([\n        1 / (1 + inter_bin_idx),\n        bin_fraction,\n        bin_parity.astype(jnp.float32),\n    ], -1)\n\n    assert embeddings.shape == t.shape + (self.num_features,), embeddings.shape\n    return embeddings\n\n  def forward(self, inputs, weights):\n    state = self.state\n    depth = inputs.shape[-1]\n\n    if self._mode == \'predict\':\n      emb = self._get_embeddings(t=state)\n      emb = emb[:, jnp.newaxis, :]\n      state = state + 1\n    else:\n      input_len = inputs.shape[-2]\n      emb = self._get_embeddings(t=jnp.arange(input_len, dtype=jnp.int32))\n      # Leave batch axis as 1 for broadcasting:\n      emb = emb[jnp.newaxis, :, :]\n      emb = jnp.broadcast_to(emb, inputs.shape[:-1] + (3,))\n\n    # Replace the last num_features channels of input.\n    inputs = jnp.concatenate([inputs[..., :-self.num_features], emb], -1)\n    if inputs.shape[-1] > depth:\n      logging.warning(\n          \'dropping feature(s): %d down to %d\', inputs.shape[-1], depth)\n      inputs = inputs[..., -depth:]\n\n    assert inputs.shape[-1] == depth, inputs.shape\n    self.state = state\n    return inputs\n\n  def new_weights(self, input_signature):\n    if self._mode == \'predict\':\n      batch_size = input_signature.shape[0]\n      self.state = jnp.zeros((batch_size,), dtype=jnp.int32)\n    return layer_base.EMPTY_WEIGHTS\n'"
trax/layers/research/position_encodings_test.py,6,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for trax.layers.research.position_encodings.""""""\n\nimport functools\nimport absl.testing.absltest as unittest\nimport numpy as np\nimport parameterized\n\nfrom trax import math\nimport trax.layers.research.position_encodings as pe\n\n\n@parameterized.parameterized_class([\n    # {\'Encoding\': pe.FixedBasePositionalEncoding},\n    {\'Encoding\': pe.InfinitePositionalEncoding},\n    {\'Encoding\': functools.partial(\n        pe.InfinitePositionalEncoding, affine=False)},\n    {\'Encoding\': functools.partial(\n        pe.TimeBinPositionalEncoding, time_bin_length=5)},\n])\nclass PositionEncodingsTest(unittest.TestCase):\n  """"""Position encodings conform to the position encodings protocol.""""""\n\n  @parameterized.parameterized.expand([\n      (1, 100, 8),  # typical\n      (1, 1, 8),  # short\n      (1, 100, 1),  # narrow\n      (2, 100, 8),  # batched\n  ])\n  def test_training(self, n, t, c):\n    encoding = self.Encoding()\n    input_ntc = np.random.randn(n, t, c)\n    encoding.init(input_ntc)\n    output_ntc = encoding(input_ntc)\n    self.assertEqual(output_ntc.shape, input_ntc.shape)\n    self.assertTrue(np.not_equal(output_ntc, input_ntc).any())\n\n  @parameterized.parameterized.expand([\n      (1, 100, 8),  # typical\n      (1, 100, 1),  # narrow\n      (2, 100, 8),  # batched\n  ])\n  def test_inference(self, n, t, c):\n    # Get the eval mode outputs:\n    encoding = self.Encoding(mode=\'eval\')\n    input_ntc = np.random.randn(n, t, c)\n    rng = math.random.get_prng(1234)\n    encoding.init(input_ntc, rng=rng)\n    output_ntc = encoding(input_ntc)\n\n    is_random = self.Encoding == pe.InfinitePositionalEncoding\n\n    # Get the predict mode outputs:\n    encoding_pred = self.Encoding(mode=\'predict\')\n    encoding_pred.init(input_ntc[:, 0:1, :], rng=rng)\n    output_ntc0 = encoding_pred(input_ntc[:, 0:1, :])\n    if not is_random:\n      np.testing.assert_allclose(output_ntc0, output_ntc[:, 0:1, :], atol=1e-4)\n\n    output_ntc1 = encoding_pred(input_ntc[:, 1:2, :])\n    if not is_random:\n      np.testing.assert_allclose(output_ntc1, output_ntc[:, 1:2, :], atol=1e-4)\n\n    output_ntc2 = encoding_pred(input_ntc[:, 2:3, :])\n    if not is_random:\n      np.testing.assert_allclose(output_ntc2, output_ntc[:, 2:3, :], atol=1e-4)\n\n\nif __name__ == \'__main__\':\n  unittest.main()\n'"
trax/models/reformer/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n'"
trax/models/reformer/reformer.py,6,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Reformer Models.""""""\n\nimport jax\n\nfrom trax import layers as tl\nfrom trax import math\nfrom trax.layers.combinators import (  # pylint: disable=g-multiple-import\n    _split_rngs, _inputs_from_stack, _outputs_onto_stack)\nfrom trax.math import numpy as np\nfrom trax.math import random\n\n# TODO(afrozm): Move pvt fns here.\nfrom trax.models.transformer import (  # pylint: disable=g-multiple-import\n    _ConcatWithPadding, _MaskOfRightShiftedArray,\n    _StripFromConcatenateWithPadding)\n\n# Layers are always CamelCase, but functions in general are snake_case\n# pylint: disable=invalid-name\n\n\nclass BroadcastedDropout(tl.Layer):\n  """"""Layer constructor function for a broadcasted dropout layer.""""""\n\n  def __init__(self, rate=0.0, mode=\'train\', broadcast_dims=(-2,)):\n    super(BroadcastedDropout, self).__init__()\n    self._rate = rate\n    if self._rate >= 1.0:\n      raise ValueError(\'Dropout rate (%f) must be lower than 1.\' % rate)\n    self._broadcast_dims = broadcast_dims\n    self._mode = mode\n\n  def forward(self, x, weights):\n    """"""Dropout, with broadcasting to save memory.""""""\n    del weights\n    if self._mode == \'train\' and self._rate > 0.0:\n      noise_shape = list(x.shape)\n      for dim in self._broadcast_dims:\n        noise_shape[dim] = 1\n      keep_prob = jax.lax.tie_in(self.rng, 1.0 - self._rate)\n      keep = random.bernoulli(self.rng, keep_prob, tuple(noise_shape))\n      multiplier = keep.astype(x.dtype) / jax.lax.tie_in(keep, keep_prob)\n      return x * multiplier\n    else:\n      return x\n\n\ndef FeedForward(d_model, d_ff, dropout, activation, act_dropout, mode):\n  """"""Feed-forward block with layer normalization at start.""""""\n  if act_dropout is None:\n    act_dropout = dropout\n  return [\n      tl.LayerNorm(),\n      tl.Dense(d_ff),\n      BroadcastedDropout(rate=act_dropout, mode=mode),  # pylint: disable=no-value-for-parameter\n      activation(),\n      tl.Dense(d_model),\n      BroadcastedDropout(rate=dropout, mode=mode),  # pylint: disable=no-value-for-parameter\n  ]\n\n\ndef ChunkedFeedForward(d_model, d_ff, dropout, activation, act_dropout,\n                       chunk_size, mode):\n  """"""Chunked feed-forward block with layer normalization at start.""""""\n  ff = FeedForward(d_model, d_ff, dropout, activation, act_dropout, mode)\n  if chunk_size < 1:\n    return ff\n  def reshape_to_chunks(x):\n    batch_times_length = x.shape[0] * x.shape[1]\n    assert batch_times_length % chunk_size == 0\n    n_chunks = batch_times_length // chunk_size\n    return np.reshape(x, [n_chunks, 1, chunk_size] + list(x.shape[2:]))\n  return [\n      tl.Dup(),  # Just to have shape for later after scan.\n      tl.Fn(\'ReshapeToChunks\', reshape_to_chunks, n_out=1),\n      tl.Scan(tl.Serial(ff), axis=0, n_carry=0, remat=True),\n      tl.Fn(\'ReshapeXToY\', lambda x, y: np.reshape(x, y.shape))\n  ]\n\n\nclass ReversibleHalfResidualV2(tl.ReversibleLayer):\n  """"""Half of a RevNet-style residual that optionally performs attention.\n\n  When attention_layer is None, this layer has\n  the signature [accumulator, *context] -> [accumulator + f(context), *context].\n  The attention_layer must be an instance of EfficientAttentionBase or one of\n  its subclasses (see efficient_attention.py), or None.\n\n  Attention is special-cased for the following two reasons:\n  - LSH attention needs to save bucket assignments from the forward pass to the\n    backward pass, for training stability. This requires special-casing it.\n  - We can call attention_layer.forward_and_or_backward to compute its output\n    (needed for inverting a reversible residual layer) while simultaneously\n    performing the backward pass. Sharing computation between these two\n    operations improves training speed.\n  """"""\n\n  def __init__(self, *residual_layers, attention_layer=None):\n    super(ReversibleHalfResidualV2, self).__init__()\n\n    self.compute_residual = tl.Serial(*residual_layers)\n    self.attention_layer = attention_layer\n\n    if self.attention_layer is None:\n      self._sublayers = (self.compute_residual,)\n    else:\n      assert hasattr(attention_layer, \'forward_and_or_backward\')\n      self._sublayers = (self.compute_residual, self.attention_layer)\n\n    running_max = 0\n    running_total = 0\n    for layer in self._sublayers:\n      running_total += layer.n_in\n      running_max = max(running_max, running_total)\n      running_total -= layer.n_out\n    self._n_in = self._n_out = running_max + 1\n\n  def forward(self, xs, weights):\n    rngs = _split_rngs(self.rng, len(self.sublayers))\n    accumulator, *context = xs\n    stack = context = tuple(context)\n    new_state = []\n    for layer, w, s, rng in zip(self.sublayers, weights, self.state, rngs):\n      inputs = _inputs_from_stack(layer, stack)\n      outputs, s = layer.pure_fn(inputs, w, s, rng)\n      stack = _outputs_onto_stack(layer, outputs, stack)\n      new_state.append(s)\n    residual = stack[0] if isinstance(stack, (tuple, list)) else stack\n\n    output = accumulator + residual\n    stack = (output,) + context\n    self.state = new_state\n    return stack\n\n  def reverse(self, output, weights=(), state=(), new_state=(), rng=None):\n    raise NotImplementedError(\'Only reverse_and_grad is actually used.\')\n\n  def reverse_and_grad(self, output, ct, weights=(), state=(), new_state=(),\n                       rng=None):\n    rngs = _split_rngs(rng, len(self.sublayers))\n\n    accumulator_output, *context = output\n    context = tuple(context)\n    accumulator_output_ct, *context_ct = ct\n    context_ct = tuple(context_ct)\n\n    # Forward pass through self.compute_residual. Outputs that will not receive\n    # a gradient signal from subsequent layers are moved to aux.\n    def call_compute_residual(x, weights):\n      res, _ = self.compute_residual.pure_fn(\n          x, weights=weights, state=state[0], rng=rngs[0])\n      if not isinstance(res, (tuple, list)):\n        return res, None\n      else:\n        n_differentiable = 1\n        if self.attention_layer is not None:\n          n_differentiable = min(len(res), self.attention_layer.n_in)\n        return res[:n_differentiable], res[n_differentiable:]\n\n    stack = context\n    inputs = _inputs_from_stack(self.compute_residual, stack)\n    outputs, compute_residual_vjpfun, outputs_aux = jax.vjp(\n        call_compute_residual, inputs, weights[0], has_aux=True)\n    if outputs_aux is not None:\n      n_differentiable_outputs = len(outputs)\n      outputs = outputs + outputs_aux\n    stack = _outputs_onto_stack(self.compute_residual, outputs, stack)\n\n    stack_ct = accumulator_output_ct\n    if self.attention_layer is None:\n      residual = stack[0] if isinstance(stack, (tuple, list)) else stack\n    else:\n      inputs = _inputs_from_stack(self.attention_layer, stack)\n      (residual, _, attn_inputs_ct, attn_weights_ct\n      ) = self.attention_layer.forward_and_or_backward(\n          inputs, weights[1], new_state[1], rngs[1],\n          output_grad=accumulator_output_ct,\n          compute_output=True, update_state=False)\n      stack_ct = _outputs_onto_stack(\n          self.attention_layer, attn_inputs_ct, stack_ct,\n          self.attention_layer.n_out, self.attention_layer.n_in)\n\n    compute_residual_ct = _inputs_from_stack(\n        self.compute_residual, stack_ct, self.compute_residual.n_out)\n    if outputs_aux is not None:\n      if not isinstance(compute_residual_ct, (tuple, list)):\n        compute_residual_ct = (compute_residual_ct,)\n      compute_residual_ct = compute_residual_ct[:n_differentiable_outputs]\n      assert len(compute_residual_ct) == n_differentiable_outputs\n    (compute_residual_inputs_ct, compute_residual_weights_ct\n    ) = compute_residual_vjpfun(compute_residual_ct)\n    stack_ct = _outputs_onto_stack(\n        self.compute_residual, compute_residual_inputs_ct, stack_ct,\n        self.compute_residual.n_out, self.compute_residual.n_in)\n    if not isinstance(stack_ct, (tuple, list)):\n      stack_ct = (stack_ct,)\n    stack_ct = (accumulator_output_ct,) + math.nested_map_multiarg(\n        lambda x, y: x+y, context_ct[:len(stack_ct)], stack_ct\n        ) + context_ct[len(stack_ct):]\n\n    reconstructed_x = accumulator_output - residual\n    stack = (reconstructed_x,) + context\n    if self.attention_layer is None:\n      weights_ct = (compute_residual_weights_ct,)\n    else:\n      weights_ct = (compute_residual_weights_ct, attn_weights_ct)\n    return stack, (stack_ct, weights_ct)\n\n  # pylint: disable=protected-access\n  def new_weights(self, input_signature):\n    stack = input_signature[1:]\n    if len(stack) == 1:\n      stack = stack[0]\n\n    inputs = _inputs_from_stack(self.compute_residual, stack)\n    weights, state = self.compute_residual.init(inputs)\n    outputs, _ = self.compute_residual._forward_abstract(inputs)\n    stack = _outputs_onto_stack(self.compute_residual, outputs, stack)\n\n    if self.attention_layer is None:\n      self.state = (state,)\n      return (weights,)\n    else:\n      inputs = _inputs_from_stack(self.attention_layer, stack)\n      attn_weights, attn_state = self.attention_layer.init(inputs)\n      self.state = (state, attn_state)\n      return (weights, attn_weights)\n  # pylint: enable=protected-access\n\n\ndef DecoderBlock(d_model, d_ff, d_attention_key, d_attention_value,\n                 n_heads, attention_type,\n                 dropout, ff_activation, ff_use_sru, ff_chunk_size, mode):\n  """"""Reversible transformer decoder layer.\n\n  Args:\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    d_attention_key: int: depth of key vector for each attention head\n    d_attention_value: int: depth of value vector for each attention head\n    n_heads: int: number of attention heads\n    attention_type: subclass of tl.BaseCausalAttention: attention class to use\n    dropout: float: dropout rate (how much to drop out)\n    ff_activation: the non-linearity in feed-forward layer\n    ff_use_sru: int; if > 0, we use this many SRU layers instead of feed-forward\n    ff_chunk_size: int; if > 0, chunk feed-forward into this-sized chunks\n    mode: str: \'train\' or \'eval\'\n\n  Returns:\n    the layer.\n  """"""\n  attention = attention_type(\n      n_heads=n_heads, d_qk=d_attention_key, d_v=d_attention_value,\n      causal=True, output_dropout=dropout, mode=mode)\n  attention_half_residual = ReversibleHalfResidualV2(\n      tl.LayerNorm(),\n      attention_layer=attention,\n  )\n\n  if ff_use_sru:\n    feed_forward = [tl.SRU(d_model) for _ in range(ff_use_sru)]\n  else:\n    feed_forward = [ChunkedFeedForward(d_model, d_ff, dropout, ff_activation,\n                                       dropout, ff_chunk_size, mode)]\n\n  return [\n      attention_half_residual,\n      tl.ReversibleSwap(),\n      ReversibleHalfResidualV2(feed_forward),\n      tl.ReversibleSwap(),\n  ]\n\n\ndef ReformerLM(vocab_size,\n               d_model=512,\n               d_ff=2048,\n               d_attention_key=64,\n               d_attention_value=64,\n               n_layers=6,\n               n_heads=8,\n               dropout=0.1,\n               max_len=2048,\n               attention_type=tl.SelfAttention,\n               axial_pos_shape=(),\n               d_axial_pos_embs=None,\n               ff_activation=tl.FastGelu,\n               ff_use_sru=0,\n               ff_chunk_size=0,\n               mode=\'train\'):\n  """"""Reversible transformer language model (only uses a decoder, no encoder).\n\n  Args:\n    vocab_size: int: vocab size\n    d_model: int:  depth of *each half* of the two-part features\n    d_ff: int: depth of feed-forward layer\n    d_attention_key: int: depth of key vector for each attention head\n    d_attention_value: int: depth of value vector for each attention head\n    n_layers: int: number of decoder layers\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    max_len: int: maximum symbol length for positional encoding\n    attention_type: class: attention class to use, such as SelfAttention.\n    axial_pos_shape: tuple of ints: input shape to use for the axial position\n      encoding. If unset, axial position encoding is disabled.\n    d_axial_pos_embs: tuple of ints: depth of position embedding for each axis.\n      Tuple length must match axial_pos_shape, and values must sum to d_model.\n    ff_activation: the non-linearity in feed-forward layer\n    ff_use_sru: int; if > 0, we use this many SRU layers instead of feed-forward\n    ff_chunk_size: int; if > 0, chunk feed-forward into this-sized chunks\n    mode: str: \'train\', \'eval\', or \'predict\'\n\n  Returns:\n    the layer.\n  """"""\n  d_emb = d_model\n  if not axial_pos_shape:\n    positional_encoding = tl.PositionalEncoding(\n        max_len=max_len, dropout=dropout, mode=mode)\n  elif axial_pos_shape == \'fixed-base\':  # TODO(lukaszkaiser): remove this HACK\n    positional_encoding = tl.FixedBasePositionalEncoding(mode=mode)\n    d_emb //= 2\n  elif axial_pos_shape == \'infinite\':  # TODO(lukaszkaiser): remove this HACK\n    positional_encoding = tl.InfinitePositionalEncoding(affine=False)\n  elif axial_pos_shape == \'infinite-affine\':\n    # TODO(lukaszkaiser): remove this HACK\n    positional_encoding = tl.InfinitePositionalEncoding()\n  elif axial_pos_shape == \'time-bin\':  # TODO(lukaszkaiser): remove this HACK\n    positional_encoding = tl.TimeBinPositionalEncoding()\n  else:\n    assert d_axial_pos_embs is not None\n    positional_encoding = tl.AxialPositionalEncoding(\n        shape=axial_pos_shape, d_embs=d_axial_pos_embs,\n        dropout_broadcast_dims=tuple(range(1, len(axial_pos_shape) + 1)),\n        dropout=dropout, mode=mode)\n\n  positional_embedder = [\n      tl.Embedding(d_emb, vocab_size),\n      BroadcastedDropout(rate=dropout, mode=mode),  # pylint: disable=no-value-for-parameter\n      positional_encoding,\n  ]\n\n  decoder_blocks = []\n\n  if isinstance(attention_type, (tuple, list)):\n    assert n_layers % len(attention_type) == 0\n  else:\n    attention_type = [attention_type]\n  for layer_idx in range(n_layers):\n    layer_attention_type = attention_type[layer_idx % len(attention_type)]\n    decoder_block = DecoderBlock(\n        d_model, d_ff, d_attention_key, d_attention_value, n_heads,\n        attention_type=layer_attention_type,\n        dropout=dropout,\n        ff_activation=ff_activation,\n        ff_use_sru=ff_use_sru,\n        ff_chunk_size=ff_chunk_size,\n        mode=mode)\n    decoder_blocks.append(decoder_block)\n\n  return tl.Serial(\n      tl.ShiftRight(mode=mode),\n      positional_embedder,\n      tl.Dup(),\n      tl.ReversibleSerial(decoder_blocks),\n      tl.Concatenate(),\n      # TODO(kitaev): Test whether dropout should go before or after the\n      # LayerNorm, and whether dropout broadcasting is needed here.\n      tl.LayerNorm(),\n      BroadcastedDropout(rate=dropout, mode=mode),  # pylint: disable=no-value-for-parameter\n      tl.Dense(vocab_size),\n      tl.LogSoftmax(),\n  )\n\n\ndef ReformerShortenLM(vocab_size,\n                      shorten_factor=1,\n                      d_embedding=256,\n                      d_model=512,\n                      d_ff=2048,\n                      d_attention_key=64,\n                      d_attention_value=64,\n                      n_layers=6,\n                      n_heads=8,\n                      dropout=0.1,\n                      max_len=2048,\n                      attention_type=tl.SelfAttention,\n                      axial_pos_shape=(),\n                      d_axial_pos_embs=None,\n                      ff_activation=tl.FastGelu,\n                      ff_use_sru=0,\n                      ff_chunk_size=0,\n                      mode=\'train\'):\n  """"""Reversible transformer language model with shortening.\n\n  When shorten_factor is F and processing an input of shape [batch, length],\n  we embed the (shifted-right) input and then group each F elements (on length)\n  into a single vector -- so that in the end we process a tensor of shape\n    [batch, length // F, d_model]\n  almost until the end -- at the end it\'s un-shortend and a SRU is applied.\n  This reduces the length processed inside the main model body, effectively\n  making the model faster but possibly slightly less accurate.\n\n  Args:\n    vocab_size: int: vocab size\n    shorten_factor: by how much to shorten, see above\n    d_embedding: the depth of the embedding layer and final logits\n    d_model: int:  depth of *each half* of the two-part features\n    d_ff: int: depth of feed-forward layer\n    d_attention_key: int: depth of key vector for each attention head\n    d_attention_value: int: depth of value vector for each attention head\n    n_layers: int: number of decoder layers\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    max_len: int: maximum symbol length for positional encoding\n    attention_type: class: attention class to use, such as SelfAttention.\n    axial_pos_shape: tuple of ints: input shape to use for the axial position\n      encoding. If unset, axial position encoding is disabled.\n    d_axial_pos_embs: tuple of ints: depth of position embedding for each axis.\n      Tuple length must match axial_pos_shape, values must sum to d_embedding.\n    ff_activation: the non-linearity in feed-forward layer\n    ff_use_sru: int; if > 0, we use this many SRU layers instead of feed-forward\n    ff_chunk_size: int; if > 0, chunk feed-forward into this-sized chunks\n    mode: str: \'train\' or \'eval\'\n\n  Returns:\n    the layer.\n  """"""\n  assert mode != \'predict\'  # TODO(lukaszkaiser,kitaev): fast inference\n\n  if not axial_pos_shape:\n    positional_encoding = tl.PositionalEncoding(\n        max_len=max_len, dropout=dropout, mode=mode)\n  else:\n    assert d_axial_pos_embs is not None\n    positional_encoding = tl.AxialPositionalEncoding(\n        shape=axial_pos_shape, d_embs=d_axial_pos_embs,\n        dropout_broadcast_dims=tuple(range(1, len(axial_pos_shape) + 1)),\n        dropout=dropout, mode=mode)\n\n  positional_embedder = [\n      tl.Embedding(d_embedding, vocab_size),\n      BroadcastedDropout(rate=dropout, mode=mode),  # pylint: disable=no-value-for-parameter\n      positional_encoding,\n  ]\n\n  decoder_blocks = []\n\n  if isinstance(attention_type, (tuple, list)):\n    assert n_layers % len(attention_type) == 0\n  else:\n    attention_type = [attention_type]\n  for layer_idx in range(n_layers):\n    layer_attention_type = attention_type[layer_idx % len(attention_type)]\n    decoder_block = DecoderBlock(\n        d_model, d_ff, d_attention_key, d_attention_value, n_heads,\n        attention_type=layer_attention_type,\n        dropout=dropout,\n        ff_activation=ff_activation,\n        ff_use_sru=ff_use_sru,\n        ff_chunk_size=ff_chunk_size,\n        mode=mode)\n    decoder_blocks.append(decoder_block)\n\n  # pylint: disable=g-long-lambda\n  return tl.Serial(\n      tl.ShiftRight(),\n      positional_embedder,\n      tl.Dup(),              # Stack has (x, x), the first will be shortened\n      # Before shortening, we need to pad by shorten factor so as not to leak\n      # information into the future. To understand why, imagine shorten factor\n      # of 2 and sequence of length 4, so ABCD. If we shift just by 1, then we\n      # would have 0ABC, which gets grouped to [0A][BC] on input, which is\n      # predicting ABCD as targets. The problem is that [0A] has access to A\n      # and [BC] has access to C -- it will learn to copy it, peek into\n      # the future. Shifting twice to [00][AB] solves the problem as the first\n      # ""big"" symbol becomes all-0 and the rest is shifted enough.\n      tl.ShiftRight(n_shifts=shorten_factor - 1),\n      tl.Fn(\'Shorten\', lambda x: np.reshape(  # Shorten -- move to depth.\n          x, (x.shape[0], x.shape[1] // shorten_factor, -1)), n_out=1),\n      tl.Dense(d_model),\n      tl.Dup(),  # Stack has (short_x, short_x, x)\n      tl.ReversibleSerial(decoder_blocks),\n      tl.Select([0], n_in=2),\n      tl.LayerNorm(),\n      BroadcastedDropout(rate=dropout, mode=mode),  # pylint: disable=no-value-for-parameter\n      tl.Dense(shorten_factor * d_embedding),\n      tl.Fn(\'ProlongBack\', lambda x: np.reshape(  # Prolong back.\n          x, (x.shape[0], x.shape[1] * shorten_factor, -1)), n_out=1),\n      tl.Concatenate(),  # Concatenate with just the embeddings.\n      tl.CausalConv(d_embedding),\n      tl.Relu(),\n      tl.SRU(d_embedding),  # One RNN layer for conditional dependence.\n      tl.Dense(vocab_size),\n      tl.LogSoftmax()\n  )\n  # pylint: enable=g-long-lambda\n\n\ndef EncoderBlock(d_model, d_ff, n_heads, attention_type, dropout, ff_activation,\n                 ff_dropout, mode):\n  """"""Returns a list of layers that implements a Reformer encoder block.\n\n  The input to the layer is a pair, (activations, mask), where the mask was\n  created from the original source tokens to prevent attending to the padding\n  part of the input.\n\n  Args:\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    n_heads: int: number of attention heads\n    attention_type: subclass of tl.BaseCausalAttention: attention class to use\n    dropout: float: dropout rate (how much to drop out)\n    ff_activation: the non-linearity in feed-forward layer\n    ff_dropout: the dropout rate in feed-forward layer\n    mode: str: \'train\' or \'eval\'\n\n  Returns:\n    A list of layers that maps (activations, mask) to (activations, mask).\n  """"""\n  if mode == \'predict\':\n    # Mode \'predict\' means that the decoder should be run one token at a time.\n    # The encoder only ever runs over full sequences, which is why it\'s switched\n    # to \'eval\' mode instead.\n    mode = \'eval\'\n\n  attention = attention_type(\n      n_heads=n_heads, d_qk=d_model//n_heads, d_v=d_model//n_heads,\n      masked=True, causal=False,\n      attention_dropout=dropout, output_dropout=dropout,\n      mode=mode)\n  attention_half_residual = ReversibleHalfResidualV2(\n      tl.LayerNorm(),\n      attention_layer=attention,\n  )\n\n  feed_forward = FeedForward(\n      d_model, d_ff, dropout, ff_activation, ff_dropout, mode)\n\n  return [\n      attention_half_residual,\n      tl.ReversibleSwap(),\n      ReversibleHalfResidualV2(feed_forward),\n      tl.ReversibleSwap(),\n  ]\n\n\ndef EncoderDecoderBlock(d_model, d_ff, n_heads, dropout, ff_activation,\n                        ff_dropout, mode):\n  """"""Reversible transformer decoder layer.\n\n  Args:\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    ff_activation: the non-linearity in feed-forward layer\n    ff_dropout: float: (optional) separate dropout rate for feed-forward layer\n    mode: str: \'train\' or \'eval\'\n\n  Returns:\n    the layer.\n  """"""\n  enc_dec_attention = tl.EncDecAttention(\n      n_heads=n_heads, d_qk=d_model//n_heads, d_v=d_model//n_heads,\n      attention_dropout=dropout, output_dropout=dropout,\n      mode=mode)\n  enc_dec_attention_half_residual = ReversibleHalfResidualV2(\n      tl.LayerNorm(),\n      attention_layer=enc_dec_attention,\n  )\n\n  causal_attention = tl.SelfAttention(\n      n_heads=n_heads, d_qk=d_model//n_heads, d_v=d_model//n_heads,\n      causal=True,\n      attention_dropout=dropout, output_dropout=dropout,\n      mode=mode)\n  causal_attention_half_residual = ReversibleHalfResidualV2(\n      tl.LayerNorm(),\n      attention_layer=causal_attention,\n  )\n\n  feed_forward = FeedForward(\n      d_model, d_ff, dropout, ff_activation, ff_dropout, mode)\n\n  return [                             # vec_d1 vec_d2 vec_e masks\n      causal_attention_half_residual,\n      tl.ReversibleSwap(),\n      enc_dec_attention_half_residual,\n      tl.ReversibleSwap(),\n      ReversibleHalfResidualV2(feed_forward),\n      tl.ReversibleSwap(),\n  ]\n\n\ndef Reformer(input_vocab_size,\n             output_vocab_size=None,\n             d_model=512,\n             d_ff=2048,\n             n_encoder_layers=6,\n             n_decoder_layers=6,\n             n_heads=8,\n             dropout=0.1,\n             max_len=2048,\n             ff_activation=tl.Relu,\n             ff_dropout=None,\n             mode=\'train\'):\n  """"""Reversible transformer encoder-decoder model.\n\n  This model expects an input pair: target, source.\n\n  At the moment, this model supports dot-product attention only. For the\n  attention types in the Reformer paper, see ReformerLM.\n\n  Args:\n    input_vocab_size: int: vocab size of the source.\n    output_vocab_size: int (optional): vocab size of the target. If None, the\n      source and target are assumed to have the same vocab.\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    n_encoder_layers: int: number of encoder layers\n    n_decoder_layers: int: number of decoder layers\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    max_len: int: maximum symbol length for positional encoding\n    ff_activation: the non-linearity in feed-forward layer\n    ff_dropout: float: (optional) separate dropout rate at feed-forward\n      nonlinearity. This is called relu_dropout in T2T.\n    mode: str: \'train\' or \'eval\'\n\n  Returns:\n    A Reformer model as a layer that maps from a target, source pair to\n    activations over a vocab set.\n  """"""\n  # The current API for custom gradients assumes that a layer must be\n  # differentiable wrt all of its inputs, but the Transformer puts bool-dtype\n  # masks on the stack. This causes jax to error, even though the so-called\n  # ""gradient"" wrt the masks is never actually computed.\n  # TODO(kitaev): remove this hack.\n  jax.api._check_inexact_input_vjp = lambda x: None  # pylint: disable=protected-access\n\n  def PositionalEncoder(vocab_size, mode):  # tokens --> vectors\n    # TODO(kitaev): axial positional encoding is better for very long sequences.\n    positional_encoding = tl.PositionalEncoding(\n        max_len=max_len, dropout=dropout, mode=mode)\n    return [\n        tl.Embedding(d_model, vocab_size),\n        BroadcastedDropout(rate=dropout, mode=mode),\n        positional_encoding,\n    ]\n\n  # TODO(kitaev): The regular trax Transformer shares vocab embeddings and\n  # position embeddings between the encoder and decoder if output_vocab_size is\n  # None. This isn\'t supported here because (a) Trax shares weights by sharing\n  # layer instances, but we need two separate instances to have mode == \'eval\'\n  # for the encoder but mode == \'predict\' for the decoder; and (b) tl.Cache does\n  # not work if its sublayers participate in any weight sharing.\n\n  # Mode \'predict\' means that the decoder should be run one token at a time.\n  # The encoder only ever runs over full sequences, which is why it\'s switched\n  # to \'eval\' mode instead.\n  in_encoder = PositionalEncoder(\n      input_vocab_size, mode=\'eval\' if mode == \'predict\' else mode)\n  if output_vocab_size is None:\n    output_vocab_size = input_vocab_size\n  out_encoder = PositionalEncoder(output_vocab_size, mode)\n\n  # pylint: disable=g-complex-comprehension\n  encoder_blocks = [\n      EncoderBlock(\n          d_model, d_ff, n_heads, tl.SelfAttention, dropout, ff_activation,\n          ff_dropout, mode)\n      for _ in range(n_encoder_layers)]\n  # pylint: enable=g-complex-comprehension\n\n  encoder = tl.Serial([\n      in_encoder,\n      tl.Dup(),\n      tl.ReversibleSerial(encoder_blocks),\n      tl.Fn(\'XYAvg\', lambda x, y: (x + y) / 2.0),\n      tl.LayerNorm(),\n  ])\n  if mode == \'predict\':\n    encoder = tl.Cache(encoder)\n\n  encoder_decoder_blocks = [\n      EncoderDecoderBlock(\n          d_model, d_ff, n_heads, dropout, ff_activation, ff_dropout, mode)\n      for _ in range(n_decoder_layers)]\n\n  # Assemble and return the model.\n  return tl.Serial(\n      # Input: encoder_side_tokens, decoder_side_tokens\n      # Copy decoder tokens for use in loss.\n      tl.Select([0, 1, 1]),                 # tok_e tok_d tok_d\n      tl.Branch([], [tl.PaddingMask(),\n                     tl.Fn(\'Squeeze\',\n                           lambda x: np.squeeze(x, (1, 2)), n_out=1)]),\n      #                                     # tok_e mask  tok_d .....\n\n      # Encode.\n      encoder,                              # vec_e  mask tok_d .....\n\n      # Decode.\n      tl.Select([2, 0, 1]),                 # tok_d vec_e mask .....\n      tl.ShiftRight(mode=mode),             # tok_d vec_e mask .....\n      out_encoder,                          # vec_d vec_e mask .....\n      tl.Dup(),                             # vec_d1 vec_d2 vec_e mask .....\n      tl.ReversibleSerial(encoder_decoder_blocks),\n      tl.Fn(\'XYAvg\',\n            lambda x, y: (x + y) / 2.0),    # vec_d vec_e mask .....\n      tl.LayerNorm(),                       # vec_d vec_e mask .....\n\n      # Map to output vocab.\n      tl.Select([0], n_in=3),               # vec_d .....\n      tl.Dense(output_vocab_size),          # vec_d .....\n      tl.LogSoftmax(),                      # vec_d .....\n  )\n\n\ndef ReformerNoEncDecAttention(input_vocab_size,\n                              output_vocab_size=None,\n                              d_model=512,\n                              d_ff=2048,\n                              d_attention_key=64,\n                              d_attention_value=64,\n                              n_encoder_layers=6,\n                              n_decoder_layers=6,\n                              n_heads=8,\n                              dropout=0.1,\n                              max_len=2048,\n                              encoder_attention_type=tl.SelfAttention,\n                              encoder_decoder_attention_type=tl.SelfAttention,\n                              axial_pos_shape=(),\n                              d_axial_pos_embs=None,\n                              ff_activation=tl.Relu,\n                              ff_use_sru=0,\n                              ff_chunk_size=0,\n                              ff_dropout=None,\n                              mode=\'train\'):\n  """"""Reversible transformer encoder-decoder model.\n\n  This model expects an input pair: source, target.\n\n  At the moment, this model supports dot-product attention only. For the\n  attention types in the Reformer paper, see ReformerLM.\n\n  Args:\n    input_vocab_size: int: vocab size of the source.\n    output_vocab_size: int (optional): vocab size of the target. If None, the\n      source and target are assumed to have the same vocab.\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    d_attention_key: int: depth of key vector for each attention head\n    d_attention_value: int: depth of value vector for each attention head\n    n_encoder_layers: int: number of encoder layers\n    n_decoder_layers: int: number of decoder layers\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    max_len: int: maximum symbol length for positional encoding\n    encoder_attention_type: class: attention class to use, such as SelfAttention\n    encoder_decoder_attention_type: class: attention class to use, such as\n      SelfAttention\n    axial_pos_shape: tuple of ints: input shape to use for the axial position\n      encoding. If unset, axial position encoding is disabled.\n    d_axial_pos_embs: tuple of ints: depth of position embedding for each axis.\n      Tuple length must match axial_pos_shape, and values must sum to d_model.\n    ff_activation: the non-linearity in feed-forward layer\n    ff_use_sru: int; if > 0, we use this many SRU layers instead of feed-forward\n    ff_chunk_size: int; if > 0, chunk feed-forward into this-sized chunks\n    ff_dropout: float: (optional) separate dropout rate at feed-forward\n      nonlinearity. This is called relu_dropout in T2T.\n    mode: str: \'train\' or \'eval\'\n\n  Returns:\n    A Reformer model as a layer that maps from a target, source pair to\n    activations over a vocab set.\n  """"""\n  # The current API for custom gradients assumes that a layer must be\n  # differentiable wrt all of its inputs, but the Transformer puts bool-dtype\n  # masks on the stack. This causes jax to error, even though the so-called\n  # ""gradient"" wrt the masks is never actually computed.\n  # TODO(kitaev): remove this hack.\n  jax.api._check_inexact_input_vjp = lambda x: None  # pylint: disable=protected-access\n\n  def PositionalEncoder(vocab_size, mode):  # tokens --> vectors\n    if not axial_pos_shape:\n      positional_encoding = tl.PositionalEncoding(\n          max_len=max_len, dropout=dropout, mode=mode)\n    else:\n      assert d_axial_pos_embs is not None\n      positional_encoding = tl.AxialPositionalEncoding(\n          shape=axial_pos_shape, d_embs=d_axial_pos_embs,\n          dropout_broadcast_dims=tuple(range(1, len(axial_pos_shape) + 1)),\n          dropout=dropout, mode=mode)\n\n    return [\n        tl.Embedding(d_model, vocab_size),\n        BroadcastedDropout(rate=dropout, mode=mode),\n        positional_encoding,\n    ]\n\n  # TODO(kitaev): The regular trax Transformer shares vocab embeddings and\n  # position embeddings between the encoder and decoder if output_vocab_size is\n  # None. This isn\'t supported here because (a) Trax shares weights by sharing\n  # layer instances, but we need two separate instances to have mode == \'eval\'\n  # for the encoder but mode == \'predict\' for the decoder; and (b) tl.Cache does\n  # not work if its sublayers participate in any weight sharing.\n\n  # Mode \'predict\' means that the decoder should be run one token at a time.\n  # The encoder only ever runs over full sequences, which is why it\'s switched\n  # to \'eval\' mode instead.\n  in_encoder = PositionalEncoder(\n      input_vocab_size, mode=\'eval\' if mode == \'predict\' else mode)\n  if output_vocab_size is None:\n    output_vocab_size = input_vocab_size\n  out_encoder = PositionalEncoder(output_vocab_size, mode)\n\n  # pylint: disable=g-complex-comprehension\n  encoder_blocks = [\n      EncoderBlock(\n          d_model, d_ff, n_heads, encoder_attention_type, dropout,\n          ff_activation, ff_dropout, mode)\n      for _ in range(n_encoder_layers)]\n  # pylint: enable=g-complex-comprehension\n\n  encoder = tl.Serial([                # tok_e mask_e tok_e tok_d tok_d\n      in_encoder,                      # vec_e mask_e tok_e tok_d tok_d\n      tl.Dup(),                        # vec_e1 vec_e2 mask_e tok_e tok_d tok_d\n      tl.ReversibleSerial(encoder_blocks),\n      tl.Fn(\'XYAvg\', lambda x, y: (x + y) / 2.0),\n      tl.LayerNorm(),\n  ])\n  if mode == \'predict\':\n    encoder = tl.Cache(encoder)\n\n  decoder_blocks = []\n\n  if isinstance(encoder_decoder_attention_type, (tuple, list)):\n    assert n_decoder_layers % len(encoder_decoder_attention_type) == 0\n  else:\n    encoder_decoder_attention_type = [encoder_decoder_attention_type]\n  for layer_idx in range(n_decoder_layers):\n    layer_attention_type = encoder_decoder_attention_type[\n        layer_idx % len(encoder_decoder_attention_type)]\n    decoder_block = DecoderBlock(\n        d_model, d_ff, d_attention_key, d_attention_value, n_heads,\n        attention_type=layer_attention_type,\n        dropout=dropout,\n        ff_activation=ff_activation,\n        ff_use_sru=ff_use_sru,\n        ff_chunk_size=ff_chunk_size,\n        mode=mode)\n    decoder_blocks.append(decoder_block)\n\n  # Assemble and return the model.\n  return tl.Serial(\n      # Input: encoder_side_tokens, decoder_side_tokens\n      # Copy decoder tokens for use in loss.\n      tl.Select([0, 0, 1, 1]),                  # tok_e tok_e tok_d tok_d\n      tl.Branch([], [tl.PaddingMask(),\n                     tl.Fn(\'Squeeze\',\n                           lambda x: np.squeeze(x, (1, 2)), n_out=1)]),\n      #                                         # tok_e mask_e tok_e tok_d tok_d\n\n      # Encode.\n      encoder,                                  # vec_e mask_e tok_e tok_d tok_d\n\n      # Decode.\n      tl.Select([3, 0, 1, 2]),                 #  tok_d vec_e mask_e tok_e tok_d\n      tl.ShiftRight(mode=mode),                # stok_d vec_e mask_e tok_e tok_d\n      tl.Branch(\n          [],\n          _MaskOfRightShiftedArray()\n      ),                                # stok_d mask_d vec_e mask_e tok_e tok_d\n      out_encoder,                      # svec_d mask_d vec_e mask_e tok_e tok_d\n\n      # Concat encoder and decoder, given their masks.\n      tl.Select([2, 0, 3, 1]),          # svec_d mask_d vec_e mask_e tok_e tok_d\n      _ConcatWithPadding(),                        # vec_ed tok_e tok_d\n\n      # Run (encoder and) decoder blocks.\n      tl.Dup(),                                    # vec_ed1 vec_ed2 tok_e tok_d\n      tl.ReversibleSerial(decoder_blocks),         # vec_ed1 vec_ed2 tok_e tok_d\n      tl.Fn(\'XYAvg\',\n            lambda x, y: (x + y) / 2.0),           # vec_ed tok_e tok_d\n      tl.LayerNorm(),                              # vec_ed tok_e tok_d\n\n      # Separate out the encoder part from the concatenated vector.\n      tl.Select([0, 1, 2, 2]),                     # vec_ed tok_e tok_d tok_d\n      _StripFromConcatenateWithPadding(),          # vec_d tok_d\n\n      # Map to output vocab.\n      tl.Dense(output_vocab_size),                 # vec_d tok_d\n      tl.LogSoftmax(),                             # vec_d tok_d\n  )\n'"
trax/models/reformer/reformer_e2e_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""End to end test for Reformer.""""""\n\nimport contextlib\nimport os\nimport tempfile\n\nfrom absl.testing import absltest\nimport gin\nfrom tensorflow.compat.v1 import test\nfrom tensorflow.compat.v1.io import gfile\n\nimport trax\nfrom trax.models.reformer import reformer  # pylint: disable=unused-import\nfrom trax.supervised import trainer_lib\n\npkg_dir, _ = os.path.split(__file__)\n_TESTDATA = os.path.join(pkg_dir, \'testdata\')\n_CONFIG_DIR = os.path.join(pkg_dir, \'../../configs/\')\n\n\nclass ReformerE2ETest(absltest.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    gin.clear_config()\n\n  @contextlib.contextmanager\n  def tmp_dir(self):\n    tmp = tempfile.mkdtemp(dir=test.get_temp_dir())\n    yield tmp\n    gfile.rmtree(tmp)\n\n  def test_reformer_wmt_ende(self):\n    trax.math.disable_jit()\n\n    batch_size_per_device = 2\n    steps = 1\n    n_layers = 2\n    d_ff = 32\n\n    gin.parse_config_file(os.path.join(_CONFIG_DIR, \'reformer_wmt_ende.gin\'))\n\n    gin.bind_parameter(\'data_streams.data_dir\', _TESTDATA)\n    gin.bind_parameter(\'batcher.batch_size_per_device\', batch_size_per_device)\n    gin.bind_parameter(\'train.steps\', steps)\n    gin.bind_parameter(\'Reformer.n_encoder_layers\', n_layers)\n    gin.bind_parameter(\'Reformer.n_decoder_layers\', n_layers)\n    gin.bind_parameter(\'Reformer.d_ff\', d_ff)\n\n    with self.tmp_dir() as output_dir:\n      _ = trainer_lib.train(output_dir=output_dir)\n\n  def test_reformer_noencdecattn_wmt_ende(self):\n    trax.math.disable_jit()\n\n    batch_size_per_device = 1  # Ignored, but needs to be set.\n    steps = 1\n    n_layers = 2\n    d_ff = 32\n\n    gin.parse_config_file(os.path.join(_CONFIG_DIR,\n                                       \'reformer_noencdecattn_wmt_ende.gin\'))\n\n    gin.bind_parameter(\'data_streams.data_dir\', _TESTDATA)\n    gin.bind_parameter(\'batcher.batch_size_per_device\', batch_size_per_device)\n    gin.bind_parameter(\'batcher.buckets\', ([513], [1, 1]))  # batch size 1.\n    gin.bind_parameter(\'train.steps\', steps)\n    gin.bind_parameter(\'ReformerNoEncDecAttention.n_encoder_layers\', n_layers)\n    gin.bind_parameter(\'ReformerNoEncDecAttention.n_decoder_layers\', n_layers)\n    gin.bind_parameter(\'ReformerNoEncDecAttention.d_ff\', d_ff)\n\n    with self.tmp_dir() as output_dir:\n      _ = trainer_lib.train(output_dir=output_dir)\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/models/reformer/reformer_memory_test.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Test for memory usage in Reformer models.\n\nThis test is designed to run on TPUv3 hardware, processing 1 million tokens at a\ntime while just barely fitting within the 16 GB memory budget.\n""""""\n\nimport functools\n\nfrom absl.testing import absltest\n\nimport jax\nfrom jax import numpy as jnp\nfrom jax import test_util  # pylint: disable=unused-import\nfrom jax.config import config\n\nimport numpy as np\n\nfrom trax import layers as tl\nfrom trax import math\nfrom trax import shapes\nfrom trax.models.reformer import reformer\n\n\nclass ReformerMemoryTest(absltest.TestCase):\n\n  def test_reformer_lm_memory(self):\n    lsh_self_attention = functools.partial(\n        tl.LSHSelfAttention,\n        attention_dropout=0.0,\n        chunk_len=64,\n        n_buckets=[128, 128],\n        n_chunks_after=0,\n        n_chunks_before=1,\n        n_hashes=1,\n        n_parallel_heads=1,\n        predict_drop_len=128,\n        predict_mem_len=1024,\n    )\n    timebin_self_attention = functools.partial(\n        tl.SelfAttention,\n        attention_dropout=0.05,\n        chunk_len=64,\n        n_chunks_before=1,\n        n_parallel_heads=1,\n    )\n\n    model = reformer.ReformerLM(\n        vocab_size=256,\n        d_model=256,\n        d_ff=512,\n        d_attention_key=64,\n        d_attention_value=64,\n        n_layers=6,\n        n_heads=2,\n        dropout=0.05,\n        max_len=1048576,\n        attention_type=[timebin_self_attention, lsh_self_attention],\n        axial_pos_shape=(1024, 1024),\n        d_axial_pos_embs=(64, 192),\n        ff_activation=tl.Relu,\n        ff_use_sru=0,\n        ff_chunk_size=131072,\n        mode=\'train\',\n    )\n    x = np.ones((1, 1048576)).astype(np.int32)\n    weights, state = model.init(shapes.signature(x))\n\n    @jax.jit\n    def mock_training_step(x, weights, state, rng):\n      def compute_mock_loss(weights):\n        logits, new_state = model.pure_fn(x, weights, state, rng)\n        loss = jnp.mean(logits[..., 0])\n        return loss, (new_state, logits)\n      gradients, (new_state, logits) = jax.grad(\n          compute_mock_loss, has_aux=True)(weights)\n      new_weights = math.nested_map_multiarg(\n          lambda w, g: w - 1e-4 * g, weights, gradients)\n      return new_weights, new_state, logits\n\n    weights, state, logits = mock_training_step(\n        x, weights, state, jax.random.PRNGKey(0))\n    self.assertEqual(logits.shape, (1, 1048576, 256))\n\n\nif __name__ == \'__main__\':\n  config.config_with_absl()\n  absltest.main()\n'"
trax/models/reformer/reformer_oom_test.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for OOM for ReformerNoEncDecAttention .""""""\n\nimport functools\nimport operator\n\nfrom absl.testing import absltest\nimport gin\nimport numpy as np\n\nfrom trax import layers as tl\nfrom trax import math\nfrom trax import shapes\nfrom trax.models.reformer import reformer\n\n\nclass ReformerOOMTest(absltest.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    gin.clear_config()\n\n  def _lsh_self_attention_fn(self):\n    return functools.partial(\n        tl.LSHSelfAttention,\n        attention_dropout=0.0,\n        chunk_len=64,\n        n_buckets=[32, 32],\n        n_chunks_after=0,\n        n_chunks_before=1,\n        n_hashes=1,\n        n_parallel_heads=1,\n        predict_drop_len=128,\n        predict_mem_len=1024,\n    )\n\n  def test_reformer_no_enc_dec_attention_one_step(self):\n    d_model = 1024\n    vocab_size = 14041\n    max_len = 16384\n    axial_pos = (128, 128)  # should multiply to max_len\n    d_axial_pos_embs = (512, 512)  # sum to d model\n\n    assert operator.mul(*axial_pos) == max_len\n    assert sum(d_axial_pos_embs) == d_model\n\n    d_ff = 4096\n    n_heads = 8\n    d_attn = d_model // n_heads\n\n    n_buckets = 128\n    encoder_chunk_len = (2 * max_len) // n_buckets  # 256\n    decoder_chunk_len = 2 * encoder_chunk_len       # 512\n    encoder_n_chunks_after = 1                      # since its not causal.\n\n    lsh_self_attention = functools.partial(self._lsh_self_attention_fn(),\n                                           n_buckets=n_buckets)\n\n    encoder_lsh_self_attention = functools.partial(\n        lsh_self_attention, n_chunks_after=encoder_n_chunks_after,\n        chunk_len=encoder_chunk_len)\n\n    decoder_lsh_self_attention = functools.partial(\n        lsh_self_attention, n_chunks_after=0,\n        chunk_len=decoder_chunk_len)\n\n    model = reformer.ReformerNoEncDecAttention(\n        vocab_size,\n        d_model=d_model,\n        d_ff=d_ff,\n        d_attention_key=d_attn,\n        d_attention_value=d_attn,\n        n_encoder_layers=1,\n        n_decoder_layers=1,\n        n_heads=n_heads,\n        dropout=0.05,\n        max_len=max_len,\n        encoder_attention_type=encoder_lsh_self_attention,\n        encoder_decoder_attention_type=decoder_lsh_self_attention,\n        axial_pos_shape=axial_pos,\n        d_axial_pos_embs=d_axial_pos_embs,\n        ff_activation=tl.Relu,\n        ff_use_sru=0,\n        mode=\'train\',\n    )\n\n    def random_sentence():\n      return np.random.randint(low=1, high=vocab_size - 1, size=(1, max_len),\n                               dtype=np.int32)\n\n    x = [random_sentence(), random_sentence()]\n    weights, state = model.init(shapes.signature(x))\n\n    @math.jit\n    def mock_training_step(x, weights, state, rng):\n      def compute_mock_loss(weights):\n        logits_and_dec_toks, new_state = model.pure_fn(x, weights, state, rng)\n        # This returns [logits, decoder tokens]\n        logits = logits_and_dec_toks[0]\n        loss = math.numpy.mean(logits[..., 0])\n        return loss, (new_state, logits)\n      gradients, (new_state, logits) = math.grad(\n          compute_mock_loss, has_aux=True)(weights)\n      new_weights = math.nested_map_multiarg(\n          lambda w, g: w - 1e-4 * g, weights, gradients)\n      return new_weights, new_state, logits\n\n    weights, state, logits = mock_training_step(\n        x, weights, state, math.random.get_prng(0))\n\n    self.assertEqual(logits.shape, (1, max_len, vocab_size))\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/models/reformer/reformer_test.py,5,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for Reformer models.""""""\n\nimport functools\n\nfrom absl.testing import absltest\nimport gin\nimport numpy as np\n\nfrom trax import layers as tl\nfrom trax import math\nfrom trax import shapes\nfrom trax.models.reformer import reformer\n\n\nclass ReformerTest(absltest.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    gin.clear_config()\n\n  def _lsh_self_attention_fn(self):\n    return functools.partial(\n        tl.LSHSelfAttention,\n        attention_dropout=0.0,\n        chunk_len=64,\n        n_buckets=[32, 32],\n        n_chunks_after=0,\n        n_chunks_before=1,\n        n_hashes=1,\n        n_parallel_heads=1,\n        predict_drop_len=128,\n        predict_mem_len=1024,\n    )\n\n  def _timebin_self_attention_fn(self):\n    return functools.partial(\n        tl.SelfAttention,\n        attention_dropout=0.05,\n        chunk_len=64,\n        n_chunks_before=1,\n        n_parallel_heads=1,\n    )\n\n  def test_reformer_lm_forward_shape(self):\n    vocab_size = 16\n    model = reformer.ReformerLM(\n        vocab_size, d_model=32, d_ff=64, d_attention_key=16,\n        d_attention_value=16, n_layers=1, n_heads=2, max_len=16)\n    xs = [np.ones((1, 8)).astype(np.int32),\n          np.ones((1, 8)).astype(np.int32)]\n    _, _ = model.init(shapes.signature(xs))\n    ys = model(xs)\n    self.assertEqual([y.shape for y in ys], [(1, 8, 16), (1, 8)])\n\n  def test_reformer_lm_lsh(self):\n    lsh_self_attention = self._lsh_self_attention_fn()\n    timebin_self_attention = self._timebin_self_attention_fn()\n\n    model = reformer.ReformerLM(\n        vocab_size=256,\n        d_model=256,\n        d_ff=512,\n        d_attention_key=64,\n        d_attention_value=64,\n        n_layers=2,\n        n_heads=2,\n        dropout=0.05,\n        max_len=65536,\n        attention_type=[timebin_self_attention, lsh_self_attention],\n        axial_pos_shape=(256, 256),\n        d_axial_pos_embs=(64, 192),\n        ff_activation=tl.Relu,\n        ff_use_sru=0,\n        ff_chunk_size=8192,\n        mode=\'train\',\n    )\n    x = np.ones((1, 65536)).astype(np.int32)\n    weights, state = model.init(shapes.signature(x))\n\n    @math.jit\n    def mock_training_step(x, weights, state, rng):\n      def compute_mock_loss(weights):\n        logits, new_state = model.pure_fn(x, weights, state, rng)\n        loss = math.numpy.mean(logits[..., 0])\n        return loss, (new_state, logits)\n      gradients, (new_state, logits) = math.grad(\n          compute_mock_loss, has_aux=True)(weights)\n      new_weights = math.nested_map_multiarg(\n          lambda w, g: w - 1e-4 * g, weights, gradients)\n      return new_weights, new_state, logits\n\n    weights, state, logits = mock_training_step(\n        x, weights, state, math.random.get_prng(0))\n    self.assertEqual(logits.shape, (1, 65536, 256))\n\n  def test_reformer_no_enc_dec_attention_one_step(self):\n    vocab_size = 256\n    max_len = 65536\n    axial_pos = 256\n    assert axial_pos * axial_pos == max_len\n\n    chunk_len = 64\n\n    # Since 2 * chunk_len * n_buckets should be max_len.\n    n_buckets = max_len // (2 * chunk_len)\n\n    lsh_self_attention = functools.partial(self._lsh_self_attention_fn(),\n                                           chunk_len=chunk_len,\n                                           n_buckets=n_buckets)\n\n    timebin_self_attention = self._timebin_self_attention_fn()\n\n    model = reformer.ReformerNoEncDecAttention(\n        vocab_size,\n        d_model=256,\n        d_ff=512,\n        d_attention_key=64,\n        d_attention_value=64,\n        n_encoder_layers=2,\n        n_decoder_layers=2,\n        n_heads=2,\n        dropout=0.05,\n        max_len=max_len,\n        encoder_attention_type=lsh_self_attention,\n        encoder_decoder_attention_type=[timebin_self_attention,\n                                        lsh_self_attention],\n        axial_pos_shape=(axial_pos, axial_pos),\n        d_axial_pos_embs=(64, 192),\n        ff_activation=tl.Relu,\n        ff_use_sru=0,\n        ff_chunk_size=8192,\n        mode=\'train\',\n    )\n\n    x = [np.ones((1, max_len)).astype(np.int32),\n         np.ones((1, max_len)).astype(np.int32)]\n    weights, state = model.init(shapes.signature(x))\n\n    @math.jit\n    def mock_training_step(x, weights, state, rng):\n      def compute_mock_loss(weights):\n        logits_and_dec_toks, new_state = model.pure_fn(x, weights, state, rng)\n        # This returns [logits, decoder tokens]\n        logits = logits_and_dec_toks[0]\n        loss = math.numpy.mean(logits[..., 0])\n        return loss, (new_state, logits)\n      gradients, (new_state, logits) = math.grad(\n          compute_mock_loss, has_aux=True)(weights)\n      new_weights = math.nested_map_multiarg(\n          lambda w, g: w - 1e-4 * g, weights, gradients)\n      return new_weights, new_state, logits\n\n    weights, state, logits = mock_training_step(\n        x, weights, state, math.random.get_prng(0))\n\n    self.assertEqual(logits.shape, (1, max_len, vocab_size))\n\n\nif __name__ == \'__main__\':\n  absltest.main()\n'"
trax/models/research/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n'"
trax/models/research/bert.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""BERT.""""""\n\nimport jax\nimport tensorflow as tf\n\nfrom trax import layers as tl\nfrom trax import math\nfrom trax.math import numpy as np\n\n# pylint: disable=invalid-name\n\n\nclass AddBias(tl.Layer):\n\n  def forward(self, inputs, weights):\n    x = inputs\n    return x + weights\n\n  def new_weights(self, input_signature, rng):\n    del rng\n    return np.zeros(input_signature.shape[-1])\n\n\ndef BERTClassifierHead(n_classes):\n  return tl.Serial([\n      tl.Select([0], n_in=2),\n      tl.Dense(n_classes,\n               kernel_initializer=tl.RandomNormalInitializer(0.02),\n               bias_initializer=tl.RandomNormalInitializer(1e-6),\n              ),\n      tl.LogSoftmax(),\n  ])\n\n\ndef BERTRegressionHead():\n  return tl.Serial([\n      tl.Select([0], n_in=2),\n      tl.Dense(1,\n               kernel_initializer=tl.RandomNormalInitializer(0.02),\n               bias_initializer=tl.RandomNormalInitializer(1e-6),\n              ),\n  ])\n\n\n# TODO(kitaev): regression head, masked LM head\n\n\ndef BERT(d_model=768,\n         vocab_size=30522,\n         max_len=512,\n         type_vocab_size=2,\n         n_heads=12,\n         d_ff=3072,\n         n_layers=12,\n         head=None,\n         init_checkpoint=None,\n         mode=\'eval\',\n        ):\n  """"""BERT (default hparams are for bert-base-uncased).""""""\n  layer_norm_eps = 1e-12\n  d_head = d_model // n_heads\n\n  word_embeddings = tl.Embedding(d_model, vocab_size)\n  type_embeddings = tl.Embedding(d_model, type_vocab_size)\n  position_embeddings = tl.PositionalEncoding(max_len, mode=mode)\n  embeddings = [\n      tl.Select([0, 1, 0], n_in=3),  # Drops \'idx\' input.\n      tl.Parallel(\n          word_embeddings,\n          type_embeddings,\n          [tl.PaddingMask(),\n           tl.Fn(\'Squeeze\', lambda x: np.squeeze(x, (1, 2)), n_out=1)]\n      ),\n      tl.Add(),\n      position_embeddings,\n      tl.LayerNorm(epsilon=layer_norm_eps),\n  ]\n\n  encoder = []\n  for _ in range(n_layers):\n    attn = tl.SelfAttention(n_heads=n_heads, d_qk=d_head, d_v=d_head,\n                            bias=True, masked=True, mode=mode)\n    feed_forward = [\n        tl.Dense(d_ff),\n        tl.Gelu(),\n        tl.Dense(d_model)\n    ]\n    encoder += [\n        tl.Select([0, 1, 1]),  # Save a copy of the mask\n        tl.Residual(attn, AddBias()),  # pylint: disable=no-value-for-parameter\n        tl.LayerNorm(epsilon=layer_norm_eps),\n        tl.Residual(*feed_forward),\n        tl.LayerNorm(epsilon=layer_norm_eps),\n    ]\n\n  encoder += [tl.Select([0], n_in=2)]  # Drop the mask\n\n  pooler = [\n      tl.Fn(\'\', lambda x: (x[:, 0, :], x), n_out=2),\n      tl.Dense(d_model),\n      tl.Tanh(),\n  ]\n\n  init_checkpoint = init_checkpoint if mode == \'train\' else None\n  bert = PretrainedBERT(\n      embeddings + encoder + pooler, init_checkpoint=init_checkpoint)\n\n  if head is not None:\n    bert = tl.Serial(bert, head())\n\n  return bert\n\n\nclass PretrainedBERT(tl.Serial):\n  """"""Wrapper that always initializes weights from a pre-trained checkpoint.""""""\n\n  def __init__(self, *sublayers, init_checkpoint=None):\n    super().__init__(*sublayers)\n\n    # TODO(kitaev): Support shorthand model names in the trax OSS release\n    if init_checkpoint == \'bert-base-uncased\':\n      raise NotImplementedError(\n          \'Please manually specify the path to bert_model.ckpt\')\n    self.init_checkpoint = init_checkpoint\n\n  def new_weights(self, input_signature):\n    weights = super().new_weights(input_signature)\n    if self.init_checkpoint is None:\n      return weights\n\n    print(\'Loading pre-trained weights from\', self.init_checkpoint)\n    ckpt = tf.train.load_checkpoint(self.init_checkpoint)\n\n    def reshape_qkv(name):\n      x = ckpt.get_tensor(name)\n      return x.reshape((x.shape[0], -1, 64)).swapaxes(0, 1)\n    def reshape_o(name):\n      x = ckpt.get_tensor(name)\n      return x.reshape((-1, 64, x.shape[-1]))\n    def reshape_bias(name):\n      x = ckpt.get_tensor(name)\n      return x.reshape((-1, 64))\n\n    new_w = [\n        ckpt.get_tensor(\'bert/embeddings/word_embeddings\'),\n        ckpt.get_tensor(\'bert/embeddings/token_type_embeddings\'),\n        ckpt.get_tensor(\'bert/embeddings/position_embeddings\')[None, ...],\n        ckpt.get_tensor(\'bert/embeddings/LayerNorm/gamma\'),\n        ckpt.get_tensor(\'bert/embeddings/LayerNorm/beta\'),\n    ]\n\n    for i in range(12):  # 12 layers\n      new_w += [\n          reshape_qkv(f\'bert/encoder/layer_{i}/attention/self/query/kernel\'),\n          reshape_qkv(f\'bert/encoder/layer_{i}/attention/self/key/kernel\'),\n          reshape_qkv(f\'bert/encoder/layer_{i}/attention/self/value/kernel\'),\n          reshape_o(f\'bert/encoder/layer_{i}/attention/output/dense/kernel\'),\n          reshape_bias(f\'bert/encoder/layer_{i}/attention/self/query/bias\'),\n          reshape_bias(f\'bert/encoder/layer_{i}/attention/self/key/bias\'),\n          reshape_bias(f\'bert/encoder/layer_{i}/attention/self/value/bias\'),\n          ckpt.get_tensor(\n              f\'bert/encoder/layer_{i}/attention/output/dense/bias\'),\n          ckpt.get_tensor(\n              f\'bert/encoder/layer_{i}/attention/output/LayerNorm/gamma\'),\n          ckpt.get_tensor(\n              f\'bert/encoder/layer_{i}/attention/output/LayerNorm/beta\'),\n          ckpt.get_tensor(f\'bert/encoder/layer_{i}/intermediate/dense/kernel\'),\n          ckpt.get_tensor(f\'bert/encoder/layer_{i}/intermediate/dense/bias\'),\n          ckpt.get_tensor(f\'bert/encoder/layer_{i}/output/dense/kernel\'),\n          ckpt.get_tensor(f\'bert/encoder/layer_{i}/output/dense/bias\'),\n          ckpt.get_tensor(f\'bert/encoder/layer_{i}/output/LayerNorm/gamma\'),\n          ckpt.get_tensor(f\'bert/encoder/layer_{i}/output/LayerNorm/beta\'),\n      ]\n\n    new_w += [\n        ckpt.get_tensor(\'bert/pooler/dense/kernel\'),\n        ckpt.get_tensor(\'bert/pooler/dense/bias\'),\n    ]\n\n    for a, b in zip(math.tree_leaves(weights), new_w):\n      assert a.shape == b.shape, (\n          f\'Expected shape {a.shape}, got shape {b.shape}\')\n    weights = jax.tree_unflatten(jax.tree_structure(weights), new_w)\n    move_to_device = jax.jit(lambda x: x)\n    weights = jax.tree_map(move_to_device, weights)\n    return weights\n'"
trax/models/research/skipping_transformer.py,2,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Layer-Skipping Transformer Models.""""""\n\nfrom trax import layers as tl\nfrom trax import math\nfrom trax.layers.combinators import _inputs_from_stack\nfrom trax.layers.combinators import _outputs_onto_stack\nfrom trax.layers.combinators import _split_rngs\nfrom trax.math import numpy as np\nfrom trax.math import random\nfrom trax.models import transformer\n\n\nclass SkippingSerial(tl.Serial):\n  """"""Serial combinator that also skips layers.""""""\n\n  def __init__(self, *sublayers, **kwargs):\n    super(SkippingSerial, self).__init__(*sublayers)\n    self._mode = kwargs.get(\'mode\', \'train\')\n    # Parameters for skipping: how many steps to warm-up, how often to skip.\n    self._skipping_warmup_steps = kwargs.get(\'skipping_warmup_steps\', 20000)\n    self._skip_fraction = kwargs.get(\'skip_fraction\', 0.4)\n    # Ensure that each layer has the same number of inputs and outputs.\n    if self.sublayers:\n      n_in_out = self.sublayers[0].n_in\n      for layer in self.sublayers:\n        assert layer.n_in == n_in_out\n        assert layer.n_out == n_in_out\n\n  def new_weights(self, input_signature):\n    """"""Add a step-counter to the state. Initialize with 0.""""""\n    weights = super(SkippingSerial, self).new_weights(input_signature)\n    self.state = (0, self.state)\n    return weights\n\n  @tl.Layer.state.setter\n  def state(self, state):\n    """"""Recursively sets non-param state on this layer and all sublayers.""""""\n    self._state = state\n    n_layers = self._n_layers\n    if n_layers != 1 and len(state[1]) != n_layers:\n      raise ValueError(\n          f\'Number of state elements ({len(state[1])}) does not equal \'\n          f\'number of sublayers ({n_layers}).\')\n    for layer, sublayer_state in zip(self.sublayers, state[1]):\n      if sublayer_state is not tl.GET_STATE_FROM_CACHE:\n        layer.state = sublayer_state\n\n  def forward(self, xs, weights):\n    self._validate_forward_inputs(xs)\n    (step, layers_state) = self.state\n    # Get N+1 rngs, N for running layers and one extra.\n    rngs = _split_rngs(self.rng, self._n_layers + 1)\n    rng0, rngs = rngs[0], rngs[1:]\n    if not self.sublayers:  # No-op: leave args unchanged.\n      self.state = (step + 1, layers_state)\n      return xs\n\n    # Prepare the stack and do some safety checks as in the parent class.\n    stack = xs\n    new_state = []\n    n_layers = self._n_layers\n    if n_layers != 1 and len(weights) != n_layers:\n      raise ValueError(\'number of weights ({}) not equal to number of layers \'\n                       \'({})\'.format(len(weights), n_layers))\n    if n_layers != 1 and len(layers_state) != n_layers:\n      raise ValueError(\'length of state ({}) not equal to number of layers \'\n                       \'({})\'.format(len(layers_state), n_layers))\n\n    # TODO(chowdhery): try different strategies, also try running not all\n    # layers backwards by using math.stop_gradient where needed.\n\n    # Calculate how many layers to run forward.\n    if self._mode == \'train\':\n      # warmup goes from 1.0 at start to 0.0 at skipping_warmup_steps and after\n      w_steps = float(self._skipping_warmup_steps)\n      warmup = np.maximum(0.0, (w_steps - step.astype(np.float32)) / w_steps)\n      # low is the minimum number of layers to *not* skip, from n_layers to 0\n      low = warmup * float(n_layers)\n      # high should be so that (high - n_layers) / high = 1.0 - skip_fraction\n      # because (high - n_layers) / high is the probability we\'re not skipping\n      # (after warmup); so high - n_layers = high - high * skip_fraction\n      high = float(n_layers) / self._skip_fraction\n      # We want the same rng0 on all cores.\n      if math.device_count() > 1:\n        rng0 = math.psum(rng0, \'batch\')\n      n_forward_layers = random.uniform(rng0, (), np.float32, low, high)\n    else:\n      n_forward_layers = float(n_layers)\n    # Run layers skipping after a certain number.\n    cur_layer_idx = 0.0\n    for layer, p, s, rng in zip(self.sublayers, weights, layers_state, rngs):\n      inputs = _inputs_from_stack(layer, stack)\n      outputs, s = math.cond(  # Skip (do identity) if > n_forward_layers.\n          pred=(math.lt(cur_layer_idx, n_forward_layers)),\n          true_operand=(inputs, p, s, rng),  # This tuple is t below.\n          true_fun=(lambda t: layer.pure_fn(t[0], t[1], t[2], t[3])),  # pylint: disable=cell-var-from-loop\n          false_operand=(inputs, p, s, rng),\n          false_fun=(lambda t: (t[0], t[2])),  # return (inputs, state)\n      )\n      stack = _outputs_onto_stack(layer, outputs, stack)\n      new_state.append(s)\n      cur_layer_idx += 1.0\n    self.state = (step + 1, new_state)\n    return stack\n\n\ndef SkippingTransformerLM(vocab_size,\n                          d_model=512,\n                          d_ff=2048,\n                          n_layers=6,\n                          n_heads=8,\n                          dropout=0.1,\n                          max_len=2048,\n                          mode=\'train\',\n                          ff_activation=tl.Relu):\n  """"""Returns a Skipping Transformer language model.\n\n  The input to the model is a tensor of tokens. (This model uses only the\n  decoder part of the overall Transformer.)\n\n  Args:\n    vocab_size: int: vocab size\n    d_model: int:  depth of embedding\n    d_ff: int: depth of feed-forward layer\n    n_layers: int: number of encoder/decoder layers\n    n_heads: int: number of attention heads\n    dropout: float: dropout rate (how much to drop out)\n    max_len: int: maximum symbol length for positional encoding\n    mode: str: \'train\', \'eval\' or \'predict\', predict mode is for fast inference\n    ff_activation: the non-linearity in feed-forward layer\n\n  Returns:\n    A Transformer language model as a layer that maps from a tensor of tokens\n    to activations over a vocab set.\n  """"""\n  embedder = [\n      tl.Embedding(d_model, vocab_size),\n      tl.Dropout(rate=dropout, name=\'embedding\', mode=mode),\n      tl.PositionalEncoding(max_len=max_len, mode=mode),\n  ]\n\n  return tl.Serial(\n      tl.ShiftRight(mode=mode),\n      embedder,\n      SkippingSerial([\n          transformer._DecoderBlock(  # pylint: disable=g-complex-comprehension,protected-access\n              d_model, d_ff, n_heads, dropout, i, mode, ff_activation)\n          for i in range(n_layers)], mode=mode),\n      tl.LayerNorm(),\n      tl.Dense(vocab_size),\n      tl.LogSoftmax(),\n  )\n'"
trax/rl/envs/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Environments defined in RL.""""""\n\nimport gin\nfrom gym.envs.registration import register\n\nfrom trax.rl.envs import online_tune_env\nfrom trax.rl.envs import online_tune_rl_env\n\n\n# Ginify and register in gym.\ndef configure_and_register_env(env_class):\n  register(\n      id=\'{}-v0\'.format(env_class.__name__),\n      entry_point=\'trax.rl.envs:{}\'.format(env_class.__name__),\n  )\n  return gin.external_configurable(env_class, module=\'trax.rl.envs\')\n\n\n# pylint: disable=invalid-name\nOnlineTuneEnv = configure_and_register_env(online_tune_env.OnlineTuneEnv)\nOnlineTuneRLEnv = configure_and_register_env(online_tune_rl_env.OnlineTuneRLEnv)\n'"
trax/rl/envs/async_trajectory_collector.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""A trajectory collector that polls on policy files and keeps collecting trajectories.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport multiprocessing\nimport os\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\nimport gin\nimport jax\nfrom jax.config import config\nfrom tensor2tensor.envs import env_problem_utils\nimport tensorflow as tf\nfrom trax import rl  # pylint: disable=unused-import\nfrom trax.rl import envs as rl_envs  # pylint: disable=unused-import\nfrom trax.rl.envs import async_trajectory_collector_lib as async_lib\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_multi_string(\'config_file\', None,\n                          \'Configuration file with parameters (.gin).\')\nflags.DEFINE_multi_string(\'config\', None,\n                          \'Configuration parameters (gin string).\')\nflags.DEFINE_bool(\'use_tpu\', False, ""Whether we\'re running on TPU."")\nflags.DEFINE_bool(\'xm\', False, \'Copy atari roms?\')\n\nflags.DEFINE_bool(\n    \'try_abort\', True,\n    \'Should we try to abort a trajectory collection if a newer \'\n    \'policy is available.\')\n\nflags.DEFINE_string(\'output_dir\', \'\', \'Output dir.\')\nflags.DEFINE_string(\'envs_output_dir\', \'\', \'Output dir for the envs.\')\n\nflags.DEFINE_boolean(\n    \'jax_debug_nans\', False,\n    \'Setting to true will help to debug nans and disable jit.\')\nflags.DEFINE_boolean(\'disable_jit\', False, \'Setting to true will disable jit.\')\n\nflags.DEFINE_boolean(\'parallelize_envs\', False,\n                     \'If true, sets parallelism to number of cpu cores.\')\n\nflags.DEFINE_integer(\'replica\', 0, \'Basically to append to trajectory name.\')\nflags.DEFINE_bool(\'enable_eager_execution\', False, \'\')\n\nflags.DEFINE_integer(\n    \'max_trajectories_to_collect\', -1,\n    \'-1 for infinite, otherwise whatever number was specified.\')\n\n\n# TODO(afrozm): This code snippet is strewn across many places, unify it.\ndef initialize_gin():\n  gin_configs = FLAGS.config or []\n  gin.parse_config_files_and_bindings(FLAGS.config_file, gin_configs)\n\n\ndef get_output_dir():\n  """"""Return output_dir.""""""\n  output_dir = FLAGS.output_dir\n  return output_dir\n\n\ndef update_jax_config():\n  """"""Update JAX config based on flags.""""""\n\n  if FLAGS.jax_debug_nans:\n    config.update(\'jax_debug_nans\', True)\n\n  if FLAGS.use_tpu:\n    config.update(\'jax_platform_name\', \'tpu\')\n  else:\n    config.update(\'jax_platform_name\', \'\')\n\n\n@gin.configurable(blacklist=[\n    \'output_dir\',\n])\ndef create_envs_and_collect_trajectories(\n    output_dir,\n    env_name=\'OnlineTuneEnv-v0\',\n    max_timestep=None,\n    clip_rewards=False,\n    rendered_env=False,\n    resize_dims=(105, 80),\n):\n  """"""Creates the envs and continuously collects trajectories.""""""\n\n\n  train_batch_size = 1\n  eval_batch_size = 1\n\n  # TODO(pkozakowski): Find a better way to determine this.\n  train_env_kwargs = {}\n  eval_env_kwargs = {}\n  if \'OnlineTuneEnv\' in env_name:\n    envs_output_dir = FLAGS.envs_output_dir or os.path.join(output_dir, \'envs\')\n    train_env_output_dir = os.path.join(envs_output_dir, \'train\')\n    eval_env_output_dir = os.path.join(envs_output_dir, \'eval\')\n    train_env_kwargs = {\'output_dir\': train_env_output_dir}\n    eval_env_kwargs = {\'output_dir\': eval_env_output_dir}\n\n  parallelism = multiprocessing.cpu_count() if FLAGS.parallelize_envs else 1\n  train_parallelism = min(train_batch_size, parallelism)\n  eval_parallelism = min(eval_batch_size, parallelism)\n\n  train_env = env_problem_utils.make_env(\n      batch_size=train_batch_size,\n      env_problem_name=env_name,\n      resize=rendered_env,\n      resize_dims=resize_dims,\n      max_timestep=max_timestep,\n      clip_rewards=clip_rewards,\n      parallelism=train_parallelism,\n      use_tpu=FLAGS.use_tpu,\n      **train_env_kwargs)\n  assert train_env\n\n  eval_env = env_problem_utils.make_env(\n      batch_size=eval_batch_size,\n      env_problem_name=env_name,\n      resize=rendered_env,\n      resize_dims=resize_dims,\n      max_timestep=max_timestep,\n      clip_rewards=clip_rewards,\n      parallelism=eval_parallelism,\n      use_tpu=FLAGS.use_tpu,\n      **eval_env_kwargs)\n  assert eval_env\n\n  def run_collect_loop():\n    async_lib.continuously_collect_trajectories(\n        output_dir,\n        train_env,\n        eval_env,\n        trajectory_dump_dir=None,\n        env_id=FLAGS.replica,\n        try_abort=FLAGS.try_abort,\n        max_trajectories_to_collect=(None\n                                     if FLAGS.max_trajectories_to_collect < 0\n                                     else FLAGS.max_trajectories_to_collect))\n\n  if FLAGS.jax_debug_nans or FLAGS.disable_jit:\n    with jax.disable_jit():\n      run_collect_loop()\n  else:\n    run_collect_loop()\n\n\ndef main(argv):\n  del argv\n\n  if FLAGS.enable_eager_execution:\n    tf.enable_eager_execution()\n\n  logging.info(\'Initializing Gin.\')\n  initialize_gin()\n\n  logging.info(\'Update JAX config.\')\n  update_jax_config()\n\n  logging.info(\'Getting output_dir\')\n  output_dir = get_output_dir()\n  logging.info(\'Got output_dir = %s\', output_dir)\n\n  logging.info(\'Starting Trajectory collection.\')\n  create_envs_and_collect_trajectories(output_dir)\n\n\nif __name__ == \'__main__\':\n  app.run(main)\n'"
trax/rl/envs/async_trajectory_collector_lib.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Uitlity functions for the async trajectory collector.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport random\nimport time\n\nfrom absl import logging\nfrom tensor2tensor.envs import trajectory\nfrom tensorflow.compat.v1.io import gfile\nfrom trax.rl import policy_based_utils\nfrom trax.rl import trainers as rl_trainers\n\nLARGE_MAX_TRIES_FOR_POLICY_FILE = 100\n\n\n# TODO(afrozm): Is there a better way to poll for a file on CNS?\ndef get_newer_policy_model_file(output_dir,\n                                min_epoch=-1,\n                                sleep_time_secs=0.1,\n                                max_sleep_time_secs=1.0,\n                                max_tries=1,\n                                wait_forever=False,):\n  """"""Gets a policy model file subject to availability and wait time.""""""\n\n  while max_tries or wait_forever:\n    max_tries -= 1\n    policy_files = policy_based_utils.get_policy_model_files(output_dir)\n\n    def do_wait(t):\n      time.sleep(t)\n      t *= 2\n      return min(t, max_sleep_time_secs)\n\n    # No policy files at all.\n    if not policy_files:\n      logging.info(\'There are no policy files in [%s], waiting for %s secs.\',\n                   output_dir, sleep_time_secs)\n      sleep_time_secs = do_wait(sleep_time_secs)\n      continue\n\n    # Check if we have a newer epoch.\n    policy_file = policy_files[0]\n    epoch = policy_based_utils.get_epoch_from_policy_model_file(policy_file)\n\n    # We don\'t - wait.\n    if epoch <= min_epoch:\n      logging.info(\'epoch [%s] <= min_epoch [%s], waiting for %s secs.\', epoch,\n                   min_epoch, sleep_time_secs)\n      sleep_time_secs = do_wait(sleep_time_secs)\n      continue\n\n    # We do have a new file, return it.\n    policy_file = policy_files[0]\n    epoch = policy_based_utils.get_epoch_from_policy_model_file(policy_file)\n    logging.info(\'Found epoch [%s] and policy file [%s]\', epoch, policy_file)\n    return policy_file, epoch\n\n  # Exhausted our waiting limit.\n  return None\n\n\ndef dump_trajectory(output_dir, epoch, env_id, temperature, random_string,\n                    trajs):\n  """"""Write the trajectory to disk.""""""\n\n  assert 1 == len(trajs)\n  traj = trajs[0]\n\n  trajectory_file_name = trajectory.TRAJECTORY_FILE_FORMAT.format(\n      epoch=epoch, env_id=env_id, temperature=temperature, r=random_string)\n\n  with gfile.GFile(os.path.join(output_dir, trajectory_file_name), \'w\') as f:\n    trajectory.get_pickle_module().dump(traj, f)\n\n\ndef continuously_collect_trajectories(output_dir,\n                                      train_env,\n                                      eval_env,\n                                      trajectory_dump_dir=None,\n                                      env_id=None,\n                                      max_trajectories_to_collect=None,\n                                      try_abort=True):\n  """"""Instantiates a PPO trainer and collects trajectories.""""""\n\n  # Make the PPO trainer.\n  ppo_trainer = rl_trainers.PPO(\n      output_dir=output_dir,\n      train_env=train_env,\n      eval_env=eval_env,\n      trajectory_dump_dir=trajectory_dump_dir,\n  )\n\n  # TODO(afrozm): Update base_trainer interface to support SimPLe as well.\n  assert isinstance(ppo_trainer, rl_trainers.PPO)\n\n  assert env_id is not None\n\n  # Get an initial policy and wait a forever to get it if needed.\n  policy_and_epoch = get_newer_policy_model_file(output_dir, wait_forever=True)\n  assert policy_and_epoch\n  policy_file, epoch = policy_and_epoch\n  logging.info(\'Read initial policy for epoch [%s] -> [%s]\', epoch, policy_file)\n\n  # Returns immediately if there is a newer epoch available.\n  def is_newer_policy_file_available(epoch_, sleep_time_secs_=0.1):\n    return get_newer_policy_model_file(\n        output_dir, min_epoch=epoch_, sleep_time_secs=sleep_time_secs_)\n\n  # Does a __done__ file exist?\n  def done_file_exists():\n    return gfile.exists(os.path.join(output_dir, \'__done__\'))\n\n  assert 1 == train_env.batch_size\n  assert 1 == eval_env.batch_size\n\n  temperature = 1.0\n\n  trajectories_collected = 0\n\n  train_env_trajectory_dump_dir = os.path.join(output_dir, \'trajectories/train\')\n  eval_env_trajectory_dump_dir = os.path.join(output_dir, \'trajectories/eval\')\n\n  gfile.makedirs(train_env_trajectory_dump_dir)\n  gfile.makedirs(eval_env_trajectory_dump_dir)\n\n  while max_trajectories_to_collect is None or trajectories_collected < int(\n      max_trajectories_to_collect):\n    logging.info(\'Collecting a trajectory, trajectories_collected = %s\',\n                 trajectories_collected)\n\n    # Abort function -- if something newever is available, then abort the\n    # current computation and reload.\n\n    # Useful if env.step is long.\n    def long_abort_fn():\n      # We want this to be as quick as possible.\n      return (is_newer_policy_file_available(epoch, 0) is not None) or (\n          done_file_exists())\n\n    abort_fn = long_abort_fn if try_abort else None\n\n    # Collect a training trajectory.\n    trajs, n_done, unused_timing_info, unused_model_state = (\n        ppo_trainer.collect_trajectories(train=True,\n                                         temperature=temperature,\n                                         abort_fn=abort_fn,\n                                         raw_trajectory=True))\n\n    if done_file_exists():\n      logging.info(\'__done__ file found in %s, we are done here.\', output_dir)\n      break\n\n    if trajs and n_done > 0:\n      assert 1 == n_done\n      trajectories_collected += n_done\n\n      # Write the trajectory down.\n      logging.info(\n          \'Dumping the collected trajectory, trajectories_collected = %s\',\n          trajectories_collected)\n      dump_trajectory(train_env_trajectory_dump_dir, epoch, env_id, temperature,\n                      str(random.randint(0, 2**31 - 1)), trajs)\n    else:\n      logging.info(\'Computation was aborted, a new policy is available.\')\n\n    # This maybe useless, since `abort_fn` will take care of it. We might want\n    # to have this here if abort_fn is False always.\n    # Do we have a newer policy?\n    policy_file_and_epoch = is_newer_policy_file_available(epoch)\n    if policy_file_and_epoch is None:\n      # Continue churning out these policies.\n      logging.info(""We don\'t have a newer policy, continuing with the old one."")\n      continue\n\n    # We have a newer policy, read it and update the parameters.\n    policy_file, epoch = policy_file_and_epoch\n    logging.info(\n        \'We have a newer policy epoch [%s], file [%s], updating parameters.\',\n        epoch, policy_file)\n    ppo_trainer.update_optimization_state(output_dir)\n    logging.info(\'Parameters of PPOTrainer updated.\')\n\n    # Check that the epochs match.\n    assert epoch == ppo_trainer.epoch\n'"
trax/rl/envs/async_trajectory_collector_lib_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow import test\nfrom tensorflow.compat.v1.io import gfile\nfrom trax.rl import policy_based_utils\nfrom trax.rl.envs import async_trajectory_collector_lib as async_lib\n\n\nclass AsyncTrajectoryCollectorLibTest(test.TestCase):\n\n  def test_get_newer_policy_model_file(self):\n    output_dir = self.get_temp_dir()\n\n    def write_policy_model_file(epoch):\n      fname = policy_based_utils.get_policy_model_file_from_epoch(\n          output_dir, epoch\n      )\n      with gfile.GFile(fname, \'w\') as f:\n        f.write(\'some data\')\n      return fname\n\n    # No file exists currently.\n    self.assertIsNone(async_lib.get_newer_policy_model_file(output_dir))\n\n    # Write a policy model file.\n    epoch = 0\n    policy_model_filename = write_policy_model_file(epoch)\n\n    # See that we get it.\n    actual_policy_file, actual_epoch = (\n        async_lib.get_newer_policy_model_file(output_dir, min_epoch=-1))\n\n    self.assertEqual(actual_policy_file, policy_model_filename)\n    self.assertEqual(actual_epoch, epoch)\n\n    # If we now ask for a larger epoch, we don\'t get it.\n    self.assertIsNone(\n        async_lib.get_newer_policy_model_file(output_dir, min_epoch=0))\n\n    # Write a newer epoch and expect to get that with appropriate min_epoch.\n    epoch = 1\n    policy_model_filename = write_policy_model_file(epoch)\n    actual_policy_file, actual_epoch = (\n        async_lib.get_newer_policy_model_file(output_dir, min_epoch=0))\n    self.assertEqual(actual_policy_file, policy_model_filename)\n    self.assertEqual(actual_epoch, epoch)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/envs/fake_env.py,1,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""A fake gym environment.\n\nCan specify either:\n1. A done action, i.e. the action on which the environment returns done.\n2. A done time-step, i.e. the time step at which the environment returns done.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport gym\nimport numpy as np\n\n\nclass FakeEnv(gym.Env):\n  """"""A fake env which is either done with a specific action or a time-step.""""""\n\n  def __init__(self,\n               input_shape=(4,),\n               n_actions=2,\n               n_controls=1,\n               done_time_step=None,\n               done_action=None):\n    self._input_shape = input_shape\n    self._done_time_step = done_time_step\n    self._done_action = done_action\n    self._t = 0\n    if n_controls == 1:\n      self.action_space = gym.spaces.Discrete(n_actions)\n    else:\n      self.action_space = gym.spaces.MultiDiscrete([n_actions] * n_controls)\n    self.observation_space = gym.spaces.Box(\n        low=-1.0, high=1.0, shape=input_shape)\n\n  def _get_random_observation(self):\n    return np.random.random(self._input_shape)\n\n  def reset(self):\n    self._t = 0\n    return self._get_random_observation()\n\n  def step(self, action):\n    assert self.action_space.contains(action)\n    done = False\n    if self._done_action is not None:\n      done = action == self._done_action\n    elif self._done_time_step is not None:\n      done = self._t == self._done_time_step\n\n    reward = -1.0 if not done else 1.0\n    self._t += 1\n    return self._get_random_observation(), reward, done, {}\n'"
trax/rl/envs/fake_env_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.rl.fake_env.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom tensorflow import test\nfrom trax.rl.envs import fake_env\n\n\nclass FakeEnvTest(test.TestCase):\n\n  def test_done_action(self):\n    env = fake_env.FakeEnv(input_shape=(2, 3),\n                           n_actions=10,\n                           done_time_step=None,\n                           done_action=9)\n    env.reset()\n\n    # Actions 0 to 8\n    for action in range(9):\n      _, reward, done, _ = env.step(action)\n      self.assertFalse(done)\n      self.assertEqual(-1.0, reward)\n\n    _, reward, done, _ = env.step(9)\n    self.assertTrue(done)\n    self.assertEqual(1.0, reward)\n\n  def test_done_time_step(self):\n    env = fake_env.FakeEnv(input_shape=(2, 3),\n                           n_actions=10,\n                           done_time_step=10,\n                           done_action=None)\n    env.reset()\n\n    # Take 10 steps.\n    for _ in range(10):\n      _, reward, done, _ = env.step(0)\n      self.assertFalse(done)\n      self.assertEqual(-1.0, reward)\n\n    # Take final time-step, this is the time-step numbered 10 since time-steps\n    # are 0 indexed.\n    _, reward, done, _ = env.step(0)\n    self.assertTrue(done)\n    self.assertEqual(1.0, reward)\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/envs/online_tune.py,5,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Utility functions for OnlineTuneEnv.""""""\n\nimport math\nimport numpy as np\n\n\nLEARNING_RATE_METRIC = (\'train\', \'training/learning_rate\')\n\n\ndef historical_metric_values(\n    history, metric, observation_range=(-math.inf, math.inf)):\n  """"""Converts a metric stream from a trax History object into a numpy array.""""""\n  # Use math.inf rather than np.inf in default value to help Sphinx autodoc.\n  metric_sequence = history.get(*metric)\n  metric_values = np.array([\n      metric_value for (_, metric_value) in metric_sequence\n  ])\n  return np.clip(metric_values, *observation_range)\n\n\ndef history_to_observations(history, metrics, observation_range, include_lr):\n  """"""Converts a trax History object into a sequence of observations.""""""\n  observation_dimensions = [\n      historical_metric_values(history, metric, observation_range)\n      for metric in metrics\n  ]\n  if include_lr:\n    # Logartihm of the learning rate.\n    observation_dimensions.append(np.log(historical_metric_values(\n        history, LEARNING_RATE_METRIC, observation_range\n    )))\n  return np.stack(observation_dimensions, axis=1)\n\n\ndef new_learning_rate(action, history, action_multipliers, max_lr):\n  """"""Calculates a new learning rate based on an action.""""""\n  learning_rates = historical_metric_values(history, LEARNING_RATE_METRIC)\n  assert learning_rates.shape[0] > 0, \'No last learning rate found in history.\'\n  current_lr = learning_rates[-1]\n  return min(current_lr * action_multipliers[action], max_lr)\n'"
trax/rl/envs/online_tune_env.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""An environment for tuning model hyperparameters during training.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nimport os\n\nimport gym\nimport tensorflow as tf\nfrom trax import layers\nfrom trax import models as trax_models\nfrom trax import optimizers as trax_opt\nfrom trax.rl import online_tune\nfrom trax.supervised import inputs as trax_inputs\nfrom trax.supervised import trainer_lib\n\n\nclass OnlineTuneEnv(gym.Env):\n  """"""An environment for tuning model hyperparameters during training.\n\n  A rollout is one instance of training a specific model on a specific problem.\n  Observations are the values of some evaluation metric. Actions control\n  hyperparameter changes during training. Reward is the change of the evaluation\n  metric. One environment step corresponds to a fixed number of training steps.\n  """"""\n\n  # Chosen so that the opposite actions cancel each other out, so random walk\n  # has a median of 1.\n  DEFAULT_ACTION_MULTIPLIERS = [1.0 / 1.5, 1.0 / 1.25, 1.0, 1.25, 1.5]\n\n  reward_range = (-1, 1)\n\n  def __init__(self,\n               output_dir,\n               model=trax_models.TransformerLM,\n               trainer_class=trainer_lib.Trainer,\n               loss_fn=layers.CrossEntropyLoss(),\n               optimizer=trax_opt.Adafactor,\n               inputs=trax_inputs.batcher,\n               action_multipliers=None,\n               observation_metrics=(\n                   (\'train\', \'metrics/accuracy\'),\n                   (\'train\', \'metrics/loss\'),\n                   (\'eval\', \'metrics/accuracy\'),\n                   (\'eval\', \'metrics/loss\'),\n               ),\n               include_controls_in_observation=False,\n               reward_metric=(\'eval\', \'metrics/accuracy\'),\n               train_steps=100,\n               eval_steps=10,\n               env_steps=100,\n               # This is a tuple instead of a dict because the controls are\n               # ordered in the action space.\n               control_configs=(\n                   # (name, start, (low, high), flip)\n                   (\'learning_rate\', 1e-3, (1e-9, 10.0), False),\n               ),\n               nontrainable_param_map=None,\n               observation_range=(0.0, 10.0),\n               # Don\'t save checkpoints by default, as they tend to use a lot of\n               # space.\n               should_save_checkpoints=False,\n               # Same here.\n               should_write_summaries=False,\n               id_to_mask=None):\n    if action_multipliers is None:\n      action_multipliers = self.DEFAULT_ACTION_MULTIPLIERS\n    self._model = model\n    # Initialize Trainer in OnlineTuneEnv lazily to prevent long startup in the\n    # async setup, where we just use the environments as containers for\n    # trajectories.\n    self._trainer_fn = functools.partial(\n        trainer_class,\n        model=model,\n        loss_fn=loss_fn,\n        optimizer=optimizer,\n        lr_schedule=(lambda history: lambda step: self._current_controls),\n        inputs=inputs,\n        should_save_checkpoints=should_save_checkpoints,\n        should_write_summaries=should_write_summaries,\n        nontrainable_param_map=nontrainable_param_map,\n        id_to_mask=id_to_mask,\n    )\n    self._trainer = None\n    self._action_multipliers = action_multipliers\n    self._observation_metrics = observation_metrics\n    self._include_controls_in_observation = include_controls_in_observation\n    self._reward_metric = reward_metric\n    self._train_steps = train_steps\n    self._eval_steps = eval_steps\n    self._env_steps = env_steps\n    self._control_configs = control_configs\n    self._observation_range = observation_range\n\n    self._output_dir = output_dir\n    tf.io.gfile.makedirs(self._output_dir)\n    # Actions are indices in self._action_multipliers.\n    self.action_space = gym.spaces.MultiDiscrete(\n        [len(self._action_multipliers)] * len(self._control_configs)\n    )\n    # Observation is a vector with the values of the metrics specified in\n    # observation_metrics plus optionally the current controls.\n    observation_dim = (\n        len(self._observation_metrics) +\n        int(self._include_controls_in_observation) * len(self._control_configs)\n    )\n\n    (obs_low, obs_high) = observation_range\n    self.observation_space = gym.spaces.Box(\n        # Observations are clipped to this range.\n        low=obs_low, high=obs_high, shape=(observation_dim,),\n    )\n\n  @property\n  def _next_trajectory_dir(self):\n    """"""Assigns a new output dir for a trajectory under self._output_dir.\n\n    Directory names are consecutive integers starting from zero. New directory\n    index is assigned as the maximum of past indices plus one. Directories that\n    are not integers are ignored.\n\n    Returns:\n      A path of the new directory.\n    """"""\n    trajectory_dirs = tf.io.gfile.listdir(self._output_dir)\n\n    def int_or_none(s):\n      try:\n        return int(s)\n      except TypeError:\n        return None\n\n    past_trajectory_ids = [\n        trajectory_id for trajectory_id in map(int_or_none, trajectory_dirs)\n        if trajectory_id is not None]\n    next_trajectory_id = max([-1] + past_trajectory_ids) + 1\n\n    return os.path.join(self._output_dir, str(next_trajectory_id))\n\n  @property\n  def _current_reward_metric(self):\n    metric_values = online_tune.historical_metric_values(\n        self._trainer.state.history,\n        self._reward_metric,\n    )\n    assert metric_values.shape[0] > 0, (\n        \'No values in history for metric {}.\'.format(self._reward_metric))\n    return metric_values[-1]\n\n  @property\n  def _current_observation(self):\n    observations = online_tune.history_to_observations(\n        self._trainer.state.history,\n        self._observation_metrics,\n        self._observation_range,\n        self._control_configs if self._include_controls_in_observation\n        else None,\n    )\n    assert observations.shape[0] > 0, \'No values in history for any metric.\'\n    return observations[-1, :]\n\n  @property\n  def trainer(self):\n    if self._trainer is None:\n      raise ValueError(\'The environment has to be reset first.\')\n    return self._trainer\n\n  def reset(self):\n    if self._trainer is None:\n      self._trainer = self._trainer_fn()\n    self._current_controls = {\n        name: start_value\n        for (name, start_value, _, _) in self._control_configs\n    }\n    self._step = 0\n    self._trainer.reset(output_dir=self._next_trajectory_dir)\n    self._trainer.evaluate(self._eval_steps)\n    return self._current_observation\n\n  def step(self, action):\n    """"""Step the environment.\n\n    One environment step corresponds to self.train_steps training steps.\n\n    Args:\n      action: (int) Action to take. An index in self.action_multipliers.\n\n    Returns:\n      Tuple (observation, reward, done, info). observation is a singleton vector\n        with the current value of the metric. reward is the difference in the\n        metric since the last step. done is set after reaching self.env_steps\n        environment steps. info is an empty dict.\n    """"""\n    self._current_controls = {\n        # name: value\n        control_config[0]: online_tune.update_control(  # pylint: disable=g-complex-comprehension\n            control_config,\n            control_action,\n            self._trainer.state.history,\n            self._action_multipliers,\n        )\n        for (control_action, control_config) in zip(\n            action, self._control_configs\n        )\n    }\n    last_reward_metric = self._current_reward_metric\n    self._trainer.train_epoch(self._train_steps, self._eval_steps)\n    self._step += 1\n    current_reward_metric = self._current_reward_metric\n    observation = self._current_observation\n    reward = current_reward_metric - last_reward_metric\n    done = self._step == self._env_steps\n    return (observation, reward, done, {})\n'"
trax/rl/envs/online_tune_env_test.py,6,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.rl.online_tune_env.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\n\nimport numpy as np\nfrom tensorflow import test\nfrom tensorflow.compat.v1.io import gfile\nfrom trax import models\nfrom trax import optimizers\nfrom trax.rl import online_tune\nfrom trax.rl.envs import online_tune_env\nfrom trax.supervised import inputs as trax_inputs\nfrom trax.supervised import trainer_lib\n\nHISTORY_MODE = \'eval\'\nMETRIC = \'metrics/accuracy\'\n\n\nclass MockTrainer(trainer_lib.Trainer):\n\n  def __init__(self, metrics_to_report, *args, **kwargs):\n    self.init_metrics_to_report = metrics_to_report\n    super(MockTrainer, self).__init__(*args, **kwargs)\n    self.controls = []\n    self.metrics_to_report = None\n\n  def reset(self, output_dir):\n    super(MockTrainer, self).reset(output_dir)\n    # Copy the sequence to a list so we can modify it later.\n    self.metrics_to_report = list(self.init_metrics_to_report)\n\n  def train_epoch(self, epoch_steps, eval_steps):\n    del epoch_steps\n    self.controls.append(self.nontrainable_params)\n    self.evaluate(eval_steps)\n\n  def evaluate(self, eval_steps):\n    del eval_steps\n    self.state.history.append(\n        mode=HISTORY_MODE,\n        metric=METRIC,\n        step=self.step,\n        value=self.metrics_to_report.pop(0))\n    for (name, value) in self.nontrainable_params.items():\n      (mode, metric) = online_tune.control_metric(name)\n      self.state.history.append(\n          mode=mode,\n          metric=metric,\n          step=self.step,\n          value=value)\n\n\nclass OnlineTuneTest(test.TestCase):\n\n  @staticmethod\n  def _create_env(\n      output_dir, metrics_to_report=(0.0,), action_multipliers=(1,)\n  ):\n    return online_tune_env.OnlineTuneEnv(\n        trainer_class=functools.partial(MockTrainer, metrics_to_report),\n        model=functools.partial(\n            models.MLP, n_hidden_layers=0, n_output_classes=1),\n        inputs=functools.partial(\n            trax_inputs.random_inputs,\n            input_shape=(1, 1),\n            input_dtype=np.float32,\n            output_shape=(1, 1),\n            output_dtype=np.float32),\n        optimizer=optimizers.Momentum,\n        control_configs=(\n            (\'learning_rate\', 1e-3, (1e-9, 10.0), False),\n            (\'weight_decay_rate\', 1e-5, (1e-9, 0.1), False),\n        ),\n        include_controls_in_observation=False,\n        output_dir=output_dir,\n        action_multipliers=action_multipliers,\n        observation_metrics=[(HISTORY_MODE, METRIC)],\n        reward_metric=(HISTORY_MODE, METRIC),\n        train_steps=1,\n        eval_steps=1,\n        env_steps=(len(metrics_to_report) - 1))\n\n  def test_communicates_with_trainer(self):\n    action_multipliers = [0.8, 1.0, 1.25]\n    metrics_to_report = [0.1, 0.5, 0.8, 0.9]\n    actions_to_take = [[0, 1], [1, 2], [2, 0]]\n    expected_observations = np.expand_dims(metrics_to_report, axis=1)\n    # Metric difference in consecutive timesteps.\n    expected_rewards = [0.4, 0.3, 0.1]\n    expected_dones = [False, False, True]\n    expected_controls = [\n        {\'learning_rate\': 0.0008, \'weight_decay_rate\': 1e-5},\n        {\'learning_rate\': 0.0008, \'weight_decay_rate\': 1.25e-5},\n        {\'learning_rate\': 0.001, \'weight_decay_rate\': 1e-5},\n    ]\n\n    env = self._create_env(\n        output_dir=self.get_temp_dir(),\n        metrics_to_report=metrics_to_report,\n        action_multipliers=action_multipliers)\n    actual_observations = [env.reset()]\n    actual_rewards = []\n    actual_dones = []\n    for action in actions_to_take:\n      (observation, reward, done, _) = env.step(action)\n      actual_observations.append(observation)\n      actual_rewards.append(reward)\n      actual_dones.append(done)\n\n    np.testing.assert_allclose(actual_observations, expected_observations)\n    np.testing.assert_allclose(actual_rewards, expected_rewards)\n    self.assertEqual(actual_dones, expected_dones)\n    def get_control(name, controls):\n      return [control[name] for control in controls]\n    for name in (\'learning_rate\', \'weight_decay_rate\'):\n      np.testing.assert_allclose(\n          get_control(name, env.trainer.controls),\n          get_control(name, expected_controls),\n      )\n\n  def test_creates_new_trajectory_dirs(self):\n    output_dir = self.get_temp_dir()\n    env = self._create_env(output_dir=output_dir)\n    self.assertEqual(set(gfile.listdir(output_dir)), set())\n    env.reset()\n    self.assertEqual(set(gfile.listdir(output_dir)), {\'0\'})\n    env.reset()\n    self.assertEqual(set(gfile.listdir(output_dir)), {\'0\', \'1\'})\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/envs/online_tune_rl_env.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""An environment for tuning RL agent hyperparameters during training.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nimport os\n\nimport gym\n\nfrom tensor2tensor.envs import env_problem_utils\nfrom tensorflow.compat.v1.io import gfile\nfrom trax.rl import online_tune\nfrom trax.rl import ppo_trainer\n\n\nclass OnlineTuneRLEnv(gym.Env):\n  """"""An environment for tuning model hyperparameters during RL training.\n\n  A rollout is one instance of training a specific agent on a specific\n  environment. Observations are the values of some evaluation metrics. Actions\n  control hyperparameter changes during training. Reward is the change of some\n  evaluation metric. One environment step corresponds to a fixed number of\n  training steps.\n\n  For now only works with PPO.\n  """"""\n\n  # Chosen so that the opposite actions cancel each other out, so random walk\n  # has a median of 1.\n  DEFAULT_ACTION_MULTIPLIERS = [1.0 / 1.5, 1.0 / 1.25, 1.0, 1.25, 1.5]\n\n  def __init__(\n      self,\n      output_dir,\n      env_name=\'PongNoFrameskip-v4\',\n      env_kwargs=None,\n      train_batch_size=16,\n      eval_batch_size=16,\n      trainer_class=ppo_trainer.PPO,\n      action_multipliers=None,\n      observation_metrics=(\n          (\'eval\', \'eval/raw_reward_mean/temperature_1.0\'),\n          (\'eval\', \'eval/raw_reward_std/temperature_1.0\'),\n      ),\n      include_controls_in_observation=False,\n      reward_metric=(\'eval\', \'eval/raw_reward_mean/temperature_1.0\'),\n      train_epochs=100,\n      env_steps=100,\n      # This is a tuple instead of a dict because the controls are\n      # ordered in the action space.\n      control_configs=(\n          # (name, start, (low, high), flip)\n          (\'learning_rate\', 1e-3, (1e-9, 10.0), False),\n      ),\n      observation_range=(0.0, 10.0),\n      # Don\'t save checkpoints by default, as they tend to use a lot of\n      # space.\n      should_save_checkpoints=False,\n      # Same here.\n      should_write_summaries=False,\n  ):\n    if action_multipliers is None:\n      action_multipliers = self.DEFAULT_ACTION_MULTIPLIERS\n    if env_kwargs is None:\n      env_kwargs = {}\n    (train_env, eval_env) = tuple(\n        env_problem_utils.make_env(  # pylint: disable=g-complex-comprehension\n            env_problem_name=env_name,\n            batch_size=batch_size,\n            **env_kwargs\n        )\n        for batch_size in (train_batch_size, eval_batch_size)\n    )\n    # Initialize Trainer in OnlineTuneRLEnv lazily to prevent long startup in\n    # the async setup, where we just use the environments as containers for\n    # trajectories.\n    self._trainer_fn = functools.partial(\n        trainer_class,\n        train_env=train_env,\n        eval_env=eval_env,\n        controller=(lambda history: lambda step: self._current_controls),\n        should_save_checkpoints=should_save_checkpoints,\n        should_write_summaries=should_write_summaries,\n    )\n    self._trainer = None\n    self._action_multipliers = action_multipliers\n    self._observation_metrics = observation_metrics\n    self._include_controls_in_observation = include_controls_in_observation\n    self._reward_metric = reward_metric\n    self._train_epochs = train_epochs\n    self._env_steps = env_steps\n    self._control_configs = control_configs\n    self._observation_range = observation_range\n\n    self._output_dir = output_dir\n    gfile.makedirs(self._output_dir)\n    # Actions are indices in self._action_multipliers.\n    self.action_space = gym.spaces.MultiDiscrete(\n        [len(self._action_multipliers)] * len(self._control_configs)\n    )\n    # Observation is a vector with the values of the metrics specified in\n    # observation_metrics plus optionally the current controls.\n    observation_dim = (\n        len(self._observation_metrics) +\n        int(self._include_controls_in_observation) * len(self._control_configs)\n    )\n\n    (obs_low, obs_high) = observation_range\n    self.observation_space = gym.spaces.Box(\n        # Observations are clipped to this range.\n        low=obs_low, high=obs_high, shape=(observation_dim,),\n    )\n\n  @property\n  def _next_trajectory_dir(self):\n    """"""Assigns a new output dir for a trajectory under self._output_dir.\n\n    Directory names are consecutive integers starting from zero. New directory\n    index is assigned as the maximum of past indices plus one. Directories that\n    are not integers are ignored.\n\n    Returns:\n      A path of the new directory.\n    """"""\n    trajectory_dirs = gfile.listdir(self._output_dir)\n\n    def int_or_none(s):\n      try:\n        return int(s)\n      except TypeError:\n        return None\n\n    past_trajectory_ids = [\n        trajectory_id for trajectory_id in map(int_or_none, trajectory_dirs)\n        if trajectory_id is not None]\n    next_trajectory_id = max([-1] + past_trajectory_ids) + 1\n\n    return os.path.join(self._output_dir, str(next_trajectory_id))\n\n  @property\n  def _current_reward_metric(self):\n    metric_values = online_tune.historical_metric_values(\n        self._trainer.history,\n        self._reward_metric,\n    )\n    assert metric_values.shape[0] > 0, (\n        \'No values in history for metric {}.\'.format(self._reward_metric))\n    return metric_values[-1]\n\n  @property\n  def _current_observation(self):\n    observations = online_tune.history_to_observations(\n        self._trainer.history,\n        self._observation_metrics,\n        self._observation_range,\n        self._control_configs if self._include_controls_in_observation\n        else None,\n    )\n    assert observations.shape[0] > 0, \'No values in history for any metric.\'\n    return observations[-1, :]\n\n  @property\n  def trainer(self):\n    if self._trainer is None:\n      raise ValueError(\'The environment has to be reset first.\')\n    return self._trainer\n\n  def reset(self):\n    if self._trainer is None:\n      self._trainer = self._trainer_fn()\n    self._current_controls = {\n        name: start_value\n        for (name, start_value, _, _) in self._control_configs\n    }\n    self._step = 0\n    self._trainer.reset(output_dir=self._next_trajectory_dir)\n    self._trainer.evaluate()\n    return self._current_observation\n\n  def step(self, action):\n    """"""Step the environment.\n\n    One environment step corresponds to self._train_epochs training epochs.\n\n    Args:\n      action: (int) Action to take. An index in self.action_multipliers.\n\n    Returns:\n      Tuple (observation, reward, done, info). observation is a singleton vector\n        with the current value of the metric. reward is the difference in the\n        metric since the last step. done is set after reaching self.env_steps\n        environment steps. info is an empty dict.\n    """"""\n    self._current_controls = {\n        # name: value\n        control_config[0]: online_tune.update_control(  # pylint: disable=g-complex-comprehension\n            control_config,\n            control_action,\n            self._trainer.history,\n            self._action_multipliers,\n        )\n        for (control_action, control_config) in zip(\n            action, self._control_configs\n        )\n    }\n    for _ in range(self._train_epochs):\n      self._trainer.train_epoch(evaluate=False)\n    self._trainer.evaluate()\n    self._step += 1\n    observation = self._current_observation\n    reward = self._current_reward_metric\n    done = self._step == self._env_steps\n    return (observation, reward, done, {})\n'"
trax/rl/envs/online_tune_rl_env_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.rl.online_tune_rl_env.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\n\nfrom tensorflow import test\nfrom tensorflow.compat.v1.io import gfile\nfrom trax import models\nfrom trax.rl import ppo_trainer\nfrom trax.rl.envs import online_tune_rl_env\n\n\nclass OnlineTuneRLTest(test.TestCase):\n\n  @staticmethod\n  def _create_env(output_dir):\n    return online_tune_rl_env.OnlineTuneRLEnv(\n        trainer_class=functools.partial(\n            ppo_trainer.PPO,\n            policy_and_value_model=functools.partial(\n                models.FrameStackMLP, hidden_sizes=()\n            ),\n            max_timestep=1,\n            max_timestep_eval=1,\n        ),\n        env_name=\'CartPole-v0\',\n        env_kwargs={\'max_timestep\': 1, \'resize\': False},\n        train_batch_size=1,\n        eval_batch_size=1,\n        train_epochs=1,\n        output_dir=output_dir,\n    )\n\n  def test_runs(self):\n    env = self._create_env(output_dir=self.get_temp_dir())\n    obs = env.reset()\n    self.assertEqual(obs.shape, env.observation_space.shape)\n    (obs, _, _, _) = env.step(env.action_space.sample())\n    self.assertEqual(obs.shape, env.observation_space.shape)\n\n  def test_creates_new_trajectory_dirs(self):\n    output_dir = self.get_temp_dir()\n    env = self._create_env(output_dir=output_dir)\n    self.assertEqual(set(gfile.listdir(output_dir)), set())\n    env.reset()\n    self.assertEqual(set(gfile.listdir(output_dir)), {\'0\'})\n    env.reset()\n    self.assertEqual(set(gfile.listdir(output_dir)), {\'0\', \'1\'})\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/envs/online_tune_test.py,6,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for trax.rl.online_tune.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom tensorflow import test\nfrom trax import history as trax_history\nfrom trax.rl.envs import online_tune\n\n\nclass OnlineTuneTest(test.TestCase):\n\n  def _append_metrics(self, h, metric, values):\n    for (i, value) in enumerate(values):\n      h.append(*metric, step=i, value=value)\n\n  def test_retrieves_historical_metric_values(self):\n    history = trax_history.History()\n    self._append_metrics(history, (\'train\', \'accuracy\'), [0.1, 0.73])\n    metric_values = online_tune.historical_metric_values(\n        history, metric=(\'train\', \'accuracy\'), observation_range=(0, 5))\n    np.testing.assert_array_equal(metric_values, [0.1, 0.73])\n\n  def test_clips_historical_metric_values(self):\n    history = trax_history.History()\n    self._append_metrics(history, (\'train\', \'loss\'), [-10, 10])\n    metric_values = online_tune.historical_metric_values(\n        history, metric=(\'train\', \'loss\'), observation_range=(-1, 1))\n    np.testing.assert_array_equal(metric_values, [-1, 1])\n\n  def test_converts_history_to_observations_without_learning_rate(self):\n    history = trax_history.History()\n    self._append_metrics(history, (\'train\', \'loss\'), [3.0, 1.07])\n    self._append_metrics(history, (\'eval\', \'accuracy\'), [0.12, 0.68])\n    observations = online_tune.history_to_observations(\n        history,\n        metrics=((\'eval\', \'accuracy\'), (\'train\', \'loss\')),\n        observation_range=(0, 5),\n        include_lr=False,\n    )\n    np.testing.assert_array_equal(observations, [[0.12, 3.0], [0.68, 1.07]])\n\n  def test_converts_history_to_observations_with_learning_rate(self):\n    history = trax_history.History()\n    self._append_metrics(\n        history, (\'train\', \'training/learning_rate\'), [1e-3, 1e-4])\n    observations = online_tune.history_to_observations(\n        history,\n        metrics=(),\n        observation_range=(0, 5),\n        include_lr=True,\n    )\n    self.assertEqual(observations.shape, (2, 1))\n    ((log_lr_1,), (log_lr_2,)) = observations\n    self.assertGreater(log_lr_1, log_lr_2)\n\n  def test_clips_observations(self):\n    history = trax_history.History()\n    self._append_metrics(history, (\'eval\', \'loss\'), [-10, 10])\n    observations = online_tune.history_to_observations(\n        history,\n        metrics=((\'eval\', \'loss\'),),\n        observation_range=(-2, 2),\n        include_lr=False,\n    )\n    np.testing.assert_array_equal(observations, [[-2], [2]])\n\n  def test_calculates_new_learning_rate(self):\n    history = trax_history.History()\n    self._append_metrics(\n        history, online_tune.LEARNING_RATE_METRIC, [1e-2, 1e-3])\n    new_lr = online_tune.new_learning_rate(\n        action=2,\n        history=history,\n        action_multipliers=(0.5, 1.0, 2.0),\n        max_lr=1.0,\n    )\n    np.testing.assert_almost_equal(new_lr, 2e-3)\n\n  def test_clips_new_learning_rate(self):\n    history = trax_history.History()\n    self._append_metrics(history, online_tune.LEARNING_RATE_METRIC, [1e-3])\n    new_lr = online_tune.new_learning_rate(\n        action=0,\n        history=history,\n        action_multipliers=(4.0, 1.0, 0.25),\n        max_lr=3e-3,\n    )\n    np.testing.assert_almost_equal(new_lr, 3e-3)\n\n\nif __name__ == \'__main__\':\n  test.main()\n'"
trax/rl/trajectory/replay_buffer.py,28,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Replay buffer, focusing on sampling states.""""""\n\nfrom typing import List\n\nfrom absl import logging\nimport numpy as np\nfrom tensor2tensor.envs import trajectory\n\n\nclass ReplayBuffer:\n  """"""A replay buffer with state (not trajectory) oriented focus.""""""\n\n  TERMINATE_KEY = \'terminate\'\n  PATH_START_KEY = \'path_start\'\n  PATH_END_KEY = \'path_end\'\n\n  OBSERVATIONS_KEY = \'observations\'\n  ACTIONS_KEY = \'actions\'\n  # TODO(afrozm): Maybe rename to LOGPS_KEY_TRAJ?\n  LOGPS_KEY = \'logps\'\n  REWARDS_KEY = \'rewards\'\n\n  LOGPS_KEY_TRAJ = \'log_prob_actions\'\n  INVALID_IDX = -1\n\n  def __init__(self, buffer_size: int):\n    # TODO(afrozm): Rename to max_num_states or something better.\n    assert buffer_size > 0\n    self.buffer_size = buffer_size\n    self.total_count = 0\n    self.buffer_head = 0\n    self.buffer_tail = self.INVALID_IDX\n    self.num_paths = 0\n\n    # TODO(afrozm): Flatten this dictionary, too confusing now.\n    self.buffers = None\n\n    self.clear()\n    return\n\n  def sample(self, n, filter_end=True):\n    """"""Sample `n` observations from the replay buffer.""""""\n    curr_size = self.get_current_size()\n    assert curr_size > 0\n\n    # Select the indices to sample from.\n    if filter_end:\n      idxs_to_sample_from = self.get_valid_idx()\n    else:\n      idxs_to_sample_from = self.get_unrolled_indices()\n\n    return np.random.choice(idxs_to_sample_from, size=n, replace=True)\n\n  def get(self, key, idx):\n    return self.buffers[key][idx]\n\n  def get_all(self, key):\n    return self.buffers[key]\n\n  def get_unrolled_indices(self):\n    indices = None\n    if self.buffer_tail == self.INVALID_IDX:\n      indices = []\n    elif self.buffer_tail < self.buffer_head:\n      indices = list(range(self.buffer_tail, self.buffer_head))\n    else:\n      indices = list(range(self.buffer_tail, self.buffer_size))\n      indices += list(range(0, self.buffer_head))\n    return indices\n\n  def get_path_start(self, idx):\n    return self.buffers[self.PATH_START_KEY][idx]\n\n  def get_path_end(self, idx):\n    return self.buffers[self.PATH_END_KEY][idx]\n\n  def get_subpath_indices(self, idx: int) -> List[int]:\n    """"""Get indices of path that starts at `idx`.""""""\n    start_idx = idx\n    end_idx = self.get_path_end(idx)\n\n    if start_idx <= end_idx:\n      path_indices = list(range(start_idx, end_idx + 1))\n    else:\n      path_indices = list(range(start_idx, self.buffer_size))\n      path_indices += list(range(0, end_idx + 1))\n\n    return path_indices\n\n  def get_pathlen(self, idx):\n    """"""Returns lengths of paths at indices `idx`.""""""\n    is_array = isinstance(idx, np.ndarray) or isinstance(idx, list)\n    if not is_array:\n      idx = [idx]\n\n    n = len(idx)\n    start_idx = self.get_path_start(idx)\n    end_idx = self.get_path_end(idx)\n    pathlen = np.empty(n, dtype=int)\n\n    for i in range(n):\n      curr_start = start_idx[i]\n      curr_end = end_idx[i]\n      if curr_start < curr_end:\n        curr_len = curr_end - curr_start\n      else:\n        curr_len = self.buffer_size - curr_start + curr_end\n      pathlen[i] = curr_len\n\n    if not is_array:\n      pathlen = pathlen[0]\n\n    return pathlen\n\n  def is_valid_path(self, idx):\n    """"""Returns if `idx` is part of a valid path.""""""\n    start_idx = self.get_path_start(idx)\n    valid = start_idx != self.INVALID_IDX\n    return valid\n\n  def store(self, path: trajectory.Trajectory):\n    """"""Stores a given trajectory in the replay buffer.""""""\n    if not self._path_is_valid(path) or not self._path_check_values(path):\n      return self.INVALID_IDX\n\n    n = self._path_length(path)\n    if n <= 0:\n      return self.INVALID_IDX\n\n    (observations_np, actions_np, rewards_np, raw_rewards_np,\n     info_np_dict) = path.as_numpy\n\n    del raw_rewards_np\n\n    return self.store_np(n, observations_np, actions_np, rewards_np,\n                         info_np_dict)\n\n  def store_np(self, n, observations_np, actions_np, rewards_np, info_np_dict):\n    """"""Stores a given trajectory in numpy form in the replay buffer.""""""\n    idx = self._request_idx(n + 1)\n    self._store_path(observations_np, actions_np, rewards_np, info_np_dict, idx)\n\n    self.num_paths += 1\n    self.total_count += n + 1\n    return idx[0]\n\n  def clear(self):\n    self.buffer_head = 0\n    self.buffer_tail = self.INVALID_IDX\n    self.num_paths = 0\n    return\n\n  def get_prev_idx(self, idx) -> int:\n    prev_idx = idx - 1\n    prev_idx[prev_idx < 0] += self.buffer_size\n    is_start = self.is_path_start(idx)\n    prev_idx[is_start] = idx[is_start]\n    return prev_idx\n\n  def get_next_idx(self, idx) -> int:\n    next_idx = np.mod(idx + 1, self.buffer_size)\n    is_end = self.is_path_end(idx)\n    next_idx[is_end] = idx[is_end]\n    return next_idx\n\n  def is_terminal_state(self, idx) -> bool:\n    terminate_flags = self.buffers[self.TERMINATE_KEY][idx]\n    terminate = terminate_flags != 0\n    is_end = self.is_path_end(idx)\n    terminal_state = np.logical_and(terminate, is_end)\n    return terminal_state\n\n  def check_terminal_flag(self, idx, flag) -> bool:\n    terminate_flags = self.buffers[self.TERMINATE_KEY][idx]\n    terminate = (terminate_flags == flag.value)\n    return terminate\n\n  def is_path_start(self, idx) -> bool:\n    is_end = self.buffers[self.PATH_START_KEY][idx] == idx\n    return is_end\n\n  def is_path_end(self, idx) -> bool:\n    is_end = self.buffers[self.PATH_END_KEY][idx] == idx\n    return is_end\n\n  def get_current_size(self) -> int:\n    if self.buffer_tail == self.INVALID_IDX:\n      return 0\n    elif self.buffer_tail < self.buffer_head:\n      return self.buffer_head - self.buffer_tail\n    else:\n      return self.buffer_size - self.buffer_tail + self.buffer_head\n\n  def get_valid_idx(self) -> List[int]:\n    """"""Returns indices that aren\'t the end states.""""""\n    valid_idx = np.argwhere(\n        self.buffers[self.PATH_START_KEY] != self.INVALID_IDX)\n    is_end = self.is_path_end(valid_idx)\n    valid_idx = valid_idx[np.logical_not(is_end)]\n    return valid_idx\n\n  def init_buffers(self, observations_np, actions_np, rewards_np, logp_np):\n    """"""Initialize the buffers.""""""\n\n    self.buffers = dict()\n\n    # path start, path end, terminate.\n    for key, value in zip(\n        [self.PATH_START_KEY, self.PATH_END_KEY, self.TERMINATE_KEY],\n        [self.INVALID_IDX, self.INVALID_IDX, 0]):\n      self.buffers[key] = np.full(self.buffer_size, value, dtype=np.int32)\n\n    # observations, actions, rewards and log probabilities.\n    for key, value in zip(\n        [self.OBSERVATIONS_KEY, self.ACTIONS_KEY, self.REWARDS_KEY,\n         self.LOGPS_KEY],\n        [observations_np, actions_np, rewards_np, logp_np]\n    ):\n      self.buffers[key] = np.zeros(\n          [self.buffer_size] + list(value.shape[1:]),\n          dtype=value.dtype\n      )\n      logging.info(\n          f\'Initialized buffer[{key}] with shape: {self.buffers[key].shape}\')\n    return\n\n  def get_valid_indices(self):\n    """"""Returns an array of valid (non-terminal) indices and masks.""""""\n    idx = np.array(self.get_unrolled_indices())\n\n    end_mask = self.is_path_end(idx)\n    valid_mask = np.logical_not(end_mask)\n    valid_idx = idx[valid_mask]\n    valid_idx = np.column_stack([valid_idx, np.nonzero(valid_mask)[0]])\n\n    # `idx` is an array of all filled positions in the buffer.\n    # `valid_idx`\'s first column are all the valid positions (non-ending) and\n    # the second column is its index in the `idx` array.\n    return idx, valid_mask, valid_idx\n\n  def iterate_over_paths(self, idx=None):\n    """"""Iterates over valid paths if `idx` is None, else on given paths.""""""\n    if idx is None:\n      idx = self.get_unrolled_indices()\n\n    idx = np.asarray(idx)\n    assert len(idx.shape) == 1\n    n = len(idx)\n\n    # `*_i` are indices into idx\n    # `*_idx` are indices into rb.buffers\n    start_i = 0\n    while start_i < n:\n      start_idx = idx[start_i]\n      path_length = self.get_pathlen(start_idx)\n      end_i = start_i + path_length\n      end_idx = idx[end_i]\n\n      # Consistency check.\n      assert start_idx == self.get_path_start(start_idx)\n      assert end_idx == self.get_path_end(start_idx)\n\n      yield (start_i, end_i + 1)\n\n      # Go to the starting of the next path.\n      start_i = end_i + 1\n\n  def _request_idx(self, n):\n    """"""Returns an index capable of storing a trajectory of path length `n`.""""""\n    assert n + 1 < self.buffer_size  # bad things can happen if path is too long\n\n    remainder = n\n    idx = []\n\n    start_idx = self.buffer_head\n    while remainder > 0:\n      end_idx = np.minimum(start_idx + remainder, self.buffer_size)\n      remainder -= (end_idx - start_idx)\n\n      free_idx = list(range(start_idx, end_idx))\n      self._free_idx(free_idx)\n      idx += free_idx\n      start_idx = 0\n\n    self.buffer_head = (self.buffer_head + n) % self.buffer_size\n    return idx\n\n  def _free_idx(self, idx):\n    """"""Free the whole path at `idx` in the buffer.""""""\n    assert idx[0] <= idx[-1]\n    n = len(idx)\n    if self.buffer_tail != self.INVALID_IDX:\n      update_tail = ((idx[0] <= idx[-1]) and\n                     (idx[0] <= self.buffer_tail) and\n                     (idx[-1] >= self.buffer_tail))\n      update_tail |= idx[0] > idx[-1] and (idx[0] <= self.buffer_tail or\n                                           idx[-1] >= self.buffer_tail)\n\n      if update_tail:\n        i = 0\n        while i < n:\n          curr_idx = idx[i]\n          if self.is_valid_path(curr_idx):\n            start_idx = self.get_path_start(curr_idx)\n            end_idx = self.get_path_end(curr_idx)\n            pathlen = self.get_pathlen(curr_idx)\n\n            if start_idx < end_idx:\n              self.buffers[self.PATH_START_KEY][start_idx:end_idx +\n                                                1] = self.INVALID_IDX\n            else:\n              self.buffers[self.PATH_START_KEY][start_idx:self\n                                                .buffer_size] = self.INVALID_IDX\n              self.buffers[self.PATH_START_KEY][0:end_idx +\n                                                1] = self.INVALID_IDX\n\n            self.num_paths -= 1\n            i += pathlen + 1\n            self.buffer_tail = (end_idx + 1) % self.buffer_size\n          else:\n            i += 1\n    else:\n      self.buffer_tail = idx[0]\n    return\n\n  def _store_path(self, states_np, actions_np, rewards_np, info_np_dict,\n                  idx: List[int]):\n    """"""Store the given trajectory in the replay buffer.""""""\n    n = actions_np.shape[0]\n\n    assert len(states_np) == n + 1\n    assert len(actions_np) == n\n    assert len(rewards_np) == n\n    logp_np = info_np_dict[self.LOGPS_KEY_TRAJ]\n    assert len(logp_np) == n\n    if (len(logp_np.shape) > 1) and (logp_np.shape[1] == 1):\n      # Sometimes we can get something like (n+1, 1, #actions)\n      logp_np = np.squeeze(logp_np, axis=1)\n      # Then extract logps only for the actions we carried out.\n      logp_np = np.squeeze(logp_np[np.arange(n)[None, :], actions_np])\n      # Give this a shape (n + 1, 1) and actions a shape (n, 1)\n      logp_np = logp_np[..., None]\n      # So to with actions.\n      actions_np = actions_np[..., None]\n    elif len(logp_np.shape) > 1:\n      n, h, _ = logp_np.shape\n      if actions_np.shape != (n, h):\n        raise ValueError(\n            f\'Shape mismatch, actions_np.shape {actions_np.shape} != ({n}, {h})\'\n            f\'states_np.shape = {states_np.shape} \'\n            f\'actions_np.shape = {actions_np.shape} \'\n            f\'rewards_np.shape = {rewards_np.shape} \'\n            f\'logp_np.shape = {logp_np.shape} \')\n      logp_np = logp_np[np.arange(n)[:, None], np.arange(h), actions_np]\n\n    if self.buffers is None:\n      self.init_buffers(states_np, actions_np, rewards_np, logp_np)\n\n    self.buffers[self.OBSERVATIONS_KEY][idx[:n + 1]] = [x for x in states_np]\n    self.buffers[self.ACTIONS_KEY][idx[:n]] = [x for x in actions_np]\n    self.buffers[self.REWARDS_KEY][idx[:n]] = [x for x in rewards_np]\n    self.buffers[self.LOGPS_KEY][idx[:n]] = [x for x in logp_np]\n\n    self.buffers[self.TERMINATE_KEY][idx] = 0  # path.terminate.value\n    self.buffers[self.PATH_START_KEY][idx] = idx[0]\n    self.buffers[self.PATH_END_KEY][idx] = idx[-1]\n    return\n\n  def _path_length(self, path: trajectory.Trajectory) -> int:\n    # Returns the number of actions, which is 1 less than number of time-steps.\n    return path.num_time_steps - 1\n\n  def _path_is_valid(self, path: trajectory.Trajectory) -> bool:\n    # The internals of the path are always consistent.\n    del path\n    return True\n\n  def _path_check_values(self, path: trajectory.Trajectory):\n    # Is any value infinity?\n    obs_np, actions_np, rewards_np, raw_rewards_np, info_np = path.as_numpy\n    del info_np\n\n    def check_all_finite(np_obj):\n      return np.isfinite(np_obj).all()\n\n    return all(\n        check_all_finite(x)\n        for x in [obs_np, actions_np, rewards_np, raw_rewards_np])\n'"
trax/rl/trajectory/replay_buffer_test.py,13,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n""""""Tests for trax.rl.trajectory.replay_buffer.""""""\n\nfrom absl.testing import absltest\nimport numpy as np\nfrom tensor2tensor.envs import trajectory\nfrom trax.rl.trajectory import replay_buffer\n\n\nclass ReplayBufferTest(absltest.TestCase):\n\n  def get_random_trajectory(self,\n                            max_time_step=None,\n                            obs_shape=(2, 2)) -> trajectory.Trajectory:\n    t = trajectory.Trajectory()\n    max_time_step = max_time_step or np.random.randint(2, 10)\n    for _ in range(max_time_step):\n      r = float(np.random.uniform(size=()))\n      t.add_time_step(\n          observation=np.random.uniform(size=obs_shape),\n          done=False,\n          raw_reward=r,\n          processed_reward=r,\n          action=int(np.random.choice(10, ())),\n          info={\n              replay_buffer.ReplayBuffer.LOGPS_KEY_TRAJ:\n                  float(np.random.uniform(low=-10, high=0))\n          })\n    t.change_last_time_step(done=True)\n    return t\n\n  def test_add_three_trajectories(self):\n    n1 = 10\n    t1 = self.get_random_trajectory(max_time_step=n1)\n\n    n2 = 5\n    t2 = self.get_random_trajectory(max_time_step=n2)\n\n    # Make a buffer of just sufficient size to hold these two.\n    rb = replay_buffer.ReplayBuffer(n1 + n2)\n\n    # import pdb; pdb.set_trace()\n\n    start_index_t1 = rb.store(t1)\n\n    # Stored at the beginning.\n    self.assertEqual(0, start_index_t1)\n    # One path stored in total.\n    self.assertEqual(1, rb.num_paths)\n    # Total number of states stored, ever.\n    self.assertEqual(n1, rb.total_count)\n    # The current number of states stored.\n    self.assertEqual(n1, rb.get_current_size())\n\n    start_index_t2 = rb.store(t2)\n\n    # Stored right afterwards\n    self.assertEqual(n1, start_index_t2)\n    self.assertEqual(2, rb.num_paths)\n    self.assertEqual(n1 + n2, rb.total_count)\n    self.assertEqual(n1 + n2, rb.get_current_size())\n\n    # We now make a path that is smaller than n1.\n    # Since there is no more space in the buffer, t1 will be ejected.\n    # t2 will remain there.\n\n    n3 = 6\n    assert n3 < n1\n    t3 = self.get_random_trajectory(max_time_step=n3)\n    start_index_t3 = rb.store(t3)\n    self.assertEqual(0, start_index_t3)\n    self.assertEqual(2, rb.num_paths)\n    self.assertEqual(n1 + n2 + n3, rb.total_count)\n    self.assertEqual(n2 + n3, rb.get_current_size())\n\n    # So the first n3 rb.buffers[replay_buffer.ReplayBuffer.PATH_START_KEY] will\n    # be 0, the next n1 - n3 will be -1, and the rest will be start_index_t2.\n    path_start_array = ([0] * n3) + ([-1] * (n1 - n3)) + ([start_index_t2] * n2)\n\n    np.testing.assert_array_equal(\n        path_start_array, rb.buffers[replay_buffer.ReplayBuffer.PATH_START_KEY])\n\n    # The unrolled indices will be first t2s indices, then t3s.\n    unrolled_indices = [start_index_t2 + x for x in range(n2)\n                       ] + [start_index_t3 + x for x in range(n3)]\n\n    np.testing.assert_array_equal(unrolled_indices, rb.get_unrolled_indices())\n\n    invalid_indices = [start_index_t3 + n3 - 1, start_index_t2 + n2 - 1]\n\n    # Let\'s sample a really large sample.\n    n = 1000\n    sample_valid_indices = rb.sample(n, filter_end=True)\n    sample_all_indices = rb.sample(n, filter_end=False)\n\n    self.assertNotIn(invalid_indices[0], sample_valid_indices)\n    self.assertNotIn(invalid_indices[1], sample_valid_indices)\n\n    # Holds w.h.p.\n    self.assertIn(invalid_indices[0], sample_all_indices)\n    self.assertIn(invalid_indices[1], sample_all_indices)\n\n  def test_valid_indices(self):\n    lens = [10, 5, 7]\n    rb = replay_buffer.ReplayBuffer(lens[0] + lens[1])\n    trajs = [self.get_random_trajectory(max_time_step=l) for l in lens]\n    for traj in trajs:\n      rb.store(traj)\n\n    # Now the buffer looks like [traj3 <gap> traj2]\n    self.assertLess(rb.buffer_head, rb.buffer_tail)\n\n    idx, valid_mask, valid_idx = rb.get_valid_indices()\n\n    np.testing.assert_array_equal(\n        idx, np.array([10, 11, 12, 13, 14, 0, 1, 2, 3, 4, 5, 6]))\n\n    np.testing.assert_array_equal(\n        valid_idx,\n        np.array([[10, 0], [11, 1], [12, 2], [13, 3], [0, 5], [1, 6], [2, 7],\n                  [3, 8], [4, 9], [5, 10]],))\n\n    np.testing.assert_array_equal(\n        valid_mask,\n        np.array([\n            True, True, True, True, False, True, True, True, True, True, True,\n            False\n        ]))\n\n  def test_iteration(self):\n    lens = [10, 5, 7]\n    rb = replay_buffer.ReplayBuffer(lens[0] + lens[1])\n    trajs = [self.get_random_trajectory(max_time_step=l) for l in lens]\n\n    # buffer will have traj0 only.\n    rb.store(trajs[0])\n    idx = rb.get_unrolled_indices()\n    start_end_pairs = [\n        (idx[p[0]], idx[p[1] - 1]) for p in rb.iterate_over_paths(idx)\n    ]\n    self.assertEqual([(0, 9)], start_end_pairs)\n\n    # buffer will have traj0 and traj1.\n    rb.store(trajs[1])\n    idx = rb.get_unrolled_indices()\n    start_end_pairs = [\n        (idx[p[0]], idx[p[1] - 1]) for p in rb.iterate_over_paths(idx)\n    ]\n    self.assertEqual([(0, 9), (10, 14)], start_end_pairs)\n\n    # buffer will have traj1 and traj2, traj0 is booted out.\n    rb.store(trajs[2])\n    idx = rb.get_unrolled_indices()\n    start_end_pairs = [\n        (idx[p[0]], idx[p[1] - 1]) for p in rb.iterate_over_paths(idx)\n    ]\n    self.assertEqual([(10, 14), (0, 6)], start_end_pairs)\n\n\nif __name__ == ""__main__"":\n  absltest.main()\n'"
trax/tf_numpy/extensions/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""JAX-like function transformations and extensions for TF-numpy.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# pylint: disable=wildcard-import\nfrom trax.tf_numpy.extensions.extensions import *\n# pylint: enable=wildcard-import\n'"
trax/tf_numpy/extensions/extensions.py,47,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Extensions such as `jit`, `grad`, `logsumexp`, etc.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport bisect\nimport contextlib\nimport threading\nimport numpy as np\nimport six\n\nimport tensorflow.compat.v2 as tf\n\nimport trax.tf_numpy.numpy as tf_np\n\n_int_dtype_lower_bounds = [\n    -2**63, -2**31, -2**15, -2**7, 0, 2**7, 2**15, 2**31, 2**64\n]\n_int_dtypes = [\n    tf.int64, tf.int32, tf.int16, tf.int8, tf.uint8, tf.uint16, tf.uint32,\n    tf.uint64\n]\n\n\ndef most_precise_int_dtype(x):\n  if not isinstance(x, six.integer_types) or isinstance(x, bool):\n    return None\n  i = bisect.bisect_right(_int_dtype_lower_bounds, x)\n  if i in (0, len(_int_dtype_lower_bounds)):\n    raise ValueError(""Integer %s is out of bounds"" % x)\n  assert len(_int_dtype_lower_bounds) == len(_int_dtypes) + 1\n  return _int_dtypes[i - 1]\n\n\ndef _canonicalize_jit_arg(x):\n  if isinstance(x, tf_np.ndarray):\n    return x.data\n  else:\n    try:\n      # We need to convert `int` to the most precise dtype, otherwise the dtype\n      # of the result may be different from numpy\'s. For example, when a binary\n      # op takes in a Python integer 5 and an array of uint32, numpy will pick\n      # uint32 as 5\'s dtype, while tf.convert_to_tensor will choose int32 which\n      # will cause the two arguments to be promoted to int64. We pick uint8\n      # here, which will be promoted to uint32 by the binary op.\n      # Note that we prefer unsigned int to signed int when both are equally\n      # precise. For example, for 5, we pick uint8 instead of int8. There is no\n      # reason to prefer one to the other, because for each there is a case\n      # where the behavior diverges from numpy. If we prefer signed int,\n      # consider the case where the first operand is 5 and the second is\n      # 2**64-1. Numpy picks uint64 as the result dtype, but because we choose a\n      # signed type for 5 such as int8, the result type will be float64. On the\n      # other hand, if we prefer unsigned int, consider the case where the first\n      # operand is 2**31-1 and the second is -1. Numpy will pick int32, but\n      # because we choose uint32 for 2*32-1, the result will be int64. The root\n      # of the problem is that `jit` converts `int` to tensors (hence committing\n      # to a dtype) too early, when we don\'t have enough information about the\n      # jitted function (e.g. which subset of the arguments should be promoted\n      # together using np.result_type). tf.function doesn\'t have this problem\n      # because it doesn\'t convert `int` to tensors. jax.jit doesn\'t have this\n      # problem because it converts `int` to ""int tracer"" which doesn\'t commit\n      # to a dtype.\n      # TODO(wangpeng): Revisit this design and see whether we can improve `jit`\n      #   and tf.function.\n      dtype = most_precise_int_dtype(x)\n      return tf_np.convert_to_tensor(value=x, dtype=dtype)\n    except (TypeError, ValueError):\n      return x\n\n\ndef _canonicalize_jit_arguments(inp):\n  """"""Canonicalize arguments to be used for jit.\n\n  Args:\n    inp: a nested structure of arguments to be canonicalized (i.e. to be\n      converted to Tensors). Only tf_np.ndarray and things accepted by\n      `tf.convert_to_tensor` will be converted.\n\n  Returns:\n    The canonicalized version.\n  """"""\n  return tf.nest.map_structure(_canonicalize_jit_arg, inp)\n\n\ndef _np_to_tf(inp):\n\n  def f(x):\n    if isinstance(x, tf_np.ndarray):\n      return x.data\n    else:\n      return x\n\n  return tf.nest.map_structure(f, inp)\n\n\ndef _tf_to_np(inp):\n\n  def f(x):\n    if isinstance(x, (tf.Tensor, tf.IndexedSlices)):\n      return tf_np.array(x, copy=False)\n    else:\n      return x\n\n  return tf.nest.map_structure(f, inp)\n\n\ndef stop_gradient(x):\n  return _tf_to_np(tf.nest.map_structure(tf.stop_gradient, _np_to_tf(x)))\n\n\ndef custom_grad(f_vjp, f_original=None):\n  """"""Decorator to define a function with a custom gradient.\n\n  This function is very similar to `tf.custom_gradient`. See the documentation\n  of `tf.custom_gradient` for detailed usage.\n\n  The differences with `tf.custom_gradient` are:\n\n  - All arguments and results are tf_np.ndarrays instead of tensors.\n\n  - The `grad_fn` returned by `f_vjp` accepts and returns nested structures,\n    unlike that in `tf.custom_gradient` which only accepts and returns lists.\n\n  Args:\n    f_vjp: the same as the `f` argument of `tf.custom_gradient`. Note that all\n      inputs and outputs of `f_vjp` and of the `grad_fn` function it returns can\n      be nested structures.\n    f_original: (optional) not used.\n\n  Returns:\n    The same as `tf.custom_gradient`.\n  """"""\n  del f_original\n\n  @tf.custom_gradient\n  def tf_f(*tf_args, **tf_kwargs):\n    np_args = _tf_to_np(tf_args)\n    np_kwargs = _tf_to_np(tf_kwargs)\n    np_y, np_vjp = f_vjp(*np_args, **np_kwargs)\n    tf_y = _np_to_tf(np_y)\n\n    def tf_vjp(*flat_tf_dy):\n      tf_dy = tf.nest.pack_sequence_as(tf_y, flat_tf_dy)\n      np_dy = _tf_to_np(tf_dy)\n      np_dx = np_vjp(np_dy)\n      return tf.nest.flatten(_np_to_tf(np_dx))\n\n    return tf_y, tf_vjp\n\n  def np_f(*args, **kwargs):\n    return _tf_to_np(tf_f(*_np_to_tf(args), **_np_to_tf(kwargs)))\n\n  return np_f\n\n\ndef vjp(f, *primals, has_aux=False):\n  """"""Returns the result and the VJP function of `f`.\n\n  This function returns the result and the vector-Jacobian-product (VJP)\n  function of `f`.\n\n  Args:\n    f: a function from (nested structures of) tf_np.ndarrays to a (nested\n      structure of) tf_np.ndarray. If `has_aux` is True, it should return an\n      extra output.\n    *primals: the inputs to be fed to `f`.\n    has_aux: if True, the second output of `f` will be regarded as an auxiliary,\n      non-differentiable output that will be ignored by the VJP function.\n\n  Returns:\n    A pair `(y, vjpfun)` if `has_aux` is False; a tuple `(y, vjpfun, aux)`\n    otherwise. `y` and `aux` are the outputs of `f`, i.e. `y, aux =\n    f(*primals)`. `vjpfun` is a function `dx = vjpfun(dy)`, where `dy` is the\n    cotengents of `y`, having the same structures, shapes and dtypes as\n    `y`. `dx` is the cotengents of `x`, having the same structures, shapes and\n    dtypes as `x`.\n  """"""\n  tf_primals = _np_to_tf(primals)\n  with tf.GradientTape(persistent=True) as tape:\n    tape.watch(tf.nest.flatten(tf_primals))\n    outputs = f(*primals)\n    if has_aux:\n      np_out, aux = outputs\n    else:\n      np_out = outputs\n    tf_out = _np_to_tf(np_out)\n\n    def _vjp(dy):\n      tf_dy = _np_to_tf(dy)\n      tf_dx = tape.gradient(tf_out, tf_primals, output_gradients=tf_dy)\n      return _tf_to_np(tf_dx)\n\n  if has_aux:\n    ret = (np_out, _vjp, aux)\n  else:\n    ret = (np_out, _vjp)\n  return ret\n\n\n# TODO(wangpeng): match JAX\'s handling of kwargs and non-ndarray args\ndef grad(f, has_aux=False):\n  """"""Returns a function that computes gradient of f.\n\n  Gradients can only be computed through numpy and tensorflow operations and not\n  through python float operations and values.\n\n  Args:\n    f: a function of type (params, *args) -> scalar. \'params\' can be a nested\n      structure (made of lists and tuples) of ndarrays and the gradient is\n      evaluated against it. `scalar` is a scalar ndarray.\n    has_aux: bool, indicates whether fun returns a pair where the first element\n      is considered the output of the mathematical function to be differentiated\n      and the second element is auxiliary data.\n\n  Returns:\n    A gradient function of type (params, *args) -> gradients, where the result\n    \'gradients\' has the same structure and shapes as \'params\'.\n  """"""\n\n  def check_loss_shape(np_loss):\n    if not isinstance(np_loss, tf_np.ndarray):\n      raise ValueError(\n          ""The result of the function to take gradient must be an ndarray."")\n    if not np_loss.data.shape.is_compatible_with([]):\n      raise ValueError(\n          ""The result of the function to take gradient must be a scalar."")\n\n  def _f(params, *args):\n    """"""The gradient function to be returned.""""""\n    tf_params = _np_to_tf(params)\n    with tf.GradientTape() as g:\n      g.watch(tf.nest.flatten(tf_params))\n      outputs = f(params, *args)\n      if has_aux:\n        np_loss, aux = outputs\n      else:\n        np_loss = outputs\n      check_loss_shape(np_loss)\n      tf_grads = g.gradient(np_loss.data, tf_params)\n      if has_aux:\n        res = (tf_grads, aux)\n      else:\n        res = tf_grads\n      return _tf_to_np(res)\n\n  return _f\n\n\n# A workaround for b/121383831\n_orig_result_is_list = threading.local()\n\n\ndef _record_result_type(f):\n  # A wrapper just for setting _orig_result_is_list, as a workaround for\n  # b/121383831\n  def wrapper(*args, **kwargs):\n    res = f(*args, **kwargs)\n    _orig_result_is_list.val = isinstance(res, list)\n    return res\n\n  return wrapper\n\n\ndef jit(f,\n        static_argnums=(),\n        xla_forced_compile=False,\n        input_signature=None,\n        autograph=False):\n  """"""Returns a function that runs a trace-compiled version of `f`.\n\n  A trace-compiled version of a function `f` has the same behavior as `f` (when\n  called with the same ""static arguments"", see below), but runs faster because\n  the whole computation is compiled into a computation graph once which is\n  reused for subsequent executions.\n\n  The trace compilation happens lazily, when the returned function is called for\n  the first time. The compiled function may not be cached implicitly and\n  multiple calls to `jit` may not share the compiled function (see below for\n  ""static"" vs ""dynamic"" arguments).\n\n  Args:\n    f: a function that takes any positional arguments `args` and any keyword\n      arguments `kwargs`. `ndarray`s and things accepted by\n      `tf.convert_to_tensor` in `args` and `kwargs` will be treated as \'dynamic\n      arguments\' in the sense that calling the function with different values\n      for these arguments will not cause retracing. In contrast, arguments of\n      other types in `args` and `kwargs` are treated as \'static arguments\' and\n      calling the function with different values of them will cause\n      re-compiling. Positional arguments whose positions are in `static_argnums`\n      are always treated as static arguments.\n    static_argnums: a tuple of positions of arguments that will be treated as\n      static arguments. Note that as aforementioned, any arguments that were not\n      convertible to tensor will also be static.\n    xla_forced_compile: if true, it will use XLA to force-compile the graph.\n      This requires that the function only contain ops that are XLA compatible.\n    input_signature: a list of `tf.TensorSpec`, as the input signature to\n      control tracing behavior. See the\n      [doc](https://www.tensorflow.org/api_docs/python/tf/function]) of\n        `tf.function` for details.\n    autograph: whether to use autograph to convert Python constructs such as\n      `if` and `while` to their TensorFlow counterparts. See the\n      [doc](https://www.tensorflow.org/api_docs/python/tf/function]) of\n        `tf.function` for details.\n\n  Returns:\n    A trace-compiled version of f.\n  """"""\n\n  @tf.function(input_signature=input_signature, autograph=autograph)\n  def _tf_f(*args, **kwargs):\n    """"""Accelerated function with tensor inputs/outputs.""""""\n    np_args = _tf_to_np(args)\n    kwargs = {k: _tf_to_np(v) for k, v in kwargs.items()}\n    if xla_forced_compile:\n      # Workaround b/121383831\n      f_ = _record_result_type(f)\n      np_out = tf.xla.experimental.compile(lambda: f_(*np_args, **kwargs))\n      # Workaround b/121383831\n      if (isinstance(np_out, list) and len(np_out) == 1 and\n          not _orig_result_is_list.val):\n        np_out = np_out[0]\n    else:\n      np_out = f(*np_args, **kwargs)\n    return _np_to_tf(np_out)\n\n  def _f(*args, **kwargs):\n    args = [\n        _canonicalize_jit_arguments(arg) if i not in static_argnums else arg\n        for i, arg in enumerate(args)\n    ]\n    kwargs = {k: _canonicalize_jit_arguments(v) for k, v in kwargs.items()}\n    tf_out = _tf_f(*args, **kwargs)\n    return _tf_to_np(tf_out)\n\n  _f.tf_function = _tf_f\n\n  return _f\n\n\ndef eval_on_shapes(f, static_argnums=()):\n  """"""Returns a function that evaluates `f` given input shapes and dtypes.\n\n  It transforms function `f` to a function that performs the same computation as\n  `f` but only on shapes and dtypes (a.k.a. shape inference).\n\n  Args:\n    f: the function to be transformed.\n    static_argnums: See documentation of `jit`.\n\n  Returns:\n    A function whose input arguments can be either the same as `f`\'s or only\n    their shapes/dtypes represented by `TensorSpec`, and whose return values are\n    `TensorSpec`s with the same nested structure as `f`\'s return values.\n  """"""\n  # TODO(wangpeng): tf.function could add a knob to turn off materializing the\n  #   graph, so that we don\'t waste computation and memory when we just want\n  #   shape inference.\n  tf_f = jit(f, static_argnums=static_argnums).tf_function\n  # pylint: disable=missing-docstring\n  def f_return(*args):\n\n    def abstractify(x):\n      x = _canonicalize_jit_arg(x)\n      if isinstance(x, (tf.Tensor, tf_np.ndarray)):\n        return tf.TensorSpec(x.shape, x.dtype)\n      else:\n        return x\n\n    def to_tensor_spec(x):\n      if isinstance(x, tf.Tensor):\n        return tf.TensorSpec(x.shape, x.dtype)\n      else:\n        return x\n\n    new_args = []\n    for i, arg in enumerate(args):\n      if i in static_argnums:\n        new_args.append(arg)\n      else:\n        new_args.append(tf.nest.map_structure(abstractify, arg))\n    res = tf_f.get_concrete_function(*new_args).structured_outputs\n\n    return tf.nest.map_structure(to_tensor_spec, res)\n\n  # Provides access to `tf_f` for testing purpose.\n  f_return._tf_function = tf_f  # pylint: disable=protected-access\n  return f_return\n\n\ndef logsumexp(x, axis=None, keepdims=None):\n  """"""Computes log(sum(exp(elements across dimensions of a tensor))).\n\n  Reduces `x` along the dimensions given in `axis`.\n  Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n  entry in `axis`. If `keepdims` is true, the reduced dimensions\n  are retained with length 1.\n  If `axis` has no entries, all dimensions are reduced, and a\n  tensor with a single element is returned.\n  This function is more numerically stable than log(sum(exp(input))). It avoids\n  overflows caused by taking the exp of large inputs and underflows caused by\n  taking the log of small inputs.\n\n  Args:\n    x: The tensor to reduce. Should have numeric type.\n    axis: The dimensions to reduce. If `None` (the default), reduces all\n      dimensions. Must be in the range `[-rank(x), rank(x))`.\n    keepdims: If true, retains reduced dimensions with length 1.\n\n  Returns:\n    The reduced tensor.\n  """"""\n  return tf_np.asarray(\n      tf.math.reduce_logsumexp(\n          input_tensor=x.data, axis=axis, keepdims=keepdims))\n\n\ndef expit(x):\n  """"""Compute 1 / (1 + exp(-x)).""""""\n  return tf_np.asarray(tf.math.sigmoid(x.data))\n\n\ndef erf(x):\n  """"""Computes the Gauss error function of x element-wise.""""""\n  return tf_np.asarray(tf.math.erf(x.data))\n\n\ndef conv(inp,\n         fltr,\n         window_strides,\n         padding,\n         dimension_numbers,\n         filter_dilation=None):\n  """"""Convolution over an N-D array.\n\n  See https://www.tensorflow.org/api_docs/python/tf/nn/convolution and\n  https://www.tensorflow.org/xla/operation_semantics#conv_convolution for\n  reference.\n\n  Args:\n    inp: an (N+2)-D array. The input of the convolution.\n    fltr: an (N+2)-D array. The filter (i.e. kernel) of the convolution.\n    window_strides: a sequence of N ints, the strides for moving the convolution\n      window.\n    padding: a string, either ""VALID"" or ""SAME"". The padding algorithm.\n    dimension_numbers: a tuple of three strings encoding the data format of\n      input, filter and output. ""I"" means input; ""O"" means output; ""C"" means\n      channel; other characters such as ""W"", ""H"" and ""D"" means spatial\n      dimensions.\n    filter_dilation: the dilation rates for the filter. Dilating the filter\n      means adding ""holes"" to the filter.\n\n  Returns:\n    An (N+2)-D array. The convolution result.\n  """"""\n  input_spec, filter_spec, output_spec = dimension_numbers\n  if input_spec != output_spec:\n    raise ValueError(""Input and output data formats must be the same; got %s ""\n                     ""and %s"" % (input_spec, output_spec))\n  supported_filter_spec = [""WIO"", ""HWIO"", ""DHWIO""]\n  if filter_spec not in supported_filter_spec:\n    raise ValueError(""The supported data format for the filter are %s; got %s"" %\n                     (supported_filter_spec, filter_spec))\n  if input_spec[1:-1] != filter_spec[:-2]:\n    raise ValueError(""Input data format (%s) is not compatible with filter ""\n                     ""data format (%s)"" % (input_spec, filter_spec))\n  # No type promotion in order to prevent accidentally doing more expensive\n  # computation.\n  inp = tf_np.asarray(inp)\n  fltr = tf_np.asarray(fltr)\n  return tf_np.asarray(\n      tf.nn.convolution(\n          input=inp.data,\n          filters=fltr.data,\n          padding=padding,\n          strides=window_strides,\n          dilations=filter_dilation,\n          data_format=input_spec))\n\n\ndef avg_pool(x, pool_size, strides, padding):\n  """"""Performs an N-D average pooling.\n\n  Args:\n    x: ndarray of rank N+2, of shape `[batch_size] + input_spatial_shape +\n      [num_channels]`. Pooling happens over the spatial dimensions only.\n    pool_size: sequence of N ints.\n    strides: sequence of N ints.\n    padding: a string, the padding algorithm. Must be ""SAME"" or ""VALID"".\n\n  Returns:\n    An (N+2)-D array,  of shape\n      [batch_size] + output_spatial_shape + [num_channels],\n    where `output_spatial_shape` depends on the value of padding:\n    If padding = ""SAME"":\n      output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i])\n    If padding = ""VALID"":\n      output_spatial_shape[i] =\n        ceil((input_spatial_shape[i] - (pool_size[i] - 1)) / strides[i]).\n  """"""\n  x = tf_np.asarray(x)\n  return tf_np.asarray(\n      tf.nn.pool(\n          input=x,\n          window_shape=pool_size,\n          pooling_type=""AVG"",\n          strides=strides,\n          padding=padding))\n\n\ndef max_pool(x, pool_size, strides, padding):\n  """"""Performs an N-D max pooling.\n\n  Args:\n    x: ndarray of rank N+2, of shape `[batch_size] + input_spatial_shape +\n      [num_channels]`. Pooling happens over the spatial dimensions only.\n    pool_size: sequence of N ints.\n    strides: sequence of N ints.\n    padding: a string, the padding algorithm. Must be ""SAME"" or ""VALID"".\n\n  Returns:\n    An (N+2)-D array,  of shape\n      [batch_size] + output_spatial_shape + [num_channels],\n    where `output_spatial_shape` depends on the value of padding:\n    If padding = ""SAME"":\n      output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i])\n    If padding = ""VALID"":\n      output_spatial_shape[i] =\n        ceil((input_spatial_shape[i] - (pool_size[i] - 1)) / strides[i]).\n  """"""\n  x = tf_np.asarray(x)\n  return tf_np.asarray(\n      tf.nn.pool(\n          input=x,\n          window_shape=pool_size,\n          pooling_type=""MAX"",\n          strides=strides,\n          padding=padding))\n\n\ndef sort_key_val(keys, values, dimension=-1):\n  """"""Sorts keys along a dimension and applies same permutation to values.\n\n  Args:\n    keys: an array. The dtype must be comparable numbers (integers and reals).\n    values: an array, with the same shape of `keys`.\n    dimension: an `int`. The dimension along which to sort.\n\n  Returns:\n    Permuted keys and values.\n  """"""\n  keys = tf_np.asarray(keys)\n  values = tf_np.asarray(values)\n  rank = keys.ndim\n  if rank is None:\n    rank = values.ndim\n  if rank is None:\n    # We need to know the rank because tf.gather requires batch_dims to be `int`\n    raise ValueError(""The rank of either keys or values must be known, but ""\n                     ""both are unknown (i.e. their shapes are both None)."")\n  if dimension in (-1, rank - 1):\n    def maybe_swapaxes(a):\n      return a\n  else:\n    def maybe_swapaxes(a):\n      return tf_np.swapaxes(a, dimension, -1)\n  # We need to swap axes because tf.gather (and tf.gather_nd) supports\n  # batch_dims on the left but not on the right.\n  # TODO(wangpeng): Investigate whether we should do swapaxes or moveaxis.\n  keys = maybe_swapaxes(keys)\n  values = maybe_swapaxes(values)\n  idxs = tf_np.argsort(keys)\n  idxs = idxs.data\n  # Using tf.gather rather than np.take because the former supports batch_dims\n  def gather(a):\n    return tf_np.asarray(tf.gather(a.data, idxs, batch_dims=rank-1))\n  keys = gather(keys)\n  values = gather(values)\n  keys = maybe_swapaxes(keys)\n  values = maybe_swapaxes(values)\n  return keys, values\n\n\n# Use int64 instead of int32 to avoid TF\'s ""int32 problem""\n_RNG_KEY_DTYPE = np.int64\n\n\ndef _key2seed(a):\n  """"""Converts an RNG key to an RNG seed.\n\n  Args:\n    a: an RNG key, an ndarray of shape [] and dtype `np.int64`.\n\n  Returns:\n    an RNG seed, a tensor of shape [2] and dtype `tf.int32`.\n  """"""\n\n  def int64_to_int32s(a):\n    """"""Converts an int64 tensor of shape [] to an int32 tensor of shape [2].""""""\n    a = tf.cast(a, tf.uint64)\n    fst = tf.cast(a, tf.uint32)\n    snd = tf.cast(\n        tf.bitwise.right_shift(a, tf.constant(32, tf.uint64)), tf.uint32)\n    a = [fst, snd]\n    a = tf.nest.map_structure(lambda x: tf.cast(x, tf.int32), a)\n    a = tf.stack(a)\n    return a\n\n  return int64_to_int32s(a.data)\n\n\ndef _seed2key(a):\n  """"""Converts an RNG seed to an RNG key.\n\n  Args:\n    a: an RNG seed, a tensor of shape [2] and dtype `tf.int32`.\n\n  Returns:\n    an RNG key, an ndarray of shape [] and dtype `np.int64`.\n  """"""\n\n  def int32s_to_int64(a):\n    """"""Converts an int32 tensor of shape [2] to an int64 tensor of shape [].""""""\n    a = tf.bitwise.bitwise_or(\n        tf.cast(a[0], tf.uint64),\n        tf.bitwise.left_shift(\n            tf.cast(a[1], tf.uint64), tf.constant(32, tf.uint64)))\n    a = tf.cast(a, tf.int64)\n    return a\n\n  return tf_np.asarray(int32s_to_int64(a))\n\n\ndef prng(s):\n  """"""Creates RNG state from seed.\n\n  Args:\n    s: the seed, an integer.\n\n  Returns:\n    An RNG state, as a scalar array of dtype `np.int64`.\n  """"""\n  # TODO(wangpeng): Become bitwise-identical to JAX when TF stateless RNGs get\n  #   improved.\n  return tf_np.asarray(s, dtype=_RNG_KEY_DTYPE)\n\n\ndef split(state, num):\n  """"""Creates new independent RNG states from an existing state.\n\n  Args:\n    state: the existing state.\n    num: the number of the new states.\n\n  Returns:\n    A tuple of new states.\n  """"""\n  state = tf_np.asarray(state, dtype=_RNG_KEY_DTYPE)\n  state = _key2seed(state)\n  states = tf.random.experimental.stateless_split(state, num)\n  states = tf.unstack(states, num)\n  states = tf.nest.map_structure(_seed2key, states)\n  return states\n\n\ndef uniform(key,\n            shape,\n            dtype=tf_np.random.DEFAULT_RANDN_DTYPE,\n            minval=0.,\n            maxval=1.):\n  """"""Sample uniform random values in range [`minval`, `maxval`).\n\n  Args:\n    key: the RNG key.\n    shape: the shape of the result.\n    dtype: the dtype of the result.\n    minval: the minimal value (inclusive).\n    maxval: the maximal value (exclusive).\n\n  Returns:\n    An ndarray with shape `shape` and dtype `dtype`. Each value in the ndarray\n    is sampled uniformly randomly in range [`minval`, `maxval`).\n  """"""\n  key = tf_np.asarray(key, dtype=_RNG_KEY_DTYPE)\n  return tf_np.asarray(\n      tf.random.stateless_uniform(\n          shape, seed=_key2seed(key), dtype=dtype, minval=minval,\n          maxval=maxval))\n\n\ndef normal(key, shape, dtype=tf.float32):\n  """"""Sample standard-normal random values.\n\n  Args:\n    key: the RNG key.\n    shape: the shape of the result.\n    dtype: the dtype of the result.\n\n  Returns:\n    Random values in standard-normal distribution.\n  """"""\n  key = tf_np.asarray(key, dtype=_RNG_KEY_DTYPE)\n  return tf_np.asarray(\n      tf.random.stateless_normal(shape, seed=_key2seed(key), dtype=dtype))\n\n\ndef bernoulli(key, mean=np.float32(0.5), shape=None):\n  """"""Sample Bernoulli random values with given shape and mean.\n\n  Args:\n    key: the RNG key.\n    mean: optional, an array_like broadcastable to `shape` for the mean of the\n      random variables (default 0.5).\n    shape: optional, a tuple of nonnegative integers representing the shape\n      (default to `mean`\'s shape).\n\n  Returns:\n    A random array with the specified shape and boolean dtype.\n  """"""\n  mean = tf_np.asarray(mean)\n  if shape is None:\n    shape = mean.shape\n  return uniform(key, shape) < mean\n\n\ndef _eager_dataset_iterator(dataset):\n  for item in dataset:\n    yield tf.nest.map_structure(tf_np.asarray, item)\n\n\ndef dataset_as_numpy(dataset):\n  """"""Converts a `tf.data.Dataset` to an iterable of ndarrays.\n\n  `dataset_as_numpy` converts a possibly nested structure of `tf.data.Dataset`s\n  and `tf.Tensor`s to iterables of ndarrays and ndarrays, respectively. This\n  function must be run in eager mode outside tf.function.\n\n  Args:\n    dataset: a possibly nested structure of `tf.data.Dataset`s and/or\n      `tf.Tensor`s.\n\n  Returns:\n    A structure matching `dataset` where `tf.data.Dataset`s are converted to\n    generators of ndarrays and `tf.Tensor`s are converted to ndarrays.\n  """"""\n  if not tf.executing_eagerly():\n    raise ValueError(\n        ""dataset_as_numpy must be run in eager mode outside tf.function"")\n  nested_ds = dataset\n  del dataset\n\n  # Flatten\n  flat_ds = tf.nest.flatten(nested_ds)\n  flat_np = []\n\n  # Type check for Tensors and Datasets\n  for ds_el in flat_ds:\n    if not isinstance(ds_el, (tf.Tensor, tf.data.Dataset)):\n      types = tf.nest.map_structure(type, nested_ds)\n      raise ValueError(""Arguments to dataset_as_numpy must be (possibly nested ""\n                       ""structure of) tf.Tensors or tf.data.Datasets. Got: %s"" %\n                       types)\n\n  for ds_el in flat_ds:\n    if isinstance(ds_el, tf.Tensor):\n      np_el = tf_np.asarray(ds_el)\n    elif isinstance(ds_el, tf.data.Dataset):\n      np_el = _eager_dataset_iterator(ds_el)\n    else:\n      assert False\n    flat_np.append(np_el)\n\n  return tf.nest.pack_sequence_as(nested_ds, flat_np)\n\n\n# TODO(nareshmodi): Group key should change based on the set of devices that we\n# are mapping over. Make it so that we assign a unique group_key for every\n# unique set of devices. We don\'t change it every time to avoid the overhead of\n# discovering the full group (though may not be problematic in the local case).\n_GROUP_KEY = 1\n_INSTANCE_KEY = 0\n_INSTANCE_LOCK = threading.Lock()\n\n\n# TODO(b/142565636): Ensure that multiple concurrent calls to a tf.function\n# containing a collective op run reasonably.\ndef _get_instance_key():\n  global _INSTANCE_KEY\n  global _INSTANCE_LOCK\n  with _INSTANCE_LOCK:\n    _INSTANCE_KEY = _INSTANCE_KEY + 1\n    return _INSTANCE_KEY\n\n\nclass _PmapConfig(threading.local):\n  """"""Simple config used to maintain state related to a current pmap call.""""""\n\n  def __init__(self):\n    super(_PmapConfig, self).__init__()\n    self._axis_name = None\n    self._devices = None\n\n  def axis_name(self):\n    return self._axis_name\n\n  def set_axis_name(self, axis_name):\n    self._axis_name = axis_name\n\n  def devices(self):\n    return self._devices\n\n  def set_devices(self, devices):\n    self._devices = devices\n\n\n_pmap_config = _PmapConfig()\n\n\n@contextlib.contextmanager\ndef pmap_config(axis_name, devices):\n  """"""Records axis_name and devices for this context.""""""\n  old_axis_name = _pmap_config.axis_name()\n  old_devices = _pmap_config.devices()\n  _pmap_config.set_axis_name(axis_name)\n  _pmap_config.set_devices(devices)\n  try:\n    yield\n  finally:\n    _pmap_config.set_axis_name(old_axis_name)\n    _pmap_config.set_devices(old_devices)\n\n\ndef psum(tensor, axis_name=None):\n  """"""Sum all-reduction.\n\n  Args:\n    tensor: A tensor.\n    axis_name: The axis name to reduce. Must equal to that of the surrounding\n      pmap.\n\n  Returns:\n    The sum of the `tensor` replicas on each participating devices.\n  """"""\n  if axis_name != _pmap_config.axis_name():\n    raise ValueError(""axis_name (%s) is not equal to that of the surrounding ""\n                     ""pmap (%s)"" % (axis_name, _pmap_config.axis_name()))\n  devices = _pmap_config.devices()\n  if devices is None:\n    raise ValueError(""Can\'t retrieve the device list from the surrounding pmap"")\n  if tpu_devices(devices):\n    # TODO(wangpeng): Supply the `group_assignment` argument to\n    # tpu.cross_replica_sum, calculated from `devices`.\n    return tf.compat.v1.tpu.cross_replica_sum(tensor)\n  else:\n    return tf.raw_ops.CollectiveReduce(\n        input=tensor.data,\n        group_size=len(devices),\n        group_key=_GROUP_KEY,\n        instance_key=_get_instance_key(),\n        merge_op=""Add"",\n        final_op=""Id"",\n        subdiv_offsets=(0,))\n\n\n# Note this is not available in the jax api, but seemed like a reasonable API\n# to have.\ndef pmean(tensor, axis_name=None):\n  """"""Mean all-reduction.\n\n  Args:\n    tensor: A tensor.\n    axis_name: The axis name to reduce. Must equal to that of the surrounding\n      pmap.\n\n  Returns:\n    The mean of the `tensor` replicas on each participating devices.\n  """"""\n  if axis_name != _pmap_config.axis_name():\n    raise ValueError(""axis_name (%s) is not equal to that of the surrounding ""\n                     ""pmap (%s)"" % (axis_name, _pmap_config.axis_name()))\n  devices = _pmap_config.devices()\n  if devices is None:\n    raise ValueError(""Can\'t retrieve the device list from the surrounding pmap"")\n  if tpu_devices(devices):\n    # TODO(wangpeng): Implement this.\n    raise ValueError(""pmean for TPU is not supported yet."")\n  else:\n    return tf.raw_ops.CollectiveReduce(\n        input=tensor.data,\n        group_size=len(devices),\n        group_key=_GROUP_KEY,\n        instance_key=_get_instance_key(),\n        merge_op=""Add"",\n        final_op=""Div"",\n        subdiv_offsets=(0,))\n\n\ndef _get_pmap_impl(f, devices, has_tpu):\n  """"""This is a helper function to return the pmap impl.\n\n  Args:\n    f: a function that takes ndarrays and returns ndarrays.\n    devices: a list of strings; the device list.\n    has_tpu: boolean; whether `devices` contains TPU devices.\n\n  Returns:\n    A function that takes tensors and returns tensors.\n  """"""\n  if has_tpu:\n    # Workaround b/121383831\n    f = _record_result_type(f)\n\n  def tf_f(*tf_args):\n    """"""A wrapper for `f` that takes/returns tensors.""""""\n    np_args = _tf_to_np(tf_args)\n    np_out = f(*np_args)\n    return _np_to_tf(np_out)\n\n  if has_tpu:\n\n    @tf.function(autograph=False)\n    def fn(inputs):\n      # TODO(wangpeng): Supply the `device_assignment` argument to\n      # tpu.replicate, calculated from `devices`.\n      return tf.compat.v1.tpu.replicate(tf_f, inputs)\n\n    return fn\n  else:\n    # This is run in a tf.function so that the various underlying functions can\n    # be run in parallel.\n    # The trace happens on the client, so any devices should not depend on any\n    # side effects.\n\n    jit_tf_f = tf.function(tf_f, autograph=False)\n\n    @tf.function(autograph=False)\n    def fn(all_per_device_args):\n      """"""Multi-device function with calls placed on the correct device.""""""\n\n      results = []\n      for per_device_args, device in zip(all_per_device_args, devices):\n        with tf.device(device):\n          results.append(jit_tf_f(*per_device_args))\n      return results\n\n    return fn\n\n\ndef pmap(f, axis_name=None, devices=None):\n  """"""Transforms a function into a multi-device function.\n\n  The semantics are similar to JAX\'s pmap.\n\n  Args:\n    f: The function to be converted.\n    axis_name: Used for nested pmap, which is not supported yet.\n    devices: The devices over which the returned function will run.\n\n  Returns:\n    A function that runs the underlying function `f` on `devices`. Its arguments\n    can be `ShardedNdArray`s, tensors or other Python objects, and its return\n    values are all `ShardedNdArray`s. If an input is a tensor, the length of its\n    first dimension must equal the number of devices, and the tensor will be\n    splitted along its first dimension among the devices. If an input is an\n    unknown Python object, it will be replicated among the devices.\n  """"""\n  if devices is None:\n    devices = accelerators()\n  if not isinstance(devices, (list, tuple)):\n    raise ValueError(""Must pass a list or tuple of devices"")\n  num_devices = len(devices)\n  if not num_devices:\n    raise ValueError(""There must be at least 1 device"")\n  has_tpu = bool(tpu_devices(devices))\n\n  pmap_fn = _get_pmap_impl(f, devices, has_tpu)\n\n  def wrapper(*args):\n    """"""Wrapper that wraps/unwraps args, retvals, and runs the function.""""""\n    if _pmap_config.devices() is not None:\n      raise ValueError(""Found a surrounding pmap. Nested pmap is not supported ""\n                       ""yet."")\n    # TODO(wangpeng): Maybe we should use `asarray` to convert everything\n    # to ndarray first.\n    args = _np_to_tf(args)\n\n    flattened_input_args = tf.nest.flatten(args)\n    flattened_per_device_args = [[] for _ in devices]\n    for arg in flattened_input_args:\n      if isinstance(arg, tf.Tensor):\n        # TODO(nareshmodi): Try and use the dynamic shape instead.\n        if (not arg.shape.rank) or arg.shape[0] != len(devices):\n          # TODO(nareshmodi): Fix this restriction\n          raise ValueError(\n              ""Input tensors need to have a first dimension equal to ""\n              ""the number of devices; got tensor of shape %s and %s devices"" %\n              (arg.shape, len(devices)))\n        # NOTE: Alternatively use tf.split, and place the split tensors on the\n        # appropriate device. The best solution for this is to have an API that\n        # splits a tensor across devices.\n        for j, device in enumerate(devices):\n          updated_arg = tf.gather(arg, j)\n          # TODO(wangpeng): Investigate whether we need a tf.identity for TPU.\n          if not has_tpu:\n            with tf.device(device):\n              updated_arg = tf.identity(updated_arg)\n          flattened_per_device_args[j].append(updated_arg)\n      elif isinstance(arg, tf_np.ShardedNdArray):\n        for device_args, tensor in zip(flattened_per_device_args, arg.tensors):\n          device_args.append(tensor)\n      else:\n        for device_args in flattened_per_device_args:\n          device_args.append(arg)\n\n    all_per_device_args = [\n        tf.nest.pack_sequence_as(args, device_args)\n        for device_args in flattened_per_device_args\n    ]\n\n    with pmap_config(axis_name, devices):\n      results = pmap_fn(all_per_device_args)\n\n    # Rewrap things. This can probably be written better.\n    flattened_results = [tf.nest.flatten(result) for result in results]\n    final_tree = []\n\n    # TODO(nareshmodi): assert all items in flattened_results have the same\n    # structures\n\n    for i in range(len(flattened_results[0])):\n      tensors = []\n      for j, device in enumerate(devices):\n        assert isinstance(\n            flattened_results[j][i],\n            tf.Tensor), (""currently only tensor return items are supported"")\n        tensors.append(flattened_results[j][i])\n      final_tree.append(tf_np.ShardedNdArray(tensors))\n\n    final_actual_result = tf.nest.pack_sequence_as(results[0], final_tree)\n\n    # Workaround b/121383831\n    if (has_tpu and isinstance(final_actual_result, list) and\n        len(final_actual_result) == 1) and not _orig_result_is_list.val:\n      return final_actual_result[0]\n    else:\n      return final_actual_result\n\n  return wrapper\n\n\ndef find_devices(device_type, devices=None):\n  if not devices:\n    devices = [d.name for d in tf.config.experimental.list_logical_devices()]\n  devices = [(d, tf.DeviceSpec.from_string(d)) for d in devices]\n  results = [name for name, d in devices if d.device_type == device_type]\n  return results\n\n\ndef tpu_devices(devices=None):\n  """"""Gets TPU devices out of `devices`.\n\n  Args:\n    devices: A device list (as a list of strings). If None, the list of all\n      available devices will be used for it.\n\n  Returns:\n    Those in `devices` that are TPUs.\n  """"""\n  return find_devices(""TPU"", devices)\n\n\ndef gpu_devices(devices=None):\n  """"""Gets GPU devices out of `devices`.\n\n  Args:\n    devices: A device list (as a list of strings). If None, the list of all\n      available devices will be used for it.\n\n  Returns:\n    Those in `devices` that are GPUs.\n  """"""\n  return find_devices(""GPU"", devices)\n\n\ndef accelerators(devices=None):\n  return tpu_devices(devices) or gpu_devices(devices)\n'"
trax/tf_numpy/extensions/extensions_test.py,49,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for tf numpy mathematical methods.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nfrom absl import flags\nfrom absl.testing import parameterized\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy import extensions\nimport trax.tf_numpy.numpy as tf_np\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_bool(""requires_tpu"", False, ""Requires TPU."")\n\n\ndef generate_params_inputs_targets(num_examples=1000):\n  params = (tf_np.tensor_to_ndarray(tf.constant(5.)),\n            tf_np.tensor_to_ndarray(tf.constant(0.)))\n\n  params_true = (tf_np.tensor_to_ndarray(tf.constant(3.)),\n                 tf_np.tensor_to_ndarray(tf.constant(2.)))\n\n  inputs = tf_np.tensor_to_ndarray(tf.random.normal(shape=[num_examples]))\n  noise = tf_np.tensor_to_ndarray(tf.random.normal(shape=[num_examples]))\n  targets = inputs * params_true[0] + params_true[1] + noise\n\n  return params, params_true, inputs, targets\n\n\ndef loss_fn(params, inputs, targets):\n  predicted = params[0] * inputs + params[1]\n  loss = tf.reduce_mean(input_tensor=tf.square(predicted - targets))\n  return tf_np.tensor_to_ndarray(loss)\n\n\ndef train_step(params, inputs, targets, learning_rate=0.1):\n  grad_fn = extensions.grad(loss_fn)\n  grads = grad_fn(params, inputs, targets)\n  new_w = params[0] - (grads[0] * learning_rate)\n  new_b = params[1] - (grads[1] * learning_rate)\n\n  return new_w, new_b\n\n\ndef uniform(rng, shape, dtype):\n  if np.issubdtype(dtype, np.integer):\n    minval = None\n  else:\n    minval = 0\n  return tf_np.asarray(rng.uniform(shape=shape, dtype=dtype, minval=minval))\n\n\ndef to_tf(a):\n  return tf.nest.map_structure(lambda x: x.data, a)\n\n\nclass ExtensionsTest(tf.test.TestCase, parameterized.TestCase):\n\n  def __init__(self, methodName=""runTest""):  # pylint: disable=invalid-name\n    super(ExtensionsTest, self).__init__(methodName)\n    physical_devices = tf.config.experimental.list_physical_devices(""CPU"")\n    tf.config.experimental.set_virtual_device_configuration(\n        physical_devices[0], [\n            tf.config.experimental.VirtualDeviceConfiguration(),\n            tf.config.experimental.VirtualDeviceConfiguration()\n        ])\n    if extensions.tpu_devices():\n      resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=""local"")\n      tf.tpu.experimental.initialize_tpu_system(resolver)\n\n  def _hasGPU(self):\n    physical_devices = tf.config.experimental.list_physical_devices(""GPU"")\n    return physical_devices\n\n  def testCustomGrad(self):\n    """"""Test for custom_grad.""""""\n    x_shape = (tf.TensorShape([10]), tf.TensorShape([1, 10]))\n    y_shape = (tf.TensorShape([]))\n    dtype = np.float32\n    scale1 = 5.0\n    scale2 = 6.0\n\n    def fwd(a, b):\n      return tf_np.sum(tf_np.sqrt(tf_np.exp(a)) + b)\n\n    @extensions.custom_grad\n    def f(a, b):\n      y = fwd(a, b)\n\n      def vjp(dy):\n        return dy * scale1 * a, dy * scale2 * b\n\n      return y, vjp\n\n    rng = tf.random.Generator.from_seed(1234)\n    x, dy = tf.nest.map_structure(lambda shape: uniform(rng, shape, dtype),\n                                  [x_shape, y_shape])\n    expected_y = fwd(*x)\n    expected_dx = (dy * scale1 * x[0], dy * scale2 * x[1])\n    y, vjp = extensions.vjp(f, *x)\n    dx = vjp(dy)\n    self.assertAllClose(to_tf(expected_y), to_tf(y))\n    self.assertAllClose(to_tf(expected_dx), to_tf(dx))\n\n  @parameterized.named_parameters([\n      (  # pylint: disable=g-complex-comprehension\n          (\n              ""_%s_%s_%s"" % (\n                  decorator_id,\n                  x_struct,\n                  y_struct)).replace("" "", """").replace(""None"", """"),\n          decorator,\n          x_struct,\n          y_struct)\n      for y_struct in [[None, ()], (None, (), [], (None, ((), None)))]\n      for x_struct in [(None, ()), (((), ()), [None, None], [], (None, ()))]\n      for decorator_id, decorator in enumerate([lambda f: f, extensions.jit])\n  ])\n  def testCustomGradStructure(self, decorator, x_struct, y_struct):\n    """"""Tests that custom_grad can handle structured inputs/outputs.""""""\n\n    def zeros(x):\n      return tf.nest.map_structure(lambda _: tf_np.zeros([], np.float32), x)\n\n    def get_struct(x):\n      return tf.nest.map_structure(lambda _: None, x)\n\n    @extensions.custom_grad\n    def f(*x):\n      del x\n\n      def vjp(dy):\n        self.assertEqual(y_struct, get_struct(dy))\n        return zeros(x_struct)\n\n      return zeros(y_struct), vjp\n\n    x, dy = zeros([x_struct, y_struct])\n\n    @decorator\n    def run(x, dy):\n      y, vjp = extensions.vjp(f, *x)\n      dx = vjp(dy)\n      return dx, y\n\n    dx, y = run(x, dy)\n    self.assertEqual(x_struct, get_struct(dx))\n    self.assertEqual(y_struct, get_struct(y))\n\n  @parameterized.named_parameters([\n      (""_%s"" % has_aux, has_aux) for has_aux in [True, False]\n  ])\n  def testVjp(self, has_aux):\n    x_shape = (tf.TensorShape([10]), tf.TensorShape([1, 10]))\n    y_shape = (tf.TensorShape([]))\n    dtype = np.float32\n\n    def f(a, b):\n      y = tf_np.sum(tf_np.sqrt(tf_np.exp(a)) + b)\n      if has_aux:\n        return y, tf_np.asarray(1)\n      else:\n        return y\n\n    rng = tf.random.Generator.from_seed(1234)\n    x, dy_list = tf.nest.map_structure(lambda shape: uniform(rng, shape, dtype),\n                                       [x_shape, [y_shape] * 2])\n    tf_x = to_tf(x)\n    outputs = extensions.vjp(f, *x, has_aux=has_aux)\n    if has_aux:\n      y, vjp, aux = outputs\n    else:\n      y, vjp = outputs\n    with tf.GradientTape(persistent=True) as tape:\n      tape.watch(tf_x)\n      outputs = f(*x)\n      if has_aux:\n        expected_y, expected_aux = outputs\n        self.assertAllClose(to_tf(expected_aux), to_tf(aux))\n      else:\n        expected_y = outputs\n    self.assertAllClose(to_tf(expected_y), to_tf(y))\n    for dy in dy_list:\n      expected_dx = tape.gradient(\n          to_tf(expected_y), tf_x, output_gradients=to_tf(dy))\n      self.assertAllClose(expected_dx, to_tf(vjp(dy)))\n\n  def testGrad(self):\n\n    def f(a, b):\n      return tf_np.sum(tf_np.sqrt(tf_np.exp(a)) + b)\n\n    g = extensions.grad(f)\n\n    def compare(a, b):\n      with tf.GradientTape() as tape:\n        tape.watch(a.data)\n        r = f(a, b)\n      expected = tape.gradient(r.data, a.data)\n      self.assertAllEqual(expected, g(a, b))\n\n    shape = [10]\n    a = tf_np.random.randn(*shape)\n    b = tf_np.random.randn(*shape)\n    compare(a, b)\n\n  def testGradNonArrayOutput(self):\n\n    def f(_):\n      return 1.0\n\n    g = extensions.grad(f)\n    with self.assertRaisesWithPredicateMatch(ValueError,\n                                             r""result .* must be an ndarray""):\n      g(tf_np.asarray(1.0))\n\n  def testGradNonScalarOutput(self):\n\n    def f(a):\n      return a\n\n    g = extensions.grad(f)\n    with self.assertRaisesWithPredicateMatch(ValueError,\n                                             r""result .* must be a scalar""):\n      g(tf_np.asarray([1.0, 2.0]))\n\n    @extensions.jit\n    def g_jitted(a):\n      return extensions.grad(f)(a)\n\n    g_jitted(tf_np.asarray(1.0))\n    with self.assertRaisesWithPredicateMatch(ValueError,\n                                             r""result .* must be a scalar""):\n      g_jitted(tf_np.asarray([1.0, 2.0]))\n\n  def testJit(self):\n\n    def f(a, b):\n      return tf_np.sum(tf_np.sqrt(tf_np.exp(a)) + b)\n\n    f_jitted = extensions.jit(f)\n    shape = [10]\n    a = tf_np.random.randn(*shape)\n    b = tf_np.random.randn(*shape)\n    self.assertAllClose(f(a, b), f_jitted(a, b))\n    # Call again since the code path is different on second call\n    self.assertAllClose(f(a, b), f_jitted(a, b))\n\n  def testJitNoUnnecessaryTracing(self):\n\n    def num_traces(f):\n      return len(f.tf_function._list_all_concrete_functions_for_serialization())\n\n    def check_trace_only_once(arg1, arg2):\n\n      @extensions.jit\n      def f(a):\n        return a + 1\n\n      self.assertAllEqual(0, num_traces(f))\n      f(arg1)\n      self.assertAllEqual(1, num_traces(f))\n      f(arg2)\n      self.assertAllEqual(1, num_traces(f))\n\n    check_trace_only_once(1, 2)\n    check_trace_only_once(1.1, 2.1)\n    check_trace_only_once(tf_np.asarray(1), tf_np.asarray(2))\n    check_trace_only_once(\n        tf.convert_to_tensor(value=1), tf.convert_to_tensor(value=2))\n\n  def _testEvalOnShapes(self, transformer):\n\n    def f(a, b):\n      return tf_np.sum(tf_np.sqrt(tf_np.exp(a)) + b)\n\n    f_prime = transformer(f)\n    shape = [10]\n    dtype = np.float16\n    a = tf_np.zeros(shape=shape, dtype=dtype)\n    b = tf_np.zeros(shape=shape, dtype=dtype)\n    expected = f(a, b)\n    got = f_prime(a, b)\n    self.assertAllEqual(expected.shape, got.shape)\n    self.assertAllEqual(expected.dtype, got.dtype)\n    # Call again since the code path is different on second call\n    got = f_prime(a, b)\n    self.assertAllEqual(expected.shape, got.shape)\n    self.assertAllEqual(expected.dtype, got.dtype)\n\n  def testEvalOnShapes(self):\n\n    def transformer(f):\n      return extensions.eval_on_shapes(f)\n\n    self._testEvalOnShapes(transformer)\n\n  def testJitOfEvalOnShapes(self):\n    """"""Tests that eval_on_shapes can be called within jit.""""""\n\n    def transformer(f):\n\n      @extensions.jit\n      def f_prime(a, b):\n        shape_dtype = extensions.eval_on_shapes(f)(a, b)\n        return tf_np.zeros(shape=shape_dtype.shape, dtype=shape_dtype.dtype)\n\n      return f_prime\n\n    self._testEvalOnShapes(transformer)\n\n  def testEvalOnShapesNoUnnecessaryTracing(self):\n\n    def num_traces(f):\n      return len(\n          f._tf_function._list_all_concrete_functions_for_serialization())\n\n    def check_trace_only_once(arg1, arg2):\n\n      @extensions.eval_on_shapes\n      def f(a):\n        return a + 1\n\n      self.assertAllEqual(0, num_traces(f))\n      f(arg1)\n      self.assertAllEqual(1, num_traces(f))\n      f(arg2)\n      self.assertAllEqual(1, num_traces(f))\n\n    check_trace_only_once(1, 2)\n    check_trace_only_once(1.1, 2.1)\n    check_trace_only_once(tf_np.asarray(1), tf_np.asarray(2))\n    check_trace_only_once(\n        tf.convert_to_tensor(value=1), tf.convert_to_tensor(value=2))\n\n  def testConv(self):\n    y = extensions.conv(\n        np.ones([5, 320, 480, 3], dtype=np.float32),\n        np.ones([3, 4, 3, 11], dtype=np.float32), [1, 1], ""SAME"",\n        (""NHWC"", ""HWIO"", ""NHWC""))\n    self.assertAllClose(y.shape, [5, 320, 480, 11])\n    self.assertAllClose(\n        y,\n        tf.nn.conv2d(\n            input=tf.ones([5, 320, 480, 3], dtype=tf.float32),\n            filters=tf.ones([3, 4, 3, 11], dtype=tf.float32),\n            strides=1,\n            padding=""SAME""))\n\n  def testAvgPool(self):\n    y = extensions.avg_pool(np.ones([5, 320, 480, 3]), [3, 5], [2, 3], ""VALID"")\n    self.assertAllEqual(\n        y,\n        tf.nn.pool(\n            input=tf.ones([5, 320, 480, 3]),\n            window_shape=[3, 5],\n            pooling_type=""AVG"",\n            padding=""VALID"",\n            strides=[2, 3],\n        ))\n\n  def testMaxPool(self):\n    y = extensions.max_pool(np.ones([5, 320, 480, 3]), [3, 5], [2, 3], ""VALID"")\n    self.assertAllEqual(\n        y,\n        tf.nn.pool(\n            input=tf.ones([5, 320, 480, 3]),\n            window_shape=[3, 5],\n            pooling_type=""MAX"",\n            padding=""VALID"",\n            strides=[2, 3],\n        ))\n\n  def testPrng(self):\n    self.assertAllEqual(tf_np.asarray(123, np.int64), extensions.prng(123))\n\n  def testUniform(self):\n    minval = 0.43\n    maxval = 3.10\n    shape = [13, 34, 29]\n    atol = 0.1\n    outputs = extensions.uniform(123, shape, minval=minval, maxval=maxval)\n    self.assertAllClose((minval + maxval) / 2.0, np.mean(outputs), atol=atol)\n\n  def testNormal(self):\n    shape = [13, 34, 29]\n    atol = 0.1\n    outputs = extensions.normal(123, shape)\n    self.assertAllClose(0, np.mean(outputs), atol=atol)\n    self.assertAllClose(1, np.std(outputs), atol=atol)\n\n  def testBernoulli(self):\n    mean = 0.23\n    shape = [13, 34, 29]\n    atol = 0.1\n    outputs = extensions.bernoulli(123, mean, shape)\n    self.assertAllClose(mean, np.mean(outputs), atol=atol)\n\n  def testBernoulliWrongShape(self):\n    mean = [0.1, 0.2]\n    shape = [3]\n    with self.assertRaisesWithPredicateMatch(tf.errors.InvalidArgumentError,\n                                             r""Incompatible shapes""):\n      extensions.bernoulli(123, mean, shape)\n\n  def testDatasetAsNumpy(self):\n    arrs = extensions.dataset_as_numpy(\n        [tf.constant([1, 2]), tf.constant([3, 4])])\n    for a in arrs:\n      self.assertIsInstance(a, tf_np.ndarray)\n    with self.assertRaisesWithPredicateMatch(\n        ValueError,\n        r""dataset_as_numpy must be run in eager mode outside tf.function""):\n\n      @tf.function\n      def f():\n        return extensions.dataset_as_numpy([tf.constant([1, 2])])\n\n      f()\n\n  def _get_two_devices(self, require_same_type=False):\n    tpus = extensions.tpu_devices()\n    if FLAGS.requires_tpu:\n      if len(tpus) == 2:\n        res = tpus\n      else:\n        raise ValueError(""This test requires 2 TPU cores but %s are found"" %\n                         len(tpus))\n    else:\n      if len(tpus) == 2:\n        res = tpus\n      elif self._hasGPU() and not require_same_type:\n        res = (""CPU:0"", ""GPU:0"")\n      else:\n        res = (""CPU:0"", ""CPU:1"")\n    return res\n\n  def testPmap(self):\n    devices = self._get_two_devices()\n\n    @functools.partial(extensions.pmap, devices=devices)\n    def return_three(f):\n      return f, f + 1.0, f + 2.0\n\n    result = return_three(tf.ones((2, 20)))\n    # The function returned 3 items, so we got 3 items back.\n    self.assertLen(result, 3)\n\n    # Each of the items should be a ShardedNdarray that when converted to tensor\n    # should produce a tensor of shape (2, 20)\n    converted = tf.nest.map_structure(tf.convert_to_tensor, result)\n\n    self.assertLen(result, 3)\n\n    self.assertAllEqual(converted[0].shape, converted[1].shape)\n    self.assertAllEqual(converted[0].shape, converted[2].shape)\n\n    self.assertAllEqual(converted[0], tf.ones((2, 20)))\n    self.assertAllEqual(converted[1], 1 + tf.ones((2, 20)))\n    self.assertAllEqual(converted[2], 2 + tf.ones((2, 20)))\n\n    @functools.partial(extensions.pmap, devices=devices)\n    def return_one(f):\n      return f + 2.0\n\n    result = return_one(tf.ones((2, 20)))\n\n    # Only a single item is returned, so we can convert it directly.\n    converted = tf.convert_to_tensor(value=result)\n    self.assertAllEqual(converted, 2 + tf.ones((2, 20)))\n\n    @functools.partial(extensions.pmap, devices=devices)\n    def return_list(f):\n      return [f + 2.0]\n\n    result = return_list(tf.ones((2, 20)))\n\n    # A singleton list is returned.\n    self.assertLen(result, 1)\n    converted = tf.convert_to_tensor(value=result[0])\n    self.assertAllEqual(converted, 2 + tf.ones((2, 20)))\n\n  def testGradSimpleModel(self):\n    params, params_true, inputs, targets = generate_params_inputs_targets()\n\n    for _ in range(50):\n      params = train_step(params, inputs, targets)\n\n    # This is not trained super well, but it usually gets ""close"".\n    self.assertAllClose(params[0], params_true[0], atol=1e-1)\n    self.assertAllClose(params[1], params_true[1], atol=1e-1)\n\n  # NOTE: Compare to testGradSimpleModel to see the differences when pmapping.\n  def testPmapSimpleModel(self):\n    devices = self._get_two_devices(require_same_type=True)\n    n_devices = len(devices)\n\n    params, params_true, inputs, targets = generate_params_inputs_targets()\n\n    def _train_and_reduce(params, inputs, targets, learning_rate=0.1):\n      new_w, new_b = train_step(params, inputs, targets, learning_rate)\n\n      return (extensions.psum(new_w) / n_devices,\n              extensions.psum(new_b) / n_devices)\n\n    train_step_pmapped = extensions.pmap(_train_and_reduce, devices=devices)\n\n    def replicate(x, num_devices=2):\n      return tf_np.broadcast_to(x, (num_devices,) + x.shape)\n\n    params = tf.nest.map_structure(replicate, params)\n\n    def reshape(x, num_devices=2):\n      x_shape = list(x.shape)\n      batch_size = x_shape[0]\n      batch_size_per_device = batch_size // num_devices\n\n      # New shape.\n      new_shape_prefix = [num_devices, batch_size_per_device]\n      return tf_np.reshape(x, new_shape_prefix + x_shape[1:])\n\n    inputs = tf.nest.map_structure(reshape, inputs)\n    targets = tf.nest.map_structure(reshape, targets)\n\n    for _ in range(50):\n      params = train_step_pmapped(params, inputs, targets)\n\n    # PMAP returns sharded tensors.\n\n    # Since the inputs are identical, the returned tensors should be identical\n    self.assertAllClose(params[0][0], params[0][1])\n    self.assertAllClose(params[1][0], params[1][1])\n\n    # This is not trained super well, but it usually gets ""close"".\n    self.assertAllClose(params[0][0], params_true[0], atol=1e-1)\n    self.assertAllClose(params[1][0], params_true[1], atol=1e-1)\n\n  def testPsum(self):\n    devices = self._get_two_devices(require_same_type=True)\n\n    def reduce_sum(f):\n      return extensions.psum(f)\n\n    data = tf_np.asarray(tf.convert_to_tensor(value=[1, 3]))\n    pmapped = extensions.pmap(reduce_sum, devices=devices)\n    result = pmapped(data)\n\n    self.assertAllClose(result[0], 4)\n    self.assertAllClose(result[1], 4)\n\n  def testPmean(self):\n    if extensions.tpu_devices():\n      self.skipTest(""pmean for TPU is not supported yet"")\n    devices = self._get_two_devices(require_same_type=True)\n\n    def reduce_mean(f):\n      return extensions.pmean(f)\n\n    data = tf_np.asarray(tf.convert_to_tensor(value=[1, 3]))\n    pmapped = extensions.pmap(reduce_mean, devices=devices)\n    result = pmapped(data)\n\n    self.assertAllClose(result[0], 2)\n    self.assertAllClose(result[1], 2)\n\n  def testAxisName(self):\n    devices = self._get_two_devices(require_same_type=True)\n\n    def reduce_sum(f):\n      return extensions.psum(f, axis_name=""foo"")\n\n    data = tf_np.asarray(tf.convert_to_tensor(value=[1, 3]))\n    pmapped = extensions.pmap(reduce_sum, axis_name=""foo"", devices=devices)\n    pmapped(data)\n\n  def testWrongAxisName(self):\n    devices = self._get_two_devices(require_same_type=True)\n\n    def reduce_sum(f):\n      return extensions.psum(f, axis_name=""bar"")\n\n    data = tf_np.asarray(tf.convert_to_tensor(value=[1, 3]))\n    with self.assertRaisesWithPredicateMatch(\n        ValueError, r""axis_name (.*) is not equal to that of the surrounding""):\n      pmapped = extensions.pmap(reduce_sum, axis_name=""foo"", devices=devices)\n      pmapped(data)\n\n  def testNoNestedPmap(self):\n    devices = self._get_two_devices(require_same_type=True)\n\n    def f(x):\n      return x + 1.0\n\n    data = tf_np.asarray(tf.convert_to_tensor(value=[1, 3]))\n    with self.assertRaisesWithPredicateMatch(ValueError,\n                                             r""Nested pmap is not supported""):\n      f = extensions.pmap(f, devices=devices)\n      f = extensions.pmap(f, devices=devices)\n      f(data)\n\n\nif __name__ == ""__main__"":\n  tf.compat.v1.enable_eager_execution()\n  tf.test.main()\n'"
trax/tf_numpy/jax_tests/config.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Copyright 2018 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nimport sys\n\ndef bool_env(varname: str, default: bool) -> bool:\n  """"""Read an environment variable and interpret it as a boolean.\n\n  True values are (case insensitive): \'y\', \'yes\', \'t\', \'true\', \'on\', and \'1\';\n  false values are \'n\', \'no\', \'f\', \'false\', \'off\', and \'0\'.\n\n  Args:\n    varname: the name of the variable\n    default: the default boolean value\n  Raises: ValueError if the environment variable is anything else.\n  """"""\n  val = os.getenv(varname, str(default))\n  val = val.lower()\n  if val in (\'y\', \'yes\', \'t\', \'true\', \'on\', \'1\'):\n    return True\n  elif val in (\'n\', \'no\', \'f\', \'false\', \'off\', \'0\'):\n    return False\n  else:\n    raise ValueError(""invalid truth value %r for environment %r"" % (val, varname))\n\n\nclass Config(object):\n  def __init__(self):\n    self.values = {}\n    self.meta = {}\n    self.FLAGS = NameSpace(self.read)\n    self.use_absl = False\n\n  def update(self, name, val):\n    if self.use_absl:\n      setattr(self.absl_flags.FLAGS, name, val)\n    else:\n      self.check_exists(name)\n      if name not in self.values:\n        raise Exception(""Unrecognized config option: {}"".format(name))\n      self.values[name] = val\n\n  def read(self, name):\n    if self.use_absl:\n      return getattr(self.absl_flags.FLAGS, name)\n    else:\n      self.check_exists(name)\n      return self.values[name]\n\n  def add_option(self, name, default, opt_type, meta_args, meta_kwargs):\n    if name in self.values:\n      raise Exception(""Config option {} already defined"".format(name))\n    self.values[name] = default\n    self.meta[name] = (opt_type, meta_args, meta_kwargs)\n\n  def check_exists(self, name):\n    if name not in self.values:\n      raise Exception(""Unrecognized config option: {}"".format(name))\n\n  def DEFINE_bool(self, name, default, *args, **kwargs):\n    self.add_option(name, default, bool, args, kwargs)\n\n  def DEFINE_integer(self, name, default, *args, **kwargs):\n    self.add_option(name, default, int, args, kwargs)\n\n  def DEFINE_string(self, name, default, *args, **kwargs):\n    self.add_option(name, default, str, args, kwargs)\n\n  def DEFINE_enum(self, name, default, *args, **kwargs):\n    self.add_option(name, default, \'enum\', args, kwargs)\n\n  def config_with_absl(self):\n    # Run this before calling `app.run(main)` etc\n    import absl.flags as absl_FLAGS\n    from absl import app, flags as absl_flags\n\n    self.use_absl = True\n    self.absl_flags = absl_flags\n    absl_defs = { bool: absl_flags.DEFINE_bool,\n                  int:  absl_flags.DEFINE_integer,\n                  str:  absl_flags.DEFINE_string,\n                  \'enum\': absl_flags.DEFINE_enum }\n\n    for name, val in self.values.items():\n      flag_type, meta_args, meta_kwargs = self.meta[name]\n      absl_defs[flag_type](name, val, *meta_args, **meta_kwargs)\n\n    app.call_after_init(lambda: self.complete_absl_config(absl_flags))\n\n  def complete_absl_config(self, absl_flags):\n    for name, _ in self.values.items():\n      self.update(name, getattr(absl_flags.FLAGS, name))\n\n  def parse_flags_with_absl(self):\n    global already_configured_with_absl\n    if not already_configured_with_absl:\n      import absl.flags\n      self.config_with_absl()\n      absl.flags.FLAGS(sys.argv, known_only=True)\n      self.complete_absl_config(absl.flags)\n      already_configured_with_absl = True\n\n\nclass NameSpace(object):\n  def __init__(self, getter):\n    self._getter = getter\n\n  def __getattr__(self, name):\n    return self._getter(name)\n\n\nconfig = Config()\nflags = config\nFLAGS = flags.FLAGS\n\nalready_configured_with_absl = False\n\nflags.DEFINE_bool(\n    \'jax_enable_checks\',\n    bool_env(\'JAX_ENABLE_CHECKS\', False),\n    help=\'Turn on invariant checking (core.skip_checks = False)\')\n\nflags.DEFINE_bool(\'tf_numpy_additional_tests\', True,\n                  \'Run tests added specifically for TF numpy\')\n'"
trax/tf_numpy/jax_tests/lax_numpy_indexing_test.py,152,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Copyright 2018 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nimport collections\nimport enum\nfrom functools import partial\nimport itertools\nimport unittest\nimport warnings\n\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\n\nimport numpy as onp\n\nimport trax.tf_numpy.numpy as jnp\n\nfrom trax.tf_numpy.jax_tests.config import config\nimport trax.tf_numpy.jax_tests.test_util as jtu\n\nconfig.parse_flags_with_absl()\n\n\n# We disable the whitespace continuation check in this file because otherwise it\n# makes the test name formatting unwieldy.\n# pylint: disable=bad-continuation\n# We also disable undefined-variable till we start enabling tests.\n# pylint: disable=undefined-variable\n\n\nfloat_dtypes = [onp.float32, onp.float64]\nint_dtypes = [onp.int32, onp.int64]\nbool_types = [onp.bool_]\ndefault_dtypes = float_dtypes + int_dtypes\nall_dtypes = float_dtypes + int_dtypes + bool_types\n\nIndexSpec = collections.namedtuple(""IndexTest"", [""shape"", ""indexer""])\n\n\nsuppress_deprecated_indexing_warnings = partial(\n  jtu.ignore_warning, category=FutureWarning,\n  message=\'Using a non-tuple sequence.*\')\n\n\nSTATIC_INDEXING_TESTS = [\n    (""OneIntIndex"", [\n        IndexSpec(shape=(3,), indexer=1),\n        IndexSpec(shape=(3, 3), indexer=0),\n        IndexSpec(shape=(3, 4, 5), indexer=2),\n        IndexSpec(shape=(3,), indexer=-1),\n        IndexSpec(shape=(3,), indexer=-2),\n    ]),\n    (""TwoIntIndices"", [\n        IndexSpec(shape=(3, 3), indexer=(2, 1)),\n        IndexSpec(shape=(3, 4, 5), indexer=(1, 2)),\n        IndexSpec(shape=(3, 4, 5), indexer=(-1, 2)),\n    ]),\n    (""ThreeIntIndices"", [IndexSpec((3, 4, 5), indexer=(1, 2, 3))]),\n    (""OneSliceIndex"", [\n        IndexSpec(shape=(10,), indexer=slice(1, 3)),\n        IndexSpec(shape=(10,), indexer=slice(1, -1)),\n        IndexSpec(shape=(10,), indexer=slice(None, -1)),\n        IndexSpec(shape=(10,), indexer=slice(None, None, None)),\n        IndexSpec(shape=(10, 8), indexer=slice(1, 3)),\n        IndexSpec(shape=(10, 8), indexer=slice(1, None)),\n        IndexSpec(shape=(10, 8), indexer=slice(None, 3)),\n        IndexSpec(shape=(10, 8), indexer=slice(-3, None)),\n    ]),\n    (""OneSliceIndexNegativeStride"", [\n        IndexSpec(shape=(10,), indexer=slice(3, 1, -1)),\n        IndexSpec(shape=(10,), indexer=slice(1, 8, -1)),  # empty result\n        IndexSpec(shape=(10,), indexer=slice(None, 1, -2)),\n        IndexSpec(shape=(10,), indexer=slice(None, None, -1)),\n        IndexSpec(shape=(10, 8), indexer=slice(3, 1, -1)),\n        IndexSpec(shape=(10, 8), indexer=slice(0, 8, -1)),  # empty result\n        IndexSpec(shape=(10, 8), indexer=slice(None, None, -1)),\n    ]),\n    (""OneSliceIndexNonUnitStride"", [\n        IndexSpec(shape=(10,), indexer=slice(0, 8, 2)),\n        IndexSpec(shape=(10,), indexer=slice(0, 8, 3)),\n        IndexSpec(shape=(10,), indexer=slice(1, 3, 2)),\n        IndexSpec(shape=(10,), indexer=slice(1, None, 2)),\n        IndexSpec(shape=(10,), indexer=slice(None, 1, -2)),\n        IndexSpec(shape=(10, 8), indexer=slice(1, 8, 3)),\n        IndexSpec(shape=(10, 8), indexer=slice(None, None, 2)),\n        IndexSpec(shape=(10, 8), indexer=slice(None, 1, -2)),\n        IndexSpec(shape=(10, 8), indexer=slice(None, None, -2)),\n    ]),\n    (""TwoSliceIndices"", [\n        IndexSpec(shape=(10, 8), indexer=(slice(1, 3), slice(0, 2))),\n        IndexSpec(shape=(10, 8), indexer=(slice(1, None), slice(None, 2))),\n        IndexSpec(\n            shape=(10, 8), indexer=(slice(None, None, -1), slice(None, 2))),\n        IndexSpec(shape=(10, 8, 3), indexer=(slice(1, 3), slice(0, 2))),\n        IndexSpec(shape=(10, 8, 3), indexer=(slice(1, 3), slice(0, None))),\n        IndexSpec(shape=(10, 8, 3), indexer=(slice(1, None), slice(0, 2))),\n    ]),\n    (""OneColonIndex"", [\n        IndexSpec(shape=(3,), indexer=slice(None)),\n        IndexSpec(shape=(3, 4), indexer=slice(None)),\n    ]),\n    (""MultipleColonIndices"", [\n        IndexSpec(shape=(3, 4), indexer=(slice(None), slice(None))),\n        IndexSpec(shape=(3, 4, 5), indexer=(slice(None), slice(None))),\n    ]),\n    (""MixedSliceIndices"", [\n        IndexSpec(shape=(10, 4), indexer=(slice(None), slice(0, 2))),\n        IndexSpec(shape=(10, 4), indexer=(1, slice(None))),\n    ]),\n    (""EllipsisIndex"", [\n        IndexSpec(shape=(3,), indexer=Ellipsis),\n        IndexSpec(shape=(3, 4), indexer=Ellipsis),\n        IndexSpec(shape=(3, 4, 5), indexer=(0, Ellipsis)),\n        IndexSpec(shape=(3, 4, 5), indexer=(Ellipsis, 2, 3)),\n    ]),\n    (""NoneIndex"", [\n        IndexSpec(shape=(), indexer=None),\n        IndexSpec(shape=(), indexer=(None, None)),\n        IndexSpec(shape=(), indexer=(Ellipsis, None)),\n        IndexSpec(shape=(3,), indexer=None),\n        IndexSpec(shape=(3, 4), indexer=None),\n        IndexSpec(shape=(3, 4), indexer=(Ellipsis, None)),\n        IndexSpec(shape=(3, 4), indexer=(0, None, Ellipsis)),\n        IndexSpec(shape=(3, 4, 5), indexer=(1, None, Ellipsis)),\n    ]),\n    (""EmptyIndex"", [\n        IndexSpec(shape=(), indexer=()),\n        IndexSpec(shape=(3,), indexer=()),\n        IndexSpec(shape=(3, 4), indexer=()),\n    ]),\n]\n\nSTATIC_INDEXING_GRAD_TESTS = [\n    (""OneIntIndex"", [\n        IndexSpec(shape=(3,), indexer=1),\n        IndexSpec(shape=(3, 3), indexer=0),\n        IndexSpec(shape=(3, 4, 5), indexer=2),\n        IndexSpec(shape=(3,), indexer=-1),\n        IndexSpec(shape=(3,), indexer=-2),\n    ]),\n    (""TwoIntIndices"", [\n        IndexSpec(shape=(3, 3), indexer=(2, 1)),\n        IndexSpec(shape=(3, 4, 5), indexer=(1, 2)),\n        IndexSpec(shape=(3, 4, 5), indexer=(-1, 2)),\n    ]),\n    (""ThreeIntIndices"", [IndexSpec((3, 4, 5), indexer=(1, 2, 3))]),\n    (""OneSliceIndex"", [\n        IndexSpec(shape=(5,), indexer=slice(1, 3)),\n        IndexSpec(shape=(5,), indexer=slice(1, -1)),\n        IndexSpec(shape=(5,), indexer=slice(None, -1)),\n        IndexSpec(shape=(5,), indexer=slice(None, None, None)),\n        IndexSpec(shape=(5, 4), indexer=slice(1, 3)),\n        IndexSpec(shape=(5, 4), indexer=slice(1, None)),\n        IndexSpec(shape=(5, 4), indexer=slice(None, 3)),\n        IndexSpec(shape=(5, 4), indexer=slice(-3, None)),\n    ]),\n    (""TwoSliceIndices"", [\n        IndexSpec(shape=(5, 4), indexer=(slice(1, 3), slice(0, 2))),\n        IndexSpec(shape=(5, 4), indexer=(slice(1, None), slice(None, 2))),\n        IndexSpec(shape=(5, 4, 3), indexer=(slice(1, 3), slice(0, 2))),\n        IndexSpec(shape=(5, 4, 3), indexer=(slice(1, 3), slice(0, None))),\n        IndexSpec(shape=(5, 4, 3), indexer=(slice(1, None), slice(0, 2))),\n    ]),\n    (""OneColonIndex"", [\n        IndexSpec(shape=(3,), indexer=slice(None)),\n        IndexSpec(shape=(3, 4), indexer=slice(None)),\n    ]),\n    (""MultipleColonIndices"", [\n        IndexSpec(shape=(3, 4), indexer=(slice(None), slice(None))),\n        IndexSpec(shape=(3, 4, 5), indexer=(slice(None), slice(None))),\n    ]),\n    (""MixedSliceIndices"", [\n        IndexSpec(shape=(5, 4), indexer=(slice(None), slice(0, 2))),\n        IndexSpec(shape=(5, 4), indexer=(1, slice(None))),\n    ]),\n    (""EllipsisIndex"", [\n        IndexSpec(shape=(3,), indexer=Ellipsis),\n        IndexSpec(shape=(3, 4), indexer=Ellipsis),\n        IndexSpec(shape=(3, 4, 5), indexer=(0, Ellipsis)),\n        IndexSpec(shape=(3, 4, 5), indexer=(Ellipsis, 2, 3)),\n    ]),\n    (""NoneIndex"", [\n        IndexSpec(shape=(), indexer=None),\n        IndexSpec(shape=(), indexer=(None, None)),\n        IndexSpec(shape=(), indexer=(Ellipsis, None)),\n        IndexSpec(shape=(3,), indexer=None),\n        IndexSpec(shape=(3, 4), indexer=None),\n        IndexSpec(shape=(3, 4), indexer=(Ellipsis, None)),\n        IndexSpec(shape=(3, 4), indexer=(0, None, Ellipsis)),\n        IndexSpec(shape=(3, 4, 5), indexer=(1, None, Ellipsis)),\n    ]),\n    # TODO(mattjj): these fail for uninteresting dtype reasons\n    # (""EmptyIndex"",\n    #  [IndexSpec(shape=(), indexer=()),\n    #   IndexSpec(shape=(3,), indexer=()),\n    #   IndexSpec(shape=(3, 4), indexer=()),\n    #   ]),\n]\n\nADVANCED_INDEXING_TESTS = [\n    (""One1DIntArrayIndex"",\n     [IndexSpec(shape=(3,), indexer=onp.array([0, 1])),\n     IndexSpec(shape=(3, 3), indexer=onp.array([1, 2, 1])),\n     IndexSpec(shape=(3, 4, 5), indexer=onp.array([0, 2, 0, 1])),\n     IndexSpec(shape=(3,), indexer=onp.array([-1, 1])),\n     IndexSpec(shape=(3,), indexer=onp.array([-2, -1])),\n     IndexSpec(shape=(0,), indexer=onp.array([], dtype=onp.int32)),\n     ]),\n    (""One2DIntArrayIndex"",\n     [IndexSpec(shape=(3,), indexer=onp.array([[0, 0]])),\n     IndexSpec(shape=(3, 3), indexer=onp.array([[1, 2, 1],\n                                                [0, 1, -1]])),\n     IndexSpec(shape=(3, 4, 5), indexer=onp.array([[0, 2, 0, 1],\n                                                   [-1, -2, 1, 0]])),\n     ]),\n    (""Two1DIntArrayIndicesNoBroadcasting"",\n     [IndexSpec(shape=(3, 3), indexer=[onp.array([0, 1]),\n                                       onp.array([1, 2])]),\n     IndexSpec(shape=(3, 4, 5), indexer=[onp.array([0, 2, 0, 1]),\n                                         onp.array([-1, 0, -1, 2])]),\n     ]),\n    (""Two1DIntArrayIndicesWithBroadcasting"",\n     [IndexSpec(shape=(3, 3), indexer=[onp.array([[0, 1]]),\n                                       onp.array([1, 2])]),\n     IndexSpec(shape=(3, 4, 5), indexer=[onp.array([[0, 2, 0, 1]]),\n                                         onp.array([-1, 0, -1, 2])]),\n     ]),\n    (""ListOfPythonInts"",\n     [IndexSpec(shape=(3,), indexer=[0, 1, 0]),\n     IndexSpec(shape=(3, 4, 5), indexer=[0, -1]),\n     ]),\n    (""ListOfListsOfPythonInts"",\n     [IndexSpec(shape=(3, 4, 5), indexer=[[0, 1]]),\n     IndexSpec(shape=(3, 4, 5), indexer=[[[0], [-1]], [[2, 3, 0, 3]]]),\n     ]),\n    (""TupleOfListsOfPythonInts"",\n     [IndexSpec(shape=(3, 4, 5), indexer=([0, 1])),\n     IndexSpec(shape=(3, 4, 5), indexer=([[0], [-1]], [[2, 3, 0, 3]])),\n     ]),\n    (""ListOfPythonIntsAndIntArrays"",\n     [IndexSpec(shape=(3, 4, 5), indexer=[0, onp.array([0, 1])]),\n     IndexSpec(shape=(3, 4, 5), indexer=[0, 1,\n                                         onp.array([[2, 3, 0, 3]])]),\n     ]),\n    (""ListOfListsOfPythonIntsAndIntArrays"",\n     [IndexSpec(shape=(3, 4, 5), indexer=[[0, 1], onp.array([0])]),\n     IndexSpec(shape=(3, 4, 5), indexer=[[[0], [-1]],\n                                         onp.array([[2, 3, 0, 3]])]),\n     ]),\n]\n\nADVANCED_INDEXING_TESTS_NO_REPEATS = [\n    (""One1DIntArrayIndex"",\n     [IndexSpec(shape=(3,), indexer=onp.array([0, 1])),\n      IndexSpec(shape=(3, 3), indexer=onp.array([1, 2, 0])),\n      IndexSpec(shape=(3, 4, 5), indexer=onp.array([0, 2, 1])),\n      IndexSpec(shape=(3,), indexer=onp.array([-1, 1])),\n      IndexSpec(shape=(3,), indexer=onp.array([-2, -1])),\n      IndexSpec(shape=(0,), indexer=onp.array([], dtype=onp.int32)),\n     ]),\n    (""One2DIntArrayIndex"",\n     [IndexSpec(shape=(3,), indexer=onp.array([[0, 1]])),\n      IndexSpec(shape=(6, 6), indexer=onp.array([[1, 2, 0],\n                                                 [3, 4, -1]])),\n     ]),\n    (""Two1DIntArrayIndicesNoBroadcasting"",\n     [IndexSpec(shape=(3, 3), indexer=[onp.array([0, 1]),\n                                       onp.array([1, 2])]),\n      IndexSpec(shape=(4, 5, 6), indexer=[onp.array([0, 2, 1, 3]),\n                                          onp.array([-1, 0, -2, 1])]),\n     ]),\n    (""Two1DIntArrayIndicesWithBroadcasting"",\n     [IndexSpec(shape=(3, 3), indexer=[onp.array([[0, 1]]),\n                                       onp.array([1, 2])]),\n      IndexSpec(shape=(4, 5, 6), indexer=[onp.array([[0, 2, -1, 1]]),\n                                          onp.array([-1, 0, -2, 2])]),\n     ]),\n    (""ListOfPythonInts"",\n     [IndexSpec(shape=(3,), indexer=[0, 2, 1]),\n      IndexSpec(shape=(3, 4, 5), indexer=[0, -1]),\n     ]),\n    (""ListOfListsOfPythonInts"",\n     [IndexSpec(shape=(3, 4, 5), indexer=[[0, 1]]),\n      IndexSpec(shape=(3, 4, 5), indexer=[[[0], [-1]], [[2, 3, 0]]]),\n     ]),\n    (""TupleOfListsOfPythonInts"",\n     [IndexSpec(shape=(3, 4, 5), indexer=([0, 1])),\n      IndexSpec(shape=(3, 4, 5), indexer=([[0], [-1]], [[2, 3, 0]])),\n     ]),\n    (""ListOfPythonIntsAndIntArrays"",\n     [IndexSpec(shape=(3, 4, 5), indexer=[0, onp.array([0, 1])]),\n      IndexSpec(shape=(3, 4, 5), indexer=[0, 1,\n                                          onp.array([[2, 3, 0]])]),\n     ]),\n    (""ListOfListsOfPythonIntsAndIntArrays"",\n     [IndexSpec(shape=(3, 4, 5), indexer=[[0, 1], onp.array([0])]),\n      IndexSpec(shape=(3, 4, 5), indexer=[[[0], [-1]],\n                                          onp.array([[2, 3, 0]])]),\n     ]),\n]\n\nMIXED_ADVANCED_INDEXING_TESTS_NO_REPEATS = [\n    (""SlicesAndOneIntArrayIndex"",\n     [IndexSpec(shape=(2, 3), indexer=(onp.array([0, 1]), slice(1, 2))),\n     IndexSpec(shape=(2, 3), indexer=(slice(0, 2),\n                                      onp.array([0, 2]))),\n     IndexSpec(shape=(3, 4, 5), indexer=(Ellipsis,\n                                         onp.array([0, 2]),\n                                         slice(None))),\n     IndexSpec(shape=(3, 4, 5), indexer=(Ellipsis,\n                                         onp.array([[0, 2], [1, 3]]),\n                                         slice(None))),\n     ]),\n    (""SlicesAndTwoIntArrayIndices"",\n     [IndexSpec(shape=(3, 4, 5), indexer=(Ellipsis,\n                                          onp.array([0, 2]),\n                                          onp.array([-1, 2]))),\n     IndexSpec(shape=(3, 4, 5), indexer=(onp.array([0, 2]),\n                                         Ellipsis,\n                                         onp.array([-1, 2]))),\n     IndexSpec(shape=(3, 4, 5), indexer=(onp.array([0, 2]),\n                                         onp.array([-1, 2]),\n                                         Ellipsis)),\n     IndexSpec(shape=(3, 4, 5), indexer=(onp.array([0, 2]),\n                                         onp.array([-1, 2]),\n                                         slice(1, 3))),\n     IndexSpec(shape=(3, 4, 5), indexer=(onp.array([0, 2]),\n                                         slice(1, 3),\n                                         onp.array([-1, 2]))),\n     IndexSpec(shape=(3, 4, 5), indexer=(onp.array([0, 2, -2]),\n                                         slice(None, None, 2),\n                                         onp.array([-1, 2, 1]))),\n     ]),\n    (""NonesAndIntArrayIndices"",\n     [IndexSpec(shape=(3, 4, 5), indexer=[onp.array([0, 2]),\n                                          None,\n                                          onp.array([-1, 2])]),\n     IndexSpec(shape=(3, 4, 5), indexer=(onp.array([0, 2]),\n                                         None,\n                                         None,\n                                         onp.array([-1, 2]))),\n     IndexSpec(shape=(3, 4, 5), indexer=(Ellipsis,\n                                         onp.array([0, 2]),\n                                         None,\n                                         None,\n                                         onp.array([-1, 2]))),\n     ]),\n    (""IntArrayWithInt32Type"",\n     [IndexSpec(shape=(3, 4), indexer=(Ellipsis, onp.array(1, dtype=onp.int32)))\n     ]),\n]\n\nMIXED_ADVANCED_INDEXING_TESTS = MIXED_ADVANCED_INDEXING_TESTS_NO_REPEATS + [\n    (""SlicesAndOneIntArrayIndex"",\n     [\n     IndexSpec(shape=(3, 4, 5), indexer=(Ellipsis,\n                                         onp.array([[0, 2], [1, 1]]),\n                                         slice(None))),\n     ]),\n    (""SlicesAndTwoIntArrayIndices"",\n     [IndexSpec(shape=(3, 4, 5), indexer=(onp.array([0, 2, -2]),\n                                         slice(None, None, 2),\n                                         onp.array([-1, 2, -1]))),\n      IndexSpec(shape=(3, 4, 5), indexer=(onp.array([[0, 2], [2, 0]]),\n                                          Ellipsis,\n                                          onp.array([[1, 0], [1, 0]]))),\n     ]),]\n\n\nclass IndexingTest(jtu.TestCase):\n  """"""Tests for Numpy indexing translation rules.""""""\n\n  @parameterized.named_parameters(jtu.cases_from_list({\n      ""testcase_name"": ""{}_inshape={}_indexer={}"".format(\n          name, jtu.format_shape_dtype_string( shape, dtype), indexer),\n       ""shape"": shape, ""dtype"": dtype, ""rng_factory"": rng_factory, ""indexer"": indexer\n  } for name, index_specs in STATIC_INDEXING_TESTS\n    for shape, indexer in index_specs\n    for dtype in all_dtypes\n    for rng_factory in [jtu.rand_default]))\n  def testStaticIndexing(self, shape, dtype, rng_factory, indexer):\n    # TODO(rohanj): Revisit passing in self.rng() to this to customize further.\n    # This would need updating lax_numpy_test as well.\n    rng = rng_factory()\n    args_maker = lambda: [rng(shape, dtype)]\n    fun = lambda x: x[indexer]\n    self._CompileAndCheck(fun, args_maker, check_dtypes=True)\n\n  @parameterized.named_parameters({\n      ""testcase_name"":\n          ""{}_inshape={}_indexer={}"".format(name,\n                                            jtu.format_shape_dtype_string(\n                                                shape, dtype), indexer),\n      ""shape"": shape, ""dtype"": dtype, ""rng_factory"": rng_factory, ""indexer"": indexer\n  } for name, index_specs in STATIC_INDEXING_GRAD_TESTS\n    for shape, indexer in index_specs\n    for dtype in float_dtypes\n    for rng_factory in [jtu.rand_default])\n  @jtu.disable\n  def testStaticIndexingGrads(self, shape, dtype, rng_factory, indexer):\n    rng = rng_factory()\n    tol = 1e-2 if jnp.finfo(dtype).bits == 32 else None\n    arg = rng(shape, dtype)\n    fun = lambda x: x[indexer]**2\n    check_grads(fun, (arg,), 2, tol, tol, tol)\n\n  def _ReplaceSlicesWithTuples(self, idx):\n    """"""Helper method to replace slices with tuples for dynamic indexing args.""""""\n    if isinstance(idx, slice):\n      triple = idx.start, idx.stop, idx.step\n      isnone = [i for i, elt in enumerate(triple) if elt is None]\n      zeros = itertools.repeat(0)\n      nones = itertools.repeat(None)\n      out = util.subvals(triple, zip(isnone, zeros))\n      return out, lambda out: slice(*util.subvals(out, zip(isnone, nones)))\n    elif isinstance(idx, (tuple, list)) and idx:\n      t = type(idx)\n      elts, packs = zip(*map(self._ReplaceSlicesWithTuples, idx))\n      return elts, lambda elts: t((pack(i) for pack, i in zip(packs, elts)))\n    else:\n      return idx, lambda x: x\n\n  @parameterized.named_parameters(\n      {""testcase_name"": ""{}_inshape={}_indexer={}""\n       .format(name, jtu.format_shape_dtype_string(shape, dtype), indexer),\n       ""shape"": shape, ""dtype"": dtype, ""rng_factory"": rng_factory, ""indexer"": indexer}\n      for name, index_specs in [\n          (""OneSliceIndex"",\n           [IndexSpec(shape=(5,), indexer=slice(1, 3)),\n            IndexSpec(shape=(5, 4), indexer=slice(1, 3))]),\n          (""TwoSliceIndices"",\n           [IndexSpec(shape=(5, 4), indexer=(slice(1, 3), slice(0, 2))),\n            IndexSpec(shape=(5, 4, 3), indexer=(slice(1, 3), slice(0, 2)))]),\n          (""NonUnitStrides"", [\n              IndexSpec(shape=(3,), indexer=slice(None, None, -1)),\n              IndexSpec(shape=(3, 3), indexer=slice(0, 3, -2)),\n              IndexSpec(shape=(3, 4, 5), indexer=slice(0, 4, 2))\n          ]),\n          (""OnlyStartOrStopDynamic"", [\n              IndexSpec(shape=(5, 4), indexer=(slice(None, 3), slice(0, 2))),\n              IndexSpec(shape=(5, 4, 3), indexer=(slice(1, 3), slice(0, None)))\n          ]),\n      ]\n      for shape, indexer in index_specs\n      for dtype in all_dtypes\n      for rng_factory in [jtu.rand_default])\n  @jtu.disable\n  def testDynamicIndexingWithSlicesErrors(self, shape, dtype, rng_factory, indexer):\n    rng = rng_factory(self.rng())\n    unpacked_indexer, pack_indexer = self._ReplaceSlicesWithTuples(indexer)\n\n    @api.jit\n    def fun(x, unpacked_indexer):\n      indexer = pack_indexer(unpacked_indexer)\n      return x[indexer]\n\n    args_maker = lambda: [rng(shape, dtype), unpacked_indexer]\n    self.assertRaises(IndexError, lambda: fun(*args_maker()))\n\n  @parameterized.named_parameters(\n      {""testcase_name"": ""{}_inshape={}_indexer={}""\n       .format(name, jtu.format_shape_dtype_string(shape, dtype), indexer),\n       ""shape"": shape, ""dtype"": dtype, ""rng_factory"": rng_factory, ""indexer"": indexer}\n      for name, index_specs in [\n          (""OneIntIndex"",\n           [IndexSpec(shape=(3,), indexer=1),\n            IndexSpec(shape=(3, 3), indexer=0),\n            IndexSpec(shape=(3, 4, 5), indexer=2),\n            IndexSpec(shape=(3,), indexer=-1),\n            IndexSpec(shape=(3,), indexer=-2)]),\n          (""TwoIntIndices"",\n           [IndexSpec(shape=(3, 3), indexer=(2, 1)),\n            IndexSpec(shape=(3, 4, 5), indexer=(1, 2)),\n            IndexSpec(shape=(3, 4, 5), indexer=(-1, 2))]),\n          (""ThreeIntIndices"",\n           [IndexSpec((3, 4, 5), indexer=(1, 2, 3))]),\n      ]\n      for shape, indexer in index_specs\n      for dtype in all_dtypes\n      for rng_factory in [jtu.rand_default])\n  @jtu.disable\n  def testDynamicIndexingWithIntegers(self, shape, dtype, rng_factory, indexer):\n    rng = rng_factory(self.rng())\n    unpacked_indexer, pack_indexer = self._ReplaceSlicesWithTuples(indexer)\n\n    def fun(x, unpacked_indexer):\n      indexer = pack_indexer(unpacked_indexer)\n      return x[indexer]\n\n    args_maker = lambda: [rng(shape, dtype), unpacked_indexer]\n    self._CompileAndCheck(fun, args_maker, check_dtypes=True)\n\n  @parameterized.named_parameters(\n      {""testcase_name"": ""{}_inshape={}_indexer={}""\n       .format(name, jtu.format_shape_dtype_string(shape, dtype), indexer),\n       ""shape"": shape, ""dtype"": dtype, ""rng_factory"": rng_factory, ""indexer"": indexer}\n      for name, index_specs in [\n          (""OneIntIndex"",\n           [IndexSpec(shape=(3,), indexer=1),\n            IndexSpec(shape=(3, 3), indexer=0),\n            IndexSpec(shape=(3, 4, 5), indexer=2),\n            IndexSpec(shape=(3,), indexer=-1),\n            IndexSpec(shape=(3,), indexer=-2),\n            ]),\n          (""TwoIntIndices"",\n           [IndexSpec(shape=(3, 3), indexer=(2, 1)),\n            IndexSpec(shape=(3, 4, 5), indexer=(1, 2)),\n            IndexSpec(shape=(3, 4, 5), indexer=(-1, 2)),\n            ]),\n          (""ThreeIntIndices"",\n           [IndexSpec((3, 4, 5), indexer=(1, 2, 3))]),\n      ]\n      for shape, indexer in index_specs\n      for dtype in float_dtypes\n      for rng_factory in [jtu.rand_default])\n  @jtu.disable\n  def testDynamicIndexingWithIntegersGrads(self, shape, dtype, rng_factory, indexer):\n    rng = rng_factory(self.rng())\n    tol = 1e-2 if jnp.finfo(dtype).bits == 32 else None\n    unpacked_indexer, pack_indexer = self._ReplaceSlicesWithTuples(indexer)\n\n    @api.jit\n    def fun(unpacked_indexer, x):\n      indexer = pack_indexer(unpacked_indexer)\n      return x[indexer]\n\n    arr = rng(shape, dtype)\n    check_grads(partial(fun, unpacked_indexer), (arr,), 2, tol, tol, tol)\n\n  @parameterized.named_parameters(\n      {""testcase_name"": ""{}_inshape={}_indexer={}""\n       .format(name, jtu.format_shape_dtype_string(shape, dtype), indexer),\n       ""shape"": shape, ""dtype"": dtype, ""rng_factory"": rng_factory, ""indexer"": indexer}\n      for name, index_specs in ADVANCED_INDEXING_TESTS\n      for shape, indexer in index_specs\n      for dtype in all_dtypes\n      for rng_factory in [jtu.rand_default])\n  @jtu.disable\n  def testAdvancedIntegerIndexing(self, shape, dtype, rng_factory, indexer):\n    rng = rng_factory(self.rng())\n    args_maker = lambda: [rng(shape, dtype), indexer]\n    fun = lambda x, idx: jnp.asarray(x)[idx]\n    self._CompileAndCheck(fun, args_maker, check_dtypes=True)\n\n  @parameterized.named_parameters(\n      {""testcase_name"": ""{}_inshape={}_indexer={}""\n       .format(name, jtu.format_shape_dtype_string(shape, dtype), indexer),\n       ""shape"": shape, ""dtype"": dtype, ""rng_factory"": rng_factory, ""indexer"": indexer}\n      for name, index_specs in [\n          (""One1DIntArrayIndex"",\n           [IndexSpec(shape=(3,), indexer=onp.array([0, 1])),\n            IndexSpec(shape=(3, 3), indexer=onp.array([1, 2, 1])),\n            IndexSpec(shape=(3, 4, 5), indexer=onp.array([0, 2, 0, 1])),\n            IndexSpec(shape=(3,), indexer=onp.array([-1, 1])),\n            IndexSpec(shape=(3,), indexer=onp.array([-2, -1])),\n            ]),\n          (""One2DIntArrayIndex"",\n           [IndexSpec(shape=(3,), indexer=onp.array([[0, 0]])),\n            IndexSpec(shape=(3, 3), indexer=onp.array([[1, 2, 1],\n                                                       [0, 1, -1]])),\n            IndexSpec(shape=(3, 4, 5), indexer=onp.array([[0, 2, 0, 1],\n                                                          [-1, -2, 1, 0]])),\n            ]),\n          (""Two1DIntArrayIndicesNoBroadcasting"",\n           [IndexSpec(shape=(3, 3), indexer=[onp.array([0, 1]),\n                                             onp.array([1, 2])]),\n            IndexSpec(shape=(3, 4, 5), indexer=[onp.array([0, 2, 0, 1]),\n                                                onp.array([-1, 0, -1, 2])]),\n            ]),\n          (""Two1DIntArrayIndicesWithBroadcasting"",\n           [IndexSpec(shape=(3, 3), indexer=[onp.array([[0, 1]]),\n                                             onp.array([1, 2])]),\n            IndexSpec(shape=(3, 4, 5), indexer=[onp.array([[0, 2, 0, 1]]),\n                                                onp.array([-1, 0, -1, 2])]),\n            ]),\n          (""ListOfPythonInts"",\n           [IndexSpec(shape=(3,), indexer=[0, 1, 0]),\n            IndexSpec(shape=(3, 4, 5), indexer=[0, -1]),\n            ]),\n          (""ListOfListsOfPythonInts"",\n           [IndexSpec(shape=(3, 4, 5), indexer=[[0, 1]]),\n            IndexSpec(shape=(3, 4, 5), indexer=[[[0], [-1]], [[2, 3, 0, 3]]]),\n            ]),\n          (""ListOfPythonIntsAndIntArrays"",\n           [IndexSpec(shape=(3, 4, 5), indexer=[0, onp.array([0, 1])]),\n            IndexSpec(shape=(3, 4, 5), indexer=[0, 1,\n                                                onp.array([[2, 3, 0, 3]])]),\n            ]),\n          (""ListOfListsOfPythonIntsAndIntArrays"",\n           [IndexSpec(shape=(3, 4, 5), indexer=[[0, 1], onp.array([0])]),\n            IndexSpec(shape=(3, 4, 5), indexer=[[[0], [-1]],\n                                                onp.array([[2, 3, 0, 3]])]),\n            ]),\n      ]\n      for shape, indexer in index_specs\n      for dtype in float_dtypes\n      for rng_factory in [jtu.rand_default])\n  @jtu.disable\n  def testAdvancedIntegerIndexingGrads(self, shape, dtype, rng_factory, indexer):\n    rng = rng_factory(self.rng())\n    tol = 1e-2 if jnp.finfo(dtype).bits == 32 else None\n    arg = rng(shape, dtype)\n    fun = lambda x: jnp.asarray(x)[indexer]\n    check_grads(fun, (arg,), 2, tol, tol, eps=1.)\n\n  @parameterized.named_parameters(\n      {""testcase_name"": ""{}_inshape={}_indexer={}""\n       .format(name, jtu.format_shape_dtype_string(shape, dtype), indexer),\n       ""shape"": shape, ""dtype"": dtype, ""rng_factory"": rng_factory, ""indexer"": indexer}\n      for name, index_specs in MIXED_ADVANCED_INDEXING_TESTS\n      for shape, indexer in index_specs\n      for dtype in all_dtypes\n      for rng_factory in [jtu.rand_default])\n  @jtu.disable\n  def testMixedAdvancedIntegerIndexing(self, shape, dtype, rng_factory, indexer):\n    rng = rng_factory(self.rng())\n    indexer_with_dummies = [e if isinstance(e, onp.ndarray) else ()\n                            for e in indexer]\n    substitutes = [(i, e) for i, e in enumerate(indexer)\n                   if not isinstance(e, onp.ndarray)]\n    args_maker = lambda: [rng(shape, dtype), indexer_with_dummies]\n\n    def fun(x, indexer_with_dummies):\n      idx = type(indexer)(util.subvals(indexer_with_dummies, substitutes))\n      return jnp.asarray(x)[idx]\n\n    self._CompileAndCheck(fun, args_maker, check_dtypes=True)\n\n  @jtu.disable\n  def testAdvancedIndexingManually(self):\n    x = onp.random.RandomState(0).randn(3, 4, 5)\n    index_array = onp.array([0, 2, -1, 0])\n\n    op = lambda x, index_array: x[..., index_array, :]\n    cop = api.jit(op)\n\n    a1 = op(x, index_array)\n    a2 = cop(x, index_array)\n\n    self.assertAllClose(a1, a2, check_dtypes=True)\n\n    op = lambda x, index_array: x[..., index_array, :, index_array, None]\n    cop = api.jit(op)\n\n    a1 = op(x, index_array)\n    a2 = cop(x, index_array)\n\n    self.assertAllClose(a1, a2, check_dtypes=True)\n\n    op = lambda x, index_array: x[index_array, ..., index_array[:, None], None]\n    cop = api.jit(op)\n\n    a1 = op(x, index_array)\n    a2 = cop(x, index_array)\n\n    self.assertAllClose(a1, a2, check_dtypes=True)\n\n  @jtu.disable\n  def testUnpacking(self):\n\n    def foo(x):\n      a, b, c = x\n      return a + b + c\n\n    cfoo = api.jit(foo)\n\n    a1 = foo(onp.arange(3))\n    a2 = cfoo(onp.arange(3))\n\n    self.assertAllClose(a1, a2, check_dtypes=True)\n\n  @jtu.disable\n  def testBooleanIndexingArray1D(self):\n    idx = onp.array([True, True, False])\n    x = api.device_put(onp.arange(3))\n    ans = x[idx]\n    expected = onp.arange(3)[idx]\n    self.assertAllClose(ans, expected, check_dtypes=False)\n\n  @jtu.disable\n  def testBooleanIndexingList1D(self):\n    idx = [True, True, False]\n    x = api.device_put(onp.arange(3))\n    ans = x[idx]\n    expected = onp.arange(3)[idx]\n    self.assertAllClose(ans, expected, check_dtypes=False)\n\n  @jtu.disable\n  def testBooleanIndexingArray2DBroadcast(self):\n    idx = onp.array([True, True, False, True])\n    x = onp.arange(8).reshape(4, 2)\n    ans = api.device_put(x)[idx]\n    expected = x[idx]\n    self.assertAllClose(ans, expected, check_dtypes=False)\n\n  @jtu.disable\n  def testBooleanIndexingList2DBroadcast(self):\n    idx = [True, True, False, True]\n    x = onp.arange(8).reshape(4, 2)\n    ans = api.device_put(x)[idx]\n    expected = x[idx]\n    self.assertAllClose(ans, expected, check_dtypes=False)\n\n  @jtu.disable\n  def testBooleanIndexingArray2D(self):\n    idx = onp.array([[True, False],\n                     [False, True],\n                     [False, False],\n                     [True, True]])\n    x = onp.arange(8).reshape(4, 2)\n    ans = api.device_put(x)[idx]\n    expected = x[idx]\n    self.assertAllClose(ans, expected, check_dtypes=False)\n\n  @jtu.disable\n  def testBooleanIndexingDynamicShapeError(self):\n    x = onp.zeros(3)\n    i = onp.array([True, True, False])\n    self.assertRaises(IndexError, lambda: api.jit(lambda x, i: x[i])(x, i))\n\n  @jtu.disable\n  def testIssue187(self):\n    x = jnp.ones((5, 5))\n    x[[0, 2, 4], [0, 2, 4]]  # doesn\'t crash\n\n    x = onp.arange(25).reshape((5, 5))\n    ans = api.jit(lambda x: x[[0, 2, 4], [0, 2, 4]])(x)\n    expected = x[[0, 2, 4], [0, 2, 4]]\n    self.assertAllClose(ans, expected, check_dtypes=False)\n\n  @jtu.disable\n  def testJVPOfGradOfIndexing(self):\n    # Should return a value, even though we didn\'t pass a symbolic zero as the\n    # index tangent.\n    x = jnp.ones((3, 4), jnp.float32)\n    i = jnp.ones((3,), jnp.int32)\n    f = lambda x, i: jnp.sum(x[i])\n    primals, tangents = api.jvp(api.grad(f), (x, i), (x, onp.zeros_like(i)))\n    expected = onp.broadcast_to(\n      onp.array([0, 3, 0], dtype=onp.float32)[:, None], (3, 4))\n    self.assertAllClose(expected, primals, check_dtypes=True)\n    self.assertAllClose(onp.zeros_like(x), tangents, check_dtypes=True)\n\n  @jtu.disable\n  def testTrivialGatherIsntGenerated(self):\n    # https://github.com/google/jax/issues/1621\n    jaxpr = api.make_jaxpr(lambda x: x[:, None])(onp.arange(4))\n    self.assertEqual(len(jaxpr.jaxpr.eqns), 1)\n    self.assertNotIn(\'gather\', str(jaxpr))\n\n  @jtu.disable\n  def testIndexingEmptyDimension(self):\n    # Issue 2671: XLA error when indexing into dimension of size 0\n    x = jnp.ones((2, 0))\n    # The following work, even on axis 1 of size 0\n    _ = x[0, :] + x[0, None] + x[0, 1:] + x[0, 1:3:2]\n\n    with self.assertRaisesRegex(IndexError,\n                                ""index .* is out of bounds for axis .* with size 0""):\n      _ = onp.ones((2, 0))[0, 0]  # The numpy error\n    with self.assertRaisesRegex(IndexError,\n                                ""index is out of bounds for axis .* with size 0""):\n      _ = x[0, 0]  # JAX indexing\n    with self.assertRaisesRegex(IndexError,\n                                ""index is out of bounds for axis .* with size 0""):\n      api.jit(lambda i: x[0, i])(0)  # JAX indexing under jit\n\n  @jtu.disable\n  def testBooleanIndexingWithEmptyResult(self):\n    # based on a TensorFlow Probability test that started failing after #1622\n    x = jnp.array([-1])\n    mask = jnp.array([False])\n    ans = x[mask]  # doesn\'t crash\n\n    expected =  onp.array([-1])[onp.array([False])]\n    self.assertAllClose(ans, expected, check_dtypes=False)\n\n  @jtu.disable\n  def testFloatIndexingError(self):\n    BAD_INDEX_TYPE_ERROR = ""Indexer must have integer or boolean type, got indexer with type""\n    with self.assertRaisesRegex(TypeError, BAD_INDEX_TYPE_ERROR):\n      jnp.zeros(2)[0.]\n    with self.assertRaisesRegex(TypeError, BAD_INDEX_TYPE_ERROR):\n      jnp.zeros((2, 2))[(0, 0.)]\n    with self.assertRaisesRegex(TypeError, BAD_INDEX_TYPE_ERROR):\n      jnp.zeros((2, 2))[(0, 0.)]\n    with self.assertRaisesRegex(TypeError, BAD_INDEX_TYPE_ERROR):\n      api.jit(lambda idx: jnp.zeros((2, 2))[idx])((0, 0.))\n    with self.assertRaisesRegex(TypeError, BAD_INDEX_TYPE_ERROR):\n      ops.index_add(jnp.zeros(2), 0., 1.)\n    with self.assertRaisesRegex(TypeError, BAD_INDEX_TYPE_ERROR):\n      ops.index_update(jnp.zeros(2), 0., 1.)\n\n\n  @jtu.disable\n  def testIndexOutOfBounds(self):  # https://github.com/google/jax/issues/2245\n    array = jnp.ones(5)\n    self.assertAllClose(array, array[:10], check_dtypes=True)\n\n\ndef _broadcastable_shapes(shape):\n  """"""Returns all shapes that broadcast to `shape`.""""""\n  def f(rshape):\n    yield []\n    if rshape:\n      for s in f(rshape[1:]):\n        yield rshape[0:1] + s\n      if rshape[0] != 1:\n        for s in f(rshape[1:]):\n          yield [1] + s\n  for x in f(list(reversed(shape))):\n    yield list(reversed(x))\n\n@suppress_deprecated_indexing_warnings()\ndef _update_shape(shape, indexer):\n  return onp.zeros(shape)[indexer].shape\n\n\nclass UpdateOps(enum.Enum):\n  UPDATE = 0\n  ADD = 1\n  MUL = 2\n  MIN = 3\n  MAX = 4\n\n  @suppress_deprecated_indexing_warnings()\n  def onp_fn(op, indexer, x, y):\n    x = x.copy()\n    x[indexer] = {\n      UpdateOps.UPDATE: lambda: y,\n      UpdateOps.ADD: lambda: x[indexer] + y,\n      UpdateOps.MUL: lambda: x[indexer] * y,\n      UpdateOps.MIN: lambda: onp.minimum(x[indexer], y),\n      UpdateOps.MAX: lambda: onp.maximum(x[indexer], y),\n    }[op]()\n    return x\n\n  def jax_fn(op, indexer, x, y):\n    return {\n      UpdateOps.UPDATE: ops.index_update,\n      UpdateOps.ADD: ops.index_add,\n      UpdateOps.MUL: ops.index_mul,\n      UpdateOps.MIN: ops.index_min,\n      UpdateOps.MAX: ops.index_max,\n    }[op](x, indexer, y)\n\n  def sugar_fn(op, indexer, x, y):\n    x = jnp.array(x)\n    return {\n      UpdateOps.UPDATE: x.at[indexer].set,\n      UpdateOps.ADD: x.at[indexer].add,\n      UpdateOps.MUL: x.at[indexer].mul,\n      UpdateOps.MIN: x.at[indexer].min,\n      UpdateOps.MAX: x.at[indexer].max,\n    }[op](y)\n\n\nclass IndexedUpdateTest(jtu.TestCase):\n\n  @parameterized.named_parameters(jtu.cases_from_list({\n      ""testcase_name"": ""{}_inshape={}_indexer={}_update={}_sugared={}_op={}"".format(\n          name, jtu.format_shape_dtype_string(shape, dtype), indexer,\n          jtu.format_shape_dtype_string(update_shape, update_dtype), sugared, op.name),\n       ""shape"": shape, ""dtype"": dtype, ""rng_factory"": rng_factory, ""indexer"": indexer,\n       ""update_shape"": update_shape, ""update_dtype"": update_dtype,\n       ""op"": op, ""sugared"": sugared\n  } for name, index_specs in STATIC_INDEXING_TESTS\n    for shape, indexer in index_specs\n    for op in UpdateOps\n    for dtype in (all_dtypes if op == UpdateOps.UPDATE else default_dtypes)\n    for update_shape in _broadcastable_shapes(_update_shape(shape, indexer))\n    for update_dtype in ([dtype] if op == UpdateOps.ADD else all_dtypes)\n    for sugared in [True, False]\n    for rng_factory in [jtu.rand_default]))\n  @jtu.disable\n  def testStaticIndexing(self, shape, dtype, update_shape, update_dtype,\n                         rng_factory, indexer, sugared, op):\n    rng = rng_factory()\n    args_maker = lambda: [rng(shape, dtype), rng(update_shape, update_dtype)]\n    onp_fn = lambda x, y: UpdateOps.onp_fn(op, indexer, x, y)\n    if sugared:\n      jax_fn = lambda x, y: UpdateOps.sugar_fn(op, indexer, x, y)\n    else:\n      jax_fn = lambda x, y: UpdateOps.jax_fn(op, indexer, x, y)\n    self._CheckAgainstNumpy(onp_fn, jax_fn, args_maker, check_dtypes=True)\n    self._CompileAndCheck(jax_fn, args_maker, check_dtypes=True)\n\n  @parameterized.named_parameters(jtu.cases_from_list({\n      ""testcase_name"": ""{}_inshape={}_indexer={}_update={}_sugared={}_op={}"".format(\n          name, jtu.format_shape_dtype_string(shape, dtype), indexer,\n          jtu.format_shape_dtype_string(update_shape, update_dtype), sugared, op.name),\n       ""shape"": shape, ""dtype"": dtype, ""rng_factory"": rng_factory, ""indexer"": indexer,\n       ""update_shape"": update_shape, ""update_dtype"": update_dtype,\n       ""op"": op, ""sugared"": sugared\n  } for name, index_specs in ADVANCED_INDEXING_TESTS_NO_REPEATS\n    for shape, indexer in index_specs\n    for op in UpdateOps\n    for dtype in (all_dtypes if op == UpdateOps.UPDATE else default_dtypes)\n    for update_shape in _broadcastable_shapes(_update_shape(shape, indexer))\n    for update_dtype in ([dtype] if op == UpdateOps.ADD else all_dtypes)\n    for sugared in [True, False]\n    for rng_factory in [jtu.rand_default]))\n  @jtu.disable\n  def testAdvancedIndexing(self, shape, dtype, update_shape, update_dtype,\n                           rng_factory, indexer, sugared, op):\n    rng = rng_factory()\n    args_maker = lambda: [rng(shape, dtype), rng(update_shape, update_dtype)]\n    onp_fn = lambda x, y: UpdateOps.onp_fn(op, indexer, x, y)\n    if sugared:\n      jax_fn = lambda x, y: UpdateOps.sugar_fn(op, indexer, x, y)\n    else:\n      jax_fn = lambda x, y: UpdateOps.jax_fn(op, indexer, x, y)\n    self._CheckAgainstNumpy(onp_fn, jax_fn, args_maker, check_dtypes=True)\n    self._CompileAndCheck(jax_fn, args_maker, check_dtypes=True)\n\n  @parameterized.named_parameters(jtu.cases_from_list({\n      ""testcase_name"": ""{}_inshape={}_indexer={}_update={}_op={}"".format(\n          name, jtu.format_shape_dtype_string(shape, dtype), indexer,\n          jtu.format_shape_dtype_string(update_shape, update_dtype), op.name),\n       ""shape"": shape, ""dtype"": dtype, ""rng_factory"": rng_factory, ""indexer"": indexer,\n       ""update_shape"": update_shape, ""update_dtype"": update_dtype,\n       ""op"": op, ""sugared"": sugared\n  } for name, index_specs in MIXED_ADVANCED_INDEXING_TESTS_NO_REPEATS\n    for shape, indexer in index_specs\n    for op in UpdateOps\n    for dtype in (all_dtypes if op == UpdateOps.UPDATE else default_dtypes)\n    for update_shape in _broadcastable_shapes(_update_shape(shape, indexer))\n    for update_dtype in ([dtype] if op == UpdateOps.ADD else all_dtypes)\n    for sugared in [True, False]\n    for rng_factory in [jtu.rand_default]))\n  @jtu.disable\n  def testMixedAdvancedIndexing(self, shape, dtype, update_shape, update_dtype,\n                                rng_factory, indexer, sugared, op):\n    rng = rng_factory()\n    args_maker = lambda: [rng(shape, dtype), rng(update_shape, update_dtype)]\n    onp_fn = lambda x, y: UpdateOps.onp_fn(op, indexer, x, y)\n    if sugared:\n      jax_fn = lambda x, y: UpdateOps.sugar_fn(op, indexer, x, y)\n    else:\n      jax_fn = lambda x, y: UpdateOps.jax_fn(op, indexer, x, y)\n    self._CheckAgainstNumpy(onp_fn, jax_fn, args_maker, check_dtypes=True)\n    self._CompileAndCheck(jax_fn, args_maker, check_dtypes=True)\n\n  @parameterized.named_parameters(jtu.cases_from_list({\n      ""testcase_name"": ""{}_inshape={}_indexer={}_update={}_op={}"".format(\n          name, jtu.format_shape_dtype_string(shape, dtype), indexer,\n          jtu.format_shape_dtype_string(update_shape, update_dtype), op.name),\n       ""shape"": shape, ""dtype"": dtype, ""rng_factory"": rng_factory, ""indexer"": indexer,\n       ""update_shape"": update_shape, ""update_dtype"": update_dtype,\n       ""op"": op\n  } for name, index_specs in STATIC_INDEXING_TESTS\n    for shape, indexer in index_specs\n    for op in [UpdateOps.ADD, UpdateOps.MUL, UpdateOps.UPDATE]\n    for dtype in float_dtypes\n    for update_shape in _broadcastable_shapes(_update_shape(shape, indexer))\n    for update_dtype in ([dtype] if op == UpdateOps.ADD else float_dtypes)\n    for rng_factory in [jtu.rand_default]))\n  @jtu.skip_on_devices(""tpu"")  # TODO(mattjj,phawkins): tpu issues\n  @jtu.disable\n  def testStaticIndexingGrads(self, shape, dtype, update_shape, update_dtype,\n                              rng_factory, indexer, op):\n    rng = rng_factory()\n    jax_fn = lambda x, y: UpdateOps.jax_fn(op, indexer, x, y)\n    x = rng(shape, dtype)\n    y = rng(update_shape, update_dtype)\n    check_grads(jax_fn, (x, y), 2, rtol=1e-3, atol=1e-3, eps=1.)\n\n  @jtu.disable\n  def testSegmentSumBehavior(self):\n    # testAdvancedIndexing compares against NumPy, and as a result doesn\'t check\n    # repeated indices. This test is just a simple manual check, based on\n    # https://www.tensorflow.org/api_docs/python/tf/math/segment_sum\n    data = onp.array([5, 1, 7, 2, 3, 4, 1, 3])\n    segment_ids = onp.array([0, 0, 0, 1, 2, 2, 3, 3])\n\n    ans = ops.index_add(onp.zeros(onp.max(segment_ids) + 1), segment_ids, data)\n    expected = onp.array([13, 2, 7, 4])\n    self.assertAllClose(ans, expected, check_dtypes=False)\n\n  @jtu.disable\n  def testSegmentSum(self):\n    data = onp.array([5, 1, 7, 2, 3, 4, 1, 3])\n    segment_ids = onp.array([0, 0, 0, 1, 2, 2, 3, 3])\n\n    # test with explicit num_segments\n    ans = ops.segment_sum(data, segment_ids, num_segments=4)\n    expected = onp.array([13, 2, 7, 4])\n    self.assertAllClose(ans, expected, check_dtypes=False)\n\n    # test without explicit num_segments\n    ans = ops.segment_sum(data, segment_ids)\n    expected = onp.array([13, 2, 7, 4])\n    self.assertAllClose(ans, expected, check_dtypes=False)\n\n  @jtu.disable\n  def testIndexDtypeError(self):\n    # https://github.com/google/jax/issues/2795\n    jnp.array(1)  # get rid of startup warning\n    with warnings.catch_warnings(record=True) as w:\n      warnings.simplefilter(""error"")\n      jnp.zeros(5).at[::2].set(1)\n      self.assertLen(w, 0)\n\n\nif __name__ == ""__main__"":\n  absltest.main()\n'"
trax/tf_numpy/jax_tests/lax_numpy_test.py,513,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport functools\nfrom functools import partial\nimport itertools\nimport operator\nimport unittest\nfrom unittest import SkipTest\nimport warnings\n\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\nimport six\n\nimport numpy as onp\n\n\nimport tensorflow.compat.v2 as tf\nimport trax.tf_numpy.numpy as lnp\nimport trax.tf_numpy.extensions as npe\nfrom trax.tf_numpy.jax_tests.config import config, FLAGS\nimport trax.tf_numpy.jax_tests.test_util as jtu\n\nconfig.parse_flags_with_absl()\n\n\nnonempty_nonscalar_array_shapes = [(4,), (3, 4), (3, 1), (1, 4), (2, 1, 4), (2, 3, 4)]\nnonempty_array_shapes = [()] + nonempty_nonscalar_array_shapes\nempty_array_shapes = [(0,), (0, 4), (3, 0),]\n\nscalar_shapes = [jtu.NUMPY_SCALAR_SHAPE, jtu.PYTHON_SCALAR_SHAPE]\narray_shapes = nonempty_array_shapes + empty_array_shapes\nnonzerodim_shapes = nonempty_nonscalar_array_shapes + empty_array_shapes\nnonempty_shapes = scalar_shapes + nonempty_array_shapes\nall_shapes =  scalar_shapes + array_shapes\n\n# TODO(wangpeng): float_dtypes = [lnp.bfloat16, onp.float16, onp.float32,\n#                                 onp.float64]\nfloat_dtypes = [onp.float16, onp.float32, onp.float64]\ncomplex_dtypes = [onp.complex64, onp.complex128]\nint_dtypes = [onp.int32, onp.int64]\nunsigned_dtypes = [onp.uint32, onp.uint64]\nbool_dtypes = [onp.bool_]\ndefault_dtypes = float_dtypes + int_dtypes\ninexact_dtypes = float_dtypes + complex_dtypes\nnumber_dtypes = float_dtypes + complex_dtypes + int_dtypes\nall_dtypes = number_dtypes + bool_dtypes\n\n\npython_scalar_dtypes = [lnp.bool_, lnp.int_, lnp.float_, lnp.complex_]\n\ndef _valid_dtypes_for_shape(shape, dtypes):\n  # Not all (shape, dtype) pairs are valid. In particular, Python scalars only\n  # have one type in each category (float, bool, etc.)\n  if shape is jtu.PYTHON_SCALAR_SHAPE:\n    return [t for t in dtypes if t in python_scalar_dtypes]\n  return dtypes\n\ndef _shape_and_dtypes(shapes, dtypes):\n  for shape in shapes:\n    for dtype in _valid_dtypes_for_shape(shape, dtypes):\n      yield (shape, dtype)\n\nOpRecord = collections.namedtuple(\n  ""OpRecord"",\n  [""name"", ""nargs"", ""dtypes"", ""shapes"", ""rng_factory"", ""diff_modes"",\n   ""test_name"", ""check_dtypes"", ""tolerance"", ""inexact""])\n\ndef op_record(name, nargs, dtypes, shapes, rng_factory, diff_modes,\n              test_name=None, check_dtypes=True, tolerance=None, inexact=False):\n  test_name = test_name or name\n  return OpRecord(name, nargs, dtypes, shapes, rng_factory, diff_modes,\n                  test_name, check_dtypes, tolerance, inexact)\n\n\ndef minus(a, b):\n  return [x for x in a if x not in b]\n\n\nJAX_ONE_TO_ONE_OP_RECORDS = [\n    op_record(""abs"", 1, number_dtypes, all_shapes, jtu.rand_default, [""rev""]),\n    op_record(""add"", 2, all_dtypes, all_shapes, jtu.rand_default, [""rev""]),\n    op_record(""ceil"", 1, float_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""conj"", 1, number_dtypes, all_shapes, jtu.rand_default, [""rev""]),\n    op_record(""equal"", 2, all_dtypes, all_shapes, jtu.rand_some_equal, []),\n    op_record(""exp"", 1, number_dtypes, all_shapes, jtu.rand_default, [""rev""],\n              inexact=True),\n    op_record(""fabs"", 1, float_dtypes, all_shapes, jtu.rand_default, [""rev""]),\n    op_record(""float_power"", 2, inexact_dtypes, all_shapes,\n              partial(jtu.rand_default, scale=1), [""rev""],\n              tolerance={\n                  # TODO(wangpeng): lnp.bfloat16: 1e-2,\n                  onp.float32: 1e-3,\n                  onp.float64: 1e-12, onp.complex64: 2e-4,\n                  onp.complex128: 1e-12}, check_dtypes=False),\n    op_record(""floor"", 1, float_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""greater"", 2, minus(all_dtypes, complex_dtypes), all_shapes,\n              jtu.rand_some_equal, []),\n    op_record(""greater_equal"", 2, minus(all_dtypes, complex_dtypes), all_shapes,\n              jtu.rand_some_equal, []),\n    op_record(""less"", 2, minus(all_dtypes, complex_dtypes), all_shapes,\n              jtu.rand_some_equal, []),\n    op_record(""less_equal"", 2, minus(all_dtypes, complex_dtypes), all_shapes,\n              jtu.rand_some_equal, []),\n    op_record(""log"", 1, number_dtypes, all_shapes, jtu.rand_positive, [""rev""],\n              inexact=True),\n    op_record(""logical_and"", 2, all_dtypes, all_shapes, jtu.rand_bool, []),\n    op_record(""logical_not"", 1, all_dtypes, all_shapes, jtu.rand_bool, []),\n    op_record(""logical_or"", 2, all_dtypes, all_shapes, jtu.rand_bool, []),\n    op_record(""logical_xor"", 2, all_dtypes, all_shapes, jtu.rand_bool, []),\n    op_record(""maximum"", 2, minus(all_dtypes, complex_dtypes), all_shapes,\n              jtu.rand_some_inf, []),\n    op_record(""minimum"", 2, minus(all_dtypes, complex_dtypes), all_shapes,\n              jtu.rand_some_inf, []),\n    op_record(""multiply"", 2, all_dtypes, all_shapes, jtu.rand_default, [""rev""]),\n    op_record(""negative"", 1, number_dtypes, all_shapes, jtu.rand_default, [""rev""]),\n    op_record(""nextafter"", 2, [f for f in float_dtypes\n                               if f not in (lnp.bfloat16, onp.float16)],\n              all_shapes, jtu.rand_default, [""rev""], inexact=True, tolerance=0),\n    op_record(""not_equal"", 2, all_dtypes, all_shapes, jtu.rand_some_equal, [""rev""]),\n    op_record(""array_equal"", 2, number_dtypes, all_shapes, jtu.rand_some_equal, [""rev""]),\n    op_record(""reciprocal"", 1, inexact_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""subtract"", 2, number_dtypes, all_shapes, jtu.rand_default, [""rev""]),\n    op_record(""signbit"", 1, default_dtypes + bool_dtypes, all_shapes,\n              jtu.rand_some_inf_and_nan, [""rev""]),\n    op_record(""sin"", 1, number_dtypes, all_shapes, jtu.rand_default, [""rev""],\n              inexact=True),\n    op_record(""cos"", 1, number_dtypes, all_shapes, jtu.rand_default, [""rev""],\n              inexact=True),\n    op_record(""tan"", 1, number_dtypes, all_shapes,\n              partial(jtu.rand_uniform, -1.5, 1.5), [""rev""], inexact=True),\n    # TODO(wangpeng): Add float16 support\n    op_record(""sinh"", 1, minus(number_dtypes, [onp.float16]), all_shapes, jtu.rand_default, [""rev""],\n              inexact=True),\n    op_record(""cosh"", 1, minus(number_dtypes, [onp.float16]), all_shapes, jtu.rand_default, [""rev""],\n              inexact=True),\n    # TODO(b/142975473): on CPU, tanh for complex128 is only accurate to\n    # ~float32 precision.\n    # TODO(b/143135720): on GPU, tanh has only ~float32 precision.\n    op_record(""tanh"", 1, number_dtypes, all_shapes, jtu.rand_default, [""rev""],\n              tolerance={onp.float64: 1e-7, onp.complex128: 1e-7},\n              inexact=True),\n    op_record(""arcsin"", 1, minus(float_dtypes, [onp.float16]), all_shapes, jtu.rand_small, [""rev""],\n              inexact=True),\n    op_record(""arccos"", 1, minus(float_dtypes, [onp.float16]), all_shapes, jtu.rand_small, [""rev""],\n              inexact=True),\n    op_record(""arctan"", 1, minus(float_dtypes, [onp.float16]), all_shapes, jtu.rand_small, [""rev""],\n              inexact=True),\n    op_record(""arctan2"", 2, minus(float_dtypes, [onp.float16]), all_shapes, jtu.rand_small, [""rev""],\n              inexact=True),\n    op_record(""arcsinh"", 1, minus(number_dtypes, [onp.float16]), all_shapes, jtu.rand_positive, [""rev""],\n              inexact=True),\n    op_record(""arccosh"", 1, minus(number_dtypes, [onp.float16]), all_shapes, jtu.rand_positive, [""rev""],\n              inexact=True),\n    op_record(""arctanh"", 1, minus(number_dtypes, [onp.float16]), all_shapes, jtu.rand_small, [""rev""],\n              inexact=True),\n]\n\nJAX_COMPOUND_OP_RECORDS = [\n    # angle has inconsistent 32/64-bit return types across numpy versions.\n    op_record(""angle"", 1, number_dtypes, all_shapes, jtu.rand_default, [],\n              check_dtypes=False, inexact=True),\n    op_record(""atleast_1d"", 1, default_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""atleast_2d"", 1, default_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""atleast_3d"", 1, default_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""cbrt"", 1, default_dtypes, all_shapes, jtu.rand_default, [""rev""],\n              inexact=True),\n    op_record(""conjugate"", 1, number_dtypes, all_shapes, jtu.rand_default, [""rev""]),\n    op_record(""deg2rad"", 1, float_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""divide"", 2, number_dtypes, all_shapes, jtu.rand_nonzero, [""rev""],\n              inexact=six.PY3),\n    op_record(""divmod"", 2, minus(int_dtypes + float_dtypes, [onp.float16]),\n              all_shapes, jtu.rand_nonzero, []),\n    op_record(""exp2"", 1, number_dtypes, all_shapes, jtu.rand_default, [""rev""],\n              tolerance={\n                  # TODO(wangpeng): lnp.bfloat16: 2e-2,\n                  onp.float16: 1e-2}, inexact=True),\n    # TODO(b/142975473): on CPU, expm1 for float64 is only accurate to ~float32\n    # precision.\n    op_record(""expm1"", 1, number_dtypes, all_shapes, jtu.rand_positive, [],\n              test_name=""expm1_large"", tolerance={onp.float64: 1e-8}, inexact=True),\n    op_record(""expm1"", 1, number_dtypes, all_shapes, jtu.rand_small_positive,\n              [], tolerance={onp.float64: 1e-8}, inexact=True),\n    op_record(""fix"", 1, float_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""floor_divide"", 2, minus(number_dtypes, complex_dtypes),\n              all_shapes, jtu.rand_nonzero, [""rev""]),\n    op_record(""heaviside"", 2, default_dtypes, all_shapes, jtu.rand_default, [],\n              inexact=True),\n    op_record(""hypot"", 2, default_dtypes, all_shapes, jtu.rand_default, [],\n              inexact=True),\n    op_record(""kron"", 2, number_dtypes, nonempty_shapes, jtu.rand_default, []),\n    op_record(""outer"", 2, number_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""imag"", 1, number_dtypes, all_shapes, jtu.rand_some_inf, []),\n    op_record(""iscomplex"", 1, number_dtypes, all_shapes, jtu.rand_some_inf, []),\n    op_record(""isfinite"", 1, minus(inexact_dtypes, complex_dtypes), all_shapes,\n              jtu.rand_some_inf_and_nan, []),\n    op_record(""isinf"", 1, minus(inexact_dtypes, complex_dtypes), all_shapes,\n              jtu.rand_some_inf_and_nan, []),\n    op_record(""isnan"", 1, minus(inexact_dtypes, complex_dtypes), all_shapes,\n              jtu.rand_some_inf_and_nan, []),\n    op_record(""isneginf"", 1, float_dtypes, all_shapes, jtu.rand_some_inf_and_nan, []),\n    op_record(""isposinf"", 1, float_dtypes, all_shapes, jtu.rand_some_inf_and_nan, []),\n    op_record(""isreal"", 1, number_dtypes, all_shapes, jtu.rand_some_inf, []),\n    op_record(""isrealobj"", 1, number_dtypes, all_shapes, jtu.rand_some_inf, []),\n    op_record(""log2"", 1, number_dtypes, all_shapes, jtu.rand_positive, [""rev""],\n              inexact=True),\n    op_record(""log10"", 1, number_dtypes, all_shapes, jtu.rand_positive, [""rev""],\n              inexact=True),\n    op_record(""log1p"", 1, number_dtypes, all_shapes, jtu.rand_positive, [],\n              test_name=""log1p_large"", tolerance={onp.float64: 1e-12},\n              inexact=True),\n    op_record(""log1p"", 1, number_dtypes, all_shapes, jtu.rand_small_positive, [],\n              tolerance={onp.float64: 1e-12}, inexact=True),\n    op_record(""logaddexp"", 2, float_dtypes, all_shapes,\n              jtu.rand_some_inf_and_nan, [""rev""],\n              tolerance={onp.float64: 1e-12}, inexact=True),\n    op_record(""logaddexp2"", 2, float_dtypes, all_shapes,\n              jtu.rand_some_inf_and_nan, [""rev""],\n              tolerance={onp.float16: 1e-2}, inexact=True),\n    op_record(""polyval"", 2, number_dtypes, nonempty_nonscalar_array_shapes,\n              jtu.rand_default, [], check_dtypes=False,\n              tolerance={onp.float16: 1e-2, onp.float64: 1e-12}),\n    op_record(""positive"", 1, number_dtypes, all_shapes, jtu.rand_default, [""rev""]),\n    op_record(""power"", 2, number_dtypes, all_shapes, jtu.rand_positive, [""rev""],\n              tolerance={onp.complex128: 1e-14}),\n    op_record(""rad2deg"", 1, float_dtypes, all_shapes, jtu.rand_default, [],\n              tolerance={onp.float64: 5e-6}),\n    op_record(""ravel"", 1, all_dtypes, all_shapes, jtu.rand_default, [""rev""]),\n    op_record(""real"", 1, number_dtypes, all_shapes, jtu.rand_some_inf, []),\n    op_record(""remainder"", 2, minus(default_dtypes, [onp.float16]), all_shapes,\n              jtu.rand_nonzero, [], tolerance={onp.float16: 1e-2}),\n    op_record(""mod"", 2, minus(default_dtypes, [onp.float16]), all_shapes,\n              jtu.rand_nonzero, []),\n    op_record(""sinc"", 1, [t for t in number_dtypes if t != lnp.bfloat16],\n              all_shapes, jtu.rand_default, [""rev""],\n              tolerance={onp.complex64: 1e-5}, inexact=True,\n              check_dtypes=False),\n    op_record(""square"", 1, number_dtypes, all_shapes, jtu.rand_default, [""rev""]),\n    op_record(""sqrt"", 1, number_dtypes, all_shapes, jtu.rand_positive, [""rev""],\n              inexact=True),\n    op_record(""transpose"", 1, all_dtypes, all_shapes, jtu.rand_default, [""rev""],\n              check_dtypes=False),\n    op_record(""true_divide"", 2, all_dtypes, all_shapes, jtu.rand_nonzero,\n              [""rev""], inexact=True),\n    op_record(""diff"", 1, number_dtypes, nonzerodim_shapes, jtu.rand_default, [""rev""]),\n]\n\nJAX_BITWISE_OP_RECORDS = [\n    op_record(""bitwise_and"", 2, int_dtypes + unsigned_dtypes, all_shapes,\n              jtu.rand_default, []),\n    op_record(""bitwise_not"", 1, int_dtypes + unsigned_dtypes, all_shapes,\n              jtu.rand_default, []),\n    op_record(""bitwise_or"", 2, int_dtypes + unsigned_dtypes, all_shapes,\n              jtu.rand_default, []),\n    op_record(""bitwise_xor"", 2, int_dtypes + unsigned_dtypes, all_shapes,\n              jtu.rand_default, []),\n]\n\nJAX_REDUCER_RECORDS = [\n    op_record(""mean"", 1, number_dtypes, nonempty_shapes, jtu.rand_default, [],\n              inexact=True),\n    op_record(""prod"", 1, all_dtypes, all_shapes, jtu.rand_small_positive, []),\n    op_record(""sum"", 1, all_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""nanmean"", 1, minus(inexact_dtypes, complex_dtypes),\n              nonempty_shapes, jtu.rand_some_nan, [], inexact=True),\n    op_record(""nanprod"", 1, minus(inexact_dtypes, complex_dtypes), all_shapes,\n              jtu.rand_some_nan, []),\n    op_record(""nansum"", 1, minus(number_dtypes, complex_dtypes), all_shapes,\n              jtu.rand_some_nan, []),\n]\n\nJAX_REDUCER_NO_DTYPE_RECORDS = [\n    op_record(""all"", 1, all_dtypes, all_shapes, jtu.rand_some_zero, []),\n    op_record(""any"", 1, all_dtypes, all_shapes, jtu.rand_some_zero, []),\n    op_record(""max"", 1, minus(all_dtypes, complex_dtypes), nonempty_shapes,\n              jtu.rand_default, []),\n    op_record(""min"", 1, minus(all_dtypes, complex_dtypes), nonempty_shapes,\n              jtu.rand_default, []),\n    op_record(""var"", 1, all_dtypes, nonempty_shapes, jtu.rand_default, [],\n              inexact=True),\n    op_record(""std"", 1, all_dtypes, nonempty_shapes, jtu.rand_default, [],\n              inexact=True),\n]\n\nJAX_ARGMINMAX_RECORDS = [\n    op_record(""argmin"", 1, minus(all_dtypes, complex_dtypes), nonempty_shapes,\n              jtu.rand_some_equal, []),\n    op_record(""argmax"", 1, minus(all_dtypes, complex_dtypes), nonempty_shapes,\n              jtu.rand_some_equal, []),\n]\n\nJAX_OPERATOR_OVERLOADS = [\n    op_record(""__add__"", 2, number_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""__sub__"", 2, number_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""__mul__"", 2, number_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""__eq__"", 2, number_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""__ne__"", 2, number_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""__lt__"", 2, default_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""__gt__"", 2, default_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""__ge__"", 2, default_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""__pos__"", 1, number_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""__neg__"", 1, number_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""__pow__"", 2, inexact_dtypes, all_shapes, jtu.rand_positive, [],\n              tolerance={onp.float32: 2e-4, onp.complex64: 2e-4, onp.complex128: 1e-14}),\n    op_record(""__mod__"", 2, minus(default_dtypes, [onp.float16]), all_shapes, jtu.rand_nonzero, [],\n              tolerance={onp.float16: 1e-1}),\n    op_record(""__floordiv__"", 2, default_dtypes, all_shapes, jtu.rand_nonzero, []),\n    op_record(""__truediv__"", 2, number_dtypes, all_shapes, jtu.rand_nonzero, [],\n              inexact=True),\n    op_record(""__abs__"", 1, number_dtypes, all_shapes, jtu.rand_default, []),\n    # TODO(mattjj): __invert__ fails on bool dtypes because ~True == -2\n    op_record(""__invert__"", 1, int_dtypes, all_shapes, jtu.rand_default, []),\n    # TODO(mattjj): investigate these failures\n    # op_record(""__or__"", 2, number_dtypes, all_shapes, jtu.rand_bool, []),\n    # op_record(""__and__"", 2, number_dtypes, all_shapes, jtu.rand_default, []),\n    # op_record(""__xor__"", 2, number_dtypes, all_shapes, jtu.rand_bool, []),\n    # op_record(""__divmod__"", 2, number_dtypes, all_shapes, jtu.rand_nonzero, []),\n    # TODO(mattjj): lshift, rshift\n]\n\nJAX_RIGHT_OPERATOR_OVERLOADS = [\n    op_record(""__radd__"", 2, number_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""__rsub__"", 2, number_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""__rmul__"", 2, number_dtypes, all_shapes, jtu.rand_default, []),\n    op_record(""__rpow__"", 2, inexact_dtypes, all_shapes, jtu.rand_positive, [],\n              tolerance={onp.float32: 2e-4, onp.complex64: 1e-3}),\n    op_record(""__rmod__"", 2, minus(default_dtypes, [onp.float16]), all_shapes, jtu.rand_nonzero, [],\n              tolerance={onp.float16: 1e-1}),\n    op_record(""__rfloordiv__"", 2, default_dtypes, all_shapes, jtu.rand_nonzero, []),\n    op_record(""__rtruediv__"", 2, number_dtypes, all_shapes, jtu.rand_nonzero, [],\n              inexact=True),\n    # op_record(""__ror__"", 2, number_dtypes, all_shapes, jtu.rand_bool, []),\n    # op_record(""__rand__"", 2, number_dtypes, all_shapes, jtu.rand_default, []),\n    # op_record(""__rxor__"", 2, number_dtypes, all_shapes, jtu.rand_bool, []),\n    # op_record(""__rdivmod__"", 2, number_dtypes, all_shapes, jtu.rand_nonzero, []),\n]\n\nnumpy_version = tuple(map(int, onp.version.version.split(\'.\')))\nif numpy_version >= (1, 15):\n  JAX_COMPOUND_OP_RECORDS += [\n      op_record(""isclose"", 2, [t for t in all_dtypes if t != lnp.bfloat16],\n                all_shapes, jtu.rand_small_positive, []),\n      op_record(""gcd"", 2, int_dtypes, all_shapes, jtu.rand_default, []),\n      op_record(""lcm"", 2, int_dtypes, all_shapes, jtu.rand_default, []),\n  ]\n  JAX_REDUCER_NO_DTYPE_RECORDS += [\n      op_record(""ptp"", 1, minus(number_dtypes, complex_dtypes), nonempty_shapes,\n                jtu.rand_default, []),\n  ]\n\nif six.PY2:\n  JAX_OPERATOR_OVERLOADS += [\n    op_record(""__div__"", 2, number_dtypes, all_shapes, jtu.rand_nonzero, []),\n  ]\n  JAX_RIGHT_OPERATOR_OVERLOADS += [\n    op_record(""__rdiv__"", 2, number_dtypes, all_shapes, jtu.rand_nonzero, []),\n  ]\n\n\nCombosWithReplacement = itertools.combinations_with_replacement\n\n\ndef _dtypes_are_compatible_for_bitwise_ops(args):\n  if len(args) <= 1:\n    return True\n  is_signed = lambda dtype: lnp.issubdtype(dtype, onp.signedinteger)\n  width = lambda dtype: lnp.iinfo(dtype).bits\n  x, y = args\n  # `lnp.iinfo(dtype).bits` can\'t be called on bools, so we convert bools to\n  # ints.\n  if x == lnp.bool_:\n    x = lnp.int32\n  if y == lnp.bool_:\n    y = lnp.int32\n  if width(x) > width(y):\n    x, y = y, x\n  if x == lnp.uint32 and y == lnp.uint64:\n    return False\n  # The following condition seems a little ad hoc, but seems to capture what\n  # numpy actually implements.\n  return (\n      is_signed(x) == is_signed(y)\n      or (width(x) == 32 and width(y) == 32)\n      or (width(x) == 32 and width(y) == 64 and is_signed(y)))\n\n\ndef _shapes_are_broadcast_compatible(shapes):\n  accumulator = onp.zeros([])\n  for shape in shapes:\n    try:\n      accumulator = accumulator + onp.zeros(shape)\n    except ValueError:\n      return False\n  return True\n\ndef _shapes_are_equal_length(shapes):\n  return all(len(shape) == len(shapes[0]) for shape in shapes[1:])\n\n\ndef _promote_like_lnp(fun, inexact=False):\n  """"""Decorator that promotes the arguments of `fun` to `lnp.result_type(*args)`.\n\n  lnp and onp have different type promotion semantics; this decorator allows\n  tests make an onp reference implementation act more like an lnp\n  implementation.\n  """"""\n  def wrapper(*args, **kw):\n    flat_args = tf.nest.flatten(args)\n    if inexact and not any(lnp.issubdtype(lnp.result_type(x), lnp.inexact)\n                           for x in flat_args):\n      dtype = lnp.result_type(lnp.float_, *flat_args)\n    else:\n      dtype = lnp.result_type(*flat_args)\n    args = tf.nest.map_structure(lambda a: onp.asarray(a, dtype), args)\n    return fun(*args, **kw)\n  return wrapper\n\n\ndef new_test(f):\n\n  def wrapper(self, *args, **kwargs):\n    if not FLAGS.tf_numpy_additional_tests:\n      self.skipTest(""Newly added test is disabled, since flag is False."")\n    else:\n      f(self, *args, **kwargs)\n\n  return wrapper\n\n\ndef named_parameters(ls):\n  """"""A version that allows an empty param list.""""""\n  def noop(_):\n    def wrapper(self, *args, **kwargs):\n      self.skipTest(""Empty parameter list"")\n    return wrapper\n  if isinstance(ls, (list, tuple)) and not ls:\n    return noop\n  if isinstance(ls, itertools.chain):\n    try:\n      first = next(ls)\n    except StopIteration:\n      return noop\n    else:\n      ls = itertools.chain([first], ls)\n  return parameterized.named_parameters(ls)\n\n\n# TODO(wangpeng): Enable all disabled tests in this class\nclass LaxBackedNumpyTests(jtu.TestCase):\n  """"""Tests for LAX-backed Numpy implementation.""""""\n\n  def _GetArgsMaker(self, rng, shapes, dtypes, onp_arrays=True):\n    def f():\n      out = [rng(shape, dtype or lnp.float_)\n             for shape, dtype in zip(shapes, dtypes)]\n      return out if onp_arrays else [lnp.asarray(a) for a in out]\n    return f\n\n  @named_parameters(itertools.chain.from_iterable(\n      jtu.cases_from_list(\n        {""testcase_name"": jtu.format_test_name_suffix(rec.test_name, shapes,\n                                                      dtypes),\n         ""rng_factory"": rec.rng_factory, ""shapes"": shapes, ""dtypes"": dtypes,\n         ""onp_op"": getattr(onp, rec.name), ""lnp_op"": getattr(lnp, rec.name),\n         ""check_dtypes"": rec.check_dtypes, ""tolerance"": rec.tolerance,\n         ""inexact"": rec.inexact}\n        for shapes in filter(\n          _shapes_are_broadcast_compatible,\n          CombosWithReplacement(rec.shapes, rec.nargs))\n        for dtypes in itertools.product(\n          *(_valid_dtypes_for_shape(s, rec.dtypes) for s in shapes)))\n      for rec in itertools.chain(JAX_ONE_TO_ONE_OP_RECORDS,\n                                 JAX_COMPOUND_OP_RECORDS)))\n  def testOp(self, onp_op, lnp_op, rng_factory, shapes, dtypes, check_dtypes,\n             tolerance, inexact):\n    # TODO(b/147769803): Remove this skipping\n    if lnp_op.__name__ == ""kron"" and shapes == ((2, 3, 4), (2, 3, 4)):\n      self.skipTest(""Case disabled because of b/147769803"")\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng, shapes, dtypes, onp_arrays=False)\n    tol = max(jtu.tolerance(dtype, tolerance) for dtype in dtypes)\n    tol = functools.reduce(jtu.join_tolerance,\n                           [tolerance, tol, jtu.default_tolerance()])\n    self._CheckAgainstNumpy(_promote_like_lnp(onp_op, inexact), lnp_op,\n                            args_maker, check_dtypes=check_dtypes, tol=tol)\n    self._CompileAndCheck(lnp_op, args_maker, check_dtypes=check_dtypes,\n                          atol=tol, rtol=tol)\n\n  @named_parameters(itertools.chain.from_iterable(\n      jtu.cases_from_list(\n        {""testcase_name"": jtu.format_test_name_suffix(rec.test_name, shapes,\n                                                      dtypes),\n         ""rng_factory"": rec.rng_factory, ""shapes"": shapes, ""dtypes"": dtypes, ""name"": rec.name,\n         ""tol"": rec.tolerance}\n        for shapes in filter(\n          _shapes_are_broadcast_compatible,\n          CombosWithReplacement(rec.shapes, rec.nargs))\n        for dtypes in itertools.product(\n          *(_valid_dtypes_for_shape(s, rec.dtypes) for s in shapes)))\n      for rec in JAX_OPERATOR_OVERLOADS))\n  def testOperatorOverload(self, name, rng_factory, shapes, dtypes, tol):\n    rng = rng_factory()\n    # onp and lnp arrays have different type promotion rules; force the use of\n    # lnp arrays.\n    args_maker = self._GetArgsMaker(rng, shapes, dtypes, onp_arrays=False)\n    fun = lambda *xs: getattr(operator, name.strip(\'_\'))(*xs)\n    scalar_arg = (jtu.PYTHON_SCALAR_SHAPE in shapes or\n                  jtu.NUMPY_SCALAR_SHAPE in shapes or\n                  () in shapes)\n    empty_shape = any(isinstance(s, tuple) and 0 in s for s in shapes)\n    self._CompileAndCheck(\n      fun, args_maker, check_dtypes=True, #not scalar_arg and not empty_shape,\n      atol=tol, rtol=tol)\n\n  @named_parameters(itertools.chain.from_iterable(\n      jtu.cases_from_list(\n        {""testcase_name"": jtu.format_test_name_suffix(rec.test_name, shapes,\n                                                      dtypes),\n         ""rng_factory"": rec.rng_factory, ""shapes"": shapes, ""dtypes"": dtypes, ""name"": rec.name,\n         ""op_tolerance"": rec.tolerance}\n        for shapes in filter(\n          _shapes_are_broadcast_compatible,\n          CombosWithReplacement(rec.shapes, rec.nargs))\n        for dtypes in itertools.product(\n          *(_valid_dtypes_for_shape(s, rec.dtypes) for s in shapes)))\n      for rec in JAX_RIGHT_OPERATOR_OVERLOADS))\n  def testRightOperatorOverload(self, name, rng_factory, shapes, dtypes,\n                                op_tolerance):\n    if shapes[1] is jtu.PYTHON_SCALAR_SHAPE:\n      raise SkipTest()  # TODO(mattjj): clean up\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng, shapes, dtypes, onp_arrays=False)\n    fun = lambda fst, snd: getattr(snd, name)(fst)\n    tol = max(jtu.tolerance(dtype, op_tolerance) for dtype in dtypes)\n    scalar_arg = (jtu.PYTHON_SCALAR_SHAPE in shapes or\n                  jtu.NUMPY_SCALAR_SHAPE in shapes or\n                  () in shapes)\n    empty_shape = any(isinstance(s, tuple) and 0 in s for s in shapes)\n    self._CompileAndCheck(\n      fun, args_maker, check_dtypes=True, # not scalar_arg and not empty_shape,\n      atol=tol, rtol=tol)\n\n  @named_parameters(itertools.chain.from_iterable(\n      jtu.cases_from_list(\n        {""testcase_name"": jtu.format_test_name_suffix(\n            rec.test_name, shapes, dtypes),\n         ""rng_factory"": rec.rng_factory, ""shapes"": shapes, ""dtypes"": dtypes,\n         ""onp_op"": getattr(onp, rec.name), ""lnp_op"": getattr(lnp, rec.name)}\n        for shapes in filter(\n          _shapes_are_broadcast_compatible,\n          CombosWithReplacement(rec.shapes, rec.nargs))\n        for dtypes in filter(\n          _dtypes_are_compatible_for_bitwise_ops,\n          CombosWithReplacement(rec.dtypes, rec.nargs)))\n      for rec in JAX_BITWISE_OP_RECORDS))\n  def testBitwiseOp(self, onp_op, lnp_op, rng_factory, shapes, dtypes):\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng, shapes, dtypes)\n    has_python_scalar = jtu.PYTHON_SCALAR_SHAPE in shapes\n    self._CheckAgainstNumpy(onp_op, lnp_op, args_maker, check_dtypes=True)\n    if onp_op == onp.bitwise_not and has_python_scalar:\n      # For bitwise_not with a Python `int`, npe.jit may choose a different\n      # dtype for the `int` from onp\'s choice, which may result in a different\n      # result value, so we skip _CompileAndCheck.\n      return\n    # Numpy does value-dependent dtype promotion on Python/numpy/array scalars\n    # which `jit` can\'t do (when np.result_type is called inside `jit`, tensor\n    # values are not available), so we skip dtype check in this case.\n    check_dtypes = not(set(shapes) & set([jtu.NUMPY_SCALAR_SHAPE,\n                                          jtu.PYTHON_SCALAR_SHAPE, ()]))\n    self._CompileAndCheck(lnp_op, args_maker, check_dtypes=check_dtypes)\n\n  @named_parameters(itertools.chain.from_iterable(\n      jtu.cases_from_list(\n        {""testcase_name"": ""{}_inshape={}_axis={}_dtype={}_keepdims={}"".format(\n            rec.test_name.capitalize(),\n            jtu.format_shape_dtype_string(shape, dtype), axis,\n            ""None"" if out_dtype is None else onp.dtype(out_dtype).name, keepdims),\n         ""rng_factory"": rec.rng_factory, ""shape"": shape, ""dtype"": dtype, ""out_dtype"": out_dtype,\n         ""onp_op"": getattr(onp, rec.name), ""lnp_op"": getattr(lnp, rec.name),\n         ""axis"": axis, ""keepdims"": keepdims, ""inexact"": rec.inexact}\n        for shape in rec.shapes for dtype in rec.dtypes\n        for out_dtype in [None] + rec.dtypes\n        for axis in set(range(-len(shape), len(shape))) | set([None])\n        for keepdims in [False, True])\n    for rec in JAX_REDUCER_RECORDS))\n  def testReducer(self, onp_op, lnp_op, rng_factory, shape, dtype, out_dtype,\n                  axis, keepdims, inexact):\n    rng = rng_factory()\n    def onp_fun(x):\n      x_cast = x if dtype != lnp.bfloat16 else x.astype(onp.float32)\n      t = out_dtype if out_dtype != lnp.bfloat16 else onp.float32\n      return onp_op(x_cast, axis, dtype=t, keepdims=keepdims)\n    onp_fun = _promote_like_lnp(onp_fun, inexact)\n    lnp_fun = lambda x: lnp_op(x, axis, dtype=out_dtype, keepdims=keepdims)\n    args_maker = lambda: [rng(shape, dtype)]\n    tol_spec = {onp.float16: 1e-2, onp.float32: 1e-3, onp.complex64: 1e-3,\n                onp.float64: 1e-5, onp.complex128: 1e-5}\n    tol = jtu.tolerance(dtype, tol_spec)\n    tol = max(tol, jtu.tolerance(out_dtype, tol_spec)) if out_dtype else tol\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker,\n                            check_dtypes=lnp.bfloat16 not in (dtype, out_dtype),\n                            tol=tol)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True, atol=tol,\n                          rtol=tol)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""{}_inshape={}_axis={}_keepdims={}"".format(\n          rec.test_name.capitalize(),\n          jtu.format_shape_dtype_string(shape, dtype), axis, keepdims),\n       ""rng_factory"": rec.rng_factory, ""shape"": shape, ""dtype"": dtype,\n       ""onp_op"": getattr(onp, rec.name), ""lnp_op"": getattr(lnp, rec.name),\n       ""axis"": axis, ""keepdims"": keepdims, ""inexact"": rec.inexact}\n      for rec in JAX_REDUCER_NO_DTYPE_RECORDS\n      for shape in rec.shapes for dtype in rec.dtypes\n      for axis in set(range(-len(shape), len(shape))) | set([None])\n      for keepdims in [False, True]))\n  def testReducerNoDtype(self, onp_op, lnp_op, rng_factory, shape, dtype, axis,\n                         keepdims, inexact):\n    rng = rng_factory()\n    onp_fun = lambda x: onp_op(x, axis, keepdims=keepdims)\n    onp_fun = _promote_like_lnp(onp_fun, inexact)\n    lnp_fun = lambda x: lnp_op(x, axis, keepdims=keepdims)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_shape={}_axis={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype), axis),\n       ""shape"": shape, ""dtype"": dtype, ""axis"": axis}\n      for shape in all_shapes for dtype in all_dtypes\n      for axis in set(range(-len(shape), len(shape))) | set([None])))\n  def testCountNonzero(self, shape, dtype, axis):\n    rng = jtu.rand_some_zero()\n    onp_fun = lambda x: onp.count_nonzero(x, axis)\n    lnp_fun = lambda x: lnp.count_nonzero(x, axis)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=False)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_shape={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype)),\n       ""shape"": shape, ""dtype"": dtype}\n      for shape in all_shapes for dtype in all_dtypes))\n  def testNonzero(self, shape, dtype):\n    rng = jtu.rand_some_zero()\n    onp_fun = lambda x: onp.nonzero(x)\n    lnp_fun = lambda x: lnp.nonzero(x)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=False)\n    # The shapes of `nonzero`\'s results are value-dependent, so `eval_on_shapes`\n    # won\'t return concrete shapes.\n    # Also, `nonzero` requires a known rank.\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_eval_on_shapes=False,\n        check_incomplete_shape=True, check_unknown_rank=False)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""{}_inshape={}_axis={}"".format(\n          rec.test_name.capitalize(),\n          jtu.format_shape_dtype_string(shape, dtype), axis),\n       ""rng_factory"": rec.rng_factory, ""shape"": shape, ""dtype"": dtype,\n       ""onp_op"": getattr(onp, rec.name), ""lnp_op"": getattr(lnp, rec.name),\n       ""axis"": axis}\n      for rec in JAX_ARGMINMAX_RECORDS\n      for shape, dtype in _shape_and_dtypes(rec.shapes, rec.dtypes)\n      for axis in range(-len(shape), len(shape))))\n  def testArgMinMax(self, onp_op, lnp_op, rng_factory, shape, dtype, axis):\n    rng = rng_factory()\n    if dtype == onp.complex128 and jtu.device_under_test() == ""gpu"":\n      raise unittest.SkipTest(""complex128 reductions not supported on GPU"")\n\n    def onp_fun(array_to_reduce):\n      return onp_op(array_to_reduce, axis).astype(lnp.int_)\n\n    def lnp_fun(array_to_reduce):\n      return lnp_op(array_to_reduce, axis)\n\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_{}_{}"".format(\n          jtu.format_shape_dtype_string(lhs_shape, lhs_dtype),\n          jtu.format_shape_dtype_string(rhs_shape, rhs_dtype),\n          axes),\n       ""lhs_shape"": lhs_shape, ""lhs_dtype"": lhs_dtype,\n       ""rhs_shape"": rhs_shape, ""rhs_dtype"": rhs_dtype,\n       ""axes"": axes, ""rng_factory"": rng_factory}\n      for rng_factory in [jtu.rand_default]\n      for lhs_shape, rhs_shape, axes in [\n          [(2,), (2,), (-1, -1, -1, None)], # scalar output\n          [(2, 4), (2, 4), (-1, -1, -1, 0)], # 2D vectors\n          [(3, 4), (3, 4), (-1, -1, -1, 0)], # 3D vectors\n          [(3, 4), (3, 6, 5, 4), (-1, -1, -1, 0)], # broadcasting\n          [(4, 3), (3, 6, 5, 4), (1, 0, -1, None)], # different axes\n          [(6, 1, 3), (5, 3), (-1, -1, -1, None)], # more broadcasting\n          [(6, 1, 2), (5, 3), (-1, -1, -1, None)], # mixed 2D and 3D vectors\n          [(10, 5, 2, 8), (1, 5, 1, 3), (-2, -1, -3, None)], # axes/broadcasting\n          [(4, 5, 2), (4, 5, 2), (-1, -1, 0, None)], # axisc should do nothing\n          [(4, 5, 2), (4, 5, 2), (-1, -1, -1, None)] # same as before\n      ]\n      for lhs_dtype, rhs_dtype in CombosWithReplacement(\n          minus(number_dtypes, complex_dtypes), 2)))\n  def testCross(self, lhs_shape, lhs_dtype, rhs_shape, rhs_dtype, axes, rng_factory):\n    rng = rng_factory()\n    args_maker = lambda: [rng(lhs_shape, lhs_dtype), rng(rhs_shape, rhs_dtype)]\n    axisa, axisb, axisc, axis = axes\n    lnp_fun = lambda a, b: lnp.cross(a, b, axisa, axisb, axisc, axis)\n    def onp_fun(a, b):\n      a = a.astype(onp.float32) if lhs_dtype == lnp.bfloat16 else a\n      b = b.astype(onp.float32) if rhs_dtype == lnp.bfloat16 else b\n      out = onp.cross(a, b, axisa, axisb, axisc, axis)\n      return out.astype(lnp.promote_types(lhs_dtype, rhs_dtype))\n    tol_spec = {\n        # TODO(wangpeng): dtypes.bfloat16: 3e-1,\n        onp.float16: 0.15}\n    tol = max(jtu.tolerance(lhs_dtype, tol_spec),\n              jtu.tolerance(rhs_dtype, tol_spec))\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True,\n                            tol=tol)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True, atol=tol,\n                          rtol=tol, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_{}_{}"".format(\n          name,\n          jtu.format_shape_dtype_string(lhs_shape, lhs_dtype),\n          jtu.format_shape_dtype_string(rhs_shape, rhs_dtype)),\n       ""lhs_shape"": lhs_shape, ""lhs_dtype"": lhs_dtype,\n       ""rhs_shape"": rhs_shape, ""rhs_dtype"": rhs_dtype,\n       ""rng_factory"": rng_factory}\n      for rng_factory in [jtu.rand_default]\n      for name, lhs_shape, rhs_shape in [\n          (""matrix-scalar"", (3, 3), ()),\n          (""scalar-matrix"", (), (3, 3)),\n          (""matrix-vector"", (4, 5), (5,)),\n          (""vector-matrix"", (6,), (6, 4)),\n          (""matrix-matrix"", (3, 4), (4, 5)),\n          (""tensor-vector"", (4, 3, 2), (2,)),\n          (""vector-tensor"", (2,), (3, 2, 4)),\n          (""tensor-matrix"", (4, 3, 2), (2, 5)),\n          (""matrix-tensor"", (5, 2), (3, 2, 4)),\n          (""tensor-tensor"", (2, 3, 4), (5, 4, 1))]\n      for lhs_dtype, rhs_dtype in CombosWithReplacement(number_dtypes, 2)))\n  def testDot(self, lhs_shape, lhs_dtype, rhs_shape, rhs_dtype, rng_factory):\n    rng = rng_factory()\n    args_maker = lambda: [rng(lhs_shape, lhs_dtype), rng(rhs_shape, rhs_dtype)]\n    tol = {onp.float16: 1e-2, onp.float32: 1e-5, onp.float64: 1e-14,\n           onp.complex128: 1e-14}\n    if jtu.device_under_test() == ""tpu"":\n      tol[onp.float32] = tol[onp.complex64] = 2e-1\n    def onp_dot(x, y):\n      x = x.astype(onp.float32) if lhs_dtype == lnp.bfloat16 else x\n      y = y.astype(onp.float32) if rhs_dtype == lnp.bfloat16 else y\n      # `onp.dot(x, y).dtype` sometimes differs from `onp.result_type(x, y)`\n      # (e.g. when x is float64[] and y is complex64[3,3], or when x is\n      # float16[3,3] and y is int64[]). We ignore this corner case and pretend\n      # that they agree.\n      return onp.dot(x, y).astype(onp.result_type(x, y))\n    self._CheckAgainstNumpy(onp_dot, lnp.dot, args_maker,\n                            check_dtypes=True, tol=tol)\n    # We disable dtype check in the following cases because `np.dot` does\n    # value-dependent type promotion in those cases.\n    check_dtypes = () not in (lhs_shape, rhs_shape)\n    self._CompileAndCheck(lnp.dot, args_maker, check_dtypes=check_dtypes,\n                          atol=tol, rtol=tol, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_{}_{}"".format(\n          name,\n          jtu.format_shape_dtype_string(lhs_shape, lhs_dtype),\n          jtu.format_shape_dtype_string(rhs_shape, rhs_dtype)),\n       ""lhs_shape"": lhs_shape, ""lhs_dtype"": lhs_dtype,\n       ""rhs_shape"": rhs_shape, ""rhs_dtype"": rhs_dtype,\n       ""rng_factory"": rng_factory}\n      for rng_factory in [jtu.rand_default]\n      for name, lhs_shape, rhs_shape in [\n          (""vector-vector"", (3,), (3,)),\n          (""matrix-vector"", (3, 3), (3,)),\n          (""vector-matrix"", (3,), (3, 3)),\n          (""matrix-matrix"", (3, 3), (3, 3)),\n          (""vector-tensor"", (3,), (5, 3, 2)),\n          (""tensor-vector"", (5, 3, 2), (2,)),\n          (""matrix-tensor"", (5, 2), (3, 2, 4)),\n          (""tensor-matrix"", (5, 2, 3), (3, 2)),\n          (""tensor-tensor"", (5, 3, 4), (5, 4, 1)),\n          (""tensor-tensor-broadcast"", (3, 1, 3, 4), (5, 4, 1))]\n      for lhs_dtype, rhs_dtype in CombosWithReplacement(number_dtypes, 2)))\n  def testMatmul(self, lhs_shape, lhs_dtype, rhs_shape, rhs_dtype, rng_factory):\n    rng = rng_factory()\n    def onp_fun(x, y):\n      dtype = lnp.promote_types(lhs_dtype, rhs_dtype)\n      return onp.matmul(x, y).astype(dtype)\n    args_maker = lambda: [rng(lhs_shape, lhs_dtype), rng(rhs_shape, rhs_dtype)]\n    tol = {onp.float16: 1e-2, onp.float32: 2e-2, onp.float64: 1e-12,\n           onp.complex128: 1e-12}\n    if jtu.device_under_test() == ""tpu"":\n      tol[onp.float32] = tol[onp.complex64] = 4e-2\n    self._CheckAgainstNumpy(onp_fun, lnp.matmul, args_maker,\n                            check_dtypes=True, tol=tol)\n    self._CompileAndCheck(lnp.matmul, args_maker, check_dtypes=True, atol=tol,\n                          rtol=tol, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_{}_{}"".format(\n          jtu.format_shape_dtype_string(lhs_shape, lhs_dtype),\n          jtu.format_shape_dtype_string(rhs_shape, rhs_dtype),\n          axes),\n       ""lhs_shape"": lhs_shape, ""lhs_dtype"": lhs_dtype,\n       ""rhs_shape"": rhs_shape, ""rhs_dtype"": rhs_dtype,\n       ""axes"": axes, ""rng_factory"": rng_factory}\n      for rng_factory in [jtu.rand_default]\n      for lhs_shape, rhs_shape, axes in [\n          [(2, 3, 4), (5, 6, 7), 0],  # from issue #740\n          [(2, 3, 4), (3, 4, 5, 6), 2],\n          [(2, 3, 4), (5, 4, 3, 6), [1, 2]],\n          [(2, 3, 4), (5, 4, 3, 6), [[1, 2], [2, 1]]],\n          [(1, 2, 3, 4), (4, 5, 3, 6), [[2, 3], [2, 0]]],\n      ]\n      for lhs_dtype, rhs_dtype in CombosWithReplacement(number_dtypes, 2)))\n  def testTensordot(self, lhs_shape, lhs_dtype, rhs_shape, rhs_dtype, axes, rng_factory):\n    rng = rng_factory()\n    args_maker = lambda: [rng(lhs_shape, lhs_dtype), rng(rhs_shape, rhs_dtype)]\n    lnp_fun = lambda a, b: lnp.tensordot(a, b, axes)\n    def onp_fun(a, b):\n      a = a if lhs_dtype != lnp.bfloat16 else a.astype(onp.float32)\n      b = b if rhs_dtype != lnp.bfloat16 else b.astype(onp.float32)\n      dtype = lnp.promote_types(lhs_dtype, rhs_dtype)\n      return onp.tensordot(a, b, axes).astype(dtype)\n    tol = {onp.float16: 1e-1, onp.float32: 1e-3, onp.float64: 1e-12,\n           onp.complex64: 1e-3, onp.complex128: 1e-12}\n    if jtu.device_under_test() == ""tpu"":\n      tol[onp.float32] = tol[onp.complex64] = 2e-1\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True,\n                            tol=tol)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True,\n                          check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_{}"".format(\n          jtu.format_shape_dtype_string(lhs_shape, lhs_dtype),\n          jtu.format_shape_dtype_string(rhs_shape, rhs_dtype)),\n       ""lhs_shape"": lhs_shape, ""lhs_dtype"": lhs_dtype,\n       ""rhs_shape"": rhs_shape, ""rhs_dtype"": rhs_dtype,\n       ""rng_factory"": jtu.rand_default}\n      # TODO(phawkins): support integer dtypes too.\n      for lhs_shape, lhs_dtype in _shape_and_dtypes(all_shapes, inexact_dtypes)\n      for rhs_shape, rhs_dtype in _shape_and_dtypes(all_shapes, inexact_dtypes)\n      if len(jtu._dims_of_shape(lhs_shape)) == 0\n      or len(jtu._dims_of_shape(rhs_shape)) == 0\n      or lhs_shape[-1] == rhs_shape[-1]))\n  def testInner(self, lhs_shape, lhs_dtype, rhs_shape, rhs_dtype, rng_factory):\n    rng = rng_factory()\n    args_maker = lambda: [rng(lhs_shape, lhs_dtype), rng(rhs_shape, rhs_dtype)]\n    def onp_fun(lhs, rhs):\n      lhs = lhs if lhs_dtype != lnp.bfloat16 else lhs.astype(onp.float32)\n      rhs = rhs if rhs_dtype != lnp.bfloat16 else rhs.astype(onp.float32)\n      dtype = lnp.promote_types(lhs_dtype, rhs_dtype)\n      return onp.inner(lhs, rhs).astype(dtype)\n    lnp_fun = lambda lhs, rhs: lnp.inner(lhs, rhs)\n    tol_spec = {onp.float16: 1e-2, onp.float32: 1e-5, onp.float64: 2e-6}\n    if jtu.device_under_test() == ""tpu"":\n      tol_spec[onp.float32] = tol_spec[onp.complex64] = 2e-1\n    tol = max(jtu.tolerance(lhs_dtype, tol_spec),\n              jtu.tolerance(rhs_dtype, tol_spec))\n    # TODO(phawkins): there are float32/float64 disagreements for some inputs.\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=False,\n                            tol=tol)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=False, atol=tol,\n                          rtol=tol, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_amin={}_amax={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype), a_min, a_max),\n       ""shape"": shape, ""dtype"": dtype, ""a_min"": a_min, ""a_max"": a_max,\n       ""rng_factory"": jtu.rand_default}\n      for shape in all_shapes for dtype in minus(number_dtypes, complex_dtypes)\n      for a_min, a_max in [(-1, None), (None, 1), (-1, 1),\n                           (-onp.ones(1), None),\n                           (None, onp.ones(1)),\n                           (-onp.ones(1), onp.ones(1))]))\n  def testClipStaticBounds(self, shape, dtype, a_min, a_max, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda x: onp.clip(x, a_min=a_min, a_max=a_max)\n    lnp_fun = lambda x: lnp.clip(x, a_min=a_min, a_max=a_max)\n    args_maker = lambda: [rng(shape, dtype)]\n    tol_spec = {onp.float64: 2e-7}\n    tol = jtu.tolerance(dtype, tol_spec)\n    is_x32_scalar = (dtype in [onp.int32, onp.float32] and\n                     shape in [jtu.NUMPY_SCALAR_SHAPE, ()])\n    # Turns check_dtypes off if is_x32_scalar is True because there is\n    # a weird promotion inconsistency in numpy:\n    # ```\n    # print(np.result_type(np.ones([], np.int32), 1))\n    # print(np.result_type(np.ones([1], np.int32), 1))\n    # print(np.result_type(np.int32(1), 1))\n    # print(np.result_type(np.int32, 1))\n    # print(np.result_type(np.ones([], np.float32), 1))\n    # print(np.result_type(np.ones([1], np.float32), 1))\n    # print(np.result_type(np.float32(1), 1))\n    # print(np.result_type(np.float32, 1))\n    # ```\n    # >>>\n    # int64\n    # int32\n    # int64\n    # int32\n    # float64\n    # float32\n    # float64\n    # float32\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker,\n                            check_dtypes=not is_x32_scalar, tol=tol)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=not is_x32_scalar,\n                          atol=tol, rtol=tol, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_decimals={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype), decimals),\n       ""shape"": shape, ""dtype"": dtype, ""decimals"": decimals,\n       ""rng_factory"": jtu.rand_default}\n      for shape, dtype in _shape_and_dtypes(\n          all_shapes, minus(number_dtypes, complex_dtypes))\n      for decimals in [0, 1, -2]))\n  def testRoundStaticDecimals(self, shape, dtype, decimals, rng_factory):\n    rng = rng_factory()\n    if lnp.issubdtype(dtype, onp.integer) and decimals < 0:\n      self.skipTest(""Integer rounding with decimals < 0 not implemented"")\n    onp_fun = lambda x: onp.round(x, decimals=decimals)\n    lnp_fun = lambda x: lnp.round(x, decimals=decimals)\n    args_maker = lambda: [rng(shape, dtype)]\n    tol = {\n        # TODO(b/154768983): lnp.bfloat16: 5e-2,\n        onp.float16: 1e-2}\n    check_dtypes = shape is not jtu.PYTHON_SCALAR_SHAPE\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker,\n                            check_dtypes=check_dtypes, tol=tol)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=check_dtypes,\n                          atol=tol, rtol=tol, check_incomplete_shape=True)\n\n  def testOperatorRound(self):\n    self.assertAllClose(round(onp.float32(7.532), 1),\n                        round(lnp.float32(7.5), 1), check_dtypes=True)\n    self.assertAllClose(round(onp.float32(1.234), 2),\n                        round(lnp.float32(1.234), 2), check_dtypes=True)\n    self.assertAllClose(round(onp.float32(1.234)),\n                        round(lnp.float32(1.234)), check_dtypes=False)\n    self.assertAllClose(round(onp.float32(7.532), 1),\n                        round(lnp.array(7.5, lnp.float32), 1), check_dtypes=True)\n    self.assertAllClose(round(onp.float32(1.234), 2),\n                        round(lnp.array(1.234, lnp.float32), 2), check_dtypes=True)\n    self.assertAllClose(round(onp.float32(1.234)),\n                        round(lnp.array(1.234, lnp.float32)),\n                        check_dtypes=False)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_shape={}_mode={}_rpadwidth={}_rconstantvalues={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype), mode, pad_width_rank,\n          constant_values_rank),\n       ""shape"": shape, ""dtype"": dtype, ""mode"": mode,\n       ""pad_width_rank"": pad_width_rank,\n       ""constant_values_rank"": constant_values_rank,\n       ""rng_factory"": jtu.rand_default,\n       ""irng_factory"": partial(jtu.rand_int, 3)}\n      for mode, constant_values_rank, shapes in [\n        (\'constant\', 0, all_shapes),\n        (\'constant\', 1, all_shapes),\n        (\'constant\', 2, all_shapes),\n        (\'symmetric\', None, nonempty_shapes),\n        (\'reflect\', None, nonempty_shapes),\n        (\'wrap\', None, nonempty_shapes),\n      ]\n      for shape, dtype in _shape_and_dtypes(shapes, all_dtypes)\n      for pad_width_rank in range(3)))\n  @jtu.disable\n  def testPad(self, shape, dtype, mode, pad_width_rank, constant_values_rank,\n              rng_factory, irng_factory):\n    rng = rng_factory()\n    irng = irng_factory()\n    pad_width = irng([len(shape), 2][2 - pad_width_rank:], onp.int32)\n    def onp_fun(x, kwargs):\n      if pad_width.size == 0:\n        return x\n      return onp.pad(x, pad_width, mode=mode, **kwargs)\n    def lnp_fun(x, kwargs):\n      return lnp.pad(x, pad_width, mode=mode, **kwargs)\n\n    def args_maker():\n      kwargs = {}\n      if constant_values_rank:\n        kwargs[""constant_values""] = rng(\n          [len(shape), 2][2 - constant_values_rank:], dtype)\n      return rng(shape, dtype), kwargs\n\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker,\n                            check_dtypes=shape is not jtu.PYTHON_SCALAR_SHAPE)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_shape=[{}]_reps={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype), reps),\n       ""shape"": shape, ""dtype"": dtype, ""reps"": reps,\n       ""rng_factory"": jtu.rand_default}\n      for reps in [(), (2,), (3, 4), (2, 3, 4)]\n      for shape, dtype in _shape_and_dtypes(all_shapes, default_dtypes)\n      ))\n  def testTile(self, shape, dtype, reps, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda arg: onp.tile(arg, reps)\n    lnp_fun = lambda arg: lnp.tile(arg, reps)\n    args_maker = lambda: [rng(shape, dtype)]\n    tol_spec = {onp.float64: 2e-7}\n    tol = jtu.tolerance(dtype, tol_spec)\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker,\n                            check_dtypes=shape is not jtu.PYTHON_SCALAR_SHAPE,\n                            tol=tol)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True, atol=tol,\n                          rtol=tol)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_axis={}_baseshape=[{}]_dtypes=[{}]"".format(\n          axis, "","".join(str(d) for d in base_shape),\n          "","".join(onp.dtype(dtype).name for dtype in arg_dtypes)),\n       ""axis"": axis, ""base_shape"": base_shape, ""arg_dtypes"": arg_dtypes,\n       ""rng_factory"": jtu.rand_default}\n      for num_arrs in [3]\n      for arg_dtypes in CombosWithReplacement(default_dtypes, num_arrs)\n      for base_shape in [(4,), (3, 4), (2, 3, 4)]\n      for axis in range(-len(base_shape)+1, len(base_shape))))\n  def testConcatenate(self, axis, base_shape, arg_dtypes, rng_factory):\n    rng = rng_factory()\n    wrapped_axis = axis % len(base_shape)\n    shapes = [base_shape[:wrapped_axis] + (size,) + base_shape[wrapped_axis+1:]\n              for size, _ in zip(itertools.cycle([3, 1, 4]), arg_dtypes)]\n    def onp_fun(*args):\n      # TODO(nareshmodi): enable once bfloat16 has better support\n      # args = [x if x.dtype != bfloat16 else x.astype(onp.float32)\n      #         for x in args]\n      dtype = functools.reduce(lnp.promote_types, arg_dtypes)\n      return onp.concatenate(args, axis=axis).astype(dtype)\n    lnp_fun = lambda *args: lnp.concatenate(args, axis=axis)\n\n    def args_maker():\n      return [rng(shape, dtype) for shape, dtype in zip(shapes, arg_dtypes)]\n\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_axis={}_baseshape=[{}]_dtypes=[{}]"".format(\n          axis, "","".join(str(d) for d in base_shape),\n          "","".join(onp.dtype(dtype).name for dtype in arg_dtypes)),\n       ""axis"": axis, ""base_shape"": base_shape, ""arg_dtypes"": arg_dtypes,\n       ""rng_factory"": jtu.rand_default}\n      for arg_dtypes in CombosWithReplacement(default_dtypes, 2)\n      for base_shape in [(4,), (3, 4), (2, 3, 4)]\n      for axis in range(-len(base_shape)+1, len(base_shape))))\n  def testAppend(self, axis, base_shape, arg_dtypes, rng_factory):\n    rng = rng_factory()\n    wrapped_axis = axis % len(base_shape)\n    shapes = [base_shape[:wrapped_axis] + (size,) + base_shape[wrapped_axis+1:]\n              for size, _ in zip(itertools.cycle([3, 1, 4]), arg_dtypes)]\n    def onp_fun(arr, values):\n      arr = arr.astype(onp.float32) if lnp.bfloat16 == arr.dtype else arr\n      values = (\n          values.astype(onp.float32)\n          if lnp.bfloat16 == values.dtype else values)\n      out = onp.append(arr, values, axis=axis)\n      return out.astype(lnp.promote_types(*arg_dtypes))\n    lnp_fun = lambda arr, values: lnp.append(arr, values, axis=axis)\n\n    def args_maker():\n      return [rng(shape, dtype) for shape, dtype in zip(shapes, arg_dtypes)]\n\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_shape=[{}]_axis={}_repeats={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype), axis, repeats),\n       ""axis"": axis, ""shape"": shape, ""dtype"": dtype, ""repeats"": repeats,\n       ""rng_factory"": jtu.rand_default}\n      for repeats in [0, 1, 2]\n      for shape, dtype in _shape_and_dtypes(all_shapes, default_dtypes)\n      for axis in [None] + list(range(-len(shape), len(shape)))))\n  def testRepeat(self, axis, shape, dtype, repeats, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda arg: onp.repeat(arg, repeats=repeats, axis=axis)\n    onp_fun = _promote_like_lnp(onp_fun)\n    lnp_fun = lambda arg: lnp.repeat(arg, repeats=repeats, axis=axis)\n\n    args_maker = lambda: [rng(shape, dtype)]\n\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True)\n\n  def testIssue1233(self):\n    \'\'\'\n    Following numpy test suite from `test_repeat` at https://github.com/numpy/numpy/blob/master/numpy/core/tests/test_multiarray.py\n    \'\'\'\n    tol = 1e-5\n\n    def test_single(m, args_maker, repeats, axis):\n      lax_ans = lnp.repeat(m, repeats, axis)\n      numpy_ans = onp.repeat(m, repeats, axis)\n\n      self.assertAllClose(lax_ans, numpy_ans, check_dtypes=True, rtol=tol, atol=tol)\n\n      lnp_fun = lambda arg: lnp.repeat(arg, repeats = repeats, axis=axis)\n      self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True)\n\n    m = lnp.array([1,2,3,4,5,6])\n    args_maker = lambda: [m]\n\n    for repeats in [2, [1,3,2,1,1,2], [1,3,0,1,1,2], [2], lnp.array([1,3,2,1,1,2]), lnp.array([2])]:\n      test_single(m, args_maker, repeats, None)\n\n    m_rect = m.reshape((2,3))\n    args_maker = lambda: [m_rect]\n\n    for repeats in [2, [2,1], [2], lnp.array([2,1]), lnp.array([2])]:\n      test_single(m_rect, args_maker, repeats, axis=0)\n\n    for repeats in [2, [1,3,2], [2], lnp.array([1,3,2]), lnp.array([2])]:\n      test_single(m_rect, args_maker, repeats, axis=1)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""op={}_shape=[{}]_axis={}_out_dtype={}"".format(\n          op, jtu.format_shape_dtype_string(shape, dtype), axis, out_dtype),\n       ""axis"": axis, ""shape"": shape, ""dtype"": dtype, ""out_dtype"": out_dtype,\n       ""rng_factory"": jtu.rand_default, ""lnp_op"": getattr(lnp, op),\n       ""onp_op"": getattr(onp, op)}\n      for op in [""cumsum"", ""cumprod""]\n      for dtype in default_dtypes\n      for out_dtype in default_dtypes\n      for shape in all_shapes\n      for axis in [None] + list(range(-len(shape), len(shape)))))\n  def testCumSumProd(self, axis, shape, dtype, out_dtype, onp_op, lnp_op, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda arg: onp_op(arg, axis=axis, dtype=out_dtype)\n    lnp_fun = lambda arg: lnp_op(arg, axis=axis, dtype=out_dtype)\n\n    args_maker = lambda: [rng(shape, dtype)]\n\n    tol = max(jtu.tolerance(dtype), jtu.tolerance(out_dtype))\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True,\n                            tol=tol)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_dtype={}_m={}_n={}_k={}"".format(\n          onp.dtype(dtype).name, m, n, k),\n       ""m"": m, ""n"": n, ""k"": k, ""dtype"": dtype, ""rng_factory"": jtu.rand_default}\n      for dtype in default_dtypes\n      for n in [0, 4]\n      for m in [None, 0, 1, 3, 4]\n      for k in list(range(-4, 4))))\n  def testTri(self, m, n, k, dtype, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda: onp.tri(n, M=m, k=k, dtype=dtype)\n    lnp_fun = lambda: lnp.tri(n, M=m, k=k, dtype=dtype)\n    args_maker = lambda: []\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_op={}_shape={}_k={}"".format(\n          op, jtu.format_shape_dtype_string(shape, dtype), k),\n       ""dtype"": dtype, ""shape"": shape, ""op"": op, ""k"": k,\n       ""rng_factory"": jtu.rand_default}\n      for dtype in default_dtypes\n      for shape in [shape for shape in all_shapes if len(shape) >= 2]\n      for op in [""tril"", ""triu""]\n      for k in list(range(-3, 3))))\n  def testTriLU(self, dtype, shape, op, k, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda arg: getattr(onp, op)(arg, k=k)\n    lnp_fun = lambda arg: getattr(lnp, op)(arg, k=k)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    # Incomplete shape support is not implemented at the moment.\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_ndim={}_n={}"".format(ndim, n),\n       ""ndim"": ndim, ""n"": n}\n      for ndim in [0, 1, 4]\n      for n in [0, 1, 7]))\n  def testDiagIndices(self, ndim, n):\n    onp.testing.assert_equal(onp.diag_indices(n, ndim),\n                             lnp.diag_indices(n, ndim))\n\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_shape={}_k={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype), k),\n       ""dtype"": dtype, ""shape"": shape, ""k"": k, ""rng_factory"": jtu.rand_default}\n      for dtype in default_dtypes\n      for shape in [shape for shape in all_shapes if len(shape) in (1, 2)]\n      for k in list(range(-4, 4))))\n  def testDiag(self, shape, dtype, k, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda arg: onp.diag(arg, k)\n    lnp_fun = lambda arg: lnp.diag(arg, k)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_shape={}_offset={}_axis1={}_axis2={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype), offset, axis1, axis2),\n       ""dtype"": dtype, ""shape"": shape, ""offset"": offset, ""axis1"": axis1,\n       ""axis2"": axis2, ""rng_factory"": jtu.rand_default}\n      for dtype in default_dtypes\n      for shape in [shape for shape in all_shapes if len(shape) >= 2]\n      for axis1 in range(-len(shape), len(shape))\n      for axis2 in [a for a in range(-len(shape), len(shape))\n                    if a % len(shape) != axis1 % len(shape)]\n      for offset in list(range(-4, 4))))\n  def testDiagonal(self, shape, dtype, offset, axis1, axis2, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda arg: onp.diagonal(arg, offset, axis1, axis2)\n    lnp_fun = lambda arg: lnp.diagonal(arg, offset, axis1, axis2)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_shape={}_n={}"".format(onp.dtype(dtype).name, n),\n       ""dtype"": dtype, ""n"": n}\n      for dtype in default_dtypes\n      for n in list(range(4))))\n  def testIdentity(self, n, dtype):\n    onp_fun = lambda: onp.identity(n, dtype)\n    lnp_fun = lambda: lnp.identity(n, dtype)\n    args_maker = lambda: []\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_shape={}_dtype_{}_offset={}_axis1={}_axis2={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype),\n          out_dtype, offset, axis1, axis2),\n       ""dtype"": dtype, ""out_dtype"": out_dtype, ""shape"": shape, ""offset"": offset,\n       ""axis1"": axis1, ""axis2"": axis2, ""rng_factory"": jtu.rand_default}\n      for dtype in default_dtypes\n      for out_dtype in [None] + number_dtypes\n      for shape in [shape for shape in all_shapes if len(shape) >= 2]\n      for axis1 in range(-len(shape), len(shape))\n      for axis2 in range(-len(shape), len(shape))\n      if (axis1 % len(shape)) != (axis2 % len(shape))\n      for offset in list(range(-4, 4))))\n  def testTrace(self, shape, dtype, out_dtype, offset, axis1, axis2, rng_factory):\n    rng = rng_factory()\n    def onp_fun(arg):\n      if out_dtype == lnp.bfloat16:\n        return onp.trace(arg, offset, axis1, axis2, onp.float32).astype(lnp.bfloat16)\n      else:\n        return onp.trace(arg, offset, axis1, axis2, out_dtype)\n    lnp_fun = lambda arg: lnp.trace(arg, offset, axis1, axis2, out_dtype)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_axis={}"".format(\n          jtu.format_test_name_suffix("""", [shape] * len(dtypes), dtypes), axis),\n       ""shape"": shape, ""axis"": axis, ""dtypes"": dtypes, ""rng_factory"": rng_factory}\n      for dtypes in [\n        [onp.float32],\n        [onp.float32, onp.float32],\n        [onp.float32, onp.int32, onp.float32],\n        [onp.float32, onp.int64, onp.float32],\n        [onp.float32, onp.int32, onp.float64],\n      ]\n      for shape in [(), (2,), (3, 4), (1, 100)]\n      for axis in range(-len(shape), len(shape) + 1)\n      for rng_factory in [jtu.rand_default]))\n  def testStack(self, shape, axis, dtypes, rng_factory):\n    rng = rng_factory()\n    args_maker = lambda: [[rng(shape, dtype) for dtype in dtypes]]\n    onp_fun = _promote_like_lnp(partial(onp.stack, axis=axis))\n    lnp_fun = partial(lnp.stack, axis=axis)\n    self._CheckAgainstNumpy(lnp_fun, onp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_op={}_{}"".format(\n          op, jtu.format_test_name_suffix("""", [shape] * len(dtypes), dtypes)),\n       ""shape"": shape, ""op"": op, ""dtypes"": dtypes, ""rng_factory"": rng_factory}\n      for op in [""hstack"", ""vstack"", ""dstack""]\n      for dtypes in [\n        [onp.float32],\n        [onp.float32, onp.float32],\n        [onp.float32, onp.int32, onp.float32],\n        [onp.float32, onp.int64, onp.float32],\n        [onp.float32, onp.int32, onp.float64],\n      ]\n      for shape in [(), (2,), (3, 4), (1, 100), (2, 3, 4)]\n      for rng_factory in [jtu.rand_default]))\n  def testHVDStack(self, shape, op, dtypes, rng_factory):\n    rng = rng_factory()\n    args_maker = lambda: [[rng(shape, dtype) for dtype in dtypes]]\n    onp_fun = _promote_like_lnp(getattr(onp, op))\n    lnp_fun = getattr(lnp, op)\n    self._CheckAgainstNumpy(lnp_fun, onp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_inshape={}_outdtype={}"".format(\n          jtu.format_shape_dtype_string(shape, fill_value_dtype),\n          onp.dtype(out_dtype).name if out_dtype else ""None""),\n       ""shape"": shape, ""fill_value_dtype"": fill_value_dtype,\n       ""out_dtype"": out_dtype, ""rng_factory"": jtu.rand_default}\n      for shape in array_shapes + [3, onp.array(7, dtype=onp.int32)]\n      for fill_value_dtype in default_dtypes\n      for out_dtype in [None] + default_dtypes))\n  def testFull(self, shape, fill_value_dtype, out_dtype, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda fill_value: onp.full(shape, fill_value, dtype=out_dtype)\n    lnp_fun = lambda fill_value: lnp.full(shape, fill_value, dtype=out_dtype)\n    args_maker = lambda: [rng((), fill_value_dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(\n    jtu.cases_from_list(\n      {""testcase_name"": (""_op={}_shape={}_dtype={}"").format(op, shape, dtype),\n       ""onp_op"": getattr(onp, op), ""lnp_op"": getattr(lnp, op),\n       ""shape"": shape, ""dtype"": dtype}\n      for op in [""zeros"", ""ones""]\n      for shape in [2, (), (2,), (3, 0), onp.array((4, 5, 6), dtype=onp.int32),\n                    onp.array(4, dtype=onp.int32)]\n      for dtype in all_dtypes))\n  def testZerosOnes(self, onp_op, lnp_op, shape, dtype):\n    rng = jtu.rand_default()\n    def args_maker(): return []\n    onp_op = partial(onp_op, shape, dtype)\n    lnp_op = partial(lnp_op, shape, dtype)\n    self._CheckAgainstNumpy(onp_op, lnp_op, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_op, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_inshape={}_filldtype={}_outdtype={}"".format(\n          jtu.format_shape_dtype_string(shape, in_dtype),\n          onp.dtype(fill_value_dtype).name,\n          onp.dtype(out_dtype).name),\n       ""shape"": shape, ""in_dtype"": in_dtype,\n       ""fill_value_dtype"": fill_value_dtype, ""out_dtype"": out_dtype,\n       ""rng_factory"": jtu.rand_default}\n      for shape in array_shapes\n      for in_dtype in default_dtypes\n      for fill_value_dtype in default_dtypes\n      for out_dtype in default_dtypes))\n  def testFullLike(self, shape, in_dtype, fill_value_dtype, out_dtype, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda x, fill_value: onp.full_like(x, fill_value, dtype=out_dtype)\n    lnp_fun = lambda x, fill_value: lnp.full_like(x, fill_value, dtype=out_dtype)\n    args_maker = lambda: [rng(shape, in_dtype), rng((), fill_value_dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_axis={}_{}sections"".format(\n          jtu.format_shape_dtype_string(shape, dtype), axis, num_sections),\n       ""shape"": shape, ""num_sections"": num_sections, ""axis"": axis,\n       ""dtype"": dtype, ""rng_factory"": jtu.rand_default}\n      for shape, axis, num_sections in [\n          ((3,), 0, 3), ((12,), 0, 3), ((12, 4), 0, 4), ((12, 4), 1, 2),\n          ((2, 3, 4), -1, 2), ((2, 3, 4), -2, 3)]\n      for dtype in default_dtypes))\n  def testSplitStaticInt(self, shape, num_sections, axis, dtype, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda x: onp.split(x, num_sections, axis=axis)\n    lnp_fun = lambda x: lnp.split(x, num_sections, axis=axis)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_axis={}_{}sections"".format(\n          jtu.format_shape_dtype_string(shape, dtype), axis, num_sections),\n       ""shape"": shape, ""num_sections"": num_sections, ""axis"": axis,\n       ""dtype"": dtype, ""rng_factory"": jtu.rand_default}\n      for shape, axis, num_sections in [\n          ((12, 4), 0, 4), ((12, 4), 1, 2),\n          ((2, 3, 4), 2, 2), ((4, 3, 4), 0, 2)]\n      for dtype in default_dtypes))\n  def testHVDSplit(self, shape, num_sections, axis, dtype, rng_factory):\n    rng = rng_factory()\n    def fn(module, axis):\n      if axis == 0:\n        return module.vsplit\n      elif axis == 1:\n        return module.hsplit\n      else:\n        assert axis == 2\n        return module.dsplit\n\n    onp_fun = lambda x: fn(onp, axis)(x, num_sections)\n    lnp_fun = lambda x: fn(lnp, axis)(x, num_sections)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_inshape={}_outshape={}_order={}"".format(\n          jtu.format_shape_dtype_string(arg_shape, dtype),\n          jtu.format_shape_dtype_string(out_shape, dtype),\n          order),\n       ""arg_shape"": arg_shape, ""out_shape"": out_shape, ""dtype"": dtype,\n       ""order"": order, ""rng_factory"": jtu.rand_default}\n      for dtype in default_dtypes\n      for order in [""C"", ""F""]\n      for arg_shape, out_shape in [\n          (jtu.NUMPY_SCALAR_SHAPE, (1, 1, 1)),\n          ((), (1, 1, 1)),\n          ((7, 0), (0, 42, 101)),\n          ((3, 4), 12),\n          ((3, 4), (12,)),\n          ((3, 4), -1),\n          ((2, 1, 4), (-1,)),\n          ((2, 2, 4), (2, 8))\n      ]))\n  def testReshape(self, arg_shape, out_shape, dtype, order, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda x: onp.reshape(x, out_shape, order=order)\n    lnp_fun = lambda x: lnp.reshape(x, out_shape, order=order)\n    args_maker = lambda: [rng(arg_shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_inshape={}_outshape={}"".format(\n          jtu.format_shape_dtype_string(arg_shape, dtype),\n          jtu.format_shape_dtype_string(out_shape, dtype)),\n       ""arg_shape"": arg_shape, ""out_shape"": out_shape, ""dtype"": dtype,\n       ""rng_factory"": jtu.rand_default}\n      for dtype in default_dtypes\n      for arg_shape, out_shape in [\n          ((7, 0), (0, 42, 101)),\n          ((2, 1, 4), (-1,)),\n          ((2, 2, 4), (2, 8))\n      ]))\n  def testReshapeMethod(self, arg_shape, out_shape, dtype, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda x: onp.reshape(x, out_shape)\n    lnp_fun = lambda x: x.reshape(*out_shape)\n    args_maker = lambda: [rng(arg_shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_inshape={}_expanddim={}"".format(\n          jtu.format_shape_dtype_string(arg_shape, dtype), dim),\n       ""arg_shape"": arg_shape, ""dtype"": dtype, ""dim"": dim,\n       ""rng_factory"": jtu.rand_default}\n      for arg_shape in [(), (3,), (3, 4)]\n      for dtype in default_dtypes\n      for dim in range(-len(arg_shape)+1, len(arg_shape))))\n  def testExpandDimsStaticDim(self, arg_shape, dtype, dim, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda x: onp.expand_dims(x, dim)\n    lnp_fun = lambda x: lnp.expand_dims(x, dim)\n    args_maker = lambda: [rng(arg_shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_inshape={}_axes=({},{})"".format(\n          jtu.format_shape_dtype_string(arg_shape, dtype), ax1, ax2),\n       ""arg_shape"": arg_shape, ""dtype"": dtype, ""ax1"": ax1, ""ax2"": ax2,\n       ""rng_factory"": jtu.rand_default}\n      for arg_shape, ax1, ax2 in [\n          ((3, 4), 0, 1), ((3, 4), 1, 0), ((3, 4, 5), 1, 2),\n          ((3, 4, 5), -1, -2), ((3, 4, 5), 0, 1)]\n      for dtype in default_dtypes))\n  def testSwapAxesStaticAxes(self, arg_shape, dtype, ax1, ax2, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda x: onp.swapaxes(x, ax1, ax2)\n    lnp_fun = lambda x: lnp.swapaxes(x, ax1, ax2)\n    args_maker = lambda: [rng(arg_shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_shape={}_axes=({},{})"".format(\n          jtu.format_shape_dtype_string(arg_shape, dtype), source, destination),\n       ""arg_shape"": arg_shape, ""dtype"": dtype, ""source"": source,\n       ""destination"": destination, ""rng_factory"": jtu.rand_default}\n      for arg_shape, source, destination in [\n          (tuple(range(6)), (0, 2), (3, 5)),\n          (tuple(range(6)), (0, 2), (-1, -3)),\n          (tuple(range(6)), (-6, -4),(3, 5)),\n          (tuple(range(6)), (-6, -4), (-1, -3)),\n          (tuple(range(6)), 0, 4),\n          (tuple(range(6)), -6, -2),\n          (tuple(range(6)), tuple(range(6)), tuple(range(6))),\n          (tuple(range(6)), tuple(range(6)), tuple(reversed(range(6)))),\n          (tuple(range(6)), (), ()),\n      ] for dtype in default_dtypes))\n  @new_test\n  def testMoveaxisStaticAxes(self, arg_shape, dtype, source, destination,\n                             rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda x: onp.moveaxis(x, source, destination)\n    lnp_fun = lambda x: lnp.moveaxis(x, source, destination)\n    args_maker = lambda: [rng(arg_shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_inshape={}_axis={}"".format(\n          jtu.format_shape_dtype_string(arg_shape, dtype), ax),\n       ""arg_shape"": arg_shape, ""dtype"": dtype, ""ax"": ax,\n       ""rng_factory"": jtu.rand_default}\n      for arg_shape, ax in [\n          ((3, 1), None),\n          ((3, 1), 1),\n          ((1, 3, 1), (0, 2)),\n          ((1, 4, 1), (0,))]\n      for dtype in default_dtypes))\n  def testSqueeze(self, arg_shape, dtype, ax, rng_factory):\n    rng = rng_factory()\n    onp_fun = lambda x: onp.squeeze(x, ax)\n    lnp_fun = lambda x: lnp.squeeze(x, ax)\n    args_maker = lambda: [rng(arg_shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_shape={}_axis={}_weights={}_returned={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype),\n          axis,\n          (None if weights_shape is None else jtu.format_shape_dtype_string(weights_shape, dtype)),\n          returned),\n       ""rng_factory"": jtu.rand_default, ""shape"": shape, ""dtype"": dtype, ""axis"": axis,\n       ""weights_shape"": weights_shape, ""returned"": returned}\n      for shape, dtype in _shape_and_dtypes(nonempty_shapes, number_dtypes)\n      for axis in set(range(-len(shape), len(shape))) | set([None])\n      # `weights_shape` is either `None`, same as the averaged axis, or same as\n      # that of the input\n      for weights_shape in ([None, shape] if axis is None or len(shape) == 1\n                            else [None, (shape[axis],), shape])\n      for returned in [False, True]))\n  def testAverage(self, shape, dtype, axis, weights_shape, returned, rng_factory):\n    rng = rng_factory()\n    if weights_shape is None:\n      onp_fun = lambda x: onp.average(x, axis, returned=returned)\n      lnp_fun = lambda x: lnp.average(x, axis, returned=returned)\n      args_maker = lambda: [rng(shape, dtype)]\n    else:\n      onp_fun = lambda x, weights: onp.average(x, axis, weights, returned)\n      lnp_fun = lambda x, weights: lnp.average(x, axis, weights, returned)\n      args_maker = lambda: [rng(shape, dtype), rng(weights_shape, dtype)]\n    onp_fun = _promote_like_lnp(onp_fun, inexact=True)\n    tol = {\n        # TODO(b/154768983): lnp.bfloat16: 1e-1,\n        onp.float16: 1e-1, onp.float32: 1e-3, onp.float64: 2e-7,\n        onp.complex64: 1e-3, onp.complex128: 1e-10,\n    }\n    check_dtypes = shape is not jtu.PYTHON_SCALAR_SHAPE\n    try:\n      self._CheckAgainstNumpy(\n          onp_fun, lnp_fun, args_maker, check_dtypes=check_dtypes, tol=tol)\n    except ZeroDivisionError:\n      self.skipTest(""don\'t support checking for ZeroDivisionError"")\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=check_dtypes,\n                          rtol=tol, atol=tol, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_arg{}_ndmin={}"".format(i, ndmin),\n       ""arg"": arg, ""ndmin"": ndmin, ""dtype"": dtype}\n      for i, (arg, dtype) in enumerate([\n          ([True, False, True], lnp.bool_),\n          (3., lnp.float_),\n          ([1, 2, 3], lnp.int_),\n          ([1., 2., 3.], lnp.float_),\n          ([[1, 2], [3, 4], [5, 6]], lnp.int_),\n          ([[1, 2.], [3, 4], [5, 6]], lnp.float_),\n          ([[1., 2j], [3., 4.], [5., 6.]], lnp.complex_),\n          ([[3, onp.array(2, dtype=lnp.float_), 1],\n           onp.arange(3., dtype=lnp.float_)], lnp.float_),\n      ])\n      for ndmin in [None, onp.ndim(arg), onp.ndim(arg) + 1, onp.ndim(arg) + 2]))\n  def testArray(self, arg, ndmin, dtype):\n    args_maker = lambda: [arg]\n    dtype = lnp.canonicalize_dtype(dtype)\n    if ndmin is not None:\n      onp_fun = partial(onp.array, ndmin=ndmin, dtype=dtype)\n      lnp_fun = partial(lnp.array, ndmin=ndmin)\n    else:\n      onp_fun = partial(onp.array, dtype=dtype)\n      lnp_fun = lnp.array\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True,\n                          check_incomplete_shape=True, static_argnums=[0])\n\n  def testIssue121(self):\n    assert not onp.isscalar(lnp.array(3))\n\n  @jtu.disable\n  def testArrayMethod(self):\n    class arraylike(object):\n      dtype = onp.float32\n      def __array__(self, dtype=None):\n        return 3.\n    a = arraylike()\n    ans = lnp.array(a)\n    assert ans == 3.\n\n  @jtu.skip_on_devices(""tpu"")  # TODO(b/32368900): TPUs don\'t support uint8 yet.\n  @jtu.disable\n  def testMemoryView(self):\n    ans = lnp.array(bytearray(b\'\\x2a\'))\n    self.assertAllClose(\n        ans,\n        onp.array([0x2a], dtype=onp.uint8),\n        check_dtypes=True)\n\n  def testAllClose(self):\n    rng = onp.random.RandomState(0)\n    x = rng.randn(2, 2)\n    y = rng.randn(2)\n\n    def same(list1, list2):\n      allclose = functools.partial(lnp.allclose, atol=1e-3, rtol=1e-3)\n      elements_close = list(map(allclose, list1, list2))\n      return lnp.all(lnp.array(elements_close))\n\n    csame = npe.jit(same)\n\n    a1 = same((x, y), (x, y))\n    a2 = csame((x, y), (x, y))\n    a3 = csame((x, y), (x, 2 * y))\n\n    self.assertTrue(a1)\n    self.assertTrue(a2)\n    self.assertFalse(a3)\n\n  @jtu.skip_on_devices(""tpu"")  # TODO(mattjj): investigate this failure\n  @jtu.disable\n  def testOnesBroadcastingConstantHandler(self):\n    # TODO(mattjj): update this test for jax3\n    self.skipTest(""test needs jax3 update"")\n\n    def fun(x):\n      ones = lnp.ones((3, 4))\n      assert isinstance(ones, onp.ndarray) and ones.strides == (0, 0)\n\n      # To check that the constant handler generates a Broadcast for stride-zero\n      # arrays, we monkey-patch the client instance.\n      # TODO(mattjj): once we have better HLO dumping and inspecting facilities,\n      # we can check the HLO more directly.\n      c = x._node.c\n      Broadcast = c.Broadcast  # pylint: disable=invalid-name\n      was_called = []\n      c.Broadcast = lambda *args: was_called.append(True) or Broadcast(*args)\n      out = x + ones  # the ndarray constant handler should call Broadcast here\n      assert was_called, ""Broadcast was not called.""\n\n      return out\n\n    fun = api.jit(fun)\n    out_val = fun(lnp.ones(4))\n    self.assertAllClose(out_val, onp.full((3, 4), 2.), check_dtypes=False)\n\n  def testZeroStridesConstantHandler(self):\n    raw_const = onp.random.RandomState(0).randn(1, 2, 1, 1, 5, 1)\n    const = onp.broadcast_to(raw_const, (3, 2, 3, 4, 5, 6))\n\n    def fun(x):\n      return x * const\n\n    fun = npe.jit(fun)\n    out_val = fun(3.)\n    self.assertAllClose(out_val, 3. * const, check_dtypes=False)\n\n  def testIsInstanceNdarrayDuringTracing(self):\n    arr = onp.ones(3)\n\n    @npe.jit\n    def f(x):\n      self.assertIsInstance(x, lnp.ndarray)\n      return lnp.sum(x)\n\n    f(arr)\n\n  @jtu.disable\n  def testNonArrayErrorMessage(self):\n    x = [1., 2.]\n    y = onp.array([3., 4.])\n\n    def g(x, y):\n      return lnp.add(x, y)\n\n    def f(x, y):\n      return lnp.dot(x, y)\n\n    self.assertRaises(TypeError, lambda: g(x, y))\n    self.assertRaises(TypeError, lambda: f(x, y))\n    self.assertRaises(TypeError, lambda: api.jit(g)(x, y))\n    self.assertRaises(TypeError, lambda: api.jit(f)(x, y))\n\n  @jtu.disable\n  def testAbstractionErrorMessage(self):\n\n    @api.jit\n    def f(x, n):\n      for _ in range(n):\n        x = x * x\n      return x\n\n    self.assertRaises(TypeError, lambda: f(3., 3))\n\n    @api.jit\n    def g(x):\n      if x > 0.:\n        return x * 2\n      else:\n        return x + 2\n\n    self.assertRaises(TypeError, lambda: g(3.))\n\n  @jtu.disable\n  def testTracingPrimitiveWithNoTranslationErrorMessage(self):\n    # TODO(mattjj): update this for jax3\n    self.skipTest(""test needs jax3 update"")\n    foo = lnp._not_implemented(lambda x: x)\n\n    # No error if there\'s no tracing.\n    foo(onp.arange(3))\n\n    cfoo = api.jit(foo)\n    self.assertRaises(NotImplementedError, lambda: cfoo(onp.arange(3)))\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_axis={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype), axis),\n       ""rng_factory"": rng_factory, ""shape"": shape, ""dtype"": dtype, ""axis"": axis}\n      for shape in [(3,), (2, 3)]\n      for dtype in default_dtypes\n      for axis in list(range(-len(shape), len(shape))) + [None]  # Test negative axes\n      for rng_factory in [jtu.rand_default]))\n  def testFlip(self, shape, dtype, axis, rng_factory):\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    lnp_op = lambda x: lnp.flip(x, axis)\n    onp_op = lambda x: onp.flip(x, axis)\n    self._CheckAgainstNumpy(onp_op, lnp_op, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_op, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}"".format(\n          jtu.format_shape_dtype_string(shape, dtype)),\n       ""rng_factory"": rng_factory, ""shape"": shape, ""dtype"": dtype}\n      for shape in [(3,), (2, 3), (3, 2, 4)]\n      for dtype in default_dtypes\n      for rng_factory in [jtu.rand_default]))\n  def testFlipud(self, shape, dtype, rng_factory):\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    lnp_op = lambda x: lnp.flipud(x)\n    onp_op = lambda x: onp.flipud(x)\n    self._CheckAgainstNumpy(onp_op, lnp_op, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_op, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}"".format(\n          jtu.format_shape_dtype_string(shape, dtype)),\n       ""rng_factory"": rng_factory, ""shape"": shape, ""dtype"": dtype}\n      for shape in [(3, 2), (2, 3), (3, 2, 4)]\n      for dtype in default_dtypes\n      for rng_factory in [jtu.rand_default]))\n  def testFliplr(self, shape, dtype, rng_factory):\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    lnp_op = lambda x: lnp.fliplr(x)\n    onp_op = lambda x: onp.fliplr(x)\n    self._CheckAgainstNumpy(onp_op, lnp_op, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_op, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_k={}_axes={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype), k, axes),\n       ""rng_factory"": rng_factory, ""shape"": shape, ""dtype"": dtype, ""k"": k, ""axes"": axes}\n      for shape, axes in [\n          [(2, 3), (0, 1)],\n          [(2, 3), (1, 0)],\n          [(4, 3, 2), (0, 2)],\n          [(4, 3, 2), (2, 1)],\n      ]\n      for k in range(-3, 4)\n      for dtype in default_dtypes\n      for rng_factory in [jtu.rand_default]))\n  def testRot90(self, shape, dtype, k, axes, rng_factory):\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    lnp_op = lambda x: lnp.rot90(x, k, axes)\n    onp_op = lambda x: onp.rot90(x, k, axes)\n    self._CheckAgainstNumpy(onp_op, lnp_op, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_op, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_k={}_axes={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype), k, axes),\n       ""rng_factory"": rng_factory, ""shape"": shape, ""dtype"": dtype, ""k"": k,\n       ""axes"": axes}\n      for shape, axes in [\n          [(2, 3), (-2, -1)],\n          [(2, 3), (-2, 1)],\n          [(4, 3, 2), (-1, -2)],\n          [(4, 3, 2), (2, -2)],\n      ]\n      for k in range(-3, 4)\n      for dtype in default_dtypes\n      for rng_factory in [jtu.rand_default]))\n  @new_test\n  # These tests are only added as a separate test from testRot90 since we would\n  # like to measure coverage directly against the existing baseline. Once we\n  # stop measuring that, we can combine this test with the above.\n  def testRot90Additional(self, shape, dtype, k, axes, rng_factory):\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    lnp_op = lambda x: lnp.rot90(x, k, axes)\n    onp_op = lambda x: onp.rot90(x, k, axes)\n    self._CheckAgainstNumpy(onp_op, lnp_op, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_op, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  # TODO(mattjj): test infix operator overrides\n\n  def testRavel(self):\n    rng = onp.random.RandomState(0)\n    args_maker = lambda: [rng.randn(3, 4).astype(""float32"")]\n    self._CompileAndCheck(lambda x: x.ravel(), args_maker, check_dtypes=True,\n                          check_incomplete_shape=True)\n\n  def testAstype(self):\n    rng = onp.random.RandomState(0)\n    args_maker = lambda: [rng.randn(3, 4).astype(""float32"")]\n    op = lambda x: x.astype(lnp.int32)\n    self._CheckAgainstNumpy(op, op, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        op, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  # TODO(mattjj): test other ndarray-like method overrides\n\n  def testOnpMean(self):\n    # from https://github.com/google/jax/issues/125\n    x = lnp.add(lnp.eye(3, dtype=lnp.float_), 0.)\n    ans = onp.mean(x)\n    self.assertAllClose(ans, onp.array(1./3), check_dtypes=False)\n\n  @jtu.disable\n  def testArangeOnFloats(self):\n    # from https://github.com/google/jax/issues/145\n    expected = onp.arange(0.0, 1.0, 0.1, dtype=lnp.float_)\n    ans = lnp.arange(0.0, 1.0, 0.1)\n    self.assertAllClose(expected, ans, check_dtypes=True)\n\n  def testSortManually(self):\n\n    def _test(*args, **kwargs):\n\n      raw_ans = lnp.sort(*args, **kwargs)\n      fn_ans = npe.jit(lnp.sort, static_argnums=(1,))(*args, **kwargs)\n      expected = onp.sort(*args, **kwargs)\n\n      self.assertAllClose(expected, raw_ans, check_dtypes=True)\n      self.assertAllClose(expected, fn_ans, check_dtypes=True)\n\n    # manual tests for sort are nice because we don\'t have to worry about ties.\n    # lax.sort is tested combinatorially.\n    _test(onp.array([16, 15, 23, 42, 8, 4]))\n    _test(onp.array([[1, 4], [3, 1]]), None)\n    _test(onp.array([[1, 4], [3, 1]]))\n    _test(onp.array([[1, 4], [3, 1]]), 0)\n\n  def testArgsortManually(self):\n\n    def _test(*args, **kwargs):\n\n      raw_ans = lnp.argsort(*args, **kwargs)\n      fn_ans = npe.jit(lnp.argsort, static_argnums=(1,))(*args, **kwargs)\n      expected = onp.argsort(*args, **kwargs)\n\n      self.assertAllClose(expected, raw_ans, check_dtypes=True)\n      self.assertAllClose(expected, fn_ans, check_dtypes=True)\n\n    _test(onp.array([16, 15, 23, 42, 8, 4]))\n    _test(onp.array([[16, 15, 23], [42, 8, 4]]), 0)\n    _test(onp.array([[16, 15, 23], [42, 8, 4]]), 1)\n    _test(onp.array([[16, 15, 23], [42, 8, 4]]), None)\n    _test(onp.array([[16, 15, 23], [42, 8, 4]]))\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_shifts={}_axis={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype),\n          shifts, axis),\n       ""rng_factory"": rng_factory, ""shape"": shape, ""dtype"": dtype, ""shifts"": shifts,\n       ""axis"": axis}\n      for dtype in all_dtypes\n      for shape in [(3, 4), (3, 4, 5), (7, 4, 0)]\n      for shifts, axis in [\n        (3, None),\n        (1, 1),\n        ((3,), (0,)),\n        ((-2,), (-2,)),\n        ((1, 2), (0, -1))\n      ]\n      for rng_factory in [jtu.rand_default]))\n  def testRoll(self, shape, dtype, shifts, axis, rng_factory):\n    rng = rng_factory()\n    args_maker = lambda: [rng(shape, dtype), onp.array(shifts)]\n    lnp_op = partial(lnp.roll, axis=axis)\n    onp_op = partial(onp.roll, axis=axis)\n    self._CheckAgainstNumpy(lnp_op, onp_op, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_op, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_index={}_axis={}_mode={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype),\n          jtu.format_shape_dtype_string(index_shape, index_dtype),\n          axis, mode),\n       ""rng_factory"": rng_factory, ""rng_indices_factory"": rng_indices_factory,\n       ""shape"": shape, ""index_shape"": index_shape, ""dtype"": dtype,\n       ""index_dtype"": index_dtype, ""axis"": axis, ""mode"": mode}\n      for shape in [(3,), (3, 4), (3, 4, 5)]\n      for index_shape in scalar_shapes + [(3,), (2, 1, 3)]\n      for axis in itertools.chain(range(-len(shape), len(shape)), [None])\n      for dtype in all_dtypes\n      for index_dtype in int_dtypes\n      for mode in [\'wrap\', \'clip\']\n      for rng_factory in [jtu.rand_default]\n      for rng_indices_factory in [partial(jtu.rand_int, -5, 5)]))\n  def testTake(self, shape, dtype, index_shape, index_dtype, axis, mode,\n               rng_factory, rng_indices_factory):\n    def args_maker():\n      x = rng(shape, dtype)\n      i = rng_indices(index_shape, index_dtype)\n      return x, i\n\n    rng = rng_factory()\n    rng_indices = rng_indices_factory()\n    lnp_op = lambda x, i: lnp.take(x, i, axis=axis, mode=mode)\n    onp_op = lambda x, i: onp.take(x, i, axis=axis, mode=mode)\n    self._CheckAgainstNumpy(lnp_op, onp_op, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_op, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_{}_ishape={}_axis={}"".format(\n          jtu.format_shape_dtype_string(x_shape, dtype), i_shape, axis),\n       ""rng_factory"": rng_factory, ""x_shape"": x_shape, ""i_shape"": i_shape, ""dtype"": dtype,\n       ""axis"": axis}\n      for x_shape, i_shape in filter(\n        _shapes_are_equal_length,\n        filter(_shapes_are_broadcast_compatible,\n               CombosWithReplacement(nonempty_nonscalar_array_shapes, 2)))\n      for axis in itertools.chain(range(len(x_shape)), [-1], [None])\n      for dtype in default_dtypes\n      for rng_factory in [jtu.rand_default]))\n  @jtu.disable\n  def testTakeAlongAxis(self, x_shape, i_shape, dtype, axis, rng_factory):\n    rng = rng_factory()\n    i_shape = onp.array(i_shape)\n    if axis is None:\n      i_shape = [onp.prod(i_shape, dtype=onp.int64)]\n    else:\n      # Test the case where the size of the axis doesn\'t necessarily broadcast.\n      i_shape[axis] *= 3\n      i_shape = list(i_shape)\n    def args_maker():\n      x = rng(x_shape, dtype)\n      n = onp.prod(x_shape, dtype=onp.int32) if axis is None else x_shape[axis]\n      i = rng(i_shape, onp.int32) % (2 * n - 1) - (n - 1)\n      return x, i\n\n    lnp_op = lambda x, i: lnp.take_along_axis(x, i, axis=axis)\n\n    if hasattr(onp, ""take_along_axis""):\n      onp_op = lambda x, i: onp.take_along_axis(x, i, axis=axis)\n      self._CheckAgainstNumpy(lnp_op, onp_op, args_maker, check_dtypes=True)\n    self._CompileAndCheck(lnp_op, args_maker, check_dtypes=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_shape={}_n={}_increasing={}"".format(\n          jtu.format_shape_dtype_string([shape], dtype),\n          n, increasing),\n       ""dtype"": dtype, ""shape"": shape, ""n"": n, ""increasing"": increasing,\n       ""rng_factory"": jtu.rand_default}\n      for dtype in inexact_dtypes\n      for shape in [0, 5]\n      for n in [2, 4]\n      for increasing in [False, True]))\n  def testVander(self, shape, dtype, n, increasing, rng_factory):\n    rng = rng_factory()\n    def onp_fun(arg):\n      arg = arg.astype(onp.float32) if dtype == lnp.bfloat16 else arg\n      return onp.vander(arg, N=n, increasing=increasing)\n    lnp_fun = lambda arg: lnp.vander(arg, N=n, increasing=increasing)\n    args_maker = lambda: [rng([shape], dtype)]\n    # np.vander seems to return float64 for all floating types. We could obey\n    # those semantics, but they seem like a bug.\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=False,\n                            tol={onp.float32: 1e-3})\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=False, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n        {""testcase_name"": jtu.format_test_name_suffix(""nan_to_num"", [shape],\n                                                      [dtype]),\n         ""rng_factory"": jtu.rand_some_inf_and_nan, ""shape"": shape,\n         ""dtype"": dtype}\n        for shape in all_shapes\n        for dtype in inexact_dtypes))\n  @jtu.disable\n  def testNanToNum(self, rng_factory, shape, dtype):\n    rng = rng_factory()\n    dtype = onp.dtype(dtypes.canonicalize_dtype(dtype)).type\n    def onp_fun(x):\n      if dtype == lnp.bfloat16:\n        x = onp.where(onp.isnan(x), dtype(0), x)\n        x = onp.where(onp.isposinf(x), lnp.finfo(dtype).max, x)\n        x = onp.where(onp.isneginf(x), lnp.finfo(dtype).min, x)\n        return x\n      else:\n        return onp.nan_to_num(x).astype(dtype)\n\n    args_maker = lambda: [rng(shape, dtype)]\n    check_dtypes = shape is not jtu.PYTHON_SCALAR_SHAPE\n    self._CheckAgainstNumpy(onp_fun, lnp.nan_to_num, args_maker,\n                            check_dtypes=check_dtypes)\n    self._CompileAndCheck(lnp.nan_to_num, args_maker,\n                          check_dtypes=check_dtypes)\n\n  @named_parameters(jtu.cases_from_list(\n        {""testcase_name"": jtu.format_test_name_suffix(""ix_"", shapes, dtypes),\n         ""rng_factory"": jtu.rand_default, ""shapes"": shapes, ""dtypes"": dtypes}\n        for shapes, dtypes in (\n          ((), ()),\n          (((7,),), (onp.int32,)),\n          (((3,), (4,)), (onp.int32, onp.int32)),\n          (((3,), (1,), (4,)), (onp.int32, onp.int32, onp.int32)),\n        )))\n  def testIx_(self, rng_factory, shapes, dtypes):\n    rng = rng_factory()\n    args_maker = lambda: [rng(shape, dtype)\n                          for shape, dtype in zip(shapes, dtypes)]\n    self._CheckAgainstNumpy(onp.ix_, lnp.ix_, args_maker,\n                            check_dtypes=True)\n    self._CompileAndCheck(\n        lnp.ix_, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(jtu.cases_from_list(\n        {""testcase_name"":\n           ""_op={}_a_shape={}_q_shape={}_axis={}_keepdims={}"".format(\n             op,\n             jtu.format_shape_dtype_string(a_shape, a_dtype),\n             jtu.format_shape_dtype_string(q_shape, q_dtype),\n             axis, keepdims),\n         ""a_rng"": jtu.rand_default(), ""q_rng"": q_rng, ""op"": op,\n         ""a_shape"": a_shape, ""a_dtype"": a_dtype,\n         ""q_shape"": q_shape, ""q_dtype"": q_dtype, ""axis"": axis,\n         ""keepdims"": keepdims}\n        for (op, q_rng) in (\n          (""percentile"", jtu.rand_uniform(low=0., high=100.)),\n          (""quantile"", jtu.rand_uniform(low=0., high=1.)),\n          (""median"", jtu.rand_uniform(low=0., high=1.)),\n        )\n        for a_dtype in float_dtypes\n        for a_shape, axis in (\n          ((7,), None),\n          ((47, 7), 0),\n          ((4, 101), 1),\n        )\n        for q_dtype in [onp.float32]\n        for q_shape in scalar_shapes + [(4,)]\n        for keepdims in [False, True]))\n  @jtu.disable\n  def testQuantile(self, op, a_rng, q_rng, a_shape, a_dtype, q_shape, q_dtype,\n                   axis, keepdims):\n    if op == ""quantile"" and numpy_version < (1, 15):\n      raise SkipTest(""Numpy < 1.15 does not have np.quantile"")\n    if op == ""median"":\n      args_maker = lambda: [a_rng(a_shape, a_dtype)]\n    else:\n      args_maker = lambda: [a_rng(a_shape, a_dtype), q_rng(q_shape, q_dtype)]\n\n    def onp_fun(*args):\n      args = [x if lnp.result_type(x) != lnp.bfloat16 else\n              onp.asarray(x, onp.float32) for x in args]\n      return getattr(onp, op)(*args, axis=axis, keepdims=keepdims)\n    lnp_fun = partial(getattr(lnp, op), axis=axis, keepdims=keepdims)\n    # TODO(phawkins): we currently set dtype=False because we aren\'t as\n    # aggressive about promoting to float64. It\'s not clear we want to mimic\n    # Numpy here.\n    tol_spec = {onp.float32: 2e-4, onp.float64: 5e-6}\n    tol = max(jtu.tolerance(a_dtype, tol_spec),\n              jtu.tolerance(q_dtype, tol_spec))\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=False,\n                            tol=tol)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True, rtol=tol)\n\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_shape={}"".format(\n          jtu.format_shape_dtype_string(shape, dtype)),\n       ""shape"": shape, ""dtype"": dtype}\n      for shape in all_shapes for dtype in all_dtypes))\n  def testWhereOneArgument(self, shape, dtype):\n    rng = jtu.rand_some_zero()\n    onp_fun = lambda x: onp.where(x)\n    lnp_fun = lambda x: lnp.where(x)\n    args_maker = lambda: [rng(shape, dtype)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=False)\n    self._CompileAndCheck(\n        lnp.where,\n        args_maker,\n        check_dtypes=True,\n        check_eval_on_shapes=False,\n        check_incomplete_shape=True,\n        check_unknown_rank=False)\n\n\n  @named_parameters(jtu.cases_from_list(\n    {""testcase_name"": ""_{}"".format(""_"".join(\n        jtu.format_shape_dtype_string(shape, dtype)\n        for shape, dtype in zip(shapes, dtypes))),\n     ""rng_factory"": jtu.rand_default, ""shapes"": shapes, ""dtypes"": dtypes}\n    for shapes in filter(_shapes_are_broadcast_compatible,\n                         CombosWithReplacement(all_shapes, 3))\n    for dtypes in CombosWithReplacement(all_dtypes, 3)))\n  def testWhereThreeArgument(self, rng_factory, shapes, dtypes):\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng_factory(), shapes, dtypes)\n    def onp_fun(cond, x, y):\n      return _promote_like_lnp(partial(onp.where, cond))(x, y)\n    self._CheckAgainstNumpy(onp_fun, lnp.where, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp.where, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  def testWhereScalarPromotion(self):\n    x = lnp.where(lnp.array([True, False]), 3,\n                  lnp.ones((2,), dtype=lnp.float32))\n    self.assertEqual(x.dtype, onp.dtype(onp.float32))\n\n  @named_parameters(jtu.cases_from_list(\n        {""testcase_name"": jtu.format_test_name_suffix("""", shapes,\n                                                      (onp.bool_,) * n + dtypes),\n         ""rng_factory"": jtu.rand_default, ""shapes"": shapes, ""dtypes"": dtypes}\n        for n in range(0, 3)\n        for shapes in filter(\n          _shapes_are_broadcast_compatible,\n          CombosWithReplacement(all_shapes, 2 * n + 1))\n        for dtypes in CombosWithReplacement(all_dtypes, n + 1)))\n  def testSelect(self, rng_factory, shapes, dtypes):\n    rng = rng_factory()\n    n = len(dtypes) - 1\n    def args_maker():\n      condlist = [rng(shape, onp.bool_) for shape in shapes[:n]]\n      choicelist = [rng(shape, dtype)\n                    for shape, dtype in zip(shapes[n:-1], dtypes[:n])]\n      default = rng(shapes[-1], dtypes[-1])\n      return condlist, choicelist, default\n    # TODO(phawkins): float32/float64 type mismatches\n    def onp_fun(condlist, choicelist, default):\n      choicelist = [x if lnp.bfloat16 != lnp.result_type(x)\n                    else x.astype(onp.float32) for x in choicelist]\n      dtype = lnp.result_type(default, *choicelist)\n      return onp.select(condlist,\n                        [onp.asarray(x, dtype=dtype) for x in choicelist],\n                        onp.asarray(default, dtype=dtype))\n    self._CheckAgainstNumpy(onp_fun, lnp.select, args_maker,\n                            check_dtypes=False)\n    self._CompileAndCheck(lnp.select, args_maker, check_dtypes=True,\n                          check_incomplete_shape=True,\n                          rtol={onp.float64: 1e-7, onp.complex128: 1e-7})\n\n\n  @jtu.disable\n  def testIssue330(self):\n    x = lnp.full((1, 1), lnp.array([1])[0])  # doesn\'t crash\n    self.assertEqual(x[0, 0], 1)\n\n  @jtu.disable\n  def testScalarDtypePromotion(self):\n    orig_numpy_result = (1 + onp.eye(1, dtype=onp.float32)).dtype\n    jax_numpy_result = (1 + lnp.eye(1, dtype=lnp.float32)).dtype\n    self.assertEqual(orig_numpy_result, jax_numpy_result)\n\n  @jtu.disable\n  def testSymmetrizeDtypePromotion(self):\n    x = onp.eye(3, dtype=onp.float32)\n    orig_numpy_result = ((x + x.T) / 2).dtype\n\n    x = lnp.eye(3, dtype=lnp.float32)\n    jax_numpy_result = ((x + x.T) / 2).dtype\n    self.assertEqual(orig_numpy_result, jax_numpy_result)\n\n  @jtu.disable\n  def testIssue347(self):\n    # https://github.com/google/jax/issues/347\n    def test_fail(x):\n      x = lnp.sqrt(lnp.sum(x ** 2, axis=1))\n      ones = lnp.ones_like(x)\n      x = lnp.where(x > 0.5, x, ones)\n      return lnp.sum(x)\n\n    x = lnp.array([[1, 2], [3, 4], [0, 0]], dtype=lnp.float64)\n    result = api.grad(test_fail)(x)\n    assert not onp.any(onp.isnan(result))\n\n  def testIssue453(self):\n    # https://github.com/google/jax/issues/453\n    a = onp.arange(6) + 1\n    ans = lnp.reshape(a, (3, 2), order=\'F\')\n    expected = onp.reshape(a, (3, 2), order=\'F\')\n    self.assertAllClose(ans, expected, check_dtypes=True)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"": ""_op={}_dtype={}"".format(op, pytype.__name__),\n       ""pytype"": pytype, ""dtype"": dtype, ""op"": op}\n      for pytype, dtype in [(int, lnp.int_), (float, lnp.float_),\n                            (bool, lnp.bool_), (complex, lnp.complex_)]\n      for op in [""atleast_1d"", ""atleast_2d"", ""atleast_3d""]))\n  def testAtLeastNdLiterals(self, pytype, dtype, op):\n    # Fixes: https://github.com/google/jax/issues/634\n    onp_fun = lambda arg: getattr(onp, op)(arg).astype(dtype)\n    lnp_fun = lambda arg: getattr(lnp, op)(arg)\n    args_maker = lambda: [pytype(2)]\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n\n  def testLongLong(self):\n    self.assertAllClose(\n        onp.int64(7), npe.jit(lambda x: x)(onp.longlong(7)), check_dtypes=True)\n\n  def testArange(self):\n    # test cases inspired by dask tests at\n    # https://github.com/dask/dask/blob/master/dask/array/tests/test_creation.py#L92\n    self.assertAllClose(lnp.arange(77),\n                        onp.arange(77, dtype=lnp.int_), check_dtypes=True)\n    self.assertAllClose(lnp.arange(2, 13),\n                        onp.arange(2, 13, dtype=lnp.int_), check_dtypes=True)\n    self.assertAllClose(lnp.arange(4, 21, 9),\n                        onp.arange(4, 21, 9, dtype=lnp.int_), check_dtypes=True)\n    self.assertAllClose(lnp.arange(53, 5, -3),\n                        onp.arange(53, 5, -3, dtype=lnp.int_),\n                        check_dtypes=True)\n    # TODO(mattjj): make these tests work when enable_x64=True\n    self.assertAllClose(\n        lnp.arange(77, dtype=float),\n        onp.arange(77, dtype=float),\n        check_dtypes=True)\n    self.assertAllClose(\n        lnp.arange(2, 13, dtype=int),\n        onp.arange(2, 13, dtype=int),\n        check_dtypes=True)\n    self.assertAllClose(lnp.arange(0, 1, -0.5),\n                        onp.arange(0, 1, -0.5, dtype=lnp.float_),\n                        check_dtypes=True)\n\n    self.assertRaises(TypeError, lambda: lnp.arange())\n\n    # # The following have been disabled since they test JAX specific behavior\n    # # test that lnp.arange(N) doesn\'t instantiate an ndarray\n    # self.assertFalse(type(lnp.arange(77)) == type(onp.arange(77)))\n    # self.assertTrue(type(lnp.arange(77)) == type(lax.iota(onp.int32, 77)))\n\n    # # test that lnp.arange(N, dtype=int32) doesn\'t instantiate an ndarray\n    # self.assertFalse(type(lnp.arange(77, dtype=lnp.int32)) ==\n    #                  type(onp.arange(77, dtype=onp.int32)))\n    # self.assertTrue(type(lnp.arange(77, dtype=lnp.int32)) ==\n    #                 type(lax.iota(onp.int32, 77)))\n\n  def testIssue830(self):\n    a = lnp.arange(4, dtype=lnp.complex64)\n    self.assertEqual(a.dtype, lnp.complex64)\n\n  def testIssue728(self):\n    assert lnp.allclose(lnp.eye(5000), onp.eye(5000))\n    self.assertEqual(0, onp.sum(lnp.eye(1050) - onp.eye(1050)))\n\n  def testIssue746(self):\n    lnp.arange(12).reshape(3, 4)  # doesn\'t crash\n\n  def testIssue764(self):\n    x = lnp.linspace(190, 200, 4)\n    f = npe.grad(lambda x: lnp.sum(lnp.tanh(x)))\n    # Expected values computed with autograd in float64 precision.\n    expected = onp.array([3.71669453e-165, 4.72999108e-168, 6.01954653e-171,\n                          7.66067839e-174], onp.float64)\n    self.assertAllClose(f(x), expected, check_dtypes=False)\n\n  @jtu.disable\n  def testIssue776(self):\n    """"""Tests that the scatter-add transpose rule instantiates symbolic zeros.""""""\n    def f(u):\n      y = jax.ops.index_add(onp.ones(10,), [2, 4, 5], u)\n      # The transpose rule for lax.tie_in returns a symbolic zero for its first\n      # argument.\n      return lax.tie_in(y, 7.)\n\n    self.assertAllClose(onp.zeros(3,), api.grad(f)(onp.ones(3,)),\n                        check_dtypes=True)\n\n  @jtu.disable\n  def testIssue777(self):\n    x = lnp.linspace(-200, 0, 4, dtype=onp.float32)\n    f = npe.grad(lambda x: lnp.sum(1 / (1 + lnp.exp(-x))))\n    self.assertAllClose(f(x), onp.array([0., 0., 0., 0.25], dtype=onp.float32),\n                        check_dtypes=True)\n\n  @named_parameters(\n      jtu.cases_from_list(\n        {""testcase_name"": jtu.format_test_name_suffix(op, [()], [dtype]),\n         ""dtype"": dtype, ""op"": op}\n      for dtype in float_dtypes\n      for op in (""sqrt"", ""arccos"", ""arcsin"", ""arctan"", ""sin"", ""cos"", ""tan"",\n                 ""sinh"", ""cosh"", ""tanh"", ""arccosh"", ""arcsinh"", ""arctanh"", ""exp"",\n                 ""log"", ""expm1"", ""log1p"")))\n  def testMathSpecialFloatValues(self, op, dtype):\n    onp_op = getattr(onp, op)\n    lnp_op = getattr(lnp, op)\n    dtype = onp.dtype(lnp.canonicalize_dtype(dtype)).type\n    for x in (onp.nan, -onp.inf, -100., -2., -1., 0., 1., 2., 100., onp.inf,\n              lnp.finfo(dtype).max, onp.sqrt(lnp.finfo(dtype).max),\n              onp.sqrt(lnp.finfo(dtype).max) * 2.):\n      if (op in (""sin"", ""cos"", ""tan"", ""arctan"") and\n          jtu.device_under_test() == ""tpu""):\n        continue  # TODO(b/132196789, b/134175194): fix and reenable.\n      # TODO(b/158006398): fix and reenable.\n      if (op in (""cosh"", ""arccosh"", ""arcsinh"", ""arcsin"", ""sinh"", ""arccos"",\n                 ""arctan"", ""arctanh"") and dtype == onp.float16):\n        continue\n      x = dtype(x)\n      expected = onp_op(x)\n      actual = lnp_op(x)\n      tol = jtu.tolerance(dtype, {onp.float32: 1e-3, onp.float64: 1e-7})\n      self.assertAllClose(expected, actual, check_dtypes=True, atol=tol,\n                          rtol=tol)\n\n  def testIssue883(self):\n    # from https://github.com/google/jax/issues/883\n\n    @partial(npe.jit, static_argnums=(1,))\n    def f(x, v):\n      return x\n\n    x = lnp.ones((10, 10))\n    v = lnp.array([1, 2, 3])\n    first_call = f(x, v)\n    second_call = f(x, v)  # doesn\'t crash\n\n  def testReductionOfOutOfBoundsAxis(self):  # Issue 888\n    x = lnp.ones((3, 4))\n    self.assertRaises(\n        tf.errors.InvalidArgumentError, lambda: lnp.sum(x, axis=2))\n\n  @jtu.disable\n  def testIssue956(self):\n    self.assertRaises(TypeError, lambda: lnp.ndarray((1, 1)))\n\n  @named_parameters(\n      jtu.cases_from_list(\n        {""testcase_name"":\n         ""_shape={}_dtype={}_out_dtype={}_axis={}_ddof={}_keepdims={}""\n         .format(shape, dtype, out_dtype, axis, ddof, keepdims),\n         ""shape"": shape, ""dtype"": dtype, ""out_dtype"": out_dtype, ""axis"": axis,\n         ""ddof"": ddof, ""keepdims"": keepdims, ""rng_factory"": rng_factory}\n        for shape in [(5,), (10, 5)]\n        for dtype in all_dtypes\n        for out_dtype in inexact_dtypes\n        for axis in [None, 0, -1]\n        for ddof in [0, 1, 2]\n        for keepdims in [False, True]\n        for rng_factory in [jtu.rand_default]))\n  def testVar(self, shape, dtype, out_dtype, axis, ddof, keepdims, rng_factory):\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    def onp_fun(x):\n      out = onp.var(x.astype(lnp.promote_types(onp.float32, dtype)),\n                    axis=axis, ddof=ddof, keepdims=keepdims)\n      return out.astype(out_dtype)\n    lnp_fun = partial(lnp.var, dtype=out_dtype, axis=axis, ddof=ddof, keepdims=keepdims)\n    tol = jtu.tolerance(out_dtype, {onp.float16: 1e-1, onp.float32: 1e-3,\n                                    onp.float64: 1e-3, onp.complex128: 1e-6})\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True,\n                            tol=tol)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True, rtol=tol,\n                          atol=tol, check_incomplete_shape=True)\n\n  @named_parameters(\n      jtu.cases_from_list(\n        {""testcase_name"": ""_shape={}_dtype={}_rowvar={}_ddof={}_bias={}"".format(\n            shape, dtype, rowvar, ddof, bias),\n         ""shape"": shape, ""dtype"": dtype, ""rowvar"": rowvar, ""ddof"": ddof,\n         ""bias"": bias, ""rng_factory"": rng_factory}\n        for shape in [(5,), (10, 5), (5, 10)]\n        for dtype in all_dtypes\n        for rowvar in [True, False]\n        for bias in [True, False]\n        for ddof in [None, 2, 3]\n        for rng_factory in [jtu.rand_default]))\n  @jtu.skip_on_devices(""gpu"")  # TODO(b/138003641): test fails on GPU.\n  @jtu.disable\n  def testCov(self, shape, dtype, rowvar, ddof, bias, rng_factory):\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    onp_fun = partial(onp.cov, rowvar=rowvar, ddof=ddof, bias=bias)\n    lnp_fun = partial(lnp.cov, rowvar=rowvar, ddof=ddof, bias=bias)\n    tol = {onp.float32: 1e-5, onp.float64: 1e-13, onp.complex128: 1e-13}\n    tol = 7e-2 if jtu.device_under_test() == ""tpu"" else tol\n    tol = jtu.join_tolerance(tol, jtu.tolerance(dtype))\n    self._CheckAgainstNumpy(\n        onp_fun, lnp_fun, args_maker, check_dtypes=False, tol=tol)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True, atol=tol,\n                          rtol=tol)\n\n  def testIssue967(self):\n    self.assertRaises(TypeError, lambda: lnp.zeros(1.5))\n\n  @named_parameters(\n      jtu.cases_from_list(\n        {""testcase_name"": ""_shape={}_dtype={}_rowvar={}_ddof={}_bias={}"".format(\n            shape, dtype, rowvar, ddof, bias),\n         ""shape"": shape, ""dtype"": dtype, ""rowvar"": rowvar, ""ddof"": ddof,\n         ""bias"": bias, ""rng_factory"": rng_factory}\n        for shape in [(5,), (10, 5), (3, 10)]\n        for dtype in number_dtypes\n        for rowvar in [True, False]\n        for bias in [True, False]\n        for ddof in [None, 2, 3]\n        for rng_factory in [jtu.rand_default]))\n  @jtu.disable\n  def testCorrCoef(self, shape, dtype, rowvar, ddof, bias, rng_factory):\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng, [shape], [dtype])\n    mat = onp.asarray([rng(shape, dtype)])\n    onp_fun = partial(onp.corrcoef, rowvar=rowvar, ddof=ddof, bias=bias)\n    lnp_fun = partial(lnp.corrcoef, rowvar=rowvar, ddof=ddof, bias=bias)\n    if not onp.any(onp.isclose(onp.std(mat), 0.0)):\n      self._CheckAgainstNumpy(\n          onp_fun, lnp_fun, args_maker, check_dtypes=False,\n          tol=1e-2 if jtu.device_under_test() == ""tpu"" else None)\n    self._CompileAndCheck(lnp_fun, args_maker, check_dtypes=True)\n\n  @named_parameters(\n      jtu.cases_from_list(\n          {\n              ""testcase_name"":\n                  ""_shapes={}_dtype={}_indexing={}_sparse={}"".format(\n                      shapes, dtype, indexing, sparse),\n              ""shapes"":\n                  shapes,\n              ""dtype"":\n                  dtype,\n              ""indexing"":\n                  indexing,\n              ""sparse"":\n                  sparse,\n              ""rng_factory"":\n                  rng_factory\n          } for shapes in [(), (5,), (5, 3)] for dtype in number_dtypes\n          for indexing in [""xy"", ""ij""]\n          for sparse in [False]  # TODO(nareshmodi): Make sparse work\n          for rng_factory in [jtu.rand_default]))\n  def testMeshGrid(self, shapes, dtype, indexing, sparse, rng_factory):\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng, [(x,) for x in shapes],\n                                    [dtype] * len(shapes))\n    onp_fun = partial(onp.meshgrid, indexing=indexing, sparse=sparse)\n    lnp_fun = partial(lnp.meshgrid, indexing=indexing, sparse=sparse)\n    self._CheckAgainstNumpy(onp_fun, lnp_fun, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_fun, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  @named_parameters(\n      jtu.cases_from_list(\n        {""testcase_name"": (""_start_shape={}_stop_shape={}_num={}_endpoint={}""\n                           ""_retstep={}_dtype={}"").format(\n            start_shape, stop_shape, num, endpoint, retstep, dtype),\n         ""start_shape"": start_shape, ""stop_shape"": stop_shape,\n         ""num"": num, ""endpoint"": endpoint, ""retstep"": retstep,\n         ""dtype"": dtype, ""rng_factory"": rng_factory}\n        for start_shape in [(), (2,), (2, 2)]\n        for stop_shape in [(), (2,), (2, 2)]\n        for num in [0, 1, 2, 5, 20]\n        for endpoint in [True, False]\n        for retstep in [True, False]\n        for dtype in number_dtypes + [None,]\n        for rng_factory in [jtu.rand_default]))\n  def testLinspace(self, start_shape, stop_shape, num, endpoint,\n                   retstep, dtype, rng_factory):\n    if not endpoint and onp.issubdtype(dtype, onp.integer):\n      # TODO(b/157597565): Support all dtypes when the tf op supports endpoint\n      # Currently, subtracting the step early leads to rounding errors for\n      # integers.\n      return\n    rng = rng_factory()\n    # relax default tolerances slightly\n    tol = jtu.tolerance(dtype if dtype else onp.float32) * 10\n    args_maker = self._GetArgsMaker(rng,\n                                    [start_shape, stop_shape],\n                                    [dtype, dtype])\n    start, stop = args_maker()\n    ndim = len(onp.shape(start + stop))\n    for axis in range(-ndim, ndim):\n      lnp_op = lambda start, stop: lnp.linspace(\n        start, stop, num,\n        endpoint=endpoint, retstep=retstep, dtype=dtype, axis=axis)\n      onp_op = lambda start, stop: onp.linspace(\n        start, stop, num,\n        endpoint=endpoint, retstep=retstep, dtype=dtype, axis=axis)\n      self._CheckAgainstNumpy(onp_op, lnp_op, args_maker,\n                              check_dtypes=False, tol=tol)\n      # floating-point compute between jitted platforms and non-jit + rounding\n      # cause unavoidable variation in integer truncation for some inputs.\n      if dtype in (inexact_dtypes + [None,]):\n        self._CompileAndCheck(lnp_op, args_maker,\n                              check_dtypes=False, atol=tol, rtol=tol,\n                              check_incomplete_shape=True)\n\n  @named_parameters(\n      jtu.cases_from_list(\n        {""testcase_name"": (""_start_shape={}_stop_shape={}_num={}_endpoint={}""\n                           ""_base={}_dtype={}"").format(\n            start_shape, stop_shape, num, endpoint, base,\n            dtype.__name__ if dtype else ""None""),\n         ""start_shape"": start_shape,\n         ""stop_shape"": stop_shape,\n         ""num"": num, ""endpoint"": endpoint, ""base"": base,\n         ""dtype"": dtype, ""rng_factory"": rng_factory}\n        for start_shape in [(), (2,), (2, 2)]\n        for stop_shape in [(), (2,), (2, 2)]\n        for num in [0, 1, 2, 5, 20]\n        for endpoint in [True, False]\n        for base in [10.0, 2, onp.e]\n        for dtype in inexact_dtypes + [None,]\n        for rng_factory in [jtu.rand_default]))\n  def testLogspace(self, start_shape, stop_shape, num,\n                   endpoint, base, dtype, rng_factory):\n    if (dtype in int_dtypes and\n        jtu.device_under_test() in (""gpu"", ""tpu"") and\n        not FLAGS.enable_x64):\n      raise unittest.SkipTest(""GPUx32 truncated exponentiation""\n                              "" doesn\'t exactly match other platforms."")\n    rng = rng_factory()\n    # relax default tolerances slightly\n    tol = {onp.float16: 2e-2, onp.float32: 1e-2, onp.float64: 1e-6,\n           onp.complex64: 1e-3, onp.complex128: 1e-6}\n    args_maker = self._GetArgsMaker(rng,\n                                    [start_shape, stop_shape],\n                                    [dtype, dtype])\n    start, stop = args_maker()\n    ndim = len(onp.shape(start + stop))\n    for axis in range(-ndim, ndim):\n      lnp_op = lambda start, stop: lnp.logspace(\n        start, stop, num, endpoint=endpoint, base=base, dtype=dtype, axis=axis)\n      onp_op = lambda start, stop: onp.logspace(\n        start, stop, num, endpoint=endpoint, base=base, dtype=dtype, axis=axis)\n      self._CheckAgainstNumpy(onp_op, lnp_op, args_maker,\n                              check_dtypes=False, tol=tol)\n      if dtype in (inexact_dtypes + [None,]):\n        # Why do compiled and op-by-op float16 np.power numbers differ\n        # slightly more than expected?\n        atol = {onp.float16: 1e-2}\n        self._CompileAndCheck(lnp_op, args_maker,\n                              check_dtypes=False, atol=atol, rtol=tol,\n                              check_incomplete_shape=True)\n\n  @named_parameters(\n      jtu.cases_from_list(\n        {""testcase_name"": (""_start_shape={}_stop_shape={}_num={}_endpoint={}""\n                           ""_dtype={}"").format(\n            start_shape, stop_shape, num, endpoint, dtype),\n         ""start_shape"": start_shape,\n         ""stop_shape"": stop_shape,\n         ""num"": num, ""endpoint"": endpoint,\n         ""dtype"": dtype, ""rng_factory"": rng_factory}\n        for start_shape in [(), (2,), (2, 2)]\n        for stop_shape in [(), (2,), (2, 2)]\n        for num in [0, 1, 2, 5, 20]\n        for endpoint in [True, False]\n        # NB: numpy\'s geomspace gives nonsense results on integer types\n        for dtype in inexact_dtypes + [None,]\n        for rng_factory in [jtu.rand_default]))\n  def testGeomspace(self, start_shape, stop_shape, num,\n                    endpoint, dtype, rng_factory):\n    rng = rng_factory()\n    # relax default tolerances slightly\n    tol = {onp.float16: 4e-3, onp.float32: 2e-3, onp.complex128: 1e-14}\n    def args_maker():\n      """"""Test the set of inputs onp.geomspace is well-defined on.""""""\n      start, stop = self._GetArgsMaker(rng,\n                                [start_shape, stop_shape],\n                                [dtype, dtype])()\n      # onp.geomspace can\'t handle differently ranked tensors\n      # w. negative numbers!\n      start, stop = lnp.broadcast_arrays(start, stop)\n      if dtype in complex_dtypes:\n        return start, stop\n      # to avoid NaNs, non-complex start and stop cannot\n      # differ in sign, elementwise\n      start = start * lnp.sign(start) * lnp.sign(stop)\n      return start, stop\n    start, stop = args_maker()\n    ndim = len(onp.shape(start + stop))\n    for axis in range(-ndim, ndim):\n      def lnp_op(start, stop):\n        return lnp.geomspace(start, stop, num, endpoint=endpoint, dtype=dtype,\n                             axis=axis)\n      def onp_op(start, stop):\n        start = start.astype(onp.float32) if dtype == lnp.bfloat16 else start\n        stop = stop.astype(onp.float32) if dtype == lnp.bfloat16 else stop\n        return onp.geomspace(\n          start, stop, num, endpoint=endpoint,\n          dtype=dtype if dtype != lnp.bfloat16 else onp.float32,\n          axis=axis).astype(dtype)\n      self._CheckAgainstNumpy(onp_op, lnp_op, args_maker,\n                              check_dtypes=False, tol=tol)\n      if dtype in (inexact_dtypes + [None,]):\n        self._CompileAndCheck(lnp_op, args_maker,\n                              check_dtypes=False, atol=tol, rtol=tol,\n                              check_incomplete_shape=True)\n\n  @jtu.disable\n  def testDisableNumpyRankPromotionBroadcasting(self):\n    try:\n      prev_flag = FLAGS.jax_numpy_rank_promotion\n      FLAGS.jax_numpy_rank_promotion = ""allow""\n      lnp.ones(2) + lnp.ones((1, 2))  # works just fine\n    finally:\n      FLAGS.jax_numpy_rank_promotion = prev_flag\n\n    try:\n      prev_flag = FLAGS.jax_numpy_rank_promotion\n      FLAGS.jax_numpy_rank_promotion = ""raise""\n      self.assertRaises(ValueError, lambda: lnp.ones(2) + lnp.ones((1, 2)))\n    finally:\n      FLAGS.jax_numpy_rank_promotion = prev_flag\n\n    try:\n      prev_flag = FLAGS.jax_numpy_rank_promotion\n      FLAGS.jax_numpy_rank_promotion = ""warn""\n      with warnings.catch_warnings(record=True) as w:\n        warnings.simplefilter(""always"")\n        lnp.ones(2) + lnp.ones((1, 2))\n        assert len(w) > 0\n        msg = str(w[-1].message)\n        expected_msg = (""Following NumPy automatic rank promotion for add on ""\n                        ""shapes (2,) (1, 2)."")\n        self.assertEqual(msg[:len(expected_msg)], expected_msg)\n\n        prev_len = len(w)\n        lnp.ones(2) + 3\n        self.assertEqual(len(w), prev_len)  # don\'t want to warn for scalars\n    finally:\n      FLAGS.jax_numpy_rank_promotion = prev_flag\n\n  def testStackArrayArgument(self):\n    # tests https://github.com/google/jax/issues/1271\n    @npe.jit\n    def foo(x):\n      return lnp.stack(x)\n    foo(onp.zeros(2))  # doesn\'t crash\n\n    @npe.jit\n    def foo(x):\n      return lnp.concatenate(x)\n    foo(onp.zeros((2, 2)))  # doesn\'t crash\n\n  @jtu.disable\n  def testReluGradientConstants(self):\n    # This is a regression test that verifies that constants associated with the\n    # gradient of np.maximum (from lax._balanced_eq) aren\'t hoisted into the\n    # outermost jaxpr. This was producing some large materialized constants for\n    # every relu activation in a model.\n    def body(i, xy):\n      x, y = xy\n      y = y + jax.grad(lambda z: lnp.sum(lnp.maximum(z, 0.)))(x)\n      return x, y\n\n    f = lambda y: lax.fori_loop(0, 5, body, (y, y))\n    wrapped = linear_util.wrap_init(f)\n    pv = partial_eval.PartialVal(\n      (jax.ShapedArray((3, 4), onp.float32), jax.core.unit))\n    _, _, consts = partial_eval.trace_to_jaxpr(wrapped, [pv])\n    self.assertFalse(\n      any(onp.array_equal(x, onp.full((3, 4), 2., dtype=onp.float32))\n          for x in consts))\n\n  @named_parameters(\n      {""testcase_name"": ""_from={}_to={}"".format(from_shape, to_shape),\n       ""rng_factory"": rng_factory, ""from_shape"": from_shape, ""to_shape"": to_shape}\n      for from_shape, to_shape in [\n          [(1, 3), (4, 3)],\n          [(3,), (2, 1, 3)],\n          [(3,), (3, 3)],\n          [(1,), (3,)],\n      ]\n      for rng_factory in [jtu.rand_default])\n  def testBroadcastTo(self, from_shape, to_shape, rng_factory):\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(rng, [from_shape], [onp.float32])\n    onp_op = lambda x: onp.broadcast_to(x, to_shape)\n    lnp_op = lambda x: lnp.broadcast_to(x, to_shape)\n    self._CheckAgainstNumpy(onp_op, lnp_op, args_maker, check_dtypes=True)\n    self._CompileAndCheck(\n        lnp_op, args_maker, check_dtypes=True, check_incomplete_shape=True)\n\n  def testBroadcastToIssue1522(self):\n    self.assertRaisesRegex(\n        Exception, ""Unable to broadcast"",\n        lambda: lnp.broadcast_to(onp.ones((2, 3)), (1, 3)))\n\n  def testBroadcastToIntIssue1548(self):\n    self.assertAllClose(lnp.broadcast_to(1, (3, 2)), onp.ones((3, 2)),\n                        check_dtypes=False)\n\n  def testBroadcastToOnScalar(self):\n    self.assertIsInstance(lnp.broadcast_to(10.0, ()), lnp.ndarray)\n    self.assertIsInstance(onp.broadcast_to(10.0, ()), onp.ndarray)\n\n  @jtu.disable\n  def testPrecision(self):\n\n    ones_1d = onp.ones((2,))\n    ones_2d = onp.ones((2, 2))\n    ones_3d = onp.ones((2, 2, 2))\n    HIGHEST = lax.Precision.HIGHEST\n\n    jtu.assert_dot_precision(None, lnp.dot, ones_1d, ones_1d)\n    jtu.assert_dot_precision(\n        HIGHEST,\n        partial(lnp.dot, precision=HIGHEST),\n        ones_1d, ones_1d)\n    jtu.assert_dot_precision(\n        HIGHEST,\n        partial(lnp.dot, precision=HIGHEST),\n        ones_3d, ones_3d)\n    jtu.assert_dot_precision(\n        HIGHEST,\n        partial(lnp.matmul, precision=HIGHEST),\n        ones_2d, ones_2d)\n    jtu.assert_dot_precision(\n        HIGHEST,\n        partial(lnp.vdot, precision=HIGHEST),\n        ones_1d, ones_1d)\n    jtu.assert_dot_precision(\n        HIGHEST,\n        partial(lnp.tensordot, axes=2, precision=HIGHEST),\n        ones_2d, ones_2d)\n    jtu.assert_dot_precision(\n        HIGHEST,\n        partial(lnp.tensordot, axes=(0, 0), precision=HIGHEST),\n        ones_1d, ones_1d)\n    jtu.assert_dot_precision(\n        HIGHEST,\n        partial(lnp.tensordot, axes=((0,), (0,)), precision=HIGHEST),\n        ones_1d, ones_1d)\n    jtu.assert_dot_precision(\n        HIGHEST,\n        partial(lnp.einsum, \'i,i\', precision=HIGHEST),\n        ones_1d, ones_1d)\n    jtu.assert_dot_precision(\n        HIGHEST,\n        partial(lnp.einsum, \'ij,ij\', precision=HIGHEST),\n        ones_2d, ones_2d)\n    jtu.assert_dot_precision(\n        HIGHEST,\n        partial(lnp.inner, precision=HIGHEST),\n        ones_1d, ones_1d)\n\n  @named_parameters(jtu.cases_from_list(\n      {""testcase_name"":\n       ""_{}_{}_{}_{}"".format(\n           shape, jtu.dtype_str(key_dtype), jtu.dtype_str(value_dtype),\n           dimension).replace("" "", """"),\n       ""shape"": shape, ""key_dtype"": key_dtype, ""value_dtype"": value_dtype,\n       ""dimension"": dimension, ""rng_factory"": rng_factory}\n      for shape in all_shapes\n      for key_dtype in minus(number_dtypes, complex_dtypes)\n      for value_dtype in all_dtypes\n      for dimension in range(-len(shape), len(shape))\n      for rng_factory in [jtu.rand_default]))\n  @new_test\n  def testSortKeyValue(self, shape, key_dtype, value_dtype, dimension,\n                       rng_factory):\n    def onp_ref(keys, values):\n      idxs = list(onp.ix_(*[onp.arange(d) for d in keys.shape]))\n      idxs[dimension] = onp.argsort(keys, axis=dimension)\n      return keys[tuple(idxs)], values[tuple(idxs)]\n    rng = rng_factory()\n    args_maker = self._GetArgsMaker(\n        rng, [shape, shape], [key_dtype, value_dtype])\n    op = partial(npe.sort_key_val, dimension=dimension)\n    self._CheckAgainstNumpy(onp_ref, op, args_maker,\n                            check_dtypes=True)\n    # sort_key_val requires known rank\n    self._CompileAndCheck(op, args_maker, check_dtypes=True,\n                          check_incomplete_shape=True, check_unknown_rank=False)\n\n\n# Most grad tests are at the lax level (see lax_test.py), but we add some here\n# as needed for e.g. particular compound ops of interest.\n\nGradTestSpec = collections.namedtuple(\n    ""GradTestSpec"",\n    [""op"", ""nargs"", ""order"", ""rng_factory"", ""dtypes"", ""name"", ""tol""])\ndef grad_test_spec(op, nargs, order, rng_factory, dtypes, name=None, tol=None):\n  return GradTestSpec(\n      op, nargs, order, rng_factory, dtypes, name or op.__name__, tol)\n\nGRAD_TEST_RECORDS = [\n    grad_test_spec(lnp.arcsinh, nargs=1, order=2,\n                   rng_factory=jtu.rand_positive,\n                   dtypes=[onp.float64, onp.complex64], tol=1e-4),\n    grad_test_spec(lnp.arccosh, nargs=1, order=2,\n                   rng_factory=jtu.rand_positive,\n                   dtypes=[onp.float64, onp.complex64], tol=1e-4),\n    grad_test_spec(lnp.arctanh, nargs=1, order=2,\n                   rng_factory=partial(jtu.rand_uniform, -0.9, 0.9),\n                   dtypes=[onp.float64, onp.complex64], tol=1e-4),\n]\n\nGradSpecialValuesTestSpec = collections.namedtuple(\n    ""GradSpecialValuesTestSpec"", [""op"", ""values"", ""order""])\n\nGRAD_SPECIAL_VALUE_TEST_RECORDS = [\n    GradSpecialValuesTestSpec(lnp.arcsinh, [0., 1000.], 2),\n    GradSpecialValuesTestSpec(lnp.arccosh, [1000.], 2),\n    GradSpecialValuesTestSpec(lnp.arctanh, [0.], 2),\n    # TODO(wangpeng): Add `GradSpecialValuesTestSpec(lnp.sinc, [0.], 1)`\n]\n\ndef num_float_bits(dtype):\n  return lnp.finfo(dtypes.canonicalize_dtype(dtype)).bits\n\nclass NumpyGradTests(jtu.TestCase):\n  @named_parameters(itertools.chain.from_iterable(\n      jtu.cases_from_list(\n        {""testcase_name"": jtu.format_test_name_suffix(\n            rec.name, shapes, itertools.repeat(dtype)),\n         ""op"": rec.op, ""rng_factory"": rec.rng_factory, ""shapes"": shapes, ""dtype"": dtype,\n         ""order"": rec.order, ""tol"": rec.tol}\n        for shapes in CombosWithReplacement(nonempty_shapes, rec.nargs)\n        for dtype in rec.dtypes)\n      for rec in GRAD_TEST_RECORDS))\n  @jtu.disable\n  def testOpGrad(self, op, rng_factory, shapes, dtype, order, tol):\n    rng = rng_factory()\n    tol = {onp.float32: 1e-1, onp.complex64: 1e-1}\n    args = tuple(rng(shape, dtype) for shape in shapes)\n    check_grads(op, args, order, [""fwd"", ""rev""], tol, tol)\n\n  @named_parameters(itertools.chain.from_iterable(\n      jtu.cases_from_list(\n          {""testcase_name"": ""_{}_{}"".format(rec.op.__name__, special_value),\n           ""op"": rec.op, ""special_value"": special_value, ""order"": rec.order}\n          for special_value in rec.values)\n      for rec in GRAD_SPECIAL_VALUE_TEST_RECORDS))\n  @jtu.disable\n  def testOpGradSpecialValue(self, op, special_value, order):\n    check_grads(op, (special_value,), order, [""fwd"", ""rev""],\n                atol={onp.float32: 3e-3})\n\n  @jtu.disable\n  def testTakeAlongAxisIssue1521(self):\n    # https://github.com/google/jax/issues/1521\n    idx = lnp.repeat(lnp.arange(3), 10).reshape((30, 1))\n\n    def f(x):\n      y = x * lnp.arange(3.).reshape((1, 3))\n      return lnp.take_along_axis(y, idx, -1).sum()\n\n    check_grads(f, (1.,), order=1)\n\n\nif __name__ == ""__main__"":\n  tf.enable_v2_behavior()\n  absltest.main()\n'"
trax/tf_numpy/jax_tests/test_util.py,95,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Copyright 2018 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nfrom contextlib import contextmanager\nfrom distutils.util import strtobool\nimport functools\nfrom functools import partial\nimport re\nimport itertools as it\nimport os\nfrom typing import Dict, Sequence, Union\nimport sys\nimport unittest\nimport warnings\n\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\n\nimport numpy as onp\nimport numpy.random as npr\nimport scipy\n\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.jax_tests.config import flags, bool_env\nimport trax.tf_numpy.extensions as npe\n\n\ntree_map = tf.nest.map_structure\ntree_multimap = tf.nest.map_structure\n\n\nFLAGS = flags.FLAGS\n\n\n# TODO(wangpeng): Remove this flag after broken tests are fixed\nflags.DEFINE_bool(\'enable_x64\',\n                  strtobool(\'False\'),\n                  \'Enable 64-bit types to be used.\')\n\n\nflags.DEFINE_enum(\n    \'test_dut\', \'\',\n    enum_values=[\'\', \'cpu\', \'gpu\', \'tpu\'],\n    help=\n    \'Describes the device under test in case special consideration is required.\'\n)\n\n\nflags.DEFINE_integer(\n  \'num_generated_cases\',\n  10,\n  help=\'Number of generated cases to test\')\n\n\nEPS = 1e-4\n\n\n# Default dtypes corresponding to Python scalars.\npython_scalar_dtypes = {\n  bool: onp.dtype(onp.bool_),\n  int: onp.dtype(onp.int_),\n  float: onp.dtype(onp.float_),\n  complex: onp.dtype(onp.complex_),\n}\n\n\ndef _dtype(x):\n  return (getattr(x, \'dtype\', None) or\n          onp.dtype(python_scalar_dtypes.get(type(x), None)) or\n          onp.asarray(x).dtype)\n\n\ndef is_sequence(x):\n  try:\n    iter(x)\n  except TypeError:\n    return False\n  else:\n    return True\n\n_default_tolerance = {\n  onp.dtype(onp.bool_): 0,\n  onp.dtype(onp.int8): 0,\n  onp.dtype(onp.int16): 0,\n  onp.dtype(onp.int32): 0,\n  onp.dtype(onp.int64): 0,\n  onp.dtype(onp.uint8): 0,\n  onp.dtype(onp.uint16): 0,\n  onp.dtype(onp.uint32): 0,\n  onp.dtype(onp.uint64): 0,\n  # TODO(b/154768983): onp.dtype(dtypes.bfloat16): 1e-2,\n  onp.dtype(onp.float16): 1e-3,\n  onp.dtype(onp.float32): 1e-6,\n  onp.dtype(onp.float64): 1e-15,\n  onp.dtype(onp.complex64): 1e-6,\n  onp.dtype(onp.complex128): 1e-15,\n}\n\ndef default_tolerance():\n  return _default_tolerance\n\ndefault_gradient_tolerance = {\n  # TODO(b/154768983): onp.dtype(dtypes.bfloat16): 1e-1,\n  onp.dtype(onp.float16): 1e-2,\n  onp.dtype(onp.float32): 2e-3,\n  onp.dtype(onp.float64): 1e-5,\n  onp.dtype(onp.complex64): 1e-3,\n  onp.dtype(onp.complex128): 1e-5,\n}\n\ndef _assert_numpy_allclose(a, b, atol=None, rtol=None):\n  # TODO(b/154768983):\n  #   a = a.astype(onp.float32) if a.dtype == dtypes.bfloat16 else a\n  #   b = b.astype(onp.float32) if b.dtype == dtypes.bfloat16 else b\n  kw = {}\n  if atol: kw[""atol""] = atol\n  if rtol: kw[""rtol""] = rtol\n  onp.testing.assert_allclose(a, b, **kw)\n\ndef tolerance(dtype, tol=None):\n  tol = {} if tol is None else tol\n  if not isinstance(tol, dict):\n    return tol\n  tol = {onp.dtype(key): value for key, value in tol.items()}\n  dtype = onp.dtype(dtype)\n  return tol.get(dtype, default_tolerance()[dtype])\n\ndef _normalize_tolerance(tol):\n  tol = tol or 0\n  if isinstance(tol, dict):\n    return {onp.dtype(k): v for k, v in tol.items()}\n  else:\n    return {k: tol for k in _default_tolerance.keys()}\n\ndef join_tolerance(tol1, tol2):\n  tol1 = _normalize_tolerance(tol1)\n  tol2 = _normalize_tolerance(tol2)\n  out = tol1\n  for k, v in tol2.items():\n    out[k] = max(v, tol1.get(k, 0))\n  return out\n\ndef _assert_numpy_close(a, b, atol=None, rtol=None):\n  assert a.shape == b.shape\n  atol = max(tolerance(a.dtype, atol), tolerance(b.dtype, atol))\n  rtol = max(tolerance(a.dtype, rtol), tolerance(b.dtype, rtol))\n  _assert_numpy_allclose(a, b, atol=atol * a.size, rtol=rtol * b.size)\n\n\ndef check_eq(xs, ys):\n  tree_all(tree_multimap(_assert_numpy_allclose, xs, ys))\n\n\ndef check_close(xs, ys, atol=None, rtol=None):\n  assert_close = partial(_assert_numpy_close, atol=atol, rtol=rtol)\n  tree_all(tree_multimap(assert_close, xs, ys))\n\n\ndef inner_prod(xs, ys):\n  def contract(x, y):\n    return onp.real(onp.dot(onp.conj(x).reshape(-1), y.reshape(-1)))\n  return tree_reduce(onp.add, tree_multimap(contract, xs, ys))\n\n\nadd = partial(tree_multimap, lambda x, y: onp.add(x, y, dtype=_dtype(x)))\nsub = partial(tree_multimap, lambda x, y: onp.subtract(x, y, dtype=_dtype(x)))\nconj = partial(tree_map, lambda x: onp.conj(x, dtype=_dtype(x)))\n\ndef scalar_mul(xs, a):\n  return tree_map(lambda x: onp.multiply(x, a, dtype=_dtype(x)), xs)\n\n\ndef rand_like(rng, x):\n  shape = onp.shape(x)\n  dtype = _dtype(x)\n  randn = lambda: onp.asarray(rng.randn(*shape), dtype=dtype)\n  if onp.issubdtype(dtype, onp.complexfloating):\n    return randn() + dtype.type(1.0j) * randn()\n  else:\n    return randn()\n\n\ndef numerical_jvp(f, primals, tangents, eps=EPS):\n  delta = scalar_mul(tangents, eps)\n  f_pos = f(*add(primals, delta))\n  f_neg = f(*sub(primals, delta))\n  return scalar_mul(sub(f_pos, f_neg), 0.5 / eps)\n\n\ndef _merge_tolerance(tol, default):\n  if tol is None:\n    return default\n  if not isinstance(tol, dict):\n    return tol\n  out = default.copy()\n  for k, v in tol.items():\n    out[onp.dtype(k)] = v\n  return out\n\ndef check_jvp(f, f_jvp, args, atol=None, rtol=None, eps=EPS):\n  atol = _merge_tolerance(atol, default_gradient_tolerance)\n  rtol = _merge_tolerance(rtol, default_gradient_tolerance)\n  rng = onp.random.RandomState(0)\n  tangent = tree_map(partial(rand_like, rng), args)\n  v_out, t_out = f_jvp(args, tangent)\n  v_out_expected = f(*args)\n  t_out_expected = numerical_jvp(f, args, tangent, eps=eps)\n  # In principle we should expect exact equality of v_out and v_out_expected,\n  # but due to nondeterminism especially on GPU (e.g., due to convolution\n  # autotuning) we only require ""close"".\n  check_close(v_out, v_out_expected, atol=atol, rtol=rtol)\n  check_close(t_out, t_out_expected, atol=atol, rtol=rtol)\n\n\ndef check_vjp(f, f_vjp, args, atol=None, rtol=None, eps=EPS):\n  atol = _merge_tolerance(atol, default_gradient_tolerance)\n  rtol = _merge_tolerance(rtol, default_gradient_tolerance)\n  _rand_like = partial(rand_like, onp.random.RandomState(0))\n  v_out, vjpfun = f_vjp(*args)\n  v_out_expected = f(*args)\n  check_close(v_out, v_out_expected, atol=atol, rtol=rtol)\n  tangent = tree_map(_rand_like, args)\n  tangent_out = numerical_jvp(f, args, tangent, eps=eps)\n  cotangent = tree_map(_rand_like, v_out)\n  cotangent_out = conj(vjpfun(conj(cotangent)))\n  ip = inner_prod(tangent, cotangent_out)\n  ip_expected = inner_prod(tangent_out, cotangent)\n  check_close(ip, ip_expected, atol=atol, rtol=rtol)\n\n\ndef check_grads(f, args, order,\n                modes=[""fwd"", ""rev""], atol=None, rtol=None, eps=None):\n  """"""Check gradients from automatic differentiation against finite differences.\n\n  Gradients are only checked in a single randomly chosen direction, which\n  ensures that the finite difference calculation does not become prohibitively\n  expensive even for large input/output spaces.\n\n  Args:\n    f: function to check at ``f(*args)``.\n    args: tuple of argument values.\n    order: forward and backwards gradients up to this order are checked.\n    modes: lists of gradient modes to check (\'fwd\' and/or \'rev\').\n    atol: absolute tolerance for gradient equality.\n    rtol: relative tolerance for gradient equality.\n    eps: step size used for finite differences.\n\n  Raises:\n    AssertionError: if gradients do not match.\n  """"""\n  args = tuple(args)\n  eps = eps or EPS\n\n  _check_jvp = partial(check_jvp, atol=atol, rtol=rtol, eps=eps)\n  _check_vjp = partial(check_vjp, atol=atol, rtol=rtol, eps=eps)\n\n  def _check_grads(f, args, order):\n    if ""fwd"" in modes:\n      _check_jvp(f, partial(api.jvp, f), args)\n      if order > 1:\n        _check_grads(partial(api.jvp, f), (args, args), order - 1)\n\n    if ""rev"" in modes:\n      _check_vjp(f, partial(api.vjp, f), args)\n      if order > 1:\n        def f_vjp(*args):\n          out_primal_py, vjp_py = api.vjp(f, *args)\n          return vjp_py(out_primal_py)\n        _check_grads(f_vjp, args, order - 1)\n\n  _check_grads(f, args, order)\n\n\n@contextmanager\ndef count_primitive_compiles():\n  xla.xla_primitive_callable.cache_clear()\n\n  # We count how many times we call primitive_computation (which is called\n  # inside xla_primitive_callable) instead of xla_primitive_callable so we don\'t\n  # count cache hits.\n  primitive_computation = xla.primitive_computation\n  count = [0]\n\n  def primitive_computation_and_count(*args, **kwargs):\n    count[0] += 1\n    return primitive_computation(*args, **kwargs)\n\n  xla.primitive_computation = primitive_computation_and_count\n  try:\n    yield count\n  finally:\n    xla.primitive_computation = primitive_computation\n\n\n@contextmanager\ndef count_jit_and_pmap_compiles():\n  # No need to clear any caches since we generally jit and pmap fresh callables\n  # in tests.\n\n  jaxpr_subcomp = xla.jaxpr_subcomp\n  count = [0]\n\n  def jaxpr_subcomp_and_count(*args, **kwargs):\n    count[0] += 1\n    return jaxpr_subcomp(*args, **kwargs)\n\n  xla.jaxpr_subcomp = jaxpr_subcomp_and_count\n  try:\n    yield count\n  finally:\n    xla.jaxpr_subcomp = jaxpr_subcomp\n\n\ndef device_under_test():\n  return FLAGS.test_dut\n\ndef if_device_under_test(device_type: Union[str, Sequence[str]],\n                         if_true, if_false):\n  """"""Chooses `if_true` of `if_false` based on device_under_test.""""""\n  if device_under_test() in ([device_type] if isinstance(device_type, str)\n                             else device_type):\n    return if_true\n  else:\n    return if_false\n\ndef supported_dtypes():\n  if device_under_test() == ""tpu"":\n    return {onp.bool_, onp.int32, onp.uint32, dtypes.bfloat16, onp.float32,\n            onp.complex64}\n  else:\n    return {onp.bool_, onp.int8, onp.int16, onp.int32, onp.int64,\n            onp.uint8, onp.uint16, onp.uint32, onp.uint64,\n            dtypes.bfloat16, onp.float16, onp.float32, onp.float64,\n            onp.complex64, onp.complex128}\n\ndef skip_if_unsupported_type(dtype):\n  if dtype not in supported_dtypes():\n    raise unittest.SkipTest(\n      f""Type {dtype} not supported on {device_under_test()}"")\n\ndef skip_on_devices(*disabled_devices):\n  """"""A decorator for test methods to skip the test on certain devices.""""""\n  def skip(test_method):\n    @functools.wraps(test_method)\n    def test_method_wrapper(self, *args, **kwargs):\n      device = device_under_test()\n      if device in disabled_devices:\n        test_name = getattr(test_method, \'__name__\', \'[unknown test]\')\n        raise unittest.SkipTest(\n          f""{test_name} not supported on {device.upper()}."")\n      return test_method(self, *args, **kwargs)\n    return test_method_wrapper\n  return skip\n\n\ndef skip_on_flag(flag_name, skip_value):\n  """"""A decorator for test methods to skip the test when flags are set.""""""\n  def skip(test_method):        # pylint: disable=missing-docstring\n    @functools.wraps(test_method)\n    def test_method_wrapper(self, *args, **kwargs):\n      flag_value = getattr(FLAGS, flag_name)\n      if flag_value == skip_value:\n        test_name = getattr(test_method, \'__name__\', \'[unknown test]\')\n        raise unittest.SkipTest(\n          f""{test_name} not supported when FLAGS.{flag_name} is {flag_value}"")\n      return test_method(self, *args, **kwargs)\n    return test_method_wrapper\n  return skip\n\n# TODO(phawkins): workaround for bug https://github.com/google/jax/issues/432\n# Delete this code after the minimum jaxlib version is 0.1.46 or greater.\nskip_on_mac_linalg_bug = partial(\n  unittest.skipIf,\n  (sys.platform == ""darwin"" and scipy.version.version > ""1.1.0"" and\n   lib.version < (0, 1, 46)),\n  ""Test fails on Mac with new scipy (issue #432)"")\n\n\ndef format_test_name_suffix(opname, shapes, dtypes):\n  arg_descriptions = (format_shape_dtype_string(shape, dtype)\n                      for shape, dtype in zip(shapes, dtypes))\n  return \'{}_{}\'.format(opname.capitalize(), \'_\'.join(arg_descriptions))\n\n\n# We use special symbols, represented as singleton objects, to distinguish\n# between NumPy scalars, Python scalars, and 0-D arrays.\nclass ScalarShape(object):\n  def __len__(self): return 0\nclass _NumpyScalar(ScalarShape): pass\nclass _PythonScalar(ScalarShape): pass\nNUMPY_SCALAR_SHAPE = _NumpyScalar()\nPYTHON_SCALAR_SHAPE = _PythonScalar()\n\n\ndef _dims_of_shape(shape):\n  """"""Converts `shape` to a tuple of dimensions.""""""\n  if type(shape) in (list, tuple):\n    return shape\n  elif isinstance(shape, ScalarShape):\n    return ()\n  else:\n    raise TypeError(type(shape))\n\n\ndef _cast_to_shape(value, shape, dtype):\n  """"""Casts `value` to the correct Python type for `shape` and `dtype`.""""""\n  if shape is NUMPY_SCALAR_SHAPE:\n    # explicitly cast to NumPy scalar in case `value` is a Python scalar.\n    return onp.dtype(dtype).type(value)\n  elif shape is PYTHON_SCALAR_SHAPE:\n    # explicitly cast to Python scalar via https://stackoverflow.com/a/11389998\n    return onp.asarray(value).item()\n  elif type(shape) in (list, tuple):\n    assert onp.shape(value) == tuple(shape)\n    return value\n  else:\n    raise TypeError(type(shape))\n\n\ndef dtype_str(dtype):\n  return onp.dtype(dtype).name\n\n\ndef format_shape_dtype_string(shape, dtype):\n  if shape is NUMPY_SCALAR_SHAPE:\n    return dtype_str(dtype)\n  elif shape is PYTHON_SCALAR_SHAPE:\n    return \'py\' + dtype_str(dtype)\n  elif type(shape) in (list, tuple):\n    shapestr = \',\'.join(str(dim) for dim in shape)\n    return \'{}[{}]\'.format(dtype_str(dtype), shapestr)\n  elif type(shape) is int:\n    return \'{}[{},]\'.format(dtype_str(dtype), shape)\n  elif isinstance(shape, onp.ndarray):\n    return \'{}[{}]\'.format(dtype_str(dtype), shape)\n  else:\n    raise TypeError(type(shape))\n\n\ndef _rand_dtype(rand, shape, dtype, scale=1., post=lambda x: x):\n  """"""Produce random values given shape, dtype, scale, and post-processor.\n\n  Args:\n    rand: a function for producing random values of a given shape, e.g. a\n      bound version of either onp.RandomState.randn or onp.RandomState.rand.\n    shape: a shape value as a tuple of positive integers.\n    dtype: a numpy dtype.\n    scale: optional, a multiplicative scale for the random values (default 1).\n    post: optional, a callable for post-processing the random values (default\n      identity).\n\n  Returns:\n    An ndarray of the given shape and dtype using random values based on a call\n    to rand but scaled, converted to the appropriate dtype, and post-processed.\n  """"""\n  r = lambda: onp.asarray(scale * rand(*_dims_of_shape(shape)), dtype)\n  if onp.issubdtype(dtype, onp.complexfloating):\n    vals = r() + 1.0j * r()\n  else:\n    vals = r()\n  return _cast_to_shape(onp.asarray(post(vals), dtype), shape, dtype)\n\n\ndef rand_default(scale=3):\n  randn = npr.RandomState(0).randn\n  return partial(_rand_dtype, randn, scale=scale)\n\n\ndef rand_nonzero():\n  post = lambda x: onp.where(x == 0, onp.array(1, dtype=x.dtype), x)\n  randn = npr.RandomState(0).randn\n  return partial(_rand_dtype, randn, scale=3, post=post)\n\n\ndef rand_positive():\n  post = lambda x: x + 1\n  rand = npr.RandomState(0).rand\n  return partial(_rand_dtype, rand, scale=2, post=post)\n\n\ndef rand_small():\n  randn = npr.RandomState(0).randn\n  return partial(_rand_dtype, randn, scale=1e-3)\n\n\ndef rand_not_small(offset=10.):\n  post = lambda x: x + onp.where(x > 0, offset, -offset)\n  randn = npr.RandomState(0).randn\n  return partial(_rand_dtype, randn, scale=3., post=post)\n\n\ndef rand_small_positive():\n  rand = npr.RandomState(0).rand\n  return partial(_rand_dtype, rand, scale=2e-5)\n\ndef rand_uniform(low=0.0, high=1.0):\n  assert low < high\n  rand = npr.RandomState(0).rand\n  post = lambda x: x * (high - low) + low\n  return partial(_rand_dtype, rand, post=post)\n\n\ndef rand_some_equal():\n  randn = npr.RandomState(0).randn\n  rng = npr.RandomState(0)\n\n  def post(x):\n    x_ravel = x.ravel()\n    if len(x_ravel) == 0:\n      return x\n    flips = rng.rand(*onp.shape(x)) < 0.5\n    return onp.where(flips, x_ravel[0], x)\n\n  return partial(_rand_dtype, randn, scale=100., post=post)\n\n\ndef rand_some_inf():\n  """"""Return a random sampler that produces infinities in floating types.""""""\n  rng = npr.RandomState(1)\n  base_rand = rand_default()\n\n  """"""\n  TODO: Complex numbers are not correctly tested\n  If blocks should be switched in order, and relevant tests should be fixed\n  """"""\n  def rand(shape, dtype):\n    """"""The random sampler function.""""""\n    if not onp.issubdtype(dtype, onp.floating):\n      # only float types have inf\n      return base_rand(shape, dtype)\n\n    if onp.issubdtype(dtype, onp.complexfloating):\n      base_dtype = onp.real(onp.array(0, dtype=dtype)).dtype\n      out = (rand(shape, base_dtype) +\n             onp.array(1j, dtype) * rand(shape, base_dtype))\n      return _cast_to_shape(out, shape, dtype)\n\n    dims = _dims_of_shape(shape)\n    posinf_flips = rng.rand(*dims) < 0.1\n    neginf_flips = rng.rand(*dims) < 0.1\n\n    vals = base_rand(shape, dtype)\n    vals = onp.where(posinf_flips, onp.array(onp.inf, dtype=dtype), vals)\n    vals = onp.where(neginf_flips, onp.array(-onp.inf, dtype=dtype), vals)\n\n    return _cast_to_shape(onp.asarray(vals, dtype=dtype), shape, dtype)\n\n  return rand\n\ndef rand_some_nan():\n  """"""Return a random sampler that produces nans in floating types.""""""\n  rng = npr.RandomState(1)\n  base_rand = rand_default()\n\n  def rand(shape, dtype):\n    """"""The random sampler function.""""""\n    if onp.issubdtype(dtype, onp.complexfloating):\n      base_dtype = onp.real(onp.array(0, dtype=dtype)).dtype\n      out = (rand(shape, base_dtype) +\n             onp.array(1j, dtype) * rand(shape, base_dtype))\n      return _cast_to_shape(out, shape, dtype)\n\n    if not onp.issubdtype(dtype, onp.floating):\n      # only float types have inf\n      return base_rand(shape, dtype)\n\n    dims = _dims_of_shape(shape)\n    nan_flips = rng.rand(*dims) < 0.1\n\n    vals = base_rand(shape, dtype)\n    vals = onp.where(nan_flips, onp.array(onp.nan, dtype=dtype), vals)\n\n    return _cast_to_shape(onp.asarray(vals, dtype=dtype), shape, dtype)\n\n  return rand\n\ndef rand_some_inf_and_nan():\n  """"""Return a random sampler that produces infinities in floating types.""""""\n  rng = npr.RandomState(1)\n  base_rand = rand_default()\n\n  """"""\n  TODO: Complex numbers are not correctly tested\n  If blocks should be switched in order, and relevant tests should be fixed\n  """"""\n  def rand(shape, dtype):\n    """"""The random sampler function.""""""\n    if not onp.issubdtype(dtype, onp.floating):\n      # only float types have inf\n      return base_rand(shape, dtype)\n\n    if onp.issubdtype(dtype, onp.complexfloating):\n      base_dtype = onp.real(onp.array(0, dtype=dtype)).dtype\n      out = (rand(shape, base_dtype) +\n             onp.array(1j, dtype) * rand(shape, base_dtype))\n      return _cast_to_shape(out, shape, dtype)\n\n    dims = _dims_of_shape(shape)\n    posinf_flips = rng.rand(*dims) < 0.1\n    neginf_flips = rng.rand(*dims) < 0.1\n    nan_flips = rng.rand(*dims) < 0.1\n\n    vals = base_rand(shape, dtype)\n    vals = onp.where(posinf_flips, onp.array(onp.inf, dtype=dtype), vals)\n    vals = onp.where(neginf_flips, onp.array(-onp.inf, dtype=dtype), vals)\n    vals = onp.where(nan_flips, onp.array(onp.nan, dtype=dtype), vals)\n\n    return _cast_to_shape(onp.asarray(vals, dtype=dtype), shape, dtype)\n\n  return rand\n\n# TODO(mattjj): doesn\'t handle complex types\ndef rand_some_zero():\n  """"""Return a random sampler that produces some zeros.""""""\n  rng = npr.RandomState(1)\n  base_rand = rand_default()\n\n  def rand(shape, dtype):\n    """"""The random sampler function.""""""\n    dims = _dims_of_shape(shape)\n    zeros = rng.rand(*dims) < 0.5\n\n    vals = base_rand(shape, dtype)\n    vals = onp.where(zeros, onp.array(0, dtype=dtype), vals)\n\n    return _cast_to_shape(onp.asarray(vals, dtype=dtype), shape, dtype)\n\n  return rand\n\n\ndef rand_int(low, high=None):\n  randint = npr.RandomState(0).randint\n  def fn(shape, dtype):\n    return randint(low, high=high, size=shape, dtype=dtype)\n  return fn\n\ndef rand_unique_int():\n  randchoice = npr.RandomState(0).choice\n  def fn(shape, dtype):\n    return randchoice(onp.arange(onp.prod(shape), dtype=dtype),\n                      size=shape, replace=False)\n  return fn\n\ndef rand_bool():\n  rng = npr.RandomState(0)\n  def generator(shape, dtype):\n    return _cast_to_shape(rng.rand(*_dims_of_shape(shape)) < 0.5, shape, dtype)\n  return generator\n\ndef check_raises(thunk, err_type, msg):\n  try:\n    thunk()\n    assert False\n  except err_type as e:\n    assert str(e).startswith(msg), ""\\n{}\\n\\n{}\\n"".format(e, msg)\n\ndef check_raises_regexp(thunk, err_type, pattern):\n  try:\n    thunk()\n    assert False\n  except err_type as e:\n    assert re.match(pattern, str(e)), ""{}\\n\\n{}\\n"".format(e, pattern)\n\n\ndef _iter_eqns(jaxpr):\n  # TODO(necula): why doesn\'t this search in params?\n  for eqn in jaxpr.eqns:\n    yield eqn\n  for subjaxpr in core.subjaxprs(jaxpr):\n    yield from _iter_eqns(subjaxpr)\n\ndef assert_dot_precision(expected_precision, fun, *args):\n  jaxpr = api.make_jaxpr(fun)(*args)\n  precisions = [eqn.params[\'precision\'] for eqn in _iter_eqns(jaxpr.jaxpr)\n                if eqn.primitive == lax.dot_general_p]\n  for precision in precisions:\n    msg = ""Unexpected precision: {} != {}"".format(expected_precision, precision)\n    assert precision == expected_precision, msg\n\n\n_CACHED_INDICES: Dict[int, Sequence[int]] = {}\n\ndef cases_from_list(xs):\n  xs = list(xs)\n  n = len(xs)\n  k = min(n, FLAGS.num_generated_cases)\n  # Random sampling for every parameterized test is expensive. Do it once and\n  # cache the result.\n  indices = _CACHED_INDICES.get(n)\n  if indices is None:\n    rng = npr.RandomState(42)\n    _CACHED_INDICES[n] = indices = rng.permutation(n)\n  return [xs[i] for i in indices[:k]]\n\ndef cases_from_gens(*gens):\n  sizes = [1, 3, 10]\n  cases_per_size = int(FLAGS.num_generated_cases / len(sizes)) + 1\n  for size in sizes:\n    for i in range(cases_per_size):\n      yield (\'_{}_{}\'.format(size, i),) + tuple(gen(size) for gen in gens)\n\n\nclass TestCase(parameterized.TestCase):\n  """"""Base class for tests including numerical checks and boilerplate.""""""\n\n  # TODO(mattjj): this obscures the error messages from failures, figure out how\n  # to re-enable it\n  # def tearDown(self) -> None:\n  #   assert core.reset_trace_state()\n\n  def assertArraysAllClose(self, x, y, check_dtypes, atol=None, rtol=None):\n    """"""Assert that x and y are close (up to numerical tolerances).""""""\n    self.assertEqual(x.shape, y.shape)\n    atol = max(tolerance(_dtype(x), atol), tolerance(_dtype(y), atol))\n    rtol = max(tolerance(_dtype(x), rtol), tolerance(_dtype(y), rtol))\n\n    _assert_numpy_allclose(x, y, atol=atol, rtol=rtol)\n\n    if check_dtypes:\n      self.assertDtypesMatch(x, y)\n\n  def assertDtypesMatch(self, x, y):\n    if FLAGS.enable_x64:\n      self.assertEqual(_dtype(x), _dtype(y))\n\n  def assertAllClose(self, x, y, check_dtypes, atol=None, rtol=None):\n    """"""Assert that x and y, either arrays or nested tuples/lists, are close.""""""\n    if isinstance(x, dict):\n      self.assertIsInstance(y, dict)\n      self.assertEqual(set(x.keys()), set(y.keys()))\n      for k in x.keys():\n        self.assertAllClose(x[k], y[k], check_dtypes, atol=atol, rtol=rtol)\n    elif is_sequence(x) and not hasattr(x, \'__array__\'):\n      self.assertTrue(is_sequence(y) and not hasattr(y, \'__array__\'))\n      self.assertEqual(len(x), len(y))\n      for x_elt, y_elt in zip(x, y):\n        self.assertAllClose(x_elt, y_elt, check_dtypes, atol=atol, rtol=rtol)\n    elif hasattr(x, \'__array__\') or onp.isscalar(x):\n      self.assertTrue(hasattr(y, \'__array__\') or onp.isscalar(y))\n      if check_dtypes:\n        self.assertDtypesMatch(x, y)\n      x = onp.asarray(x)\n      y = onp.asarray(y)\n      self.assertArraysAllClose(x, y, check_dtypes=False, atol=atol, rtol=rtol)\n    elif x == y:\n      return\n    else:\n      raise TypeError((type(x), type(y)))\n\n  def assertMultiLineStrippedEqual(self, expected, what):\n    """"""Asserts two strings are equal, after stripping each line.""""""\n    ignore_space_re = re.compile(r\'\\s*\\n\\s*\')\n    expected_clean = re.sub(ignore_space_re, \'\\n\', expected.strip())\n    what_clean = re.sub(ignore_space_re, \'\\n\', what.strip())\n    self.assertMultiLineEqual(expected_clean, what_clean,\n                              msg=""Found\\n{}\\nExpecting\\n{}"".format(what, expected))\n\n  def _CheckAgainstNumpy(self, numpy_reference_op, lax_op, args_maker,\n                         check_dtypes=False, tol=None):\n    args = args_maker()\n    lax_ans = lax_op(*args)\n    numpy_ans = numpy_reference_op(*args)\n    self.assertAllClose(numpy_ans, lax_ans, check_dtypes=check_dtypes,\n                        atol=tol, rtol=tol)\n\n  # TODO(wangpeng): Make check_incomplete_shape default to True.\n  def _CompileAndCheck(self,\n                       fun,\n                       args_maker,\n                       check_dtypes,\n                       rtol=None,\n                       atol=None,\n                       check_eval_on_shapes=True,\n                       check_incomplete_shape=False,\n                       check_unknown_rank=True,\n                       static_argnums=()):\n    """"""Compiles the function and checks the results.\n\n    Args:\n      fun: the function to be checked.\n      args_maker: a callable that returns a tuple which will be used as the\n        positional arguments.\n      check_dtypes: whether to check that the result dtypes from non-compiled\n        and compiled runs agree.\n      rtol: relative tolerance for allclose assertions.\n      atol: absolute tolerance for allclose assertions.\n      check_eval_on_shapes: whether to run `eval_on_shapes` on the function and\n        check that the result shapes and dtypes are correct.\n      check_incomplete_shape: whether to check that the function can handle\n        incomplete shapes (including those with and without a known rank).\n      check_unknown_rank: (only has effect when check_incomplete_shape is True)\n        whether to check that the function can handle unknown ranks.\n      static_argnums: indices of arguments to be treated as static arguments for\n        `jit` and `eval_on_shapes`.\n    """"""\n    args = args_maker()\n\n    for x in args:\n      if not hasattr(x, \'dtype\'):\n        # If there is a input that doesn\'t have dtype info, jit and\n        # eval_on_shapes may pick a different dtype for it than numpy, so we\n        # skip the dtype check.\n        check_dtypes = False\n\n    # `wrapped_fun` and `python_should_be_executing` are used to check that when\n    # the jitted function is called the second time, the original Python\n    # function won\'t be executed.\n    def wrapped_fun(*args):\n      self.assertTrue(python_should_be_executing)\n      return fun(*args)\n\n    python_ans = fun(*args)\n\n    python_shapes = tf.nest.map_structure(lambda x: onp.shape(x), python_ans)\n    onp_shapes = tf.nest.map_structure(lambda x: onp.shape(onp.asarray(x)),\n                                       python_ans)\n    self.assertEqual(python_shapes, onp_shapes)\n\n    cfun = npe.jit(wrapped_fun, static_argnums=static_argnums)\n    python_should_be_executing = True\n    monitored_ans = cfun(*args)\n\n    python_should_be_executing = False\n    compiled_ans = cfun(*args)\n\n    self.assertAllClose(python_ans, monitored_ans, check_dtypes, atol, rtol)\n    self.assertAllClose(python_ans, compiled_ans, check_dtypes, atol, rtol)\n\n    # Run `cfun` with a different set of arguments to check that changing\n    # arguments won\'t cause recompilation.\n\n    new_args = args_maker()\n\n    skip_retracing_test = False\n    for old, new in zip(args, new_args):\n      if npe.most_precise_int_dtype(old) != npe.most_precise_int_dtype(new):\n        # If the old and new arguments result in different dtypes (because they\n        # fall into different value ranges), tf-numpy will retrace, so we skip\n        # the no-retrace test.\n        skip_retracing_test = True\n\n    if not skip_retracing_test:\n      python_should_be_executing = True\n      new_python_ans = fun(*new_args)\n      python_should_be_executing = False\n      compiled_ans = cfun(*new_args)\n      self.assertAllClose(new_python_ans, compiled_ans, check_dtypes, atol,\n                          rtol)\n\n    if check_eval_on_shapes:\n      # Check that npe.eval_on_shapes can get complete output shapes given\n      # complete input shapes.\n      cfun = npe.eval_on_shapes(fun, static_argnums=static_argnums)\n      compiled_ans = cfun(*args)\n      flat_python_ans = tf.nest.flatten(python_ans)\n      flat_compiled_ans = tf.nest.flatten(compiled_ans)\n      self.assertEqual(len(flat_python_ans), len(flat_compiled_ans))\n      for a, b in zip(flat_python_ans, flat_compiled_ans):\n        if hasattr(a, \'shape\'):\n          self.assertEqual(a.shape, b.shape)\n        if check_dtypes and hasattr(a, \'dtype\'):\n          self.assertEqual(tf.as_dtype(a.dtype), b.dtype)\n\n    # If some argument doesn\'t have a `dtype` attr (e.g. a Python scalar), we\n    # skip incomplete-shape checks, since shape specs need dtype. It\'s OK to\n    # skip since the same incomplete-shape checks will run for []-shaped arrays.\n    if check_incomplete_shape and all(hasattr(x, \'dtype\') for x in args):\n      # Check partial shapes with known ranks.\n      # Numpy scalars (created by e.g. np.int32(5)) have `dtype` but not\n      # `shape`.\n      if all(hasattr(x, \'shape\') for x in args):\n        specs = [tf.TensorSpec([None] * len(x.shape), x.dtype) for x in args]\n        cfun = npe.jit(\n            fun, static_argnums=static_argnums, input_signature=specs)\n        compiled_ans = cfun(*args)\n        self.assertAllClose(python_ans, compiled_ans, check_dtypes, atol, rtol)\n\n      if check_unknown_rank:\n        # Check unknown ranks.\n        specs = [tf.TensorSpec(None, x.dtype) for x in args]\n        cfun = npe.jit(\n            fun, static_argnums=static_argnums, input_signature=specs)\n        compiled_ans = cfun(*args)\n        self.assertAllClose(python_ans, compiled_ans, check_dtypes, atol, rtol)\n\n\n@contextmanager\ndef ignore_warning(**kw):\n  with warnings.catch_warnings():\n    warnings.filterwarnings(""ignore"", **kw)\n    yield\n\n\ndef disable(_):\n\n  def wrapper(self, *args, **kwargs):\n    self.skipTest(\'Test is disabled\')\n\n  return wrapper\n'"
trax/tf_numpy/numpy/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""NumPy like wrapper for Tensorflow.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# pylint: disable=wildcard-import\n# pylint: disable=g-import-not-at-top\n\ntry:\n  # pylint: disable=g-direct-tensorflow-import\n  from tensorflow.python.ops.numpy_ops import *\nexcept Exception:  # pylint: disable=broad-except\n  from tensorflow import newaxis\n\n  from trax.tf_numpy.numpy_impl import random\n\n  # pylint: disable=wildcard-import\n  from trax.tf_numpy.numpy_impl.array_ops import *\n  from trax.tf_numpy.numpy_impl.arrays import *\n  from trax.tf_numpy.numpy_impl.dtypes import *\n  from trax.tf_numpy.numpy_impl.math_ops import *\n  from trax.tf_numpy.numpy_impl.utils import finfo\n  from trax.tf_numpy.numpy_impl.utils import promote_types\n  from trax.tf_numpy.numpy_impl.utils import result_type\n  # pylint: enable=wildcard-import\n\n  max = amax  # pylint: disable=redefined-builtin,undefined-variable\n  min = amin  # pylint: disable=redefined-builtin,undefined-variable\n  round = around  # pylint: disable=redefined-builtin,undefined-variable\n'"
trax/tf_numpy/numpy_impl/__init__.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""NumPy API. Deprecated.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'"
trax/tf_numpy/numpy_impl/array_ops.py,79,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Common array methods.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport functools\nimport math\nimport numpy as np\nimport six\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.numpy_impl import arrays as arrays_lib\nfrom trax.tf_numpy.numpy_impl import dtypes\nfrom trax.tf_numpy.numpy_impl import utils\n\n\ndef empty(shape, dtype=float):  # pylint: disable=redefined-outer-name\n  """"""Returns an empty array with the specified shape and dtype.\n\n  Args:\n    shape: A fully defined shape. Could be - NumPy array or a python scalar,\n      list or tuple of integers, - TensorFlow tensor/ndarray of integer type and\n      rank <=1.\n    dtype: Optional, defaults to float. The type of the resulting ndarray. Could\n      be a python type, a NumPy type or a TensorFlow `DType`.\n\n  Returns:\n    An ndarray.\n  """"""\n  return zeros(shape, dtype)\n\n\ndef empty_like(a, dtype=None):\n  """"""Returns an empty array with the shape and possibly type of the input array.\n\n  Args:\n    a: array_like. Could be an ndarray, a Tensor or any object that can be\n      converted to a Tensor using `tf.convert_to_tensor`.\n    dtype: Optional, defaults to dtype of the input array. The type of the\n      resulting ndarray. Could be a python type, a NumPy type or a TensorFlow\n      `DType`.\n\n  Returns:\n    An ndarray.\n  """"""\n  return zeros_like(a, dtype)\n\n\ndef zeros(shape, dtype=float):  # pylint: disable=redefined-outer-name\n  """"""Returns an ndarray with the given shape and type filled with zeros.\n\n  Args:\n    shape: A fully defined shape. Could be - NumPy array or a python scalar,\n      list or tuple of integers, - TensorFlow tensor/ndarray of integer type and\n      rank <=1.\n    dtype: Optional, defaults to float. The type of the resulting ndarray. Could\n      be a python type, a NumPy type or a TensorFlow `DType`.\n\n  Returns:\n    An ndarray.\n  """"""\n  if dtype:\n    dtype = utils.result_type(dtype)\n  if isinstance(shape, arrays_lib.ndarray):\n    shape = shape.data\n  return arrays_lib.tensor_to_ndarray(tf.zeros(shape, dtype=dtype))\n\n\ndef zeros_like(a, dtype=None):\n  """"""Returns an array of zeros with the shape and type of the input array.\n\n  Args:\n    a: array_like. Could be an ndarray, a Tensor or any object that can be\n      converted to a Tensor using `tf.convert_to_tensor`.\n    dtype: Optional, defaults to dtype of the input array. The type of the\n      resulting ndarray. Could be a python type, a NumPy type or a TensorFlow\n      `DType`.\n\n  Returns:\n    An ndarray.\n  """"""\n  if isinstance(a, arrays_lib.ndarray):\n    a = a.data\n  if dtype is None:\n    # We need to let utils.result_type decide the dtype, not tf.zeros_like\n    dtype = utils.result_type(a)\n  else:\n    # TF and numpy has different interpretations of Python types such as\n    # `float`, so we let `utils.result_type` decide.\n    dtype = utils.result_type(dtype)\n  dtype = tf.as_dtype(dtype)  # Work around b/149877262\n  return arrays_lib.tensor_to_ndarray(tf.zeros_like(a, dtype))\n\n\ndef ones(shape, dtype=float):  # pylint: disable=redefined-outer-name\n  """"""Returns an ndarray with the given shape and type filled with ones.\n\n  Args:\n    shape: A fully defined shape. Could be - NumPy array or a python scalar,\n      list or tuple of integers, - TensorFlow tensor/ndarray of integer type and\n      rank <=1.\n    dtype: Optional, defaults to float. The type of the resulting ndarray. Could\n      be a python type, a NumPy type or a TensorFlow `DType`.\n\n  Returns:\n    An ndarray.\n  """"""\n  if dtype:\n    dtype = utils.result_type(dtype)\n  if isinstance(shape, arrays_lib.ndarray):\n    shape = shape.data\n  return arrays_lib.tensor_to_ndarray(tf.ones(shape, dtype=dtype))\n\n\ndef ones_like(a, dtype=None):\n  """"""Returns an array of ones with the shape and type of the input array.\n\n  Args:\n    a: array_like. Could be an ndarray, a Tensor or any object that can be\n      converted to a Tensor using `tf.convert_to_tensor`.\n    dtype: Optional, defaults to dtype of the input array. The type of the\n      resulting ndarray. Could be a python type, a NumPy type or a TensorFlow\n      `DType`.\n\n  Returns:\n    An ndarray.\n  """"""\n  if isinstance(a, arrays_lib.ndarray):\n    a = a.data\n  if dtype is None:\n    dtype = utils.result_type(a)\n  else:\n    dtype = utils.result_type(dtype)\n  return arrays_lib.tensor_to_ndarray(tf.ones_like(a, dtype))\n\n\n@utils.np_doc(np.eye)\ndef eye(N, M=None, k=0, dtype=float):  # pylint: disable=invalid-name,missing-docstring\n  if dtype:\n    dtype = utils.result_type(dtype)\n  if not M:\n    M = N\n  # Making sure N, M and k are `int`\n  N = int(N)\n  M = int(M)\n  k = int(k)\n  if k >= M or -k >= N:\n    # tf.linalg.diag will raise an error in this case\n    return zeros([N, M], dtype=dtype)\n  if k == 0:\n    return arrays_lib.tensor_to_ndarray(tf.eye(N, M, dtype=dtype))\n  # We need the precise length, otherwise tf.linalg.diag will raise an error\n  diag_len = min(N, M)\n  if k > 0:\n    if N >= M:\n      diag_len -= k\n    elif N + k > M:\n      diag_len = M - k\n  elif k <= 0:\n    if M >= N:\n      diag_len += k\n    elif M - k > N:\n      diag_len = N + k\n  diagonal_ = tf.ones([diag_len], dtype=dtype)\n  return arrays_lib.tensor_to_ndarray(\n      tf.linalg.diag(diagonal=diagonal_, num_rows=N, num_cols=M, k=k))\n\n\ndef identity(n, dtype=float):\n  """"""Returns a square array with ones on the main diagonal and zeros elsewhere.\n\n  Args:\n    n: number of rows/cols.\n    dtype: Optional, defaults to float. The type of the resulting ndarray. Could\n      be a python type, a NumPy type or a TensorFlow `DType`.\n\n  Returns:\n    An ndarray of shape (n, n) and requested type.\n  """"""\n  return eye(N=n, M=n, dtype=dtype)\n\n\ndef full(shape, fill_value, dtype=None):  # pylint: disable=redefined-outer-name\n  """"""Returns an array with given shape and dtype filled with `fill_value`.\n\n  Args:\n    shape: A valid shape object. Could be a native python object or an object\n       of type ndarray, numpy.ndarray or tf.TensorShape.\n    fill_value: array_like. Could be an ndarray, a Tensor or any object that can\n      be converted to a Tensor using `tf.convert_to_tensor`.\n    dtype: Optional, defaults to dtype of the `fill_value`. The type of the\n      resulting ndarray. Could be a python type, a NumPy type or a TensorFlow\n      `DType`.\n\n  Returns:\n    An ndarray.\n\n  Raises:\n    ValueError: if `fill_value` can not be broadcast to shape `shape`.\n  """"""\n  fill_value = asarray(fill_value, dtype=dtype)\n  if utils.isscalar(shape):\n    shape = tf.reshape(shape, [1])\n  return arrays_lib.tensor_to_ndarray(tf.broadcast_to(fill_value.data, shape))\n\n\n# Using doc only here since np full_like signature doesn\'t seem to have the\n# shape argument (even though it exists in the documentation online).\n@utils.np_doc_only(np.full_like)\ndef full_like(a, fill_value, dtype=None, order=\'K\', subok=True, shape=None):  # pylint: disable=missing-docstring,redefined-outer-name\n  """"""order, subok and shape arguments mustn\'t be changed.""""""\n  if order != \'K\':\n    raise ValueError(\'Non-standard orders are not supported.\')\n  if not subok:\n    raise ValueError(\'subok being False is not supported.\')\n  if shape:\n    raise ValueError(\'Overriding the shape is not supported.\')\n\n  a = asarray(a).data\n  dtype = dtype or utils.result_type(a)\n  fill_value = asarray(fill_value, dtype=dtype)\n  return arrays_lib.tensor_to_ndarray(\n      tf.broadcast_to(fill_value.data, tf.shape(a)))\n\n\n# TODO(wangpeng): investigate whether we can make `copy` default to False.\n# TODO(wangpeng): utils.np_doc can\'t handle np.array because np.array is a\n#   builtin function. Make utils.np_doc support builtin functions.\ndef array(val, dtype=None, copy=True, ndmin=0):  # pylint: disable=redefined-outer-name\n  """"""Creates an ndarray with the contents of val.\n\n  Args:\n    val: array_like. Could be an ndarray, a Tensor or any object that can be\n      converted to a Tensor using `tf.convert_to_tensor`.\n    dtype: Optional, defaults to dtype of the `val`. The type of the resulting\n      ndarray. Could be a python type, a NumPy type or a TensorFlow `DType`.\n    copy: Determines whether to create a copy of the backing buffer. Since\n      Tensors are immutable, a copy is made only if val is placed on a different\n      device than the current one. Even if `copy` is False, a new Tensor may\n      need to be built to satisfy `dtype` and `ndim`. This is used only if `val`\n      is an ndarray or a Tensor.\n    ndmin: The minimum rank of the returned array.\n\n  Returns:\n    An ndarray.\n  """"""\n  if dtype:\n    dtype = utils.result_type(dtype)\n  if isinstance(val, arrays_lib.ndarray):\n    result_t = val.data\n  else:\n    result_t = val\n\n  if copy and isinstance(result_t, tf.Tensor):\n    # Note: In eager mode, a copy of `result_t` is made only if it is not on\n    # the context device.\n    result_t = tf.identity(result_t)\n\n  if not isinstance(result_t, tf.Tensor):\n    if not dtype:\n      dtype = utils.result_type(result_t)\n    # We can\'t call `convert_to_tensor(result_t, dtype=dtype)` here because\n    # convert_to_tensor doesn\'t allow incompatible arguments such as (5.5, int)\n    # while np.array allows them. We need to convert-then-cast.\n    def maybe_data(x):\n      if isinstance(x, arrays_lib.ndarray):\n        return x.data\n      return x\n\n    # Handles lists of ndarrays\n    result_t = tf.nest.map_structure(maybe_data, result_t)\n    result_t = arrays_lib.convert_to_tensor(result_t)\n    result_t = tf.cast(result_t, dtype=dtype)\n  elif dtype:\n    result_t = tf.cast(result_t, dtype)\n  ndims = tf.rank(result_t)\n\n  def true_fn():\n    old_shape = tf.shape(result_t)\n    new_shape = tf.concat([tf.ones(ndmin - ndims, tf.int32), old_shape], axis=0)\n    return tf.reshape(result_t, new_shape)\n\n  result_t = utils.cond(utils.greater(ndmin, ndims), true_fn, lambda: result_t)\n  return arrays_lib.tensor_to_ndarray(result_t)\n\n\n@utils.np_doc(np.asarray)\ndef asarray(a, dtype=None):\n  if dtype:\n    dtype = utils.result_type(dtype)\n  if isinstance(a, arrays_lib.ndarray) and (not dtype or dtype == a.dtype):\n    return a\n  return array(a, dtype, copy=False)\n\n\n@utils.np_doc(np.asanyarray)\ndef asanyarray(a, dtype=None):\n  return asarray(a, dtype)\n\n\n@utils.np_doc(np.ascontiguousarray)\ndef ascontiguousarray(a, dtype=None):\n  return array(a, dtype, ndmin=1)\n\n\n# Numerical ranges.\ndef arange(start, stop=None, step=1, dtype=None):\n  """"""Returns `step`-separated values in the range [start, stop).\n\n  Args:\n    start: Start of the interval. Included in the range.\n    stop: End of the interval. If not specified, `start` is treated as 0 and\n      `start` value is used as `stop`. If specified, it is not included in the\n      range if `step` is integer. When `step` is floating point, it may or may\n      not be included.\n    step: The difference between 2 consecutive values in the output range. It is\n      recommended to use `linspace` instead of using non-integer values for\n      `step`.\n    dtype: Optional. Type of the resulting ndarray. Could be a python type, a\n      NumPy type or a TensorFlow `DType`. If not provided, the largest type of\n      `start`, `stop`, `step` is used.\n\n  Raises:\n    ValueError: If step is zero.\n  """"""\n  if not step:\n    raise ValueError(\'step must be non-zero.\')\n  if dtype:\n    dtype = utils.result_type(dtype)\n  else:\n    if stop is None:\n      dtype = utils.result_type(start, step)\n    else:\n      dtype = utils.result_type(start, step, stop)\n  if step > 0 and ((stop is not None and start > stop) or\n                   (stop is None and start < 0)):\n    return array([], dtype=dtype)\n  if step < 0 and ((stop is not None and start < stop) or\n                   (stop is None and start > 0)):\n    return array([], dtype=dtype)\n  # TODO(srbs): There are some bugs when start or stop is float type and dtype\n  # is integer type.\n  return arrays_lib.tensor_to_ndarray(\n      tf.cast(tf.range(start, limit=stop, delta=step), dtype=dtype))\n\n\n@utils.np_doc(np.geomspace)\ndef geomspace(start, stop, num=50, endpoint=True, dtype=float):  # pylint: disable=missing-docstring\n  if dtype:\n    dtype = utils.result_type(dtype)\n  if num < 0:\n    raise ValueError(\'Number of samples {} must be non-negative.\'.format(num))\n  if not num:\n    return empty([0])\n  step = 1.\n  if endpoint:\n    if num > 1:\n      step = tf.pow((stop / start), 1 / (num - 1))\n  else:\n    step = tf.pow((stop / start), 1 / num)\n  result = tf.cast(tf.range(num), step.dtype)\n  result = tf.pow(step, result)\n  result = tf.multiply(result, start)\n  if dtype:\n    result = tf.cast(result, dtype=dtype)\n  return arrays_lib.tensor_to_ndarray(result)\n\n\n# Building matrices.\n@utils.np_doc(np.diag)\ndef diag(v, k=0):  # pylint: disable=missing-docstring\n  """"""Raises an error if input is not 1- or 2-d.""""""\n  v = asarray(v).data\n  v_rank = tf.rank(v)\n\n  v.shape.with_rank_at_most(2)\n\n  # TODO(nareshmodi): Consider a utils.Assert version that will fail during\n  # tracing time if the shape is known.\n  tf.debugging.Assert(\n      utils.logical_or(tf.equal(v_rank, 1), tf.equal(v_rank, 2)), [v_rank])\n\n  def _diag(v, k):\n    return utils.cond(\n        tf.equal(tf.size(v), 0),\n        lambda: tf.zeros([abs(k), abs(k)], dtype=v.dtype),\n        lambda: tf.linalg.diag(v, k=k))\n\n  def _diag_part(v, k):\n    v_shape = tf.shape(v)\n    v, k = utils.cond(\n        utils.logical_or(\n            utils.less_equal(k, -1 * utils.getitem(v_shape, 0)),\n            utils.greater_equal(k, utils.getitem(v_shape, 1)),\n        ), lambda: (tf.zeros([0, 0], dtype=v.dtype), 0), lambda: (v, k))\n    result = tf.linalg.diag_part(v, k=k)\n    return result\n\n  result = utils.cond(\n      tf.equal(v_rank, 1), lambda: _diag(v, k), lambda: _diag_part(v, k))\n  return utils.tensor_to_ndarray(result)\n\n\n@utils.np_doc(np.diagonal)\ndef diagonal(a, offset=0, axis1=0, axis2=1):  # pylint: disable=missing-docstring\n  a = asarray(a).data\n\n  maybe_rank = a.shape.rank\n  if maybe_rank is not None and offset == 0 and (\n      axis1 == maybe_rank - 2 or axis1 == -2) and (axis2 == maybe_rank - 1 or\n                                                   axis2 == -1):\n    return utils.tensor_to_ndarray(tf.linalg.diag_part(a))\n\n  a = moveaxis(utils.tensor_to_ndarray(a), (axis1, axis2), (-2, -1)).data\n\n  a_shape = tf.shape(a)\n\n  def _zeros():  # pylint: disable=missing-docstring\n    return (tf.zeros(tf.concat([a_shape[:-1], [0]], 0), dtype=a.dtype), 0)\n\n  # All zeros since diag_part doesn\'t handle all possible k (aka offset).\n  # Written this way since cond will run shape inference on both branches,\n  # and diag_part shape inference will fail when offset is out of bounds.\n  a, offset = utils.cond(\n      utils.logical_or(\n          utils.less_equal(offset, -1 * utils.getitem(a_shape, -2)),\n          utils.greater_equal(offset, utils.getitem(a_shape, -1)),\n      ), _zeros, lambda: (a, offset))\n\n  a = utils.tensor_to_ndarray(tf.linalg.diag_part(a, k=offset))\n  return a\n\n\ndef diagflat(v, k=0):\n  """"""Returns a 2-d array with flattened `v` as diagonal.\n\n  Args:\n    v: array_like of any rank. Gets flattened when setting as diagonal. Could be\n      an ndarray, a Tensor or any object that can be converted to a Tensor using\n      `tf.convert_to_tensor`.\n    k: Position of the diagonal. Defaults to 0, the main diagonal. Positive\n      values refer to diagonals shifted right, negative values refer to\n      diagonals shifted left.\n\n  Returns:\n    2-d ndarray.\n  """"""\n  v = asarray(v)\n  return diag(tf.reshape(v.data, [-1]), k)\n\n\ndef _promote_dtype(*arrays):\n  dtype = utils.result_type(*arrays)\n  return [asarray(a, dtype=dtype) for a in arrays]\n\n\ndef all(a, axis=None, keepdims=None):  # pylint: disable=redefined-builtin\n  """"""Whether all array elements or those along an axis evaluate to true.\n\n  Casts the array to bool type if it is not already and uses `tf.reduce_all` to\n  compute the result.\n\n  Args:\n    a: array_like. Could be an ndarray, a Tensor or any object that can\n      be converted to a Tensor using `tf.convert_to_tensor`.\n    axis: Optional. Could be an int or a tuple of integers. If not specified,\n      the reduction is performed over all array indices.\n    keepdims: If true, retains reduced dimensions with length 1.\n\n  Returns:\n    An ndarray. Note that unlike NumPy this does not return a scalar bool if\n    `axis` is None.\n  """"""\n  a = asarray(a, dtype=bool)\n  return utils.tensor_to_ndarray(\n      tf.reduce_all(input_tensor=a.data, axis=axis, keepdims=keepdims))\n\n\ndef any(a, axis=None, keepdims=None):  # pylint: disable=redefined-builtin\n  """"""Whether any element in the entire array or in an axis evaluates to true.\n\n  Casts the array to bool type if it is not already and uses `tf.reduce_any` to\n  compute the result.\n\n  Args:\n    a: array_like. Could be an ndarray, a Tensor or any object that can\n      be converted to a Tensor using `tf.convert_to_tensor`.\n    axis: Optional. Could be an int or a tuple of integers. If not specified,\n      the reduction is performed over all array indices.\n    keepdims: If true, retains reduced dimensions with length 1.\n\n  Returns:\n    An ndarray. Note that unlike NumPy this does not return a scalar bool if\n    `axis` is None.\n  """"""\n  a = asarray(a, dtype=bool)\n  return utils.tensor_to_ndarray(\n      tf.reduce_any(input_tensor=a.data, axis=axis, keepdims=keepdims))\n\n\ndef compress(condition, a, axis=None):\n  """"""Compresses `a` by selecting values along `axis` with `condition` true.\n\n  Uses `tf.boolean_mask`.\n\n  Args:\n    condition: 1-d array of bools. If `condition` is shorter than the array\n      axis (or the flattened array if axis is None), it is padded with False.\n    a: array_like. Could be an ndarray, a Tensor or any object that can\n      be converted to a Tensor using `tf.convert_to_tensor`.\n    axis: Optional. Axis along which to select elements. If None, `condition` is\n      applied on flattened array.\n\n  Returns:\n    An ndarray.\n\n  Raises:\n    ValueError: if `condition` is not of rank 1.\n  """"""\n  condition = asarray(condition, dtype=bool)\n  a = asarray(a)\n\n  if condition.ndim != 1:\n    raise ValueError(\'condition must be a 1-d array.\')\n  # `np.compress` treats scalars as 1-d arrays.\n  if a.ndim == 0:\n    a = ravel(a)\n\n  if axis is None:\n    a = ravel(a)\n    axis = 0\n\n  if axis < 0:\n    axis += a.ndim\n\n  assert axis >= 0 and axis < a.ndim\n\n  # `tf.boolean_mask` requires the first dimensions of array and condition to\n  # match. `np.compress` pads condition with False when it is shorter.\n  condition_t = condition.data\n  a_t = a.data\n  if condition.shape[0] < a.shape[axis]:\n    padding = tf.fill([a.shape[axis] - condition.shape[0]], False)\n    condition_t = tf.concat([condition_t, padding], axis=0)\n  return utils.tensor_to_ndarray(tf.boolean_mask(tensor=a_t, mask=condition_t,\n                                                 axis=axis))\n\n\ndef copy(a):\n  """"""Returns a copy of the array.""""""\n  return array(a, copy=True)\n\n\ndef _maybe_promote_to_int(a):\n  if tf.as_dtype(a.dtype).is_integer:\n    # If a is an integer type and its precision is less than that of `int`,\n    # the output type will be `int`.\n    output_type = np.promote_types(a.dtype, int)\n    if output_type != a.dtype:\n      a = asarray(a, dtype=output_type)\n\n  return a\n\n\n@utils.np_doc(np.cumprod)\ndef cumprod(a, axis=None, dtype=None):  # pylint: disable=missing-docstring\n  a = asarray(a, dtype=dtype)\n\n  if dtype is None:\n    a = _maybe_promote_to_int(a)\n\n  # If axis is None, the input is flattened.\n  if axis is None:\n    a = ravel(a)\n    axis = 0\n  elif axis < 0:\n    axis += tf.rank(a.data)\n  return utils.tensor_to_ndarray(tf.math.cumprod(a.data, axis))\n\n\n@utils.np_doc(np.cumsum)\ndef cumsum(a, axis=None, dtype=None):  # pylint: disable=missing-docstring\n  a = asarray(a, dtype=dtype)\n\n  if dtype is None:\n    a = _maybe_promote_to_int(a)\n\n  # If axis is None, the input is flattened.\n  if axis is None:\n    a = ravel(a)\n    axis = 0\n  elif axis < 0:\n    axis += tf.rank(a.data)\n  return utils.tensor_to_ndarray(tf.cumsum(a.data, axis))\n\n\ndef imag(a):\n  """"""Returns imaginary parts of all elements in `a`.\n\n  Uses `tf.imag`.\n\n  Args:\n    a: array_like. Could be an ndarray, a Tensor or any object that can\n      be converted to a Tensor using `tf.convert_to_tensor`.\n\n  Returns:\n    An ndarray with the same shape as `a`.\n  """"""\n  a = asarray(a)\n  # TODO(srbs): np.imag returns a scalar if a is a scalar, whereas we always\n  # return an ndarray.\n  return utils.tensor_to_ndarray(tf.math.imag(a.data))\n\n\n_TO_INT64 = 0\n_TO_FLOAT = 1\n\n\ndef _reduce(tf_fn, a, axis=None, dtype=None, keepdims=None,\n            promote_int=_TO_INT64, tf_bool_fn=None, preserve_bool=False):\n  """"""A general reduction function.\n\n  Args:\n    tf_fn: the TF reduction function.\n    a: the array to be reduced.\n    axis: (optional) the axis along which to do the reduction. If None, all\n      dimensions are reduced.\n    dtype: (optional) the dtype of the result.\n    keepdims: (optional) whether to keep the reduced dimension(s).\n    promote_int: how to promote integer and bool inputs. There are three\n      choices: (1) _TO_INT64: always promote them to int64 or uint64; (2)\n      _TO_FLOAT: always promote them to a float type (determined by\n      dtypes.default_float_type); (3) None: don\'t promote.\n    tf_bool_fn: (optional) the TF reduction function for bool inputs. It\n      will only be used if `dtype` is explicitly set to `np.bool_` or if `a`\'s\n      dtype is `np.bool_` and `preserve_bool` is True.\n    preserve_bool: a flag to control whether to use `tf_bool_fn` if `a`\'s dtype\n      is `np.bool_` (some reductions such as np.sum convert bools to\n      integers, while others such as np.max preserve bools.\n\n  Returns:\n    An ndarray.\n  """"""\n  if dtype:\n    dtype = utils.result_type(dtype)\n  if keepdims is None:\n    keepdims = False\n  a = asarray(a, dtype=dtype)\n  if ((dtype == np.bool_ or preserve_bool and a.dtype == np.bool_)\n      and tf_bool_fn is not None):\n    return utils.tensor_to_ndarray(\n        tf_bool_fn(input_tensor=a.data, axis=axis, keepdims=keepdims))\n  if dtype is None:\n    dtype = a.dtype\n    if np.issubdtype(dtype, np.integer) or dtype == np.bool_:\n      if promote_int == _TO_INT64:\n        # If a is an integer/bool type and whose bit width is less than 64,\n        # numpy up-casts it to 64-bit.\n        if dtype == np.bool_:\n          is_signed = True\n          width = 8  # We can use any number here that is less than 64\n        else:\n          is_signed = np.issubdtype(dtype, np.signedinteger)\n          width = np.iinfo(dtype).bits\n        if width < 64:\n          if is_signed:\n            dtype = np.int64\n          else:\n            dtype = np.uint64\n          a = a.astype(dtype)\n      elif promote_int == _TO_FLOAT:\n        a = a.astype(dtypes.default_float_type())\n\n  return utils.tensor_to_ndarray(\n      tf_fn(input_tensor=a.data, axis=axis, keepdims=keepdims))\n\n\n@utils.np_doc(np.sum)\ndef sum(a, axis=None, dtype=None, keepdims=None):  # pylint: disable=redefined-builtin\n  return _reduce(tf.reduce_sum, a, axis=axis, dtype=dtype, keepdims=keepdims,\n                 tf_bool_fn=tf.reduce_any)\n\n\n@utils.np_doc(np.prod)\ndef prod(a, axis=None, dtype=None, keepdims=None):\n  return _reduce(tf.reduce_prod, a, axis=axis, dtype=dtype, keepdims=keepdims,\n                 tf_bool_fn=tf.reduce_all)\n\n\n@utils.np_doc(np.mean)\ndef mean(a, axis=None, dtype=None, keepdims=None):\n  return _reduce(tf.math.reduce_mean, a, axis=axis, dtype=dtype,\n                 keepdims=keepdims, promote_int=_TO_FLOAT)\n\n\n@utils.np_doc(np.amax)\ndef amax(a, axis=None, keepdims=None):\n  return _reduce(tf.reduce_max, a, axis=axis, dtype=None, keepdims=keepdims,\n                 promote_int=None, tf_bool_fn=tf.reduce_any, preserve_bool=True)\n\n\n@utils.np_doc(np.amin)\ndef amin(a, axis=None, keepdims=None):\n  return _reduce(tf.reduce_min, a, axis=axis, dtype=None, keepdims=keepdims,\n                 promote_int=None, tf_bool_fn=tf.reduce_all, preserve_bool=True)\n\n\n# TODO(wangpeng): Remove this workaround once b/157232284 is fixed\ndef _reduce_variance_complex(input_tensor, axis, keepdims):\n  f = functools.partial(tf.math.reduce_variance, axis=axis, keepdims=keepdims)\n  return f(tf.math.real(input_tensor)) + f(tf.math.imag(input_tensor))\n\n\n# TODO(wangpeng): Remove this workaround once b/157232284 is fixed\ndef _reduce_std_complex(input_tensor, axis, keepdims):\n  y = _reduce_variance_complex(input_tensor=input_tensor, axis=axis,\n                               keepdims=keepdims)\n  return tf.math.sqrt(y)\n\n\n@utils.np_doc(np.var)\ndef var(a, axis=None, keepdims=None):\n  def f(input_tensor, axis, keepdims):\n    if input_tensor.dtype in (tf.complex64, tf.complex128):\n      # A workaround for b/157232284\n      fn = _reduce_variance_complex\n    else:\n      fn = tf.math.reduce_variance\n    return fn(input_tensor=input_tensor, axis=axis, keepdims=keepdims)\n  return _reduce(f, a, axis=axis, dtype=None, keepdims=keepdims,\n                 promote_int=_TO_FLOAT)\n\n\n@utils.np_doc(np.std)\ndef std(a, axis=None, keepdims=None):\n  def f(input_tensor, axis, keepdims):\n    if input_tensor.dtype in (tf.complex64, tf.complex128):\n      # A workaround for b/157232284\n      fn = _reduce_std_complex\n    else:\n      fn = tf.math.reduce_std\n    return fn(input_tensor=input_tensor, axis=axis, keepdims=keepdims)\n  return _reduce(f, a, axis=axis, dtype=None, keepdims=keepdims,\n                 promote_int=_TO_FLOAT)\n\n\n@utils.np_doc(np.ravel)\ndef ravel(a):  # pylint: disable=missing-docstring\n  a = asarray(a)\n  if a.ndim == 1:\n    return a\n  return utils.tensor_to_ndarray(tf.reshape(a.data, [-1]))\n\n\nsetattr(arrays_lib.ndarray, \'ravel\', ravel)\n\n\ndef real(val):\n  """"""Returns real parts of all elements in `a`.\n\n  Uses `tf.real`.\n\n  Args:\n    val: array_like. Could be an ndarray, a Tensor or any object that can\n      be converted to a Tensor using `tf.convert_to_tensor`.\n\n  Returns:\n    An ndarray with the same shape as `a`.\n  """"""\n  val = asarray(val)\n  # TODO(srbs): np.real returns a scalar if val is a scalar, whereas we always\n  # return an ndarray.\n  return utils.tensor_to_ndarray(tf.math.real(val.data))\n\n\n@utils.np_doc(np.repeat)\ndef repeat(a, repeats, axis=None):  # pylint: disable=missing-docstring\n  a = asarray(a).data\n  original_shape = a._shape_as_list()  # pylint: disable=protected-access\n  # Best effort recovery of the shape.\n  if original_shape is not None and None not in original_shape:\n    if not original_shape:\n      original_shape = (repeats,)\n    else:\n      repeats_np = np.ravel(np.array(repeats))\n      if repeats_np.size == 1:\n        repeats_np = repeats_np.item()\n        if axis is None:\n          original_shape = (repeats_np * np.prod(original_shape),)\n        else:\n          original_shape[axis] = repeats_np * original_shape[axis]\n      else:\n        if axis is None:\n          original_shape = (repeats_np.sum(),)\n        else:\n          original_shape[axis] = repeats_np.sum()\n\n  repeats = asarray(repeats).data\n  result = tf.repeat(a, repeats, axis)\n  result.set_shape(original_shape)\n\n  return utils.tensor_to_ndarray(result)\n\n\n@utils.np_doc(np.around)\ndef around(a, decimals=0):  # pylint: disable=missing-docstring\n  a = asarray(a)\n  dtype = a.dtype\n  factor = math.pow(10, decimals)\n  if np.issubdtype(dtype, np.inexact):\n    factor = tf.cast(factor, dtype)\n  else:\n    # Use float as the working dtype when a.dtype is exact (e.g. integer),\n    # because `decimals` can be negative.\n    float_dtype = dtypes.default_float_type()\n    a = a.astype(float_dtype).data\n    factor = tf.cast(factor, float_dtype)\n  a = tf.multiply(a, factor)\n  a = tf.round(a)\n  a = tf.math.divide(a, factor)\n  return utils.tensor_to_ndarray(a).astype(dtype)\n\n\nround_ = around\nsetattr(arrays_lib.ndarray, \'__round__\', around)\n\n\n@utils.np_doc(np.reshape)\ndef reshape(a, newshape, order=\'C\'):\n  """"""order argument can only b \'C\' or \'F\'.""""""\n  if order not in {\'C\', \'F\'}:\n    raise ValueError(\'Unsupported order argument {}\'.format(order))\n\n  a = asarray(a)\n  if isinstance(newshape, arrays_lib.ndarray):\n    newshape = newshape.data\n  if isinstance(newshape, int):\n    newshape = [newshape]\n\n  if order == \'F\':\n    r = tf.transpose(tf.reshape(tf.transpose(a.data), newshape[::-1]))\n  else:\n    r = tf.reshape(a.data, newshape)\n\n  return utils.tensor_to_ndarray(r)\n\n\ndef _reshape_method_wrapper(a, *newshape, **kwargs):\n  order = kwargs.pop(\'order\', \'C\')\n  if kwargs:\n    raise ValueError(\'Unsupported arguments: {}\'.format(kwargs.keys()))\n\n  if len(newshape) == 1 and not isinstance(newshape[0], int):\n    newshape = newshape[0]\n\n  return reshape(a, newshape, order=order)\n\n\ndef expand_dims(a, axis):\n  """"""Expand the shape of an array.\n\n  Args:\n    a: array_like. Could be an ndarray, a Tensor or any object that can\n      be converted to a Tensor using `tf.convert_to_tensor`.\n    axis: int. axis on which to expand the shape.\n\n  Returns:\n    An ndarray with the contents and dtype of `a` and shape expanded on axis.\n  """"""\n  a = asarray(a)\n  return utils.tensor_to_ndarray(tf.expand_dims(a.data, axis=axis))\n\n\ndef squeeze(a, axis=None):\n  """"""Removes single-element axes from the array.\n\n  Args:\n    a: array_like. Could be an ndarray, a Tensor or any object that can\n      be converted to a Tensor using `tf.convert_to_tensor`.\n    axis: scalar or list/tuple of ints.\n\n  TODO(srbs): tf.squeeze throws error when axis is a Tensor eager execution\n  is enabled. So we cannot allow axis to be array_like here. Fix.\n\n  Returns:\n    An ndarray.\n  """"""\n  a = asarray(a)\n  return utils.tensor_to_ndarray(tf.squeeze(a, axis))\n\n\ndef transpose(a, axes=None):\n  """"""Permutes dimensions of the array.\n\n  Args:\n    a: array_like. Could be an ndarray, a Tensor or any object that can\n      be converted to a Tensor using `tf.convert_to_tensor`.\n    axes: array_like. A list of ints with length rank(a) or None specifying the\n      order of permutation. The i\'th dimension of the output array corresponds\n      to axes[i]\'th dimension of the `a`. If None, the axes are reversed.\n\n  Returns:\n    An ndarray.\n  """"""\n  a = asarray(a)\n  if axes is not None:\n    axes = asarray(axes)\n  return utils.tensor_to_ndarray(tf.transpose(a=a.data, perm=axes))\n\n\n@utils.np_doc(np.swapaxes)\ndef swapaxes(a, axis1, axis2):  # pylint: disable=missing-docstring\n  a = asarray(a)\n\n  a_rank = tf.rank(a)\n  if axis1 < 0:\n    axis1 += a_rank\n  if axis2 < 0:\n    axis2 += a_rank\n\n  perm = tf.range(a_rank)\n  perm = tf.tensor_scatter_nd_update(perm, [[axis1], [axis2]], [axis2, axis1])\n  a = tf.transpose(a, perm)\n\n  return utils.tensor_to_ndarray(a)\n\n\n@utils.np_doc(np.moveaxis)\ndef moveaxis(a, source, destination):  # pylint: disable=missing-docstring\n  """"""Raises ValueError if source, destination not in (-ndim(a), ndim(a)).""""""\n  if not source and not destination:\n    return a\n\n  a = asarray(a).data\n\n  if isinstance(source, int):\n    source = (source,)\n  if isinstance(destination, int):\n    destination = (destination,)\n\n  a_rank = utils._maybe_static(tf.rank(a))  # pylint: disable=protected-access\n\n  def _correct_axis(axis, rank):\n    if axis < 0:\n      return axis + rank\n    return axis\n\n  source = tuple(_correct_axis(axis, a_rank) for axis in source)\n  destination = tuple(_correct_axis(axis, a_rank) for axis in destination)\n\n  if a.shape.rank is not None:\n    perm = [i for i in range(a_rank) if i not in source]\n    for dest, src in sorted(zip(destination, source)):\n      assert dest <= len(perm)\n      perm.insert(dest, src)\n  else:\n    r = tf.range(a_rank)\n\n    def _remove_indices(a, b):\n      """"""Remove indices (`b`) from `a`.""""""\n      items = tf.unstack(tf.sort(tf.stack(b)), num=len(b))\n\n      i = 0\n      result = []\n\n      for item in items:\n        result.append(a[i:item])\n        i = item + 1\n\n      result.append(a[i:])\n\n      return tf.concat(result, 0)\n\n    minus_sources = _remove_indices(r, source)\n    minus_dest = _remove_indices(r, destination)\n\n    perm = tf.scatter_nd(tf.expand_dims(minus_dest, 1), minus_sources, [a_rank])\n    perm = tf.tensor_scatter_nd_update(perm, tf.expand_dims(destination, 1),\n                                       source)\n  a = tf.transpose(a, perm)\n\n  return utils.tensor_to_ndarray(a)\n\n\ndef _setitem(arr, index, value):\n  """"""Sets the `value` at `index` in the array `arr`.\n\n  This works by replacing the slice at `index` in the tensor with `value`.\n  Since tensors are immutable, this builds a new tensor using the `tf.concat`\n  op. Currently, only 0-d and 1-d indices are supported.\n\n  Note that this may break gradients e.g.\n\n  a = tf_np.array([1, 2, 3])\n  old_a_t = a.data\n\n  with tf.GradientTape(persistent=True) as g:\n    g.watch(a.data)\n    b = a * 2\n    a[0] = 5\n  g.gradient(b.data, [a.data])  # [None]\n  g.gradient(b.data, [old_a_t])  # [[2., 2., 2.]]\n\n  Here `d_b / d_a` is `[None]` since a.data no longer points to the same\n  tensor.\n\n  Args:\n    arr: array_like.\n    index: scalar or 1-d integer array.\n    value: value to set at index.\n\n  Returns:\n    ndarray\n\n  Raises:\n    ValueError: if `index` is not a scalar or 1-d array.\n  """"""\n  # TODO(srbs): Figure out a solution to the gradient problem.\n  arr = asarray(arr)\n  index = asarray(index)\n  if index.ndim == 0:\n    index = ravel(index)\n  elif index.ndim > 1:\n    raise ValueError(\'index must be a scalar or a 1-d array.\')\n  value = asarray(value, dtype=arr.dtype)\n  if arr.shape[len(index):] != value.shape:\n    value = full(arr.shape[len(index):], value)\n  prefix_t = arr.data[:index.data[0]]\n  postfix_t = arr.data[index.data[0] + 1:]\n  if len(index) == 1:\n    arr._data = tf.concat(  # pylint: disable=protected-access\n        [prefix_t, tf.expand_dims(value.data, 0), postfix_t], 0)\n  else:\n    subarray = arr[index.data[0]]\n    _setitem(subarray, index[1:], value)\n    arr._data = tf.concat(  # pylint: disable=protected-access\n        [prefix_t, tf.expand_dims(subarray.data, 0), postfix_t], 0)\n\n\nsetattr(arrays_lib.ndarray, \'transpose\', transpose)\nsetattr(arrays_lib.ndarray, \'reshape\', _reshape_method_wrapper)\nsetattr(arrays_lib.ndarray, \'__setitem__\', _setitem)\n\n\ndef pad(ary, pad_width, mode, constant_values=0):\n  """"""Pads an array.\n\n  Args:\n    ary: array_like of rank N. Input array.\n    pad_width: {sequence, array_like, int}.\n      Number of values padded to the edges of each axis.\n      ((before_1, after_1), ... (before_N, after_N)) unique pad widths\n      for each axis.\n      ((before, after),) yields same before and after pad for each axis.\n      (pad,) or int is a shortcut for before = after = pad width for all\n      axes.\n    mode: string. One of the following string values:\n      \'constant\'\n          Pads with a constant value.\n      \'reflect\'\n          Pads with the reflection of the vector mirrored on\n          the first and last values of the vector along each\n          axis.\n      \'symmetric\'\n          Pads with the reflection of the vector mirrored\n          along the edge of the array.\n      **NOTE**: The supported list of `mode` does not match that of numpy\'s.\n    constant_values: scalar with same dtype as `array`.\n      Used in \'constant\' mode as the pad value.  Default is 0.\n\n\n  Returns:\n    An ndarray padded array of rank equal to `array` with shape increased\n    according to `pad_width`.\n\n  Raises:\n    ValueError if `mode` is not supported.\n  """"""\n  if not (mode == \'constant\' or mode == \'reflect\' or mode == \'symmetric\'):\n    raise ValueError(\'Unsupported padding mode: \' + mode)\n  mode = mode.upper()\n  ary = asarray(ary)\n  pad_width = asarray(pad_width, dtype=tf.int32)\n  return utils.tensor_to_ndarray(tf.pad(\n      tensor=ary.data, paddings=pad_width.data, mode=mode,\n      constant_values=constant_values))\n\n\n@utils.np_doc(np.take)\ndef take(a, indices, axis=None, out=None, mode=\'clip\'):\n  """"""out argument is not supported, and default mode is clip.""""""\n  if out is not None:\n    raise ValueError(\'out argument is not supported in take.\')\n\n  if mode not in {\'raise\', \'clip\', \'wrap\'}:\n    raise ValueError(""Invalid mode \'{}\' for take"".format(mode))\n\n  a = asarray(a).data\n  indices = asarray(indices).data\n\n  if axis is None:\n    a = tf.reshape(a, [-1])\n    axis = 0\n\n  axis_size = tf.shape(a, indices.dtype)[axis]\n  if mode == \'clip\':\n    indices = tf.clip_by_value(indices, 0, axis_size-1)\n  elif mode == \'wrap\':\n    indices = tf.math.floormod(indices, axis_size)\n  else:\n    raise ValueError(""The \'raise\' mode to take is not supported."")\n\n  return utils.tensor_to_ndarray(tf.gather(a, indices, axis=axis))\n\n\n@utils.np_doc_only(np.where)\ndef where(condition, x=None, y=None):\n  """"""Raises ValueError if exactly one of x or y is not None.""""""\n  condition = asarray(condition, dtype=np.bool_)\n  if x is None and y is None:\n    return nonzero(condition)\n  elif x is not None and y is not None:\n    x, y = _promote_dtype(x, y)\n    return utils.tensor_to_ndarray(tf.where(condition.data, x.data, y.data))\n  raise ValueError(\'Both x and y must be ndarrays, or both must be None.\')\n\n\n@utils.np_doc(np.select)\ndef select(condlist, choicelist, default=0):  # pylint: disable=missing-docstring\n  if len(condlist) != len(choicelist):\n    msg = \'condlist must have length equal to choicelist ({} vs {})\'\n    raise ValueError(msg.format(len(condlist), len(choicelist)))\n  if not condlist:\n    raise ValueError(\'condlist must be non-empty\')\n  choices = _promote_dtype(default, *choicelist)\n  choicelist = choices[1:]\n  output = choices[0]\n  # The traversal is in reverse order so we can return the first value in\n  # choicelist where condlist is True.\n  for cond, choice in zip(condlist[::-1], choicelist[::-1]):\n    output = where(cond, choice, output)\n  return output\n\n\ndef shape(a):\n  """"""Return the shape of an array.\n\n  Args:\n    a: array_like. Input array.\n\n  Returns:\n    Tuple of ints.\n  """"""\n  a = asarray(a)\n  return a.shape\n\n\ndef ndim(a):\n  a = asarray(a)\n  return a.ndim\n\n\ndef isscalar(a):\n  return ndim(a) == 0\n\n\ndef _boundaries_to_sizes(a, boundaries, axis):\n  """"""Converting boundaries of splits to sizes of splits.\n\n  Args:\n    a: the array to be split.\n    boundaries: the boundaries, as in np.split.\n    axis: the axis along which to split.\n\n  Returns:\n    A list of sizes of the splits, as in tf.split.\n  """"""\n  if axis >= len(a.shape):\n    raise ValueError(\'axis %s is out of bound for shape %s\' % (axis, a.shape))\n  total_size = a.shape[axis]\n  sizes = []\n  sizes_sum = 0\n  prev = 0\n  for i, b in enumerate(boundaries):\n    size = b - prev\n    if size < 0:\n      raise ValueError(\'The %s-th boundary %s is smaller than the previous \'\n                       \'boundary %s\' % (i, b, prev))\n    size = min(size, max(0, total_size - sizes_sum))\n    sizes.append(size)\n    sizes_sum += size\n    prev = b\n  sizes.append(max(0, total_size - sizes_sum))\n  return sizes\n\n\n@utils.np_doc(np.split)\ndef split(ary, indices_or_sections, axis=0):\n  ary = asarray(ary)\n  if not isinstance(indices_or_sections, six.integer_types):\n    indices_or_sections = _boundaries_to_sizes(ary, indices_or_sections, axis)\n  result = tf.split(ary.data, indices_or_sections, axis=axis)\n  return [utils.tensor_to_ndarray(a) for a in result]\n\n\ndef _split_on_axis(np_fun, axis):\n  @utils.np_doc(np_fun)\n  def f(ary, indices_or_sections):\n    return split(ary, indices_or_sections, axis=axis)\n  return f\n\n\nvsplit = _split_on_axis(np.vsplit, axis=0)\nhsplit = _split_on_axis(np.hsplit, axis=1)\ndsplit = _split_on_axis(np.dsplit, axis=2)\n\n\n@utils.np_doc(np.broadcast_to)\ndef broadcast_to(array, shape):  # pylint: disable=redefined-outer-name\n  return full(shape, array)\n\n\n@utils.np_doc(np.stack)\ndef stack(arrays, axis=0):\n  arrays = _promote_dtype(*arrays)  # pylint: disable=protected-access\n  unwrapped_arrays = [\n      a.data if isinstance(a, arrays_lib.ndarray) else a for a in arrays\n  ]\n  return asarray(tf.stack(unwrapped_arrays, axis))\n\n\n@utils.np_doc(np.hstack)\ndef hstack(tup):\n  arrays = [atleast_1d(a) for a in tup]\n  arrays = _promote_dtype(*arrays)  # pylint: disable=protected-access\n  unwrapped_arrays = [\n      a.data if isinstance(a, arrays_lib.ndarray) else a for a in arrays\n  ]\n  rank = tf.rank(unwrapped_arrays[0])\n  return utils.cond(rank == 1, lambda: tf.concat(unwrapped_arrays, axis=0),\n                    lambda: tf.concat(unwrapped_arrays, axis=1))\n\n\n@utils.np_doc(np.vstack)\ndef vstack(tup):\n  arrays = [atleast_2d(a) for a in tup]\n  arrays = _promote_dtype(*arrays)  # pylint: disable=protected-access\n  unwrapped_arrays = [\n      a.data if isinstance(a, arrays_lib.ndarray) else a for a in arrays\n  ]\n  return tf.concat(unwrapped_arrays, axis=0)\n\n\n@utils.np_doc(np.dstack)\ndef dstack(tup):\n  arrays = [atleast_3d(a) for a in tup]\n  arrays = _promote_dtype(*arrays)  # pylint: disable=protected-access\n  unwrapped_arrays = [\n      a.data if isinstance(a, arrays_lib.ndarray) else a for a in arrays\n  ]\n  return tf.concat(unwrapped_arrays, axis=2)\n\n\ndef _pad_left_to(n, old_shape):\n  old_shape = asarray(old_shape, dtype=np.int32).data\n  new_shape = tf.pad(\n      old_shape, [[tf.math.maximum(n - tf.size(old_shape), 0), 0]],\n      constant_values=1)\n  return asarray(new_shape)\n\n\ndef _atleast_nd(n, new_shape, *arys):\n  """"""Reshape arrays to be at least `n`-dimensional.\n\n  Args:\n    n: The minimal rank.\n    new_shape: a function that takes `n` and the old shape and returns the\n      desired new shape.\n    *arys: ndarray(s) to be reshaped.\n\n  Returns:\n    The reshaped array(s).\n  """"""\n\n  def f(x):\n    # pylint: disable=g-long-lambda\n    x = asarray(x)\n    return asarray(\n        utils.cond(\n            utils.greater(n, tf.rank(x)),\n            lambda: reshape(x, new_shape(n, tf.shape(x.data))).data,\n            lambda: x.data))\n\n  arys = list(map(f, arys))\n  if len(arys) == 1:\n    return arys[0]\n  else:\n    return arys\n\n\n@utils.np_doc(np.atleast_1d)\ndef atleast_1d(*arys):\n  return _atleast_nd(1, _pad_left_to, *arys)\n\n\n@utils.np_doc(np.atleast_2d)\ndef atleast_2d(*arys):\n  return _atleast_nd(2, _pad_left_to, *arys)\n\n\n@utils.np_doc(np.atleast_3d)\ndef atleast_3d(*arys):  # pylint: disable=missing-docstring\n\n  def new_shape(_, old_shape):\n    # pylint: disable=g-long-lambda\n    ndim_ = tf.size(old_shape)\n    return utils.cond(\n        ndim_ == 0, lambda: tf.constant([1, 1, 1], dtype=tf.int32),\n        lambda: utils.cond(\n            ndim_ == 1, lambda: tf.pad(old_shape, [[1, 1]], constant_values=1),\n            lambda: tf.pad(old_shape, [[0, 1]], constant_values=1)))\n\n  return _atleast_nd(3, new_shape, *arys)\n\n\n@utils.np_doc(np.nonzero)\ndef nonzero(a):\n  a = atleast_1d(a).data\n  if a.shape.rank is None:\n    raise ValueError(""The rank of `a` is unknown, so we can\'t decide how many ""\n                     ""arrays to return."")\n  return tf.nest.map_structure(\n      arrays_lib.tensor_to_ndarray,\n      tf.unstack(tf.where(tf.cast(a, tf.bool)), a.shape.rank, axis=1))\n\n\n@utils.np_doc(np.diag_indices)\ndef diag_indices(n, ndim=2):  # pylint: disable=missing-docstring,redefined-outer-name\n  if n < 0:\n    raise ValueError(\'n argument to diag_indices must be nonnegative, got {}\'\n                     .format(n))\n  if ndim < 0:\n    raise ValueError(\'ndim argument to diag_indices must be nonnegative, got {}\'\n                     .format(ndim))\n\n  return (tf.range(n),) * ndim\n\n\n@utils.np_doc(np.tri)\ndef tri(N, M=None, k=0, dtype=None):  # pylint: disable=invalid-name,missing-docstring\n  M = M if M is not None else N\n  if dtype is not None:\n    dtype = utils.result_type(dtype)\n  else:\n    dtype = dtypes.default_float_type()\n\n  if k < 0:\n    lower = -k - 1\n    if lower > N:\n      r = tf.zeros([N, M], dtype)\n    else:\n      # Keep as tf bool, since we create an upper triangular matrix and invert\n      # it.\n      o = tf.ones([N, M], dtype=tf.bool)\n      r = tf.cast(tf.math.logical_not(tf.linalg.band_part(o, lower, -1)), dtype)\n  else:\n    o = tf.ones([N, M], dtype)\n    if k > M:\n      r = o\n    else:\n      r = tf.linalg.band_part(o, -1, k)\n  return utils.tensor_to_ndarray(r)\n\n\n@utils.np_doc(np.tril)\ndef tril(m, k=0):  # pylint: disable=missing-docstring\n  m = asarray(m).data\n  m_shape = m.shape.as_list()\n\n  if len(m_shape) < 2:\n    raise ValueError(\'Argument to tril must have rank at least 2\')\n\n  if m_shape[-1] is None or m_shape[-2] is None:\n    raise ValueError(\'Currently, the last two dimensions of the input array \'\n                     \'need to be known.\')\n\n  z = tf.constant(0, m.dtype)\n\n  mask = tri(*m_shape[-2:], k=k, dtype=bool)\n  return utils.tensor_to_ndarray(\n      tf.where(tf.broadcast_to(mask, tf.shape(m)), m, z))\n\n\n@utils.np_doc(np.triu)\ndef triu(m, k=0):  # pylint: disable=missing-docstring\n  m = asarray(m).data\n  m_shape = m.shape.as_list()\n\n  if len(m_shape) < 2:\n    raise ValueError(\'Argument to triu must have rank at least 2\')\n\n  if m_shape[-1] is None or m_shape[-2] is None:\n    raise ValueError(\'Currently, the last two dimensions of the input array \'\n                     \'need to be known.\')\n\n  z = tf.constant(0, m.dtype)\n\n  mask = tri(*m_shape[-2:], k=k - 1, dtype=bool)\n  return utils.tensor_to_ndarray(\n      tf.where(tf.broadcast_to(mask, tf.shape(m)), z, m))\n\n\n@utils.np_doc(np.flip)\ndef flip(m, axis=None):  # pylint: disable=missing-docstring\n  m = asarray(m).data\n\n  if axis is None:\n    return utils.tensor_to_ndarray(tf.reverse(m, tf.range(tf.rank(m))))\n\n  axis = utils._canonicalize_axis(axis, tf.rank(m))  # pylint: disable=protected-access\n\n  return utils.tensor_to_ndarray(tf.reverse(m, [axis]))\n\n\n@utils.np_doc(np.flipud)\ndef flipud(m):  # pylint: disable=missing-docstring\n  return flip(m, 0)\n\n\n@utils.np_doc(np.fliplr)\ndef fliplr(m):  # pylint: disable=missing-docstring\n  return flip(m, 1)\n\n\n@utils.np_doc(np.roll)\ndef roll(a, shift, axis=None):  # pylint: disable=missing-docstring\n  a = asarray(a).data\n\n  if axis is not None:\n    return utils.tensor_to_ndarray(tf.roll(a, shift, axis))\n\n  # If axis is None, the roll happens as a 1-d tensor.\n  original_shape = tf.shape(a)\n  a = tf.roll(tf.reshape(a, [-1]), shift, 0)\n  return utils.tensor_to_ndarray(tf.reshape(a, original_shape))\n\n\n@utils.np_doc(np.rot90)\ndef rot90(m, k=1, axes=(0, 1)):  # pylint: disable=missing-docstring\n  m_rank = tf.rank(m)\n  ax1, ax2 = utils._canonicalize_axes(axes, m_rank)  # pylint: disable=protected-access\n\n  k = k % 4\n  if k == 0:\n    return m\n  elif k == 2:\n    return flip(flip(m, ax1), ax2)\n  else:\n    perm = tf.range(m_rank)\n    perm = tf.tensor_scatter_nd_update(perm, [[ax1], [ax2]], [ax2, ax1])\n\n    if k == 1:\n      return transpose(flip(m, ax2), perm)\n    else:\n      return flip(transpose(m, perm), ax2)\n\n\n@utils.np_doc(np.vander)\ndef vander(x, N=None, increasing=False):  # pylint: disable=missing-docstring,invalid-name\n  x = asarray(x).data\n\n  x_shape = tf.shape(x)\n  N = N or x_shape[0]\n\n  N_temp = utils.get_static_value(N)  # pylint: disable=invalid-name\n  if N_temp is not None:\n    N = N_temp\n    if N < 0:\n      raise ValueError(\'N must be nonnegative\')\n  else:\n    tf.debugging.Assert(N >= 0, [N])\n\n  rank = tf.rank(x)\n  rank_temp = utils.get_static_value(rank)\n  if rank_temp is not None:\n    rank = rank_temp\n    if rank != 1:\n      raise ValueError(\'x must be a one-dimensional array\')\n  else:\n    tf.debugging.Assert(rank == 1, [rank])\n\n  if increasing:\n    start = 0\n    limit = N\n    delta = 1\n  else:\n    start = N - 1\n    limit = -1\n    delta = -1\n\n  x = tf.expand_dims(x, -1)\n  return utils.tensor_to_ndarray(\n      tf.math.pow(x, tf.cast(tf.range(start, limit, delta), dtype=x.dtype)))\n\n\n@utils.np_doc(np.ix_)\ndef ix_(*args):  # pylint: disable=missing-docstring\n  n = len(args)\n  output = []\n  for i, a in enumerate(args):\n    a = asarray(a).data\n    a_rank = tf.rank(a)\n    a_rank_temp = utils.get_static_value(a_rank)\n    if a_rank_temp is not None:\n      a_rank = a_rank_temp\n      if a_rank != 1:\n        raise ValueError(\n            \'Arguments must be 1-d, got arg {} of rank {}\'.format(i, a_rank))\n    else:\n      tf.debugging.Assert(a_rank == 1, [a_rank])\n\n    new_shape = [1] * n\n    new_shape[i] = -1\n    dtype = a.dtype\n    if dtype == tf.bool:\n      output.append(\n          utils.tensor_to_ndarray(tf.reshape(nonzero(a)[0].data, new_shape)))\n    elif dtype.is_integer:\n      output.append(utils.tensor_to_ndarray(tf.reshape(a, new_shape)))\n    else:\n      raise ValueError(\n          \'Only integer and bool dtypes are supported, got {}\'.format(dtype))\n\n  return output\n'"
trax/tf_numpy/numpy_impl/arrays.py,10,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""ndarray class.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport six\n\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.numpy_impl import dtypes\n\n\ndef convert_to_tensor(value, dtype=None):\n  # A safer version of `tf.convert_to_tensor` to work around b/149876037.\n  # TODO(wangpeng): Remove this function once the bug is fixed.\n  if (dtype is None and isinstance(value, six.integer_types)\n      and value >= 2 ** 63):\n    dtype = tf.uint64\n  elif (dtype is None and isinstance(value, float)):\n    dtype = dtypes.default_float_type()\n  return tf.convert_to_tensor(value, dtype=dtype)\n\n\nclass ndarray(object):  # pylint: disable=invalid-name\n  """"""Equivalent of numpy.ndarray backed by TensorFlow tensors.\n\n  This does not support all features of NumPy ndarrays e.g. strides and\n  memory order since, unlike NumPy, the backing storage is not a raw memory\n  buffer.\n\n  TODO(srbs): Clearly specify which attributes and methods are not supported\n  or if there are any differences in behavior.\n  """"""\n\n  def __init__(self, shape, dtype=float, buffer=None):  # pylint: disable=redefined-builtin\n    """"""Initializes an ndarray.\n\n    This is a low level interface for building ndarrays and should be avoided.\n    Users should instead use methods in array_creation.py.\n\n    This class provides a numpy.ndarray like interface for a TF Tensor with a\n    fully-defined shape. Note that, unlike the backing buffer of np.ndarray,\n    Tensors are immutable. So, operations like `__setitem__` are performed by\n    replacing the Tensor. This restricts the ability to implement NumPy `view`\n    semantics.\n\n    Compared to numpy.ndarray, this does not support `offset`, `strides`\n    and `order` arguments.\n\n    Args:\n      shape: The shape of the array. Must be a scalar, an iterable of integers\n        or a `TensorShape` object.\n      dtype: Optional. The dtype of the array. Must be a python type, a numpy\n        type or a tensorflow `DType` object.\n      buffer: Optional. The backing buffer of the array. Must have shape\n        `shape`. Must be a `ndarray`, `np.ndarray` or a `Tensor`.\n\n    Raises:\n      ValueError: If `buffer` is specified and its shape does not match\n       `shape`.\n    """"""\n    if dtype and not isinstance(dtype, tf.DType):\n      dtype = tf.as_dtype(np.dtype(dtype))\n    if buffer is None:\n      buffer = tf.zeros(shape, dtype=dtype)\n    else:\n      if isinstance(buffer, ndarray):\n        buffer = buffer.data\n      elif isinstance(buffer, np.ndarray):\n        # If `buffer` is a np.ndarray, the Tensor will share the underlying\n        # storage of the array.\n        buffer = convert_to_tensor(value=buffer, dtype=dtype)\n      elif not isinstance(buffer, tf.Tensor):\n        raise ValueError(\'Unexpected type for `buffer` {}. Must be an ndarray,\'\n                         \' Tensor or np.ndarray.\'.format(type(buffer)))\n\n      if shape is not None and tuple(shape) != buffer._shape_tuple():  # pylint: disable=protected-access\n        # TODO(srbs): NumPy allows this. Investigate if/how to support this.\n        raise ValueError(\'shape arg must match buffer.shape.\')\n\n    assert isinstance(buffer, tf.Tensor)\n    if dtype and dtype != buffer.dtype:\n      buffer = tf.bitcast(buffer, dtype)\n    self._data = buffer\n    self.base = None\n\n  @property\n  def data(self):\n    """"""Tensor object containing the array data.\n\n    This has a few key differences from the Python buffer object used in\n    NumPy arrays.\n    1. Tensors are immutable. So operations requiring in-place edit, e.g.\n       __setitem__, are performed by replacing the underlying buffer with a new\n       one.\n    2. Tensors do not provide access to their raw buffer.\n\n    Returns:\n      A Tensor.\n    """"""\n    return self._data\n\n  @property\n  def shape(self):\n    """"""Returns a tuple of array dimensions.""""""\n    return self.data._shape_tuple()  # pylint: disable=protected-access\n\n  @property\n  def dtype(self):\n    return np.dtype(self.data.dtype.as_numpy_dtype)\n\n  @property\n  def ndim(self):\n    return self.data.shape.ndims\n\n  @property\n  def size(self):\n    """"""Returns the number of elements in the array.""""""\n    return np.prod(self.shape)\n\n  @property\n  def T(self):  # pylint: disable=invalid-name\n    return self.transpose()\n\n  def __len__(self):\n    if self.shape:\n      return self.shape[0]\n    else:\n      raise TypeError(\'len() of unsized object.\')\n\n  def astype(self, dtype):\n    if self.dtype == dtype:\n      return self\n    else:\n      return tensor_to_ndarray(tf.cast(self.data, dtype))\n\n  # Unary operations\n  def __neg__(self):\n    return tensor_to_ndarray(-self.data)  # pylint: disable=invalid-unary-operand-type\n\n  def __pos__(self):\n    return self\n\n  __hash__ = None\n\n  def __int__(self):\n    return int(self.data)\n\n  def __float__(self):\n    return float(self.data)\n\n  def __nonzero__(self):\n    return bool(self.data)\n\n  def __bool__(self):\n    return self.__nonzero__()\n\n  def __getitem__(self, slice_spec):\n    # TODO(srbs): Need to support better indexing.\n    result_t = self.data.__getitem__(slice_spec)\n    return tensor_to_ndarray(result_t)\n\n  def __iter__(self):\n    for i in range(self.shape[0]):\n      result_t = self.data[i]\n      yield tensor_to_ndarray(result_t)\n    return\n\n  def __array__(self, dtype=None):\n    """"""Returns a NumPy ndarray.\n\n    This allows instances of this class to be directly used in NumPy routines.\n    However, doing that may force a copy to CPU.\n\n    Args:\n      dtype: A NumPy compatible type.\n\n    Returns:\n      A NumPy ndarray.\n    """"""\n    return np.asarray(self.data, dtype)\n\n  __array_priority__ = 110\n\n  def __index__(self):\n    """"""Returns a python scalar.\n\n    This allows using an instance of this class as an array index.\n    Note that only arrays of integer types with size 1 can be used as array\n    indices.\n\n    Returns:\n      A Python scalar.\n\n    Raises:\n      TypeError: If the array is not of an integer type.\n      ValueError: If the array does not have size 1.\n    """"""\n    # TODO(wangpeng): Handle graph mode\n    return np.asscalar(self.data.numpy())\n\n  def tolist(self):\n    return self.data.numpy().tolist()\n\n  def __str__(self):\n    return \'ndarray<{}>\'.format(self.data.__str__())\n\n  def __repr__(self):\n    return \'ndarray<{}>\'.format(self.data.__repr__())\n\n\ndef tensor_to_ndarray(tensor):\n  return ndarray(tensor._shape_tuple(), dtype=tensor.dtype, buffer=tensor)  # pylint: disable=protected-access\n\n\ndef ndarray_to_tensor(arr, dtype=None, name=None, as_ref=False):\n  if as_ref:\n    raise ValueError(\'as_ref is not supported.\')\n  if dtype and tf.as_dtype(arr.dtype) != dtype:\n    return tf.cast(arr.data, dtype)\n  result_t = arr.data\n  if name:\n    result_t = tf.identity(result_t, name=name)\n  return result_t\n\n\ntf.register_tensor_conversion_function(ndarray, ndarray_to_tensor)\n\n\n# Don\'t use a namedtuple since nest considers that a tuple and unflattens and\n# flattens it.\nclass ShardedNdArray(object):\n  """"""Wrapper over ndarray that can contain tensors on multiple devices.\n\n    This is returned by extensions.pmap, and contains the individual tensors on\n    different devices.\n  """"""\n\n  def __init__(self, tensors):\n    """"""Initializes the ShardedNdArray.\n\n    Note that the tensors should be ordered in the way the pmap producing these\n    tensors is run.\n\n    Args:\n      tensors: list or tuple of eager tensors, one for each device.\n    """"""\n\n    if not isinstance(tensors, (list, tuple)) or not tensors:\n      raise ValueError(\n          \'Unable to create a ShardedNdArray without a list of tensors.\')\n    self.tensors = tensors\n    self.n_devices = len(tensors)\n\n  def __getitem__(self, i):\n    return self.tensors[i]\n\n  @property\n  def shape(self):\n    return (self.n_devices,) + self.tensors[0]._shape_tuple()  # pylint: disable=protected-access\n\n  @property\n  def dtype(self):\n    return x.tensors[0].dtype\n\n\ndef convert_sharded_tensor_to_eager_tensor(value, *args, **kwargs):\n  del args, kwargs\n  # TODO(nareshmodi): Consider a collective op to gather the tensors from the\n  # various devices for performance reasons.\n  return tf.stack(value.tensors)\n\ntf.register_tensor_conversion_function(\n    ShardedNdArray, convert_sharded_tensor_to_eager_tensor)\n'"
trax/tf_numpy/numpy_impl/dtypes.py,5,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Dtypes and dtype utilities.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\n\n# We use numpy\'s dtypes instead of TF\'s, because the user expects to use them\n# with numpy facilities such as `np.dtype(np.int64)` and\n# `if x.dtype.type is np.int64`.\n# pylint: disable=unused-import\n# pylint: disable=g-bad-import-order\nfrom numpy import bool_\nfrom numpy import int_\nfrom numpy import int16\nfrom numpy import int32\nfrom numpy import int64\nfrom numpy import int8\nfrom numpy import uint16\nfrom numpy import uint32\nfrom numpy import uint64\nfrom numpy import uint8\nfrom numpy import float_\nfrom numpy import float16\nfrom numpy import float32\nfrom numpy import float64\nfrom numpy import complex_\nfrom numpy import complex64\nfrom numpy import complex128\n\nfrom numpy import inexact\n\nfrom numpy import iinfo\nfrom numpy import issubdtype\n\nfrom numpy import inf\n\n# TODO(wangpeng): Make bfloat16 a numpy dtype instead of using TF\'s\nfrom tensorflow.compat.v2 import bfloat16\n# pylint: enable=g-bad-import-order\n# pylint: enable=unused-import\n\n\n_to_float32 = {\n    np.dtype(\'float64\'): np.dtype(\'float32\'),\n    np.dtype(\'complex128\'): np.dtype(\'complex64\'),\n}\n\n\n_allow_float64 = True\n\n\ndef is_allow_float64():\n  return _allow_float64\n\n\ndef set_allow_float64(b):\n  global _allow_float64\n  _allow_float64 = b\n\n\ndef canonicalize_dtype(dtype):\n  if not is_allow_float64():\n    return _to_float32.get(dtype, dtype)\n  else:\n    return dtype\n\n\ndef _result_type(*arrays_and_dtypes):\n  dtype = np.result_type(*arrays_and_dtypes)\n  return canonicalize_dtype(dtype)\n\n\ndef default_float_type():\n  """"""Gets the default float type.\n\n  Returns:\n    If `is_allow_float64()` is true, returns float64; otherwise returns float32.\n  """"""\n  if is_allow_float64():\n    return float64\n  else:\n    return float32\n'"
trax/tf_numpy/numpy_impl/math_ops.py,134,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Mathematical operations.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport sys\n\nimport numpy as np\nimport six\n\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.numpy_impl import array_ops\nfrom trax.tf_numpy.numpy_impl import arrays\nfrom trax.tf_numpy.numpy_impl import dtypes\nfrom trax.tf_numpy.numpy_impl import utils\n\n\n@utils.np_doc_only(np.dot)\ndef dot(a, b):  # pylint: disable=missing-docstring\n  def f(a, b):  # pylint: disable=missing-docstring\n    return utils.cond(\n        utils.logical_or(tf.rank(a) == 0, tf.rank(b) == 0),\n        lambda: a * b,\n        lambda: utils.cond(  # pylint: disable=g-long-lambda\n            tf.rank(b) == 1,\n            lambda: tf.tensordot(a, b, axes=[[-1], [-1]]),\n            lambda: tf.tensordot(a, b, axes=[[-1], [-2]])))\n  return _bin_op(f, a, b)\n\n\n# TODO(wangpeng): Make element-wise ops `ufunc`s\ndef _bin_op(tf_fun, a, b, promote=True):\n  if promote:\n    a, b = array_ops._promote_dtype(a, b)  # pylint: disable=protected-access\n  else:\n    a = array_ops.array(a)\n    b = array_ops.array(b)\n  return utils.tensor_to_ndarray(tf_fun(a.data, b.data))\n\n\n@utils.np_doc(np.add)\ndef add(x1, x2):\n  def add_or_or(x1, x2):\n    if x1.dtype == tf.bool:\n      assert x2.dtype == tf.bool\n      return tf.logical_or(x1, x2)\n    return tf.add(x1, x2)\n  return _bin_op(add_or_or, x1, x2)\n\n\n@utils.np_doc(np.subtract)\ndef subtract(x1, x2):\n  return _bin_op(tf.subtract, x1, x2)\n\n\n@utils.np_doc(np.multiply)\ndef multiply(x1, x2):\n  def mul_or_and(x1, x2):\n    if x1.dtype == tf.bool:\n      assert x2.dtype == tf.bool\n      return tf.logical_and(x1, x2)\n    return tf.multiply(x1, x2)\n  return _bin_op(mul_or_and, x1, x2)\n\n\n@utils.np_doc(np.true_divide)\ndef true_divide(x1, x2):\n  def _avoid_float64(x1, x2):\n    if x1.dtype == x2.dtype and x1.dtype in (tf.int32, tf.int64):\n      x1 = tf.cast(x1, dtype=tf.float32)\n      x2 = tf.cast(x2, dtype=tf.float32)\n    return x1, x2\n\n  def f(x1, x2):\n    if x1.dtype == tf.bool:\n      assert x2.dtype == tf.bool\n      float_ = dtypes.default_float_type()\n      x1 = tf.cast(x1, float_)\n      x2 = tf.cast(x2, float_)\n    if not dtypes.is_allow_float64():\n      # tf.math.truediv in Python3 produces float64 when both inputs are int32\n      # or int64. We want to avoid that when is_allow_float64() is False.\n      x1, x2 = _avoid_float64(x1, x2)\n    return tf.math.truediv(x1, x2)\n  return _bin_op(f, x1, x2)\n\n\ndivide = true_divide\n\n\n@utils.np_doc(np.floor_divide)\ndef floor_divide(x1, x2):\n  def f(x1, x2):\n    if x1.dtype == tf.bool:\n      assert x2.dtype == tf.bool\n      x1 = tf.cast(x1, tf.int8)\n      x2 = tf.cast(x2, tf.int8)\n    return tf.math.floordiv(x1, x2)\n  return _bin_op(f, x1, x2)\n\n\n@utils.np_doc(np.mod)\ndef mod(x1, x2):\n  def f(x1, x2):\n    if x1.dtype == tf.bool:\n      assert x2.dtype == tf.bool\n      x1 = tf.cast(x1, tf.int8)\n      x2 = tf.cast(x2, tf.int8)\n    return tf.math.mod(x1, x2)\n  return _bin_op(f, x1, x2)\n\n\nremainder = mod\n\n\n@utils.np_doc(np.divmod)\ndef divmod(x1, x2):\n  return floor_divide(x1, x2), mod(x1, x2)\n\n\n@utils.np_doc(np.maximum)\ndef maximum(x1, x2):\n  def max_or_or(x1, x2):\n    if x1.dtype == tf.bool:\n      assert x2.dtype == tf.bool\n      return tf.logical_or(x1, x2)\n    return tf.math.maximum(x1, x2)\n  return _bin_op(max_or_or, x1, x2)\n\n\n@utils.np_doc(np.minimum)\ndef minimum(x1, x2):\n  def min_or_and(x1, x2):\n    if x1.dtype == tf.bool:\n      assert x2.dtype == tf.bool\n      return tf.logical_and(x1, x2)\n    return tf.math.minimum(x1, x2)\n  return _bin_op(min_or_and, x1, x2)\n\n\n@utils.np_doc(np.clip)\ndef clip(a, a_min, a_max):  # pylint: disable=missing-docstring\n  if a_min is None and a_max is None:\n    raise ValueError(\'Not more than one of `a_min` and `a_max` may be `None`.\')\n  if a_min is None:\n    return minimum(a, a_max)\n  elif a_max is None:\n    return maximum(a, a_min)\n  else:\n    a, a_min, a_max = array_ops._promote_dtype(a, a_min, a_max)  # pylint: disable=protected-access\n    return utils.tensor_to_ndarray(\n        tf.clip_by_value(*utils.tf_broadcast(a.data, a_min.data, a_max.data)))\n\n\n@utils.np_doc(np.matmul)\ndef matmul(x1, x2):  # pylint: disable=missing-docstring\n  def f(x1, x2):\n    try:\n      return utils.cond(tf.rank(x2) == 1,\n                        lambda: tf.tensordot(x1, x2, axes=1),\n                        lambda: utils.cond(tf.rank(x1) == 1,  # pylint: disable=g-long-lambda\n                                           lambda: tf.tensordot(  # pylint: disable=g-long-lambda\n                                               x1, x2, axes=[[0], [-2]]),\n                                           lambda: tf.matmul(x1, x2)))\n    except tf.errors.InvalidArgumentError as err:\n      six.reraise(ValueError, ValueError(str(err)), sys.exc_info()[2])\n  return _bin_op(f, x1, x2)\n\n\n@utils.np_doc(np.tensordot)\ndef tensordot(a, b, axes=2):\n  return _bin_op(lambda a, b: tf.tensordot(a, b, axes=axes), a, b)\n\n\n@utils.np_doc_only(np.inner)\ndef inner(a, b):\n  def f(a, b):\n    return utils.cond(utils.logical_or(tf.rank(a) == 0, tf.rank(b) == 0),\n                      lambda: a * b,\n                      lambda: tf.tensordot(a, b, axes=[[-1], [-1]]))\n  return _bin_op(f, a, b)\n\n\n@utils.np_doc(np.cross)\ndef cross(a, b, axisa=-1, axisb=-1, axisc=-1, axis=None):  # pylint: disable=missing-docstring\n  def f(a, b):  # pylint: disable=missing-docstring\n    # We can\'t assign to captured variable `axisa`, so make a new variable\n    axis_a = axisa\n    axis_b = axisb\n    axis_c = axisc\n    if axis is not None:\n      axis_a = axis\n      axis_b = axis\n      axis_c = axis\n    if axis_a < 0:\n      axis_a = utils.add(axis_a, tf.rank(a))\n    if axis_b < 0:\n      axis_b = utils.add(axis_b, tf.rank(b))\n    def maybe_move_axis_to_last(a, axis):\n      def move_axis_to_last(a, axis):\n        return tf.transpose(\n            a, tf.concat(\n                [tf.range(axis), tf.range(axis + 1, tf.rank(a)), [axis]],\n                axis=0))\n      return utils.cond(\n          axis == utils.subtract(tf.rank(a), 1),\n          lambda: a,\n          lambda: move_axis_to_last(a, axis))\n    a = maybe_move_axis_to_last(a, axis_a)\n    b = maybe_move_axis_to_last(b, axis_b)\n    a_dim = utils.getitem(tf.shape(a), -1)\n    b_dim = utils.getitem(tf.shape(b), -1)\n    def maybe_pad_0(a, size_of_last_dim):\n      def pad_0(a):\n        return tf.pad(a, tf.concat([tf.zeros([tf.rank(a) - 1, 2], tf.int32),\n                                    tf.constant([[0, 1]], tf.int32)], axis=0))\n      return utils.cond(size_of_last_dim == 2,\n                        lambda: pad_0(a),\n                        lambda: a)\n    a = maybe_pad_0(a, a_dim)\n    b = maybe_pad_0(b, b_dim)\n    c = tf.linalg.cross(*utils.tf_broadcast(a, b))\n    if axis_c < 0:\n      axis_c = utils.add(axis_c, tf.rank(c))\n    def move_last_to_axis(a, axis):\n      r = tf.rank(a)\n      return tf.transpose(\n          a, tf.concat(\n              [tf.range(axis), [r - 1], tf.range(axis, r - 1)], axis=0))\n    c = utils.cond(\n        (a_dim == 2) & (b_dim == 2),\n        lambda: c[..., 2],\n        lambda: utils.cond(  # pylint: disable=g-long-lambda\n            axis_c == utils.subtract(tf.rank(c), 1),\n            lambda: c,\n            lambda: move_last_to_axis(c, axis_c)))\n    return c\n  return _bin_op(f, a, b)\n\n\n@utils.np_doc(np.power)\ndef power(x1, x2):\n  return _bin_op(tf.math.pow, x1, x2)\n\n\n@utils.np_doc(np.float_power)\ndef float_power(x1, x2):\n  return power(x1, x2)\n\n\n@utils.np_doc(np.arctan2)\ndef arctan2(x1, x2):\n  return _bin_op(tf.math.atan2, x1, x2)\n\n\n@utils.np_doc(np.nextafter)\ndef nextafter(x1, x2):\n  return _bin_op(tf.math.nextafter, x1, x2)\n\n\n@utils.np_doc(np.heaviside)\ndef heaviside(x1, x2):\n  def f(x1, x2):\n    return tf.where(x1 < 0, tf.constant(0, dtype=x2.dtype),\n                    tf.where(x1 > 0, tf.constant(1, dtype=x2.dtype), x2))\n  y = _bin_op(f, x1, x2)\n  if not np.issubdtype(y.dtype, np.inexact):\n    y = y.astype(dtypes.default_float_type())\n  return y\n\n\n@utils.np_doc(np.hypot)\ndef hypot(x1, x2):\n  return sqrt(square(x1) + square(x2))\n\n\n@utils.np_doc(np.kron)\ndef kron(a, b):\n  # pylint: disable=protected-access,g-complex-comprehension\n  a, b = array_ops._promote_dtype(a, b)\n  ndim = max(a.ndim, b.ndim)\n  if a.ndim < ndim:\n    a = array_ops.reshape(a, array_ops._pad_left_to(ndim, a.shape))\n  if b.ndim < ndim:\n    b = array_ops.reshape(b, array_ops._pad_left_to(ndim, b.shape))\n  a_reshaped = array_ops.reshape(a, [i for d in a.shape for i in (d, 1)])\n  b_reshaped = array_ops.reshape(b, [i for d in b.shape for i in (1, d)])\n  out_shape = tuple(np.multiply(a.shape, b.shape))\n  return array_ops.reshape(a_reshaped * b_reshaped, out_shape)\n\n\n@utils.np_doc(np.outer)\ndef outer(a, b):\n  def f(a, b):\n    return tf.reshape(a, [-1, 1]) * tf.reshape(b, [-1])\n  return _bin_op(f, a, b)\n\n\n# This can also be implemented via tf.reduce_logsumexp\n@utils.np_doc(np.logaddexp)\ndef logaddexp(x1, x2):\n  amax = maximum(x1, x2)\n  delta = x1 - x2\n  return array_ops.where(\n      isnan(delta),\n      x1 + x2,  # NaNs or infinities of the same sign.\n      amax + log1p(exp(-abs(delta))))\n\n\n@utils.np_doc(np.logaddexp2)\ndef logaddexp2(x1, x2):\n  amax = maximum(x1, x2)\n  delta = x1 - x2\n  return array_ops.where(\n      isnan(delta),\n      x1 + x2,  # NaNs or infinities of the same sign.\n      amax + log1p(exp2(-abs(delta))) / np.log(2))\n\n\n@utils.np_doc(np.polyval)\ndef polyval(p, x):\n  def f(p, x):\n    if p.shape.rank == 0:\n      p = tf.reshape(p, [1])\n    p = tf.unstack(p)\n    # TODO(wangpeng): Make tf version take a tensor for p instead of a list.\n    y = tf.math.polyval(p, x)\n    # If the polynomial is 0-order, numpy requires the result to be broadcast to\n    # `x`\'s shape.\n    if len(p) == 1:\n      y = tf.broadcast_to(y, x.shape)\n    return y\n  return _bin_op(f, p, x)\n\n\n@utils.np_doc(np.isclose)\ndef isclose(a, b, rtol=1e-05, atol=1e-08, equal_nan=False):  # pylint: disable=missing-docstring\n  def f(a, b):  # pylint: disable=missing-docstring\n    dtype = a.dtype\n    if np.issubdtype(dtype.as_numpy_dtype, np.inexact):\n      rtol_ = tf.convert_to_tensor(rtol, dtype.real_dtype)\n      atol_ = tf.convert_to_tensor(atol, dtype.real_dtype)\n      result = (tf.math.abs(a - b) <= atol_ + rtol_ * tf.math.abs(b))\n      if equal_nan:\n        result = result | (tf.math.is_nan(a) & tf.math.is_nan(b))\n      return result\n    else:\n      return a == b\n  return _bin_op(f, a, b)\n\n\n@utils.np_doc(np.allclose)\ndef allclose(a, b, rtol=1e-05, atol=1e-08, equal_nan=False):\n  return array_ops.all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))\n\n\ndef _tf_gcd(x1, x2):\n  def _gcd_cond_fn(x1, x2):\n    return tf.reduce_any(x2 != 0)\n  def _gcd_body_fn(x1, x2):\n    # tf.math.mod will raise an error when any element of x2 is 0. To avoid\n    # that, we change those zeros to ones. Their values don\'t matter because\n    # they won\'t be used.\n    x2_safe = tf.where(x2 != 0, x2, tf.constant(1, x2.dtype))\n    x1, x2 = (tf.where(x2 != 0, x2, x1),\n              tf.where(x2 != 0, tf.math.mod(x1, x2_safe),\n                       tf.constant(0, x2.dtype)))\n    return (tf.where(x1 < x2, x2, x1), tf.where(x1 < x2, x1, x2))\n  if (not np.issubdtype(x1.dtype.as_numpy_dtype, np.integer) or\n      not np.issubdtype(x2.dtype.as_numpy_dtype, np.integer)):\n    raise ValueError(""Arguments to gcd must be integers."")\n  shape = tf.broadcast_static_shape(x1.shape, x2.shape)\n  x1 = tf.broadcast_to(x1, shape)\n  x2 = tf.broadcast_to(x2, shape)\n  gcd, _ = tf.while_loop(_gcd_cond_fn, _gcd_body_fn,\n                         (tf.math.abs(x1), tf.math.abs(x2)))\n  return gcd\n\n\n@utils.np_doc(np.gcd)\ndef gcd(x1, x2):\n  return _bin_op(_tf_gcd, x1, x2)\n\n\n@utils.np_doc(np.lcm)\ndef lcm(x1, x2):\n  def f(x1, x2):\n    d = _tf_gcd(x1, x2)\n    # Same as the `x2_safe` trick above\n    d_safe = tf.where(d == 0, tf.constant(1, d.dtype), d)\n    return tf.where(d == 0, tf.constant(0, d.dtype),\n                    tf.math.abs(x1 * x2) // d_safe)\n  return _bin_op(f, x1, x2)\n\n\ndef _bitwise_binary_op(tf_fn, x1, x2):\n  def f(x1, x2):\n    is_bool = (x1.dtype == tf.bool)\n    if is_bool:\n      assert x2.dtype == tf.bool\n      x1 = tf.cast(x1, tf.int8)\n      x2 = tf.cast(x2, tf.int8)\n    r = tf_fn(x1, x2)\n    if is_bool:\n      r = tf.cast(r, tf.bool)\n    return r\n  return _bin_op(f, x1, x2)\n\n\n@utils.np_doc(np.bitwise_and)\ndef bitwise_and(x1, x2):\n  return _bitwise_binary_op(tf.bitwise.bitwise_and, x1, x2)\n\n\n@utils.np_doc(np.bitwise_or)\ndef bitwise_or(x1, x2):\n  return _bitwise_binary_op(tf.bitwise.bitwise_or, x1, x2)\n\n\n@utils.np_doc(np.bitwise_xor)\ndef bitwise_xor(x1, x2):\n  return _bitwise_binary_op(tf.bitwise.bitwise_xor, x1, x2)\n\n\n@utils.np_doc(np.bitwise_not)\ndef bitwise_not(x):\n  def f(x):\n    if x.dtype == tf.bool:\n      return tf.logical_not(x)\n    return tf.bitwise.invert(x)\n  return _scalar(f, x)\n\n\ndef _scalar(tf_fn, x, promote_to_float=False):\n  """"""Computes the tf_fn(x) for each element in `x`.\n\n  Args:\n    tf_fn: function that takes a single Tensor argument.\n    x: array_like. Could be an ndarray, a Tensor or any object that can\n      be converted to a Tensor using `tf.convert_to_tensor`.\n    promote_to_float: whether to cast the argument to a float dtype\n      (`dtypes.default_float_type`) if it is not already.\n\n  Returns:\n    An ndarray with the same shape as `x`. The default output dtype is\n    determined by `dtypes.default_float_type`, unless x is an ndarray with a\n    floating point type, in which case the output type is same as x.dtype.\n  """"""\n  x = array_ops.asarray(x)\n  if promote_to_float and not np.issubdtype(x.dtype, np.inexact):\n    x = x.astype(dtypes.default_float_type())\n  return utils.tensor_to_ndarray(tf_fn(x.data))\n\n\n@utils.np_doc(np.log)\ndef log(x):\n  return _scalar(tf.math.log, x, True)\n\n\n@utils.np_doc(np.exp)\ndef exp(x):\n  return _scalar(tf.exp, x, True)\n\n\n@utils.np_doc(np.sqrt)\ndef sqrt(x):\n  return _scalar(tf.sqrt, x, True)\n\n\n@utils.np_doc(np.abs)\ndef abs(x):\n  return _scalar(tf.math.abs, x)\n\n\n@utils.np_doc(np.absolute)\ndef absolute(x):\n  return abs(x)\n\n\n@utils.np_doc(np.fabs)\ndef fabs(x):\n  return abs(x)\n\n\n@utils.np_doc(np.ceil)\ndef ceil(x):\n  return _scalar(tf.math.ceil, x, True)\n\n\n@utils.np_doc(np.floor)\ndef floor(x):\n  return _scalar(tf.math.floor, x, True)\n\n\n@utils.np_doc(np.conj)\ndef conj(x):\n  return _scalar(tf.math.conj, x)\n\n\n@utils.np_doc(np.negative)\ndef negative(x):\n  return _scalar(tf.math.negative, x)\n\n\n@utils.np_doc(np.reciprocal)\ndef reciprocal(x):\n  return _scalar(tf.math.reciprocal, x)\n\n\n@utils.np_doc(np.signbit)\ndef signbit(x):\n  def f(x):\n    if x.dtype == tf.bool:\n      return tf.fill(x.shape, False)\n    return x < 0\n  return _scalar(f, x)\n\n\n@utils.np_doc(np.sin)\ndef sin(x):\n  return _scalar(tf.math.sin, x, True)\n\n\n@utils.np_doc(np.cos)\ndef cos(x):\n  return _scalar(tf.math.cos, x, True)\n\n\n@utils.np_doc(np.tan)\ndef tan(x):\n  return _scalar(tf.math.tan, x, True)\n\n\n@utils.np_doc(np.sinh)\ndef sinh(x):\n  return _scalar(tf.math.sinh, x, True)\n\n\n@utils.np_doc(np.cosh)\ndef cosh(x):\n  return _scalar(tf.math.cosh, x, True)\n\n\n@utils.np_doc(np.tanh)\ndef tanh(x):\n  return _scalar(tf.math.tanh, x, True)\n\n\n@utils.np_doc(np.arcsin)\ndef arcsin(x):\n  return _scalar(tf.math.asin, x, True)\n\n\n@utils.np_doc(np.arccos)\ndef arccos(x):\n  return _scalar(tf.math.acos, x, True)\n\n\n@utils.np_doc(np.arctan)\ndef arctan(x):\n  return _scalar(tf.math.atan, x, True)\n\n\n@utils.np_doc(np.arcsinh)\ndef arcsinh(x):\n  return _scalar(tf.math.asinh, x, True)\n\n\n@utils.np_doc(np.arccosh)\ndef arccosh(x):\n  return _scalar(tf.math.acosh, x, True)\n\n\n@utils.np_doc(np.arctanh)\ndef arctanh(x):\n  return _scalar(tf.math.atanh, x, True)\n\n\n@utils.np_doc(np.deg2rad)\ndef deg2rad(x):\n  def f(x):\n    return x * (np.pi / 180.0)\n  return _scalar(f, x, True)\n\n\n@utils.np_doc(np.rad2deg)\ndef rad2deg(x):\n  return x * (180.0 / np.pi)\n\n\n_tf_float_types = [tf.bfloat16, tf.float16, tf.float32, tf.float64]\n\n\n@utils.np_doc(np.angle)\ndef angle(z, deg=False):\n  def f(x):\n    if x.dtype in _tf_float_types:\n      # Workaround for b/147515503\n      return tf.where(x < 0, np.pi, 0)\n    else:\n      return tf.math.angle(x)\n  y = _scalar(f, z, True)\n  if deg:\n    y = rad2deg(y)\n  return y\n\n\n@utils.np_doc(np.cbrt)\ndef cbrt(x):\n  def f(x):\n    # __pow__ can\'t handle negative base, so we use `abs` here.\n    rt = tf.math.abs(x) ** (1.0 / 3)\n    return tf.where(x < 0, -rt, rt)\n  return _scalar(f, x, True)\n\n\n@utils.np_doc(np.conjugate)\ndef conjugate(x):\n  return _scalar(tf.math.conj, x)\n\n\n@utils.np_doc(np.exp2)\ndef exp2(x):\n  def f(x):\n    return 2 ** x\n  return _scalar(f, x, True)\n\n\n@utils.np_doc(np.expm1)\ndef expm1(x):\n  return _scalar(tf.math.expm1, x, True)\n\n\n@utils.np_doc(np.fix)\ndef fix(x):\n  def f(x):\n    return tf.where(x < 0, tf.math.ceil(x), tf.math.floor(x))\n  return _scalar(f, x, True)\n\n\n@utils.np_doc(np.iscomplex)\ndef iscomplex(x):\n  return array_ops.imag(x) != 0\n\n\n@utils.np_doc(np.isreal)\ndef isreal(x):\n  return array_ops.imag(x) == 0\n\n\n@utils.np_doc(np.iscomplexobj)\ndef iscomplexobj(x):\n  x = array_ops.array(x)\n  return np.issubdtype(x.dtype, np.complexfloating)\n\n\n@utils.np_doc(np.isrealobj)\ndef isrealobj(x):\n  return not iscomplexobj(x)\n\n\n@utils.np_doc(np.isnan)\ndef isnan(x):\n  return _scalar(tf.math.is_nan, x, True)\n\n\ndef _make_nan_reduction(onp_reduction, reduction, init_val):\n  """"""Helper to generate nan* functions.""""""\n  @utils.np_doc(onp_reduction)\n  def nan_reduction(a, axis=None, dtype=None, keepdims=False):\n    a = array_ops.array(a)\n    v = array_ops.array(init_val, dtype=a.dtype)\n    return reduction(\n        array_ops.where(isnan(a), v, a),\n        axis=axis,\n        dtype=dtype,\n        keepdims=keepdims)\n  return nan_reduction\n\n\nnansum = _make_nan_reduction(np.nansum, array_ops.sum, 0)\nnanprod = _make_nan_reduction(np.nanprod, array_ops.prod, 1)\n\n\n@utils.np_doc(np.nanmean)\ndef nanmean(a, axis=None, dtype=None, keepdims=None):  # pylint: disable=missing-docstring\n  a = array_ops.array(a)\n  if np.issubdtype(a.dtype, np.bool_) or np.issubdtype(a.dtype, np.integer):\n    return array_ops.mean(a, axis=axis, dtype=dtype, keepdims=keepdims)\n  nan_mask = logical_not(isnan(a))\n  if dtype is None:\n    dtype = a.dtype\n  normalizer = array_ops.sum(\n      nan_mask, axis=axis, dtype=dtype, keepdims=keepdims)\n  return nansum(a, axis=axis, dtype=dtype, keepdims=keepdims) / normalizer\n\n\n@utils.np_doc(np.isfinite)\ndef isfinite(x):\n  return _scalar(tf.math.is_finite, x, True)\n\n\n@utils.np_doc(np.isinf)\ndef isinf(x):\n  return _scalar(tf.math.is_inf, x, True)\n\n\n@utils.np_doc(np.isneginf)\ndef isneginf(x):\n  return x == array_ops.full_like(x, -np.inf)\n\n\n@utils.np_doc(np.isposinf)\ndef isposinf(x):\n  return x == array_ops.full_like(x, np.inf)\n\n\n@utils.np_doc(np.log2)\ndef log2(x):\n  return log(x) / np.log(2)\n\n\n@utils.np_doc(np.log10)\ndef log10(x):\n  return log(x) / np.log(10)\n\n\n@utils.np_doc(np.log1p)\ndef log1p(x):\n  return _scalar(tf.math.log1p, x, True)\n\n\n@utils.np_doc(np.positive)\ndef positive(x):\n  return _scalar(lambda x: x, x)\n\n\n@utils.np_doc(np.sinc)\ndef sinc(x):\n  def f(x):\n    pi_x = x * np.pi\n    return tf.where(x == 0, tf.ones_like(x), tf.math.sin(pi_x) / pi_x)\n  return _scalar(f, x, True)\n\n\n@utils.np_doc(np.square)\ndef square(x):\n  return _scalar(tf.math.square, x)\n\n\n@utils.np_doc(np.diff)\ndef diff(a, n=1, axis=-1):\n  def f(a):\n    nd = a.shape.rank\n    if (axis + nd if axis < 0 else axis) >= nd:\n      raise ValueError(""axis %s is out of bounds for array of dimension %s"" %\n                       (axis, nd))\n    if n < 0:\n      raise ValueError(""order must be non-negative but got %s"" % n)\n    slice1 = [slice(None)] * nd\n    slice2 = [slice(None)] * nd\n    slice1[axis] = slice(1, None)\n    slice2[axis] = slice(None, -1)\n    slice1 = tuple(slice1)\n    slice2 = tuple(slice2)\n    op = tf.not_equal if a.dtype == tf.bool else tf.subtract\n    for _ in range(n):\n      a = op(a[slice1], a[slice2])\n    return a\n  return _scalar(f, a)\n\n\ndef _flip_args(f):\n  def _f(a, b):\n    return f(b, a)\n  return _f\n\n\nsetattr(arrays.ndarray, \'__abs__\', absolute)\nsetattr(arrays.ndarray, \'__floordiv__\', floor_divide)\nsetattr(arrays.ndarray, \'__rfloordiv__\', _flip_args(floor_divide))\nsetattr(arrays.ndarray, \'__mod__\', mod)\nsetattr(arrays.ndarray, \'__rmod__\', _flip_args(mod))\nsetattr(arrays.ndarray, \'__add__\', add)\nsetattr(arrays.ndarray, \'__radd__\', _flip_args(add))\nsetattr(arrays.ndarray, \'__sub__\', subtract)\nsetattr(arrays.ndarray, \'__rsub__\', _flip_args(subtract))\nsetattr(arrays.ndarray, \'__mul__\', multiply)\nsetattr(arrays.ndarray, \'__rmul__\', _flip_args(multiply))\nsetattr(arrays.ndarray, \'__pow__\', power)\nsetattr(arrays.ndarray, \'__rpow__\', _flip_args(power))\nsetattr(arrays.ndarray, \'__truediv__\', true_divide)\nsetattr(arrays.ndarray, \'__rtruediv__\', _flip_args(true_divide))\n\n\ndef _comparison(tf_fun, x1, x2, cast_bool_to_int=False):\n  dtype = utils.result_type(x1, x2)\n  # Cast x1 and x2 to the result_type if needed.\n  x1 = array_ops.array(x1, dtype=dtype)\n  x2 = array_ops.array(x2, dtype=dtype)\n  x1 = x1.data\n  x2 = x2.data\n  if cast_bool_to_int and x1.dtype == tf.bool:\n    x1 = tf.cast(x1, tf.int32)\n    x2 = tf.cast(x2, tf.int32)\n  return utils.tensor_to_ndarray(tf_fun(x1, x2))\n\n\n@utils.np_doc(np.equal)\ndef equal(x1, x2):\n  return _comparison(tf.equal, x1, x2)\n\n\n@utils.np_doc(np.not_equal)\ndef not_equal(x1, x2):\n  return _comparison(tf.not_equal, x1, x2)\n\n\n@utils.np_doc(np.greater)\ndef greater(x1, x2):\n  return _comparison(tf.greater, x1, x2, True)\n\n\n@utils.np_doc(np.greater_equal)\ndef greater_equal(x1, x2):\n  return _comparison(tf.greater_equal, x1, x2, True)\n\n\n@utils.np_doc(np.less)\ndef less(x1, x2):\n  return _comparison(tf.less, x1, x2, True)\n\n\n@utils.np_doc(np.less_equal)\ndef less_equal(x1, x2):\n  return _comparison(tf.less_equal, x1, x2, True)\n\n\n@utils.np_doc(np.array_equal)\ndef array_equal(a1, a2):\n  def f(a1, a2):\n    if a1.shape != a2.shape:\n      return tf.constant(False)\n    return tf.reduce_all(tf.equal(a1, a2))\n  return _comparison(f, a1, a2)\n\n\ndef _logical_binary_op(tf_fun, x1, x2):\n  x1 = array_ops.array(x1, dtype=np.bool_)\n  x2 = array_ops.array(x2, dtype=np.bool_)\n  return utils.tensor_to_ndarray(tf_fun(x1.data, x2.data))\n\n\n@utils.np_doc(np.logical_and)\ndef logical_and(x1, x2):\n  return _logical_binary_op(tf.logical_and, x1, x2)\n\n\n@utils.np_doc(np.logical_or)\ndef logical_or(x1, x2):\n  return _logical_binary_op(tf.logical_or, x1, x2)\n\n\n@utils.np_doc(np.logical_xor)\ndef logical_xor(x1, x2):\n  return _logical_binary_op(tf.math.logical_xor, x1, x2)\n\n\n@utils.np_doc(np.logical_not)\ndef logical_not(x):\n  x = array_ops.array(x, dtype=np.bool_)\n  return utils.tensor_to_ndarray(tf.logical_not(x.data))\n\nsetattr(arrays.ndarray, \'__invert__\', logical_not)\nsetattr(arrays.ndarray, \'__lt__\', less)\nsetattr(arrays.ndarray, \'__le__\', less_equal)\nsetattr(arrays.ndarray, \'__gt__\', greater)\nsetattr(arrays.ndarray, \'__ge__\', greater_equal)\nsetattr(arrays.ndarray, \'__eq__\', equal)\nsetattr(arrays.ndarray, \'__ne__\', not_equal)\n\n\n@utils.np_doc(np.linspace)\ndef linspace(  # pylint: disable=missing-docstring\n    start, stop, num=50, endpoint=True, retstep=False, dtype=float, axis=0):\n  if dtype:\n    dtype = utils.result_type(dtype)\n  start = array_ops.array(start, dtype=dtype).data\n  stop = array_ops.array(stop, dtype=dtype).data\n  if num < 0:\n    raise ValueError(\'Number of samples {} must be non-negative.\'.format(num))\n  step = tf.convert_to_tensor(np.nan)\n  if endpoint:\n    result = tf.linspace(start, stop, num, axis=axis)\n    if num > 1:\n      step = (stop - start) / (num - 1)\n  else:\n    # tf.linspace does not support endpoint=False so we manually handle it\n    # here.\n    if num > 1:\n      step = ((stop - start) / num)\n      new_stop = tf.cast(stop, step.dtype) - step\n      start = tf.cast(start, new_stop.dtype)\n      result = tf.linspace(start, new_stop, num, axis=axis)\n    else:\n      result = tf.linspace(start, stop, num, axis=axis)\n  if dtype:\n    result = tf.cast(result, dtype)\n  if retstep:\n    return arrays.tensor_to_ndarray(result), arrays.tensor_to_ndarray(step)\n  else:\n    return arrays.tensor_to_ndarray(result)\n\n\n@utils.np_doc(np.logspace)\ndef logspace(start, stop, num=50, endpoint=True, base=10.0, dtype=None, axis=0):\n  dtype = utils.result_type(start, stop, dtype)\n  result = linspace(\n      start, stop, num=num, endpoint=endpoint, dtype=dtype, axis=axis).data\n  result = tf.pow(tf.cast(base, result.dtype), result)\n  if dtype:\n    result = tf.cast(result, dtype)\n  return arrays.tensor_to_ndarray(result)\n\n\n@utils.np_doc(np.ptp)\ndef ptp(a, axis=None, keepdims=None):\n  return (array_ops.amax(a, axis=axis, keepdims=keepdims) -\n          array_ops.amin(a, axis=axis, keepdims=keepdims))\n\n\n@utils.np_doc_only(np.concatenate)\ndef concatenate(arys, axis=0):\n  if not isinstance(arys, (list, tuple)):\n    arys = [arys]\n  if not arys:\n    raise ValueError(\'Need at least one array to concatenate.\')\n  dtype = utils.result_type(*arys)\n  arys = [array_ops.array(array, dtype=dtype).data for array in arys]\n  return arrays.tensor_to_ndarray(tf.concat(arys, axis))\n\n\n@utils.np_doc_only(np.tile)\ndef tile(a, reps):\n  a = array_ops.array(a).data\n  reps = array_ops.array(reps, dtype=tf.int32).reshape([-1]).data\n\n  a_rank = tf.rank(a)\n  reps_size = tf.size(reps)\n  reps = tf.pad(\n      reps, [[tf.math.maximum(a_rank - reps_size, 0), 0]],\n      constant_values=1)\n  a_shape = tf.pad(\n      tf.shape(a), [[tf.math.maximum(reps_size - a_rank, 0), 0]],\n      constant_values=1)\n  a = tf.reshape(a, a_shape)\n\n  return arrays.tensor_to_ndarray(tf.tile(a, reps))\n\n\n@utils.np_doc(np.count_nonzero)\ndef count_nonzero(a, axis=None):\n  return arrays.tensor_to_ndarray(\n      tf.math.count_nonzero(array_ops.array(a).data, axis))\n\n\n@utils.np_doc(np.argsort)\ndef argsort(a, axis=-1, kind=\'quicksort\', order=None):  # pylint: disable=missing-docstring\n  # TODO(nareshmodi): make string tensors also work.\n  if kind not in (\'quicksort\', \'stable\'):\n    raise ValueError(""Only \'quicksort\' and \'stable\' arguments are supported."")\n  if order is not None:\n    raise ValueError(""\'order\' argument to sort is not supported."")\n  stable = (kind == \'stable\')\n\n  a = array_ops.array(a).data\n\n  def _argsort(a, axis, stable):\n    if axis is None:\n      a = tf.reshape(a, [-1])\n      axis = 0\n\n    return tf.argsort(a, axis, stable=stable)\n\n  tf_ans = tf.cond(\n      tf.rank(a) == 0, lambda: tf.constant([0]),\n      lambda: _argsort(a, axis, stable))\n\n  return array_ops.array(tf_ans, dtype=np.intp)\n\n\n@utils.np_doc(np.sort)\ndef sort(a, axis=-1, kind=\'quicksort\', order=None):  # pylint: disable=missing-docstring\n  if kind != \'quicksort\':\n    raise ValueError(""Only \'quicksort\' is supported."")\n  if order is not None:\n    raise ValueError(""\'order\' argument to sort is not supported."")\n\n  a = array_ops.array(a)\n\n  if axis is None:\n    result_t = tf.sort(tf.reshape(a.data, [-1]), 0)\n    return utils.tensor_to_ndarray(result_t)\n  else:\n    return utils.tensor_to_ndarray(tf.sort(a.data, axis))\n\n\ndef _argminmax(fn, a, axis=None):\n  a = array_ops.array(a)\n  if axis is None:\n    # When axis is None numpy flattens the array.\n    a_t = tf.reshape(a.data, [-1])\n  else:\n    a_t = array_ops.atleast_1d(a).data\n  return utils.tensor_to_ndarray(fn(input=a_t, axis=axis))\n\n\n@utils.np_doc(np.argmax)\ndef argmax(a, axis=None):\n  return _argminmax(tf.argmax, a, axis)\n\n\n@utils.np_doc(np.argmin)\ndef argmin(a, axis=None):\n  return _argminmax(tf.argmin, a, axis)\n\n\n@utils.np_doc(np.append)\ndef append(arr, values, axis=None):\n  if axis is None:\n    return concatenate([array_ops.ravel(arr), array_ops.ravel(values)], 0)\n  else:\n    return concatenate([arr, values], axis=axis)\n\n\n@utils.np_doc(np.average)\ndef average(a, axis=None, weights=None, returned=False):  # pylint: disable=missing-docstring\n  if axis is not None and not isinstance(axis, six.integer_types):\n    # TODO(wangpeng): Support tuple of ints as `axis`\n    raise ValueError(\'`axis` must be an integer. Tuple of ints is not \'\n                     \'supported yet. Got type: %s\' % type(axis))\n  a = array_ops.array(a)\n  if weights is None:  # Treat all weights as 1\n    if not np.issubdtype(a.dtype, np.inexact):\n      a = a.astype(utils.result_type(a.dtype, dtypes.default_float_type()))\n    avg = tf.reduce_mean(a.data, axis=axis)\n    if returned:\n      if axis is None:\n        weights_sum = tf.size(a.data)\n      else:\n        weights_sum = tf.shape(a.data)[axis]\n      weights_sum = tf.cast(weights_sum, a.data.dtype)\n  else:\n    if np.issubdtype(a.dtype, np.inexact):\n      out_dtype = utils.result_type(a.dtype, weights)\n    else:\n      out_dtype = utils.result_type(a.dtype, weights,\n                                    dtypes.default_float_type())\n    a = array_ops.array(a, out_dtype).data\n    weights = array_ops.array(weights, out_dtype).data\n\n    def rank_equal_case():\n      tf.debugging.Assert(tf.reduce_all(tf.shape(a) == tf.shape(weights)),\n                          [tf.shape(a), tf.shape(weights)])\n      weights_sum = tf.reduce_sum(weights, axis=axis)\n      avg = tf.reduce_sum(a * weights, axis=axis) / weights_sum\n      return avg, weights_sum\n    if axis is None:\n      avg, weights_sum = rank_equal_case()\n    else:\n      def rank_not_equal_case():\n        tf.debugging.Assert(tf.rank(weights) == 1, [tf.rank(weights)])\n        weights_sum = tf.reduce_sum(weights)\n        axes = tf.convert_to_tensor([[axis], [0]])\n        avg = tf.tensordot(a, weights, axes) / weights_sum\n        return avg, weights_sum\n      # We condition on rank rather than shape equality, because if we do the\n      # latter, when the shapes are partially unknown but the ranks are known\n      # and different, utils.cond will run shape checking on the true branch,\n      # which will raise a shape-checking error.\n      avg, weights_sum = utils.cond(tf.rank(a) == tf.rank(weights),\n                                    rank_equal_case, rank_not_equal_case)\n\n  avg = array_ops.array(avg)\n  if returned:\n    weights_sum = array_ops.broadcast_to(weights_sum, tf.shape(avg.data))\n    return avg, weights_sum\n  return avg\n\n\n@utils.np_doc(np.trace)\ndef trace(a, offset=0, axis1=0, axis2=1, dtype=None):  # pylint: disable=missing-docstring\n  if dtype:\n    dtype = utils.result_type(dtype)\n  a = array_ops.asarray(a, dtype).data\n\n  if offset == 0:\n    a_shape = a.shape\n    if a_shape.rank is not None:\n      rank = len(a_shape)\n      if (axis1 == -2 or axis1 == rank - 2) and (axis2 == -1 or\n                                                 axis2 == rank - 1):\n        return utils.tensor_to_ndarray(tf.linalg.trace(a))\n\n  a = array_ops.diagonal(a, offset, axis1, axis2)\n  return array_ops.sum(a, -1, dtype)\n\n\n@utils.np_doc(np.meshgrid)\ndef meshgrid(*xi, **kwargs):\n  """"""This currently requires copy=True and sparse=False.""""""\n  sparse = kwargs.get(\'sparse\', False)\n  if sparse:\n    raise ValueError(\'tf.numpy doesnt support returning sparse arrays yet\')\n\n  copy = kwargs.get(\'copy\', True)\n  if not copy:\n    raise ValueError(\'tf.numpy only supports copy=True\')\n\n  indexing = kwargs.get(\'indexing\', \'xy\')\n\n  xi = [array_ops.asarray(arg).data for arg in xi]\n  kwargs = {\'indexing\': indexing}\n\n  outputs = tf.meshgrid(*xi, **kwargs)\n  outputs = [utils.tensor_to_ndarray(output) for output in outputs]\n\n  return outputs\n'"
trax/tf_numpy/numpy_impl/random.py,1,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Random functions.""""""\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.numpy_impl import utils\n\n\nDEFAULT_RANDN_DTYPE = np.float32\n\n\ndef randn(*args):\n  """"""Returns samples from a normal distribution.\n\n  Uses `tf.random_normal`.\n\n  Args:\n    *args: The shape of the output array.\n\n  Returns:\n    An ndarray with shape `args` and dtype `float64`.\n  """"""\n  # TODO(wangpeng): Use new stateful RNG\n  if utils.isscalar(args):\n    args = (args,)\n  return utils.tensor_to_ndarray(\n      tf.random.normal(args, dtype=DEFAULT_RANDN_DTYPE))\n\n\ndef seed(s):\n  """"""Sets the seed for the random number generator.\n\n  Uses `tf.set_random_seed`.\n\n  Args:\n    s: an integer.\n  """"""\n  # TODO(wangpeng): make the signature the same as numpy\n  tf.random.set_seed(s)\n'"
trax/tf_numpy/numpy_impl/utils.py,12,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Utility functions for internal use.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# TODO(wangpeng): Use tf_inspect once we move into TF.\nimport funcsigs\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.numpy_impl import arrays\nfrom trax.tf_numpy.numpy_impl import dtypes\n\n\ntensor_to_ndarray = arrays.tensor_to_ndarray\n\n\ndef _canonicalize_axis(axis, rank):\n  return _canonicalize_axes([axis], rank)[0]\n\n\ndef _canonicalize_axes(axes, rank):\n  rank = _maybe_static(rank)\n\n  if isinstance(rank, tf.Tensor):\n    canonicalizer = (\n        lambda axis: cond(axis < 0, lambda: axis + rank, lambda: axis))\n  else:\n    canonicalizer = lambda axis: axis+rank if axis < 0 else axis\n\n  return [canonicalizer(axis) for axis in axes]\n\n\ndef _to_tf_type(dtype):\n  """"""Converts a native python or numpy type to TF DType.\n\n  Args:\n    dtype: Could be a python type, a numpy type or a TF DType.\n\n  Returns:\n    A tensorflow `DType`.\n  """"""\n  return tf.as_dtype(dtype)\n\n\ndef _to_numpy_type(dtype):\n  """"""Converts a native python or TF DType to numpy type.\n\n  Args:\n    dtype: Could be a python type, a numpy type or a TF DType.\n\n  Returns:\n    A NumPy `dtype`.\n  """"""\n  if isinstance(dtype, tf.DType):\n    return dtype.as_numpy_dtype\n  return np.dtype(dtype)\n\n\ndef finfo(dtype):\n  """"""Returns properties of floating point types.\n\n  Note that currently it just forwards to the numpy namesake, while tensorflow\n  and numpy dtypes may have different properties.\n\n  Args:\n    dtype: Could be a python type, a numpy type or a TF DType.\n\n  Returns:\n    A class describing properties of `dtype`, as described by\n    https://docs.scipy.org/doc/numpy/reference/generated/numpy.finfo.html\n  """"""\n  return np.finfo(_to_numpy_type(dtype))\n\n\ndef isscalar(val):\n  """"""Returns whether `val` is a scalar value or scalar Tensor.""""""\n  if isinstance(val, (np.ndarray, arrays.ndarray, tf.Tensor)):\n    return len(val.shape) == 0  # pylint: disable=g-explicit-length-test\n  return np.isscalar(val)\n\n\n# Can\'t use np_doc because np.result_type is a builtin function.\ndef result_type(*arrays_and_dtypes):\n  """"""Returns the type resulting from applying NumPy type promotion to arguments.\n\n  Args:\n    *arrays_and_dtypes: A list of array_like objects or dtypes.\n\n  Returns:\n    A numpy dtype.\n  """"""\n  def maybe_get_dtype(x):\n    # Don\'t put np.ndarray in this list, because np.result_type looks at the\n    # value (not just dtype) of np.ndarray to decide the result type.\n    if isinstance(x, (arrays.ndarray, arrays.ShardedNdArray,\n                      tf.Tensor, tf.IndexedSlices)):\n      return _to_numpy_type(x.dtype)\n    elif isinstance(x, tf.DType):\n      return _to_numpy_type(x)\n    return x\n  arrays_and_dtypes = [maybe_get_dtype(x) for x in\n                       tf.nest.flatten(arrays_and_dtypes)]\n  if not arrays_and_dtypes:\n    # If arrays_and_dtypes is an empty list, let numpy decide what the dtype is.\n    arrays_and_dtypes = [np.asarray([])]\n  return dtypes._result_type(*arrays_and_dtypes)\n\n\ndef promote_types(type1, type2):\n  """"""Returns the type resulting from applying NumPy type promotion.\n\n  Args:\n    type1: A numpy type.\n    type2: A numpy type.\n\n  Returns:\n    A numpy type.\n  """"""\n  type1 = _to_numpy_type(type1)\n  type2 = _to_numpy_type(type2)\n  return dtypes.canonicalize_dtype(np.promote_types(type1, type2))\n\n\ndef _has_docstring(f):\n  return hasattr(f, \'__doc__\') and isinstance(f.__doc__, str) and f.__doc__\n\n\ndef _add_blank_line(s):\n  if s.endswith(\'\\n\'):\n    return s + \'\\n\'\n  else:\n    return s + \'\\n\\n\'\n\n\ndef _np_signature(f):\n  """"""An enhanced funcsigs.signature that can handle numpy.ufunc.""""""\n  if not isinstance(f, np.ufunc):\n    return funcsigs.signature(f)\n  def names_from_num(prefix, n):\n    if n <= 0:\n      return []\n    elif n == 1:\n      return [prefix]\n    else:\n      return [prefix + str(i + 1) for i in range(n)]\n  input_names = names_from_num(\'x\', f.nin)\n  output_names = names_from_num(\'out\', f.nout)\n  keyword_only_params = [\n      (\'where\', True),\n      (\'casting\', \'same_kind\'),\n      (\'order\', \'K\'),\n      (\'dtype\', None),\n      (\'subok\', True),\n      (\'signature\', None),\n      (\'extobj\', None)]\n  params = []\n  params += [funcsigs.Parameter(name, funcsigs.Parameter.POSITIONAL_ONLY)\n             for name in input_names]\n  if f.nout > 1:\n    params += [funcsigs.Parameter(name, funcsigs.Parameter.POSITIONAL_ONLY,\n                                  default=None)\n               for name in output_names]\n  params += [funcsigs.Parameter(\n      \'out\', funcsigs.Parameter.POSITIONAL_OR_KEYWORD,\n      default=None if f.nout == 1 else (None,) * f.nout)]\n  params += [funcsigs.Parameter(name, funcsigs.Parameter.KEYWORD_ONLY,\n                                default=default)\n             for name, default in keyword_only_params]\n  return funcsigs.Signature(params)\n\n\n# Python 2 doesn\'t allow keyword-only argument. Python prior to 3.8 doesn\'t\n# allow positional-only argument. So we conflate positional-only, keyword-only\n# and positional-or-keyword arguments here.\ndef _is_compatible_param_kind(a, b):\n  def relax(k):\n    if k in (funcsigs.Parameter.POSITIONAL_ONLY,\n             funcsigs.Parameter.KEYWORD_ONLY):\n      return funcsigs.Parameter.POSITIONAL_OR_KEYWORD\n    return k\n  return relax(a) == relax(b)\n\n\ndef np_doc(np_fun):\n  """"""Attachs numpy docstring to a function.\n\n  Args:\n    np_fun: the numpy function whose docstring will be used.\n\n  Returns:\n    A function decorator that attaches the docstring from `np_fun` to the\n    decorated function.\n  """"""\n  np_sig = _np_signature(np_fun)\n  def decorator(f):\n    """"""The decorator.""""""\n    sig = funcsigs.signature(f)\n    for name, param in sig.parameters.items():\n      np_param = np_sig.parameters.get(name)\n      if np_param is None:\n        raise TypeError(\'Cannot find parameter ""%s"" in the numpy function\\\'s \'\n                        \'signature\' % name)\n      if not _is_compatible_param_kind(param.kind, np_param.kind):\n        raise TypeError(\'Parameter ""%s"" is of kind %s while in numpy it is of \'\n                        \'kind %s\' % (name, param.kind, np_param.kind))\n      has_default = (param.default != funcsigs.Parameter.empty)\n      np_has_default = (np_param.default != funcsigs.Parameter.empty)\n      if has_default != np_has_default:\n        raise TypeError(\'Parameter ""%s"" should%s have a default value\' %\n                        (name, \'\' if np_has_default else \' not\'))\n    unsupported_params = []\n    for name in np_sig.parameters:\n      if name not in sig.parameters:\n        unsupported_params.append(name)\n    f.__doc__ = _np_doc_helper(f, np_fun, unsupported_params)\n    return f\n  return decorator\n\n\ndef _np_doc_helper(f, np_f, unsupported_params=None):\n  """"""Helper to get docs.""""""\n  if not unsupported_params and not _has_docstring(f) and _has_docstring(np_f):\n    return np_f.__doc__\n  doc = \'TensorFlow variant of `numpy.%s`.\\n\\n\' % np_f.__name__\n  if unsupported_params:\n    doc += \'Unsupported arguments: \' + \', \'.join(\n        \'`\' + name + \'`\' for name in unsupported_params) + \'.\\n\\n\'\n  if _has_docstring(f):\n    doc += f.__doc__\n    doc = _add_blank_line(doc)\n  if _has_docstring(np_f):\n    doc += \'Documentation for `numpy.%s`:\\n\\n\' % np_f.__name__\n    doc += np_f.__doc__\n  return doc\n\n\ndef np_doc_only(np_f):\n  """"""Attachs numpy docstring to a function.\n\n  This differs from np_doc in that it doesn\'t check for a match in signature.\n\n  Args:\n    np_f: the numpy function whose docstring will be used.\n\n  Returns:\n    A function decorator that attaches the docstring from `np_f` to the\n    decorated function.\n  """"""\n\n  def decorator(f):\n    f.__doc__ = _np_doc_helper(f, np_f)\n    return f\n\n  return decorator\n\n\ndef tf_broadcast(*args):\n  """"""Broadcast tensors.\n\n  Args:\n    *args: a list of tensors whose shapes are broadcastable against each other.\n\n  Returns:\n    Tensors broadcasted to the common shape.\n  """"""\n  if len(args) <= 1:\n    return args\n  sh = tf.shape(args[0])\n  for arg in args[1:]:\n    sh = tf.broadcast_dynamic_shape(sh, tf.shape(arg))\n  return [tf.broadcast_to(arg, sh) for arg in args]\n\n\n# TODO(wangpeng): Move the following functions to a separate file and check for\n#   float dtypes in each of them.\n\n\ndef get_static_value(x):\n  """"""A version of tf.get_static_value that returns None on float dtypes.\n\n  It returns None on float dtypes in order to avoid breaking gradients.\n\n  Args:\n    x: a tensor.\n\n  Returns:\n    Same as `tf.get_static_value`, except that it returns None when `x` has a\n    float dtype.\n  """"""\n  if isinstance(x, tf.Tensor) and (x.dtype.is_floating or x.dtype.is_complex):\n    return None\n  return tf.get_static_value(x)\n\n\ndef _maybe_static(x):\n  value = get_static_value(x)\n  if value is None:\n    return x\n  else:\n    return value\n\n\n# All the following functions exist becaues get_static_value can\'t handle\n# their TF counterparts.\n\n\ndef cond(pred, true_fn, false_fn):\n  """"""A version of tf.cond that tries to evaluate the condition.""""""\n  v = get_static_value(pred)\n  if v is None:\n    return tf.cond(pred, true_fn, false_fn)\n  if v:\n    return true_fn()\n  else:\n    return false_fn()\n\n\ndef add(a, b):\n  """"""A version of tf.add that eagerly evaluates if possible.""""""\n  return _maybe_static(a) + _maybe_static(b)\n\n\ndef subtract(a, b):\n  """"""A version of tf.subtract that eagerly evaluates if possible.""""""\n  return _maybe_static(a) - _maybe_static(b)\n\n\ndef greater(a, b):\n  """"""A version of tf.greater that eagerly evaluates if possible.""""""\n  return _maybe_static(a) > _maybe_static(b)\n\n\ndef greater_equal(a, b):\n  """"""A version of tf.greater_equal that eagerly evaluates if possible.""""""\n  return _maybe_static(a) >= _maybe_static(b)\n\n\ndef less_equal(a, b):\n  """"""A version of tf.less_equal that eagerly evaluates if possible.""""""\n  return _maybe_static(a) <= _maybe_static(b)\n\n\ndef logical_and(a, b):\n  """"""A version of tf.logical_and that eagerly evaluates if possible.""""""\n  a_value = get_static_value(a)\n  if a_value is not None:\n    if np.isscalar(a_value):\n      if a_value:\n        return _maybe_static(b)\n      else:\n        return a_value\n    else:\n      return a_value & _maybe_static(b)\n  else:\n    return a & _maybe_static(b)\n\n\ndef logical_or(a, b):\n  """"""A version of tf.logical_or that eagerly evaluates if possible.""""""\n  a_value = get_static_value(a)\n  if a_value is not None:\n    if np.isscalar(a_value):\n      if a_value:\n        return a_value\n      else:\n        return _maybe_static(b)\n    else:\n      return a_value | _maybe_static(b)\n  else:\n    return a | _maybe_static(b)\n\n\ndef getitem(a, slice_spec):\n  """"""A version of __getitem__ that eagerly evaluates if possible.""""""\n  return _maybe_static(a)[slice_spec]\n\n\ndef reduce_all(input_tensor, axis=None, keepdims=False):\n  """"""A version of tf.reduce_all that eagerly evaluates if possible.""""""\n  v = get_static_value(input_tensor)\n  if v is None:\n    return tf.reduce_all(input_tensor, axis=axis, keepdims=keepdims)\n  else:\n    return v.all(axis=axis, keepdims=keepdims)\n\n\ndef reduce_any(input_tensor, axis=None, keepdims=False):\n  """"""A version of tf.reduce_any that eagerly evaluates if possible.""""""\n  v = get_static_value(input_tensor)\n  if v is None:\n    return tf.reduce_any(input_tensor, axis=axis, keepdims=keepdims)\n  else:\n    return v.any(axis=axis, keepdims=keepdims)\n'"
trax/tf_numpy/examples/mnist/dataset.py,1,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Load pickled MNIST data.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport gzip\nimport os\nimport pickle\nimport random\nimport urllib\nimport numpy as np\n\n\ndef load():\n  """"""Loads the dataset.\n\n  Looks for the dataset at /tmp/mnist.pkl.gz and downloads it if it is not there\n  already.\n\n  Note: The training data is shuffled.\n\n  Returns:\n    ((train_x, train_y), (valid_x, valid_y), (test_x, test_y)).\n    Shapes:\n      train_x: num_training_examples x image_size\n      train_y: num_training_examples x num_classes\n      valid_x: num_validation_examples x image_size\n      valid_y: num_validation_examples x num_classes\n      test_x: num_test_examples x image_size\n      test_y: num_test_examples x num_classes\n  """"""\n  filepath = _maybe_download()\n  with gzip.open(os.path.join(filepath), \'rb\') as f:\n    training_data, validation_data, test_data = pickle.load(f)\n  training_data = (training_data[0], [to_one_hot(x) for x in training_data[1]])\n  validation_data = (validation_data[0],\n                     [to_one_hot(x) for x in validation_data[1]])\n  test_data = (test_data[0], [to_one_hot(x) for x in test_data[1]])\n\n  def shuffle(data):\n    zipped = zip(*data)\n    random.shuffle(zipped)\n    return zip(*zipped)\n\n  return (shuffle(training_data), validation_data, test_data)\n\n\ndef to_one_hot(label, num_classes=10):\n  vec = np.zeros(num_classes, dtype=np.float32)\n  vec[label] = 1.\n  return vec\n\n\ndef _maybe_download():\n  """"""Downloads the MNIST dataset if it is not there already.""""""\n  data_url = \'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz\'\n  filename = data_url.split(\'/\')[-1]\n  filepath = os.path.join(_get_data_dir(), filename)\n  if not os.path.exists(filepath):\n\n    def _progress(count, block_size, total_size):\n      print(\'\\r>> Downloading %s %.1f%%\' %\n            (filename, float(count * block_size) / float(total_size) * 100.0))\n\n    filepath, _ = urllib.urlretrieve(data_url, filepath, _progress)\n    statinfo = os.stat(filepath)\n    print(\'Successfully downloaded %s %d bytes.\' % (filename, statinfo.st_size))\n  else:\n    print(\'Data already present on disk.\')\n  return filepath\n\n\ndef _get_data_dir():\n  return \'/tmp\'\n'"
trax/tf_numpy/examples/mnist/model.py,13,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Model for training on MNIST data.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom numpy import float32\nfrom numpy import int32\n\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy import numpy as np\n\n\nclass Model(object):\n  """"""A simple neural network with dense layers and sigmoid non-linearity.\n\n  The network consists of `len(hidden_layers) + 1` dense layers. The sizes of\n  the hidden layers are specified by the user in `hidden_layers` and the\n  network takes care of adding layers to match the input and output size.\n\n  Attributes:\n    weights: A list of 2-d float32 arrays containing the layer weights.\n    biases: A list of 2-d float32 arrays containing the layer biases.\n\n  Methods:\n    forward: Can be used to perform a forward pass on a batch of\n      flattened images. Output is returned as a batch of one-hot vectors of the\n      classes.\n    train: method performs a forward and backward pass and updates the\n      weights and biases.\n    evaluate: method can be used to evaluate the network on a batch of\n      examples.\n  """"""\n\n  def __init__(self, hidden_layers, input_size=784, num_classes=10):\n    """"""Initializes the neural network.\n\n    Args:\n      hidden_layers: List of ints specifying the sizes of hidden layers. Could\n        be empty.\n      input_size: Length of the input array. The network receives the input\n        image as a flattened 1-d array. Defaults to 784(28*28), the default\n        image size for MNIST.\n      num_classes: The number of output classes. Defaults to 10.\n    """"""\n    hidden_layers = [input_size] + hidden_layers + [num_classes]\n    self.weights = []\n    self.biases = []\n    for i in range(len(hidden_layers) - 1):\n      # TODO(srbs): This is manually cast to float32 to avoid the cast in\n      # np.dot since backprop fails for tf.cast op.\n      self.weights.append(\n          np.array(\n              np.random.randn(hidden_layers[i + 1], hidden_layers[i]),\n              copy=False,\n              dtype=float32))\n      self.biases.append(\n          np.array(\n              np.random.randn(hidden_layers[i + 1]), copy=False, dtype=float32))\n\n  def forward(self, x):\n    """"""Performs the forward pass.\n\n    Args:\n      x: 2-d array of size batch_size x image_size.\n\n    Returns:\n      A 2-d array of size batch_size x num_classes.\n    """"""\n\n    def sigmoid(x):\n      return 1.0 / (1.0 + np.exp(-x))\n\n    for w, b in zip(self.weights, self.biases):\n      x = sigmoid(np.dot(w, x.T).T + b)\n    return x\n\n  def train(self, x, y, learning_rate=0.01):\n    """"""Runs a single training pass.\n\n    Args:\n      x: 2-d array of size batch_size x image_size.\n      y: 2-d array of size batch_size x num_classes in one-hot notation.\n      learning_rate: The learning rate.\n    """"""\n    x = np.array(x, copy=False)\n    y = np.array(y, copy=False)\n\n    def mean_squared_error(x, y):\n      diff = x - y\n      return np.sum(diff * diff) / len(x)\n\n    wb_tensors = [p.data for p in self.weights + self.biases]\n    with tf.GradientTape() as g:\n      g.watch(wb_tensors)\n      loss = mean_squared_error(self.forward(x), y)\n    gradients = g.gradient(loss.data, wb_tensors)\n\n    new_weights_and_biases = []\n    for v, dv in zip(self.weights + self.biases, gradients):\n      new_weights_and_biases.append(v - learning_rate * dv)\n\n    total_len = len(new_weights_and_biases)\n    self.weights = new_weights_and_biases[:total_len // 2]\n    self.biases = new_weights_and_biases[total_len // 2:]\n\n  def evaluate(self, x, y):\n    """"""Returns the number of correct predictions.\n\n    Args:\n      x: 2-d array of size batch_size x image_size.\n      y: 2-d array of size batch_size x num_classes.\n\n    Returns:\n      A scalar, the number of correct predictions.\n    """"""\n    y_actual = np.argmax(y, axis=1)\n    y_predicted = np.argmax(self.forward(x), axis=1)\n    return int(\n        np.sum(np.array(y_actual == y_predicted, copy=False, dtype=int32)))\n'"
trax/tf_numpy/examples/mnist/train.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Perform training.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl import app\nfrom absl import flags\n\nfrom six.moves import range\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.examples.mnist import dataset\nfrom trax.tf_numpy.examples.mnist import model as model_lib\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_integer(\'batch_size\', 50, \'Batch size.\')\nflags.DEFINE_integer(\'num_training_iters\', 10000,\n                     \'Number of iterations to train for.\')\nflags.DEFINE_integer(\n    \'validation_steps\', 100,\n    \'Validation is performed every these many training steps.\')\nflags.DEFINE_float(\'learning_rate\', 5.0, \'Learning rate.\')\n\n\ndef train(batch_size, learning_rate, num_training_iters, validation_steps):\n  """"""Runs the training.""""""\n  print(\'Loading data\')\n  training_data, validation_data, test_data = dataset.load()\n  print(\'Loaded dataset with {} training, {} validation and {} test examples.\'.\n        format(\n            len(training_data[0]), len(validation_data[0]), len(test_data[0])))\n\n  assert len(training_data[0]) % batch_size == 0\n  assert len(validation_data[0]) % batch_size == 0\n  assert len(test_data[0]) % batch_size == 0\n\n  def build_iterator(data, infinite=True):\n    """"""Build the iterator for inputs.""""""\n    index = 0\n    size = len(data[0])\n    while True:\n      if index + batch_size > size:\n        if infinite:\n          index = 0\n        else:\n          return\n      yield data[0][index:index + batch_size], data[1][index:index + batch_size]\n      index += batch_size\n\n  train_iter = build_iterator(training_data)\n  model = model_lib.Model([30])\n\n  for i in range(num_training_iters):\n    train_x, train_y = next(train_iter)\n    model.train(train_x, train_y, learning_rate)\n    if not (i + 1) % validation_steps:\n      validation_iter = build_iterator(validation_data, infinite=False)\n      correct_predictions = 0\n      for valid_x, valid_y in validation_iter:\n        correct_predictions += model.evaluate(valid_x, valid_y)\n      print(\'{}/{} correct validation predictions.\'.format(\n          correct_predictions, len(validation_data[0])))\n\n\ndef main(unused_argv):\n  train(FLAGS.batch_size, FLAGS.learning_rate, FLAGS.num_training_iters,\n        FLAGS.validation_steps)\n\n\nif __name__ == \'__main__\':\n  tf.compat.v1.enable_eager_execution()\n  app.run()\n'"
trax/tf_numpy/examples/mnist/train_test.py,3,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Test that the example training script works on fake data.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport mock\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.examples.mnist import dataset\nfrom trax.tf_numpy.examples.mnist import train\n\n\nclass TFNumpyMnistExampleTest(tf.test.TestCase):\n\n  def testRuns(self):\n    with mock.patch.object(dataset, \'load\', new=fake_mnist_data):\n      train.train(\n          batch_size=1,\n          learning_rate=0.1,\n          num_training_iters=10,\n          validation_steps=5)\n      train.train(\n          batch_size=2,\n          learning_rate=0.1,\n          num_training_iters=5,\n          validation_steps=2)\n      train.train(\n          batch_size=10,\n          learning_rate=0.1,\n          num_training_iters=1,\n          validation_steps=1)\n\n\ndef fake_mnist_data():\n\n  def gen_examples(num_examples):\n    x = np.array(\n        np.random.randn(num_examples, 784), copy=False, dtype=np.float32)\n    y = np.zeros((num_examples, 10), dtype=np.float32)\n    y[:][0] = 1.\n    return (x, y)\n\n  return (gen_examples(100), gen_examples(10), gen_examples(10))\n\n\nif __name__ == \'__main__\':\n  tf.compat.v1.enable_eager_execution()\n  tf.test.main()\n'"
trax/tf_numpy/numpy_impl/tests/array_ops_test.py,139,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for tf numpy array methods.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport itertools\nimport sys\nimport numpy as np\nfrom six.moves import range\nfrom six.moves import zip\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.numpy_impl import array_ops\nfrom trax.tf_numpy.numpy_impl import arrays\n\n\nclass ArrayCreationTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ArrayCreationTest, self).setUp()\n    python_shapes = [\n        0, 1, 2, (), (1,), (2,), (1, 2, 3), [], [1], [2], [1, 2, 3]\n    ]\n    self.shape_transforms = [\n        lambda x: x, lambda x: np.array(x, dtype=int),\n        lambda x: array_ops.array(x, dtype=int), tf.TensorShape\n    ]\n\n    self.all_shapes = []\n    for fn in self.shape_transforms:\n      self.all_shapes.extend([fn(s) for s in python_shapes])\n\n    if sys.version_info.major == 3:\n      # There is a bug of np.empty (and alike) in Python 3 causing a crash when\n      # the `shape` argument is an arrays.ndarray scalar (or tf.Tensor scalar).\n      def not_ndarray_scalar(s):\n        return not (isinstance(s, arrays.ndarray) and s.ndim == 0)\n      self.all_shapes = list(filter(not_ndarray_scalar, self.all_shapes))\n\n    self.all_types = [\n        int, float, np.int16, np.int32, np.int64, np.float16, np.float32,\n        np.float64\n    ]\n\n    source_array_data = [\n        1,\n        5.5,\n        7,\n        (),\n        (8, 10.),\n        ((), ()),\n        ((1, 4), (2, 8)),\n        [],\n        [7],\n        [8, 10.],\n        [[], []],\n        [[1, 4], [2, 8]],\n        ([], []),\n        ([1, 4], [2, 8]),\n        [(), ()],\n        [(1, 4), (2, 8)],\n    ]\n\n    self.array_transforms = [\n        lambda x: x,\n        tf.convert_to_tensor,\n        np.array,\n        array_ops.array,\n    ]\n    self.all_arrays = []\n    for fn in self.array_transforms:\n      self.all_arrays.extend([fn(s) for s in source_array_data])\n\n  def testEmpty(self):\n    for s in self.all_shapes:\n      actual = array_ops.empty(s)\n      expected = np.empty(s)\n      msg = \'shape: {}\'.format(s)\n      self.match_shape(actual, expected, msg)\n      self.match_dtype(actual, expected, msg)\n\n    for s, t in itertools.product(self.all_shapes, self.all_types):\n      actual = array_ops.empty(s, t)\n      expected = np.empty(s, t)\n      msg = \'shape: {}, dtype: {}\'.format(s, t)\n      self.match_shape(actual, expected, msg)\n      self.match_dtype(actual, expected, msg)\n\n  def testEmptyLike(self):\n    for a in self.all_arrays:\n      actual = array_ops.empty_like(a)\n      expected = np.empty_like(a)\n      msg = \'array: {}\'.format(a)\n      self.match_shape(actual, expected, msg)\n      self.match_dtype(actual, expected, msg)\n\n    for a, t in itertools.product(self.all_arrays, self.all_types):\n      actual = array_ops.empty_like(a, t)\n      expected = np.empty_like(a, t)\n      msg = \'array: {} type: {}\'.format(a, t)\n      self.match_shape(actual, expected, msg)\n      self.match_dtype(actual, expected, msg)\n\n  def testZeros(self):\n    for s in self.all_shapes:\n      actual = array_ops.zeros(s)\n      expected = np.zeros(s)\n      msg = \'shape: {}\'.format(s)\n      self.match(actual, expected, msg)\n\n    for s, t in itertools.product(self.all_shapes, self.all_types):\n      actual = array_ops.zeros(s, t)\n      expected = np.zeros(s, t)\n      msg = \'shape: {}, dtype: {}\'.format(s, t)\n      self.match(actual, expected, msg)\n\n  def testZerosLike(self):\n    for a in self.all_arrays:\n      actual = array_ops.zeros_like(a)\n      expected = np.zeros_like(a)\n      msg = \'array: {}\'.format(a)\n      self.match(actual, expected, msg)\n\n    for a, t in itertools.product(self.all_arrays, self.all_types):\n      actual = array_ops.zeros_like(a, t)\n      expected = np.zeros_like(a, t)\n      msg = \'array: {} type: {}\'.format(a, t)\n      self.match(actual, expected, msg)\n\n  def testOnes(self):\n    for s in self.all_shapes:\n      actual = array_ops.ones(s)\n      expected = np.ones(s)\n      msg = \'shape: {}\'.format(s)\n      self.match(actual, expected, msg)\n\n    for s, t in itertools.product(self.all_shapes, self.all_types):\n      actual = array_ops.ones(s, t)\n      expected = np.ones(s, t)\n      msg = \'shape: {}, dtype: {}\'.format(s, t)\n      self.match(actual, expected, msg)\n\n  def testOnesLike(self):\n    for a in self.all_arrays:\n      actual = array_ops.ones_like(a)\n      expected = np.ones_like(a)\n      msg = \'array: {}\'.format(a)\n      self.match(actual, expected, msg)\n\n    for a, t in itertools.product(self.all_arrays, self.all_types):\n      actual = array_ops.ones_like(a, t)\n      expected = np.ones_like(a, t)\n      msg = \'array: {} type: {}\'.format(a, t)\n      self.match(actual, expected, msg)\n\n  def testEye(self):\n    n_max = 3\n    m_max = 3\n\n    for n in range(1, n_max + 1):\n      self.match(array_ops.eye(n), np.eye(n))\n      for k in range(-n, n + 1):\n        self.match(array_ops.eye(n, k=k), np.eye(n, k=k))\n      for m in range(1, m_max + 1):\n        self.match(array_ops.eye(n, m), np.eye(n, m))\n        for k in range(-n, m):\n          self.match(array_ops.eye(n, k=k), np.eye(n, k=k))\n          self.match(array_ops.eye(n, m, k), np.eye(n, m, k))\n\n    for dtype in self.all_types:\n      for n in range(1, n_max + 1):\n        self.match(array_ops.eye(n, dtype=dtype), np.eye(n, dtype=dtype))\n        for k in range(-n, n + 1):\n          self.match(\n              array_ops.eye(n, k=k, dtype=dtype), np.eye(n, k=k, dtype=dtype))\n        for m in range(1, m_max + 1):\n          self.match(\n              array_ops.eye(n, m, dtype=dtype), np.eye(n, m, dtype=dtype))\n          for k in range(-n, m):\n            self.match(\n                array_ops.eye(n, k=k, dtype=dtype), np.eye(n, k=k, dtype=dtype))\n            self.match(\n                array_ops.eye(n, m, k, dtype=dtype),\n                np.eye(n, m, k, dtype=dtype))\n\n  def testIdentity(self):\n    n_max = 3\n\n    for n in range(1, n_max + 1):\n      self.match(array_ops.identity(n), np.identity(n))\n\n    for dtype in self.all_types:\n      for n in range(1, n_max + 1):\n        self.match(\n            array_ops.identity(n, dtype=dtype), np.identity(n, dtype=dtype))\n\n  def testFull(self):\n    # List of 2-tuples of fill value and shape.\n    data = [\n        (5, ()),\n        (5, (7,)),\n        (5., (7,)),\n        ([5, 8], (2,)),\n        ([5, 8], (3, 2)),\n        ([[5], [8]], (2, 3)),\n        ([[5], [8]], (3, 2, 5)),\n        ([[5.], [8.]], (3, 2, 5)),\n        ([[3, 4], [5, 6], [7, 8]], (3, 3, 2)),\n    ]\n    for f, s in data:\n      for fn1, fn2 in itertools.product(self.array_transforms,\n                                        self.shape_transforms):\n        fill_value = fn1(f)\n        shape = fn2(s)\n        self.match(\n            array_ops.full(shape, fill_value), np.full(shape, fill_value))\n        for dtype in self.all_types:\n          self.match(\n              array_ops.full(shape, fill_value, dtype=dtype),\n              np.full(shape, fill_value, dtype=dtype))\n\n  def testFullLike(self):\n    # List of 2-tuples of fill value and shape.\n    data = [\n        (5, ()),\n        (5, (7,)),\n        (5., (7,)),\n        ([5, 8], (2,)),\n        ([5, 8], (3, 2)),\n        ([[5], [8]], (2, 3)),\n        ([[5], [8]], (3, 2, 5)),\n        ([[5.], [8.]], (3, 2, 5)),\n    ]\n    zeros_builders = [array_ops.zeros, np.zeros]\n    for f, s in data:\n      for fn1, fn2, arr_dtype in itertools.product(\n          self.array_transforms, zeros_builders, self.all_types):\n        fill_value = fn1(f)\n        arr = fn2(s, arr_dtype)\n        self.match(\n            array_ops.full_like(arr, fill_value), np.full_like(arr, fill_value))\n        for dtype in self.all_types:\n          self.match(\n              array_ops.full_like(arr, fill_value, dtype=dtype),\n              np.full_like(arr, fill_value, dtype=dtype))\n\n  def testArray(self):\n    ndmins = [0, 1, 2, 5]\n    for a, dtype, ndmin, copy in itertools.product(\n        self.all_arrays, self.all_types, ndmins, [True, False]):\n      self.match(\n          array_ops.array(a, dtype=dtype, ndmin=ndmin, copy=copy),\n          np.array(a, dtype=dtype, ndmin=ndmin, copy=copy))\n\n    zeros_list = array_ops.zeros(5)\n\n    # TODO(srbs): Test that copy=True when context.device is different from\n    # tensor device copies the tensor.\n\n    # Backing tensor is the same if copy=False, other attributes being None.\n    self.assertIs(array_ops.array(zeros_list, copy=False).data, zeros_list.data)\n    self.assertIs(\n        array_ops.array(zeros_list.data, copy=False).data, zeros_list.data)\n\n    # Backing tensor is different if ndmin is not satisfied.\n    self.assertIsNot(\n        array_ops.array(zeros_list, copy=False, ndmin=2).data, zeros_list.data)\n    self.assertIsNot(\n        array_ops.array(zeros_list.data, copy=False, ndmin=2).data,\n        zeros_list.data)\n    self.assertIs(\n        array_ops.array(zeros_list, copy=False, ndmin=1).data, zeros_list.data)\n    self.assertIs(\n        array_ops.array(zeros_list.data, copy=False, ndmin=1).data,\n        zeros_list.data)\n\n    # Backing tensor is different if dtype is not satisfied.\n    self.assertIsNot(\n        array_ops.array(zeros_list, copy=False, dtype=int).data,\n        zeros_list.data)\n    self.assertIsNot(\n        array_ops.array(zeros_list.data, copy=False, dtype=int).data,\n        zeros_list.data)\n    self.assertIs(\n        array_ops.array(zeros_list, copy=False, dtype=float).data,\n        zeros_list.data)\n    self.assertIs(\n        array_ops.array(zeros_list.data, copy=False, dtype=float).data,\n        zeros_list.data)\n\n  def testAsArray(self):\n    for a, dtype in itertools.product(self.all_arrays, self.all_types):\n      self.match(array_ops.asarray(a, dtype=dtype), np.asarray(a, dtype=dtype))\n\n    zeros_list = array_ops.zeros(5)\n    # Same instance is returned if no dtype is specified and input is ndarray.\n    self.assertIs(array_ops.asarray(zeros_list), zeros_list)\n    # Different instance is returned if dtype is specified and input is ndarray.\n    self.assertIsNot(array_ops.asarray(zeros_list, dtype=int), zeros_list)\n\n  def testAsAnyArray(self):\n    for a, dtype in itertools.product(self.all_arrays, self.all_types):\n      self.match(\n          array_ops.asanyarray(a, dtype=dtype), np.asanyarray(a, dtype=dtype))\n    zeros_list = array_ops.zeros(5)\n    # Same instance is returned if no dtype is specified and input is ndarray.\n    self.assertIs(array_ops.asanyarray(zeros_list), zeros_list)\n    # Different instance is returned if dtype is specified and input is ndarray.\n    self.assertIsNot(array_ops.asanyarray(zeros_list, dtype=int), zeros_list)\n\n  def testAsContiguousArray(self):\n    for a, dtype in itertools.product(self.all_arrays, self.all_types):\n      self.match(\n          array_ops.ascontiguousarray(a, dtype=dtype),\n          np.ascontiguousarray(a, dtype=dtype))\n\n  def testARange(self):\n    int_values = np.arange(-3, 3).tolist()\n    float_values = np.arange(-3.5, 3.5).tolist()\n    all_values = int_values + float_values\n    for dtype in self.all_types:\n      for start in all_values:\n        msg = \'dtype:{} start:{}\'.format(dtype, start)\n        self.match(array_ops.arange(start), np.arange(start), msg=msg)\n        self.match(\n            array_ops.arange(start, dtype=dtype),\n            np.arange(start, dtype=dtype),\n            msg=msg)\n        for stop in all_values:\n          msg = \'dtype:{} start:{} stop:{}\'.format(dtype, start, stop)\n          self.match(\n              array_ops.arange(start, stop), np.arange(start, stop), msg=msg)\n          # TODO(srbs): Investigate and remove check.\n          # There are some bugs when start or stop is float and dtype is int.\n          if not isinstance(start, float) and not isinstance(stop, float):\n            self.match(\n                array_ops.arange(start, stop, dtype=dtype),\n                np.arange(start, stop, dtype=dtype),\n                msg=msg)\n          # Note: We intentionally do not test with float values for step\n          # because numpy.arange itself returns inconsistent results. e.g.\n          # np.arange(0.5, 3, step=0.5, dtype=int) returns\n          # array([0, 1, 2, 3, 4])\n          for step in int_values:\n            msg = \'dtype:{} start:{} stop:{} step:{}\'.format(\n                dtype, start, stop, step)\n            if not step:\n              with self.assertRaises(ValueError):\n                self.match(\n                    array_ops.arange(start, stop, step),\n                    np.arange(start, stop, step),\n                    msg=msg)\n                if not isinstance(start, float) and not isinstance(stop, float):\n                  self.match(\n                      array_ops.arange(start, stop, step, dtype=dtype),\n                      np.arange(start, stop, step, dtype=dtype),\n                      msg=msg)\n            else:\n              self.match(\n                  array_ops.arange(start, stop, step),\n                  np.arange(start, stop, step),\n                  msg=msg)\n              if not isinstance(start, float) and not isinstance(stop, float):\n                self.match(\n                    array_ops.arange(start, stop, step, dtype=dtype),\n                    np.arange(start, stop, step, dtype=dtype),\n                    msg=msg)\n\n  def testGeomSpace(self):\n\n    def run_test(start, stop, **kwargs):\n      arg1 = start\n      arg2 = stop\n      self.match(\n          array_ops.geomspace(arg1, arg2, **kwargs),\n          np.geomspace(arg1, arg2, **kwargs),\n          msg=\'geomspace({}, {})\'.format(arg1, arg2),\n          almost=True,\n          decimal=4)\n\n    run_test(1, 1000, num=5)\n    run_test(1, 1000, num=5, endpoint=False)\n    run_test(-1, -1000, num=5)\n    run_test(-1, -1000, num=5, endpoint=False)\n\n  def testDiag(self):\n    array_transforms = [\n        lambda x: x,  # Identity,\n        tf.convert_to_tensor,\n        np.array,\n        lambda x: np.array(x, dtype=np.float32),\n        lambda x: np.array(x, dtype=np.float64),\n        array_ops.array,\n        lambda x: array_ops.array(x, dtype=np.float32),\n        lambda x: array_ops.array(x, dtype=np.float64)\n    ]\n\n    def run_test(arr):\n      for fn in array_transforms:\n        arr = fn(arr)\n        self.match(\n            array_ops.diag(arr), np.diag(arr), msg=\'diag({})\'.format(arr))\n        for k in range(-3, 3):\n          self.match(\n              array_ops.diag(arr, k),\n              np.diag(arr, k),\n              msg=\'diag({}, k={})\'.format(arr, k))\n\n    # 2-d arrays.\n    run_test(np.arange(9).reshape((3, 3)).tolist())\n    run_test(np.arange(6).reshape((2, 3)).tolist())\n    run_test(np.arange(6).reshape((3, 2)).tolist())\n    run_test(np.arange(3).reshape((1, 3)).tolist())\n    run_test(np.arange(3).reshape((3, 1)).tolist())\n    run_test([[5]])\n    run_test([[]])\n    run_test([[], []])\n\n    # 1-d arrays.\n    run_test([])\n    run_test([1])\n    run_test([1, 2])\n\n  def testDiagFlat(self):\n    array_transforms = [\n        lambda x: x,  # Identity,\n        tf.convert_to_tensor,\n        np.array,\n        lambda x: np.array(x, dtype=np.float32),\n        lambda x: np.array(x, dtype=np.float64),\n        array_ops.array,\n        lambda x: array_ops.array(x, dtype=np.float32),\n        lambda x: array_ops.array(x, dtype=np.float64)\n    ]\n\n    def run_test(arr):\n      for fn in array_transforms:\n        arr = fn(arr)\n        self.match(\n            array_ops.diagflat(arr),\n            np.diagflat(arr),\n            msg=\'diagflat({})\'.format(arr))\n        for k in range(-3, 3):\n          self.match(\n              array_ops.diagflat(arr, k),\n              np.diagflat(arr, k),\n              msg=\'diagflat({}, k={})\'.format(arr, k))\n\n    # 1-d arrays.\n    run_test([])\n    run_test([1])\n    run_test([1, 2])\n    # 2-d arrays.\n    run_test([[]])\n    run_test([[5]])\n    run_test([[], []])\n    run_test(np.arange(4).reshape((2, 2)).tolist())\n    run_test(np.arange(2).reshape((2, 1)).tolist())\n    run_test(np.arange(2).reshape((1, 2)).tolist())\n    # 3-d arrays\n    run_test(np.arange(8).reshape((2, 2, 2)).tolist())\n\n  def match_shape(self, actual, expected, msg=None):\n    if msg:\n      msg = \'Shape match failed for: {}. Expected: {} Actual: {}\'.format(\n          msg, expected.shape, actual.shape)\n    self.assertEqual(actual.shape, expected.shape, msg=msg)\n    if msg:\n      msg = \'Shape: {} is not a tuple for {}\'.format(actual.shape, msg)\n    self.assertIsInstance(actual.shape, tuple, msg=msg)\n\n  def match_dtype(self, actual, expected, msg=None):\n    if msg:\n      msg = \'Dtype match failed for: {}. Expected: {} Actual: {}.\'.format(\n          msg, expected.dtype, actual.dtype)\n    self.assertEqual(actual.dtype, expected.dtype, msg=msg)\n\n  def match(self, actual, expected, msg=None, almost=False, decimal=7):\n    msg_ = \'Expected: {} Actual: {}\'.format(expected, actual)\n    if msg:\n      msg = \'{} {}\'.format(msg_, msg)\n    else:\n      msg = msg_\n    self.assertIsInstance(actual, arrays.ndarray)\n    self.match_dtype(actual, expected, msg)\n    self.match_shape(actual, expected, msg)\n    if not almost:\n      if not actual.shape:\n        self.assertEqual(actual.tolist(), expected.tolist())\n      else:\n        self.assertSequenceEqual(actual.tolist(), expected.tolist())\n    else:\n      np.testing.assert_almost_equal(\n          actual.tolist(), expected.tolist(), decimal=decimal)\n\n  def testIndexedSlices(self):\n    dtype = tf.int64\n    iss = tf.IndexedSlices(values=tf.ones([2, 3], dtype=dtype),\n                           indices=tf.constant([1, 9]),\n                           dense_shape=[10, 3])\n    a = array_ops.array(iss, copy=False)\n    expected = tf.scatter_nd([[1], [9]], tf.ones([2, 3], dtype=dtype), [10, 3])\n    self.assertAllEqual(expected, a)\n\n\nclass ArrayMethodsTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ArrayMethodsTest, self).setUp()\n    self.array_transforms = [\n        lambda x: x,\n        tf.convert_to_tensor,\n        np.array,\n        array_ops.array,\n    ]\n\n  def testAllAny(self):\n\n    def run_test(arr, *args, **kwargs):\n      for fn in self.array_transforms:\n        arr = fn(arr)\n        self.match(\n            array_ops.all(arr, *args, **kwargs), np.all(arr, *args, **kwargs))\n        self.match(\n            array_ops.any(arr, *args, **kwargs), np.any(arr, *args, **kwargs))\n\n    run_test(0)\n    run_test(1)\n    run_test([])\n    run_test([[True, False], [True, True]])\n    run_test([[True, False], [True, True]], axis=0)\n    run_test([[True, False], [True, True]], axis=0, keepdims=True)\n    run_test([[True, False], [True, True]], axis=1)\n    run_test([[True, False], [True, True]], axis=1, keepdims=True)\n    run_test([[True, False], [True, True]], axis=(0, 1))\n    run_test([[True, False], [True, True]], axis=(0, 1), keepdims=True)\n    run_test([5.2, 3.5], axis=0)\n    run_test([1, 0], axis=0)\n\n  def testCompress(self):\n\n    def run_test(condition, arr, *args, **kwargs):\n      for fn1 in self.array_transforms:\n        for fn2 in self.array_transforms:\n          arg1 = fn1(condition)\n          arg2 = fn2(arr)\n          self.match(\n              array_ops.compress(arg1, arg2, *args, **kwargs),\n              np.compress(\n                  np.asarray(arg1).astype(np.bool), arg2, *args, **kwargs))\n\n    run_test([True], 5)\n    run_test([False], 5)\n    run_test([], 5)\n    run_test([True, False, True], [1, 2, 3])\n    run_test([True, False], [1, 2, 3])\n    run_test([False, True], [[1, 2], [3, 4]])\n    run_test([1, 0, 1], [1, 2, 3])\n    run_test([1, 0], [1, 2, 3])\n    run_test([0, 1], [[1, 2], [3, 4]])\n    run_test([True], [[1, 2], [3, 4]])\n    run_test([False, True], [[1, 2], [3, 4]], axis=1)\n    run_test([False, True], [[1, 2], [3, 4]], axis=0)\n    run_test([False, True], [[1, 2], [3, 4]], axis=-1)\n    run_test([False, True], [[1, 2], [3, 4]], axis=-2)\n\n  def testCopy(self):\n\n    def run_test(arr, *args, **kwargs):\n      for fn in self.array_transforms:\n        arg = fn(arr)\n        self.match(\n            array_ops.copy(arg, *args, **kwargs), np.copy(arg, *args, **kwargs))\n\n    run_test([])\n    run_test([1, 2, 3])\n    run_test([1., 2., 3.])\n    run_test([True])\n    run_test(np.arange(9).reshape((3, 3)).tolist())\n\n  def testCumProdAndSum(self):\n\n    def run_test(arr, *args, **kwargs):\n      for fn in self.array_transforms:\n        arg = fn(arr)\n        self.match(\n            array_ops.cumprod(arg, *args, **kwargs),\n            np.cumprod(arg, *args, **kwargs))\n        self.match(\n            array_ops.cumsum(arg, *args, **kwargs),\n            np.cumsum(arg, *args, **kwargs))\n\n    run_test([])\n    run_test([1, 2, 3])\n    run_test([1, 2, 3], dtype=float)\n    run_test([1, 2, 3], dtype=np.float32)\n    run_test([1, 2, 3], dtype=np.float64)\n    run_test([1., 2., 3.])\n    run_test([1., 2., 3.], dtype=int)\n    run_test([1., 2., 3.], dtype=np.int32)\n    run_test([1., 2., 3.], dtype=np.int64)\n    run_test([[1, 2], [3, 4]], axis=1)\n    run_test([[1, 2], [3, 4]], axis=0)\n    run_test([[1, 2], [3, 4]], axis=-1)\n    run_test([[1, 2], [3, 4]], axis=-2)\n\n  def testImag(self):\n\n    def run_test(arr, *args, **kwargs):\n      for fn in self.array_transforms:\n        arg = fn(arr)\n        self.match(\n            array_ops.imag(arg, *args, **kwargs),\n            # np.imag may return a scalar so we convert to a np.ndarray.\n            np.array(np.imag(arg, *args, **kwargs)))\n\n    run_test(1)\n    run_test(5.5)\n    run_test(5 + 3j)\n    run_test(3j)\n    run_test([])\n    run_test([1, 2, 3])\n    run_test([1 + 5j, 2 + 3j])\n    run_test([[1 + 5j, 2 + 3j], [1 + 7j, 2 + 8j]])\n\n  def testAMaxAMin(self):\n\n    def run_test(arr, *args, **kwargs):\n      axis = kwargs.pop(\'axis\', None)\n      for fn1 in self.array_transforms:\n        for fn2 in self.array_transforms:\n          arr_arg = fn1(arr)\n          axis_arg = fn2(axis) if axis is not None else None\n          self.match(\n              array_ops.amax(arr_arg, axis=axis_arg, *args, **kwargs),\n              np.amax(arr_arg, axis=axis, *args, **kwargs))\n          self.match(\n              array_ops.amin(arr_arg, axis=axis_arg, *args, **kwargs),\n              np.amin(arr_arg, axis=axis, *args, **kwargs))\n\n    run_test([1, 2, 3])\n    run_test([1., 2., 3.])\n    run_test([[1, 2], [3, 4]], axis=1)\n    run_test([[1, 2], [3, 4]], axis=0)\n    run_test([[1, 2], [3, 4]], axis=-1)\n    run_test([[1, 2], [3, 4]], axis=-2)\n    run_test([[1, 2], [3, 4]], axis=(0, 1))\n    run_test(np.arange(8).reshape((2, 2, 2)).tolist(), axis=(0, 2))\n    run_test(\n        np.arange(8).reshape((2, 2, 2)).tolist(), axis=(0, 2), keepdims=True)\n    run_test(np.arange(8).reshape((2, 2, 2)).tolist(), axis=(2, 0))\n    run_test(\n        np.arange(8).reshape((2, 2, 2)).tolist(), axis=(2, 0), keepdims=True)\n\n  def testMean(self):\n\n    def run_test(arr, *args, **kwargs):\n      axis = kwargs.pop(\'axis\', None)\n      for fn1 in self.array_transforms:\n        for fn2 in self.array_transforms:\n          arr_arg = fn1(arr)\n          axis_arg = fn2(axis) if axis is not None else None\n          self.match(\n              array_ops.mean(arr_arg, axis=axis_arg, *args, **kwargs),\n              np.mean(arr_arg, axis=axis, *args, **kwargs))\n\n    run_test([1, 2, 1])\n    run_test([1., 2., 1.])\n    run_test([1., 2., 1.], dtype=int)\n    run_test([[1, 2], [3, 4]], axis=1)\n    run_test([[1, 2], [3, 4]], axis=0)\n    run_test([[1, 2], [3, 4]], axis=-1)\n    run_test([[1, 2], [3, 4]], axis=-2)\n    run_test([[1, 2], [3, 4]], axis=(0, 1))\n    run_test(np.arange(8).reshape((2, 2, 2)).tolist(), axis=(0, 2))\n    run_test(\n        np.arange(8).reshape((2, 2, 2)).tolist(), axis=(0, 2), keepdims=True)\n    run_test(np.arange(8).reshape((2, 2, 2)).tolist(), axis=(2, 0))\n    run_test(\n        np.arange(8).reshape((2, 2, 2)).tolist(), axis=(2, 0), keepdims=True)\n\n  def testProd(self):\n\n    def run_test(arr, *args, **kwargs):\n      for fn in self.array_transforms:\n        arg = fn(arr)\n        self.match(\n            array_ops.prod(arg, *args, **kwargs), np.prod(arg, *args, **kwargs))\n\n    run_test([1, 2, 3])\n    run_test([1., 2., 3.])\n    run_test(np.array([1, 2, 3], dtype=np.int16))\n    run_test([[1, 2], [3, 4]], axis=1)\n    run_test([[1, 2], [3, 4]], axis=0)\n    run_test([[1, 2], [3, 4]], axis=-1)\n    run_test([[1, 2], [3, 4]], axis=-2)\n    run_test([[1, 2], [3, 4]], axis=(0, 1))\n    run_test(np.arange(8).reshape((2, 2, 2)).tolist(), axis=(0, 2))\n    run_test(\n        np.arange(8).reshape((2, 2, 2)).tolist(), axis=(0, 2), keepdims=True)\n    run_test(np.arange(8).reshape((2, 2, 2)).tolist(), axis=(2, 0))\n    run_test(\n        np.arange(8).reshape((2, 2, 2)).tolist(), axis=(2, 0), keepdims=True)\n\n  def _testReduce(self, math_fun, np_fun, name):\n    axis_transforms = [\n        lambda x: x,  # Identity,\n        tf.convert_to_tensor,\n        np.array,\n        array_ops.array,\n        lambda x: array_ops.array(x, dtype=np.float32),\n        lambda x: array_ops.array(x, dtype=np.float64),\n    ]\n\n    def run_test(a, **kwargs):\n      axis = kwargs.pop(\'axis\', None)\n      for fn1 in self.array_transforms:\n        for fn2 in axis_transforms:\n          arg1 = fn1(a)\n          axis_arg = fn2(axis) if axis is not None else None\n          self.match(\n              math_fun(arg1, axis=axis_arg, **kwargs),\n              np_fun(arg1, axis=axis, **kwargs),\n              msg=\'{}({}, axis={}, keepdims={})\'.format(\n                  name, arg1, axis, kwargs.get(\'keepdims\')))\n\n    run_test(5)\n    run_test([2, 3])\n    run_test([[2, -3], [-6, 7]])\n    run_test([[2, -3], [-6, 7]], axis=0)\n    run_test([[2, -3], [-6, 7]], axis=0, keepdims=True)\n    run_test([[2, -3], [-6, 7]], axis=1)\n    run_test([[2, -3], [-6, 7]], axis=1, keepdims=True)\n    run_test([[2, -3], [-6, 7]], axis=(0, 1))\n    run_test([[2, -3], [-6, 7]], axis=(1, 0))\n\n  def testSum(self):\n    self._testReduce(array_ops.sum, np.sum, \'sum\')\n\n  def testAmax(self):\n    self._testReduce(array_ops.amax, np.amax, \'amax\')\n\n  def testRavel(self):\n\n    def run_test(arr, *args, **kwargs):\n      for fn in self.array_transforms:\n        arg = fn(arr)\n        self.match(\n            array_ops.ravel(arg, *args, **kwargs),\n            np.ravel(arg, *args, **kwargs))\n\n    run_test(5)\n    run_test(5.)\n    run_test([])\n    run_test([[]])\n    run_test([[], []])\n    run_test([1, 2, 3])\n    run_test([1., 2., 3.])\n    run_test([[1, 2], [3, 4]])\n    run_test(np.arange(8).reshape((2, 2, 2)).tolist())\n\n  def testReal(self):\n\n    def run_test(arr, *args, **kwargs):\n      for fn in self.array_transforms:\n        arg = fn(arr)\n        self.match(\n            array_ops.real(arg, *args, **kwargs),\n            np.array(np.real(arg, *args, **kwargs)))\n\n    run_test(1)\n    run_test(5.5)\n    run_test(5 + 3j)\n    run_test(3j)\n    run_test([])\n    run_test([1, 2, 3])\n    run_test([1 + 5j, 2 + 3j])\n    run_test([[1 + 5j, 2 + 3j], [1 + 7j, 2 + 8j]])\n\n  def testRepeat(self):\n\n    def run_test(arr, repeats, *args, **kwargs):\n      for fn1 in self.array_transforms:\n        for fn2 in self.array_transforms:\n          arr_arg = fn1(arr)\n          repeats_arg = fn2(repeats)\n          self.match(\n              array_ops.repeat(arr_arg, repeats_arg, *args, **kwargs),\n              np.repeat(arr_arg, repeats_arg, *args, **kwargs))\n\n    run_test(1, 2)\n    run_test([1, 2], 2)\n    run_test([1, 2], [2])\n    run_test([1, 2], [1, 2])\n    run_test([[1, 2], [3, 4]], 3, axis=0)\n    run_test([[1, 2], [3, 4]], 3, axis=1)\n    run_test([[1, 2], [3, 4]], [3], axis=0)\n    run_test([[1, 2], [3, 4]], [3], axis=1)\n    run_test([[1, 2], [3, 4]], [3, 2], axis=0)\n    run_test([[1, 2], [3, 4]], [3, 2], axis=1)\n    run_test([[1, 2], [3, 4]], [3, 2], axis=-1)\n    run_test([[1, 2], [3, 4]], [3, 2], axis=-2)\n\n  def testAround(self):\n\n    def run_test(arr, *args, **kwargs):\n      for fn in self.array_transforms:\n        arg = fn(arr)\n        self.match(\n            array_ops.around(arg, *args, **kwargs),\n            np.around(arg, *args, **kwargs))\n\n    run_test(5.5)\n    run_test(5.567, decimals=2)\n    run_test([])\n    run_test([1.27, 2.49, 2.75], decimals=1)\n    run_test([23.6, 45.1], decimals=-1)\n\n  def testReshape(self):\n\n    def run_test(arr, newshape, *args, **kwargs):\n      for fn1 in self.array_transforms:\n        for fn2 in self.array_transforms:\n          arr_arg = fn1(arr)\n          newshape_arg = fn2(newshape)\n          self.match(\n              array_ops.reshape(arr_arg, newshape_arg, *args, **kwargs),\n              np.reshape(arr_arg, newshape, *args, **kwargs))\n\n    run_test(5, [-1])\n    run_test([], [-1])\n    run_test([1, 2, 3], [1, 3])\n    run_test([1, 2, 3], [3, 1])\n    run_test([1, 2, 3, 4], [2, 2])\n    run_test([1, 2, 3, 4], [2, 1, 2])\n\n  def testExpandDims(self):\n\n    def run_test(arr, axis):\n      self.match(array_ops.expand_dims(arr, axis), np.expand_dims(arr, axis))\n\n    run_test([1, 2, 3], 0)\n    run_test([1, 2, 3], 1)\n\n  def testSqueeze(self):\n\n    def run_test(arr, *args, **kwargs):\n      for fn in self.array_transforms:\n        arg = fn(arr)\n        # Note: np.squeeze ignores the axis arg for non-ndarray objects.\n        # This looks like a bug: https://github.com/numpy/numpy/issues/8201\n        # So we convert the arg to np.ndarray before passing to np.squeeze.\n        self.match(\n            array_ops.squeeze(arg, *args, **kwargs),\n            np.squeeze(np.array(arg), *args, **kwargs))\n\n    run_test(5)\n    run_test([])\n    run_test([5])\n    run_test([[1, 2, 3]])\n    run_test([[[1], [2], [3]]])\n    run_test([[[1], [2], [3]]], axis=0)\n    run_test([[[1], [2], [3]]], axis=2)\n    run_test([[[1], [2], [3]]], axis=(0, 2))\n    run_test([[[1], [2], [3]]], axis=-1)\n    run_test([[[1], [2], [3]]], axis=-3)\n\n  def testTranspose(self):\n\n    def run_test(arr, axes=None):\n      for fn1 in self.array_transforms:\n        for fn2 in self.array_transforms:\n          arr_arg = fn1(arr)\n          axes_arg = fn2(axes) if axes is not None else None\n          self.match(\n              array_ops.transpose(arr_arg, axes_arg),\n              np.transpose(arr_arg, axes))\n\n    run_test(5)\n    run_test([])\n    run_test([5])\n    run_test([5, 6, 7])\n    run_test(np.arange(30).reshape(2, 3, 5).tolist())\n    run_test(np.arange(30).reshape(2, 3, 5).tolist(), [0, 1, 2])\n    run_test(np.arange(30).reshape(2, 3, 5).tolist(), [0, 2, 1])\n    run_test(np.arange(30).reshape(2, 3, 5).tolist(), [1, 0, 2])\n    run_test(np.arange(30).reshape(2, 3, 5).tolist(), [1, 2, 0])\n    run_test(np.arange(30).reshape(2, 3, 5).tolist(), [2, 0, 1])\n    run_test(np.arange(30).reshape(2, 3, 5).tolist(), [2, 1, 0])\n\n  def testSetItem(self):\n\n    def run_test(arr, index, value):\n      for fn in self.array_transforms:\n        value_arg = fn(value)\n        tf_array = array_ops.array(arr)\n        np_array = np.array(arr)\n        tf_array[index] = value_arg\n        # TODO(srbs): ""setting an array element with a sequence"" is thrown\n        # if we do not wrap value_arg in a numpy array. Investigate how this can\n        # be avoided.\n        np_array[index] = np.array(value_arg)\n        self.match(tf_array, np_array)\n\n    run_test([1, 2, 3], 1, 5)\n    run_test([[1, 2], [3, 4]], 0, [6, 7])\n    run_test([[1, 2], [3, 4]], 1, [6, 7])\n    run_test([[1, 2], [3, 4]], (0, 1), 6)\n    run_test([[1, 2], [3, 4]], 0, 6)  # Value needs to broadcast.\n\n  def match_shape(self, actual, expected, msg=None):\n    if msg:\n      msg = \'Shape match failed for: {}. Expected: {} Actual: {}\'.format(\n          msg, expected.shape, actual.shape)\n    self.assertEqual(actual.shape, expected.shape, msg=msg)\n    if msg:\n      msg = \'Shape: {} is not a tuple for {}\'.format(actual.shape, msg)\n    self.assertIsInstance(actual.shape, tuple, msg=msg)\n\n  def match_dtype(self, actual, expected, msg=None):\n    if msg:\n      msg = \'Dtype match failed for: {}. Expected: {} Actual: {}.\'.format(\n          msg, expected.dtype, actual.dtype)\n    self.assertEqual(actual.dtype, expected.dtype, msg=msg)\n\n  def match(self, actual, expected, msg=None, check_dtype=True):\n    msg_ = \'Expected: {} Actual: {}\'.format(expected, actual)\n    if msg:\n      msg = \'{} {}\'.format(msg_, msg)\n    else:\n      msg = msg_\n    self.assertIsInstance(actual, arrays.ndarray)\n    if check_dtype:\n      self.match_dtype(actual, expected, msg)\n    self.match_shape(actual, expected, msg)\n    if not actual.shape:\n      self.assertAllClose(actual.tolist(), expected.tolist())\n    else:\n      self.assertAllClose(actual.tolist(), expected.tolist())\n\n  def testPad(self):\n    t = [[1, 2, 3], [4, 5, 6]]\n    paddings = [[1, 1,], [2, 2]]\n    self.assertAllEqual(\n        array_ops.pad(t, paddings, \'constant\'),\n        [[0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 2, 3, 0, 0], [0, 0, 4, 5, 6, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0]])\n\n    self.assertAllEqual(\n        array_ops.pad(t, paddings, \'reflect\'),\n        [[6, 5, 4, 5, 6, 5, 4], [3, 2, 1, 2, 3, 2, 1], [6, 5, 4, 5, 6, 5, 4],\n         [3, 2, 1, 2, 3, 2, 1]])\n\n    self.assertAllEqual(\n        array_ops.pad(t, paddings, \'symmetric\'),\n        [[2, 1, 1, 2, 3, 3, 2], [2, 1, 1, 2, 3, 3, 2], [5, 4, 4, 5, 6, 6, 5],\n         [5, 4, 4, 5, 6, 6, 5]])\n\n  def testTake(self):\n    a = [4, 3, 5, 7, 6, 8]\n    indices = [0, 1, 4]\n    self.assertAllEqual([4, 3, 6], array_ops.take(a, indices))\n    indices = [[0, 1], [2, 3]]\n    self.assertAllEqual([[4, 3], [5, 7]], array_ops.take(a, indices))\n    a = [[4, 3, 5], [7, 6, 8]]\n    self.assertAllEqual([[4, 3], [5, 7]], array_ops.take(a, indices))\n    a = np.random.rand(2, 16, 3)\n    axis = 1\n    self.assertAllEqual(\n        np.take(a, indices, axis=axis), array_ops.take(a, indices, axis=axis))\n\n  def testWhere(self):\n    self.assertAllEqual([[1.0, 1.0], [1.0, 1.0]],\n                        array_ops.where([True], [1.0, 1.0], [[0, 0], [0, 0]]))\n\n  def testShape(self):\n    self.assertAllEqual((1, 2), array_ops.shape([[0, 0]]))\n\n  def testSwapaxes(self):\n    x = [[1, 2, 3]]\n    self.assertAllEqual([[1], [2], [3]], array_ops.swapaxes(x, 0, 1))\n    self.assertAllEqual([[1], [2], [3]], array_ops.swapaxes(x, -2, -1))\n    x = [[[0, 1], [2, 3]], [[4, 5], [6, 7]]]\n    self.assertAllEqual([[[0, 4], [2, 6]], [[1, 5], [3, 7]]],\n                        array_ops.swapaxes(x, 0, 2))\n    self.assertAllEqual([[[0, 4], [2, 6]], [[1, 5], [3, 7]]],\n                        array_ops.swapaxes(x, -3, -1))\n\n  def testMoveaxis(self):\n\n    def _test(*args):\n      expected = np.moveaxis(*args)\n      raw_ans = array_ops.moveaxis(*args)\n\n      self.assertAllEqual(expected, raw_ans)\n\n    a = np.random.rand(1, 2, 3, 4, 5, 6)\n\n    # Basic\n    _test(a, (0, 2), (3, 5))\n    _test(a, (0, 2), (-1, -3))\n    _test(a, (-6, -4), (3, 5))\n    _test(a, (-6, -4), (-1, -3))\n    _test(a, 0, 4)\n    _test(a, -6, -2)\n    _test(a, tuple(range(6)), tuple(range(6)))\n    _test(a, tuple(range(6)), tuple(reversed(range(6))))\n    _test(a, (), ())\n\n  def testNdim(self):\n    self.assertAllEqual(0, array_ops.ndim(0.5))\n    self.assertAllEqual(1, array_ops.ndim([1, 2]))\n\n  def testIsscalar(self):\n    self.assertTrue(array_ops.isscalar(0.5))\n    self.assertTrue(array_ops.isscalar(5))\n    self.assertTrue(array_ops.isscalar(False))\n    self.assertFalse(array_ops.isscalar([1, 2]))\n\n  def assertListEqual(self, a, b):\n    self.assertAllEqual(len(a), len(b))\n    for x, y in zip(a, b):\n      self.assertAllEqual(x, y)\n\n  def testSplit(self):\n    x = array_ops.arange(9)\n    y = array_ops.split(x, 3)\n    self.assertListEqual([([0, 1, 2]),\n                          ([3, 4, 5]),\n                          ([6, 7, 8])], y)\n\n    x = array_ops.arange(8)\n    y = array_ops.split(x, [3, 5, 6, 10])\n    self.assertListEqual([([0, 1, 2]),\n                          ([3, 4]),\n                          ([5]),\n                          ([6, 7]),\n                          ([])], y)\n\n\nclass ArrayManipulationTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(ArrayManipulationTest, self).setUp()\n    self.array_transforms = [\n        lambda x: x,\n        tf.convert_to_tensor,\n        np.array,\n        array_ops.array,\n    ]\n\n  def testBroadcastTo(self):\n\n    def run_test(arr, shape):\n      for fn in self.array_transforms:\n        arg1 = fn(arr)\n        self.match(\n            array_ops.broadcast_to(arg1, shape), np.broadcast_to(arg1, shape))\n\n    run_test(1, 2)\n    run_test(1, (2, 2))\n    run_test([1, 2], (2, 2))\n    run_test([[1], [2]], (2, 2))\n    run_test([[1, 2]], (3, 2))\n    run_test([[[1, 2]], [[3, 4]], [[5, 6]]], (3, 4, 2))\n\n  def testIx_(self):\n    possible_arys = [[True, True], [True, False], [False, False],\n                     list(range(5)), array_ops.empty(0, dtype=np.int64)]\n    for r in range(len(possible_arys)):\n      for arys in itertools.combinations_with_replacement(possible_arys, r):\n        tnp_ans = array_ops.ix_(*arys)\n        onp_ans = np.ix_(*arys)\n        for t, o in zip(tnp_ans, onp_ans):\n          self.match(t, o)\n\n  def match_shape(self, actual, expected, msg=None):\n    if msg:\n      msg = \'Shape match failed for: {}. Expected: {} Actual: {}\'.format(\n          msg, expected.shape, actual.shape)\n    self.assertEqual(actual.shape, expected.shape, msg=msg)\n    if msg:\n      msg = \'Shape: {} is not a tuple for {}\'.format(actual.shape, msg)\n    self.assertIsInstance(actual.shape, tuple, msg=msg)\n\n  def match_dtype(self, actual, expected, msg=None):\n    if msg:\n      msg = \'Dtype match failed for: {}. Expected: {} Actual: {}.\'.format(\n          msg, expected.dtype, actual.dtype)\n    self.assertEqual(actual.dtype, expected.dtype, msg=msg)\n\n  def match(self, actual, expected, msg=None):\n    msg_ = \'Expected: {} Actual: {}\'.format(expected, actual)\n    if msg:\n      msg = \'{} {}\'.format(msg_, msg)\n    else:\n      msg = msg_\n    self.assertIsInstance(actual, arrays.ndarray)\n    self.match_dtype(actual, expected, msg)\n    self.match_shape(actual, expected, msg)\n    if not actual.shape:\n      self.assertEqual(actual.tolist(), expected.tolist())\n    else:\n      self.assertSequenceEqual(actual.tolist(), expected.tolist())\n\n\nif __name__ == \'__main__\':\n  tf.compat.v1.enable_eager_execution()\n  tf.test.main()\n'"
trax/tf_numpy/numpy_impl/tests/arrays_test.py,34,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for ndarray.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.numpy_impl import arrays\n# Required for operator overloads\nfrom trax.tf_numpy.numpy_impl import math_ops  # pylint: disable=unused-import\n\n\nt2a = arrays.tensor_to_ndarray\n\n\nclass ArrayTest(tf.test.TestCase):\n\n  def testDtype(self):\n    a = t2a(tf.zeros(shape=[1, 2], dtype=tf.int64))\n    self.assertIs(a.dtype.type, np.int64)\n    self.assertAllEqual(0, a.dtype.type(0))\n\n  def testAstype(self):\n    a = t2a(tf.convert_to_tensor(value=1.1, dtype=tf.float32)).astype(np.int32)\n    self.assertIs(a.dtype.type, np.int32)\n    self.assertAllEqual(1, a)\n    a = t2a(tf.convert_to_tensor(value=[0.0, 1.1],\n                                 dtype=tf.float32)).astype(np.bool_)\n    self.assertIs(a.dtype.type, np.bool_)\n    self.assertAllEqual([False, True], a)\n\n  def testNeg(self):\n    a = t2a(tf.convert_to_tensor(value=[1.0, 2.0]))\n    self.assertAllEqual([-1.0, -2.0], -a)\n\n  def _testBinOp(self, a, b, out, f, types=None):\n    a = t2a(tf.convert_to_tensor(value=a, dtype=np.int32))\n    b = t2a(tf.convert_to_tensor(value=b, dtype=np.int32))\n    if not isinstance(out, arrays.ndarray):\n      out = t2a(tf.convert_to_tensor(value=out, dtype=np.int32))\n    if types is None:\n      types = [[np.int32, np.int32, np.int32],\n               [np.int64, np.int32, np.int64],\n               [np.int32, np.int64, np.int64],\n               [np.float32, np.int32, np.float64],\n               [np.int32, np.float32, np.float64],\n               [np.float32, np.float32, np.float32],\n               [np.float64, np.float32, np.float64],\n               [np.float32, np.float64, np.float64]]\n    for a_type, b_type, out_type in types:\n      o = f(a.astype(a_type), b.astype(b_type))\n      self.assertIs(o.dtype.type, out_type)\n      self.assertAllEqual(out.astype(out_type), o)\n\n  def testAdd(self):\n    self._testBinOp([1, 2], [3, 4], [4, 6], lambda a, b: a.__add__(b))\n\n  def testRadd(self):\n    self._testBinOp([1, 2], [3, 4], [4, 6], lambda a, b: b.__radd__(a))\n\n  def testSub(self):\n    self._testBinOp([1, 2], [3, 5], [-2, -3], lambda a, b: a.__sub__(b))\n\n  def testRsub(self):\n    self._testBinOp([1, 2], [3, 5], [-2, -3], lambda a, b: b.__rsub__(a))\n\n  def testMul(self):\n    self._testBinOp([1, 2], [3, 4], [3, 8], lambda a, b: a.__mul__(b))\n\n  def testRmul(self):\n    self._testBinOp([1, 2], [3, 4], [3, 8], lambda a, b: b.__rmul__(a))\n\n  def testPow(self):\n    self._testBinOp([4, 5], [3, 2], [64, 25], lambda a, b: a.__pow__(b))\n\n  def testRpow(self):\n    self._testBinOp([4, 5], [3, 2], [64, 25], lambda a, b: b.__rpow__(a))\n\n  _truediv_types = [[np.int32, np.int32, np.float64],\n                    [np.int64, np.int32, np.float64],\n                    [np.int32, np.int64, np.float64],\n                    [np.float32, np.int32, np.float64],\n                    [np.int32, np.float32, np.float64],\n                    [np.float32, np.float32, np.float32],\n                    [np.float64, np.float32, np.float64],\n                    [np.float32, np.float64, np.float64]]\n\n  def testTruediv(self):\n    self._testBinOp([3, 5], [2, 4],\n                    t2a(tf.convert_to_tensor(value=[1.5, 1.25])),\n                    lambda a, b: a.__truediv__(b), types=self._truediv_types)\n\n  def testRtruediv(self):\n    self._testBinOp([3, 5], [2, 4],\n                    t2a(tf.convert_to_tensor(value=[1.5, 1.25])),\n                    lambda a, b: b.__rtruediv__(a), types=self._truediv_types)\n\n  def _testCmp(self, a, b, out, f):\n    a = t2a(tf.convert_to_tensor(value=a, dtype=np.int32))\n    b = t2a(tf.convert_to_tensor(value=b, dtype=np.int32))\n    types = [[np.int32, np.int32],\n             [np.int64, np.int32],\n             [np.int32, np.int64],\n             [np.float32, np.int32],\n             [np.int32, np.float32],\n             [np.float32, np.float32],\n             [np.float64, np.float32],\n             [np.float32, np.float64]]\n    for a_type, b_type in types:\n      o = f(a.astype(a_type), b.astype(b_type))\n      self.assertAllEqual(out, o)\n\n  def testLt(self):\n    self._testCmp([1, 2, 3], [3, 2, 1], [True, False, False],\n                  lambda a, b: a.__lt__(b))\n\n  def testLe(self):\n    self._testCmp([1, 2, 3], [3, 2, 1], [True, True, False],\n                  lambda a, b: a.__le__(b))\n\n  def testGt(self):\n    self._testCmp([1, 2, 3], [3, 2, 1], [False, False, True],\n                  lambda a, b: a.__gt__(b))\n\n  def testGe(self):\n    self._testCmp([1, 2, 3], [3, 2, 1], [False, True, True],\n                  lambda a, b: a.__ge__(b))\n\n  def testEq(self):\n    self._testCmp([1, 2, 3], [3, 2, 1], [False, True, False],\n                  lambda a, b: a.__eq__(b))\n\n  def testNe(self):\n    self._testCmp([1, 2, 3], [3, 2, 1], [True, False, True],\n                  lambda a, b: a.__ne__(b))\n\n  def testInt(self):\n    v = 10\n    u = int(t2a(tf.convert_to_tensor(value=v)))\n    self.assertIsInstance(u, int)\n    self.assertAllEqual(v, u)\n\n  def testFloat(self):\n    v = 21.32\n    u = float(t2a(tf.convert_to_tensor(value=v)))\n    self.assertIsInstance(u, float)\n    self.assertAllClose(v, u)\n\n  def testBool(self):\n    b = bool(t2a(tf.convert_to_tensor(value=10)))\n    self.assertIsInstance(b, bool)\n    self.assertTrue(b)\n    self.assertFalse(bool(t2a(tf.convert_to_tensor(value=0))))\n    self.assertTrue(bool(t2a(tf.convert_to_tensor(value=0.1))))\n    self.assertFalse(bool(t2a(tf.convert_to_tensor(value=0.0))))\n\n  def testHash(self):\n    a = t2a(tf.convert_to_tensor(value=10))\n    self.assertNotIsInstance(a, collections.Hashable)\n    with self.assertRaisesWithPredicateMatch(\n        TypeError, r\'unhashable type\'):\n      hash(a)\n\n\nif __name__ == \'__main__\':\n  tf.compat.v1.enable_eager_execution()\n  tf.test.main()\n'"
trax/tf_numpy/numpy_impl/tests/backprop_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for backpropgration on tf-numpy functions.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.numpy_impl import array_ops\n# Required for operator overloads\nfrom trax.tf_numpy.numpy_impl import math_ops  # pylint: disable=unused-import\n\n\nclass BackpropTest(tf.test.TestCase):\n\n  def test_setitem(self):\n    # Single integer index.\n    a = array_ops.array([1., 2., 3.])\n    b = array_ops.array(5.)\n    c = array_ops.array(10.)\n\n    tensors = [arr.data for arr in [a, b, c]]\n    with tf.GradientTape() as g:\n      g.watch(tensors)\n      a[1] = b + c\n      loss = array_ops.sum(a)\n\n    gradients = g.gradient(loss.data, tensors)\n    self.assertSequenceEqual(\n        array_ops.array(gradients[0]).tolist(), [1., 0., 1.])\n    self.assertEqual(array_ops.array(gradients[1]).tolist(), 1.)\n    self.assertEqual(array_ops.array(gradients[2]).tolist(), 1.)\n\n    # Tuple index.\n    a = array_ops.array([[[1., 2.], [3., 4.]], [[5., 6.],\n                                                [7., 8.]]])  # 2x2x2 array.\n    b = array_ops.array([10., 11.])\n\n    tensors = [arr.data for arr in [a, b]]\n    with tf.GradientTape() as g:\n      g.watch(tensors)\n      a[(1, 0)] = b\n      loss = array_ops.sum(a)\n\n    gradients = g.gradient(loss.data, tensors)\n    self.assertSequenceEqual(\n        array_ops.array(gradients[0]).tolist(),\n        [[[1., 1.], [1., 1.]], [[0., 0.], [1., 1.]]])\n    self.assertEqual(array_ops.array(gradients[1]).tolist(), [1., 1.])\n\n\nif __name__ == \'__main__\':\n  tf.compat.v1.enable_eager_execution()\n  tf.test.main()\n'"
trax/tf_numpy/numpy_impl/tests/logic_test.py,6,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for tf numpy random number methods.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.numpy_impl import array_ops\nfrom trax.tf_numpy.numpy_impl import arrays\nfrom trax.tf_numpy.numpy_impl import math_ops\n\n\nclass LogicTest(tf.test.TestCase):\n\n  def setUp(self):\n    super(LogicTest, self).setUp()\n    self.array_transforms = [\n        lambda x: x,  # Identity,\n        tf.convert_to_tensor,\n        np.array,\n        lambda x: np.array(x, dtype=np.int32),\n        lambda x: np.array(x, dtype=np.int64),\n        lambda x: np.array(x, dtype=np.float32),\n        lambda x: np.array(x, dtype=np.float64),\n        array_ops.array,\n        lambda x: array_ops.array(x, dtype=tf.int32),\n        lambda x: array_ops.array(x, dtype=tf.int64),\n        lambda x: array_ops.array(x, dtype=tf.float32),\n        lambda x: array_ops.array(x, dtype=tf.float64),\n    ]\n\n  def testEqual(self):\n\n    def run_test(x1, x2=None):\n      if x2 is None:\n        x2 = x1\n      for fn1 in self.array_transforms:\n        for fn2 in self.array_transforms:\n          arg1 = fn1(x1)\n          arg2 = fn2(x2)\n          self.match(\n              math_ops.equal(arg1, arg2),\n              np.equal(\n                  make_numpy_compatible(arg1), make_numpy_compatible(arg2)))\n\n    run_test(1)\n    run_test(1, 2)\n    run_test([1, 2])\n    run_test([1, 2, 3], [2])\n    run_test([[1, 2], [3, 4]], [1, 2])\n    run_test([[1, 2], [1, 4]], [1, 2])\n    run_test([1, 2], [[1, 2], [1, 4]])\n    run_test([[1, 2], [3, 4]], [[1, 2], [3, 4]])\n    run_test([[1, 2], [3, 4]], [[1, 3], [3, 4]])\n\n  def match_shape(self, actual, expected, msg=None):\n    if msg:\n      msg = \'Shape match failed for: {}. Expected: {} Actual: {}\'.format(\n          msg, expected.shape, actual.shape)\n    self.assertEqual(actual.shape, expected.shape, msg=msg)\n    if msg:\n      msg = \'Shape: {} is not a tuple for {}\'.format(actual.shape, msg)\n    self.assertIsInstance(actual.shape, tuple, msg=msg)\n\n  def match_dtype(self, actual, expected, msg=None):\n    if msg:\n      msg = \'Dtype match failed for: {}. Expected: {} Actual: {}.\'.format(\n          msg, expected.dtype, actual.dtype)\n    self.assertEqual(actual.dtype, expected.dtype, msg=msg)\n\n  def match(self, actual, expected, msg=None):\n    msg_ = \'Expected: {} Actual: {}\'.format(expected, actual)\n    if msg:\n      msg = \'{} {}\'.format(msg_, msg)\n    else:\n      msg = msg_\n    self.assertIsInstance(actual, arrays.ndarray)\n    self.match_dtype(actual, expected, msg)\n    self.match_shape(actual, expected, msg)\n    if not actual.shape:\n      self.assertEqual(actual.tolist(), expected.tolist())\n    else:\n      self.assertSequenceEqual(actual.tolist(), expected.tolist())\n\n\ndef make_numpy_compatible(s):\n  return s if not isinstance(s, arrays.ndarray) else s.data.numpy()\n\n\nif __name__ == \'__main__\':\n  tf.compat.v1.enable_eager_execution()\n  tf.test.main()\n'"
trax/tf_numpy/numpy_impl/tests/math_ops_test.py,51,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for tf numpy mathematical methods.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport itertools\nfrom absl.testing import parameterized\nimport numpy as np\nfrom six.moves import range\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.numpy_impl import array_ops\nfrom trax.tf_numpy.numpy_impl import arrays\nfrom trax.tf_numpy.numpy_impl import math_ops\n\n\nclass MathTest(tf.test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    super(MathTest, self).setUp()\n    self.array_transforms = [\n        lambda x: x,  # Identity,\n        tf.convert_to_tensor,\n        np.array,\n        lambda x: np.array(x, dtype=np.float32),\n        lambda x: np.array(x, dtype=np.float64),\n        array_ops.array,\n        lambda x: array_ops.array(x, dtype=np.float32),\n        lambda x: array_ops.array(x, dtype=np.float64),\n    ]\n    self.types = [np.int32, np.int64, np.float32, np.float64]\n\n  def _testBinaryOp(self, math_fun, np_fun, name, operands=None,\n                    extra_operands=None,\n                    check_promotion=True,\n                    check_promotion_result_type=True):\n\n    def run_test(a, b):\n      for fn in self.array_transforms:\n        arg1 = fn(a)\n        arg2 = fn(b)\n        self.match(\n            math_fun(arg1, arg2),\n            np_fun(arg1, arg2),\n            msg=\'{}({}, {})\'.format(name, arg1, arg2))\n      # Tests type promotion\n      for type_a in self.types:\n        for type_b in self.types:\n          if not check_promotion and type_a != type_b:\n            continue\n          arg1 = array_ops.array(a, dtype=type_a)\n          arg2 = array_ops.array(b, dtype=type_b)\n          self.match(\n              math_fun(arg1, arg2),\n              np_fun(arg1, arg2),\n              msg=\'{}({}, {})\'.format(name, arg1, arg2),\n              check_dtype=check_promotion_result_type)\n\n    if operands is None:\n      operands = [(5, 2),\n                  (5, [2, 3]),\n                  (5, [[2, 3], [6, 7]]),\n                  ([1, 2, 3], 7),\n                  ([1, 2, 3], [5, 6, 7])]\n    for operand1, operand2 in operands:\n      run_test(operand1, operand2)\n    if extra_operands is not None:\n      for operand1, operand2 in extra_operands:\n        run_test(operand1, operand2)\n\n  def testDot(self):\n    extra_operands = [\n        ([1, 2], [[5, 6, 7], [8, 9, 10]]),\n        (np.arange(2 * 3 * 5).reshape([2, 3, 5]).tolist(),\n         np.arange(5 * 7 * 11).reshape([7, 5, 11]).tolist())]\n    return self._testBinaryOp(\n        math_ops.dot, np.dot, \'dot\', extra_operands=extra_operands)\n\n  def testMinimum(self):\n    # The numpy version has strange result type when promotion happens,\n    # so set check_promotion_result_type to False.\n    return self._testBinaryOp(\n        math_ops.minimum,\n        np.minimum,\n        \'minimum\',\n        check_promotion_result_type=False)\n\n  def testMaximum(self):\n    # The numpy version has strange result type when promotion happens,\n    # so set check_promotion_result_type to False.\n    return self._testBinaryOp(\n        math_ops.maximum,\n        np.maximum,\n        \'maximum\',\n        check_promotion_result_type=False)\n\n  def testMatmul(self):\n    operands = [([[1, 2]], [[3, 4, 5], [6, 7, 8]])]\n    return self._testBinaryOp(\n        math_ops.matmul, np.matmul, \'matmul\', operands=operands)\n\n  def testMatmulError(self):\n    with self.assertRaisesRegex(ValueError, r\'\'):\n      math_ops.matmul(\n          array_ops.ones([], np.int32), array_ops.ones([2, 3], np.int32))\n    with self.assertRaisesRegex(ValueError, r\'\'):\n      math_ops.matmul(\n          array_ops.ones([2, 3], np.int32), array_ops.ones([], np.int32))\n\n  def _testUnaryOp(self, math_fun, np_fun, name):\n\n    def run_test(a):\n      for fn in self.array_transforms:\n        arg1 = fn(a)\n        self.match(math_fun(arg1), np_fun(arg1),\n                   msg=\'{}({})\'.format(name, arg1))\n\n    run_test(5)\n    run_test([2, 3])\n    run_test([[2, -3], [-6, 7]])\n\n  def testLog(self):\n    self._testUnaryOp(math_ops.log, np.log, \'log\')\n\n  def testExp(self):\n    self._testUnaryOp(math_ops.exp, np.exp, \'exp\')\n\n  def testTanh(self):\n    self._testUnaryOp(math_ops.tanh, np.tanh, \'tanh\')\n\n  def testSqrt(self):\n    self._testUnaryOp(math_ops.sqrt, np.sqrt, \'sqrt\')\n\n  def match(self, actual, expected, msg=\'\', check_dtype=True):\n    self.assertIsInstance(actual, arrays.ndarray)\n    if check_dtype:\n      self.assertEqual(\n          actual.dtype, expected.dtype,\n          \'Dtype mismatch.\\nActual: {}\\nExpected: {}\\n{}\'.format(\n              actual.dtype, expected.dtype, msg))\n    self.assertEqual(\n        actual.shape, expected.shape,\n        \'Shape mismatch.\\nActual: {}\\nExpected: {}\\n{}\'.format(\n            actual.shape, expected.shape, msg))\n    np.testing.assert_almost_equal(actual.tolist(), expected.tolist())\n\n  def testArgsort(self):\n    self._testUnaryOp(math_ops.argsort, np.argsort, \'argsort\')\n\n    # Test stability\n    r = np.arange(100)\n    a = np.zeros(100)\n    np.testing.assert_equal(math_ops.argsort(a, kind=\'stable\'), r)\n\n  def testArgMaxArgMin(self):\n    data = [\n        0,\n        5,\n        [1],\n        [1, 2, 3],\n        [[1, 2, 3]],\n        [[4, 6], [7, 8]],\n        [[[4, 6], [9, 10]], [[7, 8], [12, 34]]],\n    ]\n    for fn, d in itertools.product(self.array_transforms, data):\n      arr = fn(d)\n      self.match(math_ops.argmax(arr), np.argmax(arr))\n      self.match(math_ops.argmin(arr), np.argmin(arr))\n      if hasattr(arr, \'shape\'):\n        ndims = len(arr.shape)\n      else:\n        ndims = array_ops.array(arr, copy=False).ndim\n      if ndims == 0:\n        # Numpy flattens the scalar ndarray and treats it as a 1-d array of\n        # size 1.\n        ndims = 1\n      for axis in range(-ndims, ndims):\n        self.match(math_ops.argmax(arr, axis=axis), np.argmax(arr, axis=axis))\n        self.match(math_ops.argmin(arr, axis=axis), np.argmin(arr, axis=axis))\n\n  @parameterized.parameters([False, True])\n  def testIsCloseEqualNan(self, equal_nan):\n    a = np.asarray([1, 1, np.nan, 1, np.nan], np.float32)\n    b = np.asarray([1, 2, 1, np.nan, np.nan], np.float32)\n    self.match(\n        math_ops.isclose(a, b, equal_nan=equal_nan),\n        np.isclose(a, b, equal_nan=equal_nan))\n\n  def testAverageWrongShape(self):\n    with self.assertRaisesWithPredicateMatch(\n        tf.errors.InvalidArgumentError, r\'\'):\n      math_ops.average(np.ones([2, 3]), weights=np.ones([2, 4]))\n    with self.assertRaisesWithPredicateMatch(\n        tf.errors.InvalidArgumentError, r\'\'):\n      math_ops.average(np.ones([2, 3]), axis=0, weights=np.ones([2, 4]))\n    with self.assertRaisesWithPredicateMatch(\n        tf.errors.InvalidArgumentError, r\'\'):\n      math_ops.average(np.ones([2, 3]), axis=0, weights=np.ones([]))\n    with self.assertRaisesWithPredicateMatch(\n        tf.errors.InvalidArgumentError, r\'\'):\n      math_ops.average(np.ones([2, 3]), axis=0, weights=np.ones([5]))\n\n  def testClip(self):\n\n    def run_test(arr, *args, **kwargs):\n      check_dtype = kwargs.pop(\'check_dtype\', True)\n      for fn in self.array_transforms:\n        arr = fn(arr)\n        self.match(\n            math_ops.clip(arr, *args, **kwargs),\n            np.clip(arr, *args, **kwargs),\n            check_dtype=check_dtype)\n\n    # NumPy exhibits weird typing behavior when a/a_min/a_max are scalars v/s\n    # lists, e.g.,\n    #\n    # np.clip(np.array(0, dtype=np.int32), -5, 5).dtype == np.int64\n    # np.clip(np.array([0], dtype=np.int32), -5, 5).dtype == np.int32\n    # np.clip(np.array([0], dtype=np.int32), [-5], [5]).dtype == np.int64\n    #\n    # So we skip matching type. In tf-numpy the type of the output array is\n    # always the same as the input array.\n    run_test(0, -1, 5, check_dtype=False)\n    run_test(-1, -1, 5, check_dtype=False)\n    run_test(5, -1, 5, check_dtype=False)\n    run_test(-10, -1, 5, check_dtype=False)\n    run_test(10, -1, 5, check_dtype=False)\n    run_test(10, None, 5, check_dtype=False)\n    run_test(10, -1, None, check_dtype=False)\n    run_test([0, 20, -5, 4], -1, 5, check_dtype=False)\n    run_test([0, 20, -5, 4], None, 5, check_dtype=False)\n    run_test([0, 20, -5, 4], -1, None, check_dtype=False)\n    run_test([0.5, 20.2, -5.7, 4.4], -1.5, 5.1, check_dtype=False)\n\n    run_test([0, 20, -5, 4], [-5, 0, -5, 0], [0, 5, 0, 5], check_dtype=False)\n    run_test([[1, 2, 3], [4, 5, 6]], [2, 0, 2], 5, check_dtype=False)\n    run_test([[1, 2, 3], [4, 5, 6]], 0, [5, 3, 1], check_dtype=False)\n\n  def testPtp(self):\n\n    def run_test(arr, *args, **kwargs):\n      for fn in self.array_transforms:\n        arg = fn(arr)\n        self.match(\n            math_ops.ptp(arg, *args, **kwargs), np.ptp(arg, *args, **kwargs))\n\n    run_test([1, 2, 3])\n    run_test([1., 2., 3.])\n    run_test([[1, 2], [3, 4]], axis=1)\n    run_test([[1, 2], [3, 4]], axis=0)\n    run_test([[1, 2], [3, 4]], axis=-1)\n    run_test([[1, 2], [3, 4]], axis=-2)\n\n  def testLinSpace(self):\n    array_transforms = [\n        lambda x: x,  # Identity,\n        tf.convert_to_tensor,\n        np.array,\n        lambda x: np.array(x, dtype=np.float32),\n        lambda x: np.array(x, dtype=np.float64),\n        array_ops.array,\n        lambda x: array_ops.array(x, dtype=np.float32),\n        lambda x: array_ops.array(x, dtype=np.float64)\n    ]\n\n    def run_test(start, stop, **kwargs):\n      for fn1 in array_transforms:\n        for fn2 in array_transforms:\n          arg1 = fn1(start)\n          arg2 = fn2(stop)\n          self.match(\n              math_ops.linspace(arg1, arg2, **kwargs),\n              np.linspace(arg1, arg2, **kwargs),\n              msg=\'linspace({}, {})\'.format(arg1, arg2))\n\n    run_test(0, 1)\n    run_test(0, 1, num=10)\n    run_test(0, 1, endpoint=False)\n    run_test(0, -1)\n    run_test(0, -1, num=10)\n    run_test(0, -1, endpoint=False)\n\n  def testLogSpace(self):\n    array_transforms = [\n        lambda x: x,  # Identity,\n        tf.convert_to_tensor,\n        np.array,\n        lambda x: np.array(x, dtype=np.float32),\n        lambda x: np.array(x, dtype=np.float64),\n        array_ops.array,\n        lambda x: array_ops.array(x, dtype=np.float32),\n        lambda x: array_ops.array(x, dtype=np.float64)\n    ]\n\n    def run_test(start, stop, **kwargs):\n      for fn1 in array_transforms:\n        for fn2 in array_transforms:\n          arg1 = fn1(start)\n          arg2 = fn2(stop)\n          self.match(\n              math_ops.logspace(arg1, arg2, **kwargs),\n              np.logspace(arg1, arg2, **kwargs),\n              msg=\'logspace({}, {})\'.format(arg1, arg2))\n\n    run_test(0, 5)\n    run_test(0, 5, num=10)\n    run_test(0, 5, endpoint=False)\n    run_test(0, 5, base=2.0)\n    run_test(0, -5)\n    run_test(0, -5, num=10)\n    run_test(0, -5, endpoint=False)\n    run_test(0, -5, base=2.0)\n\n\nif __name__ == \'__main__\':\n  tf.compat.v1.enable_eager_execution()\n  tf.test.main()\n'"
trax/tf_numpy/numpy_impl/tests/random_test.py,6,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for tf numpy random number methods.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom six.moves import range\nimport tensorflow.compat.v2 as tf\n\n# Needed for ndarray.reshape.\nfrom trax.tf_numpy.numpy_impl import array_ops  # pylint: disable=unused-import\nfrom trax.tf_numpy.numpy_impl import random\n\n\nclass RandomTest(tf.test.TestCase):\n\n  def assertNotAllClose(self, a, b, **kwargs):\n    try:\n      self.assertAllClose(a, b, **kwargs)\n    except AssertionError:\n      return\n    raise AssertionError(\n        \'The two values are close at all %d elements\' % np.size(a))\n\n  def testRandN(self):\n\n    def run_test(*args):\n      num_samples = 1000\n      tol = 0.1  # High tolerance to keep the # of samples low else the test\n      # takes a long time to run.\n      random.seed(10)\n      outputs = [random.randn(*args) for _ in range(num_samples)]\n\n      # Test output shape.\n      for output in outputs:\n        self.assertEqual(output.shape, tuple(args))\n        self.assertEqual(output.dtype.type, random.DEFAULT_RANDN_DTYPE)\n\n      if np.prod(args):  # Don\'t bother with empty arrays.\n        outputs = [output.tolist() for output in outputs]\n\n        # Test that the properties of normal distribution are satisfied.\n        mean = np.mean(outputs, axis=0)\n        stddev = np.std(outputs, axis=0)\n        self.assertAllClose(mean, np.zeros(args), atol=tol)\n        self.assertAllClose(stddev, np.ones(args), atol=tol)\n\n        # Test that outputs are different with different seeds.\n        random.seed(20)\n        diff_seed_outputs = [\n            random.randn(*args).tolist() for _ in range(num_samples)\n        ]\n        self.assertNotAllClose(outputs, diff_seed_outputs)\n\n        # Test that outputs are the same with the same seed.\n        random.seed(10)\n        same_seed_outputs = [\n            random.randn(*args).tolist() for _ in range(num_samples)\n        ]\n        self.assertAllClose(outputs, same_seed_outputs)\n\n    run_test()\n    run_test(0)\n    run_test(1)\n    run_test(5)\n    run_test(2, 3)\n    run_test(0, 2, 3)\n    run_test(2, 0, 3)\n    run_test(2, 3, 0)\n    run_test(2, 3, 5)\n\n\nif __name__ == \'__main__\':\n  tf.compat.v1.enable_eager_execution()\n  tf.test.main()\n'"
trax/tf_numpy/numpy_impl/tests/utils_test.py,0,"b'# coding=utf-8\n# Copyright 2020 The Trax Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Tests for utils.py.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow.compat.v2 as tf\n\nfrom trax.tf_numpy.numpy_impl import utils\n\n\nclass UtilsTest(tf.test.TestCase):\n\n  # pylint: disable=unused-argument\n  def testNpDoc(self):\n    def np_fun(x):\n      """"""np_fun docstring.""""""\n      return\n    @utils.np_doc(np_fun)\n    def f():\n      """"""f docstring.""""""\n      return\n    expected = """"""TensorFlow variant of `numpy.np_fun`.\n\nUnsupported arguments: `x`.\n\nf docstring.\n\nDocumentation for `numpy.np_fun`:\n\nnp_fun docstring.""""""\n    self.assertEqual(f.__doc__, expected)\n\n  def testNpDocErrors(self):\n    def np_fun(x, y=1, **kwargs):\n      return\n    # pylint: disable=unused-variable\n    with self.assertRaisesRegexp(TypeError, \'Cannot find parameter\'):\n      @utils.np_doc(np_fun)\n      def f1(a):\n        return\n    with self.assertRaisesRegexp(TypeError, \'is of kind\'):\n      @utils.np_doc(np_fun)\n      def f2(x, kwargs):\n        return\n    with self.assertRaisesRegexp(\n        TypeError, \'Parameter ""y"" should have a default value\'):\n      @utils.np_doc(np_fun)\n      def f3(x, y):\n        return\n\n\nif __name__ == \'__main__\':\n  tf.enable_v2_behavior()\n  tf.test.main()\n'"
