file_path,api_count,code
pyefd.py,47,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n""""""\n\nA Python implementation of the method described in [#a]_ and [#b]_ for\ncalculating Fourier coefficients for characterizing\nclosed contours.\n\nReferences\n----------\n\n.. [#a] F. P. Kuhl and C. R. Giardina, \xe2\x80\x9cElliptic Fourier Features of a\n   Closed Contour,"" Computer Vision, Graphics and Image Processing,\n   Vol. 18, pp. 236-258, 1982.\n\n.. [#b] Oivind Due Trier, Anil K. Jain and Torfinn Taxt, \xe2\x80\x9cFeature Extraction\n   Methods for Character Recognition - A Survey\xe2\x80\x9d, Pattern Recognition\n   Vol. 29, No.4, pp. 641-662, 1996\n\nCreated by hbldh <henrik.blidh@nedomkull.com> on 2016-01-30.\n\n""""""\n\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nfrom __future__ import absolute_import\n\nimport numpy as np\n\ntry:\n    _range = xrange\nexcept NameError:\n    _range = range\n\n\ndef elliptic_fourier_descriptors(contour, order=10, normalize=False):\n    """"""Calculate elliptical Fourier descriptors for a contour.\n\n    :param numpy.ndarray contour: A contour array of size ``[M x 2]``.\n    :param int order: The order of Fourier coefficients to calculate.\n    :param bool normalize: If the coefficients should be normalized;\n        see references for details.\n    :return: A ``[order x 4]`` array of Fourier coefficients.\n    :rtype: :py:class:`numpy.ndarray`\n\n    """"""\n    dxy = np.diff(contour, axis=0)\n    dt = np.sqrt((dxy ** 2).sum(axis=1))\n    t = np.concatenate([([0.]), np.cumsum(dt)])\n    T = t[-1]\n\n    phi = (2 * np.pi * t) / T\n\n    orders = np.arange(1, order + 1)\n    consts = T / (2 * orders * orders * np.pi * np.pi)\n    phi = phi * orders.reshape((order, -1))\n    d_cos_phi = np.cos(phi[:, 1:]) - np.cos(phi[:, :-1])\n    d_sin_phi = np.sin(phi[:, 1:]) - np.sin(phi[:, :-1])\n    cos_phi = (dxy[:, 0] / dt) * d_cos_phi\n    a = consts * np.sum(cos_phi, axis=1)\n    b = consts * np.sum((dxy[:, 0] / dt) * d_sin_phi, axis=1)\n    c = consts * np.sum((dxy[:, 1] / dt) * d_cos_phi, axis=1)\n    d = consts * np.sum((dxy[:, 1] / dt) * d_sin_phi, axis=1)\n\n    coeffs = np.concatenate(\n        [\n            a.reshape((order, 1)),\n            b.reshape((order, 1)),\n            c.reshape((order, 1)),\n            d.reshape((order, 1)),\n        ],\n        axis=1,\n    )\n\n    if normalize:\n        coeffs = normalize_efd(coeffs)\n\n    return coeffs\n\n\ndef normalize_efd(coeffs, size_invariant=True):\n    """"""Normalizes an array of Fourier coefficients.\n\n    See [#a]_ and [#b]_ for details.\n\n    :param numpy.ndarray coeffs: A ``[n x 4]`` Fourier coefficient array.\n    :param bool size_invariant: If size invariance normalizing should be done as well.\n        Default is ``True``.\n    :return: The normalized ``[n x 4]`` Fourier coefficient array.\n    :rtype: :py:class:`numpy.ndarray`\n\n    """"""\n    # Make the coefficients have a zero phase shift from\n    # the first major axis. Theta_1 is that shift angle.\n    theta_1 = 0.5 * np.arctan2(\n        2 * ((coeffs[0, 0] * coeffs[0, 1]) + (coeffs[0, 2] * coeffs[0, 3])),\n        (\n            (coeffs[0, 0] ** 2)\n            - (coeffs[0, 1] ** 2)\n            + (coeffs[0, 2] ** 2)\n            - (coeffs[0, 3] ** 2)\n        ),\n    )\n    # Rotate all coefficients by theta_1.\n    for n in _range(1, coeffs.shape[0] + 1):\n        coeffs[n - 1, :] = np.dot(\n            np.array(\n                [\n                    [coeffs[n - 1, 0], coeffs[n - 1, 1]],\n                    [coeffs[n - 1, 2], coeffs[n - 1, 3]],\n                ]\n            ),\n            np.array(\n                [\n                    [np.cos(n * theta_1), -np.sin(n * theta_1)],\n                    [np.sin(n * theta_1), np.cos(n * theta_1)],\n                ]\n            ),\n        ).flatten()\n\n    # Make the coefficients rotation invariant by rotating so that\n    # the semi-major axis is parallel to the x-axis.\n    psi_1 = np.arctan2(coeffs[0, 2], coeffs[0, 0])\n    psi_rotation_matrix = np.array(\n        [[np.cos(psi_1), np.sin(psi_1)], [-np.sin(psi_1), np.cos(psi_1)]]\n    )\n    # Rotate all coefficients by -psi_1.\n    for n in _range(1, coeffs.shape[0] + 1):\n        coeffs[n - 1, :] = psi_rotation_matrix.dot(\n            np.array(\n                [\n                    [coeffs[n - 1, 0], coeffs[n - 1, 1]],\n                    [coeffs[n - 1, 2], coeffs[n - 1, 3]],\n                ]\n            )\n        ).flatten()\n\n    if size_invariant:\n        # Obtain size-invariance by normalizing.\n        coeffs /= np.abs(coeffs[0, 0])\n\n    return coeffs\n\n\ndef calculate_dc_coefficients(contour):\n    """"""Calculate the :math:`A_0` and :math:`C_0` coefficients of the elliptic Fourier series.\n\n    :param numpy.ndarray contour: A contour array of size ``[M x 2]``.\n    :return: The :math:`A_0` and :math:`C_0` coefficients.\n    :rtype: tuple\n\n    """"""\n    dxy = np.diff(contour, axis=0)\n    dt = np.sqrt((dxy ** 2).sum(axis=1))\n    t = np.concatenate([([0.]), np.cumsum(dt)])\n    T = t[-1]\n\n    xi = np.cumsum(dxy[:, 0]) - (dxy[:, 0] / dt) * t[1:]\n    A0 = (1 / T) * np.sum(((dxy[:, 0] / (2 * dt)) * np.diff(t ** 2)) + xi * dt)\n    delta = np.cumsum(dxy[:, 1]) - (dxy[:, 1] / dt) * t[1:]\n    C0 = (1 / T) * np.sum(((dxy[:, 1] / (2 * dt)) * np.diff(t ** 2)) + delta * dt)\n\n    # A0 and CO relate to the first point of the contour array as origin.\n    # Adding those values to the coefficients to make them relate to true origin.\n    return contour[0, 0] + A0, contour[0, 1] + C0\n\n\ndef reconstruct_contour(coeffs, locus=(0, 0), num_points=300):\n    """"""Returns the contour specified by the coefficients.\n\n    :param coeffs: A ``[n x 4]`` Fourier coefficient array.\n    :type coeffs: numpy.ndarray\n    :param locus: The :math:`A_0` and :math:`C_0` elliptic locus in [#a]_ and [#b]_.\n    :type locus: list, tuple or numpy.ndarray\n    :param num_points: The number of sample points used for reconstructing the contour from the EFD.\n    :type num_points: int\n    :return: A list of x,y coordinates for the reconstructed contour.\n    :rtype: numpy.ndarray\n\n    """"""\n    t = np.linspace(0, 1.0, num_points)\n    # Append extra dimension to enable element-wise broadcasted multiplication\n    coeffs = coeffs.reshape(coeffs.shape[0], coeffs.shape[1], 1)\n\n    orders = coeffs.shape[0]\n    orders = np.arange(1, orders + 1).reshape(-1, 1)\n    order_phases = 2 * orders * np.pi * t.reshape(1, -1)\n\n    xt_all = coeffs[:, 0] * np.cos(order_phases) + coeffs[:, 1] * np.sin(order_phases)\n    yt_all = coeffs[:, 2] * np.cos(order_phases) + coeffs[:, 3] * np.sin(order_phases)\n\n    xt_all = xt_all.sum(axis=0)\n    yt_all = yt_all.sum(axis=0)\n    xt_all = xt_all + np.ones((num_points,)) * locus[0]\n    yt_all = yt_all + np.ones((num_points,)) * locus[1]\n\n    reconstruction = np.stack([xt_all, yt_all], axis=1)\n    return reconstruction\n\n\ndef plot_efd(coeffs, locus=(0., 0.), image=None, contour=None, n=300):\n    """"""Plot a ``[2 x (N / 2)]`` grid of successive truncations of the series.\n\n    .. note::\n\n        Requires `matplotlib <http://matplotlib.org/>`_!\n\n    :param numpy.ndarray coeffs: ``[N x 4]`` Fourier coefficient array.\n    :param list, tuple or numpy.ndarray locus:\n        The :math:`A_0` and :math:`C_0` elliptic locus in [#a]_ and [#b]_.\n    :param int n: Number of points to use for plotting of Fourier series.\n\n    """"""\n    try:\n        import matplotlib.pyplot as plt\n    except ImportError:\n        print(""Cannot plot: matplotlib was not installed."")\n        return\n\n    N = coeffs.shape[0]\n    N_half = int(np.ceil(N / 2))\n    n_rows = 2\n\n    t = np.linspace(0, 1.0, n)\n    xt = np.ones((n,)) * locus[0]\n    yt = np.ones((n,)) * locus[1]\n\n    for n in _range(coeffs.shape[0]):\n        xt += (coeffs[n, 0] * np.cos(2 * (n + 1) * np.pi * t)) + (\n            coeffs[n, 1] * np.sin(2 * (n + 1) * np.pi * t)\n        )\n        yt += (coeffs[n, 2] * np.cos(2 * (n + 1) * np.pi * t)) + (\n            coeffs[n, 3] * np.sin(2 * (n + 1) * np.pi * t)\n        )\n        ax = plt.subplot2grid((n_rows, N_half), (n // N_half, n % N_half))\n        ax.set_title(str(n + 1))\n        if contour is not None:\n            ax.plot(contour[:, 1], contour[:, 0], ""c--"", linewidth=2)\n        ax.plot(yt, xt, ""r"", linewidth=2)\n        if image is not None:\n            ax.imshow(image, plt.cm.gray)\n\n    plt.show()\n'"
setup.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n# Note: To use the \'upload\' functionality of this file, you must:\n#   $ pip install twine\n\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nimport io\nimport os\nimport sys\nfrom shutil import rmtree\n\nfrom setuptools import setup, Command\n\n# Package meta-data.\nNAME = ""pyefd""\nDESCRIPTION = \'Python implementation of ""Elliptic Fourier Features of a Closed Contour""\'\nURL = ""https://github.com/hbldh/pyefd""\nEMAIL = ""henrik.blidh@nedomkull.com""\nAUTHOR = ""Henrik Blidh""\nREQUIRES_PYTHON = "">=2.7.10""\nVERSION = ""1.4.0""\n\nREQUIRED = [""numpy>=1.7.0""]\n\nTEST_REQUIRED = [""pytest"", ""scipy""]\n\nhere = os.path.abspath(os.path.dirname(__file__))\n\nwith io.open(os.path.join(here, ""README.md""), encoding=""utf-8"") as f:\n    long_description = ""\\n"" + f.read()\nwith io.open(os.path.join(here, ""HISTORY.md""), encoding=""utf-8"") as f:\n    long_description = long_description + ""\\n\\n"" + f.read()\n\n# Load the package\'s __version__.py module as a dictionary.\nabout = {}\nif not VERSION:\n    with open(os.path.join(here, NAME, ""__version__.py"")) as f:\n        exec(f.read(), about)\nelse:\n    about[""__version__""] = VERSION\n\n\nclass UploadCommand(Command):\n    """"""Support setup.py upload.""""""\n\n    description = ""Build and publish the package.""\n    user_options = []\n\n    @staticmethod\n    def status(s):\n        """"""Prints things in bold.""""""\n        print(""\\033[1m{0}\\033[0m"".format(s))\n\n    def initialize_options(self):\n        pass\n\n    def finalize_options(self):\n        pass\n\n    def run(self):\n        try:\n            self.status(""Removing previous builds\xe2\x80\xa6"")\n            rmtree(os.path.join(here, ""dist""))\n        except OSError:\n            pass\n\n        self.status(""Building Source and Wheel (universal) distribution\xe2\x80\xa6"")\n        os.system(""{0} setup.py sdist bdist_wheel --universal"".format(sys.executable))\n\n        self.status(""Uploading the package to PyPi via Twine\xe2\x80\xa6"")\n        os.system(""twine upload dist/*"")\n\n        self.status(""Pushing git tags\xe2\x80\xa6"")\n        os.system(""git tag v{0}"".format(about[""__version__""]))\n        os.system(""git push --tags"")\n\n        sys.exit()\n\n\nsetup(\n    name=NAME,\n    version=about[""__version__""],\n    description=DESCRIPTION,\n    long_description=long_description,\n    long_description_content_type=""text/markdown"",\n    author=AUTHOR,\n    author_email=EMAIL,\n    python_requires=REQUIRES_PYTHON,\n    setup_requires=[""pytest-runner""],\n    tests_require=TEST_REQUIRED,\n    keywords=[\n        ""elliptic fourier descriptors"",\n        ""fourier descriptors"",\n        ""shape descriptors"",\n        ""image analysis"",\n    ],\n    py_modules=[""pyefd""],\n    install_requires=REQUIRED,\n    include_package_data=True,\n    license=""MIT"",\n    classifiers=[\n        # Trove classifiers\n        # Full list: https://pypi.python.org/pypi?%3Aaction=list_classifiers\n        ""Development Status :: 5 - Production/Stable"",\n        ""Operating System :: OS Independent"",\n        ""Intended Audience :: Science/Research"",\n        ""Intended Audience :: Developers"",\n        ""License :: OSI Approved :: MIT License"",\n        ""Topic :: Software Development"",\n        ""Topic :: Scientific/Engineering"",\n        ""Programming Language :: Python :: 2"",\n        ""Programming Language :: Python :: 2.7"",\n        ""Programming Language :: Python :: 3"",\n        ""Programming Language :: Python :: 3.4"",\n        ""Programming Language :: Python :: 3.5"",\n        ""Programming Language :: Python :: 3.6"",\n        ""Programming Language :: Python :: Implementation :: CPython"",\n        ""Programming Language :: Python :: Implementation :: PyPy"",\n    ],\n    # $ setup.py publish support.\n    cmdclass={""upload"": UploadCommand},\n)\n'"
tests.py,23,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n""""""\ntests.py\n========\n\nCreated by: hbldh <henrik.blidh@nedomkull.com>\nCreated on: 2016-02-07, 23:50\n\n""""""\n\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\nfrom __future__ import absolute_import\n\nimport time\n\nimport numpy as np\nfrom scipy.spatial.distance import directed_hausdorff\n\nimport pyefd\n\n\nlbl_1 = 5\nimg_1 = np.array(\n    [\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            191,\n            64,\n            127,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            0,\n            0,\n            0,\n            127,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            64,\n            0,\n            0,\n            0,\n            0,\n            64,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            191,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            64,\n            127,\n            64,\n            64,\n            0,\n            0,\n            64,\n            191,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            191,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            127,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            64,\n            0,\n            0,\n            127,\n            255,\n            255,\n            191,\n            64,\n            0,\n            0,\n            0,\n            0,\n            0,\n            64,\n            127,\n            127,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            191,\n            0,\n            0,\n            0,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            191,\n            0,\n            0,\n            0,\n            64,\n            127,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            64,\n            0,\n            0,\n            0,\n            0,\n            0,\n            64,\n            191,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            127,\n            64,\n            0,\n            0,\n            0,\n            0,\n            64,\n            191,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            191,\n            127,\n            0,\n            0,\n            0,\n            0,\n            127,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            191,\n            127,\n            0,\n            0,\n            0,\n            64,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            0,\n            0,\n            0,\n            191,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            127,\n            0,\n            0,\n            127,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            127,\n            0,\n            0,\n            127,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            127,\n            191,\n            255,\n            255,\n            255,\n            255,\n            127,\n            0,\n            0,\n            0,\n            191,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            127,\n            0,\n            127,\n            255,\n            255,\n            191,\n            64,\n            0,\n            0,\n            0,\n            191,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            191,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            127,\n            0,\n            0,\n            0,\n            0,\n            0,\n            0,\n            64,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            127,\n            0,\n            0,\n            0,\n            64,\n            191,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n        [\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n            255,\n        ],\n    ]\n)\ncontour_1 = np.array(\n    [\n        [24.0, 13.0125],\n        [23.0125, 14.0],\n        [23.004188481675392, 15.0],\n        [23.0, 15.0125],\n        [22.0125, 16.0],\n        [22.00313725490196, 17.0],\n        [22.0, 17.004188481675392],\n        [21.0, 17.004188481675392],\n        [20.004188481675392, 18.0],\n        [20.0, 18.004188481675392],\n        [19.0, 18.006299212598424],\n        [18.0, 18.006299212598424],\n        [17.0, 18.004188481675392],\n        [16.9875, 18.0],\n        [16.0, 17.0125],\n        [15.993700787401576, 17.0],\n        [15.0, 16.006299212598424],\n        [14.995811518324608, 16.0],\n        [14.9875, 15.0],\n        [14.0, 14.0125],\n        [13.995811518324608, 14.0],\n        [13.9875, 13.0],\n        [13.0, 12.0125],\n        [12.996862745098039, 12.0],\n        [12.993700787401576, 11.0],\n        [12.9875, 10.0],\n        [12.0, 9.0125],\n        [11.0, 9.003137254901961],\n        [10.0, 9.006299212598424],\n        [9.006299212598424, 10.0],\n        [9.003137254901961, 11.0],\n        [9.003137254901961, 12.0],\n        [9.004188481675392, 13.0],\n        [9.0125, 14.0],\n        [10.0, 14.9875],\n        [10.003137254901961, 15.0],\n        [10.003137254901961, 16.0],\n        [10.003137254901961, 17.0],\n        [10.003137254901961, 18.0],\n        [10.003137254901961, 19.0],\n        [10.0, 19.0125],\n        [9.0125, 20.0],\n        [9.006299212598424, 21.0],\n        [9.006299212598424, 22.0],\n        [9.0, 22.006299212598424],\n        [8.9875, 22.0],\n        [8.0, 21.0125],\n        [7.996862745098039, 21.0],\n        [7.996862745098039, 20.0],\n        [8.0, 19.9875],\n        [8.9875, 19.0],\n        [8.9875, 18.0],\n        [8.993700787401576, 17.0],\n        [8.9875, 16.0],\n        [8.0, 15.0125],\n        [7.996862745098039, 15.0],\n        [7.9875, 14.0],\n        [7.0, 13.0125],\n        [6.993700787401575, 13.0],\n        [6.0, 12.006299212598424],\n        [5.993700787401575, 12.0],\n        [5.9875, 11.0],\n        [5.995811518324607, 10.0],\n        [6.0, 9.996862745098039],\n        [7.0, 9.9875],\n        [7.9875, 9.0],\n        [8.0, 8.995811518324608],\n        [8.995811518324608, 8.0],\n        [9.0, 7.995811518324607],\n        [10.0, 7.9875],\n        [10.9875, 7.0],\n        [11.0, 6.995811518324607],\n        [12.0, 6.995811518324607],\n        [12.0125, 7.0],\n        [13.0, 7.9875],\n        [13.003137254901961, 8.0],\n        [13.006299212598424, 9.0],\n        [13.0125, 10.0],\n        [14.0, 10.9875],\n        [14.004188481675392, 11.0],\n        [14.006299212598424, 12.0],\n        [15.0, 12.993700787401576],\n        [15.004188481675392, 13.0],\n        [15.006299212598424, 14.0],\n        [16.0, 14.993700787401576],\n        [16.00313725490196, 15.0],\n        [17.0, 15.996862745098039],\n        [17.006299212598424, 16.0],\n        [18.0, 16.993700787401576],\n        [19.0, 16.993700787401576],\n        [19.993700787401576, 16.0],\n        [20.0, 15.993700787401576],\n        [20.993700787401576, 15.0],\n        [21.0, 14.9875],\n        [21.9875, 14.0],\n        [21.995811518324608, 13.0],\n        [21.99686274509804, 12.0],\n        [21.99686274509804, 11.0],\n        [21.993700787401576, 10.0],\n        [21.0, 9.006299212598424],\n        [20.993700787401576, 9.0],\n        [21.0, 8.993700787401576],\n        [22.0, 8.996862745098039],\n        [22.006299212598424, 9.0],\n        [23.0, 9.993700787401576],\n        [23.006299212598424, 10.0],\n        [24.0, 10.993700787401576],\n        [24.00313725490196, 11.0],\n        [24.00313725490196, 12.0],\n        [24.00313725490196, 13.0],\n        [24.0, 13.0125],\n    ]\n)\n\n\ndef test_efd_shape_1():\n    coeffs = pyefd.elliptic_fourier_descriptors(contour_1, order=10)\n    assert coeffs.shape == (10, 4)\n\n\ndef test_efd_shape_2():\n    c = pyefd.elliptic_fourier_descriptors(contour_1, order=40)\n    assert c.shape == (40, 4)\n\n\ndef test_normalizing_1():\n    c = pyefd.elliptic_fourier_descriptors(contour_1, normalize=False)\n    assert np.abs(c[0, 0]) > 0.0\n    assert np.abs(c[0, 1]) > 0.0\n    assert np.abs(c[0, 2]) > 0.0\n\n\ndef test_normalizing_2():\n    c = pyefd.elliptic_fourier_descriptors(contour_1, normalize=True)\n    np.testing.assert_almost_equal(c[0, 0], 1.0, decimal=14)\n    np.testing.assert_almost_equal(c[0, 1], 0.0, decimal=14)\n    np.testing.assert_almost_equal(c[0, 2], 0.0, decimal=14)\n\n\ndef test_locus():\n    locus = pyefd.calculate_dc_coefficients(contour_1)\n    np.testing.assert_array_almost_equal(locus, np.mean(contour_1, axis=0), decimal=0)\n\n\ndef test_reconstruct_simple_contour():\n    simple_polygon = np.array([[1., 1.], [0., 1.], [0., 0.], [1., 0.], [1., 1.]])\n    number_of_points = simple_polygon.shape[0]\n    locus = pyefd.calculate_dc_coefficients(simple_polygon)\n    coeffs = pyefd.elliptic_fourier_descriptors(simple_polygon, order=30)\n\n    reconstruction = pyefd.reconstruct_contour(coeffs, locus, number_of_points)\n    # with only 2 decimal accuracy it is a bit of a course test, but it will do\n    # directly comparing the two polygons will only work here, because efd coefficients will be cycle-consistent\n    np.testing.assert_array_almost_equal(simple_polygon, reconstruction, decimal=2)\n    hausdorff_distance, _, _ = directed_hausdorff(reconstruction, simple_polygon)\n    assert hausdorff_distance < 0.01\n\n\ndef test_larger_contour():\n    locus = pyefd.calculate_dc_coefficients(contour_1)\n    coeffs = pyefd.elliptic_fourier_descriptors(contour_1, order=50)\n    number_of_points = contour_1.shape[0]\n\n    reconstruction = pyefd.reconstruct_contour(coeffs, locus, number_of_points)\n    hausdorff_distance, _, _ = directed_hausdorff(contour_1, reconstruction)\n    assert hausdorff_distance < 0.4\n\n\ndef test_performance():\n    def for_loop_efd(contour, order=10, normalize=False):\n        """"""Calculate elliptical Fourier descriptors for a contour.\n        :param numpy.ndarray contour: A contour array of size ``[M x 2]``.\n        :param int order: The order of Fourier coefficients to calculate.\n        :param bool normalize: If the coefficients should be normalized;\n            see references for details.\n        :return: A ``[order x 4]`` array of Fourier coefficients.\n        :rtype: :py:class:`numpy.ndarray`\n        """"""\n        dxy = np.diff(contour, axis=0)\n        dt = np.sqrt((dxy ** 2).sum(axis=1))\n        t = np.concatenate([([0.]), np.cumsum(dt)])\n        T = t[-1]\n\n        phi = (2 * np.pi * t) / T\n\n        coeffs = np.zeros((order, 4))\n        for n in range(1, order + 1):\n            const = T / (2 * n * n * np.pi * np.pi)\n            phi_n = phi * n\n            d_cos_phi_n = np.cos(phi_n[1:]) - np.cos(phi_n[:-1])\n            d_sin_phi_n = np.sin(phi_n[1:]) - np.sin(phi_n[:-1])\n            a_n = const * np.sum((dxy[:, 0] / dt) * d_cos_phi_n)\n            b_n = const * np.sum((dxy[:, 0] / dt) * d_sin_phi_n)\n            c_n = const * np.sum((dxy[:, 1] / dt) * d_cos_phi_n)\n            d_n = const * np.sum((dxy[:, 1] / dt) * d_sin_phi_n)\n            coeffs[n - 1, :] = a_n, b_n, c_n, d_n\n\n    sample_size = 100\n\n    start = time.time()\n\n    for _ in range(sample_size):\n        pyefd.elliptic_fourier_descriptors(contour_1, order=30)\n\n    stop = time.time()\n    vectorized_time = stop - start\n\n    print(\n        ""Time taken to create order 30 efd coefficients for 1000 contours:"",\n        vectorized_time,\n    )\n\n    start = time.time()\n    for _ in range(sample_size):\n        for_loop_efd(contour_1, order=30)\n\n    stop = time.time()\n    for_loop_time = stop - start\n    print(\n        ""Time taken to create order 30 efd coefficients for 100 contours:"",\n        for_loop_time,\n    )\n    assert vectorized_time < for_loop_time\n'"
docs/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# PyEFD documentation build configuration file, created by\n# sphinx-quickstart on Mon Apr 18 09:48:09 2016.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys\nimport os\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n# sys.path.insert(0, os.path.abspath(\'.\'))\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    ""sphinx.ext.autodoc"",\n    ""sphinx.ext.doctest"",\n    ""sphinx.ext.todo"",\n    ""sphinx.ext.coverage"",\n    ""sphinx.ext.mathjax"",\n    ""sphinx.ext.ifconfig"",\n    ""sphinx.ext.viewcode"",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [""_templates""]\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = "".rst""\n\n# The encoding of source files.\n# source_encoding = \'utf-8-sig\'\n\n# The master toctree document.\nmaster_doc = ""index""\n\n# General information about the project.\nproject = u""PyEFD""\ncopyright = u""2016, Henrik Blidh""\nauthor = u""Henrik Blidh""\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = u""1.0""\n# The full version, including alpha/beta/rc tags.\nrelease = u""1.0""\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n# today = \'\'\n# Else, today_fmt is used as the format for a strftime call.\n# today_fmt = \'%B %d, %Y\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = [""_build"", ""Thumbs.db"", "".DS_Store""]\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n# default_role = None\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n# add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n# add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n# show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = ""sphinx""\n\n# A list of ignored prefixes for module index sorting.\n# modindex_common_prefix = []\n\n# If true, keep warnings as ""system message"" paragraphs in the built documents.\n# keep_warnings = False\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n# html_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n# html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\n# html_theme_path = []\n\n# The name for this set of Sphinx documents.\n# ""<project> v<release> documentation"" by default.\n# html_title = u\'PyEFD v1.0\'\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n# html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n# html_logo = None\n\n# The name of an image file (relative to this directory) to use as a favicon of\n# the docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n# html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [""_static""]\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n# html_extra_path = []\n\n# If not None, a \'Last updated on:\' timestamp is inserted at every page\n# bottom, using the given strftime format.\n# The empty string is equivalent to \'%b %d, %Y\'.\n# html_last_updated_fmt = None\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n# html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n# html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n# html_additional_pages = {}\n\n# If false, no module index is generated.\n# html_domain_indices = True\n\n# If false, no index is generated.\n# html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n# html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n# html_show_sourcelink = True\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.\n# html_show_sphinx = True\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.\n# html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n# html_use_opensearch = \'\'\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n# html_file_suffix = None\n\n# Language to be used for generating the HTML full-text search index.\n# Sphinx supports the following languages:\n#   \'da\', \'de\', \'en\', \'es\', \'fi\', \'fr\', \'hu\', \'it\', \'ja\'\n#   \'nl\', \'no\', \'pt\', \'ro\', \'ru\', \'sv\', \'tr\', \'zh\'\n# html_search_language = \'en\'\n\n# A dictionary with options for the search language support, empty by default.\n# \'ja\' uses this config value.\n# \'zh\' user can custom change `jieba` dictionary path.\n# html_search_options = {\'type\': \'default\'}\n\n# The name of a javascript file (relative to the configuration directory) that\n# implements a search results scorer. If empty, the default will be used.\n# html_search_scorer = \'scorer.js\'\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = ""PyEFDdoc""\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    # \'papersize\': \'letterpaper\',\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    # \'pointsize\': \'10pt\',\n    # Additional stuff for the LaTeX preamble.\n    # \'preamble\': \'\',\n    # Latex figure (float) alignment\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, ""PyEFD.tex"", u""PyEFD Documentation"", u""Henrik Blidh"", ""manual"")\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n# latex_logo = None\n\n# For ""manual"" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n# latex_use_parts = False\n\n# If true, show page references after internal links.\n# latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n# latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n# latex_appendices = []\n\n# If false, no module index is generated.\n# latex_domain_indices = True\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [(master_doc, ""pyefd"", u""PyEFD Documentation"", [author], 1)]\n\n# If true, show URL addresses after external links.\n# man_show_urls = False\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        master_doc,\n        ""PyEFD"",\n        u""PyEFD Documentation"",\n        author,\n        ""PyEFD"",\n        ""One line description of project."",\n        ""Miscellaneous"",\n    )\n]\n\n# Documents to append as an appendix to all manuals.\n# texinfo_appendices = []\n\n# If false, no module index is generated.\n# texinfo_domain_indices = True\n\n# How to display URL addresses: \'footnote\', \'no\', or \'inline\'.\n# texinfo_show_urls = \'footnote\'\n\n# If true, do not generate a @detailmenu in the ""Top"" node\'s menu.\n# texinfo_no_detailmenu = False\n'"
