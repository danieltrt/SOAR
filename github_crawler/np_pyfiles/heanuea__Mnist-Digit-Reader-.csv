file_path,api_count,code
app.py,1,"b""# taken from https://community.canvaslms.com/thread/2595\n\nfrom flask import Flask, render_template,url_for, request, jsonify\nimport numpy as np\nimport tensorflow as tf\nfrom PIL import Image\nimport re\nimport io\nimport base64\n\nimport tensor as ten\n\napp = Flask(__name__)\n\n\n@app.route('/', methods=['GET','POST'])\ndef get_image(): \n    guess = 0\n    if request.method== 'POST':\n        #requests image from url \n        img_size = 28, 28 \n        image_url = request.values['imageBase64']  \n        image_string = re.search(r'base64,(.*)', image_url).group(1)  \n        image_bytes = io.BytesIO(base64.b64decode(image_string)) \n        image = Image.open(image_bytes) \n        image = image.resize(img_size, Image.LANCZOS)  \n        image = image.convert('1') \n        image_array = np.asarray(image)\n        image_array = image_array.flatten()  \n        \n        with tf.Session() as sess:\n            saver = tf.train.import_meta_graph('tmp/tensor_model.meta')\n            saver.restore(sess, tf.train.latest_checkpoint('tmp/'))\n\n            predict_number = tf.argmax(ten.y, 1)\n            predicted_number = ten.sess.run([predict_number], feed_dict={ten.x: [image_array]})\n            guess = predicted_number[0][0]\n            guess = int(guess)\n            print(guess)\n\n        return jsonify(guess = guess) #returns as jason format\n\n    return render_template('index.html', guess = guess)\n\n\nif __name__ == '__main__':\n    app.run(debug = True)\n"""
tensor.py,0,"b'\n#   TfLearn version of DeepMNIST\n# taking from https://www.tensorflow.org/get_started/mnist/pros\nfrom tensorflow.examples.tutorials.mnist import input_data\n# Create input object which reads data from MNIST datasets.  Perform one-hot encoding to define the digit\nmnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)\n\nsavePath = \'tmp/tensor_model\'\n\n# Using Interactive session makes it the default sessions so we do not need to pass sess \nimport tensorflow as tf\nsess = tf.InteractiveSession()\n\n\n\n# Define placeholders for MNIST input data\n\nx = tf.placeholder(tf.float32, shape=[None, 784])\ny_ = tf.placeholder(tf.float32, [None, 10])  \n    #We now define the weights W and biases b for our model. \nW = tf.Variable(tf.zeros([784, 10]))\nb = tf.Variable(tf.zeros([10]))\n\n#Before Variables can be used within a session, they must be initialized using that session\nsess.run(tf.global_variables_initializer())\n\n# Save the session for later use\nsaver = tf.train.Saver()\n\n# regression model\ny = tf.nn.softmax(tf.matmul(x,W)+b)\n\n# Set prediction\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n\n\n# Set training\n#TensorFlow has a variety of built-in optimization algorithms.\n# For this example, we will use steepest gradient descent,\n# with a step length of 0.5, to descend the cross entropy.\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\n# Train the model\nfor _ in range(10000):\n    batch = mnist.train.next_batch(100)  \n    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n\t\n# Evaluate the model \ncorrect_pred = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Print out the accuracy\nacc_eval = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\nprint(""Current accuracy: %.2f%%""% (acc_eval*100))\t\n\n# Save the path to the trained model\nsaver.save(sess, savePath)\nprint(\'Session saved in path \'+savePath)\n\n#print(""Test accuracy {0:.3f}%"".format(accuracy.eval(feed_dict={\n   # x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})*100.0))\n#model.save(\'LSTM_model.tfl\')\n# model.save(""mnist_model.h5"")-'"
