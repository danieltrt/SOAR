file_path,api_count,code
06. Neural Networks in PyTorch/helper.py,6,"b'import matplotlib.pyplot as plt\nimport numpy as np\nfrom torch import nn, optim\nfrom torch.autograd import Variable\n\n\ndef test_network(net, trainloader):\n\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(net.parameters(), lr=0.001)\n\n    dataiter = iter(trainloader)\n    images, labels = dataiter.next()\n\n    # Create Variables for the inputs and targets\n    inputs = Variable(images)\n    targets = Variable(images)\n\n    # Clear the gradients from all Variables\n    optimizer.zero_grad()\n\n    # Forward pass, then backward pass, then update weights\n    output = net.forward(inputs)\n    loss = criterion(output, targets)\n    loss.backward()\n    optimizer.step()\n\n    return True\n\n\ndef imshow(image, ax=None, title=None, normalize=True):\n    """"""Imshow for Tensor.""""""\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.spines[\'left\'].set_visible(False)\n    ax.spines[\'bottom\'].set_visible(False)\n    ax.tick_params(axis=\'both\', length=0)\n    ax.set_xticklabels(\'\')\n    ax.set_yticklabels(\'\')\n\n    return ax\n\n\ndef view_recon(img, recon):\n    \'\'\' Function for displaying an image (as a PyTorch Tensor) and its\n        reconstruction also a PyTorch Tensor\n    \'\'\'\n\n    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n    axes[0].imshow(img.numpy().squeeze())\n    axes[1].imshow(recon.data.numpy().squeeze())\n    for ax in axes:\n        ax.axis(\'off\')\n        ax.set_adjustable(\'box-forced\')\n\ndef view_classify(img, ps, version=""MNIST""):\n    \'\'\' Function for viewing an image and it\'s predicted classes.\n    \'\'\'\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis(\'off\')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    if version == ""MNIST"":\n        ax2.set_yticklabels(np.arange(10))\n    elif version == ""Fashion"":\n        ax2.set_yticklabels([\'T-shirt/top\',\n                            \'Trouser\',\n                            \'Pullover\',\n                            \'Dress\',\n                            \'Coat\',\n                            \'Sandal\',\n                            \'Shirt\',\n                            \'Sneaker\',\n                            \'Bag\',\n                            \'Ankle Boot\'], size=\'small\');\n    ax2.set_title(\'Class Probability\')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n'"
07. Training Neural Networks in PyTorch/helper.py,6,"b'import matplotlib.pyplot as plt\nimport numpy as np\nfrom torch import nn, optim\nfrom torch.autograd import Variable\n\n\ndef test_network(net, trainloader):\n\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(net.parameters(), lr=0.001)\n\n    dataiter = iter(trainloader)\n    images, labels = dataiter.next()\n\n    # Create Variables for the inputs and targets\n    inputs = Variable(images)\n    targets = Variable(images)\n\n    # Clear the gradients from all Variables\n    optimizer.zero_grad()\n\n    # Forward pass, then backward pass, then update weights\n    output = net.forward(inputs)\n    loss = criterion(output, targets)\n    loss.backward()\n    optimizer.step()\n\n    return True\n\n\ndef imshow(image, ax=None, title=None, normalize=True):\n    """"""Imshow for Tensor.""""""\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.spines[\'left\'].set_visible(False)\n    ax.spines[\'bottom\'].set_visible(False)\n    ax.tick_params(axis=\'both\', length=0)\n    ax.set_xticklabels(\'\')\n    ax.set_yticklabels(\'\')\n\n    return ax\n\n\ndef view_recon(img, recon):\n    \'\'\' Function for displaying an image (as a PyTorch Tensor) and its\n        reconstruction also a PyTorch Tensor\n    \'\'\'\n\n    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n    axes[0].imshow(img.numpy().squeeze())\n    axes[1].imshow(recon.data.numpy().squeeze())\n    for ax in axes:\n        ax.axis(\'off\')\n        ax.set_adjustable(\'box-forced\')\n\ndef view_classify(img, ps, version=""MNIST""):\n    \'\'\' Function for viewing an image and it\'s predicted classes.\n    \'\'\'\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis(\'off\')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    if version == ""MNIST"":\n        ax2.set_yticklabels(np.arange(10))\n    elif version == ""Fashion"":\n        ax2.set_yticklabels([\'T-shirt/top\',\n                            \'Trouser\',\n                            \'Pullover\',\n                            \'Dress\',\n                            \'Coat\',\n                            \'Sandal\',\n                            \'Shirt\',\n                            \'Sneaker\',\n                            \'Bag\',\n                            \'Ankle Boot\'], size=\'small\');\n    ax2.set_title(\'Class Probability\')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n'"
08. Classifying Fashion-MNIST In PyTorch/helper.py,6,"b'import matplotlib.pyplot as plt\nimport numpy as np\nfrom torch import nn, optim\nfrom torch.autograd import Variable\n\n\ndef test_network(net, trainloader):\n\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(net.parameters(), lr=0.001)\n\n    dataiter = iter(trainloader)\n    images, labels = dataiter.next()\n\n    # Create Variables for the inputs and targets\n    inputs = Variable(images)\n    targets = Variable(images)\n\n    # Clear the gradients from all Variables\n    optimizer.zero_grad()\n\n    # Forward pass, then backward pass, then update weights\n    output = net.forward(inputs)\n    loss = criterion(output, targets)\n    loss.backward()\n    optimizer.step()\n\n    return True\n\n\ndef imshow(image, ax=None, title=None, normalize=True):\n    """"""Imshow for Tensor.""""""\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.spines[\'left\'].set_visible(False)\n    ax.spines[\'bottom\'].set_visible(False)\n    ax.tick_params(axis=\'both\', length=0)\n    ax.set_xticklabels(\'\')\n    ax.set_yticklabels(\'\')\n\n    return ax\n\n\ndef view_recon(img, recon):\n    \'\'\' Function for displaying an image (as a PyTorch Tensor) and its\n        reconstruction also a PyTorch Tensor\n    \'\'\'\n\n    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n    axes[0].imshow(img.numpy().squeeze())\n    axes[1].imshow(recon.data.numpy().squeeze())\n    for ax in axes:\n        ax.axis(\'off\')\n        ax.set_adjustable(\'box-forced\')\n\ndef view_classify(img, ps, version=""MNIST""):\n    \'\'\' Function for viewing an image and it\'s predicted classes.\n    \'\'\'\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis(\'off\')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    if version == ""MNIST"":\n        ax2.set_yticklabels(np.arange(10))\n    elif version == ""Fashion"":\n        ax2.set_yticklabels([\'T-shirt/top\',\n                            \'Trouser\',\n                            \'Pullover\',\n                            \'Dress\',\n                            \'Coat\',\n                            \'Sandal\',\n                            \'Shirt\',\n                            \'Sneaker\',\n                            \'Bag\',\n                            \'Ankle Boot\'], size=\'small\');\n    ax2.set_title(\'Class Probability\')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n'"
09. Inference & Validation in PyTorch/helper.py,6,"b'import matplotlib.pyplot as plt\nimport numpy as np\nfrom torch import nn, optim\nfrom torch.autograd import Variable\n\n\ndef test_network(net, trainloader):\n\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(net.parameters(), lr=0.001)\n\n    dataiter = iter(trainloader)\n    images, labels = dataiter.next()\n\n    # Create Variables for the inputs and targets\n    inputs = Variable(images)\n    targets = Variable(images)\n\n    # Clear the gradients from all Variables\n    optimizer.zero_grad()\n\n    # Forward pass, then backward pass, then update weights\n    output = net.forward(inputs)\n    loss = criterion(output, targets)\n    loss.backward()\n    optimizer.step()\n\n    return True\n\n\ndef imshow(image, ax=None, title=None, normalize=True):\n    """"""Imshow for Tensor.""""""\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.spines[\'left\'].set_visible(False)\n    ax.spines[\'bottom\'].set_visible(False)\n    ax.tick_params(axis=\'both\', length=0)\n    ax.set_xticklabels(\'\')\n    ax.set_yticklabels(\'\')\n\n    return ax\n\n\ndef view_recon(img, recon):\n    \'\'\' Function for displaying an image (as a PyTorch Tensor) and its\n        reconstruction also a PyTorch Tensor\n    \'\'\'\n\n    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n    axes[0].imshow(img.numpy().squeeze())\n    axes[1].imshow(recon.data.numpy().squeeze())\n    for ax in axes:\n        ax.axis(\'off\')\n        ax.set_adjustable(\'box-forced\')\n\ndef view_classify(img, ps, version=""MNIST""):\n    \'\'\' Function for viewing an image and it\'s predicted classes.\n    \'\'\'\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis(\'off\')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    if version == ""MNIST"":\n        ax2.set_yticklabels(np.arange(10))\n    elif version == ""Fashion"":\n        ax2.set_yticklabels([\'T-shirt/top\',\n                            \'Trouser\',\n                            \'Pullover\',\n                            \'Dress\',\n                            \'Coat\',\n                            \'Sandal\',\n                            \'Shirt\',\n                            \'Sneaker\',\n                            \'Bag\',\n                            \'Ankle Boot\'], size=\'small\');\n    ax2.set_title(\'Class Probability\')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n'"
10. Saving and Loading Models in PyTorch/fc_model.py,0,"b'import torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n\nclass Network(nn.Module):\n    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n        \'\'\' Builds a feedforward network with arbitrary hidden layers.\n        \n            Arguments\n            ---------\n            input_size: integer, size of the input layer\n            output_size: integer, size of the output layer\n            hidden_layers: list of integers, the sizes of the hidden layers\n        \n        \'\'\'\n        super().__init__()\n        # Input to a hidden layer\n        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n        \n        # Add a variable number of more hidden layers\n        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n        \n        self.output = nn.Linear(hidden_layers[-1], output_size)\n        \n        self.dropout = nn.Dropout(p=drop_p)\n        \n    def forward(self, x):\n        \'\'\' Forward pass through the network, returns the output logits \'\'\'\n        \n        for each in self.hidden_layers:\n            x = F.relu(each(x))\n            x = self.dropout(x)\n        x = self.output(x)\n        \n        return F.log_softmax(x, dim=1)\n\n\ndef validation(model, testloader, criterion):\n    accuracy = 0\n    test_loss = 0\n    for images, labels in testloader:\n\n        images = images.resize_(images.size()[0], 784)\n\n        output = model.forward(images)\n        test_loss += criterion(output, labels).item()\n\n        ## Calculating the accuracy \n        # Model\'s output is log-softmax, take exponential to get the probabilities\n        ps = torch.exp(output)\n        # Class with highest probability is our predicted class, compare with true label\n        equality = (labels.data == ps.max(1)[1])\n        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n        accuracy += equality.type_as(torch.FloatTensor()).mean()\n\n    return test_loss, accuracy\n\n\ndef train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n    \n    steps = 0\n    running_loss = 0\n    for e in range(epochs):\n        # Model in training mode, dropout is on\n        model.train()\n        for images, labels in trainloader:\n            steps += 1\n            \n            # Flatten images into a 784 long vector\n            images.resize_(images.size()[0], 784)\n            \n            optimizer.zero_grad()\n            \n            output = model.forward(images)\n            loss = criterion(output, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n\n            if steps % print_every == 0:\n                # Model in inference mode, dropout is off\n                model.eval()\n                \n                # Turn off gradients for validation, will speed up inference\n                with torch.no_grad():\n                    test_loss, accuracy = validation(model, testloader, criterion)\n                \n                print(""Epoch: {}/{}.. "".format(e+1, epochs),\n                      ""Training Loss: {:.3f}.. "".format(running_loss/print_every),\n                      ""Test Loss: {:.3f}.. "".format(test_loss/len(testloader)),\n                      ""Test Accuracy: {:.3f}"".format(accuracy/len(testloader)))\n                \n                running_loss = 0\n                \n                # Make sure dropout and grads are on for training\n                model.train()\n'"
10. Saving and Loading Models in PyTorch/helper.py,6,"b'import matplotlib.pyplot as plt\nimport numpy as np\nfrom torch import nn, optim\nfrom torch.autograd import Variable\n\n\ndef test_network(net, trainloader):\n\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(net.parameters(), lr=0.001)\n\n    dataiter = iter(trainloader)\n    images, labels = dataiter.next()\n\n    # Create Variables for the inputs and targets\n    inputs = Variable(images)\n    targets = Variable(images)\n\n    # Clear the gradients from all Variables\n    optimizer.zero_grad()\n\n    # Forward pass, then backward pass, then update weights\n    output = net.forward(inputs)\n    loss = criterion(output, targets)\n    loss.backward()\n    optimizer.step()\n\n    return True\n\n\ndef imshow(image, ax=None, title=None, normalize=True):\n    """"""Imshow for Tensor.""""""\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.spines[\'left\'].set_visible(False)\n    ax.spines[\'bottom\'].set_visible(False)\n    ax.tick_params(axis=\'both\', length=0)\n    ax.set_xticklabels(\'\')\n    ax.set_yticklabels(\'\')\n\n    return ax\n\n\ndef view_recon(img, recon):\n    \'\'\' Function for displaying an image (as a PyTorch Tensor) and its\n        reconstruction also a PyTorch Tensor\n    \'\'\'\n\n    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n    axes[0].imshow(img.numpy().squeeze())\n    axes[1].imshow(recon.data.numpy().squeeze())\n    for ax in axes:\n        ax.axis(\'off\')\n        ax.set_adjustable(\'box-forced\')\n\ndef view_classify(img, ps, version=""MNIST""):\n    \'\'\' Function for viewing an image and it\'s predicted classes.\n    \'\'\'\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis(\'off\')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    if version == ""MNIST"":\n        ax2.set_yticklabels(np.arange(10))\n    elif version == ""Fashion"":\n        ax2.set_yticklabels([\'T-shirt/top\',\n                            \'Trouser\',\n                            \'Pullover\',\n                            \'Dress\',\n                            \'Coat\',\n                            \'Sandal\',\n                            \'Shirt\',\n                            \'Sneaker\',\n                            \'Bag\',\n                            \'Ankle Boot\'], size=\'small\');\n    ax2.set_title(\'Class Probability\')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n'"
11. Loading Image Data in PyTorch/helper.py,6,"b'import matplotlib.pyplot as plt\nimport numpy as np\nfrom torch import nn, optim\nfrom torch.autograd import Variable\n\n\ndef test_network(net, trainloader):\n\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(net.parameters(), lr=0.001)\n\n    dataiter = iter(trainloader)\n    images, labels = dataiter.next()\n\n    # Create Variables for the inputs and targets\n    inputs = Variable(images)\n    targets = Variable(images)\n\n    # Clear the gradients from all Variables\n    optimizer.zero_grad()\n\n    # Forward pass, then backward pass, then update weights\n    output = net.forward(inputs)\n    loss = criterion(output, targets)\n    loss.backward()\n    optimizer.step()\n\n    return True\n\n\ndef imshow(image, ax=None, title=None, normalize=True):\n    """"""Imshow for Tensor.""""""\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines[\'top\'].set_visible(False)\n    ax.spines[\'right\'].set_visible(False)\n    ax.spines[\'left\'].set_visible(False)\n    ax.spines[\'bottom\'].set_visible(False)\n    ax.tick_params(axis=\'both\', length=0)\n    ax.set_xticklabels(\'\')\n    ax.set_yticklabels(\'\')\n\n    return ax\n\n\ndef view_recon(img, recon):\n    \'\'\' Function for displaying an image (as a PyTorch Tensor) and its\n        reconstruction also a PyTorch Tensor\n    \'\'\'\n\n    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n    axes[0].imshow(img.numpy().squeeze())\n    axes[1].imshow(recon.data.numpy().squeeze())\n    for ax in axes:\n        ax.axis(\'off\')\n        ax.set_adjustable(\'box-forced\')\n\ndef view_classify(img, ps, version=""MNIST""):\n    \'\'\' Function for viewing an image and it\'s predicted classes.\n    \'\'\'\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis(\'off\')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    if version == ""MNIST"":\n        ax2.set_yticklabels(np.arange(10))\n    elif version == ""Fashion"":\n        ax2.set_yticklabels([\'T-shirt/top\',\n                            \'Trouser\',\n                            \'Pullover\',\n                            \'Dress\',\n                            \'Coat\',\n                            \'Sandal\',\n                            \'Shirt\',\n                            \'Sneaker\',\n                            \'Bag\',\n                            \'Ankle Boot\'], size=\'small\');\n    ax2.set_title(\'Class Probability\')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()\n'"
