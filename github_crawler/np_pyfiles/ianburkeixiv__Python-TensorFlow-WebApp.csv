file_path,api_count,code
app.py,3,"b'from flask import Flask, flash, render_template, request, redirect, url_for, send_from_directory\nfrom werkzeug.utils import secure_filename \nimport os\nfrom skimage import color # change colour of image\nfrom scipy.misc import imread, imresize, imsave # For images\nimport numpy as np # martix math\nimport re #regular expression used for canvas img string data\nimport base64 # Encode canvas data bytes\nimport keras.models as km \nfrom keras.models import model_from_json\n\n# Upload files code adapted from: http://flask.pocoo.org/docs/0.12/patterns/fileuploads/\n# Canvas image code adapted from: https://github.com/llSourcell/how_to_deploy_a_keras_model_to_production/blob/master/app.py\n\n# =========== Initialisation ============================================================================================================\n\n# UPLOAD_FOLDER is where we will store the uploaded image files\nUPLOAD_FOLDER = \'./static/uploads\'\n# set of allowed file extensions.\nALLOWED_EXTENSIONS = set([\'pdf\', \'png\', \'jpg\', \'jpeg\', \'gif\']) \n\n# Pass in __name__ to help flask determine root path\napp = Flask(__name__) # Initialising flask app\napp.config[\'UPLOAD_FOLDER\'] = UPLOAD_FOLDER # configure upload folder\n\n# =============== Routing/Mapping =======================================================================================================\n\n# @ signifies a decorator which is a way to wrap a function and modify its behaviour\n@app.route(\'/\') #connect a webpage. \'/\' is a root directory.\ndef main():\n   return render_template(""index.html"") # return rendered template \n\n# ============== Upload image ====================\n\n# function that checks if file extension is allowed\ndef allowed_file(filename):\n    return \'.\' in filename and \\\n           filename.rsplit(\'.\', 1)[1].lower() in ALLOWED_EXTENSIONS\n\n# Upload Image file\n@app.route(""/upload"", methods=[\'GET\', \'POST\']) \ndef upload_file():\n    if request.method == \'POST\':\n        # check if the post request has the file part\n        if \'file\' not in request.files:\n            flash(\'No file part\')\n            return redirect(request.url)\n        file = request.files[\'file\']\n        # if user does not select file, browser also\n        # submit a empty part without filename\n        if file.filename == \'\':\n            flash(\'No selected file\')\n            return redirect(request.url)\n        # if theres a file with allowed extension then..\n        if file and allowed_file(file.filename):\n            # secure a filename before storing it directly\n            filename = secure_filename(file.filename) \n            # Save file to upload_folder\n            file.save(os.path.join(app.config[\'UPLOAD_FOLDER\'], filename)) \n           \n            return redirect(url_for(\'uploaded_file\', filename=filename))\n    \n   # return render_template(\'index.html\')\n\n#@app.route(\'/uploads/<filename>\')\n#def uploaded_file(filename):\n#    return send_from_directory(app.config[\'UPLOAD_FOLDER\'],filename)\n\n# ============== Canvas Image ========================\n\n# Canvas Digit Image \n@app.route(\'/predict\',methods=[\'GET\',\'POST\'])\ndef predict():\n    # Get data from canvas\n    imgData = request.get_data()\n    # base64 is used to take binary data and turn it into text to easily transmit from html,\n    # using regular expression\n    # Adapted from: https://github.com/llSourcell/how_to_deploy_a_keras_model_to_production/blob/master/app.py\n    imgstr = re.search(b\'base64,(.*)\', imgData).group(1)\n    # Create/open file and write in the encoded data then decode it to form the image\n    with open(\'digit.png\',\'wb\') as output:\n        output.write(base64.decodebytes(imgstr))\n    \n    # read parsed image back in mode L = 8-bit pixels, black and white.\n    img = imread(\'digit.png\',mode=\'L\')\n    # compute a bit-wise inversion\n    img = np.invert(img)\n    # make it 28x28\n    img = imresize(img,(28,28))\n    \n    #convert to a 4D tensor to feed into our neural network model\n    img = img.reshape(1,28,28,1)\n    \n    # call our pre loaded graph from load.py\n    #with graph.as_default():\n    json_file = open(\'./model/mnistModel.json\',\'r\') # open json file\n    model_json = json_file.read() # read the model structure\n    json_file.close() # close when done\n    # \n    model = model_from_json(model_json)\n    # predict the digit using our model\n    model.load_weights(\'./model/mnistModel.h5\')\n    #model = km.load_model()\n    # feed the image into the model and get our prediction\n    prediction = model.predict(img)\n    #print(prediction)\n    #print(np.argmax(prediction,axis=1))\n    #convert the response to a string\n    response = np.array_str(np.argmax(prediction,axis=1))\n    return response \n\n\n\n\nif __name__ == ""__main__"":\n    app.run(debug=True) # Start the web server. debug=True means to auto refresh page after code changes '"
mnist_nn.py,2,"b'import keras as kr\nfrom keras.datasets import mnist # automatically downloaded once function is called.\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.utils import np_utils\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n\n# MNIST convolutional neural network (CNN)\n\n# Adapted from: https://github.com/wxs/keras-mnist-tutorial/blob/master/MNIST%20in%20Keras.ipynb\n\n# input image dimensions\n# 28x28 pixel images. \nimg_rows, img_cols = 28, 28\n\n# Load the pre-shuffled MNIST dataset from keras.datasets -> Dataset of 60,000 28x28 grayscale images of 10 digits & test set of 10,000 images\n# 2 tuples ( immutable data structure/lists consisting of mulitple parts):\n# x_train, x_test = Uint8 array of grayscale image data with shape (num_samples, 28,28)\n# y_train, y_test = Uint8 array of digit labels (integers in range 0-9) with shape(num_samples)\n# Adapted from: https://keras.io/datasets/\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n\n# this assumes our data format \n# depending on format...Arrange the data in a certain way\n# For 3D data, ""channels_last"" assumes (conv_dim1, conv_dim2, conv_dim3, channels) while \n# ""channels_first"" assumes (channels, conv_dim1, conv_dim2, conv_dim3).\nif K.image_data_format() == \'channels_first\':\n    \n    # We must declare a dimension of depth of the input image\n    # a full-color image with all 3 RGB channels will have a depth of 3\n    # MNIST images only have a depth of 1 (greyscale) but we need to declare that..\n    # we want to transform our dataset from having shape (n, width, height) to (n, depth, width, height).\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\n\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n\ninput_shape = (img_rows, img_cols, 1)\n\n# Format/reshape the data for training\nx_train = x_train.astype(\'float32\')\nx_test = x_test.astype(\'float32\')\n# normalize inputs from 0-255 to 0-1\nx_train /= 255\nx_test /= 255\n\n# there are 10 image classes\nnum_classes = 10 \n\n# Convert 1-dimensional class arrays to 10-dimensional class matrices\ny_train = kr.utils.to_categorical(y_train, num_classes)\ny_test = kr.utils.to_categorical(y_test, num_classes)\n# This means that if the array is:\n# [1, 0, 0, 0, 0, 0, 0, 0, 0, 0] then digit = 0\n# [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] then digit = 1\n# [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] then digit = 2\n# [0, 0, 0, 1, 0, 0, 0, 0, 0, 0] then digit = 3\n# [0, 0, 0, 0, 1, 0, 0, 0, 0, 0] then digit = 4 and so on..to 9\n\n# ================== CREATE MODEL ============================================================\n# A model is understood as a sequence or a graph of standalone, \n# ..fully-configurable modules that can be plugged together with as little restrictions as possible.\n# For more: https://keras.io/\n# Creating model and a neural network\n# model is used to organise layers\n# Create our model using sequential model which is a linear stack of layers\nmodel = Sequential()\n\n# Using 2D convolution layer. Ref: https://keras.io/layers/convolutional/\n# Declare input layer\n# 32 = the number output of filters in the convolution\n# kernel_size = list of 2 integers, specifying the width and height of the 2D convolution window\n# activation function \'relu\' which means rectified linear unit\n# input_shape = (1,28,28) = (depth, width, height)\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation=\'relu\',\n                 kernel_initializer=\'he_normal\',\n                 input_shape=input_shape))\n\n# Dropout method for regularizing our model in order to prevent overfitting\n# Add another convolution layer\nmodel.add(Conv2D(64, (3, 3), activation=\'relu\'))\n# MaxPooling2D is a way to reduce the number of parameters in our model.. \n# by sliding a 2x2 pooling filter across the previous layer and taking the max of the 4 values in the 2x2 filter\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# Dropout method for regularizing our model in order to prevent overfitting\nmodel.add(Dropout(0.25)) # float between 0 and 1. Fraction of the input units to drop.\n# Flatten the weights to 1 dimensional before passing to dense layer\nmodel.add(Flatten())\n# Add dense layer\n# 128 = output size\nmodel.add(Dense(128, activation=\'relu\'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation=\'softmax\'))\n\n\n# ================ TRAIN THE MODEL ======================================================\n# Configure and compile the model for training.\n# Uses the adam optimizer and categorical cross entropy as the loss function.\n# using adam optimizer algorithm for gradient descent\n# Loss function is the objective that the model will try to minimize\n# Add in some extra metrics - accuracy being the only one\nmodel.compile(optimizer=""adam"",\n                loss=""categorical_crossentropy"",\n                metrics=[""accuracy""])\n\n\n# Fit the model using our training data.\n# epochs is the number of times the training algorithm will iterate over the entire training set before terminating\n# batch_size is the number of training examples being used simultaneously during a single iteration\n# verbose is used to log the model being trained\n# verbose=1 means verbose mode 1 which is a progress bar\n# Verbosity mode: 0 = silent, 1 = progress bar, 2 = one line per epoch.\nmodel.fit(x_train, y_train, batch_size=128, epochs=4, verbose=1)\n\n# ================== TEST MODEL ==========================================================\n# Evaluate the model using the test data set.\n# model.evaluate compare answers\n# Verbose mode: 0 = silent\nloss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n\n# Output the accuracy of the model.\nprint(""\\n\\nLoss: %6.4f\\tAccuracy: %6.4f"" % (loss, accuracy))\n\n# ================== Prediction ===========================================================\n# Predict the digit\n# using model.predict\n# numpy.around to evenly round the given data\n# numpy.expand_dims to expand the shape of an array\nprediction = np.around(model.predict(np.expand_dims(x_test[0], axis=0))).astype(np.int)[0]\n\n# print out the actual digit and the prediction\nprint(""Actual: %s\\tEstimated: %s"" % (y_test[0].astype(np.int), prediction))\n\n# Json file used to save structure of model \n# faster way to have the model loaded when called from the app\n# parse/serialise model to json format\nmodel_json = model.to_json()\nwith open(""mnistModel.json"", ""w"") as json_file:\n    json_file.write(model_json)\n\n# Save the model weights (learned values)\n# h5 is the file format for keras to save the weights of model\nmodel.save(""mnistModel.h5"")'"
