file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python3\n\nfrom setuptools import setup\n\nsetup(\n    name=""orjson"",\n    url=""https://github.com/ijl/orjson"",\n)\n'"
bench/__init__.py,0,b''
bench/benchmark_dumps.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\n\nfrom json import dumps as _json_dumps\nfrom json import loads as json_loads\n\nfrom orjson import dumps as _orjson_dumps\nfrom rapidjson import dumps as _rapidjson_dumps\nfrom simplejson import dumps as _simplejson_dumps\nfrom ujson import dumps as _ujson_dumps\n\nfrom .util import read_fixture_obj\n\n\ndef orjson_dumps(obj):\n    return _orjson_dumps(obj)\n\n\ndef ujson_dumps(obj):\n    return _ujson_dumps(obj).encode(""utf-8"")\n\n\ndef rapidjson_dumps(obj):\n    return _rapidjson_dumps(obj).encode(""utf-8"")\n\n\ndef json_dumps(obj):\n    return _json_dumps(obj).encode(""utf-8"")\n\n\ndef simplejson_dumps(obj):\n    return _simplejson_dumps(obj).encode(""utf-8"")\n\n\ndef test_dumps_canada_orjson(benchmark):\n    benchmark.group = ""canada.json serialization""\n    benchmark.extra_info[""lib""] = ""orjson""\n    data = read_fixture_obj(""canada.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(orjson_dumps(data)) == data\n    benchmark(orjson_dumps, data)\n\n\ndef test_dumps_canada_ujson(benchmark):\n    benchmark.group = ""canada.json serialization""\n    benchmark.extra_info[""lib""] = ""ujson""\n    data = read_fixture_obj(""canada.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(ujson_dumps(data)) == data\n    benchmark(ujson_dumps, data)\n\n\ndef test_dumps_canada_json(benchmark):\n    benchmark.group = ""canada.json serialization""\n    benchmark.extra_info[""lib""] = ""json""\n    data = read_fixture_obj(""canada.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(json_dumps(data)) == data\n    benchmark(json_dumps, data)\n\n\ndef test_dumps_canada_rapidjson(benchmark):\n    benchmark.group = ""canada.json serialization""\n    benchmark.extra_info[""lib""] = ""rapidjson""\n    data = read_fixture_obj(""canada.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(rapidjson_dumps(data)) == data\n    benchmark(rapidjson_dumps, data)\n\n\ndef test_dumps_canada_simplejson(benchmark):\n    benchmark.group = ""canada.json serialization""\n    benchmark.extra_info[""lib""] = ""simplejson""\n    data = read_fixture_obj(""canada.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(simplejson_dumps(data)) == data\n    benchmark(simplejson_dumps, data)\n\n\ndef test_dumps_citm_catalog_orjson(benchmark):\n    benchmark.group = ""citm_catalog.json serialization""\n    benchmark.extra_info[""lib""] = ""orjson""\n    data = read_fixture_obj(""citm_catalog.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(orjson_dumps(data)) == data\n    benchmark(orjson_dumps, data)\n\n\ndef test_dumps_citm_catalog_ujson(benchmark):\n    benchmark.group = ""citm_catalog.json serialization""\n    benchmark.extra_info[""lib""] = ""ujson""\n    data = read_fixture_obj(""citm_catalog.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(ujson_dumps(data)) == data\n    benchmark(ujson_dumps, data)\n\n\ndef test_dumps_citm_catalog_json(benchmark):\n    benchmark.group = ""citm_catalog.json serialization""\n    benchmark.extra_info[""lib""] = ""json""\n    data = read_fixture_obj(""citm_catalog.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(json_dumps(data)) == data\n    benchmark(json_dumps, data)\n\n\ndef test_dumps_citm_catalog_rapidjson(benchmark):\n    benchmark.group = ""citm_catalog.json serialization""\n    benchmark.extra_info[""lib""] = ""rapidjson""\n    data = read_fixture_obj(""citm_catalog.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(rapidjson_dumps(data)) == data\n    benchmark(rapidjson_dumps, data)\n\n\ndef test_dumps_citm_catalog_simplejson(benchmark):\n    benchmark.group = ""citm_catalog.json serialization""\n    benchmark.extra_info[""lib""] = ""simplejson""\n    data = read_fixture_obj(""citm_catalog.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(simplejson_dumps(data)) == data\n    benchmark(simplejson_dumps, data)\n\n\ndef test_dumps_github_orjson(benchmark):\n    benchmark.group = ""github.json serialization""\n    benchmark.extra_info[""lib""] = ""orjson""\n    data = read_fixture_obj(""github.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(orjson_dumps(data)) == data\n    benchmark(orjson_dumps, data)\n\n\ndef test_dumps_github_ujson(benchmark):\n    benchmark.group = ""github.json serialization""\n    benchmark.extra_info[""lib""] = ""ujson""\n    data = read_fixture_obj(""github.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(ujson_dumps(data)) == data\n    benchmark(ujson_dumps, data)\n\n\ndef test_dumps_github_json(benchmark):\n    benchmark.group = ""github.json serialization""\n    benchmark.extra_info[""lib""] = ""json""\n    data = read_fixture_obj(""github.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(json_dumps(data)) == data\n    benchmark(json_dumps, data)\n\n\ndef test_dumps_github_rapidjson(benchmark):\n    benchmark.group = ""github.json serialization""\n    benchmark.extra_info[""lib""] = ""rapidjson""\n    data = read_fixture_obj(""github.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(rapidjson_dumps(data)) == data\n    benchmark(rapidjson_dumps, data)\n\n\ndef test_dumps_github_simplejson(benchmark):\n    benchmark.group = ""github.json serialization""\n    benchmark.extra_info[""lib""] = ""simplejson""\n    data = read_fixture_obj(""github.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(simplejson_dumps(data)) == data\n    benchmark(simplejson_dumps, data)\n\n\ndef test_dumps_twitter_orjson(benchmark):\n    benchmark.group = ""twitter.json serialization""\n    benchmark.extra_info[""lib""] = ""orjson""\n    data = read_fixture_obj(""twitter.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(orjson_dumps(data)) == data\n    benchmark(orjson_dumps, data)\n\n\ndef test_dumps_twitter_ujson(benchmark):\n    benchmark.group = ""twitter.json serialization""\n    benchmark.extra_info[""lib""] = ""ujson""\n    data = read_fixture_obj(""twitter.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(ujson_dumps(data)) == data\n    benchmark(ujson_dumps, data)\n\n\ndef test_dumps_twitter_json(benchmark):\n    benchmark.group = ""twitter.json serialization""\n    benchmark.extra_info[""lib""] = ""json""\n    data = read_fixture_obj(""twitter.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(json_dumps(data)) == data\n    benchmark(json_dumps, data)\n\n\ndef test_dumps_twitter_rapidjson(benchmark):\n    benchmark.group = ""twitter.json serialization""\n    benchmark.extra_info[""lib""] = ""rapidjson""\n    data = read_fixture_obj(""twitter.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(rapidjson_dumps(data)) == data\n    benchmark(rapidjson_dumps, data)\n\n\ndef test_dumps_twitter_simplejson(benchmark):\n    benchmark.group = ""twitter.json serialization""\n    benchmark.extra_info[""lib""] = ""simplejson""\n    data = read_fixture_obj(""twitter.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(simplejson_dumps(data)) == data\n    benchmark(simplejson_dumps, data)\n'"
bench/benchmark_loads.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\n\nfrom json import dumps as json_dumps\nfrom json import loads as json_loads\n\nfrom orjson import dumps as orjson_dumps\nfrom orjson import loads as orjson_loads\nfrom rapidjson import dumps as rapidjson_dumps\nfrom rapidjson import loads as rapidjson_loads\nfrom simplejson import dumps as simplejson_dumps\nfrom simplejson import loads as simplejson_loads\nfrom ujson import dumps as ujson_dumps\nfrom ujson import loads as ujson_loads\n\nfrom .util import read_fixture_str\n\n\ndef test_loads_canada_orjson(benchmark):\n    benchmark.group = ""canada.json deserialization""\n    benchmark.extra_info[""lib""] = ""orjson""\n    data = read_fixture_str(""canada.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        orjson_dumps(orjson_loads(data))\n    ) == json_loads(data)\n    benchmark(orjson_loads, data)\n\n\ndef test_loads_canada_ujson(benchmark):\n    benchmark.group = ""canada.json deserialization""\n    benchmark.extra_info[""lib""] = ""ujson""\n    data = read_fixture_str(""canada.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        ujson_dumps(ujson_loads(data))\n    ) == json_loads(data)\n    benchmark(ujson_loads, data)\n\n\ndef test_loads_canada_json(benchmark):\n    benchmark.group = ""canada.json deserialization""\n    benchmark.extra_info[""lib""] = ""json""\n    data = read_fixture_str(""canada.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        json_dumps(json_loads(data))\n    ) == json_loads(data)\n    benchmark(json_loads, data)\n\n\ndef test_loads_canada_rapidjson(benchmark):\n    benchmark.group = ""canada.json deserialization""\n    benchmark.extra_info[""lib""] = ""rapidjson""\n    data = read_fixture_str(""canada.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        rapidjson_dumps(rapidjson_loads(data))\n    ) == json_loads(data)\n    benchmark(rapidjson_loads, data)\n\n\ndef test_loads_canada_simplejson(benchmark):\n    benchmark.group = ""canada.json deserialization""\n    benchmark.extra_info[""lib""] = ""simplejson""\n    data = read_fixture_str(""canada.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        simplejson_dumps(simplejson_loads(data))\n    ) == json_loads(data)\n    benchmark(simplejson_loads, data)\n\n\ndef test_loads_citm_catalog_orjson(benchmark):\n    benchmark.group = ""citm_catalog.json deserialization""\n    benchmark.extra_info[""lib""] = ""orjson""\n    data = read_fixture_str(""citm_catalog.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        orjson_dumps(orjson_loads(data))\n    ) == json_loads(data)\n    benchmark(orjson_loads, data)\n\n\ndef test_loads_citm_catalog_ujson(benchmark):\n    benchmark.group = ""citm_catalog.json deserialization""\n    benchmark.extra_info[""lib""] = ""ujson""\n    data = read_fixture_str(""citm_catalog.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        ujson_dumps(ujson_loads(data))\n    ) == json_loads(data)\n    benchmark(ujson_loads, data)\n\n\ndef test_loads_citm_catalog_json(benchmark):\n    benchmark.group = ""citm_catalog.json deserialization""\n    benchmark.extra_info[""lib""] = ""json""\n    data = read_fixture_str(""citm_catalog.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        json_dumps(json_loads(data))\n    ) == json_loads(data)\n    benchmark(json_loads, data)\n\n\ndef test_loads_citm_catalog_rapidjson(benchmark):\n    benchmark.group = ""citm_catalog.json deserialization""\n    benchmark.extra_info[""lib""] = ""rapidjson""\n    data = read_fixture_str(""citm_catalog.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        rapidjson_dumps(rapidjson_loads(data))\n    ) == json_loads(data)\n    benchmark(rapidjson_loads, data)\n\n\ndef test_loads_citm_catalog_simplejson(benchmark):\n    benchmark.group = ""citm_catalog.json deserialization""\n    benchmark.extra_info[""lib""] = ""simplejson""\n    data = read_fixture_str(""citm_catalog.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        simplejson_dumps(simplejson_loads(data))\n    ) == json_loads(data)\n    benchmark(simplejson_loads, data)\n\n\ndef test_loads_github_orjson(benchmark):\n    benchmark.group = ""github.json deserialization""\n    benchmark.extra_info[""lib""] = ""orjson""\n    data = read_fixture_str(""github.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        orjson_dumps(orjson_loads(data))\n    ) == json_loads(data)\n    benchmark(orjson_loads, data)\n\n\ndef test_loads_github_ujson(benchmark):\n    benchmark.group = ""github.json deserialization""\n    benchmark.extra_info[""lib""] = ""ujson""\n    data = read_fixture_str(""github.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        ujson_dumps(ujson_loads(data))\n    ) == json_loads(data)\n    benchmark(ujson_loads, data)\n\n\ndef test_loads_github_json(benchmark):\n    benchmark.group = ""github.json deserialization""\n    benchmark.extra_info[""lib""] = ""json""\n    data = read_fixture_str(""github.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        json_dumps(json_loads(data))\n    ) == json_loads(data)\n    benchmark(json_loads, data)\n\n\ndef test_loads_github_rapidjson(benchmark):\n    benchmark.group = ""github.json deserialization""\n    benchmark.extra_info[""lib""] = ""rapidjson""\n    data = read_fixture_str(""github.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        rapidjson_dumps(rapidjson_loads(data))\n    ) == json_loads(data)\n    benchmark(rapidjson_loads, data)\n\n\ndef test_loads_github_simplejson(benchmark):\n    benchmark.group = ""github.json deserialization""\n    benchmark.extra_info[""lib""] = ""simplejson""\n    data = read_fixture_str(""github.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        simplejson_dumps(simplejson_loads(data))\n    ) == json_loads(data)\n    benchmark(simplejson_loads, data)\n\n\ndef test_loads_twitter_orjson(benchmark):\n    benchmark.group = ""twitter.json deserialization""\n    benchmark.extra_info[""lib""] = ""orjson""\n    data = read_fixture_str(""twitter.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        orjson_dumps(orjson_loads(data))\n    ) == json_loads(data)\n    benchmark(orjson_loads, data)\n\n\ndef test_loads_twitter_ujson(benchmark):\n    benchmark.group = ""twitter.json deserialization""\n    benchmark.extra_info[""lib""] = ""ujson""\n    data = read_fixture_str(""twitter.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        ujson_dumps(ujson_loads(data))\n    ) == json_loads(data)\n    benchmark(ujson_loads, data)\n\n\ndef test_loads_twitter_json(benchmark):\n    benchmark.group = ""twitter.json deserialization""\n    benchmark.extra_info[""lib""] = ""json""\n    data = read_fixture_str(""twitter.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        json_dumps(json_loads(data))\n    ) == json_loads(data)\n    benchmark(json_loads, data)\n\n\ndef test_loads_twitter_rapidjson(benchmark):\n    benchmark.group = ""twitter.json deserialization""\n    benchmark.extra_info[""lib""] = ""rapidjson""\n    data = read_fixture_str(""twitter.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        rapidjson_dumps(rapidjson_loads(data))\n    ) == json_loads(data)\n    benchmark(rapidjson_loads, data)\n\n\ndef test_loads_twitter_simplejson(benchmark):\n    benchmark.group = ""twitter.json deserialization""\n    benchmark.extra_info[""lib""] = ""simplejson""\n    data = read_fixture_str(""twitter.json.xz"")\n    benchmark.extra_info[""correct""] = json_loads(\n        simplejson_dumps(simplejson_loads(data))\n    ) == json_loads(data)\n    benchmark(simplejson_loads, data)\n'"
bench/util.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport lzma\nimport os\nfrom pathlib import Path\nfrom typing import Any, Dict\n\nimport orjson\n\ndirname = os.path.join(os.path.dirname(__file__), ""../data"")\n\nSTR_CACHE: Dict[str, str] = {}\n\nOBJ_CACHE: Dict[str, Any] = {}\n\n\nos.sched_setaffinity(os.getpid(), {0, 1})\n\n\ndef read_fixture_str(filename):\n    if not filename in STR_CACHE:\n        path = Path(dirname, filename)\n        if path.suffix == "".xz"":\n            contents = lzma.decompress(path.read_bytes())\n        else:\n            contents = path.read_bytes()\n        STR_CACHE[filename] = contents.decode(""utf-8"")\n    return STR_CACHE[filename]\n\n\ndef read_fixture_obj(filename):\n    if not filename in OBJ_CACHE:\n        OBJ_CACHE[filename] = orjson.loads(read_fixture_str(filename))\n    return OBJ_CACHE[filename]\n'"
integration/wsgi.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport os\nimport lzma\n\nfrom flask import Flask\nimport orjson\n\napp = Flask(__name__)\n\nfilename = os.path.join(os.path.dirname(__file__), "".."", ""data"", ""twitter.json.xz"")\n\nwith lzma.open(filename, ""r"") as fileh:\n    DATA = orjson.loads(fileh.read())\n\n\n@app.route(""/"")\ndef root():\n    data = orjson.dumps(DATA)\n    return app.response_class(\n        response=data, status=200, mimetype=""application/json; charset=utf-8""\n    )\n'"
test/__init__.py,0,b''
test/test_api.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport datetime\nimport inspect\nimport json\nimport unittest\n\nimport orjson\n\nSIMPLE_TYPES = (1, 1.0, -1, None, ""str"", True, False)\n\n\ndef default(obj):\n    return str(obj)\n\n\nclass ApiTests(unittest.TestCase):\n    def test_loads_trailing(self):\n        """"""\n        loads() handles trailing whitespace\n        """"""\n        self.assertEqual(orjson.loads(""{}\\n\\t ""), {})\n\n    def test_loads_trailing_invalid(self):\n        """"""\n        loads() handles trailing invalid\n        """"""\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, ""{}\\n\\t a"")\n\n    def test_simple_json(self):\n        """"""\n        dumps() equivalent to json on simple types\n        """"""\n        for obj in SIMPLE_TYPES:\n            self.assertEqual(orjson.dumps(obj), json.dumps(obj).encode(""utf-8""))\n\n    def test_simple_round_trip(self):\n        """"""\n        dumps(), loads() round trip on simple types\n        """"""\n        for obj in SIMPLE_TYPES:\n            self.assertEqual(orjson.loads(orjson.dumps(obj)), obj)\n\n    def test_loads_type(self):\n        """"""\n        loads() invalid type\n        """"""\n        for val in (1, 3.14, [], {}, None):\n            self.assertRaises(orjson.JSONDecodeError, orjson.loads, val)\n\n    def test_loads_recursion(self):\n        """"""\n        loads() recursion limit\n        """"""\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, ""["" * (1024 * 1024))\n\n    def test_version(self):\n        """"""\n        __version__\n        """"""\n        self.assertRegex(orjson.__version__, r""^\\d+\\.\\d+(\\.\\d+)?$"")\n\n    def test_valueerror(self):\n        """"""\n        orjson.JSONDecodeError is a subclass of ValueError\n        """"""\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, ""{"")\n        self.assertRaises(ValueError, orjson.loads, ""{"")\n\n    def test_option_not_int(self):\n        """"""\n        dumps() option not int or None\n        """"""\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(True, option=True)\n\n    def test_option_invalid_int(self):\n        """"""\n        dumps() option invalid 64-bit number\n        """"""\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(True, option=9223372036854775809)\n\n    def test_option_range_low(self):\n        """"""\n        dumps() option out of range low\n        """"""\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(True, option=-1)\n\n    def test_option_range_high(self):\n        """"""\n        dumps() option out of range high\n        """"""\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(True, option=1 << 10)\n\n    def test_opts_multiple(self):\n        """"""\n        dumps() multiple option\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [1, datetime.datetime(2000, 1, 1, 2, 3, 4)],\n                option=orjson.OPT_STRICT_INTEGER | orjson.OPT_NAIVE_UTC,\n            ),\n            b\'[1,""2000-01-01T02:03:04+00:00""]\',\n        )\n\n    def test_default_positional(self):\n        """"""\n        dumps() positional arg\n        """"""\n        with self.assertRaises(TypeError):\n            orjson.dumps(__obj={})\n        with self.assertRaises(TypeError):\n            orjson.dumps(zxc={})\n\n    def test_default_unknown_kwarg(self):\n        """"""\n        dumps() unknown kwarg\n        """"""\n        with self.assertRaises(TypeError):\n            orjson.dumps({}, zxc=default)\n\n    def test_default_twice(self):\n        """"""\n        dumps() default twice\n        """"""\n        with self.assertRaises(TypeError):\n            orjson.dumps({}, default, default=default)\n\n    def test_option_twice(self):\n        """"""\n        dumps() option twice\n        """"""\n        with self.assertRaises(TypeError):\n            orjson.dumps({}, None, orjson.OPT_NAIVE_UTC, option=orjson.OPT_NAIVE_UTC)\n\n    def test_option_mixed(self):\n        """"""\n        dumps() option one arg, one kwarg\n        """"""\n\n        class Custom:\n            def __str__(self):\n                return ""zxc""\n\n        self.assertEqual(\n            orjson.dumps(\n                [Custom(), datetime.datetime(2000, 1, 1, 2, 3, 4)],\n                default,\n                option=orjson.OPT_NAIVE_UTC,\n            ),\n            b\'[""zxc"",""2000-01-01T02:03:04+00:00""]\',\n        )\n\n    def test_dumps_signature(self):\n        """"""\n        dumps() valid __text_signature__\n        """"""\n        self.assertEqual(\n            str(inspect.signature(orjson.dumps)), ""(obj, /, default, option)""\n        )\n\n    def test_loads_signature(self):\n        """"""\n        loads() valid __text_signature__\n        """"""\n        self.assertEqual(str(inspect.signature(orjson.loads)), ""(obj, /)"")\n\n    def test_bytes_buffer(self):\n        """"""\n        dumps() trigger buffer growing where length is greater than growth\n        """"""\n        a = ""a"" * 900\n        b = ""b"" * 4096\n        c = ""c"" * 4096 * 4096\n        self.assertEqual(\n            orjson.dumps([a, b, c]), f\'[""{a}"",""{b}"",""{c}""]\'.encode(""utf-8"")\n        )\n'"
test/test_canonical.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport unittest\n\nimport orjson\n\n\nclass CanonicalTests(unittest.TestCase):\n    def test_dumps_ctrl_escape(self):\n        """"""\n        dumps() ctrl characters\n        """"""\n        self.assertEqual(orjson.dumps(""text\\u0003\\r\\n""), b\'""text\\\\u0003\\\\r\\\\n""\')\n\n    def test_dumps_escape_quote_backslash(self):\n        """"""\n        dumps() quote, backslash escape\n        """"""\n        self.assertEqual(orjson.dumps(r\'""\\ test\'), b\'""\\\\""\\\\\\\\ test""\')\n\n    def test_dumps_escape_line_separator(self):\n        """"""\n        dumps() U+2028, U+2029 escape\n        """"""\n        self.assertEqual(\n            orjson.dumps({""spaces"": ""\\u2028 \\u2029""}),\n            b\'{""spaces"":""\\xe2\\x80\\xa8 \\xe2\\x80\\xa9""}\',\n        )\n'"
test/test_circular.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport unittest\n\nimport orjson\n\n\nclass CircularTests(unittest.TestCase):\n    def test_circular_dict(self):\n        """"""\n        dumps() circular reference dict\n        """"""\n        obj = {}\n        obj[""obj""] = obj\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(obj)\n\n    def test_circular_list(self):\n        """"""\n        dumps() circular reference list\n        """"""\n        obj = []\n        obj.append(obj)\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(obj)\n\n    def test_circular_nested(self):\n        """"""\n        dumps() circular reference nested dict, list\n        """"""\n        obj = {}\n        obj[""list""] = [{""obj"": obj}]\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(obj)\n'"
test/test_dataclass.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport unittest\nimport uuid\nfrom dataclasses import InitVar, dataclass, field\nfrom enum import Enum\nfrom typing import ClassVar, Dict, Optional\n\nimport orjson\n\n\nclass AnEnum(Enum):\n    ONE = 1\n    TWO = 2\n\n\n@dataclass\nclass Dataclass1:\n    name: str\n    number: int\n    sub: Optional[""Dataclass1""]\n\n\n@dataclass\nclass Dataclass2:\n    name: Optional[str] = field(default=""?"")\n\n\n@dataclass\nclass Dataclass3:\n    a: str\n    b: int\n    c: dict\n    d: bool\n    e: float\n    f: list\n    g: tuple\n\n\n@dataclass\nclass Dataclass4:\n    a: str = field()\n    b: int = field(metadata={""unrelated"": False})\n    c: float = 1.1\n\n\n@dataclass\nclass Datasubclass(Dataclass1):\n    additional: bool\n\n\n@dataclass\nclass Slotsdataclass:\n    __slots__ = (""a"", ""b"", ""_c"", ""d"")\n    a: str\n    b: int\n    _c: str\n    d: InitVar[str]\n    cls_var: ClassVar[str] = ""cls""\n\n\n@dataclass\nclass Defaultdataclass:\n    a: uuid.UUID\n    b: AnEnum\n\n\n@dataclass\nclass UnsortedDataclass:\n    c: int\n    b: int\n    a: int\n    d: Optional[Dict]\n\n\n@dataclass\nclass InitDataclass:\n    a: InitVar[str]\n    b: InitVar[str]\n    cls_var: ClassVar[str] = ""cls""\n    ab: str = """"\n\n    def __post_init__(self, a: str, b: str):\n        self._other = 1\n        self.ab = f""{a} {b}""\n\n\nclass DataclassTests(unittest.TestCase):\n    def test_dataclass(self):\n        """"""\n        dumps() dataclass\n        """"""\n        obj = Dataclass1(""a"", 1, None)\n        self.assertEqual(\n            orjson.dumps(obj), b\'{""name"":""a"",""number"":1,""sub"":null}\',\n        )\n\n    def test_dataclass_recursive(self):\n        """"""\n        dumps() dataclass recursive\n        """"""\n        obj = Dataclass1(""a"", 1, Dataclass1(""b"", 2, None))\n        self.assertEqual(\n            orjson.dumps(obj),\n            b\'{""name"":""a"",""number"":1,""sub"":{""name"":""b"",""number"":2,""sub"":null}}\',\n        )\n\n    def test_dataclass_circular(self):\n        """"""\n        dumps() dataclass circular\n        """"""\n        obj1 = Dataclass1(""a"", 1, None)\n        obj2 = Dataclass1(""b"", 2, obj1)\n        obj1.sub = obj2\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(obj1)\n\n    def test_dataclass_default_arg(self):\n        """"""\n        dumps() dataclass default arg\n        """"""\n        obj = Dataclass2()\n        self.assertEqual(orjson.dumps(obj), b\'{""name"":""?""}\')\n\n    def test_dataclass_types(self):\n        """"""\n        dumps() dataclass types\n        """"""\n        obj = Dataclass3(""a"", 1, {""a"": ""b""}, True, 1.1, [1, 2], (3, 4))\n        self.assertEqual(\n            orjson.dumps(obj),\n            b\'{""a"":""a"",""b"":1,""c"":{""a"":""b""},""d"":true,""e"":1.1,""f"":[1,2],""g"":[3,4]}\',\n        )\n\n    def test_dataclass_metadata(self):\n        """"""\n        dumps() dataclass metadata\n        """"""\n        obj = Dataclass4(""a"", 1, 2.1)\n        self.assertEqual(\n            orjson.dumps(obj), b\'{""a"":""a"",""b"":1,""c"":2.1}\',\n        )\n\n    def test_dataclass_classvar(self):\n        """"""\n        dumps() dataclass class variable\n        """"""\n        obj = Dataclass4(""a"", 1)\n        self.assertEqual(\n            orjson.dumps(obj), b\'{""a"":""a"",""b"":1,""c"":1.1}\',\n        )\n\n    def test_dataclass_subclass(self):\n        """"""\n        dumps() dataclass subclass\n        """"""\n        obj = Datasubclass(""a"", 1, None, False)\n        self.assertEqual(\n            orjson.dumps(obj), b\'{""name"":""a"",""number"":1,""sub"":null,""additional"":false}\',\n        )\n\n    def test_dataclass_slots(self):\n        """"""\n        dumps() dataclass with __slots__ does not include under attributes, InitVar, or ClassVar\n        """"""\n        obj = Slotsdataclass(""a"", 1, ""c"", ""d"")\n        assert ""__dict__"" not in dir(obj)\n        self.assertEqual(orjson.dumps(obj), b\'{""a"":""a"",""b"":1}\')\n\n    def test_dataclass_default(self):\n        """"""\n        dumps() dataclass with default\n        """"""\n\n        def default(__obj):\n            if isinstance(__obj, uuid.UUID):\n                return str(__obj)\n            elif isinstance(__obj, Enum):\n                return __obj.value\n\n        obj = Defaultdataclass(\n            uuid.UUID(""808989c0-00d5-48a8-b5c4-c804bf9032f2""), AnEnum.ONE\n        )\n        self.assertEqual(\n            orjson.dumps(obj, default=default),\n            b\'{""a"":""808989c0-00d5-48a8-b5c4-c804bf9032f2"",""b"":1}\',\n        )\n\n    def test_dataclass_sort(self):\n        """"""\n        OPT_SORT_KEYS has no effect on dataclasses\n        """"""\n        obj = UnsortedDataclass(1, 2, 3, None)\n        self.assertEqual(\n            orjson.dumps(obj, option=orjson.OPT_SORT_KEYS),\n            b\'{""c"":1,""b"":2,""a"":3,""d"":null}\',\n        )\n\n    def test_dataclass_sort_sub(self):\n        """"""\n        dataclass fast path does not prevent OPT_SORT_KEYS from cascading\n        """"""\n        obj = UnsortedDataclass(1, 2, 3, {""f"": 2, ""e"": 1})\n        self.assertEqual(\n            orjson.dumps(obj, option=orjson.OPT_SORT_KEYS),\n            b\'{""c"":1,""b"":2,""a"":3,""d"":{""e"":1,""f"":2}}\',\n        )\n\n    def test_dataclass_under(self):\n        """"""\n        dumps() does not include under attributes, InitVar, or ClassVar\n        """"""\n        obj = InitDataclass(""zxc"", ""vbn"")\n        self.assertEqual(\n            orjson.dumps(obj), b\'{""ab"":""zxc vbn""}\',\n        )\n\n    def test_dataclass_option(self):\n        """"""\n        dumps() accepts deprecated OPT_SERIALIZE_DATACLASS\n        """"""\n        obj = Dataclass1(""a"", 1, None)\n        self.assertEqual(\n            orjson.dumps(obj, option=orjson.OPT_SERIALIZE_DATACLASS),\n            b\'{""name"":""a"",""number"":1,""sub"":null}\',\n        )\n'"
test/test_datetime.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport datetime\nimport unittest\n\nimport orjson\nimport pytest\nimport pytz\nfrom dateutil import tz\n\ntry:\n    import pendulum\nexcept ImportError:\n    pendulum = None  # type: ignore\n\n\nclass DatetimeTests(unittest.TestCase):\n    def test_datetime_naive(self):\n        """"""\n        datetime.datetime naive prints without offset\n        """"""\n        self.assertEqual(\n            orjson.dumps([datetime.datetime(2000, 1, 1, 2, 3, 4, 123)]),\n            b\'[""2000-01-01T02:03:04.000123""]\',\n        )\n\n    def test_datetime_naive_utc(self):\n        """"""\n        datetime.datetime naive with opt assumes UTC\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [datetime.datetime(2000, 1, 1, 2, 3, 4, 123)],\n                option=orjson.OPT_NAIVE_UTC,\n            ),\n            b\'[""2000-01-01T02:03:04.000123+00:00""]\',\n        )\n\n    def test_datetime_min(self):\n        """"""\n        datetime.datetime min range\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [datetime.datetime(datetime.MINYEAR, 1, 1, 0, 0, 0, 0)],\n                option=orjson.OPT_NAIVE_UTC,\n            ),\n            b\'[""1-01-01T00:00:00+00:00""]\',\n        )\n\n    def test_datetime_max(self):\n        """"""\n        datetime.datetime max range\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [datetime.datetime(datetime.MAXYEAR, 12, 31, 23, 59, 50, 999999)],\n                option=orjson.OPT_NAIVE_UTC,\n            ),\n            b\'[""9999-12-31T23:59:50.999999+00:00""]\',\n        )\n\n    def test_datetime_tz_assume(self):\n        """"""\n        datetime.datetime tz with assume UTC uses tz\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        2018, 1, 1, 2, 3, 4, 0, tzinfo=tz.gettz(""Asia/Shanghai"")\n                    )\n                ],\n                option=orjson.OPT_NAIVE_UTC,\n            ),\n            b\'[""2018-01-01T02:03:04+08:00""]\',\n        )\n\n    def test_datetime_timezone_utc(self):\n        """"""\n        datetime.datetime UTC\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        2018, 6, 1, 2, 3, 4, 0, tzinfo=datetime.timezone.utc\n                    )\n                ]\n            ),\n            b\'[""2018-06-01T02:03:04+00:00""]\',\n        )\n\n    def test_datetime_pytz_utc(self):\n        """"""\n        datetime.datetime UTC\n        """"""\n        self.assertEqual(\n            orjson.dumps([datetime.datetime(2018, 6, 1, 2, 3, 4, 0, tzinfo=pytz.UTC)]),\n            b\'[""2018-06-01T02:03:04+00:00""]\',\n        )\n\n    @pytest.mark.skipif(pendulum is None, reason=""pendulum install broken on win"")\n    def test_datetime_pendulum_utc(self):\n        """"""\n        datetime.datetime UTC\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [datetime.datetime(2018, 6, 1, 2, 3, 4, 0, tzinfo=pendulum.UTC)]\n            ),\n            b\'[""2018-06-01T02:03:04+00:00""]\',\n        )\n\n    def test_datetime_arrow_positive(self):\n        """"""\n        datetime.datetime positive UTC\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        2018, 1, 1, 2, 3, 4, 0, tzinfo=tz.gettz(""Asia/Shanghai"")\n                    )\n                ]\n            ),\n            b\'[""2018-01-01T02:03:04+08:00""]\',\n        )\n\n    def test_datetime_pytz_positive(self):\n        """"""\n        datetime.datetime positive UTC\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        2018, 1, 1, 2, 3, 4, 0, tzinfo=pytz.timezone(""Asia/Shanghai"")\n                    )\n                ]\n            ),\n            b\'[""2018-01-01T02:03:04+08:00""]\',\n        )\n\n    @pytest.mark.skipif(pendulum is None, reason=""pendulum install broken on win"")\n    def test_datetime_pendulum_positive(self):\n        """"""\n        datetime.datetime positive UTC\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        2018,\n                        1,\n                        1,\n                        2,\n                        3,\n                        4,\n                        0,\n                        tzinfo=pendulum.timezone(""Asia/Shanghai""),\n                    )\n                ]\n            ),\n            b\'[""2018-01-01T02:03:04+08:00""]\',\n        )\n\n    def test_datetime_pytz_negative_dst(self):\n        """"""\n        datetime.datetime negative UTC DST\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        2018, 6, 1, 2, 3, 4, 0, tzinfo=pytz.timezone(""America/New_York"")\n                    )\n                ]\n            ),\n            b\'[""2018-06-01T02:03:04-04:00""]\',\n        )\n\n    @pytest.mark.skipif(pendulum is None, reason=""pendulum install broken on win"")\n    def test_datetime_pendulum_negative_dst(self):\n        """"""\n        datetime.datetime negative UTC DST\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        2018,\n                        6,\n                        1,\n                        2,\n                        3,\n                        4,\n                        0,\n                        tzinfo=pendulum.timezone(""America/New_York""),\n                    )\n                ]\n            ),\n            b\'[""2018-06-01T02:03:04-04:00""]\',\n        )\n\n    def test_datetime_pytz_negative_non_dst(self):\n        """"""\n        datetime.datetime negative UTC non-DST\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        2018,\n                        12,\n                        1,\n                        2,\n                        3,\n                        4,\n                        0,\n                        tzinfo=pytz.timezone(""America/New_York""),\n                    )\n                ]\n            ),\n            b\'[""2018-12-01T02:03:04-05:00""]\',\n        )\n\n    @pytest.mark.skipif(pendulum is None, reason=""pendulum install broken on win"")\n    def test_datetime_pendulum_negative_non_dst(self):\n        """"""\n        datetime.datetime negative UTC non-DST\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        2018,\n                        12,\n                        1,\n                        2,\n                        3,\n                        4,\n                        0,\n                        tzinfo=pendulum.timezone(""America/New_York""),\n                    )\n                ]\n            ),\n            b\'[""2018-12-01T02:03:04-05:00""]\',\n        )\n\n    def test_datetime_partial_hour(self):\n        """"""\n        datetime.datetime UTC offset partial hour\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        2018,\n                        12,\n                        1,\n                        2,\n                        3,\n                        4,\n                        0,\n                        tzinfo=pytz.timezone(""Australia/Adelaide""),\n                    )\n                ]\n            ),\n            b\'[""2018-12-01T02:03:04+10:30""]\',\n        )\n\n    def test_datetime_pytz_partial_hour(self):\n        """"""\n        datetime.datetime UTC offset partial hour\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        2018,\n                        12,\n                        1,\n                        2,\n                        3,\n                        4,\n                        0,\n                        tzinfo=pytz.timezone(""Australia/Adelaide""),\n                    )\n                ]\n            ),\n            b\'[""2018-12-01T02:03:04+10:30""]\',\n        )\n\n    @pytest.mark.skipif(pendulum is None, reason=""pendulum install broken on win"")\n    def test_datetime_pendulum_partial_hour(self):\n        """"""\n        datetime.datetime UTC offset partial hour\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        2018,\n                        12,\n                        1,\n                        2,\n                        3,\n                        4,\n                        0,\n                        tzinfo=pendulum.timezone(""Australia/Adelaide""),\n                    )\n                ]\n            ),\n            b\'[""2018-12-01T02:03:04+10:30""]\',\n        )\n\n    @pytest.mark.skipif(pendulum is None, reason=""pendulum install broken on win"")\n    def test_datetime_partial_second_pendulum_supported(self):\n        """"""\n        datetime.datetime UTC offset round seconds\n\n        https://tools.ietf.org/html/rfc3339#section-5.8\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        1937,\n                        1,\n                        1,\n                        12,\n                        0,\n                        27,\n                        87,\n                        tzinfo=pendulum.timezone(""Europe/Amsterdam""),\n                    )\n                ]\n            ),\n            b\'[""1937-01-01T12:00:27.000087+00:20""]\',\n        )\n\n    def test_datetime_partial_second_pytz(self):\n        """"""\n        datetime.datetime UTC offset round seconds\n\n        https://tools.ietf.org/html/rfc3339#section-5.8\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        1937,\n                        1,\n                        1,\n                        12,\n                        0,\n                        27,\n                        87,\n                        tzinfo=pytz.timezone(""Europe/Amsterdam""),\n                    )\n                ]\n            ),\n            b\'[""1937-01-01T12:00:27.000087+00:20""]\',\n        )\n\n    def test_datetime_partial_second_dateutil(self):\n        """"""\n        datetime.datetime UTC offset round seconds\n\n        https://tools.ietf.org/html/rfc3339#section-5.8\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        1937, 1, 1, 12, 0, 27, 87, tzinfo=tz.gettz(""Europe/Amsterdam"")\n                    )\n                ]\n            ),\n            b\'[""1937-01-01T12:00:27.000087+00:20""]\',\n        )\n\n    def test_datetime_microsecond_max(self):\n        """"""\n        datetime.datetime microsecond max\n        """"""\n        self.assertEqual(\n            orjson.dumps(datetime.datetime(2000, 1, 1, 0, 0, 0, 999999)),\n            b\'""2000-01-01T00:00:00.999999""\',\n        )\n\n    def test_datetime_microsecond_min(self):\n        """"""\n        datetime.datetime microsecond min\n        """"""\n        self.assertEqual(\n            orjson.dumps(datetime.datetime(2000, 1, 1, 0, 0, 0, 1)),\n            b\'""2000-01-01T00:00:00.000001""\',\n        )\n\n    def test_datetime_omit_microseconds(self):\n        """"""\n        datetime.datetime OPT_OMIT_MICROSECONDS\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [datetime.datetime(2000, 1, 1, 2, 3, 4, 123)],\n                option=orjson.OPT_OMIT_MICROSECONDS,\n            ),\n            b\'[""2000-01-01T02:03:04""]\',\n        )\n\n    def test_datetime_omit_microseconds_naive(self):\n        """"""\n        datetime.datetime naive OPT_OMIT_MICROSECONDS\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [datetime.datetime(2000, 1, 1, 2, 3, 4, 123)],\n                option=orjson.OPT_NAIVE_UTC | orjson.OPT_OMIT_MICROSECONDS,\n            ),\n            b\'[""2000-01-01T02:03:04+00:00""]\',\n        )\n\n    def test_time_omit_microseconds(self):\n        """"""\n        datetime.time OPT_OMIT_MICROSECONDS\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [datetime.time(2, 3, 4, 123)], option=orjson.OPT_OMIT_MICROSECONDS\n            ),\n            b\'[""02:03:04""]\',\n        )\n\n    def test_datetime_utc_z_naive_omit(self):\n        """"""\n        datetime.datetime naive OPT_UTC_Z\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [datetime.datetime(2000, 1, 1, 2, 3, 4, 123)],\n                option=orjson.OPT_NAIVE_UTC\n                | orjson.OPT_UTC_Z\n                | orjson.OPT_OMIT_MICROSECONDS,\n            ),\n            b\'[""2000-01-01T02:03:04Z""]\',\n        )\n\n    def test_datetime_utc_z_naive(self):\n        """"""\n        datetime.datetime naive OPT_UTC_Z\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [datetime.datetime(2000, 1, 1, 2, 3, 4, 123)],\n                option=orjson.OPT_NAIVE_UTC | orjson.OPT_UTC_Z,\n            ),\n            b\'[""2000-01-01T02:03:04.000123Z""]\',\n        )\n\n    def test_datetime_utc_z_without_tz(self):\n        """"""\n        datetime.datetime naive OPT_UTC_Z\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [datetime.datetime(2000, 1, 1, 2, 3, 4, 123)], option=orjson.OPT_UTC_Z\n            ),\n            b\'[""2000-01-01T02:03:04.000123""]\',\n        )\n\n    def test_datetime_utc_z_with_tz(self):\n        """"""\n        datetime.datetime naive OPT_UTC_Z\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        2000, 1, 1, 0, 0, 0, 1, tzinfo=datetime.timezone.utc\n                    )\n                ],\n                option=orjson.OPT_UTC_Z,\n            ),\n            b\'[""2000-01-01T00:00:00.000001Z""]\',\n        )\n        self.assertEqual(\n            orjson.dumps(\n                [\n                    datetime.datetime(\n                        1937, 1, 1, 12, 0, 27, 87, tzinfo=tz.gettz(""Europe/Amsterdam"")\n                    )\n                ],\n                option=orjson.OPT_UTC_Z,\n            ),\n            b\'[""1937-01-01T12:00:27.000087+00:20""]\',\n        )\n\n    @pytest.mark.skipif(pendulum is None, reason=""pendulum install broken on win"")\n    def test_datetime_roundtrip(self):\n        """"""\n        datetime.datetime parsed by pendulum\n        """"""\n        obj = datetime.datetime(2000, 1, 1, 0, 0, 0, 1, tzinfo=datetime.timezone.utc)\n        serialized = orjson.dumps(obj).decode(""utf-8"").replace(\'""\', """")\n        parsed = pendulum.parse(serialized)\n        for attr in (""year"", ""month"", ""day"", ""hour"", ""minute"", ""second"", ""microsecond""):\n            self.assertEqual(getattr(obj, attr), getattr(parsed, attr))\n\n\nclass DateTests(unittest.TestCase):\n    def test_date(self):\n        """"""\n        datetime.date\n        """"""\n        self.assertEqual(orjson.dumps([datetime.date(2000, 1, 13)]), b\'[""2000-01-13""]\')\n\n    def test_date_min(self):\n        """"""\n        datetime.date MINYEAR\n        """"""\n        self.assertEqual(\n            orjson.dumps([datetime.date(datetime.MINYEAR, 1, 1)]), b\'[""1-01-01""]\'\n        )\n\n    def test_date_max(self):\n        """"""\n        datetime.date MAXYEAR\n        """"""\n        self.assertEqual(\n            orjson.dumps([datetime.date(datetime.MAXYEAR, 12, 31)]), b\'[""9999-12-31""]\'\n        )\n\n\nclass TimeTests(unittest.TestCase):\n    def test_time(self):\n        """"""\n        datetime.time\n        """"""\n        self.assertEqual(\n            orjson.dumps([datetime.time(12, 15, 59, 111)]), b\'[""12:15:59.000111""]\'\n        )\n        self.assertEqual(orjson.dumps([datetime.time(12, 15, 59)]), b\'[""12:15:59""]\')\n\n    def test_time_tz(self):\n        """"""\n        datetime.time with tzinfo error\n        """"""\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(\n                [datetime.time(12, 15, 59, 111, tzinfo=tz.gettz(""Asia/Shanghai""))]\n            )\n\n    def test_time_microsecond_max(self):\n        """"""\n        datetime.time microsecond max\n        """"""\n        self.assertEqual(\n            orjson.dumps(datetime.time(0, 0, 0, 999999)), b\'""00:00:00.999999""\'\n        )\n\n    def test_time_microsecond_min(self):\n        """"""\n        datetime.time microsecond min\n        """"""\n        self.assertEqual(orjson.dumps(datetime.time(0, 0, 0, 1)), b\'""00:00:00.000001""\')\n\n\nclass DateclassPassthroughTests(unittest.TestCase):\n    def test_passthrough_datetime(self):\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(\n                datetime.datetime(1970, 1, 1), option=orjson.OPT_PASSTHROUGH_DATETIME\n            )\n\n    def test_passthrough_date(self):\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(\n                datetime.date(1970, 1, 1), option=orjson.OPT_PASSTHROUGH_DATETIME\n            )\n\n    def test_passthrough_time(self):\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(\n                datetime.time(12, 0, 0), option=orjson.OPT_PASSTHROUGH_DATETIME\n            )\n\n    def test_passthrough_datetime_default(self):\n        def default(obj):\n            return obj.strftime(""%a, %d %b %Y %H:%M:%S GMT"")\n\n        self.assertEqual(\n            orjson.dumps(\n                datetime.datetime(1970, 1, 1),\n                option=orjson.OPT_PASSTHROUGH_DATETIME,\n                default=default,\n            ),\n            b\'""Thu, 01 Jan 1970 00:00:00 GMT""\',\n        )\n'"
test/test_default.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport unittest\nimport uuid\n\nimport orjson\n\n\nclass Custom:\n    def __init__(self):\n        self.name = uuid.uuid4().hex\n\n    def __str__(self):\n        return f""{self.__class__.__name__}({self.name})""\n\n\nclass Recursive:\n    def __init__(self, cur):\n        self.cur = cur\n\n\ndef default(obj):\n    if obj.cur != 0:\n        obj.cur -= 1\n        return obj\n    return obj.cur\n\n\nclass TypeTests(unittest.TestCase):\n    def test_default_not_callable(self):\n        """"""\n        dumps() default not callable\n        """"""\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(Custom(), default=NotImplementedError)\n\n        ran = False\n        try:\n            orjson.dumps(Custom(), default=NotImplementedError)\n        except Exception as err:\n            self.assertIsInstance(err, orjson.JSONEncodeError)\n            self.assertEqual(str(err), ""default serializer exceeds recursion limit"")\n            ran = True\n        self.assertTrue(ran)\n\n    def test_default_func(self):\n        """"""\n        dumps() default function\n        """"""\n        ref = Custom()\n\n        def default(obj):\n            return str(obj)\n\n        self.assertEqual(\n            orjson.dumps(ref, default=default), b\'""%s""\' % str(ref).encode(""utf-8"")\n        )\n\n    def test_default_func_none(self):\n        """"""\n        dumps() default function None ok\n        """"""\n        self.assertEqual(orjson.dumps(Custom(), default=lambda x: None), b""null"")\n\n    def test_default_func_empty(self):\n        """"""\n        dumps() default function no explicit return\n        """"""\n        ref = Custom()\n\n        def default(obj):\n            if isinstance(obj, set):\n                return list(obj)\n\n        self.assertEqual(orjson.dumps(ref, default=default), b""null"")\n        self.assertEqual(orjson.dumps({ref}, default=default), b""[null]"")\n\n    def test_default_func_exc(self):\n        """"""\n        dumps() default function raises exception\n        """"""\n\n        def default(obj):\n            raise NotImplementedError\n\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(Custom(), default=default)\n\n        ran = False\n        try:\n            orjson.dumps(Custom(), default=default)\n        except Exception as err:\n            self.assertIsInstance(err, orjson.JSONEncodeError)\n            self.assertEqual(str(err), ""Type is not JSON serializable: Custom"")\n            ran = True\n        self.assertTrue(ran)\n\n    def test_default_func_nested_str(self):\n        """"""\n        dumps() default function nested str\n        """"""\n        ref = Custom()\n\n        def default(obj):\n            return str(obj)\n\n        self.assertEqual(\n            orjson.dumps({""a"": ref}, default=default),\n            b\'{""a"":""%s""}\' % str(ref).encode(""utf-8""),\n        )\n\n    def test_default_func_list(self):\n        """"""\n        dumps() default function nested list\n        """"""\n        ref = Custom()\n\n        def default(obj):\n            if isinstance(obj, Custom):\n                return [str(obj)]\n\n        self.assertEqual(\n            orjson.dumps({""a"": ref}, default=default),\n            b\'{""a"":[""%s""]}\' % str(ref).encode(""utf-8""),\n        )\n\n    def test_default_func_nested_list(self):\n        """"""\n        dumps() default function list\n        """"""\n        ref = Custom()\n\n        def default(obj):\n            return str(obj)\n\n        self.assertEqual(\n            orjson.dumps([ref] * 100, default=default),\n            b""[%s]"" % b"","".join(b\'""%s""\' % str(ref).encode(""utf-8"") for _ in range(100)),\n        )\n\n    def test_default_func_bytes(self):\n        """"""\n        dumps() default function errors on non-str\n        """"""\n        ref = Custom()\n\n        def default(obj):\n            return bytes(obj)\n\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(ref, default=default)\n\n        ran = False\n        try:\n            orjson.dumps(ref, default=default)\n        except Exception as err:\n            self.assertIsInstance(err, orjson.JSONEncodeError)\n            self.assertEqual(str(err), ""Type is not JSON serializable: Custom"")\n            ran = True\n        self.assertTrue(ran)\n\n    def test_default_func_invalid_str(self):\n        """"""\n        dumps() default function errors on invalid str\n        """"""\n        ref = Custom()\n\n        def default(obj):\n            return ""\\ud800""\n\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(ref, default=default)\n\n    def test_default_lambda_ok(self):\n        """"""\n        dumps() default lambda\n        """"""\n        ref = Custom()\n        self.assertEqual(\n            orjson.dumps(ref, default=lambda x: str(x)),\n            b\'""%s""\' % str(ref).encode(""utf-8""),\n        )\n\n    def test_default_callable_ok(self):\n        """"""\n        dumps() default callable\n        """"""\n\n        class CustomSerializer:\n            def __init__(self):\n                self._cache = {}\n\n            def __call__(self, obj):\n                if obj not in self._cache:\n                    self._cache[obj] = str(obj)\n                return self._cache[obj]\n\n        ref_obj = Custom()\n        ref_bytes = b\'""%s""\' % str(ref_obj).encode(""utf-8"")\n        for obj in [ref_obj] * 100:\n            self.assertEqual(orjson.dumps(obj, default=CustomSerializer()), ref_bytes)\n\n    def test_default_recursion(self):\n        """"""\n        dumps() default recursion limit\n        """"""\n        self.assertEqual(orjson.dumps(Recursive(254), default=default), b""0"")\n\n    def test_default_recursion_reset(self):\n        """"""\n        dumps() default recursion limit reset\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                [Recursive(254), {""a"": ""b""}, Recursive(254), Recursive(254)],\n                default=default,\n            ),\n            b\'[0,{""a"":""b""},0,0]\',\n        )\n\n    def test_default_recursion_infinite(self):\n        """"""\n        dumps() default infinite recursion\n        """"""\n        ref = Custom()\n\n        def default(obj):\n            return obj\n\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(ref, default=default)\n'"
test/test_enum.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport datetime\nimport enum\nimport unittest\n\nimport orjson\n\n\nclass StrEnum(str, enum.Enum):\n    AAA = ""aaa""\n\n\nclass IntEnum(int, enum.Enum):\n    ONE = 1\n\n\nclass IntEnumEnum(enum.IntEnum):\n    ONE = 1\n\n\nclass IntFlagEnum(enum.IntFlag):\n    ONE = 1\n\n\nclass FlagEnum(enum.Flag):\n    ONE = 1\n\n\nclass AutoEnum(enum.auto):\n    A = ""a""\n\n\nclass FloatEnum(float, enum.Enum):\n    ONE = 1.1\n\n\nclass Custom:\n    def __init__(self, val):\n        self.val = val\n\n\ndef default(obj):\n    if isinstance(obj, Custom):\n        return obj.val\n    raise TypeError\n\n\nclass UnspecifiedEnum(enum.Enum):\n    A = ""a""\n    B = 1\n    C = FloatEnum.ONE\n    D = {""d"": IntEnum.ONE}\n    E = Custom(""c"")\n    F = datetime.datetime(1970, 1, 1)\n\n\nclass EnumTests(unittest.TestCase):\n    def test_cannot_subclass(self):\n        """"""\n        enum.Enum cannot be subclassed\n\n        obj->ob_type->ob_base will always be enum.EnumMeta\n        """"""\n        with self.assertRaises(TypeError):\n\n            class Subclass(StrEnum):\n                B = ""b""\n\n    def test_arbitrary_enum(self):\n        self.assertEqual(orjson.dumps(UnspecifiedEnum.A), b\'""a""\')\n        self.assertEqual(orjson.dumps(UnspecifiedEnum.B), b""1"")\n        self.assertEqual(orjson.dumps(UnspecifiedEnum.C), b""1.1"")\n        self.assertEqual(orjson.dumps(UnspecifiedEnum.D), b\'{""d"":1}\')\n\n    def test_custom_enum(self):\n        self.assertEqual(orjson.dumps(UnspecifiedEnum.E, default=default), b\'""c""\')\n\n    def test_enum_options(self):\n        self.assertEqual(\n            orjson.dumps(UnspecifiedEnum.F, option=orjson.OPT_NAIVE_UTC),\n            b\'""1970-01-01T00:00:00+00:00""\',\n        )\n\n    def test_int_enum(self):\n        self.assertEqual(orjson.dumps(IntEnum.ONE), b""1"")\n\n    def test_intenum_enum(self):\n        self.assertEqual(orjson.dumps(IntEnumEnum.ONE), b""1"")\n\n    def test_intflag_enum(self):\n        self.assertEqual(orjson.dumps(IntFlagEnum.ONE), b""1"")\n\n    def test_flag_enum(self):\n        self.assertEqual(orjson.dumps(FlagEnum.ONE), b""1"")\n\n    def test_auto_enum(self):\n        self.assertEqual(orjson.dumps(AutoEnum.A), b\'""a""\')\n\n    def test_float_enum(self):\n        self.assertEqual(orjson.dumps(FloatEnum.ONE), b""1.1"")\n\n    def test_str_enum(self):\n        self.assertEqual(orjson.dumps(StrEnum.AAA), b\'""aaa""\')\n\n    def test_bool_enum(self):\n        with self.assertRaises(TypeError):\n\n            class BoolEnum(bool, enum.Enum):\n                TRUE = True\n\n    def test_non_str_keys_enum(self):\n        self.assertEqual(\n            orjson.dumps({StrEnum.AAA: 1}, option=orjson.OPT_NON_STR_KEYS), b\'{""aaa"":1}\'\n        )\n        self.assertEqual(\n            orjson.dumps({IntEnum.ONE: 1}, option=orjson.OPT_NON_STR_KEYS), b\'{""1"":1}\'\n        )\n'"
test/test_fixture.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport unittest\n\nimport orjson\n\nfrom .util import read_fixture_bytes, read_fixture_str\n\n\nclass FixtureTests(unittest.TestCase):\n    def test_twitter(self):\n        """"""\n        loads(),dumps() twitter.json\n        """"""\n        val = read_fixture_str(""twitter.json.xz"")\n        read = orjson.loads(val)\n        orjson.dumps(read)\n\n    def test_canada(self):\n        """"""\n        loads(), dumps() canada.json\n        """"""\n        val = read_fixture_str(""canada.json.xz"")\n        read = orjson.loads(val)\n        orjson.dumps(read)\n\n    def test_citm_catalog(self):\n        """"""\n        loads(), dumps() citm_catalog.json\n        """"""\n        val = read_fixture_str(""citm_catalog.json.xz"")\n        read = orjson.loads(val)\n        orjson.dumps(read)\n\n    def test_github(self):\n        """"""\n        loads(), dumps() github.json\n        """"""\n        val = read_fixture_str(""github.json.xz"")\n        read = orjson.loads(val)\n        orjson.dumps(read)\n\n    def test_blns(self):\n        """"""\n        loads() blns.json JSONDecodeError\n\n        https://github.com/minimaxir/big-list-of-naughty-strings\n        """"""\n        val = read_fixture_bytes(""blns.txt.xz"")\n        for line in val.split(b""\\n""):\n            if line and not line.startswith(b""#""):\n                with self.assertRaises(orjson.JSONDecodeError):\n                    _ = orjson.loads(b\'""\' + val + b\'""\')\n'"
test/test_indent.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport datetime\nimport json\nimport unittest\n\nimport orjson\n\nfrom .util import read_fixture_obj\n\n\nclass IndentedOutputTests(unittest.TestCase):\n    def test_equivalent(self):\n        """"""\n        OPT_INDENT_2 is equivalent to indent=2\n        """"""\n        obj = {""a"": ""b"", ""c"": {""d"": True}, ""e"": [1, 2]}\n        self.assertEqual(\n            orjson.dumps(obj, option=orjson.OPT_INDENT_2),\n            json.dumps(obj, indent=2).encode(""utf-8""),\n        )\n\n    def test_sort(self):\n        obj = {""b"": 1, ""a"": 2}\n        self.assertEqual(\n            orjson.dumps(obj, option=orjson.OPT_INDENT_2 | orjson.OPT_SORT_KEYS),\n            b\'{\\n  ""a"": 2,\\n  ""b"": 1\\n}\',\n        )\n\n    def test_non_str(self):\n        obj = {1: 1, ""a"": 2}\n        self.assertEqual(\n            orjson.dumps(obj, option=orjson.OPT_INDENT_2 | orjson.OPT_NON_STR_KEYS),\n            b\'{\\n  ""1"": 1,\\n  ""a"": 2\\n}\',\n        )\n\n    def test_options(self):\n        obj = {\n            1: 1,\n            ""b"": True,\n            ""a"": datetime.datetime(1970, 1, 1),\n        }\n        self.assertEqual(\n            orjson.dumps(\n                obj,\n                option=orjson.OPT_INDENT_2\n                | orjson.OPT_SORT_KEYS\n                | orjson.OPT_NON_STR_KEYS\n                | orjson.OPT_NAIVE_UTC,\n            ),\n            b\'{\\n  ""1"": 1,\\n  ""a"": ""1970-01-01T00:00:00+00:00"",\\n  ""b"": true\\n}\',\n        )\n\n    def test_twitter_pretty(self):\n        """"""\n        twitter.json pretty\n        """"""\n        obj = read_fixture_obj(""twitter.json.xz"")\n        self.assertEqual(\n            orjson.dumps(obj, option=orjson.OPT_INDENT_2),\n            json.dumps(obj, indent=2, ensure_ascii=False).encode(""utf-8""),\n        )\n\n    def test_github_pretty(self):\n        """"""\n        github.json pretty\n        """"""\n        obj = read_fixture_obj(""github.json.xz"")\n        self.assertEqual(\n            orjson.dumps(obj, option=orjson.OPT_INDENT_2),\n            json.dumps(obj, indent=2, ensure_ascii=False).encode(""utf-8""),\n        )\n\n    def test_canada_pretty(self):\n        """"""\n        canada.json pretty\n        """"""\n        obj = read_fixture_obj(""canada.json.xz"")\n        self.assertEqual(\n            orjson.dumps(obj, option=orjson.OPT_INDENT_2),\n            json.dumps(obj, indent=2, ensure_ascii=False).encode(""utf-8""),\n        )\n\n    def test_citm_catalog_pretty(self):\n        """"""\n        citm_catalog.json pretty\n        """"""\n        obj = read_fixture_obj(""citm_catalog.json.xz"")\n        self.assertEqual(\n            orjson.dumps(obj, option=orjson.OPT_INDENT_2),\n            json.dumps(obj, indent=2, ensure_ascii=False).encode(""utf-8""),\n        )\n'"
test/test_jsonchecker.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n""""""\nTests files from http://json.org/JSON_checker/\n""""""\n\nimport unittest\n\nimport orjson\n\nfrom .util import read_fixture_str\n\nPATTERN_1 = \'[""JSON Test Pattern pass1"",{""object with 1 member"":[""array with 1 element""]},{},[],-42,true,false,null,{""integer"":1234567890,""real"":-9876.54321,""e"":1.23456789e-13,""E"":1.23456789e34,"""":2.3456789012e76,""zero"":0,""one"":1,""space"":"" "",""quote"":""\\\\"""",""backslash"":""\\\\\\\\"",""controls"":""\\\\b\\\\f\\\\n\\\\r\\\\t"",""slash"":""/ & /"",""alpha"":""abcdefghijklmnopqrstuvwyz"",""ALPHA"":""ABCDEFGHIJKLMNOPQRSTUVWYZ"",""digit"":""0123456789"",""0123456789"":""digit"",""special"":""`1~!@#$%^&*()_+-={\\\':[,]}|;.</>?"",""hex"":""\xc4\xa3\xe4\x95\xa7\xe8\xa6\xab\xec\xb7\xaf\xea\xaf\x8d\\uef4a"",""true"":true,""false"":false,""null"":null,""array"":[],""object"":{},""address"":""50 St. James Street"",""url"":""http://www.JSON.org/"",""comment"":""// /* <!-- --"",""# -- --> */"":"" "","" s p a c e d "":[1,2,3,4,5,6,7],""compact"":[1,2,3,4,5,6,7],""jsontext"":""{\\\\""object with 1 member\\\\"":[\\\\""array with 1 element\\\\""]}"",""quotes"":""&#34; \\\\"" %22 0x22 034 &#x22;"",""/\\\\\\\\\\\\""\xec\xab\xbe\xeb\xaa\xbe\xea\xae\x98\xef\xb3\x9e\xeb\xb3\x9a\\uef4a\\\\b\\\\f\\\\n\\\\r\\\\t`1~!@#$%^&*()_+-=[]{}|;:\\\',./<>?"":""A key can be any string""},0.5,98.6,99.44,1066,10.0,1.0,0.1,1.0,2.0,2.0,""rosebud""]\'.encode()\n\n\nclass JsonCheckerTests(unittest.TestCase):\n    def _run_fail_json(self, filename, exc=orjson.JSONDecodeError):\n        data = read_fixture_str(filename, ""jsonchecker"")\n        self.assertRaises(exc, orjson.loads, data)\n\n    def _run_pass_json(self, filename, match=""""):\n        data = read_fixture_str(filename, ""jsonchecker"")\n        self.assertEqual(orjson.dumps(orjson.loads(data)), match)\n\n    def test_fail01(self):\n        """"""\n        fail01.json\n        """"""\n        self._run_pass_json(\n            ""fail01.json"",\n            b\'""A JSON payload should be an object or array, not a string.""\',\n        )\n\n    def test_fail02(self):\n        """"""\n        fail02.json\n        """"""\n        self._run_fail_json(""fail02.json"", orjson.JSONDecodeError)  # EOF\n\n    def test_fail03(self):\n        """"""\n        fail03.json\n        """"""\n        self._run_fail_json(""fail03.json"")\n\n    def test_fail04(self):\n        """"""\n        fail04.json\n        """"""\n        self._run_fail_json(""fail04.json"")\n\n    def test_fail05(self):\n        """"""\n        fail05.json\n        """"""\n        self._run_fail_json(""fail05.json"")\n\n    def test_fail06(self):\n        """"""\n        fail06.json\n        """"""\n        self._run_fail_json(""fail06.json"")\n\n    def test_fail07(self):\n        """"""\n        fail07.json\n        """"""\n        self._run_fail_json(""fail07.json"")\n\n    def test_fail08(self):\n        """"""\n        fail08.json\n        """"""\n        self._run_fail_json(""fail08.json"")\n\n    def test_fail09(self):\n        """"""\n        fail09.json\n        """"""\n        self._run_fail_json(""fail09.json"")\n\n    def test_fail10(self):\n        """"""\n        fail10.json\n        """"""\n        self._run_fail_json(""fail10.json"")\n\n    def test_fail11(self):\n        """"""\n        fail11.json\n        """"""\n        self._run_fail_json(""fail11.json"")\n\n    def test_fail12(self):\n        """"""\n        fail12.json\n        """"""\n        self._run_fail_json(""fail12.json"")\n\n    def test_fail13(self):\n        """"""\n        fail13.json\n        """"""\n        self._run_fail_json(""fail13.json"")\n\n    def test_fail14(self):\n        """"""\n        fail14.json\n        """"""\n        self._run_fail_json(""fail14.json"")\n\n    def test_fail15(self):\n        """"""\n        fail15.json\n        """"""\n        self._run_fail_json(""fail15.json"")\n\n    def test_fail16(self):\n        """"""\n        fail16.json\n        """"""\n        self._run_fail_json(""fail16.json"")\n\n    def test_fail17(self):\n        """"""\n        fail17.json\n        """"""\n        self._run_fail_json(""fail17.json"")\n\n    def test_fail18(self):\n        """"""\n        fail18.json\n        """"""\n        self._run_pass_json(\n            ""fail18.json"", b\'[[[[[[[[[[[[[[[[[[[[""Too deep""]]]]]]]]]]]]]]]]]]]]\'\n        )\n\n    def test_fail19(self):\n        """"""\n        fail19.json\n        """"""\n        self._run_fail_json(""fail19.json"")\n\n    def test_fail20(self):\n        """"""\n        fail20.json\n        """"""\n        self._run_fail_json(""fail20.json"")\n\n    def test_fail21(self):\n        """"""\n        fail21.json\n        """"""\n        self._run_fail_json(""fail21.json"")\n\n    def test_fail22(self):\n        """"""\n        fail22.json\n        """"""\n        self._run_fail_json(""fail22.json"")\n\n    def test_fail23(self):\n        """"""\n        fail23.json\n        """"""\n        self._run_fail_json(""fail23.json"")\n\n    def test_fail24(self):\n        """"""\n        fail24.json\n        """"""\n        self._run_fail_json(""fail24.json"")\n\n    def test_fail25(self):\n        """"""\n        fail25.json\n        """"""\n        self._run_fail_json(""fail25.json"")\n\n    def test_fail26(self):\n        """"""\n        fail26.json\n        """"""\n        self._run_fail_json(""fail26.json"")\n\n    def test_fail27(self):\n        """"""\n        fail27.json\n        """"""\n        self._run_fail_json(""fail27.json"")\n\n    def test_fail28(self):\n        """"""\n        fail28.json\n        """"""\n        self._run_fail_json(""fail28.json"")\n\n    def test_fail29(self):\n        """"""\n        fail29.json\n        """"""\n        self._run_fail_json(""fail29.json"")\n\n    def test_fail30(self):\n        """"""\n        fail30.json\n        """"""\n        self._run_fail_json(""fail30.json"")\n\n    def test_fail31(self):\n        """"""\n        fail31.json\n        """"""\n        self._run_fail_json(""fail31.json"")\n\n    def test_fail32(self):\n        """"""\n        fail32.json\n        """"""\n        self._run_fail_json(""fail32.json"", orjson.JSONDecodeError)  # EOF\n\n    def test_fail33(self):\n        """"""\n        fail33.json\n        """"""\n        self._run_fail_json(""fail33.json"")\n\n    def test_pass01(self):\n        """"""\n        pass01.json\n        """"""\n        self._run_pass_json(""pass01.json"", PATTERN_1)\n\n    def test_pass02(self):\n        """"""\n        pass02.json\n        """"""\n        self._run_pass_json(\n            ""pass02.json"", b\'[[[[[[[[[[[[[[[[[[[""Not too deep""]]]]]]]]]]]]]]]]]]]\'\n        )\n\n    def test_pass03(self):\n        """"""\n        pass03.json\n        """"""\n        self._run_pass_json(\n            ""pass03.json"",\n            b\'{""JSON Test Pattern pass3"":{""The outermost value"":""must be \'\n            b\'an object or array."",""In this test"":""It is an object.""}}\',\n        )\n'"
test/test_memory.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport dataclasses\nimport datetime\nimport gc\nimport random\nimport unittest\nfrom typing import List\n\nimport orjson\nimport psutil\nimport pytest\n\ntry:\n    import numpy\nexcept ImportError:\n    numpy = None\n\nFIXTURE = \'{""a"":[81891289, 8919812.190129012], ""b"": false, ""c"": null, ""d"": ""\xe6\x9d\xb1\xe4\xba\xac""}\'\n\n\ndef default(obj):\n    return str(obj)\n\n\n@dataclasses.dataclass\nclass Member:\n    id: int\n    active: bool\n\n\n@dataclasses.dataclass\nclass Object:\n    id: int\n    updated_at: datetime.datetime\n    name: str\n    members: List[Member]\n\n\nDATACLASS_FIXTURE = [\n    Object(\n        i,\n        datetime.datetime.now(datetime.timezone.utc)\n        + datetime.timedelta(seconds=random.randint(0, 10000)),\n        str(i) * 3,\n        [Member(j, True) for j in range(0, 10)],\n    )\n    for i in range(100000, 101000)\n]\n\nMAX_INCREASE = 1048576  # 1MiB\n\n\nclass Unsupported:\n    pass\n\n\nclass MemoryTests(unittest.TestCase):\n    def test_memory_loads(self):\n        """"""\n        loads() memory leak\n        """"""\n        proc = psutil.Process()\n        gc.collect()\n        val = orjson.loads(FIXTURE)\n        mem = proc.memory_info().rss\n        for _ in range(10000):\n            val = orjson.loads(FIXTURE)\n        gc.collect()\n        self.assertTrue(proc.memory_info().rss <= mem + MAX_INCREASE)\n\n    def test_memory_dumps(self):\n        """"""\n        dumps() memory leak\n        """"""\n        proc = psutil.Process()\n        gc.collect()\n        fixture = orjson.loads(FIXTURE)\n        val = orjson.dumps(fixture)\n        mem = proc.memory_info().rss\n        for _ in range(10000):\n            val = orjson.dumps(fixture)\n        gc.collect()\n        self.assertTrue(proc.memory_info().rss <= mem + MAX_INCREASE)\n\n    def test_memory_loads_exc(self):\n        """"""\n        loads() memory leak exception without a GC pause\n        """"""\n        proc = psutil.Process()\n        gc.disable()\n        mem = proc.memory_info().rss\n        n = 10000\n        i = 0\n        for _ in range(n):\n            try:\n                orjson.loads("""")\n            except orjson.JSONDecodeError:\n                i += 1\n        assert n == i\n        self.assertTrue(proc.memory_info().rss <= mem + MAX_INCREASE)\n        gc.enable()\n\n    def test_memory_dumps_exc(self):\n        """"""\n        dumps() memory leak exception without a GC pause\n        """"""\n        proc = psutil.Process()\n        gc.disable()\n        data = Unsupported()\n        mem = proc.memory_info().rss\n        n = 10000\n        i = 0\n        for _ in range(n):\n            try:\n                orjson.dumps(data)\n            except orjson.JSONEncodeError:\n                i += 1\n        assert n == i\n        self.assertTrue(proc.memory_info().rss <= mem + MAX_INCREASE)\n        gc.enable()\n\n    def test_memory_dumps_default(self):\n        """"""\n        dumps() default memory leak\n        """"""\n        proc = psutil.Process()\n        gc.collect()\n        fixture = orjson.loads(FIXTURE)\n\n        class Custom:\n            def __init__(self, name):\n                self.name = name\n\n            def __str__(self):\n                return f""{self.__class__.__name__}({self.name})""\n\n        fixture[""custom""] = Custom(""orjson"")\n        val = orjson.dumps(fixture, default=default)\n        mem = proc.memory_info().rss\n        for _ in range(10000):\n            val = orjson.dumps(fixture, default=default)\n        gc.collect()\n        self.assertTrue(proc.memory_info().rss <= mem + MAX_INCREASE)\n\n    def test_memory_dumps_dataclass(self):\n        """"""\n        dumps() dataclass memory leak\n        """"""\n        proc = psutil.Process()\n        gc.collect()\n        val = orjson.dumps(DATACLASS_FIXTURE)\n        mem = proc.memory_info().rss\n        for _ in range(100):\n            val = orjson.dumps(DATACLASS_FIXTURE)\n        gc.collect()\n        self.assertTrue(proc.memory_info().rss <= mem + MAX_INCREASE)\n\n    def test_memory_loads_keys(self):\n        """"""\n        loads() memory leak with number of keys causing cache eviction\n        """"""\n        proc = psutil.Process()\n        gc.collect()\n        fixture = {""key_%s"" % idx: ""value"" for idx in range(1024)}\n        self.assertEqual(len(fixture), 1024)\n        val = orjson.dumps(fixture)\n        loaded = orjson.loads(val)\n        mem = proc.memory_info().rss\n        for _ in range(100):\n            loaded = orjson.loads(val)\n        gc.collect()\n        self.assertTrue(proc.memory_info().rss <= mem + MAX_INCREASE)\n\n    @pytest.mark.skipif(numpy is None, reason=""numpy is not installed"")\n    def test_memory_dumps_numpy(self):\n        """"""\n        dumps() dataclass memory leak\n        """"""\n        proc = psutil.Process()\n        gc.collect()\n        fixture = numpy.random.rand(4, 4, 4)\n        val = orjson.dumps(fixture, option=orjson.OPT_SERIALIZE_NUMPY)\n        mem = proc.memory_info().rss\n        for _ in range(100):\n            val = orjson.dumps(fixture, option=orjson.OPT_SERIALIZE_NUMPY)\n        gc.collect()\n        self.assertTrue(proc.memory_info().rss <= mem + MAX_INCREASE)\n'"
test/test_non_str_keys.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport dataclasses\nimport datetime\nimport unittest\nimport uuid\n\nimport orjson\nimport pytest\nimport pytz\n\ntry:\n    import numpy\nexcept ImportError:\n    numpy = None\n\n\nclass SubStr(str):\n    pass\n\n\nclass NonStrKeyTests(unittest.TestCase):\n    def test_dict_keys_duplicate(self):\n        """"""\n        OPT_NON_STR_KEYS serializes duplicate keys\n        """"""\n        self.assertEqual(\n            orjson.dumps({""1"": True, 1: False}, option=orjson.OPT_NON_STR_KEYS),\n            b\'{""1"":true,""1"":false}\',\n        )\n\n    def test_dict_keys_int(self):\n        self.assertEqual(\n            orjson.dumps({1: True, 2: False}, option=orjson.OPT_NON_STR_KEYS),\n            b\'{""1"":true,""2"":false}\',\n        )\n\n    def test_dict_keys_substr(self):\n        self.assertEqual(\n            orjson.dumps({SubStr(""aaa""): True}, option=orjson.OPT_NON_STR_KEYS),\n            b\'{""aaa"":true}\',\n        )\n\n    def test_dict_keys_substr_passthrough(self):\n        """"""\n        OPT_PASSTHROUGH_SUBCLASS does not affect OPT_NON_STR_KEYS\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                {SubStr(""aaa""): True},\n                option=orjson.OPT_NON_STR_KEYS | orjson.OPT_PASSTHROUGH_SUBCLASS,\n            ),\n            b\'{""aaa"":true}\',\n        )\n\n    def test_dict_keys_substr_invalid(self):\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps({SubStr(""\\ud800""): True}, option=orjson.OPT_NON_STR_KEYS)\n\n    def test_dict_keys_strict(self):\n        """"""\n        OPT_NON_STR_KEYS does not respect OPT_STRICT_INTEGER\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                {9223372036854775807: True},\n                option=orjson.OPT_NON_STR_KEYS | orjson.OPT_STRICT_INTEGER,\n            ),\n            b\'{""9223372036854775807"":true}\',\n        )\n\n    def test_dict_keys_int_range(self):\n        """"""\n        OPT_NON_STR_KEYS has a 64-bit range for int\n        """"""\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps({9223372036854775809: True}, option=orjson.OPT_NON_STR_KEYS)\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps({-9223372036854775809: True}, option=orjson.OPT_NON_STR_KEYS)\n\n    def test_dict_keys_float(self):\n        self.assertEqual(\n            orjson.dumps({1.1: True, 2.2: False}, option=orjson.OPT_NON_STR_KEYS),\n            b\'{""1.1"":true,""2.2"":false}\',\n        )\n\n    def test_dict_keys_inf(self):\n        self.assertEqual(\n            orjson.dumps({float(""Infinity""): True}, option=orjson.OPT_NON_STR_KEYS),\n            b\'{""null"":true}\',\n        )\n        self.assertEqual(\n            orjson.dumps({float(""-Infinity""): True}, option=orjson.OPT_NON_STR_KEYS),\n            b\'{""null"":true}\',\n        )\n\n    def test_dict_keys_nan(self):\n        self.assertEqual(\n            orjson.dumps({float(""NaN""): True}, option=orjson.OPT_NON_STR_KEYS),\n            b\'{""null"":true}\',\n        )\n\n    def test_dict_keys_bool(self):\n        self.assertEqual(\n            orjson.dumps({True: True, False: False}, option=orjson.OPT_NON_STR_KEYS),\n            b\'{""true"":true,""false"":false}\',\n        )\n\n    def test_dict_keys_datetime(self):\n        self.assertEqual(\n            orjson.dumps(\n                {datetime.datetime(2000, 1, 1, 2, 3, 4, 123): True},\n                option=orjson.OPT_NON_STR_KEYS,\n            ),\n            b\'{""2000-01-01T02:03:04.000123"":true}\',\n        )\n\n    def test_dict_keys_datetime_opt(self):\n        self.assertEqual(\n            orjson.dumps(\n                {datetime.datetime(2000, 1, 1, 2, 3, 4, 123): True},\n                option=orjson.OPT_NON_STR_KEYS\n                | orjson.OPT_OMIT_MICROSECONDS\n                | orjson.OPT_NAIVE_UTC\n                | orjson.OPT_UTC_Z,\n            ),\n            b\'{""2000-01-01T02:03:04Z"":true}\',\n        )\n\n    def test_dict_keys_datetime_passthrough(self):\n        """"""\n        OPT_PASSTHROUGH_DATETIME does not affect OPT_NON_STR_KEYS\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                {datetime.datetime(2000, 1, 1, 2, 3, 4, 123): True},\n                option=orjson.OPT_NON_STR_KEYS | orjson.OPT_PASSTHROUGH_DATETIME,\n            ),\n            b\'{""2000-01-01T02:03:04.000123"":true}\',\n        )\n\n    def test_dict_keys_uuid(self):\n        """"""\n        OPT_NON_STR_KEYS always serializes UUID as keys\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                {uuid.UUID(""7202d115-7ff3-4c81-a7c1-2a1f067b1ece""): True},\n                option=orjson.OPT_NON_STR_KEYS,\n            ),\n            b\'{""7202d115-7ff3-4c81-a7c1-2a1f067b1ece"":true}\',\n        )\n\n    def test_dict_keys_date(self):\n        self.assertEqual(\n            orjson.dumps(\n                {datetime.date(1970, 1, 1): True}, option=orjson.OPT_NON_STR_KEYS\n            ),\n            b\'{""1970-01-01"":true}\',\n        )\n\n    def test_dict_keys_time(self):\n        self.assertEqual(\n            orjson.dumps(\n                {datetime.time(12, 15, 59, 111): True}, option=orjson.OPT_NON_STR_KEYS,\n            ),\n            b\'{""12:15:59.000111"":true}\',\n        )\n\n    def test_dict_non_str_and_sort_keys(self):\n        self.assertEqual(\n            orjson.dumps(\n                {\n                    ""other"": 1,\n                    datetime.date(1970, 1, 5): 2,\n                    datetime.date(1970, 1, 3): 3,\n                },\n                option=orjson.OPT_NON_STR_KEYS | orjson.OPT_SORT_KEYS,\n            ),\n            b\'{""1970-01-03"":3,""1970-01-05"":2,""other"":1}\',\n        )\n\n    def test_dict_keys_time_err(self):\n        """"""\n        OPT_NON_STR_KEYS propagates errors in types\n        """"""\n        val = datetime.time(12, 15, 59, 111, tzinfo=pytz.timezone(""Asia/Shanghai""))\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps({val: True}, option=orjson.OPT_NON_STR_KEYS)\n\n    def test_dict_keys_str(self):\n        self.assertEqual(\n            orjson.dumps({""1"": True}, option=orjson.OPT_NON_STR_KEYS), b\'{""1"":true}\',\n        )\n\n    def test_dict_keys_type(self):\n        class Obj:\n            a: str\n\n        val = Obj()\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps({val: True}, option=orjson.OPT_NON_STR_KEYS)\n\n    @pytest.mark.skipif(numpy is None, reason=""numpy is not installed"")\n    def test_dict_keys_array(self):\n        with self.assertRaises(TypeError):\n            {numpy.array([1, 2]): True}\n\n    def test_dict_keys_dataclass(self):\n        @dataclasses.dataclass\n        class Dataclass:\n            a: str\n\n        with self.assertRaises(TypeError):\n            {Dataclass(""a""): True}\n\n    def test_dict_keys_dataclass_hash(self):\n        @dataclasses.dataclass\n        class Dataclass:\n            a: str\n\n            def __hash__(self):\n                return 1\n\n        obj = {Dataclass(""a""): True}\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(obj, option=orjson.OPT_NON_STR_KEYS)\n\n    def test_dict_keys_list(self):\n        with self.assertRaises(TypeError):\n            {[]: True}\n\n    def test_dict_keys_dict(self):\n        with self.assertRaises(TypeError):\n            {{}: True}\n\n    def test_dict_keys_tuple(self):\n        obj = {(): True}\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(obj, option=orjson.OPT_NON_STR_KEYS)\n\n    def test_dict_keys_unknown(self):\n        obj = {frozenset(): True}\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps({frozenset(): True}, option=orjson.OPT_NON_STR_KEYS)\n\n    def test_dict_keys_no_str_call(self):\n        class Obj:\n            a: str\n\n            def __str__(self):\n                return ""Obj""\n\n        val = Obj()\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps({val: True}, option=orjson.OPT_NON_STR_KEYS)\n'"
test/test_numpy.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport unittest\n\nimport orjson\nimport pytest\n\ntry:\n    import numpy\nexcept ImportError:\n    numpy = None\n\n\ndef numpy_default(obj):\n    return obj.tolist()\n\n\n@pytest.mark.skipif(numpy is None, reason=""numpy is not installed"")\nclass NumpyTests(unittest.TestCase):\n    def test_numpy_array_d1_uintp(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array([0, 18446744073709551615], numpy.uintp),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[0,18446744073709551615]"",\n        )\n\n    def test_numpy_array_d1_intp(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array([-9223372036854775807, 9223372036854775807], numpy.intp),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[-9223372036854775807,9223372036854775807]"",\n        )\n\n    def test_numpy_array_d1_i64(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array([-9223372036854775807, 9223372036854775807], numpy.int64),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[-9223372036854775807,9223372036854775807]"",\n        )\n\n    def test_numpy_array_d1_u64(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array([0, 18446744073709551615], numpy.uint64),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[0,18446744073709551615]"",\n        )\n\n    def test_numpy_array_d1_i32(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array([-2147483647, 2147483647], numpy.int32),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[-2147483647,2147483647]"",\n        )\n\n    def test_numpy_array_d1_u32(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array([0, 4294967295], numpy.uint32),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[0,4294967295]"",\n        )\n\n    def test_numpy_array_d1_f32(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array([1.0, 3.4028235e38], numpy.float32),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[1.0,3.4028235e38]"",\n        )\n\n    def test_numpy_array_d1_f64(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array([1.0, 1.7976931348623157e308], numpy.float64),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[1.0,1.7976931348623157e308]"",\n        )\n\n    def test_numpy_array_d1_bool(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array([True, False, False, True]),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[true,false,false,true]"",\n        )\n\n    def test_numpy_array_d2_i64(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array([[1, 2, 3], [4, 5, 6]], numpy.int64),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[[1,2,3],[4,5,6]]"",\n        )\n\n    def test_numpy_array_d2_f64(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], numpy.float64),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[[1.0,2.0,3.0],[4.0,5.0,6.0]]"",\n        )\n\n    def test_numpy_array_d3_i32(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]], numpy.int32),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[[[1,2],[3,4]],[[5,6],[7,8]]]"",\n        )\n\n    def test_numpy_array_d3_i64(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array([[[1, 2], [3, 4], [5, 6], [7, 8]]], numpy.int64),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[[[1,2],[3,4],[5,6],[7,8]]]"",\n        )\n\n    def test_numpy_array_d3_f64(self):\n        self.assertEqual(\n            orjson.dumps(\n                numpy.array(\n                    [[[1.0, 2.0], [3.0, 4.0]], [[5.0, 6.0], [7.0, 8.0]]], numpy.float64\n                ),\n                option=orjson.OPT_SERIALIZE_NUMPY,\n            ),\n            b""[[[1.0,2.0],[3.0,4.0]],[[5.0,6.0],[7.0,8.0]]]"",\n        )\n\n    def test_numpy_array_d0(self):\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(numpy.int32(1), option=orjson.OPT_SERIALIZE_NUMPY)\n\n    def test_numpy_array_fotran(self):\n        array = numpy.array([[1, 2], [3, 4]], order=""F"")\n        assert array.flags[""F_CONTIGUOUS""] == True\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(array, option=orjson.OPT_SERIALIZE_NUMPY)\n        self.assertEqual(\n            orjson.dumps(\n                array, default=numpy_default, option=orjson.OPT_SERIALIZE_NUMPY\n            ),\n            orjson.dumps(array.tolist()),\n        )\n\n    def test_numpy_array_unsupported_dtype(self):\n        array = numpy.array([[1, 2], [3, 4]], numpy.int8)\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(array, option=orjson.OPT_SERIALIZE_NUMPY)\n        self.assertEqual(\n            orjson.dumps(\n                array, default=numpy_default, option=orjson.OPT_SERIALIZE_NUMPY\n            ),\n            orjson.dumps(array.tolist()),\n        )\n\n    def test_numpy_array_d1(self):\n        array = numpy.array([1])\n        self.assertEqual(\n            orjson.loads(orjson.dumps(array, option=orjson.OPT_SERIALIZE_NUMPY,)),\n            array.tolist(),\n        )\n\n    def test_numpy_array_d2(self):\n        array = numpy.array([[1]])\n        self.assertEqual(\n            orjson.loads(orjson.dumps(array, option=orjson.OPT_SERIALIZE_NUMPY,)),\n            array.tolist(),\n        )\n\n    def test_numpy_array_d3(self):\n        array = numpy.array([[[1]]])\n        self.assertEqual(\n            orjson.loads(orjson.dumps(array, option=orjson.OPT_SERIALIZE_NUMPY,)),\n            array.tolist(),\n        )\n\n    def test_numpy_array_d4(self):\n        array = numpy.array([[[[1]]]])\n        self.assertEqual(\n            orjson.loads(orjson.dumps(array, option=orjson.OPT_SERIALIZE_NUMPY,)),\n            array.tolist(),\n        )\n\n    def test_numpy_array_4_stride(self):\n        array = numpy.random.rand(4, 4, 4, 4)\n        self.assertEqual(\n            orjson.loads(orjson.dumps(array, option=orjson.OPT_SERIALIZE_NUMPY,)),\n            array.tolist(),\n        )\n\n    def test_numpy_array_dimension_max(self):\n        array = numpy.random.rand(\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n            1,\n        )\n        assert array.ndim == 32\n        self.assertEqual(\n            orjson.loads(orjson.dumps(array, option=orjson.OPT_SERIALIZE_NUMPY,)),\n            array.tolist(),\n        )\n'"
test/test_parsing.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport unittest\n\nimport orjson\n\nfrom .util import read_fixture_bytes\n\n\nclass JSONTestSuiteParsingTests(unittest.TestCase):\n    def _run_fail_json(self, filename, exc=orjson.JSONDecodeError):\n        data = read_fixture_bytes(filename, ""parsing"")\n        with self.assertRaises(exc, msg=data):\n            res = orjson.loads(data)\n        with self.assertRaises(exc, msg=data):\n            res = orjson.loads(bytearray(data))\n        try:\n            decoded = data.decode(""utf-8"")\n        except UnicodeDecodeError:\n            pass\n        else:\n            with self.assertRaises(exc, msg=decoded):\n                res = orjson.loads(decoded)\n\n    def _run_pass_json(self, filename, match=""""):\n        data = read_fixture_bytes(filename, ""parsing"")\n        orjson.loads(data)\n        orjson.loads(bytearray(data))\n        orjson.loads(data.decode(""utf-8""))\n\n    def test_y_array_arraysWithSpace(self):\n        """"""\n        y_array_arraysWithSpaces.json\n        """"""\n        self._run_pass_json(""y_array_arraysWithSpaces.json"")\n\n    def test_y_array_empty_string(self):\n        """"""\n        y_array_empty-string.json\n        """"""\n        self._run_pass_json(""y_array_empty-string.json"")\n\n    def test_y_array_empty(self):\n        """"""\n        y_array_empty.json\n        """"""\n        self._run_pass_json(""y_array_empty.json"")\n\n    def test_y_array_ending_with_newline(self):\n        """"""\n        y_array_ending_with_newline.json\n        """"""\n        self._run_pass_json(""y_array_ending_with_newline.json"")\n\n    def test_y_array_false(self):\n        """"""\n        y_array_false.json\n        """"""\n        self._run_pass_json(""y_array_false.json"")\n\n    def test_y_array_heterogeneou(self):\n        """"""\n        y_array_heterogeneous.json\n        """"""\n        self._run_pass_json(""y_array_heterogeneous.json"")\n\n    def test_y_array_null(self):\n        """"""\n        y_array_null.json\n        """"""\n        self._run_pass_json(""y_array_null.json"")\n\n    def test_y_array_with_1_and_newline(self):\n        """"""\n        y_array_with_1_and_newline.json\n        """"""\n        self._run_pass_json(""y_array_with_1_and_newline.json"")\n\n    def test_y_array_with_leading_space(self):\n        """"""\n        y_array_with_leading_space.json\n        """"""\n        self._run_pass_json(""y_array_with_leading_space.json"")\n\n    def test_y_array_with_several_null(self):\n        """"""\n        y_array_with_several_null.json\n        """"""\n        self._run_pass_json(""y_array_with_several_null.json"")\n\n    def test_y_array_with_trailing_space(self):\n        """"""\n        y_array_with_trailing_space.json\n        """"""\n        self._run_pass_json(""y_array_with_trailing_space.json"")\n\n    def test_y_number(self):\n        """"""\n        y_number.json\n        """"""\n        self._run_pass_json(""y_number.json"")\n\n    def test_y_number_0e_1(self):\n        """"""\n        y_number_0e+1.json\n        """"""\n        self._run_pass_json(""y_number_0e+1.json"")\n\n    def test_y_number_0e1(self):\n        """"""\n        y_number_0e1.json\n        """"""\n        self._run_pass_json(""y_number_0e1.json"")\n\n    def test_y_number_after_space(self):\n        """"""\n        y_number_after_space.json\n        """"""\n        self._run_pass_json(""y_number_after_space.json"")\n\n    def test_y_number_double_close_to_zer(self):\n        """"""\n        y_number_double_close_to_zero.json\n        """"""\n        self._run_pass_json(""y_number_double_close_to_zero.json"")\n\n    def test_y_number_int_with_exp(self):\n        """"""\n        y_number_int_with_exp.json\n        """"""\n        self._run_pass_json(""y_number_int_with_exp.json"")\n\n    def test_y_number_minus_zer(self):\n        """"""\n        y_number_minus_zero.json\n        """"""\n        self._run_pass_json(""y_number_minus_zero.json"")\n\n    def test_y_number_negative_int(self):\n        """"""\n        y_number_negative_int.json\n        """"""\n        self._run_pass_json(""y_number_negative_int.json"")\n\n    def test_y_number_negative_one(self):\n        """"""\n        y_number_negative_one.json\n        """"""\n        self._run_pass_json(""y_number_negative_one.json"")\n\n    def test_y_number_negative_zer(self):\n        """"""\n        y_number_negative_zero.json\n        """"""\n        self._run_pass_json(""y_number_negative_zero.json"")\n\n    def test_y_number_real_capital_e(self):\n        """"""\n        y_number_real_capital_e.json\n        """"""\n        self._run_pass_json(""y_number_real_capital_e.json"")\n\n    def test_y_number_real_capital_e_neg_exp(self):\n        """"""\n        y_number_real_capital_e_neg_exp.json\n        """"""\n        self._run_pass_json(""y_number_real_capital_e_neg_exp.json"")\n\n    def test_y_number_real_capital_e_pos_exp(self):\n        """"""\n        y_number_real_capital_e_pos_exp.json\n        """"""\n        self._run_pass_json(""y_number_real_capital_e_pos_exp.json"")\n\n    def test_y_number_real_exponent(self):\n        """"""\n        y_number_real_exponent.json\n        """"""\n        self._run_pass_json(""y_number_real_exponent.json"")\n\n    def test_y_number_real_fraction_exponent(self):\n        """"""\n        y_number_real_fraction_exponent.json\n        """"""\n        self._run_pass_json(""y_number_real_fraction_exponent.json"")\n\n    def test_y_number_real_neg_exp(self):\n        """"""\n        y_number_real_neg_exp.json\n        """"""\n        self._run_pass_json(""y_number_real_neg_exp.json"")\n\n    def test_y_number_real_pos_exponent(self):\n        """"""\n        y_number_real_pos_exponent.json\n        """"""\n        self._run_pass_json(""y_number_real_pos_exponent.json"")\n\n    def test_y_number_simple_int(self):\n        """"""\n        y_number_simple_int.json\n        """"""\n        self._run_pass_json(""y_number_simple_int.json"")\n\n    def test_y_number_simple_real(self):\n        """"""\n        y_number_simple_real.json\n        """"""\n        self._run_pass_json(""y_number_simple_real.json"")\n\n    def test_y_object(self):\n        """"""\n        y_object.json\n        """"""\n        self._run_pass_json(""y_object.json"")\n\n    def test_y_object_basic(self):\n        """"""\n        y_object_basic.json\n        """"""\n        self._run_pass_json(""y_object_basic.json"")\n\n    def test_y_object_duplicated_key(self):\n        """"""\n        y_object_duplicated_key.json\n        """"""\n        self._run_pass_json(""y_object_duplicated_key.json"")\n\n    def test_y_object_duplicated_key_and_value(self):\n        """"""\n        y_object_duplicated_key_and_value.json\n        """"""\n        self._run_pass_json(""y_object_duplicated_key_and_value.json"")\n\n    def test_y_object_empty(self):\n        """"""\n        y_object_empty.json\n        """"""\n        self._run_pass_json(""y_object_empty.json"")\n\n    def test_y_object_empty_key(self):\n        """"""\n        y_object_empty_key.json\n        """"""\n        self._run_pass_json(""y_object_empty_key.json"")\n\n    def test_y_object_escaped_null_in_key(self):\n        """"""\n        y_object_escaped_null_in_key.json\n        """"""\n        self._run_pass_json(""y_object_escaped_null_in_key.json"")\n\n    def test_y_object_extreme_number(self):\n        """"""\n        y_object_extreme_numbers.json\n        """"""\n        self._run_pass_json(""y_object_extreme_numbers.json"")\n\n    def test_y_object_long_string(self):\n        """"""\n        y_object_long_strings.json\n        """"""\n        self._run_pass_json(""y_object_long_strings.json"")\n\n    def test_y_object_simple(self):\n        """"""\n        y_object_simple.json\n        """"""\n        self._run_pass_json(""y_object_simple.json"")\n\n    def test_y_object_string_unicode(self):\n        """"""\n        y_object_string_unicode.json\n        """"""\n        self._run_pass_json(""y_object_string_unicode.json"")\n\n    def test_y_object_with_newline(self):\n        """"""\n        y_object_with_newlines.json\n        """"""\n        self._run_pass_json(""y_object_with_newlines.json"")\n\n    def test_y_string_1_2_3_bytes_UTF_8_sequence(self):\n        """"""\n        y_string_1_2_3_bytes_UTF-8_sequences.json\n        """"""\n        self._run_pass_json(""y_string_1_2_3_bytes_UTF-8_sequences.json"")\n\n    def test_y_string_accepted_surrogate_pair(self):\n        """"""\n        y_string_accepted_surrogate_pair.json\n        """"""\n        self._run_pass_json(""y_string_accepted_surrogate_pair.json"")\n\n    def test_y_string_accepted_surrogate_pairs(self):\n        """"""\n        y_string_accepted_surrogate_pairs.json\n        """"""\n        self._run_pass_json(""y_string_accepted_surrogate_pairs.json"")\n\n    def test_y_string_allowed_escape(self):\n        """"""\n        y_string_allowed_escapes.json\n        """"""\n        self._run_pass_json(""y_string_allowed_escapes.json"")\n\n    def test_y_string_backslash_and_u_escaped_zer(self):\n        """"""\n        y_string_backslash_and_u_escaped_zero.json\n        """"""\n        self._run_pass_json(""y_string_backslash_and_u_escaped_zero.json"")\n\n    def test_y_string_backslash_doublequote(self):\n        """"""\n        y_string_backslash_doublequotes.json\n        """"""\n        self._run_pass_json(""y_string_backslash_doublequotes.json"")\n\n    def test_y_string_comment(self):\n        """"""\n        y_string_comments.json\n        """"""\n        self._run_pass_json(""y_string_comments.json"")\n\n    def test_y_string_double_escape_a(self):\n        """"""\n        y_string_double_escape_a.json\n        """"""\n        self._run_pass_json(""y_string_double_escape_a.json"")\n\n    def test_y_string_double_escape_(self):\n        """"""\n        y_string_double_escape_n.json\n        """"""\n        self._run_pass_json(""y_string_double_escape_n.json"")\n\n    def test_y_string_escaped_control_character(self):\n        """"""\n        y_string_escaped_control_character.json\n        """"""\n        self._run_pass_json(""y_string_escaped_control_character.json"")\n\n    def test_y_string_escaped_noncharacter(self):\n        """"""\n        y_string_escaped_noncharacter.json\n        """"""\n        self._run_pass_json(""y_string_escaped_noncharacter.json"")\n\n    def test_y_string_in_array(self):\n        """"""\n        y_string_in_array.json\n        """"""\n        self._run_pass_json(""y_string_in_array.json"")\n\n    def test_y_string_in_array_with_leading_space(self):\n        """"""\n        y_string_in_array_with_leading_space.json\n        """"""\n        self._run_pass_json(""y_string_in_array_with_leading_space.json"")\n\n    def test_y_string_last_surrogates_1_and_2(self):\n        """"""\n        y_string_last_surrogates_1_and_2.json\n        """"""\n        self._run_pass_json(""y_string_last_surrogates_1_and_2.json"")\n\n    def test_y_string_nbsp_uescaped(self):\n        """"""\n        y_string_nbsp_uescaped.json\n        """"""\n        self._run_pass_json(""y_string_nbsp_uescaped.json"")\n\n    def test_y_string_nonCharacterInUTF_8_U_10FFFF(self):\n        """"""\n        y_string_nonCharacterInUTF-8_U+10FFFF.json\n        """"""\n        self._run_pass_json(""y_string_nonCharacterInUTF-8_U+10FFFF.json"")\n\n    def test_y_string_nonCharacterInUTF_8_U_FFFF(self):\n        """"""\n        y_string_nonCharacterInUTF-8_U+FFFF.json\n        """"""\n        self._run_pass_json(""y_string_nonCharacterInUTF-8_U+FFFF.json"")\n\n    def test_y_string_null_escape(self):\n        """"""\n        y_string_null_escape.json\n        """"""\n        self._run_pass_json(""y_string_null_escape.json"")\n\n    def test_y_string_one_byte_utf_8(self):\n        """"""\n        y_string_one-byte-utf-8.json\n        """"""\n        self._run_pass_json(""y_string_one-byte-utf-8.json"")\n\n    def test_y_string_pi(self):\n        """"""\n        y_string_pi.json\n        """"""\n        self._run_pass_json(""y_string_pi.json"")\n\n    def test_y_string_reservedCharacterInUTF_8_U_1BFFF(self):\n        """"""\n        y_string_reservedCharacterInUTF-8_U+1BFFF.json\n        """"""\n        self._run_pass_json(""y_string_reservedCharacterInUTF-8_U+1BFFF.json"")\n\n    def test_y_string_simple_ascii(self):\n        """"""\n        y_string_simple_ascii.json\n        """"""\n        self._run_pass_json(""y_string_simple_ascii.json"")\n\n    def test_y_string_space(self):\n        """"""\n        y_string_space.json\n        """"""\n        self._run_pass_json(""y_string_space.json"")\n\n    def test_y_string_surrogates_U_1D11E_MUSICAL_SYMBOL_G_CLEF(self):\n        """"""\n        y_string_surrogates_U+1D11E_MUSICAL_SYMBOL_G_CLEF.json\n        """"""\n        self._run_pass_json(""y_string_surrogates_U+1D11E_MUSICAL_SYMBOL_G_CLEF.json"")\n\n    def test_y_string_three_byte_utf_8(self):\n        """"""\n        y_string_three-byte-utf-8.json\n        """"""\n        self._run_pass_json(""y_string_three-byte-utf-8.json"")\n\n    def test_y_string_two_byte_utf_8(self):\n        """"""\n        y_string_two-byte-utf-8.json\n        """"""\n        self._run_pass_json(""y_string_two-byte-utf-8.json"")\n\n    def test_y_string_u_2028_line_sep(self):\n        """"""\n        y_string_u+2028_line_sep.json\n        """"""\n        self._run_pass_json(""y_string_u+2028_line_sep.json"")\n\n    def test_y_string_u_2029_par_sep(self):\n        """"""\n        y_string_u+2029_par_sep.json\n        """"""\n        self._run_pass_json(""y_string_u+2029_par_sep.json"")\n\n    def test_y_string_uEscape(self):\n        """"""\n        y_string_uEscape.json\n        """"""\n        self._run_pass_json(""y_string_uEscape.json"")\n\n    def test_y_string_uescaped_newline(self):\n        """"""\n        y_string_uescaped_newline.json\n        """"""\n        self._run_pass_json(""y_string_uescaped_newline.json"")\n\n    def test_y_string_unescaped_char_delete(self):\n        """"""\n        y_string_unescaped_char_delete.json\n        """"""\n        self._run_pass_json(""y_string_unescaped_char_delete.json"")\n\n    def test_y_string_unicode(self):\n        """"""\n        y_string_unicode.json\n        """"""\n        self._run_pass_json(""y_string_unicode.json"")\n\n    def test_y_string_unicodeEscapedBackslash(self):\n        """"""\n        y_string_unicodeEscapedBackslash.json\n        """"""\n        self._run_pass_json(""y_string_unicodeEscapedBackslash.json"")\n\n    def test_y_string_unicode_2(self):\n        """"""\n        y_string_unicode_2.json\n        """"""\n        self._run_pass_json(""y_string_unicode_2.json"")\n\n    def test_y_string_unicode_U_10FFFE_nonchar(self):\n        """"""\n        y_string_unicode_U+10FFFE_nonchar.json\n        """"""\n        self._run_pass_json(""y_string_unicode_U+10FFFE_nonchar.json"")\n\n    def test_y_string_unicode_U_1FFFE_nonchar(self):\n        """"""\n        y_string_unicode_U+1FFFE_nonchar.json\n        """"""\n        self._run_pass_json(""y_string_unicode_U+1FFFE_nonchar.json"")\n\n    def test_y_string_unicode_U_200B_ZERO_WIDTH_SPACE(self):\n        """"""\n        y_string_unicode_U+200B_ZERO_WIDTH_SPACE.json\n        """"""\n        self._run_pass_json(""y_string_unicode_U+200B_ZERO_WIDTH_SPACE.json"")\n\n    def test_y_string_unicode_U_2064_invisible_plu(self):\n        """"""\n        y_string_unicode_U+2064_invisible_plus.json\n        """"""\n        self._run_pass_json(""y_string_unicode_U+2064_invisible_plus.json"")\n\n    def test_y_string_unicode_U_FDD0_nonchar(self):\n        """"""\n        y_string_unicode_U+FDD0_nonchar.json\n        """"""\n        self._run_pass_json(""y_string_unicode_U+FDD0_nonchar.json"")\n\n    def test_y_string_unicode_U_FFFE_nonchar(self):\n        """"""\n        y_string_unicode_U+FFFE_nonchar.json\n        """"""\n        self._run_pass_json(""y_string_unicode_U+FFFE_nonchar.json"")\n\n    def test_y_string_unicode_escaped_double_quote(self):\n        """"""\n        y_string_unicode_escaped_double_quote.json\n        """"""\n        self._run_pass_json(""y_string_unicode_escaped_double_quote.json"")\n\n    def test_y_string_utf8(self):\n        """"""\n        y_string_utf8.json\n        """"""\n        self._run_pass_json(""y_string_utf8.json"")\n\n    def test_y_string_with_del_character(self):\n        """"""\n        y_string_with_del_character.json\n        """"""\n        self._run_pass_json(""y_string_with_del_character.json"")\n\n    def test_y_structure_lonely_false(self):\n        """"""\n        y_structure_lonely_false.json\n        """"""\n        self._run_pass_json(""y_structure_lonely_false.json"")\n\n    def test_y_structure_lonely_int(self):\n        """"""\n        y_structure_lonely_int.json\n        """"""\n        self._run_pass_json(""y_structure_lonely_int.json"")\n\n    def test_y_structure_lonely_negative_real(self):\n        """"""\n        y_structure_lonely_negative_real.json\n        """"""\n        self._run_pass_json(""y_structure_lonely_negative_real.json"")\n\n    def test_y_structure_lonely_null(self):\n        """"""\n        y_structure_lonely_null.json\n        """"""\n        self._run_pass_json(""y_structure_lonely_null.json"")\n\n    def test_y_structure_lonely_string(self):\n        """"""\n        y_structure_lonely_string.json\n        """"""\n        self._run_pass_json(""y_structure_lonely_string.json"")\n\n    def test_y_structure_lonely_true(self):\n        """"""\n        y_structure_lonely_true.json\n        """"""\n        self._run_pass_json(""y_structure_lonely_true.json"")\n\n    def test_y_structure_string_empty(self):\n        """"""\n        y_structure_string_empty.json\n        """"""\n        self._run_pass_json(""y_structure_string_empty.json"")\n\n    def test_y_structure_trailing_newline(self):\n        """"""\n        y_structure_trailing_newline.json\n        """"""\n        self._run_pass_json(""y_structure_trailing_newline.json"")\n\n    def test_y_structure_true_in_array(self):\n        """"""\n        y_structure_true_in_array.json\n        """"""\n        self._run_pass_json(""y_structure_true_in_array.json"")\n\n    def test_y_structure_whitespace_array(self):\n        """"""\n        y_structure_whitespace_array.json\n        """"""\n        self._run_pass_json(""y_structure_whitespace_array.json"")\n\n    def test_n_array_1_true_without_comma(self):\n        """"""\n        n_array_1_true_without_comma.json\n        """"""\n        self._run_fail_json(""n_array_1_true_without_comma.json"")\n\n    def test_n_array_a_invalid_utf8(self):\n        """"""\n        n_array_a_invalid_utf8.json\n        """"""\n        self._run_fail_json(""n_array_a_invalid_utf8.json"")\n\n    def test_n_array_colon_instead_of_comma(self):\n        """"""\n        n_array_colon_instead_of_comma.json\n        """"""\n        self._run_fail_json(""n_array_colon_instead_of_comma.json"")\n\n    def test_n_array_comma_after_close(self):\n        """"""\n        n_array_comma_after_close.json\n        """"""\n        self._run_fail_json(""n_array_comma_after_close.json"")\n\n    def test_n_array_comma_and_number(self):\n        """"""\n        n_array_comma_and_number.json\n        """"""\n        self._run_fail_json(""n_array_comma_and_number.json"")\n\n    def test_n_array_double_comma(self):\n        """"""\n        n_array_double_comma.json\n        """"""\n        self._run_fail_json(""n_array_double_comma.json"")\n\n    def test_n_array_double_extra_comma(self):\n        """"""\n        n_array_double_extra_comma.json\n        """"""\n        self._run_fail_json(""n_array_double_extra_comma.json"")\n\n    def test_n_array_extra_close(self):\n        """"""\n        n_array_extra_close.json\n        """"""\n        self._run_fail_json(""n_array_extra_close.json"")\n\n    def test_n_array_extra_comma(self):\n        """"""\n        n_array_extra_comma.json\n        """"""\n        self._run_fail_json(""n_array_extra_comma.json"")\n\n    def test_n_array_incomplete(self):\n        """"""\n        n_array_incomplete.json\n        """"""\n        self._run_fail_json(""n_array_incomplete.json"")\n\n    def test_n_array_incomplete_invalid_value(self):\n        """"""\n        n_array_incomplete_invalid_value.json\n        """"""\n        self._run_fail_json(""n_array_incomplete_invalid_value.json"")\n\n    def test_n_array_inner_array_no_comma(self):\n        """"""\n        n_array_inner_array_no_comma.json\n        """"""\n        self._run_fail_json(""n_array_inner_array_no_comma.json"")\n\n    def test_n_array_invalid_utf8(self):\n        """"""\n        n_array_invalid_utf8.json\n        """"""\n        self._run_fail_json(""n_array_invalid_utf8.json"")\n\n    def test_n_array_items_separated_by_semicol(self):\n        """"""\n        n_array_items_separated_by_semicolon.json\n        """"""\n        self._run_fail_json(""n_array_items_separated_by_semicolon.json"")\n\n    def test_n_array_just_comma(self):\n        """"""\n        n_array_just_comma.json\n        """"""\n        self._run_fail_json(""n_array_just_comma.json"")\n\n    def test_n_array_just_minu(self):\n        """"""\n        n_array_just_minus.json\n        """"""\n        self._run_fail_json(""n_array_just_minus.json"")\n\n    def test_n_array_missing_value(self):\n        """"""\n        n_array_missing_value.json\n        """"""\n        self._run_fail_json(""n_array_missing_value.json"")\n\n    def test_n_array_newlines_unclosed(self):\n        """"""\n        n_array_newlines_unclosed.json\n        """"""\n        self._run_fail_json(""n_array_newlines_unclosed.json"")\n\n    def test_n_array_number_and_comma(self):\n        """"""\n        n_array_number_and_comma.json\n        """"""\n        self._run_fail_json(""n_array_number_and_comma.json"")\n\n    def test_n_array_number_and_several_comma(self):\n        """"""\n        n_array_number_and_several_commas.json\n        """"""\n        self._run_fail_json(""n_array_number_and_several_commas.json"")\n\n    def test_n_array_spaces_vertical_tab_formfeed(self):\n        """"""\n        n_array_spaces_vertical_tab_formfeed.json\n        """"""\n        self._run_fail_json(""n_array_spaces_vertical_tab_formfeed.json"")\n\n    def test_n_array_star_inside(self):\n        """"""\n        n_array_star_inside.json\n        """"""\n        self._run_fail_json(""n_array_star_inside.json"")\n\n    def test_n_array_unclosed(self):\n        """"""\n        n_array_unclosed.json\n        """"""\n        self._run_fail_json(""n_array_unclosed.json"")\n\n    def test_n_array_unclosed_trailing_comma(self):\n        """"""\n        n_array_unclosed_trailing_comma.json\n        """"""\n        self._run_fail_json(""n_array_unclosed_trailing_comma.json"")\n\n    def test_n_array_unclosed_with_new_line(self):\n        """"""\n        n_array_unclosed_with_new_lines.json\n        """"""\n        self._run_fail_json(""n_array_unclosed_with_new_lines.json"")\n\n    def test_n_array_unclosed_with_object_inside(self):\n        """"""\n        n_array_unclosed_with_object_inside.json\n        """"""\n        self._run_fail_json(""n_array_unclosed_with_object_inside.json"")\n\n    def test_n_incomplete_false(self):\n        """"""\n        n_incomplete_false.json\n        """"""\n        self._run_fail_json(""n_incomplete_false.json"")\n\n    def test_n_incomplete_null(self):\n        """"""\n        n_incomplete_null.json\n        """"""\n        self._run_fail_json(""n_incomplete_null.json"")\n\n    def test_n_incomplete_true(self):\n        """"""\n        n_incomplete_true.json\n        """"""\n        self._run_fail_json(""n_incomplete_true.json"")\n\n    def test_n_multidigit_number_then_00(self):\n        """"""\n        n_multidigit_number_then_00.json\n        """"""\n        self._run_fail_json(""n_multidigit_number_then_00.json"")\n\n    def test_n_number__(self):\n        """"""\n        n_number_++.json\n        """"""\n        self._run_fail_json(""n_number_++.json"")\n\n    def test_n_number_1(self):\n        """"""\n        n_number_+1.json\n        """"""\n        self._run_fail_json(""n_number_+1.json"")\n\n    def test_n_number_Inf(self):\n        """"""\n        n_number_+Inf.json\n        """"""\n        self._run_fail_json(""n_number_+Inf.json"")\n\n    def test_n_number_01(self):\n        """"""\n        n_number_-01.json\n        """"""\n        self._run_fail_json(""n_number_-01.json"")\n\n    def test_n_number_1_0(self):\n        """"""\n        n_number_-1.0..json\n        """"""\n        self._run_fail_json(""n_number_-1.0..json"")\n\n    def test_n_number_2(self):\n        """"""\n        n_number_-2..json\n        """"""\n        self._run_fail_json(""n_number_-2..json"")\n\n    def test_n_number_negative_NaN(self):\n        """"""\n        n_number_-NaN.json\n        """"""\n        self._run_fail_json(""n_number_-NaN.json"")\n\n    def test_n_number_negative_1(self):\n        """"""\n        n_number_.-1.json\n        """"""\n        self._run_fail_json(""n_number_.-1.json"")\n\n    def test_n_number_2e_3(self):\n        """"""\n        n_number_.2e-3.json\n        """"""\n        self._run_fail_json(""n_number_.2e-3.json"")\n\n    def test_n_number_0_1_2(self):\n        """"""\n        n_number_0.1.2.json\n        """"""\n        self._run_fail_json(""n_number_0.1.2.json"")\n\n    def test_n_number_0_3e_(self):\n        """"""\n        n_number_0.3e+.json\n        """"""\n        self._run_fail_json(""n_number_0.3e+.json"")\n\n    def test_n_number_0_3e(self):\n        """"""\n        n_number_0.3e.json\n        """"""\n        self._run_fail_json(""n_number_0.3e.json"")\n\n    def test_n_number_0_e1(self):\n        """"""\n        n_number_0.e1.json\n        """"""\n        self._run_fail_json(""n_number_0.e1.json"")\n\n    def test_n_number_0_capital_E_(self):\n        """"""\n        n_number_0_capital_E+.json\n        """"""\n        self._run_fail_json(""n_number_0_capital_E+.json"")\n\n    def test_n_number_0_capital_E(self):\n        """"""\n        n_number_0_capital_E.json\n        """"""\n        self._run_fail_json(""n_number_0_capital_E.json"")\n\n    def test_n_number_0e_(self):\n        """"""\n        n_number_0e+.json\n        """"""\n        self._run_fail_json(""n_number_0e+.json"")\n\n    def test_n_number_0e(self):\n        """"""\n        n_number_0e.json\n        """"""\n        self._run_fail_json(""n_number_0e.json"")\n\n    def test_n_number_1_0e_(self):\n        """"""\n        n_number_1.0e+.json\n        """"""\n        self._run_fail_json(""n_number_1.0e+.json"")\n\n    def test_n_number_1_0e_2(self):\n        """"""\n        n_number_1.0e-.json\n        """"""\n        self._run_fail_json(""n_number_1.0e-.json"")\n\n    def test_n_number_1_0e(self):\n        """"""\n        n_number_1.0e.json\n        """"""\n        self._run_fail_json(""n_number_1.0e.json"")\n\n    def test_n_number_1_000(self):\n        """"""\n        n_number_1_000.json\n        """"""\n        self._run_fail_json(""n_number_1_000.json"")\n\n    def test_n_number_1eE2(self):\n        """"""\n        n_number_1eE2.json\n        """"""\n        self._run_fail_json(""n_number_1eE2.json"")\n\n    def test_n_number_2_e_3(self):\n        """"""\n        n_number_2.e+3.json\n        """"""\n        self._run_fail_json(""n_number_2.e+3.json"")\n\n    def test_n_number_2_e_3_2(self):\n        """"""\n        n_number_2.e-3.json\n        """"""\n        self._run_fail_json(""n_number_2.e-3.json"")\n\n    def test_n_number_2_e3_3(self):\n        """"""\n        n_number_2.e3.json\n        """"""\n        self._run_fail_json(""n_number_2.e3.json"")\n\n    def test_n_number_9_e_(self):\n        """"""\n        n_number_9.e+.json\n        """"""\n        self._run_fail_json(""n_number_9.e+.json"")\n\n    def test_n_number_negative_Inf(self):\n        """"""\n        n_number_Inf.json\n        """"""\n        self._run_fail_json(""n_number_Inf.json"")\n\n    def test_n_number_NaN(self):\n        """"""\n        n_number_NaN.json\n        """"""\n        self._run_fail_json(""n_number_NaN.json"")\n\n    def test_n_number_U_FF11_fullwidth_digit_one(self):\n        """"""\n        n_number_U+FF11_fullwidth_digit_one.json\n        """"""\n        self._run_fail_json(""n_number_U+FF11_fullwidth_digit_one.json"")\n\n    def test_n_number_expressi(self):\n        """"""\n        n_number_expression.json\n        """"""\n        self._run_fail_json(""n_number_expression.json"")\n\n    def test_n_number_hex_1_digit(self):\n        """"""\n        n_number_hex_1_digit.json\n        """"""\n        self._run_fail_json(""n_number_hex_1_digit.json"")\n\n    def test_n_number_hex_2_digit(self):\n        """"""\n        n_number_hex_2_digits.json\n        """"""\n        self._run_fail_json(""n_number_hex_2_digits.json"")\n\n    def test_n_number_infinity(self):\n        """"""\n        n_number_infinity.json\n        """"""\n        self._run_fail_json(""n_number_infinity.json"")\n\n    def test_n_number_invalid_(self):\n        """"""\n        n_number_invalid+-.json\n        """"""\n        self._run_fail_json(""n_number_invalid+-.json"")\n\n    def test_n_number_invalid_negative_real(self):\n        """"""\n        n_number_invalid-negative-real.json\n        """"""\n        self._run_fail_json(""n_number_invalid-negative-real.json"")\n\n    def test_n_number_invalid_utf_8_in_bigger_int(self):\n        """"""\n        n_number_invalid-utf-8-in-bigger-int.json\n        """"""\n        self._run_fail_json(""n_number_invalid-utf-8-in-bigger-int.json"")\n\n    def test_n_number_invalid_utf_8_in_exponent(self):\n        """"""\n        n_number_invalid-utf-8-in-exponent.json\n        """"""\n        self._run_fail_json(""n_number_invalid-utf-8-in-exponent.json"")\n\n    def test_n_number_invalid_utf_8_in_int(self):\n        """"""\n        n_number_invalid-utf-8-in-int.json\n        """"""\n        self._run_fail_json(""n_number_invalid-utf-8-in-int.json"")\n\n    def test_n_number_minus_infinity(self):\n        """"""\n        n_number_minus_infinity.json\n        """"""\n        self._run_fail_json(""n_number_minus_infinity.json"")\n\n    def test_n_number_minus_sign_with_trailing_garbage(self):\n        """"""\n        n_number_minus_sign_with_trailing_garbage.json\n        """"""\n        self._run_fail_json(""n_number_minus_sign_with_trailing_garbage.json"")\n\n    def test_n_number_minus_space_1(self):\n        """"""\n        n_number_minus_space_1.json\n        """"""\n        self._run_fail_json(""n_number_minus_space_1.json"")\n\n    def test_n_number_neg_int_starting_with_zer(self):\n        """"""\n        n_number_neg_int_starting_with_zero.json\n        """"""\n        self._run_fail_json(""n_number_neg_int_starting_with_zero.json"")\n\n    def test_n_number_neg_real_without_int_part(self):\n        """"""\n        n_number_neg_real_without_int_part.json\n        """"""\n        self._run_fail_json(""n_number_neg_real_without_int_part.json"")\n\n    def test_n_number_neg_with_garbage_at_end(self):\n        """"""\n        n_number_neg_with_garbage_at_end.json\n        """"""\n        self._run_fail_json(""n_number_neg_with_garbage_at_end.json"")\n\n    def test_n_number_real_garbage_after_e(self):\n        """"""\n        n_number_real_garbage_after_e.json\n        """"""\n        self._run_fail_json(""n_number_real_garbage_after_e.json"")\n\n    def test_n_number_real_with_invalid_utf8_after_e(self):\n        """"""\n        n_number_real_with_invalid_utf8_after_e.json\n        """"""\n        self._run_fail_json(""n_number_real_with_invalid_utf8_after_e.json"")\n\n    def test_n_number_real_without_fractional_part(self):\n        """"""\n        n_number_real_without_fractional_part.json\n        """"""\n        self._run_fail_json(""n_number_real_without_fractional_part.json"")\n\n    def test_n_number_starting_with_dot(self):\n        """"""\n        n_number_starting_with_dot.json\n        """"""\n        self._run_fail_json(""n_number_starting_with_dot.json"")\n\n    def test_n_number_with_alpha(self):\n        """"""\n        n_number_with_alpha.json\n        """"""\n        self._run_fail_json(""n_number_with_alpha.json"")\n\n    def test_n_number_with_alpha_char(self):\n        """"""\n        n_number_with_alpha_char.json\n        """"""\n        self._run_fail_json(""n_number_with_alpha_char.json"")\n\n    def test_n_number_with_leading_zer(self):\n        """"""\n        n_number_with_leading_zero.json\n        """"""\n        self._run_fail_json(""n_number_with_leading_zero.json"")\n\n    def test_n_object_bad_value(self):\n        """"""\n        n_object_bad_value.json\n        """"""\n        self._run_fail_json(""n_object_bad_value.json"")\n\n    def test_n_object_bracket_key(self):\n        """"""\n        n_object_bracket_key.json\n        """"""\n        self._run_fail_json(""n_object_bracket_key.json"")\n\n    def test_n_object_comma_instead_of_col(self):\n        """"""\n        n_object_comma_instead_of_colon.json\n        """"""\n        self._run_fail_json(""n_object_comma_instead_of_colon.json"")\n\n    def test_n_object_double_col(self):\n        """"""\n        n_object_double_colon.json\n        """"""\n        self._run_fail_json(""n_object_double_colon.json"")\n\n    def test_n_object_emoji(self):\n        """"""\n        n_object_emoji.json\n        """"""\n        self._run_fail_json(""n_object_emoji.json"")\n\n    def test_n_object_garbage_at_end(self):\n        """"""\n        n_object_garbage_at_end.json\n        """"""\n        self._run_fail_json(""n_object_garbage_at_end.json"")\n\n    def test_n_object_key_with_single_quote(self):\n        """"""\n        n_object_key_with_single_quotes.json\n        """"""\n        self._run_fail_json(""n_object_key_with_single_quotes.json"")\n\n    def test_n_object_lone_continuation_byte_in_key_and_trailing_comma(self):\n        """"""\n        n_object_lone_continuation_byte_in_key_and_trailing_comma.json\n        """"""\n        self._run_fail_json(\n            ""n_object_lone_continuation_byte_in_key_and_trailing_comma.json""\n        )\n\n    def test_n_object_missing_col(self):\n        """"""\n        n_object_missing_colon.json\n        """"""\n        self._run_fail_json(""n_object_missing_colon.json"")\n\n    def test_n_object_missing_key(self):\n        """"""\n        n_object_missing_key.json\n        """"""\n        self._run_fail_json(""n_object_missing_key.json"")\n\n    def test_n_object_missing_semicol(self):\n        """"""\n        n_object_missing_semicolon.json\n        """"""\n        self._run_fail_json(""n_object_missing_semicolon.json"")\n\n    def test_n_object_missing_value(self):\n        """"""\n        n_object_missing_value.json\n        """"""\n        self._run_fail_json(""n_object_missing_value.json"")\n\n    def test_n_object_no_col(self):\n        """"""\n        n_object_no-colon.json\n        """"""\n        self._run_fail_json(""n_object_no-colon.json"")\n\n    def test_n_object_non_string_key(self):\n        """"""\n        n_object_non_string_key.json\n        """"""\n        self._run_fail_json(""n_object_non_string_key.json"")\n\n    def test_n_object_non_string_key_but_huge_number_instead(self):\n        """"""\n        n_object_non_string_key_but_huge_number_instead.json\n        """"""\n        self._run_fail_json(""n_object_non_string_key_but_huge_number_instead.json"")\n\n    def test_n_object_repeated_null_null(self):\n        """"""\n        n_object_repeated_null_null.json\n        """"""\n        self._run_fail_json(""n_object_repeated_null_null.json"")\n\n    def test_n_object_several_trailing_comma(self):\n        """"""\n        n_object_several_trailing_commas.json\n        """"""\n        self._run_fail_json(""n_object_several_trailing_commas.json"")\n\n    def test_n_object_single_quote(self):\n        """"""\n        n_object_single_quote.json\n        """"""\n        self._run_fail_json(""n_object_single_quote.json"")\n\n    def test_n_object_trailing_comma(self):\n        """"""\n        n_object_trailing_comma.json\n        """"""\n        self._run_fail_json(""n_object_trailing_comma.json"")\n\n    def test_n_object_trailing_comment(self):\n        """"""\n        n_object_trailing_comment.json\n        """"""\n        self._run_fail_json(""n_object_trailing_comment.json"")\n\n    def test_n_object_trailing_comment_ope(self):\n        """"""\n        n_object_trailing_comment_open.json\n        """"""\n        self._run_fail_json(""n_object_trailing_comment_open.json"")\n\n    def test_n_object_trailing_comment_slash_ope(self):\n        """"""\n        n_object_trailing_comment_slash_open.json\n        """"""\n        self._run_fail_json(""n_object_trailing_comment_slash_open.json"")\n\n    def test_n_object_trailing_comment_slash_open_incomplete(self):\n        """"""\n        n_object_trailing_comment_slash_open_incomplete.json\n        """"""\n        self._run_fail_json(""n_object_trailing_comment_slash_open_incomplete.json"")\n\n    def test_n_object_two_commas_in_a_row(self):\n        """"""\n        n_object_two_commas_in_a_row.json\n        """"""\n        self._run_fail_json(""n_object_two_commas_in_a_row.json"")\n\n    def test_n_object_unquoted_key(self):\n        """"""\n        n_object_unquoted_key.json\n        """"""\n        self._run_fail_json(""n_object_unquoted_key.json"")\n\n    def test_n_object_unterminated_value(self):\n        """"""\n        n_object_unterminated-value.json\n        """"""\n        self._run_fail_json(""n_object_unterminated-value.json"")\n\n    def test_n_object_with_single_string(self):\n        """"""\n        n_object_with_single_string.json\n        """"""\n        self._run_fail_json(""n_object_with_single_string.json"")\n\n    def test_n_object_with_trailing_garbage(self):\n        """"""\n        n_object_with_trailing_garbage.json\n        """"""\n        self._run_fail_json(""n_object_with_trailing_garbage.json"")\n\n    def test_n_single_space(self):\n        """"""\n        n_single_space.json\n        """"""\n        self._run_fail_json(""n_single_space.json"")\n\n    def test_n_string_1_surrogate_then_escape(self):\n        """"""\n        n_string_1_surrogate_then_escape.json\n        """"""\n        self._run_fail_json(""n_string_1_surrogate_then_escape.json"")\n\n    def test_n_string_1_surrogate_then_escape_u(self):\n        """"""\n        n_string_1_surrogate_then_escape_u.json\n        """"""\n        self._run_fail_json(""n_string_1_surrogate_then_escape_u.json"")\n\n    def test_n_string_1_surrogate_then_escape_u1(self):\n        """"""\n        n_string_1_surrogate_then_escape_u1.json\n        """"""\n        self._run_fail_json(""n_string_1_surrogate_then_escape_u1.json"")\n\n    def test_n_string_1_surrogate_then_escape_u1x(self):\n        """"""\n        n_string_1_surrogate_then_escape_u1x.json\n        """"""\n        self._run_fail_json(""n_string_1_surrogate_then_escape_u1x.json"")\n\n    def test_n_string_accentuated_char_no_quote(self):\n        """"""\n        n_string_accentuated_char_no_quotes.json\n        """"""\n        self._run_fail_json(""n_string_accentuated_char_no_quotes.json"")\n\n    def test_n_string_backslash_00(self):\n        """"""\n        n_string_backslash_00.json\n        """"""\n        self._run_fail_json(""n_string_backslash_00.json"")\n\n    def test_n_string_escape_x(self):\n        """"""\n        n_string_escape_x.json\n        """"""\n        self._run_fail_json(""n_string_escape_x.json"")\n\n    def test_n_string_escaped_backslash_bad(self):\n        """"""\n        n_string_escaped_backslash_bad.json\n        """"""\n        self._run_fail_json(""n_string_escaped_backslash_bad.json"")\n\n    def test_n_string_escaped_ctrl_char_tab(self):\n        """"""\n        n_string_escaped_ctrl_char_tab.json\n        """"""\n        self._run_fail_json(""n_string_escaped_ctrl_char_tab.json"")\n\n    def test_n_string_escaped_emoji(self):\n        """"""\n        n_string_escaped_emoji.json\n        """"""\n        self._run_fail_json(""n_string_escaped_emoji.json"")\n\n    def test_n_string_incomplete_escape(self):\n        """"""\n        n_string_incomplete_escape.json\n        """"""\n        self._run_fail_json(""n_string_incomplete_escape.json"")\n\n    def test_n_string_incomplete_escaped_character(self):\n        """"""\n        n_string_incomplete_escaped_character.json\n        """"""\n        self._run_fail_json(""n_string_incomplete_escaped_character.json"")\n\n    def test_n_string_incomplete_surrogate(self):\n        """"""\n        n_string_incomplete_surrogate.json\n        """"""\n        self._run_fail_json(""n_string_incomplete_surrogate.json"")\n\n    def test_n_string_incomplete_surrogate_escape_invalid(self):\n        """"""\n        n_string_incomplete_surrogate_escape_invalid.json\n        """"""\n        self._run_fail_json(""n_string_incomplete_surrogate_escape_invalid.json"")\n\n    def test_n_string_invalid_utf_8_in_escape(self):\n        """"""\n        n_string_invalid-utf-8-in-escape.json\n        """"""\n        self._run_fail_json(""n_string_invalid-utf-8-in-escape.json"")\n\n    def test_n_string_invalid_backslash_esc(self):\n        """"""\n        n_string_invalid_backslash_esc.json\n        """"""\n        self._run_fail_json(""n_string_invalid_backslash_esc.json"")\n\n    def test_n_string_invalid_unicode_escape(self):\n        """"""\n        n_string_invalid_unicode_escape.json\n        """"""\n        self._run_fail_json(""n_string_invalid_unicode_escape.json"")\n\n    def test_n_string_invalid_utf8_after_escape(self):\n        """"""\n        n_string_invalid_utf8_after_escape.json\n        """"""\n        self._run_fail_json(""n_string_invalid_utf8_after_escape.json"")\n\n    def test_n_string_leading_uescaped_thinspace(self):\n        """"""\n        n_string_leading_uescaped_thinspace.json\n        """"""\n        self._run_fail_json(""n_string_leading_uescaped_thinspace.json"")\n\n    def test_n_string_no_quotes_with_bad_escape(self):\n        """"""\n        n_string_no_quotes_with_bad_escape.json\n        """"""\n        self._run_fail_json(""n_string_no_quotes_with_bad_escape.json"")\n\n    def test_n_string_single_doublequote(self):\n        """"""\n        n_string_single_doublequote.json\n        """"""\n        self._run_fail_json(""n_string_single_doublequote.json"")\n\n    def test_n_string_single_quote(self):\n        """"""\n        n_string_single_quote.json\n        """"""\n        self._run_fail_json(""n_string_single_quote.json"")\n\n    def test_n_string_single_string_no_double_quote(self):\n        """"""\n        n_string_single_string_no_double_quotes.json\n        """"""\n        self._run_fail_json(""n_string_single_string_no_double_quotes.json"")\n\n    def test_n_string_start_escape_unclosed(self):\n        """"""\n        n_string_start_escape_unclosed.json\n        """"""\n        self._run_fail_json(""n_string_start_escape_unclosed.json"")\n\n    def test_n_string_unescaped_crtl_char(self):\n        """"""\n        n_string_unescaped_crtl_char.json\n        """"""\n        self._run_fail_json(""n_string_unescaped_crtl_char.json"")\n\n    def test_n_string_unescaped_newline(self):\n        """"""\n        n_string_unescaped_newline.json\n        """"""\n        self._run_fail_json(""n_string_unescaped_newline.json"")\n\n    def test_n_string_unescaped_tab(self):\n        """"""\n        n_string_unescaped_tab.json\n        """"""\n        self._run_fail_json(""n_string_unescaped_tab.json"")\n\n    def test_n_string_unicode_CapitalU(self):\n        """"""\n        n_string_unicode_CapitalU.json\n        """"""\n        self._run_fail_json(""n_string_unicode_CapitalU.json"")\n\n    def test_n_string_with_trailing_garbage(self):\n        """"""\n        n_string_with_trailing_garbage.json\n        """"""\n        self._run_fail_json(""n_string_with_trailing_garbage.json"")\n\n    def test_n_structure_100000_opening_array(self):\n        """"""\n        n_structure_100000_opening_arrays.json\n        """"""\n        self._run_fail_json(""n_structure_100000_opening_arrays.json.xz"")\n\n    def test_n_structure_U_2060_word_joined(self):\n        """"""\n        n_structure_U+2060_word_joined.json\n        """"""\n        self._run_fail_json(""n_structure_U+2060_word_joined.json"")\n\n    def test_n_structure_UTF8_BOM_no_data(self):\n        """"""\n        n_structure_UTF8_BOM_no_data.json\n        """"""\n        self._run_fail_json(""n_structure_UTF8_BOM_no_data.json"")\n\n    def test_n_structure_angle_bracket_(self):\n        """"""\n        n_structure_angle_bracket_..json\n        """"""\n        self._run_fail_json(""n_structure_angle_bracket_..json"")\n\n    def test_n_structure_angle_bracket_null(self):\n        """"""\n        n_structure_angle_bracket_null.json\n        """"""\n        self._run_fail_json(""n_structure_angle_bracket_null.json"")\n\n    def test_n_structure_array_trailing_garbage(self):\n        """"""\n        n_structure_array_trailing_garbage.json\n        """"""\n        self._run_fail_json(""n_structure_array_trailing_garbage.json"")\n\n    def test_n_structure_array_with_extra_array_close(self):\n        """"""\n        n_structure_array_with_extra_array_close.json\n        """"""\n        self._run_fail_json(""n_structure_array_with_extra_array_close.json"")\n\n    def test_n_structure_array_with_unclosed_string(self):\n        """"""\n        n_structure_array_with_unclosed_string.json\n        """"""\n        self._run_fail_json(""n_structure_array_with_unclosed_string.json"")\n\n    def test_n_structure_ascii_unicode_identifier(self):\n        """"""\n        n_structure_ascii-unicode-identifier.json\n        """"""\n        self._run_fail_json(""n_structure_ascii-unicode-identifier.json"")\n\n    def test_n_structure_capitalized_True(self):\n        """"""\n        n_structure_capitalized_True.json\n        """"""\n        self._run_fail_json(""n_structure_capitalized_True.json"")\n\n    def test_n_structure_close_unopened_array(self):\n        """"""\n        n_structure_close_unopened_array.json\n        """"""\n        self._run_fail_json(""n_structure_close_unopened_array.json"")\n\n    def test_n_structure_comma_instead_of_closing_brace(self):\n        """"""\n        n_structure_comma_instead_of_closing_brace.json\n        """"""\n        self._run_fail_json(""n_structure_comma_instead_of_closing_brace.json"")\n\n    def test_n_structure_double_array(self):\n        """"""\n        n_structure_double_array.json\n        """"""\n        self._run_fail_json(""n_structure_double_array.json"")\n\n    def test_n_structure_end_array(self):\n        """"""\n        n_structure_end_array.json\n        """"""\n        self._run_fail_json(""n_structure_end_array.json"")\n\n    def test_n_structure_incomplete_UTF8_BOM(self):\n        """"""\n        n_structure_incomplete_UTF8_BOM.json\n        """"""\n        self._run_fail_json(""n_structure_incomplete_UTF8_BOM.json"")\n\n    def test_n_structure_lone_invalid_utf_8(self):\n        """"""\n        n_structure_lone-invalid-utf-8.json\n        """"""\n        self._run_fail_json(""n_structure_lone-invalid-utf-8.json"")\n\n    def test_n_structure_lone_open_bracket(self):\n        """"""\n        n_structure_lone-open-bracket.json\n        """"""\n        self._run_fail_json(""n_structure_lone-open-bracket.json"")\n\n    def test_n_structure_no_data(self):\n        """"""\n        n_structure_no_data.json\n        """"""\n        self._run_fail_json(""n_structure_no_data.json"")\n\n    def test_n_structure_null_byte_outside_string(self):\n        """"""\n        n_structure_null-byte-outside-string.json\n        """"""\n        self._run_fail_json(""n_structure_null-byte-outside-string.json"")\n\n    def test_n_structure_number_with_trailing_garbage(self):\n        """"""\n        n_structure_number_with_trailing_garbage.json\n        """"""\n        self._run_fail_json(""n_structure_number_with_trailing_garbage.json"")\n\n    def test_n_structure_object_followed_by_closing_object(self):\n        """"""\n        n_structure_object_followed_by_closing_object.json\n        """"""\n        self._run_fail_json(""n_structure_object_followed_by_closing_object.json"")\n\n    def test_n_structure_object_unclosed_no_value(self):\n        """"""\n        n_structure_object_unclosed_no_value.json\n        """"""\n        self._run_fail_json(""n_structure_object_unclosed_no_value.json"")\n\n    def test_n_structure_object_with_comment(self):\n        """"""\n        n_structure_object_with_comment.json\n        """"""\n        self._run_fail_json(""n_structure_object_with_comment.json"")\n\n    def test_n_structure_object_with_trailing_garbage(self):\n        """"""\n        n_structure_object_with_trailing_garbage.json\n        """"""\n        self._run_fail_json(""n_structure_object_with_trailing_garbage.json"")\n\n    def test_n_structure_open_array_apostrophe(self):\n        """"""\n        n_structure_open_array_apostrophe.json\n        """"""\n        self._run_fail_json(""n_structure_open_array_apostrophe.json"")\n\n    def test_n_structure_open_array_comma(self):\n        """"""\n        n_structure_open_array_comma.json\n        """"""\n        self._run_fail_json(""n_structure_open_array_comma.json"")\n\n    def test_n_structure_open_array_object(self):\n        """"""\n        n_structure_open_array_object.json\n        """"""\n        self._run_fail_json(""n_structure_open_array_object.json.xz"")\n\n    def test_n_structure_open_array_open_object(self):\n        """"""\n        n_structure_open_array_open_object.json\n        """"""\n        self._run_fail_json(""n_structure_open_array_open_object.json"")\n\n    def test_n_structure_open_array_open_string(self):\n        """"""\n        n_structure_open_array_open_string.json\n        """"""\n        self._run_fail_json(""n_structure_open_array_open_string.json"")\n\n    def test_n_structure_open_array_string(self):\n        """"""\n        n_structure_open_array_string.json\n        """"""\n        self._run_fail_json(""n_structure_open_array_string.json"")\n\n    def test_n_structure_open_object(self):\n        """"""\n        n_structure_open_object.json\n        """"""\n        self._run_fail_json(""n_structure_open_object.json"")\n\n    def test_n_structure_open_object_close_array(self):\n        """"""\n        n_structure_open_object_close_array.json\n        """"""\n        self._run_fail_json(""n_structure_open_object_close_array.json"")\n\n    def test_n_structure_open_object_comma(self):\n        """"""\n        n_structure_open_object_comma.json\n        """"""\n        self._run_fail_json(""n_structure_open_object_comma.json"")\n\n    def test_n_structure_open_object_open_array(self):\n        """"""\n        n_structure_open_object_open_array.json\n        """"""\n        self._run_fail_json(""n_structure_open_object_open_array.json"")\n\n    def test_n_structure_open_object_open_string(self):\n        """"""\n        n_structure_open_object_open_string.json\n        """"""\n        self._run_fail_json(""n_structure_open_object_open_string.json"")\n\n    def test_n_structure_open_object_string_with_apostrophe(self):\n        """"""\n        n_structure_open_object_string_with_apostrophes.json\n        """"""\n        self._run_fail_json(""n_structure_open_object_string_with_apostrophes.json"")\n\n    def test_n_structure_open_ope(self):\n        """"""\n        n_structure_open_open.json\n        """"""\n        self._run_fail_json(""n_structure_open_open.json"")\n\n    def test_n_structure_single_eacute(self):\n        """"""\n        n_structure_single_eacute.json\n        """"""\n        self._run_fail_json(""n_structure_single_eacute.json"")\n\n    def test_n_structure_single_star(self):\n        """"""\n        n_structure_single_star.json\n        """"""\n        self._run_fail_json(""n_structure_single_star.json"")\n\n    def test_n_structure_trailing_(self):\n        """"""\n        n_structure_trailing_#.json\n        """"""\n        self._run_fail_json(""n_structure_trailing_#.json"")\n\n    def test_n_structure_uescaped_LF_before_string(self):\n        """"""\n        n_structure_uescaped_LF_before_string.json\n        """"""\n        self._run_fail_json(""n_structure_uescaped_LF_before_string.json"")\n\n    def test_n_structure_unclosed_array(self):\n        """"""\n        n_structure_unclosed_array.json\n        """"""\n        self._run_fail_json(""n_structure_unclosed_array.json"")\n\n    def test_n_structure_unclosed_array_partial_null(self):\n        """"""\n        n_structure_unclosed_array_partial_null.json\n        """"""\n        self._run_fail_json(""n_structure_unclosed_array_partial_null.json"")\n\n    def test_n_structure_unclosed_array_unfinished_false(self):\n        """"""\n        n_structure_unclosed_array_unfinished_false.json\n        """"""\n        self._run_fail_json(""n_structure_unclosed_array_unfinished_false.json"")\n\n    def test_n_structure_unclosed_array_unfinished_true(self):\n        """"""\n        n_structure_unclosed_array_unfinished_true.json\n        """"""\n        self._run_fail_json(""n_structure_unclosed_array_unfinished_true.json"")\n\n    def test_n_structure_unclosed_object(self):\n        """"""\n        n_structure_unclosed_object.json\n        """"""\n        self._run_fail_json(""n_structure_unclosed_object.json"")\n\n    def test_n_structure_unicode_identifier(self):\n        """"""\n        n_structure_unicode-identifier.json\n        """"""\n        self._run_fail_json(""n_structure_unicode-identifier.json"")\n\n    def test_n_structure_whitespace_U_2060_word_joiner(self):\n        """"""\n        n_structure_whitespace_U+2060_word_joiner.json\n        """"""\n        self._run_fail_json(""n_structure_whitespace_U+2060_word_joiner.json"")\n\n    def test_n_structure_whitespace_formfeed(self):\n        """"""\n        n_structure_whitespace_formfeed.json\n        """"""\n        self._run_fail_json(""n_structure_whitespace_formfeed.json"")\n\n    def test_i_number_double_huge_neg_exp(self):\n        """"""\n        i_number_double_huge_neg_exp.json\n        """"""\n        self._run_pass_json(""i_number_double_huge_neg_exp.json"")\n\n    def test_i_number_huge_exp(self):\n        """"""\n        i_number_huge_exp.json\n        """"""\n        self._run_fail_json(""i_number_huge_exp.json"")\n\n    def test_i_number_neg_int_huge_exp(self):\n        """"""\n        i_number_neg_int_huge_exp.json\n        """"""\n        self._run_fail_json(""i_number_neg_int_huge_exp.json"")\n\n    def test_i_number_pos_double_huge_exp(self):\n        """"""\n        i_number_pos_double_huge_exp.json\n        """"""\n        self._run_fail_json(""i_number_pos_double_huge_exp.json"")\n\n    def test_i_number_real_neg_overflow(self):\n        """"""\n        i_number_real_neg_overflow.json\n        """"""\n        self._run_fail_json(""i_number_real_neg_overflow.json"")\n\n    def test_i_number_real_pos_overflow(self):\n        """"""\n        i_number_real_pos_overflow.json\n        """"""\n        self._run_fail_json(""i_number_real_pos_overflow.json"")\n\n    def test_i_number_real_underflow(self):\n        """"""\n        i_number_real_underflow.json\n        """"""\n        self._run_pass_json(""i_number_real_underflow.json"")\n\n    def test_i_number_too_big_neg_int(self):\n        """"""\n        i_number_too_big_neg_int.json\n        """"""\n        self._run_pass_json(""i_number_too_big_neg_int.json"")\n\n    def test_i_number_too_big_pos_int(self):\n        """"""\n        i_number_too_big_pos_int.json\n        """"""\n        self._run_pass_json(""i_number_too_big_pos_int.json"")\n\n    def test_i_number_very_big_negative_int(self):\n        """"""\n        i_number_very_big_negative_int.json\n        """"""\n        self._run_pass_json(""i_number_very_big_negative_int.json"")\n\n    def test_i_object_key_lone_2nd_surrogate(self):\n        """"""\n        i_object_key_lone_2nd_surrogate.json\n        """"""\n        self._run_fail_json(""i_object_key_lone_2nd_surrogate.json"")\n\n    def test_i_string_1st_surrogate_but_2nd_missing(self):\n        """"""\n        i_string_1st_surrogate_but_2nd_missing.json\n        """"""\n        self._run_fail_json(""i_string_1st_surrogate_but_2nd_missing.json"")\n\n    def test_i_string_1st_valid_surrogate_2nd_invalid(self):\n        """"""\n        i_string_1st_valid_surrogate_2nd_invalid.json\n        """"""\n        self._run_fail_json(""i_string_1st_valid_surrogate_2nd_invalid.json"")\n\n    def test_i_string_UTF_16LE_with_BOM(self):\n        """"""\n        i_string_UTF-16LE_with_BOM.json\n        """"""\n        self._run_fail_json(""i_string_UTF-16LE_with_BOM.json"")\n\n    def test_i_string_UTF_8_invalid_sequence(self):\n        """"""\n        i_string_UTF-8_invalid_sequence.json\n        """"""\n        self._run_fail_json(""i_string_UTF-8_invalid_sequence.json"")\n\n    def test_i_string_UTF8_surrogate_U_D800(self):\n        """"""\n        i_string_UTF8_surrogate_U+D800.json\n        """"""\n        self._run_fail_json(""i_string_UTF8_surrogate_U+D800.json"")\n\n    def test_i_string_incomplete_surrogate_and_escape_valid(self):\n        """"""\n        i_string_incomplete_surrogate_and_escape_valid.json\n        """"""\n        self._run_fail_json(""i_string_incomplete_surrogate_and_escape_valid.json"")\n\n    def test_i_string_incomplete_surrogate_pair(self):\n        """"""\n        i_string_incomplete_surrogate_pair.json\n        """"""\n        self._run_fail_json(""i_string_incomplete_surrogate_pair.json"")\n\n    def test_i_string_incomplete_surrogates_escape_valid(self):\n        """"""\n        i_string_incomplete_surrogates_escape_valid.json\n        """"""\n        self._run_fail_json(""i_string_incomplete_surrogates_escape_valid.json"")\n\n    def test_i_string_invalid_lonely_surrogate(self):\n        """"""\n        i_string_invalid_lonely_surrogate.json\n        """"""\n        self._run_fail_json(""i_string_invalid_lonely_surrogate.json"")\n\n    def test_i_string_invalid_surrogate(self):\n        """"""\n        i_string_invalid_surrogate.json\n        """"""\n        self._run_fail_json(""i_string_invalid_surrogate.json"")\n\n    def test_i_string_invalid_utf_8(self):\n        """"""\n        i_string_invalid_utf-8.json\n        """"""\n        self._run_fail_json(""i_string_invalid_utf-8.json"")\n\n    def test_i_string_inverted_surrogates_U_1D11E(self):\n        """"""\n        i_string_inverted_surrogates_U+1D11E.json\n        """"""\n        self._run_fail_json(""i_string_inverted_surrogates_U+1D11E.json"")\n\n    def test_i_string_iso_latin_1(self):\n        """"""\n        i_string_iso_latin_1.json\n        """"""\n        self._run_fail_json(""i_string_iso_latin_1.json"")\n\n    def test_i_string_lone_second_surrogate(self):\n        """"""\n        i_string_lone_second_surrogate.json\n        """"""\n        self._run_fail_json(""i_string_lone_second_surrogate.json"")\n\n    def test_i_string_lone_utf8_continuation_byte(self):\n        """"""\n        i_string_lone_utf8_continuation_byte.json\n        """"""\n        self._run_fail_json(""i_string_lone_utf8_continuation_byte.json"")\n\n    def test_i_string_not_in_unicode_range(self):\n        """"""\n        i_string_not_in_unicode_range.json\n        """"""\n        self._run_fail_json(""i_string_not_in_unicode_range.json"")\n\n    def test_i_string_overlong_sequence_2_byte(self):\n        """"""\n        i_string_overlong_sequence_2_bytes.json\n        """"""\n        self._run_fail_json(""i_string_overlong_sequence_2_bytes.json"")\n\n    def test_i_string_overlong_sequence_6_byte(self):\n        """"""\n        i_string_overlong_sequence_6_bytes.json\n        """"""\n        self._run_fail_json(""i_string_overlong_sequence_6_bytes.json"")\n\n    def test_i_string_overlong_sequence_6_bytes_null(self):\n        """"""\n        i_string_overlong_sequence_6_bytes_null.json\n        """"""\n        self._run_fail_json(""i_string_overlong_sequence_6_bytes_null.json"")\n\n    def test_i_string_truncated_utf_8(self):\n        """"""\n        i_string_truncated-utf-8.json\n        """"""\n        self._run_fail_json(""i_string_truncated-utf-8.json"")\n\n    def test_i_string_utf16BE_no_BOM(self):\n        """"""\n        i_string_utf16BE_no_BOM.json\n        """"""\n        self._run_fail_json(""i_string_utf16BE_no_BOM.json"")\n\n    def test_i_string_utf16LE_no_BOM(self):\n        """"""\n        i_string_utf16LE_no_BOM.json\n        """"""\n        self._run_fail_json(""i_string_utf16LE_no_BOM.json"")\n\n    def test_i_structure_500_nested_array(self):\n        """"""\n        i_structure_500_nested_arrays.json\n        """"""\n        self._run_fail_json(""i_structure_500_nested_arrays.json.xz"")\n\n    def test_i_structure_UTF_8_BOM_empty_object(self):\n        """"""\n        i_structure_UTF-8_BOM_empty_object.json\n        """"""\n        self._run_fail_json(""i_structure_UTF-8_BOM_empty_object.json"")\n'"
test/test_roundtrip.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport unittest\n\nimport orjson\n\nfrom .util import read_fixture_str\n\n\nclass JsonCheckerTests(unittest.TestCase):\n    def _run_roundtrip_json(self, filename):\n        data = read_fixture_str(filename, ""roundtrip"")\n        self.assertEqual(orjson.dumps(orjson.loads(data)), data.encode(""utf-8""))\n\n    def test_roundtrip001(self):\n        """"""\n        roundtrip001.json\n        """"""\n        self._run_roundtrip_json(""roundtrip01.json"")\n\n    def test_roundtrip002(self):\n        """"""\n        roundtrip002.json\n        """"""\n        self._run_roundtrip_json(""roundtrip02.json"")\n\n    def test_roundtrip003(self):\n        """"""\n        roundtrip003.json\n        """"""\n        self._run_roundtrip_json(""roundtrip03.json"")\n\n    def test_roundtrip004(self):\n        """"""\n        roundtrip004.json\n        """"""\n        self._run_roundtrip_json(""roundtrip04.json"")\n\n    def test_roundtrip005(self):\n        """"""\n        roundtrip005.json\n        """"""\n        self._run_roundtrip_json(""roundtrip05.json"")\n\n    def test_roundtrip006(self):\n        """"""\n        roundtrip006.json\n        """"""\n        self._run_roundtrip_json(""roundtrip06.json"")\n\n    def test_roundtrip007(self):\n        """"""\n        roundtrip007.json\n        """"""\n        self._run_roundtrip_json(""roundtrip07.json"")\n\n    def test_roundtrip008(self):\n        """"""\n        roundtrip008.json\n        """"""\n        self._run_roundtrip_json(""roundtrip08.json"")\n\n    def test_roundtrip009(self):\n        """"""\n        roundtrip009.json\n        """"""\n        self._run_roundtrip_json(""roundtrip09.json"")\n\n    def test_roundtrip010(self):\n        """"""\n        roundtrip010.json\n        """"""\n        self._run_roundtrip_json(""roundtrip10.json"")\n\n    def test_roundtrip011(self):\n        """"""\n        roundtrip011.json\n        """"""\n        self._run_roundtrip_json(""roundtrip11.json"")\n\n    def test_roundtrip012(self):\n        """"""\n        roundtrip012.json\n        """"""\n        self._run_roundtrip_json(""roundtrip12.json"")\n\n    def test_roundtrip013(self):\n        """"""\n        roundtrip013.json\n        """"""\n        self._run_roundtrip_json(""roundtrip13.json"")\n\n    def test_roundtrip014(self):\n        """"""\n        roundtrip014.json\n        """"""\n        self._run_roundtrip_json(""roundtrip14.json"")\n\n    def test_roundtrip015(self):\n        """"""\n        roundtrip015.json\n        """"""\n        self._run_roundtrip_json(""roundtrip15.json"")\n\n    def test_roundtrip016(self):\n        """"""\n        roundtrip016.json\n        """"""\n        self._run_roundtrip_json(""roundtrip16.json"")\n\n    def test_roundtrip017(self):\n        """"""\n        roundtrip017.json\n        """"""\n        self._run_roundtrip_json(""roundtrip17.json"")\n\n    def test_roundtrip018(self):\n        """"""\n        roundtrip018.json\n        """"""\n        self._run_roundtrip_json(""roundtrip18.json"")\n\n    def test_roundtrip019(self):\n        """"""\n        roundtrip019.json\n        """"""\n        self._run_roundtrip_json(""roundtrip19.json"")\n\n    def test_roundtrip020(self):\n        """"""\n        roundtrip020.json\n        """"""\n        self._run_roundtrip_json(""roundtrip20.json"")\n\n    def test_roundtrip021(self):\n        """"""\n        roundtrip021.json\n        """"""\n        self._run_roundtrip_json(""roundtrip21.json"")\n\n    def test_roundtrip022(self):\n        """"""\n        roundtrip022.json\n        """"""\n        self._run_roundtrip_json(""roundtrip22.json"")\n\n    def test_roundtrip023(self):\n        """"""\n        roundtrip023.json\n        """"""\n        self._run_roundtrip_json(""roundtrip23.json"")\n\n    def test_roundtrip024(self):\n        """"""\n        roundtrip024.json\n        """"""\n        self._run_roundtrip_json(""roundtrip24.json"")\n\n    def test_roundtrip025(self):\n        """"""\n        roundtrip025.json\n        """"""\n        self._run_roundtrip_json(""roundtrip25.json"")\n\n    def test_roundtrip026(self):\n        """"""\n        roundtrip026.json\n        """"""\n        self._run_roundtrip_json(""roundtrip26.json"")\n\n    def test_roundtrip027(self):\n        """"""\n        roundtrip027.json\n        """"""\n        self._run_roundtrip_json(""roundtrip27.json"")\n'"
test/test_sort_keys.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport unittest\n\nimport orjson\n\nfrom .util import read_fixture_obj\n\n\nclass DictSortKeysTests(unittest.TestCase):\n    # citm_catalog is already sorted\n    def test_twitter_sorted(self):\n        """"""\n        twitter.json sorted\n        """"""\n        obj = read_fixture_obj(""twitter.json.xz"")\n        self.assertNotEqual(list(obj.keys()), sorted(list(obj.keys())))\n        serialized = orjson.dumps(obj, option=orjson.OPT_SORT_KEYS)\n        val = orjson.loads(serialized)\n        self.assertEqual(list(val.keys()), sorted(list(val.keys())))\n\n    def test_canada_sorted(self):\n        """"""\n        canada.json sorted\n        """"""\n        obj = read_fixture_obj(""canada.json.xz"")\n        self.assertNotEqual(list(obj.keys()), sorted(list(obj.keys())))\n        serialized = orjson.dumps(obj, option=orjson.OPT_SORT_KEYS)\n        val = orjson.loads(serialized)\n        self.assertEqual(list(val.keys()), sorted(list(val.keys())))\n\n    def test_github_sorted(self):\n        """"""\n        github.json sorted\n        """"""\n        obj = read_fixture_obj(""github.json.xz"")\n        for each in obj:\n            self.assertNotEqual(list(each.keys()), sorted(list(each.keys())))\n        serialized = orjson.dumps(obj, option=orjson.OPT_SORT_KEYS)\n        val = orjson.loads(serialized)\n        for each in val:\n            self.assertEqual(list(each.keys()), sorted(list(each.keys())))\n\n    def test_utf8_sorted(self):\n        """"""\n        UTF-8 sorted\n        """"""\n        obj = {""a"": 1, ""\xc3\xa4"": 2, ""A"": 3}\n        self.assertNotEqual(list(obj.keys()), sorted(list(obj.keys())))\n        serialized = orjson.dumps(obj, option=orjson.OPT_SORT_KEYS)\n        val = orjson.loads(serialized)\n        self.assertEqual(list(val.keys()), sorted(list(val.keys())))\n'"
test/test_subclass.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport collections\nimport json\nimport unittest\n\nimport orjson\n\n\nclass SubStr(str):\n    pass\n\n\nclass SubInt(int):\n    pass\n\n\nclass SubDict(dict):\n    pass\n\n\nclass SubList(list):\n    pass\n\n\nclass SubFloat(float):\n    pass\n\n\nclass SubTuple(tuple):\n    pass\n\n\nclass SubclassTests(unittest.TestCase):\n    def test_subclass_str(self):\n        self.assertEqual(\n            orjson.dumps(SubStr(""zxc"")), b\'""zxc""\',\n        )\n\n    def test_subclass_str_invalid(self):\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(SubStr(""\\ud800""))\n\n    def test_subclass_int(self):\n        self.assertEqual(orjson.dumps(SubInt(1)), b""1"")\n\n    def test_subclass_int_64(self):\n        for val in (9223372036854775807, -9223372036854775807):\n            self.assertEqual(orjson.dumps(SubInt(val)), str(val).encode(""utf-8""))\n\n    def test_subclass_int_53(self):\n        for val in (9007199254740992, -9007199254740992):\n            with self.assertRaises(orjson.JSONEncodeError):\n                orjson.dumps(SubInt(val), option=orjson.OPT_STRICT_INTEGER)\n\n    def test_subclass_dict(self):\n        self.assertEqual(\n            orjson.dumps(SubDict({""a"": ""b""})), b\'{""a"":""b""}\',\n        )\n\n    def test_subclass_list(self):\n        self.assertEqual(\n            orjson.dumps(SubList([""a"", ""b""])), b\'[""a"",""b""]\',\n        )\n        ref = [True] * 512\n        self.assertEqual(orjson.loads(orjson.dumps(SubList(ref))), ref)\n\n    def test_subclass_float(self):\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(SubFloat(1.1))\n        self.assertEqual(\n            json.dumps(SubFloat(1.1)), ""1.1"",\n        )\n\n    def test_subclass_tuple(self):\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(SubTuple((1, 2)))\n        self.assertEqual(\n            json.dumps(SubTuple((1, 2))), ""[1, 2]"",\n        )\n\n    def test_namedtuple(self):\n        Point = collections.namedtuple(""Point"", [""x"", ""y""])\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(Point(1, 2))\n\n    def test_subclass_circular_dict(self):\n        obj = SubDict({})\n        obj[""obj""] = obj\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(obj)\n\n    def test_subclass_circular_list(self):\n        obj = SubList([])\n        obj.append(obj)\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(obj)\n\n    def test_subclass_circular_nested(self):\n        obj = SubDict({})\n        obj[""list""] = SubList([{""obj"": obj}])\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(obj)\n\n\nclass SubclassPassthroughTests(unittest.TestCase):\n    def test_subclass_str(self):\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(SubStr(""zxc""), option=orjson.OPT_PASSTHROUGH_SUBCLASS)\n\n    def test_subclass_int(self):\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(SubInt(1), option=orjson.OPT_PASSTHROUGH_SUBCLASS)\n\n    def test_subclass_dict(self):\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(SubDict({""a"": ""b""}), option=orjson.OPT_PASSTHROUGH_SUBCLASS)\n\n    def test_subclass_list(self):\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(SubList([""a"", ""b""]), option=orjson.OPT_PASSTHROUGH_SUBCLASS)\n'"
test/test_transform.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport unittest\n\nimport orjson\n\nfrom .util import read_fixture_bytes\n\n\ndef _read_file(filename):\n    return read_fixture_bytes(filename, ""transform"").strip(b""\\n"").strip(b""\\r"")\n\n\nclass JSONTestSuiteTransformTests(unittest.TestCase):\n    def _pass_transform(self, filename, reference=None):\n        data = _read_file(filename)\n        self.assertEqual(orjson.dumps(orjson.loads(data)), reference or data)\n\n    def _fail_transform(self, filename):\n        data = _read_file(filename)\n        with self.assertRaises(orjson.JSONDecodeError):\n            orjson.loads(data)\n\n    def test_number_1(self):\n        """"""\n        number_1.0.json\n        """"""\n        self._pass_transform(""number_1.0.json"")\n\n    def test_number_1e6(self):\n        """"""\n        number_1e6.json\n        """"""\n        self._pass_transform(""number_1e6.json"", b""[1000000.0]"")\n\n    def test_number_1e_999(self):\n        """"""\n        number_1e-999.json\n        """"""\n        self._pass_transform(""number_1e-999.json"", b""[0.0]"")\n\n    def test_number_10000000000000000999(self):\n        """"""\n        number_10000000000000000999.json\n        """"""\n        # cannot serialize due to range\n        self.assertEqual(\n            orjson.loads(_read_file(""number_10000000000000000999.json"")),\n            [10000000000000000999],\n        )\n\n    def test_number_1000000000000000(self):\n        """"""\n        number_1000000000000000.json\n        """"""\n        self._pass_transform(""number_1000000000000000.json"")\n\n    def test_object_key_nfc_nfd(self):\n        """"""\n        object_key_nfc_nfd.json\n        """"""\n        self._pass_transform(""object_key_nfc_nfd.json"")\n\n    def test_object_key_nfd_nfc(self):\n        """"""\n        object_key_nfd_nfc.json\n        """"""\n        self._pass_transform(""object_key_nfd_nfc.json"")\n\n    def test_object_same_key_different_values(self):\n        """"""\n        object_same_key_different_values.json\n        """"""\n        self._pass_transform(""object_same_key_different_values.json"", b\'{""a"":2}\')\n\n    def test_object_same_key_same_value(self):\n        """"""\n        object_same_key_same_value.json\n        """"""\n        self._pass_transform(""object_same_key_same_value.json"", b\'{""a"":1}\')\n\n    def test_object_same_key_unclear_values(self):\n        """"""\n        object_same_key_unclear_values.json\n        """"""\n        self._pass_transform(""object_same_key_unclear_values.json"", b\'{""a"":0}\')\n\n    def test_string_1_escaped_invalid_codepoint(self):\n        """"""\n        string_1_escaped_invalid_codepoint.json\n        """"""\n        self._fail_transform(""string_1_escaped_invalid_codepoint.json"")\n\n    def test_string_1_invalid_codepoint(self):\n        """"""\n        string_1_invalid_codepoint.json\n        """"""\n        self._fail_transform(""string_1_invalid_codepoint.json"")\n\n    def test_string_2_escaped_invalid_codepoints(self):\n        """"""\n        string_2_escaped_invalid_codepoints.json\n        """"""\n        self._fail_transform(""string_2_escaped_invalid_codepoints.json"")\n\n    def test_string_2_invalid_codepoints(self):\n        """"""\n        string_2_invalid_codepoints.json\n        """"""\n        self._fail_transform(""string_2_invalid_codepoints.json"")\n\n    def test_string_3_escaped_invalid_codepoints(self):\n        """"""\n        string_3_escaped_invalid_codepoints.json\n        """"""\n        self._fail_transform(""string_3_escaped_invalid_codepoints.json"")\n\n    def test_string_3_invalid_codepoints(self):\n        """"""\n        string_3_invalid_codepoints.json\n        """"""\n        self._fail_transform(""string_3_invalid_codepoints.json"")\n\n    def test_string_with_escaped_NULL(self):\n        """"""\n        string_with_escaped_NULL.json\n        """"""\n        self._pass_transform(""string_with_escaped_NULL.json"")\n'"
test/test_type.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport unittest\n\nimport orjson\n\n\nclass TypeTests(unittest.TestCase):\n    def test_fragment(self):\n        """"""\n        orjson.JSONDecodeError on fragments\n        """"""\n        for val in (""n"", ""{"", ""["", ""t""):\n            self.assertRaises(orjson.JSONDecodeError, orjson.loads, val)\n\n    def test_invalid(self):\n        """"""\n        orjson.JSONDecodeError on invalid\n        """"""\n        for val in (\'{""age"", 44}\', ""[31337,]"", ""[,31337]"", ""[]]"", ""[,]""):\n            self.assertRaises(orjson.JSONDecodeError, orjson.loads, val)\n\n    def test_str(self):\n        """"""\n        str\n        """"""\n        for (obj, ref) in ((""blah"", b\'""blah""\'), (""\xe6\x9d\xb1\xe4\xba\xac"", b\'""\\xe6\\x9d\\xb1\\xe4\\xba\\xac""\')):\n            self.assertEqual(orjson.dumps(obj), ref)\n            self.assertEqual(orjson.loads(ref), obj)\n\n    def test_str_replacement(self):\n        """"""\n        str roundtrip \xef\xbf\xbd\n        """"""\n        self.assertEqual(orjson.dumps(""\xef\xbf\xbd""), b\'""\\xef\\xbf\\xbd""\')\n        self.assertEqual(orjson.loads(b\'""\\xef\\xbf\\xbd""\'), ""\xef\xbf\xbd"")\n\n    def test_str_surrogates_loads(self):\n        """"""\n        str unicode surrogates loads()\n        """"""\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, \'""\\ud800""\')\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, \'""\\ud83d\\ude80""\')\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, \'""\\udcff""\')\n        self.assertRaises(\n            orjson.JSONDecodeError, orjson.loads, b\'""\\xed\\xa0\\xbd\\xed\\xba\\x80""\'\n        )  # \\ud83d\\ude80\n\n    def test_str_surrogates_dumps(self):\n        """"""\n        str unicode surrogates dumps()\n        """"""\n        self.assertRaises(orjson.JSONEncodeError, orjson.dumps, ""\\ud800"")\n        self.assertRaises(orjson.JSONEncodeError, orjson.dumps, ""\\ud83d\\ude80"")\n        self.assertRaises(orjson.JSONEncodeError, orjson.dumps, ""\\udcff"")\n        self.assertRaises(orjson.JSONEncodeError, orjson.dumps, {""\\ud83d\\ude80"": None})\n        self.assertRaises(\n            orjson.JSONEncodeError, orjson.dumps, b""\\xed\\xa0\\xbd\\xed\\xba\\x80""\n        )  # \\ud83d\\ude80\n\n    def test_bytes_dumps(self):\n        """"""\n        bytes dumps not supported\n        """"""\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps([b""a""])\n\n    def test_bytes_loads(self):\n        """"""\n        bytes loads\n        """"""\n        self.assertEqual(orjson.loads(b""[]""), [])\n\n    def test_bytearray_loads(self):\n        """"""\n        bytearray loads\n        """"""\n        arr = bytearray()\n        arr.extend(b""[]"")\n        self.assertEqual(orjson.loads(arr), [])\n\n    def test_bool(self):\n        """"""\n        bool\n        """"""\n        for (obj, ref) in ((True, ""true""), (False, ""false"")):\n            self.assertEqual(orjson.dumps(obj), ref.encode(""utf-8""))\n            self.assertEqual(orjson.loads(ref), obj)\n\n    def test_bool_true_array(self):\n        """"""\n        bool true array\n        """"""\n        obj = [True] * 256\n        ref = (""["" + (""true,"" * 255) + ""true]"").encode(""utf-8"")\n        self.assertEqual(orjson.dumps(obj), ref)\n        self.assertEqual(orjson.loads(ref), obj)\n\n    def test_bool_false_array(self):\n        """"""\n        bool false array\n        """"""\n        obj = [False] * 256\n        ref = (""["" + (""false,"" * 255) + ""false]"").encode(""utf-8"")\n        self.assertEqual(orjson.dumps(obj), ref)\n        self.assertEqual(orjson.loads(ref), obj)\n\n    def test_none(self):\n        """"""\n        null\n        """"""\n        obj = None\n        ref = ""null""\n        self.assertEqual(orjson.dumps(obj), ref.encode(""utf-8""))\n        self.assertEqual(orjson.loads(ref), obj)\n\n    def test_null_array(self):\n        """"""\n        null array\n        """"""\n        obj = [None] * 256\n        ref = (""["" + (""null,"" * 255) + ""null]"").encode(""utf-8"")\n        self.assertEqual(orjson.dumps(obj), ref)\n        self.assertEqual(orjson.loads(ref), obj)\n\n    def test_nan_dumps(self):\n        """"""\n        NaN serializes to null\n        """"""\n        self.assertEqual(orjson.dumps(float(""NaN"")), b""null"")\n\n    def test_nan_loads(self):\n        """"""\n        NaN is not valid JSON\n        """"""\n        with self.assertRaises(orjson.JSONDecodeError):\n            orjson.loads(""[NaN]"")\n        with self.assertRaises(orjson.JSONDecodeError):\n            orjson.loads(""[nan]"")\n\n    def test_infinity_dumps(self):\n        """"""\n        Infinity serializes to null\n        """"""\n        self.assertEqual(orjson.dumps(float(""Infinity"")), b""null"")\n\n    def test_infinity_loads(self):\n        """"""\n        Infinity, -Infinity is not valid JSON\n        """"""\n        with self.assertRaises(orjson.JSONDecodeError):\n            orjson.loads(""[infinity]"")\n        with self.assertRaises(orjson.JSONDecodeError):\n            orjson.loads(""[Infinity]"")\n        with self.assertRaises(orjson.JSONDecodeError):\n            orjson.loads(""[-Infinity]"")\n        with self.assertRaises(orjson.JSONDecodeError):\n            orjson.loads(""[-infinity]"")\n\n    def test_int_53(self):\n        """"""\n        int 53-bit\n        """"""\n        for val in (9007199254740991, -9007199254740991):\n            self.assertEqual(orjson.loads(str(val)), val)\n            self.assertEqual(\n                orjson.dumps(val, option=orjson.OPT_STRICT_INTEGER),\n                str(val).encode(""utf-8""),\n            )\n\n    def test_int_53_exc(self):\n        """"""\n        int 53-bit exception on 64-bit\n        """"""\n        for val in (9007199254740992, -9007199254740992):\n            with self.assertRaises(orjson.JSONEncodeError):\n                orjson.dumps(val, option=orjson.OPT_STRICT_INTEGER)\n\n    def test_int_64(self):\n        """"""\n        int 64-bit\n        """"""\n        for val in (9223372036854775807, -9223372036854775807):\n            self.assertEqual(orjson.loads(str(val)), val)\n            self.assertEqual(orjson.dumps(val), str(val).encode(""utf-8""))\n\n    def test_int_128(self):\n        """"""\n        int 128-bit\n\n        These are an OverflowError in ujson, but valid in stdlib json.\n        """"""\n        for val in (9223372036854775809, -9223372036854775809):\n            self.assertRaises(orjson.JSONEncodeError, orjson.dumps, val)\n\n    def test_float(self):\n        """"""\n        float\n        """"""\n        self.assertEqual(-1.1234567893, orjson.loads(""-1.1234567893""))\n        self.assertEqual(-1.234567893, orjson.loads(""-1.234567893""))\n        self.assertEqual(-1.34567893, orjson.loads(""-1.34567893""))\n        self.assertEqual(-1.4567893, orjson.loads(""-1.4567893""))\n        self.assertEqual(-1.567893, orjson.loads(""-1.567893""))\n        self.assertEqual(-1.67893, orjson.loads(""-1.67893""))\n        self.assertEqual(-1.7893, orjson.loads(""-1.7893""))\n        self.assertEqual(-1.893, orjson.loads(""-1.893""))\n        self.assertEqual(-1.3, orjson.loads(""-1.3""))\n\n        self.assertEqual(1.1234567893, orjson.loads(""1.1234567893""))\n        self.assertEqual(1.234567893, orjson.loads(""1.234567893""))\n        self.assertEqual(1.34567893, orjson.loads(""1.34567893""))\n        self.assertEqual(1.4567893, orjson.loads(""1.4567893""))\n        self.assertEqual(1.567893, orjson.loads(""1.567893""))\n        self.assertEqual(1.67893, orjson.loads(""1.67893""))\n        self.assertEqual(1.7893, orjson.loads(""1.7893""))\n        self.assertEqual(1.893, orjson.loads(""1.893""))\n        self.assertEqual(1.3, orjson.loads(""1.3""))\n\n    def test_float_precision_loads(self):\n        """"""\n        float precision loads()\n        """"""\n        self.assertEqual(orjson.loads(""31.245270191439438""), 31.245270191439438)\n        self.assertEqual(orjson.loads(""-31.245270191439438""), -31.245270191439438)\n        self.assertEqual(orjson.loads(""121.48791951161945""), 121.48791951161945)\n        self.assertEqual(orjson.loads(""-121.48791951161945""), -121.48791951161945)\n        self.assertEqual(orjson.loads(""100.78399658203125""), 100.78399658203125)\n        self.assertEqual(orjson.loads(""-100.78399658203125""), -100.78399658203125)\n\n    def test_float_precision_dumps(self):\n        """"""\n        float precision dumps()\n        """"""\n        self.assertEqual(orjson.dumps(31.245270191439438), b""31.245270191439438"")\n        self.assertEqual(orjson.dumps(-31.245270191439438), b""-31.245270191439438"")\n        self.assertEqual(orjson.dumps(121.48791951161945), b""121.48791951161945"")\n        self.assertEqual(orjson.dumps(-121.48791951161945), b""-121.48791951161945"")\n        self.assertEqual(orjson.dumps(100.78399658203125), b""100.78399658203125"")\n        self.assertEqual(orjson.dumps(-100.78399658203125), b""-100.78399658203125"")\n\n    def test_float_edge(self):\n        """"""\n        float edge cases\n        """"""\n        self.assertEqual(orjson.dumps(0.8701), b""0.8701"")\n\n        self.assertEqual(orjson.loads(""0.8701""), 0.8701)\n        self.assertEqual(\n            orjson.loads(""0.0000000000000000000000000000000000000000000000000123e50""),\n            1.23,\n        )\n        self.assertEqual(orjson.loads(""0.4e5""), 40000.0)\n        self.assertEqual(orjson.loads(""0.00e-00""), 0.0)\n        self.assertEqual(orjson.loads(""0.4e-001""), 0.04)\n        self.assertEqual(orjson.loads(""0.123456789e-12""), 1.23456789e-13)\n        self.assertEqual(orjson.loads(""1.234567890E+34""), 1.23456789e34)\n        self.assertEqual(orjson.loads(""23456789012E66""), 2.3456789012e76)\n\n    def test_float_notation(self):\n        """"""\n        float notation\n        """"""\n        for val in (""1.337E40"", ""1.337e+40"", ""1337e40"", ""1.337E-4""):\n            obj = orjson.loads(val)\n            self.assertEqual(obj, float(val))\n            self.assertEqual(orjson.dumps(val), (\'""%s""\' % val).encode(""utf-8""))\n\n    def test_list(self):\n        """"""\n        list\n        """"""\n        obj = [""a"", ""\xf0\x9f\x98\x8a"", True, {""b"": 1.1}, 2]\n        ref = \'[""a"",""\xf0\x9f\x98\x8a"",true,{""b"":1.1},2]\'\n        self.assertEqual(orjson.dumps(obj), ref.encode(""utf-8""))\n        self.assertEqual(orjson.loads(ref), obj)\n\n    def test_tuple(self):\n        """"""\n        tuple\n        """"""\n        obj = (""a"", ""\xf0\x9f\x98\x8a"", True, {""b"": 1.1}, 2)\n        ref = \'[""a"",""\xf0\x9f\x98\x8a"",true,{""b"":1.1},2]\'\n        self.assertEqual(orjson.dumps(obj), ref.encode(""utf-8""))\n        self.assertEqual(orjson.loads(ref), list(obj))\n\n    def test_dict(self):\n        """"""\n        dict\n        """"""\n        obj = {""key"": ""value""}\n        ref = \'{""key"":""value""}\'\n        self.assertEqual(orjson.dumps(obj), ref.encode(""utf-8""))\n        self.assertEqual(orjson.loads(ref), obj)\n\n    def test_dict_duplicate_loads(self):\n        self.assertEqual(orjson.loads(b\'{""1"":true,""1"":false}\'), {""1"": False})\n\n    def test_dict_large(self):\n        """"""\n        dict with >512 keys\n        """"""\n        obj = {""key_%s"" % idx: ""value"" for idx in range(513)}\n        self.assertEqual(len(obj), 513)\n        self.assertEqual(orjson.loads(orjson.dumps(obj)), obj)\n\n    def test_dict_large_keys(self):\n        """"""\n        dict with keys too large to cache\n        """"""\n        obj = {\n            ""keeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeey"": ""value""\n        }\n        ref = \'{""keeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeey"":""value""}\'\n        self.assertEqual(orjson.dumps(obj), ref.encode(""utf-8""))\n        self.assertEqual(orjson.loads(ref), obj)\n\n    def test_dict_unicode(self):\n        """"""\n        dict unicode keys\n        """"""\n        obj = {""\xf0\x9f\x90\x88"": ""value""}\n        ref = b\'{""\\xf0\\x9f\\x90\\x88"":""value""}\'\n        self.assertEqual(orjson.dumps(obj), ref)\n        self.assertEqual(orjson.loads(ref), obj)\n        self.assertEqual(orjson.loads(ref)[""\xf0\x9f\x90\x88""], ""value"")\n\n    def test_dict_invalid_key_dumps(self):\n        """"""\n        dict invalid key dumps()\n        """"""\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps({1: ""value""})\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps({b""key"": ""value""})\n\n    def test_dict_invalid_key_loads(self):\n        """"""\n        dict invalid key loads()\n        """"""\n        with self.assertRaises(orjson.JSONDecodeError):\n            orjson.loads(\'{1:""value""}\')\n        with self.assertRaises(orjson.JSONDecodeError):\n            orjson.loads(\'{{""a"":true}:true}\')\n\n    def test_object(self):\n        """"""\n        object() dumps()\n        """"""\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(object())\n'"
test/test_typeddict.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport unittest\n\nimport orjson\n\ntry:\n    from typing import TypedDict\nexcept ImportError:\n    from typing_extensions import TypedDict\n\n\nclass TypedDictTests(unittest.TestCase):\n    def test_typeddict(self):\n        """"""\n        dumps() TypedDict\n        """"""\n\n        class TypedDict1(TypedDict):\n            a: str\n            b: int\n\n        obj = TypedDict1(a=""a"", b=1)\n        self.assertEqual(orjson.dumps(obj), b\'{""a"":""a"",""b"":1}\')\n'"
test/test_ujson.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\n\nimport json\nimport math\nimport unittest\n\nimport orjson\n\n\nclass UltraJSONTests(unittest.TestCase):\n    def test_doubleLongIssue(self):\n        sut = {""a"": -4342969734183514}\n        encoded = orjson.dumps(sut)\n        decoded = orjson.loads(encoded)\n        self.assertEqual(sut, decoded)\n        encoded = orjson.dumps(sut)\n        decoded = orjson.loads(encoded)\n        self.assertEqual(sut, decoded)\n\n    def test_doubleLongDecimalIssue(self):\n        sut = {""a"": -12345678901234.56789012}\n        encoded = orjson.dumps(sut)\n        decoded = orjson.loads(encoded)\n        self.assertEqual(sut, decoded)\n        encoded = orjson.dumps(sut)\n        decoded = orjson.loads(encoded)\n        self.assertEqual(sut, decoded)\n\n    def test_encodeDecodeLongDecimal(self):\n        sut = {""a"": -528656961.4399388}\n        encoded = orjson.dumps(sut)\n        orjson.loads(encoded)\n\n    def test_decimalDecodeTest(self):\n        sut = {""a"": 4.56}\n        encoded = orjson.dumps(sut)\n        decoded = orjson.loads(encoded)\n        self.assertAlmostEqual(sut[""a""], decoded[""a""])\n\n    def test_encodeDictWithUnicodeKeys(self):\n        input = {\n            ""key1"": ""value1"",\n            ""key1"": ""value1"",\n            ""key1"": ""value1"",\n            ""key1"": ""value1"",\n            ""key1"": ""value1"",\n            ""key1"": ""value1"",\n        }\n        orjson.dumps(input)\n\n        input = {\n            ""\xd8\xa8\xd9\x86"": ""value1"",\n            ""\xd8\xa8\xd9\x86"": ""value1"",\n            ""\xd8\xa8\xd9\x86"": ""value1"",\n            ""\xd8\xa8\xd9\x86"": ""value1"",\n            ""\xd8\xa8\xd9\x86"": ""value1"",\n            ""\xd8\xa8\xd9\x86"": ""value1"",\n            ""\xd8\xa8\xd9\x86"": ""value1"",\n        }\n        orjson.dumps(input)\n\n    def test_encodeDoubleConversion(self):\n        input = math.pi\n        output = orjson.dumps(input)\n        self.assertEqual(round(input, 5), round(orjson.loads(output), 5))\n        self.assertEqual(round(input, 5), round(orjson.loads(output), 5))\n\n    def test_encodeDoubleNegConversion(self):\n        input = -math.pi\n        output = orjson.dumps(input)\n\n        self.assertEqual(round(input, 5), round(orjson.loads(output), 5))\n        self.assertEqual(round(input, 5), round(orjson.loads(output), 5))\n\n    def test_encodeArrayOfNestedArrays(self):\n        input = [[[[]]]] * 20\n        output = orjson.dumps(input)\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(input, orjson.loads(output))\n\n    def test_encodeArrayOfDoubles(self):\n        input = [31337.31337, 31337.31337, 31337.31337, 31337.31337] * 10\n        output = orjson.dumps(input)\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(input, orjson.loads(output))\n\n    def test_encodeStringConversion2(self):\n        input = ""A string \\\\ / \\b \\f \\n \\r \\t""\n        output = orjson.dumps(input)\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(output, b\'""A string \\\\\\\\ / \\\\b \\\\f \\\\n \\\\r \\\\t""\')\n        self.assertEqual(input, orjson.loads(output))\n\n    def test_decodeUnicodeConversion(self):\n        pass\n\n    def test_encodeUnicodeConversion1(self):\n        input = ""R\xc3\xa4ksm\xc3\xb6rg\xc3\xa5s \xd8\xa7\xd8\xb3\xd8\xa7\xd9\x85\xd8\xa9 \xd8\xa8\xd9\x86 \xd9\x85\xd8\xad\xd9\x85\xd8\xaf \xd8\xa8\xd9\x86 \xd8\xb9\xd9\x88\xd8\xb6 \xd8\xa8\xd9\x86 \xd9\x84\xd8\xa7\xd8\xaf\xd9\x86""\n        enc = orjson.dumps(input)\n        dec = orjson.loads(enc)\n        self.assertEqual(enc, orjson.dumps(input))\n        self.assertEqual(dec, orjson.loads(enc))\n\n    def test_encodeControlEscaping(self):\n        input = ""\\x19""\n        enc = orjson.dumps(input)\n        dec = orjson.loads(enc)\n        self.assertEqual(input, dec)\n        self.assertEqual(enc, orjson.dumps(input))\n\n    def test_encodeUnicodeConversion2(self):\n        input = ""\\xe6\\x97\\xa5\\xd1\\x88""\n        enc = orjson.dumps(input)\n        dec = orjson.loads(enc)\n        self.assertEqual(enc, orjson.dumps(input))\n        self.assertEqual(dec, orjson.loads(enc))\n\n    def test_encodeUnicodeSurrogatePair(self):\n        input = ""\\xf0\\x90\\x8d\\x86""\n        enc = orjson.dumps(input)\n        dec = orjson.loads(enc)\n\n        self.assertEqual(enc, orjson.dumps(input))\n        self.assertEqual(dec, orjson.loads(enc))\n\n    def test_encodeUnicode4BytesUTF8(self):\n        input = ""\\xf0\\x91\\x80\\xb0TRAILINGNORMAL""\n        enc = orjson.dumps(input)\n        dec = orjson.loads(enc)\n\n        self.assertEqual(enc, orjson.dumps(input))\n        self.assertEqual(dec, orjson.loads(enc))\n\n    def test_encodeUnicode4BytesUTF8Highest(self):\n        input = ""\\xf3\\xbf\\xbf\\xbfTRAILINGNORMAL""\n        enc = orjson.dumps(input)\n        dec = orjson.loads(enc)\n\n        self.assertEqual(enc, orjson.dumps(input))\n        self.assertEqual(dec, orjson.loads(enc))\n\n    # Characters outside of Basic Multilingual Plane(larger than\n    # 16 bits) are represented as \\UXXXXXXXX in python but should be encoded\n    # as \\uXXXX\\uXXXX in orjson.\n    def testEncodeUnicodeBMP(self):\n        s = ""\\U0001f42e\\U0001f42e\\U0001F42D\\U0001F42D""  # \xf0\x9f\x90\xae\xf0\x9f\x90\xae\xf0\x9f\x90\xad\xf0\x9f\x90\xad\n        orjson.dumps(s)\n        json.dumps(s)\n\n        self.assertEqual(json.loads(json.dumps(s)), s)\n        self.assertEqual(orjson.loads(orjson.dumps(s)), s)\n\n    def testEncodeSymbols(self):\n        s = ""\\u273f\\u2661\\u273f""  # \xe2\x9c\xbf\xe2\x99\xa1\xe2\x9c\xbf\n        encoded = orjson.dumps(s)\n        encoded_json = json.dumps(s)\n\n        decoded = orjson.loads(encoded)\n        self.assertEqual(s, decoded)\n\n        encoded = orjson.dumps(s)\n\n        # json outputs an unicode object\n        encoded_json = json.dumps(s, ensure_ascii=False)\n        self.assertEqual(encoded, encoded_json.encode(""utf-8""))\n        decoded = orjson.loads(encoded)\n        self.assertEqual(s, decoded)\n\n    def test_encodeArrayInArray(self):\n        input = [[[[]]]]\n        output = orjson.dumps(input)\n\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(output, orjson.dumps(input))\n        self.assertEqual(input, orjson.loads(output))\n\n    def test_encodeIntConversion(self):\n        input = 31337\n        output = orjson.dumps(input)\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(output, orjson.dumps(input))\n        self.assertEqual(input, orjson.loads(output))\n\n    def test_encodeIntNegConversion(self):\n        input = -31337\n        output = orjson.dumps(input)\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(output, orjson.dumps(input))\n        self.assertEqual(input, orjson.loads(output))\n\n    def test_encodeLongNegConversion(self):\n        input = -9223372036854775808\n        output = orjson.dumps(input)\n\n        orjson.loads(output)\n        orjson.loads(output)\n\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(output, orjson.dumps(input))\n        self.assertEqual(input, orjson.loads(output))\n\n    def test_encodeListConversion(self):\n        input = [1, 2, 3, 4]\n        output = orjson.dumps(input)\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(input, orjson.loads(output))\n\n    def test_encodeDictConversion(self):\n        input = {""k1"": 1, ""k2"": 2, ""k3"": 3, ""k4"": 4}\n        output = orjson.dumps(input)\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(input, orjson.loads(output))\n\n    def test_encodeNoneConversion(self):\n        input = None\n        output = orjson.dumps(input)\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(output, orjson.dumps(input))\n        self.assertEqual(input, orjson.loads(output))\n\n    def test_encodeTrueConversion(self):\n        input = True\n        output = orjson.dumps(input)\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(output, orjson.dumps(input))\n        self.assertEqual(input, orjson.loads(output))\n\n    def test_encodeFalseConversion(self):\n        input = False\n        output = orjson.dumps(input)\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(output, orjson.dumps(input))\n        self.assertEqual(input, orjson.loads(output))\n\n    def test_encodeToUTF8(self):\n        input = b""\\xe6\\x97\\xa5\\xd1\\x88""\n        input = input.decode(""utf-8"")\n        enc = orjson.dumps(input)\n        dec = orjson.loads(enc)\n        self.assertEqual(enc, orjson.dumps(input))\n        self.assertEqual(dec, orjson.loads(enc))\n\n    def test_decodeFromUnicode(self):\n        input = \'{""obj"": 31337}\'\n        dec1 = orjson.loads(input)\n        dec2 = orjson.loads(str(input))\n        self.assertEqual(dec1, dec2)\n\n    def test_decodeJibberish(self):\n        input = ""fdsa sda v9sa fdsa""\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeBrokenArrayStart(self):\n        input = ""[""\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeBrokenObjectStart(self):\n        input = ""{""\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeBrokenArrayEnd(self):\n        input = ""]""\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeBrokenObjectEnd(self):\n        input = ""}""\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeObjectDepthTooBig(self):\n        input = ""{"" * (1024 * 1024)\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeStringUnterminated(self):\n        input = \'""TESTING\'\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeStringUntermEscapeSequence(self):\n        input = \'""TESTING\\\\""\'\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeStringBadEscape(self):\n        input = \'""TESTING\\\\""\'\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeTrueBroken(self):\n        input = ""tru""\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeFalseBroken(self):\n        input = ""fa""\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeNullBroken(self):\n        input = ""n""\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeBrokenDictKeyTypeLeakTest(self):\n        input = \'{{1337:""""}}\'\n        for _ in range(1000):\n            self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeBrokenDictLeakTest(self):\n        input = \'{{""key"":""}\'\n        for _ in range(1000):\n            self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeBrokenListLeakTest(self):\n        input = ""[[[true""\n        for _ in range(1000):\n            self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeDictWithNoKey(self):\n        input = ""{{{{31337}}}}""\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeDictWithNoColonOrValue(self):\n        input = \'{{{{""key""}}}}\'\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeDictWithNoValue(self):\n        input = \'{{{{""key"":}}}}\'\n        self.assertRaises(orjson.JSONDecodeError, orjson.loads, input)\n\n    def test_decodeNumericIntPos(self):\n        input = ""31337""\n        self.assertEqual(31337, orjson.loads(input))\n\n    def test_decodeNumericIntNeg(self):\n        input = ""-31337""\n        self.assertEqual(-31337, orjson.loads(input))\n\n    def test_encodeNullCharacter(self):\n        input = ""31337 \\x00 1337""\n        output = orjson.dumps(input)\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(output, orjson.dumps(input))\n        self.assertEqual(input, orjson.loads(output))\n\n        input = ""\\x00""\n        output = orjson.dumps(input)\n        self.assertEqual(input, orjson.loads(output))\n        self.assertEqual(output, orjson.dumps(input))\n        self.assertEqual(input, orjson.loads(output))\n\n        self.assertEqual(b\'""  \\\\u0000\\\\r\\\\n ""\', orjson.dumps(""  \\u0000\\r\\n ""))\n\n    def test_decodeNullCharacter(self):\n        input = \'""31337 \\\\u0000 31337""\'\n        self.assertEqual(orjson.loads(input), json.loads(input))\n\n    def test_decodeEscape(self):\n        base = ""\\u00e5"".encode()\n        quote = b\'""\'\n        input = quote + base + quote\n        self.assertEqual(json.loads(input), orjson.loads(input))\n\n    def test_decodeBigEscape(self):\n        for _ in range(10):\n            base = ""\\u00e5"".encode()\n            quote = b\'""\'\n            input = quote + (base * 1024 * 1024 * 2) + quote\n            self.assertEqual(json.loads(input), orjson.loads(input))\n'"
test/test_uuid.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport unittest\nimport uuid\n\nimport orjson\n\n\nclass UUIDTests(unittest.TestCase):\n    def test_uuid_immutable(self):\n        """"""\n        UUID objects are immutable\n        """"""\n        val = uuid.uuid4()\n        with self.assertRaises(TypeError):\n            val.int = 1\n        with self.assertRaises(TypeError):\n            val.int = None\n\n    def test_uuid_int(self):\n        """"""\n        UUID.int is a 128-bit integer\n        """"""\n        val = uuid.UUID(""7202d115-7ff3-4c81-a7c1-2a1f067b1ece"")\n        self.assertIsInstance(val.int, int)\n        self.assertTrue(val.int >= 2 ** 64)\n        self.assertTrue(val.int < 2 ** 128)\n        self.assertEqual(val.int, 151546616840194781678008611711208857294)\n\n    def test_uuid_overflow(self):\n        """"""\n        UUID.int can\'t trigger errors in _PyLong_AsByteArray\n        """"""\n        with self.assertRaises(ValueError):\n            uuid.UUID(int=2 ** 128)\n        with self.assertRaises(ValueError):\n            uuid.UUID(int=-1)\n\n    def test_uuid_subclass(self):\n        """"""\n        UUID subclasses are not serialized\n        """"""\n\n        class AUUID(uuid.UUID):\n            pass\n\n        with self.assertRaises(orjson.JSONEncodeError):\n            orjson.dumps(AUUID(""{12345678-1234-5678-1234-567812345678}""))\n\n    def test_serializes_withopt(self):\n        """"""\n        dumps() accepts deprecated OPT_SERIALIZE_UUID\n        """"""\n        self.assertEqual(\n            orjson.dumps(\n                uuid.UUID(""7202d115-7ff3-4c81-a7c1-2a1f067b1ece""),\n                option=orjson.OPT_SERIALIZE_UUID,\n            ),\n            b\'""7202d115-7ff3-4c81-a7c1-2a1f067b1ece""\',\n        )\n\n    def test_nil_uuid(self):\n        self.assertEqual(\n            orjson.dumps(uuid.UUID(""00000000-0000-0000-0000-000000000000"")),\n            b\'""00000000-0000-0000-0000-000000000000""\',\n        )\n\n    def test_all_ways_to_create_uuid_behave_equivalently(self):\n        # Note that according to the docstring for the uuid.UUID class, all the\n        # forms below are equivalent -- they end up with the same value for\n        # `self.int`, which is all that really matters\n        uuids = [\n            uuid.UUID(""{12345678-1234-5678-1234-567812345678}""),\n            uuid.UUID(""12345678123456781234567812345678""),\n            uuid.UUID(""urn:uuid:12345678-1234-5678-1234-567812345678""),\n            uuid.UUID(bytes=b""\\x12\\x34\\x56\\x78"" * 4),\n            uuid.UUID(\n                bytes_le=b""\\x78\\x56\\x34\\x12\\x34\\x12\\x78\\x56""\n                + b""\\x12\\x34\\x56\\x78\\x12\\x34\\x56\\x78""\n            ),\n            uuid.UUID(fields=(0x12345678, 0x1234, 0x5678, 0x12, 0x34, 0x567812345678)),\n            uuid.UUID(int=0x12345678123456781234567812345678),\n        ]\n        result = orjson.dumps(uuids)\n        canonical_uuids = [\'""%s""\' % str(u) for u in uuids]\n        serialized = (""[%s]"" % "","".join(canonical_uuids)).encode(""utf8"")\n        self.assertEqual(result, serialized)\n\n    def test_serializes_correctly_with_leading_zeroes(self):\n        instance = uuid.UUID(int=0x00345678123456781234567812345678)\n        self.assertEqual(\n            orjson.dumps(instance), (\'""%s""\' % str(instance)).encode(""utf8""),\n        )\n\n    def test_all_uuid_creation_functions_create_serializable_uuids(self):\n        uuids = (\n            uuid.uuid1(),\n            uuid.uuid3(uuid.NAMESPACE_DNS, ""python.org""),\n            uuid.uuid4(),\n            uuid.uuid5(uuid.NAMESPACE_DNS, ""python.org""),\n        )\n        for val in uuids:\n            self.assertEqual(\n                orjson.dumps(val), f\'""{val}""\'.encode(""utf-8""),\n            )\n'"
test/util.py,0,"b'# SPDX-License-Identifier: (Apache-2.0 OR MIT)\n\nimport lzma\nimport os\nfrom pathlib import Path\nfrom typing import Any, Dict\n\nimport orjson\n\ndirname = os.path.join(os.path.dirname(__file__), ""../data"")\n\nSTR_CACHE: Dict[str, str] = {}\n\nOBJ_CACHE: Dict[str, Any] = {}\n\n\ndef read_fixture_bytes(filename, subdir=None):\n    if subdir is None:\n        parts = (dirname, filename)\n    else:\n        parts = (dirname, subdir, filename)\n    path = Path(*parts)\n    if path.suffix == "".xz"":\n        contents = lzma.decompress(path.read_bytes())\n    else:\n        contents = path.read_bytes()\n    return contents\n\n\ndef read_fixture_str(filename, subdir=None):\n    if not filename in STR_CACHE:\n        STR_CACHE[filename] = read_fixture_bytes(filename, subdir).decode(""utf-8"")\n    return STR_CACHE[filename]\n\n\ndef read_fixture_obj(filename):\n    if not filename in OBJ_CACHE:\n        OBJ_CACHE[filename] = orjson.loads(read_fixture_str(filename))\n    return OBJ_CACHE[filename]\n'"
