file_path,api_count,code
columnwise_corrcoef_perf.py,48,"b'# Performance of column-wise correlation coefficient\n#\n# http://stackoverflow.com/questions/19401078/efficient-columnwise-correlation-coefficient-calculation-with-numpy\n#\n# Ilya Kizhvatov, stackoverflow community (see attribution below) \n\nimport numpy as np\n\n### Functions for correlating matrix to a column\n# O - (n,t) array of observations: n traces with t samples each\n# P - column of n predictions\n\n# initial version, copied from my Matlab code\ndef ColumnWiseCorrcoef(O, P):\n    n = P.size\n    DO = O - (np.sum(O, 0) / np.double(n))\n    DP = P - (np.sum(P) / np.double(n))\n    return np.dot(DP, DO) / np.sqrt(np.sum(DO ** 2, 0) * np.sum(DP ** 2))\n\n# the slow naive version using the built-in function\ndef ColumnWiseCorrcoefNaive(O, P):\n    return np.corrcoef(P,O.T)[0,1:O[0].size+1]\n\n# improvement over the initial one from Daniel at stackoverflow.com\n# note that it modifies P  (however, the gain in performance from it appears to be insignificant)\ndef newColumnWiseCorrcoef(O, P):\n    n = P.size\n    DO = O - (np.einsum(\'ij->j\',O) / np.double(n))\n    P -= (np.einsum(\'i->\',P) / np.double(n))\n    tmp = np.einsum(\'ij,ij->j\',DO,DO)\n    tmp *= np.einsum(\'i,i->\',P,P)          #Dot or vdot doesnt really change much.\n    return np.dot(P, DO) / np.sqrt(tmp)\n\n\n### Functions for correlating matrix to a matrix\n# O - (n,t) array of observations: n traces with t samples each\n# P - (n,m) array of n predictions for each of the m candidates\n# C - (optional) pre-allocated (m,t) array for correlation traces of length t for each of the m candidates\n\n# Naively using an outer loop with the function from above, as a reference for comparing performance\ndef loopedNewColumnWiseCorrcoef(O, P, C):\n    for i in range(0,256):\n        C[i] = newColumnWiseCorrcoef(O, P[:,i])\n\n# this one has the naive loop over columns of P internally\ndef AlmightyCorrcoefNaive(O, P, C):\n    (n, t) = O.shape      # n traces of t samples\n    (n_bis, m) = P.shape  # n predictions for each of m candidates\n\n    DO = O - (np.sum(O, 0) / np.double(n)) # compute O - mean(O); note that mean(O) will be appleid row-wise to O\n    DP = P - (np.sum(P, 0) / np.double(n)) # compute P - mean(P)\n\n    for i in np.arange(0, m):\n        tmp = np.sum(DO ** 2, 0)\n        tmp *= np.sum(DP[:,i] ** 2)\n        C[:,i] = np.dot(DP[:,i], DO) / np.sqrt(tmp)\n\n# here the loop is avoided by matrix operations\n# returns (m,t) correaltion matrix of m traces t samples each\ndef AlmightyCorrcoef(O, P):\n    (n, t) = O.shape      # n traces of t samples\n    (n_bis, m) = P.shape  # n predictions for each of m candidates\n\n    DO = O - (np.sum(O, 0) / np.double(n)) # compute O - mean(O)\n    DP = P - (np.sum(P, 0) / np.double(n)) # compute P - mean(P)\n    # note that mean row will be appleid row-wise to original matrices\n\n    cov = np.einsum(""nt,nm->tm"", DO, DP)\n\n    varO = np.sum(DO ** 2, 0)\n    varP = np.sum(DP ** 2, 0)\n    tmp = np.outer(varO, varP)\n\n    return cov / np.sqrt(tmp)\n\n# Here the einsum is applied to speed up the computations\n# O - (n,t) array of n traces with t samples each\n# P - (n,m) array of n predictions for each of the m candidates\n# returns (m,t) correaltion matrix of m traces t samples each\ndef AlmightyCorrcoefEinsum(O, P):\n    (n, t) = O.shape      # n traces of t samples\n    (n_bis, m) = P.shape  # n predictions for each of m candidates\n\n    DO = O - (np.einsum(""nt->t"", O) / np.double(n)) # compute O - mean(O)\n    DP = P - (np.einsum(""nm->m"", P) / np.double(n)) # compute P - mean(P)\n\n    cov = np.einsum(""nm,nt->mt"", DP, DO)\n\n    varP = np.einsum(""nm,nm->m"", DP, DP)\n    varO = np.einsum(""nt,nt->t"", DO, DO)\n    tmp = np.einsum(""m,t->mt"", varP, varO)\n\n    return cov / np.sqrt(tmp)\n\n# same, but with einsum optimization\ndef AlmightyCorrcoefEinsumOptimized(O, P):\n    (n, t) = O.shape      # n traces of t samples\n    (n_bis, m) = P.shape  # n predictions for each of m candidates\n\n    DO = O - (np.einsum(""nt->t"", O, optimize=\'optimal\') / np.double(n)) # compute O - mean(O)\n    DP = P - (np.einsum(""nm->m"", P, optimize=\'optimal\') / np.double(n)) # compute P - mean(P)\n\n    cov = np.einsum(""nm,nt->mt"", DP, DO, optimize=\'optimal\')\n\n    varP = np.einsum(""nm,nm->m"", DP, DP, optimize=\'optimal\')\n    varO = np.einsum(""nt,nt->t"", DO, DO, optimize=\'optimal\')\n    tmp = np.einsum(""m,t->mt"", varP, varO, optimize=\'optimal\')\n\n    return cov / np.sqrt(tmp)\n\n# check computation correctness\ndef testCorrectness():\n    \n    O = np.random.rand(int(1E3), int(1E2))\n    P = np.random.rand(int(1E3), 256)\n\n    C = AlmightyCorrcoefEinsumOptimized(O,P)\n    firstRow = ColumnWiseCorrcoef(O,P[:, 0])\n    secondRow = ColumnWiseCorrcoef(O,P[:,1])\n\n    firstRowOk = np.allclose(C[0], firstRow)\n    secondRowOk = np.allclose(C[1], secondRow)\n\n    if firstRowOk and secondRowOk:\n        print(""Test passed"")\n    else:\n        print(""Test failed"")\n\ndef testCorrectnessBis():\n    \n    O = np.random.rand(int(1E3), int(1E2))\n    P = np.random.rand(int(1E3), 256)\n    C = np.zeros((256, int(1E2)))\n\n    loopedNewColumnWiseCorrcoef(O, P, C)\n    Z = AlmightyCorrcoefEinsumOptimized(O,P)\n\n    if np.allclose(C,Z):\n        print(""Test passed"")\n    else:\n        print(""Test failed"")\n\n\nif __name__ == \'__main__\':\n\n    import timeit\n    import sys\n\n    # system information\n    print(""Python: "" + sys.version)\n    print(""Numpy : "" + np.version.version)\n    np.__config__.show()\n\n    # setup snippet\n    timingSetup = """"""\nimport numpy as np\nfrom __main__ import AlmightyCorrcoefEinsumOptimized\nO = np.random.rand(int(1E5),int(1E3))\nP = np.random.rand(int(1E5), 256)\n""""""\n    # timing\n    print(min(timeit.repeat(""AlmightyCorrcoefEinsumOptimized(O, P)"", setup=timingSetup, repeat=3, number=1)))\n'"
