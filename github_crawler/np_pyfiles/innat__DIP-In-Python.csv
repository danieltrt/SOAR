file_path,api_count,code
Autoencoder Image Compression/Stack autoen compress.py,2,"b'""""""\nImage Data Analysis Using Numpy & OpenCV\nauthor: Mohammed Innat\nemail:  innat1994@gmail.com\nwebsite: https://iphton.github.io/iphton.github.io/\nPlease feel free to use and modify this, but keep the above information. Thanks!\n""""""\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(""MNIST_data"",one_hot=True)\n\n# Parameter\nnum_inputs = 784 # 28*28\nneurons_hid1 = 392\nneurons_hid2 = 196\nneurons_hid3 = neurons_hid1 # Decoder Begins\nnum_outputs = num_inputs\n\nlearning_rate = 0.01\n\n# activation function\nactf = tf.nn.relu\n\n# place holder\nX = tf.placeholder(tf.float32, shape=[None, num_inputs])\n\n# Weights\ninitializer = tf.variance_scaling_initializer()\n\nw1 = tf.Variable(initializer([num_inputs, neurons_hid1]), dtype=tf.float32)\nw2 = tf.Variable(initializer([neurons_hid1, neurons_hid2]), dtype=tf.float32)\nw3 = tf.Variable(initializer([neurons_hid2, neurons_hid3]), dtype=tf.float32)\nw4 = tf.Variable(initializer([neurons_hid3, num_outputs]), dtype=tf.float32)\n\n\n# Biases\nb1 = tf.Variable(tf.zeros(neurons_hid1))\nb2 = tf.Variable(tf.zeros(neurons_hid2))\nb3 = tf.Variable(tf.zeros(neurons_hid3))\nb4 = tf.Variable(tf.zeros(num_outputs))\n\n# Activation Function and Layers\nact_func = tf.nn.relu\n\nhid_layer1 = act_func(tf.matmul(X, w1) + b1)\nhid_layer2 = act_func(tf.matmul(hid_layer1, w2) + b2)\nhid_layer3 = act_func(tf.matmul(hid_layer2, w3) + b3)\noutput_layer = tf.matmul(hid_layer3, w4) + b4\n\n# Loss Function\nloss = tf.reduce_mean(tf.square(output_layer - X))\n\n# Optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate)\ntrain = optimizer.minimize(loss)\n\n# Intialize Variables\ninit = tf.global_variables_initializer()\nsaver = tf.train.Saver()\n\nnum_epochs = 5\nbatch_size = 150\n\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # Epoch == Entire Training Set\n    for epoch in range(num_epochs):\n\n        num_batches = mnist.train.num_examples // batch_size\n\n        # 150 batch size\n        for iteration in range(num_batches):\n\n            X_batch, y_batch = mnist.train.next_batch(batch_size)\n            sess.run(train, feed_dict={X: X_batch})\n\n        training_loss = loss.eval(feed_dict={X: X_batch})\n\n        print(""Epoch {} Complete. Training Loss: {}"".format(epoch,training_loss))\n\n    saver.save(sess, ""./stacked_autoencoder.ckpt"")\n\n# Test Autoencoder output on Test Data\nnum_test_images = 10\n\nwith tf.Session() as sess:\n    saver.restore(sess,""./stacked_autoencoder.ckpt"")\n    results = output_layer.eval(feed_dict={X:mnist.test.images[:num_test_images]})\n\n\n# Compare original images with their reconstructions\nf, a = plt.subplots(2, 10, figsize=(20, 4))\nfor i in range(num_test_images):\n    a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n    a[1][i].imshow(np.reshape(results[i], (28, 28)))\n'"
Basic Intensity Transformation/Gamma Correction.py,0,"b'\r\n""""""\r\nImage Data Analysis Using Numpy & OpenCV\r\nauthor: Mohammed Innat\r\nemail:  innat1994@gmail.com\r\nwebsite: https://iphton.github.io/iphton.github.io/\r\nPlease feel free to use and modify this, but keep the above information. Thanks!\r\n""""""\r\n\r\n\r\n# read details on blog post\r\n\r\nimport imageio\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\npic = imageio.imread(\'<image location>\')\r\ngamma = 2.2\r\noriginal = ((pic/255) ** (1/gamma))\r\n\r\nplt.imshow(original)\r\n'"
Basic Intensity Transformation/Log Transform.py,4,"b'""""""\r\nImage Data Analysis Using Numpy & OpenCV\r\nauthor: Mohammed Innat\r\nemail:  innat1994@gmail.com\r\nwebsite: https://iphton.github.io/iphton.github.io/\r\nPlease feel free to use and modify this, but keep the above information. Thanks!\r\n""""""\r\n\r\n# read details on blog post\r\n\r\nimport imageio\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\npic = imageio.imread(\'<image location>\')\r\ngray = lambda rgb : np.dot(rgb[... , :3] , [0.299 , 0.587, 0.114])\r\ngray = gray(pic)\r\n\r\nmax_ = np.max(gray)\r\n\r\n\'\'\'\r\nlog transform\r\n# s = c*log(1+r)\r\n# r = np.log(1+gray)\r\n# c = (L-1)/log(1+|I_max|)\r\n\r\n\'\'\'\r\ndef log_transform():\r\n    return 255/np.log(1+max_) * np.log(1+gray)\r\n\r\nplt.figure(figsize = (5,5))\r\nplt.imshow(log_transform()[:,300:1500], cmap = plt.get_cmap(name = \'gray\'))\r\n'"
Basic Intensity Transformation/Negative Image.py,0,"b'\r\n""""""\r\nImage Data Analysis Using Numpy & OpenCV\r\nauthor: Mohammed Innat\r\nemail:  innat1994@gmail.com\r\nwebsite: https://iphton.github.io/iphton.github.io/\r\nPlease feel free to use and modify this, but keep the above information. Thanks!\r\n""""""\r\n\r\n# read details on blog post\r\n\r\nimport imageio\r\nimport matplotlib.pyplot as plt\r\n\r\npic = imageio.imread(\'<image location>\')\r\nplt.figure(figsize = (6,6))\r\nplt.imshow(255 - pic);\r\n'"
Convolution/Edge_kernel.py,2,"b'\r\n""""""\r\nImage Data Analysis Using Numpy & OpenCV\r\nauthor: Mohammed Innat\r\nemail:  innat1994@gmail.com\r\nwebsite: https://iphton.github.io/iphton.github.io/\r\nPlease feel free to use and modify this, but keep the above information. Thanks!\r\n""""""\r\n\r\n# importing necessary packages\r\nfrom skimage import color\r\nfrom skimage import exposure\r\nimport numpy as np\r\nimport imageio\r\nimport matplotlib.pyplot as plt\r\nfrom scipy.signal import convolve2d\r\n\r\n# load the image\r\npic = imageio.imread(\'<image location>\')\r\nplt.figure(figsize = (6,6))\r\nplt.imshow(pic);\r\n\r\n# Convert the image to grayscale\r\nimg = color.rgb2gray(pic)\r\n\r\n# outline kernel - used for edge detection\r\nkernel = np.array([[-1,-1,-1],\r\n                   [-1,8,-1],\r\n                   [-1,-1,-1]])\r\n\r\n# we use \'valid\' which means we do not add zero padding to our image\r\nedges = convolve2d(img, kernel, mode = \'valid\')\r\n\r\n\r\n# Adjust the contrast of the filtered image by applying Histogram Equalization\r\nedges_equalized = exposure.equalize_adapthist(edges/np.max(np.abs(edges)),\r\n                                              clip_limit = 0.03)\r\n\r\n# plot the edges_clipped\r\nplt.imshow(edges_equalized, cmap=\'gray\')\r\nplt.axis(\'off\')\r\nplt.show()\r\n'"
Convolution/Gaussain_kernel.py,3,"b'\r\n""""""\r\nImage Data Analysis Using Numpy & OpenCV\r\nauthor: Mohammed Innat\r\nemail:  innat1994@gmail.com\r\nwebsite: https://iphton.github.io/iphton.github.io/\r\nPlease feel free to use and modify this, but keep the above information. Thanks!\r\n""""""\r\n\r\n\r\n# importing necessary packages\r\nfrom skimage import color\r\nfrom skimage import exposure\r\nimport numpy as np\r\nimport imageio\r\nimport matplotlib.pyplot as plt\r\nfrom scipy.signal import convolve2d\r\n\r\n# Convert the image to grayscale\r\npic = imageio.imread(\'<image location>\')\r\nimg = color.rgb2gray(pic)\r\n\r\n# gaussian kernel - used for blurring\r\nkernel = np.array([[1,2,1],\r\n                   [2,4,2],\r\n                   [1,2,1]])\r\nkernel = kernel / np.sum(kernel)\r\n\r\n# we use \'valid\' which means we do not add zero padding to our image\r\nedges = convolve2d(img, kernel, mode = \'valid\')\r\n\r\n\r\n# Adjust the contrast of the filtered image by applying Histogram Equalization\r\nedges_equalized = exposure.equalize_adapthist(edges/np.max(np.abs(edges)),\r\n                                              clip_limit = 0.03)\r\n\r\n# plot the edges_clipped\r\nplt.imshow(edges_equalized, cmap=\'gray\')\r\nplt.axis(\'off\')\r\nplt.show()\r\n'"
Convolution/Image_convolution.py,3,"b'\r\n""""""\r\nImage Data Analysis Using Numpy & OpenCV\r\nauthor: Mohammed Innat\r\nemail:  innat1994@gmail.com\r\nwebsite: https://iphton.github.io/iphton.github.io/\r\nPlease feel free to use and modify this, but keep the above information. Thanks!\r\n""""""\r\n\r\n# importing necessary packages\r\nimport numpy as np\r\nimport imageio\r\nimport matplotlib.pyplot as plt\r\nfrom scipy.signal import convolve2d\r\n\r\n# load the image\r\npic = imageio.imread(\'<image location>\')\r\nplt.figure(figsize = (6,6))\r\nplt.imshow(pic);\r\n\r\n# convolution function\r\ndef Convolution(image, kernel):\r\n    conv_bucket = []\r\n    for d in range(image.ndim):\r\n        conv_channel = convolve2d(image[:,:,d], kernel,\r\n                               mode=""same"", boundary=""symm"")\r\n        conv_bucket.append(conv_channel)\r\n    return np.stack(conv_bucket, axis=2).astype(""uint8"")\r\n\r\n# different size of kernel\r\nkernel_sizes = [9,15,30,60]\r\nfig, axs = plt.subplots(nrows = 1, ncols = len(kernel_sizes), figsize=(15,15));\r\n\r\n# iterate through all the kernel and convoluted image\r\nfor k, ax in zip(kernel_sizes, axs):\r\n    kernel = np.ones((k,k))\r\n    kernel /= np.sum(kernel)\r\n    ax.imshow(Convolution(pic, kernel));\r\n    ax.set_title(""Convolved By Kernel: {}"".format(k));\r\n    ax.set_axis_off();\r\n'"
Convolution/Image_gradient_using_sobel_operator.py,4,"b'\r\n""""""\r\nImage Data Analysis Using Numpy & OpenCV\r\nauthor: Mohammed Innat\r\nemail:  innat1994@gmail.com\r\nwebsite: https://iphton.github.io/iphton.github.io/\r\nPlease feel free to use and modify this, but keep the above information. Thanks!\r\n""""""\r\n\r\n\r\n# importing necessary packages\r\nfrom skimage import color\r\nfrom skimage import exposure\r\nimport numpy as np\r\nimport imageio\r\nimport matplotlib.pyplot as plt\r\nfrom scipy.signal import convolve2d\r\n\r\n# right sobel\r\nsobel_x = np.c_[\r\n    [-1,0,1],\r\n    [-2,0,2],\r\n    [-1,0,1]\r\n]\r\n\r\n# top sobel\r\nsobel_y = np.c_[\r\n    [1,2,1],\r\n    [0,0,0],\r\n    [-1,-2,-1]\r\n]\r\n\r\nims = []\r\nfor i in range(3):\r\n    sx = convolve2d(pic[:,:,i], sobel_x, mode=""same"", boundary=""symm"")\r\n    sy = convolve2d(pic[:,:,i], sobel_y, mode=""same"", boundary=""symm"")\r\n    ims.append(np.sqrt(sx*sx + sy*sy))\r\n\r\nimg_conv = np.stack(ims, axis=2).astype(""uint8"")\r\n\r\nplt.figure(figsize = (6,5))\r\nplt.axis(\'off\')\r\nplt.imshow(img_conv);\r\n'"
Convolution/Median_filtering_gradient_finding_operations_combined.py,5,"b'\r\n""""""\r\nImage Data Analysis Using Numpy & OpenCV\r\nauthor: Mohammed Innat\r\nemail:  innat1994@gmail.com\r\nwebsite: https://iphton.github.io/iphton.github.io/\r\nPlease feel free to use and modify this, but keep the above information. Thanks!\r\n""""""\r\n\r\n# importing necessary packages\r\nfrom skimage import color\r\nfrom skimage import exposure\r\nimport numpy as np\r\nimport imageio\r\nimport matplotlib.pyplot as plt\r\nfrom scipy.signal import convolve2d\r\nfrom scipy.ndimage import median_filter\r\n\r\ndef median_filter_(img, mask):\r\n    """"""\r\n    Applies a median filer to all channels\r\n    """"""\r\n    ims = []\r\n    for d in range(3):\r\n        img_conv_d = median_filter(img[:,:,d], size=(mask,mask))\r\n        ims.append(img_conv_d)\r\n\r\n    return np.stack(ims, axis=2).astype(""uint8"")\r\n\r\npic = imageio.imread(\'<image location>\')\r\nfiltered_img = median_filter_(pic, 80)\r\n\r\n# right sobel\r\nsobel_x = np.c_[\r\n    [-1,0,1],\r\n    [-2,0,2],\r\n    [-1,0,1]\r\n]\r\n\r\n# top sobel\r\nsobel_y = np.c_[\r\n    [1,2,1],\r\n    [0,0,0],\r\n    [-1,-2,-1]\r\n]\r\n\r\nims = []\r\nfor d in range(3):\r\n    sx = convolve2d(filtered_img[:,:,d], sobel_x, mode=""same"", boundary=""symm"")\r\n    sy = convolve2d(filtered_img[:,:,d], sobel_y, mode=""same"", boundary=""symm"")\r\n    ims.append(np.sqrt(sx*sx + sy*sy))\r\n\r\nimg_conv = np.stack(ims, axis=2).astype(""uint8"")\r\n\r\nplt.figure(figsize=(7,7))\r\nplt.axis(\'off\')\r\nplt.imshow(img_conv);\r\n'"
Convolution/Sharpen_edge_KernelCombined.py,4,"b'\r\n""""""\r\nImage Data Analysis Using Numpy & OpenCV\r\nauthor: Mohammed Innat\r\nemail:  innat1994@gmail.com\r\nwebsite: https://iphton.github.io/iphton.github.io/\r\nPlease feel free to use and modify this, but keep the above information. Thanks!\r\n""""""\r\n\r\n#importing necessary packages\r\nfrom skimage import color\r\nfrom skimage import exposure\r\nimport numpy as np\r\nimport imageio\r\nimport matplotlib.pyplot as plt\r\nfrom scipy.signal import convolve2d\r\n\r\npic = imageio.imread(\'<image location>\')\r\n# Convert the image to grayscale\r\nimg = color.rgb2gray(img)\r\n\r\n# apply sharpen filter to the original image\r\nsharpen_kernel = np.array([[0,-1,0],\r\n                           [-1,5,-1],\r\n                           [0,-1,0]])\r\nimage_sharpen = convolve2d(img, sharpen_kernel, mode = \'valid\')\r\n\r\n# apply edge kernel to the output of the sharpen kernel\r\nedge_kernel = np.array([[-1,-1,-1],\r\n                        [-1,8,-1],\r\n                        [-1,-1,-1]])\r\nedges = convolve2d(image_sharpen, edge_kernel, mode = \'valid\')\r\n\r\n# apply normalize box blur filter to the edge detection filtered image\r\nblur_kernel = np.array([[1,1,1],\r\n                        [1,1,1],\r\n                        [1,1,1]])/9.0;\r\ndenoised = convolve2d(edges, blur_kernel, mode = \'valid\')\r\n\r\n# Adjust the contrast of the filtered image by applying Histogram Equalization\r\ndenoised_equalized = exposure.equalize_adapthist(denoised/np.max(np.abs(denoised)),\r\n                                                 clip_limit=0.03)\r\nplt.imshow(denoised_equalized, cmap=\'gray\')    # plot the denoised_clipped\r\nplt.axis(\'off\')\r\nplt.show()\r\n'"
Scripts/Greyscale_Image.py,2,"b'\n""""""\nImage Data Analysis Using Numpy & OpenCV\n\nauthor: Mohammed Innat\nemail:  innat1994@gmail.com\nwebsite: https://iphton.github.io/iphton.github.io/\nPlease feel free to use and modify this, but keep the above information. Thanks!\n""""""\n\nimport imageio\nimport numpy as np\nimport matplotlib.pyplot as plt\n\npic = imageio.imread(\'F:/demo_2.jpg\')\n\ngray = lambda rgb : np.dot(rgb[... , :3] , [0.299 , 0.587, 0.114]) \ngray = gray(pic)  \n\nplt.figure( figsize = (10,10))\nplt.imshow(gray, cmap = plt.get_cmap(name = \'gray\'))\nplt.show()\n\n\'\'\'\nHowever, the GIMP converting color to grayscale image software \nhas three algorithms to do the task.\n\nLightness The graylevel will be calculated as\n\nLightness = \xc2\xbd \xc3\x97 (max(R,G,B) + min(R,G,B))\n\nLuminosity The graylevel will be calculated as\n\nLuminosity = 0.21 \xc3\x97 R + 0.72 \xc3\x97 G + 0.07 \xc3\x97 B\n\nAverage The graylevel will be calculated as\n\nAverage Brightness = (R + G + B) \xc3\xb7 3\n\n\'\'\'\n\npic = imageio.imread(\'F:/demo_2.jpg\')\n\ngray = lambda rgb : np.dot(rgb[... , :3] , [0.21 , 0.72, 0.07]) \ngray = gray(pic)  \n\nplt.figure( figsize = (10,10))\nplt.imshow(gray, cmap = plt.get_cmap(name = \'gray\'))\nplt.show()\n\n\'\'\'\nLet\'s take a quick overview some the changed properties now the color image.\nLike we observe some properties of color image, same statements are applying \nnow for gray scaled image.\n\'\'\'\n\nprint(\'Type of the image : \' , type(gray))\nprint()\nprint(\'Shape of the image : {}\'.format(gray.shape))\nprint(\'Image Hight {}\'.format(gray.shape[0]))\nprint(\'Image Width {}\'.format(gray.shape[1]))\nprint(\'Dimension of Image {}\'.format(gray.ndim))\nprint()\nprint(\'Image size {}\'.format(gray.size))\nprint(\'Maximum RGB value in this image {}\'.format(gray.max()))\nprint(\'Minimum RGB value in this image {}\'.format(gray.min()))\nprint(\'Random indexes [X,Y] : {}\'.format(gray[100, 50]))\n'"
Scripts/Masking_Imaging.py,2,"b'\n""""""\nImage Data Analysis Using Numpy & OpenCV\n\nauthor: Mohammed Innat\nemail:  innat1994@gmail.com\nwebsite: https://iphton.github.io/iphton.github.io/\nPlease feel free to use and modify this, but keep the above information. Thanks!\n""""""\n\nimport imageio\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nif __name__ == \'__main__\':\n    \n    # load the image\n    pic = imageio.imread(\'F:/demo_1.jpg\')\n    \n    # seperate the row and column values\n    total_row , total_col , layers = pic.shape\n    \n    \'\'\'\n    Create vector.\n    \n    Ogrid is a compact method of creating a multidimensional-\n    ndarray operations in single lines.\n    for ex:\n    \n    >>> ogrid[0:5,0:5]\n    output: [array([[0],\n                    [1],\n                    [2],\n                    [3],\n                    [4]]), \n            array([[0, 1, 2, 3, 4]])]\n            \n    \'\'\'\n    x , y = np.ogrid[:total_row , :total_col]\n\n    # get the center values of the image\n    cen_x , cen_y = total_row/2 , total_col/2\n    \n    \n    \'\'\'\n    Measure distance value from center to each border pixel.\n    To make it easy, we can think it\'s like, we draw a line from center-\n    to each edge pixel value --> s**2 = (Y-y)**2 + (X-x)**2 \n    \'\'\'\n    distance_from_the_center = np.sqrt((x-cen_x)**2 + (y-cen_y)**2)\n\n    # Select convenient radius value\n    radius = (total_row/2)\n\n    # Using logical operator \'>\' \n    \'\'\'\n    logical operator to do this task which will return as a value \n    of True for all the index according to the given condition\n    \'\'\'\n    circular_pic = distance_from_the_center > radius\n\n    \'\'\'\n    let assign value zero for all pixel value that outside the cirular disc.\n    All the pixel value outside the circular disc, will be black now.\n    \'\'\'\n    pic[circular_pic] = 0\n    plt.figure(figsize = (10,10))\n    plt.imshow(pic) \n    plt.show()'"
Scripts/Splitting Layers.py,1,"b'\n""""""\nImage Data Analysis Using Numpy & OpenCV\n\nauthor: Mohammed Innat\nemail:  innat1994@gmail.com\nwebsite: https://iphton.github.io/iphton.github.io/\nPlease feel free to use and modify this, but keep the above information. Thanks!\n""""""\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\npic = imageio.imread(\'F:/demo_2.jpg\')\n\nfig, ax = plt.subplots(nrows = 1, ncols=3, figsize=(15,5))\n\nfor c, ax in zip(range(3), ax):\n    \n    # create zero matrix\n    split_img = np.zeros(pic.shape, dtype=""uint8"") # \'dtype\' by default: \'numpy.float64\'\n    \n    # assing each channel \n    split_img[ :, :, c] = pic[ :, :, c]\n    \n    # display each channel\n    ax.imshow(split_img)'"
Scripts/logical_operator_image_processing.py,0,"b'\n""""""\nImage Data Analysis Using Numpy & OpenCV\n\nauthor: Mohammed Innat\nemail:  innat1994@gmail.com\nwebsite: https://iphton.github.io/iphton.github.io/\nPlease feel free to use and modify this, but keep the above information. Thanks!\n""""""\n\nimport imageio\nimport numpy as np\nimport matplotlib.pyplot as plt\n\npic = imageio.imread(\'F:/demo_1.jpg\')\nplt.figure(figsize = (10,10))\nplt.imshow(pic)\nplt.show()\n\n\nlow_pixel = pic < 20\n\n# to ensure of it let\'s check if all values in low_pixel are True or not\nif low_pixel.any() == True:\n    print(low_pixel.shape)\n\n\nprint(pic.shape)\nprint(low_pixel.shape)  \n\n\'\'\'\nWe generated that low value filter using a global  comparison operator for \nall the values less than 200. However, we can use this low_pixel array as an index \nto set those low values to some specific values which  may be higher than or lower \nthan the previous pixel value.\n\'\'\'\n\n# randomly choose a value \nimport random\n\n# load the orginal image\npic = imageio.imread(\'F:/demo_1.jpg\')\n\n# set value randomly range from 25 to 225 - these value also randomly choosen\npic[low_pixel] = random.randint(25,225)\n\n# display the image\nplt.figure( figsize = (10,10))\nplt.imshow(pic)\nplt.show()'"
Scripts/observe_image_properties.py,0,"b'\n""""""\nImage Data Analysis Using Numpy & OpenCV\n\nauthor: Mohammed Innat\nemail:  innat1994@gmail.com\nwebsite: https://iphton.github.io/iphton.github.io/\nPlease feel free to use and modify this, but keep the above information. Thanks!\n""""""\n\n\n\n# Importing Image\nif __name__ == \'__main__\':\n    import imageio\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n\n    pic = imageio.imread(\'F:/demo_2.jpg\')\n    plt.figure(figsize = (15,15))\n\n    plt.imshow(pic)\n\n    print(\'Type of the image : \' , type(pic))\n\tprint()\n\tprint(\'Shape of the image : {}\'.format(pic.shape))\n\tprint(\'Image Hight {}\'.format(pic.shape[0]))\n\tprint(\'Image Width {}\'.format(pic.shape[1]))\n\tprint(\'Dimension of Image {}\'.format(pic.ndim))\n\n\tprint(\'Image size {}\'.format(pic.size))\n\n\tprint(\'Maximum RGB value in this image {}\'.format(pic.max()))\n\tprint(\'Minimum RGB value in this image {}\'.format(pic.min()))\n\n\'\'\'\nLet\'s pick a specific pixel located at 100 th Rows and 50 th Column. \nAnd view the RGB value gradually. \n\'\'\'\n\tpic[ 100, 50 ]\n\n\t# A specific pixel located at Row : 100 ; Column : 50 \n    # Each channel\'s value of it, gradually R , G , B\n\tprint(\'Value of only R channel {}\'.format(pic[ 100, 50, 0]))\n\tprint(\'Value of only G channel {}\'.format(pic[ 100, 50, 1]))\n\tprint(\'Value of only B channel {}\'.format(pic[ 100, 50, 2]))\n\n    # let\'s take a quick view of each channels in the whole image.\n\n\tplt.title(\'R channel\')\n\tplt.ylabel(\'Height {}\'.format(pic.shape[0]))\n\tplt.xlabel(\'Width {}\'.format(pic.shape[1]))\n\n\tplt.imshow(pic[ : , : , 0])\n\tplt.show()\n\n\tplt.title(\'G channel\')\n\tplt.ylabel(\'Height {}\'.format(pic.shape[0]))\n\tplt.xlabel(\'Width {}\'.format(pic.shape[1]))\n\n\tplt.imshow(pic[ : , : , 1])\n\tplt.show()\n\n\tplt.title(\'B channel\')\n\tplt.ylabel(\'Height {}\'.format(pic.shape[0]))\n\tplt.xlabel(\'Width {}\'.format(pic.shape[1]))\n\n\tplt.imshow(pic[ : , : , 2])\n\tplt.show()\n\n\n\n# ------------------------------------------------------\n\n\'\'\'\n\nNow, here we can also able to change the number of RGB values. As an example, let\'s set the Red, Green, Blue layer for following Rows values to full intensity.\n\nR channel: Row- 50 to 150\nG channel: Row- 200 to 300\nB channel: Row- 350 to 450\nWe\'ll load the image once, so that we can visualize each change simultaneously.\n\n\'\'\'\n\npic = imageio.imread(\'F:/demo_2.jpg\')\n\npic[50:150 , : , 0] = 255 # full intensity to those pixel\'s R channel\nplt.figure( figsize = (10,10))\nplt.imshow(pic)\nplt.show()\n\n\npic[200:300 , : , 1] = 255 # full intensity to those pixel\'s G channel\nplt.figure( figsize = (10,10))\nplt.imshow(pic)\nplt.show()\n\npic[350:450 , : , 2] = 255 # full intensity to those pixel\'s B channel\nplt.figure( figsize = (10,10))\nplt.imshow(pic)\nplt.show()\n\n# To make it more clear let\'s change the column section and this time \n# we\'ll change the RGB channel simultaneously\n\n# set value 200 of all channels to those pixels which turns them to white\npic[ 50:450 , 400:600 , [0,1,2] ] = 200 \nplt.figure( figsize = (10,10))\nplt.imshow(pic)\nplt.show()\n\n\n\n\n'"
Scripts/satellite_img_processing.py,1,"b'\n""""""\nImage Data Analysis Using Numpy & OpenCV\n\nauthor: Mohammed Innat\nemail:  innat1994@gmail.com\nwebsite: https://iphton.github.io/iphton.github.io/\nPlease feel free to use and modify this, but keep the above information. Thanks!\n""""""\n\nimport imageio\nimport numpy as np\nimport matplotlib.pyplot as plt\n\npic = imageio.imread(\'F:\\satimg.jpg\')\nplt.figure(figsize = (10,10))\nplt.imshow(pic)\nplt.show()\n\nprint(f\'Shape of the image {pic.shape}\')\nprint(f\'hieght {pic.shape[0]} pixels\')\nprint(f\'width {pic.shape[1]} pixels\')\n\n# Detecting High Pixel of Each Channel\n\n# Only Red Pixel value , higher than 180\npic = imageio.imread(\'F:\\satimg.jpg\')\nred_mask = pic[:, :, 0] < 180\n\npic[red_mask] = 0\nplt.figure(figsize=(15,15))\nplt.imshow(pic)\n\n\n# Only Green Pixel value , higher than 180\npic = imageio.imread(\'F:\\satimg.jpg\')\ngreen_mask = pic[:, :, 1] < 180\n\npic[green_mask] = 0\nplt.figure(figsize=(15,15))\nplt.imshow(pic)\n\n\n# Only Blue Pixel value , higher than 180\npic = imageio.imread(\'F:\\satimg.jpg\')\nblue_mask = pic[:, :, 2] < 180\n\npic[blue_mask] = 0\nplt.figure(figsize=(15,15))\nplt.imshow(pic)\n\n# Composite mask using logical_and\npic = imageio.imread(\'F:\\satimg.jpg\')\nfinal_mask = np.logical_and(red_mask, green_mask, blue_mask)\npic[final_mask] = 40\nplt.figure(figsize=(15,15))\nplt.imshow(pic)'"
Vectorization/Contour_tracking.py,1,"b'\r\n""""""\r\nImage Data Analysis Using Numpy & OpenCV\r\nauthor: Mohammed Innat\r\nemail:  innat1994@gmail.com\r\nwebsite: https://iphton.github.io/iphton.github.io/\r\nPlease feel free to use and modify this, but keep the above information. Thanks!\r\n""""""\r\n\r\n\r\n\'\'\'\r\nWe can use a contour tracing algorithm from Scikit-Image to extract the\r\npaths around the object. This controls how accurately the path follows the\r\noriginal bitmap shape.\r\n\'\'\'\r\n\r\nfrom sklearn.cluster import KMeans\r\nimport matplotlib.pyplot as plt\r\nfrom skimage import measure\r\nimport numpy as np\r\nimport imageio\r\nimport warnings\r\nimport matplotlib.cbook\r\nwarnings.filterwarnings(""ignore"",category=matplotlib.cbook.mplDeprecation)\r\n\r\npic = imageio.imread(\'<image location>\')\r\n\r\nh,w = pic.shape[:2]\r\n\r\nim_small_long = pic.reshape((h * w, 3))\r\nim_small_wide = im_small_long.reshape((h,w,3))\r\n\r\nkm = KMeans(n_clusters=2)\r\nkm.fit(im_small_long)\r\n\r\nseg = np.asarray([(1 if i == 1 else 0)\r\n                  for i in km.labels_]).reshape((h,w))\r\n\r\ncontours = measure.find_contours(seg, 0.5, fully_connected=""high"")\r\nsimplified_contours = [measure.approximate_polygon(c, tolerance=5)\r\n                       for c in contours]\r\n\r\nplt.figure(figsize=(5,10))\r\nfor n, contour in enumerate(simplified_contours):\r\n    plt.plot(contour[:, 1], contour[:, 0], linewidth=2)\r\n\r\n\r\nplt.ylim(h,0)\r\nplt.axes().set_aspect(\'equal\')\r\n'"
Segmentation/Object Detection/Canny Edge Detector/detector.py,0,"b'\n"""""" Canny Edge Detection is based on the following five steps:\n\n    1. Gaussian filter\n    2. Gradient Intensity\n    3. Non-maximum suppression\n    4. Double threshold\n    5. Edge tracking\n\n    This module contains these five steps as five separate Python functions.\n""""""\n\nfrom CannyEdge.utils import to_ndarray\nfrom CannyEdge.core import (gs_filter, gradient_intensity, suppression,\n                            threshold, tracking)\nimport numpy as np\nfrom copy import copy\nimport argparse\nfrom scipy import misc\nimport matplotlib.pyplot as plt\n\n# Argparse\nparser = argparse.ArgumentParser(description=\'Educational Edge Detector\')\nparser.add_argument(\'source\', metavar=\'src\', help=\'image source (jpg, png)\')\nparser.add_argument(\'sigma\', type=float, metavar=\'sigma\', help=\'Gaussian smoothing parameter\')\nparser.add_argument(\'t\', type=int, metavar=\'t\', help=\'lower threshold\')\nparser.add_argument(\'T\', type=int, metavar=\'T\', help=\'upper threshold\')\nparser.add_argument(""--all"", help=""Plot all in-between steps"")\nargs = parser.parse_args()\n\ndef ced(img_file, sigma, t, T, all=False):\n    img = to_ndarray(img_file)\n    if not all:\n        # avoid copies, just do all steps:\n        img = gs_filter(img, sigma)\n        img, D = gradient_intensity(img)\n        img = suppression(img, D)\n        img, weak = threshold(img, t, T)\n        img = tracking(img, weak)\n        return [img]\n    else:\n        # make copies, step by step\n        img1 = gs_ilter(img, sigma)\n        img2, D = gradient_intensity(img1)\n        img3 = suppression(copy(img2), D)\n        img4, weak = threshold(copy(img3), t, T)\n        img5 = tracking(copy(img4), weak)\n        return [to_ndarray(img_file), img1, img2, img3, img4, img5]\n\ndef plot(img_list, safe=False):\n    for d, img in enumerate(img_list):\n        plt.subplot(1, len(img_list), d+1), plt.imshow(img, cmap=\'gray\'),\n        plt.xticks([]), plt.yticks([])\n    plt.show()\n\nimg_list = ced(args.source, args.sigma, args.t, args.T, all=args.all)\nplot(img_list)\n'"
Segmentation/Object Detection/Hough Transform/hough_transform.py,10,"b'""""""\r\nImage Data Analysis Using Numpy & OpenCV\r\nauthor: Mohammed Innat\r\nemail:  innat1994@gmail.com\r\nwebsite: https://iphton.github.io/iphton.github.io/\r\nPlease feel free to use and modify this, but keep the above information. Thanks!\r\n""""""\r\n\r\nimport imageio\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom skimage.color import rgb2gray\r\n\r\n\r\ndef hough_line(img, angle_step = 1, white_lines = True, threshold = 5):\r\n\r\n    """"""\r\n    param:: img - 2D binary image\r\n    param:: angle_step - Spacing between angles to use every n-th angle, Default step is 1.\r\n    param:: lines_are_white - boolean indicator\r\n    param:: value_threshold - Pixel values above or below the threshold are edges\r\n\r\n    Returns:\r\n    param:: accumulator - 2D array of the hough transform accumulator\r\n    param:: theta - array of angles used in computation, in radians.\r\n    param:: rhos - array of rho values.\r\n    """"""\r\n    # Rho and Theta ranges\r\n    thetas = np.deg2rad(np.arange(-90.0, 90.0, angle_step))\r\n    width, height = img.shape\r\n    diag_len = int(np.ceil(np.sqrt(width * width + height * height)))\r\n    rhos = np.linspace(-diag_len, diag_len, diag_len * 2)\r\n\r\n    # Cache some resuable values\r\n    cos_t = np.cos(thetas)\r\n    sin_t = np.sin(thetas)\r\n    num_thetas = len(thetas)\r\n\r\n    # Hough accumulator array of theta vs rho\r\n    accumulator = np.zeros((2 * diag_len, num_thetas), dtype=np.uint8)\r\n    # (row, col) indexes to edges\r\n    are_edges = img > threshold if white_lines else img < threshold\r\n    y_idxs, x_idxs = np.nonzero(are_edges)\r\n\r\n    # Vote in the hough accumulator\r\n    for i in range(len(x_idxs)):\r\n        x = x_idxs[i]\r\n        y = y_idxs[i]\r\n\r\n        for t_idx in range(num_thetas):\r\n            # Calculate rho. diag_len is added for a positive index\r\n            rho = diag_len + int(round(x * cos_t[t_idx] + y * sin_t[t_idx]))\r\n            accumulator[rho, t_idx] += 1\r\n\r\n    return accumulator, thetas, rhos\r\n\r\n\r\ndef viz_hough_line(img, accumulator, thetas, rhos, save_path=None):\r\n\r\n    # plot\r\n    fig, ax = plt.subplots(1, 2, figsize=(10, 10))\r\n\r\n    ax[0].imshow(img, cmap=plt.cm.gray)\r\n    ax[0].set_title(\'Input Image\')\r\n    ax[0].axis(\'image\')\r\n\r\n    ax[1].imshow( accumulator, cmap=\'jet\', extent=[np.rad2deg(thetas[-1]),\r\n                                                   np.rad2deg(thetas[0]), rhos[-1], rhos[0]])\r\n    ax[1].set_aspect(\'equal\', adjustable=\'box\')\r\n    ax[1].set_title(\'Hough Transform\')\r\n    ax[1].set_xlabel(\'Angles (deg)\')\r\n    ax[1].set_ylabel(\'Distance (px)\')\r\n    ax[1].axis(\'image\')\r\n\r\n    plt.axis(\'off\')\r\n    plt.show()\r\n\r\n\r\ngray = lambda rgb : np.dot(rgb[... , :3] , [0.299 , 0.587, 0.114])\r\n\r\nif __name__ == \'__main__\':\r\n    # import and function calling\r\n    pic = imageio.imread(\'<image location>\')\r\n    gray = gray(pic)\r\n\r\n    accumulator, thetas, rhos = hough_line(gray) # get the parameter\r\n    viz_hough_line(gray, accumulator, thetas, rhos) # visualization\r\n'"
Segmentation/Threshold/KMeans Clustering/KMeans_Clustering.py,0,"b'\r\n""""""\r\nImage Data Analysis Using Numpy & OpenCV\r\nauthor: Mohammed Innat\r\nemail:  innat1994@gmail.com\r\nwebsite: https://iphton.github.io/iphton.github.io/\r\nPlease feel free to use and modify this, but keep the above information. Thanks!\r\n""""""\r\nfrom sklearn import cluster\r\npic = imageio.imread(\'<image location>\')\r\nplt.imshow(pic)\r\n\r\nx, y, z = pic.shape\r\npic_2d = pic.reshape(x*y, z)\r\n\r\nkmeans_cluster = cluster.KMeans(n_clusters=5)\r\nkmeans_cluster.fit(pic_2d)\r\ncluster_centers = kmeans_cluster.cluster_centers_\r\ncluster_labels = kmeans_cluster.labels_\r\n\r\nplt.figure(figsize = (15,8))\r\nplt.imshow(cluster_centers[cluster_labels].reshape(x, y, z))\r\n'"
Segmentation/Threshold/Ostu-s Method/Ostu's Method.py,2,"b'\r\n""""""\r\nImage Data Analysis Using Numpy & OpenCV\r\nauthor: Mohammed Innat\r\nemail:  innat1994@gmail.com\r\nwebsite: https://iphton.github.io/iphton.github.io/\r\nPlease feel free to use and modify this, but keep the above information. Thanks!\r\n""""""\r\n\r\nimport numpy as np\r\nimport imageio\r\nimport matplotlib.pyplot as plt\r\n\r\npic = imageio.imread(\'<image location>\')\r\nplt.imshow(pic);\r\n\r\ndef otsu_threshold(im):\r\n\r\n    # Compute histogram and probabilities of each intensity level\r\n    pixel_counts = [np.sum(im == i) for i in range(256)]\r\n\r\n    # Initialization\r\n    s_max = (0,0)\r\n\r\n    for threshold in range(256):\r\n\r\n        # update\r\n        w_0 = sum(pixel_counts[:threshold])\r\n        w_1 = sum(pixel_counts[threshold:])\r\n\r\n        mu_0 = sum([i * pixel_counts[i] for i in range(0,threshold)]) / w_0 if w_0 > 0 else 0\r\n        mu_1 = sum([i * pixel_counts[i] for i in range(threshold, 256)]) / w_1 if w_1 > 0 else 0\r\n\r\n        # calculate - inter class variance\r\n        s = w_0 * w_1 * (mu_0 - mu_1) ** 2\r\n\r\n        if s > s_max[1]:\r\n            s_max = (threshold, s)\r\n\r\n\r\n    return s_max[0]\r\n\r\n\r\ndef threshold(pic, threshold):\r\n    return ((pic > threshold) * 255).astype(\'uint8\')\r\n\r\ngray = lambda rgb : np.dot(rgb[... , :3] , [0.21 , 0.72, 0.07])\r\nplt.imshow(threshold(gray(pic), otsu_threshold(pic)), cmap=\'Greys\')\r\nplt.axis(\'off\')\r\n'"
Segmentation/Object Detection/Canny Edge Detector/CannyEdge/core.py,14,"b'"""""" Canny Edge Detection is based on the following five steps:\n\n    1. Gaussian filter\n    2. Gradient Intensity\n    3. Non-maximum suppression\n    4. Double threshold\n    5. Edge tracking\n\n    This module contains these five steps as five separate Python functions.\n""""""\n\n# Third party imports\nfrom scipy.ndimage.filters import gaussian_filter\nfrom scipy.ndimage import (sobel, generic_gradient_magnitude, generic_filter)\nfrom scipy import ndimage\nimport numpy as np\n\n# Module imports\nfrom CannyEdge.utils import round_angle\n\n\ndef gs_filter(img, sigma):\n    """""" Step 1: Gaussian filter\n\n    Args:\n        img: Numpy ndarray of image\n        sigma: Smoothing parameter\n\n    Returns:\n        Numpy ndarray of smoothed image\n    """"""\n    if type(img) != np.ndarray:\n        raise TypeError(\'input image must be of type ndarray\')\n    else:\n        return gaussian_filter(img, sigma)\n\n\ndef gradient_intensity(img):\n    """""" Step 2: Find gradients\n\n    Args:\n        img: Numpy ndarray of image to be processed (denoised image)\n\n    Returns:\n        grad: gradient-intensed image\n        thetas: gradient directions\n    """"""\n\n    # Kernel for Gradient in x-direction\n    sobel_x = np.array(\n        [[-1, 0, 1],\n        [-2, 0, 2],\n        [-1, 0, 1]], np.int32\n    )\n    # Kernel for Gradient in y-direction\n    sobel_y = np.array(\n        [[1, 2, 1],\n        [0, 0, 0],\n        [-1, -2, -1]], np.int32\n    )\n    # Apply kernels to the image\n    sx = ndimage.filters.convolve(img, sobel_x)\n    sy = ndimage.filters.convolve(img, sobel_y)\n\n    # return the hypothenuse of (Ix, Iy)\n    grad = np.hypot(sx, sy) # Equivalent to sqrt(x1**2 + x2**2)\n    thetas = np.arctan2(sy, sy) # Equivalent to tan inverse sy / sx\n\n    return (grad, thetas)\n\n\ndef suppression(img, thetas):\n    """""" Step 3: Non-maximum suppression\n\n    Args:\n        img: Numpy ndarray of image to be processed (gradient-intensed image)\n        D: Numpy ndarray of gradient directions for each pixel in img\n\n    Returns:\n        ...\n    """"""\n    # gray image shape\n    h, w = img.shape\n    z = np.zeros((h,w), dtype=np.int32)\n\n    for i in range(h):\n        for j in range(w):\n            # find neighbour pixels to visit from the gradient directions\n            loc = round_angle(thetas[i, j])\n            try:\n                if loc == 0:\n                    if (img[i, j] >= img[i, j - 1]) and (img[i, j] >= img[i, j + 1]):\n                        z[i,j] = img[i,j]\n                elif loc == 90:\n                    if (img[i, j] >= img[i - 1, j]) and (img[i, j] >= img[i + 1, j]):\n                        z[i,j] = img[i,j]\n                elif loc == 135:\n                    if (img[i, j] >= img[i - 1, j - 1]) and (img[i, j] >= img[i + 1, j + 1]):\n                        z[i,j] = img[i,j]\n                elif loc == 45:\n                    if (img[i, j] >= img[i - 1, j + 1]) and (img[i, j] >= img[i + 1, j - 1]):\n                        z[i,j] = img[i,j]\n            except IndexError as e:\n                pass\n    return z\n\n\ndef threshold(img, t, T):\n    """""" Step 4: Thresholding\n    Iterates through image pixels and marks them as WEAK and STRONG edge\n    pixels based on the threshold values.\n\n    Args:\n        img: Numpy ndarray of image to be processed (suppressed image)\n        t: lower threshold\n        T: upper threshold\n\n    Return:\n        img: Thresholdes image\n\n    """"""\n    # define gray value of a WEAK and a STRONG pixel\n    cf = {\n        \'WEAK\': np.int32(70),\n        \'STRONG\': np.int32(255),\n    }\n\n    # get strong pixel indices\n    strong_i, strong_j = np.where(img > T)\n\n    # get weak pixel indices\n    weak_i, weak_j = np.where((img >= t) & (img <= T))\n\n    # get pixel indices set to be zero\n    zero_i, zero_j = np.where(img < t)\n\n    # set values\n    img[strong_i, strong_j] = cf.get(\'STRONG\')\n    img[weak_i, weak_j] = cf.get(\'WEAK\')\n    img[zero_i, zero_j] = np.int32(0)\n\n    return (img, cf.get(\'WEAK\'))\n\ndef tracking(img, weak, strong=255):\n    """""" Step 5:\n    Checks if edges marked as weak are connected to strong edges.\n\n    Note that there are better methods (blob analysis) to do this,\n    but they are more difficult to understand. This just checks neighbour\n    edges.\n\n    Also note that for perfomance reasons you wouldn\'t do this kind of tracking\n    in a seperate loop, you would do it in the loop of the tresholding process.\n    Since this is an **educational** implementation ment to generate plots\n    to help people understand the major steps of the Canny Edge algorithm,\n    we exceptionally don\'t care about perfomance here.\n\n    Args:\n        img: Numpy ndarray of image to be processed (thresholded image)\n        weak: Value that was used to mark a weak edge in Step 4\n\n    Returns:\n        final Canny Edge image.\n    """"""\n\n    h, w = img.shape\n    for i in range(h):\n        for j in range(w):\n            if img[i, j] == weak:\n                # check if one of the neighbours is strong (=255 by default)\n                try:\n                    if ((img[i + 1, j] == strong) or (img[i - 1, j] == strong)\n                         or (img[i, j + 1] == strong) or (img[i, j - 1] == strong)\n                         or (img[i+1, j + 1] == strong) or (img[i-1, j - 1] == strong)):\n                        img[i, j] = strong\n                    else:\n                        img[i, j] = 0\n                except IndexError as e:\n                    pass\n    return img\n'"
Segmentation/Object Detection/Canny Edge Detector/CannyEdge/utils.py,1,"b'"""""" Canny Edge Detection is based on the following five steps:\n\n    1. Gaussian filter\n    2. Gradient Intensity\n    3. Non-maximum suppression\n    4. Double threshold\n    5. Edge tracking\n\n    This module contains these five steps as five separate Python functions.\n""""""\n\nfrom scipy import misc\nimport numpy as np\n\ndef to_ndarray(img):\n    im = misc.imread(img, flatten=True)\n    im = im.astype(\'int32\')\n    return im\n\ndef round_angle(angle):\n    """""" Input angle must be in [0,180) """"""\n    angle = np.rad2deg(angle) % 180\n    if (0 <= angle < 22.5) or (157.5 <= angle < 180):\n        angle = 0\n    elif (22.5 <= angle < 67.5):\n        angle = 45\n    elif (67.5 <= angle < 112.5):\n        angle = 90\n    elif (112.5 <= angle < 157.5):\n        angle = 135\n    return angle\n'"
