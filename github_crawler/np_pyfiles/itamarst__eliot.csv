file_path,api_count,code
setup.py,0,"b'from setuptools import setup\n\nimport versioneer\n\n\ndef read(path):\n    """"""\n    Read the contents of a file.\n    """"""\n    with open(path) as f:\n        return f.read()\n\n\nsetup(\n    classifiers=[\n        ""Intended Audience :: Developers"",\n        ""License :: OSI Approved :: Apache Software License"",\n        ""Operating System :: OS Independent"",\n        ""Programming Language :: Python"",\n        ""Programming Language :: Python :: 3"",\n        ""Programming Language :: Python :: 3.5"",\n        ""Programming Language :: Python :: 3.6"",\n        ""Programming Language :: Python :: 3.7"",\n        ""Programming Language :: Python :: 3.8"",\n        ""Programming Language :: Python :: Implementation :: CPython"",\n        ""Programming Language :: Python :: Implementation :: PyPy"",\n        ""Topic :: System :: Logging"",\n    ],\n    name=""eliot"",\n    version=versioneer.get_version(),\n    cmdclass=versioneer.get_cmdclass(),\n    description=""Logging library that tells you why it happened"",\n    python_requires="">=3.5.3"",\n    install_requires=[\n        # Python 3 compatibility:\n        ""six"",\n        # Internal code documentation:\n        ""zope.interface"",\n        # Persistent objects for Python:\n        ""pyrsistent >= 0.11.8"",  # version with multi-type pvector/pmap_field\n        # Better decorators, with version that works better with type annotations:\n        ""boltons >= 19.0.1"",\n        # Backwards compatibility for Python 3.5 and 3.6:\n        \'aiocontextvars;python_version<""3.7"" and python_version>""2.7""\',\n    ],\n    extras_require={\n        ""journald"": [\n            # We use cffi to talk to the journald API:\n            ""cffi >= 1.1.2""  # significant API changes in older releases\n        ],\n        ""test"": [\n            # Bug-seeking missile:\n            ""hypothesis >= 1.14.0"",\n            # Tasteful testing for Python:\n            ""testtools"",\n            ""pytest"",\n        ],\n        ""dev"": [\n            # Ensure we can do python_requires correctly:\n            ""setuptools >= 40"",\n            # For uploading releases:\n            ""twine >= 1.12.1"",\n            # Allows us to measure code coverage:\n            ""coverage"",\n            ""sphinx"",\n            ""sphinx_rtd_theme"",\n            ""flake8"",\n            ""black"",\n        ],\n    },\n    entry_points={""console_scripts"": [""eliot-prettyprint = eliot.prettyprint:_main""]},\n    keywords=""logging"",\n    license=""Apache 2.0"",\n    packages=[""eliot"", ""eliot.tests""],\n    url=""https://github.com/itamarst/eliot/"",\n    maintainer=""Itamar Turner-Trauring"",\n    maintainer_email=""itamar@itamarst.org"",\n    long_description=read(""README.rst""),\n)\n'"
versioneer.py,0,"b'\n# Version: 0.18\n\n""""""The Versioneer - like a rocketeer, but for versions.\n\nThe Versioneer\n==============\n\n* like a rocketeer, but for versions!\n* https://github.com/warner/python-versioneer\n* Brian Warner\n* License: Public Domain\n* Compatible With: python2.6, 2.7, 3.2, 3.3, 3.4, 3.5, 3.6, and pypy\n* [![Latest Version]\n(https://pypip.in/version/versioneer/badge.svg?style=flat)\n](https://pypi.python.org/pypi/versioneer/)\n* [![Build Status]\n(https://travis-ci.org/warner/python-versioneer.png?branch=master)\n](https://travis-ci.org/warner/python-versioneer)\n\nThis is a tool for managing a recorded version number in distutils-based\npython projects. The goal is to remove the tedious and error-prone ""update\nthe embedded version string"" step from your release process. Making a new\nrelease should be as easy as recording a new tag in your version-control\nsystem, and maybe making new tarballs.\n\n\n## Quick Install\n\n* `pip install versioneer` to somewhere to your $PATH\n* add a `[versioneer]` section to your setup.cfg (see below)\n* run `versioneer install` in your source tree, commit the results\n\n## Version Identifiers\n\nSource trees come from a variety of places:\n\n* a version-control system checkout (mostly used by developers)\n* a nightly tarball, produced by build automation\n* a snapshot tarball, produced by a web-based VCS browser, like github\'s\n  ""tarball from tag"" feature\n* a release tarball, produced by ""setup.py sdist"", distributed through PyPI\n\nWithin each source tree, the version identifier (either a string or a number,\nthis tool is format-agnostic) can come from a variety of places:\n\n* ask the VCS tool itself, e.g. ""git describe"" (for checkouts), which knows\n  about recent ""tags"" and an absolute revision-id\n* the name of the directory into which the tarball was unpacked\n* an expanded VCS keyword ($Id$, etc)\n* a `_version.py` created by some earlier build step\n\nFor released software, the version identifier is closely related to a VCS\ntag. Some projects use tag names that include more than just the version\nstring (e.g. ""myproject-1.2"" instead of just ""1.2""), in which case the tool\nneeds to strip the tag prefix to extract the version identifier. For\nunreleased software (between tags), the version identifier should provide\nenough information to help developers recreate the same tree, while also\ngiving them an idea of roughly how old the tree is (after version 1.2, before\nversion 1.3). Many VCS systems can report a description that captures this,\nfor example `git describe --tags --dirty --always` reports things like\n""0.7-1-g574ab98-dirty"" to indicate that the checkout is one revision past the\n0.7 tag, has a unique revision id of ""574ab98"", and is ""dirty"" (it has\nuncommitted changes.\n\nThe version identifier is used for multiple purposes:\n\n* to allow the module to self-identify its version: `myproject.__version__`\n* to choose a name and prefix for a \'setup.py sdist\' tarball\n\n## Theory of Operation\n\nVersioneer works by adding a special `_version.py` file into your source\ntree, where your `__init__.py` can import it. This `_version.py` knows how to\ndynamically ask the VCS tool for version information at import time.\n\n`_version.py` also contains `$Revision$` markers, and the installation\nprocess marks `_version.py` to have this marker rewritten with a tag name\nduring the `git archive` command. As a result, generated tarballs will\ncontain enough information to get the proper version.\n\nTo allow `setup.py` to compute a version too, a `versioneer.py` is added to\nthe top level of your source tree, next to `setup.py` and the `setup.cfg`\nthat configures it. This overrides several distutils/setuptools commands to\ncompute the version when invoked, and changes `setup.py build` and `setup.py\nsdist` to replace `_version.py` with a small static file that contains just\nthe generated version data.\n\n## Installation\n\nSee [INSTALL.md](./INSTALL.md) for detailed installation instructions.\n\n## Version-String Flavors\n\nCode which uses Versioneer can learn about its version string at runtime by\nimporting `_version` from your main `__init__.py` file and running the\n`get_versions()` function. From the ""outside"" (e.g. in `setup.py`), you can\nimport the top-level `versioneer.py` and run `get_versions()`.\n\nBoth functions return a dictionary with different flavors of version\ninformation:\n\n* `[\'version\']`: A condensed version string, rendered using the selected\n  style. This is the most commonly used value for the project\'s version\n  string. The default ""pep440"" style yields strings like `0.11`,\n  `0.11+2.g1076c97`, or `0.11+2.g1076c97.dirty`. See the ""Styles"" section\n  below for alternative styles.\n\n* `[\'full-revisionid\']`: detailed revision identifier. For Git, this is the\n  full SHA1 commit id, e.g. ""1076c978a8d3cfc70f408fe5974aa6c092c949ac"".\n\n* `[\'date\']`: Date and time of the latest `HEAD` commit. For Git, it is the\n  commit date in ISO 8601 format. This will be None if the date is not\n  available.\n\n* `[\'dirty\']`: a boolean, True if the tree has uncommitted changes. Note that\n  this is only accurate if run in a VCS checkout, otherwise it is likely to\n  be False or None\n\n* `[\'error\']`: if the version string could not be computed, this will be set\n  to a string describing the problem, otherwise it will be None. It may be\n  useful to throw an exception in setup.py if this is set, to avoid e.g.\n  creating tarballs with a version string of ""unknown"".\n\nSome variants are more useful than others. Including `full-revisionid` in a\nbug report should allow developers to reconstruct the exact code being tested\n(or indicate the presence of local changes that should be shared with the\ndevelopers). `version` is suitable for display in an ""about"" box or a CLI\n`--version` output: it can be easily compared against release notes and lists\nof bugs fixed in various releases.\n\nThe installer adds the following text to your `__init__.py` to place a basic\nversion in `YOURPROJECT.__version__`:\n\n    from ._version import get_versions\n    __version__ = get_versions()[\'version\']\n    del get_versions\n\n## Styles\n\nThe setup.cfg `style=` configuration controls how the VCS information is\nrendered into a version string.\n\nThe default style, ""pep440"", produces a PEP440-compliant string, equal to the\nun-prefixed tag name for actual releases, and containing an additional ""local\nversion"" section with more detail for in-between builds. For Git, this is\nTAG[+DISTANCE.gHEX[.dirty]] , using information from `git describe --tags\n--dirty --always`. For example ""0.11+2.g1076c97.dirty"" indicates that the\ntree is like the ""1076c97"" commit but has uncommitted changes ("".dirty""), and\nthat this commit is two revisions (""+2"") beyond the ""0.11"" tag. For released\nsoftware (exactly equal to a known tag), the identifier will only contain the\nstripped tag, e.g. ""0.11"".\n\nOther styles are available. See [details.md](details.md) in the Versioneer\nsource tree for descriptions.\n\n## Debugging\n\nVersioneer tries to avoid fatal errors: if something goes wrong, it will tend\nto return a version of ""0+unknown"". To investigate the problem, run `setup.py\nversion`, which will run the version-lookup code in a verbose mode, and will\ndisplay the full contents of `get_versions()` (including the `error` string,\nwhich may help identify what went wrong).\n\n## Known Limitations\n\nSome situations are known to cause problems for Versioneer. This details the\nmost significant ones. More can be found on Github\n[issues page](https://github.com/warner/python-versioneer/issues).\n\n### Subprojects\n\nVersioneer has limited support for source trees in which `setup.py` is not in\nthe root directory (e.g. `setup.py` and `.git/` are *not* siblings). The are\ntwo common reasons why `setup.py` might not be in the root:\n\n* Source trees which contain multiple subprojects, such as\n  [Buildbot](https://github.com/buildbot/buildbot), which contains both\n  ""master"" and ""slave"" subprojects, each with their own `setup.py`,\n  `setup.cfg`, and `tox.ini`. Projects like these produce multiple PyPI\n  distributions (and upload multiple independently-installable tarballs).\n* Source trees whose main purpose is to contain a C library, but which also\n  provide bindings to Python (and perhaps other langauges) in subdirectories.\n\nVersioneer will look for `.git` in parent directories, and most operations\nshould get the right version string. However `pip` and `setuptools` have bugs\nand implementation details which frequently cause `pip install .` from a\nsubproject directory to fail to find a correct version string (so it usually\ndefaults to `0+unknown`).\n\n`pip install --editable .` should work correctly. `setup.py install` might\nwork too.\n\nPip-8.1.1 is known to have this problem, but hopefully it will get fixed in\nsome later version.\n\n[Bug #38](https://github.com/warner/python-versioneer/issues/38) is tracking\nthis issue. The discussion in\n[PR #61](https://github.com/warner/python-versioneer/pull/61) describes the\nissue from the Versioneer side in more detail.\n[pip PR#3176](https://github.com/pypa/pip/pull/3176) and\n[pip PR#3615](https://github.com/pypa/pip/pull/3615) contain work to improve\npip to let Versioneer work correctly.\n\nVersioneer-0.16 and earlier only looked for a `.git` directory next to the\n`setup.cfg`, so subprojects were completely unsupported with those releases.\n\n### Editable installs with setuptools <= 18.5\n\n`setup.py develop` and `pip install --editable .` allow you to install a\nproject into a virtualenv once, then continue editing the source code (and\ntest) without re-installing after every change.\n\n""Entry-point scripts"" (`setup(entry_points={""console_scripts"": ..})`) are a\nconvenient way to specify executable scripts that should be installed along\nwith the python package.\n\nThese both work as expected when using modern setuptools. When using\nsetuptools-18.5 or earlier, however, certain operations will cause\n`pkg_resources.DistributionNotFound` errors when running the entrypoint\nscript, which must be resolved by re-installing the package. This happens\nwhen the install happens with one version, then the egg_info data is\nregenerated while a different version is checked out. Many setup.py commands\ncause egg_info to be rebuilt (including `sdist`, `wheel`, and installing into\na different virtualenv), so this can be surprising.\n\n[Bug #83](https://github.com/warner/python-versioneer/issues/83) describes\nthis one, but upgrading to a newer version of setuptools should probably\nresolve it.\n\n### Unicode version strings\n\nWhile Versioneer works (and is continually tested) with both Python 2 and\nPython 3, it is not entirely consistent with bytes-vs-unicode distinctions.\nNewer releases probably generate unicode version strings on py2. It\'s not\nclear that this is wrong, but it may be surprising for applications when then\nwrite these strings to a network connection or include them in bytes-oriented\nAPIs like cryptographic checksums.\n\n[Bug #71](https://github.com/warner/python-versioneer/issues/71) investigates\nthis question.\n\n\n## Updating Versioneer\n\nTo upgrade your project to a new release of Versioneer, do the following:\n\n* install the new Versioneer (`pip install -U versioneer` or equivalent)\n* edit `setup.cfg`, if necessary, to include any new configuration settings\n  indicated by the release notes. See [UPGRADING](./UPGRADING.md) for details.\n* re-run `versioneer install` in your source tree, to replace\n  `SRC/_version.py`\n* commit any changed files\n\n## Future Directions\n\nThis tool is designed to make it easily extended to other version-control\nsystems: all VCS-specific components are in separate directories like\nsrc/git/ . The top-level `versioneer.py` script is assembled from these\ncomponents by running make-versioneer.py . In the future, make-versioneer.py\nwill take a VCS name as an argument, and will construct a version of\n`versioneer.py` that is specific to the given VCS. It might also take the\nconfiguration arguments that are currently provided manually during\ninstallation by editing setup.py . Alternatively, it might go the other\ndirection and include code from all supported VCS systems, reducing the\nnumber of intermediate scripts.\n\n\n## License\n\nTo make Versioneer easier to embed, all its code is dedicated to the public\ndomain. The `_version.py` that it creates is also in the public domain.\nSpecifically, both are released under the Creative Commons ""Public Domain\nDedication"" license (CC0-1.0), as described in\nhttps://creativecommons.org/publicdomain/zero/1.0/ .\n\n""""""\n\nfrom __future__ import print_function\ntry:\n    import configparser\nexcept ImportError:\n    import ConfigParser as configparser\nimport errno\nimport json\nimport os\nimport re\nimport subprocess\nimport sys\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_root():\n    """"""Get the project root directory.\n\n    We require that all commands are run from the project root, i.e. the\n    directory that contains setup.py, setup.cfg, and versioneer.py .\n    """"""\n    root = os.path.realpath(os.path.abspath(os.getcwd()))\n    setup_py = os.path.join(root, ""setup.py"")\n    versioneer_py = os.path.join(root, ""versioneer.py"")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        # allow \'python path/to/setup.py COMMAND\'\n        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))\n        setup_py = os.path.join(root, ""setup.py"")\n        versioneer_py = os.path.join(root, ""versioneer.py"")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        err = (""Versioneer was unable to run the project root directory. ""\n               ""Versioneer requires setup.py to be executed from ""\n               ""its immediate directory (like \'python setup.py COMMAND\'), ""\n               ""or in a way that lets it use sys.argv[0] to find the root ""\n               ""(like \'python path/to/setup.py COMMAND\')."")\n        raise VersioneerBadRootError(err)\n    try:\n        # Certain runtime workflows (setup.py install/develop in a setuptools\n        # tree) execute all dependencies in a single python process, so\n        # ""versioneer"" may be imported multiple times, and python\'s shared\n        # module-import table will cache the first one. So we can\'t use\n        # os.path.dirname(__file__), as that will find whichever\n        # versioneer.py was first imported, even in later projects.\n        me = os.path.realpath(os.path.abspath(__file__))\n        me_dir = os.path.normcase(os.path.splitext(me)[0])\n        vsr_dir = os.path.normcase(os.path.splitext(versioneer_py)[0])\n        if me_dir != vsr_dir:\n            print(""Warning: build in %s is using versioneer.py from %s""\n                  % (os.path.dirname(me), versioneer_py))\n    except NameError:\n        pass\n    return root\n\n\ndef get_config_from_root(root):\n    """"""Read the project setup.cfg file to determine Versioneer config.""""""\n    # This might raise EnvironmentError (if setup.cfg is missing), or\n    # configparser.NoSectionError (if it lacks a [versioneer] section), or\n    # configparser.NoOptionError (if it lacks ""VCS=""). See the docstring at\n    # the top of versioneer.py for instructions on writing your setup.cfg .\n    setup_cfg = os.path.join(root, ""setup.cfg"")\n    parser = configparser.SafeConfigParser()\n    with open(setup_cfg, ""r"") as f:\n        parser.readfp(f)\n    VCS = parser.get(""versioneer"", ""VCS"")  # mandatory\n\n    def get(parser, name):\n        if parser.has_option(""versioneer"", name):\n            return parser.get(""versioneer"", name)\n        return None\n    cfg = VersioneerConfig()\n    cfg.VCS = VCS\n    cfg.style = get(parser, ""style"") or """"\n    cfg.versionfile_source = get(parser, ""versionfile_source"")\n    cfg.versionfile_build = get(parser, ""versionfile_build"")\n    cfg.tag_prefix = get(parser, ""tag_prefix"")\n    if cfg.tag_prefix in (""\'\'"", \'""""\'):\n        cfg.tag_prefix = """"\n    cfg.parentdir_prefix = get(parser, ""parentdir_prefix"")\n    cfg.verbose = get(parser, ""verbose"")\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\n# these dictionaries contain VCS-specific tools\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n                env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %s"" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %s"" % (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %s (error)"" % dispcmd)\n            print(""stdout was %s"" % stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\nLONG_VERSION_PY[\'git\'] = \'\'\'\n# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain. Generated by\n# versioneer-0.18 (https://github.com/warner/python-versioneer)\n\n""""""Git implementation of _version.py.""""""\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\n\n\ndef get_keywords():\n    """"""Get the keywords needed to look up the version information.""""""\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = ""%(DOLLAR)sFormat:%%d%(DOLLAR)s""\n    git_full = ""%(DOLLAR)sFormat:%%H%(DOLLAR)s""\n    git_date = ""%(DOLLAR)sFormat:%%ci%(DOLLAR)s""\n    keywords = {""refnames"": git_refnames, ""full"": git_full, ""date"": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_config():\n    """"""Create, populate and return the VersioneerConfig() object.""""""\n    # these strings are filled in when \'setup.py versioneer\' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = ""git""\n    cfg.style = ""%(STYLE)s""\n    cfg.tag_prefix = ""%(TAG_PREFIX)s""\n    cfg.parentdir_prefix = ""%(PARENTDIR_PREFIX)s""\n    cfg.versionfile_source = ""%(VERSIONFILE_SOURCE)s""\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n                env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %%s"" %% dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %%s"" %% (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %%s (error)"" %% dispcmd)\n            print(""stdout was %%s"" %% stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {""version"": dirname[len(parentdir_prefix):],\n                    ""full-revisionid"": None,\n                    ""dirty"": False, ""error"": None, ""date"": None}\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(""Tried directories %%s but none started with prefix %%s"" %%\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %%d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r\'\\d\', r)])\n        if verbose:\n            print(""discarding \'%%s\', no digits"" %% "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %%s"" %% "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(""picking %%s"" %% r)\n            return {""version"": r,\n                    ""full-revisionid"": keywords[""full""].strip(),\n                    ""dirty"": False, ""error"": None,\n                    ""date"": date}\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {""version"": ""0+unknown"",\n            ""full-revisionid"": keywords[""full""].strip(),\n            ""dirty"": False, ""error"": ""no suitable tags"", ""date"": None}\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n                          hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %%s not under git control"" %% root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty"",\n                                          ""--always"", ""--long"",\n                                          ""--match"", ""%%s*"" %% tag_prefix],\n                                   cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\'^(.+)-(\\d+)-g([0-9a-f]+)$\', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = (""unable to parse git-describe output: \'%%s\'""\n                               %% describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%%s\' doesn\'t start with prefix \'%%s\'""\n                print(fmt %% (full_tag, tag_prefix))\n            pieces[""error""] = (""tag \'%%s\' doesn\'t start with prefix \'%%s\'""\n                               %% (full_tag, tag_prefix))\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n                                    cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%%ci"", ""HEAD""],\n                       cwd=root)[0].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%%d.g%%s"" %% (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%%d.g%%s"" %% (pieces[""distance""],\n                                          pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%%d"" %% pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%%d"" %% pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%%d"" %% pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%%s"" %% pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%%d"" %% pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%%s"" %% pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%%d"" %% pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%%d"" %% pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%%d-g%%s"" %% (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%%d-g%%s"" %% (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {""version"": ""unknown"",\n                ""full-revisionid"": pieces.get(""long""),\n                ""dirty"": None,\n                ""error"": pieces[""error""],\n                ""date"": None}\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%%s\'"" %% style)\n\n    return {""version"": rendered, ""full-revisionid"": pieces[""long""],\n            ""dirty"": pieces[""dirty""], ""error"": None,\n            ""date"": pieces.get(""date"")}\n\n\ndef get_versions():\n    """"""Get version information or return default if unable to do so.""""""\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don\'t do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split(\'/\'):\n            root = os.path.dirname(root)\n    except NameError:\n        return {""version"": ""0+unknown"", ""full-revisionid"": None,\n                ""dirty"": None,\n                ""error"": ""unable to find root of source tree"",\n                ""date"": None}\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {""version"": ""0+unknown"", ""full-revisionid"": None,\n            ""dirty"": None,\n            ""error"": ""unable to compute version"", ""date"": None}\n\'\'\'\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r\'\\d\', r)])\n        if verbose:\n            print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %s"" % "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(""picking %s"" % r)\n            return {""version"": r,\n                    ""full-revisionid"": keywords[""full""].strip(),\n                    ""dirty"": False, ""error"": None,\n                    ""date"": date}\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {""version"": ""0+unknown"",\n            ""full-revisionid"": keywords[""full""].strip(),\n            ""dirty"": False, ""error"": ""no suitable tags"", ""date"": None}\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n                          hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %s not under git control"" % root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty"",\n                                          ""--always"", ""--long"",\n                                          ""--match"", ""%s*"" % tag_prefix],\n                                   cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\'^(.+)-(\\d+)-g([0-9a-f]+)$\', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = (""unable to parse git-describe output: \'%s\'""\n                               % describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                print(fmt % (full_tag, tag_prefix))\n            pieces[""error""] = (""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                               % (full_tag, tag_prefix))\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n                                    cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""],\n                       cwd=root)[0].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef do_vcs_install(manifest_in, versionfile_source, ipy):\n    """"""Git-specific installation logic for Versioneer.\n\n    For Git, this means creating/changing .gitattributes to mark _version.py\n    for export-subst keyword substitution.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n    files = [manifest_in, versionfile_source]\n    if ipy:\n        files.append(ipy)\n    try:\n        me = __file__\n        if me.endswith("".pyc"") or me.endswith("".pyo""):\n            me = os.path.splitext(me)[0] + "".py""\n        versioneer_file = os.path.relpath(me)\n    except NameError:\n        versioneer_file = ""versioneer.py""\n    files.append(versioneer_file)\n    present = False\n    try:\n        f = open("".gitattributes"", ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(versionfile_source):\n                if ""export-subst"" in line.strip().split()[1:]:\n                    present = True\n        f.close()\n    except EnvironmentError:\n        pass\n    if not present:\n        f = open("".gitattributes"", ""a+"")\n        f.write(""%s export-subst\\n"" % versionfile_source)\n        f.close()\n        files.append("".gitattributes"")\n    run_command(GITS, [""add"", ""--""] + files)\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {""version"": dirname[len(parentdir_prefix):],\n                    ""full-revisionid"": None,\n                    ""dirty"": False, ""error"": None, ""date"": None}\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(""Tried directories %s but none started with prefix %s"" %\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\nSHORT_VERSION_PY = """"""\n# This file was generated by \'versioneer.py\' (0.18) from\n# revision-control system data, or from the parent directory name of an\n# unpacked source archive. Distribution tarballs contain a pre-generated copy\n# of this file.\nfrom __future__ import absolute_import\nimport json\n\nversion_json = \'\'\'\n%s\n\'\'\'  # END VERSION_JSON\n\n\ndef get_versions():\n    return json.loads(version_json)\n""""""\n\n\ndef versions_from_file(filename):\n    """"""Try to determine the version from _version.py if present.""""""\n    try:\n        with open(filename) as f:\n            contents = f.read()\n    except EnvironmentError:\n        raise NotThisMethod(""unable to read _version.py"")\n    mo = re.search(r""version_json = \'\'\'\\n(.*)\'\'\'  # END VERSION_JSON"",\n                   contents, re.M | re.S)\n    if not mo:\n        mo = re.search(r""version_json = \'\'\'\\r\\n(.*)\'\'\'  # END VERSION_JSON"",\n                       contents, re.M | re.S)\n    if not mo:\n        raise NotThisMethod(""no version_json in _version.py"")\n    return json.loads(mo.group(1))\n\n\ndef write_to_version_file(filename, versions):\n    """"""Write the given version number to the given _version.py file.""""""\n    os.unlink(filename)\n    contents = json.dumps(versions, sort_keys=True,\n                          indent=1, separators=("","", "": ""))\n    with open(filename, ""w"") as f:\n        f.write(SHORT_VERSION_PY % contents)\n\n    print(""set %s to \'%s\'"" % (filename, versions[""version""]))\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%d.g%s"" % (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%d.g%s"" % (pieces[""distance""],\n                                          pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%d"" % pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%d"" % pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%s"" % pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%s"" % pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {""version"": ""unknown"",\n                ""full-revisionid"": pieces.get(""long""),\n                ""dirty"": None,\n                ""error"": pieces[""error""],\n                ""date"": None}\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%s\'"" % style)\n\n    return {""version"": rendered, ""full-revisionid"": pieces[""long""],\n            ""dirty"": pieces[""dirty""], ""error"": None,\n            ""date"": pieces.get(""date"")}\n\n\nclass VersioneerBadRootError(Exception):\n    """"""The project root directory is unknown or missing key files.""""""\n\n\ndef get_versions(verbose=False):\n    """"""Get the project version from whatever source is available.\n\n    Returns dict with two keys: \'version\' and \'full\'.\n    """"""\n    if ""versioneer"" in sys.modules:\n        # see the discussion in cmdclass.py:get_cmdclass()\n        del sys.modules[""versioneer""]\n\n    root = get_root()\n    cfg = get_config_from_root(root)\n\n    assert cfg.VCS is not None, ""please set [versioneer]VCS= in setup.cfg""\n    handlers = HANDLERS.get(cfg.VCS)\n    assert handlers, ""unrecognized VCS \'%s\'"" % cfg.VCS\n    verbose = verbose or cfg.verbose\n    assert cfg.versionfile_source is not None, \\\n        ""please set versioneer.versionfile_source""\n    assert cfg.tag_prefix is not None, ""please set versioneer.tag_prefix""\n\n    versionfile_abs = os.path.join(root, cfg.versionfile_source)\n\n    # extract version from first of: _version.py, VCS command (e.g. \'git\n    # describe\'), parentdir. This is meant to work for developers using a\n    # source checkout, for users of a tarball created by \'setup.py sdist\',\n    # and for users of a tarball/zipball created by \'git archive\' or github\'s\n    # download-from-tag feature or the equivalent in other VCSes.\n\n    get_keywords_f = handlers.get(""get_keywords"")\n    from_keywords_f = handlers.get(""keywords"")\n    if get_keywords_f and from_keywords_f:\n        try:\n            keywords = get_keywords_f(versionfile_abs)\n            ver = from_keywords_f(keywords, cfg.tag_prefix, verbose)\n            if verbose:\n                print(""got version from expanded keyword %s"" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        ver = versions_from_file(versionfile_abs)\n        if verbose:\n            print(""got version from file %s %s"" % (versionfile_abs, ver))\n        return ver\n    except NotThisMethod:\n        pass\n\n    from_vcs_f = handlers.get(""pieces_from_vcs"")\n    if from_vcs_f:\n        try:\n            pieces = from_vcs_f(cfg.tag_prefix, root, verbose)\n            ver = render(pieces, cfg.style)\n            if verbose:\n                print(""got version from VCS %s"" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        if cfg.parentdir_prefix:\n            ver = versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n            if verbose:\n                print(""got version from parentdir %s"" % ver)\n            return ver\n    except NotThisMethod:\n        pass\n\n    if verbose:\n        print(""unable to compute version"")\n\n    return {""version"": ""0+unknown"", ""full-revisionid"": None,\n            ""dirty"": None, ""error"": ""unable to compute version"",\n            ""date"": None}\n\n\ndef get_version():\n    """"""Get the short version string for this project.""""""\n    return get_versions()[""version""]\n\n\ndef get_cmdclass():\n    """"""Get the custom setuptools/distutils subclasses used by Versioneer.""""""\n    if ""versioneer"" in sys.modules:\n        del sys.modules[""versioneer""]\n        # this fixes the ""python setup.py develop"" case (also \'install\' and\n        # \'easy_install .\'), in which subdependencies of the main project are\n        # built (using setup.py bdist_egg) in the same python process. Assume\n        # a main project A and a dependency B, which use different versions\n        # of Versioneer. A\'s setup.py imports A\'s Versioneer, leaving it in\n        # sys.modules by the time B\'s setup.py is executed, causing B to run\n        # with the wrong versioneer. Setuptools wraps the sub-dep builds in a\n        # sandbox that restores sys.modules to it\'s pre-build state, so the\n        # parent is protected against the child\'s ""import versioneer"". By\n        # removing ourselves from sys.modules here, before the child build\n        # happens, we protect the child from the parent\'s versioneer too.\n        # Also see https://github.com/warner/python-versioneer/issues/52\n\n    cmds = {}\n\n    # we add ""version"" to both distutils and setuptools\n    from distutils.core import Command\n\n    class cmd_version(Command):\n        description = ""report generated version string""\n        user_options = []\n        boolean_options = []\n\n        def initialize_options(self):\n            pass\n\n        def finalize_options(self):\n            pass\n\n        def run(self):\n            vers = get_versions(verbose=True)\n            print(""Version: %s"" % vers[""version""])\n            print("" full-revisionid: %s"" % vers.get(""full-revisionid""))\n            print("" dirty: %s"" % vers.get(""dirty""))\n            print("" date: %s"" % vers.get(""date""))\n            if vers[""error""]:\n                print("" error: %s"" % vers[""error""])\n    cmds[""version""] = cmd_version\n\n    # we override ""build_py"" in both distutils and setuptools\n    #\n    # most invocation pathways end up running build_py:\n    #  distutils/build -> build_py\n    #  distutils/install -> distutils/build ->..\n    #  setuptools/bdist_wheel -> distutils/install ->..\n    #  setuptools/bdist_egg -> distutils/install_lib -> build_py\n    #  setuptools/install -> bdist_egg ->..\n    #  setuptools/develop -> ?\n    #  pip install:\n    #   copies source tree to a tempdir before running egg_info/etc\n    #   if .git isn\'t copied too, \'git describe\' will fail\n    #   then does setup.py bdist_wheel, or sometimes setup.py install\n    #  setup.py egg_info -> ?\n\n    # we override different ""build_py"" commands for both environments\n    if ""setuptools"" in sys.modules:\n        from setuptools.command.build_py import build_py as _build_py\n    else:\n        from distutils.command.build_py import build_py as _build_py\n\n    class cmd_build_py(_build_py):\n        def run(self):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_py.run(self)\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            if cfg.versionfile_build:\n                target_versionfile = os.path.join(self.build_lib,\n                                                  cfg.versionfile_build)\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n    cmds[""build_py""] = cmd_build_py\n\n    if ""cx_Freeze"" in sys.modules:  # cx_freeze enabled?\n        from cx_Freeze.dist import build_exe as _build_exe\n        # nczeczulin reports that py2exe won\'t like the pep440-style string\n        # as FILEVERSION, but it can be used for PRODUCTVERSION, e.g.\n        # setup(console=[{\n        #   ""version"": versioneer.get_version().split(""+"", 1)[0], # FILEVERSION\n        #   ""product_version"": versioneer.get_version(),\n        #   ...\n\n        class cmd_build_exe(_build_exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _build_exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, ""w"") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {""DOLLAR"": ""$"",\n                             ""STYLE"": cfg.style,\n                             ""TAG_PREFIX"": cfg.tag_prefix,\n                             ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                             ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                             })\n        cmds[""build_exe""] = cmd_build_exe\n        del cmds[""build_py""]\n\n    if \'py2exe\' in sys.modules:  # py2exe enabled?\n        try:\n            from py2exe.distutils_buildexe import py2exe as _py2exe  # py3\n        except ImportError:\n            from py2exe.build_exe import py2exe as _py2exe  # py2\n\n        class cmd_py2exe(_py2exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _py2exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, ""w"") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {""DOLLAR"": ""$"",\n                             ""STYLE"": cfg.style,\n                             ""TAG_PREFIX"": cfg.tag_prefix,\n                             ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                             ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                             })\n        cmds[""py2exe""] = cmd_py2exe\n\n    # we override different ""sdist"" commands for both environments\n    if ""setuptools"" in sys.modules:\n        from setuptools.command.sdist import sdist as _sdist\n    else:\n        from distutils.command.sdist import sdist as _sdist\n\n    class cmd_sdist(_sdist):\n        def run(self):\n            versions = get_versions()\n            self._versioneer_generated_versions = versions\n            # unless we update this, the command will keep using the old\n            # version\n            self.distribution.metadata.version = versions[""version""]\n            return _sdist.run(self)\n\n        def make_release_tree(self, base_dir, files):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            _sdist.make_release_tree(self, base_dir, files)\n            # now locate _version.py in the new base_dir directory\n            # (remembering that it may be a hardlink) and replace it with an\n            # updated value\n            target_versionfile = os.path.join(base_dir, cfg.versionfile_source)\n            print(""UPDATING %s"" % target_versionfile)\n            write_to_version_file(target_versionfile,\n                                  self._versioneer_generated_versions)\n    cmds[""sdist""] = cmd_sdist\n\n    return cmds\n\n\nCONFIG_ERROR = """"""\nsetup.cfg is missing the necessary Versioneer configuration. You need\na section like:\n\n [versioneer]\n VCS = git\n style = pep440\n versionfile_source = src/myproject/_version.py\n versionfile_build = myproject/_version.py\n tag_prefix =\n parentdir_prefix = myproject-\n\nYou will also need to edit your setup.py to use the results:\n\n import versioneer\n setup(version=versioneer.get_version(),\n       cmdclass=versioneer.get_cmdclass(), ...)\n\nPlease read the docstring in ./versioneer.py for configuration instructions,\nedit setup.cfg, and re-run the installer or \'python versioneer.py setup\'.\n""""""\n\nSAMPLE_CONFIG = """"""\n# See the docstring in versioneer.py for instructions. Note that you must\n# re-run \'versioneer.py setup\' after changing this section, and commit the\n# resulting files.\n\n[versioneer]\n#VCS = git\n#style = pep440\n#versionfile_source =\n#versionfile_build =\n#tag_prefix =\n#parentdir_prefix =\n\n""""""\n\nINIT_PY_SNIPPET = """"""\nfrom ._version import get_versions\n__version__ = get_versions()[\'version\']\ndel get_versions\n""""""\n\n\ndef do_setup():\n    """"""Main VCS-independent setup function for installing Versioneer.""""""\n    root = get_root()\n    try:\n        cfg = get_config_from_root(root)\n    except (EnvironmentError, configparser.NoSectionError,\n            configparser.NoOptionError) as e:\n        if isinstance(e, (EnvironmentError, configparser.NoSectionError)):\n            print(""Adding sample versioneer config to setup.cfg"",\n                  file=sys.stderr)\n            with open(os.path.join(root, ""setup.cfg""), ""a"") as f:\n                f.write(SAMPLE_CONFIG)\n        print(CONFIG_ERROR, file=sys.stderr)\n        return 1\n\n    print("" creating %s"" % cfg.versionfile_source)\n    with open(cfg.versionfile_source, ""w"") as f:\n        LONG = LONG_VERSION_PY[cfg.VCS]\n        f.write(LONG % {""DOLLAR"": ""$"",\n                        ""STYLE"": cfg.style,\n                        ""TAG_PREFIX"": cfg.tag_prefix,\n                        ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                        ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                        })\n\n    ipy = os.path.join(os.path.dirname(cfg.versionfile_source),\n                       ""__init__.py"")\n    if os.path.exists(ipy):\n        try:\n            with open(ipy, ""r"") as f:\n                old = f.read()\n        except EnvironmentError:\n            old = """"\n        if INIT_PY_SNIPPET not in old:\n            print("" appending to %s"" % ipy)\n            with open(ipy, ""a"") as f:\n                f.write(INIT_PY_SNIPPET)\n        else:\n            print("" %s unmodified"" % ipy)\n    else:\n        print("" %s doesn\'t exist, ok"" % ipy)\n        ipy = None\n\n    # Make sure both the top-level ""versioneer.py"" and versionfile_source\n    # (PKG/_version.py, used by runtime code) are in MANIFEST.in, so\n    # they\'ll be copied into source distributions. Pip won\'t be able to\n    # install the package without this.\n    manifest_in = os.path.join(root, ""MANIFEST.in"")\n    simple_includes = set()\n    try:\n        with open(manifest_in, ""r"") as f:\n            for line in f:\n                if line.startswith(""include ""):\n                    for include in line.split()[1:]:\n                        simple_includes.add(include)\n    except EnvironmentError:\n        pass\n    # That doesn\'t cover everything MANIFEST.in can do\n    # (http://docs.python.org/2/distutils/sourcedist.html#commands), so\n    # it might give some false negatives. Appending redundant \'include\'\n    # lines is safe, though.\n    if ""versioneer.py"" not in simple_includes:\n        print("" appending \'versioneer.py\' to MANIFEST.in"")\n        with open(manifest_in, ""a"") as f:\n            f.write(""include versioneer.py\\n"")\n    else:\n        print("" \'versioneer.py\' already in MANIFEST.in"")\n    if cfg.versionfile_source not in simple_includes:\n        print("" appending versionfile_source (\'%s\') to MANIFEST.in"" %\n              cfg.versionfile_source)\n        with open(manifest_in, ""a"") as f:\n            f.write(""include %s\\n"" % cfg.versionfile_source)\n    else:\n        print("" versionfile_source already in MANIFEST.in"")\n\n    # Make VCS-specific changes. For git, this means creating/changing\n    # .gitattributes to mark _version.py for export-subst keyword\n    # substitution.\n    do_vcs_install(manifest_in, cfg.versionfile_source, ipy)\n    return 0\n\n\ndef scan_setup_py():\n    """"""Validate the contents of setup.py against Versioneer\'s expectations.""""""\n    found = set()\n    setters = False\n    errors = 0\n    with open(""setup.py"", ""r"") as f:\n        for line in f.readlines():\n            if ""import versioneer"" in line:\n                found.add(""import"")\n            if ""versioneer.get_cmdclass()"" in line:\n                found.add(""cmdclass"")\n            if ""versioneer.get_version()"" in line:\n                found.add(""get_version"")\n            if ""versioneer.VCS"" in line:\n                setters = True\n            if ""versioneer.versionfile_source"" in line:\n                setters = True\n    if len(found) != 3:\n        print("""")\n        print(""Your setup.py appears to be missing some important items"")\n        print(""(but I might be wrong). Please make sure it has something"")\n        print(""roughly like the following:"")\n        print("""")\n        print("" import versioneer"")\n        print("" setup( version=versioneer.get_version(),"")\n        print(""        cmdclass=versioneer.get_cmdclass(),  ...)"")\n        print("""")\n        errors += 1\n    if setters:\n        print(""You should remove lines like \'versioneer.VCS = \' and"")\n        print(""\'versioneer.versionfile_source = \' . This configuration"")\n        print(""now lives in setup.cfg, and should be removed from setup.py"")\n        print("""")\n        errors += 1\n    return errors\n\n\nif __name__ == ""__main__"":\n    cmd = sys.argv[1]\n    if cmd == ""setup"":\n        errors = do_setup()\n        errors += scan_setup_py()\n        if errors:\n            sys.exit(1)\n'"
benchmarks/logwriter.py,0,"b'""""""\nA benchmark for eliot.logwriter.\n""""""\n\nimport tempfile\nimport time\n\nfrom twisted.internet.task import react\nfrom twisted.python.filepath import FilePath\n\nfrom eliot.logwriter import ThreadedFileWriter\n\n\nLENGTH = 100\nMESSAGES = 100000\n\n\ndef main(reactor):\n    print(""Message size: %d bytes   Num messages: %d"" % (LENGTH, MESSAGES))\n    message = b""a"" * LENGTH\n    fp = FilePath(tempfile.mktemp())\n    writer = ThreadedFileWriter(fp.open(""ab""), reactor)\n    writer.startService()\n\n    start = time.time()\n    for i in range(MESSAGES):\n        writer(message)\n    d = writer.stopService()\n\n    def done(_):\n        elapsed = time.time() - start\n        kbSec = (LENGTH * MESSAGES) / (elapsed * 1024)\n        messagesSec = MESSAGES / elapsed\n        print(""messages/sec: %s   KB/sec: %s"" % (messagesSec, kbSec))\n\n    d.addCallback(done)\n\n    def cleanup(result):\n        fp.restat()\n        print()\n        print(""File size: "", fp.getsize())\n        fp.remove()\n\n    d.addBoth(cleanup)\n    return d\n\n\nif __name__ == ""__main__"":\n    react(main, [])\n'"
benchmarks/serialization.py,0,"b'""""""\nBenchmark of message serialization.\n\nThe goal here is to mostly focus on performance of serialization, in a vaguely\nrealistic manner. That is, mesages are logged in context of a message with a\nsmall number of fields.\n""""""\n\nfrom __future__ import unicode_literals\n\nimport time\n\nfrom eliot import Message, start_action, to_file\n\n# Ensure JSON serialization is part of benchmark:\nto_file(open(""/dev/null"", ""w""))\n\nN = 10000\n\n\ndef run():\n    start = time.time()\n    for i in range(N):\n        with start_action(action_type=""my_action""):\n            with start_action(action_type=""my_action2"") as ctx:\n                ctx.log(\n                    message_type=""my_message"",\n                    integer=3,\n                    string=""abcdeft"",\n                    string2=""dgsjdlkgjdsl"",\n                    list=[1, 2, 3, 4],\n                )\n    end = time.time()\n\n    # Each iteration has 5 messages: start/end of my_action, start/end of\n    # my_action2, and my_message.\n    print(""%.6f per message"" % ((end - start) / (N * 5),))\n    print(""%s messages/sec"" % (int(N / (end - start)),))\n\n\nif __name__ == ""__main__"":\n    run()\n'"
eliot/__init__.py,0,"b'""""""\nEliot: Logging for Complex & Distributed Systems.\n""""""\nfrom warnings import warn\nfrom sys import version_info\n\n# Enable asyncio contextvars support in Python 3.5/3.6:\nif version_info < (3, 7):\n    # On Python 3.5.2 and earlier, some of the necessary attributes aren\'t exposed:\n    if version_info < (3, 5, 3):\n        raise RuntimeError(\n            ""This version of Eliot doesn\'t work on Python 3.5.2 or earlier. ""\n            ""Either upgrade to Python 3.5.3 or later (on Ubuntu 16.04 ""\n            ""you can use https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa ""\n            ""to get Python 3.6), or pin Eliot to version 1.7.""\n        )\n    import aiocontextvars\n\n    dir(aiocontextvars)  # pacify pyflakes\n    del aiocontextvars\n\n# Expose the public API:\nfrom ._message import Message\nfrom ._action import (\n    start_action,\n    startTask,\n    Action,\n    preserve_context,\n    current_action,\n    log_call,\n    log_message,\n)\nfrom ._output import ILogger, Logger, MemoryLogger, to_file, FileDestination\nfrom ._validation import Field, fields, MessageType, ActionType, ValidationError\nfrom ._traceback import write_traceback, writeFailure\nfrom ._errors import register_exception_extractor\nfrom ._version import get_versions\n\n# Backwards compatibility:\ndef add_destination(destination):\n    warn(\n        ""add_destination is deprecated since 1.1.0. "" ""Use add_destinations instead."",\n        DeprecationWarning,\n        stacklevel=2,\n    )\n    Logger._destinations.add(destination)\n\n\n# Backwards compatibility:\ndef use_asyncio_context():\n    warn(\n        ""This function is no longer as needed as of Eliot 1.8.0."",\n        DeprecationWarning,\n        stacklevel=2,\n    )\n\n\n# Backwards compatibilty:\naddDestination = add_destination\nremoveDestination = Logger._destinations.remove\naddGlobalFields = Logger._destinations.addGlobalFields\nwriteTraceback = write_traceback\nstartAction = start_action\n\n# PEP 8 variants:\nstart_task = startTask\nwrite_failure = writeFailure\nadd_destinations = Logger._destinations.add\nremove_destination = removeDestination\nadd_global_fields = addGlobalFields\n\n# Backwards compatibility for old versions of eliot-tree, which rely on\n# eliot._parse:\ndef _parse_compat():\n    # Force eliot.parse to be imported in way that works with old Python:\n    from .parse import Parser\n\n    del Parser\n    import sys\n\n    sys.modules[""eliot._parse""] = sys.modules[""eliot.parse""]\n    return sys.modules[""eliot.parse""]\n\n\n_parse = _parse_compat()\ndel _parse_compat\n\n\n__all__ = [\n    ""Message"",\n    ""writeTraceback"",\n    ""writeFailure"",\n    ""startAction"",\n    ""startTask"",\n    ""Action"",\n    ""preserve_context"",\n    ""Field"",\n    ""fields"",\n    ""MessageType"",\n    ""ActionType"",\n    ""ILogger"",\n    ""Logger"",\n    ""MemoryLogger"",\n    ""addDestination"",\n    ""removeDestination"",\n    ""addGlobalFields"",\n    ""FileDestination"",\n    ""register_exception_extractor"",\n    ""current_action"",\n    ""use_asyncio_context"",\n    ""ValidationError"",\n    # PEP 8 variants:\n    ""write_traceback"",\n    ""write_failure"",\n    ""start_action"",\n    ""start_task"",\n    ""add_destination"",\n    ""add_destinations"",\n    ""remove_destination"",\n    ""add_global_fields"",\n    ""to_file"",\n    ""log_call"",\n    ""log_message"",\n    ""__version__"",\n    # Backwards compat for eliot-tree:\n    ""_parse"",\n]\n\n\n__version__ = get_versions()[""version""]\ndel get_versions\n'"
eliot/_action.py,0,"b'""""""\nSupport for actions and tasks.\n\nActions have a beginning and an eventual end, and can be nested. Tasks are\ntop-level actions.\n""""""\n\nfrom __future__ import unicode_literals, absolute_import\n\nimport threading\nfrom uuid import uuid4\nfrom contextlib import contextmanager\nfrom functools import partial\nfrom inspect import getcallargs\nfrom contextvars import ContextVar\n\nfrom pyrsistent import field, PClass, optional, pmap_field, pvector\nfrom boltons.funcutils import wraps\nfrom six import text_type as unicode, PY3\n\nfrom ._message import (\n    WrittenMessage,\n    EXCEPTION_FIELD,\n    REASON_FIELD,\n    TASK_UUID_FIELD,\n    MESSAGE_TYPE_FIELD,\n)\nfrom ._util import safeunicode\nfrom ._errors import _error_extraction\n\nACTION_STATUS_FIELD = ""action_status""\nACTION_TYPE_FIELD = ""action_type""\n\nSTARTED_STATUS = ""started""\nSUCCEEDED_STATUS = ""succeeded""\nFAILED_STATUS = ""failed""\n\nVALID_STATUSES = (STARTED_STATUS, SUCCEEDED_STATUS, FAILED_STATUS)\n\n_ACTION_CONTEXT = ContextVar(""eliot.action"")\n\nfrom ._message import TIMESTAMP_FIELD, TASK_LEVEL_FIELD\n\n\ndef current_action():\n    """"""\n    @return: The current C{Action} in context, or C{None} if none were set.\n    """"""\n    return _ACTION_CONTEXT.get(None)\n\n\nclass TaskLevel(object):\n    """"""\n    The location of a message within the tree of actions of a task.\n\n    @ivar level: A pvector of integers. Each item indicates a child\n        relationship, and the value indicates message count. E.g. C{[2,\n        3]} indicates this is the third message within an action which is\n        the second item in the task.\n    """"""\n\n    def __init__(self, level):\n        self._level = level\n\n    def as_list(self):\n        """"""Return the current level.\n\n        @return: List of integers.\n        """"""\n        return self._level[:]\n\n    # Backwards compatibility:\n    @property\n    def level(self):\n        return pvector(self._level)\n\n    def __lt__(self, other):\n        return self._level < other._level\n\n    def __le__(self, other):\n        return self._level <= other._level\n\n    def __gt__(self, other):\n        return self._level > other._level\n\n    def __ge__(self, other):\n        return self._level >= other._level\n\n    def __eq__(self, other):\n        if other.__class__ != TaskLevel:\n            return False\n        return self._level == other._level\n\n    def __ne__(self, other):\n        if other.__class__ != TaskLevel:\n            return True\n        return self._level != other._level\n\n    def __hash__(self):\n        return hash(tuple(self._level))\n\n    @classmethod\n    def fromString(cls, string):\n        """"""\n        Convert a serialized Unicode string to a L{TaskLevel}.\n\n        @param string: Output of L{TaskLevel.toString}.\n\n        @return: L{TaskLevel} parsed from the string.\n        """"""\n        return cls(level=[int(i) for i in string.split(""/"") if i])\n\n    def toString(self):\n        """"""\n        Convert to a Unicode string, for serialization purposes.\n\n        @return: L{unicode} representation of the L{TaskLevel}.\n        """"""\n        return ""/"" + ""/"".join(map(unicode, self._level))\n\n    def next_sibling(self):\n        """"""\n        Return the next L{TaskLevel}, that is a task at the same level as this\n        one, but one after.\n\n        @return: L{TaskLevel} which follows this one.\n        """"""\n        new_level = self._level[:]\n        new_level[-1] += 1\n        return TaskLevel(level=new_level)\n\n    def child(self):\n        """"""\n        Return a child of this L{TaskLevel}.\n\n        @return: L{TaskLevel} which is the first child of this one.\n        """"""\n        new_level = self._level[:]\n        new_level.append(1)\n        return TaskLevel(level=new_level)\n\n    def parent(self):\n        """"""\n        Return the parent of this L{TaskLevel}, or C{None} if it doesn\'t have\n        one.\n\n        @return: L{TaskLevel} which is the parent of this one.\n        """"""\n        if not self._level:\n            return None\n        return TaskLevel(level=self._level[:-1])\n\n    def is_sibling_of(self, task_level):\n        """"""\n        Is this task a sibling of C{task_level}?\n        """"""\n        return self.parent() == task_level.parent()\n\n    # PEP 8 compatibility:\n    from_string = fromString\n    to_string = toString\n\n\n_TASK_ID_NOT_SUPPLIED = object()\n\nimport time\n\n\nclass Action(object):\n    """"""\n    Part of a nested heirarchy of ongoing actions.\n\n    An action has a start and an end; a message is logged for each.\n\n    Actions should only be used from a single thread, by implication the\n    thread where they were created.\n\n    @ivar _identification: Fields identifying this action.\n\n    @ivar _successFields: Fields to be included in successful finish message.\n\n    @ivar _finished: L{True} if the L{Action} has finished, otherwise L{False}.\n    """"""\n\n    def __init__(self, logger, task_uuid, task_level, action_type, serializers=None):\n        """"""\n        Initialize the L{Action} and log the start message.\n\n        You probably do not want to use this API directly: use L{start_action}\n        or L{startTask} instead.\n\n        @param logger: The L{eliot.ILogger} to which to write\n            messages.\n\n        @param task_uuid: The uuid of the top-level task, e.g. C{""123525""}.\n\n        @param task_level: The action\'s level in the task.\n        @type task_level: L{TaskLevel}\n\n        @param action_type: The type of the action,\n            e.g. C{""yourapp:subsystem:dosomething""}.\n\n        @param serializers: Either a L{eliot._validation._ActionSerializers}\n            instance or C{None}. In the latter case no validation or\n            serialization will be done for messages generated by the\n            L{Action}.\n        """"""\n        self._successFields = {}\n        self._logger = _output._DEFAULT_LOGGER if (logger is None) else logger\n        self._task_level = task_level\n        self._last_child = None\n        self._identification = {\n            TASK_UUID_FIELD: task_uuid,\n            ACTION_TYPE_FIELD: action_type,\n        }\n        self._serializers = serializers\n        self._finished = False\n\n    @property\n    def task_uuid(self):\n        """"""\n        @return str: the current action\'s task UUID.\n        """"""\n        return self._identification[TASK_UUID_FIELD]\n\n    def serialize_task_id(self):\n        """"""\n        Create a unique identifier for the current location within the task.\n\n        The format is C{b""<task_uuid>@<task_level>""}.\n\n        @return: L{bytes} encoding the current location within the task.\n        """"""\n        return ""{}@{}"".format(\n            self._identification[TASK_UUID_FIELD], self._nextTaskLevel().toString()\n        ).encode(""ascii"")\n\n    @classmethod\n    def continue_task(cls, logger=None, task_id=_TASK_ID_NOT_SUPPLIED):\n        """"""\n        Start a new action which is part of a serialized task.\n\n        @param logger: The L{eliot.ILogger} to which to write\n            messages, or C{None} if the default one should be used.\n\n        @param task_id: A serialized task identifier, the output of\n            L{Action.serialize_task_id}, either ASCII-encoded bytes or unicode\n            string. Required.\n\n        @return: The new L{Action} instance.\n        """"""\n        if task_id is _TASK_ID_NOT_SUPPLIED:\n            raise RuntimeError(""You must supply a task_id keyword argument."")\n        if isinstance(task_id, bytes):\n            task_id = task_id.decode(""ascii"")\n        uuid, task_level = task_id.split(""@"")\n        action = cls(\n            logger, uuid, TaskLevel.fromString(task_level), ""eliot:remote_task""\n        )\n        action._start({})\n        return action\n\n    # Backwards-compat variants:\n    serializeTaskId = serialize_task_id\n    continueTask = continue_task\n\n    def _nextTaskLevel(self):\n        """"""\n        Return the next C{task_level} for messages within this action.\n\n        Called whenever a message is logged within the context of an action.\n\n        @return: The message\'s C{task_level}.\n        """"""\n        if not self._last_child:\n            self._last_child = self._task_level.child()\n        else:\n            self._last_child = self._last_child.next_sibling()\n        return self._last_child\n\n    def _start(self, fields):\n        """"""\n        Log the start message.\n\n        The action identification fields, and any additional given fields,\n        will be logged.\n\n        In general you shouldn\'t call this yourself, instead using a C{with}\n        block or L{Action.finish}.\n        """"""\n        fields[ACTION_STATUS_FIELD] = STARTED_STATUS\n        fields[TIMESTAMP_FIELD] = time.time()\n        fields.update(self._identification)\n        fields[TASK_LEVEL_FIELD] = self._nextTaskLevel().as_list()\n        if self._serializers is None:\n            serializer = None\n        else:\n            serializer = self._serializers.start\n        self._logger.write(fields, serializer)\n\n    def finish(self, exception=None):\n        """"""\n        Log the finish message.\n\n        The action identification fields, and any additional given fields,\n        will be logged.\n\n        In general you shouldn\'t call this yourself, instead using a C{with}\n        block or L{Action.finish}.\n\n        @param exception: C{None}, in which case the fields added with\n            L{Action.addSuccessFields} are used. Or an L{Exception}, in\n            which case an C{""exception""} field is added with the given\n            L{Exception} type and C{""reason""} with its contents.\n        """"""\n        if self._finished:\n            return\n        self._finished = True\n        serializer = None\n        if exception is None:\n            fields = self._successFields\n            fields[ACTION_STATUS_FIELD] = SUCCEEDED_STATUS\n            if self._serializers is not None:\n                serializer = self._serializers.success\n        else:\n            fields = _error_extraction.get_fields_for_exception(self._logger, exception)\n            fields[EXCEPTION_FIELD] = ""%s.%s"" % (\n                exception.__class__.__module__,\n                exception.__class__.__name__,\n            )\n            fields[REASON_FIELD] = safeunicode(exception)\n            fields[ACTION_STATUS_FIELD] = FAILED_STATUS\n            if self._serializers is not None:\n                serializer = self._serializers.failure\n\n        fields[TIMESTAMP_FIELD] = time.time()\n        fields.update(self._identification)\n        fields[TASK_LEVEL_FIELD] = self._nextTaskLevel().as_list()\n        self._logger.write(fields, serializer)\n\n    def child(self, logger, action_type, serializers=None):\n        """"""\n        Create a child L{Action}.\n\n        Rather than calling this directly, you can use L{start_action} to\n        create child L{Action} using the execution context.\n\n        @param logger: The L{eliot.ILogger} to which to write\n            messages.\n\n        @param action_type: The type of this action,\n            e.g. C{""yourapp:subsystem:dosomething""}.\n\n        @param serializers: Either a L{eliot._validation._ActionSerializers}\n            instance or C{None}. In the latter case no validation or\n            serialization will be done for messages generated by the\n            L{Action}.\n        """"""\n        newLevel = self._nextTaskLevel()\n        return self.__class__(\n            logger,\n            self._identification[TASK_UUID_FIELD],\n            newLevel,\n            action_type,\n            serializers,\n        )\n\n    def run(self, f, *args, **kwargs):\n        """"""\n        Run the given function with this L{Action} as its execution context.\n        """"""\n        parent = _ACTION_CONTEXT.set(self)\n        try:\n            return f(*args, **kwargs)\n        finally:\n            _ACTION_CONTEXT.reset(parent)\n\n    def addSuccessFields(self, **fields):\n        """"""\n        Add fields to be included in the result message when the action\n        finishes successfully.\n\n        @param fields: Additional fields to add to the result message.\n        """"""\n        self._successFields.update(fields)\n\n    # PEP 8 variant:\n    add_success_fields = addSuccessFields\n\n    @contextmanager\n    def context(self):\n        """"""\n        Create a context manager that ensures code runs within action\'s context.\n\n        The action does NOT finish when the context is exited.\n        """"""\n        parent = _ACTION_CONTEXT.set(self)\n        try:\n            yield self\n        finally:\n            _ACTION_CONTEXT.reset(parent)\n\n    # Python context manager implementation:\n    def __enter__(self):\n        """"""\n        Push this action onto the execution context.\n        """"""\n        self._parent_token = _ACTION_CONTEXT.set(self)\n        return self\n\n    def __exit__(self, type, exception, traceback):\n        """"""\n        Pop this action off the execution context, log finish message.\n        """"""\n        _ACTION_CONTEXT.reset(self._parent_token)\n        self._parent_token = None\n        self.finish(exception)\n\n    ## Message logging\n    def log(self, message_type, **fields):\n        """"""Log individual message.""""""\n        fields[TIMESTAMP_FIELD] = time.time()\n        fields[TASK_UUID_FIELD] = self._identification[TASK_UUID_FIELD]\n        fields[TASK_LEVEL_FIELD] = self._nextTaskLevel().as_list()\n        fields[MESSAGE_TYPE_FIELD] = message_type\n        self._logger.write(fields, fields.pop(""__eliot_serializer__"", None))\n\n\nclass WrongTask(Exception):\n    """"""\n    Tried to add a message to an action, but the message was from another\n    task.\n    """"""\n\n    def __init__(self, action, message):\n        Exception.__init__(\n            self,\n            ""Tried to add {} to {}. Expected task_uuid = {}, got {}"".format(\n                message, action, action.task_uuid, message.task_uuid\n            ),\n        )\n\n\nclass WrongTaskLevel(Exception):\n    """"""\n    Tried to add a message to an action, but the task level of the message\n    indicated that it was not a direct child.\n    """"""\n\n    def __init__(self, action, message):\n        Exception.__init__(\n            self,\n            ""Tried to add {} to {}, but {} is not a sibling of {}"".format(\n                message, action, message.task_level, action.task_level\n            ),\n        )\n\n\nclass WrongActionType(Exception):\n    """"""\n    Tried to end a message with a different action_type than the beginning.\n    """"""\n\n    def __init__(self, action, message):\n        error_msg = ""Tried to end {} with {}. Expected action_type = {}, got {}""\n        Exception.__init__(\n            self,\n            error_msg.format(\n                action,\n                message,\n                action.action_type,\n                message.contents.get(ACTION_TYPE_FIELD, ""<undefined>""),\n            ),\n        )\n\n\nclass InvalidStatus(Exception):\n    """"""\n    Tried to end a message with an invalid status.\n    """"""\n\n    def __init__(self, action, message):\n        error_msg = ""Tried to end {} with {}. Expected status {} or {}, got {}""\n        Exception.__init__(\n            self,\n            error_msg.format(\n                action,\n                message,\n                SUCCEEDED_STATUS,\n                FAILED_STATUS,\n                message.contents.get(ACTION_STATUS_FIELD, ""<undefined>""),\n            ),\n        )\n\n\nclass DuplicateChild(Exception):\n    """"""\n    Tried to add a child to an action that already had a child at that task\n    level.\n    """"""\n\n    def __init__(self, action, message):\n        Exception.__init__(\n            self,\n            ""Tried to add {} to {}, but already had child at {}"".format(\n                message, action, message.task_level\n            ),\n        )\n\n\nclass InvalidStartMessage(Exception):\n    """"""\n    Tried to start an action with an invalid message.\n    """"""\n\n    def __init__(self, message, reason):\n        Exception.__init__(self, ""Invalid start message {}: {}"".format(message, reason))\n\n    @classmethod\n    def wrong_status(cls, message):\n        return cls(message, \'must have status ""STARTED""\')\n\n    @classmethod\n    def wrong_task_level(cls, message):\n        return cls(message, ""first message must have task level ending in 1"")\n\n\nclass WrittenAction(PClass):\n    """"""\n    An Action that has been logged.\n\n    This class is intended to provide a definition within Eliot of what an\n    action actually is, and a means of constructing actions that are known to\n    be valid.\n\n    @ivar WrittenMessage start_message: A start message whose task UUID and\n        level match this action, or C{None} if it is not yet set on the\n        action.\n    @ivar WrittenMessage end_message: An end message hose task UUID and\n        level match this action. Can be C{None} if the action is\n        unfinished.\n    @ivar TaskLevel task_level: The action\'s task level, e.g. if start\n        message has level C{[2, 3, 1]} it will be\n        C{TaskLevel(level=[2, 3])}.\n    @ivar UUID task_uuid: The UUID of the task to which this action belongs.\n    @ivar _children: A L{pmap} from L{TaskLevel} to the L{WrittenAction} and\n        L{WrittenMessage} objects that make up this action.\n    """"""\n\n    start_message = field(type=optional(WrittenMessage), mandatory=True, initial=None)\n    end_message = field(type=optional(WrittenMessage), mandatory=True, initial=None)\n    task_level = field(type=TaskLevel, mandatory=True)\n    task_uuid = field(type=unicode, mandatory=True, factory=unicode)\n    # Pyrsistent doesn\'t support pmap_field with recursive types.\n    _children = pmap_field(TaskLevel, object)\n\n    @classmethod\n    def from_messages(cls, start_message=None, children=pvector(), end_message=None):\n        """"""\n        Create a C{WrittenAction} from C{WrittenMessage}s and other\n        C{WrittenAction}s.\n\n        @param WrittenMessage start_message: A message that has\n            C{ACTION_STATUS_FIELD}, C{ACTION_TYPE_FIELD}, and a C{task_level}\n            that ends in C{1}, or C{None} if unavailable.\n        @param children: An iterable of C{WrittenMessage} and C{WrittenAction}\n        @param WrittenMessage end_message: A message that has the same\n            C{action_type} as this action.\n\n        @raise WrongTask: If C{end_message} has a C{task_uuid} that differs\n            from C{start_message.task_uuid}.\n        @raise WrongTaskLevel: If any child message or C{end_message} has a\n            C{task_level} that means it is not a direct child.\n        @raise WrongActionType: If C{end_message} has an C{ACTION_TYPE_FIELD}\n            that differs from the C{ACTION_TYPE_FIELD} of C{start_message}.\n        @raise InvalidStatus: If C{end_message} doesn\'t have an\n            C{action_status}, or has one that is not C{SUCCEEDED_STATUS} or\n            C{FAILED_STATUS}.\n        @raise InvalidStartMessage: If C{start_message} does not have a\n            C{ACTION_STATUS_FIELD} of C{STARTED_STATUS}, or if it has a\n            C{task_level} indicating that it is not the first message of an\n            action.\n\n        @return: A new C{WrittenAction}.\n        """"""\n        actual_message = [\n            message\n            for message in [start_message, end_message] + list(children)\n            if message\n        ][0]\n        action = cls(\n            task_level=actual_message.task_level.parent(),\n            task_uuid=actual_message.task_uuid,\n        )\n        if start_message:\n            action = action._start(start_message)\n        for child in children:\n            if action._children.get(child.task_level, child) != child:\n                raise DuplicateChild(action, child)\n            action = action._add_child(child)\n        if end_message:\n            action = action._end(end_message)\n        return action\n\n    @property\n    def action_type(self):\n        """"""\n        The type of this action, e.g. C{""yourapp:subsystem:dosomething""}.\n        """"""\n        if self.start_message:\n            return self.start_message.contents[ACTION_TYPE_FIELD]\n        elif self.end_message:\n            return self.end_message.contents[ACTION_TYPE_FIELD]\n        else:\n            return None\n\n    @property\n    def status(self):\n        """"""\n        One of C{STARTED_STATUS}, C{SUCCEEDED_STATUS}, C{FAILED_STATUS} or\n        C{None}.\n        """"""\n        message = self.end_message if self.end_message else self.start_message\n        if message:\n            return message.contents[ACTION_STATUS_FIELD]\n        else:\n            return None\n\n    @property\n    def start_time(self):\n        """"""\n        The Unix timestamp of when the action started, or C{None} if there has\n        been no start message added so far.\n        """"""\n        if self.start_message:\n            return self.start_message.timestamp\n\n    @property\n    def end_time(self):\n        """"""\n        The Unix timestamp of when the action ended, or C{None} if there has been\n        no end message.\n        """"""\n        if self.end_message:\n            return self.end_message.timestamp\n\n    @property\n    def exception(self):\n        """"""\n        If the action failed, the name of the exception that was raised to cause\n        it to fail. If the action succeeded, or hasn\'t finished yet, then\n        C{None}.\n        """"""\n        if self.end_message:\n            return self.end_message.contents.get(EXCEPTION_FIELD, None)\n\n    @property\n    def reason(self):\n        """"""\n        The reason the action failed. If the action succeeded, or hasn\'t finished\n        yet, then C{None}.\n        """"""\n        if self.end_message:\n            return self.end_message.contents.get(REASON_FIELD, None)\n\n    @property\n    def children(self):\n        """"""\n        The list of child messages and actions sorted by task level, excluding the\n        start and end messages.\n        """"""\n        return pvector(sorted(self._children.values(), key=lambda m: m.task_level))\n\n    def _validate_message(self, message):\n        """"""\n        Is C{message} a valid direct child of this action?\n\n        @param message: Either a C{WrittenAction} or a C{WrittenMessage}.\n\n        @raise WrongTask: If C{message} has a C{task_uuid} that differs from the\n            action\'s C{task_uuid}.\n        @raise WrongTaskLevel: If C{message} has a C{task_level} that means\n            it\'s not a direct child.\n        """"""\n        if message.task_uuid != self.task_uuid:\n            raise WrongTask(self, message)\n        if not message.task_level.parent() == self.task_level:\n            raise WrongTaskLevel(self, message)\n\n    def _add_child(self, message):\n        """"""\n        Return a new action with C{message} added as a child.\n\n        Assumes C{message} is not an end message.\n\n        @param message: Either a C{WrittenAction} or a C{WrittenMessage}.\n\n        @raise WrongTask: If C{message} has a C{task_uuid} that differs from the\n            action\'s C{task_uuid}.\n        @raise WrongTaskLevel: If C{message} has a C{task_level} that means\n            it\'s not a direct child.\n\n        @return: A new C{WrittenAction}.\n        """"""\n        self._validate_message(message)\n        level = message.task_level\n        return self.transform((""_children"", level), message)\n\n    def _start(self, start_message):\n        """"""\n        Start this action given its start message.\n\n        @param WrittenMessage start_message: A start message that has the\n            same level as this action.\n\n        @raise InvalidStartMessage: If C{start_message} does not have a\n            C{ACTION_STATUS_FIELD} of C{STARTED_STATUS}, or if it has a\n            C{task_level} indicating that it is not the first message of an\n            action.\n        """"""\n        if start_message.contents.get(ACTION_STATUS_FIELD, None) != STARTED_STATUS:\n            raise InvalidStartMessage.wrong_status(start_message)\n        if start_message.task_level.level[-1] != 1:\n            raise InvalidStartMessage.wrong_task_level(start_message)\n        return self.set(start_message=start_message)\n\n    def _end(self, end_message):\n        """"""\n        End this action with C{end_message}.\n\n        Assumes that the action has not already been ended.\n\n        @param WrittenMessage end_message: An end message that has the\n            same level as this action.\n\n        @raise WrongTask: If C{end_message} has a C{task_uuid} that differs\n            from the action\'s C{task_uuid}.\n        @raise WrongTaskLevel: If C{end_message} has a C{task_level} that means\n            it\'s not a direct child.\n        @raise InvalidStatus: If C{end_message} doesn\'t have an\n            C{action_status}, or has one that is not C{SUCCEEDED_STATUS} or\n            C{FAILED_STATUS}.\n\n        @return: A new, completed C{WrittenAction}.\n        """"""\n        action_type = end_message.contents.get(ACTION_TYPE_FIELD, None)\n        if self.action_type not in (None, action_type):\n            raise WrongActionType(self, end_message)\n        self._validate_message(end_message)\n        status = end_message.contents.get(ACTION_STATUS_FIELD, None)\n        if status not in (FAILED_STATUS, SUCCEEDED_STATUS):\n            raise InvalidStatus(self, end_message)\n        return self.set(end_message=end_message)\n\n\ndef start_action(logger=None, action_type="""", _serializers=None, **fields):\n    """"""\n    Create a child L{Action}, figuring out the parent L{Action} from execution\n    context, and log the start message.\n\n    You can use the result as a Python context manager, or use the\n    L{Action.finish} API to explicitly finish it.\n\n         with start_action(logger, ""yourapp:subsystem:dosomething"",\n                          entry=x) as action:\n              do(x)\n              result = something(x * 2)\n              action.addSuccessFields(result=result)\n\n    Or alternatively:\n\n         action = start_action(logger, ""yourapp:subsystem:dosomething"",\n                              entry=x)\n         with action.context():\n              do(x)\n              result = something(x * 2)\n              action.addSuccessFields(result=result)\n         action.finish()\n\n    @param logger: The L{eliot.ILogger} to which to write messages, or\n        C{None} to use the default one.\n\n    @param action_type: The type of this action,\n        e.g. C{""yourapp:subsystem:dosomething""}.\n\n    @param _serializers: Either a L{eliot._validation._ActionSerializers}\n        instance or C{None}. In the latter case no validation or serialization\n        will be done for messages generated by the L{Action}.\n\n    @param fields: Additional fields to add to the start message.\n\n    @return: A new L{Action}.\n    """"""\n    parent = current_action()\n    if parent is None:\n        return startTask(logger, action_type, _serializers, **fields)\n    else:\n        action = parent.child(logger, action_type, _serializers)\n        action._start(fields)\n        return action\n\n\ndef startTask(logger=None, action_type="""", _serializers=None, **fields):\n    """"""\n    Like L{action}, but creates a new top-level L{Action} with no parent.\n\n    @param logger: The L{eliot.ILogger} to which to write messages, or\n        C{None} to use the default one.\n\n    @param action_type: The type of this action,\n        e.g. C{""yourapp:subsystem:dosomething""}.\n\n    @param _serializers: Either a L{eliot._validation._ActionSerializers}\n        instance or C{None}. In the latter case no validation or serialization\n        will be done for messages generated by the L{Action}.\n\n    @param fields: Additional fields to add to the start message.\n\n    @return: A new L{Action}.\n    """"""\n    action = Action(\n        logger, unicode(uuid4()), TaskLevel(level=[]), action_type, _serializers\n    )\n    action._start(fields)\n    return action\n\n\nclass TooManyCalls(Exception):\n    """"""\n    The callable was called more than once.\n\n    This typically indicates a coding bug: the result of\n    C{preserve_context} should only be called once, and\n    C{preserve_context} should therefore be called each time you want to\n    pass the callable to a thread.\n    """"""\n\n\ndef preserve_context(f):\n    """"""\n    Package up the given function with the current Eliot context, and then\n    restore context and call given function when the resulting callable is\n    run. This allows continuing the action context within a different thread.\n\n    The result should only be used once, since it relies on\n    L{Action.serialize_task_id} whose results should only be deserialized\n    once.\n\n    @param f: A callable.\n\n    @return: One-time use callable that calls given function in context of\n        a child of current Eliot action.\n    """"""\n    action = current_action()\n    if action is None:\n        return f\n    task_id = action.serialize_task_id()\n    called = threading.Lock()\n\n    def restore_eliot_context(*args, **kwargs):\n        # Make sure the function has not already been called:\n        if not called.acquire(False):\n            raise TooManyCalls(f)\n\n        with Action.continue_task(task_id=task_id):\n            return f(*args, **kwargs)\n\n    return restore_eliot_context\n\n\ndef log_call(\n    wrapped_function=None, action_type=None, include_args=None, include_result=True\n):\n    """"""Decorator/decorator factory that logs inputs and the return result.\n\n    If used with inputs (i.e. as a decorator factory), it accepts the following\n    parameters:\n\n    @param action_type: The action type to use.  If not given the function name\n        will be used.\n    @param include_args: If given, should be a list of strings, the arguments to log.\n    @param include_result: True by default. If False, the return result isn\'t logged.\n    """"""\n    if wrapped_function is None:\n        return partial(\n            log_call,\n            action_type=action_type,\n            include_args=include_args,\n            include_result=include_result,\n        )\n\n    if action_type is None:\n        if PY3:\n            action_type = ""{}.{}"".format(\n                wrapped_function.__module__, wrapped_function.__qualname__\n            )\n        else:\n            action_type = wrapped_function.__name__\n\n    if PY3 and include_args is not None:\n        from inspect import signature\n\n        sig = signature(wrapped_function)\n        if set(include_args) - set(sig.parameters):\n            raise ValueError(\n                (\n                    ""include_args ({}) lists arguments not in the "" ""wrapped function""\n                ).format(include_args)\n            )\n\n    @wraps(wrapped_function)\n    def logging_wrapper(*args, **kwargs):\n        callargs = getcallargs(wrapped_function, *args, **kwargs)\n\n        # Remove self is it\'s included:\n        if ""self"" in callargs:\n            callargs.pop(""self"")\n\n        # Filter arguments to log, if necessary:\n        if include_args is not None:\n            callargs = {k: callargs[k] for k in include_args}\n\n        with start_action(action_type=action_type, **callargs) as ctx:\n            result = wrapped_function(*args, **kwargs)\n            if include_result:\n                ctx.add_success_fields(result=result)\n            return result\n\n    return logging_wrapper\n\n\ndef log_message(message_type, **fields):\n    """"""Log a message in the context of the current action.\n\n    If there is no current action, a new UUID will be generated.\n    """"""\n    # Loggers will hopefully go away...\n    logger = fields.pop(""__eliot_logger__"", None)\n    action = current_action()\n    if action is None:\n        action = Action(logger, str(uuid4()), TaskLevel(level=[]), """")\n    action.log(message_type, **fields)\n\n\nfrom . import _output\n'"
eliot/_bytesjson.py,0,"b'""""""\nPython 2/3 JSON encoding/decoding, emulating Python 2\'s json module.\n\nPython 3 json module doesn\'t support decoding bytes or encoding. Rather than\nadding isinstance checks in main code path which would slow down Python 2,\ninstead we write our encoder that can support those.\n""""""\n\nfrom __future__ import absolute_import\n\nimport json as pyjson\nimport warnings\n\nfrom six import PY2\n\n\ndef _loads(s):\n    """"""\n    Support decoding bytes.\n    """"""\n    if isinstance(s, bytes):\n        s = s.decode(""utf-8"")\n    return pyjson.loads(s)\n\n\ndef _dumps(obj, cls=pyjson.JSONEncoder):\n    """"""\n    Encode to bytes, and presume bytes in inputs are UTF-8 encoded strings.\n    """"""\n\n    class WithBytes(cls):\n        """"""\n        JSON encoder that supports L{bytes}.\n        """"""\n\n        def default(self, o):\n            if isinstance(o, bytes):\n                warnings.warn(\n                    ""Eliot will soon stop supporting encoding bytes in JSON""\n                    "" on Python 3"",\n                    DeprecationWarning,\n                )\n                return o.decode(""utf-8"")\n            return cls.default(self, o)\n\n    return pyjson.dumps(obj, cls=WithBytes).encode(""utf-8"")\n\n\nif PY2:\n    # No need for the above on Python 2\n    loads, dumps = pyjson.loads, pyjson.dumps\nelse:\n    loads, dumps = _loads, _dumps\n\n__all__ = [""loads"", ""dumps""]\n'"
eliot/_errors.py,0,"b'""""""\nError-handling utility code.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom inspect import getmro\n\n\nclass ErrorExtraction(object):\n    """"""\n    Extract fields from exceptions for failed-action messages.\n\n    @ivar registry: Map exception class to function that extracts fields.\n    """"""\n\n    def __init__(self):\n        self.registry = {}\n\n    def register_exception_extractor(self, exception_class, extractor):\n        """"""\n        Register a function that converts exceptions to fields.\n\n        @param exception_class: Class to register for.\n\n        @param extractor: Single-argument callable that takes an exception\n            of the given class (or a subclass) and returns a dictionary,\n            fields to include in a failed action message.\n        """"""\n        self.registry[exception_class] = extractor\n\n    def get_fields_for_exception(self, logger, exception):\n        """"""\n        Given an exception instance, return fields to add to the failed action\n        message.\n\n        @param logger: ``ILogger`` currently being used.\n        @param exception: An exception instance.\n\n        @return: Dictionary with fields to include.\n        """"""\n        for klass in getmro(exception.__class__):\n            if klass in self.registry:\n                extractor = self.registry[klass]\n                try:\n                    return extractor(exception)\n                except:\n                    from ._traceback import write_traceback\n\n                    write_traceback(logger)\n                    return {}\n        return {}\n\n\n_error_extraction = ErrorExtraction()\nregister_exception_extractor = _error_extraction.register_exception_extractor\nget_fields_for_exception = _error_extraction.get_fields_for_exception\n\n# Default handler for OSError and IOError by registered EnvironmentError:\nregister_exception_extractor(EnvironmentError, lambda e: {""errno"": e.errno})\n'"
eliot/_generators.py,0,"b'""""""\nSupport for maintaining an action context across generator suspension.\n""""""\n\nfrom __future__ import unicode_literals, absolute_import\n\nfrom sys import exc_info\nfrom functools import wraps\nfrom contextlib import contextmanager\nfrom contextvars import copy_context\nfrom weakref import WeakKeyDictionary\n\nfrom . import log_message\n\n\nclass _GeneratorContext(object):\n    """"""Generator sub-context for C{_ExecutionContext}.""""""\n\n    def __init__(self, execution_context):\n        self._execution_context = execution_context\n        self._contexts = WeakKeyDictionary()\n        self._current_generator = None\n\n    def init_stack(self, generator):\n        """"""Create a new stack for the given generator.""""""\n        self._contexts[generator] = copy_context()\n\n    @contextmanager\n    def in_generator(self, generator):\n        """"""Context manager: set the given generator as the current generator.""""""\n        previous_generator = self._current_generator\n        try:\n            self._current_generator = generator\n            yield\n        finally:\n            self._current_generator = previous_generator\n\n\nclass GeneratorSupportNotEnabled(Exception):\n    """"""\n    An attempt was made to use a decorated generator without first turning on\n    the generator context manager.\n    """"""\n\n\ndef eliot_friendly_generator_function(original):\n    """"""\n    Decorate a generator function so that the Eliot action context is\n    preserved across ``yield`` expressions.\n    """"""\n\n    @wraps(original)\n    def wrapper(*a, **kw):\n        # Keep track of whether the next value to deliver to the generator is\n        # a non-exception or an exception.\n        ok = True\n\n        # Keep track of the next value to deliver to the generator.\n        value_in = None\n\n        # Create the generator with a call to the generator function.  This\n        # happens with whatever Eliot action context happens to be active,\n        # which is fine and correct and also irrelevant because no code in the\n        # generator function can run until we call send or throw on it.\n        gen = original(*a, **kw)\n\n        # Initialize the per-generator context to a copy of the current context.\n        context = copy_context()\n        while True:\n            try:\n                # Whichever way we invoke the generator, we will do it\n                # with the Eliot action context stack we\'ve saved for it.\n                # Then the context manager will re-save it and restore the\n                # ""outside"" stack for us.\n                #\n                # Regarding the support of Twisted\'s inlineCallbacks-like\n                # functionality (see eliot.twisted.inline_callbacks):\n                #\n                # The invocation may raise the inlineCallbacks internal\n                # control flow exception _DefGen_Return.  It is not wrong to\n                # just let that propagate upwards here but inlineCallbacks\n                # does think it is wrong.  The behavior triggers a\n                # DeprecationWarning to try to get us to fix our code.  We\n                # could explicitly handle and re-raise the _DefGen_Return but\n                # only at the expense of depending on a private Twisted API.\n                # For now, I\'m opting to try to encourage Twisted to fix the\n                # situation (or at least not worsen it):\n                # https://twistedmatrix.com/trac/ticket/9590\n                #\n                # Alternatively, _DefGen_Return is only required on Python 2.\n                # When Python 2 support is dropped, this concern can be\n                # eliminated by always using `return value` instead of\n                # `returnValue(value)` (and adding the necessary logic to the\n                # StopIteration handler below).\n                def go():\n                    if ok:\n                        value_out = gen.send(value_in)\n                    else:\n                        value_out = gen.throw(*value_in)\n                    # We have obtained a value from the generator.  In\n                    # giving it to us, it has given up control.  Note this\n                    # fact here.  Importantly, this is within the\n                    # generator\'s action context so that we get a good\n                    # indication of where the yield occurred.\n                    #\n                    # This is noisy, enable only for debugging:\n                    if wrapper.debug:\n                        log_message(message_type=""yielded"")\n                    return value_out\n\n                value_out = context.run(go)\n            except StopIteration:\n                # When the generator raises this, it is signaling\n                # completion.  Leave the loop.\n                break\n            else:\n                try:\n                    # Pass the generator\'s result along to whoever is\n                    # driving.  Capture the result as the next value to\n                    # send inward.\n                    value_in = yield value_out\n                except:\n                    # Or capture the exception if that\'s the flavor of the\n                    # next value.  This could possibly include GeneratorExit\n                    # which turns out to be just fine because throwing it into\n                    # the inner generator effectively propagates the close\n                    # (and with the right context!) just as you would want.\n                    # True, the GeneratorExit does get re-throwing out of the\n                    # gen.throw call and hits _the_generator_context\'s\n                    # contextmanager.  But @contextmanager extremely\n                    # conveniently eats it for us!  Thanks, @contextmanager!\n                    ok = False\n                    value_in = exc_info()\n                else:\n                    ok = True\n\n    wrapper.debug = False\n    return wrapper\n'"
eliot/_message.py,0,"b'""""""\nLog messages and related utilities.\n""""""\n\nfrom __future__ import unicode_literals\n\nimport time\nfrom warnings import warn\nfrom six import text_type as unicode\n\nfrom pyrsistent import PClass, pmap_field\n\nMESSAGE_TYPE_FIELD = ""message_type""\nTASK_UUID_FIELD = ""task_uuid""\nTASK_LEVEL_FIELD = ""task_level""\nTIMESTAMP_FIELD = ""timestamp""\n\nEXCEPTION_FIELD = ""exception""\nREASON_FIELD = ""reason""\n\n\nclass Message(object):\n    """"""\n    A log message.\n\n    Messages are basically dictionaries, mapping ""fields"" to ""values"". Field\n    names should not start with C{\'_\'}, as those are reserved for system use\n    (e.g. C{""_id""} is used by Elasticsearch for unique message identifiers and\n    may be auto-populated by logstash).\n    """"""\n\n    # Overrideable for testing purposes:\n    _time = time.time\n\n    @classmethod\n    def new(_class, _serializer=None, **fields):\n        """"""\n        Create a new L{Message}.\n\n        The keyword arguments will become the initial contents of the L{Message}.\n\n        @param _serializer: A positional argument, either C{None} or a\n            L{eliot._validation._MessageSerializer} with which a\n            L{eliot.ILogger} may choose to serialize the message. If you\'re\n            using L{eliot.MessageType} this will be populated for you.\n\n        @return: The new L{Message}\n        """"""\n        warn(\n            ""Message.new() is deprecated since 1.11.0, ""\n            ""use eliot.log_message() instead."",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        return _class(fields, _serializer)\n\n    @classmethod\n    def log(_class, **fields):\n        """"""\n        Write a new L{Message} to the default L{Logger}.\n\n        The keyword arguments will become contents of the L{Message}.\n        """"""\n        warn(\n            ""Message.log() is deprecated since 1.11.0, ""\n            ""use Action.log() or eliot.log_message() instead."",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        _class(fields).write()\n\n    def __init__(self, contents, serializer=None):\n        """"""\n        You can also use L{Message.new} to create L{Message} objects.\n\n        @param contents: The contents of this L{Message}, a C{dict} whose keys\n           must be C{unicode}, or text that has been UTF-8 encoded to\n           C{bytes}.\n\n        @param serializer: Either C{None}, or\n            L{eliot._validation._MessageSerializer} with which a\n            L{eliot.Logger} may choose to serialize the message. If you\'re\n            using L{eliot.MessageType} this will be populated for you.\n        """"""\n        self._contents = contents.copy()\n        self._serializer = serializer\n\n    def bind(self, **fields):\n        """"""\n        Return a new L{Message} with this message\'s contents plus the\n        additional given bindings.\n        """"""\n        contents = self._contents.copy()\n        contents.update(fields)\n        return Message(contents, self._serializer)\n\n    def contents(self):\n        """"""\n        Return a copy of L{Message} contents.\n        """"""\n        return self._contents.copy()\n\n    def _timestamp(self):\n        """"""\n        Return the current time.\n        """"""\n        return self._time()\n\n    def write(self, logger=None, action=None):\n        """"""\n        Write the message to the given logger.\n\n        This will additionally include a timestamp, the action context if any,\n        and any other fields.\n\n        Byte field names will be converted to Unicode.\n\n        @type logger: L{eliot.ILogger} or C{None} indicating the default one.\n\n        @param action: The L{Action} which is the context for this message. If\n            C{None}, the L{Action} will be deduced from the current call\n            stack.\n        """"""\n        fields = dict(self._contents)\n        if ""message_type"" not in fields:\n            fields[""message_type""] = """"\n        if self._serializer is not None:\n            fields[""__eliot_serializer__""] = self._serializer\n        if action is None:\n            fields[""__eliot_logger__""] = logger\n            log_message(**fields)\n        else:\n            action.log(**fields)\n\n\nclass WrittenMessage(PClass):\n    """"""\n    A L{Message} that has been logged.\n\n    @ivar _logged_dict: The originally logged dictionary.\n    """"""\n\n    _logged_dict = pmap_field((str, unicode), object)\n\n    @property\n    def timestamp(self):\n        """"""\n        The Unix timestamp of when the message was logged.\n        """"""\n        return self._logged_dict[TIMESTAMP_FIELD]\n\n    @property\n    def task_uuid(self):\n        """"""\n        The UUID of the task in which the message was logged.\n        """"""\n        return self._logged_dict[TASK_UUID_FIELD]\n\n    @property\n    def task_level(self):\n        """"""\n        The L{TaskLevel} of this message appears within the task.\n        """"""\n        return TaskLevel(level=self._logged_dict[TASK_LEVEL_FIELD])\n\n    @property\n    def contents(self):\n        """"""\n        A C{PMap}, the message contents without Eliot metadata.\n        """"""\n        return (\n            self._logged_dict.discard(TIMESTAMP_FIELD)\n            .discard(TASK_UUID_FIELD)\n            .discard(TASK_LEVEL_FIELD)\n        )\n\n    @classmethod\n    def from_dict(cls, logged_dictionary):\n        """"""\n        Reconstruct a L{WrittenMessage} from a logged dictionary.\n\n        @param logged_dictionary: A C{PMap} representing a parsed log entry.\n        @return: A L{WrittenMessage} for that dictionary.\n        """"""\n        return cls(_logged_dict=logged_dictionary)\n\n    def as_dict(self):\n        """"""\n        Return the dictionary that was used to write this message.\n\n        @return: A C{dict}, as might be logged by Eliot.\n        """"""\n        return self._logged_dict\n\n\n# Import at end to deal with circular imports:\nfrom ._action import log_message, TaskLevel\n'"
eliot/_output.py,0,"b'""""""\nImplementation of hooks and APIs for outputting log messages.\n""""""\n\nimport sys\nimport traceback\nimport inspect\nimport json as pyjson\nfrom threading import Lock\nfrom functools import wraps\nfrom io import IOBase\n\nfrom pyrsistent import PClass, field\n\nfrom . import _bytesjson as bytesjson\nfrom zope.interface import Interface, implementer\n\nfrom ._traceback import write_traceback, TRACEBACK_MESSAGE\nfrom ._message import EXCEPTION_FIELD, MESSAGE_TYPE_FIELD, REASON_FIELD\nfrom ._util import saferepr, safeunicode\nfrom .json import EliotJSONEncoder\nfrom ._validation import ValidationError\n\n\nclass _DestinationsSendError(Exception):\n    """"""\n    An error occured sending to one or more destinations.\n\n    @ivar errors: A list of tuples output from C{sys.exc_info()}.\n    """"""\n\n    def __init__(self, errors):\n        self.errors = errors\n        Exception.__init__(self, errors)\n\n\nclass BufferingDestination(object):\n    """"""\n    Buffer messages in memory.\n    """"""\n\n    def __init__(self):\n        self.messages = []\n\n    def __call__(self, message):\n        self.messages.append(message)\n        while len(self.messages) > 1000:\n            self.messages.pop(0)\n\n\nclass Destinations(object):\n    """"""\n    Manage a list of destinations for message dictionaries.\n\n    The global instance of this class is where L{Logger} instances will\n    send written messages.\n    """"""\n\n    def __init__(self):\n        self._destinations = [BufferingDestination()]\n        self._any_added = False\n        self._globalFields = {}\n\n    def addGlobalFields(self, **fields):\n        """"""\n        Add fields that will be included in all messages sent through this\n        destination.\n\n        @param fields: Keyword arguments mapping field names to values.\n        """"""\n        self._globalFields.update(fields)\n\n    def send(self, message):\n        """"""\n        Deliver a message to all destinations.\n\n        The passed in message might be mutated.\n\n        @param message: A message dictionary that can be serialized to JSON.\n        @type message: L{dict}\n        """"""\n        message.update(self._globalFields)\n        errors = []\n        for dest in self._destinations:\n            try:\n                dest(message)\n            except:\n                errors.append(sys.exc_info())\n        if errors:\n            raise _DestinationsSendError(errors)\n\n    def add(self, *destinations):\n        """"""\n        Adds new destinations.\n\n        A destination should never ever throw an exception. Seriously.\n        A destination should not mutate the dictionary it is given.\n\n        @param destinations: A list of callables that takes message\n            dictionaries.\n        """"""\n        buffered_messages = None\n        if not self._any_added:\n            # These are first set of messages added, so we need to clear\n            # BufferingDestination:\n            self._any_added = True\n            buffered_messages = self._destinations[0].messages\n            self._destinations = []\n        self._destinations.extend(destinations)\n        if buffered_messages:\n            # Re-deliver buffered messages:\n            for message in buffered_messages:\n                self.send(message)\n\n    def remove(self, destination):\n        """"""\n        Remove an existing destination.\n\n        @param destination: A destination previously added with C{self.add}.\n\n        @raises ValueError: If the destination is unknown.\n        """"""\n        self._destinations.remove(destination)\n\n\nclass ILogger(Interface):\n    """"""\n    Write out message dictionaries to some destination.\n    """"""\n\n    def write(dictionary, serializer=None):\n        """"""\n        Write a dictionary to the appropriate destination.\n\n        @note: This method is thread-safe.\n\n        @param serializer: Either C{None}, or a\n            L{eliot._validation._MessageSerializer} which can be used to\n            validate this message.\n\n        @param dictionary: The message to write out. The given dictionary\n             will not be mutated.\n        @type dictionary: C{dict}\n        """"""\n\n\n@implementer(ILogger)\nclass Logger(object):\n    """"""\n    Write out messages to the globally configured destination(s).\n\n    You will typically want to create one of these for every chunk of code\n    whose messages you want to unit test in isolation, e.g. a class. The tests\n    can then replace a specific L{Logger} with a L{MemoryLogger}.\n    """"""\n\n    _destinations = Destinations()\n    _log_tracebacks = True\n\n    def _safeUnicodeDictionary(self, dictionary):\n        """"""\n        Serialize a dictionary to a unicode string no matter what it contains.\n\n        The resulting dictionary will loosely follow Python syntax but it is\n        not expected to actually be a lossless encoding in all cases.\n\n        @param dictionary: A L{dict} to serialize.\n\n        @return: A L{unicode} string representing the input dictionary as\n            faithfully as can be done without putting in too much effort.\n        """"""\n        try:\n            return str(\n                dict(\n                    (saferepr(key), saferepr(value))\n                    for (key, value) in dictionary.items()\n                )\n            )\n        except:\n            return saferepr(dictionary)\n\n    def write(self, dictionary, serializer=None):\n        """"""\n        Serialize the dictionary, and write it to C{self._destinations}.\n        """"""\n        dictionary = dictionary.copy()\n        try:\n            if serializer is not None:\n                serializer.serialize(dictionary)\n        except:\n            write_traceback(self)\n            from ._action import log_message\n\n            log_message(\n                ""eliot:serialization_failure"",\n                message=self._safeUnicodeDictionary(dictionary),\n                __eliot_logger__=self,\n            )\n            return\n\n        try:\n            self._destinations.send(dictionary)\n        except _DestinationsSendError as e:\n            from ._action import log_message\n\n            if self._log_tracebacks:\n                for (exc_type, exception, exc_traceback) in e.errors:\n                    # Can\'t use same Logger as serialization errors because\n                    # if destination continues to error out we will get\n                    # infinite recursion. So instead we have to manually\n                    # construct a Logger that won\'t retry.\n                    logger = Logger()\n                    logger._log_tracebacks = False\n                    logger._destinations = self._destinations\n                    msg = {\n                        MESSAGE_TYPE_FIELD: ""eliot:destination_failure"",\n                        REASON_FIELD: safeunicode(exception),\n                        EXCEPTION_FIELD: exc_type.__module__ + ""."" + exc_type.__name__,\n                        ""message"": self._safeUnicodeDictionary(dictionary),\n                        ""__eliot_logger__"": logger,\n                    }\n                    log_message(**msg)\n            else:\n                # Nothing we can do here, raising exception to caller will\n                # break business logic, better to have that continue to\n                # work even if logging isn\'t.\n                pass\n\n\ndef exclusively(f):\n    """"""\n    Decorate a function to make it thread-safe by serializing invocations\n    using a per-instance lock.\n    """"""\n\n    @wraps(f)\n    def exclusively_f(self, *a, **kw):\n        with self._lock:\n            return f(self, *a, **kw)\n\n    return exclusively_f\n\n\n@implementer(ILogger)\nclass MemoryLogger(object):\n    """"""\n    Store written messages in memory.\n\n    When unit testing you don\'t want to create this directly but rather use\n    the L{eliot.testing.validateLogging} decorator on a test method, which\n    will provide additional testing integration.\n\n    @ivar messages: A C{list} of the dictionaries passed to\n        L{MemoryLogger.write}. Do not mutate this list.\n\n    @ivar serializers: A C{list} of the serializers passed to\n        L{MemoryLogger.write}, each corresponding to a message\n        L{MemoryLogger.messages}. Do not mutate this list.\n\n    @ivar tracebackMessages: A C{list} of messages written to this logger for\n        tracebacks using L{eliot.write_traceback} or L{eliot.writeFailure}. Do\n        not mutate this list.\n    """"""\n\n    def __init__(self):\n        self._lock = Lock()\n        self.reset()\n\n    @exclusively\n    def flushTracebacks(self, exceptionType):\n        """"""\n        Flush all logged tracebacks whose exception is of the given type.\n\n        This means they are expected tracebacks and should not cause the test\n        to fail.\n\n        @param exceptionType: A subclass of L{Exception}.\n\n        @return: C{list} of flushed messages.\n        """"""\n        result = []\n        remaining = []\n        for message in self.tracebackMessages:\n            if isinstance(message[REASON_FIELD], exceptionType):\n                result.append(message)\n            else:\n                remaining.append(message)\n        self.tracebackMessages = remaining\n        return result\n\n    # PEP 8 variant:\n    flush_tracebacks = flushTracebacks\n\n    @exclusively\n    def write(self, dictionary, serializer=None):\n        """"""\n        Add the dictionary to list of messages.\n        """"""\n        # Validate copy of the dictionary, to ensure what we store isn\'t\n        # mutated.\n        try:\n            self._validate_message(dictionary.copy(), serializer)\n        except Exception as e:\n            # Skip irrelevant frames that don\'t help pinpoint the problem:\n            from . import _output, _message, _action\n\n            skip_filenames = [_output.__file__, _message.__file__, _action.__file__]\n            for frame in inspect.stack():\n                if frame[1] not in skip_filenames:\n                    break\n            self._failed_validations.append(\n                ""{}: {}"".format(e, """".join(traceback.format_stack(frame[0])))\n            )\n        self.messages.append(dictionary)\n        self.serializers.append(serializer)\n        if serializer is TRACEBACK_MESSAGE._serializer:\n            self.tracebackMessages.append(dictionary)\n\n    def _validate_message(self, dictionary, serializer):\n        """"""Validate an individual message.\n\n        As a side-effect, the message is replaced with its serialized contents.\n\n        @param dictionary: A message C{dict} to be validated.  Might be mutated\n            by the serializer!\n\n        @param serializer: C{None} or a serializer.\n\n        @raises TypeError: If a field name is not unicode, or the dictionary\n            fails to serialize to JSON.\n\n        @raises eliot.ValidationError: If serializer was given and validation\n            failed.\n        """"""\n        if serializer is not None:\n            serializer.validate(dictionary)\n        for key in dictionary:\n            if not isinstance(key, str):\n                if isinstance(key, bytes):\n                    key.decode(""utf-8"")\n                else:\n                    raise TypeError(dictionary, ""%r is not unicode"" % (key,))\n        if serializer is not None:\n            serializer.serialize(dictionary)\n\n        try:\n            bytesjson.dumps(dictionary)\n            pyjson.dumps(dictionary)\n        except Exception as e:\n            raise TypeError(""Message %s doesn\'t encode to JSON: %s"" % (dictionary, e))\n\n    @exclusively\n    def validate(self):\n        """"""\n        Validate all written messages.\n\n        Does minimal validation of types, and for messages with corresponding\n        serializers use those to do additional validation.\n\n        As a side-effect, the messages are replaced with their serialized\n        contents.\n\n        @raises TypeError: If a field name is not unicode, or the dictionary\n            fails to serialize to JSON.\n\n        @raises eliot.ValidationError: If serializer was given and validation\n            failed.\n        """"""\n        for dictionary, serializer in zip(self.messages, self.serializers):\n            try:\n                self._validate_message(dictionary, serializer)\n            except (TypeError, ValidationError) as e:\n                # We already figured out which messages failed validation\n                # earlier. This just lets us figure out which exception type to\n                # raise.\n                raise e.__class__(""\\n\\n"".join(self._failed_validations))\n\n    @exclusively\n    def serialize(self):\n        """"""\n        Serialize all written messages.\n\n        This is the Field-based serialization, not JSON.\n\n        @return: A C{list} of C{dict}, the serialized messages.\n        """"""\n        result = []\n        for dictionary, serializer in zip(self.messages, self.serializers):\n            dictionary = dictionary.copy()\n            serializer.serialize(dictionary)\n            result.append(dictionary)\n        return result\n\n    @exclusively\n    def reset(self):\n        """"""\n        Clear all logged messages.\n\n        Any logged tracebacks will also be cleared, and will therefore not\n        cause a test failure.\n\n        This is useful to ensure a logger is in a known state before testing\n        logging of a specific code path.\n        """"""\n        self.messages = []\n        self.serializers = []\n        self.tracebackMessages = []\n        self._failed_validations = []\n\n\nclass FileDestination(PClass):\n    """"""\n    Callable that writes JSON messages to a file.\n\n    On Python 3 the file may support either C{bytes} or C{unicode}.  On\n    Python 2 only C{bytes} are supported since that is what all files expect\n    in practice.\n\n    @ivar file: The file to which messages will be written.\n\n    @ivar _dumps: Function that serializes an object to JSON.\n\n    @ivar _linebreak: C{""\\n""} as either bytes or unicode.\n    """"""\n\n    file = field(mandatory=True)\n    encoder = field(mandatory=True)\n    _dumps = field(mandatory=True)\n    _linebreak = field(mandatory=True)\n\n    def __new__(cls, file, encoder=EliotJSONEncoder):\n        if isinstance(file, IOBase) and not file.writable():\n            raise RuntimeError(""Given file {} is not writeable."")\n\n        unicodeFile = False\n        try:\n            file.write(b"""")\n        except TypeError:\n            unicodeFile = True\n\n        if unicodeFile:\n            # On Python 3 native json module outputs unicode:\n            _dumps = pyjson.dumps\n            _linebreak = ""\\n""\n        else:\n            _dumps = bytesjson.dumps\n            _linebreak = b""\\n""\n        return PClass.__new__(\n            cls, file=file, _dumps=_dumps, _linebreak=_linebreak, encoder=encoder\n        )\n\n    def __call__(self, message):\n        """"""\n        @param message: A message dictionary.\n        """"""\n        self.file.write(self._dumps(message, cls=self.encoder) + self._linebreak)\n        self.file.flush()\n\n\ndef to_file(output_file, encoder=EliotJSONEncoder):\n    """"""\n    Add a destination that writes a JSON message per line to the given file.\n\n    @param output_file: A file-like object.\n    """"""\n    Logger._destinations.add(FileDestination(file=output_file, encoder=encoder))\n\n\n# The default Logger, used when none is specified:\n_DEFAULT_LOGGER = Logger()\n'"
eliot/_traceback.py,0,"b'""""""\nLogging of tracebacks and L{twisted.python.failure.Failure} instances,\nas well as common utilities for handling exception logging.\n""""""\n\nfrom __future__ import unicode_literals\n\nimport traceback\nimport sys\n\nfrom ._message import EXCEPTION_FIELD, REASON_FIELD\nfrom ._util import safeunicode, load_module\nfrom ._validation import MessageType, Field\nfrom ._errors import _error_extraction\n\nTRACEBACK_MESSAGE = MessageType(\n    ""eliot:traceback"",\n    [\n        Field(REASON_FIELD, safeunicode, ""The exception\'s value.""),\n        Field(""traceback"", safeunicode, ""The traceback.""),\n        Field(\n            EXCEPTION_FIELD,\n            lambda typ: ""%s.%s"" % (typ.__module__, typ.__name__),\n            ""The exception type\'s FQPN."",\n        ),\n    ],\n    ""An unexpected exception indicating a bug."",\n)\n# The fields here are actually subset of what you might get in practice,\n# due to exception extraction, so we hackily modify the serializer:\nTRACEBACK_MESSAGE._serializer.allow_additional_fields = True\n\n\ndef _writeTracebackMessage(logger, typ, exception, traceback):\n    """"""\n    Write a traceback to the log.\n\n    @param typ: The class of the exception.\n\n    @param exception: The L{Exception} instance.\n\n    @param traceback: The traceback, a C{str}.\n    """"""\n    msg = TRACEBACK_MESSAGE(reason=exception, traceback=traceback, exception=typ)\n    msg = msg.bind(**_error_extraction.get_fields_for_exception(logger, exception))\n    msg.write(logger)\n\n\n# The default Python standard library traceback.py formatting functions\n# involving reading source from disk. This is a potential performance hit\n# since disk I/O can block. We therefore format the tracebacks with in-memory\n# information only.\n#\n# Unfortunately, the easiest way to do this is... exciting.\ndef _get_traceback_no_io():\n    """"""\n    Return a version of L{traceback} that doesn\'t do I/O.\n    """"""\n    try:\n        module = load_module(str(""_traceback_no_io""), traceback)\n    except NotImplementedError:\n        # Can\'t fix the I/O problem, oh well:\n        return traceback\n\n    class FakeLineCache(object):\n        def checkcache(self, *args, **kwargs):\n            None\n\n        def getline(self, *args, **kwargs):\n            return """"\n\n        def lazycache(self, *args, **kwargs):\n            return None\n\n    module.linecache = FakeLineCache()\n    return module\n\n\n_traceback_no_io = _get_traceback_no_io()\n\n\ndef write_traceback(logger=None, exc_info=None):\n    """"""\n    Write the latest traceback to the log.\n\n    This should be used inside an C{except} block. For example:\n\n         try:\n             dostuff()\n         except:\n             write_traceback(logger)\n\n    Or you can pass the result of C{sys.exc_info()} to the C{exc_info}\n    parameter.\n    """"""\n    if exc_info is None:\n        exc_info = sys.exc_info()\n    typ, exception, tb = exc_info\n    traceback = """".join(_traceback_no_io.format_exception(typ, exception, tb))\n    _writeTracebackMessage(logger, typ, exception, traceback)\n\n\ndef writeFailure(failure, logger=None):\n    """"""\n    Write a L{twisted.python.failure.Failure} to the log.\n\n    This is for situations where you got an unexpected exception and want to\n    log a traceback. For example, if you have C{Deferred} that might error,\n    you\'ll want to wrap it with a L{eliot.twisted.DeferredContext} and then add\n    C{writeFailure} as the error handler to get the traceback logged:\n\n        d = DeferredContext(dostuff())\n        d.addCallback(process)\n        # Final error handler.\n        d.addErrback(writeFailure)\n\n    @param failure: L{Failure} to write to the log.\n\n    @type logger: L{eliot.ILogger}. Will be deprecated at some point, so just\n        ignore it.\n\n    @return: None\n    """"""\n    # Failure.getBriefTraceback does not include source code, so does not do\n    # I/O.\n    _writeTracebackMessage(\n        logger, failure.value.__class__, failure.value, failure.getBriefTraceback()\n    )\n'"
eliot/_util.py,0,"b'""""""\nUtilities that don\'t go anywhere else.\n""""""\n\nfrom __future__ import unicode_literals\n\nimport sys\nfrom types import ModuleType\n\nfrom six import exec_, text_type as unicode, PY3\n\n\ndef safeunicode(o):\n    """"""\n    Like C{unicode()}, but catches and swallows any raised exceptions.\n\n    @param o: An object of some sort.\n\n    @return: C{unicode(o)}, or an error message if that failed.\n    @rtype: C{unicode}\n    """"""\n    try:\n        return unicode(o)\n    except:\n        # Not much we can do about this...\n        return ""eliot: unknown, unicode() raised exception""\n\n\ndef saferepr(o):\n    """"""\n    Like C{unicode(repr())}, but catches and swallows any raised exceptions.\n\n    @param o: An object of some sort.\n\n    @return: C{unicode(repr(o))}, or an error message if that failed.\n    @rtype: C{unicode}\n    """"""\n    try:\n        return unicode(repr(o))\n    except:\n        # Not much we can do about this...\n        return ""eliot: unknown, unicode() raised exception""\n\n\ndef load_module(name, original_module):\n    """"""\n    Load a copy of a module, distinct from what you\'d get if you imported\n    it directly.\n\n    @param str name: The name of the new module.\n    @param original_module: The original module we\'re recreating.\n\n    @return: A new, distinct module.\n    """"""\n    module = ModuleType(name)\n    if PY3:\n        import importlib.util\n\n        spec = importlib.util.find_spec(original_module.__name__)\n        source = spec.loader.get_code(original_module.__name__)\n    else:\n        if getattr(sys, ""frozen"", False):\n            raise NotImplementedError(""Can\'t load modules on Python 2 with PyInstaller"")\n        path = original_module.__file__\n        if path.endswith("".pyc"") or path.endswith("".pyo""):\n            path = path[:-1]\n        with open(path) as f:\n            source = f.read()\n    exec_(source, module.__dict__, module.__dict__)\n    return module\n'"
eliot/_validation.py,0,"b'""""""\nA log message serialization and validation system for Eliot.\n\nValidation is intended to be done by unit tests, not the production code path,\nalthough in theory it could be done then as well.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom warnings import warn\n\nimport six\n\nunicode = six.text_type\n\nfrom pyrsistent import PClass, field as pyrsistent_field\n\nfrom ._message import (\n    Message,\n    REASON_FIELD,\n    MESSAGE_TYPE_FIELD,\n    TASK_LEVEL_FIELD,\n    TASK_UUID_FIELD,\n    TIMESTAMP_FIELD,\n)\nfrom ._action import (\n    start_action,\n    startTask,\n    ACTION_STATUS_FIELD,\n    ACTION_TYPE_FIELD,\n    STARTED_STATUS,\n    SUCCEEDED_STATUS,\n    FAILED_STATUS,\n    log_message,\n)\n\n\nclass ValidationError(Exception):\n    """"""\n    A field value failed validation.\n    """"""\n\n\n# Types that can be encoded to JSON:\n_JSON_TYPES = {type(None), int, float, unicode, list, dict, bytes, bool}\n_JSON_TYPES |= set(six.integer_types)\n\nRESERVED_FIELDS = (TASK_LEVEL_FIELD, TASK_UUID_FIELD, TIMESTAMP_FIELD)\n\n\nclass Field(object):\n    """"""\n    A named field that can accept rich types and serialize them to the logging\n    system\'s basic types (currently, JSON types).\n\n    An optional extra validation function can be used to validate inputs when\n    unit testing.\n\n    @ivar key: The name of the field, the key which refers to it,\n        e.g. C{""path""}.\n\n    @ivar description: A description of what this field contains.\n    @type description: C{unicode}\n    """"""\n\n    def __init__(self, key, serializer, description="""", extraValidator=None):\n        """"""\n        @param serializer: A function that takes a single rich input and\n            returns a serialized value that can be written out as JSON. May\n            raise L{ValidationError} to indicate bad inputs.\n\n        @param extraValidator: Allow additional validation of the field\n            value. A callable that takes a field value, and raises\n            L{ValidationError} if the value is a incorrect one for this\n            field. Alternatively can be set to C{None}, in which case no\n            additional validation is done.\n        """"""\n        self.key = key\n        self.description = description\n        self._serializer = serializer\n        self._extraValidator = extraValidator\n\n    def validate(self, input):\n        """"""\n        Validate the given input value against this L{Field} definition.\n\n        @param input: An input value supposedly serializable by this L{Field}.\n\n        @raises ValidationError: If the value is not serializable or fails to\n            be validated by the additional validator.\n        """"""\n        # Make sure the input serializes:\n        self._serializer(input)\n        # Use extra validator, if given:\n        if self._extraValidator is not None:\n            self._extraValidator(input)\n\n    def serialize(self, input):\n        """"""\n        Convert the given input to a value that can actually be logged.\n\n        @param input: An input value supposedly serializable by this L{Field}.\n\n        @return: A serialized value.\n        """"""\n        return self._serializer(input)\n\n    @classmethod\n    def forValue(klass, key, value, description):\n        """"""\n        Create a L{Field} that can only have a single value.\n\n        @param key: The name of the field, the key which refers to it,\n            e.g. C{""path""}.\n\n        @param value: The allowed value for the field.\n\n        @param description: A description of what this field contains.\n        @type description: C{unicode}\n\n        @return: A L{Field}.\n        """"""\n\n        def validate(checked):\n            if checked != value:\n                raise ValidationError(checked, ""Field %r must be %r"" % (key, value))\n\n        return klass(key, lambda _: value, description, validate)\n\n    # PEP 8 variant:\n    for_value = forValue\n\n    @classmethod\n    def forTypes(klass, key, classes, description, extraValidator=None):\n        """"""\n        Create a L{Field} that must be an instance of a given set of types.\n\n        @param key: The name of the field, the key which refers to it,\n            e.g. C{""path""}.\n\n        @ivar classes: A C{list} of allowed Python classes for this field\'s\n            values. Supported classes are C{unicode}, C{int}, C{float},\n            C{bool}, C{long}, C{list} and C{dict} and C{None} (the latter\n            isn\'t strictly a class, but will be converted appropriately).\n\n        @param description: A description of what this field contains.\n        @type description: C{unicode}\n\n        @param extraValidator: See description in L{Field.__init__}.\n\n        @return: A L{Field}.\n        """"""\n        fixedClasses = []\n        for k in classes:\n            if k is None:\n                k = type(None)\n            if k not in _JSON_TYPES:\n                raise TypeError(""%s is not JSON-encodeable"" % (k,))\n            fixedClasses.append(k)\n        fixedClasses = tuple(fixedClasses)\n\n        def validate(value):\n            if not isinstance(value, fixedClasses):\n                raise ValidationError(\n                    value, ""Field %r requires type to be one of %s"" % (key, classes)\n                )\n            if extraValidator is not None:\n                extraValidator(value)\n\n        return klass(key, lambda v: v, description, extraValidator=validate)\n\n    # PEP 8 variant:\n    for_types = forTypes\n\n\ndef fields(*fields, **keys):\n    """"""\n    Factory for for L{MessageType} and L{ActionType} field definitions.\n\n    @param *fields: A L{tuple} of L{Field} instances.\n\n    @param **keys: A L{dict} mapping key names to the expected type of the\n        field\'s values.\n\n    @return: A L{list} of L{Field} instances.\n    """"""\n    return list(fields) + [\n        Field.forTypes(key, [value], """") for key, value in keys.items()\n    ]\n\n\nREASON = Field.forTypes(REASON_FIELD, [unicode], ""The reason for an event."")\nTRACEBACK = Field.forTypes(""traceback"", [unicode], ""The traceback for an exception."")\nEXCEPTION = Field.forTypes(""exception"", [unicode], ""The FQPN of an exception class."")\n\n\nclass _MessageSerializer(object):\n    """"""\n    A serializer and validator for messages.\n\n    @ivar fields: A C{dict} mapping a C{unicode} field name to the respective\n        L{Field}.\n    @ivar allow_additional_fields: If true, additional fields don\'t cause\n        validation failure.\n    """"""\n\n    def __init__(self, fields, allow_additional_fields=False):\n        keys = []\n        for field in fields:\n            if not isinstance(field, Field):\n                raise TypeError(""Expected a Field instance but got"", field)\n            keys.append(field.key)\n        if len(set(keys)) != len(keys):\n            raise ValueError(keys, ""Duplicate field name"")\n        if ACTION_TYPE_FIELD in keys:\n            if MESSAGE_TYPE_FIELD in keys:\n                raise ValueError(\n                    keys,\n                    ""Messages must have either ""\n                    ""\'action_type\' or \'message_type\', not both"",\n                )\n        elif MESSAGE_TYPE_FIELD not in keys:\n            raise ValueError(\n                keys, ""Messages must have either \'action_type\' "", ""or \'message_type\'""\n            )\n        if any(key.startswith(""_"") for key in keys):\n            raise ValueError(keys, ""Field names must not start with \'_\'"")\n        for reserved in RESERVED_FIELDS:\n            if reserved in keys:\n                raise ValueError(\n                    keys,\n                    ""The field name %r is reserved for use ""\n                    ""by the logging framework"" % (reserved,),\n                )\n        self.fields = dict((field.key, field) for field in fields)\n        self.allow_additional_fields = allow_additional_fields\n\n    def serialize(self, message):\n        """"""\n        Serialize the given message in-place, converting inputs to outputs.\n\n        We do this in-place for performance reasons. There are more fields in\n        a message than there are L{Field} objects because of the timestamp,\n        task_level and task_uuid fields. By only iterating over our L{Fields}\n        we therefore reduce the number of function calls in a critical code\n        path.\n\n        @param message: A C{dict}.\n        """"""\n        for key, field in self.fields.items():\n            message[key] = field.serialize(message[key])\n\n    def validate(self, message):\n        """"""\n        Validate the given message.\n\n        @param message: A C{dict}.\n\n        @raises ValidationError: If the message has the wrong fields or one of\n            its field values fail validation.\n        """"""\n        for key, field in self.fields.items():\n            if key not in message:\n                raise ValidationError(message, ""Field %r is missing"" % (key,))\n            field.validate(message[key])\n\n        if self.allow_additional_fields:\n            return\n        # Otherwise, additional fields are not allowed:\n        fieldSet = set(self.fields) | set(RESERVED_FIELDS)\n        for key in message:\n            if key not in fieldSet:\n                raise ValidationError(message, ""Unexpected field %r"" % (key,))\n\n\nclass MessageType(object):\n    """"""\n    A specific type of non-action message.\n\n    Example usage:\n\n        # Schema definition:\n        KEY = Field(""key"", [int], u""The lookup key for things."")\n        STATUS = Field(""status"", [int], u""The status of a thing."")\n        LOG_STATUS = MessageType(\n            ""yourapp:subsystem:status"", [KEY, STATUS],\n            u""We just set the status of something."")\n\n        # Actual code, with logging added:\n        def setstatus(key, status):\n            doactualset(key, status)\n            LOG_STATUS(key=key, status=status).write()\n\n    You do not need to use the L{MessageType} to create the L{eliot.Message},\n    however; you could build it up using a series of L{eliot.Message.bind}\n    calls. Having a L{MessageType} is nonetheless still useful for validation\n    and documentation.\n\n    @ivar message_type: The name of the type,\n        e.g. C{""yourapp:subsystem:yourtype""}.\n\n    @ivar description: A description of what this message means.\n    @type description: C{unicode}\n    """"""\n\n    def __init__(self, message_type, fields, description=""""):\n        """"""\n        @ivar type: The name of the type,\n            e.g. C{""yourapp:subsystem:yourtype""}.\n\n        @ivar fields: A C{list} of L{Field} instances which can appear in this\n            type.\n\n        @param description: A description of what this message means.\n        @type description: C{unicode}\n        """"""\n        self.message_type = message_type\n        self.description = description\n        self._serializer = _MessageSerializer(\n            fields\n            + [Field.forValue(MESSAGE_TYPE_FIELD, message_type, ""The message type."")]\n        )\n\n    def __call__(self, **fields):\n        """"""\n        Create a new L{eliot.Message} of this type with the given fields.\n\n        @param fields: Extra fields to add to the message.\n\n        @rtype: L{eliot.Message}\n        """"""\n        warn(\n            ""MessageType.__call__() is deprecated since 1.11.0, ""\n            ""use MessageType.log() instead."",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        fields[MESSAGE_TYPE_FIELD] = self.message_type\n        return Message(fields, self._serializer)\n\n    def log(self, **fields):\n        """"""\n        Write a new L{Message} of this type to the default L{Logger}.\n\n        The keyword arguments will become contents of the L{Message}.\n        """"""\n        fields[""__eliot_serializer__""] = self._serializer\n        log_message(self.message_type, **fields)\n\n\nclass _ActionSerializers(PClass):\n    """"""\n    Serializers for the three action messages: start, success and failure.\n    """"""\n\n    start = pyrsistent_field(mandatory=True)\n    success = pyrsistent_field(mandatory=True)\n    failure = pyrsistent_field(mandatory=True)\n\n\nclass ActionType(object):\n    """"""\n    A specific type of action.\n\n    Example usage:\n\n        # Schema definition:\n        KEY = Field(""key"", [int], u""The lookup key for things."")\n        RESULT = Field(""result"", [str], u""The result of lookups."")\n        LOG_DOSOMETHING = ActionType(\n            ""yourapp:subsystem:youraction"",\n            [KEY], [RESULT],\n            u""Do something with a key, resulting in a value."")\n\n        # Actual code, with logging added:\n        def dosomething(key):\n            with LOG_DOSOMETHING(logger, key=key) as action:\n                _dostuff(key)\n                _morestuff(key)\n                result = _theresult()\n                action.addSuccessFields(result=result)\n            return result\n\n    @ivar action_type: The name of the action,\n        e.g. C{""yourapp:subsystem:youraction""}.\n\n    @ivar startFields: A C{list} of L{Field} instances which can appear in\n        this action\'s start message.\n\n    @ivar successFields: A C{list} of L{Field} instances which can appear in\n        this action\'s successful finish message.\n\n    @ivar failureFields: A C{list} of L{Field} instances which can appear in\n        this action\'s failed finish message (in addition to the built-in\n        C{""exception""} and C{""reason""} fields).\n\n    @ivar description: A description of what this action\'s messages mean.\n    @type description: C{unicode}\n    """"""\n\n    # Overrideable hook for testing; need staticmethod() so functions don\'t\n    # get turned into methods.\n    _start_action = staticmethod(start_action)\n    _startTask = staticmethod(startTask)\n\n    def __init__(self, action_type, startFields, successFields, description=""""):\n        self.action_type = action_type\n        self.description = description\n\n        actionTypeField = Field.forValue(\n            ACTION_TYPE_FIELD, action_type, ""The action type""\n        )\n\n        def makeActionStatusField(value):\n            return Field.forValue(ACTION_STATUS_FIELD, value, ""The action status"")\n\n        startFields = startFields + [\n            actionTypeField,\n            makeActionStatusField(STARTED_STATUS),\n        ]\n        successFields = successFields + [\n            actionTypeField,\n            makeActionStatusField(SUCCEEDED_STATUS),\n        ]\n        failureFields = [\n            actionTypeField,\n            makeActionStatusField(FAILED_STATUS),\n            REASON,\n            EXCEPTION,\n        ]\n\n        self._serializers = _ActionSerializers(\n            start=_MessageSerializer(startFields),\n            success=_MessageSerializer(successFields),\n            # Failed action messages can have extra fields from exception\n            # extraction:\n            failure=_MessageSerializer(failureFields, allow_additional_fields=True),\n        )\n\n    def __call__(self, logger=None, **fields):\n        """"""\n        Start a new L{eliot.Action} of this type with the given start fields.\n\n        You can use the result as a Python context manager, or use the\n        L{eliot.Action.finish} API.\n\n             LOG_DOSOMETHING = ActionType(""yourapp:subsystem:dosomething"",\n                                      [Field.forTypes(""entry"", [int], """")],\n                                      [Field.forTypes(""result"", [int], """")],\n                                      [],\n                                      ""Do something with an entry."")\n             with LOG_DOSOMETHING(entry=x) as action:\n                  do(x)\n                  result = something(x * 2)\n                  action.addSuccessFields(result=result)\n\n        Or perhaps:\n\n             action = LOG_DOSOMETHING(entry=x)\n             action.run(doSomething)\n             action.finish()\n\n        @param logger: A L{eliot.ILogger} provider to which the action\'s\n            messages will be written, or C{None} to use the default one.\n\n        @param fields: Extra fields to add to the message.\n\n        @rtype: L{eliot.Action}\n        """"""\n        return self._start_action(logger, self.action_type, self._serializers, **fields)\n\n    def as_task(self, logger=None, **fields):\n        """"""\n        Start a new L{eliot.Action} of this type as a task (i.e. top-level\n        action) with the given start fields.\n\n        See L{ActionType.__call__} for example of usage.\n\n        @param logger: A L{eliot.ILogger} provider to which the action\'s\n            messages will be written, or C{None} to use the default one.\n\n        @param fields: Extra fields to add to the message.\n\n        @rtype: L{eliot.Action}\n        """"""\n        return self._startTask(logger, self.action_type, self._serializers, **fields)\n\n    # Backwards compatible variant:\n    asTask = as_task\n\n\n__all__ = []\n'"
eliot/_version.py,0,"b'# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain. Generated by\n# versioneer-0.18 (https://github.com/warner/python-versioneer)\n\n""""""Git implementation of _version.py.""""""\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\n\n\ndef get_keywords():\n    """"""Get the keywords needed to look up the version information.""""""\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = ""$Format:%d$""\n    git_full = ""$Format:%H$""\n    git_date = ""$Format:%ci$""\n    keywords = {""refnames"": git_refnames, ""full"": git_full, ""date"": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_config():\n    """"""Create, populate and return the VersioneerConfig() object.""""""\n    # these strings are filled in when \'setup.py versioneer\' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = ""git""\n    cfg.style = ""pep440""\n    cfg.tag_prefix = """"\n    cfg.parentdir_prefix = ""eliot-""\n    cfg.versionfile_source = ""eliot/_version.py""\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen(\n                [c] + args,\n                cwd=cwd,\n                env=env,\n                stdout=subprocess.PIPE,\n                stderr=(subprocess.PIPE if hide_stderr else None),\n            )\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %s"" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %s"" % (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %s (error)"" % dispcmd)\n            print(""stdout was %s"" % stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {\n                ""version"": dirname[len(parentdir_prefix) :],\n                ""full-revisionid"": None,\n                ""dirty"": False,\n                ""error"": None,\n                ""date"": None,\n            }\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(\n            ""Tried directories %s but none started with prefix %s""\n            % (str(rootdirs), parentdir_prefix)\n        )\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG) :] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r""\\d"", r)])\n        if verbose:\n            print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %s"" % "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix) :]\n            if verbose:\n                print(""picking %s"" % r)\n            return {\n                ""version"": r,\n                ""full-revisionid"": keywords[""full""].strip(),\n                ""dirty"": False,\n                ""error"": None,\n                ""date"": date,\n            }\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {\n        ""version"": ""0+unknown"",\n        ""full-revisionid"": keywords[""full""].strip(),\n        ""dirty"": False,\n        ""error"": ""no suitable tags"",\n        ""date"": None,\n    }\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root, hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %s not under git control"" % root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(\n        GITS,\n        [\n            ""describe"",\n            ""--tags"",\n            ""--dirty"",\n            ""--always"",\n            ""--long"",\n            ""--match"",\n            ""%s*"" % tag_prefix,\n        ],\n        cwd=root,\n    )\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[: git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r""^(.+)-(\\d+)-g([0-9a-f]+)$"", git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = ""unable to parse git-describe output: \'%s\'"" % describe_out\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                print(fmt % (full_tag, tag_prefix))\n            pieces[""error""] = ""tag \'%s\' doesn\'t start with prefix \'%s\'"" % (\n                full_tag,\n                tag_prefix,\n            )\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix) :]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""], cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""], cwd=root)[\n        0\n    ].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%d.g%s"" % (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%d.g%s"" % (pieces[""distance""], pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%d"" % pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%d"" % pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%s"" % pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%s"" % pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {\n            ""version"": ""unknown"",\n            ""full-revisionid"": pieces.get(""long""),\n            ""dirty"": None,\n            ""error"": pieces[""error""],\n            ""date"": None,\n        }\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%s\'"" % style)\n\n    return {\n        ""version"": rendered,\n        ""full-revisionid"": pieces[""long""],\n        ""dirty"": pieces[""dirty""],\n        ""error"": None,\n        ""date"": pieces.get(""date""),\n    }\n\n\ndef get_versions():\n    """"""Get version information or return default if unable to do so.""""""\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don\'t do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix, verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split(""/""):\n            root = os.path.dirname(root)\n    except NameError:\n        return {\n            ""version"": ""0+unknown"",\n            ""full-revisionid"": None,\n            ""dirty"": None,\n            ""error"": ""unable to find root of source tree"",\n            ""date"": None,\n        }\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {\n        ""version"": ""0+unknown"",\n        ""full-revisionid"": None,\n        ""dirty"": None,\n        ""error"": ""unable to compute version"",\n        ""date"": None,\n    }\n'"
eliot/dask.py,0,"b'""""""Support for Eliot tracing with Dask computations.""""""\n\nfrom pyrsistent import PClass, field\n\nfrom dask import compute, optimize, persist\n\ntry:\n    from dask.distributed import Future\nexcept:\n\n    class Future(object):\n        pass\n\n\nfrom dask.core import toposort, get_dependencies, ishashable\nfrom . import start_action, current_action, Action\n\n\nclass _RunWithEliotContext(PClass):\n    """"""\n    Run a callable within an Eliot context.\n\n    @ivar task_id: The serialized Eliot task ID.\n    @ivar func: The function that Dask wants to run.\n    @ivar key: The key in the Dask graph.\n    @ivar dependencies: The keys in the Dask graph this depends on.\n    """"""\n\n    task_id = field(type=str)\n    func = field()  # callable\n    key = field(type=str)\n    dependencies = field()\n\n    # Pretend to be underlying callable for purposes of equality; necessary for\n    # optimizer to be happy:\n\n    def __eq__(self, other):\n        return self.func == other\n\n    def __ne__(self, other):\n        return self.func != other\n\n    def __hash__(self):\n        return hash(self.func)\n\n    def __call__(self, *args, **kwargs):\n        with Action.continue_task(task_id=self.task_id) as action:\n            action.log(\n                message_type=""dask:task"", key=self.key, dependencies=self.dependencies\n            )\n            return self.func(*args, **kwargs)\n\n\ndef compute_with_trace(*args):\n    """"""Do Dask compute(), but with added Eliot tracing.\n\n    Dask is a graph of tasks, but Eliot logs trees.  So we need to emulate a\n    graph using a tree.  We do this by making Eliot action for each task, but\n    having it list the tasks it depends on.\n\n    We use the following algorithm:\n\n        1. Create a top-level action.\n\n        2. For each entry in the dask graph, create a child with\n           serialize_task_id.  Do this in likely order of execution, so that\n           if B depends on A the task level of B is higher than the task Ievel\n           of A.\n\n        3. Replace each function with a wrapper that uses the corresponding\n           task ID (with Action.continue_task), and while it\'s at it also\n           records which other things this function depends on.\n\n    Known issues:\n\n        1. Retries will confuse Eliot.  Probably need different\n           distributed-tree mechanism within Eliot to solve that.\n    """"""\n    # 1. Create top-level Eliot Action:\n    with start_action(action_type=""dask:compute""):\n        # In order to reduce logging verbosity, add logging to the already\n        # optimized graph:\n        optimized = optimize(*args, optimizations=[_add_logging])\n        return compute(*optimized, optimize_graph=False)\n\n\ndef persist_with_trace(*args):\n    """"""Do Dask persist(), but with added Eliot tracing.\n\n    Known issues:\n\n        1. Retries will confuse Eliot.  Probably need different\n           distributed-tree mechanism within Eliot to solve that.\n    """"""\n    # 1. Create top-level Eliot Action:\n    with start_action(action_type=""dask:persist""):\n        # In order to reduce logging verbosity, add logging to the already\n        # optimized graph:\n        optimized = optimize(*args, optimizations=[_add_logging])\n        return persist(*optimized, optimize_graph=False)\n\n\ndef _add_logging(dsk, ignore=None):\n    """"""\n    Add logging to a Dask graph.\n\n    @param dsk: The Dask graph.\n\n    @return: New Dask graph.\n    """"""\n    ctx = current_action()\n    result = {}\n\n    # Use topological sort to ensure Eliot actions are in logical order of\n    # execution in Dask:\n    keys = toposort(dsk)\n\n    # Give each key a string name. Some keys are just aliases to other\n    # keys, so make sure we have underlying key available. Later on might\n    # want to shorten them as well.\n    def simplify(k):\n        if isinstance(k, str):\n            return k\n        return ""-"".join(str(o) for o in k)\n\n    key_names = {}\n    for key in keys:\n        value = dsk[key]\n        if not callable(value) and ishashable(value) and value in keys:\n            # It\'s an alias for another key:\n            key_names[key] = key_names[value]\n        else:\n            key_names[key] = simplify(key)\n\n    # Values in the graph can be either:\n    #\n    # 1. A list of other values.\n    # 2. A tuple, where first value might be a callable, aka a task.\n    # 3. A literal of some sort.\n    def maybe_wrap(key, value):\n        if isinstance(value, list):\n            return [maybe_wrap(key, v) for v in value]\n        elif isinstance(value, tuple):\n            func = value[0]\n            args = value[1:]\n            if not callable(func):\n                # Not a callable, so nothing to wrap.\n                return value\n            wrapped_func = _RunWithEliotContext(\n                task_id=str(ctx.serialize_task_id(), ""utf-8""),\n                func=func,\n                key=key_names[key],\n                dependencies=[key_names[k] for k in get_dependencies(dsk, key)],\n            )\n            return (wrapped_func,) + args\n        else:\n            return value\n\n    # Replace function with wrapper that logs appropriate Action; iterate in\n    # topological order so action task levels are in reasonable order.\n    for key in keys:\n        result[key] = maybe_wrap(key, dsk[key])\n\n    assert set(result.keys()) == set(dsk.keys())\n    return result\n\n\n__all__ = [""compute_with_trace"", ""persist_with_trace""]\n'"
eliot/filter.py,0,"b'""""""\nCommand line program for filtering line-based Eliot logs.\n""""""\n\nfrom __future__ import unicode_literals, absolute_import\n\nif __name__ == ""__main__"":\n    import eliot.filter\n\n    eliot.filter.main()\n\nimport sys\nfrom datetime import datetime, timedelta\nfrom json import JSONEncoder\n\nfrom ._bytesjson import dumps, loads\n\n\nclass _DatetimeJSONEncoder(JSONEncoder):\n    """"""\n    JSON encoder that supports L{datetime}.\n    """"""\n\n    def default(self, o):\n        if isinstance(o, datetime):\n            return o.isoformat()\n        return JSONEncoder.default(self, o)\n\n\nclass EliotFilter(object):\n    """"""\n    Filter Eliot log lines using a Python expression.\n\n    @ivar code: A Python code object, the compiled filter expression.\n    """"""\n\n    _SKIP = object()\n\n    def __init__(self, expr, incoming, output):\n        """"""\n        @param expr: A Python expression that will be called for each log message.\n        @type expr: L{str}\n\n        @param incoming: An iterable of L{bytes}, each of which is a serialized\n            Eliot message.\n\n        @param output: A file to which output should be written.\n        @type output: L{file} or a file-like object.\n        """"""\n        self.code = compile(expr, ""<string>"", ""eval"")\n        self.incoming = incoming\n        self.output = output\n\n    def run(self):\n        """"""\n        For each incoming message, decode the JSON, evaluate expression, encode\n        as JSON and write that to the output file.\n        """"""\n        for line in self.incoming:\n            message = loads(line)\n            result = self._evaluate(message)\n            if result is self._SKIP:\n                continue\n            self.output.write(dumps(result, cls=_DatetimeJSONEncoder) + b""\\n"")\n\n    def _evaluate(self, message):\n        """"""\n        Evaluate the expression with the given Python object in its locals.\n\n        @param message: A decoded JSON input.\n\n        @return: The resulting object.\n        """"""\n        return eval(\n            self.code,\n            globals(),\n            {\n                ""J"": message,\n                ""timedelta"": timedelta,\n                ""datetime"": datetime,\n                ""SKIP"": self._SKIP,\n            },\n        )\n\n\nUSAGE = b""""""\\\nUsage: cat eliot.log | python -m eliot.filter <expr>\n\nRead JSON-expression per line from stdin, and filter it using a Python\nexpression <expr>.\n\nThe expression will have a local `J` containing decoded JSON. `datetime` and\n`timedelta` from Python\'s `datetime` module are also available as locals,\ncontaining the corresponding classes. `SKIP` is also available, if it\'s the\nexpression result that indicates nothing should be output.\n\nThe output will be written to stdout using JSON serialization. `datetime`\nobjects will be serialized to ISO format.\n\nExamples:\n\n- Pass through the messages unchanged:\n\n    $ cat eliot.log | python -m eliot.filter J\n\n- Retrieve a specific field from a specific message type, dropping messages\n  of other types:\n\n    $ cat eliot.log | python -m eliot.filter \\\\\n        ""J[\'field\'] if J.get(\'message_type\') == \'my:message\' else SKIP""\n""""""\n\n\ndef main(sys=sys):\n    """"""\n    Run the program.\n\n    Accept arguments from L{sys.argv}, read from L{sys.stdin}, write to\n    L{sys.stdout}.\n\n    @param sys: An object with same interface and defaulting to the L{sys}\n        module.\n    """"""\n    if len(sys.argv) != 2:\n        sys.stderr.write(USAGE)\n        return 1\n    EliotFilter(sys.argv[1], sys.stdin, sys.stdout).run()\n    return 0\n'"
eliot/journald.py,0,"b'""""""\njournald support for Eliot.\n""""""\n\nfrom cffi import FFI\nfrom os import strerror\nfrom sys import argv\nfrom os.path import basename\n\nfrom ._bytesjson import dumps\nfrom ._message import TASK_UUID_FIELD, MESSAGE_TYPE_FIELD\nfrom ._action import ACTION_TYPE_FIELD, ACTION_STATUS_FIELD, FAILED_STATUS\n\n_ffi = FFI()\n_ffi.cdef(\n    """"""\nint sd_journal_send(const char *format, ...);\n""""""\n)\ntry:\n    try:\n        _journald = _ffi.dlopen(""libsystemd.so.0"")\n    except OSError:\n        # Older versions of systemd have separate library:\n        _journald = _ffi.dlopen(""libsystemd-journal.so.0"")\nexcept OSError as e:\n    raise ImportError(""Failed to load journald: "" + str(e))\n\n\ndef sd_journal_send(**kwargs):\n    """"""\n    Send a message to the journald log.\n\n    @param kwargs: Mapping between field names to values, both as bytes.\n\n    @raise IOError: If the operation failed.\n    """"""\n    # The function uses printf formatting, so we need to quote\n    # percentages.\n    fields = [\n        _ffi.new(""char[]"", key.encode(""ascii"") + b""="" + value.replace(b""%"", b""%%""))\n        for key, value in kwargs.items()\n    ]\n    fields.append(_ffi.NULL)\n    result = _journald.sd_journal_send(*fields)\n    if result != 0:\n        raise IOError(-result, strerror(-result))\n\n\nclass JournaldDestination(object):\n    """"""\n    A logging destination that writes to journald.\n\n    The message will be logged as JSON, with an additional field\n    C{ELIOT_TASK} storing the C{task_uuid} and C{ELIOT_TYPE} storing the\n    C{message_type} or C{action_type}.\n\n    Messages for failed actions will get priority 3 (""error""), and\n    traceback messages will get priority 2 (""critical""). All other\n    messages will get priority 1 (""info"").\n    """"""\n\n    def __init__(self):\n        self._identifier = basename(argv[0]).encode(""utf-8"")\n\n    def __call__(self, message):\n        """"""\n        Write the given message to journald.\n\n        @param message: Dictionary passed from a C{Logger}.\n        """"""\n        eliot_type = """"\n        priority = b""6""\n        if ACTION_TYPE_FIELD in message:\n            eliot_type = message[ACTION_TYPE_FIELD]\n            if message[ACTION_STATUS_FIELD] == FAILED_STATUS:\n                priority = b""3""\n        elif MESSAGE_TYPE_FIELD in message:\n            eliot_type = message[MESSAGE_TYPE_FIELD]\n            if eliot_type == ""eliot:traceback"":\n                priority = b""2""\n        sd_journal_send(\n            MESSAGE=dumps(message),\n            ELIOT_TASK=message[TASK_UUID_FIELD].encode(""utf-8""),\n            ELIOT_TYPE=eliot_type.encode(""utf-8""),\n            SYSLOG_IDENTIFIER=self._identifier,\n            PRIORITY=priority,\n        )\n'"
eliot/json.py,0,"b'""""""Custom JSON encoding support.""""""\n\nfrom __future__ import absolute_import\n\nimport json\nimport sys\n\n\nclass EliotJSONEncoder(json.JSONEncoder):\n    """"""JSON encoder with additional functionality.\n\n    In particular, supports NumPy types.\n    """"""\n\n    def default(self, o):\n        numpy = sys.modules.get(""numpy"", None)\n        if numpy is not None:\n            if isinstance(o, numpy.floating):\n                return float(o)\n            if isinstance(o, numpy.integer):\n                return int(o)\n            if isinstance(o, (numpy.bool, numpy.bool_)):\n                return bool(o)\n            if isinstance(o, numpy.ndarray):\n                if o.size > 10000:\n                    # Too big to want to log as-is, log a summary:\n                    return {\n                        ""array_start"": o.flat[:10000].tolist(),\n                        ""original_shape"": o.shape,\n                    }\n                else:\n                    return o.tolist()\n        return json.JSONEncoder.default(self, o)\n\n\n__all__ = [""EliotJSONEncoder""]\n'"
eliot/logwriter.py,0,"b'""""""\nA log destination for use by Twisted applications.\n\nRuns in a thread, so that we don\'t do blocking I/O in the event loop thread.\n""""""\n\nfrom __future__ import unicode_literals, absolute_import\n\nimport threading\nimport select\nfrom warnings import warn\n\nfrom twisted.application.service import Service\nfrom twisted.internet.threads import deferToThreadPool\n\nif getattr(select, ""poll"", None):\n    from twisted.internet.pollreactor import PollReactor as Reactor\nelse:\n    from twisted.internet.selectreactor import SelectReactor as Reactor\n\nfrom . import addDestination, removeDestination\nfrom ._output import FileDestination\n\n\nclass ThreadedWriter(Service):\n    """"""\n    An non-blocking Eliot log destination that wraps a blocking\n    destination, writing log messages to the latter in a managed thread.\n\n    Unfortunately Python\'s Queue is not reentrant\n    (http://bugs.python.org/issue14976) and neither is RLock\n    (http://bugs.python.org/issue13697). In order to queue items in a thread we\n    therefore rely on the self-pipe trick, and the easiest way to do that is by\n    running another reactor in the thread.\n\n    @ivar _reactor: A private reactor running in a thread which will do the log\n        writes.\n\n    @ivar _thread: C{None}, or a L{threading.Thread} running the private\n        reactor.\n    """"""\n\n    name = ""Eliot Log Writer""\n\n    def __init__(self, destination, reactor):\n        """"""\n        @param destination: The underlying destination for log files. This will\n            be called from a non-reactor thread.\n\n        @param reactor: The main reactor.\n        """"""\n        self._destination = destination\n        self._reactor = Reactor()\n        # Ick. See https://twistedmatrix.com/trac/ticket/6982 for real solution.\n        self._reactor._registerAsIOThread = False\n        self._mainReactor = reactor\n        self._thread = None\n\n    def startService(self):\n        """"""\n        Start the writer thread.\n        """"""\n        Service.startService(self)\n        self._thread = threading.Thread(target=self._writer)\n        self._thread.start()\n        addDestination(self)\n\n    def stopService(self):\n        """"""\n        Stop the writer thread, wait for it to finish.\n        """"""\n        Service.stopService(self)\n        removeDestination(self)\n        self._reactor.callFromThread(self._reactor.stop)\n        return deferToThreadPool(\n            self._mainReactor, self._mainReactor.getThreadPool(), self._thread.join\n        )\n\n    def __call__(self, data):\n        """"""\n        Add the data to the queue, to be serialized to JSON and written by the\n        writer thread with a newline added.\n\n        @param data: C{bytes} to write to disk.\n        """"""\n        self._reactor.callFromThread(self._destination, data)\n\n    def _writer(self):\n        """"""\n        The function run by the writer thread.\n        """"""\n        self._reactor.run(installSignalHandlers=False)\n\n\nclass ThreadedFileWriter(ThreadedWriter):\n    """"""\n    ``ThreadedWriter`` that takes a log file and writes to it using a\n    ``FileDestination``.\n\n    This exists for backwards compatibility purpose. The recommended API is\n    ``ThreadedWriter``.\n    """"""\n\n    def __init__(self, logFile, reactor):\n        """"""\n        @param logFile: A C{file}-like object that is at the end of its\n            existing contents (e.g. opened with append mode) and accepts\n            bytes.\n        @type logFile: C{file}, or any file-like object with C{write},\n            C{flush} and C{close} methods e.g. a\n            L{twisted.python.logfile.LogFile} if you want log rotation.\n\n        @param reactor: The main reactor.\n        """"""\n        warn(\n            ""ThreadedFileWriter is deprecated since 0.9.0. ""\n            ""Use ThreadedWriter instead."",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        self._logFile = logFile\n        ThreadedWriter.__init__(self, FileDestination(file=logFile), reactor)\n\n    def stopService(self):\n        d = ThreadedWriter.stopService(self)\n        d.addCallback(lambda _: self._logFile.close())\n        return d\n'"
eliot/parse.py,0,"b'""""""\nParse a stream of serialized messages into a forest of\n``WrittenAction`` and ``WrittenMessage`` objects.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom six import text_type as unicode\n\nfrom pyrsistent import PClass, pmap_field, pset_field, discard\n\nfrom ._message import WrittenMessage, TASK_UUID_FIELD\nfrom ._action import (\n    TaskLevel,\n    WrittenAction,\n    ACTION_STATUS_FIELD,\n    STARTED_STATUS,\n    ACTION_TYPE_FIELD,\n)\n\n\nclass Task(PClass):\n    """"""\n    A tree of actions with the same task UUID.\n    """"""\n\n    _nodes = pmap_field(TaskLevel, (WrittenAction, WrittenMessage))\n    _completed = pset_field(TaskLevel)\n    _root_level = TaskLevel(level=[])\n\n    def root(self):\n        """"""\n        @return: The root L{WrittenAction}.\n        """"""\n        return self._nodes[self._root_level]\n\n    def is_complete(self):\n        """"""\n        @return bool: True only if all messages in the task tree have been\n        added to it.\n        """"""\n        return self._root_level in self._completed\n\n    def _insert_action(self, node):\n        """"""\n        Add a L{WrittenAction} to the tree.\n\n        Parent actions will be created as necessary.\n\n        @param child: A L{WrittenAction} to add to the tree.\n\n        @return: Updated L{Task}.\n        """"""\n        task = self\n        if (\n            node.end_message\n            and node.start_message\n            and (len(node.children) == node.end_message.task_level.level[-1] - 2)\n        ):\n            # Possibly this action is complete, make sure all sub-actions\n            # are complete:\n            completed = True\n            for child in node.children:\n                if (\n                    isinstance(child, WrittenAction)\n                    and child.task_level not in self._completed\n                ):\n                    completed = False\n                    break\n            if completed:\n                task = task.transform([""_completed""], lambda s: s.add(node.task_level))\n        task = task.transform([""_nodes"", node.task_level], node)\n        return task._ensure_node_parents(node)\n\n    def _ensure_node_parents(self, child):\n        """"""\n        Ensure the node (WrittenAction/WrittenMessage) is referenced by parent\n        nodes.\n\n        Parent actions will be created as necessary.\n\n        @param child: A L{WrittenMessage} or L{WrittenAction} which is\n            being added to the tree.\n\n        @return: Updated L{Task}.\n        """"""\n        task_level = child.task_level\n        if task_level.parent() is None:\n            return self\n\n        parent = self._nodes.get(task_level.parent())\n        if parent is None:\n            parent = WrittenAction(\n                task_level=task_level.parent(), task_uuid=child.task_uuid\n            )\n        parent = parent._add_child(child)\n        return self._insert_action(parent)\n\n    def add(self, message_dict):\n        """"""\n        Update the L{Task} with a dictionary containing a serialized Eliot\n        message.\n\n        @param message_dict: Dictionary whose task UUID matches this one.\n\n        @return: Updated L{Task}.\n        """"""\n        is_action = message_dict.get(ACTION_TYPE_FIELD) is not None\n        written_message = WrittenMessage.from_dict(message_dict)\n        if is_action:\n            action_level = written_message.task_level.parent()\n            action = self._nodes.get(action_level)\n            if action is None:\n                action = WrittenAction(\n                    task_level=action_level, task_uuid=message_dict[TASK_UUID_FIELD]\n                )\n            if message_dict[ACTION_STATUS_FIELD] == STARTED_STATUS:\n                # Either newly created MissingAction, or one created by\n                # previously added descendant of the action.\n                action = action._start(written_message)\n            else:\n                action = action._end(written_message)\n            return self._insert_action(action)\n        else:\n            # Special case where there is no action:\n            if written_message.task_level.level == [1]:\n                return self.transform(\n                    [""_nodes"", self._root_level],\n                    written_message,\n                    [""_completed""],\n                    lambda s: s.add(self._root_level),\n                )\n            else:\n                return self._ensure_node_parents(written_message)\n\n\nclass Parser(PClass):\n    """"""\n    Parse serialized Eliot messages into L{Task} instances.\n\n    @ivar _tasks: Map from UUID to corresponding L{Task}.\n    """"""\n\n    _tasks = pmap_field(unicode, Task)\n\n    def add(self, message_dict):\n        """"""\n        Update the L{Parser} with a dictionary containing a serialized Eliot\n        message.\n\n        @param message_dict: Dictionary of serialized Eliot message.\n\n        @return: Tuple of (list of completed L{Task} instances, updated\n            L{Parser}).\n        """"""\n        uuid = message_dict[TASK_UUID_FIELD]\n        if uuid in self._tasks:\n            task = self._tasks[uuid]\n        else:\n            task = Task()\n        task = task.add(message_dict)\n        if task.is_complete():\n            parser = self.transform([""_tasks"", uuid], discard)\n            return [task], parser\n        else:\n            parser = self.transform([""_tasks"", uuid], task)\n            return [], parser\n\n    def incomplete_tasks(self):\n        """"""\n        @return: List of L{Task} that are not yet complete.\n        """"""\n        return list(self._tasks.values())\n\n    @classmethod\n    def parse_stream(cls, iterable):\n        """"""\n        Parse a stream of messages into a stream of L{Task} instances.\n\n        :param iterable: An iterable of serialized Eliot message dictionaries.\n\n        :return: An iterable of parsed L{Task} instances. Remaining\n            incomplete L{Task} will be returned when the input stream is\n            exhausted.\n        """"""\n        parser = Parser()\n        for message_dict in iterable:\n            completed, parser = parser.add(message_dict)\n            for task in completed:\n                yield task\n        for task in parser.incomplete_tasks():\n            yield task\n\n\n__all__ = [""Parser"", ""Task"", ""TaskLevel"", ""WrittenMessage"", ""WrittenAction""]\n'"
eliot/prettyprint.py,0,"b'""""""\nAPI and command-line support for human-readable Eliot messages.\n""""""\n\nimport pprint\nimport argparse\nfrom datetime import datetime\nfrom sys import stdin, stdout\nfrom collections import OrderedDict\nfrom json import dumps\n\nfrom ._bytesjson import loads\nfrom ._message import (\n    TIMESTAMP_FIELD,\n    TASK_UUID_FIELD,\n    TASK_LEVEL_FIELD,\n    MESSAGE_TYPE_FIELD,\n)\nfrom ._action import ACTION_TYPE_FIELD, ACTION_STATUS_FIELD\n\n\n# Ensure binary stdin, since we expect specifically UTF-8 encoded\n# messages, not platform-encoding messages.\nstdin = stdin.buffer\n\n\n# Fields that all Eliot messages are expected to have:\nREQUIRED_FIELDS = {TASK_LEVEL_FIELD, TASK_UUID_FIELD, TIMESTAMP_FIELD}\n\n# Fields that get treated specially when formatting.\n_skip_fields = {\n    TIMESTAMP_FIELD,\n    TASK_UUID_FIELD,\n    TASK_LEVEL_FIELD,\n    MESSAGE_TYPE_FIELD,\n    ACTION_TYPE_FIELD,\n    ACTION_STATUS_FIELD,\n}\n\n# First fields to render:\n_first_fields = [ACTION_TYPE_FIELD, MESSAGE_TYPE_FIELD, ACTION_STATUS_FIELD]\n\n\ndef _render_timestamp(message: dict, local_timezone: bool) -> str:\n    """"""Convert a message\'s timestamp to a string.""""""\n    # If we were returning or storing the datetime we\'d want to use an\n    # explicit timezone instead of a naive datetime, but since we\'re\n    # just using it for formatting we needn\'t bother.\n    if local_timezone:\n        dt = datetime.fromtimestamp(message[TIMESTAMP_FIELD])\n    else:\n        dt = datetime.utcfromtimestamp(message[TIMESTAMP_FIELD])\n    result = dt.isoformat(sep=""T"")\n    if not local_timezone:\n        result += ""Z""\n    return result\n\n\ndef pretty_format(message: dict, local_timezone: bool = False) -> str:\n    """"""\n    Convert a message dictionary into a human-readable string.\n\n    @param message: Message to parse, as dictionary.\n\n    @return: Unicode string.\n    """"""\n\n    def add_field(previous, key, value):\n        value = (\n            pprint.pformat(value, width=40).replace(""\\\\n"", ""\\n "").replace(""\\\\t"", ""\\t"")\n        )\n        # Reindent second line and later to match up with first line\'s\n        # indentation:\n        lines = value.split(""\\n"")\n        # indent lines are ""  <key length>|  <value>""\n        indent = ""{}| "".format("" "" * (2 + len(key)))\n        value = ""\\n"".join([lines[0]] + [indent + l for l in lines[1:]])\n        return ""  %s: %s\\n"" % (key, value)\n\n    remaining = """"\n    for field in _first_fields:\n        if field in message:\n            remaining += add_field(remaining, field, message[field])\n    for (key, value) in sorted(message.items()):\n        if key not in _skip_fields:\n            remaining += add_field(remaining, key, value)\n\n    level = ""/"" + ""/"".join(map(str, message[TASK_LEVEL_FIELD]))\n    return ""%s -> %s\\n%s\\n%s"" % (\n        message[TASK_UUID_FIELD],\n        level,\n        _render_timestamp(message, local_timezone),\n        remaining,\n    )\n\n\ndef compact_format(message: dict, local_timezone: bool = False) -> str:\n    """"""Format an Eliot message into a single line.\n\n    The message is presumed to be JSON-serializable.\n    """"""\n    ordered_message = OrderedDict()\n    for field in _first_fields:\n        if field in message:\n            ordered_message[field] = message[field]\n    for (key, value) in sorted(message.items()):\n        if key not in _skip_fields:\n            ordered_message[key] = value\n    # drop { and } from JSON:\n    rendered = "" "".join(\n        ""{}={}"".format(key, dumps(value, separators=("","", "":"")))\n        for (key, value) in ordered_message.items()\n    )\n\n    return ""%s%s %s %s"" % (\n        message[TASK_UUID_FIELD],\n        ""/"" + ""/"".join(map(str, message[TASK_LEVEL_FIELD])),\n        _render_timestamp(message, local_timezone),\n        rendered,\n    )\n\n\n_CLI_HELP = """"""\\\nConvert Eliot messages into more readable format.\n\nReads JSON lines from stdin, write out pretty-printed results on stdout.\n""""""\n\n\ndef _main():\n    """"""\n    Command-line program that reads in JSON from stdin and writes out\n    pretty-printed messages to stdout.\n    """"""\n    parser = argparse.ArgumentParser(\n        description=_CLI_HELP, usage=""cat messages | %(prog)s [options]""\n    )\n    parser.add_argument(\n        ""-c"",\n        ""--compact"",\n        action=""store_true"",\n        dest=""compact"",\n        help=""Compact format, one message per line."",\n    )\n    parser.add_argument(\n        ""-l"",\n        ""--local-timezone"",\n        action=""store_true"",\n        dest=""local_timezone"",\n        help=""Use local timezone instead of UTC."",\n    )\n\n    args = parser.parse_args()\n    if args.compact:\n        formatter = compact_format\n    else:\n        formatter = pretty_format\n\n    for line in stdin:\n        try:\n            message = loads(line)\n        except ValueError:\n            stdout.write(""Not JSON: {}\\n\\n"".format(line.rstrip(b""\\n"")))\n            continue\n        if REQUIRED_FIELDS - set(message.keys()):\n            stdout.write(""Not an Eliot message: {}\\n\\n"".format(line.rstrip(b""\\n"")))\n            continue\n        result = formatter(message, args.local_timezone) + ""\\n""\n        stdout.write(result)\n\n\n__all__ = [""pretty_format"", ""compact_format""]\n'"
eliot/serializers.py,0,"b'""""""\nStandardized serialization code.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom hashlib import md5\n\n_TIME_FORMAT = ""%Y-%m-%dT%H:%M:%S.%fZ""\n\n\ndef timestamp(dt):\n    """"""\n    Convert a UTC datetime to a string.\n\n    @param dt: A C{datetime.datetime} in UTC timezone.\n\n    @return: C{unicode}\n    """"""\n    return dt.strftime(_TIME_FORMAT)\n\n\ndef identity(value):\n    """"""\n    Return the passed in object.\n    """"""\n    return value\n\n\ndef md5hex(data):\n    """"""\n    Return hex MD5 of the input bytes.\n\n    @param data: Some C{bytes}.\n\n    @return: Hex-encoded MD5 of the data.\n    """"""\n    return md5(data).hexdigest()\n'"
eliot/stdlib.py,0,"b'""""""Integration with the standard library ``logging`` package.""""""\n\nfrom logging import Handler\n\nfrom ._action import log_message\nfrom ._traceback import write_traceback\n\n\nclass EliotHandler(Handler):\n    """"""A C{logging.Handler} that routes log messages to Eliot.""""""\n\n    def emit(self, record):\n        log_message(\n            message_type=""eliot:stdlib"",\n            log_level=record.levelname,\n            logger=record.name,\n            message=record.getMessage(),\n        )\n        if record.exc_info:\n            write_traceback(exc_info=record.exc_info)\n\n\n__all__ = [""EliotHandler""]\n'"
eliot/tai64n.py,0,"b'""""""\nTAI64N encoding and decoding.\n\nTAI64N encodes nanosecond-accuracy timestamps and is supported by logstash.\n\n@see: U{http://cr.yp.to/libtai/tai64.html}.\n""""""\n\nfrom __future__ import unicode_literals\n\nimport struct\nfrom binascii import b2a_hex, a2b_hex\n\n_STRUCTURE = b"">QI""\n_OFFSET = (2 ** 62) + 10  # last 10 are leap seconds\n\n\ndef encode(timestamp):\n    """"""\n    Convert seconds since epoch to TAI64N string.\n\n    @param timestamp: Seconds since UTC Unix epoch as C{float}.\n\n    @return: TAI64N-encoded time, as C{unicode}.\n    """"""\n    seconds = int(timestamp)\n    nanoseconds = int((timestamp - seconds) * 1000000000)\n    seconds = seconds + _OFFSET\n    encoded = b2a_hex(struct.pack(_STRUCTURE, seconds, nanoseconds))\n    return ""@"" + encoded.decode(""ascii"")\n\n\ndef decode(tai64n):\n    """"""\n    Convert TAI64N string to seconds since epoch.\n\n    Note that dates before 2013 may not decode accurately due to leap second\n    issues. If you need correct decoding for earlier dates you can try the\n    tai64n package available from PyPI (U{https://pypi.python.org/pypi/tai64n}).\n\n    @param tai64n: TAI64N-encoded time, as C{unicode}.\n\n    @return: Seconds since UTC Unix epoch as C{float}.\n    """"""\n    seconds, nanoseconds = struct.unpack(_STRUCTURE, a2b_hex(tai64n[1:]))\n    seconds -= _OFFSET\n    return seconds + (nanoseconds / 1000000000.0)\n'"
eliot/testing.py,0,"b'""""""\nUtilities to aid unit testing L{eliot} and code that uses it.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom unittest import SkipTest\nfrom functools import wraps\n\nfrom pyrsistent import PClass, field\nfrom six import text_type\n\nfrom ._action import (\n    ACTION_STATUS_FIELD,\n    ACTION_TYPE_FIELD,\n    STARTED_STATUS,\n    FAILED_STATUS,\n    SUCCEEDED_STATUS,\n)\nfrom ._message import MESSAGE_TYPE_FIELD, TASK_LEVEL_FIELD, TASK_UUID_FIELD\nfrom ._output import MemoryLogger\nfrom . import _output\n\nCOMPLETED_STATUSES = (FAILED_STATUS, SUCCEEDED_STATUS)\n\n\ndef issuperset(a, b):\n    """"""\n    Use L{assertContainsFields} instead.\n\n    @type a: C{dict}\n\n    @type b: C{dict}\n\n    @return: Boolean indicating whether C{a} has all key/value pairs that C{b}\n        does.\n    """"""\n    aItems = a.items()\n    return all(pair in aItems for pair in b.items())\n\n\ndef assertContainsFields(test, message, fields):\n    """"""\n    Assert that the given message contains the given fields.\n\n    @param test: L{unittest.TestCase} being run.\n\n    @param message: C{dict}, the message we are checking.\n\n    @param fields: C{dict}, the fields we expect the message to have.\n\n    @raises AssertionError: If the message doesn\'t contain the fields.\n    """"""\n    messageSubset = dict(\n        [(key, value) for key, value in message.items() if key in fields]\n    )\n    test.assertEqual(messageSubset, fields)\n\n\nclass LoggedAction(PClass):\n    """"""\n    An action whose start and finish messages have been logged.\n\n    @ivar startMessage: A C{dict}, the start message contents. Also\n        available as C{start_message}.\n\n    @ivar endMessage: A C{dict}, the end message contents (in both success and\n        failure cases). Also available as C{end_message}.\n\n    @ivar children: A C{list} of direct child L{LoggedMessage} and\n        L{LoggedAction} instances.\n    """"""\n\n    startMessage = field(mandatory=True)\n    endMessage = field(mandatory=True)\n    children = field(mandatory=True)\n\n    def __new__(cls, startMessage, endMessage, children):\n        return PClass.__new__(\n            cls, startMessage=startMessage, endMessage=endMessage, children=children\n        )\n\n    @property\n    def start_message(self):\n        return self.startMessage\n\n    @property\n    def end_message(self):\n        return self.endMessage\n\n    @classmethod\n    def fromMessages(klass, uuid, level, messages):\n        """"""\n        Given a task uuid and level (identifying an action) and a list of\n        dictionaries, create a L{LoggedAction}.\n\n        All child messages and actions will be added as L{LoggedAction} or\n        L{LoggedMessage} children. Note that some descendant messages may be\n        missing if you end up logging to two or more different ILogger\n        providers.\n\n        @param uuid: The uuid of the task (C{unicode}).\n\n        @param level: The C{task_level} of the action\'s start message,\n            e.g. C{""/1/2/1""}.\n\n        @param messages: A list of message C{dict}s.\n\n        @return: L{LoggedAction} constructed from start and finish messages for\n            this specific action.\n\n        @raises: L{ValueError} if one or both of the action\'s messages cannot be\n            found.\n        """"""\n        startMessage = None\n        endMessage = None\n        children = []\n        levelPrefix = level[:-1]\n\n        for message in messages:\n            if message[TASK_UUID_FIELD] != uuid:\n                # Different task altogether:\n                continue\n\n            messageLevel = message[TASK_LEVEL_FIELD]\n\n            if messageLevel[:-1] == levelPrefix:\n                status = message.get(ACTION_STATUS_FIELD)\n                if status == STARTED_STATUS:\n                    startMessage = message\n                elif status in COMPLETED_STATUSES:\n                    endMessage = message\n                else:\n                    # Presumably a message in this action:\n                    children.append(LoggedMessage(message))\n            elif (\n                len(messageLevel) == len(levelPrefix) + 2\n                and messageLevel[:-2] == levelPrefix\n                and messageLevel[-1] == 1\n            ):\n                # If start message level is [1], [1, 2, 1] implies first\n                # message of a direct child.\n                child = klass.fromMessages(uuid, message[TASK_LEVEL_FIELD], messages)\n                children.append(child)\n        if startMessage is None:\n            raise ValueError(""Missing start message"")\n        if endMessage is None:\n            raise ValueError(\n                ""Missing end message of type ""\n                + message.get(ACTION_TYPE_FIELD, ""unknown"")\n            )\n        return klass(startMessage, endMessage, children)\n\n    # PEP 8 variant:\n    from_messages = fromMessages\n\n    @classmethod\n    def of_type(klass, messages, actionType):\n        """"""\n        Find all L{LoggedAction} of the specified type.\n\n        @param messages: A list of message C{dict}s.\n\n        @param actionType: A L{eliot.ActionType}, the type of the actions to\n            find, or the type as a C{str}.\n\n        @return: A C{list} of L{LoggedAction}.\n        """"""\n        if not isinstance(actionType, text_type):\n            actionType = actionType.action_type\n        result = []\n        for message in messages:\n            if (\n                message.get(ACTION_TYPE_FIELD) == actionType\n                and message[ACTION_STATUS_FIELD] == STARTED_STATUS\n            ):\n                result.append(\n                    klass.fromMessages(\n                        message[TASK_UUID_FIELD], message[TASK_LEVEL_FIELD], messages\n                    )\n                )\n        return result\n\n    # Backwards compat:\n    ofType = of_type\n\n    def descendants(self):\n        """"""\n        Find all descendant L{LoggedAction} or L{LoggedMessage} of this\n        instance.\n\n        @return: An iterable of L{LoggedAction} and L{LoggedMessage} instances.\n        """"""\n        for child in self.children:\n            yield child\n            if isinstance(child, LoggedAction):\n                for descendant in child.descendants():\n                    yield descendant\n\n    @property\n    def succeeded(self):\n        """"""\n        Indicate whether this action succeeded.\n\n        @return: C{bool} indicating whether the action succeeded.\n        """"""\n        return self.endMessage[ACTION_STATUS_FIELD] == SUCCEEDED_STATUS\n\n    def type_tree(self):\n        """"""Return dictionary of all child action and message types.\n\n        Actions become dictionaries that look like\n        C{{<action_type>: [<child_message_type>, <child_action_dict>]}}\n\n        @return: C{dict} where key is action type, and value is list of child\n            types: either strings for messages, or dicts for actions.\n        """"""\n        children = []\n        for child in self.children:\n            if isinstance(child, LoggedAction):\n                children.append(child.type_tree())\n            else:\n                children.append(child.message[MESSAGE_TYPE_FIELD])\n        return {self.startMessage[ACTION_TYPE_FIELD]: children}\n\n\nclass LoggedMessage(PClass):\n    """"""\n    A message that has been logged.\n\n    @ivar message: A C{dict}, the message contents.\n    """"""\n\n    message = field(mandatory=True)\n\n    def __new__(cls, message):\n        return PClass.__new__(cls, message=message)\n\n    @classmethod\n    def of_type(klass, messages, messageType):\n        """"""\n        Find all L{LoggedMessage} of the specified type.\n\n        @param messages: A list of message C{dict}s.\n\n        @param messageType: A L{eliot.MessageType}, the type of the messages\n            to find, or the type as a L{str}.\n\n        @return: A C{list} of L{LoggedMessage}.\n        """"""\n        result = []\n        if not isinstance(messageType, text_type):\n            messageType = messageType.message_type\n        for message in messages:\n            if message.get(MESSAGE_TYPE_FIELD) == messageType:\n                result.append(klass(message))\n        return result\n\n    # Backwards compat:\n    ofType = of_type\n\n\nclass UnflushedTracebacks(Exception):\n    """"""\n    The L{MemoryLogger} had some tracebacks logged which were not flushed.\n\n    This means either your code has a bug and logged an unexpected\n    traceback. If you expected the traceback then you will need to flush it\n    using L{MemoryLogger.flushTracebacks}.\n    """"""\n\n\ndef check_for_errors(logger):\n    """"""\n    Raise exception if logger has unflushed tracebacks or validation errors.\n\n    @param logger: A L{MemoryLogger}.\n\n    @raise L{UnflushedTracebacks}: If any tracebacks were unflushed.\n    """"""\n    # Check for unexpected tracebacks first, since that indicates business\n    # logic errors:\n    if logger.tracebackMessages:\n        raise UnflushedTracebacks(logger.tracebackMessages)\n    # If those are fine, validate the logging:\n    logger.validate()\n\n\ndef swap_logger(logger):\n    """"""Swap out the global logging sink.\n\n    @param logger: An C{ILogger}.\n\n    @return: The current C{ILogger}.\n    """"""\n    previous_logger = _output._DEFAULT_LOGGER\n    _output._DEFAULT_LOGGER = logger\n    return previous_logger\n\n\ndef validateLogging(assertion, *assertionArgs, **assertionKwargs):\n    """"""\n    Decorator factory for L{unittest.TestCase} methods to add logging\n    validation.\n\n    1. The decorated test method gets a C{logger} keyword argument, a\n       L{MemoryLogger}.\n    2. All messages logged to this logger will be validated at the end of\n       the test.\n    3. Any unflushed logged tracebacks will cause the test to fail.\n\n    For example:\n\n        from unittest import TestCase\n        from eliot.testing import assertContainsFields, validateLogging\n\n        class MyTests(TestCase):\n            def assertFooLogging(self, logger):\n                assertContainsFields(self, logger.messages[0], {""key"": 123})\n\n\n    @param assertion: A callable that will be called with the\n       L{unittest.TestCase} instance, the logger and C{assertionArgs} and\n       C{assertionKwargs} once the actual test has run, allowing for extra\n       logging-related assertions on the effects of the test. Use L{None} if you\n       want the cleanup assertions registered but no custom assertions.\n\n    @param assertionArgs: Additional positional arguments to pass to\n        C{assertion}.\n\n    @param assertionKwargs: Additional keyword arguments to pass to\n        C{assertion}.\n    """"""\n\n    def decorator(function):\n        @wraps(function)\n        def wrapper(self, *args, **kwargs):\n            skipped = False\n\n            kwargs[""logger""] = logger = MemoryLogger()\n            self.addCleanup(check_for_errors, logger)\n            # TestCase runs cleanups in reverse order, and we want this to\n            # run *before* tracebacks are checked:\n            if assertion is not None:\n                self.addCleanup(\n                    lambda: skipped\n                    or assertion(self, logger, *assertionArgs, **assertionKwargs)\n                )\n            try:\n                return function(self, *args, **kwargs)\n            except SkipTest:\n                skipped = True\n                raise\n\n        return wrapper\n\n    return decorator\n\n\n# PEP 8 variant:\nvalidate_logging = validateLogging\n\n\ndef capture_logging(assertion, *assertionArgs, **assertionKwargs):\n    """"""\n    Capture and validate all logging that doesn\'t specify a L{Logger}.\n\n    See L{validate_logging} for details on the rest of its behavior.\n    """"""\n\n    def decorator(function):\n        @validate_logging(assertion, *assertionArgs, **assertionKwargs)\n        @wraps(function)\n        def wrapper(self, *args, **kwargs):\n            logger = kwargs[""logger""]\n            previous_logger = swap_logger(logger)\n\n            def cleanup():\n                swap_logger(previous_logger)\n\n            self.addCleanup(cleanup)\n            return function(self, *args, **kwargs)\n\n        return wrapper\n\n    return decorator\n\n\ndef assertHasMessage(testCase, logger, messageType, fields=None):\n    """"""\n    Assert that the given logger has a message of the given type, and the first\n    message found of this type has the given fields.\n\n    This can be used as the assertion function passed to L{validateLogging} or\n    as part of a unit test.\n\n    @param testCase: L{unittest.TestCase} instance.\n\n    @param logger: L{eliot.MemoryLogger} whose messages will be checked.\n\n    @param messageType: L{eliot.MessageType} indicating which message we\'re\n        looking for.\n\n    @param fields: The first message of the given type found must have a\n        superset of the given C{dict} as its fields. If C{None} then fields are\n        not checked.\n\n    @return: The first found L{LoggedMessage} of the given type, if field\n        validation succeeded.\n\n    @raises AssertionError: No message was found, or the fields were not\n        superset of given fields.\n    """"""\n    if fields is None:\n        fields = {}\n    messages = LoggedMessage.ofType(logger.messages, messageType)\n    testCase.assertTrue(messages, ""No messages of type %s"" % (messageType,))\n    loggedMessage = messages[0]\n    assertContainsFields(testCase, loggedMessage.message, fields)\n    return loggedMessage\n\n\ndef assertHasAction(\n    testCase, logger, actionType, succeeded, startFields=None, endFields=None\n):\n    """"""\n    Assert that the given logger has an action of the given type, and the first\n    action found of this type has the given fields and success status.\n\n    This can be used as the assertion function passed to L{validateLogging} or\n    as part of a unit test.\n\n    @param testCase: L{unittest.TestCase} instance.\n\n    @param logger: L{eliot.MemoryLogger} whose messages will be checked.\n\n    @param actionType: L{eliot.ActionType} or C{str} indicating which message\n        we\'re looking for.\n\n    @param succeeded: Expected success status of the action, a C{bool}.\n\n    @param startFields: The first action of the given type found must have a\n        superset of the given C{dict} as its start fields.  If C{None} then\n        fields are not checked.\n\n    @param endFields: The first action of the given type found must have a\n        superset of the given C{dict} as its end fields.  If C{None} then\n        fields are not checked.\n\n    @return: The first found L{LoggedAction} of the given type, if field\n        validation succeeded.\n\n    @raises AssertionError: No action was found, or the fields were not\n        superset of given fields.\n    """"""\n    if startFields is None:\n        startFields = {}\n    if endFields is None:\n        endFields = {}\n    actions = LoggedAction.ofType(logger.messages, actionType)\n    testCase.assertTrue(actions, ""No actions of type %s"" % (actionType,))\n    action = actions[0]\n    testCase.assertEqual(action.succeeded, succeeded)\n    assertContainsFields(testCase, action.startMessage, startFields)\n    assertContainsFields(testCase, action.endMessage, endFields)\n    return action\n'"
eliot/twisted.py,0,"b'""""""\nAPIs for using Eliot from Twisted.\n""""""\n\nfrom __future__ import absolute_import, unicode_literals\n\nimport os\nimport sys\n\nfrom twisted.logger import Logger as TwistedLogger\nfrom twisted.python.failure import Failure\nfrom twisted.internet.defer import inlineCallbacks\n\nfrom ._action import current_action\nfrom . import addDestination\nfrom ._generators import eliot_friendly_generator_function\n\n__all__ = [\n    ""AlreadyFinished"",\n    ""DeferredContext"",\n    ""redirectLogsForTrial"",\n    ""inline_callbacks"",\n]\n\n\ndef _passthrough(result):\n    return result\n\n\nclass AlreadyFinished(Exception):\n    """"""\n    L{DeferredContext.addCallbacks} or similar method was called after\n    L{DeferredContext.addActionFinish}.\n\n    This indicates a programming bug, e.g. forgetting to unwrap the\n    underlying L{Deferred} when passing on to some other piece of code that\n    doesn\'t care about the action context.\n    """"""\n\n\nclass DeferredContext(object):\n    """"""\n    A L{Deferred} equivalent of L{eliot.Action.context} and\n    L{eliot.action.finish}.\n\n    Makes a L{Deferred}\'s callbacks run in a L{eliot.Action}\'s context, and\n    allows indicating which callbacks to wait for before the action is\n    finished.\n\n    The action to use will be taken from the call context.\n\n    @ivar result: The wrapped L{Deferred}.\n    """"""\n\n    def __init__(self, deferred):\n        """"""\n        @param deferred: L{twisted.internet.defer.Deferred} to wrap.\n        """"""\n        self.result = deferred\n        self._action = current_action()\n        self._finishAdded = False\n        if self._action is None:\n            raise RuntimeError(\n                ""DeferredContext() should only be created in the context of ""\n                ""an eliot.Action.""\n            )\n\n    def addCallbacks(\n        self,\n        callback,\n        errback=None,\n        callbackArgs=None,\n        callbackKeywords=None,\n        errbackArgs=None,\n        errbackKeywords=None,\n    ):\n        """"""\n        Add a pair of callbacks that will be run in the context of an eliot\n        action.\n\n        @return: C{self}\n        @rtype: L{DeferredContext}\n\n        @raises AlreadyFinished: L{DeferredContext.addActionFinish} has been\n            called. This indicates a programmer error.\n        """"""\n        if self._finishAdded:\n            raise AlreadyFinished()\n\n        if errback is None:\n            errback = _passthrough\n\n        def callbackWithContext(*args, **kwargs):\n            return self._action.run(callback, *args, **kwargs)\n\n        def errbackWithContext(*args, **kwargs):\n            return self._action.run(errback, *args, **kwargs)\n\n        self.result.addCallbacks(\n            callbackWithContext,\n            errbackWithContext,\n            callbackArgs,\n            callbackKeywords,\n            errbackArgs,\n            errbackKeywords,\n        )\n        return self\n\n    def addCallback(self, callback, *args, **kw):\n        """"""\n        Add a success callback that will be run in the context of an eliot\n        action.\n\n        @return: C{self}\n        @rtype: L{DeferredContext}\n\n        @raises AlreadyFinished: L{DeferredContext.addActionFinish} has been\n            called. This indicates a programmer error.\n        """"""\n        return self.addCallbacks(\n            callback, _passthrough, callbackArgs=args, callbackKeywords=kw\n        )\n\n    def addErrback(self, errback, *args, **kw):\n        """"""\n        Add a failure callback that will be run in the context of an eliot\n        action.\n\n        @return: C{self}\n        @rtype: L{DeferredContext}\n\n        @raises AlreadyFinished: L{DeferredContext.addActionFinish} has been\n            called. This indicates a programmer error.\n        """"""\n        return self.addCallbacks(\n            _passthrough, errback, errbackArgs=args, errbackKeywords=kw\n        )\n\n    def addBoth(self, callback, *args, **kw):\n        """"""\n        Add a single callback as both success and failure callbacks.\n\n        @return: C{self}\n        @rtype: L{DeferredContext}\n\n        @raises AlreadyFinished: L{DeferredContext.addActionFinish} has been\n            called. This indicates a programmer error.\n        """"""\n        return self.addCallbacks(callback, callback, args, kw, args, kw)\n\n    def addActionFinish(self):\n        """"""\n        Indicates all callbacks that should run within the action\'s context\n        have been added, and that the action should therefore finish once\n        those callbacks have fired.\n\n        @return: The wrapped L{Deferred}.\n\n        @raises AlreadyFinished: L{DeferredContext.addActionFinish} has been\n            called previously. This indicates a programmer error.\n        """"""\n        if self._finishAdded:\n            raise AlreadyFinished()\n        self._finishAdded = True\n\n        def done(result):\n            if isinstance(result, Failure):\n                exception = result.value\n            else:\n                exception = None\n            self._action.finish(exception)\n            return result\n\n        self.result.addBoth(done)\n        return self.result\n\n\nclass TwistedDestination(object):\n    """"""\n    An Eliot logging destination that forwards logs to Twisted\'s logging.\n\n    Do not use if you\'re also redirecting Twisted\'s logs to Eliot, since then\n    you\'ll have an infinite loop.\n    """"""\n\n    def __init__(self):\n        self._logger = TwistedLogger(namespace=""eliot"")\n\n    def __call__(self, message):\n        """"""\n        Log an Eliot message to Twisted\'s log.\n\n        @param message: A rendered Eliot message.\n        @type message: L{dict}\n        """"""\n        if message.get(""message_type"") == ""eliot:traceback"":\n            method = self._logger.critical\n        else:\n            method = self._logger.info\n        method(format=""Eliot message: {eliot}"", eliot=message)\n\n\nclass _RedirectLogsForTrial(object):\n    """"""\n    When called inside a I{trial} process redirect Eliot log messages to\n    Twisted\'s logging system, otherwise do nothing.\n\n    This allows reading Eliot logs output by running unit tests with\n    I{trial} in its normal log location: C{_trial_temp/test.log}.\n\n    The way you use it is by calling it a module level in some module that will\n    be loaded by trial, typically the top-level C{__init__.py} of your package.\n\n    This function can usually be safely called in all programs since it will\n    have no side-effects if used outside of trial. The only exception is you\n    are redirecting Twisted logs to Eliot; you should make sure not call\n    this function in that case so as to prevent infinite loops. In addition,\n    calling the function multiple times has the same effect as calling it\n    once.\n\n    (This is not thread-safe at the moment, so in theory multiple threads\n    calling this might result in multiple destinatios being added - see\n    https://github.com/itamarst/eliot/issues/78).\n\n    Currently this works by checking if C{sys.argv[0]} is called C{trial};\n    the ideal mechanism would require\n    https://twistedmatrix.com/trac/ticket/6939 to be fixed, but probably\n    there are better solutions even without that -\n    https://github.com/itamarst/eliot/issues/76 covers those.\n\n    @ivar _sys: An object similar to, and typically identical to, Python\'s\n        L{sys} module.\n\n    @ivar _redirected: L{True} if trial logs have been redirected once already.\n    """"""\n\n    def __init__(self, sys):\n        self._sys = sys\n        self._redirected = False\n\n    def __call__(self):\n        """"""\n        Do the redirect if necessary.\n\n        @return: The destination added to Eliot if any, otherwise L{None}.\n        """"""\n        if os.path.basename(self._sys.argv[0]) == ""trial"" and not self._redirected:\n            self._redirected = True\n            destination = TwistedDestination()\n            addDestination(destination)\n            return destination\n\n\nredirectLogsForTrial = _RedirectLogsForTrial(sys)\n\n\ndef inline_callbacks(original, debug=False):\n    """"""\n    Decorate a function like ``inlineCallbacks`` would but in a more\n    Eliot-friendly way.  Use it just like ``inlineCallbacks`` but where you\n    want Eliot action contexts to Do The Right Thing inside the decorated\n    function.\n    """"""\n    f = eliot_friendly_generator_function(original)\n    if debug:\n        f.debug = True\n    return inlineCallbacks(f)\n'"
examples/asyncio_linkcheck.py,0,"b'import asyncio\nimport aiohttp\nfrom eliot import start_action, to_file\nto_file(open(""linkcheck.log"", ""w""))\n\n\nasync def check_links(urls):\n    session = aiohttp.ClientSession()\n    with start_action(action_type=""check_links"", urls=urls):\n        for url in urls:\n            try:\n                with start_action(action_type=""download"", url=url):\n                    async with session.get(url) as response:\n                        response.raise_for_status()\n            except Exception as e:\n                raise ValueError(str(e))\n\ntry:\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(\n        check_links([""http://eliot.readthedocs.io"", ""http://nosuchurl""])\n    )\nexcept ValueError:\n    print(""Not all links were valid."")\n'"
examples/cross_process_client.py,0,"b'""""""\nCross-process log tracing: HTTP client.\n""""""\nfrom __future__ import unicode_literals\n\nimport sys\nimport requests\n\nfrom eliot import to_file, start_action, add_global_fields\nadd_global_fields(process=""client"")\nto_file(sys.stdout)\n\n\ndef remote_divide(x, y):\n    with start_action(action_type=""http_request"", x=x, y=y) as action:\n        task_id = action.serialize_task_id()\n        response = requests.get(\n            ""http://localhost:5000/?x={}&y={}"".format(x, y),\n            headers={""x-eliot-task-id"": task_id})\n        response.raise_for_status()  # ensure this is a successful response\n        result = float(response.text)\n        action.add_success_fields(result=result)\n        return result\n\n\nif __name__ == \'__main__\':\n    with start_action(action_type=""main""):\n        remote_divide(int(sys.argv[1]), int(sys.argv[2]))\n'"
examples/cross_process_server.py,0,"b'""""""\nCross-process log tracing: HTTP server.\n""""""\nfrom __future__ import unicode_literals\n\nimport sys\nfrom flask import Flask, request\n\nfrom eliot import to_file, Action, start_action, add_global_fields\nadd_global_fields(process=""server"")\nto_file(sys.stdout)\n\n\napp = Flask(""server"")\n\n\ndef divide(x, y):\n    with start_action(action_type=""divide"", x=x, y=y) as action:\n        result = x / y\n        action.add_success_fields(result=result)\n        return result\n\n\n@app.route(""/"")\ndef main():\n    with Action.continue_task(task_id=request.headers[""x-eliot-task-id""]):\n        x = int(request.args[""x""])\n        y = int(request.args[""y""])\n        return str(divide(x, y))\n\n\nif __name__ == \'__main__\':\n    app.run()\n'"
examples/cross_thread.py,0,"b'#!/usr/bin/env python\n\n""""""\nExample of an Eliot action context spanning multiple threads.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom threading import Thread\nfrom sys import stdout\n\nfrom eliot import to_file, preserve_context, start_action\nto_file(stdout)\n\n\ndef add_in_thread(x, y):\n    with start_action(action_type=""in_thread"", x=x, y=y) as context:\n        context.add_success_fields(result=x+y)\n\n\nwith start_action(action_type=""main_thread""):\n    # Preserve Eliot context and restore in new thread:\n    thread = Thread(target=preserve_context(add_in_thread),\n                    kwargs={""x"": 3, ""y"": 4})\n    thread.start()\n    # Wait for the thread to exit:\n    thread.join()\n\n'"
examples/dask_eliot.py,0,"b'from os import getpid\n\nfrom dask.bag import from_sequence\nimport dask.config\nfrom dask.distributed import Client\nfrom eliot import log_call, to_file\nfrom eliot.dask import compute_with_trace\n\n\n@log_call\ndef multiply(x, y=7):\n    return x * y\n\n@log_call\ndef add(x, y):\n    return x + y\n\n@log_call\ndef main_computation():\n    bag = from_sequence([1, 2, 3])\n    bag = bag.map(multiply).fold(add)\n    return compute_with_trace(bag)[0]  # instead of dask.compute(bag)\n\ndef _start_logging():\n    # Name log file based on PID, so different processes so stomp on each\n    # others\' logfiles:\n    to_file(open(""{}.log"".format(getpid()), ""a""))\n\ndef main():\n    # Setup logging on the main process:\n    _start_logging()\n\n    # Start three worker processes on the local machine:\n    client = Client(n_workers=3, threads_per_worker=1)\n\n    # Setup Eliot logging on each worker process:\n    client.run(_start_logging)\n\n    # Run the Dask computation in the worker processes:\n    result = main_computation()\n    print(""Result:"", result)\n\n\nif __name__ == \'__main__\':\n    import dask_eliot\n    dask_eliot.main()\n'"
examples/journald.py,0,"b'""""""\nWrite some logs to journald.\n""""""\n\nfrom __future__ import print_function\n\nfrom eliot import log_message, start_action, add_destinations\nfrom eliot.journald import JournaldDestination\n\nadd_destinations(JournaldDestination())\n\n\ndef divide(a, b):\n    with start_action(action_type=""divide"", a=a, b=b):\n        return a / b\n\nprint(divide(10, 2))\nlog_message(message_type=""inbetween"")\nprint(divide(10, 0))\n'"
examples/linkcheck.py,0,"b'import requests\nfrom eliot import start_action, to_file\nto_file(open(""linkcheck.log"", ""w""))\n\n\ndef check_links(urls):\n    with start_action(action_type=""check_links"", urls=urls):\n        for url in urls:\n            try:\n                with start_action(action_type=""download"", url=url):\n                    response = requests.get(url)\n                    response.raise_for_status()\n            except Exception as e:\n                raise ValueError(str(e))\n\ntry:\n    check_links([""http://eliot.readthedocs.io"", ""http://nosuchurl""])\nexcept ValueError:\n    print(""Not all links were valid."")\n'"
examples/logfile.py,0,"b'""""""\nOutput an Eliot message to a log file using the threaded log writer.\n""""""\nfrom __future__ import unicode_literals, print_function\n\nfrom twisted.internet.task import react\n\nfrom eliot.logwriter import ThreadedWriter\nfrom eliot import log_message, FileDestination\n\n\ndef main(reactor):\n    print(""Logging to example-eliot.log..."")\n    logWriter = ThreadedWriter(\n        FileDestination(file=open(""example-eliot.log"", ""ab"")), reactor)\n\n    # Manually start the service, which will add it as a\n    # destination. Normally we\'d register ThreadedWriter with the usual\n    # Twisted Service/Application infrastructure.\n    logWriter.startService()\n\n    # Log a message:\n    log_message(message_type=""test"", value=""hello"", another=1)\n\n    # Manually stop the service.\n    done = logWriter.stopService()\n    return done\n\n\nif __name__ == \'__main__\':\n    react(main, [])\n'"
examples/rometrip_actions.py,0,"b'from sys import stdout\nfrom eliot import start_action, to_file\nto_file(stdout)\n\n\nclass Place(object):\n    def __init__(self, name, contained=()):\n        self.name = name\n        self.contained = contained\n\n    def visited(self, people):\n        # No need to repetitively log people, since caller will:\n        with start_action(action_type=""visited"", place=self.name):\n            for thing in self.contained:\n                thing.visited(people)\n\n\ndef honeymoon(family, destination):\n    with start_action(action_type=""honeymoon"", people=family):\n        destination.visited(family)\n\n\nhoneymoon([""Mrs. Casaubon"", ""Mr. Casaubon""],\n          Place(""Rome, Italy"",\n                [Place(""Vatican Museum"",\n                       [Place(""Statue #1""), Place(""Statue #2"")])]))\n'"
examples/stdlib.py,0,"b'""""""\nExample of routing standard library logging to Eliot.\n\nThe assumption is you have legacy logging using stdlib, and are switching over\nto Eliot.\n""""""\n\nimport logging\nimport sys\n\nfrom eliot.stdlib import EliotHandler\nfrom eliot import start_action, to_file\n\n# A Logger left over from before switch to Eliot\nLEGACY_LOGGER = logging.Logger(""mypackage"")\n\n\ndef do_a_thing(i):\n    with start_action(action_type=""mypackage:do_a_thing""):\n        # run your business logic....\n        if i == 3:\n            LEGACY_LOGGER.error(""The number 3 is a bad number, don\'t use it."")\n            raise ValueError(""I hate the number 3"")\n\n\ndef main():\n    with start_action(action_type=""mypackage:main""):\n        for i in [1, 3]:\n            try:\n                do_a_thing(i)\n            except ValueError:\n                LEGACY_LOGGER.info(""Number {} was rejected."".format(i))\n\n\nif __name__ == \'__main__\':\n    # Hook up stdlib logging to Eliot:\n    LEGACY_LOGGER.addHandler(EliotHandler())\n    # Write Eliot logs to stdout:\n    to_file(sys.stdout)\n    # Run the code:\n    main()\n'"
examples/stdout.py,0,"b'""""""\nOutput a few Eliot message to standard out.\n""""""\nfrom __future__ import unicode_literals\n\nimport sys\nimport time\n\nfrom eliot import log_message, to_file\nto_file(sys.stdout)\n\n\ndef main():\n    log_message(message_type=""test"", value=""hello"", another=1)\n    time.sleep(0.2)\n    log_message(message_type=""test"", value=""goodbye"", another=2)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
examples/trio_say.py,0,"b'from eliot import start_action, to_file\nimport trio\n\nto_file(open(""trio.log"", ""w""))\n\n\nasync def say(message, delay):\n    with start_action(action_type=""say"", message=message):\n        await trio.sleep(delay)\n\nasync def main():\n    with start_action(action_type=""main""):\n        async with trio.open_nursery() as nursery:\n            nursery.start_soon(say, ""hello"", 1)\n            nursery.start_soon(say, ""world"", 2)\n\ntrio.run(main)\n'"
docs/source/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Eliot documentation build configuration file, created by\n# sphinx-quickstart on Mon Apr 14 12:04:03 2014.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys\nimport os\n\n# Make sure local eliot is used when importing:\nsys.path.insert(0, os.path.abspath(os.path.join(\'..\', \'..\')))\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#sys.path.insert(0, os.path.abspath(\'.\'))\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = []\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix of source filenames.\nsource_suffix = \'.rst\'\n\n# The encoding of source files.\n#source_encoding = \'utf-8-sig\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = u\'Eliot\'\ncopyright = u\'2014-2018, ClusterHQ and Itamar Turner-Trauring\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nimport eliot\nversion = eliot.__version__\n# Versioneer adds .dirty suffix to version if checkout is dirty, and\n# therefore ReadTheDocs somehow ends up with this in its version, so strip\n# it out.\nif version.endswith("".dirty""):\n    version = version[:-len("".dirty"")]\n# The full version, including alpha/beta/rc tags.\nrelease = version\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#language = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = \'\'\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = \'%B %d, %Y\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = []\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n#default_role = None\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n\n# If true, keep warnings as ""system message"" paragraphs in the built documents.\n#keep_warnings = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\n#html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# ""<project> v<release> documentation"".\n#html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n#html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n#html_extra_path = []\n\n# If not \'\', a \'Last updated on:\' timestamp is inserted at every page bottom,\n# using the given strftime format.\n#html_last_updated_fmt = \'%b %d, %Y\'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n#html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n\n# If false, no module index is generated.\n#html_domain_indices = True\n\n# If false, no index is generated.\n#html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n#html_show_sourcelink = True\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.\n#html_show_sphinx = True\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.\n#html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = \'\'\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n#html_file_suffix = None\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'Eliotdoc\'\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n# The paper size (\'letterpaper\' or \'a4paper\').\n#\'papersize\': \'letterpaper\',\n\n# The font size (\'10pt\', \'11pt\' or \'12pt\').\n#\'pointsize\': \'10pt\',\n\n# Additional stuff for the LaTeX preamble.\n#\'preamble\': \'\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n  (\'index\', \'Eliot.tex\', u\'Eliot Documentation\',\n   u\'Itamar Turner-Trauring\', \'manual\'),\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n#latex_logo = None\n\n# For ""manual"" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n#latex_use_parts = False\n\n# If true, show page references after internal links.\n#latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n#latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n#latex_appendices = []\n\n# If false, no module index is generated.\n#latex_domain_indices = True\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (\'index\', \'eliot\', u\'Eliot Documentation\',\n     [u\'Itamar Turner-Trauring\'], 1)\n]\n\n# If true, show URL addresses after external links.\n#man_show_urls = False\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n  (\'index\', \'Eliot\', u\'Eliot Documentation\',\n   u\'Itamar Turner-Trauring\', \'Eliot\', \'One line description of project.\',\n   \'Miscellaneous\'),\n]\n\n# Documents to append as an appendix to all manuals.\n#texinfo_appendices = []\n\n# If false, no module index is generated.\n#texinfo_domain_indices = True\n\n# How to display URL addresses: \'footnote\', \'no\', or \'inline\'.\n#texinfo_show_urls = \'footnote\'\n\n# If true, do not generate a @detailmenu in the ""Top"" node\'s menu.\n#texinfo_no_detailmenu = False\n'"
eliot/tests/__init__.py,0,"b'""""""\nTests for the eliot package.\n""""""\n\n# Increase hypothesis deadline so we don\'t time out on PyPy:\nfrom hypothesis import settings\n\nsettings.register_profile(""eliot"", deadline=1000)\nsettings.load_profile(""eliot"")\n'"
eliot/tests/common.py,0,"b'""""""\nCommon testing infrastructure.\n""""""\n\nfrom io import BytesIO\n\n\nclass FakeSys(object):\n    """"""\n    A fake L{sys} module.\n    """"""\n\n    def __init__(self, argv, stdinBytes):\n        """"""\n        @param argv: List of command-line arguments.\n\n        @param stdinBytes: C{bytes} that are readable from stdin.\n        """"""\n        self.argv = argv\n        self.stdin = BytesIO(stdinBytes)\n        self.stdout = BytesIO()\n        self.stderr = BytesIO()\n'"
eliot/tests/strategies.py,0,"b'""""""\nHypothesis strategies for eliot.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom functools import partial\nfrom six import text_type as unicode\n\nfrom hypothesis.strategies import (\n    builds,\n    dictionaries,\n    fixed_dictionaries,\n    floats,\n    integers,\n    lists,\n    just,\n    none,\n    one_of,\n    recursive,\n    text,\n    uuids,\n)\n\nfrom pyrsistent import pmap, pvector, ny, thaw\n\nfrom .._action import (\n    ACTION_STATUS_FIELD,\n    ACTION_TYPE_FIELD,\n    FAILED_STATUS,\n    STARTED_STATUS,\n    SUCCEEDED_STATUS,\n    TaskLevel,\n    WrittenAction,\n)\nfrom .._message import (\n    EXCEPTION_FIELD,\n    REASON_FIELD,\n    TASK_LEVEL_FIELD,\n    TASK_UUID_FIELD,\n    WrittenMessage,\n)\n\ntask_level_indexes = integers(min_value=1, max_value=10)\n# Task levels can be arbitrarily deep, but in the wild rarely as much as 100.\n# Five seems a sensible average.\ntask_level_lists = lists(task_level_indexes, min_size=1, max_size=6)\ntask_levels = task_level_lists.map(lambda level: TaskLevel(level=level))\n\n# Text generation is slow, and most of the things are short labels. We set\n# a restricted alphabet so they\'re easier to read, and in general large\n# amount of randomness in label generation doesn\'t enhance our testing in\n# any way, since we don\'t parse type names or user field values.\nlabels = text(min_size=1, max_size=8, alphabet=""CGAT"")\n\ntimestamps = floats(min_value=0, max_value=1000.0)\n\nmessage_core_dicts = fixed_dictionaries(\n    dict(\n        task_level=task_level_lists.map(pvector),\n        task_uuid=uuids().map(unicode),\n        timestamp=timestamps,\n    )\n).map(pmap)\n\n# Text generation is slow. We can make it faster by not generating so\n# much. These are reasonable values.\nmessage_data_dicts = dictionaries(\n    keys=labels,\n    values=labels,\n    # People don\'t normally put much more than ten fields in their\n    # messages, surely?\n    max_size=10,\n).map(pmap)\n\n\ndef written_from_pmap(d):\n    """"""\n    Convert a C{pmap} to a C{WrittenMessage}.\n    """"""\n    return WrittenMessage.from_dict(thaw(d))\n\n\ndef union(*dicts):\n    result = pmap().evolver()\n    for d in dicts:\n        # Work around bug in pyrsistent where it sometimes loses updates if\n        # they contain some kv pairs that are identical to the ones in the\n        # dict being updated.\n        #\n        # https://github.com/tobgu/pyrsistent/pull/54\n        for key, value in d.items():\n            if key in result and result[key] is value:\n                continue\n            result[key] = value\n    return result.persistent()\n\n\nmessage_dicts = builds(union, message_data_dicts, message_core_dicts)\nwritten_messages = message_dicts.map(written_from_pmap)\n\n_start_action_fields = fixed_dictionaries(\n    {ACTION_STATUS_FIELD: just(STARTED_STATUS), ACTION_TYPE_FIELD: labels}\n)\nstart_action_message_dicts = builds(union, message_dicts, _start_action_fields).map(\n    lambda x: x.update({TASK_LEVEL_FIELD: x[TASK_LEVEL_FIELD].set(-1, 1)})\n)\nstart_action_messages = start_action_message_dicts.map(written_from_pmap)\n\n\ndef sibling_task_level(message, n):\n    return message.task_level.parent().level.append(n)\n\n\n_end_action_fields = one_of(\n    just({ACTION_STATUS_FIELD: SUCCEEDED_STATUS}),\n    fixed_dictionaries(\n        {\n            ACTION_STATUS_FIELD: just(FAILED_STATUS),\n            # Text generation is slow. We can make it faster by not generating so\n            # much. Thqese are reasonable values.\n            EXCEPTION_FIELD: labels,\n            REASON_FIELD: labels,\n        }\n    ),\n)\n\n\ndef _make_written_action(start_message, child_messages, end_message_dict):\n    """"""\n    Helper for creating arbitrary L{WrittenAction}s.\n\n    The child messages and end message (if provided) will be updated to have\n    the same C{task_uuid} as C{start_message}. Likewise, their C{task_level}s\n    will be such that they follow on from C{start_message}.\n\n    @param WrittenMessage start_message: The message to start the action with.\n    @param child_messages: A sequence of L{WrittenAction}s and\n        L{WrittenMessage}s that make up the action.\n    @param (PMap | None) end_message_dict: A dictionary that makes up an end\n        message. If None, then the action is unfinished.\n\n    @return: A L{WrittenAction}\n    """"""\n    task_uuid = start_message.task_uuid\n    children = []\n\n    for i, child in enumerate(child_messages, 2):\n        task_level = TaskLevel(level=sibling_task_level(start_message, i))\n        children.append(reparent_action(task_uuid, task_level, child))\n\n    if end_message_dict:\n        end_message = written_from_pmap(\n            union(\n                end_message_dict,\n                {\n                    ACTION_TYPE_FIELD: start_message.contents[ACTION_TYPE_FIELD],\n                    TASK_UUID_FIELD: task_uuid,\n                    TASK_LEVEL_FIELD: sibling_task_level(\n                        start_message, 2 + len(children)\n                    ),\n                },\n            )\n        )\n    else:\n        end_message = None\n\n    return WrittenAction.from_messages(start_message, children, end_message)\n\n\nwritten_actions = recursive(\n    written_messages,\n    lambda children: builds(\n        _make_written_action,\n        start_message=start_action_messages,\n        child_messages=lists(children, max_size=5),\n        end_message_dict=builds(union, message_dicts, _end_action_fields) | none(),\n    ),\n)\n\n\ndef _map_messages(f, written_action):\n    """"""\n    Map C{f} across all of the messages that make up C{written_action}.\n\n    This is a structure-preserving map operation. C{f} will be applied to all\n    messages that make up C{written_action}: the start message, end message,\n    and children. If any of the children are themselves L{WrittenAction}s, we\n    recurse down into them.\n\n    @param f: A function that takes a L{WrittenMessage} and returns a new\n        L{WrittenMessage}.\n    @param (WrittenAction | WrittenMessage) written_action: A written\n\n    @return: A L{WrittenMessage} if C{written_action} is a C{WrittenMessage},\n        a L{WrittenAction} otherwise.\n    """"""\n    if isinstance(written_action, WrittenMessage):\n        return f(written_action)\n\n    start_message = f(written_action.start_message)\n    children = written_action.children.transform([ny], partial(_map_messages, f))\n    if written_action.end_message:\n        end_message = f(written_action.end_message)\n    else:\n        end_message = None\n\n    return WrittenAction.from_messages(\n        start_message=start_message, children=pvector(children), end_message=end_message\n    )\n\n\ndef reparent_action(task_uuid, task_level, written_action):\n    """"""\n    Return a version of C{written_action} that has the given C{task_uuid} and\n    is rooted at the given C{task_level}.\n\n    @param UUID task_uuid: The new task UUID.\n    @param TaskLevel task_level: The new task level.\n    @param (WrittenAction | WrittenMessage) written_action: The action or\n        message to update.\n\n    @return: A new version of C{written_action}.\n    """"""\n    new_prefix = list(task_level.level)\n    old_prefix_len = len(written_action.task_level.level)\n\n    def fix_message(message):\n        return message.transform(\n            [""_logged_dict"", TASK_LEVEL_FIELD],\n            lambda level: new_prefix + level[old_prefix_len:],\n        ).transform([""_logged_dict"", TASK_UUID_FIELD], task_uuid)\n\n    return _map_messages(fix_message, written_action)\n'"
eliot/tests/test_action.py,0,"b'""""""\nTests for L{eliot._action}.\n""""""\n\nfrom __future__ import unicode_literals\n\nimport pickle\nimport time\nfrom unittest import TestCase, skipIf\nfrom unittest.mock import patch\nfrom threading import Thread\n\nimport six\n\nif six.PY3:\n    unicode = six.text_type\n\nfrom hypothesis import assume, given, settings, HealthCheck\nfrom hypothesis.strategies import integers, lists, just, text\n\nfrom pyrsistent import pvector, v\n\nimport testtools\nfrom testtools.matchers import MatchesStructure\n\nfrom .._action import (\n    Action,\n    current_action,\n    startTask,\n    start_action,\n    ACTION_STATUS_FIELD,\n    ACTION_TYPE_FIELD,\n    FAILED_STATUS,\n    STARTED_STATUS,\n    SUCCEEDED_STATUS,\n    DuplicateChild,\n    InvalidStartMessage,\n    InvalidStatus,\n    TaskLevel,\n    WrittenAction,\n    WrongActionType,\n    WrongTask,\n    WrongTaskLevel,\n    TooManyCalls,\n    log_call,\n)\nfrom .._message import (\n    EXCEPTION_FIELD,\n    REASON_FIELD,\n    TASK_LEVEL_FIELD,\n    TASK_UUID_FIELD,\n    MESSAGE_TYPE_FIELD,\n    Message,\n)\nfrom .._output import MemoryLogger\nfrom .._validation import ActionType, Field, _ActionSerializers\nfrom ..testing import assertContainsFields, capture_logging\nfrom ..parse import Parser\nfrom .. import (\n    add_destination,\n    remove_destination,\n    register_exception_extractor,\n    preserve_context,\n)\n\nfrom .strategies import (\n    message_dicts,\n    start_action_message_dicts,\n    start_action_messages,\n    task_level_indexes,\n    task_level_lists,\n    written_actions,\n    written_messages,\n    reparent_action,\n    sibling_task_level,\n    union,\n    written_from_pmap,\n)\n\n\nclass ActionTests(TestCase):\n    """"""\n    Tests for L{Action}.\n    """"""\n\n    def test_start(self):\n        """"""\n        L{Action._start} logs an C{action_status=""started""} message.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""unique"", TaskLevel(level=[]), ""sys:thename"")\n        action._start({""key"": ""value""})\n        assertContainsFields(\n            self,\n            logger.messages[0],\n            {\n                ""task_uuid"": ""unique"",\n                ""task_level"": [1],\n                ""action_type"": ""sys:thename"",\n                ""action_status"": ""started"",\n                ""key"": ""value"",\n            },\n        )\n\n    def test_task_uuid(self):\n        """"""\n        L{Action.task_uuid} return the task\'s UUID.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""unique"", TaskLevel(level=[]), ""sys:thename"")\n        self.assertEqual(action.task_uuid, ""unique"")\n\n    def test_startMessageSerialization(self):\n        """"""\n        The start message logged by L{Action._start} is created with the\n        appropriate start message L{eliot._validation._MessageSerializer}.\n        """"""\n        serializers = ActionType(\n            ""sys:thename"", [Field(""key"", lambda x: x, """")], [], """"\n        )._serializers\n\n        class Logger(list):\n            def write(self, msg, serializer):\n                self.append(serializer)\n\n        logger = Logger()\n        action = Action(\n            logger, ""unique"", TaskLevel(level=[]), ""sys:thename"", serializers\n        )\n        action._start({""key"": ""value""})\n        self.assertIs(logger[0], serializers.start)\n\n    def test_child(self):\n        """"""\n        L{Action.child} returns a new L{Action} with the given logger, system\n        and name, and a task_uuid taken from the parent L{Action}.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""unique"", TaskLevel(level=[]), ""sys:thename"")\n        logger2 = MemoryLogger()\n        child = action.child(logger2, ""newsystem:newname"")\n        self.assertEqual(\n            [child._logger, child._identification, child._task_level],\n            [\n                logger2,\n                {""task_uuid"": ""unique"", ""action_type"": ""newsystem:newname""},\n                TaskLevel(level=[1]),\n            ],\n        )\n\n    def test_childLevel(self):\n        """"""\n        Each call to L{Action.child} increments the new sub-level set on the\n        child.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""unique"", TaskLevel(level=[]), ""sys:thename"")\n        child1 = action.child(logger, ""newsystem:newname"")\n        child2 = action.child(logger, ""newsystem:newname"")\n        child1_1 = child1.child(logger, ""newsystem:other"")\n        self.assertEqual(child1._task_level, TaskLevel(level=[1]))\n        self.assertEqual(child2._task_level, TaskLevel(level=[2]))\n        self.assertEqual(child1_1._task_level, TaskLevel(level=[1, 1]))\n\n    def test_childSerializers(self):\n        """"""\n        L{Action.child} returns a new L{Action} with the serializers passed to\n        it, rather than the parent\'s.\n        """"""\n        logger = MemoryLogger()\n        serializers = object()\n        action = Action(\n            logger, ""unique"", TaskLevel(level=[]), ""sys:thename"", serializers\n        )\n        childSerializers = object()\n        child = action.child(logger, ""newsystem:newname"", childSerializers)\n        self.assertIs(child._serializers, childSerializers)\n\n    def test_run(self):\n        """"""\n        L{Action.run} runs the given function with given arguments, returning\n        its result.\n        """"""\n        action = Action(None, """", TaskLevel(level=[]), """")\n\n        def f(*args, **kwargs):\n            return args, kwargs\n\n        result = action.run(f, 1, 2, x=3)\n        self.assertEqual(result, ((1, 2), {""x"": 3}))\n\n    def test_runContext(self):\n        """"""\n        L{Action.run} runs the given function with the action set as the\n        current action.\n        """"""\n        result = []\n        action = Action(None, """", TaskLevel(level=[]), """")\n        action.run(lambda: result.append(current_action()))\n        self.assertEqual(result, [action])\n\n    def test_per_thread_context(self):\n        """"""Different threads have different contexts.""""""\n        in_thread = []\n\n        def run_in_thread():\n            action = Action(None, """", TaskLevel(level=[]), """")\n            with action.context():\n                time.sleep(0.5)\n                in_thread.append(current_action())\n\n        thread = Thread(target=run_in_thread)\n        thread.start()\n        time.sleep(0.2)\n        self.assertEqual(current_action(), None)\n        thread.join()\n        self.assertIsInstance(in_thread[0], Action)\n\n    def test_runContextUnsetOnReturn(self):\n        """"""\n        L{Action.run} unsets the action once the given function returns.\n        """"""\n        action = Action(None, """", TaskLevel(level=[]), """")\n        action.run(lambda: None)\n        self.assertIs(current_action(), None)\n\n    def test_runContextUnsetOnRaise(self):\n        """"""\n        L{Action.run} unsets the action once the given function raises an\n        exception.\n        """"""\n        action = Action(None, """", TaskLevel(level=[]), """")\n        self.assertRaises(ZeroDivisionError, action.run, lambda: 1 / 0)\n        self.assertIs(current_action(), None)\n\n    def test_withSetsContext(self):\n        """"""\n        L{Action.__enter__} sets the action as the current action.\n        """"""\n        action = Action(MemoryLogger(), """", TaskLevel(level=[]), """")\n        with action:\n            self.assertIs(current_action(), action)\n\n    def test_withUnsetOnReturn(self):\n        """"""\n        L{Action.__exit__} unsets the action on successful block finish.\n        """"""\n        action = Action(MemoryLogger(), """", TaskLevel(level=[]), """")\n        with action:\n            pass\n        self.assertIs(current_action(), None)\n\n    def test_withUnsetOnRaise(self):\n        """"""\n        L{Action.__exit__} unsets the action if the block raises an exception.\n        """"""\n        action = Action(MemoryLogger(), """", TaskLevel(level=[]), """")\n        try:\n            with action:\n                1 / 0\n        except ZeroDivisionError:\n            pass\n        else:\n            self.fail(""no exception"")\n        self.assertIs(current_action(), None)\n\n    def test_withContextSetsContext(self):\n        """"""\n        L{Action.context().__enter__} sets the action as the current action.\n        """"""\n        action = Action(MemoryLogger(), """", TaskLevel(level=[]), """")\n        with action.context():\n            self.assertIs(current_action(), action)\n\n    def test_withContextReturnsaction(self):\n        """"""\n        L{Action.context().__enter__} returns the action.\n        """"""\n        action = Action(MemoryLogger(), """", TaskLevel(level=[]), """")\n        with action.context() as action2:\n            self.assertIs(action, action2)\n\n    def test_withContextUnsetOnReturn(self):\n        """"""\n        L{Action.context().__exit__} unsets the action on successful block\n        finish.\n        """"""\n        action = Action(MemoryLogger(), """", TaskLevel(level=[]), """")\n        with action.context():\n            pass\n        self.assertIs(current_action(), None)\n\n    def test_withContextNoLogging(self):\n        """"""\n        L{Action.context().__exit__} does not log any messages.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, """", TaskLevel(level=[]), """")\n        with action.context():\n            pass\n        self.assertFalse(logger.messages)\n\n    def test_withContextUnsetOnRaise(self):\n        """"""\n        L{Action.conext().__exit__} unsets the action if the block raises an\n        exception.\n        """"""\n        action = Action(MemoryLogger(), """", TaskLevel(level=[]), """")\n        try:\n            with action.context():\n                1 / 0\n        except ZeroDivisionError:\n            pass\n        else:\n            self.fail(""no exception"")\n        self.assertIs(current_action(), None)\n\n    def test_finish(self):\n        """"""\n        L{Action.finish} with no exception logs an C{action_status=""succeeded""}\n        message.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""unique"", TaskLevel(level=[]), ""sys:thename"")\n        action.finish()\n        assertContainsFields(\n            self,\n            logger.messages[0],\n            {\n                ""task_uuid"": ""unique"",\n                ""task_level"": [1],\n                ""action_type"": ""sys:thename"",\n                ""action_status"": ""succeeded"",\n            },\n        )\n\n    def test_successfulFinishSerializer(self):\n        """"""\n        L{Action.finish} with no exception passes the success\n        L{eliot._validation._MessageSerializer} to the message it creates.\n        """"""\n        serializers = ActionType(\n            ""sys:thename"", [], [Field(""key"", lambda x: x, """")], """"\n        )._serializers\n\n        class Logger(list):\n            def write(self, msg, serializer):\n                self.append(serializer)\n\n        logger = Logger()\n        action = Action(\n            logger, ""unique"", TaskLevel(level=[]), ""sys:thename"", serializers\n        )\n        action.finish()\n        self.assertIs(logger[0], serializers.success)\n\n    def test_failureFinishSerializer(self):\n        """"""\n        L{Action.finish} with an exception passes the failure\n        L{eliot._validation._MessageSerializer} to the message it creates.\n        """"""\n        serializers = ActionType(\n            ""sys:thename"", [], [Field(""key"", lambda x: x, """")], """"\n        )._serializers\n\n        class Logger(list):\n            def write(self, msg, serializer):\n                self.append(serializer)\n\n        logger = Logger()\n        action = Action(\n            logger, ""unique"", TaskLevel(level=[]), ""sys:thename"", serializers\n        )\n        action.finish(Exception())\n        self.assertIs(logger[0], serializers.failure)\n\n    def test_startFieldsNotInFinish(self):\n        """"""\n        L{Action.finish} logs a message without the fields from\n        L{Action._start}.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""unique"", TaskLevel(level=[]), ""sys:thename"")\n        action._start({""key"": ""value""})\n        action.finish()\n        self.assertNotIn(""key"", logger.messages[1])\n\n    def test_finishWithBadException(self):\n        """"""\n        L{Action.finish} still logs a message if the given exception raises\n        another exception when called with C{unicode()}.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""unique"", TaskLevel(level=[]), ""sys:thename"")\n\n        class BadException(Exception):\n            def __str__(self):\n                raise TypeError()\n\n        action.finish(BadException())\n        self.assertEqual(\n            logger.messages[0][""reason""], ""eliot: unknown, unicode() raised exception""\n        )\n\n    def test_withLogsSuccessfulFinishMessage(self):\n        """"""\n        L{Action.__exit__} logs an action finish message on a successful block\n        finish.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""uuid"", TaskLevel(level=[1]), ""sys:me"")\n        with action:\n            pass\n        # Start message is only created if we use the action()/task() utility\n        # functions, the intended public APIs.\n        self.assertEqual(len(logger.messages), 1)\n        assertContainsFields(\n            self,\n            logger.messages[0],\n            {\n                ""task_uuid"": ""uuid"",\n                ""task_level"": [1, 1],\n                ""action_type"": ""sys:me"",\n                ""action_status"": ""succeeded"",\n            },\n        )\n\n    def test_withLogsExceptionMessage(self):\n        """"""\n        L{Action.__exit__} logs an action finish message on an exception\n        raised from the block.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""uuid"", TaskLevel(level=[1]), ""sys:me"")\n        exception = RuntimeError(""because"")\n\n        try:\n            with action:\n                raise exception\n        except RuntimeError:\n            pass\n        else:\n            self.fail(""no exception"")\n\n        self.assertEqual(len(logger.messages), 1)\n        assertContainsFields(\n            self,\n            logger.messages[0],\n            {\n                ""task_uuid"": ""uuid"",\n                ""task_level"": [1, 1],\n                ""action_type"": ""sys:me"",\n                ""action_status"": ""failed"",\n                ""reason"": ""because"",\n                ""exception"": ""%s.RuntimeError"" % (RuntimeError.__module__,),\n            },\n        )\n\n    def test_withReturnValue(self):\n        """"""\n        L{Action.__enter__} returns the action itself.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""uuid"", TaskLevel(level=[1]), ""sys:me"")\n        with action as act:\n            self.assertIs(action, act)\n\n    def test_addSuccessFields(self):\n        """"""\n        On a successful finish, L{Action.__exit__} adds fields from\n        L{Action.addSuccessFields} to the result message.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""uuid"", TaskLevel(level=[1]), ""sys:me"")\n        with action as act:\n            act.addSuccessFields(x=1, y=2)\n            act.addSuccessFields(z=3)\n        assertContainsFields(self, logger.messages[0], {""x"": 1, ""y"": 2, ""z"": 3})\n\n    def test_nextTaskLevel(self):\n        """"""\n        Each call to L{Action._nextTaskLevel()} increments a counter.\n        """"""\n        action = Action(MemoryLogger(), ""uuid"", TaskLevel(level=[1]), ""sys:me"")\n        self.assertEqual(\n            [action._nextTaskLevel() for i in range(5)],\n            [\n                TaskLevel(level=level)\n                for level in ([1, 1], [1, 2], [1, 3], [1, 4], [1, 5])\n            ],\n        )\n\n    def test_multipleFinishCalls(self):\n        """"""\n        If L{Action.finish} is called, subsequent calls to L{Action.finish}\n        have no effect.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""uuid"", TaskLevel(level=[1]), ""sys:me"")\n        with action as act:\n            act.finish()\n            act.finish(Exception())\n            act.finish()\n        # Only initial finish message is logged:\n        self.assertEqual(len(logger.messages), 1)\n\n\nclass StartActionAndTaskTests(TestCase):\n    """"""\n    Tests for L{start_action} and L{startTask}.\n    """"""\n\n    def test_startTaskNewAction(self):\n        """"""\n        L{startTask} creates a new top-level L{Action}.\n        """"""\n        logger = MemoryLogger()\n        action = startTask(logger, ""sys:do"")\n        self.assertIsInstance(action, Action)\n        self.assertEqual(action._task_level, TaskLevel(level=[]))\n\n    def test_start_task_default_action_type(self):\n        """"""\n        L{start_task} sets a default C{action_type} if none is set.\n        """"""\n        logger = MemoryLogger()\n        startTask(logger)\n        assertContainsFields(self, logger.messages[0], {""action_type"": """"})\n\n    def test_startTaskSerializers(self):\n        """"""\n        If serializers are passed to L{startTask} they are attached to the\n        resulting L{Action}.\n        """"""\n        logger = MemoryLogger()\n        serializers = _ActionSerializers(start=None, success=None, failure=None)\n        action = startTask(logger, ""sys:do"", serializers)\n        self.assertIs(action._serializers, serializers)\n\n    def test_startActionSerializers(self):\n        """"""\n        If serializers are passed to L{start_action} they are attached to the\n        resulting L{Action}.\n        """"""\n        logger = MemoryLogger()\n        serializers = _ActionSerializers(start=None, success=None, failure=None)\n        action = start_action(logger, ""sys:do"", serializers)\n        self.assertIs(action._serializers, serializers)\n\n    def test_startTaskNewUUID(self):\n        """"""\n        L{startTask} creates an L{Action} with its own C{task_uuid}.\n        """"""\n        logger = MemoryLogger()\n        action = startTask(logger, ""sys:do"")\n        action2 = startTask(logger, ""sys:do"")\n        self.assertNotEqual(\n            action._identification[""task_uuid""], action2._identification[""task_uuid""]\n        )\n\n    def test_startTaskLogsStart(self):\n        """"""\n        L{startTask} logs a start message for the newly created L{Action}.\n        """"""\n        logger = MemoryLogger()\n        action = startTask(logger, ""sys:do"", key=""value"")\n        assertContainsFields(\n            self,\n            logger.messages[0],\n            {\n                ""task_uuid"": action._identification[""task_uuid""],\n                ""task_level"": [1],\n                ""action_type"": ""sys:do"",\n                ""action_status"": ""started"",\n                ""key"": ""value"",\n            },\n        )\n\n    def test_start_action_default_action_type(self):\n        """"""\n        L{start_action} sets a default C{action_type} if none is set.\n        """"""\n        logger = MemoryLogger()\n        start_action(logger)\n        assertContainsFields(self, logger.messages[0], {""action_type"": """"})\n\n    def test_startActionNoParent(self):\n        """"""\n        L{start_action} when C{current_action()} is C{None} creates a top-level\n        L{Action}.\n        """"""\n        logger = MemoryLogger()\n        action = start_action(logger, ""sys:do"")\n        self.assertIsInstance(action, Action)\n        self.assertEqual(action._task_level, TaskLevel(level=[]))\n\n    def test_startActionNoParentLogStart(self):\n        """"""\n        L{start_action} when C{current_action()} is C{None} logs a start\n        message.\n        """"""\n        logger = MemoryLogger()\n        action = start_action(logger, ""sys:do"", key=""value"")\n        assertContainsFields(\n            self,\n            logger.messages[0],\n            {\n                ""task_uuid"": action._identification[""task_uuid""],\n                ""task_level"": [1],\n                ""action_type"": ""sys:do"",\n                ""action_status"": ""started"",\n                ""key"": ""value"",\n            },\n        )\n\n    def test_startActionWithParent(self):\n        """"""\n        L{start_action} uses the C{current_action()} as parent for a new\n        L{Action}.\n        """"""\n        logger = MemoryLogger()\n        parent = Action(logger, ""uuid"", TaskLevel(level=[2]), ""other:thing"")\n        with parent:\n            action = start_action(logger, ""sys:do"")\n            self.assertIsInstance(action, Action)\n            self.assertEqual(action._identification[""task_uuid""], ""uuid"")\n            self.assertEqual(action._task_level, TaskLevel(level=[2, 1]))\n\n    def test_startActionWithParentLogStart(self):\n        """"""\n        L{start_action} when C{current_action()} is an L{Action} logs a start\n        message.\n        """"""\n        logger = MemoryLogger()\n        parent = Action(logger, ""uuid"", TaskLevel(level=[]), ""other:thing"")\n        with parent:\n            start_action(logger, ""sys:do"", key=""value"")\n            assertContainsFields(\n                self,\n                logger.messages[0],\n                {\n                    ""task_uuid"": ""uuid"",\n                    ""task_level"": [1, 1],\n                    ""action_type"": ""sys:do"",\n                    ""action_status"": ""started"",\n                    ""key"": ""value"",\n                },\n            )\n\n    def test_startTaskNoLogger(self):\n        """"""\n        When no logger is given L{startTask} logs to the default ``Logger``.\n        """"""\n        messages = []\n        add_destination(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n        action = startTask(action_type=""sys:do"", key=""value"")\n        assertContainsFields(\n            self,\n            messages[0],\n            {\n                ""task_uuid"": action._identification[""task_uuid""],\n                ""task_level"": [1],\n                ""action_type"": ""sys:do"",\n                ""action_status"": ""started"",\n                ""key"": ""value"",\n            },\n        )\n\n    def test_startActionNoLogger(self):\n        """"""\n        When no logger is given L{start_action} logs to the default ``Logger``.\n        """"""\n        messages = []\n        add_destination(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n        action = start_action(action_type=""sys:do"", key=""value"")\n        assertContainsFields(\n            self,\n            messages[0],\n            {\n                ""task_uuid"": action._identification[""task_uuid""],\n                ""task_level"": [1],\n                ""action_type"": ""sys:do"",\n                ""action_status"": ""started"",\n                ""key"": ""value"",\n            },\n        )\n\n\nclass PEP8Tests(TestCase):\n    """"""\n    Tests for PEP 8 method compatibility.\n    """"""\n\n    def test_add_success_fields(self):\n        """"""\n        L{Action.addSuccessFields} is the same as L{Action.add_success_fields}.\n        """"""\n        self.assertEqual(Action.addSuccessFields, Action.add_success_fields)\n\n    def test_serialize_task_id(self):\n        """"""\n        L{Action.serialize_task_id} is the same as L{Action.serializeTaskId}.\n        """"""\n        self.assertEqual(Action.serialize_task_id, Action.serializeTaskId)\n\n    def test_continue_task(self):\n        """"""\n        L{Action.continue_task} is the same as L{Action.continueTask}.\n        """"""\n        self.assertEqual(Action.continue_task, Action.continueTask)\n\n\nclass SerializationTests(TestCase):\n    """"""\n    Tests for L{Action} serialization and deserialization.\n    """"""\n\n    def test_serializeTaskId(self):\n        """"""\n        L{Action.serialize_task_id} result is composed of the task UUID and an\n        incremented task level.\n        """"""\n        action = Action(None, ""uniq123"", TaskLevel(level=[1, 2]), ""mytype"")\n        self.assertEqual(\n            [\n                action._nextTaskLevel(),\n                action.serialize_task_id(),\n                action._nextTaskLevel(),\n            ],\n            [TaskLevel(level=[1, 2, 1]), b""uniq123@/1/2/2"", TaskLevel(level=[1, 2, 3])],\n        )\n\n    def test_continueTaskReturnsAction(self):\n        """"""\n        L{Action.continue_task} returns an L{Action} whose C{task_level} and\n        C{task_uuid} are derived from those in the given serialized task\n        identifier.\n        """"""\n        originalAction = Action(None, ""uniq456"", TaskLevel(level=[3, 4]), ""mytype"")\n        taskId = originalAction.serializeTaskId()\n\n        newAction = Action.continue_task(MemoryLogger(), taskId)\n        self.assertEqual(\n            [newAction.__class__, newAction._identification, newAction._task_level],\n            [\n                Action,\n                {""task_uuid"": ""uniq456"", ""action_type"": ""eliot:remote_task""},\n                TaskLevel(level=[3, 4, 1]),\n            ],\n        )\n\n    def test_continueTaskUnicode(self):\n        """"""\n        L{Action.continue_task} can take a Unicode task identifier.\n        """"""\n        original_action = Action(None, ""uniq790"", TaskLevel(level=[3, 4]), ""mytype"")\n        task_id = unicode(original_action.serialize_task_id(), ""utf-8"")\n\n        new_action = Action.continue_task(MemoryLogger(), task_id)\n        self.assertEqual(new_action._identification[""task_uuid""], ""uniq790"")\n\n    def test_continueTaskStartsAction(self):\n        """"""\n        L{Action.continue_task} starts the L{Action} it creates.\n        """"""\n        originalAction = Action(None, ""uniq456"", TaskLevel(level=[3, 4]), ""mytype"")\n        taskId = originalAction.serializeTaskId()\n        logger = MemoryLogger()\n\n        Action.continue_task(logger, taskId)\n        assertContainsFields(\n            self,\n            logger.messages[0],\n            {\n                ""task_uuid"": ""uniq456"",\n                ""task_level"": [3, 4, 1, 1],\n                ""action_type"": ""eliot:remote_task"",\n                ""action_status"": ""started"",\n            },\n        )\n\n    def test_continueTaskNoLogger(self):\n        """"""\n        L{Action.continue_task} can be called without a logger.\n        """"""\n        originalAction = Action(None, ""uniq456"", TaskLevel(level=[3, 4]), ""mytype"")\n        taskId = originalAction.serializeTaskId()\n\n        messages = []\n        add_destination(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n        Action.continue_task(task_id=taskId)\n        assertContainsFields(\n            self,\n            messages[-1],\n            {\n                ""task_uuid"": ""uniq456"",\n                ""task_level"": [3, 4, 1, 1],\n                ""action_type"": ""eliot:remote_task"",\n                ""action_status"": ""started"",\n            },\n        )\n\n    def test_continueTaskRequiredTaskId(self):\n        """"""\n        L{Action.continue_task} requires a C{task_id} to be passed in.\n        """"""\n        self.assertRaises(RuntimeError, Action.continue_task)\n\n\nclass TaskLevelTests(TestCase):\n    """"""\n    Tests for L{TaskLevel}.\n    """"""\n\n    def assert_fully_less_than(self, x, y):\n        """"""\n        Assert that x < y according to all the comparison operators.\n        """"""\n        self.assertTrue(\n            all(\n                [\n                    # lt\n                    x < y,\n                    not y < x,\n                    # le\n                    x <= y,\n                    not y <= x,\n                    # gt\n                    y > x,\n                    not x > y,\n                    # ge\n                    y >= x,\n                    not x >= y,\n                    # eq\n                    not x == y,\n                    not y == x,\n                    # ne\n                    x != y,\n                    y != x,\n                ]\n            )\n        )\n\n    def test_equality(self):\n        """"""\n        L{TaskChild} correctly implements equality and hashing.\n        """"""\n        a = TaskLevel(level=[1, 2])\n        a2 = TaskLevel(level=[1, 2])\n        b = TaskLevel(level=[2, 999])\n        self.assertTrue(\n            all(\n                [\n                    a == a2,\n                    a2 == a,\n                    a != b,\n                    b != a,\n                    not b == a,\n                    not a == b,\n                    not a == 1,\n                    a != 1,\n                    hash(a) == hash(a2),\n                    hash(b) != hash(a),\n                ]\n            )\n        )\n\n    def test_as_list(self):\n        """"""\n        L{TaskChild.as_list} returns the level.\n        """"""\n        self.assertEqual(TaskLevel(level=[1, 2, 3]).as_list(), [1, 2, 3])\n\n    @given(lists(task_level_indexes))\n    def test_parent_of_child(self, base_task_level):\n        """"""\n        L{TaskLevel.child} returns the first child of the task.\n        """"""\n        base_task = TaskLevel(level=base_task_level)\n        child_task = base_task.child()\n        self.assertEqual(base_task, child_task.parent())\n\n    @given(task_level_lists)\n    def test_child_greater_than_parent(self, task_level):\n        """"""\n        L{TaskLevel.child} returns a child that is greater than its parent.\n        """"""\n        task = TaskLevel(level=task_level)\n        self.assert_fully_less_than(task, task.child())\n\n    @given(task_level_lists)\n    def test_next_sibling_greater(self, task_level):\n        """"""\n        L{TaskLevel.next_sibling} returns a greater task level.\n        """"""\n        task = TaskLevel(level=task_level)\n        self.assert_fully_less_than(task, task.next_sibling())\n\n    @given(task_level_lists)\n    def test_next_sibling(self, task_level):\n        """"""\n        L{TaskLevel.next_sibling} returns the next sibling of a task.\n        """"""\n        task = TaskLevel(level=task_level)\n        sibling = task.next_sibling()\n        self.assertEqual(\n            sibling, TaskLevel(level=task_level[:-1] + [task_level[-1] + 1])\n        )\n\n    def test_parent_of_root(self):\n        """"""\n        L{TaskLevel.parent} of the root task level is C{None}.\n        """"""\n        self.assertIs(TaskLevel(level=[]).parent(), None)\n\n    def test_toString(self):\n        """"""\n        L{TaskLevel.toString} serializes the object to a Unicode string.\n        """"""\n        root = TaskLevel(level=[])\n        child2_1 = root.child().next_sibling().child()\n        self.assertEqual([root.toString(), child2_1.toString()], [""/"", ""/2/1""])\n\n    def test_fromString(self):\n        """"""\n        L{TaskLevel.fromString} deserializes the output of\n        L{TaskLevel.toString}.\n        """"""\n        self.assertEqual(\n            [TaskLevel.fromString(""/""), TaskLevel.fromString(""/2/1"")],\n            [TaskLevel(level=[]), TaskLevel(level=[2, 1])],\n        )\n\n    def test_from_string(self):\n        """"""\n        L{TaskLevel.from_string} is the same as as L{TaskLevel.fromString}.\n        """"""\n        self.assertEqual(TaskLevel.from_string, TaskLevel.fromString)\n\n    def test_to_string(self):\n        """"""\n        L{TaskLevel.to_string} is the same as as L{TaskLevel.toString}.\n        """"""\n        self.assertEqual(TaskLevel.to_string, TaskLevel.toString)\n\n\nclass WrittenActionTests(testtools.TestCase):\n    """"""\n    Tests for L{WrittenAction}.\n    """"""\n\n    @given(start_action_messages)\n    def test_from_single_start_message(self, message):\n        """"""\n        A L{WrittenAction} can be constructed from a single ""start"" message.\n        Such an action inherits the C{action_type} of the start message, has no\n        C{end_time}, and has a C{status} of C{STARTED_STATUS}.\n        """"""\n        action = WrittenAction.from_messages(message)\n        self.assertThat(\n            action,\n            MatchesStructure.byEquality(\n                status=STARTED_STATUS,\n                action_type=message.contents[ACTION_TYPE_FIELD],\n                task_uuid=message.task_uuid,\n                task_level=message.task_level.parent(),\n                start_time=message.timestamp,\n                children=pvector([]),\n                end_time=None,\n                reason=None,\n                exception=None,\n            ),\n        )\n\n    @given(start_action_messages, message_dicts, integers(min_value=2))\n    def test_from_single_end_message(self, start_message, end_message_dict, n):\n        """"""\n        A L{WrittenAction} can be constructed from a single ""end""\n        message. Such an action inherits the C{action_type} and\n        C{task_level} of the end message, has no C{start_time}, and has a\n        C{status} matching that of the end message.\n        """"""\n        end_message = written_from_pmap(\n            union(\n                end_message_dict,\n                {\n                    ACTION_STATUS_FIELD: SUCCEEDED_STATUS,\n                    ACTION_TYPE_FIELD: start_message.contents[ACTION_TYPE_FIELD],\n                    TASK_UUID_FIELD: start_message.task_uuid,\n                    TASK_LEVEL_FIELD: sibling_task_level(start_message, n),\n                },\n            )\n        )\n        action = WrittenAction.from_messages(end_message=end_message)\n        self.assertThat(\n            action,\n            MatchesStructure.byEquality(\n                status=SUCCEEDED_STATUS,\n                action_type=end_message.contents[ACTION_TYPE_FIELD],\n                task_uuid=end_message.task_uuid,\n                task_level=end_message.task_level.parent(),\n                start_time=None,\n                children=pvector([]),\n                end_time=end_message.timestamp,\n                reason=None,\n                exception=None,\n            ),\n        )\n\n    @given(message_dicts)\n    def test_from_single_child_message(self, message_dict):\n        """"""\n        A L{WrittenAction} can be constructed from a single child\n        message. Such an action inherits the C{task_level} of the message,\n        has no C{start_time}, C{status}, C{task_type} or C{end_time}.\n        """"""\n        message = written_from_pmap(message_dict)\n        action = WrittenAction.from_messages(children=[message])\n        self.assertThat(\n            action,\n            MatchesStructure.byEquality(\n                status=None,\n                action_type=None,\n                task_uuid=message.task_uuid,\n                task_level=message.task_level.parent(),\n                start_time=None,\n                children=pvector([message]),\n                end_time=None,\n                reason=None,\n                exception=None,\n            ),\n        )\n\n    @given(start_action_messages, message_dicts, integers(min_value=2))\n    def test_different_task_uuid(self, start_message, end_message_dict, n):\n        """"""\n        By definition, an action is either a top-level task or takes place\n        within such a task. If we try to assemble actions from messages with\n        differing task UUIDs, we raise an error.\n        """"""\n        assume(start_message.task_uuid != end_message_dict[""task_uuid""])\n        action_type = start_message.as_dict()[ACTION_TYPE_FIELD]\n        end_message = written_from_pmap(\n            union(\n                end_message_dict.set(ACTION_TYPE_FIELD, action_type),\n                {\n                    ACTION_STATUS_FIELD: SUCCEEDED_STATUS,\n                    TASK_LEVEL_FIELD: sibling_task_level(start_message, n),\n                },\n            )\n        )\n        self.assertRaises(\n            WrongTask,\n            WrittenAction.from_messages,\n            start_message,\n            end_message=end_message,\n        )\n\n    @given(message_dicts)\n    def test_invalid_start_message_missing_status(self, message_dict):\n        """"""\n        A start message must have an C{ACTION_STATUS_FIELD} with the value\n        C{STARTED_STATUS}, otherwise it\'s not a start message. If we receive\n        such a message, raise an error.\n\n        This test handles the case where the status field is not present.\n        """"""\n        assume(ACTION_STATUS_FIELD not in message_dict)\n        message = written_from_pmap(message_dict)\n        self.assertRaises(InvalidStartMessage, WrittenAction.from_messages, message)\n\n    @given(\n        message_dict=start_action_message_dicts,\n        status=(just(FAILED_STATUS) | just(SUCCEEDED_STATUS) | text()),\n    )\n    def test_invalid_start_message_wrong_status(self, message_dict, status):\n        """"""\n        A start message must have an C{ACTION_STATUS_FIELD} with the value\n        C{STARTED_STATUS}, otherwise it\'s not a start message. If we receive\n        such a message, raise an error.\n\n        This test handles the case where the status field is present, but is\n        not C{STARTED_STATUS}.\n        """"""\n        message = written_from_pmap(message_dict.update({ACTION_STATUS_FIELD: status}))\n        self.assertRaises(InvalidStartMessage, WrittenAction.from_messages, message)\n\n    @given(start_action_message_dicts, integers(min_value=2))\n    def test_invalid_task_level_in_start_message(self, start_message_dict, i):\n        """"""\n        All messages in an action have a task level. The first message in an\n        action must have a task level ending in C{1}, indicating that it\'s the\n        first message.\n\n        If we try to start an action with a message that has a task level that\n        does not end in C{1}, raise an error.\n        """"""\n        new_level = start_message_dict[TASK_LEVEL_FIELD].append(i)\n        message_dict = start_message_dict.set(TASK_LEVEL_FIELD, new_level)\n        message = written_from_pmap(message_dict)\n        self.assertRaises(InvalidStartMessage, WrittenAction.from_messages, message)\n\n    @given(start_action_messages, message_dicts, text(), integers(min_value=1))\n    def test_action_type_mismatch(self, start_message, end_message_dict, end_type, n):\n        """"""\n        The end message of an action must have the same C{ACTION_TYPE_FIELD} as\n        the start message of an action. If we try to end an action with a\n        message that has a different type, we raise an error.\n        """"""\n        assume(end_type != start_message.contents[ACTION_TYPE_FIELD])\n        end_message = written_from_pmap(\n            union(\n                end_message_dict,\n                {\n                    ACTION_STATUS_FIELD: SUCCEEDED_STATUS,\n                    ACTION_TYPE_FIELD: end_type,\n                    TASK_UUID_FIELD: start_message.task_uuid,\n                    TASK_LEVEL_FIELD: sibling_task_level(start_message, n),\n                },\n            )\n        )\n        self.assertRaises(\n            WrongActionType,\n            WrittenAction.from_messages,\n            start_message,\n            end_message=end_message,\n        )\n\n    @given(start_action_messages, message_dicts, integers(min_value=2))\n    def test_successful_end(self, start_message, end_message_dict, n):\n        """"""\n        A L{WrittenAction} can be constructed with just a start message and an\n        end message: in this case, an end message that indicates the action was\n        successful.\n\n        Such an action inherits the C{end_time} from the end message, and has\n        a C{status} of C{SUCCEEDED_STATUS}.\n        """"""\n        end_message = written_from_pmap(\n            union(\n                end_message_dict,\n                {\n                    ACTION_STATUS_FIELD: SUCCEEDED_STATUS,\n                    ACTION_TYPE_FIELD: start_message.contents[ACTION_TYPE_FIELD],\n                    TASK_UUID_FIELD: start_message.task_uuid,\n                    TASK_LEVEL_FIELD: sibling_task_level(start_message, n),\n                },\n            )\n        )\n        action = WrittenAction.from_messages(start_message, end_message=end_message)\n        self.assertThat(\n            action,\n            MatchesStructure.byEquality(\n                action_type=start_message.contents[ACTION_TYPE_FIELD],\n                status=SUCCEEDED_STATUS,\n                task_uuid=start_message.task_uuid,\n                task_level=start_message.task_level.parent(),\n                start_time=start_message.timestamp,\n                children=pvector([]),\n                end_time=end_message.timestamp,\n                reason=None,\n                exception=None,\n            ),\n        )\n\n    @given(start_action_messages, message_dicts, text(), text(), integers(min_value=2))\n    def test_failed_end(self, start_message, end_message_dict, exception, reason, n):\n        """"""\n        A L{WrittenAction} can be constructed with just a start message and an\n        end message: in this case, an end message that indicates that the\n        action failed.\n\n        Such an action inherits the C{end_time} from the end message, has a\n        C{status} of C{FAILED_STATUS}, and an C{exception} and C{reason} that\n        match the raised exception.\n        """"""\n        end_message = written_from_pmap(\n            union(\n                end_message_dict,\n                {\n                    ACTION_STATUS_FIELD: FAILED_STATUS,\n                    ACTION_TYPE_FIELD: start_message.contents[ACTION_TYPE_FIELD],\n                    TASK_UUID_FIELD: start_message.task_uuid,\n                    TASK_LEVEL_FIELD: sibling_task_level(start_message, n),\n                    EXCEPTION_FIELD: exception,\n                    REASON_FIELD: reason,\n                },\n            )\n        )\n        action = WrittenAction.from_messages(start_message, end_message=end_message)\n        self.assertThat(\n            action,\n            MatchesStructure.byEquality(\n                action_type=start_message.contents[ACTION_TYPE_FIELD],\n                status=FAILED_STATUS,\n                task_uuid=start_message.task_uuid,\n                task_level=start_message.task_level.parent(),\n                start_time=start_message.timestamp,\n                children=pvector([]),\n                end_time=end_message.timestamp,\n                reason=reason,\n                exception=exception,\n            ),\n        )\n\n    @given(start_action_messages, message_dicts, integers(min_value=2))\n    def test_end_has_no_status(self, start_message, end_message_dict, n):\n        """"""\n        If we try to end a L{WrittenAction} with a message that lacks an\n        C{ACTION_STATUS_FIELD}, we raise an error, because it\'s not a valid\n        end message.\n        """"""\n        assume(ACTION_STATUS_FIELD not in end_message_dict)\n        end_message = written_from_pmap(\n            union(\n                end_message_dict,\n                {\n                    ACTION_TYPE_FIELD: start_message.contents[ACTION_TYPE_FIELD],\n                    TASK_UUID_FIELD: start_message.task_uuid,\n                    TASK_LEVEL_FIELD: sibling_task_level(start_message, n),\n                },\n            )\n        )\n        self.assertRaises(\n            InvalidStatus,\n            WrittenAction.from_messages,\n            start_message,\n            end_message=end_message,\n        )\n\n    # This test is slow, and when run under coverage on pypy on Travis won\'t\n    # make the default of 5 examples. 1 is enough.\n    @given(start_action_messages, lists(written_messages | written_actions))\n    @settings(suppress_health_check=[HealthCheck.too_slow])\n    def test_children(self, start_message, child_messages):\n        """"""\n        We can construct a L{WrittenAction} with child messages. These messages\n        can be either L{WrittenAction}s or L{WrittenMessage}s. They are\n        available in the C{children} field.\n        """"""\n        messages = [\n            reparent_action(\n                start_message.task_uuid,\n                TaskLevel(level=sibling_task_level(start_message, i)),\n                message,\n            )\n            for (i, message) in enumerate(child_messages, 2)\n        ]\n        action = WrittenAction.from_messages(start_message, messages)\n\n        def task_level(m):\n            return m.task_level\n\n        self.assertEqual(sorted(messages, key=task_level), action.children)\n\n    @given(start_action_messages, message_dicts)\n    def test_wrong_task_uuid(self, start_message, child_message):\n        """"""\n        All child messages of an action must have the same C{task_uuid} as the\n        action.\n        """"""\n        assume(child_message[TASK_UUID_FIELD] != start_message.task_uuid)\n        message = written_from_pmap(child_message)\n        self.assertRaises(\n            WrongTask, WrittenAction.from_messages, start_message, v(message)\n        )\n\n    @given(start_action_messages, message_dicts)\n    def test_wrong_task_level(self, start_message, child_message):\n        """"""\n        All child messages of an action must have a task level that is a direct\n        child of the action\'s task level.\n        """"""\n        assume(\n            not start_message.task_level.is_sibling_of(\n                TaskLevel(level=child_message[TASK_LEVEL_FIELD])\n            )\n        )\n        message = written_from_pmap(\n            child_message.update({TASK_UUID_FIELD: start_message.task_uuid})\n        )\n        self.assertRaises(\n            WrongTaskLevel, WrittenAction.from_messages, start_message, v(message)\n        )\n\n    @given(start_action_messages, message_dicts, message_dicts, integers(min_value=2))\n    def test_duplicate_task_level(self, start_message, child1, child2, index):\n        """"""\n        If we try to add a child to an action that has a task level that\'s the\n        same as the task level of an existing child, we raise an error.\n        """"""\n        parent_level = start_message.task_level.parent().level\n        messages = [\n            written_from_pmap(\n                union(\n                    child_message,\n                    {\n                        TASK_UUID_FIELD: start_message.task_uuid,\n                        TASK_LEVEL_FIELD: parent_level.append(index),\n                    },\n                )\n            )\n            for child_message in [child1, child2]\n        ]\n        assume(messages[0] != messages[1])\n        self.assertRaises(\n            DuplicateChild, WrittenAction.from_messages, start_message, messages\n        )\n\n\ndef make_error_extraction_tests(get_messages):\n    """"""\n    Create a test case class for testing extraction of fields from exceptions.\n\n    @param get_messages: Callable that takes an exception instance, returns\n        all message dictionaries generated by logging it.\n\n    @return: ``TestCase`` subclass.\n    """"""\n\n    class ErrorFieldExtraction(TestCase):\n        """"""\n        Tests for extracting fields from exceptions in failed actions.\n        """"""\n\n        def test_matching_class(self):\n            """"""\n            If an exception fails an action and the exact type has registered\n            extractor, extract errors using it.\n            """"""\n\n            class MyException(Exception):\n                pass\n\n            register_exception_extractor(MyException, lambda e: {""key"": e.args[0]})\n            exception = MyException(""a value"")\n            [message] = get_messages(exception)\n            assertContainsFields(self, message, {""key"": ""a value""})\n\n        def test_subclass_falls_back_to_parent(self):\n            """"""\n            If an exception fails an action and the exact type has not been\n            registered but the error is a subclass of a registered class,\n            extract errors using it.\n            """"""\n\n            class MyException(Exception):\n                pass\n\n            class SubException(MyException):\n                pass\n\n            register_exception_extractor(MyException, lambda e: {""key"": e.args[0]})\n            [message] = get_messages(SubException(""the value""))\n            assertContainsFields(self, message, {""key"": ""the value""})\n\n        def test_subclass_matches_first(self):\n            """"""\n            If both a superclass and base class have registered extractors, the\n            more specific one is used.\n            """"""\n\n            class MyException(Exception):\n                pass\n\n            class SubException(MyException):\n                pass\n\n            class SubSubException(SubException):\n                pass\n\n            register_exception_extractor(MyException, lambda e: {""parent"": e.args[0]})\n            register_exception_extractor(SubException, lambda e: {""child"": e.args[0]})\n            [message] = get_messages(SubSubException(""the value""))\n            assertContainsFields(self, message, {""child"": ""the value""})\n\n        def test_error_in_extracter(self):\n            """"""\n            If an error occurs in extraction, log the message as usual just\n            without the extra fields, and an additional traceback.\n            """"""\n\n            class MyException(Exception):\n                pass\n\n            def extract(e):\n                return e.nosuchattribute\n\n            register_exception_extractor(MyException, extract)\n\n            messages = get_failed_action_messages(MyException())\n            assertContainsFields(\n                self, messages[1], {""action_type"": ""sys:me"", ""action_status"": ""failed""}\n            )\n            assertContainsFields(self, messages[0], {""message_type"": ""eliot:traceback""})\n            self.assertIn(""nosuchattribute"", str(messages[0][""reason""]))\n\n        def test_environmenterror(self):\n            """"""\n            ``EnvironmentError`` has a registered extractor that extracts the\n            errno.\n            """"""\n            [message] = get_messages(EnvironmentError(12, ""oh noes""))\n            assertContainsFields(self, message, {""errno"": 12})\n\n    return ErrorFieldExtraction\n\n\ndef get_failed_action_messages(exception):\n    """"""\n    Fail an action using the given exception.\n\n    :return: Logged dictionaries from the exception failing an action.\n    """"""\n    action_type = ActionType(""sys:me"", [], [])\n    logger = MemoryLogger()\n    action = action_type.as_task(logger=logger)\n    try:\n        with action:\n            raise exception\n    except exception.__class__:\n        pass\n    logger.validate()\n    return logger.messages[1:]\n\n\nclass FailedActionExtractionTests(\n    make_error_extraction_tests(get_failed_action_messages)\n):\n    """"""\n    Tests for error extraction in failed actions.\n    """"""\n\n    def test_regular_fields(self):\n        """"""\n        The normal failed action fields are still present when error\n        extraction is used.\n        """"""\n\n        class MyException(Exception):\n            pass\n\n        register_exception_extractor(MyException, lambda e: {""key"": e.args[0]})\n\n        exception = MyException(""because"")\n        messages = get_failed_action_messages(exception)\n        assertContainsFields(\n            self,\n            messages[0],\n            {\n                ""task_level"": [2],\n                ""action_type"": ""sys:me"",\n                ""action_status"": ""failed"",\n                ""reason"": ""because"",\n                ""exception"": ""eliot.tests.test_action.MyException"",\n            },\n        )\n\n\nclass PreserveContextTests(TestCase):\n    """"""\n    Tests for L{preserve_context}.\n    """"""\n\n    def add(self, x, y):\n        """"""\n        Add two inputs.\n        """"""\n        Message.log(message_type=""child"")\n        return x + y\n\n    def test_no_context(self):\n        """"""\n        If C{preserve_context} is run outside an action context it just\n        returns the same function.\n        """"""\n        wrapped = preserve_context(self.add)\n        self.assertEqual(wrapped(2, 3), 5)\n\n    def test_with_context_calls_underlying(self):\n        """"""\n        If run inside an Eliot context, the result of C{preserve_context} is\n        the result of calling the underlying function.\n        """"""\n        with start_action(action_type=""parent""):\n            wrapped = preserve_context(self.add)\n            self.assertEqual(wrapped(3, y=4), 7)\n\n    @capture_logging(None)\n    def test_with_context_preserves_context(self, logger):\n        """"""\n        If run inside an Eliot context, the result of C{preserve_context} runs\n        the wrapped function within a C{eliot:task} which is a child of\n        the original action.\n        """"""\n        with start_action(action_type=""parent""):\n            wrapped = preserve_context(lambda: self.add(3, 4))\n        thread = Thread(target=wrapped)\n        thread.start()\n        thread.join()\n        [tree] = Parser.parse_stream(logger.messages)\n        root = tree.root()\n        self.assertEqual(\n            (\n                root.action_type,\n                root.children[0].action_type,\n                root.children[0].children[0].contents[MESSAGE_TYPE_FIELD],\n            ),\n            (""parent"", ""eliot:remote_task"", ""child""),\n        )\n\n    def test_callable_only_once(self):\n        """"""\n        The result of C{preserve_context} can only be called once.\n        """"""\n        with start_action(action_type=""parent""):\n            wrapped = preserve_context(self.add)\n        wrapped(1, 2)\n        self.assertRaises(TooManyCalls, wrapped, 3, 4)\n\n\n@log_call\ndef for_pickling():\n    pass\n\n\nclass LogCallTests(TestCase):\n    """"""Tests for log_call decorator.""""""\n\n    def assert_logged(self, logger, action_type, expected_params, expected_result):\n        """"""Assert that an action of given structure was logged.""""""\n        if six.PY2:\n            # On Python 2 we don\'t include the module or class:\n            action_type = action_type.split(""."")[-1]\n        [tree] = Parser.parse_stream(logger.messages)\n        root = tree.root()\n        self.assertEqual(root.action_type, action_type)\n        message = dict(root.start_message.contents)\n        for field in [ACTION_STATUS_FIELD, ACTION_TYPE_FIELD]:\n            message.pop(field)\n        self.assertEqual(message, expected_params)\n        self.assertEqual(root.end_message.contents[""result""], expected_result)\n        self.assertEqual(root.status, SUCCEEDED_STATUS)\n\n    @capture_logging(None)\n    def test_no_args_return(self, logger):\n        """"""\n        C{@log_call} with no arguments logs return result, arguments, and has\n        action type based on the action name.\n        """"""\n\n        @log_call\n        def myfunc(x, y):\n            return 4\n\n        myfunc(2, 3)\n        self.assert_logged(logger, self.id() + "".<locals>.myfunc"", {""x"": 2, ""y"": 3}, 4)\n\n    @capture_logging(None)\n    def test_exception(self, logger):\n        """"""C{@log_call} with an exception logs a failed action.""""""\n\n        @log_call\n        def myfunc(x, y):\n            1 / 0\n\n        with self.assertRaises(ZeroDivisionError):\n            myfunc(2, 4)\n\n        [tree] = Parser.parse_stream(logger.messages)\n        root = tree.root()\n        self.assertIn(""ZeroDivisionError"", root.end_message.contents[""exception""])\n        self.assertEqual(root.status, FAILED_STATUS)\n\n    @capture_logging(None)\n    def test_action_type(self, logger):\n        """"""C{@log_call} can take an action type.""""""\n\n        @log_call(action_type=""myaction"")\n        def myfunc(x, y):\n            return 4\n\n        myfunc(2, 3)\n        self.assert_logged(logger, ""myaction"", {""x"": 2, ""y"": 3}, 4)\n\n    @capture_logging(None)\n    def test_default_argument_given(self, logger):\n        """"""C{@log_call} logs default arguments that were passed in.""""""\n\n        @log_call\n        def myfunc(x, y=1):\n            return 4\n\n        myfunc(2, y=5)\n        self.assert_logged(logger, self.id() + "".<locals>.myfunc"", {""x"": 2, ""y"": 5}, 4)\n\n    @capture_logging(None)\n    def test_default_argument_missing(self, logger):\n        """"""C{@log_call} logs default arguments that weren\'t passed in.""""""\n\n        @log_call\n        def myfunc(x, y=1):\n            return 6\n\n        myfunc(2)\n        self.assert_logged(logger, self.id() + "".<locals>.myfunc"", {""x"": 2, ""y"": 1}, 6)\n\n    @capture_logging(None)\n    def test_star_args_kwargs(self, logger):\n        """"""C{@log_call} logs star args and kwargs.""""""\n\n        @log_call\n        def myfunc(x, *y, **z):\n            return 6\n\n        myfunc(2, 3, 4, a=1, b=2)\n        self.assert_logged(\n            logger,\n            self.id() + "".<locals>.myfunc"",\n            {""x"": 2, ""y"": (3, 4), ""z"": {""a"": 1, ""b"": 2}},\n            6,\n        )\n\n    @capture_logging(None)\n    def test_whitelist_args(self, logger):\n        """"""C{@log_call} only includes whitelisted arguments.""""""\n\n        @log_call(include_args=(""x"", ""z""))\n        def myfunc(x, y, z):\n            return 6\n\n        myfunc(2, 3, 4)\n        self.assert_logged(logger, self.id() + "".<locals>.myfunc"", {""x"": 2, ""z"": 4}, 6)\n\n    @skipIf(six.PY2, ""Didn\'t bother implementing safety check on Python 2"")\n    def test_wrong_whitelist_args(self):\n        """"""If C{include_args} doesn\'t match function, raise an exception.""""""\n        with self.assertRaises(ValueError):\n\n            @log_call(include_args=[""a"", ""x"", ""y""])\n            def f(x, y):\n                pass\n\n    @capture_logging(None)\n    def test_no_result(self, logger):\n        """"""C{@log_call} can omit logging the result.""""""\n\n        @log_call(include_result=False)\n        def myfunc(x, y):\n            return 6\n\n        myfunc(2, 3)\n\n        [tree] = Parser.parse_stream(logger.messages)\n        root = tree.root()\n        self.assertNotIn(""result"", root.end_message.contents)\n        self.assertEqual(root.status, SUCCEEDED_STATUS)\n\n    def test_pickleable(self):\n        """"""Functions decorated with C{log_call} are pickleable.\n\n        This is necessary for e.g. Dask usage.\n        """"""\n        self.assertIs(for_pickling, pickle.loads(pickle.dumps(for_pickling)))\n\n    @capture_logging(None)\n    def test_methods(self, logger):\n        """"""self is not logged.""""""\n\n        class C(object):\n            @log_call\n            def f(self, x):\n                pass\n\n        C().f(2)\n        self.assert_logged(logger, self.id() + "".<locals>.C.f"", {""x"": 2}, None)\n\n\nclass IndividualMessageLogTests(TestCase):\n    """"""Action.log() tests.""""""\n\n    def test_log_creates_new_dictionary(self):\n        """"""\n        L{Action.log} creates a new dictionary on each call.\n\n        This is important because we might mutate the dictionary in\n        ``Logger.write``.\n        """"""\n        messages = []\n        add_destination(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n\n        with start_action(action_type=""x"") as action:\n            action.log(""mymessage"", key=4)\n            action.log(message_type=""mymessage2"", key=5)\n        self.assertEqual(messages[1][""key""], 4)\n        self.assertEqual(messages[2][""key""], 5)\n        self.assertEqual(messages[1][""message_type""], ""mymessage"")\n        self.assertEqual(messages[2][""message_type""], ""mymessage2"")\n\n    @patch(""time.time"")\n    def test_log_adds_timestamp(self, time_func):\n        """"""\n        L{Action.log} adds a C{""timestamp""} field to the dictionary written\n        to the logger, with the current time in seconds since the epoch.\n        """"""\n        messages = []\n        add_destination(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n\n        time_func.return_value = timestamp = 1387299889.153187625\n        with start_action(action_type=""x"") as action:\n            action.log(""mymessage"", key=4)\n        self.assertEqual(messages[1][""timestamp""], timestamp)\n\n    def test_part_of_action(self):\n        """"""\n        L{Action.log} adds the identification fields from the given\n        L{Action} to the dictionary written to the logger.\n        """"""\n        messages = []\n        add_destination(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n\n        action = Action(None, ""unique"", TaskLevel(level=[37, 4]), ""sys:thename"")\n        action.log(""me"", key=2)\n        written = messages[0]\n        del written[""timestamp""]\n        self.assertEqual(\n            written,\n            {\n                ""task_uuid"": ""unique"",\n                ""task_level"": [37, 4, 1],\n                ""key"": 2,\n                ""message_type"": ""me"",\n            },\n        )\n'"
eliot/tests/test_api.py,0,"b'""""""\nTests for the public API exposed by L{eliot}.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom unittest import TestCase\n\nfrom .._output import Logger\nimport eliot\n\n\nclass PublicAPITests(TestCase):\n    """"""\n    Tests for the public API.\n    """"""\n\n    def test_addDestination(self):\n        """"""\n        L{eliot.addDestination} adds destinations to the L{Destinations}\n        attached to L{Logger}.\n        """"""\n        o = object()\n        eliot.addDestination(o)\n        self.addCleanup(eliot.removeDestination, o)\n        self.assertIn(o, Logger._destinations._destinations)\n\n    def test_removeDestination(self):\n        """"""\n        L{eliot.addDestination} removes destinations from the L{Destinations}\n        attached to L{Logger}.\n        """"""\n        self.assertEqual(eliot.removeDestination, Logger._destinations.remove)\n\n    def test_addGlobalFields(self):\n        """"""\n        L{eliot.addGlobalFields} calls the corresponding method on the\n        L{Destinations} attached to L{Logger}.\n        """"""\n        self.assertEqual(eliot.addGlobalFields, Logger._destinations.addGlobalFields)\n\n\nclass PEP8Tests(TestCase):\n    """"""\n    Tests for the PEP 8 variant of the the public API.\n    """"""\n\n    def test_add_destination(self):\n        """"""\n        L{eliot.addDestionation} is the same as L{eliot.add_destination}.\n        """"""\n        self.assertIs(eliot.add_destination, eliot.addDestination)\n\n    def test_remove_destination(self):\n        """"""\n        L{eliot.removeDestionation} is the same as L{eliot.remove_destination}.\n        """"""\n        self.assertIs(eliot.remove_destination, eliot.removeDestination)\n\n    def test_add_global_fields(self):\n        """"""\n        L{eliot.add_global_fields} is the same as L{eliot.addGlobalFields}.\n        """"""\n        self.assertIs(eliot.add_global_fields, eliot.addGlobalFields)\n\n    def test_write_traceback(self):\n        """"""\n        L{eliot.writeTraceback} is the same as L{eliot.write_traceback}.\n        """"""\n        self.assertIs(eliot.write_traceback, eliot.writeTraceback)\n\n    def test_write_failure(self):\n        """"""\n        L{eliot.writeFailure} is the same as L{eliot.write_failure}.\n        """"""\n        self.assertIs(eliot.write_failure, eliot.writeFailure)\n\n    def test_start_task(self):\n        """"""\n        L{eliot.startTask} is the same as L{eliot.start_task}.\n        """"""\n        self.assertIs(eliot.start_task, eliot.startTask)\n\n    def test_start_action(self):\n        """"""\n        L{eliot.startAction} is the same as L{eliot.start_action}.\n        """"""\n        self.assertIs(eliot.start_action, eliot.startAction)\n'"
eliot/tests/test_coroutines.py,0,"b'""""""\nTests for coroutines.\n\nImported into test_coroutine.py when running tests under Python 3.5 or later;\nin earlier versions of Python this code is a syntax error.\n""""""\n\nimport asyncio\nfrom unittest import TestCase\n\nfrom ..testing import capture_logging\nfrom ..parse import Parser\nfrom .. import start_action\n\n\nasync def standalone_coro():\n    """"""\n    Log a message inside a new coroutine.\n    """"""\n    await asyncio.sleep(0.1)\n    with start_action(action_type=""standalone""):\n        pass\n\n\nasync def calling_coro():\n    """"""\n    Log an action inside a coroutine, and call another coroutine.\n    """"""\n    with start_action(action_type=""calling""):\n        await standalone_coro()\n\n\ndef run_coroutines(*async_functions):\n    """"""\n    Run a coroutine until it finishes.\n    """"""\n    loop = asyncio.get_event_loop()\n    futures = [asyncio.ensure_future(f()) for f in async_functions]\n\n    async def wait_for_futures():\n        for future in futures:\n            await future\n\n    loop.run_until_complete(wait_for_futures())\n\n\nclass CoroutineTests(TestCase):\n    """"""\n    Tests for coroutines.\n    """"""\n\n    @capture_logging(None)\n    def test_multiple_coroutines_contexts(self, logger):\n        """"""\n        Each top-level coroutine has its own Eliot logging context.\n        """"""\n\n        async def waiting_coro():\n            with start_action(action_type=""waiting""):\n                await asyncio.sleep(0.5)\n\n        run_coroutines(waiting_coro, standalone_coro)\n        trees = Parser.parse_stream(logger.messages)\n        self.assertEqual(\n            sorted([(t.root().action_type, t.root().children) for t in trees]),\n            [(""standalone"", []), (""waiting"", [])],\n        )\n\n    @capture_logging(None)\n    def test_await_inherits_coroutine_contexts(self, logger):\n        """"""\n        awaited coroutines inherit the logging context.\n        """"""\n        run_coroutines(calling_coro)\n        [tree] = Parser.parse_stream(logger.messages)\n        root = tree.root()\n        [child] = root.children\n        self.assertEqual(\n            (root.action_type, child.action_type, child.children),\n            (""calling"", ""standalone"", []),\n        )\n\n    @capture_logging(None)\n    def test_interleaved_coroutines(self, logger):\n        """"""\n        start_action() started in one coroutine doesn\'t impact another in a\n        different coroutine.\n        """"""\n\n        async def coro_sleep(delay, action_type):\n            with start_action(action_type=action_type):\n                await asyncio.sleep(delay)\n\n        async def main():\n            with start_action(action_type=""main""):\n                f1 = asyncio.ensure_future(coro_sleep(1, ""a""))\n                f2 = asyncio.ensure_future(coro_sleep(0.5, ""b""))\n                await f1\n                await f2\n\n        run_coroutines(main)\n        [tree] = list(Parser.parse_stream(logger.messages))\n        root = tree.root()\n        self.assertEqual(root.action_type, ""main"")\n        self.assertEqual(sorted([c.action_type for c in root.children]), [""a"", ""b""])\n'"
eliot/tests/test_dask.py,0,"b'""""""Tests for eliot.dask.""""""\n\nfrom unittest import TestCase, skipUnless\n\nfrom ..testing import capture_logging, LoggedAction, LoggedMessage\nfrom .. import start_action, log_message\n\ntry:\n    import dask\n    from dask.bag import from_sequence\n    from dask.distributed import Client\n    import dask.dataframe as dd\n    import pandas as pd\nexcept ImportError:\n    dask = None\nelse:\n    from ..dask import (\n        compute_with_trace,\n        _RunWithEliotContext,\n        _add_logging,\n        persist_with_trace,\n    )\n\n\n@skipUnless(dask, ""Dask not available."")\nclass DaskTests(TestCase):\n    """"""Tests for end-to-end functionality.""""""\n\n    def setUp(self):\n        dask.config.set(scheduler=""threading"")\n\n    def test_compute(self):\n        """"""compute_with_trace() runs the same logic as compute().""""""\n        bag = from_sequence([1, 2, 3])\n        bag = bag.map(lambda x: x * 7).map(lambda x: x * 4)\n        bag = bag.fold(lambda x, y: x + y)\n        self.assertEqual(dask.compute(bag), compute_with_trace(bag))\n\n    def test_future(self):\n        """"""compute_with_trace() can handle Futures.""""""\n        client = Client(processes=False)\n        self.addCleanup(client.shutdown)\n        [bag] = dask.persist(from_sequence([1, 2, 3]))\n        bag = bag.map(lambda x: x * 5)\n        result = dask.compute(bag)\n        self.assertEqual(result, ([5, 10, 15],))\n        self.assertEqual(result, compute_with_trace(bag))\n\n    def test_persist_result(self):\n        """"""persist_with_trace() runs the same logic as process().""""""\n        client = Client(processes=False)\n        self.addCleanup(client.shutdown)\n        bag = from_sequence([1, 2, 3])\n        bag = bag.map(lambda x: x * 7)\n        self.assertEqual(\n            [b.compute() for b in dask.persist(bag)],\n            [b.compute() for b in persist_with_trace(bag)],\n        )\n\n    def test_persist_pandas(self):\n        """"""persist_with_trace() with a Pandas dataframe.\n\n        This ensures we don\'t blow up, which used to be the case.\n        """"""\n        df = pd.DataFrame()\n        df = dd.from_pandas(df, npartitions=1)\n        persist_with_trace(df)\n\n    @capture_logging(None)\n    def test_persist_logging(self, logger):\n        """"""persist_with_trace() preserves Eliot context.""""""\n\n        def persister(bag):\n            [bag] = persist_with_trace(bag)\n            return dask.compute(bag)\n\n        self.assert_logging(logger, persister, ""dask:persist"")\n\n    @capture_logging(None)\n    def test_compute_logging(self, logger):\n        """"""compute_with_trace() preserves Eliot context.""""""\n        self.assert_logging(logger, compute_with_trace, ""dask:compute"")\n\n    def assert_logging(self, logger, run_with_trace, top_action_name):\n        """"""Utility function for _with_trace() logging tests.""""""\n\n        def mult(x):\n            log_message(message_type=""mult"")\n            return x * 4\n\n        def summer(x, y):\n            log_message(message_type=""finally"")\n            return x + y\n\n        bag = from_sequence([1, 2])\n        bag = bag.map(mult).fold(summer)\n        with start_action(action_type=""act1""):\n            run_with_trace(bag)\n\n        [logged_action] = LoggedAction.ofType(logger.messages, ""act1"")\n        self.assertEqual(\n            logged_action.type_tree(),\n            {\n                ""act1"": [\n                    {\n                        top_action_name: [\n                            {""eliot:remote_task"": [""dask:task"", ""mult""]},\n                            {""eliot:remote_task"": [""dask:task"", ""mult""]},\n                            {""eliot:remote_task"": [""dask:task"", ""finally""]},\n                        ]\n                    }\n                ]\n            },\n        )\n\n        # Make sure dependencies are tracked:\n        mult1_msg, mult2_msg, final_msg = LoggedMessage.ofType(\n            logger.messages, ""dask:task""\n        )\n        self.assertEqual(\n            sorted(final_msg.message[""dependencies""]),\n            sorted([mult1_msg.message[""key""], mult2_msg.message[""key""]]),\n        )\n\n        # Make sure dependencies are logically earlier in the logs:\n        self.assertTrue(\n            mult1_msg.message[""task_level""] < final_msg.message[""task_level""]\n        )\n        self.assertTrue(\n            mult2_msg.message[""task_level""] < final_msg.message[""task_level""]\n        )\n\n\n@skipUnless(dask, ""Dask not available."")\nclass AddLoggingTests(TestCase):\n    """"""Tests for _add_logging().""""""\n\n    maxDiff = None\n\n    def test_add_logging_to_full_graph(self):\n        """"""_add_logging() recreates Dask graph with wrappers.""""""\n        bag = from_sequence([1, 2, 3])\n        bag = bag.map(lambda x: x * 7).map(lambda x: x * 4)\n        bag = bag.fold(lambda x, y: x + y)\n        graph = bag.__dask_graph__()\n\n        # Add logging:\n        with start_action(action_type=""bleh""):\n            logging_added = _add_logging(graph)\n\n        # Ensure resulting graph hasn\'t changed substantively:\n        logging_removed = {}\n        for key, value in logging_added.items():\n            if callable(value[0]):\n                func, args = value[0], value[1:]\n                self.assertIsInstance(func, _RunWithEliotContext)\n                value = (func.func,) + args\n            logging_removed[key] = value\n\n        self.assertEqual(logging_removed, graph)\n\n    def test_add_logging_explicit(self):\n        """"""_add_logging() on more edge cases of the graph.""""""\n\n        def add(s):\n            return s + ""s""\n\n        def add2(s):\n            return s + ""s""\n\n        # b runs first, then d, then a and c.\n        graph = {\n            ""a"": ""d"",\n            ""d"": [1, 2, (add, ""b"")],\n            (""b"", 0): 1,\n            ""c"": (add2, ""d""),\n        }\n\n        with start_action(action_type=""bleh"") as action:\n            task_id = action.task_uuid\n            self.assertEqual(\n                _add_logging(graph),\n                {\n                    ""d"": [\n                        1,\n                        2,\n                        (\n                            _RunWithEliotContext(\n                                task_id=task_id + ""@/2"",\n                                func=add,\n                                key=""d"",\n                                dependencies=[""b""],\n                            ),\n                            ""b"",\n                        ),\n                    ],\n                    ""a"": ""d"",\n                    (""b"", 0): 1,\n                    ""c"": (\n                        _RunWithEliotContext(\n                            task_id=task_id + ""@/3"",\n                            func=add2,\n                            key=""c"",\n                            dependencies=[""d""],\n                        ),\n                        ""d"",\n                    ),\n                },\n            )\n'"
eliot/tests/test_filter.py,0,"b'""""""\nTests for L{eliot.filter}.\n""""""\nfrom __future__ import unicode_literals\n\nimport sys\n\nfrom unittest import TestCase\nfrom datetime import datetime\nfrom io import BytesIO\nimport inspect\n\nfrom .common import FakeSys\nfrom .. import _bytesjson as json\nfrom ..filter import EliotFilter, main, USAGE\n\n\nclass EliotFilterTests(TestCase):\n    """"""\n    Tests for L{EliotFilter}.\n    """"""\n\n    def test_expression(self):\n        """"""\n        For each item in the incoming sequence L{EliotFilter.run} calls\n        L{EliotFilter._evaluate} with the item decoded from JSON, and writes the\n        result to the output file as JSON.\n        """"""\n        f = BytesIO()\n        efilter = EliotFilter(""J"", [b\'""abcd""\', b""[1, 2]""], f)\n        efilter._evaluate = lambda expr: {""x"": len(expr), ""orig"": expr}\n        self.assertEqual(f.getvalue(), b"""")\n        efilter.run()\n        self.assertEqual(\n            f.getvalue(),\n            json.dumps({""x"": 4, ""orig"": ""abcd""})\n            + b""\\n""\n            + json.dumps({""x"": 2, ""orig"": [1, 2]})\n            + b""\\n"",\n        )\n\n    def evaluateExpression(self, expr, message):\n        """"""\n        Render a single message with the given expression using\n        L{EliotFilter._evaluate}.\n        """"""\n        efilter = EliotFilter(expr, [], BytesIO())\n        return efilter._evaluate(message)\n\n    def test_J(self):\n        """"""\n        The expression has access to the decoded JSON message as C{J} in its\n        locals.\n        """"""\n        result = self.evaluateExpression(""J[\'a\']"", {""a"": 123})\n        self.assertEqual(result, 123)\n\n    def test_otherLocals(self):\n        """"""\n        The expression has access to L{datetime} and L{timedelta} in its\n        built-ins.\n        """"""\n        result = self.evaluateExpression(\n            ""isinstance(datetime.utcnow() - datetime.utcnow(), timedelta)"", {}\n        )\n        self.assertEqual(result, True)\n\n    def test_datetimeSerialization(self):\n        """"""\n        Any L{datetime} in results will be serialized using L{datetime.isoformat}.\n        """"""\n        dt = datetime(2012, 12, 31)\n        f = BytesIO()\n        EliotFilter(""datetime(2012, 12, 31)"", [""{}""], f).run()\n        expected = json.dumps(dt.isoformat()) + b""\\n""\n        self.assertEqual(f.getvalue(), expected)\n\n    def test_SKIP(self):\n        """"""\n        A result of C{SKIP} indicates nothing should be output.\n        """"""\n        f = BytesIO()\n        EliotFilter(""SKIP"", [b\'{""a"": 123}\'], f).run()\n        self.assertEqual(f.getvalue(), b"""")\n\n\nclass MainTests(TestCase):\n    """"""\n    Test cases for L{main}.\n    """"""\n\n    def test_default(self):\n        """"""\n        By default L{main} uses information from L{sys}.\n        """"""\n        self.assertEqual(inspect.getargspec(main).defaults, (sys,))\n\n    def test_stdinOut(self):\n        """"""\n        L{main} reads from the C{stdin} attribute of the given C{sys} equivalent,\n        and writes rendered expressions to the C{stdout} attribute.\n        """"""\n        sys = FakeSys([""eliotfilter"", ""J[0]""], b""[1, 2]\\n[4, 5]\\n"")\n        main(sys)\n        self.assertEqual(sys.stdout.getvalue(), b""1\\n4\\n"")\n\n    def test_success(self):\n        """"""\n        A successful run returns C{0}.\n        """"""\n        sys = FakeSys([""eliotfilter"", ""J[0]""], b""[1, 2]\\n[4, 5]\\n"")\n        result = main(sys)\n        self.assertEqual(result, 0)\n\n    def test_noArguments(self):\n        """"""\n        If given no arguments, usage documentation is printed to stderr and C{1}\n        is returned.\n        """"""\n        sys = FakeSys([""eliotfilter""], b"""")\n        result = main(sys)\n        self.assertEqual(sys.stderr.getvalue(), USAGE)\n        self.assertEqual(result, 1)\n'"
eliot/tests/test_generators.py,0,"b'""""""\nTests for L{eliot._generators}.\n""""""\n\nfrom __future__ import unicode_literals, absolute_import\n\nfrom pprint import pformat\nfrom unittest import TestCase\n\nfrom eliot import Message, start_action\nfrom ..testing import capture_logging, assertHasAction\n\nfrom .._generators import eliot_friendly_generator_function\n\n\ndef assert_expected_action_tree(\n    testcase, logger, expected_action_type, expected_type_tree\n):\n    """"""\n    Assert that a logger has a certain logged action with certain children.\n\n    @see: L{assert_generator_logs_action_tree}\n    """"""\n    logged_action = assertHasAction(testcase, logger, expected_action_type, True)\n    type_tree = logged_action.type_tree()\n    testcase.assertEqual(\n        {expected_action_type: expected_type_tree},\n        type_tree,\n        ""Logger had messages:\\n{}"".format(pformat(logger.messages, indent=4)),\n    )\n\n\ndef assert_generator_logs_action_tree(\n    testcase, generator_function, logger, expected_action_type, expected_type_tree\n):\n    """"""\n    Assert that exhausting a generator from the given function logs an action\n    of the given type with children matching the given type tree.\n\n    @param testcase: A test case instance to use to make assertions.\n    @type testcase: L{unittest.TestCase}\n\n    @param generator_function: A no-argument callable that returns a generator\n        to be exhausted.\n\n    @param logger: A logger to inspect for logged messages.\n    @type logger: L{MemoryLogger}\n\n    @param expected_action_type: An action type which should be logged by the\n        generator.\n    @type expected_action_type: L{unicode}\n\n    @param expected_type_tree: The types of actions and messages which should\n        be logged beneath the expected action.  The structure of this value\n        matches the structure returned by L{LoggedAction.type_tree}.\n    @type expected_type_tree: L{list}\n    """"""\n    list(eliot_friendly_generator_function(generator_function)())\n    assert_expected_action_tree(\n        testcase, logger, expected_action_type, expected_type_tree\n    )\n\n\nclass EliotFriendlyGeneratorFunctionTests(TestCase):\n    """"""\n    Tests for L{eliot_friendly_generator_function}.\n    """"""\n\n    # Get our custom assertion failure messages *and* the standard ones.\n    longMessage = True\n\n    @capture_logging(None)\n    def test_yield_none(self, logger):\n        @eliot_friendly_generator_function\n        def g():\n            Message.log(message_type=""hello"")\n            yield\n            Message.log(message_type=""goodbye"")\n\n        g.debug = True  # output yielded messages\n\n        with start_action(action_type=""the-action""):\n            list(g())\n\n        assert_expected_action_tree(\n            self, logger, ""the-action"", [""hello"", ""yielded"", ""goodbye""]\n        )\n\n    @capture_logging(None)\n    def test_yield_value(self, logger):\n        expected = object()\n\n        @eliot_friendly_generator_function\n        def g():\n            Message.log(message_type=""hello"")\n            yield expected\n            Message.log(message_type=""goodbye"")\n\n        g.debug = True  # output yielded messages\n\n        with start_action(action_type=""the-action""):\n            self.assertEqual([expected], list(g()))\n\n        assert_expected_action_tree(\n            self, logger, ""the-action"", [""hello"", ""yielded"", ""goodbye""]\n        )\n\n    @capture_logging(None)\n    def test_yield_inside_another_action(self, logger):\n        @eliot_friendly_generator_function\n        def g():\n            Message.log(message_type=""a"")\n            with start_action(action_type=""confounding-factor""):\n                Message.log(message_type=""b"")\n                yield None\n                Message.log(message_type=""c"")\n            Message.log(message_type=""d"")\n\n        g.debug = True  # output yielded messages\n\n        with start_action(action_type=""the-action""):\n            list(g())\n\n        assert_expected_action_tree(\n            self,\n            logger,\n            ""the-action"",\n            [""a"", {""confounding-factor"": [""b"", ""yielded"", ""c""]}, ""d""],\n        )\n\n    @capture_logging(None)\n    def test_yield_inside_nested_actions(self, logger):\n        @eliot_friendly_generator_function\n        def g():\n            Message.log(message_type=""a"")\n            with start_action(action_type=""confounding-factor""):\n                Message.log(message_type=""b"")\n                yield None\n                with start_action(action_type=""double-confounding-factor""):\n                    yield None\n                    Message.log(message_type=""c"")\n                Message.log(message_type=""d"")\n            Message.log(message_type=""e"")\n\n        g.debug = True  # output yielded messages\n\n        with start_action(action_type=""the-action""):\n            list(g())\n\n        assert_expected_action_tree(\n            self,\n            logger,\n            ""the-action"",\n            [\n                ""a"",\n                {\n                    ""confounding-factor"": [\n                        ""b"",\n                        ""yielded"",\n                        {""double-confounding-factor"": [""yielded"", ""c""]},\n                        ""d"",\n                    ]\n                },\n                ""e"",\n            ],\n        )\n\n    @capture_logging(None)\n    def test_generator_and_non_generator(self, logger):\n        @eliot_friendly_generator_function\n        def g():\n            Message.log(message_type=""a"")\n            yield\n            with start_action(action_type=""action-a""):\n                Message.log(message_type=""b"")\n                yield\n                Message.log(message_type=""c"")\n\n            Message.log(message_type=""d"")\n            yield\n\n        g.debug = True  # output yielded messages\n\n        with start_action(action_type=""the-action""):\n            generator = g()\n            next(generator)\n            Message.log(message_type=""0"")\n            next(generator)\n            Message.log(message_type=""1"")\n            next(generator)\n            Message.log(message_type=""2"")\n            self.assertRaises(StopIteration, lambda: next(generator))\n\n        assert_expected_action_tree(\n            self,\n            logger,\n            ""the-action"",\n            [\n                ""a"",\n                ""yielded"",\n                ""0"",\n                {""action-a"": [""b"", ""yielded"", ""c""]},\n                ""1"",\n                ""d"",\n                ""yielded"",\n                ""2"",\n            ],\n        )\n\n    @capture_logging(None)\n    def test_concurrent_generators(self, logger):\n        @eliot_friendly_generator_function\n        def g(which):\n            Message.log(message_type=""{}-a"".format(which))\n            with start_action(action_type=which):\n                Message.log(message_type=""{}-b"".format(which))\n                yield\n                Message.log(message_type=""{}-c"".format(which))\n            Message.log(message_type=""{}-d"".format(which))\n\n        g.debug = True  # output yielded messages\n\n        gens = [g(""1""), g(""2"")]\n        with start_action(action_type=""the-action""):\n            while gens:\n                for g in gens[:]:\n                    try:\n                        next(g)\n                    except StopIteration:\n                        gens.remove(g)\n\n        assert_expected_action_tree(\n            self,\n            logger,\n            ""the-action"",\n            [\n                ""1-a"",\n                {""1"": [""1-b"", ""yielded"", ""1-c""]},\n                ""2-a"",\n                {""2"": [""2-b"", ""yielded"", ""2-c""]},\n                ""1-d"",\n                ""2-d"",\n            ],\n        )\n\n    @capture_logging(None)\n    def test_close_generator(self, logger):\n        @eliot_friendly_generator_function\n        def g():\n            Message.log(message_type=""a"")\n            try:\n                yield\n                Message.log(message_type=""b"")\n            finally:\n                Message.log(message_type=""c"")\n\n        g.debug = True  # output yielded messages\n\n        with start_action(action_type=""the-action""):\n            gen = g()\n            next(gen)\n            gen.close()\n\n        assert_expected_action_tree(self, logger, ""the-action"", [""a"", ""yielded"", ""c""])\n\n    @capture_logging(None)\n    def test_nested_generators(self, logger):\n        @eliot_friendly_generator_function\n        def g(recurse):\n            with start_action(action_type=""a-recurse={}"".format(recurse)):\n                Message.log(message_type=""m-recurse={}"".format(recurse))\n                if recurse:\n                    set(g(False))\n                else:\n                    yield\n\n        g.debug = True  # output yielded messages\n\n        with start_action(action_type=""the-action""):\n            set(g(True))\n\n        assert_expected_action_tree(\n            self,\n            logger,\n            ""the-action"",\n            [\n                {\n                    ""a-recurse=True"": [\n                        ""m-recurse=True"",\n                        {""a-recurse=False"": [""m-recurse=False"", ""yielded""]},\n                    ]\n                }\n            ],\n        )\n'"
eliot/tests/test_journald.py,0,"b'""""""\nTests for L{eliot.journald}.\n""""""\nfrom os import getpid, strerror\nfrom unittest import skipUnless, TestCase\nfrom subprocess import check_output, CalledProcessError, STDOUT\nfrom errno import EINVAL\nfrom sys import argv\nfrom uuid import uuid4\nfrom time import sleep\n\nfrom six import text_type as unicode\n\nfrom .._bytesjson import loads\nfrom .._output import MemoryLogger\nfrom .._message import TASK_UUID_FIELD\nfrom .. import start_action, Message, write_traceback\n\ntry:\n    from ..journald import sd_journal_send, JournaldDestination\nexcept ImportError:\n    sd_journal_send = None\n\n\ndef _journald_available():\n    """"""\n    :return: Boolean indicating whether journald is available to use.\n    """"""\n    if sd_journal_send is None:\n        return False\n    try:\n        check_output([""journalctl"", ""-b"", ""-n1""], stderr=STDOUT)\n    except (OSError, CalledProcessError):\n        return False\n    return True\n\n\ndef last_journald_message():\n    """"""\n    @return: Last journald message from this process as a dictionary in\n         journald JSON format.\n    """"""\n    # It may take a little for messages to actually reach journald, so we\n    # write out marker message and wait until it arrives. We can then be\n    # sure the message right before it is the one we want.\n    marker = unicode(uuid4())\n    sd_journal_send(MESSAGE=marker.encode(""ascii""))\n    for i in range(500):\n        messages = check_output(\n            [\n                b""journalctl"",\n                b""-a"",\n                b""-o"",\n                b""json"",\n                b""-n2"",\n                b""_PID="" + str(getpid()).encode(""ascii""),\n            ]\n        )\n        messages = [loads(m) for m in messages.splitlines()]\n        if len(messages) == 2 and messages[1][""MESSAGE""] == marker:\n            return messages[0]\n        sleep(0.01)\n    raise RuntimeError(""Message never arrived?!"")\n\n\nclass SdJournaldSendTests(TestCase):\n    """"""\n    Functional tests for L{sd_journal_send}.\n    """"""\n\n    @skipUnless(\n        _journald_available(), ""journald unavailable or inactive on this machine.""\n    )\n    def setUp(self):\n        pass\n\n    def assert_roundtrip(self, value):\n        """"""\n        Write a value as a C{MESSAGE} field, assert it is output.\n\n        @param value: Value to write as unicode.\n        """"""\n        sd_journal_send(MESSAGE=value)\n        result = last_journald_message()\n        self.assertEqual(value, result[""MESSAGE""].encode(""utf-8""))\n\n    def test_message(self):\n        """"""\n        L{sd_journal_send} can write a C{MESSAGE} field.\n        """"""\n        self.assert_roundtrip(b""hello"")\n\n    def test_percent(self):\n        """"""\n        L{sd_journal_send} can write a C{MESSAGE} field with a percent.\n\n        Underlying C API calls does printf formatting so this is a\n        plausible failure mode.\n        """"""\n        self.assert_roundtrip(b""hello%world"")\n\n    def test_large(self):\n        """"""\n        L{sd_journal_send} can write a C{MESSAGE} field with a large message.\n        """"""\n        self.assert_roundtrip(b""hello world"" * 20000)\n\n    def test_multiple_fields(self):\n        """"""\n        L{sd_journal_send} can send multiple fields.\n        """"""\n        sd_journal_send(MESSAGE=b""hello"", BONUS_FIELD=b""world"")\n        result = last_journald_message()\n        self.assertEqual(\n            (b""hello"", b""world""),\n            (result[""MESSAGE""].encode(""ascii""), result[""BONUS_FIELD""].encode(""ascii"")),\n        )\n\n    def test_error(self):\n        """"""\n        L{sd_journal_send} raises an error when it gets a non-0 result\n        from the underlying API.\n        """"""\n        with self.assertRaises(IOError) as context:\n            sd_journal_send(**{"""": b""123""})\n        exc = context.exception\n        self.assertEqual((exc.errno, exc.strerror), (EINVAL, strerror(EINVAL)))\n\n\nclass JournaldDestinationTests(TestCase):\n    """"""\n    Tests for L{JournaldDestination}.\n    """"""\n\n    @skipUnless(\n        _journald_available(), ""journald unavailable or inactive on this machine.""\n    )\n    def setUp(self):\n        self.destination = JournaldDestination()\n        self.logger = MemoryLogger()\n\n    def test_json(self):\n        """"""\n        The message is stored as JSON in the MESSAGE field.\n        """"""\n        Message.new(hello=""world"", key=123).write(self.logger)\n        message = self.logger.messages[0]\n        self.destination(message)\n        self.assertEqual(loads(last_journald_message()[""MESSAGE""]), message)\n\n    def assert_field_for(self, message, field_name, field_value):\n        """"""\n        If the given message is logged by Eliot, the given journald field has\n        the expected value.\n\n        @param message: Dictionary to log.\n        @param field_name: Journald field name to check.\n        @param field_value: Expected value for the field.\n        """"""\n        self.destination(message)\n        self.assertEqual(last_journald_message()[field_name], field_value)\n\n    def test_action_type(self):\n        """"""\n        The C{action_type} is stored in the ELIOT_TYPE field.\n        """"""\n        action_type = ""test:type""\n        start_action(self.logger, action_type=action_type)\n        self.assert_field_for(self.logger.messages[0], ""ELIOT_TYPE"", action_type)\n\n    def test_message_type(self):\n        """"""\n        The C{message_type} is stored in the ELIOT_TYPE field.\n        """"""\n        message_type = ""test:type:message""\n        Message.new(message_type=message_type).write(self.logger)\n        self.assert_field_for(self.logger.messages[0], ""ELIOT_TYPE"", message_type)\n\n    def test_no_type(self):\n        """"""\n        An empty string is stored in ELIOT_TYPE if no type is known.\n        """"""\n        Message.new().write(self.logger)\n        self.assert_field_for(self.logger.messages[0], ""ELIOT_TYPE"", """")\n\n    def test_uuid(self):\n        """"""\n        The task UUID is stored in the ELIOT_TASK field.\n        """"""\n        start_action(self.logger, action_type=""xxx"")\n        self.assert_field_for(\n            self.logger.messages[0],\n            ""ELIOT_TASK"",\n            self.logger.messages[0][TASK_UUID_FIELD],\n        )\n\n    def test_info_priorities(self):\n        """"""\n        Untyped messages, action start, successful action end, random typed\n        message all get priority 6 (""info"").\n        """"""\n        with start_action(self.logger, action_type=""xxx""):\n            Message.new(message_type=""msg"").write(self.logger)\n            Message.new(x=123).write(self.logger)\n        priorities = []\n        for message in self.logger.messages:\n            self.destination(message)\n            priorities.append(last_journald_message()[""PRIORITY""])\n        self.assertEqual(priorities, [""6"", ""6"", ""6"", ""6""])\n\n    def test_error_priority(self):\n        """"""\n        A failed action gets priority 3 (""error"").\n        """"""\n        try:\n            with start_action(self.logger, action_type=""xxx""):\n                raise ZeroDivisionError()\n        except ZeroDivisionError:\n            pass\n        self.assert_field_for(self.logger.messages[-1], ""PRIORITY"", ""3"")\n\n    def test_critical_priority(self):\n        """"""\n        A traceback gets priority 2 (""critical"").\n        """"""\n        try:\n            raise ZeroDivisionError()\n        except ZeroDivisionError:\n            write_traceback(logger=self.logger)\n        self.assert_field_for(self.logger.serialize()[-1], ""PRIORITY"", ""2"")\n\n    def test_identifier(self):\n        """"""\n        C{SYSLOG_IDENTIFIER} defaults to C{os.path.basename(sys.argv[0])}.\n        """"""\n        identifier = ""/usr/bin/testing123""\n        try:\n            original = argv[0]\n            argv[0] = identifier\n            # Recreate JournaldDestination with the newly set argv[0].\n            self.destination = JournaldDestination()\n            Message.new(message_type=""msg"").write(self.logger)\n            self.assert_field_for(\n                self.logger.messages[0], ""SYSLOG_IDENTIFIER"", ""testing123""\n            )\n        finally:\n            argv[0] = original\n'"
eliot/tests/test_json.py,29,"b'""""""\nTests for L{eliot.json}.\n""""""\n\nfrom __future__ import unicode_literals, absolute_import\n\nfrom unittest import TestCase, skipUnless, skipIf\nfrom json import loads, dumps\nfrom math import isnan\n\ntry:\n    import numpy as np\nexcept ImportError:\n    np = None\n\nfrom eliot.json import EliotJSONEncoder\n\n\nclass EliotJSONEncoderTests(TestCase):\n    """"""Tests for L{EliotJSONEncoder}.""""""\n\n    def test_nan_inf(self):\n        """"""NaN, inf and -inf are round-tripped.""""""\n        l = [float(""nan""), float(""inf""), float(""-inf"")]\n        roundtripped = loads(dumps(l, cls=EliotJSONEncoder))\n        self.assertEqual(l[1:], roundtripped[1:])\n        self.assertTrue(isnan(roundtripped[0]))\n\n    @skipUnless(np, ""NumPy not installed."")\n    def test_numpy(self):\n        """"""NumPy objects get serialized to readable JSON.""""""\n        l = [\n            np.float32(12.5),\n            np.float64(2.0),\n            np.float16(0.5),\n            np.bool(True),\n            np.bool(False),\n            np.bool_(True),\n            np.unicode_(""hello""),\n            np.byte(12),\n            np.short(12),\n            np.intc(-13),\n            np.int_(0),\n            np.longlong(100),\n            np.intp(7),\n            np.ubyte(12),\n            np.ushort(12),\n            np.uintc(13),\n            np.ulonglong(100),\n            np.uintp(7),\n            np.int8(1),\n            np.int16(3),\n            np.int32(4),\n            np.int64(5),\n            np.uint8(1),\n            np.uint16(3),\n            np.uint32(4),\n            np.uint64(5),\n        ]\n        l2 = [l, np.array([1, 2, 3])]\n        roundtripped = loads(dumps(l2, cls=EliotJSONEncoder))\n        self.assertEqual([l, [1, 2, 3]], roundtripped)\n\n    @skipIf(np, ""NumPy is installed."")\n    def test_numpy_not_imported(self):\n        """"""If NumPy is not available, EliotJSONEncoder continues to work.\n\n        This ensures NumPy isn\'t a hard dependency.\n        """"""\n        with self.assertRaises(TypeError):\n            dumps([object()], cls=EliotJSONEncoder)\n        self.assertEqual(dumps(12, cls=EliotJSONEncoder), ""12"")\n\n    @skipUnless(np, ""NumPy is not installed."")\n    def test_large_numpy_array(self):\n        """"""\n        Large NumPy arrays are not serialized completely, since this is (A) a\n        performance hit (B) probably a mistake on the user\'s part.\n        """"""\n        a1000 = np.array([0] * 10000)\n        self.assertEqual(loads(dumps(a1000, cls=EliotJSONEncoder)), a1000.tolist())\n        a1002 = np.zeros((2, 5001))\n        a1002[0][0] = 12\n        a1002[0][1] = 13\n        a1002[1][1] = 500\n        self.assertEqual(\n            loads(dumps(a1002, cls=EliotJSONEncoder)),\n            {""array_start"": a1002.flat[:10000].tolist(), ""original_shape"": [2, 5001]},\n        )\n'"
eliot/tests/test_logwriter.py,0,"b'""""""\nTests for L{eliot.logwriter}.\n""""""\n\nfrom __future__ import unicode_literals\n\nimport time\nimport threading\n\n# Make sure to use StringIO that only accepts unicode:\nfrom io import BytesIO, StringIO\nfrom unittest import skipIf\nimport json as pyjson\nfrom warnings import catch_warnings, simplefilter\n\nfrom six import PY2\n\ntry:\n    from zope.interface.verify import verifyClass\n    from twisted.internet import reactor\n    from twisted.trial.unittest import TestCase\n    from twisted.application.service import IService\n    from twisted.python import threadable\nexcept ImportError:\n    # Make tests not run at all.\n    TestCase = object\nelse:\n    # Make sure we always import this if Twisted is available, so broken\n    # logwriter.py causes a failure:\n    from ..logwriter import ThreadedFileWriter, ThreadedWriter\n\nfrom .. import Logger, removeDestination, FileDestination\n\n\nclass BlockingFile(object):\n    """"""\n    A file-like whose writes can be blocked.\n\n    Also, allow calling C{getvalue} after C{close}, unlike L{BytesIO}.\n    """"""\n\n    def __init__(self):\n        self.file = BytesIO()\n        self.lock = threading.Lock()\n        self.data = b""""\n\n    def block(self):\n        """"""\n        Prevent writes until L{unblock} is called.\n        """"""\n        self.lock.acquire()\n\n    def unblock(self):\n        """"""\n        Allow writes if L{block} was previous called.\n        """"""\n        self.lock.release()\n\n    def getvalue(self):\n        """"""\n        Get written bytes.\n\n        @return: Written bytes.\n        """"""\n        return self.data\n\n    def write(self, data):\n        with self.lock:\n            self.file.write(data)\n\n    def flush(self):\n        self.data = self.file.getvalue()\n\n    def close(self):\n        self.file.close()\n\n\nclass ThreadedWriterTests(TestCase):\n    """"""\n    Tests for L{ThreadedWriter}.\n\n    Many of these tests involve interactions across threads, so they\n    arbitrarily wait for up to 5 seconds to reduce chances of slow thread\n    switching causing the test to fail.\n    """"""\n\n    def test_interface(self):\n        """"""\n        L{ThreadedWriter} provides L{IService}.\n        """"""\n        verifyClass(IService, ThreadedWriter)\n\n    def test_name(self):\n        """"""\n        L{ThreadedWriter} has a name.\n        """"""\n        self.assertEqual(ThreadedWriter.name, ""Eliot Log Writer"")\n\n    def test_startServiceRunning(self):\n        """"""\n        L{ThreadedWriter.startService} starts the service as required by the\n        L{IService} interface.\n        """"""\n        writer = ThreadedWriter(FileDestination(file=BytesIO()), reactor)\n        self.assertFalse(writer.running)\n        writer.startService()\n        self.addCleanup(writer.stopService)\n        self.assertTrue(writer.running)\n\n    def test_stopServiceRunning(self):\n        """"""\n        L{ThreadedWriter.stopService} stops the service as required by the\n        L{IService} interface.\n        """"""\n        writer = ThreadedWriter(FileDestination(file=BytesIO()), reactor)\n        writer.startService()\n        d = writer.stopService()\n        d.addCallback(lambda _: self.assertFalse(writer.running))\n        return d\n\n    def test_startServiceStartsThread(self):\n        """"""\n        L{ThreadedWriter.startService} starts up a thread running\n        L{ThreadedWriter._writer}.\n        """"""\n        previousThreads = threading.enumerate()\n        result = []\n        event = threading.Event()\n\n        def _writer():\n            current = threading.currentThread()\n            if current not in previousThreads:\n                result.append(current)\n            event.set()\n\n        writer = ThreadedWriter(FileDestination(file=BytesIO()), reactor)\n        writer._writer = _writer\n        writer.startService()\n        event.wait()\n        self.assertTrue(result)\n        # Make sure thread is dead so it doesn\'t die half way through another\n        # test:\n        result[0].join(5)\n\n    def test_stopServiceStopsThread(self):\n        """"""\n        L{ThreadedWriter.stopService} stops the writer thread.\n        """"""\n        previousThreads = set(threading.enumerate())\n        writer = ThreadedWriter(FileDestination(file=BytesIO()), reactor)\n        writer.startService()\n        start = time.time()\n        while set(threading.enumerate()) == previousThreads and (\n            time.time() - start < 5\n        ):\n            time.sleep(0.0001)\n        # If not true the next assertion might pass by mistake:\n        self.assertNotEqual(set(threading.enumerate()), previousThreads)\n        writer.stopService()\n        while set(threading.enumerate()) != previousThreads and (\n            time.time() - start < 5\n        ):\n            time.sleep(0.0001)\n        self.assertEqual(set(threading.enumerate()), previousThreads)\n\n    def test_stopServiceFinishesWriting(self):\n        """"""\n        L{ThreadedWriter.stopService} stops the writer thread, but only after\n        all queued writes are written out.\n        """"""\n        f = BlockingFile()\n        writer = ThreadedWriter(FileDestination(file=f), reactor)\n        f.block()\n        writer.startService()\n        for i in range(100):\n            writer({""write"": 123})\n        threads = threading.enumerate()\n        writer.stopService()\n        # Make sure writes didn\'t happen before the stopService, thus making the\n        # test pointless:\n        self.assertEqual(f.getvalue(), b"""")\n        f.unblock()\n        start = time.time()\n        while threading.enumerate() == threads and time.time() - start < 5:\n            time.sleep(0.0001)\n        self.assertEqual(f.getvalue(), b\'{""write"": 123}\\n\' * 100)\n\n    def test_stopServiceResult(self):\n        """"""\n        L{ThreadedWriter.stopService} returns a L{Deferred} that fires only\n        after the thread has shut down.\n        """"""\n        f = BlockingFile()\n        writer = ThreadedWriter(FileDestination(file=f), reactor)\n        f.block()\n        writer.startService()\n\n        writer({""hello"": 123})\n        threads = threading.enumerate()\n        d = writer.stopService()\n        f.unblock()\n\n        def done(_):\n            self.assertEqual(f.getvalue(), b\'{""hello"": 123}\\n\')\n            self.assertNotEqual(threading.enumerate(), threads)\n\n        d.addCallback(done)\n        return d\n\n    def test_noChangeToIOThread(self):\n        """"""\n        Running a L{ThreadedWriter} doesn\'t modify the Twisted registered IO\n        thread.\n        """"""\n        writer = ThreadedWriter(FileDestination(file=BytesIO()), reactor)\n        writer.startService()\n        d = writer.stopService()\n        # Either the current thread (the one running the tests) is the the I/O\n        # thread or the I/O thread was never set. Either may happen depending on\n        # how and whether the reactor has been started by the unittesting\n        # framework.\n        d.addCallback(\n            lambda _: self.assertIn(\n                threadable.ioThread, (None, threading.currentThread().ident)\n            )\n        )\n        return d\n\n    def test_startServiceRegistersDestination(self):\n        """"""\n        L{ThreadedWriter.startService} registers itself as an Eliot log\n        destination.\n        """"""\n        f = BlockingFile()\n        writer = ThreadedWriter(FileDestination(file=f), reactor)\n        writer.startService()\n        Logger().write({""x"": ""abc""})\n        d = writer.stopService()\n        d.addCallback(lambda _: self.assertIn(b""abc"", f.getvalue()))\n        return d\n\n    def test_stopServiceUnregistersDestination(self):\n        """"""\n        L{ThreadedWriter.stopService} unregisters itself as an Eliot log\n        destination.\n        """"""\n        writer = ThreadedWriter(FileDestination(file=BytesIO()), reactor)\n        writer.startService()\n        d = writer.stopService()\n        d.addCallback(lambda _: removeDestination(writer))\n        return self.assertFailure(d, ValueError)\n\n    def test_call(self):\n        """"""\n        The message passed to L{ThreadedWriter.__call__} is passed to the\n        underlying destination in the writer thread.\n        """"""\n        result = []\n\n        def destination(message):\n            result.append((message, threading.currentThread().ident))\n\n        writer = ThreadedWriter(destination, reactor)\n        writer.startService()\n        thread_ident = writer._thread.ident\n        msg = {""key"": 123}\n        writer(msg)\n        d = writer.stopService()\n        d.addCallback(lambda _: self.assertEqual(result, [(msg, thread_ident)]))\n        return d\n\n\nclass ThreadedFileWriterTests(TestCase):\n    """"""\n    Tests for ``ThreadedFileWriter``.\n    """"""\n\n    def test_deprecation_warning(self):\n        """"""\n        Instantiating ``ThreadedFileWriter`` gives a ``DeprecationWarning``.\n        """"""\n        with catch_warnings(record=True) as warnings:\n            ThreadedFileWriter(BytesIO(), reactor)\n            simplefilter(""always"")  # Catch all warnings\n            self.assertEqual(warnings[-1].category, DeprecationWarning)\n\n    def test_write(self):\n        """"""\n        Messages passed to L{ThreadedFileWriter.__call__} are then written by\n        the writer thread with a newline added.\n        """"""\n        f = BytesIO()\n        writer = ThreadedFileWriter(f, reactor)\n        writer.startService()\n        self.addCleanup(writer.stopService)\n\n        writer({""hello"": 123})\n        start = time.time()\n        while not f.getvalue() and time.time() - start < 5:\n            time.sleep(0.0001)\n        self.assertEqual(f.getvalue(), b\'{""hello"": 123}\\n\')\n\n    @skipIf(PY2, ""Python 2 files always accept bytes"")\n    def test_write_unicode(self):\n        """"""\n        Messages passed to L{ThreadedFileWriter.__call__} are then written by\n        the writer thread with a newline added to files that accept\n        unicode.\n        """"""\n        f = StringIO()\n        writer = ThreadedFileWriter(f, reactor)\n        writer.startService()\n        self.addCleanup(writer.stopService)\n\n        original = {""hello\\u1234"": 123}\n        writer(original)\n        start = time.time()\n        while not f.getvalue() and time.time() - start < 5:\n            time.sleep(0.0001)\n        self.assertEqual(f.getvalue(), pyjson.dumps(original) + ""\\n"")\n\n    def test_stopServiceClosesFile(self):\n        """"""\n        L{ThreadedWriter.stopService} closes the file.\n        """"""\n        f = BytesIO()\n        writer = ThreadedFileWriter(f, reactor)\n        writer.startService()\n        d = writer.stopService()\n\n        def done(_):\n            self.assertTrue(f.closed)\n\n        d.addCallback(done)\n        return d\n'"
eliot/tests/test_message.py,0,"b'""""""\nTests for L{eliot._message}.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom unittest import TestCase\nfrom uuid import UUID\nimport time\n\nfrom pyrsistent import pmap\n\ntry:\n    from twisted.python.failure import Failure\nexcept ImportError:\n    Failure = None\n\nfrom .._message import WrittenMessage, Message, log_message\nfrom .._output import MemoryLogger\nfrom .._action import Action, start_action, TaskLevel\nfrom .. import add_destinations, remove_destination\n\n\nclass DeprecatedMessageTests(TestCase):\n    """"""\n    Test for L{Message}.\n    """"""\n\n    def test_new(self):\n        """"""\n        L{Message.new} returns a new L{Message} that is initialized with the\n        given keyword arguments as its contents, and a default message type.\n        """"""\n        msg = Message.new(key=""value"", another=2)\n        self.assertEqual(msg.contents(), {""key"": ""value"", ""another"": 2})\n\n    def test_contentsCopies(self):\n        """"""\n        L{Message.contents} returns a copy of the L{Message} contents.\n        """"""\n        msg = Message.new(key=""value"")\n        del msg.contents()[""key""]\n        self.assertEqual(msg.contents(), {""key"": ""value""})\n\n    def test_bindOverwrites(self):\n        """"""\n        L{Message.bind} returns a new L{Message} whose contents include the\n        additional given fields.\n        """"""\n        msg = Message.new(key=""value"", another=2)\n        another = msg.bind(another=3, more=4)\n        self.assertIsInstance(another, Message)\n        self.assertEqual(another.contents(), {""key"": ""value"", ""another"": 3, ""more"": 4})\n\n    def test_bindPreservesOriginal(self):\n        """"""\n        L{Message.bind} does not mutate the instance it is called on.\n        """"""\n        msg = Message.new(key=4)\n        msg.bind(key=6)\n        self.assertEqual(msg.contents(), {""key"": 4})\n\n    def test_writeCallsLoggerWrite(self):\n        """"""\n        L{Message.write} calls the given logger\'s C{write} method with a\n        dictionary that is superset of the L{Message} contents.\n        """"""\n        logger = MemoryLogger()\n        msg = Message.new(key=4)\n        msg.write(logger)\n        self.assertEqual(len(logger.messages), 1)\n        self.assertEqual(logger.messages[0][""key""], 4)\n\n    def test_writeDefaultLogger(self):\n        """"""\n        L{Message.write} writes to the default logger if none is given.\n        """"""\n        messages = []\n        add_destinations(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n        Message.new(some_key=1234).write()\n        self.assertEqual(messages[0][""some_key""], 1234)\n\n    def test_writeCreatesNewDictionary(self):\n        """"""\n        L{Message.write} creates a new dictionary on each call.\n\n        This is important because we mutate the dictionary in\n        ``Logger.write``, so we want to make sure the ``Message`` is unchanged\n        in that case. In general we want ``Message`` objects to be effectively\n        immutable.\n        """"""\n\n        class Logger(list):\n            def write(self, d, serializer):\n                self.append(d)\n\n        logger = Logger()\n        msg = Message.new(key=4)\n        msg.write(logger)\n        logger[0][""key""] = 5\n        msg.write(logger)\n        self.assertEqual(logger[1][""key""], 4)\n\n    def test_logCallsDefaultLoggerWrite(self):\n        """"""\n        L{Message.log} calls the default logger\'s C{write} method with a\n        dictionary that is superset of the L{Message} contents.\n        """"""\n        messages = []\n        add_destinations(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n        Message.log(some_key=1234)\n        self.assertEqual(messages[0][""some_key""], 1234)\n\n    def test_defaultTime(self):\n        """"""\n        L{Message._time} returns L{time.time} by default.\n        """"""\n        msg = Message({})\n        self.assertIs(msg._time, time.time)\n\n    def test_writeAddsTimestamp(self):\n        """"""\n        L{Message.write} adds a C{""timestamp""} field to the dictionary written\n        to the logger, with the current time in seconds since the epoch.\n        """"""\n        logger = MemoryLogger()\n        msg = Message.new(key=4)\n        msg.write(logger)\n        self.assertTrue(time.time() - logger.messages[0][""timestamp""] < 0.1)\n\n    def test_write_preserves_message_type(self):\n        """"""\n        L{Message.write} doesn\'t add a C{message_type} if one is already set.\n        """"""\n        logger = MemoryLogger()\n        msg = Message.new(key=4, message_type=""isetit"")\n        msg.write(logger)\n        self.assertEqual(logger.messages[0][""message_type""], ""isetit"")\n        self.assertNotIn(""action_type"", logger.messages[0])\n\n    def test_explicitAction(self):\n        """"""\n        L{Message.write} adds the identification fields from the given\n        L{Action} to the dictionary written to the logger, as well as a\n        message_type if none is set.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""unique"", TaskLevel(level=[]), ""sys:thename"")\n        msg = Message.new(key=2)\n        msg.write(logger, action)\n        written = logger.messages[0]\n        del written[""timestamp""]\n        self.assertEqual(\n            written,\n            {""task_uuid"": ""unique"", ""task_level"": [1], ""key"": 2, ""message_type"": """"},\n        )\n\n    def test_implicitAction(self):\n        """"""\n        If no L{Action} is specified, L{Message.write} adds the identification\n        fields from the current execution context\'s L{Action} to the\n        dictionary written to the logger.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""unique"", TaskLevel(level=[]), ""sys:thename"")\n        msg = Message.new(key=2)\n        with action:\n            msg.write(logger)\n        written = logger.messages[0]\n        del written[""timestamp""]\n        self.assertEqual(\n            written,\n            {""task_uuid"": ""unique"", ""task_level"": [1], ""key"": 2, ""message_type"": """"},\n        )\n\n    def test_missingAction(self):\n        """"""\n        If no L{Action} is specified, and the current execution context has no\n        L{Action}, a new task_uuid is generated.\n\n        This ensures all messages have a unique identity, as specified by\n        task_uuid/task_level.\n        """"""\n        logger = MemoryLogger()\n        Message.new(key=2).write(logger)\n        Message.new(key=3).write(logger)\n\n        message1, message2 = logger.messages\n        self.assertEqual(\n            (\n                UUID(message1[""task_uuid""]) != UUID(message2[""task_uuid""]),\n                message1[""task_level""],\n                message2[""task_level""],\n            ),\n            (True, [1], [1]),\n        )\n\n    def test_actionCounter(self):\n        """"""\n        Each message written within the context of an L{Action} gets its\n        C{task_level} field incremented.\n        """"""\n        logger = MemoryLogger()\n        msg = Message.new(key=2)\n        with start_action(logger, ""sys:thename""):\n            for i in range(4):\n                msg.write(logger)\n        # We expect 6 messages: start action, 4 standalone messages, finish\n        # action:\n        self.assertEqual(\n            [m[""task_level""] for m in logger.messages], [[1], [2], [3], [4], [5], [6]]\n        )\n\n    def test_writePassesSerializer(self):\n        """"""\n        If a L{Message} is created with a serializer, it is passed as a second\n        argument to the logger when C{write} is called.\n        """"""\n\n        class ListLogger(list):\n            def write(self, dictionary, serializer):\n                self.append(serializer)\n\n        logger = ListLogger()\n        serializer = object()\n        msg = Message({}, serializer)\n        msg.write(logger)\n        self.assertIs(logger[0], serializer)\n\n    def test_serializerPassedInBind(self):\n        """"""\n        The L{Message} returned by L{Message.bind} includes the serializer\n        passed to the parent.\n        """"""\n        serializer = object()\n        msg = Message({}, serializer)\n        msg2 = msg.bind(x=1)\n        self.assertIs(msg2._serializer, serializer)\n\n    def test_newWithSerializer(self):\n        """"""\n        L{Message.new} can accept a serializer.\n        """"""\n        serializer = object()\n        msg = Message.new(serializer, x=1)\n        self.assertIs(msg._serializer, serializer)\n\n\nclass WrittenMessageTests(TestCase):\n    """"""\n    Tests for L{WrittenMessage}.\n    """"""\n\n    def test_as_dict(self):\n        """"""\n        L{WrittenMessage.as_dict} returns the dictionary that will be serialized\n        to the log.\n        """"""\n        log_entry = pmap(\n            {""timestamp"": 1, ""task_uuid"": ""unique"", ""task_level"": [1], ""foo"": ""bar""}\n        )\n        self.assertEqual(WrittenMessage.from_dict(log_entry).as_dict(), log_entry)\n\n    def test_from_dict(self):\n        """"""\n        L{WrittenMessage.from_dict} converts a dictionary that has been\n        deserialized from a log into a L{WrittenMessage} object.\n        """"""\n        log_entry = pmap(\n            {""timestamp"": 1, ""task_uuid"": ""unique"", ""task_level"": [1], ""foo"": ""bar""}\n        )\n        parsed = WrittenMessage.from_dict(log_entry)\n        self.assertEqual(parsed.timestamp, 1)\n        self.assertEqual(parsed.task_uuid, ""unique"")\n        self.assertEqual(parsed.task_level, TaskLevel(level=[1]))\n        self.assertEqual(parsed.contents, pmap({""foo"": ""bar""}))\n\n\nclass LogMessageTests(TestCase):\n    """"""Tests for L{log_message}.""""""\n\n    def test_writes_message(self):\n        """"""\n        L{log_message} writes to the default logger.\n        """"""\n        messages = []\n        add_destinations(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n        log_message(message_type=""hello"", some_key=1234)\n        self.assertEqual(messages[0][""some_key""], 1234)\n        self.assertEqual(messages[0][""message_type""], ""hello"")\n        self.assertTrue(time.time() - messages[0][""timestamp""] < 0.1)\n\n    def test_implicitAction(self):\n        """"""\n        If no L{Action} is specified, L{log_message} adds the identification\n        fields from the current execution context\'s L{Action} to the\n        dictionary written to the logger.\n        """"""\n        logger = MemoryLogger()\n        action = Action(logger, ""unique"", TaskLevel(level=[]), ""sys:thename"")\n        with action:\n            log_message(key=2, message_type=""a"")\n        written = logger.messages[0]\n        del written[""timestamp""]\n        self.assertEqual(\n            written,\n            {""task_uuid"": ""unique"", ""task_level"": [1], ""key"": 2, ""message_type"": ""a""},\n        )\n\n    def test_missingAction(self):\n        """"""\n        If no L{Action} is specified, and the current execution context has no\n        L{Action}, a new task_uuid is generated.\n\n        This ensures all messages have a unique identity, as specified by\n        task_uuid/task_level.\n        """"""\n        messages = []\n        add_destinations(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n\n        log_message(key=2, message_type="""")\n        log_message(key=3, message_type="""")\n\n        message1, message2 = messages\n        self.assertEqual(\n            (\n                UUID(message1[""task_uuid""]) != UUID(message2[""task_uuid""]),\n                message1[""task_level""],\n                message2[""task_level""],\n            ),\n            (True, [1], [1]),\n        )\n'"
eliot/tests/test_output.py,1,"b'""""""\nTests for L{eliot._output}.\n""""""\n\nfrom sys import stdout\nfrom unittest import TestCase, skipUnless\n\n# Make sure to use StringIO that only accepts unicode:\nfrom io import BytesIO, StringIO\nimport json as pyjson\nfrom tempfile import mktemp\nfrom time import time\nfrom uuid import UUID\nfrom threading import Thread\n\ntry:\n    import numpy as np\nexcept ImportError:\n    np = None\nfrom zope.interface.verify import verifyClass\n\nfrom .._output import (\n    MemoryLogger,\n    ILogger,\n    Destinations,\n    Logger,\n    bytesjson as json,\n    to_file,\n    FileDestination,\n    _DestinationsSendError,\n)\nfrom .._validation import ValidationError, Field, _MessageSerializer\nfrom .._traceback import write_traceback\nfrom ..testing import assertContainsFields\n\n\nclass MemoryLoggerTests(TestCase):\n    """"""\n    Tests for L{MemoryLogger}.\n    """"""\n\n    def test_interface(self):\n        """"""\n        L{MemoryLogger} implements L{ILogger}.\n        """"""\n        verifyClass(ILogger, MemoryLogger)\n\n    def test_write(self):\n        """"""\n        Dictionaries written with L{MemoryLogger.write} are stored on a list.\n        """"""\n        logger = MemoryLogger()\n        logger.write({""a"": ""b""})\n        logger.write({""c"": 1})\n        self.assertEqual(logger.messages, [{""a"": ""b""}, {""c"": 1}])\n        logger.validate()\n\n    def test_notStringFieldKeys(self):\n        """"""\n        Field keys must be unicode or bytes; if not L{MemoryLogger.validate}\n        raises a C{TypeError}.\n        """"""\n        logger = MemoryLogger()\n        logger.write({123: ""b""})\n        self.assertRaises(TypeError, logger.validate)\n\n    def test_bytesMustBeUTF8(self):\n        """"""\n        Field keys can be bytes, but only if they\'re UTF-8 encoded Unicode.\n        """"""\n        logger = MemoryLogger()\n        logger.write({""\\u1234"".encode(""utf-16""): ""b""})\n        self.assertRaises(UnicodeDecodeError, logger.validate)\n\n    def test_serializer(self):\n        """"""\n        L{MemoryLogger.validate} calls the given serializer\'s C{validate()}\n        method with the message, as does L{MemoryLogger.write}.\n        """"""\n\n        class FakeValidator(list):\n            def validate(self, message):\n                self.append(message)\n\n            def serialize(self, obj):\n                return obj\n\n        validator = FakeValidator()\n        logger = MemoryLogger()\n        message = {""message_type"": ""mymessage"", ""X"": 1}\n        logger.write(message, validator)\n        self.assertEqual(validator, [message])\n        logger.validate()\n        self.assertEqual(validator, [message, message])\n\n    def test_failedValidation(self):\n        """"""\n        L{MemoryLogger.validate} will allow exceptions raised by the serializer\n        to pass through.\n        """"""\n        serializer = _MessageSerializer(\n            [Field.forValue(""message_type"", ""mymessage"", ""The type"")]\n        )\n        logger = MemoryLogger()\n        logger.write({""message_type"": ""wrongtype""}, serializer)\n        self.assertRaises(ValidationError, logger.validate)\n\n    def test_JSON(self):\n        """"""\n        L{MemoryLogger.validate} will encode the output of serialization to\n        JSON.\n        """"""\n        serializer = _MessageSerializer(\n            [\n                Field.forValue(""message_type"", ""type"", ""The type""),\n                Field(""foo"", lambda value: object(), ""The type""),\n            ]\n        )\n        logger = MemoryLogger()\n        logger.write(\n            {""message_type"": ""type"", ""foo"": ""will become object()""}, serializer\n        )\n        self.assertRaises(TypeError, logger.validate)\n\n    def test_serialize(self):\n        """"""\n        L{MemoryLogger.serialize} returns a list of serialized versions of the\n        logged messages.\n        """"""\n        serializer = _MessageSerializer(\n            [\n                Field.forValue(""message_type"", ""mymessage"", ""The type""),\n                Field(""length"", len, ""The length""),\n            ]\n        )\n        messages = [\n            {""message_type"": ""mymessage"", ""length"": ""abc""},\n            {""message_type"": ""mymessage"", ""length"": ""abcd""},\n        ]\n        logger = MemoryLogger()\n        for message in messages:\n            logger.write(message, serializer)\n        self.assertEqual(\n            logger.serialize(),\n            [\n                {""message_type"": ""mymessage"", ""length"": 3},\n                {""message_type"": ""mymessage"", ""length"": 4},\n            ],\n        )\n\n    def test_serializeCopies(self):\n        """"""\n        L{MemoryLogger.serialize} does not mutate the original logged messages.\n        """"""\n        serializer = _MessageSerializer(\n            [\n                Field.forValue(""message_type"", ""mymessage"", ""The type""),\n                Field(""length"", len, ""The length""),\n            ]\n        )\n        message = {""message_type"": ""mymessage"", ""length"": ""abc""}\n        logger = MemoryLogger()\n        logger.write(message, serializer)\n        logger.serialize()\n        self.assertEqual(logger.messages[0][""length""], ""abc"")\n\n    def write_traceback(self, logger, exception):\n        """"""\n        Write an exception as a traceback to the logger.\n        """"""\n        try:\n            raise exception\n        except:\n            write_traceback(logger)\n\n    def test_tracebacksCauseTestFailure(self):\n        """"""\n        Logging a traceback to L{MemoryLogger} will add its exception to\n        L{MemoryLogger.tracebackMessages}.\n        """"""\n        logger = MemoryLogger()\n        exception = Exception()\n        self.write_traceback(logger, exception)\n        self.assertEqual(logger.tracebackMessages[0][""reason""], exception)\n\n    def test_flushTracebacksNoTestFailure(self):\n        """"""\n        Any tracebacks cleared by L{MemoryLogger.flushTracebacks} (as specified\n        by exception type) are removed from\n        L{MemoryLogger.tracebackMessages}.\n        """"""\n        logger = MemoryLogger()\n        exception = RuntimeError()\n        self.write_traceback(logger, exception)\n        logger.flushTracebacks(RuntimeError)\n        self.assertEqual(logger.tracebackMessages, [])\n\n    def test_flushTracebacksReturnsExceptions(self):\n        """"""\n        L{MemoryLogger.flushTracebacks} returns the traceback messages.\n        """"""\n        exceptions = [ZeroDivisionError(), ZeroDivisionError()]\n        logger = MemoryLogger()\n        logger.write({""x"": 1})\n        for exc in exceptions:\n            self.write_traceback(logger, exc)\n        logger.write({""x"": 1})\n        flushed = logger.flushTracebacks(ZeroDivisionError)\n        self.assertEqual(flushed, logger.messages[1:3])\n\n    def test_flushTracebacksUnflushedTestFailure(self):\n        """"""\n        Any tracebacks uncleared by L{MemoryLogger.flushTracebacks} (because\n        they are of a different type) are still listed in\n        L{MemoryLogger.tracebackMessages}.\n        """"""\n        logger = MemoryLogger()\n        exception = RuntimeError()\n        self.write_traceback(logger, exception)\n        logger.flushTracebacks(KeyError)\n        self.assertEqual(logger.tracebackMessages[0][""reason""], exception)\n\n    def test_flushTracebacksUnflushedUnreturned(self):\n        """"""\n        Any tracebacks uncleared by L{MemoryLogger.flushTracebacks} (because\n        they are of a different type) are not returned.\n        """"""\n        logger = MemoryLogger()\n        exception = RuntimeError()\n        self.write_traceback(logger, exception)\n        self.assertEqual(logger.flushTracebacks(KeyError), [])\n\n    def test_reset(self):\n        """"""\n        L{MemoryLogger.reset} clears all logged messages and tracebacks.\n        """"""\n        logger = MemoryLogger()\n        logger.write({""key"": ""value""}, None)\n        logger.reset()\n        self.assertEqual(\n            (logger.messages, logger.serializers, logger.tracebackMessages),\n            ([], [], []),\n        )\n\n    def test_threadSafeWrite(self):\n        """"""\n        L{MemoryLogger.write} can be called from multiple threads concurrently.\n        """"""\n        # Some threads will log some messages\n        thread_count = 10\n\n        # A lot of messages.  This will keep the threads running long enough\n        # to give them a chance to (try to) interfere with each other.\n        write_count = 10000\n\n        # They\'ll all use the same MemoryLogger instance.\n        logger = MemoryLogger()\n\n        # Each thread will have its own message and serializer that it writes\n        # to the log over and over again.\n        def write(msg, serializer):\n            for i in range(write_count):\n                logger.write(msg, serializer)\n\n        # Generate a single distinct message for each thread to log.\n        msgs = list({""i"": i} for i in range(thread_count))\n\n        # Generate a single distinct serializer for each thread to log.\n        serializers = list(object() for i in range(thread_count))\n\n        # Pair them all up.  This gives us a simple invariant we can check\n        # later on.\n        write_args = zip(msgs, serializers)\n\n        # Create the threads.\n        threads = list(Thread(target=write, args=args) for args in write_args)\n\n        # Run them all.  Note threads early in this list will start writing to\n        # the log before later threads in the list even get a chance to start.\n        # That\'s part of why we have each thread write so many messages.\n        for t in threads:\n            t.start()\n        # Wait for them all to finish.\n        for t in threads:\n            t.join()\n\n        # Check that we got the correct number of messages in the log.\n        expected_count = thread_count * write_count\n        self.assertEqual(len(logger.messages), expected_count)\n        self.assertEqual(len(logger.serializers), expected_count)\n\n        # Check the simple invariant we created above.  Every logged message\n        # must be paired with the correct serializer, where ""correct"" is\n        # defined by ``write_args`` above.\n        for position, (msg, serializer) in enumerate(\n            zip(logger.messages, logger.serializers)\n        ):\n            # The indexes must match because the objects are paired using\n            # zip() above.\n            msg_index = msgs.index(msg)\n            serializer_index = serializers.index(serializer)\n            self.assertEqual(\n                msg_index,\n                serializer_index,\n                ""Found message #{} with serializer #{} at position {}"".format(\n                    msg_index, serializer_index, position\n                ),\n            )\n\n\nclass MyException(Exception):\n    """"""\n    Custom exception.\n    """"""\n\n\nclass BadDestination(list):\n    """"""\n    A destination that throws an exception the first time it is called.\n    """"""\n\n    called = 0\n\n    def __call__(self, msg):\n        if not self.called:\n            self.called = True\n            raise MyException(""ono"")\n        self.append(msg)\n\n\nclass DestinationsTests(TestCase):\n    """"""\n    Tests for L{Destinations}.\n    """"""\n\n    def test_send(self):\n        """"""\n        L{Destinations.send} calls all destinations added with\n        L{Destinations.add} with the given dictionary.\n        """"""\n        destinations = Destinations()\n        message = {""hoorj"": ""blargh""}\n        dest = []\n        dest2 = []\n        dest3 = []\n        destinations.add(dest.append, dest2.append)\n        destinations.add(dest3.append)\n        destinations.send(message)\n        self.assertEqual(dest, [message])\n        self.assertEqual(dest2, [message])\n        self.assertEqual(dest3, [message])\n\n    def test_destinationExceptionMultipleDestinations(self):\n        """"""\n        If one destination throws an exception, other destinations still\n        get the message.\n        """"""\n        destinations = Destinations()\n        dest = []\n        dest2 = BadDestination()\n        dest3 = []\n        destinations.add(dest.append)\n        destinations.add(dest2)\n        destinations.add(dest3.append)\n\n        message = {""hello"": 123}\n        self.assertRaises(_DestinationsSendError, destinations.send, {""hello"": 123})\n        self.assertEqual((dest, dest3), ([message], [message]))\n\n    def test_destinationExceptionContinue(self):\n        """"""\n        If a destination throws an exception, future messages are still\n        sent to it.\n        """"""\n        destinations = Destinations()\n        dest = BadDestination()\n        destinations.add(dest)\n\n        self.assertRaises(_DestinationsSendError, destinations.send, {""hello"": 123})\n        destinations.send({""hello"": 200})\n        self.assertEqual(dest, [{""hello"": 200}])\n\n    def test_remove(self):\n        """"""\n        A destination removed with L{Destinations.remove} will no longer\n        receive messages from L{Destionations.add} calls.\n        """"""\n        destinations = Destinations()\n        message = {""hello"": 123}\n        dest = []\n        destinations.add(dest.append)\n        destinations.remove(dest.append)\n        destinations.send(message)\n        self.assertEqual(dest, [])\n\n    def test_removeNonExistent(self):\n        """"""\n        Removing a destination that has not previously been added with result\n        in a C{ValueError} being thrown.\n        """"""\n        destinations = Destinations()\n        self.assertRaises(ValueError, destinations.remove, [].append)\n\n    def test_addGlobalFields(self):\n        """"""\n        L{Destinations.addGlobalFields} adds the given fields and values to\n        the messages being passed in.\n        """"""\n        destinations = Destinations()\n        dest = []\n        destinations.add(dest.append)\n        destinations.addGlobalFields(x=123, y=""hello"")\n        destinations.send({""z"": 456})\n        self.assertEqual(dest, [{""x"": 123, ""y"": ""hello"", ""z"": 456}])\n\n    def test_addGlobalFieldsCumulative(self):\n        """"""\n        L{Destinations.addGlobalFields} adds the given fields to those set by\n        previous calls.\n        """"""\n        destinations = Destinations()\n        dest = []\n        destinations.add(dest.append)\n        destinations.addGlobalFields(x=123, y=""hello"")\n        destinations.addGlobalFields(x=456, z=456)\n        destinations.send({""msg"": ""X""})\n        self.assertEqual(dest, [{""x"": 456, ""y"": ""hello"", ""z"": 456, ""msg"": ""X""}])\n\n    def test_buffering(self):\n        """"""\n        Before any destinations are set up to 1000 messages are buffered, and\n        then delivered to the first registered destinations.\n        """"""\n        destinations = Destinations()\n        messages = [{""k"": i} for i in range(1050)]\n        for m in messages:\n            destinations.send(m)\n        dest, dest2 = [], []\n        destinations.add(dest.append, dest2.append)\n        self.assertEqual((dest, dest2), (messages[-1000:], messages[-1000:]))\n\n    def test_buffering_second_batch(self):\n        """"""\n        The second batch of added destination don\'t get the buffered messages.\n        """"""\n        destinations = Destinations()\n        message = {""m"": 1}\n        message2 = {""m"": 2}\n        destinations.send(message)\n        dest = []\n        dest2 = []\n        destinations.add(dest.append)\n        destinations.add(dest2.append)\n        destinations.send(message2)\n        self.assertEqual((dest, dest2), ([message, message2], [message2]))\n\n    def test_global_fields_buffering(self):\n        """"""\n        Global fields are added to buffered messages, when possible.\n        """"""\n        destinations = Destinations()\n        message = {""m"": 1}\n        destinations.send(message)\n        destinations.addGlobalFields(k=123)\n        dest = []\n        destinations.add(dest.append)\n        self.assertEqual(dest, [{""m"": 1, ""k"": 123}])\n\n\ndef makeLogger():\n    """"""\n    Return a tuple (L{Logger} instance, C{list} of written messages).\n    """"""\n    logger = Logger()\n    logger._destinations = Destinations()\n    written = []\n    logger._destinations.add(written.append)\n    return logger, written\n\n\nclass LoggerTests(TestCase):\n    """"""\n    Tests for L{Logger}.\n    """"""\n\n    def test_interface(self):\n        """"""\n        L{Logger} implements L{ILogger}.\n        """"""\n        verifyClass(ILogger, Logger)\n\n    def test_global(self):\n        """"""\n        A global L{Destinations} is used by the L{Logger} class.\n        """"""\n        self.assertIsInstance(Logger._destinations, Destinations)\n\n    def test_write(self):\n        """"""\n        L{Logger.write} sends the given dictionary L{Destinations} object.\n        """"""\n        logger, written = makeLogger()\n\n        d = {""hello"": 1}\n        logger.write(d)\n        self.assertEqual(written, [d])\n\n    def test_serializer(self):\n        """"""\n        If a L{_MessageSerializer} is passed to L{Logger.write}, it is used to\n        serialize the message before it is passed to the destination.\n        """"""\n        logger, written = makeLogger()\n\n        serializer = _MessageSerializer(\n            [\n                Field.forValue(""message_type"", ""mymessage"", ""The type""),\n                Field(""length"", len, ""The length of a thing""),\n            ]\n        )\n        logger.write({""message_type"": ""mymessage"", ""length"": ""thething""}, serializer)\n        self.assertEqual(written, [{""message_type"": ""mymessage"", ""length"": 8}])\n\n    def test_passedInDictionaryUnmodified(self):\n        """"""\n        The dictionary passed in to L{Logger.write} is not modified.\n        """"""\n        logger, written = makeLogger()\n\n        serializer = _MessageSerializer(\n            [\n                Field.forValue(""message_type"", ""mymessage"", ""The type""),\n                Field(""length"", len, ""The length of a thing""),\n            ]\n        )\n        d = {""message_type"": ""mymessage"", ""length"": ""thething""}\n        original = d.copy()\n        logger.write(d, serializer)\n        self.assertEqual(d, original)\n\n    def test_safeUnicodeDictionary(self):\n        """"""\n        L{Logger._safeUnicodeDictionary} converts the given dictionary\'s\n        values and keys to unicode using C{safeunicode}.\n        """"""\n\n        class badobject(object):\n            def __repr__(self):\n                raise TypeError()\n\n        dictionary = {badobject(): 123, 123: badobject()}\n        badMessage = ""eliot: unknown, unicode() raised exception""\n        self.assertEqual(\n            eval(Logger()._safeUnicodeDictionary(dictionary)),\n            {badMessage: ""123"", ""123"": badMessage},\n        )\n\n    def test_safeUnicodeDictionaryFallback(self):\n        """"""\n        If converting the dictionary failed for some reason,\n        L{Logger._safeUnicodeDictionary} runs C{repr} on the object.\n        """"""\n        self.assertEqual(Logger()._safeUnicodeDictionary(None), ""None"")\n\n    def test_safeUnicodeDictionaryFallbackFailure(self):\n        """"""\n        If all else fails, L{Logger._safeUnicodeDictionary} just gives up.\n        """"""\n\n        class badobject(object):\n            def __repr__(self):\n                raise TypeError()\n\n        self.assertEqual(\n            Logger()._safeUnicodeDictionary(badobject()),\n            ""eliot: unknown, unicode() raised exception"",\n        )\n\n    def test_serializationErrorTraceback(self):\n        """"""\n        If serialization fails in L{Logger.write}, a traceback is logged,\n        along with a C{eliot:serialization_failure} message for debugging\n        purposes.\n        """"""\n        logger, written = makeLogger()\n\n        def raiser(i):\n            raise RuntimeError(""oops"")\n\n        serializer = _MessageSerializer(\n            [\n                Field.forValue(""message_type"", ""mymessage"", ""The type""),\n                Field(""fail"", raiser, ""Serialization fail""),\n            ]\n        )\n        message = {""message_type"": ""mymessage"", ""fail"": ""will""}\n        logger.write(message, serializer)\n        self.assertEqual(len(written), 2)\n        tracebackMessage = written[0]\n        assertContainsFields(\n            self,\n            tracebackMessage,\n            {\n                ""exception"": ""%s.RuntimeError"" % (RuntimeError.__module__,),\n                ""message_type"": ""eliot:traceback"",\n            },\n        )\n        self.assertIn(""RuntimeError: oops"", tracebackMessage[""traceback""])\n        # Calling _safeUnicodeDictionary multiple times leads to\n        # inconsistent results due to hash ordering, so compare contents:\n        assertContainsFields(\n            self, written[1], {""message_type"": ""eliot:serialization_failure""}\n        )\n        self.assertEqual(\n            eval(written[1][""message""]),\n            dict((repr(key), repr(value)) for (key, value) in message.items()),\n        )\n\n    def test_destinationExceptionCaught(self):\n        """"""\n        If a destination throws an exception, an appropriate error is\n        logged.\n        """"""\n        logger = Logger()\n        logger._destinations = Destinations()\n        dest = BadDestination()\n        logger._destinations.add(dest)\n\n        message = {""hello"": 123}\n        logger.write({""hello"": 123})\n        assertContainsFields(\n            self,\n            dest[0],\n            {\n                ""message_type"": ""eliot:destination_failure"",\n                ""message"": logger._safeUnicodeDictionary(message),\n                ""reason"": ""ono"",\n                ""exception"": ""eliot.tests.test_output.MyException"",\n            },\n        )\n\n    def test_destinationMultipleExceptionsCaught(self):\n        """"""\n        If multiple destinations throw an exception, an appropriate error is\n        logged for each.\n        """"""\n        logger = Logger()\n        logger._destinations = Destinations()\n        logger._destinations.add(BadDestination())\n        logger._destinations.add(lambda msg: 1 / 0)\n        messages = []\n        logger._destinations.add(messages.append)\n\n        try:\n            1 / 0\n        except ZeroDivisionError as e:\n            zero_divide = str(e)\n        zero_type = ZeroDivisionError.__module__ + "".ZeroDivisionError""\n\n        message = {""hello"": 123}\n        logger.write({""hello"": 123})\n\n        def remove(key):\n            return [message.pop(key) for message in messages[1:]]\n\n        # Make sure we have task_level & task_uuid in exception messages.\n        task_levels = remove(""task_level"")\n        task_uuids = remove(""task_uuid"")\n        timestamps = remove(""timestamp"")\n\n        self.assertEqual(\n            (\n                abs(timestamps[0] + timestamps[1] - 2 * time()) < 1,\n                task_levels == [[1], [1]],\n                len([UUID(uuid) for uuid in task_uuids]) == 2,\n                messages,\n            ),\n            (\n                True,\n                True,\n                True,\n                [\n                    message,\n                    {\n                        ""message_type"": ""eliot:destination_failure"",\n                        ""message"": logger._safeUnicodeDictionary(message),\n                        ""reason"": ""ono"",\n                        ""exception"": ""eliot.tests.test_output.MyException"",\n                    },\n                    {\n                        ""message_type"": ""eliot:destination_failure"",\n                        ""message"": logger._safeUnicodeDictionary(message),\n                        ""reason"": zero_divide,\n                        ""exception"": zero_type,\n                    },\n                ],\n            ),\n        )\n\n    def test_destinationExceptionCaughtTwice(self):\n        """"""\n        If a destination throws an exception, and the logged error about\n        it also causes an exception, then just drop that exception on the\n        floor, since there\'s nothing we can do with it.\n        """"""\n        logger = Logger()\n        logger._destinations = Destinations()\n\n        def always_raise(message):\n            raise ZeroDivisionError()\n\n        logger._destinations.add(always_raise)\n\n        # No exception raised; since everything is dropped no other\n        # assertions to be made.\n        logger.write({""hello"": 123})\n\n\nclass PEP8Tests(TestCase):\n    """"""\n    Tests for PEP 8 method compatibility.\n    """"""\n\n    def test_flush_tracebacks(self):\n        """"""\n        L{MemoryLogger.flush_tracebacks} is the same as\n        L{MemoryLogger.flushTracebacks}\n        """"""\n        self.assertEqual(MemoryLogger.flush_tracebacks, MemoryLogger.flushTracebacks)\n\n\nclass ToFileTests(TestCase):\n    """"""\n    Tests for L{to_file}.\n    """"""\n\n    def test_to_file_adds_destination(self):\n        """"""\n        L{to_file} adds a L{FileDestination} destination with the given file.\n        """"""\n        f = stdout\n        to_file(f)\n        expected = FileDestination(file=f)\n        self.addCleanup(Logger._destinations.remove, expected)\n        self.assertIn(expected, Logger._destinations._destinations)\n\n    def test_to_file_custom_encoder(self):\n        """"""\n        L{to_file} accepts a custom encoder, and sets it on the resulting\n        L{FileDestination}.\n        """"""\n        f = stdout\n        encoder = object()\n        to_file(f, encoder=encoder)\n        expected = FileDestination(file=f, encoder=encoder)\n        self.addCleanup(Logger._destinations.remove, expected)\n        self.assertIn(expected, Logger._destinations._destinations)\n\n    def test_bytes_values(self):\n        """"""\n        DEPRECATED: On Python 3L{FileDestination} will encode bytes as if they were\n        UTF-8 encoded strings when writing to BytesIO only.\n        """"""\n        message = {""x"": b""abc""}\n        bytes_f = BytesIO()\n        destination = FileDestination(file=bytes_f)\n        destination(message)\n        self.assertEqual(\n            [json.loads(line) for line in bytes_f.getvalue().splitlines()],\n            [{""x"": ""abc""}],\n        )\n\n    @skipUnless(np, ""NumPy is not installed."")\n    def test_default_encoder_is_EliotJSONEncoder(self):\n        """"""The default encoder if none are specified is EliotJSONEncoder.""""""\n        message = {""x"": np.int64(3)}\n        f = StringIO()\n        destination = FileDestination(file=f)\n        destination(message)\n        self.assertEqual(\n            [json.loads(line) for line in f.getvalue().splitlines()], [{""x"": 3}]\n        )\n\n    def test_filedestination_writes_json_bytes(self):\n        """"""\n        L{FileDestination} writes JSON-encoded messages to a file that accepts\n        bytes.\n        """"""\n        message1 = {""x"": 123}\n        message2 = {""y"": None, ""x"": ""abc""}\n        bytes_f = BytesIO()\n        destination = FileDestination(file=bytes_f)\n        destination(message1)\n        destination(message2)\n        self.assertEqual(\n            [json.loads(line) for line in bytes_f.getvalue().splitlines()],\n            [message1, message2],\n        )\n\n    def test_filedestination_custom_encoder(self):\n        """"""\n        L{FileDestionation} can use a custom encoder.\n        """"""\n        custom = object()\n\n        class CustomEncoder(pyjson.JSONEncoder):\n            def default(self, o):\n                if o is custom:\n                    return ""CUSTOM!""\n                else:\n                    return pyjson.JSONEncoder.default(self, o)\n\n        message = {""x"": 123, ""z"": custom}\n        f = BytesIO()\n        destination = FileDestination(file=f, encoder=CustomEncoder)\n        destination(message)\n        self.assertEqual(\n            json.loads(f.getvalue().splitlines()[0]), {""x"": 123, ""z"": ""CUSTOM!""}\n        )\n\n    def test_filedestination_flushes(self):\n        """"""\n        L{FileDestination} flushes after every write, to ensure logs get\n        written out even if the local buffer hasn\'t filled up.\n        """"""\n        path = mktemp()\n        # File with large buffer:\n        f = open(path, ""wb"", 1024 * 1024 * 10)\n        # and a small message that won\'t fill the buffer:\n        message1 = {""x"": 123}\n\n        destination = FileDestination(file=f)\n        destination(message1)\n\n        # Message got written even though buffer wasn\'t filled:\n        self.assertEqual(\n            [json.loads(line) for line in open(path, ""rb"").read().splitlines()],\n            [message1],\n        )\n\n    def test_filedestination_writes_json_unicode(self):\n        """"""\n        L{FileDestination} writes JSON-encoded messages to file that only\n        accepts Unicode.\n        """"""\n        message = {""x"": ""\\u1234""}\n        unicode_f = StringIO()\n        destination = FileDestination(file=unicode_f)\n        destination(message)\n        self.assertEqual(pyjson.loads(unicode_f.getvalue()), message)\n\n    def test_filedestination_unwriteable_file(self):\n        """"""\n        L{FileDestination} raises a runtime error if the given file isn\'t writeable.\n        """"""\n        path = mktemp()\n        open(path, ""w"").close()\n        f = open(path, ""r"")\n        with self.assertRaises(RuntimeError):\n            FileDestination(f)\n'"
eliot/tests/test_parse.py,0,"b'""""""\nTests for L{eliot._parse}.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom unittest import TestCase\nfrom itertools import chain\n\nfrom six import text_type as unicode, assertCountEqual\nfrom six.moves import zip_longest\n\nfrom hypothesis import strategies as st, given, assume\n\nfrom pyrsistent import PClass, field, pvector_field\n\nfrom .. import start_action, Message\nfrom ..testing import MemoryLogger\nfrom ..parse import Task, Parser\nfrom .._message import (\n    WrittenMessage,\n    MESSAGE_TYPE_FIELD,\n    TASK_LEVEL_FIELD,\n    TASK_UUID_FIELD,\n)\nfrom .._action import FAILED_STATUS, ACTION_STATUS_FIELD, WrittenAction\nfrom .strategies import labels\n\n\nclass ActionStructure(PClass):\n    """"""\n    A tree structure used to generate/compare to Eliot trees.\n\n    Individual messages are encoded as a unicode string; actions are\n    encoded as a L{ActionStructure} instance.\n    """"""\n\n    type = field(type=(unicode, None.__class__))\n    children = pvector_field(object)  # XXX (""StubAction"", unicode))\n    failed = field(type=bool)\n\n    @classmethod\n    def from_written(cls, written):\n        """"""\n        Create an L{ActionStructure} or L{unicode} from a L{WrittenAction} or\n        L{WrittenMessage}.\n        """"""\n        if isinstance(written, WrittenMessage):\n            return written.as_dict()[MESSAGE_TYPE_FIELD]\n        else:  # WrittenAction\n            if not written.end_message:\n                raise AssertionError(""Missing end message."")\n            return cls(\n                type=written.action_type,\n                failed=(\n                    written.end_message.contents[ACTION_STATUS_FIELD] == FAILED_STATUS\n                ),\n                children=[cls.from_written(o) for o in written.children],\n            )\n\n    @classmethod\n    def to_eliot(cls, structure_or_message, logger):\n        """"""\n        Given a L{ActionStructure} or L{unicode}, generate appropriate\n        structured Eliot log mesages to given L{MemoryLogger}.\n        """"""\n        if isinstance(structure_or_message, cls):\n            action = structure_or_message\n            try:\n                with start_action(logger, action_type=action.type):\n                    for child in action.children:\n                        cls.to_eliot(child, logger)\n                    if structure_or_message.failed:\n                        raise RuntimeError(""Make the eliot action fail."")\n            except RuntimeError:\n                pass\n        else:\n            Message.new(message_type=structure_or_message).write(logger)\n        return logger.messages\n\n\n@st.composite\ndef action_structures(draw):\n    """"""\n    A Hypothesis strategy that creates a tree of L{ActionStructure} and\n    L{unicode}.\n    """"""\n    tree = draw(st.recursive(labels, st.lists, max_leaves=20))\n\n    def to_structure(tree_or_message):\n        if isinstance(tree_or_message, list):\n            return ActionStructure(\n                type=draw(labels),\n                failed=draw(st.booleans()),\n                children=[to_structure(o) for o in tree_or_message],\n            )\n        else:\n            return tree_or_message\n\n    return to_structure(tree)\n\n\ndef _structure_and_messages(structure):\n    messages = ActionStructure.to_eliot(structure, MemoryLogger())\n    return st.permutations(messages).map(lambda permuted: (structure, permuted))\n\n\n# Hypothesis strategy that creates a tuple of ActionStructure/unicode and\n# corresponding serialized Eliot messages, randomly shuffled.\nSTRUCTURES_WITH_MESSAGES = action_structures().flatmap(_structure_and_messages)\n\n\ndef parse_to_task(messages):\n    """"""\n    Feed a set of messages to a L{Task}.\n\n    @param messages: Sequence of messages dictionaries to parse.\n\n    @return: Resulting L{Task}.\n    """"""\n    task = Task()\n    for message in messages:\n        task = task.add(message)\n    return task\n\n\nclass TaskTests(TestCase):\n    """"""\n    Tests for L{Task}.\n    """"""\n\n    @given(structure_and_messages=STRUCTURES_WITH_MESSAGES)\n    def test_missing_action(self, structure_and_messages):\n        """"""\n        If we parse messages (in shuffled order) but a start message is\n        missing then the structure is still deduced correctly from the\n        remaining messages.\n        """"""\n        action_structure, messages = structure_and_messages\n        assume(not isinstance(action_structure, unicode))\n\n        # Remove first start message we encounter; since messages are\n        # shuffled the location removed will differ over Hypothesis test\n        # iterations:\n        messages = messages[:]\n        for i, message in enumerate(messages):\n            if message[TASK_LEVEL_FIELD][-1] == 1:  # start message\n                del messages[i]\n                break\n\n        task = parse_to_task(messages)\n        parsed_structure = ActionStructure.from_written(task.root())\n\n        # We expect the action with missing start message to otherwise\n        # be parsed correctly:\n        self.assertEqual(parsed_structure, action_structure)\n\n    @given(structure_and_messages=STRUCTURES_WITH_MESSAGES)\n    def test_parse_from_random_order(self, structure_and_messages):\n        """"""\n        If we shuffle messages and parse them the parser builds a tree of\n        actions that is the same as the one used to generate the messages.\n\n        Shuffled messages means we have to deal with (temporarily) missing\n        information sufficiently well to be able to parse correctly once\n        the missing information arrives.\n        """"""\n        action_structure, messages = structure_and_messages\n\n        task = Task()\n        for message in messages:\n            task = task.add(message)\n\n        # Assert parsed structure matches input structure:\n        parsed_structure = ActionStructure.from_written(task.root())\n        self.assertEqual(parsed_structure, action_structure)\n\n    @given(structure_and_messages=STRUCTURES_WITH_MESSAGES)\n    def test_is_complete(self, structure_and_messages):\n        """"""\n        ``Task.is_complete()`` only returns true when all messages within the\n        tree have been delivered.\n        """"""\n        action_structure, messages = structure_and_messages\n\n        task = Task()\n        completed = []\n        for message in messages:\n            task = task.add(message)\n            completed.append(task.is_complete())\n\n        self.assertEqual(completed, [False for m in messages[:-1]] + [True])\n\n    def test_parse_contents(self):\n        """"""\n        L{{Task.add}} parses the contents of the messages it receives.\n        """"""\n        logger = MemoryLogger()\n        with start_action(logger, action_type=""xxx"", y=123) as ctx:\n            Message.new(message_type=""zzz"", z=4).write(logger)\n            ctx.add_success_fields(foo=[1, 2])\n        messages = logger.messages\n        expected = WrittenAction.from_messages(\n            WrittenMessage.from_dict(messages[0]),\n            [WrittenMessage.from_dict(messages[1])],\n            WrittenMessage.from_dict(messages[2]),\n        )\n\n        task = parse_to_task(messages)\n        self.assertEqual(task.root(), expected)\n\n\nclass ParserTests(TestCase):\n    """"""\n    Tests for L{Parser}.\n    """"""\n\n    @given(\n        structure_and_messages1=STRUCTURES_WITH_MESSAGES,\n        structure_and_messages2=STRUCTURES_WITH_MESSAGES,\n        structure_and_messages3=STRUCTURES_WITH_MESSAGES,\n    )\n    def test_parse_into_tasks(\n        self, structure_and_messages1, structure_and_messages2, structure_and_messages3\n    ):\n        """"""\n        Adding messages to a L{Parser} parses them into a L{Task} instances.\n        """"""\n        _, messages1 = structure_and_messages1\n        _, messages2 = structure_and_messages2\n        _, messages3 = structure_and_messages3\n        all_messages = (messages1, messages2, messages3)\n        # Need unique UUIDs per task:\n        assume(len(set(m[0][TASK_UUID_FIELD] for m in all_messages)) == 3)\n\n        parser = Parser()\n        all_tasks = []\n        for message in chain(*zip_longest(*all_messages)):\n            if message is not None:\n                completed_tasks, parser = parser.add(message)\n                all_tasks.extend(completed_tasks)\n\n        assertCountEqual(\n            self, all_tasks, [parse_to_task(msgs) for msgs in all_messages]\n        )\n\n    @given(structure_and_messages=STRUCTURES_WITH_MESSAGES)\n    def test_incomplete_tasks(self, structure_and_messages):\n        """"""\n        Until a L{Task} is fully parsed, it is returned in\n        L{Parser.incomplete_tasks}.\n        """"""\n        _, messages = structure_and_messages\n        parser = Parser()\n        task = Task()\n        incomplete_matches = []\n        for message in messages[:-1]:\n            _, parser = parser.add(message)\n            task = task.add(message)\n            incomplete_matches.append(parser.incomplete_tasks() == [task])\n\n        task = task.add(messages[-1])\n        _, parser = parser.add(messages[-1])\n        self.assertEqual(\n            dict(\n                incomplete_matches=incomplete_matches,\n                final_incompleted=parser.incomplete_tasks(),\n            ),\n            dict(incomplete_matches=[True] * (len(messages) - 1), final_incompleted=[]),\n        )\n\n    @given(\n        structure_and_messages1=STRUCTURES_WITH_MESSAGES,\n        structure_and_messages2=STRUCTURES_WITH_MESSAGES,\n        structure_and_messages3=STRUCTURES_WITH_MESSAGES,\n    )\n    def test_parse_stream(\n        self, structure_and_messages1, structure_and_messages2, structure_and_messages3\n    ):\n        """"""\n        L{Parser.parse_stream} returns an iterable of completed and then\n        incompleted tasks.\n        """"""\n        _, messages1 = structure_and_messages1\n        _, messages2 = structure_and_messages2\n        _, messages3 = structure_and_messages3\n        # Need at least one non-dropped message in partial tree:\n        assume(len(messages3) > 1)\n        # Need unique UUIDs per task:\n        assume(\n            len(set(m[0][TASK_UUID_FIELD] for m in (messages1, messages2, messages3)))\n            == 3\n        )\n\n        # Two complete tasks, one incomplete task:\n        all_messages = (messages1, messages2, messages3[:-1])\n\n        all_tasks = list(\n            Parser.parse_stream(\n                [m for m in chain(*zip_longest(*all_messages)) if m is not None]\n            )\n        )\n        assertCountEqual(\n            self, all_tasks, [parse_to_task(msgs) for msgs in all_messages]\n        )\n\n\nclass BackwardsCompatibility(TestCase):\n    """"""Tests for backwards compatibility.""""""\n\n    def test_imports(self):\n        """"""Old ways of importing still work.""""""\n        import eliot._parse\n        from eliot import _parse\n        import eliot.parse\n\n        self.assertIs(eliot.parse, eliot._parse)\n        self.assertIs(_parse, eliot.parse)\n'"
eliot/tests/test_prettyprint.py,0,"b'""""""\nTests for C{eliot.prettyprint}.\n""""""\n\nfrom unittest import TestCase\nfrom subprocess import check_output, Popen, PIPE\nfrom collections import OrderedDict\nfrom datetime import datetime\n\nfrom pyrsistent import pmap\n\nfrom .._bytesjson import dumps\nfrom ..prettyprint import pretty_format, compact_format, REQUIRED_FIELDS\n\nSIMPLE_MESSAGE = {\n    ""timestamp"": 1443193754,\n    ""task_uuid"": ""8c668cde-235b-4872-af4e-caea524bd1c0"",\n    ""message_type"": ""messagey"",\n    ""task_level"": [1, 2],\n    ""keys"": [123, 456],\n}\n\nUNTYPED_MESSAGE = {\n    ""timestamp"": 1443193754,\n    ""task_uuid"": ""8c668cde-235b-4872-af4e-caea524bd1c0"",\n    ""task_level"": [1],\n    ""key"": 1234,\n    ""abc"": ""def"",\n}\n\n\nclass FormattingTests(TestCase):\n    """"""\n    Tests for L{pretty_format}.\n    """"""\n\n    def test_message(self):\n        """"""\n        A typed message is printed as expected.\n        """"""\n        self.assertEqual(\n            pretty_format(SIMPLE_MESSAGE),\n            """"""\\\n8c668cde-235b-4872-af4e-caea524bd1c0 -> /1/2\n2015-09-25T15:09:14Z\n  message_type: \'messagey\'\n  keys: [123, 456]\n"""""",\n        )\n\n    def test_untyped_message(self):\n        """"""\n        A message with no type is printed as expected.\n        """"""\n        self.assertEqual(\n            pretty_format(UNTYPED_MESSAGE),\n            """"""\\\n8c668cde-235b-4872-af4e-caea524bd1c0 -> /1\n2015-09-25T15:09:14Z\n  abc: \'def\'\n  key: 1234\n"""""",\n        )\n\n    def test_action(self):\n        """"""\n        An action message is printed as expected.\n        """"""\n        message = {\n            ""task_uuid"": ""8bc6ded2-446c-4b6d-abbc-4f21f1c9a7d8"",\n            ""place"": ""Statue #1"",\n            ""task_level"": [2, 2, 2, 1],\n            ""action_type"": ""visited"",\n            ""timestamp"": 1443193958.0,\n            ""action_status"": ""started"",\n        }\n        self.assertEqual(\n            pretty_format(message),\n            """"""\\\n8bc6ded2-446c-4b6d-abbc-4f21f1c9a7d8 -> /2/2/2/1\n2015-09-25T15:12:38Z\n  action_type: \'visited\'\n  action_status: \'started\'\n  place: \'Statue #1\'\n"""""",\n        )\n\n    def test_multi_line(self):\n        """"""\n        Multiple line values are indented nicely.\n        """"""\n        message = {\n            ""timestamp"": 1443193754,\n            ""task_uuid"": ""8c668cde-235b-4872-af4e-caea524bd1c0"",\n            ""task_level"": [1],\n            ""key"": ""hello\\nthere\\nmonkeys!\\n"",\n            ""more"": ""stuff"",\n        }\n        self.assertEqual(\n            pretty_format(message),\n            """"""\\\n8c668cde-235b-4872-af4e-caea524bd1c0 -> /1\n2015-09-25T15:09:14Z\n  key: \'hello\n     |  there\n     |  monkeys!\n     |  \'\n  more: \'stuff\'\n"""""",\n        )\n\n    def test_tabs(self):\n        """"""\n        Tabs are formatted as tabs, not quoted.\n        """"""\n        message = {\n            ""timestamp"": 1443193754,\n            ""task_uuid"": ""8c668cde-235b-4872-af4e-caea524bd1c0"",\n            ""task_level"": [1],\n            ""key"": ""hello\\tmonkeys!"",\n        }\n        self.assertEqual(\n            pretty_format(message),\n            """"""\\\n8c668cde-235b-4872-af4e-caea524bd1c0 -> /1\n2015-09-25T15:09:14Z\n  key: \'hello\tmonkeys!\'\n"""""",\n        )\n\n    def test_structured(self):\n        """"""\n        Structured field values (e.g. a dictionary) are formatted in a helpful\n        manner.\n        """"""\n        message = {\n            ""timestamp"": 1443193754,\n            ""task_uuid"": ""8c668cde-235b-4872-af4e-caea524bd1c0"",\n            ""task_level"": [1],\n            ""key"": {""value"": 123, ""another"": [1, 2, {""more"": ""data""}]},\n        }\n        self.assertEqual(\n            pretty_format(message),\n            """"""\\\n8c668cde-235b-4872-af4e-caea524bd1c0 -> /1\n2015-09-25T15:09:14Z\n  key: {\'another\': [1, 2, {\'more\': \'data\'}],\n     |  \'value\': 123}\n"""""",\n        )\n\n    def test_microsecond(self):\n        """"""\n        Microsecond timestamps are rendered in the output.\n        """"""\n        message = {\n            ""timestamp"": 1443193754.123455,\n            ""task_uuid"": ""8c668cde-235b-4872-af4e-caea524bd1c0"",\n            ""task_level"": [1],\n        }\n        self.assertEqual(\n            pretty_format(message),\n            """"""\\\n8c668cde-235b-4872-af4e-caea524bd1c0 -> /1\n2015-09-25T15:09:14.123455Z\n"""""",\n        )\n\n    def test_compact(self):\n        """"""\n        The compact mode does everything on a single line, including\n        dictionaries and multi-line messages.\n        """"""\n        message = {\n            ""timestamp"": 1443193754,\n            ""task_uuid"": ""8c668cde-235b-4872-af4e-caea524bd1c0"",\n            ""task_level"": [1],\n            ""key"": OrderedDict([(""value"", 123), (""another"", [1, 2, {""more"": ""data""}])]),\n            ""multiline"": ""hello\\n\\tthere!\\nabc"",\n        }\n        self.assertEqual(\n            compact_format(message),\n            r\'8c668cde-235b-4872-af4e-caea524bd1c0/1 2015-09-25T15:09:14Z key={""value"":123,""another"":[1,2,{""more"":""data""}]} multiline=""hello\\n\\tthere!\\nabc""\',\n        )\n\n    def test_local(self):\n        """"""\n        Timestamps can be generated in local timezone.\n        """"""\n        message = {\n            ""timestamp"": 1443193754,\n            ""task_uuid"": ""8c668cde-235b-4872-af4e-caea524bd1c0"",\n            ""task_level"": [1],\n        }\n        expected = datetime.fromtimestamp(1443193754).isoformat(sep=""T"")\n        self.assertIn(expected, pretty_format(message, True))\n        self.assertIn(expected, compact_format(message, True))\n\n\nclass CommandLineTests(TestCase):\n    """"""\n    Tests for the command-line tool.\n    """"""\n\n    def test_help(self):\n        """"""\n        C{--help} prints out the help text and exits.\n        """"""\n        result = check_output([""eliot-prettyprint"", ""--help""])\n        self.assertIn(b""Convert Eliot messages into more readable"", result)\n\n    def write_and_read(self, lines, extra_args=()):\n        """"""\n        Write the given lines to the command-line on stdin, return stdout.\n\n        @param lines: Sequences of lines to write, as bytes, and lacking\n            new lines.\n        @return: Unicode-decoded result of subprocess stdout.\n        """"""\n        process = Popen(\n            [b""eliot-prettyprint""] + list(extra_args), stdin=PIPE, stdout=PIPE\n        )\n        process.stdin.write(b"""".join(line + b""\\n"" for line in lines))\n        process.stdin.close()\n        result = process.stdout.read().decode(""utf-8"")\n        process.stdout.close()\n        return result\n\n    def test_output(self):\n        """"""\n        Lacking command-line arguments the process reads JSON lines from stdin\n        and writes out a pretty-printed version.\n        """"""\n        messages = [SIMPLE_MESSAGE, UNTYPED_MESSAGE, SIMPLE_MESSAGE]\n        stdout = self.write_and_read(map(dumps, messages))\n        self.assertEqual(\n            stdout, """".join(pretty_format(message) + ""\\n"" for message in messages)\n        )\n\n    def test_compact_output(self):\n        """"""\n        In compact mode, the process reads JSON lines from stdin and writes out\n        a pretty-printed compact version.\n        """"""\n        messages = [SIMPLE_MESSAGE, UNTYPED_MESSAGE, SIMPLE_MESSAGE]\n        stdout = self.write_and_read(map(dumps, messages), [b""--compact""])\n        self.assertEqual(\n            stdout, """".join(compact_format(message) + ""\\n"" for message in messages)\n        )\n\n    def test_local_timezone(self):\n        """"""\n        Local timezones are used if --local-timezone is given.\n        """"""\n        message = {\n            ""timestamp"": 1443193754,\n            ""task_uuid"": ""8c668cde-235b-4872-af4e-caea524bd1c0"",\n            ""task_level"": [1],\n        }\n        expected = datetime.fromtimestamp(1443193754).isoformat(sep=""T"")\n        stdout = self.write_and_read(\n            [dumps(message)], [b""--compact"", b""--local-timezone""]\n        )\n        self.assertIn(expected, stdout)\n        stdout = self.write_and_read(\n            [dumps(message)], [b""--compact"", b""--local-timezone""]\n        )\n        self.assertIn(expected, stdout)\n\n    def test_not_json_message(self):\n        """"""\n        Non-JSON lines are not formatted.\n        """"""\n        not_json = b""NOT JSON!!""\n        lines = [dumps(SIMPLE_MESSAGE), not_json, dumps(UNTYPED_MESSAGE)]\n        stdout = self.write_and_read(lines)\n        self.assertEqual(\n            stdout,\n            ""{}\\nNot JSON: {}\\n\\n{}\\n"".format(\n                pretty_format(SIMPLE_MESSAGE),\n                str(not_json),\n                pretty_format(UNTYPED_MESSAGE),\n            ),\n        )\n\n    def test_missing_required_field(self):\n        """"""\n        Non-Eliot JSON messages are not formatted.\n        """"""\n        base = pmap(SIMPLE_MESSAGE)\n        messages = [dumps(dict(base.remove(field))) for field in REQUIRED_FIELDS] + [\n            dumps(SIMPLE_MESSAGE)\n        ]\n        stdout = self.write_and_read(messages)\n        self.assertEqual(\n            stdout,\n            ""{}{}\\n"".format(\n                """".join(\n                    ""Not an Eliot message: {}\\n\\n"".format(msg) for msg in messages[:-1]\n                ),\n                pretty_format(SIMPLE_MESSAGE),\n            ),\n        )\n'"
eliot/tests/test_pyinstaller.py,0,"b'""""""Test for pyinstaller compatibility.""""""\n\nfrom __future__ import absolute_import\n\nfrom unittest import TestCase, SkipTest\nfrom tempfile import mkdtemp, NamedTemporaryFile\nfrom subprocess import check_call, CalledProcessError\nimport os\n\nfrom six import PY2\n\nif PY2:\n    FileNotFoundError = OSError\n\n\nclass PyInstallerTests(TestCase):\n    """"""Make sure PyInstaller doesn\'t break Eliot.""""""\n\n    def setUp(self):\n        try:\n            check_call([""pyinstaller"", ""--help""])\n        except (CalledProcessError, FileNotFoundError):\n            raise SkipTest(""Can\'t find pyinstaller."")\n\n    def test_importable(self):\n        """"""The Eliot package can be imported inside a PyInstaller packaged binary.""""""\n        output_dir = mkdtemp()\n        with NamedTemporaryFile(mode=""w"") as f:\n            f.write(""import eliot; import eliot.prettyprint\\n"")\n            f.flush()\n            check_call(\n                [\n                    ""pyinstaller"",\n                    ""--distpath"",\n                    output_dir,\n                    ""-F"",\n                    ""-n"",\n                    ""importeliot"",\n                    f.name,\n                ]\n            )\n        check_call([os.path.join(output_dir, ""importeliot"")])\n'"
eliot/tests/test_serializers.py,0,"b'""""""\nTests for L{eliot.serializers}.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom unittest import TestCase\nfrom datetime import datetime\nfrom hashlib import md5\n\nfrom ..serializers import timestamp, identity, md5hex\n\n\nclass SerializerTests(TestCase):\n    """"""\n    Tests for standard serializers.\n    """"""\n\n    def test_timestamp(self):\n        """"""\n        L{timestamp} converts a UTC L{datetime} to a Unicode strings.\n        """"""\n        dt = datetime(2012, 9, 28, 14, 53, 6, 123456)\n        self.assertEqual(timestamp(dt), ""2012-09-28T14:53:06.123456Z"")\n\n    def test_identity(self):\n        """"""\n        L{identity} returns the input object.\n        """"""\n        obj = object()\n        self.assertIs(identity(obj), obj)\n\n    def test_md5hex(self):\n        """"""\n        L{md5hex} returns the hex value of a MD5 checksum.\n        """"""\n        data = b""01234456789""\n        self.assertEqual(md5hex(data), md5(data).hexdigest())\n'"
eliot/tests/test_stdlib.py,0,"b'""""""Tests for standard library logging integration.""""""\n\nfrom unittest import TestCase\nimport logging\nimport traceback\n\nfrom ..testing import assertContainsFields, capture_logging\nfrom ..stdlib import EliotHandler\nfrom .test_traceback import assert_expected_traceback\n\n\nclass StdlibTests(TestCase):\n    """"""Tests for stdlib integration.""""""\n\n    @capture_logging(None)\n    def test_handler(self, logger):\n        """"""The EliotHandler routes messages to Eliot.""""""\n        stdlib_logger = logging.getLogger(""eliot-test"")\n        stdlib_logger.setLevel(logging.DEBUG)\n        handler = EliotHandler()\n        stdlib_logger.addHandler(handler)\n        stdlib_logger.info(""hello"")\n        stdlib_logger.warning(""ono"")\n        message = logger.messages[0]\n        assertContainsFields(\n            self,\n            message,\n            {\n                ""message_type"": ""eliot:stdlib"",\n                ""log_level"": ""INFO"",\n                ""message"": ""hello"",\n                ""logger"": ""eliot-test"",\n            },\n        )\n        message = logger.messages[1]\n        assertContainsFields(\n            self,\n            message,\n            {\n                ""message_type"": ""eliot:stdlib"",\n                ""log_level"": ""WARNING"",\n                ""message"": ""ono"",\n                ""logger"": ""eliot-test"",\n            },\n        )\n\n    @capture_logging(None)\n    def test_traceback(self, logger):\n        """"""The EliotHandler routes tracebacks to Eliot.""""""\n        stdlib_logger = logging.getLogger(""eliot-test2"")\n        stdlib_logger.setLevel(logging.DEBUG)\n        handler = EliotHandler()\n        stdlib_logger.addHandler(handler)\n        try:\n            raise RuntimeError()\n        except Exception as e:\n            exception = e\n            expected_traceback = traceback.format_exc()\n            stdlib_logger.exception(""ono"")\n        message = logger.messages[0]\n        assertContainsFields(\n            self,\n            message,\n            {\n                ""message_type"": ""eliot:stdlib"",\n                ""log_level"": ""ERROR"",\n                ""message"": ""ono"",\n                ""logger"": ""eliot-test2"",\n            },\n        )\n        assert_expected_traceback(\n            self, logger, logger.messages[1], exception, expected_traceback\n        )\n'"
eliot/tests/test_tai64n.py,0,"b'""""""\nTests for L{eliot.tai64n}.\n""""""\n\nfrom __future__ import unicode_literals\n\nimport errno\nimport time\nimport subprocess\nfrom unittest import TestCase, SkipTest\n\nfrom ..tai64n import encode, decode\n\n\nclass CodecTests(TestCase):\n    """"""\n    Tests for L{encode} and L{decode}.\n    """"""\n\n    def test_encode(self):\n        """"""\n        L{encode} encodes timestamps in TAI64N format.\n        """"""\n        t = 1387299889.153187625\n        self.assertEqual(encode(t), ""@4000000052b0843b092174b9"")\n\n    def test_decode(self):\n        """"""\n        L{decode} decodes timestamps from TAI64N format.\n        """"""\n        t = time.time()\n        self.assertAlmostEqual(t, decode(encode(t)), 9)\n\n\nclass FunctionalTests(TestCase):\n    """"""\n    Functional tests for L{encode}.\n    """"""\n\n    def test_encode(self):\n        """"""\n        The daemontools tai64nlocal tool can correctly decode timestamps output\n        by L{encode}.\n        """"""\n        try:\n            process = subprocess.Popen(\n                [""tai64nlocal""],\n                bufsize=4096,\n                stdin=subprocess.PIPE,\n                stdout=subprocess.PIPE,\n            )\n        except OSError as e:\n            if e.errno == errno.ENOENT:\n                raise SkipTest(""This test requires the daemontools package"")\n            else:\n                raise\n        # Because of limitations of the time libraries tai64nlocal uses we\n        # apparently can\'t verify beyond this level of accuracy.\n        timestamp = int(time.time()) + 0.12345\n        process.stdin.write((encode(timestamp) + ""\\n"").encode(""ascii""))\n        process.stdin.close()\n        decodedToLocalTime = process.stdout.read().strip()\n        self.assertEqual(\n            time.strftime(""%Y-%m-%d %H:%M:%S.12345"", time.localtime(timestamp)).encode(\n                ""ascii""\n            ),\n            decodedToLocalTime[:25],\n        )\n'"
eliot/tests/test_testing.py,0,"b'""""""\nTests for L{eliot.testing}.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom unittest import SkipTest, TestResult, TestCase\n\nfrom ..testing import (\n    issuperset,\n    assertContainsFields,\n    LoggedAction,\n    LoggedMessage,\n    validateLogging,\n    UnflushedTracebacks,\n    assertHasMessage,\n    assertHasAction,\n    validate_logging,\n    capture_logging,\n    swap_logger,\n    check_for_errors,\n)\nfrom .._output import MemoryLogger\nfrom .._action import start_action\nfrom .._message import Message\nfrom .._validation import ActionType, MessageType, ValidationError, Field\nfrom .._traceback import write_traceback\nfrom .. import add_destination, remove_destination, _output\n\n\nclass IsSuperSetTests(TestCase):\n    """"""\n    Tests for L{issuperset}.\n    """"""\n\n    def test_equal(self):\n        """"""\n        Equal dictionaries are supersets of each other.\n        """"""\n        a = {""a"": 1}\n        b = a.copy()\n        self.assertTrue(issuperset(a, b))\n\n    def test_additionalIsSuperSet(self):\n        """"""\n        If C{A} is C{B} plus some extra entries, C{A} is superset of C{B}.\n        """"""\n        a = {""a"": 1, ""b"": 2, ""c"": 3}\n        b = {""a"": 1, ""c"": 3}\n        self.assertTrue(issuperset(a, b))\n\n    def test_missingIsNotSuperSet(self):\n        """"""\n        If C{A} is C{B} minus some entries, C{A} is not a superset of C{B}.\n        """"""\n        a = {""a"": 1, ""c"": 3}\n        b = {""a"": 1, ""b"": 2, ""c"": 3}\n        self.assertFalse(issuperset(a, b))\n\n\nclass LoggedActionTests(TestCase):\n    """"""\n    Tests for L{LoggedAction}.\n    """"""\n\n    def test_values(self):\n        """"""\n        The values given to the L{LoggedAction} constructor are stored on it.\n        """"""\n        d1 = {""x"": 1}\n        d2 = {""y"": 2}\n        root = LoggedAction(d1, d2, [])\n        self.assertEqual((root.startMessage, root.endMessage), (d1, d2))\n\n    def fromMessagesIndex(self, messages, index):\n        """"""\n        Call L{LoggedAction.fromMessages} using action specified by index in\n        a list of message dictionaries.\n\n        @param messages: A C{list} of message dictionaries.\n\n        @param index: Index to the logger\'s messages.\n\n        @return: Result of L{LoggedAction.fromMessages}.\n        """"""\n        uuid = messages[index][""task_uuid""]\n        level = messages[index][""task_level""]\n        return LoggedAction.fromMessages(uuid, level, messages)\n\n    def test_fromMessagesCreatesLoggedAction(self):\n        """"""\n        L{LoggedAction.fromMessages} returns a L{LoggedAction}.\n        """"""\n        logger = MemoryLogger()\n        with start_action(logger, ""test""):\n            pass\n        logged = self.fromMessagesIndex(logger.messages, 0)\n        self.assertIsInstance(logged, LoggedAction)\n\n    def test_fromMessagesStartAndSuccessfulFinish(self):\n        """"""\n        L{LoggedAction.fromMessages} finds the start and successful finish\n        messages of an action and stores them in the result.\n        """"""\n        logger = MemoryLogger()\n        Message.new(x=1).write(logger)\n        with start_action(logger, ""test""):\n            Message.new(x=1).write(logger)\n        # Now we should have x message, start action message, another x message\n        # and finally finish message.\n        logged = self.fromMessagesIndex(logger.messages, 1)\n        self.assertEqual(\n            (logged.startMessage, logged.endMessage),\n            (logger.messages[1], logger.messages[3]),\n        )\n\n    def test_fromMessagesStartAndErrorFinish(self):\n        """"""\n        L{LoggedAction.fromMessages} finds the start and successful finish\n        messages of an action and stores them in the result.\n        """"""\n        logger = MemoryLogger()\n        try:\n            with start_action(logger, ""test""):\n                raise KeyError()\n        except KeyError:\n            pass\n        logged = self.fromMessagesIndex(logger.messages, 0)\n        self.assertEqual(\n            (logged.startMessage, logged.endMessage),\n            (logger.messages[0], logger.messages[1]),\n        )\n\n    def test_fromMessagesStartNotFound(self):\n        """"""\n        L{LoggedAction.fromMessages} raises a L{ValueError} if a start message\n        is not found.\n        """"""\n        logger = MemoryLogger()\n        with start_action(logger, action_type=""test""):\n            pass\n        self.assertRaises(ValueError, self.fromMessagesIndex, logger.messages[1:], 0)\n\n    def test_fromMessagesFinishNotFound(self):\n        """"""\n        L{LoggedAction.fromMessages} raises a L{ValueError} if a finish message\n        is not found.\n        """"""\n        logger = MemoryLogger()\n        with start_action(logger, action_type=""test""):\n            pass\n        with self.assertRaises(ValueError) as cm:\n            self.fromMessagesIndex(logger.messages[:1], 0)\n        self.assertEqual(cm.exception.args[0], ""Missing end message of type test"")\n\n    def test_fromMessagesAddsChildMessages(self):\n        """"""\n        L{LoggedAction.fromMessages} adds direct child messages to the\n        constructed L{LoggedAction}.\n        """"""\n        logger = MemoryLogger()\n        # index 0:\n        Message.new(x=1).write(logger)\n        # index 1 - start action\n        with start_action(logger, ""test""):\n            # index 2\n            Message.new(x=2).write(logger)\n            # index 3\n            Message.new(x=3).write(logger)\n        # index 4 - end action\n        # index 5\n        Message.new(x=4).write(logger)\n        logged = self.fromMessagesIndex(logger.messages, 1)\n\n        expectedChildren = [\n            LoggedMessage(logger.messages[2]),\n            LoggedMessage(logger.messages[3]),\n        ]\n        self.assertEqual(logged.children, expectedChildren)\n\n    def test_fromMessagesAddsChildActions(self):\n        """"""\n        L{LoggedAction.fromMessages} recursively adds direct child actions to\n        the constructed L{LoggedAction}.\n        """"""\n        logger = MemoryLogger()\n        # index 0\n        with start_action(logger, ""test""):\n            # index 1:\n            with start_action(logger, ""test2""):\n                # index 2\n                Message.new(message_type=""end"", x=2).write(logger)\n            # index 3 - end action\n            with start_action(logger, ""test3""):\n                # index 4\n                pass\n            # index 5 - end action\n        # index 6 - end action\n        logged = self.fromMessagesIndex(logger.messages, 0)\n\n        self.assertEqual(logged.children[0], self.fromMessagesIndex(logger.messages, 1))\n        self.assertEqual(\n            logged.type_tree(), {""test"": [{""test2"": [""end""]}, {""test3"": []}]}\n        )\n\n    def test_ofType(self):\n        """"""\n        L{LoggedAction.ofType} returns a list of L{LoggedAction} created by the\n        specified L{ActionType}.\n        """"""\n        ACTION = ActionType(""myaction"", [], [], ""An action!"")\n        logger = MemoryLogger()\n        # index 0\n        with start_action(logger, ""test""):\n            # index 1:\n            with ACTION(logger):\n                # index 2\n                Message.new(x=2).write(logger)\n            # index 3 - end action\n            # index 4 - end action\n            # index 5\n        with ACTION(logger):\n            pass\n        # index 6 - end action\n        logged = LoggedAction.ofType(logger.messages, ACTION)\n        self.assertEqual(\n            logged,\n            [\n                self.fromMessagesIndex(logger.messages, 1),\n                self.fromMessagesIndex(logger.messages, 5),\n            ],\n        )\n\n        # String-variant of ofType:\n        logged2 = LoggedAction.ofType(logger.messages, ""myaction"")\n        self.assertEqual(logged, logged2)\n\n    def test_ofTypeNotFound(self):\n        """"""\n        L{LoggedAction.ofType} returns an empty list if actions of the given\n        type cannot be found.\n        """"""\n        ACTION = ActionType(""myaction"", [], [], ""An action!"")\n        logger = MemoryLogger()\n        self.assertEqual(LoggedAction.ofType(logger.messages, ACTION), [])\n\n    def test_descendants(self):\n        """"""\n        L{LoggedAction.descendants} returns all descendants of the\n        L{LoggedAction}.\n        """"""\n        ACTION = ActionType(""myaction"", [], [], ""An action!"")\n        logger = MemoryLogger()\n        # index 0\n        with ACTION(logger):\n            # index 1:\n            with start_action(logger, ""test""):\n                # index 2\n                Message.new(x=2).write(logger)\n            # index 3 - end action\n            # index 4\n            Message.new(x=2).write(logger)\n        # index 5 - end action\n\n        loggedAction = LoggedAction.ofType(logger.messages, ACTION)[0]\n        self.assertEqual(\n            list(loggedAction.descendants()),\n            [\n                self.fromMessagesIndex(logger.messages, 1),\n                LoggedMessage(logger.messages[2]),\n                LoggedMessage(logger.messages[4]),\n            ],\n        )\n\n    def test_succeeded(self):\n        """"""\n        If the action succeeded, L{LoggedAction.succeeded} will be true.\n        """"""\n        logger = MemoryLogger()\n        with start_action(logger, ""test""):\n            pass\n        logged = self.fromMessagesIndex(logger.messages, 0)\n        self.assertTrue(logged.succeeded)\n\n    def test_notSucceeded(self):\n        """"""\n        If the action failed, L{LoggedAction.succeeded} will be false.\n        """"""\n        logger = MemoryLogger()\n        try:\n            with start_action(logger, ""test""):\n                raise KeyError()\n        except KeyError:\n            pass\n        logged = self.fromMessagesIndex(logger.messages, 0)\n        self.assertFalse(logged.succeeded)\n\n\nclass LoggedMessageTest(TestCase):\n    """"""\n    Tests for L{LoggedMessage}.\n    """"""\n\n    def test_values(self):\n        """"""\n        The values given to the L{LoggedMessage} constructor are stored on it.\n        """"""\n        message = {""x"": 1}\n        logged = LoggedMessage(message)\n        self.assertEqual(logged.message, message)\n\n    def test_ofType(self):\n        """"""\n        L{LoggedMessage.ofType} returns a list of L{LoggedMessage} created by the\n        specified L{MessageType}.\n        """"""\n        MESSAGE = MessageType(""mymessage"", [], ""A message!"")\n        logger = MemoryLogger()\n        # index 0\n        MESSAGE().write(logger)\n        # index 1\n        Message.new(x=2).write(logger)\n        # index 2\n        MESSAGE().write(logger)\n        logged = LoggedMessage.ofType(logger.messages, MESSAGE)\n        self.assertEqual(\n            logged,\n            [LoggedMessage(logger.messages[0]), LoggedMessage(logger.messages[2])],\n        )\n\n        # Lookup by string type:\n        logged2 = LoggedMessage.ofType(logger.messages, ""mymessage"")\n        self.assertEqual(logged, logged2)\n\n    def test_ofTypeNotFound(self):\n        """"""\n        L{LoggedMessage.ofType} returns an empty list if messages of the given\n        type cannot be found.\n        """"""\n        MESSAGE = MessageType(""mymessage"", [], ""A message!"")\n        logger = MemoryLogger()\n        self.assertEqual(LoggedMessage.ofType(logger.messages, MESSAGE), [])\n\n\nclass AssertContainsFields(TestCase):\n    """"""\n    Tests for L{assertContainsFields}.\n    """"""\n\n    class ContainsTest(TestCase):\n        """"""\n        A test case that uses L{assertContainsFields}.\n        """"""\n\n        def __init__(self, message, expectedFields):\n            TestCase.__init__(self)\n            self.message = message\n            self.expectedFields = expectedFields\n\n        def runTest(self):\n            assertContainsFields(self, self.message, self.expectedFields)\n\n    def test_equal(self):\n        """"""\n        Equal dictionaries contain each other.\n        """"""\n        message = {""a"": 1}\n        expected = message.copy()\n        test = self.ContainsTest(message, expected)\n        # No exception raised:\n        test.debug()\n\n    def test_additionalIsSuperSet(self):\n        """"""\n        If C{A} is C{B} plus some extra entries, C{A} contains the fields in\n        C{B}.\n        """"""\n        message = {""a"": 1, ""b"": 2, ""c"": 3}\n        expected = {""a"": 1, ""c"": 3}\n        test = self.ContainsTest(message, expected)\n        # No exception raised:\n        test.debug()\n\n    def test_missingFields(self):\n        """"""\n        If C{A} is C{B} minus some entries, C{A} does not contain the fields in\n        C{B}.\n        """"""\n        message = {""a"": 1, ""c"": 3}\n        expected = {""a"": 1, ""b"": 2, ""c"": 3}\n        test = self.ContainsTest(message, expected)\n        self.assertRaises(AssertionError, test.debug)\n\n    def test_differentValues(self):\n        """"""\n        If C{A} has a different value for a specific field than C{B}, C{A} does\n        not contain the fields in C{B}.\n        """"""\n        message = {""a"": 1, ""c"": 3}\n        expected = {""a"": 1, ""c"": 2}\n        test = self.ContainsTest(message, expected)\n        self.assertRaises(AssertionError, test.debug)\n\n\nclass ValidateLoggingTestsMixin(object):\n    """"""\n    Tests for L{validateLogging} and L{capture_logging}.\n    """"""\n\n    validate = None\n\n    def test_decoratedFunctionCalledWithMemoryLogger(self):\n        """"""\n        The underlying function decorated with L{validateLogging} is called with\n        a L{MemoryLogger} instance.\n        """"""\n        result = []\n\n        class MyTest(TestCase):\n            @self.validate(None)\n            def test_foo(this, logger):\n                result.append((this, logger.__class__))\n\n        theTest = MyTest(""test_foo"")\n        theTest.run()\n        self.assertEqual(result, [(theTest, MemoryLogger)])\n\n    def test_decorated_function_passthrough(self):\n        """"""\n        Additional arguments are passed to the underlying function.\n        """"""\n        result = []\n\n        def another_wrapper(f):\n            def g(this):\n                f(this, 1, 2, c=3)\n\n            return g\n\n        class MyTest(TestCase):\n            @another_wrapper\n            @self.validate(None)\n            def test_foo(this, a, b, logger, c=None):\n                result.append((a, b, c))\n\n        theTest = MyTest(""test_foo"")\n        theTest.debug()\n        self.assertEqual(result, [(1, 2, 3)])\n\n    def test_newMemoryLogger(self):\n        """"""\n        The underlying function decorated with L{validateLogging} is called with\n        a new L{MemoryLogger} every time the wrapper is called.\n        """"""\n        result = []\n\n        class MyTest(TestCase):\n            @self.validate(None)\n            def test_foo(this, logger):\n                result.append(logger)\n\n        theTest = MyTest(""test_foo"")\n        theTest.run()\n        theTest.run()\n        self.assertIsNot(result[0], result[1])\n\n    def test_returns(self):\n        """"""\n        The result of the underlying function is returned by wrapper when called.\n        """"""\n\n        class MyTest(TestCase):\n            @self.validate(None)\n            def test_foo(self, logger):\n                return 123\n\n        self.assertEqual(MyTest(""test_foo"").test_foo(), 123)\n\n    def test_raises(self):\n        """"""\n        The exception raised by the underlying function is passed through by the\n        wrapper when called.\n        """"""\n        exc = Exception()\n\n        class MyTest(TestCase):\n            @self.validate(None)\n            def test_foo(self, logger):\n                raise exc\n\n        raised = None\n        try:\n            MyTest(""test_foo"").debug()\n        except Exception as e:\n            raised = e\n        self.assertIs(exc, raised)\n\n    def test_name(self):\n        """"""\n        The wrapper has the same name as the wrapped function.\n        """"""\n\n        class MyTest(TestCase):\n            @self.validate(None)\n            def test_foo(self, logger):\n                pass\n\n        self.assertEqual(MyTest.test_foo.__name__, ""test_foo"")\n\n    def test_addCleanupValidate(self):\n        """"""\n        When a test method is decorated with L{validateLogging} it has\n        L{MemoryLogger.validate} registered as a test cleanup.\n        """"""\n        MESSAGE = MessageType(""mymessage"", [], ""A message"")\n\n        class MyTest(TestCase):\n            @self.validate(None)\n            def runTest(self, logger):\n                self.logger = logger\n                logger.write({""message_type"": ""wrongmessage""}, MESSAGE._serializer)\n\n        test = MyTest()\n        with self.assertRaises(ValidationError) as context:\n            test.debug()\n        # Some reference to the reason:\n        self.assertIn(""wrongmessage"", str(context.exception))\n        # Some reference to which file caused the problem:\n        self.assertIn(""test_testing.py"", str(context.exception))\n\n    def test_addCleanupTracebacks(self):\n        """"""\n        When a test method is decorated with L{validateLogging} it has has a\n        check unflushed tracebacks in the L{MemoryLogger} registered as a\n        test cleanup.\n        """"""\n\n        class MyTest(TestCase):\n            @self.validate(None)\n            def runTest(self, logger):\n                try:\n                    1 / 0\n                except ZeroDivisionError:\n                    write_traceback(logger)\n\n        test = MyTest()\n        self.assertRaises(UnflushedTracebacks, test.debug)\n\n    def test_assertion(self):\n        """"""\n        If a callable is passed to L{validateLogging}, it is called with the\n        L{TestCase} instance and the L{MemoryLogger} passed to the test\n        method.\n        """"""\n        result = []\n\n        class MyTest(TestCase):\n            def assertLogging(self, logger):\n                result.append((self, logger))\n\n            @self.validate(assertLogging)\n            def runTest(self, logger):\n                self.logger = logger\n\n        test = MyTest()\n        test.run()\n        self.assertEqual(result, [(test, test.logger)])\n\n    def test_assertionArguments(self):\n        """"""\n        If a callable together with additional arguments and keyword arguments are\n        passed to L{validateLogging}, the callable is called with the additional\n        args and kwargs.\n        """"""\n        result = []\n\n        class MyTest(TestCase):\n            def assertLogging(self, logger, x, y):\n                result.append((self, logger, x, y))\n\n            @self.validate(assertLogging, 1, y=2)\n            def runTest(self, logger):\n                self.logger = logger\n\n        test = MyTest()\n        test.run()\n        self.assertEqual(result, [(test, test.logger, 1, 2)])\n\n    def test_assertionAfterTest(self):\n        """"""\n        If a callable is passed to L{validateLogging}, it is called with the\n        after the main test code has run, allowing it to make assertions\n        about log messages from the test.\n        """"""\n\n        class MyTest(TestCase):\n            def assertLogging(self, logger):\n                self.result.append(2)\n\n            @self.validate(assertLogging)\n            def runTest(self, logger):\n                self.result = [1]\n\n        test = MyTest()\n        test.run()\n        self.assertEqual(test.result, [1, 2])\n\n    def test_assertionBeforeTracebackCleanup(self):\n        """"""\n        If a callable is passed to L{validateLogging}, it is called with the\n        before the check for unflushed tracebacks, allowing it to flush\n        traceback log messages.\n        """"""\n\n        class MyTest(TestCase):\n            def assertLogging(self, logger):\n                logger.flushTracebacks(ZeroDivisionError)\n                self.flushed = True\n\n            @self.validate(assertLogging)\n            def runTest(self, logger):\n                self.flushed = False\n                try:\n                    1 / 0\n                except ZeroDivisionError:\n                    write_traceback(logger)\n\n        test = MyTest()\n        test.run()\n        self.assertTrue(test.flushed)\n\n\nclass ValidateLoggingTests(ValidateLoggingTestsMixin, TestCase):\n    """"""\n    Tests for L{validate_logging}.\n    """"""\n\n    validate = staticmethod(validate_logging)\n\n\nclass CaptureLoggingTests(ValidateLoggingTestsMixin, TestCase):\n    """"""\n    Tests for L{capture_logging}.\n    """"""\n\n    validate = staticmethod(capture_logging)\n\n    def setUp(self):\n        # Since we\'re not always calling the test method via the TestCase\n        # infrastructure, sometimes cleanup methods are not called. This\n        # means the original default logger is not restored. So we do so\n        # manually. If the issue is a bug in capture_logging itself the\n        # tests below will catch that.\n        original_logger = _output._DEFAULT_LOGGER\n\n        def cleanup():\n            _output._DEFAULT_LOGGER = original_logger\n\n        self.addCleanup(cleanup)\n\n    def test_default_logger(self):\n        """"""\n        L{capture_logging} captures messages from logging that\n        doesn\'t specify a L{Logger}.\n        """"""\n\n        class MyTest(TestCase):\n            @capture_logging(None)\n            def runTest(self, logger):\n                Message.log(some_key=1234)\n                self.logger = logger\n\n        test = MyTest()\n        test.run()\n        self.assertEqual(test.logger.messages[0][""some_key""], 1234)\n\n    def test_global_cleanup(self):\n        """"""\n        After the function wrapped with L{capture_logging} finishes,\n        logging that doesn\'t specify a logger is logged normally.\n        """"""\n\n        class MyTest(TestCase):\n            @capture_logging(None)\n            def runTest(self, logger):\n                pass\n\n        test = MyTest()\n        test.run()\n        messages = []\n        add_destination(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n        Message.log(some_key=1234)\n        self.assertEqual(messages[0][""some_key""], 1234)\n\n    def test_global_cleanup_exception(self):\n        """"""\n        If the function wrapped with L{capture_logging} throws an exception,\n        logging that doesn\'t specify a logger is logged normally.\n        """"""\n\n        class MyTest(TestCase):\n            @capture_logging(None)\n            def runTest(self, logger):\n                raise RuntimeError()\n\n        test = MyTest()\n        test.run()\n        messages = []\n        add_destination(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n        Message.log(some_key=1234)\n        self.assertEqual(messages[0][""some_key""], 1234)\n\n    def test_validationNotRunForSkip(self):\n        """"""\n        If the decorated test raises L{SkipTest} then the logging validation is\n        also skipped.\n        """"""\n\n        class MyTest(TestCase):\n            recorded = False\n\n            def record(self, logger):\n                self.recorded = True\n\n            @validateLogging(record)\n            def runTest(self, logger):\n                raise SkipTest(""Do not run this test."")\n\n        test = MyTest()\n        result = TestResult()\n        test.run(result)\n\n        # Verify that the validation function did not run and that the test was\n        # nevertheless marked as a skip with the correct reason.\n        self.assertEqual(\n            (test.recorded, result.skipped, result.errors, result.failures),\n            (False, [(test, ""Do not run this test."")], [], []),\n        )\n\n\nMESSAGE1 = MessageType(\n    ""message1"", [Field.forTypes(""x"", [int], ""A number"")], ""A message for testing.""\n)\nMESSAGE2 = MessageType(""message2"", [], ""A message for testing."")\n\n\nclass AssertHasMessageTests(TestCase):\n    """"""\n    Tests for L{assertHasMessage}.\n    """"""\n\n    class UnitTest(TestCase):\n        """"""\n        Test case that can be instantiated.\n        """"""\n\n        def runTest(self):\n            pass\n\n    def test_failIfNoMessagesOfType(self):\n        """"""\n        L{assertHasMessage} raises L{AssertionError} if the given L{MemoryLogger}\n        has no messages of the given L{MessageType}.\n        """"""\n        test = self.UnitTest()\n        logger = MemoryLogger()\n        MESSAGE1(x=123).write(logger)\n        self.assertRaises(AssertionError, assertHasMessage, test, logger, MESSAGE2)\n\n    def test_returnsIfMessagesOfType(self):\n        """"""\n        L{assertHasMessage} returns the first message of the given L{MessageType}.\n        """"""\n        test = self.UnitTest()\n        logger = MemoryLogger()\n        MESSAGE1(x=123).write(logger)\n        self.assertEqual(\n            assertHasMessage(test, logger, MESSAGE1),\n            LoggedMessage.ofType(logger.messages, MESSAGE1)[0],\n        )\n\n    def test_failIfNotSubset(self):\n        """"""\n        L{assertHasMessage} raises L{AssertionError} if the found message doesn\'t\n        contain the given fields.\n        """"""\n        test = self.UnitTest()\n        logger = MemoryLogger()\n        MESSAGE1(x=123).write(logger)\n        self.assertRaises(\n            AssertionError, assertHasMessage, test, logger, MESSAGE1, {""x"": 24}\n        )\n\n    def test_returnsIfSubset(self):\n        """"""\n        L{assertHasMessage} returns the first message of the given L{MessageType} if\n        it contains the given fields.\n        """"""\n        test = self.UnitTest()\n        logger = MemoryLogger()\n        MESSAGE1(x=123).write(logger)\n        self.assertEqual(\n            assertHasMessage(test, logger, MESSAGE1, {""x"": 123}),\n            LoggedMessage.ofType(logger.messages, MESSAGE1)[0],\n        )\n\n\nACTION1 = ActionType(\n    ""action1"",\n    [Field.forTypes(""x"", [int], ""A number"")],\n    [Field.forTypes(""result"", [int], ""A number"")],\n    ""A action for testing."",\n)\nACTION2 = ActionType(""action2"", [], [], ""A action for testing."")\n\n\nclass AssertHasActionTests(TestCase):\n    """"""\n    Tests for L{assertHasAction}.\n    """"""\n\n    class UnitTest(TestCase):\n        """"""\n        Test case that can be instantiated.\n        """"""\n\n        def runTest(self):\n            pass\n\n    def test_failIfNoActionsOfType(self):\n        """"""\n        L{assertHasAction} raises L{AssertionError} if the given L{MemoryLogger}\n        has no actions of the given L{ActionType}.\n        """"""\n        test = self.UnitTest()\n        logger = MemoryLogger()\n        with ACTION1(logger, x=123):\n            pass\n        self.assertRaises(AssertionError, assertHasAction, test, logger, ACTION2, True)\n\n    def test_failIfWrongSuccessStatus(self):\n        """"""\n        L{assertHasAction} raises L{AssertionError} if the given success status does\n        not match that of the found actions.\n        """"""\n        test = self.UnitTest()\n        logger = MemoryLogger()\n        with ACTION1(logger, x=123):\n            pass\n        try:\n            with ACTION2(logger):\n                1 / 0\n        except ZeroDivisionError:\n            pass\n        self.assertRaises(AssertionError, assertHasAction, test, logger, ACTION1, False)\n        self.assertRaises(AssertionError, assertHasAction, test, logger, ACTION2, True)\n\n    def test_returnsIfMessagesOfType(self):\n        """"""\n        A successful L{assertHasAction} returns the first message of the given\n        L{ActionType}.\n        """"""\n        test = self.UnitTest()\n        logger = MemoryLogger()\n        with ACTION1(logger, x=123):\n            pass\n        self.assertEqual(\n            assertHasAction(test, logger, ACTION1, True),\n            LoggedAction.ofType(logger.messages, ACTION1)[0],\n        )\n\n    def test_failIfNotStartSubset(self):\n        """"""\n        L{assertHasAction} raises L{AssertionError} if the found action doesn\'t\n        contain the given start fields.\n        """"""\n        test = self.UnitTest()\n        logger = MemoryLogger()\n        with ACTION1(logger, x=123):\n            pass\n        self.assertRaises(\n            AssertionError, assertHasAction, test, logger, ACTION1, True, {""x"": 24}\n        )\n\n    def test_failIfNotEndSubset(self):\n        """"""\n        L{assertHasAction} raises L{AssertionError} if the found action doesn\'t\n        contain the given end fields.\n        """"""\n        test = self.UnitTest()\n        logger = MemoryLogger()\n        with ACTION1(logger, x=123) as act:\n            act.addSuccessFields(result=5)\n        self.assertRaises(\n            AssertionError,\n            assertHasAction,\n            test,\n            logger,\n            ACTION1,\n            True,\n            startFields={""x"": 123},\n            endFields={""result"": 24},\n        )\n\n    def test_returns(self):\n        """"""\n        A successful L{assertHasAction} returns the first message of the given\n        L{ActionType} after doing all validation.\n        """"""\n        test = self.UnitTest()\n        logger = MemoryLogger()\n        with ACTION1(logger, x=123) as act:\n            act.addSuccessFields(result=5)\n        self.assertEqual(\n            assertHasAction(test, logger, ACTION1, True, {""x"": 123}, {""result"": 5}),\n            LoggedAction.ofType(logger.messages, ACTION1)[0],\n        )\n\n\nclass PEP8Tests(TestCase):\n    """"""\n    Tests for PEP 8 method compatibility.\n    """"""\n\n    def test_LoggedAction_from_messages(self):\n        """"""\n        L{LoggedAction.from_messages} is the same as\n        L{LoggedAction.fromMessages}.\n        """"""\n        self.assertEqual(LoggedAction.from_messages, LoggedAction.fromMessages)\n\n    def test_LoggedAction_of_type(self):\n        """"""\n        L{LoggedAction.of_type} is the same as\n        L{LoggedAction.ofType}.\n        """"""\n        self.assertEqual(LoggedAction.of_type, LoggedAction.ofType)\n\n    def test_LoggedAction_end_message(self):\n        """"""\n        L{LoggedAction.end_message} is the same as L{LoggedAction.endMessage}.\n        """"""\n        action = LoggedAction({1: 2}, {3: 4}, [])\n        self.assertEqual(action.end_message, action.endMessage)\n\n    def test_LoggedAction_start_message(self):\n        """"""\n        L{LoggedAction.start_message} is the same as\n        L{LoggedAction.startMessage}.\n        """"""\n        action = LoggedAction({1: 2}, {3: 4}, [])\n        self.assertEqual(action.start_message, action.startMessage)\n\n    def test_LoggedMessage_of_type(self):\n        """"""\n        L{LoggedMessage.of_type} is the same as\n        L{LoggedMessage.ofType}.\n        """"""\n        self.assertEqual(LoggedMessage.of_type, LoggedMessage.ofType)\n\n    def test_validate_logging(self):\n        """"""\n        L{validate_logging} is the same as L{validateLogging}.\n        """"""\n        self.assertEqual(validate_logging, validateLogging)\n\n\nclass LowLevelTestingHooks(TestCase):\n    """"""Tests for lower-level APIs for setting up MemoryLogger.""""""\n\n    @capture_logging(None)\n    def test_swap_logger(self, logger):\n        """"""C{swap_logger} swaps out the current logger.""""""\n        new_logger = MemoryLogger()\n        old_logger = swap_logger(new_logger)\n        Message.log(message_type=""hello"")\n\n        # We swapped out old logger for new:\n        self.assertIs(old_logger, logger)\n        self.assertEqual(new_logger.messages[0][""message_type""], ""hello"")\n\n        # Now restore old logger:\n        intermediate_logger = swap_logger(old_logger)\n        Message.log(message_type=""goodbye"")\n        self.assertIs(intermediate_logger, new_logger)\n        self.assertEqual(logger.messages[0][""message_type""], ""goodbye"")\n\n    def test_check_for_errors_unflushed_tracebacks(self):\n        """"""C{check_for_errors} raises on unflushed tracebacks.""""""\n        logger = MemoryLogger()\n\n        # No errors initially:\n        check_for_errors(logger)\n\n        try:\n            1 / 0\n        except ZeroDivisionError:\n            write_traceback(logger)\n        logger.flush_tracebacks(ZeroDivisionError)\n\n        # Flushed tracebacks don\'t count:\n        check_for_errors(logger)\n\n        # But unflushed tracebacks do:\n        try:\n            raise RuntimeError\n        except RuntimeError:\n            write_traceback(logger)\n        with self.assertRaises(UnflushedTracebacks):\n            check_for_errors(logger)\n\n    def test_check_for_errors_validation(self):\n        """"""C{check_for_errors} raises on validation errors.""""""\n        logger = MemoryLogger()\n        logger.write({""x"": 1, ""message_type"": ""mem""})\n\n        # No errors:\n        check_for_errors(logger)\n\n        # Now long something unserializable to JSON:\n        logger.write({""message_type"": object()})\n        with self.assertRaises(TypeError):\n            check_for_errors(logger)\n'"
eliot/tests/test_traceback.py,0,"b'""""""\nTests for L{eliot._traceback}.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom unittest import TestCase, SkipTest\nimport traceback\nimport sys\n\ntry:\n    from twisted.python.failure import Failure\nexcept ImportError:\n    Failure = None\n\nfrom .._traceback import write_traceback, writeFailure, _writeTracebackMessage\nfrom ..testing import (\n    assertContainsFields,\n    validateLogging,\n    capture_logging,\n    MemoryLogger,\n)\nfrom .._errors import register_exception_extractor\nfrom .test_action import make_error_extraction_tests\n\n\ndef assert_expected_traceback(test, logger, message, exception, expected_traceback):\n    """"""Assert we logged the given exception and the expected traceback.""""""\n    lines = expected_traceback.split(""\\n"")\n    # Remove source code lines:\n    expected_traceback = ""\\n"".join([l for l in lines if not l.startswith(""    "")])\n    assertContainsFields(\n        test,\n        message,\n        {\n            ""message_type"": ""eliot:traceback"",\n            ""exception"": RuntimeError,\n            ""reason"": exception,\n            ""traceback"": expected_traceback,\n        },\n    )\n    logger.flushTracebacks(RuntimeError)\n\n\nclass TracebackLoggingTests(TestCase):\n    """"""\n    Tests for L{write_traceback} and L{writeFailure}.\n    """"""\n\n    @validateLogging(None)\n    def test_write_traceback_implicit(self, logger):\n        """"""\n        L{write_traceback} with no arguments writes the current traceback to\n        the log.\n        """"""\n        e = None\n\n        def raiser():\n            raise RuntimeError(""because"")\n\n        try:\n            raiser()\n        except Exception as exception:\n            expected_traceback = traceback.format_exc()\n            write_traceback(logger)\n            e = exception\n        assert_expected_traceback(\n            self, logger, logger.messages[0], e, expected_traceback\n        )\n\n    @validateLogging(None)\n    def test_write_traceback_explicit(self, logger):\n        """"""\n        L{write_traceback} with explicit arguments writes the given traceback\n        to the log.\n        """"""\n        e = None\n\n        def raiser():\n            raise RuntimeError(""because"")\n\n        try:\n            raiser()\n        except Exception as exception:\n            expected_traceback = traceback.format_exc()\n            write_traceback(logger, exc_info=sys.exc_info())\n            e = exception\n        assert_expected_traceback(\n            self, logger, logger.messages[0], e, expected_traceback\n        )\n\n    @capture_logging(None)\n    def test_writeTracebackDefaultLogger(self, logger):\n        """"""\n        L{write_traceback} writes to the default log, if none is\n        specified.\n        """"""\n\n        def raiser():\n            raise RuntimeError(""because"")\n\n        try:\n            raiser()\n        except Exception:\n            write_traceback()\n\n        message = logger.messages[0]\n        assertContainsFields(self, message, {""message_type"": ""eliot:traceback""})\n        logger.flushTracebacks(RuntimeError)\n\n    @validateLogging(None)\n    def test_writeFailure(self, logger):\n        """"""\n        L{writeFailure} writes a L{Failure} to the log.\n        """"""\n        if Failure is None:\n            raise SkipTest(""Twisted unavailable"")\n\n        try:\n            raise RuntimeError(""because"")\n        except:\n            failure = Failure()\n            expectedTraceback = failure.getBriefTraceback()\n            writeFailure(failure, logger)\n        message = logger.messages[0]\n        assertContainsFields(\n            self,\n            message,\n            {\n                ""message_type"": ""eliot:traceback"",\n                ""exception"": RuntimeError,\n                ""reason"": failure.value,\n                ""traceback"": expectedTraceback,\n            },\n        )\n        logger.flushTracebacks(RuntimeError)\n\n    @capture_logging(None)\n    def test_writeFailureDefaultLogger(self, logger):\n        """"""\n        L{writeFailure} writes to the default log, if none is\n        specified.\n        """"""\n        if Failure is None:\n            raise SkipTest(""Twisted unavailable"")\n\n        try:\n            raise RuntimeError(""because"")\n        except:\n            failure = Failure()\n            writeFailure(failure)\n        message = logger.messages[0]\n        assertContainsFields(self, message, {""message_type"": ""eliot:traceback""})\n        logger.flushTracebacks(RuntimeError)\n\n    @validateLogging(None)\n    def test_writeFailureResult(self, logger):\n        """"""\n        L{writeFailure} returns C{None}.\n        """"""\n        if Failure is None:\n            raise SkipTest(""Twisted unavailable"")\n\n        try:\n            raise RuntimeError(""because"")\n        except:\n            result = writeFailure(Failure(), logger)\n        self.assertIs(result, None)\n        logger.flushTracebacks(RuntimeError)\n\n    @validateLogging(None)\n    def test_serialization(self, logger):\n        """"""\n        L{_writeTracebackMessage} serializes exceptions to string values and\n        types to FQPN.\n        """"""\n        try:\n            raise KeyError(123)\n        except:\n            exc_info = sys.exc_info()\n        _writeTracebackMessage(logger, *exc_info)\n        serialized = logger.serialize()[0]\n        assertContainsFields(\n            self,\n            serialized,\n            {""exception"": ""%s.KeyError"" % (KeyError.__module__,), ""reason"": ""123""},\n        )\n        logger.flushTracebacks(KeyError)\n\n    @validateLogging(None)\n    def test_badException(self, logger):\n        """"""\n        L{_writeTracebackMessage} logs a message even if given a bad exception.\n        """"""\n\n        class BadException(Exception):\n            def __str__(self):\n                raise TypeError()\n\n        try:\n            raise BadException()\n        except BadException:\n            exc_info = sys.exc_info()\n        _writeTracebackMessage(logger, *exc_info)\n        self.assertEqual(\n            logger.serialize()[0][""reason""],\n            ""eliot: unknown, unicode() raised exception"",\n        )\n        logger.flushTracebacks(BadException)\n\n\ndef get_traceback_messages(exception):\n    """"""\n    Given an exception instance generate a traceback Eliot message.\n    """"""\n    logger = MemoryLogger()\n    try:\n        raise exception\n    except exception.__class__:\n        write_traceback(logger)\n    # MemoryLogger.validate() mutates messages:\n    # https://github.com/itamarst/eliot/issues/243\n    messages = [message.copy() for message in logger.messages]\n    logger.validate()\n    return messages\n\n\nclass TracebackExtractionTests(make_error_extraction_tests(get_traceback_messages)):\n    """"""\n    Error extraction tests for tracebacks.\n    """"""\n\n    def test_regular_fields(self):\n        """"""\n        The normal traceback fields are still present when error\n        extraction is used.\n        """"""\n\n        class MyException(Exception):\n            pass\n\n        register_exception_extractor(MyException, lambda e: {""key"": e.args[0]})\n        exception = MyException(""because"")\n        messages = get_traceback_messages(exception)\n        assertContainsFields(\n            self,\n            messages[0],\n            {\n                ""message_type"": ""eliot:traceback"",\n                ""reason"": exception,\n                ""exception"": MyException,\n            },\n        )\n'"
eliot/tests/test_twisted.py,0,"b'""""""\nTests for L{eliot.twisted}.\n""""""\n\nfrom __future__ import absolute_import, unicode_literals, print_function\n\nimport sys\nfrom functools import wraps\n\ntry:\n    from twisted.internet.defer import Deferred, succeed, fail, returnValue\n    from twisted.trial.unittest import TestCase\n    from twisted.python.failure import Failure\n    from twisted.logger import globalLogPublisher\nexcept ImportError:\n    # Make tests not run at all.\n    TestCase = object\nelse:\n    # Make sure we always import this if Twisted is available, so broken\n    # logwriter.py causes a failure:\n    from ..twisted import (\n        DeferredContext,\n        AlreadyFinished,\n        _passthrough,\n        redirectLogsForTrial,\n        _RedirectLogsForTrial,\n        TwistedDestination,\n        inline_callbacks,\n    )\n\nfrom .test_generators import assert_expected_action_tree\n\nfrom .._action import start_action, current_action, Action, TaskLevel\nfrom .._output import MemoryLogger, Logger\nfrom .._message import Message\nfrom ..testing import assertContainsFields, capture_logging\nfrom .. import removeDestination, addDestination\nfrom .._traceback import write_traceback\nfrom .common import FakeSys\n\n\nclass PassthroughTests(TestCase):\n    """"""\n    Tests for L{_passthrough}.\n    """"""\n\n    def test_passthrough(self):\n        """"""\n        L{_passthrough} returns the passed-in value.\n        """"""\n        obj = object()\n        self.assertIs(obj, _passthrough(obj))\n\n\ndef withActionContext(f):\n    """"""\n    Decorator that calls a function with an action context.\n\n    @param f: A function.\n    """"""\n    logger = MemoryLogger()\n    action = start_action(logger, ""test"")\n\n    @wraps(f)\n    def test(self):\n        with action.context():\n            return f(self)\n\n    return test\n\n\nclass DeferredContextTests(TestCase):\n    """"""\n    Tests for L{DeferredContext}.\n    """"""\n\n    def test_requireContext(self):\n        """"""\n        L{DeferredContext} raises a L{RuntimeError} if it is called without an\n        action context.\n        """"""\n        self.assertRaises(RuntimeError, DeferredContext, Deferred())\n\n    @withActionContext\n    def test_result(self):\n        """"""\n        The passed-in L{Deferred} is available as the L{DeferredContext}\'s\n        C{result} attribute.\n        """"""\n        result = Deferred()\n        context = DeferredContext(result)\n        self.assertIs(context.result, result)\n\n    @withActionContext\n    def test_addCallbacksCallbackToDeferred(self):\n        """"""\n        L{DeferredContext.addCallbacks} passes the given callback and its\n        corresponding arguments to the wrapped L{Deferred}\'s\n        C{addCallbacks}.\n        """"""\n        called = []\n\n        def f(value, x, y):\n            called.append((value, x, y))\n\n        result = Deferred()\n        context = DeferredContext(result)\n        context.addCallbacks(f, lambda x: None, (1,), {""y"": 2})\n        result.callback(0)\n        self.assertEqual(called, [(0, 1, 2)])\n\n    @withActionContext\n    def test_addCallbacksErrbackToDeferred(self):\n        """"""\n        L{DeferredContext.addCallbacks} passes the given errback and its\n        corresponding arguments to the wrapped L{Deferred}\'s\n        C{addCallbacks}.\n        """"""\n        called = []\n\n        def f(value, x, y):\n            value.trap(RuntimeError)\n            called.append((x, y))\n\n        result = Deferred()\n        context = DeferredContext(result)\n        context.addCallbacks(lambda x: None, f, None, None, (1,), {""y"": 2})\n        result.errback(RuntimeError())\n        self.assertEqual(called, [(1, 2)])\n\n    @withActionContext\n    def test_addCallbacksWithOnlyCallback(self):\n        """"""\n        L{DeferredContext.addCallbacks} can be called with a single argument, a\n        callback function, and passes it to the wrapped L{Deferred}\'s\n        C{addCallbacks}.\n        """"""\n        called = []\n\n        def f(value):\n            called.append(value)\n\n        result = Deferred()\n        context = DeferredContext(result)\n        context.addCallbacks(f)\n        result.callback(0)\n        self.assertEqual(called, [0])\n\n    @withActionContext\n    def test_addCallbacksWithOnlyCallbackErrorCase(self):\n        """"""\n        L{DeferredContext.addCallbacks} can be called with a single argument, a\n        callback function, and passes a pass-through errback to the wrapped\n        L{Deferred}\'s C{addCallbacks}.\n        """"""\n        called = []\n\n        def f(value):\n            called.append(value)\n\n        class ExpectedException(Exception):\n            pass\n\n        result = Deferred()\n        context = DeferredContext(result)\n        context.addCallbacks(f)\n        result.errback(Failure(ExpectedException()))\n        self.assertEqual(called, [])\n        # The assertion is inside `failureResultOf`.\n        self.failureResultOf(result, ExpectedException)\n\n    @withActionContext\n    def test_addCallbacksReturnSelf(self):\n        """"""\n        L{DeferredContext.addCallbacks} returns the L{DeferredContext}.\n        """"""\n        result = Deferred()\n        context = DeferredContext(result)\n        self.assertIs(context, context.addCallbacks(lambda x: None, lambda x: None))\n\n    def test_addCallbacksCallbackContext(self):\n        """"""\n        L{DeferedContext.addCallbacks} adds a callback that runs in context of\n        action that the L{DeferredContext} was created with.\n        """"""\n        logger = MemoryLogger()\n        action1 = start_action(logger, ""test"")\n        action2 = start_action(logger, ""test"")\n        context = []\n        d = succeed(None)\n        with action1.context():\n            d = DeferredContext(d)\n            with action2.context():\n                d.addCallbacks(lambda x: context.append(current_action()), lambda x: x)\n        self.assertEqual(context, [action1])\n\n    def test_addCallbacksErrbackContext(self):\n        """"""\n        L{DeferedContext.addCallbacks} adds an errback that runs in context of\n        action that the L{DeferredContext} was created with.\n        """"""\n        logger = MemoryLogger()\n        action1 = start_action(logger, ""test"")\n        action2 = start_action(logger, ""test"")\n        context = []\n        d = fail(RuntimeError())\n        with action1.context():\n            d = DeferredContext(d)\n            with action2.context():\n                d.addCallbacks(lambda x: x, lambda x: context.append(current_action()))\n        self.assertEqual(context, [action1])\n\n    @withActionContext\n    def test_addCallbacksCallbackResult(self):\n        """"""\n        A callback added with DeferredContext.addCallbacks has its result\n        passed on to the next callback.\n        """"""\n        d = succeed(0)\n        d = DeferredContext(d)\n        d.addCallbacks(lambda x: [x, 1], lambda x: x)\n        self.assertEqual(self.successResultOf(d.result), [0, 1])\n\n    @withActionContext\n    def test_addCallbacksErrbackResult(self):\n        """"""\n        An errback added with DeferredContext.addCallbacks has its result\n        passed on to the next callback.\n        """"""\n        exception = ZeroDivisionError()\n        d = fail(exception)\n        d = DeferredContext(d)\n        d.addCallbacks(lambda x: x, lambda x: [x.value, 1])\n        self.assertEqual(self.successResultOf(d.result), [exception, 1])\n\n    def test_addActionFinishNoImmediateLogging(self):\n        """"""\n        L{DeferredContext.addActionFinish} does not log anything if the\n        L{Deferred} hasn\'t fired yet.\n        """"""\n        d = Deferred()\n        logger = MemoryLogger()\n        action = Action(logger, ""uuid"", TaskLevel(level=[1]), ""sys:me"")\n        with action.context():\n            DeferredContext(d).addActionFinish()\n        self.assertFalse(logger.messages)\n\n    def test_addActionFinishSuccess(self):\n        """"""\n        When the L{Deferred} referred to by L{DeferredContext.addActionFinish}\n        fires successfully, a finish message is logged.\n        """"""\n        d = Deferred()\n        logger = MemoryLogger()\n        action = Action(logger, ""uuid"", TaskLevel(level=[1]), ""sys:me"")\n        with action.context():\n            DeferredContext(d).addActionFinish()\n        d.callback(""result"")\n        assertContainsFields(\n            self,\n            logger.messages[0],\n            {\n                ""task_uuid"": ""uuid"",\n                ""task_level"": [1, 1],\n                ""action_type"": ""sys:me"",\n                ""action_status"": ""succeeded"",\n            },\n        )\n\n    def test_addActionFinishSuccessPassThrough(self):\n        """"""\n        L{DeferredContext.addActionFinish} passes through a successful result\n        unchanged.\n        """"""\n        d = Deferred()\n        logger = MemoryLogger()\n        action = Action(logger, ""uuid"", TaskLevel(level=[1]), ""sys:me"")\n        with action.context():\n            DeferredContext(d).addActionFinish()\n        d.callback(""result"")\n        result = []\n        d.addCallback(result.append)\n        self.assertEqual(result, [""result""])\n\n    def test_addActionFinishFailure(self):\n        """"""\n        When the L{Deferred} referred to in L{DeferredContext.addActionFinish}\n        fires with an exception, a finish message is logged.\n        """"""\n        d = Deferred()\n        logger = MemoryLogger()\n        action = Action(logger, ""uuid"", TaskLevel(level=[1]), ""sys:me"")\n        with action.context():\n            DeferredContext(d).addActionFinish()\n        exception = RuntimeError(""because"")\n        d.errback(exception)\n        assertContainsFields(\n            self,\n            logger.messages[0],\n            {\n                ""task_uuid"": ""uuid"",\n                ""task_level"": [1, 1],\n                ""action_type"": ""sys:me"",\n                ""action_status"": ""failed"",\n                ""reason"": ""because"",\n                ""exception"": ""%s.RuntimeError"" % (RuntimeError.__module__,),\n            },\n        )\n        d.addErrback(lambda _: None)  # don\'t let Failure go to Twisted logs\n\n    def test_addActionFinishFailurePassThrough(self):\n        """"""\n        L{DeferredContext.addActionFinish} passes through a failed result\n        unchanged.\n        """"""\n        d = Deferred()\n        logger = MemoryLogger()\n        action = Action(logger, ""uuid"", TaskLevel(level=[1]), ""sys:me"")\n        with action.context():\n            DeferredContext(d).addActionFinish()\n        failure = Failure(RuntimeError())\n        d.errback(failure)\n        result = []\n        d.addErrback(result.append)\n        self.assertEqual(result, [failure])\n\n    @withActionContext\n    def test_addActionFinishRaisesAfterAddActionFinish(self):\n        """"""\n        After L{DeferredContext.addActionFinish} is called, additional calls to\n        L{DeferredContext.addActionFinish} result in a L{AlreadyFinished}\n        exception.\n        """"""\n        d = DeferredContext(Deferred())\n        d.addActionFinish()\n        self.assertRaises(AlreadyFinished, d.addActionFinish)\n\n    @withActionContext\n    def test_addCallbacksRaisesAfterAddActionFinish(self):\n        """"""\n        After L{DeferredContext.addActionFinish} is called, additional calls to\n        L{DeferredContext.addCallbacks} result in a L{AlreadyFinished}\n        exception.\n        """"""\n        d = DeferredContext(Deferred())\n        d.addActionFinish()\n        self.assertRaises(AlreadyFinished, d.addCallbacks, lambda x: x, lambda x: x)\n\n    @withActionContext\n    def test_addActionFinishResult(self):\n        """"""\n        L{DeferredContext.addActionFinish} returns the L{Deferred}.\n        """"""\n        d = Deferred()\n        self.assertIs(d, DeferredContext(d).addActionFinish())\n\n    # Having made sure DeferredContext.addCallbacks does the right thing\n    # regarding action contexts, for addCallback/addErrback/addBoth we only\n    # need to ensure that they call DeferredContext.addCallbacks.\n\n    @withActionContext\n    def test_addCallbackCallsAddCallbacks(self):\n        """"""\n        L{DeferredContext.addCallback} passes its arguments on to\n        L{DeferredContext.addCallbacks}.\n        """"""\n        result = Deferred()\n        context = DeferredContext(result)\n        called = []\n\n        def addCallbacks(\n            callback,\n            errback,\n            callbackArgs=None,\n            callbackKeywords=None,\n            errbackArgs=None,\n            errbackKeywords=None,\n        ):\n            called.append(\n                (\n                    callback,\n                    errback,\n                    callbackArgs,\n                    callbackKeywords,\n                    errbackArgs,\n                    errbackKeywords,\n                )\n            )\n\n        context.addCallbacks = addCallbacks\n\n        def f(x, y, z):\n            return None\n\n        context.addCallback(f, 2, z=3)\n        self.assertEqual(called, [(f, _passthrough, (2,), {""z"": 3}, None, None)])\n\n    @withActionContext\n    def test_addCallbackReturnsSelf(self):\n        """"""\n        L{DeferredContext.addCallback} returns the L{DeferredContext}.\n        """"""\n        result = Deferred()\n        context = DeferredContext(result)\n        self.assertIs(context, context.addCallback(lambda x: None))\n\n    @withActionContext\n    def test_addErrbackCallsAddCallbacks(self):\n        """"""\n        L{DeferredContext.addErrback} passes its arguments on to\n        L{DeferredContext.addCallbacks}.\n        """"""\n        result = Deferred()\n        context = DeferredContext(result)\n        called = []\n\n        def addCallbacks(\n            callback,\n            errback,\n            callbackArgs=None,\n            callbackKeywords=None,\n            errbackArgs=None,\n            errbackKeywords=None,\n        ):\n            called.append(\n                (\n                    callback,\n                    errback,\n                    callbackArgs,\n                    callbackKeywords,\n                    errbackArgs,\n                    errbackKeywords,\n                )\n            )\n\n        context.addCallbacks = addCallbacks\n\n        def f(x, y, z):\n            pass\n\n        context.addErrback(f, 2, z=3)\n        self.assertEqual(called, [(_passthrough, f, None, None, (2,), {""z"": 3})])\n\n    @withActionContext\n    def test_addErrbackReturnsSelf(self):\n        """"""\n        L{DeferredContext.addErrback} returns the L{DeferredContext}.\n        """"""\n        result = Deferred()\n        context = DeferredContext(result)\n        self.assertIs(context, context.addErrback(lambda x: None))\n\n    @withActionContext\n    def test_addBothCallsAddCallbacks(self):\n        """"""\n        L{DeferredContext.addBoth} passes its arguments on to\n        L{DeferredContext.addCallbacks}.\n        """"""\n        result = Deferred()\n        context = DeferredContext(result)\n        called = []\n\n        def addCallbacks(\n            callback,\n            errback,\n            callbackArgs=None,\n            callbackKeywords=None,\n            errbackArgs=None,\n            errbackKeywords=None,\n        ):\n            called.append(\n                (\n                    callback,\n                    errback,\n                    callbackArgs,\n                    callbackKeywords,\n                    errbackArgs,\n                    errbackKeywords,\n                )\n            )\n\n        context.addCallbacks = addCallbacks\n\n        def f(x, y, z):\n            return None\n\n        context.addBoth(f, 2, z=3)\n        self.assertEqual(called, [(f, f, (2,), {""z"": 3}, (2,), {""z"": 3})])\n\n    @withActionContext\n    def test_addBothReturnsSelf(self):\n        """"""\n        L{DeferredContext.addBoth} returns the L{DeferredContext}.\n        """"""\n        result = Deferred()\n        context = DeferredContext(result)\n        self.assertIs(context, context.addBoth(lambda x: None))\n\n\nclass RedirectLogsForTrialTests(TestCase):\n    """"""\n    Tests for L{redirectLogsForTrial}.\n    """"""\n\n    def assertDestinationAdded(self, programPath):\n        """"""\n        Assert that when running under the given program a new destination is\n        added by L{redirectLogsForTrial}.\n\n        @param programPath: A path to a program.\n        @type programPath: L{str}\n        """"""\n        destination = _RedirectLogsForTrial(FakeSys([programPath], b""""))()\n        self.assertIsInstance(destination, TwistedDestination)\n        # If this was not added as destination, removing it will raise an\n        # exception:\n        try:\n            removeDestination(destination)\n        except ValueError:\n            self.fail(""Destination was not added."")\n\n    def test_withTrial(self):\n        """"""\n        When C{sys.argv[0]} is C{""trial""} a new destination is added by\n        L{redirectLogsForTrial}.\n        """"""\n        self.assertDestinationAdded(""trial"")\n\n    def test_withAbsoluteTrialPath(self):\n        """"""\n        When C{sys.argv[0]} is an absolute path ending with C{""trial""} a new\n        destination is added by L{redirectLogsForTrial}.\n        """"""\n        self.assertDestinationAdded(""/usr/bin/trial"")\n\n    def test_withRelativeTrialPath(self):\n        """"""\n        When C{sys.argv[0]} is a relative path ending with C{""trial""} a new\n        destination is added by L{redirectLogsForTrial}.\n        """"""\n        self.assertDestinationAdded(""./trial"")\n\n    def test_withoutTrialNoDestination(self):\n        """"""\n        When C{sys.argv[0]} is not C{""trial""} no destination is added by\n        L{redirectLogsForTrial}.\n        """"""\n        originalDestinations = Logger._destinations._destinations[:]\n        _RedirectLogsForTrial(FakeSys([""myprogram.py""], b""""))()\n        self.assertEqual(Logger._destinations._destinations, originalDestinations)\n\n    def test_trialAsPathNoDestination(self):\n        """"""\n        When C{sys.argv[0]} has C{""trial""} as directory name but not program\n        name no destination is added by L{redirectLogsForTrial}.\n        """"""\n        originalDestinations = Logger._destinations._destinations[:]\n        _RedirectLogsForTrial(FakeSys([""./trial/myprogram.py""], b""""))()\n        self.assertEqual(Logger._destinations._destinations, originalDestinations)\n\n    def test_withoutTrialResult(self):\n        """"""\n        When not running under I{trial} L{None} is returned.\n        """"""\n        self.assertIs(None, _RedirectLogsForTrial(FakeSys([""myprogram.py""], b""""))())\n\n    def test_noDuplicateAdds(self):\n        """"""\n        If a destination has already been added, calling\n        L{redirectLogsForTrial} a second time does not add another destination.\n        """"""\n        redirect = _RedirectLogsForTrial(FakeSys([""trial""], b""""))\n        destination = redirect()\n        self.addCleanup(removeDestination, destination)\n        originalDestinations = Logger._destinations._destinations[:]\n        redirect()\n        self.assertEqual(Logger._destinations._destinations, originalDestinations)\n\n    def test_noDuplicateAddsResult(self):\n        """"""\n        If a destination has already been added, calling\n        L{redirectLogsForTrial} a second time returns L{None}.\n        """"""\n        redirect = _RedirectLogsForTrial(FakeSys([""trial""], b""""))\n        destination = redirect()\n        self.addCleanup(removeDestination, destination)\n        result = redirect()\n        self.assertIs(result, None)\n\n    def test_publicAPI(self):\n        """"""\n        L{redirectLogsForTrial} is an instance of L{_RedirectLogsForTrial}.\n        """"""\n        self.assertIsInstance(redirectLogsForTrial, _RedirectLogsForTrial)\n\n    def test_defaults(self):\n        """"""\n        By default L{redirectLogsForTrial} looks at L{sys.argv}.\n        """"""\n        self.assertEqual(redirectLogsForTrial._sys, sys)\n\n\nclass TwistedDestinationTests(TestCase):\n    """"""\n    Tests for L{TwistedDestination}.\n    """"""\n\n    def redirect_to_twisted(self):\n        """"""\n        Redirect Eliot logs to Twisted.\n\n        @return: L{list} of L{dict} - the log messages written to Twisted will\n             eventually be appended to this list.\n        """"""\n        written = []\n\n        def got_event(event):\n            if event.get(""log_namespace"") == ""eliot"":\n                written.append((event[""log_level""].name, event[""eliot""]))\n\n        globalLogPublisher.addObserver(got_event)\n        self.addCleanup(globalLogPublisher.removeObserver, got_event)\n        destination = TwistedDestination()\n        addDestination(destination)\n        self.addCleanup(removeDestination, destination)\n        return written\n\n    def redirect_to_list(self):\n        """"""\n        Redirect Eliot logs to a list.\n\n        @return: L{list} that will have eventually have the written Eliot\n            messages added to it.\n        """"""\n        written = []\n        destination = written.append\n        addDestination(destination)\n        self.addCleanup(removeDestination, destination)\n        return written\n\n    def test_normalMessages(self):\n        """"""\n        Regular eliot messages are pretty-printed to the given L{LogPublisher}.\n        """"""\n        writtenToTwisted = self.redirect_to_twisted()\n        written = self.redirect_to_list()\n        logger = Logger()\n        Message.new(x=123, y=456).write(logger)\n        self.assertEqual(writtenToTwisted, [(""info"", written[0])])\n\n    def test_tracebackMessages(self):\n        """"""\n        Traceback eliot messages are written to the given L{LogPublisher} with\n        the traceback formatted for easier reading.\n        """"""\n        writtenToTwisted = self.redirect_to_twisted()\n        written = self.redirect_to_list()\n        logger = Logger()\n\n        def raiser():\n            raise RuntimeError(""because"")\n\n        try:\n            raiser()\n        except Exception:\n            write_traceback(logger)\n        self.assertEqual(writtenToTwisted, [(""critical"", written[0])])\n\n\nclass InlineCallbacksTests(TestCase):\n    """"""Tests for C{inline_callbacks}.""""""\n\n    # Get our custom assertion failure messages *and* the standard ones.\n    longMessage = True\n\n    def _a_b_test(self, logger, g):\n        """"""A yield was done in between messages a and b inside C{inline_callbacks}.""""""\n        with start_action(action_type=""the-action""):\n            self.assertIs(None, self.successResultOf(g()))\n        assert_expected_action_tree(self, logger, ""the-action"", [""a"", ""yielded"", ""b""])\n\n    @capture_logging(None)\n    def test_yield_none(self, logger):\n        def g():\n            Message.log(message_type=""a"")\n            yield\n            Message.log(message_type=""b"")\n\n        g = inline_callbacks(g, debug=True)\n\n        self._a_b_test(logger, g)\n\n    @capture_logging(None)\n    def test_yield_fired_deferred(self, logger):\n        def g():\n            Message.log(message_type=""a"")\n            yield succeed(None)\n            Message.log(message_type=""b"")\n\n        g = inline_callbacks(g, debug=True)\n\n        self._a_b_test(logger, g)\n\n    @capture_logging(None)\n    def test_yield_unfired_deferred(self, logger):\n        waiting = Deferred()\n\n        def g():\n            Message.log(message_type=""a"")\n            yield waiting\n            Message.log(message_type=""b"")\n\n        g = inline_callbacks(g, debug=True)\n\n        with start_action(action_type=""the-action""):\n            d = g()\n            self.assertNoResult(waiting)\n            waiting.callback(None)\n            self.assertIs(None, self.successResultOf(d))\n        assert_expected_action_tree(self, logger, ""the-action"", [""a"", ""yielded"", ""b""])\n\n    @capture_logging(None)\n    def test_returnValue(self, logger):\n        result = object()\n\n        @inline_callbacks\n        def g():\n            if False:\n                yield\n            returnValue(result)\n\n        with start_action(action_type=""the-action""):\n            d = g()\n            self.assertIs(result, self.successResultOf(d))\n\n        assert_expected_action_tree(self, logger, ""the-action"", [])\n\n    @capture_logging(None)\n    def test_returnValue_in_action(self, logger):\n        result = object()\n\n        @inline_callbacks\n        def g():\n            if False:\n                yield\n            with start_action(action_type=""g""):\n                returnValue(result)\n\n        with start_action(action_type=""the-action""):\n            d = g()\n            self.assertIs(result, self.successResultOf(d))\n\n        assert_expected_action_tree(self, logger, ""the-action"", [{""g"": []}])\n\n    @capture_logging(None)\n    def test_nested_returnValue(self, logger):\n        result = object()\n        another = object()\n\n        def g():\n            d = h()\n            # Run h through to the end but ignore its result.\n            yield d\n            # Give back _our_ result.\n            returnValue(result)\n\n        g = inline_callbacks(g, debug=True)\n\n        def h():\n            yield\n            returnValue(another)\n\n        h = inline_callbacks(h, debug=True)\n\n        with start_action(action_type=""the-action""):\n            d = g()\n            self.assertIs(result, self.successResultOf(d))\n\n        assert_expected_action_tree(self, logger, ""the-action"", [""yielded"", ""yielded""])\n\n    @capture_logging(None)\n    def test_async_returnValue(self, logger):\n        result = object()\n        waiting = Deferred()\n\n        @inline_callbacks\n        def g():\n            yield waiting\n            returnValue(result)\n\n        with start_action(action_type=""the-action""):\n            d = g()\n            waiting.callback(None)\n            self.assertIs(result, self.successResultOf(d))\n\n    @capture_logging(None)\n    def test_nested_async_returnValue(self, logger):\n        result = object()\n        another = object()\n\n        waiting = Deferred()\n\n        @inline_callbacks\n        def g():\n            yield h()\n            returnValue(result)\n\n        @inline_callbacks\n        def h():\n            yield waiting\n            returnValue(another)\n\n        with start_action(action_type=""the-action""):\n            d = g()\n            waiting.callback(None)\n            self.assertIs(result, self.successResultOf(d))\n'"
eliot/tests/test_util.py,0,"b'""""""\nTests for L{eliot._util}.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom unittest import TestCase\nimport pprint\n\nfrom .._util import load_module\n\n\nclass LoadModuleTests(TestCase):\n    """"""\n    Tests for L{load_module}.\n    """"""\n\n    maxDiff = None\n\n    def test_returns_module(self):\n        """"""\n        L{load_module} returns an object with same methods as original module.\n        """"""\n        loaded = load_module(str(""copy""), pprint)\n        obj = [1, 2, b""hello""]\n        self.assertEqual(loaded.pformat(obj), pprint.pformat(obj))\n\n    def test_name(self):\n        """"""\n        L{load_module} returns an object with the given name.\n        """"""\n        name = str(""my_copy"")\n        loaded = load_module(name, pprint)\n        self.assertEqual(loaded.__name__, name)\n\n    def test_distinct_from_original(self):\n        """"""\n        L{load_module} returns a distinct object from the original module.\n        """"""\n        loaded = load_module(str(""copy""), pprint)\n        # Override repr in copy:\n        loaded.repr = lambda o: str(""OVERRIDE"")\n        # Demonstrate that override applies to copy but not original:\n        self.assertEqual(\n            dict(original=pprint.pformat(123), loaded=loaded.pformat(123)),\n            dict(original=""123"", loaded=""OVERRIDE""),\n        )\n'"
eliot/tests/test_validation.py,0,"b'""""""\nTests for L{eliot._validation}.\n""""""\n\nfrom __future__ import unicode_literals\n\nfrom unittest import TestCase\n\nfrom six import text_type as unicode\n\nfrom .._validation import (\n    Field,\n    MessageType,\n    ActionType,\n    ValidationError,\n    fields,\n    _MessageSerializer,\n)\nfrom .._action import start_action, startTask\nfrom .._output import MemoryLogger\nfrom ..serializers import identity\nfrom .. import add_destination, remove_destination\n\n\nclass TypedFieldTests(TestCase):\n    """"""\n    Tests for L{Field.forTypes}.\n    """"""\n\n    def test_validateCorrectType(self):\n        """"""\n        L{Field.validate} will not raise an exception if the given value is in\n        the list of supported classes.\n        """"""\n        field = Field.forTypes(""path"", [unicode, int], ""A path!"")\n        field.validate(123)\n        field.validate(""hello"")\n\n    def test_validateNone(self):\n        """"""\n        When given a ""class"" of C{None}, L{Field.validate} will support\n        validating C{None}.\n        """"""\n        field = Field.forTypes(""None"", [None], ""Nothing!"")\n        field.validate(None)\n\n    def test_validateWrongType(self):\n        """"""\n        L{Field.validate} will raise a L{ValidationError} exception if the\n        given value\'s type is not in the list of supported classes.\n        """"""\n        field = Field.forTypes(""key"", [int], ""An integer key"")\n        self.assertRaises(ValidationError, field.validate, ""lala"")\n        self.assertRaises(ValidationError, field.validate, None)\n        self.assertRaises(ValidationError, field.validate, object())\n\n    def test_extraValidatorPasses(self):\n        """"""\n        L{Field.validate} will not raise an exception if the extra validator\n        does not raise an exception.\n        """"""\n\n        def validate(i):\n            if i > 10:\n                return\n            else:\n                raise ValidationError(""too small"")\n\n        field = Field.forTypes(""key"", [int], ""An integer key"", validate)\n        field.validate(11)\n\n    def test_extraValidatorFails(self):\n        """"""\n        L{Field.validate} will raise a L{ValidationError} exception if the\n        extra validator raises one.\n        """"""\n\n        def validate(i):\n            if i > 10:\n                return\n            else:\n                raise ValidationError(""too small"")\n\n        field = Field.forTypes(""key"", [int], ""An int"", validate)\n        self.assertRaises(ValidationError, field.validate, 10)\n\n    def test_onlyValidTypes(self):\n        """"""\n        Only JSON supported types can be passed to L{Field.forTypes}.\n        """"""\n        self.assertRaises(TypeError, Field.forTypes, ""key"", [complex], ""Oops"")\n\n    def test_listIsValidType(self):\n        """"""\n        A C{list} is a valid type for L{Field.forTypes}.\n        """"""\n        Field.forTypes(""key"", [list], ""Oops"")\n\n    def test_dictIsValidType(self):\n        """"""\n        A C{dict} is a valid type for L{Field.forTypes}.\n        """"""\n        Field.forTypes(""key"", [dict], ""Oops"")\n\n\nclass FieldTests(TestCase):\n    """"""\n    Tests for L{Field}.\n    """"""\n\n    def test_description(self):\n        """"""\n        L{Field.description} stores the passed in description.\n        """"""\n        field = Field(""path"", identity, ""A path!"")\n        self.assertEqual(field.description, ""A path!"")\n\n    def test_optionalDescription(self):\n        """"""\n        L{Field} can be constructed with no description.\n        """"""\n        field = Field(""path"", identity)\n        self.assertEqual(field.description, """")\n\n    def test_key(self):\n        """"""\n        L{Field.key} stores the passed in field key.\n        """"""\n        field = Field(""path"", identity, ""A path!"")\n        self.assertEqual(field.key, ""path"")\n\n    def test_serialize(self):\n        """"""\n        L{Field.serialize} calls the given serializer function.\n        """"""\n        result = []\n        Field(""key"", result.append, ""field"").serialize(123)\n        self.assertEqual(result, [123])\n\n    def test_serializeResult(self):\n        """"""\n        L{Field.serialize} returns the result of the given serializer function.\n        """"""\n        result = Field(""key"", lambda obj: 456, ""field"").serialize(None)\n        self.assertEqual(result, 456)\n\n    def test_serializeCallsValidate(self):\n        """"""\n        L{Field.validate} calls the serializer, in case that raises an\n        exception for the given input.\n        """"""\n\n        class MyException(Exception):\n            pass\n\n        def serialize(obj):\n            raise MyException()\n\n        field = Field(""key"", serialize, """")\n        self.assertRaises(MyException, field.validate, 123)\n\n    def test_noExtraValidator(self):\n        """"""\n        L{Field.validate} doesn\'t break if there is no extra validator.\n        """"""\n        field = Field(""key"", identity, """")\n        field.validate(123)\n\n    def test_extraValidatorPasses(self):\n        """"""\n        L{Field.validate} will not raise an exception if the extra validator\n        does not raise an exception.\n        """"""\n\n        def validate(i):\n            if i > 10:\n                return\n            else:\n                raise ValidationError(""too small"")\n\n        field = Field(""path"", identity, ""A path!"", validate)\n        field.validate(11)\n\n    def test_extraValidatorFails(self):\n        """"""\n        L{Field.validate} will raise a L{ValidationError} exception if the\n        extra validator raises one.\n        """"""\n\n        def validate(i):\n            if i > 10:\n                return\n            else:\n                raise ValidationError(""too small"")\n\n        field = Field(""path"", identity, ""A path!"", validate)\n        self.assertRaises(ValidationError, field.validate, 10)\n\n\nclass FieldForValueTests(TestCase):\n    """"""\n    Tests for L{Field.forValue}.\n    """"""\n\n    def test_forValue(self):\n        """"""\n        L{Field.forValue} creates a L{Field} with the given key and description.\n        """"""\n        field = Field.forValue(""key"", None, ""description"")\n        self.assertEqual(field.key, ""key"")\n        self.assertEqual(field.description, ""description"")\n\n    def test_forValueGoodValue(self):\n        """"""\n        The L{Field.forValue}-created L{Field} validates the value it was\n        constructed with.\n        """"""\n        field = Field.forValue(""key"", 1234, ""description"")\n        field.validate(1234)\n\n    def test_valueFieldWrongValue(self):\n        """"""\n        The L{Field.forValue}-created L{Field} raises a L{ValidationError} for\n        different values.\n        """"""\n        field = Field.forValue(""key"", 1234, ""description"")\n        self.assertRaises(ValidationError, field.validate, 5678)\n\n    def test_serialize(self):\n        """"""\n        The L{Field.forValue}-created L{Field} returns the given object when\n        serializing, regardless of input.\n\n        If the caller is buggy, no need to log garbage if we know what needs\n        logging. These bugs will be caught by unit tests, anyway, if author of\n        code is doing things correctly.\n        """"""\n        field = Field.forValue(""key"", 1234, ""description"")\n        self.assertEqual(field.serialize(None), 1234)\n\n\nclass FieldsTests(TestCase):\n    """"""\n    Tests for L{fields}.\n    """"""\n\n    def test_positional(self):\n        """"""\n        L{fields} accepts positional arguments of L{Field} instances and\n        combines them with fields specied as keyword arguments.\n        """"""\n        a_field = Field(""akey"", identity)\n        l = fields(a_field, another=str)\n        self.assertIn(a_field, l)\n        self.assertEqual(\n            {(type(field), field.key) for field in l},\n            {(Field, ""akey""), (Field, ""another"")},\n        )\n\n    def test_keys(self):\n        """"""\n        L{fields} creates L{Field} instances with the given keys.\n        """"""\n        l = fields(key=int, status=str)\n        self.assertEqual(\n            {(type(field), field.key) for field in l},\n            {(Field, ""key""), (Field, ""status"")},\n        )\n\n    def test_validTypes(self):\n        """"""\n        The L{Field} instances constructed by L{fields} validate the specified\n        types.\n        """"""\n        (field,) = fields(key=int)\n        self.assertRaises(ValidationError, field.validate, ""abc"")\n\n    def test_noSerialization(self):\n        """"""\n        The L{Field} instances constructed by L{fields} do no special\n        serialization.\n        """"""\n        (field,) = fields(key=int)\n        self.assertEqual(field.serialize(""abc""), ""abc"")\n\n\nclass MessageSerializerTests(TestCase):\n    """"""\n    Tests for L{_MessageSerializer}.\n    """"""\n\n    def test_noMultipleFields(self):\n        """"""\n        L{_MessageSerializer.__init__} will raise a L{ValueError} exception if\n        constructed with more than object per field name.\n        """"""\n        self.assertRaises(\n            ValueError,\n            _MessageSerializer,\n            [\n                Field(""akey"", identity, """"),\n                Field(""akey"", identity, """"),\n                Field(""message_type"", identity, """"),\n            ],\n        )\n\n    def test_noBothTypeFields(self):\n        """"""\n        L{_MessageSerializer.__init__} will raise a L{ValueError} exception if\n        constructed with both a C{""message_type""} and C{""action_type""} field.\n        """"""\n        self.assertRaises(\n            ValueError,\n            _MessageSerializer,\n            [Field(""message_type"", identity, """"), Field(""action_type"", identity, """")],\n        )\n\n    def test_missingTypeField(self):\n        """"""\n        L{_MessageSerializer.__init__} will raise a L{ValueError} if there is\n        neither a C{""message_type""} nor a C{""action_type""} field.\n        """"""\n        self.assertRaises(ValueError, _MessageSerializer, [])\n\n    def test_noTaskLevel(self):\n        """"""\n        L{_MessageSerializer.__init__} will raise a L{ValueError} if there is\n        a C{""task_level""} field included.\n        """"""\n        self.assertRaises(\n            ValueError,\n            _MessageSerializer,\n            [Field(""message_type"", identity, """"), Field(""task_level"", identity, """")],\n        )\n\n    def test_noTaskUuid(self):\n        """"""\n        L{_MessageSerializer.__init__} will raise a L{ValueError} if there is\n        a C{""task_uuid""} field included.\n        """"""\n        self.assertRaises(\n            ValueError,\n            _MessageSerializer,\n            [Field(""message_type"", identity, """"), Field(""task_uuid"", identity, """")],\n        )\n\n    def test_noTimestamp(self):\n        """"""\n        L{_MessageSerializer.__init__} will raise a L{ValueError} if there is\n        a C{""timestamp""} field included.\n        """"""\n        self.assertRaises(\n            ValueError,\n            _MessageSerializer,\n            [Field(""message_type"", identity, """"), Field(""timestamp"", identity, """")],\n        )\n\n    def test_noUnderscoreStart(self):\n        """"""\n        L{_MessageSerializer.__init__} will raise a L{ValueError} if there is\n        a field included whose name starts with C{""_""}.\n        """"""\n        self.assertRaises(\n            ValueError,\n            _MessageSerializer,\n            [Field(""message_type"", identity, """"), Field(""_key"", identity, """")],\n        )\n\n    def test_serialize(self):\n        """"""\n        L{_MessageSerializer.serialize} will serialize all values in the given\n        dictionary using the respective L{Field}.\n        """"""\n        serializer = _MessageSerializer(\n            [\n                Field.forValue(""message_type"", ""mymessage"", ""The type""),\n                Field(""length"", len, ""The length of a thing""),\n            ]\n        )\n        message = {""message_type"": ""mymessage"", ""length"": ""thething""}\n        serializer.serialize(message)\n        self.assertEqual(message, {""message_type"": ""mymessage"", ""length"": 8})\n\n    def test_missingSerializer(self):\n        """"""\n        If a value in the dictionary passed to L{_MessageSerializer.serialize}\n        has no respective field, it is unchanged.\n\n        Logging attempts to capture everything, with minimal work; with any\n        luck this value is JSON-encodable. Unit tests should catch such bugs, in any case.\n        """"""\n        serializer = _MessageSerializer(\n            [\n                Field.forValue(""message_type"", ""mymessage"", ""The type""),\n                Field(""length"", len, ""The length of a thing""),\n            ]\n        )\n        message = {""message_type"": ""mymessage"", ""length"": ""thething"", ""extra"": 123}\n        serializer.serialize(message)\n        self.assertEqual(\n            message, {""message_type"": ""mymessage"", ""length"": 8, ""extra"": 123}\n        )\n\n    def test_fieldInstances(self):\n        """"""\n        Fields to L{_MessageSerializer.__init__} should be instances of\n        L{Field}.\n        """"""\n        a_field = Field(""a_key"", identity)\n        arg = object()\n        with self.assertRaises(TypeError) as cm:\n            _MessageSerializer([a_field, arg])\n        self.assertEqual((""Expected a Field instance but got"", arg), cm.exception.args)\n\n\nclass MessageTypeTests(TestCase):\n    """"""\n    Tests for L{MessageType}.\n    """"""\n\n    def messageType(self):\n        """"""\n        Return a L{MessageType} suitable for unit tests.\n        """"""\n        return MessageType(\n            ""myapp:mysystem"",\n            [Field.forTypes(""key"", [int], """"), Field.forTypes(""value"", [int], """")],\n            ""A message type"",\n        )\n\n    def test_validateMissingType(self):\n        """"""\n        L{MessageType._serializer.validate} raises a L{ValidationError} exception if the\n        given dictionary has no C{""message_type""} field.\n        """"""\n        messageType = self.messageType()\n        self.assertRaises(\n            ValidationError, messageType._serializer.validate, {""key"": 1, ""value"": 2}\n        )\n\n    def test_validateWrongType(self):\n        """"""\n        L{MessageType._serializer.validate} raises a L{ValidationError}\n        exception if the given dictionary has the wrong value for the\n        C{""message_type""} field.\n        """"""\n        messageType = self.messageType()\n        self.assertRaises(\n            ValidationError,\n            messageType._serializer.validate,\n            {""key"": 1, ""value"": 2, ""message_type"": ""wrong""},\n        )\n\n    def test_validateExtraField(self):\n        """"""\n        L{MessageType._serializer.validate} raises a L{ValidationError}\n        exception if the given dictionary has an extra unknown field.\n        """"""\n        messageType = self.messageType()\n        self.assertRaises(\n            ValidationError,\n            messageType._serializer.validate,\n            {""key"": 1, ""value"": 2, ""message_type"": ""myapp:mysystem"", ""extra"": ""hello""},\n        )\n\n    def test_validateMissingField(self):\n        """"""\n        L{MessageType._serializer.validate} raises a L{ValidationError}\n        exception if the given dictionary has a missing field.\n        """"""\n        messageType = self.messageType()\n        self.assertRaises(\n            ValidationError,\n            messageType._serializer.validate,\n            {""key"": 1, ""message_type"": ""myapp:mysystem""},\n        )\n\n    def test_validateFieldValidation(self):\n        """"""\n        L{MessageType._serializer.validate} raises a L{ValidationError}\n        exception if the one of the field values fails field-specific\n        validation.\n        """"""\n        messageType = self.messageType()\n        self.assertRaises(\n            ValidationError,\n            messageType._serializer.validate,\n            {""key"": 1, ""value"": None, ""message_type"": ""myapp:mysystem""},\n        )\n\n    def test_validateStandardFields(self):\n        """"""\n        L{MessageType._serializer.validate} does not raise an exception if the\n        dictionary has the standard fields that are added to all messages.\n        """"""\n        messageType = self.messageType()\n        messageType._serializer.validate(\n            {\n                ""key"": 1,\n                ""value"": 2,\n                ""message_type"": ""myapp:mysystem"",\n                ""task_level"": ""/"",\n                ""task_uuid"": ""123"",\n                ""timestamp"": ""xxx"",\n            }\n        )\n\n    def test_call(self):\n        """"""\n        L{MessageType.__call__} creates a new L{Message} with correct\n        C{message_type} field value added.\n        """"""\n        messageType = self.messageType()\n        message = messageType()\n        self.assertEqual(message._contents, {""message_type"": messageType.message_type})\n\n    def test_callSerializer(self):\n        """"""\n        L{MessageType.__call__} creates a new L{Message} with the\n        L{MessageType._serializer} as its serializer.\n        """"""\n        messageType = self.messageType()\n        message = messageType()\n        self.assertIs(message._serializer, messageType._serializer)\n\n    def test_callWithFields(self):\n        """"""\n        L{MessageType.__call__} creates a new L{Message} with the additional\n        given fields.\n        """"""\n        messageType = self.messageType()\n        message = messageType(key=2, value=3)\n        self.assertEqual(\n            message._contents,\n            {""message_type"": messageType.message_type, ""key"": 2, ""value"": 3},\n        )\n\n    def test_logCallsDefaultLoggerWrite(self):\n        """"""\n        L{MessageType.log} calls the given logger\'s C{write} method with a\n        dictionary that is superset of the L{Message} contents.\n        """"""\n        messages = []\n        add_destination(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n        message_type = self.messageType()\n        message_type.log(key=1234, value=3)\n        self.assertEqual(messages[0][""key""], 1234)\n        self.assertEqual(messages[0][""value""], 3)\n        self.assertEqual(messages[0][""message_type""], message_type.message_type)\n\n    def test_description(self):\n        """"""\n        L{MessageType.description} stores the passed in description.\n        """"""\n        messageType = self.messageType()\n        self.assertEqual(messageType.description, ""A message type"")\n\n    def test_optionalDescription(self):\n        """"""\n        L{MessageType} can be constructed without a description.\n        """"""\n        messageType = MessageType(""name"", [])\n        self.assertEqual(messageType.description, """")\n\n\nclass ActionTypeTestsMixin(object):\n    """"""\n    Mixin for tests for the three L{ActionType} message variants.\n    """"""\n\n    def getValidMessage(self):\n        """"""\n        Return a dictionary of a message that is of the action status being\n        tested.\n        """"""\n        raise NotImplementedError(""Override in subclasses"")\n\n    def getSerializer(self, actionType):\n        """"""\n        Given a L{ActionType}, return the L{_MessageSerializer} for this\n        variant.\n        """"""\n        raise NotImplementedError(""Override in subclasses"")\n\n    def actionType(self):\n        """"""\n        Return a L{ActionType} suitable for unit tests.\n        """"""\n        return ActionType(\n            ""myapp:mysystem:myaction"",\n            [Field.forTypes(""key"", [int], """")],  # start fields\n            [Field.forTypes(""value"", [int], """")],  # success fields\n            ""A action type"",\n        )\n\n    def test_validateMissingType(self):\n        """"""\n        L{ActionType.validate} raises a L{ValidationError} exception if the\n        given dictionary has no C{""action_type""} field.\n        """"""\n        actionType = self.actionType()\n        message = self.getValidMessage()\n        del message[""action_type""]\n        self.assertRaises(\n            ValidationError, self.getSerializer(actionType).validate, message\n        )\n\n    def test_validateWrongType(self):\n        """"""\n        L{ActionType.validate} raises a L{ValidationError} exception if the\n        given dictionary has the wrong value for the C{""action_type""} field.\n        """"""\n        actionType = self.actionType()\n        message = self.getValidMessage()\n        message[""action_type""] = ""xxx""\n        self.assertRaises(\n            ValidationError, self.getSerializer(actionType).validate, message\n        )\n\n    def test_validateExtraField(self):\n        """"""\n        L{ActionType.validate} raises a L{ValidationError} exception if the\n        given dictionary has an extra unknown field.\n        """"""\n        actionType = self.actionType()\n        message = self.getValidMessage()\n        message[""extra""] = ""ono""\n        self.assertRaises(\n            ValidationError, self.getSerializer(actionType).validate, message\n        )\n\n    def test_validateMissingField(self):\n        """"""\n        L{ActionType.validate} raises a L{ValidationError} exception if the\n        given dictionary has a missing field.\n        """"""\n        actionType = self.actionType()\n        message = self.getValidMessage()\n        for key in message:\n            if key != ""action_type"":\n                del message[key]\n                break\n        self.assertRaises(\n            ValidationError, self.getSerializer(actionType).validate, message\n        )\n\n    def test_validateFieldValidation(self):\n        """"""\n        L{ActionType.validate} raises a L{ValidationError} exception if the\n        one of the field values fails field-specific validation.\n        """"""\n        actionType = self.actionType()\n        message = self.getValidMessage()\n        for key in message:\n            if key != ""action_type"":\n                message[key] = object()\n                break\n        self.assertRaises(\n            ValidationError, self.getSerializer(actionType).validate, message\n        )\n\n    def test_validateStandardFields(self):\n        """"""\n        L{ActionType.validate} does not raise an exception if the dictionary\n        has the standard fields that are added to all messages.\n        """"""\n        actionType = self.actionType()\n        message = self.getValidMessage()\n        message.update({""task_level"": ""/"", ""task_uuid"": ""123"", ""timestamp"": ""xxx""})\n        self.getSerializer(actionType).validate(message)\n\n\nclass ActionTypeStartMessage(TestCase, ActionTypeTestsMixin):\n    """"""\n    Tests for L{ActionType} validation of action start messages.\n    """"""\n\n    def getValidMessage(self):\n        """"""\n        Return a dictionary of a valid action start message.\n        """"""\n        return {\n            ""action_type"": ""myapp:mysystem:myaction"",\n            ""action_status"": ""started"",\n            ""key"": 1,\n        }\n\n    def getSerializer(self, actionType):\n        return actionType._serializers.start\n\n\nclass ActionTypeSuccessMessage(TestCase, ActionTypeTestsMixin):\n    """"""\n    Tests for L{ActionType} validation of action success messages.\n    """"""\n\n    def getValidMessage(self):\n        """"""\n        Return a dictionary of a valid action success message.\n        """"""\n        return {\n            ""action_type"": ""myapp:mysystem:myaction"",\n            ""action_status"": ""succeeded"",\n            ""value"": 2,\n        }\n\n    def getSerializer(self, actionType):\n        return actionType._serializers.success\n\n\nclass ActionTypeFailureMessage(TestCase, ActionTypeTestsMixin):\n    """"""\n    Tests for L{ActionType} validation of action failure messages.\n    """"""\n\n    def getValidMessage(self):\n        """"""\n        Return a dictionary of a valid action failure message.\n        """"""\n        return {\n            ""action_type"": ""myapp:mysystem:myaction"",\n            ""action_status"": ""failed"",\n            ""exception"": ""exceptions.RuntimeError"",\n            ""reason"": ""because"",\n        }\n\n    def getSerializer(self, actionType):\n        return actionType._serializers.failure\n\n    def test_validateExtraField(self):\n        """"""\n        Additional fields (which can be added by exception extraction) don\'t\n        cause a validation failure for failed action messages.\n        """"""\n        actionType = self.actionType()\n        message = self.getValidMessage()\n        message.update({""task_level"": ""/"", ""task_uuid"": ""123"", ""timestamp"": ""xxx""})\n        message.update({""extra_field"": ""hello""})\n        self.getSerializer(actionType).validate(message)\n\n\nclass ChildActionTypeStartMessage(TestCase):\n    """"""\n    Tests for validation of child actions created with L{ActionType}.\n    """"""\n\n    def test_childActionUsesChildValidator(self):\n        """"""\n        Validation of child actions uses the child\'s validator.\n        """"""\n        A = ActionType(""myapp:foo"", [Field.forTypes(""a"", [int], """")], [], """")\n        B = ActionType(""myapp:bar"", [Field.forTypes(""b"", [int], """")], [], """")\n\n        logger = MemoryLogger()\n\n        with A(logger, a=1):\n            with B(logger, b=2):\n                pass\n        # If wrong serializers/validators were used, this will fail:\n        logger.validate()\n\n\nclass ActionTypeTests(TestCase):\n    """"""\n    General tests for L{ActionType}.\n    """"""\n\n    def actionType(self):\n        """"""\n        Return a L{ActionType} suitable for unit tests.\n        """"""\n        return ActionType(""myapp:mysystem:myaction"", [], [], ""An action type"")\n\n    def test_call(self):\n        """"""\n        L{ActionType.__call__} returns the result of calling\n        C{self._start_action}.\n        """"""\n        actionType = self.actionType()\n        actionType._start_action = lambda *args, **kwargs: 1234\n        result = actionType(object())\n        self.assertEqual(result, 1234)\n\n    def test_callArguments(self):\n        """"""\n        L{ActionType.__call__} calls C{self._start_action} with the logger,\n        action type, serializers and passed in fields.\n        """"""\n        called = []\n        actionType = self.actionType()\n        actionType._start_action = lambda *args, **kwargs: called.append((args, kwargs))\n        logger = object()\n        actionType(logger, key=5)\n        self.assertEqual(\n            called,\n            [\n                (\n                    (logger, ""myapp:mysystem:myaction"", actionType._serializers),\n                    {""key"": 5},\n                )\n            ],\n        )\n\n    def test_defaultStartAction(self):\n        """"""\n        L{ActionType._start_action} is L{eliot.start_action} by default.\n        """"""\n        self.assertEqual(ActionType._start_action, start_action)\n\n    def test_as_task(self):\n        """"""\n        L{ActionType.as_task} returns the result of calling C{self._startTask}.\n        """"""\n        actionType = self.actionType()\n        actionType._startTask = lambda *args, **kwargs: 1234\n        result = actionType.as_task(object())\n        self.assertEqual(result, 1234)\n\n    def test_as_taskArguments(self):\n        """"""\n        L{ActionType.as_task} calls C{self._startTask} with the logger,\n        action type and passed in fields.\n        """"""\n        called = []\n        actionType = self.actionType()\n        actionType._startTask = lambda *args, **kwargs: called.append((args, kwargs))\n        logger = object()\n        actionType.as_task(logger, key=5)\n        self.assertEqual(\n            called,\n            [\n                (\n                    (logger, ""myapp:mysystem:myaction"", actionType._serializers),\n                    {""key"": 5},\n                )\n            ],\n        )\n\n    def test_defaultStartTask(self):\n        """"""\n        L{ActionType._startTask} is L{eliot.startTask} by default.\n        """"""\n        self.assertEqual(ActionType._startTask, startTask)\n\n    def test_description(self):\n        """"""\n        L{ActionType.description} stores the passed in description.\n        """"""\n        actionType = self.actionType()\n        self.assertEqual(actionType.description, ""An action type"")\n\n    def test_optionalDescription(self):\n        """"""\n        L{ActionType} can be constructed without a description.\n        """"""\n        actionType = ActionType(""name"", [], [])\n        self.assertEqual(actionType.description, """")\n\n    def test_as_taskDefaultLogger(self):\n        """"""\n        L{ActionType.as_task} doesn\'t require passing in a logger.\n        """"""\n        actionType = self.actionType()\n        actionType.as_task(key=5)\n\n\nclass EndToEndValidationTests(TestCase):\n    """"""\n    Test validation of messages created using L{MessageType} and\n    L{ActionType}.\n    """"""\n\n    MESSAGE = MessageType(\n        ""myapp:mymessage"",\n        [Field.forTypes(""key"", [int], ""The key"")],\n        ""A message for testing."",\n    )\n    ACTION = ActionType(\n        ""myapp:myaction"",\n        [Field.forTypes(""key"", [int], ""The key"")],\n        [Field.forTypes(""result"", [unicode], ""The result"")],\n        ""An action for testing."",\n    )\n\n    def test_correctFromMessageType(self):\n        """"""\n        A correct message created using L{MessageType} will be logged to a\n        L{MemoryLogger}.\n        """"""\n        logger = MemoryLogger()\n        msg = self.MESSAGE().bind(key=123)\n        msg.write(logger)\n        self.assertEqual(logger.messages[0][""key""], 123)\n\n    def test_incorrectFromMessageType(self):\n        """"""\n        An incorrect message created using L{MessageType} will raise a\n        L{ValidationError} in L{MemoryLogger.validate}.\n        """"""\n        logger = MemoryLogger()\n        msg = self.MESSAGE().bind(key=""123"")\n        msg.write(logger)\n        self.assertRaises(ValidationError, logger.validate)\n\n    def test_correctStartFromActionType(self):\n        """"""\n        A correct start message created using a L{ActionType} will be logged\n        to a L{MemoryLogger}.\n        """"""\n        logger = MemoryLogger()\n        with self.ACTION(logger, key=123) as action:\n            action.addSuccessFields(result=""foo"")\n        self.assertEqual(logger.messages[0][""key""], 123)\n\n    def test_omitLoggerFromActionType(self):\n        """"""\n        If no logger is given to the L{ActionType} the default logger is used.\n        """"""\n        messages = []\n        add_destination(messages.append)\n        self.addCleanup(remove_destination, messages.append)\n        with self.ACTION(key=123) as action:\n            action.add_success_fields(result=""foo"")\n        self.assertEqual(messages[0][""key""], 123)\n\n    def test_incorrectStartFromActionType(self):\n        """"""\n        An incorrect start message created using a L{ActionType} will raise a\n        L{ValidationError}.\n        """"""\n        logger = MemoryLogger()\n        with self.ACTION(logger, key=""123"") as action:\n            action.addSuccessFields(result=""foo"")\n        self.assertRaises(ValidationError, logger.validate)\n\n    def test_correctSuccessFromActionType(self):\n        """"""\n        A correct success message created using a L{ActionType} will be logged\n        to a L{MemoryLogger}.\n        """"""\n        logger = MemoryLogger()\n        with self.ACTION(logger, key=123) as action:\n            action.addSuccessFields(result=""foo"")\n        self.assertEqual(logger.messages[1][""result""], ""foo"")\n\n    def test_incorrectSuccessFromActionType(self):\n        """"""\n        An incorrect success message created using a L{ActionType} will raise a\n        L{ValidationError}.\n        """"""\n        logger = MemoryLogger()\n        with self.ACTION(logger, key=123) as action:\n            action.addSuccessFields(result=-1)\n        self.assertRaises(ValidationError, logger.validate)\n\n    def test_correctFailureFromActionType(self):\n        """"""\n        A correct failure message created using a L{ActionType} will be logged\n        to a L{MemoryLogger}.\n        """"""\n        logger = MemoryLogger()\n\n        def run():\n            with self.ACTION(logger, key=123):\n                raise RuntimeError(""hello"")\n\n        self.assertRaises(RuntimeError, run)\n        self.assertEqual(logger.messages[1][""reason""], ""hello"")\n\n\nclass PEP8Tests(TestCase):\n    """"""\n    Tests for PEP 8 method compatibility.\n    """"""\n\n    def test_for_value(self):\n        """"""\n        L{Field.for_value} is the same as L{Field.forValue}.\n        """"""\n        self.assertEqual(Field.for_value, Field.forValue)\n\n    def test_for_types(self):\n        """"""\n        L{Field.for_types} is the same as L{Field.forTypes}.\n        """"""\n        self.assertEqual(Field.for_types, Field.forTypes)\n\n    def test_as_task(self):\n        """"""\n        L{ActionType.as_task} is the same as L{ActionType.asTask}.\n        """"""\n        self.assertEqual(ActionType.as_task, ActionType.asTask)\n'"
presentations/bostonpython-2018/watchtower.py,0,"b'import sys\n\nfrom eliot import start_action, to_file, Message\nto_file(sys.stdout)\n\n\nrider1 = ""Alice""\nrider2 = ""Bob""\nwildcat = ""Whiskers the Wildcat""\n\n\nwith start_action(action_type=""outside"", weather=""cold"",\n                  location=""distance""):\n    with start_action(action_type=""approach"",\n                      who=[rider1, rider2]):\n        with start_action(action_type=""growl"", who=wildcat):\n            pass\n    Message.log(message_type=""wind:howl"")\n'"
presentations/scientific-logging/badmath.py,0,"b'from eliot import log_call, to_file\nimport sys\nto_file(open(""out.log"", ""a""))\n\n@log_call\ndef add(a, b):\n    return a + b\n\n@log_call\ndef multiply(a, b):\n    return 0 * b\n\n@log_call\ndef multiplysum(a, b, c):\n    return multiply(add(a, b), c)\n\nprint(multiplysum(1, 2, 4)) # should print 12\n'"
presentations/scientific-logging/slow.py,0,"b'from eliot import log_call, to_file\nimport sys\nto_file(open(""out.log"", ""w""))\n\n@log_call\ndef double(a):\n    if a == 0:\n        import time\n        time.sleep(10)\n    return a * 2\n\n@log_call\ndef main():\n    double(13)\n    double(0)\n    double(4)\n\nmain()\n'"
