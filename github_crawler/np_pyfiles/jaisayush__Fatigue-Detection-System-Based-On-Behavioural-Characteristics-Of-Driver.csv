file_path,api_count,code
blinkDetect.py,7,"b'""""""\nTODO:\n    - Improve face landmark detection. Probably caused due to lighting changes. Eliminate the effect of lightinh with minimal computation.\n      Solved by histogram equalization\n\n    - Stabilize face landmark points\n\n    - Gaze direction\n\n""""""\n\nimport dlib\nimport sys\nimport cv2\nimport time\nimport numpy as np\nfrom scipy.spatial import distance as dist\nfrom threading import Thread\nimport playsound\nimport queue\n# from light_variability import adjust_gamma\n\nFACE_DOWNSAMPLE_RATIO = 1.5\nRESIZE_HEIGHT = 460\n\nthresh = 0.27\nmodelPath = ""models/shape_predictor_70_face_landmarks.dat""\nsound_path = ""alarm.wav""\n\ndetector = dlib.get_frontal_face_detector()\npredictor = dlib.shape_predictor(modelPath)\n\nleftEyeIndex = [36, 37, 38, 39, 40, 41]\nrightEyeIndex = [42, 43, 44, 45, 46, 47]\n\nblinkCount = 0\ndrowsy = 0\nstate = 0\nblinkTime = 0.15 #150ms\ndrowsyTime = 1.5  #1200ms\nALARM_ON = False\nGAMMA = 1.5\nthreadStatusQ = queue.Queue()\n\ninvGamma = 1.0/GAMMA\ntable = np.array([((i / 255.0) ** invGamma) * 255 for i in range(0, 256)]).astype(""uint8"")\n\ndef gamma_correction(image):\n    return cv2.LUT(image, table)\n\ndef histogram_equalization(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    return cv2.equalizeHist(gray) \n\ndef soundAlert(path, threadStatusQ):\n    while True:\n        if not threadStatusQ.empty():\n            FINISHED = threadStatusQ.get()\n            if FINISHED:\n                break\n        playsound.playsound(path)\n\ndef eye_aspect_ratio(eye):\n    A = dist.euclidean(eye[1], eye[5])\n    B = dist.euclidean(eye[2], eye[4])\n    C = dist.euclidean(eye[0], eye[3])\n    ear = (A + B) / (2.0 * C)\n\n    return ear\n\n\ndef checkEyeStatus(landmarks):\n    mask = np.zeros(frame.shape[:2], dtype = np.float32)\n    \n    hullLeftEye = []\n    for i in range(0, len(leftEyeIndex)):\n        hullLeftEye.append((landmarks[leftEyeIndex[i]][0], landmarks[leftEyeIndex[i]][1]))\n\n    cv2.fillConvexPoly(mask, np.int32(hullLeftEye), 255)\n\n    hullRightEye = []\n    for i in range(0, len(rightEyeIndex)):\n        hullRightEye.append((landmarks[rightEyeIndex[i]][0], landmarks[rightEyeIndex[i]][1]))\n\n\n    cv2.fillConvexPoly(mask, np.int32(hullRightEye), 255)\n\n    # lenLeftEyeX = landmarks[leftEyeIndex[3]][0] - landmarks[leftEyeIndex[0]][0]\n    # lenLeftEyeY = landmarks[leftEyeIndex[3]][1] - landmarks[leftEyeIndex[0]][1]\n\n    # lenLeftEyeSquared = (lenLeftEyeX ** 2) + (lenLeftEyeY ** 2)\n    # eyeRegionCount = cv2.countNonZero(mask)\n\n    # normalizedCount = eyeRegionCount/np.float32(lenLeftEyeSquared)\n\n    #############################################################################\n    leftEAR = eye_aspect_ratio(hullLeftEye)\n    rightEAR = eye_aspect_ratio(hullRightEye)\n\n    ear = (leftEAR + rightEAR) / 2.0\n    #############################################################################\n\n    eyeStatus = 1          # 1 -> Open, 0 -> closed\n    if (ear < thresh):\n        eyeStatus = 0\n\n    return eyeStatus  \n\ndef checkBlinkStatus(eyeStatus):\n    global state, blinkCount, drowsy\n    if(state >= 0 and state <= falseBlinkLimit):\n        if(eyeStatus):\n            state = 0\n\n        else:\n            state += 1\n\n    elif(state >= falseBlinkLimit and state < drowsyLimit):\n        if(eyeStatus):\n            blinkCount += 1 \n            state = 0\n\n        else:\n            state += 1\n\n\n    else:\n        if(eyeStatus):\n            state = 0\n            drowsy = 1\n            blinkCount += 1\n\n        else:\n            drowsy = 1\n\ndef getLandmarks(im):\n    imSmall = cv2.resize(im, None, \n                            fx = 1.0/FACE_DOWNSAMPLE_RATIO, \n                            fy = 1.0/FACE_DOWNSAMPLE_RATIO, \n                            interpolation = cv2.INTER_LINEAR)\n\n    rects = detector(imSmall, 0)\n    if len(rects) == 0:\n        return 0\n\n    newRect = dlib.rectangle(int(rects[0].left() * FACE_DOWNSAMPLE_RATIO),\n                            int(rects[0].top() * FACE_DOWNSAMPLE_RATIO),\n                            int(rects[0].right() * FACE_DOWNSAMPLE_RATIO),\n                            int(rects[0].bottom() * FACE_DOWNSAMPLE_RATIO))\n\n    points = []\n    [points.append((p.x, p.y)) for p in predictor(im, newRect).parts()]\n    return points\n\ncapture = cv2.VideoCapture(0)\n\nfor i in range(10):\n    ret, frame = capture.read()\n\ntotalTime = 0.0\nvalidFrames = 0\ndummyFrames = 100\n\nprint(""Caliberation in Progress!"")\nwhile(validFrames < dummyFrames):\n    validFrames += 1\n    t = time.time()\n    ret, frame = capture.read()\n    height, width = frame.shape[:2]\n    IMAGE_RESIZE = np.float32(height)/RESIZE_HEIGHT\n    frame = cv2.resize(frame, None, \n                        fx = 1/IMAGE_RESIZE, \n                        fy = 1/IMAGE_RESIZE, \n                        interpolation = cv2.INTER_LINEAR)\n\n    # adjusted = gamma_correction(frame)\n    adjusted = histogram_equalization(frame)\n\n    landmarks = getLandmarks(adjusted)\n    timeLandmarks = time.time() - t\n\n    if landmarks == 0:\n        validFrames -= 1\n        cv2.putText(frame, ""Unable to detect face, Please check proper lighting"", (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n        cv2.putText(frame, ""or decrease FACE_DOWNSAMPLE_RATIO"", (10, 50), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n        cv2.imshow(""Blink Detection Demo"", frame)\n        if cv2.waitKey(1) & 0xFF == 27:\n            sys.exit()\n\n    else:\n        totalTime += timeLandmarks\n        # cv2.putText(frame, ""Caliberation in Progress"", (200, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n        # cv2.imshow(""Blink Detection Demo"", frame)\n        \n    # if cv2.waitKey(1) & 0xFF == 27:\n    #         sys.exit()\n\nprint(""Caliberation Complete!"")\n\nspf = totalTime/dummyFrames\nprint(""Current SPF (seconds per frame) is {:.2f} ms"".format(spf * 1000))\n\ndrowsyLimit = drowsyTime/spf\nfalseBlinkLimit = blinkTime/spf\nprint(""drowsy limit: {}, false blink limit: {}"".format(drowsyLimit, falseBlinkLimit))\n\nif __name__ == ""__main__"":\n    vid_writer = cv2.VideoWriter(\'output-low-light-2.avi\',cv2.VideoWriter_fourcc(\'M\',\'J\',\'P\',\'G\'), 15, (frame.shape[1],frame.shape[0]))\n    while(1):\n        try:\n            t = time.time()\n            ret, frame = capture.read()\n            height, width = frame.shape[:2]\n            IMAGE_RESIZE = np.float32(height)/RESIZE_HEIGHT\n            frame = cv2.resize(frame, None, \n                                fx = 1/IMAGE_RESIZE, \n                                fy = 1/IMAGE_RESIZE, \n                                interpolation = cv2.INTER_LINEAR)\n\n            # adjusted = gamma_correction(frame)\n            adjusted = histogram_equalization(frame)\n\n            landmarks = getLandmarks(adjusted)\n            if landmarks == 0:\n                validFrames -= 1\n                cv2.putText(frame, ""Unable to detect face, Please check proper lighting"", (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n                cv2.putText(frame, ""or decrease FACE_DOWNSAMPLE_RATIO"", (10, 50), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n                cv2.imshow(""Blink Detection Demo"", frame)\n                if cv2.waitKey(1) & 0xFF == 27:\n                    break\n                continue\n\n            eyeStatus = checkEyeStatus(landmarks)\n            checkBlinkStatus(eyeStatus)\n\n            for i in range(0, len(leftEyeIndex)):\n                cv2.circle(frame, (landmarks[leftEyeIndex[i]][0], landmarks[leftEyeIndex[i]][1]), 1, (0, 0, 255), -1, lineType=cv2.LINE_AA)\n\n            for i in range(0, len(rightEyeIndex)):\n                cv2.circle(frame, (landmarks[rightEyeIndex[i]][0], landmarks[rightEyeIndex[i]][1]), 1, (0, 0, 255), -1, lineType=cv2.LINE_AA)\n\n            if drowsy:\n                cv2.putText(frame, ""! ! ! DROWSINESS ALERT ! ! !"", (70, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n                if not ALARM_ON:\n                    ALARM_ON = True\n                    threadStatusQ.put(not ALARM_ON)\n                    thread = Thread(target=soundAlert, args=(sound_path, threadStatusQ,))\n                    thread.setDaemon(True)\n                    thread.start()\n\n            else:\n                cv2.putText(frame, ""Blinks : {}"".format(blinkCount), (460, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2, cv2.LINE_AA)\n                # (0, 400)\n                ALARM_ON = False\n\n\n            cv2.imshow(""Blink Detection Demo"", frame)\n            vid_writer.write(frame)\n\n            k = cv2.waitKey(1) \n            if k == ord(\'r\'):\n                state = 0\n                drowsy = 0\n                ALARM_ON = False\n                threadStatusQ.put(not ALARM_ON)\n\n            elif k == 27:\n                break\n\n            # print(""Time taken"", time.time() - t)\n\n        except Exception as e:\n            print(e)\n\n    capture.release()\n    vid_writer.release()\n    cv2.destroyAllWindows()\n\n'"
