file_path,api_count,code
tools/playvideo.py,0,"b'#!/usr/bin/env python\n\nimport numpy as np\nimport cv2\n\nvideo = ""drop.avi""\n\nvideo_capture = cv2.VideoCapture(video)\nvideo_length = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n\ncount = 0\nwhile(True):\n        # Capture frame-by-frame\n        ret, frame = video_capture.read()\n        if not ret:\n            break\n\n        count += 1\n\nprint( video_length, count )\n# When everything done, release the capture\nvideo_capture.release()\ncv2.destroyAllWindows()\n\n'"
tools/showbox.py,0,"b""import numpy as np\nimport cv2\n\nimg = cv2.imread('/Users/chris/code/bounder/vidpipe/images/VidPipe.png',0)\ncv2.imshow('image',img)\nk = cv2.waitKey(1) & 0xFF\n\nif k == 27:         # wait for ESC key to exit\n    cv2.destroyAllWindows()\nelif k == ord('s'): # wait for 's' key to save and exit\n    cv2.destroyAllWindows()\n\n"""
tools/showlive.py,0,"b'# from https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\nimport cv2\nimport numpy as np\n\nsave_video = False\n\n# Create a VideoCapture object\ncap = cv2.VideoCapture(0)\n\n# Check if camera opened successfully\nif (cap.isOpened() == False): \n  print(""Unable to read camera feed"")\n\n# Default resolutions of the frame are obtained.The default resolutions are system dependent.\n# We convert the resolutions from float to integer.\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\n\n# Define the codec and create VideoWriter object.The output is stored in \'outpy.avi\' file.\nif save_video:\n    out = cv2.VideoWriter(\'outpy.avi\',cv2.VideoWriter_fourcc(\'M\',\'J\',\'P\',\'G\'), 10, (frame_width,frame_height))\nelse:\n    out = None\n\nwhile(True):\n  ret, frame = cap.read()\n\n  if ret == True:\n\n    # Write the frame into the file \'output.avi\'\n    if out:\n        out.write(frame)\n\n    # Display the resulting frame\n    cv2.imshow(\'frame\',frame)\n\n    # Press Q on keyboard to stop recording\n    if cv2.waitKey(1) & 0xFF == ord(\'q\'):\n      break\n\n  # Break the loop\n  else:\n    break\n\n# When everything done, release the video capture and video write objects\ncap.release()\nif out:\n    out.release()\n\n# Closes all the frames\ncv2.destroyAllWindows()\n\n'"
tools/vidcap.py,0,"b""#!/usr/bin/env python\n\nimport numpy as np\nimport cv2\n\ncap = cv2.VideoCapture(0)\n\n# Define the codec and create VideoWriter object\nfourcc = cv2.cv.CV_FOURCC('m', 'p', '4', 'v') # note the lower case\nout = cv2.VideoWriter('fan.avi', fourcc, 15.0, (640,480))\n\nwhile(cap.isOpened()):\n    ret, frame = cap.read()\n    if ret==True:\n\n        # write the flipped frame\n        out.write(frame)\n\n        cv2.imshow('frame',frame)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    else:\n        break\n\n# Release everything if job is finished\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n"""
vidpipe/ActivityFilter.py,10,"b'#!/usr/bin/env python\n\nfrom __future__ import division\nimport cv2\nimport random\nimport numpy as np\n\nfrom FrameProcessor import FrameProcessor\nfrom helpers import draw_rect, draw_str\n\n\'\'\'\nActivity Filter tries to detect periodic activity in each block and then remove that\nwindow of video so it\'s not passed forward.\n\nUse case:  Ignoring a fan in the background when processing video.\n\'\'\'\n\nclass ActivityFilter( FrameProcessor ):\n\n    # color of the filter and outlines\n    _color = ( 200, 180, 255 )\n\n    # 10 x 10 grid\n    _X = 10    # 64 pixels\n    _Y = 10    # 48 pixels\n    _threshold = 0.05   # 5% value change - LOWER is more sensitive\n\n    _threshold2 = 0.10  # 10% value change - HIGHER is more sensitive\n    _timeSpan2 = 10 * 10 # 10 seconds, 30 frames\n    _frameCount = 0     # always running frame count\n\n    _countMovAvg = 0\n    _lastAccum = 0\n\n    # debug flags to add one square with generated noise\n    # TODO: make this configurable in the GUI?\n    _percentNoise = 1   # percentage of screen to cover with generated noise\n    _debugRandomNoise = False\n    _debugSteadyNoise = True\n    _noiseBlock_x = 3\n    _noiseBlock_y = 7\n\n    def __init__( self ):\n        super( ActivityFilter, self ).__init__()\n        self._name = ""Activity Filter""\n\n        self._prev_frame_sum_of_values = np.zeros( ( self._Y, self._X ), np.uint64 )   # max of 4.2 bill\n        self._histAccum = np.zeros( ( self._Y, self._X ), np.uint64 )   # max of 4.2 bill\n        self._devAccum = np.zeros( ( self._Y, self._X ), np.uint64 )   # max of 4.2 bill\n        self._mask = np.zeros( ( self._Y, self._X ), np.bool_ )\n\n        random.seed( 1231 )\n\n        self._enabled = False\n\n        # frame that\'s processed but is hijacked to show a histogram instead of video\n        # useful for debugging values and buffers\n        self._watchFrame_enabled = False\n        self._watchFrame = ( 0, 8 ) # Set the watch frame at cel x=8, y=0   NOTE: Order is Y, X\n\n        self._graph_ringbuf_MovingAverage = np.zeros( 100, np.float32 )\n        self._graph_ringbuf = np.zeros( 100, np.uint8 )\n        self._maxhistAccum = 1  # use 1 to avoid divide by zero later\n\n    def prop_ChangeThresh_set( self, thresh ):\n        self._threshold = thresh / 1000\n\n    def prop_ChangeThresh_get( self):\n        return self._threshold * 1000\n\n    def type_ChangeThresh( self ):\n        return int\n\n    def prop_Watch_set( self, val ):\n        # TODO: error check\n        self._watchFrame = tuple( val )[ :: -1 ]\n        self._graph_ringbuf_MovingAverage = np.zeros( 100, np.float32 )\n        self._graph_ringbuf = np.zeros( 100, np.uint8 )\n        self._maxhistAccum = 1\n\n    def prop_Watch_get( self):\n        return self._watchFrame[ :: -1 ]\n\n    def type_Watch( self ):\n        return tuple\n\n    def processFrame( self, frame_in ):\n        # frame_in is BGR\n        # frame_in.shape = ( 480, 640, 3 )\n        self._frameCount += 1\n\n        # divide the frame into X x Y grid\n        yjump = int( 480 / self._Y )\n        xjump = int( 640 / self._X )\n\n        # brute force a background\n        #draw_rect( frame_in, 0, 0, 640, 480, ( 0, 0, 0 ) )\n\n        # inject random noise\n        if self._debugRandomNoise == True:\n            r = random.randint( 0, 255 )\n            g = random.randint( 0, 255 )\n            b = random.randint( 0, 255 )\n            draw_rect( frame_in, ( self._noiseBlock_x * xjump ), ( self._noiseBlock_y * yjump ),\n                                 ( ( self._noiseBlock_x + 1 ) * xjump - ( ( 1 - self._percentNoise ) * xjump ) - 1 ),\n                                 ( ( self._noiseBlock_y + 1 ) * yjump - ( ( 1 - self._percentNoise ) * yjump ) - 1 ),\n                                 ( r, g, b ) )\n\n        # inject noise that follows a steady pattern\n        if self._debugSteadyNoise == True:\n            color = ( 255, 255, 0 )\n            if self._frameCount % 9 == 0:\n                color = ( 128, 255, 255 )\n            elif self._frameCount % 8 == 0:\n                color = ( 0, 128, 255 )\n            elif self._frameCount % 7 == 0:\n                color = ( 128, 255, 128 )\n            elif self._frameCount % 6 == 0:\n                color = ( 0, 0, 255 )\n            elif self._frameCount % 5 == 0:\n                color = ( 33, 255, 255 )\n            elif self._frameCount % 4 == 0:\n                color = ( 0, 33, 255 )\n            elif self._frameCount % 3 == 0:\n                color = ( 0, 0, 33 )\n            elif self._frameCount % 2 == 0:\n                color = ( 50, 50, 255 )\n            draw_rect( frame_in, ( self._noiseBlock_x * xjump ), ( self._noiseBlock_y * yjump ),\n                                 ( ( self._noiseBlock_x + 1 ) * xjump - ( ( 1 - self._percentNoise ) * xjump ) - 1 ),\n                                 ( ( self._noiseBlock_y + 1 ) * yjump - ( ( 1 - self._percentNoise ) * yjump ) - 1 ),\n                                 color )\n\n        for y in range( 0, self._Y ):\n            for x in range( 0, self._X ):\n\n                # sum for each portion of the grid\n                # TODO: change to count the number of pixels change to monitor a % of area changed\n                #   sum is mixing both degree of change AND area changed\n                sum_of_values = int( frame_in[ y * yjump : ( y + 1 ) * yjump, x * xjump : ( x + 1 ) * xjump ].sum() )\n\n                # calc a delta for each portion after Z # of frames - 1st derivitate, change over time\n                dev_from_hist = abs( sum_of_values - self._prev_frame_sum_of_values[ y ][ x ] )\n\n                if self._mask[ y ][ x ] == True:\n                    frame_in[ y * yjump : ( y + 1 ) * yjump, x * xjump : ( x + 1 ) * xjump ] = 128\n\n                #if the | delta | < Threshold then blank out that sector\n                nomotion = False\n                if dev_from_hist < self._threshold * self._prev_frame_sum_of_values[ y ][ x ]:\n                    nomotion = True\n\n                    # if not already masked for some reason\n                    #if self._mask[ y ][ x ] != True:\n                    #    frame_in[ y * yjump : ( y + 1 ) * yjump, x * xjump : ( x + 1 ) * xjump ] = 0\n\n                # 2nd derivative - change of change over time\n                self._devAccum[ y ][ x ] += dev_from_hist\n\n                if self._watchFrame_enabled and self._watchFrame ==  ( y, x ):\n\n                    self._graph_ringbuf = np.roll( self._graph_ringbuf, 1 )\n                    self._graph_ringbuf[ 0 ] = yjump * dev_from_hist / 100000\n\n                    # start with a clear image\n                    #frame_in[ y * yjump : ( y + 1 ) * yjump, x * xjump : ( x + 1 ) * xjump ] = 0\n                    vis = frame_in[ y * yjump : ( y + 1 ) * yjump, x * xjump : ( x + 1 ) * xjump ]\n\n                    # plot the values\n                    for xx in range( 1, xjump ):\n                        cv2.line( vis, ( xx - 1, yjump - int( self._graph_ringbuf[ xx - 1 ] ) ), ( xx, yjump - int( self._graph_ringbuf[ xx ] ) ), ( 255, 255, 0 ), 1 )\n                        #cv2.line( vis, ( xx - 1, yjump - int( self._graph_ringbuf_MovingAverage[ xx - 1 ] ) ), ( xx, yjump - int( self._graph_ringbuf_MovingAverage[ xx ] ) ), ( 0, 25, 255 ), 2 )\n\n                    if self._mask[ y ][ x ] == True:\n                        cv2.circle( vis, ( xjump - 6, 4 ), 3, ( 0, 25, 255 ), -1 )\n\n                    # show midway mark for refrence\n                    cv2.line( vis, ( 0, yjump - int( yjump / 2 ) ), ( xjump - 1, yjump - int( yjump / 2 ) ), ( 128, 128, 128 ), 1 )\n\n                    # plot the moving average\n                    scaledMovingAvg = int( yjump * self._graph_ringbuf_MovingAverage[ 0 ] / self._maxhistAccum )\n                    cv2.line( vis, ( 0, yjump - scaledMovingAvg ), ( xjump - 1, yjump - scaledMovingAvg ), ( 0, 25, 255 ), 2 )\n\n                    scaledLastAccum = int( yjump * self._lastAccum / 1000000 )\n                    cv2.line( vis, ( 0, yjump - scaledLastAccum ), ( xjump - 1, yjump - scaledLastAccum ), ( 255, 25, 0 ), 2 )\n\n                #if self._watchFrame ==  ( y, x ):\n                #    print( ""%d\\t%d\\t%d\\t%d"" % ( sum_of_values, self._prev_frame_sum_of_values[ y ][ x ], dev_from_hist, self._devAccum[ y ][ x ] ) )\n\n                # calculuate change over time\n                if self._frameCount % self._timeSpan2 == 0:\n                    if self._histAccum[ y ][ x ] > self._devAccum[ y ][ x ]:\n                        accum = self._histAccum[ y ][ x ] - self._devAccum[ y ][ x ]\n                    else:\n                        accum = self._devAccum[ y ][ x ] - self._histAccum[ y ][ x ]\n\n                    if accum < self._threshold2 *  self._histAccum[ y ][ x ] and nomotion == False:\n                        self._mask[ y ][ x ] = True\n                    else:\n                        self._mask[ y ][ x ] = False\n\n                    self._lastAccum = accum\n\n                    if self._watchFrame ==  ( y, x ):\n                        print( ""accum: {0}\\t\\tdevAccum: {1}\\t\\thistAccum: {2}"".format( accum, self._devAccum[ y ][ x ], self._histAccum[ y ][ x ] ) )\n\n                        #self._graph_ringbuf_MovingAverage[ 0 ] = self.movingAverage( ( self._yjump * self._movingAverageSlidingWindow / self._maxhistAccum ), self._slidingWindow )\n\n                        movingAverage = ( self._devAccum[ y ][ x ] + self._countMovAvg * self._graph_ringbuf_MovingAverage[ 0 ] ) / ( self._countMovAvg + 1 )\n                        self._maxhistAccum = max( self._maxhistAccum, movingAverage )\n                        if self._countMovAvg == 0:\n                            self._maxhistAccum *= 0.25\n                        elif self._countMovAvg == 1:\n                            self._countMovAvg *= 0.50\n                        elif self._countMovAvg == 2:\n                            self._countMovAvg *= 0.75\n\n                        print(  ""MaxHistAccum: %d\\t\\tmovingAvg: %d"" %( self._maxhistAccum, movingAverage ) )\n                        self._graph_ringbuf_MovingAverage = np.roll( self._graph_ringbuf_MovingAverage, 1 )\n                        self._graph_ringbuf_MovingAverage[ 0 ] = movingAverage\n                        #self._graph_ringbuf_MovingAverage[ 0 ] = yjump * self._histAccum[ y ][ x ] / self._maxhistAccum # 1000000\n\n\n                    #if self._watchFrame == ( y, x ):\n                    #    print( ""%d\\t%d\\t%d\\t%d\\t%s"" % ( self._frameCount, self._devAccum[ self._watchFrame ], self._histAccum[ self._watchFrame ], accum, self._mask[ self._watchFrame ] ) )\n\n                    self._histAccum[ y ][ x ] = self._devAccum[ y ][ x ]\n                    self._devAccum[ y ][ x ] = 0\n\n                self._prev_frame_sum_of_values[ y ][ x ] = sum_of_values\n                last_X = x\n            last_Y = y\n\n        if self._frameCount % self._timeSpan2 == 0:\n            self._countMovAvg += 1\n\n        # return the processed frame to be either passed to the next filter\n        # or displayed\n        return frame_in\n\n'"
vidpipe/BackgroundRemove.py,1,"b'#!/usr/bin/env python\n\nfrom __future__ import division\n\nimport cv2\nimport numpy as np\n\nfrom FrameProcessor import FrameProcessor\n\n\'\'\'\nStill in progress....\n\nFilter to remove the background and only keep the parts of the video that are\nactively changing.\n\'\'\'\n\nclass BackgroundRemove( FrameProcessor ):\n\n    def __init__ ( self ):\n        super( BackgroundRemove, self ).__init__()\n        self._name = ""Background Remove""\n\n        self._speed = 0.01\n        self._avg = None\n\n        self._fgbg = cv2.BackgroundSubtractorMOG()\n\n    def prop_AdaptSpeed_set( self, val ):\n        self._speed = float( val / 100 )\n        print( self._speed )\n\n    def prop_AdaptSpeed_get( self):\n        return int( self._speed * 100 )\n\n    def type_AdaptSpeed( self ):\n        return int\n\n    #def prop_AlgorithmV_get( self ):\n    #    pass\n\n    def processFrame( self, frame_in ):\n        # version 1 - moving average\n        if self._avg == None:\n            self._avg = np.float32( frame_in )\n        cv2.accumulateWeighted( frame_in, self._avg, self._speed )\n        background = cv2.convertScaleAbs( self._avg )\n        active_area = cv2.absdiff( frame_in, background )\n\n        #version 2 - MOG - Gausian Mixture-based Background/Foreground Segmentation Algorithm\n        fgmask = self._fgbg.apply( frame_in ,learningRate = 0.01 )\n        #active_area = cv2.bitwise_and( frame_in, frame_in, mask = fgmask )\n\n        return fgmask\n\n'"
vidpipe/BlockNumber.py,0,"b'#!/usr/bin/env python\n\nfrom __future__ import division\nimport cv2\nimport numpy as np\n\nfrom FrameProcessor import FrameProcessor\nfrom helpers import draw_str, draw_rect\n\nclass BlockNumber( FrameProcessor ):\n\n    # 10 x 10 grid\n    _X = 10    # 64 pixels\n    _Y = 10    # 48 pixels\n    _frameCount = 0 # for adding noise\n\n    def __init__( self ):\n        super( BlockNumber, self ).__init__()\n        self._name = ""Block Number""\n\n        # divide the frame into X x Y grid\n        self._yjump = 480 / self._Y\n        self._xjump = 640 / self._X\n\n    def processFrame( self, frame_in ):\n        # frame_in is BGR\n        # frame_in.shape = ( 480, 640, 3 )\n        self._frameCount += 1\n\n        # brute force a background\n        #draw_rect( frame_in, 0, 0, 640, 480, ( 0, 0, 0 ) )\n\n        for y in range( 0, self._Y ):\n            for x in range( 0, self._X ):\n                # show the block number - (x, y)\n                ptx = int( x * self._xjump + .25 * self._xjump )\n                pty = int( y * self._yjump + .5 * self._yjump )\n                draw_str( frame_in, ptx, pty, ""(%d,%d)"" % ( x, y ) )\n\n        # return the processed frame to be either passed to the next filter\n        # or displayed\n        return frame_in\n\n'"
vidpipe/BlurFilter.py,0,"b'#!/usr/bin/env python\n\nimport cv2\n\nfrom FrameProcessor import FrameProcessor\n\nclass BlurFilter( FrameProcessor ):\n\n    \'\'\'\n    blur_kernel (kernel size) determines how many pixels to sample during the convolution\n    sigma defines how much to modulate them by\n    For more info:  http://http.developer.nvidia.com/GPUGems3/gpugems3_ch40.html\n    \'\'\'\n\n    _blur_kernel = 5  # good starting point is 5 - very light blur\n    _sigma = 0\n\n    def __init__( self ):\n        super( BlurFilter, self ).__init__()\n        self._name = ""Blur Filter""\n        self._sigma = 0.3 * ( ( self._blur_kernel - 1 ) * 0.5 - 1 ) + 0.8\n\n    def prop_BlurSize_set( self, val ):\n        # val must be odd\n        if val % 2 == 0:\n            val += 1    # hackish but 1 point won\'t matter enough to worry about\n        self._blur_kernel = val\n        self._sigma = 0.3 * ( ( self._blur_kernel - 1 ) * 0.5 - 1 ) + 0.8\n\n    def prop_BlurSize_get( self):\n        return self._blur_kernel\n\n    def type_BlurSize( self ):\n        return int\n\n    def processFrame( self, frame_in ):\n        # http://docs.opencv.org/modules/imgproc/doc/filtering.html#gaussianblur\n        blurred = cv2.GaussianBlur( frame_in, ( self._blur_kernel, self._blur_kernel ), self._sigma )\n        return blurred\n'"
vidpipe/CameraDevice.py,2,"b'#!/usr/bin/env python\n\nimport cv2\n\nfrom PyQt5 import QtCore\nimport numpy as np\n\nclass CameraDevice( QtCore.QObject ):\n\n    _DEFAULT_FPS = 30\n\n    newFrame = QtCore.pyqtSignal( np.ndarray )\n\n    def __init__(self, fl = None, cameraId=0, mirrored=False, parent=None):\n        super(CameraDevice, self).__init__(parent)\n\n        self.mirrored = mirrored\n\n        self._cameraDevice  = cv2.VideoCapture( fl if fl else cameraId )\n\n        self._timer = QtCore.QTimer( self )\n        self._timer.timeout.connect( self._queryFrame )\n        self._timer.setInterval( 1000 / self.fps )\n\n        if fl:\n            self._maxFrameCount = self._cameraDevice.get( cv2.CAP_PROP_FRAME_COUNT );\n        self._frameCount = 0\n\n        self.paused = False\n        self._maxFrameCount = -1\n\n    # from: https://stackoverflow.com/questions/9710520/opencv-createimage-function-isnt-working\n    def _createBlankImage( w, h, rgb_colors = ( 0, 0, 0 ) ):\n        """"""Create new image(numpy array) filled with certain color in RGB""""""\n        # Create black blank image\n        image = np.zeros((height, width, 3), np.uint8)\n\n        # Since OpenCV uses BGR, convert the color first\n        color = tuple(reversed(rgb_color))\n\n        # Fill image with color\n        image[:] = color\n\n        return image\n\n    @QtCore.pyqtSlot()\n    def _queryFrame(self):\n        success, frame = self._cameraDevice.read()\n\n        if not success:\n            print( ""Error getting frame"" )\n        else:\n            if self.mirrored:\n                h, w, channels = frame.shape\n                mirroredFrame = self._createBlankImage( w, h )\n                cv2.flip(frame, mirroredFrame, 1)\n                frame = mirroredFrame\n            self.newFrame.emit( frame )\n            self._frameCount += 1\n\n        if self._maxFrameCount > -1 and self._frameCount % self._maxFrameCount == 0:\n            print( ""Repeat at: %d"" % self._frameCount )\n\n    @property\n    def paused(self):\n        return not self._timer.isActive()\n\n    @paused.setter\n    def paused(self, p):\n        if p:\n            self._timer.stop()\n        else:\n            self._timer.start()\n\n    @property\n    def frameSize(self):\n        w = self._cameraDevice.get( cv2.CAP_PROP_FRAME_WIDTH )\n        h = self._cameraDevice.get( cv2.CAP_PROP_FRAME_HEIGHT )\n        return int(w), int(h)\n\n    @property\n    def fps( self ):\n        fps =  int( self._cameraDevice.get( cv2.CAP_PROP_FPS ) )\n        if not fps > 0:\n            fps = self._DEFAULT_FPS\n        return fps\n'"
vidpipe/CameraWidget.py,2,"b'#!/usr/bin/env python\n\nfrom PyQt5.QtCore import pyqtSlot, pyqtSignal, QPoint, QEvent, QSize\nfrom PyQt5.QtGui import QPainter\nfrom PyQt5.QtWidgets import QWidget, QSizePolicy\n\nfrom OpenCVQImage import OpenCVQImage\nimport numpy as np\n\nclass CameraWidget( QWidget ):\n\n    newFrame = pyqtSignal( np.ndarray )\n\n    def __init__( self, parent = None ):\n        super( CameraWidget, self ).__init__( parent )\n\n        self._frame = None\n\n    def setCamera( self, cameraDevice ):\n        self._cameraDevice = cameraDevice\n        self._cameraDevice.newFrame.connect( self._onNewFrame )\n\n        w, h = self._cameraDevice.frameSize\n        self.setMinimumSize(w, h)\n        self.setMaximumSize( 960, 1280)\n        #self.setSizePolicy( QSizePolicy.Fixed, QSizePolicy.Fixed )\n        self.setSizePolicy( QSizePolicy.Expanding, QSizePolicy.Expanding )\n\n    @pyqtSlot( np.ndarray )\n    def _onNewFrame(self, frame):\n        self._frame = frame.copy()\n        self.newFrame.emit( self._frame )\n        self.update()\n\n    def setNewFrame( self, frame ):\n        self._frame = frame\n\n    def changeEvent( self, e ):\n        if e.type() == QEvent.EnabledChange:\n            if self.isEnabled():\n                self._cameraDevice.newFrame.connect( self._onNewFrame )\n            else:\n                self._cameraDevice.newFrame.disconnect( self._onNewFrame )\n\n    def paintEvent( self, e ):\n        if self._frame is None:\n            return\n        painter = QPainter( self )\n        painter.drawImage( QPoint( 0, 0 ), OpenCVQImage( self._frame ) )\n\n    def sizeHint( self ):\n        w, h = self._cameraDevice.frameSize\n        return QSize( w, h )\n\n    def minimumnSizePolicy( ):\n        return sizeHint()\n\n'"
vidpipe/EdgeDetector.py,0,"b'#!/usr/bin/env python\n\nimport cv2\n\nfrom FrameProcessor import FrameProcessor\n\nfrom helpers import combine\n\nclass EdgeDetector( FrameProcessor ):\n\n    _color = ( 25, 100, 200 )\n\n    _lower_thresh = 10.0   # good starting point is 10\n    _upper_thresh = 200.0  # good starting point is 200\n\n    def __init__( self ):\n        super( EdgeDetector, self ).__init__()\n        self._name = ""Edge Detector""\n        self._testBool = False\n\n    def prop_ThreshLower_set( self, thresh ):\n        self._lower_thresh = thresh\n\n    def prop_ThreshLower_get( self):\n        return self._lower_thresh\n\n    def prop_ThreshUpper_set( self, thresh ):\n        self._upper_thresh = thresh\n\n    def prop_ThreshUpper_get( self ):\n        return self._upper_thresh\n\n    def type_ThreshUpper( self ):\n        return int\n\n    def type_ThreshLower( self ):\n        return int\n\n    def processFrame( self, frame_in ):\n        self._activeRects = []\n        self._boundingBox = []\n\n        gray = cv2.cvtColor( frame_in, cv2.COLOR_BGR2GRAY )\n        gray = cv2.equalizeHist( gray )\n        edged_g = cv2.Canny( gray, self._lower_thresh, self._upper_thresh )\n\n        # draw edges on main image\n        color = self._color\n        pen_thickness = 1\n        ( _, cnts, _ ) = cv2.findContours( edged_g.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE )\n        cv2.drawContours( frame_in, cnts, -1, color, pen_thickness )\n\n        # draw a bounding box\n        cnts = sorted( cnts, key = cv2.contourArea, reverse = True )#[ : 20 ]\n\n        for r in cnts:\n            rect = cv2.boundingRect( r )    # rect is x, y, w, h\n            self._activeRects.append( rect )\n\n            cv2.rectangle( frame_in, ( rect[ 0 ], rect[ 1 ] ), ( rect[ 0 ] + rect[ 2 ], rect[ 1 ] + rect[ 3 ] ), ( 0, 255, 255 ), 1 )\n\n        self._boundingBox = combine( self._activeRects )\n\n        return frame_in\n\n\n'"
vidpipe/FilterListOrderMapper.py,0,"b""#!/usr/bin/env python\n\nfrom PyQt5.QtWidgets import QListWidgetItem\nfrom PyQt5.QtCore import pyqtSlot, pyqtSignal, QObject, QEvent\n\n# QListWidget isn't set up to easily capture drag-rearrange events\n# This is a hack class to capture a dragged list rearrange event and spit out a signal\nclass FilterListOrderMapper( QObject ):\n    listChanged = pyqtSignal()\n\n    def eventFilter( self, sender, event ):\n\n        if event.type() == QEvent.ChildRemoved:\n        #if event.type() == QEvent.ChildRemoved:\n        #if event.type() == QEvent.ChildAdded:\n        #if event.type() == QEvent.Drop:\n            self.listChanged.emit()\n        return False\n\n"""
vidpipe/FrameProcessor.py,0,"b'#!/usr/bin/env python\n\nimport numpy as np\n\nfrom PyQt5.QtCore import pyqtSlot, pyqtSignal, QObject\n\nclass FrameProcessor( QObject ):\n    propStartsWith = ""prop_""\n    propEndsWithSetter = ""_set""\n    propEndsWithGetter = ""_get""\n    propTypeStartsWith = ""type_""\n\n    _activeRects = []\n    _boundingBox = []\n\n    _color = ( 255, 255, 255 )\n\n    def __init__ ( self ):\n        super( FrameProcessor, self ).__init__()\n        self._name = ""Frame Processor""\n        self._enabled = False\n\n    def loadConfig( self, config ):\n        print( "">>>>>>>>>>>TODO: Load configuration"" )\n\n    def saveConfig( self, config ):\n        print( "">>>>>>>>>>>TODO: Save configuration"" )\n\n    def color( self ):\n        return self._color\n\n    @property\n    def name( self ):\n        return self._name\n\n    def processFrame( self, frame_in ):\n        return frame_in\n\n    def prop_Enabled_get( self ):\n        return self._enabled\n\n    def prop_Enabled_set( self, value ):\n        if type( value ) != bool and value != True and value != False:\n            raise TypeError( ""Enabled must be either True or False"" )\n        self._enabled = value\n        print( ""Setting %s to %s"" % ( self.name, value ) )\n\n    def type_Enabled( self ):\n        return bool\n\n    def getBoundingBox( self ):\n        return self._boundingBox # CAREFUL!!: returns (x1, y1, x2, y2) NOT x, y, w, h\n\n    def getRects( self ):\n        return self._activeRects\n\n# Ignore below.  Only test code follows.....\nif __name__ == \'__main__\':\n    import inspect\n    print( ""Testing...."" )\n\n    fp = FrameProcessor()\n\n    print( ""Name is %s"" % fp.name )\n\n    try:\n        fp.enabled = 1\n    except TypeError:\n        print( ""Caught ValueError exception on setting to int"" )\n\n    try:\n        fp.enabled = ""True""\n    except TypeError:\n        print( ""Caught ValueError exception on setting to string"" )\n\n    fp.enabled = True\n    print( ""Setting to true. Did it work?: %s"" % ( fp.enabled == True ) )\n\n    fp.enabled = False\n    print( ""Setting to false. Did it work?: %s"" % ( fp.enabled == False ) )\n\n    print( ""Getting options:"" )\n    attribs = [ funct.replace( FrameProcessor.propStartsWith, """" ) for funct in dir( fp ) if callable( getattr( fp, funct ) ) and funct.startswith( FrameProcessor.propStartsWith ) ]\n    print( ""\\t"", [ ftn.replace( FrameProcessor.propEndsWithSetter, """" ) for ftn in attribs if ftn.endswith( FrameProcessor.propEndsWithSetter ) ] )\n    print( ""\\t"", [ ftn.replace( FrameProcessor.propEndsWithGetter, """" ) for ftn in attribs if ftn.endswith( FrameProcessor.propEndsWithGetter ) ] )\n\n    print( ""Finished"" )\n\n'"
vidpipe/Histogram.py,18,"b'#!/usr/bin/env python\n\nfrom __future__ import division\nimport cv2\nimport numpy as np\n\nimport math     # for sin, remove after testing\n\nfrom helpers import draw_str\n\nfrom FrameProcessor import FrameProcessor\n\n# remove later\nimport random\n\nclass HistogramFilter( FrameProcessor ):\n    _color = ( 80, 180, 80 )\n\n    # 10 x 10 grid\n    _X = 10    # 64 pixels\n    _Y = 10    # 48 pixels\n\n    _deltaT = 1    # time, in frame count-ish\n    _depth = 30     # depth of the histograph\n    _threshold = 0.05   # 5% value change - LOWER is more sensitive\n\n    _frameCount = 0     # always running frame count\n    _Counter = 0\n\n    _total = 0  # used to calc average\n    _last = 0   # last value stored\n    _count = 0  # how many values in the histagram so far\n\n    ringlen = 100\n    _xjump = int( 640 / _X )\n    _yjump = int( 480 / _Y )\n    _graph_ringbuf = np.zeros( ringlen, np.uint8 )\n    _maxScale = 1\n    _scale = 100000\n\n    _enableDumpFile = False    \n    _fileDataDumpName = ""histogram.txt""\n    _fileDataDump = None\n\n    _countCumulativeAverage = 0\n\n    def __init__( self ):\n        super( HistogramFilter, self ).__init__()\n        self._name = ""Histogram Filter""\n\n        self._prevFrameSigma = np.zeros( ( self._Y, self._X ), np.uint64 )   # max of 18446744073709551615\n        self._SigmaDeltaAccumulator = np.zeros( ( self._Y, self._X ), np.uint64 )   # max of 18446744073709551615\n        self._SigmaDelta = np.zeros( ( self._Y, self._X ), np.uint64 )   # max of 18446744073709551615\n        self._timeSpan2Mask = np.zeros( ( self._Y, self._X ), np.bool_ )\n\n        self._slidingWindow = 30\n        self._movingAverageSlidingWindow = np.zeros( self._slidingWindow, np.uint64 )\n        self._graph_ringbuf_MovingAverage = np.zeros( self.ringlen, np.uint8 )\n\n        self._enabled = False\n        self._watchFrame = ( 0, 9 ) # top right\n\n        if self._enableDumpFile:\n            self._fileDataDump = open( self._fileDataDumpName, \'w\' )\n\n        self._cumulativeAverage = np.zeros( ( self._Y, self._X ), np.uint64 )   # max of 18446744073709551615\n\n    def prop_Watch_set( self, val ):\n        # TODO: error check\n        self._watchFrame = tuple( val )[ :: -1 ]\n        self._movingAverageSlidingWindow = np.zeros( self._slidingWindow, np.uint64 )\n        self._graph_ringbuf_MovingAverage = np.zeros( self.ringlen, np.uint8 )\n\n    def prop_Watch_get( self):\n        return self._watchFrame[ :: -1 ]\n\n    def type_Watch( self ):\n        return tuple\n\n    def prop_Scale_set( self, scale ):\n        self._scale = scale\n\n    def prop_Scale_get( self):\n        return self._scale\n\n    def type_Scale( self ):\n        return int\n\n    def movingAverage( self, values, window ):\n        weights = np.repeat(1.0, window)/window\n        sma = np.convolve(values, weights, \'valid\')\n        return sma\n\n    def processFrame( self, frame_in ):\n        # frame_in is BGR\n        # frame_in.shape = ( 480, 640, 3 )\n\n        self._frameCount += 1\n\n        # divide the frame into X x Y grid\n        yjump = 480 / self._Y\n        xjump = 640 / self._X\n\n        # for spiting out data\n        outBuffer = """"\n\n        # brute force a background\n        #draw_rect( frame_in, ( 0, 0 ), ( 640, 480 ), ( 0, 0, 0 ) )\n\n        for y in range( 0, self._Y ):\n            for x in range( 0, self._X ):\n\n                # F1 sigma - sum for each portion of the grid\n                # TODO: change to count the number of pixels change to monitor a % of area changed\n                #   sum is mixing both degree of change AND area changed\n                single_frame_sum = int( frame_in[ int( y * yjump ) : int( ( y + 1 ) * yjump ), int( x * xjump ) : int( ( x + 1 ) * xjump ) ].sum() )\n\n                # Fdelta - calc a delta for each portion after Z # of frames - 1st derivitate, change over time\n                frame2frame_difference = abs( single_frame_sum - self._prevFrameSigma[ y ][ x ] )\n\n                if self._timeSpan2Mask[ y ][ x ] == True:\n                    frame_in[ int( y * yjump ) : int( ( y + 1 ) * yjump ), int( x * xjump ) : int( ( x + 1 ) * xjump ) ] = 255\n\n                if self._watchFrame == ( y, x ):\n                    # start with a clear image\n                    #frame_in[ y * yjump : ( y + 1 ) * yjump, x * xjump : ( x + 1 ) * xjump ] = 0\n                    vis = frame_in[ int( y * yjump ) : int( ( y + 1 ) * yjump ), int( x * xjump ) : int( ( x + 1 ) * xjump ) ]\n\n                    # show midway mark for refrence\n                    cv2.line( vis, ( 0, self._yjump - int( self._yjump / 2 ) ), ( self._xjump - 1, self._yjump - int( self._yjump / 2 ) ), ( 128, 128, 128 ), 1 )\n\n                    # plot the values and the moving average\n                    for xx in range( 1, self._xjump ):\n                        cv2.line( vis, ( xx - 1, self._yjump - int( self._graph_ringbuf[ xx - 1 ] ) ), ( xx, self._yjump - int( self._graph_ringbuf[ xx ] ) ), ( 255, 255, 0 ), 1 )\n                        cv2.line( vis, ( xx - 1, self._yjump - int( self._graph_ringbuf_MovingAverage[ xx - 1 ] ) ), ( xx, self._yjump - int( self._graph_ringbuf_MovingAverage[ xx ] ) ), ( 0, 25, 255 ), 2 )\n\n                    if self._timeSpan2Mask[ y ][ x ] == True:\n                        cv2.circle( vis, ( self._xjump - 6, 4 ), 3, ( 0, 25, 255 ), -1 )\n\n                # running calculation for Sigma Delta \n                self._SigmaDeltaAccumulator[ y ][ x ] += frame2frame_difference\n\n                # at time trigger Delta Sigma Delta calcuation\n                if self._frameCount % ( self._deltaT * 15 ) == 0:\n\n                    if self._SigmaDeltaAccumulator[ y ][ x ] > self._SigmaDelta[ y ][ x ]:\n                        delta_sigma_delta = self._SigmaDeltaAccumulator[ y ][ x ] - self._SigmaDelta[ y ][ x ]\n                    else:\n                        delta_sigma_delta = self._SigmaDelta[ y ][ x ] - self._SigmaDeltaAccumulator[ y ][ x ]\n\n                    #outBuffer += ""{0}:{1}:{2}\\t"".format( x, y, delta_sigma_delta )\n                    outBuffer += ""{0}\\t"".format( delta_sigma_delta )\n\n                    if self._countCumulativeAverage > 1: # skip two times\n                        self._cumulativeAverage[ y ][ x ] = ( delta_sigma_delta + ( self._countCumulativeAverage * self._cumulativeAverage[ y ][ x ] ) ) / ( self._countCumulativeAverage + 1 )\n\n                    diff = 0\n                    if delta_sigma_delta > self._cumulativeAverage[ y ][ x ]:\n                        diff = delta_sigma_delta - self._cumulativeAverage[ y ][ x ]\n                    else:\n                        diff = self._cumulativeAverage[ y ][ x ] - delta_sigma_delta\n\n                    if self._watchFrame == ( y, x ):\n                        print( ""{0},{1}\\t\\tdelta_sigma_delta:{2}\\t\\tdiff:{3}"".format( y, x, delta_sigma_delta, diff ) )\n\n                    self._timeSpan2Mask[ y ][ x ] = diff < 0.4 * self._cumulativeAverage[ y ][ x ]\n\n                    # http://en.wikipedia.org/wiki/Moving_average\n                    if self._watchFrame == ( y, x ):\n                        print( ""{0},{1}\\t\\t{2}\\t{3}\\t\\t{4}\\t\\t{5}"".format( y, x, delta_sigma_delta, diff, self._cumulativeAverage[ y ][ x ], self._timeSpan2Mask[ y ][ x ] ) )\n                        #print( ""SigDeltSig: %d"" % delta_sigma_delta )\n\n                        \'\'\'\n                        ############ Sample data to verify it\'s working right\n                        ############ testing with a sin wave\n                        gg = math.sin( math.radians( self._frameCount % 360 ) ) * 10000 + 10000 # random numbers -10000 and +10000\n                        self._graph_ringbuf = np.roll( self._graph_ringbuf, 1 )\n\n                        self._graph_ringbuf[ 0 ] = int( self._yjump * gg / self._scale )\n\n                        self._movingAverageSlidingWindow = np.roll( self._movingAverageSlidingWindow, 1 )\n                        self._movingAverageSlidingWindow[ 0 ] = gg\n                        self._graph_ringbuf_MovingAverage = np.roll( self._graph_ringbuf_MovingAverage, 1 )\n                        self._graph_ringbuf_MovingAverage[ 0 ] = self.movingAverage( ( self._yjump * self._movingAverageSlidingWindow / self._scale ), self._slidingWindow )\n                        ########### testing\n                        \'\'\'\n\n                        self._graph_ringbuf = np.roll( self._graph_ringbuf, 1 )\n                        self._graph_ringbuf[ 0 ] = int( self._yjump * delta_sigma_delta / self._scale )\n\n                        #self._movingAverageSlidingWindow = np.roll( self._movingAverageSlidingWindow, 1 )\n                        #self._movingAverageSlidingWindow[ 0 ] = gg\n\n                        self._graph_ringbuf_MovingAverage = np.roll( self._graph_ringbuf_MovingAverage, 1 )\n                        #self._graph_ringbuf_MovingAverage[ 0 ] = self.movingAverage( ( self._yjump * self._movingAverageSlidingWindow / scale ), self._slidingWindow )\n                        self._graph_ringbuf_MovingAverage[ 0 ] = self._yjump * self._cumulativeAverage[ y ][ x ] / self._scale\n\n                        #print( ""MovAvg: %d"" % self._graph_ringbuf_MovingAverage[ 0 ] )\n\n                        print( ""Count: %d   CumCount: %d"" % ( self._Counter, self._countCumulativeAverage ) )\n                        self._Counter += 1\n\n                    self._SigmaDelta[ y ][ x ] = self._SigmaDeltaAccumulator[ y ][ x ]\n                    self._SigmaDeltaAccumulator[ y ][ x ] = 0\n\n                self._prevFrameSigma[ y ][ x ] = single_frame_sum\n                last_X = x\n            last_Y = y\n\n        if self._frameCount % ( self._deltaT * 15 ) == 0:\n            self._countCumulativeAverage += 1\n\n        if self._enableDumpFile and len( outBuffer ) > 0:\n            outBuffer += ""\\n""\n            self._fileDataDump.write( outBuffer )\n\n        # return the processed frame to be either passed to the next filter\n        # or displayed\n        return frame_in\n\n'"
vidpipe/OpenCVQImage.py,2,"b'#!/usr/bin/env python\n\nimport cv2\nimport numpy as np\n\nfrom PyQt5 import QtGui\n\nclass OpenCVQImage( QtGui.QImage ):\n\n    def __init__( self, opencvBgrImg ):\n#        depth = cv2.IPL_DEPTH_8U\n\n        if len( opencvBgrImg.shape ) == 3:\n            h, w, nChannels = opencvBgrImg.shape\n            opencvRgbImg = np.zeros( ( h, w, 3 ), np.uint8 )\n            opencvRgbImg = cv2.cvtColor( opencvBgrImg, cv2.COLOR_BGR2RGB )\n        else:\n#            img_format = QtGui.QImage.Format_Mono\n            h, w = opencvBgrImg.shape\n#            opencvRgbImg = np.zeros( ( h, w, 3 ), np.uint8 )\n            opencvRgbImg = cv2.cvtColor( opencvBgrImg, cv2.COLOR_GRAY2RGB )\n#            cv2.mixChannels( [ opencvBgrImg ], [ opencvRgbImg ], [ 0, 2 ] )\n\n#        if depth != cv.IPL_DEPTH_8U or nChannels != 3:\n#            raise ValueError(""the input image must be 8-bit, 3-channel"")\n\n        self._imgData = opencvRgbImg.tostring()\n        super( OpenCVQImage, self ).__init__( self._imgData, w, h, QtGui.QImage.Format_RGB888 )\n'"
vidpipe/SampleFilter.py,0,"b'#!/usr/bin/env python\n\nimport cv2\n\nfrom FrameProcessor import FrameProcessor\n\nclass SampleFilter( FrameProcessor ):\n\n    def __init__( self ):\n        super( SampleFilter, self ).__init__()\n        self._name = ""Sample Filter""\n\n    def processFrame( self, frame_in ):\n        # frame_in is BGR\n        # frame_in.shape = ( 480, 640, 3 )\n\n        # return the processed frame to be either passed to the next filter\n        # or displayed\n        return frame_in\n\n'"
vidpipe/SimpleMotionDetection.py,8,"b'#!/usr/bin/env python\n\nfrom __future__ import division\nimport cv2\nimport numpy as np\n\nfrom FrameProcessor import FrameProcessor\nfrom helpers import draw_rect, combine\n\n\'\'\'\nFilter to detect motion.  The \'simple\' means it\'s a very simple imlplemenation:\nJust rack the difference between this frame and the previous frame and if it\'s\nabove a threashold, mark it as \'activity\'\n\n\'\'\'\n\nclass SimpleMotionDetection( FrameProcessor ):\n\n    _color = ( 200, 80, 80 )\n\n    # 10 x 10 grid\n    _X = 10    # 64 pixels\n    _Y = 10    # 48 pixels\n    _threshold = 0.05   # 5% value change - LOWER is more sensitive\n    # the percence difference between this frame and the prev frame that counts as motion\n\n    _scale = 100000\n\n    _frameCount = 0     # always running frame count\n\n    def __init__( self ):\n        super( SimpleMotionDetection, self ).__init__()\n        self._name = ""SimpleMotion Filter""\n\n        self._prev_frame_sum_of_values = np.zeros( ( self._Y, self._X ), np.uint64 )   # max of 4.2 bill\n\n        self._enabled = False\n        self._watchFrame_enabled = False\n        self._watchFrame = ( 0, 8 ) # NOTE: Order is Y, X\n\n        self._graph_ringbuf_MovingAverage = np.zeros( 100, np.float32 )\n        self._graph_ringbuf = np.zeros( 100, np.uint8 )\n\n    def prop_ChangeThresh_set( self, thresh ):\n        self._threshold = thresh / 1000\n\n    def prop_ChangeThresh_get( self):\n        return self._threshold * 1000\n\n    def type_ChangeThresh( self ):\n        return int\n\n    def prop_Scale_set( self, scale ):\n        self._scale = scale\n        self._graph_ringbuf = np.zeros( 100, np.uint8 )\n        self._frameCount = 0\n\n    def prop_Scale_get( self):\n        return self._scale\n\n    def type_Scale( self ):\n        return int\n\n    def prop_Watch_set( self, val ):\n        # TODO: error check\n        self._watchFrame = tuple( val )[ :: -1 ]\n        self._graph_ringbuf_MovingAverage = np.zeros( 100, np.float32 )\n        self._graph_ringbuf = np.zeros( 100, np.uint8 )\n        self._frameCount = 0\n\n    def prop_Watch_get( self):\n        return self._watchFrame[ :: -1 ]\n\n    def type_Watch( self ):\n        return tuple\n\n    def processFrame( self, frame_in ):\n        # frame_in is BGR\n        # frame_in.shape = ( 480, 640, 3 )\n\n        self._activeRects = []\n        self._boundingBox = []\n\n        # divide the frame into X x Y grid\n        yjump = int( 480 / self._Y )\n        xjump = int( 640 / self._X )\n\n        # brute force a background\n        #draw_rect( frame_in, ( 0, 0 ), ( 640, 480 ), ( 0, 0, 0 ) )\n\n        for y in range( 0, self._Y ):\n            for x in range( 0, self._X ):\n\n                # sum for each portion of the grid\n                # TODO: change to count the number of pixels change to monitor a % of area changed\n                #   sum is mixing both degree of change AND area changed\n                sum_of_values = int( frame_in[ y * yjump : ( y + 1 ) * yjump, x * xjump : ( x + 1 ) * xjump ].sum() )\n\n                # calc a delta for each portion after Z # of frames - 1st derivitate, change over time\n                dev_from_hist = abs( sum_of_values - self._prev_frame_sum_of_values[ y ][ x ] )\n\n                #if the | delta | < Threshold then blank out that sector\n                if dev_from_hist < self._threshold * self._prev_frame_sum_of_values[ y ][ x ]:\n                    frame_in[ y * yjump : ( y + 1 ) * yjump, x * xjump : ( x + 1 ) * xjump ] = 0\n                else:\n                    self._activeRects.append( ( x * xjump, y * yjump, xjump, yjump ) )\n\n                # debug trace window that show a histogram\n                if self._watchFrame_enabled and self._watchFrame == ( y, x ):\n                    self._graph_ringbuf = np.roll( self._graph_ringbuf, 1 )\n                    graphValue = yjump * dev_from_hist / self._scale\n                    self._graph_ringbuf[ 0 ] = graphValue\n\n                    movAverage = ( graphValue + self._frameCount * self._graph_ringbuf_MovingAverage[ 0 ] ) / ( self._frameCount + 1 )\n                    self._graph_ringbuf_MovingAverage = np.roll( self._graph_ringbuf_MovingAverage, 1 )\n                    self._graph_ringbuf_MovingAverage[ 0 ] = movAverage\n\n                    vis = frame_in[ y * yjump : ( y + 1 ) * yjump, x * xjump : ( x + 1 ) * xjump ]\n\n                    # plot the values and the moving average\n                    for xx in range( 1, xjump ):\n                        cv2.line( vis, ( xx - 1, yjump - int( self._graph_ringbuf[ xx - 1 ] ) ), ( xx, yjump - int( self._graph_ringbuf[ xx ] ) ), ( 255, 255, 0 ), 1 )\n                        #cv2.line( vis, ( xx - 1, yjump - int( self._graph_ringbuf_MovingAverage[ xx - 1 ] ) ), ( xx, yjump - int( self._graph_ringbuf_MovingAverage[ xx ] ) ), ( 0, 25, 255 ), 2 )\n\n                    # show midway mark for refrence\n                    cv2.line( vis, ( 0, yjump - int( yjump / 2 ) ), ( xjump - 1, yjump - int( yjump / 2 ) ), ( 128, 128, 128 ), 1 )\n                    cv2.line( vis, ( 0, yjump - int( self._graph_ringbuf_MovingAverage[ 0 ] ) ), ( xjump - 1, yjump - int( self._graph_ringbuf_MovingAverage[ 0 ] ) ), ( 0, 25, 255 ), 2 )\n\n                self._prev_frame_sum_of_values[ y ][ x ] = sum_of_values\n                last_X = x\n            last_Y = y\n\n        self._boundingBox = combine( self._activeRects )\n\n        # return the processed frame to be either passed to the next filter\n        # or displayed\n        self._frameCount += 1\n        return frame_in\n\n'"
vidpipe/dialog_main_auto.py,0,"b'# -*- coding: utf-8 -*-\n\n# Form implementation generated from reading ui file \'dialog_main.ui\'\n#\n# Created: Mon Mar 23 22:45:11 2015\n#      by: PyQt5 UI code generator 5.4\n#\n# WARNING! All changes made in this file will be lost!\n\nfrom PyQt5 import QtCore, QtGui, QtWidgets\nfrom CameraWidget import CameraWidget\n\nclass Ui_Dialog(object):\n    def setupUi(self, Dialog):\n        Dialog.setObjectName(""Dialog"")\n        Dialog.resize(1592, 552)\n        self.verticalLayout_2 = QtWidgets.QVBoxLayout(Dialog)\n        self.verticalLayout_2.setObjectName(""verticalLayout_2"")\n        self.horizontalLayout = QtWidgets.QHBoxLayout()\n        self.horizontalLayout.setObjectName(""horizontalLayout"")\n        self.verticalLayout_3 = QtWidgets.QVBoxLayout()\n        self.verticalLayout_3.setObjectName(""verticalLayout_3"")\n        self.horizontalLayout_6 = QtWidgets.QHBoxLayout()\n        self.horizontalLayout_6.setObjectName(""horizontalLayout_6"")\n        self.frame = QtWidgets.QFrame(Dialog)\n        self.frame.setMinimumSize(QtCore.QSize(640, 480))\n        self.frame.setMaximumSize(QtCore.QSize(640, 480))\n        self.frame.setFrameShape(QtWidgets.QFrame.StyledPanel)\n        self.frame.setFrameShadow(QtWidgets.QFrame.Raised)\n        self.frame.setObjectName(""frame"")\n        self.videoLive = CameraWidget(self.frame)\n        self.videoLive.setGeometry(QtCore.QRect(0, 0, 640, 480))\n        self.videoLive.setMinimumSize(QtCore.QSize(640, 480))\n        self.videoLive.setMaximumSize(QtCore.QSize(640, 480))\n        self.videoLive.setObjectName(""videoLive"")\n        self.horizontalLayout_6.addWidget(self.frame)\n        self.frame_2 = QtWidgets.QFrame(Dialog)\n        self.frame_2.setMinimumSize(QtCore.QSize(640, 480))\n        self.frame_2.setMaximumSize(QtCore.QSize(640, 480))\n        self.frame_2.setFrameShape(QtWidgets.QFrame.StyledPanel)\n        self.frame_2.setFrameShadow(QtWidgets.QFrame.Raised)\n        self.frame_2.setObjectName(""frame_2"")\n        self.videoFiltered = CameraWidget(self.frame_2)\n        self.videoFiltered.setGeometry(QtCore.QRect(0, 0, 640, 480))\n        self.videoFiltered.setMinimumSize(QtCore.QSize(640, 480))\n        self.videoFiltered.setMaximumSize(QtCore.QSize(640, 480))\n        self.videoFiltered.setObjectName(""videoFiltered"")\n        self.horizontalLayout_6.addWidget(self.frame_2)\n        self.verticalLayout_3.addLayout(self.horizontalLayout_6)\n        self.horizontalLayout_2 = QtWidgets.QHBoxLayout()\n        self.horizontalLayout_2.setObjectName(""horizontalLayout_2"")\n        self.label_Status = QtWidgets.QLabel(Dialog)\n        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Ignored, QtWidgets.QSizePolicy.Fixed)\n        sizePolicy.setHorizontalStretch(0)\n        sizePolicy.setVerticalStretch(0)\n        sizePolicy.setHeightForWidth(self.label_Status.sizePolicy().hasHeightForWidth())\n        self.label_Status.setSizePolicy(sizePolicy)\n        self.label_Status.setObjectName(""label_Status"")\n        self.horizontalLayout_2.addWidget(self.label_Status)\n        self.btnShowHist = QtWidgets.QPushButton(Dialog)\n        self.btnShowHist.setObjectName(""btnShowHist"")\n        self.horizontalLayout_2.addWidget(self.btnShowHist)\n        self.pushButton_2 = QtWidgets.QPushButton(Dialog)\n        self.pushButton_2.setObjectName(""pushButton_2"")\n        self.horizontalLayout_2.addWidget(self.pushButton_2)\n        self.verticalLayout_3.addLayout(self.horizontalLayout_2)\n        self.horizontalLayout.addLayout(self.verticalLayout_3)\n        self.filterList = QtWidgets.QListWidget(Dialog)\n        self.filterList.setObjectName(""filterList"")\n        self.horizontalLayout.addWidget(self.filterList)\n        self.horizontalLayout.setStretch(0, 1)\n        self.verticalLayout_2.addLayout(self.horizontalLayout)\n\n        self.retranslateUi(Dialog)\n        QtCore.QMetaObject.connectSlotsByName(Dialog)\n\n    def retranslateUi(self, Dialog):\n        _translate = QtCore.QCoreApplication.translate\n        Dialog.setWindowTitle(_translate(""Dialog"", ""Dialog""))\n        self.label_Status.setText(_translate(""Dialog"", ""This is status text!!!""))\n        self.btnShowHist.setText(_translate(""Dialog"", ""Color Histogram""))\n        self.pushButton_2.setText(_translate(""Dialog"", ""Don\\\'t Push Me""))\n\n'"
vidpipe/helpers.py,0,"b""#!/usr/bin/env python\n\nimport cv2\n\n# expects rect( x1, y1, w, h )\ndef combine( rects, thresh = 1 ):\n\n    if len( rects ) == 0:\n        return ( 0, 0, 0, 0 )\n\n    rect_array_x = [ [ rect[ 0 ], rect[ 0 ] + rect[ 2 ] ] for rect in rects ]\n    rect_array_y = [ [ rect[ 1 ], rect[ 1 ] + rect[ 3 ] ] for rect in rects ]\n\n    rect_array_x = [ number for inner in rect_array_x for number in inner ]\n    rect_array_y = [ number for inner in rect_array_y for number in inner ]\n\n    max_x = max( rect_array_x )\n    max_y = max( rect_array_y )\n    min_x = min( rect_array_x )\n    min_y = min( rect_array_y )\n\n    return ( min_x, min_y, max_x, max_y )\n\n# expects rect( x1, y1, x2, y2 )\ndef intersection_rect( rect1, rect2 ):\n    #  rect is ( x, y, w, h )\n    #            0  1  2  3\n\n    #  rect is ( x1, y1, x2, y2 )\n    #            0   1   2   3\n    x_tl = max( rect1[ 0 ], rect2[ 0 ] )\n    y_tl = max( rect1[ 1 ], rect2[ 1 ] )\n    x_br = min( rect1[ 2 ], rect2[ 2 ] )\n    y_br = min( rect1[ 3 ], rect2[ 3 ] )\n    if ( x_tl < x_br and y_tl < y_br ):\n        #return (x_tl, y_tl, x_br - x_tl, y_br - y_tl);\n        return (x_tl, y_tl, x_br, y_br);\n\n    return None\n\ndef intersection( rects ):\n    num_rects = len( rects )\n    if num_rects == 0:\n        return None\n    if num_rects == 1:\n        return rects[ 0 ]\n\n    intersect_rect = None\n    for rect_outer in rects:\n        if intersect_rect == None:\n            intersect_rect = rect_outer\n            continue\n\n        intersect_rect = intersection_rect( rect_outer, intersect_rect )\n\n        # we only care about when all intersect\n        if intersect_rect == None:\n            break\n\n    return intersect_rect\n\ndef draw_rect( dst, x, y, w, h, color ):\n    cv2.rectangle( dst, ( int( x ), int( y ) ), ( int( w ), int( h ) ), color, -1 )\n\n# blatently stolen from opencv/samples/python2/common.py\ndef clock():\n    return cv2.getTickCount() / cv2.getTickFrequency()\n\ndef draw_str(dst, x, y, s):\n    cv2.putText(dst, s, (x+1, y+1), cv2.FONT_HERSHEY_PLAIN, 1.0, (0, 0, 0), thickness = 2, lineType=cv2.LINE_AA)\n    cv2.putText(dst, s, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.0, (255, 255, 255), lineType=cv2.LINE_AA)\n\n\n'''\nx_overlap = Math.max(0, Math.min(x12,x22) - Math.max(x11,x21));\ny_overlap = Math.max(0, Math.min(y12,y22) - Math.max(y11,y21));\n'''\n"""
vidpipe/main.py,3,"b'#!/usr/bin/env python\n\nfrom __future__ import division\nimport sys\nimport numpy as np\nimport cv2\nimport random\n\nfrom PyQt5.QtWidgets import QApplication, QMainWindow, QLabel, QDialog, QGroupBox, QFrame, QLayout, QCheckBox, QListWidgetItem, QAbstractItemView, QSpinBox\nfrom PyQt5.QtWidgets import QHBoxLayout, QVBoxLayout, QWidget, QLineEdit\nfrom PyQt5.QtCore import pyqtSlot, pyqtSignal, QObject, QPoint, QEvent\nfrom PyQt5.QtCore import Qt, QSignalMapper, QVariant, QRegExp\nfrom PyQt5.QtGui import QRegExpValidator, QValidator, QPalette, QColor\nfrom dialog_main_auto import Ui_Dialog\n\nfrom helpers import draw_rect, draw_str, clock, combine, intersection_rect\n\nfrom FilterListOrderMapper import FilterListOrderMapper\n\nfrom CameraDevice import CameraDevice\nfrom CameraWidget import CameraWidget\n\nfrom FrameProcessor import FrameProcessor\nfrom EdgeDetector import EdgeDetector\nfrom BlurFilter import BlurFilter\nfrom BlockNumber import BlockNumber\nfrom Histogram import HistogramFilter\nfrom SimpleMotionDetection import SimpleMotionDetection\nfrom ActivityFilter import ActivityFilter\n\nclass KnobTurner( QObject, Ui_Dialog ):\n\n    _frameCount = 0                 # running total frames shown\n    _frameRate_RunningAvg = -1.0    # decaying average frame rate (displayed on video)\n    _alpha = 0.01                   # how fast to update the screen refresh frame rate display variable\n    _showHist = False\n    _histogramWindowName = ""Color Histogram""\n\n    class Mapper( QObject ):\n\n        def __init__(self, caller, called, action = None ):\n            QObject.__init__( self )\n            self._caller = caller\n            self._called = called\n            self._action = action\n\n        @property\n        def caller( self ):\n            return self._caller\n\n        @property\n        def called( self ):\n            return self._called\n\n        @property\n        def action( self ):\n            return self._action\n\n    def __init__( self ):\n        print( "">>>>>>>>>>>>>>>TODO: Restore the latest set of options??"" )\n        Ui_Dialog.__init__( self )\n        QObject.__init__( self )\n\n        self._filters = [\n            BlurFilter(),\n            SimpleMotionDetection(),\n            ActivityFilter(),\n            HistogramFilter(),\n            BlockNumber(),\n            EdgeDetector()\n            ]\n\n    @pyqtSlot( )\n    def resetFilterListModel( self ):\n        # if we get here then the filter list has been drag-rearranged\n\n        # reset the filter list based off the filterList order\n        self._filters = []\n        prev = None\n        for indx in range( 0, self.filterList.count() ):\n            fltr = self.filterList.item( indx ).data( Qt.UserRole )\n            self._filters.append( fltr )\n\n        for indx in range( 0, self.filterList.count() ):\n            print(""Index: %d Name: %s"" % ( indx, self.filterList.item( indx ).data( Qt.UserRole ).name ) )\n\n    def getFilterProperties( self, fltr ):\n        attribs = [ funct.replace( FrameProcessor.propStartsWith, """" ) for funct in dir( fltr ) if callable( getattr( fltr, funct ) ) and funct.startswith( FrameProcessor.propStartsWith ) ]\n\n        setters = [ ftn.replace( FrameProcessor.propEndsWithSetter, """" ) for ftn in attribs if ftn.endswith( FrameProcessor.propEndsWithSetter ) ]\n        getters = [ ftn.replace( FrameProcessor.propEndsWithGetter, """" ) for ftn in attribs if ftn.endswith( FrameProcessor.propEndsWithGetter ) ]\n\n        return getters, setters\n\n    def check_state( self, caller ):\n        validator = caller.validator()\n        state = validator.validate( caller.text(), 0 )[ 0 ]\n        if state == QValidator.Acceptable:\n            color = \'#c4df9b\' # green\n        elif state == QValidator.Intermediate:\n            color = \'#fff79a\' # yellow\n        else:\n            color = \'#f6989d\' # red\n        caller.setStyleSheet( \'QLineEdit { background-color: %s }\' % color )\n        return ( state == QValidator.Acceptable )\n\n    @pyqtSlot( QObject )\n    def saveFilterValue( self, obj ):\n        assert( isinstance( obj.caller, QSpinBox ) or isinstance( obj.caller, QCheckBox ) or isinstance( obj.caller, QLineEdit ) )\n\n        if isinstance( obj.caller, QSpinBox ):\n            newVal = obj.caller.value()\n        elif isinstance( obj.caller, QCheckBox ):\n            newVal = obj.caller.isChecked()\n        elif isinstance( obj.caller, QLineEdit ):\n            if self.check_state( obj.caller ) != True:\n                return\n            newVal = [ int( t ) for t in obj.caller.text().split( "","" ) ]\n\n        try:\n            func = getattr( obj.called, obj.action )\n        except AttributeError:\n            print( ""Whoops, for some reason the callback isn\'t valid."" )\n        else:\n            result = func( newVal )\n\n        # reset the frame rate\n        self._frameRate_RunningAvg = -1\n\n    def setupUi( self, dlg ):\n        Ui_Dialog.setupUi( self, dlg )\n\n        self.btnShowHist.clicked.connect( self.showHistogram )\n\n        self._filterListOrderMapper = FilterListOrderMapper()\n        self._filterListOrderMapper.listChanged.connect( self.resetFilterListModel )\n\n        self.filterList.installEventFilter( self._filterListOrderMapper )\n        self.filterList.setDragDropMode( QAbstractItemView.InternalMove )\n\n        self._optionMapper = QSignalMapper( dlg )\n        self._optionMapper.mapped[ QObject ].connect( self.saveFilterValue )\n        self._optionSave = []   # this is only for making sure the Mapper object doesn\'t get garbage collected\n\n        #regx = QRegExp( ""([0-9]{1,3}[\\,][ ]*){2}[0-9]{1,3}"" )\n        regx = QRegExp( ""([0-9]{1,3}[\\,][ ]*){1,2}[0-9]{1,3}"" )\n\n        for fltr in self._filters:\n            print( ""Filter added: %s"" % fltr.name )\n\n            fltr.loadConfig( None )\n\n            self.label_Status.setText( ""Loading filters"" )\n            getters, setters = self.getFilterProperties( fltr )\n            print( ""\\tAvailable GETable options: "", getters )\n            print( ""\\tAvailable SETable options: "", setters )\n\n            group = QGroupBox()\n            vbl = QVBoxLayout( group )\n\n            # Row ------\n            fm = QFrame()\n            vb = QVBoxLayout( fm )\n\n            vb.setSizeConstraint( QLayout.SetFixedSize )\n\n            # add the enabled checkbox first always\n            cb2 = QCheckBox( fltr.name )\n            cb2.setCheckState( getattr( fltr, FrameProcessor.propStartsWith + ""Enabled"" + FrameProcessor.propEndsWithGetter )() )\n            cb2.setStyleSheet( \'background-color:#%02x%02x%02x\' % ( fltr.color()[ :: -1 ] ) )\n            vb.addWidget( cb2 )\n            # watch for values changing\n            cb2.stateChanged.connect( self._optionMapper.map )\n            self._optionSave.append(\n                KnobTurner.Mapper( cb2, fltr,\n                                  FrameProcessor.propStartsWith + ""Enabled"" + FrameProcessor.propEndsWithSetter ) )\n            self._optionMapper.setMapping( cb2, self._optionSave[ -1 ] )\n\n            for item in setters:\n                prop_type = getattr( fltr, FrameProcessor.propTypeStartsWith + item )()\n                if prop_type is int:\n                    hz = QHBoxLayout()\n                    lb1 = QLabel( ""%s:"" % item )\n                    sp1 = QSpinBox()\n                    sp1.setRange( 0, 10000000 ) # TODO: add this as a query to the filter\n                    sp1.setValue( getattr( fltr, FrameProcessor.propStartsWith + item + FrameProcessor.propEndsWithGetter )() )\n                    vb.addWidget( lb1 )\n                    vb.addWidget( sp1 )\n\n                    # watch for values changing\n                    sp1.valueChanged.connect( self._optionMapper.map )\n                    self._optionSave.append(\n                        KnobTurner.Mapper( sp1, fltr,\n                                          FrameProcessor.propStartsWith + item + FrameProcessor.propEndsWithSetter ) )\n                    self._optionMapper.setMapping( sp1, self._optionSave[ -1 ] )\n\n                elif prop_type is bool:\n                    if item == ""Enabled"":\n                        continue\n                    else:\n                        cb2 = QCheckBox( item )\n                    cb2.setCheckState( getattr( fltr, FrameProcessor.propStartsWith + item + FrameProcessor.propEndsWithGetter )() )\n                    vb.addWidget( cb2 )\n\n                    # watch for values changing\n                    cb2.stateChanged.connect( self._optionMapper.map )\n                    self._optionSave.append(\n                        KnobTurner.Mapper( cb2, fltr,\n                                          FrameProcessor.propStartsWith + item + FrameProcessor.propEndsWithSetter ) )\n                    self._optionMapper.setMapping( cb2, self._optionSave[ -1 ] )\n                elif prop_type is tuple:\n                    hz = QHBoxLayout()\n                    lb1 = QLabel( ""%s:"" % item )\n\n                    val = getattr( fltr, FrameProcessor.propStartsWith + item + FrameProcessor.propEndsWithGetter )()\n                    le = QLineEdit( ""{0}"".format( val ).replace( ""("","""" ).replace( "")"", """" ).replace( ""["", """" ).replace( ""]"", """" ) )\n\n                    le.setValidator( QRegExpValidator( regx ) )\n                    le.textChanged.connect( self._optionMapper.map )\n                    le.textChanged.emit( le.text() )\n\n                    self._optionSave.append(\n                        KnobTurner.Mapper( le, fltr,\n                                          FrameProcessor.propStartsWith + item + FrameProcessor.propEndsWithSetter ) )\n                    self._optionMapper.setMapping( le, self._optionSave[ -1 ] )\n\n                    vb.addWidget( lb1 )\n                    vb.addWidget( le )\n            # end Row 2 -----\n\n            vbl.addWidget( fm )\n            vbl.setSizeConstraint( QLayout.SetFixedSize )\n\n            lwi = QListWidgetItem()\n            lwi.setSizeHint( vbl.sizeHint() )\n            lwi.setData( Qt.UserRole, QVariant( fltr ) )    # attach the filter to this item in the list\n            self.filterList.addItem( lwi )\n            self.filterList.setItemWidget( lwi, group )\n\n        self.label_Status.setText( ""Loading filters... Done"" )\n\n        self.label_Status.setText( ""Starting cameras..."" )\n        self.startCamera()\n        self.label_Status.setText( ""Starting cameras... Done"" )\n\n        self.showWindows()\n\n        self.label_Status.setText( ""Ready"" )\n\n    def startCamera( self ):\n        print( ""Starting camera"" )\n        #vid = ""drop.avi""    # use video instead of camera\n        vid = None\n        self._cameraDevice = CameraDevice( vid )\n\n        self.videoLive.setCamera( self._cameraDevice )\n        self.videoLive.newFrame.connect( self.processPreviewFrame )\n\n        self.videoFiltered.setCamera( self._cameraDevice )\n        self.videoFiltered.newFrame.connect( self.processFilteredFrame )\n\n    def showHistogram( self ):\n        self._showHist = not self._showHist\n\n        if not self._showHist:\n            cv2.destroyWindow( self._histogramWindowName )\n\n    def updateHistogram( self ):\n        bin_count = self.hist.shape[ 0 ]\n        bin_w = 40\n        img = np.zeros( ( 256, bin_count * bin_w, 3 ), np.uint8 )\n        for i in range( 0, bin_count ):\n            h = int( self.hist[ i ] )\n            cv2.rectangle( img, ( i * bin_w + 2, 255 ),                     # top left corner\n                                ( ( i + 1 ) * bin_w - 2, 255 - h ),         # bottom right corner\n                                ( int( 180.0 * i / bin_count ), 255, 255 ), # color\n                                -1 )                                        # -1 is fill shape\n        img = cv2.cvtColor( img, cv2.COLOR_HSV2BGR )\n        cv2.imshow( self._histogramWindowName, img )\n\n    def showWindows( self ):\n        self.videoLive.show()\n        self.videoFiltered.show()\n        print( ""Live video size: {}"", self.videoLive.sizeHint() )\n\n    @pyqtSlot( np.ndarray )\n    def processPreviewFrame(self, frame ):\n\n        # update histogram every 15th frame (picked arbitrarily)\n        if self._showHist == True and self._frameCount % 15 == 0:\n            hsv = cv2.cvtColor( frame, cv2.COLOR_BGR2HSV )\n            hist = cv2.calcHist( [ hsv ], [ 0 ], None, [ 16 ], [ 0, 180 ] )\n            cv2.normalize( hist, hist, 0, 255, cv2.NORM_MINMAX );\n            self.hist = hist.reshape( -1 )\n\n            self.updateHistogram()\n\n        intersect_box = None\n        colors = []\n        boxes = []\n        for fltr in self._filters:\n            if fltr.prop_Enabled_get():\n                box = fltr.getBoundingBox() # CAREFUL!!: returns (x1, y1, x2, y2) NOT x, y, w, h ****\n                if len( box ) != 0:\n                    colors.append( fltr.color() )\n                    boxes.append( box )\n                    if intersect_box == None:\n                        intersect_box = box\n                    else:\n                        intersect_box = intersection_rect( intersect_box, box )\n\n        # fade the color for all but the intersection of active areas\n        if intersect_box != None:\n            rectW = intersect_box[ 2 ] - intersect_box[ 0 ]\n            rectH = intersect_box[ 3 ] - intersect_box[ 1 ]\n            saverect = frame[ intersect_box[ 1 ] : intersect_box[ 1 ] + rectH, intersect_box[ 0 ] : intersect_box[ 0 ] + rectW ]\n\n        frame = cv2.cvtColor( frame, cv2.COLOR_BGR2GRAY )\n        ## TODO: this crashes now with \'TypeError: No loop matching the specified signature and casting was found for ufunc true_divide\' - new numpy\n        # frame /= 2  # cut the overal luminocity of the preview video by half to highlight the in-frame portion\n        frame = cv2.cvtColor( frame, cv2.COLOR_GRAY2BGR )\n\n        # restore the color to only the intersection\n        if intersect_box != None:\n            frame[ intersect_box[ 1 ] : intersect_box[ 1 ] + rectH, intersect_box[ 0 ] : intersect_box[ 0 ] + rectW ] = saverect\n\n        # paint the boxes back on top of the gray image\n        for index, box in enumerate( boxes ):\n            cv2.rectangle( frame, ( box[ 0 ], box[ 1 ] ), ( box[ 2 ], box[ 3 ] ), colors[ index ], 2 )\n\n        self.videoLive.setNewFrame( frame )\n\n    @pyqtSlot( np.ndarray )\n    def processFilteredFrame(self, frame ):\n        t = clock()\n\n        for fltr in self._filters:\n            if fltr.prop_Enabled_get() == True:   # I\'m cheating here because I know this property exists for all filters\n                frame = fltr.processFrame( frame )\n\n        # show time\n        delta_t = clock() - t\n        if self._frameRate_RunningAvg == -1:\n            self._frameRate_RunningAvg = delta_t\n        self._frameRate_RunningAvg = ( self._alpha * delta_t ) + ( 1.0 - self._alpha ) * self._frameRate_RunningAvg\n        draw_str( frame, 20, 20, \'time: %.1f ms\' % ( self._frameRate_RunningAvg * 1000 ) )\n\n        # last guy puts the frame up\n        self.videoFiltered.setNewFrame( frame )\n\n    @pyqtSlot()\n    def shutDown( self ):\n        print( "">>>>>>>>>>>>>>>TODO: Print and/or save the latest set of options!!"" )\n\n        for fltr in self._filters:\n            fltr.saveConfig( None )\n\n        print( ""Shutting down"" )\n\ndef main():\n    app = QApplication( sys.argv )\n\n    window = QDialog()\n    ui = KnobTurner()\n    ui.setupUi( window )\n\n    app.lastWindowClosed.connect( ui.shutDown )\n\n    window.show()\n    window.raise_()\n    sys.exit( app.exec_() )\n\nif __name__ == \'__main__\':\n    main()\n'"
vidpipe/gui/dialog_main.py,0,"b'# -*- coding: utf-8 -*-\n\n# Form implementation generated from reading ui file \'dialog_main.ui\'\n#\n# Created: Wed Feb 18 13:45:50 2015\n#      by: PyQt5 UI code generator 5.4\n#\n# WARNING! All changes made in this file will be lost!\n\nfrom PyQt5 import QtCore, QtGui, QtWidgets\n\nclass Ui_Dialog(object):\n    def setupUi(self, Dialog):\n        Dialog.setObjectName(""Dialog"")\n        Dialog.resize(1492, 536)\n        self.verticalLayout_2 = QtWidgets.QVBoxLayout(Dialog)\n        self.verticalLayout_2.setObjectName(""verticalLayout_2"")\n        self.horizontalLayout = QtWidgets.QHBoxLayout()\n        self.horizontalLayout.setObjectName(""horizontalLayout"")\n        self.verticalLayout_3 = QtWidgets.QVBoxLayout()\n        self.verticalLayout_3.setObjectName(""verticalLayout_3"")\n        self.horizontalLayout_6 = QtWidgets.QHBoxLayout()\n        self.horizontalLayout_6.setObjectName(""horizontalLayout_6"")\n        self.frame = QtWidgets.QFrame(Dialog)\n        self.frame.setMinimumSize(QtCore.QSize(640, 480))\n        self.frame.setMaximumSize(QtCore.QSize(640, 480))\n        self.frame.setFrameShape(QtWidgets.QFrame.StyledPanel)\n        self.frame.setFrameShadow(QtWidgets.QFrame.Raised)\n        self.frame.setObjectName(""frame"")\n        self.videoLive = QtWidgets.QWidget(self.frame)\n        self.videoLive.setGeometry(QtCore.QRect(0, 0, 640, 480))\n        self.videoLive.setMinimumSize(QtCore.QSize(640, 480))\n        self.videoLive.setMaximumSize(QtCore.QSize(640, 480))\n        self.videoLive.setObjectName(""videoLive"")\n        self.horizontalLayout_6.addWidget(self.frame)\n        self.frame_2 = QtWidgets.QFrame(Dialog)\n        self.frame_2.setMinimumSize(QtCore.QSize(640, 480))\n        self.frame_2.setMaximumSize(QtCore.QSize(640, 480))\n        self.frame_2.setFrameShape(QtWidgets.QFrame.StyledPanel)\n        self.frame_2.setFrameShadow(QtWidgets.QFrame.Raised)\n        self.frame_2.setObjectName(""frame_2"")\n        self.videoFiltered = QtWidgets.QWidget(self.frame_2)\n        self.videoFiltered.setGeometry(QtCore.QRect(0, 0, 640, 480))\n        self.videoFiltered.setMinimumSize(QtCore.QSize(640, 480))\n        self.videoFiltered.setMaximumSize(QtCore.QSize(640, 480))\n        self.videoFiltered.setObjectName(""videoFiltered"")\n        self.horizontalLayout_6.addWidget(self.frame_2)\n        self.verticalLayout_3.addLayout(self.horizontalLayout_6)\n        self.label_Status = QtWidgets.QLabel(Dialog)\n        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Ignored, QtWidgets.QSizePolicy.Fixed)\n        sizePolicy.setHorizontalStretch(0)\n        sizePolicy.setVerticalStretch(0)\n        sizePolicy.setHeightForWidth(self.label_Status.sizePolicy().hasHeightForWidth())\n        self.label_Status.setSizePolicy(sizePolicy)\n        self.label_Status.setObjectName(""label_Status"")\n        self.verticalLayout_3.addWidget(self.label_Status)\n        self.horizontalLayout.addLayout(self.verticalLayout_3)\n        self.verticalLayout = QtWidgets.QVBoxLayout()\n        self.verticalLayout.setSizeConstraint(QtWidgets.QLayout.SetDefaultConstraint)\n        self.verticalLayout.setObjectName(""verticalLayout"")\n        self.horizontalLayout_3 = QtWidgets.QHBoxLayout()\n        self.horizontalLayout_3.setSpacing(-1)\n        self.horizontalLayout_3.setSizeConstraint(QtWidgets.QLayout.SetDefaultConstraint)\n        self.horizontalLayout_3.setObjectName(""horizontalLayout_3"")\n        self.checkBox_Filter1 = QtWidgets.QCheckBox(Dialog)\n        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Fixed, QtWidgets.QSizePolicy.Fixed)\n        sizePolicy.setHorizontalStretch(0)\n        sizePolicy.setVerticalStretch(0)\n        sizePolicy.setHeightForWidth(self.checkBox_Filter1.sizePolicy().hasHeightForWidth())\n        self.checkBox_Filter1.setSizePolicy(sizePolicy)\n        self.checkBox_Filter1.setSizeIncrement(QtCore.QSize(0, 0))\n        self.checkBox_Filter1.setObjectName(""checkBox_Filter1"")\n        self.horizontalLayout_3.addWidget(self.checkBox_Filter1)\n        self.label_Filter1Name = QtWidgets.QLabel(Dialog)\n        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Fixed, QtWidgets.QSizePolicy.Fixed)\n        sizePolicy.setHorizontalStretch(0)\n        sizePolicy.setVerticalStretch(0)\n        sizePolicy.setHeightForWidth(self.label_Filter1Name.sizePolicy().hasHeightForWidth())\n        self.label_Filter1Name.setSizePolicy(sizePolicy)\n        self.label_Filter1Name.setObjectName(""label_Filter1Name"")\n        self.horizontalLayout_3.addWidget(self.label_Filter1Name)\n        self.verticalLayout.addLayout(self.horizontalLayout_3)\n        self.horizontalLayout_5 = QtWidgets.QHBoxLayout()\n        self.horizontalLayout_5.setSizeConstraint(QtWidgets.QLayout.SetDefaultConstraint)\n        self.horizontalLayout_5.setObjectName(""horizontalLayout_5"")\n        self.checkBox_Filter2 = QtWidgets.QCheckBox(Dialog)\n        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Fixed, QtWidgets.QSizePolicy.Fixed)\n        sizePolicy.setHorizontalStretch(0)\n        sizePolicy.setVerticalStretch(0)\n        sizePolicy.setHeightForWidth(self.checkBox_Filter2.sizePolicy().hasHeightForWidth())\n        self.checkBox_Filter2.setSizePolicy(sizePolicy)\n        self.checkBox_Filter2.setObjectName(""checkBox_Filter2"")\n        self.horizontalLayout_5.addWidget(self.checkBox_Filter2)\n        self.label_Filter2Name = QtWidgets.QLabel(Dialog)\n        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Fixed, QtWidgets.QSizePolicy.Fixed)\n        sizePolicy.setHorizontalStretch(0)\n        sizePolicy.setVerticalStretch(0)\n        sizePolicy.setHeightForWidth(self.label_Filter2Name.sizePolicy().hasHeightForWidth())\n        self.label_Filter2Name.setSizePolicy(sizePolicy)\n        self.label_Filter2Name.setObjectName(""label_Filter2Name"")\n        self.horizontalLayout_5.addWidget(self.label_Filter2Name)\n        self.verticalLayout.addLayout(self.horizontalLayout_5)\n        self.horizontalLayout_4 = QtWidgets.QHBoxLayout()\n        self.horizontalLayout_4.setSizeConstraint(QtWidgets.QLayout.SetDefaultConstraint)\n        self.horizontalLayout_4.setObjectName(""horizontalLayout_4"")\n        self.checkBox_Filter3 = QtWidgets.QCheckBox(Dialog)\n        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Fixed, QtWidgets.QSizePolicy.Fixed)\n        sizePolicy.setHorizontalStretch(0)\n        sizePolicy.setVerticalStretch(0)\n        sizePolicy.setHeightForWidth(self.checkBox_Filter3.sizePolicy().hasHeightForWidth())\n        self.checkBox_Filter3.setSizePolicy(sizePolicy)\n        self.checkBox_Filter3.setObjectName(""checkBox_Filter3"")\n        self.horizontalLayout_4.addWidget(self.checkBox_Filter3)\n        self.label_Filter3Name = QtWidgets.QLabel(Dialog)\n        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Fixed, QtWidgets.QSizePolicy.Fixed)\n        sizePolicy.setHorizontalStretch(0)\n        sizePolicy.setVerticalStretch(0)\n        sizePolicy.setHeightForWidth(self.label_Filter3Name.sizePolicy().hasHeightForWidth())\n        self.label_Filter3Name.setSizePolicy(sizePolicy)\n        self.label_Filter3Name.setObjectName(""label_Filter3Name"")\n        self.horizontalLayout_4.addWidget(self.label_Filter3Name)\n        self.verticalLayout.addLayout(self.horizontalLayout_4)\n        self.horizontalLayout.addLayout(self.verticalLayout)\n        self.horizontalLayout.setStretch(0, 1)\n        self.verticalLayout_2.addLayout(self.horizontalLayout)\n\n        self.retranslateUi(Dialog)\n        QtCore.QMetaObject.connectSlotsByName(Dialog)\n\n    def retranslateUi(self, Dialog):\n        _translate = QtCore.QCoreApplication.translate\n        Dialog.setWindowTitle(_translate(""Dialog"", ""Dialog""))\n        self.label_Status.setText(_translate(""Dialog"", ""This is status text!!!""))\n        self.checkBox_Filter1.setText(_translate(""Dialog"", ""Enable""))\n        self.label_Filter1Name.setText(_translate(""Dialog"", ""Filter 1 Name""))\n        self.checkBox_Filter2.setText(_translate(""Dialog"", ""Enable""))\n        self.label_Filter2Name.setText(_translate(""Dialog"", ""Filter 2 Name""))\n        self.checkBox_Filter3.setText(_translate(""Dialog"", ""Enable""))\n        self.label_Filter3Name.setText(_translate(""Dialog"", ""Filter 3 Name""))\n\n'"
vidpipe/gui/dialog_main_auto.py,0,"b'# -*- coding: utf-8 -*-\n\n# Form implementation generated from reading ui file \'dialog_main.ui\'\n#\n# Created: Mon Mar 23 22:45:11 2015\n#      by: PyQt5 UI code generator 5.4\n#\n# WARNING! All changes made in this file will be lost!\n\nfrom PyQt5 import QtCore, QtGui, QtWidgets\n\nclass Ui_Dialog(object):\n    def setupUi(self, Dialog):\n        Dialog.setObjectName(""Dialog"")\n        Dialog.resize(1592, 552)\n        self.verticalLayout_2 = QtWidgets.QVBoxLayout(Dialog)\n        self.verticalLayout_2.setObjectName(""verticalLayout_2"")\n        self.horizontalLayout = QtWidgets.QHBoxLayout()\n        self.horizontalLayout.setObjectName(""horizontalLayout"")\n        self.verticalLayout_3 = QtWidgets.QVBoxLayout()\n        self.verticalLayout_3.setObjectName(""verticalLayout_3"")\n        self.horizontalLayout_6 = QtWidgets.QHBoxLayout()\n        self.horizontalLayout_6.setObjectName(""horizontalLayout_6"")\n        self.frame = QtWidgets.QFrame(Dialog)\n        self.frame.setMinimumSize(QtCore.QSize(640, 480))\n        self.frame.setMaximumSize(QtCore.QSize(640, 480))\n        self.frame.setFrameShape(QtWidgets.QFrame.StyledPanel)\n        self.frame.setFrameShadow(QtWidgets.QFrame.Raised)\n        self.frame.setObjectName(""frame"")\n        self.videoLive = QtWidgets.QWidget(self.frame)\n        self.videoLive.setGeometry(QtCore.QRect(0, 0, 640, 480))\n        self.videoLive.setMinimumSize(QtCore.QSize(640, 480))\n        self.videoLive.setMaximumSize(QtCore.QSize(640, 480))\n        self.videoLive.setObjectName(""videoLive"")\n        self.horizontalLayout_6.addWidget(self.frame)\n        self.frame_2 = QtWidgets.QFrame(Dialog)\n        self.frame_2.setMinimumSize(QtCore.QSize(640, 480))\n        self.frame_2.setMaximumSize(QtCore.QSize(640, 480))\n        self.frame_2.setFrameShape(QtWidgets.QFrame.StyledPanel)\n        self.frame_2.setFrameShadow(QtWidgets.QFrame.Raised)\n        self.frame_2.setObjectName(""frame_2"")\n        self.videoFiltered = QtWidgets.QWidget(self.frame_2)\n        self.videoFiltered.setGeometry(QtCore.QRect(0, 0, 640, 480))\n        self.videoFiltered.setMinimumSize(QtCore.QSize(640, 480))\n        self.videoFiltered.setMaximumSize(QtCore.QSize(640, 480))\n        self.videoFiltered.setObjectName(""videoFiltered"")\n        self.horizontalLayout_6.addWidget(self.frame_2)\n        self.verticalLayout_3.addLayout(self.horizontalLayout_6)\n        self.horizontalLayout_2 = QtWidgets.QHBoxLayout()\n        self.horizontalLayout_2.setObjectName(""horizontalLayout_2"")\n        self.label_Status = QtWidgets.QLabel(Dialog)\n        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Ignored, QtWidgets.QSizePolicy.Fixed)\n        sizePolicy.setHorizontalStretch(0)\n        sizePolicy.setVerticalStretch(0)\n        sizePolicy.setHeightForWidth(self.label_Status.sizePolicy().hasHeightForWidth())\n        self.label_Status.setSizePolicy(sizePolicy)\n        self.label_Status.setObjectName(""label_Status"")\n        self.horizontalLayout_2.addWidget(self.label_Status)\n        self.btnShowHist = QtWidgets.QPushButton(Dialog)\n        self.btnShowHist.setObjectName(""btnShowHist"")\n        self.horizontalLayout_2.addWidget(self.btnShowHist)\n        self.pushButton_2 = QtWidgets.QPushButton(Dialog)\n        self.pushButton_2.setObjectName(""pushButton_2"")\n        self.horizontalLayout_2.addWidget(self.pushButton_2)\n        self.verticalLayout_3.addLayout(self.horizontalLayout_2)\n        self.horizontalLayout.addLayout(self.verticalLayout_3)\n        self.filterList = QtWidgets.QListWidget(Dialog)\n        self.filterList.setObjectName(""filterList"")\n        self.horizontalLayout.addWidget(self.filterList)\n        self.horizontalLayout.setStretch(0, 1)\n        self.verticalLayout_2.addLayout(self.horizontalLayout)\n\n        self.retranslateUi(Dialog)\n        QtCore.QMetaObject.connectSlotsByName(Dialog)\n\n    def retranslateUi(self, Dialog):\n        _translate = QtCore.QCoreApplication.translate\n        Dialog.setWindowTitle(_translate(""Dialog"", ""Dialog""))\n        self.label_Status.setText(_translate(""Dialog"", ""This is status text!!!""))\n        self.btnShowHist.setText(_translate(""Dialog"", ""Color Histogram""))\n        self.pushButton_2.setText(_translate(""Dialog"", ""Don\\\'t Push Me""))\n\n'"
