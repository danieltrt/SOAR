file_path,api_count,code
setup.py,0,"b'import os\n\nfrom setuptools import setup\n\n\ndef read(fname):\n    return open(os.path.join(os.path.dirname(__file__), fname)).read()\n\nsetup(\n    name = ""shifted_beta_geometric"",\n    version = ""0.0.1"",\n    author = ""JD Maturen"",\n    author_email = ""jdmaturen@gmail.com"",\n    description = """"""An implementation of the shifted-beta-geometric (sBG) model from Fader and Hardie\'s ""How to Project\n            Customer Retention"" (2006)"""""",\n    license = ""Apache 2"",\n    keywords = ""clv crm customer retention data modeling"",\n    # url = ""http://github.com/jdmaturen/shifted_beta_geometric_py"",\n    packages=[\'shifted_beta_geometric\'],\n\n    classifiers = [\n        ""Development Status :: 3 - Alpha"",\n        ""Programming Language :: Python"",\n        ""Topic :: Scientific/Engineering"",\n        ""Topic :: Software Development :: Libraries"",\n        ""License :: OSI Approved :: Apache Software License"",\n    ],\n)'"
shifted_beta_geometric/__init__.py,0,b'from .sbg import derl\nfrom .sbg import fit\nfrom .sbg import fit_multi_cohort\nfrom .sbg import predicted_retention\nfrom .sbg import predicted_survival\n'
shifted_beta_geometric/sbg.py,5,"b'""""""\nImplementation of the shifted beta geometric (sBG) model from ""How to Project Customer Retention"" (Fader and Hardie 2006)\n\nhttp://www.brucehardie.com/papers/021/sbg_2006-05-30.pdf\n\nApache 2 License\n""""""\n\nfrom math import log\n\nimport numpy as np\n\nfrom scipy.optimize import minimize\nfrom scipy.special import hyp2f1\n\n__author__ = \'JD Maturen\'\n\n\ndef generate_probabilities(alpha, beta, x):\n    """"""Generate probabilities in one pass for all t in x""""""\n    p = [alpha / (alpha + beta)]\n    for t in range(1, x):\n        pt = (beta + t - 1) / (alpha + beta + t) * p[t-1]\n        p.append(pt)\n    return p\n\n\ndef probability(alpha, beta, t):\n    """"""Probability function P""""""\n    if t == 0:\n        return alpha / (alpha + beta)\n    return (beta + t - 1) / (alpha + beta + t) * probability(alpha, beta, t-1)\n\n\ndef survivor(probabilities, t):\n    """"""Survivor function S""""""\n    s = 1 - probabilities[0]\n    for x in range(1, t + 1):\n        s = s - probabilities[x]\n    return s\n\n\ndef log_likelihood(alpha, beta, data, survivors=None):\n    """"""Function to maximize to obtain ideal alpha and beta parameters""""""\n    if alpha <= 0 or beta <= 0:\n        return -1000\n    if survivors is None:\n        survivors = survivor_rates(data)\n    probabilities = generate_probabilities(alpha, beta, len(data))\n    final_survivor_likelihood = survivor(probabilities, len(data) - 1)\n\n    return sum([s * log(probabilities[t]) for t, s in enumerate(survivors)]) + data[-1] * log(final_survivor_likelihood)\n\n\ndef log_likelihood_multi_cohort(alpha, beta, data):\n    """"""Function to maximize to obtain ideal alpha and beta parameters using data across multiple (contiguous) cohorts.\n    `data` must be a list of cohorts each with an absolute number per observed time unit.""""""\n    if alpha <= 0 or beta <= 0:\n        return -1000\n    probabilities = generate_probabilities(alpha, beta, len(data[0]))\n\n    cohorts = len(data)\n    total = 0\n    for i, cohort in enumerate(data):\n        total += sum([(cohort[j]-cohort[j+1])*log(probabilities[j]) for j in range(len(cohort)-1)])\n        total += cohort[-1] * log(survivor(probabilities, cohorts - i - 1))\n    return total\n\n\ndef survivor_rates(data):\n    s = []\n    for i, x in enumerate(data):\n        if i == 0:\n            s.append(1 - data[0])\n        else:\n            s.append(data[i-1] - data[i])\n    return s\n\n\ndef maximize(data):\n    survivors = survivor_rates(data)\n    func = lambda x: -log_likelihood(x[0], x[1], data, survivors)\n    x0 = np.array([100., 100.])\n    res = minimize(func, x0, method=\'nelder-mead\', options={\'xtol\': 1e-8})\n    return res\n\n\ndef maximize_multi_cohort(data):\n    func = lambda x: -log_likelihood_multi_cohort(x[0], x[1], data)\n    x0 = np.array([1., 1.])\n    res = minimize(func, x0, method=\'nelder-mead\', options={\'xtol\': 1e-8})\n    return res\n\n\ndef predicted_retention(alpha, beta, t):\n    """"""Predicted retention probability at t. Function 8 in the paper""""""\n    return (beta + t) / (alpha + beta + t)\n\n\ndef predicted_survival(alpha, beta, x):\n    """"""Predicted survival probability, i.e. percentage of customers retained, for all t in x.\n    Function 1 in the paper""""""\n    s = [predicted_retention(alpha, beta, 0)]\n    for t in range(1, x):\n        s.append(predicted_retention(alpha, beta, t) * s[t-1])\n    return s\n\n\ndef fit(data):\n    res = maximize(data)\n    if res.status != 0:\n        raise Exception(res.message)\n    return res.x\n\n\ndef fit_multi_cohort(data):\n    res = maximize_multi_cohort(data)\n    if res.status != 0:\n        raise Exception(res.message)\n    return res.x\n\n\ndef derl(alpha, beta, d, n):\n    """"""discounted expected residual lifetime from ""Customer-Base Valuation in a Contractual Setting: The Perils of\n    Ignoring Heterogeneity"" (Fader and Hardie 2009)""""""\n    return predicted_retention(alpha, beta, n) * hyp2f1(1, beta + n + 1, alpha + beta + n + 1, 1 / (1 + d))\n\n\ndef test():\n    """"""Test against the High End subscription retention data from the paper""""""\n    example_data = [.869, .743, .653, .593, .551, .517, .491]\n    ll11 = log_likelihood(1., 1., example_data)\n    print(np.allclose(ll11, -2.115, 1e-3))\n\n    res = maximize(example_data)\n    alpha, beta = res.x\n    print(res.status == 0 and np.allclose(alpha, 0.668, 1e-3) and np.allclose(beta, 3.806, 1e-3))\n    print()\n\n    print(""real\\t"", [""{0:.1f}%"".format(x*100) for x in example_data])\n    print(""pred\\t"", [""{0:.1f}%"".format(x*100) for x in predicted_survival(alpha, beta, 12)])\n    print()\n\n    print(list(map(""{0:f}"".format, [derl(alpha, beta, 0.1, x) for x in range(12)])))\n    print()\n\n    multi_cohort_data = [[10000, 8000, 6480, 5307, 4391], [10000, 8000, 6480, 5307], [10000, 8000, 6480], [10000, 8000]]\n    alpha, beta = fit_multi_cohort(multi_cohort_data)\n    print(np.allclose(alpha, 3.80, 1e-2) and np.allclose(beta, 15.19, 1e-2))\n\n\nif __name__ == \'__main__\':\n    test()\n'"
