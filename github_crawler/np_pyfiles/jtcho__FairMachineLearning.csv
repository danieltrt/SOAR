file_path,api_count,code
evaluation_T.py,3,"b""import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom fairml import beta, compute_chain, eta, interval_chaining, top_interval\n\n\ndef main():\n    c_vals = [1.0, 2.0, 5.0, 10.0]\n\n    # Plot: Varying T (# of rounds)\n    d = 2\n    k = 2\n    T_vals = range(3, 1000, 10)\n\n    results = {\n        '0': {\n            'ylabel': 'Average regret - TI',\n            'name': 'avg_regret_ti'\n        },\n        '1': {\n            'ylabel': 'Average regret - IC',\n            'name': 'avg_regret_ic'\n        },\n        '2': {\n            'ylabel': 'Average regret difference (TI - IC)',\n            'name': 'avg_regret_diff'\n        },\n        '3': {\n            'ylabel': 'Cumulative regret - TI',\n            'name': 'cum_regret_ti'\n        },\n        '4': {\n            'ylabel': 'Cumulative regret - IC',\n            'name': 'cum_regret_ic'\n        },\n        '5': {\n            'ylabel': 'Cumulative regret difference (TI - IC)',\n            'name': 'cum_regret_diff'\n        },\n        '6': {\n            'ylabel': 'Final regret - TI',\n            'name': 'final_regret_ti'\n        },\n        '7': {\n            'ylabel': 'Final regret - IC',\n            'name': 'final_regret_ic'\n        },\n        '8': {\n            'ylabel': 'Final regret difference (TI - IC)',\n            'name': 'final_regret_diff'\n        }\n    }\n    for _, v in results.items():  # 9 sets of results.\n        for j in c_vals:\n            v[str(j)] = []\n\n    for c in c_vals:\n        for T in T_vals:\n            cum_regret_tis = []\n            avg_regret_tis = []\n            final_regret_tis = []\n            cum_regret_ics = []\n            avg_regret_ics = []\n            final_regret_ics = []\n            for i in range(0, 50):  # 50 trials.\n                X = np.random.uniform(0, 1, size=(T, k, d))\n                B = beta(k, d, c)\n                Y = np.array([np.diag(X[t].dot(np.transpose(B))) for t in range(T)])\n\n                cum_regret_ti, avg_regret_ti, final_regret_ti = top_interval(\n                        X, Y, k, d, 0.05, T, _print_progress=False)\n                cum_regret_ic, avg_regret_ic, final_regret_ic = interval_chaining(\n                        X, Y, c, k, d, 0.05, T, _print_progress=False)\n                cum_regret_tis.append(cum_regret_ti)\n                avg_regret_tis.append(avg_regret_ti)\n                final_regret_tis.append(final_regret_ti)\n                cum_regret_ics.append(cum_regret_ic)\n                avg_regret_ics.append(avg_regret_ic)\n                final_regret_ics.append(final_regret_ic)\n            cum_regret_ti = mean(cum_regret_tis)\n            avg_regret_ti = mean(avg_regret_tis)\n            final_regret_ti = mean(avg_regret_tis)\n            cum_regret_ic = mean(cum_regret_ics)\n            avg_regret_ic = mean(avg_regret_ics)\n            final_regret_ics = mean(final_regret_ics)\n\n            results['0'][str(c)].append(avg_regret_ti)\n            results['1'][str(c)].append(avg_regret_ic)\n            results['2'][str(c)].append(abs(avg_regret_ti - avg_regret_ic))\n            results['3'][str(c)].append(cum_regret_ti)\n            results['4'][str(c)].append(cum_regret_ic)\n            results['5'][str(c)].append(abs(cum_regret_ti - cum_regret_ic))\n            results['6'][str(c)].append(final_regret_ti)\n            results['7'][str(c)].append(final_regret_ic)\n            results['8'][str(c)].append(abs(final_regret_ti - final_regret_ic))\n\n    for k, v in results.items():\n        plt.clf()\n        c1, = plt.plot(T_vals, results[k]['1.0'], label='c=1')\n        c2, = plt.plot(T_vals, results[k]['2.0'], label='c=2')\n        c5, = plt.plot(T_vals, results[k]['5.0'], label='c=5')\n        c10, = plt.plot(T_vals, results[k]['10.0'], label='c=10')\n        plt.xticks(np.arange(min(T_vals), max(T_vals) + 1, 200))\n        plt.legend(handles=[c1, c2, c5, c10])\n        plt.xlabel('T (# of rounds)', fontsize=18)\n        plt.ylabel(v['ylabel'], fontsize=15)\n        plt.savefig('figures_T_50x/T_50x_' + v['name'])\n\n\ndef mean(numbers):\n    return float(sum(numbers)) / max(len(numbers), 1)\n\n\nif __name__ == '__main__':\n    main()\n"""
evaluation_d.py,3,"b""import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom fairml import beta, compute_chain, eta, interval_chaining, top_interval\n\n\ndef main():\n    c_vals = [1.0, 2.0, 5.0, 10.0]\n\n    # Plot: Varying d (confidence)\n    d_vals = range(1, 50)\n    k = 2\n    T = 1000\n\n    results = {\n        '0': {\n            'ylabel': 'Average regret - TI',\n            'name': 'avg_regret_ti'\n        },\n        '1': {\n            'ylabel': 'Average regret - IC',\n            'name': 'avg_regret_ic'\n        },\n        '2': {\n            'ylabel': 'Average regret difference (TI - IC)',\n            'name': 'avg_regret_diff'\n        },\n        '3': {\n            'ylabel': 'Cumulative regret - TI',\n            'name': 'cum_regret_ti'\n        },\n        '4': {\n            'ylabel': 'Cumulative regret - IC',\n            'name': 'cum_regret_ic'\n        },\n        '5': {\n            'ylabel': 'Cumulative regret difference (TI - IC)',\n            'name': 'cum_regret_diff'\n        },\n        '6': {\n            'ylabel': 'Final regret - TI',\n            'name': 'final_regret_ti'\n        },\n        '7': {\n            'ylabel': 'Final regret - IC',\n            'name': 'final_regret_ic'\n        },\n        '8': {\n            'ylabel': 'Final regret difference (TI - IC)',\n            'name': 'final_regret_diff'\n        }\n    }\n    for _, v in results.items():  # 9 sets of results.\n        for j in c_vals:\n            v[str(j)] = []\n\n    for c in c_vals:\n        for d in d_vals:\n            cum_regret_tis = []\n            avg_regret_tis = []\n            final_regret_tis = []\n            cum_regret_ics = []\n            avg_regret_ics = []\n            final_regret_ics = []\n            for i in range(0, 50):  # 500 trials.\n                X = np.random.uniform(0, 1, size=(T, k, d))\n                B = beta(k, d, c)\n                Y = np.array([np.diag(X[t].dot(np.transpose(B))) for t in range(T)])\n\n                cum_regret_ti, avg_regret_ti, final_regret_ti = top_interval(\n                        X, Y, k, d, 0.05, T, _print_progress=False)\n                cum_regret_ic, avg_regret_ic, final_regret_ic = interval_chaining(\n                        X, Y, c, k, d, 0.05, T, _print_progress=False)\n                cum_regret_tis.append(cum_regret_ti)\n                avg_regret_tis.append(avg_regret_ti)\n                final_regret_tis.append(final_regret_ti)\n                cum_regret_ics.append(cum_regret_ic)\n                avg_regret_ics.append(avg_regret_ic)\n                final_regret_ics.append(final_regret_ic)\n            cum_regret_ti = mean(cum_regret_tis)\n            avg_regret_ti = mean(avg_regret_tis)\n            final_regret_ti = mean(avg_regret_tis)\n            cum_regret_ic = mean(cum_regret_ics)\n            avg_regret_ic = mean(avg_regret_ics)\n            final_regret_ics = mean(final_regret_ics)\n\n            results['0'][str(c)].append(avg_regret_ti)\n            results['1'][str(c)].append(avg_regret_ic)\n            results['2'][str(c)].append(abs(avg_regret_ti - avg_regret_ic))\n            results['3'][str(c)].append(cum_regret_ti)\n            results['4'][str(c)].append(cum_regret_ic)\n            results['5'][str(c)].append(abs(cum_regret_ti - cum_regret_ic))\n            results['6'][str(c)].append(final_regret_ti)\n            results['7'][str(c)].append(final_regret_ic)\n            results['8'][str(c)].append(abs(final_regret_ti - final_regret_ic))\n\n    for k, v in results.items():\n        plt.clf()\n        c1, = plt.plot(d_vals, results[k]['1.0'], label='c=1')\n        c2, = plt.plot(d_vals, results[k]['2.0'], label='c=2')\n        c5, = plt.plot(d_vals, results[k]['5.0'], label='c=5')\n        c10, = plt.plot(d_vals, results[k]['10.0'], label='c=10')\n        plt.xticks(np.arange(min(d_vals), max(d_vals) + 1, 10))\n        plt.legend(handles=[c1, c2, c5, c10])\n        plt.xlabel('d (# of features)', fontsize=18)\n        plt.ylabel(v['ylabel'], fontsize=15)\n        plt.savefig('figures_d_50x/d_50x_' + v['name'])\n\n\ndef mean(numbers):\n    return float(sum(numbers)) / max(len(numbers), 1)\n\n\nif __name__ == '__main__':\n    main()\n"""
evaluation_k.py,3,"b""import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom fairml import beta, compute_chain, eta, interval_chaining, top_interval\n\n\ndef main():\n    c_vals = [1.0, 2.0, 5.0, 10.0]\n\n    # Plot: Varying k (# groups)\n    d = 2\n    k_vals = range(1, 50, 5)\n    T = 1000\n\n    results = {\n        '0': {\n            'ylabel': 'Average regret - TI',\n            'name': 'avg_regret_ti'\n        },\n        '1': {\n            'ylabel': 'Average regret - IC',\n            'name': 'avg_regret_ic'\n        },\n        '2': {\n            'ylabel': 'Average regret difference (TI - IC)',\n            'name': 'avg_regret_diff'\n        },\n        '3': {\n            'ylabel': 'Cumulative regret - TI',\n            'name': 'cum_regret_ti'\n        },\n        '4': {\n            'ylabel': 'Cumulative regret - IC',\n            'name': 'cum_regret_ic'\n        },\n        '5': {\n            'ylabel': 'Cumulative regret difference (TI - IC)',\n            'name': 'cum_regret_diff'\n        },\n        '6': {\n            'ylabel': 'Final regret - TI',\n            'name': 'final_regret_ti'\n        },\n        '7': {\n            'ylabel': 'Final regret - IC',\n            'name': 'final_regret_ic'\n        },\n        '8': {\n            'ylabel': 'Final regret difference (TI - IC)',\n            'name': 'final_regret_diff'\n        }\n    }\n    for _, v in results.items():  # 9 sets of results.\n        for j in c_vals:\n            v[str(j)] = []\n\n    for c in c_vals:\n        for k in k_vals:\n            cum_regret_tis = []\n            avg_regret_tis = []\n            final_regret_tis = []\n            cum_regret_ics = []\n            avg_regret_ics = []\n            final_regret_ics = []\n            for i in range(0, 50):  # 50 trials.\n                X = np.random.uniform(0, 1, size=(T, k, d))\n                B = beta(k, d, c)\n                Y = np.array([np.diag(X[t].dot(np.transpose(B))) for t in range(T)])\n\n                cum_regret_ti, avg_regret_ti, final_regret_ti = top_interval(\n                        X, Y, k, d, 0.05, T, _print_progress=False)\n                cum_regret_ic, avg_regret_ic, final_regret_ic = interval_chaining(\n                        X, Y, c, k, d, 0.05, T, _print_progress=False)\n                cum_regret_tis.append(cum_regret_ti)\n                avg_regret_tis.append(avg_regret_ti)\n                final_regret_tis.append(final_regret_ti)\n                cum_regret_ics.append(cum_regret_ic)\n                avg_regret_ics.append(avg_regret_ic)\n                final_regret_ics.append(final_regret_ic)\n            cum_regret_ti = mean(cum_regret_tis)\n            avg_regret_ti = mean(avg_regret_tis)\n            final_regret_ti = mean(avg_regret_tis)\n            cum_regret_ic = mean(cum_regret_ics)\n            avg_regret_ic = mean(avg_regret_ics)\n            final_regret_ics = mean(final_regret_ics)\n\n            results['0'][str(c)].append(avg_regret_ti)\n            results['1'][str(c)].append(avg_regret_ic)\n            results['2'][str(c)].append(abs(avg_regret_ti - avg_regret_ic))\n            results['3'][str(c)].append(cum_regret_ti)\n            results['4'][str(c)].append(cum_regret_ic)\n            results['5'][str(c)].append(abs(cum_regret_ti - cum_regret_ic))\n            results['6'][str(c)].append(final_regret_ti)\n            results['7'][str(c)].append(final_regret_ic)\n            results['8'][str(c)].append(abs(final_regret_ti - final_regret_ic))\n\n    for k, v in results.items():\n        plt.clf()\n        c1, = plt.plot(k_vals, results[k]['1.0'], label='c=1')\n        c2, = plt.plot(k_vals, results[k]['2.0'], label='c=2')\n        c5, = plt.plot(k_vals, results[k]['5.0'], label='c=5')\n        c10, = plt.plot(k_vals, results[k]['10.0'], label='c=10')\n        plt.xticks(np.arange(min(k_vals), max(k_vals) + 1, 10))\n        plt.legend(handles=[c1, c2, c5, c10])\n        plt.xlabel('k (# of groups)', fontsize=18)\n        plt.ylabel(v['ylabel'], fontsize=15)\n        plt.savefig('figures_k_50x/k_50x_' + v['name'])\n\n\ndef mean(numbers):\n    return float(sum(numbers)) / max(len(numbers), 1)\n\n\nif __name__ == '__main__':\n    main()\n"""
fairml.py,21,"b'from math import sqrt\nimport numpy as np\nfrom numpy import log, transpose\nfrom numpy.linalg import inv\nfrom scipy.stats import norm\n\n\ndef eta(T):\n    """"""\n    Generates the cutoff probabilities for exploration rounds in interval\n    chaining.\n\n    :param T: the total number of iterations\n    """"""\n    return np.array([pow(t, -1/3) for t in range(1, T+1)])\n\n\ndef beta(k, d, c):\n    """"""\n    Generates the scaled down feature weights for a true model from the\n    distribution \xce\xb2 \xe2\x88\xbc U[0, c]^d.\n\n    :param k: the number of arms\n    :param d: the number of features\n    :param c: the scale of the feature weights\n    """"""\n    return np.random.uniform(0, c+1, size=(k, d))\n\n\ndef print_progress(s, should_print):\n    """"""\n    Helper function to print the progress of an algorithm as it\'s running.\n\n    :param s: the string to print\n    :should_print: whether or not the string should be printed\n    """"""\n    if should_print:\n        print(s)\n\n\ndef top_interval(X, Y, k, d, _delta, T, _print_progress=True):\n    """"""\n    Simulates T rounds of TopInterval for k.\n\n    :param X: a 3-axis (T, k, d) ndarray of d-dimensional context vectors for\n              each time-step and arm\n    :param Y: a T x k ndarray of reward function output for each context vector\n    :param k: the number of arms\n    :param d: the number of features\n    :param _delta: confidence parameter\n    :param T: the number of iterations\n    :param _print_progress: True if progress should be printed; False otherwise\n    :returns: cum_regret (the total regret across all T runs of the algorithm),\n              avg_regret (the regret averaged across all T runs of the algorithm),\n              final_regret (the regret in the last round of the algorithm)\n    """"""\n    pp = _print_progress\n    _eta = eta(T)  # exploration cutoff probabilities\n    picks = []\n    for t in range(T):\n        print_progress(\'Iteration [{0} / {1}]\'.format(t, T), pp)\n        if t <= d or np.random.rand() <= _eta[t]:\n            # Play uniformly at random from [1, k].\n            picks.append(np.random.randint(0, k))\n            print_progress(\'Exploration round.\', pp)\n        else:\n            intervals = []\n            for i in range(k):\n                # Compute beta hat.\n                _Xti = X[:t+1, i]\n                _XtiT = transpose(_Xti)\n                try:\n                    _XTX = inv(_XtiT.dot(_Xti))\n                except:\n                    print_progress(\'Encountered singular matrix. Ignoring.\', pp)\n                    continue\n                _Yti = Y[:t+1, i]\n                Bh_t_i = _XTX.dot(_XtiT).dot(_Yti)  # Compute OLS estimators.\n                yh_t_i = Bh_t_i.dot(X[t, i])\n                _s2 = np.var(Y[:t+1, i])\n                # Compute the confidence interval width using the inverse CDF.\n                w_t_i = norm.ppf(1 - _delta/(2*T*k), loc=0,\n                                 scale=np.sqrt(_s2 * X[t, i].dot(_XTX).dot(transpose(X[t, i]))))\n                intervals.append([yh_t_i - w_t_i, yh_t_i + w_t_i])\n            # Pick the agent with the largest upper bound.\n            picks.append(np.argmax(np.array(intervals)[:, 1]) if intervals else np.random.randint(0, k))\n            print_progress(\'Intervals: {0}\'.format(intervals), pp)\n    # Compute sum of best picks over each iteration.\n    best = [Y[i].max() for i in range(2, T)]\n    performance = [Y[t][picks[t-2]] for t in range(2, T)]\n    cum_regret = sum(best) - sum(performance)\n    avg_regret = cum_regret / float(T)\n    final_regret = best[-1] - performance[-1]\n    print_progress(\'Cumulative Regret: {0}\'.format(cum_regret), pp)\n    print_progress(\'Average Regret: {0}\'.format(avg_regret), pp)\n    print_progress(\'Final Regret: {0}\'.format(final_regret), pp)\n    return cum_regret, avg_regret, final_regret\n\n\ndef compute_chain(i_st, intervals, k, _print_progress=True):\n    # Sort intervals by decreasing order.\n    pp = _print_progress\n    chain = [i_st]\n    print_progress(intervals[:, 1], pp)\n    ordering = np.argsort(intervals[:, 1])[::-1]\n    intervals = intervals[ordering, :]\n\n    lowest_in_chain = intervals[0][0]\n    for i in range(1, k):\n        if intervals[i][1] >= lowest_in_chain:\n            chain.append(i)\n            lowest_in_chain = min(lowest_in_chain, intervals[i][0])\n        else:\n            return chain\n    return chain\n\n\ndef interval_chaining(X, Y, c, k, d, _delta, T, _print_progress=True):\n    """"""\n    Simulates T rounds of TopInterval for k.\n\n    :param X: a 3-axis (T, k, d) ndarray of d-dimensional context vectors for\n              each time-step and arm\n    :param Y: a T x k ndarray of reward function output for each context vector\n    :param k: the number of arms\n    :param d: the number of features\n    :param _delta: confidence parameter\n    :param T: the number of iterations\n    :param _print_progress: True if progress should be printed; False otherwise\n    :returns: cum_regret (the total regret across all T runs of the algorithm),\n              avg_regret (the regret averaged across all T runs of the algorithm),\n              final_regret (the regret in the last round of the algorithm)\n    """"""\n    pp = _print_progress\n    _eta = eta(T)  # exploration cutoff probabilities\n    picks = []\n    for t in range(T):\n        print_progress(\'Iteration [{0} / {1}]\'.format(t, T), pp)\n        if t <= d or np.random.rand() <= _eta[t]:\n            # Play uniformly at random from [1, k].\n            picks.append(np.random.randint(0, k))\n            print_progress(\'Exploration round.\', pp)\n        else:\n            intervals = []\n            for i in range(k):\n                # Compute beta hat.\n                _Xti = X[:t+1, i]\n                _XtiT = transpose(_Xti)\n                try:\n                    _XTX = inv(_XtiT.dot(_Xti))\n                except:\n                    print_progress(\'Encountered singular matrix. Ignoring.\', pp)\n                    continue\n                _Yti = Y[:t+1, i]\n                Bh_t_i = _XTX.dot(_XtiT).dot(_Yti)  # Compute OLS estimators.\n                yh_t_i = Bh_t_i.dot(X[t, i])\n                _s2 = np.var(Y[:t+1, i])\n                # Compute the confidence interval width using the inverse CDF.\n                w_t_i = norm.ppf(1 - _delta/(2*T*k), loc=0,\n                                 scale=np.sqrt(_s2 * X[t, i].dot(_XTX).dot(transpose(X[t, i]))))\n                intervals.append([yh_t_i - w_t_i, yh_t_i + w_t_i])\n            # Pick the agent with the largest upper bound.\n            if not intervals:\n                picks.append(np.random.randint(0, k))\n            else:\n                i_st = np.argmax(np.array(intervals)[:, 1])\n\n                # Chaining\n                chain = compute_chain(i_st, np.array(intervals), k, pp)\n                print_progress(\'Computed chain: {0}\'.format(chain), pp)\n                picks.append(np.random.choice(chain))\n            print_progress(\'Intervals: {0}\'.format(intervals), pp)\n    # Compute sum of best picks over each iteration.\n    best = [Y[i].max() for i in range(2, T)]\n    performance = [Y[t][picks[t-2]] for t in range(2, T)]\n    cum_regret = sum(best) - sum(performance)\n    avg_regret = cum_regret / float(T)\n    final_regret = best[-1] - performance[-1]\n    print_progress(\'Cumulative Regret: {0}\'.format(cum_regret), pp)\n    print_progress(\'Average Regret: {0}\'.format(avg_regret), pp)\n    print_progress(\'Final Regret: {0}\'.format(final_regret), pp)\n    return cum_regret, avg_regret, final_regret\n\n\ndef ridge_fair(X, Y, k, d, _delta, T, _lambda, _print_progress=True):\n    """"""\n    Simulates T rounds of ridge_fair.\n\n    :param X: a 3-axis (T, k, d) ndarray of d-dimensional context vectors for\n              each time-step and arm\n    :param Y: a T x k ndarray of reward function output for each context vector\n    :param k: the number of arms\n    :param d: the number of features\n    :param _delta: confidence parameter\n    :param T: the number of iterations\n    :param _lambda: regularization paramameter\n    """"""\n    picks = []\n    for t in range(T):\n        for i in range(k):\n            R = 1\n            intervals = []\n            try:\n                X_i = X[:t, i]  # design matrix\n                Y_i = Y[:t, i]  # same with Y\n                x_ti = X[t, i]  # feature vector for arm i in round t\n\n                X_iT = transpose(X_i)\n                _idenD = np.identity(d)\n                V_it = X_iT.dot(X_i) + (_lambda * _idenD)\n\n                B_it = inv(V_it).dot(X_iT).dot(Y_i)\n\n                y_ti = transpose(x_ti).dot(B_it)\n\n                V_itI = inv(V_it)  # inverse of V_it\n                _wti1 = sqrt(transpose(x_ti).dot(V_itI).dot(x_ti))\n                _wti2 = R * sqrt(d * log((1 + (t / _lambda)) / _delta)) + sqrt(_lambda)\n                w_ti = _wti1 * _wti2\n\n                intervals.append([y_ti - w_ti, y_ti + w_ti])\n            except:\n                    print_progress(\'Error in assigning interval value.\', _print_progress)\n                    intervals = None\n                    break\n            if not intervals:\n                picks.append(np.random.randint(0, k))\n            else:\n                i_st = np.argmax(np.array(intervals)[:, 1])\n                chain = compute_chain(i_st, np.array(intervals), k)\n                # play uniformly random from chain\n                picks.append(np.random.choice(chain))\n\n    best = [Y[i].max() for i in range(2, T)]\n    performance = [Y[t][picks[t - 2]] for t in range(2, T)]\n    print_progress(\'Cumulative Regret: {0}\'.format(sum(best) - sum(performance)), _print_progress)\n    print_progress(\'Final Regret: {0}\'.format(best[-1] - performance[-1]), _print_progress)\n'"
