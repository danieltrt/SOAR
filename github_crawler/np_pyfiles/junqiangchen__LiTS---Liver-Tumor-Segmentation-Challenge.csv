file_path,api_count,code
LiTS/vnet3d_predict.py,5,"b'import os\r\n\r\nos.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""\r\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""\r\nfrom tensorflow.python.client import device_lib\r\n\r\nprint(device_lib.list_local_devices())\r\n\r\nfrom Vnet.model_vnet3d import Vnet3dModule\r\nimport numpy as np\r\nimport pandas as pd\r\nimport cv2\r\n\r\n\r\ndef predict():\r\n    height = 512\r\n    width = 512\r\n    dimension = 32\r\n    Vnet3d = Vnet3dModule(height, width, dimension, channels=1, costname=(""dice coefficient"",), inference=True,\r\n                          model_path=""log\\\\diceVnet3d\\\\model\\Vnet3d.pd"")\r\n    srcimagepath = ""D:\\Data\\LIST\\\\test\\Image\\\\111""\r\n    predictpath = ""D:\\Data\\LIST\\\\test\\PredictMask""\r\n    index = 0\r\n    imagelist = []\r\n    for _ in os.listdir(srcimagepath):\r\n        image = cv2.imread(srcimagepath + ""/"" + str(index) + "".bmp"", cv2.IMREAD_GRAYSCALE)\r\n        tmpimage = np.reshape(image, (height, width, 1))\r\n        imagelist.append(tmpimage)\r\n        index += 1\r\n\r\n    imagearray = np.array(imagelist)\r\n    imagearray = np.reshape(imagearray, (index, height, width, 1))\r\n    imagemask = np.zeros((index, height, width), np.int32)\r\n\r\n    for i in range(0, index + dimension, dimension // 2):\r\n        if (i + dimension) <= index:\r\n            imagedata = imagearray[i:i + dimension, :, :, :]\r\n            imagemask[i:i + dimension, :, :] = Vnet3d.prediction(imagedata)\r\n        elif (i < index):\r\n            imagedata = imagearray[index - dimension:index, :, :, :]\r\n            imagemask[index - dimension:index, :, :] = Vnet3d.prediction(imagedata)\r\n\r\n    mask = imagemask.copy()\r\n    mask[imagemask > 0] = 255\r\n    result = np.clip(mask, 0, 255).astype(\'uint8\')\r\n    for i in range(0, index):\r\n        cv2.imwrite(predictpath + ""/"" + str(i) + "".bmp"", result[i])\r\n\r\n\r\npredict()\r\n'"
LiTS/vnet3d_train.py,2,"b'import os\r\n\r\nos.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""\r\nos.environ[""CUDA_VISIBLE_DEVICES""] = ""0""\r\nfrom tensorflow.python.client import device_lib\r\n\r\nprint(device_lib.list_local_devices())\r\n\r\nfrom Vnet.model_vnet3d import Vnet3dModule\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\n\r\ndef train():\r\n    \'\'\'\r\n    Preprocessing for dataset\r\n    \'\'\'\r\n    # Read  data set (Train data from CSV file)\r\n    csvmaskdata = pd.read_csv(\'trainY25625616.csv\')\r\n    csvimagedata = pd.read_csv(\'trainX25625616.csv\')\r\n    maskdata = csvmaskdata.iloc[:, :].values\r\n    imagedata = csvimagedata.iloc[:, :].values\r\n    # shuffle imagedata and maskdata together\r\n    perm = np.arange(len(csvimagedata))\r\n    np.random.shuffle(perm)\r\n    imagedata = imagedata[perm]\r\n    maskdata = maskdata[perm]\r\n\r\n    Vnet3d = Vnet3dModule(256, 256, 16, channels=1, costname=(""dice coefficient"",))\r\n    Vnet3d.train(imagedata, maskdata, ""Vnet3d.pd"", ""log\\\\diceVnet3d\\\\"", 0.001, 0.7, 10, 1)\r\n\r\n\r\ntrain()\r\n'"
LiTS/vnet3d_train_predict.py,4,"b'from promise2012.Vnet.model_vnet3d import Vnet3dModule\r\nfrom promise2012.Vnet.util import convertMetaModelToPbModel\r\nimport numpy as np\r\nimport pandas as pd\r\nimport cv2\r\n\r\n\r\ndef train():\r\n    \'\'\'\r\n    Preprocessing for dataset\r\n    \'\'\'\r\n    # Read  data set (Train data from CSV file)\r\n    csvmaskdata = pd.read_csv(\'trainY.csv\')\r\n    csvimagedata = pd.read_csv(\'trainX.csv\')\r\n    maskdata = csvmaskdata.iloc[:, :].values\r\n    imagedata = csvimagedata.iloc[:, :].values\r\n    # shuffle imagedata and maskdata together\r\n    perm = np.arange(len(csvimagedata))\r\n    np.random.shuffle(perm)\r\n    imagedata = imagedata[perm]\r\n    maskdata = maskdata[perm]\r\n\r\n    Vnet3d = Vnet3dModule(128, 128, 64, channels=1, costname=""dice coefficient"")\r\n    Vnet3d.train(imagedata, maskdata, ""model\\\\Vnet3dModule.pd"", ""log\\\\"", 0.001, 0.7, 100000, 1)\r\n\r\n\r\ndef predict0():\r\n    Vnet3d = Vnet3dModule(256, 256, 64, inference=True, model_path=""model\\\\Vnet3dModule.pd"")\r\n    for filenumber in range(30):\r\n        batch_xs = np.zeros(shape=(64, 256, 256))\r\n        for index in range(64):\r\n            imgs = cv2.imread(\r\n                ""D:\\Data\\PROMISE2012\\Vnet3d_data\\\\test\\image\\\\"" + str(filenumber) + ""\\\\"" + str(index) + "".bmp"", 0)\r\n            batch_xs[index, :, :] = imgs[128:384, 128:384]\r\n\r\n        predictvalue = Vnet3d.prediction(batch_xs)\r\n\r\n        for index in range(64):\r\n            result = np.zeros(shape=(512, 512), dtype=np.uint8)\r\n            result[128:384, 128:384] = predictvalue[index]\r\n            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\r\n            result = cv2.morphologyEx(result, cv2.MORPH_CLOSE, kernel)\r\n            cv2.imwrite(\r\n                ""D:\\Data\\PROMISE2012\\Vnet3d_data\\\\test\\image\\\\"" + str(filenumber) + ""\\\\"" + str(index) + ""mask.bmp"",\r\n                result)\r\n\r\n\r\ndef meta2pd():\r\n    convertMetaModelToPbModel(meta_model=""model\\\\Vnet3dModule.pd"", pb_model=""model"")\r\n            \r\ntrain()\r\n#predict0()\r\n#meta2pd()\r\n'"
LiTS/Vnet/__init__.py,0,"b""__author__ = 'junqiang chen'\n__version__ = '1.1.0'\n__company__ = 'Neusoft Medical System company'\n"""
LiTS/Vnet/layer.py,4,"b'\'\'\'\r\ncovlution layer\xef\xbc\x8cpool layer\xef\xbc\x8cinitialization\xe3\x80\x82\xe3\x80\x82\xe3\x80\x82\xe3\x80\x82\r\n\'\'\'\r\nfrom __future__ import division\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport cv2\r\n\r\n\r\n# Weight initialization (Xavier\'s init)\r\ndef weight_xavier_init(shape, n_inputs, n_outputs, activefunction=\'sigomd\', uniform=True, variable_name=None):\r\n    with tf.device(\'/cpu:0\'):\r\n        if activefunction == \'sigomd\':\r\n            if uniform:\r\n                init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\r\n                initial = tf.random_uniform(shape, -init_range, init_range)\r\n                return tf.get_variable(name=variable_name, initializer=initial, trainable=True)\r\n            else:\r\n                stddev = tf.sqrt(2.0 / (n_inputs + n_outputs))\r\n                initial = tf.truncated_normal(shape, mean=0.0, stddev=stddev)\r\n                return tf.get_variable(name=variable_name, initializer=initial, trainable=True)\r\n        elif activefunction == \'relu\':\r\n            if uniform:\r\n                init_range = tf.sqrt(6.0 / (n_inputs + n_outputs)) * np.sqrt(2)\r\n                initial = tf.random_uniform(shape, -init_range, init_range)\r\n                return tf.get_variable(name=variable_name, initializer=initial, trainable=True)\r\n            else:\r\n                stddev = tf.sqrt(2.0 / (n_inputs + n_outputs)) * np.sqrt(2)\r\n                initial = tf.truncated_normal(shape, mean=0.0, stddev=stddev)\r\n                return tf.get_variable(name=variable_name, initializer=initial, trainable=True)\r\n        elif activefunction == \'tan\':\r\n            if uniform:\r\n                init_range = tf.sqrt(6.0 / (n_inputs + n_outputs)) * 4\r\n                initial = tf.random_uniform(shape, -init_range, init_range)\r\n                return tf.get_variable(name=variable_name, initializer=initial, trainable=True)\r\n            else:\r\n                stddev = tf.sqrt(2.0 / (n_inputs + n_outputs)) * 4\r\n                initial = tf.truncated_normal(shape, mean=0.0, stddev=stddev)\r\n                return tf.get_variable(name=variable_name, initializer=initial, trainable=True)\r\n\r\n\r\n# Bias initialization\r\ndef bias_variable(shape, variable_name=None):\r\n    with tf.device(\'/cpu:0\'):\r\n        initial = tf.constant(0.1, shape=shape)\r\n        return tf.get_variable(name=variable_name, initializer=initial, trainable=True)\r\n\r\n\r\n# 3D convolution\r\ndef conv3d(x, W, stride=1):\r\n    conv_3d = tf.nn.conv3d(x, W, strides=[1, stride, stride, stride, 1], padding=\'SAME\')\r\n    return conv_3d\r\n\r\n\r\n# 3D upsampling\r\ndef upsample3d(x, scale_factor, scope=None):\r\n    \'\'\'\'\r\n    X shape is [nsample,dim,rows, cols, channel]\r\n    out shape is[nsample,dim*scale_factor,rows*scale_factor, cols*scale_factor, channel]\r\n    \'\'\'\r\n    x_shape = tf.shape(x)\r\n    k = tf.ones([scale_factor, scale_factor, scale_factor, x_shape[-1], x_shape[-1]])\r\n    # note k.shape = [dim,rows, cols, depth_in, depth_output]\r\n    output_shape = tf.stack(\r\n        [x_shape[0], x_shape[1] * scale_factor, x_shape[2] * scale_factor, x_shape[3] * scale_factor, x_shape[4]])\r\n    upsample = tf.nn.conv3d_transpose(value=x, filter=k, output_shape=output_shape,\r\n                                      strides=[1, scale_factor, scale_factor, scale_factor, 1],\r\n                                      padding=\'SAME\', name=scope)\r\n    return upsample\r\n\r\n\r\n# 3D deconvolution\r\ndef deconv3d(x, W, samefeature=False, depth=False):\r\n    """"""\r\n    depth flag:False is z axis is same between input and output,true is z axis is input is twice than output\r\n    """"""\r\n    x_shape = tf.shape(x)\r\n    if depth:\r\n        if samefeature:\r\n            output_shape = tf.stack([x_shape[0], x_shape[1] * 2, x_shape[2] * 2, x_shape[3] * 2, x_shape[4]])\r\n        else:\r\n            output_shape = tf.stack([x_shape[0], x_shape[1] * 2, x_shape[2] * 2, x_shape[3] * 2, x_shape[4] // 2])\r\n        deconv = tf.nn.conv3d_transpose(x, W, output_shape, strides=[1, 2, 2, 2, 1], padding=\'SAME\')\r\n    else:\r\n        if samefeature:\r\n            output_shape = tf.stack([x_shape[0], x_shape[1] * 2, x_shape[2] * 2, x_shape[3], x_shape[4]])\r\n        else:\r\n            output_shape = tf.stack([x_shape[0], x_shape[1] * 2, x_shape[2] * 2, x_shape[3], x_shape[4] // 2])\r\n        deconv = tf.nn.conv3d_transpose(x, W, output_shape, strides=[1, 2, 2, 1, 1], padding=\'SAME\')\r\n    return deconv\r\n\r\n\r\n# Max Pooling\r\ndef max_pool3d(x, depth=False):\r\n    """"""\r\n        depth flag:False is z axis is same between input and output,true is z axis is input is twice than output\r\n        """"""\r\n    if depth:\r\n        pool3d = tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding=\'SAME\')\r\n    else:\r\n        pool3d = tf.nn.max_pool3d(x, ksize=[1, 2, 2, 1, 1], strides=[1, 2, 2, 1, 1], padding=\'SAME\')\r\n    return pool3d\r\n\r\n\r\n# Unet crop and concat\r\ndef crop_and_concat(x1, x2):\r\n    x1_shape = tf.shape(x1)\r\n    x2_shape = tf.shape(x2)\r\n    # offsets for the top left corner of the crop\r\n    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2,\r\n               (x1_shape[2] - x2_shape[2]) // 2, (x1_shape[3] - x2_shape[3]) // 2, 0]\r\n    size = [-1, x2_shape[1], x2_shape[2], x2_shape[3], -1]\r\n    x1_crop = tf.slice(x1, offsets, size)\r\n    return tf.concat([x1_crop, x2], 4)\r\n\r\n\r\n# Batch Normalization\r\ndef normalizationlayer(x, is_train, height=None, width=None, image_z=None, norm_type=None, G=16, esp=1e-5, scope=None):\r\n    """"""\r\n    :param x:input data with shap of[batch,height,width,channel]\r\n    :param is_train:flag of normalizationlayer,True is training,False is Testing\r\n    :param height:in some condition,the data height is in Runtime determined,such as through deconv layer and conv2d\r\n    :param width:in some condition,the data width is in Runtime determined\r\n    :param image_z:\r\n    :param norm_type:normalization type:support""batch"",""group"",""None""\r\n    :param G:in group normalization,channel is seperated with group number(G)\r\n    :param esp:Prevent divisor from being zero\r\n    :param scope:normalizationlayer scope\r\n    :return:\r\n    """"""\r\n    with tf.name_scope(scope + norm_type):\r\n        if norm_type == None:\r\n            output = x\r\n        elif norm_type == \'batch\':\r\n            output = tf.contrib.layers.batch_norm(x, center=True, scale=True, is_train=is_train)\r\n        elif norm_type == ""group"":\r\n            # tranpose:[bs,z,h,w,c]to[bs,c,z,h,w]following the paper\r\n            x = tf.transpose(x, [0, 4, 1, 2, 3])\r\n            N, C, Z, H, W = x.get_shape().as_list()\r\n            G = min(G, C)\r\n            if H == None and W == None and Z == None:\r\n                Z, H, W = image_z, height, width\r\n            x = tf.reshape(x, [-1, G, C // G, Z, H, W])\r\n            mean, var = tf.nn.moments(x, [2, 3, 4, 5], keep_dims=True)\r\n            x = (x - mean) / tf.sqrt(var + esp)\r\n            gama = tf.get_variable(scope + norm_type + \'group_gama\', [C], initializer=tf.constant_initializer(1.0))\r\n            beta = tf.get_variable(scope + norm_type + \'group_beta\', [C], initializer=tf.constant_initializer(0.0))\r\n            gama = tf.reshape(gama, [1, C, 1, 1, 1])\r\n            beta = tf.reshape(beta, [1, C, 1, 1, 1])\r\n            output = tf.reshape(x, [-1, C, Z, H, W]) * gama + beta\r\n            # tranpose:[bs,c,z,h,w]to[bs,z,h,w,c]following the paper\r\n            output = tf.transpose(output, [0, 2, 3, 4, 1])\r\n        return output\r\n\r\n\r\n# resnet add_connect\r\ndef resnet_Add(x1, x2):\r\n    if x1.get_shape().as_list()[4] != x2.get_shape().as_list()[4]:\r\n        # Option A: Zero-padding\r\n        residual_connection = x2 + tf.pad(x1, [[0, 0], [0, 0], [0, 0], [0, 0],\r\n                                               [0, x2.get_shape().as_list()[4] -\r\n                                                x1.get_shape().as_list()[4]]])\r\n    else:\r\n        residual_connection = x2 + x1\r\n    return residual_connection\r\n\r\n\r\ndef save_images(images, size, path):\r\n    img = (images + 1.0) / 2.0\r\n    h, w = img.shape[1], img.shape[2]\r\n    merge_img = np.zeros((h * size[0], w * size[1]))\r\n    for idx, image in enumerate(images):\r\n        i = idx % size[1]\r\n        j = idx // size[1]\r\n        merge_img[j * h:j * h + h, i * w:i * w + w] = image\r\n    result = merge_img * 255.\r\n    result = np.clip(result, 0, 255).astype(\'uint8\')\r\n    return cv2.imwrite(path, result)\r\n'"
LiTS/Vnet/model_vnet3d.py,22,"b'\'\'\'\r\n\r\n\'\'\'\r\nfrom Vnet.layer import (conv3d, deconv3d, normalizationlayer, crop_and_concat, resnet_Add,\r\n                        weight_xavier_init, bias_variable, save_images)\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport cv2\r\nimport os\r\n\r\n\r\ndef conv_bn_relu_drop(x, kernal, phase, drop, image_z=None, height=None, width=None, scope=None):\r\n    with tf.name_scope(scope):\r\n        W = weight_xavier_init(shape=kernal, n_inputs=kernal[0] * kernal[1] * kernal[2] * kernal[3],\r\n                               n_outputs=kernal[-1], activefunction=\'relu\', variable_name=scope + \'conv_W\')\r\n        B = bias_variable([kernal[-1]], variable_name=scope + \'conv_B\')\r\n        conv = conv3d(x, W) + B\r\n        conv = normalizationlayer(conv, is_train=phase, height=height, width=width, image_z=image_z, norm_type=\'group\',\r\n                                  scope=scope)\r\n        conv = tf.nn.dropout(tf.nn.relu(conv), drop)\r\n        return conv\r\n\r\n\r\ndef down_sampling(x, kernal, phase, drop, image_z=None, height=None, width=None, scope=None):\r\n    with tf.name_scope(scope):\r\n        W = weight_xavier_init(shape=kernal, n_inputs=kernal[0] * kernal[1] * kernal[2] * kernal[3],\r\n                               n_outputs=kernal[-1],\r\n                               activefunction=\'relu\', variable_name=scope + \'W\')\r\n        B = bias_variable([kernal[-1]], variable_name=scope + \'B\')\r\n        conv = conv3d(x, W, 2) + B\r\n        conv = normalizationlayer(conv, is_train=phase, height=height, width=width, image_z=image_z, norm_type=\'group\',\r\n                                  scope=scope)\r\n        conv = tf.nn.dropout(tf.nn.relu(conv), drop)\r\n        return conv\r\n\r\n\r\ndef deconv_relu(x, kernal, samefeture=False, scope=None):\r\n    with tf.name_scope(scope):\r\n        W = weight_xavier_init(shape=kernal, n_inputs=kernal[0] * kernal[1] * kernal[2] * kernal[-1],\r\n                               n_outputs=kernal[-2], activefunction=\'relu\', variable_name=scope + \'W\')\r\n        B = bias_variable([kernal[-2]], variable_name=scope + \'B\')\r\n        conv = deconv3d(x, W, samefeture, True) + B\r\n        conv = tf.nn.relu(conv)\r\n        return conv\r\n\r\n\r\ndef conv_sigmod(x, kernal, scope=None):\r\n    with tf.name_scope(scope):\r\n        W = weight_xavier_init(shape=kernal, n_inputs=kernal[0] * kernal[1] * kernal[2] * kernal[3],\r\n                               n_outputs=kernal[-1], activefunction=\'sigomd\', variable_name=scope + \'W\')\r\n        B = bias_variable([kernal[-1]], variable_name=scope + \'B\')\r\n        conv = conv3d(x, W) + B\r\n        conv = tf.nn.sigmoid(conv)\r\n        return conv\r\n\r\n\r\ndef _create_conv_net(X, image_z, image_width, image_height, image_channel, phase, drop, n_class=1):\r\n    inputX = tf.reshape(X, [-1, image_z, image_width, image_height, image_channel])  # shape=(?, 32, 32, 1)\r\n    # Vnet model\r\n    # layer1->convolution\r\n    layer0 = conv_bn_relu_drop(x=inputX, kernal=(3, 3, 3, image_channel, 16), phase=phase, drop=drop,\r\n                               scope=\'layer0\')\r\n    layer1 = conv_bn_relu_drop(x=layer0, kernal=(3, 3, 3, 16, 16), phase=phase, drop=drop,\r\n                               scope=\'layer1\')\r\n    layer1 = resnet_Add(x1=layer0, x2=layer1)\r\n    # down sampling1\r\n    down1 = down_sampling(x=layer1, kernal=(3, 3, 3, 16, 32), phase=phase, drop=drop, scope=\'down1\')\r\n    # layer2->convolution\r\n    layer2 = conv_bn_relu_drop(x=down1, kernal=(3, 3, 3, 32, 32), phase=phase, drop=drop,\r\n                               scope=\'layer2_1\')\r\n    layer2 = conv_bn_relu_drop(x=layer2, kernal=(3, 3, 3, 32, 32), phase=phase, drop=drop,\r\n                               scope=\'layer2_2\')\r\n    layer2 = resnet_Add(x1=down1, x2=layer2)\r\n    # down sampling2\r\n    down2 = down_sampling(x=layer2, kernal=(3, 3, 3, 32, 64), phase=phase, drop=drop, scope=\'down2\')\r\n    # layer3->convolution\r\n    layer3 = conv_bn_relu_drop(x=down2, kernal=(3, 3, 3, 64, 64), phase=phase, drop=drop,\r\n                               scope=\'layer3_1\')\r\n    layer3 = conv_bn_relu_drop(x=layer3, kernal=(3, 3, 3, 64, 64), phase=phase, drop=drop,\r\n                               scope=\'layer3_2\')\r\n    layer3 = conv_bn_relu_drop(x=layer3, kernal=(3, 3, 3, 64, 64), phase=phase, drop=drop,\r\n                               scope=\'layer3_3\')\r\n    layer3 = resnet_Add(x1=down2, x2=layer3)\r\n    # down sampling3\r\n    down3 = down_sampling(x=layer3, kernal=(3, 3, 3, 64, 128), phase=phase, drop=drop, scope=\'down3\')\r\n    # layer4->convolution\r\n    layer4 = conv_bn_relu_drop(x=down3, kernal=(3, 3, 3, 128, 128), phase=phase, drop=drop,\r\n                               scope=\'layer4_1\')\r\n    layer4 = conv_bn_relu_drop(x=layer4, kernal=(3, 3, 3, 128, 128), phase=phase, drop=drop,\r\n                               scope=\'layer4_2\')\r\n    layer4 = conv_bn_relu_drop(x=layer4, kernal=(3, 3, 3, 128, 128), phase=phase, drop=drop,\r\n                               scope=\'layer4_3\')\r\n    layer4 = resnet_Add(x1=down3, x2=layer4)\r\n    # down sampling4\r\n    down4 = down_sampling(x=layer4, kernal=(3, 3, 3, 128, 256), phase=phase, drop=drop, scope=\'down4\')\r\n    # layer5->convolution\r\n    layer5 = conv_bn_relu_drop(x=down4, kernal=(3, 3, 3, 256, 256), phase=phase, drop=drop,\r\n                               scope=\'layer5_1\')\r\n    layer5 = conv_bn_relu_drop(x=layer5, kernal=(3, 3, 3, 256, 256), phase=phase, drop=drop,\r\n                               scope=\'layer5_2\')\r\n    layer5 = conv_bn_relu_drop(x=layer5, kernal=(3, 3, 3, 256, 256), phase=phase, drop=drop,\r\n                               scope=\'layer5_3\')\r\n    layer5 = resnet_Add(x1=down4, x2=layer5)\r\n\r\n    # layer9->deconvolution\r\n    deconv1 = deconv_relu(x=layer5, kernal=(3, 3, 3, 128, 256), scope=\'deconv1\')\r\n    # layer8->convolution\r\n    layer6 = crop_and_concat(layer4, deconv1)\r\n    _, Z, H, W, _ = layer4.get_shape().as_list()\r\n    layer6 = conv_bn_relu_drop(x=layer6, kernal=(3, 3, 3, 256, 128), image_z=Z, height=H, width=W, phase=phase,\r\n                               drop=drop, scope=\'layer6_1\')\r\n    layer6 = conv_bn_relu_drop(x=layer6, kernal=(3, 3, 3, 128, 128), image_z=Z, height=H, width=W, phase=phase,\r\n                               drop=drop, scope=\'layer6_2\')\r\n    layer6 = conv_bn_relu_drop(x=layer6, kernal=(3, 3, 3, 128, 128), image_z=Z, height=H, width=W, phase=phase,\r\n                               drop=drop, scope=\'layer6_3\')\r\n    layer6 = resnet_Add(x1=deconv1, x2=layer6)\r\n    # layer9->deconvolution\r\n    deconv2 = deconv_relu(x=layer6, kernal=(3, 3, 3, 64, 128), scope=\'deconv2\')\r\n    # layer8->convolution\r\n    layer7 = crop_and_concat(layer3, deconv2)\r\n    _, Z, H, W, _ = layer3.get_shape().as_list()\r\n    layer7 = conv_bn_relu_drop(x=layer7, kernal=(3, 3, 3, 128, 64), image_z=Z, height=H, width=W, phase=phase,\r\n                               drop=drop, scope=\'layer7_1\')\r\n    layer7 = conv_bn_relu_drop(x=layer7, kernal=(3, 3, 3, 64, 64), image_z=Z, height=H, width=W, phase=phase,\r\n                               drop=drop, scope=\'layer7_2\')\r\n    layer7 = resnet_Add(x1=deconv2, x2=layer7)\r\n    # layer9->deconvolution\r\n    deconv3 = deconv_relu(x=layer7, kernal=(3, 3, 3, 32, 64), scope=\'deconv3\')\r\n    # layer8->convolution\r\n    layer8 = crop_and_concat(layer2, deconv3)\r\n    _, Z, H, W, _ = layer2.get_shape().as_list()\r\n    layer8 = conv_bn_relu_drop(x=layer8, kernal=(3, 3, 3, 64, 32), image_z=Z, height=H, width=W, phase=phase,\r\n                               drop=drop, scope=\'layer10_1\')\r\n    layer8 = conv_bn_relu_drop(x=layer8, kernal=(3, 3, 3, 32, 32), image_z=Z, height=H, width=W, phase=phase,\r\n                               drop=drop, scope=\'layer10_2\')\r\n    layer8 = conv_bn_relu_drop(x=layer8, kernal=(3, 3, 3, 32, 32), image_z=Z, height=H, width=W, phase=phase,\r\n                               drop=drop, scope=\'layer10_3\')\r\n    layer8 = resnet_Add(x1=deconv3, x2=layer8)\r\n    # layer9->deconvolution\r\n    deconv4 = deconv_relu(x=layer8, kernal=(3, 3, 3, 16, 32), scope=\'deconv4\')\r\n    # layer8->convolution\r\n    layer9 = crop_and_concat(layer1, deconv4)\r\n    _, Z, H, W, _ = layer1.get_shape().as_list()\r\n    layer9 = conv_bn_relu_drop(x=layer9, kernal=(3, 3, 3, 32, 32), image_z=Z, height=H, width=W, phase=phase,\r\n                               drop=drop, scope=\'layer11_1\')\r\n    layer9 = conv_bn_relu_drop(x=layer9, kernal=(3, 3, 3, 32, 32), image_z=Z, height=H, width=W, phase=phase,\r\n                               drop=drop, scope=\'layer11_2\')\r\n    layer9 = conv_bn_relu_drop(x=layer9, kernal=(3, 3, 3, 32, 32), image_z=Z, height=H, width=W, phase=phase,\r\n                               drop=drop, scope=\'layer11_3\')\r\n    layer9 = resnet_Add(x1=deconv4, x2=layer9)\r\n    # layer14->output\r\n    output_map = conv_sigmod(x=layer9, kernal=(1, 1, 1, 32, n_class), scope=\'output\')\r\n    return output_map\r\n\r\n\r\n# Serve data by batches\r\ndef _next_batch(train_images, train_labels, batch_size, index_in_epoch):\r\n    start = index_in_epoch\r\n    index_in_epoch += batch_size\r\n\r\n    num_examples = train_images.shape[0]\r\n    # when all trainig data have been already used, it is reorder randomly\r\n    if index_in_epoch > num_examples:\r\n        # shuffle the data\r\n        perm = np.arange(num_examples)\r\n        np.random.shuffle(perm)\r\n        train_images = train_images[perm]\r\n        train_labels = train_labels[perm]\r\n        # start next epoch\r\n        start = 0\r\n        index_in_epoch = batch_size\r\n        assert batch_size <= num_examples\r\n    end = index_in_epoch\r\n    return train_images[start:end], train_labels[start:end], index_in_epoch\r\n\r\n\r\nclass Vnet3dModule(object):\r\n    """"""\r\n        A unet2d implementation\r\n\r\n        :param image_height: number of height in the input image\r\n        :param image_width: number of width in the input image\r\n        :param image_depth: number of depth in the input image\r\n        :param channels: number of channels in the input image\r\n        :param costname: name of the cost function.Default is ""dice coefficient""\r\n    """"""\r\n\r\n    def __init__(self, image_height, image_width, image_depth, channels=1, costname=(""dice coefficient"",),\r\n                 inference=False, model_path=None):\r\n        self.image_width = image_width\r\n        self.image_height = image_height\r\n        self.image_depth = image_depth\r\n        self.channels = channels\r\n\r\n        self.X = tf.placeholder(""float"", shape=[None, self.image_depth, self.image_height, self.image_width,\r\n                                                self.channels])\r\n        self.Y_gt = tf.placeholder(""float"", shape=[None, self.image_depth, self.image_height, self.image_width,\r\n                                                   self.channels])\r\n        self.lr = tf.placeholder(\'float\')\r\n        self.phase = tf.placeholder(tf.bool)\r\n        self.drop = tf.placeholder(\'float\')\r\n\r\n        self.Y_pred = _create_conv_net(self.X, self.image_depth, self.image_width, self.image_height, self.channels,\r\n                                       self.phase, self.drop)\r\n        self.cost = self.__get_cost(costname[0])\r\n        self.accuracy = -self.__get_cost(costname[0])\r\n        if inference:\r\n            init = tf.global_variables_initializer()\r\n            saver = tf.train.Saver()\r\n            self.sess = tf.InteractiveSession()\r\n            self.sess.run(init)\r\n            saver.restore(self.sess, model_path)\r\n\r\n    def __get_cost(self, cost_name):\r\n        Z, H, W, C = self.Y_gt.get_shape().as_list()[1:]\r\n        if cost_name == ""dice coefficient"":\r\n            smooth = 1e-5\r\n            pred_flat = tf.reshape(self.Y_pred, [-1, H * W * C * Z])\r\n            true_flat = tf.reshape(self.Y_gt, [-1, H * W * C * Z])\r\n            intersection = 2 * tf.reduce_sum(pred_flat * true_flat, axis=1) + smooth\r\n            denominator = tf.reduce_sum(pred_flat, axis=1) + tf.reduce_sum(true_flat, axis=1) + smooth\r\n            loss = -tf.reduce_mean(intersection / denominator)\r\n        return loss\r\n\r\n    def train(self, train_images, train_lanbels, model_path, logs_path, learning_rate,\r\n              dropout_conv=0.8, train_epochs=5, batch_size=1):\r\n        if not os.path.exists(logs_path):\r\n            os.makedirs(logs_path)\r\n        if not os.path.exists(logs_path + ""model\\\\""):\r\n            os.makedirs(logs_path + ""model\\\\"")\r\n        model_path = logs_path + ""model\\\\"" + model_path\r\n        train_op = tf.train.AdamOptimizer(self.lr).minimize(self.cost)\r\n\r\n        init = tf.global_variables_initializer()\r\n        saver = tf.train.Saver(tf.all_variables(), max_to_keep=10)\r\n\r\n        tf.summary.scalar(""loss"", self.cost)\r\n        tf.summary.scalar(""accuracy"", self.accuracy)\r\n        merged_summary_op = tf.summary.merge_all()\r\n        sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\r\n        summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\r\n        sess.run(init)\r\n\r\n        DISPLAY_STEP = 1\r\n        index_in_epoch = 0\r\n\r\n        train_epochs = train_images.shape[0] * train_epochs\r\n        for i in range(train_epochs):\r\n            # get new batch\r\n            batch_xs_path, batch_ys_path, index_in_epoch = _next_batch(train_images, train_lanbels, batch_size,\r\n                                                                       index_in_epoch)\r\n            batch_xs = np.empty((len(batch_xs_path), self.image_depth, self.image_height, self.image_width,\r\n                                 self.channels))\r\n            batch_ys = np.empty((len(batch_ys_path), self.image_depth, self.image_height, self.image_width,\r\n                                 self.channels))\r\n            for num in range(len(batch_xs_path)):\r\n                index = 0\r\n                for _ in os.listdir(batch_xs_path[num][0]):\r\n                    image = cv2.imread(batch_xs_path[num][0] + ""/"" + str(index) + "".bmp"", cv2.IMREAD_GRAYSCALE)\r\n                    label = cv2.imread(batch_ys_path[num][0] + ""/"" + str(index) + "".bmp"", cv2.IMREAD_GRAYSCALE)\r\n                    batch_xs[num, index, :, :, :] = np.reshape(image, (self.image_height, self.image_width,\r\n                                                                       self.channels))\r\n                    batch_ys[num, index, :, :, :] = np.reshape(label, (self.image_height, self.image_width,\r\n                                                                       self.channels))\r\n                    index += 1\r\n            # Extracting images and labels from given data\r\n            batch_xs = batch_xs.astype(np.float)\r\n            batch_ys = batch_ys.astype(np.float)\r\n            # Normalize from [0:255] => [0.0:1.0]\r\n            batch_xs = np.multiply(batch_xs, 1.0 / 255.0)\r\n            batch_ys = np.multiply(batch_ys, 1.0 / 255.0)\r\n            # check progress on every 1st,2nd,...,10th,20th,...,100th... step\r\n            if i % DISPLAY_STEP == 0 or (i + 1) == train_epochs:\r\n                train_loss, train_accuracy = sess.run([self.cost, self.accuracy],\r\n                                                      feed_dict={self.X: batch_xs,\r\n                                                                 self.Y_gt: batch_ys,\r\n                                                                 self.lr: learning_rate,\r\n                                                                 self.phase: 1,\r\n                                                                 self.drop: dropout_conv})\r\n                print(\'epochs %d training_loss ,Training_accuracy => %.5f,%.5f \' % (i, train_loss, train_accuracy))\r\n\r\n                pred = sess.run(self.Y_pred, feed_dict={self.X: batch_xs,\r\n                                                        self.Y_gt: batch_ys,\r\n                                                        self.phase: 1,\r\n                                                        self.drop: 1})\r\n\r\n                gt = np.reshape(batch_xs[0], (self.image_depth, self.image_height, self.image_width))\r\n                gt = gt.astype(np.float32)\r\n                save_images(gt, [4, 4], path=logs_path + \'src_%d_epoch.png\' % (i))\r\n\r\n                gt = np.reshape(batch_ys[0], (self.image_depth, self.image_height, self.image_width))\r\n                gt = gt.astype(np.float32)\r\n                save_images(gt, [4, 4], path=logs_path + \'gt_%d_epoch.png\' % (i))\r\n\r\n                result = np.reshape(pred[0], (self.image_depth, self.image_height, self.image_width))\r\n                result = result.astype(np.float32)\r\n                save_images(result, [4, 4], path=logs_path + \'predict_%d_epoch.png\' % (i))\r\n\r\n                save_path = saver.save(sess, model_path, global_step=i)\r\n                print(""Model saved in file:"", save_path)\r\n                if i % (DISPLAY_STEP * 10) == 0 and i:\r\n                    DISPLAY_STEP *= 10\r\n\r\n                    # train on batch\r\n            _, summary = sess.run([train_op, merged_summary_op], feed_dict={self.X: batch_xs,\r\n                                                                            self.Y_gt: batch_ys,\r\n                                                                            self.lr: learning_rate,\r\n                                                                            self.phase: 1,\r\n                                                                            self.drop: dropout_conv})\r\n            summary_writer.add_summary(summary, i)\r\n        summary_writer.close()\r\n\r\n        save_path = saver.save(sess, model_path)\r\n        print(""Model saved in file:"", save_path)\r\n\r\n    def prediction(self, test_images):\r\n        test_images = np.reshape(test_images, (test_images.shape[0], test_images.shape[1], test_images.shape[2], 1))\r\n        test_images = test_images.astype(np.float)\r\n        test_images = np.multiply(test_images, 1.0 / 255.0)\r\n        y_dummy = test_images\r\n        pred = self.sess.run(self.Y_pred, feed_dict={self.X: [test_images],\r\n                                                     self.Y_gt: [y_dummy],\r\n                                                     self.phase: 1,\r\n                                                     self.drop: 1})\r\n        result = pred.astype(np.float32) * 255.\r\n        result = np.clip(result, 0, 255).astype(\'uint8\')\r\n        result = np.reshape(result, (test_images.shape[0], test_images.shape[1], test_images.shape[2]))\r\n        return result\r\n'"
LiTS/Vnet/util.py,2,"b'from tensorflow.python.framework import graph_util\nfrom tensorflow.python.framework import graph_io\nimport tensorflow as tf\nimport numpy as np\n\n\ndef getdice(Y_pred,Y_gt,K=255):\n    intersection=2*np.sum(Y_pred[Y_gt==K])\n    denominator=np.sum(Y_pred)+np.sum(Y_gt)\n    loss=(intersection/denominator)\n    return loss\n    \n\n\ndef convertMetaModelToPbModel(meta_model, pb_model):\n    # Step 1\n    # import the model metagraph\n    saver = tf.train.import_meta_graph(meta_model + \'.meta\', clear_devices=True)\n    # make that as the default graph\n    graph = tf.get_default_graph()\n    sess = tf.Session()\n    # now restore the variables\n    saver.restore(sess, meta_model)\n    # Step 2\n    # Find the output name\n    for op in graph.get_operations():\n        print(op.name)\n    # Step 3\n    output_graph_def = graph_util.convert_variables_to_constants(\n        sess,  # The session\n        sess.graph_def,  # input_graph_def is useful for retrieving the nodes\n        [""Placeholder"", ""output/Sigmoid""])\n\n    # Step 4\n    # output folder\n    output_fld = \'./\'\n    # output pb file name\n    output_model_file = \'model.pb\'\n    # write the graph\n    graph_io.write_graph(output_graph_def, pb_model + output_fld, output_model_file, as_text=False)\n'"
LiTS/data_input/__init__.py,0,b'\n'
LiTS/data_input/dataset_input.py,2,"b'#coding=utf-8\n\nimport pandas as pd\nimport tensorflow as tf\nimport random\n\npreprocessing_dict = {\'resize_shape\':[512, 512],\n                      \'rotate\':True,\n                      \'rotate_fix\':True,\n                      \'flip\':True,\n                      \'brightness\':True,\n                      \'brightness_range\':0.2,\n                      \'saturation\':True,\n                      \'saturation_range\':[0.5, 1.5],\n                      \'contrast\':True,\n                      \'contrast_range\':[0.5, 1.5]}\n\nimage_type = \'jpg\'\n\n#TODO how to add image_type and preprocessing_dict as addition arg in map function\n\ndef _parse_function(image, mask):\n    image_string = tf.read_file(image)\n    mask_string = tf.read_file(mask)\n    if image_type == \'jpg\':\n        image_decoded = tf.image.decode_jpeg(image_string, 0)\n        mask_decoded = tf.image.decode_jpeg(mask_string, 1)\n    elif image_type == \'png\':\n        image_decoded = tf.image.decode_png(image_string, 0)\n        mask_decoded = tf.image.decode_png(mask_string, 1)\n    elif image_type == \'bmp\':\n        image_decoded = tf.image.decode_bmp(image_string, 0)\n        mask_decoded = tf.image.decode_bmp(mask_string, 1)\n    else:\n        raise TypeError(\'==> Error: Only support jpg, png and bmp.\')\n        \n    # already in 0~1\n    image_decoded = tf.image.convert_image_dtype(image_decoded, tf.float32)\n    mask_decoded = tf.image.convert_image_dtype(mask_decoded, tf.float32)\n    \n    return image_decoded, mask_decoded\n\ndef _preprocess_function(image_decoded, mask_decoded):  \n    shape = preprocessing_dict[\'resize_shape\']\n    assert len(shape) == 2 and isinstance(shape, list), \'==> Error: shape error.\'\n    image = tf.image.resize_images(image_decoded, shape)\n    mask = tf.image.resize_images(mask_decoded, shape)\n\n    # randomly rotate\n    if preprocessing_dict[\'rotate\'] ==  True:\n        if preprocessing_dict[\'rotate_fix\'] == True:\n            k = random.sample([1,2,3], 1)[0]\n            image = tf.image.rot90(image, k)\n            mask = tf.image.rot90(mask, k)\n        else:\n            raise ValueError(\'==> Error: Only support rotate 90, 180 and 270 degree.\')\n\n    # randomly flip\n    if preprocessing_dict[\'flip\'] ==  True:\n        k = [1, 2]\n        if random.sample(k, 1) == [1]:\n            image = tf.image.flip_left_right(image)\n            mask = tf.image.flip_left_right(mask)\n        else:\n            image = tf.image.flip_up_down(image)\n            mask = tf.image.flip_up_down(mask)\n\n    # adjust the brightness of images by a random factor\n    if preprocessing_dict[\'brightness\'] == True:\n        delta = preprocessing_dict[\'brightness\']\n        # delta randomly picked in the interval [-delta, delta)\n        image = tf.image.random_brightness(image, max_delta=delta)\n\n    # adjust the saturation of an RGB image by a random factor\n    if preprocessing_dict[\'saturation\'] == True:\n        saturation_range = preprocessing_dict[\'saturation_range\']\n        assert len(saturation_range) == 2 and isinstance(saturation_range, list), \'==> Error: saturation_range error.\'\n        image = tf.image.random_saturation(image, *saturation_range)\n\n    # adjust the contrast of an image by a random factor\n    if preprocessing_dict[\'contrast\'] == True:\n        contrast_range = preprocessing_dict[\'contrast_range\']\n        assert len(contrast_range) == 2 and isinstance(contrast_range, list), \'==> Error: saturation_range error.\'\n        image = tf.image.random_contrast(image, *contrast_range)\n\n    # make sure pixel value in 0~1\n    image = tf.clip_by_value(image, 0.0, 1.0)\n\n    return image, mask\n\ndef datagenerator(imagecsv_path, maskcsv_path, batch_size):\n    """"""\n    return: data iterator\n    """"""\n    df_image = pd.read_csv(imagecsv_path)\n    df_mask = pd.read_csv(maskcsv_path)\n\n    try:\n        image_filenames = tf.constant(df_image[\'filename\'].tolist())\n        mask_filenames = tf.constant(df_mask[\'filename\'].tolist())\n    except:\n        raise ValueError(\'==> csv error\')\n\n    dataset = tf.data.Dataset.from_tensor_slices((image_filenames, mask_filenames))\n    dataset = dataset.shuffle(buffer_size=10000)\n    dataset = dataset.repeat()\n    dataset = dataset.map(_parse_function)\n    dataset = dataset.map(_preprocess_function)\n    dataset = dataset.batch(batch_size)\n    data_iterator = dataset.make_initializable_iterator()\n\n    return data_iterator\n\ndef main():\n    # test\n    import cv2\n    import numpy as np\n\n    data_iterator = datagenerator(\'trainX.csv\', \'trainY.csv\', 1)\n    with tf.Session() as sess:\n        sess.run(data_iterator.initializer)\n        next_batch = data_iterator.get_next()\n        image, mask = sess.run(next_batch)\n        cv2.imwrite(\'testimage.jpg\', cv2.cvtColor(np.squeeze(image) * 255, cv2.COLOR_BGR2RGB))\n        cv2.imwrite(\'testmask.jpg\', np.squeeze(mask) * 255)\n\nif __name__ == \'__main__\':\n    main()\n'"
LiTS/dataprocess/getPatchImageAndMask.py,20,"b'from __future__ import print_function, division\nimport SimpleITK as sitk\nimport numpy as np\nimport cv2\nimport os\n\ntrainImage = ""D:\\Data\\LIST\\\\3dPatchdata_25625616\\Image""\ntrainLiverMask = ""D:\\Data\\LIST\\\\3dPatchdata_25625616\\MaskLiver""\ntrainTumorMask = ""D:\\Data\\LIST\\\\3dPatchdata_25625616\\MaskTumor""\n\n\ndef getRangImageDepth(image):\n    """"""\n    :param image:\n    :return:rangofimage depth\n    """"""\n    fistflag = True\n    startposition = 0\n    endposition = 0\n    for z in range(image.shape[0]):\n        notzeroflag = np.max(image[z])\n        if notzeroflag and fistflag:\n            startposition = z\n            fistflag = False\n        if notzeroflag:\n            endposition = z\n    return startposition, endposition\n\n\ndef subimage_generator(image, mask, patch_block_size, numberxy, numberz):\n    """"""\n    generate the sub images and masks with patch_block_size\n    :param image:\n    :param patch_block_size:\n    :param stride:\n    :return:\n    """"""\n    width = np.shape(image)[1]\n    height = np.shape(image)[2]\n    imagez = np.shape(image)[0]\n    block_width = np.array(patch_block_size)[1]\n    block_height = np.array(patch_block_size)[2]\n    blockz = np.array(patch_block_size)[0]\n    stridewidth = (width - block_width) // numberxy\n    strideheight = (height - block_height) // numberxy\n    stridez = (imagez - blockz) // numberz\n    # step 1:if stridez is bigger 1,return  numberxy * numberxy * numberz samples\n    if stridez >= 1 and stridewidth >= 1 and strideheight >= 1:\n        step_width = width - (stridewidth * numberxy + block_width)\n        step_width = step_width // 2\n        step_height = height - (strideheight * numberxy + block_height)\n        step_height = step_height // 2\n        step_z = imagez - (stridez * numberz + blockz)\n        step_z = step_z // 2\n        hr_samples_list = []\n        hr_mask_samples_list = []\n        for z in range(step_z, numberz * (stridez + 1) + step_z, numberz):\n            for x in range(step_width, numberxy * (stridewidth + 1) + step_width, numberxy):\n                for y in range(step_height, numberxy * (strideheight + 1) + step_height, numberxy):\n                    if np.max(mask[z:z + blockz, x:x + block_width, y:y + block_height]) != 0:\n                        hr_samples_list.append(image[z:z + blockz, x:x + block_width, y:y + block_height])\n                        hr_mask_samples_list.append(mask[z:z + blockz, x:x + block_width, y:y + block_height])\n        hr_samples = np.array(hr_samples_list).reshape((len(hr_samples_list), blockz, block_width, block_height))\n        hr_mask_samples = np.array(hr_mask_samples_list).reshape(\n            (len(hr_mask_samples_list), blockz, block_width, block_height))\n        return hr_samples, hr_mask_samples\n    # step 2:other sutitation,return one samples\n    else:\n        nb_sub_images = 1 * 1 * 1\n        hr_samples = np.zeros(shape=(nb_sub_images, blockz, block_width, block_height), dtype=np.float)\n        hr_mask_samples = np.zeros(shape=(nb_sub_images, blockz, block_width, block_height), dtype=np.float)\n        rangz = min(imagez, blockz)\n        rangwidth = min(width, block_width)\n        rangheight = min(height, block_height)\n        hr_samples[0, 0:rangz, 0:rangwidth, 0:rangheight] = image[0:rangz, 0:rangwidth, 0:rangheight]\n        hr_mask_samples[0, 0:rangz, 0:rangwidth, 0:rangheight] = mask[0:rangz, 0:rangwidth, 0:rangheight]\n        return hr_samples, hr_mask_samples\n\n\ndef make_patch(image,mask, patch_block_size, numberxy, numberz, startpostion, endpostion):\n    """"""\n    make number patch\n    :param image:[depth,512,512]\n    :param patch_block: such as[64,128,128]\n    :return:[samples,64,128,128]\n    expand the dimension z range the subimage:[startpostion-blockz//2:endpostion+blockz//2,:,:]\n    """"""\n    blockz = np.array(patch_block_size)[0]\n    imagezsrc = np.shape(image)[0]\n    subimage_startpostion = startpostion - blockz // 2\n    subimage_endpostion = endpostion + blockz // 2\n    if subimage_startpostion < 0:\n        subimage_startpostion = 0\n    if subimage_endpostion > imagezsrc:\n        subimage_endpostion = imagezsrc\n    if (subimage_endpostion - subimage_startpostion) < blockz:\n        subimage_startpostion = 0\n        subimage_endpostion = imagezsrc\n    imageroi = image[subimage_startpostion:subimage_endpostion, :, :]\n    image_subsample, mask_subsample = subimage_generator(image=image, mask=mask, patch_block_size=patch_block_size,\n                                                         numberxy=numberxy, numberz=numberz)\n    return image_subsample, mask_subsample\n\n\n\'\'\'\nThis funciton reads a \'.mhd\' file using SimpleITK and return the image array, origin and spacing of the image.\nread_Image_mask fucntion get image and mask\n\'\'\'\n\n\ndef load_itk(filename):\n    """"""\n    load mhd files and normalization 0-255\n    :param filename:\n    :return:\n    """"""\n    rescalFilt = sitk.RescaleIntensityImageFilter()\n    rescalFilt.SetOutputMaximum(255)\n    rescalFilt.SetOutputMinimum(0)\n    # Reads the image using SimpleITK\n    itkimage = rescalFilt.Execute(sitk.Cast(sitk.ReadImage(filename), sitk.sitkFloat32))\n    return itkimage\n\n\ndef gen_image_mask(srcimg, seg_image, index, shape, numberxy, numberz):\n    # step 1 get mask effective range(startpostion:endpostion)\n    startpostion, endpostion = getRangImageDepth(seg_image)\n    # step 2 get subimages (numberxy*numberxy*numberz,16, 256, 256)\n    sub_srcimages,sub_liverimages = make_patch(srcimg,seg_image, patch_block_size=shape, numberxy=numberxy, numberz=numberz,\n                               startpostion=startpostion,\n                               endpostion=endpostion)\n    # step 3 only save subimages (numberxy*numberxy*numberz,16, 256, 256)\n    samples, imagez = np.shape(sub_srcimages)[0], np.shape(sub_srcimages)[1]\n    for j in range(samples):\n        sub_masks = sub_liverimages.astype(np.float32)\n        sub_masks = np.clip(sub_masks, 0, 255).astype(\'uint8\')\n        if np.max(sub_masks[j, :, :, :]) == 255:\n            filepath = trainImage + ""\\\\"" + str(index) + ""_"" + str(j) + ""\\\\""\n            filepath2 = trainLiverMask + ""\\\\"" + str(index) + ""_"" + str(j) + ""\\\\""\n            if not os.path.exists(filepath) and not os.path.exists(filepath2):\n                os.makedirs(filepath)\n                os.makedirs(filepath2)\n            for z in range(imagez):\n                image = sub_srcimages[j, z, :, :]\n                image = image.astype(np.float32)\n                image = np.clip(image, 0, 255).astype(\'uint8\')\n                cv2.imwrite(filepath + str(z) + "".bmp"", image)\n                cv2.imwrite(filepath2 + str(z) + "".bmp"", sub_masks[j, z, :, :])\n\n\ndef preparetraindata():\n    for i in range(0, 131, 1):\n        seg = sitk.ReadImage(""D:\\Data\\LIST\\src_data\\segmentation-"" + str(i) + "".nii"", sitk.sitkUInt8)\n        segimg = sitk.GetArrayFromImage(seg)\n        src = load_itk(""D:\\Data\\LIST\\src_data\\\\volume-"" + str(i) + "".nii"")\n        srcimg = sitk.GetArrayFromImage(src)\n\n        seg_liverimage = segimg.copy()\n        seg_liverimage[segimg > 0] = 255\n\n        seg_tumorimage = segimg.copy()\n        seg_tumorimage[segimg == 1] = 0\n        seg_tumorimage[segimg == 2] = 255\n        gen_image_mask(srcimg, seg_liverimage, i, shape=(16, 256, 256), numberxy=5, numberz=10)\n\t# gen_image_mask(srcimg, seg_tumorimage, i, shape=(16, 256, 256), numberxy=5, numberz=10)\n\n\npreparetraindata()\n'"
LiTS/dataprocess/preprocessing.py,2,"b'import cv2\nimport numpy as np\n\nclass LITSPreprocessor(object):\n    def __init__(self, image):\n        assert len(image.shape) == 3, \'==> InputError\'\n        self.image = image\n        self.shape = image.shape\n        self.depth = image.shape[-1]\n\n    def transform_ctdata(self, windowWidth, windowCenter, normal=False):\n        """"""\n        return: trucated image according to window center and window width\n        """"""\n        minWindow = float(windowCenter) - 0.5*float(windowWidth)\n        newimg = (self.image - minWindow) / float(windowWidth)\n        newimg[newimg < 0] = 0\n        newimg[newimg > 1] = 1\n        if not normal:\n            newimg = (newimg * 255).astype(\'uint8\')\n        return newimg\n\n    def resize_3d(self, width, height):\n        """"""\n        return: resized image in shape [depth, width, height]\n        """"""\n        if not self.shape[:2] == (width, height):\n            newimg = [cv2.resize(self.image[:,:,i], (height, width)) for i in range(self.depth)]\n            newimg = np.array(newimg)\n        else:\n            newimg = self.image.transpose(2,0,1)\n        return newimg\n\ndef main():\n    # test\n    image = np.load(\'/data/LITS2017/patch_test/volume-2_patch_1.npy\')\n    print(image.shape)\n    lits = LITSPreprocessor(image)\n    # the proper ct value for observe liver is 50~70\n    image = lits.transform_ctdata(20, 60)\n    image = lits.resize_3d(128, 128)\n    print(image.shape)\n\nif __name__ == \'__main__\':\n\tmain()\n'"
LiTS/dataprocess/utils.py,0,"b'import os\r\n\r\n\r\ndef file_name_path(file_dir):\r\n    """"""\r\n    get root path,sub_dirs,all_sub_files\r\n    :param file_dir:\r\n    :return:\r\n    """"""\r\n    for root, dirs, files in os.walk(file_dir):\r\n        if len(dirs):\r\n            print(""sub_dirs:"", dirs)\r\n            return dirs\r\n\r\n\r\ndef save_file2csv(file_dir, file_name):\r\n    """"""\r\n    save file path to csv,this is for segmentation\r\n    :param file_dir:preprocess data path\r\n    :param file_name:output csv name\r\n    :return:\r\n    """"""\r\n    out = open(file_name, \'w\')\r\n    sub_dirs = file_name_path(file_dir)\r\n    out.writelines(""filename"" + ""\\n"")\r\n    for index in range(len(sub_dirs)):\r\n        out.writelines(file_dir + ""/"" + sub_dirs[index] + ""\\n"")\r\n\r\n\r\nsave_file2csv(""G:\\Data\\LIST\\\\3dliver_25625616\\Image"", ""train_X.csv"")\r\n'"
