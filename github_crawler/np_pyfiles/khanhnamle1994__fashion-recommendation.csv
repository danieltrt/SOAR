file_path,api_count,code
code/fashion_input.py,7,"b""'''\nThis python file is responsible for the image processing\n'''\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom hyper_parameters import *\n\nshuffle = True\nlocalization = FLAGS.is_localization\nimageNet_mean_pixel = [103.939, 116.799, 123.68]\nglobal_std = 68.76\n\nIMG_ROWS = 64\nIMG_COLS = 64\n\n\ndef get_image(path, x1, y1, x2, y2):\n    '''\n    :param path: image path\n    :param x1: the upper left and lower right coordinates to localize the apparels\n    :param y1:\n    :param x2:\n    :param y2:\n    :return: a numpy array with dimensions [img_row, img_col, img_depth]\n    '''\n    img = cv2.imread(path)\n    if localization is True:\n        if img is None or img.shape[0] == 0 or img.shape[1] == 0:\n            img = np.zeros((1, IMG_ROWS, IMG_COLS, 0))\n        img = cv2.resize(img, (IMG_ROWS, IMG_COLS))\n        assert img.shape == (IMG_ROWS, IMG_COLS, 3)\n    else:\n        img = cv2.resize(img, (IMG_ROWS, IMG_COLS))\n\n    img = img.reshape(1, IMG_ROWS, IMG_COLS, 3)\n\n    return img\n\n\ndef load_data_numpy(df):\n    '''\n    :param df: a pandas dataframe with the image paths and localization coordinates\n    :return: the numpy representation of the images and the corresponding labels\n    '''\n\n    num_images = len(df)\n    image_path_array = df['image_path'].as_matrix()\n    label_array = df['category'].as_matrix()\n    x1 = df['x1_modified'].as_matrix().reshape(-1, 1)\n    y1 = df['y1_modified'].as_matrix().reshape(-1, 1)\n    x2 = df['x2_modified'].as_matrix().reshape(-1, 1)\n    y2 = df['y2_modified'].as_matrix().reshape(-1, 1)\n    bbox_array = np.concatenate((x1, y1, x2, y2), axis=1)\n\n    image_array = np.array([]).reshape(-1, IMG_ROWS, IMG_COLS, 3)\n    adjusted_std = 1.0/np.sqrt(IMG_COLS * IMG_ROWS * 3)\n\n    for i in range(num_images):\n        img = get_image(image_path_array[i], x1=x1[i, 0], y1=y1[i, 0], x2=x2[i, 0], y2=y2[i, 0])\n        flip_indicator = np.random.randint(low=0, high=2)\n        if flip_indicator == 0:\n            img[0, ...] = cv2.flip(img[0, ...], 1)\n\n        image_array = np.concatenate((image_array, img))\n\n    image_array = (image_array - imageNet_mean_pixel) / global_std\n\n    # Convert to BGR image for pre-train vgg16\n    assert image_array.shape[1:] == (IMG_ROWS, IMG_COLS, 3)\n    # image_array = image_array.transpose((0, 3, 1, 2))\n\n    return image_array, label_array, bbox_array\n\n\ndef prepare_df(path, usecols, shuffle=shuffle):\n    '''\n    :param path: the path of a csv file\n    :param usecols: which columns to read\n    :return: a pandas dataframe\n    '''\n    df = pd.read_csv(path, usecols=usecols)\n    if shuffle is True:\n        order = np.random.permutation(len(df))\n        df = df.iloc[order, :]\n    return df\n"""
code/hyper_parameters.py,0,"b""'''\nThis file defines all hyper-parameters regarding training\n'''\nimport tensorflow as tf\n\nFLAGS = tf.app.flags.FLAGS\n# Hyper-parameters about saving path and data loading path\ntf.app.flags.DEFINE_string('version', 'exp1', '''version number of this experiment''')\n\ntf.app.flags.DEFINE_string('train_path', 'data/train_modified2.csv', '''path to the train image\nlist csv''')\ntf.app.flags.DEFINE_string('vali_path', 'data/vali_modified2.csv', '''path to the validation\nimage list csv''')\ntf.app.flags.DEFINE_string('test_path', 'data/vali_modified2.csv', '''path to the test image list\ncsv''')\ntf.app.flags.DEFINE_string('fc_path', 'data/downloaded_test_fc.csv', '''path to save the feature\nlayer values of the test data''')\ntf.app.flags.DEFINE_string('test_ckpt_path', 'cache/logs_v3_9/min_model.ckpt-27280',\n                           '''checkpoint to load when testing''')\ntf.app.flags.DEFINE_string('ckpt_path', 'logs_v3_10/model.ckpt-59999',\n                           '''checkpoint to load when continue training''')\n\n\n## Hyper-paramters about training\ntf.app.flags.DEFINE_float('weight_decay', 0.00025, '''scale for l2 regularization''')\ntf.app.flags.DEFINE_float('fc_weight_decay', 0.00025, '''scale for fully connected layer's l2\nregularization''')\ntf.app.flags.DEFINE_float('learning_rate', 0.01, '''Learning rate''')\ntf.app.flags.DEFINE_boolean('continue_train_ckpt', False, '''Whether to continue training from a\ncheckpoint''')\n\n## Hyper-parameters about the model\ntf.app.flags.DEFINE_integer('num_residual_blocks', 2, '''number of residual blocks in ResNet''')\ntf.app.flags.DEFINE_boolean('is_localization', True, '''Add localization task or not''')\n"""
code/preprocessing.py,4,"b""import pandas as pd\nimport numpy as np\nimport cv2\n\npath = 'data/vali_modified.csv'\ndf = pd.read_csv(path)\n\nimage_path_array = df['image_path'].as_matrix()\nlabel_array = df['category'].as_matrix()\nx1 = df['x1'].as_matrix().astype(np.float32)\ny1 = df['y1'].as_matrix().astype(np.float32)\nx2 = df['x2'].as_matrix().astype(np.float32)\ny2 = df['y2'].as_matrix().astype(np.float32)\n\n\nfor i in range(len(image_path_array)):\n    path = image_path_array[i]\n    img = cv2.imread(path)\n    if img is None:\n        continue\n    h = img.shape[0]\n    w = img.shape[1]\n\n    x1[i] = x1[i] * 1.0 /w\n    x2[i] = x2[i] * 1.0/ w\n    y1[i] = y1[i] * 1.0/ h\n    y2[i] = y2[i] * 1.0/ h\n\ndf['x1_modified'] = pd.DataFrame(x1)\ndf['y1_modified'] = pd.DataFrame(y1)\ndf['x2_modified'] = pd.DataFrame(x2)\ndf['y2_modified'] = pd.DataFrame(y2)\n\ndf.to_csv('data/vali_modified2.csv', index=False)\nprint(df.head())\n"""
code/simple_resnet.py,0,"b""'''\nThis is the resnet structure.\n'''\n\nimport tensorflow as tf\nfrom hyper_parameters import *\n\nBN_EPSILON = 0.001\nNUM_LABELS = 6\n\ndef activation_summary(x):\n    '''\n    :param x: A Tensor\n    :return: Add histogram summary and scalar summary of the sparsity of the tensor\n    '''\n    tensor_name = x.op.name\n    # tf.histogram_summary(tensor_name + '/activations', x)\n    # tf.scalar_summary(tensor_name + '/sparsity', tf.nn.zero_fraction(x))\n\ndef create_variables(name, shape, initializer=tf.contrib.layers.xavier_initializer(), is_fc_layer=False):\n    '''\n    :param name: A string. The name of the new variable\n    :param shape: A list of dimensions\n    :param initializer: User Xavier as default.\n    :param is_fc_layer: Want to create fc layer variable? May use different weight_decay for fc\n    layers.\n    :return: The created variable\n    '''\n    if is_fc_layer is True:\n        regularizer = tf.contrib.layers.l2_regularizer(scale=FLAGS.fc_weight_decay)\n    else:\n        regularizer = tf.contrib.layers.l2_regularizer(scale=FLAGS.weight_decay)\n\n    new_variables = tf.get_variable(name, shape=shape, initializer=initializer,\n                                    regularizer=regularizer)\n    return new_variables\n\ndef output_layer(input_layer, num_labels):\n    input_dim = input_layer.get_shape().as_list()[-1]\n    fc_w = create_variables(name='fc_weights', shape=[input_dim, num_labels], is_fc_layer=True,\n                            initializer=tf.uniform_unit_scaling_initializer(factor=1.0))\n\n    fc_b = create_variables(name='fc_bias', shape=[num_labels], initializer=tf.zeros_initializer)\n\n    fc_w2 = create_variables(name='fc_weights2', shape=[input_dim, 4], is_fc_layer=True,\n                            initializer=tf.uniform_unit_scaling_initializer(factor=1.0))\n    fc_b2 = create_variables(name='fc_bias2', shape=[4], initializer=tf.zeros_initializer)\n\n\n    fc_h = tf.matmul(input_layer, fc_w) + fc_b\n    fc_h2 = tf.matmul(input_layer, fc_w2) + fc_b2\n    return fc_h, fc_h2\n\n\ndef conv_bn_relu_layer(input_layer, filter_shape, stride, second_conv_residual=False,\n                       relu=True):\n    out_channel = filter_shape[-1]\n    if second_conv_residual is False:\n        filter = create_variables(name='conv', shape=filter_shape)\n    else: filter = create_variables(name='conv2', shape=filter_shape)\n\n    conv_layer = tf.nn.conv2d(input_layer, filter, strides=[1, stride, stride, 1], padding='SAME')\n\n    mean, variance = tf.nn.moments(conv_layer, axes=[0, 1, 2])\n\n    if second_conv_residual is False:\n        beta = tf.get_variable('beta', out_channel, tf.float32,\n                               initializer=tf.constant_initializer(0.0, tf.float32))\n        gamma = tf.get_variable('gamma', out_channel, tf.float32,\n                                initializer=tf.constant_initializer(1.0, tf.float32))\n    else:\n        beta = tf.get_variable('beta_second_conv', out_channel, tf.float32,\n                               initializer=tf.constant_initializer(0.0, tf.float32))\n        gamma = tf.get_variable('gamma_second_conv', out_channel, tf.float32,\n                                initializer=tf.constant_initializer(1.0, tf.float32))\n\n    bn_layer = tf.nn.batch_normalization(conv_layer, mean, variance, beta, gamma, BN_EPSILON)\n    if relu:\n        output = tf.nn.relu(bn_layer)\n    else:\n        output = bn_layer\n    return output\n\n\ndef bn_relu_conv_layer(input_layer, filter_shape, stride, second_conv_residual=False):\n    in_channel = input_layer.get_shape().as_list()[-1]\n    mean, variance = tf.nn.moments(input_layer, axes=[0, 1, 2])\n\n    if second_conv_residual is False:\n        beta = tf.get_variable('beta', in_channel, tf.float32,\n                               initializer=tf.constant_initializer(0.0, tf.float32))\n        gamma = tf.get_variable('gamma', in_channel, tf.float32,\n                                initializer=tf.constant_initializer(1.0, tf.float32))\n    else:\n        beta = tf.get_variable('beta_second_conv', in_channel, tf.float32,\n                               initializer=tf.constant_initializer(0.0, tf.float32))\n        gamma = tf.get_variable('gamma_second_conv', in_channel, tf.float32,\n                                initializer=tf.constant_initializer(1.0, tf.float32))\n\n    bn_layer = tf.nn.batch_normalization(input_layer, mean, variance, beta, gamma, BN_EPSILON)\n    relu_layer = tf.nn.relu(bn_layer)\n\n    if second_conv_residual is False:\n        filter = create_variables(name='conv', shape=filter_shape)\n    else: filter = create_variables(name='conv2', shape=filter_shape)\n    conv_layer = tf.nn.conv2d(relu_layer, filter, strides=[1, stride, stride, 1], padding='SAME')\n    return conv_layer\n\n\n\ndef residual_block_new(input_layer, output_channel, first_block=False):\n    input_channel = input_layer.get_shape().as_list()[-1]\n\n    if input_channel * 2 == output_channel:\n        increase_dim = True\n        stride = 2\n    elif input_channel == output_channel:\n        increase_dim = False\n        stride = 1\n    else:\n        raise ValueError('Output and input channel does not match in residual blocks!!!')\n\n    if first_block:\n        filter = create_variables(name='conv', shape=[3, 3, input_channel, output_channel])\n        conv1 = tf.nn.conv2d(input_layer, filter=filter, strides=[1, 1, 1, 1], padding='SAME')\n    else:\n        conv1 = bn_relu_conv_layer(input_layer, [3, 3, input_channel, output_channel], stride)\n    conv2 = bn_relu_conv_layer(conv1, [3, 3, output_channel, output_channel], 1,\n                               second_conv_residual=True)\n\n    if increase_dim is True:\n        pooled_input = tf.nn.avg_pool(input_layer, ksize=[1, 2, 2, 1],\n                                      strides=[1, 2, 2, 1], padding='SAME')\n        padded_input = tf.pad(pooled_input, [[0, 0], [0, 0], [0, 0], [input_channel // 2,\n                                                                     input_channel // 2]])\n    else:\n        padded_input = input_layer\n\n    output = conv2 + padded_input\n    return output\n\n\ndef inference(input_tensor_batch, n, reuse, keep_prob_placeholder):\n    '''\n    total layers = 1 + 2n + 2n + 2n +1 = 6n + 2\n    '''\n    layers = []\n    with tf.variable_scope('conv0', reuse=reuse):\n        conv0 = conv_bn_relu_layer(input_tensor_batch, [3, 3, 3, 16], 1)\n        # activation_summary(conv0)\n        layers.append(conv0)\n\n    for i in range(n):\n        with tf.variable_scope('conv1_%d' %i, reuse=reuse):\n            if i == 0:\n                conv1 = residual_block_new(layers[-1], 16, first_block=True)\n            else:\n                conv1 = residual_block_new(layers[-1], 16)\n            # activation_summary(conv1)\n            layers.append(conv1)\n\n    for i in range(n):\n        with tf.variable_scope('conv2_%d' %i, reuse=reuse):\n            conv2 = residual_block_new(layers[-1], 32)\n            # activation_summary(conv2)\n            layers.append(conv2)\n\n    for i in range(n):\n        with tf.variable_scope('conv3_%d' %i, reuse=reuse):\n            conv3 = residual_block_new(layers[-1], 64)\n            layers.append(conv3)\n        # assert conv3.get_shape().as_list()[1:] == [16, 16, 64]\n\n    with tf.variable_scope('fc', reuse=reuse):\n        in_channel = layers[-1].get_shape().as_list()[-1]\n        mean, variance = tf.nn.moments(layers[-1], axes=[0, 1, 2])\n        beta = tf.get_variable('beta', in_channel, tf.float32,\n                               initializer=tf.constant_initializer(0.0, tf.float32))\n        gamma = tf.get_variable('gamma', in_channel, tf.float32,\n                                initializer=tf.constant_initializer(1.0, tf.float32))\n\n        bn_layer = tf.nn.batch_normalization(layers[-1], mean, variance, beta, gamma, BN_EPSILON)\n        relu_layer = tf.nn.relu(bn_layer)\n\n\n        global_pool = tf.reduce_mean(relu_layer, [1, 2])\n\n        assert global_pool.get_shape().as_list()[-1:] == [64]\n        cls_output, bbx_output = output_layer(global_pool, NUM_LABELS)\n        layers.append(cls_output)\n        layers.append(bbx_output)\n\n    return cls_output, bbx_output, global_pool\n"""
code/train_n_test.py,13,"b""'''\nThis is the main training profile.\n'''\nfrom fashion_input import *\nimport os\nimport tensorflow as tf\nimport time\nfrom datetime import datetime\nfrom simple_resnet import *\nfrom hyper_parameters import *\n\nTRAIN_DIR = 'logs_' + FLAGS.version + '/'\nTRAIN_LOG_PATH = FLAGS.version + '_error.csv'\n\nREPORT_FREQ = 50\nTRAIN_BATCH_SIZE = 32\nVALI_BATCH_SIZE = 25\nTEST_BATCH_SIZE = 25\nFULL_VALIDATION = False\nError_EMA = 0.98\n\nSTEP_TO_TRAIN = 45000\nDECAY_STEP0 = 25000\nDECAY_STEP1 = 35000\n\ndef generate_validation_batch(df):\n    '''\n    :param df: a pandas dataframe with validation image paths and the corresponding labels\n    :return: two random numpy arrays: validation_batch and validation_label\n    '''\n    offset = np.random.choice(len(df) - VALI_BATCH_SIZE, 1)[0]\n    validation_df = df.iloc[offset:offset+VALI_BATCH_SIZE, :]\n\n    validation_batch, validation_label, validation_bbox_label = load_data_numpy(validation_df)\n    return validation_batch, validation_label, validation_bbox_label\n\n\nclass Train:\n    '''\n    The class defining the training process and relevant helper functions\n    '''\n    def __init__(self):\n        self.placeholders()\n\n    def loss(self, logits, bbox, labels, bbox_labels):\n        labels = tf.cast(labels, tf.int64)\n        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels, name='cross_entropy_per_example')\n        mse_loss = tf.reduce_mean(tf.losses.mean_squared_error(bbox_labels, bbox), name='mean_square_loss')\n        cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n        return cross_entropy_mean + mse_loss\n\n    def top_k_error(self, predictions, labels, k):\n        batch_size = predictions.get_shape().as_list()[0]\n        in_top1 = tf.to_float(tf.nn.in_top_k(predictions, labels, k=1))\n        num_correct = tf.reduce_sum(in_top1)\n        return (batch_size - num_correct) / float(batch_size)\n\n\n    def placeholders(self):\n        self.image_placeholder = tf.placeholder(dtype=tf.float32, shape=[TRAIN_BATCH_SIZE,\n                                                                        IMG_ROWS, IMG_COLS, 3])\n        self.label_placeholder = tf.placeholder(dtype=tf.int32, shape=[TRAIN_BATCH_SIZE])\n        self.bbox_placeholder = tf.placeholder(dtype=tf.float32, shape=[TRAIN_BATCH_SIZE, 4])\n\n        self.vali_image_placeholder = tf.placeholder(dtype=tf.float32, shape=[VALI_BATCH_SIZE,\n                                                                IMG_ROWS, IMG_COLS, 3])\n        self.vali_label_placeholder = tf.placeholder(dtype=tf.int32, shape=[VALI_BATCH_SIZE])\n        self.vali_bbox_placeholder = tf.placeholder(dtype=tf.float32, shape=[VALI_BATCH_SIZE, 4])\n\n        self.lr_placeholder = tf.placeholder(dtype=tf.float32, shape=[])\n        self.dropout_prob_placeholder = tf.placeholder(dtype=tf.float32, shape=[])\n\n\n    def train_operation(self, global_step, total_loss, top1_error):\n        tf.summary.scalar('learning_rate', self.lr_placeholder)\n        tf.summary.scalar('train_loss', total_loss)\n        tf.summary.scalar('train_top1_error', top1_error)\n\n        ema = tf.train.ExponentialMovingAverage(0.95, global_step)\n        train_ema_op = ema.apply([total_loss, top1_error])\n        tf.summary.scalar('train_top1_error_avg', ema.average(top1_error))\n        tf.summary.scalar('train_loss_avg', ema.average(total_loss))\n\n        opt = tf.train.MomentumOptimizer(learning_rate=self.lr_placeholder, momentum=0.9)\n        train_op = opt.minimize(total_loss, global_step=global_step)\n        return train_op, train_ema_op\n\n\n    def validation_op(self, validation_step, top1_error, loss):\n        ema = tf.train.ExponentialMovingAverage(0.0, validation_step)\n        ema2 = tf.train.ExponentialMovingAverage(0.95, validation_step)\n        val_op = tf.group(validation_step.assign_add(1), ema.apply([top1_error, loss]), ema2.apply([top1_error, loss]))\n        top1_error_val = ema.average(top1_error)\n        top1_error_avg = ema2.average(top1_error)\n        loss_val = ema.average(loss)\n        loss_val_avg = ema2.average(loss)\n        tf.summary.scalar('val_top1_error', top1_error_val)\n        tf.summary.scalar('val_top1_error_avg', top1_error_avg)\n        tf.summary.scalar('val_loss', loss_val)\n        tf.summary.scalar('val_loss_avg', loss_val_avg)\n        return val_op\n\n\n    def full_validation(self, validation_df, sess, vali_loss, vali_top1_error, batch_data, batch_label, batch_bbox):\n        num_batches = len(validation_df) // VALI_BATCH_SIZE\n        error_list = []\n        loss_list = []\n\n        for i in range(num_batches):\n            offset = i * VALI_BATCH_SIZE\n            vali_batch_df = validation_df.iloc[offset:offset+VALI_BATCH_SIZE, :]\n            validation_image_batch, validation_labels_batch, validation_bbox_batch = load_data_numpy(vali_batch_df)\n\n            vali_error, vali_loss_value = sess.run([vali_top1_error, vali_loss],\n                                              {self.image_placeholder: batch_data,\n                                                     self.label_placeholder: batch_label,\n                                                    self.bbox_placeholder:batch_bbox,\n                                                     self.vali_image_placeholder: validation_image_batch,\n                                                     self.vali_label_placeholder: validation_labels_batch,\n                                                    self.vali_bbox_placeholder: validation_bbox_batch,\n                                                     self.lr_placeholder: FLAGS.learning_rate,\n                                                     self.dropout_prob_placeholder: 0.5})\n            error_list.append(vali_error)\n            loss_list.append(vali_loss_value)\n\n        return np.mean(error_list), np.mean(loss_list)\n\n\n\n    def train(self):\n        train_df = prepare_df(FLAGS.train_path, usecols=['image_path', 'category', 'x1_modified', 'y1_modified', 'x2_modified', 'y2_modified'])\n        vali_df = prepare_df(FLAGS.vali_path, usecols=['image_path', 'category', 'x1_modified', 'y1_modified', 'x2_modified', 'y2_modified'])\n\n        num_train = len(train_df)\n        global_step = tf.Variable(0, trainable=False)\n        validation_step = tf.Variable(0, trainable=False)\n\n\n        logits, bbox, _ = inference(self.image_placeholder, n=FLAGS.num_residual_blocks, reuse=False,\n                                    keep_prob_placeholder=self.dropout_prob_placeholder)\n        vali_logits, vali_bbox, _ = inference(self.vali_image_placeholder, n=FLAGS.num_residual_blocks,\n                                         reuse=True, keep_prob_placeholder=self.dropout_prob_placeholder)\n\n\n        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n        loss = self.loss(logits, bbox, self.label_placeholder, self.bbox_placeholder)\n        full_loss = tf.add_n([loss] + reg_losses)\n\n        predictions = tf.nn.softmax(logits)\n        top1_error = self.top_k_error(predictions, self.label_placeholder, 1)\n        vali_loss = self.loss(vali_logits, vali_bbox, self.vali_label_placeholder, self.vali_bbox_placeholder)\n        vali_predictions = tf.nn.softmax(vali_logits)\n        vali_top1_error = self.top_k_error(vali_predictions, self.vali_label_placeholder, 1)\n\n\n        train_op, train_ema_op = self.train_operation(global_step, full_loss, top1_error)\n        val_op = self.validation_op(validation_step, vali_top1_error, vali_loss)\n\n        saver = tf.train.Saver(tf.all_variables())\n        summary_op = tf.summary.merge_all()\n        init = tf.initialize_all_variables()\n        sess = tf.Session()\n\n        if FLAGS.continue_train_ckpt is True:\n            print('Model restored!')\n            saver.restore(sess, FLAGS.ckpt_path)\n        else:\n            sess.run(init)\n        summary_writer = tf.summary.FileWriter(TRAIN_DIR, sess.graph)\n\n        step_list = []\n        train_error_list = []\n        vali_error_list = []\n        min_error = 0.5\n\n        for step in range(STEP_TO_TRAIN):\n\n            offset = np.random.choice(num_train - TRAIN_BATCH_SIZE, 1)[0]\n\n            train_batch_df = train_df.iloc[offset:offset+TRAIN_BATCH_SIZE, :]\n            batch_data, batch_label, batch_bbox = load_data_numpy(train_batch_df)\n\n            vali_image_batch, vali_labels_batch, vali_bbox_batch = generate_validation_batch(vali_df)\n\n            start_time = time.time()\n\n            if step == 0:\n                if FULL_VALIDATION is True:\n                    top1_error_value, vali_loss_value = self.full_validation(vali_df,\n                                                                             sess=sess,\n                                                            vali_loss=vali_loss,\n                                                            vali_top1_error=vali_top1_error,\n                                                            batch_data=batch_data,\n                                                            batch_label=batch_label,\n                                                            batch_bbox=batch_bbox)\n                    vali_summ = tf.Summary()\n                    vali_summ.value.add(tag='full_validation_error',\n                                    simple_value=top1_error_value.astype(np.float))\n                    vali_summ.value.add(tag='full_validation_loss',\n                                    simple_value=vali_loss_value.astype(np.float))\n                    summary_writer.add_summary(vali_summ, step)\n                    summary_writer.flush()\n\n                else:\n                    _, top1_error_value, vali_loss_value = sess.run([val_op, vali_top1_error,\n                                                                     vali_loss],\n                                                    {self.image_placeholder: batch_data,\n                                                     self.label_placeholder: batch_label,\n                                                     self.vali_image_placeholder: vali_image_batch,\n                                                     self.vali_label_placeholder: vali_labels_batch,\n                                                     self.lr_placeholder: FLAGS.learning_rate,\n                                                     self.bbox_placeholder: batch_bbox,\n                                                     self.vali_bbox_placeholder: vali_bbox_batch,\n                                                     self.dropout_prob_placeholder: 1.0})\n                print('Validation top1 error = %.4f' % top1_error_value)\n                print('Validation loss = ', vali_loss_value)\n                print('----------------------------')\n\n\n            _, _, loss_value, train_top1_error = sess.run([train_op, train_ema_op, loss,\n                    top1_error], {self.image_placeholder: batch_data,\n                                  self.label_placeholder: batch_label,\n                                  self.bbox_placeholder: batch_bbox,\n                                  self.vali_image_placeholder: vali_image_batch,\n                                  self.vali_label_placeholder: vali_labels_batch,\n                                  self.vali_bbox_placeholder: vali_bbox_batch,\n                                  self.lr_placeholder: FLAGS.learning_rate,\n                                  self.dropout_prob_placeholder: 0.5})\n            duration = time.time() - start_time\n\n            if step % REPORT_FREQ == 0:\n                summary_str = sess.run(summary_op, {self.image_placeholder: batch_data,\n                                                    self.label_placeholder: batch_label,\n                                                    self.bbox_placeholder: batch_bbox,\n                                                    self.vali_image_placeholder: vali_image_batch,\n                                                    self.vali_label_placeholder: vali_labels_batch,\n                                                    self.vali_bbox_placeholder: vali_bbox_batch,\n                                                    self.lr_placeholder: FLAGS.learning_rate,\n                                                    self.dropout_prob_placeholder: 0.5})\n                summary_writer.add_summary(summary_str, step)\n\n\n                num_examples_per_step = TRAIN_BATCH_SIZE\n                examples_per_sec = num_examples_per_step / duration\n                sec_per_batch = float(duration)\n\n                format_str = ('%s: step %d, loss = %.4f (%.1f examples/sec; %.3f ' 'sec/batch)')\n                print (format_str % (datetime.now(), step, loss_value, examples_per_sec, sec_per_batch))\n                print('Train top1 error = ', train_top1_error)\n\n                if FULL_VALIDATION is True:\n                    top1_error_value, vali_loss_value = self.full_validation(vali_df,\n                                                                             sess=sess,\n                                                            vali_loss=vali_loss,\n                                                            vali_top1_error=vali_top1_error,\n                                                            batch_data=batch_data,\n                                                            batch_label=batch_label,\n                                                            batch_bbox=batch_bbox)\n                    vali_summ = tf.Summary()\n                    vali_summ.value.add(tag='full_validation_error',\n                                    simple_value=top1_error_value.astype(np.float))\n                    vali_summ.value.add(tag='full_validation_loss',\n                                    simple_value=vali_loss_value.astype(np.float))\n                    summary_writer.add_summary(vali_summ, step)\n                    summary_writer.flush()\n\n                else:\n\n                    _, top1_error_value, vali_loss_value = sess.run([val_op, vali_top1_error,\n                                                                 vali_loss],\n                                                {self.image_placeholder: batch_data,\n                                                 self.label_placeholder: batch_label,\n                                                 self.bbox_placeholder: batch_bbox,\n                                                 self.vali_image_placeholder: vali_image_batch,\n                                                 self.vali_label_placeholder: vali_labels_batch,\n                                                 self.vali_bbox_placeholder: vali_bbox_batch,\n                                                 self.lr_placeholder: FLAGS.learning_rate,\n                                                 self.dropout_prob_placeholder: 0.5})\n\n                print('Validation top1 error = %.4f' % top1_error_value)\n                print('Validation loss = ', vali_loss_value)\n                print('----------------------------')\n\n                if top1_error_value < min_error:\n                    min_error = top1_error_value\n                    checkpoint_path = os.path.join(TRAIN_DIR, 'min_model.ckpt')\n                    saver.save(sess, checkpoint_path, global_step=step)\n                    print('Current lowest error = ', min_error)\n\n                step_list.append(step)\n                train_error_list.append(train_top1_error)\n                vali_error_list.append(top1_error_value)\n\n\n            if step == DECAY_STEP0 or step == DECAY_STEP1:\n                FLAGS.learning_rate = FLAGS.learning_rate * 0.1\n\n\n            if step % 10000 == 0 or (step + 1) == STEP_TO_TRAIN:\n                checkpoint_path = os.path.join(TRAIN_DIR, 'model.ckpt')\n                saver.save(sess, checkpoint_path, global_step=step)\n\n                error_df = pd.DataFrame(data={'step':step_list, 'train_error':\n                    train_error_list, 'validation_error': vali_error_list})\n                error_df.to_csv(TRAIN_DIR + TRAIN_LOG_PATH, index=False)\n\n            if (step + 1) == STEP_TO_TRAIN:\n                checkpoint_path = os.path.join(TRAIN_DIR, 'model.ckpt')\n                saver.save(sess, checkpoint_path, global_step=step)\n\n                error_df = pd.DataFrame(data={'step': step_list, 'train_error':\n                    train_error_list, 'validation_error': vali_error_list})\n                error_df.to_csv(TRAIN_DIR + TRAIN_LOG_PATH, index=False)\n\n        print('Training finished!!')\n\n    def test(self):\n        self.test_image_placeholder = tf.placeholder(dtype=tf.float32, shape=[25, IMG_ROWS,\n                                                                              IMG_COLS, 3])\n        self.test_label_placeholder = tf.placeholder(dtype=tf.int32, shape=[25])\n\n        ##########################\n        # Build test graph\n        logits, global_pool = inference(self.test_image_placeholder, n=FLAGS.num_residual_blocks, reuse=False,\n                                              keep_prob_placeholder=self.dropout_prob_placeholder)\n        predictions = tf.nn.softmax(logits)\n        test_error = self.top_k_error(predictions, self.test_label_placeholder, 1)\n\n        saver = tf.train.Saver(tf.all_variables())\n        sess = tf.Session()\n        saver.restore(sess, FLAGS.test_ckpt_path)\n        print('Model restored!')\n        ##########################\n\n        test_df = prepare_df(FLAGS.test_path, usecols=['image_path', 'category', 'x1', 'y1', 'x2', 'y2'], shuffle=False)\n        test_df = test_df.iloc[-25:, :]\n\n        prediction_np = np.array([]).reshape(-1, 6)\n        fc_np = np.array([]).reshape(-1, 64)\n        # Hack here: 25 as batch size. 50000 images in total\n        for step in range(len(test_df) // TEST_BATCH_SIZE):\n            if step % 100 == 0:\n                print('Testing %i batches...' %step)\n                if step != 0:\n                    print('Test_error = ', test_error_value)\n\n            df_batch = test_df.iloc[step*25 : (step+1)*25, :]\n            test_batch, test_label = load_data_numpy(df_batch)\n\n            prediction_batch_value, test_error_value = sess.run([predictions, test_error],\n                                                               feed_dict={\n                self.test_image_placeholder:test_batch, self.test_label_placeholder: test_label})\n            fc_batch_value = sess.run(global_pool, feed_dict={\n                self.test_image_placeholder:test_batch, self.test_label_placeholder: test_label})\n\n            prediction_np = np.concatenate((prediction_np, prediction_batch_value), axis=0)\n            fc_np = np.concatenate((fc_np, fc_batch_value))\n\n        print('Predictin array has shape ', fc_np.shape)\n        np.save(FLAGS.fc_path, fc_np[-5:,:])\n\ntrain = Train()\ntrain.train()\ntrain.test()\n"""
