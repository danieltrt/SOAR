file_path,api_count,code
FRAS/Capture_Image.py,0,"b'import csv\n\nimport cv2\nimport os\n\n\n# counting the numbers\n\n\ndef is_number(s):\n    try:\n        float(s)\n        return True\n    except ValueError:\n        pass\n\n    try:\n        import unicodedata\n        unicodedata.numeric(s)\n        return True\n    except (TypeError, ValueError):\n        pass\n\n    return False\n\n\n\n# Take image function\n\ndef takeImages():\n    \n\n    Id = input(""Enter Your Id: "")\n    name = input(""Enter Your Name: "")\n\n    if(is_number(Id) and name.isalpha()):\n        cam = cv2.VideoCapture(0)\n        harcascadePath = ""haarcascade_frontalface_default.xml""\n        detector = cv2.CascadeClassifier(harcascadePath)\n        sampleNum = 0\n\n        while(True):\n            ret, img = cam.read()\n            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            faces = detector.detectMultiScale(gray, 1.3, 5)\n            for(x,y,w,h) in faces:\n                cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n                #incrementing sample number\n                sampleNum = sampleNum+1\n                #saving the captured face in the dataset folder TrainingImage\n                cv2.imwrite(""TrainingImage"" + os.sep +name + "".""+Id + \'.\' +\n                            str(sampleNum) + "".jpg"", gray[y:y+h, x:x+w])\n                #display the frame\n                cv2.imshow(\'frame\', img)\n            #wait for 100 miliseconds\n            if cv2.waitKey(100) & 0xFF == ord(\'q\'):\n                break\n            # break if the sample number is morethan 100\n            elif sampleNum > 60:\n                break\n        cam.release()\n        cv2.destroyAllWindows()\n        res = ""Images Saved for ID : "" + Id + "" Name : "" + name\n        row = [Id, name]\n        with open(""StudentDetails""+os.sep+""StudentDetails.csv"", \'a+\') as csvFile:\n            writer = csv.writer(csvFile)\n            writer.writerow(row)\n        csvFile.close()\n    else:\n        if(is_number(Id)):\n            print(""Enter Alphabetical Name"")\n        if(name.isalpha()):\n            print(""Enter Numeric ID"")\n\n\n'"
FRAS/Recognize.py,0,"b'import datetime\nimport os\nimport time\n\nimport cv2\nimport pandas as pd\n\n\n#-------------------------\ndef recognize_attendence():\n    recognizer = cv2.face.LBPHFaceRecognizer_create()  # cv2.createLBPHFaceRecognizer()\n    recognizer.read(""TrainingImageLabel""+os.sep+""Trainner.yml"")\n    harcascadePath = ""haarcascade_frontalface_default.xml""\n    faceCascade = cv2.CascadeClassifier(harcascadePath)\n    df = pd.read_csv(""StudentDetails""+os.sep+""StudentDetails.csv"")\n    cam = cv2.VideoCapture(0)\n    font = cv2.FONT_HERSHEY_SIMPLEX\n    col_names = [\'Id\', \'Name\', \'Date\', \'Time\']\n    attendance = pd.DataFrame(columns=col_names)\n\n    while True:\n        ret, im = cam.read()\n        gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n        faces = faceCascade.detectMultiScale(gray, 1.2, 5)\n        for(x, y, w, h) in faces:\n            cv2.rectangle(im, (x, y), (x+w, y+h), (225, 0, 0), 2)\n            Id, conf = recognizer.predict(gray[y:y+h, x:x+w])\n\n            if(conf < 50):\n                ts = time.time()\n                date = datetime.datetime.fromtimestamp(ts).strftime(\'%Y-%m-%d\')\n                timeStamp = datetime.datetime.fromtimestamp(\n                    ts).strftime(\'%H:%M:%S\')\n                aa = df.loc[df[\'Id\'] == Id][\'Name\'].values\n                tt = str(Id)+""-""+aa\n                attendance.loc[len(attendance)] = [Id, aa, date, timeStamp]\n\n            else:\n                Id = \'Unknown\'\n                tt = str(Id)\n            if(conf > 75):\n                noOfFile = len(os.listdir(""ImagesUnknown""))+1\n                cv2.imwrite(""ImagesUnknown""+os.sep+""Image""+str(noOfFile) +\n                            "".jpg"", im[y:y+h, x:x+w])\n            cv2.putText(im, str(tt), (x, y+h), font, 1, (255, 255, 255), 2)\n        attendance = attendance.drop_duplicates(subset=[\'Id\'], keep=\'first\')\n        cv2.imshow(\'im\', im)\n        if (cv2.waitKey(1) == ord(\'q\')):\n            break\n    ts = time.time()\n    date = datetime.datetime.fromtimestamp(ts).strftime(\'%Y-%m-%d\')\n    timeStamp = datetime.datetime.fromtimestamp(ts).strftime(\'%H:%M:%S\')\n    Hour, Minute, Second = timeStamp.split("":"")\n    fileName = ""Attendance""+os.sep+""Attendance_""+date+""_""+Hour+""-""+Minute+""-""+Second+"".csv""\n    attendance.to_csv(fileName, index=False)\n    cam.release()\n    cv2.destroyAllWindows()\n\n    print(""Attendance Successfull"")\n'"
FRAS/Train_Image.py,2,"b'import os\n\nimport cv2\nimport numpy as np\nfrom PIL import Image\n\n\n# -------------- image labesl ------------------------\n\ndef getImagesAndLabels(path):\n    # get the path of all the files in the folder\n    imagePaths = [os.path.join(path, f) for f in os.listdir(path)]\n    # print(imagePaths)\n\n    # create empth face list\n    faces = []\n    # create empty ID list\n    Ids = []\n    # now looping through all the image paths and loading the Ids and the images\n    for imagePath in imagePaths:\n        # loading the image and converting it to gray scale\n        pilImage = Image.open(imagePath).convert(\'L\')\n        # Now we are converting the PIL image into numpy array\n        imageNp = np.array(pilImage, \'uint8\')\n        # getting the Id from the image\n        Id = int(os.path.split(imagePath)[-1].split(""."")[1])\n        # extract the face from the training image sample\n        faces.append(imageNp)\n        Ids.append(Id)\n    return faces, Ids\n\n\n# ----------- train images function ---------------\ndef TrainImages():\n    recognizer = cv2.face_LBPHFaceRecognizer.create()\n    harcascadePath = ""haarcascade_frontalface_default.xml""\n    detector = cv2.CascadeClassifier(harcascadePath)\n    faces, Id = getImagesAndLabels(""TrainingImage"")\n    recognizer.train(faces, np.array(Id))\n    recognizer.save(""TrainingImageLabel""+os.sep+""Trainner.yml"")\n    print(""Images Trained"")\n'"
FRAS/automail.py,0,"b'import yagmail\nimport os\n\nreceiver = ""mygmail@gmail.com""  # receiver email address\nbody = ""Attendence File""  # email body\nfilename = ""Attendance""+os.sep+""Attendance_2019-08-29_13-09-07.csv""  # attach the file\n\n# mail information\nyag = yagmail.SMTP(""mygmail@gmail.com"", ""mypassword"")\n\n# sent the mail\nyag.send(\n    to=receiver,\n    subject=""Attendance Report"",  # email subject\n    contents=body,  # email body\n    attachments=filename,  # file attached\n)\n'"
FRAS/check_camera.py,0,"b""import cv2\n\n\ndef camer():\n    cap = cv2.VideoCapture(0)\n\n    while(True):\n        #capture frame-by-frame\n        ret, frame  = cap.read()\n        #operations on the frame come here\n        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n        #display the resulting frame\n        cv2.imshow('frame', gray)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    # when everything is done\n    cap.release()\n    cv2.destroyAllWindows()\n\n"""
FRAS/main.py,0,"b'import os  # accessing the os functions\nimport check_camera\nimport Capture_Image\nimport Train_Image\nimport Recognize\n\n\n# creating the title bar function\n\ndef title_bar():\n    os.system(\'cls\')  # for windows\n\n    # title of the program\n\n    print(""\\t**********************************************"")\n    print(""\\t***** Face Recognition Attendance System *****"")\n    print(""\\t**********************************************"")\n\n\n# creating the user main menu function\n\ndef mainMenu():\n    title_bar()\n    print()\n    print(10 * ""*"", ""WELCOME MENU"", 10 * ""*"")\n    print(""[1] Check Camera"")\n    print(""[2] Capture Faces"")\n    print(""[3] Train Images"")\n    print(""[4] Recognize & Attendance"")\n    print(""[5] Auto Mail"")\n    print(""[6] Quit"")\n\n    while True:\n        try:\n            choice = int(input(""Enter Choice: ""))\n\n            if choice == 1:\n                checkCamera()\n                break\n            elif choice == 2:\n                CaptureFaces()\n                break\n            elif choice == 3:\n                Trainimages()\n                break\n            elif choice == 4:\n                RecognizeFaces()\n                break\n            elif choice == 5:\n                os.system(""py automail.py"")\n                break\n                mainMenu()\n            elif choice == 6:\n                print(""Thank You"")\n                break\n            else:\n                print(""Invalid Choice. Enter 1-4"")\n                mainMenu()\n        except ValueError:\n            print(""Invalid Choice. Enter 1-4\\n Try Again"")\n    exit\n\n\n# ---------------------------------------------------------\n# calling the camera test function from check camera.py file\n\ndef checkCamera():\n    check_camera.camer()\n    key = input(""Enter any key to return main menu"")\n    mainMenu()\n\n\n# --------------------------------------------------------------\n# calling the take image function form capture image.py file\n\ndef CaptureFaces():\n    Capture_Image.takeImages()\n    key = input(""Enter any key to return main menu"")\n    mainMenu()\n\n\n# -----------------------------------------------------------------\n# calling the train images from train_images.py file\n\ndef Trainimages():\n    Train_Image.TrainImages()\n    key = input(""Enter any key to return main menu"")\n    mainMenu()\n\n\n# --------------------------------------------------------------------\n# calling the recognize_attendance from recognize.py file\n\ndef RecognizeFaces():\n    Recognize.recognize_attendence()\n    key = input(""Enter any key to return main menu"")\n    mainMenu()\n\n\n# ---------------main driver ------------------\nmainMenu()\n'"
Raspberry Pi files/Dataset.py,0,"b'import cv2\nfrom picamera.array import PiRGBArray\nfrom picamera import PiCamera\nimport time\nimport os\nimport numpy\nimport io\n\n#Create a memory stream so photos doesn\'t need to be saved in a file\nstream = io.BytesIO()\n\n\n\ncam = cv2.VideoCapture(0) \ndetector=cv2.CascadeClassifier(\'haarcascade_frontalface_default.xml\')\n\n#Convert the picture into a numpy array\nbuff = numpy.fromstring(stream.getvalue(), dtype=numpy.uint8)\n\n\n\nId=raw_input(\'enter your id\')\nsampleNum=0\nwhile(True):\n    ret, img = cam.read()    #cam output\n    cv2.imshow(\'frame\',img)   #screen output\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)   #convert black and white\n    faces = detector.detectMultiScale(gray, 1.3, 5)  #detect face\n    \n    for (x,y,w,h) in faces:\n        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)  #framing\n        cv2.imwrite(""Dataset/""+Id +\'_\'+ str(sampleNum) + "".jpg"", gray[y:y+h,x:x+w]) #saving data in id\n        #incrementing sample number \n        sampleNum=sampleNum+1 \n        #saving the captured face in the dataset folder\n        \n\n        cv2.imshow(\'frame\',img)\n    #wait for 100 miliseconds \n    if cv2.waitKey(100) & 0xFF == ord(\'q\'):\n        break\n    # break if the sample number is morethan 20\n    elif sampleNum>30:\n        break\ncam.release()\ncv2.destroyAllWindows()\n'"
Raspberry Pi files/Main.py,1,"b'import cv2\nimport numpy as np \nimport os\nfrom picamera.array import PiRGBArray\nfrom picamera import PiCamera\nimport time\nimport sys\nimport logging as log\nimport datetime as dt\nfrom time import sleep\n\n\n\ncx = 160\ncy = 120\n\n# names related to ids: example\nnames = [\'None\', \'tasnim\',\'Amir\'] \n\n\n#iniciate id counter\nid = 0\n\n\n\n\n\nxdeg = 150\nydeg = 150\n\n\n  # calling the harr cascade file\ncascadePath = ""haarcascade_frontalface_default.xml""\nfaceCascade = cv2.CascadeClassifier(cascadePath)\nrecognizer=cv2.face.LBPHFaceRecognizer_create()\nlog.basicConfig(filename=\'database.log\',level=log.INFO)\n# opening the database file using append mode\nfile = open(""/home/pi/Testnew/data_log.csv"", ""a"")\n\n\n\n\n\t\n\n\nimages=[]\nlabels=[]\nfor filename in os.listdir(\'Dataset\'):\n\tim=cv2.imread(\'Dataset/\'+filename,0)\n\timages.append(im)\n\tlabels.append(int(filename.split(\'.\')[0][0]))\n\t\n\n\n\nrecognizer.train(images,np.array(labels))\nprint \'Training Done . . . \'\n\nfont = cv2.FONT_HERSHEY_SIMPLEX\ncap=cv2.VideoCapture(0)\nlastRes=\'\'\ncount=0\n\nprint \' Done 2 . . . \'\nlog.info(""Date Time , Student Name \\n"")\nfile.write(""-------------------------------------------------  \\n"")\nfile.write(""        Date:""+str(dt.datetime.now().strftime(""%d-%m-%Y""))+""        \\n"")\nfile.write(""-------------------------------------------------  \\n"")\nfile.write(""Time , Student Name \\n"")\nwhile(1):\n\tret, frame=cap.read()\n\tgray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n\tfaces = faceCascade.detectMultiScale(gray)\n\tcount+=1\n\n\tfor (x,y,w,h) in faces:\n\t\tcv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n                  \n                \n                id,confidence=recognizer.predict(gray[y:y+h, x:x+w])\n\n                # Check if confidence is less them 100 ==> ""0"" is perfect match \n                if (confidence < 40):\n                    id = names[id]\n                    confidence = ""  {0}%"".format(round(100 - confidence))\n                    log.info(str(dt.datetime.now()) + "",""+ str(id)+""\\n"")\n                    file.write(str(dt.datetime.now().strftime(""%H:%M:%S"")) + "",""+ str(id)+""\\n"")\n\n                else:\n                    id = ""unknown""\n                    confidence = ""  {0}%"".format(round(100 - confidence))\n        \n                cv2.putText(frame, str(id), (x+5,y-5), font, 1, (255,255,255), 2)\n                cv2.putText(frame, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)  \n\n                \n                #cv2.putText( frame, str(lastRes), ( x, y ), cv2.FONT_HERSHEY_SIMPLEX, 0.5, ( 0, 0, 255 ), 2 )\n                \n\n\n\t\t\n\n\t\n\t\n\tcv2.imshow(\'frame\',frame)\n\tk = 0xFF & cv2.waitKey(10)\n\tif k == 27:\n\t\tbreak\ncap.release()\ncv2.destroyAllWindows()\n\n'"
