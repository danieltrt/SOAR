file_path,api_count,code
setup.py,0,"b""#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport csv\nimport importlib\nimport os\nimport shutil\nimport sys\nfrom setuptools import setup, find_packages\n\n# Constants\nDISTNAME = 'kymatio'\nDESCRIPTION = 'Wavelet scattering transforms in Python with GPU acceleration'\nURL = 'https://www.kymat.io'\nLICENSE = 'BSD-3-Clause'\n\n\n# Parse description\nwith open('README.md', encoding='utf8') as f:\n    README = f.read().split('\\n')\n    LONG_DESCRIPTION = '\\n'.join([x for x in README if not x[:3]=='[!['])\n\n\n# Parse version.py\nkymatio_version_spec = importlib.util.spec_from_file_location(\n    'kymatio_version', 'kymatio/version.py')\nkymatio_version_module = importlib.util.module_from_spec(kymatio_version_spec)\nkymatio_version_spec.loader.exec_module(kymatio_version_module)\nVERSION = kymatio_version_module.version\n\n\n# Parse requirements.txt\nwith open('requirements.txt', 'r') as f:\n    REQUIREMENTS = f.read().split('\\n')\n\n\nsetup_info = dict(\n    # Metadata\n    name=DISTNAME,\n    version=VERSION,\n    author=('Edouard Oyallon, Eugene Belilovsky, Sergey Zagoruyko, '\n            'Michael Eickenberg, Mathieu Andreux, Georgios Exarchakis, '\n            'Louis Thiry, Vincent Lostanlen, Joakim And\xc3\xa9n, '\n            'Tom\xc3\xa1s Angles, Gabriel Huang, Roberto Leonarduzzi'),\n    author_email=('edouard.oyallon@lip6.fr, belilove@iro.umontreal.ca, '\n                  'sergey.zagoruyko@inria.fr, michael.eickenberg@berkeley.edu, '\n                  'mathieu.andreux@ens.fr, georgios.exarchakis@ens.fr, '\n                  'louis.thiry@ens.fr, vincent.lostanlen@nyu.edu, janden@flatironinstitute.org, '\n                  'tomas.angles@ens.fr, gabriel.huang@umontreal.ca, roberto.leonarduzzi@ens.fr'),\n    url=URL,\n    download_url='https://github.com/kymatio/kymatio/releases',\n    project_urls={\n        'Documentation': 'https://www.kymat.io/codereference.html',\n        'Source': 'https://github.com/kymatio/kymatio/',\n        'Tracker': 'https://github.com/kymatio/kymatio/issues',\n        'Authors': 'https://github.com/kymatio/kymatio/blob/master/AUTHORS.md'\n    },\n    classifiers=['Intended Audience :: Education',\n                 'Intended Audience :: Science/Research',\n                 'License :: OSI Approved :: BSD License',\n                 'Natural Language :: English',\n                 'Operating System :: MacOS',\n                 'Operating System :: POSIX :: Linux',\n                 'Programming Language :: Python :: 3.5',\n                 'Programming Language :: Python :: 3.6',\n                 'Programming Language :: Python :: 3.7',\n                 'Programming Language :: Python :: 3.8',\n                 'Topic :: Multimedia :: Graphics :: 3D Modeling',\n                 'Topic :: Multimedia :: Sound/Audio :: Analysis',\n                 'Topic :: Scientific/Engineering :: Artificial Intelligence',\n                 'Topic :: Scientific/Engineering :: Chemistry',\n                 'Topic :: Scientific/Engineering :: Image Recognition',\n                 'Topic :: Scientific/Engineering :: Information Analysis',\n                 'Topic :: Scientific/Engineering :: Mathematics',\n                 'Topic :: Scientific/Engineering :: Physics',\n                 'Topic :: Software Development :: Libraries :: Python Modules',\n                 ],\n    description=DESCRIPTION,\n    long_description=LONG_DESCRIPTION,\n    long_description_content_type='text/markdown',\n    python_requires='>=3.5',\n    license=LICENSE,\n    packages=find_packages(exclude=('test',)),\n    install_requires=REQUIREMENTS,\n    zip_safe=True,\n)\n\nsetup(**setup_info)\n"""
kymatio/__init__.py,0,"b""# Make sure that DeprecationWarning within this package always gets printed\n### Snippet copied from sklearn.__init__\nimport warnings\nimport re\n\nwarnings.filterwarnings('always', category=DeprecationWarning,\n                        module=r'^{0}.*'.format(re.escape(__name__)))\nwarnings.filterwarnings('always', category=PendingDeprecationWarning,\n                        module=r'^{0}.*'.format(re.escape(__name__)))\n### End Snippet\n\n__all__ = [\n            'Scattering1D',\n            'Scattering2D',\n            'HarmonicScattering3D'\n            ]\n\nfrom .scattering1d import ScatteringEntry1D as Scattering1D\nfrom .scattering2d import ScatteringEntry2D as Scattering2D\nfrom .scattering3d import HarmonicScatteringEntry3D as HarmonicScattering3D\n\nfrom .version import version as __version__\n"""
kymatio/caching.py,0,"b'import os\n\n\ndef find_cache_base_dir(cache_base_dir=None):\n    """"""\n    Finds the base cache directory for caching operations\n\n    Arguments\n    ---------\n    cache_base_dir: string, optional\n        Defaults to None. If None, then the cache directory is searched in the\n        environement variable \'KYMATIO_CACHE\'. If the latter does not\n        exist (so returns None), then the default base cache directory is:\n        ""~/kymatio_cache""\n\n    Returns\n    -------\n    cache_base_dir: string\n        The path to the cache base directory.\n    """"""\n    if cache_base_dir is None:\n        kymatio_cache = os.environ.get(\'KYMATIO_CACHE\')\n        if kymatio_cache is None:\n            return os.path.join(os.path.expanduser(""~""), ""kymatio_cache"")\n        else:\n            return kymatio_cache\n    else:\n        return cache_base_dir\n\n\ndef get_cache_dir(name="""", cache_base_dir=None, create=True):\n    """"""\n    Get the path to a cache directory of given name, possibly created if\n    not existing before.\n\n    Arguments\n    ---------\n    name: string, optional\n        Name of the cache directory. For instance, ""mnist"" or ""fsdd"".\n        Defaults to empty string.\n    cache_base_dir: string, optional\n        Name of the base directory. Passed to find_cache_base_dir.\n        Defaults to None.\n    create: boolean, optional\n        Provides the authorization to create non-existing directories\n\n    Returns\n    -------\n    path: string\n        The path to the caching directory\n    """"""\n    path = os.path.join(\n        find_cache_base_dir(cache_base_dir=cache_base_dir), name)\n    if os.path.exists(path):\n        return path\n    else:\n        if create:\n            os.makedirs(path)\n            return path\n        else:\n            raise ValueError(\n                \'The cache directory does not exist,\' +\n                \'but I cannot create it: {}\'.format(path))\n'"
kymatio/datasets.py,12,"b'import os\nimport subprocess\nimport numpy as np\nfrom scipy.io import loadmat\nfrom .caching import get_cache_dir\ntry:\n    from urllib.request import urlopen\n    from urllib.error import HTTPError, URLError\nexcept:\n    from urllib2 import urlopen, HTTPError, URLError\n\ndef find_datasets_base_dir(datasets_base_dir=None):\n    """"""\n    Finds the base cache directory for caching operations\n\n    Arguments\n    ---------\n    datasets_base_dir: string, optional\n        Defaults to None. If None, then the datasets directory is searched in the\n        environement variable \'KYMATIO_DATASETS\'. If the latter does not\n        exist the default base cache directory is: ""~/kymatio_datasets""\n\n    Returns\n    -------\n    datasets_base_dir: string\n        The path to the datasets base directory.\n\n\n    Notes\n    -----\n    Set the environment variable KYMATIO_DATASETS to direct dataset\n    downloads to a desired download location.\n    """"""\n\n\n    if datasets_base_dir is None:\n        datasets_base_dir = os.environ.get(\'KYMATIO_DATASETS\',\n                                os.path.expanduser(""~/kymatio_datasets""))\n    return datasets_base_dir\n\n\ndef get_dataset_dir(dataset_name, datasets_base_dir=None, create=True):\n    """"""\n    Get the path to a dataset directory of given name, possibly create it if\n    it doesn\'t exist.\n\n    Arguments\n    ---------\n    dataset_name: string\n        Name of the dataset. For instance, ""mnist"" or ""fsdd"".\n    datasets_base_dir: string, optional\n        Name of the base directory. Passed to find_cache_base_dir.\n        Defaults to None, resulting in choice of default dataset directory.\n    create: boolean, optional\n        Provides the authorization to create non-existing directories\n\n    Returns\n    -------\n    path: string\n        The path to the dataset directory\n    """"""\n\n    base_dir = find_datasets_base_dir(datasets_base_dir)\n    full_path = os.path.join(base_dir, dataset_name)\n    if os.path.exists(full_path):\n        return full_path\n    elif create:\n        os.makedirs(full_path)\n        return full_path\n    else:\n        raise ValueError(""Could not find dataset dir {}"".format(full_path))\n\n\n\ndef _download(url, filename):\n\n    try:\n        f = urlopen(url)\n        with open(filename, \'wb\') as local_file:\n            local_file.write(f.read())\n    except URLError as e:\n        raise\n    except HTTPError as e:\n        raise\n\n\n\n\n\n\nfsdd_url= ""https://github.com/Jakobovski/free-spoken-digit-dataset.git""\ndef fetch_fsdd(verbose=False):\n    """"""\n    Fetches the Free Spoken Digit Dataset (FSDD).\n    If the dataset is not present in the caching directory named ""fsdd"", it\n    is downloaded via git.\n\n    Arguments\n    ---------\n    base_dir: string, optional\n        Name of the base directory for the caching. Will be rooted at the root\n        dataset directory given by functions in caching.py. Defaults to \'fsdd\'\n    url: string, optional\n        url for the github repository containing the dataset.\n        Defaults to\n        ""https://github.com/Jakobovski/free-spoken-digit-dataset.git""\n    verbose: boolean, optional\n        Whether to display indications of the operations undertaken.\n        Defaults to False\n\n    Returns\n    -------\n    dictionary: dictionary\n        A dictionary containing the keys \'path_dataset\', with value the\n        absolute path to the recordings\n        (should be base_dir/free-spoken-digit-dataset/recordings),\n        and \'files\', with value the list of the files in path_dataset\n        ending with .wav\n    """"""\n    path = get_dataset_dir(""fsdd"")\n    # check if there is already the free sound dataset within this directory\n    name_git = \'free-spoken-digit-dataset\'\n    downloaded = name_git in os.listdir(path)\n    # download the git if not existing:\n    if not(downloaded):\n        if verbose:\n            print(\'Cloning git repository at \', fsdd_url)\n        instruction = ""git clone "" + fsdd_url + \' \' + str(\n            os.path.join(path, name_git))\n        status, msg = subprocess.getstatusoutput(instruction)\n        if status != 0:\n            raise RuntimeError(msg)\n    # now that it is downloaded, look at the recordings\n    repo = os.path.join(path, name_git, \'recordings\')\n    files = [f for f in os.listdir(repo) if f.endswith(\'.wav\')]\n    dictionary = {\'path_dataset\': repo, \'files\': files}\n    return dictionary\n\n\natom_charges=dict(H=1, C=6, O=8, N=7, S=16)\n\ndef read_xyz(filename):\n    """"""Reads xyz files that are used for storing molecule configurations.\n\n    Parameters\n    ==========\n\n    filename: str\n        Filename of the xyz file\n\n    Returns\n    =======\n    dictionary containing molecule details\n\n    Notes\n    =====\n    The file format is #atoms\\\\nenergy\\\\nrepeat: atom type\\\\tx\\\\ty\\\\tz""""""\n\n    energies = []\n    charges = []\n    positions = []\n    n_atoms = []\n\n    with open(filename, ""r"") as f:\n        content = f.read()\n\n    raw_molecule_txts = content.split(""\\n\\n"")\n    for raw_molecule_txt in raw_molecule_txts:\n        s = raw_molecule_txt.split(""\\n"")\n        n_atoms.append(int(s[0]))\n        energies.append(float(s[1]))\n        atom_positions = []\n        molecule_charges = []\n        charges.append(molecule_charges)\n        positions.append(atom_positions)\n        for i, row in zip(range(n_atoms[-1]), s[2:]):\n            atom_type, *str_position = [x for x in row.split("" "") if x]\n            molecule_charges.append(atom_charges[atom_type])\n            pos = np.array(list(map(float, str_position)))\n            atom_positions.append(pos)\n\n    arr_positions = np.zeros((len(n_atoms), max(n_atoms), 3), dtype=\'float32\')\n    for arr_pos, pos, n in zip(arr_positions, positions, n_atoms):\n        arr_pos[:n] = np.array(pos)\n\n    arr_charges = np.zeros_like(arr_positions[..., 0], dtype=\'int\')\n    for arr_charge, molecule_charges, n in zip(arr_charges, charges, n_atoms):\n        arr_charge[:n] = molecule_charges\n\n    return dict(positions=arr_positions,\n                energies=np.array(energies, dtype=\'float32\'),\n                charges=arr_charges)\n\n\ndef _pca_align_positions(positions, masks, inplace=False):\n    """"""Rotate molecules so that longest axis is x""""""\n    if not inplace:\n        output = np.zeros_like(positions)\n    else:\n        output = positions\n\n    masks = masks.astype(\'bool\')\n    for pos, mask, out in zip(positions, masks, output):\n        masked_pos = pos[mask]\n        masked_pos -= masked_pos.mean(0)\n        cov = masked_pos.T.dot(masked_pos.copy())\n        v, V = np.linalg.eigh(cov)\n        aligned = masked_pos.dot(V[:, ::-1])  # largest to smallest\n        out[mask] = aligned\n\n    if not inplace:\n        return output\n\n\n\nqm7_url = ""https://qmml.org/Datasets/gdb7-12.zip""\ndef fetch_qm7(align=True, cache=True):\n    """"""Fetches the GDB7-12 dataset""""""\n\n    if cache:\n        cache_path = get_cache_dir(""qm7"")\n        if align:\n            aligned_filename = os.path.join(cache_path, ""qm7_aligned.npz"")\n            if os.path.exists(aligned_filename):\n                f = np.load(aligned_filename)\n                return dict(**f)\n\n        # load unaligned if existent, align if required\n        unaligned_filename = os.path.join(cache_path, ""qm7.npz"")\n        if os.path.exists(unaligned_filename):\n            f = np.load(unaligned_filename)\n            if align:\n                _pca_align_positions(f[\'positions\'], f[\'charges\'], inplace=True)\n                np.savez(aligned_filename, **f)\n            return dict(**f)\n\n    path = get_dataset_dir(""qm7"")\n    qm7_file = os.path.join(path, ""dsgdb7ae.xyz"")\n    if not os.path.exists(qm7_file):\n        qm7_zipfile = os.path.join(path, ""gdb7-12.zip"")\n        if not os.path.exists(qm7_zipfile):\n            _download(qm7_url, qm7_zipfile)\n            import zipfile\n            with zipfile.ZipFile(qm7_zipfile, ""r"") as zipref:\n                zipref.extractall(path)\n\n    qm7 = read_xyz(qm7_file)\n    if cache:\n        np.savez(unaligned_filename, **qm7)\n\n    if align:\n        _pca_align_positions(qm7[\'positions\'], qm7[\'charges\'], inplace=True)\n        if cache:\n            np.savez(aligned_filename, **qm7)\n\n    return qm7\n'"
kymatio/keras.py,0,"b""from .scattering1d.frontend.keras_frontend \\\n    import ScatteringKeras1D as Scattering1D\nfrom .scattering2d.frontend.keras_frontend \\\n    import ScatteringKeras2D as Scattering2D\n\nScattering1D.__module__ = 'kymatio.keras'\nScattering1D.__name__ = 'Scattering1D'\n\nScattering2D.__module__ = 'kymatio.keras'\nScattering2D.__name__ = 'Scattering2D'\n\n__all__ = ['Scattering1D', 'Scattering2D']\n"""
kymatio/numpy.py,0,"b""from .scattering1d.frontend.numpy_frontend import ScatteringNumPy1D as Scattering1D\nfrom .scattering2d.frontend.numpy_frontend import ScatteringNumPy2D as Scattering2D\nfrom .scattering3d.frontend.numpy_frontend \\\n        import HarmonicScatteringNumPy3D as HarmonicScattering3D\n\nScattering1D.__module__ = 'kymatio.numpy'\nScattering1D.__name__ = 'Scattering1D'\n\nScattering2D.__module__ = 'kymatio.numpy'\nScattering2D.__name__ = 'Scattering2D'\n\nHarmonicScattering3D.__module__ = 'kymatio.numpy'\nHarmonicScattering3D.__name__ = 'HarmonicScattering3D'\n\n__all__ = ['Scattering1D', 'Scattering2D', 'HarmonicScattering3D']\n"""
kymatio/sklearn.py,0,"b""from .scattering1d.frontend.sklearn_frontend \\\n    import ScatteringTransformer1D as Scattering1D\nfrom .scattering2d.frontend.sklearn_frontend \\\n    import ScatteringTransformer2D as Scattering2D\nfrom .scattering3d.frontend.sklearn_frontend \\\n    import HarmonicScatteringTransformer3D as HarmonicScattering3D\n\nScattering1D.__module__ = 'kymatio.sklearn'\nScattering1D.__name__ = 'Scattering1D'\n\nScattering2D.__module__ = 'kymatio.sklearn'\nScattering2D.__name__ = 'Scattering2D'\n\nHarmonicScattering3D.__module__ = 'kymatio.sklearn'\nHarmonicScattering3D.__name__ = 'HarmonicScattering3D'\n\n__all__ = ['Scattering1D', 'Scattering2D', 'HarmonicScattering3D']\n"""
kymatio/tensorflow.py,0,"b""from .scattering1d.frontend.tensorflow_frontend import ScatteringTensorFlow1D as Scattering1D\nfrom .scattering2d.frontend.tensorflow_frontend import ScatteringTensorFlow2D as Scattering2D\nfrom .scattering3d.frontend.tensorflow_frontend \\\n        import HarmonicScatteringTensorFlow3D as HarmonicScattering3D\n\nScattering1D.__module__ = 'kymatio.tensorflow'\nScattering1D.__name__ = 'Scattering1D'\n\nScattering2D.__module__ = 'kymatio.tensorflow'\nScattering2D.__name__ = 'Scattering2D'\n\nHarmonicScattering3D.__module__ = 'kymatio.tensorflow'\nHarmonicScattering3D.__name__ = 'HarmonicScattering3D'\n\n__all__ = ['Scattering1D', 'Scattering2D', 'HarmonicScattering3D']\n"""
kymatio/torch.py,0,"b""from .scattering1d.frontend.torch_frontend import ScatteringTorch1D as Scattering1D\nfrom .scattering2d.frontend.torch_frontend import ScatteringTorch2D as Scattering2D\nfrom .scattering3d.frontend.torch_frontend \\\n        import HarmonicScatteringTorch3D as HarmonicScattering3D\n\nScattering1D.__module__ = 'kymatio.torch'\nScattering1D.__name__ = 'Scattering1D'\n\nScattering2D.__module__ = 'kymatio.torch'\nScattering2D.__name__ = 'Scattering2D'\n\nHarmonicScattering3D.__module__ = 'kymatio.torch'\nHarmonicScattering3D.__name__ = 'HarmonicScattering3D'\n\n__all__ = ['Scattering1D', 'Scattering2D', 'HarmonicScattering3D']\n"""
kymatio/version.py,0,"b""short_version = '0.3'\nversion = '0.3.dev0'\n\n"""
benchmarks/benchmarks/__init__.py,0,b'from . import common\n'
benchmarks/benchmarks/common.py,0,b'import torch\ntorch.manual_seed(0)\n'
benchmarks/benchmarks/scattering1d.py,0,"b'import torch\nimport kymatio.scattering1d.backend as backend\nfrom kymatio import Scattering1D\n\nclass BenchmarkScattering1D:\n    params = [\n        [\n            { # Typical of EEG. J=8, Q=1, N=1024\n              # See Warrick et al. Physiological Measurement 2019\n                ""J"": 8,\n                ""Q"": 1,\n                ""shape"": 1024,\n            },\n            { # Typical of speech.\n              # See And\xc3\xa9n and Mallat TASLP 2014\n                ""J"": 8,\n                ""Q"": 8,\n                ""shape"": 4096,\n            },\n            { # Typical of music.\n              # See And\xc3\xa9n et al.\n                ""J"": 16,\n                ""Q"": 12,\n                ""shape"": 131072,\n            },\n        ],\n        [\n            32,\n        ]\n    ]\n    param_names = [""sc_params"", ""batch_size""]\n\n    def setup(self, sc_params, batch_size):\n        n_channels = 1\n        scattering = Scattering1D(**sc_params)\n        scattering.cpu()\n        x = torch.randn(\n            batch_size,\n            n_channels,\n            sc_params[""shape""],\n            dtype=torch.float32)\n        x.cpu()\n        self.scattering = scattering\n        self.x = x\n\n    def time_constructor(self, sc_params, batch_size):\n        Scattering1D(**sc_params)\n\n    def time_forward(self, sc_params, batch_size):\n        (self.scattering).forward(self.x)\n'"
benchmarks/benchmarks/scattering2d.py,0,"b'import torch\nimport kymatio.scattering2d.backend as backend\nfrom kymatio import Scattering2D\n\nclass BenchmarkScattering2D:\n    params = [\n        [\n            { # MNIST-like. 32x32, 2 scales, 8 orientations\n                ""J"": 2,\n                ""shape"": (32, 32),\n                ""L"": 8,\n            },\n            { # ImageNet-like. 224x224, 3 scales, 8 orientations\n                ""J"": 3,\n                ""shape"": (224, 224),\n                ""L"": 8,\n            },\n            { # A case with many scales (J=7) and few orientations (L=2)\n                ""J"": 7,\n                ""shape"": (224, 224),\n                ""L"": 2,\n            },\n        ],\n        [\n            32,\n        ]\n    ]\n    param_names = [""sc_params"", ""batch_size""]\n\n    def setup(self, sc_params, batch_size):\n        n_channels = 1\n        scattering = Scattering2D(**sc_params)\n        scattering.cpu()\n        x = torch.randn(\n            batch_size,\n            n_channels,\n            sc_params[""shape""][0], sc_params[""shape""][1],\n            dtype=torch.float32)\n        x.cpu()\n        self.scattering = scattering\n        self.x = x\n\n    def time_constructor(self, sc_params, batch_size):\n        Scattering2D(**sc_params)\n\n    def time_forward(self, sc_params, batch_size):\n        (self.scattering).forward(self.x)\n'"
benchmarks/benchmarks/scattering3d.py,0,"b'import torch\nimport kymatio.scattering3d.backend as backend\nfrom kymatio import HarmonicScattering3D\n\nclass BenchmarkHarmonicScattering3D:\n    params = [\n        [\n            { # Small. 32x32x32, 2 scales, 2 harmonics\n                ""J"": 2,\n                ""shape"": (32, 32, 32),\n                ""L"": 2,\n            },\n            { # Large. 128x128x128, 2 scales, 2 harmonics\n                ""J"": 2,\n                ""shape"": (128, 128, 128),\n                ""L"": 2,\n            },\n            { # A case with many scales (J=6) and few harmonics (L=1)\n                ""J"": 6,\n                ""shape"": (128, 128, 128),\n                ""L"": 1,\n            },\n            { # A case with few scales (J=2) and many harmonics (L=6)\n                ""J"": 2,\n                ""shape"": (32, 32, 32),\n                ""L"": 4,\n            }\n        ],\n        [\n            1,\n        ]\n    ]\n    param_names = [""sc_params"", ""batch_size""]\n\n    def setup(self, sc_params, batch_size):\n        scattering = HarmonicScattering3D(**sc_params)\n        scattering.cpu()\n        x = torch.randn(\n            batch_size,\n            sc_params[""shape""][0], sc_params[""shape""][1], sc_params[""shape""][2],\n            dtype=torch.float32)\n        x.cpu()\n        self.scattering = scattering\n        self.x = x\n\n    def time_constructor(self, sc_params, batch_size):\n        HarmonicScattering3D(**sc_params)\n\n    def time_forward(self, sc_params, batch_size):\n        (self.scattering).forward(self.x)\n'"
doc/source/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\nimport kymatio\nfrom distutils.version import LooseVersion\n\n\n\nsys.path.insert(0, os.path.abspath(\'../..\'))\n\n\n\n# -- Project information -----------------------------------------------------\n\nproject = \'kymatio\'\ncopyright = \'2018\xe2\x80\x932020, The Kymatio Developers\'\nauthor = \'The Kymatio Developers\'\n\n# The short X.Y version\nv = LooseVersion(kymatio.__version__).version\n\nversion = ""."".join(map(str, v[:2]))\n\n# The full version, including alpha/beta/rc tags\nrelease = kymatio.__version__\n\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.doctest\',\n    \'sphinx.ext.coverage\',\n    \'sphinx.ext.imgmath\',\n    \'sphinx.ext.viewcode\',\n    \'sphinx.ext.githubpages\',\n    \'sphinxcontrib.bibtex\',\n    \'sphinx_gallery.gen_gallery\',\n    \'sphinx.ext.napoleon\',\n    \'texext\',\n    \'m2r\'\n]\n\nhtml_favicon = \'_static/kymatio.ico\'\n\n# Add path to sphynx gallery\nsphinx_gallery_conf = {\n    # path to your examples scripts\n    \'examples_dirs\': [\'../../examples/1d\',\'../../examples/2d\',\'../../examples/3d\'],\n    # path where to save gallery generated examples\n    \'gallery_dirs\': [\'gallery_1d\',\'gallery_2d\',\'gallery_3d\'],\n    \'ignore_pattern\': r\'long_\',\n    \'filename_pattern\': r\'/plot_\'\n}\n\nintersphinx_mapping = {\'kymatio\': (\'../kymatio\', None)}\n\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\nsource_suffix = [\'.rst\', \'.md\']\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = \'en\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path .\nexclude_patterns = []\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'alabaster\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\nhtml_theme_options = {\n    \'logo\': \'kymatio.jpg\',\n    \'touch_icon\': \'kymatio.jpg\',\n    \'logo_name\':\'Kymatio\',\n    \'description\': \'Wavelet Scattering in Python<br>\'\n                   \'&nbsp;&nbsp;&nbsp;<a href=""https://twitter.com/KymatioWavelets""><img width=""40px"" src=""https://avatars3.githubusercontent.com/u/50278?s=200&v=4""></a>\',\n    \'github_button\': True,\n    \'github_type\': \'star\',\n    \'github_user\': \'kymatio\',\n    \'github_repo\': \'kymatio\',\n    \'fixed_sidebar\': False,\n    \'github_banner\': True,\n    \'analytics_id\': \'UA-130785726-1\',\n    \'font_family\': \'""Avenir Next"", Avenir, ""Helvetica Neue"",Helvetica,Arial,sans-serif\'\n}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don\'t match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``[\'localtoc.html\', \'relations.html\', \'sourcelink.html\',\n# \'searchbox.html\']``.\n#\n\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'kymatiodoc\'\n\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'kymatio.tex\', \'kymatio Documentation\',\n     \'The Kymatio Developers\', \'manual\'),\n]\n\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'kymatio\', \'Kymatio Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'kymatio\', \'kymatio Documentation\',\n     author, \'kymatio\', \'Wavelet Scattering in Python\',\n     \'Miscellaneous\'),\n]\n\n\n# -- Extension configuration -------------------------------------------------\n\nautodoc_default_option = [\'members\', \'inherited-members\']\n\n\n'"
examples/1d/classif_keras.py,5,"b'""""""\nClassification of spoken digit recordings\n=========================================\n\nIn this example we use the 1D scattering transform to represent spoken digits,\nwhich we then classify using a simple classifier. This shows that 1D scattering\nrepresentations are useful for this type of problem.\n\nThis dataset is automatically downloaded and preprocessed from\nhttps://github.com/Jakobovski/free-spoken-digit-dataset.git\n\nDownloading and precomputing scattering coefficients should take about 5 min.\nRunning the gradient descent takes about 1 min.\n\nResults:\nTraining accuracy = 99.7%\nTesting accuracy = 98.0%\n""""""\n\n###############################################################################\n# Preliminaries\n# -------------\n#\n# Since we\'re using TensorFlow and Keras to train the model, import the\n# relevant modules.\n\nimport tensorflow as tf\n\nfrom tensorflow.keras import layers\n\n###############################################################################\n# To handle audio file I/O, we import `os` and `scipy.io.wavfile`. We also need\n# `numpy` for some basic array manipulation.\n\nfrom scipy.io import wavfile\nimport os\nimport numpy as np\n\n###############################################################################\n# Finally, we import the `Scattering1D` class from the `kymatio.keras` package\n# and the `fetch_fsdd` function from `kymatio.datasets`. The `Scattering1D`\n# class is what lets us calculate the scattering transform, while the\n# `fetch_fsdd` function downloads the FSDD, if needed.\n\nfrom kymatio.keras import Scattering1D\nfrom kymatio.datasets import fetch_fsdd\n\n###############################################################################\n# Pipeline setup\n# --------------\n# We start by specifying the dimensions of our processing pipeline along with\n# some other parameters.\n#\n# First, we have signal length. Longer signals are truncated and shorter\n# signals are zero-padded. The sampling rate is 8000 Hz, so this corresponds to\n# little over a second.\n\nT = 2 ** 13\n\n###############################################################################\n# Maximum scale 2**J of the scattering transform (here, about 30 milliseconds)\n# and the number of wavelets per octave.\nJ = 8\nQ = 12\n\n###############################################################################\n# We need a small constant to add to the scattering coefficients before\n# computing the logarithm. This prevents very large values when the scattering\n# coefficients are very close to zero.\nlog_eps = 1e-6\n\n###############################################################################\n# Loading the data\n# ----------------\n# Once the parameter are set, we can start loading the data into a format that\n# can be fed into the scattering transform and then a logistic regression\n# classifier.\n#\n# We first download the dataset. If it\'s already downloaded, `fetch_fsdd` will\n# simply return the information corresponding to the dataset that\'s already\n# on disk.\n\ninfo_data = fetch_fsdd()\nfiles = info_data[\'files\']\npath_dataset = info_data[\'path_dataset\']\n\n###############################################################################\n# Set up NumPy arrays to hold the audio signals (`x_all`), the labels\n# (`y_all`), and whether the signal is in the train or test set (`subset`).\n\nx_all = np.zeros((len(files), T))\ny_all = np.zeros(len(files), dtype=np.uint8)\nsubset = np.zeros(len(files), dtype=np.uint8)\n\n###############################################################################\n# For each file in the dataset, we extract its label `y` and its index from the\n# filename. If the index is between 0 and 4, it is placed in the test set, while\n# files with larger indices are used for training. The actual signals are\n# normalized to have maximum amplitude one, and are truncated or zero-padded\n# to the desired length `T`. They are then stored in the `x_all` array while\n# their labels are in `y_all`.\n\nfor k, f in enumerate(files):\n    basename = f.split(\'.\')[0]\n\n    # Get label (0-9) of recording.\n    y = int(basename.split(\'_\')[0])\n\n    # Index larger than 5 gets assigned to training set.\n    if int(basename.split(\'_\')[2]) >= 5:\n        subset[k] = 0\n    else:\n        subset[k] = 1\n\n    # Load the audio signal and normalize it.\n    _, x = wavfile.read(os.path.join(path_dataset, f))\n    x = np.asarray(x, dtype=\'float\')\n    x /= np.max(np.abs(x))\n\n    # If it\'s too long, truncate it.\n    if len(x) > T:\n        x = x[:T]\n\n    # If it\'s too short, zero-pad it.\n    start = (T - len(x)) // 2\n\n    x_all[k,start:start + len(x)] = x\n    y_all[k] = y\n\n###############################################################################\n# Log-scattering layer\n# --------------------\n# We now create a classification model using the `Scattering1D` Keras layer.\n# First, we take the input signals of length `T`.\n\nx_in = layers.Input(shape=(T))\n\n###############################################################################\n# These are fed into the `Scattering1D` layer.\n\nx = Scattering1D(J, Q=Q)(x_in)\n\n###############################################################################\n# Since it does not carry useful information, we remove the zeroth-order\n# scattering coefficients, which are always placed in the first channel of\n# the scattering transform.\n\nx = layers.Lambda(lambda x: x[..., 1:, :])(x)\n\n# To increase discriminability, we take the logarithm of the scattering\n# coefficients (after adding a small constant to make sure nothing blows up\n# when scattering coefficients are close to zero). This is known as the\n# log-scattering transform.\n\nx = layers.Lambda(lambda x: tf.math.log(tf.abs(x) + log_eps))(x)\n\n###############################################################################\n# We then average along the last dimension (time) to get a time-shift\n# invariant representation.\n\nx = layers.GlobalAveragePooling1D(data_format=\'channels_first\')(x)\n\n###############################################################################\n# Finally, we apply batch normalization to ensure that the data is within a\n# moderate range.\n\nx = layers.BatchNormalization(axis=1)(x)\n\n###############################################################################\n# These features are then used to classify the input signal using a dense\n# layer followed by a softmax activation.\n\nx_out = layers.Dense(10, activation=\'softmax\')(x)\n\n###############################################################################\n# Finally, we create the model and display it.\n\nmodel = tf.keras.models.Model(x_in, x_out)\nmodel.summary()\n\n###############################################################################\n# Training the classifier\n# -----------------------\n# Having set up the model, we attach an Adam optimizer and a cross-entropy\n# loss function.\n\nmodel.compile(optimizer=\'adam\',\n              loss=\'sparse_categorical_crossentropy\',\n              metrics=[\'accuracy\'])\n\n###############################################################################\n# We then train the model using `model.fit`. The training data is given by\n# those indices satisfying `subset == 0`.\n\nmodel.fit(x_all[subset == 0], y_all[subset == 0], epochs=50,\n          batch_size=64, validation_split=0.2)\n\n###############################################################################\n# Finally, we evaluate the model on the held-out test data. These are given by\n# the indices `subset == 1`.\n\nmodel.evaluate(x_all[subset == 1], y_all[subset == 1], verbose=2)\n'"
examples/1d/plot_classif_torch.py,3,"b'""""""\nClassification of spoken digit recordings\n=========================================\n\nIn this example we use the 1D scattering transform to represent spoken digits,\nwhich we then classify using a simple classifier. This shows that 1D scattering\nrepresentations are useful for this type of problem.\n\nThis dataset is automatically downloaded and preprocessed from\nhttps://github.com/Jakobovski/free-spoken-digit-dataset.git\n\nDownloading and precomputing scattering coefficients should take about 5 min.\nRunning the gradient descent takes about 1 min.\n\nResults:\nTraining accuracy = 99.7%\nTesting accuracy = 98.0%\n""""""\n\n###############################################################################\n# Preliminaries\n# -------------\n#\n# Since we\'re using PyTorch to train the model, import `torch`.\n\nimport torch\n\n###############################################################################\n# We will be constructing a logistic regression classifier on top of the\n# scattering coefficients, so we need some of the neural network tools from\n# `torch.nn` and the Adam optimizer from `torch.optim`.\n\nfrom torch.nn import Linear, NLLLoss, LogSoftmax, Sequential\nfrom torch.optim import Adam\n\n###############################################################################\n# To handle audio file I/O, we import `os` and `scipy.io.wavfile`. We also need\n# `numpy` for some basic array manipulation.\n\nfrom scipy.io import wavfile\nimport os\nimport numpy as np\n\n###############################################################################\n# To evaluate our results, we need to form a confusion matrix using\n# scikit-learn and display them using `matplotlib`.\n\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\n###############################################################################\n# Finally, we import the `Scattering1D` class from the `kymatio.torch` package\n# and the `fetch_fsdd` function from `kymatio.datasets`. The `Scattering1D`\n# class is what lets us calculate the scattering transform, while the\n# `fetch_fsdd` function downloads the FSDD, if needed.\n\nfrom kymatio.torch import Scattering1D\nfrom kymatio.datasets import fetch_fsdd\n\n###############################################################################\n# Pipeline setup\n# --------------\n# We start by specifying the dimensions of our processing pipeline along with\n# some other parameters.\n#\n# First, we have signal length. Longer signals are truncated and shorter\n# signals are zero-padded. The sampling rate is 8000 Hz, so this corresponds to\n# little over a second.\n\nT = 2**13\n\n###############################################################################\n# Maximum scale 2**J of the scattering transform (here, about 30 milliseconds)\n# and the number of wavelets per octave.\n\nJ = 8\nQ = 12\n\n###############################################################################\n# We need a small constant to add to the scattering coefficients before\n# computing the logarithm. This prevents very large values when the scattering\n# coefficients are very close to zero.\n\nlog_eps = 1e-6\n\n###############################################################################\n# If a GPU is available, let\'s use it!\n\nuse_cuda = torch.cuda.is_available()\n\n###############################################################################\n# For reproducibility, we fix the seed of the random number generator.\n\ntorch.manual_seed(42)\n\n###############################################################################\n# Loading the data\n# ----------------\n# Once the parameter are set, we can start loading the data into a format that\n# can be fed into the scattering transform and then a logistic regression\n# classifier.\n#\n# We first download the dataset. If it\'s already downloaded, `fetch_fsdd` will\n# simply return the information corresponding to the dataset that\'s already\n# on disk.\n\ninfo_data = fetch_fsdd()\nfiles = info_data[\'files\']\npath_dataset = info_data[\'path_dataset\']\n\n###############################################################################\n# Set up Tensors to hold the audio signals (`x_all`), the labels (`y_all`), and\n# whether the signal is in the train or test set (`subset`).\n\nx_all = torch.zeros(len(files), T, dtype=torch.float32)\ny_all = torch.zeros(len(files), dtype=torch.int64)\nsubset = torch.zeros(len(files), dtype=torch.int64)\n\n###############################################################################\n# For each file in the dataset, we extract its label `y` and its index from the\n# filename. If the index is between 0 and 4, it is placed in the test set, while\n# files with larger indices are used for training. The actual signals are\n# normalized to have maximum amplitude one, and are truncated or zero-padded\n# to the desired length `T`. They are then stored in the `x_all` Tensor while\n# their labels are in `y_all`.\n\nfor k, f in enumerate(files):\n    basename = f.split(\'.\')[0]\n\n    # Get label (0-9) of recording.\n    y = int(basename.split(\'_\')[0])\n\n    # Index larger than 5 gets assigned to training set.\n    if int(basename.split(\'_\')[2]) >= 5:\n        subset[k] = 0\n    else:\n        subset[k] = 1\n\n    # Load the audio signal and normalize it.\n    _, x = wavfile.read(os.path.join(path_dataset, f))\n    x = np.asarray(x, dtype=\'float\')\n    x /= np.max(np.abs(x))\n\n    # Convert from NumPy array to PyTorch Tensor.\n    x = torch.from_numpy(x)\n\n    # If it\'s too long, truncate it.\n    if x.numel() > T:\n        x = x[:T]\n\n    # If it\'s too short, zero-pad it.\n    start = (T - x.numel()) // 2\n\n    x_all[k,start:start + x.numel()] = x\n    y_all[k] = y\n\n###############################################################################\n# Log-scattering transform\n# ------------------------\n# We now create the `Scattering1D` object that will be used to calculate the\n# scattering coefficients.\n\nscattering = Scattering1D(J, T, Q)\n\n###############################################################################\n# If we are using CUDA, the scattering transform object must be transferred to\n# the GPU by calling its `cuda()` method. The data is similarly transferred.\n\nif use_cuda:\n    scattering.cuda()\n    x_all = x_all.cuda()\n    y_all = y_all.cuda()\n\n###############################################################################\n# Compute the scattering transform for all signals in the dataset.\n\nSx_all = scattering.forward(x_all)\n\n###############################################################################\n# Since it does not carry useful information, we remove the zeroth-order\n# scattering coefficients, which are always placed in the first channel of\n# the scattering Tensor.\n\nSx_all = Sx_all[:,1:,:]\n\n###############################################################################\n# To increase discriminability, we take the logarithm of the scattering\n# coefficients (after adding a small constant to make sure nothing blows up\n# when scattering coefficients are close to zero). This is known as the\n# log-scattering transform.\n\nSx_all = torch.log(torch.abs(Sx_all) + log_eps)\n\n###############################################################################\n# Finally, we average along the last dimension (time) to get a time-shift\n# invariant representation.\n\nSx_all = torch.mean(Sx_all, dim=-1)\n\n###############################################################################\n# Training the classifier\n# -----------------------\n# With the log-scattering coefficients in hand, we are ready to train our\n# logistic regression classifier.\n#\n# First, we extract the training data (those for which `subset` equals `0`)\n# and the associated labels.\n\nSx_tr, y_tr = Sx_all[subset == 0], y_all[subset == 0]\n\n###############################################################################\n# Standardize the data to have mean zero and unit variance. Note that we need\n# to apply the same transformation to the test data later, so we save the\n# mean and standard deviation Tensors.\n\nmu_tr = Sx_tr.mean(dim=0)\nstd_tr = Sx_tr.std(dim=0)\nSx_tr = (Sx_tr - mu_tr) / std_tr\n\n###############################################################################\n# Here we define a logistic regression model using PyTorch. We train it using\n# Adam with a negative log-likelihood loss.\n\nnum_input = Sx_tr.shape[-1]\nnum_classes = y_tr.cpu().unique().numel()\nmodel = Sequential(Linear(num_input, num_classes), LogSoftmax(dim=1))\noptimizer = Adam(model.parameters())\ncriterion = NLLLoss()\n\n###############################################################################\n# As before, if we\'re on a GPU, transfer the model and the loss function onto\n# the device.\n\nif use_cuda:\n    model = model.cuda()\n    criterion = criterion.cuda()\n\n###############################################################################\n# Before training the model, we set some parameters for the optimization\n# procedure.\n\n# Number of signals to use in each gradient descent step (batch).\nbatch_size = 32\n# Number of epochs.\nnum_epochs = 50\n# Learning rate for Adam.\nlr = 1e-4\n\n###############################################################################\n# Given these parameters, we compute the total number of batches.\n\nnsamples = Sx_tr.shape[0]\nnbatches = nsamples // batch_size\n\n###############################################################################\n# Now we\'re ready to train the classifier.\n\nfor e in range(num_epochs):\n    # Randomly permute the data. If necessary, transfer the permutation to the\n    # GPU.\n    perm = torch.randperm(nsamples)\n    if use_cuda:\n        perm = perm.cuda()\n\n    # For each batch, calculate the gradient with respect to the loss and take\n    # one step.\n    for i in range(nbatches):\n        idx = perm[i * batch_size : (i+1) * batch_size]\n        model.zero_grad()\n        resp = model.forward(Sx_tr[idx])\n        loss = criterion(resp, y_tr[idx])\n        loss.backward()\n        optimizer.step()\n\n    # Calculate the response of the training data at the end of this epoch and\n    # the average loss.\n    resp = model.forward(Sx_tr)\n    avg_loss = criterion(resp, y_tr)\n\n    # Try predicting the classes of the signals in the training set and compute\n    # the accuracy.\n    y_hat = resp.argmax(dim=1)\n    accuracy = (y_tr == y_hat).float().mean()\n\n    print(\'Epoch {}, average loss = {:1.3f}, accuracy = {:1.3f}\'.format(\n        e, avg_loss, accuracy))\n\n###############################################################################\n# Now that our network is trained, let\'s test it!\n#\n# First, we extract the test data (those for which `subset` equals `1`) and the\n# associated labels.\n\nSx_te, y_te = Sx_all[subset == 1], y_all[subset == 1]\n\n###############################################################################\n# Use the mean and standard deviation calculated on the training data to\n# standardize the testing data, as well.\n\nSx_te = (Sx_te - mu_tr) / std_tr\n\n###############################################################################\n# Calculate the response of the classifier on the test data and the resulting\n# loss.\n\nresp = model.forward(Sx_te)\navg_loss = criterion(resp, y_te)\n\n# Try predicting the labels of the signals in the test data and compute the\n# accuracy.\n\ny_hat = resp.argmax(dim=1)\naccu = (y_te == y_hat).float().mean()\n\nprint(\'TEST, average loss = {:1.3f}, accuracy = {:1.3f}\'.format(\n      avg_loss, accu))\n\n###############################################################################\n# Plotting the classification accuracy as a confusion matrix\n# ----------------------------------------------------------\n# Let\'s see what the very few misclassified sounds get misclassified as. We\n# will plot a confusion matrix which indicates in a 2D histogram how often\n# one sample was mistaken for another (anything on the diagonal is correctly\n# classified, anything off the diagonal is wrong).\n\npredicted_categories = y_hat.cpu().numpy()\nactual_categories = y_te.cpu().numpy()\n\nconfusion = confusion_matrix(actual_categories, predicted_categories)\nplt.figure()\nplt.imshow(confusion)\ntick_locs = np.arange(10)\nticks = [\'{}\'.format(i) for i in range(1, 11)]\nplt.xticks(tick_locs, ticks)\nplt.yticks(tick_locs, ticks)\nplt.ylabel(""True number"")\nplt.xlabel(""Predicted number"")\nplt.show()\n'"
examples/1d/plot_filters.py,5,"b'""""""\nPlot the 1D wavelet filters\n===========================\nLet us examine the wavelet filters used by kymatio to calculate 1D scattering\ntransforms. Filters are generated using the\n:meth:`kymatio.scattering1d.filter_bank.scattering_filter_factory` method,\nwhich creates both the first- and second-order filter banks.\n""""""\n\n###############################################################################\n# Preliminaries\n# -------------\n# First, we import the `scattering_filter_factory` method, which we will use\n# to generate the filters.\n\nfrom kymatio.scattering1d.filter_bank import scattering_filter_factory\n\n###############################################################################\n# We then import `numpy` and `matplotlib` to display the filters.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n###############################################################################\n# Filter parameters and generation\n# --------------------------------\n# The filters are defined for a certain support size `T` which corresponds to\n# the size of the input signal. The only restriction is that `T` must be a\n# power of two. Since we are not computing any scattering transforms here, we\n# may pick any power of two for `T`. Here, we choose `2**13 = 8192`.\n\nT = 2**13\n\n###############################################################################\n# The parameter `J` specifies the maximum scale of the filters as a power of\n# two. In other words, the largest filter will be concentrated in a time\n# interval of size `2**J`.\n\nJ = 5\n\n###############################################################################\n# The `Q` parameter controls the number of wavelets per octave in the\n# first-order filter bank. The larger the value, the narrower these filters\n# are in the frequency domain and the wider they are in the time domain (in\n# general, the number of non-negligible oscillations in time is proportional\n# to `Q`). For audio signals, it is often beneficial to have a large value for\n# `Q` (between 4 and 16), since these signals are often highly oscillatory and\n# are better localized in frequency than they are in time. We therefore set:\n\nQ = 8\n\n###############################################################################\n# Note that it is currently not possible to control the number of wavelets\n# per octave in the second-order filter bank, which is fixed to one.\n#\n# We are now ready to create the filters. These are generated by the\n# `scattering_filter_factory` method, which takes the logarithm of `T` and\n# the `J` and `Q` parameters. It returns the lowpass filter (`phi_f`), the\n# first-order wavelet filters (`psi1_f`), and the second-order filters\n# (`psi2_f`).\n\nphi_f, psi1_f, psi2_f, _ = scattering_filter_factory(np.log2(T), J, Q)\n\n###############################################################################\n# The `phi_f` output is a dictionary where each integer key corresponds points\n# to the instantiation of the filter at a certain resolution. In other words,\n# `phi_f[0]` corresponds to the lowpass filter at resolution `T`, while \n# `phi_f[1]` corresponds to the filter at resolution `T/2`, and so on.\n#\n# While `phi_f` only contains a single filter (at different resolutions),\n# the `psi1_f` and `psi2_f` outputs are lists of filters, one for each wavelet\n# bandpass filter in the filter bank.\n\n###############################################################################\n# Plot the filters\n# ================\n# We are now ready to plot the filters. We first display the lowpass filter\n# (at full resolution) in red. We then plot each of the bandpass filters in\n# blue. Since we don\'t care about the negative frequencies, we limit the\n# plot to the frequency interval :math:`[0, 0.5]`. Finally, we add some\n# explanatory labels and title.\n\nplt.figure()\nplt.plot(np.arange(T)/T, phi_f[0], \'r\')\n\nfor psi_f in psi1_f:\n    plt.plot(np.arange(T)/T, psi_f[0], \'b\')\n\nplt.xlim(0, 0.5)\n\nplt.xlabel(r\'$\\omega$\', fontsize=18)\nplt.ylabel(r\'$\\hat\\psi_j(\\omega)$\', fontsize=18)\nplt.title(\'First-order filters (Q = {})\'.format(Q), fontsize=18)\n\n###############################################################################\n# Do the same plot for the second-order filters. Note that since here `Q = 1`,\n# we obtain wavelets that have higher frequency bandwidth.\n\nplt.figure()\nplt.plot(np.arange(T)/T, phi_f[0], \'r\')\nfor psi_f in psi2_f:\n    plt.plot(np.arange(T)/T, psi_f[0], \'b\')\nplt.xlim(0, 0.5)\nplt.ylim(0, 1.2)\nplt.xlabel(r\'$\\omega$\', fontsize=18)\nplt.ylabel(r\'$\\hat\\psi_j(\\omega)$\', fontsize=18)\nplt.title(\'Second-order filters (Q = 1)\', fontsize=18)\n\n###############################################################################\n# Display the plots!\n\nplt.show()\n'"
examples/1d/plot_real_signal.py,4,"b'""""""\nCompute the scattering transform of a speech recording\n======================================================\nThis script loads a speech signal from the free spoken digit dataset (FSDD)\nof a man pronouncing the word ""zero,"" computes its scattering transform, and\ndisplays the zeroth-, first-, and second-order scattering coefficients.\n""""""\n\n###############################################################################\n# Preliminaries\n# -------------\n#\n###############################################################################\n# To handle audio file I/O, we import `os` and `scipy.io.wavfile`.\n\nimport numpy as np\nimport os\nimport scipy.io.wavfile\n\n###############################################################################\n# We import `matplotlib` to plot the calculated scattering coefficients.\n\nimport matplotlib.pyplot as plt\n\n###############################################################################\n# Finally, we import the `Scattering1D` class from the `scattering` package and\n# the `fetch_fsdd` function from `scattering.datasets`. The `Scattering1D`\n# class is what lets us calculate the scattering transform, while the\n# `fetch_fsdd` function downloads the FSDD, if needed.\n\nfrom kymatio.numpy import Scattering1D\nfrom kymatio.datasets import fetch_fsdd\n\n###############################################################################\n# Scattering setup\n# ----------------\n# First, we download the FSDD (if not already downloaded) and read in the\n# recording `0_jackson_0.wav` of a man pronouncing the word ""zero"".\n\ninfo_dataset = fetch_fsdd(verbose=True)\n\nfile_path = os.path.join(info_dataset[\'path_dataset\'], sorted(info_dataset[\'files\'])[0])\n_, x = scipy.io.wavfile.read(file_path)\n\n###############################################################################\n# Once the recording is in memory, we normalize it.\n\nx = x / np.max(np.abs(x))\n\n###############################################################################\n# We are now ready to set up the parameters for the scattering transform.\n# First, the number of samples, `T`, is given by the size of our input `x`.\n# The averaging scale is specified as a power of two, `2**J`. Here, we set\n# `J = 6` to get an averaging, or maximum, scattering scale of `2**6 = 64`\n# samples. Finally, we set the number of wavelets per octave, `Q`, to `16`.\n# This lets us resolve frequencies at a resolution of `1/16` octaves.\n\nT = x.shape[-1]\nJ = 6\nQ = 16\n\n###############################################################################\n# Finally, we are able to create the object which computes our scattering\n# transform, `scattering`.\n\nscattering = Scattering1D(J, T, Q)\n\n###############################################################################\n# Compute and display the scattering coefficients\n# -----------------------------------------------\n# Computing the scattering transform of a signal is achieved using the\n# `__call__` method of the `Scattering1D` class. The output is an array of\n# shape `(C, T)`. Here, `C` is the number of scattering coefficient outputs,\n# and `T` is the number of samples along the time axis. This is typically much\n# smaller than the number of input samples since the scattering transform\n# performs an average in time and subsamples the result to save memory.\n\nSx = scattering(x)\n\n###############################################################################\n# To display the scattering coefficients, we must first identify which belong\n# to each order (zeroth, first, or second). We do this by extracting the `meta`\n# information from the scattering object and constructing masks for each order.\n\nmeta = scattering.meta()\norder0 = np.where(meta[\'order\'] == 0)\norder1 = np.where(meta[\'order\'] == 1)\norder2 = np.where(meta[\'order\'] == 2)\n\n###############################################################################\n# First, we plot the original signal `x`.\n\nplt.figure(figsize=(8, 2))\nplt.plot(x)\nplt.title(\'Original signal\')\n\n###############################################################################\n# We now plot the zeroth-order scattering coefficient, which is simply an\n# average of the original signal at the scale `2**J`.\n\nplt.figure(figsize=(8, 8))\nplt.subplot(3, 1, 1)\nplt.plot(Sx[order0][0])\nplt.title(\'Zeroth-order scattering\')\n\n###############################################################################\n# We then plot the first-order coefficients, which are arranged along time\n# and log-frequency.\n\nplt.subplot(3, 1, 2)\nplt.imshow(Sx[order1], aspect=\'auto\')\nplt.title(\'First-order scattering\')\n\n###############################################################################\n# Finally, we plot the second-order scattering coefficients. These are also\n# organized aling time, but has two log-frequency indices: one first-order\n# frequency and one second-order frequency. Here, both indices are mixed along\n# the vertical axis.\n\nplt.subplot(3, 1, 3)\nplt.imshow(Sx[order2], aspect=\'auto\')\nplt.title(\'Second-order scattering\')\n\n###############################################################################\n# Display the plots!\n\nplt.show()\n'"
examples/1d/plot_synthetic.py,12,"b'""""""\nCompute the scattering transform of a synthetic signal\n======================================================\n\nIn this example we generate a harmonic signal of a few different frequencies\nand analyze it with the 1D scattering transform.\n""""""\n\n\n###############################################################################\n# Import the necessary packages\n# -----------------------------\nfrom kymatio.numpy import Scattering1D\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n###############################################################################\n# Write a function that can generate a harmonic signal\n# ----------------------------------------------------\n# Let\'s write a function that can generate some simple blip-type sounds with\n# decaying harmonics. It will take four arguments: T, the length of the output\n# vector; num_intervals, the number of different blips; gamma, the exponential\n# decay factor of the harmonic; random_state, a random seed to generate\n# random pitches and phase shifts.\n# The function proceeds by splitting the time length T into intervals, chooses\n# base frequencies and phases, generates sinusoidal sounds and harmonics,\n# and then adds a windowed version to the output signal.\ndef generate_harmonic_signal(T, num_intervals=4, gamma=0.9, random_state=42):\n    """"""\n    Generates a harmonic signal, which is made of piecewise constant notes\n    (of random fundamental frequency), with half overlap\n    """"""\n    rng = np.random.RandomState(random_state)\n    num_notes = 2 * (num_intervals - 1) + 1\n    support = T // num_intervals\n    half_support = support // 2\n\n    base_freq = 0.1 * rng.rand(num_notes) + 0.05\n    phase = 2 * np.pi * rng.rand(num_notes)\n    window = np.hanning(support)\n    x = np.zeros(T, dtype=\'float32\')\n    t = np.arange(0, support)\n    u = 2 * np.pi * t\n    for i in range(num_notes):\n        ind_start = i * half_support\n        note = np.zeros(support)\n        for k in range(1):\n            note += (np.power(gamma, k) *\n                     np.cos(u * (k + 1) * base_freq[i] + phase[i]))\n        x[ind_start:ind_start + support] += note * window\n\n    return x\n\n###############################################################################\n# Let\'s take a look at what such a signal could look like\n# -------------------------------------------------------\nT = 2 ** 13\nx = generate_harmonic_signal(T)\nplt.figure(figsize=(8, 2))\nplt.plot(x)\nplt.title(""Original signal"")\n\n###############################################################################\n# Spectrogram\n# -----------\n# Let\'s take a look at the signal spectrogram\nplt.figure(figsize=(8, 4))\nplt.specgram(x, Fs=1024)\nplt.title(""Time-Frequency spectrogram of signal"")\n\n###############################################################################\n# Doing the scattering transform\n# ------------------------------\nJ = 6\nQ = 16\n\nscattering = Scattering1D(J, T, Q)\n\nmeta = scattering.meta()\norder0 = np.where(meta[\'order\'] == 0)\norder1 = np.where(meta[\'order\'] == 1)\norder2 = np.where(meta[\'order\'] == 2)\n\nSx = scattering(x)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(3, 1, 1)\nplt.plot(Sx[order0][0])\nplt.title(\'Zeroth-order scattering\')\nplt.subplot(3, 1, 2)\nplt.imshow(Sx[order1], aspect=\'auto\')\nplt.title(\'First-order scattering\')\nplt.subplot(3, 1, 3)\nplt.imshow(Sx[order2], aspect=\'auto\')\nplt.title(\'Second-order scattering\')\n\nplt.show()\n'"
examples/1d/reconstruct_torch.py,9,"b'""""""\nReconstruct a synthetic signal from its scattering transform\n============================================================\nIn this example we generate a harmonic signal of a few different frequencies,\nanalyze it with the 1D scattering transform, and reconstruct the scattering\ntransform back to the harmonic signal.\n""""""\n\n###############################################################################\n# Import the necessary packages\n# -----------------------------\n\nimport numpy as np\nimport torch\nfrom kymatio.torch import Scattering1D\n\nfrom torch.autograd import backward\nimport matplotlib.pyplot as plt\n\n###############################################################################\n# Write a function that can generate a harmonic signal\n# ----------------------------------------------------\n# Let\'s write a function that can generate some simple blip-type sounds with\n# decaying harmonics. It will take four arguments: T, the length of the output\n# vector; num_intervals, the number of different blips; gamma, the exponential\n# decay factor of the harmonic; random_state, a random seed to generate\n# random pitches and phase shifts.\n# The function proceeds by splitting the time length T into intervals, chooses\n# base frequencies and phases, generates sinusoidal sounds and harmonics,\n# and then adds a windowed version to the output signal.\ndef generate_harmonic_signal(T, num_intervals=4, gamma=0.9, random_state=42):\n    """"""\n    Generates a harmonic signal, which is made of piecewise constant notes\n    (of random fundamental frequency), with half overlap\n    """"""\n    rng = np.random.RandomState(random_state)\n    num_notes = 2 * (num_intervals - 1) + 1\n    support = T // num_intervals\n    half_support = support // 2\n\n    base_freq = 0.1 * rng.rand(num_notes) + 0.05\n    phase = 2 * np.pi * rng.rand(num_notes)\n    window = np.hanning(support)\n    x = np.zeros(T, dtype=\'float32\')\n    t = np.arange(0, support)\n    u = 2 * np.pi * t\n    for i in range(num_notes):\n        ind_start = i * half_support\n        note = np.zeros(support)\n        for k in range(1):\n            note += (np.power(gamma, k) *\n                     np.cos(u * (k + 1) * base_freq[i] + phase[i]))\n        x[ind_start:ind_start + support] += note * window\n\n    return x\n\n###############################################################################\n# Let\xe2\x80\x99s take a look at what such a signal could look like.\n\nT = 2 ** 13\nx = torch.from_numpy(generate_harmonic_signal(T))\nplt.figure(figsize=(8, 2))\nplt.plot(x.numpy())\nplt.title(""Original signal"")\n\n###############################################################################\n# Let\xe2\x80\x99s take a look at the signal spectrogram.\n\nplt.figure(figsize=(8, 8))\nplt.specgram(x.numpy(), Fs=1024)\nplt.title(""Spectrogram of original signal"")\n\n###############################################################################\n## Doing the scattering transform.\n\nJ = 6\nQ = 16\n\nscattering = Scattering1D(J, T, Q)\n\nSx = scattering(x)\n\nlearning_rate = 100\nbold_driver_accelerator = 1.1\nbold_driver_brake = 0.55\nn_iterations = 200\n\n###############################################################################\n# Reconstruct the scattering transform back to original signal.\n\n# Random guess to initialize.\ntorch.manual_seed(0)\ny = torch.randn((T,), requires_grad=True)\nSy = scattering(y)\n\nhistory = []\nsignal_update = torch.zeros_like(x)\n\n# Iterate to recontsruct random guess to be close to target.\nfor k in range(n_iterations):\n    # Backpropagation.\n    err = torch.norm(Sx - Sy)\n\n    if k % 10 == 0:\n        print(\'Iteration %3d, loss %.2f\' % (k, err.detach().numpy()))\n\n    # Measure the new loss.\n    history.append(err)\n\n    backward(err)\n\n    delta_y = y.grad\n\n    # Gradient descent\n    with torch.no_grad():\n        signal_update = - learning_rate * delta_y\n        new_y = y + signal_update\n    new_y.requires_grad = True\n\n    # New forward propagation.\n    Sy = scattering(new_y)\n\n    if history[k] > history[k - 1]:\n        learning_rate *= bold_driver_brake\n    else:\n        learning_rate *= bold_driver_accelerator\n        y = new_y\n\nplt.figure(figsize=(8, 2))\nplt.plot(history)\nplt.title(""MSE error vs. iterations"")\n\nplt.figure(figsize=(8, 2))\nplt.plot(y.detach().numpy())\nplt.title(""Reconstructed signal"")\n\nplt.figure(figsize=(8, 8))\nplt.specgram(y.detach().numpy(), Fs=1024)\nplt.title(""Spectrogram of reconstructed signal"")\n\nplt.show()\n'"
examples/2d/cifar_resnet_torch.py,0,"b'""""""\nClassification on CIFAR10 (ResNet)\n==================================\n\nBased on pytorch example for CIFAR10\n""""""\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim\nfrom torchvision import datasets, transforms\nfrom kymatio.torch import Scattering2D\nimport kymatio.datasets as scattering_datasets\nimport argparse\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Scattering2dResNet(nn.Module):\n    def __init__(self, in_channels,  k=2, n=4, num_classes=10):\n        super(Scattering2dResNet, self).__init__()\n        self.inplanes = 16 * k\n        self.ichannels = 16 * k\n        self.K = in_channels\n        self.init_conv = nn.Sequential(\n            nn.BatchNorm2d(in_channels, eps=1e-5, affine=False),\n            nn.Conv2d(in_channels, self.ichannels,\n                  kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(self.ichannels),\n            nn.ReLU(True)\n        )\n\n        self.layer2 = self._make_layer(BasicBlock, 32 * k, n)\n        self.layer3 = self._make_layer(BasicBlock, 64 * k, n)\n        self.avgpool = nn.AdaptiveAvgPool2d(2)\n        self.fc = nn.Linear(64 * k * 4, num_classes)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes),\n            )\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = x.view(x.size(0), self.K, 8, 8)\n        x = self.init_conv(x)\n\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n\n\ndef train(model, device, train_loader, optimizer, epoch, scattering):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(scattering(data))\n        loss = F.cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 50 == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n\ndef test(model, device, test_loader, scattering):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(scattering(data))\n            test_loss += F.cross_entropy(output, target, reduction=\'sum\').item() # sum up batch loss\n            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\nif __name__ == \'__main__\':\n\n    """"""Train a simple Hybrid Resnet Scattering + CNN model on CIFAR.\n\n        scattering 1st order can also be set by the mode\n        Scattering features are normalized by batch normalization.\n        The model achieves around 88% testing accuracy after 10 epochs.\n\n        scatter 1st order +\n        scatter 2nd order + linear achieves 70.5% in 90 epochs\n\n        scatter + cnn achieves 88% in 15 epochs\n\n    """"""\n    parser = argparse.ArgumentParser(description=\'CIFAR scattering  + hybrid examples\')\n    parser.add_argument(\'--mode\', type=int, default=1,help=\'scattering 1st or 2nd order\')\n    parser.add_argument(\'--width\', type=int, default=2,help=\'width factor for resnet\')\n    args = parser.parse_args()\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(""cuda"" if use_cuda else ""cpu"")\n\n    if args.mode == 1:\n        scattering = Scattering2D(J=2, shape=(32, 32), max_order=1)\n        K = 17*3\n    else:\n        scattering = Scattering2D(J=2, shape=(32, 32))\n        K = 81*3\n    if use_cuda:\n        scattering = scattering.cuda()\n\n\n\n\n    model = Scattering2dResNet(K, args.width).to(device)\n\n    # DataLoaders\n    if use_cuda:\n        num_workers = 4\n        pin_memory = True\n    else:\n        num_workers = None\n        pin_memory = False\n\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(root=scattering_datasets.get_dataset_dir(\'CIFAR\'), train=True, transform=transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomCrop(32, 4),\n            transforms.ToTensor(),\n            normalize,\n        ]), download=True),\n        batch_size=128, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(root=scattering_datasets.get_dataset_dir(\'CIFAR\'), train=False, transform=transforms.Compose([\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=128, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n\n    # Optimizer\n    lr = 0.1\n    for epoch in range(0, 90):\n        if epoch%20==0:\n            optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9,\n                                        weight_decay=0.0005)\n            lr*=0.2\n\n        train(model, device, train_loader, optimizer, epoch+1, scattering)\n        test(model, device, test_loader, scattering)\n'"
examples/2d/cifar_small_sample.py,3,"b'""""""\nClassification on CIFAR10 (ResNet)\n==================================\n\nBased on pytorch example for CIFAR10\n""""""\n\n\nimport torch.optim\nfrom torchvision import datasets, transforms\nimport torch.nn.functional as F\nfrom kymatio import Scattering2D\nimport torch\nimport argparse\nimport kymatio.datasets as scattering_datasets\nimport torch.nn as nn\nfrom numpy.random import RandomState\nimport numpy as np\n\n\nclass Identity(nn.Module):\n    def __init__(self, *args, **kwargs):\n        super().__init__()\n    def forward(self, x):\n        return x\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Scattering2dResNet(nn.Module):\n    def __init__(self, in_channels,  k=2, n=4, num_classes=10,standard=False):\n        super(Scattering2dResNet, self).__init__()\n        self.inplanes = 16 * k\n        self.ichannels = 16 * k\n        if standard:\n\n            self.init_conv = nn.Sequential(\n                nn.Conv2d(3, self.ichannels,\n                          kernel_size=3, stride=1, padding=1, bias=False),\n                nn.BatchNorm2d(self.ichannels),\n                nn.ReLU(True)\n            )\n            self.layer1 = self._make_layer(BasicBlock, 16 * k, n)\n            self.standard = True\n        else:\n            self.K = in_channels\n            self.init_conv = nn.Sequential(\n                nn.BatchNorm2d(in_channels, eps=1e-5, affine=False),\n                nn.Conv2d(in_channels, self.ichannels,\n                      kernel_size=3, stride=1, padding=1, bias=False),\n                nn.BatchNorm2d(self.ichannels),\n                nn.ReLU(True)\n            )\n            self.standard = False\n\n        self.layer2 = self._make_layer(BasicBlock, 32 * k, n)\n        self.layer3 = self._make_layer(BasicBlock, 64 * k, n)\n        self.avgpool = nn.AdaptiveAvgPool2d(2)\n        self.fc = nn.Linear(64 * k * 4, num_classes)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes),\n            )\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        if not self.standard:\n            x = x.view(x.size(0), self.K, 8, 8)\n\n        x = self.init_conv(x)\n\n        if self.standard:\n            x = self.layer1(x)\n\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n\n\ndef train(model, device, train_loader, optimizer, epoch, scattering):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(scattering(data))\n        loss = F.cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 50 == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n\ndef test(model, device, test_loader, scattering):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(scattering(data))\n            test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\ndef main():\n    """"""Train a simple Hybrid Resnet Scattering + CNN model on CIFAR.\n\n    """"""\n    parser = argparse.ArgumentParser(description=\'CIFAR scattering  + hybrid examples\')\n    parser.add_argument(\'--mode\', type=str, default=\'scattering\',choices=[\'scattering\', \'standard\'],\n                        help=\'network_type\')\n    parser.add_argument(\'--num_samples\', type=int, default=50,\n                        help=\'samples per class\')\n    parser.add_argument(\'--learning_schedule_multi\', type=int, default=10,\n                        help=\'samples per class\')\n    parser.add_argument(\'--seed\', type=int, default=0,\n                        help=\'seed for dataset subselection\')\n    parser.add_argument(\'--width\', type=int, default=2,help=\'width factor for resnet\')\n    args = parser.parse_args()\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(""cuda"" if use_cuda else ""cpu"")\n\n    if args.mode == \'scattering\':\n        scattering = Scattering2D(J=2, shape=(32, 32))\n        K = 81*3\n        model = Scattering2dResNet(K, args.width).to(device)\n        if use_cuda:\n            scattering = scattering.cuda()\n    else:\n        model = Scattering2dResNet(8, args.width,standard=True).to(device)\n        scattering = Identity()\n\n\n    # DataLoaders\n    if use_cuda:\n        num_workers = 4\n        pin_memory = True\n    else:\n        num_workers = 0\n        pin_memory = False\n\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n\n    #####cifar data\n    cifar_data = datasets.CIFAR10(root=scattering_datasets.get_dataset_dir(\'CIFAR\'), train=True, transform=transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomCrop(32, 4),\n            transforms.ToTensor(),\n            normalize,\n        ]), download=True)\n    # Extract a subset of X samples per class\n    prng = RandomState(args.seed)\n    random_permute = prng.permutation(np.arange(0, 5000))[0:args.num_samples]\n    indx = np.concatenate([np.where(np.array(cifar_data.targets) == classe)[0][random_permute] for classe in range(0, 10)])\n\n    cifar_data.data, cifar_data.targets = cifar_data.data[indx], list(np.array(cifar_data.targets)[indx])\n    train_loader = torch.utils.data.DataLoader(cifar_data,\n                                               batch_size=32, shuffle=True, num_workers=num_workers,\n                                               pin_memory=pin_memory)\n\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(root=scattering_datasets.get_dataset_dir(\'CIFAR\'), train=False, transform=transforms.Compose([\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=128, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n\n\n\n    # Optimizer\n    lr = 0.1\n    M = args.learning_schedule_multi\n    drops = [60*M,120*M,160*M]\n    for epoch in range(0, 200*M):\n        if epoch in drops or epoch==0:\n            optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9,\n                                        weight_decay=0.0005)\n            lr*=0.2\n\n        train(model, device, train_loader, optimizer, epoch+1, scattering)\n        if epoch%10==0:\n            test(model, device, test_loader, scattering)\n\n\n\nif __name__ == \'__main__\':\n    main()\n'"
examples/2d/cifar_torch.py,0,"b'""""""\nClassification on CIFAR10\n=========================\n\nBased on pytorch example for MNIST\n""""""\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim\nfrom torchvision import datasets, transforms\nfrom kymatio.torch import Scattering2D\nimport kymatio.datasets as scattering_datasets\nimport argparse\n\n\nclass Scattering2dCNN(nn.Module):\n    \'\'\'\n        Simple CNN with 3x3 convs based on VGG\n    \'\'\'\n    def __init__(self, in_channels, classifier_type=\'cnn\'):\n        super(Scattering2dCNN, self).__init__()\n        self.in_channels = in_channels\n        self.classifier_type = classifier_type\n        self.build()\n\n    def build(self):\n        cfg = [256, 256, 256, \'M\', 512, 512, 512, 1024, 1024]\n        layers = []\n        self.K = self.in_channels\n        self.bn = nn.BatchNorm2d(self.K)\n        if self.classifier_type == \'cnn\':\n            for v in cfg:\n                if v == \'M\':\n                    layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n                else:\n                    conv2d = nn.Conv2d(self.in_channels, v, kernel_size=3, padding=1)\n                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n                    self.in_channels = v\n\n            layers += [nn.AdaptiveAvgPool2d(2)]\n            self.features = nn.Sequential(*layers)\n            self.classifier =  nn.Linear(1024*4, 10)\n\n        elif self.classifier_type == \'mlp\':\n            self.classifier = nn.Sequential(\n                        nn.Linear(self.K*8*8, 1024), nn.ReLU(),\n                        nn.Linear(1024, 1024), nn.ReLU(),\n                        nn.Linear(1024, 10))\n            self.features = None\n\n        elif self.classifier_type == \'linear\':\n            self.classifier = nn.Linear(self.K*8*8,10)\n            self.features = None\n\n\n    def forward(self, x):\n        x = self.bn(x.view(-1, self.K, 8, 8))\n        if self.features:\n            x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n\n\ndef train(model, device, train_loader, optimizer, epoch, scattering):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(scattering(data))\n        loss = F.cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 50 == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n\ndef test(model, device, test_loader, scattering):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(scattering(data))\n            test_loss += F.cross_entropy(output, target, reduction=\'sum\').item() # sum up batch loss\n            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\nif __name__ == \'__main__\':\n\n    """"""Train a simple Hybrid Scattering + CNN model on CIFAR.\n\n        Three models are demoed:\n        \'linear\' - scattering + linear model\n        \'mlp\' - scattering + MLP\n        \'cnn\' - scattering + CNN\n\n        scattering 1st order can also be set by the mode\n        Scattering features are normalized by batch normalization.\n        The model achieves around 88% testing accuracy after 10 epochs.\n\n        scatter 1st order + linear achieves 64% in 90 epochs\n        scatter 2nd order + linear achieves 70.5% in 90 epochs\n\n        scatter + cnn achieves 88% in 15 epochs\n\n    """"""\n    parser = argparse.ArgumentParser(description=\'MNIST scattering  + hybrid examples\')\n    parser.add_argument(\'--mode\', type=int, default=1,help=\'scattering 1st or 2nd order\')\n    parser.add_argument(\'--classifier\', type=str, default=\'cnn\',help=\'classifier model\')\n    args = parser.parse_args()\n    assert(args.classifier in [\'linear\',\'mlp\',\'cnn\'])\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(""cuda"" if use_cuda else ""cpu"")\n\n    if args.mode == 1:\n        scattering = Scattering2D(J=2, shape=(32, 32), max_order=1)\n        K = 17*3\n    else:\n        scattering = Scattering2D(J=2, shape=(32, 32))\n        K = 81*3\n    if use_cuda:\n        scattering = scattering.cuda()\n\n\n\n\n    model = Scattering2dCNN(K,args.classifier).to(device)\n\n    # DataLoaders\n    if use_cuda:\n        num_workers = 4\n        pin_memory = True\n    else:\n        num_workers = None\n        pin_memory = False\n\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(root=scattering_datasets.get_dataset_dir(\'CIFAR\'), train=True, transform=transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomCrop(32, 4),\n            transforms.ToTensor(),\n            normalize,\n        ]), download=True),\n        batch_size=128, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(root=scattering_datasets.get_dataset_dir(\'CIFAR\'), train=False, transform=transforms.Compose([\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=128, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n\n    # Optimizer\n    lr = 0.1\n    for epoch in range(0, 90):\n        if epoch%20==0:\n            optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9,\n                                        weight_decay=0.0005)\n            lr*=0.2\n\n        train(model, device, train_loader, optimizer, epoch+1, scattering)\n        test(model, device, test_loader, scattering)\n'"
examples/2d/long_mnist_classify_torch.py,1,"b'""""""\nClassification of Few Sample MNIST with Scattering\n=====================================================================\nHere we demonstrate a simple application of scattering on the MNIST dataset.\nWe use 5000 MNIST samples to train a linear classifier. Features are normalized by batch normalization.\nPlease also see more extensive classification examples/2d/cifar.py\nthat consider training CNNs on top of the scattering. These are\nare included as  executable script with command line arguments\n""""""\n\n\n###############################################################################\n# If a GPU is available, let\'s use it!\nimport torch\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(""cuda"" if use_cuda else ""cpu"")\n\n###############################################################################\n# For reproducibility, we fix the seed of the random number generator.\nfrom numpy.random import RandomState\nimport numpy as np\ntorch.manual_seed(42)\nprng = RandomState(42)\n\n###############################################\n# Create dataloaders\nfrom torchvision import datasets, transforms\nimport kymatio.datasets as scattering_datasets\n\nif use_cuda:\n    num_workers = 4\n    pin_memory = True\nelse:\n    num_workers = 0\n    pin_memory = False\n\ntrain_data = datasets.MNIST(\n                scattering_datasets.get_dataset_dir(\'MNIST\'),\n                train=True, download=True,\n                transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                ]))\n\n# Extract a subset of 5000 samples from MNIST training\nrandom_permute=prng.permutation(np.arange(0,60000))[0:5000]\ntrain_data.data = train_data.data[random_permute]\ntrain_data.targets = train_data.targets[random_permute]\ntrain_loader = torch.utils.data.DataLoader(train_data,\n    batch_size=128, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n\n# Create the test loader on the full MNIST test set\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(\n        scattering_datasets.get_dataset_dir(\'MNIST\'),\n        train=False, transform=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n    ])),\n    batch_size=128, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n\n\n###############################################################################\n# This will help us define networks a bit more cleanly\nimport torch.nn as nn\nclass View(nn.Module):\n    def __init__(self, *args):\n        super(View, self).__init__()\n        self.shape = args\n\n    def forward(self, x):\n        return x.view(-1,*self.shape)\n\n\n###############################################################################\n# Create a training and test function\nimport torch.nn.functional as F\n\ndef train(model, device, train_loader, optimizer, scattering):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(scattering(data))\n        loss = F.cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n\n\ndef test(model, device, test_loader, scattering):\n    model.eval()\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(scattering(data))\n            pred = output.max(1, keepdim = True)[1]\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    return 100. * correct / len(test_loader.dataset)\n############################################################################\n# Train a simple Hybrid Scattering + CNN model on MNIST.\n\nfrom kymatio.torch import Scattering2D\nimport torch.optim\nimport math\n\n\n# Evaluate linear model on top of scattering\nscattering = Scattering2D(shape = (28, 28), J=2)\nK = 81 #Number of output coefficients for each spatial postiion\n\nif use_cuda:\n    scattering = scattering.cuda()\n\nmodel = nn.Sequential(\n    View(K, 7, 7),\n    nn.BatchNorm2d(K),\n    View(K * 7 * 7),\n    nn.Linear(K * 7 * 7, 10)\n).to(device)\n\n# Optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9,\n                            weight_decay=0.0005)\nfor epoch in range(0, 20):\n    train( model, device, train_loader, optimizer, scattering)\n\nacc = test(model, device, test_loader, scattering)\nprint(\'Scattering order 2 linear model test accuracy: %.2f\' % acc)\n'"
examples/2d/mnist_keras.py,0,"b'""""""\nClassification of MNIST with scattering\n=======================================\nHere we demonstrate a simple application of scattering on the MNIST dataset.\nWe use 10000 images to train a linear classifier. Features are normalized by\nbatch normalization.\n""""""\n\n###############################################################################\n# Preliminaries\n# -------------\n#\n# Since we\'re using TensorFlow and Keras to train the model, import the\n# relevant modules.\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense\n\n###############################################################################\n# Finally, we import the `Scattering2D` class from the `kymatio.keras`\n# package.\n\nfrom kymatio.keras import Scattering2D\n\n###############################################################################\n# Training and testing the model\n# ------------------------------\n#\n# First, we load in the data and normalize it.\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\nx_train, x_test = x_train / 255., x_test / 255.\n\n###############################################################################\n# We then create a Keras model using the scattering transform followed by a\n# dense layer and a softmax activation.\n\ninputs = Input(shape=(28, 28))\nx = Scattering2D(J=3, L=8)(inputs)\nx = Flatten()(x)\nx_out = Dense(10, activation=\'softmax\')(x)\nmodel = Model(inputs, x_out)\n\n###############################################################################\n# Display the created model.\n\nmodel.summary()\n\n###############################################################################\n# Once the model is created, we couple it with an Adam optimizer and a\n# cross-entropy loss function.\n\nmodel.compile(optimizer=\'adam\',\n              loss=\'sparse_categorical_crossentropy\',\n              metrics=[\'accuracy\'])\n\n###############################################################################\n# We then train the model using `model.fit` on a subset of the MNIST data.\n\nmodel.fit(x_train[:10000], y_train[:10000], epochs=15,\n          batch_size=64, validation_split=0.2)\n\n###############################################################################\n# Finally, we evaluate the model on the held-out test data.\n\nmodel.evaluate(x_test, y_test)\n'"
examples/2d/plot_filters.py,8,"b'""""""\nPlot the 2D wavelet filters\n===========================\nSee :meth:`kymatio.scattering2d.filter_bank` for more informations about the used wavelets.\n""""""\n\nfrom colorsys import hls_to_rgb\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom kymatio.scattering2d.filter_bank import filter_bank\nfrom kymatio.scattering2d.utils import fft2\n\n\n###############################################################################\n# Initial parameters of the filter bank\n# -------------------------------------\nM = 32\nJ = 3\nL = 8\nfilters_set = filter_bank(M, M, J, L=L)\n\n###############################################################################\n# Imshow complex images\n# ---------------------\n# Thanks to https://stackoverflow.com/questions/17044052/mathplotlib-imshow-complex-2d-array\n\n\ndef colorize(z):\n    n, m = z.shape\n    c = np.zeros((n, m, 3))\n    c[np.isinf(z)] = (1.0, 1.0, 1.0)\n    c[np.isnan(z)] = (0.5, 0.5, 0.5)\n\n    idx = ~(np.isinf(z) + np.isnan(z))\n    A = (np.angle(z[idx]) + np.pi) / (2*np.pi)\n    A = (A + 0.5) % 1.0\n    B = 1.0/(1.0 + abs(z[idx])**0.3)\n    c[idx] = [hls_to_rgb(a, b, 0.8) for a, b in zip(A, B)]\n    return c\n\n###############################################################################\n# Bandpass filters\n# ----------------\n# First, we display each wavelet according to its scale and orientation.\nfig, axs = plt.subplots(J, L, sharex=True, sharey=True)\nfig.set_figheight(6)\nfig.set_figwidth(6)\nplt.rc(\'text\', usetex=True)\nplt.rc(\'font\', family=\'serif\')\ni = 0\nfor filter in filters_set[\'psi\']:\n    f = filter[0]\n    filter_c = fft2(f)\n    filter_c = np.fft.fftshift(filter_c)\n    axs[i // L, i % L].imshow(colorize(filter_c))\n    axs[i // L, i % L].axis(\'off\')\n    axs[i // L, i % L].set_title(\n        ""$j = {}$ \\n $\\\\theta={}$"".format(i // L, i % L))\n    i = i+1\n\nfig.suptitle((r""Wavelets for each scales $j$ and angles $\\theta$ used.""\n              ""\\nColor saturation and color hue respectively denote complex ""\n              ""magnitude and complex phase.""), fontsize=13)\nfig.show()\n\n###############################################################################\n# Lowpass filter\n# --------------\n# We finally display the low-pass filter.\nplt.figure()\nplt.rc(\'text\', usetex=True)\nplt.rc(\'font\', family=\'serif\')\nplt.axis(\'off\')\nplt.set_cmap(\'gray_r\')\n\nf = filters_set[\'phi\'][0]\n\nfilter_c = fft2(f)\nfilter_c = np.fft.fftshift(filter_c)\nplt.suptitle((""The corresponding low-pass filter, also known as scaling ""\n              ""function.\\nColor saturation and color hue respectively denote ""\n              ""complex magnitude and complex phase""), fontsize=13)\nfilter_c = np.abs(filter_c)\nplt.imshow(filter_c)\n\nplt.show()\n'"
examples/2d/plot_invert_scattering_torch.py,6,"b'""""""\nInverting scattering via mse\n============================\nThis script aims to quantify the information loss for natural images by\nperforming a reconstruction of an image from its scattering coefficients via a\nL2-norm minimization.\n""""""\n\n###############################################################################\n# Imports\n# -------\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom PIL import Image\nfrom torch import optim\nfrom scipy.misc import face\n\nfrom kymatio.torch import Scattering2D\n\ndevice = ""cuda"" if torch.cuda.is_available() else ""cpu""\n\n###############################################################################\n# Load test image\n# ---------------\nsrc_img = Image.fromarray(face())\nsrc_img = src_img.resize((512, 384), Image.ANTIALIAS)\nsrc_img = np.array(src_img).astype(np.float32)\nsrc_img = src_img / 255.0\nplt.imshow(src_img)\nplt.title(""Original image"")\n\nsrc_img = np.moveaxis(src_img, -1, 0)  # HWC to CHW\nmax_iter = 5 # number of steps for the GD\nprint(""Image shape: "", src_img.shape)\nchannels, height, width = src_img.shape\n\n###############################################################################\n#  Main loop\n# ----------\nfor order in [1]:\n    for J in [2, 4]:\n\n        # Compute scattering coefficients\n        scattering = Scattering2D(J=J, shape=(height, width), max_order=order)\n        if device == ""cuda"":\n            scattering = scattering.cuda()\n            max_iter = 500\n        src_img_tensor = torch.from_numpy(src_img).to(device).contiguous()\n        scattering_coefficients = scattering(src_img_tensor)\n\n        # Create trainable input image\n        input_tensor = torch.rand(src_img.shape, requires_grad=True, device=device)\n\n        # Optimizer hyperparams\n        optimizer = optim.Adam([input_tensor], lr=1)\n\n        # Training\n        best_img = None\n        best_loss = float(""inf"")\n        for epoch in range(1, max_iter):\n            new_coefficients = scattering(input_tensor)\n            loss = F.mse_loss(input=new_coefficients, target=scattering_coefficients)\n            print(""Epoch {}, loss: {}"".format(epoch, loss.item()), end=""\\r"")\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            if loss < best_loss:\n                best_loss = loss.detach().cpu().item()\n                best_img = input_tensor.detach().cpu().numpy()\n\n        best_img = np.clip(best_img, 0.0, 1.0)\n\n        # PSNR\n        mse = np.mean((src_img - best_img) ** 2)\n        psnr = 20 * np.log10(1.0 / np.sqrt(mse))\n        print(""\\nPSNR: {:.2f}dB for order {} and J={}"".format(psnr, order, J))\n\n        # Plot\n        plt.figure()\n        plt.imshow(np.moveaxis(best_img, 0, -1))\n        plt.title(""PSNR: {:.2f}dB (order {}, J={})"".format(psnr, order, J))\n\nplt.show()\n'"
examples/2d/plot_scattering_disk.py,6,"b'""""""\nScattering disk display\n=======================\nThis script reproduces concentric circles that encode Scattering coefficient\'s\nenergy as described in ""Invariant Scattering Convolution Networks"" by Bruna and Mallat.\nHere, for the sake of simplicity, we only consider first order scattering.\n\nAuthor: https://github.com/Jonas1312\nEdited by: Edouard Oyallon\n""""""\n\n\n\nimport matplotlib as mpl\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom kymatio import Scattering2D\nfrom PIL import Image\nimport os\n\n\nimg_name = os.path.join(os.getcwd(),""images/digit.png"")\n\n####################################################################\n# Scattering computations\n#-------------------------------------------------------------------\n# First, we read the input digit:\nsrc_img = Image.open(img_name).convert(\'L\').resize((32,32))\nsrc_img = np.array(src_img)\nprint(""img shape: "", src_img.shape)\n\n####################################################################\n# We compute a Scattering Transform with L=6 angles and J=3 scales.\n# Rotating a wavelet $\\psi$ by $\\pi$ is equivalent to consider its\n# conjugate in fourier: $\\hat\\psi_{\\pi}(\\omega)=\\hat\\psi(r_{-\\pi}\\omega)^*$.\n#\n# Combining this and the fact that a real signal has a Hermitian symmetry\n# implies that it is usually sufficient to use the angles $\\{\\frac{\\pi l}{L}\\}_{l\\leq L}$ at computation time.\n# For consistency, we will however display $\\{\\frac{2\\pi l}{L}\\}_{l\\leq 2L}$,\n# which implies that our visualization will be redundant and have a symmetry by rotation of $\\pi$.\n\nL = 6\nJ = 3\nscattering = Scattering2D(J=J, shape=src_img.shape, L=L, max_order=1, frontend=\'numpy\')\n\n####################################################################\n# We now compute the scattering coefficients:\nsrc_img_tensor = src_img.astype(np.float32) / 255.\n\nscattering_coefficients = scattering(src_img_tensor)\nprint(""coeffs shape: "", scattering_coefficients.shape)\n# Invert colors\nscattering_coefficients = -scattering_coefficients\n\n####################################################################\n# We skip the low pass filter...\nscattering_coefficients = scattering_coefficients[1:, :, :]\nnorm = mpl.colors.Normalize(scattering_coefficients.min(), scattering_coefficients.max(), clip=True)\nmapper = cm.ScalarMappable(norm=norm, cmap=""gray"")\nnb_coeffs, window_rows, window_columns = scattering_coefficients.shape\n\n####################################################################\n# Figure reproduction\n#-------------------------------------------------------------------\n\n####################################################################\n# Now we can reproduce a figure that displays the energy of the first\n# order Scattering coefficient, which are given by $\\{\\mid x\\star\\psi_{j,\\theta}\\mid\\star\\phi_J|\\}_{j,\\theta}$ .\n# Here, each scattering coefficient is represented on the polar plane. The polar radius and angle correspond\n# respectively to the scale $j$ and the rotation $\\theta$ applied to the mother wavelet.\n#\n# Observe that as predicted, the visualization exhibit a redundancy and a symmetry.\n\nfig,ax = plt.subplots()\n\nplt.imshow(1-src_img,cmap=\'gray\',interpolation=\'nearest\', aspect=\'auto\')\nax.axis(\'off\')\noffset = 0.1\nfor row in range(window_rows):\n    for column in range(window_columns):\n        ax=fig.add_subplot(window_rows, window_columns, 1 + column + row * window_rows, projection=\'polar\')\n        ax.set_ylim(0, 1)\n        ax.axis(\'off\')\n        ax.set_yticklabels([])  # turn off radial tick labels (yticks)\n        ax.set_xticklabels([])  # turn off degrees\n        # ax.set_theta_zero_location(\'N\')  # 0\xc2\xb0 to North\n        coefficients = scattering_coefficients[:, row, column]\n        for j in range(J):\n            for l in range(L):\n                coeff = coefficients[l + (J - 1 - j) * L]\n                color = mpl.colors.to_hex(mapper.to_rgba(coeff))\n                ax.bar(x=(4.5+l) *  np.pi / L,\n                       height=2*(2**(j-1) / 2**J),\n                       width=2 * np.pi / L,\n                       bottom=offset + (2**j / 2**J) ,\n                       color=color)\n                ax.bar(x=(4.5+l+L) * np.pi / L,\n                       height=2*(2**(j-1) / 2**J),\n                       width=2 * np.pi / L,\n                       bottom=offset + (2**j / 2**J) ,\n                       color=color)\n'"
examples/2d/plot_sklearn.py,0,"b'""""""\nScikit-learn transformer example\n================================\nHere we demonstrate a simple application of scattering as a transformer\n""""""\n\n###############################################################################\n# Preliminaries\n# -------------\n#\n# Import the relevant classes and functions from sciki-learn.\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n###############################################################################\n# Import the scikit-learn `Scattering2D` frontend.\n\nfrom kymatio.sklearn import Scattering2D\n\n###############################################################################\n# Preparing the data\n# ------------------\n#\n# First, we load the dataset. In this case, it\'s the UCI ML digits dataset\n# included with scikit-learn, consisting of 8\xc3\x978 images of handwritten digits\n# from one to ten.\n\ndigits = datasets.load_digits()\n\n###############################################################################\n# We then extract the images, reshape them to an array of size `(n_features,\n# n_samples)` needed for processing in a scikit-learn pipeline.\n\nimages = digits.images\nimages = images.reshape((images.shape[0], -1))\n\n###############################################################################\n# We then split the images (and their labels) into a train and a test set.\n\nx_train, x_test, y_train, y_test = train_test_split(images, digits.target,\n                                                    test_size=0.5, shuffle=False)\n\n###############################################################################\n# Training and testing the model\n# ------------------------------\n# Create a `Scattering2D` object, which implements a scikit-learn\n# `Transformer`. We set the input shape to match that of the the images (8\xc3\x978)\n# and the averaging scale is set to `J = 1`, which means that the local\n# invariance is `2 ** 1 = 1`.\n\nS = Scattering2D(shape=(8, 8), J=1)\n\n###############################################################################\n# We then plug this into a scikit-learn pipeline which takes the scattering\n# features and provides them to a `LogisticRegression` classifier.\n\nclassifier = LogisticRegression()\nestimators = [(\'scatter\', S), (\'clf\', classifier)]\npipeline = Pipeline(estimators)\n\n###############################################################################\n# Given the pipeline, we train it on `(x_train, y_train)` using\n# `pipelien.fit`.\n\npipeline.fit(x_train, y_train)\n\n###############################################################################\n# Finally, we calculate the predicted labels on the test data and output the\n# classification accuracy.\n\ny_pred = pipeline.predict(x_test)\n\nprint(\'Accuracy:\', accuracy_score(y_test, y_pred))\n'"
examples/2d/regularized_inverse_scattering_MNIST_torch.py,4,"b'""""""\nRegularized inverse of a scattering transform on MNIST\n======================================================\n\nDescription:\nThis example trains a convolutional network to invert the scattering transform at scale 2 of MNIST digits.\nAfter only two epochs, it produces a network that transforms a linear interpolation in the scattering space into a\nnonlinear interpolation in the image space.\n\nRemarks:\nThe model after two epochs and the path (which consists of a sequence of images) are stored in the cache directory.\nThe two epochs take roughly 5 minutes in a Quadro M6000.\n\nReference:\nhttps://arxiv.org/abs/1805.06621\n""""""\n\nimport argparse\nimport os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom PIL import Image\n\nfrom kymatio.torch import Scattering2D as Scattering\nfrom kymatio.caching import get_cache_dir\nfrom kymatio.datasets import get_dataset_dir\n\n\ndevice = ""cuda"" if torch.cuda.is_available() else ""cpu""\n\nclass Generator(nn.Module):\n    def __init__(self, num_input_channels, num_hidden_channels, num_output_channels=1, filter_size=3):\n        super(Generator, self).__init__()\n        self.num_input_channels = num_input_channels\n        self.num_hidden_channels = num_hidden_channels\n        self.num_output_channels = num_output_channels\n        self.filter_size = filter_size\n        self.build()\n\n    def build(self):\n        padding = (self.filter_size - 1) // 2\n\n        self.main = nn.Sequential(\n            nn.ReflectionPad2d(padding),\n            nn.Conv2d(self.num_input_channels, self.num_hidden_channels, self.filter_size, bias=False),\n            nn.BatchNorm2d(self.num_hidden_channels, eps=0.001, momentum=0.9),\n            nn.ReLU(inplace=True),\n            nn.Upsample(scale_factor=2, mode=\'bilinear\', align_corners=False),\n\n            nn.ReflectionPad2d(padding),\n            nn.Conv2d(self.num_hidden_channels, self.num_hidden_channels, self.filter_size, bias=False),\n            nn.BatchNorm2d(self.num_hidden_channels, eps=0.001, momentum=0.9),\n            nn.ReLU(inplace=True),\n            nn.Upsample(scale_factor=2, mode=\'bilinear\', align_corners=False),\n\n            nn.ReflectionPad2d(padding),\n            nn.Conv2d(self.num_hidden_channels, self.num_output_channels, self.filter_size, bias=False),\n            nn.BatchNorm2d(self.num_output_channels, eps=0.001, momentum=0.9),\n            nn.Tanh()\n        )\n\n    def forward(self, input_tensor):\n        return self.main(input_tensor)\n\n\nif __name__ == \'__main__\':\n\n    parser = argparse.ArgumentParser(description=\'Regularized inverse scattering\')\n    parser.add_argument(\'--num_epochs\', default=2, help=\'Number of epochs to train\')\n    parser.add_argument(\'--load_model\', default=False, help=\'Load a trained model?\')\n    parser.add_argument(\'--dir_save_images\', default=\'interpolation_images\', help=\'Dir to save the sequence of images\')\n    args = parser.parse_args()\n\n    num_epochs = args.num_epochs\n    load_model = args.load_model\n    dir_save_images = args.dir_save_images\n\n    dir_to_save = get_cache_dir(\'reg_inverse_example\')\n\n    transforms_to_apply = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))  # Normalization for reproducibility issues\n    ])\n\n    mnist_dir = get_dataset_dir(""MNIST"", create=True)\n    dataset = datasets.MNIST(mnist_dir, train=True, download=True, transform=transforms_to_apply)\n    dataloader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=True)\n\n    fixed_dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n    fixed_batch = next(iter(fixed_dataloader))\n    fixed_batch = fixed_batch[0].float().to(device)\n\n    scattering = Scattering(J=2, shape=(28, 28)).to(device)\n\n    scattering_fixed_batch = scattering(fixed_batch).squeeze(1)\n    num_input_channels = scattering_fixed_batch.shape[1]\n    num_hidden_channels = num_input_channels\n\n    generator = Generator(num_input_channels, num_hidden_channels).to(device)\n    generator.train()\n\n    # Either train the network or load a trained model\n    ##################################################\n    if load_model:\n        filename_model = os.path.join(dir_to_save, \'model.pth\')\n        generator.load_state_dict(torch.load(filename_model))\n    else:\n        criterion = torch.nn.L1Loss()\n        optimizer = optim.Adam(generator.parameters())\n\n        for idx_epoch in range(num_epochs):\n            print(\'Training epoch {}\'.format(idx_epoch))\n            for _, current_batch in enumerate(dataloader):\n                generator.zero_grad()\n                batch_images = Variable(current_batch[0]).float().to(device)\n                batch_scattering = scattering(batch_images).squeeze(1)\n                batch_inverse_scattering = generator(batch_scattering)\n                loss = criterion(batch_inverse_scattering, batch_images)\n                loss.backward()\n                optimizer.step()\n\n        print(\'Saving results in {}\'.format(dir_to_save))\n\n        torch.save(generator.state_dict(), os.path.join(dir_to_save, \'model.pth\'))\n\n    generator.eval()\n\n    # We create the batch containing the linear interpolation points in the scattering space\n    ########################################################################################\n    z0 = scattering_fixed_batch.cpu().numpy()[[0]]\n    z1 = scattering_fixed_batch.cpu().numpy()[[1]]\n    batch_z = np.copy(z0)\n    num_samples = 32\n    interval = np.linspace(0, 1, num_samples)\n    for t in interval:\n        if t > 0:\n            zt = (1 - t) * z0 + t * z1\n            batch_z = np.vstack((batch_z, zt))\n\n    z = torch.from_numpy(batch_z).float().to(device)\n    path = generator(z).data.cpu().numpy().squeeze(1)\n    path = (path + 1) / 2  # The pixels are now in [0, 1]\n\n    # We show and store the nonlinear interpolation in the image space\n    ##################################################################\n    dir_path = os.path.join(dir_to_save, dir_save_images)\n\n    if not os.path.exists(dir_path):\n        os.makedirs(dir_path)\n\n    for idx_image in range(num_samples):\n        current_image = np.uint8(path[idx_image] * 255.0)\n        filename = os.path.join(dir_path, \'{}.png\'.format(idx_image))\n        Image.fromarray(current_image).save(filename)\n        plt.imshow(current_image, cmap=\'gray\')\n        plt.axis(\'off\')\n        plt.pause(0.1)\n        plt.draw()\n'"
examples/3d/scattering3d_qm7_torch.py,16,"b'""""""\n3D scattering quantum chemistry regression\n==========================================\n\nDescription:\nThis example trains a classifier combined with a scattering transform to\nregress molecular atomization energies on the QM7 dataset. Here, we use full\ncharges, valence charges and core charges. A linear regression is deployed.\n\nRemarks:\nThe linear regression of the QM7 energies with the given values gives MAE\n2.75, RMSE 4.18 (kcal.mol-1)\n\nReference:\nhttps://arxiv.org/abs/1805.00571\n""""""\n\n###############################################################################\n# Preliminaries\n# -------------\n#\n# First, we import NumPy, PyTorch, and some utility modules.\n\nimport numpy as np\nimport torch\nimport time\nimport os\n\n###############################################################################\n# We will use scikit-learn to construct a linear model, so we import the\n# necessary modules. In addition, we need to compute distance matrices when\n# normalizing our input features, so we import `pdist` from `scipy.spatial`.\n\nfrom sklearn import (linear_model, model_selection, preprocessing,\n                     pipeline)\nfrom scipy.spatial.distance import pdist\n\n######################################################################\n# We then import the necessary functionality from Kymatio. First, we need the\n# PyTorch frontend of the 3D solid harmonic cattering transform.\n\nfrom kymatio.torch import HarmonicScattering3D\n\n###############################################################################\n# The 3D transform doesn\'t compute the zeroth-order coefficients, so we need\n# to import `compute_integrals` to do this manually.\n\nfrom kymatio.scattering3d.backend.torch_backend \\\n    import compute_integrals\n\n###############################################################################\n# To generate the input 3D maps, we need to calculate sums of Gaussians, so we\n# import the function `generate_weighted_sum_of_gaussians`.\n\nfrom kymatio.scattering3d.utils \\\n    import generate_weighted_sum_of_gaussians\n\n###############################################################################\n# Finally, we import the utility functions that let us access the QM7 dataset\n# and the cache directories to store our results.\n\nfrom kymatio.datasets import fetch_qm7\nfrom kymatio.caching import get_cache_dir\n\n###############################################################################\n# Data preparation\n# ----------------\n#\n# Fetch the QM7 database and extract the atomic positions and nuclear charges\n# of each molecule. This dataset contains 7165 organic molecules with up to\n# seven non-hydrogen atoms, whose energies were computed using density\n# functional theory.\n\nqm7 = fetch_qm7(align=True)\npos = qm7[\'positions\']\nfull_charges = qm7[\'charges\']\n\nn_molecules = pos.shape[0]\n\n###############################################################################\n# From the nuclear charges, we compute the number of valence electrons, which\n# we store as the valence charge of that atom.\n\nmask = full_charges <= 2\nvalence_charges = full_charges * mask\n\nmask = np.logical_and(full_charges > 2, full_charges <= 10)\nvalence_charges += (full_charges - 2) * mask\n\nmask = np.logical_and(full_charges > 10, full_charges <= 18)\nvalence_charges += (full_charges - 10) * mask\n\n###############################################################################\n# We then normalize the positions of the atoms. Specifically, the positions\n# are rescaled such that two Gaussians of width `sigma` placed at those\n# positions overlap with amplitude less than `overlapping_precision`.\n\noverlapping_precision = 1e-1\nsigma = 2.0\nmin_dist = np.inf\n\nfor i in range(n_molecules):\n    n_atoms = np.sum(full_charges[i] != 0)\n    pos_i = pos[i, :n_atoms, :]\n    min_dist = min(min_dist, pdist(pos_i).min())\n\ndelta = sigma * np.sqrt(-8 * np.log(overlapping_precision))\npos = pos * delta / min_dist\n\n###############################################################################\n# Scattering Transform\n# --------------------------------\n# Given the rescaled positions and charges, we are now ready to compute the\n# density maps by placing Gaussians at the different positions weighted by the\n# appropriate charge. These are fed into the 3D solid harmonic scattering\n# transform to obtain features that are used to regress the energies. In\n# order to do this, we must first define a grid.\n\nM, N, O = 192, 128, 96\n\ngrid = np.mgrid[-M//2:-M//2+M, -N//2:-N//2+N, -O//2:-O//2+O]\ngrid = np.fft.ifftshift(grid)\n\n###############################################################################\n# We then define the scattering transform using the `HarmonicScattering3D`\n# class.\n\nJ = 2\nL = 3\nintegral_powers = [0.5, 1.0, 2.0, 3.0]\n\nscattering = HarmonicScattering3D(J=J, shape=(M, N, O),\n                                  L=L, sigma_0=sigma,\n                                  integral_powers=integral_powers)\n\n###############################################################################\n# We then check whether a GPU is available, in which case we transfer our\n# scattering object there.\n\nif torch.cuda.is_available():\n    device = \'cuda\'\nelse:\n    device = \'cpu\'\n\nscattering.to(device)\n\n###############################################################################\n# The maps computed for each molecule are quite large, so the computation has\n# to be done by batches. Here we select a small batch size to ensure that we\n# have enough memory when running on the GPU. Dividing the number of molecules\n# by the batch size then gives us the number of batches.\n\nbatch_size = 8\nn_batches = int(np.ceil(n_molecules / batch_size))\n\n###############################################################################\n# We are now ready to compute the scattering transforms. In the following\n# loop, each batch of molecules is transformed into three maps using Gaussians\n# centered at the atomic positions, one for the nuclear charges, one for the\n# valence charges, and one with their difference (called the \xe2\x80\x9ccore\xe2\x80\x9d charges).\n# For each map, we compute its scattering transform up to order two and store\n# the results.\n\norder_0, orders_1_and_2 = [], []\nprint(\'Computing solid harmonic scattering coefficients of \'\n      \'{} molecules from the QM7 database on {}\'.format(\n        n_molecules, {\'cuda\': \'GPU\', \'cpu\': \'CPU\'}[device]))\nprint(\'sigma: {}, L: {}, J: {}, integral powers: {}\'.format(\n        sigma, L, J, integral_powers))\n\nthis_time = None\nlast_time = None\nfor i in range(n_batches):\n    this_time = time.time()\n    if last_time is not None:\n        dt = this_time - last_time\n        print(""Iteration {} ETA: [{:02}:{:02}:{:02}]"".format(\n                    i + 1, int(((n_batches - i - 1) * dt) // 3600),\n                    int((((n_batches - i - 1) * dt) // 60) % 60),\n                    int(((n_batches - i - 1) * dt) % 60)))\n    else:\n        print(""Iteration {} ETA: {}"".format(i + 1, \'-\'))\n    last_time = this_time\n    time.sleep(1)\n\n    # Extract the current batch.\n    start = i * batch_size\n    end = min(start + batch_size, n_molecules)\n\n    pos_batch = pos[start:end]\n    full_batch = full_charges[start:end]\n    val_batch = valence_charges[start:end]\n\n    # Calculate the density map for the nuclear charges and transfer\n    # to PyTorch.\n    full_density_batch = generate_weighted_sum_of_gaussians(grid,\n            pos_batch, full_batch, sigma)\n    full_density_batch = torch.from_numpy(full_density_batch)\n    full_density_batch = full_density_batch.to(device).float()\n\n    # Compute zeroth-order, first-order, and second-order scattering\n    # coefficients of the nuclear charges.\n    full_order_0 = compute_integrals(full_density_batch,\n                                     integral_powers)\n    full_scattering = scattering(full_density_batch)\n\n    # Compute the map for valence charges.\n    val_density_batch = generate_weighted_sum_of_gaussians(grid,\n            pos_batch, val_batch, sigma)\n    val_density_batch = torch.from_numpy(val_density_batch)\n    val_density_batch = val_density_batch.to(device).float()\n\n    # Compute scattering coefficients for the valence charges.\n    val_order_0 = compute_integrals(val_density_batch,\n                                    integral_powers)\n    val_scattering = scattering(val_density_batch)\n\n    # Take the difference between nuclear and valence charges, then\n    # compute the corresponding scattering coefficients.\n    core_density_batch = full_density_batch - val_density_batch\n\n    core_order_0 = compute_integrals(core_density_batch,\n                                     integral_powers)\n    core_scattering = scattering(core_density_batch)\n\n    # Stack the nuclear, valence, and core coefficients into arrays\n    # and append them to the output.\n    batch_order_0 = torch.stack(\n        (full_order_0, val_order_0, core_order_0), dim=-1)\n    batch_orders_1_and_2 = torch.stack(\n        (full_scattering, val_scattering, core_scattering), dim=-1)\n\n    order_0.append(batch_order_0)\n    orders_1_and_2.append(batch_orders_1_and_2)\n\n###############################################################################\n# Concatenate the batch outputs and transfer to NumPy.\n\norder_0 = torch.cat(order_0, dim=0)\norders_1_and_2 = torch.cat(orders_1_and_2, dim=0)\n\norder_0 = order_0.cpu().numpy()\norders_1_and_2 = orders_1_and_2.cpu().numpy()\n\n###############################################################################\n# Regression\n# ----------\n#\n# To use the scattering coefficients as features in a scikit-learn pipeline,\n# these must be of shape `(n_samples, n_features)`, so we reshape our arrays\n# accordingly.\n\norder_0 = order_0.reshape((n_molecules, -1))\norders_1_and_2 = orders_1_and_2.reshape((n_molecules, -1))\n\n###############################################################################\n# Since the above calculation is quite lengthy, we save the results to a cache\n# for future use.\n\nbasename = \'qm7_L_{}_J_{}_sigma_{}_MNO_{}_powers_{}.npy\'.format(\n        L, J, sigma, (M, N, O), integral_powers)\n\ncache_dir = get_cache_dir(""qm7/experiments"")\n\nfilename = os.path.join(cache_dir, \'order_0_\' + basename)\nnp.save(filename, order_0)\n\nfilename = os.path.join(cache_dir, \'orders_1_and_2\' + basename)\nnp.save(filename, orders_1_and_2)\n\n###############################################################################\n# We now concatenate the zeroth-order coefficients with the rest since we want\n# to use all of them as features.\n\nscattering_coef = np.concatenate([order_0, orders_1_and_2], axis=1)\n\n###############################################################################\n# Fetch the target energies from the QM7 dataset.\n\nqm7 = fetch_qm7()\ntarget = qm7[\'energies\']\n\n###############################################################################\n# We evaluate the performance of the regression using five-fold\n# cross-validation. To do so, we first shuffle the molecules, then we store\n# the resulting indices in `cross_val_folds`.\n\nn_folds = 5\n\nP = np.random.permutation(n_molecules).reshape((n_folds, -1))\n\ncross_val_folds = []\n\nfor i_fold in range(n_folds):\n    fold = (np.concatenate(P[np.arange(n_folds) != i_fold], axis=0),\n            P[i_fold])\n    cross_val_folds.append(fold)\n\n###############################################################################\n# Given these folds, we compute the regression error for various settings of\n# the `alpha` parameter, which controls the amount of regularization applied\n# to the regression problem (here in the form of a simple ridge regression, or\n# Tikhonov, regularization). The mean absolute error (MAE) and root mean\n# square error (RMSE) is output for each value of `alpha`.\n\nalphas = 10.0 ** (-np.arange(1, 10))\nfor i, alpha in enumerate(alphas):\n    scaler = preprocessing.StandardScaler()\n    ridge = linear_model.Ridge(alpha=alpha)\n\n    regressor = pipeline.make_pipeline(scaler, ridge)\n\n    target_prediction = model_selection.cross_val_predict(regressor,\n            X=scattering_coef, y=target, cv=cross_val_folds)\n\n    MAE = np.mean(np.abs(target_prediction - target))\n    RMSE = np.sqrt(np.mean((target_prediction - target) ** 2))\n\n    print(\'Ridge regression, alpha: {}, MAE: {}, RMSE: {}\'.format(\n        alpha, MAE, RMSE))\n'"
kymatio/backend/__init__.py,0,b''
kymatio/backend/base_backend.py,0,"b'\n\nclass FFT:\n    def __init__(self, fft, ifft, irfft, type_checks):\n        self.fft = fft\n        self.ifft = ifft\n        self.irfft = irfft\n        self.sanity_checks = type_checks\n\n    def fft_forward(self, x, direction=\'C2C\', inverse=False):\n        """"""Interface with FFT routines for any dimensional signals and any backend signals.\n\n            Example (for Torch)\n            -------\n            x = torch.randn(128, 32, 32, 2)\n            x_fft = fft(x)\n            x_ifft = fft(x, inverse=True)\n\n            Parameters\n            ----------\n            x : input\n                Complex input for the FFT.\n            direction : string\n                \'C2R\' for complex to real, \'C2C\' for complex to complex.\n            inverse : bool\n                True for computing the inverse FFT.\n                NB : If direction is equal to \'C2R\', then an error is raised.\n\n            Raises\n            ------\n            RuntimeError\n                In the event that we are going from complex to real and not doing\n                the inverse FFT or in the event x is not contiguous.\n\n\n            Returns\n            -------\n            output :\n                Result of FFT or IFFT.\n        """"""\n        if direction == \'C2R\':\n            if not inverse:\n                raise RuntimeError(\'C2R mode can only be done with an inverse FFT.\')\n\n        self.sanity_checks(x)\n\n        if direction == \'C2R\':\n            output = self.irfft(x)\n        elif direction == \'C2C\':\n            if inverse:\n                output = self.ifft(x)\n            else:\n                output = self.fft(x)\n\n        return output\n\n    def __call__(self, x, direction=\'C2C\', inverse=False):\n        return self.fft_forward(x, direction=direction, inverse=inverse)\n'"
kymatio/backend/numpy_backend.py,5,"b'import numpy as np\n\ndef input_checks(x):\n    if x is None:\n        raise TypeError(\'The input should be not empty.\')\n\n\ndef modulus(x):\n    """"""\n        This function implements a modulus transform for complex numbers.\n\n        Usage\n        -----\n        x_mod = modulus(x)\n\n        Parameters\n        ---------\n        x: input complex tensor.\n\n        Returns\n        -------\n        output: a real tensor equal to the modulus of x.\n\n    """"""\n    return np.abs(x)\n\n\ndef _is_complex(x):\n    return (x.dtype == np.complex64) or (x.dtype == np.complex128)\n\n\ndef _is_real(x):\n    return (x.dtype == np.float32) or (x.dtype == np.float64)\n\n\ndef cdgmm(A, B, inplace=False):\n    """"""\n        Complex pointwise multiplication between (batched) tensor A and tensor B.\n\n        Parameters\n        ----------\n        A : tensor\n            A is a complex tensor of size (B, C, M, N, 2)\n        B : tensor\n            B is a complex tensor of size (M, N) or real tensor of (M, N)\n        inplace : boolean, optional\n            if set to True, all the operations are performed inplace\n\n        Returns\n        -------\n        C : tensor\n            output tensor of size (B, C, M, N, 2) such that:\n            C[b, c, m, n, :] = A[b, c, m, n, :] * B[m, n, :]\n\n    """"""\n\n    if not _is_complex(A):\n        raise TypeError(\'The first input must be complex.\')\n\n    if A.shape[-len(B.shape):] != B.shape[:]:\n        raise RuntimeError(\'The inputs are not compatible for \'\n                           \'multiplication.\')\n\n    if not _is_complex(B) and not _is_real(B):\n        raise TypeError(\'The second input must be complex or real.\')\n\n    if inplace:\n        return np.multiply(A, B, out=A)\n    else:\n        return A * B\n\n\ndef real(x):\n    """"""Real part of complex tensor\n    Takes the real part of a complex tensor, where the last axis corresponds\n    to the real and imaginary parts.\n    Parameters\n    ----------\n    x : tensor\n        A complex tensor (that is, whose last dimension is equal to 2).\n    Returns\n    -------\n    x_real : tensor\n        The tensor x[..., 0] which is interpreted as the real part of x.\n    """"""\n    return np.real(x)\n'"
kymatio/backend/tensorflow_backend.py,2,"b'import tensorflow as tf\nimport numpy as np\n\n\n\ndef _is_complex(x):\n    return (x.dtype == np.complex64) or (x.dtype == np.complex128)\n\n\ndef _is_real(x):\n    return (x.dtype == np.float32) or (x.dtype == np.float64)\n\n\nclass Modulus():\n    """"""This class implements a modulus transform for complex numbers.\n\n    Parameters\n    ----------\n    x: input complex tensor.\n\n    Returns\n    ----------\n    output: a complex tensor equal to the modulus of x.\n\n    Usage\n    ----------\n    modulus = Modulus()\n    x_mod = modulus(x)\n    """"""\n    def __call__(self, x):\n        norm = tf.abs(x)\n        return tf.cast(norm, tf.complex64)\n\n\ndef real(x):\n    """"""Real part of complex tensor\n    Takes the real part of a complex tensor, where the last axis corresponds\n    to the real and imaginary parts.\n    Parameters\n    ----------\n    x : tensor\n        A complex tensor (that is, whose last dimension is equal to 2).\n    Returns\n    -------\n    x_real : tensor\n        The tensor x[..., 0] which is interpreted as the real part of x.\n    """"""\n    return tf.math.real(x)\n\n\ndef concatenate(arrays, dim):\n    return tf.stack(arrays, axis=dim)\n\n\ndef cdgmm(A, B, inplace=False):\n    """"""\n        Complex pointwise multiplication between (batched) tensor A and tensor B.\n        Parameters\n        ----------\n        A : tensor\n            A is a complex tensor of size (B, C, M, N, 2)\n        B : tensor\n            B is a complex tensor of size (M, N) or real tensor of (M, N)\n        inplace : boolean, optional\n            if set to True, all the operations are performed inplace\n        Returns\n        -------\n        C : tensor\n            output tensor of size (B, C, M, N, 2) such that:\n            C[b, c, m, n, :] = A[b, c, m, n, :] * B[m, n, :]\n    """"""\n\n    if not _is_complex(A):\n        raise TypeError(\'The first input must be complex.\')\n\n    if A.shape[-len(B.shape):] != B.shape[:]:\n        raise RuntimeError(\'The inputs are not compatible for multiplication.\')\n\n    if not _is_complex(B) and not _is_real(B):\n        raise TypeError(\'The second input must be complex or real.\')\n\n    return A * B\n\n\ndef sanity_check(x):\n    if not _is_complex(x):\n        raise TypeError(\'The input should be complex.\')\n\n    if not x.is_contiguous():\n        raise RuntimeError(\'Tensors must be contiguous.\')\n'"
kymatio/backend/torch_backend.py,0,"b'from torch.autograd import Function\nimport torch\n\nBACKEND_NAME = \'torch\'\n\ndef input_checks(x):\n    if x is None:\n        raise TypeError(\'The input should be not empty.\')\n\n    if not x.is_contiguous():\n        raise RuntimeError(\'The input must be contiguous.\')\n\ndef _is_complex(x):\n    return x.shape[-1] == 2\n\ndef _is_real(x):\n    return x.shape[-1] == 1\n\nclass ModulusStable(Function):\n    """"""Stable complex modulus\n\n    This class implements a modulus transform for complex numbers which is\n    stable with respect to very small inputs (z close to 0), avoiding\n    returning nans in all cases.\n\n    Usage\n    -----\n    modulus = ModulusStable.apply  # apply inherited from Function\n    x_mod = modulus(x)\n\n    Parameters\n    ---------\n    x : tensor\n        The complex tensor (i.e., whose last dimension is two) whose modulus\n        we want to compute.\n\n    Returns\n    -------\n    output : tensor\n        A tensor of same size as the input tensor, except for the last\n        dimension, which is removed. This tensor is differentiable with respect\n        to the input in a stable fashion (so gradent of the modulus at zero is\n        zero).\n    """"""\n\n    @staticmethod\n    def forward(ctx, x):\n        """"""Forward pass of the modulus.\n\n        This is a static method which does not require an instantiation of the\n        class.\n\n        Arguments\n        ---------\n        ctx : context object\n            Collected during the forward pass. These are automatically added\n            by PyTorch and should not be touched. They are then used for the\n            backward pass.\n        x : tensor\n            The complex tensor whose modulus is to be computed.\n\n        Returns\n        -------\n        output : tensor\n            This contains the modulus computed along the last axis, with that\n            axis removed.\n        """"""\n        ctx.p = 2\n        ctx.dim = -1\n        ctx.keepdim = False\n\n        output = (x[...,0] * x[...,0] + x[...,1] * x[...,1]).sqrt()\n\n        ctx.save_for_backward(x, output)\n\n        return output\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        """"""Backward pass of the modulus\n\n        This is a static method which does not require an instantiation of the\n        class.\n\n        Arguments\n        ---------\n        ctx : context object\n            Collected during the forward pass. These are automatically added\n            by PyTorch and should not be touched. They are then used for the\n            backward pass.\n        grad_output : tensor\n            The gradient with respect to the output tensor computed at the\n            forward pass.\n\n        Returns\n        -------\n        grad_input : tensor\n            The gradient with respect to the input.\n        """"""\n        x, output = ctx.saved_tensors\n        if ctx.dim is not None and ctx.keepdim is False and x.dim() != 1:\n            grad_output = grad_output.unsqueeze(ctx.dim)\n            output = output.unsqueeze(ctx.dim)\n\n        grad_input = x.mul(grad_output).div(output)\n\n        # Special case at 0 where we return a subgradient containing 0\n        grad_input.masked_fill_(output == 0, 0)\n\n        return grad_input\n\n# shortcut for ModulusStable.apply\nmodulus = ModulusStable.apply\n\nclass Modulus():\n    """"""This class implements a modulus transform for complex numbers.\n\n        Usage\n        -----\n        modulus = Modulus()\n        x_mod = modulus(x)\n\n        Parameters\n        ---------\n        x : tensor\n            Complex torch tensor.\n\n        Returns\n        -------\n        output : tensor\n            A tensor with the same dimensions as x, such that output[..., 0]\n            contains the complex modulus of x, while output[..., 1] = 0.\n    """"""\n    def __call__(self, x):\n        type_checks(x)\n\n        norm = torch.zeros_like(x)\n        norm[..., 0] = modulus(x)\n        return norm\n\ndef type_checks(x):\n    if not _is_complex(x):\n        raise TypeError(\'The input should be complex (i.e. last dimension is 2).\')\n\n    if not x.is_contiguous():\n        raise RuntimeError(\'Tensors must be contiguous.\')\n\ndef cdgmm(A, B, inplace=False):\n    """"""Complex pointwise multiplication.\n\n        Complex pointwise multiplication between (batched) tensor A and tensor B.\n\n        Parameters\n        ----------\n        A : tensor\n            A is a complex tensor of size (B, C, M, N, 2).\n        B : tensor\n            B is a complex tensor of size (M, N, 2) or real tensor of (M, N, 1).\n        inplace : boolean, optional\n            If set to True, all the operations are performed in place.\n\n        Raises\n        ------\n        RuntimeError\n            In the event that the filter B is not a 3-tensor with a last\n            dimension of size 1 or 2, or A and B are not compatible for\n            multiplication.\n\n        TypeError\n            In the event that A is not complex, or B does not have a final\n            dimension of 1 or 2, or A and B are not of the same dtype, or if\n            A and B are not on the same device.\n\n        Returns\n        -------\n        C : tensor\n            Output tensor of size (B, C, M, N, 2) such that:\n            C[b, c, m, n, :] = A[b, c, m, n, :] * B[m, n, :].\n\n    """"""\n    if not _is_real(B):\n        type_checks(B)\n    else:\n        if not B.is_contiguous():\n            raise RuntimeError(\'Tensors must be contiguous.\')\n\n    type_checks(A)\n\n    if A.shape[-len(B.shape):-1] != B.shape[:-1]:\n        raise RuntimeError(\'The filters are not compatible for multiplication.\')\n\n    if A.dtype is not B.dtype:\n        raise TypeError(\'Input and filter must be of the same dtype.\')\n\n    if B.device.type == \'cuda\':\n        if A.device.type == \'cuda\':\n            if A.device.index != B.device.index:\n                raise TypeError(\'Input and filter must be on the same GPU.\')\n        else:\n            raise TypeError(\'Input must be on GPU.\')\n\n    if B.device.type == \'cpu\':\n        if A.device.type == \'cuda\':\n            raise TypeError(\'Input must be on CPU.\')\n\n    if _is_real(B):\n        if inplace:\n            return A.mul_(B)\n        else:\n            return A * B\n    else:\n        C = A.new(A.shape)\n\n        A_r = A[..., 0].view(-1, B.nelement() // 2)\n        A_i = A[..., 1].view(-1, B.nelement() // 2)\n\n        B_r = B[..., 0].view(-1).unsqueeze(0).expand_as(A_r)\n        B_i = B[..., 1].view(-1).unsqueeze(0).expand_as(A_i)\n\n        C[..., 0].view(-1, B.nelement() // 2)[:] = A_r * B_r - A_i * B_i\n        C[..., 1].view(-1, B.nelement() // 2)[:] = A_r * B_i + A_i * B_r\n\n        return C if not inplace else A.copy_(C)\n\ndef concatenate(arrays, dim):\n    return torch.stack(arrays, dim=dim)\n\n\ndef real(x):\n    """"""Real part of complex tensor\n\n    Takes the real part of a complex tensor, where the last axis corresponds\n    to the real and imaginary parts.\n\n    Parameters\n    ----------\n    x : tensor\n        A complex tensor (that is, whose last dimension is equal to 2).\n\n    Returns\n    -------\n    x_real : tensor\n        The tensor x[..., 0] which is interpreted as the real part of x.\n    """"""\n    return x[..., 0]\n'"
kymatio/backend/torch_skcuda_backend.py,0,"b'import torch\nfrom skcuda import cublas\n\n\nBACKEND_NAME = \'torch_skcuda\'\n\n\ndef _is_complex(x):\n    return x.shape[-1] == 2\n\n\ndef _is_real(x):\n    return x.shape[-1] == 1\n\n\ndef cdgmm(A, B, inplace=False):\n    """"""Complex pointwise multiplication.\n\n        Complex pointwise multiplication between (batched) tensor A and tensor\n        B.\n\n        Parameters\n        ----------\n        A : tensor\n            A is a complex tensor of size (B, C, M, N, 2).\n        B : tensor\n            B is a complex tensor of size (M, N, 2) or real tensor of (M, N,\n            1).\n        inplace : boolean, optional\n            If set to True, all the operations are performed in place.\n\n        Raises\n        ------\n        RuntimeError\n            In the event that the filter B is not a 3-tensor with a last\n            dimension of size 1 or 2, or A and B are not compatible for\n            multiplication, or if A or B are not contiguous.\n        TypeError\n            In the event that A is not complex, or B does not have a final\n            dimension of 1 or 2, or A and B are not of the same dtype, or\n            if A or B are not cuda tensors, or if A and B are not on the same\n            device.\n\n        Returns\n        -------\n        C : tensor\n            Output tensor of size (B, C, M, N, 2) such that:\n            C[b, c, m, n, :] = A[b, c, m, n, :] * B[m, n, :].\n\n    """"""\n    if not _is_complex(A):\n        raise TypeError(\'The input should be complex (i.e. last dimension is 2).\')\n\n    if not _is_complex(B) and not _is_real(B):\n        raise TypeError(\'The filter should be complex or real, indicated by a \'\n                        \'last dimension of size 2 or 1, respectively.\')\n\n    if A.shape[-len(B.shape):-1] != B.shape[:-1]:\n        raise RuntimeError(\'The filters are not compatible for multiplication.\')\n\n    if A.dtype is not B.dtype:\n        raise TypeError(\'Input and filter must be of the same dtype.\')\n\n    if not A.is_cuda or not B.is_cuda:\n        raise TypeError(\'Input and filter must be CUDA tensors.\')\n\n    if A.device.index != B.device.index:\n        raise TypeError(\'Input and filter must be on the same GPU.\')\n\n    if _is_real(B):\n        if inplace:\n            return A.mul_(B)\n        else:\n            return A * B\n    else:\n        if not A.is_contiguous() or not B.is_contiguous():\n            raise RuntimeError(\'Tensors must be contiguous.\')\n\n        C = A.new(A.shape) if not inplace else A\n        m, n = B.nelement() // 2, A.nelement() // B.nelement()\n        lda = m\n        ldc = m\n        incx = 1\n        handle = torch.cuda.current_blas_handle()\n        stream = torch.cuda.current_stream()._as_parameter_\n        cublas.cublasSetStream(handle, stream)\n        cublas.cublasCdgmm(handle, \'l\', m, n, A.data_ptr(), lda, B.data_ptr(), incx, C.data_ptr(), ldc)\n        return C\n'"
kymatio/frontend/__init__.py,0,b''
kymatio/frontend/base_frontend.py,0,"b'import importlib\n\n\nclass ScatteringBase():\n    def __init__(self):\n        super(ScatteringBase, self).__init__()\n\n    def build(self):\n        """""" Defines elementary routines.\n\n        This function should always call and create the filters via\n        self.create_filters() defined below. For instance, via:\n        self.filters = self.create_filters() """"""\n        raise NotImplementedError\n\n    def _instantiate_backend(self, import_string):\n        """""" This function should instantiate the backend to be used if not already\n        specified""""""\n\n        # Either the user entered a string, in which case we load the corresponding backend.\n        if isinstance(self.backend, str):\n            if self.backend.startswith(self.frontend_name):\n                try:\n                    self.backend = importlib.import_module(import_string + self.backend + ""_backend"", \'backend\').backend\n                except ImportError:\n                    raise ImportError(\'Backend \' + self.backend + \' not found!\')\n            else:\n                raise ImportError(\'The backend \' + self.backend + \' can not be called from the frontend \' +\n                                   self.frontend_name + \'.\')\n        # Either the user passed a backend object, in which case we perform a compatibility check.\n        else:\n            if not self.backend.name.startswith(self.frontend_name):\n                raise ImportError(\'The backend \' + self.backend.name + \' is not supported by the frontend \' +\n                                   self.frontend_name + \'.\')\n\n    def create_filters(self):\n        """""" This function should run a filterbank function that\n        will create the filters as numpy array, and then, it should\n        save those arrays. """"""\n        raise NotImplementedError\n'"
kymatio/frontend/entry.py,0,"b'import logging\nimport warnings\nimport importlib\n\n\nclass ScatteringEntry(object):\n    def __init__(self, *args, **kwargs):\n        self.name = kwargs[\'name\']\n        self.class_name = kwargs[\'class_name\']\n        kwargs.pop(\'name\')\n        kwargs.pop(\'class_name\')\n\n        frontend_suffixes = {\'torch\' : \'Torch\',\n                             \'numpy\' : \'NumPy\',\n                             \'tensorflow\' : \'TensorFlow\',\n                             \'keras\': \'Keras\',\n                             \'sklearn\': \'Transformer\'}\n\n        if \'frontend\' not in kwargs:\n            warnings.warn(""Torch frontend is currently the default, but NumPy will become the default in the next""\n                          "" version."", DeprecationWarning)\n            frontend = \'torch\'\n        else:\n            frontend = kwargs[\'frontend\'].lower()\n            kwargs.pop(\'frontend\')\n\n        frontends = list(frontend_suffixes.keys())\n\n        if frontend not in frontends:\n            raise RuntimeError(\'The frontend \\\'%s\\"" is not valid. Must be \'\n                               \'one of \\\'%s\\\', or \\\'%s\\\'.\' %\n                               (frontend, \'\\\', \\\'\'.join(frontends[:-1]),\n                                frontends[-1]))\n\n        try:\n            module = importlib.import_module(\'kymatio.\' + self.class_name + \'.frontend.\' + frontend + \'_frontend\')\n\n            # Create frontend-specific class name by inserting frontend name\n            # after `Scattering`.\n            frontend = frontend_suffixes[frontend]\n\n            class_name = self.__class__.__name__\n\n            base_name = class_name[:-len(\'Entry*D\')]\n            dim_suffix = class_name[-len(\'*D\'):]\n\n            class_name = base_name + frontend + dim_suffix\n\n            self.__class__ = getattr(module, class_name)\n            self.__init__(*args, **kwargs)\n        except Exception as e:\n            raise e from RuntimeError(\'\\nThe frontend \\\'\' + frontend + \'\\\' could not be correctly imported.\')\n\n        logging.info(\'The \' + self.name + \' frontend \' + frontend + \' was imported.\')\n\n\n__all__ = [\'ScatteringEntry\']\n'"
kymatio/frontend/keras_frontend.py,1,"b'from tensorflow.keras.layers import Layer\n\n\nclass ScatteringKeras(Layer):\n    def __init__(self):\n        Layer.__init__(self)\n        self.frontend_name = \'keras\'\n\n    def build(self, input_shape):\n        self.shape = input_shape\n        Layer.build(self, input_shape)\n\n    def scattering(self, x):\n        return self.S.scattering(x)\n\n    def call(self, x):\n        return self.scattering(x)\n\n    _doc_array = \'tf.Tensor\'\n    _doc_array_n = \'\'\n\n    _doc_alias_name = \'call\'\n\n    _doc_alias_call = \'\'\n\n    _doc_frontend_paragraph = \\\n        """"""\n        This class inherits from `tf.keras.layers.Layer`. As a result, it has\n        all the same capabilities as a standard Keras `Layer`.\n        """"""\n\n    _doc_sample = \'np.random.randn({shape})\'\n\n    _doc_has_shape = False\n\n    _doc_has_out_type = False\n'"
kymatio/frontend/numpy_frontend.py,2,"b'from ..backend.numpy_backend import input_checks\n\nclass ScatteringNumPy:\n    def __init__(self):\n        self.frontend_name = \'numpy\'\n\n    def scattering(self, x):\n        """""" This function should compute the scattering transform.""""""\n        raise NotImplementedError\n\n    def __call__(self, x):\n        """"""This method is an alias for `scattering`.""""""\n\n        input_checks(x)\n\n        return self.scattering(x)\n\n    _doc_array = \'np.ndarray\'\n    _doc_array_n = \'n\'\n\n    _doc_alias_name = \'__call__\'\n\n    _doc_alias_call = \'\'\n\n    _doc_frontend_paragraph = \'\'\n\n    _doc_sample = \'np.random.randn({shape})\'\n\n    _doc_has_shape = True\n\n    _doc_has_out_type = True\n'"
kymatio/frontend/sklearn_frontend.py,2,"b'from sklearn.base import BaseEstimator, TransformerMixin\n\n\nclass ScatteringTransformerMixin(BaseEstimator, TransformerMixin):\n    def fit(self, x=None, y=None):\n        # No fitting necessary.\n        return self\n\n    def predict(self, x):\n        n_samples = x.shape[0]\n        x = x.reshape((-1,) + self.shape)\n        Sx = self.scattering(x)\n        Sx = Sx.reshape(n_samples, -1)\n\n        return Sx\n\n    transform = predict\n\n    _doc_array = \'np.ndarray\'\n    _doc_array_n = \'n\'\n\n    _doc_alias_name = \'predict\'\n\n    _doc_alias_call = \'.predict\'\n\n    _doc_frontend_paragraph = \\\n        """"""\n        This class inherits from `BaseEstimator` and `TransformerMixin` in\n        `sklearn.base`. As a result, it supports calculating the scattering\n        transform by calling the `predict` and `transform` methods. By\n        extension, it can be included as part of a scikit-learn `Pipeline`.\n        """"""\n\n    _doc_sample = \'np.random.randn(np.prod({shape}))\'\n\n    _doc_has_shape = True\n\n    _doc_has_out_type = False\n'"
kymatio/frontend/tensorflow_frontend.py,1,"b'import tensorflow as tf\n\nclass ScatteringTensorFlow(tf.Module):\n    def __init__(self, name):\n        super(ScatteringTensorFlow, self).__init__(name=name)\n        self.frontend_name = \'tensorflow\'\n\n    def scattering(self, x):\n        """""" This function should call the functional scattering.""""""\n        raise NotImplementedError\n\n    @tf.Module.with_name_scope\n    def __call__(self, x):\n        """"""This method is an alias for `scattering`.""""""\n        return self.scattering(x)\n\n    _doc_array = \'tf.Tensor\'\n    _doc_array_n = \'\'\n\n    _doc_alias_name = \'__call__\'\n\n    _doc_alias_call = \'\'\n\n    _doc_frontend_paragraph = \\\n        """"""\n        This class inherits from `tf.Module`. As a result, it has all the\n        same capabilities as a standard TensorFlow `Module`.\n        """"""\n\n    _doc_sample = \'np.random.randn({shape})\'\n\n    _doc_has_shape = True\n\n    _doc_has_out_type = True\n'"
kymatio/frontend/torch_frontend.py,0,"b'import torch.nn as nn\nfrom ..backend.torch_backend import input_checks\n\nclass ScatteringTorch(nn.Module):\n    def __init__(self):\n        super(ScatteringTorch, self).__init__()\n        self.frontend_name = \'torch\'\n\n    def register_filters(self):\n        """""" This function should be called after filters are generated,\n        saving those arrays as module buffers. """"""\n        raise NotImplementedError\n\n    def scattering(self, x):\n        """""" This function should compute the scattering transform.""""""\n        raise NotImplementedError\n\n    def forward(self, x):\n        """"""This method is an alias for `scattering`.""""""\n\n        input_checks(x)\n\n        return self.scattering(x)\n\n    _doc_array = \'torch.Tensor\'\n    _doc_array_n = \'\'\n\n    _doc_alias_name = \'forward\'\n\n    _doc_alias_call = \'.forward\'\n\n    _doc_frontend_paragraph = \\\n        """"""\n        This class inherits from `torch.nn.Module`. As a result, it has all\n        the same capabilities, including transferring the object to the GPU\n        using the `cuda` or `to` methods. This object would then take GPU\n        tensors as input and output the scattering coefficients of those\n        tensors.\n        """"""\n\n    _doc_sample = \'torch.randn({shape})\'\n\n    _doc_has_shape = True\n\n    _doc_has_out_type = True\n'"
kymatio/scattering1d/__init__.py,0,"b""from .frontend.entry import ScatteringEntry1D\n\n__all__ = ['ScatteringEntry1D']\n"""
kymatio/scattering1d/filter_bank.py,17,"b'import numpy as np\nimport math\nimport warnings\nfrom scipy.fftpack import ifft\n\ndef adaptive_choice_P(sigma, eps=1e-7):\n    """"""\n    Adaptive choice of the value of the number of periods in the frequency\n    domain used to compute the Fourier transform of a Morlet wavelet.\n\n    This function considers a Morlet wavelet defined as the sum\n    of\n    * a Gabor term hat psi(omega) = hat g_{sigma}(omega - xi)\n    where 0 < xi < 1 is some frequency and g_{sigma} is\n    the Gaussian window defined in Fourier by\n    hat g_{sigma}(omega) = e^{-omega^2/(2 sigma^2)}\n    * a low pass term \\\\hat \\\\phi which is proportional to \\\\hat g_{\\\\sigma}.\n\n    If \\\\sigma is too large, then these formula will lead to discontinuities\n    in the frequency interval [0, 1] (which is the interval used by numpy.fft).\n    We therefore choose a larger integer P >= 1 such that at the boundaries\n    of the Fourier transform of both filters on the interval [1-P, P], the\n    magnitude of the entries is below the required machine precision.\n    Mathematically, this means we would need P to satisfy the relations:\n\n    |\\\\hat \\\\psi(P)| <= eps and |\\\\hat \\\\phi(1-P)| <= eps\n\n    Since 0 <= xi <= 1, the latter implies the former. Hence the formula which\n    is easily derived using the explicit formula for g_{\\\\sigma} in Fourier.\n\n    Parameters\n    ----------\n    sigma: float\n        Positive number controlling the bandwidth of the filters\n    eps : float, optional\n        Positive number containing required precision. Defaults to 1e-7\n\n    Returns\n    -------\n    P : int\n        integer controlling the number of periods used to ensure the\n        periodicity of the final Morlet filter in the frequency interval\n        [0, 1[. The value of P will lead to the use of the frequency\n        interval [1-P, P[, so that there are 2*P - 1 periods.\n    """"""\n    val = math.sqrt(-2 * (sigma**2) * math.log(eps))\n    P = int(math.ceil(val + 1))\n    return P\n\n\ndef periodize_filter_fourier(h_f, nperiods=1):\n    """"""\n    Computes a periodization of a filter provided in the Fourier domain.\n\n    Parameters\n    ----------\n    h_f : array_like\n        complex numpy array of shape (N*n_periods,)\n    n_periods: int, optional\n        Number of periods which should be used to periodize\n\n    Returns\n    -------\n    v_f : array_like\n        complex numpy array of size (N,), which is a periodization of\n        h_f as described in the formula:\n        v_f[k] = sum_{i=0}^{n_periods - 1} h_f[i * N + k]\n    """"""\n    N = h_f.shape[0] // nperiods\n    v_f = h_f.reshape(nperiods, N).mean(axis=0)\n    return v_f\n\n\ndef morlet_1d(N, xi, sigma, normalize=\'l1\', P_max=5, eps=1e-7):\n    """"""\n    Computes the Fourier transform of a Morlet filter.\n\n    A Morlet filter is the sum of a Gabor filter and a low-pass filter\n    to ensure that the sum has exactly zero mean in the temporal domain.\n    It is defined by the following formula in time:\n    psi(t) = g_{sigma}(t) (e^{i xi t} - beta)\n    where g_{sigma} is a Gaussian envelope, xi is a frequency and beta is\n    the cancelling parameter.\n\n    Parameters\n    ----------\n    N : int\n        size of the temporal support\n    xi : float\n        central frequency (in [0, 1])\n    sigma : float\n        bandwidth parameter\n    normalize : string, optional\n        normalization types for the filters. Defaults to \'l1\'.\n        Supported normalizations are \'l1\' and \'l2\' (understood in time domain).\n    P_max: int, optional\n        integer controlling the maximal number of periods to use to ensure\n        the periodicity of the Fourier transform. (At most 2*P_max - 1 periods\n        are used, to ensure an equal distribution around 0.5). Defaults to 5\n        Should be >= 1\n    eps : float\n        required machine precision (to choose the adequate P)\n\n    Returns\n    -------\n    morlet_f : array_like\n        numpy array of size (N,) containing the Fourier transform of the Morlet\n        filter at the frequencies given by np.fft.fftfreq(N).\n    """"""\n    if type(P_max) != int:\n        raise ValueError(\'P_max should be an int, got {}\'.format(type(P_max)))\n    if P_max < 1:\n        raise ValueError(\'P_max should be non-negative, got {}\'.format(P_max))\n    # Find the adequate value of P\n    P = min(adaptive_choice_P(sigma, eps=eps), P_max)\n    assert P >= 1\n    # Define the frequencies over [1-P, P[\n    freqs = np.arange((1 - P) * N, P * N, dtype=float) / float(N)\n    if P == 1:\n        # in this case, make sure that there is continuity around 0\n        # by using the interval [-0.5, 0.5]\n        freqs_low = np.fft.fftfreq(N)\n    elif P > 1:\n        freqs_low = freqs\n    # define the gabor at freq xi and the low-pass, both of width sigma\n    gabor_f = np.exp(-(freqs - xi)**2 / (2 * sigma**2))\n    low_pass_f = np.exp(-(freqs_low**2) / (2 * sigma**2))\n    # discretize in signal <=> periodize in Fourier\n    gabor_f = periodize_filter_fourier(gabor_f, nperiods=2 * P - 1)\n    low_pass_f = periodize_filter_fourier(low_pass_f, nperiods=2 * P - 1)\n    # find the summation factor to ensure that morlet_f[0] = 0.\n    kappa = gabor_f[0] / low_pass_f[0]\n    morlet_f = gabor_f - kappa * low_pass_f\n    # normalize the Morlet if necessary\n    morlet_f *= get_normalizing_factor(morlet_f, normalize=normalize)\n    return morlet_f\n\n\ndef get_normalizing_factor(h_f, normalize=\'l1\'):\n    """"""\n    Computes the desired normalization factor for a filter defined in Fourier.\n\n    Parameters\n    ----------\n    h_f : array_like\n        numpy vector containing the Fourier transform of a filter\n    normalized : string, optional\n        desired normalization type, either \'l1\' or \'l2\'. Defaults to \'l1\'.\n\n    Returns\n    -------\n    norm_factor : float\n        such that h_f * norm_factor is the adequately normalized vector.\n    """"""\n    h_real = ifft(h_f)\n    if np.abs(h_real).sum() < 1e-7:\n        raise ValueError(\'Zero division error is very likely to occur, \' +\n                         \'aborting computations now.\')\n    if normalize == \'l1\':\n        norm_factor = 1. / (np.abs(h_real).sum())\n    elif normalize == \'l2\':\n        norm_factor = 1. / np.sqrt((np.abs(h_real)**2).sum())\n    else:\n        raise ValueError(""Supported normalizations only include \'l1\' and \'l2\'"")\n    return norm_factor\n\n\ndef gauss_1d(N, sigma, normalize=\'l1\', P_max=5, eps=1e-7):\n    """"""\n    Computes the Fourier transform of a low pass gaussian window.\n\n    \\\\hat g_{\\\\sigma}(\\\\omega) = e^{-\\\\omega^2 / 2 \\\\sigma^2}\n\n    Parameters\n    ----------\n    N : int\n        size of the temporal support\n    sigma : float\n        bandwidth parameter\n    normalize : string, optional\n        normalization types for the filters. Defaults to \'l1\'\n        Supported normalizations are \'l1\' and \'l2\' (understood in time domain).\n    P_max : int, optional\n        integer controlling the maximal number of periods to use to ensure\n        the periodicity of the Fourier transform. (At most 2*P_max - 1 periods\n        are used, to ensure an equal distribution around 0.5). Defaults to 5\n        Should be >= 1\n    eps : float, optional\n        required machine precision (to choose the adequate P)\n\n    Returns\n    -------\n    g_f : array_like\n        numpy array of size (N,) containing the Fourier transform of the\n        filter (with the frequencies in the np.fft.fftfreq convention).\n    """"""\n    # Find the adequate value of P\n    if type(P_max) != int:\n        raise ValueError(\'P_max should be an int, got {}\'.format(type(P_max)))\n    if P_max < 1:\n        raise ValueError(\'P_max should be non-negative, got {}\'.format(P_max))\n    P = min(adaptive_choice_P(sigma, eps=eps), P_max)\n    assert P >= 1\n    # switch cases\n    if P == 1:\n        freqs_low = np.fft.fftfreq(N)\n    elif P > 1:\n        freqs_low = np.arange((1 - P) * N, P * N, dtype=float) / float(N)\n    # define the low pass\n    g_f = np.exp(-freqs_low**2 / (2 * sigma**2))\n    # periodize it\n    g_f = periodize_filter_fourier(g_f, nperiods=2 * P - 1)\n    # normalize the signal\n    g_f *= get_normalizing_factor(g_f, normalize=normalize)\n    # return the Fourier transform\n    return g_f\n\n\ndef compute_sigma_psi(xi, Q, r=math.sqrt(0.5)):\n    """"""\n    Computes the frequential width sigma for a Morlet filter of frequency xi\n    belonging to a family with Q wavelets.\n\n    The frequential width is adapted so that the intersection of the\n    frequency responses of the next filter occurs at a r-bandwidth specified\n    by r, to ensure a correct coverage of the whole frequency axis.\n\n    Parameters\n    ----------\n    xi : float\n        frequency of the filter in [0, 1]\n    Q : int\n        number of filters per octave, Q is an integer >= 1\n    r : float, optional\n        Positive parameter defining the bandwidth to use.\n        Should be < 1. We recommend keeping the default value.\n        The larger r, the larger the filters in frequency domain.\n\n    Returns\n    -------\n    sigma : float\n        frequential width of the Morlet wavelet.\n\n    Refs\n    ----\n    Convolutional operators in the time-frequency domain, V. Lostanlen,\n    PhD Thesis, 2017\n    https://tel.archives-ouvertes.fr/tel-01559667\n    """"""\n    factor = 1. / math.pow(2, 1. / Q)\n    term1 = (1 - factor) / (1 + factor)\n    term2 = 1. / math.sqrt(2 * math.log(1. / r))\n    return xi * term1 * term2\n\n\ndef compute_temporal_support(h_f, criterion_amplitude=1e-3):\n    """"""\n    Computes the (half) temporal support of a family of centered,\n    symmetric filters h provided in the Fourier domain\n\n    This function computes the support T which is the smallest integer\n    such that for all signals x and all filters h,\n\n    \\\\| x \\\\conv h - x \\\\conv h_{[-T, T]} \\\\|_{\\\\infty} \\\\leq \\\\epsilon\n        \\\\| x \\\\|_{\\\\infty}  (1)\n\n    where 0<\\\\epsilon<1 is an acceptable error, and h_{[-T, T]} denotes the\n    filter h whose support is restricted in the interval [-T, T]\n\n    The resulting value T used to pad the signals to avoid boundary effects\n    and numerical errors.\n\n    If the support is too small, no such T might exist.\n    In this case, T is defined as the half of the support of h, and a\n    UserWarning is raised.\n\n    Parameters\n    ----------\n    h_f : array_like\n        a numpy array of size batch x time, where each row contains the\n        Fourier transform of a filter which is centered and whose absolute\n        value is symmetric\n    criterion_amplitude : float, optional\n        value \\\\epsilon controlling the numerical\n        error. The larger criterion_amplitude, the smaller the temporal\n        support and the larger the numerical error. Defaults to 1e-3\n\n    Returns\n    -------\n    t_max : int\n        temporal support which ensures (1) for all rows of h_f\n\n    """"""\n    h = ifft(h_f, axis=1)\n    half_support = h.shape[1] // 2\n    # compute ||h - h_[-T, T]||_1\n    l1_residual = np.fliplr(\n        np.cumsum(np.fliplr(np.abs(h)[:, :half_support]), axis=1))\n    # find the first point above criterion_amplitude\n    if np.any(np.max(l1_residual, axis=0) <= criterion_amplitude):\n        # if it is possible\n        T = np.min(\n            np.where(np.max(l1_residual, axis=0) <= criterion_amplitude)[0])\\\n            + 1\n    else:\n        # if there is none:\n        T = half_support\n        # Raise a warning to say that there will be border effects\n        warnings.warn(\'Signal support is too small to avoid border effects\')\n    return T\n\n\ndef get_max_dyadic_subsampling(xi, sigma, alpha=5.):\n    """"""\n    Computes the maximal dyadic subsampling which is possible for a Gabor\n    filter of frequency xi and width sigma\n\n    Finds the maximal integer j such that:\n    omega_0 < 2^{-(j + 1)}\n    where omega_0 is the boundary of the filter, defined as\n    omega_0 = xi + alpha * sigma\n\n    This ensures that the filter can be subsampled by a factor 2^j without\n    aliasing.\n\n    We use the same formula for Gabor and Morlet filters.\n\n    Parameters\n    ----------\n    xi : float\n        frequency of the filter in [0, 1]\n    sigma : float\n        frequential width of the filter\n    alpha : float, optional\n        parameter controlling the error done in the aliasing.\n        The larger alpha, the smaller the error. Defaults to 5.\n\n    Returns\n    -------\n    j : int\n        integer such that 2^j is the maximal subsampling accepted by the\n        Gabor filter without aliasing.\n    """"""\n    upper_bound = min(xi + alpha * sigma, 0.5)\n    j = math.floor(-math.log2(upper_bound)) - 1\n    j = int(j)\n    return j\n\n\ndef move_one_dyadic_step(cv, Q, alpha=5.):\n    """"""\n    Computes the parameters of the next wavelet on the low frequency side,\n    based on the parameters of the current wavelet.\n\n    This function is used in the loop defining all the filters, starting\n    at the wavelet frequency and then going to the low frequencies by\n    dyadic steps. This makes the loop in compute_params_filterbank much\n    simpler to read.\n\n    The steps are defined as:\n    xi_{n+1} = 2^{-1/Q} xi_n\n    sigma_{n+1} = 2^{-1/Q} sigma_n\n\n    Parameters\n    ----------\n    cv : dictionary\n        stands for current_value. Is a dictionary with keys:\n        *\'key\': a tuple (j, n) where n is a counter and j is the maximal\n            dyadic subsampling accepted by this wavelet.\n        *\'xi\': central frequency of the wavelet\n        *\'sigma\': width of the wavelet\n    Q : int\n        number of wavelets per octave. Controls the relationship between\n        the frequency and width of the current wavelet and the next wavelet.\n    alpha : float, optional\n        tolerance parameter for the aliasing. The larger alpha,\n        the more conservative the algorithm is. Defaults to 5.\n\n    Returns\n    -------\n    new_cv : dictionary\n        a dictionary with the same keys as the ones listed for cv,\n        whose values are updated\n    """"""\n    factor = 1. / math.pow(2., 1. / Q)\n    n = cv[\'key\']\n    new_cv = {\'xi\': cv[\'xi\'] * factor, \'sigma\': cv[\'sigma\'] * factor}\n    # compute the new j\n    new_cv[\'j\'] = get_max_dyadic_subsampling(new_cv[\'xi\'], new_cv[\'sigma\'], alpha=alpha)\n    new_cv[\'key\'] = n + 1\n    return new_cv\n\n\ndef compute_xi_max(Q):\n    """"""\n    Computes the maximal xi to use for the Morlet family, depending on Q.\n\n    Parameters\n    ----------\n    Q : int\n        number of wavelets per octave (integer >= 1)\n\n    Returns\n    -------\n    xi_max : float\n        largest frequency of the wavelet frame.\n    """"""\n    xi_max = max(1. / (1. + math.pow(2., 3. / Q)), 0.35)\n    return xi_max\n\n\ndef compute_params_filterbank(sigma_low, Q, r_psi=math.sqrt(0.5), alpha=5.):\n    """"""\n    Computes the parameters of a Morlet wavelet filterbank.\n\n    This family is defined by constant ratios between the frequencies and\n    width of adjacent filters, up to a minimum frequency where the frequencies\n    are translated.\n    This ensures that the low-pass filter has the largest temporal support\n    among all filters, while preserving the coverage of the whole frequency\n    axis.\n\n    The keys of the dictionaries are tuples of integers (j, n) where n is a\n    counter (starting at 0 for the highest frequency filter) and j is the\n    maximal dyadic subsampling accepted by this filter.\n\n    Parameters\n    ----------\n    sigma_low : float\n        frequential width of the low-pass filter. This acts as a\n        lower-bound on the frequential widths of the band-pass filters,\n        so as to ensure that the low-pass filter has the largest temporal\n        support among all filters.\n    Q : int\n        number of wavelets per octave.\n    r_psi : float, optional\n        Should be >0 and <1. Controls the redundancy of the filters\n        (the larger r_psi, the larger the overlap between adjacent wavelets).\n        Defaults to sqrt(0.5).\n    alpha : float, optional\n        tolerance factor for the aliasing after subsampling.\n        The larger alpha, the more conservative the value of maximal\n        subsampling is. Defaults to 5.\n\n    Returns\n    -------\n    xi : dictionary\n        dictionary containing the central frequencies of the wavelets.\n    sigma : dictionary\n        dictionary containing the frequential widths of the wavelets.\n\n    Refs\n    ----\n    Convolutional operators in the time-frequency domain, 2.1.3, V. Lostanlen,\n    PhD Thesis, 2017\n    https://tel.archives-ouvertes.fr/tel-01559667\n    """"""\n    xi_max = compute_xi_max(Q)\n    sigma_max = compute_sigma_psi(xi_max, Q, r=r_psi)\n\n    xi = []\n    sigma = []\n    j = []\n\n    if sigma_max <= sigma_low:\n        # in this exceptional case, we will not go through the loop, so\n        # we directly assign\n        last_xi = sigma_max\n    else:\n        # fill all the dyadic wavelets as long as possible\n        current = {\'key\': 0, \'j\': 0, \'xi\': xi_max, \'sigma\': sigma_max}\n        while current[\'sigma\'] > sigma_low:  # while we can attribute something\n            xi.append(current[\'xi\'])\n            sigma.append(current[\'sigma\'])\n            j.append(current[\'j\'])\n            current = move_one_dyadic_step(current, Q, alpha=alpha)\n        # get the last key\n        last_xi = xi[-1]\n    # fill num_interm wavelets between last_xi and 0, both excluded\n    num_intermediate = Q - 1\n    for q in range(1, num_intermediate + 1):\n        factor = (num_intermediate + 1. - q) / (num_intermediate + 1.)\n        new_xi = factor * last_xi\n        new_sigma = sigma_low\n        xi.append(new_xi)\n        sigma.append(new_sigma)\n        j.append(get_max_dyadic_subsampling(new_xi, new_sigma, alpha=alpha))\n    # return results\n    return xi, sigma, j\n\n\ndef calibrate_scattering_filters(J, Q, r_psi=math.sqrt(0.5), sigma0=0.1,\n                                 alpha=5.):\n    """"""\n    Calibrates the parameters of the filters used at the 1st and 2nd orders\n    of the scattering transform.\n\n    These filterbanks share the same low-pass filterbank, but use a\n    different Q: Q_1 = Q and Q_2 = 1.\n\n    The dictionaries for the band-pass filters have keys which are 2-tuples\n    of the type (j, n), where n is an integer >=0 counting the filters (for\n    identification purposes) and j is an integer >= 0 denoting the maximal\n    subsampling 2**j which can be performed on a signal convolved with this\n    filter without aliasing.\n\n    Parameters\n    ----------\n    J : int\n        maximal scale of the scattering (controls the number of wavelets)\n    Q : int\n        number of wavelets per octave for the first order\n    r_psi : float, optional\n        Should be >0 and <1. Controls the redundancy of the filters\n        (the larger r_psi, the larger the overlap between adjacent wavelets).\n        Defaults to sqrt(0.5)\n    sigma0 : float, optional\n        frequential width of the low-pass filter at scale J=0\n        (the subsequent widths are defined by sigma_J = sigma0 / 2^J).\n        Defaults to 1e-1\n    alpha : float, optional\n        tolerance factor for the aliasing after subsampling.\n        The larger alpha, the more conservative the value of maximal\n        subsampling is. Defaults to 5.\n\n    Returns\n    -------\n    sigma_low : float\n        frequential width of the low-pass filter\n    xi1 : dictionary\n        dictionary containing the center frequencies of the first order\n        filters. See above for a decsription of the keys.\n    sigma1 : dictionary\n        dictionary containing the frequential width of the first order\n        filters. See above for a description of the keys.\n    xi2 : dictionary\n        dictionary containing the center frequencies of the second order\n        filters. See above for a decsription of the keys.\n    sigma2 : dictionary\n        dictionary containing the frequential width of the second order\n        filters. See above for a description of the keys.\n    """"""\n    if Q < 1:\n        raise ValueError(\'Q should always be >= 1, got {}\'.format(Q))\n    sigma_low = sigma0 / math.pow(2, J)  # width of the low pass\n    xi1, sigma1, j1 = compute_params_filterbank(sigma_low, Q, r_psi=r_psi,\n                                            alpha=alpha)\n    xi2, sigma2, j2 = compute_params_filterbank(sigma_low, 1, r_psi=r_psi,\n                                            alpha=alpha)\n    return sigma_low, xi1, sigma1, j1, xi2, sigma2, j2\n\n\ndef scattering_filter_factory(J_support, J_scattering, Q, r_psi=math.sqrt(0.5),\n                              criterion_amplitude=1e-3, normalize=\'l1\',\n                              max_subsampling=None, sigma0=0.1, alpha=5.,\n                              P_max=5, eps=1e-7, **kwargs):\n    """"""\n    Builds in Fourier the Morlet filters used for the scattering transform.\n\n    Each single filter is provided as a dictionary with the following keys:\n    * \'xi\': central frequency, defaults to 0 for low-pass filters.\n    * \'sigma\': frequential width\n    * k where k is an integer bounded below by 0. The maximal value for k\n        depends on the type of filter, it is dynamically chosen depending\n        on max_subsampling and the characteristics of the filters.\n        Each value for k is an array (or tensor) of size 2**(J_support - k)\n        containing the Fourier transform of the filter after subsampling by\n        2**k\n\n    Parameters\n    ----------\n    J_support : int\n        2**J_support is the desired support size of the filters\n    J_scattering : int\n        parameter for the scattering transform (2**J_scattering\n        corresponds to the averaging support of the low-pass filter)\n    Q : int\n        number of wavelets per octave at the first order. For audio signals,\n        a value Q >= 12 is recommended in order to separate partials.\n    r_psi : float, optional\n        Should be >0 and <1. Controls the redundancy of the filters\n        (the larger r_psi, the larger the overlap between adjacent wavelets).\n        Defaults to sqrt(0.5).\n    criterion_amplitude : float, optional\n        Represents the numerical error which is allowed to be lost after\n        convolution and padding. Defaults to 1e-3.\n    normalize : string, optional\n        Normalization convention for the filters (in the\n        temporal domain). Supported values include \'l1\' and \'l2\'; a ValueError\n        is raised otherwise. Defaults to \'l1\'.\n    max_subsampling: int or None, optional\n        maximal dyadic subsampling to compute, in order\n        to save computation time if it is not required. Defaults to None, in\n        which case this value is dynamically adjusted depending on the filters.\n    sigma0 : float, optional\n        parameter controlling the frequential width of the\n        low-pass filter at J_scattering=0; at a an absolute J_scattering, it\n        is equal to sigma0 / 2**J_scattering. Defaults to 1e-1\n    alpha : float, optional\n        tolerance factor for the aliasing after subsampling.\n        The larger alpha, the more conservative the value of maximal\n        subsampling is. Defaults to 5.\n    P_max : int, optional\n        maximal number of periods to use to make sure that the Fourier\n        transform of the filters is periodic. P_max = 5 is more than enough for\n        double precision. Defaults to 5. Should be >= 1\n    eps : float, optional\n        required machine precision for the periodization (single\n        floating point is enough for deep learning applications).\n        Defaults to 1e-7\n\n    Returns\n    -------\n    phi_f : dictionary\n        a dictionary containing the low-pass filter at all possible\n        subsamplings. See above for a description of the dictionary structure.\n        The possible subsamplings are controlled by the inputs they can\n        receive, which correspond to the subsamplings performed on top of the\n        1st and 2nd order transforms.\n    psi1_f : dictionary\n        a dictionary containing the band-pass filters of the 1st order,\n        only for the base resolution as no subsampling is used in the\n        scattering tree.\n        Each value corresponds to a dictionary for a single filter, see above\n        for an exact description.\n        The keys of this dictionary are of the type (j, n) where n is an\n        integer counting the filters and j the maximal dyadic subsampling\n        which can be performed on top of the filter without aliasing.\n    psi2_f : dictionary\n        a dictionary containing the band-pass filters of the 2nd order\n        at all possible subsamplings. The subsamplings are determined by the\n        input they can receive, which depends on the scattering tree.\n        Each value corresponds to a dictionary for a single filter, see above\n        for an exact description.\n        The keys of this dictionary are of th etype (j, n) where n is an\n        integer counting the filters and j is the maximal dyadic subsampling\n        which can be performed on top of this filter without aliasing.\n    t_max_phi : int\n        temporal size to use to pad the signal on the right and on the\n        left by making at most criterion_amplitude error. Assumes that the\n        temporal support of the low-pass filter is larger than all filters.\n\n    Refs\n    ----\n    Convolutional operators in the time-frequency domain, V. Lostanlen,\n    PhD Thesis, 2017\n    https://tel.archives-ouvertes.fr/tel-01559667\n    """"""\n    # compute the spectral parameters of the filters\n    sigma_low, xi1, sigma1, j1s, xi2, sigma2, j2s = calibrate_scattering_filters(\n        J_scattering, Q, r_psi=r_psi, sigma0=sigma0, alpha=alpha)\n\n    # instantiate the dictionaries which will contain the filters\n    phi_f = {}\n    psi1_f = []\n    psi2_f = []\n\n    # compute the band-pass filters of the second order,\n    # which can take as input a subsampled\n    for (n2, j2) in enumerate(j2s):\n        # compute the current value for the max_subsampling,\n        # which depends on the input it can accept.\n        if max_subsampling is None:\n            possible_subsamplings_after_order1 = [\n                j1 for j1 in j1s if j2 > j1]\n            if len(possible_subsamplings_after_order1) > 0:\n                max_sub_psi2 = max(possible_subsamplings_after_order1)\n            else:\n                max_sub_psi2 = 0\n        else:\n            max_sub_psi2 = max_subsampling\n        # We first compute the filter without subsampling\n        T = 2**J_support\n\n        psi_f = {}\n        psi_f[0] = morlet_1d(\n            T, xi2[n2], sigma2[n2], normalize=normalize, P_max=P_max,\n            eps=eps)\n        # compute the filter after subsampling at all other subsamplings\n        # which might be received by the network, based on this first filter\n        for subsampling in range(1, max_sub_psi2 + 1):\n            factor_subsampling = 2**subsampling\n            psi_f[subsampling] = periodize_filter_fourier(\n                psi_f[0], nperiods=factor_subsampling)\n        psi2_f.append(psi_f)\n\n    # for the 1st order filters, the input is not subsampled so we\n    # can only compute them with T=2**J_support\n    for (n1, j1) in enumerate(j1s):\n        T = 2**J_support\n        psi1_f.append({0: morlet_1d(\n            T, xi1[n1], sigma1[n1], normalize=normalize,\n            P_max=P_max, eps=eps)})\n\n    # compute the low-pass filters phi\n    # Determine the maximal subsampling for phi, which depends on the\n    # input it can accept (both 1st and 2nd order)\n    if max_subsampling is None:\n        max_subsampling_after_psi1 = max(j1s)\n        max_subsampling_after_psi2 = max(j2s)\n        max_sub_phi = max(max_subsampling_after_psi1,\n                          max_subsampling_after_psi2)\n    else:\n        max_sub_phi = max_subsampling\n\n    # compute the filters at all possible subsamplings\n    phi_f[0] = gauss_1d(T, sigma_low, P_max=P_max, eps=eps)\n    for subsampling in range(1, max_sub_phi + 1):\n        factor_subsampling = 2**subsampling\n        # compute the low_pass filter\n        phi_f[subsampling] = periodize_filter_fourier(\n            phi_f[0], nperiods=factor_subsampling)\n\n    # Embed the meta information within the filters\n    for (n1, j1) in enumerate(j1s):\n        psi1_f[n1][\'xi\'] = xi1[n1]\n        psi1_f[n1][\'sigma\'] = sigma1[n1]\n        psi1_f[n1][\'j\'] = j1\n    for (n2, j2) in enumerate(j2s):\n        psi2_f[n2][\'xi\'] = xi2[n2]\n        psi2_f[n2][\'sigma\'] = sigma2[n2]\n        psi2_f[n2][\'j\'] = j2\n    phi_f[\'xi\'] = 0.\n    phi_f[\'sigma\'] = sigma_low\n    phi_f[\'j\'] = 0\n\n    # compute the support size allowing to pad without boundary errors\n    # at the finest resolution\n    t_max_phi = compute_temporal_support(\n        phi_f[0].reshape(1, -1), criterion_amplitude=criterion_amplitude)\n\n    # return results\n    return phi_f, psi1_f, psi2_f, t_max_phi\n'"
kymatio/scattering1d/utils.py,2,"b'import numpy as np\nimport math\nfrom .filter_bank import scattering_filter_factory, calibrate_scattering_filters\n\ndef compute_border_indices(J, i0, i1):\n    """"""\n    Computes border indices at all scales which correspond to the original\n    signal boundaries after padding.\n\n    At the finest resolution,\n    original_signal = padded_signal[..., i0:i1].\n    This function finds the integers i0, i1 for all temporal subsamplings\n    by 2**J, being conservative on the indices.\n\n    Parameters\n    ----------\n    J : int\n        maximal subsampling by 2**J\n    i0 : int\n        start index of the original signal at the finest resolution\n    i1 : int\n        end index (excluded) of the original signal at the finest resolution\n\n    Returns\n    -------\n    ind_start, ind_end: dictionaries with keys in [0, ..., J] such that the\n        original signal is in padded_signal[ind_start[j]:ind_end[j]]\n        after subsampling by 2**j\n    """"""\n    ind_start = {0: i0}\n    ind_end = {0: i1}\n    for j in range(1, J + 1):\n        ind_start[j] = (ind_start[j - 1] // 2) + (ind_start[j - 1] % 2)\n        ind_end[j] = (ind_end[j - 1] // 2) + (ind_end[j - 1] % 2)\n    return ind_start, ind_end\n\ndef compute_padding(J_pad, T):\n    """"""\n    Computes the padding to be added on the left and on the right\n    of the signal.\n\n    It should hold that 2**J_pad >= T\n\n    Parameters\n    ----------\n    J_pad : int\n        2**J_pad is the support of the padded signal\n    T : int\n        original signal support size\n\n    Returns\n    -------\n    pad_left: amount to pad on the left (""beginning"" of the support)\n    pad_right: amount to pad on the right (""end"" of the support)\n    """"""\n    T_pad = 2**J_pad\n    if T_pad < T:\n        raise ValueError(\'Padding support should be larger than the original\' +\n                         \'signal size!\')\n    to_add = 2**J_pad - T\n    pad_left = to_add // 2\n    pad_right = to_add - pad_left\n    if max(pad_left, pad_right) >= T:\n        raise ValueError(\'Too large padding value, will lead to NaN errors\')\n    return pad_left, pad_right\n\ndef compute_minimum_support_to_pad(T, J, Q, criterion_amplitude=1e-3,\n                                       normalize=\'l1\', r_psi=math.sqrt(0.5),\n                                       sigma0=1e-1, alpha=5., P_max=5, eps=1e-7):\n\n\n    """"""\n    Computes the support to pad given the input size and the parameters of the\n    scattering transform.\n\n    Parameters\n    ----------\n    T : int\n        temporal size of the input signal\n    J : int\n        scale of the scattering\n    Q : int\n        number of wavelets per octave\n    normalize : string, optional\n        normalization type for the wavelets.\n        Only `\'l2\'` or `\'l1\'` normalizations are supported.\n        Defaults to `\'l1\'`\n    criterion_amplitude: float `>0` and `<1`, optional\n        Represents the numerical error which is allowed to be lost after\n        convolution and padding.\n        The larger criterion_amplitude, the smaller the padding size is.\n        Defaults to `1e-3`\n    r_psi : float, optional\n        Should be `>0` and `<1`. Controls the redundancy of the filters\n        (the larger r_psi, the larger the overlap between adjacent\n        wavelets).\n        Defaults to `sqrt(0.5)`.\n    sigma0 : float, optional\n        parameter controlling the frequential width of the\n        low-pass filter at J_scattering=0; at a an absolute J_scattering,\n        it is equal to :math:`\\\\frac{\\\\sigma_0}{2^J}`.\n        Defaults to `1e-1`.\n    alpha : float, optional\n        tolerance factor for the aliasing after subsampling.\n        The larger the alpha, the more conservative the value of maximal\n        subsampling is.\n        Defaults to `5`.\n    P_max : int, optional\n        maximal number of periods to use to make sure that the Fourier\n        transform of the filters is periodic.\n        `P_max = 5` is more than enough for double precision.\n        Defaults to `5`.\n    eps : float, optional\n        required machine precision for the periodization (single\n        floating point is enough for deep learning applications).\n        Defaults to `1e-7`.\n\n    Returns\n    -------\n    min_to_pad: int\n        minimal value to pad the signal on one size to avoid any\n        boundary error.\n    """"""\n    J_tentative = int(np.ceil(np.log2(T)))\n    _, _, _, t_max_phi = scattering_filter_factory(\n        J_tentative, J, Q, normalize=normalize, to_torch=False,\n        max_subsampling=0, criterion_amplitude=criterion_amplitude,\n        r_psi=r_psi, sigma0=sigma0, alpha=alpha, P_max=P_max, eps=eps)\n    min_to_pad = 3 * t_max_phi\n    return min_to_pad\n\n\ndef precompute_size_scattering(J, Q, max_order=2, detail=False):\n    """"""Get size of the scattering transform\n\n    The number of scattering coefficients depends on the filter\n    configuration and so can be calculated using a few of the scattering\n    transform parameters.\n\n    Parameters\n    ----------\n    J : int\n        The maximum log-scale of the scattering transform.\n        In other words, the maximum scale is given by `2**J`.\n    Q : int >= 1\n        The number of first-order wavelets per octave.\n        Second-order wavelets are fixed to one wavelet per octave.\n    max_order : int, optional\n        The maximum order of scattering coefficients to compute.\n        Must be either equal to `1` or `2`. Defaults to `2`.\n    detail : boolean, optional\n        Specifies whether to provide a detailed size (number of coefficient\n        per order) or an aggregate size (total number of coefficients).\n\n    Returns\n    -------\n    size : int or tuple\n        If `detail` is `False`, returns the number of coefficients as an\n        integer. If `True`, returns a tuple of size `max_order` containing\n        the number of coefficients in each order.\n    """"""\n    sigma_low, xi1, sigma1, j1, xi2, sigma2, j2 = \\\n        calibrate_scattering_filters(J, Q)\n\n    size_order0 = 1\n    size_order1 = len(xi1)\n    size_order2 = 0\n    for n1 in range(len(xi1)):\n        for n2 in range(len(xi2)):\n            if j2[n2] > j1[n1]:\n                size_order2 += 1\n    if detail:\n        if max_order == 2:\n            return size_order0, size_order1, size_order2\n        else:\n            return size_order0, size_order1\n    else:\n        if max_order == 2:\n            return size_order0 + size_order1 + size_order2\n        else:\n            return size_order0 + size_order1\n\n\ndef compute_meta_scattering(J, Q, max_order=2):\n    """"""Get metadata on the transform.\n\n    This information specifies the content of each scattering coefficient,\n    which order, which frequencies, which filters were used, and so on.\n\n    Parameters\n    ----------\n    J : int\n        The maximum log-scale of the scattering transform.\n        In other words, the maximum scale is given by `2**J`.\n    Q : int >= 1\n        The number of first-order wavelets per octave.\n        Second-order wavelets are fixed to one wavelet per octave.\n    max_order : int, optional\n        The maximum order of scattering coefficients to compute.\n        Must be either equal to `1` or `2`. Defaults to `2`.\n\n    Returns\n    -------\n    meta : dictionary\n        A dictionary with the following keys:\n\n        - `\'order`\' : tensor\n            A Tensor of length `C`, the total number of scattering\n            coefficients, specifying the scattering order.\n        - `\'xi\'` : tensor\n            A Tensor of size `(C, max_order)`, specifying the center\n            frequency of the filter used at each order (padded with NaNs).\n        - `\'sigma\'` : tensor\n            A Tensor of size `(C, max_order)`, specifying the frequency\n            bandwidth of the filter used at each order (padded with NaNs).\n        - `\'j\'` : tensor\n            A Tensor of size `(C, max_order)`, specifying the dyadic scale\n            of the filter used at each order (padded with NaNs).\n        - `\'n\'` : tensor\n            A Tensor of size `(C, max_order)`, specifying the indices of\n            the filters used at each order (padded with NaNs).\n        - `\'key\'` : list\n            The tuples indexing the corresponding scattering coefficient\n            in the non-vectorized output.\n    """"""\n    sigma_low, xi1s, sigma1s, j1s, xi2s, sigma2s, j2s = \\\n        calibrate_scattering_filters(J, Q)\n\n    meta = {}\n\n    meta[\'order\'] = [[], [], []]\n    meta[\'xi\'] = [[], [], []]\n    meta[\'sigma\'] = [[], [], []]\n    meta[\'j\'] = [[], [], []]\n    meta[\'n\'] = [[], [], []]\n    meta[\'key\'] = [[], [], []]\n\n    meta[\'order\'][0].append(0)\n    meta[\'xi\'][0].append(())\n    meta[\'sigma\'][0].append(())\n    meta[\'j\'][0].append(())\n    meta[\'n\'][0].append(())\n    meta[\'key\'][0].append(())\n\n    for (n1, (xi1, sigma1, j1)) in enumerate(zip(xi1s, sigma1s, j1s)):\n        meta[\'order\'][1].append(1)\n        meta[\'xi\'][1].append((xi1,))\n        meta[\'sigma\'][1].append((sigma1,))\n        meta[\'j\'][1].append((j1,))\n        meta[\'n\'][1].append((n1,))\n        meta[\'key\'][1].append((n1,))\n\n        if max_order < 2:\n            continue\n\n        for (n2, (xi2, sigma2, j2)) in enumerate(zip(xi2s, sigma2s, j2s)):\n            if j2 > j1:\n                meta[\'order\'][2].append(2)\n                meta[\'xi\'][2].append((xi1, xi2))\n                meta[\'sigma\'][2].append((sigma1, sigma2))\n                meta[\'j\'][2].append((j1, j2))\n                meta[\'n\'][2].append((n1, n2))\n                meta[\'key\'][2].append((n1, n2))\n\n    for field, value in meta.items():\n        meta[field] = value[0] + value[1] + value[2]\n\n    pad_fields = [\'xi\', \'sigma\', \'j\', \'n\']\n    pad_len = max_order\n\n    for field in pad_fields:\n        meta[field] = [x + (math.nan,) * (pad_len - len(x)) for x in meta[field]]\n\n    array_fields = [\'order\', \'xi\', \'sigma\', \'j\', \'n\']\n\n    for field in array_fields:\n        meta[field] = np.array(meta[field])\n\n    return meta\n'"
kymatio/scattering2d/__init__.py,0,"b""from .frontend.entry import ScatteringEntry2D\n\n\n__all__ = ['ScatteringEntry2D']\n"""
kymatio/scattering2d/filter_bank.py,17,"b'""""""\nAuthors: Eugene Belilovsky, Edouard Oyallon and Sergey Zagoruyko\nAll rights reserved, 2017.\n""""""\n\nimport numpy as np\nfrom scipy.fftpack import fft2, ifft2\n\n\ndef filter_bank(M, N, J, L=8):\n    """"""\n        Builds in Fourier the Morlet filters used for the scattering transform.\n        Each single filter is provided as a dictionary with the following keys:\n        * \'j\' : scale\n        * \'theta\' : angle used\n        Parameters\n        ----------\n        M, N : int\n            spatial support of the input\n        J : int\n            logscale of the scattering\n        L : int, optional\n            number of angles used for the wavelet transform\n        Returns\n        -------\n        filters : list\n            A two list of dictionary containing respectively the low-pass and\n             wavelet filters.\n        Notes\n        -----\n        The design of the filters is optimized for the value L = 8.\n    """"""\n    filters = {}\n    filters[\'psi\'] = []\n\n    for j in range(J):\n        for theta in range(L):\n            psi = {}\n            psi[\'j\'] = j\n            psi[\'theta\'] = theta\n            psi_signal = morlet_2d(M, N, 0.8 * 2**j,\n                (int(L-L/2-1)-theta) * np.pi / L,\n                3.0 / 4.0 * np.pi /2**j, 4.0/L)\n            psi_signal_fourier = fft2(psi_signal)\n            # drop the imaginary part, it is zero anyway\n            psi_signal_fourier = np.real(psi_signal_fourier)\n            for res in range(min(j + 1, max(J - 1, 1))):\n                psi_signal_fourier_res = periodize_filter_fft(\n                    psi_signal_fourier, res)\n                psi[res] = psi_signal_fourier_res\n            filters[\'psi\'].append(psi)\n\n    filters[\'phi\'] = {}\n    phi_signal = gabor_2d(M, N, 0.8 * 2**(J-1), 0, 0)\n    phi_signal_fourier = fft2(phi_signal)\n    # drop the imaginary part, it is zero anyway\n    phi_signal_fourier = np.real(phi_signal_fourier)\n    filters[\'phi\'][\'j\'] = J\n    for res in range(J):\n        phi_signal_fourier_res = periodize_filter_fft(phi_signal_fourier, res)\n        filters[\'phi\'][res] = phi_signal_fourier_res\n\n    return filters\n\n\ndef periodize_filter_fft(x, res):\n    """"""\n        Parameters\n        ----------\n        x : numpy array\n            signal to periodize in Fourier\n        res :\n            resolution to which the signal is cropped.\n\n        Returns\n        -------\n        crop : numpy array\n            It returns a crop version of the filter, assuming that\n             the convolutions will be done via compactly supported signals.\n    """"""\n    M = x.shape[0]\n    N = x.shape[1]\n\n    crop = np.zeros((M // 2 ** res, N // 2 ** res), x.dtype)\n\n    mask = np.ones(x.shape, np.float32)\n    len_x = int(M * (1 - 2 ** (-res)))\n    start_x = int(M * 2 ** (-res - 1))\n    len_y = int(N * (1 - 2 ** (-res)))\n    start_y = int(N * 2 ** (-res - 1))\n    mask[start_x:start_x + len_x,:] = 0\n    mask[:, start_y:start_y + len_y] = 0\n    x = np.multiply(x,mask)\n\n    for k in range(int(M / 2 ** res)):\n        for l in range(int(N / 2 ** res)):\n            for i in range(int(2 ** res)):\n                for j in range(int(2 ** res)):\n                    crop[k, l] += x[k + i * int(M / 2 ** res), l + j * int(N / 2 ** res)]\n\n    return crop\n\n\ndef morlet_2d(M, N, sigma, theta, xi, slant=0.5, offset=0):\n    """"""\n        Computes a 2D Morlet filter.\n        A Morlet filter is the sum of a Gabor filter and a low-pass filter\n        to ensure that the sum has exactly zero mean in the temporal domain.\n        It is defined by the following formula in space:\n        psi(u) = g_{sigma}(u) (e^(i xi^T u) - beta)\n        where g_{sigma} is a Gaussian envelope, xi is a frequency and beta is\n        the cancelling parameter.\n\n        Parameters\n        ----------\n        M, N : int\n            spatial sizes\n        sigma : float\n            bandwidth parameter\n        xi : float\n            central frequency (in [0, 1])\n        theta : float\n            angle in [0, pi]\n        slant : float, optional\n            parameter which guides the elipsoidal shape of the morlet\n        offset : int, optional\n            offset by which the signal starts\n\n        Returns\n        -------\n        morlet_fft : ndarray\n            numpy array of size (M, N)\n    """"""\n    wv = gabor_2d(M, N, sigma, theta, xi, slant, offset)\n    wv_modulus = gabor_2d(M, N, sigma, theta, 0, slant, offset)\n    K = np.sum(wv) / np.sum(wv_modulus)\n\n    mor = wv - K * wv_modulus\n    return mor\n\n\ndef gabor_2d(M, N, sigma, theta, xi, slant=1.0, offset=0):\n    """"""\n        Computes a 2D Gabor filter.\n        A Gabor filter is defined by the following formula in space:\n        psi(u) = g_{sigma}(u) e^(i xi^T u)\n        where g_{sigma} is a Gaussian envelope and xi is a frequency.\n\n        Parameters\n        ----------\n        M, N : int\n            spatial sizes\n        sigma : float\n            bandwidth parameter\n        xi : float\n            central frequency (in [0, 1])\n        theta : float\n            angle in [0, pi]\n        slant : float, optional\n            parameter which guides the elipsoidal shape of the morlet\n        offset : int, optional\n            offset by which the signal starts\n\n        Returns\n        -------\n        morlet_fft : ndarray\n            numpy array of size (M, N)\n    """"""\n    gab = np.zeros((M, N), np.complex64)\n    R = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]], np.float32)\n    R_inv = np.array([[np.cos(theta), np.sin(theta)], [-np.sin(theta), np.cos(theta)]], np.float32)\n    D = np.array([[1, 0], [0, slant * slant]])\n    curv = np.dot(R, np.dot(D, R_inv)) / ( 2 * sigma * sigma)\n\n    for ex in [-2, -1, 0, 1, 2]:\n        for ey in [-2, -1, 0, 1, 2]:\n            [xx, yy] = np.mgrid[offset + ex * M:offset + M + ex * M, offset + ey * N:offset + N + ey * N]\n            arg = -(curv[0, 0] * np.multiply(xx, xx) + (curv[0, 1] + curv[1, 0]) * np.multiply(xx, yy) + curv[\n                1, 1] * np.multiply(yy, yy)) + 1.j * (xx * xi * np.cos(theta) + yy * xi * np.sin(theta))\n            gab += np.exp(arg)\n\n    norm_factor = (2 * 3.1415 * sigma * sigma / slant)\n    gab /= norm_factor\n\n    return gab\n\n\n__all__ = [\'filter_bank\']\n'"
kymatio/scattering2d/utils.py,0,"b'import scipy.fftpack\nimport warnings\n\ndef compute_padding(M, N, J):\n    """"""\n         Precomputes the future padded size. If 2^J=M or 2^J=N,\n         border effects are unavoidable in this case, and it is\n         likely that the input has either a compact support,\n         either is periodic.\n\n         Parameters\n         ----------\n         M, N : int\n             input size\n\n         Returns\n         -------\n         M, N : int\n             padded size\n    """"""\n    M_padded = ((M + 2 ** J) // 2 ** J + 1) * 2 ** J\n    N_padded = ((N + 2 ** J) // 2 ** J + 1) * 2 ** J\n\n    return M_padded, N_padded\n\ndef fft2(x):\n    with warnings.catch_warnings():\n        warnings.simplefilter(\'ignore\', FutureWarning)\n        return scipy.fftpack.fft2(x)\n'"
kymatio/scattering3d/__init__.py,0,"b""from .frontend.entry import HarmonicScatteringEntry3D\n\n\n__all__ = ['HarmonicScatteringEntry3D']\n"""
kymatio/scattering3d/filter_bank.py,20,"b'""""""\nAuthors: Louis Thiry, Georgios Exarchakis and Michael Eickenberg\nAll rights reserved, 2017.\n""""""\n\n__all__ = [\'solid_harmonic_filter_bank\']\n\nimport numpy as np\nfrom scipy.special import sph_harm, factorial\nfrom .utils import get_3d_angles, double_factorial, sqrt\n\n\ndef solid_harmonic_filter_bank(M, N, O, J, L, sigma_0, fourier=True):\n    """"""\n        Computes a set of 3D Solid Harmonic Wavelets of scales j = [0, ..., J]\n        and first orders l = [0, ..., L].\n\n        Parameters\n        ----------\n        M, N, O : int\n            spatial sizes\n        J : int\n            maximal scale of the wavelets\n        L : int\n            maximal first order of the wavelets\n        sigma_0 : float\n            width parameter of mother solid harmonic wavelet\n        fourier : boolean\n            if true, wavelets are computed in Fourier space\n\t    if false, wavelets are computed in signal space\n\n        Returns\n        -------\n        filters : list of ndarray\n            the element number l of the list is a torch array array of size\n            (J+1, 2l+1, M, N, O, 2) containing the (J+1)x(2l+1) wavelets of order l.\n    """"""\n    filters = []\n    for l in range(L + 1):\n        filters_l = np.zeros((J + 1, 2 * l + 1, M, N, O), dtype=\'complex64\')\n        for j in range(J+1):\n            sigma = sigma_0 * 2 ** j\n            filters_l[j,...] = solid_harmonic_3d(M, N, O, sigma, l, fourier=fourier)\n        filters.append(filters_l)\n    return filters\n\n\ndef gaussian_filter_bank(M, N, O, J, sigma_0, fourier=True):\n    """"""\n        Computes a set of 3D Gaussian filters of scales j = [0, ..., J].\n\n        Parameters\n        ----------\n        M, N, O : int\n            spatial sizes\n        J : int\n            maximal scale of the wavelets\n        sigma_0 : float\n            width parameter of father Gaussian filter\n        fourier : boolean\n            if true, wavelets are computed in Fourier space\n\t    if false, wavelets are computed in signal space\n\n        Returns\n        -------\n        gaussians : ndarray\n            torch array array of size (J+1, M, N, O, 2) containing the (J+1)\n            Gaussian filters.\n    """"""\n    gaussians = np.zeros((J + 1, M, N, O), dtype=\'complex64\')\n    for j in range(J + 1):\n        sigma = sigma_0 * 2 ** j\n        gaussians[j, ...] = gaussian_3d(M, N, O, sigma, fourier=fourier)\n    return gaussians\n\n\ndef gaussian_3d(M, N, O, sigma, fourier=True):\n    """"""\n        Computes a 3D Gaussian filter.\n\n        Parameters\n        ----------\n        M, N, O : int\n            spatial sizes\n        sigma : float\n            gaussian width parameter\n        fourier : boolean\n            if true, the Gaussian if computed in Fourier space\n\t    if false, the Gaussian if computed in signal space\n\n        Returns\n        -------\n        gaussian : ndarray\n            numpy array of size (M, N, O) and type float32 ifftshifted such\n            that the origin is at the point [0, 0, 0]\n    """"""\n    grid = np.fft.ifftshift(\n        np.mgrid[-M // 2:-M // 2 + M,\n                 -N // 2:-N // 2 + N,\n                 -O // 2:-O // 2 + O].astype(\'float32\'),\n        axes=(1,2,3))\n    _sigma = sigma\n    if fourier:\n        grid[0] *= 2 * np.pi / M\n        grid[1] *= 2 * np.pi / N\n        grid[2] *= 2 * np.pi / O\n        _sigma = 1. / sigma\n\n    gaussian = np.exp(-0.5 * (grid ** 2).sum(0) / _sigma ** 2)\n    if not fourier:\n        gaussian /= (2 * np.pi) ** 1.5 * _sigma ** 3\n\n    return gaussian\n\n\ndef solid_harmonic_3d(M, N, O, sigma, l, fourier=True):\n    """"""\n        Computes a set of 3D Solid Harmonic Wavelets.\n\tA solid harmonic wavelet has two integer orders l >= 0 and -l <= m <= l\n\tIn spherical coordinates (r, theta, phi), a solid harmonic wavelet is\n\tthe product of a polynomial Gaussian r^l exp(-0.5 r^2 / sigma^2)\n\twith a spherical harmonic function Y_{l,m} (theta, phi).\n\n        Parameters\n        ----------\n        M, N, O : int\n            spatial sizes\n        sigma : float\n            width parameter of the solid harmonic wavelets\n        l : int\n            first integer order of the wavelets\n        fourier : boolean\n            if true, wavelets are computed in Fourier space\n\t    if false, wavelets are computed in signal space\n\n        Returns\n        -------\n        solid_harm : ndarray, type complex64\n            numpy array of size (2l+1, M, N, 0) and type complex64 containing\n            the 2l+1 wavelets of order (l , m) with -l <= m <= l.\n            It is ifftshifted such that the origin is at the point [., 0, 0, 0]\n    """"""\n    solid_harm = np.zeros((2*l+1, M, N, O), np.complex64)\n    grid = np.fft.ifftshift(\n        np.mgrid[-M // 2:-M // 2 + M,\n                 -N // 2:-N // 2 + N,\n                 -O // 2:-O // 2 + O].astype(\'float32\'),\n        axes=(1,2,3))\n    _sigma = sigma\n\n    if fourier:\n        grid[0] *= 2 * np.pi / M\n        grid[1] *= 2 * np.pi / N\n        grid[2] *= 2 * np.pi / O\n        _sigma = 1. / sigma\n\n    r_square = (grid ** 2).sum(0)\n    r_power_l = sqrt(r_square ** l)\n    gaussian = np.exp(-0.5 * r_square / _sigma ** 2).astype(\'complex64\')\n\n    if l == 0:\n        if fourier:\n            return gaussian.reshape((1, M, N, O))\n        return gaussian.reshape((1, M, N, O)) / (\n                                          (2 * np.pi) ** 1.5 * _sigma ** 3)\n\n    polynomial_gaussian = r_power_l * gaussian / _sigma ** l\n\n    polar, azimuthal = get_3d_angles(grid)\n\n    for i_m, m in enumerate(range(-l, l + 1)):\n        solid_harm[i_m] = sph_harm(m, l, azimuthal, polar) * polynomial_gaussian\n\n    if l % 2 == 0:\n        norm_factor = 1. / (2 * np.pi * np.sqrt(l + 0.5) * \n                                            double_factorial(l + 1))\n    else :\n        norm_factor = 1. / (2 ** (0.5 * ( l + 3)) * \n                            np.sqrt(np.pi * (2 * l + 1)) * \n                            factorial((l + 1) / 2))\n\n    if fourier:\n        norm_factor *= (2 * np.pi) ** 1.5 * (-1j) ** l\n    else:\n        norm_factor /= _sigma ** 3\n\n    solid_harm *= norm_factor\n\n    return solid_harm\n'"
kymatio/scattering3d/utils.py,10,"b'""""""Author: Louis Thiry""""""\nimport numpy as np\nimport warnings\n\n\ndef generate_weighted_sum_of_gaussians(grid, positions, weights, sigma):\n    """"""\n        Computes sum of 3D Gaussians centered at given positions and weighted\n        with the given weights.\n        Parameters\n        ----------\n        grid : numpy array\n            numerical grid, size (3, M, N, O)\n        positions: numpy array\n            positions of the Gaussians, size (B, N_gaussians, 3)\n            B batch_size, N_gaussians number or gaussians\n        weights: numpy array\n            weights of the Gaussians, size (B, N_gaussians)\n            zero weights are assumed to be at the end since if a weight is zero\n            all weights after are ignored\n        sigma : float\n            width parameter of the Gaussian\n        Returns\n        -------\n        signals : numpy array\n            numpy array of size (B, M, N, O)\n            B is the batch_size, M, N, O are the size of the signal\n    """"""\n    _, M, N, O = grid.shape\n    signals = np.zeros((positions.shape[0], M, N, O))\n\n    for i_signal in range(positions.shape[0]):\n        n_points = positions[i_signal].shape[0]\n        for i_point in range(n_points):\n            if weights[i_signal, i_point] == 0:\n                break\n            weight = weights[i_signal, i_point]\n            center = positions[i_signal, i_point]\n            signals[i_signal] = np.add(signals[i_signal] , weight * np.exp(\n                -0.5 * ((grid[0] - center[0]) ** 2 +\n                        (grid[1] - center[1]) ** 2 +\n                        (grid[2] - center[2]) ** 2) / sigma**2))\n    return signals / ((2 * np.pi) ** 1.5 * sigma ** 3)\n\ndef get_3d_angles(cartesian_grid):\n    """"""\n        Given a cartesian grid, computes the spherical coord angles (theta, phi).\n        Parameters\n        ----------\n        cartesian_grid: numpy array\n            4D array of shape (3, M, N, O)\n        Returns\n        -------\n        polar: numpy array\n            polar angles, shape (M, N, O)\n        azimutal: numpy array\n            azimutal angles, shape (M, N, O)\n    """"""\n    z, y, x = cartesian_grid\n    azimuthal = np.arctan2(y, x)\n    rxy = sqrt(x ** 2 + y ** 2)\n    polar = np.arctan2(z, rxy) + np.pi / 2\n    return polar, azimuthal\n\n\ndef double_factorial(i):\n    """"""Computes the double factorial of an integer.""""""\n    return 1 if (i < 1) else np.prod(np.arange(i, 0, -2))\n\n\ndef sqrt(x):\n    """"""\n        Compute the square root of an array\n        This suppresses any warnings due to invalid input, unless the array is\n        real and has negative values. This fixes the erroneous warnings\n        introduced by an Intel SVM bug for large single-precision arrays. For\n        more information, see:\n            https://github.com/numpy/numpy/issues/11448\n            https://github.com/ContinuumIO/anaconda-issues/issues/9129\n        Parameters\n        ----------\n        x : numpy array\n            An array for which we would like to compute the square root.\n        Returns\n        -------\n        y : numpy array\n            The square root of the array.\n    """"""\n    if np.isrealobj(x) and (x < 0).any():\n        warnings.warn(""Negative value encountered in sqrt"", RuntimeWarning,\n            stacklevel=1)\n    old_settings = np.seterr(invalid=\'ignore\')\n    y = np.sqrt(x)\n    np.seterr(**old_settings)\n\n    return y\n\ndef _apply_filters(filters, fn):\n    """"""\n        Parameters\n        ----------\n        filters: a filter bank\n        fn: a function to apply on the parameters\n        Returns\n        -------\n        filters: the filters modified\n    """"""\n    for k in range(len(filters)):\n        filters[k] = fn(filters[k])\n    return filters\n'"
tests/general/test_torch_backend.py,0,"b'import torch\nimport pytest\nfrom kymatio.backend.torch_backend import ModulusStable, modulus\n\n\ndef test_modulus(random_state=42):\n    """"""\n    Tests the stability and differentiability of modulus\n    """"""\n\n    x = torch.randn(100, 4, 128, 2, requires_grad=True)\n    x_grad = x.clone()\n    x_abs = modulus(x)\n\n    x_grad[..., 0] = x[..., 0] / x_abs\n    x_grad[..., 1] = x[..., 1] / x_abs\n\n    class FakeContext:\n        def save_for_backward(self, *args):\n            self.saved_tensors = args\n\n    ctx = FakeContext()\n    y = ModulusStable.forward(ctx, x)\n    y_grad = torch.ones_like(y)\n    x_grad_manual = ModulusStable.backward(ctx, y_grad)\n    assert torch.allclose(x_grad_manual, x_grad)\n'"
tests/scattering1d/test_filters_scattering1d.py,33,"b'""""""\nTesting all functions in filters_bank\n""""""\nfrom kymatio.scattering1d.filter_bank import (adaptive_choice_P, periodize_filter_fourier, get_normalizing_factor,\n    compute_sigma_psi, compute_temporal_support, compute_xi_max, morlet_1d, calibrate_scattering_filters,\n    get_max_dyadic_subsampling, gauss_1d)\nimport numpy as np\nimport math\nimport pytest\n\n\ndef test_adaptive_choice_P():\n    """"""\n    Tests whether adaptive_choice_P provides a bound P which satisfies\n    the adequate requirements\n    """"""\n    sigma_range = np.logspace(-5, 2, num=10)\n    eps_range = np.logspace(-10, -5, num=8)\n    for i in range(sigma_range.size):\n        for j in range(eps_range.size):\n            sigma = sigma_range[i]\n            eps = eps_range[j]\n            # choose the formula\n            P = adaptive_choice_P(sigma, eps=eps)\n            # check at the boundaries\n            denom = 2 * (sigma**2)\n            lim_left = np.exp(-((1 - P)**2) / denom)\n            lim_right = np.exp(-(P**2) / denom)\n            assert lim_left <= eps\n            assert lim_right <= eps\n\n\ndef test_periodize_filter_fourier(random_state=42):\n    """"""\n    Tests whether the periodization in Fourier corresponds to\n    a subsampling in time\n    """"""\n    rng = np.random.RandomState(random_state)\n    size_signal = [2**j for j in range(5, 10)]\n    periods = [2**k for k in range(0, 6)]\n\n    for N in size_signal:\n        x = rng.randn(N) + 1j * rng.randn(N)\n        x_f = np.fft.fft(x)\n        for per in periods:\n            x_per_f = periodize_filter_fourier(x_f, nperiods=per)\n            x_per = np.fft.ifft(x_per_f)\n            assert np.max(np.abs(x_per - x[::per])) < 1e-7\n\n\ndef test_normalizing_factor(random_state=42):\n    """"""\n    Tests whether the computation of the normalizing factor does the correct\n    job (i.e. actually normalizes the signal in l1 or l2)\n    """"""\n    rng = np.random.RandomState(random_state)\n    size_signal = [2**j for j in range(5, 13)]\n    norm_type = [\'l1\', \'l2\']\n    for N in size_signal:\n        x = rng.randn(N) + 1j * rng.randn(N)\n        x_f = np.fft.fft(x)\n        for norm in norm_type:\n            kappa = get_normalizing_factor(x_f, norm)\n            x_norm = kappa * x\n            if norm == \'l1\':\n                assert np.isclose(np.sum(np.abs(x_norm)) - 1, 0.)\n            elif norm == \'l2\':\n                assert np.isclose(np.sqrt(np.sum(np.abs(x_norm)**2)) - 1., 0.)\n\n    with pytest.raises(ValueError) as ve:\n        get_normalizing_factor(np.zeros(4))\n    assert ""Zero division error is very likely"" in ve.value.args[0]\n\n    with pytest.raises(ValueError) as ve:\n        get_normalizing_factor(np.ones(4), normalize=\'l0\')\n    assert ""normalizations only include"" in ve.value.args[0]\n\n\ndef test_morlet_1d():\n    """"""\n    Tests for Morlet wavelets:\n    - Make sure that it has exact zero mean\n    - Make sure that it has a fast decay in time\n    - Check that the maximal frequency is relatively close to xi,\n        up to 1% accuracy\n    """"""\n    size_signal = [2**13]\n    Q_range = np.arange(1, 20, dtype=int)\n    P_range = [1, 5]\n    for N in size_signal:\n        for Q in Q_range:\n            xi_max = compute_xi_max(Q)\n            xi_range = xi_max / np.power(2, np.arange(7))\n            for xi in xi_range:\n                for P in P_range:\n                    sigma = compute_sigma_psi(xi, Q)\n                    # get the morlet for these parameters\n                    psi_f = morlet_1d(N, xi, sigma, normalize=\'l2\', P_max=P)\n                    # make sure that it has zero mean\n                    assert np.isclose(psi_f[0], 0.)\n                    # make sure that it has a fast decay in time\n                    psi = np.fft.ifft(psi_f)\n                    psi_abs = np.abs(psi)\n                    assert np.min(psi_abs) / np.max(psi_abs) < 1e-3\n                    # Check that the maximal frequency is relatively close to xi,\n                    # up to 1 percent\n                    k_max = np.argmax(np.abs(psi_f))\n                    xi_emp = float(k_max) / float(N)\n                    assert np.abs(xi_emp - xi) / xi < 1e-2\n\n    Q = 1\n    xi = compute_xi_max(Q)\n    sigma = compute_sigma_psi(xi, Q)\n\n    with pytest.raises(ValueError) as ve:\n        morlet_1d(size_signal[0], xi, sigma, P_max=5.1)\n    assert ""should be an int"" in ve.value.args[0]\n\n    with pytest.raises(ValueError) as ve:\n        morlet_1d(size_signal[0], xi, sigma, P_max=-5)\n    assert ""should be non-negative"" in ve.value.args[0]\n\n\ndef test_gauss_1d():\n    """"""\n    Tests for Gabor low-pass\n    - Make sure that it has a fast decay in time\n    - Make sure that it is symmetric, up to 1e-7 absolute precision\n    """"""\n    N = 2**13\n    J = 7\n    P_range = [1, 5]\n    sigma0 = 0.1\n    tol = 1e-7\n    for j in range(1, J + 1):\n        for P in P_range:\n            sigma_low = sigma0 / math.pow(2, j)\n            g_f = gauss_1d(N, sigma_low, P_max=P)\n            # check the symmetry of g_f\n            assert np.max(np.abs(g_f[1:N // 2] - g_f[N // 2 + 1:][::-1])) < tol\n            # make sure that it has a fast decay in time\n            phi = np.fft.ifft(g_f)\n            assert np.min(phi) > - tol\n            assert np.min(np.abs(phi)) / np.max(np.abs(phi)) < 1e-4\n\n    Q = 1\n    xi = compute_xi_max(Q)\n    sigma = compute_sigma_psi(xi, Q)\n\n    with pytest.raises(ValueError) as ve:\n        gauss_1d(N, xi, sigma, P_max=5.1)\n    assert ""should be an int"" in ve.value.args[0]\n\n    with pytest.raises(ValueError) as ve:\n        gauss_1d(N, xi, sigma, P_max=-5)\n    assert ""should be non-negative"" in ve.value.args[0]\n\n\ndef test_calibrate_scattering_filters():\n    """"""\n    Various tests on the central frequencies xi and spectral width sigma\n    computed for the scattering filterbank\n    - Checks that all widths are > 0\n    - Check that sigma_low is smaller than all sigma2\n    """"""\n    J_range = np.arange(2, 11)\n    Q_range = np.arange(1, 21, dtype=int)\n    for J in J_range:\n        for Q in Q_range:\n            sigma_low, xi1, sigma1, j1, xi2, sigma2, j2 = \\\n                calibrate_scattering_filters( J, Q)\n            # Check that all sigmas are > 0\n            assert sigma_low > 0\n            for sig in sigma1:\n                assert sig > 0\n            for sig in sigma2:\n                assert sig > 0\n            # check that sigma_low is smaller than all sigma2\n            for sig in sigma1:\n                assert sig >= sigma_low\n            for sig in sigma2:\n                assert sig >= sigma_low\n\n    with pytest.raises(ValueError) as ve:\n        calibrate_scattering_filters(J_range[0], 0.9)\n    assert ""should always be >= 1"" in ve.value.args[0]\n\n\ndef test_compute_xi_max():\n    """"""\n    Tests that 0.25 <= xi_max(Q) <= 0.5, whatever Q\n    """"""\n    Q_range = np.arange(1, 21, dtype=int)\n    for Q in Q_range:\n        xi_max = compute_xi_max(Q)\n        assert xi_max <= 0.5\n        assert xi_max >= 0.25\n\n\ndef test_get_max_dyadic_subsampling():\n    """"""\n    Tests on the subsampling formula for wavelets, to check that the retained\n    value does not create aliasing (the wavelet should have decreased by\n    a relative value of 1e-2 at the border of the aliasing.)\n    """"""\n    N = 2**12\n    Q_range = np.arange(1, 20, dtype=int)\n    J = 7\n    for Q in Q_range:\n        xi_max = compute_xi_max(Q)\n        xi_range = xi_max * np.power(0.5, np.arange(J * Q) / float(Q))\n        for xi in xi_range:\n            sigma = compute_sigma_psi(xi, Q)\n            j = get_max_dyadic_subsampling(xi, sigma)\n            # Check for subsampling. If there is no subsampling, the filters\n            # cannot be aliased, so no need to check them.\n            if j > 0:\n                # compute the corresponding Morlet\n                psi_f = morlet_1d(N, xi, sigma)\n                # find the integer k such that\n                k = N // 2**(j + 1)\n                assert np.abs(psi_f[k]) / np.max(np.abs(psi_f)) < 1e-2\n\n\ndef test_compute_temporal_support():\n    # Define constant averaging filter. This will be ""too long"" to avoid\n    # border effects.\n    h_f = np.fft.fft(np.ones((1, 4)), axis=1)\n    with pytest.warns(UserWarning) as record:\n        compute_temporal_support(h_f)\n    assert ""too small to avoid border effects"" in record[0].message.args[0]\n'"
tests/scattering1d/test_numpy_scattering1d.py,2,"b'import pytest\nfrom kymatio import Scattering1D\nimport os\nimport numpy as np\nimport io\n\nbackends = []\n\nfrom kymatio.scattering1d.backend.numpy_backend import backend\nbackends.append(backend)\n\nclass TestScattering1DNumpy:\n    @pytest.mark.parametrize(\'backend\', backends)\n    def test_Scattering1D(self, backend):\n        """"""\n        Applies scattering on a stored signal to make sure its output agrees with\n        a previously calculated version.\n        """"""\n        test_data_dir = os.path.dirname(__file__)\n\n        with open(os.path.join(test_data_dir, \'test_data_1d.npz\'), \'rb\') as f:\n            buffer = io.BytesIO(f.read())\n            data = np.load(buffer)\n\n        x = data[\'x\']\n        J = data[\'J\']\n        Q = data[\'Q\']\n        Sx0 = data[\'Sx\']\n\n        T = x.shape[-1]\n\n        scattering = Scattering1D(J, T, Q, backend=backend, frontend=\'numpy\')\n\n        Sx = scattering(x)\n        assert np.allclose(Sx, Sx0)\n'"
tests/scattering1d/test_tensorflow_scattering1d.py,2,"b'import pytest\nfrom kymatio import Scattering1D\nimport os\nimport numpy as np\nimport io\n\n\nbackends = []\n\nfrom kymatio.scattering1d.backend.tensorflow_backend import backend\nbackends.append(backend)\n\n\nclass TestScattering1DTensorFlow:\n    @pytest.mark.parametrize(\'backend\', backends)\n    def test_Scattering1D(self, backend):\n        """"""\n        Applies scattering on a stored signal to make sure its output agrees with\n        a previously calculated version.\n        """"""\n        test_data_dir = os.path.dirname(__file__)\n\n        with open(os.path.join(test_data_dir, \'test_data_1d.npz\'), \'rb\') as f:\n            buffer = io.BytesIO(f.read())\n            data = np.load(buffer)\n\n        x = data[\'x\']\n        J = data[\'J\']\n        Q = data[\'Q\']\n        Sx0 = data[\'Sx\']\n\n        T = x.shape[-1]\n\n        scattering = Scattering1D(J, T, Q, backend=backend, frontend=\'tensorflow\')\n\n        Sx = scattering(x)\n        assert np.allclose(Sx, Sx0, atol=1e-6, rtol =1e-7)\n'"
tests/scattering1d/test_torch_scattering1d.py,7,"b'import pytest\nimport torch\nfrom kymatio import Scattering1D\nimport math\nimport os\nimport io\nimport numpy as np\n\n\nbackends = []\n\nskcuda_available = False\ntry:\n    if torch.cuda.is_available():\n        from skcuda import cublas\n        import cupy\n        skcuda_available = True\nexcept:\n    Warning(\'torch_skcuda backend not available.\')\n\nif skcuda_available:\n    from kymatio.scattering1d.backend.torch_skcuda_backend import backend\n    backends.append(backend)\n\nfrom kymatio.scattering1d.backend.torch_backend import backend\nbackends.append(backend)\n\nif torch.cuda.is_available():\n    devices = [\'cuda\', \'cpu\']\nelse:\n    devices = [\'cpu\']\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_simple_scatterings(device, backend, random_state=42):\n    """"""\n    Checks the behaviour of the scattering on simple signals\n    (zero, constant, pure cosine)\n    """"""\n\n    rng = np.random.RandomState(random_state)\n    J = 6\n    Q = 8\n    T = 2**9\n    scattering = Scattering1D(J, T, Q, backend=backend, frontend=\'torch\').to(device)\n    return\n\n    # zero signal\n    x0 = torch.zeros(2, T).to(device)\n\n    if backend.name == \'torch_skcuda\' and device == \'cpu\':\n        with pytest.raises(TypeError) as ve:\n            s = scattering(x0)\n        assert ""CPU"" in ve.value.args[0]\n        return\n    s = scattering(x0)\n\n    # check that s is zero!\n    assert torch.max(torch.abs(s)) < 1e-7\n\n    # constant signal\n    x1 = rng.randn(1)[0] * torch.ones(1, T).to(device)\n    if backend.name != \'torch_skcuda\' or device != \'cpu\':\n        s1 = scattering(x1)\n\n        # check that all orders above 1 are 0\n        assert torch.max(torch.abs(s1[:, 1:])) < 1e-7\n\n    # sinusoid scattering\n    meta = scattering.meta()\n    for _ in range(3):\n        k = rng.randint(1, T // 2, 1)[0]\n        x2 = torch.cos(2 * math.pi * float(k) * torch.arange(0, T, dtype=torch.float32) / float(T))\n        x2 = x2.unsqueeze(0).to(device)\n        if backend.name != \'torch_skcuda\' or device != \'cpu\':\n            s2 = scattering(x2)\n\n            assert(s2[:,torch.from_numpy(meta[\'order\']) != 1,:].abs().max() < 1e-2)\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_sample_scattering(device, backend):\n    """"""\n    Applies scattering on a stored signal to make sure its output agrees with\n    a previously calculated version.\n    """"""\n    test_data_dir = os.path.dirname(__file__)\n\n    with open(os.path.join(test_data_dir, \'test_data_1d.npz\'), \'rb\') as f:\n        buffer = io.BytesIO(f.read())\n        data = np.load(buffer)\n\n\n    x = torch.from_numpy(data[\'x\']).to(device)\n    J = data[\'J\']\n    Q = data[\'Q\']\n    Sx0 = torch.from_numpy(data[\'Sx\']).to(device)\n\n    T = x.shape[-1]\n\n    scattering = Scattering1D(J, T, Q, backend=backend, frontend=\'torch\').to(device)\n\n    if backend.name == \'torch_skcuda\' and device == \'cpu\':\n        with pytest.raises(TypeError) as ve:\n            Sx = scattering(x)\n        assert ""CPU"" in ve.value.args[0]\n        return\n\n    Sx = scattering(x)\n    assert torch.allclose(Sx, Sx0)\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_computation_Ux(backend, device, random_state=42):\n    """"""\n    Checks the computation of the U transform (no averaging for 1st order)\n    """"""\n    rng = np.random.RandomState(random_state)\n    J = 6\n    Q = 8\n    T = 2**12\n    scattering = Scattering1D(J, T, Q, average=False,\n                              max_order=1, vectorize=False, frontend=\'torch\', backend=backend).to(device)\n    # random signal\n    x = torch.from_numpy(rng.randn(1, T)).float().to(device)\n\n    if backend.name != \'torch_skcuda\' or device != \'cpu\':\n        s = scattering(x)\n\n        # check that the keys in s correspond to the order 0 and second order\n        for k in range(len(scattering.psi1_f)):\n            assert (k,) in s.keys()\n        for k in s.keys():\n            if k is not ():\n                assert k[0] < len(scattering.psi1_f)\n            else:\n                assert True\n\n        scattering.max_order = 2\n\n        s = scattering(x)\n\n        count = 1\n        for k1, filt1 in enumerate(scattering.psi1_f):\n            assert (k1,) in s.keys()\n            count += 1\n            for k2, filt2 in enumerate(scattering.psi2_f):\n                if filt2[\'j\'] > filt1[\'j\']:\n                    assert (k1, k2) in s.keys()\n                    count += 1\n\n        assert count == len(s)\n\n        with pytest.raises(ValueError) as ve:\n            scattering.vectorize = True\n            scattering(x)\n        assert ""mutually incompatible"" in ve.value.args[0]\n\n\n# Technical tests\n@pytest.mark.parametrize(""backend"", backends)\ndef test_scattering_GPU_CPU(backend, random_state=42):\n    """"""\n    This function tests whether the CPU computations are equivalent to\n    the GPU ones\n    """"""\n    if torch.cuda.is_available() and backend.name != \'torch_skcuda\':\n        torch.manual_seed(random_state)\n\n        J = 6\n        Q = 8\n        T = 2**12\n\n        # build the scattering\n        scattering = Scattering1D(J, T, Q, backend=backend, frontend=\'torch\').cpu()\n\n        x = torch.randn(2, T)\n        s_cpu = scattering(x)\n\n        scattering = scattering.cuda()\n        x_gpu = x.clone().cuda()\n        s_gpu = scattering(x_gpu).cpu()\n        # compute the distance\n\n        Warning(\'Tolerance has been slightly lowered here...\')\n        assert torch.allclose(s_cpu, s_gpu, atol=1e-7)\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_coordinates(device, backend, random_state=42):\n    """"""\n    Tests whether the coordinates correspond to the actual values (obtained\n    with Scattering1d.meta()), and with the vectorization\n    """"""\n\n    torch.manual_seed(random_state)\n    J = 6\n    Q = 8\n    T = 2**12\n\n    scattering = Scattering1D(J, T, Q, max_order=2, backend=backend, frontend=\'torch\')\n\n    x = torch.randn(2, T)\n\n    scattering.to(device)\n    x = x.to(device)\n\n    for max_order in [1, 2]:\n        scattering.max_order = max_order\n\n        scattering.vectorize = False\n\n        if backend.name == \'torch_skcuda\' and device == \'cpu\':\n            with pytest.raises(TypeError) as ve:\n                s_dico = scattering(x)\n            assert ""CPU"" in ve.value.args[0]\n        else:\n            s_dico = scattering(x)\n            s_dico = {k: s_dico[k].data for k in s_dico.keys()}\n        scattering.vectorize = True\n\n        if backend.name == \'torch_skcuda\' and device == \'cpu\':\n            with pytest.raises(TypeError) as ve:\n                s_vec = scattering(x)\n            assert ""CPU"" in ve.value.args[0]\n        else:\n            s_vec = scattering(x)\n            s_dico = {k: s_dico[k].cpu() for k in s_dico.keys()}\n            s_vec = s_vec.cpu()\n\n        meta = scattering.meta()\n\n        if backend.name != \'torch_skcuda\' or device != \'cpu\':\n            assert len(s_dico) == s_vec.shape[1]\n\n            for cc in range(s_vec.shape[1]):\n                k = meta[\'key\'][cc]\n                assert torch.allclose(s_vec[:, cc], torch.squeeze(s_dico[k]))\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_precompute_size_scattering(device, backend, random_state=42):\n    """"""\n    Tests that precompute_size_scattering computes a size which corresponds\n    to the actual scattering computed\n    """"""\n    torch.manual_seed(random_state)\n\n    J = 6\n    Q = 8\n    T = 2**12\n\n    scattering = Scattering1D(J, T, Q, vectorize=False, backend=backend, frontend=\'torch\')\n\n    x = torch.randn(2, T)\n\n    scattering.to(device)\n    x = x.to(device)\n    if backend.name != \'torch_skcuda\' or device != \'cpu\':\n        for max_order in [1, 2]:\n            scattering.max_order = max_order\n            s_dico = scattering(x)\n            for detail in [True, False]:\n                # get the size of scattering\n                size = scattering.output_size(detail=detail)\n                if detail:\n                    num_orders = {0: 0, 1: 0, 2: 0}\n                    for k in s_dico.keys():\n                        if k is ():\n                            num_orders[0] += 1\n                        else:\n                            if len(k) == 1:  # order1\n                                num_orders[1] += 1\n                            elif len(k) == 2:\n                                num_orders[2] += 1\n                    todo = 2 if max_order == 2 else 1\n                    for i in range(todo):\n                        assert num_orders[i] == size[i]\n                        # check that the orders are completely equal\n                else:\n                    assert len(s_dico) == size\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_differentiability_scattering(device, backend, random_state=42):\n    """"""\n    It simply tests whether it is really differentiable or not.\n    This does NOT test whether the gradients are correct.\n    """"""\n\n    if backend.name == ""torch_skcuda"":\n        pytest.skip(""The skcuda backend does not pass differentiability""\n            ""tests, but that\'s ok (for now)."")\n\n    torch.manual_seed(random_state)\n\n    J = 6\n    Q = 8\n    T = 2**12\n\n    scattering = Scattering1D(J, T, Q, frontend=\'torch\', backend=backend).to(device)\n\n    x = torch.randn(2, T, requires_grad=True, device=device)\n\n    s = scattering.forward(x)\n    loss = torch.sum(torch.abs(s))\n    loss.backward()\n    assert torch.max(torch.abs(x.grad)) > 0.\n\n\n@pytest.mark.parametrize(""backend"", backends)\ndef test_scattering_shape_input(backend):\n    # Checks that a wrong input to shape raises an error\n    J, Q = 6, 8\n    with pytest.raises(ValueError) as ve:\n        shape = 5, 6\n        s = Scattering1D(J, shape, Q, backend=backend, frontend=\'torch\')\n    assert ""exactly one element"" in ve.value.args[0]\n\n\n    with pytest.raises(ValueError) as ve:\n        shape = 1.5\n        s = Scattering1D(J, shape, Q, backend=backend, frontend=\'torch\')\n        # should invoke the else branch\n    assert ""1-tuple"" in ve.value.args[0]\n    assert ""integer"" in ve.value.args[0]\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_batch_shape_agnostic(device, backend):\n    J, Q = 3, 8\n    length = 1024\n    shape = (length,)\n\n    length_ds = length / 2**J\n\n    S = Scattering1D(J, shape, Q, backend=backend, frontend=\'torch\').to(device)\n\n    with pytest.raises(ValueError) as ve:\n        S(torch.zeros(()).to(device))\n    assert ""at least one axis"" in ve.value.args[0]\n\n    x = torch.zeros(shape).to(device)\n\n    if backend.name == \'torch_skcuda\' and device == \'cpu\':\n        with pytest.raises(TypeError) as ve:\n            Sx = S(x)\n        assert ""CPU"" in ve.value.args[0]\n        return\n\n    Sx = S(x)\n\n    assert Sx.dim() == 2\n    assert Sx.shape[-1] == length_ds\n\n    n_coeffs = Sx.shape[-2]\n\n    test_shapes = ((1,) + shape, (2,) + shape, (2,2) + shape, (2,2,2) + shape)\n\n    for test_shape in test_shapes:\n        x = torch.zeros(test_shape).to(device)\n\n        S.vectorize = True\n        Sx = S(x)\n\n        assert Sx.dim() == len(test_shape)+1\n        assert Sx.shape[-1] == length_ds\n        assert Sx.shape[-2] == n_coeffs\n        assert Sx.shape[:-2] == test_shape[:-1]\n\n        S.vectorize = False\n        Sx = S(x)\n\n        assert len(Sx) == n_coeffs\n        for k, v in Sx.items():\n            assert v.shape[-1] == length_ds\n            assert v.shape[-2] == 1\n            assert v.shape[:-2] == test_shape[:-1]\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_pad_1d(device, backend, random_state=42):\n    """"""\n    Tests the correctness and differentiability of pad_1d\n    """"""\n    torch.manual_seed(random_state)\n    N = 128\n    for pad_left in range(0, N - 16, 16):\n        for pad_right in [pad_left, pad_left + 16]:\n            x = torch.randn(2, 4, N, requires_grad=True, device=device)\n            x_pad = backend.pad_1d(x, pad_left, pad_right, mode=\'reflect\')\n            # Check the size\n            x2 = x.clone()\n            x_pad2 = x_pad.clone()\n            for t in range(1, pad_left + 1):\n                assert torch.allclose(x_pad2[..., pad_left - t],x2[..., t])\n            for t in range(x2.shape[-1]):\n                assert torch.allclose(x_pad2[..., pad_left + t], x2[..., t])\n            for t in range(1, pad_right + 1):\n                assert torch.allclose(x_pad2[..., x_pad.shape[-1] - 1 - pad_right + t], x2[..., x.shape[-1] - 1 - t])\n            # check the differentiability\n            loss = 0.5 * torch.sum(x_pad**2)\n            loss.backward()\n            # compute the theoretical gradient for x\n            x_grad_original = x.clone()\n            x_grad = x_grad_original.new(x_grad_original.shape).fill_(0.)\n            x_grad += x_grad_original\n            for t in range(1, pad_left + 1):\n                x_grad[..., t] += x_grad_original[..., t]\n            for t in range(1, pad_right + 1):  # it is counted twice!\n                t0 = x.shape[-1] - 1 - t\n                x_grad[..., t0] += x_grad_original[..., t0]\n            # get the difference\n            assert torch.allclose(x.grad, x_grad)\n    # Check that the padding shows an error if we try to pad\n    with pytest.raises(ValueError):\n        backend.pad_1d(x, x.shape[-1], 0, mode=\'reflect\')\n    with pytest.raises(ValueError):\n        backend.pad_1d(x, 0, x.shape[-1], mode=\'reflect\')\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_modulus(device, backend, random_state=42):\n    """"""\n    Tests the stability and differentiability of modulus\n    """"""\n    torch.manual_seed(random_state)\n    # Test with a random vector\n    x = torch.randn(2, 4, 128, 2, requires_grad=True, device=device)\n\n    if backend.name == \'torch_skcuda\' and device == \'cpu\':\n        # If we are using a GPU-only backend, make sure it raises the proper\n        # errors for CPU tensors.\n        with pytest.raises(TypeError) as re:\n            x_bad = torch.randn((4, 2)).cpu()\n            backend.modulus_complex(x_bad)\n        assert ""for CPU tensors"" in re.value.args[0]\n        return\n\n\n    x_abs = backend.modulus_complex(x)\n\n    assert len(x_abs.shape) == len(x.shape)\n    # check the value\n    x_abs2 = x_abs.clone()\n    x2 = x.clone()\n    assert torch.allclose(x_abs2[..., 0], torch.sqrt(x2[..., 0]**2 + x2[..., 1]**2))\n\n    with pytest.raises(TypeError) as te:\n        x_bad = torch.randn(4).to(device)\n        backend.modulus_complex(x_bad)\n    assert ""should be complex"" in te.value.args[0]\n\n    if backend.name == ""torch_skcuda"":\n        pytest.skip(""The skcuda backend does not pass differentiability""\n            ""tests, but that\'s ok (for now)."")\n\n    # check the gradient\n    loss = torch.sum(x_abs)\n    loss.backward()\n    x_grad = x2 / x_abs2[..., 0].unsqueeze(dim=-1)\n    assert torch.allclose(x.grad, x_grad)\n\n\n    # Test the differentiation with a vector made of zeros\n    x0 = torch.zeros(100, 4, 128, 2, requires_grad=True, device=device)\n    x_abs0 = backend.modulus_complex(x0)\n    loss0 = torch.sum(x_abs0)\n    loss0.backward()\n    assert torch.max(torch.abs(x0.grad)) <= 1e-7\n\n\n@pytest.mark.parametrize(""backend"", backends)\n@pytest.mark.parametrize(""device"", devices)\ndef test_subsample_fourier(backend, device, random_state=42):\n    """"""\n    Tests whether the periodization in Fourier performs a good subsampling\n    in time\n    """"""\n    if backend.name == \'torch_skcuda\' and device == \'cpu\':\n        with pytest.raises(TypeError) as re:\n            x_bad = torch.randn((4, 2)).cpu()\n            backend.subsample_fourier(x_bad, 1)\n        assert ""for CPU tensors"" in re.value.args[0]\n        return\n    rng = np.random.RandomState(random_state)\n    J = 10\n    x = rng.randn(2, 4, 2**J) + 1j * rng.randn(2, 4, 2**J)\n    x_f = np.fft.fft(x, axis=-1)[..., np.newaxis]\n    x_f.dtype = \'float64\'  # make it a vector\n    x_f_th = torch.from_numpy(x_f).to(device)\n\n    for j in range(J + 1):\n        x_f_sub_th = backend.subsample_fourier(x_f_th, 2**j).cpu()\n        x_f_sub = x_f_sub_th.numpy()\n        x_f_sub.dtype = \'complex128\'\n        x_sub = np.fft.ifft(x_f_sub[..., 0], axis=-1)\n        assert np.allclose(x[:, :, ::2**j], x_sub)\n\n    # If we are using a GPU-only backend, make sure it raises the proper\n    # errors for CPU tensors.\n    if device==\'cuda\':\n        with pytest.raises(TypeError) as te:\n            x_bad = torch.randn(4).cuda()\n            backend.subsample_fourier(x_bad, 1)\n        assert ""should be complex"" in te.value.args[0]\n'"
tests/scattering1d/test_utils_scattering1d.py,5,"b'import numpy as np\nimport pytest\nfrom kymatio import Scattering1D\nfrom kymatio.scattering1d.frontend.torch_frontend import ScatteringTorch1D\nfrom kymatio.scattering1d.utils import compute_border_indices, compute_padding\n\n\ndef test_compute_padding():\n    """"""\n    Test the compute_padding function\n    """"""\n\n    pad_left, pad_right = compute_padding(5, 16)\n    assert pad_left == 8 and pad_right == 8\n\n    with pytest.raises(ValueError) as ve:\n        _, _ = compute_padding(3, 16)\n    assert ""should be larger"" in ve.value.args[0]\n\n    with pytest.raises(ValueError) as ve:\n        _, _ = compute_padding(6, 16)\n    assert ""Too large padding value"" in ve.value.args[0]\n\n\ndef test_border_indices(random_state=42):\n    """"""\n    Tests whether the border indices to unpad are well computed\n    """"""\n    rng = np.random.RandomState(random_state)\n    J_signal = 10  # signal lives in 2**J_signal\n    J = 6  # maximal subsampling\n\n    T = 2**J_signal\n\n    i0 = rng.randint(0, T // 2 + 1, 1)[0]\n    i1 = rng.randint(i0 + 1, T, 1)[0]\n\n    x = np.ones(T)\n    x[i0:i1] = 0.\n\n    ind_start, ind_end = compute_border_indices(J, i0, i1)\n\n    for j in range(J + 1):\n        assert j in ind_start.keys()\n        assert j in ind_end.keys()\n        x_sub = x[::2**j]\n        # check that we did take the strict interior\n        assert np.max(x_sub[ind_start[j]:ind_end[j]]) == 0.\n        # check that we have not forgotten points\n        if ind_start[j] > 0:\n            assert np.min(x_sub[:ind_start[j]]) > 0.\n        if ind_end[j] < x_sub.shape[-1]:\n            assert np.min(x_sub[ind_end[j]:]) > 0.\n\n\n# Check that the default frontend is numpy and that errors are correctly launched.\ndef test_scattering1d_frontend():\n    scattering = Scattering1D(2, shape=(10, ))\n    assert isinstance(scattering, ScatteringTorch1D), \'could not be correctly imported\'\n\n    with pytest.raises(RuntimeError) as ve:\n        scattering = Scattering1D(2, shape=(10,), frontend=\'doesnotexist\')\n    assert ""is not valid"" in ve.value.args[0]\n'"
tests/scattering2d/test_frontend_scattering2d.py,0,"b'import pytest\n\nfrom kymatio import Scattering2D\nfrom kymatio.scattering2d.frontend.torch_frontend import ScatteringTorch2D\n\n# Check that the default frontend is Torch and that errors are correctly launched.\ndef test_scattering2d_frontend():\n    scattering = Scattering2D(2, shape=(10, 10))\n    assert isinstance(scattering, ScatteringTorch2D), \'Torch frontend is not selected by default\'\n\n    with pytest.raises(RuntimeError) as ve:\n        scattering = Scattering2D(2, shape=(10, 10), frontend=\'doesnotexist\')\n    assert ""is not valid"" in ve.value.args[0]\n\n# Check the default backend is Torch and that errors are correctly launched.\ndef test_scattering2d_backend():\n    with pytest.raises(ImportError) as ve:\n        scattering = Scattering2D(2, shape=(10, 10), backend=\'doesnotexist\')\n    assert ""can not be called"" in ve.value.args[0]\n'"
tests/scattering2d/test_keras_scattering2d.py,2,"b""import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense\nfrom kymatio.keras import Scattering2D\nimport os, io\nimport numpy as np\n\ndef test_Scattering2D():\n    test_data_dir = os.path.dirname(__file__)\n    data = None\n    with open(os.path.join(test_data_dir, 'test_data_2d.npz'), 'rb') as f:\n        buffer = io.BytesIO(f.read())\n        data = np.load(buffer)\n\n    x = data['x']\n    S = data['Sx']\n    J = data['J']\n    pre_pad = data['pre_pad']\n\n    M = x.shape[2]\n    N = x.shape[3]\n\n    inputs = Input(shape=(3, M, N))\n    scat = Scattering2D(J=J)(inputs)\n\n    model = Model(inputs, scat)\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n\n    x = x\n    S = S\n    Sg = model.predict(x)\n    assert np.allclose(Sg, S)\n"""
tests/scattering2d/test_numpy_scattering2d.py,46,"b""import os\nimport io\nimport numpy as np\nfrom kymatio import Scattering2D\nfrom collections import namedtuple\nimport pytest\n\n\nbackends = []\n\nfrom kymatio.scattering2d.backend.numpy_backend import backend\nbackends.append(backend)\n\n\nclass TestPad:\n    @pytest.mark.parametrize('backend', backends)\n    def test_Pad(self, backend):\n        pad = backend.Pad((2, 2, 2, 2), (4, 4), pre_pad=False)\n\n        x = np.random.randn(4, 4) + 1J * np.random.randn(4, 4)\n        x = x[np.newaxis, ...]\n\n        z = pad(x)\n\n        assert z.shape == (1, 8, 8)\n        assert z[0, 2, 2] == x[0, 0, 0]\n        assert z[0, 1, 0] == x[0, 1, 2]\n        assert z[0, 1, 1] == x[0, 1, 1]\n        assert z[0, 1, 2] == x[0, 1, 0]\n        assert z[0, 1, 3] == x[0, 1, 1]\n\n        pad = backend.Pad((2, 2, 2, 2), (4, 4), pre_pad=True)\n\n        x = np.random.randn(8, 8) + 1J * np.random.randn(8, 8)\n\n        z = pad(x)\n\n        assert np.allclose(x, z)\n\n    @pytest.mark.parametrize('backend', backends)\n    def test_unpad(self, backend):\n        x = np.random.randn(4, 4) + 1J * np.random.randn(4, 4)\n\n        y = backend.unpad(x)\n\n        assert y.shape == (2, 2)\n        assert y[0, 0] == x[1, 1]\n        assert y[0, 1] == x[1, 2]\n\n\nclass TestModulus:\n    @pytest.mark.parametrize('backend', backends)\n    def test_Modulus(self, backend):\n        modulus = backend.modulus\n\n        x = np.random.rand(100, 10, 4) + 1J * np.random.rand(100, 10, 4)\n\n        y = modulus(x)\n        u = np.squeeze(np.sqrt(np.real(x) ** 2 + np.imag(x) ** 2))\n        v = y\n        assert np.allclose(u, v)\n\n\nclass TestSubsampleFourier:\n    @pytest.mark.parametrize('backend', backends)\n    def test_SubsampleFourier(self, backend):\n        subsample_fourier = backend.subsample_fourier\n\n        x = (np.random.rand(100, 128, 128)\n             + 1J * np.random.rand(100, 128, 128))\n\n        y = np.zeros((100, 8, 8), dtype=np.complex128)\n\n        from itertools import product\n        for i, j in product(range(8), range(8)):\n            for m, n in product(range(16), range(16)):\n                y[..., i, j] += x[..., i + m * 8, j + n * 8]\n\n        y /= 16 ** 2\n\n        z = subsample_fourier(x, k=16)\n        assert np.allclose(y, z)\n\n\nclass TestCDGMM:\n    @pytest.fixture(params=(False, True))\n    def data(self, request):\n        real_filter = request.param\n        x = (np.random.randn(100, 128, 128)\n             + 1J * np.random.randn(100, 128, 128))\n        filt = (np.random.randn(128, 128)\n                + 1J * np.random.randn(128, 128))\n        y = (np.random.randn(100, 128, 128)\n             + 1J * np.random.randn(100, 128, 128))\n\n        if real_filter:\n            filt = np.real(filt)\n\n        y = x * filt\n\n        return x, filt, y\n\n    @pytest.mark.parametrize('backend', backends)\n    @pytest.mark.parametrize('inplace', (False, True))\n    def test_cdgmm_forward(self, data, backend, inplace):\n        x, filt, y = data\n\n        z = backend.cdgmm(x, filt, inplace=inplace)\n\n        assert np.allclose(y, z)\n\n    @pytest.mark.parametrize('backend', backends)\n    def test_cdgmm_exceptions(self, backend):\n        with pytest.raises(TypeError) as record:\n            backend.cdgmm(np.empty((3, 4, 5)).astype(np.float64),\n                          np.empty((4, 5)).astype(np.complex128))\n        assert 'first input must be complex' in record.value.args[0]\n\n        with pytest.raises(TypeError) as record:\n            backend.cdgmm(np.empty((3, 4, 5)).astype(np.complex128),\n                          np.empty((4, 5)).astype(np.int64))\n        assert 'second input must be complex or real' in record.value.args[0]\n\n        with pytest.raises(RuntimeError) as record:\n            backend.cdgmm(np.empty((3, 4, 5)).astype(np.complex128),\n                          np.empty((4, 6)).astype(np.complex128))\n        assert 'not compatible for multiplication' in record.value.args[0]\n\n\nclass TestFFT:\n    @pytest.mark.parametrize('backend', backends)\n    def test_fft(self, backend):\n        x = np.random.randn(2, 2) + 1J * np.random.randn(2, 2)\n\n        y = np.array([[x[0, 0] + x[0, 1] + x[1, 0] + x[1, 1],\n                       x[0, 0] - x[0, 1] + x[1, 0] - x[1, 1]],\n                      [x[0, 0] + x[0, 1] - x[1, 0] - x[1, 1],\n                       x[0, 0] - x[0, 1] - x[1, 0] + x[1, 1]]])\n\n        z = backend.fft(x, direction='C2C')\n\n        assert np.allclose(y, z)\n\n        z = backend.fft(x, direction='C2C', inverse=True)\n\n        z = z * 4\n\n        assert np.allclose(y, z)\n\n        z = backend.fft(x, direction='C2R', inverse=True)\n\n        z = z * 4\n\n        assert not np.iscomplexobj(z)\n        assert np.allclose(np.real(y), z)\n\n\n    @pytest.mark.parametrize('backend', backends)\n    def test_fft_exceptions(self, backend):\n        with pytest.raises(RuntimeError) as record:\n            backend.fft(np.empty((2, 2)), direction='C2R',\n                        inverse=False)\n        assert 'done with an inverse' in record.value.args[0]\n\n\nclass TestBackendUtils:\n    @pytest.mark.parametrize('backend', backends)\n    def test_concatenate(self, backend):\n        x = np.random.randn(3, 6, 6) + 1J * np.random.randn(3, 6, 6)\n        y = np.random.randn(3, 6, 6) + 1J * np.random.randn(3, 6, 6)\n        z = np.random.randn(3, 6, 6) + 1J * np.random.randn(3, 6, 6)\n\n        w = backend.concatenate((x, y, z))\n\n        assert w.shape == (x.shape[0],) + (3,) + (x.shape[-2:])\n        assert np.allclose(w[:, 0, ...], x)\n        assert np.allclose(w[:, 1, ...], y)\n        assert np.allclose(w[:, 2, ...], z)\n\n\nclass TestScattering2DNumpy:\n    @pytest.mark.parametrize('backend', backends)\n    def test_Scattering2D(self, backend):\n        test_data_dir = os.path.dirname(__file__)\n        data = None\n        with open(os.path.join(test_data_dir, 'test_data_2d.npz'), 'rb') as f:\n            buffer = io.BytesIO(f.read())\n            data = np.load(buffer)\n\n        x = data['x']\n        S = data['Sx']\n        J = data['J']\n        pre_pad = data['pre_pad']\n\n        M = x.shape[2]\n        N = x.shape[3]\n\n        scattering = Scattering2D(J, shape=(M, N), pre_pad=pre_pad,\n                                  frontend='numpy', backend=backend)\n\n        x = x\n        S = S\n        Sg = scattering(x)\n        assert np.allclose(Sg, S)\n\n        scattering = Scattering2D(J, shape=(M, N), pre_pad=pre_pad,\n                                  max_order=1, frontend='numpy',\n                                  backend=backend)\n\n        S1x = scattering(x)\n        assert np.allclose(S1x, S[..., :S1x.shape[-3], :, :])\n\n    @pytest.mark.parametrize('backend', backends)\n    def test_batch_shape_agnostic(self, backend):\n        J = 3\n        L = 8\n        shape = (32, 32)\n\n        shape_ds = tuple(n // (2 ** J) for n in shape)\n\n        S = Scattering2D(J, shape, L, backend=backend, frontend='numpy')\n\n        x = np.zeros(shape)\n\n        Sx = S(x)\n\n        assert len(Sx.shape) == 3\n        assert Sx.shape[-2:] == shape_ds\n\n        n_coeffs = Sx.shape[-3]\n\n        test_shapes = ((1,) + shape, (2,) + shape, (2, 2) + shape,\n                       (2, 2, 2) + shape)\n\n        for test_shape in test_shapes:\n            x = np.zeros(test_shape)\n\n            Sx = S(x)\n\n            assert len(Sx.shape) == len(test_shape) + 1\n            assert Sx.shape[-2:] == shape_ds\n            assert Sx.shape[-3] == n_coeffs\n            assert Sx.shape[:-3] == test_shape[:-2]\n\n    @pytest.mark.parametrize('backend', backends)\n    def test_scattering2d_errors(self, backend):\n        S = Scattering2D(3, (32, 32), frontend='numpy', backend=backend)\n\n        with pytest.raises(TypeError) as record:\n            S(None)\n        assert 'input should be' in record.value.args[0]\n\n        x = np.random.randn(32)\n\n        with pytest.raises(RuntimeError) as record:\n            S(x)\n        assert 'have at least two dimensions' in record.value.args[0]\n\n        x = np.random.randn(31, 31)\n\n        with pytest.raises(RuntimeError) as record:\n            S(x)\n        assert 'NumPy array must be of spatial size' in record.value.args[0]\n\n        S = Scattering2D(3, (32, 32), pre_pad=True, frontend='numpy',\n                         backend=backend)\n\n        with pytest.raises(RuntimeError) as record:\n            S(x)\n        assert 'Padded array must be of spatial size' in record.value.args[0]\n\n\n    def test_inputs(self):\n        fake_backend = namedtuple('backend', ['name',])\n        fake_backend.name = 'fake'\n\n        with pytest.raises(ImportError) as ve:\n            scattering = Scattering2D(2, shape=(10, 10), frontend='numpy', backend=fake_backend)\n        assert 'not supported' in ve.value.args[0]\n\n        with pytest.raises(RuntimeError) as ve:\n            scattering = Scattering2D(10, shape=(10, 10), frontend='numpy')\n        assert 'smallest dimension' in ve.value.args[0]\n"""
tests/scattering2d/test_sklearn_2d.py,2,"b""import os\nimport io\nimport numpy as np\n\nfrom kymatio.sklearn import Scattering2D as ScatteringTransformer2D\nfrom kymatio.numpy import Scattering2D as ScatteringNumPy2D\n\ndef test_sklearn_transformer():\n    test_data_dir = os.path.join(os.path.dirname(__file__))\n\n    with open(os.path.join(test_data_dir, 'test_data_2d.npz'), 'rb') as f:\n        buf = io.BytesIO(f.read())\n        data = np.load(buf)\n\n    x = data['x']\n    J = data['J']\n\n    S = ScatteringNumPy2D(J, x.shape[2:])\n    Sx = S.scattering(x)\n\n    x_raveled = x.reshape(x.shape[0], -1)\n    Sx_raveled = Sx.reshape(x.shape[0], -1)\n\n    st = ScatteringTransformer2D(J, x.shape[2:])\n\n    t = st.transform(x_raveled)\n\n    assert np.allclose(Sx_raveled, t)\n"""
tests/scattering2d/test_tensorflow_scattering2d.py,53,"b""import os\nimport io\nfrom kymatio import Scattering2D\nimport numpy as np\nimport pytest\nfrom collections import namedtuple\n\nbackends = []\n\nfrom kymatio.scattering2d.backend.tensorflow_backend import backend\nbackends.append(backend)\n\nclass TestPad:\n    @pytest.mark.parametrize('backend', backends)\n    def test_Pad(self, backend):\n        pad = backend.Pad((2, 2, 2, 2), (4, 4), pre_pad=False)\n\n        x = np.random.randn(4, 4) + 1J * np.random.randn(4, 4)\n        x = x[np.newaxis, ...]\n\n        z = pad(x)\n\n        assert z.shape == (1, 8, 8)\n        assert np.isclose(z[0, 2, 2], x[0, 0, 0])\n        assert np.isclose(z[0, 1, 0], x[0, 1, 2])\n        assert np.isclose(z[0, 1, 1], x[0, 1, 1])\n        assert np.isclose(z[0, 1, 2], x[0, 1, 0])\n        assert np.isclose(z[0, 1, 3], x[0, 1, 1])\n\n        pad = backend.Pad((2, 2, 2, 2), (4, 4), pre_pad=True)\n\n        x = np.random.randn(8, 8) + 1J * np.random.randn(8, 8)\n\n        z = pad(x)\n\n        assert np.allclose(x, z)\n\n    @pytest.mark.parametrize('backend', backends)\n    def test_unpad(self, backend):\n        x = np.random.randn(4, 4) + 1J * np.random.randn(4, 4)\n\n        y = backend.unpad(x)\n\n        assert y.shape == (2, 2)\n        assert np.isclose(y[0, 0], x[1, 1])\n        assert np.isclose(y[0, 1], x[1, 2])\n\nclass TestModulus:\n    @pytest.mark.parametrize('backend', backends)\n    def test_Modulus(self, backend):\n        modulus = backend.modulus\n\n        x = np.random.rand(100, 10, 4) + 1J * np.random.rand(100, 10, 4)\n\n        y = modulus(x)\n        u = np.squeeze(np.sqrt(np.real(x) ** 2 + np.imag(x) ** 2))\n        v = y\n        assert np.allclose(u, v)\n\nclass TestSubsampleFourier:\n    @pytest.mark.parametrize('backend', backends)\n    def test_SubsampleFourier(self, backend):\n        subsample_fourier = backend.subsample_fourier\n\n        x = (np.random.rand(100, 128, 128)\n             + 1J * np.random.rand(100, 128, 128))\n\n        y = np.zeros((100, 8, 8), dtype=np.complex128)\n\n        from itertools import product\n        for i, j in product(range(8), range(8)):\n            for m, n in product(range(16), range(16)):\n                y[..., i, j] += x[..., i + m * 8, j + n * 8]\n\n        y /= 16 ** 2\n\n        z = subsample_fourier(x, k=16)\n        assert np.allclose(y, z)\n\nclass TestCDGMM:\n    @pytest.fixture(params=(False, True))\n    def data(self, request):\n        real_filter = request.param\n        x = (np.random.randn(100, 128, 128)\n             + 1J * np.random.randn(100, 128, 128))\n        filt = (np.random.randn(128, 128)\n                + 1J * np.random.randn(128, 128))\n        y = (np.random.randn(100, 128, 128)\n             + 1J * np.random.randn(100, 128, 128))\n\n        if real_filter:\n            filt = np.real(filt)\n\n        y = x * filt\n\n        return x, filt, y\n\n    @pytest.mark.parametrize('backend', backends)\n    @pytest.mark.parametrize('inplace', (False, True))\n    def test_cdgmm_forward(self, data, backend, inplace):\n        x, filt, y = data\n\n        z = backend.cdgmm(x, filt, inplace=inplace)\n\n        assert np.allclose(y, z)\n\n    @pytest.mark.parametrize('backend', backends)\n    def test_cdgmm_exceptions(self, backend):\n        with pytest.raises(TypeError) as record:\n            backend.cdgmm(np.empty((3, 4, 5)).astype(np.float64),\n                          np.empty((4, 5)).astype(np.complex128))\n        assert 'first input must be complex' in record.value.args[0]\n\n        with pytest.raises(TypeError) as record:\n            backend.cdgmm(np.empty((3, 4, 5)).astype(np.complex128),\n                          np.empty((4, 5)).astype(np.int64))\n        assert 'second input must be complex or real' in record.value.args[0]\n\n        with pytest.raises(RuntimeError) as record:\n            backend.cdgmm(np.empty((3, 4, 5)).astype(np.complex128),\n                          np.empty((4, 6)).astype(np.complex128))\n        assert 'not compatible for multiplication' in record.value.args[0]\n\n\n\nclass TestFFT:\n    @pytest.mark.parametrize('backend', backends)\n    def test_fft(self, backend):\n        x = np.random.randn(2, 2) + 1J * np.random.randn(2, 2)\n        x = x.astype('complex64')\n        y = np.array([[x[0, 0] + x[0, 1] + x[1, 0] + x[1, 1],\n                       x[0, 0] - x[0, 1] + x[1, 0] - x[1, 1]],\n                      [x[0, 0] + x[0, 1] - x[1, 0] - x[1, 1],\n                       x[0, 0] - x[0, 1] - x[1, 0] + x[1, 1]]])\n\n        z = backend.fft(x, direction='C2C')\n\n        assert np.allclose(y, z)\n\n        z = backend.fft(x, direction='C2C', inverse=True)\n\n        z = z * 4\n\n        assert np.allclose(y, z)\n\n        z = backend.fft(x, direction='C2R', inverse=True)\n\n        z = z * 4\n\n        assert not np.iscomplexobj(z)\n        assert np.allclose(np.real(y), z)\n\n\n    @pytest.mark.parametrize('backend', backends)\n    def test_fft_exceptions(self, backend):\n        with pytest.raises(RuntimeError) as record:\n            backend.fft(np.empty((2, 2)), direction='C2R',\n                        inverse=False)\n        assert 'done with an inverse' in record.value.args[0]\n\n\nclass TestBackendUtils:\n    @pytest.mark.parametrize('backend', backends)\n    def test_concatenate(self, backend):\n        x = np.random.randn(3, 6, 6) + 1J * np.random.randn(3, 6, 6)\n        y = np.random.randn(3, 6, 6) + 1J * np.random.randn(3, 6, 6)\n        z = np.random.randn(3, 6, 6) + 1J * np.random.randn(3, 6, 6)\n\n        w = backend.concatenate((x, y, z))\n\n        assert w.shape == (x.shape[0],) + (3,) + (x.shape[-2:])\n        assert np.allclose(w[:, 0, ...], x)\n        assert np.allclose(w[:, 1, ...], y)\n        assert np.allclose(w[:, 2, ...], z)\n\n\nclass TestScattering2DTensorFlow:\n    @pytest.mark.parametrize('backend', backends)\n    def test_Scattering2D(self, backend):\n        test_data_dir = os.path.dirname(__file__)\n        data = None\n        with open(os.path.join(test_data_dir, 'test_data_2d.npz'), 'rb') as f:\n            buffer = io.BytesIO(f.read())\n            data = np.load(buffer)\n\n        x = data['x']\n        S = data['Sx']\n        J = data['J']\n        pre_pad = data['pre_pad']\n\n        M = x.shape[2]\n        N = x.shape[3]\n\n        scattering = Scattering2D(J, shape=(M, N), pre_pad=pre_pad,\n                                  frontend='tensorflow', backend=backend)\n\n        x = x\n        S = S\n        Sg = scattering(x)\n        assert np.allclose(Sg, S)\n\n        scattering = Scattering2D(J, shape=(M, N), pre_pad=pre_pad,\n                                  max_order=1, frontend='tensorflow',\n                                  backend=backend)\n\n        S1x = scattering(x)\n        assert np.allclose(S1x, S[..., :S1x.shape[-3], :, :])\n\n    @pytest.mark.parametrize('backend', backends)\n    def test_batch_shape_agnostic(self, backend):\n        J = 3\n        L = 8\n        shape = (32, 32)\n\n        shape_ds = tuple(n // (2 ** J) for n in shape)\n\n        S = Scattering2D(J, shape, L, backend=backend, frontend='tensorflow')\n\n        x = np.zeros(shape)\n\n        Sx = S(x)\n\n        assert len(Sx.shape) == 3\n        assert Sx.shape[-2:] == shape_ds\n\n        n_coeffs = Sx.shape[-3]\n\n        test_shapes = ((1,) + shape, (2,) + shape, (2, 2) + shape,\n                       (2, 2, 2) + shape)\n\n        for test_shape in test_shapes:\n            x = np.zeros(test_shape)\n\n            Sx = S(x)\n\n            assert len(Sx.shape) == len(test_shape) + 1\n            assert Sx.shape[-2:] == shape_ds\n            assert Sx.shape[-3] == n_coeffs\n            assert Sx.shape[:-3] == test_shape[:-2]\n\n    @pytest.mark.parametrize('backend', backends)\n    def test_scattering2d_errors(self, backend):\n        S = Scattering2D(3, (32, 32), frontend='tensorflow', backend=backend)\n\n        with pytest.raises(TypeError) as record:\n            S(None)\n        assert 'input should be' in record.value.args[0]\n\n        x = np.random.randn(32)\n\n        with pytest.raises(RuntimeError) as record:\n            S(x)\n        assert 'have at least two dimensions' in record.value.args[0]\n\n        x = np.random.randn(31, 31)\n\n        with pytest.raises(RuntimeError) as record:\n            S(x)\n        assert 'Tensor must be of spatial size' in record.value.args[0]\n\n        S = Scattering2D(3, (32, 32), pre_pad=True, frontend='tensorflow',\n                         backend=backend)\n\n        with pytest.raises(RuntimeError) as record:\n            S(x)\n        assert 'Padded tensor must be of spatial size' in record.value.args[0]\n\n\n    def test_inputs(self):\n        fake_backend = namedtuple('backend', ['name',])\n        fake_backend.name = 'fake'\n\n        with pytest.raises(ImportError) as ve:\n            scattering = Scattering2D(2, shape=(10, 10), frontend='tensorflow', backend=fake_backend)\n        assert 'not supported' in ve.value.args[0]\n\n        with pytest.raises(RuntimeError) as ve:\n            scattering = Scattering2D(10, shape=(10, 10), frontend='tensorflow')\n        assert 'smallest dimension' in ve.value.args[0]\n"""
tests/scattering2d/test_torch_scattering2d.py,4,"b'"""""" This script will test the submodules used by the scattering module""""""\n\nimport os\nimport io\nimport numpy as np\nimport torch\nimport pytest\nfrom kymatio import Scattering2D\nfrom torch.autograd import gradcheck\nfrom collections import namedtuple\n\n\ndevices = [\'cpu\']\nif torch.cuda.is_available():\n    devices.append(\'cuda\')\n\n\nbackends = []\nbackends_devices = []\n\nskcuda_available = False\ntry:\n    if torch.cuda.is_available():\n        from skcuda import cublas\n        import cupy\n        skcuda_available = True\nexcept:\n    Warning(\'torch_skcuda backend not available.\')\n\nif skcuda_available:\n    from kymatio.scattering2d.backend.torch_skcuda_backend import backend\n    backends.append(backend)\n    if \'cuda\' in devices:\n        backends_devices.append((backend, \'cuda\'))\n\n\nfrom kymatio.scattering2d.backend.torch_backend import backend\nbackends.append(backend)\nbackends_devices.append((backend, \'cpu\'))\nif \'cuda\' in devices:\n    backends_devices.append((backend, \'cuda\'))\n\n\nclass TestPad:\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    def test_Pad(self, backend_device):\n        backend, device = backend_device\n\n        pad = backend.Pad((2, 2, 2, 2), (4, 4), pre_pad=False)\n\n        x = torch.randn(1, 4, 4)\n        x = x.to(device)\n\n        z = pad(x)\n\n        assert z.shape == (1, 8, 8, 2)\n        assert torch.allclose(z[0, 2, 2, 0], x[0, 0, 0])\n        assert torch.allclose(z[0, 1, 0, 0], x[0, 1, 2])\n        assert torch.allclose(z[0, 1, 1, 0], x[0, 1, 1])\n        assert torch.allclose(z[0, 1, 2, 0], x[0, 1, 0])\n        assert torch.allclose(z[0, 1, 3, 0], x[0, 1, 1])\n        assert torch.allclose(z[..., 1], torch.zeros_like(z[..., 1]))\n\n        pad = backend.Pad((2, 2, 2, 2), (4, 4), pre_pad=True)\n\n        x = torch.randn(1, 8, 8)\n        x = x.to(device)\n\n        z = pad(x)\n\n        assert torch.allclose(z[..., 0], x)\n        assert torch.allclose(z[..., 1], torch.zeros_like(z[..., 1]))\n\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    def test_unpad(self, backend_device):\n        backend, device = backend_device\n\n        x = torch.randn(4, 4)\n        x = x.to(device)\n\n        y = backend.unpad(x)\n\n        assert y.shape == (2, 2)\n        assert torch.allclose(y[0, 0], x[1, 1])\n        assert torch.allclose(y[0, 1], x[1, 2])\n\n\n# Checked the modulus\nclass TestModulus:\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    def test_Modulus(self, backend_device):\n        backend, device = backend_device\n\n        modulus = backend.modulus\n        x = torch.rand(100, 10, 4, 2).to(device)\n\n        y = modulus(x)\n        u = torch.squeeze(torch.sqrt(torch.sum(x * x, 3)))\n        v = y.narrow(3, 0, 1)\n        u = u.squeeze()\n        v = v.squeeze()\n        assert torch.allclose(u, v)\n\n        y = x[..., 0].contiguous()\n        with pytest.raises(TypeError) as record:\n            modulus(y)\n        assert \'should be complex\' in record.value.args[0]\n\n        y = x[::2, ::2]\n        with pytest.raises(RuntimeError) as record:\n            modulus(y)\n        assert \'contiguous\' in record.value.args[0]\n\n    @pytest.mark.parametrize(\'backend\', backends)\n    def test_cuda_only(self, backend):\n        modulus = backend.modulus\n        if backend.name == \'torch_skcuda\':\n            x = torch.rand(100, 10, 4, 2).cpu()\n            with pytest.raises(TypeError) as exc:\n                y = modulus(x)\n            assert \'Use the torch backend\' in exc.value.args[0]\n\n\n# Checked the subsampling\nclass TestSubsampleFourier:\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    def test_SubsampleFourier(self, backend_device):\n        backend, device = backend_device\n        subsample_fourier = backend.subsample_fourier\n\n        x = torch.rand(100, 1, 128, 128, 2).to(device)\n\n        y = torch.zeros(100, 1, 8, 8, 2).to(device)\n\n        for i in range(8):\n            for j in range(8):\n                for m in range(16):\n                    for n in range(16):\n                        y[...,i,j,:] += x[...,i+m*8,j+n*8,:]\n\n        y = y / (16*16)\n\n        z = subsample_fourier(x, k=16)\n        assert torch.allclose(y, z)\n\n        y = x[..., 0]\n        with pytest.raises(TypeError) as record:\n            subsample_fourier(y, k=16)\n        assert \'should be complex\' in record.value.args[0]\n\n        y = x[::2, ::2]\n        with pytest.raises(RuntimeError) as record:\n            subsample_fourier(y, k=16)\n        assert \'should be contiguous\' in record.value.args[0]\n\n    @pytest.mark.parametrize(\'backend\', backends)\n    def test_gpu_only(self, backend):\n        subsample_fourier = backend.subsample_fourier\n\n        if backend.name == \'torch_skcuda\':\n            x = torch.rand(100, 1, 128, 128, 2).cpu()\n            with pytest.raises(TypeError) as exc:\n                z = subsample_fourier(x, k=16)\n            assert \'Use the torch backend\' in exc.value.args[0]\n\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    def test_batch_shape_agnostic(self, backend_device):\n        backend, device = backend_device\n        subsample_fourier = backend.subsample_fourier\n\n        x = torch.rand(100, 1, 8, 128, 128, 2).to(device)\n\n        y = torch.zeros(100, 1, 8, 8, 8, 2).to(device)\n\n        for i in range(8):\n            for j in range(8):\n                for m in range(16):\n                    for n in range(16):\n                        y[...,i,j,:] += x[...,i+m*8,j+n*8,:]\n\n        y = y / (16*16)\n\n        z = subsample_fourier(x, k=16)\n        assert torch.allclose(y, z)\n\n\n# Check the CUBLAS routines\nclass TestCDGMM:\n    @pytest.fixture(params=(False, True))\n    def data(self, request):\n        real_filter = request.param\n\n        x = torch.rand(100, 128, 128, 2).float()\n        filt = torch.rand(128, 128, 2).float()\n        y = torch.ones(100, 128, 128, 2).float()\n\n        if real_filter:\n            filt[..., 1] = 0\n\n        y[..., 0] = x[..., 0] * filt[..., 0] - x[..., 1] * filt[..., 1]\n        y[..., 1] = x[..., 1] * filt[..., 0] + x[..., 0] * filt[..., 1]\n\n        if real_filter:\n            filt = filt[..., :1].contiguous()\n\n        return x, filt, y\n\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    @pytest.mark.parametrize(\'inplace\', (False, True))\n    def test_cdgmm_forward(self, data, backend_device, inplace):\n        backend, device = backend_device\n\n        x, filt, y = data\n        x, filt, y = x.to(device), filt.to(device), y.to(device)\n\n        z = backend.cdgmm(x, filt, inplace=inplace)\n\n        Warning(\'Tolerance has been slightly lowered here...\')\n        # There is a very small meaningless difference for skcuda+GPU\n        assert torch.allclose(y, z, atol=1e-7, rtol =1e-6)\n\n    @pytest.mark.parametrize(\'backend\', backends)\n    def test_gpu_only(self, data, backend):\n        x, filt, y = data\n        if backend.name == \'torch_skcuda\':\n            x = x.cpu()\n            filt = filt.cpu()\n\n            with pytest.raises(TypeError) as exc:\n                z = backend.cdgmm(x, filt)\n            assert \'must be CUDA\' in exc.value.args[0]\n\n    @pytest.mark.parametrize(\'backend\', backends)\n    def test_cdgmm_exceptions(self, backend):\n        with pytest.raises(RuntimeError) as exc:\n            backend.cdgmm(torch.empty(3, 4, 5, 2), torch.empty(4, 3, 2))\n        assert \'not compatible\' in exc.value.args[0]\n\n        with pytest.raises(TypeError) as exc:\n            backend.cdgmm(torch.empty(3, 4, 5, 1), torch.empty(4, 5, 1))\n        assert \'input should be complex\' in exc.value.args[0]\n\n        with pytest.raises(TypeError) as exc:\n            backend.cdgmm(torch.empty(3, 4, 5, 2), torch.empty(4, 5, 3))\n        assert \'should be complex\' in exc.value.args[0]\n\n        with pytest.raises(TypeError) as exc:\n            backend.cdgmm(torch.empty(3, 4, 5, 2),\n                          torch.empty(4, 5, 1).double())\n        assert \'must be of the same dtype\' in exc.value.args[0]\n\n        if \'cuda\' in devices:\n            if backend.name==\'torch_skcuda\':\n                with pytest.raises(TypeError) as exc:\n                    backend.cdgmm(torch.empty(3, 4, 5, 2),\n                                  torch.empty(4, 5, 1).cuda())\n                assert \'must be cuda tensors\' in exc.value.args[0].lower()\n            elif backend.name==\'torch\':\n                with pytest.raises(TypeError) as exc:\n                    backend.cdgmm(torch.empty(3, 4, 5, 2),\n                                  torch.empty(4, 5, 1).cuda())\n                assert \'input must be on gpu\' in exc.value.args[0].lower()\n\n                with pytest.raises(TypeError) as exc:\n                    backend.cdgmm(torch.empty(3, 4, 5, 2).cuda(),\n                                  torch.empty(4, 5, 1))\n                assert \'input must be on cpu\' in exc.value.args[0].lower()\n\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    def test_contiguity_exception(self, backend_device):\n        backend, device = backend_device\n\n        x = torch.empty(3, 4, 5, 3).to(device)[..., :2]\n        y = torch.empty(4, 5, 3).to(device)[..., :2]\n\n        with pytest.raises(RuntimeError) as exc:\n            backend.cdgmm(x.contiguous(), y)\n        assert \'be contiguous\' in exc.value.args[0]\n\n        with pytest.raises(RuntimeError) as exc:\n            backend.cdgmm(x, y.contiguous())\n        assert \'be contiguous\' in exc.value.args[0]\n\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    def test_device_mismatch(self, backend_device):\n        backend, device = backend_device\n\n        if device == \'cpu\':\n            return\n\n        if torch.cuda.device_count() < 2:\n            return\n\n        x = torch.empty(3, 4, 5, 2).to(\'cuda:0\')\n        y = torch.empty(4, 5, 1).to(\'cuda:1\')\n\n        with pytest.raises(TypeError) as exc:\n            backend.cdgmm(x, y)\n        assert \'must be on the same GPU\' in exc.value.args[0]\n\n\nclass TestFFT:\n    @pytest.mark.parametrize(\'backend\', backends)\n    def test_fft(self, backend):\n        x = torch.randn(2, 2, 2)\n\n        y = torch.empty_like(x)\n        y[0, 0, :] = x[0, 0, :] + x[0, 1, :] + x[1, 0, :] + x[1, 1, :]\n        y[0, 1, :] = x[0, 0, :] - x[0, 1, :] + x[1, 0, :] - x[1, 1, :]\n        y[1, 0, :] = x[0, 0, :] + x[0, 1, :] - x[1, 0, :] - x[1, 1, :]\n        y[1, 1, :] = x[0, 0, :] - x[0, 1, :] - x[1, 0, :] + x[1, 1, :]\n\n        z = backend.fft(x, direction=\'C2C\')\n\n        assert torch.allclose(y, z)\n\n        z = backend.fft(x, direction=\'C2C\', inverse=True)\n\n        z = z * 4.0\n\n        assert torch.allclose(y, z)\n\n        z = backend.fft(x, direction=\'C2R\', inverse=True)\n\n        z = z * 4.0\n\n        assert z.shape == x.shape[:-1]\n        assert torch.allclose(y[..., 0], z)\n\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    def test_fft_exceptions(self, backend_device):\n        backend, device = backend_device\n\n        with pytest.raises(RuntimeError) as record:\n            backend.fft(torch.empty(2, 2), direction=\'C2R\',\n                        inverse=False)\n        assert \'done with an inverse\' in record.value.args[0]\n\n        x = torch.rand(4, 4, 1)\n        x = x.to(device)\n        with pytest.raises(TypeError) as record:\n            backend.fft(x)\n        assert \'complex\' in record.value.args[0]\n\n        x = torch.randn(4, 4, 2)\n        x = x.to(device)\n        y = x[::2, ::2]\n\n        with pytest.raises(RuntimeError) as record:\n            backend.fft(y)\n        assert \'must be contiguous\' in record.value.args[0]\n\n\nclass TestBackendUtils:\n    @pytest.mark.parametrize(\'backend\', backends)\n    def test_concatenate(self, backend):\n        x = torch.randn(3, 6, 6)\n        y = torch.randn(3, 6, 6)\n        z = torch.randn(3, 6, 6)\n\n        w = backend.concatenate((x, y, z))\n\n        assert w.shape == (x.shape[0],) + (3,) + (x.shape[-2:])\n        assert np.allclose(w[:, 0, ...], x)\n        assert np.allclose(w[:, 1, ...], y)\n        assert np.allclose(w[:, 2, ...], z)\n\n\nclass TestScatteringTorch2D:\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    def test_Scattering2D(self, backend_device):\n        backend, device = backend_device\n\n        test_data_dir = os.path.dirname(__file__)\n        with open(os.path.join(test_data_dir, \'test_data_2d.npz\'), \'rb\') as f:\n            buffer = io.BytesIO(f.read())\n            data = np.load(buffer)\n\n        x = torch.from_numpy(data[\'x\'])\n        S = torch.from_numpy(data[\'Sx\'])\n        J = data[\'J\']\n        pre_pad = data[\'pre_pad\']\n\n        M = x.shape[2]\n        N = x.shape[3]\n\n        scattering = Scattering2D(J, shape=(M, N), pre_pad=pre_pad,\n                                  backend=backend, frontend=\'torch\')\n        Sg = []\n        x = x.to(device)\n        scattering.to(device)\n        S = S.to(device)\n        Sg = scattering(x)\n        assert torch.allclose(Sg, S)\n\n        scattering = Scattering2D(J, shape=(M, N), pre_pad=pre_pad,\n                                  max_order=1, frontend=\'torch\',\n                                  backend=backend)\n        scattering.to(device)\n\n        S1x = scattering(x)\n        assert torch.allclose(S1x, S[..., :S1x.shape[-3], :, :])\n\n    @pytest.mark.parametrize(\'backend\', backends)\n    def test_gpu_only(self, backend):\n        if backend.name == \'torch_skcuda\':\n            scattering = Scattering2D(3, shape=(32, 32), backend=backend,\n                                      frontend=\'torch\')\n\n            x = torch.rand(32, 32)\n\n            with pytest.raises(TypeError) as ve:\n                Sg = scattering(x)\n            assert \'CUDA\' in ve.value.args[0]\n\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    def test_batch_shape_agnostic(self, backend_device):\n        backend, device = backend_device\n\n        J = 3\n        L = 8\n        shape = (32, 32)\n\n        shape_ds = tuple(n // (2 ** J) for n in shape)\n\n        S = Scattering2D(J, shape, L, backend=backend, frontend=\'torch\')\n\n        with pytest.raises(RuntimeError) as ve:\n            S(torch.zeros(()))\n        assert \'at least two\' in ve.value.args[0]\n\n        with pytest.raises(RuntimeError) as ve:\n            S(torch.zeros((32, )))\n        assert \'at least two\' in ve.value.args[0]\n\n        x = torch.zeros(shape)\n\n        x = x.to(device)\n        S.to(device)\n\n        Sx = S(x)\n\n        assert len(Sx.shape) == 3\n        assert Sx.shape[-2:] == shape_ds\n\n        n_coeffs = Sx.shape[-3]\n\n        test_shapes = ((1,) + shape, (2,) + shape, (2, 2) + shape,\n                       (2, 2, 2) + shape)\n\n        for test_shape in test_shapes:\n            x = torch.zeros(test_shape)\n\n            x = x.to(device)\n\n            Sx = S(x)\n\n            assert len(Sx.shape) == len(test_shape) + 1\n            assert Sx.shape[-2:] == shape_ds\n            assert Sx.shape[-3] == n_coeffs\n            assert Sx.shape[:-3] == test_shape[:-2]\n\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    def test_scattering2d_errors(self, backend_device):\n        backend, device = backend_device\n\n        S = Scattering2D(3, (32, 32), backend=backend, frontend=\'torch\')\n\n        S.to(device)\n\n        with pytest.raises(TypeError) as record:\n            S(None)\n        assert \'input should be\' in record.value.args[0]\n\n        x = torch.randn(4,4)\n        y = x[::2,::2]\n\n        with pytest.raises(RuntimeError) as record:\n            S(y)\n        assert \'must be contiguous\' in record.value.args[0]\n\n        x = torch.randn(31, 31)\n\n        with pytest.raises(RuntimeError) as record:\n            S(x)\n        assert \'Tensor must be of spatial size\' in record.value.args[0]\n\n        S = Scattering2D(3, (32, 32), pre_pad=True, backend=backend,\n                         frontend=\'torch\')\n\n        with pytest.raises(RuntimeError) as record:\n            S(x)\n        assert \'Padded tensor must be of spatial size\' in record.value.args[0]\n\n        x = torch.randn(8,8)\n        S = Scattering2D(2, (8, 8), backend=backend, frontend=\'torch\')\n\n        x = x.to(device)\n        S = S.to(device)\n        if not (device == \'cpu\' and backend.name == \'torch_skcuda\'):\n            y = S(x)\n            assert x.device == y.device\n\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    def test_input_size_agnostic(self, backend_device):\n        backend, device = backend_device\n\n        for N in [31, 32, 33]:\n            for J in [1, 2, 4]:\n                scattering = Scattering2D(J, shape=(N, N), backend=backend,\n                                          frontend=\'torch\')\n                x = torch.zeros(3, 3, N, N)\n\n                x = x.to(device)\n                scattering.to(device)\n\n                S = scattering(x)\n                scattering = Scattering2D(J, shape=(N, N), pre_pad=True,\n                                          backend=backend, frontend=\'torch\')\n                x = torch.zeros(3, 3, scattering.M_padded, scattering.N_padded)\n\n                x = x.to(device)\n                scattering.to(device)\n\n        N = 32\n        J = 5\n        scattering = Scattering2D(J, shape=(N, N), backend=backend,\n                                  frontend=\'torch\')\n        x = torch.zeros(3, 3, N, N)\n\n        x = x.to(device)\n        scattering.to(device)\n\n        S = scattering(x)\n        assert S.shape[-2:] == (1, 1)\n\n        N = 32\n        J = 5\n        scattering = Scattering2D(J, shape=(N+5, N), backend=backend,\n                                  frontend=\'torch\')\n        x = torch.zeros(3, 3, N+5, N)\n\n        x = x.to(device)\n        scattering.to(device)\n\n        S = scattering(x)\n        assert S.shape[-2:] == (1, 1)\n\n    def test_inputs(self):\n        fake_backend = namedtuple(\'backend\', [\'name\',])\n        fake_backend.name = \'fake\'\n\n        with pytest.raises(ImportError) as ve:\n            scattering = Scattering2D(2, shape=(10, 10), frontend=\'torch\',\n                                      backend=fake_backend)\n        assert \'not supported\' in ve.value.args[0]\n\n        with pytest.raises(RuntimeError) as ve:\n            scattering = Scattering2D(10, shape=(10, 10), frontend=\'torch\')\n        assert \'smallest dimension\' in ve.value.args[0]\n\n    @pytest.mark.parametrize(\'backend_device\', backends_devices)\n    def test_gradients(self, backend_device):\n        backend, device = backend_device\n\n        if backend.name == \'torch_skcuda\':\n            pytest.skip(\'The gradients are currently not implemented with \'\n                        \'the skcuda backend.\')\n        else:\n            scattering = Scattering2D(2, shape=(8, 8), backend=backend,\n                                      frontend=\'torch\').double().to(device)\n            x = torch.rand(2, 1, 8, 8).double().to(device).requires_grad_()\n            gradcheck(scattering, x, nondet_tol=1e-5)\n'"
tests/scattering3d/test_numpy_scattering3d.py,5,"b'"""""" This script will test the submodules used by the scattering module""""""\nimport os\nimport io\nimport numpy as np\nimport pytest\nfrom kymatio import HarmonicScattering3D\n\nbackends = []\n\nfrom kymatio.scattering3d.backend.numpy_backend import backend\nbackends.append(backend)\n\n\ndef relative_difference(a, b):\n    return np.sum(np.abs(a - b)) / max(np.sum(np.abs(a)), np.sum(np.abs(b)))\n\n\n@pytest.mark.parametrize(""backend"", backends)\ndef test_against_standard_computations(backend):\n    file_path = os.path.abspath(os.path.dirname(__file__))\n    with open(os.path.join(file_path, \'test_data_3d.npz\'), \'rb\') as f:\n        buffer = io.BytesIO(f.read())\n        data = np.load(buffer)\n    x = data[\'x\']\n    scattering_ref = data[\'Sx\']\n    J = data[\'J\']\n    L = data[\'L\']\n    integral_powers = data[\'integral_powers\']\n\n    M = x.shape[1]\n\n    batch_size = x.shape[0]\n\n    N, O = M, M\n    sigma = 1\n\n    scattering = HarmonicScattering3D(J=J, shape=(M, N, O), L=L,\n                                      sigma_0=sigma, method=\'integral\',\n                                      integral_powers=integral_powers,\n                                      max_order=2, backend=backend,\n                                      frontend=\'numpy\')\n\n    order_0 = backend.compute_integrals(x, integral_powers)\n    scattering.max_order = 2\n    scattering.method = \'integral\'\n    scattering.integral_powers = integral_powers\n    orders_1_and_2 = scattering(x)\n\n    order_0 = order_0.reshape((batch_size, -1))\n    start = 0\n    end = order_0.shape[1]\n    order_0_ref = scattering_ref[:, start:end]\n\n    orders_1_and_2 = orders_1_and_2.reshape((batch_size, -1))\n    start = end\n    end += orders_1_and_2.shape[1]\n    orders_1_and_2_ref = scattering_ref[:, start:end]\n\n    order_0_diff_cpu = relative_difference(order_0_ref, order_0)\n    print(orders_1_and_2_ref.shape)\n    print(orders_1_and_2.shape)\n    orders_1_and_2_diff_cpu = relative_difference(\n        orders_1_and_2_ref, orders_1_and_2)\n\n    assert order_0_diff_cpu < 1e-6, ""CPU : order 0 do not match, diff={}"".format(order_0_diff_cpu)\n    assert orders_1_and_2_diff_cpu < 1e-6, ""CPU : orders 1 and 2 do not match, diff={}"".format(orders_1_and_2_diff_cpu)\n\n\n@pytest.mark.parametrize(""backend"", backends)\ndef test_scattering_batch_shape_agnostic(backend):\n    J = 2\n    shape = (16, 16, 16)\n\n    S = HarmonicScattering3D(J=J, shape=shape, frontend=\'numpy\', backend=backend)\n    for k in range(3):\n        with pytest.raises(RuntimeError) as ve:\n            S(np.zeros(shape[:k]))\n        assert \'at least three\' in ve.value.args[0]\n\n    x = np.zeros(shape=shape)\n\n    Sx = S(x)\n\n    assert len(Sx.shape) == 3\n\n    coeffs_shape = Sx.shape[-3:]\n\n    test_shapes = ((1,) + shape, (2,) + shape, (2, 2) + shape,\n                   (2, 2, 2) + shape)\n\n    for test_shape in test_shapes:\n        x = np.zeros(shape=test_shape)\n        x = x\n\n        Sx = S(x)\n\n        assert len(Sx.shape) == len(test_shape)\n        assert Sx.shape[-3:] == coeffs_shape\n        assert Sx.shape[:-3] == test_shape[:-3]\n'"
tests/scattering3d/test_tensorflow_scattering3d.py,5,"b'import os\nimport io\nimport tensorflow as tf\nfrom kymatio import HarmonicScattering3D\nimport numpy as np\nimport pytest\n\nfrom kymatio.scattering3d.backend.tensorflow_backend import backend\n\n\ndef relative_difference(a, b):\n    return np.sum(np.abs(a - b)) / max(np.sum(np.abs(a)), np.sum(np.abs(b)))\n\n\ndef test_against_standard_computations():\n    file_path = os.path.abspath(os.path.dirname(__file__))\n    with open(os.path.join(file_path, \'test_data_3d.npz\'), \'rb\') as f:\n        buffer = io.BytesIO(f.read())\n        data = np.load(buffer)\n    x = data[\'x\']\n    scattering_ref = data[\'Sx\']\n    J = data[\'J\']\n    L = data[\'L\']\n    integral_powers = data[\'integral_powers\']\n\n    M = x.shape[1]\n    batch_size = x.shape[0]\n    N, O = M, M\n    sigma = 1\n\n    scattering = HarmonicScattering3D(J=J, shape=(M, N, O), L=L,\n                                      sigma_0=sigma,\n                                      method=\'integral\',\n                                      integral_powers=integral_powers,\n                                      max_order=2,\n                                      frontend=\'tensorflow\',\n                                      backend=backend)\n    orders_1_and_2 = scattering(x)\n\n    orders_1_and_2 = orders_1_and_2.numpy()\n\n    # TODO: order_0 test\n    start = 0\n    end = 2\n    order_0_ref = scattering_ref[:,start: end]\n\n    orders_1_and_2 = orders_1_and_2.reshape((batch_size, -1))\n\n    start = end\n    end += orders_1_and_2.shape[1]\n    orders_1_and_2_ref = scattering_ref[:,start: end]\n\n    orders_1_and_2_diff_cpu = relative_difference(orders_1_and_2_ref, orders_1_and_2)\n    assert orders_1_and_2_diff_cpu < 5e-7, ""Tensorflow : orders 1 and 2 do not match, diff={}"".format(orders_1_and_2_diff_cpu)\n\ndef test_scattering_batch_shape_agnostic():\n    J = 2\n    shape = (16, 16, 16)\n\n    S = HarmonicScattering3D(J=J, shape=shape, frontend=\'tensorflow\')\n\n    for k in range(3):\n        with pytest.raises(RuntimeError) as ve:\n            S(np.zeros(shape[:k]))\n        assert \'at least three\' in ve.value.args[0]\n\n    x = np.zeros(shape)\n\n    Sx = S(x)\n\n    assert len(Sx.shape) == 3\n\n    coeffs_shape = Sx.shape[-3:]\n\n    test_shapes = ((1,) + shape, (2,) + shape, (2, 2) + shape,\n                   (2, 2, 2) + shape)\n\n    for test_shape in test_shapes:\n        x = np.zeros(test_shape)\n        Sx = S(x)\n\n        assert len(Sx.shape) == len(test_shape)\n        assert Sx.shape[-3:] == coeffs_shape\n        assert Sx.shape[:-3] == test_shape[:-3]\n'"
tests/scattering3d/test_torch_scattering3d.py,7,"b'"""""" This script will test the submodules used by the scattering module""""""\nimport torch\nimport os\nimport io\nimport numpy as np\nimport pytest\nfrom kymatio import HarmonicScattering3D\nfrom kymatio.scattering3d.utils import generate_weighted_sum_of_gaussians\n\n\nbackends = []\n\nskcuda_available = False\ntry:\n    if torch.cuda.is_available():\n        from skcuda import cublas\n        import cupy\n        skcuda_available = True\nexcept:\n    Warning(\'torch_skcuda backend not available.\')\n\nif skcuda_available:\n    from kymatio.scattering3d.backend.torch_skcuda_backend import backend\n    backends.append(backend)\n\n\nfrom kymatio.scattering3d.backend.torch_backend import backend\nbackends.append(backend)\n\nif torch.cuda.is_available():\n    devices = [\'cuda\', \'cpu\']\nelse:\n    devices = [\'cpu\']\n\n\ndef relative_difference(a, b):\n    return np.sum(np.abs(a - b)) / max(np.sum(np.abs(a)), np.sum(np.abs(b)))\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_FFT3d_central_freq_batch(device, backend):\n    # Checked the 0 frequency for the 3D FFT\n    for device in devices:\n        x = torch.zeros(1, 32, 32, 32, 2).float()\n        if device == \'gpu\':\n            x = x.cuda()\n        a = x.sum()\n        y = backend.fft(x)\n        c = y[:, 0, 0, 0].sum()\n        assert (c - a).abs().sum() < 1e-6\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_fft3d_error(backend, device):\n    x = torch.zeros(8, 1)\n    with pytest.raises(TypeError) as record:\n        backend.fft(x)\n    assert ""should be complex"" in record.value.args[0]\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\n@pytest.mark.parametrize(""inplace"", [False, True])\ndef test_cdgmm3d(device, backend, inplace):\n    if backend.name == \'torch\' or device != \'cpu\':\n        # Not all backends currently implement the inplace variant\n        x = torch.zeros(2, 3, 4, 2).to(device)\n        x[..., 0] = 2\n        x[..., 1] = 3\n\n        y = torch.zeros_like(x)\n        y[..., 0] = 4\n        y[..., 1] = 5\n\n        prod = torch.zeros_like(x)\n        prod[..., 0] = x[..., 0] * y[..., 0] - x[..., 1] * y[..., 1]\n        prod[..., 1] = x[..., 0] * y[..., 1] + x[..., 1] * y[..., 0]\n\n        z = backend.cdgmm3d(x, y, inplace=inplace)\n\n        assert (z - prod).norm().cpu().item() < 1e-7\n\n        if inplace:\n            assert (x - z).norm().cpu().item() < 1e-7\n\n        with pytest.warns(UserWarning) as record:\n            x = torch.randn((3, 4, 3, 2), device=device)\n            x = x[:, 0:3, ...]\n            y = torch.randn((3, 3, 3, 2), device=device)\n            backend.cdgmm3d(x, y)\n        assert ""A is converted"" in record[0].message.args[0]\n\n        with pytest.warns(UserWarning) as record:\n            x = torch.randn((3, 3, 3, 2), device=device)\n            y = torch.randn((3, 4, 3, 2), device=device)\n            y = y[:, 0:3, ...]\n            backend.cdgmm3d(x, y)\n        assert ""B is converted"" in record[0].message.args[0]\n\n        with pytest.raises(RuntimeError) as record:\n            x = torch.randn((3, 3, 3, 2), device=device)\n            y = torch.randn((4, 4, 4, 2), device=device)\n            backend.cdgmm3d(x, y)\n        assert ""not compatible"" in record.value.args[0]\n\n        x = torch.randn((2, 3, 3, 3, 2), device=device)\n        y = torch.randn((3, 3, 3, 2), device=device)\n        backend.cdgmm3d(x, y)\n\n        with pytest.raises(TypeError) as record:\n            x = torch.randn((3, 3, 3, 1), device=device)\n            y = torch.randn((3, 3, 3, 1), device=device)\n            backend.cdgmm3d(x, y)\n        assert ""should be complex"" in record.value.args[0]\n\n        # This one is a little tricky. We can\'t have the number of dimensions be\n        # greater than 4 since that triggers the ""not compatible"" error.\n        with pytest.raises(RuntimeError) as record:\n            x = torch.randn((3, 3, 2), device=device)\n            y = torch.randn((3, 3, 2), device=device)\n            backend.cdgmm3d(x, y)\n        assert ""must be simply a complex"" in record.value.args[0]\n\n        # Create a tensor that behaves like `torch.Tensor` but is technically a\n        # different type.\n        class FakeTensor(torch.Tensor):\n            pass\n\n        with pytest.raises(RuntimeError) as record:\n            x = FakeTensor(3, 3, 3, 2)\n            y = torch.randn(3, 3, 3, 2)\n            backend.cdgmm3d(x, y)\n        assert ""should be same type"" in record.value.args[0]\n\n    if backend.name == \'torch_skcuda\':\n        x = torch.randn((3, 3, 3, 2), device=torch.device(\'cpu\'))\n        y = torch.randn((3, 3, 3, 2), device=torch.device(\'cpu\'))\n        with pytest.raises(RuntimeError) as record:\n            backend.cdgmm3d(x, y)\n        assert ""for CPU tensors"" in record.value.args[0]\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_complex_modulus(backend, device):\n    x = torch.randn(4, 3, 2).to(device)\n    xm = torch.sqrt(x[..., 0] ** 2 + x[..., 1] ** 2)\n    y = backend.modulus(x)\n    assert (y[..., 0] - xm).norm() < 1e-7\n    assert (y[..., 1]).norm() < 1e-7\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_against_standard_computations(device, backend):\n    if backend.name == ""torch_skcuda"" and device == ""cpu"":\n        pytest.skip(""The skcuda backend does not support CPU tensors."")\n\n    file_path = os.path.abspath(os.path.dirname(__file__))\n    with open(os.path.join(file_path, \'test_data_3d.npz\'), \'rb\') as f:\n        buffer = io.BytesIO(f.read())\n        data = np.load(buffer)\n    x = torch.from_numpy(data[\'x\'])\n    scattering_ref = torch.from_numpy(data[\'Sx\'])\n    J = data[\'J\']\n    L = data[\'L\']\n    integral_powers = data[\'integral_powers\']\n\n    M = x.shape[1]\n\n    batch_size = x.shape[0]\n\n    N, O = M, M\n    sigma = 1\n\n    scattering = HarmonicScattering3D(J=J, shape=(M, N, O), L=L,\n            sigma_0=sigma, method=\'integral\',\n            integral_powers=integral_powers, max_order=2, backend=backend, frontend=\'torch\')\n\n    scattering.to(device)\n    x = x.to(device)\n\n    order_0 = backend.compute_integrals(x, integral_powers)\n    scattering.max_order = 2\n    scattering.method = \'integral\'\n    scattering.integral_powers = integral_powers\n    orders_1_and_2 = scattering(x)\n\n    order_0 = order_0.cpu().numpy().reshape((batch_size, -1))\n    start = 0\n    end = order_0.shape[1]\n    order_0_ref = scattering_ref[:, start:end].cpu().numpy()\n\n    orders_1_and_2 = orders_1_and_2.cpu().numpy().reshape((batch_size, -1))\n    start = end\n    end += orders_1_and_2.shape[1]\n    orders_1_and_2_ref = scattering_ref[:, start:end].cpu().numpy()\n\n    order_0_diff_cpu = relative_difference(order_0_ref, order_0)\n    orders_1_and_2_diff_cpu = relative_difference(\n        orders_1_and_2_ref, orders_1_and_2)\n\n    assert order_0_diff_cpu < 1e-6, ""CPU : order 0 do not match, diff={}"".format(order_0_diff_cpu)\n    assert orders_1_and_2_diff_cpu < 1e-6, ""CPU : orders 1 and 2 do not match, diff={}"".format(orders_1_and_2_diff_cpu)\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_solid_harmonic_scattering(device, backend):\n    if backend.name == ""torch_skcuda"" and device == ""cpu"":\n        pytest.skip(""The skcuda backend does not support CPU tensors."")\n\n    # Compare value to analytical formula in the case of a single Gaussian\n    centers = np.zeros((1, 1, 3))\n    weights = np.ones((1, 1))\n    sigma_gaussian = 3.\n    sigma_0_wavelet = 3.\n    M, N, O, J, L = 128, 128, 128, 1, 3\n    grid = np.mgrid[-M // 2:-M // 2 + M, -N // 2:-N // 2 + N, -O // 2:-O // 2 + O]\n    grid = grid.astype(\'float32\')\n    grid = np.fft.ifftshift(grid, axes=(1, 2, 3))\n    x = torch.from_numpy(generate_weighted_sum_of_gaussians(grid, centers,\n        weights, sigma_gaussian)).to(device).float()\n    scattering = HarmonicScattering3D(J=J, shape=(M, N, O), L=L,\n            sigma_0=sigma_0_wavelet,max_order=1, method=\'integral\',\n            integral_powers=[1], frontend=\'torch\',backend=backend).to(device)\n\n    scattering.max_order = 1\n    scattering.method = \'integral\'\n    scattering.integral_powers = [1]\n\n    s = scattering(x)\n\n    for j in range(J+1):\n        sigma_wavelet = sigma_0_wavelet*2**j\n        k = sigma_wavelet / np.sqrt(sigma_wavelet**2 + sigma_gaussian**2)\n        for l in range(1, L+1):\n            err = torch.abs(s[0, j, l, 0] - k ** l).sum()/(1e-6+s[0, j, l, 0].abs().sum())\n            assert err<1e-4\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_larger_scales(device, backend):\n    if backend.name == ""torch_skcuda"" and device == ""cpu"":\n        pytest.skip(""The skcuda backend does not support CPU tensors."")\n\n    shape = (32, 32, 32)\n    L = 3\n    sigma_0 = 1\n\n    x = torch.randn((1,) + shape).to(device)\n\n    for J in range(3, 4+1):\n        scattering = HarmonicScattering3D(J=J, shape=shape, L=L, sigma_0=sigma_0, frontend=\'torch\', backend=backend).to(device)\n        scattering.method = \'integral\'\n        Sx = scattering(x)\n\n\n@pytest.mark.parametrize(""device"", devices)\n@pytest.mark.parametrize(""backend"", backends)\ndef test_scattering_batch_shape_agnostic(device, backend):\n    if backend.name == ""torch_skcuda"" and device == ""cpu"":\n        pytest.skip(""The skcuda backend does not support CPU tensors."")\n\n    J = 2\n    shape = (16, 16, 16)\n\n    S = HarmonicScattering3D(J=J, shape=shape)\n\n    for k in range(3):\n        with pytest.raises(RuntimeError) as ve:\n            S(torch.zeros(shape[:k]))\n        assert \'at least three\' in ve.value.args[0]\n\n    x = torch.zeros(shape)\n\n    x = x.to(device)\n    S.to(device)\n\n    Sx = S(x)\n\n    assert len(Sx.shape) == 3\n\n    coeffs_shape = Sx.shape[-3:]\n\n    test_shapes = ((1,) + shape, (2,) + shape, (2, 2) + shape,\n                   (2, 2, 2) + shape)\n\n    for test_shape in test_shapes:\n        x = torch.zeros(test_shape)\n\n        x = x.to(device)\n\n        Sx = S(x)\n\n        assert len(Sx.shape) == len(test_shape)\n        assert Sx.shape[-3:] == coeffs_shape\n        assert Sx.shape[:-3] == test_shape[:-3]\n'"
tests/scattering3d/test_utils_scattering3d.py,4,"b'from kymatio.scattering3d.utils import sqrt\nimport pytest\nimport numpy as np\n\ndef test_utils():\n    # Simple test\n    x = np.arange(8)\n    y = sqrt(x**2)\n    assert (y == x).all()\n\n    # Test problematic case\n    x = np.arange(8193, dtype=\'float32\')\n    y = sqrt(x**2)\n    assert (y == x).all()\n\n    # Make sure we still don\'t let in negatives...\n    with pytest.warns(RuntimeWarning) as record:\n        x = np.array([-1, 0, 1])\n        y = sqrt(x)\n    assert ""Negative"" in record[0].message.args[0]\n\n    # ...unless they are complex numbers!\n    with pytest.warns(None) as record:\n        x = np.array([-1, 0, 1], dtype=\'complex64\')\n        y = sqrt(x)\n    assert not record.list\n'"
kymatio/scattering1d/backend/__init__.py,0,b''
kymatio/scattering1d/backend/numpy_backend.py,3,"b'# Authors: Edouard Oyallon, Joakim Anden, Mathieu Andreux\nfrom collections import namedtuple\nimport scipy\nimport numpy as np\n\nBACKEND_NAME = \'numpy\'\n\nfrom ...backend.numpy_backend import modulus, cdgmm, real\nfrom ...backend.base_backend import FFT\n\n\ndef subsample_fourier(x, k):\n    """"""Subsampling in the Fourier domain\n    Subsampling in the temporal domain amounts to periodization in the Fourier\n    domain, so the input is periodized according to the subsampling factor.\n    Parameters\n    ----------\n    x : tensor\n        Input tensor with at least 3 dimensions, where the next to last\n        corresponds to the frequency index in the standard PyTorch FFT\n        ordering. The length of this dimension should be a power of 2 to\n        avoid errors. The last dimension should represent the real and\n        imaginary parts of the Fourier transform.\n    k : int\n        The subsampling factor.\n    Returns\n    -------\n    res : tensor\n        The input tensor periodized along the next to last axis to yield a\n        tensor of size x.shape[-2] // k along that dimension.\n    """"""\n\n    N = x.shape[-1]\n    res = x.reshape(x.shape[:-1] + (k, N // k)).mean(axis=(-2,))\n    return res\n\n\ndef pad_1d(x, pad_left, pad_right, mode=\'constant\', value=0.):\n    """"""Pad real 1D tensors\n    1D implementation of the padding function for real PyTorch tensors.\n    Parameters\n    ----------\n    x : tensor\n        Three-dimensional input tensor with the third axis being the one to\n        be padded.\n    pad_left : int\n        Amount to add on the left of the tensor (at the beginning of the\n        temporal axis).\n    pad_right : int\n        amount to add on the right of the tensor (at the end of the temporal\n        axis).\n    mode : string, optional\n        Padding mode. Options include \'constant\' and \'reflect\'. See the\n        PyTorch API for other options.  Defaults to \'constant\'.\n    value : float, optional\n        If mode == \'constant\', value to input within the padding. Defaults to\n        0.\n    Returns\n    -------\n    res : tensor\n        The tensor passed along the third dimension.\n    """"""\n    if (pad_left >= x.shape[-1]) or (pad_right >= x.shape[-1]):\n        if mode == \'reflect\':\n            raise ValueError(\'Indefinite padding size (larger than tensor).\')\n\n    res = np.pad(x, ((0, 0), (0, 0), (pad_left, pad_right),), mode=mode)\n    return res\n\n\ndef pad(x, pad_left=0, pad_right=0):\n    """"""Pad real 1D tensors and map to complex\n    Padding which allows to simultaneously pad in a reflection fashion and map\n    to complex if necessary.\n    Parameters\n    ----------\n    x : tensor\n        Three-dimensional input tensor with the third axis being the one to\n        be padded.\n    pad_left : int\n        Amount to add on the left of the tensor (at the beginning of the\n        temporal axis).\n    pad_right : int\n        amount to add on the right of the tensor (at the end of the temporal\n        axis).\n    Returns\n    -------\n    output : tensor\n        A padded signal.\n    """"""\n    output = pad_1d(x, pad_left, pad_right, mode=\'reflect\')\n    return output\n\n\ndef unpad(x, i0, i1):\n    """"""Unpad real 1D tensor\n    Slices the input tensor at indices between i0 and i1 along the last axis.\n    Parameters\n    ----------\n    x : tensor\n        Input tensor with least one axis.\n    i0 : int\n        Start of original signal before padding.\n    i1 : int\n        End of original signal before padding.\n    Returns\n    -------\n    x_unpadded : tensor\n        The tensor x[..., i0:i1].\n    """"""\n    return x[..., i0:i1]\n\n\n\n\ndef concatenate(arrays):\n    return np.stack(arrays, axis=-2)\n\n\nbackend = namedtuple(\'backend\',\n                     [\'name\', \'modulus_complex\', \'subsample_fourier\', \'real\',\n                      \'unpad\', \'fft\', \'concatenate\', \'cdgmm\'])\nbackend.name = \'numpy\'\nbackend.modulus_complex = modulus\nbackend.subsample_fourier = subsample_fourier\nbackend.real = real\nbackend.unpad = unpad\nbackend.pad = pad\nbackend.pad_1d = pad_1d\nbackend.cdgmm = cdgmm\nbackend.fft = FFT(lambda x:scipy.fftpack.fft(x),\n                  lambda x:scipy.fftpack.ifft(x),\n                  lambda x:np.real(scipy.fftpack.ifft(x)),\n                  lambda x:None)\nbackend.concatenate = concatenate\n'"
kymatio/scattering1d/backend/tensorflow_backend.py,0,"b'# Authors: Edouard Oyallon, Joakim Anden, Mathieu Andreux\nimport tensorflow as tf\nfrom collections import namedtuple\n\n\nBACKEND_NAME = \'tensorflow\'\n\n\nfrom ...backend.tensorflow_backend import Modulus, real, concatenate, cdgmm\nfrom ...backend.base_backend import FFT\n\ndef subsample_fourier(x, k):\n    """"""Subsampling in the Fourier domain\n    Subsampling in the temporal domain amounts to periodization in the Fourier\n    domain, so the input is periodized according to the subsampling factor.\n    Parameters\n    ----------\n    x : tensor\n        Input tensor with at least 3 dimensions, where the next to last\n        corresponds to the frequency index in the standard PyTorch FFT\n        ordering. The length of this dimension should be a power of 2 to\n        avoid errors. The last dimension should represent the real and\n        imaginary parts of the Fourier transform.\n    k : int\n        The subsampling factor.\n    Returns\n    -------\n    res : tensor\n        The input tensor periodized along the next to last axis to yield a\n        tensor of size x.shape[-2] // k along that dimension.\n    """"""\n\n    N = x.shape[-1]\n    y = tf.reshape(x, (-1, k, N // k))\n\n    return tf.reduce_mean(y, axis=(1,))\n\n\ndef pad_1d(x, pad_left, pad_right, mode=\'constant\', value=0.):\n    """"""Pad real 1D tensors\n    1D implementation of the padding function for real PyTorch tensors.\n    Parameters\n    ----------\n    x : tensor\n        Three-dimensional input tensor with the third axis being the one to\n        be padded.\n    pad_left : int\n        Amount to add on the left of the tensor (at the beginning of the\n        temporal axis).\n    pad_right : int\n        amount to add on the right of the tensor (at the end of the temporal\n        axis).\n    mode : string, optional\n        Padding mode. Options include \'constant\' and \'reflect\'. See the\n        PyTorch API for other options.  Defaults to \'constant\'.\n    value : float, optional\n        If mode == \'constant\', value to input within the padding. Defaults to\n        0.\n    Returns\n    -------\n    res : tensor\n        The tensor passed along the third dimension.\n    """"""\n    if (pad_left >= x.shape[-1]) or (pad_right >= x.shape[-1]):\n        if mode == \'reflect\':\n            raise ValueError(\'Indefinite padding size (larger than tensor).\')\n\n    paddings = [[0, 0]] * len(x.shape[:-1])\n    paddings += [[pad_left, pad_right],]\n    return tf.cast(tf.pad(x, paddings, mode=""REFLECT""), tf.complex64)\n\n\ndef pad(x, pad_left=0, pad_right=0):\n    """"""Pad real 1D tensors and map to complex\n    Padding which allows to simultaneously pad in a reflection fashion and map\n    to complex if necessary.\n    Parameters\n    ----------\n    x : tensor\n        Three-dimensional input tensor with the third axis being the one to\n        be padded.\n    pad_left : int\n        Amount to add on the left of the tensor (at the beginning of the\n        temporal axis).\n    pad_right : int\n        amount to add on the right of the tensor (at the end of the temporal\n        axis).\n    Returns\n    -------\n    output : tensor\n        A padded signal\n    """"""\n    output = pad_1d(x, pad_left, pad_right, mode=\'reflect\')\n    return output\n\n\ndef unpad(x, i0, i1):\n    """"""Unpad real 1D tensor\n    Slices the input tensor at indices between i0 and i1 along the last axis.\n    Parameters\n    ----------\n    x : tensor\n        Input tensor with least one axis.\n    i0 : int\n        Start of original signal before padding.\n    i1 : int\n        End of original signal before padding.\n    Returns\n    -------\n    x_unpadded : tensor\n        The tensor x[..., i0:i1].\n    """"""\n    return x[..., i0:i1]\n\n\n\nbackend = namedtuple(\'backend\', [\'name\', \'modulus_complex\', \'subsample_fourier\', \'real\', \'unpad\', \'fft\', \'concatenate\'])\nbackend.name = \'tensorflow\'\nbackend.modulus_complex = Modulus()\nbackend.subsample_fourier = subsample_fourier\nbackend.real = real\nbackend.unpad = unpad\nbackend.cdgmm = cdgmm\nbackend.pad = pad\nbackend.pad_1d = pad_1d\nbackend.fft = FFT(lambda x: tf.signal.fft(x, name=\'fft1d\'),\n                  lambda x: tf.signal.ifft(x, name=\'ifft1d\'),\n                  lambda x: tf.math.real(tf.signal.ifft(x, name=\'irfft1d\')),\n                  lambda x: None)\nbackend.concatenate = lambda x: concatenate(x, -2)\n'"
kymatio/scattering1d/backend/torch_backend.py,0,"b'# Authors: Edouard Oyallon, Joakim Anden, Mathieu Andreux\n\nimport torch\nimport torch.nn.functional as F\n\nfrom collections import namedtuple\n\nBACKEND_NAME = \'torch\'\n\nfrom ...backend.torch_backend import _is_complex, Modulus, concatenate, type_checks, cdgmm, real\nfrom ...backend.base_backend import FFT\n\ndef subsample_fourier(x, k):\n    """"""Subsampling in the Fourier domain\n\n    Subsampling in the temporal domain amounts to periodization in the Fourier\n    domain, so the input is periodized according to the subsampling factor.\n\n    Parameters\n    ----------\n    x : tensor\n        Input tensor with at least 3 dimensions, where the next to last\n        corresponds to the frequency index in the standard PyTorch FFT\n        ordering. The length of this dimension should be a power of 2 to\n        avoid errors. The last dimension should represent the real and\n        imaginary parts of the Fourier transform.\n    k : int\n        The subsampling factor.\n\n    Returns\n    -------\n    res : tensor\n        The input tensor periodized along the next to last axis to yield a\n        tensor of size x.shape[-2] // k along that dimension.\n    """"""\n    if not _is_complex(x):\n        raise TypeError(\'The input should be complex.\')\n\n    N = x.shape[-2]\n    res = x.view(x.shape[:-2] + (k, N // k, 2)).mean(dim=-3)\n    return res\n\ndef pad_1d(x, pad_left, pad_right, mode=\'constant\', value=0.):\n    """"""Pad real 1D tensors\n\n    1D implementation of the padding function for real PyTorch tensors.\n\n    Parameters\n    ----------\n    x : tensor\n        Three-dimensional input tensor with the third axis being the one to\n        be padded.\n    pad_left : int\n        Amount to add on the left of the tensor (at the beginning of the\n        temporal axis).\n    pad_right : int\n        amount to add on the right of the tensor (at the end of the temporal\n        axis).\n    mode : string, optional\n        Padding mode. Options include \'constant\' and \'reflect\'. See the\n        PyTorch API for other options.  Defaults to \'constant\'.\n    value : float, optional\n        If mode == \'constant\', value to input within the padding. Defaults to\n        0.\n\n    Returns\n    -------\n    res : tensor\n        The tensor passed along the third dimension.\n    """"""\n    if (pad_left >= x.shape[-1]) or (pad_right >= x.shape[-1]):\n        if mode == \'reflect\':\n            raise ValueError(\'Indefinite padding size (larger than tensor).\')\n    res = F.pad(x.unsqueeze(2),\n                (pad_left, pad_right, 0, 0),\n                mode=mode, value=value).squeeze(2)\n    return res\n\ndef pad(x, pad_left=0, pad_right=0, to_complex=True):\n    """"""Pad real 1D tensors and map to complex\n\n    Padding which allows to simultaneously pad in a reflection fashion and map\n    to complex if necessary.\n\n    Parameters\n    ----------\n    x : tensor\n        Three-dimensional input tensor with the third axis being the one to\n        be padded.\n    pad_left : int\n        Amount to add on the left of the tensor (at the beginning of the\n        temporal axis).\n    pad_right : int\n        amount to add on the right of the tensor (at the end of the temporal\n        axis).\n    to_complex : boolean, optional\n        Whether to map the resulting padded tensor to a complex type (seen\n        as a real number). Defaults to True.\n\n    Returns\n    -------\n    output : tensor\n        A padded signal, possibly transformed into a four-dimensional tensor\n        with the last axis of size 2 if to_complex is True (this axis\n        corresponds to the real and imaginary parts).\n    """"""\n    output = pad_1d(x, pad_left, pad_right, mode=\'reflect\')\n    if to_complex:\n        output = torch.stack((output, torch.zeros_like(output)), dim=-1)\n    return output\n\ndef unpad(x, i0, i1):\n    """"""Unpad real 1D tensor\n\n    Slices the input tensor at indices between i0 and i1 along the last axis.\n\n    Parameters\n    ----------\n    x : tensor\n        Input tensor with least one axis.\n    i0 : int\n        Start of original signal before padding.\n    i1 : int\n        End of original signal before padding.\n\n    Returns\n    -------\n    x_unpadded : tensor\n        The tensor x[..., i0:i1].\n    """"""\n    return x[..., i0:i1]\n\n\nfft = FFT(lambda x: torch.fft(x, 1, normalized=False),\n    lambda x: torch.ifft(x, 1, normalized=False),\n    lambda x: torch.irfft(x, 1, normalized=False, onesided=False),\n    type_checks)\n\n\nbackend = namedtuple(\'backend\', [\'name\', \'modulus_complex\', \'subsample_fourier\', \'real\', \'unpad\', \'fft\', \'concatenate\'])\nbackend.name = \'torch\'\nbackend.modulus_complex = Modulus()\nbackend.subsample_fourier = subsample_fourier\nbackend.real = real\nbackend.unpad = unpad\nbackend.cdgmm = cdgmm\nbackend.pad = pad\nbackend.pad_1d = pad_1d\nbackend.fft = fft\nbackend.concatenate = lambda x: concatenate(x, -2)\n'"
kymatio/scattering1d/backend/torch_skcuda_backend.py,0,"b'# Authors: Edouard Oyallon, Joakim Anden\n\nimport torch\nimport cupy\nfrom collections import namedtuple\nfrom string import Template\n\nBACKEND_NAME = \'torch_skcuda\'\n\n@cupy.util.memoize(for_each_device=True)\ndef load_kernel(kernel_name, code, **kwargs):\n    code = Template(code).substitute(**kwargs)\n    kernel_code = cupy.cuda.compile_with_cache(code)\n    return kernel_code.get_function(kernel_name)\n\nStream = namedtuple(\'Stream\', [\'ptr\'])\n\ndef get_dtype(t):\n    if isinstance(t, torch.cuda.FloatTensor):\n        return \'float\'\n    elif isinstance(t, torch.cuda.DoubleTensor):\n        return \'double\'\n\ndef _is_complex(input):\n    return input.shape[-1] == 2\n\nclass Modulus(object):\n    """"""Stable complex modulus\n\n    This class implements a modulus transform for complex numbers which is\n    stable with respect to very small inputs (z close to 0), avoiding\n    returning nans in all cases.\n\n    Usage\n    -----\n    modulus = ModulusStable.apply  # apply inherited from Function\n    x_mod = modulus(x)\n\n    Parameters\n    ---------\n    x : tensor\n        The complex tensor (i.e., whose last dimension is two) whose modulus\n        we want to compute.\n\n    Returns\n    -------\n    output : tensor\n        A tensor of same size as the input tensor, except for the last\n        dimension, which is removed. This tensor is differentiable with respect\n        to the input in a stable fashion (so gradent of the modulus at zero is\n        zero).\n    """"""\n\n    def __init__(self, backend=\'skcuda\'):\n        self.CUDA_NUM_THREADS = 1024\n        self.backend = backend\n\n    def get_blocks(self, N):\n        return (N + self.CUDA_NUM_THREADS - 1) // self.CUDA_NUM_THREADS\n\n    def __call__(self, x):\n        if not x.is_cuda and self.backend==\'skcuda\':\n            raise TypeError(\'Use the torch backend (without skcuda) for CPU tensors.\')\n\n        out = x.new(x.shape)\n\n        if not x.is_contiguous():\n            raise RuntimeError(\'Input should be contiguous.\')\n\n        if not _is_complex(x):\n            raise TypeError(\'The input and outputs should be complex.\')\n\n        kernel = """"""\n        extern ""C""\n        __global__ void abs_complex_value(const ${dtype} * x, ${dtype}2 * z, int n)\n        {\n            int i = blockIdx.x * blockDim.x + threadIdx.x;\n        if (i >= n)\n            return;\n        z[i] = make_${dtype}2(normf(2, x + 2*i), 0);\n\n        }\n        """"""\n        fabs = load_kernel(\'abs_complex_value\', kernel, dtype=get_dtype(x))\n        fabs(grid=(self.get_blocks(int(out.nelement())//2), 1, 1),\n             block=(self.CUDA_NUM_THREADS, 1, 1),\n             args=[x.data_ptr(), out.data_ptr(), out.numel() // 2],\n             stream=Stream(ptr=torch.cuda.current_stream().cuda_stream))\n        return out\n\nmodulus = Modulus()\n\ndef modulus_complex(x):\n    """"""Compute the complex modulus\n\n    Computes the modulus of x and stores the result in a complex tensor of the\n    same size, with the real part equal to the modulus and the imaginary part\n    equal to zero.\n\n    Parameters\n    ----------\n    x : tensor\n        A complex tensor (that is, whose last dimension is equal to 2).\n\n    Returns\n    -------\n    norm : tensor\n        A tensor with the same dimensions as x, such that norm[..., 0] contains\n        the complex modulus of x, while norm[..., 1] = 0.\n    """"""\n    return modulus(x)\n\nclass SubsampleFourier(object):\n    """"""Subsampling in the Fourier domain\n\n    Subsampling in the temporal domain amounts to periodization in the Fourier\n    domain, so the input is periodized according to the subsampling factor.\n\n    Usage\n    -----\n    sub_fourier = SubsampleFourier()\n    res = sub_fourier(x, 8)\n\n    Parameters\n    ----------\n    x : tensor\n        Input tensor with at least 3 dimensions, where the next to last\n        corresponds to the frequency index in the standard PyTorch FFT\n        ordering. The length of this dimension should be a power of 2 to\n        avoid errors. The last dimension should represent the real and\n        imaginary parts of the Fourier transform.\n    k : int\n        The subsampling factor.\n\n    Returns\n    -------\n    res : tensor\n        The input tensor periodized along the next to last axis to yield a\n        tensor of size x.shape[-2] // k along that dimension.\n    """"""\n    def __init__(self, backend=\'skcuda\'):\n        self.block = (1024, 1, 1)\n        self.backend = backend\n\n    def get_blocks(self, N, threads):\n        return (N + threads - 1) // threads\n\n    def __call__(self, x, k):\n        if not x.is_cuda and self.backend == \'skcuda\':\n            raise TypeError(\'Use the torch backend (without skcuda) for CPU tensors.\')\n\n        if not _is_complex(x):\n            raise TypeError(\'The input and outputs should be complex.\')\n\n        if not x.is_contiguous():\n            raise RuntimeError(\'Input should be contiguous.\')\n\n        out = x.new(x.shape[0], x.shape[1], x.shape[2] // k, 2)\n\n        kernel = \'\'\'\n        #define NT ${T} / ${k}\n        extern ""C""\n        __global__ void periodize(const ${dtype}2 *input, ${dtype}2 *output)\n        {\n          int tx = blockIdx.x * blockDim.x + threadIdx.x;\n          int ty = blockIdx.y * blockDim.y + threadIdx.y;\n\n          if(tx >= NT || ty >= ${B})\n            return;\n          input += ty * ${T} + tx;\n          ${dtype}2 res = make_${dtype}2(0.f, 0.f);\n\n            for (int i=0; i<${k}; ++i)\n            {\n              const ${dtype}2 &c = input[i * NT];\n              res.x += c.x;\n              res.y += c.y;\n            }\n          res.x /= ${k};\n          res.y /= ${k};\n          output[ty * NT + tx] = res;\n        }\n        \'\'\'\n        B = x.shape[0] * x.shape[1]\n        T = x.shape[2]\n        periodize = load_kernel(\'periodize\', kernel, B=B, T=T, k=k, dtype=get_dtype(x))\n        grid = (self.get_blocks(out.shape[-2], self.block[0]),\n                self.get_blocks(out.nelement() // (2*out.shape[-2]), self.block[1]),\n                1)\n        periodize(grid=grid, block=self.block, args=[x.data_ptr(), out.data_ptr()],\n                  stream=Stream(ptr=torch.cuda.current_stream().cuda_stream))\n        return out\n\nsubsamplefourier = SubsampleFourier()\n\ndef subsample_fourier(x, k):\n    """"""Subsampling in the Fourier domain\n\n    Subsampling in the temporal domain amounts to periodization in the Fourier\n    domain, so the input is periodized according to the subsampling factor.\n\n    Parameters\n    ----------\n    x : tensor\n        Input tensor with at least 3 dimensions, where the next to last\n        corresponds to the frequency index in the standard PyTorch FFT\n        ordering. The length of this dimension should be a power of 2 to\n        avoid errors. The last dimension should represent the real and\n        imaginary parts of the Fourier transform.\n    k : int\n        The subsampling factor.\n\n    Returns\n    -------\n    res : tensor\n        The input tensor periodized along the next to last axis to yield a\n        tensor of size x.shape[-2] // k along that dimension.\n    """"""\n    return subsamplefourier(x,k)\n\n\nfrom .torch_backend import real, cdgmm, unpad, pad, pad_1d, concatenate, fft\n\nbackend = namedtuple(\'backend\', [\'name\', \'modulus_complex\', \'subsample_fourier\', \'real\', \'unpad\', \'fft\', \'concatenate\'])\n\nbackend.name = \'torch_skcuda\'\nbackend.modulus_complex = modulus_complex\nbackend.subsample_fourier = subsample_fourier\nbackend.real = real\nbackend.cdgmm = cdgmm\nbackend.unpad = unpad\nbackend.pad = pad\nbackend.pad_1d = pad_1d\nbackend.fft = fft\nbackend.concatenate = lambda x: concatenate(x, -2)\n'"
kymatio/scattering1d/core/__init__.py,0,b''
kymatio/scattering1d/core/scattering1d.py,0,"b'# Authors: Mathieu Andreux, Joakim Anden, Edouard Oyallon\n# Scientific Ancestry: Joakim Anden, Mathieu Andreux, Vincent Lostanlen\n\n\ndef scattering1d(x, pad, unpad, backend, J, psi1, psi2, phi, pad_left=0,\n        pad_right=0, ind_start=None, ind_end=None, oversampling=0,\n        max_order=2, average=True, size_scattering=(0, 0, 0),\n        vectorize=False, out_type=\'array\'):\n    """"""\n    Main function implementing the 1-D scattering transform.\n\n    Parameters\n    ----------\n    x : Tensor\n        a torch Tensor of size `(B, 1, T)` where `T` is the temporal size\n    psi1 : dictionary\n        a dictionary of filters (in the Fourier domain), with keys (`j`, `q`).\n        `j` corresponds to the downsampling factor for\n        :math:`x \\\\ast psi1[(j, q)]``, and `q` corresponds to a pitch class\n        (chroma).\n        * psi1[(j, n)] is itself a dictionary, with keys corresponding to the\n        dilation factors: psi1[(j, n)][j2] corresponds to a support of size\n        :math:`2^{J_\\\\text{max} - j_2}`, where :math:`J_\\\\text{max}` has been\n        defined a priori (`J_max = size` of the padding support of the input)\n        * psi1[(j, n)] only has real values;\n        the tensors are complex so that broadcasting applies\n    psi2 : dictionary\n        a dictionary of filters, with keys (j2, n2). Same remarks as for psi1\n    phi : dictionary\n        a dictionary of filters of scale :math:`2^J` with keys (`j`)\n        where :math:`2^j` is the downsampling factor.\n        The array `phi[j]` is a real-valued filter.\n    J : int\n        scale of the scattering\n    pad_left : int, optional\n        how much to pad the signal on the left. Defaults to `0`\n    pad_right : int, optional\n        how much to pad the signal on the right. Defaults to `0`\n    ind_start : dictionary of ints, optional\n        indices to truncate the signal to recover only the\n        parts which correspond to the actual signal after padding and\n        downsampling. Defaults to None\n    ind_end : dictionary of ints, optional\n        See description of ind_start\n    oversampling : int, optional\n        how much to oversample the scattering (with respect to :math:`2^J`):\n        the higher, the larger the resulting scattering\n        tensor along time. Defaults to `0`\n    order2 : boolean, optional\n        Whether to compute the 2nd order or not. Defaults to `False`.\n    average_U1 : boolean, optional\n        whether to average the first order vector. Defaults to `True`\n    size_scattering : tuple\n        Contains the number of channels of the scattering, precomputed for\n        speed-up. Defaults to `(0, 0, 0)`.\n    vectorize : boolean, optional\n        whether to return a dictionary or a tensor. Defaults to False.\n\n    """"""\n    subsample_fourier = backend.subsample_fourier\n    modulus_complex = backend.modulus_complex\n    real = backend.real\n    fft = backend.fft\n    cdgmm = backend.cdgmm\n    concatenate = backend.concatenate\n\n\n    # S is simply a dictionary if we do not perform the averaging...\n    batch_size = x.shape[0]\n    kJ = max(J - oversampling, 0)\n    temporal_size = ind_end[kJ] - ind_start[kJ]\n    out_S_0, out_S_1, out_S_2 = [], [], []\n\n    # pad to a dyadic size and make it complex\n    U_0 = pad(x, pad_left=pad_left, pad_right=pad_right)\n\n    # compute the Fourier transform\n    U_0_hat = fft(U_0, \'C2C\')\n\n    # Get S0\n    k0 = max(J - oversampling, 0)\n\n    if average:\n        S_0_c = cdgmm(U_0_hat, phi[0])\n        S_0_hat = subsample_fourier(S_0_c, 2**k0)\n        S_0_r = fft(S_0_hat, \'C2R\', inverse=True)\n\n        S_0 = unpad(S_0_r, ind_start[k0], ind_end[k0])\n    else:\n        S_0 = x\n\n    out_S_0.append({\'coef\': S_0,\n                    \'j\': (),\n                    \'n\': ()})\n\n    # First order:\n    for n1 in range(len(psi1)):\n        # Convolution + downsampling\n        j1 = psi1[n1][\'j\']\n\n        k1 = max(j1 - oversampling, 0)\n\n        assert psi1[n1][\'xi\'] < 0.5 / (2**k1)\n\n        U_1_c = cdgmm(U_0_hat, psi1[n1][0])\n        U_1_hat = subsample_fourier(U_1_c, 2**k1)\n        U_1_c = fft(U_1_hat, \'C2C\', inverse=True)\n\n        # Take the modulus\n        U_1_m = modulus_complex(U_1_c)\n\n        if average or max_order > 1:\n            U_1_hat = fft(U_1_m, \'C2C\')\n\n        if average:\n            # Convolve with phi_J\n            k1_J = max(J - k1 - oversampling, 0)\n\n            S_1_c = cdgmm(U_1_hat, phi[k1])\n            S_1_hat = subsample_fourier(S_1_c, 2**k1_J)\n            S_1_r = fft(S_1_hat, \'C2R\', inverse=True)\n\n            S_1 = unpad(S_1_r, ind_start[k1_J + k1], ind_end[k1_J + k1])\n        else:\n            # just take the real value and unpad\n            U_1_r = real(U_1_m)\n\n            S_1 = unpad(U_1_r, ind_start[k1], ind_end[k1])\n\n        out_S_1.append({\'coef\': S_1,\n                        \'j\': (j1,),\n                        \'n\': (n1,)})\n\n        if max_order == 2:\n            # 2nd order\n            for n2 in range(len(psi2)):\n                j2 = psi2[n2][\'j\']\n\n                if j2 > j1:\n                    assert psi2[n2][\'xi\'] < psi1[n1][\'xi\']\n\n                    # convolution + downsampling\n                    k2 = max(j2 - k1 - oversampling, 0)\n\n                    U_2_c = cdgmm(U_1_hat, psi2[n2][k1])\n                    U_2_hat = subsample_fourier(U_2_c, 2**k2)\n                    # take the modulus\n                    U_2_c = fft(U_2_hat, \'C2C\', inverse=True)\n\n                    U_2_m = modulus_complex(U_2_c)\n\n                    if average:\n                        U_2_hat = fft(U_2_m, \'C2C\')\n\n                        # Convolve with phi_J\n                        k2_J = max(J - k2 - k1 - oversampling, 0)\n\n                        S_2_c = cdgmm(U_2_hat, phi[k1 + k2])\n                        S_2_hat = subsample_fourier(S_2_c, 2**k2_J)\n                        S_2_r = fft(S_2_hat, \'C2R\', inverse=True)\n\n                        S_2 = unpad(S_2_r, ind_start[k1 + k2 + k2_J], ind_end[k1 + k2 + k2_J])\n                    else:\n                        # just take the real value and unpad\n                        U_2_r = real(U_2_m)\n                        S_2 = unpad(U_2_r, ind_start[k1 + k2], ind_end[k1 + k2])\n\n                    out_S_2.append({\'coef\': S_2,\n                                    \'j\': (j1, j2),\n                                    \'n\': (n1, n2)})\n\n    out_S = []\n    out_S.extend(out_S_0)\n    out_S.extend(out_S_1)\n    out_S.extend(out_S_2)\n\n    if out_type == \'array\' and vectorize:\n        out_S = concatenate([x[\'coef\'] for x in out_S])\n    elif out_type == \'array\' and not vectorize:\n        out_S = {x[\'n\']: x[\'coef\'] for x in out_S}\n    elif out_type == \'list\':\n        # NOTE: This overrides the vectorize flag.\n        for x in out_S:\n            x.pop(\'n\')\n\n    return out_S\n\n__all__ = [\'scattering1d\']\n'"
kymatio/scattering1d/frontend/__init__.py,0,b''
kymatio/scattering1d/frontend/base_frontend.py,2,"b'from ...frontend.base_frontend import ScatteringBase\nimport math\nimport numbers\n\nimport numpy as np\n\nfrom ..filter_bank import scattering_filter_factory\nfrom ..utils import (compute_border_indices, compute_padding, compute_minimum_support_to_pad,\ncompute_meta_scattering, precompute_size_scattering)\n\n\nclass ScatteringBase1D(ScatteringBase):\n    def __init__(self, J, shape, Q=1, max_order=2, average=True,\n            oversampling=0, vectorize=True, out_type=\'array\', backend=None):\n        super(ScatteringBase1D, self).__init__()\n        self.J = J\n        self.shape = shape\n        self.Q = Q\n        self.max_order = max_order\n        self.average = average\n        self.oversampling = oversampling\n        self.vectorize = vectorize\n        self.out_type = out_type\n        self.backend = backend\n\n    def build(self):\n        """"""Set up padding and filters\n\n        Certain internal data, such as the amount of padding and the wavelet\n        filters to be used in the scattering transform, need to be computed\n        from the parameters given during construction. This function is called\n        automatically during object creation and no subsequent calls are\n        therefore needed.\n        """"""\n        self.r_psi = math.sqrt(0.5)\n        self.sigma0 = 0.1\n        self.alpha = 5.\n        self.P_max = 5\n        self.eps = 1e-7\n        self.criterion_amplitude = 1e-3\n        self.normalize = \'l1\'\n\n        # check the shape\n        if isinstance(self.shape, numbers.Integral):\n            self.T = self.shape\n        elif isinstance(self.shape, tuple):\n            self.T = self.shape[0]\n            if len(self.shape) > 1:\n                raise ValueError(""If shape is specified as a tuple, it must ""\n                                 ""have exactly one element"")\n        else:\n            raise ValueError(""shape must be an integer or a 1-tuple"")\n\n        # Compute the minimum support to pad (ideally)\n        min_to_pad = compute_minimum_support_to_pad(\n            self.T, self.J, self.Q, r_psi=self.r_psi, sigma0=self.sigma0,\n            alpha=self.alpha, P_max=self.P_max, eps=self.eps,\n            criterion_amplitude=self.criterion_amplitude,\n            normalize=self.normalize)\n        # to avoid padding more than T - 1 on the left and on the right,\n        # since otherwise torch sends nans\n        J_max_support = int(np.floor(np.log2(3 * self.T - 2)))\n        self.J_pad = min(int(np.ceil(np.log2(self.T + 2 * min_to_pad))),\n                         J_max_support)\n        # compute the padding quantities:\n        self.pad_left, self.pad_right = compute_padding(self.J_pad, self.T)\n        # compute start and end indices\n        self.ind_start, self.ind_end = compute_border_indices(\n            self.J, self.pad_left, self.pad_left + self.T)\n\n    def create_filters(self):\n        # Create the filters\n        self.phi_f, self.psi1_f, self.psi2_f, _ = scattering_filter_factory(\n            self.J_pad, self.J, self.Q, normalize=self.normalize,\n            criterion_amplitude=self.criterion_amplitude,\n            r_psi=self.r_psi, sigma0=self.sigma0, alpha=self.alpha,\n            P_max=self.P_max, eps=self.eps)\n\n    def meta(self):\n        """"""Get meta information on the transform\n\n        Calls the static method `compute_meta_scattering()` with the\n        parameters of the transform object.\n\n        Returns\n        ------\n        meta : dictionary\n            See the documentation for `compute_meta_scattering()`.\n        """"""\n        return compute_meta_scattering(self.J, self.Q, max_order=self.max_order)\n\n    def output_size(self, detail=False):\n        """"""Get size of the scattering transform\n\n        Calls the static method `precompute_size_scattering()` with the\n        parameters of the transform object.\n\n        Parameters\n        ----------\n        detail : boolean, optional\n            Specifies whether to provide a detailed size (number of coefficient\n            per order) or an aggregate size (total number of coefficients).\n\n        Returns\n        ------\n        size : int or tuple\n            See the documentation for `precompute_size_scattering()`.\n        """"""\n\n        return precompute_size_scattering(\n            self.J, self.Q, max_order=self.max_order, detail=detail)\n\n    _doc_shape = \'T\'\n\n    _doc_instantiation_shape = {True: \'S = Scattering1D(J, T, Q)\',\n                                False: \'S = Scattering1D(J, Q)\'}\n\n    _doc_param_shape = \\\n    r""""""shape : int\n            The length of the input signals.\n        """"""\n\n    _doc_attrs_shape = \\\n    r""""""J_pad : int\n            The logarithm of the padded length of the signals.\n        pad_left : int\n            The amount of padding to the left of the signal.\n        pad_right : int\n            The amount of padding to the right of the signal.\n        phi_f : dictionary\n            A dictionary containing the lowpass filter at all resolutions. See\n            `filter_bank.scattering_filter_factory` for an exact description.\n        psi1_f : dictionary\n            A dictionary containing all the first-order wavelet filters, each\n            represented as a dictionary containing that filter at all\n            resolutions. See `filter_bank.scattering_filter_factory` for an\n            exact description.\n        psi2_f : dictionary\n            A dictionary containing all the second-order wavelet filters, each\n            represented as a dictionary containing that filter at all\n            resolutions. See `filter_bank.scattering_filter_factory` for an\n            exact description.\n        """"""\n\n    _doc_param_average = \\\n    r""""""average : boolean, optional\n            Determines whether the output is averaged in time or not. The\n            averaged output corresponds to the standard scattering transform,\n            while the un-averaged output skips the last convolution by\n            :math:`\\phi_J(t)`.  This parameter may be modified after object\n            creation. Defaults to `True`.\n        """"""\n\n    _doc_attr_average = \\\n    r""""""average : boolean\n            Controls whether the output should be averaged (the standard\n            scattering transform) or not (resulting in wavelet modulus\n            coefficients). Note that to obtain unaveraged output, the\n            `vectorize` flag must be set to `False` or `out_type` must be set\n            to `\'list\'`.\n     """"""\n\n    _doc_param_vectorize = \\\n    r""""""vectorize : boolean, optional\n            Determines wheter to return a vectorized scattering transform\n            (that is, a large array containing the output) or a dictionary\n            (where each entry corresponds to a separate scattering\n            coefficient). This parameter may be modified after object\n            creation. Deprecated in favor of `out_type` (see below). Defaults\n            to True.\n        out_type : str, optional\n            The format of the output of a scattering transform. If set to\n            `\'list\'`, then the output is a list containing each individual\n            scattering coefficient with meta information. Otherwise, if set to\n            `\'array\'`, the output is a large array containing the\n            concatenation of all scattering coefficients. Defaults to\n            `\'array\'`.\n        """"""\n\n    _doc_attr_vectorize = \\\n    r""""""vectorize : boolean\n            Controls whether the output should be vectorized into a single\n            Tensor or collected into a dictionary. Deprecated in favor of\n            `out_type`. For more details, see the documentation for\n            `scattering`.\n        out_type : str\n            Specifices the output format of the transform, which is currently\n            one of `\'array\'` or `\'list`\'. If `\'array\'`, the output is a large\n            array containing the scattering coefficients. If `\'list`\', the\n            output is a list of dictionaries, each containing a scattering\n            coefficient along with meta information. For more information, see\n            the documentation for `scattering`.\n        """"""\n\n    _doc_class = \\\n    r""""""The 1D scattering transform\n\n        The scattering transform computes a cascade of wavelet transforms\n        alternated with a complex modulus non-linearity. The scattering\n        transform of a 1D signal :math:`x(t)` may be written as\n\n            $S_J x = [S_J^{{(0)}} x, S_J^{{(1)}} x, S_J^{{(2)}} x]$\n\n        where\n\n            $S_J^{{(0)}} x(t) = x \\star \\phi_J(t)$,\n\n            $S_J^{{(1)}} x(t, \\lambda) = |x \\star \\psi_\\lambda^{{(1)}}| \\star \\phi_J$, and\n\n            $S_J^{{(2)}} x(t, \\lambda, \\mu) = |\\,| x \\star \\psi_\\lambda^{{(1)}}| \\star \\psi_\\mu^{{(2)}} | \\star \\phi_J$.\n\n        In the above formulas, :math:`\\star` denotes convolution in time. The\n        filters $\\psi_\\lambda^{{(1)}}(t)$ and $\\psi_\\mu^{{(2)}}(t)$ are analytic\n        wavelets with center frequencies $\\lambda$ and $\\mu$, while\n        $\\phi_J(t)$ is a real lowpass filter centered at the zero frequency.\n\n        The `Scattering1D` class implements the 1D scattering transform for a\n        given set of filters whose parameters are specified at initialization.\n        While the wavelets are fixed, other parameters may be changed after\n        the object is created, such as whether to compute all of\n        :math:`S_J^{{(0)}} x`, $S_J^{{(1)}} x$, and $S_J^{{(2)}} x$ or just\n        $S_J^{{(0)}} x$ and $S_J^{{(1)}} x$.\n        {frontend_paragraph}\n        Given an input `{array}` `x` of shape `(B, T)`, where `B` is the\n        number of signals to transform (the batch size) and `T` is the length\n        of the signal, we compute its scattering transform by passing it to\n        the `scattering` method (or calling the alias `{alias_name}`). Note\n        that `B` can be one, in which case it may be omitted, giving an input\n        of shape `(T,)`.\n\n        Example\n        -------\n        ::\n\n            # Set the parameters of the scattering transform.\n            J = 6\n            T = 2 ** 13\n            Q = 8\n\n            # Generate a sample signal.\n            x = {sample}\n\n            # Define a Scattering1D object.\n            {instantiation}\n\n            # Calculate the scattering transform.\n            Sx = S.scattering(x)\n\n            # Equivalently, use the alias.\n            Sx = S{alias_call}(x)\n\n        Above, the length of the signal is :math:`T = 2^{{13}} = 8192`, while the\n        maximum scale of the scattering transform is set to :math:`2^J = 2^6 =\n        64`. The time-frequency resolution of the first-order wavelets\n        :math:`\\psi_\\lambda^{{(1)}}(t)` is set to `Q = 8` wavelets per octave.\n        The second-order wavelets :math:`\\psi_\\mu^{{(2)}}(t)` always have one\n        wavelet per octave.\n\n        Parameters\n        ----------\n        J : int\n            The maximum log-scale of the scattering transform. In other words,\n            the maximum scale is given by :math:`2^J`.\n        {param_shape}Q : int >= 1\n            The number of first-order wavelets per octave (second-order\n            wavelets are fixed to one wavelet per octave). Defaults to `1`.\n        max_order : int, optional\n            The maximum order of scattering coefficients to compute. Must be\n            either `1` or `2`. Defaults to `2`.\n        {param_average}oversampling : integer >= 0, optional\n            Controls the oversampling factor relative to the default as a\n            power of two. Since the convolving by wavelets (or lowpass\n            filters) and taking the modulus reduces the high-frequency content\n            of the signal, we can subsample to save space and improve\n            performance. However, this may reduce precision in the\n            calculation. If this is not desirable, `oversampling` can be set\n            to a large value to prevent too much subsampling. This parameter\n            may be modified after object creation. Defaults to `0`.\n        {param_vectorize}\n        Attributes\n        ----------\n        J : int\n            The maximum log-scale of the scattering transform. In other words,\n            the maximum scale is given by `2 ** J`.\n        {param_shape}Q : int\n            The number of first-order wavelets per octave (second-order\n            wavelets are fixed to one wavelet per octave).\n        {attrs_shape}max_order : int\n            The maximum scattering order of the transform.\n        {attr_average}oversampling : int\n            The number of powers of two to oversample the output compared to\n            the default subsampling rate determined from the filters.\n        {attr_vectorize}""""""\n\n    _doc_scattering = \\\n    """"""Apply the scattering transform\n\n       Given an input `{array}` of size `(B, T)`, where `B` is the batch\n       size (it can be potentially an integer or a shape) and `T` is the length\n       of the individual signals, this function computes its scattering\n       transform. If the `vectorize` flag is set to `True` (or if it is not\n       available in this frontend), the output is in the form of a `{array}`\n       or size `(B, C, T1)`, where `T1` is the signal length after subsampling\n       to the scale :math:`2^J` (with the appropriate oversampling factor to\n       reduce aliasing), and `C` is the number of scattering coefficients. If\n       `vectorize` is set `False`, however, the output is a dictionary\n       containing `C` keys, each a tuple whose length corresponds to the\n       scattering order and whose elements are the sequence of filter indices\n       used.\n\n       Note that the `vectorize` flag has been deprecated in favor of the\n       `out_type` parameter. If this is set to `\'array\'` (the default), the\n       `vectorize` flag is still respected, but if not, `out_type` takes\n       precedence. The two current output types are `\'array\'` and `\'list\'`.\n       The former gives the type of output described above. If set to\n       `\'list\'`, however, the output is a list of dictionaries, each\n       dictionary corresponding to a scattering coefficient and its associated\n       meta information. The coefficient is stored under the `\'coef\'` key,\n       while other keys contain additional information, such as `\'j\'` (the\n       scale of the filter used) and `\'n`\' (the filter index).\n\n       Furthermore, if the `average` flag is set to `False`, these outputs\n       are not averaged, but are simply the wavelet modulus coefficients of\n       the filters.\n\n       Parameters\n       ----------\n       x : {array}\n           An input `{array}` of size `(B, T)`.\n\n       Returns\n       -------\n       S : tensor or dictionary\n           If `out_type` is `\'array\'` and the `vectorize` flag is `True`, the\n           output is a{n} `{array}` containing the scattering coefficients,\n           while if `vectorize` is `False`, it is a dictionary indexed by\n           tuples of filter indices. If `out_type` is `\'list\'`, the output is\n           a list of dictionaries as described above.\n    """"""\n\n    @classmethod\n    def _document(cls):\n        instantiation = cls._doc_instantiation_shape[cls._doc_has_shape]\n        param_shape = cls._doc_param_shape if cls._doc_has_shape else \'\'\n        attrs_shape = cls._doc_attrs_shape if cls._doc_has_shape else \'\'\n\n        param_average = cls._doc_param_average if cls._doc_has_out_type else \'\'\n        attr_average = cls._doc_attr_average if cls._doc_has_out_type else \'\'\n        param_vectorize = cls._doc_param_vectorize if cls._doc_has_out_type else \'\'\n        attr_vectorize = cls._doc_attr_vectorize if cls._doc_has_out_type else \'\'\n\n        cls.__doc__ = ScatteringBase1D._doc_class.format(\n            array=cls._doc_array,\n            frontend_paragraph=cls._doc_frontend_paragraph,\n            alias_name=cls._doc_alias_name,\n            alias_call=cls._doc_alias_call,\n            instantiation=instantiation,\n            param_shape=param_shape,\n            attrs_shape=attrs_shape,\n            param_average=param_average,\n            attr_average=attr_average,\n            param_vectorize=param_vectorize,\n            attr_vectorize=attr_vectorize,\n            sample=cls._doc_sample.format(shape=cls._doc_shape))\n\n        cls.scattering.__doc__ = ScatteringBase1D._doc_scattering.format(\n            array=cls._doc_array,\n            n=cls._doc_array_n)\n\n\n__all__ = [\'ScatteringBase1D\']\n'"
kymatio/scattering1d/frontend/entry.py,0,"b""from ...frontend.entry import ScatteringEntry\n\nclass ScatteringEntry1D(ScatteringEntry):\n    def __init__(self, *args, **kwargs):\n        super().__init__(name='1D', class_name='scattering1d', *args, **kwargs)\n\n\n__all__ = ['ScatteringEntry1D']\n"""
kymatio/scattering1d/frontend/keras_frontend.py,0,"b""from ...frontend.keras_frontend import ScatteringKeras\nfrom ...scattering1d.frontend.base_frontend import ScatteringBase1D\n\nfrom kymatio.tensorflow import Scattering1D as ScatteringTensorFlow1D\n\nfrom tensorflow.python.framework import tensor_shape\n\n\nclass ScatteringKeras1D(ScatteringKeras, ScatteringBase1D):\n    def __init__(self, J, Q=1, max_order=2, oversampling=0):\n        ScatteringKeras.__init__(self)\n        ScatteringBase1D.__init__(self, J, None, Q, max_order, True,\n                oversampling, True, 'array', None)\n\n    def build(self, input_shape):\n        shape = tuple(tensor_shape.TensorShape(input_shape).as_list()[-1:])\n        self.S = ScatteringTensorFlow1D(J=self.J, shape=shape,\n                                        Q=self.Q, max_order=self.max_order,\n                                        oversampling=self.oversampling)\n        ScatteringKeras.build(self, input_shape)\n\n    def compute_output_shape(self, input_shape):\n        input_shape = tensor_shape.TensorShape(input_shape).as_list()\n        nc = self.S.output_size()\n        k0 = max(self.J - self.oversampling, 0)\n        ln = self.S.ind_end[k0] - self.S.ind_start[k0]\n        output_shape = [input_shape[0], nc, ln]\n        return tensor_shape.TensorShape(output_shape)\n\n\nScatteringKeras1D._document()\n"""
kymatio/scattering1d/frontend/numpy_frontend.py,0,"b'# Authors: Mathieu Andreux, Joakim Anden, Edouard Oyallon\n# Scientific Ancestry: Joakim Anden, Mathieu Andreux, Vincent Lostanlen\n\nimport warnings\n\nfrom ...frontend.numpy_frontend import ScatteringNumPy\nfrom ..core.scattering1d import scattering1d\nfrom ..utils import precompute_size_scattering\nfrom .base_frontend import ScatteringBase1D\n\n\nclass ScatteringNumPy1D(ScatteringNumPy, ScatteringBase1D):\n    def __init__(self, J, shape, Q=1, max_order=2, average=True,\n            oversampling=0, vectorize=True, out_type=\'array\', backend=\'numpy\'):\n        ScatteringNumPy.__init__(self)\n        ScatteringBase1D.__init__(self, J, shape, Q, max_order, average,\n                oversampling, vectorize, out_type, backend)\n        ScatteringBase1D._instantiate_backend(self, \'kymatio.scattering1d.backend.\')\n        ScatteringBase1D.build(self)\n        ScatteringBase1D.create_filters(self)\n\n    def scattering(self, x):\n        # basic checking, should be improved\n        if len(x.shape) < 1:\n            raise ValueError(\n                \'Input tensor x should have at least one axis, got {}\'.format(\n                    len(x.shape)))\n\n        if not self.out_type in (\'array\', \'list\'):\n            raise RuntimeError(""The out_type must be one of \'array\' or \'list\'."")\n\n        if not self.average and self.out_type == \'array\' and self.vectorize:\n            raise ValueError(""Options average=False, out_type=\'array\' and ""\n                             ""vectorize=True are mutually incompatible. ""\n                             ""Please set out_type to \'list\' or vectorize to ""\n                             ""False."")\n        if not self.vectorize:\n            warnings.warn(""The vectorize option is deprecated and will be ""\n                          ""removed in version 0.3. Please set ""\n                          ""out_type=\'list\' for equivalent functionality."",\n                          DeprecationWarning)\n\n        batch_shape = x.shape[:-1]\n        signal_shape = x.shape[-1:]\n\n        x = x.reshape((-1, 1) + signal_shape)\n\n        # get the arguments before calling the scattering\n        # treat the arguments\n        if self.vectorize:\n            size_scattering = precompute_size_scattering(\n                self.J, self.Q, max_order=self.max_order, detail=True)\n        else:\n            size_scattering = 0\n\n        S = scattering1d(x, self.backend.pad, self.backend.unpad, self.backend, self.J, self.psi1_f, self.psi2_f,\n                         self.phi_f, max_order=self.max_order, average=self.average, pad_left=self.pad_left,\n                         pad_right=self.pad_right, ind_start=self.ind_start, ind_end=self.ind_end,\n                         oversampling=self.oversampling,\n                         vectorize=self.vectorize,\n                         size_scattering=size_scattering,\n                         out_type=self.out_type)\n\n        if self.out_type == \'array\' and self.vectorize:\n            scattering_shape = S.shape[-2:]\n            new_shape = batch_shape + scattering_shape\n\n            S = S.reshape(new_shape)\n        elif self.out_type == \'array\' and not self.vectorize:\n            for k, v in S.items():\n                # NOTE: Have to get the shape for each one since we may have\n                # average == False.\n                scattering_shape = v.shape[-2:]\n                new_shape = batch_shape + scattering_shape\n\n                S[k] = v.reshape(new_shape)\n        elif self.out_type == \'list\':\n            for x in S:\n                scattering_shape = x[\'coef\'].shape[-1:]\n                new_shape = batch_shape + scattering_shape\n\n                x[\'coef\'] = x[\'coef\'].reshape(new_shape)\n\n        return S\n\n\nScatteringNumPy1D._document()\n\n\n__all__ = [\'ScatteringNumPy1D\']\n'"
kymatio/scattering1d/frontend/sklearn_frontend.py,0,"b""from ...frontend.sklearn_frontend import ScatteringTransformerMixin\nfrom ...numpy import Scattering1D as ScatteringNumPy1D\n\n\n# NOTE: Order in base classes matters here, since we want the sklearn-specific\n# documentation parameters to take precedence over NP.\nclass ScatteringTransformer1D(ScatteringTransformerMixin, ScatteringNumPy1D):\n    pass\n\n\nScatteringTransformer1D._document()\n\n\n__all__ = ['ScatteringTransformer1D']\n"""
kymatio/scattering1d/frontend/tensorflow_frontend.py,0,"b'# Authors: Mathieu Andreux, Joakim Anden, Edouard Oyallon\n# Scientific Ancestry: Joakim Anden, Mathieu Andreux, Vincent Lostanlen\nimport tensorflow as tf\nimport warnings\n\nfrom ...frontend.tensorflow_frontend import ScatteringTensorFlow\nfrom ..core.scattering1d import scattering1d\nfrom ..utils import precompute_size_scattering\nfrom .base_frontend import ScatteringBase1D\n\n\nclass ScatteringTensorFlow1D(ScatteringTensorFlow, ScatteringBase1D):\n    def __init__(self, J, shape, Q=1, max_order=2, average=True,\n            oversampling=0, vectorize=True, out_type=\'array\', backend=\'tensorflow\',\n                 name=\'Scattering1D\'):\n        ScatteringTensorFlow.__init__(self, name=name)\n        ScatteringBase1D.__init__(self, J, shape, Q, max_order, average,\n                oversampling, vectorize, out_type, backend)\n        ScatteringBase1D._instantiate_backend(self, \'kymatio.scattering1d.backend.\')\n        ScatteringBase1D.build(self)\n        ScatteringBase1D.create_filters(self)\n\n    def scattering(self, x):\n        # basic checking, should be improved\n        if len(x.shape) < 1:\n            raise ValueError(\n                \'Input tensor x should have at least one axis, got {}\'.format(\n                    len(x.shape)))\n\n        if not self.out_type in (\'array\', \'list\'):\n            raise RuntimeError(""The out_type must be one of \'array\' or \'list\'."")\n\n        if not self.average and self.out_type == \'array\' and self.vectorize:\n            raise ValueError(""Options average=False, out_type=\'array\' and ""\n                             ""vectorize=True are mutually incompatible. ""\n                             ""Please set out_type to \'list\' or vectorize to ""\n                             ""False."")\n\n        if not self.vectorize:\n            warnings.warn(""The vectorize option is deprecated and will be ""\n                          ""removed in version 0.3. Please set ""\n                          ""out_type=\'list\' for equivalent functionality."",\n                          DeprecationWarning)\n\n        batch_shape = tf.shape(x)[:-1]\n        signal_shape = tf.shape(x)[-1:]\n\n        x = tf.reshape(x, tf.concat(((-1, 1), signal_shape), 0))\n\n        # get the arguments before calling the scattering\n        # treat the arguments\n        if self.vectorize:\n            size_scattering = precompute_size_scattering(\n                self.J, self.Q, max_order=self.max_order, detail=True)\n        else:\n            size_scattering = 0\n\n        S = scattering1d(x, self.backend.pad, self.backend.unpad, self.backend, self.J, self.psi1_f, self.psi2_f,\n                         self.phi_f, max_order=self.max_order, average=self.average, pad_left=self.pad_left,\n                         pad_right=self.pad_right, ind_start=self.ind_start, ind_end=self.ind_end,\n                         oversampling=self.oversampling,\n                         vectorize=self.vectorize,\n                         size_scattering=size_scattering,\n                         out_type=self.out_type)\n\n        if self.out_type == \'array\' and self.vectorize:\n            scattering_shape = tf.shape(S)[-2:]\n            new_shape = tf.concat((batch_shape, scattering_shape), 0)\n\n            S = tf.reshape(S, new_shape)\n        elif self.out_type == \'array\' and not self.vectorize:\n            for k, v in S.items():\n                # NOTE: Have to get the shape for each one since we may have\n                # average == False.\n                scattering_shape = tf.shape(v)[-2:]\n                new_shape = tf.concat((batch_shape, scattering_shape), 0)\n\n                S[k] = tf.reshape(v, new_shape)\n        elif self.out_type == \'list\':\n            for x in S:\n                scattering_shape = tf.shape(x[\'coef\'])[-1:]\n                new_shape = tf.concat((batch_shape, scattering_shape), 0)\n\n                x[\'coef\'] = tf.reshape(x[\'coef\'], new_shape)\n\n        return S\n\n\nScatteringTensorFlow1D._document()\n\n\n__all__ = [\'ScatteringTensorFlow1D\']\n'"
kymatio/scattering1d/frontend/torch_frontend.py,0,"b'# Authors: Mathieu Andreux, Joakim Anden, Edouard Oyallon\n# Scientific Ancestry: Joakim Anden, Mathieu Andreux, Vincent Lostanlen\n\nimport torch\nimport warnings\n\nfrom ...frontend.torch_frontend import ScatteringTorch\nfrom ..core.scattering1d import scattering1d\nfrom ..utils import precompute_size_scattering\nfrom .base_frontend import ScatteringBase1D\n\n\nclass ScatteringTorch1D(ScatteringTorch, ScatteringBase1D):\n    def __init__(self, J, shape, Q=1, max_order=2, average=True,\n            oversampling=0, vectorize=True, out_type=\'array\', backend=\'torch\'):\n        ScatteringTorch.__init__(self)\n        ScatteringBase1D.__init__(self, J, shape, Q, max_order, average,\n                oversampling, vectorize, out_type, backend)\n        ScatteringBase1D._instantiate_backend(self, \'kymatio.scattering1d.backend.\')\n        ScatteringBase1D.build(self)\n        ScatteringBase1D.create_filters(self)\n        self.register_filters()\n\n    def register_filters(self):\n        """""" This function run the filterbank function that\n        will create the filters as numpy array, and then, it\n        saves those arrays as module\'s buffers.""""""\n        n = 0\n        # prepare for pytorch\n        for k in self.phi_f.keys():\n            if type(k) != str:\n                # view(-1, 1).repeat(1, 2) because real numbers!\n                self.phi_f[k] = torch.from_numpy(\n                    self.phi_f[k]).float().view(-1, 1)\n                self.register_buffer(\'tensor\' + str(n), self.phi_f[k])\n                n += 1\n        for psi_f in self.psi1_f:\n            for sub_k in psi_f.keys():\n                if type(sub_k) != str:\n                    # view(-1, 1).repeat(1, 2) because real numbers!\n                    psi_f[sub_k] = torch.from_numpy(\n                        psi_f[sub_k]).float().view(-1, 1)\n                    self.register_buffer(\'tensor\' + str(n), psi_f[sub_k])\n                    n += 1\n        for psi_f in self.psi2_f:\n            for sub_k in psi_f.keys():\n                if type(sub_k) != str:\n                    # view(-1, 1).repeat(1, 2) because real numbers!\n                    psi_f[sub_k] = torch.from_numpy(\n                        psi_f[sub_k]).float().view(-1, 1)\n                    self.register_buffer(\'tensor\' + str(n), psi_f[sub_k])\n                    n += 1\n\n    def load_filters(self):\n        """"""This function loads filters from the module\'s buffer """"""\n        buffer_dict = dict(self.named_buffers())\n        n = 0\n\n        for k in self.phi_f.keys():\n            if type(k) != str:\n                self.phi_f[k] = buffer_dict[\'tensor\' + str(n)]\n                n += 1\n\n        for psi_f in self.psi1_f:\n            for sub_k in psi_f.keys():\n                if type(sub_k) != str:\n                    psi_f[sub_k] = buffer_dict[\'tensor\' + str(n)]\n                    n += 1\n\n        for psi_f in self.psi2_f:\n            for sub_k in psi_f.keys():\n                if type(sub_k) != str:\n                    psi_f[sub_k] = buffer_dict[\'tensor\' + str(n)]\n                    n += 1\n\n    def scattering(self, x):\n        # basic checking, should be improved\n        if len(x.shape) < 1:\n            raise ValueError(\n                \'Input tensor x should have at least one axis, got {}\'.format(\n                    len(x.shape)))\n\n        if not self.out_type in (\'array\', \'list\'):\n            raise RuntimeError(""The out_type must be one of \'array\' or \'list\'."")\n\n        if not self.average and self.out_type == \'array\' and self.vectorize:\n            raise ValueError(""Options average=False, out_type=\'array\' and ""\n                             ""vectorize=True are mutually incompatible. ""\n                             ""Please set out_type to \'list\' or vectorize to ""\n                             ""False."")\n\n        if not self.vectorize:\n            warnings.warn(""The vectorize option is deprecated and will be ""\n                          ""removed in version 0.3. Please set ""\n                          ""out_type=\'list\' for equivalent functionality."",\n                          DeprecationWarning)\n\n        batch_shape = x.shape[:-1]\n        signal_shape = x.shape[-1:]\n\n        x = x.reshape((-1, 1) + signal_shape)\n\n        self.load_filters()\n\n        # get the arguments before calling the scattering\n        # treat the arguments\n        if self.vectorize:\n            size_scattering = precompute_size_scattering(\n                self.J, self.Q, max_order=self.max_order, detail=True)\n        else:\n            size_scattering = 0\n\n\n        S = scattering1d(x, self.backend.pad, self.backend.unpad, self.backend, self.J, self.psi1_f, self.psi2_f, self.phi_f,\\\n                         max_order=self.max_order, average=self.average,\n                       pad_left=self.pad_left, pad_right=self.pad_right,\n                       ind_start=self.ind_start, ind_end=self.ind_end,\n                       oversampling=self.oversampling,\n                       vectorize=self.vectorize,\n                       size_scattering=size_scattering,\n                       out_type=self.out_type)\n\n        if self.out_type == \'array\' and self.vectorize:\n            scattering_shape = S.shape[-2:]\n            new_shape = batch_shape + scattering_shape\n\n            S = S.reshape(new_shape)\n        elif self.out_type == \'array\' and not self.vectorize:\n            for k, v in S.items():\n                # NOTE: Have to get the shape for each one since we may have\n                # average == False.\n                scattering_shape = v.shape[-2:]\n                new_shape = batch_shape + scattering_shape\n\n                S[k] = v.reshape(new_shape)\n        elif self.out_type == \'list\':\n            for x in S:\n                scattering_shape = x[\'coef\'].shape[-1:]\n                new_shape = batch_shape + scattering_shape\n\n                x[\'coef\'] = x[\'coef\'].reshape(new_shape)\n\n        return S\n\n\nScatteringTorch1D._document()\n\n\n__all__ = [\'ScatteringTorch1D\']\n'"
kymatio/scattering2d/backend/__init__.py,0,b''
kymatio/scattering2d/backend/numpy_backend.py,5,"b'# Authors: Edouard Oyallon, Sergey Zagoruyko, Muawiz Chaudhary\n\nimport numpy as np\nfrom collections import namedtuple\n\nBACKEND_NAME = \'numpy\'\n\n\nfrom ...backend.numpy_backend import modulus, cdgmm\nfrom ...backend.base_backend import FFT\n\n\nclass Pad(object):\n    def __init__(self, pad_size, input_size, pre_pad=False):\n        """"""\n            Padding which allows to simultaneously pad in a reflection fashion\n            and map to complex.\n\n            Parameters\n            ----------\n            pad_size : list of 4 integers\n                size of padding to apply.\n            input_size : list of 2 integers\n                size of the original signal\n            pre_pad : boolean\n                if set to true, then there is no padding, one simply converts\n                from real to complex.\n\n        """"""\n        self.pre_pad = pre_pad\n        self.pad_size = pad_size\n\n    def __call__(self, x):\n        if self.pre_pad:\n            return x\n        else:\n            np_pad = ((self.pad_size[0], self.pad_size[1]), (self.pad_size[2], self.pad_size[3]))\n            output = np.pad(x, ((0,0), np_pad[0], np_pad[1]), mode=\'reflect\')\n            return output\n\n\ndef unpad(in_):\n    """"""\n        Slices the input tensor at indices between 1::-1\n\n        Parameters\n        ----------\n        in_ : tensor_like\n            input tensor\n\n        Returns\n        -------\n        in_[..., 1:-1, 1:-1]\n\n    """"""\n    return in_[..., 1:-1, 1:-1]\n\n\nclass SubsampleFourier(object):\n    """""" Subsampling of a 2D image performed in the Fourier domain.\n\n        Subsampling in the spatial domain amounts to periodization\n        in the Fourier domain, hence the formula.\n\n        Parameters\n        ----------\n        x : tensor_like\n            input tensor with at least three dimensions.\n        k : int\n            integer such that x is subsampled by k along the spatial variables.\n\n        Returns\n        -------\n        out : tensor_like\n            Tensor such that its Fourier transform is the Fourier\n            transform of a subsampled version of x, i.e. in\n            F^{-1}(out)[u1, u2] = F^{-1}(x)[u1 * k, u2 * k]\n\n    """"""\n    def __call__(self, x, k):\n        y = x.reshape(-1, k, x.shape[1] // k, k, x.shape[2] // k)\n\n        out = y.mean(axis=(1, 3))\n\n        return out\n\n\ndef concatenate(arrays):\n    return np.stack(arrays, axis=-3)\n\n\nbackend = namedtuple(\'backend\', [\'name\', \'cdgmm\', \'modulus\', \'subsample_fourier\', \'fft\', \'Pad\', \'unpad\', \'concatenate\'])\nbackend.name = \'numpy\'\nbackend.cdgmm = cdgmm\nbackend.modulus = modulus\nbackend.subsample_fourier = SubsampleFourier()\nbackend.fft = FFT(lambda x:np.fft.fft2(x),\n                  lambda x:np.fft.ifft2(x),\n                  lambda x:np.real(np.fft.ifft2(x)),\n                  lambda x:None)\nbackend.Pad = Pad\nbackend.unpad = unpad\nbackend.concatenate = concatenate\n'"
kymatio/scattering2d/backend/tensorflow_backend.py,0,"b'# Authors: Edouard Oyallon, Sergey Zagoruyko, Muawiz Chaudhary\n\nimport tensorflow as tf\nfrom collections import namedtuple\n\nBACKEND_NAME = \'tensorflow\'\n\n\nfrom ...backend.tensorflow_backend import Modulus, cdgmm, concatenate\nfrom ...backend.base_backend import FFT\n\nclass Pad(object):\n    def __init__(self, pad_size, input_size, pre_pad=False):\n        """"""\n            Padding which allows to simultaneously pad in a reflection fashion\n            and map to complex.\n            Parameters\n            ----------\n            pad_size : list of 4 integers\n                size of padding to apply.\n            input_size : list of 2 integers\n                size of the original signal\n            pre_pad : boolean\n                if set to true, then there is no padding, one simply adds the imaginarty part.\n        """"""\n        self.pre_pad = pre_pad\n        self.pad_size = pad_size\n\n    def __call__(self, x):\n        if self.pre_pad:\n            return x\n        else:\n            paddings = [[0, 0]] * len(x.shape[:-2])\n            paddings += [[self.pad_size[0], self.pad_size[1]], [self.pad_size[2], self.pad_size[3]]]\n            return tf.cast(tf.pad(x, paddings, mode=""REFLECT""), tf.complex64)\n\ndef unpad(in_):\n    """"""\n        Slices the input tensor at indices between 1::-1\n        Parameters\n        ----------\n        in_ : tensor_like\n            input tensor\n        Returns\n        -------\n        in_[..., 1:-1, 1:-1]\n    """"""\n    return in_[..., 1:-1, 1:-1]\n\nclass SubsampleFourier(object):\n    """""" Subsampling of a 2D image performed in the Fourier domain.\n\n        Subsampling in the spatial domain amounts to periodization\n        in the Fourier domain, hence the formula.\n\n        Parameters\n        ----------\n        x : tensor_like\n            input tensor with at least three dimensions.\n        k : int\n            integer such that x is subsampled by k along the spatial variables.\n\n        Returns\n        -------\n        out : tensor_like\n            Tensor such that its Fourier transform is the Fourier\n            transform of a subsampled version of x, i.e. in\n            F^{-1}(out)[u1, u2] = F^{-1}(x)[u1 * k, u2 * k]\n\n    """"""\n    def __call__(self, x, k):\n        y = tf.reshape(x, (-1, k, x.shape[1] // k, k, x.shape[2] // k))\n\n        out = tf.reduce_mean(y, axis=(1, 3))\n        return out\n\n\n\nbackend = namedtuple(\'backend\', [\'name\', \'cdgmm\', \'modulus\', \'subsample_fourier\', \'fft\', \'Pad\', \'unpad\', \'concatenate\'])\n\nbackend.name = \'tensorflow\'\nbackend.cdgmm = cdgmm\nbackend.modulus = Modulus()\nbackend.subsample_fourier = SubsampleFourier()\nbackend.fft = FFT(lambda x: tf.signal.fft2d(x, name=\'fft2d\'),\n                  lambda x: tf.signal.ifft2d(x, name=\'ifft2d\'),\n                  lambda x: tf.math.real(tf.signal.ifft2d(x, name=\'irfft2d\')),\n                  lambda x: None)\nbackend.Pad = Pad\nbackend.unpad = unpad\nbackend.concatenate = lambda x: concatenate(x, -3)\n'"
kymatio/scattering2d/backend/torch_backend.py,0,"b'# Authors: Edouard Oyallon, Sergey Zagoruyko\n\nimport torch\nfrom torch.nn import ReflectionPad2d\nfrom collections import namedtuple\n\nBACKEND_NAME = \'torch\'\n\nfrom ...backend.torch_backend import _is_complex, cdgmm, type_checks, Modulus, concatenate\nfrom ...backend.base_backend import FFT\n\n\nclass Pad(object):\n    def __init__(self, pad_size, input_size, pre_pad=False):\n        """"""Padding which allows to simultaneously pad in a reflection fashion\n            and map to complex.\n\n            Parameters\n            ----------\n            pad_size : list of 4 integers\n                Size of padding to apply [top, bottom, left, right].\n            input_size : list of 2 integers\n                size of the original signal [height, width].\n            pre_pad : boolean, optional\n                If set to true, then there is no padding, one simply adds the imaginary part.\n\n        """"""\n        self.pre_pad = pre_pad\n        self.pad_size = pad_size\n        self.input_size = input_size\n\n        self.build()\n\n    def build(self):\n        """"""Builds the padding module.\n\n            Attributes\n            ----------\n            padding_module : ReflectionPad2d\n                Pads the input tensor using the reflection of the input\n                boundary.\n\n        """"""\n        pad_size_tmp = list(self.pad_size)\n\n        # This handles the case where the padding is equal to the image size\n        if pad_size_tmp[0] == self.input_size[0]:\n            pad_size_tmp[0] -= 1\n            pad_size_tmp[1] -= 1\n        if pad_size_tmp[2] == self.input_size[1]:\n            pad_size_tmp[2] -= 1\n            pad_size_tmp[3] -= 1\n        # Pytorch expects its padding as [left, right, top, bottom]\n        self.padding_module = ReflectionPad2d([pad_size_tmp[2], pad_size_tmp[3],\n                                               pad_size_tmp[0], pad_size_tmp[1]])\n\n    def __call__(self, x):\n        """"""Applies padding and maps to complex.\n\n            Parameters\n            ----------\n            x : tensor\n                Real tensor input to be padded and sent to complex domain.\n\n            Returns\n            -------\n            output : tensor\n                Complex torch tensor that has been padded.\n\n        """"""\n        batch_shape = x.shape[:-2]\n        signal_shape = x.shape[-2:]\n        x = x.reshape((-1, 1) + signal_shape)\n        if not self.pre_pad:\n            x = self.padding_module(x)\n\n            # Note: PyTorch is not effective to pad signals of size N-1 with N\n            # elements, thus we had to add this fix.\n            if self.pad_size[0] == self.input_size[0]:\n                x = torch.cat([x[:, :, 1, :].unsqueeze(2), x, x[:, :, x.shape[2] - 2, :].unsqueeze(2)], 2)\n            if self.pad_size[2] == self.input_size[1]:\n                x = torch.cat([x[:, :, :, 1].unsqueeze(3), x, x[:, :, :, x.shape[3] - 2].unsqueeze(3)], 3)\n\n        output = x.new_zeros(x.shape + (2,))\n        output[..., 0] = x\n        output = output.reshape(batch_shape + output.shape[-3:])\n        return output\n\ndef unpad(in_):\n    """"""Unpads input.\n\n        Slices the input tensor at indices between 1:-1.\n\n        Parameters\n        ----------\n        in_ : tensor\n            Input tensor.\n\n        Returns\n        -------\n        in_[..., 1:-1, 1:-1] : tensor\n            Output tensor.  Unpadded input.\n\n    """"""\n    return in_[..., 1:-1, 1:-1]\n\nclass SubsampleFourier(object):\n    """"""Subsampling of a 2D image performed in the Fourier domain\n\n        Subsampling in the spatial domain amounts to periodization\n        in the Fourier domain, hence the formula.\n\n        Parameters\n        ----------\n        x : tensor\n            Input tensor with at least 5 dimensions, the last being the real\n            and imaginary parts.\n        k : int\n            Integer such that x is subsampled by k along the spatial variables.\n\n        Returns\n        -------\n        out : tensor\n            Tensor such that its Fourier transform is the Fourier\n            transform of a subsampled version of x, i.e. in\n            F^{-1}(out)[u1, u2] = F^{-1}(x)[u1 * k, u2 * k].\n\n    """"""\n    def __call__(self, x, k):\n        if not _is_complex(x):\n            raise TypeError(\'The x should be complex.\')\n\n        if not x.is_contiguous():\n            raise RuntimeError(\'Input should be contiguous.\')\n        batch_shape = x.shape[:-3]\n        signal_shape = x.shape[-3:]\n        x = x.view((-1,) + signal_shape)\n        y = x.view(-1,\n                       k, x.shape[1] // k,\n                       k, x.shape[2] // k,\n                       2)\n\n        out = y.mean(3, keepdim=False).mean(1, keepdim=False)\n        out = out.reshape(batch_shape + out.shape[-3:])\n        return out\n\n\nfft = FFT(lambda x: torch.fft(x, 2, normalized=False),\n          lambda x: torch.ifft(x, 2, normalized=False),\n          lambda x: torch.irfft(x, 2, normalized=False, onesided=False),\n          type_checks)\n\n\nbackend = namedtuple(\'backend\', [\'name\', \'cdgmm\', \'modulus\', \'subsample_fourier\', \'fft\', \'Pad\', \'unpad\', \'concatenate\'])\nbackend.name = \'torch\'\nbackend.cdgmm = cdgmm\nbackend.modulus = Modulus()\nbackend.subsample_fourier = SubsampleFourier()\nbackend.fft = fft\nbackend.Pad = Pad\nbackend.unpad = unpad\nbackend.concatenate = lambda x: concatenate(x, -3)\n'"
kymatio/scattering2d/backend/torch_skcuda_backend.py,0,"b'# Authors: Edouard Oyallon, Sergey Zagoruyko, Muawiz Chaudhary\n\nfrom collections import namedtuple\nimport torch\nimport cupy\nfrom string import Template\n\n\nBACKEND_NAME = \'torch_skcuda\'\n\nfrom ...backend.torch_backend import _is_complex\nfrom ...backend.torch_skcuda_backend import cdgmm\n\n@cupy.util.memoize(for_each_device=True)\ndef _load_kernel(kernel_name, code, **kwargs):\n    code = Template(code).substitute(**kwargs)\n    kernel_code = cupy.cuda.compile_with_cache(code)\n    return kernel_code.get_function(kernel_name)\n\nStream = namedtuple(\'Stream\', [\'ptr\'])\n\ndef _get_dtype(t):\n    dtypes = {torch.float32: \'float\',\n              torch.float64: \'double\'}\n\n    return dtypes[t.dtype]\n\nclass SubsampleFourier(object):\n    """"""Subsampling of a 2D image performed in the Fourier domain.\n\n        Subsampling in the spatial domain amounts to periodization\n        in the Fourier domain, hence the formula.\n\n        Parameters\n        ----------\n        x : tensor\n             Torch tensor with at least 5 dimensions, the last being the real\n             and imaginary parts. Ideally, the last dimension should be a\n             power of 2 to avoid errors.\n        k : int\n            Integer such that x is subsampled by k along the spatial variables.\n\n        Raises\n        ------\n        RuntimeError\n            In the event that x is not contiguous.\n        TypeError\n            In the event that x is on CPU or the input is not complex.\n\n        Returns\n        -------\n        out : tensor\n            Tensor such that its fourier transform is the Fourier\n            transform of a subsampled version of x, i.e. in\n            F^{-1}(out)[u1, u2] = F^{-1}(x)[u1 * k, u2 * k)].\n\n    """"""\n    def __init__(self):\n        self.block = (32, 32, 1)\n\n    def GET_BLOCKS(self, N, threads):\n        return (N + threads - 1) // threads\n\n    def __call__(self, x, k):\n        if not x.is_cuda:\n            raise TypeError(\'Use the torch backend (without skcuda) for CPU tensors.\')\n\n        batch_shape = x.shape[:-3]\n        signal_shape = x.shape[-3:]\n        x = x.view((-1,) + signal_shape)\n\n        out = x.new(size=[x.shape[0], x.shape[1] // k, x.shape[2] // k, 2])\n\n        if not _is_complex(x):\n            raise TypeError(\'The x should be complex.\')\n\n        if not x.is_contiguous():\n            raise RuntimeError(\'Input should be contiguous.\')\n\n        kernel = \'\'\'\n        #define NW ${W} / ${k}\n        #define NH ${H} / ${k}\n        extern ""C""\n        __global__ void periodize(const ${Dtype}2 *input, ${Dtype}2 *output)\n        {\n          int tx = blockIdx.x * blockDim.x + threadIdx.x;\n          int ty = blockIdx.y * blockDim.y + threadIdx.y;\n          int tz = blockIdx.z * blockDim.z + threadIdx.z;\n          if(tx >= NW || ty >= NH || tz >= ${B})\n            return;\n          input += tz * ${H} * ${W} + ty * ${W} + tx;\n          ${Dtype}2 res = make_${Dtype}2(0.f, 0.f);\n          for (int j=0; j<${k}; ++j)\n            for (int i=0; i<${k}; ++i)\n            {\n              const ${Dtype}2 &c = input[j * NH * ${W} + i * NW];\n              res.x += c.x;\n              res.y += c.y;\n            }\n          res.x /= ${k} * ${k};\n          res.y /= ${k} * ${k};\n          output[tz * NH * NW + ty * NW + tx] = res;\n        }\n        \'\'\'\n        B = x.shape[0]\n        W = x.shape[2]\n        H = x.shape[1]\n\n        periodize = _load_kernel(\'periodize\', kernel, B=B, H=H, W=W, k=k, Dtype=_get_dtype(x))\n        grid = (self.GET_BLOCKS(out.shape[1], self.block[0]),\n                self.GET_BLOCKS(out.shape[2], self.block[1]),\n                self.GET_BLOCKS(out.shape[0], self.block[2]))\n        periodize(grid=grid, block=self.block, args=[x.data_ptr(), out.data_ptr()],\n                  stream=Stream(ptr=torch.cuda.current_stream().cuda_stream))\n        out = out.reshape(batch_shape + out.shape[-3:])\n        return out\n\nclass Modulus(object):\n    """"""This class implements a modulus transform for complex numbers.\n\n        Usage\n        -----\n        modulus = Modulus()\n        x_mod = modulus(x)\n\n        Parameters\n        ---------\n        x : tensor\n            Complex torch tensor.\n\n        Raises\n        ------\n        RuntimeError\n            In the event that x is not contiguous.\n        TypeError\n            In the event that x is on CPU or the input is not complex.\n\n        Returns\n        -------\n        output : tensor\n            A tensor with the same dimensions as x, such that output[..., 0]\n            contains the complex modulus of x, while output[..., 1] = 0.\n\n    """"""\n    def __init__(self):\n        self.CUDA_NUM_THREADS = 1024\n\n    def GET_BLOCKS(self, N):\n        return (N + self.CUDA_NUM_THREADS - 1) // self.CUDA_NUM_THREADS\n\n    def __call__(self, x):\n        if not x.is_cuda:\n            raise TypeError(\'Use the torch backend (without skcuda) for CPU tensors.\')\n\n        out = x.new(x.shape)\n\n        if not _is_complex(x):\n            raise TypeError(\'The inputs should be complex.\')\n\n        if not x.is_contiguous():\n            raise RuntimeError(\'Input should be contiguous.\')\n\n        kernel = """"""\n        extern ""C""\n        __global__ void abs_complex_value(const ${Dtype} * x, ${Dtype}2 * z, int n)\n        {\n            int i = blockIdx.x * blockDim.x + threadIdx.x;\n        if (i >= n)\n            return;\n        z[i] = make_${Dtype}2(normf(2, x + 2*i), 0);\n\n        }\n        """"""\n        fabs = _load_kernel(\'abs_complex_value\', kernel, Dtype=_get_dtype(x))\n        fabs(grid=(self.GET_BLOCKS(int(out.nelement()) // 2), 1, 1),\n             block=(self.CUDA_NUM_THREADS, 1, 1),\n             args=[x.data_ptr(), out.data_ptr(), out.numel() // 2],\n             stream=Stream(ptr=torch.cuda.current_stream().cuda_stream))\n        return out\n\n\nfrom .torch_backend import unpad\nfrom .torch_backend import Pad\nfrom .torch_backend import fft\nfrom .torch_backend import concatenate\n\nbackend = namedtuple(\'backend\', [\'name\', \'cdgmm\', \'modulus\', \'subsample_fourier\', \'fft\', \'Pad\', \'unpad\', \'concatenate\'])\nbackend.name = \'torch_skcuda\'\nbackend.cdgmm = cdgmm\nbackend.modulus = Modulus()\nbackend.subsample_fourier = SubsampleFourier()\nbackend.fft = fft\nbackend.Pad = Pad\nbackend.unpad = unpad\nbackend.concatenate = lambda x: concatenate(x, -3)\n'"
kymatio/scattering2d/core/__init__.py,0,b''
kymatio/scattering2d/core/scattering2d.py,0,"b""# Authors: Edouard Oyallon, Muawiz Chaudhary\n# Scientific Ancestry: Edouard Oyallon, Laurent Sifre, Joan Bruna\n\ndef scattering2d(x, pad, unpad, backend, J, L, phi, psi, max_order,\n        out_type='array'):\n    subsample_fourier = backend.subsample_fourier\n    modulus = backend.modulus\n    fft = backend.fft\n    cdgmm = backend.cdgmm\n    concatenate = backend.concatenate\n\n    # Define lists for output.\n    out_S_0, out_S_1, out_S_2 = [], [], []\n\n    U_r = pad(x)\n\n    U_0_c = fft(U_r, 'C2C')\n\n    # First low pass filter\n    U_1_c = cdgmm(U_0_c, phi[0])\n    U_1_c = subsample_fourier(U_1_c, k=2 ** J)\n\n    S_0 = fft(U_1_c, 'C2R', inverse=True)\n    S_0 = unpad(S_0)\n\n    out_S_0.append({'coef': S_0,\n                    'j': (),\n                    'theta': ()})\n\n    for n1 in range(len(psi)):\n        j1 = psi[n1]['j']\n        theta1 = psi[n1]['theta']\n\n        U_1_c = cdgmm(U_0_c, psi[n1][0])\n        if j1 > 0:\n            U_1_c = subsample_fourier(U_1_c, k=2 ** j1)\n        U_1_c = fft(U_1_c, 'C2C', inverse=True)\n        U_1_c = modulus(U_1_c)\n        U_1_c = fft(U_1_c, 'C2C')\n\n        # Second low pass filter\n        S_1_c = cdgmm(U_1_c, phi[j1])\n        S_1_c = subsample_fourier(S_1_c, k=2 ** (J - j1))\n\n        S_1_r = fft(S_1_c, 'C2R', inverse=True)\n        S_1_r = unpad(S_1_r)\n\n        out_S_1.append({'coef': S_1_r,\n                        'j': (j1,),\n                        'theta': (theta1,)})\n\n        if max_order < 2:\n            continue\n        for n2 in range(len(psi)):\n            j2 = psi[n2]['j']\n            theta2 = psi[n2]['theta']\n\n            if j2 <= j1:\n                continue\n\n            U_2_c = cdgmm(U_1_c, psi[n2][j1])\n            U_2_c = subsample_fourier(U_2_c, k=2 ** (j2 - j1))\n            U_2_c = fft(U_2_c, 'C2C', inverse=True)\n            U_2_c = modulus(U_2_c)\n            U_2_c = fft(U_2_c, 'C2C')\n\n            # Third low pass filter\n            S_2_c = cdgmm(U_2_c, phi[j2])\n            S_2_c = subsample_fourier(S_2_c, k=2 ** (J - j2))\n\n            S_2_r = fft(S_2_c, 'C2R', inverse=True)\n            S_2_r = unpad(S_2_r)\n\n            out_S_2.append({'coef': S_2_r,\n                            'j': (j1, j2),\n                            'theta': (theta1, theta2)})\n\n    out_S = []\n    out_S.extend(out_S_0)\n    out_S.extend(out_S_1)\n    out_S.extend(out_S_2)\n\n    if out_type == 'array':\n        out_S = concatenate([x['coef'] for x in out_S])\n\n    return out_S\n\n\n__all__ = ['scattering2d']\n"""
kymatio/scattering2d/frontend/__init__.py,0,b''
kymatio/scattering2d/frontend/base_frontend.py,0,"b'from ...frontend.base_frontend import ScatteringBase\n\nfrom ..filter_bank import filter_bank\nfrom ..utils import compute_padding\n\n\nclass ScatteringBase2D(ScatteringBase):\n    def __init__(self, J, shape, L=8, max_order=2, pre_pad=False,\n            backend=None, out_type=\'array\'):\n        super(ScatteringBase2D, self).__init__()\n        self.pre_pad = pre_pad\n        self.L = L\n        self.backend = backend\n        self.J = J\n        self.shape = shape\n        self.max_order = max_order\n        self.out_type = out_type\n\n    def build(self):\n        self.M, self.N = self.shape\n\n        if 2 ** self.J > self.M or 2 ** self.J > self.N:\n            raise RuntimeError(\'The smallest dimension should be larger than 2^J.\')\n        self.M_padded, self.N_padded = compute_padding(self.M, self.N, self.J)\n        # pads equally on a given side if the amount of padding to add is an even number of pixels, otherwise it adds an extra pixel\n        self.pad = self.backend.Pad([(self.M_padded - self.M) // 2, (self.M_padded - self.M+1) // 2, (self.N_padded - self.N) // 2,\n                                (self.N_padded - self.N + 1) // 2], [self.M, self.N], pre_pad=self.pre_pad)\n        self.unpad = self.backend.unpad\n\n    def create_filters(self):\n        filters = filter_bank(self.M_padded, self.N_padded, self.J, self.L)\n        self.phi, self.psi = filters[\'phi\'], filters[\'psi\']\n\n    _doc_shape = \'M, N\'\n\n    _doc_instantiation_shape = {True: \'S = Scattering2D(J, (M, N))\',\n                                False: \'S = Scattering2D(J)\'}\n\n    _doc_param_shape = \\\n    r""""""shape : tuple of ints\n            Spatial support (M, N) of the input\n        """"""\n\n    _doc_attrs_shape = \\\n    r""""""Psi : dictionary\n            Contains the wavelets filters at all resolutions. See\n            `filter_bank.filter_bank` for an exact description.\n        Phi : dictionary\n            Contains the low-pass filters at all resolutions. See\n            `filter_bank.filter_bank` for an exact description.\n        M_padded, N_padded : int\n             Spatial support of the padded input.\n        """"""\n\n    _doc_param_out_type = \\\n    r""""""out_type : str, optional\n            The format of the output of a scattering transform. If set to\n            `\'list\'`, then the output is a list containing each individual\n            scattering path with meta information. Otherwise, if set to\n            `\'array\'`, the output is a large array containing the\n            concatenation of all scattering coefficients. Defaults to\n            `\'array\'`.\n        """"""\n\n    _doc_attr_out_type = \\\n    r""""""out_type : str\n            The format of the scattering output. See documentation for\n            `out_type` parameter above and the documentation for `scattering`.\n        """"""\n\n    _doc_class = \\\n    r""""""The 2D scattering transform\n\n        The scattering transform computes two wavelet transform\n        followed by modulus non-linearity. It can be summarized as\n\n            $S_J x = [S_J^{{(0)}} x, S_J^{{(1)}} x, S_J^{{(2)}} x]$\n\n        where\n\n            $S_J^{{(0)}} x = x \\star \\phi_J$,\n\n            $S_J^{{(1)}} x = [|x \\star \\psi^{{(1)}}_\\lambda| \\star \\phi_J]_\\lambda$, and\n\n            $S_J^{{(2)}} x = [||x \\star \\psi^{{(1)}}_\\lambda| \\star\n            \\psi^{{(2)}}_\\mu| \\star \\phi_J]_{{\\lambda, \\mu}}$.\n\n        where $\\star$ denotes the convolution (in space), $\\phi_J$ is a\n        lowpass filter, $\\psi^{{(1)}}_\\lambda$ is a family of bandpass filters\n        and $\\psi^{{(2)}}_\\mu$ is another family of bandpass filters. Only\n        Morlet filters are used in this implementation. Convolutions are\n        efficiently performed in the Fourier domain.\n        {frontend_paragraph}\n        Example\n        -------\n        ::\n\n            # Set the parameters of the scattering transform.\n            J = 3\n            M, N = 32, 32\n\n            # Generate a sample signal.\n            x = {sample}\n\n            # Define a Scattering2D object.\n            {instantiation}\n\n            # Calculate the scattering transform.\n            Sx = S.scattering(x)\n\n            # Equivalently, use the alias.\n            Sx = S{alias_call}(x)\n\n        Parameters\n        ----------\n        J : int\n            Log-2 of the scattering scale.\n        {param_shape}L : int, optional\n            Number of angles used for the wavelet transform. Defaults to `8`.\n        max_order : int, optional\n            The maximum order of scattering coefficients to compute. Must be\n            either `1` or `2`. Defaults to `2`.\n        pre_pad : boolean, optional\n            Controls the padding: if set to False, a symmetric padding is\n            applied on the signal. If set to True, the software will assume\n            the signal was padded externally. Defaults to `False`.\n        backend : object, optional\n            Controls the backend which is combined with the frontend.\n        {param_out_type}\n        Attributes\n        ----------\n        J : int\n            Log-2 of the scattering scale.\n        {param_shape}L : int, optional\n            Number of angles used for the wavelet transform.\n        max_order : int, optional\n            The maximum order of scattering coefficients to compute.\n            Must be either `1` or `2`.\n        pre_pad : boolean\n            Controls the padding: if set to False, a symmetric padding is\n            applied on the signal. If set to True, the software will assume\n            the signal was padded externally.\n        {attrs_shape}{attr_out_type}\n        Notes\n        -----\n        The design of the filters is optimized for the value `L = 8`.\n\n        The `pre_pad` flag is particularly useful when cropping bigger images\n        because this does not introduce border effects inherent to padding.\n        """"""\n\n    _doc_scattering = \\\n    """"""Apply the scattering transform\n\n       Parameters\n       ----------\n       input : {array}\n           An input `{array}` of size `(B, M, N)`.\n\n       Raises\n       ------\n       RuntimeError\n           In the event that the input does not have at least two dimensions,\n           or the tensor is not contiguous, or the tensor is not of the\n           correct spatial size, padded or not.\n       TypeError\n           In the event that the input is not of type `{array}`.\n\n       Returns\n       -------\n       S : {array}\n           Scattering transform of the input. If `out_type` is set to\n           `\'array\'` (or if it is not availabel for this frontend), this is\n           a{n} `{array}` of shape `(B, C, M1, N1)` where `M1 = M // 2 ** J`\n           and `N1 = N // 2 ** J`. The `C` is the number of scattering\n           channels calculated. If `out_type` is `\'list\'`, the output is a\n           list of dictionaries, with each dictionary corresponding to a\n           scattering coefficient and its meta information. The actual\n           coefficient is contained in the `\'coef\'` key, while other keys hold\n           additional information, such as `\'j\'` (the scale of the filter\n           used), and `\'theta\'` (the angle index of the filter used).\n    """"""\n\n\n    @classmethod\n    def _document(cls):\n        instantiation = cls._doc_instantiation_shape[cls._doc_has_shape]\n        param_shape = cls._doc_param_shape if cls._doc_has_shape else \'\'\n        attrs_shape = cls._doc_attrs_shape if cls._doc_has_shape else \'\'\n\n        param_out_type = cls._doc_param_out_type if cls._doc_has_out_type else \'\'\n        attr_out_type = cls._doc_attr_out_type if cls._doc_has_out_type else \'\'\n\n        cls.__doc__ = ScatteringBase2D._doc_class.format(\n            array=cls._doc_array,\n            frontend_paragraph=cls._doc_frontend_paragraph,\n            alias_name=cls._doc_alias_name,\n            alias_call=cls._doc_alias_call,\n            instantiation=instantiation,\n            param_shape=param_shape,\n            attrs_shape=attrs_shape,\n            param_out_type=param_out_type,\n            attr_out_type=attr_out_type,\n            sample=cls._doc_sample.format(shape=cls._doc_shape))\n\n        cls.scattering.__doc__ = ScatteringBase2D._doc_scattering.format(\n            array=cls._doc_array,\n            n=cls._doc_array_n)\n\n\n__all__ = [\'ScatteringBase2D\']\n'"
kymatio/scattering2d/frontend/entry.py,0,"b""from ...frontend.entry import ScatteringEntry\n\nclass ScatteringEntry2D(ScatteringEntry):\n    def __init__(self, *args, **kwargs):\n        super().__init__(name='2D', class_name='scattering2d', *args, **kwargs)\n\n\n__all__ = ['ScatteringEntry2D']\n"""
kymatio/scattering2d/frontend/keras_frontend.py,0,"b""from ...frontend.keras_frontend import ScatteringKeras\nfrom ...scattering2d.frontend.base_frontend import ScatteringBase2D\n\nfrom ...tensorflow import Scattering2D as ScatteringTensorFlow2D\n\nfrom tensorflow.python.framework import tensor_shape\n\n\nclass ScatteringKeras2D(ScatteringKeras, ScatteringBase2D):\n    def __init__(self, J, L=8, max_order=2, pre_pad=False):\n        ScatteringKeras.__init__(self)\n        ScatteringBase2D.__init__(self, J, None, L, max_order, pre_pad,\n                                  'array')\n\n    def build(self, input_shape):\n        shape = tuple(tensor_shape.TensorShape(input_shape).as_list()[-2:])\n        self.S = ScatteringTensorFlow2D(J=self.J, shape=shape,\n                                        L=self.L, max_order=self.max_order,\n                                        pre_pad=self.pre_pad)\n        ScatteringKeras.build(self, input_shape)\n        # NOTE: Do not call ScatteringBase2D.build here since that will\n        # recreate the filters already in self.S\n\n    def compute_output_shape(self, input_shape):\n        input_shape = tensor_shape.TensorShape(input_shape).as_list()\n        m0 = input_shape[-2] // 2 ** self.J\n        m1 = input_shape[-1] // 2 ** self.J\n        nc = (self.L ** 2) * self.J * (self.J - 1) // 2 + self.L * self.J + 1\n        output_shape = [input_shape[0], nc, m0, m1]\n        return tensor_shape.TensorShape(output_shape)\n\n\nScatteringKeras2D._document()\n"""
kymatio/scattering2d/frontend/numpy_frontend.py,1,"b'from ...frontend.numpy_frontend import ScatteringNumPy\nfrom ...scattering2d.core.scattering2d import scattering2d\nfrom .base_frontend import ScatteringBase2D\nimport numpy as np\n\nclass ScatteringNumPy2D(ScatteringNumPy, ScatteringBase2D):\n    def __init__(self, J, shape, L=8, max_order=2, pre_pad=False,\n            backend=\'numpy\', out_type=\'array\'):\n        ScatteringNumPy.__init__(self)\n        ScatteringBase2D.__init__(self, J, shape, L, max_order, pre_pad,\n                backend, out_type)\n        ScatteringBase2D._instantiate_backend(self, \'kymatio.scattering2d.backend.\')\n        ScatteringBase2D.build(self)\n        ScatteringBase2D.create_filters(self)\n\n    def scattering(self, input):\n        if not type(input) is np.ndarray:\n            raise TypeError(\'The input should be a NumPy array.\')\n\n        if len(input.shape) < 2:\n            raise RuntimeError(\'Input array must have at least two dimensions.\')\n\n        if (input.shape[-1] != self.N or input.shape[-2] != self.M) and not self.pre_pad:\n            raise RuntimeError(\'NumPy array must be of spatial size (%i,%i).\' % (self.M, self.N))\n\n        if (input.shape[-1] != self.N_padded or input.shape[-2] != self.M_padded) and self.pre_pad:\n            raise RuntimeError(\'Padded array must be of spatial size (%i,%i).\' % (self.M_padded, self.N_padded))\n\n        if not self.out_type in (\'array\', \'list\'):\n            raise RuntimeError(""The out_type must be one of \'array\' or \'list\'."")\n\n\n        batch_shape = input.shape[:-2]\n        signal_shape = input.shape[-2:]\n\n        input = input.reshape((-1,) + signal_shape)\n\n        S = scattering2d(input, self.pad, self.unpad, self.backend, self.J,\n                self.L, self.phi, self.psi, self.max_order, self.out_type)\n\n        if self.out_type == \'array\':\n            scattering_shape = S.shape[-3:]\n            new_shape = batch_shape + scattering_shape\n\n            S = S.reshape(new_shape)\n        else:\n            scattering_shape = S[0][\'coef\'].shape[-2:]\n            new_shape = batch_shape + scattering_shape\n\n            for x in S:\n                x[\'coef\'] = x[\'coef\'].reshape(new_shape)\n\n        return S\n\n\nScatteringNumPy2D._document()\n\n\n__all__ = [\'ScatteringNumPy2D\']\n'"
kymatio/scattering2d/frontend/sklearn_frontend.py,0,"b""from ...frontend.sklearn_frontend import ScatteringTransformerMixin\nfrom ...numpy import Scattering2D as ScatteringNumPy2D\n\n\n# NOTE: Order in base classes matters here, since we want the sklearn-specific\n# documentation parameters to take precedence over NP.\nclass ScatteringTransformer2D(ScatteringTransformerMixin, ScatteringNumPy2D):\n    pass\n\n\nScatteringTransformer2D._document()\n\n\n__all__ = ['ScatteringTransformer2D']\n"""
kymatio/scattering2d/frontend/tensorflow_frontend.py,0,"b'import tensorflow as tf\nfrom ...frontend.tensorflow_frontend import ScatteringTensorFlow\nfrom ...scattering2d.core.scattering2d import scattering2d\nfrom .base_frontend import ScatteringBase2D\n\nclass ScatteringTensorFlow2D(ScatteringTensorFlow, ScatteringBase2D):\n    def __init__(self, J, shape, L=8, max_order=2, pre_pad=False,\n            backend=\'tensorflow\', name=\'Scattering2D\', out_type=\'array\'):\n        ScatteringTensorFlow.__init__(self, name)\n        ScatteringBase2D.__init__(self, J, shape, L, max_order, pre_pad,\n                backend, out_type)\n        ScatteringBase2D._instantiate_backend(self, \'kymatio.scattering2d.backend.\')\n        ScatteringBase2D.build(self)\n        ScatteringBase2D.create_filters(self)\n\n    def scattering(self, input):\n        with tf.name_scope(\'scattering\') as scope:\n            try:\n                input = tf.convert_to_tensor(input)\n            except ValueError:\n                raise TypeError(\'The input should be convertible to a \'\n                                \'TensorFlow Tensor.\')\n\n            if len(input.shape) < 2:\n                raise RuntimeError(\'Input tensor should have at least two \'\n                                   \'dimensions.\')\n\n            if (input.shape[-1] != self.N or input.shape[-2] != self.M) and not self.pre_pad:\n                raise RuntimeError(\'Tensor must be of spatial size (%i,%i).\' % (self.M, self.N))\n\n            if (input.shape[-1] != self.N_padded or input.shape[-2] != self.M_padded) and self.pre_pad:\n                raise RuntimeError(\'Padded tensor must be of spatial size (%i,%i).\' % (self.M_padded, self.N_padded))\n            if not self.out_type in (\'array\', \'list\'):\n                raise RuntimeError(""The out_type must be one of \'array\' or \'list\'."")\n\n            # Use tf.shape to get the dynamic shape of the tf.Tensors at\n            # execution time.\n            batch_shape = tf.shape(input)[:-2]\n            signal_shape = tf.shape(input)[-2:]\n\n            # NOTE: Cannot simply concatenate these using + since they are\n            # tf.Tensors and that would add their values.\n            input = tf.reshape(input, tf.concat(((-1,), signal_shape), 0))\n\n            S = scattering2d(input, self.pad, self.unpad, self.backend, self.J, self.L, self.phi, self.psi,\n                             self.max_order, self.out_type)\n\n            if self.out_type == \'array\':\n                scattering_shape = tf.shape(S)[-3:]\n                new_shape = tf.concat((batch_shape, scattering_shape), 0)\n\n                S = tf.reshape(S, new_shape)\n            else:\n                scattering_shape = tf.shape(S[0][\'coef\'])[-2:]\n                new_shape = tf.concat((batch_shape, scattering_shape), 0)\n\n                for x in S:\n                    x[\'coef\'] = tf.reshape(x[\'coef\'], new_shape)\n\n            return S\n\n\nScatteringTensorFlow2D._document()\n\n\n__all__ = [\'ScatteringTensorFlow2D\']\n'"
kymatio/scattering2d/frontend/torch_frontend.py,0,"b'import torch\n\nfrom .base_frontend import ScatteringBase2D\nfrom ...scattering2d.core.scattering2d import scattering2d\nfrom ...frontend.torch_frontend import ScatteringTorch\n\n\nclass ScatteringTorch2D(ScatteringTorch, ScatteringBase2D):\n    def __init__(self, J, shape, L=8, max_order=2, pre_pad=False,\n            backend=\'torch\', out_type=\'array\'):\n        ScatteringTorch.__init__(self)\n        ScatteringBase2D.__init__(**locals())\n        ScatteringBase2D._instantiate_backend(self, \'kymatio.scattering2d.backend.\')\n        ScatteringBase2D.build(self)\n        ScatteringBase2D.create_filters(self)\n\n        self.register_filters()\n\n    def register_single_filter(self, v, n):\n        current_filter = torch.from_numpy(v).unsqueeze(-1)\n        self.register_buffer(\'tensor\' + str(n), current_filter)\n        return current_filter\n\n    def register_filters(self):\n        """""" This function run the filterbank function that\n            will create the filters as numpy array, and then, it\n            saves those arrays as module\'s buffers.""""""\n        # Create the filters\n\n        n = 0\n\n        for c, phi in self.phi.items():\n            if not isinstance(c, int):\n                continue\n\n            self.phi[c] = self.register_single_filter(phi, n)\n            n = n + 1\n\n        for j in range(len(self.psi)):\n            for k, v in self.psi[j].items():\n                if not isinstance(k, int):\n                    continue\n\n                self.psi[j][k] = self.register_single_filter(v, n)\n                n = n + 1\n\n    def load_single_filter(self, n, buffer_dict):\n        return buffer_dict[\'tensor\' + str(n)]\n\n    def load_filters(self):\n        """""" This function loads filters from the module\'s buffers """"""\n        # each time scattering is run, one needs to make sure self.psi and self.phi point to\n        # the correct buffers\n        buffer_dict = dict(self.named_buffers())\n\n        n = 0\n\n        phis = self.phi\n        for c, phi in phis.items():\n            if not isinstance(c, int):\n                continue\n\n            phis[c] = self.load_single_filter(n, buffer_dict)\n            n = n + 1\n\n        psis = self.psi\n        for j in range(len(psis)):\n            for k, v in psis[j].items():\n                if not isinstance(k, int):\n                    continue\n\n                psis[j][k] = self.load_single_filter(n, buffer_dict)\n                n = n + 1\n\n        return phis, psis\n\n    def scattering(self, input):\n        if not torch.is_tensor(input):\n            raise TypeError(\'The input should be a PyTorch Tensor.\')\n\n        if len(input.shape) < 2:\n            raise RuntimeError(\'Input tensor must have at least two dimensions.\')\n\n        if not input.is_contiguous():\n            raise RuntimeError(\'Tensor must be contiguous.\')\n\n        if (input.shape[-1] != self.N or input.shape[-2] != self.M) and not self.pre_pad:\n            raise RuntimeError(\'Tensor must be of spatial size (%i,%i).\' % (self.M, self.N))\n\n        if (input.shape[-1] != self.N_padded or input.shape[-2] != self.M_padded) and self.pre_pad:\n            raise RuntimeError(\'Padded tensor must be of spatial size (%i,%i).\' % (self.M_padded, self.N_padded))\n\n        if not self.out_type in (\'array\', \'list\'):\n            raise RuntimeError(""The out_type must be one of \'array\' or \'list\'."")\n\n        phi, psi = self.load_filters()\n\n        batch_shape = input.shape[:-2]\n        signal_shape = input.shape[-2:]\n\n        input = input.reshape((-1,) + signal_shape)\n\n        S = scattering2d(input, self.pad, self.unpad, self.backend, self.J,\n                            self.L, phi, psi, self.max_order, self.out_type)\n\n        if self.out_type == \'array\':\n            scattering_shape = S.shape[-3:]\n            S = S.reshape(batch_shape + scattering_shape)\n        else:\n            scattering_shape = S[0][\'coef\'].shape[-2:]\n            new_shape = batch_shape + scattering_shape\n\n            for x in S:\n                x[\'coef\'] = x[\'coef\'].reshape(new_shape)\n\n        return S\n\n\nScatteringTorch2D._document()\n\n\n__all__ = [\'ScatteringTorch2D\']\n'"
kymatio/scattering3d/backend/__init__.py,0,b''
kymatio/scattering3d/backend/numpy_backend.py,10,"b'import numpy as np\nfrom collections import namedtuple\nfrom scipy.fftpack import fftn, ifftn\n\n\nBACKEND_NAME = \'numpy\'\n\n\ndef _iscomplex(x):\n    return x.dtype == np.complex64 or x.dtype == np.complex128\n\n\ndef complex_modulus(input_array):\n    """"""Computes complex modulus.\n\n        Parameters\n        ----------\n        input_array : tensor\n            Input tensor whose complex modulus is to be calculated.\n        Returns\n        -------\n        modulus : tensor\n            Tensor the same size as input_array. modulus[..., 0] holds the\n            result of the complex modulus, modulus[..., 1] = 0.\n\n    """"""\n\n    return np.abs(input_array)\n\n\ndef modulus_rotation(x, module=None):\n    """"""Used for computing rotation invariant scattering transform coefficents.\n\n        Parameters\n        ----------\n        x : tensor\n            Size (batchsize, M, N, O, 2).\n        module : tensor\n            Tensor that holds the overall sum. If none, initializes the tensor\n            to zero (default).\n        Returns\n        -------\n        output : torch tensor\n            Tensor of the same size as input_array. It holds the output of\n            the operation::\n            $\\\\sqrt{\\\\sum_m (\\\\text{input}_\\\\text{array} \\\\star \\\\psi_{j,l,m})^2)}$\n            which is covariant to 3D translations and rotations.\n    """"""\n    if module is None:\n        module = np.zeros_like(x)\n    else:\n        module = module ** 2\n    module += np.abs(x) ** 2\n    return np.sqrt(module)\n\n\ndef compute_integrals(input_array, integral_powers):\n    """"""Computes integrals.\n\n        Computes integrals of the input_array to the given powers.\n        Parameters\n        ----------\n        input_array : torch tensor\n            Size (B, M, N, O), where B is batch_size, and M, N, O are spatial\n            dims.\n        integral_powers : list\n            List of P positive floats containing the p values used to\n            compute the integrals of the input_array to the power p (l_p\n            norms).\n        Returns\n        -------\n        integrals : torch tensor\n            Tensor of size (B, P) containing the integrals of the input_array\n            to the powers p (l_p norms).\n    """"""\n    integrals = np.zeros((input_array.shape[0], len(integral_powers)),\n            dtype=np.complex64)\n    for i_q, q in enumerate(integral_powers):\n        integrals[:, i_q] = (input_array ** q).reshape((input_array.shape[0], -1)).sum(axis=1)\n    return integrals\n\n\ndef fft(x, direction=\'C2C\', inverse=False):\n    """"""\n        Interface with torch FFT routines for 2D signals.\n\n        Example\n        -------\n        x = torch.randn(128, 32, 32, 2)\n        x_fft = fft(x, inverse=True)\n\n        Parameters\n        ----------\n        input : tensor\n            complex input for the FFT\n        direction : string\n            \'C2R\' for complex to real, \'C2C\' for complex to complex\n        inverse : bool\n            True for computing the inverse FFT.\n            NB : if direction is equal to \'C2R\', then an error is raised.\n\n    """"""\n    if direction == \'C2R\':\n        if not inverse:\n            raise RuntimeError(\'C2R mode can only be done with an inverse FFT.\')\n\n    if direction == \'C2R\':\n        output = np.real(ifftn(x, axes=(-3, -2, -1)))\n    elif direction == \'C2C\':\n        if inverse:\n            output = ifftn(x, axes=(-3, -2, -1))\n        else:\n            output = fftn(x, axes=(-3, -2, -1))\n\n    return output\n\n\ndef cdgmm3d(A, B, inplace=False):\n    """"""Complex pointwise multiplication.\n\n        Complex pointwise multiplication between (batched) tensor A and tensor B.\n\n        Parameters\n        ----------\n        A : torch tensor\n            Complex torch tensor.\n        B : torch tensor\n            Complex of the same size as A.\n        inplace : boolean, optional\n            If set True, all the operations are performed inplace.\n\n        Raises\n        ------\n        RuntimeError\n            In the event that the tensors are not compatibile for multiplication\n            (i.e. the final four dimensions of A do not match with the dimensions\n            of B), or in the event that B is not complex, or in the event that the\n            type of A and B are not the same.\n        TypeError\n            In the event that x is not complex i.e. does not have a final dimension\n            of 2, or in the event that both tensors are not on the same device.\n\n        Returns\n        -------\n        output : torch tensor\n            Torch tensor of the same size as A containing the result of the\n            elementwise complex multiplication of A with B.\n    """"""\n\n    if A.shape[-3:] != B.shape[-3:]:\n        raise RuntimeError(\'The tensors are not compatible for multiplication.\')\n\n    if not _iscomplex(A) or not _iscomplex(B):\n        raise TypeError(\'The input, filter and output should be complex.\')\n\n    if B.ndim != 3:\n        raise RuntimeError(\'The second tensor must be simply a complex array.\')\n\n    if type(A) is not type(B):\n        raise RuntimeError(\'A and B should be same type.\')\n\n\n    if inplace:\n        return np.multiply(A, B, out=A)\n    else:\n        return A * B\n\n\ndef concatenate(arrays, L):\n    S = np.stack(arrays, axis=1)\n    S = S.reshape((S.shape[0], S.shape[1] // (L + 1), (L + 1)) + S.shape[2:])\n    return S\n\n\nbackend = namedtuple(\'backend\',\n                     [\'name\',\n                      \'cdgmm3d\',\n                      \'fft\',\n                      \'modulus\',\n                      \'modulus_rotation\',\n                      \'compute_integrals\',\n                      \'concatenate\'])\n\nbackend.name = \'numpy\'\nbackend.cdgmm3d = cdgmm3d\nbackend.fft = fft\nbackend.concatenate = concatenate\nbackend.modulus = complex_modulus\nbackend.modulus_rotation = modulus_rotation\nbackend.compute_integrals = compute_integrals\n'"
kymatio/scattering3d/backend/tensorflow_backend.py,2,"b'import tensorflow as tf\n\nimport numpy as np\n\nfrom collections import namedtuple\n\n\nBACKEND_NAME = \'tensorflow\'\n\n\ndef complex_modulus(x):\n    """"""Computes complex modulus.\n\n        Parameters\n        ----------\n        x : tensor\n            Input tensor whose complex modulus is to be calculated.\n\n        Returns\n        -------\n        modulus : tensor\n            Tensor the same size as input_array. modulus holds the\n            result of the complex modulus.\n\n    """"""\n    modulus = tf.abs(x)\n    return modulus\n\n\ndef modulus_rotation(x, module):\n    """"""Used for computing rotation invariant scattering transform coefficents.\n\n        Parameters\n        ----------\n        x : tensor\n            Size (batchsize, M, N, O).\n        module : tensor\n            Tensor that holds the overall sum.\n\n        Returns\n        -------\n        output : tensor\n            Tensor of the same size as input_array. It holds the output of\n            the operation::\n\n            $\\\\sqrt{\\\\sum_m (\\\\text{input}_\\\\text{array} \\\\star \\\\psi_{j,l,m})^2)}$\n\n            which is covariant to 3D translations and rotations.\n\n    """"""\n    if module is None:\n        module = tf.zeros_like(x, tf.float32)\n    else:\n        module = module ** 2\n    module += tf.abs(x) ** 2\n    return tf.sqrt(module)\n\n\ndef compute_integrals(input_array, integral_powers):\n    """"""Computes integrals.\n\n        Computes integrals of the input_array to the given powers.\n\n        Parameters\n        ----------\n        input_array : tensor\n            Size (B, M, N, O), where B is batch_size, and M, N, O are spatial\n            dims.\n        integral_powers : list\n            List of P positive floats containing the p values used to\n            compute the integrals of the input_array to the power p (l_p\n            norms).\n\n        Returns\n        -------\n        integrals : tensor\n            Tensor of size (B, P) containing the integrals of the input_array\n            to the powers p (l_p norms).\n\n    """"""\n    integrals = []\n    for i_q, q in enumerate(integral_powers):\n        integrals.append(tf.reduce_sum(tf.reshape(tf.pow(input_array, q), shape=(input_array.shape[0], -1)), axis=1))\n    return tf.stack(integrals, axis=-1)\n\n\ndef fft(x, direction=\'C2C\', inverse=False):\n    """"""FFT of a 3d signal.\n\n        Example\n        -------\n        real = tf.random.uniform(128, 32, 32, 32)\n        imag = tf.random.uniform(128, 32, 32, 32)\n\n        x = tf.complex(real, imag)\n\n        x_fft = fft(x)\n        x_ifft = fft(x, inverse=True)\n\n        x = fft(x_fft, inverse=True)\n        x = fft(x_ifft, inverse=False)\n\n        Parameters\n        ----------\n        input : tensor\n            Complex input for the FFT.\n        direction : string\n        \'C2R\' for complex to real, \'C2C\' for complex to complex.\n        inverse : bool\n            True for computing the inverse FFT.\n            NB : If direction is equal to \'C2R\', then an error is raised.\n\n        Raises\n        ------\n        RuntimeError\n            Raised in event we attempt to map from complex to real without\n            inverse FFT.\n\n        Returns\n        -------\n        output : tensor\n            Result of FFT or IFFT.\n\n    """"""\n    if direction == \'C2R\':\n        if not inverse:\n            raise RuntimeError(\'C2R mode can only be done with an inverse FFT\')\n\n    x = tf.cast(x, tf.complex64)\n\n    if direction == \'C2R\':\n        output = tf.math.real(tf.signal.ifft3d(x, name=\'irfft3d\'))\n    elif direction == \'C2C\':\n        if inverse:\n            output = tf.signal.ifft3d(x, name=\'ifft3d\')\n        else:\n            output = tf.signal.fft3d(x, name=\'fft3d\')\n    return tf.cast(output, tf.complex64)\n\n\ndef cdgmm3d(A, B, inplace=False):\n    """"""Complex pointwise multiplication.\n\n        Complex pointwise multiplication between (batched) tensor A and tensor B.\n\n        Parameters\n        ----------\n        A : tensor\n            Complex tensor.\n        B : tensor\n            Complex tensor of the same size as A.\n        inplace : boolean, optional\n            If set True, all the operations are performed inplace.\n\n        Returns\n        -------\n        output : tensor\n            Tensor of the same size as A containing the result of the elementwise\n            complex multiplication of A with B.\n\n    """"""\n    if B.ndim != 3:\n        raise RuntimeError(\'The dimension of the second input must be 3.\')\n\n    Cr = tf.cast(tf.math.real(A) * np.real(B) - tf.math.imag(A) * np.imag(B), tf.complex64)\n    Ci = tf.cast(tf.math.real(A) * np.imag(B) + tf.math.imag(A) * np.real(B), tf.complex64)\n\n    return Cr + 1.0j * Ci\n\n\ndef concatenate(arrays, L):\n    S = tf.stack(arrays, axis=1)\n    S = tf.reshape(S, tuple((S.shape[0], S.shape[1] // (L + 1), (L + 1))) + tuple(S.shape[2:]))\n    return S\n\n\nbackend = namedtuple(\'backend\', [\'name\', \'cdgmm3d\', \'fft\', \'modulus\', \'modulus_rotation\', \'compute_integrals\'])\n\nbackend.name = \'tensorflow\'\nbackend.cdgmm3d = cdgmm3d\nbackend.fft = fft\nbackend.modulus = complex_modulus\nbackend.modulus_rotation = modulus_rotation\nbackend.compute_integrals = compute_integrals\nbackend.concatenate = concatenate\n'"
kymatio/scattering3d/backend/torch_backend.py,0,"b'import torch\nimport warnings\n\nBACKEND_NAME = \'torch\'\nfrom collections import namedtuple\n\n\ndef _is_complex(input):\n    """"""Checks if input is complex.\n\n        Parameters\n        ----------\n        input : tensor\n            Input to be checked if complex.\n        Returns\n        -------\n        output : boolean\n            Returns True if complex (i.e. final dimension is 2), False\n            otherwise.\n    """"""\n    return input.shape[-1] == 2\n\n\ndef complex_modulus(input_array):\n    """"""Computes complex modulus.\n\n        Parameters\n        ----------\n        input_array : tensor\n            Input tensor whose complex modulus is to be calculated.\n        Returns\n        -------\n        modulus : tensor\n            Tensor the same size as input_array. modulus[..., 0] holds the\n            result of the complex modulus, modulus[..., 1] = 0.\n\n    """"""\n    modulus = torch.zeros_like(input_array)\n    modulus[..., 0] = torch.sqrt((input_array ** 2).sum(-1))\n    return modulus\n\n\ndef modulus_rotation(x, module=None):\n    """"""Used for computing rotation invariant scattering transform coefficents.\n\n        Parameters\n        ----------\n        x : tensor\n            Size (batchsize, M, N, O, 2).\n        module : tensor\n            Tensor that holds the overall sum. If none, initializes the tensor\n            to zero (default).\n        Returns\n        -------\n        output : torch tensor\n            Tensor of the same size as input_array. It holds the output of\n            the operation::\n            $\\\\sqrt{\\\\sum_m (\\\\text{input}_\\\\text{array} \\\\star \\\\psi_{j,l,m})^2)}$\n            which is covariant to 3D translations and rotations.\n    """"""\n    if module is None:\n        module = torch.zeros_like(x)\n    else:\n        module = module ** 2\n    module[..., 0] += (x ** 2).sum(-1)\n    return torch.sqrt(module)\n\n\ndef compute_integrals(input_array, integral_powers):\n    """"""Computes integrals.\n\n        Computes integrals of the input_array to the given powers.\n        Parameters\n        ----------\n        input_array : torch tensor\n            Size (B, M, N, O), where B is batch_size, and M, N, O are spatial\n            dims.\n        integral_powers : list\n            List of P positive floats containing the p values used to\n            compute the integrals of the input_array to the power p (l_p\n            norms).\n        Returns\n        -------\n        integrals : torch tensor\n            Tensor of size (B, P) containing the integrals of the input_array\n            to the powers p (l_p norms).\n    """"""\n    integrals = torch.zeros((input_array.shape[0], len(integral_powers)),\n            device=input_array.device)\n    for i_q, q in enumerate(integral_powers):\n        integrals[:, i_q] = (input_array ** q).view(\n            input_array.shape[0], -1).sum(1)\n    return integrals\n\n\ndef fft(input, inverse=False):\n    """"""Interface with torch FFT routines for 3D signals.\n        fft of a 3d signal\n        Example\n        -------\n        x = torch.randn(128, 32, 32, 32, 2)\n\n        x_fft = fft(x)\n        x_ifft = fft(x, inverse=True)\n        Parameters\n        ----------\n        x : tensor\n            Complex input for the FFT.\n        inverse : bool\n            True for computing the inverse FFT.\n\n        Raises\n        ------\n        TypeError\n            In the event that x does not have a final dimension 2 i.e. not\n            complex.\n\n        Returns\n        -------\n        output : tensor\n            Result of FFT or IFFT.\n    """"""\n    if not _is_complex(input):\n        raise TypeError(\'The input should be complex (e.g. last dimension is 2)\')\n    if inverse:\n        return torch.ifft(input, 3)\n    return torch.fft(input, 3)\n\n\ndef cdgmm3d(A, B, inplace=False):\n    """"""Complex pointwise multiplication.\n\n        Complex pointwise multiplication between (batched) tensor A and tensor B.\n\n        Parameters\n        ----------\n        A : torch tensor\n            Complex torch tensor.\n        B : torch tensor\n            Complex of the same size as A.\n        inplace : boolean, optional\n            If set True, all the operations are performed inplace.\n\n        Raises\n        ------\n        RuntimeError\n            In the event that the tensors are not compatibile for multiplication\n            (i.e. the final four dimensions of A do not match with the dimensions\n            of B), or in the event that B is not complex, or in the event that the\n            type of A and B are not the same.\n        TypeError\n            In the event that x is not complex i.e. does not have a final dimension\n            of 2, or in the event that both tensors are not on the same device.\n\n        Returns\n        -------\n        output : torch tensor\n            Torch tensor of the same size as A containing the result of the\n            elementwise complex multiplication of A with B.\n    """"""\n    if not A.is_contiguous():\n        warnings.warn(""cdgmm3d: tensor A is converted to a contiguous array."")\n        A = A.contiguous()\n    if not B.is_contiguous():\n        warnings.warn(""cdgmm3d: tensor B is converted to a contiguous array."")\n        B = B.contiguous()\n\n    if A.shape[-4:] != B.shape:\n        raise RuntimeError(\'The tensors are not compatible for multiplication.\')\n\n    if not _is_complex(A) or not _is_complex(B):\n        raise TypeError(\'The input, filter and output should be complex.\')\n\n    if B.ndimension() != 4:\n        raise RuntimeError(\'The second tensor must be simply a complex array.\')\n\n    if type(A) is not type(B):\n        raise RuntimeError(\'A and B should be same type.\')\n\n    if A.device.type != B.device.type:\n        raise TypeError(\'A and B must be both on GPU or both on CPU.\')\n\n    if A.device.type == \'cuda\':\n        if A.device.index != B.device.index:\n            raise TypeError(\'A and B must be on the same GPU.\')\n\n    C = A.new(A.shape)\n\n    C[..., 0] = A[..., 0] * B[..., 0] - A[..., 1] * B[..., 1]\n    C[..., 1] = A[..., 0] * B[..., 1] + A[..., 1] * B[..., 0]\n\n    return C if not inplace else A.copy_(C)\n\n\ndef concatenate(arrays, L):\n    S = torch.stack(arrays, dim=1)\n    S = S.reshape((S.shape[0], S.shape[1] // (L + 1), (L + 1)) + S.shape[2:])\n    return S\n\n\nbackend = namedtuple(\'backend\',\n                     [\'name\',\n                      \'cdgmm3d\',\n                      \'fft\',\n                      \'modulus\',\n                      \'modulus_rotation\',\n                      \'compute_integrals\',\n                      \'concatenate\'])\n\nbackend.name = \'torch\'\nbackend.cdgmm3d = cdgmm3d\nbackend.fft = fft\nbackend.concatenate = concatenate\nbackend.modulus = complex_modulus\nbackend.modulus_rotation = modulus_rotation\nbackend.compute_integrals = compute_integrals\n'"
kymatio/scattering3d/backend/torch_skcuda_backend.py,0,"b'import torch\nimport warnings\nfrom skcuda import cublas\n\nBACKEND_NAME = \'torch_skcuda\'\n\nfrom collections import namedtuple\n\n\ndef _is_complex(input):\n    return input.shape[-1] == 2\n\n\ndef cdgmm3d(A, B, inplace=False):\n    """"""Complex pointwise multiplication.\n\n        Complex pointwise multiplication between (batched) tensor A and tensor B.\n\n        Parameters\n        ----------\n        A : torch tensor\n            Complex torch tensor.\n        B : torch tensor\n            Complex of the same size as A.\n        inplace : boolean, optional\n            If set True, all the operations are performed inplace.\n\n        Raises\n        ------\n        RuntimeError\n            In the event that the tensors are not compatibile for multiplication\n            (i.e. the final four dimensions of A do not match with the dimensions\n            of B), or in the event that B is not complex, or in the event that the\n            type of A and B are not the same.\n        TypeError\n            In the event that x is not complex i.e. does not have a final dimension\n            of 2, or in the event that both tensors are not on the same device.\n\n        Returns\n        -------\n        output : torch tensor\n            Torch tensor of the same size as A containing the result of the\n            elementwise complex multiplication of A with B.\n\n    """"""\n    if not A.is_contiguous():\n        warnings.warn(""cdgmm3d: tensor A is converted to a contiguous array"")\n        A = A.contiguous()\n    if not B.is_contiguous():\n        warnings.warn(""cdgmm3d: tensor B is converted to a contiguous array"")\n        B = B.contiguous()\n\n    if A.shape[-4:] != B.shape:\n        raise RuntimeError(\'The filters are not compatible for multiplication.\')\n\n    if not _is_complex(A) or not _is_complex(B):\n        raise TypeError(\'The input, filter and output should be complex.\')\n\n    if B.ndimension() != 4:\n        raise RuntimeError(\'The filters must be simply a complex array.\')\n\n    if type(A) is not type(B):\n        raise RuntimeError(\'A and B should be same type.\')\n\n    if not A.is_cuda:\n        raise RuntimeError(\'Use the torch backend for CPU tensors.\')\n\n    C = A.new(A.shape) if not inplace else A\n    m, n = B.nelement() // 2, A.nelement() // B.nelement()\n    lda = m\n    ldc = m\n    incx = 1\n    handle = torch.cuda.current_blas_handle()\n    stream = torch.cuda.current_stream()._as_parameter_\n    cublas.cublasSetStream(handle, stream)\n    cublas.cublasCdgmm(handle, \'l\', m, n, A.data_ptr(), lda, B.data_ptr(), incx, C.data_ptr(), ldc)\n    return C\n\n\nfrom .torch_backend import complex_modulus\nfrom .torch_backend import fft\nfrom .torch_backend import modulus_rotation\nfrom .torch_backend import compute_integrals\nfrom .torch_backend import concatenate\n\nbackend = namedtuple(\'backend\', [\'name\', \'cdgmm3d\', \'fft\', \'modulus\', \'modulus_rotation\',\n                                 \'compute_integrals\', \'concatenate\'])\n\nbackend.name = \'torch_skcuda\'\nbackend.cdgmm3d = cdgmm3d\nbackend.fft = fft\nbackend.concatenate = concatenate\nbackend.modulus = complex_modulus\nbackend.modulus_rotation = modulus_rotation\nbackend.compute_integrals = compute_integrals\n'"
kymatio/scattering3d/core/__init__.py,0,b''
kymatio/scattering3d/core/scattering3d.py,0,"b'# Authors: Louis Thiry, Georgios Exarchakis\n# Scientific Ancestry: Louis Thiry, Georgios Exarchakis, Matthew Hirn, Michael Eickenberg\n\ndef scattering3d(x, filters, rotation_covariant, L, J, max_order, backend, averaging):\n    """"""\n    The forward pass of 3D solid harmonic scattering\n    Parameters\n    ----------\n    input_array: torch tensor\n        input of size (batchsize, M, N, O)\n    Returns\n    -------\n    output: tuple | torch tensor\n        if max_order is 1 it returns a torch tensor with the\n        first order scattering coefficients\n        if max_order is 2 it returns a torch tensor with the\n        first and second order scattering coefficients,\n        concatenated along the feature axis\n    """"""\n    fft = backend.fft\n    cdgmm3d = backend.cdgmm3d\n    modulus = backend.modulus\n    modulus_rotation = backend.modulus_rotation\n    concatenate = backend.concatenate\n\n    U_0_c = fft(x)\n\n    s_order_1, s_order_2 = [], []\n    for l in range(L + 1):\n        s_order_1_l, s_order_2_l = [], []\n        for j_1 in range(J + 1):\n            U_1_m = None\n            if rotation_covariant:\n                for m in range(len(filters[l][j_1])):\n                    U_1_c = cdgmm3d(U_0_c, filters[l][j_1][m])\n                    U_1_c = fft(U_1_c, inverse=True)\n                    U_1_m = modulus_rotation(U_1_c, U_1_m)\n            else:\n                U_1_c = cdgmm3d(U_0_c, filters[l][j_1][0])\n                U_1_c = fft(U_1_c , inverse=True)\n                U_1_m = modulus(U_1_c)\n\n            S_1_l = averaging(U_1_m)\n            s_order_1_l.append(S_1_l)\n\n            if max_order > 1:\n                U_1_c = fft(U_1_m)\n                for j_2 in range(j_1 + 1, J + 1):\n                    U_2_m = None\n                    if rotation_covariant:\n                        for m in range(len(filters[l][j_2])):\n                            U_2_c = cdgmm3d(U_1_c, filters[l][j_2][m])\n                            U_2_c = fft(U_2_c, inverse=True)\n                            U_2_m = modulus_rotation(U_2_c, U_2_m)\n                    else:\n                        U_2_c = cdgmm3d(U_1_c, filters[l][j_2][0])\n                        U_2_c = fft(U_2_c, inverse=True)\n                        U_2_m = modulus(U_2_c)\n                    S_2_l = averaging(U_2_m)\n                    s_order_2_l.append(S_2_l)\n\n        s_order_1.append(s_order_1_l)\n\n        if max_order == 2:\n            s_order_2.append(s_order_2_l)\n\n    # Concatenate the orders (along the j axis) if needed.\n    S = s_order_1\n    if max_order == 2:\n        S = [x + y for x, y in zip(S, s_order_2)]\n\n    # Invert (ell, m \xc3\x97 j) ordering to (m \xc3\x97 j, ell).\n    S = [x for y in zip(*S) for x in y]\n\n    S = concatenate(S, L)\n\n    return S\n'"
kymatio/scattering3d/frontend/__init__.py,0,b''
kymatio/scattering3d/frontend/base_frontend.py,0,"b'from ...frontend.base_frontend import ScatteringBase\nfrom ..filter_bank import solid_harmonic_filter_bank, gaussian_filter_bank\n\n\nclass ScatteringBase3D(ScatteringBase):\n    def __init__(self, J, shape, L=3, sigma_0=1, max_order=2,\n                 rotation_covariant=True, method=\'integral\', points=None,\n                 integral_powers=(0.5, 1., 2.), backend=None):\n        super(ScatteringBase3D, self).__init__()\n        self.J = J\n        self.shape = shape\n        self.L = L\n        self.sigma_0 = sigma_0\n\n        self.max_order = max_order\n        self.rotation_covariant = rotation_covariant\n        self.method = method\n        self.points = points\n        self.integral_powers = integral_powers\n        self.backend = backend\n\n    def build(self):\n        self.M, self.N, self.O = self.shape\n\n    def create_filters(self):\n        self.filters = solid_harmonic_filter_bank(\n            self.M, self.N, self.O, self.J, self.L, self.sigma_0)\n\n        self.gaussian_filters = gaussian_filter_bank(\n            self.M, self.N, self.O, self.J + 1, self.sigma_0)\n\n    _doc_shape = \'M, N, O\'\n\n    _doc_class = \\\n    r""""""The 3D solid harmonic scattering transform\n\n        This class implements solid harmonic scattering on a 3D input image.\n        For details see https://arxiv.org/abs/1805.00571.\n        {frontend_paragraph}\n\n        Example\n        -------\n        ::\n\n            # Set the parameters of the scattering transform.\n            J = 3\n            M, N, O = 32, 32, 32\n\n            # Generate a sample signal.\n            x = {sample}\n\n            # Define a HarmonicScattering3D object.\n            S = HarmonicScattering3D(J, (M, N, O))\n\n            # Calculate the scattering transform.\n            Sx = S.scattering(x)\n\n            # Equivalently, use the alias.\n            Sx = S{alias_call}(x)\n\n        Parameters\n        ----------\n        J: int\n            Number of scales.\n        shape: tuple of ints\n            Shape `(M, N, O)` of the input signal\n        L: int, optional\n            Number of `l` values. Defaults to `3`.\n        sigma_0: float, optional\n            Bandwidth of mother wavelet. Defaults to `1`.\n        max_order: int, optional\n            The maximum order of scattering coefficients to compute. Must be\n            either `1` or `2`. Defaults to `2`.\n        rotation_covariant: bool, optional\n            If set to `True` the first-order moduli take the form:\n\n            $\\sqrt{{\\sum_m (x \\star \\psi_{{j,l,m}})^2)}}$\n\n            if set to `False` the first-order moduli take the form:\n\n            $x \\star \\psi_{{j,l,m}}$\n\n            The second order moduli change analogously. Defaults to `True`.\n        method: string, optional\n            Specifies the method for obtaining scattering coefficients.\n            Currently, only `\'integral\'` is available. Defaults to `\'integral\'`.\n        integral_powers: array-like\n            List of exponents to the power of which moduli are raised before\n            integration.\n        """"""\n\n    _doc_scattering = \\\n    """"""Apply the scattering transform\n\n       Parameters\n       ----------\n       input_array: {array}\n           Input of size `(batch_size, M, N, O)`.\n\n       Returns\n       -------\n       output: {array}\n           If max_order is `1` it returns a{n} `{array}` with the first-order\n           scattering coefficients. If max_order is `2` it returns a{n}\n           `{array}` with the first- and second- order scattering\n           coefficients, concatenated along the feature axis.\n    """"""\n\n    @classmethod\n    def _document(cls):\n        cls.__doc__ = ScatteringBase3D._doc_class.format(\n            array=cls._doc_array,\n            frontend_paragraph=cls._doc_frontend_paragraph,\n            alias_name=cls._doc_alias_name,\n            alias_call=cls._doc_alias_call,\n            sample=cls._doc_sample.format(shape=cls._doc_shape))\n\n        cls.scattering.__doc__ = ScatteringBase3D._doc_scattering.format(\n            array=cls._doc_array,\n            n=cls._doc_array_n)\n\n\n__all__ = [\'ScatteringBase3D\']\n'"
kymatio/scattering3d/frontend/entry.py,0,"b""from ...frontend.entry import ScatteringEntry\n\n\nclass HarmonicScatteringEntry3D(ScatteringEntry):\n    def __init__(self, *args, **kwargs):\n        super().__init__(name='harmonic 3D',\n                         class_name='scattering3d',\n                         *args, **kwargs)\n\n\n__all__ = ['HarmonicScatteringEntry3D']\n"""
kymatio/scattering3d/frontend/numpy_frontend.py,1,"b""from ...frontend.numpy_frontend import ScatteringNumPy\nfrom kymatio.scattering3d.core.scattering3d import scattering3d\nfrom .base_frontend import ScatteringBase3D\nimport numpy as np\n\n\nclass HarmonicScatteringNumPy3D(ScatteringNumPy, ScatteringBase3D):\n    def __init__(self, J, shape, L=3, sigma_0=1, max_order=2, rotation_covariant=True, method='integral', points=None,\n                 integral_powers=(0.5, 1., 2.), backend='numpy'):\n        ScatteringNumPy.__init__(self)\n        ScatteringBase3D.__init__(self, J, shape, L, sigma_0, max_order,\n                                  rotation_covariant, method, points,\n                                  integral_powers, backend)\n\n        self.build()\n\n    def build(self):\n        ScatteringBase3D._instantiate_backend(self, 'kymatio.scattering3d.backend.')\n        ScatteringBase3D.build(self)\n        ScatteringBase3D.create_filters(self)\n\n    def scattering(self, input_array):\n        if not type(input_array) is np.ndarray:\n            raise TypeError('The input should be a NumPy array.')\n\n        if input_array.ndim < 3:\n            raise RuntimeError('Input tensor must have at least three '\n                               'dimensions.')\n\n        if (input_array.shape[-1] != self.O or input_array.shape[-2] != self.N\n            or input_array.shape[-3] != self.M):\n            raise RuntimeError(\n                'Tensor must be of spatial size (%i, %i, %i).' % (\n                    self.M, self.N, self.O))\n\n        batch_shape = input_array.shape[:-3]\n        signal_shape = input_array.shape[-3:]\n\n        input_array = input_array.reshape((-1,) + signal_shape)\n        self.averaging = lambda x: self.backend.compute_integrals(x, self.integral_powers)\n\n        S = scattering3d(input_array, filters=self.filters, rotation_covariant=self.rotation_covariant, L=self.L,\n                            J=self.J, max_order=self.max_order, backend=self.backend, averaging=self.averaging)\n\n\n        scattering_shape = S.shape[1:]\n\n        S = S.reshape(batch_shape + scattering_shape)\n\n        return S\n\n\nHarmonicScatteringNumPy3D._document()\n\n\n__all__ = ['HarmonicScatteringNumPy3D']\n"""
kymatio/scattering3d/frontend/sklearn_frontend.py,0,"b""from ...frontend.sklearn_frontend import ScatteringTransformerMixin\nfrom ...numpy import HarmonicScattering3D as HarmonicScatteringNumPy3D\n\n\n# NOTE: Order in base classes matters here, since we want the sklearn-specific\n# documentation parameters to take precedence over NP.\nclass HarmonicScatteringTransformer3D(ScatteringTransformerMixin,\n                                      HarmonicScatteringNumPy3D):\n    pass\n\n\nHarmonicScatteringTransformer3D._document()\n\n\n__all__ = ['HarmonicScatteringTransformer3D']\n"""
kymatio/scattering3d/frontend/tensorflow_frontend.py,0,"b""# Authors: Louis Thiry, Georgios Exarchakis\n# Scientific Ancestry: Louis Thiry, Georgios Exarchakis, Matthew Hirn, Michael Eickenberg\n\n__all__ = ['HarmonicScattering3DTensorFlow']\n\n\nimport tensorflow as tf\nfrom ...frontend.tensorflow_frontend import ScatteringTensorFlow\nfrom ..core.scattering3d import scattering3d\nfrom .base_frontend import ScatteringBase3D\n\n\nclass HarmonicScatteringTensorFlow3D(ScatteringTensorFlow, ScatteringBase3D):\n    def __init__(self, J, shape, L=3, sigma_0=1, max_order=2,\n            rotation_covariant=True, method='integral', points=None,\n            integral_powers=(0.5, 1., 2.), backend='tensorflow', name='HarmonicScattering3D'):\n        ScatteringTensorFlow.__init__(self, name=name)\n        ScatteringBase3D.__init__(self, J, shape, L, sigma_0, max_order,\n                                  rotation_covariant, method, points,\n                                  integral_powers, backend)\n        self.build()\n\n\n    def build(self):\n        ScatteringBase3D._instantiate_backend(self, 'kymatio.scattering3d.backend.')\n        ScatteringBase3D.build(self)\n        ScatteringBase3D.create_filters(self)\n\n    def scattering(self, x):\n        with tf.name_scope('scattering') as scope:\n            try:\n                x = tf.convert_to_tensor(x)\n            except ValueError:\n                raise TypeError('The input should be convertible to a '\n                                'TensorFlow Tensor.')\n\n            if len(x.shape) < 3:\n                raise RuntimeError('Input tensor should have at least three '\n                                   'dimensions.')\n\n            if (x.shape[-1] != self.O or x.shape[-2] != self.N or x.shape[-3] != self.M):\n                raise RuntimeError(\n                    'Tensor must be of spatial size (%i, %i, %i).' % (\n                        self.M, self.N, self.O))\n\n            methods = ['integral']\n\n            if not self.method in methods:\n                raise ValueError('method must be in {}'.format(methods))\n\n            if self.method == 'integral':\n                self.averaging = lambda x: self.backend.compute_integrals(x, self.integral_powers)\n\n            batch_shape = tf.shape(x)[:-3]\n            signal_shape = tf.shape(x)[-3:]\n\n            x = tf.reshape(x, tf.concat(((-1,), signal_shape), 0))\n\n            S = scattering3d(x, filters=self.filters,\n                             rotation_covariant=self.rotation_covariant,\n                             L=self.L, J=self.J, max_order=self.max_order,\n                             backend=self.backend, averaging=self.averaging)\n\n            scattering_shape = tf.shape(S)[1:]\n\n            S = tf.reshape(S, tf.concat((batch_shape, scattering_shape), 0))\n\n            return S\n\n\nHarmonicScatteringTensorFlow3D._document()\n"""
kymatio/scattering3d/frontend/torch_frontend.py,0,"b""# Authors: Louis Thiry, Georgios Exarchakis\n# Scientific Ancestry: Louis Thiry, Georgios Exarchakis, Matthew Hirn, Michael Eickenberg\n\nimport torch\nfrom ...frontend.torch_frontend import ScatteringTorch\nfrom ..core.scattering3d import scattering3d\nfrom .base_frontend import ScatteringBase3D\n\n\nclass HarmonicScatteringTorch3D(ScatteringTorch, ScatteringBase3D):\n    def __init__(self, J, shape, L=3, sigma_0=1, max_order=2, rotation_covariant=True, method='integral', points=None,\n                 integral_powers=(0.5, 1., 2.), backend='torch'):\n        ScatteringTorch.__init__(self)\n        ScatteringBase3D.__init__(self, J, shape, L, sigma_0, max_order,\n                                  rotation_covariant, method, points,\n                                  integral_powers, backend)\n\n        self.build()\n\n    def build(self):\n        ScatteringBase3D._instantiate_backend(self, 'kymatio.scattering3d.backend.')\n        ScatteringBase3D.build(self)\n        ScatteringBase3D.create_filters(self)\n\n        self.register_filters()\n\n    def register_filters(self):\n        # transfer the filters from numpy to torch\n        for k in range(len(self.filters)):\n            filt = torch.zeros(self.filters[k].shape + (2,))\n            filt[..., 0] = torch.from_numpy(self.filters[k].real).reshape(self.filters[k].shape)\n            filt[..., 1] = torch.from_numpy(self.filters[k].imag).reshape(self.filters[k].shape)\n            self.filters[k] = filt\n            self.register_buffer('tensor' + str(k), self.filters[k])\n\n        g = torch.zeros(self.gaussian_filters.shape + (2,))\n        g[..., 0] = torch.from_numpy(self.gaussian_filters.real)\n        self.gaussian_filters = g\n        self.register_buffer('tensor_gaussian_filter', self.gaussian_filters)\n\n    def scattering(self, input_array):\n        if not torch.is_tensor(input_array):\n            raise TypeError(\n                'The input should be a torch.cuda.FloatTensor, '\n                'a torch.FloatTensor or a torch.DoubleTensor.')\n\n        if input_array.dim() < 3:\n            raise RuntimeError('Input tensor must have at least three '\n                               'dimensions.')\n\n        if (input_array.shape[-1] != self.O or input_array.shape[-2] != self.N\n            or input_array.shape[-3] != self.M):\n            raise RuntimeError(\n                'Tensor must be of spatial size (%i, %i, %i).' % (\n                    self.M, self.N, self.O))\n\n        input_array = input_array.contiguous()\n\n        batch_shape = input_array.shape[:-3]\n        signal_shape = input_array.shape[-3:]\n\n        input_array = input_array.reshape((-1,) + signal_shape)\n\n        x = input_array.new(input_array.shape + (2,)).fill_(0)\n        x[..., 0] = input_array\n\n        buffer_dict = dict(self.named_buffers())\n        for k in range(len(self.filters)):\n            self.filters[k] = buffer_dict['tensor' + str(k)]\n\n        methods = ['integral']\n        if not self.method in methods:\n            raise ValueError('method must be in {}'.format(methods))\n\n        if self.method == 'integral': \\\n                self.averaging = lambda x: self.backend.compute_integrals(x, self.integral_powers)\n\n        S = scattering3d(x, filters=self.filters, rotation_covariant=self.rotation_covariant, L=self.L,\n                            J=self.J, max_order=self.max_order, backend=self.backend, averaging=self.averaging)\n        scattering_shape = S.shape[1:]\n\n        S = S.reshape(batch_shape + scattering_shape)\n\n        return S\n\n\nHarmonicScatteringTorch3D._document()\n\n\n__all__ = ['HarmonicScatteringTorch3D']\n"""
