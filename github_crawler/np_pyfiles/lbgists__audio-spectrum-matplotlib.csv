file_path,api_count,code
sound-spectrum-wave.py,8,"b'#!/usr/bin/env python\n# Written by Yu-Jie Lin\n# Public Domain\n#\n# Deps: PyAudio, NumPy, and Matplotlib\n# Blog: https://yjlv.blogspot.com/2012/11/frequency-spectrum-of-sound-using.html\n\nfrom __future__ import print_function\n\nimport struct\nimport wave\n\nimport matplotlib.animation as animation\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nTITLE = \'\'\nWIDTH = 1280\nHEIGHT = 720\nFPS = 25.0\n\nnFFT = 512\nBUF_SIZE = 4 * nFFT\nSAMPLE_SIZE = 2\nCHANNELS = 2\nRATE = 44100\n\n\ndef animate(i, line, wf, MAX_y):\n\n  N = (int((i + 1) * RATE / FPS) - wf.tell()) / nFFT\n  if not N:\n    return line,\n  N *= nFFT\n  data = wf.readframes(N)\n  print(\'{:5.1f}% - V: {:5,d} - A: {:10,d} / {:10,d}\'.format(\n    100.0 * wf.tell() / wf.getnframes(), i, wf.tell(), wf.getnframes()\n  ))\n\n  # Unpack data, LRLRLR...\n  y = np.array(struct.unpack(""%dh"" % (len(data) / SAMPLE_SIZE), data)) / MAX_y\n  y_L = y[::2]\n  y_R = y[1::2]\n\n  Y_L = np.fft.fft(y_L, nFFT)\n  Y_R = np.fft.fft(y_R, nFFT)\n\n  # Sewing FFT of two channels together, DC part uses right channel\'s\n  Y = abs(np.hstack((Y_L[-nFFT / 2:-1], Y_R[:nFFT / 2])))\n\n  line.set_ydata(Y)\n  return line,\n\n\ndef init(line):\n\n  # This data is a clear frame for animation\n  line.set_ydata(np.zeros(nFFT - 1))\n  return line,\n\n\ndef main():\n\n  dpi = plt.rcParams[\'figure.dpi\']\n  plt.rcParams[\'savefig.dpi\'] = dpi\n  plt.rcParams[""figure.figsize""] = (1.0 * WIDTH / dpi, 1.0 * HEIGHT / dpi)\n\n  fig = plt.figure()\n\n  # Frequency range\n  x_f = 1.0 * np.arange(-nFFT / 2 + 1, nFFT / 2) / nFFT * RATE\n  ax = fig.add_subplot(111, title=TITLE, xlim=(x_f[0], x_f[-1]),\n                       ylim=(0, 2 * np.pi * nFFT ** 2 / RATE))\n  ax.set_yscale(\'symlog\', linthreshy=nFFT ** 0.5)\n\n  line, = ax.plot(x_f, np.zeros(nFFT - 1))\n\n  # Change x tick labels for left channel\n  def change_xlabel(evt):\n    labels = [label.get_text().replace(u\'\\u2212\', \'\')\n              for label in ax.get_xticklabels()]\n    ax.set_xticklabels(labels)\n    fig.canvas.mpl_disconnect(drawid)\n  drawid = fig.canvas.mpl_connect(\'draw_event\', change_xlabel)\n\n  MAX_y = 2.0 ** (SAMPLE_SIZE * 8 - 1)\n  wf = wave.open(\'temp.wav\', \'rb\')\n  assert wf.getnchannels() == CHANNELS\n  assert wf.getsampwidth() == SAMPLE_SIZE\n  assert wf.getframerate() == RATE\n  frames = wf.getnframes()\n\n  ani = animation.FuncAnimation(\n    fig, animate, int(frames / RATE * FPS),\n    init_func=lambda: init(line), fargs=(line, wf, MAX_y),\n    interval=1000.0 / FPS, blit=True\n  )\n  ani.save(\'temp.mp4\', fps=FPS)\n\n  wf.close()\n\n\nif __name__ == \'__main__\':\n  main()\n'"
sound-spectrum.py,8,"b'#!/usr/bin/env python\n# Written by Yu-Jie Lin\n# Public Domain\n#\n# Deps: PyAudio, NumPy, and Matplotlib\n# Blog: https://yjlv.blogspot.com2012/11/frequency-spectrum-of-sound-using.html\n\nimport struct\nimport wave\n\nimport matplotlib.animation as animation\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pyaudio\n\nSAVE = 0.0\nTITLE = \'\'\nWIDTH = 1280\nHEIGHT = 720\nFPS = 25.0\n\nnFFT = 512\nBUF_SIZE = 4 * nFFT\nFORMAT = pyaudio.paInt16\nCHANNELS = 2\nRATE = 44100\n\n\ndef animate(i, line, stream, wf, MAX_y):\n\n  # Read n*nFFT frames from stream, n > 0\n  N = max(stream.get_read_available() / nFFT, 1) * nFFT\n  data = stream.read(N)\n  if SAVE:\n    wf.writeframes(data)\n\n  # Unpack data, LRLRLR...\n  y = np.array(struct.unpack(""%dh"" % (N * CHANNELS), data)) / MAX_y\n  y_L = y[::2]\n  y_R = y[1::2]\n\n  Y_L = np.fft.fft(y_L, nFFT)\n  Y_R = np.fft.fft(y_R, nFFT)\n\n  # Sewing FFT of two channels together, DC part uses right channel\'s\n  Y = abs(np.hstack((Y_L[-nFFT / 2:-1], Y_R[:nFFT / 2])))\n\n  line.set_ydata(Y)\n  return line,\n\n\ndef init(line):\n\n  # This data is a clear frame for animation\n  line.set_ydata(np.zeros(nFFT - 1))\n  return line,\n\n\ndef main():\n\n  dpi = plt.rcParams[\'figure.dpi\']\n  plt.rcParams[\'savefig.dpi\'] = dpi\n  plt.rcParams[""figure.figsize""] = (1.0 * WIDTH / dpi, 1.0 * HEIGHT / dpi)\n\n  fig = plt.figure()\n\n  # Frequency range\n  x_f = 1.0 * np.arange(-nFFT / 2 + 1, nFFT / 2) / nFFT * RATE\n  ax = fig.add_subplot(111, title=TITLE, xlim=(x_f[0], x_f[-1]),\n                       ylim=(0, 2 * np.pi * nFFT ** 2 / RATE))\n  ax.set_yscale(\'symlog\', linthreshy=nFFT ** 0.5)\n\n  line, = ax.plot(x_f, np.zeros(nFFT - 1))\n\n  # Change x tick labels for left channel\n  def change_xlabel(evt):\n    labels = [label.get_text().replace(u\'\\u2212\', \'\')\n              for label in ax.get_xticklabels()]\n    ax.set_xticklabels(labels)\n    fig.canvas.mpl_disconnect(drawid)\n  drawid = fig.canvas.mpl_connect(\'draw_event\', change_xlabel)\n\n  p = pyaudio.PyAudio()\n  # Used for normalizing signal. If use paFloat32, then it\'s already -1..1.\n  # Because of saving wave, paInt16 will be easier.\n  MAX_y = 2.0 ** (p.get_sample_size(FORMAT) * 8 - 1)\n\n  frames = None\n  wf = None\n  if SAVE:\n    frames = int(FPS * SAVE)\n    wf = wave.open(\'temp.wav\', \'wb\')\n    wf.setnchannels(CHANNELS)\n    wf.setsampwidth(p.get_sample_size(FORMAT))\n    wf.setframerate(RATE)\n\n  stream = p.open(format=FORMAT,\n                  channels=CHANNELS,\n                  rate=RATE,\n                  input=True,\n                  frames_per_buffer=BUF_SIZE)\n\n  ani = animation.FuncAnimation(\n    fig, animate, frames,\n    init_func=lambda: init(line), fargs=(line, stream, wf, MAX_y),\n    interval=1000.0 / FPS, blit=True\n  )\n\n  if SAVE:\n    ani.save(\'temp.mp4\', fps=FPS)\n  else:\n    plt.show()\n\n  stream.stop_stream()\n  stream.close()\n  p.terminate()\n\n  if SAVE:\n    wf.close()\n\n\nif __name__ == \'__main__\':\n  main()\n'"
