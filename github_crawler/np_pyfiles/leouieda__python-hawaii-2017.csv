file_path,api_count,code
download_data.py,0,"b'""""""\nThis script downloads temperature measurements from http://berkeleyearth.org\n(country mean) for all available countries listed in ""countries.txt"" plus the\ndata for Hawaii.\n\nIt uses the library ""requests"" to perform HTTP GET requests to the server and\nget the respective data file. We have to do some clever manipulations because\nthe data files are encoded using Latin1 instead of Unicode. And life is so much\nnicer when everything is Unicode.\n\nAll data files are placed in the ""data"" folder.\n""""""\nimport os\nimport requests\n\n# If the \'data\' folder doesn\'t exist, create it.\nif not os.path.exists(\'data\'):\n    os.mkdir(\'data\')\n    print(\'Create ""data"" folder.\')\nelse:\n    print(\'Using existing ""data"" folder.\')\n    print(\'WARNING: Will overwrite any files in there!\')\n# Empty \'print\' will print an empty line.\nprint()\n\n# Load the list of countries\n# Use the \'open\' function to open a file for reading. The file content is\n# accessed using the \'country_file\' variable.\nwith open(\'countries.txt\') as country_file:\n    # We need to read in the country names, filter out empty strings from the\n    # country list, and strip trailing white space and line breaks.\n    # We\'ll start with an empty list and fill it with the names from our open\n    # file.\n    countries = []\n    # Using an open file object in a \'for\' loop will iterate over the lines of\n    # that file, one at a time, until the end of the file.\n    for line in country_file:\n        # Remove trailing spaces and newlines.\n        stripped = line.strip()\n        # Check if the line is not an empty string after removing trailing\n        # spaces and newlines.\n        if stripped:\n            # Add to the country list\n            countries.append(stripped)\n    # As a bonus, the above code could be substituted by a single line using\n    # Pythons coolest feature: list comprehensions.\n    # countries = [line.strip() for line in country_file if line.strip()]\n\n# We\'ll be sneaky (lazy?) and add Hawaii to our list of countries to download\n# the data from there as well.\ncountries.append(\'Hawaii\')\n\nbaseurl = \'http://berkeleyearth.lbl.gov/auto/Regional/TAVG/Text/\'\n\n# We will collect the names of any country that we fail to download.\nfailed = []\n\nprint(""Downloading data files:"")\n\n# The \'enumerate\' function will produce an index number along with the list\n# elements in a \'for\' loop. It\'s very handy.\nfor country_number, country in enumerate(countries):\n    # Print the number of the current country and its name. We add 1 because\n    # enumerate starts from 0.\n    print(\'    {}. {}... \'.format(country_number + 1, country), end=\'\')\n    # Convert to lower case (lower) and use \'-\' instead of white space in case\n    # of composite names.\n    country_no_spaces = country.lower().replace(\' \', \'-\')\n    # The country names are Unicode strings (with some special characters, like\n    # in ""\xc3\x85land""). To get those characters into URLs, we must encode them using\n    # a specific notation (e.g., \'%20\' instead of \' \'). We can do that using\n    # requests. Another detail is that the file names on the server are\n    # actually encoded using latin1 instead of Unicode :(\n    country_quoted = requests.utils.quote(country_no_spaces, encoding=\'latin1\')\n    file_name =  country_quoted + \'-TAVG-Trend.txt\'\n    url = baseurl + file_name\n    # Now that we have a URL, we can make a GET request to get back our data\n    # file.\n    request = requests.get(url)\n    # The status code tells us if the request was successful (200).\n    if request.status_code != 200:\n        failed.append(country)\n        print(\'FAILED\')\n    else:\n        # Save the downloaded text to a file in the ""data"" folder.\n        # We can use the \'os\' module to operate on paths in a\n        # platform-independent way.\n        # We need to open the file with write permission (\'w\')\n        with open(os.path.join(\'data\', file_name), \'w\') as output_file:\n            # Once again, text encoding is an issue. The data file is encoded\n            # using latin1 instead of unicode (which is what Python likes), so\n            # special characters will break when we read in the data.\n            # Luckily, it\'s easy to convert the data file to unicode using the\n            # \'decode\' method.\n            output_file.write(request.content.decode(\'latin1\'))\n        print(\'Success\')\n\n# An empty list will evaluate to False in an \'if\' statement, so we can easily\n# check if any of our downloads failed.\nif failed:\n    print(""\\nFailed to download data from the following countries:"")\n    for country in failed:\n        print(country)\nelse:\n    print(\'\\nDone\')\n'"
