file_path,api_count,code
main.py,0,"b'#!/usr/bin/env python3\nimport argparse\nimport functools\nimport os\nimport sys\nimport time\nfrom datetime import datetime\nfrom typing import Iterable, Tuple, NamedTuple\n\nimport numpy\n\nfrom audio_io import read_audio_info, read_audio_data, TagKey, TrackInfo, get_tag_with_alternatives\nfrom audio_io.audio_io import AudioSourceInfo, AudioData\nfrom audio_metrics import compute_dr\nfrom util.constants import MEASURE_SAMPLE_RATE\n\n\ndef get_log_path(in_path):\n    if os.path.isdir(in_path):\n        out_path = in_path\n    else:\n        out_path = os.path.dirname(in_path)\n    return os.path.join(out_path, \'dr.txt\')\n\n\nclass LogGroup(NamedTuple):\n    performers: Iterable[str]\n    albums: Iterable[str]\n    channels: int\n    sample_rate: int\n    tracks_dr: Iterable[Tuple[int, float, float, int, str]]\n\n\ndef get_group_title(group: LogGroup):\n    return f\'{"", "".join(group.performers)} \xe2\x80\x94 {"", "".join(group.albums)}\'\n\n\ndef format_time(seconds):\n    d = divmod\n    m, s = d(seconds, 60)\n    h, m = d(m, 60)\n    if h:\n        return f\'{h}:{m:02d}:{s:02d}\'\n    return f\'{m}:{s:02d}\'\n\n\ndef write_log(write_fun, dr_log_groups: Iterable[LogGroup], average_dr):\n    l1 = \'-\' * 80\n    l2 = \'=\' * 80\n    w = write_fun\n    w(f""generated by https://github.com/magicgoose/simple_dr_meter\\n""\n      f""log date: {datetime.now().strftime(\'%Y-%m-%d %H:%M:%S\')}\\n\\n"")\n    for group in dr_log_groups:\n        group_name = get_group_title(group)\n\n        w(f""{l1}\\nAnalyzed: {group_name}\\n{l1}\\n\\nDR         Peak         RMS     Duration Track\\n{l1}\\n"")\n        track_count = 0\n        for dr, peak, rms, duration_sec, track_name in group.tracks_dr:\n            dr_formatted = f""DR{str(dr).ljust(4)}"" if dr is not None else ""N/A   ""\n            w(dr_formatted +\n              f""{peak:9.2f} dB""\n              f""{rms:9.2f} dB""\n              f""{format_time(duration_sec).rjust(10)} ""\n              f""{track_name}\\n"")\n            track_count += 1\n        w(f""{l1}\\n\\nNumber of tracks:  {track_count}\\nOfficial DR value: DR{average_dr}\\n\\n""\n          f""Samplerate:        {group.sample_rate} Hz\\nChannels:          {group.channels}\\n{l2}\\n\\n"")\n\n\ndef flatmap(f, items):\n    for i in items:\n        yield from f(i)\n\n\ndef make_log_groups(l: Iterable[Tuple[AudioSourceInfo, Iterable[Tuple[int, float, float, int, str]]]]):\n    import itertools\n    grouped = itertools.groupby(l, key=lambda x: (x[0].channel_count, x[0].sample_rate))\n\n    for ((channels, sample_rate), subitems) in grouped:\n        subitems = tuple(subitems)\n        performers = set(map(lambda x: get_tag_with_alternatives(x[0].tags, TagKey.PERFORMER), subitems))\n        albums = set(map(lambda x: get_tag_with_alternatives(x[0].tags, TagKey.ALBUM), subitems))\n        tracks_dr = flatmap(lambda x: x[1], subitems)\n        yield LogGroup(\n            performers=performers,\n            albums=albums,\n            channels=channels,\n            sample_rate=sample_rate,\n            tracks_dr=tracks_dr)\n\n\ndef parse_args():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(""input"", help=\'Input file or directory\')\n    ap.add_argument(""--no-log"", help=\'Do not write log (dr.txt), by default a log file is written after analysis\',\n                    action=\'store_true\')\n    ap.add_argument(""--keep-precision"", help=\'Do not round values, this also disables log\', action=\'store_true\')\n    args = sys.argv[1:]\n    if args:\n        return ap.parse_args(args)\n    else:\n        ap.print_help()\n        return None\n\n\ndef main():\n    args = parse_args()\n    if not args:\n        return\n\n    in_path = os.path.expanduser(args.input)\n    should_write_log = not args.no_log and not args.keep_precision\n    keep_precision = args.keep_precision\n\n    if should_write_log:\n        log_path = get_log_path(in_path)\n        if os.path.exists(log_path):\n            sys.exit(\'the log file already exists!\')\n\n    def track_cb(track_info: TrackInfo, dr):\n        dr_formatted = f\'DR{dr}\' if dr is not None else \'N/A\'\n        title = get_tag_with_alternatives(track_info.tags, TagKey.TITLE)\n        print(f""{track_info.global_index:02d} - {title}: {dr_formatted}"")\n\n    time_start = time.time()\n    dr_log_items, dr_mean, dr_median = analyze_dr(in_path, track_cb, keep_precision)\n    print(f\'Official DR = {dr_mean}, Median DR = {dr_median}\')\n    print(f\'Analyzed all tracks in {time.time() - time_start:.2f} seconds\')\n\n    if should_write_log:\n        # noinspection PyUnboundLocalVariable\n        print(f\'writing log to {log_path}\')\n        with open(log_path, mode=\'x\', encoding=\'utf8\') as f:\n            write_log(f.write, dr_log_items, dr_mean)\n        print(\'\xe2\x80\xa6done\')\n    else:\n        write_log(sys.stdout.write, dr_log_items, dr_mean)\n    fix_tty()\n\n\ndef fix_tty():\n    """"""I don\'t know why this is needed, but it is. Otherwise the terminal may cease to\n    accept any keyboard input after this application finishes. Hopefully I will find\n    something better eventually.""""""\n    platform = sys.platform.lower()\n    if platform.startswith(\'darwin\') or platform.startswith(\'linux\'):\n        if os.isatty(sys.stdin.fileno()):\n            os.system(\'stty sane\')\n\n\ndef analyze_dr(in_path: str, track_cb, keep_precision: bool):\n    audio_info = tuple(read_audio_info(in_path))\n    num_files = len(audio_info)\n    assert num_files > 0\n\n    import multiprocessing.dummy as mt\n    import multiprocessing\n\n    cpu_count = multiprocessing.cpu_count()\n\n    def choose_map_impl(threads, *, chunksize):\n        if threads <= 1:\n            return map\n        pool = mt.Pool(threads)\n        return functools.partial(pool.imap_unordered, chunksize=chunksize)\n\n    threads_outer = max(1, min(num_files, cpu_count))\n    threads_inner = cpu_count // threads_outer\n    map_impl_outer = choose_map_impl(threads_outer, chunksize=1)\n    map_impl_inner = choose_map_impl(threads_inner, chunksize=4)\n\n    def analyze_part_tracks(audio_data: AudioData, audio_info_part: AudioSourceInfo, map_impl):\n        for track_samples, track_info in zip(audio_data.blocks_generator, audio_info_part.tracks):\n            dr_metrics = compute_dr(map_impl, audio_info_part, track_samples, keep_precision)\n            yield track_info, dr_metrics\n\n    def analyze_part(map_impl, audio_info_part: AudioSourceInfo):\n        audio_data = read_audio_data(audio_info_part, 3 * MEASURE_SAMPLE_RATE)\n        return audio_info_part, analyze_part_tracks(audio_data, audio_info_part, map_impl)\n\n    dr_items = []\n    dr_log_items = []\n\n    def process_results(audio_info_part, analyzed_tracks):\n        nonlocal dr_items\n        dr_log_subitems = []\n        dr_log_items.append((audio_info_part, dr_log_subitems))\n        track_results = []\n        for track_info, dr_metrics in analyzed_tracks:\n            dr = dr_metrics.dr\n            track_results.append((track_info, dr))\n            track_cb(track_info, dr)\n            if dr:\n                dr_items.append(dr)\n\n            duration_seconds = round(dr_metrics.sample_count / MEASURE_SAMPLE_RATE)\n            title = get_tag_with_alternatives(track_info.tags, TagKey.TITLE)\n            dr_log_subitems.append(\n                (dr, dr_metrics.peak, dr_metrics.rms, duration_seconds,\n                 f""{track_info.global_index:02d}-{title}""))\n        return track_results\n\n    def process_part(map_impl, audio_info_part: AudioSourceInfo):\n        audio_info_part, analyzed_tracks = analyze_part(map_impl, audio_info_part)\n        return process_results(audio_info_part, analyzed_tracks)\n\n    for x in map_impl_outer(functools.partial(process_part, map_impl_inner), audio_info):\n        for track_result in x:\n            pass  # we need to go through all items for the side effects\n\n    if keep_precision:\n        dr_mean_rounded = numpy.mean(dr_items)\n    else:\n        dr_mean_rounded = int(numpy.round(numpy.mean(dr_items)))  # official\n    dr_median = numpy.median(dr_items)\n\n    dr_log_items = make_log_groups(dr_log_items)\n    return dr_log_items, dr_mean_rounded, dr_median\n\n\nif __name__ == \'__main__\':\n    main()\n'"
setup.py,0,b''
audio_io/__init__.py,0,b'from audio_io.audio_io import *\n'
audio_io/audio_io.py,5,"b'import itertools\nimport json\nimport os\nimport subprocess as sp\nimport sys\nfrom enum import Enum, auto\nfrom os import path\nfrom subprocess import DEVNULL, PIPE\nfrom typing import NamedTuple, Iterator, Sequence, Iterable, List, Optional\n\nimport numpy as np\n\nfrom audio_io.cue.cue_parser import CueCmd, parse_cue_str, read_cue_from_file\nfrom util.constants import MEASURE_SAMPLE_RATE\nfrom util.natural_sort import natural_sort_key\n\nex_ffprobe = \'ffprobe\'\nex_ffmpeg = \'ffmpeg\'\n\nknown_audio_extensions = {\n    \'aac\',\n    \'ac3\',\n    \'aif\',\n    \'aiff\',\n    \'ape\',\n    \'dts\',\n    \'flac\',\n    \'m4a\',\n    \'mka\',\n    \'mp2\',\n    \'mp3\',\n    \'mpc\',\n    \'ofr\',\n    \'ogg\',\n    \'opus\',\n    \'tak\',\n    \'tta\',\n    \'wav\',\n    \'wv\',\n}\n\n\nclass FileKind(Enum):\n    CUE = auto()\n    FOLDER = auto()\n    AUDIO = auto()\n\n\nclass TagKey(str, Enum):\n    TITLE = \'TITLE\'\n    ALBUM = \'ALBUM\'\n    ARTIST = \'ARTIST\'\n    PERFORMER = \'PERFORMER\'\n    CUESHEET = \'CUESHEET\'\n\n\n_tag_alternatives = {\n    TagKey.PERFORMER: (TagKey.ARTIST,),\n    TagKey.ARTIST: (TagKey.PERFORMER,),\n}\n\n\ndef get_tag_with_alternatives(tags: dict, tag_key: TagKey) -> Optional[str]:\n    exact_match = tags.get(tag_key)\n    if exact_match:\n        return exact_match\n    for alt_key in _tag_alternatives.get(tag_key, ()):\n        v = tags.get(alt_key)\n        if v:\n            return v\n    return None\n\n\ndef get_file_kind(in_path: str) -> FileKind:\n    if os.path.isdir(in_path):\n        return FileKind.FOLDER\n    _, ext = path.splitext(in_path)\n    if \'.cue\' == ext.lower():\n        return FileKind.CUE\n    return FileKind.AUDIO\n\n\nclass TrackInfo(NamedTuple):\n    global_index: int\n    offset_samples: int\n    tags: dict\n\n\nclass AudioFileMetadata(NamedTuple):\n    file_path: str\n    channel_count: int\n    sample_rate: int\n    cuesheet: str or None\n    tags: dict\n\n\nclass AudioSourceInfo(NamedTuple):\n    file_path: str\n    channel_count: int\n    sample_rate: int\n    tags: dict\n    tracks: List[TrackInfo]\n\n\nclass AudioData(NamedTuple):\n    source_info: AudioSourceInfo\n    samples_per_block: int\n    blocks_generator: Iterator[Iterator[np.ndarray]]\n\n\ndef _translate_from_cue(cue_items,\n                        directory_path=None,\n                        parent_audio_file: AudioFileMetadata = None) -> Iterable[AudioSourceInfo]:\n    global_track_counter = itertools.count(1)\n    index_number = None\n    index_offset = None\n    last_file_path = None\n    channel_count = None\n    sample_rate = None\n\n    track_start = False  # if parser is between TRACK and INDEX commands\n    global_tags = dict()\n    track_tags = dict()\n\n    def add_tag(key: TagKey, value: str, is_global: bool):\n        if is_global:\n            global_tags[key] = value\n            if key not in track_tags:\n                track_tags[key] = value\n        else:\n            track_tags[key] = value\n\n    tracks = []\n\n    join = os.path.join\n\n    for cmd, *args in cue_items:\n        if cmd == CueCmd.TRACK or cmd == CueCmd.FILE or cmd == CueCmd.EOF:\n            if index_number is not None:\n                assert index_offset is not None\n                # noinspection PyTypeChecker\n                tracks.append(TrackInfo(\n                    global_index=next(global_track_counter),\n                    offset_samples=index_offset,\n                    tags=track_tags\n                ))\n                track_tags = dict(global_tags)\n                index_number = None\n            if cmd == CueCmd.TRACK:\n                track_start = True\n                continue\n\n        if cmd == CueCmd.FILE or cmd == CueCmd.EOF:\n            if last_file_path:\n                yield AudioSourceInfo(\n                    file_path=last_file_path,\n                    channel_count=channel_count,\n                    sample_rate=sample_rate,\n                    tracks=tracks,\n                    tags=global_tags)\n                tracks = []\n            if cmd == CueCmd.EOF:\n                return\n\n            if directory_path:\n                last_file_path = join(directory_path, args[0])\n                p = read_audio_file_metadata(last_file_path)\n                channel_count, sample_rate = p.channel_count, p.sample_rate\n                global_tags.update(p.tags)\n            elif parent_audio_file:\n                last_file_path = parent_audio_file.file_path\n                channel_count = parent_audio_file.channel_count\n                sample_rate = parent_audio_file.sample_rate\n                global_tags.update(parent_audio_file.tags)\n            else:\n                raise ValueError\n        elif cmd == CueCmd.TITLE:\n            add_tag(TagKey.TITLE, args[0], is_global=not track_start)\n            if not track_start:\n                add_tag(TagKey.ALBUM, args[0], is_global=True)\n        elif cmd == CueCmd.PERFORMER:\n            add_tag(TagKey.PERFORMER, args[0], is_global=not track_start)\n        elif cmd == CueCmd.INDEX:\n            track_start = False\n            number, offset = args\n\n            if len(tracks):\n                num_condition = lambda: index_number < number\n            else:\n                num_condition = lambda: index_number > number\n\n            if (index_number is None) or (number <= 1 and num_condition()):\n                index_number, index_offset = number, int(MEASURE_SAMPLE_RATE * offset)\n        elif cmd == CueCmd.REM:\n            add_tag(args[0], args[1], is_global=not track_start)\n        else:\n            raise NotImplementedError\n\n\ndef _single_track_audio_source(p: AudioFileMetadata, track_index):\n    track_info = TrackInfo(global_index=track_index, offset_samples=0, tags=p.tags)\n    return AudioSourceInfo(\n        file_path=p.file_path,\n        channel_count=p.channel_count,\n        sample_rate=p.sample_rate,\n        tags=p.tags,\n        tracks=[track_info])\n\n\ndef _audio_source_from_file(in_path, track_index=1) -> AudioSourceInfo:\n    p = read_audio_file_metadata(in_path)\n    if not p.cuesheet:\n        return _single_track_audio_source(p, track_index)\n    cue_entries = parse_cue_str(p.cuesheet)\n    return next(iter(_translate_from_cue(cue_entries, parent_audio_file=p)))\n\n\ndef _audio_sources_from_folder(in_path) -> Iterable[AudioSourceInfo]:\n    track_counter = itertools.count(1)\n    for dirpath, dirnames, filenames in os.walk(in_path, topdown=True):\n        filenames = sorted(filenames, key=natural_sort_key)\n        for f in filenames:\n            _, ext = path.splitext(f)\n            ext = ext[1:].lower()\n            if ext in known_audio_extensions:\n                yield _audio_source_from_file(path.join(in_path, f), track_index=next(track_counter))\n        break\n\n\ndef read_audio_info(in_path: str) -> Iterable[AudioSourceInfo]:\n    """"""\n    if input file is a cue, it can reference multiple audio files with different sample rates.\n    therefore the result is a sequence.\n    """"""\n    kind = get_file_kind(in_path)\n    if kind == FileKind.FOLDER:\n        yield from _audio_sources_from_folder(in_path)\n    elif kind == FileKind.CUE:\n        cue_str = read_cue_from_file(in_path)\n        yield from _translate_from_cue(parse_cue_str(cue_str), directory_path=os.path.dirname(in_path))\n    elif kind == FileKind.AUDIO:\n        yield _audio_source_from_file(in_path)\n    else:\n        raise NotImplementedError\n\n\ndef read_audio_data(audio_source: AudioSourceInfo, samples_per_block: int) -> AudioData:\n    audio_blocks = _read_audio_blocks(audio_source.file_path,\n                                      audio_source.channel_count,\n                                      samples_per_block,\n                                      audio_source.tracks)\n    return AudioData(audio_source, samples_per_block, audio_blocks)\n\n\ndef _test_ffmpeg():\n    try:\n        for n in (ex_ffmpeg, ex_ffprobe):\n            sp.check_call((n, \'-version\'), stderr=DEVNULL, stdout=DEVNULL)\n    except sp.CalledProcessError:\n        sys.exit(\'ffmpeg not installed, broken or not on PATH\')\n\n\ndef _parse_audio_metadata(in_path: str, data_from_ffprobe: dict) -> AudioFileMetadata:\n    def get(*keys, default_value=None):\n        d = data_from_ffprobe\n        for k in keys:\n            try:\n                d = d[k]\n            except (KeyError, IndexError):\n                return default_value\n        return d\n\n    tags = {key.upper(): val for key, val in get(\'format\', \'tags\', default_value={}).items()}\n    return AudioFileMetadata(\n        file_path=in_path,\n        channel_count=int(get(\'streams\', 0, \'channels\')),\n        sample_rate=int(get(\'streams\', 0, \'sample_rate\')),\n        tags=tags,\n        cuesheet=tags.get(TagKey.CUESHEET))\n\n\ndef read_audio_file_metadata(in_path) -> AudioFileMetadata:\n    p = sp.Popen(\n        (ex_ffprobe,\n         \'-v\', \'error\',\n         \'-print_format\', \'json\',\n         \'-select_streams\', \'a:0\',\n         \'-show_entries\', \'stream=channels,sample_rate\',\n         \'-show_entries\', \'format_tags\',\n         in_path),\n        stdout=PIPE, stderr=PIPE)\n    out, err = p.communicate()\n    returncode = p.returncode\n    if returncode != 0:\n        raise Exception(\'ffprobe returned {}\'.format(returncode))\n    audio_metadata = _parse_audio_metadata(in_path, json.loads(out, encoding=\'utf-8\'))\n    assert audio_metadata.channel_count >= 1\n    return audio_metadata\n\n\ndef _read_audio_blocks(in_path, channel_count, samples_per_block, tracks: List[TrackInfo]) -> \\\n        Iterator[Iterator[np.ndarray]]:\n    bytes_per_sample = 4 * channel_count\n    max_bytes_per_block = bytes_per_sample * samples_per_block\n\n    p = sp.Popen(\n        (ex_ffmpeg, \'-loglevel\', \'fatal\',\n         \'-i\', in_path,\n         \'-map\', \'0:a:0\',\n         \'-c:a\', \'pcm_f32le\',\n         \'-ar\', str(MEASURE_SAMPLE_RATE),\n         # ^ because apparently official meter resamples to 44k before measuring;\n         # using default low quality resampling because it doesn\'t affect measurements and is faster\n         \'-f\', \'f32le\',\n         \'-\'),\n        stderr=None,\n        stdout=PIPE)\n\n    sample_type = np.dtype(\'<f4\')\n    frombuffer = np.frombuffer\n    reshape = np.reshape\n    with p.stdout as f:\n        skip_samples = tracks[0].offset_samples\n        if skip_samples > 0:\n            f.read(bytes_per_sample * skip_samples)\n\n        def make_array(buffer, size):\n            a = frombuffer(buffer, dtype=sample_type, count=size // 4)\n            a = reshape(a, (channel_count, -1), order=\'F\')\n            return a\n\n        def read_n_bytes(n):\n            while (n is None) or (n >= max_bytes_per_block):\n                b = f.read(max_bytes_per_block)\n                read_size = len(b)\n                if read_size > 0:\n                    yield make_array(b, read_size)\n                    if n:\n                        n -= read_size\n                else:\n                    return\n            if n:\n                b = f.read(n)\n                read_size = len(b)\n                assert read_size == n\n                yield make_array(b, read_size)\n\n        track_count = len(tracks)\n        for ti in range(track_count):\n            if track_count == ti + 1:\n                bytes_to_read = None\n            else:\n                samples_to_read = tracks[ti + 1].offset_samples - tracks[ti].offset_samples\n                bytes_to_read = samples_to_read * bytes_per_sample\n            yield read_n_bytes(bytes_to_read)\n'"
audio_metrics/__init__.py,0,b'from audio_metrics.audio_metrics import *\n'
audio_metrics/audio_metrics.py,18,"b""from math import floor\nfrom typing import NamedTuple, Iterator\n\nimport numpy as np\n\nfrom audio_io.audio_io import AudioSourceInfo\n\n\nclass DynamicRangeMetrics(NamedTuple):\n    dr: int\n    peak: float\n    rms: float\n    sample_count: int\n\n\ndef _calc_block_metrics(map_impl, samples: Iterator[np.ndarray], sample_count):\n    def process_part(a: np.ndarray):\n        length = a.shape[1]\n        sample_count[0] += length\n\n        a = np.ascontiguousarray(a)\n        peaks = np.max(np.abs(a), axis=1)\n\n        a = a ** 2  # numpy sometimes created readonly array so a**=2 won't always work\n        sum_sqr = np.sum(a, axis=1)\n        rms = np.sqrt(2.0 * sum_sqr / length)\n        return peaks, rms, sum_sqr\n\n    results = map_impl(process_part, samples)\n\n    for peaks, rms, sum_sqr in results:\n        yield from peaks\n        yield from rms\n        yield from sum_sqr\n\n\ndef decibel(a):\n    return np.log10(a) * 20\n\n\ndef compute_dr(pool, a: AudioSourceInfo, samples: Iterator[np.ndarray], keep_precision: bool) -> DynamicRangeMetrics:\n    channel_count = a.channel_count\n\n    sample_count = [0]\n\n    metrics = np.fromiter(_calc_block_metrics(pool, samples, sample_count), dtype='<f4').reshape((\n        -1,  # number of block\n        3,  # peak, rms, sum_sqr\n        channel_count\n    ))\n    block_count = metrics.shape[0]\n    sample_count = sample_count[0]\n\n    peaks = metrics[:, 0, :]\n    rms = metrics[:, 1, :]\n    sum_of_squares_all = metrics[:, 2, :]\n\n    peak_index = block_count - 2\n    rms_percentile = 0.2\n\n    total_second_peak = np.partition(peaks, peak_index, axis=0)[peak_index, :]\n\n    rms_count = max(1, int(floor(block_count * rms_percentile)))\n\n    rms_start = block_count - rms_count\n    rms_range = range(rms_start, block_count)\n    rms = np.partition(rms, rms_start, axis=0)[rms_range, :]\n    rms **= 2\n    rms_sqr_sum = np.sum(rms, axis=0)\n    dr_per_channel = -decibel(np.sqrt(rms_sqr_sum / rms_count) / total_second_peak)\n\n    dr = float(np.mean(dr_per_channel, axis=0))\n    if 0 < dr < 40:\n        if not keep_precision:\n            dr = int(round(dr))\n    else:\n        dr = None\n\n    peak_db = float(decibel(np.max(peaks)))\n\n    sum_of_squares_all = np.sum(sum_of_squares_all, axis=0)\n    rms_all = np.sqrt(2.0 * sum_of_squares_all / float(sample_count))\n    rms_all = np.mean(rms_all)\n    rms_db = float(decibel(rms_all))\n\n    return DynamicRangeMetrics(dr, peak_db, rms_db, sample_count)\n"""
util/__init__.py,0,b''
util/constants.py,0,b'MEASURE_SAMPLE_RATE = 44100\n'
util/natural_sort.py,0,"b""import re\n\n_num_pattern = re.compile('([0-9]+)')\n\n\ndef natural_sort_key(s):\n    return [int(text) if text.isdigit() else text\n            for text in re.split(_num_pattern, s)]\n"""
audio_io/cue/__init__.py,0,b''
audio_io/cue/cue_parser.py,0,"b'import re\nfrom enum import Enum, auto\nfrom fractions import Fraction\nfrom io import BufferedIOBase\nfrom numbers import Number\nfrom typing import Iterable\n\nimport chardet\n\n\nclass CueCmd(Enum):\n    PERFORMER = auto()\n    TITLE = auto()\n    FILE = auto()\n    TRACK = auto()\n    INDEX = auto()\n    REM = auto()\n    EOF = auto()\n\n\ndef _unquote(s: str):\n    return s[1 + s.index(\'""\'):s.rindex(\'""\')]\n\n\n_whitespace_pattern = re.compile(r\'\\s+\')\n_rem_tag_pattern = re.compile(r\'([A-Z_]+) (.+)\')\n\n\ndef parse_cd_time(offset: str) -> Number:\n    """"""parse time in CD-DA (75fps) format to seconds, exactly\n    MM:SS:FF""""""\n    m, s, f = map(int, offset.split(\':\'))\n    return m * 60 + s + Fraction(f, 75)\n\n\ndef _parse_cue_cmd(line: str, offset_in_seconds: bool = True):\n    line = line.strip()\n    cmd, args = _whitespace_pattern.split(line, 1)\n    if cmd == \'PERFORMER\':\n        return CueCmd.PERFORMER, _unquote(args)\n    if cmd == \'TITLE\':\n        return CueCmd.TITLE, _unquote(args)\n    if cmd == \'FILE\':\n        return CueCmd.FILE, _unquote(args)\n    if cmd == \'TRACK\':\n        number, _ = _whitespace_pattern.split(args, 1)\n        number = int(number)\n        return CueCmd.TRACK, number\n    if cmd == \'INDEX\':\n        number, offset = _whitespace_pattern.split(args, 1)\n        number = int(number)\n        if offset_in_seconds:\n            offset = parse_cd_time(offset)\n        return CueCmd.INDEX, number, offset\n    if cmd == \'REM\':\n        tag_name, tag_value = _rem_tag_pattern.fullmatch(args).groups()\n        return CueCmd.REM, tag_name, tag_value\n\n    return None\n\n\ndef read_cue_from_file(in_path: str) -> str:\n    with open(in_path, \'rb\') as f:\n        assert isinstance(f, BufferedIOBase)\n        content = f.read()\n    encoding = chardet.detect(content)[\'encoding\']\n    return content.decode(encoding)\n\n\ndef parse_cue_str(content: str, offset_in_seconds: bool = True) -> Iterable[tuple]:\n    for line in content.splitlines():\n        cmd = _parse_cue_cmd(line, offset_in_seconds)\n        if cmd:\n            yield cmd\n    yield CueCmd.EOF, None\n'"
