file_path,api_count,code
setup.py,0,"b'import os\n\nfrom setuptools import setup, find_packages\n\nfrom nrrd._version import __version__\n\ncurrentPath = os.path.abspath(os.path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(os.path.join(currentPath, \'README.rst\'), \'r\') as fh:\n    longDescription = fh.read()\n\nlongDescription = \'\\n\' + longDescription\n\nsetup(name=\'pynrrd\',\n      version=__version__,\n      description=\'Pure python module for reading and writing NRRD files.\',\n      long_description=longDescription,\n      long_description_content_type=\'text/x-rst\',\n      author=\'Maarten Everts\',\n      author_email=\'me@nn8.nl\',\n      url=\'https://github.com/mhe/pynrrd\',\n      license=\'MIT License\',\n      install_requires=[\'numpy>=1.11.1\'],\n      packages=find_packages(exclude=[\'*.tests\', \'*.tests.*\', \'tests.*\', \'tests\']),\n      keywords=\'nrrd teem image processing file format\',\n      classifiers=[\n          \'License :: OSI Approved :: MIT License\',\n          \'Topic :: Scientific/Engineering\',\n          \'Programming Language :: Python\',\n          ""Programming Language :: Python :: 2.7"",\n          \'Programming Language :: Python :: 3\',\n          ""Programming Language :: Python :: 3.4"",\n          ""Programming Language :: Python :: 3.5"",\n          ""Programming Language :: Python :: 3.6""\n      ],\n      project_urls={\n          \'Tracker\': \'https://github.com/mhe/pynrrd/issues\',\n      }\n      )\n'"
nrrd/__init__.py,0,"b""from nrrd._version import __version__\nfrom nrrd.formatters import *\nfrom nrrd.parsers import *\nfrom nrrd.reader import read, read_data, read_header\nfrom nrrd.writer import write\n\n__all__ = ['read', 'read_data', 'read_header', 'write', 'format_number_list', 'format_number', 'format_matrix',\n           'format_optional_matrix', 'format_optional_vector', 'format_vector', 'parse_matrix',\n           'parse_number_auto_dtype', 'parse_number_list', 'parse_optional_matrix', 'parse_optional_vector',\n           'parse_vector', '__version__']\n"""
nrrd/_version.py,0,"b""__version__ = '0.4.2'\n"""
nrrd/errors.py,0,"b'class NRRDError(Exception):\n    """"""Exceptions for NRRD class.""""""\n    pass\n'"
nrrd/formatters.py,1,"b'import numpy as np\n\n\ndef format_number(x):\n    """"""Format number to string\n\n    Function converts a number to string. For numbers of class :class:`float`, up to 17 digits will be used to print\n    the entire floating point number. Any padding zeros will be removed at the end of the number.\n\n    See :ref:`user-guide:int` and :ref:`user-guide:double` for more information on the format.\n\n    .. note::\n            IEEE754-1985 standard says that 17 significant decimal digits are required to adequately represent a\n            64-bit floating point number. Not all fractional numbers can be exactly represented in floating point. An\n            example is 0.1 which will be approximated as 0.10000000000000001.\n\n    Parameters\n    ----------\n    x : :class:`int` or :class:`float`\n        Number to convert to string\n\n    Returns\n    -------\n    vector : :class:`str`\n        String of number :obj:`x`\n    """"""\n\n    if isinstance(x, float):\n        # Helps prevent loss of precision as using str() in Python 2 only prints 12 digits of precision.\n        # However, IEEE754-1985 standard says that 17 significant decimal digits is required to adequately represent a\n        # floating point number.\n        # The g option is used rather than f because g precision uses significant digits while f is just the number of\n        # digits after the decimal. (NRRD C implementation uses g).\n        value = \'{:.17g}\'.format(x)\n    else:\n        value = str(x)\n\n    return value\n\n\ndef format_vector(x):\n    """"""Format a (N,) :class:`numpy.ndarray` into a NRRD vector string\n\n    See :ref:`user-guide:int vector` and :ref:`user-guide:double vector` for more information on the format.\n\n    Parameters\n    ----------\n    x : (N,) :class:`numpy.ndarray`\n        Vector to convert to NRRD vector string\n\n    Returns\n    -------\n    vector : :class:`str`\n        String containing NRRD vector\n    """"""\n\n    return \'(\' + \',\'.join([format_number(y) for y in x]) + \')\'\n\n\ndef format_optional_vector(x):\n    """"""Format a (N,) :class:`numpy.ndarray` into a NRRD optional vector string\n\n    Function converts a (N,) :class:`numpy.ndarray` or :obj:`None` into a string using NRRD vector format. If the input\n    :obj:`x` is :obj:`None`, then :obj:`vector` will be \'none\'\n\n    See :ref:`user-guide:int vector` and :ref:`user-guide:double vector` for more information on the format.\n\n    Parameters\n    ----------\n    x : (N,) :class:`numpy.ndarray` or :obj:`None`\n        Vector to convert to NRRD vector string\n\n    Returns\n    -------\n    vector : :class:`str`\n        String containing NRRD vector\n    """"""\n\n    # If vector is None or all elements are NaN, then return none\n    # Otherwise format the vector as normal\n    if x is None or np.all(np.isnan(x)):\n        return \'none\'\n    else:\n        return format_vector(x)\n\n\ndef format_matrix(x):\n    """"""Format a (M,N) :class:`numpy.ndarray` into a NRRD matrix string\n\n    See :ref:`user-guide:int matrix` and :ref:`user-guide:double matrix` for more information on the format.\n\n    Parameters\n    ----------\n    x : (M,N) :class:`numpy.ndarray`\n        Matrix to convert to NRRD vector string\n\n    Returns\n    -------\n    matrix : :class:`str`\n        String containing NRRD matrix\n    """"""\n\n    return \' \'.join([format_vector(y) for y in x])\n\n\ndef format_optional_matrix(x):\n    """"""Format a (M,N) :class:`numpy.ndarray` of :class:`float` into a NRRD optional matrix string\n\n    Function converts a (M,N) :class:`numpy.ndarray` of :class:`float` into a string using the NRRD matrix format. For\n    any rows of the matrix that contain all NaNs for each element, the row will be replaced with a \'none\' indicating\n    the row has no vector.\n\n    See :ref:`user-guide:double matrix` for more information on the format.\n\n    .. note::\n            :obj:`x` must have a datatype of float because NaN\'s are only defined for floating point numbers.\n\n    Parameters\n    ----------\n    x : (M,N) :class:`numpy.ndarray` of :class:`float`\n        Matrix to convert to NRRD vector string\n\n    Returns\n    -------\n    matrix : :class:`str`\n        String containing NRRD matrix\n    """"""\n\n    return \' \'.join([format_optional_vector(y) for y in x])\n\n\ndef format_number_list(x):\n    """"""Format a (N,) :class:`numpy.ndarray` into a NRRD number list.\n\n    See :ref:`user-guide:int list` and :ref:`user-guide:double list` for more information on the format.\n\n    Parameters\n    ----------\n    x : (N,) :class:`numpy.ndarray`\n        Vector to convert to NRRD number list string\n\n    Returns\n    -------\n    list : :class:`str`\n        String containing NRRD list\n    """"""\n\n    return \' \'.join([format_number(y) for y in x])\n'"
nrrd/parsers.py,11,"b'import numpy as np\n\nfrom nrrd.errors import NRRDError\n\n\ndef parse_vector(x, dtype=None):\n    """"""Parse NRRD vector from string into (N,) :class:`numpy.ndarray`.\n\n    See :ref:`user-guide:int vector` and :ref:`user-guide:double vector` for more information on the format.\n\n    Parameters\n    ----------\n    x : :class:`str`\n        String containing NRRD vector\n    dtype : data-type, optional\n        Datatype to use for the resulting Numpy array. Datatype can be :class:`float`, :class:`int` or :obj:`None`. If\n        :obj:`dtype` is :obj:`None`, then it will be automatically determined by checking any of the vector elements\n        for fractional numbers. If found, then the vector will be converted to :class:`float`, otherwise :class:`int`.\n        Default is to automatically determine datatype.\n\n    Returns\n    -------\n    vector : (N,) :class:`numpy.ndarray`\n        Vector that is parsed from the :obj:`x` string\n    """"""\n\n    if x[0] != \'(\' or x[-1] != \')\':\n        raise NRRDError(\'Vector should be enclosed by parentheses.\')\n\n    # Always convert to float and then truncate to integer if desired\n    # The reason why is parsing a floating point string to int will fail (i.e. int(\'25.1\') will fail)\n    vector = np.array([float(x) for x in x[1:-1].split(\',\')])\n\n    # If using automatic datatype detection, then start by converting to float and determining if the number is whole\n    # Truncate to integer if dtype is int also\n    if dtype is None:\n        vector_trunc = vector.astype(int)\n\n        if np.all((vector - vector_trunc) == 0):\n            vector = vector_trunc\n    elif dtype == int:\n        vector = vector.astype(int)\n    elif dtype != float:\n        raise NRRDError(\'dtype should be None for automatic type detection, float or int\')\n\n    return vector\n\n\ndef parse_optional_vector(x, dtype=None):\n    """"""Parse optional NRRD vector from string into (N,) :class:`numpy.ndarray` or :obj:`None`.\n\n    Function parses optional NRRD vector from string into an (N,) :class:`numpy.ndarray`. This function works the same\n    as :meth:`parse_vector` except if :obj:`x` is \'none\', :obj:`vector` will be :obj:`None`\n\n    See :ref:`user-guide:int vector` and :ref:`user-guide:double vector` for more information on the format.\n\n    Parameters\n    ----------\n    x : :class:`str`\n        String containing NRRD vector or \'none\'\n    dtype : data-type, optional\n        Datatype to use for the resulting Numpy array. Datatype can be :class:`float`, :class:`int` or :obj:`None`. If\n        :obj:`dtype` is :obj:`None`, then it will be automatically determined by checking any of the vector elements\n        for fractional numbers. If found, then the vector will be converted to :class:`float`, otherwise :class:`int`.\n        Default is to automatically determine datatype.\n\n    Returns\n    -------\n    vector : (N,) :class:`numpy.ndarray` or :obj:`None`\n        Vector that is parsed from the :obj:`x` string or :obj:`None` if :obj:`x` is \'none\'\n    """"""\n\n    if x == \'none\':\n        return None\n    else:\n        return parse_vector(x, dtype)\n\n\ndef parse_matrix(x, dtype=None):\n    """"""Parse NRRD matrix from string into (M,N) :class:`numpy.ndarray`.\n\n    See :ref:`user-guide:int matrix` and :ref:`user-guide:double matrix` for more information on the format.\n\n    Parameters\n    ----------\n    x : :class:`str`\n        String containing NRRD matrix\n    dtype : data-type, optional\n        Datatype to use for the resulting Numpy array. Datatype can be :class:`float`, :class:`int` or :obj:`None`. If\n        :obj:`dtype` is :obj:`None`, then it will be automatically determined by checking any of the elements\n        for fractional numbers. If found, then the matrix will be converted to :class:`float`, otherwise :class:`int`.\n        Default is to automatically determine datatype.\n\n    Returns\n    -------\n    matrix : (M,N) :class:`numpy.ndarray`\n        Matrix that is parsed from the :obj:`x` string\n    """"""\n\n    # Split input by spaces, convert each row into a vector and stack them vertically to get a matrix\n    matrix = [parse_vector(x, dtype=float) for x in x.split()]\n\n    # Get the size of each row vector and then remove duplicate sizes\n    # There should be exactly one value in the matrix because all row sizes need to be the same\n    if len(np.unique([len(x) for x in matrix])) != 1:\n        raise NRRDError(\'Matrix should have same number of elements in each row\')\n\n    matrix = np.vstack(matrix)\n\n    # If using automatic datatype detection, then start by converting to float and determining if the number is whole\n    # Truncate to integer if dtype is int also\n    if dtype is None:\n        matrix_trunc = matrix.astype(int)\n\n        if np.all((matrix - matrix_trunc) == 0):\n            matrix = matrix_trunc\n    elif dtype == int:\n        matrix = matrix.astype(int)\n    elif dtype != float:\n        raise NRRDError(\'dtype should be None for automatic type detection, float or int\')\n\n    return matrix\n\n\ndef parse_optional_matrix(x):\n    """"""Parse optional NRRD matrix from string into (M,N) :class:`numpy.ndarray` of :class:`float`.\n\n    Function parses optional NRRD matrix from string into an (M,N) :class:`numpy.ndarray` of :class:`float`. This\n    function works the same as :meth:`parse_matrix` except if a row vector in the matrix is none, the resulting row in\n    the returned matrix will be all NaNs.\n\n    See :ref:`user-guide:double matrix` for more information on the format.\n\n    Parameters\n    ----------\n    x : :class:`str`\n        String containing NRRD matrix\n\n    Returns\n    -------\n    matrix : (M,N) :class:`numpy.ndarray` of :class:`float`\n        Matrix that is parsed from the :obj:`x` string\n    """"""\n\n    # Split input by spaces to get each row and convert into a vector. The row can be \'none\', in which case it will\n    # return None\n    matrix = [parse_optional_vector(x, dtype=float) for x in x.split()]\n\n    # Get the size of each row vector, 0 if None\n    sizes = np.array([0 if x is None else len(x) for x in matrix])\n\n    # Get sizes of each row vector removing duplicate sizes\n    # Since each row vector should be same size, the unique sizes should return one value for the row size or it may\n    # return a second one (0) if there are None vectors\n    unique_sizes = np.unique(sizes)\n\n    if len(unique_sizes) != 1 and (len(unique_sizes) != 2 or unique_sizes.min() != 0):\n        raise NRRDError(\'Matrix should have same number of elements in each row\')\n\n    # Create a vector row of NaN\'s that matches same size of remaining vector rows\n    # Stack the vector rows together to create matrix\n    nan_row = np.full((unique_sizes.max()), np.nan)\n    matrix = np.vstack([nan_row if x is None else x for x in matrix])\n\n    return matrix\n\n\ndef parse_number_list(x, dtype=None):\n    """"""Parse NRRD number list from string into (N,) :class:`numpy.ndarray`.\n\n    See :ref:`user-guide:int list` and :ref:`user-guide:double list` for more information on the format.\n\n    Parameters\n    ----------\n    x : :class:`str`\n        String containing NRRD number list\n    dtype : data-type, optional\n        Datatype to use for the resulting Numpy array. Datatype can be :class:`float`, :class:`int` or :obj:`None`. If\n        :obj:`dtype` is :obj:`None`, then it will be automatically determined by checking for fractional numbers. If\n        found, then the string will be converted to :class:`float`, otherwise :class:`int`. Default is to automatically\n        determine datatype.\n\n    Returns\n    -------\n    vector : (N,) :class:`numpy.ndarray`\n        Vector that is parsed from the :obj:`x` string\n    """"""\n\n    # Always convert to float and then perform truncation to integer if necessary\n    number_list = np.array([float(x) for x in x.split()])\n\n    if dtype is None:\n        number_list_trunc = number_list.astype(int)\n\n        # If there is no difference between the truncated number list and the number list, then that means that the\n        # number list was all integers and we can just return that\n        if np.all((number_list - number_list_trunc) == 0):\n            number_list = number_list_trunc\n    elif dtype == int:\n        number_list = number_list.astype(int)\n    elif dtype != float:\n        raise NRRDError(\'dtype should be None for automatic type detection, float or int\')\n\n    return number_list\n\n\ndef parse_number_auto_dtype(x):\n    """"""Parse number from string with automatic type detection.\n\n    Parses input string and converts to a number using automatic type detection. If the number contains any\n    fractional parts, then the number will be converted to float, otherwise the number will be converted to an int.\n\n    See :ref:`user-guide:int` and :ref:`user-guide:double` for more information on the format.\n\n    Parameters\n    ----------\n    x : :class:`str`\n        String representation of number\n\n    Returns\n    -------\n    result : :class:`int` or :class:`float`\n        Number parsed from :obj:`x` string\n    """"""\n\n    value = float(x)\n\n    if value.is_integer():\n        value = int(value)\n\n    return value\n'"
nrrd/reader.py,7,"b'# encoding: utf-8\nimport bz2\nimport os\nimport re\nimport shlex\nimport warnings\nimport zlib\nfrom collections import OrderedDict\n\nfrom nrrd.parsers import *\n\n# Older versions of Python had issues when uncompressed data was larger than 4GB (2^32). This should be fixed in latest\n# version of Python 2.7 and all versions of Python 3. The fix for this issue is to read the data in smaller chunks.\n# Chunk size is set to be large at 1GB to improve performance. If issues arise decompressing larger files, try to reduce\n# this value\n_READ_CHUNKSIZE = 2 ** 32\n\n_NRRD_REQUIRED_FIELDS = [\'dimension\', \'type\', \'encoding\', \'sizes\']\n\nALLOW_DUPLICATE_FIELD = False\n""""""Allow duplicate header fields when reading NRRD files\n\nWhen there are duplicated fields in a NRRD file header, pynrrd throws an error by default. Setting this field as\n:obj:`True` will instead show a warning.\n\nExample:\n    Reading a NRRD file with duplicated header field \'space\' with field set to :obj:`False`.\n\n    >>> filedata, fileheader = nrrd.read(\'filename_duplicatedheader.nrrd\')\n    nrrd.errors.NRRDError: Duplicate header field: \'space\'\n\n    Set the field as :obj:`True` to receive a warning instead.\n\n    >>> nrrd.reader.ALLOW_DUPLICATE_FIELD = True\n    >>> filedata, fileheader = nrrd.read(\'filename_duplicatedheader.nrrd\')\n    UserWarning: Duplicate header field: \'space\' warnings.warn(dup_message)\n\nNote:\n    Duplicated fields are prohibited by the NRRD file specification.\n""""""\n\n_TYPEMAP_NRRD2NUMPY = {\n    \'signed char\': \'i1\',\n    \'int8\': \'i1\',\n    \'int8_t\': \'i1\',\n    \'uchar\': \'u1\',\n    \'unsigned char\': \'u1\',\n    \'uint8\': \'u1\',\n    \'uint8_t\': \'u1\',\n    \'short\': \'i2\',\n    \'short int\': \'i2\',\n    \'signed short\': \'i2\',\n    \'signed short int\': \'i2\',\n    \'int16\': \'i2\',\n    \'int16_t\': \'i2\',\n    \'ushort\': \'u2\',\n    \'unsigned short\': \'u2\',\n    \'unsigned short int\': \'u2\',\n    \'uint16\': \'u2\',\n    \'uint16_t\': \'u2\',\n    \'int\': \'i4\',\n    \'signed int\': \'i4\',\n    \'int32\': \'i4\',\n    \'int32_t\': \'i4\',\n    \'uint\': \'u4\',\n    \'unsigned int\': \'u4\',\n    \'uint32\': \'u4\',\n    \'uint32_t\': \'u4\',\n    \'longlong\': \'i8\',\n    \'long long\': \'i8\',\n    \'long long int\': \'i8\',\n    \'signed long long\': \'i8\',\n    \'signed long long int\': \'i8\',\n    \'int64\': \'i8\',\n    \'int64_t\': \'i8\',\n    \'ulonglong\': \'u8\',\n    \'unsigned long long\': \'u8\',\n    \'unsigned long long int\': \'u8\',\n    \'uint64\': \'u8\',\n    \'uint64_t\': \'u8\',\n    \'float\': \'f4\',\n    \'double\': \'f8\',\n    \'block\': \'V\'\n}\n\n\ndef _get_field_type(field, custom_field_map):\n    if field in [\'dimension\', \'lineskip\', \'line skip\', \'byteskip\', \'byte skip\', \'space dimension\']:\n        return \'int\'\n    elif field in [\'min\', \'max\', \'oldmin\', \'old min\', \'oldmax\', \'old max\']:\n        return \'double\'\n    elif field in [\'endian\', \'encoding\', \'content\', \'sample units\', \'datafile\', \'data file\', \'space\', \'type\']:\n        return \'string\'\n    elif field in [\'sizes\']:\n        return \'int list\'\n    elif field in [\'spacings\', \'thicknesses\', \'axismins\', \'axis mins\', \'axismaxs\', \'axis maxs\']:\n        return \'double list\'\n    elif field in [\'kinds\', \'centerings\']:\n        return \'string list\'\n    elif field in [\'labels\', \'units\', \'space units\']:\n        return \'quoted string list\'\n    # No int vector fields as of now\n    # elif field in []:\n    #     return \'int vector\'\n    elif field in [\'space origin\']:\n        return \'double vector\'\n    elif field in [\'measurement frame\']:\n        return \'double matrix\'\n    elif field in [\'space directions\']:\n        return \'double matrix\'\n    else:\n        if custom_field_map and field in custom_field_map:\n            return custom_field_map[field]\n\n        # Default the type to string if unknown type\n        return \'string\'\n\n\ndef _parse_field_value(value, field_type):\n    if field_type == \'int\':\n        return int(value)\n    elif field_type == \'double\':\n        return float(value)\n    elif field_type == \'string\':\n        return str(value)\n    elif field_type == \'int list\':\n        return parse_number_list(value, dtype=int)\n    elif field_type == \'double list\':\n        return parse_number_list(value, dtype=float)\n    elif field_type == \'string list\':\n        return [str(x) for x in value.split()]\n    elif field_type == \'quoted string list\':\n        return shlex.split(value)\n    elif field_type == \'int vector\':\n        return parse_vector(value, dtype=int)\n    elif field_type == \'double vector\':\n        return parse_vector(value, dtype=float)\n    elif field_type == \'int matrix\':\n        return parse_matrix(value, dtype=int)\n    elif field_type == \'double matrix\':\n        # For matrices of double type, parse as an optional matrix to allow for rows of the matrix to be none\n        # This is only valid for double matrices because the matrix is represented with NaN in the entire row\n        # for none rows. NaN is only valid for floating point numbers\n        return parse_optional_matrix(value)\n    else:\n        raise NRRDError(\'Invalid field type given: %s\' % field_type)\n\n\ndef _determine_datatype(fields):\n    """"""Determine the numpy dtype of the data.""""""\n\n    # Convert the NRRD type string identifier into a NumPy string identifier using a map\n    np_typestring = _TYPEMAP_NRRD2NUMPY[fields[\'type\']]\n\n    # This is only added if the datatype has more than one byte and is not using ASCII encoding\n    # Note: Endian is not required for ASCII encoding\n    if np.dtype(np_typestring).itemsize > 1 and fields[\'encoding\'] not in [\'ASCII\', \'ascii\', \'text\', \'txt\']:\n        if \'endian\' not in fields:\n            raise NRRDError(\'Header is missing required field: ""endian"".\')\n        elif fields[\'endian\'] == \'big\':\n            np_typestring = \'>\' + np_typestring\n        elif fields[\'endian\'] == \'little\':\n            np_typestring = \'<\' + np_typestring\n        else:\n            raise NRRDError(\'Invalid endian value in header: ""%s""\' % fields[\'endian\'])\n\n    return np.dtype(np_typestring)\n\n\ndef _validate_magic_line(line):\n    """"""For NRRD files, the first four characters are always ""NRRD"", and\n    remaining characters give information about the file format version\n\n    >>> _validate_magic_line(\'NRRD0005\')\n    8\n    >>> _validate_magic_line(\'NRRD0006\')\n    Traceback (most recent call last):\n        ...\n    NrrdError: NRRD file version too new for this library.\n    >>> _validate_magic_line(\'NRRD\')\n    Traceback (most recent call last):\n        ...\n    NrrdError: Invalid NRRD magic line: NRRD\n    """"""\n\n    if not line.startswith(\'NRRD\'):\n        raise NRRDError(\'Invalid NRRD magic line. Is this an NRRD file?\')\n\n    try:\n        version = int(line[4:])\n        if version > 5:\n            raise NRRDError(\'Unsupported NRRD file version (version: %i). This library only supports v%i and below.\'\n                            % (version, 5))\n    except ValueError:\n        raise NRRDError(\'Invalid NRRD magic line: %s\' % line)\n\n    return len(line)\n\n\ndef read_header(file, custom_field_map=None):\n    """"""Read contents of header and parse values from :obj:`file`\n\n    :obj:`file` can be a filename indicating where the NRRD header is located or a string iterator object. If a\n    filename is specified, then the file will be opened and closed after the header is read from it. If not specifying\n    a filename, the :obj:`file` parameter can be any sort of iterator that returns a string each time :meth:`next` is\n    called. The two common objects that meet these requirements are file objects and a list of strings. When\n    :obj:`file` is a file object, it must be opened with the binary flag (\'b\') on platforms where that makes a\n    difference, such as Windows.\n\n    See :ref:`user-guide:Reading NRRD files` for more information on reading NRRD files.\n\n    Parameters\n    ----------\n    file : :class:`str` or string iterator\n        Filename, file object or string iterator object to read NRRD header from\n    custom_field_map : :class:`dict` (:class:`str`, :class:`str`), optional\n        Dictionary used for parsing custom field types where the key is the custom field name and the value is a\n        string identifying datatype for the custom field.\n\n    Returns\n    -------\n    header : :class:`dict` (:class:`str`, :obj:`Object`)\n        Dictionary containing the header fields and their corresponding parsed value\n\n    See Also\n    --------\n    :meth:`read`, :meth:`read_data`\n    """"""\n\n    # If the file is a filename rather than the file handle, then open the file and call this function again with the\n    # file handle. Since read function uses a filename, it is easy to think read_header is the same syntax.\n    if isinstance(file, str) and file.count(\'\\n\') == 0:\n        with open(file, \'rb\') as fh:\n            header = read_header(fh, custom_field_map)\n            return header\n\n    # Collect number of bytes in the file header (for seeking below)\n    header_size = 0\n\n    # Get iterator for the file and extract the first line, the magic line\n    it = iter(file)\n    magic_line = next(it)\n\n    # Depending on what type file is, decoding may or may not be necessary. Decode if necessary, otherwise skip.\n    need_decode = False\n    if hasattr(magic_line, \'decode\'):\n        need_decode = True\n        magic_line = magic_line.decode(\'ascii\', \'ignore\')\n\n    # Validate the magic line and increment header size by size of the line\n    header_size += _validate_magic_line(magic_line)\n\n    # Create empty header\n    # This is an OrderedDict rather than an ordinary dict because an OrderedDict will keep it\'s order that key/values\n    # are added for when looping back through it. The added benefit of this is that saving the header will save the\n    # fields in the same order.\n    header = OrderedDict()\n\n    # Loop through each line\n    for line in it:\n        header_size += len(line)\n        if need_decode:\n            line = line.decode(\'ascii\', \'ignore\')\n\n        # Trailing whitespace ignored per the NRRD spec\n        line = line.rstrip()\n\n        # Skip comments starting with # (no leading whitespace is allowed)\n        # Or, stop reading the header once a blank line is encountered. This separates header from data.\n        if line.startswith(\'#\'):\n            continue\n        elif line == \'\':\n            break\n\n        # Read the field and value from the line, split using regex to search for := or : delimiter\n        field, value = re.split(r\':=?\', line, 1)\n\n        # Remove whitespace before and after the field and value\n        field, value = field.strip(), value.strip()\n\n        # Check if the field has been added already\n        if field in header.keys():\n            dup_message = ""Duplicate header field: \'%s\'"" % str(field)\n\n            if not ALLOW_DUPLICATE_FIELD:\n                raise NRRDError(dup_message)\n\n            warnings.warn(dup_message)\n\n        # Get the datatype of the field based on it\'s field name and custom field map\n        field_type = _get_field_type(field, custom_field_map)\n\n        # Parse the field value using the datatype retrieved\n        # Place it in the header dictionary\n        header[field] = _parse_field_value(value, field_type)\n\n    # Reading the file line by line is buffered and so the header is not in the correct position for reading data if\n    # the file contains the data in it as well. The solution is to set the file pointer to just behind the header.\n    if hasattr(file, \'seek\'):\n        file.seek(header_size)\n\n    return header\n\n\ndef read_data(header, fh=None, filename=None, index_order=\'F\'):\n    """"""Read data from file into :class:`numpy.ndarray`\n\n    The two parameters :obj:`fh` and :obj:`filename` are optional depending on the parameters but it never hurts to\n    specify both. The file handle (:obj:`fh`) is necessary if the header is attached with the NRRD data. However, if\n    the NRRD data is detached from the header, then the :obj:`filename` parameter is required to obtain the absolute\n    path to the data file.\n\n    See :ref:`user-guide:Reading NRRD files` for more information on reading NRRD files.\n\n    Parameters\n    ----------\n    header : :class:`dict` (:class:`str`, :obj:`Object`)\n        Parsed fields/values obtained from :meth:`read_header` function\n    fh : file-object, optional\n        File object pointing to first byte of data. Only necessary if data is attached to header.\n    filename : :class:`str`, optional\n        Filename of the header file. Only necessary if data is detached from the header. This is used to get the\n        absolute data path.\n    index_order : {\'C\', \'F\'}, optional\n        Specifies the index order of the resulting data array. Either \'C\' (C-order) where the dimensions are ordered from\n        slowest-varying to fastest-varying (e.g. (z, y, x)), or \'F\' (Fortran-order) where the dimensions are ordered\n        from fastest-varying to slowest-varying (e.g. (x, y, z)).\n\n    Returns\n    -------\n    data : :class:`numpy.ndarray`\n        Data read from NRRD file\n\n    See Also\n    --------\n    :meth:`read`, :meth:`read_header`\n    """"""\n\n    if index_order not in [\'F\', \'C\']:\n        raise NRRDError(\'Invalid index order\')\n\n    # Check that the required fields are in the header\n    for field in _NRRD_REQUIRED_FIELDS:\n        if field not in header:\n            raise NRRDError(\'Header is missing required field: ""%s"".\' % field)\n\n    if header[\'dimension\'] != len(header[\'sizes\']):\n        raise NRRDError(\'Number of elements in sizes does not match dimension. Dimension: %i, len(sizes): %i\' % (\n            header[\'dimension\'], len(header[\'sizes\'])))\n\n    # Determine the data type from the header\n    dtype = _determine_datatype(header)\n\n    # Determine the byte skip, line skip and the data file\n    # These all can be written with or without the space according to the NRRD spec, so we check them both\n    line_skip = header.get(\'lineskip\', header.get(\'line skip\', 0))\n    byte_skip = header.get(\'byteskip\', header.get(\'byte skip\', 0))\n    data_filename = header.get(\'datafile\', header.get(\'data file\', None))\n\n    # If the data file is separate from the header file, then open the data file to read from that instead\n    if data_filename is not None:\n        # If the pathname is relative, then append the current directory from the filename\n        if not os.path.isabs(data_filename):\n            if filename is None:\n                raise NRRDError(\'Filename parameter must be specified when a relative data file path is given\')\n\n            data_filename = os.path.join(os.path.dirname(filename), data_filename)\n\n        # Override the fh parameter with the data filename\n        # Note that this is opened without a ""with"" block, thus it must be closed manually in all circumstances\n        fh = open(data_filename, \'rb\')\n\n    # Get the total number of data points by multiplying the size of each dimension together\n    total_data_points = header[\'sizes\'].prod(dtype=np.int64)\n\n    # Skip the number of lines requested when line_skip >= 0\n    # Irrespective of the NRRD file having attached/detached header\n    # Lines are skipped before getting to the beginning of the data\n    if line_skip >= 0:\n        for _ in range(line_skip):\n            fh.readline()\n    else:\n        # Must close the file because if the file was opened above from detached filename, there is no ""with"" block to\n        # close it for us\n        fh.close()\n\n        raise NRRDError(\'Invalid lineskip, allowed values are greater than or equal to 0\')\n\n    # Skip the requested number of bytes or seek backward, and then parse the data using NumPy\n    if byte_skip < -1:\n        # Must close the file because if the file was opened above from detached filename, there is no ""with"" block to\n        # close it for us\n        fh.close()\n\n        raise NRRDError(\'Invalid byteskip, allowed values are greater than or equal to -1\')\n    elif byte_skip >= 0:\n        fh.seek(byte_skip, os.SEEK_CUR)\n    elif byte_skip == -1 and header[\'encoding\'] not in [\'gzip\', \'gz\', \'bzip2\', \'bz2\']:\n        fh.seek(-dtype.itemsize * total_data_points, os.SEEK_END)\n    else:\n        # The only case left should be: byte_skip == -1 and header[\'encoding\'] == \'gzip\'\n        byte_skip = -dtype.itemsize * total_data_points\n\n    # If a compression encoding is used, then byte skip AFTER decompressing\n    if header[\'encoding\'] == \'raw\':\n        data = np.fromfile(fh, dtype)\n    elif header[\'encoding\'] in [\'ASCII\', \'ascii\', \'text\', \'txt\']:\n        data = np.fromfile(fh, dtype, sep=\' \')\n    else:\n        # Handle compressed data now\n        # Construct the decompression object based on encoding\n        if header[\'encoding\'] in [\'gzip\', \'gz\']:\n            decompobj = zlib.decompressobj(zlib.MAX_WBITS | 16)\n        elif header[\'encoding\'] in [\'bzip2\', \'bz2\']:\n            decompobj = bz2.BZ2Decompressor()\n        else:\n            # Must close the file because if the file was opened above from detached filename, there is no ""with"" block\n            # to close it for us\n            fh.close()\n\n            raise NRRDError(\'Unsupported encoding: ""%s""\' % header[\'encoding\'])\n\n        # Loop through the file and read a chunk at a time (see _READ_CHUNKSIZE why it is read in chunks)\n        decompressed_data = bytearray()\n\n        # Read all of the remaining data from the file\n        # Obtain the length of the compressed data since we will be using it repeatedly, more efficient\n        compressed_data = fh.read()\n        compressed_data_len = len(compressed_data)\n        start_index = 0\n\n        # Loop through data and decompress it chunk by chunk\n        while start_index < compressed_data_len:\n            # Calculate the end index = start index plus chunk size\n            # Set to the string length to read the remaining chunk at the end\n            end_index = min(start_index + _READ_CHUNKSIZE, compressed_data_len)\n\n            # Decompress and append data\n            decompressed_data += decompobj.decompress(compressed_data[start_index:end_index])\n\n            # Update start index\n            start_index = end_index\n\n        # Delete the compressed data since we do not need it anymore\n        # This could potentially be using a lot of memory\n        del compressed_data\n\n        # Byte skip is applied AFTER the decompression. Skip first x bytes of the decompressed data and parse it using\n        # NumPy\n        data = np.frombuffer(decompressed_data[byte_skip:], dtype)\n\n    # Close the file, even if opened using ""with"" block, closing it manually does not hurt\n    fh.close()\n\n    if total_data_points != data.size:\n        raise NRRDError(\'Size of the data does not equal the product of all the dimensions: {0}-{1}={2}\'\n                        .format(total_data_points, data.size, total_data_points - data.size))\n\n    # In the NRRD header, the fields are specified in Fortran order, i.e, the first index is the one that changes\n    # fastest and last index changes slowest. This needs to be taken into consideration since numpy uses C-order\n    # indexing.\n\n    # The array shape from NRRD (x,y,z) needs to be reversed as numpy expects (z,y,x).\n    data = np.reshape(data, tuple(header[\'sizes\'][::-1]))\n\n    # Transpose data to enable Fortran indexing if requested.\n    if index_order == \'F\':\n        data = data.T\n\n    return data\n\n\ndef read(filename, custom_field_map=None, index_order=\'F\'):\n    """"""Read a NRRD file and return the header and data\n\n    See :ref:`user-guide:Reading NRRD files` for more information on reading NRRD files.\n\n    .. note::\n            Users should be aware that the `index_order` argument needs to be consistent between `nrrd.read` and `nrrd.write`. I.e., reading an array with `index_order=\'F\'` will result in a transposed version of the original data and hence the writer needs to be aware of this.\n\n    Parameters\n    ----------\n    filename : :class:`str`\n        Filename of the NRRD file\n    custom_field_map : :class:`dict` (:class:`str`, :class:`str`), optional\n        Dictionary used for parsing custom field types where the key is the custom field name and the value is a\n        string identifying datatype for the custom field.\n    index_order : {\'C\', \'F\'}, optional\n        Specifies the index order of the resulting data array. Either \'C\' (C-order) where the dimensions are ordered from\n        slowest-varying to fastest-varying (e.g. (z, y, x)), or \'F\' (Fortran-order) where the dimensions are ordered\n        from fastest-varying to slowest-varying (e.g. (x, y, z)).\n\n    Returns\n    -------\n    data : :class:`numpy.ndarray`\n        Data read from NRRD file\n    header : :class:`dict` (:class:`str`, :obj:`Object`)\n        Dictionary containing the header fields and their corresponding parsed value\n\n    See Also\n    --------\n    :meth:`write`, :meth:`read_header`, :meth:`read_data`\n    """"""\n\n    """"""Read a NRRD file and return a tuple (data, header).""""""\n    with open(filename, \'rb\') as fh:\n        header = read_header(fh, custom_field_map)\n        data = read_data(header, fh, filename, index_order)\n\n    return data, header\n'"
nrrd/writer.py,2,"b'import bz2\nimport os\nimport zlib\nfrom collections import OrderedDict\nfrom datetime import datetime\n\nfrom nrrd.errors import NRRDError\nfrom nrrd.formatters import *\nfrom nrrd.reader import _get_field_type\n\n# Older versions of Python had issues when uncompressed data was larger than 4GB (2^32). This should be fixed in latest\n# version of Python 2.7 and all versions of Python 3. The fix for this issue is to read the data in smaller chunks. The\n# chunk size is set to be small here at 1MB since performance did not vary much based on the chunk size. A smaller chunk\n# size has the benefit of using less RAM at once.\n_WRITE_CHUNKSIZE = 2 ** 20\n\n_NRRD_FIELD_ORDER = [\n    \'type\',\n    \'dimension\',\n    \'space dimension\',\n    \'space\',\n    \'sizes\',\n    \'space directions\',\n    \'kinds\',\n    \'endian\',\n    \'encoding\',\n    \'min\',\n    \'max\',\n    \'oldmin\',\n    \'old min\',\n    \'oldmax\',\n    \'old max\',\n    \'content\',\n    \'sample units\',\n    \'spacings\',\n    \'thicknesses\',\n    \'axis mins\',\n    \'axismins\',\n    \'axis maxs\',\n    \'axismaxs\',\n    \'centerings\',\n    \'labels\',\n    \'units\',\n    \'space units\',\n    \'space origin\',\n    \'measurement frame\',\n    \'data file\']\n\n_TYPEMAP_NUMPY2NRRD = {\n    \'i1\': \'int8\',\n    \'u1\': \'uint8\',\n    \'i2\': \'int16\',\n    \'u2\': \'uint16\',\n    \'i4\': \'int32\',\n    \'u4\': \'uint32\',\n    \'i8\': \'int64\',\n    \'u8\': \'uint64\',\n    \'f4\': \'float\',\n    \'f8\': \'double\',\n    \'V\': \'block\'\n}\n\n_NUMPY2NRRD_ENDIAN_MAP = {\n    \'<\': \'little\',\n    \'L\': \'little\',\n    \'>\': \'big\',\n    \'B\': \'big\'\n}\n\n\ndef _format_field_value(value, field_type):\n    if field_type == \'int\':\n        return format_number(value)\n    elif field_type == \'double\':\n        return format_number(value)\n    elif field_type == \'string\':\n        return str(value)\n    elif field_type == \'int list\':\n        return format_number_list(value)\n    elif field_type == \'double list\':\n        return format_number_list(value)\n    elif field_type == \'string list\':\n        return \' \'.join(value)\n    elif field_type == \'quoted string list\':\n        return \' \'.join(\'""{0}""\'.format(x) for x in value)\n    elif field_type == \'int vector\':\n        return format_vector(value)\n    elif field_type == \'double vector\':\n        return format_optional_vector(value)\n    elif field_type == \'int matrix\':\n        return format_matrix(value)\n    elif field_type == \'double matrix\':\n        return format_optional_matrix(value)\n    else:\n        raise NRRDError(\'Invalid field type given: %s\' % field_type)\n\n\ndef write(filename, data, header=None, detached_header=False, relative_data_path=True, custom_field_map=None,\n          compression_level=9, index_order=\'F\'):\n    """"""Write :class:`numpy.ndarray` to NRRD file\n\n    The :obj:`filename` parameter specifies the absolute or relative filename to write the NRRD file to. If the\n    :obj:`filename` extension is .nhdr, then the :obj:`detached_header` parameter is set to true automatically. If the\n    :obj:`detached_header` parameter is set to :obj:`True` and the :obj:`filename` ends in .nrrd, then the header file\n    will have the same path and base name as the :obj:`filename` but with an extension of .nhdr. In all other cases,\n    the header and data are saved in the same file.\n\n    :obj:`header` is an optional parameter containing the fields and values to be added to the NRRD header.\n\n    .. note::\n            The following fields are automatically generated based on the :obj:`data` parameter ignoring these values\n            in the :obj:`header`: \'type\', \'endian\', \'dimension\', \'sizes\', and \'data file\'. In addition, the generated\n            fields will be added to the given :obj:`header`. Thus, one can check the generated fields by viewing the\n            passed :obj:`header`.\n\n    .. note::\n            The default encoding field used if not specified in :obj:`header` is \'gzip\'.\n\n    .. note::\n            The :obj:`index_order` parameter must be consistent with the index order specified in :meth:`read`.\n            Reading an NRRD file in C-order and then writing as Fortran-order or vice versa will result in the data\n            being transposed in the NRRD file.\n\n    See :ref:`user-guide:Writing NRRD files` for more information on writing NRRD files.\n\n    Parameters\n    ----------\n    filename : :class:`str`\n        Filename of the NRRD file\n    data : :class:`numpy.ndarray`\n        Data to save to the NRRD file\n    detached_header : :obj:`bool` or :obj:`str`, optional\n        Whether the header and data should be saved in separate files. Defaults to :obj:`False`. If a :obj:`str` is\n        given this specifies the path to the datafile. This path will ONLY be used if the given filename ends with nhdr\n        (i.e. the file is a header)\n    relative_data_path : :class:`bool`\n        Whether the data filename in detached header is saved with a relative path or absolute path.\n        This parameter is ignored if there is no detached header. Defaults to :obj:`True`\n    custom_field_map : :class:`dict` (:class:`str`, :class:`str`), optional\n        Dictionary used for parsing custom field types where the key is the custom field name and the value is a\n        string identifying datatype for the custom field.\n    compression_level : :class:`int`\n        Integer between 1 to 9 specifying the compression level when using a compressed encoding (gzip or bzip). A value\n        of :obj:`1` compresses the data the least amount and is the fastest, while a value of :obj:`9` compresses the\n        data the most and is the slowest.\n    index_order : {\'C\', \'F\'}, optional\n        Specifies the index order used for writing. Either \'C\' (C-order) where the dimensions are ordered from\n        slowest-varying to fastest-varying (e.g. (z, y, x)), or \'F\' (Fortran-order) where the dimensions are ordered\n        from fastest-varying to slowest-varying (e.g. (x, y, z)).\n\n    See Also\n    --------\n    :meth:`read`, :meth:`read_header`, :meth:`read_data`\n    """"""\n\n    if header is None:\n        header = {}\n\n    # Infer a number of fields from the NumPy array and overwrite values in the header dictionary.\n    # Get type string identifier from the NumPy datatype\n    header[\'type\'] = _TYPEMAP_NUMPY2NRRD[data.dtype.str[1:]]\n\n    # If the datatype contains more than one byte and the encoding is not ASCII, then set the endian header value\n    # based on the datatype\'s endianness. Otherwise, delete the endian field from the header if present\n    if data.dtype.itemsize > 1 and header.get(\'encoding\', \'\').lower() not in [\'ascii\', \'text\', \'txt\']:\n        header[\'endian\'] = _NUMPY2NRRD_ENDIAN_MAP[data.dtype.str[:1]]\n    elif \'endian\' in header:\n        del header[\'endian\']\n\n    # If space is specified in the header, then space dimension can not. See\n    # http://teem.sourceforge.net/nrrd/format.html#space\n    if \'space\' in header.keys() and \'space dimension\' in header.keys():\n        del header[\'space dimension\']\n\n    # Update the dimension and sizes fields in the header based on the data. Since NRRD expects meta data to be in\n    # Fortran order we are required to reverse the shape in the case of the array being in C order. E.g., data was read\n    # using index_order=\'C\'.\n    header[\'dimension\'] = data.ndim\n    header[\'sizes\'] = list(data.shape) if index_order == \'F\' else list(data.shape[::-1])\n\n    # The default encoding is \'gzip\'\n    if \'encoding\' not in header:\n        header[\'encoding\'] = \'gzip\'\n\n    # Remove detached data filename from the header\n    if \'datafile\' in header:\n        header.pop(\'datafile\')\n\n    if \'data file\' in header:\n        header.pop(\'data file\')\n\n    # A bit of magic in handling options here.\n    # If *.nhdr filename provided, this overrides `detached_header=False`\n    # If *.nrrd filename provided AND detached_header=True, separate header and data files written.\n    # For all other cases, header & data written to same file.\n    if filename.endswith(\'.nhdr\'):\n        if isinstance(detached_header, str):\n            # Utilize the detached_header if a string was given as the path\n            # Note: An absolute path is obtained and assumed to be relative to the current path of the running Python\n            # program\n            data_filename = os.path.abspath(detached_header)\n        else:\n            # Get the base filename without the extension\n            base_filename = os.path.splitext(filename)[0]\n\n            # Get the appropriate data filename based on encoding, see here for information on the standard detached\n            # filename: http://teem.sourceforge.net/nrrd/format.html#encoding\n            if header[\'encoding\'] == \'raw\':\n                data_filename = \'%s.raw\' % base_filename\n            elif header[\'encoding\'] in [\'ASCII\', \'ascii\', \'text\', \'txt\']:\n                data_filename = \'%s.txt\' % base_filename\n            elif header[\'encoding\'] in [\'gzip\', \'gz\']:\n                data_filename = \'%s.raw.gz\' % base_filename\n            elif header[\'encoding\'] in [\'bzip2\', \'bz2\']:\n                data_filename = \'%s.raw.bz2\' % base_filename\n            else:\n                raise NRRDError(\'Invalid encoding specification while writing NRRD file: %s\' % header[\'encoding\'])\n\n        # Update the data file field in the header with the path of the detached data\n        # TODO This will cause problems when the user specifies a relative data path and gives a custom path OUTSIDE\n        #  of the current directory.\n        header[\'data file\'] = os.path.basename(data_filename) \\\n            if relative_data_path else os.path.abspath(data_filename)\n        detached_header = True\n    elif filename.endswith(\'.nrrd\') and detached_header:\n        data_filename = filename\n        filename = \'%s.nhdr\' % os.path.splitext(filename)[0]\n        header[\'data file\'] = os.path.basename(data_filename) \\\n            if relative_data_path else os.path.abspath(data_filename)\n    else:\n        # Write header & data as one file\n        data_filename = filename\n        detached_header = False\n\n    with open(filename, \'wb\') as fh:\n        fh.write(b\'NRRD0005\\n\')\n        fh.write(b\'# This NRRD file was generated by pynrrd\\n\')\n        fh.write(b\'# on \' + datetime.utcnow().strftime(\'%Y-%m-%d %H:%M:%S\').encode(\'ascii\') + b\'(GMT).\\n\')\n        fh.write(b\'# Complete NRRD file format specification at:\\n\')\n        fh.write(b\'# http://teem.sourceforge.net/nrrd/format.html\\n\')\n\n        # Copy the options since dictionaries are mutable when passed as an argument\n        # Thus, to prevent changes to the actual options, a copy is made\n        # Empty ordered_options list is made (will be converted into dictionary)\n        local_options = header.copy()\n        ordered_options = []\n\n        # Loop through field order and add the key/value if present\n        # Remove the key/value from the local options so that we know not to add it again\n        for field in _NRRD_FIELD_ORDER:\n            if field in local_options:\n                ordered_options.append((field, local_options[field]))\n                del local_options[field]\n\n        # Leftover items are assumed to be the custom field/value options\n        # So get current size and any items past this index will be a custom value\n        custom_field_start_index = len(ordered_options)\n\n        # Add the leftover items to the end of the list and convert the options into a dictionary\n        ordered_options.extend(local_options.items())\n        ordered_options = OrderedDict(ordered_options)\n\n        for x, (field, value) in enumerate(ordered_options.items()):\n            # Get the field_type based on field and then get corresponding\n            # value as a str using _format_field_value\n            field_type = _get_field_type(field, custom_field_map)\n            value_str = _format_field_value(value, field_type)\n\n            # Custom fields are written as key/value pairs with a := instead of : delimeter\n            if x >= custom_field_start_index:\n                fh.write((\'%s:=%s\\n\' % (field, value_str)).encode(\'ascii\'))\n            else:\n                fh.write((\'%s: %s\\n\' % (field, value_str)).encode(\'ascii\'))\n\n        # Write the closing extra newline\n        fh.write(b\'\\n\')\n\n        # If header & data in the same file is desired, write data in the file\n        if not detached_header:\n            _write_data(data, fh, header, compression_level=compression_level, index_order=index_order)\n\n    # If detached header desired, write data to different file\n    if detached_header:\n        with open(data_filename, \'wb\') as data_fh:\n            _write_data(data, data_fh, header, compression_level=compression_level, index_order=index_order)\n\n\ndef _write_data(data, fh, header, compression_level=None, index_order=\'F\'):\n    if index_order not in [\'F\', \'C\']:\n        raise NRRDError(\'Invalid index order\')\n\n    if header[\'encoding\'] == \'raw\':\n        # Convert the data into a string\n        raw_data = data.tostring(order=index_order)\n\n        # Write the data in chunks (see _WRITE_CHUNKSIZE declaration for more information why)\n        # Obtain the length of the data since we will be using it repeatedly, more efficient\n        start_index = 0\n        raw_data_len = len(raw_data)\n        # Loop through the data and write it by chunk\n        while start_index < raw_data_len:\n            # End index is start index plus the chunk size\n            # Set to the string length to read the remaining chunk at the end\n            end_index = min(start_index + _WRITE_CHUNKSIZE, raw_data_len)\n\n            # Write the compressed data\n            fh.write(raw_data[start_index:end_index])\n\n            start_index = end_index\n\n        # Finish writing the data\n        fh.flush()\n\n    elif header[\'encoding\'].lower() in [\'ascii\', \'text\', \'txt\']:\n        # savetxt only works for 1D and 2D arrays, so reshape any > 2 dim arrays into one long 1D array\n        if data.ndim > 2:\n            np.savetxt(fh, data.ravel(order=index_order), \'%.17g\')\n        else:\n            np.savetxt(fh, data if index_order == \'C\' else data.T, \'%.17g\')\n\n    else:\n        # Convert the data into a string\n        raw_data = data.tostring(order=index_order)\n\n        # Construct the compressor object based on encoding\n        if header[\'encoding\'] in [\'gzip\', \'gz\']:\n            compressobj = zlib.compressobj(compression_level, zlib.DEFLATED, zlib.MAX_WBITS | 16)\n        elif header[\'encoding\'] in [\'bzip2\', \'bz2\']:\n            compressobj = bz2.BZ2Compressor(compression_level)\n        else:\n            raise NRRDError(\'Unsupported encoding: ""%s""\' % header[\'encoding\'])\n\n        # Write the data in chunks (see _WRITE_CHUNKSIZE declaration for more information why)\n        # Obtain the length of the data since we will be using it repeatedly, more efficient\n        start_index = 0\n        raw_data_len = len(raw_data)\n\n        # Loop through the data and write it by chunk\n        while start_index < raw_data_len:\n            # End index is start index plus the chunk size\n            # Set to the string length to read the remaining chunk at the end\n            end_index = min(start_index + _WRITE_CHUNKSIZE, raw_data_len)\n\n            # Write the compressed data\n            fh.write(compressobj.compress(raw_data[start_index:end_index]))\n\n            start_index = end_index\n\n        # Finish writing the data\n        fh.write(compressobj.flush())\n        fh.flush()\n'"
docs/source/conf.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# pynrrd documentation build configuration file, created by\n# sphinx-quickstart on Sun Aug 19 12:13:41 2018.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath(\'../../\'))\nimport nrrd\n\ndef setup(app):\n    app.add_stylesheet(\'css/custom.css\')\n\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\'sphinx.ext.autodoc\',\n    \'sphinx.ext.intersphinx\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.autosummary\',\n    \'sphinx.ext.ifconfig\',\n    \'sphinx.ext.viewcode\',\n    \'sphinx.ext.githubpages\',\n\t\'sphinx.ext.autosectionlabel\',\n\t\'numpydoc\']\n\nautosectionlabel_prefix_document = True\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\nsource_suffix = [\'.rst\']\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = \'pynrrd\'\ncopyright = \'2018, Maarten Everts\'\nauthor = \'Maarten Everts\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = nrrd.__version__\n# The full version, including alpha/beta/rc tags.\nrelease = nrrd.__version__\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = [\'nrrd.tests.rst\']\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# This is required for the alabaster theme\n# refs: http://alabaster.readthedocs.io/en/latest/installation.html#sidebars\nhtml_sidebars = {\n    \'**\': [\n        \'about.html\',\n        \'navigation.html\',\n        \'relations.html\',  # needs \'show_related\': True theme option to display\n        \'searchbox.html\',\n        \'donate.html\',\n    ]\n}\n\n\n# -- Options for HTMLHelp output ------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'pynrrddoc\'\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'pynrrd.tex\', \'pynrrd Documentation\',\n     \'Maarten Everts\', \'manual\'),\n]\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'pynrrd\', \'pynrrd Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'pynrrd\', \'pynrrd Documentation\',\n     author, \'pynrrd\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {\'https://docs.python.org/\': None,\n                       \'numpy\': (\'http://docs.scipy.org/doc/numpy/\', None),\n                       \'scipy\': (\'http://docs.scipy.org/doc/scipy/reference/\', None),\n                       \'matplotlib\': (\'http://matplotlib.sourceforge.net/\', None)}\n'"
nrrd/tests/__init__.py,0,b'# __init__.py\n# Required for find_packages to retrieve the test Python files\n'
nrrd/tests/test_formatting.py,22,"b""import os\nimport sys\n\n# Required specifically in each module so that searches happen at the parent directory for importing modules\nsys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))\n\nimport numpy as np\nfrom nrrd.tests.util import *\nimport nrrd\n\n\nclass TestFieldFormatting(unittest.TestCase):\n    def setUp(self):\n        pass\n\n    def test_format_number(self):\n        # Loop through 0 -> 10 in increments of 0.1 and test if the formatted number equals what str(number) returns.\n        for x in np.linspace(0.1, 10.0, 100):\n            self.assertEqual(nrrd.format_number(x), format(x, '.17').rstrip('0').rstrip('.'))\n\n        # A few example floating points and the resulting output numbers that should be seen\n        values = {\n            123412341234.123: '123412341234.123',\n            0.000000123123: '1.2312300000000001e-07'\n        }\n\n        for key, value in values.items():\n            self.assertEqual(nrrd.format_number(key), value)\n\n    def test_format_vector(self):\n        self.assertEqual(nrrd.format_vector([1, 2, 3]), '(1,2,3)')\n        self.assertEqual(nrrd.format_vector([1., 2., 3.]), '(1,2,3)')\n        self.assertEqual(nrrd.format_vector([1.2, 2., 3.2]), '(1.2,2,3.2000000000000002)')\n\n        self.assertEqual(nrrd.format_vector(np.array([1, 2, 3])), '(1,2,3)')\n        self.assertEqual(nrrd.format_vector(np.array([1., 2., 3.])), '(1,2,3)')\n        self.assertEqual(nrrd.format_vector(np.array([1.2, 2., 3.2])), '(1.2,2,3.2000000000000002)')\n\n    def test_format_optional_vector(self):\n        self.assertEqual(nrrd.format_optional_vector([1, 2, 3]), '(1,2,3)')\n        self.assertEqual(nrrd.format_optional_vector([1., 2., 3.]), '(1,2,3)')\n        self.assertEqual(nrrd.format_optional_vector([1.2, 2., 3.2]), '(1.2,2,3.2000000000000002)')\n\n        self.assertEqual(nrrd.format_optional_vector(np.array([1, 2, 3])), '(1,2,3)')\n        self.assertEqual(nrrd.format_optional_vector(np.array([1., 2., 3.])), '(1,2,3)')\n        self.assertEqual(nrrd.format_optional_vector(np.array([1.2, 2., 3.2])), '(1.2,2,3.2000000000000002)')\n\n        self.assertEqual(nrrd.format_optional_vector(None), 'none')\n        self.assertEqual(nrrd.format_optional_vector(np.array([np.NaN, np.NaN, np.NaN])), 'none')\n        self.assertEqual(nrrd.format_optional_vector([np.NaN, np.NaN, np.NaN]), 'none')\n\n    def test_format_matrix(self):\n        self.assertEqual(nrrd.format_matrix(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])), '(1,2,3) (4,5,6) (7,8,9)')\n        self.assertEqual(nrrd.format_matrix(np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])), '(1,2,3) (4,5,6) '\n                                                                                                   '(7,8,9)')\n        self.assertEqual(nrrd.format_matrix(np.array([[1, 2.2, 3.3], [4.4, 5.5, 6.6], [7.7, 8.8, 9.9]])),\n                         '(1,2.2000000000000002,3.2999999999999998) (4.4000000000000004,5.5,6.5999999999999996) '\n                         '(7.7000000000000002,8.8000000000000007,9.9000000000000004)')\n\n        self.assertEqual(nrrd.format_matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), '(1,2,3) (4,5,6) (7,8,9)')\n        self.assertEqual(nrrd.format_matrix([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]]), '(1,2,3) (4,5,6) '\n                                                                                         '(7,8,9)')\n        self.assertEqual(nrrd.format_matrix([[1, 2.2, 3.3], [4.4, 5.5, 6.6], [7.7, 8.8, 9.9]]),\n                         '(1,2.2000000000000002,3.2999999999999998) (4.4000000000000004,5.5,6.5999999999999996) '\n                         '(7.7000000000000002,8.8000000000000007,9.9000000000000004)')\n\n    def test_format_optional_matrix(self):\n        self.assertEqual(nrrd.format_optional_matrix(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])),\n                         '(1,2,3) (4,5,6) (7,8,9)')\n        self.assertEqual(nrrd.format_optional_matrix(np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])),\n                         '(1,2,3) (4,5,6) (7,8,9)')\n        self.assertEqual(nrrd.format_optional_matrix(np.array([[1, 2.2, 3.3], [4.4, 5.5, 6.6], [7.7, 8.8, 9.9]])),\n                         '(1,2.2000000000000002,3.2999999999999998) (4.4000000000000004,5.5,6.5999999999999996) '\n                         '(7.7000000000000002,8.8000000000000007,9.9000000000000004)')\n\n        self.assertEqual(nrrd.format_optional_matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), '(1,2,3) (4,5,6) (7,8,9)')\n        self.assertEqual(nrrd.format_optional_matrix([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]]),\n                         '(1,2,3) (4,5,6) (7,8,9)')\n        self.assertEqual(nrrd.format_optional_matrix([[1, 2.2, 3.3], [4.4, 5.5, 6.6], [7.7, 8.8, 9.9]]),\n                         '(1,2.2000000000000002,3.2999999999999998) (4.4000000000000004,5.5,6.5999999999999996) '\n                         '(7.7000000000000002,8.8000000000000007,9.9000000000000004)')\n\n        self.assertEqual(nrrd.format_optional_matrix(np.array([\n            [np.NaN, np.NaN, np.NaN], [1, 2, 3], [4, 5, 6], [7, 8, 9]])),\n            'none (1,2,3) (4,5,6) (7,8,9)')\n        self.assertEqual(nrrd.format_optional_matrix(np.array([\n            [1, 2, 3], [np.NaN, np.NaN, np.NaN], [4, 5, 6], [7, 8, 9]])),\n            '(1,2,3) none (4,5,6) (7,8,9)')\n\n    def test_format_number_list(self):\n        self.assertEqual(nrrd.format_number_list([1, 2, 3]), '1 2 3')\n        self.assertEqual(nrrd.format_number_list([1., 2., 3.]), '1 2 3')\n        self.assertEqual(nrrd.format_number_list([1.2, 2., 3.2]), '1.2 2 3.2000000000000002')\n\n        self.assertEqual(nrrd.format_number_list(np.array([1, 2, 3])), '1 2 3')\n        self.assertEqual(nrrd.format_number_list(np.array([1., 2., 3.])), '1 2 3')\n        self.assertEqual(nrrd.format_number_list(np.array([1.2, 2., 3.2])), '1.2 2 3.2000000000000002')\n\n\nif __name__ == '__main__':\n    unittest.main()\n"""
nrrd/tests/test_parsing.py,8,"b""import os\nimport sys\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))\n\nimport numpy as np\nfrom nrrd.tests.util import *\nimport nrrd\n\n\nclass TestFieldParsing(unittest.TestCase):\n    def setUp(self):\n        pass\n\n    def assert_equal_with_datatype(self, desired, actual):\n        self.assertEqual(desired.dtype, np.array(actual[0]).dtype)\n        np.testing.assert_equal(desired, actual)\n\n    def test_parse_vector(self):\n        with self.assertRaisesRegex(nrrd.NRRDError, 'Vector should be enclosed by parentheses.'):\n            nrrd.parse_vector('100, 200, 300)')\n\n        with self.assertRaisesRegex(nrrd.NRRDError, 'Vector should be enclosed by parentheses.'):\n            nrrd.parse_vector('(100, 200, 300')\n\n        with self.assertRaisesRegex(nrrd.NRRDError, 'Vector should be enclosed by parentheses.'):\n            nrrd.parse_vector('100, 200, 300')\n\n        self.assert_equal_with_datatype(nrrd.parse_vector('(100, 200, 300)'), [100, 200, 300])\n        self.assert_equal_with_datatype(nrrd.parse_vector('(100, 200, 300)', dtype=float), [100., 200., 300.])\n        self.assert_equal_with_datatype(nrrd.parse_vector('(100, 200, 300)', dtype=int), [100, 200, 300])\n\n        self.assert_equal_with_datatype(nrrd.parse_vector('(100.50, 200, 300)'), [100.50, 200., 300.])\n        self.assert_equal_with_datatype(nrrd.parse_vector('(100, 200.50, 300)', dtype=float), [100., 200.50, 300.])\n        self.assert_equal_with_datatype(nrrd.parse_vector('(100, 200, 300.50)', dtype=int), [100, 200, 300])\n\n        self.assert_equal_with_datatype(nrrd.parse_vector('(100.47655, 220.32, 300.50)'), [100.47655, 220.32, 300.50])\n        self.assert_equal_with_datatype(nrrd.parse_vector('(100.47655, 220.32, 300.50)', dtype=float),\n                                        [100.47655, 220.32, 300.50])\n        self.assert_equal_with_datatype(nrrd.parse_vector('(100.47655, 220.32, 300.50)', dtype=int), [100, 220, 300])\n\n        self.assert_equal_with_datatype(nrrd.parse_vector('(100.47655, 220.32)'), [100.47655, 220.32])\n        self.assert_equal_with_datatype(nrrd.parse_vector('(100.47655, 220.32)', dtype=float), [100.47655, 220.32])\n        self.assert_equal_with_datatype(nrrd.parse_vector('(100.47655, 220.32)', dtype=int), [100, 220])\n\n        with self.assertRaisesRegex(nrrd.NRRDError, 'dtype should be None for automatic type detection, float or int'):\n            nrrd.parse_vector('(100.47655, 220.32)', dtype=np.uint8)\n\n    def test_parse_optional_vector(self):\n        with self.assertRaisesRegex(nrrd.NRRDError, 'Vector should be enclosed by parentheses.'):\n            nrrd.parse_optional_vector('100, 200, 300)')\n\n        with self.assertRaisesRegex(nrrd.NRRDError, 'Vector should be enclosed by parentheses.'):\n            nrrd.parse_optional_vector('(100, 200, 300')\n\n        with self.assertRaisesRegex(nrrd.NRRDError, 'Vector should be enclosed by parentheses.'):\n            nrrd.parse_optional_vector('100, 200, 300')\n\n        self.assert_equal_with_datatype(nrrd.parse_optional_vector('(100, 200, 300)'), [100, 200, 300])\n        self.assert_equal_with_datatype(nrrd.parse_optional_vector('(100, 200, 300)', dtype=float),\n                                        [100., 200., 300.])\n        self.assert_equal_with_datatype(nrrd.parse_optional_vector('(100, 200, 300)', dtype=int), [100, 200, 300])\n\n        self.assert_equal_with_datatype(nrrd.parse_optional_vector('(100.50, 200, 300)'), [100.50, 200., 300.])\n        self.assert_equal_with_datatype(nrrd.parse_optional_vector('(100, 200.50, 300)', dtype=float),\n                                        [100., 200.50, 300.])\n        self.assert_equal_with_datatype(nrrd.parse_optional_vector('(100, 200, 300.50)', dtype=int),\n                                        [100, 200, 300])\n\n        self.assert_equal_with_datatype(nrrd.parse_optional_vector('(100.47655, 220.32, 300.50)'),\n                                        [100.47655, 220.32, 300.50])\n        self.assert_equal_with_datatype(nrrd.parse_optional_vector('(100.47655, 220.32, 300.50)', dtype=float),\n                                        [100.47655, 220.32, 300.50])\n        self.assert_equal_with_datatype(nrrd.parse_optional_vector('(100.47655, 220.32, 300.50)', dtype=int),\n                                        [100, 220, 300])\n\n        self.assert_equal_with_datatype(nrrd.parse_optional_vector('(100.47655, 220.32)'),\n                                        [100.47655, 220.32])\n        self.assert_equal_with_datatype(nrrd.parse_optional_vector('(100.47655, 220.32)', dtype=float),\n                                        [100.47655, 220.32])\n        self.assert_equal_with_datatype(nrrd.parse_optional_vector('(100.47655, 220.32)', dtype=int), [100, 220])\n\n        self.assertEqual(nrrd.parse_optional_vector('none'), None)\n\n        with self.assertRaisesRegex(nrrd.NRRDError, 'dtype should be None for automatic type detection, float or int'):\n            nrrd.parse_optional_vector('(100.47655, 220.32)', dtype=np.uint8)\n\n    def test_parse_matrix(self):\n        self.assert_equal_with_datatype(\n            nrrd.parse_matrix('(1.4726600000000003,-0,0) (-0,1.4726600000000003,-0) (0,-0,4.7619115092114601)'),\n            [[1.4726600000000003, 0, 0], [0, 1.4726600000000003, 0], [0, 0, 4.7619115092114601]])\n\n        self.assert_equal_with_datatype(\n            nrrd.parse_matrix('(1.4726600000000003,-0,0) (-0,1.4726600000000003,-0) (0,-0,4.7619115092114601)',\n                              dtype=float),\n            [[1.4726600000000003, 0, 0], [0, 1.4726600000000003, 0], [0, 0, 4.7619115092114601]])\n\n        self.assert_equal_with_datatype(\n            nrrd.parse_matrix('(1.4726600000000003,-0,0) (-0,1.4726600000000003,-0) (0,-0,4.7619115092114601)',\n                              dtype=int), [[1, 0, 0], [0, 1, 0], [0, 0, 4]])\n\n        self.assert_equal_with_datatype(nrrd.parse_matrix('(1,0,0) (0,1,0) (0,0,1)'),\n                                        [[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n        self.assert_equal_with_datatype(nrrd.parse_matrix('(1,0,0) (0,1,0) (0,0,1)', dtype=float),\n                                        [[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])\n        self.assert_equal_with_datatype(nrrd.parse_matrix('(1,0,0) (0,1,0) (0,0,1)', dtype=int),\n                                        [[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n\n        with self.assertRaisesRegex(nrrd.NRRDError, 'Matrix should have same number of elements in each row'):\n            nrrd.parse_matrix('(1,0,0,0) (0,1,0) (0,0,1)')\n\n        with self.assertRaisesRegex(nrrd.NRRDError, 'dtype should be None for automatic type detection, float or int'):\n            nrrd.parse_matrix('(1,0,0) (0,1,0) (0,0,1)', dtype=np.uint8)\n\n    def test_parse_optional_matrix(self):\n        self.assert_equal_with_datatype(nrrd.parse_optional_matrix(\n            '(1.4726600000000003,-0,0) (-0,1.4726600000000003,-0) (0,-0,4.7619115092114601)'),\n            [[1.4726600000000003, 0, 0], [0, 1.4726600000000003, 0], [0, 0, 4.7619115092114601]])\n\n        self.assert_equal_with_datatype(nrrd.parse_optional_matrix('(1,0,0) (0,1,0) (0,0,1)'),\n                                        [[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])\n\n        self.assert_equal_with_datatype(nrrd.parse_optional_matrix(\n            'none (1.4726600000000003,-0,0) (-0,1.4726600000000003,-0) (0,-0,4.7619115092114601)'),\n            [[np.NaN, np.NaN, np.NaN], [1.4726600000000003, 0, 0], [0, 1.4726600000000003, 0],\n             [0, 0, 4.7619115092114601]])\n\n        self.assert_equal_with_datatype(nrrd.parse_optional_matrix(\n            '(1.4726600000000003,-0,0) none (-0,1.4726600000000003,-0) (0,-0,4.7619115092114601)'),\n            [[1.4726600000000003, 0, 0], [np.NaN, np.NaN, np.NaN], [0, 1.4726600000000003, 0],\n             [0, 0, 4.7619115092114601]])\n\n        with self.assertRaisesRegex(nrrd.NRRDError, 'Matrix should have same number of elements in each row'):\n            nrrd.parse_optional_matrix('(1,0,0,0) (0,1,0) (0,0,1)')\n\n        with self.assertRaisesRegex(nrrd.NRRDError, 'Matrix should have same number of elements in each row'):\n            nrrd.parse_optional_matrix('none (1,0,0,0) (0,1,0) (0,0,1)')\n\n    def test_parse_number_list_int(self):\n        self.assert_equal_with_datatype(nrrd.parse_number_list('1 2 3 4'), [1, 2, 3, 4])\n        self.assert_equal_with_datatype(nrrd.parse_number_list('1 2 3 4', dtype=float), [1., 2., 3., 4.])\n        self.assert_equal_with_datatype(nrrd.parse_number_list('1 2 3 4', dtype=int), [1, 2, 3, 4])\n\n        self.assert_equal_with_datatype(nrrd.parse_number_list('1'), [1])\n\n        with self.assertRaisesRegex(nrrd.NRRDError, 'dtype should be None for automatic type detection, float or int'):\n            nrrd.parse_number_list('1 2 3 4', dtype=np.uint8)\n\n    def test_parse_number_list_float(self):\n        self.assert_equal_with_datatype(nrrd.parse_number_list('1.5 2 3 4'), [1.5, 2., 3., 4.])\n        self.assert_equal_with_datatype(nrrd.parse_number_list('1 2 3 4.9', dtype=float), [1., 2., 3., 4.9])\n        self.assert_equal_with_datatype(nrrd.parse_number_list('1 2.9 3 4', dtype=int), [1, 2, 3, 4])\n\n        self.assert_equal_with_datatype(nrrd.parse_number_list('1.3'), [1.3])\n\n    def test_parse_number_auto_dtype(self):\n        self.assertEqual(nrrd.parse_number_auto_dtype('25'), 25)\n        self.assertEqual(nrrd.parse_number_auto_dtype('25.125'), 25.125)\n\n\nif __name__ == '__main__':\n    unittest.main()\n"""
nrrd/tests/test_reading.py,55,"b'import os\nimport sys\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))\n\nimport numpy as np\nfrom nrrd.tests.util import *\nimport nrrd\n\n\nclass TestReadingFunctions(object):\n    def setUp(self):\n        self.expected_header = {u\'dimension\': 3,\n                                u\'encoding\': \'raw\',\n                                u\'endian\': \'little\',\n                                u\'kinds\': [\'domain\', \'domain\', \'domain\'],\n                                u\'sizes\': np.array([30, 30, 30]),\n                                u\'space\': \'left-posterior-superior\',\n                                u\'space directions\': np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]),\n                                u\'space origin\': np.array([0, 0, 0]),\n                                u\'type\': \'short\'}\n\n        self.expected_data = np.fromfile(RAW_DATA_FILE_PATH, np.int16).reshape((30, 30, 30))\n        if self.index_order == \'F\':\n            self.expected_data = self.expected_data.T\n\n    def test_read_header_only(self):\n        with open(RAW_NRRD_FILE_PATH, \'rb\') as fh:\n            header = nrrd.read_header(fh)\n\n        # np.testing.assert_equal is used to compare the headers because it will appropriately handle each\n        # value in the structure. Since some of the values can be Numpy arrays inside the headers, this must be\n        # used to compare the two values.\n        np.testing.assert_equal(self.expected_header, header)\n\n    def test_read_header_only_with_filename(self):\n        header = nrrd.read_header(RAW_NRRD_FILE_PATH)\n\n        # np.testing.assert_equal is used to compare the headers because it will appropriately handle each\n        # value in the structure. Since some of the values can be Numpy arrays inside the headers, this must be\n        # used to compare the two values.\n        np.testing.assert_equal(self.expected_header, header)\n\n    def test_read_detached_header_only(self):\n        expected_header = self.expected_header\n        expected_header[u\'data file\'] = os.path.basename(RAW_DATA_FILE_PATH)\n\n        with open(RAW_NHDR_FILE_PATH, \'rb\') as fh:\n            header = nrrd.read_header(fh)\n\n        np.testing.assert_equal(self.expected_header, header)\n\n    def test_read_header_and_data_filename(self):\n        data, header = nrrd.read(RAW_NRRD_FILE_PATH, index_order=self.index_order)\n\n        np.testing.assert_equal(self.expected_header, header)\n        np.testing.assert_equal(data, self.expected_data)\n\n        # Test that the data read is able to be edited\n        self.assertTrue(data.flags[\'WRITEABLE\'])\n\n    def test_read_detached_header_and_data(self):\n        expected_header = self.expected_header\n        expected_header[u\'data file\'] = os.path.basename(RAW_DATA_FILE_PATH)\n\n        data, header = nrrd.read(RAW_NHDR_FILE_PATH, index_order=self.index_order)\n\n        np.testing.assert_equal(self.expected_header, header)\n        np.testing.assert_equal(data, self.expected_data)\n\n        # Test that the data read is able to be edited\n        self.assertTrue(data.flags[\'WRITEABLE\'])\n\n    def test_read_detached_header_and_data_with_byteskip_minus1(self):\n        expected_header = self.expected_header\n        expected_header[u\'data file\'] = os.path.basename(RAW_DATA_FILE_PATH)\n        expected_header[u\'byte skip\'] = -1\n\n        data, header = nrrd.read(RAW_BYTESKIP_NHDR_FILE_PATH, index_order=self.index_order)\n\n        np.testing.assert_equal(self.expected_header, header)\n        np.testing.assert_equal(data, self.expected_data)\n\n        # Test that the data read is able to be edited\n        self.assertTrue(data.flags[\'WRITEABLE\'])\n\n    def test_read_detached_header_and_nifti_data_with_byteskip_minus1(self):\n        expected_header = self.expected_header\n        expected_header[u\'data file\'] = os.path.basename(RAW_DATA_FILE_PATH)\n        expected_header[u\'byte skip\'] = -1\n        expected_header[u\'encoding\'] = \'gzip\'\n        expected_header[u\'data file\'] = \'BallBinary30x30x30.nii.gz\'\n\n        data, header = nrrd.read(GZ_BYTESKIP_NIFTI_NHDR_FILE_PATH, index_order=self.index_order)\n\n        np.testing.assert_equal(self.expected_header, header)\n        np.testing.assert_equal(data, self.expected_data)\n\n        # Test that the data read is able to be edited\n        self.assertTrue(data.flags[\'WRITEABLE\'])\n\n    def test_read_detached_header_and_nifti_data(self):\n        with self.assertRaisesRegex(nrrd.NRRDError, \'Size of the data does not equal \'\n                                                    + \'the product of all the dimensions: 27000-27176=-176\'):\n            nrrd.read(GZ_NIFTI_NHDR_FILE_PATH, index_order=self.index_order)\n\n    def test_read_detached_header_and_data_with_byteskip_minus5(self):\n        with self.assertRaisesRegex(nrrd.NRRDError, \'Invalid byteskip, allowed values \'\n                                                    + \'are greater than or equal to -1\'):\n            nrrd.read(RAW_INVALID_BYTESKIP_NHDR_FILE_PATH, index_order=self.index_order)\n\n    def test_read_header_and_gz_compressed_data(self):\n        expected_header = self.expected_header\n        expected_header[u\'encoding\'] = \'gzip\'\n\n        data, header = nrrd.read(GZ_NRRD_FILE_PATH, index_order=self.index_order)\n\n        np.testing.assert_equal(self.expected_header, header)\n        np.testing.assert_equal(data, self.expected_data)\n\n        # Test that the data read is able to be edited\n        self.assertTrue(data.flags[\'WRITEABLE\'])\n\n    def test_read_header_and_gz_compressed_data_with_byteskip_minus1(self):\n        expected_header = self.expected_header\n        expected_header[u\'encoding\'] = \'gzip\'\n        expected_header[u\'type\'] = \'int16\'\n        expected_header[u\'byte skip\'] = -1\n\n        data, header = nrrd.read(GZ_BYTESKIP_NRRD_FILE_PATH, index_order=self.index_order)\n\n        np.testing.assert_equal(self.expected_header, header)\n        np.testing.assert_equal(data, self.expected_data)\n\n        # Test that the data read is able to be edited\n        self.assertTrue(data.flags[\'WRITEABLE\'])\n\n    def test_read_header_and_bz2_compressed_data(self):\n        expected_header = self.expected_header\n        expected_header[u\'encoding\'] = \'bzip2\'\n\n        data, header = nrrd.read(BZ2_NRRD_FILE_PATH, index_order=self.index_order)\n\n        np.testing.assert_equal(self.expected_header, header)\n        np.testing.assert_equal(data, self.expected_data)\n\n        # Test that the data read is able to be edited\n        self.assertTrue(data.flags[\'WRITEABLE\'])\n\n    def test_read_header_and_gz_compressed_data_with_lineskip3(self):\n        expected_header = self.expected_header\n        expected_header[u\'encoding\'] = \'gzip\'\n        expected_header[u\'line skip\'] = 3\n\n        data, header = nrrd.read(GZ_LINESKIP_NRRD_FILE_PATH, index_order=self.index_order)\n\n        np.testing.assert_equal(self.expected_header, header)\n        np.testing.assert_equal(data, self.expected_data)\n\n        # Test that the data read is able to be edited\n        self.assertTrue(data.flags[\'WRITEABLE\'])\n\n    def test_read_raw_header(self):\n        expected_header = {u\'type\': \'float\', u\'dimension\': 3, u\'min\': 0, u\'max\': 35.4}\n        header = nrrd.read_header((\'NRRD0005\', \'type: float\', \'dimension: 3\', \'min: 0\', \'max: 35.4\'))\n        self.assertEqual(expected_header, header)\n\n        expected_header = {u\'my extra info\': u\'my : colon-separated : values\'}\n        header = nrrd.read_header((\'NRRD0005\', \'my extra info:=my : colon-separated : values\'))\n        np.testing.assert_equal(expected_header, header)\n\n    def test_read_dup_field_error_and_warn(self):\n        expected_header = {u\'type\': \'float\', u\'dimension\': 3}\n        header_txt_tuple = (\'NRRD0005\', \'type: float\', \'dimension: 3\', \'type: float\')\n\n        with self.assertRaisesRegex(nrrd.NRRDError, ""Duplicate header field: \'type\'""):\n            header = nrrd.read_header(header_txt_tuple)\n\n        import warnings\n        with warnings.catch_warnings(record=True) as w:\n            nrrd.reader.ALLOW_DUPLICATE_FIELD = True\n            header = nrrd.read_header(header_txt_tuple)\n\n            self.assertTrue(""Duplicate header field: \'type\'"" in str(w[0].message))\n\n            self.assertEqual(expected_header, header)\n            nrrd.reader.ALLOW_DUPLICATE_FIELD = False\n\n    def test_read_header_and_ascii_1d_data(self):\n        expected_header = {u\'dimension\': 1,\n                           u\'encoding\': \'ASCII\',\n                           u\'kinds\': [\'domain\'],\n                           u\'sizes\': [27],\n                           u\'spacings\': [1.0458000000000001],\n                           u\'type\': \'unsigned char\'}\n\n        data, header = nrrd.read(ASCII_1D_NRRD_FILE_PATH, index_order=self.index_order)\n\n        self.assertEqual(header, expected_header)\n        np.testing.assert_equal(data.dtype, np.uint8)\n        np.testing.assert_equal(data, np.arange(1, 28))\n\n        # Test that the data read is able to be edited\n        self.assertTrue(data.flags[\'WRITEABLE\'])\n\n    def test_read_header_and_ascii_2d_data(self):\n        expected_header = {u\'dimension\': 2,\n                           u\'encoding\': \'ASCII\',\n                           u\'kinds\': [\'domain\', \'domain\'],\n                           u\'sizes\': [3, 9],\n                           u\'spacings\': [1.0458000000000001, 2],\n                           u\'type\': \'unsigned short\'}\n\n        data, header = nrrd.read(ASCII_2D_NRRD_FILE_PATH, index_order=self.index_order)\n\n        np.testing.assert_equal(header, expected_header)\n        np.testing.assert_equal(data.dtype, np.uint16)\n\n        expected_shape = (3, 9) if self.index_order == \'F\' else (9, 3)\n        np.testing.assert_equal(data, np.arange(1, 28).reshape(expected_shape, order=self.index_order))\n\n        # Test that the data read is able to be edited\n        self.assertTrue(data.flags[\'WRITEABLE\'])\n\n    def test_read_simple_4d_nrrd(self):\n        expected_header = {\'type\': \'double\',\n                           \'dimension\': 4,\n                           \'space\': \'right-anterior-superior\',\n                           \'sizes\': np.array([1, 1, 1, 1]),\n                           \'space directions\': np.array([[1.5, 0., 0.],\n                                                         [0., 1.5, 0.],\n                                                         [0., 0., 1.],\n                                                         [np.NaN, np.NaN, np.NaN]]),\n                           \'endian\': \'little\',\n                           \'encoding\': \'raw\',\n                           \'measurement frame\': np.array([[1.0001, 0., 0.],\n                                                          [0., 1.0000000006, 0.],\n                                                          [0., 0., 1.000000000000009]])}\n\n        data, header = nrrd.read(RAW_4D_NRRD_FILE_PATH, index_order=self.index_order)\n\n        np.testing.assert_equal(header, expected_header)\n        np.testing.assert_equal(data.dtype, np.float64)\n        np.testing.assert_equal(header[\'measurement frame\'].dtype, np.float64)\n        np.testing.assert_equal(data, np.array([[[[0.76903426]]]]))\n\n        # Test that the data read is able to be edited\n        self.assertTrue(data.flags[\'WRITEABLE\'])\n\n    def test_custom_fields_without_field_map(self):\n        expected_header = {u\'dimension\': 1,\n                           u\'encoding\': \'ASCII\',\n                           u\'kinds\': [\'domain\'],\n                           u\'sizes\': [27],\n                           u\'spacings\': [1.0458000000000001],\n                           u\'int\': \'24\',\n                           u\'double\': \'25.5566\',\n                           u\'string\': \'This is a long string of information that is important.\',\n                           u\'int list\': \'1 2 3 4 5 100\',\n                           u\'double list\': \'0.2 0.502 0.8\',\n                           u\'string list\': \'words are split by space in list\',\n                           u\'int vector\': \'(100, 200, -300)\',\n                           u\'double vector\': \'(100.5,200.3,-300.99)\',\n                           u\'int matrix\': \'(1,0,0) (0,1,0) (0,0,1)\',\n                           u\'double matrix\': \'(1.2,0.3,0) (0,1.5,0) (0,-0.55,1.6)\',\n                           u\'type\': \'unsigned char\'}\n\n        header = nrrd.read_header(ASCII_1D_CUSTOM_FIELDS_FILE_PATH)\n\n        self.assertEqual(header, expected_header)\n\n    def test_custom_fields_with_field_map(self):\n        expected_header = {u\'dimension\': 1,\n                           u\'encoding\': \'ASCII\',\n                           u\'kinds\': [\'domain\'],\n                           u\'sizes\': [27],\n                           u\'spacings\': [1.0458000000000001],\n                           u\'int\': 24,\n                           u\'double\': 25.5566,\n                           u\'string\': \'This is a long string of information that is important.\',\n                           u\'int list\': np.array([1, 2, 3, 4, 5, 100]),\n                           u\'double list\': np.array([0.2, 0.502, 0.8]),\n                           u\'string list\': [\'words\', \'are\', \'split\', \'by\', \'space\', \'in\', \'list\'],\n                           u\'int vector\': np.array([100, 200, -300]),\n                           u\'double vector\': np.array([100.5, 200.3, -300.99]),\n                           u\'int matrix\': np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]),\n                           u\'double matrix\': np.array([[1.2, 0.3, 0.0], [0.0, 1.5, 0.0], [0.0, -0.55, 1.6]]),\n                           u\'type\': \'unsigned char\'}\n\n        custom_field_map = {\'int\': \'int\',\n                            \'double\': \'double\',\n                            \'string\': \'string\',\n                            \'int list\': \'int list\',\n                            \'double list\': \'double list\',\n                            \'string list\': \'string list\',\n                            \'int vector\': \'int vector\',\n                            \'double vector\': \'double vector\',\n                            \'int matrix\': \'int matrix\',\n                            \'double matrix\': \'double matrix\'}\n        header = nrrd.read_header(ASCII_1D_CUSTOM_FIELDS_FILE_PATH, custom_field_map)\n\n        np.testing.assert_equal(header, expected_header)\n\n    def test_invalid_custom_field(self):\n        custom_field_map = {\'int\': \'fake\'}\n\n        with self.assertRaisesRegex(nrrd.NRRDError, \'Invalid field type given: fake\'):\n            nrrd.read_header(ASCII_1D_CUSTOM_FIELDS_FILE_PATH, custom_field_map)\n\n    def test_invalid_magic_line(self):\n        with self.assertRaisesRegex(nrrd.NRRDError, \'Invalid NRRD magic line. Is this an NRRD file?\'):\n            nrrd.read_header((\'invalid magic line\', \'my extra info:=my : colon-separated : values\'))\n\n    def test_invalid_magic_line2(self):\n        with self.assertRaisesRegex(nrrd.NRRDError, \'Unsupported NRRD file version \\\\(version: 2000\\\\). This library \'\n                                                    \'only supports v5 and below.\'):\n            nrrd.read_header((\'NRRD2000\', \'my extra info:=my : colon-separated : values\'))\n\n    def test_invalid_magic_line3(self):\n        with self.assertRaisesRegex(nrrd.NRRDError, \'Invalid NRRD magic line: NRRDnono\'):\n            nrrd.read_header((\'NRRDnono\', \'my extra info:=my : colon-separated : values\'))\n\n    def test_missing_required_field(self):\n        with open(RAW_NRRD_FILE_PATH, \'rb\') as fh:\n            header = nrrd.read_header(fh)\n            np.testing.assert_equal(self.expected_header, header)\n\n            # Delete required field\n            del header[\'type\']\n\n            with self.assertRaisesRegex(nrrd.NRRDError, \'Header is missing required field: ""type"".\'):\n                nrrd.read_data(header, fh, RAW_NRRD_FILE_PATH)\n\n    def test_wrong_sizes(self):\n        with open(RAW_NRRD_FILE_PATH, \'rb\') as fh:\n            header = nrrd.read_header(fh)\n            np.testing.assert_equal(self.expected_header, header)\n\n            # Make the number of dimensions wrong\n            header[\'dimension\'] = 2\n\n            with self.assertRaisesRegex(nrrd.NRRDError, \'Number of elements in sizes does not match dimension. \'\n                                                        \'Dimension: 2, len\\\\(sizes\\\\): 3\'):\n                nrrd.read_data(header, fh, RAW_NRRD_FILE_PATH)\n\n    def test_invalid_encoding(self):\n        with open(RAW_NRRD_FILE_PATH, \'rb\') as fh:\n            header = nrrd.read_header(fh)\n            np.testing.assert_equal(self.expected_header, header)\n\n            # Set the encoding to be incorrect\n            header[\'encoding\'] = \'fake\'\n\n            with self.assertRaisesRegex(nrrd.NRRDError, \'Unsupported encoding: ""fake""\'):\n                nrrd.read_data(header, fh, RAW_NRRD_FILE_PATH)\n\n    def test_detached_header_no_filename(self):\n        self.expected_header[u\'data file\'] = os.path.basename(RAW_DATA_FILE_PATH)\n\n        with open(RAW_NHDR_FILE_PATH, \'rb\') as fh:\n            header = nrrd.read_header(fh)\n            np.testing.assert_equal(self.expected_header, header)\n\n            # No filename is specified for read_data\n            with self.assertRaisesRegex(nrrd.NRRDError, \'Filename parameter must be specified when a relative data file\'\n                                                        \' path is given\'):\n                nrrd.read_data(header, fh)\n\n    def test_invalid_lineskip(self):\n        with open(RAW_NRRD_FILE_PATH, \'rb\') as fh:\n            header = nrrd.read_header(fh)\n            np.testing.assert_equal(self.expected_header, header)\n\n            # Set the line skip to be incorrect\n            header[\'line skip\'] = -1\n\n            with self.assertRaisesRegex(nrrd.NRRDError, \'Invalid lineskip, allowed values are greater than or equal to\'\n                                                        \' 0\'):\n                nrrd.read_data(header, fh, RAW_NRRD_FILE_PATH)\n\n    def test_missing_endianness(self):\n        with open(RAW_NRRD_FILE_PATH, \'rb\') as fh:\n            header = nrrd.read_header(fh)\n            np.testing.assert_equal(self.expected_header, header)\n\n            # Delete the endian field from header\n            # Since our data is short (itemsize = 2), we should receive an error\n            del header[\'endian\']\n\n            with self.assertRaisesRegex(nrrd.NRRDError, \'Header is missing required field: ""endian"".\'):\n                nrrd.read_data(header, fh, RAW_NRRD_FILE_PATH)\n\n    def test_big_endian(self):\n        with open(RAW_NRRD_FILE_PATH, \'rb\') as fh:\n            header = nrrd.read_header(fh)\n            np.testing.assert_equal(self.expected_header, header)\n\n            # Set endianness to big to verify it is doing correctly\n            header[\'endian\'] = \'big\'\n\n            data = nrrd.read_data(header, fh, RAW_NRRD_FILE_PATH)\n            np.testing.assert_equal(data, self.expected_data.byteswap())\n\n    def test_invalid_endian(self):\n        with open(RAW_NRRD_FILE_PATH, \'rb\') as fh:\n            header = nrrd.read_header(fh)\n            np.testing.assert_equal(self.expected_header, header)\n\n            # Set endianness to fake value\n            header[\'endian\'] = \'fake\'\n\n            with self.assertRaisesRegex(nrrd.NRRDError, \'Invalid endian value in header: ""fake""\'):\n                nrrd.read_data(header, fh, RAW_NRRD_FILE_PATH)\n\n    def test_invalid_index_order(self):\n        with self.assertRaisesRegex(nrrd.NRRDError, \'Invalid index order\'):\n            nrrd.read(RAW_NRRD_FILE_PATH, index_order=None)\n\n    def test_read_quoted_string_header(self):\n        header = nrrd.read_header([\n            \'NRRD0004\',\n            \'# Complete NRRD file format specification at:\',\n            \'# http://teem.sourceforge.net/nrrd/format.html\',\n            \'type: double\',\n            \'dimension: 3\',\n            \'space dimension: 3\',\n            \'sizes: 32 40 16\',\n            \'encoding: raw\',\n            \'units: ""mm"" ""cm"" ""in""\',\n            \'space units: ""mm"" ""cm"" ""in""\',\n            \'labels: ""X"" ""Y"" ""f(log(X, 10), Y)""\',\n            \'space origin: (-0.79487200000000002,-1,-0.38461499999999998)\'\n        ])\n\n        # Check that the quoted values were appropriately parsed\n        self.assertEqual([\'mm\', \'cm\', \'in\'], header[\'units\'])\n        self.assertEqual([\'mm\', \'cm\', \'in\'], header[\'space units\'])\n        self.assertEqual([\'X\', \'Y\', \'f(log(X, 10), Y)\'], header[\'labels\'])\n\n    def test_read_quoted_string_header_no_quotes(self):\n        header = nrrd.read_header([\n            \'NRRD0004\',\n            \'# Complete NRRD file format specification at:\',\n            \'# http://teem.sourceforge.net/nrrd/format.html\',\n            \'type: double\',\n            \'dimension: 3\',\n            \'space dimension: 3\',\n            \'sizes: 32 40 16\',\n            \'encoding: raw\',\n            \'units: mm cm in\',\n            \'space units: mm cm in\',\n            \'labels: X Y f(log(X,10),Y)\',\n            \'space origin: (-0.79487200000000002,-1,-0.38461499999999998)\'\n        ])\n\n        # Check that the quoted values were appropriately parsed\n        self.assertEqual([\'mm\', \'cm\', \'in\'], header[\'units\'])\n        self.assertEqual([\'mm\', \'cm\', \'in\'], header[\'space units\'])\n        self.assertEqual([\'X\', \'Y\', \'f(log(X,10),Y)\'], header[\'labels\'])\n\n\nclass TestReadingFunctionsFortran(TestReadingFunctions, unittest.TestCase):\n    index_order = \'F\'\n\n\nclass TestReadingFunctionsC(TestReadingFunctions, unittest.TestCase):\n    index_order = \'C\'\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
nrrd/tests/test_writing.py,12,"b'import os\nimport sys\n\nsys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))\n\nimport tempfile\nimport numpy as np\nfrom nrrd.tests.util import *\nimport nrrd\n\n\nclass TestWritingFunctions(object):\n    def setUp(self):\n        self.temp_write_dir = tempfile.mkdtemp(\'nrrdtest\')\n        self.data_input, _ = nrrd.read(RAW_NRRD_FILE_PATH, index_order=self.index_order)\n\n        with open(RAW_DATA_FILE_PATH, \'rb\') as fh:\n            self.expected_data = fh.read()\n\n    def write_and_read_back_with_encoding(self, encoding, level=9):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_{}_{}.nrrd\'.format(encoding, str(level)))\n        nrrd.write(output_filename, self.data_input, {u\'encoding\': encoding}, compression_level=level,\n                   index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(self.expected_data, data.tostring(order=self.index_order))\n        self.assertEqual(header[\'encoding\'], encoding)\n\n        return output_filename\n\n    def test_write_default_header(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_default_header.nrrd\')\n        nrrd.write(output_filename, self.data_input, index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(self.expected_data, data.tostring(order=self.index_order))\n\n    def test_write_raw(self):\n        self.write_and_read_back_with_encoding(u\'raw\')\n\n    def test_write_gz(self):\n        self.write_and_read_back_with_encoding(u\'gzip\')\n\n    def test_write_bzip2(self):\n        self.write_and_read_back_with_encoding(u\'bzip2\')\n\n    def test_write_gz_level1(self):\n        filename = self.write_and_read_back_with_encoding(u\'gzip\', level=1)\n\n        self.assertLess(os.path.getsize(GZ_NRRD_FILE_PATH), os.path.getsize(filename))\n\n    def test_write_bzip2_level1(self):\n        _ = self.write_and_read_back_with_encoding(u\'bzip2\', level=1)\n\n        # note: we don\'t currently assert reduction here, because with the binary ball test data,\n        #       the output size does not change at different bz2 levels.\n        # self.assertLess(os.path.getsize(BZ2_NRRD_FILE_PATH), os.path.getsize(fn))\n\n    def test_write_ascii_1d(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_ascii_1d.nrrd\')\n\n        x = np.arange(1, 28)\n        nrrd.write(output_filename, x, {u\'encoding\': \'ascii\'}, index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(header[\'encoding\'], \'ascii\')\n        np.testing.assert_equal(data, x)\n\n    def test_write_ascii_2d(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_ascii_2d.nrrd\')\n\n        x = np.arange(1, 28).reshape((3, 9), order=self.index_order)\n        nrrd.write(output_filename, x, {u\'encoding\': \'ascii\'}, index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(header[\'encoding\'], \'ascii\')\n        np.testing.assert_equal(data, x)\n\n    def test_write_ascii_3d(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_ascii_3d.nrrd\')\n\n        x = np.arange(1, 28).reshape((3, 3, 3), order=self.index_order)\n        nrrd.write(output_filename, x, {u\'encoding\': \'ascii\'}, index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(header[\'encoding\'], \'ascii\')\n        np.testing.assert_equal(x, data)\n\n    def test_write_custom_fields_without_custom_field_map(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_custom_fields.nrrd\')\n\n        data, header = nrrd.read(ASCII_1D_CUSTOM_FIELDS_FILE_PATH, index_order=self.index_order)\n        nrrd.write(output_filename, data, header, index_order=self.index_order)\n\n        with open(output_filename, \'r\') as fh:\n            lines = fh.readlines()\n\n            # Strip newline from end of line\n            lines = [line.rstrip() for line in lines]\n\n            self.assertEqual(lines[5], \'type: uint8\')\n            self.assertEqual(lines[6], \'dimension: 1\')\n            self.assertEqual(lines[7], \'sizes: 27\')\n            self.assertEqual(lines[8], \'kinds: domain\')\n            self.assertEqual(lines[9], \'encoding: ASCII\')\n            self.assertEqual(lines[10], \'spacings: 1.0458000000000001\')\n            self.assertEqual(lines[11], \'int:=24\')\n            self.assertEqual(lines[12], \'double:=25.5566\')\n            self.assertEqual(lines[13], \'string:=This is a long string of information that is important.\')\n            self.assertEqual(lines[14], \'int list:=1 2 3 4 5 100\')\n            self.assertEqual(lines[15], \'double list:=0.2 0.502 0.8\')\n            self.assertEqual(lines[16], \'string list:=words are split by space in list\')\n            self.assertEqual(lines[17], \'int vector:=(100, 200, -300)\')\n            self.assertEqual(lines[18], \'double vector:=(100.5,200.3,-300.99)\')\n            self.assertEqual(lines[19], \'int matrix:=(1,0,0) (0,1,0) (0,0,1)\')\n            self.assertEqual(lines[20], \'double matrix:=(1.2,0.3,0) (0,1.5,0) (0,-0.55,1.6)\')\n\n    def test_write_custom_fields_with_custom_field_map(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_custom_fields.nrrd\')\n\n        custom_field_map = {\'int\': \'int\',\n                            \'double\': \'double\',\n                            \'string\': \'string\',\n                            \'int list\': \'int list\',\n                            \'double list\': \'double list\',\n                            \'string list\': \'string list\',\n                            \'int vector\': \'int vector\',\n                            \'double vector\': \'double vector\',\n                            \'int matrix\': \'int matrix\',\n                            \'double matrix\': \'double matrix\'}\n\n        data, header = nrrd.read(ASCII_1D_CUSTOM_FIELDS_FILE_PATH, custom_field_map, index_order=self.index_order)\n        nrrd.write(output_filename, data, header, custom_field_map=custom_field_map, index_order=self.index_order)\n\n        with open(output_filename, \'r\') as fh:\n            lines = fh.readlines()\n\n            # Strip newline from end of line\n            lines = [line.rstrip() for line in lines]\n\n            self.assertEqual(lines[5], \'type: uint8\')\n            self.assertEqual(lines[6], \'dimension: 1\')\n            self.assertEqual(lines[7], \'sizes: 27\')\n            self.assertEqual(lines[8], \'kinds: domain\')\n            self.assertEqual(lines[9], \'encoding: ASCII\')\n            self.assertEqual(lines[10], \'spacings: 1.0458000000000001\')\n            self.assertEqual(lines[11], \'int:=24\')\n            self.assertEqual(lines[12], \'double:=25.5566\')\n            self.assertEqual(lines[13], \'string:=This is a long string of information that is important.\')\n            self.assertEqual(lines[14], \'int list:=1 2 3 4 5 100\')\n            self.assertEqual(lines[15], \'double list:=0.20000000000000001 0.502 0.80000000000000004\')\n            self.assertEqual(lines[16], \'string list:=words are split by space in list\')\n            self.assertEqual(lines[17], \'int vector:=(100,200,-300)\')\n            self.assertEqual(lines[18], \'double vector:=(100.5,200.30000000000001,-300.99000000000001)\')\n            self.assertEqual(lines[19], \'int matrix:=(1,0,0) (0,1,0) (0,0,1)\')\n            self.assertEqual(lines[20], \'double matrix:=(1.2,0.29999999999999999,0) (0,1.5,0) (0,-0.55000000000000004,\'\n                                        \'1.6000000000000001)\')\n\n    def test_write_detached_raw_as_nrrd(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_detached_raw.nhdr\')\n        output_data_filename = os.path.join(self.temp_write_dir, \'testfile_detached_raw.nrrd\')\n\n        nrrd.write(output_data_filename, self.data_input, {u\'encoding\': \'raw\'}, detached_header=True,\n                   relative_data_path=False, index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(self.expected_data, data.tostring(order=self.index_order))\n        self.assertEqual(header[\'encoding\'], \'raw\')\n        self.assertEqual(header[\'data file\'], output_data_filename)\n\n    def test_write_detached_raw_odd_extension(self):\n        output_data_filename = os.path.join(self.temp_write_dir, \'testfile_detached_raw.nrrd2\')\n\n        nrrd.write(output_data_filename, self.data_input, {u\'encoding\': \'raw\'}, detached_header=True,\n                   index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_data_filename, index_order=self.index_order)\n        self.assertEqual(self.expected_data, data.tostring(order=self.index_order))\n        self.assertEqual(header[\'encoding\'], \'raw\')\n        self.assertEqual(\'data file\' in header, False)\n\n    def test_write_fake_encoding(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_detached_raw.nhdr\')\n\n        with self.assertRaisesRegex(nrrd.NRRDError, \'Invalid encoding specification while writing NRRD file: fake\'):\n            nrrd.write(output_filename, self.data_input, {u\'encoding\': \'fake\'}, index_order=self.index_order)\n\n    def test_write_detached_raw(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_detached_raw.nhdr\')\n\n        # Data & header are still detached even though detached_header is False because the filename is .nhdr\n        # Test also checks detached data filename that it is relative (default value)\n        nrrd.write(output_filename, self.data_input, {u\'encoding\': \'raw\'}, detached_header=False,\n                   index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(self.expected_data, data.tostring(order=self.index_order))\n        self.assertEqual(header[\'encoding\'], \'raw\')\n        self.assertEqual(header[\'data file\'], \'testfile_detached_raw.raw\')\n\n    def test_write_detached_gz(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_detached_raw.nhdr\')\n        output_data_filename = os.path.join(self.temp_write_dir, \'testfile_detached_raw.raw.gz\')\n\n        # Data & header are still detached even though detached_header is False because the filename is .nhdr\n        # Test also checks detached data filename that it is absolute\n        nrrd.write(output_filename, self.data_input, {u\'encoding\': \'gz\'}, detached_header=False,\n                   relative_data_path=False, index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(self.expected_data, data.tostring(order=self.index_order))\n        self.assertEqual(header[\'encoding\'], \'gz\')\n        self.assertEqual(header[\'data file\'], output_data_filename)\n\n    def test_write_detached_bz2(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_detached_raw.nhdr\')\n\n        # Data & header are still detached even though detached_header is False because the filename is .nhdr\n        # Test also checks detached data filename that it is relative (default value)\n        nrrd.write(output_filename, self.data_input, {u\'encoding\': \'bz2\'}, detached_header=False,\n                   index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(self.expected_data, data.tostring(order=self.index_order))\n        self.assertEqual(header[\'encoding\'], \'bz2\')\n        self.assertEqual(header[\'data file\'], \'testfile_detached_raw.raw.bz2\')\n\n    def test_write_detached_ascii(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_detached_raw.nhdr\')\n\n        # Data & header are still detached even though detached_header is False because the filename is .nhdr\n        # Test also checks detached data filename that it is relative (default value)\n        nrrd.write(output_filename, self.data_input, {u\'encoding\': \'txt\'}, detached_header=False,\n                   index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(self.expected_data, data.tostring(order=self.index_order))\n        self.assertEqual(header[\'encoding\'], \'txt\')\n        self.assertEqual(header[\'data file\'], \'testfile_detached_raw.txt\')\n\n    def test_invalid_custom_field(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_invalid_custom_field.nrrd\')\n        header = {\'int\': 12}\n        custom_field_map = {\'int\': \'fake\'}\n\n        with self.assertRaisesRegex(nrrd.NRRDError, \'Invalid field type given: fake\'):\n            nrrd.write(output_filename, np.zeros((3, 9)), header, custom_field_map=custom_field_map,\n                       index_order=self.index_order)\n\n    def test_remove_endianness(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_remove_endianness.nrrd\')\n\n        x = np.arange(1, 28)\n        nrrd.write(output_filename, x, {u\'encoding\': \'ascii\', u\'endian\': \'little\', \'space\': \'right-anterior-superior\',\n                                        \'space dimension\': 3}, index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(header[\'encoding\'], \'ascii\')\n\n        # Check for endian and space dimension, both of these should have been removed from the header\n        # Endian because it is an ASCII encoded file and space dimension because space is specified\n        self.assertFalse(\'endian\' in header)\n        self.assertFalse(\'space dimension\' in header)\n        np.testing.assert_equal(data, x)\n\n    def test_unsupported_encoding(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_unsupported_encoding.nrrd\')\n        header = {\'encoding\': \'fake\'}\n\n        with self.assertRaisesRegex(nrrd.NRRDError, \'Unsupported encoding: ""fake""\'):\n            nrrd.write(output_filename, np.zeros((3, 9)), header, index_order=self.index_order)\n\n    def test_invalid_index_order(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_invalid_index_order.nrrd\')\n\n        with self.assertRaisesRegex(nrrd.NRRDError, \'Invalid index order\'):\n            nrrd.write(output_filename, np.zeros((3,9)), index_order=None)\n\n    def test_quoted_string_list_header(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_ascii_3d.nrrd\')\n\n        x = np.arange(1, 28).reshape((3, 3, 3), order=self.index_order)\n        nrrd.write(output_filename, x, {\n            u\'encoding\': \'ascii\',\n            u\'units\': [\'mm\', \'cm\', \'in\'],\n            u\'space units\': [\'mm\', \'cm\', \'in\'],\n            u\'labels\': [\'X\', \'Y\', \'f(log(X, 10), Y)\'],\n        }, index_order=self.index_order)\n\n        with open(output_filename, \'r\') as fh:\n            lines = fh.readlines()\n\n            # Strip newline from end of line\n            lines = [line.rstrip() for line in lines]\n\n            # Note the order of the lines dont matter, we just want to verify theyre outputted correctly\n            self.assertTrue(\'units: ""mm"" ""cm"" ""in""\' in lines)\n            self.assertTrue(\'space units: ""mm"" ""cm"" ""in""\' in lines)\n            self.assertTrue(\'labels: ""X"" ""Y"" ""f(log(X, 10), Y)""\' in lines)\n\n    def test_write_detached_datafile_check(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_detached.nhdr\')\n\n        nrrd.write(output_filename, self.data_input, {\'datafile\': \'testfile_detachedWRONG.gz\'}, detached_header=True,\n                   index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(header[\'data file\'], \'testfile_detached.raw.gz\')\n\n    def test_write_detached_datafile_check2(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_detached.nhdr\')\n\n        nrrd.write(output_filename, self.data_input, {\'data file\': \'testfile_detachedWRONG.gz\'}, detached_header=True,\n                   index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(header[\'data file\'], \'testfile_detached.raw.gz\')\n\n    def test_write_detached_datafile_custom_name(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile_detached.nhdr\')\n        # Specify a custom path to write the\n        output_header_filename = os.path.join(self.temp_write_dir, \'testfile_detachedDifferent.gz\')\n\n        nrrd.write(output_filename, self.data_input, detached_header=output_header_filename,\n                   index_order=self.index_order)\n\n        # Read back the same file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertEqual(header[\'data file\'], \'testfile_detachedDifferent.gz\')\n\n    def test_write_check_remove_datafile(self):\n        output_filename = os.path.join(self.temp_write_dir, \'testfile.nrrd\')\n\n        nrrd.write(output_filename, self.data_input, {\'data file\': \'testfile_detached.gz\'}, detached_header=False,\n                   index_order=self.index_order)\n\n        # Read back the same file\n        # The \'data file\' parameter should be missing since this is NOT a detached file\n        data, header = nrrd.read(output_filename, index_order=self.index_order)\n        self.assertFalse(\'data file\' in header)\n\n\nclass TestWritingFunctionsFortran(TestWritingFunctions, unittest.TestCase):\n    index_order = \'F\'\n\n\nclass TestWritingFunctionsC(TestWritingFunctions, unittest.TestCase):\n    index_order = \'C\'\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
nrrd/tests/util.py,0,"b'import os\nimport unittest\nimport warnings\n\n# Enable all warnings\nwarnings.simplefilter(""always"")\n\nDATA_DIR_PATH = os.path.join(os.path.dirname(__file__), \'data\')\nRAW_NRRD_FILE_PATH = os.path.join(DATA_DIR_PATH, \'BallBinary30x30x30.nrrd\')\nRAW_NHDR_FILE_PATH = os.path.join(DATA_DIR_PATH, \'BallBinary30x30x30.nhdr\')\nRAW_BYTESKIP_NHDR_FILE_PATH = os.path.join(DATA_DIR_PATH, \'BallBinary30x30x30_byteskip_minus_one.nhdr\')\nGZ_BYTESKIP_NIFTI_NHDR_FILE_PATH = os.path.join(DATA_DIR_PATH, \'BallBinary30x30x30_byteskip_minus_one_nifti.nhdr\')\nGZ_NIFTI_NHDR_FILE_PATH = os.path.join(DATA_DIR_PATH, \'BallBinary30x30x30_nifti.nhdr\')\nRAW_INVALID_BYTESKIP_NHDR_FILE_PATH = os.path.join(DATA_DIR_PATH, \'BallBinary30x30x30_byteskip_minus_five.nhdr\')\nRAW_DATA_FILE_PATH = os.path.join(DATA_DIR_PATH, \'BallBinary30x30x30.raw\')\nGZ_NRRD_FILE_PATH = os.path.join(DATA_DIR_PATH, \'BallBinary30x30x30_gz.nrrd\')\nBZ2_NRRD_FILE_PATH = os.path.join(DATA_DIR_PATH, \'BallBinary30x30x30_bz2.nrrd\')\nGZ_LINESKIP_NRRD_FILE_PATH = os.path.join(DATA_DIR_PATH, \'BallBinary30x30x30_gz_lineskip.nrrd\')\nGZ_BYTESKIP_NRRD_FILE_PATH = os.path.join(DATA_DIR_PATH, \'BallBinary30x30x30_gz_byteskip_minus_one.nrrd\')\nRAW_4D_NRRD_FILE_PATH = os.path.join(DATA_DIR_PATH, \'test_simple4d_raw.nrrd\')\n\nASCII_1D_NRRD_FILE_PATH = os.path.join(DATA_DIR_PATH, \'test1d_ascii.nrrd\')\nASCII_2D_NRRD_FILE_PATH = os.path.join(DATA_DIR_PATH, \'test2d_ascii.nrrd\')\nASCII_1D_CUSTOM_FIELDS_FILE_PATH = os.path.join(DATA_DIR_PATH, \'test_customFields.nrrd\')\n\n# Fix issue with assertRaisesRegex only available in Python 3 while\n# assertRaisesRegexp is available in Python 2 (and deprecated in Python 3)\nif not hasattr(unittest.TestCase, \'assertRaisesRegex\'):\n    unittest.TestCase.assertRaisesRegex = getattr(unittest.TestCase, \'assertRaisesRegexp\')\n'"
