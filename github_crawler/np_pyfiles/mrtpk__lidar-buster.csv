file_path,api_count,code
helpers.py,1,"b'import matplotlib.pyplot as plt\nimport numpy as np\n\ndef display_stuff(imgs, labels, is_gray=False, figsize=(20,10), fontsize=30):\n    \'\'\'\n    Displays images and labels in a plot\n    \'\'\'\n    f, axes = plt.subplots(1, len(imgs), figsize=figsize)\n    for i in range(0,len(imgs)):\n        if is_gray:\n            axes[i].imshow(imgs[i], cmap=\'gray\')\n        else:\n            axes[i].imshow(imgs[i])\n        axes[i].set_title(labels[i], fontsize=fontsize)\n    return axes\n\ndef scale_to_255(a, min, max, dtype=np.uint8):\n    """""" Scales an array of values from specified min, max range to 0-255\n        Optionally specify the data type of the output (default is uint8)\n    """"""\n    return (((a - min) / float(max - min)) * 255).astype(dtype)\n'"
kitti_road_lidar.py,9,"b'import numpy as np\nimport copy\n\nclass kittiRoad(object):\n    \'\'\'\n    Collection of helpers for processing LiDAR point cloud provided in KITTI road evaluation dataset.\n    \'\'\'\n    def read_kitti_calib(self, file_path):\n        \'\'\'\n        Reads calib file of KITTI\'s road evaluation dataset\n        \'\'\'\n        float_chars = set(""0123456789.e+- "")\n        calib_data = {}\n        with open(file_path, \'r\') as f:\n            for line in f.readlines():\n                key, value = line.split(\':\', 1)\n                value = value.strip()\n                calib_data[key] = value\n                if float_chars.issuperset(value):\n                        # each value is stored in float64\n                        calib_data[key] = np.array(list(map(float, value.split(\' \'))))\n        return calib_data\n    \n    def get_projection_mappings_selector(self, pixel_mappings, img):\n        \'\'\'\n        Returns a boolean mask for pixel mappings inside the image\n        \'\'\'\n        x, y = pixel_mappings\n        h, w = img.shape[0], img.shape[1]\n        return (y < h) * (y > 0) * (x < w) * (x > 0)\n    \n    def get_projection_mappings(self, points, calib_data, img=None, return_selector=False):\n        \'\'\'\n        Returns pixel mappings for each point in the LiDAR point cloud\n        for projecting it onto an image.\n        \'\'\'\n        transformation = calib_data[\'Tr_velo_to_cam\'].reshape(3, 4)\n        rectification = calib_data[\'R0_rect\'].reshape(3, 3)\n        projection = calib_data[\'P2\'].reshape(3, 4)\n\n        _x = points[:,0]\n        x_mask = _x >= 0.0\n        \n        _points = copy.deepcopy(points.T) # np.vstack([_x[x_mask], _y[x_mask], _z[x_mask], _r[x_mask]])\n\n        # Convert filtered velodyne coordinates(X_v, Y_v, Z_v) to camera coordinates(X_c, Y_c, Z_c) \n        for i in range(_points.shape[1]):\n            _points[:3,i] = np.matmul(transformation, _points[:,i]) # only x, y, z are changed.\n\n        # Rectification\n        _points = np.delete(_points, 3, axis=0) # we don\'t need r amymore\n        for i in range(_points.shape[1]):\n            _points[:,i] = np.matmul(rectification, _points[:,i])\n\n        # Convert camera coordinates(X_c, Y_c, Z_c) image(pixel) coordinates(x,y)\n        projection = projection[:3, :3]\n        for i in range(_points.shape[1]):\n            _points[:,i] = np.matmul(projection, _points[:,i]) \n        # Normalize\n        _points = _points[::]/_points[::][2]\n        _points = np.delete(_points, 2, axis=0)\n        _points = np.floor(_points).astype(int)\n        \n        x, y = _points\n        if img is None:\n            return x, y\n        selector = self.get_projection_mappings_selector(pixel_mappings=_points, img=img)\n        selector = np.logical_and(x_mask, selector)\n        if return_selector:\n            return x[selector], y[selector], selector\n        return x[selector], y[selector]'"
lidar_convenience.py,21,"b""import numpy as np\nclass LidarTools(object):\n    '''\n    Collection of helpers for processing LiDAR point cloud.\n    '''\n    def get_bev(self, points, resolution=0.1, pixel_values=None, generate_img=None):  \n        '''\n        Returns bird's eye view of a LiDAR point cloud for a given resolution.\n        Optional pixel_values can be used for giving color coded info the point cloud.\n        Optional generate_img function can be used for creating images.\n        '''\n        \n        x = points[:, 0]\n        y = points[:, 1]\n        z = points[:, 2]\n        \n        x_range = -1 * np.ceil(y.max()).astype(np.int), ((y.min()/np.abs(y.min())) * np.floor(y.min())).astype(np.int)\n        y_range = np.floor(x.min()).astype(np.int), np.ceil(x.max()).astype(np.int)\n\n        # Create mapping from a 3D point to a pixel based on resolution\n        # floor() used to prevent issues with -ve vals rounding upwards causing index out bound error\n        x_img = (-y / resolution).astype(np.int32) - int(np.floor(x_range[0]/resolution))\n        y_img = (x / resolution).astype(np.int32) - int(np.floor(y_range[0]/resolution))\n\n        img_width  = int((x_range[1] - x_range[0])/resolution)\n        img_height = int((y_range[1] - y_range[0])/resolution)\n\n        if pixel_values is None:\n            pixel_values = (((z - z.min()) / float(z.max() - z.min())) * 255).astype(np.uint8)\n\n        if generate_img is None:\n            img = np.zeros([img_height, img_width], dtype=np.uint8)\n            img[-y_img, x_img] = pixel_values\n            return img\n        \n        return generate_img(img_height, img_width, -y_img, x_img, pixel_values)\n    \n    def filter_points(self, points, side_range=None, fwd_range=None, \\\n                  height_range=None, horizontal_fov=None, vertical_fov=None):\n        '''\n        Returns filtered points based on side, forward and height range, and, horizontal and vertical field of view.\n        '''\n        x = points[:, 0]\n        y = points[:, 1]\n        z = points[:, 2]\n        r = points[:, 3]\n        \n        mask = np.full_like(x, True)\n        \n        if side_range is not None:\n            side_mask = np.logical_and((y > -side_range[1]), (y < -side_range[0]))\n            mask = np.logical_and(mask, side_mask)\n\n        if fwd_range is not None:\n            fwd_mask = np.logical_and((x > fwd_range[0]), (x < fwd_range[1]))\n            mask = np.logical_and(mask, fwd_mask)\n\n        if height_range is not None:\n            height_mask = np.logical_and((z > height_range[0]), (z < height_range[1]))\n            mask = np.logical_and(mask, height_mask)\n            \n        if horizontal_fov is not None:\n            horizontal_fov_mask = np.logical_and(np.arctan2(y, x) > (-horizontal_fov[1] * np.pi / 180), \\\n                            np.arctan2(y, x) < (-horizontal_fov[0] * np.pi / 180))\n            mask = np.logical_and(mask, horizontal_fov_mask)\n        \n        if vertical_fov is not None:\n            distance = np.sqrt(x ** 2 + y ** 2 + z ** 2)\n            vertical_fov_mask = np.logical_and(np.arctan2(z,distance) < (vertical_fov[1] * np.pi / 180), \\\n                            np.arctan2(z,distance) > (vertical_fov[0] * np.pi / 180))\n            mask = np.logical_and(mask, vertical_fov_mask)\n\n        indices = np.argwhere(mask).flatten()\n        return points[indices, :]    """
