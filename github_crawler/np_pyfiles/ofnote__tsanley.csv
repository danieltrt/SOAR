file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python\n\nimport os\nimport setuptools\n\ndef get_long_description():\n    filename = os.path.join(os.path.dirname(__file__), \'README.md\')\n    with open(filename) as f:\n        return f.read()\n\nsetuptools.setup(name=\'tsanley\',\n      version=\'0.2.0\',\n      description=""Tsanley: Understanding Tensor Programs"",\n      long_description=get_long_description(),\n      long_description_content_type=""text/markdown"",\n      author=\'Nishant Sinha\',\n      author_email=\'nishant@offnote.co\',\n      url=\'https://github.com/ofnote/tsanley\',\n      license=\'Apache 2.0\',\n      platforms=[\'POSIX\'],\n      packages=setuptools.find_packages(),\n      #entry_points={},\n      scripts=[\'scripts/tsa\'],\n      classifiers=[\n          \'Environment :: Console\',\n          \'Intended Audience :: Developers\',\n          \'License :: OSI Approved :: Apache Software License\',\n          \'Operating System :: OS Independent\',\n          \'Programming Language :: Python :: 3.6\',\n          \'Programming Language :: Python :: 3.7\',\n          \'Topic :: Software Development\',\n          \'Topic :: Scientific/Engineering :: Artificial Intelligence\'\n          ],\n\n      setup_requires=[\'sympy\', \'typed_ast\', \'typed-astunparse\', \'easydict\', \'astpretty\', \'tsalib\'],\n      install_requires=[\'sympy\', \'typed_ast\', \'typed-astunparse\', \'easydict\', \'astpretty\', \'tsalib\'],\n      )'"
models/allennlp_multi_head_similarity.py,0,"b'#Original file : https://github.com/allenai/allennlp/blob/master/allennlp/modules/similarity_functions/multiheaded.py\n\n# The annotations in the `forward` function are sufficient to explain the module\'s functionality\n\nimport sys\nsys.path.append(\'../\')\nfrom tsalib import dim_vars\n\n\nfrom overrides import overrides\nimport torch\nfrom torch.nn.parameter import Parameter\n\nfrom allennlp.common.checks import ConfigurationError\nfrom allennlp.modules.similarity_functions.similarity_function import SimilarityFunction\nfrom allennlp.modules.similarity_functions.dot_product import DotProductSimilarity\n\n\n@SimilarityFunction.register(""multiheaded"")\nclass MultiHeadedSimilarity(SimilarityFunction):\n    """"""\n    This similarity function uses multiple ""heads"" to compute similarity.  That is, we take the\n    input tensors and project them into a number of new tensors, and compute similarities on each\n    of the projected tensors individually.  The result here has one more dimension than a typical\n    similarity function.\n    For example, say we have two input tensors, both of shape ``(batch_size, sequence_length,\n    100)``, and that we want 5 similarity heads.  We\'ll project these tensors with a ``100x100``\n    matrix, then split the resultant tensors to have shape ``(batch_size, sequence_length, 5,\n    20)``.  Then we call a wrapped similarity function on the result (by default just a dot\n    product), giving a tensor of shape ``(batch_size, sequence_length, 5)``.\n    Parameters\n    ----------\n    num_heads : ``int``\n        The number of similarity heads to compute.\n    tensor_1_dim : ``int``\n        The dimension of the first tensor described above.  This is ``tensor.size()[-1]`` - the\n        length of the vector `before` the multi-headed projection.  We need this so we can build\n        the weight matrix correctly.\n    tensor_1_projected_dim : ``int``, optional\n        The dimension of the first tensor `after` the multi-headed projection, `before` we split\n        into multiple heads.  This number must be divisible evenly by ``num_heads``.  If not given,\n        we default to ``tensor_1_dim``.\n    tensor_2_dim : ``int``, optional\n        The dimension of the second tensor described above.  This is ``tensor.size()[-1]`` - the\n        length of the vector `before` the multi-headed projection.  We need this so we can build\n        the weight matrix correctly.  If not given, we default to ``tensor_1_dim``.\n    tensor_2_projected_dim : ``int``, optional\n        The dimension of the second tensor `after` the multi-headed projection, `before` we split\n        into multiple heads.  This number must be divisible evenly by ``num_heads``.  If not given,\n        we default to ``tensor_2_dim``.\n    internal_similarity : ``SimilarityFunction``, optional\n        The ``SimilarityFunction`` to call on the projected, multi-headed tensors.  The default is\n        to use a dot product.\n    """"""\n    def __init__(self,\n                 num_heads: int,\n                 tensor_1_dim: int,\n                 tensor_1_projected_dim: int = None,\n                 tensor_2_dim: int = None,\n                 tensor_2_projected_dim: int = None,\n                 internal_similarity: SimilarityFunction = DotProductSimilarity()) -> None:\n        super(MultiHeadedSimilarity, self).__init__()\n        self.num_heads = num_heads\n        self._internal_similarity = internal_similarity\n        tensor_1_projected_dim = tensor_1_projected_dim or tensor_1_dim\n        tensor_2_dim = tensor_2_dim or tensor_1_dim\n        tensor_2_projected_dim = tensor_2_projected_dim or tensor_2_dim\n        if tensor_1_projected_dim % num_heads != 0:\n            raise ConfigurationError(""Projected dimension not divisible by number of heads: %d, %d""\n                                     % (tensor_1_projected_dim, num_heads))\n        if tensor_2_projected_dim % num_heads != 0:\n            raise ConfigurationError(""Projected dimension not divisible by number of heads: %d, %d""\n                                     % (tensor_2_projected_dim, num_heads))\n\n        # tsalib dim vars defined locally (to minimize changes from original implementation)\n        # better: define and store them in the config dictionary and use everywhere\n        self.D1, self.D2, self.D1p, self.D2p = dim_vars(\'D1:{0} D2:{1} D1p:{2} D2p:{3}\'\n                        .format(tensor_1_dim, tensor_2_dim, tensor_1_projected_dim, tensor_2_projected_dim))\n        \n        # original impl\n        self._tensor_1_projection = Parameter(torch.Tensor(tensor_1_dim, tensor_1_projected_dim))\n        self._tensor_2_projection = Parameter(torch.Tensor(tensor_2_dim, tensor_2_projected_dim))\n        \n        # with tsalib:\n        self._tensor_1_projection: (self.D1, self.D1p) = Parameter(torch.Tensor(self.D1, self.D1p))\n        self._tensor_2_projection: (self.D2, self.D2p) = Parameter(torch.Tensor(self.D2, self.D2p))\n\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        torch.nn.init.xavier_uniform_(self._tensor_1_projection)\n        torch.nn.init.xavier_uniform_(self._tensor_2_projection)\n\n    def forward_old(self, tensor_1: \'b,t,d1\', tensor_2: \'b,t,d2\') :\n        # This is the original `forward` implementation\n        # note the shape \'surgery\' below\n        H = self.num_heads\n        B, T = dim_vars(\'Batch(b):{tensor_1.shape(0)} T(t):{tensor_1.shape(1)}\')\n        D1, D2, D1p, D2p = self.D1, self.D2, self.D1p, self.D2p\n\n        projected_tensor_1: (B, T, D1p) = torch.matmul(tensor_1, self._tensor_1_projection)\n        projected_tensor_2: (B, T, D2p) = torch.matmul(tensor_2, self._tensor_2_projection)\n\n        # Here we split the last dimension of the tensors from (..., projected_dim) to\n        # (..., num_heads, projected_dim / num_heads), using tensor.view().\n        last_dim_size = projected_tensor_1.size(-1) // H\n        new_shape = list(projected_tensor_1.size())[:-1] + [H, last_dim_size]\n        split_tensor_1: (B, T, H, D1p // H) = projected_tensor_1.view(*new_shape)\n        \n        last_dim_size = projected_tensor_2.size(-1) // H\n        new_shape = list(projected_tensor_2.size())[:-1] + [H, last_dim_size]\n        split_tensor_2: (B, T, H, D2p // H) = projected_tensor_2.view(*new_shape)\n\n        # And then we pass this off to our internal similarity function.  Because the similarity\n        # functions don\'t care what dimension their input has, and only look at the last dimension,\n        # we don\'t need to do anything special here.  It will just compute similarity on the\n        # projection dimension for each head, returning a tensor of shape (..., num_heads).\n        ret : (B, T, H) = self._internal_similarity(split_tensor_1, split_tensor_2)\n        return ret\n\n    @overrides\n    def forward(self, tensor_1: \'b,t,d1\', tensor_2: \'b,t,d2\') :\n        # Cleaner implementation with tsalib\n\n        #B, T, H defined locally here (to minimize changes to original implementation)\n        # better: define and store them in the config dictionary and use everywhere\n        B, T, H = dim_vars(f\'Batch(b):{tensor_1.shape(0)} T(t):{tensor_1.shape(1)} H(h):{self.num_heads}\')\n        D1, D2, D1p, D2p = self.D1, self.D2, self.D1p, self.D2p\n\n        projected_tensor_1: (B, T, D1p) = torch.matmul(tensor_1, self._tensor_1_projection)\n        projected_tensor_2: (B, T, D2p) = torch.matmul(tensor_2, self._tensor_2_projection)\n\n        split_tensor_1 = projected_tensor_1.view(B, T, H, D1p // H)\n        split_tensor_2  = projected_tensor_2.view(B, T, H, D2p // H)\n\n        # And then we pass this off to our internal similarity function.  Because the similarity\n        # functions don\'t care what dimension their input has, and only look at the last dimension,\n        # we don\'t need to do anything special here.  It will just compute similarity on the\n        # projection dimension for each head, returning a tensor of shape (..., num_heads).\n        ret : (B, T, H) = self._internal_similarity(split_tensor_1, split_tensor_2)\n        return ret'"
models/effnet.py,0,"b""'''\nEffNet: AN EFFICIENT STRUCTURE FOR CONVOLUTIONAL NEURAL NETWORKS\nImplementation in Pytorch of Effnet.\nhttps://arxiv.org/abs/1801.06434\n\n'''\nimport torch\nimport torch.nn as nn\n\nfrom tsanley.dynamic import init_analyzer\nfrom tsalib import dim_vars\n\nB, C = dim_vars('Batch(b):20 Channels(c):3')\nH, W = dim_vars('Height(h):32 Width(w):32')\nN = dim_vars('Nclass(n):10')\n\nclass Flatten(nn.Module):\n    def forward(self, x):\n        x = x.view(x.size()[0], -1)\n        return x\n     \nclass EffNet(nn.Module):\n\n    def __init__(self, nb_classes=10, include_top=True, weights=None):\n        super(EffNet, self).__init__()\n        \n        self.block1 = self.make_layers(32, 64)\n        self.block2 = self.make_layers(64, 128)\n        self.block3 = self.make_layers(128, 256)\n        self.flatten = Flatten()\n        self.linear = nn.Linear(4096, nb_classes)\n        self.include_top = include_top\n        self.weights = weights\n\n    def make_layers(self, ch_in, ch_out):\n        layers = [\n            nn.Conv2d(3, ch_in, kernel_size=(1,1), stride=(1,1), bias=False, padding=0, dilation=(1,1)) \n            if ch_in ==32 else \n            nn.Conv2d(ch_in, ch_in, kernel_size=(1,1),stride=(1,1), bias=False, padding=0, dilation=(1,1)) ,\n            self.make_post(ch_in),\n            # DepthWiseConvolution2D\n            nn.Conv2d(ch_in, 1 * ch_in, groups=ch_in, kernel_size=(1, 3),stride=(1,1), padding=(0,1), bias=False, dilation=(1,1)),\n            self.make_post(ch_in),\n            nn.MaxPool2d(kernel_size=(2,1), stride=(2,1)),\n            # DepthWiseConvolution2D\n            nn.Conv2d(ch_in, 1 * ch_in, groups=ch_in, kernel_size=(3, 1), stride=(1,1), padding=(1,0), bias=False, dilation=(1,1)),\n            self.make_post(ch_in),\n            nn.Conv2d(ch_in, ch_out, kernel_size=(1, 2), stride=(1, 2), bias=False, padding=(0,0), dilation=(1,1)),\n            self.make_post(ch_out),\n        ]\n        return nn.Sequential(*layers)\n\n    def make_post(self, ch_in):\n        layers = [\n            nn.LeakyReLU(0.3),\n            nn.BatchNorm2d(ch_in, momentum=0.99)\n        ]\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x: 'bchw'\n        x: 'b,64,h//2,w//2' = self.block1(x)\n        x: 'b,128,h//4,w//4' = self.block2(x)\n        x: 'b,256,h//8,w//8' = self.block3(x)\n        if self.include_top:\n            x: 'b,4096' = self.flatten(x)\n            x: 'b,n' = self.linear(x)\n        return x\n\n\n\ndef test_effnet ():\n    eff = EffNet()\n    x: 'bchw' = torch.ones(B, C, H, W)\n    init_analyzer(['EffNet.forward'])\n    out = eff.forward(x)\n    print (out.size())\n\nif __name__ == '__main__':\n    test_effnet()"""
models/resnet.py,0,"b'import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\n\n\n# Original file: https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n# Updated to add shape annotations (BasicBlock and ResNet modules)\n\nimport sys\nfrom tsalib import dim_vars, get_dim_vars\n\n\n\n__all__ = [\'ResNet\', \'resnet18\', \'resnet34\', \'resnet50\', \'resnet101\',\n           \'resnet152\']\n\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes: \'Ci\', planes: \'Co\', stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        #x: \'b,ci,h,w\'\n        residual: \'b,ci,h1,w1\' = x\n\n        out: \'b,co,h1,w1\' = self.conv1(x)\n        out: \'b,co,h1,w1\' = self.bn1(out)\n        out: \'b,co,h1,w1\' = self.relu(out)\n        out: \'b,co,h1,w1\' = self.conv2(out)\n        out: \'b,co,h1,w1\'  = self.bn2(out)\n\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        #assert residual.size() == out.size()\n        out: \'b,co,h1,w1\' = out + residual\n        out: \'b,co,h1,w1\' = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        #print (f\'block expansion {block.expansion}\')\n        self.inplanes = 64\n        N = dim_vars(f\'N(nc):{num_classes}\')\n\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\'fan_out\', nonlinearity=\'relu\')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x): #H = W = 224\n        x: \'b,3,h,w\'\n        x: \'b,64,h//2,w//2\' = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x: \'b,64,h//4,w//4\' = self.maxpool(x)\n\n        x: \'b,64*e,h//4,w//4\' = self.layer1(x)\n        x: \'b,128*e,h//8,w//8\' = self.layer2(x)\n        x: \'b,256*e,h//16,w//16\' = self.layer3(x)\n        x: \'b,512*e,h//32,w//32\' = self.layer4(x)\n\n        x: \'b,512*e,1,1\' = self.avgpool(x)\n        \n        B, Ex = get_dim_vars(\'b e\')\n        x: \'b,512*e\' = x.view(B, 512*Ex)\n        x: \'b,nc\' = self.fc(x)\n\n        return x\n\n\ndef resnet18(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet18\']))\n    return model\n\n\ndef resnet34(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-34 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet34\']))\n    return model\n\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n\n\ndef resnet101(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet101\']))\n    return model\n\n\ndef resnet152(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet152\']))\n    return model\n\n\ndef test_basic_block():\n    bb = BasicBlock(64, 64)\n    x = torch.ones(10, 64, 256, 256)\n    out = bb.forward(x)\n    print (out.size())\n\ndef test_resnet ():\n    # declare dim vars: required for checking\n    \n    B, C, Ci, Co = dim_vars(\'Batch(b):10 Channels(c):3 ChannelsIn(ci) ChannelsOut(co)\')\n    H, W, Ex, NC = dim_vars(\'Height(h):224 Width(w):224 BlockExpansion(e):1 NumClasses(nc):1000\')\n\n    rs18 = resnet18()\n    x: \'bchw\' = torch.ones(10, 3, 224, 224)\n    from tsanley.dynamic import init_analyzer\n    #init_analyzer(trace_func_names=[\'ResNet.forward\', \'BasicBlock.forward\'])\n    init_analyzer(trace_func_names=[\'ResNet.forward\'])\n    out = rs18.forward(x)\n    print (out.size())\n\nif __name__ == \'__main__\':\n    test_resnet()\n\n\n'"
models/test_pytorch.py,0,"b""\n\ndef f1(x):\n    dim = 0\n    x: 'b,t,d'\n    y: 'b,d' = x.mean(dim=dim) #error: dim should be 1\n    #   ^ \n    #   | tsanley detects shape violation\n\ndef f2(x):\n    dim = 1\n    x: 'b,t,d'\n    y: 'b,d' = x.mean(dim=dim) #all shape checks passed\n\ndef test_func():\n    import torch\n    from tsalib import get_dim_vars\n\n    B, L, D = get_dim_vars('b t d')\n    x = torch.Tensor(B, L, D)\n    f1(x) #error\n    f2(x) #success\n\ndef test():\n    #declare the main named dimension variables using tsalib api\n    #recall these values anywhere in the program using `get_dim_vars`\n    from tsalib import dim_vars\n    dim_vars('Batch(b):10 Length(t):100 Hidden(d):1024')\n\n    from tsanley.dynamic import init_analyzer\n    init_analyzer(trace_func_names=['f*'], show_updates=True)\n\n    test_func()\n\ndef foo(x):\n    x: 'b,t,d' #shape check: ok!\n    y: 'b,d' = x.mean(dim=0) #error: dim should be 1\n    z: 'b,d' = x.mean(dim=1) #shape check: ok!\n\ndef test_foo():\n    import torch\n    from tsalib import get_dim_vars\n\n    # get the declared dimension sizes: 10, 100, 1024\n    B, L, D = get_dim_vars('b t d') \n    x = torch.Tensor(B, L, D)\n    foo(x)\n\ndef test2():\n    #declare the named dimension variables using the tsalib api\n    from tsalib import dim_vars\n    dim_vars('Batch(b):10 Length(t):100 Hidden(d):1024')\n\n    # initialize tsanley's dynamic shape analyzer\n    from tsanley.dynamic import init_analyzer\n    init_analyzer(trace_func_names=['foo'], show_updates=True, debug=False) #check_tsa=True, debug=False\n\n    test_foo()\n\n\n\nif __name__ == '__main__':\n    test2()"""
models/test_tf.py,0,"b'import tensorflow as tf\n\ndef foo(x):\n    x: \'b,t,d\' #shape check: ok!\n    y: \'b,d\' = tf.reduce_mean(x, axis=0) #error: dim should be 1\n    z: \'b,d\' = tf.reduce_mean(x, axis=1) #shape check: ok!\n\n    print (y)\n    print (z)\n\ndef test_foo():\n    from tsalib import get_dim_vars\n\n    # get the declared dimension sizes: 10, 100, 1024\n    B, L, D = get_dim_vars(\'b t d\') \n    #x = tf.get_variable(""x"", [B, L, D])\n    x = tf.Variable(tf.zeros([B, L, D]))\n    foo(x)\n\ndef test2():\n    #declare the named dimension variables using the tsalib api\n    from tsalib import dim_vars\n    dim_vars(\'Batch(b):10 Length(t):100 Hidden(d):1024\')\n\n    # initialize tsanley\'s dynamic shape analyzer\n    from tsanley.dynamic import init_analyzer\n    init_analyzer(trace_func_names=[\'foo\'], show_updates=True, debug=False, backend=\'tensorflow\') #check_tsa=True, debug=False\n\n    test_foo()\n\n\n\nif __name__ == \'__main__\':\n    test2()'"
tsanley/__init__.py,0,"b""\nname = 'tsanley'\n\nfrom .dynamic import dynamic_shape_analyzer"""
models/geom/agnn.py,0,"b""import os.path as osp\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import AGNNConv\n\ndataset = 'Cora'\npath = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)\ndataset = Planetoid(path, dataset, T.NormalizeFeatures())\ndata = dataset[0]\n\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.lin1 = torch.nn.Linear(dataset.num_features, 16)\n        self.prop1 = AGNNConv(requires_grad=False)\n        self.prop2 = AGNNConv(requires_grad=True)\n        self.lin2 = torch.nn.Linear(16, dataset.num_classes)\n\n    def forward(self):\n        x = F.dropout(data.x, training=self.training)\n        x = F.relu(self.lin1(x))\n        x = self.prop1(x, data.edge_index)\n        x = self.prop2(x, data.edge_index)\n        x = F.dropout(x, training=self.training)\n        x = self.lin2(x)\n        z = F.log_softmax(x, dim=1)\n        return z\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel, data = Net().to(device), data.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n\n\ndef setup_named_dims ():\n    from tsanley.dynamic import init_analyzer\n    init_analyzer(trace_func_names=['Net.forward', 'AGNNConv.forward'], show_updates=True) #check_tsa=True, debug=False\n\nsetup_named_dims()\n\ndef train():\n    model.train()\n    optimizer.zero_grad()\n    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n    optimizer.step()\n\n\ndef test():\n    model.eval()\n    logits, accs = model(), []\n    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n        pred = logits[mask].max(1)[1]\n        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n        accs.append(acc)\n    return accs\n\n\nbest_val_acc = test_acc = 0\nfor epoch in range(1, 2):\n    train()\n    train_acc, val_acc, tmp_test_acc = test()\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        test_acc = tmp_test_acc\n    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n    print(log.format(epoch, train_acc, best_val_acc, test_acc))\n"""
models/geom/gcn.py,0,"b""import os.path as osp\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv, ChebConv  # noqa\n\ndataset = 'Cora'\npath = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)\ndataset = Planetoid(path, dataset, T.NormalizeFeatures())\ndata = dataset[0]\n\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = GCNConv(dataset.num_features, 16, cached=True)\n        self.conv2 = GCNConv(16, dataset.num_classes, cached=True)\n        # self.conv1 = ChebConv(data.num_features, 16, K=2)\n        # self.conv2 = ChebConv(16, data.num_features, K=2)\n\n    def forward(self):\n        x, edge_index = data.x, data.edge_index\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.dropout(x, training=self.training)\n        x = self.conv2(x, edge_index)\n        return F.log_softmax(x, dim=1)\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel, data = Net().to(device), data.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n\n\ndef train():\n    model.train()\n    optimizer.zero_grad()\n    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n    optimizer.step()\n\n\ndef test():\n    model.eval()\n    logits, accs = model(), []\n    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n        pred = logits[mask].max(1)[1]\n        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n        accs.append(acc)\n    return accs\n\ndef setup_named_dims ():\n    from tsanley.dynamic import init_analyzer\n    init_analyzer(trace_func_names=['Net.forward'], show_updates=True) #check_tsa=True, debug=False\n\nsetup_named_dims()\nbest_val_acc = test_acc = 0\nfor epoch in range(1, 201):\n    train()\n    train_acc, val_acc, tmp_test_acc = test()\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        test_acc = tmp_test_acc\n    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n    print(log.format(epoch, train_acc, best_val_acc, test_acc))\n"""
models/geom/tsa_agnn.py,0,"b""\nimport os.path as osp\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import AGNNConv\ndataset = 'Cora'\npath = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)\ndataset = Planetoid(path, dataset, T.NormalizeFeatures())\ndata = dataset[0]\n\nclass Net(torch.nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        self.lin1 = torch.nn.Linear(dataset.num_features, 16)\n        self.prop1 = AGNNConv(requires_grad=False)\n        self.prop2 = AGNNConv(requires_grad=True)\n        self.lin2 = torch.nn.Linear(16, dataset.num_classes)\n\n    def forward(self):\n        x = F.dropout(data.x, training=self.training)\n        x = F.relu(self.lin1(x))\n        x = self.prop1(x, data.edge_index)\n        x = self.prop2(x, data.edge_index)\n        x = F.dropout(x, training=self.training)\n        x = self.lin2(x)\n        z = F.log_softmax(x, dim=1)\n        return z\ndevice = torch.device(('cuda' if torch.cuda.is_available() else 'cpu'))\n(model, data) = (Net().to(device), data.to(device))\noptimizer: 'b,t,d' = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)\n\ndef setup_named_dims():\n    from tsanley.dynamic import init_analyzer\n    init_analyzer(trace_func_names=['Net.forward', 'AGNNConv.forward'], show_updates=True)\nsetup_named_dims()\n\ndef train():\n    model.train()\n    optimizer.zero_grad()\n    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n    optimizer.step()\n\ndef test():\n    model.eval()\n    (logits, accs) = (model(), [])\n    for (_, mask) in data('train_mask', 'val_mask', 'test_mask'):\n        pred = logits[mask].max(1)[1]\n        acc = (pred.eq(data.y[mask]).sum().item() / mask.sum().item())\n        accs.append(acc)\n    return accs\nbest_val_acc = test_acc = 0\nfor epoch in range(1, 2):\n    train()\n    (train_acc, val_acc, tmp_test_acc) = test()\n    if (val_acc > best_val_acc):\n        best_val_acc = val_acc\n        test_acc = tmp_test_acc\n    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n    print(log.format(epoch, train_acc, best_val_acc, test_acc))\n"""
models/pytorch-gated-graph-neural-network/gnn.py,0,"b'import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.utils\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n\nfrom typing import List, Tuple, Dict, Sequence, Any\n\n\nclass AdjacencyList:\n    """"""represent the topology of a graph""""""\n    def __init__(self, node_num: int, adj_list: List, device: torch.device):\n        self.node_num = node_num\n        self.data = torch.tensor(adj_list, dtype=torch.long, device=device)\n        self.edge_num = len(adj_list)\n\n    @property\n    def device(self):\n        return self.data.device\n\n    def __getitem__(self, item):\n        return self.data[item]\n\n\nclass GatedGraphNeuralNetwork(nn.Module):\n    def __init__(self, hidden_size, num_edge_types, layer_timesteps,\n                 residual_connections,\n                 state_to_message_dropout=0.3,\n                 rnn_dropout=0.3,\n                 use_bias_for_message_linear=True):\n\n        super(GatedGraphNeuralNetwork, self).__init__()\n\n        self.hidden_size = hidden_size\n        self.num_edge_types = num_edge_types\n        self.layer_timesteps = layer_timesteps\n        self.residual_connections = residual_connections\n        self.state_to_message_dropout = state_to_message_dropout\n        self.rnn_dropout = rnn_dropout\n        self.use_bias_for_message_linear = use_bias_for_message_linear\n\n        # Prepare linear transformations from node states to messages, for each layer and each edge type\n        # Prepare rnn cells for each layer\n        self.state_to_message_linears = []\n        self.rnn_cells = []\n        for layer_idx in range(len(self.layer_timesteps)):\n            state_to_msg_linears_cur_layer = []\n            # Initiate a linear transformation for each edge type\n            for edge_type_j in range(self.num_edge_types):\n                # TODO: glorot_init?\n                state_to_msg_linear_layer_i_type_j = nn.Linear(self.hidden_size, self.hidden_size, bias=use_bias_for_message_linear)\n                setattr(self,\n                        \'state_to_message_linear_layer%d_type%d\' % (layer_idx, edge_type_j),\n                        state_to_msg_linear_layer_i_type_j)\n\n                state_to_msg_linears_cur_layer.append(state_to_msg_linear_layer_i_type_j)\n            self.state_to_message_linears.append(state_to_msg_linears_cur_layer)\n\n            layer_residual_connections = self.residual_connections.get(layer_idx, [])\n            rnn_cell_layer_i = nn.GRUCell(self.hidden_size * (1 + len(layer_residual_connections)), self.hidden_size)\n            setattr(self, \'rnn_cell_layer%d\' % layer_idx, rnn_cell_layer_i)\n            self.rnn_cells.append(rnn_cell_layer_i)\n\n        self.state_to_message_dropout_layer = nn.Dropout(self.state_to_message_dropout)\n        self.rnn_dropout_layer = nn.Dropout(self.rnn_dropout)\n\n    @property\n    def device(self):\n        return self.rnn_cells[0].weight_hh.device\n\n    def forward(self,\n                initial_node_representation: Variable,\n                adjacency_lists: List[AdjacencyList],\n                return_all_states=False) -> Variable:\n        return self.compute_node_representations(initial_node_representation, adjacency_lists,\n                                                 return_all_states=return_all_states)\n\n    def compute_node_representations(self,\n                                     initial_node_representation: Variable,\n                                     adjacency_lists: List[AdjacencyList],\n                                     return_all_states=False) -> Variable:\n        # If the dimension of initial node embedding is smaller, then perform padding first\n        # one entry per layer (final state of that layer), shape: number of nodes in batch v x D\n        init_node_repr_size = initial_node_representation.size(1)\n        device = adjacency_lists[0].data.device\n        if init_node_repr_size < self.hidden_size:\n            pad_size = self.hidden_size - init_node_repr_size\n            zero_pads = torch.zeros(initial_node_representation.size(0), pad_size, dtype=torch.float, device=device)\n            initial_node_representation = torch.cat([initial_node_representation, zero_pads], dim=-1)\n        node_states_per_layer = [initial_node_representation]\n\n        node_num = initial_node_representation.size(0)\n\n        message_targets = []  # list of tensors of message targets of shape [E]\n        for edge_type_idx, adjacency_list_for_edge_type in enumerate(adjacency_lists):\n            if adjacency_list_for_edge_type.edge_num > 0:\n                edge_targets = adjacency_list_for_edge_type[:, 1]\n                message_targets.append(edge_targets)\n        message_targets = torch.cat(message_targets, dim=0)  # Shape [M]\n\n        # sparse matrix of shape [V, M]\n        # incoming_msg_sparse_matrix = self.get_incoming_message_sparse_matrix(adjacency_lists).to(device)\n        for layer_idx, num_timesteps in enumerate(self.layer_timesteps):\n            # Used shape abbreviations:\n            #   V ~ number of nodes\n            #   D ~ state dimension\n            #   E ~ number of edges of current type\n            #   M ~ number of messages (sum of all E)\n\n            # Extract residual messages, if any:\n            layer_residual_connections = self.residual_connections.get(layer_idx, [])\n            # List[(V, D)]\n            layer_residual_states: List[torch.FloatTensor] = [node_states_per_layer[residual_layer_idx]\n                                                              for residual_layer_idx in layer_residual_connections]\n\n            # Record new states for this layer. Initialised to last state, but will be updated below:\n            node_states_for_this_layer = node_states_per_layer[-1]\n            # For each message propagation step\n            for t in range(num_timesteps):\n                messages: List[torch.FloatTensor] = []  # list of tensors of messages of shape [E, D]\n                message_source_states: List[torch.FloatTensor] = []  # list of tensors of edge source states of shape [E, D]\n\n                # Collect incoming messages per edge type\n                for edge_type_idx, adjacency_list_for_edge_type in enumerate(adjacency_lists):\n                    if adjacency_list_for_edge_type.edge_num > 0:\n                        # shape [E]\n                        edge_sources = adjacency_list_for_edge_type[:, 0]\n                        # shape [E, D]\n                        edge_source_states = node_states_for_this_layer[edge_sources]\n\n                        f_state_to_message = self.state_to_message_linears[layer_idx][edge_type_idx]\n                        # Shape [E, D]\n                        all_messages_for_edge_type = self.state_to_message_dropout_layer(f_state_to_message(edge_source_states))\n\n                        messages.append(all_messages_for_edge_type)\n                        message_source_states.append(edge_source_states)\n\n                # shape [M, D]\n                messages: torch.FloatTensor = torch.cat(messages, dim=0)\n\n                # Sum up messages that go to the same target node\n                # shape [V, D]\n                incoming_messages = torch.zeros(node_num, messages.size(1), device=device)\n                incoming_messages = incoming_messages.scatter_add_(0,\n                                                                   message_targets.unsqueeze(-1).expand_as(messages),\n                                                                   messages)\n\n                # shape [V, D * (1 + num of residual connections)]\n                incoming_information = torch.cat(layer_residual_states + [incoming_messages], dim=-1)\n\n                # pass updated vertex features into RNN cell\n                # Shape [V, D]\n                updated_node_states = self.rnn_cells[layer_idx](incoming_information, node_states_for_this_layer)\n                updated_node_states = self.rnn_dropout_layer(updated_node_states)\n                node_states_for_this_layer = updated_node_states\n\n            node_states_per_layer.append(node_states_for_this_layer)\n\n        if return_all_states:\n            return node_states_per_layer[1:]\n        else:\n            node_states_for_last_layer = node_states_per_layer[-1]\n            return node_states_for_last_layer\n\n\ndef main():\n    gnn = GatedGraphNeuralNetwork(hidden_size=64, num_edge_types=2,\n                                  layer_timesteps=[3, 5, 7, 2], residual_connections={2: [0], 3: [0, 1]})\n\n    adj_list_type1 = AdjacencyList(node_num=4, adj_list=[(0, 2), (2, 1), (1, 3)], device=gnn.device)\n    adj_list_type2 = AdjacencyList(node_num=4, adj_list=[(0, 0), (0, 1)], device=gnn.device)\n\n    node_representations = gnn.compute_node_representations(initial_node_representation=torch.randn(4, 64),\n                                                            adjacency_lists=[adj_list_type1, adj_list_type2])\n\n    print(node_representations)\n\n\ndef test_gnn ():\n    from tsanley.dynamic import init_analyzer\n    init_analyzer([\'GatedGraphNeuralNetwork.compute_node_representations\'])\n    main()\n\nif __name__ == \'__main__\':\n    #main()\n    test_gnn()\n'"
tsanley/annotate/__init__.py,0,b'from .annotate import AnnotatorConfig'
tsanley/annotate/annotate.py,0,"b'#!/usr/bin/env python\n\nfrom typed_ast import ast3 as ast\nimport astpretty\n#import astunparse\nimport typed_astunparse\n#https://pypi.org/project/typed-astunparse/\n\n\nclass Annotator(ast.NodeTransformer):\n    def __init__ (self, line2shape):\n        self.line2shape = line2shape\n\n    def visit_Assign(self, node):\n        #astpretty.pprint(node)\n        #Assign(expr* targets, expr value)\n        #AnnAssign(expr target, expr annotation, expr? value, int simple)\n\n        res = node\n        targets, value = node.targets, node.value\n        lineno = node.lineno\n        if lineno in self.line2shape:\n            assert len(targets) == 1\n            target = targets[0]\n            shape = self.line2shape[lineno]\n            ann = ast.Str(s=f\'{shape}\', kind=\'\', lineno=lineno, col_offset=node.col_offset)\n            #print(""\\n===>"", astpretty.pprint(node, indent=\' \'))\n            res = ast.AnnAssign(target=target, annotation=ann, value=value, simple=1, \n                        lineno=lineno, col_offset=node.col_offset)\n\n        return res\n\ndef annotate(fname, outfname, line2shape, debug=False):\n    tree = ast.parse(open(fname).read())\n    #astpretty.pprint (tree)\n\n    ann = Annotator(line2shape)\n    tree = ann.visit(tree)\n\n    if debug:\n        print (line2shape)\n\n    #treestr = astpretty.pformat(tree)\n    #astpretty.pprint (tree)\n    code = typed_astunparse.unparse(tree)\n    #print (code)\n    print (f\'Writing to annotated file {outfname}\')\n    with open(outfname, \'w\') as f:\n        f.write(code)\n\nimport json\ndef parse_shape_file (shape_log_file):\n    line2shape = {}\n    with open(shape_log_file, \'r\') as fp:\n        shape_log = json.load(fp)\n\n        for func, vals in shape_log.items():\n            for lineno, rhs in vals.items(): #rhs = [\'b,t\', \'varname\']\n                line2shape[int(lineno)] = rhs[0]\n    return line2shape\n\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\n@dataclass\nclass AnnotatorConfig:\n    fname: str\n    outfname: str = None\n    shape_log_file: str = None #\'/tmp/shape_log.json\'\n\n\n    def __post_init__(self):\n        if self.shape_log_file is None:\n            self.shape_log_file = \'/tmp/shape_log.json\'\n        \n        self.fname = Path(self.fname).resolve()     \n        if self.outfname is None:   \n            parent, name = self.fname.parent, self.fname.parts[-1]\n            self.outfname = parent / f\'tsa_{name}\'\n        else:\n            self.outfname = Path(self.outfname).resolve()\n\n    def annotate(self, debug=False):\n        line2shape = parse_shape_file(self.shape_log_file)\n        annotate(self.fname, self.outfname, line2shape, debug=debug)\n\n\n\n\n\n\n'"
tsanley/common/ast_utils.py,0,"b""import astpretty\nfrom typed_ast import ast3 as ast\nimport sympy\n\ndef is_tsalib_annotation(e):\n    return True\n\ndef aop(op, e1, e2):\n    if isinstance(op, ast.FloorDiv): res = e1 // e2\n    elif isinstance(op,ast.Div): res = e1 / e2\n    elif isinstance(op, ast.Mult): res = e1 * e2\n    elif isinstance(op, ast.Add): res = e1 + e2\n    else: \n        print (f'op not handled {op}')\n        assert False\n    return res\n\ndef expr2ann(e):\n    #print (f'expr2ann: {e}')\n    #astpretty.pprint(e)\n\n    #if not is_tsalib_annotation(e): return None\n\n    ann = None\n    if isinstance(e, ast.Tuple):\n        ann = [expr2ann(el) for el in e.elts]\n        ann = tuple(ann)\n    elif isinstance(e, ast.Num):\n        ann = e.n\n    elif isinstance(e, ast.Name):\n        #print 'eval_expr_val: ast.Name', e.id, type(e.id)\n        if e.id.isdigit() or e.id in ['True', 'False', 'None']: \n            ann = e.id\n        else: \n            ann = sympy.Symbol(e.id)\n    elif isinstance(e, ast.BinOp):\n        lhs = expr2ann(e.left)\n        r = expr2ann(e.right)\n        ann = aop(e.op, lhs, r)\n\n    elif isinstance(e, ast.Str):\n        ann = e.s\n    else:\n        print ('expr2ann: Not handled: ', type(e))\n        #assert False\n    return ann\n"""
tsanley/common/log_utils.py,0,"b""\nclass bcolors:\n    HEADER = '\\033[95m'\n    OKBLUE = '\\033[94m'\n    OKGREEN = '\\033[92m'\n    WARNING = '\\033[93m'\n    FAIL = '\\033[91m'\n    ENDC = '\\033[0m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'\n\ncolmap = {\n    'green': bcolors.OKGREEN,\n    'blue': bcolors.OKBLUE,\n    'red': bcolors.FAIL,\n    'bold': bcolors.BOLD\n}\ndef debug_log (*s, level=0):\n    if level >=2: log (*s, style=bcolors.BOLD)\n\ndef log (*s, style=bcolors.OKBLUE):\n    if style in colmap: style = colmap[style] \n    print(style, bcolors.BOLD, *s, bcolors.ENDC)\n"""
tsanley/common/static.py,0,"b""from collections import namedtuple\n\nclass DVal ():\n    def __init__(self, shape=None, val=None):\n        self._shape, self._val = shape, val\n    @property\n    def shape(self): return self._shape\n    @property\n    def val(self): return self._val\n\n    def __repr__(self):\n        s = f'(shape: {self._shape}, val: {self._val})'\n        return s\n\n\n\nclass ArgList (list):\n    def __init__(self, l):\n        if isinstance (l, DVal): l = [l]\n        else:\n            #print (type(l))\n            assert isinstance (l, list)\n        list.__init__(self, l)\n        \n    \n    def __getitem__(self, key):\n        return list.__getitem__(self, key)\n\n    def __add__(self, x):\n        if isinstance (x, DVal): x = [x]\n        assert isinstance(x, (list, ArgList))\n        x = list.__add__(self,x)\n        return ArgList(x)\n\n    def __repr__(self):\n        return list.__repr__(self)\n\n\nRefArg = namedtuple('RefArg', ['ref', 'args'])\n\n"""
tsanley/dynamic/__init__.py,0,"b""name = 'dynamic'\nfrom .dynamic_shape_analyzer import init_analyzer"""
tsanley/dynamic/dynamic_shape_analyzer.py,0,"b'import sys\nimport os\nimport inspect\n\nfrom pathlib import Path\nfrom collections import defaultdict\nfrom easydict import EasyDict as ED\n\nfrom .trace_utils import get_function_name_from_frame\nfrom typed_ast import ast3 as ast\nfrom ..common.ast_utils import expr2ann\nfrom ..common.log_utils import log, debug_log\nfrom .shape_cache import ShapeCache\n\nfrom tsalib.ts import get_decls\nfrom tsalib.tsn import tsn_to_tuple, resolve_to_int_tuple\n\n\nPY_HOME = str(Path(sys.executable).parents[1])\nEXCLUDE_FILES = [PY_HOME]\nEXCLUDE_CLASSES = [\'DimVar\', \'DimExpr\']\nDEBUG_LEVEL = 0\n\n\n# stores \nGLOBALS = ED({})\n\ndef should_filter_call(filename, func_name):\n    ret = False\n    if filename is not None: \n        ret = any([x in filename for x in EXCLUDE_FILES])\n        if ret: return ret\n    if func_name is not None:\n        ret = any([x in func_name for x in EXCLUDE_CLASSES])\n\n    return ret\n\ndef eval_attribute (a):\n    if isinstance(a.value, ast.Name):\n        receiver = a.value.id\n        ret = receiver + \'.\' + a.attr\n    elif isinstance(a.value, ast.Attribute):\n        prefix = eval_attribute(a.value)\n        ret = prefix + \'.\' + a.attr\n    else:\n        import astpretty\n        astpretty.pprint(a)\n        print (f\'{type(a.value)}\')\n        raise NotImplementedError\n\n    return ret\n\ndef eval_lhs(lhs):\n    res = None\n    if isinstance(lhs, ast.Name):\n        res = lhs.id\n    elif isinstance(lhs, ast.Tuple):\n        res = [l.id for l in lhs.elts if l]\n    elif isinstance(lhs, ast.Attribute):\n        res = eval_attribute (lhs)\n    else:\n        #raise NotImplementedError(f\'{type(lhs)}\')\n        print (f\'Not implemented eval lhs for {type(lhs)}\')\n    return res\n\n\ndef get_var_ann_from_stmt (stmt, frame):\n    var, ann = None, None\n    tree = None\n    #print (f\'get_var_ann_from_stmt: {stmt}\')\n\n    try:\n        tree = ast.parse(stmt.strip())\n        #astpretty.pprint(tree)\n    except:\n        if GLOBALS.debug:\n            log (f\'parse failed: {stmt}\', style=\'green\')\n\n    if tree is not None and len(tree.body) > 0:\n        assign = tree.body[0]\n        if isinstance(assign, (ast.AnnAssign, ast.Assign) ):\n\n            if isinstance(assign, ast.AnnAssign):\n                #assign.target, assign.annotation\n                ann = expr2ann(assign.annotation)\n                if ann is not None:\n                    if isinstance(ann, str):\n                        ann = tsn_to_tuple(ann)\n                    else:\n                        assert False, f\'unknown annotation format {ann}\'\n                    var = eval_lhs(assign.target)\n\n            elif isinstance(assign, ast.Assign):\n                assert len(assign.targets) == 1\n                trg = assign.targets[0]\n                lvars = eval_lhs(trg)\n                if isinstance(lvars, str):\n                    var = lvars\n                elif isinstance(lvars, (list, tuple)):\n                    var = lvars[0]\n                    if len(lvars) > 1:\n                        log (f\'lvars = {lvars}\')\n                        log (\'WARN: only supporting single lhs tensor assignments\')\n\n    return var, ann\n\ndef get_var_shape (var, frame):\n    if \'.\' not in var:\n        var_shape = frame.f_locals[var]\n    else:\n        ap = var.split(\'.\')\n        #assert len(ap) == 2 #TODO: generalize\n        #if len(ap) > 2: print (frame.f_locals)\n        obj = frame.f_locals[ap[0]]\n        for p in ap[1:]:\n            obj = getattr(obj, p)\n        var_shape = obj\n\n        if len(ap) > 2: print (var_shape)\n\n    return var_shape\n\n\n\ndef analyze_stmt (last_exec_stmt, line_no, func_name, filename, frame, trb):\n    debug = GLOBALS.debug\n    check_tsa = GLOBALS.check_tsa\n    shape_cache = GLOBALS.shape_cache\n\n    var, ann = get_var_ann_from_stmt(last_exec_stmt, frame)\n    #the current shape of x (named var) corresponds to post-execution of prev statement\n    # so we can check prev stmt\'s ann against x\'s shape\n    if debug: log (f\'>> var, ann : {var}, {ann}\')\n\n    if var is not None:\n        debug_log (f\'\\n({func_name}:{line_no}), var={var}\', trb.index, level=DEBUG_LEVEL)\n        #print (frame.f_locals)\n\n        var_shape = get_var_shape(var, frame)\n        shape_cache.update_var_shape(var, var_shape, func_name, filename, line_no, \n                        show=GLOBALS.show_updates)\n        \n        if ann is not None and check_tsa:\n            shape_cache.shape_check(var, ann, func_name, line_no)\n\ndef get_earlier_exec_stmts (last_exec_line, curr_line, frame):\n    global GLOBALS\n    debug = GLOBALS.debug\n\n    co_src = inspect.getsourcelines(frame.f_code)\n    stmt_list, first_line = co_src\n\n    curr_idx = (curr_line - first_line) \n    if last_exec_line is None: \n        last_exec_line = curr_line - 1\n    last_idx = (last_exec_line - first_line)\n    earlier_stmts = [(first_line + i, stmt_list[i]) for i in range(last_idx, curr_idx)]\n\n    if debug:\n        log (last_exec_line, curr_line, last_idx, curr_idx, earlier_stmts, style=\'bold\')\n    return earlier_stmts\n\ndef trace_lines(frame, event, arg):\n    global GLOBALS\n    debug = GLOBALS.debug\n    shape_cache = GLOBALS.shape_cache\n\n    if debug:\n        print (f\'\\n==> tracelines: event = {event}\')\n    \n    if event == \'line\': \n        context_pos = 0\n    elif event == \'return\': \n        context_pos = -1\n\n    else:\n        raise NotImplementedError(f\'trace_lines: unknown event {event}\')\n\n    #co = frame.f_code\n    #func_name = co.co_name\n    #print (\'varnames: \', co.co_varnames, co.co_freevars)\n    co_src = inspect.getsourcelines(frame.f_code)\n\n    filename = frame.f_code.co_filename\n    #curr_line = curr_line - 1 - context_pos\n    curr_line = frame.f_lineno\n    func_name = get_function_name_from_frame(frame)\n\n    if debug:\n        log (f\'trace_lines: function ""{func_name}"", executing line {curr_line}\')\n        log(f\'code {co_src[0]}\')\n\n    trb = inspect.getframeinfo(frame, context=1)\n    #print (trb)\n    #code_context = trb.code_context\n    #curr_line = code_context[trb.index]\n    #print (\'globals: \', frame.f_globals )\n\n    if event == \'return\': curr_line += 1 #allow tracking the last line before return\n\n    stmts = get_earlier_exec_stmts (GLOBALS.last_exec_line, curr_line, frame)\n    for stmt_line, stmt in stmts:\n        analyze_stmt (stmt, stmt_line, func_name, filename, frame, trb)\n\n    GLOBALS.last_exec_line = curr_line\n\n    if event == \'return\':\n        shape_cache.save(\'/tmp/shape_log.json\')\n        GLOBALS.last_exec_line = None # function returns, so stop keeping track\n\n    if event != \'line\':\n        #print (f\'tracelines: event = {event}\')\n        return\n\n\n    \n    \'\'\'\n    frame_mem = inspect.getmembers(frame)\n    for name, v in frame_mem:\n        #print (name)\n        if name == \'f_locals\':\n            print (name, v)\n    \'\'\'\n\n\nimport fnmatch\n\ndef trace_calls(frame, event, arg):\n    global GLOBALS\n    TRACE_INTO = GLOBALS.trace_into\n    debug = GLOBALS.debug\n\n    #print (frame, event, arg, frame.f_code.co_name)\n    if event == \'call\':\n        co = frame.f_code\n        func_name = co.co_name\n        if func_name == \'write\':\n            # Ignore write() calls from print statements\n            return\n        func_name = get_function_name_from_frame(frame)\n        #if func_name in TRACE_INTO:\n        #    debug_log (f\'> trying {func_name}, {co.co_filename}\')\n\n        curr_line = frame.f_lineno\n        filename = co.co_filename\n        #log (f\'>> call to {func_name} on line {curr_line} of {filename}\')\n\n        if should_filter_call(filename, func_name): return \n        #log (f\'>> call to {func_name} on line {curr_line} of {filename}: {TRACE_INTO}\')\n\n\n        matched = False\n        if len(TRACE_INTO) == 0: matched = True\n        else:\n            matched = any([fnmatch.fnmatch(func_name, pat) for pat in TRACE_INTO])\n        #if len(TRACE_INTO) == 0 or func_name in TRACE_INTO or \'forward\' in func_name:\n        if matched:\n            # Trace into this function\n            log(f\'\\n> Analyzing function {func_name}\')\n            GLOBALS.last_exec_line = None #TODO: push curr_line on stack\n            return trace_lines\n        #return trace_calls\n    elif event == \'return\':\n        debug_log (f\'return {frame.f_code.co_name}\')\n\n        assert False\n\n\n\ndef init_analyzer(trace_func_names=[\'main\'], check_tsa=True, show_updates=True, debug=False, backend=\'pytorch\'):\n    global GLOBALS\n    GLOBALS.debug = debug\n    GLOBALS.shape_cache = ShapeCache(debug, backend)\n    GLOBALS.trace_into = trace_func_names\n    GLOBALS.check_tsa = check_tsa\n    GLOBALS.show_updates = show_updates\n    GLOBALS.last_exec_line = None\n\n    #global SIZE2NAME\n    #assert False\n\n    sys.settrace(trace_calls)\n\n\n\n\n\n#if __name__ == \'__main__\':\n#    main()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'"
tsanley/dynamic/eval_utils.py,0,"b""from tsalib.ts import get_decls\nfrom tsalib.ts import get_dim_vars_by_long_name\n\ndef get_dimvar_subst_map ():\n    from sympy import Symbol\n    decls = get_decls()\n    subst_map = {}\n    for k, dv in decls.items():\n        subst_map[Symbol(dv._name)] = dv._val\n    return subst_map\n\ndef resolve_ann_in_frame(ann, frame):\n    '''def eval(a, ):\n        if isinstance(a, int): return a\n        if astr in frame.f_globals: return frame.f_globals[astr]\n        elif astr in frame.f_locals: return frame.f_locals[astr]\n        else:\n            assert False, f'not found ann symbol: {a}'\n    '''\n    sub_map = get_dimvar_subst_map() # Batch: 10, \n    print (sub_map)\n    ret = [e.subs(sub_map) if not isinstance(e, int) else e for e in ann]\n    print (f'resolved from {ann} to {ret}')\n    return ret\n\n\n\ndname2expr = {}\n\n\ndef lookup_long_name (name):\n    assert isinstance(name, str)\n    if name not in dname2expr: \n        e = get_dim_vars_by_long_name(name)\n    return dname2expr[e]"""
tsanley/dynamic/shape_cache.py,0,"b'from collections import defaultdict\nimport json\nfrom ..common.log_utils import log\n\nfrom tsalib.ts import get_decls\nfrom tsalib.backend import get_backend_by_name, get_str_type\n\n\ntensor_classes = {\n    \'torch\': [\'torch.Tensor\', \'torch.nn.parameter.Parameter\', \'torch.nn.modules.sparse.Embedding\'],\n    # \'tensorflow.python.ops.resource_variable_ops.ResourceVariable\'\n    \'tensorflow\': [\'ops.resource_variable_ops.ResourceVariable\', \'ops.Tensor\', \'ops.EagerTensor\']\n}\n\ndef is_name_in_class (name, class_names):\n    return any([k in name for k in class_names])\n\ndef is_tensor(x, debug):\n    t = get_str_type(x)\n\n    if \'numpy.\' in t: ret = (\'numpy.ndarray\' in t)\n    elif \'torch.\' in t: \n        ret = any([x in t for x in tensor_classes[\'torch\']])\n    elif \'tensorflow.\' in t: \n        ret = is_name_in_class(t, tensor_classes[\'tensorflow\'])\n    else: ret = False\n\n    if debug and not ret: \n        log (f\'shape_cache: Not is_tensor: {t}\', style=\'red\')\n\n    return ret\n\nclass ShapeCache:\n    def __init__ (self, debug, backend):\n        self.var2shape = defaultdict(dict)\n        self.func2ann = defaultdict(dict) # forward -> {lineno: shape}\n        self.sz2name = None\n        self.debug = debug\n\n        self.BE = get_backend_by_name(backend)\n\n    def make_decl_map (self):\n        if self.sz2name is None:\n            decl_dvs = get_decls().values()\n            self.sz2name = {dv.size: dv.shortname for dv in decl_dvs}\n\n    def get_shape(self, val):\n        self.make_decl_map()\n        shape = self.BE.shape(val)\n        actual_shape_ann = [self.sz2name[s] if s in self.sz2name else str(s) for s in shape]\n        return shape, \',\'.join(actual_shape_ann)\n\n    def update_var_shape(self, v, val, func_name, filename, lineno, show=False):\n        if not is_tensor(val, self.debug): return None\n\n        #print (\'update_var_shape\', type(val))\n        if not isinstance(val, (list, tuple) ):\n            shape, actual_shape_ann = self.get_shape(val)\n        else:\n            lenv = len(val)\n            shape, actual_shape_ann = self.get_shape(val[0])\n            shape = (lenv, shape)\n            actual_shape_ann = (lenv, actual_shape_ann)\n\n        self.var2shape[func_name][v] = shape\n        self.func2ann[func_name+\',\'+filename][lineno] = (actual_shape_ann, v)\n        if show:\n            log(f\'\\nUpdate at line {lineno}: actual shape of {v} = {actual_shape_ann}\')\n        return shape\n\n    def shape_check (self, v, shape_ann, func_name, lineno, verbose=True):\n        cache = self.var2shape[func_name]\n        assert v in cache\n        store_shape = tuple(cache[v])\n        #shape = resolve_to_int_tuple(shape)\n        #print (type(shape[0]))\n        if store_shape == shape_ann:\n            log (f\'>> shape check succeeded at line {lineno}\', style=\'green\')\n        else:\n            log (f\'>> FAILED shape check at line {lineno}\', style=\'red\')\n            log (f\'expected: {shape_ann}, actual: {store_shape}\', style=\'red\')\n            #assert False\n\n    def save(self, fname):\n        print (f\'saving shapes to {fname} ..\')\n        json_obj = (dict(self.func2ann))\n        with open(fname, ""w"", encoding=\'utf-8\') as of:\n            json.dump(json_obj, of, indent=2)\n\n'"
tsanley/dynamic/trace_utils.py,0,"b'\n\nimport opcode\n\ndef tracer(frame, event, arg):\n    if event == \'return\':\n        if arg is not None or (opcode.opname[frame.f_code.co_code[frame.f_lasti]]\n                               in (\'RETURN_VALUE\', \'YIELD_VALUE\')):\n            print(\'exit via return\', arg)\n        else:\n            print(\'exit via exception\')\n\n# copied from https://github.com/dropbox/pyannotate/blob/master/pyannotate_runtime/collect_types.py\n\n# TODO: Make this faster\ndef get_function_name_from_frame(frame):\n    # type: (Any) -> str\n    """"""\n    Heuristic to find the class-specified name by @guido\n    For instance methods we return ""ClassName.method_name""\n    For functions we return ""function_name""\n    """"""\n\n    def bases_to_mro(cls, bases):\n        # type: (type, List[type]) -> List[type]\n        """"""\n        Convert __bases__ to __mro__\n        """"""\n        mro = [cls]\n        for base in bases:\n            if base not in mro:\n                mro.append(base)\n            sub_bases = getattr(base, \'__bases__\', None)\n            if sub_bases:\n                sub_bases = [sb for sb in sub_bases if sb not in mro and sb not in bases]\n                if sub_bases:\n                    mro.extend(bases_to_mro(base, sub_bases))\n        return mro\n\n    code = frame.f_code\n    # This ought to be aggressively cached with the code object as key.\n    funcname = code.co_name\n    if code.co_varnames:\n        varname = code.co_varnames[0]\n        if varname == \'self\':\n            inst = frame.f_locals.get(varname)\n            if inst is not None:\n                try:\n                    mro = inst.__class__.__mro__\n                except AttributeError:\n                    mro = None\n                else:\n                    try:\n                        bases = inst.__class__.__bases__\n                    except AttributeError:\n                        bases = None\n                    else:\n                        mro = bases_to_mro(inst.__class__, bases)\n                if mro:\n                    for cls in mro:\n                        bare_method = cls.__dict__.get(funcname)\n                        if bare_method and getattr(bare_method, \'__code__\', None) is code:\n                            return \'%s.%s\' % (cls.__name__, funcname)\n    return funcname\n\n\n\ndef _trace_dispatch(frame, event, arg):\n\n\n    if not tracking:\n        return\n\n    #print (\'event - \', event, arg)\n\n    code = frame.f_code\n    key = id(code)\n    n = sampling_counters.get(key, 0)\n    if n is None:\n        return\n\n    if event == \'call\':\n        # Bump counter and bail depending on sampling sequence.\n        sampling_counters[key] = n + 1\n\n    elif event == \'return\':\n        if key not in call_pending:\n            return\n        call_pending.discard(key) \n    else:\n        return \n\n\n    filename = _filter_filename(code.co_filename)\n    if filename:\n        func_name = get_function_name_from_frame(frame)\n        print (filename, func_name, code.co_firstlineno)\n        print (code)\n\n\n\n\n\'\'\'\nfrom decorator import decorator\nfrom line_profiler import LineProfiler\n\n@decorator\ndef profile_each_line(func, *args, **kwargs):\n    profiler = LineProfiler()\n    profiled_func = profiler(func)\n    try:\n        profiled_func(*args, **kwargs)\n    finally:\n        profiler.print_stats()\n\'\'\'\n\n\'\'\'\n# Array of counters indexed by ID of code object.\nsampling_counters = {}  # type: Dict[int, Optional[int]]\n# IDs of code objects for which the previous event was a call (awaiting return).\ncall_pending = set()  # type: Set[int]\n\ndef _filter_types(types_dict):\n    # type: (Dict[FunctionKey, T]) -> Dict[FunctionKey, T]\n    """"""Filter type info before dumping it to the file.""""""\n\n    def exclude(k):\n        # type: (FunctionKey) -> bool\n        """"""Exclude filter""""""\n        return k.path.startswith(\'<\') or k.func_name == \'<module>\'\n\n    return {k: v for k, v in types_dict.items() if not exclude(k)}\n\'\'\'\n'"
