file_path,api_count,code
elm.py,17,"b""import numpy as np\nimport h5py\n\ndef _mean_squared_error(y_true, y_pred):\n    return 0.5 * np.mean((y_true - y_pred)**2)\n\ndef _mean_absolute_error(y_true, y_pred):\n    return np.mean(np.abs(y_true - y_pred))\n\ndef _sigmoid(x):\n    return 1. / (1. + np.exp(-x))\n\ndef _identity(x):\n    return x\n\nclass ELM(object):\n    def __init__(\n        self, n_input_nodes, n_hidden_nodes, n_output_nodes,\n        activation='sigmoid', loss='mean_squared_error', name=None,\n        beta_init=None, alpha_init=None, bias_init=None):\n\n        self.name = name\n        self.__n_input_nodes = n_input_nodes\n        self.__n_hidden_nodes = n_hidden_nodes\n        self.__n_output_nodes = n_output_nodes\n\n        # initialize weights and a bias\n        if isinstance(beta_init, np.ndarray):\n            if beta_init.shape != (self.__n_hidden_nodes, self.__n_output_nodes):\n                raise ValueError(\n                    'the shape of beta_init is expected to be (%d,%d).' % (self.__n_hidden_nodes, self.__n_output_nodes)\n                )\n            self.__beta = beta_init\n        else:\n            self.__beta = np.random.uniform(-1.,1.,size=(self.__n_hidden_nodes, self.__n_output_nodes))\n        if isinstance(alpha_init, np.ndarray):\n            if alpha_init.shape != (self.__n_input_nodes, self.__n_hidden_nodes):\n                raise ValueError(\n                    'the shape of alpha_init is expected to be (%d,%d).' % (self.__n_hidden_nodes, self.__n_output_nodes)\n                )\n            self.__alpha = alpha_init\n        else:\n            self.__alpha = np.random.uniform(-1.,1.,size=(self.__n_input_nodes, self.__n_hidden_nodes))\n        if isinstance(bias_init, np.ndarray):\n            if bias_init.shape != (self.__n_hidden_nodes,):\n                raise ValueError(\n                    'the shape of bias_init is expected to be (%d,).' % (self.__n_hidden_nodes,)\n                )\n            self.__bias = bias_init\n        else:\n            self.__bias = np.zeros(shape=(self.__n_hidden_nodes,))\n\n        # set an activation function\n        self.__activation = self.__get_activation_function(activation)\n\n        # set a loss function\n        self.__loss = self.__get_loss_function(loss)\n\n    def __call__(self, x):\n        h = self.__activation(x.dot(self.__alpha) + self.__bias)\n        return h.dot(self.__beta)\n\n    def predict(self, x):\n        return list(self(x))\n\n    def evaluate(self, x, t, metrics=['loss']):\n        y_pred = self.predict(x)\n        y_true = t\n        y_pred_argmax = np.argmax(y_pred, axis=-1)\n        y_true_argmax = np.argmax(y_true, axis=-1)\n        ret = []\n        for m in metrics:\n            if m == 'loss':\n                loss = self.__loss(y_true, y_pred)\n                ret.append(loss)\n            elif m == 'accuracy':\n                acc = np.sum(y_pred_argmax == y_true_argmax) / len(t)\n                ret.append(acc)\n            elif m == 'uar':\n                num_classes = len(t[0])\n                uar = []\n                for i in range(num_classes):\n                    tp = np.sum((y_pred_argmax == i) & (y_true_argmax == i))\n                    tp_fn = np.sum(y_true_argmax == i)\n                    uar.append(tp / tp_fn)\n                uar = np.mean(uar)\n                ret.append(uar)\n            else:\n                raise ValueError(\n                    'an unknown evaluation indicator \\'%s\\'.' % m\n                )\n        if len(ret) == 1:\n            ret = ret[0]\n        elif len(ret) == 0:\n            ret = None\n        return ret\n\n\n    def fit(self, x, t):\n        H = self.__activation(x.dot(self.__alpha) + self.__bias)\n\n        # compute a pseudoinverse of H\n        H_pinv = np.linalg.pinv(H)\n\n        # update beta\n        self.__beta = H_pinv.dot(t)\n\n    def save(self, filepath):\n        with h5py.File(filepath, 'w') as f:\n            arc = f.create_dataset('architecture', data=np.array([self.__n_input_nodes, self.__n_hidden_nodes, self.__n_output_nodes]))\n            arc.attrs['activation'] = self.__get_activation_name(self.__activation).encode('utf-8')\n            arc.attrs['loss'] = self.__get_loss_name(self.__loss).encode('utf-8')\n            arc.attrs['name'] = self.name.encode('utf-8')\n            f.create_group('weights')\n            f.create_dataset('weights/alpha', data=self.__alpha)\n            f.create_dataset('weights/beta', data=self.__beta)\n            f.create_dataset('weights/bias', data=self.__bias)\n\n    def __get_activation_function(self, name):\n        if name == 'sigmoid':\n            return _sigmoid\n        elif name == 'identity':\n            return _identity\n        else:\n            raise ValueError(\n                'an unknown activation function \\'%s\\'.' % name\n            )\n\n    def __get_activation_name(self, activation):\n        if activation == _sigmoid:\n            return 'sigmoid'\n        elif activation == _identity:\n            return 'identity'\n\n    def __get_loss_function(self, name):\n        if name == 'mean_squared_error':\n            return _mean_squared_error\n        elif name == 'mean_absolute_error':\n            return _mean_absolute_error\n        else:\n            raise ValueError(\n                'an unknown loss function \\'%s\\'.' % name\n            )\n\n    def __get_loss_name(self, loss):\n        if loss == _mean_squared_error:\n            return 'mean_squared_error'\n        elif loss == _mean_absolute_error:\n            return 'mean_absolute_error'\n    \n    @property\n    def weights(self):\n        return {\n            'alpha': self.__alpha,\n            'beta': self.__beta,\n            'bias': self.__bias,\n        }\n\n    @property\n    def input_shape(self):\n        return (self.__n_input_nodes,)\n\n    @property\n    def output_shape(self):\n        return (self.__n_output_nodes,)\n\n    @property\n    def n_input_nodes(self):\n        return self.__n_input_nodes\n\n    @property\n    def n_hidden_nodes(self):\n        return self.__n_hidden_nodes\n\n    @property\n    def n_output_nodes(self):\n        return self.__n_output_nodes\n\n    @property\n    def activation(self):\n        return self.__get_activation_name(self.__activation)\n\n    @property\n    def loss(self):\n        return self.__get_loss_name(self.__loss)\n\ndef load_model(filepath):\n    with h5py.File(filepath, 'r') as f:\n        alpha_init = f['weights/alpha'][...]\n        beta_init = f['weights/beta'][...]\n        bias_init = f['weights/bias'][...]\n        arc = f['architecture']\n        n_input_nodes = arc[0]\n        n_hidden_nodes = arc[1]\n        n_output_nodes = arc[2]\n        activation = arc.attrs['activation'].decode('utf-8')\n        loss = arc.attrs['loss'].decode('utf-8')\n        name = arc.attrs['name'].decode('utf-8')\n        model = ELM(\n            n_input_nodes=n_input_nodes,\n            n_hidden_nodes=n_hidden_nodes,\n            n_output_nodes=n_output_nodes,\n            activation=activation,\n            loss=loss,\n            alpha_init=alpha_init,\n            beta_init=beta_init,\n            bias_init=bias_init,\n            name=name,\n        )\n    return model\n"""
train.py,9,"b""from keras.datasets import mnist\nfrom keras.utils import to_categorical\nfrom elm import ELM, load_model\nimport argparse\nimport os\nimport numpy as np\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--n_hidden_nodes', type=int, default=1024)\nparser.add_argument('--loss',\n    choices=['mean_squared_error', 'mean_absolute_error'],\n    default='mean_squared_error',\n)\nparser.add_argument('--activation',\n    choices=['sigmoid', 'identity'],\n    default='sigmoid',\n)\n\ndef softmax(x):\n    c = np.max(x, axis=-1)\n    upper = np.exp(x - c)\n    lower = np.sum(upper, axis=-1)\n    return upper / lower\n\ndef main(args):\n    # ===============================\n    # Load dataset\n    # ===============================\n    n_classes = 10\n    (x_train, t_train), (x_test, t_test) = mnist.load_data()\n\n    # ===============================\n    # Preprocess\n    # ===============================\n    x_train = x_train.astype(np.float32) / 255.\n    x_train = x_train.reshape(-1, 28**2)\n    x_test = x_test.astype(np.float32) / 255.\n    x_test = x_test.reshape(-1, 28**2)\n    t_train = to_categorical(t_train, n_classes).astype(np.float32)\n    t_test = to_categorical(t_test, n_classes).astype(np.float32)\n\n    # ===============================\n    # Instantiate ELM\n    # ===============================\n    model = ELM(\n        n_input_nodes=28**2,\n        n_hidden_nodes=args.n_hidden_nodes,\n        n_output_nodes=n_classes,\n        loss=args.loss,\n        activation=args.activation,\n        name='elm',\n    )\n\n    # ===============================\n    # Training\n    # ===============================\n    model.fit(x_train, t_train)\n    train_loss, train_acc, train_uar = model.evaluate(x_train, t_train, metrics=['loss', 'accuracy', 'uar'])\n    print('train_loss: %f' % train_loss) # loss value\n    print('train_acc: %f' % train_acc) # accuracy\n    print('train_uar: %f' % train_uar) # uar (unweighted average recall)\n\n    # ===============================\n    # Validation\n    # ===============================\n    val_loss, val_acc, val_uar = model.evaluate(x_test, t_test, metrics=['loss', 'accuracy', 'uar'])\n    print('val_loss: %f' % val_loss)\n    print('val_acc: %f' % val_acc)\n    print('val_uar: %f' % val_uar)\n\n    # ===============================\n    # Prediction\n    # ===============================\n    x = x_test[:10]\n    t = t_test[:10]\n    y = softmax(model.predict(x))\n\n    for i in range(len(y)):\n        print('---------- prediction %d ----------' % (i+1))\n        class_pred = np.argmax(y[i])\n        prob_pred = y[i][class_pred]\n        class_true = np.argmax(t[i])\n        print('prediction:')\n        print('\\tclass: %d, probability: %f' % (class_pred, prob_pred))\n        print('\\tclass (true): %d' % class_true)\n\n    # ===============================\n    # Save model\n    # ===============================\n    print('saving model...')\n    model.save('model.h5')\n    del model\n\n    # ===============================\n    # Load model\n    # ===============================\n    print('loading model...')\n    model = load_model('model.h5')\n\n\nif __name__ == '__main__':\n    args = parser.parse_args()\n    main(args)\n"""
