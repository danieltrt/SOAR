file_path,api_count,code
make.py,0,"b""#!/usr/bin/env python2.7\n\nimport os,sys,glob,platform, Image\nglobal SRC,LIB,SCRIPTS,CC,CFLAGS, TRASH_FILE_EXT, UI, CLI, DIRECTORIES\n\nTRASH_FILE_EXT=['.pyc','.c','.so']\n\n\nSRC='src'\nLIB='src/lib'\nUI='src/lib/ui'\nCLI='src/lib/cli'\nSCRIPTS='src/scripts'\n\n\nDIRECTORIES=[SRC,LIB,UI,CLI,SCRIPTS]\n\n\nCC=['gcc','i586-mingw32msvc-gcc']\n\n\nCFLAGS='-shared -pthread -fPIC -fwrapv -O2 -Wall -I /usr/include/python2.7' \n\n\ndef cythonize():\n\tdef _cythonize(_dir):\n\t\tos.system('cython {0}/*.py'.format(_dir))\n\tfor d in DIRECTORIES:\n\t\t_cythonize(d)\n\t\tprint 'Cycy!'\n\t\ndef clean():\n\tdef _clean(_dir):\n\t\tfor t in TRASH_FILE_EXT:\n\t\t\tos.system('rm {0}/*{1}'.format(_dir,t))\n\tfor d in DIRECTORIES:\n\t\t_clean(d)\n\t\t\ndef gen_so(WINDOWS=False):\n\tif WINDOWS:\n\t\tn=1\n\telse:\n\t\tn=0\n\t\t\n\tdef _gen_so(_dir):\n\t\tCfiles = glob.glob('{0}/*.c'.format(_dir))\n\t\tfor f in Cfiles:\n\t\t\tf = f[:len(f) - 2] #strip .c\n\t\t\tos.system('{0} {1} -o {2}/{3}.so {2}/{3}.c'.format(CC[n],CFLAGS,_dir,f))\n\tcythonize()\t\n\tfor d in DIRECTORIES:\n\t\t_gen_so(_dir)\n\t\t\ndef archive():\n\tos.system('tar -cvf ../triton-fpr/')\n\t\n\nif __name__ == '__main__':\n\tFUNC_DIR = {'cythonize': cythonize,\n\t'clean': clean,\n\t'gen_so': gen_so,\n\t'archive': archive}\n\t\n\n\tFUNC_DIR[sys.argv[1]]()\n\t\n\t\n\t\n\n"""
src/__init__.py,0,b''
src/base.py,0,"b'""""""BASE FILE\nGeneral Imports needed for main.py in order to function properly""""""\n\n#Built-in\nimport os\nimport sys\nfrom math import sqrt\nimport Image\nimport psycopg2\n\n#Numpy\nimport numpy as np\n\n#OpenCV\nimport cv\nimport cv2\n\n#Kivy\nfrom kivy.app import App\nfrom kivy.uix.boxlayout import BoxLayout\nfrom kivy.uix.popup import Popup\n\n#Project Libraries\n#lib package\nimport lib.fish as fish\nimport lib.shape_analyzer as shape_analyzer\nimport lib.config_parser as config_parser\n#gui\nimport lib.ui.main_gui as main_gui\n\ndef initialize_fishbase(datasource_url):\n\t""""""Populates database and returns a FishDatabase object""""""\n\ttry:\n\t\tfishbase = fish.FishDatabase(datasource_url) \n\t\tprint \'Connection Established\'\n\texcept psycopg2.OperationalError:\n\t\texit() \n\t\t\n\tfor specimen in fishbase.species_list:\n\t\tcode = specimen[0]\n\t\tname = specimen[1]\t\n\t\tf = fish.Fish()\n\t\tf.code = code\n\t\tf.name = name\n\t\tf.bodycascade = fishbase.query_cascade(code,\'BC\')\n\t\tf.fcascades = fishbase.query_feature_cascades(code)\n\t\tf.morphometrics.cHL = fishbase.query_morphometrics(code, \'HL\')\n\t\tf.morphometrics.cFL = fishbase.query_morphometrics(code, \'FL\')\n\t\tf.morphometrics.cSL = fishbase.query_morphometrics(code, \'SL\')\n\t\tf.morphometrics.cBD = fishbase.query_morphometrics(code, \'BD\')\n\t\tf.morphometrics.cPaL = fishbase.query_morphometrics(code, \'PaL\')\n\t\tf.morphometrics.cPdL = fishbase.query_morphometrics(code, \'PdL\')\n\t\tf.morphometrics.cPpL = fishbase.query_morphometrics(code, \'PpL\')\n\t\tf.morphometrics.cPpeL = fishbase.query_morphometrics(code, \'PpeL\')\n\t\tf.morphometrics.cED = fishbase.query_morphometrics(code, \'ED\')\n\t\tf.morphometrics.cPoL = fishbase.query_morphometrics(code, \'PoL\')\n\t\tf.morphometrics.cPcL = fishbase.query_morphometrics(code, \'PcL\')\n\t\tf.images_dir = fishbase.query_images_dir(code)\n\t\tfishbase.append_member(f)\t\n\n\tprint \'Elements were sucessfully populated\'\n\treturn fishbase\n\t\ndef get_temp_dir():\n\t""""""Returns the temp directory (/tmp under Linux, C:\\Temp under win)""""""\n\timport platform\n\tp = platform.system()\n\tif \'Linux\' in p:\n\t\treturn \'/tmp\'\n\telif \'Windows\' in p:\n\t\treturn \'\'\'C:\\Temp\'\'\'\n\telse:\n\t\treturn \'/\'\n'"
src/main.py,0,"b'#!/usr/bin/python\n""""""Main Application""""""\n\nfrom base import *\n\nif __name__ == \'__main__\':\n\t#configurations\n\tconf_parser = config_parser.ConfigParser(\'config.spec\',regex=\':\')\n\tglobal fishbase\n\tfishbase = initialize_fishbase(conf_parser.get(\'DATASOURCE_URL\'))\n\tbanner = \'../res/logo/bitmap/banner_90dpi.png\'\n\t\n\t#run\n\tmain_gui_app = main_gui.MainGUIApp()\n\tmain_gui_app._setup(fishbase, banner, get_temp_dir())\n\tmain_gui_app.run()\n'"
doc/source/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Triton FPR documentation build configuration file, created by\n# sphinx-quickstart on Sat Jul 26 17:11:43 2014.\n#\n# This file is execfile()d with the current directory set to its containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys, os\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\nsys.path.insert(0, os.path.abspath(\'../../src\'))\n\n# -- General configuration -----------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be extensions\n# coming with Sphinx (named \'sphinx.ext.*\') or your custom ones.\nextensions = [\'sphinx.ext.autodoc\', \'sphinx.ext.doctest\', \'sphinx.ext.todo\', \'sphinx.ext.coverage\', \'sphinx.ext.mathjax\', \'sphinx.ext.viewcode\']\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'.templates\']\n\n# The suffix of source filenames.\nsource_suffix = \'.rst\'\n\n# The encoding of source files.\n#source_encoding = \'utf-8-sig\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = u\'Triton FPR\'\ncopyright = u\'2014, Marios Papachristou\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = \'v0.1\'\n# The full version, including alpha/beta/rc tags.\nrelease = \'v0.1\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#language = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = \'\'\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = \'%B %d, %Y\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = []\n\n# The reST default role (used for this markup: `text`) to use for all documents.\n#default_role = None\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n\n\n# -- Options for HTML output ---------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \'default\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\n#html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# ""<project> v<release> documentation"".\n#html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n#html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'.static\']\n\n# If not \'\', a \'Last updated on:\' timestamp is inserted at every page bottom,\n# using the given strftime format.\n#html_last_updated_fmt = \'%b %d, %Y\'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n#html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n\n# If false, no module index is generated.\n#html_domain_indices = True\n\n# If false, no index is generated.\n#html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n#html_show_sourcelink = True\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.\n#html_show_sphinx = True\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.\n#html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = \'\'\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n#html_file_suffix = None\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'TritonFPRdoc\'\n\n\n# -- Options for LaTeX output --------------------------------------------------\n\nlatex_elements = {\n# The paper size (\'letterpaper\' or \'a4paper\').\n#\'papersize\': \'letterpaper\',\n\n# The font size (\'10pt\', \'11pt\' or \'12pt\').\n#\'pointsize\': \'10pt\',\n\n# Additional stuff for the LaTeX preamble.\n#\'preamble\': \'\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass [howto/manual]).\nlatex_documents = [\n  (\'index\', \'TritonFPR.tex\', u\'Triton FPR Documentation\',\n   u\'Marios Papachristou\', \'manual\'),\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n#latex_logo = None\n\n# For ""manual"" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n#latex_use_parts = False\n\n# If true, show page references after internal links.\n#latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n#latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n#latex_appendices = []\n\n# If false, no module index is generated.\n#latex_domain_indices = True\n\n\n# -- Options for manual page output --------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (\'index\', \'tritonfpr\', u\'Triton FPR Documentation\',\n     [u\'Marios Papachristou\'], 1)\n]\n\n# If true, show URL addresses after external links.\n#man_show_urls = False\n\n\n# -- Options for Texinfo output ------------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n  (\'index\', \'TritonFPR\', u\'Triton FPR Documentation\',\n   u\'Marios Papachristou\', \'TritonFPR\', \'One line description of project.\',\n   \'Miscellaneous\'),\n]\n\n# Documents to append as an appendix to all manuals.\n#texinfo_appendices = []\n\n# If false, no module index is generated.\n#texinfo_domain_indices = True\n\n# How to display URL addresses: \'footnote\', \'no\', or \'inline\'.\n#texinfo_show_urls = \'footnote\'\n'"
src/lib/__init__.py,0,b''
src/lib/config_parser.py,0,"b'class ConfigParserException(Exception):\n\tpass\n\nclass ConfigParser:\n\t""""""Parses configuration files""""""\n\tdef __init__(self, filename,regex=\'=\'):\n\t\tself.filename = filename\n\t\tself.regex = regex\n\t\tself.things = {}\n\t\twith open(filename, \'r\') as f:\n\t\t\tlines = f.readlines()\n\t\tfor line in lines:\n\t\t\tline = line.split(regex)\n\t\t\tself.things[line[0]] = line[1]\n\t\t\t\n\tdef get(self,p):\n\t\ttry:\n\t\t\treturn self.things[p]\n\t\texcept KeyError:\n\t\t\traise ConfigParserException()\n\t\t\t\n\tdef append(self, p, v):\n\t\tself.things[p] = v\n\n\tdef rewrite(self):\n\t\twith open(self.filename, \'w\') as f:\n\t\t\tfor k in self.things.keys():\n\t\t\t\tf.write(\'{0}={1}\'.format(k,self.things[k]))\n'"
src/lib/contourfeatures.py,8,"b'import cv2\nimport numpy as np\n\nclass Contour:\n    \'\'\' Provides detailed parameter informations about a contour\n\n        Create a Contour instant as follows: c = Contour(src_img, contour)\n                where src_img should be grayscale image.\n\n        Attributes:\n\n        c.area -- gives the area of the region\n        c.parameter -- gives the perimeter of the region\n        c.moments -- gives all values of moments as a dict\n        c.centroid -- gives the centroid of the region as a tuple (x,y)\n        c.bounding_box -- gives the bounding box parameters as a tuple => (x,y,width,height)\n        c.bx,c.by,c.bw,c.bh -- corresponds to (x,y,width,height) of the bounding box\n        c.aspect_ratio -- aspect ratio is the ratio of width to height\n        c.equi_diameter -- equivalent diameter of the circle with same as area as that of region\n        c.extent -- extent = contour area/bounding box area\n        c.convex_hull -- gives the convex hull of the region\n        c.convex_area -- gives the area of the convex hull\n        c.solidity -- solidity = contour area / convex hull area\n        c.center -- gives the center of the ellipse\n        c.majoraxis_length -- gives the length of major axis\n        c.minoraxis_length -- gives the length of minor axis\n        c.orientation -- gives the orientation of ellipse\n        c.eccentricity -- gives the eccentricity of ellipse\n        c.filledImage -- returns the image where region is white and others are black\n        c.filledArea -- finds the number of white pixels in filledImage\n        c.convexImage -- returns the image where convex hull region is white and others are black\n        c.pixelList -- array of indices of on-pixels in filledImage\n        c.maxval -- corresponds to max intensity in the contour region\n        c.maxloc -- location of max.intensity pixel location\n        c.minval -- corresponds to min intensity in the contour region\n        c.minloc -- corresponds to min.intensity pixel location\n        c.meanval -- finds mean intensity in the contour region\n        c.leftmost -- leftmost point of the contour\n        c.rightmost -- rightmost point of the contour\n        c.topmost -- topmost point of the contour\n        c.bottommost -- bottommost point of the contour\n        c.distance_image((x,y)) -- return the distance (x,y) from the contour.\n        c.distance_image() -- return the distance image where distance to all points on image are calculated\n        \'\'\'\n    def __init__(self,img,cnt):\n        self.img = img\n        self.cnt = cnt\n        self.size = len(cnt)\n\n        # MAIN PARAMETERS\n\n        #Contour.area - Area bounded by the contour region\'\'\'\n        self.area = cv2.contourArea(self.cnt)\n\n        # contour perimeter\n        self.perimeter = cv2.arcLength(cnt,True)\n\n        # centroid\n        self.moments = cv2.moments(cnt)\n        if self.moments[\'m00\'] != 0.0:\n            self.cx = self.moments[\'m10\']/self.moments[\'m00\']\n            self.cy = self.moments[\'m01\']/self.moments[\'m00\']\n            self.centroid = (self.cx,self.cy)\n        else:\n            self.centroid = ""Region has zero area""\n\n        # bounding box\n        self.bounding_box=cv2.boundingRect(cnt)\n        (self.bx,self.by,self.bw,self.bh) = self.bounding_box\n\n        # aspect ratio\n        self.aspect_ratio = self.bw/float(self.bh)\n\n        # equivalent diameter\n        self.equi_diameter = np.sqrt(4*self.area/np.pi)\n\n        # extent = contour area/boundingrect area\n        self.extent = self.area/(self.bw*self.bh)\n\n\n        ### CONVEX HULL ###\n\n        # convex hull\n        self.convex_hull = cv2.convexHull(cnt)\n\n        # convex hull area\n        self.convex_area = cv2.contourArea(self.convex_hull)\n\n        # solidity = contour area / convex hull area\n        self.solidity = self.area/float(self.convex_area)\n\n\n        ### ELLIPSE  ###\n\n        self.ellipse = cv2.fitEllipse(cnt)\n\n        # center, axis_length and orientation of ellipse\n        (self.center,self.axes,self.orientation) = self.ellipse\n\n        # length of MAJOR and minor axis\n        self.majoraxis_length = max(self.axes)\n        self.minoraxis_length = min(self.axes)\n\n        # eccentricity = sqrt( 1 - (ma/MA)^2) --- ma= minor axis --- MA= major axis\n        self.eccentricity = np.sqrt(1-(self.minoraxis_length/self.majoraxis_length)**2)\n\n\n        ### CONTOUR APPROXIMATION ###\n\n        self.approx = cv2.approxPolyDP(cnt,0.02*self.perimeter,True)\n\n\n        ### EXTRA IMAGES ###\n\n        # filled image :- binary image with contour region white and others black\n        self.filledImage = np.zeros(self.img.shape[0:2],np.uint8)\n        cv2.drawContours(self.filledImage,[self.cnt],0,255,-1)\n\n        # area of filled image\n        filledArea = cv2.countNonZero(self.filledImage)\n\n        # pixelList - array of indices of contour region\n        self.pixelList = np.transpose(np.nonzero(self.filledImage))\n\n        # convex image :- binary image with convex hull region white and others black\n        self.convexImage = np.zeros(self.img.shape[0:2],np.uint8)\n        cv2.drawContours(self.convexImage,[self.convex_hull],0,255,-1)\n\n\n        ### PIXEL PARAMETERS\n      \n        # mean value, minvalue, maxvalue\n        self.minval,self.maxval,self.minloc,self.maxloc = cv2.minMaxLoc(self.img,mask = self.filledImage)\n        self.meanval = cv2.mean(self.img,mask = self.filledImage)\n\n\n        ### EXTREME POINTS ###\n\n        # Finds the leftmost, rightmost, topmost and bottommost points\n        self.leftmost = tuple(self.cnt[self.cnt[:,:,0].argmin()][0])\n        self.rightmost = tuple(self.cnt[self.cnt[:,:,0].argmax()][0])\n        self.topmost = tuple(self.cnt[self.cnt[:,:,1].argmin()][0])\n        self.bottommost = tuple(self.cnt[self.cnt[:,:,1].argmax()][0])\n        self.extreme = (self.leftmost,self.rightmost,self.topmost,self.bottommost)\n\n    ### DISTANCE CALCULATION\n  \n    def distance_image(self,point=None):\n      \n        \'\'\'find the distance between a point and adjacent point on contour specified. Point should be a tuple or list (x,y)\n            If no point is given, distance to all point is calculated and distance image is returned\'\'\'\n        if type(point) == tuple:\n            if len(point)==2:\n                self.dist = cv2.pointPolygonTest(self.cnt,point,True)\n                return self.dist\n        else:\n            dst = np.empty(self.img.shape)\n            for i in xrange(self.img.shape[0]):\n                for j in xrange(self.img.shape[1]):\n                    dst.itemset(i,j,cv2.pointPolygonTest(self.cnt,(j,i),True))\n\n            dst = dst+127\n            dst = np.uint8(np.clip(dst,0,255))\n\n            # plotting using palette method in numpy\n            palette = []\n            for i in xrange(256):\n                if i<127:\n                    palette.append([2*i,0,0])\n                elif i==127:\n                    palette.append([255,255,255])\n                elif i>127:\n                    l = i-128\n                    palette.append([0,0,255-2*l])\n            palette = np.array(palette,np.uint8)\n            self.h2 = palette[dst]\n            return self.h2\n\n\n#### DEMO ######\nif __name__==\'__main__\':\n\n    import sys\n    if len(sys.argv)>1:\n        image = sys.argv[1]\n    else:\n        image = \'new.bmp\'\n        print ""Usage : python contourfeatures.py <image_file>""\n  \n    im = cv2.imread(image)\n    imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n    thresh = cv2.adaptiveThreshold(imgray,255,0,1,11,2)\n    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n    k = 1000\n    for cnt in contours:\n\n        # first shows the original image\n        im2 = im.copy()\n        c = Contour(imgray,cnt)\n        print c.leftmost,c.rightmost\n        cv2.putText(im2,\'original image\',(20,20), cv2.FONT_HERSHEY_PLAIN, 1.0,(0,255,0))       \n        cv2.imshow(\'image\',im2)\n        if cv2.waitKey(k)==27:\n            break\n      \n        im2 = im.copy()\n\n        # Now shows original contours, approximated contours, convex hull\n        cv2.drawContours(im2,[cnt],0,(0,255,0),4)\n        string1 = \'green : original contour\'\n        cv2.putText(im2,string1,(20,20), cv2.FONT_HERSHEY_PLAIN, 1.0,(0,255,0))\n        cv2.imshow(\'image\',im2)\n        if cv2.waitKey(k)==27:\n            break\n      \n        approx = c.approx\n        cv2.drawContours(im2,[approx],0,(255,0,0),2)\n        string2 = \'blue : approximated contours\'\n        cv2.putText(im2,string2,(20,40), cv2.FONT_HERSHEY_PLAIN, 1.0,(0,255,0))\n        cv2.imshow(\'image\',im2)\n        if cv2.waitKey(k)==27:\n            break\n      \n        hull = c.convex_hull\n        cv2.drawContours(im2,[hull],0,(0,0,255),2)\n        string3 = \'red : convex hull\'\n        cv2.putText(im2,string3,(20,60), cv2.FONT_HERSHEY_PLAIN, 1.0,(0,255,0))\n        cv2.imshow(\'image\',im2)\n        if cv2.waitKey(k)==27:\n            break\n\n        im2 = im.copy()\n\n        # Now mark centroid and bounding box on image\n        (cx,cy) = c.centroid\n        cv2.circle(im2,(int(cx),int(cy)),5,(0,255,0),-1)\n        cv2.putText(im2,\'green : centroid\',(20,20), cv2.FONT_HERSHEY_PLAIN, 1.0,(0,255,0))\n\n        (x,y,w,h) = c.bounding_box\n        cv2.rectangle(im2,(x,y),(x+w,y+h),(0,0,255))\n        cv2.putText(im2,\'red : bounding rectangle\',(20,40), cv2.FONT_HERSHEY_PLAIN, 1.0,(0,255,0))\n\n        (center , axis, angle) = c.ellipse\n        cx,cy = int(center[0]),int(center[1])\n        ax1,ax2 = int(axis[0]),int(axis[1])\n        orientation = int(angle)\n        cv2.ellipse(im2,(cx,cy),(ax1,ax2),orientation,0,360,(255,255,255),3)\n        cv2.putText(im2,\'white : fitting ellipse\',(20,60), cv2.FONT_HERSHEY_PLAIN, 1.0,(255,255,255))\n\n        cv2.circle(im2,c.leftmost,5,(0,255,0),-1)\n        cv2.circle(im2,c.rightmost,5,(0,255,0))\n        cv2.circle(im2,c.topmost,5,(0,0,255),-1)\n        cv2.circle(im2,c.bottommost,5,(0,0,255))\n        cv2.imshow(\'image\',im2)\n        if cv2.waitKey(k)==27:\n            break\n\n      \n        # Now shows the filled image, convex image, and distance image\n        filledimage = c.filledImage\n        cv2.putText(filledimage,\'filledImage\',(20,20), cv2.FONT_HERSHEY_PLAIN, 1.0,255)\n        cv2.imshow(\'image\',filledimage)\n        if cv2.waitKey(k)==27:\n            break\n\n        conveximage = c.convexImage\n        cv2.putText(conveximage,\'convexImage\',(20,20), cv2.FONT_HERSHEY_PLAIN, 1.0,255)\n        cv2.imshow(\'image\',conveximage)\n        if cv2.waitKey(k)==27:\n            break\n\n        distance_image = c.distance_image()\n        cv2.imshow(\'image\',distance_image)\n        cv2.putText(distance_image,\'distance_image\',(20,20), cv2.FONT_HERSHEY_PLAIN, 1.0,(255,255,255))\n        if cv2.waitKey(k)==27:\n            break\n      \ncv2.destroyAllWindows()\n'"
src/lib/detectors.py,0,"b""#!/usr/bin/env python2.7\n\nimport numpy as np\nimport cv2, glob, mstatistics, os\n\nglobal orb, sift, CV_HOMOGENITY_COEFFICIENT\norb = cv2.ORB(); sift = cv2.SIFT()\nCV_HOMOGENITY_COEFFICIENT = 0.15\n\nclass BruteForceORBFeatureMatching:\n\tclass ImageSet:\n\t\tdef __init__(self, name, directory, ext='.jpg'):\n\t\t\tself.name, self.directory, self.images = name, directory, []\n\t\t\timages_list = glob.glob('{0}/*{1}'.format(directory,ext))\n\t\t\tself.orb = orb\n\t\t\tfor _img in images_list:\n\t\t\t\timg = cv2.imread(_img,0); self.images.append(img)\n\t\t\t\t\t\n\t\tdef get_matches(self, query_image,check_homogenity=True):\n\t\t\tmatches = []\n\t\t\tfor image in self.images:\n\t\t\t\tkp1, des1 = self.orb.detectAndCompute(query_image,None)\n\t\t\t\tkp2, des2 = self.orb.detectAndCompute(image,None)\n\t\t\t\n\t\t\t\t# create BFMatcher object\n\t\t\t\tbf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n\t\t\t\t# Match descriptors.\n\t\t\t\t_matches = bf.match(des1,des2)\n\t\t\t\tmatches.append(len(_matches))\n\t\t\t\t# Sort them in the order of their distance.\n\t\t\t\t#_matches = sorted(_matches, key = lambda x:x.distance)\n\t\t\tif len(matches) == 0:\n\t\t\t\treturn 0\n\t\t\tself.cv = mstatistics.coefficients_of_variation(matches)\n\t\t\tif check_homogenity:\n\t\t\t\tif self.cv <= CV_HOMOGENITY_COEFFICIENT:\n\t\t\t\t\treturn mstatistics.mean(matches)\n\t\t\t\telse:\n\t\t\t\t\treturn 0\n\t\t\telse:\n\t\t\t\treturn [mstatistics.mean(matches), max(matches)]\n\t\t\n\tdef __init__(self, image_sets = []):\n\t\tself.orb = orb\n\t\tself.image_sets = image_sets\n\t\t\n\tdef append_image_set(self, s):\n\t\tself.image_sets.append(s)\n\t\n\tdef compare_matches(self, query_image):\n\t\tM = {}\n\t\tfor image_set in self.image_sets:\n\t\t\tM[image_set.get_matches(query_image)[1]] = image_set \n\t\treturn M[max(M.keys())]\n\t\t\n\tdef identify(self, query_image):\n\t\tresult = self.compare_matches(query_image)\n\t\tprint result.name\n\t\t\t\nclass BruteForceSIFTFeatureMatching:\n\tclass ImageSet:\n\t\tdef __init__(self, name, directory, ext='.jpg'):\n\t\t\tself.name, self.directory, self.images = name, directory, []\n\t\t\timages_list = glob.glob('{0}/*{1}'.format(directory,ext))\n\t\t\tself.sift = sift\n\t\t\tfor _img in images_list:\n\t\t\t\timg = cv2.imread(_img,0); self.images.append(img)\n\t\t\t\t\t\n\t\tdef get_matches(self, query_image,check_homogenity=False,k=2):\n\t\t\tgood_matches = []\n\t\t\tfor image in self.images:\n\t\t\t\tkp1, des1 = self.sift.detectAndCompute(query_image,None)\n\t\t\t\tkp2, des2 = self.sift.detectAndCompute(image,None)\n\t\t\t\t# BFMatcher with default params\n\t\t\t\tbf = cv2.BFMatcher()\n\t\t\t\tmatches = bf.knnMatch(des1,des2, k=k)\n\t\t\t\t# Apply ratio test\n\t\t\t\tgood = []\n\t\t\t\tfor m,n in matches:\n\t\t\t\t\tif m.distance < 0.75*n.distance:\n\t\t\t\t\t\tgood.append([m])\t\n\t\t\tgood_matches.append(len(good))\n\t\t\tself.cv = mstatistics.coefficients_of_variation(good_matches)\n\n\t\t\tif len(good_matches) == 0:\n\t\t\t\treturn 0\n\t\t\tif check_homogenity:\n\t\t\t\tif self.cv <= CV_HOMOGENITY_COEFFICIENT:\n\t\t\t\t\treturn mstatistics.mean(good_matches)\n\t\t\t\telse:\n\t\t\t\t\treturn 0\n\t\t\telse:\n\t\t\t\treturn [mstatistics.mean(good_matches), max(good_matches)]\n\t\t\n\tdef __init__(self, image_sets = []):\n\t\tself.sift = sift\n\t\tself.image_sets = image_sets\n\t\t\n\tdef append_image_set(self, s):\n\t\tself.image_sets.append(s)\n\t\n\tdef compare_matches(self, query_image):\n\t\tM = {}\n\t\tfor image_set in self.image_sets:\n\t\t\tM[image_set.get_matches(query_image)[1]] = image_set \n\t\treturn M[max(M.keys())]\n\t\t\n\tdef identify(self, query_image):\n\t\tresult = self.compare_matches(query_image)\n\t\tprint result.name\n\t\t\nclass SIFTHolographyFeatureMatching:\n\tclass ImageSet:\n\t\tdef __init__(self, name, directory, ext='.jpg'):\n\t\t\tself.name, self.directory, self.images = name, directory, []\n\t\t\timages_list = glob.glob('{0}/*{1}'.format(directory,ext))\n\t\t\tself.sift = sift\n\t\t\tfor _img in images_list:\n\t\t\t\timg = cv2.imread(_img,0); self.images.append(img)\n\t\t\t\t\t\n\t\tdef get_matches(self, query_image,check_homogenity=False,k=2):\n\t\t\tgood_matches = []\n\t\t\tfor image in self.images:\n\t\t\t\tkp1, des1 = self.sift.detectAndCompute(query_image,None)\n\t\t\t\tkp2, des2 = self.sift.detectAndCompute(image,None)\n\t\t\t\tFLANN_INDEX_KDTREE = 0\n\t\t\t\tindex_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n\t\t\t\tsearch_params = dict(checks = 50)\n\t\t\t\tflann = cv2.FlannBasedMatcher(index_params, search_params)\n\t\t\t\tmatches = flann.knnMatch(des1,des2,k=2)\n\t\t\t\tgood = []\n\t\t\t\t\n\t\t\t\tfor m,n in matches:\n\t\t\t\t\tif m.distance < 0.7*n.distance:\n\t\t\t\t\t\tgood.append(m)\n\t\t\tgood_matches.append(len(good))\n\t\t\tself.cv = mstatistics.coefficients_of_variation(good_matches)\n\n\t\t\tif len(good_matches) == 0:\n\t\t\t\treturn 0\n\t\t\tif check_homogenity:\n\t\t\t\tif self.cv <= CV_HOMOGENITY_COEFFICIENT:\n\t\t\t\t\treturn mstatistics.mean(good_matches)\n\t\t\t\telse:\n\t\t\t\t\treturn 0\n\t\t\telse:\n\t\t\t\treturn [mstatistics.mean(good_matches), max(good_matches)]\n\t\t\n\tdef __init__(self, image_sets = []):\n\t\tself.sift = sift\n\t\tself.image_sets = image_sets\n\t\t\n\tdef append_image_set(self, s):\n\t\tself.image_sets.append(s)\n\t\n\tdef compare_matches(self, query_image):\n\t\tM = {}\n\t\tfor image_set in self.image_sets:\n\t\t\tM[image_set.get_matches(query_image)[1]] = image_set \n\t\treturn M[max(M.keys())]\n\t\t\n\tdef identify(self, query_image):\n\t\tresult = self.compare_matches(query_image)\n\t\tprint result.name\n\n\n\nif __name__ == '__main__':\n\timport time\n\tt1 = time.time()\n\tq = cv2.imread('../../data/test-images/2.jpg',0)\n\n\ts1 = BruteForceSIFTFeatureMatching().ImageSet('Pagellus Erythrinus', '../../data/train-images/pagellus_erythrinus')\n\ts2 = BruteForceSIFTFeatureMatching().ImageSet('M.B', '../../data/train-images/mullus_barbatus')\n\ts3 = BruteForceSIFTFeatureMatching().ImageSet('H.D', '../../data/train-images/helicolenus_dactylopterus')\n\ts4 = BruteForceSIFTFeatureMatching().ImageSet('S.C', '../../data/train-images/scyliorhinus_canicula')\n\ts = [s1,s2,s3,s4]\n\tb = BruteForceSIFTFeatureMatching(s)\n\tb.identify(q)\n\t\n\th1 = SIFTHolographyFeatureMatching().ImageSet('Pagellus Erythrinus', '../../data/train-images/pagellus_erythrinus')\n\th2 = SIFTHolographyFeatureMatching().ImageSet('M.B', '../../data/train-images/mullus_barbatus')\n\th3 = SIFTHolographyFeatureMatching().ImageSet('H.D', '../../data/train-images/helicolenus_dactylopterus')\n\th4 = SIFTHolographyFeatureMatching().ImageSet('S.C', '../../data/train-images/scyliorhinus_canicula')\n\th = [h1,h2,h3,h4]\n\tH = SIFTHolographyFeatureMatching(h)\n\tH.identify(q)\n\t\n\n"""
src/lib/fish.py,0,"b'from detectors import *\n\nclass Fish:\n\t""""""Stores info for each fish""""""\n\tdef __init__(self, name=\'\', bodycascade=None, fcascades = []):\n\t\tself.name = name; self.bodycascade = bodycascade;\n\t\tself.fcascades = fcascades\n\t\tself.morphometrics = Morphometrics()\n\t\tself.code = None\n\t\tself.images_dir, self.image_set = \'\', None\n\t\t\n\tdef __str__(self):\n\t\treturn self.name\n\t\t\n\tdef get_morphometrics(self):\n\t\tnames =   {\'Head Length\' : self.morphometrics.cHL,\n\t\t\t\t\t\'Fork Length\' : self.morphometrics.cFL,\n\t\t\t\t\t\'Standard Length\': self.morphometrics.cSL,\n\t\t\t\t\t\'Pre-dorsal Length\': self.morphometrics.cPdL,\n\t\t\t\t\t\'Pre-pelvic Length\': self.morphometrics.cPpL,\n\t\t\t\t\t\'Pre-pectoral Length\': self.morphometrics.cPpeL,\n\t\t\t\t\t\'Body depth\': self.morphometrics.cBD,\n\t\t\t\t\t\'Pre-orbital Length\': self.morphometrics.cPoL,\n\t\t\t\t\t\'Pre-caudial fin Length\': self.morphometrics.cPcL,\n\t\t\t\t\t\'Pre-anal Length\': self.morphometrics.cPaL}\n\t\tresult = \'\'\'\'\'\'\t\t\t\t\n\t\tfor k in names.keys():\n\t\t\tresult += \'{0} : {1} of TL\\n\'.format(k,names[k])\n\t\treturn result\n\t\t\t\nclass Morphometrics(Fish):\n\t""""""Morphometrics are stored at this class""""""\n\tdef __init__(self, cHL=0, cFL=0, cSL=0, cPdL=0, cPpL=0, cPpeL=0,cBD=0, cPoL=0, cPcL=0, cED=0, cPaL=0):\n\t\tself.cHL, self.cFL, self.cSL, self.cPdL, self.cPpL, self.cPpeL, self.cBD, self.cPoL, self.cPcL, self.cED, self.cPaL =  cHL, cFL, cSL, cPdL, cPpL, cPpeL, cBD, cPoL, cPcL, cED, cPaL\n\nclass Database:\n\t""""""Handle PostgreSQL databases""""""\n\tdef __init__(self, datasource_url):\n\t\t""""""Initializes a connection and its cursor using the psycopg2 module for talking with Postgres databases"""""" \t\n\t\timport psycopg2 \n\t\tself.connection = psycopg2.connect(datasource_url)\n\t\tself.cursor = self.connection.cursor()\n\t\t\n\tdef execute(self, cmd):\n\t\t""""""Executes a command""""""\n\t\tself.cursor.execute(cmd)\n\t\n\tdef query(self,q):\n\t\t""""""Runs a query and fetches all the information""""""\n\t\tself.cursor.execute(q)\n\t\treturn self.cursor.fetchall()\n\nclass FishDatabase(Database):\n\t""""""Database for fishes""""""\t\n\tdef __init__(self, datasource_url):\n\t\tself.members = []\n\t\tself.db = Database(datasource_url)\n\t\tself.species_list = self.db.query(\'SELECT * FROM ""FISHES_PARAM""\')\n\t\tprint \'Species list populated succesfully\'\n\t\n\tdef append_member(self, m):\n\t\t""""""Appends member to database""""""\n\t\tself.members.append(m)\n\t\t\t\t\n\tdef query_morphometrics(self, code, morph):\n\t\t""""""Returns morphometric value according to specimen\'s code and morphometric code""""""\n\t\tr = self.db.query(\'\'\'SELECT * FROM ""MORPHOMETRICS_MASTER"" WHERE ""CD_SPECIES""=\'{0}\' AND ""CD_COEFFICIENT""=\'{1}\'; \'\'\'.format(code,morph))\n\t\tif len(r) is 0:\n\t\t\treturn 0\n\t\telif len(r) is 1:\n\t\t\treturn r[0][2] \n\t\telse: #return avg\n\t\t\ts = 0\n\t\t\tfor e in r:\n\t\t\t\ts += e[2]\n\t\t\treturn s/len(r)\n\t\t\t\n\tdef query_cascade(self, code, casc):\n\t\t""""""Returns a cascade (.xml file) from the FishDatabase according to specimen\'s code and cascade\'s code""""""\n\t\tr = self.db.query(\'\'\'SELECT * FROM ""CASCADE_MASTER"" WHERE ""CD_SPECIES""=\'{0}\' AND ""CD_CASCADE""=\'{1}\'; \'\'\'.format(code,casc))\n\t\tif len(r) is 0:\n\t\t\treturn None\n\t\telse:\n\t\t\treturn r[0][2]\n\t\t\t\n\tdef query_feature_cascades(self, code):\n\t\t""""""Returns feature cascades from the FishDatabase according to specimen\'s code""""""\n\t\tr = self.db.query(\'\'\'SELECT * FROM ""CASCADE_MASTER"" WHERE ""CD_SPECIES""=\'{0}\' AND ""CD_CASCADE""!=\'BC\';\'\'\'.format(code))\n\t\tfeatures = []\n\t\tif len(r) is 0:\n\t\t\treturn []\n\t\telse:\n\t\t\tfor _r in r:\n\t\t\t\tfeatures.append(_r[3])\n\t\treturn features\n\t\t\t\n\tdef query_code(self, code, name=False):\n\t\t""""""Returns a member of the database depending on its code""""""\n\t\tfor m in self.members:\n\t\t\tif m.code is code:\n\t\t\t\tif name:\n\t\t\t\t\treturn m.name\n\t\t\t\treturn m\n\t\treturn None\n\t\t\n\tdef query_images_dir(self, code):\n\t\t""""""Returns the images directory using an SQL query"""""" \n\t\tr = self.db.query(\'\'\'SELECT * FROM ""IMAGES_DIR"" WHERE ""CD_SPECIES""=\'{0}\';\'\'\'.format(code))\n\t\ttry:\n\t\t\treturn r[0][2]\n\t\texcept IndexError:\n\t\t\treturn None\n\t\t\n\t#open image in 0 mode\n\tdef identify(self,img, draw=False, detectCharacteristics=False):\n\t\t""""""DEPRECATED: Please use identify2. Performs the identification process based on Haar-like features from the members of \'this\' base. Returns a Fish if found, otherwise None""""""\n\t\timport cv2; timg = img.copy()\n\t\tfor m in self.members:\n\t\t\tcascade = cv2.CascadeClassifier(m.bodycascade)\n\t\t\tfeatures = cascade.detectMultiScale(img)\n\t\t\tif len(features) is not 0:\n\t\t\t\tprint m.code, m.name, \'found\'\n\t\t\t\tif draw:\n\t\t\t\t\tfor (x,y,w,h) in features:\n\t\t\t\t\t\ttimg = cv2.rectangle(timg, (x,y), (x+w,y+h), (255,0,0), 2)\n\t\t\t\t\t\tif detectCharacteristics:\n\t\t\t\t\t\t\troi = timg[y:y+h, x:x+w]\n\t\t\t\t\t\t\tfor f in m.fcascades:\n\t\t\t\t\t\t\t\t_cascade = cv2.CascadeClassifier(f)\n\t\t\t\t\t\t\t\t_features = f.detectMultiScale(roi)\n\t\t\t\t\t\t\t\tfor (fx,fy,fw,fh) in _features:\n\t\t\t\t\t\t\t\t\tcv2.rectangle(roi, (fx,fy), (fx+fw, fy+fh), (255,0,0), 2)\n\t\t\t\treturn m\n\t\treturn None \n\t\t\n\tdef identify2(self, img, mode=\'BFORB\', cv_check=False):\n\t\t""""""Performs Identification process. Please specify \'mode\' as:\n\t\t1. BFORB for Brute-force matching with  ORB Features\n\t\t2. BFORB for Brute-force matching SIFT Features\n\t\t3. SIFTH for SIFT and Holography Feature Detection""""""\n\t\td = {}\n\t\tif mode == \'BFORB\':\n\t\t\tfor m in self.members:\n\t\t\t\tif m.images_dir != None:\n\t\t\t\t\tm.image_set = BruteForceORBFeatureMatching().ImageSet(m.name, m.images_dir)\n\t\t\t\t\td[m.image_set.get_matches(img,check_homogenity=cv_check)[1]] = m\n\t\t\tr =  d[max(d.keys())]\n\t\t\tprint r.code, r.name, \'found\'\n\t\t\treturn r\n\t\telif mode == \'BFSIFT\':\n\t\t\tfor m in self.members:\n\t\t\t\tif m.images_dir != None:\n\t\t\t\t\tm.image_set = BruteForceSIFTFeatureMatching().ImageSet(m.name, m.images_dir)\n\t\t\t\t\td[m.image_set.get_matches(img,check_homogenity=False)[1]] = m\n\t\t\tr =  d[max(d.keys())]\n\t\t\tprint r.code, r.name, \'found\'\n\t\t\treturn r\n\t\telif mode == \'SIFTH\':\n\t\t\tfor m in self.members:\n\t\t\t\tif m.images_dir != None:\n\t\t\t\t\tm.image_set = SIFTHolographyFeatureMatching().ImageSet(m.name, m.images_dir)\n\t\t\t\t\td[m.image_set.get_matches(img,check_homogenity=False)[1]] = m\n\t\t\tr =  d[max(d.keys())]\n\t\t\tprint r.code, r.name, \'found\'\n\t\t\treturn r\n\t\telse:\n\t\t\treturn None\n\t\t\t\n'"
src/lib/mstatistics.py,0,"b'import math\n\ndef mean(M):\n\t""""""Arithmetic mean""""""\n\treturn sum(M)/len(M)\n\t\ndef standard_deviation(M):\n\t""""""Standard deviation""""""\n\tsums = 0\n\tx_dash = mean(M)\n\tfor t in M:\n\t\tsums += (t - x_dash)**2\n\treturn math.sqrt(sums)\t\n\t\t\ndef coefficients_of_variation(M):\n\t""""""Coefficients of variation""""""\n\tif len(M) != 0:\n\t\treturn abs(standard_deviation(M)/mean(M))\n\t\ndef get_coefficients_of_variation_dict(D):\n\td  = {}\n\tfor k in D.keys():\n\t\td[k] = coefficients_of_variation(D[k])\n\treturn d\n'"
src/lib/shape_analyzer.py,24,"b'#!/usr/bin/python\n\n#POINTS are of the type (y,x)\nimport cv2,sys,math,random\nimport numpy as np\nfrom mstatistics import *\n\t\ndef midpoint(A,B):\n\tx = (A[0] + B[0])/2\n\ty = (A[1] + B[1])/2\n\treturn x,y\n\t\ndef get_angle(u,v):\n\t""""""Returns the angle of two vectors""""""\t\n\treturn (u.dot(v)/(np.linalg.norm(u)*np.linalg.norm(v)))\n\t\n\t\ndef display_multiple_images(images, title):\n\t""""""Display multiple images via the numpy hstack() function""""""\n\tnimg = np.hstack(images)\n\tcv2.imshow(title, nimg)\n\t\ndef rectangular_crop(points, ry, rx): \n\t""""""Perform a rectangular crop to points of the type (y,x)""""""\n\tpoints2 = points\n\tfor p in points2:\n\t\tif p[0] < ry or p[0] >= len(points2) - ry:\n\t\t\tdel(p)\n\t\telif p[1] < rx or p[1] >= len(points2) - rx:\n\t\t\tdel(p)\n\treturn points2\n\t\nclass ShapeAnalyzer:\n\t""""""Developed for image shape analysis""""""\n\n\tdef __init__(self, image, threshold1=0,threshold2=255):\n\t\t""""""ShapeAnalyzer Class Constructor. It generates results by performing:\n\t\t1. a Gaussian Blur filter\n\t\t2. Otsu\'s Threshold and Binary Threshold\n\t\t3. Canny Edge Detection\n\t\t4. Second binary threshold\n\t\t5. calculations to find extreme points (TM,BM,LM,RM)\n\t\tBesides this, it:\n\t\t6. computes four characteristic vectors connecting the extreme points\n\t\t7. finds the area of the formed polygon via cross product\n\t\t8. finds total length in XY directions via dot product with the base vectors i=[0,1] j=[1,0] if points have type of (y,x)\t\t\n\t\t""""""\n\t\tself.image = image; self.drawn_img = self.image; self.ratio = 1\n\t\t# Otsu\'s thresholding after Gaussian filtering\n\t\tself.blur = cv2.GaussianBlur(self.image,(5,5),0)\n\t\tself.ret,self.th = cv2.threshold(self.blur,threshold1,threshold2,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n\t\n\t\t#Canny Edge Detection and second threshold\n\t\tself.canny_edges = cv2.Canny(self.th, 0, 255)\n\t\tself.ret2,self.th2 = cv2.threshold(self.canny_edges, 127,255, cv2.THRESH_BINARY)\t\t\n\n\t\t#image details\n\t\tself.h,self.w = self.th2.shape[:2]\n\t\tself.bPoints, self.wPoints = [],[]\n\n\t\tindx = np.where(self.th2==0)\n\t\tfor i,j in zip(indx[0], indx[1]):\n\t\t\tself.bPoints.append((i,j))\n\n\t\tindx = np.where(self.th2==255)\n\t\tfor i,j in zip(indx[0], indx[1]):\n\t\t\tself.wPoints.append((i,j))\n\t\t\n\t\tself.bPoints = np.array(self.bPoints)\n\t\tself.wPoints =  np.array(self.wPoints)\n\t\t\n\t\tif len(self.wPoints) <= len(self.bPoints):\n\t\t\tself.points = self.wPoints\n\t\telse:\n\t\t\tself.points = self.bPoints\n\t\t\n\t\t#Extreme points\n\t\tself.topmost = min(self.points, key = lambda t: t[0])\n\t\tself.bottommost = max(self.points, key = lambda t: t[0])\n\t\tself.leftmost = min(self.points, key = lambda t: t[1])\n\t\tself.rightmost = max(self.points, key = lambda t: t[1])\n\t\t\n\t\t#Characteristic Vectors\n\t\tself.v = np.array(self.topmost) - np.array(self.bottommost)\n\t\tself.u = np.array(self.leftmost) - np.array(self.rightmost)\n\t\tself.a = - (np.array(self.topmost) - np.array(self.rightmost))\n\t\tself.b = - (np.array(self.topmost) - np.array(self.leftmost))\n\t\tself.c = - (np.array(self.leftmost) - np.array(self.bottommost))\n\t\tself.d = - (np.array(self.rightmost) - np.array(self.bottommost))\n\t\n\t\t#area of polygon defined by the vectors a,b,c,d\n\n\t\n\t\t#Length in x and y directions\n\t\tself.ly = abs(self.v.dot([1,0]))\n\t\tself.lx = abs(self.u.dot([0,1]))\n\t\t\n\t\tself.__details = [\'Height: \'+ str(self.h), \'Width: \' + str(self.w), \'Total Length (X): \' + str(self.lx), \'Total Length (Y): \' + str(self.ly)]\n\t\t\t\n\t\tself.area = 0.5 * (np.linalg.norm(np.cross(self.a,self.b)) + np.linalg.norm(np.cross(self.c,self.d)))\n\t\tself.rhombus_area = 0.5*(self.lx*self.ly)\n\t\tself.mean_area = mean([self.area, self.rhombus_area])\n\t\tself.area_standard_deviation = standard_deviation([self.area, self.rhombus_area])\t\n\t\t\t\n\tdef print_details(self):\n\t\t""""""Print shape analysis results""""""\n\t\tfor d in self.details:\n\t\t\tprint d\n\t\t\n\tdef draw_extreme_points_lines(self,thickness=1):\n\t\t""""""Draws lines that join the extreme points together""""""\n\t\t#tuples are reversed here\n\t\tcv2.line(self.drawn_img,tuple(self.topmost)[::-1],tuple(self.bottommost)[::-1],(200,0,0),thickness)\n\t\tcv2.line(self.drawn_img,tuple(self.leftmost)[::-1],tuple(self.rightmost)[::-1],(200,0,0),thickness)\n\t\tcv2.line(self.drawn_img,tuple(self.topmost)[::-1],tuple(self.rightmost)[::-1],(150,0,0),thickness)\n\t\tcv2.line(self.drawn_img,tuple(self.topmost)[::-1],tuple(self.leftmost)[::-1],(150,0,0),thickness)\n\t\tcv2.line(self.drawn_img,tuple(self.bottommost)[::-1],tuple(self.leftmost)[::-1],(150,0,0),thickness)\n\t\tcv2.line(self.drawn_img,tuple(self.bottommost)[::-1],tuple(self.rightmost)[::-1],(150,0,0),thickness)\n\t\n\tdef display_steps(self):\n\t\t""""""Displays the shape analysis steps""""""\n\t\ttitle = \'Shape analysis\'\n\t\tdisplay_multiple_images((self.image,self.blur,self.th,self.canny_edges,self.th2d,self.drawn_img),title)\n\t\tcv2.waitKey()\n\n\tdef write_steps(self, _dir):\n\t\t""""""Exports steps to a directory""""""\n\t\tif not(_dir.endswith(\'/\')):\n\t\t\t_dir = _dir + \'/\'\n\t\tcv2.imwrite(_dir + \'gaussian_blur.jpg\', self.blur) \n\t\tcv2.imwrite(_dir + \'otsu_threshold.jpg\', self.th) \n\t\tcv2.imwrite(_dir + \'canny_edges.jpg\', self.canny_edges) \n\t\tcv2.imwrite(_dir + \'final_image.jpg\', self.drawn_img)\n\t\t\n\tdef write_final_image(self, _dir):\n\t\t""""""Writes final image to storage""""""\n\t\tif not(_dir.endswith(\'/\')):\n\t\t\t_dir = _dir + \'/\'\n\t\tcv2.imwrite(_dir + \'final_image.jpg\', self.drawn_img)  \n\n\tdef draw_details(self):\n\t\t""""""Draws the details on the image""""""\n\t\tfor i in range(len(self.__details)):\n\t\t\tcv2.putText(self.drawn_img,self.__details[i],(0,20*(i+1)), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1,(200,200,200),1)\n\t\t\t\n\tdef calculate_morphometrics_according_to_specimen(self, fish):\n\t\t""""""Calculates morphometrics according to specimen""""""\n\t\tself.TL = max((self.lx,self.ly))\n\t\t\n\t\t#TL dependent\t\n\t\tself.HL = fish.morphometrics.cHL * self.TL \n\t\tself.FL = fish.morphometrics.cFL * self.TL\n\t\tself.SL = fish.morphometrics.cSL * self.TL \n\t\tself.PdL = fish.morphometrics.cPdL * self.TL\n\t\tself.PpL = fish.morphometrics.cPpL * self.TL\n\t\tself.PpeL = fish.morphometrics.cPpeL * self.TL\n\t\tself.BD = fish.morphometrics.cPpeL * self.TL\n\t\tself.PcL = fish.morphometrics.cPcL * self.TL\n\t\tself.PoL = fish.morphometrics.cPoL * self.TL\n\t\t\n\t\t#HL dependent\n\t\tself.ED = fish.morphometrics.cED * self.HL\n\t\n\tdef draw_morphometric_line(self, text, coefficient, point, tilt=(0,0), thickness=2):\n\t\t#numpyfied\n\t\ttry:\n\t\t\tA = point[::-1]\n\t\t\tcx, cy =  np.array((int(coefficient),0)), np.array((0,int(coefficient)))\n\t\t\ttilt = np.array(tilt)\n\t\t\tif point is self.topmost:\n\t\t\t\tif text is not \'ED\':\n\t\t\t\t\tB = A + cy\n\t\t\t\t\tM = (A + B)/2.0 - (30,0 )\n\t\t\t\telse:\n\t\t\t\t\tA = (A[0], int(A[1] + self.PoL))\n\t\t\t\t\tB = (A[0], int(A[1] + self.ED))\n\t\t\t\t\tmx,my = midpoint(A,B); mx -= 30; M = (mx,my)\n\t\t\telif point is self.bottommost:\n\t\t\t\tB = A - cy\n\t\t\t\tM = (A + B)/2.0 - (30,0 )\n\n\t\t\telif point is self.leftmost:\n\t\t\t\tB = A + cx\n\t\t\t\tM = (A+B)/2.0 - (0,30)\n\t\t\telif point is self.rightmost:\t\n\t\t\t\tB = A - cx\n\t\t\t\tM = (A+B)/2.0 - (0,30)\n\t\t\telse:\n\t\t\t\treturn\n\t\t\tA += tilt; B+=tilt; M+=tilt; M = M.astype(np.integer)\n\t\t\tc  = random.randint(0,255)\n\t\t\tcv2.line(self.drawn_img, tuple(A), tuple(B), (c,0,0), thickness)\n\t\t\tcv2.putText(self.drawn_img,text,tuple(M), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1,(c,0,0),1)\n\t\texcept NameError:\n\t\t\treturn\n\t\t\t\t\t\n\tdef draw_morphometric_lines_according_to_specimen(self, fish,thickness=2):\n\t\t""""""Draws morphometrics as lines according to defined specimen""""""\n\t\tself.calculate_morphometrics_according_to_specimen(fish)\n\n\t\tself.draw_morphometric_line(\'ED\', self.ED, self.topmost, tilt=(10,0))\n\t\tself.draw_morphometric_line(\'PdL\', self.PdL, self.topmost, tilt=(5,0))\n\t\tself.draw_morphometric_line(\'PpL\', self.PpL, self.topmost, tilt=(15,0))\n\t\tself.draw_morphometric_line(\'PpeL\', self.PpeL, self.topmost, tilt=(20,0))\n\t\tself.draw_morphometric_line(\'PoL\', self.PoL, self.topmost, tilt=(-5,0))\n\t\tself.draw_morphometric_line(\'HL\', self.HL, self.topmost, tilt=(-10,0))\n\t\tself.draw_morphometric_line(\'SL\', self.SL, self.topmost, tilt=(-15,0))\n\t\tself.draw_morphometric_line(\'FL\', self.FL, self.topmost)\n\n\tdef draw_haar_feature(self, xml_file):\n\t\tcascade = cv2.CascadeClassifier(xml_file)\n\t\tfeatures = cascade.detectMultiScale(self.image)\n\t\tfor (x,y,w,h) in features: \n\t\t\tcv2.rectangle(self.drawn_img, (x,y), (x+w, y+h), (255,255,255), 3)\n\t\t\tif len(features) is 1:\n\t\t\t\tprint \'x={0},y={1},w={2},h={3}, cascade={4}\'.format(x,y,w,h,xml_file)\n\t\nclass Contour:\n    \'\'\' Provides detailed parameter informations about a contour\n\n        Create a Contour instant as follows: c = Contour(src_img, contour)\n                where src_img should be grayscale image.\n\n        Attributes:\n\n        c.area -- gives the area of the region\n        c.parameter -- gives the perimeter of the region\n        c.moments -- gives all values of moments as a dict\n        c.centroid -- gives the centroid of the region as a tuple (x,y)\n        c.bounding_box -- gives the bounding box parameters as a tuple => (x,y,width,height)\n        c.bx,c.by,c.bw,c.bh -- corresponds to (x,y,width,height) of the bounding box\n        c.aspect_ratio -- aspect ratio is the ratio of width to height\n        c.equi_diameter -- equivalent diameter of the circle with same as area as that of region\n        c.extent -- extent = contour area/bounding box area\n        c.convex_hull -- gives the convex hull of the region\n        c.convex_area -- gives the area of the convex hull\n        c.solidity -- solidity = contour area / convex hull area\n        c.center -- gives the center of the ellipse\n        c.majoraxis_length -- gives the length of major axis\n        c.minoraxis_length -- gives the length of minor axis\n        c.orientation -- gives the orientation of ellipse\n        c.eccentricity -- gives the eccentricity of ellipse\n        c.filledImage -- returns the image where region is white and others are black\n        c.filledArea -- finds the number of white pixels in filledImage\n        c.convexImage -- returns the image where convex hull region is white and others are black\n        c.pixelList -- array of indices of on-pixels in filledImage\n        c.maxval -- corresponds to max intensity in the contour region\n        c.maxloc -- location of max.intensity pixel location\n        c.minval -- corresponds to min intensity in the contour region\n        c.minloc -- corresponds to min.intensity pixel location\n        c.meanval -- finds mean intensity in the contour region\n        c.leftmost -- leftmost point of the contour\n        c.rightmost -- rightmost point of the contour\n        c.topmost -- topmost point of the contour\n        c.bottommost -- bottommost point of the contour\n        c.distance_image((x,y)) -- return the distance (x,y) from the contour.\n        c.distance_image() -- return the distance image where distance to all points on image are calculated\n        \'\'\'\n    def __init__(self,img,cnt):\n        self.img = img\n        self.cnt = cnt\n        self.size = len(cnt)\n\n        # MAIN PARAMETERS\n\n        #Contour.area - Area bounded by the contour region\'\'\'\n        self.area = cv2.contourArea(self.cnt)\n\n        # contour perimeter\n        self.perimeter = cv2.arcLength(cnt,True)\n\n        # centroid\n        self.moments = cv2.moments(cnt)\n        if self.moments[\'m00\'] != 0.0:\n            self.cx = self.moments[\'m10\']/self.moments[\'m00\']\n            self.cy = self.moments[\'m01\']/self.moments[\'m00\']\n            self.centroid = (self.cx,self.cy)\n        else:\n            self.centroid = ""Region has zero area""\n\n        # bounding box\n        self.bounding_box=cv2.boundingRect(cnt)\n        (self.bx,self.by,self.bw,self.bh) = self.bounding_box\n\n        # aspect ratio\n        self.aspect_ratio = self.bw/float(self.bh)\n\n        # equivalent diameter\n        self.equi_diameter = np.sqrt(4*self.area/np.pi)\n\n        # extent = contour area/boundingrect area\n        self.extent = self.area/(self.bw*self.bh)\n\n\n        ### CONVEX HULL ###\n\n        # convex hull\n        self.convex_hull = cv2.convexHull(cnt)\n\n        # convex hull area\n        self.convex_area = cv2.contourArea(self.convex_hull)\n\n        # solidity = contour area / convex hull area\n        self.solidity = self.area/float(self.convex_area)\n\n\n        ### ELLIPSE  ###\n\n        self.ellipse = cv2.fitEllipse(cnt)\n\n        # center, axis_length and orientation of ellipse\n        (self.center,self.axes,self.orientation) = self.ellipse\n\n        # length of MAJOR and minor axis\n        self.majoraxis_length = max(self.axes)\n        self.minoraxis_length = min(self.axes)\n\n        # eccentricity = sqrt( 1 - (ma/MA)^2) --- ma= minor axis --- MA= major axis\n        self.eccentricity = np.sqrt(1-(self.minoraxis_length/self.majoraxis_length)**2)\n\n\n        ### CONTOUR APPROXIMATION ###\n\n        self.approx = cv2.approxPolyDP(cnt,0.02*self.perimeter,True)\n\n\n        ### EXTRA IMAGES ###\n\n        # filled image :- binary image with contour region white and others black\n        self.filledImage = np.zeros(self.img.shape[0:2],np.uint8)\n        cv2.drawContours(self.filledImage,[self.cnt],0,255,-1)\n\n        # area of filled image\n        filledArea = cv2.countNonZero(self.filledImage)\n\n        # pixelList - array of indices of contour region\n        self.pixelList = np.transpose(np.nonzero(self.filledImage))\n\n        # convex image :- binary image with convex hull region white and others black\n        self.convexImage = np.zeros(self.img.shape[0:2],np.uint8)\n        cv2.drawContours(self.convexImage,[self.convex_hull],0,255,-1)\n\n\n        ### PIXEL PARAMETERS\n      \n        # mean value, minvalue, maxvalue\n        self.minval,self.maxval,self.minloc,self.maxloc = cv2.minMaxLoc(self.img,mask = self.filledImage)\n        self.meanval = cv2.mean(self.img,mask = self.filledImage)\n\n\n        ### EXTREME POINTS ###\n\n        # Finds the leftmost, rightmost, topmost and bottommost points\n        self.leftmost = tuple(self.cnt[self.cnt[:,:,0].argmin()][0])\n        self.rightmost = tuple(self.cnt[self.cnt[:,:,0].argmax()][0])\n        self.topmost = tuple(self.cnt[self.cnt[:,:,1].argmin()][0])\n        self.bottommost = tuple(self.cnt[self.cnt[:,:,1].argmax()][0])\n        self.extreme = (self.leftmost,self.rightmost,self.topmost,self.bottommost)\n\n    ### DISTANCE CALCULATION\n  \n    def distance_image(self,point=None):\n      \n        \'\'\'find the distance between a point and adjacent point on contour specified. Point should be a tuple or list (x,y)\n            If no point is given, distance to all point is calculated and distance image is returned\'\'\'\n        if type(point) == tuple:\n            if len(point)==2:\n                self.dist = cv2.pointPolygonTest(self.cnt,point,True)\n                return self.dist\n        else:\n            dst = np.empty(self.img.shape)\n            for i in xrange(self.img.shape[0]):\n                for j in xrange(self.img.shape[1]):\n                    dst.itemset(i,j,cv2.pointPolygonTest(self.cnt,(j,i),True))\n\n            dst = dst+127\n            dst = np.uint8(np.clip(dst,0,255))\n\n            # plotting using palette method in numpy\n            palette = []\n            for i in xrange(256):\n                if i<127:\n                    palette.append([2*i,0,0])\n                elif i==127:\n                    palette.append([255,255,255])\n                elif i>127:\n                    l = i-128\n                    palette.append([0,0,255-2*l])\n            palette = np.array(palette,np.uint8)\n            self.h2 = palette[dst]\n            return self.h2\n\n\tdef demonstrate():\n\t   \n\t    if len(sys.argv)>1:\n\t        image = sys.argv[1]\n\t    else:\n\t        image = \'new.bmp\'\n\t        print ""Usage : python contourfeatures.py <image_file>""\n\t  \n\t    im = cv2.imread(image)\n\t    imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n\t    thresh = cv2.adaptiveThreshold(imgray,255,0,1,11,2)\n\t    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n\t    k = 1000\n\t    for cnt in contours:\n\t\n\t        # first shows the original image\n\t        im2 = im.copy()\n\t        c = Contour(imgray,cnt)\n\t        print c.leftmost,c.rightmost\n\t        cv2.putText(im2,\'original image\',(20,20), cv2.FONT_HERSHEY_PLAIN, 1.0,(0,255,0))       \n\t        cv2.imshow(\'image\',im2)\n\t        if cv2.waitKey(k)==27:\n\t            break\n\t      \n\t        im2 = im.copy()\n\t\n\t        # Now shows original contours, approximated contours, convex hull\n\t        cv2.drawContours(im2,[cnt],0,(0,255,0),4)\n\t        string1 = \'green : original contour\'\n\t        cv2.putText(im2,string1,(20,20), cv2.FONT_HERSHEY_PLAIN, 1.0,(0,255,0))\n\t        cv2.imshow(\'image\',im2)\n\t        if cv2.waitKey(k)==27:\n\t            break\n\t      \n\t        approx = c.approx\n\t        cv2.drawContours(im2,[approx],0,(255,0,0),2)\n\t        string2 = \'blue : approximated contours\'\n\t        cv2.putText(im2,string2,(20,40), cv2.FONT_HERSHEY_PLAIN, 1.0,(0,255,0))\n\t        cv2.imshow(\'image\',im2)\n\t        if cv2.waitKey(k)==27:\n\t            break\n\t      \n\t        hull = c.convex_hull\n\t        cv2.drawContours(im2,[hull],0,(0,0,255),2)\n\t        string3 = \'red : convex hull\'\n\t        cv2.putText(im2,string3,(20,60), cv2.FONT_HERSHEY_PLAIN, 1.0,(0,255,0))\n\t        cv2.imshow(\'image\',im2)\n\t        if cv2.waitKey(k)==27:\n\t            break\n\t\n\t        im2 = im.copy()\n\t\n\t        # Now mark centroid and bounding box on image\n\t        (cx,cy) = c.centroid\n\t        cv2.circle(im2,(int(cx),int(cy)),5,(0,255,0),-1)\n\t        cv2.putText(im2,\'green : centroid\',(20,20), cv2.FONT_HERSHEY_PLAIN, 1.0,(0,255,0))\n\t\n\t        (x,y,w,h) = c.bounding_box\n\t        cv2.rectangle(im2,(x,y),(x+w,y+h),(0,0,255))\n\t        cv2.putText(im2,\'red : bounding rectangle\',(20,40), cv2.FONT_HERSHEY_PLAIN, 1.0,(0,255,0))\n\t\n\t        (center , axis, angle) = c.ellipse\n\t        cx,cy = int(center[0]),int(center[1])\n\t        ax1,ax2 = int(axis[0]),int(axis[1])\n\t        orientation = int(angle)\n\t        cv2.ellipse(im2,(cx,cy),(ax1,ax2),orientation,0,360,(255,255,255),3)\n\t        cv2.putText(im2,\'white : fitting ellipse\',(20,60), cv2.FONT_HERSHEY_PLAIN, 1.0,(255,255,255))\n\t\n\t        cv2.circle(im2,c.leftmost,5,(0,255,0),-1)\n\t        cv2.circle(im2,c.rightmost,5,(0,255,0))\n\t        cv2.circle(im2,c.topmost,5,(0,0,255),-1)\n\t        cv2.circle(im2,c.bottommost,5,(0,0,255))\n\t        cv2.imshow(\'image\',im2)\n\t        if cv2.waitKey(k)==27:\n\t            break\n\t\n\t      \n\t        # Now shows the filled image, convex image, and distance image\n\t        filledimage = c.filledImage\n\t        cv2.putText(filledimage,\'filledImage\',(20,20), cv2.FONT_HERSHEY_PLAIN, 1.0,255)\n\t        cv2.imshow(\'image\',filledimage)\n\t        if cv2.waitKey(k)==27:\n\t            break\n\t\n\t        conveximage = c.convexImage\n\t        cv2.putText(conveximage,\'convexImage\',(20,20), cv2.FONT_HERSHEY_PLAIN, 1.0,255)\n\t        cv2.imshow(\'image\',conveximage)\n\t        if cv2.waitKey(k)==27:\n\t            break\n\t\t\n\t        distance_image = c.distance_image()\n\t        cv2.imshow(\'image\',distance_image)\n\t        cv2.putText(distance_image,\'distance_image\',(20,20), cv2.FONT_HERSHEY_PLAIN, 1.0,(255,255,255))\n\t        if cv2.waitKey(k)==27:\n\t            break\n\t      \n\tcv2.destroyAllWindows()\n\t\n\n\t\nif __name__ == \'__main__\':\n\timg = cv2.imread(\'/home/marios/2.jpg\',0)\n\tfrom fish import Fish\n\t#a dumb fish\n\tf1 = Fish(name=\'f1\')\n\tf1.morphometrics.cHL = 0.3\n\tf1.morphometrics.cSL = 0.7\n\tf1.morphometrics.cFL = 0.7\n\tf1.morphometrics.cPoL = 0.2\n\tf1.morphometrics.cED = 0.05\n\ts = ShapeAnalyzer(img)\n\ts.draw_extreme_points_lines()\n\t#s.draw_details()\n\ts.draw_morphometric_lines_according_to_specimen(f1)\n\ts.write_steps(\'/home/marios\')\n\tprint s.TL\n\tprint s.HL\n\tprint s.area\n\tprint s.rhombus_area\n\tprint s.mean_area\n\tprint s.area_standard_deviation\n'"
src/scripts/__init__.py,0,"b""__version__ = '0.1'\n"""
src/scripts/detect.py,0,"b'#!/usr/bin/python\n#scripts.detector\n#OBSOLETE: Used only for tests or as an assistant script for quick tests\n\nimport sys\nimport cv,cv2\nimport numpy\n\n""""""Feature detector script""""""\n__doc__ = \'\'\'Usage: ./detect.py /dir/image.jpg /dir2/cascade.xml\'\'\'\n\ndef detect(image,cascade):\n\t""""""Haar-like Feature detection function. OBSOLETE: Uses cv (v1)""""""\n\tbitmap = cv.fromarray(image)\n\tfaces = cv.HaarDetectObjects(bitmap, cascade, cv.CreateMemStorage(0))\n\tif faces:\n\t\tfor (x,y,w,h),n in faces:  \n\t\t\tcv2.rectangle(image,(x,y),(x+w,y+h),(255,255,255),3)\n\treturn image\n\n\t\ndef detect2(image, cascade):\n\t""""""Haar-like Feature detection function. Uses cv2""""""\n\t\n\tfeatures = cascade.detectMultiScale(image)\n\tif len(features) is not 0:\n\t\tfor (x,y,w,h) in features:\n\t\t\tcv2.rectangle(image, (x,y), (x+w, y+h), (255,255,255), 3)\n\t\telems = [image, len(features), True, features]\n\telse:\n\t\telems = [0,0,False,0]\n\treturn elems\n\t\n\nif __name__ == ""__main__"":\n\tif len(sys.argv) is not 3:\n\t\traise Exception(\'Bad Input\')\n\t\texit()\n\telse:\n\t\tcascade = cv2.CascadeClassifier(sys.argv[2])\n\t\timg = cv2.imread(sys.argv[1])\n\t\telements  = detect2(img, cascade)\n\t\ttitle = \'Found {0} matches\'.format(elements[1])\n\t\tcv2.imshow(title, img)\n\t\tprint title\n\t\tfor e in elements[3]:\n\t\t\tprint str(e)\t\n\t\tcv2.waitKey()\n'"
src/scripts/grayscaler.py,0,"b'import os,sys, cv2\nfrom PIL import Image\nimport numpy as np\n\n""""""A small script for converting images from user-defined directories to grayscale""""""\n\n\n__doc__ = \'\'\' Usage: ./grayscaler.py /dir/of/images\'\'\'\n\ndef main(in_dir):\n\tos.chdir(in_dir)\n\tfilelist = os.listdir(\'.\')\n\tfor e in filelist:\n\t\ttry:\n\t\t\tImage.open(e)\n\t\t\timg = cv2.imread(e)\n\t\t\timg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\t\t\tcv2.imwrite(e, img)\n\t\texcept IOError:\n\t\t\tprint \'{0} is not a valid image\'.format(e)\n\t\t\tcontinue \t\n\t\nif __name__ == \'__main__\':\n\tif len(sys.argv) is not 2:\n\t\traise Exception(\'Bad input\')\n\t\tprint __doc__\n\t\texit()\n\telse:\n\t\tinput_dir = sys.argv[1]\n\t\tmain(input_dir)\n'"
src/scripts/mergevec.py,0,"b'import sys\nimport glob\nimport struct\nimport argparse\nimport traceback\n\n\ndef exception_response(e):\n\texc_type, exc_value, exc_traceback = sys.exc_info()\n\tlines = traceback.format_exception(exc_type, exc_value, exc_traceback)\n\tfor line in lines:\n\t\tprint(line)\n\ndef get_args():\n\tparser = argparse.ArgumentParser()\n\tparser.add_argument(\'-v\', dest=\'vec_directory\')\n\tparser.add_argument(\'-o\', dest=\'output_filename\')\n\targs = parser.parse_args()\n\treturn (args.vec_directory, args.output_filename)\n\ndef merge_vec_files(vec_directory, output_vec_file):\n\t""""""\n\tIterates throught the .vec files in a directory and combines them. \n\n\t(1) Iterates through files getting a count of the total images in the .vec files\n\t(2) checks that the image sizes in all files are the same\n\n\tThe format of a .vec file is:\n\n\t4 bytes denoting number of total images (int)\n\t4 bytes denoting size of images (int)\n\t2 bytes denoting min value (short)\n\t2 bytes denoting max value (short)\n\n\tex: \t6400 0000 4605 0000 0000 0000\n\n\t\thex\t\t6400 0000  \t4605 0000 \t\t0000 \t\t0000\n\t\t\t   \t# images  \tsize of h * w\t\tmin\t\tmax\n\t\tdec\t    \t100     \t1350\t\t\t0 \t\t0\n\t\n\t:type vec_directory: string\n\t:param vec_directory: Name of the directory containing .vec files to be combined. \n\t\t\t\tDo not end with slash. Ex: \'/Users/username/Documents/vec_files\'\n\n\t:type output_vec_file: string\n\t:param output_vec_file: Name of aggregate .vec file for output. \n\t\tEx: \'/Users/username/Documents/aggregate_vec_file.vec\'\n\n\t""""""\n\t\n\t# Check that the .vec directory does not end in \'/\' and if it does, remove it.\n\tif vec_directory.endswith(\'/\'):\n\t\tvec_directory = vec_directory[:-1]\n\t# Get .vec files\n\tfiles = glob.glob(\'{0}/*.vec\'.format(vec_directory))\n\n\t# Check to make sure there are .vec files in the directory\n\tif len(files) <= 0:\n\t\tprint(\'Vec files to be mereged could not be found from directory: {0}\'.format(vec_directory))\n\t\tsys.exit(1)\n\t# Check to make sure there are more than one .vec files\n\tif len(files) == 1:\n\t\tprint(\'Only 1 vec file was found in directory: {0}. Cannot merge a single file.\'.format(vec_directory))\n\t\tsys.exit(1)\n\t\t\n\n\t# Get the value for the first image size\n\tprev_image_size = 0\n\ttry:\n\t\twith open(files[0], \'rb\') as vecfile:\n\t\t\tcontent = \'\'.join(vecfile.readlines())\n\t\t\tval = struct.unpack(\'<iihh\', content[:12])\n\t\t\tprev_image_size = val[1]\n\texcept IOError as e:\n\t\tprint(\'An IO error occured while processing the file: {0}\'.format(f))\n\t\texception_response(e)\n\n\n\t# Get the total number of images\n\ttotal_num_images = 0\n\tfor f in files:\n\t\ttry:\n\t\t\twith open(f, \'rb\') as vecfile:\t\n\t\t\t\tcontent = \'\'.join(vecfile.readlines())\n\t\t\t\tval = struct.unpack(\'<iihh\', content[:12])\n\t\t\t\tnum_images = val[0]\n\t\t\t\timage_size = val[1]\n\t\t\t\tif image_size != prev_image_size:\n\t\t\t\t\terr_msg = """"""The image sizes in the .vec files differ. These values must be the same. \\n The image size of file {0}: {1}\\n \n\t\t\t\t\t\tThe image size of previous files: {0}"""""".format(f, image_size, prev_image_size)\n\t\t\t\t\tsys.exit(err_msg)\n\n\t\t\t\ttotal_num_images += num_images\n\t\texcept IOError as e:\n\t\t\tprint(\'An IO error occured while processing the file: {0}\'.format(f))\n\t\t\texception_response(e)\n\n\t\n\t# Iterate through the .vec files, writing their data (not the header) to the output file\n\t# \'<iihh\' means \'little endian, int, int, short, short\'\n\theader = struct.pack(\'<iihh\', total_num_images, image_size, 0, 0)\n\ttry:\n\t\twith open(output_vec_file, \'wb\') as outputfile:\n\t\t\toutputfile.write(header)\n\n\t\t\tfor f in files:\n\t\t\t\twith open(f, \'rb\') as vecfile:\n\t\t\t\t\tcontent = \'\'.join(vecfile.readlines())\n\t\t\t\t\tdata = content[12:]\n\t\t\t\t\toutputfile.write(data)\n\texcept Exception as e:\n\t\texception_response(e)\n\n\nif __name__ == \'__main__\':\n\tvec_directory, output_filename = get_args()\n\tif not vec_directory:\n\t\tsys.exit(\'mergvec requires a directory of vec files. Call mergevec.py with -v /your_vec_directory\')\n\tif not output_filename:\n\t\tsys.exit(\'mergevec requires an output filename. Call mergevec.py with -o your_output_filename\')\n\n\tmerge_vec_files(vec_directory, output_filename)\n'"
src/scripts/objectmarker.py,0,"b'#!/usr/bin/python\n \n__doc__ = \'\'\'\n# object-marker\n\nA object marker based on OpenCV.\n\n## Feature\n\n- Cross platform (platform can run OpenCV)\n- Easy to use\n\n## Usage\n\n`object-marker object-output-filename background-output-filename \'file-glob-pattern\'`\n\n- `left mouse button` drag to mark object\n- `right mouse button` to cancle mark\n- `a` to add mark-object\n- `s` to save\n- `b` toggle current image file is a backgound (contain no object) or not\n- `q` exit\n- `<left>` save & previous image\n- `<right>` save & next image\n\'\'\'\n \nimport cv,sys,os,glob\n \nIMG_SIZE = (300,300)\nIMG_CHAN = 3\nIMG_DEPTH = cv.IPL_DEPTH_8U\ncurrent_image = cv.CreateImage(IMG_SIZE, IMG_DEPTH, IMG_CHAN)\nimage2 = cv.CreateImage(IMG_SIZE, IMG_DEPTH, IMG_CHAN) \nhas_roi = False\nroi_x0 = 0\nroi_y0 = 0\nroi_x1 = 0\nroi_y1 = 0\ncur_mouse_x = 0\ncur_mouse_y = 0\nnum_of_rec = 0\ndraging = False\n#window_name = ""<Space> to save and load next, <X> to skip, <ESC> to exit.""\ncurrent_img_file_name = """"\nwindow_name = ""Object Marker for Python using OpenCV. Import module and use help(objectmarker) to display help""\n\ntable_file_name = \'\'\nbackground_file_name = \'\'\nimage_file_glob = \'\'\n \nrect_table = {}\nbackground_files = set()\n\ndef read_rect_table() :\n    if os.path.exists(table_file_name) :\n        fin = open(table_file_name)\n        lines = fin.readlines()\n        cnt_all_rects = 0\n        for line in lines :\n            tokens = line.split()\n            pic_name = tokens[0]\n            rect_table[pic_name] = set()\n            num_rect = int(tokens[1])\n            cnt_all_rects += num_rect\n            for i in range(0, num_rect) :\n                rect = tuple(tokens[i * 4 + 2 : i * 4 + 6])\n                rect = tuple([int(v) for v in rect])\n                rect_table[pic_name].add(rect)\n        print \'Reading %d objects in %d images\' % (cnt_all_rects, len(lines))\n\n    if os.path.exists(background_file_name) :\n        fin = open(background_file_name)\n        lines = fin.readlines()\n        for line in lines :\n            background_files.add(line.strip())\n\ndef write_rect_table() :\n    fout = open(table_file_name, \'w\')\n    for (f, rect_set) in rect_table.iteritems() :\n        if len(rect_set) == 0 :\n            continue\n        fout.write(f + \'  \' + str(len(rect_set)))\n        for r in rect_set :\n            rect_str = \'  %d %d %d %d\' % r\n            fout.write(rect_str)\n        fout.write(\'\\n\')\n\n    fout = open(background_file_name, \'w\')\n    for f in background_files :\n        fout.write(f + \'\\n\')\n\ndef clear_roi() :\n    global has_roi\n    global roi_x0\n    global roi_y0\n    global roi_x1\n    global roi_y1\n\n    has_roi = False\n    roi_x0 = 0\n    roi_y0 = 0\n    roi_x1 = 0\n    roi_y1 = 0\n\ndef redraw() :\n    global draging\n    global has_roi\n    global roi_x0\n    global roi_y0\n    global cur_mouse_x\n    global cur_mouse_y\n    #Redraw ROI selection\n    image2 = cv.CloneImage(current_image)\n\n    # redraw old rect\n    pen_width = 4\n    if rect_table.has_key(current_img_file_name) :\n        rects_in_table = rect_table[current_img_file_name]\n        for r in rects_in_table :\n            cv.Rectangle(image2, (r[0], r[1]), (r[0] + r[2], r[1] + r[3]), cv.CV_RGB(0,255,0),pen_width)\n\n    # redraw new rect\n    if has_roi :\n        cv.Rectangle(image2, (roi_x0, roi_y0), (cur_mouse_x, cur_mouse_y), cv.CV_RGB(255,0,255),pen_width)\n\n    # draw background\n    if current_img_file_name in background_files :\n        cv.Line(image2, (0, 0), (image2.width, image2.height), cv.CV_RGB(255, 0, 0))\n        cv.Line(image2, (0, image2.height), (image2.width, 0), cv.CV_RGB(255, 0, 0))\n\n    cv.ShowImage(window_name, image2)\n\ndef remove_rect(x, y):\n    if not rect_table.has_key(current_img_file_name) :\n        return\n\n    rects_contain_xy = set()\n    rects_in_table = rect_table[current_img_file_name]\n    for r in rects_in_table :\n        if x < r[0] : continue\n        if y < r[1] : continue\n        if x > r[0] + r[2] : continue\n        if y > r[1] + r[3] : continue\n        rects_contain_xy.add(r)\n\n    for r in rects_contain_xy :\n        rects_in_table.remove(r)\n\n    rect_table[current_img_file_name] = rects_in_table\n    if len(rects_contain_xy) > 0 :\n        redraw()\n\n    write_rect_table()\n\ndef on_mouse(event, x, y, flag, params):\n    global current_img_file_name\n    global draging\n    global has_roi\n    global roi_x0\n    global roi_y0\n    global roi_x1\n    global roi_y1\n    global cur_mouse_x\n    global cur_mouse_y\n\n    cur_mouse_x = x\n    cur_mouse_y = y\n\n    if (event == cv.CV_EVENT_LBUTTONDOWN):\n        draging = True\n        has_roi = True\n        roi_x0 = x\n        roi_y0 = y\n    elif (event == cv.CV_EVENT_LBUTTONUP):\n        draging = False\n        has_roi = True\n        roi_x1 = x\n        roi_y1 = y\n\n        # normalize\n        if roi_x1 < roi_x0 :\n            roi_x0, roi_x1 = roi_x1, roi_x0 \n        if roi_y1 < roi_y0 :\n            roi_y0, roi_y1 = roi_y1, roi_y0 \n\n    elif (event == cv.CV_EVENT_RBUTTONDOWN):\n        clear_roi()\n        redraw()\n\n    elif (event == cv.CV_EVENT_MOUSEMOVE):\n        if draging:\n            redraw()\n \ndef object_detection():\n \n    global current_image\n    global current_img_file_name\n    global has_roi\n    global roi_x0\n    global roi_y0\n    global roi_x1\n    global roi_y1\n\n    iKey = 0\n    \n    files = glob.glob(image_file_glob)\n    if len(files) == 0 :\n        print ""No files match glob pattern""\n        return\n \n    files = [os.path.abspath(f) for f in files]\n    files.sort()\n \n    # init GUI\n    cv.NamedWindow(window_name, 1)\n    cv.SetMouseCallback(window_name, on_mouse, None)\n \n    sys.stderr.write(""Opening directory..."")\n    # init output of rectangles to the info file\n    #os.chdir(input_directory)\n    sys.stderr.write(""done.\\n"")\n \n    current_file_index = 0\n \n    while True :\n\n        current_img_file_name = files[current_file_index]\n\n        num_of_rec = 0\n        sys.stderr.write(""Loading current_image (%d/%d) %s...\\n"" % (current_file_index + 1, len(files), current_img_file_name))\n \n        try: \n            current_image = cv.LoadImage(current_img_file_name, 1)\n        except IOError: \n            sys.stderr.write(""Failed to load current_image %s.\\n"" % current_img_file_name)\n            return -1\n \n        #  Work on current current_image\n        #cv.ShowImage(window_name, current_image)\n        redraw()\n\n        # Need to figure out waitkey returns.\n        # <Space> =  32     add rectangle to current image\n        # <left>  =  81     save & next\n        # <right> =  83     save & prev\n        # <a>     =  97     add rect to table\n        # <b>     =  98     toggle file is background or not\n        # <d>     = 100     remove old rect\n        # <q>     = 113     exit program\n        # <s>     = 115     save rect table\n        # <x>     = 136     skip image\n        iKey = cv.WaitKey(0) % 255\n        # This is ugly, but is actually a simplification of the C++.\n        #sys.stderr.write(str(iKey) + \'\\n\')\n        if draging :\n            continue\n\n        if iKey == 81:\n            current_file_index -= 1\n            if current_file_index == -1 :\n                current_file_index = len(files) - 1\n            clear_roi()\n        elif iKey == 83:\n            current_file_index += 1\n            if current_file_index == len(files) :\n                current_file_index = 0\n            clear_roi()\n        elif iKey == 113:\n            cv.DestroyWindow(window_name)\n            return 0\n        elif iKey == 97:\n            rect_table.setdefault(current_img_file_name, set()).add((roi_x0, roi_y0, roi_x1 - roi_x0, roi_y1 - roi_y0)) \n            clear_roi()\n            write_rect_table()\n            redraw()\n        elif iKey == 98:\n            if current_img_file_name in background_files :\n                background_files.remove(current_img_file_name)\n            else :\n                background_files.add(current_img_file_name)\n        elif iKey == 100:\n            remove_rect(cur_mouse_x, cur_mouse_y)\n        elif iKey == 115:\n            write_rect_table()\n        elif iKey == 136:\n            sys.stderr.write(""Skipped %s.\\n"" % current_file_index)\n        \nif __name__ == \'__main__\':\n    print sys.argv\n    if (len(sys.argv) != 4):\n        sys.stderr.write(""usage: %s objects.txt background.txt \'image_glob_pattern\'\\n"" % sys.argv[0])\n        sys.stderr.write(""example: %s objects.txt background.txt \'training_img/*.png\'\\n"" % sys.argv[0])\n    else:\n        table_file_name      = sys.argv[1]\n        background_file_name = sys.argv[2]\n        image_file_glob      = sys.argv[3]\n\n        read_rect_table()\n        object_detection()\n\n'"
src/scripts/resizer.py,0,"b""#!/usr/bin/python\n\nimport cv2,sys, Image, os\nimport numpy as np\n\n__doc__ = '''Usage: ./resizer.py dir1/ <scale factor>'''\n\ndef resize_images_in_directory(input_dir, scale_factor, replace=True):\n\tos.chdir(input_dir)\n\tfilelist = os.listdir('.')\n\tfor e in filelist:\n\t\ttry:\n\t\t\tImage.open(e)\n\t\t\timg = cv2.imread(e)\n\t\t\th,w = img.shape[:2]\n\t\t\trimg = cv2.resize(img, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)\n\t\t\tif not(replace):\n\t\t\t\te = 'scaled_' + e\n\t\t\tcv2.imwrite(e, rimg)\n\t\t\t\n\t\texcept IOError:\t\n\t\t\tpass \n\nif __name__ == '__main__':\n\t_indir = sys.argv[1]\n\t_sf = float(sys.argv[2])\n\tresize_images_in_directory(_indir, _sf, replace=True)\n\tprint 'Done'\n\t\n\t\n"""
src/scripts/trainer.py,0,"b'#!/usr/bin/env python2.7\n\nfrom kivy.app import App\nfrom kivy.uix.boxlayout import BoxLayout\nimport os,sys,platform\nimport psycopg2 as db\nimport mergevec\n\n\nclass Trainer:\n\t\n\tdef __init__(self):\n\t\tself.cs_cmd = \'opencv_createsamples\'\n\t\tself.ht_cmd = \'opencv_traincascade\' #opencv_traincascade\n\t\tif platform.system() is \'Windows\':\n\t\t\tself.cs_cmd += \'.exe\'\n\t\t\tself.ht_cmd += \'.exe\'\n\t\n\tdef tcreate_samples(self,input_filename, output_filename, number, width, height):\n\t\t""""""Create PS via opencv_createsamples\n\t\t\tE.g.: opencv_createsamples -info marked_positives.info -vec data/positives.vec -num 1000 -w 20 -h 20\n\t\t\tWhere:\n\t\t\ti. -num: The number of samples\n\t\t\tii. -w, -h: The min dimensions of the object""""""\n\t\t\n\t\tos.system(\'{0} -info {1} -vec {2} -num {3} -w {4} -h {5}\'.format(self.cs_cmd, input_filename, output_filename, number, width, height))\n\t\treturn 1\n\t\t\n\tdef thaar_training(self, output_dir, vec_filename, npos, nneg, nstage, malloc, mode, width, height, featureType, bg_filename):\n\t\t""""""Do a Haar Training \n\t\topencv_haartraining -data data/cascade.xml -vec data/positives.vec -bg \n\t\tnegatives/negatives.info -npos 2890 -nneg 2977 -nstage 20 -mem 1000 -mode ALL -w 20 -h 20""""""\n\t\tos.system(\'{0} -data {1} -vec {2} -bg {3} -npos {4} -nneg{5} -nstage {6} -mem {7} -mode {8} -w {9} -h {10} -featureType {11}\'.format(self.ht_cmd, output_dir, vec_filename, bg_filename, npos, nneg, nstage, malloc, mode, width, height, featureType))\n\t\treturn 1\t\n\t\t\nclass Interface(BoxLayout):\n\t\n\tdef connect(self):\n\t\tglobal conn, cursor,trainer\n\t\ttrainer = Trainer()\n\t\t_durl = str(self.ids[\'datasource_input\'].text)\n\t\ttry:\n\t\t\tconn = db.connect(_durl)\n\t\t\tself.ids[\'status\'].text = \'Status: Connected\'\n\t\t\tcursor = conn.cursor()\n\t\texcept db.OperationalError:\n\t\t\tself.ids[\'status\'].text = \'Status: Error\'\n\t\t\t\n\tdef create_samples(self):\n\t\twhile True:\n\t\t\ttry:\n\t\t\t\tcursor.execute(\'SELECT * FROM ""OPENCV_CREATE_SAMPLES""\')\n\t\t\t\tdata = cursor.fetchall()\n\t\t\t\tbreak\n\t\t\texcept db.InternalError:\n\t\t\t\tconn.rollback()\n\t\t\t\tcontinue\n\t\tfor e in data:\n\t\t\ttrainer.tcreate_samples(e[3], e[2], e[4], e[5], e[6])\n\t\t\t\n\t\tself.ids[\'status\'].text = \'Status: Samples Created\' \t\n\t\treturn 1\n\t\t\t\n\tdef haar_training(self):\n\t\twhile True:\n\t\t\ttry:\n\t\t\t\tcursor.execute(\'SELECT * FROM ""OPENCV_HAARTRAINING_TABLE""\')\n\t\t\t\tdata = cursor.fetchall()\n\t\t\t\tbreak\n\t\t\texcept db.InternalError:\n\t\t\t\tconn.rollback()\n\t\t\t\tcontinue\t\t\n\t\t\t\n\t\tfor e in data:\n\t\t\ttrainer.thaar_training(e[2], e[3], e[4], e[5], e[6], e[7], e[8], e[9], e[11], e[12], e[10])\n\t\t\n\t\tself.ids[\'status\'].text = \'Status: Training Finished\' \t\n\t\treturn 1\n\t\t\nclass TrainerGUIApp(App):\n\t""""""Trainer app using kivy frontend""""""\n\tdef build(self):\n\t\tself.title = \'PostgreSQL Integrated Trainer for Haar Training\'\n\t\treturn Interface()\n\t\t\n\t\t\n\n\nif __name__ == \'__main__\':\n\tTrainerGUIApp().run()\n'"
src/lib/ui/__init__.py,0,b''
src/lib/ui/main_gui.py,0,"b'#!/usr/bin/env python2.7\n\n#general imports\nimport Image,cv2,sys,time,os,platform; import numpy as np\n\n#kivy imports\nfrom kivy.app import App\nfrom kivy.uix.boxlayout import BoxLayout\nfrom kivy.uix.popup import Popup\n\n#parent imports\nsys.path.append(\'../..\')\nimport lib.shape_analyzer as shape_analyzer\nimport lib.config_parser as config_parser\n\n#global vars\nglobal selected_image_filename,fishbase\n\nclass LoadDialog(BoxLayout):\n\t""""""Load dialog""""""\n\tdef load(self):\n\t\t""""""Loads defined image""""""\n\t\tglobal selected_image,chanelled_image, selected_image_filename\n\t\tselected_image_filename = self.ids[\'load_filechooser\'].selection[0]\n\t\ttry:\n\t\t\tImage.open(selected_image_filename)\n\t\t\tselected_image = cv2.imread(selected_image_filename)\n\t\t\tchanelled_image = cv2.imread(selected_image_filename,0)\n\t\t\tprint selected_image_filename + \' loaded\'\n\t\t\tload_popup.dismiss()\n\t\texcept IOError:\n\t\t\tselected_image = None\n\t\t\traise Exception(\'Bad Input\')\n\t\t\t\n\t\t\t\n\tdef cancel(self):\n\t\t""""""Dismisses the popup""""""\n\t\tload_popup.dismiss()\n\t\t\n\tdef get_home(self):\n\t\tif \'Windows\' in platform.system():\n\t\t\treturn \'\'\'..\\data\'\'\'\n\t\treturn os.getenv(\'HOME\')\n\t\t\nclass AboutDialog(BoxLayout):\n\t\n\tdef get_about_text(self):\n\t\t""""""Returns the about text""""""\n\t\tabout_txt = \'\'\'Author: Marios Papachristou <mrmarios97@gmail.com>\'\'\'\n\t\treturn about_txt\n\t\t\n\tdef go_to_homepage(self):\n\t\t""""""Opens homepage via xdg-open""""""\n\t\tfrom os import system\n\t\tsystem(\'xdg-open http://http://www.hcmr.gr/en/\')\n\t\t\n\tdef close(self):\n\t\t""""""Closes the popup""""""\n\t\tabout_dialog_popup.dismiss()\t\n\t\t\nclass IdentifierInterface(BoxLayout):\n\t\n\tdef get_artifacts(self):\n\t\treturn \'Species: {0}\\nCode: {1}\'.format(identified_specimen.name, identified_specimen.code)\n\t\t\n\tdef show_morphometrics(self):\n\t\tself.ids[\'output_label\'].text +=  (\'\\n\' + str(identified_specimen.get_morphometrics()))\n\t\n\tdef close(self):\n\t\tidentifier_interface_popup.dismiss()\n\t\t\n\tdef get_source(self):\n\t\treturn selected_image_filename\n\t\t\t\nclass ShapeAnalyzerInterface(BoxLayout):\n\t\n\tdef get_source(self):\n\t\tif \'Windows\' in platform.system():\n\t\t\treturn \'\'\'C:\\Temp\\final_image.jpg\'\'\'\n\t\telse:\n\t\t\treturn \'/tmp/final_image.jpg\'\n\t\n\tdef close(self):\n\t\tshape_analyzer_popup.dismiss()\n\t\t\n\tdef refresh(self):\n\t\t""""""Reloads the image""""""\n\t\tselected_image_shape_analyzer.write_final_image(TEMP_DIR)\n\t\tself.ids[\'shape_analyzed_image\'].reload()\n\t\t\n\tdef draw_el(self):\n\t\tselected_image_shape_analyzer.draw_extreme_points_lines()\n\t\tself.refresh()\n\t\t\n\tdef draw_ml(self):\n\t\tselected_image_shape_analyzer.draw_morphometric_lines_according_to_specimen(identified_specimen)\n\t\tself.refresh()\n\t\t\n\tdef save(self):\n\t\t""""""Saves the output image to the home folder""""""\n\t\tif \'Windows\' in platform.system():\n\t\t\tcv2.imwrite(\'\'\'C:\\output.jpg\'\'\',selected_image_shape_analyzer.drawn_img)\n\t\telse:\t\n\t\t\tcv2.imwrite(\'{0}/output.jpg\'.format(os.getenv(\'HOME\')),selected_image_shape_analyzer.drawn_img)\n\t\tprint \'Success\'\n\t\t\n\tdef draw_haar_like_features(self):\n\t\tfor f in identified_specimen.fcascades:\n\t\t\tselected_image_shape_analyzer.draw_haar_feature(f)\n\t\tself.refresh()\n\t\t\t\t\nclass Interface(BoxLayout):\n\t""""""Class that handles the main interface""""""\n\t\t\n\tdef get_banner(self):\n\t\treturn BANNER\n\t\t\t\t\n\tdef show_load(self):\n\t\t""""""Shows the load dialog""""""\n\t\tglobal load_popup\n\t\tload_popup = Popup(title=\'Load an Image\',\n\t\tcontent=LoadDialog(),\n\t\tsize_hint=(None, None), size=(600, 600))\n\t\tload_popup.open()\n\t\t\t\n\tdef show_about_dialog(self):\n\t\t""""""Shows the about dialog""""""\n\t\tglobal about_dialog_popup\n\t\tabout_dialog_popup = Popup(title= \'About\',\n\t\tcontent = AboutDialog(),\n\t\tsize_hint=(None,None), size=(500,500))\n\t\tabout_dialog_popup.open()\n\t\t\n\tdef perform_identification(self):\n\t\t""""""DEPRECATED: Please use perform_identification2. Performs identification based on Haar features""""""\n\t\tglobal identified_specimen\n\t\tidentified_specimen = fishbase.identify(chanelled_image)\n\t\t\n\tdef perform_identification2(self):\n\t\t""""""Calls FishDatabase.identify2 to perform identification using one of the three methods:\n\t\t1. Brute-force matcher ORB Features\t\n\t\t2. Brute-force matcher SIFT Features\t\n\t\t3. SIFT Features and Holography""""""\t\n\t\tc = str(self.ids[\'modes_spinner\'].text)\n\t\tif c == \'\':\n\t\t\tc = \'BFORB\'\n\t\tprint c\n\t\t_t = time.time()\n\t\tglobal identified_specimen\n\t\ttry:\n\t\t\tidentified_specimen = fishbase.identify2(chanelled_image,mode=c,cv_check=self.ids[\'cv_test_checkbox\'].active)\n\t\t\t_dt = time.time() - _t\n\t\texcept NameError:\n\t\t\tprint \'Specimen is not defined!\'\n\t\t\treturn\n\t\tglobal identifier_interface_popup\n\t\tidentifier_interface_popup = Popup(title= \'Identified specimen. Identification time: {0} sec\'.format(_dt),\n\t\tcontent = IdentifierInterface(),\n\t\tsize_hint=(None,None), size=(600,800))\n\t\tidentifier_interface_popup.open()\n\t\t\t\n\tdef perform_shape_analysis(self):\n\t\t""""""Calls the shape analyzer to perform shape analysis""""""\n\t\tglobal selected_image_shape_analyzer\n\t\t_threshold1 = int(self.ids[\'sl1\'].value)\n\t\t_threshold2 = int(self.ids[\'sl2\'].value)\n\t\tselected_image_shape_analyzer = shape_analyzer.ShapeAnalyzer(chanelled_image,threshold1=_threshold1, threshold2=_threshold2)\n\t\tselected_image_shape_analyzer.write_final_image(TEMP_DIR)\n\t\tglobal shape_analyzer_popup\n\t\tshape_analyzer_popup = Popup(title= \'Shape Analyzer\',\n\t\tcontent = ShapeAnalyzerInterface(),\n\t\tsize_hint=(None,None), size=(700,700))\n\t\tshape_analyzer_popup.open()\n\t\t\n\tdef clear_all(self):\n\t\t""""""Clears all the defined parameters""""""\n\t\tidentified_specimen = None\n\t\tselected_image = None\n\t\tselected_image_filename = None\n\t\tselected_image_shape_analyzer = None\n\t\tchanelled_image = None\n\t\tprint \'Cleared\'\n\t\t\n\tdef show_scripts_interface(self):\n\t\tglobal scripts_dialog_popup\n\t\tscripts_dialog_popup = Popup(title= \'Select a script...\',\n\t\tcontent = ScriptsInterface(),\n\t\tsize_hint=(None,None), size=(500,500))\n\t\tscripts_dialog_popup.open()\n\t\t\n\tdef capture_image(self):\n\t\tglobal selected_image,chanelled_image,selected_image_filename\n\t\tselected_image_filename = \'{0}/capture.jpg\'.format(TEMP_DIR)\n\t\ts, selected_image = cam.read()\n\t\tchanelled_image = cv2.cvtColor(selected_image, cv2.COLOR_BGR2GRAY)\n\t\tcv2.imwrite(selected_image_filename, selected_image)\n\t\tprint \'Ok\'\n\t\t\n\nclass ScriptsInterface(BoxLayout):\n\t\n\tdef get_scripts(self):\n\t\timport glob\n\t\tresults = []\n\t\tflst = glob.glob(\'./scripts/*.py\')\n\t\treturn tuple(flst)\n\t\t\t\t\t\n\tdef run_script(self):\n\t\tos.system(\'{0} {1} {2}\'.format(\'python\', self.ids[\'scripts_spinner\'].text, self.ids[\'args_textinput\'].text))\n\t\t\n\tdef close(self):\n\t\tscripts_dialog_popup.dismiss()\n\nclass MainGUIApp(App):\n\t""""""Main GUI Application""""""\n\n\tdef build(self):\n\t\tself.title = \'Triton FPR\'\n\t\treturn Interface()\n\n\tdef _setup(self,fb, banner, tmp_dir=\'/tmp\'):\n\t\t""""""Sets up global parameters""""""\n\t\tglobal fishbase, BANNER, TEMP_DIR, cam\n\t\tfishbase = fb\n\t\tBANNER = banner\n\t\tTEMP_DIR = tmp_dir\n\t\tcam = cv2.VideoCapture(0)\n\nif __name__ == \'__main__\':\n\t""""""Executed if standalone""""""\n\t#general imports\n\tsys.path.append(\'../..\')\n\timport base\n\t\n\t#configurations\n\tconf_parser = config_parser.ConfigParser(\'../../config.spec\',regex=\':\')\n\tfishbase = base.initialize_fishbase(conf_parser.get(\'DATASOURCE_URL\'))\n\tbanner = \'../../../res/logo/bitmap/banner_90dpi.png\'\n\ttmp_dir = base.get_temp_dir()\n\t\n\t#execution\n\tmain_gui_app = MainGUIApp()\n\tmain_gui_app._setup(fishbase, banner, tmp_dir)\n\tmain_gui_app.run()\n'"
