file_path,api_count,code
setup.py,0,"b""from setuptools import setup\nimport os.path\n\nwith open(os.path.join('tidynamics', 'VERSION')) as f:\n    VERSION = f.read().strip()\n\nwith open('README.rst', 'r') as f:\n    readme = f.read()\n\nsetup(name='tidynamics',\n      version=VERSION,\n      description='Tiny package to compute dynamics correlations',\n      long_description=readme,\n      long_description_content_type='text/x-rst',\n      author='Pierre de Buyl',\n      author_email='pdebuyl@pdebuyl.be',\n      license='BSD',\n      url='https://pypi.org/project/tidynamics/',\n      packages=['tidynamics'],\n      install_requires=['numpy'],\n      package_data={'tidynamics': ['VERSION']},\n      classifiers=[\n          'License :: OSI Approved :: BSD License',\n          'Programming Language :: Python :: 2.7',\n          'Programming Language :: Python :: 3',\n      ],\n)\n"""
doc/conf.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# tidynamics documentation build configuration file, created by\n# sphinx-quickstart on Sat Dec  9 22:10:27 2017.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport os.path\nimport sys\nsys.path.insert(0, os.path.pardir)\nimport re\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\'sphinx.ext.autodoc\',\n    \'sphinx.ext.napoleon\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx_gallery.gen_gallery\',\n    \'sphinxcontrib.bibtex\',\n    ]\n\nsphinx_gallery_conf = {\n    # path to your examples scripts\n    \'examples_dirs\' : \'../examples\',\n    # path where to save gallery generated examples\n    \'gallery_dirs\'  : \'auto_examples\',\n    \'backreferences_dir\': False,\n}\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'contents\'\n\n# General information about the project.\nproject = \'tidynamics\'\ncopyright = \'2017-2018, Pierre de Buyl\'\nauthor = \'Pierre de Buyl\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\nwith open(os.path.join(os.path.pardir, \'tidynamics\', \'VERSION\')) as f:\n    # The full version, including alpha/beta/rc tags.\n    release = f.read().strip()\n\n# The short X.Y version.\nversion = re.match(\'\\d+\\.\\d+\\.\\d+\', release).group()\n\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = [\'_build\', \'Thumbs.db\', \'.DS_Store\']\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'alabaster\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\nhtml_sidebars = {\n               \'**\': [\'about.html\', \'navigation.html\', \'sourcelink.html\', \'searchbox.html\'],\n                 }\n\n\n# -- Options for HTMLHelp output ------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'tidynamicsdoc\'\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\n#latex_toplevel_sectioning = \'section\'\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n    \'printindex\': \'\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'tidynamics.tex\', \'tidynamics Documentation\',\n     \'Pierre de Buyl\', \'howto\'),\n]\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'tidynamics\', \'tidynamics Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'tidynamics\', \'tidynamics Documentation\',\n     author, \'tidynamics\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n\n\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {\'https://docs.python.org/\': None}\n'"
examples/plot_acf_1.py,10,"b'""""""\n=====================\nCorrelation functions\n=====================\n\nGenerate the velocity for a Ornstein-Uhlenbeck process and compute its\nautocorrelation function.\n\nWe also display the force velocity correlation as an example of using the\nroutine `correlation`.\n""""""\n\nimport numpy as np\nimport tidynamics\nimport matplotlib.pyplot as plt\n\nplt.rcParams[\'figure.figsize\'] = 5.12, 3.84\nplt.rcParams[\'figure.subplot.bottom\'] = 0.18\nplt.rcParams[\'figure.subplot.left\'] = 0.16\n\n# Generate data for a Ornstein-Uhlenbeck process\n\ngamma = 2.7\nT = 0.1\ndt = 0.02\nv_factor = np.sqrt(2*T*gamma*dt)\n\nN = 32768\nv = 0\nfor i in range(100):\n    noise_force = v_factor*np.random.normal()\n    v = v - gamma*v*dt + noise_force\n\nv_data = []\nnoise_data = []\n\nfor i in range(N):\n    noise_force = v_factor*np.random.normal()\n    v = v - gamma*v*dt + noise_force\n    v_data.append(v)\n    noise_data.append(noise_force)\nv_data = np.array(v_data)\nnoise_data = np.array(noise_data)/np.sqrt(dt)\n\n# Compute the autocorrelation function and plot the result\n\nacf = tidynamics.acf(v_data)[:N//64]\n\ntime = np.arange(N//64)*dt\n\nplt.plot(time, acf, label=\'VACF (num.)\')\n\nplt.plot(time, T*np.exp(-gamma*time), label=\'VACF (theo.)\')\n\nplt.legend()\nplt.title(\'Velocity autocorrelation\')\nplt.xlabel(r\'$\\tau$\')\nplt.ylabel(r\'$\\langle v(t) v(t+\\tau) \\rangle$\')\n\n# Compute the force velocity correlation and plot the result\n\nplt.figure()\n\ntime = np.arange(N)*dt\ntwotimes = np.concatenate((-time[1:][::-1], time))\n\nplt.plot(twotimes, tidynamics.correlation(noise_data, v_data),\n         label=\'num.\')\nplt.plot(time, 2*T/gamma*np.exp(-gamma*time), label=\'theo.\')\n\nplt.xlim(-5/gamma, 5/gamma)\n\nplt.ylim(-2*T/gamma/10, 1.1*2*T/gamma)\n\nplt.legend()\nplt.title(\'Force-velocity correlation\')\nplt.xlabel(r\'$\\tau$\')\nplt.ylabel(r\'$\\langle F(t) v(t+\\tau) \\rangle$\')\n\nplt.show()\n'"
examples/plot_msd_1.py,6,"b'r""""""\n===============================\nMean-square displacements (MSD)\n===============================\n\nGenerate a number of random walks and compute their MSD.\n\nCompute also the MSD for a constant velocity motion.\n\nFor a random walk, the MSD is linear: :math:`MSD(\\tau) \\approx 2 D \\tau`\n\nFor a constant velocity motion, the MSD is quadratic:\n:math:`MSD(\\tau) = v \\tau^2`\n\nWe show in the figures the numerical result computed by `tidynamics.msd`\n(\'num.\') and the theoretical value (\'theo.\').\n\nFor the constant velocity case, we also display a ""pedestrian approach"" where\nthe loop for averaging the MSD is performed explicitly.\n""""""\n\nimport numpy as np\nimport tidynamics\nimport matplotlib.pyplot as plt\n\nplt.rcParams[\'figure.figsize\'] = 5.12, 3.84\nplt.rcParams[\'figure.subplot.bottom\'] = 0.18\nplt.rcParams[\'figure.subplot.left\'] = 0.16\n\n# Generate 32 random walks and compute their mean-square\n# displacements\n\nN = 1000\nmean = np.zeros(N)\ncount = 0\nfor i in range(32):\n    # Generate steps of value +/- 1\n    steps = -1 + 2*np.random.randint(0, 2, size=(N, 2))\n    # Compute random walk position\n    data = np.cumsum(steps, axis=0)\n    mean += tidynamics.msd(data)\n    count += 1\n\nmean /= count\nmean = mean[1:N//2]\n\ntime = np.arange(N)[1:N//2]\n\nplt.plot(time, mean, label=\'Random walk (num.)\')\n\nplt.plot(time, 2*time, label=\'Random walk (theo.)\')\n\ntime = np.arange(N//2)\n\n# Display the mean-square displacement for a trajectory with\n# constant velocity. Here the trajectory is taken equal to the\n# numerical value of the time.\n\nplt.plot(time[1:], tidynamics.msd(time)[1:],\n         label=\'Constant velocity (num.)\', ls=\'--\')\nplt.plot(time[1:], time[1:]**2,\n         label=\'Constant velocity (theo.)\', ls=\'--\')\n\n# Compute the the mean-square displacement by explicitly\n# computing the displacements along shorter samples of the\n# trajectory.\n\nsum_size = N//10\npedestrian_msd = np.zeros(N//10)\nfor i in range(10):\n    for j in range(N//10):\n        pedestrian_msd[j] += (time[10*i]-time[10*i+j])**2\npedestrian_msd /= 10\nplt.plot(time[1:N//10], pedestrian_msd[1:], ls=\'--\',\n         label=""pedestrian"")\n\nplt.loglog()\nplt.legend()\nplt.xlabel(\'time\')\nplt.ylabel(\'mean square displacement\')\nplt.title(\'Examples for the mean-square displacement\')\nplt.show()\n'"
examples/plot_nlogn_scaling.py,5,"b'""""""\n=================\nScaling behaviour\n=================\n\nCompute the autocorrelation for varying time series lengths.\n\nThe figure displays the timing and a :math:`N log N` scaling law, demonstrating\nthe claimed complexity.\n""""""\nfrom __future__ import division\n\nimport numpy as np\nimport tidynamics\nimport matplotlib.pyplot as plt\nimport time\n\nplt.rcParams[\'figure.figsize\'] = 5.12, 3.84\nplt.rcParams[\'figure.subplot.bottom\'] = 0.18\nplt.rcParams[\'figure.subplot.left\'] = 0.16\n\n\nall_N = []\nN = 64\nfor i in range(14):\n    all_N.append(N + int(N/3))\n    all_N.append(N + int(N/2))\n    all_N.append(N + int(2*N/3))\n    N = 2*N\nall_N = np.array(all_N)\n\nmax_direct_N = 32768\nall_time = []\ndirect_time = []\nn_runs = 5\n\nfor N in all_N:\n    t = 0\n    direct_t = 0\n    for i in range(n_runs):\n        data = np.random.random(size=N)\n        t0 = time.time()\n        acf = tidynamics.acf(data)\n        t += time.time() - t0\n        if N <= max_direct_N:\n            t0 = time.time()\n            acf = np.correlate(data, data, mode=\'full\')\n            direct_t += time.time() - t0\n\n    all_time.append(t/n_runs)\n    if N <= max_direct_N:\n        direct_time.append(direct_t/n_runs)\n\nplt.plot(all_N, all_time, label=\'actual compute time\')\nplt.plot(all_N,\n         all_time[-1] * all_N*np.log(all_N) / (all_N[-1]*np.log(all_N[-1])),\n         label=r\'$N\\log N$ scaling\')\nplt.plot(all_N[:len(direct_time)], direct_time,\n         label=\'np.correlate compute time\', ls=\'--\')\n\ndata_len = len(direct_time)\nplt.plot(all_N[:data_len],\n         all_N[:data_len]**2 * direct_time[data_len-1] / all_N[data_len-1]**2,\n         label=r\'$N^2$ scaling\', ls=\':\')\n\nplt.xlabel(r\'$N$\')\nplt.ylabel(\'time\')\n\nplt.loglog()\nplt.legend()\n\nplt.show()\n'"
examples/tidynamics_tool.py,4,"b'#!/usr/bin/env python\n""""""\n====================================\nCommand-line interface to tidynamics\n====================================\n\nThe program reads in data from the file input_file (using np.loadtxt from\nNumPy) and performs the selected action on the data, chosen in:\n\n* acf for the autocorrelation function\n* msd for the mean-square displacement\n\nThe program writes the result in the file output_file using the function\nnp.savetxt from NumPy.\n\nFor more information, consult the documentation of tidynamics at\nhttp://lab.pdebuyl.be/tidynamics/\n\n""""""\nfrom __future__ import print_function, division\n\nimport argparse\nimport numpy as np\nimport tidynamics\n\n\nparser = argparse.ArgumentParser(description=__doc__,\n                        formatter_class=argparse.RawDescriptionHelpFormatter)\nparser.add_argument(\'action\',\n                    help=\'Choice of computation to perform on input file\',\n                    choices=[\'acf\', \'msd\'])\nparser.add_argument(\'input_file\',\n                    help=\'Filename for input data\')\nparser.add_argument(\'output_file\',\n                    help=\'Filename for the result of the computation\')\nargs = parser.parse_args()\n\ninput_data = np.loadtxt(args.input_file)\n\nif args.action == \'acf\':\n    result = tidynamics.acf(input_data)\nelif args.action == \'msd\':\n    result = tidynamics.msd(input_data)\n\nnp.savetxt(args.output_file, result)\n'"
tests/test_acf_1.py,6,"b'import numpy as np\nimport tidynamics\n\ndef test_cst_acf_1d():\n    N = 100\n    data = np.ones(N)\n    reference_acf = np.ones_like(data)\n    computed_acf = tidynamics.acf(data)\n    assert np.allclose(reference_acf, computed_acf)\n\ndef test_cst_acf_nd():\n    N = 100\n    ND = 3\n    data = np.ones((N, ND))\n    reference_acf = ND*np.ones(N)\n    computed_acf = tidynamics.acf(data)\n    assert np.allclose(reference_acf, computed_acf)\n'"
tests/test_acf_2.py,6,"b'import numpy as np\nimport tidynamics\n\ndef test_cst_acf_1d():\n    N = 0\n    data = np.ones(N)\n    reference_acf = np.ones_like(data)\n    print(reference_acf)\n    computed_acf = tidynamics.acf(data)\n    assert np.allclose(reference_acf, computed_acf)\n\ndef test_cst_acf_nd():\n    N = 0\n    ND = 3\n    data = np.ones((N, ND))\n    reference_acf = ND*np.ones(N)\n    computed_acf = tidynamics.acf(data)\n    assert np.allclose(reference_acf, computed_acf)\n'"
tests/test_correlation_1.py,6,"b'import numpy as np\nimport tidynamics\n\ndef test_correlation_acf_1():\n    N = 100\n    size = (N, 4)\n    data = np.random.random(size=size)\n    acf = tidynamics.acf(data)\n    comparison = tidynamics.correlation(data, data)\n    assert np.allclose(acf, comparison[-N:])\n\ndef test_cst_correlation_acf():\n    N = 200\n    size = (N, 3)\n    x = 3.5\n    data1 = np.ones(shape=size)\n    data2 = x*np.ones(shape=size)\n    reference_cf = x*size[1]*np.ones(2*N-1)\n    computed_cf = tidynamics.correlation(data1, data2)\n    assert np.allclose(reference_cf, computed_cf)\n\n'"
tests/test_correlation_1d.py,6,"b'import numpy as np\nimport tidynamics\n\ndef test_correlation_acf_1():\n    N = 100\n    data = np.random.random(size=N)\n    acf = tidynamics.acf(data)\n    comparison = tidynamics.core.correlation_1d(data, data)\n    assert np.allclose(acf, comparison[-N:])\n\ndef test_cst_correlation_acf():\n    N = 200\n    x = 3.5\n    data1 = np.ones(N)\n    data2 = x*np.ones(N)\n    reference_cf = x*np.ones(2*N-1)\n    computed_cf = tidynamics.core.correlation_1d(data1, data2)\n    assert np.allclose(reference_cf, computed_cf)\n    \n'"
tests/test_cross_msd_1.py,2,"b'import numpy as np\nimport tidynamics\n\ndef test_cross_disp_1():\n    N = 100\n    D = 4\n    data = np.random.random(size=(N, D))\n    cross_disp = tidynamics.cross_displacement(data)\n    for i in range(D):\n        assert np.allclose(cross_disp[i][i], tidynamics.msd(data[:,i]))\n'"
tests/test_msd_1.py,5,"b'import numpy as np\nimport tidynamics\n\ndef test_linear_msd():\n    N = 100\n    time = np.arange(N)\n    reference_msd = time**2\n    computed_msd = tidynamics.msd(time)\n    assert np.allclose(reference_msd, computed_msd)\n\ndef test_cst_msd():\n    N = 100\n    data = np.ones(N)\n    reference_msd = np.zeros_like(data)\n    computed_msd = tidynamics.msd(data)\n    assert np.allclose(reference_msd, computed_msd)\n'"
tests/test_msd_2.py,7,"b'import numpy as np\nimport tidynamics\n\ndef test_random_walk_msd():\n\n    def brute_force_msd(pos):\n        """"""\n        Compute the mean-square displacement with an explicit loop over all\n        time intervals.\n        """"""\n        pos = np.asarray(pos)\n        if pos.ndim==1:\n            pos = pos.reshape((-1,1))\n        trajectory_length = len(pos)\n        msd = np.zeros(trajectory_length)\n        msd_count = np.zeros(trajectory_length)\n        for i in range(trajectory_length):\n            for j in range(i, trajectory_length):\n                msd[j-i] += np.sum((pos[i]-pos[j])**2)\n                msd_count[j-i] += 1\n        msd = msd/msd_count\n        return msd\n\n    N = 200\n    N_dim = 2\n    # Generate steps of value +/- 1\n    steps = -1 + 2*np.random.randint(0, 2, size=(N, N_dim))\n    # Compute random walk position\n    walk = np.cumsum(steps, axis=0)\n\n    tidynamics_msd = tidynamics.msd(walk)\n    comparison_msd = brute_force_msd(walk)\n\n    assert np.allclose(tidynamics_msd, comparison_msd)\n'"
tests/test_msd_3.py,9,"b'import numpy as np\nimport tidynamics\n\ndef test_length_one_msd():\n    N = 1\n    pos = np.zeros(N)\n    reference_msd = np.zeros(N)\n    computed_msd = tidynamics.msd(pos)\n    assert np.allclose(reference_msd, computed_msd)\n\ndef test_length_zero_msd():\n    N = 0\n    pos = np.zeros(N)\n    reference_msd = np.zeros(N)\n    computed_msd = tidynamics.msd(pos)\n    assert np.allclose(reference_msd, computed_msd)\n\ndef test_length_one_msd_nd():\n    N = 1\n    ND = 4\n    data = np.ones((N, ND))\n    reference_msd = np.zeros_like(data[:,0])\n    computed_msd = tidynamics.msd(data)\n    assert np.allclose(reference_msd, computed_msd)\n'"
tidynamics/__init__.py,0,"b'""""""\ntidynamics\n==========\n\nA tiny package to compute the dynamics of stochastic and molecular simulations.\n\nDocumentation: http://lab.pdebuyl.be/tidynamics/\n\nWhen using tidynamics in a publication, please cite the following paper:\n    Pierre de Buyl (2018), *tidynamics: A tiny package to compute the dynamics\n    of stochastic and molecular simulations*, The Journal of Open Source\n    Software https://doi.org/10.21105/joss.00877\n\n\n""""""\nfrom ._correlation import acf, msd, cross_displacement, correlation\nimport os.path\n\nwith open(os.path.join(os.path.dirname(__file__), \'VERSION\')) as f:\n    __version__ = f.read().strip()\n'"
tidynamics/_correlation.py,10,"b'from __future__ import division\nimport numpy as np\nfrom .core import autocorrelation_1d, correlation_1d\nimport itertools\n\ndef acf(data):\n    """"""Autocorrelation of the input data using the Fast Correlation Algorithm.\n\n    Computes the autocorrelation for all time lags in the input data. The numerical results for\n    large lags contain fewer samples than for short lags and are not accurate. This is intrinsic to\n    the computation and not a limitation of the algorithm.\n\n    For D-dimensional time series, a sum is performed on the last dimension.\n\n    Args:\n        data (array-like): The input signal, of shape (N,) or (N,D).\n\n    Returns:\n        ndarray of shape (N,) with the autocorrelation for successive linearly\n        spaced time delays\n\n    """"""\n\n    data = np.asarray(data)\n    if data.ndim==1:\n        return autocorrelation_1d(data)\n    elif data.ndim>1:\n        result = autocorrelation_1d(data[:,0])\n        for j in range(1, data.shape[1]):\n            result += autocorrelation_1d(data[:,j])\n        return result\n\ndef msd(pos):\n    """"""Mean-squared displacement (MSD) of the input trajectory using the Fast\n    Correlation Algorithm.\n\n    Computes the MSD for all possible time deltas in the trajectory. The numerical results for large\n    time deltas contain fewer samples than for small time times and are less accurate. This is\n    intrinsic to the computation and not a limitation of the algorithm.\n\n    Args:\n        pos (array-like): The input trajectory, of shape (N,) or (N,D).\n\n    Returns:\n        : ndarray of shape (N,) with the MSD for successive linearly spaced time\n        delays.\n\n    """"""\n\n    pos = np.asarray(pos)\n    if pos.shape[0] == 0:\n        return np.array([], dtype=pos.dtype)\n    if pos.ndim==1:\n        pos = pos.reshape((-1,1))\n    N = len(pos)\n    rsq = np.sum(pos**2, axis=1)\n    MSD = np.zeros(N, dtype=float)\n\n    SAB = autocorrelation_1d(pos[:,0])\n    for i in range(1, pos.shape[1]):\n        SAB += autocorrelation_1d(pos[:,i])\n\n    SUMSQ = 2*np.sum(rsq)\n\n    m = 0\n    MSD[m] = SUMSQ - 2*SAB[m]*N\n\n    MSD[1:] = (SUMSQ - np.cumsum(rsq)[:-1] - np.cumsum(rsq[1:][::-1])) / (N-1-np.arange(N-1))\n    MSD[1:] -= 2*SAB[1:]\n\n    return MSD\n\ndef cross_displacement(pos):\n    """"""Cross displacement of the components of the input trajectory.\n\n    Args:\n        pos (array-like): The input trajectory, of shape (N, D).\n\n    Returns:\n        : list of lists of times series, where the fist two indices [i][j]\n        denote the coordinates for the cross displacement: ""(Delta pos[:,i]) (Delta pos[:,j])"".\n\n    """"""\n\n    pos = np.asarray(pos)\n    if pos.ndim != 2:\n        raise ValueError(""Incorrect input data for cross_displacement"")\n    D = pos.shape[1]\n\n    # Precompute the component-wise MSD\n    split_msd = [msd(pos_i) for pos_i in pos.T]\n\n    # Create list of lists for the output\n    result = [[] for i in range(D)]\n    for i, j in itertools.product(range(D), range(D)):\n        result[i].append([])\n\n    for i, j in itertools.product(range(D), range(D)):\n        if i==j:\n            result[i][j] = split_msd[i]\n        else:\n            sum_of_pos = msd(pos[:,i]+pos[:,j])\n            result[i][j] = 0.5*(sum_of_pos - split_msd[i] - split_msd[j])\n\n    return result\n\ndef correlation(data1, data2):\n    """"""Correlation between the input data using the Fast Correlation Algorithm.\n\n    For D-dimensional time series, a sum is performed on the last dimension.\n\n    Args:\n        data1 (array-like): The first input signal, of shape (N,) or (N,D).\n\n        data2 (array-like): The first input signal, of equal shape as data1.\n\n    Returns:\n        : ndarray of shape (2*N-1,) with the correlation for\n        ""data1*data2[tau]"" where tau is the lag in units of the timestep in the\n        input data. The correlation is given from time -N to time N.\n\n    """"""\n\n    data1 = np.asarray(data1)\n    data2 = np.asarray(data2)\n    if data1.shape != data2.shape:\n        raise ValueError(\'Incompatible shapes for data1 and data2\')\n\n    if data1.ndim==1:\n        return correlation_1d(data1, data2)\n    elif data1.ndim>1:\n        result = correlation_1d(data1[:,0], data2[:,0])\n        for j in range(1, data1.shape[1]):\n            result += correlation_1d(data1[:,j], data2[:,j])\n        return result\n'"
tidynamics/core.py,12,"b'from __future__ import division\nimport numpy as np\n\ndef select_power_of_two(n):\n    """"""\n    Select the closest i such that n<=2**i\n    """"""\n    current_exp = int(np.ceil(np.log2(n+1)))\n    if n == 2**current_exp:\n        n_fft = n\n    if n < 2**current_exp:\n        n_fft = 2**current_exp\n    elif n > 2**current_exp:\n        n_fft = 2**(current_exp+1)\n\n    return n_fft\n\n\ndef autocorrelation_1d(data):\n    """"""\n    Compute the autocorrelation of a scalar time series.\n    """"""\n\n    N = len(data)\n    n_fft = select_power_of_two(N)\n\n    # Pad the signal with zeros to avoid the periodic images.\n\n    R_data = np.zeros(2*n_fft)\n    R_data[:N] = data\n\n    F_data = np.fft.fft(R_data)\n\n    result = np.fft.ifft(F_data*F_data.conj())[:N].real/(N-np.arange(N))\n\n    return result[:N]\n\n\ndef correlation_1d(data1, data2):\n    """"""\n    Compute the correlation of two scalar time series.\n\n    Args:\n        data1 (array-like): Input time series of shape (N,)\n        data2 (array-like): Input time series of shape (N,)\n\n    Returns:\n        : ndarray of shape (2*N-1,) with the correlation for\n        ""data1*data2[tau]"" where tau is the lag in units of the timestep in the\n        input data. The correlation is given from time -N to time N.\n    """"""\n\n    N = len(data1)\n    assert N == len(data2)\n    n_fft = select_power_of_two(N)\n\n    # Pad the signal with zeros to avoid the periodic images.\n    R_data1 = np.zeros(2*n_fft)\n    R_data1[:N] = data1\n    R_data2 = np.zeros(2*n_fft)\n    R_data2[:N] = data2\n    F_data1 = np.fft.fft(R_data1)\n    F_data2 = np.fft.fft(R_data2)\n    result = np.fft.ifft(F_data1.conj()*F_data2)\n    positive_time = result[:N].real/(N-np.arange(N))\n    negative_time = result[-N+1:][::-1].real/(N-1-np.arange(N-1))\n\n    return np.concatenate((negative_time[::-1], positive_time))\n'"
