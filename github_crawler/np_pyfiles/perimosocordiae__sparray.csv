file_path,api_count,code
setup.py,1,"b""#!/usr/bin/env python\nfrom setuptools import setup, Extension\n\ntry:\n  from Cython.Build import cythonize\n  import numpy as np\nexcept ImportError:\n  use_cython = False\nelse:\n  use_cython = True\n\nsetup_kwargs = dict(\n    name='sparray',\n    version='0.0.4',\n    author='CJ Carey',\n    author_email='perimosocordiae@gmail.com',\n    description='Sparse representation for ndarrays',\n    url='http://github.com/perimosocordiae/sparray',\n    license='MIT',\n    packages=['sparray'],\n    package_data = {'': ['*.pyx']},\n    install_requires=[\n        'numpy >= 1.9',\n        'scipy >= 0.15',\n        'Cython >= 0.21',\n    ],\n)\nif use_cython:\n  exts = [Extension('*', ['sparray/*.pyx'], include_dirs=[np.get_include()])]\n  setup_kwargs['ext_modules'] = cythonize(exts)\n\nsetup(**setup_kwargs)\n"""
speed_comparison.py,4,"b'#!/usr/bin/env python\nfrom __future__ import print_function\nimport timeit\nimport numpy as np\nimport scipy.sparse as ss\n\nfrom sparray import FlatSparray\n\n\ndef run_bench(fn, arrays, number=100, repeats=3):\n  for a in arrays:\n    try:\n      res = timeit.repeat(lambda: fn(a), repeat=repeats, number=number)\n    except TypeError:\n      res = [np.inf]\n    yield min(res) * 1e6 / number\n\n\ndef format_time(usec):\n  if np.isinf(usec):\n    return ""N/A""\n  if usec < 1000:\n    return ""%.3g us"" % usec\n  msec = usec / 1000.\n  if msec < 1000:\n    return ""%.3g ms"" % msec\n  sec = msec / 1000.\n  return ""%.3g s"" % sec\n\n\ndef main():\n  arr = ss.rand(1000, 500, density=0.1)\n  fmts = [\'csr\', \'csc\', \'dense\', \'FlatSparray\']\n  arrays = [arr.tocsr(), arr.tocsc(), arr.toarray(),\n            FlatSparray.from_spmatrix(arr)]\n  benches = [\n      (\'arr * 3\', lambda a: a * 3),\n      (\'arr.sum()\', lambda a: a.sum()),\n      (\'arr[154,145]\', lambda a: a[154,145]),\n      (\'arr[:5,:5]\', lambda a: a[:5,:5]),\n      (\'arr[876]\', lambda a: a[876]),\n      (\'arr[:,273]\', lambda a: a[:,273]),\n      (\'diag(arr)\', lambda a: a.diagonal()),\n  ]\n\n  label_size = max(len(b[0]) for b in benches)\n  fmt_size = max(len(f) for f in fmts[:-1]) + 1\n  print(\' \' * label_size, *[f.ljust(fmt_size) for f in fmts])\n  for label, fn in benches:\n    result = list(run_bench(fn, arrays))\n    ratio = np.array(result[:-1]) / result[-1]\n    ratio = [\'N/A\' if np.isinf(r) else (\'%.2fx\' % r) for r in ratio]\n    print(label.ljust(label_size), *[r.ljust(fmt_size) for r in ratio], end=\' \')\n    print(format_time(result[-1]).ljust(fmt_size))\n\nif __name__ == \'__main__\':\n  main()\n'"
sparray/__init__.py,0,b'from __future__ import absolute_import\n\nfrom .base import is_sparray\nfrom .flat import FlatSparray\n'
sparray/base.py,17,"b'from __future__ import absolute_import\nimport numpy as np\n\n__all__ = [\'is_sparray\']\n\n\nclass _BaseSparray(object):\n  \'\'\'Base-class for Sparray types.\'\'\'\n  __array_priority__ = 999\n\n  def __len__(self):\n    # Mimic ndarray here, instead of spmatrix\n    return self.shape[0]\n\n  def __bool__(self):\n    if np.prod(self.shape) <= 1:\n      return bool(self.nnz)\n    raise ValueError(""The truth value of an array with more than one ""\n                     ""element is ambiguous. Use a.any() or a.all()."")\n\n  __nonzero__ = __bool__\n\n  def __iter__(self):\n    for i in range(self.shape[0]):\n      yield self[i]\n\n  def __eq__(self, other):\n    return self._comparison(other, \'__eq__\', np.equal, \'==\')\n\n  def __ne__(self, other):\n    return self._comparison(other, \'__ne__\', np.not_equal, \'!=\')\n\n  def __lt__(self, other):\n    return self._comparison(other, \'__lt__\', np.less, \'<\')\n\n  def __le__(self, other):\n    return self._comparison(other, \'__le__\', np.less_equal, \'<=\')\n\n  def __gt__(self, other):\n    return self._comparison(other, \'__gt__\', np.greater, \'>\')\n\n  def __ge__(self, other):\n    return self._comparison(other, \'__ge__\', np.greater_equal, \'>=\')\n\n  def __radd__(self, other):\n    return self.__add__(other)\n\n  def __sub__(self, other):\n    return self.__add__(-other)\n\n  def __rsub__(self, other):\n    return (-self).__add__(other)\n\n  def __rmul__(self, other):\n    return self.__mul__(other)\n\n  def multiply(self, other):\n    \'\'\'Element-wise multiplication. Alias for self * other\'\'\'\n    return self.__mul__(other)\n\n  def __div__(self, other):\n    return self._divide(other)\n\n  def __rdiv__(self, other):\n    return self._divide(other, rdivide=True)\n\n  def __truediv__(self, other):\n    return self._divide(other, div_func=np.true_divide)\n\n  def __rtruediv__(self, other):\n    return self._divide(other, div_func=np.true_divide, rdivide=True)\n\n  def __floordiv__(self, other):\n    return self._divide(other, div_func=np.floor_divide)\n\n  def __rfloordiv__(self, other):\n    return self._divide(other, div_func=np.floor_divide, rdivide=True)\n\n  def __matmul__(self, other):\n    return self.dot(other)\n\n  def _rdot(self, other):\n    # This only gets called for dense other,\n    # because spmatrix.dot(x) calls np.asarray(x)\n    return other.dot(self.toarray())\n\n  def mean(self, axis=None, dtype=None):\n    if dtype is None:\n      dtype = self.dtype\n    # Mimic numpy upcasting\n    if np.can_cast(dtype, np.float_):\n      dtype = np.float_\n    elif np.can_cast(dtype, np.complex_):\n      dtype = np.complex_\n    s = self.sum(axis=axis, dtype=dtype)\n    if axis is None:\n      num_elts = np.prod(self.shape)\n    else:\n      # XXX: we don\'t support tuples of axes, yet\n      num_elts = self.shape[axis]\n    if num_elts != 1:\n      s /= num_elts\n    return s\n\n  def __getattr__(self, attr):\n    if attr == \'A\':\n      return self.toarray()\n    if attr == \'T\':\n      return self.transpose()\n    if attr == \'size\':\n      return self.getnnz()\n    if attr == \'ndim\':\n      return len(self.shape)\n    raise AttributeError(attr + "" not found"")\n\n  def __iadd__(self, other):\n    raise NotImplementedError(\'in-place add is not supported\')\n\n  def __isub__(self, other):\n    raise NotImplementedError(\'in-place subtract is not supported\')\n\n  def conjugate(self):\n    return self.conj()\n\n\ndef is_sparray(x):\n  return isinstance(x, _BaseSparray)\n'"
sparray/compat.py,28,"b""import numpy as np\nimport scipy.sparse as ss\n\n__all__ = [\n    'broadcast_to', 'broadcast_shapes', 'ufuncs_with_fixed_point_at_zero',\n    'intersect1d_sorted', 'union1d_sorted', 'combine_ranges', 'len_range'\n]\n\n\ndef _broadcast_to(array, shape, subok=False):\n  '''copied in reduced form from numpy 1.10'''\n  shape = tuple(shape)\n  array = np.array(array, copy=False, subok=subok)\n  broadcast = np.nditer((array,), flags=['multi_index', 'zerosize_ok'],\n                        op_flags=['readonly'], itershape=shape, order='C'\n                        ).itviews[0]\n  if type(array) is not type(broadcast):\n    broadcast = broadcast.view(type=type(array))\n    if broadcast.__array_finalize__:\n      broadcast.__array_finalize__(array)\n  return broadcast\n\n\n# Re-create np.broadcast rules, but for shapes instead of array-likes\ndef broadcast_shapes(*shapes):\n  # this uses a tricky hack to make fake ndarrays\n  x = np.array(0)\n  fake_arrays = [broadcast_to(x, s) for s in shapes]\n  return np.broadcast(*fake_arrays).shape\n\n\ndef _intersect1d_sorted(a, b, return_inds=False):\n  # technique adapted from http://stackoverflow.com/a/12427633/10601\n  c = np.concatenate((a, b))\n  c.sort(kind='mergesort')\n  mask = np.zeros(len(c), dtype=bool)\n  np.equal(c[1:], c[:-1], out=mask[:-1])\n  c = c[mask]\n  if not return_inds:\n    return c\n  a_inds = np.searchsorted(a, c)\n  b_inds = np.searchsorted(b, c)\n  return c, a_inds, b_inds\n\n\ndef _union1d_sorted(a, b, return_masks=False):\n  a = np.asanyarray(a)\n  b = np.asanyarray(b)\n  common_mask = np.in1d(a, b, assume_unique=True)\n  common = a[common_mask]\n  b_mask = np.in1d(b, common, assume_unique=True, invert=True)\n  b_only = b[b_mask]\n  c = np.concatenate((a, b_only))\n  c.sort(kind='mergesort')\n  mask = np.ones(len(c), dtype=bool)\n  np.not_equal(c[1:], c[:-1], out=mask[1:])\n  c = c[mask]\n  if not return_masks:\n    return c\n  lut = np.in1d(c, b_only) + 2 * np.in1d(c, common)\n  a_mask = ~common_mask\n  return c, lut, a_mask, b_mask\n\n\ndef _combine_ranges(ranges, shape, result_size, inner=False):\n  if inner:\n    return np.ravel_multi_index([np.arange(*row) for row in ranges], shape)\n  strides = np.ones(len(shape), dtype=ranges.dtype)\n  np.cumprod(shape[:0:-1], out=strides[1:])\n  flat_ranges = ranges * strides[::-1, None]\n  flat_idxs = (np.arange(*row) for row in flat_ranges)\n  result = next(flat_idxs)\n  for idx in flat_idxs:\n    result = np.add.outer(result, idx).ravel()\n  return result[:result_size]\n\n\ndef _len_range(start, stop, step):\n  if step > 0:\n    if start >= stop:\n      return 0\n    return (stop - start - 1) // step + 1\n  # negative step case\n  if stop >= start:\n    return 0\n  return (start - stop - 1) // -step + 1\n\n\n# Apply the shims where necessary\n\nif hasattr(np, 'broadcast_to'):  # pragma: no cover\n  broadcast_to = np.broadcast_to\nelse:  # pragma: no cover\n  broadcast_to = _broadcast_to\n\nif hasattr(ss.base, '_ufuncs_with_fixed_point_at_zero'):  # pragma: no cover\n  ufuncs_with_fixed_point_at_zero = ss.base._ufuncs_with_fixed_point_at_zero\nelse:  # pragma: no cover\n  ufuncs_with_fixed_point_at_zero = frozenset((\n      np.sin, np.tan, np.arcsin, np.arctan, np.sinh, np.tanh, np.arcsinh,\n      np.arctanh, np.rint, np.sign, np.expm1, np.log1p, np.deg2rad, np.rad2deg,\n      np.floor, np.ceil, np.trunc, np.sqrt))\n\ntry:  # pragma: no cover\n  # use pre-compiled _merge.so library\n  from _merge import (\n      intersect1d_sorted, union1d_sorted, combine_ranges, len_range)\nexcept ImportError:\n  # try compiling it ourselves on the fly\n  try:\n    import pyximport\n    pyximport.install(setup_args={'include_dirs': np.get_include()})\n    from _merge import (\n        intersect1d_sorted, union1d_sorted, combine_ranges, len_range)\n  except ImportError:\n    # fall back to pure-Python versions\n    intersect1d_sorted = _intersect1d_sorted\n    union1d_sorted = _union1d_sorted\n    combine_ranges = _combine_ranges\n    len_range = _len_range\n"""
sparray/flat.py,87,"b'from __future__ import absolute_import\nimport numbers\nimport numpy as np\nimport scipy.sparse as ss\nimport warnings\n\nfrom .base import _BaseSparray\nfrom .compat import (\n    broadcast_to, broadcast_shapes, ufuncs_with_fixed_point_at_zero,\n    intersect1d_sorted, union1d_sorted, combine_ranges, len_range\n)\n\n# masks for kinds of multidimensional indexing\nEMPTY_SLICE_INDEX_MASK = 0b1\nSLICE_INDEX_MASK = 0b10\nINTEGER_INDEX_MASK = 0b100\nARRAY_INDEX_MASK = 0b1000\n\n\nclass FlatSparray(_BaseSparray):\n  \'\'\'Simple sparse ndarray-like, similar to scipy.sparse matrices.\n  Defined by three member variables:\n    self.data : array of nonzero values (may include zeros)\n    self.indices : sorted int64 array of nonzero flat indices\n    self.shape : tuple of integers, ala ndarray shape\n  \'\'\'\n  def __init__(self, indices, data, shape=None, is_canonical=False):\n    indices = np.array(indices, dtype=int, copy=False).ravel()\n    data = np.array(data, copy=False).ravel()\n    assert len(indices) == len(data), \'# inds (%d) != # data (%d)\' % (\n        len(indices), len(data))\n    if not is_canonical:\n      # sort and sum duplicates, but allow explicit zeros\n      indices, inv_ind = np.unique(indices, return_inverse=True)\n      data = np.bincount(inv_ind, weights=data).astype(data.dtype, copy=False)\n    if shape is None:\n      self.shape = (indices[-1]+1,)\n    else:\n      self.shape = shape\n      assert np.prod(shape) >= len(data)\n    self.indices = indices\n    self.data = data\n\n  @property\n  def dtype(self):\n    return self.data.dtype\n\n  @staticmethod\n  def from_ndarray(arr):\n    \'\'\'Converts an array-like to a FlatSparray object.\'\'\'\n    arr = np.array(arr, copy=False)\n    mask = arr.flat != 0\n    idx, = np.nonzero(mask)\n    return FlatSparray(idx, arr.flat[mask], shape=arr.shape, is_canonical=True)\n\n  @staticmethod\n  def from_spmatrix(mat):\n    \'\'\'Converts a scipy.sparse matrix to a FlatSparray object\'\'\'\n    # attempt to canonicalize using scipy.sparse\'s code\n    try:\n      mat.sum_duplicates()\n    except AttributeError:\n      pass\n    mat = mat.tocoo()\n    inds = np.ravel_multi_index((mat.row, mat.col), mat.shape)\n    if (np.diff(inds) > 0).all():\n      # easy case: indices are pre-sorted\n      return FlatSparray(inds, mat.data, shape=mat.shape, is_canonical=True)\n    # do the sorting ourselves\n    order = np.argsort(inds)\n    return FlatSparray(inds[order], mat.data[order], shape=mat.shape,\n                       is_canonical=True)\n\n  def toarray(self):\n    a = np.zeros(self.shape, dtype=self.data.dtype)\n    a.flat[self.indices] = self.data\n    return a\n\n  def tocoo(self):\n    assert len(self.shape) == 2\n    row, col = np.unravel_index(self.indices, self.shape)\n    return ss.coo_matrix((self.data, (row, col)), shape=self.shape)\n\n  def getnnz(self):\n    \'\'\'Get the count of explicitly-stored values\'\'\'\n    return len(self.indices)\n\n  nnz = property(fget=getnnz, doc=getnnz.__doc__)\n\n  def nonzero(self):\n    \'\'\'Returns a tuple of arrays containing indices of non-zero elements.\n    Note: Does not include explicitly-stored zeros.\n    \'\'\'\n    nz_inds = self.indices[self.data!=0]\n    return np.unravel_index(nz_inds, self.shape)\n\n  def transpose(self, *axes):\n    if self.ndim < 2:\n      return self\n    # axes control dimension order, defaults to reverse\n    if not axes:\n      axes = range(self.ndim-1, -1, -1)\n    elif len(axes) == 1 and self.ndim > 1:\n      axes = axes[0]\n    new_shape = tuple(self.shape[i] for i in axes)\n    if self.shape == new_shape:\n      return self\n    # Hack: convert our flat indices into the new shape\'s flat indices.\n    old_multi_index = np.unravel_index(self.indices, self.shape)\n    new_multi_index = tuple(old_multi_index[i] for i in axes)\n    new_inds = np.ravel_multi_index(new_multi_index, new_shape)\n    return FlatSparray(new_inds, self.data, new_shape)\n\n  def diagonal(self, offset=0, axis1=0, axis2=1):\n    if axis1 == axis2:\n      raise ValueError(\'axis1 and axis2 cannot be the same\')\n    if self.ndim < 2:\n      raise ValueError(\'diagonal requires at least two dimensions\')\n    # TODO: support different axes, ndim > 2, etc\n    if self.ndim > 2:\n      raise NotImplementedError(\'diagonal() is NYI for ndim > 2\')\n    if axis1 != 0 or axis2 != 1:\n      raise NotImplementedError(\'diagonal() is NYI for non-default axes\')\n\n    if offset >= 0:\n      n = min(self.shape[0], self.shape[1] - offset)\n      ranges = np.array([[0, n, 1], [offset, n + offset, 1]],\n                        dtype=self.indices.dtype)\n    else:\n      n = min(self.shape[0] + offset, self.shape[1])\n      ranges = np.array([[-offset, n - offset, 1], [0, n, 1]],\n                        dtype=self.indices.dtype)\n    if n < 0:\n      return FlatSparray([], [], shape=(0,), is_canonical=True)\n\n    flat_idx = combine_ranges(ranges, self.shape, n, inner=True)\n    return self._getitem_flatidx(flat_idx, (n,))\n\n  def setdiag(self, values, offset=0):\n    if self.ndim < 2:\n      raise ValueError(\'setdiag() requires at least two dimensions\')\n    # TODO: support different axes, ndim > 2, etc\n    if self.ndim > 2:\n      raise NotImplementedError(\'setdiag() is NYI for ndim > 2\')\n\n    # XXX: copypasta from diagonal()\n    if offset >= 0:\n      n = min(self.shape[0], self.shape[1] - offset)\n      ranges = np.array([[0, n, 1], [offset, n + offset, 1]],\n                        dtype=self.indices.dtype)\n    else:\n      n = min(self.shape[0] + offset, self.shape[1])\n      ranges = np.array([[-offset, n - offset, 1], [0, n, 1]],\n                        dtype=self.indices.dtype)\n\n    if n <= 0:\n      return self\n\n    diag_indices = combine_ranges(ranges, self.shape, n, inner=True)\n    self._setitem_flatidx(diag_indices, values)\n\n  def __repr__(self):\n    return \'<%s-FlatSparray of type %s\\n\\twith %d stored elements>\' % (\n        self.shape, self.data.dtype, self.getnnz())\n\n  def __str__(self):\n    lines = []\n    multi_inds = np.unravel_index(self.indices, self.shape)\n    for x in zip(self.data, *multi_inds):\n      lines.append(\'  %s\\t%s\' % (x[1:], x[0]))\n    return \'\\n\'.join(lines)\n\n  def reshape(self, new_shape):\n    try:\n      idx = new_shape.index(-1)\n    except ValueError:\n      assert np.prod(new_shape) >= len(self.data)\n    else:\n      assert sum(d == -1 for d in new_shape) == 1, \'Only one -1 allowed\'\n      new_shape = list(new_shape)\n      new_shape[idx] = np.prod(self.shape) // -np.prod(new_shape)\n    return FlatSparray(self.indices, self.data, shape=new_shape,\n                       is_canonical=True)\n\n  def resize(self, new_shape):\n    assert np.prod(new_shape) >= len(self.data)\n    self.shape = new_shape\n\n  def ravel(self):\n    n = int(np.prod(self.shape))\n    return FlatSparray(self.indices, self.data, shape=(n,), is_canonical=True)\n\n  def _prepare_indices(self, index):\n    # avoid dealing with non-tuple cases\n    if not isinstance(index, tuple):\n      index = (index,)\n\n    # check for Ellipsis and array-like indices\n    ell_inds = []\n    mut_indices = []\n    for idx in index:\n      if idx is Ellipsis:\n        ell_inds.append(len(mut_indices))\n      elif not isinstance(idx, (slice, numbers.Integral)):\n        if not hasattr(idx, \'ndim\'):\n          idx = np.array(idx, copy=False, subok=True, order=\'A\')\n        if idx.dtype in (bool, np.bool_):\n          mut_indices.extend(idx.nonzero())\n          continue\n        if idx.ndim > 1:\n          # TODO: support this case\n          raise NotImplementedError(\'Multi-dimensional indexing is NYI\')\n      mut_indices.append(idx)\n\n    if len(ell_inds) > 1:\n      # According to http://sourceforge.net/p/numpy/mailman/message/12594675/,\n      # only the first Ellipsis is ""real"", and the rest are just slice(None).\n      # In recent numpy versions this is disallowed, so we take the easy route.\n      raise IndexError(""an index can only have a single ellipsis (\'...\')"")\n\n    # pad missing dimensions with colons (empty slices)\n    missing_dims = len(self.shape) - len(mut_indices)\n    if ell_inds:\n      # insert as many colons as we need at the Ellipsis position\n      ell_pos, = ell_inds\n      mut_indices[ell_pos:ell_pos+1] = [slice(None)] * (missing_dims+1)\n    elif missing_dims > 0:\n      mut_indices.extend([slice(None)] * missing_dims)\n\n    if len(mut_indices) > len(self.shape):\n      raise IndexError(\'too many indices for FlatSparray\')\n    # indices now match our shape, and each index is int|slice|array\n    assert len(mut_indices) == len(self.shape)\n\n    # do some simple checking / fixup\n    idx_type = 0\n    for axis, (idx, dim) in enumerate(zip(mut_indices, self.shape)):\n      if isinstance(idx, numbers.Integral):\n        if not (-dim <= idx < dim):\n          raise IndexError(\'index %d is out of bounds \'\n                           \'for axis %d with size %d\' % (idx, axis, dim))\n        if idx < 0:\n          mut_indices[axis] += dim\n        idx_type |= INTEGER_INDEX_MASK\n      elif isinstance(idx, slice):\n        if idx == slice(None):\n          idx_type |= EMPTY_SLICE_INDEX_MASK\n        else:\n          idx_type |= SLICE_INDEX_MASK\n      elif hasattr(idx, \'shape\'):\n        idx_type |= ARRAY_INDEX_MASK\n    return tuple(mut_indices), idx_type\n\n  def __getitem__(self, indices):\n    indices, idx_type = self._prepare_indices(indices)\n\n    # trivial case: all slices are colons\n    if idx_type == EMPTY_SLICE_INDEX_MASK:\n      return self\n\n    # simple case: all indices are simple int indexes\n    if idx_type == INTEGER_INDEX_MASK:\n      flat_idx = np.ravel_multi_index(indices, self.shape)\n      i = np.searchsorted(self.indices, flat_idx)\n      if i >= len(self.indices) or self.indices[i] != flat_idx:\n        return 0\n      return self.data[i]\n\n    # non-fancy case: all indices are slices or integers\n    if not (idx_type & ARRAY_INDEX_MASK):\n      ranges, new_shape = self._indices_to_ranges(indices)\n      flat_idx = combine_ranges(ranges, self.shape, np.product(new_shape),\n                                inner=False)\n      return self._getitem_flatidx(flat_idx, new_shape)\n\n    # inner-only fancy indexing\n    # TODO: ndim index arrays are NYI for now\n    if not (idx_type & (EMPTY_SLICE_INDEX_MASK | SLICE_INDEX_MASK)):\n      flat_idx = np.ravel_multi_index(indices, self.shape)\n      return self._getitem_flatidx(flat_idx, (len(flat_idx),))\n\n    # compute the new shape, pulling out int/array indices\n    new_shape = []\n    inner_indices, outer_indices = [], []\n    inner_shape_idx = None\n    non_slice_idxs = []\n    for i, idx in enumerate(indices):\n      if isinstance(idx, slice):\n        x = np.arange(*idx.indices(self.shape[i]))\n        new_shape.append(len(x))\n        inner_indices.append(0)  # placeholder\n        outer_indices.append(x)\n      else:\n        non_slice_idxs.append(i)\n        inner_indices.append(idx)\n        if inner_shape_idx is None:\n          inner_shape_idx = len(new_shape)\n          # make placeholders\n          if isinstance(idx, numbers.Integral):\n            new_shape.append(-1)\n          else:\n            new_shape.append(len(idx))\n          outer_indices.append(None)\n        elif not isinstance(idx, numbers.Integral):\n          new_shape[inner_shape_idx] = max(len(idx), new_shape[inner_shape_idx])\n\n    # exit now if there\'s a zero dimension\n    if any(s == 0 for s in new_shape):\n      return FlatSparray([], [], tuple(new_shape), is_canonical=True)\n\n    # coalesce the inner indices\n    if inner_shape_idx is not None:\n      x = np.ravel_multi_index(inner_indices, self.shape)\n      new_shape[inner_shape_idx] = len(x)\n      outer_indices[inner_shape_idx] = x\n\n    # only outer indexes remain\n    strides = np.ones(len(self.shape), dtype=self.indices.dtype)\n    np.cumprod(self.shape[:0:-1], out=strides[1:])\n    strides = strides[::-1]\n    strides[non_slice_idxs] = 1\n    flat_idx = outer_indices[0] * strides[0]\n    for idx, s in zip(outer_indices[1:], strides[1:]):\n      flat_idx = np.add.outer(flat_idx, idx * s).ravel()\n    return self._getitem_flatidx(flat_idx, new_shape, is_sorted=(self.ndim<2))\n\n  def __setitem__(self, indices, val):\n    indices, idx_type = self._prepare_indices(indices)\n\n    # all slices are colons\n    if idx_type == EMPTY_SLICE_INDEX_MASK:\n      raise ValueError(\'Assigning to entire FlatSparray would densify.\')\n\n    # all indices are simple int indexes\n    if idx_type == INTEGER_INDEX_MASK:\n      flat_idx = np.ravel_multi_index(indices, self.shape)\n      i = np.searchsorted(self.indices, flat_idx)\n      if i >= len(self.indices) or self.indices[i] != flat_idx:\n        # we\'re not in the existing sparsity structure\n        # TODO: raise a warning here?\n        new_size = self.data.shape[0] + 1\n        new_data = np.empty(new_size, dtype=self.data.dtype)\n        new_data[:i] = self.data[:i]\n        new_data[i+1:] = self.data[i:]\n        new_indices = np.empty(new_size, dtype=self.indices.dtype)\n        new_indices[:i] = self.indices[:i]\n        new_indices[i] = flat_idx\n        new_indices[i+1:] = self.indices[i:]\n        self.data = new_data\n        self.indices = new_indices\n      # we\'re now definitely in the sparsity structure, so assign away\n      self.data[i] = val\n      return\n\n    # non-fancy case: all indices are slices or integers\n    if not (idx_type & ARRAY_INDEX_MASK):\n      ranges, idx_shape = self._indices_to_ranges(indices)\n      new_indices = combine_ranges(ranges, self.shape, np.product(idx_shape),\n                                   inner=False)\n      self._setitem_flatidx(new_indices, val)\n      return\n\n    # TODO: implement the rest\n    raise NotImplementedError(\'Fancy assignment is still NYI\')\n\n  def _indices_to_ranges(self, indices):\n    \'\'\'Assumes that all indices are slices or integers.\n    Returns:\n      ranges - an array of [(start, stop, step)] values\n      new_shape - the resulting shape of the indexing operation\n    \'\'\'\n    ranges = np.zeros((len(indices), 3), dtype=self.indices.dtype)\n    new_shape = []\n    for i, idx in enumerate(indices):\n      if isinstance(idx, slice):\n        row = idx.indices(self.shape[i])\n        ranges[i,:] = row\n        new_shape.append(len_range(*row))\n      else:\n        ranges[i,:] = (idx, idx + 1, 1)\n    return ranges, new_shape\n\n  def _getitem_flatidx(self, flat_idx, new_shape, is_sorted=True):\n    if not is_sorted:\n      order = np.argsort(flat_idx, kind=\'mergesort\')\n      flat_idx = flat_idx[order]\n    _, data_inds, new_indices = intersect1d_sorted(self.indices, flat_idx,\n                                                   return_inds=True)\n    new_data = self.data[data_inds]\n    if not is_sorted:\n      new_indices = order[new_indices]\n    return FlatSparray(new_indices, new_data, tuple(new_shape),\n                       is_canonical=True)\n\n  def _setitem_flatidx(self, flat_idx, values):\n    idx, lut, lhs_only, rhs_only = union1d_sorted(self.indices, flat_idx,\n                                                  return_masks=True)\n    if np.count_nonzero(rhs_only) == 0:\n      # no change to sparsity structure\n      self.data[lut!=0] = values\n    else:\n      # need to expand the structure (TODO: warn here?)\n      data = np.empty_like(idx, dtype=self.dtype)\n      data[lut!=1] = self.data\n      data[lut!=0] = values\n      self.indices = idx\n      self.data = data\n\n  def _pairwise_sparray(self, other, ufunc, dtype=None):\n    \'\'\'Helper function for the pattern: ufunc(sparse, sparse) -> sparse\n    other : FlatSparray with the same shape\n    ufunc : vectorized binary function\n    \'\'\'\n    if dtype is None:\n      dtype = np.promote_types(self.dtype, other.dtype)\n    idx, lut, lhs_only, rhs_only = union1d_sorted(self.indices, other.indices,\n                                                  return_masks=True)\n    data = np.empty_like(idx, dtype=dtype)\n    data[lut==0] = ufunc(self.data[lhs_only], 0)\n    data[lut==1] = ufunc(0, other.data[rhs_only])\n    data[lut==2] = ufunc(self.data[~lhs_only], other.data[~rhs_only])\n    return FlatSparray(idx, data, self.shape, is_canonical=True)\n\n  def _pairwise_sparray_fixed_zero(self, other, ufunc):\n    \'\'\'Helper function for the pattern: ufunc(sparse, sparse) -> sparse\n    other : FlatSparray with the same shape\n    ufunc : vectorized binary function, where ufunc(x, 0) -> 0\n    \'\'\'\n    idx, lhs_inds, rhs_inds = intersect1d_sorted(self.indices, other.indices,\n                                                 return_inds=True)\n    lhs = self.data[lhs_inds]\n    rhs = other.data[rhs_inds]\n    data = ufunc(lhs, rhs)\n    return FlatSparray(idx, data, self.shape, is_canonical=True)\n\n  def _pairwise_dense2dense(self, other, ufunc):\n    \'\'\'Helper function for the pattern: ufunc(dense, sparse) -> dense\n    other : ndarray\n    \'\'\'\n    result = other.copy(order=\'C\')\n    result.flat[self.indices] = ufunc(result.flat[self.indices], self.data)\n    return result\n\n  def _pairwise_dense2sparse(self, other, ufunc):\n    \'\'\'Helper function for the pattern: ufunc(dense, sparse) -> sparse\n    other : array_like\n    \'\'\'\n    other = np.asanyarray(other)\n    return self._with_data(ufunc(self.data, other.flat[self.indices]))\n\n  def _handle_broadcasting(self, other):\n    if other.shape == self.shape:\n      return self, other\n    # Find a shape that we can broadcast to\n    bshape = broadcast_shapes(self.shape, other.shape)\n    # Do broadcasting for the lhs\n    if self.shape == bshape:\n      lhs = self\n    else:\n      lhs = self._broadcast(bshape)\n    # Do broadcasting for the rhs\n    if other.shape == bshape:\n      rhs = other\n    elif isinstance(other, FlatSparray):\n      rhs = other._broadcast(bshape)\n    else:\n      rhs = broadcast_to(other, bshape, subok=True)\n    return lhs, rhs\n\n  def _broadcast(self, shape):\n    # TODO: fix this hack! Need to avoid densifying here.\n    return FlatSparray.from_ndarray(broadcast_to(self.toarray(), shape))\n\n  def _comparison(self, other, method_name, ufunc, op_symbol):\n    if np.isscalar(other):\n      if not ufunc(0, other):\n        return self._with_data(ufunc(self.data, other))\n      kind = \'nonzero scalar\' if other != 0 else \'0\'\n      warnings.warn(\'FlatSparray %s %s densifies\' % (op_symbol, kind),\n                    ss.SparseEfficiencyWarning)\n      return ufunc(self.toarray(), other)\n    if ss.issparse(other):\n      return getattr(self.tocoo(), method_name)(other)  # punt\n    lhs, rhs = self._handle_broadcasting(other)\n    assert isinstance(lhs, FlatSparray)\n    if isinstance(rhs, FlatSparray):\n      return lhs._pairwise_sparray(rhs, ufunc, dtype=bool)\n    return ufunc(self.toarray(), other)\n\n  def __add__(self, other):\n    if np.isscalar(other):\n      if other == 0:\n        return self.copy()\n      warnings.warn(\'FlatSparray + nonzero scalar densifies\',\n                    ss.SparseEfficiencyWarning)\n      return self.toarray() + other\n    if ss.issparse(other):\n      # np.matrix + np.array always returns np.matrix, so for now we punt\n      return self.tocoo() + other\n    lhs, rhs = self._handle_broadcasting(other)\n    assert isinstance(lhs, FlatSparray)\n    if isinstance(rhs, FlatSparray):\n      return lhs._pairwise_sparray(rhs, np.add)\n    # dense addition\n    return lhs._pairwise_dense2dense(rhs, np.add)\n\n  def __mul__(self, other):\n    if np.isscalar(other):\n      return self._with_data(self.data * other)\n    if ss.issparse(other):\n      # np.matrix * np.array always returns np.matrix, so for now we punt\n      return self.tocoo().multiply(other)\n    lhs, rhs = self._handle_broadcasting(other)\n    assert isinstance(lhs, FlatSparray)\n    if isinstance(rhs, FlatSparray):\n      return lhs._pairwise_sparray_fixed_zero(rhs, np.multiply)\n    # dense * sparse -> sparse\n    return lhs._pairwise_dense2sparse(rhs, np.multiply)\n\n  def _divide(self, other, div_func=np.divide, rdivide=False):\n    # Don\'t bother keeping sparsity if rhs is sparse\n    if ss.issparse(other) or isinstance(other, FlatSparray):\n      other = other.toarray()\n      if not rdivide:\n        return div_func(self.toarray(), other)\n    if rdivide:\n      return div_func(other, self.toarray())\n    # Punt truediv to __mul__\n    if div_func is np.true_divide:\n      return self.__mul__(1. / other)\n    # Non-truediv cases\n    if np.isscalar(other):\n      return self._with_data(div_func(self.data, other))\n    lhs, rhs = self._handle_broadcasting(other)\n    # dense / sparse -> sparse\n    return lhs._pairwise_dense2sparse(rhs, div_func)\n\n  def dot(self, other):\n    ax1 = len(self.shape) - 1\n    ax2 = max(0, len(other.shape) - 2)\n    if self.shape[ax1] != other.shape[ax2]:\n      raise ValueError(\'shapes %s and %s not aligned\' % (self.shape,\n                                                         other.shape))\n    # if other is sparse, use spmatrix dot\n    if ss.issparse(other) or isinstance(other, FlatSparray):\n      out_shape = self.shape[:-1] + other.shape[:ax2] + other.shape[ax2+1:]\n      lhs_shape = (int(np.product(self.shape[:-1])), self.shape[ax1])\n      lhs = self.reshape(lhs_shape).tocoo()\n      if isinstance(other, FlatSparray):\n        # transpose so ax2 comes first\n        axes = (ax2,) + tuple(range(ax2)) + tuple(range(ax2+1,len(other.shape)))\n        other = other.transpose(*axes)\n        # reshape to 2d for spmatrix\n        rhs_shape = (other.shape[0], int(np.product(other.shape[1:])))\n        other = other.reshape(rhs_shape).tocoo()\n      result = lhs.dot(other)\n      # convert back to a FlatSparray with the correct shape\n      if not out_shape:  # scalar case, return a scalar\n        return result[0,0]\n      return FlatSparray.from_spmatrix(result).reshape(out_shape)\n\n    # other is dense\n    if self.ndim == 1 and other.ndim == 1:\n      # TODO: allow other shapes for self here\n      return other[self.indices].dot(self.data)\n    # dense rhs always returns dense result\n    return self.toarray().dot(other)\n\n  def __pow__(self, exponent):\n    if exponent == 0:\n      warnings.warn(\'FlatSparray ** 0 densifies\', ss.SparseEfficiencyWarning)\n      return np.ones(self.shape, dtype=self.dtype)\n    elif exponent < 0:\n      warnings.warn(\'FlatSparray ** negative exponent densifies\',\n                    ss.SparseEfficiencyWarning)\n      return self.toarray() ** exponent\n    return self._with_data(self.data ** exponent)\n\n  def _with_data(self, data):\n    return FlatSparray(self.indices.copy(), data, self.shape, is_canonical=True)\n\n  def minimum(self, other):\n    if np.isscalar(other) and other >= 0:\n      return self._with_data(np.minimum(self.data, other))\n    if isinstance(other, FlatSparray):\n      return self._pairwise_sparray(other, np.minimum)\n    if ss.issparse(other):\n      # For now, convert to FlatSparray first and then do the operation\n      return self._pairwise_sparray(FlatSparray.from_spmatrix(other),\n                                    np.minimum)\n    # Probably won\'t get a sparse result\n    return np.minimum(self.toarray(), other)\n\n  def maximum(self, other):\n    if np.isscalar(other) and other <= 0:\n      return self._with_data(np.maximum(self.data, other))\n    if isinstance(other, FlatSparray):\n      return self._pairwise_sparray(other, np.maximum)\n    if ss.issparse(other):\n      # For now, convert to FlatSparray first and then do the operation\n      return self._pairwise_sparray(FlatSparray.from_spmatrix(other),\n                                    np.maximum)\n    # Probably won\'t get a sparse result\n    return np.maximum(self.toarray(), other)\n\n  def sum(self, axis=None, dtype=None):\n    if dtype is None:\n      dtype = self.dtype\n    if axis is None:\n      return self.data.sum(dtype=dtype)\n    # XXX: we don\'t support tuples of axes, yet\n    axis = int(axis)\n    new_shape = self.shape[:axis] + self.shape[axis+1:]\n    if not new_shape:\n      return self.data.sum(dtype=dtype)\n    axis_inds = np.unravel_index(self.indices, self.shape)\n    axis_inds = axis_inds[:axis] + axis_inds[axis+1:]\n    flat_inds = np.ravel_multi_index(axis_inds, new_shape)\n    new_idx, data_idx = np.unique(flat_inds, return_inverse=True)\n    # Note: we can\'t use:\n    #    new_data = np.zeros(new_idx.shape, dtype=dtype)\n    #    new_data[data_idx] += self.data\n    # here, because the fancy index doesn\'t return a proper view.\n    new_data = np.bincount(data_idx, self.data.astype(dtype, copy=False))\n    return FlatSparray(new_idx, new_data, shape=new_shape, is_canonical=True)\n\n  def __numpy_ufunc__(self, func, method, pos, inputs, **kwargs):\n    \'\'\'ufunc dispatcher. Mostly copied from scipy.sparse.spmatrix\'\'\'\n    out = kwargs.pop(\'out\', None)\n\n    without_self = list(inputs)\n    del without_self[pos]\n    without_self = tuple(without_self)\n\n    if func is np.multiply:\n      result = self.__mul__(*without_self)\n    elif func is np.add:\n      result = self.__add__(*without_self)\n    elif func is np.dot:\n      if pos == 0:\n        result = self.dot(inputs[1])\n      else:\n        result = self._rdot(inputs[0])\n    elif func is np.subtract:\n      if pos == 0:\n        result = self.__sub__(inputs[1])\n      else:\n        result = self.__rsub__(inputs[0])\n    elif func in (np.divide, np.true_divide, np.floor_divide):\n      result = self._divide(*without_self, div_func=func, rdivide=(pos==1))\n    elif func in (np.minimum, np.maximum):\n      result = getattr(self, func.__name__)(*without_self)\n    elif func is np.absolute:\n      result = abs(self)\n    elif func in (np.conj, np.conjugate):\n      result = self.conj()\n    elif func in ufuncs_with_fixed_point_at_zero:\n      result = getattr(self, func.__name__)()\n    else:\n      return NotImplemented\n\n    if out is not None:\n      if not isinstance(out, FlatSparray) and isinstance(result, FlatSparray):\n        out[...] = result.toarray()\n      else:\n        out.data = result.data\n        out.indices = result.indices\n        out.shape = result.shape\n      result = out\n\n    return result\n\n  # The following code is completely ripped from scipy.sparse.data._data_matrix.\n  # I\'m including it here because I don\'t want to inherit from spmatrix.\n\n  def __abs__(self):\n    return self._with_data(abs(self.data))\n\n  @property\n  def real(self):\n    return self._with_data(self.data.real)\n\n  @property\n  def imag(self):\n    return self._with_data(self.data.imag)\n\n  def __neg__(self):\n    return self._with_data(-self.data)\n\n  def __imul__(self, other):  # self *= other\n    if np.isscalar(other):\n      self.data *= other\n      return self\n    # defer to self = self * other\n    return NotImplemented\n\n  def __itruediv__(self, other):  # self /= other\n    if np.isscalar(other):\n      recip = 1.0 / other\n      self.data *= recip\n      return self\n    # defer to self = self / other\n    return NotImplemented\n\n  def astype(self, t):\n    return self._with_data(self.data.astype(t))\n\n  def conj(self):\n    return self._with_data(self.data.conj())\n\n  def copy(self):\n    return self._with_data(self.data.copy())\n\n  def min(self):\n    # TODO: axis kwarg\n    return self.data.min()\n\n  def max(self):\n    # TODO: axis kwarg\n    return self.data.max()\n\n\n# Add the numpy unary ufuncs for which func(0) = 0\nfor npfunc in ufuncs_with_fixed_point_at_zero:\n  name = npfunc.__name__\n\n  def _create_method(op):\n    def method(self):\n      result = op(self.data)\n      x = self._with_data(result)\n      return x\n\n    method.__doc__ = (""Element-wise %s.\\n\\n""\n                      ""See numpy.%s for more information."" % (name, name))\n    method.__name__ = name\n    return method\n\n  setattr(FlatSparray, name, _create_method(npfunc))\n'"
bench/benchmarks/__init__.py,0,b'\n'
bench/benchmarks/construction.py,5,"b""import numpy as np\nimport scipy.sparse as ss\n\nfrom sparray import FlatSparray\n\n\nclass Construction2D(object):\n  def setup(self):\n    num_rows, num_cols = 3000, 4000\n    self.spm = ss.rand(num_rows, num_cols, density=0.1, format='coo')\n    self.arr = self.spm.A\n    self.data = self.spm.data\n    self.indices = self.spm.row * num_cols + self.spm.col\n    self.spm_csr = self.spm.tocsr()\n\n  def time_init(self):\n    FlatSparray(self.indices, self.data, shape=self.arr.shape)\n\n  def time_from_ndarray(self):\n    FlatSparray.from_ndarray(self.arr)\n\n  def time_from_spmatrix_coo(self):\n    FlatSparray.from_spmatrix(self.spm)\n\n  def time_from_spmatrix_csr(self):\n    FlatSparray.from_spmatrix(self.spm_csr)\n\n\nclass ConstructionND(object):\n  params = [[(1200000,), (1200,1000), (120,100,100), (20,30,40,50)]]\n  param_names = ['shape']\n\n  def setup(self, shape):\n    nnz = 10000\n    size = np.prod(shape)\n    self.indices = np.random.choice(size, nnz, replace=False)\n    self.sorted_indices = np.sort(self.indices)\n    self.data = np.ones(nnz, dtype=float)\n    arr = np.zeros(size, dtype=float)\n    arr[self.sorted_indices] = 1\n    self.arr = arr.reshape(shape)\n\n  def time_init(self, shape):\n    FlatSparray(self.indices, self.data, shape=shape)\n\n  def time_canonical_init(self, shape):\n    FlatSparray(self.sorted_indices, self.data, shape=shape, is_canonical=True)\n\n  def time_from_ndarray(self, shape):\n    FlatSparray.from_ndarray(self.arr)\n"""
bench/benchmarks/ops.py,0,"b""import scipy.sparse as ss\nimport warnings\nwarnings.simplefilter('ignore', ss.SparseEfficiencyWarning)\n\nfrom sparray import FlatSparray\n\n\nclass Operations(object):\n  params = [['FlatSparray', 'csr_matrix']]\n  param_names = ['arr_type']\n\n  def setup(self, arr_type):\n    mat = ss.rand(3000, 4000, density=0.1, format='csr')\n    if arr_type == 'FlatSparray':\n      self.arr = FlatSparray.from_spmatrix(mat)\n    else:\n      self.arr = mat\n\n  def time_scalar_multiplication(self, arr_type):\n    self.arr * 3\n\n  def time_sum(self, arr_type):\n    self.arr.sum()\n\n  def time_getitem_scalar(self, arr_type):\n    self.arr[154, 145]\n\n  def time_getitem_subarray(self, arr_type):\n    self.arr[:5, :5]\n\n  def time_getitem_row(self, arr_type):\n    self.arr[876]\n\n  def time_getitem_col(self, arr_type):\n    self.arr[:,273]\n\n  def time_diagonal(self, arr_type):\n    self.arr.diagonal()\n\n\nclass ImpureOperations(object):\n  params = [['FlatSparray', 'csr_matrix']]\n  param_names = ['arr_type']\n  number = 1  # make sure we re-run setup() before each timing\n\n  def setup(self, arr_type):\n    mat = ss.rand(3000, 4000, density=0.1, format='csr')\n    if arr_type == 'FlatSparray':\n      self.arr = FlatSparray.from_spmatrix(mat)\n    else:\n      self.arr = mat\n\n  def time_setdiag(self, arr_type):\n    self.arr.setdiag(99)\n"""
sparray/tests/__init__.py,0,b''
sparray/tests/_matmul.py,4,"b""# This file should only be imported in versions 3.5+\nimport unittest\nimport numpy as np\nfrom numpy.testing import assert_array_almost_equal\n\nfrom .test_base import BaseSparrayTest, dense1d, dense2d\n\n# Check for numpy 1.10+\nHAS_NUMPY_MATMUL = True\ntry:\n  np.arange(3) @ np.arange(3)\nexcept TypeError:\n  HAS_NUMPY_MATMUL = False\n\n\nclass TestMatmulOperator(BaseSparrayTest):\n\n  @unittest.skipUnless(HAS_NUMPY_MATMUL, 'Requires numpy with @ support')\n  def test_matmul(self):\n    b = np.random.random((dense2d.shape[1], dense2d.shape[0]))\n    assert_array_almost_equal(dense2d @ b, self.sp2d @ b)\n\n    b = np.random.random(dense1d.shape[0])\n    self.assertAlmostEqual(dense1d @ b, self.sp1d @ b)\n\n    # Test bad alignment for dot\n    b = np.random.random(dense1d.shape[0] + 1)\n    self.assertRaises(ValueError, lambda: self.sp1d @ b)\n"""
sparray/tests/test_base.py,5,"b""import unittest\nimport numpy as np\nimport scipy.sparse as ss\nimport warnings\nfrom numpy.testing import assert_array_equal, assert_array_almost_equal\nfrom sparray import FlatSparray\n\ndense2d = np.array([[0,0,0],[4,5,7],[6,2,0],[1,3,8]], dtype=float) / 2.\ndense2d_indices = [1,3,4,5,6,7,9,10,11]\ndense2d_data = [0,2,2.5,3.5,3,1,0.5,1.5,4]\n\n# Ignore efficiency warnings\nwarnings.simplefilter('ignore', ss.SparseEfficiencyWarning)\nsparse2d = ss.csr_matrix(dense2d)\nsparse2d[0,1] = 0  # Add the explicit zero to match indices,data\n\ndense1d = np.arange(5) - 2\ndense1d_indices = [0,1,3,4]\ndense1d_data = [-2,-1,1,2]\n\ndense3d = np.arange(24).reshape((3,2,4))[::-1]\ndense3d[[0,2],:,2:] = 0\ndense3d[1,0,:] = 0\n\n\ndef assert_sparse_equal(a, b, err_msg=''):\n  if hasattr(a, 'A'):\n    a = a.A\n  if hasattr(b, 'A'):\n    b = b.A\n  return assert_array_equal(a, b, err_msg=err_msg)\n\n\ndef assert_sparse_almost_equal(a, b, err_msg=''):\n  if hasattr(a, 'A'):\n    a = a.A\n  if hasattr(b, 'A'):\n    b = b.A\n  return assert_array_almost_equal(a, b, err_msg=err_msg)\n\n\nclass BaseSparrayTest(unittest.TestCase):\n  '''Base class that other tests can inherit from'''\n  def setUp(self):\n    self.sp1d = FlatSparray(dense1d_indices, dense1d_data, shape=dense1d.shape)\n    self.sp2d = FlatSparray(dense2d_indices, dense2d_data, shape=dense2d.shape)\n    self.sp3d = FlatSparray.from_ndarray(dense3d)\n    self.pairs = [\n        (dense1d, self.sp1d),\n        (dense2d, self.sp2d),\n        (np.array([]), FlatSparray([],[],shape=(0,))),\n        (np.zeros((1,2,3)), FlatSparray([],[],shape=(1,2,3))),\n        (dense3d, self.sp3d),\n    ]\n\n  def _same_op(self, op, assertFn):\n    for d, s in self.pairs:\n      assertFn(op(s), op(d))\n\n\nclass TestCreation(unittest.TestCase):\n  def test_init(self):\n    a = FlatSparray(dense2d_indices, dense2d_data, shape=dense2d.shape)\n    assert_array_equal(a.toarray(), dense2d)\n    b = FlatSparray(dense1d_indices, dense1d_data, shape=dense1d.shape)\n    assert_array_equal(b.toarray(), dense1d)\n    b = FlatSparray(dense1d_indices, dense1d_data)\n    assert_array_equal(b.toarray(), dense1d)\n\n  def test_from_ndarray(self):\n    for arr in (dense2d, dense1d, dense3d):\n      a = FlatSparray.from_ndarray(arr)\n      assert_array_equal(a.toarray(), arr)\n\n  def test_from_spmatrix(self):\n    for fmt in ('csr', 'csc', 'coo', 'dok', 'lil', 'dia'):\n      a = FlatSparray.from_spmatrix(sparse2d.asformat(fmt))\n      assert_array_equal(a.toarray(), dense2d,\n                         'Failed to convert from %s' % fmt.upper())\n\n\nif __name__ == '__main__':\n  unittest.main()\n"""
sparray/tests/test_compat.py,4,"b""import unittest\nimport numpy as np\nfrom numpy.testing import assert_array_equal\n\nimport sparray.compat as sc\n\n\nclass CompatibilityTest(unittest.TestCase):\n\n  def test_intersect1d_sorted(self):\n    a, b = np.array([0, 1, 4, 6, 8, 9]), np.array([2, 4, 5, 6, 7])\n    expected = [4, 6]\n    for fn in set((sc._intersect1d_sorted, sc.intersect1d_sorted)):\n      assert_array_equal(fn(a, b), expected)\n      x, a_inds, b_inds = fn(a, b, return_inds=True)\n      assert_array_equal(x, expected)\n      assert_array_equal(a_inds, [2, 3])\n      assert_array_equal(b_inds, [1, 3])\n\n  def test_union1d_sorted(self):\n    a, b = np.array([0, 2, 4, 8]), np.array([1, 4, 6, 8])\n    expected = [0, 1, 2, 4, 6, 8]\n    for fn in set((sc._union1d_sorted, sc.union1d_sorted)):\n      assert_array_equal(fn(a, b), expected)\n      x, lut, a_only, b_only = fn(a, b, return_masks=True)\n      assert_array_equal(x, expected)\n      assert_array_equal(lut, [0, 1, 0, 2, 1, 2])\n      assert_array_equal(a_only, [True, True, False, False])\n      assert_array_equal(b_only, [True, False, True, False])\n\n  def test_broadcast_to(self):\n    for x in (np.array(0), np.ma.array(0)):\n      for shape in [(5,6), (1200,), (2,3,4,5)]:\n        res = sc._broadcast_to(x, shape, subok=True)\n        self.assertEqual(res.shape, shape)\n        self.assertIs(type(res), type(x))\n\n  def test_combine_ranges(self):\n    ranges = np.array([[0, 2, 1], [1, 2, 1], [1, 4, 2]])\n    expected_outer = [5, 7, 17, 19]\n    expected_inner = [5, 19]\n    for fn in set((sc._combine_ranges, sc.combine_ranges)):\n      x = fn(ranges, (2, 3, 4), 4)\n      assert_array_equal(x, expected_outer)\n      x = fn(ranges, (2, 3, 4), 2, inner=True)\n      assert_array_equal(x, expected_inner)\n\n  def test_len_range(self):\n    for fn in set((sc._len_range, sc.len_range)):\n      self.assertEqual(fn(0, 5, 1), len(range(0, 5, 1)))\n      self.assertEqual(fn(5, 1, 1), len(range(5, 1, 1)))\n      self.assertEqual(fn(5, 0, -1), len(range(5, 0, -1)))\n      self.assertEqual(fn(0, 5, -2), len(range(0, 5, -2)))\n\nif __name__ == '__main__':\n  unittest.main()\n"""
sparray/tests/test_indexing.py,6,"b""from __future__ import absolute_import\nimport numpy as np\nimport unittest\nfrom numpy.testing import assert_array_equal\n\nfrom .test_base import (\n    BaseSparrayTest, dense1d, dense2d, sparse2d, dense3d, assert_sparse_equal)\n\n\nclass TestIndexing(BaseSparrayTest):\n\n  def test_simple_indexing(self):\n    for i in [0, 1, len(dense1d)-1, -1]:\n      self.assertEqual(dense1d[i], self.sp1d[i])\n    for i in [0, 1, len(dense2d)-1, -1]:\n      for j in [0, 1, dense2d.shape[1]-1, -1]:\n        self.assertEqual(dense2d[i,j], self.sp2d[i,j])\n    # check out of bounds indexes\n    self.assertRaises(IndexError, lambda: self.sp1d[len(dense1d)])\n\n  def test_ellipses(self):\n    assert_array_equal(dense1d[...], self.sp1d[...].toarray())\n    assert_array_equal(dense2d[...], self.sp2d[...].toarray())\n    # two ellipses is an error in recent numpy\n    self.assertRaises(IndexError, lambda: self.sp1d[...,...])\n    # three ellipses is too many for any numpy\n    self.assertRaises(IndexError, lambda: self.sp1d[...,...,...])\n\n  def test_partial_indexing(self):\n    for i in [0, 1, len(dense2d)-1, -1]:\n      assert_array_equal(dense2d[i], self.sp2d[i].toarray())\n    for j in [0, 1, dense2d.shape[1]-1, -1]:\n      assert_array_equal(dense2d[:,j], self.sp2d[:,j].toarray())\n\n  def test_iter(self):\n    assert_array_equal(dense1d, list(self.sp1d))\n    for dense_row, sparse_row in zip(dense2d, self.sp2d):\n      assert_array_equal(dense_row, sparse_row.toarray())\n\n  def test_diagonal(self):\n    assert_array_equal(dense2d.diagonal(), self.sp2d.diagonal().toarray())\n    self.assertRaises(ValueError, lambda: self.sp1d.diagonal())\n    self.assertRaises(ValueError, lambda: self.sp2d.diagonal(0,1,1))\n\n  def test_offset_diagonal(self):\n    for k in [1, -1, 2, -2, 3, -3, 4, -4]:\n      assert_sparse_equal(dense2d.diagonal(offset=k),\n                          self.sp2d.diagonal(offset=k),\n                          err_msg='Mismatch for k=%d' % k)\n\n  def test_slicing(self):\n    assert_array_equal(dense1d[1:], self.sp1d[1:].toarray())\n    assert_array_equal(dense2d[1:,1:], self.sp2d[1:,1:].toarray())\n\n  def test_mixed_fancy_indexing(self):\n    idx = [0,2]\n    assert_array_equal(dense2d[:,idx], self.sp2d[:,idx].toarray())\n    assert_array_equal(dense2d[idx,:], self.sp2d[idx,:].toarray())\n\n    assert_array_equal(dense3d[idx,:,idx], self.sp3d[idx,:,idx].toarray())\n    assert_array_equal(dense3d[[1],:,idx], self.sp3d[[1],:,idx].toarray())\n    assert_array_equal(dense3d[:,[1],idx], self.sp3d[:,[1],idx].toarray())\n    assert_array_equal(dense3d[idx,[1],:], self.sp3d[idx,[1],:].toarray())\n\n    assert_array_equal(dense3d[2,:,idx], self.sp3d[2,:,idx].toarray())\n    assert_array_equal(dense3d[:,1,idx], self.sp3d[:,1,idx].toarray())\n    assert_array_equal(dense3d[idx,1,:], self.sp3d[idx,1,:].toarray())\n\n  def test_inner_indexing(self):\n    idx = [0,2]\n    assert_array_equal(dense1d[idx], self.sp1d[idx].toarray())\n    assert_array_equal(dense2d[idx,idx], self.sp2d[idx,idx].toarray())\n\n  @unittest.expectedFailure\n  def test_outer_indexing(self):\n    ii = np.array([1,3])[:,None]\n    jj = np.array([0,2])\n    assert_array_equal(dense2d[ii,jj], self.sp2d[ii,jj].toarray())\n\n  def test_1d_boolean(self):\n    for idx in ([0,0,0,0,0], [1,0,0,0,0], [0,1,1,0,0], [1,1,1,1,1]):\n      idx = np.array(idx, dtype=bool)\n      assert_array_equal(dense1d[idx], self.sp1d[idx].toarray())\n    for idx in ([0,0,0,0], [1,0,0,0], [0,1,1,0], [1,1,1,1]):\n      idx = np.array(idx, dtype=bool)\n      assert_array_equal(dense2d[idx], self.sp2d[idx].toarray())\n    for idx in ([0,0,0], [1,0,0], [0,1,1], [1,1,1]):\n      idx = np.array(idx, dtype=bool)\n      assert_array_equal(dense2d[:,idx], self.sp2d[:,idx].toarray())\n\n  def test_nd_boolean(self):\n    idx = ((np.arange(12) % 3) == 0).reshape(dense2d.shape)\n    assert_array_equal(dense2d[idx], self.sp2d[idx])\n    idx[:,:] = False\n    assert_array_equal(dense2d[idx], self.sp2d[idx])\n    idx[:,:] = True\n    assert_array_equal(dense2d[idx], self.sp2d[idx])\n\n\nclass TestAssignment(BaseSparrayTest):\n  def test_scalar_assignment_in_structure(self):\n    a = self.sp1d.copy()\n    a_dense = dense1d.copy()\n    a[3] = 99\n    a_dense[3] = 99\n    assert_array_equal(a_dense, a.toarray())\n\n    a = self.sp2d.copy()\n    a_dense = dense2d.copy()\n    a[3,1] = 99\n    a_dense[3,1] = 99\n    assert_array_equal(a_dense, a.toarray())\n\n  def test_scalar_assignment_not_in_structure(self):\n    a = self.sp1d.copy()\n    a_dense = dense1d.copy()\n    a[2] = 99\n    a_dense[2] = 99\n    assert_array_equal(a_dense, a.toarray())\n\n    a = self.sp2d.copy()\n    a_dense = dense2d.copy()\n    a[0,2] = 99\n    a_dense[0,2] = 99\n    assert_array_equal(a_dense, a.toarray())\n\n  def test_subarray_assignment(self):\n    a = self.sp1d.copy()\n    a_dense = dense1d.copy()\n    a[:3] = 99\n    a_dense[:3] = 99\n    assert_array_equal(a_dense, a.toarray())\n\n    a = self.sp2d.copy()\n    a_dense = dense2d.copy()\n    a[:2,:2] = 99\n    a_dense[:2,:2] = 99\n    assert_array_equal(a_dense, a.toarray())\n\n  def test_setdiag(self):\n    for k in [0, 1, -1, 2, -2]:\n      a = self.sp2d.copy()\n      a_sparse = sparse2d.copy()\n      a.setdiag(99, offset=k)\n      a_sparse.setdiag(99, k=k)\n      assert_sparse_equal(a_sparse, a, err_msg='Mismatch for k=%d' % k)\n\nif __name__ == '__main__':\n  unittest.main()\n"""
sparray/tests/test_math.py,36,"b'from __future__ import absolute_import\nimport unittest\nimport numpy as np\nimport scipy.sparse as ss\nimport warnings\nfrom numpy.testing import assert_array_equal, assert_array_almost_equal\nfrom sparray import FlatSparray\nfrom sparray.compat import ufuncs_with_fixed_point_at_zero\n\nfrom .test_base import (\n    assert_sparse_equal, assert_sparse_almost_equal,\n    BaseSparrayTest, dense2d, sparse2d, dense1d\n)\n\n\nclass TestMath(BaseSparrayTest):\n  def setUp(self):\n    BaseSparrayTest.setUp(self)\n    # add complex test data\n    d = dense2d * 1j\n    self.pairs.append((d, FlatSparray.from_ndarray(d)))\n\n  def test_add_ndarray(self):\n    b = np.random.random(dense2d.shape)\n    assert_array_equal(dense2d + b, self.sp2d + b)\n    assert_array_equal(b + dense2d, b + self.sp2d)\n    # Test broadcasting\n    b = np.random.random((dense2d.shape[0], 1))\n    assert_array_equal(dense2d + b, self.sp2d + b)\n    assert_array_equal(b + dense2d, b + self.sp2d)\n\n  def test_add_spmatrix(self):\n    for fmt in (\'coo\', \'csr\', \'csc\'):\n      b = ss.rand(*sparse2d.shape, density=0.5, format=fmt)\n      assert_sparse_equal(sparse2d + b, self.sp2d + b)\n      assert_sparse_equal(b + sparse2d, b + self.sp2d)\n\n  def test_add_sparray(self):\n    s = ss.rand(*sparse2d.shape, density=0.5)\n    b = FlatSparray.from_spmatrix(s)\n    assert_array_equal(dense2d + s, (self.sp2d + b).toarray())\n    assert_array_equal(s + dense2d, (b + self.sp2d).toarray())\n    # Test broadcasting\n    s = ss.rand(sparse2d.shape[0], 1, density=0.5)\n    b = FlatSparray.from_spmatrix(s)\n    assert_sparse_equal(dense2d + s, self.sp2d + b)\n    assert_sparse_equal(s + dense2d, b + self.sp2d)\n\n  def test_add_scalar(self):\n    b = 0\n    self._same_op(lambda x: x + b, assert_sparse_equal)\n    self._same_op(lambda x: b + x, assert_sparse_equal)\n    b = 1\n    self._same_op(lambda x: x + b, assert_array_equal)\n    self._same_op(lambda x: b + x, assert_array_equal)\n\n  def test_sub_ndarray(self):\n    b = np.random.random(dense2d.shape)\n    assert_array_equal(dense2d - b, self.sp2d - b)\n    assert_array_equal(b - dense2d, b - self.sp2d)\n    # Test broadcasting\n    b = np.random.random((dense2d.shape[0], 1))\n    assert_array_equal(dense2d - b, self.sp2d - b)\n    assert_array_equal(b - dense2d, b - self.sp2d)\n\n  def test_mul_ndarray(self):\n    b = np.random.random(dense2d.shape)\n    assert_array_equal(dense2d * b, (self.sp2d * b).toarray())\n    assert_array_equal(b * dense2d, (b * self.sp2d).toarray())\n    # Test broadcasting\n    b = np.random.random((dense2d.shape[0], 1))\n    assert_array_equal(dense2d * b, (self.sp2d * b).toarray())\n    assert_array_equal(b * dense2d, (b * self.sp2d).toarray())\n\n  def test_mul_scalar(self):\n    for b in (3, -3.5, 0):\n      self._same_op(lambda x: x * b, assert_sparse_equal)\n      self._same_op(lambda x: b * x, assert_sparse_equal)\n\n  def test_mul_spmatrix(self):\n    for fmt in (\'csr\', \'csc\'):\n      b = ss.rand(*sparse2d.shape, density=0.5, format=fmt)\n      assert_sparse_equal(sparse2d.multiply(b), self.sp2d * b)\n      assert_sparse_equal(sparse2d.multiply(b), self.sp2d.multiply(b))\n\n  def test_mul_sparray(self):\n    s = ss.rand(*sparse2d.shape, density=0.5)\n    b = FlatSparray.from_spmatrix(s)\n    assert_sparse_equal(s.multiply(dense2d), b * self.sp2d)\n    # Test broadcasting\n    for shape in [(sparse2d.shape[0], 1), (1, sparse2d.shape[1])]:\n      s = ss.rand(*shape, density=0.5)\n      b = FlatSparray.from_spmatrix(s)\n      assert_sparse_equal(s.multiply(dense2d), b * self.sp2d)\n\n  def test_imul(self):\n    b = np.random.random(dense2d.shape)\n    a = self.sp2d.copy()\n    a *= b\n    assert_array_equal(dense2d * b, a.toarray())\n    b = 3\n    a = self.sp2d.copy()\n    a *= b\n    assert_array_equal(dense2d * b, a.toarray())\n\n  def test_div_scalar(self):\n    self._same_op(lambda x: x / 3, assert_sparse_almost_equal)\n    with np.errstate(divide=\'ignore\'):\n      assert_array_almost_equal(3 / dense2d, 3 / self.sp2d)\n\n  def test_div_spmatrix(self):\n    for fmt in (\'csr\', \'csc\'):\n      b = ss.rand(*sparse2d.shape, density=0.5, format=fmt)\n      # spmatrix / spmatrix is broken in scipy, so we compare against ndarrays\n      # also, np.true_divide(spmatrix, x) wraps the spmatrix in an object array\n      c = b.toarray()\n      with np.errstate(divide=\'ignore\', invalid=\'ignore\'):\n        e1 = dense2d / c\n        e2 = c / dense2d\n        e3 = dense2d // c\n        e4 = c // dense2d\n      with warnings.catch_warnings(record=True) as ws:\n        warnings.simplefilter(""always"")\n        assert_array_equal(e1, self.sp2d / b)\n        assert_array_equal(e2, b / self.sp2d)\n        assert_array_equal(e3, self.sp2d // b)\n        assert_array_equal(e4, b // self.sp2d)\n        # each operation may raise div by zero and/or invalid value warnings\n        for w in ws:\n          self.assertIn(str(w.message).split()[0], (\'divide\',\'invalid\'))\n\n  def test_div_sparray(self):\n    s = ss.rand(*sparse2d.shape, density=0.5)\n    b = FlatSparray.from_spmatrix(s)\n    # spmatrix / spmatrix is broken in scipy, so we compare against ndarrays\n    c = s.toarray()\n    with np.errstate(divide=\'ignore\', invalid=\'ignore\'):\n      e1 = dense2d / c\n      e2 = c / dense2d\n      e3 = dense2d // c\n      e4 = c // dense2d\n    with warnings.catch_warnings(record=True) as ws:\n      warnings.simplefilter(""always"")\n      assert_array_equal(e1, self.sp2d / b)\n      assert_array_equal(e2, b / self.sp2d)\n      assert_array_equal(e3, self.sp2d // b)\n      assert_array_equal(e4, b // self.sp2d)\n      # each operation may raise div by zero and/or invalid value warnings\n      for w in ws:\n        self.assertIn(str(w.message).split()[0], (\'divide\',\'invalid\'))\n\n  def test_div_ndarray(self):\n    b = np.random.random(dense2d.shape)\n    c = np.random.random((dense2d.shape[0], 1))  # Test broadcasting\n    assert_array_almost_equal(dense2d / b, (self.sp2d / b).toarray())\n    assert_array_almost_equal(dense2d / c, (self.sp2d / c).toarray())\n    with np.errstate(divide=\'ignore\'):\n      assert_array_almost_equal(b / dense2d, b / self.sp2d)\n\n  def test_idiv(self):\n    self.sp2d /= 1\n    assert_array_almost_equal(dense2d, self.sp2d.toarray())\n    b = np.random.random(dense2d.shape)\n    self.sp2d /= b\n    assert_array_almost_equal(dense2d / b, self.sp2d.toarray())\n\n  def test_neg(self):\n    self._same_op(lambda x: -x, assert_sparse_equal)\n\n  def test_conj(self):\n    self._same_op(lambda x: x.conj(), assert_sparse_equal)\n    self._same_op(lambda x: x.conjugate(), assert_sparse_equal)\n\n  def test_pow(self):\n    self._same_op(lambda x: x**2, assert_sparse_equal)\n    with np.errstate(divide=\'ignore\', invalid=\'ignore\'):\n      self._same_op(lambda x: x**-1.5, assert_array_almost_equal)\n      self._same_op(lambda x: x**0, assert_array_almost_equal)\n\n  def test_dot_ndarray(self):\n    b = np.random.random(dense2d.shape[::-1])\n    assert_array_equal(dense2d.dot(b), self.sp2d.dot(b))\n\n    b = np.random.random(dense1d.shape[0])\n    self.assertAlmostEqual(dense1d.dot(b), self.sp1d.dot(b))\n\n    # Test bad alignment for dot\n    b = np.random.random(dense1d.shape[0] + 1)\n    self.assertRaises(ValueError, lambda: self.sp1d.dot(b))\n\n  def test_dot_spmatrix(self):\n    for fmt in (\'csr\', \'csc\'):\n      b = ss.rand(dense2d.shape[1], dense2d.shape[0], density=0.5, format=fmt)\n      assert_sparse_equal(sparse2d.dot(b), self.sp2d.dot(b))\n      # XXX: spmatrix.dot(FlatSparray) calls np.asarray on us,\n      #  which just wraps us in an object array.\n      # assert_sparse_equal(b.dot(sparse2d), b.dot(self.sp2d))\n\n  def test_dot_sparray(self):\n    m,n = dense2d.shape\n    shapes = ((n,), (n,m), (2,n,m))\n    for shape in shapes:\n      d = np.random.random(shape)\n      d.flat[np.random.randint(2, size=d.size)] = 0\n      e = dense2d.dot(d)\n      b = FlatSparray.from_ndarray(d)\n      assert_array_almost_equal(e, self.sp2d.dot(b).toarray())\n\n    d = np.random.random(dense1d.shape[0])\n    d.flat[np.random.randint(2, size=d.size)] = 0\n    b = FlatSparray.from_ndarray(d)\n    self.assertEqual(dense1d.dot(d), self.sp1d.dot(b))\n    self.assertEqual(d.dot(dense1d), b.dot(self.sp1d))\n\n  def test_minmax(self):\n    self.assertEqual(dense2d.min(), self.sp2d.min())\n    self.assertEqual(dense2d.max(), self.sp2d.max())\n\n  def test_minmax_imum_ndarray(self):\n    b = np.random.random(dense2d.shape)\n    assert_array_equal(np.minimum(dense2d, b), self.sp2d.minimum(b))\n    assert_array_equal(np.maximum(dense2d, b), self.sp2d.maximum(b))\n\n  def test_minmax_imum_sparray(self):\n    s = ss.rand(*sparse2d.shape, density=0.5)\n    b = FlatSparray.from_spmatrix(s)\n    assert_sparse_equal(s.minimum(dense2d), b.minimum(self.sp2d))\n    assert_sparse_equal(s.maximum(dense2d), b.maximum(self.sp2d))\n\n  def test_minmax_imum_spmatrix(self):\n    for fmt in (\'csr\', \'csc\'):\n      b = ss.rand(*sparse2d.shape, density=0.5, format=fmt)\n      assert_sparse_equal(b.minimum(dense2d), self.sp2d.minimum(b))\n      assert_sparse_equal(b.maximum(dense2d), self.sp2d.maximum(b))\n\n  def test_minmax_imum_scalar(self):\n    b = 3\n    assert_array_equal(np.minimum(dense2d, b), self.sp2d.minimum(b).A)\n    assert_array_equal(np.maximum(dense2d, b), self.sp2d.maximum(b))\n    b = -3\n    assert_array_equal(np.minimum(dense2d, b), self.sp2d.minimum(b))\n    assert_array_equal(np.maximum(dense2d, b), self.sp2d.maximum(b).A)\n\n  def test_abs(self):\n    self._same_op(abs, assert_sparse_equal)\n\n  def test_sum(self):\n    # axis=None\n    self._same_op(lambda x: x.sum(), self.assertEqual)\n    # axis=0\n    self.assertEqual(dense1d.sum(axis=0), self.sp1d.sum(axis=0))\n    assert_sparse_equal(dense2d.sum(axis=0), self.sp2d.sum(axis=0))\n    # axis=1\n    assert_sparse_equal(dense2d.sum(axis=1), self.sp2d.sum(axis=1))\n\n  def test_mean(self):\n    # axis=None, uses assert_array_almost_equal to handle NaN values\n    with warnings.catch_warnings():\n      warnings.filterwarnings(\'ignore\', category=RuntimeWarning)\n      self._same_op(lambda x: x.mean(), assert_array_almost_equal)\n    # axis=0\n    self.assertEqual(dense1d.mean(axis=0), self.sp1d.mean(axis=0))\n    assert_sparse_equal(dense2d.mean(axis=0), self.sp2d.mean(axis=0))\n    # axis=1\n    assert_sparse_equal(dense2d.mean(axis=1), self.sp2d.mean(axis=1))\n\n  def test_fixed_point_at_zero_methods(self):\n    with np.errstate(invalid=\'ignore\', divide=\'ignore\'):\n      for ufunc in ufuncs_with_fixed_point_at_zero:\n        method = getattr(self.sp2d, ufunc.__name__)\n        assert_array_equal(ufunc(dense2d), method().toarray())\n\n  def test_comparison_scalar(self):\n    # equal\n    self._same_op(lambda x: x == 1, assert_sparse_equal)\n    self._same_op(lambda x: x == 0, assert_array_equal)\n    # not equal\n    self._same_op(lambda x: x != 0, assert_sparse_equal)\n    self._same_op(lambda x: x != 1, assert_array_equal)\n    # less than\n    self._same_op(lambda x: x < -1, assert_sparse_equal)\n    self._same_op(lambda x: x < 1, assert_array_equal)\n    # less equal\n    self._same_op(lambda x: x <= -1, assert_sparse_equal)\n    self._same_op(lambda x: x <= 0, assert_array_equal)\n    # greater than\n    self._same_op(lambda x: x > 1, assert_sparse_equal)\n    self._same_op(lambda x: x > -1, assert_array_equal)\n    # greater equal\n    self._same_op(lambda x: x >= 1, assert_sparse_equal)\n    self._same_op(lambda x: x >= 0, assert_array_equal)\n\n  def test_eq_nonscalar(self):\n    b = np.random.random(dense2d.shape)\n    assert_array_equal(dense2d == b, self.sp2d == b)\n    assert_array_equal(b == dense2d, b == self.sp2d)\n    # Test broadcasting\n    b = np.random.random((dense2d.shape[0], 1))\n    assert_array_equal(dense2d == b, self.sp2d == b)\n    assert_array_equal(b == dense2d, b == self.sp2d)\n    # Test spmatrix\n    for fmt in (\'coo\', \'csr\', \'csc\'):\n      b = ss.rand(*sparse2d.shape, density=0.5, format=fmt)\n      assert_sparse_equal(sparse2d == b, self.sp2d == b)\n      # spmatrix doesn\'t know how to handle us\n      # assert_sparse_equal(b == sparse2d, b == self.sp2d)\n\n  def test_comparison_nonscalar(self):\n    # Only testing < here, because the other ops use the same code.\n    b = np.random.random(dense2d.shape)\n    assert_array_equal(dense2d < b, self.sp2d < b)\n    assert_array_equal(b < dense2d, b < self.sp2d)\n    # Test broadcasting\n    b = np.random.random((dense2d.shape[0], 1))\n    assert_array_equal(dense2d < b, self.sp2d < b)\n    assert_array_equal(b < dense2d, b < self.sp2d)\n    # Test sparray\n    s = ss.rand(*sparse2d.shape, density=0.5)\n    b = FlatSparray.from_spmatrix(s)\n    assert_sparse_equal(sparse2d < s, self.sp2d < b)\n    assert_sparse_equal(s < sparse2d, b < self.sp2d)\n    # Test spmatrix\n    for fmt in (\'coo\', \'csr\', \'csc\'):\n      b = ss.rand(*sparse2d.shape, density=0.5, format=fmt)\n      assert_sparse_equal(sparse2d < b, self.sp2d < b)\n      # spmatrix doesn\'t know how to handle us\n      # assert_sparse_equal(b < sparse2d, b < self.sp2d)\n\nif __name__ == \'__main__\':\n  unittest.main()\n'"
sparray/tests/test_matmul.py,0,b'from __future__ import absolute_import\n\n# Check for python 3.5+\ntry:\n  from ._matmul import TestMatmulOperator\nexcept SyntaxError:\n  pass\n\n'
sparray/tests/test_ops.py,3,"b""from __future__ import absolute_import\nimport unittest\nimport numpy as np\nfrom numpy.testing import assert_array_equal\n\nfrom .test_base import (\n    assert_sparse_equal, BaseSparrayTest, dense2d,\n    dense1d_indices, dense1d_data\n)\n\n\nclass TestOps(BaseSparrayTest):\n  def test_tocoo(self):\n    assert_array_equal(self.sp2d.tocoo().A, dense2d)\n\n  def test_repr(self):\n    for _, s in self.pairs:\n      self.assertRegexpMatches(repr(s), r'<\\(.*?\\)-FlatSparray')\n\n  def test_str(self):\n    expected = '\\n'.join('  (%d,)\\t%d' % x\n                         for x in zip(dense1d_indices, dense1d_data))\n    self.assertEqual(str(self.sp1d), expected)\n\n  def test_resize(self):\n    self.sp2d.resize((5,3))\n    assert_array_equal(self.sp2d.A, np.vstack((dense2d,np.zeros((1,3)))))\n    self.sp2d.resize((12,))\n    assert_array_equal(self.sp2d.A, dense2d.ravel())\n\n  def test_reshape(self):\n    b = self.sp2d.reshape((6,2))\n    self.assertIsNot(self.sp2d, b)\n    assert_array_equal(self.sp2d.A, dense2d)\n    assert_array_equal(b.toarray(), dense2d.reshape((6,2)))\n    b = self.sp2d.reshape((2,-1))\n    assert_array_equal(b.toarray(), dense2d.reshape((2,-1)))\n\n  def test_ravel(self):\n    self._same_op(lambda x: x.ravel(), assert_sparse_equal)\n    # Make sure we're not modifying anything in-place\n    b = self.sp2d.ravel()\n    self.assertIsNot(self.sp2d, b)\n    assert_array_equal(self.sp2d.A, dense2d)\n\n  def test_astype(self):\n    self._same_op(lambda x: x.astype(np.float32), assert_sparse_equal)\n    # Make sure we're not modifying anything in-place\n    b = self.sp2d.astype(np.float32)\n    self.assertIsNot(self.sp2d, b)\n    self.assertIs(self.sp2d.dtype, dense2d.dtype)\n\n  def test_copy(self):\n    b = self.sp2d.copy()\n    self.assertIsNot(self.sp2d, b)\n    assert_array_equal(self.sp2d.A, b.A)\n    b.data[2] *= 3  # modify b's members\n    assert_array_equal(self.sp2d.A, dense2d)\n\n  def test_transpose(self):\n    self._same_op(lambda x: x.transpose(), assert_sparse_equal)\n    # test non-default axes\n    assert_array_equal(self.sp2d.transpose(0,1).A,\n                       dense2d.transpose(0,1))\n    assert_array_equal(self.sp2d.transpose((0,1)).A,\n                       dense2d.transpose((0,1)))\n\n  def test_nonzero(self):\n    self._same_op(lambda x: x.nonzero(), assert_array_equal)\n\n  def test_len(self):\n    self._same_op(len, self.assertEqual)\n\n  def test_bool(self):\n    for d, s in self.pairs:\n      try:\n         res = bool(d)\n      except ValueError:\n         self.assertRaises(ValueError, bool, s)\n      else:\n         self.assertEqual(bool(s), res)\n\n  def test_properties(self):\n    self._same_op(lambda x: x.dtype, self.assertEqual)\n    self._same_op(lambda x: x.shape, self.assertEqual)\n    self._same_op(lambda x: x.ndim, self.assertEqual)\n    # size means something different for sparse objects\n    self._same_op(lambda x: x.size, self.assertLessEqual)\n\n  def test_transform_attrs(self):\n    for attr in ('T', 'real', 'imag'):\n      self._same_op(lambda x: getattr(x, attr), assert_sparse_equal)\n\n  def test_nonexistent_attr(self):\n    self.assertRaises(AttributeError, lambda: getattr(self.sp2d, 'xxxx'))\n\n\nif __name__ == '__main__':\n  unittest.main()\n"""
sparray/tests/test_truediv.py,2,"b""from __future__ import division, absolute_import\nimport unittest\nimport numpy as np\nfrom numpy.testing import assert_array_almost_equal\n\nfrom .test_base import BaseSparrayTest, dense2d\n\n\nclass TestTrueDivision(BaseSparrayTest):\n\n  def test_truediv(self):\n    c = 3\n    assert_array_almost_equal(dense2d / c, (self.sp2d / c).toarray())\n    with np.errstate(divide='ignore'):\n      assert_array_almost_equal(c / dense2d, c / self.sp2d)\n\n  def test_itruediv(self):\n    self.sp2d /= 1\n    assert_array_almost_equal(dense2d, self.sp2d.toarray())\n    b = np.random.random(dense2d.shape)\n    self.sp2d /= b\n    assert_array_almost_equal(dense2d / b, self.sp2d.toarray())\n\n\nif __name__ == '__main__':\n  unittest.main()\n"""
sparray/tests/test_ufuncs.py,61,"b'from __future__ import absolute_import\nimport unittest\nimport numpy as np\nimport scipy.sparse as ss\nimport warnings\nfrom numpy.testing import assert_array_equal, assert_array_almost_equal\nfrom sparray import FlatSparray\nfrom sparray.compat import ufuncs_with_fixed_point_at_zero\n\nfrom .test_base import (\n    assert_sparse_equal, BaseSparrayTest, dense2d, sparse2d, dense1d\n)\n\n\n# Check for __numpy_ufunc__\nclass _UFuncCheck(object):\n    def __array__(self):\n        return np.array([1])\n\n    def __numpy_ufunc__(self, *a, **kwargs):\n        global HAS_NUMPY_UFUNC\n        HAS_NUMPY_UFUNC = True\n\nHAS_NUMPY_UFUNC = False\nnp.add(_UFuncCheck(), np.array([1]))\n\n\nclass TestUfuncs(BaseSparrayTest):\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_add_ndarray_ufunc(self):\n    b = np.random.random(dense2d.shape)\n    assert_array_equal(np.add(dense2d, b), np.add(self.sp2d, b))\n    assert_array_equal(np.add(b, dense2d), np.add(b, self.sp2d))\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_sub_ndarray_ufunc(self):\n    b = np.random.random(dense2d.shape)\n    assert_array_equal(np.subtract(dense2d, b), np.subtract(self.sp2d, b))\n    assert_array_equal(np.subtract(b, dense2d), np.subtract(b, self.sp2d))\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_mul_ndarray_ufunc(self):\n    b = np.random.random(dense2d.shape)\n    assert_array_equal(np.multiply(dense2d, b),\n                       np.multiply(self.sp2d, b).toarray())\n    assert_array_equal(np.multiply(b, dense2d),\n                       np.multiply(b, self.sp2d).toarray())\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_mul_spmatrix_ufunc(self):\n    for fmt in (\'csr\', \'csc\'):\n      b = ss.rand(*sparse2d.shape, density=0.5, format=fmt)\n      assert_sparse_equal(b.multiply(sparse2d), b.multiply(self.sp2d))\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_mul_sparray_ufunc(self):\n    s = ss.rand(*sparse2d.shape, density=0.5)\n    b = FlatSparray.from_spmatrix(s)\n    assert_sparse_equal(np.multiply(dense2d, s), self.sp2d * b)\n    # Test broadcasting\n    for shape in [(sparse2d.shape[0], 1), (1, sparse2d.shape[1])]:\n      s = ss.rand(*shape, density=0.5)\n      b = FlatSparray.from_spmatrix(s)\n      assert_sparse_equal(np.multiply(dense2d, s), self.sp2d * b)\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_div_ndarray_ufunc(self):\n    b = np.random.random(dense2d.shape)\n    assert_array_almost_equal(np.divide(dense2d, b),\n                              np.divide(self.sp2d, b).toarray())\n    assert_array_almost_equal(np.true_divide(dense2d, b),\n                              np.true_divide(self.sp2d, b).toarray())\n    with np.errstate(divide=\'ignore\'):\n      assert_array_almost_equal(np.divide(b, dense2d), np.divide(b, self.sp2d))\n      assert_array_almost_equal(np.true_divide(b, dense2d),\n                                np.true_divide(b, self.sp2d))\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_div_sparray_ufunc(self):\n    s = ss.rand(*sparse2d.shape, density=0.5)\n    b = FlatSparray.from_spmatrix(s)\n    # spmatrix / spmatrix is broken in scipy, so we compare against ndarrays\n    c = s.toarray()\n    with np.errstate(divide=\'ignore\', invalid=\'ignore\'):\n      e1 = np.true_divide(dense2d, c)\n      e2 = np.true_divide(c, dense2d)\n      e3 = np.floor_divide(dense2d, c)\n      e4 = np.floor_divide(c, dense2d)\n    with warnings.catch_warnings(record=True) as ws:\n      warnings.simplefilter(""always"")\n      assert_array_equal(e1, np.true_divide(self.sp2d, b))\n      assert_array_equal(e2, np.true_divide(b, self.sp2d))\n      assert_array_equal(e3, np.floor_divide(self.sp2d, b))\n      assert_array_equal(e4, np.floor_divide(b, self.sp2d))\n      # each operation may raise div by zero and/or invalid value warnings\n      for w in ws:\n        self.assertIn(str(w.message).split()[0], (\'divide\',\'invalid\'))\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_conjugate_ufunc(self):\n    assert_array_equal(np.conjugate(dense2d), np.conjugate(self.sp2d).toarray())\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_dot_ufunc(self):\n    b = np.random.random((dense2d.shape[1], dense2d.shape[0]))\n    # XXX: in older numpy, ndarray.dot(FlatSparray) wraps us in an object array.\n    assert_array_equal(b.dot(dense2d), b.dot(self.sp2d))\n    assert_array_equal(np.dot(dense2d, b), np.dot(self.sp2d, b))\n    assert_array_equal(np.dot(b, dense2d), np.dot(b, self.sp2d))\n\n    b = np.random.random(dense1d.shape[0])\n    # XXX: in older numpy, ndarray.dot(FlatSparray) wraps us in an object array.\n    self.assertEqual(b.dot(dense1d), b.dot(self.sp1d))\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_minmax_imum_ndarray_ufunc(self):\n    b = np.random.random(dense2d.shape)\n    assert_array_equal(np.minimum(dense2d, b), np.minimum(self.sp2d, b))\n    assert_array_equal(np.maximum(dense2d, b), np.maximum(self.sp2d, b))\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_minmax_imum_sparray_ufunc(self):\n    s = ss.rand(*sparse2d.shape, density=0.5)\n    b = FlatSparray.from_spmatrix(s)\n    assert_array_equal(np.minimum(dense2d, s),\n                       np.minimum(self.sp2d, b).toarray())\n    assert_array_equal(np.maximum(dense2d, s),\n                       np.maximum(self.sp2d, b).toarray())\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_minmax_imum_spmatrix_ufunc(self):\n    for fmt in (\'csr\', \'csc\'):\n      b = ss.rand(*sparse2d.shape, density=0.5, format=fmt)\n      assert_array_equal(np.minimum(dense2d, b),\n                         np.minimum(self.sp2d, b).toarray())\n      assert_array_equal(np.maximum(dense2d, b),\n                         np.maximum(self.sp2d, b).toarray())\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_minmax_imum_scalar_ufunc(self):\n    b = 3\n    assert_array_equal(np.minimum(dense2d, b), np.minimum(self.sp2d, b).A)\n    assert_array_equal(np.maximum(dense2d, b), np.maximum(self.sp2d, b))\n    b = -3\n    assert_array_equal(np.minimum(dense2d, b), np.minimum(self.sp2d, b))\n    assert_array_equal(np.maximum(dense2d, b), np.maximum(self.sp2d, b).A)\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_abs_ufunc(self):\n    assert_array_equal(np.abs(dense2d), np.abs(self.sp2d).toarray())\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_fixed_point_at_zero_ufuncs(self):\n    with np.errstate(invalid=\'ignore\', divide=\'ignore\'):\n      for ufunc in ufuncs_with_fixed_point_at_zero:\n        assert_array_equal(ufunc(dense2d), ufunc(self.sp2d).toarray())\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_not_implemented_ufunc(self):\n    self.assertRaises(TypeError, np.log, self.sp2d)\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_dense_out_kwarg(self):\n    b = 3\n    out1 = np.zeros_like(dense2d)\n    out2 = np.zeros_like(dense2d)\n    np.multiply(dense2d, b, out=out1)\n    res = np.multiply(self.sp2d, b, out=out2)\n    self.assertIs(res, out2)\n    assert_array_equal(out1, out2)\n\n  @unittest.skipUnless(HAS_NUMPY_UFUNC, \'Requires __numpy_ufunc__ support\')\n  def test_sparray_out_kwarg(self):\n    res = np.add(self.sp2d, 0, out=self.sp2d)\n    self.assertIs(res, self.sp2d)\n    assert_array_equal(dense2d, self.sp2d.toarray())\n\n\nif __name__ == \'__main__\':\n  unittest.main()\n'"
