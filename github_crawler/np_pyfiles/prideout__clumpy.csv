file_path,api_count,code
extras/example5.py,0,"b'#!/usr/bin/env python3\n\nfrom numpy import load\nfrom PIL import Image\nfrom os import system\n\ndef clumpy(cmd):\n    result = system(\'./clumpy \' + cmd)\n    if result: raise Exception(""clumpy failed with: "" + cmd)\n\nclumpy(\'generate_simplex 1000x500 1.0 8.0 0 potential.npy\')\nclumpy(\'curl_2d potential.npy velocity.npy\')\nclumpy(\'bridson_points 1000x500 5 0 pts.npy\')\nclumpy(\'advect_points pts.npy velocity.npy 30 1 0.95 240 anim.npy\')\nImage.fromarray(load(""000anim.npy""), ""L"").point(lambda p: p * 2).show()\n\n\'\'\'\ndef advect_points(**kwargs):\n    cmd = \'input_points velocities step_size kernel_size decay nframes output_points\'\n    cmd = \' \'.join(str(kwargs[arg]) for arg in cmd.split())\n    return clumpy(\'advect_points \' + cmd)\n\nadvect_points(\n    input_points=\'pts.npy\',\n    velocities=\'velocity.npy\',\n    step_size=30,\n    kernel_size=1,\n    decay=0.95,\n    nframes=240,\n    output_points=\'anim.npy\')\n\'\'\'\n\nImage \\\n    .fromarray(load(""000anim.npy""), ""L"") \\\n    .point(lambda p: p * 2) \\\n    .resize((500, 250), Image.BILINEAR) \\\n    .save(\'example5.png\')\n\nsystem(\'optipng example5.png\')\n'"
extras/example6.py,1,"b'#!/usr/bin/env python3\n\nimport numpy as np\nfrom os import system\nimport snowy\nfrom tqdm import tqdm\n\nresult = system(""cmake --build .release"")\nif result: raise Exception(""build failed"")\n\ndef clumpy(cmd):\n    print(f""clumpy {cmd}"")\n    result = system(f"".release/clumpy {cmd}"")\n    if result: raise Exception(""clumpy failed"")\n\nfriction = 0.9\nspacing = 20\nstep_size = 2.5\nkernel_size = 5\ndecay = 0.99\nnframes = 400\nres = 4000, 2000\nscalex = 2\nscaley = 5\n\ndim = ""x"".join(map(str,res))\n\nclumpy(f""pendulum_phase {dim} {friction} {scalex} {scaley} field.npy"")\nclumpy(f""bridson_points {dim} {spacing} 0 pts.npy"")\nclumpy(f""advect_points pts.npy field.npy {step_size} {kernel_size} {decay} {nframes} phase.npy"")\n\nim = snowy.reshape(1.0 - np.load(""000phase.npy"") / 255.0)\nim = snowy.resize(im, 500, 250)\nsnowy.export(im, ""extras/example6.png"")\nsnowy.show(im)\nsystem(""rm *.npy"")\nprint(""Generated extras/example6.png"")\n'"
extras/experiments.py,6,"b'#!/usr/bin/env python3\n\nimport numpy as np\nfrom PIL import Image\n\n# Create 8x4 image\nimg = np.zeros([4, 8])\nimg.fill(0.25)\n\n# Plot a list of points using ""column,row"".\npts = np.transpose(np.array([[7, 3], [2, 1]], dtype=np.intp))\nimg[pts[1], pts[0]] = 0.7\n\n# Add a value to a set of pixels.\nimg[pts[1], pts[0]] = img[pts[1], pts[0]] + 0.3\n\nprint(img)\n\nif False:\n    img = Image.fromarray(np.uint8(img * 255), \'L\')\n    img = img.resize([1000, 500], resample=Image.NEAREST)\n    img.show()\n\n# Get the nth row of Pascal\'s triangle.\ndef get_weights(n):\n    rows = [[1],[1,1]]\n    for j in range(2, n + 1):\n        prev = rows[j - 1]\n        newrow = [1]\n        for k in range(1, j - 1):\n            newrow.append(prev[k] + prev[k - 1])\n        newrow.append(1)\n        rows.append(newrow)\n    return np.array(rows[-1])\n\n# Generate a nxn Gaussian kernel.\ndef get_gaussian(n):\n    v = get_weights(n)\n    k = np.transpose(np.mat(v)) * v\n    return k / np.sum(k)\n\nk = get_gaussian(5)\nprint(k)\n'"
extras/island.py,35,"b'#!/usr/bin/env python3\n\n\'\'\'\nCreates a movie of infinitely zooming FBM.\n\nAll coordinates are X,Y floats with values that increase rightward and downward:\n\n    World Space: [0,0 through 1,1] spans the entire island.\n     Tile Space: [0,0 through 1,1] spans the smallest tile that wholly encompasses the viewport.\n Viewport Space: [0,0 through 1,1] spans the current view.\n\nAt Z = 0, Tile Space is equivalent to World Space.\n\nNote that numpy requires Row,Col integer coordinates, but we internalize those at the lowest level.\n(see sample_pixel)\n\n\'\'\'\n\nfrom os import system\nfrom tqdm import tqdm\nfrom sdl2.ext import clipline\n\nimport cairo\nimport imageio\nimport numpy as np\nimport scipy.interpolate as interp\n\ndef vec2(x, y): return np.array([x, y], dtype=np.float)\ndef vec3(x, y, z): return np.array([x, y, z], dtype=np.float)\ndef grid(w, h): return np.zeros([int(h), int(w)], dtype=np.float)\n\n# Configuration.\nResolution = vec2(512,512)\nVideoFps = 30\nNumFrames = VideoFps * 5\nvsTargetLn = vec2([.4,.4], [.9,.9])\nvsPanFocus = vec2(0.5, 0.5)\nSeaLevel = 0.5\nNicePalette = [\n    000, 0x001070 , # Dark Blue\n    126, 0x2C5A7C , # Light Blue\n    127, 0xE0F0A0 , # Yellow\n    128, 0x5D943C , # Dark Green\n    160, 0x606011 , # Brown\n    200, 0xFFFFFF , # White\n    255, 0xFFFFFF ] # White\n\n# Global data.\nNoiseFrequency = 16.0\nNumLayers = 4\nWidth, Height = Resolution\nLut = grid(3, 256)\nZoom = int(0)\nvsTargetPt = vec2(-1,-1)\nViewImage = grid(Width, Height) ## Current viewport. Includes NumLayers of high-freq noise.\nTileImage = grid(Width, Height) ## Smallest encompassing tile (accumulated low-freq noise).\nViewports = []\n\ndef update_view(nlayers = NumLayers):\n    resample_image(ViewImage, TileImage, Viewports[-1])\n    seed = Zoom\n    for vp in Viewports[:nlayers]:\n        noise = gradient_noise(Resolution, vp, NoiseFrequency, seed=seed)\n        np.copyto(ViewImage, 2 * (ViewImage + noise))\n        seed = seed + 1\n\ndef update_tile():\n    global Zoom\n    global Viewports\n    global NoiseFrequency\n    # Render a new base tile by adding one layer of noise.\n    update_view(1)\n    np.copyto(TileImage, ViewImage)\n    # Left-shift the viewports array and push on a new high-frequency layer.\n    Viewports = Viewports[1:] + [vec2((0,0),(1,1))]\n    Zoom = Zoom + 1\n    NoiseFrequency = min(NoiseFrequency * 1.5, 512.0)\n\ndef main():\n    global vsTargetPt\n    global NoiseFrequency\n    global NumLayers\n\n    NoiseFrequency = 16.0\n    NumLayers = 4\n    create_viewports()\n    np.copyto(Lut, create_palette())\n    np.copyto(TileImage, create_basetile(Width, Height))\n\n    update_view()\n    np.copyto(TileImage, ViewImage)\n    NumLayers = 1\n    create_viewports()\n\n    update_view()\n    vsTargetPt = marching_line(ViewImage, vsTargetLn)\n    writer = imageio.get_writer(\'out.mp4\', fps=VideoFps, quality=9)\n    for frame in tqdm(range(NumFrames)):\n\n        # Draw the heightmap for the current viewport.\n        update_view()\n\n        # Recompute the point of interest.\n        vsTargetPt = marching_line(ViewImage, vsTargetLn)\n\n        # Draw the overlay and convert the heightmap into color.\n        rgb = render_view()\n        writer.append_data(np.uint8(rgb))\n\n        # Compute the pan / zoom adjustments for the largest viewport.\n        vpdelta = shrink_viewport(Viewports[-1], zoom_speed=10, pan_speed=0.05)\n\n        # Propagate the movement to all layer viewports.\n        for vp in reversed(Viewports):\n            np.copyto(vp, vp + vpdelta)\n            vpdelta = vpdelta / 2\n\n        # If the largest viewport is sufficiently small, it\'s time to increment zoom.\n        vp = Viewports[-1]\n        vpextent = vp[1] - vp[0]\n        if vpextent[0] < 0.5 and vpextent[1] < 0.5:\n            update_tile()\n\n    writer.close()\n\ndef render_view():\n    lo, hi = np.amin(ViewImage), np.amax(ViewImage)\n    L1 = Lut[np.uint8(255 * (0.5 + 0.5 * ViewImage / (hi - lo)))]\n    draw_overlay(L1, vsTargetLn, vsTargetPt)\n    lo, hi = np.amin(TileImage), np.amax(TileImage)\n    L2 = Lut[np.uint8(255 * (0.5 + 0.5 * TileImage / (hi - lo)))]\n    # Crop so that the stack is roughly 1920x1080\n    crop = Width - Width * 960/1080\n    w0, w1 = int(crop/2), int(Width - crop/2)\n    L1 = L1[:, w0:w1, :]\n    L2 = L2[:, w0:w1, :]\n    return np.hstack([L1, L2])\n\ndef shrink_viewport(viewport, zoom_speed, pan_speed):\n    vpextent = viewport[1] - viewport[0]\n    pandir = vsTargetPt - vsPanFocus\n    pan_delta = pan_speed * pandir\n    zoom_delta = zoom_speed * vpextent / Resolution\n    return pan_delta + vec2(zoom_delta, -zoom_delta)\n\ndef draw_overlay(dst, lineseg, pxcoord):\n    dims = [dst.shape[1], dst.shape[0]]\n    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, dims[0], dims[1])\n    ctx = cairo.Context(surface)\n    ctx.scale(dims[0], dims[1])\n    ctx.set_line_width(0.005)\n    # Stroke a path along lineseg\n    ctx.set_source_rgba(1.0, 0.8, 0.8, 0.15)\n    ctx.move_to(lineseg[0][0], lineseg[0][1])\n    ctx.line_to(lineseg[1][0], lineseg[1][1])\n    ctx.stroke()\n    # Draw circle around pxcoord\n    ctx.set_source_rgba(1.0, 0.8, 0.8, 0.15)\n    ctx.save()\n    ctx.translate(pxcoord[0], pxcoord[1])\n    ctx.scale(0.02, 0.02)\n    ctx.arc(0., 0., 1., 0., 2 * np.pi)\n    ctx.restore()\n    ctx.stroke()\n    if False:\n        f = cairo.ToyFontFace("""")\n        ctx.move_to(.5, .5)\n        ctx.show_text(""Philip"")\n    # Perform composition\n    buf = surface.get_data()\n    rgb = np.ndarray(shape=dims[:2], dtype=np.uint32, buffer=buf)\n    color = np.float32([(rgb >> 8) & 0xff, (rgb >> 16) & 0xff, (rgb >> 0) & 0xff])\n    color = color.swapaxes(0, 2).swapaxes(0, 1)\n    a = np.float32((rgb >> 24) & 0xff) / 255.0\n    alpha = np.array([a, a, a]).swapaxes(0, 2).swapaxes(0, 1)\n    np.copyto(dst, dst * (1 - alpha) + color)\n\ndef clumpy(cmd):\n    result = system(\'./clumpy \' + cmd)\n    if result: raise Exception(""clumpy failed with: "" + cmd)\n\ndef gradient_noise(dims, viewport, frequency, seed):\n    (left, top), (right, bottom) = 2 * (viewport - 0.5)\n    args = ""{}x{} \'{},{},{},{}\' {} {}"".format(\n        dims[0], dims[1],\n        left, -bottom, right, -top,\n        frequency, seed)\n    clumpy(""gradient_noise "" + args)\n    noise = np.load(\'gradient_noise.npy\')\n    return noise\n\ndef sample_pixel(image_array, x, y):\n    rows, cols = image_array.shape\n    row, col = int(y * rows), int(x * cols)\n    if row < 0 or col < 0 or col >= cols or row >= rows:\n        return 0\n    return image_array[row][col]\n\ndef marching_line(image_array, line_segment):\n    x0, y0 = line_segment[0]\n    x1, y1 = line_segment[1]\n    val = sample_pixel(image_array, x0, y0)\n    sgn = np.sign(val)\n    divs = float(max(Resolution))\n    dx = (x1 - x0) / divs\n    dy = (y1 - y0) / divs\n    for i in range(int(divs)):\n        x = x0 + i * dx\n        y = y0 + i * dy\n        val = sample_pixel(image_array, x, y)\n        if np.sign(val) != sgn:\n            return [x, y]\n    print(f\'Could not find in {x0:3.3},{y0:3.3} -- {x1:3.3},{y1:3.3}\')\n    return [0.5,0.5]\n\n# TODO: use NicePalette\ndef create_palette():\n    r = np.hstack([np.linspace(0.0,     0.0, num=128), np.linspace(0.0,     0.0, num=128)])\n    g = np.hstack([np.linspace(0.0,     0.0, num=128), np.linspace(128.0, 255.0, num=128)])\n    b = np.hstack([np.linspace(128.0, 255.0, num=128), np.linspace(0.0,    64.0, num=128)])\n    return np.float32([r, g, b]).transpose()\n\n# Hermite interpolation, also known as smoothstep:\n#     (-1 => 0)     (0 => 1)     (+1 => 0)\ndef hermite(t):\n    return 1 - (3 - 2*np.abs(t))*t*t\n\ndef create_basetile(width, height):\n    rows = hermite([np.linspace(-1.0, 1.0, num=height)])\n    cols = hermite([np.linspace(-1.0, 1.0, num=width)]).T\n    return rows * cols - SeaLevel\n\ndef resample_image(dst, src, viewport):\n    height, width = dst.shape\n    domain = [np.linspace(0, 1, num) for num in (width, height)]\n    [(left, top), (right, bottom)] = viewport\n    vrange = np.linspace(left, right, num=width)\n    urange = np.linspace(top, bottom, num=height)\n    f = interp.interp1d(domain[0], src, kind=\'linear\', fill_value=\'extrapolate\')\n    temp = f(vrange)\n    f = interp.interp1d(domain[1], temp.T, kind=\'linear\', fill_value=\'extrapolate\')\n    newimg = f(urange).T\n    np.copyto(dst, newimg)\n\ndef create_viewports():\n    global Viewports\n    Viewports = []\n    frequency = 1\n    for x in range(NumLayers):\n        vp = vec2((0,0), (frequency,frequency))\n        Viewports.insert(0, vp)\n        frequency = frequency / 2\n\nmain()\n'"
extras/pendulum_video.py,3,"b'#!/usr/bin/env python3\n\nimport numpy as np\nfrom os import system\nimport snowy\nfrom tqdm import tqdm\n\ndef clumpy(cmd):\n    result = system(\'cmake --build .release\')\n    if result: raise Exception(""build failed"")\n    result = system(\'.release/clumpy \' + cmd)\n    if result: raise Exception(""clumpy failed with: "" + cmd)\n\nspacing = 20\nstep_size = 2.5\nskip = 2\nkernel_size = 7\ndecay = 0.99\nnframes = 240 * 4\nres = 2000*2, 2000*2\ndim = \'x\'.join(map(str,res))\n\nfriction = 0.1\nclumpy(f\'pendulum_phase {dim} {friction} 1 5 field.npy\')\nclumpy(f\'bridson_points {dim} {spacing} 0 pts.npy\')\nclumpy(\'advect_points pts.npy field.npy \' +\n    f\'{step_size} {kernel_size} {decay} {nframes} anim1.npy\')\n\nfriction = 0.9\nclumpy(f\'pendulum_phase {dim} {friction} 1 5 field.npy\')\nclumpy(f\'bridson_points {dim} {spacing} 0 pts.npy\')\nclumpy(\'advect_points pts.npy field.npy \' +\n    f\'{step_size} {kernel_size} {decay} {nframes} anim2.npy\')\n\nimport imageio\nwriter = imageio.get_writer(\'anim.mp4\', fps=60)\nfor i in tqdm(range(0, nframes, skip)):\n\n    im1 = snowy.reshape(np.load(""{:03}anim1.npy"".format(i)))\n    im1 = snowy.resize(im1, 960-6, 1088-8)\n\n    im2 = snowy.reshape(np.load(""{:03}anim2.npy"".format(i)))\n    im2 = snowy.resize(im2, 960-6, 1088-8)\n\n    im = np.uint8(255.0 - snowy.hstack([im1, im2], border_width=4))\n    writer.append_data(im)\n\nwriter.close()\nprint(\'Generated anim.mp4\')\n\nsystem(\'rm *.npy\')\n'"
extras/test.py,13,"b'#!/usr/bin/env python3\n\nimport numpy as np\nfrom PIL import Image\nfrom os import system\n\ndef clumpy(cmd):\n    result = system(\'./clumpy \' + cmd)\n    if result: raise Exception(""clumpy failed with: "" + cmd)\n\nNOISE_SCALE = 0.7\nDISTANCE_SCALE = 0.5\nLARGE_SPRITES = False\nSTEP_SIZE = 300\nCREATE_REDGREEN_IMAGE = False\nUSE_MATPLOTLIB = False\n\nclumpy(\'generate_simplex 1024x512 1.0 4.0  0 noise1.npy\')\nclumpy(\'generate_simplex 1024x512 1.0 8.0  1 noise2.npy\')\na, b = (np.load(\'noise{}.npy\'.format(i)) for i in [1,2])\nnoise = a + b\n\nclumpy(\'generate_dshapes 1024x512 1 0 shapes.npy\')\nshapes = np.load(\'shapes.npy\')\nsdf = (NOISE_SCALE * noise + 1.0) * shapes * DISTANCE_SCALE\nnp.save(\'potential.npy\', sdf)\nclumpy(\'visualize_sdf shapes.npy rgba viz.npy\')\noverlay_img = Image.fromarray(np.load(\'viz.npy\'), \'RGBA\')\nclumpy(\'curl_2d potential.npy velocity.npy\')\n\nif CREATE_REDGREEN_IMAGE:\n    from skimage import img_as_ubyte\n    velocity = np.load(\'velocity.npy\').swapaxes(0, 2).swapaxes(1, 2)\n    a = np.amin(velocity)\n    b = np.amax(velocity)\n    velocity = img_as_ubyte((velocity - a)/ (b - a))\n    red, grn = velocity\n    blu = img_as_ubyte(np.zeros(red.shape))\n    bands = [Image.fromarray(c) for c in [red, grn, blu]]\n    Image.merge(\'RGB\', bands).save(\'redgrn.png\')\n\nif LARGE_SPRITES:\n    clumpy(\'bridson_points 1024x512 15 0 pts.npy\')\n    clumpy(\'cull_points pts.npy potential.npy pts.npy\')\n    clumpy(\'advect_points pts.npy velocity.npy \' +\n        \'{step_size} {kernel_size} {decay} {nframes} anim.npy\'.format(\n            step_size = STEP_SIZE,\n            kernel_size = 5,\n            decay = 0.9,\n            nframes = 240\n        ))\nelse:\n    clumpy(\'bridson_points 1024x512 5 0 pts.npy\')\n    clumpy(\'cull_points pts.npy potential.npy pts.npy\')\n    clumpy(\'advect_points pts.npy velocity.npy \' +\n        \'{step_size} {kernel_size} {decay} {nframes} anim.npy\'.format(\n            step_size = STEP_SIZE,\n            kernel_size = 1,\n            decay = 0.9,\n            nframes = 240\n        ))\n\nimport imageio\nwriter = imageio.get_writer(\'anim.mp4\', fps=60)\nopaque = Image.new(\'L\', overlay_img.size, 255)\nfor i in range(240):\n    filename = ""{:03}anim.npy"".format(i)\n    frame_data = 255 - np.load(filename)\n    base_img = Image.fromarray(frame_data, \'L\')\n    base_img = Image.merge(\'RGBA\', [base_img, base_img, base_img, opaque])\n    composited = Image.alpha_composite(base_img, overlay_img)\n    frame_data = np.array(composited)\n    writer.append_data(frame_data)\nwriter.close()\nprint(\'Generated anim.mp4\')\n\n# https://matplotlib.org/gallery/images_contours_and_fields/plot_streamplot.html\n# https://scipython.com/blog/visualizing-a-vector-field-with-matplotlib/\nif USE_MATPLOTLIB:\n    import matplotlib.pyplot as plt\n    u, v = np.load(\'velocity.npy\')\n    x = np.linspace(-1, 1, 1000)\n    y = np.linspace(-1, 1, 500)\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.streamplot(x, y, u, v, linewidth=1, density=1, arrowstyle=\'-\', arrowsize=1)\n    ax.xaxis.set_visible(False)\n    ax.yaxis.set_visible(False)\n    ax.set_aspect(0.5)\n    plt.savefig(\'matplotlib.png\', dpi=1000)\n'"
extern/fmt/doc/build.py,0,"b'#!/usr/bin/env python\n# Build the documentation.\n\nfrom __future__ import print_function\nimport errno, os, shutil, sys, tempfile\nfrom subprocess import check_call, check_output, CalledProcessError, Popen, PIPE\nfrom distutils.version import LooseVersion\n\nversions = [\'1.0.0\', \'1.1.0\', \'2.0.0\', \'3.0.2\', \'4.0.0\', \'4.1.0\', \'5.0.0\', \'5.1.0\']\n\ndef pip_install(package, commit=None, **kwargs):\n  ""Install package using pip.""\n  min_version = kwargs.get(\'min_version\')\n  if min_version:\n    from pkg_resources import get_distribution, DistributionNotFound\n    try:\n      installed_version = get_distribution(os.path.basename(package)).version\n      if LooseVersion(installed_version) >= min_version:\n        print(\'{} {} already installed\'.format(package, min_version))\n        return\n    except DistributionNotFound:\n      pass\n  if commit:\n    package = \'git+https://github.com/{0}.git@{1}\'.format(package, commit)\n  print(\'Installing {0}\'.format(package))\n  check_call([\'pip\', \'install\', package])\n\ndef create_build_env(dirname=\'virtualenv\'):\n  # Create virtualenv.\n  if not os.path.exists(dirname):\n    check_call([\'virtualenv\', dirname])\n  import sysconfig\n  scripts_dir = os.path.basename(sysconfig.get_path(\'scripts\'))\n  activate_this_file = os.path.join(dirname, scripts_dir, \'activate_this.py\')\n  with open(activate_this_file) as f:\n    exec(f.read(), dict(__file__=activate_this_file))\n  # Import get_distribution after activating virtualenv to get info about\n  # the correct packages.\n  from pkg_resources import get_distribution, DistributionNotFound\n  # Upgrade pip because installation of sphinx with pip 1.1 available on Travis\n  # is broken (see #207) and it doesn\'t support the show command.\n  pip_version = get_distribution(\'pip\').version\n  if LooseVersion(pip_version) < LooseVersion(\'1.5.4\'):\n    print(""Updating pip"")\n    check_call([\'pip\', \'install\', \'--upgrade\', \'pip\'])\n  # Upgrade distribute because installation of sphinx with distribute 0.6.24\n  # available on Travis is broken (see #207).\n  try:\n    distribute_version = get_distribution(\'distribute\').version\n    if LooseVersion(distribute_version) <= LooseVersion(\'0.6.24\'):\n      print(""Updating distribute"")\n      check_call([\'pip\', \'install\', \'--upgrade\', \'distribute\'])\n  except DistributionNotFound:\n    pass\n  # Install Sphinx and Breathe.\n  pip_install(\'sphinx-doc/sphinx\', \'12b83372ac9316e8cbe86e7fed889296a4cc29ee\',\n              min_version=\'1.4.1.dev20160531\')\n  pip_install(\'michaeljones/breathe\',\n              \'129222318f7c8f865d2631e7da7b033567e7f56a\',\n              min_version=\'4.2.0\')\n\ndef build_docs(version=\'dev\', **kwargs):\n  doc_dir = kwargs.get(\'doc_dir\', os.path.dirname(os.path.realpath(__file__)))\n  work_dir = kwargs.get(\'work_dir\', \'.\')\n  include_dir = kwargs.get(\n      \'include_dir\', os.path.join(os.path.dirname(doc_dir), \'include\', \'fmt\'))\n  # Build docs.\n  cmd = [\'doxygen\', \'-\']\n  p = Popen(cmd, stdin=PIPE)\n  doxyxml_dir = os.path.join(work_dir, \'doxyxml\')\n  p.communicate(input=r\'\'\'\n      PROJECT_NAME      = fmt\n      GENERATE_LATEX    = NO\n      GENERATE_MAN      = NO\n      GENERATE_RTF      = NO\n      CASE_SENSE_NAMES  = NO\n      INPUT             = {0}/core.h {0}/format.h {0}/ostream.h \\\n                          {0}/printf.h {0}/time.h\n      QUIET             = YES\n      JAVADOC_AUTOBRIEF = YES\n      AUTOLINK_SUPPORT  = NO\n      GENERATE_HTML     = NO\n      GENERATE_XML      = YES\n      XML_OUTPUT        = {1}\n      ALIASES           = ""rst=\\verbatim embed:rst""\n      ALIASES          += ""endrst=\\endverbatim""\n      MACRO_EXPANSION   = YES\n      PREDEFINED        = _WIN32=1 \\\n                          FMT_USE_VARIADIC_TEMPLATES=1 \\\n                          FMT_USE_RVALUE_REFERENCES=1 \\\n                          FMT_USE_USER_DEFINED_LITERALS=1 \\\n                          FMT_API= \\\n                          ""FMT_BEGIN_NAMESPACE=namespace fmt {{"" \\\n                          ""FMT_END_NAMESPACE=}}""\n      EXCLUDE_SYMBOLS   = fmt::internal::* StringValue write_str\n    \'\'\'.format(include_dir, doxyxml_dir).encode(\'UTF-8\'))\n  if p.returncode != 0:\n    raise CalledProcessError(p.returncode, cmd)\n  html_dir = os.path.join(work_dir, \'html\')\n  main_versions = reversed(versions[-3:])\n  check_call([\'sphinx-build\',\n              \'-Dbreathe_projects.format=\' + os.path.abspath(doxyxml_dir),\n              \'-Dversion=\' + version, \'-Drelease=\' + version,\n              \'-Aversion=\' + version, \'-Aversions=\' + \',\'.join(main_versions),\n              \'-b\', \'html\', doc_dir, html_dir])\n  try:\n    check_call([\'lessc\', \'--clean-css\',\n                \'--include-path=\' + os.path.join(doc_dir, \'bootstrap\'),\n                os.path.join(doc_dir, \'fmt.less\'),\n                os.path.join(html_dir, \'_static\', \'fmt.css\')])\n  except OSError as e:\n    if e.errno != errno.ENOENT:\n      raise\n    print(\'lessc not found; make sure that Less (http://lesscss.org/) \' +\n          \'is installed\')\n    sys.exit(1)\n  return html_dir\n\nif __name__ == \'__main__\':\n  create_build_env()\n  build_docs(sys.argv[1])\n'"
extern/fmt/doc/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# format documentation build configuration file, created by\n# sphinx-quickstart on Tue Dec 18 06:46:16 2012.\n#\n# This file is execfile()d with the current directory set to its containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys, os, re, subprocess\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#sys.path.insert(0, os.path.abspath(\'.\'))\n\n# -- General configuration -----------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\nneeds_sphinx = \'1.2\'\n\nif os.environ.get(\'READTHEDOCS\', None) == \'True\':\n  subprocess.call(\'doxygen\')\n\n# Add any Sphinx extension module names here, as strings. They can be extensions\n# coming with Sphinx (named \'sphinx.ext.*\') or your custom ones.\nextensions = [\'sphinx.ext.ifconfig\', \'breathe\']\n\nbreathe_default_project = ""format""\nbreathe_domain_by_extension = {""h"" : ""cpp""}\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix of source filenames.\nsource_suffix = \'.rst\'\n\n# The encoding of source files.\n#source_encoding = \'utf-8-sig\'\n\n# The master toctree document.\n#master_doc = \'contents\'\n\n# General information about the project.\nproject = u\'fmt\'\ncopyright = u\'2012-present, Victor Zverovich\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\n\n# Version and release are passed from CMake.\n#version = None\n\n# The full version, including alpha/beta/rc tags.\n#release = version\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#language = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = \'\'\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = \'%B %d, %Y\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\'virtualenv\']\n\n# The reST default role (used for this markup: `text`) to use for all documents.\ndefault_role = \'cpp:any\'\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\nhighlight_language = \'c++\'\n\nprimary_domain = \'cpp\'\n\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n\n\n# -- Options for HTML output ---------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \'basic-bootstrap\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\nhtml_theme_path = [\'.\']\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# ""<project> v<release> documentation"".\n#html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n#html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# If not \'\', a \'Last updated on:\' timestamp is inserted at every page bottom,\n# using the given strftime format.\n#html_last_updated_fmt = \'%b %d, %Y\'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\nhtml_sidebars = {\n  \'**\': [\'localtoc.html\', \'relations.html\', \'sourcelink.html\', \'searchbox.html\']\n}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n\n# If false, no module index is generated.\n#html_domain_indices = True\n\n# If false, no index is generated.\n#html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n#html_show_sourcelink = True\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.\n#html_show_sphinx = True\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.\n#html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = \'\'\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n#html_file_suffix = None\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'formatdoc\'\n\n\n# -- Options for LaTeX output --------------------------------------------------\n\nlatex_elements = {\n# The paper size (\'letterpaper\' or \'a4paper\').\n#\'papersize\': \'letterpaper\',\n\n# The font size (\'10pt\', \'11pt\' or \'12pt\').\n#\'pointsize\': \'10pt\',\n\n# Additional stuff for the LaTeX preamble.\n#\'preamble\': \'\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass [howto/manual]).\nlatex_documents = [\n  (\'index\', \'format.tex\', u\'fmt documentation\',\n   u\'Victor Zverovich\', \'manual\'),\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n#latex_logo = None\n\n# For ""manual"" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n#latex_use_parts = False\n\n# If true, show page references after internal links.\n#latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n#latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n#latex_appendices = []\n\n# If false, no module index is generated.\n#latex_domain_indices = True\n\n\n# -- Options for manual page output --------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (\'index\', \'fmt\', u\'fmt documentation\', [u\'Victor Zverovich\'], 1)\n]\n\n# If true, show URL addresses after external links.\n#man_show_urls = False\n\n\n# -- Options for Texinfo output ------------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n  (\'index\', \'fmt\', u\'fmt documentation\',\n   u\'Victor Zverovich\', \'fmt\', \'One line description of project.\',\n   \'Miscellaneous\'),\n]\n\n# Documents to append as an appendix to all manuals.\n#texinfo_appendices = []\n\n# If false, no module index is generated.\n#texinfo_domain_indices = True\n\n# How to display URL addresses: \'footnote\', \'no\', or \'inline\'.\n#texinfo_show_urls = \'footnote\'\n'"
extern/fmt/support/appveyor-build.py,0,"b""#!/usr/bin/env python\n# Build the project on AppVeyor.\n\nimport os\nfrom subprocess import check_call\n\nbuild = os.environ['BUILD']\nconfig = os.environ['CONFIGURATION']\nplatform = os.environ['PLATFORM']\npath = os.environ['PATH']\nimage = os.environ['APPVEYOR_BUILD_WORKER_IMAGE']\njobid = os.environ['APPVEYOR_JOB_ID']\ncmake_command = ['cmake', '-DFMT_PEDANTIC=ON', '-DCMAKE_BUILD_TYPE=' + config, '..']\nif build == 'mingw':\n    cmake_command.append('-GMinGW Makefiles')\n    build_command = ['mingw32-make', '-j4']\n    test_command = ['mingw32-make', 'test']\n    # Remove the path to Git bin directory from $PATH because it breaks\n    # MinGW config.\n    path = path.replace(r'C:\\Program Files (x86)\\Git\\bin', '')\n    os.environ['PATH'] = r'C:\\MinGW\\bin;' + path\nelse:\n    # Add MSBuild 14.0 to PATH as described in\n    # http://help.appveyor.com/discussions/problems/2229-v140-not-found-on-vs2105rc.\n    os.environ['PATH'] = r'C:\\Program Files (x86)\\MSBuild\\15.0\\Bin;' + path\n    if image == 'Visual Studio 2013':\n        generator = 'Visual Studio 12 2013'\n    elif image == 'Visual Studio 2015':\n        generator = 'Visual Studio 14 2015'\n    elif image == 'Visual Studio 2017':\n        generator = 'Visual Studio 15 2017'\n    if platform == 'x64':\n        generator += ' Win64'\n    cmake_command.append('-G' + generator)\n    build_command = ['cmake', '--build', '.', '--config', config, '--', '/m:4']\n    test_command = ['ctest', '-C', config]\n\ncheck_call(cmake_command)\ncheck_call(build_command)\ncheck_call(test_command)\n"""
extern/fmt/support/compute-powers.py,0,"b""#!/usr/bin/env python\n# Compute 10 ** exp with exp in the range [min_exponent, max_exponent] and print\n# normalized (with most-significant bit equal to 1) significands in hexadecimal.\n\nfrom __future__ import print_function\n\nmin_exponent = -348\nmax_exponent = 340\nstep = 8\nsignificand_size = 64\nexp_offset = 2000\n\nclass fp:\n    pass\n\npowers = []\nfor i, exp in enumerate(range(min_exponent, max_exponent + 1, step)):\n    result = fp()\n    n = 10 ** exp if exp >= 0 else 2 ** exp_offset / 10 ** -exp\n    k = significand_size + 1\n    # Convert to binary and round.\n    binary = '{:b}'.format(n)\n    result.f = (int('{:0<{}}'.format(binary[:k], k), 2) + 1) / 2\n    result.e = len(binary) - (exp_offset if exp < 0 else 0) - significand_size\n    powers.append(result)\n    # Sanity check.\n    exp_offset10 = 400\n    actual = result.f * 10 ** exp_offset10\n    if result.e > 0:\n        actual *= 2 ** result.e\n    else:\n        for j in range(-result.e):\n            actual /= 2\n    expected = 10 ** (exp_offset10 + exp)\n    precision = len('{}'.format(expected)) - len('{}'.format(actual - expected))\n    if precision < 19:\n        print('low precision:', precision)\n        exit(1)\n\nprint('Significands:', end='')\nfor i, fp in enumerate(powers):\n    if i % 4 == 0:\n        print(end='\\n ')\n    print(' {:0<#16x}'.format(fp.f, ), end=',')\n\nprint('\\n\\nExponents:', end='')\nfor i, fp in enumerate(powers):\n    if i % 11 == 0:\n        print(end='\\n ')\n    print(' {:5}'.format(fp.e), end=',')\n\nprint('\\n\\nMax exponent difference:',\n      max([x.e - powers[i - 1].e for i, x in enumerate(powers)][1:]))\n"""
extern/fmt/support/docopt.py,0,"b'""""""Pythonic command-line interface parser that will make you smile.\n\n * http://docopt.org\n * Repository and issue-tracker: https://github.com/docopt/docopt\n * Licensed under terms of MIT license (see LICENSE-MIT)\n * Copyright (c) 2013 Vladimir Keleshev, vladimir@keleshev.com\n\n""""""\nimport sys\nimport re\n\n\n__all__ = [\'docopt\']\n__version__ = \'0.6.1\'\n\n\nclass DocoptLanguageError(Exception):\n\n    """"""Error in construction of usage-message by developer.""""""\n\n\nclass DocoptExit(SystemExit):\n\n    """"""Exit in case user invoked program with incorrect arguments.""""""\n\n    usage = \'\'\n\n    def __init__(self, message=\'\'):\n        SystemExit.__init__(self, (message + \'\\n\' + self.usage).strip())\n\n\nclass Pattern(object):\n\n    def __eq__(self, other):\n        return repr(self) == repr(other)\n\n    def __hash__(self):\n        return hash(repr(self))\n\n    def fix(self):\n        self.fix_identities()\n        self.fix_repeating_arguments()\n        return self\n\n    def fix_identities(self, uniq=None):\n        """"""Make pattern-tree tips point to same object if they are equal.""""""\n        if not hasattr(self, \'children\'):\n            return self\n        uniq = list(set(self.flat())) if uniq is None else uniq\n        for i, child in enumerate(self.children):\n            if not hasattr(child, \'children\'):\n                assert child in uniq\n                self.children[i] = uniq[uniq.index(child)]\n            else:\n                child.fix_identities(uniq)\n\n    def fix_repeating_arguments(self):\n        """"""Fix elements that should accumulate/increment values.""""""\n        either = [list(child.children) for child in transform(self).children]\n        for case in either:\n            for e in [child for child in case if case.count(child) > 1]:\n                if type(e) is Argument or type(e) is Option and e.argcount:\n                    if e.value is None:\n                        e.value = []\n                    elif type(e.value) is not list:\n                        e.value = e.value.split()\n                if type(e) is Command or type(e) is Option and e.argcount == 0:\n                    e.value = 0\n        return self\n\n\ndef transform(pattern):\n    """"""Expand pattern into an (almost) equivalent one, but with single Either.\n\n    Example: ((-a | -b) (-c | -d)) => (-a -c | -a -d | -b -c | -b -d)\n    Quirks: [-a] => (-a), (-a...) => (-a -a)\n\n    """"""\n    result = []\n    groups = [[pattern]]\n    while groups:\n        children = groups.pop(0)\n        parents = [Required, Optional, OptionsShortcut, Either, OneOrMore]\n        if any(t in map(type, children) for t in parents):\n            child = [c for c in children if type(c) in parents][0]\n            children.remove(child)\n            if type(child) is Either:\n                for c in child.children:\n                    groups.append([c] + children)\n            elif type(child) is OneOrMore:\n                groups.append(child.children * 2 + children)\n            else:\n                groups.append(child.children + children)\n        else:\n            result.append(children)\n    return Either(*[Required(*e) for e in result])\n\n\nclass LeafPattern(Pattern):\n\n    """"""Leaf/terminal node of a pattern tree.""""""\n\n    def __init__(self, name, value=None):\n        self.name, self.value = name, value\n\n    def __repr__(self):\n        return \'%s(%r, %r)\' % (self.__class__.__name__, self.name, self.value)\n\n    def flat(self, *types):\n        return [self] if not types or type(self) in types else []\n\n    def match(self, left, collected=None):\n        collected = [] if collected is None else collected\n        pos, match = self.single_match(left)\n        if match is None:\n            return False, left, collected\n        left_ = left[:pos] + left[pos + 1:]\n        same_name = [a for a in collected if a.name == self.name]\n        if type(self.value) in (int, list):\n            if type(self.value) is int:\n                increment = 1\n            else:\n                increment = ([match.value] if type(match.value) is str\n                             else match.value)\n            if not same_name:\n                match.value = increment\n                return True, left_, collected + [match]\n            same_name[0].value += increment\n            return True, left_, collected\n        return True, left_, collected + [match]\n\n\nclass BranchPattern(Pattern):\n\n    """"""Branch/inner node of a pattern tree.""""""\n\n    def __init__(self, *children):\n        self.children = list(children)\n\n    def __repr__(self):\n        return \'%s(%s)\' % (self.__class__.__name__,\n                           \', \'.join(repr(a) for a in self.children))\n\n    def flat(self, *types):\n        if type(self) in types:\n            return [self]\n        return sum([child.flat(*types) for child in self.children], [])\n\n\nclass Argument(LeafPattern):\n\n    def single_match(self, left):\n        for n, pattern in enumerate(left):\n            if type(pattern) is Argument:\n                return n, Argument(self.name, pattern.value)\n        return None, None\n\n    @classmethod\n    def parse(class_, source):\n        name = re.findall(\'(<\\S*?>)\', source)[0]\n        value = re.findall(\'\\[default: (.*)\\]\', source, flags=re.I)\n        return class_(name, value[0] if value else None)\n\n\nclass Command(Argument):\n\n    def __init__(self, name, value=False):\n        self.name, self.value = name, value\n\n    def single_match(self, left):\n        for n, pattern in enumerate(left):\n            if type(pattern) is Argument:\n                if pattern.value == self.name:\n                    return n, Command(self.name, True)\n                else:\n                    break\n        return None, None\n\n\nclass Option(LeafPattern):\n\n    def __init__(self, short=None, long=None, argcount=0, value=False):\n        assert argcount in (0, 1)\n        self.short, self.long, self.argcount = short, long, argcount\n        self.value = None if value is False and argcount else value\n\n    @classmethod\n    def parse(class_, option_description):\n        short, long, argcount, value = None, None, 0, False\n        options, _, description = option_description.strip().partition(\'  \')\n        options = options.replace(\',\', \' \').replace(\'=\', \' \')\n        for s in options.split():\n            if s.startswith(\'--\'):\n                long = s\n            elif s.startswith(\'-\'):\n                short = s\n            else:\n                argcount = 1\n        if argcount:\n            matched = re.findall(\'\\[default: (.*)\\]\', description, flags=re.I)\n            value = matched[0] if matched else None\n        return class_(short, long, argcount, value)\n\n    def single_match(self, left):\n        for n, pattern in enumerate(left):\n            if self.name == pattern.name:\n                return n, pattern\n        return None, None\n\n    @property\n    def name(self):\n        return self.long or self.short\n\n    def __repr__(self):\n        return \'Option(%r, %r, %r, %r)\' % (self.short, self.long,\n                                           self.argcount, self.value)\n\n\nclass Required(BranchPattern):\n\n    def match(self, left, collected=None):\n        collected = [] if collected is None else collected\n        l = left\n        c = collected\n        for pattern in self.children:\n            matched, l, c = pattern.match(l, c)\n            if not matched:\n                return False, left, collected\n        return True, l, c\n\n\nclass Optional(BranchPattern):\n\n    def match(self, left, collected=None):\n        collected = [] if collected is None else collected\n        for pattern in self.children:\n            m, left, collected = pattern.match(left, collected)\n        return True, left, collected\n\n\nclass OptionsShortcut(Optional):\n\n    """"""Marker/placeholder for [options] shortcut.""""""\n\n\nclass OneOrMore(BranchPattern):\n\n    def match(self, left, collected=None):\n        assert len(self.children) == 1\n        collected = [] if collected is None else collected\n        l = left\n        c = collected\n        l_ = None\n        matched = True\n        times = 0\n        while matched:\n            # could it be that something didn\'t match but changed l or c?\n            matched, l, c = self.children[0].match(l, c)\n            times += 1 if matched else 0\n            if l_ == l:\n                break\n            l_ = l\n        if times >= 1:\n            return True, l, c\n        return False, left, collected\n\n\nclass Either(BranchPattern):\n\n    def match(self, left, collected=None):\n        collected = [] if collected is None else collected\n        outcomes = []\n        for pattern in self.children:\n            matched, _, _ = outcome = pattern.match(left, collected)\n            if matched:\n                outcomes.append(outcome)\n        if outcomes:\n            return min(outcomes, key=lambda outcome: len(outcome[1]))\n        return False, left, collected\n\n\nclass Tokens(list):\n\n    def __init__(self, source, error=DocoptExit):\n        self += source.split() if hasattr(source, \'split\') else source\n        self.error = error\n\n    @staticmethod\n    def from_pattern(source):\n        source = re.sub(r\'([\\[\\]\\(\\)\\|]|\\.\\.\\.)\', r\' \\1 \', source)\n        source = [s for s in re.split(\'\\s+|(\\S*<.*?>)\', source) if s]\n        return Tokens(source, error=DocoptLanguageError)\n\n    def move(self):\n        return self.pop(0) if len(self) else None\n\n    def current(self):\n        return self[0] if len(self) else None\n\n\ndef parse_long(tokens, options):\n    """"""long ::= \'--\' chars [ ( \' \' | \'=\' ) chars ] ;""""""\n    long, eq, value = tokens.move().partition(\'=\')\n    assert long.startswith(\'--\')\n    value = None if eq == value == \'\' else value\n    similar = [o for o in options if o.long == long]\n    if tokens.error is DocoptExit and similar == []:  # if no exact match\n        similar = [o for o in options if o.long and o.long.startswith(long)]\n    if len(similar) > 1:  # might be simply specified ambiguously 2+ times?\n        raise tokens.error(\'%s is not a unique prefix: %s?\' %\n                           (long, \', \'.join(o.long for o in similar)))\n    elif len(similar) < 1:\n        argcount = 1 if eq == \'=\' else 0\n        o = Option(None, long, argcount)\n        options.append(o)\n        if tokens.error is DocoptExit:\n            o = Option(None, long, argcount, value if argcount else True)\n    else:\n        o = Option(similar[0].short, similar[0].long,\n                   similar[0].argcount, similar[0].value)\n        if o.argcount == 0:\n            if value is not None:\n                raise tokens.error(\'%s must not have an argument\' % o.long)\n        else:\n            if value is None:\n                if tokens.current() in [None, \'--\']:\n                    raise tokens.error(\'%s requires argument\' % o.long)\n                value = tokens.move()\n        if tokens.error is DocoptExit:\n            o.value = value if value is not None else True\n    return [o]\n\n\ndef parse_shorts(tokens, options):\n    """"""shorts ::= \'-\' ( chars )* [ [ \' \' ] chars ] ;""""""\n    token = tokens.move()\n    assert token.startswith(\'-\') and not token.startswith(\'--\')\n    left = token.lstrip(\'-\')\n    parsed = []\n    while left != \'\':\n        short, left = \'-\' + left[0], left[1:]\n        similar = [o for o in options if o.short == short]\n        if len(similar) > 1:\n            raise tokens.error(\'%s is specified ambiguously %d times\' %\n                               (short, len(similar)))\n        elif len(similar) < 1:\n            o = Option(short, None, 0)\n            options.append(o)\n            if tokens.error is DocoptExit:\n                o = Option(short, None, 0, True)\n        else:  # why copying is necessary here?\n            o = Option(short, similar[0].long,\n                       similar[0].argcount, similar[0].value)\n            value = None\n            if o.argcount != 0:\n                if left == \'\':\n                    if tokens.current() in [None, \'--\']:\n                        raise tokens.error(\'%s requires argument\' % short)\n                    value = tokens.move()\n                else:\n                    value = left\n                    left = \'\'\n            if tokens.error is DocoptExit:\n                o.value = value if value is not None else True\n        parsed.append(o)\n    return parsed\n\n\ndef parse_pattern(source, options):\n    tokens = Tokens.from_pattern(source)\n    result = parse_expr(tokens, options)\n    if tokens.current() is not None:\n        raise tokens.error(\'unexpected ending: %r\' % \' \'.join(tokens))\n    return Required(*result)\n\n\ndef parse_expr(tokens, options):\n    """"""expr ::= seq ( \'|\' seq )* ;""""""\n    seq = parse_seq(tokens, options)\n    if tokens.current() != \'|\':\n        return seq\n    result = [Required(*seq)] if len(seq) > 1 else seq\n    while tokens.current() == \'|\':\n        tokens.move()\n        seq = parse_seq(tokens, options)\n        result += [Required(*seq)] if len(seq) > 1 else seq\n    return [Either(*result)] if len(result) > 1 else result\n\n\ndef parse_seq(tokens, options):\n    """"""seq ::= ( atom [ \'...\' ] )* ;""""""\n    result = []\n    while tokens.current() not in [None, \']\', \')\', \'|\']:\n        atom = parse_atom(tokens, options)\n        if tokens.current() == \'...\':\n            atom = [OneOrMore(*atom)]\n            tokens.move()\n        result += atom\n    return result\n\n\ndef parse_atom(tokens, options):\n    """"""atom ::= \'(\' expr \')\' | \'[\' expr \']\' | \'options\'\n             | long | shorts | argument | command ;\n    """"""\n    token = tokens.current()\n    result = []\n    if token in \'([\':\n        tokens.move()\n        matching, pattern = {\'(\': [\')\', Required], \'[\': [\']\', Optional]}[token]\n        result = pattern(*parse_expr(tokens, options))\n        if tokens.move() != matching:\n            raise tokens.error(""unmatched \'%s\'"" % token)\n        return [result]\n    elif token == \'options\':\n        tokens.move()\n        return [OptionsShortcut()]\n    elif token.startswith(\'--\') and token != \'--\':\n        return parse_long(tokens, options)\n    elif token.startswith(\'-\') and token not in (\'-\', \'--\'):\n        return parse_shorts(tokens, options)\n    elif token.startswith(\'<\') and token.endswith(\'>\') or token.isupper():\n        return [Argument(tokens.move())]\n    else:\n        return [Command(tokens.move())]\n\n\ndef parse_argv(tokens, options, options_first=False):\n    """"""Parse command-line argument vector.\n\n    If options_first:\n        argv ::= [ long | shorts ]* [ argument ]* [ \'--\' [ argument ]* ] ;\n    else:\n        argv ::= [ long | shorts | argument ]* [ \'--\' [ argument ]* ] ;\n\n    """"""\n    parsed = []\n    while tokens.current() is not None:\n        if tokens.current() == \'--\':\n            return parsed + [Argument(None, v) for v in tokens]\n        elif tokens.current().startswith(\'--\'):\n            parsed += parse_long(tokens, options)\n        elif tokens.current().startswith(\'-\') and tokens.current() != \'-\':\n            parsed += parse_shorts(tokens, options)\n        elif options_first:\n            return parsed + [Argument(None, v) for v in tokens]\n        else:\n            parsed.append(Argument(None, tokens.move()))\n    return parsed\n\n\ndef parse_defaults(doc):\n    defaults = []\n    for s in parse_section(\'options:\', doc):\n        # FIXME corner case ""bla: options: --foo""\n        _, _, s = s.partition(\':\')  # get rid of ""options:""\n        split = re.split(\'\\n[ \\t]*(-\\S+?)\', \'\\n\' + s)[1:]\n        split = [s1 + s2 for s1, s2 in zip(split[::2], split[1::2])]\n        options = [Option.parse(s) for s in split if s.startswith(\'-\')]\n        defaults += options\n    return defaults\n\n\ndef parse_section(name, source):\n    pattern = re.compile(\'^([^\\n]*\' + name + \'[^\\n]*\\n?(?:[ \\t].*?(?:\\n|$))*)\',\n                         re.IGNORECASE | re.MULTILINE)\n    return [s.strip() for s in pattern.findall(source)]\n\n\ndef formal_usage(section):\n    _, _, section = section.partition(\':\')  # drop ""usage:""\n    pu = section.split()\n    return \'( \' + \' \'.join(\') | (\' if s == pu[0] else s for s in pu[1:]) + \' )\'\n\n\ndef extras(help, version, options, doc):\n    if help and any((o.name in (\'-h\', \'--help\')) and o.value for o in options):\n        print(doc.strip(""\\n""))\n        sys.exit()\n    if version and any(o.name == \'--version\' and o.value for o in options):\n        print(version)\n        sys.exit()\n\n\nclass Dict(dict):\n    def __repr__(self):\n        return \'{%s}\' % \',\\n \'.join(\'%r: %r\' % i for i in sorted(self.items()))\n\n\ndef docopt(doc, argv=None, help=True, version=None, options_first=False):\n    """"""Parse `argv` based on command-line interface described in `doc`.\n\n    `docopt` creates your command-line interface based on its\n    description that you pass as `doc`. Such description can contain\n    --options, <positional-argument>, commands, which could be\n    [optional], (required), (mutually | exclusive) or repeated...\n\n    Parameters\n    ----------\n    doc : str\n        Description of your command-line interface.\n    argv : list of str, optional\n        Argument vector to be parsed. sys.argv[1:] is used if not\n        provided.\n    help : bool (default: True)\n        Set to False to disable automatic help on -h or --help\n        options.\n    version : any object\n        If passed, the object will be printed if --version is in\n        `argv`.\n    options_first : bool (default: False)\n        Set to True to require options precede positional arguments,\n        i.e. to forbid options and positional arguments intermix.\n\n    Returns\n    -------\n    args : dict\n        A dictionary, where keys are names of command-line elements\n        such as e.g. ""--verbose"" and ""<path>"", and values are the\n        parsed values of those elements.\n\n    Example\n    -------\n    >>> from docopt import docopt\n    >>> doc = \'\'\'\n    ... Usage:\n    ...     my_program tcp <host> <port> [--timeout=<seconds>]\n    ...     my_program serial <port> [--baud=<n>] [--timeout=<seconds>]\n    ...     my_program (-h | --help | --version)\n    ...\n    ... Options:\n    ...     -h, --help  Show this screen and exit.\n    ...     --baud=<n>  Baudrate [default: 9600]\n    ... \'\'\'\n    >>> argv = [\'tcp\', \'127.0.0.1\', \'80\', \'--timeout\', \'30\']\n    >>> docopt(doc, argv)\n    {\'--baud\': \'9600\',\n     \'--help\': False,\n     \'--timeout\': \'30\',\n     \'--version\': False,\n     \'<host>\': \'127.0.0.1\',\n     \'<port>\': \'80\',\n     \'serial\': False,\n     \'tcp\': True}\n\n    See also\n    --------\n    * For video introduction see http://docopt.org\n    * Full documentation is available in README.rst as well as online\n      at https://github.com/docopt/docopt#readme\n\n    """"""\n    argv = sys.argv[1:] if argv is None else argv\n\n    usage_sections = parse_section(\'usage:\', doc)\n    if len(usage_sections) == 0:\n        raise DocoptLanguageError(\'""usage:"" (case-insensitive) not found.\')\n    if len(usage_sections) > 1:\n        raise DocoptLanguageError(\'More than one ""usage:"" (case-insensitive).\')\n    DocoptExit.usage = usage_sections[0]\n\n    options = parse_defaults(doc)\n    pattern = parse_pattern(formal_usage(DocoptExit.usage), options)\n    # [default] syntax for argument is disabled\n    #for a in pattern.flat(Argument):\n    #    same_name = [d for d in arguments if d.name == a.name]\n    #    if same_name:\n    #        a.value = same_name[0].value\n    argv = parse_argv(Tokens(argv), list(options), options_first)\n    pattern_options = set(pattern.flat(Option))\n    for options_shortcut in pattern.flat(OptionsShortcut):\n        doc_options = parse_defaults(doc)\n        options_shortcut.children = list(set(doc_options) - pattern_options)\n        #if any_options:\n        #    options_shortcut.children += [Option(o.short, o.long, o.argcount)\n        #                    for o in argv if type(o) is Option]\n    extras(help, version, argv, doc)\n    matched, left, collected = pattern.fix().match(argv)\n    if matched and left == []:  # better error message if left?\n        return Dict((a.name, a.value) for a in (pattern.flat() + collected))\n    raise DocoptExit()\n'"
extern/fmt/support/manage.py,0,"b'#!/usr/bin/env python\n\n""""""Manage site and releases.\n\nUsage:\n  manage.py release [<branch>]\n  manage.py site\n""""""\n\nfrom __future__ import print_function\nimport datetime, docopt, errno, fileinput, json, os\nimport re, requests, shutil, sys, tempfile\nfrom contextlib import contextmanager\nfrom distutils.version import LooseVersion\nfrom subprocess import check_call\n\n\nclass Git:\n    def __init__(self, dir):\n        self.dir = dir\n\n    def call(self, method, args, **kwargs):\n        return check_call([\'git\', method] + list(args), **kwargs)\n\n    def add(self, *args):\n        return self.call(\'add\', args, cwd=self.dir)\n\n    def checkout(self, *args):\n        return self.call(\'checkout\', args, cwd=self.dir)\n\n    def clean(self, *args):\n        return self.call(\'clean\', args, cwd=self.dir)\n\n    def clone(self, *args):\n        return self.call(\'clone\', list(args) + [self.dir])\n\n    def commit(self, *args):\n        return self.call(\'commit\', args, cwd=self.dir)\n\n    def pull(self, *args):\n        return self.call(\'pull\', args, cwd=self.dir)\n\n    def push(self, *args):\n        return self.call(\'push\', args, cwd=self.dir)\n\n    def reset(self, *args):\n        return self.call(\'reset\', args, cwd=self.dir)\n\n    def update(self, *args):\n        clone = not os.path.exists(self.dir)\n        if clone:\n            self.clone(*args)\n        return clone\n\n\ndef clean_checkout(repo, branch):\n    repo.clean(\'-f\', \'-d\')\n    repo.reset(\'--hard\')\n    repo.checkout(branch)\n\n\nclass Runner:\n    def __init__(self, cwd):\n        self.cwd = cwd\n\n    def __call__(self, *args, **kwargs):\n        kwargs[\'cwd\'] = kwargs.get(\'cwd\', self.cwd)\n        check_call(args, **kwargs)\n\n\ndef create_build_env():\n    """"""Create a build environment.""""""\n    class Env:\n        pass\n    env = Env()\n\n    # Import the documentation build module.\n    env.fmt_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n    sys.path.insert(0, os.path.join(env.fmt_dir, \'doc\'))\n    import build\n\n    env.build_dir = \'build\'\n    env.versions = build.versions\n\n    # Virtualenv and repos are cached to speed up builds.\n    build.create_build_env(os.path.join(env.build_dir, \'virtualenv\'))\n\n    env.fmt_repo = Git(os.path.join(env.build_dir, \'fmt\'))\n    return env\n\n\n@contextmanager\ndef rewrite(filename):\n    class Buffer:\n        pass\n    buffer = Buffer()\n    if not os.path.exists(filename):\n        buffer.data = \'\'\n        yield buffer\n        return\n    with open(filename) as f:\n        buffer.data = f.read()\n    yield buffer\n    with open(filename, \'w\') as f:\n        f.write(buffer.data)\n\n\nfmt_repo_url = \'git@github.com:fmtlib/fmt\'\n\n\ndef update_site(env):\n    env.fmt_repo.update(fmt_repo_url)\n\n    doc_repo = Git(os.path.join(env.build_dir, \'fmtlib.github.io\'))\n    doc_repo.update(\'git@github.com:fmtlib/fmtlib.github.io\')\n\n    for version in env.versions:\n        clean_checkout(env.fmt_repo, version)\n        target_doc_dir = os.path.join(env.fmt_repo.dir, \'doc\')\n        # Remove the old theme.\n        for entry in os.listdir(target_doc_dir):\n            path = os.path.join(target_doc_dir, entry)\n            if os.path.isdir(path):\n                shutil.rmtree(path)\n        # Copy the new theme.\n        for entry in [\'_static\', \'_templates\', \'basic-bootstrap\', \'bootstrap\',\n                      \'conf.py\', \'fmt.less\']:\n            src = os.path.join(env.fmt_dir, \'doc\', entry)\n            dst = os.path.join(target_doc_dir, entry)\n            copy = shutil.copytree if os.path.isdir(src) else shutil.copyfile\n            copy(src, dst)\n        # Rename index to contents.\n        contents = os.path.join(target_doc_dir, \'contents.rst\')\n        if not os.path.exists(contents):\n            os.rename(os.path.join(target_doc_dir, \'index.rst\'), contents)\n        # Fix issues in reference.rst/api.rst.\n        for filename in [\'reference.rst\', \'api.rst\']:\n            pattern = re.compile(\'doxygenfunction.. (bin|oct|hexu|hex)$\', re.M)\n            with rewrite(os.path.join(target_doc_dir, filename)) as b:\n                b.data = b.data.replace(\'std::ostream &\', \'std::ostream&\')\n                b.data = re.sub(pattern, r\'doxygenfunction:: \\1(int)\', b.data)\n                b.data = b.data.replace(\'std::FILE*\', \'std::FILE *\')\n                b.data = b.data.replace(\'unsigned int\', \'unsigned\')\n                b.data = b.data.replace(\'operator""""_\', \'operator"""" _\')\n        # Fix a broken link in index.rst.\n        index = os.path.join(target_doc_dir, \'index.rst\')\n        with rewrite(index) as b:\n            b.data = b.data.replace(\n                \'doc/latest/index.html#format-string-syntax\', \'syntax.html\')\n        # Build the docs.\n        html_dir = os.path.join(env.build_dir, \'html\')\n        if os.path.exists(html_dir):\n            shutil.rmtree(html_dir)\n        include_dir = env.fmt_repo.dir\n        if LooseVersion(version) >= LooseVersion(\'5.0.0\'):\n            include_dir = os.path.join(include_dir, \'include\', \'fmt\')\n        elif LooseVersion(version) >= LooseVersion(\'3.0.0\'):\n            include_dir = os.path.join(include_dir, \'fmt\')\n        import build\n        build.build_docs(version, doc_dir=target_doc_dir,\n                         include_dir=include_dir, work_dir=env.build_dir)\n        shutil.rmtree(os.path.join(html_dir, \'.doctrees\'))\n        # Create symlinks for older versions.\n        for link, target in {\'index\': \'contents\', \'api\': \'reference\'}.items():\n            link = os.path.join(html_dir, link) + \'.html\'\n            target += \'.html\'\n            if os.path.exists(os.path.join(html_dir, target)) and \\\n               not os.path.exists(link):\n                os.symlink(target, link)\n        # Copy docs to the website.\n        version_doc_dir = os.path.join(doc_repo.dir, version)\n        try:\n            shutil.rmtree(version_doc_dir)\n        except OSError as e:\n            if e.errno != errno.ENOENT:\n                raise\n        shutil.move(html_dir, version_doc_dir)\n\n\ndef release(args):\n    env = create_build_env()\n    fmt_repo = env.fmt_repo\n\n    branch = args.get(\'<branch>\')\n    if branch is None:\n        branch = \'master\'\n    if not fmt_repo.update(\'-b\', branch, fmt_repo_url):\n        clean_checkout(fmt_repo, branch)\n\n    # Convert changelog from RST to GitHub-flavored Markdown and get the\n    # version.\n    changelog = \'ChangeLog.rst\'\n    changelog_path = os.path.join(fmt_repo.dir, changelog)\n    import rst2md\n    changes, version = rst2md.convert(changelog_path)\n    cmakelists = \'CMakeLists.txt\'\n    for line in fileinput.input(os.path.join(fmt_repo.dir, cmakelists),\n                                inplace=True):\n        prefix = \'set(FMT_VERSION \'\n        if line.startswith(prefix):\n            line = prefix + version + \')\\n\'\n        sys.stdout.write(line)\n\n    # Update the version in the changelog.\n    title_len = 0\n    for line in fileinput.input(changelog_path, inplace=True):\n        if line.decode(\'utf-8\').startswith(version + \' - TBD\'):\n            line = version + \' - \' + datetime.date.today().isoformat()\n            title_len = len(line)\n            line += \'\\n\'\n        elif title_len:\n            line = \'-\' * title_len + \'\\n\'\n            title_len = 0\n        sys.stdout.write(line)\n\n    # Add the version to the build script.\n    script = os.path.join(\'doc\', \'build.py\')\n    script_path = os.path.join(fmt_repo.dir, script)\n    for line in fileinput.input(script_path, inplace=True):\n      m = re.match(r\'( *versions = )\\[(.+)\\]\', line)\n      if m:\n        line = \'{}[{}, \\\'{}\\\']\\n\'.format(m.group(1), m.group(2), version)\n      sys.stdout.write(line)\n\n    fmt_repo.checkout(\'-B\', \'release\')\n    fmt_repo.add(changelog, cmakelists, script)\n    fmt_repo.commit(\'-m\', \'Update version\')\n\n    # Build the docs and package.\n    run = Runner(fmt_repo.dir)\n    run(\'cmake\', \'.\')\n    run(\'make\', \'doc\', \'package_source\')\n    update_site(env)\n\n    # Create a release on GitHub.\n    fmt_repo.push(\'origin\', \'release\')\n    params = {\'access_token\': os.getenv(\'FMT_TOKEN\')}\n    r = requests.post(\'https://api.github.com/repos/fmtlib/fmt/releases\',\n                      params=params,\n                      data=json.dumps({\'tag_name\': version,\n                                       \'target_commitish\': \'release\',\n                                       \'body\': changes, \'draft\': True}))\n    if r.status_code != 201:\n        raise Exception(\'Failed to create a release \' + str(r))\n    id = r.json()[\'id\']\n    uploads_url = \'https://uploads.github.com/repos/fmtlib/fmt/releases\'\n    package = \'fmt-{}.zip\'.format(version)\n    r = requests.post(\n        \'{}/{}/assets?name={}\'.format(uploads_url, id, package),\n        params=params, files={package: open(\'build/fmt/\' + package, \'rb\')})\n    if r.status_code != 201:\n        raise Exception(\'Failed to upload an asset \' + str(r))\n\n\nif __name__ == \'__main__\':\n    args = docopt.docopt(__doc__)\n    if args.get(\'release\'):\n        release(args)\n    elif args.get(\'site\'):\n        update_site(create_build_env())\n'"
extern/fmt/support/rst2md.py,0,"b'# reStructuredText (RST) to GitHub-flavored Markdown converter\n\nimport re\nfrom docutils import core, nodes, writers\n\n\ndef is_github_ref(node):\n    return re.match(\'https://github.com/.*/(issues|pull)/.*\', node[\'refuri\'])\n\n\nclass Translator(nodes.NodeVisitor):\n    def __init__(self, document):\n        nodes.NodeVisitor.__init__(self, document)\n        self.output = \'\'\n        self.indent = 0\n        self.preserve_newlines = False\n\n    def write(self, text):\n        self.output += text.replace(\'\\n\', \'\\n\' + \' \' * self.indent)\n\n    def visit_document(self, node):\n        pass\n\n    def depart_document(self, node):\n        pass\n\n    def visit_section(self, node):\n        pass\n\n    def depart_section(self, node):\n        # Skip all sections except the first one.\n        raise nodes.StopTraversal\n\n    def visit_title(self, node):\n        self.version = re.match(r\'(\\d+\\.\\d+\\.\\d+).*\', node.children[0]).group(1)\n        raise nodes.SkipChildren\n\n    def depart_title(self, node):\n        pass\n\n    def visit_Text(self, node):\n        if not self.preserve_newlines:\n            node = node.replace(\'\\n\', \' \')\n        self.write(node)\n\n    def depart_Text(self, node):\n        pass\n\n    def visit_bullet_list(self, node):\n        pass\n\n    def depart_bullet_list(self, node):\n        pass\n\n    def visit_list_item(self, node):\n        self.write(\'* \')\n        self.indent += 2\n\n    def depart_list_item(self, node):\n        self.indent -= 2\n        self.write(\'\\n\\n\')\n\n    def visit_paragraph(self, node):\n        pass\n\n    def depart_paragraph(self, node):\n        pass\n\n    def visit_reference(self, node):\n        if not is_github_ref(node):\n            self.write(\'[\')\n\n    def depart_reference(self, node):\n        if not is_github_ref(node):\n            self.write(\'](\' + node[\'refuri\'] + \')\')\n\n    def visit_target(self, node):\n        pass\n\n    def depart_target(self, node):\n        pass\n\n    def visit_literal(self, node):\n        self.write(\'`\')\n\n    def depart_literal(self, node):\n        self.write(\'`\')\n\n    def visit_literal_block(self, node):\n        self.write(\'\\n\\n```\')\n        if \'c++\' in node[\'classes\']:\n            self.write(\'c++\')\n        self.write(\'\\n\')\n        self.preserve_newlines = True\n\n    def depart_literal_block(self, node):\n        self.write(\'\\n```\\n\')\n        self.preserve_newlines = False\n\n    def visit_inline(self, node):\n        pass\n\n    def depart_inline(self, node):\n        pass\n\n    def visit_image(self, node):\n        self.write(\'![](\' + node[\'uri\'] + \')\')\n\n    def depart_image(self, node):\n        pass\n\n\nclass MDWriter(writers.Writer):\n    """"""GitHub-flavored markdown writer""""""\n\n    supported = (\'md\',)\n    """"""Formats this writer supports.""""""\n\n    def translate(self):\n        translator = Translator(self.document)\n        self.document.walkabout(translator)\n        self.output = (translator.output, translator.version)\n\n\ndef convert(rst_path):\n    """"""Converts RST file to Markdown.""""""\n    return core.publish_file(source_path=rst_path, writer=MDWriter())\n'"
extern/fmt/support/travis-build.py,0,"b'#!/usr/bin/env python\n# Build the project on Travis CI.\n\nfrom __future__ import print_function\nimport errno, os, shutil, subprocess, sys, urllib\nfrom subprocess import call, check_call, Popen, PIPE, STDOUT\n\ndef rmtree_if_exists(dir):\n    try:\n        shutil.rmtree(dir)\n    except OSError as e:\n        if e.errno == errno.ENOENT:\n            pass\n\ndef makedirs_if_not_exist(dir):\n    try:\n        os.makedirs(dir)\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n\ndef install_dependencies():\n    branch = os.environ[\'TRAVIS_BRANCH\']\n    if branch != \'master\':\n        print(\'Branch: \' + branch)\n        exit(0) # Ignore non-master branches\n    check_call(\'curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key \' +\n               \'| sudo apt-key add -\', shell=True)\n    check_call(\'echo ""deb https://deb.nodesource.com/node_0.10 precise main"" \' +\n               \'| sudo tee /etc/apt/sources.list.d/nodesource.list\', shell=True)\n    check_call([\'sudo\', \'apt-get\', \'update\'])\n    check_call([\'sudo\', \'apt-get\', \'install\', \'python-virtualenv\', \'nodejs\'])\n    check_call([\'sudo\', \'npm\', \'install\', \'-g\', \'less@2.6.1\', \'less-plugin-clean-css\'])\n    deb_file = \'doxygen_1.8.6-2_amd64.deb\'\n    urllib.urlretrieve(\'http://mirrors.kernel.org/ubuntu/pool/main/d/doxygen/\' +\n                       deb_file, deb_file)\n    check_call([\'sudo\', \'dpkg\', \'-i\', deb_file])\n\nfmt_dir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\n\nbuild = os.environ[\'BUILD\']\nif build == \'Doc\':\n    travis = \'TRAVIS\' in os.environ\n    if travis:\n        install_dependencies()\n    sys.path.insert(0, os.path.join(fmt_dir, \'doc\'))\n    import build\n    build.create_build_env()\n    html_dir = build.build_docs()\n    repo = \'fmtlib.github.io\'\n    if travis and \'KEY\' not in os.environ:\n        # Don\'t update the repo if building on Travis from an account that\n        # doesn\'t have push access.\n        print(\'Skipping update of \' + repo)\n        exit(0)\n    # Clone the fmtlib.github.io repo.\n    rmtree_if_exists(repo)\n    git_url = \'https://github.com/\' if travis else \'git@github.com:\'\n    check_call([\'git\', \'clone\', git_url + \'fmtlib/{}.git\'.format(repo)])\n    # Copy docs to the repo.\n    target_dir = os.path.join(repo, \'dev\')\n    rmtree_if_exists(target_dir)\n    shutil.copytree(html_dir, target_dir, ignore=shutil.ignore_patterns(\'.*\'))\n    if travis:\n        check_call([\'git\', \'config\', \'--global\', \'user.name\', \'amplbot\'])\n        check_call([\'git\', \'config\', \'--global\', \'user.email\', \'viz@ampl.com\'])\n    # Push docs to GitHub pages.\n    check_call([\'git\', \'add\', \'--all\'], cwd=repo)\n    if call([\'git\', \'diff-index\', \'--quiet\', \'HEAD\'], cwd=repo):\n        check_call([\'git\', \'commit\', \'-m\', \'Update documentation\'], cwd=repo)\n        cmd = \'git push\'\n        if travis:\n            cmd += \' https://$KEY@github.com/fmtlib/fmtlib.github.io.git master\'\n        p = Popen(cmd, shell=True, stdout=PIPE, stderr=STDOUT, cwd=repo)\n        # Print the output without the key.\n        print(p.communicate()[0].replace(os.environ[\'KEY\'], \'$KEY\'))\n        if p.returncode != 0:\n            raise subprocess.CalledProcessError(p.returncode, cmd)\n    exit(0)\n\nstandard = os.environ[\'STANDARD\']\ninstall_dir    = os.path.join(fmt_dir, ""_install"")\nbuild_dir      = os.path.join(fmt_dir, ""_build"")\ntest_build_dir = os.path.join(fmt_dir, ""_build_test"")\n\n# Configure library.\nmakedirs_if_not_exist(build_dir)\ncmake_flags = [\n    \'-DCMAKE_INSTALL_PREFIX=\' + install_dir, \'-DCMAKE_BUILD_TYPE=\' + build,\n    \'-DCMAKE_CXX_STANDARD=\' + standard\n]\ncheck_call([\'cmake\', \'-DFMT_DOC=OFF\', \'-DFMT_PEDANTIC=ON\', \'-DFMT_WERROR=ON\', fmt_dir] +\n           cmake_flags, cwd=build_dir)\n\n# Build library.\ncheck_call([\'make\', \'-j4\'], cwd=build_dir)\n\n# Test library.\nenv = os.environ.copy()\nenv[\'CTEST_OUTPUT_ON_FAILURE\'] = \'1\'\nif call([\'make\', \'test\'], env=env, cwd=build_dir):\n    with open(os.path.join(build_dir, \'Testing\', \'Temporary\', \'LastTest.log\'), \'r\') as f:\n        print(f.read())\n    sys.exit(-1)\n\n# Install library.\ncheck_call([\'make\', \'install\'], cwd=build_dir)\n\n# Test installation.\nmakedirs_if_not_exist(test_build_dir)\ncheck_call([\'cmake\', os.path.join(fmt_dir, ""test"", ""find-package-test"")] +\n            cmake_flags, cwd=test_build_dir)\ncheck_call([\'make\', \'-j4\'], cwd=test_build_dir)\n'"
extern/fmt/support/update-coverity-branch.py,0,"b""#!/usr/bin/env python\n# Update the coverity branch from the master branch.\n# It is not done automatically because Coverity Scan limits\n# the number of submissions per day.\n\nfrom __future__ import print_function\nimport shutil, tempfile\nfrom subprocess import check_output, STDOUT\n\nclass Git:\n    def __init__(self, dir):\n        self.dir = dir\n\n    def __call__(self, *args):\n        output = check_output(['git'] + list(args), cwd=self.dir, stderr=STDOUT)\n        print(output)\n        return output\n\ndir = tempfile.mkdtemp()\ntry:\n    git = Git(dir)\n    git('clone', '-b', 'coverity', 'git@github.com:fmtlib/fmt.git', dir)\n    output = git('merge', '-X', 'theirs', '--no-commit', 'origin/master')\n    if 'Fast-forward' not in output:\n        git('reset', 'HEAD', '.travis.yml')\n        git('checkout', '--', '.travis.yml')\n        git('commit', '-m', 'Update coverity branch')\n    git('push')\nfinally:\n    shutil.rmtree(dir)\n"""
extern/fmt/support/rtd/conf.py,0,"b'# Sphinx configuration for readthedocs.\n\nimport os, sys\n\nmaster_doc = \'index\'\nhtml_theme = \'theme\'\nhtml_theme_path = ["".""]\n'"
