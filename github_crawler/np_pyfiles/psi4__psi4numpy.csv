file_path,api_count,code
Configuration-Interaction/CIS.py,8,"b'""""""\nA Psi4 input script to compute CIS energy from a SCF reference\n\nReferences:\nAlgorithms were taken directly from Daniel Crawford\'s programming website:\nhttp://github.com/CrawfordGroup/ProgrammingProjects\nEquations from [Szabo:1996]\n""""""\n\n__authors__ = ""Tianyuan Zhang""\n__credits__ = [""Tianyuan Zhang"", ""Jeffrey B. Schriber"", ""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-05-26""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\n\npsi4.set_options({\'basis\': \'sto-3g\',\n                  \'scf_type\': \'pk\',\n                  \'e_convergence\': 1e-8,\n                  \'d_convergence\': 1e-8})\n\nprint(\'\\nStarting SCF and integral build...\')\nt = time.time()\n\n# First compute SCF energy using Psi4\nscf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n# Grab data from wavfunction class\nC = wfn.Ca()\nndocc = wfn.doccpi()[0]\nnmo = wfn.nmo()\nnvirt = nmo - ndocc\nnDet_S = ndocc * nvirt * 2\n\n# Compute size of SO-ERI tensor in GB\nERI_Size = (nmo**4) * 128e-9\nprint(\'\\nSize of the SO ERI tensor will be %4.2f GB.\' % ERI_Size)\nmemory_footprint = ERI_Size * 5.2\nif memory_footprint > numpy_memory:\n    clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                    limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nH = np.asarray(mints.ao_kinetic()) + np.asarray(mints.ao_potential())\n\nprint(\'\\nTotal time taken for ERI integrals: %.3f seconds.\\n\' % (time.time() - t))\n\n#Make spin-orbital MO\nprint(\'Starting AO -> spin-orbital MO transformation...\')\nt = time.time()\nMO = np.asarray(mints.mo_spin_eri(C, C))\n\n# Update H, transform to MO basis and tile for alpha/beta spin\nH = np.einsum(\'uj,vi,uv\', C, C, H)\nH = np.repeat(H, 2, axis=0)\nH = np.repeat(H, 2, axis=1)\n\n# Make H block diagonal\nspin_ind = np.arange(H.shape[0], dtype=np.int) % 2\nH *= (spin_ind.reshape(-1, 1) == spin_ind)\n\nprint(\'..finished transformation in %.3f seconds.\\n\' % (time.time() - t))\n\nfrom helper_CI import Determinant, HamiltonianGenerator\nfrom itertools import combinations\n\nprint(\'Generating %d CIS singlet Determinants...\' % (nDet_S + 1))\nt = time.time()\n\noccList = [i for i in range(ndocc)]\ndet_ref = Determinant(alphaObtList=occList, betaObtList=occList)\ndetList = det_ref.generateSingleExcitationsOfDet(nmo)\ndetList.append(det_ref)\n\nprint(\'..finished generating determinants in %.3f seconds.\\n\' % (time.time() - t))\n\nprint(\'Generating Hamiltonian Matrix...\')\n\nt = time.time()\nHamiltonian_generator = HamiltonianGenerator(H, MO)\nHamiltonian_matrix = Hamiltonian_generator.generateMatrix(detList)\n\nprint(\'..finished generating Matrix in %.3f seconds.\\n\' % (time.time() - t))\n\nprint(\'Diagonalizing Hamiltonian Matrix...\')\n\nt = time.time()\n\ne_cis, wavefunctions = np.linalg.eigh(Hamiltonian_matrix)\nprint(\'..finished diagonalization in %.3f seconds.\\n\' % (time.time() - t))\n\nprint(\'# Determinants:     % 16d\' % (len(detList)))\n\nprint(\'SCF energy:         % 16.10f\' % (scf_e))\n\nhartree2eV = 27.211\n\nprint(\'\\nCIS Excitation Energies (Singlets only):\')\nprint(\' #        Hartree                  eV\')\nprint(\'--  --------------------  --------------------\')\nfor i in range(1, len(e_cis)):\n    excit_e = e_cis[i] + mol.nuclear_repulsion_energy() - scf_e\n    print(\'%2d %20.10f %20.10f\' % (i, excit_e, excit_e * hartree2eV))\n'"
Configuration-Interaction/CISD.py,8,"b'""""""\nA Psi4 input script to compute CISD energy from a SCF reference\n\nReferences:\nEquations from [Szabo:1996]\n""""""\n\n__authors__ = ""Tianyuan Zhang""\n__credits__ = [""Tianyuan Zhang"", ""Jeffrey B. Schriber"", ""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-05-26""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Check energy against psi4?\ncompare_psi4 = True\n\n# Memory for Psi4 in GB\n# psi4.core.set_memory(int(2e9), False)\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'sto-3g\', \'scf_type\': \'pk\', \'e_convergence\': 1e-8, \'d_convergence\': 1e-8})\n\nprint(\'\\nStarting SCF and integral build...\')\nt = time.time()\n\n# First compute SCF energy using Psi4\nscf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n# Grab data from wavfunction class\nC = wfn.Ca()\nndocc = wfn.doccpi()[0]\nnmo = wfn.nmo()\nnvirt = nmo - ndocc\n\n# Compute size of Hamiltonian in GB\nfrom scipy.special import comb\nnDet_S = ndocc * nvirt * 2\nnDet_D = 2 * comb(ndocc, 2) * comb(nvirt, 2) + ndocc**2 * nvirt**2\nnDet = 1 + nDet_S + nDet_D\nH_Size = nDet**2 * 8e-9\nprint(\'\\nSize of the Hamiltonian Matrix will be %4.2f GB.\' % H_Size)\nif H_Size > numpy_memory:\n    clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                    limit of %4.2f GB."" % (H_Size, numpy_memory))\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nH = np.asarray(mints.ao_kinetic()) + np.asarray(mints.ao_potential())\n\nprint(\'\\nTotal time taken for ERI integrals: %.3f seconds.\\n\' % (time.time() - t))\n\n#Make spin-orbital MO\nprint(\'Starting AO -> spin-orbital MO transformation...\')\nt = time.time()\nMO = np.asarray(mints.mo_spin_eri(C, C))\n\n# Update H, transform to MO basis and tile for alpha/beta spin\nH = np.einsum(\'uj,vi,uv\', C, C, H)\nH = np.repeat(H, 2, axis=0)\nH = np.repeat(H, 2, axis=1)\n\n# Make H block diagonal\nspin_ind = np.arange(H.shape[0], dtype=np.int) % 2\nH *= (spin_ind.reshape(-1, 1) == spin_ind)\n\nprint(\'..finished transformation in %.3f seconds.\\n\' % (time.time() - t))\n\nfrom helper_CI import Determinant, HamiltonianGenerator\nfrom itertools import combinations\n\nprint(\'Generating %d CISD Determinants...\' % (nDet))\nt = time.time()\n\noccList = [i for i in range(ndocc)]\ndet_ref = Determinant(alphaObtList=occList, betaObtList=occList)\ndetList = det_ref.generateSingleAndDoubleExcitationsOfDet(nmo)\ndetList.append(det_ref)\n\nprint(\'..finished generating determinants in %.3f seconds.\\n\' % (time.time() - t))\n\nprint(\'Generating Hamiltonian Matrix...\')\n\nt = time.time()\nHamiltonian_generator = HamiltonianGenerator(H, MO)\nHamiltonian_matrix = Hamiltonian_generator.generateMatrix(detList)\n\nprint(\'..finished generating Matrix in %.3f seconds.\\n\' % (time.time() - t))\n\nprint(\'Diagonalizing Hamiltonian Matrix...\')\n\nt = time.time()\n\ne_cisd, wavefunctions = np.linalg.eigh(Hamiltonian_matrix)\nprint(\'..finished diagonalization in %.3f seconds.\\n\' % (time.time() - t))\n\ncisd_mol_e = e_cisd[0] + mol.nuclear_repulsion_energy()\n\nprint(\'# Determinants:      % 16d\' % (len(detList)))\n\nprint(\'SCF energy:          % 16.10f\' % (scf_e))\nprint(\'CISD correlation:    % 16.10f\' % (cisd_mol_e - scf_e))\nprint(\'Total CISD energy:   % 16.10f\' % (cisd_mol_e))\n\nif compare_psi4:\n    psi4.compare_values(psi4.energy(\'DETCI\'), cisd_mol_e, 6, \'CISD Energy\')\n'"
Configuration-Interaction/CI_DL.py,9,"b'""""""\nA Psi4 input script to compute CI energy using an iterative Davidson-Lu solver.\n\nReferences:\nEquations from [Szabo:1996]\n""""""\n\n__authors__ = ""Tianyuan Zhang""\n__credits__ = [""Tianyuan Zhang"", ""Jeffrey B. Schriber"", ""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-05-26""\n\nimport numpy as np\nimport psi4\n\nnp.set_printoptions(precision=7, linewidth=200, threshold=2000, suppress=True)\n\n# Memory for Psi4 in GB\n# psi4.core.set_memory(int(2e9), False)\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\n## Uncomment for short test\n#mol = psi4.geometry(""""""\n#0 1\n#N 0.0 0.0 0.0\n#N 1.1 0.0 0.0\n#symmetry c1\n#units angstrom\n#"""""")\n## Number of roots\n#nroot = 1\n#psi4.set_options({""BASIS"": ""STO-3G"", ""NUM_ROOTS"" : 1})\n\n## Uncomment for long test\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n # Number of roots\nnroot = 1\npsi4.set_options({""BASIS"": ""6-31g"", ""NUM_ROOTS"" : 3})\n\n# Build the SCF Wavefunction\nscf_energy, scf_wfn = psi4.energy(""HF"", return_wfn=True)\n\n# Build integrals\nmints = psi4.core.MintsHelper(scf_wfn.basisset())\n\n# Build a CI Wavefunction\n# This automatically generates the determinants based on the options\n# Note that a CISD wavefunction is default if no options are given\n# Other CI wavefunctions can be requested, e.g. { ""FCI"" : True }\npsi4.core.prepare_options_for_module(""DETCI"")\nciwfn = psi4.core.CIWavefunction(scf_wfn)\n\n# Transform the integrals\nmints.integrals()\nciwfn.transform_ci_integrals()\n\n# Get the number of determinants\nndet = ciwfn.ndet()\nprint(""Number of determinants in CI space:  %d"" % ciwfn.ndet())\n\n\n## Other options\n\n# Number of guess vectors\nguess_size = 4\n\n# Convergence tolerance of the residual norm\nctol = 1.e-5\n\n# Convergence tolerance of the energy\netol = 1.e-9\n\n# Make sure the guess is smaller than the CI space\nif guess_size > ndet:\n    raise Exception(""Number of guesses (%d)  exceeds CI dimension (%d)!"" % (guess_size, ndet))\n\nprint(\'Using %d determinants in the guess\\n\' % guess_size)\n\n# Build the Hamiltonian in the space of guess determinants\nH = np.array(ciwfn.hamiltonian(guess_size))\n\n# Get guess eigenvectors\ngvecs = []\ngevals, gevecs = np.linalg.eigh(H)\n#for x in range(nroot):\nfor x in range(guess_size):\n    guess = np.zeros((ciwfn.ndet()))\n    guess[:guess_size] = gevecs[:, x]\n    gvecs.append(guess)\n    print(\'Guess CI energy (Hsize %d)   %2.9f\' % (guess_size, gevals[x] + mol.nuclear_repulsion_energy()))\nprint("""")\n\n# Maximum number of vectors\nmax_guess = 200\n\n# Build diagonal\nHd = ciwfn.Hd_vector(5)\n\ncvecs = ciwfn.new_civector(max_guess, 200, True, True)\ncvecs.set_nvec(max_guess)\ncvecs.init_io_files(False)\n\nswork_vec = max_guess\nsvecs = ciwfn.new_civector(max_guess + 1, 201, True, True)\nsvecs.set_nvec(max_guess)\nsvecs.init_io_files(False)\n\ndwork_vec = nroot\ndvecs = ciwfn.new_civector(nroot + 1, 202, True, True)\ndvecs.init_io_files(False)\ndvecs.set_nvec(nroot + 1)\n\nfor x in range(nroot + 1):\n    dvecs.write(x, 0)\nfor x in range(max_guess):\n    svecs.write(x, 0)\nfor x in range(max_guess):\n    cvecs.write(x, 0)\n\n# Current number of vectors\nnum_vecs = guess_size\n\n# Copy gvec data into in ci_gvecs\narr_cvecs = np.asarray(cvecs)\nfor x in range(guess_size):\n    arr_cvecs[:] = gvecs[x]\n    cvecs.write(x, 0)\n    cvecs.symnormalize(1 / np.linalg.norm(gvecs[x]), x)\n\ndelta_c = np.zeros(nroot)\n\nEold = scf_energy\nG = np.zeros((max_guess, max_guess))\n\n# Begin Davidson iterations\nfor CI_ITER in range(max_guess - 1):\n\n    # Subspace Matrix, Gij = < bi | H | bj >\n    for i in range(0, num_vecs):\n        # Build sigma for each b\n        cvecs.read(i, 0)\n        svecs.read(i, 0)\n        ciwfn.sigma(cvecs, svecs, i, i)\n        for j in range(i, num_vecs):\n            # G_ij = (b_i, sigma_j)\n            cvecs.read(i, 0)\n            svecs.read(j, 0)\n            G[j, i] = G[i, j] = svecs.vdot(cvecs, i, j)\n\n    evals, evecs = np.linalg.eigh(G[:num_vecs, :num_vecs])\n    CI_E = evals\n\n    # Use average over roots as convergence criteria\n    avg_energy = 0.0\n    avg_dc = 0.0\n    for n in range(nroot):\n        avg_energy += evals[n]\n        avg_dc += delta_c[n]\n    avg_energy /= nroot\n    avg_dc /= nroot\n    avg_energy += mol.nuclear_repulsion_energy()\n\n    print(\'CI Iteration %3d: Energy = %4.16f   dE = % 1.5E   dC = %1.5E\' % (CI_ITER, avg_energy, (avg_energy - Eold),\n                                                                            avg_dc))\n    if (abs(avg_energy - Eold) < etol) and (avg_dc < ctol) and (CI_ITER > 3):\n        print(\'CI has converged!\\n\')\n        break\n    Eold = avg_energy\n\n    # Build new vectors as linear combinations of the subspace matrix, H\n    for n in range(nroot):\n\n        # Build as linear combinations of previous vectors\n        dvecs.zero()\n        dvecs.write(dwork_vec, 0)\n        for c in range(len(evecs[:, n])):\n            dvecs.axpy(evecs[c, n], cvecs, dwork_vec, c)\n\n        # Build new vector new_vec = ((H * cvec) - evals[n] * cvec) / (evals[n] - Hd)\n        ciwfn.sigma(dvecs, svecs, dwork_vec, swork_vec)\n        svecs.axpy(-1 * evals[n], dvecs, swork_vec, dwork_vec)\n        norm = svecs.dcalc(evals[n], Hd, swork_vec)\n\n        if (norm < 1e-9):\n            continue\n\n        svecs.symnormalize(1 / norm, swork_vec)\n        delta_c[n] = norm\n\n        # Build a new vector that is orthornormal to all previous vectors\n        dvecs.copy(svecs, n, swork_vec)\n        norm = dvecs.norm(n)\n        dvecs.symnormalize(1 / norm, n)\n\n        total_proj = 0\n        for i in range(num_vecs):\n            proj = svecs.vdot(cvecs, swork_vec, i)\n            total_proj += proj\n            dvecs.axpy(-proj, cvecs, n, i)\n\n        norm = dvecs.norm(n)\n        dvecs.symnormalize(1 / norm, n)\n\n        # This *should* screen out contributions that are projected out by above\n        if True:\n            cvecs.write(num_vecs, 0)\n            cvecs.copy(dvecs, num_vecs, n)\n            num_vecs += 1\n\nprint(\'SCF energy:           % 16.10f\' % (scf_energy))\nfor n in range(nroot):\n    print(\'State %d Total Energy: % 16.10f\' % (n, CI_E[n] + mol.nuclear_repulsion_energy()))\nprint("""")\n\nE = psi4.energy(\'detci\')\n\nfor n in range(nroot):\n    ci_ref = psi4.variable(\'CI ROOT %d TOTAL ENERGY\' % n)\n    ci_compute = CI_E[n] + mol.nuclear_repulsion_energy()\n    psi4.compare_values(ci_ref, ci_compute, 6, \'CI Root %d Total Energy\' % n)\n'"
Configuration-Interaction/FCI.py,8,"b'""""""\nA Psi4 input script to compute Full Configuration Interaction from a SCF reference\n\nRequirements:\nSciPy 0.13.0+, NumPy 1.7.2+\n\nReferences:\nEquations from [Szabo:1996]\n""""""\n\n__authors__ = ""Tianyuan Zhang""\n__credits__ = [""Tianyuan Zhang"", ""Jeffrey B. Schriber"", ""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-05-26""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Check energy against psi4?\ncompare_psi4 = True\n\n# Memory for Psi4 in GB\n# psi4.core.set_memory(int(2e9), False)\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\n\npsi4.set_options({\'basis\': \'sto-3g\',\n                  \'scf_type\': \'pk\',\n                  \'e_convergence\': 1e-8,\n                  \'d_convergence\': 1e-8})\n\nprint(\'\\nStarting SCF and integral build...\')\nt = time.time()\n\n# First compute SCF energy using Psi4\nscf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n# Grab data from wavfunction class\nC = wfn.Ca()\nndocc = wfn.doccpi()[0]\nnmo = wfn.nmo()\n\n# Compute size of Hamiltonian in GB\nfrom scipy.special import comb\nnDet = comb(nmo, ndocc)**2\nH_Size = nDet**2 * 8e-9\nprint(\'\\nSize of the Hamiltonian Matrix will be %4.2f GB.\' % H_Size)\nif H_Size > numpy_memory:\n    clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                    limit of %4.2f GB."" % (H_Size, numpy_memory))\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nH = np.asarray(mints.ao_kinetic()) + np.asarray(mints.ao_potential())\n\nprint(\'\\nTotal time taken for ERI integrals: %.3f seconds.\\n\' % (time.time() - t))\n\n#Make spin-orbital MO\nprint(\'Starting AO -> spin-orbital MO transformation...\')\nt = time.time()\nMO = np.asarray(mints.mo_spin_eri(C, C))\n\n# Update H, transform to MO basis and tile for alpha/beta spin\nH = np.einsum(\'uj,vi,uv\', C, C, H)\nH = np.repeat(H, 2, axis=0)\nH = np.repeat(H, 2, axis=1)\n\n# Make H block diagonal\nspin_ind = np.arange(H.shape[0], dtype=np.int) % 2\nH *= (spin_ind.reshape(-1, 1) == spin_ind)\n\nprint(\'..finished transformation in %.3f seconds.\\n\' % (time.time() - t))\n\nfrom helper_CI import Determinant, HamiltonianGenerator\nfrom itertools import combinations\n\nprint(\'Generating %d Full CI Determinants...\' % (nDet))\nt = time.time()\ndetList = []\nfor alpha in combinations(range(nmo), ndocc):\n    for beta in combinations(range(nmo), ndocc):\n        detList.append(Determinant(alphaObtList=alpha, betaObtList=beta))\n\nprint(\'..finished generating determinants in %.3f seconds.\\n\' % (time.time() - t))\n\nprint(\'Generating Hamiltonian Matrix...\')\n\nt = time.time()\nHamiltonian_generator = HamiltonianGenerator(H, MO)\nHamiltonian_matrix = Hamiltonian_generator.generateMatrix(detList)\n\nprint(\'..finished generating Matrix in %.3f seconds.\\n\' % (time.time() - t))\n\nprint(\'Diagonalizing Hamiltonian Matrix...\')\n\nt = time.time()\n\ne_fci, wavefunctions = np.linalg.eigh(Hamiltonian_matrix)\nprint(\'..finished diagonalization in %.3f seconds.\\n\' % (time.time() - t))\n\nfci_mol_e = e_fci[0] + mol.nuclear_repulsion_energy()\n\nprint(\'# Determinants:     % 16d\' % (len(detList)))\n\nprint(\'SCF energy:         % 16.10f\' % (scf_e))\nprint(\'FCI correlation:    % 16.10f\' % (fci_mol_e - scf_e))\nprint(\'Total FCI energy:   % 16.10f\' % (fci_mol_e))\n\nif compare_psi4:\n    psi4.compare_values(psi4.energy(\'FCI\'), fci_mol_e, 6, \'FCI Energy\')\n'"
Configuration-Interaction/helper_CI.py,1,"b'""""""\nHelper Classes for Configuration Interaction methods\n\nReferences:\n- Equations from [Szabo:1996]\n""""""\n\n__authors__ = ""Tianyuan Zhang""\n__credits__ = [""Tianyuan Zhang"", ""Jeffrey B. Schriber"", ""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-05-26""\n\nfrom itertools import combinations\n\n\nclass Determinant:\n    """"""\n    A class for a bit-Determinant.\n    """"""\n\n    def __init__(self, alphaObtBits=0, betaObtBits=0, alphaObtList=None, betaObtList=None):\n        """"""\n        Constructor for the Determinant\n        """"""\n\n        if alphaObtBits == 0 and alphaObtList != None:\n            alphaObtBits = Determinant.obtIndexList2ObtBits(alphaObtList)\n        if betaObtBits == 0 and betaObtList != None:\n            betaObtBits = Determinant.obtIndexList2ObtBits(betaObtList)\n        self.alphaObtBits = alphaObtBits\n        self.betaObtBits = betaObtBits\n\n    def getNumOrbitals(self):\n        """"""\n        Return the number of orbitals (alpha, beta) in this determinant\n        """"""\n\n        return Determinant.countNumOrbitalsInBits(self.alphaObtBits), Determinant.countNumOrbitalsInBits(\n            self.betaObtBits)\n\n    def getOrbitalIndexLists(self):\n        """"""\n        Return lists of orbital index\n        """"""\n\n        return Determinant.obtBits2ObtIndexList(self.alphaObtBits), Determinant.obtBits2ObtIndexList(self.betaObtBits)\n\n    def getOrbitalMixedIndexList(self):\n        """"""\n        Return lists of orbital in mixed spin index alternating alpha and beta\n        """"""\n\n        return Determinant.obtBits2ObtMixSpinIndexList(self.alphaObtBits, self.betaObtBits)\n\n    @staticmethod\n    def countNumOrbitalsInBits(bits):\n        """"""\n        Return the number of orbitals in this bits\n        """"""\n\n        count = 0\n        while bits != 0:\n            if bits & 1 == 1:\n                count += 1\n            bits >>= 1\n        return count\n\n    @staticmethod\n    def countNumOrbitalsInBitsUpTo4(bits):\n        """"""\n        Return the number of orbitals in this bits\n        """"""\n\n        count = 0\n        while bits != 0 and count < 4:\n            if bits & 1 == 1:\n                count += 1\n            bits >>= 1\n        return count\n\n    @staticmethod\n    def obtBits2ObtIndexList(bits):\n        """"""\n        Return the corresponding list of orbital numbers from orbital bits\n        """"""\n\n        i = 0\n        obts = []\n        while bits != 0:\n            if bits & 1 == 1:\n                obts.append(i)\n            bits >>= 1\n            i += 1\n        return obts\n\n    @staticmethod\n    def mixIndexList(alphaList, betaList):\n        """"""\n        Mix the alpha and beta orbital index list to one mixed list\n        """"""\n\n        return [elem * 2 for elem in alphaList] + [elem * 2 + 1 for elem in betaList]\n\n    @staticmethod\n    def obtBits2ObtMixSpinIndexList(alphaBits, betaBits):\n        """"""\n        Return the corresponding list of orbital numbers of orbital bits\n        """"""\n\n        alphaList, betaList = Determinant.obtBits2ObtIndexList(alphaBits), Determinant.obtBits2ObtIndexList(betaBits)\n        return Determinant.mixIndexList(alphaList, betaList)\n\n    @staticmethod\n    def obtIndexList2ObtBits(obtList):\n        """"""\n        Return the corresponding orbital bits of list from orbital numbers\n        """"""\n\n        if len(obtList) == 0:\n            return 0\n        obtList = sorted(obtList, reverse=True)\n        iPre = obtList[0]\n        bits = 1\n        for i in obtList:\n            bits <<= iPre - i\n            bits |= 1\n            iPre = i\n        bits <<= iPre\n        return bits\n\n    @staticmethod\n    def getOrbitalPositions(bits, orbitalIndexList):\n        """"""\n        Return the position of orbital in determinant\n        """"""\n\n        count = 0\n        index = 0\n        positions = []\n        for i in orbitalIndexList:\n            while index < i:\n                if bits & 1 == 1:\n                    count += 1\n                bits >>= 1\n                index += 1\n            positions.append(count)\n            continue\n        return positions\n\n    def getOrbitalPositionLists(self, alphaIndexList, betaIndexList):\n        """"""\n        Return the positions of indexes in lists\n        """"""\n\n        return Determinant.getOrbitalPositions(self.alphaObtBits, alphaIndexList), Determinant.getOrbitalPositions(\n            self.betaObtBits, betaIndexList)\n\n    def addAlphaOrbital(self, orbitalIndex):\n        """"""\n        Add an alpha orbital to the determinant\n        """"""\n\n        self.alphaObtBits |= 1 << orbitalIndex\n\n    def addBetaOrbital(self, orbitalIndex):\n        """"""\n        Add an beta orbital to the determinant\n        """"""\n\n        self.betaObtBits |= 1 << orbitalIndex\n\n    def removeAlphaOrbital(self, orbitalIndex):\n        """"""\n        Remove an alpha orbital from the determinant\n        """"""\n\n        self.alphaObtBits &= ~(1 << orbitalIndex)\n\n    def removeBetaOrbital(self, orbitalIndex):\n        """"""\n        Remove an beta orbital from the determinant\n        """"""\n\n        self.betaObtBits &= ~(1 << orbitalIndex)\n\n    def numberOfCommonOrbitals(self, another):\n        """"""\n        Return the number of common orbitals between this determinant and another determinant\n        """"""\n\n        return Determinant.countNumOrbitalsInBits(self.alphaObtBits &\n                                                  another.alphaObtBits), Determinant.countNumOrbitalsInBits(\n                                                      self.betaObtBits & another.betaObtBits)\n\n    def getCommonOrbitalsInLists(self, another):\n        """"""Return common orbitals between this determinant and another determinant in lists""""""\n        return Determinant.obtBits2ObtIndexList(self.alphaObtBits &\n                                                another.alphaObtBits), Determinant.obtBits2ObtIndexList(\n                                                    self.betaObtBits & another.betaObtBits)\n\n    def getCommonOrbitalsInMixedSpinIndexList(self, another):\n        alphaList, betaList = self.getCommonOrbitalsInLists(another)\n        return Determinant.mixIndexList(alphaList, betaList)\n\n    def numberOfDiffOrbitals(self, another):\n        """"""\n        Return the number of different alpha and beta orbitals between this determinant and another determinant\n        """"""\n\n        diffAlpha, diffBeta = Determinant.countNumOrbitalsInBits(\n            self.alphaObtBits ^ another.alphaObtBits), Determinant.countNumOrbitalsInBits(\n                self.betaObtBits ^ another.betaObtBits)\n        return diffAlpha / 2, diffBeta / 2\n\n    def numberOfTotalDiffOrbitals(self, another):\n        """"""\n        Return the number of different orbitals between this determinant and another determinant\n        """"""\n\n        diffAlpha, diffBeta = self.numberOfDiffOrbitals(another)\n        return diffAlpha + diffBeta\n\n    def diff2OrLessOrbitals(self, another):\n        """"""\n        Return true if two determinants differ 2 or less orbitals\n        """"""\n\n        diffAlpha, diffBeta = Determinant.countNumOrbitalsInBitsUpTo4(\n            self.alphaObtBits ^ another.alphaObtBits), Determinant.countNumOrbitalsInBitsUpTo4(\n                self.betaObtBits ^ another.betaObtBits)\n        return (diffAlpha + diffBeta) <= 4\n\n    @staticmethod\n    def uniqueOrbitalsInBits(bits1, bits2):\n        """"""\n        Return the unique bits in two different bits\n        """"""\n\n        common = bits1 & bits2\n        return bits1 ^ common, bits2 ^ common\n\n    @staticmethod\n    def uniqueOrbitalsInLists(bits1, bits2):\n        """"""\n        Return the unique bits in two different bits\n        """"""\n\n        bits1, bits2 = Determinant.uniqueOrbitalsInBits(bits1, bits2)\n        return Determinant.obtBits2ObtIndexList(bits1), Determinant.obtBits2ObtIndexList(bits2)\n\n    def getUniqueOrbitalsInLists(self, another):\n        """"""\n        Return the unique orbital lists in two different determinants\n        """"""\n\n        alphaList1, alphaList2 = Determinant.uniqueOrbitalsInLists(self.alphaObtBits, another.alphaObtBits)\n        betaList1, betaList2 = Determinant.uniqueOrbitalsInLists(self.betaObtBits, another.betaObtBits)\n        return (alphaList1, betaList1), (alphaList2, betaList2)\n\n    def getUnoccupiedOrbitalsInLists(self, nmo):\n        """"""\n        Return the unoccupied orbitals in the determinants\n        """"""\n\n        alphaBits = ~self.alphaObtBits\n        betaBits = ~self.betaObtBits\n        alphaObts = []\n        betaObts = []\n        for i in range(nmo):\n            if alphaBits & 1 == 1:\n                alphaObts.append(i)\n            alphaBits >>= 1\n            if betaBits & 1 == 1:\n                betaObts.append(i)\n            betaBits >>= 1\n        return alphaObts, betaObts\n\n    def getSignToMoveOrbitalsToTheFront(self, alphaIndexList, betaIndexList):\n        """"""\n        Return the final sign if move listed orbitals to the front\n        """"""\n\n        sign = 1\n        alphaPositions, betaPositions = self.getOrbitalPositionLists(alphaIndexList, betaIndexList)\n        for i in range(len(alphaPositions)):\n            if (alphaPositions[i] - i) % 2 == 1:\n                sign = -sign\n        for i in range(len(betaPositions)):\n            if (betaPositions[i] - i) % 2 == 1:\n                sign = -sign\n        return sign\n\n    def getUniqueOrbitalsInListsPlusSign(self, another):\n        """"""\n        Return the unique orbital lists in two different determinants and the sign of the maximum coincidence determinants\n        """"""\n\n        alphaList1, alphaList2 = Determinant.uniqueOrbitalsInLists(self.alphaObtBits, another.alphaObtBits)\n        betaList1, betaList2 = Determinant.uniqueOrbitalsInLists(self.betaObtBits, another.betaObtBits)\n        sign1, sign2 = self.getSignToMoveOrbitalsToTheFront(alphaList1,\n                                                            betaList1), another.getSignToMoveOrbitalsToTheFront(\n                                                                alphaList2, betaList2)\n        return (alphaList1, betaList1), (alphaList2, betaList2), sign1 * sign2\n\n    def getUniqueOrbitalsInMixIndexListsPlusSign(self, another):\n        """"""\n        Return the unique orbital lists in two different determinants and the sign of the maximum coincidence determinants\n        """"""\n\n        (alphaList1, betaList1), (alphaList2, betaList2), sign = self.getUniqueOrbitalsInListsPlusSign(another)\n        return Determinant.mixIndexList(alphaList1, betaList1), Determinant.mixIndexList(alphaList2, betaList2), sign\n\n    def toIntTuple(self):\n        """"""\n        Return a int tuple\n        """"""\n\n        return (self.alphaObtBits, self.betaObtBits)\n\n    @staticmethod\n    def createFromIntTuple(intTuple):\n        return Determinant(alphaObtBits=intTuple[0], betaObtBits=intTuple[1])\n\n    def generateSingleExcitationsOfDet(self, nmo):\n        """"""\n        Generate all the single excitations of determinant in a list\n        """"""\n\n        alphaO, betaO = self.getOrbitalIndexLists()\n        alphaU, betaU = self.getUnoccupiedOrbitalsInLists(nmo)\n        dets = []\n\n        for i in alphaO:\n            for j in alphaU:\n                det = self.copy()\n                det.removeAlphaOrbital(i)\n                det.addAlphaOrbital(j)\n                dets.append(det)\n\n        for k in betaO:\n            for l in betaU:\n                det = self.copy()\n                det.removeBetaOrbital(k)\n                det.addBetaOrbital(l)\n                dets.append(det)\n\n        return dets\n\n    def generateDoubleExcitationsOfDet(self, nmo):\n        """"""\n        Generate all the double excitations of determinant in a list\n        """"""\n\n        alphaO, betaO = self.getOrbitalIndexLists()\n        alphaU, betaU = self.getUnoccupiedOrbitalsInLists(nmo)\n        dets = []\n\n        for i in alphaO:\n            for j in alphaU:\n                for k in betaO:\n                    for l in betaU:\n                        det = self.copy()\n                        det.removeAlphaOrbital(i)\n                        det.addAlphaOrbital(j)\n                        det.removeBetaOrbital(k)\n                        det.addBetaOrbital(l)\n                        dets.append(det)\n\n        for i1, i2 in combinations(alphaO, 2):\n            for j1, j2 in combinations(alphaU, 2):\n                det = self.copy()\n                det.removeAlphaOrbital(i1)\n                det.addAlphaOrbital(j1)\n                det.removeAlphaOrbital(i2)\n                det.addAlphaOrbital(j2)\n                dets.append(det)\n\n        for k1, k2 in combinations(betaO, 2):\n            for l1, l2 in combinations(betaU, 2):\n                det = self.copy()\n                det.removeBetaOrbital(k1)\n                det.addBetaOrbital(l1)\n                det.removeBetaOrbital(k2)\n                det.addBetaOrbital(l2)\n                dets.append(det)\n        return dets\n\n    def generateSingleAndDoubleExcitationsOfDet(self, nmo):\n        """"""\n        Generate all the single and double excitations of determinant in a list\n        """"""\n\n        return self.generateSingleExcitationsOfDet(nmo) + self.generateDoubleExcitationsOfDet(nmo)\n\n    def copy(self):\n        """"""\n        Return a deep copy of self\n        """"""\n\n        return Determinant(alphaObtBits=self.alphaObtBits, betaObtBits=self.betaObtBits)\n\n    def __str__(self):\n        """"""\n        Print a representation of the Determinant\n        """"""\n        a, b = self.getOrbitalIndexLists()\n        return ""|"" + str(a) + str(b) + "">""\n\n\nimport numpy as np\n\n\nclass HamiltonianGenerator:\n    """"""\n    class for Full CI matrix elements\n    """"""\n\n    def __init__(self, H_spin, mo_spin_eri):\n        """"""\n        Constructor for MatrixElements\n        """"""\n\n        self.Hspin = H_spin\n        self.antiSym2eInt = mo_spin_eri\n\n    def generateMatrix(self, detList):\n        """"""\n        Generate CI Matrix\n        """"""\n\n        numDet = len(detList)\n        matrix = np.zeros((numDet, numDet))\n        for i in range(numDet):\n            for j in range(i + 1):\n                matrix[i, j] = self.calcMatrixElement(detList[i], detList[j])\n                matrix[j, i] = matrix[i, j]\n        return matrix\n\n    def calcMatrixElement(self, det1, det2):\n        """"""\n        Calculate a matrix element by two determinants\n        """"""\n\n        numUniqueOrbitals = None\n        if det1.diff2OrLessOrbitals(det2):\n            numUniqueOrbitals = det1.numberOfTotalDiffOrbitals(det2)\n            if numUniqueOrbitals == 2:\n                return self.calcMatrixElementDiffIn2(det1, det2)\n            elif numUniqueOrbitals == 1:\n                return self.calcMatrixElementDiffIn1(det1, det2)\n            else:\n                return self.calcMatrixElementIdentialDet(det1)\n        else:\n            return 0.0\n\n    def calcMatrixElementDiffIn2(self, det1, det2):\n        """"""\n        Calculate a matrix element by two determinants where the determinants differ by 2 spin orbitals\n        """"""\n\n        unique1, unique2, sign = det1.getUniqueOrbitalsInMixIndexListsPlusSign(det2)\n        return sign * self.antiSym2eInt[unique1[0], unique1[1], unique2[0], unique2[1]]\n\n    def calcMatrixElementDiffIn1(self, det1, det2):\n        """"""\n        Calculate a matrix element by two determinants where the determinants differ by 1 spin orbitals\n        """"""\n\n        unique1, unique2, sign = det1.getUniqueOrbitalsInMixIndexListsPlusSign(det2)\n        m = unique1[0]\n        p = unique2[0]\n        Helem = self.Hspin[m, p]\n        common = det1.getCommonOrbitalsInMixedSpinIndexList(det2)\n        Relem = 0.0\n        for n in common:\n            Relem += self.antiSym2eInt[m, n, p, n]\n        return sign * (Helem + Relem)\n\n    def calcMatrixElementIdentialDet(self, det):\n        """"""\n        Calculate a matrix element by two determinants where they are identical\n        """"""\n\n        spinObtList = det.getOrbitalMixedIndexList()\n        Helem = 0.0\n        for m in spinObtList:\n            Helem += self.Hspin[m, m]\n        length = len(spinObtList)\n        Relem = 0.0\n        for m in range(length - 1):\n            for n in range(m + 1, length):\n                Relem += self.antiSym2eInt[spinObtList[m], spinObtList[n], spinObtList[m], spinObtList[n]]\n        return Helem + Relem\n'"
Coupled-Electron-Pair-Approximation/DF-LCCD.py,10,"b'""""""\nComputes the Linearized CCD AKA CEPA(0) without singles, correlation energy.\nEquations taken by linearizing and density fitting Eq. 153 of [Crawford:2000:33].\n\n__authors__   =  ""Jonathon P. Misiewicz""\n__credits__   =  [""Jonathon P. Misiewicz""]\n\n__copyright__ = ""(c) 2014-2020, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n""""""\n\nimport numpy as np\nimport psi4\nfrom DSD import DirectSumDiis\nfrom integrals import integrals_DF\n\n### Settings\n\nmol = psi4.geometry(""""""\nO\nH 1 1.0\nH 1 1.0 2 104.5\nsymmetry c1"""""")\nscf_type = ""df""\ntarget_convergence = 7\nfreeze_core = True\nmaxiter = 50\ncompare_psi4 = True\nbasis = ""cc-pvdz""\n\n### Setup\npsi4.set_options({\n    ""freeze_core"": freeze_core,\n    ""scf_type"": scf_type,\n    ""e_convergence"": target_convergence + 1,\n    ""basis"": basis,\n    ""cc_type"": ""df""\n})\nR, F = integrals_DF(mol)\nFo = F[""oo""].diagonal()\nFv = F[""vv""].diagonal()\nD = Fo.reshape(-1, 1, 1, 1) + Fo.reshape(-1, 1, 1) - Fv.reshape(-1, 1) - Fv\nt2 = np.zeros(D.shape)\ndsd = DirectSumDiis(3, 8)\nnvir = len(Fv)\n\n### Main Loop\nfor i in range(1, maxiter + 1):\n\n    ### Two Electron Terms\n\n    # r2 = g^ij_ab\n    temp = np.einsum(""iaq, jbq -> ijab"", R[""ov""], R[""ov""], optimize=True)\n    r2 = temp - temp.transpose((1, 0, 2, 3))\n\n    # r2 += 0.5 g^AB_cd t^IJ_cd -> IJAB\n    # Trying to do this computation by direct einsum leads to reassembling the full VVVV block of integrals.\n    # We would rather not store a V^4 intermediate in memory if we can avoid it.\n    # Accordingly, we loop over a V index.\n    for A in range(nvir):\n        temp = np.einsum(""cq, Bdq, IJcd -> IJB"", R[""vv""][A], R[""vv""], t2, optimize=True)\n        r2[:, :, A, :] += temp\n\n    # r2 += 0.5 g^kl_IJ t^kl_AB\n    r2 += np.einsum(""kIq, lJq, klAB -> IJAB"", R[""oo""], R[""oo""], t2, optimize=True)\n\n    # r2 += g^AkIc t^JkBc -> IJAB\n    temp = np.einsum(""IAq, kcq, JkBc -> IJAB"", R[""ov""], R[""ov""], t2, optimize=True)\n    temp -= np.einsum(""kIq, Acq, JkBc -> IJAB"", R[""oo""], R[""vv""], t2, optimize=True)\n    r2 += temp + temp.transpose((1, 0, 3, 2)) - temp.transpose((0, 1, 3, 2)) - temp.transpose((1, 0, 2, 3))\n\n    ### One Electron Terms. For canonical orbitals, this will reduce to -t2, after dividing by D\n    temp = -np.einsum(""Ii, iJAB -> IJAB"", F[""oo""], t2, optimize=True)\n    r2 += temp - temp.transpose((1, 0, 2, 3))\n    temp = +np.einsum(""aA, IJaB -> IJAB"", F[""vv""], t2, optimize=True)\n    r2 += temp - temp.transpose((0, 1, 3, 2))\n\n    ### Step\n    t2 += r2 / D\n    t2 = dsd.diis(r2, t2)\n    r_norm = np.linalg.norm(r2)\n    Elccd = 0.5 * np.einsum(""iaq, jbq, ijab"", R[""ov""], R[""ov""], t2, optimize=True)\n    print(f""{i:3d} E={Elccd:3.10f} R = {r_norm:0.8f}"")\n    if r_norm < float(f""1e-{target_convergence}""):\n        break\nelse:\n    raise Exception(""Equations did not converge."")\n\nif compare_psi4:\n    wfn = psi4.energy(""lccd"", return_wfn=True)[1]\n\n    # Change to wfn.variable when DFOCC variables are available on the wfn.\n    psi4.compare_values(psi4.variable(""CURRENT CORRELATION ENERGY""), Elccd, target_convergence, ""LCCD Energy"")\n'"
Coupled-Electron-Pair-Approximation/DF-LCCSD.py,20,"b'""""""\nComputes the Linearized CCSD AKA CEPA(0) with singles, correlation energy.\nEquations taken by linearizing and density fitting Eq. 152 and 153 of [Crawford:2000:33].\n\n__authors__   =  ""Jonathon P. Misiewicz""\n__credits__   =  [""Jonathon P. Misiewicz""]\n\n__copyright__ = ""(c) 2014-2020, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n""""""\n\nimport numpy as np\nimport psi4\nfrom DSD import DirectSumDiis\nfrom integrals import integrals_DF\n\n### Settings\n\nmol = psi4.geometry(""""""\nO\nH 1 1.0\nH 1 1.0 2 104.5\nsymmetry c1"""""")\nscf_type = ""df""\ntarget_convergence = 7\nfreeze_core = True\nmaxiter = 50\ncompare_psi4 = True\nbasis = ""cc-pvdz""\n\n### Setup\npsi4.set_options({\n    ""freeze_core"": freeze_core,\n    ""scf_type"": scf_type,\n    ""e_convergence"": target_convergence + 1,\n    ""basis"": basis,\n    ""cc_type"": ""df""\n})\nR, F = integrals_DF(mol, singles=True)\nFo = F[""oo""].diagonal()\nFv = F[""vv""].diagonal()\nD1 = Fo.reshape(-1, 1) - Fv\nD2 = Fo.reshape(-1, 1, 1, 1) + Fo.reshape(-1, 1, 1) - Fv.reshape(-1, 1) - Fv\nt1 = np.zeros(D1.shape)\nt2 = np.zeros(D2.shape)\ndsd = DirectSumDiis(3, 8)\nnvir = len(Fv)\n\n### Main Loop\nfor i in range(1, maxiter + 1):\n\n    ### R1: Two Electron Terms\n    # r1 = 0.5 g^iA_ab t^iI_ab\n    r1 = np.einsum(""iaq, Abq, iIab -> IA"", R[""ov""], R[""vv""], t2, optimize=True)\n\n    # r1 -= 0.5 * g^jk_Ia t^jk_Aa\n    r1 -= np.einsum(""jIq, kaq, jkAa -> IA"", R[""oo""], R[""ov""], t2, optimize=True)\n\n    # r1 = g^aI_iA t^i_a\n    r1 += np.einsum(""iaq, IAq, ia -> IA"", R[""ov""], R[""ov""], t1, optimize=True)\n    r1 -= np.einsum(""aAq, Iiq, ia -> IA"", R[""vv""], R[""oo""], t1, optimize=True)\n\n    ### R1: One Electron Terms\n    r1 += 0.5 * np.einsum(""ia, IiAa -> IA"", F[""ov""], t2, optimize=True)\n    r1 += F[""ov""] # This term is zero by Brillouin\'s Theorem for UHF or closed-shell RHF references\n    # For canonical orbtials, these next terms will reduce to -t1, after dividing by D1\n    r1 += np.einsum(""aA, Ia -> IA"", F[""vv""], t1, optimize=True)\n    r1 -= np.einsum(""Ii, iA -> IA"", F[""oo""], t1, optimize=True)\n\n    ### R2: Two Electron Terms\n\n    # r2 = g^ij_ab\n    temp = np.einsum(""iaq, jbq -> ijab"", R[""ov""], R[""ov""], optimize=True)\n    r2 = temp - temp.transpose((1, 0, 2, 3))\n\n    # r2 += 0.5 g^AB_cd t^IJ_cd -> IJAB\n    # Trying to do this computation by direct einsum leads to reassembling the full VVVV block of integrals.\n    # We would rather not store a V^4 intermediate in memory if we can avoid it.\n    # Accordingly, we loop over a V index.\n    for A in range(nvir):\n        temp = np.einsum(""cq, Bdq, IJcd -> IJB"", R[""vv""][A], R[""vv""], t2, optimize=True)\n        r2[:, :, A, :] += temp\n\n    # r2 += 0.5 g^kl_IJ t^kl_AB\n    r2 += np.einsum(""kIq, lJq, klAB -> IJAB"", R[""oo""], R[""oo""], t2, optimize=True)\n\n    # r2 += P(IJ/AB) g^AkIc t^JkBc -> IJAB\n    temp = np.einsum(""IAq, kcq, JkBc -> IJAB"", R[""ov""], R[""ov""], t2, optimize=True)\n    temp -= np.einsum(""kIq, Acq, JkBc -> IJAB"", R[""oo""], R[""vv""], t2, optimize=True)\n    r2 += temp + temp.transpose((1, 0, 3, 2)) - temp.transpose((0, 1, 3, 2)) - temp.transpose((1, 0, 2, 3))\n\n    ### R2: One Electron Terms. For canonical orbitals, this will reduce to -t2, after dividing by D\n    temp = -np.einsum(""Ii, iJAB -> IJAB"", F[""oo""], t2, optimize=True)\n    r2 += temp - temp.transpose((1, 0, 2, 3))\n    temp = +np.einsum(""aA, IJaB -> IJAB"", F[""vv""], t2, optimize=True)\n    r2 += temp - temp.transpose((0, 1, 3, 2))\n\n    ### R2: Singles Terms. These are new compared to LCCD.\n    # r2 += P(IJ) g^IaAB t^J_a\n    temp = + np.einsum(""IAq, aBq, Ja -> IJAB"", R[""ov""], R[""vv""], t1, optimize=True)\n    r2 += temp - temp.transpose((1, 0, 2, 3)) - temp.transpose((0, 1, 3, 2)) + temp.transpose((1, 0, 3, 2))\n\n    # r2 += P(AB) g^IJ_iB t^i_A\n    temp = - np.einsum(""Iiq, JBq, iA -> IJAB"", R[""oo""], R[""ov""], t1, optimize=True)\n    r2 += temp - temp.transpose((0, 1, 3, 2)) - temp.transpose((1, 0, 2, 3)) + temp.transpose((1, 0, 3, 2))\n\n    ### Step\n    t1 += r1 / D1\n    t2 += r2 / D2\n    t2, t1 = dsd.diis([r2, r1], [t2, t1])\n    r_norm = np.sqrt(np.linalg.norm(r2) ** 2 + np.linalg.norm(r1) ** 2)\n    Elccsd = 0.5 * np.einsum(""iaq, jbq, ijab"", R[""ov""], R[""ov""], t2, optimize=True) + np.sum(F[""ov""] * t1)\n    print(f""{i:3d} E={Elccsd:3.10f} R = {r_norm:0.8f}"")\n    if r_norm < float(f""1e-{target_convergence}""):\n        break\nelse:\n    raise Exception(""Equations did not converge."")\n\nif compare_psi4:\n    # Psi doesn\'t currently have DF-LCCSD implemented, so no test against Psi is possible.\n    psi4.compare_values(-0.217981606, Elccsd, target_convergence, ""LCCSD Energy"")\n'"
Coupled-Electron-Pair-Approximation/DSD.py,17,"b'""""""\nClass to perform DIIS extrapolation on a sum of vectors.\n- DIIS equations & algorithms from [Sherrill:1998], [Pulay:1980:393], & [Pulay:1969:197]\n\n__authors__   =  ""Jonathon P. Misiewicz""\n__credits__   =  [""Jonathon P. Misiewicz""]\n\n__copyright__ = ""(c) 2014-2020, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n""""""\n\nimport functools\nimport itertools\nimport numpy as np\n\nclass DirectSumDiis():\n    """"""\n    A class used to perform a DIIS extrapolation on a single vector or a list of vectors.\n    If a list is given, DirectSumDiis will DIIS extrapolate the direct sum of the vectors.\n    """"""\n\n    def __init__(self, min_diis_vecs, max_diis_vecs):\n        """"""\n        Parameters\n        ----------\n        min_diis_vecs : int\n            What is the minimum number of DIIS vectors to use? Any lower, and we don\'t extrapolate.\n        max_diis_vecs : int\n            What is the maximum number of DIIS vectors to use? Any more, and we throw out the oldest.\n        """"""\n        self.min = min_diis_vecs\n        self.max = max_diis_vecs\n        self.residuals = []\n        self.trials = []\n\n    def diis(self, r, t): \n        """"""\n        Perform a DIIS extrapolation. r, t, and t_new should always have the same number of elements,\n        if given as lists.\n\n        Parameters\n        ----------\n        r : np.ndarray or list of np.ndarray\n            The residual vector(s) of the latest iteration.\n        t : np.ndarray or list of np.ndarray\n            The amplitude vector(s) of the latest iteration.\n\n        Returns\n        -------\n        t_new : np.ndarray or list of np.ndarray\n            The new amplitude vector(s) after DIIS extrapolation.\n        """""" \n\n        self.residuals.append(copier(r))\n        self.trials.append(copier(t))\n        if len(self.residuals) > self.max:\n            # Too many DIIS vectors! Get rid of the last one.\n            self.residuals.pop(0)\n            self.trials.pop(0)\n        if len(self.residuals) >= self.min:\n            # We have enough DIIS vectors to extrapolate.\n            B_dim = 1 + len(self.residuals)\n            B = np.empty((B_dim, B_dim))\n            B[-1, :] = B[:, -1] = -1\n            B[-1, -1] = 0 \n            for i, ri in enumerate(self.residuals):\n                for j, rj in enumerate(self.residuals):\n                    if i > j: continue\n                    B[i, j] = B[j, i] = direct_sum_dot(ri, rj) \n            # Normalize the B matrix to improve convergence\n            B[:-1, :-1] /= np.abs(B[:-1, :-1]).max()\n            rhs = np.zeros((B_dim))\n            rhs[-1] = -1\n            coeffs = np.linalg.solve(B, rhs)[:-1]\n            # Return the desired linear combination of trial vectors.\n            trials_to_new = functools.partial(np.tensordot, b=coeffs, axes=(0,0))\n            if isinstance(self.trials[0], np.ndarray):\n                # Case: The user passed in and expects back a single array.\n                return trials_to_new(self.trials)\n            else:\n                # Case: The user passed in and expects back a list of vectors.\n                return list(map(trials_to_new, zip(*self.trials)))\n        else:\n            # Not enough DIIS vectors to extrapolate! Don\'t change the last one.\n            return t\n\ndef copier(obj):\n    """"""\n    Given an np.ndarray or list of them, return copies of them.\n\n    Parameters\n    ----------\n    obj : np.ndarray or list of np.ndarray\n\n    Returns\n    -------\n    copy : np.ndarray or list of np.ndarray\n    """"""\n\n    return [i.copy() for i in obj] if not isinstance(obj, np.ndarray) else obj.copy()\n\ndef direct_sum_dot(r1, r2):\n    """"""\n    Parameters\n    ----------\n    r1, r2 : np.ndarray or list of np.ndarray\n        The vectors or lists of vectors to compute the dot product of.\n\n    Returns\n    -------\n    value : int\n        The sum of the dot product for each vector in the list\n    """"""\n    if not isinstance(r1, np.ndarray):\n        # Sum the dot product of each vector space in our direct sum.\n        return sum(itertools.starmap(np.vdot, zip(r1, r2)))\n    else:\n        # There\'s only one vector space in our direct sum. Dot product away.\n        return np.vdot(r1, r2)\n'"
Coupled-Electron-Pair-Approximation/LCCD.py,8,"b'""""""\nComputes the Linearized CCD AKA CEPA(0) without singles, correlation energy.\nEquations taken by linearizing Eq. 153 of [Crawford:2000:33].\n\n__authors__   =  ""Jonathon P. Misiewicz""\n__credits__   =  [""Jonathon P. Misiewicz""]\n\n__copyright__ = ""(c) 2014-2020, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n""""""\n\nimport numpy as np\nimport psi4\nfrom DSD import DirectSumDiis\nfrom integrals import integrals\n\n### Settings\n\nmol = psi4.geometry(""""""\nO\nH 1 1.0\nH 1 1.0 2 104.5\nsymmetry c1"""""")\nscf_type = ""pk""\ntarget_convergence = 7\nfreeze_core = True\nmaxiter = 50\ncompare_psi4 = True\nbasis = ""cc-pvdz""\n\n### Setup\npsi4.set_options({""freeze_core"": freeze_core, ""scf_type"": scf_type, ""e_convergence"": target_convergence + 1, ""basis"": basis})\nI, F = integrals(mol)\nt2 = np.zeros(I[""oovv""].shape)\nFo = F[""oo""].diagonal()\nFv = F[""vv""].diagonal()\nD = Fo.reshape(-1, 1, 1, 1) + Fo.reshape(-1, 1, 1) - Fv.reshape(-1, 1) - Fv\ndsd = DirectSumDiis(3, 8)\n\n### Main Loop\nfor i in range(1, maxiter + 1):\n    # Two Electron Terms\n    r2 = I[""oovv""] + 0.5 * np.einsum(""ABcd, IJcd -> IJAB"", I[""vvvv""], t2, optimize=True)\n    r2 += 0.5 * np.einsum(""klIJ, klAB -> IJAB"", I[""oooo""], t2, optimize=True)\n    temp = np.einsum(""AkIc, JkBc -> IJAB"", I[""voov""], t2, optimize=True)\n    r2 += temp + temp.transpose((1, 0, 3, 2)) - temp.transpose((0, 1, 3, 2)) - temp.transpose((1, 0, 2, 3))\n    # One Electron Terms. For canonical orbitals, this will reduce to -t2, after dividing by D\n    temp = - np.einsum(""Ii, iJAB -> IJAB"", F[""oo""], t2, optimize=True)\n    r2 += temp - temp.transpose((1, 0, 2, 3))\n    temp = + np.einsum(""aA, IJaB -> IJAB"", F[""vv""], t2, optimize=True)\n    r2 += temp - temp.transpose((0, 1, 3, 2))\n    # Step\n    t2 += r2 / D\n    t2 = dsd.diis(r2, t2)\n    r_norm = np.linalg.norm(r2)\n    Elccd = 0.25 * np.sum(I[""oovv""] * t2)\n    print(f""{i:3d} E={Elccd:3.10f} R = {r_norm:0.8f}"")\n    if r_norm < float(f""1e-{target_convergence}""):\n        break\nelse:\n    raise Exception(""Equations did not converge."")\n\nif compare_psi4:\n   wfn = psi4.energy(""lccd"", return_wfn=True)[1]\n   psi4.compare_values(psi4.variable(""CURRENT CORRELATION ENERGY""), Elccd, target_convergence, ""LCCD Energy"")\n'"
Coupled-Electron-Pair-Approximation/LCCSD.py,17,"b'""""""\nComputes the Linearized CCSD AKA CEPA(0) with singles, correlation energy.\nEquations taken by linearizing Eq. 152 and 153 of [Crawford:2000:33].\n\n__authors__   =  ""Jonathon P. Misiewicz""\n__credits__   =  [""Jonathon P. Misiewicz""]\n\n__copyright__ = ""(c) 2014-2020, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n""""""\n\nimport numpy as np\nimport psi4\nfrom DSD import DirectSumDiis\nfrom integrals import integrals\n\n### Settings\n\nmol = psi4.geometry(""""""\nO\nH 1 1.0\nH 1 1.0 2 104.5\nsymmetry c1"""""")\nscf_type = ""pk""\ntarget_convergence = 7\nfreeze_core = True\nmaxiter = 50\ncompare_psi4 = True\nbasis = ""cc-pvdz""\n\n### Setup\npsi4.set_options({""freeze_core"": freeze_core, ""scf_type"": scf_type, ""e_convergence"": target_convergence + 1, ""basis"": basis})\nI, F = integrals(mol, singles=True)\nt1 = np.zeros(F[""ov""].shape)\nt2 = np.zeros(I[""oovv""].shape)\nFo = F[""oo""].diagonal()\nFv = F[""vv""].diagonal()\nD1 = Fo.reshape(-1, 1) - Fv\nD2 = Fo.reshape(-1, 1, 1, 1) + Fo.reshape(-1, 1, 1) - Fv.reshape(-1, 1) - Fv\ndsd = DirectSumDiis(3, 8)\n\n### Main Loop\nfor i in range(1, maxiter + 1):\n    ### R1\n    ## Two Electron Terms\n    r1 = 0.5 * np.einsum(""iAab, iIab -> IA"", I[""ovvv""], t2, optimize=True)\n    r1 -= 0.5 * np.einsum(""jkIa, jkAa -> IA"", I[""ooov""], t2, optimize=True)\n    r1 += np.einsum(""aIiA, ia -> IA"", I[""voov""], t1, optimize=True)\n    ## One Electron Terms\n    r1 += 0.5 * np.einsum(""ia, IiAa -> IA"", F[""ov""], t2, optimize=True)\n    r1 += F[""ov""] # This term is zero by Brillouin\'s Theorem for UHF or closed-shell RHF references\n    # For canonical orbtials, these next terms will reduce to -t1, after dividing by D1\n    r1 += np.einsum(""aA, Ia -> IA"", F[""vv""], t1, optimize=True)\n    r1 -= np.einsum(""Ii, iA -> IA"", F[""oo""], t1, optimize=True)\n\n    ### R2\n    # Two Electron Terms\n    r2 = I[""oovv""] + 0.5 * np.einsum(""ABcd, IJcd -> IJAB"", I[""vvvv""], t2, optimize=True)\n    r2 += 0.5 * np.einsum(""klIJ, klAB -> IJAB"", I[""oooo""], t2, optimize=True)\n    temp = np.einsum(""AkIc, JkBc -> IJAB"", I[""voov""], t2, optimize=True)\n    r2 += temp + temp.transpose((1, 0, 3, 2)) - temp.transpose((0, 1, 3, 2)) - temp.transpose((1, 0, 2, 3))\n    # One Electron Terms. For canonical orbitals, this will reduce to -t2, after dividing by D2\n    temp = - np.einsum(""Ii, iJAB -> IJAB"", F[""oo""], t2, optimize=True)\n    r2 += temp - temp.transpose((1, 0, 2, 3))\n    temp = + np.einsum(""aA, IJaB -> IJAB"", F[""vv""], t2, optimize=True)\n    r2 += temp - temp.transpose((0, 1, 3, 2))\n    # Singles Terms: New compared to LCCD\n    temp = + np.einsum(""IaAB, Ja -> IJAB"", I[""ovvv""], t1, optimize=True)\n    r2 += temp - temp.transpose((1, 0, 2, 3))\n    temp = - np.einsum(""IJiB, iA -> IJAB"", I[""ooov""], t1, optimize=True)\n    r2 += temp - temp.transpose((0, 1, 3, 2))\n\n    ### Step\n    t1 += r1 / D1\n    t2 += r2 / D2\n    t2, t1 = dsd.diis([r2, r1], [t2, t1])\n    r_norm = np.sqrt(np.linalg.norm(r2) ** 2 + np.linalg.norm(r1) ** 2)\n    # We linearize the singles in the energy function as well. See eq. 12 of [Taube:2009:144112].\n    # For canonical orbitals, F_ia vanishes, so some quantum chemistry codes (Psi4\'s `fnocc`) neglect it.\n    Elccsd = 0.25 * np.sum(I[""oovv""] * t2) + np.sum(F[""ov""] * t1) \n    print(f""{i:3d} E={Elccsd:3.10f} R = {r_norm:0.8f}"")\n    if r_norm < float(f""1e-{target_convergence}""):\n        break\nelse:\n    raise Exception(""Equations did not converge."")\n\nif compare_psi4:\n   wfn = psi4.energy(""lccsd"", return_wfn=True)[1]\n   psi4.compare_values(psi4.variable(""CURRENT CORRELATION ENERGY""), Elccsd, target_convergence, ""LCCSD Energy"")\n'"
Coupled-Electron-Pair-Approximation/OLCCD.py,47,"b'""""""\nComputes the Orbital-Optimized LCCD correlation energy.\nEquations taken from [Bozkaya:2013:054104].\n\n__authors__   =  ""Jonathon P. Misiewicz""\n__credits__   =  [""Jonathon P. Misiewicz""]\n\n__copyright__ = ""(c) 2014-2020, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n""""""\n\nimport numpy as np\nimport psi4\nfrom scipy import linalg as spla\nfrom DSD import DirectSumDiis\nfrom integrals import integrals\n\n### Settings\n\nmol = psi4.geometry(""""""\nO\nH 1 1.0\nH 1 1.0 2 104.5\nsymmetry c1"""""")\nscf_type = ""pk""\ntarget_convergence = 7\nmaxiter = 50\ncompare_psi4 = True\nbasis = ""cc-pvdz""\n\n### Setup\npsi4.set_options({""scf_type"": scf_type, ""e_convergence"": target_convergence + 1, ""basis"": basis})\nI, F, intermed = integrals(mol, singles=True, return_intermediates=True)\nt1 = np.zeros(F[""ov""].shape)\nt2 = np.zeros(I[""oovv""].shape)\ndsd = DirectSumDiis(3, 8)\nnum_occ, num_vir = t1.shape\n\n# We need the initial one-electron integrals as well for orbital-optimized methods.\n# The orbital gradient expression requires these instead of the Fock integrals that our amplitude expressions need.\nH = {\n    ""oo"": np.einsum(\'pP, qQ, pq -> PQ\', intermed[""O""], intermed[""O""], intermed[""OEI""], optimize = True),\n    ""ov"": np.einsum(\'pP, qQ, pq -> PQ\', intermed[""O""], intermed[""V""], intermed[""OEI""], optimize = True),\n    ""vv"": np.einsum(\'pP, qQ, pq -> PQ\', intermed[""V""], intermed[""V""], intermed[""OEI""], optimize = True)\n    }\nEscf = mol.nuclear_repulsion_energy() + np.trace(H[""oo""]) + 0.5 * np.einsum(""ijij ->"", I[""oooo""], optimize = True)\n\n### Main Loop\nfor i in range(1, maxiter + 1):\n\n    if i != 1:\n        # Compute new orbitals and transform into them. See Section IIA5 of Bozkaya.\n        Zoo = np.zeros((num_occ, num_occ))\n        Zvv = np.zeros((num_vir, num_vir))\n        X = np.block([[Zoo, -t1],\n                     [t1.T, Zvv]])\n        U = spla.expm(X)\n        C = np.hstack((intermed[""O""], intermed[""V""]))\n        C = C @ U\n        C_O, C_V = np.hsplit(C, [num_occ])\n        I = {\n            ""oovv"": np.einsum(\'pP,qQ,rR,sS,pqrs->PQRS\', C_O, C_O, C_V, C_V, intermed[""TEI""], optimize = True),\n            ""oooo"": np.einsum(\'pP,qQ,rR,sS,pqrs->PQRS\', C_O, C_O, C_O, C_O, intermed[""TEI""], optimize = True),\n            ""voov"": np.einsum(\'pP,qQ,rR,sS,pqrs->PQRS\', C_V, C_O, C_O, C_V, intermed[""TEI""], optimize = True),\n            ""vvvv"": np.einsum(\'pP,qQ,rR,sS,pqrs->PQRS\', C_V, C_V, C_V, C_V, intermed[""TEI""], optimize = True),\n            ""ovvv"": np.einsum(\'pP,qQ,rR,sS,pqrs->PQRS\', C_O, C_V, C_V, C_V, intermed[""TEI""], optimize = True),\n            ""ooov"": np.einsum(\'pP,qQ,rR,sS,pqrs->PQRS\', C_O, C_O, C_O, C_V, intermed[""TEI""], optimize = True)\n            }\n        H = {\n            ""oo"": np.einsum(\'pP, qQ, pq -> PQ\', C_O, C_O, intermed[""OEI""], optimize = True),\n            ""ov"": np.einsum(\'pP, qQ, pq -> PQ\', C_O, C_V, intermed[""OEI""], optimize = True),\n            ""vv"": np.einsum(\'pP, qQ, pq -> PQ\', C_V, C_V, intermed[""OEI""], optimize = True)\n            }\n        F = {\n            ""oo"": H[""oo""] + np.einsum(\'iP iQ -> PQ\', I[""oooo""], optimize = True),\n            ""ov"": H[""ov""] + np.einsum(\'iP iQ -> PQ\', I[""ooov""], optimize = True),\n            ""vv"": H[""vv""] - np.einsum(\'Pi iQ -> PQ\', I[""voov""], optimize = True)\n            }\n\n    Fo = F[""oo""].diagonal()\n    Fv = F[""vv""].diagonal()\n    D1 = Fo.reshape(-1, 1) - Fv\n    D2 = Fo.reshape(-1, 1, 1, 1) + Fo.reshape(-1, 1, 1) - Fv.reshape(-1, 1) - Fv\n\n    ### Construct reduced density matrices. Eq. 24 is always relevant.\n    scf_opdm = np.eye(*F[""oo""].shape) # Eq. 25\n    opdm_oo_corr = - 0.5 * np.einsum(""Ik ab,Jk ab->IJ"", t2, t2, optimize=True) # Eq. 29\n    opdm_oo = scf_opdm + opdm_oo_corr # OO block of eq. 23\n    opdm_vv = + 0.5 * np.einsum(""ij Ac,ij Bc->AB"", t2, t2, optimize=True) # Eq. 30\n    tpdm_oovv = t2.copy() # Eq. 34\n    tpdm_vvvv = 0.5 * np.einsum(""ijCD, ijAB -> ABCD"", t2, t2, optimize=True) # Eq. 32\n    tpdm_oooo = 0.5 * np.einsum(""IJab, KLab -> IJKL"", t2, t2, optimize=True) # Eq. 31\n    # Eq. 24\n    temp = np.einsum(""p r, q s -> pqrs"", scf_opdm, opdm_oo_corr, optimize=True)\n    tpdm_oooo += temp + temp.transpose((1, 0, 3, 2)) - temp.transpose((1, 0, 2, 3)) - temp.transpose((0, 1, 3, 2))\n    # Eq. 26\n    temp = np.einsum(""pr, qs -> pqrs"", scf_opdm, scf_opdm, optimize=True)\n    tpdm_oooo += temp - temp.transpose((0, 1, 3, 2))\n    # Eq. 33\n    tpdm_ovov = - np.einsum(""IiBa, JiAa -> IAJB"", t2, t2, optimize=True) + np.einsum(""p r, q s -> pqrs"", scf_opdm, opdm_vv, optimize=True)\n\n    # Expand out eq. 37. We use Fock matrix elements for convenience. \n    r1 = np.einsum(""iA, Ii -> IA"", H[""ov""], opdm_oo)\n    r1 -= np.einsum(""Ia, aA -> IA"", H[""ov""], opdm_vv)\n    r1 -= 0.5 * np.einsum(""jkiA, Iijk -> IA"", I[""ooov""], tpdm_oooo)\n    r1 -= 0.5 * np.einsum(""iAab, Iiab -> IA"", I[""ovvv""], tpdm_oovv)\n    r1 += np.einsum(""ibAa, Iaib -> IA"", I[""ovvv""], tpdm_ovov)\n    r1 -= 0.5 * np.einsum(""Iabc, Aabc -> IA"", I[""ovvv""], tpdm_vvvv)\n    r1 -= 0.5 * np.einsum(""ijIa, ijAa -> IA"", I[""ooov""], tpdm_oovv)\n    r1 -= np.einsum(""iIja, iAja -> IA"", I[""ooov""], tpdm_ovov)\n    t1 += r1 / D1\n\n    ### Construct T2 residual and step; Eq. 5\n    # Two Electron Terms\n    r2 = I[""oovv""] + 0.5 * np.einsum(""ABcd, IJcd -> IJAB"", I[""vvvv""], t2, optimize=True)\n    r2 += 0.5 * np.einsum(""klIJ, klAB -> IJAB"", I[""oooo""], t2, optimize=True)\n    temp = np.einsum(""AkIc, JkBc -> IJAB"", I[""voov""], t2, optimize=True)\n    r2 += temp + temp.transpose((1, 0, 3, 2)) - temp.transpose((0, 1, 3, 2)) - temp.transpose((1, 0, 2, 3))\n    # One Electron Terms. For canonical orbitals, this will reduce to -t2, after dividing by D\n    temp = - np.einsum(""Ii, iJAB -> IJAB"", F[""oo""], t2, optimize=True)\n    r2 += temp - temp.transpose((1, 0, 2, 3))\n    temp = + np.einsum(""aA, IJaB -> IJAB"", F[""vv""], t2, optimize=True)\n    r2 += temp - temp.transpose((0, 1, 3, 2))\n    # Step\n    t2 += r2 / D2\n\n    ### DIIS and Print\n    t2, t1 = dsd.diis([r2, r1], [t2, t1])\n    r_norm = np.sqrt(np.linalg.norm(r2) ** 2 + np.linalg.norm(r1) ** 2)\n    Eref = mol.nuclear_repulsion_energy() + np.trace(H[""oo""]) + 0.5 * np.einsum(""ijij ->"", I[""oooo""], optimize = True)\n    Eolccd = 0.25 * np.sum(I[""oovv""] * t2) + Eref - Escf\n    print(f""{i:3d} E={Eolccd:3.10f} R = {r_norm:0.8f}"")\n    if r_norm < float(f""1e-{target_convergence}""):\n        break\nelse:\n    raise Exception(""Equations did not converge."")\n\nif compare_psi4:\n   wfn = psi4.energy(""olccd"", return_wfn=True)[1]\n   psi4.compare_values(psi4.variable(""CURRENT CORRELATION ENERGY""), Eolccd, target_convergence, ""OLCCD Energy"")\n'"
Coupled-Electron-Pair-Approximation/integrals.py,21,"b'""""""\nReturns the Fock matrix and needed two-electron integral blocks.\n\n__authors__   =  ""Jonathon P. Misiewicz""\n__credits__   =  [""Jonathon P. Misiewicz""]\n\n__copyright__ = ""(c) 2014-2020, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n""""""\n\nimport numpy as np\nimport psi4\n\n\ndef orbitals_fock(mol, singles):\n    wfn = psi4.energy(\'scf\', molecule=mol, return_wfn=True)[1]\n\n    ### Orbitals\n    CA_O = wfn.Ca_subset(""AO"", ""ACTIVE_OCC"")\n    CB_O = wfn.Cb_subset(""AO"", ""ACTIVE_OCC"")\n    C_O = np.block([[CA_O, np.zeros(CB_O.shape)], [np.zeros(CA_O.shape), CB_O]])\n    CA_V = wfn.Ca_subset(""AO"", ""ACTIVE_VIR"")\n    CB_V = wfn.Cb_subset(""AO"", ""ACTIVE_VIR"")\n    C_V = np.block([[CA_V, np.zeros(CB_V.shape)], [np.zeros(CA_V.shape), CB_V]])\n    mints = psi4.core.MintsHelper(wfn.basisset())\n\n    ### One-Electron Integrals\n    Fa = wfn.Fa()\n    Fb = wfn.Fb()\n    FI = np.block([[Fa, np.zeros(Fb.shape)], [np.zeros(Fa.shape), Fb]])\n    F = {\n        ""oo"": np.einsum(\'pP,qQ,pq->PQ\', C_O, C_O, FI, optimize=True),\n        ""vv"": np.einsum(\'pP,qQ,pq->PQ\', C_V, C_V, FI, optimize=True)\n    }\n    if singles:\n        F[""ov""] = np.einsum(\'pP, qQ, pq -> PQ\', C_O, C_V, FI, optimize=True)\n\n    return C_O, C_V, mints, F\n\n\ndef integrals(mol, singles=False, return_intermediates=False):\n\n    C_O, C_V, mints, F = orbitals_fock(mol, singles)\n\n    ### Two-Electron Integrals\n    TEI = mints.ao_eri().np\n    # Construct electron-repulsion integrals in spinorbital basis from spatial orbital basis.\n    TEI = np.kron(np.eye(2), np.kron(np.eye(2), TEI).T)\n    # Transform integrals to physicist notation\n    TEI = TEI.swapaxes(1, 2)\n    # Antisymmetrize...\n    TEI -= TEI.swapaxes(2, 3)\n    I = {\n        ""oovv"": np.einsum(\'pP,qQ,rR,sS,pqrs->PQRS\', C_O, C_O, C_V, C_V, TEI, optimize=True),\n        ""oooo"": np.einsum(\'pP,qQ,rR,sS,pqrs->PQRS\', C_O, C_O, C_O, C_O, TEI, optimize=True),\n        ""voov"": np.einsum(\'pP,qQ,rR,sS,pqrs->PQRS\', C_V, C_O, C_O, C_V, TEI, optimize=True),\n        ""vvvv"": np.einsum(\'pP,qQ,rR,sS,pqrs->PQRS\', C_V, C_V, C_V, C_V, TEI, optimize=True)\n    }\n\n    if singles:\n        I[""ovvv""] = np.einsum(\'pP,qQ,rR,sS,pqrs->PQRS\', C_O, C_V, C_V, C_V, TEI, optimize=True)\n        I[""ooov""] = np.einsum(\'pP,qQ,rR,sS,pqrs->PQRS\', C_O, C_O, C_O, C_V, TEI, optimize=True)\n\n    if not return_intermediates:\n        return I, F\n    else:\n        OEI = np.kron(np.eye(2), mints.ao_kinetic().np + mints.ao_potential().np)\n        intermed = {""TEI"": TEI, ""O"": C_O, ""V"": C_V, ""OEI"": OEI}\n        return I, F, intermed\n\n\ndef integrals_DF(mol, singles=False):\n\n    C_O, C_V, mints, F = orbitals_fock(mol, singles)\n\n    ### Two-Electron Integrals\n    basis = mints.basisset()\n    zero_bas = psi4.core.BasisSet.zero_ao_basis_set()\n    aux = psi4.core.BasisSet.build(mol, ""DF_BASIS_CC"", """", ""RIFIT"", basis.name())\n    Ppq = np.squeeze(mints.ao_eri(zero_bas, aux, basis, basis))\n    Ppq = np.kron(np.eye(2), Ppq)  # Construct spinorbital quantities\n    metric = mints.ao_eri(zero_bas, aux, zero_bas, aux)\n    metric.power(-0.5, 1.e-10)\n    metric = np.squeeze(metric)\n    Qpq = np.einsum(""QP,Ppq->pqQ"", metric, Ppq, optimize=True)\n    R = {\n        ""oo"": np.einsum(\'pP,qQ,pqX->PQX\', C_O, C_O, Qpq, optimize=True),\n        ""ov"": np.einsum(\'pP,qQ,pqX->PQX\', C_O, C_V, Qpq, optimize=True),\n        ""vv"": np.einsum(\'pP,qQ,pqX->PQX\', C_V, C_V, Qpq, optimize=True)\n    }\n\n    return R, F\n'"
Electron-Propagator/EP2.py,8,"b'""""""\nA simple Psi4 input script to compute EP2 using spatial orbitals\n\nReferences:\n- EP2 energy expression from [Szabo:1996] page 391, Eqn. 7.39\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\n# Orbital to start at\nstart_orbs = 2\n\n# Number of orbitals to compute\nnum_orbs = 4\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'aug-cc-pvdz\',\n                  \'scf_type\': \'pk\',\n                  \'e_convergence\': 1e-8,\n                  \'d_convergence\': 1e-8})\n\nprint(\'\\nStarting RHF and integral build...\')\nt = time.time()\n\n# First compute RHF energy using Psi4\nscf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n# Grab data from wavfunction class\nndocc = wfn.doccpi()[0]\nnmo = wfn.nmo()\nSCF_E = wfn.energy()\neps = np.asarray(wfn.epsilon_a())\n\n# Compute size of ERI tensor in GB\nERI_Size = (nmo**4) * 8e-9\nprint(\'Size of the ERI/MO tensor will be %4.2f GB.\' % ERI_Size)\nmemory_footprint = ERI_Size * 2.5\nif memory_footprint > numpy_memory:\n    clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                    limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\nprint(\'Building MO integrals.\')\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nC = wfn.Ca()\nMO = np.asarray(mints.mo_eri(C, C, C, C))\n\n# Grab ndocc shape\nndocc = np.asarray(wfn.Ca_subset(""AO"", ""OCC"")).shape[1]\nnvirt = MO.shape[0] - ndocc\n\nEocc = eps[:ndocc]\nEvir = eps[ndocc:]\n\n# (pq|rs) -> <ps|rq>\nMO = MO.swapaxes(1, 2)\nprint(\'Shape of MO integrals: %s\' % str(MO.shape))\nprint(\'\\n...finished RHF and integral build in %.3f seconds.\\n\' % (time.time() - t))\n\n\n# Create occupied and virtual slices\no = slice(0, ndocc)\nv = slice(ndocc, MO.shape[0])\n\nif num_orbs > ndocc:\n    num_orbs = ndocc\n\nep2_arr = []\nfor orbital in range(start_orbs + 1, start_orbs + num_orbs + 1):\n    E = eps[orbital]\n    ep2_conv = False\n\n    for ep_iter in range(20):\n        Eold = E\n\n        # Build energy denominators\n        epsilon1 = 1 / (E + Eocc.reshape(-1, 1, 1) - Evir.reshape(-1, 1) - Evir)\n        epsilon2 = 1 / (E + Evir.reshape(-1, 1, 1) - Eocc.reshape(-1, 1) - Eocc)\n\n        # Compute sigma\'s\n        tmp1 = (2 * MO[orbital, o, v, v] - MO[o, orbital, v, v])\n        sigma1 = np.einsum(\'rsa,ars,ars->\', MO[v, v, orbital, o], tmp1, epsilon1)\n\n        tmp2 = (2 * MO[orbital, v, o, o] - MO[v, orbital, o, o])\n        sigma2 = np.einsum(\'abr,rab,rab->\', MO[o, o, orbital, v], tmp2, epsilon2)\n        Enew = eps[orbital] + sigma1 + sigma2\n\n        # Break if below threshold\n        if abs(Enew - Eold) < 1.e-4:\n            ep2_conv = True\n            ep2_arr.append(Enew * 27.21138505)\n            break\n\n        # Build derivatives\n        sigma_deriv1 = np.einsum(\'rsa,ars,ars->\', MO[v, v, orbital, o], tmp1, np.power(epsilon1, 2))\n        sigma_deriv2 = np.einsum(\'abr,rab,rab->\', MO[o, o, orbital, v], tmp2, np.power(epsilon2, 2))\n        deriv = -1 * (sigma_deriv1 + sigma_deriv2)\n\n        # Newton-Raphson update\n        E = Eold - (Eold - Enew) / (1 - deriv)\n\n    if ep2_conv is False:\n        ep2_arr.append(E * 27.21138505)\n        print(\'WARNING: EP2 for orbital HOMO - %d did not converged\' % (ndocc - orbital - 1))\n\nprint(""KP - Koopmans\' Theorem"")\nprint(""EP2 - Electron Propagator 2\\n"")\nprint(""HOMO - n         KP (eV)              EP2 (eV)"")\nprint(""----------------------------------------------"")\n\nKP_arr = eps * 27.21138505\n\nfor orbital in range(0, len(ep2_arr)):\n    kp_orb = start_orbs + orbital + 1\n    print(""% 4d     % 16.4f    % 16.4f"" % (kp_orb - ndocc + 1, KP_arr[kp_orb], ep2_arr[orbital]))\n\n\n\n'"
Electron-Propagator/EP2_SO.py,18,"b'""""""\nA simple Psi4 input script to compute EP2 using spin-orbitals.\n\nReferences:\n- EP2 SO energy expression from [Szabo:1996] pp. 390, Eqn. 7.38\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\n# Number of orbitals below the HOMO to compute\nnum_orbs = 5\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\n# Set Psi4 Options\npsi4.set_options({\'basis\': \'aug-cc-pvdz\',\n                  \'scf_type\': \'pk\',\n                  \'mp2_type\': \'conv\',\n                  \'freeze_core\': \'false\',\n                  \'e_convergence\': 1e-8,\n                  \'d_convergence\': 1e-8})\n\n# First compute RHF energy using Psi4\nscf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n# Coefficient Matrix\nC = np.array(wfn.Ca())\n# Double occupied orbitals\nndocc = wfn.doccpi()[0]\n# Number of molecular orbitals\nnmo = wfn.nmo()\n# SCF energy\nSCF_E = wfn.energy()\n# Orbital energies\neps = wfn.epsilon_a()\neps = np.array([eps.get(x) for x in range(C.shape[0])])\n\n\n# Compute size of SO-ERI tensor in GB\nERI_Size = (nmo**4)*(2**4)*8.0 / 1E9\nprint(""\\nSize of the SO ERI tensor will be %4.2f GB."" % ERI_Size)\nmemory_footprint = ERI_Size*2.2\nif memory_footprint > numpy_memory:\n    clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nI = np.array(mints.ao_eri())\nI = I.reshape(nmo, nmo, nmo, nmo)\n\nprint(\'\\nTotal time taken for ERI integrals: %.3f seconds.\\n\' % (time.time()-t))\n\n\n#Make spin-orbital MO\nt=time.time()\nprint(\'Starting AO -> spin-orbital MO transformation...\')\nnso = nmo * 2\n\nMO = np.einsum(\'rJ,pqrs->pqJs\', C, I)\nMO = np.einsum(\'pI,pqJs->IqJs\', C, MO)\nMO = np.einsum(\'sB,IqJs->IqJB\', C, MO)\nMO = np.einsum(\'qA,IqJB->IAJB\', C, MO)\n\n# Tile MO array so that we have alternating alpha/beta spin orbitals\nMO = np.repeat(MO, 2, axis=0)\nMO = np.repeat(MO, 2, axis=1)\nMO = np.repeat(MO, 2, axis=2)\nMO = np.repeat(MO, 2, axis=3)\n\n# Build spin mask\nspin_ind = np.arange(nso, dtype=np.int) % 2\nspin_mask = (spin_ind.reshape(-1, 1, 1, 1) == spin_ind.reshape(-1, 1, 1))\nspin_mask = spin_mask * (spin_ind.reshape(-1, 1) == spin_ind)\n\n# compute antisymmetrized MO integrals\nMO *= spin_mask\nMO = MO - MO.swapaxes(1, 3)\nMO = MO.swapaxes(1, 2)\nprint(\'..finished transformation in %.3f seconds.\\n\' % (time.time()-t))\n\n# Update nocc and nvirt\nnocc = ndocc * 2\nnvirt = MO.shape[0] - nocc\n\n# Build epsilon tensor\neps = np.repeat(eps, 2)\neocc = eps[:nocc]\nevirt = eps[nocc:]\n\n# Create occupied and virtual slices\no = slice(0, nocc)\nv = slice(nocc, MO.shape[0])\n\nif num_orbs > nocc:\n    num_orbs = nocc\n\nep2_arr = []\nfor orbital in range(nocc-num_orbs*2, nocc, 2):\n    E = eps[orbital]\n    ep2_conv = False\n\n    for ep_iter in range(50):\n        Eold = E\n\n        # Build energy denominators\n        epsilon1 = 1/(E + eocc.reshape(-1, 1, 1) - evirt.reshape(-1, 1) - evirt)\n        epsilon2 = 1/(E + evirt.reshape(-1, 1, 1) - eocc.reshape(-1, 1) - eocc)\n\n        # Compute sigma\'s\n        sigma1 = 0.5 * np.einsum(\'rsa,ars,ars\', MO[v, v, orbital, o], MO[orbital, o, v, v], epsilon1)\n        sigma2 = 0.5 * np.einsum(\'abr,rab,rab\', MO[o, o, orbital, v], MO[orbital, v, o, o], epsilon2)\n        Enew = eps[orbital] + sigma1 + sigma2\n\n        # Break if below threshold\n        if abs(Enew - Eold) < 1.e-4:\n            ep2_conv = True\n            ep2_arr.append(Enew * 27.21138505)\n            break\n\n        # Build derivatives\n        sigma_deriv1 = -1 * np.einsum(\'rsa,ars,ars\', MO[v, v, orbital, o], MO[orbital, o, v, v], np.power(epsilon1, 2))\n        sigma_deriv2 = -1 * np.einsum(\'abr,rab,rab\', MO[o, o, orbital, v], MO[orbital, v, o, o], np.power(epsilon2, 2))\n        deriv = 1 - (sigma_deriv1 + sigma_deriv2)\n\n        # Newton-Raphson update\n        E = Eold - (Eold - Enew) / deriv\n\n    if ep2_conv is False:\n        ep2_arr.append(Enew * 27.21138505)\n        print(\'WARNING: EP2 for orbital HOMO - %d did not converged\' % (ndocc - orbital/2 - 1))\n\n\nprint(""KP - Koopmans\' Theorem"")\nprint(""EP2 - Electron Propagator 2\\n"")\nprint(""HOMO - n         KP (eV)              EP2 (eV)"")\nprint(""----------------------------------------------"")\n\nKP_arr = eps[:nocc][::2] * 27.21138505\n\nfor orbital in range(0, len(ep2_arr)):\n    print(""% 4d     % 16.4f    % 16.4f"" % ((len(ep2_arr)-orbital-1), KP_arr[orbital], ep2_arr[orbital]))\n\n\n\n'"
Electron-Propagator/EP3_SO.py,21,"b'""""""\nA simple Psi4 input script to compute EP3 using spin-orbitals.\n\nReferences:  \n- Equations for EP3 derived by the author from framework provided in [Szabo:1996], pp. 387-392.\n- See ""Further Reading"" in [Szabo:1996], pp. 409, for additional details.\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\n# Number of orbitals below the HOMO to compute\nnum_orbs = 5\n\nmol = psi4.geometry(""""""\nO -0.0247847074 0.0000000 -0.0175254347\nH  0.0232702345 0.0000000  0.9433790708\nH  0.8971830624 0.0000000 -0.2925203027\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'6-31G\',\n                  \'scf_type\': \'pk\',\n                  \'mp2_type\': \'conv\',\n                  \'freeze_core\': \'false\',\n                  \'e_convergence\': 1e-8,\n                  \'d_convergence\': 1e-8})\n\n# First compute RHF energy using Psi4\nscf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n# Coefficient Matrix\nC = np.array(wfn.Ca())\n# Double occupied orbitals\nndocc = wfn.doccpi()[0]\n# Number of molecular orbitals\nnmo = wfn.nmo()\n# SCF energy\nSCF_E = wfn.energy()\n# Orbital energies\neps = wfn.epsilon_a()\neps = np.array([eps.get(x) for x in range(C.shape[0])])\n\n# Compute size of SO-ERI tensor in GB\nERI_Size = (nmo**4) * (2**4) * 8.0 / 1E9\nprint(""\\nSize of the SO ERI tensor will be %4.2f GB."" % ERI_Size)\nmemory_footprint = ERI_Size * 2.2\nif memory_footprint > numpy_memory:\n    clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory limit of %4.2f GB."" %\n                    (memory_footprint, numpy_memory))\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nI = np.array(mints.ao_eri())\nI = I.reshape(nmo, nmo, nmo, nmo)\n\nprint(\'\\nTotal time taken for ERI integrals: %.3f seconds.\\n\' % (time.time() - t))\n\n#Make spin-orbital MO\nt = time.time()\nprint(\'Starting AO -> spin-orbital MO transformation...\')\nnso = nmo * 2\n\nMO = np.einsum(\'rJ,pqrs->pqJs\', C, I)\nMO = np.einsum(\'pI,pqJs->IqJs\', C, MO)\nMO = np.einsum(\'sB,IqJs->IqJB\', C, MO)\nMO = np.einsum(\'qA,IqJB->IAJB\', C, MO)\n\n# Tile MO array so that we have alternating alpha/beta spin orbitals\nMO = np.repeat(MO, 2, axis=0)\nMO = np.repeat(MO, 2, axis=1)\nMO = np.repeat(MO, 2, axis=2)\nMO = np.repeat(MO, 2, axis=3)\n\n# Build spin mask\nspin_ind = np.arange(nso, dtype=np.int) % 2\nspin_mask = (spin_ind.reshape(-1, 1, 1, 1) == spin_ind.reshape(-1, 1, 1))\nspin_mask = spin_mask * (spin_ind.reshape(-1, 1) == spin_ind)\n\n# compute antisymmetrized MO integrals\nMO *= spin_mask\nMO = MO - MO.swapaxes(1, 3)\nMO = MO.swapaxes(1, 2)\nprint(\'..finished transformation in %.3f seconds.\\n\' % (time.time()-t))\n\n# Update nocc and nvirt\nnocc = ndocc * 2\nnvirt = MO.shape[0] - nocc\n\n# Build epsilon tensor\neps = np.repeat(eps, 2)\neocc = eps[:nocc]\nevirt = eps[nocc:]\n\n# Create occupied and virtual slices\no = slice(0, nocc)\nv = slice(nocc, MO.shape[0])\n\nif num_orbs > nocc:\n    num_orbs = nocc\n\ndef get_slice(char, orb):\n    """"""Returns either occupied, orbital, or virtual slice""""""\n    if char in \'abcdefgh\':\n        return slice(0, nocc)\n    elif char in \'ij\':\n        return orb\n    else:\n        return slice(nocc, MO.shape[0])\n\ndef EP_term(n, orbital, factor, string, eps_views):\n    """"""\n    n = EPn order of theory\n    orbital = orbital number\n    factor = symmetry considerations\n    string = summation string MO tensor than energy denominators\n            - First n terms will be MO views (numerator)\n            - Last n-1 terms will be epsilon view (denominator)\n    eps_view = epsilon views\n    Continously writing views seem like too much effort, why not automate the process?\n    """"""\n\n    #if not isinstance(eps_views, list):\n    #    eps_view = list(eps_views)\n\n    # Get slices\n    slices = string.split(\',\')\n    if len(slices) != (n * 2 - 1):\n        clean()\n        raise Exception(\'Number of terms does not match the order of pertubation theory\')\n\n    # Create views\n    views = []\n\n    # MO views\n    for term in range(n):\n        tmp_slice = slices[term]\n        tmp_slice = [get_slice(x, orbital) for x in tmp_slice]\n        views.append(MO[tmp_slice[0], tmp_slice[1], tmp_slice[2], tmp_slice[3]])\n\n    # Add epsilon views\n    views = views + eps_views\n\n    # Remove i and j indices\n    string = string.replace(\'i\', \'\')\n    string = string.replace(\'j\', \'\')\n\n    # Compute term!\n    string += \'->\'\n    term = factor * np.einsum(string, *views)\n    return term\n\nep2_arr = []\nep3_arr = []\nfor orbital in range(nocc - num_orbs * 2, nocc, 2):\n    E = eps[orbital]\n    ep2_conv = False\n    ep3_conv = False\n\n    # EP2\n    for ep_iter in range(50):\n        Eold = E\n\n        # Build energy denominators\n        epsilon1 = 1 / (E + eocc.reshape(-1, 1, 1) - evirt.reshape(-1, 1) - evirt)\n        epsilon2 = 1 / (E + evirt.reshape(-1, 1, 1) - eocc.reshape(-1, 1) - eocc)\n        epsilon1_2 = np.power(epsilon1, 2)\n        epsilon2_2 = np.power(epsilon2, 2)\n\n        # Compute sigma\'s\n        sigma1 = EP_term(2, orbital, 0.5, \'iapq,pqja,apq\', [epsilon1])\n        sigma2 = EP_term(2, orbital, 0.5, \'ipab,abip,pab\', [epsilon2])\n        Enew = eps[orbital] + sigma1 + sigma2\n\n        # Break if below threshold\n        if abs(Enew - Eold) < 1.e-4:\n            ep2_arr.append(Enew * 27.21138505)\n            ep2_conv = True\n            break\n\n        # # Build derivatives\n        sigma_deriv1 = EP_term(2, orbital, -0.5, \'iapq,pqja,apq\', [epsilon1_2])\n        sigma_deriv2 = EP_term(2, orbital, -0.5, \'ipab,abip,pab\', [epsilon2_2])\n        deriv = 1 - sigma_deriv1 - sigma_deriv2\n\n        # Newton-Raphson update\n        E = Eold - (E - Enew) / deriv\n\n\n    if ep2_conv is False:\n        ep2_arr.append(E)\n        print(\'WARNING: EP2 for orbital HOMO - %d did not converged\' % (ndocc - orbital/2 - 1))\n\n    EP2 = E\n    # EP3\n\n    # EP3 self energy independant terms\n    eps_ov = 1 / (eocc.reshape(-1, 1) - evirt)\n    eps_oovv = 1 / (eocc.reshape(-1, 1, 1, 1) + eocc.reshape(-1, 1, 1) - evirt.reshape(-1, 1) - evirt)\n    eps_vvoo = 1 / (evirt.reshape(-1, 1, 1, 1) + evirt.reshape(-1, 1, 1) - eocc.reshape(-1, 1) - eocc)\n\n    eps_oovv_2 = np.power(eps_oovv, 2)\n    eps_vvoo_2 = np.power(eps_vvoo, 2)\n\n\n    ep3_const  = EP_term(3, orbital,  0.5, \'ipja,qrpb,abqr,ap,abqr\', [eps_ov, eps_oovv])\n    ep3_const += EP_term(3, orbital, -0.5, \'ipjb,bqac,acpq,bp,acpq\', [eps_ov, eps_oovv])\n\n    ep3_const += EP_term(3, orbital,  0.5, \'prab,iqjp,abqr,abpr,abqr\', [eps_oovv, eps_oovv])\n    ep3_const += EP_term(3, orbital, -0.5, \'pqbc,ibja,acpq,bcpq,acpq\', [eps_oovv, eps_oovv])\n\n    ep3_const += EP_term(3, orbital,  0.5, \'prab,qbpr,iajq,abpr,aq\', [eps_oovv, eps_ov])\n    ep3_const += EP_term(3, orbital, -0.5, \'pqbc,bcaq,iajp,bcpq,ap\', [eps_oovv, eps_ov])\n\n    # Create KP-EP2 average geuss for EP3\n    E = (EP2 + eps[orbital]) / 2\n    for ep_iter in range(50):\n        Eold = E\n\n        # Compute energy denominators\n        eps_eovv = 1 / (E + eocc.reshape(-1, 1, 1) - evirt.reshape(-1, 1) - evirt)\n        eps_evoo = 1 / (E + evirt.reshape(-1, 1, 1) - eocc.reshape(-1, 1) - eocc)\n        eps_eovv_2 = np.power(eps_eovv, 2)\n        eps_evoo_2 = np.power(eps_evoo, 2)\n\n\n        Enew = eps[orbital] + ep3_const\n        Ederiv = 0\n\n        # EP2\n        Enew += EP_term(2, orbital, 0.5, \'iapq,pqja,apq\', [eps_eovv])\n        Ederiv += EP_term(2, orbital, -0.5, \'iapq,pqja,apq\', [eps_eovv_2])\n\n        Enew += EP_term(2, orbital, 0.5, \'ipab,abip,pab\', [eps_evoo])\n        Ederiv += EP_term(2, orbital, -0.5, \'ipab,abip,pab\', [eps_evoo_2])\n\n\n        #EP3\n        Enew += EP_term(3, orbital,  0.25, \'iaqs,qspr,prja,apr,aqs\', [eps_eovv, eps_eovv])\n        Ederiv += EP_term(3, orbital,  -0.25, \'iaqs,qspr,prja,apr,aqs\', [eps_eovv_2, eps_eovv])\n        Ederiv += EP_term(3, orbital,  -0.25, \'iaqs,qspr,prja,apr,aqs\', [eps_eovv, eps_eovv_2])\n\n        Enew += EP_term(3, orbital, -1.00, \'iaqr,qbpa,prjb,bpr,aqr\', [eps_eovv, eps_eovv])\n        Ederiv += EP_term(3, orbital,  1.00, \'iaqr,qbpa,prjb,bpr,aqr\', [eps_eovv_2, eps_eovv])\n        Ederiv += EP_term(3, orbital,  1.00, \'iaqr,qbpa,prjb,bpr,aqr\', [eps_eovv, eps_eovv_2])\n\n        # Block\n        Enew += EP_term(3, orbital, -1.00, \'iraq,abpr,pqjb,bpq,abpr\', [eps_eovv, eps_oovv])\n        Enew += EP_term(3, orbital,  0.25, \'icab,abpq,pqjc,cpq,abpq\', [eps_eovv, eps_oovv])\n        Enew += EP_term(3, orbital, -1.00, \'ibpr,pqab,arjq,bpr,abpq\', [eps_eovv, eps_oovv])\n        Enew += EP_term(3, orbital,  0.25, \'ibpq,pqac,acjb,bpq,acpq\', [eps_eovv, eps_oovv])\n\n        Ederiv += EP_term(3, orbital,  1.00, \'iraq,abpr,pqjb,bpq,abpr\', [eps_eovv_2, eps_oovv])\n        Ederiv += EP_term(3, orbital, -0.25, \'icab,abpq,pqjc,cpq,abpq\', [eps_eovv_2, eps_oovv])\n        Ederiv += EP_term(3, orbital,  1.00, \'ibpr,pqab,arjq,bpr,abpq\', [eps_eovv_2, eps_oovv])\n        Ederiv += EP_term(3, orbital, -0.25, \'ibpq,pqac,acjb,bpq,acpq\', [eps_eovv_2, eps_oovv])\n\n        # Block\n        Enew += EP_term(3, orbital, -0.25, \'iqab,abpr,prjq,qab,prab\', [eps_evoo, eps_vvoo])\n        Enew += EP_term(3, orbital,  1.00, \'iqac,abpq,pcjb,qac,pqab\', [eps_evoo, eps_vvoo])\n        Enew += EP_term(3, orbital, -0.25, \'irpq,pqab,abjr,rab,pqab\', [eps_evoo, eps_vvoo])\n        Enew += EP_term(3, orbital,  1.00, \'icpb,pqac,abjq,qab,pqac\', [eps_evoo, eps_vvoo])\n\n        Ederiv += EP_term(3, orbital,  0.25, \'iqab,abpr,prjq,qab,prab\', [eps_evoo_2, eps_vvoo])\n        Ederiv += EP_term(3, orbital, -1.00, \'iqac,abpq,pcjb,qac,pqab\', [eps_evoo_2, eps_vvoo])\n        Ederiv += EP_term(3, orbital,  0.25, \'irpq,pqab,abjr,rab,pqab\', [eps_evoo_2, eps_vvoo])\n        Ederiv += EP_term(3, orbital, -1.00, \'icpb,pqac,abjq,qab,pqac\', [eps_evoo_2, eps_vvoo])\n\n        # Block\n        Enew += EP_term(3, orbital,  1.00, \'ipbc,bqap,acjq,pbc,qac\', [eps_evoo, eps_evoo])\n        Ederiv += EP_term(3, orbital, -1.00, \'ipbc,bqap,acjq,pbc,qac\', [eps_evoo_2, eps_evoo])\n        Ederiv += EP_term(3, orbital, -1.00, \'ipbc,bqap,acjq,pbc,qac\', [eps_evoo, eps_evoo_2])\n\n        Enew += EP_term(3, orbital, -0.25, \'ipbd,bdac,acjp,pbd,pac\', [eps_evoo, eps_evoo])\n        Ederiv += EP_term(3, orbital,  0.25, \'ipbd,bdac,acjp,pbd,pac\', [eps_evoo_2, eps_evoo])\n        Ederiv += EP_term(3, orbital,  0.25, \'ipbd,bdac,acjp,pbd,pac\', [eps_evoo, eps_evoo_2])\n\n        # Break if below threshold\n        if abs(Enew - Eold) < 1.e-4:\n            print(\'EP3 HOMO - %d converged in %d iterations\' % ((ndocc - orbital/2 - 1), ep_iter))\n            ep3_arr.append(Enew * 27.21138505)\n            ep3_conv = True\n            break\n\n        # Newton-Raphson update\n        E = Eold - (Eold - Enew) / (1 - Ederiv)\n\n    if ep3_conv is False:\n        ep3_arr.append(E)\n        print(\'WARNING: EP3 for orbital HOMO - %d did not converged\' % (ndocc - orbital/2 - 1))\n\n\nprint(""\\nKP - Koopmans\' Theorem"")\nprint(""EP2 - Electron Propagator 2\\n"")\nprint(""HOMO - n         KP (eV)              EP2 (eV)              EP3 (eV)"")\nprint(""---------------------------------------------------------------------"")\n\nKP_arr = eps[:nocc][::2] * 27.21138505\n\nfor orbital in range(0, len(ep2_arr)):\n    print(""% 4d     % 16.4f    % 16.4f    % 16.4f"" % ((len(ep2_arr) - orbital - 1), KP_arr[orbital], ep2_arr[orbital],\n                                                      ep3_arr[orbital]))\n\n# 13.46 11.27\n'"
MD-Verlet-Integrator/md_helper.py,2,"b'""""""\nHelper functions used to compute Molecular Dynamics (MD) trajectories\n\nReferences:\nAlgorithms & equations taken from [Attig:2004].\n""""""\n\n__authors__ = ""Leonardo dos Anjod Cunha""\n__credits__ = [""Leonardo dos Anjod Cunha""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2017-05-16""\n\nimport psi4\nimport numpy as np\nimport os\n\n# Converting Atomic Mass Unit (amu) to atomic units (au)\namu2au = 1822.8884850\n\ndef md_trajectories(max_md_step):\n    """""" Creates single .xyz file with MD Trajectories with all points.\n        \n        Parameters:\n        ----------\n            int max_md_steps -- Number of MD steps calculated\n\n        Returns:\n        -------\n            file md_trajectories.xyz -- File containing all the trajectory points for visualization\n    """"""\n\n    with open(\'md_trajectories.xyz\',\'w\') as outfile:\n      for i in range(1,max_md_step+1):\n        with open(\'md_step_\'+str(i)+\'.xyz\')as infile:\n            outfile.write(infile.read())\n    os.system(\'rm md_step*\')\n\ndef integrator(int_alg,timestep,pos,veloc,accel,molec,grad_method):\n    """""" Selects the type of integration algorithm to propagate the trajectories\n        Only velocity Verlet implemented (date: 05/23/17 - LAC)\n\n        Parameters:\n        ----------\n            string int_alg --  Integrator Algorith to be used\n                Options:\n                a) veloc_verlet --  Use Velocity Verlet Algorithm\n            float timestep -- Time step to be used on the MD trajectory propagation step\n            array pos --  Numpy array (natoms,3) with old positions/trajectories\n            array veloc --  Numpy array (natoms,3) with old velocities\n            array accel -- Numpy array (natoms,3) with old accelerations\n            psi4_object molec --  Psi4 molecule object to be used\n            string grad_method: Method to be used to calculate energies and forces\n\n        Returns:\n        -------\n            array pos_new -- Numpy array (natoms,3) with the updated positions\n            array vel_new -- Numpy array (natoms,3) with the updated velocities\n            array accel_new -- Numpy array (natoms,3) with the updated accelerations\n            float E -- Updated energy of the system\n    """"""\n\n    natoms = molec.natom()\n    atom_mass = np.asarray([molec.mass(atom) for atom in range(natoms)])*amu2au\n\n    # Velocity Verlet Integrator\n    if int_alg==\'veloc_verlet\':\n        vel_new =  veloc+0.5*timestep*accel\n        pos_new =  pos+timestep*vel_new\n        molec.set_geometry(psi4.core.Matrix.from_array(pos_new))\n        E,force_new = get_forces(grad_method)\n        accel_new = force_new/(atom_mass.reshape((natoms,1)))\n        vel_new += 0*5*timestep*accel_new\n    return pos_new,vel_new,accel_new,E\n\ndef get_forces(grad_method):\n    """""" Selects the method (QC or FF) to be used to calculate energies and forces for the system\n        Only Psi4 supported methods implemented (date: 05/23/17 - LAC)\n    \n        Parameters:\n        ----------\n            string grad_method -- Method to be used to calculate forces and energies\n\n        Returns:\n        -------\n            float E -- Energy of the system\n            array force -- Numpy array (natoms,3) containing the forces acting on each atom of the system\n    """"""\n\n    E,wfn = psi4.energy(grad_method,return_wfn=True)\n    force = -np.asarray(psi4.gradient(grad_method,ref_wfn=wfn))\n    return E,force\n\n'"
MD-Verlet-Integrator/md_prog.py,4,"b'""""""\nA simple Psi4 script to compute Molecular Dynamics Trajectories using\nVelocity Verlet integration.\n\nReferences:\nEquations and algorithms taken from [Attig:2004].\n""""""\n\n__authors__ = ""Leonardo dos Anjod Cunha""\n__credits__ = [""Leonardo dos Anjod Cunha""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2017-05-16""\n\nimport numpy as np\nimport psi4\nimport os\nimport sys\nsys.path.append(\'./\')\nimport md_helper\n\npsi4.core.set_output_file(\'md_output.dat\',False)\n\nmolec = psi4.geometry(""""""\nH 0 0 0\nH 0 0 1\n"""""")\n\n# Global Constants (Atomic Units conversion)\nfs_timeau = 41.34137314\namu2au = 1822.8884850\n\n#MD Options\ntimestep =  5                       # Time step for each iteration in time atomic units\nmax_md_step = 100                 # Number of MD iterations\nveloc0 = np.zeros((2,3))            # Numpy array (natoms,3) with inital velocities\ntrajec = True                       # Boolean: Save all trajectories in a single xyz file (md_trajectories)  for visualization\ngrad_method = \'hf/3-21g\'            # Method (QC with basis set) for energy and gradient\nint_alg = \'veloc_verlet\'            # Algorithm to use as integrator\nopt    = False                      # Optimize geometry using F=ma\n\n# Molecular Dynamics Main Program\n    \n#Get initial positions,velocities, accelerations and forces\nenergy,forces = md_helper.get_forces(grad_method)\ngeom = np.asarray(molec.geometry())\nnatoms = molec.natom()\natom_mass = np.asarray([molec.mass(atom) for atom in range(natoms)])*amu2au\nif opt:\n    veloc = np.zeros((natoms,3))\nelse:\n    veloc = veloc0\naccel = forces/(atom_mass.reshape((natoms,1)))\n\n# MD LOOP\npos = geom\n# Saving energies of each iteration on md_energy file\nmd_energy = open(\'md_energy.dat\',\'w\')\nmd_energy.write(\'File with the energy of each MD trajectory point\\n\\n\')\nmd_energy.write(\'Trajectory Number\\tEnergy (Hartree)\\n\')\nmd_energy.write(\'{0:>3d}\\t\\t\\t{1:10.8f}\\n\'.format(1,energy))\nfor i in range(1,max_md_step+1):\n    \n    # Saving energies and trajectory points\n    md_energy.write(\'{0:>3d}\\t\\t\\t{1:10.8f}\\n\'.format(i,energy))\n    if trajec:\n        molec.save_xyz_file(\'md_step_\'+str(i)+\'.xyz\',False)\n\n    # Updating positions velocities and accelerations using Velocity Verlet Integrator\n    pos_new,vel_new,accel_new,energy_new = md_helper.integrator(int_alg,timestep,pos,veloc,accel,molec,grad_method)\n    pos = pos_new\n    if (not opt):\n        veloc = vel_new\n    accel = accel_new\n    energy = energy_new\nmd_energy.close()\nif trajec:\n    md_helper.md_trajectories(max_md_step)\nprint ""Done with Molecular Dynamics Program!""\n'"
Moller-Plesset/DF-MP2.py,10,"b'""""""\nA reference implementation of density-fitted MP2 from a RHF reference.\n\nReferences: \nAlgorithm modified from Rob Parrish\'s most excellent Psi4 plugin example\nBottom of the page: http://www.psicode.org/developers.php\n""""""\n\n__authors__   = ""Daniel G. A. Smith""\n__credits__   = [""Daniel G. A. Smith"", ""Dominic A. Sirianni""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2017-05-23""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Set memory & output\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\nmol = psi4.geometry("""""" \nC    1.39410    0.00000   0.00000\nC    0.69705   -1.20732   0.00000\nC   -0.69705   -1.20732   0.00000\nC   -1.39410    0.00000   0.00000\nC   -0.69705    1.20732   0.00000\nC    0.69705    1.20732   0.00000\nH    2.47618    0.00000   0.00000\nH    1.23809   -2.14444   0.00000\nH   -1.23809   -2.14444   0.00000\nH   -2.47618    0.00000   0.00000\nH   -1.23809    2.14444   0.00000\nH    1.23809    2.14444   0.00000\nsymmetry c1\n"""""")\n\n# Basis used in mp2 density fitting\npsi4.set_options({\'basis\': \'aug-cc-pVDZ\',\n                  \'df_basis_scf\': \'aug-cc-pvdz-ri\'})\n\ncheck_energy = False\n\nprint(\'\\nStarting RHF...\')\nt = time.time()\nRHF_E, wfn = psi4.energy(\'SCF\', return_wfn=True)\nprint(\'...RHF finished in %.3f seconds:   %16.10f\' % (time.time() - t, RHF_E))\n\n# Grab data from Wavfunction clas\nndocc = wfn.nalpha()\nnbf = wfn.nso()\nnvirt = nbf - ndocc\n\n# Split eigenvectors and eigenvalues into o and v\neps_occ = np.asarray(wfn.epsilon_a_subset(""AO"", ""ACTIVE_OCC""))\neps_vir = np.asarray(wfn.epsilon_a_subset(""AO"", ""ACTIVE_VIR""))\n\n# Build DF tensors\nprint(\'\\nBuilding DF ERI tensor Qov...\')\nt = time.time()\nC = wfn.Ca()\naux = psi4.core.BasisSet.build(mol, ""DF_BASIS_MP2"", """", ""RIFIT"", ""aug-cc-pvdz"")\ndf = psi4.core.DFTensor(wfn.basisset(), aux, C, ndocc, nvirt) \n# Transformed MO DF tensor\nQov = np.asarray(df.Qov())\nprint(\'...Qov build in %.3f seconds with a shape of %s, %.3f GB.\' \\\n% (time.time() - t, str(Qov.shape), np.prod(Qov.shape) * 8.e-9))\n\nprint(\'\\nComputing MP2 energy...\')\nt = time.time()\n\n# At this point we can trivially build the ovov MO tensor and compute MP2\n# identically to that as MP2.dat. However, this means we have to build the\n# 4-index ERI tensor in memory and results in little gains over conventional\n# MP2\n# MO = np.einsum(\'Qia,Qjb->iajb\', Qov, Qov)\n\n# A smarter algorithm, loop over occupied indices and exploit ERI symmetry\n\n# This part of the denominator is identical for all i,j pairs\nvv_denom = - eps_vir.reshape(-1, 1) - eps_vir\n\nMP2corr_OS = 0.0\nMP2corr_SS = 0.0\nfor i in range(ndocc):\n    eps_i = eps_occ[i]\n    i_Qv = Qov[:, i, :].copy()\n    for j in range(i, ndocc):\n\n        eps_j = eps_occ[j]\n        j_Qv = Qov[:, j, :]\n\n        # We can either use einsum here\n#        tmp = np.einsum(\'Qa,Qb->ab\', i_Qv, j_Qv)\n\n        # Or a dot product (DGEMM) for speed)\n        tmp = np.dot(i_Qv.T, j_Qv)\n\n        # Diagonal elements\n        if i == j:\n            div = 1.0 / (eps_i + eps_j + vv_denom)\n        # Off-diagonal elements\n        else:\n            div = 2.0 / (eps_i + eps_j + vv_denom)\n\n        # Opposite spin computation\n        MP2corr_OS += np.einsum(\'ab,ab,ab->\', tmp, tmp, div)\n\n        # Notice the same-spin compnent has an ""exchange"" like term associated with it\n        MP2corr_SS += np.einsum(\'ab,ab,ab->\', tmp - tmp.T, tmp, div)\n\nprint(\'...finished computing MP2 energy in %.3f seconds.\' % (time.time() - t))\n\nMP2corr_E = MP2corr_SS + MP2corr_OS\nMP2_E = RHF_E + MP2corr_E\n\n# These are the canonical SCS MP2 coefficients, many others are available however\nSCS_MP2corr_E = MP2corr_SS / 3 + MP2corr_OS * (6. / 5)\nSCS_MP2_E = RHF_E + SCS_MP2corr_E\n\nprint(\'\\nMP2 SS correlation energy:         %16.10f\' % MP2corr_SS)\nprint(\'MP2 OS correlation energy:         %16.10f\' % MP2corr_OS)\n\nprint(\'\\nMP2 correlation energy:            %16.10f\' % MP2corr_E)\nprint(\'MP2 total energy:                  %16.10f\' % MP2_E)\n\nprint(\'\\nSCS-MP2 correlation energy:        %16.10f\' % SCS_MP2corr_E)\nprint(\'SCS-MP2 total energy:              %16.10f\' % SCS_MP2_E)\n\nif check_energy:\n    psi4.energy(\'MP2\')\n    psi4.compare_values(psi4.core.variable(\'MP2 TOTAL ENERGY\'), MP2_E, 6, \'MP2 Energy\')\n    psi4.compare_values(psi4.core.variable(\'SCS-MP2 TOTAL ENERGY\'), SCS_MP2_E, 6, \'SCS-MP2 Energy\')\n\n'"
Moller-Plesset/DF-MP2_NAF.py,20,"b'""""""\nDensity-fitted MP2 from a RHF reference (same as DF-MP2) using a rank-reduced DF tensor\nfrom natural auxiliary functions (NAF) as described in [3].\n\nThis is the \'smarter\' algorithm described in the paper that avoids the costly\ndirect contraction of the Coulomb metric with the 3-index integrals (Qov tensor in PSI4 language)\nInstead cheap intermediates are used the reduced Qov tensor is regained as the last step.\n\nReferences: \n1. Algorithm modified from Rob Parrish\'s most excellent Psi4 plugin example\nBottom of the page: http://www.psicode.org/developers.php\n2. Tutorials/03_Hartree-Fock/density-fitting.ipynb\n3. M. Kallay, J. Chem. Phys. 2014, 141, 244113. [http://aip.scitation.org/doi/10.1063/1.4905005]\n""""""\n\n__authors__ = ""Holger Kruse""\n__credits__ = [""Holger Kruse"", ""Daniel G. A. Smith"", ""Dominic A. Sirianni""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2018-11-29""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Set memory & output\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\nmol = psi4.geometry("""""" \nC    1.39410    0.00000   0.00000\nC    0.69705   -1.20732   0.00000\nC   -0.69705   -1.20732   0.00000\nC   -1.39410    0.00000   0.00000\nC   -0.69705    1.20732   0.00000\nC    0.69705    1.20732   0.00000\nH    2.47618    0.00000   0.00000\nH    1.23809   -2.14444   0.00000\nH   -1.23809   -2.14444   0.00000\nH   -2.47618    0.00000   0.00000\nH   -1.23809    2.14444   0.00000\nH    1.23809    2.14444   0.00000\nsymmetry c1\n"""""")\n\n# Adjustable selection parameter (e.g 10^-2 to 10^-4)\n# for constructing the NAF space\nepsilon_naf = 1e-2\n\n# Basis used in mp2 density fitting\npsi4.set_options({\'basis\': \'aug-cc-pVDZ\', \'df_basis_mp2\': \'aug-cc-pvdz-ri\'})\n\ncheck_energy = True\n\nprint(\'\\nStarting RHF...\')\nt = time.time()\nRHF_E, wfn = psi4.energy(\'SCF\', return_wfn=True)\nprint(\'...RHF finished in %.3f seconds:   %16.10f\' % (time.time() - t, RHF_E))\n\n# Grab data from Wavfunction clas\nndocc = wfn.nalpha()\norbital_basis = wfn.basisset()\nnbf = wfn.nso()\nnvirt = nbf - ndocc\n\nprint(\'ndocc\', ndocc)\nprint(\'nvirt\', nvirt)\n\n# Split eigenvectors and eigenvalues into o and v\neps_occ = np.asarray(wfn.epsilon_a_subset(""AO"", ""ACTIVE_OCC""))\neps_vir = np.asarray(wfn.epsilon_a_subset(""AO"", ""ACTIVE_VIR""))\n\n# Build DF tensors\nprint(\'\\nBuilding DF ERI tensor Qov...\')\nt = time.time()\nC = np.asarray(wfn.Ca())\n\n# Build instance of MintsHelper\nmints = psi4.core.MintsHelper(orbital_basis)\nzero_bas = psi4.core.BasisSet.zero_ao_basis_set()\n\n# build auxiliary basis set object\naux_basis = psi4.core.BasisSet.build(\n    mol, ""DF_BASIS_MP2"", """", ""RIFIT"",\n    psi4.core.get_global_option(\'df_basis_mp2\'))\nnaux = aux_basis.nbf()\n\n# Build (P|pq) raw 3-index ERIs, dimension (1, Naux, nbf, nbf)\n# this is I^t in the paper\nPpq = mints.ao_eri(zero_bas, aux_basis, orbital_basis, orbital_basis)\nprint(\'Ppq = I^t = (Q|pg)\', Ppq.shape)\n\n# Build Coulomb metric but only invert, dimension (1, Naux, 1, Naux)\nmetric = mints.ao_eri(zero_bas, aux_basis, zero_bas, aux_basis)\nmetric.power(-1.0, 1.e-14)\n\n# Remove excess dimensions of Ppq & metric\nPpq = np.squeeze(Ppq)\nmetric = np.squeeze(metric)\n\n# cholesky decomp of inverse metric\nL = np.linalg.cholesky(metric)\nprint(""L  = cholesky[(P|Q)^1 ]dim:"", L.shape)\n\n# Form intermediate W\'= I^t*I (eq 10)\n# note that Wp = Wp^t\nWp = np.einsum(\'Ppq,Qpq->PQ\', Ppq, Ppq, optimize=True)\nprint(""W\' = (P|P) dim:"", Wp.shape)\n\n# form W proper (eq 11)\nW = np.dot(np.dot(L.T, Wp), L)\nprint(""W  = (Q|Q) dim:"", W.shape)\n\n# form N(bar) from significant eigenvectors of W\ne_val, e_vec = np.linalg.eigh(W)\nmask = np.abs(e_val) > epsilon_naf\nnaux2 = np.sum(mask)\nNbar = e_vec[:, mask]\n\nprint(\'retaining #naux = %i  of  %i [ %4.1f %% ] for epsilon(naf) = %.3e \' %\n      (naux2, naux, naux2 / naux * 100.0, epsilon_naf))\nprint(""N^bar  = (Q^bar|Q) dim)"", Nbar.shape)\n\n# form N\'(bar) = L * N(bar) (eq 12)\nNpbar = np.dot(L, Nbar)\nprint(""N\'^bar  = (P^bar|Q) dim)"", Npbar.shape)\n\n# form J(bar) = I * N\'(bar) (eq 13)\n# we form the transpose of Jbar to be inline with PSI4\nJbar = np.einsum(\'Ppq,PQ->Qpq\', Ppq, Npbar, optimize=True)\nprint(""J^bar  = (Q|pq) dim)"", Npbar.shape)\n\n# ==> AO->MO transform: Qpq -> Qmo @ O(N^4) <==\nprint(\'AO->MO transform\')\nCocc = C[:, :ndocc]\nCvirt = C[:, ndocc:]\nQov = np.einsum(\'pi,Qpq->Qqi\', Cocc, Jbar, optimize=True)\nQov = np.einsum(\'Qqi,qa->Qia\', Qov, Cvirt, optimize=True)\n\ntime_qov = time.time() - t\nprint(\'...Qov build in %.3f seconds with a shape of %s, %.3f GB.\' \\\n% (time_qov, str(Qov.shape), np.prod(Qov.shape) * 8.e-9))\n\n# Having obtained the new MO DF tensor the MP2 energy calculation proceeds as usual\nprint(\'\\nComputing MP2 energy...\')\nt = time.time()\n\n# This part of the denominator is identical for all i,j pairs\nvv_denom = -eps_vir.reshape(-1, 1) - eps_vir\n\nMP2corr_OS = 0.0\nMP2corr_SS = 0.0\nfor i in range(ndocc):\n    eps_i = eps_occ[i]\n    i_Qv = Qov[:, i, :].copy()\n    for j in range(i, ndocc):\n\n        eps_j = eps_occ[j]\n        j_Qv = Qov[:, j, :]\n\n        # Or a dot product (DGEMM) for speed)\n        tmp = np.dot(i_Qv.T, j_Qv)\n\n        # Diagonal elements\n        if i == j:\n            div = 1.0 / (eps_i + eps_j + vv_denom)\n        # Off-diagonal elements\n        else:\n            div = 2.0 / (eps_i + eps_j + vv_denom)\n\n        # Opposite spin computation\n        MP2corr_OS += np.einsum(\'ab,ab,ab->\', tmp, tmp, div)\n\n        # Notice the same-spin compnent has an ""exchange"" like term associated with it\n        MP2corr_SS += np.einsum(\'ab,ab,ab->\', tmp - tmp.T, tmp, div)\n\ntime_mp2 = time.time() - t\nprint(\'...finished computing MP2 energy in %.3f seconds.\' % (time_mp2))\n\nMP2corr_E = MP2corr_SS + MP2corr_OS\nMP2_E = RHF_E + MP2corr_E\n\n# Compute MP2 correlation & total MP2 Energy\nprint(\'E(MP2) %f\' % (MP2_E))\nprint(\'Ecorr(MP2) %f\' % (MP2corr_E))\n\nprint(\'NAF-DF-MP2 finished in: %.3f s \\n \' % (time_qov + time_mp2))\n\nif check_energy:\n    print(\' PSI4 MP2 calculation ...\')\n    # ==> Compare to Psi4 <==\n    # re-used RHF wavefunction\n    e_total = psi4.energy(\'mp2\', ref_wfn=wfn)\n    print(\'E_REF(MP2) %f\' % (e_total))\n    ecorr = psi4.core.variable(\'MP2 CORRELATION ENERGY\')\n    t = time.time()\n    print(\'reference Ecorr(MP2) = %f ; error = %.3e for epsilon(naf) = %.3e\' %\n          (ecorr, ecorr - MP2corr_E, epsilon_naf))\n    print(\'PSI4 DF-MP2 finished in %.3f s\' \\\n    % (time.time() - t))\n'"
Moller-Plesset/LT-MP2.py,7,"b'""""""\nA reference implementation of MP2 using the Laplace transformation for a restricted reference.\nThis is performed in an MO basis for demonstration, but LT-MP2 can be extended to AO-LT-MP2.\n\nReferences:\n    J. Almlof, Chem. Phys. Lett. 181, 319 (1991).\n    P. Y. Ayala and G. E. Scuseria, J. Chem. Phys., 110, 3660 (1999).\n""""""\n\n__authors__ = ""Oliver J. Backhouse""\n__credits__ = [""Oliver J. Backhouse""]\n\n__copyright__ = ""(c) 2014-2020, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2018-03-01""\n\nimport time\nimport numpy as np\nimport psi4\n\n# Settings\ncompare_to_psi4 = True\ngrid_size = 40\n\n# Set the memory and output file\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Set molecule and basis\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'aug-cc-pvdz\'})\n\n# Perform SCF\nprint(\'\\nPerforming SCF...\')\ne_scf, wfn = psi4.energy(\'SCF\', return_wfn=True)\nmints = psi4.core.MintsHelper(wfn.basisset())\n\n# Get occupied and virtual MO energies and coefficients\ne_occ = wfn.epsilon_a_subset(\'AO\', \'ACTIVE_OCC\').np \ne_vir = wfn.epsilon_a_subset(\'AO\', \'ACTIVE_VIR\').np\nc_occ = wfn.Ca_subset(\'AO\', \'OCC\')\nc_vir = wfn.Ca_subset(\'AO\', \'VIR\')\n\n# Get the two-electron integrals in MO basis\nprint(\'Building MO integrals...\')\niajb = mints.mo_eri(c_occ, c_vir, c_occ, c_vir).np\n\n# Build the grids and weights according to Gauss-Laguerre quadrature\n# Also apply a weighting function w(x) = exp(x)\ngrid, weights = np.polynomial.laguerre.laggauss(grid_size)\nweights *= np.exp(grid)\n\n# Loop over grid points and compute energies\ne_mp2_corr_os = 0.0\ne_mp2_corr_ss = 0.0\n\nprint(\'Looping over %d grid points...\' % grid_size)\nt_start = time.time()\nfor t, w in zip(grid, weights):\n    # Build the amplitudes, including the contribution from the Laplace-transformed term\n    # In some equations, this is combined with the next einsum for the energy contributions,\n    # instead we contract the amplitudes with the MO integrals to get the energies.\n    t_occ = np.exp( t * e_occ)\n    t_vir = np.exp(-t * e_vir)\n    iajb_t = np.einsum(\'i,a,j,b,iajb->iajb\', t_occ, t_vir, t_occ, t_vir, iajb)\n\n    # Calculate MP2 energy for spin cases\n    e_mp2_corr_os_contr = np.einsum(\'iajb,iajb->\', iajb_t, iajb)\n    e_mp2_corr_ss_contr = np.einsum(\'iajb,iajb->\', iajb_t, iajb - iajb.swapaxes(1, 3))\n\n    # Add to total including weights\n    e_mp2_corr_os -= w * e_mp2_corr_os_contr\n    e_mp2_corr_ss -= w * e_mp2_corr_ss_contr\n\ne_mp2_corr = e_mp2_corr_os + e_mp2_corr_ss\ne_mp2 = e_scf + e_mp2_corr\n\ne_scs_mp2_corr = e_mp2_corr_os * (6. / 5) + e_mp2_corr_ss / 3\ne_scs_mp2 = e_scf + e_scs_mp2_corr\n\nprint(\'MP2 energy calculated in %.3f seconds.\\n\' % (time.time() - t_start))\n\nprint(\'\\nMP2 SS correlation energy:  %16.10f\' % e_mp2_corr_ss)\nprint(\'MP2 OS correlation energy:  %16.10f\' % e_mp2_corr_os)\n                                   \nprint(\'\\nMP2  correlation energy:    %16.10f\' % e_mp2_corr)\nprint(\'MP2 total energy:           %16.10f\' % e_mp2)\n\nprint(\'\\nSCS-MP2 correlation energy: %16.10f\' % e_scs_mp2_corr)\nprint(\'SCS-MP2 total energy:       %16.10f\\n\' % e_scs_mp2)\n\nif compare_to_psi4:\n    psi4.energy(\'MP2\')\n    psi4.compare_values(psi4.core.variable(\'MP2 TOTAL ENERGY\'), e_mp2, 4, \'MP2 Energy\')\n    psi4.compare_values(psi4.core.variable(\'SCS-MP2 TOTAL ENERGY\'), e_scs_mp2, 4, \'SCS-MP2 Energy\')\n\n'"
Moller-Plesset/MP2.py,11,"b'""""""\nA reference implementation of second-order Moller-Plesset perturbation theory.\n\nReferences:\n- Algorithms and equations were taken directly from Daniel Crawford\'s programming website:\nhttp://github.com/CrawfordGroup/ProgrammingProjects\n\nSpecial thanks to Rob Parrish for initial assistance with libmints.\n""""""\n\n__authors__    = ""Daniel G. A. Smith""\n__credits__   = [""Daniel G. A. Smith"", ""Dominic A. Sirianni"", ""Rob Parrish""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2017-05-23""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\n\npsi4.set_options({\'basis\': \'aug-cc-pvdz\',\n                  \'scf_type\': \'pk\',\n                  \'mp2_type\': \'conv\',\n                  \'e_convergence\': 1e-8,\n                  \'d_convergence\': 1e-8})\n\n# Check energy against psi4?\ncheck_energy = False\n\nprint(\'\\nStarting SCF and integral build...\')\nt = time.time()\n\n# First compute SCF energy using Psi4\nscf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n# Grab data from wavfunction class \nndocc = wfn.nalpha()\nnmo = wfn.nmo()\nSCF_E = wfn.energy()\neps = np.asarray(wfn.epsilon_a())\n\n# Compute size of ERI tensor in GB\nERI_Size = (nmo ** 4) * 8e-9\nprint(\'Size of the ERI/MO tensor will be %4.2f GB.\' % ERI_Size)\nmemory_footprint = ERI_Size * 2.5\nif memory_footprint > numpy_memory:\n    clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                    limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\nprint(\'Building MO integrals.\')\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nCo = wfn.Ca_subset(""AO"", ""OCC"")\nCv = wfn.Ca_subset(""AO"", ""VIR"")\nMO = np.asarray(mints.mo_eri(Co, Cv, Co, Cv))\n\nEocc = eps[:ndocc]\nEvirt = eps[ndocc:]\n\nprint(\'Shape of MO integrals: %s\' % str(MO.shape))\nprint(\'\\n...finished SCF and integral build in %.3f seconds.\\n\' % (time.time() - t))\n\nprint(\'Computing MP2 energy...\')\nt = time.time()\ne_denom = 1 / (Eocc.reshape(-1, 1, 1, 1) - Evirt.reshape(-1, 1, 1) + Eocc.reshape(-1, 1) - Evirt)\n\n# Get the two spin cases\nMP2corr_OS = np.einsum(\'iajb,iajb,iajb->\', MO, MO, e_denom)\nMP2corr_SS = np.einsum(\'iajb,iajb,iajb->\', MO - MO.swapaxes(1, 3), MO, e_denom)\nprint(\'...MP2 energy computed in %.3f seconds.\\n\' % (time.time() - t))\n\nMP2corr_E = MP2corr_SS + MP2corr_OS\nMP2_E = SCF_E + MP2corr_E\n\nSCS_MP2corr_E = MP2corr_SS / 3 + MP2corr_OS * (6. / 5)\nSCS_MP2_E = SCF_E + SCS_MP2corr_E\n\nprint(\'MP2 SS correlation energy:         %16.10f\' % MP2corr_SS)\nprint(\'MP2 OS correlation energy:         %16.10f\' % MP2corr_OS)\n\nprint(\'\\nMP2 correlation energy:            %16.10f\' % MP2corr_E)\nprint(\'MP2 total energy:                  %16.10f\' % MP2_E)\n\nprint(\'\\nSCS-MP2 correlation energy:        %16.10f\' % SCS_MP2corr_E)\nprint(\'SCS-MP2 total energy:              %16.10f\' % SCS_MP2_E)\n\nif check_energy:\n    psi4.energy(\'MP2\')\n    psi4.compare_values(psi4.core.variable(\'MP2 TOTAL ENERGY\'), MP2_E, 6, \'MP2 Energy\')\n    psi4.compare_values(psi4.core.variable(\'SCS-MP2 TOTAL ENERGY\'), SCS_MP2_E, 6, \'SCS-MP2 Energy\')\n\n\n# Natural orbitals as a bonus\nlam_menf = MO + (MO - MO.swapaxes(1,3))\namp_ienf = MO * e_denom\n\n# Compute occupied and virtual MP2 densities\nGij = np.einsum(\'ienf,menf->im\', amp_ienf, lam_menf)\nGab = np.einsum(\'manf,menf->ea\', amp_ienf, lam_menf)\n\n# MP2 Density matrix\nD_occ = 0.25 * (Gij + Gij.T)\nD_occ += np.diag(np.ones(ndocc)) * 2\nD_vir = -0.25 * (Gab + Gab.T)\n\n# Build full D and diagonalize\nD = np.zeros((nmo, nmo))\nD[:ndocc, :ndocc] = D_occ\nD[ndocc:, ndocc:] = D_vir\n\nevals, evecs = np.linalg.eigh(D)\n\n# Question for the audience, what should it be?\nprint(""\\nThe sum of the natural occupation numbers is %6.4f"" % np.sum(evals))\n\n\n\n'"
Moller-Plesset/MP2_Gradient.py,52,"b'# -*- coding: utf-8 -*-\n""""""\nThis script calculates nuclear gradients for MP2 using the\ngradients of one and two electron integrals obtained from PSI4. \n\nReferences: \n1. ""Derivative studies in hartree-fock and m\xc3\xb8ller-plesset theories"",\nJ. A. Pople, R. Krishnan, H. B. Schlegel and J. S. Binkley\nDOI: 10.1002/qua.560160825\n\n2. ""Analytic evaluation of second derivatives using second-order many-body \nperturbation theory and unrestricted Hartree-Fock reference functions"",\nJ. F. Stanton, J. Gauss, and R. J. Bartlett\nDOI: 10.1016/0009-2614(92)86135-5\n\n3. ""Coupled-cluster open shell analytic gradients: Implementation of the\ndirect product decomposition approach in energy gradient calculations"",\nJ. Gauss, J. F. Stanton, R. J. Bartlett\nDOI: 10.1063/1.460915\n""""""\n\n__authors__ = ""Kirk C. Pearce""\n__credits__ = [""Kirk C. Pearce"", ""Ashutosh Kumar""]\n__copyright__ = ""(c) 2014-2017, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2019-02-11""\n\nimport time\nimport numpy as np\nimport psi4\nimport copy\n\n# Setup NumPy options\nnp.set_printoptions(\n    precision=12, \n    linewidth=200, \n    suppress=True, \n    threshold=10000\n)\n\n# Specify Molecule\nmol = psi4.geometry(""""""\nO\nH 1 R\nH 1 R 2 104\nsymmetry c1\n"""""")\n\n# physical constants changed, so geometry changes slightly\nfrom pkg_resources import parse_version\nif parse_version(psi4.__version__) >= parse_version(""1.3a1""):\n    mol.R = 1.1 * 0.52917721067 / 0.52917720859\nelse:\n    mol.R = 1.1\n\npsi4.core.set_active_molecule(mol)\n\n# Set Psi4 Options\noptions = {\n    \'BASIS\': \'STO-3G\',\n    \'SCF_TYPE\': \'PK\',\n    \'MP2_TYPE\': \'CONV\',\n    \'E_CONVERGENCE\': 1e-12,\n    \'D_CONVERGENCE\': 1e-12,\n    \'print\': 1\n}\n\npsi4.set_options(options)\n\n# Perform MP2 Energy Calculation\nmp2_e, wfn = psi4.energy(\'MP2\', return_wfn=True)\n\n# Relevant Variables\nnatoms = mol.natom()\nnmo = wfn.nmo()\nnocc = wfn.doccpi()[0]\nnvir = nmo - nocc\n\n# MO Coefficients\nC = wfn.Ca_subset(""AO"", ""ALL"")\nnpC = psi4.core.Matrix.to_array(C)\n\n# Integral generation from Psi4\'s MintsHelper\nmints = psi4.core.MintsHelper(wfn.basisset())\n\n# Build T, V, and S\nT = mints.ao_kinetic()\nnpT = psi4.core.Matrix.to_array(T)\nV = mints.ao_potential()\nnpV = psi4.core.Matrix.to_array(V)\nS = mints.ao_overlap()\nnpS = psi4.core.Matrix.to_array(S)\n\n# Build ERIs\nERI = mints.mo_eri(C, C, C, C)\nnpERI = psi4.core.Matrix.to_array(ERI)\n# Physicist notation\nnpERI = npERI.swapaxes(1, 2)\n\n# Build Core Hamiltonian in AO basis\nH_core = npT + npV\n\n# Transform H to MO basis\nH = np.einsum(\'uj,vi,uv\', npC, npC, H_core, optimize=True)\n\n# Build Fock Matrix\nF = H + 2.0 * np.einsum(\'pmqm->pq\', npERI[:, :nocc, :, :nocc], optimize=True)\nF -= np.einsum(\'pmmq->pq\', npERI[:, :nocc, :nocc, :], optimize=True)\n\n# Occupied and Virtual Orbital Energies\nF_occ = np.diag(F)[:nocc]\nF_vir = np.diag(F)[nocc:nmo]\n\n# Build Denominator\nDijab = F_occ.reshape(-1, 1, 1, 1) + F_occ.reshape(-1, 1, 1) - F_vir.reshape(-1, 1) - F_vir\n\n# Build T2 Amplitudes,\n# where t2 = <ij|ab> / (e_i + e_j - e_a - e_b),\nt2 = npERI[:nocc, :nocc, nocc:, nocc:] / Dijab\n\n# Build T2_tilde Amplitudes (tilde = closed-shell spin-free analog of antisymmetrizer),\n# i.e., t2_tilde[p,q,r,s] = 2 * t2[p,q,r,s] - t2[p,q,s,r]),\n# where t2_tilde = [2<ij|ab> - <ij|ba>] / (e_i + e_j - e_a - e_b)\nt2_tilde = 2 * t2 - t2.swapaxes(2, 3)\n\n# Build Reference OPDM\nnpD_ao = 2.0 * np.einsum(\'ui,vi->uv\', npC[:, :nocc], npC[:, :nocc], optimize=True)\n# Transform to MO Basis\nref_opdm = np.einsum(\'iu,uv,vw,wx,xj\', npC.T, npS.T, npD_ao, npS, npC, optimize=True)\n\n# Build MP2 OPDM\n# Build OO block of MP2 OPDM\n# Pij = sum_kab [( t2(i,k,a,b) * t2_tilde(j,k,a,b) ) + ( t2(j,k,a,b) * t2_tilde(i,k,a,b) )]\nPij = -1.0 * np.einsum(\'ikab,jkab->ij\', t2, t2_tilde, optimize=True)\nPij += -1.0 * np.einsum(\'jkab,ikab->ij\', t2, t2_tilde, optimize=True)\n\n# Build VV block of MP2 OPDM\n# Pab = sum_ijc [( t2(i,j,a,c) * t2_tilde(i,j,b,c) ) + ( t2(i,j,b,c) * t2_tilde(i,j,a,c) )]\nPab = np.einsum(\'ijac,ijbc->ab\', t2, t2_tilde, optimize=True)\nPab += np.einsum(\'ijbc,ijac->ab\', t2, t2_tilde, optimize=True)\n\n# Build Total OPDM\nPpq = np.zeros((nmo, nmo))\nPpq += ref_opdm\nPpq[:nocc, :nocc] += Pij\nPpq[nocc:, nocc:] += Pab\n#print(""\\n\\nTotal OPDM:\\n"", Ppq)\n#print(""\\nChecks:"")\n#print(""OPDM is symmetric: "",np.allclose(Ppq, Ppq.T))\n#print(""OPDM trace = 10: "",np.isclose(sum(np.linalg.eigh(Ppq)[0]),10))\n\n# Build Reference TPDM\nref_tpdm = np.zeros((nmo, nmo, nmo, nmo))\nref_tpdm += 2.0 * np.einsum(""pr,qs->pqrs"", ref_opdm, ref_opdm, optimize=True)\nref_tpdm -= 1.0 * np.einsum(""ps,qr->pqrs"", ref_opdm, ref_opdm, optimize=True)\nref_tpdm = -0.25 * ref_tpdm\n\n# Build MP2 TPDM\nPijab = copy.deepcopy(t2_tilde)\n\n# Build Total TPDM\nPpqrs = np.zeros((nmo, nmo, nmo, nmo))\nPpqrs += ref_tpdm\nPpqrs[:nocc, :nocc, nocc:, nocc:] += Pijab\nPpqrs[nocc:, nocc:, :nocc, :nocc] += Pijab.T\n#print(""\\n\\nTotal TPDM:\\n"", Ppqrs.reshape(nmo*nmo, nmo*nmo))\n\n\n# Build I\'\n# I\'_pq = - (1/2) * [ fpp(Ppq + Pqp) + sum_rs (Prs * (4<rp|sq> - <rp|qs> - <rq|ps>)) * kronecker_delta(q,occ) + ...\n#         ... + sum_rst (Pqrst <pr|st> + Prqst <rp|st> + Prsqt <rs|pt> + Prstq <rs|tp>) ]\nIp = np.zeros((nmo, nmo))\n\n# I\'pq += fpp(Ppq + Pqp)\nIp += np.einsum(""pr,rq->pq"", F, Ppq, optimize=True)\nIp += np.einsum(""qr,rp->pq"", Ppq, F, optimize=True)\n\n# I\'_pq += sum_rst (Pqrst <pr|st> + Prqst <rp|st> + Prsqt <rs|pt> + Prstq <rs|tp>)\nIp += np.einsum(\'qrst,prst->pq\', Ppqrs, npERI, optimize=True)\nIp += np.einsum(\'rqst,rpst->pq\', Ppqrs, npERI, optimize=True)\nIp += np.einsum(\'rsqt,rspt->pq\', Ppqrs, npERI, optimize=True)\nIp += np.einsum(\'rstq,rstp->pq\', Ppqrs, npERI, optimize=True)\n\n# I\'_pq += sum_rs Prs(4<rp|sq> - <rp|qs> - <rq|ps>) kronecker_delta(q,occ)\nIp[:, :nocc] += 4.0 * np.einsum(\'rs,rpsq->pq\', Ppq , npERI[:, :, :, :nocc], optimize=True)\nIp[:, :nocc] -= 1.0 * np.einsum(\'rs,rpqs->pq\', Ppq , npERI[:, :, :nocc, :], optimize=True)\nIp[:, :nocc] -= 1.0 * np.einsum(\'rs,rqps->pq\', Ppq , npERI[:, :nocc, :, :], optimize=True)\n\nIp *= -0.5\n#print(""\\nI\':\\n"",Ip)\n\n\n# Build I\'\' ,\n# where I\'\'_pq = I\'_qp    if (p,q) = (a,i)\n#              = I\'_pq    otherwise\nIpp = copy.deepcopy(Ip)\nIpp[nocc:, :nocc] = Ip[:nocc, nocc:].T\n\n# Build X_ai = I\'_ia - I\'_ai\nX = Ip[:nocc, nocc:].T - Ip[nocc:, :nocc]\n#print(""\\nX:\\n"", X)\n\n# Build Idenity matrices in nocc/nvir dimensions\nI_occ = np.diag(np.ones(nocc))\nI_vir = np.diag(np.ones(nvir))\n\n# Build epsilon_a - epsilon_i matrix\neps = np.asarray(wfn.epsilon_a())\neps_diag = eps[nocc:].reshape(-1, 1) - eps[:nocc]\n\n# Build the electronic hessian, G, where\n# G = ((epsilon_a - epsilon_i) * kronecker_delta(a,b) * kronecker_delta(i,j)) * (4<ij|ab> - <ij|ba> - <ia|jb>)\n\n# G += 4<ij|ab> - <ij|ba> - <ia|jb>\nG =  4.0 * npERI[:nocc, :nocc, nocc:, nocc:]\nG -= 1.0 * npERI[:nocc, :nocc, nocc:, nocc:].swapaxes(2, 3)\nG -= 1.0 * npERI[:nocc, nocc:, :nocc, nocc:].swapaxes(1, 2)\n\n# Change shape of G from ij,ab to ia,jb\nG = G.swapaxes(1, 2)\n\n# G += (epsilon_a - epsilon_i) * kronecker_delta(a,b) * kronecker delta(i,j)\nG += np.einsum(\'ai,ij,ab->iajb\', eps_diag, I_occ, I_vir, optimize=True)\n\n# Take Transpose of G_iajb\nG = G.T.reshape(nocc * nvir, nocc * nvir)\n#print(""\\n\\nMO Hessian Matrix:\\n"",G)\n\n# Solve G^T(ai,bj) Z(b,j) = X(a,i)\nX = X.reshape(nocc * nvir, -1)\nZ = np.linalg.solve(G, X).reshape(nvir, -1)\n#print(""\\n\\nZ Vector:\\n"",Z)\n\n# Relax OPDM\n# Ppq(a,i) = Ppq(i,a) = - Z(a,i)\nPpq[:nocc, nocc:] = -Z.T\nPpq[nocc:, :nocc] = -Z\n#print(""\\n\\nRelaxed Total OPDM:\\n"", Ppq)\n\n# Build Lagrangian, I, where\n# I(i,j) = I\'\'(i,j) + sum_ak ( Z(a,k) * [ 2<ai|kj> - <ai|jk>  + 2<aj|ki> - <aj|ik> ])\n# I(i,a) = I\'\'(i,a) + Z(a,i) * eps(i)\n# I(a,i) = I\'\'(a,i) + Z(a,i) * eps(i)\n# I(a,b) = I\'\'(a,b)\nI = copy.deepcopy(Ipp)\n\n# I(i,j) \nI[:nocc, :nocc] += 2.0 * np.einsum(\'ak,aikj->ij\', Z, npERI[nocc:, :nocc, :nocc, :nocc], optimize=True)\nI[:nocc, :nocc] -= 1.0 * np.einsum(\'ak,aijk->ij\', Z, npERI[nocc:, :nocc, :nocc, :nocc], optimize=True)\nI[:nocc, :nocc] += 2.0 * np.einsum(\'ak,ajki->ij\', Z, npERI[nocc:, :nocc, :nocc, :nocc], optimize=True)\nI[:nocc, :nocc] -= 1.0 * np.einsum(\'ak,ajik->ij\', Z, npERI[nocc:, :nocc, :nocc, :nocc], optimize=True)\n\n# I(a,i)\nI[nocc:, :nocc] += Z * F_occ\n\n# I(i,a)\nI[:nocc, nocc:] += (Z * F_occ).T\n\n#print(""\\n\\nLagrangian I:\\n"",I)\n\n\n# Fold the two-electron piece of the Fock matrix contributions \n# to the gradient into the TPDM, i.e. we are converting from \n# a gradient expression of the form\n#\n# dE/dx = sum_pq Ppq fpq^x + sum_pqrs Gpqrs <pq|rs>^x\n#\n# to the form:\n#\n# dE/dx = sum_pq Ppq hpq^x + sum_pqrs G\'pqrs <pq|rs>^x\n#\n# where\n#\n# G\'pqrs = Gpqrs + (2 * Ppr * kroecker_delta(q,occ) * kronecker_delta(q,s)) - (Pps * kronecker_delta(q,occ) * kronecker_delta(q,r))  \n#for p in range(nmo):\nPpqrs[:, :nocc, :, :nocc] += 2.0 * np.einsum(\'pr,qs->pqrs\', Ppq, np.eye(nocc))\nPpqrs[:, :nocc, :nocc, :] -= 1.0 * np.einsum(\'ps,qr->pqrs\', Ppq, np.eye(nocc))\n\n\nGradient = {}\nGradient[""N""] = np.zeros((natoms, 3))\nGradient[""S""] = np.zeros((natoms, 3))\nGradient[""T""] = np.zeros((natoms, 3))\nGradient[""V""] = np.zeros((natoms, 3))\nGradient[""OEI""] = np.zeros((natoms, 3))\nGradient[""TEI""] = np.zeros((natoms, 3))\nGradient[""Total""] = np.zeros((natoms, 3))\n\n# 1st Derivative of Nuclear Repulsion\nGradient[""N""] = psi4.core.Matrix.to_array(mol.nuclear_repulsion_energy_deriv1([0, 0, 0]))\n\npsi4.core.print_out(""\\n\\n"")\nN_grad = psi4.core.Matrix.from_array(Gradient[""N""])\nN_grad.name = ""NUCLEAR GRADIENT""\nN_grad.print_out()\n\n# Build Integral Derivatives\ncart = [\'_X\', \'_Y\', \'_Z\']\noei_dict = {""S"": ""OVERLAP"", ""T"": ""KINETIC"", ""V"": ""POTENTIAL""}\n\nderiv1_mat = {}\nderiv1_np = {}\n\n# 1st Derivative of OEIs\nfor atom in range(natoms):\n    for key in oei_dict:\n        string = key + str(atom)\n        deriv1_mat[string] = mints.mo_oei_deriv1(oei_dict[key], atom, C, C)\n        for p in range(3):\n            map_key = string + cart[p]\n            deriv1_np[map_key] = np.asarray(deriv1_mat[string][p])\n            if key == ""S"":\n                Gradient[""S""][atom, p] = np.einsum(\'pq,pq->\', I, deriv1_np[map_key], optimize=True)\n            else:\n                Gradient[key][atom, p] = np.einsum(""pq,pq->"", Ppq, deriv1_np[map_key], optimize=True)\n\n# Build Total OEI Gradient\nGradient[""OEI""] = Gradient[""T""] + Gradient[""V""] + Gradient[""S""]\n\n# Print OEI Components of the Gradient\npsi4.core.print_out(""\\n\\n OEI Gradients:\\n\\n"")\nfor key in Gradient:\n    Mat = psi4.core.Matrix.from_array(Gradient[key])\n    if key in oei_dict:\n        Mat.name = oei_dict[key] + "" GRADIENT""\n        Mat.print_out()\n        psi4.core.print_out(""\\n"")\n\n# 1st Derivative of TEIs\nfor atom in range(natoms):\n    string = ""TEI"" + str(atom)\n    deriv1_mat[string] = mints.mo_tei_deriv1(atom, C, C, C, C)\n    for p in range(3):\n        map_key = string + cart[p]\n        deriv1_np[map_key] = np.asarray(deriv1_mat[string][p])\n\n        Gradient[""TEI""][atom, p] += np.einsum(\'pqrs,prqs->\', Ppqrs, deriv1_np[map_key], optimize=True)\n\n# Print TEI Component of the Gradient\npsi4.core.print_out(""\\n\\n TEI Gradients:\\n\\n"")\nTEI_grad = psi4.core.Matrix.from_array(Gradient[""TEI""])\nTEI_grad.name = "" TEI GRADIENT""\nTEI_grad.print_out()\n\n# Build Total Gradient\nGradient[""Total""] = Gradient[""OEI""] + Gradient[""TEI""] + Gradient[""N""]\n\n# Print Total Gradient\npsi4.core.print_out(""\\n\\n Total Gradient:\\n\\n"")\nTot_grad = psi4.core.Matrix.from_array(Gradient[""Total""])\nTot_grad.name = "" TOTAL GRADIENT""\nTot_grad.print_out()\n\n# PSI4\'s Total Gradient\nTotal_G_psi4 = psi4.core.Matrix.from_list([\n        [-0.00000000000000, -0.00000000000000, -0.05413558328761],\n        [ 0.00000000000000, -0.06662229046965,  0.02706779164384],\n        [-0.00000000000000,  0.06662229046965,  0.02706779164384]\n    ])\n\n# Psi4Numpy Total Gradient\ntotal_grad = psi4.core.Matrix.from_array(Gradient[""Total""])\n\n# Compare Total Gradients\nG_python_total_mat = psi4.core.Matrix.from_array(Gradient[""Total""])\npsi4.compare_matrices(Total_G_psi4, G_python_total_mat, 10, ""MP2_TOTAL_GRADIENT_TEST"")\n'"
Moller-Plesset/MP2_Hessian.py,214,"b'# -*- coding: utf-8 -*-\n""""""\nThis script calculates nuclear hessians for MP2 using the\ngradients of one and two electron integrals obtained from PSI4. \n\nReferences: \n1. ""Derivative studies in hartree-fock and m\xc3\xb8ller-plesset theories"",\nJ. A. Pople, R. Krishnan, H. B. Schlegel and J. S. Binkley\nDOI: 10.1002/qua.560160825\n\n2. ""Analytic evaluation of second derivatives using second-order many-body \nperturbation theory and unrestricted Hartree-Fock reference functions"",\nJ. F. Stanton, J. Gauss, and R. J. Bartlett\nDOI: 10.1016/0009-2614(92)86135-5\n\n3. ""Coupled-cluster open shell analytic gradients: Implementation of the\ndirect product decomposition approach in energy gradient calculations"",\nJ. Gauss, J. F. Stanton, R. J. Bartlett\nDOI: 10.1063/1.460915\n""""""\n\n__authors__ = ""Kirk C. Pearce""\n__credits__ = [""Kirk C. Pearce"", ""Ashutosh Kumar""]\n__copyright__ = ""(c) 2014-2017, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2019-08-15""\n\nimport time\nimport numpy as np\nimport copy\nimport psi4\nfrom psi4 import *\n\n# Setup NumPy options\nnp.set_printoptions(\n    precision=15, \n    linewidth=200, \n    suppress=True, \n    threshold=sys.maxsize\n)\n\npsi4.set_memory(int(1e9), False)\npsi4.core.set_output_file(\'output.dat\', False)\npsi4.core.set_num_threads(4)\n\n# Specify Molecule\n#mol = psi4.geometry(""""""\n#O\n#H 1 R\n#H 1 R 2 104\n#units bohr\n#symmetry c1\n#"""""")\nmol = psi4.geometry(""""""\nO   0.0000000000     0.0000000000     0.0757918437\nH   0.0000000000    -0.8668118290    -0.6014357791\nH   0.0000000000     0.8668118290    -0.6014357791\nsymmetry c1\nunits bohr\nnoreorient\n"""""")\n\n# physical constants changed, so geometry changes slightly\nfrom pkg_resources import parse_version\nmol.R = 1.1\n#if parse_version(psi4.__version__) >= parse_version(""1.3a1""):\n#    mol.R = 1.1 * 0.52917721067 / 0.52917720859\n#else:\n#    mol.R = 1.1\n\npsi4.core.set_active_molecule(mol)\n\n# Set Psi4 Options\noptions = {\n    #\'BASIS\': \'STO-3G\',\n    \'SCF_TYPE\': \'PK\',\n    \'MP2_TYPE\': \'CONV\',\n    \'E_CONVERGENCE\': 1e-14,\n    \'D_CONVERGENCE\': 1e-14,\n    \'print\': 1\n}\n\n# Define custom basis set to match STO-3G from CFOUR\ndef basisspec_psi4_yo__anonymous203a4092(mol, role):\n    basstrings = {}\n    mol.set_basis_all_atoms(""sto-3g"", role=role)\n    basstrings[\'sto-3g\'] = """"""\ncartesian\n****\nH     0\nS   3   1.00\n3.4252509             0.1543290\n0.6239137             0.5353281\n0.1688554             0.4446345\n****\nO     0\nS   3   1.00\n130.7093214              0.1543290\n23.8088661              0.5353281\n6.4436083              0.4446345\nSP   3   1.00\n5.0331513             -0.0999672             0.1559163\n1.1695961              0.3995128             0.6076837\n0.3803890              0.7001155             0.3919574\n****\nF     0\nS   3   1.00\n166.6791340              0.1543290\n30.3608123              0.5353281\n8.2168207              0.4446345\nSP   3   1.00\n6.4648032             -0.0999672             0.1559163\n1.5022812              0.3995128             0.6076837\n0.4885885              0.7001155             0.3919574\n****\n""""""\n    return basstrings\nqcdb.libmintsbasisset.basishorde[\'ANONYMOUS203A4092\'] = basisspec_psi4_yo__anonymous203a4092\ncore.set_global_option(""BASIS"", ""anonymous203a4092"")\n\npsi4.set_options(options)\n\n# Perform MP2 Energy Calculation\nmp2_e, wfn = psi4.energy(\'MP2\', return_wfn=True)\n\n# Relevant Variables\nnatoms = mol.natom()\nnmo = wfn.nmo()\nnocc = wfn.doccpi()[0]\nnvir = nmo - nocc\n\n# MO Coefficients\nC = wfn.Ca_subset(""AO"", ""ALL"")\nnpC = psi4.core.Matrix.to_array(C)\n\n# Integral generation from Psi4\'s MintsHelper\nmints = psi4.core.MintsHelper(wfn.basisset())\n\n# Build T, V, and S\nT = mints.ao_kinetic()\nnpT = psi4.core.Matrix.to_array(T)\nV = mints.ao_potential()\nnpV = psi4.core.Matrix.to_array(V)\nS = mints.ao_overlap()\nnpS = psi4.core.Matrix.to_array(S)\n\n# Transform S to MO Basis\nnpS_mo = 2.0 * np.einsum(\'uj,vi,uv\', npC, npC, npS, optimize=True)\n\n# Build ERIs\nERI = mints.mo_eri(C, C, C, C)\nnpERI = psi4.core.Matrix.to_array(ERI)\n# Physicist notation\nnpERI = npERI.swapaxes(1, 2)\n\n# Build Core Hamiltonian in AO basis\nH_core = npT + npV\n\n# Transform H to MO basis\nH = np.einsum(\'uj,vi,uv\', npC, npC, H_core, optimize=True)\n\n# Build Fock Matrix\nF = H + 2.0 * np.einsum(\'pmqm->pq\', npERI[:, :nocc, :, :nocc], optimize=True)\nF -= np.einsum(\'pmmq->pq\', npERI[:, :nocc, :nocc, :], optimize=True)\n\n# Occupied and Virtual Orbital Energies\nF_occ = np.diag(F)[:nocc]\nF_vir = np.diag(F)[nocc:nmo]\n\n# Build Denominator\nDijab = F_occ.reshape(-1, 1, 1, 1) + F_occ.reshape(-1, 1, 1) - F_vir.reshape(-1, 1) - F_vir\n\n# Build T2 Amplitudes,\n# where t2 = <ij|ab> / (e_i + e_j - e_a - e_b),\nt2 = npERI[:nocc, :nocc, nocc:, nocc:] / Dijab\n\n# Build T2_tilde Amplitudes (tilde = closed-shell spin-free analog of antisymmetrizer),\n# i.e., t2_tilde[p,q,r,s] = 2 * t2[p,q,r,s] - t2[p,q,s,r]),\n# where t2_tilde = [2<ij|ab> - <ij|ba>] / (e_i + e_j - e_a - e_b)\nt2_tilde = 2 * t2 - t2.swapaxes(2, 3)\n\n# Build Reference OPDM\nnpD_ao = 2.0 * np.einsum(\'ui,vi->uv\', npC[:, :nocc], npC[:, :nocc], optimize=True)\n# Transform to MO Basis\nref_opdm = np.einsum(\'iu,uv,vw,wx,xj\', npC.T, npS.T, npD_ao, npS, npC, optimize=True)\n\n# Build MP2 OPDM\n# Build OO block of MP2 OPDM\n# Pij = sum_kab [( t2(i,k,a,b) * t2_tilde(j,k,a,b) ) + ( t2(j,k,a,b) * t2_tilde(i,k,a,b) )]\nPij = -1.0 * np.einsum(\'ikab,jkab->ij\', t2, t2_tilde, optimize=True)\nPij += -1.0 * np.einsum(\'jkab,ikab->ij\', t2, t2_tilde, optimize=True)\n\n# Build VV block of MP2 OPDM\n# Pab = sum_ijc [( t2(i,j,a,c) * t2_tilde(i,j,b,c) ) + ( t2(i,j,b,c) * t2_tilde(i,j,a,c) )]\nPab = np.einsum(\'ijac,ijbc->ab\', t2, t2_tilde, optimize=True)\nPab += np.einsum(\'ijbc,ijac->ab\', t2, t2_tilde, optimize=True)\n\n# Build Total OPDM\nPpq = np.zeros((nmo, nmo))\nPpq += ref_opdm\nPpq[:nocc, :nocc] += Pij\nPpq[nocc:, nocc:] += Pab\n#print(""\\n\\nTotal OPDM:\\n"", Ppq)\n#print(""\\nChecks:"")\n#print(""OPDM is symmetric: "",np.allclose(Ppq, Ppq.T))\n#print(""OPDM trace = 10: "",np.isclose(sum(np.linalg.eigh(Ppq)[0]),10))\n\n# Build Reference TPDM\nref_tpdm = np.zeros((nmo, nmo, nmo, nmo))\nref_tpdm += 2.0 * np.einsum(""pr,qs->pqrs"", ref_opdm, ref_opdm, optimize=True)\nref_tpdm -= 1.0 * np.einsum(""ps,qr->pqrs"", ref_opdm, ref_opdm, optimize=True)\nref_tpdm = -0.25 * ref_tpdm\n\n# Build MP2 TPDM\nPijab = copy.deepcopy(t2_tilde)\n\n# Build Total TPDM\nPpqrs = np.zeros((nmo, nmo, nmo, nmo))\nPpqrs += ref_tpdm\nPpqrs[:nocc, :nocc, nocc:, nocc:] += Pijab\nPpqrs[nocc:, nocc:, :nocc, :nocc] += Pijab.T\n#print(""\\n\\nTotal TPDM:\\n"", Ppqrs.reshape(nmo*nmo, nmo*nmo))\n\n\n# Build I\'\n# I\'_pq = - (1/2) * [ fpp(Ppq + Pqp) + sum_rs (Prs * (4<rp|sq> - <rp|qs> - <rq|ps>)) * kronecker_delta(q,occ) + ...\n#         ... + sum_rst (Pqrst <pr|st> + Prqst <rp|st> + Prsqt <rs|pt> + Prstq <rs|tp>) ]\nIp = np.zeros((nmo, nmo))\n\n# I\'pq += fpp(Ppq + Pqp)\nIp += np.einsum(""pr,rq->pq"", F, Ppq, optimize=True)\nIp += np.einsum(""qr,rp->pq"", Ppq, F, optimize=True)\n\n# I\'_pq += sum_rst (Pqrst <pr|st> + Prqst <rp|st> + Prsqt <rs|pt> + Prstq <rs|tp>)\nIp += np.einsum(\'qrst,prst->pq\', Ppqrs, npERI, optimize=True)\nIp += np.einsum(\'rqst,rpst->pq\', Ppqrs, npERI, optimize=True)\nIp += np.einsum(\'rsqt,rspt->pq\', Ppqrs, npERI, optimize=True)\nIp += np.einsum(\'rstq,rstp->pq\', Ppqrs, npERI, optimize=True)\n\n# I\'_pq += sum_rs Prs(4<rp|sq> - <rp|qs> - <rq|ps>) kronecker_delta(q,occ)\nIp[:, :nocc] += 4.0 * np.einsum(\'rs,rpsq->pq\', Ppq , npERI[:, :, :, :nocc], optimize=True)\nIp[:, :nocc] -= 1.0 * np.einsum(\'rs,rpqs->pq\', Ppq , npERI[:, :, :nocc, :], optimize=True)\nIp[:, :nocc] -= 1.0 * np.einsum(\'rs,rqps->pq\', Ppq , npERI[:, :nocc, :, :], optimize=True)\n\nIp *= -0.5\n#print(""\\nI\':\\n"",Ip)\n\n\n# Build I\'\' ,\n# where I\'\'_pq = I\'_qp    if (p,q) = (a,i)\n#              = I\'_pq    otherwise\nIpp = copy.deepcopy(Ip)\nIpp[nocc:, :nocc] = Ip[:nocc, nocc:].T\n\n# Build X_ai = I\'_ia - I\'_ai\nX = Ip[:nocc, nocc:].T - Ip[nocc:, :nocc]\n#print(""\\nX:\\n"", X)\n\n# Build Idenity matrices in nocc/nvir dimensions\nI_occ = np.diag(np.ones(nocc))\nI_vir = np.diag(np.ones(nvir))\n\n# Build epsilon_a - epsilon_i matrix\neps = np.asarray(wfn.epsilon_a())\neps_diag = eps[nocc:].reshape(-1, 1) - eps[:nocc]\n\n# Build the electronic hessian, G, where\n# G = ((epsilon_a - epsilon_i) * kronecker_delta(a,b) * kronecker_delta(i,j)) * (4<ij|ab> - <ij|ba> - <ia|jb>)\n\n# G += 4<ij|ab> - <ij|ba> - <ia|jb>\nG =  4.0 * npERI[:nocc, :nocc, nocc:, nocc:]\nG -= 1.0 * npERI[:nocc, :nocc, nocc:, nocc:].swapaxes(2, 3)\nG -= 1.0 * npERI[:nocc, nocc:, :nocc, nocc:].swapaxes(1, 2)\n\n# Change shape of G from ij,ab to ia,jb\nG = G.swapaxes(1, 2)\n\n# G += (epsilon_a - epsilon_i) * kronecker_delta(a,b) * kronecker delta(i,j)\nG += np.einsum(\'ai,ij,ab->iajb\', eps_diag, I_occ, I_vir, optimize=True)\n\n# Inverse of G\nGinv = np.linalg.inv(G.reshape(nocc * nvir, -1))\nGinv = Ginv.reshape(nocc, nvir, nocc, nvir)\n\n# Take Transpose of G_iajb\nG = G.T.reshape(nocc * nvir, nocc * nvir)\n#print(""\\nMO Hessian, G:\\n"", G)\n\n# Solve G^T(ai,bj) Z(b,j) = X(a,i)\nX = X.reshape(nocc * nvir, -1)\nZ = np.linalg.solve(G, X).reshape(nvir, -1)\n#print(""\\nZ Vector:\\n"", X)\n\n# Relax OPDM\n# Ppq(a,i) = Ppq(i,a) = - Z(a,i)\nPpq[:nocc, nocc:] = -Z.T\nPpq[nocc:, :nocc] = -Z\n#print(""\\n\\nRelaxed Total OPDM:\\n"", Ppq)\n\n# Build Lagrangian, I, where\n# I(i,j) = I\'\'(i,j) + sum_ak ( Z(a,k) * [ 2<ai|kj> - <ai|jk>  + 2<aj|ki> - <aj|ik> ])\n# I(i,a) = I\'\'(i,a) + Z(a,i) * eps(i)\n# I(a,i) = I\'\'(a,i) + Z(a,i) * eps(i)\n# I(a,b) = I\'\'(a,b)\nI = copy.deepcopy(Ipp)\n# I(i,j) \nI[:nocc, :nocc] += 2.0 * np.einsum(\'ak,aikj->ij\', Z, npERI[nocc:, :nocc, :nocc, :nocc], optimize=True)\nI[:nocc, :nocc] -= 1.0 * np.einsum(\'ak,aijk->ij\', Z, npERI[nocc:, :nocc, :nocc, :nocc], optimize=True)\nI[:nocc, :nocc] += 2.0 * np.einsum(\'ak,ajki->ij\', Z, npERI[nocc:, :nocc, :nocc, :nocc], optimize=True)\nI[:nocc, :nocc] -= 1.0 * np.einsum(\'ak,ajik->ij\', Z, npERI[nocc:, :nocc, :nocc, :nocc], optimize=True)\n# I(a,i)\nI[nocc:, :nocc] += Z * F_occ\n# I(i,a)\nI[:nocc, nocc:] += (Z * F_occ).T\n#print(""\\n\\nLagrangian I:\\n"", I)\n\n\n\n# Build Integral Derivatives\ncart = [\'_X\', \'_Y\', \'_Z\']\noei_dict = {""S"": ""OVERLAP"", ""T"": ""KINETIC"", ""V"": ""POTENTIAL""}\n\nderiv1_mat = {}\nderiv1_np = {}\n\n# 1st Derivative of OEIs\nfor atom in range(natoms):\n    for key in oei_dict:\n        deriv1_mat[key + str(atom)] = mints.mo_oei_deriv1(oei_dict[key], atom, C, C)\n        for p in range(3):\n            map_key = key + str(atom) + cart[p]\n            deriv1_np[map_key] = np.asarray(deriv1_mat[key + str(atom)][p])\n\n# 1st Derivative of TEIs\nfor atom in range(natoms):\n    key = ""TEI""\n    deriv1_mat[key + str(atom)] = mints.mo_tei_deriv1(atom, C, C, C, C)\n    for p in range(3):\n        map_key = key + str(atom) + cart[p]\n        deriv1_np[map_key] = np.asarray(deriv1_mat[key + str(atom)][p])\n\n# Build Fpq^x\nF_grad = {}\nfor atom in range(natoms):\n    for p in range(3):\n        key = str(atom) + cart[p]\n        F_grad[key] = copy.deepcopy(deriv1_np[""T"" + key])\n        F_grad[key] += deriv1_np[""V"" + key]\n        F_grad[key] += 2.0 * np.einsum(\'pqmm->pq\', deriv1_np[""TEI"" + key][:, :, :nocc, :nocc], optimize=True)\n        F_grad[key] -= 1.0 * np.einsum(\'pmmq->pq\', deriv1_np[""TEI"" + key][:, :nocc, :nocc, :], optimize=True)\n\n\n## Build I\'^x\n## I\'_pq^x = - (1/2) * [ fpp^x(Ppq + Pqp) + sum_rs (Prs * (4<rp|sq>^x - <rp|qs>^x - <rq|ps>^x)) * kronecker_delta(q,occ) + ...\n##         ... + sum_rst (Pqrst <pr|st>^x + Prqst <rp|st>^x + Prsqt <rs|pt>^x + Prstq <rs|tp>^x) ]\n#Ip_grad = {}\n#for atom in range(natoms):\n#    for pp in range(3):\n#        key = str(atom) + cart[pp]\n#\n#        Ip_grad[key] = np.zeros((nmo, nmo))\n#\n#        # I\'pq += fpp^x(Ppq + Pqp)\n#        Ip_grad[key] += np.einsum(""pr,rq->pq"", F_grad[key], Ppq, optimize=True)\n#        Ip_grad[key] += np.einsum(""qr,rp->pq"", Ppq, F_grad[key], optimize=True)\n#\n#        # I\'_pq += sum_rst (Pqrst <pr|st>^x + Prqst <rp|st>^x + Prsqt <rs|pt>^x + Prstq <rs|tp>^x)\n#        Ip_grad[key] += np.einsum(\'qrst,psrt->pq\', Ppqrs, deriv1_np[""TEI"" + key], optimize=True)\n#        Ip_grad[key] += np.einsum(\'rqst,rspt->pq\', Ppqrs, deriv1_np[""TEI"" + key], optimize=True)\n#        Ip_grad[key] += np.einsum(\'rsqt,rpst->pq\', Ppqrs, deriv1_np[""TEI"" + key], optimize=True)\n#        Ip_grad[key] += np.einsum(\'rstq,rtsp->pq\', Ppqrs, deriv1_np[""TEI"" + key], optimize=True)\n#\n#        # I\'_pq += sum_rs Prs(4<rp|sq>^x - <rp|qs>^x - <rq|ps>^x) kronecker_delta(q,occ)\n#        Ip_grad[key][:, :nocc] += 4.0 * np.einsum(\'rs,rspq->pq\', Ppq , deriv1_np[""TEI"" + key][:, :, :, :nocc], optimize=True)\n#        Ip_grad[key][:, :nocc] -= 1.0 * np.einsum(\'rs,rqps->pq\', Ppq , deriv1_np[""TEI"" + key][:, :nocc, :, :], optimize=True)\n#        Ip_grad[key][:, :nocc] -= 1.0 * np.einsum(\'rs,rpqs->pq\', Ppq , deriv1_np[""TEI"" + key][:, :, :nocc, :], optimize=True)\n#\n#        Ip_grad[key] *= -0.5\n\n\nHes = {};\nderiv2_mat = {}\nderiv2_np = {}\n\nHes[""N""] = np.zeros((3 * natoms, 3 * natoms))\nHes[""S""] = np.zeros((3 * natoms, 3 * natoms))\nHes[""T""] = np.zeros((3 * natoms, 3 * natoms))\nHes[""V""] = np.zeros((3 * natoms, 3 * natoms))\nHes[""TEI""] = np.zeros((3 * natoms, 3 * natoms))\nHes[""R""] = np.zeros((3 * natoms, 3 * natoms))\nHessian = np.zeros((3 * natoms, 3 * natoms))\n\n# 2nd Derivative of Nuclear Repulsion\nHes[""N""] = np.asarray(mol.nuclear_repulsion_energy_deriv2())\n\npsi4.core.print_out(""\\n\\n"")\nMat = psi4.core.Matrix.from_array(Hes[""N""])\nMat.name = ""NUCLEAR HESSIAN""\nMat.print_out()\n\n# 2nd Derivative of OEIs\nfor atom1 in range(natoms):\n    for atom2 in range(natoms):\n        for key in  oei_dict:\n            string = key + str(atom1) + str(atom2)\n            deriv2_mat[string] = mints.mo_oei_deriv2(oei_dict[key], atom1, atom2, C, C)\n            pq = 0\n            for p in range(3):\n                for q in range(3):\n                    map_key = string + cart[p] + cart[q]\n                    deriv2_np[map_key] = np.asarray(deriv2_mat[string][pq])\n                    pq += 1\n                    row = 3 * atom1 + p\n                    col = 3 * atom2 + q\n                    if key == ""S"":\n                        Hes[key][row][col] = np.einsum(""pq,pq->"", I, deriv2_np[map_key], optimize=True)\n                    else:\n                        Hes[key][row][col] = np.einsum(""pq,pq->"", Ppq, deriv2_np[map_key], optimize=True)\n\nfor key in Hes:\n    Mat = psi4.core.Matrix.from_array(Hes[key])\n    if key in oei_dict:\n        Mat.name = oei_dict[key] + "" HESSIAN""\n        Mat.print_out()\n        psi4.core.print_out(""\\n"")\n\n\nfor atom1 in range(natoms):\n    for atom2 in range(natoms):\n        string = ""TEI"" + str(atom1) + str(atom2)\n        deriv2_mat[string] = mints.mo_tei_deriv2(atom1, atom2, C, C, C, C)\n        pq = 0\n        for p in range(3):\n            for q in range(3):\n                map_key = string + cart[p] + cart[q]\n                deriv2_np[map_key] = np.asarray(deriv2_mat[string][pq])\n                pq = pq + 1\n                row = 3 * atom1 + p\n                col = 3 * atom2 + q\n\n                Hes[""TEI""][row][col] +=  2.0 * np.einsum(""pq,pqmm->"", ref_opdm, deriv2_np[map_key][:, :, :nocc, :nocc], optimize=True)\n                Hes[""TEI""][row][col] += -1.0 * np.einsum(""pq,pmmq->"", ref_opdm, deriv2_np[map_key][:, :nocc, :nocc, :], optimize=True)\n\n                Hes[""TEI""][row][col] +=  2.0 * np.einsum(""pq,pqmm->"", Ppq-ref_opdm, deriv2_np[map_key][:, :, :nocc, :nocc], optimize=True)\n                Hes[""TEI""][row][col] += -1.0 * np.einsum(""pq,pmmq->"", Ppq-ref_opdm, deriv2_np[map_key][:, :nocc, :nocc, :], optimize=True)\n\n                Hes[""TEI""][row][col] += np.einsum(""pqrs,prqs->"", Ppqrs, deriv2_np[map_key], optimize=True)\n\nTEIMat = psi4.core.Matrix.from_array(Hes[""TEI""])\nTEIMat.name = "" TEI HESSIAN""\nTEIMat.print_out()\n\n\n# Solve the first-order CPHF equations here,  G_aibj Ubj^x = Bai^x (Einstein summation),\n# where G is the electronic hessian,\n# G_aibj = delta_ij * delta_ab * epsilon_ij * epsilon_ab + 4 <ij|ab> - <ij|ba> - <ia|jb>,\n# where epsilon_ij = epsilon_i - epsilon_j, (epsilon -> orbital energies),\n# x refers to the perturbation, Ubj^x are the corresponsing CPHF coefficients\n# and Bai^x = Sai^x * epsilon_ii - Fai^x + Smn^x  * (2<am|in> - <am|ni>),\n# where, S^x =  del(S)/del(x), F^x =  del(F)/del(x).\n\n#psi4.core.print_out(""\\n\\n CPHF Coefficentsn:\\n"")\n\nB = {}\nU = {}\n# Build Bai^x\nfor atom in range(natoms):\n    for p in range(3):\n        key = str(atom) + cart[p]\n        B[key] =  np.einsum(""ai,ii->ai"", deriv1_np[""S"" + key][nocc:, :nocc], F[:nocc, :nocc], optimize=True)\n        B[key] -= F_grad[key][nocc:, :nocc]\n        B[key] +=  2.0 * np.einsum(""amin,mn->ai"", npERI[nocc:, :nocc, :nocc, :nocc], deriv1_np[""S"" + key][:nocc, :nocc], optimize=True)\n        B[key] += -1.0 * np.einsum(""amni,mn->ai"", npERI[nocc:, :nocc, :nocc, :nocc], deriv1_np[""S"" + key][:nocc, :nocc], optimize=True)\n\n        # Compute U^x, where\n        # U_ij^x = - 1/2 S_ij^a\n        # U_ai^x = G^(-1)_aibj * B_bj^x\n        # U_ia^x = - (U_ai^x + S_ai^x)\n        # U_ab^x = - 1/2 S_ab^a\n        U[key] = np.zeros((nmo, nmo))\n        U[key][:nocc, :nocc] = - 0.5 * deriv1_np[""S"" + key][:nocc, :nocc]\n        U[key][nocc:, :nocc] = np.einsum(""iajb,bj->ai"", Ginv, B[key], optimize=True)\n        U[key][:nocc, nocc:] = - (U[key][nocc:, :nocc] + deriv1_np[""S"" + key][nocc:, :nocc]).T\n        U[key][nocc:, nocc:] = - 0.5 * deriv1_np[""S"" + key][nocc:, nocc:]\n\n        #psi4.core.print_out(""\\n"")\n        #UMat = psi4.core.Matrix.from_array(U[key])\n        #UMat.name = key\n        #UMat.print_out()\n\n\n# Density Derivatives:\n# For SCF reference, dPpq/dx = 0, and dPpqrs/dx = 0.\n# For MP2, dPpq/dx and dPpqrs/dx both involve t2 derivatives\n#\n# Derivative of t2 amplitudes\nfor atom in range(natoms):\n    for p in range(3):\n        string = ""T2"" \n        key = str(atom) + cart[p]\n        map_key = string + key\n\n        # d{t2_ab^ij}/dx = ( <ij|ab>^x + sum_t [ ( Uti^x * <tj|ab> ) + ( Utj^x * <it|ab> ) + ( Uta^x * <ij|tb> ) + ( Utb^x * <ij|at> ) ] + ...\n        #                  ... + t_cb^ij * dF_ac/dx + t_ac^ij * dF_bc/dx - t_ab^kj * dF_ki/dx - t_ab^ik * dF_kj/dx ) / ( Fii + Fjj - Faa - Fbb )\n\n        # d{t2_ab^ij}/dx += <ij|ab>^x + sum_t [ ( Uti^x * <tj|ab> ) + ( Utj^x * <it|ab> ) + ( Uta^x * <ij|tb> ) + ( Utb^x * <ij|at> ) ]\n        deriv1_np[map_key] = copy.deepcopy(deriv1_np[""TEI"" + key][:nocc, nocc:, :nocc, nocc:].swapaxes(1,2))\n        deriv1_np[map_key] += np.einsum(\'ti,tjab->ijab\', U[key][:, :nocc], npERI[:, :nocc, nocc:, nocc:], optimize=True)\n        deriv1_np[map_key] += np.einsum(\'tj,itab->ijab\', U[key][:, :nocc], npERI[:nocc, :, nocc:, nocc:], optimize=True)\n        deriv1_np[map_key] += np.einsum(\'ta,ijtb->ijab\', U[key][:, nocc:], npERI[:nocc, :nocc, :, nocc:], optimize=True)\n        deriv1_np[map_key] += np.einsum(\'tb,ijat->ijab\', U[key][:, nocc:], npERI[:nocc, :nocc, nocc:, :], optimize=True)\n\n        # d{t2_ab^ij}/dx += t_cb^ij * dF_ac/dx\n        deriv1_np[map_key] += np.einsum(\'ijcb,ac->ijab\', t2, F_grad[key][nocc:, nocc:], optimize=True)\n        deriv1_np[map_key] += np.einsum(\'ijcb,ta,tc->ijab\', t2, U[key][:, nocc:], F[:, nocc:], optimize=True)\n        deriv1_np[map_key] += np.einsum(\'ijcb,tc,at->ijab\', t2, U[key][:, nocc:], F[nocc:, :], optimize=True)\n        deriv1_np[map_key] -= 0.5 * 4.0 * np.einsum(\'ijcb,mn,amcn->ijab\', t2, deriv1_np[""S"" + key][:nocc, :nocc], npERI[nocc:, :nocc, nocc:, :nocc], optimize=True)\n        deriv1_np[map_key] += 0.5 * 1.0 * np.einsum(\'ijcb,mn,acmn->ijab\', t2, deriv1_np[""S"" + key][:nocc, :nocc], npERI[nocc:, nocc:, :nocc, :nocc], optimize=True)\n        deriv1_np[map_key] += 0.5 * 1.0 * np.einsum(\'ijcb,mn,acnm->ijab\', t2, deriv1_np[""S"" + key][:nocc, :nocc], npERI[nocc:, nocc:, :nocc, :nocc], optimize=True)\n        deriv1_np[map_key] += 1.0 * 4.0 * np.einsum(\'ijcb,dm,adcm->ijab\', t2, U[key][nocc:, :nocc], npERI[nocc:, nocc:, nocc:, :nocc], optimize=True)\n        deriv1_np[map_key] -= 1.0 * 1.0 * np.einsum(\'ijcb,dm,acdm->ijab\', t2, U[key][nocc:, :nocc], npERI[nocc:, nocc:, nocc:, :nocc], optimize=True)\n        deriv1_np[map_key] -= 1.0 * 1.0 * np.einsum(\'ijcb,dm,acmd->ijab\', t2, U[key][nocc:, :nocc], npERI[nocc:, nocc:, :nocc, nocc:], optimize=True)\n        #\n        # d{t2_ab^ij}/dx += t_ac^ij * dF_bc/dx\n        deriv1_np[map_key] += np.einsum(\'ijac,bc->ijab\', t2, F_grad[key][nocc:, nocc:], optimize=True)\n        deriv1_np[map_key] += np.einsum(\'ijac,tb,tc->ijab\', t2, U[key][:, nocc:], F[:, nocc:], optimize=True)\n        deriv1_np[map_key] += np.einsum(\'ijac,tc,bt->ijab\', t2, U[key][:, nocc:], F[nocc:, :], optimize=True)\n        deriv1_np[map_key] -= 0.5 * 4.0 * np.einsum(\'ijac,mn,bmcn->ijab\', t2, deriv1_np[""S"" + key][:nocc, :nocc], npERI[nocc:, :nocc, nocc:, :nocc], optimize=True)\n        deriv1_np[map_key] += 0.5 * 1.0 * np.einsum(\'ijac,mn,bcmn->ijab\', t2, deriv1_np[""S"" + key][:nocc, :nocc], npERI[nocc:, nocc:, :nocc, :nocc], optimize=True)\n        deriv1_np[map_key] += 0.5 * 1.0 * np.einsum(\'ijac,mn,bcnm->ijab\', t2, deriv1_np[""S"" + key][:nocc, :nocc], npERI[nocc:, nocc:, :nocc, :nocc], optimize=True)\n        deriv1_np[map_key] += 1.0 * 4.0 * np.einsum(\'ijac,dm,bdcm->ijab\', t2, U[key][nocc:, :nocc], npERI[nocc:, nocc:, nocc:, :nocc], optimize=True)\n        deriv1_np[map_key] -= 1.0 * 1.0 * np.einsum(\'ijac,dm,bcdm->ijab\', t2, U[key][nocc:, :nocc], npERI[nocc:, nocc:, nocc:, :nocc], optimize=True)\n        deriv1_np[map_key] -= 1.0 * 1.0 * np.einsum(\'ijac,dm,bcmd->ijab\', t2, U[key][nocc:, :nocc], npERI[nocc:, nocc:, :nocc, nocc:], optimize=True)\n        #\n        # d{t2_ab^ij}/dx -= t_ab^kj * dF_ki/dx\n        deriv1_np[map_key] -= np.einsum(\'kjab,ki->ijab\', t2, F_grad[key][:nocc, :nocc], optimize=True)\n        deriv1_np[map_key] -= np.einsum(\'kjab,tk,ti->ijab\', t2, U[key][:, :nocc], F[:, :nocc], optimize=True)\n        deriv1_np[map_key] -= np.einsum(\'kjab,ti,kt->ijab\', t2, U[key][:, :nocc], F[:nocc, :], optimize=True)\n        deriv1_np[map_key] += 0.5 * 4.0 * np.einsum(\'kjab,mn,kmin->ijab\', t2, deriv1_np[""S"" + key][:nocc, :nocc], npERI[:nocc, :nocc, :nocc, :nocc], optimize=True)\n        deriv1_np[map_key] -= 0.5 * 1.0 * np.einsum(\'kjab,mn,kimn->ijab\', t2, deriv1_np[""S"" + key][:nocc, :nocc], npERI[:nocc, :nocc, :nocc, :nocc], optimize=True)\n        deriv1_np[map_key] -= 0.5 * 1.0 * np.einsum(\'kjab,mn,kinm->ijab\', t2, deriv1_np[""S"" + key][:nocc, :nocc], npERI[:nocc, :nocc, :nocc, :nocc], optimize=True)\n        deriv1_np[map_key] -= 1.0 * 4.0 * np.einsum(\'kjab,dm,kdim->ijab\', t2, U[key][nocc:, :nocc], npERI[:nocc, nocc:, :nocc, :nocc], optimize=True)\n        deriv1_np[map_key] += 1.0 * 1.0 * np.einsum(\'kjab,dm,kidm->ijab\', t2, U[key][nocc:, :nocc], npERI[:nocc, :nocc, nocc:, :nocc], optimize=True)\n        deriv1_np[map_key] += 1.0 * 1.0 * np.einsum(\'kjab,dm,kimd->ijab\', t2, U[key][nocc:, :nocc], npERI[:nocc, :nocc, :nocc, nocc:], optimize=True)\n        #\n        # d{t2_ab^ij}/dx -= t_ab^ik * dF_kj/dx\n        deriv1_np[map_key] -= np.einsum(\'ikab,kj->ijab\', t2, F_grad[key][:nocc, :nocc], optimize=True)\n        deriv1_np[map_key] -= np.einsum(\'ikab,tk,tj->ijab\', t2, U[key][:, :nocc], F[:, :nocc], optimize=True)\n        deriv1_np[map_key] -= np.einsum(\'ikab,tj,kt->ijab\', t2, U[key][:, :nocc], F[:nocc, :], optimize=True)\n        deriv1_np[map_key] += 0.5 * 4.0 * np.einsum(\'ikab,mn,kmjn->ijab\', t2, deriv1_np[""S"" + key][:nocc, :nocc], npERI[:nocc, :nocc, :nocc, :nocc], optimize=True)\n        deriv1_np[map_key] -= 0.5 * 1.0 * np.einsum(\'ikab,mn,kjmn->ijab\', t2, deriv1_np[""S"" + key][:nocc, :nocc], npERI[:nocc, :nocc, :nocc, :nocc], optimize=True)\n        deriv1_np[map_key] -= 0.5 * 1.0 * np.einsum(\'ikab,mn,kjnm->ijab\', t2, deriv1_np[""S"" + key][:nocc, :nocc], npERI[:nocc, :nocc, :nocc, :nocc], optimize=True)\n        deriv1_np[map_key] -= 1.0 * 4.0 * np.einsum(\'ikab,dm,kdjm->ijab\', t2, U[key][nocc:, :nocc], npERI[:nocc, nocc:, :nocc, :nocc], optimize=True)\n        deriv1_np[map_key] += 1.0 * 1.0 * np.einsum(\'ikab,dm,kjdm->ijab\', t2, U[key][nocc:, :nocc], npERI[:nocc, :nocc, nocc:, :nocc], optimize=True)\n        deriv1_np[map_key] += 1.0 * 1.0 * np.einsum(\'ikab,dm,kjmd->ijab\', t2, U[key][nocc:, :nocc], npERI[:nocc, :nocc, :nocc, nocc:], optimize=True)\n\n        # d{t2_ab^ij}/dx /= ( Fii + Fjj - Faa - Fbb )\n        deriv1_np[map_key] /= Dijab\n\n        # Make t2_tilde derivatives while we\'re at it\n        deriv1_np[""T2_tilde"" + key] = np.zeros((nocc, nocc, nvir, nvir))\n        deriv1_np[""T2_tilde"" + key] += 2.0 * deriv1_np[map_key] - deriv1_np[map_key].swapaxes(2,3)\n\n# Derivatives of MP2 Densities\ndPpq = {}\ndPpqrs = {}\nfor atom in range(natoms):\n    for p in range(3):\n        key = str(atom) + cart[p]\n\n        # MP2 Derivatives of OPDM\n        #\n        # Build OO block of MP2 OPDM derivative\n        # Pij = sum_kab [( t2(i,k,a,b) * t2_tilde(j,k,a,b) ) + ( t2(j,k,a,b) * t2_tilde(i,k,a,b) )]\n        dPij =  -1.0 * np.einsum(\'ikab,jkab->ij\', deriv1_np[""T2"" + key], t2_tilde, optimize=True)\n        dPij -=  1.0 * np.einsum(\'ikab,jkab->ij\', t2, deriv1_np[""T2_tilde"" + key], optimize=True)\n        dPij -=  1.0 * np.einsum(\'jkab,ikab->ij\', deriv1_np[""T2"" + key], t2_tilde, optimize=True)\n        dPij -=  1.0 * np.einsum(\'jkab,ikab->ij\', t2, deriv1_np[""T2_tilde"" + key], optimize=True)\n        #\n        # Build VV block of MP2 OPDM derivative\n        # Pab = sum_ijc [( t2(i,j,a,c) * t2_tilde(i,j,b,c) ) + ( t2(i,j,b,c) * t2_tilde(i,j,a,c) )]\n        dPab =  np.einsum(\'ijac,ijbc->ab\', deriv1_np[""T2"" + key], t2_tilde, optimize=True)\n        dPab += np.einsum(\'ijac,ijbc->ab\', t2, deriv1_np[""T2_tilde"" + key], optimize=True)\n        dPab += np.einsum(\'ijbc,ijac->ab\', deriv1_np[""T2"" + key], t2_tilde, optimize=True)\n        dPab += np.einsum(\'ijbc,ijac->ab\', t2, deriv1_np[""T2_tilde"" + key], optimize=True)\n        #\n        dPpq[key] = np.zeros((nmo, nmo))\n        dPpq[key][:nocc, :nocc] = dPij\n        dPpq[key][nocc:, nocc:] = dPab\n\n        # MP2 Derivatives of TPDM\n        dPijab = np.zeros((nocc, nocc, nvir, nvir))\n        #\n        # Build the ijab block of the MP2 TPDM derivative\n        dPijab += deriv1_np[""T2_tilde"" + key]\n        #Pijab = copy.deepcopy(t2_tilde)\n        #\n        dPpqrs[key] = np.zeros((nmo, nmo, nmo, nmo))\n        dPpqrs[key][:nocc, :nocc, nocc:, nocc:] += dPijab\n        dPpqrs[key][nocc:, nocc:, :nocc, :nocc] += dPijab.T\n\n\n# Build the response hessian now\nfor r in range(3 * natoms):\n    for c in range(3 * natoms):\n        atom1 = r // 3\n        atom2 = c // 3\n\n        p = r % 3\n        q = c % 3\n\n        key1  = str(atom1) + cart[p]\n        key2  = str(atom2) + cart[q]\n\n        # Ipq Contributions to the Hessian:\n        # d^2E/dxdy += P+(xy) sum_pq Ipq ( Upt^x * Uqt^y - Spt^x * Sqt^y)\n        #\n        Hes[""R""][r][c] +=  1.0 * np.einsum(\'pq,pt,qt->\', I, U[key1], U[key2], optimize=True)\n        Hes[""R""][r][c] +=  1.0 * np.einsum(\'pq,pt,qt->\', I, U[key2], U[key1], optimize=True)\n        #\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,pt,qt->\', I, deriv1_np[""S"" + key2], deriv1_np[""S"" + key1], optimize=True)\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,pt,qt->\', I, deriv1_np[""S"" + key1], deriv1_np[""S"" + key2], optimize=True)\n\n\n\n        # Ppq Contributions to the Hessian:\n        # d^2E/dxdt += P+(xy) sum_pq Ppq [ sum_t ( Upt^x * ftq^y + Utq^x * fpt^y ) ] \n        #\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pq,tp,tq->\', Ppq, U[key1], F_grad[key2], optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pq,tp,tq->\', Ppq, U[key2], F_grad[key1], optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pq,tq,pt->\', Ppq, U[key1], F_grad[key2], optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pq,tq,pt->\', Ppq, U[key2], F_grad[key1], optimize=True)\n        #\n        # d^2E/dxdy += P+(xy) sum_pq Ppq ( sum_tm [ Utm^x * ( <pm||qt>^y + <pt||qm>^y ) ] )\n        #\n        Hes[""R""][r][c] += 2.0 * np.einsum(\'pq,tm,pqmt->\', Ppq, U[key1][:, :nocc], deriv1_np[""TEI"" + key2][:, :, :nocc, :], optimize=True)\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,tm,ptmq->\', Ppq, U[key1][:, :nocc], deriv1_np[""TEI"" + key2][:, :, :nocc, :], optimize=True)\n        Hes[""R""][r][c] += 2.0 * np.einsum(\'pq,tm,pqtm->\', Ppq, U[key1][:, :nocc], deriv1_np[""TEI"" + key2][:, :, :, :nocc], optimize=True)\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,tm,pmtq->\', Ppq, U[key1][:, :nocc], deriv1_np[""TEI"" + key2][:, :nocc, :, :], optimize=True)\n        Hes[""R""][r][c] += 2.0 * np.einsum(\'pq,tm,pqmt->\', Ppq, U[key2][:, :nocc], deriv1_np[""TEI"" + key1][:, :, :nocc, :], optimize=True)\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,tm,ptmq->\', Ppq, U[key2][:, :nocc], deriv1_np[""TEI"" + key1][:, :, :nocc, :], optimize=True)\n        Hes[""R""][r][c] += 2.0 * np.einsum(\'pq,tm,pqtm->\', Ppq, U[key2][:, :nocc], deriv1_np[""TEI"" + key1][:, :, :, :nocc], optimize=True)\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,tm,pmtq->\', Ppq, U[key2][:, :nocc], deriv1_np[""TEI"" + key1][:, :nocc, :, :], optimize=True)\n        #\n        # d^2E/dxdy += P+(xy) sum_pq Ppq ( sum_tv [ Utp^x * Uvq^y * ftv ] )\n        #\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pq,tp,vq,tv->\', Ppq, U[key1], U[key2], F, optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pq,tp,vq,tv->\', Ppq, U[key2], U[key1], F, optimize=True)\n        #\n        # d^2E/dxdy += P+(xy) sum_pq Ppq ( sum_tvm [ Utp^x * Uvm^y * ( <tm||qv> + <tv||qm> ) ] )\n        #\n        Hes[""R""][r][c] += 2.0 * np.einsum(\'pq,tp,vm,tmqv->\', Ppq, U[key1], U[key2][:, :nocc], npERI[:, :nocc, :, :], optimize=True)\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,tp,vm,tmvq->\', Ppq, U[key1], U[key2][:, :nocc], npERI[:, :nocc, :, :], optimize=True)\n        Hes[""R""][r][c] += 2.0 * np.einsum(\'pq,tp,vm,tvqm->\', Ppq, U[key1], U[key2][:, :nocc], npERI[:, :, :, :nocc], optimize=True)\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,tp,vm,tvmq->\', Ppq, U[key1], U[key2][:, :nocc], npERI[:, :, :nocc, :], optimize=True)\n        Hes[""R""][r][c] += 2.0 * np.einsum(\'pq,tp,vm,tmqv->\', Ppq, U[key2], U[key1][:, :nocc], npERI[:, :nocc, :, :], optimize=True)\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,tp,vm,tmvq->\', Ppq, U[key2], U[key1][:, :nocc], npERI[:, :nocc, :, :], optimize=True)\n        Hes[""R""][r][c] += 2.0 * np.einsum(\'pq,tp,vm,tvqm->\', Ppq, U[key2], U[key1][:, :nocc], npERI[:, :, :, :nocc], optimize=True)\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,tp,vm,tvmq->\', Ppq, U[key2], U[key1][:, :nocc], npERI[:, :, :nocc, :], optimize=True)\n        #\n        # d^2E/dxdy += P+(xy) sum_pq Ppq ( sum_tvm [ Utq^x * Uvm^y * ( <pm||tv> + <pv||tm> ) ] )\n        #\n        Hes[""R""][r][c] += 2.0 * np.einsum(\'pq,tq,vm,pmtv->\', Ppq, U[key1], U[key2][:, :nocc], npERI[:, :nocc, :, :], optimize=True)\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,tq,vm,pmvt->\', Ppq, U[key1], U[key2][:, :nocc], npERI[:, :nocc, :, :], optimize=True)\n        Hes[""R""][r][c] += 2.0 * np.einsum(\'pq,tq,vm,pvtm->\', Ppq, U[key1], U[key2][:, :nocc], npERI[:, :, :, :nocc], optimize=True)\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,tq,vm,pvmt->\', Ppq, U[key1], U[key2][:, :nocc], npERI[:, :, :nocc, :], optimize=True)\n        Hes[""R""][r][c] += 2.0 * np.einsum(\'pq,tq,vm,pmtv->\', Ppq, U[key2], U[key1][:, :nocc], npERI[:, :nocc, :, :], optimize=True)\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,tq,vm,pmvt->\', Ppq, U[key2], U[key1][:, :nocc], npERI[:, :nocc, :, :], optimize=True)\n        Hes[""R""][r][c] += 2.0 * np.einsum(\'pq,tq,vm,pvtm->\', Ppq, U[key2], U[key1][:, :nocc], npERI[:, :, :, :nocc], optimize=True)\n        Hes[""R""][r][c] -= 1.0 * np.einsum(\'pq,tq,vm,pvmt->\', Ppq, U[key2], U[key1][:, :nocc], npERI[:, :, :nocc, :], optimize=True)\n        #\n        # d^2E/dxdy += P+(xy) sum_pq Ppq ( sum_tvm [ 1/2 * Utm^x * Uvm^y * ( <pt||qv> + <pv||qt> ) ] )\n        #\n        Hes[""R""][r][c] += 0.5 * 2.0 * np.einsum(\'pq,tm,vm,ptqv->\', Ppq, U[key1][:, :nocc], U[key2][:, :nocc], npERI, optimize=True)\n        Hes[""R""][r][c] -= 0.5 * 1.0 * np.einsum(\'pq,tm,vm,ptvq->\', Ppq, U[key1][:, :nocc], U[key2][:, :nocc], npERI, optimize=True)\n        Hes[""R""][r][c] += 0.5 * 2.0 * np.einsum(\'pq,tm,vm,pvqt->\', Ppq, U[key1][:, :nocc], U[key2][:, :nocc], npERI, optimize=True)\n        Hes[""R""][r][c] -= 0.5 * 1.0 * np.einsum(\'pq,tm,vm,pvtq->\', Ppq, U[key1][:, :nocc], U[key2][:, :nocc], npERI, optimize=True)\n        Hes[""R""][r][c] += 0.5 * 2.0 * np.einsum(\'pq,tm,vm,ptqv->\', Ppq, U[key2][:, :nocc], U[key1][:, :nocc], npERI, optimize=True)\n        Hes[""R""][r][c] -= 0.5 * 1.0 * np.einsum(\'pq,tm,vm,ptvq->\', Ppq, U[key2][:, :nocc], U[key1][:, :nocc], npERI, optimize=True)\n        Hes[""R""][r][c] += 0.5 * 2.0 * np.einsum(\'pq,tm,vm,pvqt->\', Ppq, U[key2][:, :nocc], U[key1][:, :nocc], npERI, optimize=True)\n        Hes[""R""][r][c] -= 0.5 * 1.0 * np.einsum(\'pq,tm,vm,pvtq->\', Ppq, U[key2][:, :nocc], U[key1][:, :nocc], npERI, optimize=True)\n\n\n        \n        # Ppqrs Contributions to the Hessian:\n        # d^2E/dxdy += P+(xy) sum_pqrs ( sum_t [ Utp^x * <tq|rs>^y + Utq^x * <pt|rs>^y + Utr^x * <pq|ts>^y + Uts^x * <pq|rt>^y ] )\n        #\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tp,trqs->\', Ppqrs, U[key1], deriv1_np[""TEI"" + key2], optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tq,prts->\', Ppqrs, U[key1], deriv1_np[""TEI"" + key2], optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tr,ptqs->\', Ppqrs, U[key1], deriv1_np[""TEI"" + key2], optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,ts,prqt->\', Ppqrs, U[key1], deriv1_np[""TEI"" + key2], optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tp,trqs->\', Ppqrs, U[key2], deriv1_np[""TEI"" + key1], optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tq,prts->\', Ppqrs, U[key2], deriv1_np[""TEI"" + key1], optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tr,ptqs->\', Ppqrs, U[key2], deriv1_np[""TEI"" + key1], optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,ts,prqt->\', Ppqrs, U[key2], deriv1_np[""TEI"" + key1], optimize=True)\n        #\n        # d^2E/dxdy += P+(xy) sum_pqrs ( sum_tv [ Utp^x * Uvq^y * <tv|rs> + Utp^x * Uvr^y * <tq|vs> + Utp^x * Uvs^y * <tq|rv> + ...\n        #                                   ... + Utq^x * Uvr^y * <pt|vs> + Utq^x * Uvs^y * <pt|rv> + Utr^x * Uvs^y * <pq|tv> ] )\n        #\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tp,vq,tvrs->\', Ppqrs, U[key1], U[key2], npERI, optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tp,vr,tqvs->\', Ppqrs, U[key1], U[key2], npERI, optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tp,vs,tqrv->\', Ppqrs, U[key1], U[key2], npERI, optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tq,vr,ptvs->\', Ppqrs, U[key1], U[key2], npERI, optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tq,vs,ptrv->\', Ppqrs, U[key1], U[key2], npERI, optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tr,vs,pqtv->\', Ppqrs, U[key1], U[key2], npERI, optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tp,vq,tvrs->\', Ppqrs, U[key2], U[key1], npERI, optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tp,vr,tqvs->\', Ppqrs, U[key2], U[key1], npERI, optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tp,vs,tqrv->\', Ppqrs, U[key2], U[key1], npERI, optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tq,vr,ptvs->\', Ppqrs, U[key2], U[key1], npERI, optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tq,vs,ptrv->\', Ppqrs, U[key2], U[key1], npERI, optimize=True)\n        Hes[""R""][r][c] += 1.0 * np.einsum(\'pqrs,tr,vs,pqtv->\', Ppqrs, U[key2], U[key1], npERI, optimize=True)\n\n\n\n        # dPpq/da Contibutions to the Hessian:\n        # d^2E/dxdy += 1/2 P+(xy) sum_pq dPpq/dx ( fpq^y + Uqp^y * fqq + Upq^y * fpp + sum_tm [ Utm^y * ( <pm||qt> + <pt||qm> ) ] )\n        #\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pq,pq->\', dPpq[key1], F_grad[key2], optimize=True)\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pq,pq->\', dPpq[key2], F_grad[key1], optimize=True)\n        #\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pq,qp,qq->\', dPpq[key1], U[key2], F, optimize=True)\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pq,pq,pp->\', dPpq[key1], U[key2], F, optimize=True)\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pq,qp,qq->\', dPpq[key2], U[key1], F, optimize=True)\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pq,pq,pp->\', dPpq[key2], U[key1], F, optimize=True)\n        #\n        Hes[""R""][r][c] += 0.5 * 2.0 * np.einsum(\'pq,tm,pmqt->\', dPpq[key1], U[key2][:, :nocc], npERI[:, :nocc, :, :], optimize=True)\n        Hes[""R""][r][c] -= 0.5 * 1.0 * np.einsum(\'pq,tm,pmtq->\', dPpq[key1], U[key2][:, :nocc], npERI[:, :nocc, :, :], optimize=True)\n        Hes[""R""][r][c] += 0.5 * 2.0 * np.einsum(\'pq,tm,ptqm->\', dPpq[key1], U[key2][:, :nocc], npERI[:, :, :, :nocc], optimize=True)\n        Hes[""R""][r][c] -= 0.5 * 1.0 * np.einsum(\'pq,tm,ptmq->\', dPpq[key1], U[key2][:, :nocc], npERI[:, :, :nocc, :], optimize=True)\n        Hes[""R""][r][c] += 0.5 * 2.0 * np.einsum(\'pq,tm,pmqt->\', dPpq[key2], U[key1][:, :nocc], npERI[:, :nocc, :, :], optimize=True)\n        Hes[""R""][r][c] -= 0.5 * 1.0 * np.einsum(\'pq,tm,pmtq->\', dPpq[key2], U[key1][:, :nocc], npERI[:, :nocc, :, :], optimize=True)\n        Hes[""R""][r][c] += 0.5 * 2.0 * np.einsum(\'pq,tm,ptqm->\', dPpq[key2], U[key1][:, :nocc], npERI[:, :, :, :nocc], optimize=True)\n        Hes[""R""][r][c] -= 0.5 * 1.0 * np.einsum(\'pq,tm,ptmq->\', dPpq[key2], U[key1][:, :nocc], npERI[:, :, :nocc, :], optimize=True)\n\n\n\n        #dPpqrs/da Contributions to the Hessian:\n        #  d^2E/dxdy += 1/2 P+(xy) sum_pqrs dPpqrs/dx ( <pq|rs>^y + sum_t [ Utp^y * <tq|rs> + Utq^y * <pt|rs> + Utr^y * <pq|ts> + Uts^y * <pq|rt> ] )\n        #\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pqrs,prqs->\', dPpqrs[key1], deriv1_np[""TEI"" + key2], optimize=True)\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pqrs,prqs->\', dPpqrs[key2], deriv1_np[""TEI"" + key1], optimize=True)\n        #\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pqrs,tp,tqrs->\', dPpqrs[key1], U[key2], npERI, optimize=True)\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pqrs,tq,ptrs->\', dPpqrs[key1], U[key2], npERI, optimize=True)\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pqrs,tr,pqts->\', dPpqrs[key1], U[key2], npERI, optimize=True)\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pqrs,ts,pqrt->\', dPpqrs[key1], U[key2], npERI, optimize=True)\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pqrs,tp,tqrs->\', dPpqrs[key2], U[key1], npERI, optimize=True)\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pqrs,tq,ptrs->\', dPpqrs[key2], U[key1], npERI, optimize=True)\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pqrs,tr,pqts->\', dPpqrs[key2], U[key1], npERI, optimize=True)\n        Hes[""R""][r][c] += 0.5 * 1.0 * np.einsum(\'pqrs,ts,pqrt->\', dPpqrs[key2], U[key1], npERI, optimize=True)\n\n\n# Build Total Hessian\nfor key in Hes:\n    Hessian += Hes[key]\n\n# Symmetrize Hessian\nHessian = (Hessian + Hessian.T)/2\n\nMat = psi4.core.Matrix.from_array(Hessian)\nMat.name = "" TOTAL HESSIAN""\nMat.print_out()\n\nH_psi4 = psi4.core.Matrix.from_list([\n[-3.6130997071,        0.0000000000,       -0.0000000000,        1.8065498535,       -0.0000000000,       -0.0000000000,        1.8065498535,        0.0000000000,        0.0000000000],\n[ 0.0000000000,        8.4484978101,        0.0000000000,       -0.0000000000,       -4.2242489050,       -4.7117763859,        0.0000000000,       -4.2242489050,        4.7117763859],\n[-0.0000000000,        0.0000000000,        3.7558758529,       -0.0000000000,       -4.3809411905,       -1.8779379264,        0.0000000000,        4.3809411905,       -1.8779379264],\n[ 1.8065498535,       -0.0000000000,       -0.0000000000,       -1.8756582110,        0.0000000000,        0.0000000000,        0.0691083574,        0.0000000000,        0.0000000000],\n[-0.0000000000,       -4.2242489050,       -4.3809411906,        0.0000000000,        4.3722044693,        4.5463587882,       -0.0000000000,       -0.1479555642,       -0.1654175976],\n[-0.0000000000,       -4.7117763860,       -1.8779379264,        0.0000000000,        4.5463587882,        1.8072072616,        0.0000000000,        0.1654175977,        0.0707306648],\n[ 1.8065498535,        0.0000000000,        0.0000000000,        0.0691083574,       -0.0000000000,        0.0000000000,       -1.8756582110,       -0.0000000000,       -0.0000000000],\n[ 0.0000000000,       -4.2242489050,        4.3809411906,        0.0000000000,       -0.1479555642,        0.1654175976,       -0.0000000000,        4.3722044693,       -4.5463587882],\n[ 0.0000000000,        4.7117763860,       -1.8779379264,        0.0000000000,       -0.1654175977,        0.0707306648,       -0.0000000000,       -4.5463587882,        1.8072072616]\n])\nH_python_mat = psi4.core.Matrix.from_array(Hessian)\npsi4.compare_matrices(H_psi4, H_python_mat, 9, ""RHF-HESSIAN-TEST"")\n'"
Moller-Plesset/MP3-SO.py,8,"b'""""""\nReference implementation of the MP3 correlation energy utilizing antisymmetrized\nspin-orbitals from an RHF reference.\n\nReferences:\n- Equations from [Szabo:1996]\n""""""\n\n__authors__    = ""Daniel G. A. Smith""\n__credits__   = [""Daniel G. A. Smith"", ""Dominic A. Sirianni""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2017-05-23""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'cc-pvdz\',\n                  \'scf_type\': \'pk\',\n                  \'mp2_type\': \'conv\',\n                  \'mp2_type\': \'conv\',\n                  \'freeze_core\': \'false\',\n                  \'e_convergence\': 1e-8,\n                  \'d_convergence\': 1e-8})\n\n# First compute RHF energy using Psi4\nscf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n# Grab data from \nC = wfn.Ca()\nndocc = wfn.doccpi()[0]\nnmo = wfn.nmo()\nSCF_E = wfn.energy()\neps = np.asarray(wfn.epsilon_a())\n\n\n# Compute size of ERI tensor in GB\nERI_Size = (nmo ** 4) * 8e-9\nprint(\'Size of the ERI/MO tensor will be %4.2f GB.\' % ERI_Size)\nmemory_footprint = ERI_Size * 2.5\nif memory_footprint > numpy_memory:\n    clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                    limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\n#Make spin-orbital MO\nt=time.time()\nprint(\'Starting ERI build and spin AO -> spin-orbital MO transformation...\')\nmints = psi4.core.MintsHelper(wfn.basisset())\nMO = np.asarray(mints.mo_spin_eri(C, C))\neps = np.repeat(eps, 2)\nnso = nmo * 2\n\nprint(\'..finished transformation in %.3f seconds.\\n\' % (time.time() - t))\n\n# Update nocc and nvirt\nnocc = ndocc * 2\nnvirt = MO.shape[0] - nocc\n\n# Build epsilon tensor\neocc = eps[:nocc]\nevir = eps[nocc:]\nepsilon = 1/(eocc.reshape(-1, 1, 1, 1) + eocc.reshape(-1, 1, 1) - evir.reshape(-1, 1) - evir)\n\n# Create occupied and virtual slices\no = slice(0, nocc)\nv = slice(nocc, MO.shape[0])\n\n# MP2 Correlation: [Szabo:1996] pp. 352, Eqn 6.72\nMP2corr_E = 0.25 * np.einsum(\'abrs,rsab,abrs\', MO[o, o, v, v], MO[v, v, o, o], epsilon)\nMP2total_E = SCF_E + MP2corr_E\nprint(\'MP2 correlation energy:      %16.10f\' % MP2corr_E)\nprint(\'MP2 total energy:            %16.10f\' % MP2total_E)\n\n# Compare to Psi4\npsi4.compare_values(psi4.energy(\'MP2\'), MP2total_E, 6, \'MP2 Energy\')\n\n# MP3 Correlation: [Szabo:1996] pp. 353, Eqn. 6.75\neqn1 = 0.125 * np.einsum(\'abrs,cdab,rscd,abrs,cdrs->\', MO[o, o, v, v], MO[o, o, o, o], MO[v, v, o, o], epsilon, epsilon)\neqn2 = 0.125 * np.einsum(\'abrs,rstu,tuab,abrs,abtu\', MO[o, o, v, v], MO[v, v, v, v], MO[v, v, o, o], epsilon, epsilon)\neqn3 = np.einsum(\'abrs,cstb,rtac,absr,acrt\', MO[o, o, v, v], MO[o, v, v, o], MO[v, v, o, o], epsilon, epsilon)\n\nMP3corr_E = eqn1 + eqn2 + eqn3\nMP3total_E = MP2total_E + MP3corr_E\nprint(\'\\nMP3 correlation energy:      %16.10f\' % MP3corr_E)\nprint(\'MP3 total energy:            %16.10f\' % MP3total_E)\n\n# Compare to Psi4\npsi4.compare_values(psi4.energy(\'MP3\'), MP3total_E, 6, \'MP3 Energy\')\n\n\n\n'"
Moller-Plesset/MP3.py,22,"b'""""""\nReference implementation for the correlation energy of MP3 with an RHF reference.\n\nReferences:\n- Equations from [Szabo:1996]\n""""""\n\n__authors__    = ""Daniel G. A. Smith""\n__credits__   = [""Daniel G. A. Smith"", ""Dominic A. Sirianni""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2017-05-23""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'aug-cc-pvdz\',\n                  \'scf_type\': \'pk\',\n                  \'guess\': \'core\',\n                  \'mp2_type\': \'conv\',\n                  \'freeze_core\': \'false\',\n                  \'e_convergence\': 1e-8,\n                  \'d_convergence\': 1e-8})\n\n# First compute RHF energy using Psi4\nscf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n# Coefficient Matrix\nC = np.array(wfn.Ca())\n# Double occupied orbitals\nndocc = wfn.doccpi()[0]\n# Number of molecular orbitals\nnmo = wfn.nmo()\n# SCF energy\nSCF_E = wfn.energy()\n# Orbital energies\neps = wfn.epsilon_a()\neps = np.array([eps.get(x) for x in range(C.shape[0])])\n\n# Compute size of ERI tensor in GB\nERI_Size = (nmo**4)*8.0 / 1E9\nprint(""Size of the ERI tensor will be %4.2f GB."" % ERI_Size)\nmemory_footprint = ERI_Size*2.5\nif memory_footprint > numpy_memory:\n    clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nI = np.array(mints.ao_eri())\nI = I.reshape(nmo, nmo, nmo, nmo)\n\nprint(\'\\nTotal time taken for ERI integrals: %.3f seconds.\' % (time.time()-t))\n\nt=time.time()\n\n# Complete the AOpqrs -> MOiajb step\nMO = np.einsum(\'rJ,pqrs->pqJs\', C, I)\nMO = np.einsum(\'pI,pqJs->IqJs\', C, MO)\nMO = np.einsum(\'sB,IqJs->IqJB\', C, MO)\nMO = np.einsum(\'qA,IqJB->IAJB\', C, MO)\n\n# (pq|rs) -> <ps|rq>\nMO = MO.swapaxes(1, 2)\n\nprint(\'\\nTotal time taken for integral transformation: %.f seconds\' % (time.time()-t))\nprint(\'Shape of MO integrals %s \\n\' % str(MO.shape))\n\n# Build epsilon tensor\neocc = eps[:ndocc]\nevirt = eps[ndocc:]\nepsilon = 1/(eocc.reshape(-1, 1, 1, 1) + eocc.reshape(-1, 1, 1) - evirt.reshape(-1, 1) - evirt)\n\n# Build o and v slices\no = slice(0, ndocc)\nv = slice(ndocc, MO.shape[0])\n\n### MP2 correlation energy\n\nMP2corr_E = 2 * np.einsum(\'abrs,rsab,abrs\', MO[o, o, v, v], MO[v, v, o, o], epsilon)\nMP2corr_E -= np.einsum(\'abrs,rsba,abrs\', MO[o, o, v, v], MO[v, v, o, o], epsilon)\nMP2total_E = SCF_E + MP2corr_E\nprint(\'MP2 correlation energy: %16.8f\' % MP2corr_E)\nprint(\'MP2 total energy:       %16.8f\' % MP2total_E)\npsi4.compare_values(psi4.energy(\'MP2\'), MP2total_E, 6, \'MP2 Energy\')\n\nprint(\'\\n Starting MP3 energy...\')\nt = time.time()\n\n# MP3 Correlation energy\n\n# Prefactors taken from terms in unnumbered expression for spatial-orbital MP3\n# energy on [Szabo:1996] pp. (bottom) 367 - (top) 368. Individual equations taken\n# from [Szabo:1996] Tbl. 6.2 pp. 364-365\n\n# Equation 1: 3rd order diagram 1\nMP3corr_E =   2.0 * np.einsum(\'abru,ruts,tsab,abru,abts\', MO[o, o, v, v], MO[v, v, v, v], MO[v, v, o, o], epsilon, epsilon) \n# Equation 2: 3rd order diagram 2 \nMP3corr_E +=  2.0 * np.einsum(\'adrs,cbad,rscb,adrs,cbrs\', MO[o, o, v, v], MO[o, o, o, o], MO[v, v, o, o], epsilon, epsilon)\n# Equation 3: 3rd order diagram 3\nMP3corr_E += -4.0 * np.einsum(\'acrt,rbsc,stab,acrt,abst\', MO[o, o, v, v], MO[v, o, v, o], MO[v, v, o, o], epsilon, epsilon)\n# Equation 4: 3rd order diagram 4\nMP3corr_E += -4.0 * np.einsum(\'bcrt,rasb,stac,bcrt,acst\', MO[o, o, v, v], MO[v, o, v, o], MO[v, v, o, o], epsilon, epsilon)\n# Equation 5: 3rd order diagram 5\nMP3corr_E +=  8.0 * np.einsum(\'acrt,btsc,rsab,acrt,abrs\', MO[o, o, v, v], MO[o, v, v, o], MO[v, v, o, o], epsilon, epsilon)\n# Equation 6: 3rd order diagram 6\nMP3corr_E +=  2.0 * np.einsum(\'cbrt,atsc,rsab,cbrt,abrs\', MO[o, o, v, v], MO[o, v, v, o], MO[v, v, o, o], epsilon, epsilon)\n# Equation 7: 3rd order diagram 7\nMP3corr_E += -1.0 * np.einsum(\'acrs,dbac,srdb,acrs,dbrs\', MO[o, o, v, v], MO[o, o, o, o], MO[v, v, o, o], epsilon, epsilon)\n# Equation 8: 3rd order diagram 8\nMP3corr_E += -1.0 * np.einsum(\'abrt,trus,usab,abtr,abus\', MO[o, o, v, v], MO[v, v, v, v], MO[v, v, o, o], epsilon, epsilon)\n# Equation 9: 3rd order diagram 9\nMP3corr_E +=  2.0 * np.einsum(\'bcrt,arbs,tsac,cbrt,acst\', MO[o, o, v, v], MO[o, v, o, v], MO[v, v, o, o], epsilon, epsilon)\n# Equation 10: 3rd order diagram 10\nMP3corr_E +=  2.0 * np.einsum(\'cbrt,rasb,stac,cbrt,acst\', MO[o, o, v, v], MO[v, o, v, o], MO[v, v, o, o], epsilon, epsilon)\n# Equation 11: 3rd order diagram 11\nMP3corr_E += -4.0 * np.einsum(\'abrs,scat,rtbc,abrs,cbrt\', MO[o, o, v, v], MO[v, o, o, v], MO[v, v, o, o], epsilon, epsilon)\n# Equation 12: 3rd order diagram 12\nMP3corr_E += -4.0 * np.einsum(\'bcrt,atsc,rsab,bctr,abrs\', MO[o, o, v, v], MO[o, v, v, o], MO[v, v, o, o], epsilon, epsilon)\n\nprint(\'...took %.3f seconds to compute MP3 correlation energy.\\n\' % (time.time()-t))\n\nprint(\'Third order energy:     %16.8f\' % MP3corr_E)\nMP3corr_E += MP2corr_E\nMP3total_E = SCF_E + MP3corr_E\nprint(\'MP3 correlation energy: %16.8f\' % MP3corr_E)\nprint(\'MP3 total energy:       %16.8f\' % MP3total_E)\npsi4.compare_values(psi4.energy(\'MP3\'), MP3total_E, 6, \'MP3 Energy\')\n\n\n'"
Moller-Plesset/MPn.py,4,"b'""""""\nReference implementation of MP3 with focus on auto-generating einsum expressions\n\nReferences:\nEquations & Goldstone diagram rules from [Szabo:1996]\n""""""\n\n__authors__   = ""Daniel G. A. Smith""\n__credits__   = [""Daniel G. A. Smith"", ""Dominic A. Sirianni""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2017-05-23""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'aug-cc-pvdz\',\n                  \'scf_type\': \'pk\',\n                  \'guess\': \'core\',\n                  \'mp2_type\': \'conv\',\n                  \'freeze_core\': \'false\',\n                  \'e_convergence\': 1e-8,\n                  \'d_convergence\': 1e-8})\n\n# First compute RHF energy using Psi4\nscf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n# Grab data from \nC = wfn.Ca()\nndocc = wfn.doccpi()[0]\nnmo = wfn.nmo()\nSCF_E = wfn.energy()\neps = np.asarray(wfn.epsilon_a())\n\n# Compute size of ERI tensor in GB\nERI_Size = (nmo ** 4) * 8e-9\nprint(\'Size of the ERI/MO tensor will be %4.2f GB.\' % ERI_Size)\nmemory_footprint = ERI_Size * 2.5\nif memory_footprint > numpy_memory:\n    clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                    limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\n#Make spin-orbital MO\nt=time.time()\nprint(\'Starting ERI build and AO -> MO transformation...\')\nmints = psi4.core.MintsHelper(wfn.basisset())\nMO = np.asarray(mints.mo_eri(C, C, C, C))\n\n# (pq|rs) -> <pr|qs>\nMO = MO.swapaxes(1, 2)\n\nprint(\'..finished transformation in %.3f seconds.\\n\' % (time.time() - t))\nprint(\'Shape of MO integrals %s \\n\' % str(MO.shape))\n\n# Build epsilon tensor\neocc = eps[:ndocc]\nevirt = eps[ndocc:]\nepsilon = 1/(eocc.reshape(-1, 1, 1, 1) + eocc.reshape(-1, 1, 1) - evirt.reshape(-1, 1) - evirt)\n\ndef MP_term(n, h, l, factor, string):\n    """"""Computes value of given Goldstone diagram from MBPT expansion.\n\n    Computes the contribution of a given Goldstone diagram to \n    the nth-order Moller--Plesset correlation energy, according\n    to the rules on pp. 363 of [Szabo:1996].\n\n    Parameters\n    ----------\n    n : int\n        MPn order of theory\n    h : int\n        Number of holes\n    l : int\n        Number of loops\n    factor : int or float\n        Symmetry considerations\n    string : str\n        Summation string MO tensor, then energy denominators\n\n    Returns\n    -------\n    term : float\n        Contribution to MPn correlation energy for given Goldstone diagram.\n    """"""   \n    def get_slice(char):\n        """"""Returns slice object for MPn expansion.\n\n        Occupied and/or virtual orbital slices are returned according to index\n        convention in [Szabo:1996]:\n\n            Occupied indices: abcdefgh\n            Virtual indicies: rstuv\n\n        Parameters\n        ----------\n        char : str\n            Orbital index belonging to desired slice.\n\n        Returns\n        -------\n        slice \n            Slice object corresponding to orbital subset (occupied or virtual)\n            to which the provided orbital index belongs.\n        """"""\n        if char in \'abcdefgh\':\n            return slice(0, ndocc)\n        else:\n            return slice(ndocc, MO.shape[0])\n \n    # Compute prefactor\n    pref = (-1)**(h+l) * (2**l) * float(factor)\n\n    # Get slices\n    slices = string.split(\',\')\n    if len(slices)!=(n*2-1):\n        clean()\n        raise Exception(\'Number of terms does not match the order of pertubation theory\')\n\n    # Create views\n    views = []\n    \n    # MO views\n    for term in range(n):\n        tmp_slice = slices[term]\n        tmp_slice = [get_slice(x) for x in tmp_slice]\n        views.append(MO[tmp_slice[0], tmp_slice[1], tmp_slice[2], tmp_slice[3]])\n    \n    # Epsilon views \n    for term in range(n-1):\n        views.append(epsilon)\n    \n    # Compute term!\n    string += \'->\'\n    term = np.einsum(string, *views)\n    term *= pref\n    return term\n\n### MP2\n\nMP2corr_E = MP_term(2, 2, 2, 0.5, \'abrs,rsab,abrs\')\nMP2corr_E += MP_term(2, 2, 1, 0.5, \'abrs,rsba,abrs\')\nMP2total_E = SCF_E + MP2corr_E\nprint(\'MP2 correlation energy: %.8f\' % MP2corr_E)\nprint(\'MP2 total energy:       %.8f\' % MP2total_E)\npsi4.compare_values(psi4.energy(\'MP2\'), MP2total_E, 6, \'MP2 Energy\')\n\n### MP3 Correlation Energy\n### Terms taken from [Szabo:1996] Tbl. 6.2, pp. 364-365\n\nprint(\'\\nStarting MP3 correlation energy...\')\n# MP3 Eqn 1: 3rd order diagram 1\nMP3corr_E =  MP_term(3, 2, 2, 0.5, \'abru,ruts,tsab,abru,abts\') \n# MP3 Eqn 2: 3rd order diagram 2\nMP3corr_E += MP_term(3, 4, 2, 0.5, \'adrs,cbad,rscb,adrs,cbrs\')\n# MP3 Eqn 3: 3rd order diagram 3\nMP3corr_E += MP_term(3, 3, 2, 1.0, \'acrt,rbsc,stab,acrt,abst\')\n# MP3 Eqn 4: 3rd order diagram 4 \nMP3corr_E += MP_term(3, 3, 2, 1.0, \'bcrt,rasb,stac,bcrt,acst\')\n# MP3 Eqn 5: 3rd order diagram 5 \nMP3corr_E += MP_term(3, 3, 3, 1.0, \'acrt,btsc,rsab,acrt,abrs\')\n# MP3 Eqn 6: 3rd order diagram 6 \nMP3corr_E += MP_term(3, 3, 1, 1.0, \'cbrt,atsc,rsab,cbrt,abrs\')\n# MP3 Eqn 7: 3rd order diagram 7 \nMP3corr_E += MP_term(3, 4, 1, 0.5, \'acrs,dbac,srdb,acrs,dbrs\')\n# MP3 Eqn 8: 3rd order diagram 8 \nMP3corr_E += MP_term(3, 2, 1, 0.5, \'abrt,trus,usab,abtr,abus\')\n# MP3 Eqn 9: 3rd order diagram 9\nMP3corr_E += MP_term(3, 3, 1, 1.0, \'bcrt,arbs,tsac,cbrt,acst\')\n# MP3 Eqn 10: 3rd order diagram 10\nMP3corr_E += MP_term(3, 3, 1, 1.0, \'cbrt,rasb,stac,cbrt,acst\')\n# MP3 Eqn 11: 3rd order diagram 11\nMP3corr_E += MP_term(3, 3, 2, 1.0, \'abrs,scat,rtbc,abrs,cbrt\')\n# MP3 Eqn 12: 3rd order diagram 12\nMP3corr_E += MP_term(3, 3, 2, 1.0, \'bcrt,atsc,rsab,bctr,abrs\')\n\nprint(\'...took %.3f seconds to compute MP3 correlation energy.\\n\' % (time.time() - t))\n\nprint(\'Third order energy:     %.8f\' % MP3corr_E)\nMP3corr_E += MP2corr_E\nMP3total_E = SCF_E + MP3corr_E\nprint(\'MP3 correlation energy: %.8f\' % MP3corr_E)\nprint(\'MP3 total energy:       %.8f\' % MP3total_E)\n\n# Compare to Psi4\npsi4.compare_values(psi4.energy(\'MP3\'), MP3total_E, 6, \'MP3 Energy\')\n\n\n'"
Moller-Plesset/UMP2_Spin_Adapted.py,5,"b'""""""\nA reference implementation of MP2 from a UHF reference in the spatial orbital basis.\nIntended to show basic example of spin adapting a spin orbital code.\n""""""\n\n__authors__ = ""Matthew McAllister Davis""\n__credits__ = [""Matthew McAllister Davis"", ""Justin M. Turney""]\n__copyright__ = ""(c) 2014-2020, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2020-01-08""\n\nimport psi4\nimport numpy as np\nfrom time import time\n\nnp.set_printoptions(precision=10, linewidth=200, suppress=True)\npsi4.core.be_quiet()\npsi4.core.set_output_file(""output.dat"")\npsi4.set_memory(\'2 GB\')\n\n# Computing on ethane cation!\nmol = psi4.geometry(""""""\n        1 2\n        O\n        H 1 1.1\n        H 1 1.1 2 104.0\n        symmetry c1\n        """""")\n\ncompare = True\npsi4.set_options({\n    \'basis\': \'sto-3g\',\n    \'reference\': \'uhf\',\n    \'mp2_type\': \'conv\',\n    \'e_convergence\': 1e-12,\n    \'d_convergence\': 1e-10,\n    \'scf_type\': \'pk\'\n})\n\n# Get SCF wavefunction and basic info\nprint(\'Starting RHF.\')\nt = time()\ne, wfn = psi4.energy(\'scf\', return_wfn=True, mol=mol)\nt = time() - t\nprint(f\'Computed @RHF {e:16.10f} Eh in {t:4.6f} s.\\n\')\nnmo = wfn.nmo()\nnalpha = wfn.nalpha()\nnbeta = wfn.nbeta()\n\n# size of occ and vir spaces for alpha and beta spin\nocca = nalpha\nvira = nmo - nalpha\noccb = nbeta\nvirb = nmo - nbeta\n\n# Core hamiltonian in AO basis\nh = wfn.H().np\n\n# Orbital eigenvalues for MP2 denominators\nepsa = wfn.epsilon_a().np\nepsb = wfn.epsilon_b().np\nepsa_occ = epsa[:occa]\nepsa_vir = epsa[occa:]\nepsb_occ = epsb[:occb]\nepsb_vir = epsb[occb:]\n\n# Make a MintsHelper for integral transformation\nmints = psi4.core.MintsHelper(wfn.basisset())\n\n# occ and vir slices for alpha and beta\noa = slice(0, nalpha)\nva = slice(nalpha, nmo)\nob = slice(0, nbeta)\nvb = slice(nbeta, nmo)\n\n# AO->MO coefficients, occ and vir subsets\nCoa = wfn.Ca_subset(""AO"", ""OCC"")\nCob = wfn.Cb_subset(""AO"", ""OCC"")\nCva = wfn.Ca_subset(""AO"", ""VIR"")\nCvb = wfn.Cb_subset(""AO"", ""VIR"")\n\n# Build MO basis TEI\nt = time()\nprint(\'Transforming TEI from AO -> MO.\')\nI = mints.ao_eri()\nmo_ijab = mints.mo_transform(I, Coa, Cva, Coa, Cva).np\nmo_iJaB = mints.mo_transform(I, Coa, Cva, Cob, Cvb).np\nmo_IJAB = mints.mo_transform(I, Cob, Cvb, Cob, Cvb).np\nt = time() - t\nprint(f\'Transformed TEI in {t:4.6f} s.\\n\')\n\n# Form antisymmetrized MO integrals\n# 0 1 2 3\n# i j a b\n# (0,2,1,3) -> chemists notation to physicists notation\n# (0,2,3,1) -> chemists notation to physicists notation and interchange a,b\nt = time()\nprint(\'Antisymmetrizing TEI.\')\nijab = mo_ijab.transpose(0, 2, 1, 3) - mo_ijab.transpose(0, 2, 3, 1)\niJaB = mo_iJaB.transpose(0, 2, 1, 3)\nIJAB = mo_IJAB.transpose(0, 2, 1, 3) - mo_IJAB.transpose(0, 2, 3, 1)\nt = time() - t\nprint(f\'Antisymmetrized TEI in {t:4.6f} s.\\n\')\n\nt = time()\nprint(\'Building denominator arrays and T2 arrays.\')\n\n# Compute denominator arrays\nDijab = epsa_occ.reshape(-1, 1, 1, 1) + epsa_occ.reshape(\n    -1, 1, 1) - epsa_vir.reshape(-1, 1) - epsa_vir\ntijab = ijab / Dijab\nDiJaB = epsa_occ.reshape(-1, 1, 1, 1) + epsb_occ.reshape(\n    -1, 1, 1) - epsa_vir.reshape(-1, 1) - epsb_vir\ntiJaB = iJaB / DiJaB\nDIJAB = epsb_occ.reshape(-1, 1, 1, 1) + epsb_occ.reshape(\n    -1, 1, 1) - epsb_vir.reshape(-1, 1) - epsb_vir\ntIJAB = IJAB / DIJAB\nt = time() - t\nprint(f\'Denominator and T2 arrays finished in {t:4.6f} s.\\n\')\n\n# Compute the MP2 energy\nt = time()\nprint(\'Computing the UMP2 energy.\')\nemp2 = (1 / 4) * np.einsum(\'ijab,ijab->\', tijab, ijab)\nemp2 += np.einsum(\'ijab,ijab->\', tiJaB, iJaB)\nemp2 += (1 / 4) * np.einsum(\'ijab,ijab->\', tIJAB, IJAB)\nt = time() - t\nprint(f""Computed MP2 correction {emp2:16.10f} Eh in {t:4.6f} s."")\nif compare:\n    emp2_psi = psi4.energy(\'mp2\', mol=mol)\n    print(""Does the psi4numpy energy match Psi4? "",\n          np.allclose(emp2_psi - e, emp2))\n'"
Moller-Plesset/sDF-MP2.py,12,"b'""""""\r\nA reference implementation of stochastic orbital resolution of identity\r\n(or density-fitted) MP2 (sRI-MP2) from a RHF reference.\r\n\r\nReference: \r\nStochastic Formulation of the Resolution of Identity: Application to\r\nSecond Order Moller-Plesset Perturbation Theory\r\nJ. Chem. Theory Comput., 2017, 13 (10), pp 4605-4610\r\nDOI: 10.1021/acs.jctc.7b00343\r\n\r\nTyler Y. Takeshita \r\nDepartment of Chemistry, University of California Berkeley\r\nMaterials Sciences Division, Lawrence Berkeley National Laboratory\r\n\r\nWibe A. de Jong\r\nComputational Research Division, Lawrence Berkeley National Laboratory\r\n\r\nDaniel Neuhauser\r\nDepartment of Chemistry and Biochemistry, University of California, Los Angeles\r\n\r\nRoi Baer\r\nFritz Harber Center for Molecular Dynamics, Institute of Chemistry, The Hebrew University of Jerusalem\r\n\r\nEran Rabani\r\nDepartment of Chemistry, University of California Berkeley\r\nMaterials Sciences Division, Lawrence Berkeley National Laboratory\r\nThe Sackler Center for Computational Molecular Science, Tel Aviv University\r\n""""""\r\n\r\n__authors__   = [""Tyler Y. Takeshita"", ""Daniel G. A. Smith""]\r\n__credits__   = [""Tyler Y. Takeshita"", ""Daniel G. A. Smith""]\r\n\r\n__copyright__ = ""(c) 2014-2017, The Psi4NumPy Developers""\r\n__license__   = ""BSD-3-Clause""\r\n__date__      = ""2018-04-14""\r\n\r\nimport numpy as np\r\nimport psi4\r\nimport time\r\n\r\n# Set numpy defaults\r\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\r\n# psi4.set_output_file(""output.dat"")\r\n\r\n# ==> Geometry <==\r\n# Note: Symmetry was turned off\r\nmol = psi4.geometry(""""""\r\nO\r\nH 1 0.96\r\nH 1 0.96 2 104\r\nsymmetry c1\r\n"""""")\r\n\r\n# How many samples to run?\r\nnsample = 5000\r\n\r\n# ==> Basis sets <==\r\npsi4.set_options({\r\n    \'basis\': \'aug-cc-pvdz\',\r\n    \'scf_type\': \'df\',\r\n    \'e_convergence\': 1e-10,\r\n    \'d_convergence\': 1e-10\r\n})\r\n\r\nwfn = psi4.core.Wavefunction.build(mol, psi4.core.get_global_option(\'basis\'))\r\n\r\n# Build auxiliary basis set\r\naux = psi4.core.BasisSet.build(mol, ""DF_BASIS_SCF"", """", ""RIFIT"", ""aug-cc-pVDZ"") \r\n\r\n# Get orbital basis & build zero basis\r\norb = wfn.basisset()\r\n\r\n# The zero basis set\r\nzero_bas = psi4.core.BasisSet.zero_ao_basis_set()\r\n\r\n# Build instance of MintsHelper\r\nmints = psi4.core.MintsHelper(orb)\r\n\r\n# ==> Build Density-Fitted Integrals <==\r\n\r\n# Build (P|pq) raw 3-index ERIs, dimension (1, Naux, nbf, nbf)\r\nPpq = mints.ao_eri(zero_bas, aux, orb, orb)\r\n\r\n# Build & invert Coulomb metric, dimension (1, Naux, 1, Naux)\r\nmetric = mints.ao_eri(zero_bas, aux, zero_bas, aux)\r\nmetric.power(-0.5, 1.e-14)\r\n\r\n# Remove excess dimensions of Ppq, & metric\r\nPpq = np.squeeze(Ppq)\r\nmetric = np.squeeze(metric)\r\n\r\n# Build the Qso object\r\nQpq = np.einsum(\'QP,Ppq->Qpq\', metric, Ppq)\r\n\r\n# ==> Perform HF <==\r\nenergy, scf_wfn = psi4.energy(\'scf\', return_wfn=True)\r\nprint(""Finished SCF..."")\r\n\r\n# ==> AO -> MO Transformation of integrals <==\r\n# Get the MO coefficients and energies\r\nevecs = np.array(scf_wfn.epsilon_a())\r\n\r\nCo = scf_wfn.Ca_subset(""AO"", ""OCC"")\r\nCv = scf_wfn.Ca_subset(""AO"", ""VIR"")\r\n\r\nQia = np.einsum(""Qpq,pi,qa->Qia"", Qpq, Co, Cv, optimize=True)\r\n\r\nnocc = scf_wfn.nalpha()\r\nnvirt = scf_wfn.nmo() - nocc\r\n\r\ndenom = 1.0 / (evecs[:nocc].reshape(-1, 1, 1, 1) + evecs[:nocc].reshape(-1, 1, 1) -\r\n               evecs[nocc:].reshape(-1, 1) - evecs[nocc:])\r\n\r\nt = time.time()\r\ne_srimp2 = 0.0\r\nprint(""Transformed ERIs..."")\r\n\r\n# Loop over samples to reduce stochastic noise\r\nprint(""Starting sample loop..."")\r\nfor x in range(nsample):\r\n\r\n    # ==> Build Stochastic Integral Matrices <==\r\n    # Create two random vector\r\n    vec = np.random.choice([-1, 1], size=(Qia.shape[0]))\r\n    vecp = np.random.choice([-1, 1], size=(Qia.shape[0]))\r\n\r\n    # Generate first R matrices\r\n    ia = np.einsum(""Q,Qia->ia"", vec, Qia)\r\n    iap = np.einsum(""Q,Qia->ia"", vecp, Qia)\r\n\r\n    # ==> Calculate a single stochastic RI-MP2 (sRI-MP2) sample <==\r\n\r\n    # Caculate sRI-MP2 correlation energy\r\n    e_srimp2 += 2.0 * np.einsum(\'ijab,ia,ia,jb,jb->\', denom, ia, iap, ia, iap)\r\n    e_srimp2 -= np.einsum(\'ijab,ia,ib,jb,ja->\', denom, ia, iap, ia, iap)\r\n\r\ne_srimp2 /= float(nsample)\r\ntotal_time = time.time() - t\r\ntime_per_sample = total_time / float(nsample)\r\n\r\n# Print sample energy to output\r\nprint(""\\nNumber of samples:                 % 16d"" % nsample)\r\nprint(""Total time (s):                    % 16.2f"" % total_time)\r\nprint(""Time per sample (us):              % 16.2f"" % (time_per_sample * 1.e6))\r\nprint(""sRI-MP2 correlation sample energy: % 16.10f"" % e_srimp2)\r\n\r\npsi_mp2_energy = psi4.energy(""MP2"")\r\nmp2_correlation_energy = psi4.variable(""MP2 CORRELATION ENERGY"")\r\n\r\nprint(""\\nRI-MP2 energy:                     % 16.10f"" % mp2_correlation_energy)\r\nprint(""Sample error                       % 16.10f"" % (e_srimp2 - mp2_correlation_energy))\r\n'"
Self-Consistent-Field/RHF.py,17,"b'""""""\nA restricted Hartree-Fock script using the Psi4NumPy Formalism\n\nReferences:\n- Algorithm taken from [Szabo:1996], pp. 146\n- Equations taken from [Szabo:1996]\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'500 MB\')\npsi4.core.set_output_file(""output.dat"", False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'cc-pvdz\',\n                  \'scf_type\': \'pk\',\n                  \'e_convergence\': 1e-8})\n\n# Set defaults\nmaxiter = 40\nE_conv = 1.0E-6\nD_conv = 1.0E-3\n\n# Integral generation from Psi4\'s MintsHelper\nwfn = psi4.core.Wavefunction.build(mol, psi4.core.get_global_option(\'BASIS\'))\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nS = np.asarray(mints.ao_overlap())\n\n# Get nbf and ndocc for closed shell molecules\nnbf = S.shape[0]\nndocc = wfn.nalpha()\n\nprint(\'\\nNumber of occupied orbitals: %d\' % ndocc)\nprint(\'Number of basis functions: %d\' % nbf)\n\n# Run a quick check to make sure everything will fit into memory\nI_Size = (nbf**4) * 8.e-9\nprint(""\\nSize of the ERI tensor will be %4.2f GB."" % I_Size)\n\n# Estimate memory usage\nmemory_footprint = I_Size * 1.5\nif I_Size > numpy_memory:\n    psi4.core.clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                    limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\n# Compute required quantities for SCF\nV = np.asarray(mints.ao_potential())\nT = np.asarray(mints.ao_kinetic())\nI = np.asarray(mints.ao_eri())\n\nprint(\'\\nTotal time taken for integrals: %.3f seconds.\' % (time.time() - t))\nt = time.time()\n\n# Build H_core: [Szabo:1996] Eqn. 3.153, pp. 141\nH = T + V\n\n# Orthogonalizer A = S^(-1/2) using Psi4\'s matrix power.\nA = mints.ao_overlap()\nA.power(-0.5, 1.e-16)\nA = np.asarray(A)\n\n# Calculate initial core guess: [Szabo:1996] pp. 145\nHp = A.dot(H).dot(A)            # Eqn. 3.177\ne, C2 = np.linalg.eigh(Hp)      # Solving Eqn. 1.178\nC = A.dot(C2)                   # Back transform, Eqn. 3.174\nCocc = C[:, :ndocc]\n\nD = np.einsum(\'pi,qi->pq\', Cocc, Cocc) # [Szabo:1996] Eqn. 3.145, pp. 139\n\nprint(\'\\nTotal time taken for setup: %.3f seconds\' % (time.time() - t))\n\nprint(\'\\nStart SCF iterations:\\n\')\nt = time.time()\nE = 0.0\nEnuc = mol.nuclear_repulsion_energy()\nEold = 0.0\nDold = np.zeros_like(D)\n\nE_1el = np.einsum(\'pq,pq->\', H + H, D) + Enuc\nprint(\'One-electron energy = %4.16f\' % E_1el)\n\nfor SCF_ITER in range(1, maxiter + 1):\n\n    # Build fock matrix: [Szabo:1996] Eqn. 3.154, pp. 141\n    J = np.einsum(\'pqrs,rs->pq\', I, D)\n    K = np.einsum(\'prqs,rs->pq\', I, D)\n    F = H + J * 2 - K\n\n    diis_e = np.einsum(\'ij,jk,kl->il\', F, D, S) - np.einsum(\'ij,jk,kl->il\', S, D, F)\n    diis_e = A.dot(diis_e).dot(A)\n    dRMS = np.mean(diis_e**2)**0.5\n\n    # SCF energy and update: [Szabo:1996], Eqn. 3.184, pp. 150\n    SCF_E = np.einsum(\'pq,pq->\', F + H, D) + Enuc\n\n    print(\'SCF Iteration %3d: Energy = %4.16f   dE = % 1.5E   dRMS = %1.5E\' % (SCF_ITER, SCF_E, (SCF_E - Eold), dRMS))\n    if (abs(SCF_E - Eold) < E_conv) and (dRMS < D_conv):\n        break\n\n    Eold = SCF_E\n    Dold = D\n\n    # Diagonalize Fock matrix: [Szabo:1996] pp. 145              \n    Fp = A.dot(F).dot(A)                   # Eqn. 3.177\n    e, C2 = np.linalg.eigh(Fp)             # Solving Eqn. 1.178\n    C = A.dot(C2)                          # Back transform, Eqn. 3.174\n    Cocc = C[:, :ndocc]                                                              \n    D = np.einsum(\'pi,qi->pq\', Cocc, Cocc) # [Szabo:1996] Eqn. 3.145, pp. 139\n\n    if SCF_ITER == maxiter:\n        psi4.core.clean()\n        raise Exception(""Maximum number of SCF cycles exceeded."")\n\nprint(\'Total time for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\nprint(\'Final SCF energy: %.8f hartree\' % SCF_E)\nSCF_E_psi = psi4.energy(\'SCF\')\npsi4.compare_values(SCF_E_psi, SCF_E, 6, \'SCF Energy\')\n'"
Self-Consistent-Field/RHF_DIIS.py,21,"b'""""""\nImplementation of RHF with convergence acceleration via Direct\nInversion of the Iteravite Subspace (DIIS).\n\nReferences:\n- RHF algorithm & equations from [Szabo:1996]\n- DIIS algorithm adapted from [Sherrill:1998] & [Pulay:1980:393]\n- DIIS equations taken from [Sherrill:1998], [Pulay:1980:393], & [Pulay:1969:197]\n""""""\n\n__authors__   = ""Daniel G. A. Smith""\n__credits__   = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2017-9-30""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\',False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\n# Set some options\npsi4.set_options({""basis"": ""cc-pvdz"",\n                  ""scf_type"": ""pk"",\n                  ""e_convergence"": 1e-8})\n\n# Set defaults\nmaxiter = 40\nE_conv = 1.0E-8\nD_conv = 1.0E-3\n\n# Integral generation from Psi4\'s MintsHelper\nwfn = psi4.core.Wavefunction.build(mol, psi4.core.get_global_option(\'BASIS\'))\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nS = np.asarray(mints.ao_overlap())\n\n# Get nbf and ndocc for closed shell molecules\nnbf = wfn.nso()\nndocc = wfn.nalpha()\n\nprint(\'\\nNumber of occupied orbitals: %d\' % ndocc)\nprint(\'Number of basis functions: %d\' % nbf)\n\n# Run a quick check to make sure everything will fit into memory\nI_Size = (nbf**4) * 8.e-9\nprint(""\\nSize of the ERI tensor will be %4.2f GB."" % I_Size)\n\n# Estimate memory usage\nmemory_footprint = I_Size * 1.5\nif I_Size > numpy_memory:\n    clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                    limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\n# Compute required quantities for SCF\nV = np.asarray(mints.ao_potential())\nT = np.asarray(mints.ao_kinetic())\nI = np.asarray(mints.ao_eri())\n\nprint(\'\\nTotal time taken for integrals: %.3f seconds.\' % (time.time() - t))\n\nt = time.time()\n\n# Build H_core\nH = T + V\n\n# Orthogonalizer A = S^(-1/2)\nA = mints.ao_overlap()\nA.power(-0.5, 1.e-16)\nA = np.asarray(A)\n\n# Calculate initial core guess: [Szabo:1996] pp. 145\nHp = A.dot(H).dot(A)            # Eqn. 3.177\ne, C2 = np.linalg.eigh(Hp)      # Solving Eqn. 1.178\nC = A.dot(C2)                   # Back transform, Eqn. 3.174\nCocc = C[:, :ndocc]\n\nD = np.einsum(\'pi,qi->pq\', Cocc, Cocc) # [Szabo:1996] Eqn. 3.145, pp. 139\n\nprint(\'\\nTotal time taken for setup: %.3f seconds\' % (time.time() - t))\n\nprint(\'\\nStart SCF iterations:\\n\')\nt = time.time()\nE = 0.0\nEnuc = mol.nuclear_repulsion_energy()\nEold = 0.0\n\nFock_list = []\nDIIS_error = []\n\nfor SCF_ITER in range(1, maxiter + 1):\n\n    # Build fock matrix\n    J = np.einsum(\'pqrs,rs->pq\', I, D)\n    K = np.einsum(\'prqs,rs->pq\', I, D)\n    F = H + J * 2 - K\n\n    # DIIS error build w/ HF analytic gradient ([Pulay:1969:197])\n    diis_e = np.einsum(\'ij,jk,kl->il\', F, D, S) - np.einsum(\'ij,jk,kl->il\', S, D, F)\n    diis_e = A.dot(diis_e).dot(A)\n    Fock_list.append(F)\n    DIIS_error.append(diis_e)\n    dRMS = np.mean(diis_e**2)**0.5\n\n    # SCF energy and update: [Szabo:1996], Eqn. 3.184, pp. 150\n    SCF_E = np.einsum(\'pq,pq->\', F + H, D) + Enuc\n\n    print(\'SCF Iteration %3d: Energy = %4.16f   dE = % 1.5E   dRMS = %1.5E\'\n          % (SCF_ITER, SCF_E, (SCF_E - Eold), dRMS))\n    if (abs(SCF_E - Eold) < E_conv) and (dRMS < D_conv):\n        break\n\n    Eold = SCF_E\n\n    if SCF_ITER >= 2:\n\n        # Limit size of DIIS vector\n        diis_count = len(Fock_list)\n        if diis_count > 6:\n            # Remove oldest vector\n            del Fock_list[0]\n            del DIIS_error[0]\n            diis_count -= 1\n\n        # Build error matrix B, [Pulay:1980:393], Eqn. 6, LHS\n        B = np.empty((diis_count + 1, diis_count + 1))\n        B[-1, :] = -1\n        B[:, -1] = -1\n        B[-1, -1] = 0\n        for num1, e1 in enumerate(DIIS_error):\n            for num2, e2 in enumerate(DIIS_error):\n                if num2 > num1: continue\n                val = np.einsum(\'ij,ij->\', e1, e2)\n                B[num1, num2] = val\n                B[num2, num1] = val\n\n        # normalize\n        B[:-1, :-1] /= np.abs(B[:-1, :-1]).max()\n\n        # Build residual vector, [Pulay:1980:393], Eqn. 6, RHS\n        resid = np.zeros(diis_count + 1)\n        resid[-1] = -1\n\n        # Solve Pulay equations, [Pulay:1980:393], Eqn. 6\n        ci = np.linalg.solve(B, resid)\n\n        # Calculate new fock matrix as linear\n        # combination of previous fock matrices\n        F = np.zeros_like(F)\n        for num, c in enumerate(ci[:-1]):\n            F += c * Fock_list[num]\n\n    # Diagonalize Fock matrix\n    Fp = A.dot(F).dot(A)\n    e, C2 = np.linalg.eigh(Fp)\n    C = A.dot(C2)\n    Cocc = C[:, :ndocc]\n    D = np.einsum(\'pi,qi->pq\', Cocc, Cocc)\n\n    if SCF_ITER == maxiter:\n        psi4.core.clean()\n        raise Exception(""Maximum number of SCF cycles exceeded."")\n\nprint(\'Total time for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\nprint(\'Final SCF energy: %.8f hartree\' % SCF_E)\n\n# Compare to Psi4\nSCF_E_psi = psi4.energy(\'SCF\')\npsi4.compare_values(SCF_E_psi, SCF_E, 6, \'SCF Energy\')\n'"
Self-Consistent-Field/RHF_EFP.py,38,"b'""""""\nReference implementation of RHF/EFP using libefp through PylibEFP.\n\nRequirements:\nNumPy\nPylibEFP >=0.1\nlibEFP >=1.5b1\nPsi4 >=1.2a1.dev507 (c. late Aug 2017)\n\nReferences:\nSCF in Python from @dgasmith\'s most excellent Self-Consistent-Field/RHF.py .\nSCF/EFP in Psi4 by @andysim, @edeprince3, @ilyak, @loriab\nlibefp from [Kaliman:2013:2284]\n\n""""""\nfrom __future__ import division\nfrom __future__ import print_function\n\n__authors__   = ""Lori A. Burns""\n__credits__   = [""Andrew C. Simmonett"", ""A. Eugene DePrince III"", ""Ilya A. Kaliman"", ""Lori A. Burns"", ""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2017-08-28""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\nimport pylibefp\n\nimport os\n\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'500 MB\')\npsi4.core.set_output_file(""output.dat"", False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\ndef set_qm_atoms(mol, efpobj):\n    """"""Provides list of coordinates of quantum mechanical atoms from\n    psi4.core.Molecule `mol` to pylibefp.core.efp() `efpobj`.\n\n    """"""\n    ptc = []\n    coords = []\n    for iat in range(mol.natom()):\n        ptc.append(mol.charge(iat))\n        coords.append(mol.x(iat))\n        coords.append(mol.y(iat))\n        coords.append(mol.z(iat))\n\n    efpobj.set_point_charges(ptc, coords)\n\n\ndef modify_Fock_permanent(mol, nbf, efpobj):\n    """"""Computes array of the EFP contribution to the potential felt by\n    QM atoms, due to permanent EFP moments, for a SCF procedure.\n\n    Requires psi4.core.Molecule `mol`, number of basis functions `nbf`,\n    and pylibefp.core.efp() `efpobj`.\n\n    """"""\n    # get composition counts from libefp\n    n_fr = efpobj.get_frag_count()\n    natoms = efpobj.get_frag_atom_count()\n\n    # get multipoles count, pos\'n, values from libefp\n    #   charge + dipoles + quadrupoles + octupoles = 20\n    n_mp = efpobj.get_multipole_count()\n    xyz_mp = np.asarray(efpobj.get_multipole_coordinates()).reshape(n_mp, 3)\n    val_mp = np.asarray(efpobj.get_multipole_values()).reshape(n_mp, 20)\n\n    #                    0  X  Y  Z  XX   YY   ZZ   XY   XZ   YZ\n    prefacs = np.array([ 1, 1, 1, 1, 1/3, 1/3, 1/3, 2/3, 2/3, 2/3,\n        1/15, 1/15, 1/15, 3/15, 3/15, 3/15, 3/15, 3/15, 3/15, 6/15])\n    #   XXX   YYY   ZZZ   XXY   XXZ   XYY   YYZ   XZZ   YZZ   XYZ\n\n    # EFP permanent moment contribution to the Fock Matrix\n    V2 = np.zeros((nbf, nbf))\n\n    # Cartesian basis one-electron EFP perturbation\n    efp_ints = np.zeros((20, nbf, nbf))\n\n    for imp in range(n_mp):\n        origin = xyz_mp[imp]\n\n        # get EFP multipole integrals from Psi4\n        p4_efp_ints = mints.ao_efp_multipole_potential(origin=origin)\n        for pole in range(20):\n            efp_ints[pole] = np.asarray(p4_efp_ints[pole])\n\n        # add frag atom Z into multipole charge (when pos\'n of atom matches mp)\n        for ifr in range(n_fr):\n            atoms = efpobj.get_frag_atoms(ifr)\n            for iat in range(natoms[ifr]):\n                xyz_atom = [atoms[iat][\'x\'], atoms[iat][\'y\'], atoms[iat][\'z\']]\n                if np.allclose(xyz_atom, origin, atol=1e-10):\n                    val_mp[imp, 0] += atoms[iat][\'Z\']\n\n        # scale multipole integrals by multipole magnitudes. result goes into V\n        for pole in range(20):\n            efp_ints[pole] *= -prefacs[pole] * val_mp[imp, pole]\n            V2 += efp_ints[pole]\n\n    return V2\n\n\ndef modify_Fock_induced(nbf, efpobj, verbose=1):\n    """"""Returns shared matrix containing the EFP contribution to the potential\n    felt by QM atoms, due to EFP induced dipoles, in a SCF procedure.\n\n    """"""\n    # get induced dipoles count, pos\'n, values from libefp\n    #   dipoles = 3\n    n_id = efpobj.get_induced_dipole_count()\n    xyz_id = np.asarray(efpobj.get_induced_dipole_coordinates(verbose=verbose)).reshape(n_id, 3)\n    val_id = np.asarray(efpobj.get_induced_dipole_values(verbose=verbose)).reshape(n_id, 3)\n    val_idt = np.asarray(efpobj.get_induced_dipole_conj_values(verbose=verbose)).reshape(n_id, 3)\n\n    # take average of induced dipole and conjugate\n    val_id = (val_id + val_idt) * 0.5\n\n    # EFP induced dipole contribution to the Fock Matrix\n    V2 = np.zeros((nbf, nbf))\n\n    # Cartesian basis one-electron EFP perturbation\n    field_ints = np.zeros((3, nbf, nbf))\n\n    for iid in range(n_id):\n        origin = xyz_id[iid]\n\n        # get electric field integrals from Psi4\n        p4_field_ints = mints.electric_field(origin=origin)\n        for pole in range(3):\n            field_ints[pole] = np.asarray(p4_field_ints[pole])\n\n        # scale field integrals by induced dipole magnitudes. result goes into V\n        for pole in range(3):\n            field_ints[pole] *= -val_id[iid, pole]\n            V2 += field_ints[pole]\n\n    return V2\n\n\ndef field_fn(xyz):\n    """"""Compute electric field from electrons in ab initio part for libefp polarization calculation.\n\n    Parameters\n    ----------\n    xyz : list\n        3 * n_pt (flat) array of points at which to compute electric field\n\n    Returns\n    -------\n    list\n        3 * n_pt (flat) array of electric field at points in `xyz`.\n\n    Notes\n    -----\n    Function signature defined by libefp, so function uses number of\n    basis functions `nbf` and density matrix `efp_density` from global\n    namespace.\n\n    """"""\n    global nbf\n    global efp_density\n\n    points = np.array(xyz).reshape(-1, 3)\n    n_pt = len(points)\n\n    # Cartesian basis one-electron EFP perturbation\n    field_ints = np.zeros((3, nbf, nbf))\n\n    # Electric field at points\n    field = np.zeros((n_pt, 3))\n\n    for ipt in range(n_pt):\n        # get electric field integrals from Psi4\n        p4_field_ints = mints.electric_field(origin=points[ipt])\n\n        field[ipt] = [np.vdot(efp_density, np.asarray(p4_field_ints[0])) * 2.0,  # Ex\n                      np.vdot(efp_density, np.asarray(p4_field_ints[1])) * 2.0,  # Ey\n                      np.vdot(efp_density, np.asarray(p4_field_ints[2])) * 2.0]  # Ez\n\n    field = np.reshape(field, 3 * n_pt)\n\n    return field\n\n\nref_V2 = np.array([\n [ -0.02702339455725,    -0.00631509453548,    -0.00000280084677,    -0.00060226624612,     0.00000155158400,  -0.00452046694500,    -0.00000038595163,    -0.00008299120179,     0.00000021380548,    -0.00090142990526,      0.00000473984815,     0.00000183105977,    -0.00091126369988,     0.00000235760871,    -0.00090571433548,    -0.00093899785533,    -0.00186143580968,    -0.00093995668834,    -0.00186166418149],\n [ -0.00631509453548,    -0.02702339455725,    -0.00001910979606,    -0.00410918056805,     0.00001058624630,  -0.02063616591789,    -0.00001267718384,    -0.00272597555850,     0.00000702277450,    -0.01445203384431,      0.00033391900577,     0.00012899688747,    -0.01514481783551,     0.00016609189393,    -0.01475386897318,    -0.00642763371094,    -0.01023119897476,    -0.00663585147245,    -0.01026009701560],\n [ -0.00000280084677,    -0.00001910979606,    -0.02665234730712,     0.00037371007562,     0.00014436865150,  -0.00001859005760,    -0.01317104219809,     0.00038448758263,     0.00014853213109,    -0.00013643690212,     -0.00190980298320,    -0.00014163627448,     0.00010970691227,    -0.00002569550824,    -0.00001652160690,     0.00553694631171,     0.00296253882599,    -0.00592518334643,    -0.00307008036331],\n [ -0.00060226624612,    -0.00410918056805,     0.00037371007562,    -0.02742768609665,     0.00018588404124,  -0.00399742114424,     0.00038448758263,    -0.01396874115447,     0.00019124479202,    -0.00190980298320,      0.00010970691227,    -0.00002569550824,    -0.00553609000895,     0.00005214006927,    -0.00185450039426,    -0.00111418876009,    -0.00223702838075,    -0.00084629056834,    -0.00203426014685],\n [  0.00000155158400,     0.00001058624630,     0.00014436865150,     0.00018588404124,    -0.02699015026797,   0.00001029832686,     0.00014853213109,     0.00019124479202,    -0.01351858713356,    -0.00014163627448,     -0.00002569550824,    -0.00001652160690,     0.00005214006927,    -0.00185450039426,     0.00011345627547,     0.00451469309687,     0.00241810592738,     0.00477138911517,     0.00250189743578],\n [ -0.00452046694500,    -0.02063616591789,    -0.00001859005760,    -0.00399742114424,     0.00001029832686,  -0.02702319749786,    -0.00003768753434,    -0.00796996845458,     0.00002030483034,    -0.01818952603674,      0.00070524995886,     0.00027244649517,    -0.01965271296696,     0.00035079256242,    -0.01882701369086,    -0.00987165499275,    -0.01795740782584,    -0.01115822875565,    -0.01834575971991],\n [ -0.00000038595163,    -0.00001267718384,    -0.01317104219809,     0.00038448758263,     0.00014853213109,  -0.00003768753434,    -0.02503648443824,     0.00199702997314,     0.00077269122299,    -0.00033902442705,     -0.00294678699585,    -0.00039007690599,     0.00030807567722,    -0.00006972255302,    -0.00003443473716,     0.00878465177892,     0.00777812963854,    -0.01154437574140,    -0.00936638912773],\n [ -0.00008299120179,    -0.00272597555850,     0.00038448758263,    -0.01396874115447,     0.00019124479202,  -0.00796996845458,     0.00199702997314,    -0.02918413124002,     0.00099361419288,    -0.00294678699585,      0.00030807567722,    -0.00006972255302,    -0.00831580669109,     0.00013571897621,    -0.00279672819574,    -0.00251085900448,    -0.00821286621429,    -0.00153039204428,    -0.00622386437502],\n [  0.00000021380548,     0.00000702277450,     0.00014853213109,     0.00019124479202,    -0.01351858713356,   0.00002030483034,     0.00077269122299,     0.00099361419288,    -0.02684469027539,    -0.00039007690599,     -0.00006972255302,    -0.00003443473716,     0.00013571897621,    -0.00279672819574,     0.00029057799444,     0.00789015760008,     0.00719868343548,     0.00944135089382,     0.00814913589233],\n [ -0.00090142990526,    -0.01445203384431,    -0.00013643690212,    -0.00190980298320,    -0.00014163627448,  -0.01818952603674,    -0.00033902442705,    -0.00294678699585,    -0.00039007690599,    -0.02563070634460,      0.00066403177471,     0.00035090564283,    -0.00910270453424,     0.00007502850470,    -0.00874245358696,    -0.00913676610260,    -0.01107408168593,    -0.01046477748444,    -0.01146456481073],\n [  0.00000473984815,     0.00033391900577,    -0.00190980298320,     0.00010970691227,    -0.00002569550824,   0.00070524995886,    -0.00294678699585,     0.00030807567722,    -0.00006972255302,     0.00066403177471,     -0.00910270453424,     0.00007502850470,     0.00068756471942,     0.00005040470506,     0.00022274776644,     0.00124025666869,     0.00135413078331,    -0.00068224645268,    -0.00032923928756],\n [  0.00000183105977,     0.00012899688747,    -0.00014163627448,    -0.00002569550824,    -0.00001652160690,   0.00027244649517,    -0.00039007690599,    -0.00006972255302,    -0.00003443473716,     0.00035090564283,      0.00007502850470,    -0.00874245358696,     0.00005040470506,     0.00022274776644,     0.00020687758368,    -0.00412380528180,    -0.00051519173670,     0.00491320446628,     0.00097904308284],\n [ -0.00091126369988,    -0.01514481783551,     0.00010970691227,    -0.00553609000895,     0.00005214006927,  -0.01965271296696,     0.00030807567722,    -0.00831580669109,     0.00013571897621,    -0.00910270453424,      0.00068756471942,     0.00005040470506,    -0.02840235120105,     0.00033061285791,    -0.00923711128151,    -0.00458459601546,    -0.01138951947581,    -0.00454371602298,    -0.01120759511573],\n [  0.00000235760871,     0.00016609189393,    -0.00002569550824,     0.00005214006927,    -0.00185450039426,   0.00035079256242,    -0.00006972255302,     0.00013571897621,    -0.00279672819574,     0.00007502850470,      0.00005040470506,     0.00022274776644,     0.00033061285791,    -0.00923711128151,     0.00037744020930,     0.00095088751145,     0.00091755913622,     0.00066686324895,     0.00079498664458],\n [ -0.00090571433548,    -0.01475386897318,    -0.00001652160690,    -0.00185450039426,     0.00011345627547,  -0.01882701369086,    -0.00003443473716,    -0.00279672819574,     0.00029057799444,    -0.00874245358696,      0.00022274776644,     0.00020687758368,    -0.00923711128151,     0.00037744020930,    -0.02691937643507,    -0.00793049330280,    -0.01147295613562,    -0.00845374029895,    -0.01156033431781],\n [ -0.00093899785533,    -0.00642763371094,     0.00553694631171,    -0.00111418876009,     0.00451469309687,  -0.00987165499275,     0.00878465177892,    -0.00251085900448,     0.00789015760008,    -0.00913676610260,      0.00124025666869,    -0.00412380528180,    -0.00458459601546,     0.00095088751145,    -0.00793049330280,    -0.01785633292778,    -0.01175654591020,    -0.00144863365096,    -0.00543904115350],\n [ -0.00186143580968,    -0.01023119897476,     0.00296253882599,    -0.00223702838075,     0.00241810592738,  -0.01795740782584,     0.00777812963854,    -0.00821286621429,     0.00719868343548,    -0.01107408168593,      0.00135413078331,    -0.00051519173670,    -0.01138951947581,     0.00091755913622,    -0.01147295613562,    -0.01175654591020,    -0.01842598268335,    -0.00600898660138,    -0.01416862694275],\n [ -0.00093995668834,    -0.00663585147245,    -0.00592518334643,    -0.00084629056834,     0.00477138911517,  -0.01115822875565,    -0.01154437574140,    -0.00153039204428,     0.00944135089382,    -0.01046477748444,     -0.00068224645268,     0.00491320446628,    -0.00454371602298,     0.00066686324895,    -0.00845374029895,    -0.00144863365096,    -0.00600898660138,    -0.02521907195360,    -0.01660151455045],\n [ -0.00186166418149,    -0.01026009701560,    -0.00307008036331,    -0.00203426014685,     0.00250189743578,  -0.01834575971991,    -0.00936638912773,    -0.00622386437502,     0.00814913589233,    -0.01146456481073,     -0.00032923928756,     0.00097904308284,    -0.01120759511573,     0.00079498664458,    -0.01156033431781,    -0.00543904115350,    -0.01416862694275,    -0.01660151455045,    -0.02521511777687]])\n\n\n\nmol = psi4.geometry(""""""\nunits bohr\n0 1\nO1     0.000000000000     0.000000000000     0.224348285559\nH2    -1.423528800232     0.000000000000    -0.897393142237\nH3     1.423528800232     0.000000000000    -0.897393142237\nsymmetry c1\nno_com\nno_reorient\n"""""")\n\n# <-- efp\n# [Kaliman:2013:2284] Fig. 4 -- Initialize EFP\nefpmol = pylibefp.core.efp()\n# [Kaliman:2013:2284] Fig. 4 -- Set fragment coordinates\nfrags = [\'h2o\', \'nh3\', \'nh3\']\nefpmol.add_potential(frags)\nefpmol.add_fragment(frags)\nefpmol.set_frag_coordinates(0, \'xyzabc\', [-4.014110144291,  2.316749370493, -1.801514729931, -2.902133, 1.734999, -1.953647])\nefpmol.set_frag_coordinates(1, \'xyzabc\', [ 1.972094713645,  3.599497221584,  5.447701074734, -1.105309, 2.033306, -1.488582])\nefpmol.set_frag_coordinates(2, \'xyzabc\', [-7.876296399270, -1.854372164887, -2.414804197762,  2.526442, 1.658262, -2.742084])\nefpmol.prepare()\nefpmol.set_opts({}, append=\'psi\')\nefpmol.set_electron_density_field_fn(field_fn)\n# --> efp\n\npsi4.set_options({\'basis\': \'6-31g*\',\n                  \'scf_type\': \'pk\',\n                  \'e_convergence\': 1e-8})\n\n# Set defaults\nmaxiter = 40\nE_conv = 1.0E-6\nD_conv = 1.0E-3\n\n# Integral generation from Psi4\'s MintsHelper\nwfn = psi4.core.Wavefunction.build(mol, psi4.core.get_global_option(\'BASIS\'))\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nS = np.asarray(mints.ao_overlap())\n\n# Get nbf and ndocc for closed shell molecules\nnbf = S.shape[0]\nndocc = wfn.nalpha()\n\nprint(\'\\nNumber of occupied orbitals: %d\' % ndocc)\nprint(\'Number of basis functions: %d\' % nbf)\n\n# Run a quick check to make sure everything will fit into memory\nI_Size = (nbf ** 4) * 8.e-9\nprint(""\\nSize of the ERI tensor will be %4.2f GB."" % I_Size)\n\n# Estimate memory usage\nmemory_footprint = I_Size * 1.5\nif I_Size > numpy_memory:\n    psi4.core.clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                    limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\n# Compute required quantities for SCF\nV = np.asarray(mints.ao_potential())\nT = np.asarray(mints.ao_kinetic())\nI = np.asarray(mints.ao_eri())\n\nprint(\'\\nTotal time taken for integrals: %.3f seconds.\' % (time.time() - t))\n\nt = time.time()\n\n# Build H_core\nH = T + V\n\n# <-- efp: add in permanent moment contribution and cache\nVefp = modify_Fock_permanent(mol, nbf, efpmol)\nassert(psi4.compare_integers(1, np.allclose(Vefp, ref_V2), \'EFP permanent Fock contrib\'))\nH = H + Vefp\nHorig = H.copy()\nset_qm_atoms(mol, efpmol)\n# --> efp\n\n# Orthogonalizer A = S^(-1/2) using Psi4\'s matrix power.\nA = mints.ao_overlap()\nA.power(-0.5, 1.e-16)\nA = np.asarray(A)\n\n# Calculate initial core guess\nHp = A.dot(H).dot(A)\ne, C2 = np.linalg.eigh(Hp)\nC = A.dot(C2)\nCocc = C[:, :ndocc]\nD = np.einsum(\'pi,qi->pq\', Cocc, Cocc)\n\nprint(\'\\nTotal time taken for setup: %.3f seconds\' % (time.time() - t))\n\nprint(\'QM/EFP: iterating Total Energy including QM/EFP Induction\')\nt = time.time()\nE = 0.0\nEnuc = mol.nuclear_repulsion_energy()\nEold = 0.0\nDold = np.zeros_like(D)\n\nfor SCF_ITER in range(1, maxiter + 1):\n\n    # <-- efp: add contribution to Fock matrix\n    verbose_dipoles = 1 if (SCF_ITER == 1) else 0\n    # [Kaliman:2013:2284] Fig. 4 -- Compute electric field from wavefunction\n    # [Kaliman:2013:2284] Fig. 4 -- Compute electric field from induced dipoles\n    Vefp = modify_Fock_induced(nbf, efpmol, verbose=verbose_dipoles)\n    H = Horig.copy() + Vefp\n    # --> efp\n\n    # Build fock matrix\n    J = np.einsum(\'pqrs,rs->pq\', I, D)\n    K = np.einsum(\'prqs,rs->pq\', I, D)\n    F = H + J * 2 - K\n\n    diis_e = np.einsum(\'ij,jk,kl->il\', F, D, S) - np.einsum(\'ij,jk,kl->il\', S, D, F)\n    diis_e = A.dot(diis_e).dot(A)\n\n    # SCF energy and update\n    # [Kaliman:2013:2284] Fig. 4 -- Compute QM wavefunction\n    SCF_E = np.einsum(\'pq,pq->\', F + H, D) + Enuc\n    dRMS = np.mean(diis_e**2)**0.5\n\n    # <-- efp: add contribution to energy\n    efp_density = D\n    # [Kaliman:2013:2284] Fig. 4 -- Compute EFP induced dipoles\n    efp_wfn_dependent_energy = efpmol.get_wavefunction_dependent_energy()\n    SCF_E += efp_wfn_dependent_energy\n    # --> efp\n\n    print(\'SCF Iteration %3d: Energy = %4.16f   dE = % 1.5E   dRMS = %1.5E   dEFP = %12.8f\'\n          % (SCF_ITER, SCF_E, (SCF_E - Eold), dRMS, efp_wfn_dependent_energy))\n    if (abs(SCF_E - Eold) < E_conv) and (dRMS < D_conv):\n        break\n\n    Eold = SCF_E\n    Dold = D\n\n    # Diagonalize Fock matrix\n    Fp = A.dot(F).dot(A)\n    e, C2 = np.linalg.eigh(Fp)\n    C = A.dot(C2)\n    Cocc = C[:, :ndocc]\n    D = np.einsum(\'pi,qi->pq\', Cocc, Cocc)\n\n    if SCF_ITER == maxiter:\n        clean()\n        raise Exception(""Maximum number of SCF cycles exceeded."")\n\n\n# <-- efp\nefpmol.compute()\nefpene = efpmol.get_energy(label=\'psi\')\n# [Kaliman:2013:2284] Fig. 4 -- Compute one electron EFP contributions to Hamiltonian\nefp_wfn_independent_energy = efpene[\'total\'] - efpene[\'ind\']\nSCF_E += efp_wfn_independent_energy\nprint(efpmol.energy_summary(scfefp=SCF_E, label=\'psi\'))\n# --> efp\n\nprint(\'Total time for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\n# references confirmed against Q-Chem & Psi4\nassert(psi4.compare_values( 0.2622598847, efpene[\'total\'] - efpene[\'ind\'], 6, \'EFP corr to SCF\'))\nassert(psi4.compare_values(-0.0117694790, efpene[\'ind\'], 6, \'QM-EFP Indc\'))\nassert(psi4.compare_values(-0.0021985285, efpene[\'disp\'], 6, \'EFP-EFP Disp\'))\nassert(psi4.compare_values( 0.0056859871, efpene[\'exch\'], 6, \'EFP-EFP Exch\'))\nassert(psi4.compare_values( 0.2504904057, efpene[\'total\'], 6, \'EFP-EFP Totl\'))\nassert(psi4.compare_values(-76.0139362744, SCF_E, 6, \'SCF\'))\nefpmol.clean()\n'"
Self-Consistent-Field/RHF_Gradient.py,25,"b'""""""\nThis script calculates nuclear gradients of RHF Wavefunction using\ngradients of one and two electron integrals obtained from PSI4. \n\nReference: \n- Equations and algorithms from [Pople:1979:225]\n""""""\n\n__authors__ = ""Ashutosh Kumar""\n__credits__ = [""Ashutosh Kumar""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-12-17""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=15, linewidth=200, suppress=True)\nimport psi4\n\nmol = psi4.geometry(""""""\nO\nH 1 R\nH 1 R 2 104\nsymmetry c1\n"""""")\n\n# physical constants changed, so geometry changes slightly\nfrom pkg_resources import parse_version\nif parse_version(psi4.__version__) >= parse_version(""1.3a1""):\n    mol.R = 1.1 * 0.52917721067 / 0.52917720859\nelse:\n    mol.R = 1.1\n\npsi4.core.set_active_molecule(mol)\n\noptions = {\'BASIS\':\'STO-3G\', \'SCF_TYPE\':\'PK\',\n           \'E_CONVERGENCE\':1e-10,\n           \'D_CONVERGENCE\':1e-10}\n\npsi4.set_options(options)\n\n\nrhf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n# Assuming C1 symmetry    \nocc = wfn.doccpi()[0]\nnmo = wfn.nmo()\n\nC = wfn.Ca_subset(""AO"", ""ALL"")\nnpC = np.asarray(C)\n\nmints = psi4.core.MintsHelper(wfn.basisset())\nH_ao = np.asarray(mints.ao_kinetic()) + np.asarray(mints.ao_potential())\n\n# Update H, transform to MO basis \nH = np.einsum(\'uj,vi,uv\', npC, npC, H_ao)\n\n# Integral generation from Psi4\'s MintsHelper\nMO = np.asarray(mints.mo_eri(C, C, C, C))\n# Physicist notation    \nMO = MO.swapaxes(1,2)\n\nF = H + 2.0 * np.einsum(\'pmqm->pq\', MO[:, :occ, :, :occ])\nF -= np.einsum(\'pmmq->pq\', MO[:, :occ, :occ, :])\nnatoms = mol.natom()\ncart = [\'_X\', \'_Y\', \'_Z\']\noei_dict = {""S"" : ""OVERLAP"", ""T"" : ""KINETIC"", ""V"" : ""POTENTIAL""}\n\nderiv1_mat = {}\nderiv1_np = {}\n\nGradient = {};\n\nGradient[""N""] = np.zeros((natoms, 3))\nGradient[""S""] = np.zeros((natoms, 3))\nGradient[""S\'""] = np.zeros((natoms, 3))\nGradient[""V""] = np.zeros((natoms, 3))\nGradient[""T""] = np.zeros((natoms, 3))\nGradient[""J""] = np.zeros((natoms, 3))\nGradient[""K""] = np.zeros((natoms, 3))\nGradient[""Total""] = np.zeros((natoms, 3))\n\nGradient[""N""] = np.asarray(mol.nuclear_repulsion_energy_deriv1([0,0,0]))\n\npsi4.core.print_out(""\\n\\n"")\nMat = psi4.core.Matrix.from_array(Gradient[""N""])\nMat.name = ""NUCLEAR GRADIENT""\nMat.print_out()\n\n\n# 1st Derivative of OEIs \n\nfor atom in range(natoms):\n    for key in  oei_dict:\n        deriv1_mat[key + str(atom)] = mints.mo_oei_deriv1(oei_dict[key], atom, C, C)\n        for p in range(3):\n            map_key = key + str(atom) + cart[p]\n            deriv1_np[map_key] = np.asarray(deriv1_mat[key + str(atom)][p])\n            if key == ""S"":\n                Gradient[key][atom, p] = -2.0 * np.einsum(""ii,ii->"", F[:occ,:occ], deriv1_np[map_key][:occ,:occ])\n                Gradient[""S\'""][atom, p] = 2.0 * np.einsum(""ii->"", deriv1_np[map_key][:occ,:occ]) # For comparison with PSI4\'s overlap_grad\n            else:\n                Gradient[key][atom, p] = 2.0 * np.einsum(""ii->"", deriv1_np[map_key][:occ,:occ])\n\npsi4.core.print_out(""\\n\\n OEI Gradients\\n\\n"")\nfor key in Gradient: \n    Mat = psi4.core.Matrix.from_array(Gradient[key])\n    if key in oei_dict:\n        Mat.name = oei_dict[key] + "" GRADIENT""\n        Mat.print_out()    \n        psi4.core.print_out(""\\n"")\n\n\nGradient[""J""] = np.zeros((natoms, 3))\nGradient[""K""] = np.zeros((natoms, 3))\n\n# 1st Derivative of TEIs \n\nfor atom in range(natoms):\n    string = ""TEI"" + str(atom)\n    deriv1_mat[string] = mints.mo_tei_deriv1(atom, C, C, C, C)\n    for p in range(3):\n        map_key = string + cart[p]\n        deriv1_np[map_key] = np.asarray(deriv1_mat[string][p])\n        Gradient[""J""][atom, p] =  2.0 * np.einsum(""iijj->"", deriv1_np[map_key][:occ,:occ,:occ,:occ])\n        Gradient[""K""][atom, p] = -1.0 * np.einsum(""ijij->"", deriv1_np[map_key][:occ,:occ,:occ,:occ])\n\npsi4.core.print_out(""\\n\\n TEI Gradients\\n\\n"")\nJMat = psi4.core.Matrix.from_array(Gradient[""J""])\nKMat = psi4.core.Matrix.from_array(Gradient[""K""])\nJMat.name = "" COULOMB  GRADIENT""\nKMat.name = "" EXCHANGE GRADIENT""\nJMat.print_out()    \nKMat.print_out()    \n\nGradient[""OEI""] = Gradient[""S""] + Gradient[""V""] + Gradient[""T""] \nGradient[""TEI""] = Gradient[""J""] + Gradient[""K""]\nGradient[""Total""] = Gradient[""OEI""] + Gradient[""TEI""] + Gradient[""N""]\n\n\n# PIS4\'s overlap_grad, kinetic_grad and potential_grad\n\nPSI4_Grad = {}\nD = wfn.Da()\nD.add(wfn.Db())\n\nPSI4_Grad[""S""] = mints.overlap_grad(D) \nPSI4_Grad[""T""] = mints.kinetic_grad(D)\nPSI4_Grad[""V""] = mints.potential_grad(D)\n\n#Convert np array into PSI4 Matrix \nG_python_S_mat = psi4.core.Matrix.from_array(Gradient[""S\'""])\nG_python_T_mat = psi4.core.Matrix.from_array(Gradient[""T""])\nG_python_V_mat = psi4.core.Matrix.from_array(Gradient[""V""])\n\n# Test OEI gradients with that of PSI4\npsi4.compare_matrices(PSI4_Grad[""S""], G_python_S_mat, 10, ""OVERLAP_GRADIENT_TEST"")   # TEST \npsi4.compare_matrices(PSI4_Grad[""T""], G_python_T_mat, 10, ""KINETIC_GRADIENT_TEST"")   # TEST\npsi4.compare_matrices(PSI4_Grad[""V""], G_python_V_mat, 10, ""POTENTIAL_GRADIENT_TEST"") # TEST\n\n# PSI4\'s Total Gradient \nTotal_G_psi4 = psi4.core.Matrix.from_list([                                     \n        [ 0.000000000000, -0.000000000000, -0.097441440379],\n        [-0.000000000000, -0.086300100260,  0.048720720189],\n        [-0.000000000000,  0.086300100260,  0.048720720189]\n    ])\nG_python_total_mat = psi4.core.Matrix.from_array(Gradient[""Total""])\npsi4.compare_matrices(Total_G_psi4, G_python_total_mat, 10, ""RHF_TOTAL_GRADIENT_TEST"") # TEST\n'"
Self-Consistent-Field/RHF_Hessian.py,41,"b'""""""\nThis script calculates nuclear Hessians of RHF Wavefunction using\nderivatives of one and two electron integrals obtained from PSI4\n\nReference: \n- Equations & algorithms from [Pople:1979:225]\n""""""\n\n__authors__ = ""Ashutosh Kumar""\n__credits__ = [""Ashutosh Kumar""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-12-17""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=15, linewidth=200, suppress=True)\nimport psi4\n\npsi4.set_memory(int(1e9), False)\npsi4.core.set_output_file(\'output.dat\', False)\npsi4.core.set_num_threads(4)\n\nmol = psi4.geometry(""""""\nO\nH 1 R\nH 1 R 2 104\nsymmetry c1\n"""""")\n\n# physical constants changed, so geometry changes slightly\nfrom pkg_resources import parse_version\nif parse_version(psi4.__version__) >= parse_version(""1.3a1""):\n    mol.R = 1.1 * 0.52917721067 / 0.52917720859\nelse:\n    mol.R = 1.1\n\npsi4.core.set_active_molecule(mol)\n\noptions = {\'BASIS\':\'STO-3G\', \'SCF_TYPE\':\'PK\',\n           \'E_CONVERGENCE\':1e-10,\n           \'D_CONVERGENCE\':1e-10\n           }\n\npsi4.set_options(options)\n\nrhf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n# Assuming C1 symmetry    \nocc = wfn.doccpi()[0]\nnmo = wfn.nmo()\nvir = nmo - occ\n\nC = wfn.Ca_subset(""AO"", ""ALL"")\nnpC = np.asarray(C)\n\nmints = psi4.core.MintsHelper(wfn.basisset())\nH_ao = np.asarray(mints.ao_kinetic()) + np.asarray(mints.ao_potential())\n\n# Update H, transform to MO basis \nH = np.einsum(\'uj,vi,uv\', npC, npC, H_ao)\n\n# Integral generation from Psi4\'s MintsHelper\nMO = np.asarray(mints.mo_eri(C, C, C, C))\n# Physicist notation    \nMO = MO.swapaxes(1,2)\n\nF = H + 2.0 * np.einsum(\'pmqm->pq\', MO[:, :occ, :, :occ])\nF -= np.einsum(\'pmmq->pq\', MO[:, :occ, :occ, :])\nnatoms = mol.natom()\ncart = [\'_X\', \'_Y\', \'_Z\'] \noei_dict = {""S"" : ""OVERLAP"", ""T"" : ""KINETIC"", ""V"" : ""POTENTIAL""}\n\nderiv1_mat = {}\nderiv1 = {}\n\n# 1st Derivative of OEIs \n\nfor atom in range(natoms):\n    for key in  oei_dict:\n        deriv1_mat[key + str(atom)] = mints.mo_oei_deriv1(oei_dict[key], atom, C, C)\n        for p in range(3):\n            map_key = key + str(atom) + cart[p]\n            deriv1[map_key] = np.asarray(deriv1_mat[key + str(atom)][p])\n\n# 1st Derivative of TEIs \n\nfor atom in range(natoms):\n    string = ""TEI"" + str(atom)\n    deriv1_mat[string] = mints.mo_tei_deriv1(atom, C, C, C, C)\n    for p in range(3):\n        map_key = string + cart[p]\n        deriv1[map_key] = np.asarray(deriv1_mat[string][p])\n\nHes = {};\nderiv2_mat = {}\nderiv2 = {}\n\nHes[""S""] = np.zeros((3 * natoms, 3 * natoms))\nHes[""V""] = np.zeros((3 * natoms, 3 * natoms))\nHes[""T""] = np.zeros((3 * natoms, 3 * natoms))\nHes[""N""] = np.zeros((3 * natoms, 3 * natoms))\nHes[""J""] = np.zeros((3 * natoms, 3 * natoms))\nHes[""K""] = np.zeros((3 * natoms, 3 * natoms))\nHes[""R""] = np.zeros((3 * natoms, 3 * natoms))\nHessian  = np.zeros((3 * natoms, 3 * natoms))\n\nHes[""N""] = np.asarray(mol.nuclear_repulsion_energy_deriv2())\n\npsi4.core.print_out(""\\n\\n"")\nMat = psi4.core.Matrix.from_array(Hes[""N""])\nMat.name = ""NUCLEAR HESSIAN""\nMat.print_out()\n\n# 2nd Derivative of OEIs \n\nfor atom1 in range(natoms):\n    for atom2 in range(atom1 + 1):\n        for key in  oei_dict:\n            string = key + str(atom1) + str(atom2)\n            deriv2_mat[string] = mints.mo_oei_deriv2(oei_dict[key], atom1, atom2, C, C)\n            pq = 0\n            for p in range(3):\n                for q in range(3):\n                    map_key = string + cart[p] + cart[q]\n                    deriv2[map_key] = np.asarray(deriv2_mat[string][pq])\n                    pq = pq+1\n                    row = 3 * atom1 + p\n                    col = 3 * atom2 + q\n                    if key == ""S"":\n                        Hes[key][row][col] = -2.0 * np.einsum(""ii,ii->"", F[:occ,:occ], deriv2[map_key][:occ,:occ])\n                    else:\n                        Hes[key][row][col] = 2.0 * np.einsum(""ii->"", deriv2[map_key][:occ,:occ])\n                    Hes[key][col][row] = Hes[key][row][col]\n                    Hes[key][col][row] = Hes[key][row][col]\n\n\nfor key in Hes: \n    Mat = psi4.core.Matrix.from_array(Hes[key])\n    if key in oei_dict:\n        Mat.name = oei_dict[key] + "" HESSIAN""\n        Mat.print_out()    \n        psi4.core.print_out(""\\n"")\n\n\n# 2nd Derivative of TEIs\n\nfor atom1 in range(natoms):\n    for atom2 in range(atom1 + 1):\n        string = ""TEI"" + str(atom1) + str(atom2)\n        deriv2_mat[string] = mints.mo_tei_deriv2(atom1, atom2, C, C, C, C)\n        pq = 0\n        for p in range(3):\n            for q in range(3):\n                map_key = string + cart[p] + cart[q]\n                deriv2[map_key] = np.asarray(deriv2_mat[string][pq])\n                pq = pq + 1\n                row = 3 * atom1 + p\n                col = 3 * atom2 + q\n                Hes[""J""][row][col] =  2.0 * np.einsum(""iijj->"", deriv2[map_key][:occ,:occ,:occ,:occ])\n                Hes[""K""][row][col] = -1.0 * np.einsum(""ijij->"", deriv2[map_key][:occ,:occ,:occ,:occ])\n\n                Hes[""J""][col][row] = Hes[""J""][row][col]\n                Hes[""K""][col][row] = Hes[""K""][row][col]\n\nJMat = psi4.core.Matrix.from_array(Hes[""J""])\nKMat = psi4.core.Matrix.from_array(Hes[""K""])\nJMat.name = "" COULOMB  HESSIAN""\nKMat.name = "" EXCHANGE HESSIAN""\nJMat.print_out()    \nKMat.print_out()    \n\n# Solve the CPHF equations here,  G_aibj Ubj^x = Bai^x (Einstein summation),\n# where G is the electronic hessian,\n# G_aibj = delta_ij * delta_ab * epsilon_ij * epsilon_ab + 4 <ij|ab> - <ij|ba> - <ia|jb>, \n# where epsilon_ij = epsilon_i - epsilon_j, (epsilon -> orbital energies),\n# x refers to the perturbation, Ubj^x are the corresponsing CPHF coefficients \n# and Bai^x = Sai^x * epsilon_ii - Fai^x + Smn^x  * (2<am|in> - <am|ni>),\n# where, S^x =  del(S)/del(x), F^x =  del(F)/del(x).\n\nI_occ = np.diag(np.ones(occ))\nI_vir = np.diag(np.ones(vir))\nepsilon = np.asarray(wfn.epsilon_a())\neps_diag = epsilon[occ:].reshape(-1, 1) - epsilon[:occ]\n\n#  Build the electronic hessian G\n\nG =  4 * MO[:occ, :occ, occ:, occ:]\nG -= MO[:occ, :occ:, occ:, occ:].swapaxes(2,3)\nG -= MO[:occ, occ:, :occ, occ:].swapaxes(1,2)\nG = G.swapaxes(1,2)\nG += np.einsum(\'ai,ij,ab->iajb\', eps_diag, I_occ, I_vir)\n\n# Inverse of G\nGinv = np.linalg.inv(G.reshape(occ * vir, -1))\nGinv = Ginv.reshape(occ,vir,occ,vir)\n\nB = {}\nF_grad = {}\nU = {}\n\n# Build Fpq^x now\nfor atom in range(natoms):\n    for p in range(3):\n        key = str(atom) + cart[p]\n        F_grad[key] =  deriv1[""T"" + key]\n        F_grad[key] += deriv1[""V"" + key]\n        F_grad[key] += 2.0 * np.einsum(\'pqmm->pq\', deriv1[""TEI"" + key][:,:,:occ,:occ])\n        F_grad[key] -= 1.0 * np.einsum(\'pmmq->pq\', deriv1[""TEI"" + key][:,:occ,:occ,:])\n\n\npsi4.core.print_out(""\\n\\n CPHF Coefficentsn:\\n"")\n\n# Build Bai^x now\n\nfor atom in range(natoms):\n    for p in range(3):\n        key = str(atom) + cart[p]\n        B[key] =  np.einsum(""ai,ii->ai"", deriv1[""S"" + key][occ:,:occ], F[:occ,:occ])\n        B[key] -= F_grad[key][occ:,:occ]\n        B[key] +=  2.0 * np.einsum(""amin,mn->ai"", MO[occ:,:occ,:occ,:occ], deriv1[""S"" + key][:occ,:occ])\n        B[key] += -1.0 * np.einsum(""amni,mn->ai"", MO[occ:,:occ,:occ,:occ], deriv1[""S"" + key][:occ,:occ])\n\n\t\t# Compute U^x now: U_ai^x = G^(-1)_aibj * B_bj^x  \n\n        U[key] = np.einsum(""iajb,bj->ai"", Ginv, B[key])\n        psi4.core.print_out(""\\n"")\n        UMat = psi4.core.Matrix.from_array(U[key])\n        UMat.name = key \n        UMat.print_out()    \n\n\n# Build the response hessian now\n\nfor atom1 in range(natoms):\n    for atom2 in range(atom1+1):\n        for p in range(3):\n            for q in range(3):\n                key1  = str(atom1) + cart[p]\n                key2  = str(atom2) + cart[q]\n                key1S = ""S"" + key1\n                key2S = ""S"" + key2\n                r = 3 * atom1 + p\n                c = 3 * atom2 + q\n\n                Hes[""R""][r][c] = -2.0 * np.einsum(""ij,ij->"", deriv1[key1S][:occ,:occ], F_grad[key2][:occ,:occ])\n                Hes[""R""][r][c] -= 2.0 * np.einsum(""ij,ij->"", deriv1[key2S][:occ,:occ], F_grad[key1][:occ,:occ])\n                Hes[""R""][r][c] += 4.0 * np.einsum(""ii,mi,mi->"", F[:occ,:occ], deriv1[key2S][:occ,:occ], deriv1[key1S][:occ,:occ])\n\n                Hes[""R""][r][c] += 4.0 * np.einsum(""ij,mn,imjn->"", deriv1[key1S][:occ,:occ], deriv1[key2S][:occ,:occ], MO[:occ,:occ,:occ,:occ])\n                Hes[""R""][r][c] -= 2.0 * np.einsum(""ij,mn,imnj->"", deriv1[key1S][:occ,:occ], deriv1[key2S][:occ,:occ], MO[:occ,:occ,:occ,:occ])\n\n                Hes[""R""][r][c] -= 4.0 * np.einsum(""ai,ai->"", U[key2], B[key1])\n                Hes[""R""][c][r] = Hes[""R""][r][c]\n\nMat = psi4.core.Matrix.from_array(Hes[""R""])\nMat.name = "" RESPONSE HESSIAN""\nMat.print_out()    \n\nfor key in Hes:\n    Hessian += Hes[key]\n\nMat = psi4.core.Matrix.from_array(Hessian)\nMat.name = "" TOTAL HESSIAN""\nMat.print_out()    \n\nH_psi4 = psi4.core.Matrix.from_list([\n[ 0.07613952484989, 0.00000000000000, 0.00000000000000,-0.03806976242497, 0.00000000000000,-0.00000000000000,-0.03806976242497,-0.00000000000000, 0.00000000000000], \n[ 0.00000000000000, 0.48290536165172,-0.00000000000000,-0.00000000000000,-0.24145268082589, 0.15890015082364, 0.00000000000000,-0.24145268082590,-0.15890015082364],\n[ 0.00000000000000,-0.00000000000000, 0.43734495429393,-0.00000000000000, 0.07344233387869,-0.21867247714697,-0.00000000000000,-0.07344233387869,-0.21867247714697],\n[-0.03806976242497,-0.00000000000000,-0.00000000000000, 0.04537741867538,-0.00000000000000, 0.00000000000000,-0.00730765625041, 0.00000000000000,-0.00000000000000],\n[ 0.00000000000000,-0.24145268082589, 0.07344233387869,-0.00000000000000, 0.25786500091002,-0.11617124235117, 0.00000000000000,-0.01641232008412, 0.04272890847247],\n[-0.00000000000000, 0.15890015082364,-0.21867247714697, 0.00000000000000,-0.11617124235117, 0.19775197798054, 0.00000000000000,-0.04272890847247, 0.02092049916645],\n[-0.03806976242497, 0.00000000000000,-0.00000000000000,-0.00730765625041, 0.00000000000000, 0.00000000000000, 0.04537741867538,-0.00000000000000, 0.00000000000000],\n[-0.00000000000000,-0.24145268082590,-0.07344233387869, 0.00000000000000,-0.01641232008412,-0.04272890847247,-0.00000000000000, 0.25786500091002, 0.11617124235117],\n[ 0.00000000000000,-0.15890015082364,-0.21867247714697,-0.00000000000000, 0.04272890847247, 0.02092049916645, 0.00000000000000, 0.11617124235117, 0.19775197798054]\n])\n\nH_python_mat = psi4.core.Matrix.from_array(Hessian)\npsi4.compare_matrices(H_psi4, H_python_mat, 10, ""RHF-HESSIAN-TEST"") # TEST\n'"
Self-Consistent-Field/RHF_libJK.py,1,"b'""""""\nA restricted Hartree-Fock code using the Psi4 JK class for the \n4-index electron repulsion integrals.\n\nReferences:\n- Algorithms from [Szabo:1996], [Sherrill:1998], and [Pulay:1980:393]\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\nimport helper_HF\n\n# Memory & Output File\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Benzene\nmol = psi4.geometry(""""""\nC  0.000  1.396  0.000\nC  1.209  0.698  0.000\nC  1.209 -0.698  0.000\nC  0.000 -1.396  0.000\nC -1.209 -0.698  0.000\nC -1.209  0.698  0.000\nH  0.000  2.479  0.000\nH  2.147  1.240  0.000\nH  2.147 -1.240  0.000\nH  0.000 -2.479  0.000\nH -2.147 -1.240  0.000\nH -2.147  1.240  0.000\nsymmetry c1\n"""""")\n\n# Set a few options\npsi4.set_options({""BASIS"": ""AUG-CC-PVDZ"",\n                  ""SCF_TYPE"": ""DF"",\n                  ""E_CONVERGENCE"": 1.e-8})\n\n# Set tolerances\nmaxiter = 12\nE_conv = 1.0E-6\nD_conv = 1.0E-5\n\n# Integral generation from Psi4\'s MintsHelper\nwfn = psi4.core.Wavefunction.build(mol, psi4.core.get_global_option(\'BASIS\'))\nmints = psi4.core.MintsHelper(wfn.basisset())\nS = mints.ao_overlap()\n\n# Get nbf and ndocc for closed shell molecules\nnbf = wfn.nso()\nndocc = wfn.nalpha()\nif wfn.nalpha() != wfn.nbeta():\n    raise PsiException(""Only valid for RHF wavefunctions!"")\n\nprint(\'\\nNumber of occupied orbitals: %d\\n\' % ndocc)\nprint(\'Number of basis functions:   %d\\n\' % nbf)\n\n# Build H_core\nV = mints.ao_potential()\nT = mints.ao_kinetic()\nH = T.clone()\nH.add(V)\n\n# Orthogonalizer A = S^(-1/2)\nA = mints.ao_overlap()\nA.power(-0.5, 1.e-16)\n\n# Build diis\ndiis = helper_HF.DIIS_helper(max_vec=6)\n\n# Diagonalize routine\ndef build_orbitals(diag):\n    Fp = psi4.core.Matrix.triplet(A, diag, A, True, False, True)\n\n    Cp = psi4.core.Matrix(nbf, nbf)\n    eigvals = psi4.core.Vector(nbf)\n    Fp.diagonalize(Cp, eigvals, psi4.core.DiagonalizeOrder.Ascending)\n\n    C = psi4.core.Matrix.doublet(A, Cp, False, False)\n\n    Cocc = psi4.core.Matrix(nbf, ndocc)\n    Cocc.np[:] = C.np[:, :ndocc]\n\n    D = psi4.core.Matrix.doublet(Cocc, Cocc, False, True)\n    return C, Cocc, D\n\n# Build core orbitals\nC, Cocc, D = build_orbitals(H)\n\n# Setup data for DIIS\nt = time.time()\nE = 0.0\nEnuc = mol.nuclear_repulsion_energy()\nEold = 0.0\nDold = psi4.core.Matrix(nbf, nbf)\nFock_list = []\nDIIS_error = []\n\n# Initialize the JK object\njk = psi4.core.JK.build(wfn.basisset())\njk.set_memory(int(1.25e8))  # 1GB\njk.initialize()\njk.print_header()\n\nprint(\'\\nTotal time taken for setup: %.3f seconds\\n\' % (time.time() - t))\n\nprint(\'\\nStart SCF iterations:\\n\\n\')\nt = time.time()\n\nfor SCF_ITER in range(1, maxiter + 1):\n\n    # Compute JK\n    jk.C_left_add(Cocc)\n    jk.compute()\n    jk.C_clear()\n\n    # Build Fock matrix\n    F = H.clone()\n    F.axpy(2.0, jk.J()[0])\n    F.axpy(-1.0, jk.K()[0])\n\n    # DIIS error build and update\n    diis_e = psi4.core.Matrix.triplet(F, D, S, False, False, False)\n    diis_e.subtract(psi4.core.Matrix.triplet(S, D, F, False, False, False))\n    diis_e = psi4.core.Matrix.triplet(A, diis_e, A, False, False, False)\n\n    diis.add(F, diis_e)\n\n    # SCF energy and update\n    FH = F.clone()\n    FH.add(H)\n    SCF_E = FH.vector_dot(D) + Enuc\n\n    dRMS = diis_e.rms()\n\n    print(\'SCF Iteration %3d: Energy = %4.16f   dE = % 1.5E   dRMS = %1.5E\'\n          % (SCF_ITER, SCF_E, (SCF_E - Eold), dRMS))\n    if (abs(SCF_E - Eold) < E_conv) and (dRMS < D_conv):\n        break\n\n    Eold = SCF_E\n    Dold = D\n\n    F = psi4.core.Matrix.from_array(diis.extrapolate())\n\n    # Diagonalize Fock matrix\n    C, Cocc, D = build_orbitals(F)\n\n    if SCF_ITER == maxiter:\n        psi4.clean()\n        raise Exception(""Maximum number of SCF cycles exceeded.\\n"")\n\nprint(\'Total time for SCF iterations: %.3f seconds \\n\\n\' % (time.time() - t))\n\nprint(\'Final SCF energy: %.8f hartree\\n\' % SCF_E)\npsi4.compare_values(-230.7277181465556453, SCF_E, 6, \'SCF Energy\')\n'"
Self-Consistent-Field/RHF_symmetry.py,12,"b'""""""A restricted Hartree-Fock script using the Psi4NumPy formalism that\naccounts for molecular symmetry using symmetrized orbitals.\n\nReferences:\n- SCF Algorithm taken from [Szabo:1996] (pp. 146)\n- SCF Equations taken from [Szabo:1996]\n- Symmetry-specific details taken from https://github.com/CrawfordGroup/ProgrammingProjects/tree/master/Project%2309\n""""""\n\n__authors__ = ""Eric J. Berquist""\n__credits__ = [""Eric J. Berquist"", ""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2018-12-26""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=8, linewidth=200, suppress=True)\nimport psi4\nfrom helper_HF import transform_aotoso, transform_sotoao\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'500 MB\')\npsi4.core.set_output_file(""output.dat"", False)\n\n# Memory for NumPy in GB\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\n"""""")\n\npsi4.set_options({\'basis\': \'sto-3g\',\n                  \'scf_type\': \'direct\',\n                  \'e_convergence\': 1e-8})\n\n# Set defaults\nmaxiter = 50\nE_conv = 1.0E-8\nD_conv = 1.0E-7\n\n# Integral generation from Psi4\'s MintsHelper, which automatically\n# performs symmetry adaptation.\nwfn = psi4.core.Wavefunction.build(mol, psi4.core.get_global_option(\'BASIS\'))\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\n\nnirrep = wfn.nirrep()\n# Water belongs to the C2v point group, which has four irreducable\n# representations (irreps): A_1, A_2, B_1, and B_2.\nassert nirrep == 4\nnsopi = list(wfn.nsopi())\n\n# Get nbf and ndocc for closed shell molecules\nnbf = sum(nsopi)\nndocc = wfn.nalpha()\n\nprint(\'\\nNumber of occupied orbitals: %d\' % ndocc)\nprint(\'Number of basis functions: %d\' % nbf)\nprint(\'Number of spin orbitals per irrep:\', nsopi)\n\n# Run a quick check to make sure everything will fit into memory\nI_Size = (nbf**4) * 8.e-9\nprint(""\\nSize of the ERI tensor will be %4.2f GB."" % I_Size)\n\n# Estimate memory usage\nmemory_footprint = I_Size * 1.5\nif I_Size > numpy_memory:\n    psi4.core.clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory ""\n                    ""limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\ndef filter_empty_irrep(coll):\n    """"""\n    A matrix is returned for every irrep, even if the irrep is not present for\n    the molecule; these must be filtered out to avoid problems with NumPy\n    arrays that have a zero dimension.\n    """"""\n    return tuple(m for m in coll if all(m.shape))\n\n# The convention will be to have quantities in the spin orbital (SO) basis\n# ending with an underscore, each consisting of one matrix per irrep.\nS_ = filter_empty_irrep(mints.so_overlap().to_array())\nT_ = filter_empty_irrep(mints.so_kinetic().to_array())\nV_ = filter_empty_irrep(mints.so_potential().to_array())\n\n# The two-electron integrals are not blocked according to symmetry, so a\n# transformation between the atomic orbital (AO) and SO bases will be required.\nI_AO = np.asarray(mints.ao_eri())\n\n# In order to convert from the C1 AO basis to the symmetrized SO basis, a set\n# of matrices (one for each irrep with shape [nao, irrep_size]) is used to\n# transform the dense AO representation into the block-diagonal SO\n# representation. A SO-to-AO transformation matrix is obtained by transposing\n# the corresponding AO-to-SO transformation matrix.\ntransformers_ = filter_empty_irrep(wfn.aotoso().to_array())\n\n# At this point, all irreps that are not present (such as A_2 in water) should\n# be filtered out.\nassert len(S_) == len(T_) == len(V_) == len(transformers_)\nnirrep = len(S_)\nnsopi = [n for n in nsopi if n > 0]\nprint(\'Number of spin orbitals per irrep (with empty irreps removed):\', nsopi)\n\nprint(\'\\nTotal time taken for integrals: %.3f seconds.\' % (time.time() - t))\nt = time.time()\n\n# Build H_core: [Szabo:1996] Eqn. 3.153, pp. 141\nH_ = [T + V for (T, V) in zip(T_, V_)]\n\ndef build_orthogonalizer(S):\n    """"""\n    Form the orthogonalization matrix A = S^{-1/2} using pure NumPy.\n    """"""\n    # Application of a function to a matrix requires transforming to\n    # the diagonal basis, applying the function to the diagonal form,\n    # then backtransformation to the original basis.\n    eigval, eigvec = np.linalg.eigh(S)\n    eigval_diag = np.diag(eigval ** (-1./2))\n    return eigvec.dot(eigval_diag).dot(eigvec.T)\n\nA_ = [build_orthogonalizer(S) for S in S_]\n\ndef form_new_orbitals(A, F):\n    Fp = A.dot(F).dot(A)        # Eqn. 3.177\n    e, C2 = np.linalg.eigh(Fp)  # Solving Eqn. 1.178\n    C = A.dot(C2)               # Back transform, Eqn. 3.174\n    return C, e\n\n# Calculate initial core guess: [Szabo:1996] pp. 145\nC_ = []\ne_ = []\nfor i in range(nirrep):\n    C, e = form_new_orbitals(A_[i], H_[i])\n    C_.append(C)\n    e_.append(e)\n\n# Occupations of each irrep are taken from the lowest eigenvalues (energies)\n# of the guess coefficients.\nenergies_and_irreps = np.array(sorted(\n    (energy, irrep)\n    for (irrep, energies_irrep) in enumerate(e_)\n    for energy in energies_irrep\n))\nlowest_occupied = energies_and_irreps[:ndocc, 1].astype(int).tolist()\nndoccpi = [lowest_occupied.count(i) for i in range(nirrep)]\nprint(\'Number of occupied spin orbitals per irrep:\', ndoccpi)\n\n# Form (occupied) density: [Szabo:1996] Eqn. 3.145, pp. 139\nD_ = [np.einsum(\'mi,ni->mn\', C_[i][:, :indocc], C_[i][:, :indocc])\n      for i, indocc in enumerate(ndoccpi)]\n\nprint(\'\\nTotal time taken for setup: %.3f seconds\' % (time.time() - t))\n\nprint(\'\\nStart SCF iterations:\\n\')\nt = time.time()\nE = 0.0\nEnuc = mol.nuclear_repulsion_energy()\nEold = 0.0\n\nE_ = np.array([(D * (H + H)).sum() for (D, H) in zip(D_, H_)])\nE_1el = sum(E_) + Enuc\nprint(\'One-electron energy = %4.16f\' % E_1el)\n\ndef form_new_density(A, F, indocc):\n    C, _ = form_new_orbitals(A, F)\n    Cocc = C[:, :indocc]\n    return np.einsum(\'mi,ni->mn\', Cocc, Cocc)\n\nfor SCF_ITER in range(1, maxiter + 1):\n\n    # Perform the two-electron integral contraction with the density in the AO\n    # basis.\n    D_AO = transform_sotoao(D_, transformers_)\n    J_ = transform_aotoso(np.einsum(""mnls,ls->mn"", I_AO, D_AO), transformers_)\n    K_ = transform_aotoso(np.einsum(""mlns,ls->mn"", I_AO, D_AO), transformers_)\n    F_ = [H + (2 * J) - K for H, J, K in zip(H_, J_, K_)]\n    E_ = [np.einsum(""mn,mn->"", D, H + F) for D, H, F in zip(D_, H_, F_)]\n\n    SCF_E = sum(E_) + Enuc\n\n    print(\'SCF Iteration %3d: Energy = %4.16f   dE = % 1.5E\' % (SCF_ITER, SCF_E, (SCF_E - Eold)))\n    if abs(SCF_E - Eold) < E_conv:\n        break\n\n    Eold = SCF_E\n\n    D_ = [form_new_density(A_[h], F_[h], indocc)\n          for h, indocc in enumerate(ndoccpi)]\n\n    if SCF_ITER == maxiter:\n        psi4.core.clean()\n        raise Exception(""Maximum number of SCF cycles exceeded."")\n\nprint(\'Total time for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\nprint(\'Final SCF energy: %.8f hartree\' % SCF_E)\nSCF_E_psi = psi4.energy(\'SCF\')\npsi4.compare_values(SCF_E_psi, SCF_E, 6, \'SCF Energy\')\n'"
Self-Consistent-Field/ROHF_libJK.py,18,"b'""""""\nA restricted open-shell Hartree-Fock script using the Psi4NumPy Formalism\n\nReferences:\n- Equations and algorithm taken from Psi4\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nimport helper_HF as scf_helper\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\n# Triplet O2\nmol = psi4.geometry(""""""\n    0 3\n    O\n    O 1 1.2\nsymmetry c1\n"""""")\n\npsi4.set_options({\'guess\': \'gwh\',\n                  \'basis\': \'aug-cc-pvdz\',\n                  \'scf_type\': \'df\',\n                  \'e_convergence\': 1e-8,\n                  \'reference\': \'rohf\'})\n\nwfn = psi4.core.Wavefunction.build(mol, psi4.core.get_global_option(\'BASIS\'))\n\n# Set occupations\nnocca = wfn.nalpha()\nnoccb = wfn.nbeta()\nndocc = min(nocca, noccb)\nnocc = max(nocca, noccb)\nnsocc = nocc - ndocc\n\n# Set defaults\nmaxiter = 20\nE_conv = 1.0E-8\nD_conv = 1.0E-8\nguess = \'gwh\'\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nS = np.asarray(mints.ao_overlap())\nnbf = S.shape[0]\n\nprint(\'\\nNumber of doubly occupied orbitals: %d\' % ndocc)\nprint(\'Number of singly occupied orbitals:   %d\' % nsocc)\nprint(\'Number of basis functions:            %d\' % nbf)\n\nV = np.asarray(mints.ao_potential())\nT = np.asarray(mints.ao_kinetic())\n\nprint(\'\\nTotal time taken for integrals: %.3f seconds.\' % (time.time()-t))\n\nt = time.time()\n\n# Build H_core\nH = T + V\n\n# Orthogonalizer A = S^(-1/2)\nA = mints.ao_overlap()\nA.power(-0.5, 1.e-16)\nA = np.asarray(A)\n\nif guess == \'gwh\':\n    F = 0.875 * S * (np.diag(H)[:, None] + np.diag(H))\n    F[np.diag_indices_from(F)] = np.diag(H)\nelif guess == \'core\':\n    F = H.copy()\nelse:\n    raise Exception(""Unrecognized guess type %s. Please use \'core\' or \'gwh\'."" % guess)\n\n# Build initial orbitals and density matrices\nHp = A.dot(F).dot(A)\ne, Ct = np.linalg.eigh(Hp)\nC = A.dot(Ct)\nCnocc = C[:, :nocc]\nDocc = np.dot(Cnocc, Cnocc.T)\nCndocc = C[:, :ndocc]\nDdocc = np.dot(Cndocc, Cndocc.T)\n\nt = time.time()\nE = 0.0\nEnuc = mol.nuclear_repulsion_energy()\nEold = 0.0\n\n# Initialize the JK object\njk = psi4.core.JK.build(wfn.basisset())\njk.initialize()\n\n# Build a DIIS helper object\ndiis = scf_helper.DIIS_helper()\n\nprint(\'\\nTotal time taken for setup: %.3f seconds\' % (time.time() - t))\n\nprint(\'\\nStart SCF iterations:\\n\')\nt = time.time()\n\nfor SCF_ITER in range(1, maxiter + 1):\n\n    # Build a and b fock matrices\n    J, K = scf_helper.compute_jk(jk, [C[:, :nocc], C[:, :ndocc]])\n    J = J[0] + J[1]\n    Fa = H + J - K[0]\n    Fb = H + J - K[1]\n\n    # Build MO Fock matrix\n    moFa = (C.T).dot(Fa).dot(C)\n    moFb = (C.T).dot(Fb).dot(C)\n\n    # Special note on the ROHF Fock matrix (taken from Psi4)\n    # Fo = open-shell fock matrix = 0.5 Fa\n    # Fc = closed-shell fock matrix = 0.5 (Fa + Fb)\n    #\n    # The effective Fock matrix has the following structure\n    #          |  closed     open    virtual\n    #  ----------------------------------------\n    #  closed  |    Fc     2(Fc-Fo)    Fc\n    #  open    | 2(Fc-Fo)     Fc      2Fo\n    #  virtual |    Fc       2Fo       Fc\n\n    #print moFa[ndocc:nocc, ndocc:nocc] + moFb[ndocc:nocc, ndocc:nocc]\n    moFeff = 0.5 * (moFa + moFb)\n    moFeff[:ndocc, ndocc:nocc] = moFb[:ndocc, ndocc:nocc]\n    moFeff[ndocc:nocc, :ndocc] = moFb[ndocc:nocc, :ndocc]\n    moFeff[ndocc:nocc, nocc:] = moFa[ndocc:nocc, nocc:]\n    moFeff[nocc:, ndocc:nocc] = moFa[nocc:, ndocc:nocc]\n\n    # Back transform to AO Fock\n    Feff = (Ct).dot(moFeff).dot(Ct.T)\n\n    # Build gradient\n    IFock = moFeff[:nocc, ndocc:].copy()\n    IFock[:, :nsocc] /= 2\n    IFock[ndocc:, :] /= 2\n    IFock[ndocc:, :nsocc] = 0.0\n#    IFock[np.diag_indices_from(IFock)] = 0.0\n    diis_e = (Ct[:, :nocc]).dot(IFock).dot(Ct[:, ndocc:].T)\n    diis.add(Feff, diis_e)\n\n    # SCF energy and update\n    SCF_E  = np.einsum(\'pq,pq->\', Docc + Ddocc, H)\n    SCF_E += np.einsum(\'pq,pq->\', Docc, Fa)\n    SCF_E += np.einsum(\'pq,pq->\', Ddocc, Fb)\n    SCF_E *= 0.5\n    SCF_E += Enuc\n\n    dRMS = np.mean(diis_e**2)**0.5\n    print(\'SCF Iteration %3d: Energy = %4.16f   dE = % 1.5E   dRMS = %1.5E\'\n          % (SCF_ITER, SCF_E, (SCF_E - Eold), dRMS))\n    if (abs(SCF_E - Eold) < E_conv) and (dRMS < D_conv):\n        break\n\n    Eold = SCF_E\n\n    # Build new orbitals\n    Feff = diis.extrapolate()\n    e, Ct = np.linalg.eigh(Feff)\n    C = A.dot(Ct)\n\n    Cnocc = C[:, :nocc]\n    Docc = np.dot(Cnocc, Cnocc.T)\n    Cndocc = C[:, :ndocc]\n    Ddocc = np.dot(Cndocc, Cndocc.T)\n\n    if SCF_ITER == maxiter:\n        clean()\n        raise Exception(""Maximum number of SCF cycles exceeded."")\n\nprint(\'Total time for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\nprint(\'Final SCF energy: %.8f hartree\' % SCF_E)\n# Compare with Psi4\nSCF_E_psi = psi4.energy(\'SCF\')\npsi4.compare_values(SCF_E_psi, SCF_E, 6, \'SCF Energy\')\n'"
Self-Consistent-Field/SORHF.py,15,"b'""""""\nRestricted Hartree-Fock script using direct second-order convergence\nacceleration.\n\nReferences:\n- RHF equations & algorithms from [Szabo:1996]\n- SO equations & algorithm from [Helgaker:2000]\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=3, linewidth=200, suppress=True)\nfrom helper_HF import *\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'500 MB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'cc-pvdz\',\n                  \'guess\': \'sad\',\n                  \'d_convergence\': 1e-13,\n                  \'e_convergence\': 1e-13})\n\n# Build objects\ndiis = DIIS_helper()\nhf = helper_HF(mol, scf_type=\'PK\', guess=\'SAD\')\nndocc = hf.ndocc\nnvirt = hf.nvirt\nmints = psi4.core.MintsHelper(hf.wfn.basisset())\nmI = mints.ao_eri()\nhf.diag(hf.H, set_C=True)\n\n# Build Matrix and Numpy arrays that share memory\n# Updating npC changes mC\nmC = psi4.core.Matrix(hf.nbf, hf.nbf)\nnpC = np.asarray(mC)\nocc_mC = psi4.core.Matrix(hf.nbf, hf.ndocc)\nocc_npC = np.asarray(occ_mC)\n\n# Knobs\nE_conv = 1e-8\nD_conv = 1e-8\n\nprint(\'\\nStart SCF iterations:\\n\')\nt = time.time()\nE = 0.0\nEold = 0.0\nDold = 0.0\niter_type = \'DIAG\'\n\nfor SCF_ITER in range(1, 20):\n\n    # Build new fock matrix\n    F = hf.build_fock()\n\n    # DIIS error and update\n    diis_e = F.dot(hf.Da).dot(hf.S) - hf.S.dot(hf.Da).dot(F)\n    diis_e = (hf.A).dot(diis_e).dot(hf.A)\n    diis.add(F, diis_e)\n\n    # SCF energy and update\n    scf_e = hf.compute_hf_energy()\n    dRMS = np.mean(diis_e**2)**0.5\n    print(\'SCF Iteration %3d: Energy = %4.16f   dE = % 1.3E   dRMS = %1.3E   %s\' %\n          (SCF_ITER, hf.scf_e, (hf.scf_e - Eold), dRMS, iter_type))\n    if (abs(hf.scf_e - Eold) < E_conv) and (dRMS < D_conv):\n        break\n\n    Eold = hf.scf_e\n    Dold = hf.Da\n\n    if np.any(diis_e > 0.1):\n        F = diis.extrapolate()\n        e, C = hf.diag(F)\n        hf.set_Cleft(C)\n        iter_type = \'DIIS\'\n    else:\n        # Build MO Fock matrix & electronic gradient\n        moF = np.einsum(\'ui,vj,uv\', hf.Ca, hf.Ca, F)\n        gn = -4 * moF[:ndocc, ndocc:] # [Helgaker:2000] Eqn. 10.8.34, pp. 484\n\n        # AO -> MO ERI transform\n        # Only transform occupied on first index, oN^4 <<< N^5\n        # Update the Psi4 Matrices that these numpy arrays point to\n        npC[:] = hf.Ca\n        occ_npC[:] = hf.Ca[:, :ndocc]\n        MO = np.asarray(mints.mo_transform(mI, occ_mC, mC, mC, mC))\n\n        # Build electronic Hessian: [Helgaker:2000] Eqn. 10.9.22, pp. 494\n        # Biajb = 4 * [(Fab - Fij) + 4 * (ia|jb) - (ib|ja) - (ij|ab)]\n        Biajb = np.einsum(\'ab,ij->iajb\', moF[ndocc:, ndocc:], np.diag(np.ones(ndocc)))\n        Biajb -= np.einsum(\'ij,ab->iajb\', moF[:ndocc:, :ndocc], np.diag(np.ones(nvirt)))\n        Biajb += 4 * MO[:, ndocc:, :ndocc, ndocc:]\n        Biajb -= MO[:, ndocc:, :ndocc, ndocc:].swapaxes(0, 2)\n        Biajb -= MO[:, :ndocc, ndocc:, ndocc:].swapaxes(1, 2)\n        Biajb *= 4\n\n        # Invert B, (o^3 v^3); solves Newton equations H*x = B\n        Binv = np.linalg.inv(Biajb.reshape(ndocc * nvirt, -1)).reshape(ndocc, nvirt, ndocc, nvirt)\n\n        # Build orbital rotation matrix from Hessian inverse & gradient\n        x = np.einsum(\'iajb,ia->jb\', Binv, gn)\n        U = np.zeros_like(hf.Ca)\n        U[:ndocc, ndocc:] = x\n        U[ndocc:, :ndocc] = -x.T\n        U += 0.5 * np.dot(U, U)\n        U[np.diag_indices_from(hf.A)] += 1\n\n        # Easy access to Schmidt orthogonalization\n        U, r = np.linalg.qr(U.T)\n\n        # Rotate and set orbitals\n        C = hf.Ca.dot(U)\n        hf.set_Cleft(C)\n        iter_type = \'SOSCF\'\n\nprint(\'Total time taken for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\nprint(\'Final SCF energy:     %.8f hartree\' % hf.scf_e)\n\n# Compare to Psi4\nSCF_E_psi = psi4.energy(\'SCF\')\npsi4.compare_values(SCF_E_psi, hf.scf_e, 6, \'SCF Energy\')\n\n'"
Self-Consistent-Field/SORHF_iterative.py,14,"b'""""""\nRestricted Hartree--Fock script using iterative second-order\nconvergence acceleration via preconditioned conjugate gradients (PCG).\n\nReferences:\n- RHF equations & algorithms from [Szabo:1996]\n- SO equations from [Helgaker:2000]\n- PCG equations & algorithm from [Shewchuk:1994]\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=3, linewidth=200, suppress=True)\nfrom helper_HF import *\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 109\nsymmetry c1\n"""""")\n\npsi4.set_options({\'scf_type\': \'df\',\n                  \'basis\': \'aug-cc-pvdz\',\n                  \'e_convergence\': 1e1,\n                  \'d_convergence\': 1e1})\n\n# Knobs\nE_conv = 1.e-8\nD_conv = 1.e-4\nmax_macro = 10\nmax_micro = 3\nmicro_conv = 1.e-3\nmicro_print = True\n\n# Build objects\ndiis = DIIS_helper()\nhf = helper_HF(mol, scf_type=\'DF\', guess=\'CORE\')\nndocc = hf.ndocc\nnvirt = hf.nvirt\n\nprint(\'\\nStart SCF iterations:\\n\')\nt = time.time()\nE = 0.0\nEold = 0.0\niter_type = \'CORE\'\n\ndef SCF_Hx(x, moF, Co, Cv):\n    """"""\n    Compute the ""matrix-vector"" product between electronic Hessian (rank-4) and \n    matrix of nonredundant orbital rotations (rank-2).\n\n    Parameters\n    ----------\n    x : numpy.array\n        Matrix of nonredundant rotations.\n    moF : numpy.array\n        MO-basis Fock matrix\n    Co : numpy.array\n        Matrix of occupied orbital coefficients.\n    Cv : numpy.array\n        Matrix of virtual orbital coefficients.\n\n    Returns\n    -------\n    F : numpy.array\n        Hessian product tensor\n    """"""\n    F = np.dot(moF[:ndocc, :ndocc], x)\n    F -= np.dot(x, moF[ndocc:, ndocc:])\n\n    # Build two electron part, M = -4 (4 G_{mnip} - g_{mpin} - g_{npim}) K_{ip}\n    # From [Helgaker:2000] Eqn. 10.8.65\n    C_right = np.einsum(\'ia,sa->si\', -x, Cv)\n    J, K = hf.build_jk(Co, C_right)\n    F += (Co.T).dot(4 * J - K.T - K).dot(Cv)\n    F *= -4\n    return F\n\nfor SCF_ITER in range(1, max_macro):\n\n    # Build new fock matrix\n    F = hf.build_fock()\n\n    # DIIS error and update\n    diis_e = F.dot(hf.Da).dot(hf.S) - hf.S.dot(hf.Da).dot(F)\n    diis_e = (hf.A).dot(diis_e).dot(hf.A)\n    diis.add(F, diis_e)\n\n    # SCF energy and update\n    scf_e = hf.compute_hf_energy()\n    dRMS = np.mean(diis_e**2)**0.5\n    print(\'SCF Iteration %3d: Energy = %4.16f   dE = % 1.5E   dRMS = %1.5E   %s\' %\n          (SCF_ITER, hf.scf_e, (hf.scf_e - Eold), dRMS, iter_type))\n    if (abs(hf.scf_e - Eold) < E_conv) and (dRMS < D_conv):\n        break\n\n    Eold = hf.scf_e\n\n    # Build MO fock matrix and gradient\n    Co = hf.Ca[:, :ndocc]\n    Cv = hf.Ca[:, ndocc:]\n    moF = np.einsum(\'ui,vj,uv->ij\', hf.Ca, hf.Ca, F)\n    gradient = -4 * moF[:ndocc, ndocc:] # [Helgaker:2000] Eqn. 10.8.34, pp. 484\n    grad_dot = np.vdot(gradient, gradient)\n\n    if (np.max(np.abs(gradient)) > 0.2):\n        F = diis.extrapolate()\n        eps, C = hf.diag(F)\n        hf.set_Cleft(C)\n        iter_type = \'DIIS\'\n    else:\n        # Perform PCG on H*x = B to solve for rotation matrix `x`\n        # Initial guess\n        eps = np.diag(moF)\n        # Construct Jacobi preconditioner for H\n        precon = -4 * (eps[:ndocc].reshape(-1, 1) - eps[ndocc:])\n\n        x = gradient / precon\n        Ax = SCF_Hx(x, moF, Co, Cv)\n        r = gradient - Ax\n        z = r / precon\n        p = z.copy()\n        rms = (np.vdot(r, r) / grad_dot)**0.5\n        if micro_print:\n            print(\'Micro Iteration Guess: Rel. RMS = %1.5e\' % (rms))\n\n        # PCG iterations: [Shewchuk:1994]\n        for rot_iter in range(max_micro):\n            rz_old = np.vdot(r, z)\n\n            Ap = SCF_Hx(p, moF, Co, Cv)\n            alpha = rz_old / np.vdot(Ap, p)\n\n            x += alpha * p\n            r -= alpha * Ap\n            z = r / precon\n\n            rms = (np.vdot(r, r) / grad_dot)**0.5\n\n            if micro_print:\n                print(\'Micro Iteration %5d: Rel. RMS = %1.5e\' % (rot_iter + 1, rms))\n            if rms < micro_conv:\n                break\n\n            beta = np.vdot(r, z) / rz_old\n            p = z + beta * p\n\n        C = rotate_orbitals(hf.Ca, x)\n\n        hf.set_Cleft(C)\n        iter_type = \'SOSCF, nmicro \' + str(rot_iter + 1)\n\nprint(\'Total time taken for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\nprint(\'Final SCF energy:     %.8f hartree\' % hf.scf_e)\n\n# Compute w/ Psi4 and compare\npsi4.set_options({\'e_convergence\': 1e-7,\n                  \'d_convergence\': 1e-7})\n\nSCF_E_psi = psi4.energy(\'SCF\')\npsi4.compare_values(SCF_E_psi, hf.scf_e, 6, \'SCF Energy\')\n\n\n'"
Self-Consistent-Field/SOROHF.py,40,"b'""""""\nRestricted open-shell Hartree--Fock (ROHF) using direct second-order\nconvergence acceleration.\n\nReferences:\n- ROHF equations & algorithms adapted from Psi4\n- SO equations & algorithm from [Helgaker:2000]\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nimport helper_HF as scf_helper\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\n# Triplet O2\nmol = psi4.geometry(""""""\n    0 3\n    O\n    O 1 1.2\nsymmetry c1\n"""""")\n\npsi4.set_options({\'guess\': \'core\',\n                  \'basis\': \'aug-cc-pvdz\',\n                  \'scf_type\': \'pk\',\n                  \'e_convergence\': 1e-8,\n                  \'reference\': \'rohf\'})\n\nwfn = psi4.core.Wavefunction.build(mol, psi4.core.get_global_option(\'BASIS\'))\n\n# Set occupations\nnocc = wfn.nalpha()\nndocc = wfn.nbeta()\nnsocc = nocc - ndocc\n\n# Set defaults\nmaxiter = 10\nmax_micro = 4\nmicro_print = True\nmicro_conv = 1.e-3\nE_conv = 1.0E-8\nD_conv = 1.0E-4\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nS = np.asarray(mints.ao_overlap())\nnbf = S.shape[0]\n\njk = psi4.core.JK.build(wfn.basisset())\njk.initialize()\nif nbf > 100:\n    raise Exception(""This has a N^4 memory overhead, killing if nbf > 100."")\n\nprint(\'\\nNumber of doubly occupied orbitals: %d\' % ndocc)\nprint(\'Number of singly occupied orbitals: %d\' % nsocc)\nprint(\'Number of basis functions:          %d\' % nbf)\n\nV = np.asarray(mints.ao_potential())\nT = np.asarray(mints.ao_kinetic())\n\n# Build H_core\nH = T + V\n\n# ERI\'s\nI = np.asarray(mints.ao_eri())\n\n# Orthogonalizer A = S^(-1/2)\nA = mints.ao_overlap()\nA.power(-0.5, 1.e-16)\nA = np.asarray(A)\n\nprint(\'\\nTotal time taken for integrals: %.3f seconds.\' % (time.time() - t))\n\nt = time.time()\n\n\ndef transform(I, C1, C2, C3, C4):\n    """"""\n    Transforms the 4-index ERI I with the 4 transformation matrices C1 to C4.\n    """"""\n    nao = I.shape[0]\n    MO = np.dot(C1.T, I.reshape(nao, -1)).reshape(C1.shape[1], nao, nao, nao)\n\n    MO = np.einsum(\'qB,Aqrs->ABrs\', C2, MO)\n    MO = np.einsum(\'rC,ABrs->ABCs\', C3, MO)\n    MO = np.einsum(\'sD,ABCs->ABCD\', C4, MO)\n    return MO\n\n\n# Build initial orbitals and density matrices\nHp = A.dot(H).dot(A)\ne, Ct = np.linalg.eigh(Hp)\nC = A.dot(Ct)\nCnocc = C[:, :nocc]\nDocc = np.dot(Cnocc, Cnocc.T)\nCndocc = C[:, :ndocc]\nDdocc = np.dot(Cndocc, Cndocc.T)\n\nt = time.time()\nE = 0.0\nEnuc = mol.nuclear_repulsion_energy()\nEold = 0.0\niter_type = \'CORE\'\n\n# Build a DIIS helper object\ndiis = scf_helper.DIIS_helper()\n\nprint(\'\\nTotal time taken for setup: %.3f seconds\' % (time.time() - t))\n\nprint(\'\\nStart SCF iterations:\\n\')\nt = time.time()\n\nfor SCF_ITER in range(1, maxiter + 1):\n\n    # Build a and b fock matrices\n    Ja = np.einsum(\'pqrs,rs->pq\', I, Docc)\n    Ka = np.einsum(\'prqs,rs->pq\', I, Docc)\n    Jb = np.einsum(\'pqrs,rs->pq\', I, Ddocc)\n    Kb = np.einsum(\'prqs,rs->pq\', I, Ddocc)\n    J = Ja + Jb\n    Fa = H + J - Ka\n    Fb = H + J - Kb\n\n    # Build MO Fock matrix\n    moFa = (C.T).dot(Fa).dot(C)\n    moFb = (C.T).dot(Fb).dot(C)\n\n    # Special note on the ROHF Fock matrix (taken from psi4)\n    # Fo = open-shell fock matrix = 0.5 Fa\n    # Fc = closed-shell fock matrix = 0.5 (Fa + Fb)\n    #\n    # The effective Fock matrix has the following structure\n    #          |  closed     open    virtual\n    #  ----------------------------------------\n    #  closed  |    Fc     2(Fc-Fo)    Fc\n    #  open    | 2(Fc-Fo)     Fc      2Fo\n    #  virtual |    Fc       2Fo       Fc\n\n    moFeff = 0.5 * (moFa + moFb)\n    moFeff[:ndocc, ndocc:nocc] = moFb[:ndocc, ndocc:nocc]\n    moFeff[ndocc:nocc, :ndocc] = moFb[ndocc:nocc, :ndocc]\n    moFeff[ndocc:nocc, nocc:] = moFa[ndocc:nocc, nocc:]\n    moFeff[nocc:, ndocc:nocc] = moFa[nocc:, ndocc:nocc]\n\n    # Back transform to AO Fock\n    Feff = (Ct).dot(moFeff).dot(Ct.T)\n\n    # Build gradient\n    IFock = moFeff[:nocc, ndocc:].copy()\n    IFock[ndocc:, :nsocc] = 0.0\n    diis_e = (Ct[:, :nocc]).dot(IFock).dot(Ct[:, ndocc:].T)\n    diis.add(Feff, diis_e)\n\n    # SCF energy and update\n    SCF_E = np.einsum(\'pq,pq->\', Docc + Ddocc, H)\n    SCF_E += np.einsum(\'pq,pq->\', Docc, Fa)\n    SCF_E += np.einsum(\'pq,pq->\', Ddocc, Fb)\n    SCF_E *= 0.5\n    SCF_E += Enuc\n\n    dRMS = np.mean(diis_e**2)**0.5\n    print(\'SCF Iteration %3d: Energy = %4.16f   dE = % 1.5E   dRMS = %1.5E   %s\' % \\\n            (SCF_ITER, SCF_E, (SCF_E - Eold), dRMS, iter_type))\n    if (abs(SCF_E - Eold) < E_conv) and (dRMS < D_conv):\n        break\n\n    #if SCF_ITER == maxiter:\n    #    clean()\n    #    raise Exception(""Maximum number of SCF cycles exceeded."")\n\n    ediff = abs(SCF_E - Eold)\n    Eold = SCF_E\n\n    gradient = -4 * IFock.copy()\n    gradient[ndocc:] /= 2\n    gradient[:, :nsocc] /= 2\n    gradient[ndocc:, :nsocc] = 0.0\n    grad_dot = np.linalg.norm(gradient)\n\n    #if True:\n    if (np.max(np.abs(gradient)) > 0.1):\n        # Conventional update\n        Feff = diis.extrapolate()\n        e, Ct = np.linalg.eigh(Feff)\n        C = A.dot(Ct)\n        iter_type = \'DIIS\'\n\n    else:\n        # Second-order update\n        Cocc = C[:, :nocc]\n        Cvir = C[:, ndocc:]\n        nvir = nbf - ndocc\n\n        # Build an approximate ROHF guess\n        eps = np.diag(moFeff)\n        precon = -4 * (eps[:nocc].reshape(-1, 1) - eps[ndocc:])\n        precon[ndocc:, :nsocc] = 1\n        precon[ndocc:] /= 2\n        guess_x = gradient / precon\n\n        # Start Hessian\n        MOovov = transform(I, Cocc, Cvir, Cocc, Cvir)\n        MOoovv = transform(I, Cocc, Cocc, Cvir, Cvir)\n\n        IAJB = MOovov.copy()\n\n        IAJB -= 0.5 * np.einsum(\'pqrs->psrq\', MOovov)\n        IAJB -= 0.5 * np.einsum(\'pqrs->qspr\', MOoovv)\n\n        iajb = IAJB.copy()\n\n        IAJB += 0.5 * np.einsum(\'IJ,AB->IAJB\', np.diag(np.ones(nocc)), moFa[ndocc:, ndocc:])\n        IAJB -= 0.5 * np.einsum(\'AB,IJ->IAJB\', np.diag(np.ones(nvir)), moFa[:nocc, :nocc])\n\n        # We need to zero out the redundant rotations\n        IAJB[:, :nsocc, :, :] = 0.0\n        IAJB[:, :, :, :nsocc] = 0.0\n\n        iajb += 0.5 * np.einsum(\'IJ,AB->IAJB\', np.diag(np.ones(nocc)), moFb[ndocc:, ndocc:])\n        iajb -= 0.5 * np.einsum(\'AB,IJ->IAJB\', np.diag(np.ones(nvir)), moFb[:nocc, :nocc])\n\n        # We need to zero out the redundant rotations\n        iajb[:, :, ndocc:, :] = 0.0\n        iajb[ndocc:, :, :, :] = 0.0\n\n        IAjb = MOovov.copy()\n        for i in range(nsocc):\n            IAjb[ndocc + i, :, :, i] += 0.5 * moFb[ndocc:, :nocc]\n\n        # We need to zero out the redundant rotations\n        IAjb[:, :, ndocc:, :] = 0.0\n        IAjb[:, :nsocc, :, :] = 0.0\n\n        iaJB = np.einsum(\'pqrs->rspq\', IAjb)\n\n        # Build and find x\n        Hess = IAJB + IAjb + iaJB + iajb\n\n        Hess *= 4\n        ndim = Hess.shape[0] * Hess.shape[1]\n\n        Hess = Hess.reshape(gradient.size, -1)  # Make the hessian square\n        Hess[np.diag_indices_from(Hess)] += 1.e-14  # Prevent singularities\n        x = np.linalg.solve(Hess, gradient.ravel()).reshape(nocc, nvir)\n\n        # Special orbital rotation, some overlap in the middle\n        U = np.zeros((C.shape[1], C.shape[1]))\n        U[:nocc, ndocc:] = x\n        U[ndocc:, :nocc] = -x.T\n\n        U += 0.5 * np.dot(U, U)\n        U[np.diag_indices_from(U)] += 1\n\n        # Easy acess to shmidt orthogonalization\n        U, r = np.linalg.qr(U.T)\n        #print U\n\n        # Rotate and set orbitals\n        Ct = Ct.dot(U)\n        C = A.dot(Ct)\n\n        iter_type = \'SOSCF\'\n\n    Cnocc = C[:, :nocc]\n    Docc = np.dot(Cnocc, Cnocc.T)\n    Cndocc = C[:, :ndocc]\n    Ddocc = np.dot(Cndocc, Cndocc.T)\n\nprint(\'Total time for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\nprint(\'Final SCF energy: %.8f hartree\' % SCF_E)\n\n# Compare to Psi4\nSCF_E_psi = psi4.energy(\'SCF\')\npsi4.compare_values(SCF_E_psi, SCF_E, 6, \'SCF Energy\')\n'"
Self-Consistent-Field/SOROHF_iterative.py,33,"b'""""""\nA iterative second-order restricted open-shell Hartree-Fock script using the Psi4NumPy Formalism\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nimport helper_HF as scf_helper\nimport scipy.linalg as SLA\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\n# Triplet O2\nmol = psi4.geometry(""""""\n    0 5\n    O\n    O 1 1.2\nsymmetry c1\n"""""")\n\npsi4.set_options({\'guess\': \'core\',\n                  \'basis\': \'aug-cc-pvtz\',\n                  \'scf_type\': \'df\',\n                  \'e_convergence\': 1e-8,\n                  \'reference\': \'rohf\'})\n\nwfn = psi4.core.Wavefunction.build(mol, psi4.core.get_global_option(\'BASIS\'))\n\n# Set occupations\nnocc = wfn.nalpha()\nndocc = wfn.nbeta()\nnsocc = nocc - ndocc\n\n# Set defaults\nmaxiter = 15\nmax_micro = 5\nmicro_print = True\nmicro_conv = 5.e-3\nE_conv = 1.0E-8\nD_conv = 1.0E-8\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nS = np.asarray(mints.ao_overlap())\nnbf = S.shape[0]\n\n#I = np.array(mints.ao_eri())\n\nprint(\'\\nNumber of doubly occupied orbitals: %d\' % ndocc)\nprint(\'Number of singly occupied orbitals: %d\' % nsocc)\nprint(\'Number of basis functions:          %d\' % nbf)\n\nV = np.asarray(mints.ao_potential())\nT = np.asarray(mints.ao_kinetic())\n\nprint(\'\\nTotal time taken for integrals: %.3f seconds.\' % (time.time()-t))\n\nt = time.time()\n\n# Build H_core\nH = T + V\n\n# Orthogonalizer A = S^(-1/2)\nA = mints.ao_overlap()\nA.power(-0.5, 1.e-16)\nA = np.asarray(A)\n\ndef SCF_Hx(x, moFa, moFb, C):\n    """"""\n    Compute a hessian vector guess where x is a ov matrix of nonredundant operators.\n    """"""\n\n    Co_a = C[:, :nocc]\n    Co_b = C[:, :ndocc]\n    C_right_a = np.dot(C[:, nocc:], x[:, nsocc:].T)\n    C_right_b = np.dot(C[:, ndocc:], x[:ndocc, :].T)\n    J, K = scf_helper.compute_jk(jk, [Co_a, Co_b], [C_right_a, C_right_b])\n    J1, J2 = J\n    K1, K2 = K\n\n    IAJB = (C[:, :nocc].T).dot(J1 - 0.5 * K1 - 0.5 * K1.T).dot(C[:, ndocc:])\n    IAJB += 0.5 * np.dot(x[:, nsocc:], moFa[nocc:, ndocc:])\n    IAJB -= 0.5 * np.dot(moFa[:nocc, :nocc], x)\n    IAJB[:, :nsocc] = 0.0\n\n    iajb = (C[:, :nocc].T).dot(J2 - 0.5 * K2 - 0.5 * K2.T).dot(C[:, ndocc:])\n    iajb += 0.5 * np.dot(x, moFb[ndocc:, ndocc:])\n    iajb -= 0.5 * np.dot(moFb[:nocc, :ndocc], x[:ndocc, :])\n    iajb[ndocc:, :] = 0.0\n\n    IAjb = (C[:, :nocc].T).dot(J2).dot(C[:, ndocc:])\n    IAjb[ndocc:] += 0.5 * np.dot(x[:, :nsocc].T, moFb[:nocc, ndocc:])\n    IAjb[:, :nsocc] = 0.0\n\n    iaJB = (C[:, :nocc].T).dot(J1).dot(C[:, ndocc:])\n    iaJB[:, :nsocc] += 0.5 * np.dot(moFb[:nocc, nocc:], x[ndocc:, nsocc:].T)\n    iaJB[ndocc:] = 0.0\n\n    ret = 4 * (IAJB + IAjb + iaJB + iajb)\n\n    return ret\n\n# Build initial orbitals and density matrices\nHp = A.dot(H).dot(A)\ne, Ct = np.linalg.eigh(Hp)\nC = A.dot(Ct)\nCnocc = C[:, :nocc]\nDocc = np.dot(Cnocc, Cnocc.T)\nCndocc = C[:, :ndocc]\nDdocc = np.dot(Cndocc, Cndocc.T)\n\nt = time.time()\nE = 0.0\nEnuc = mol.nuclear_repulsion_energy()\nEold = 0.0\niter_type = \'CORE\'\n\n# Initialize the JK object\njk = psi4.core.JK.build(wfn.basisset())\njk.initialize()\n\n# Build a DIIS helper object\ndiis = scf_helper.DIIS_helper()\n\nprint(\'\\nTotal time taken for setup: %.3f seconds\' % (time.time() - t))\n\nprint(\'\\nStart SCF iterations:\\n\')\nt = time.time()\n\nfor SCF_ITER in range(1, maxiter + 1):\n\n    # Build a and b fock matrices\n    J, K = scf_helper.compute_jk(jk, [C[:, :nocc], C[:, :ndocc]])\n    J = J[0] + J[1]\n    Fa = H + J - K[0]\n    Fb = H + J - K[1]\n\n    # Build MO Fock matrix\n    moFa = (C.T).dot(Fa).dot(C)\n    moFb = (C.T).dot(Fb).dot(C)\n\n    # Special note on the ROHF Fock matrix (taken from psi4)\n    # Fo = open-shell fock matrix = 0.5 Fa\n    # Fc = closed-shell fock matrix = 0.5 (Fa + Fb)\n    #\n    # The effective Fock matrix has the following structure\n    #          |  closed     open    virtual\n    #  ----------------------------------------\n    #  closed  |    Fc     2(Fc-Fo)    Fc\n    #  open    | 2(Fc-Fo)     Fc      2Fo\n    #  virtual |    Fc       2Fo       Fc\n\n    moFeff = 0.5 * (moFa + moFb)\n    moFeff[:ndocc, ndocc:nocc] = moFb[:ndocc, ndocc:nocc]\n    moFeff[ndocc:nocc, :ndocc] = moFb[ndocc:nocc, :ndocc]\n    moFeff[ndocc:nocc, nocc:] = moFa[ndocc:nocc, nocc:]\n    moFeff[nocc:, ndocc:nocc] = moFa[nocc:, ndocc:nocc]\n\n    # Back transform to AO Fock\n    Feff = (Ct).dot(moFeff).dot(Ct.T)\n\n    # Build gradient\n    IFock = moFeff[:nocc, ndocc:].copy()\n    IFock[ndocc:, :nsocc] = 0.0\n    diis_e = (Ct[:, :nocc]).dot(IFock).dot(Ct[:, ndocc:].T)\n    diis.add(Feff, diis_e)\n\n    # SCF energy and update\n    SCF_E  = np.einsum(\'pq,pq->\', Docc + Ddocc, H)\n    SCF_E += np.einsum(\'pq,pq->\', Docc, Fa)\n    SCF_E += np.einsum(\'pq,pq->\', Ddocc, Fb)\n    SCF_E *= 0.5\n    SCF_E += Enuc\n\n    dRMS = np.mean(diis_e**2)**0.5\n    print(\'SCF Iteration %3d: Energy = %4.16f   dE = % 1.5E   dRMS = %1.5E   %s\' % \\\n            (SCF_ITER, SCF_E, (SCF_E - Eold), dRMS, iter_type))\n    if (abs(SCF_E - Eold) < E_conv) and (dRMS < D_conv):\n        break\n\n    if SCF_ITER == maxiter:\n        psi4.core.clean()\n        raise Exception(""Maximum number of SCF cycles exceeded."")\n\n    ediff = abs(SCF_E - Eold)\n    Eold = SCF_E\n\n\n    gradient = -4 * IFock.copy()\n    gradient[ndocc:] /= 2\n    gradient[:, :nsocc] /= 2\n    grad_dot = np.vdot(gradient, gradient)\n\n    if (np.max(np.abs(gradient)) > 0.2):\n        # Conventional update\n        Feff = diis.extrapolate()\n        e, Ct = np.linalg.eigh(Feff)\n        C = A.dot(Ct)\n        iter_type = \'DIIS\'\n\n    else:\n        # Second-order update\n        eps = np.diag(moFeff)\n        precon = -3.5 * (eps[:nocc].reshape(-1, 1) - eps[ndocc:])\n        precon[ndocc:] *= 0.5\n        precon[:, :nsocc] *= 0.5\n        precon[ndocc:, :nsocc] = 1\n        x = gradient / precon\n\n        Ax = SCF_Hx(x, moFa, moFb, C)\n        r = gradient - Ax\n        z = r / precon\n        p = z.copy()\n        rms = (np.vdot(r,r) / grad_dot) ** 0.5\n        if micro_print:\n            print(\'Micro Iteration Guess: Rel. RMS = %1.5e\' %  (rms))\n\n        # CG iterations\n        for rot_iter in range(max_micro):\n            rz_old = np.vdot(r, z)\n\n            Ap = SCF_Hx(p, moFa, moFb, C)\n            alpha = rz_old / np.vdot(Ap, p)\n\n            x += alpha * p\n            r -= alpha * Ap\n            z = r / precon\n\n            rms = (np.vdot(r, r) / grad_dot) ** 0.5\n\n            if micro_print:\n                print(\'Micro Iteration %5d: Rel. RMS = %1.5e\' %  (rot_iter + 1, rms))\n            if rms < micro_conv:\n                break\n\n            beta = np.vdot(r, z) / rz_old\n            p = z + beta * p\n\n        # Special orbital rotation, some overlap in the middle\n        U = np.zeros((C.shape[1], C.shape[1]))\n        U[:nocc, ndocc:] = x\n        U[ndocc:, :nocc] = -x.T\n\n        U = SLA.expm(U.T)\n        # Rotate and set orbitals\n        Ct = Ct.dot(U)\n        C = C.dot(U)\n\n        iter_type = \'SOSCF, nmicro \' + str(rot_iter + 1)\n\n    Cnocc = C[:, :nocc]\n    Docc = np.dot(Cnocc, Cnocc.T)\n    Cndocc = C[:, :ndocc]\n    Ddocc = np.dot(Cndocc, Cndocc.T)\n\n\nprint(\'Total time for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\nprint(\'Final SCF energy: %.8f hartree\' % SCF_E)\n\n# Compare to Psi4\nSCF_E_psi = psi4.energy(\'SCF\')\npsi4.compare_values(SCF_E_psi, SCF_E, 6, \'SCF Energy\')\n'"
Self-Consistent-Field/SOUHF.py,37,"b'""""""\nUnrestricted open-shell Hartree-Fock using direct second-order\nconvergence acceleration.\n\nReferences:\n- UHF equations & algorithm from [Szabo:1996]\n- SO equations & algorithm from [Helgaker:2000]\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Set Psi4 memory and output options\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Triplet oxygen\nmol = psi4.geometry(""""""\n    0 3\n    O\n    O 1 1.2\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'aug-cc-pvdz\',\n                  \'reference\': \'uhf\'})\n\n# Set defaults\nmaxiter = 10\nE_conv = 1.0E-13\nD_conv = 1.0E-13\n\n# Integral generation from Psi4\'s MintsHelper\nwfn = psi4.core.Wavefunction.build(mol, psi4.core.get_global_option(\'BASIS\'))\nmints = psi4.core.MintsHelper(wfn.basisset())\nS = np.asarray(mints.ao_overlap())\nV = np.asarray(mints.ao_potential())\nT = np.asarray(mints.ao_kinetic())\n\n# Occupations\nnbf = wfn.nso()\nnalpha = wfn.nalpha()\nnbeta = wfn.nbeta()\n\nif nbf > 100:\n    raise Exception(""This has a N^4 memory overhead, killing if nbf > 100."")\n\nH = T + V\n\n# Orthogonalizer A = S^(-1/2)\nA = mints.ao_overlap()\nA.power(-0.5, 1.e-16)\nA = np.asarray(A)\n\n# ERI\'s\nI = np.asarray(mints.ao_eri())\n\n# Steal a good starting guess\npsi4.set_options({\'e_convergence\': 1e-4,\n                  \'d_convergence\': 1e-4,\n                  \'maxiter\': 7,\n                  \'guess\': \'sad\'})\n\nscf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\nCa = np.array(wfn.Ca())\nDa = np.array(wfn.Da())\nCb = np.array(wfn.Cb())\nDb = np.array(wfn.Db())\n\nnalpha = wfn.nalpha()\nnbeta = wfn.nbeta()\n\nt = time.time()\nE = 0.0\nEnuc = mol.nuclear_repulsion_energy()\nEold = 0.0\n\nprint(\'\\nTotal time taken for setup: %.3f seconds\' % (time.time() - t))\n\nprint(\'\\nStart SCF iterations:\\n\')\nt = time.time()\n\n\ndef transform(I, C1, C2, C3, C4):\n    #MO = np.einsum(\'pA,pqrs->Aqrs\', C1,  I)\n    nao = I.shape[0]\n    MO = np.dot(C1.T, I.reshape(nao, -1)).reshape(C1.shape[1], nao, nao, nao)\n\n    MO = np.einsum(\'qB,Aqrs->ABrs\', C2, MO)\n    MO = np.einsum(\'rC,ABrs->ABCs\', C3, MO)\n    MO = np.einsum(\'sD,ABCs->ABCD\', C4, MO)\n    return MO\n\n# Rotate orbs and produce C and D matrices\ndef rotate_orbs(C, x, nocc):\n    U = np.zeros_like(C)\n    U[:nocc, nocc:] = x\n    U[nocc:, :nocc] = -x.T\n\n    expU = U.copy()\n    expU[np.diag_indices_from(U)] += 1\n    expU += 0.5 * np.dot(U, U)\n\n    expU, r = np.linalg.qr(expU.T)\n    Cn = C.dot(expU)\n    D = np.dot(Cn[:,:nocc], Cn[:,:nocc].T)\n    return (Cn, D)\n\nfor SCF_ITER in range(1, maxiter + 1):\n\n    # Build the alpha & beta Fock matrices\n    Ja = np.einsum(\'pqrs,rs->pq\', I, Da)\n    Ka = np.einsum(\'prqs,rs->pq\', I, Da)\n    Jb = np.einsum(\'pqrs,rs->pq\', I, Db)\n    Kb = np.einsum(\'prqs,rs->pq\', I, Db)\n\n    Fa = H + (Ja + Jb) - Ka\n    Fb = H + (Ja + Jb) - Kb\n\n    # dRMS error\n    diisa_e = A.dot(Fa.dot(Da).dot(S) - S.dot(Da).dot(Fa)).dot(A)\n    diisb_e = A.dot(Fb.dot(Db).dot(S) - S.dot(Db).dot(Fb)).dot(A)\n\n    # SCF energy and update: [Szabo:1996], exercise 3.40, pp. 215\n    SCF_E = np.einsum(\'pq,pq->\', Da + Db, H)\n    SCF_E += np.einsum(\'pq,pq->\', Da, Fa)\n    SCF_E += np.einsum(\'pq,pq->\', Db, Fb)\n    SCF_E *= 0.5\n    SCF_E += Enuc\n\n    dRMS = 0.5 * (np.mean(diisa_e**2)**0.5 + np.mean(diisb_e**2)**0.5)\n    print(\'SCF Iteration %3d: Energy = %4.16f   dE = % 1.5E   dRMS = %1.5E\'\n          % (SCF_ITER, SCF_E, (SCF_E - Eold), dRMS))\n    if (abs(SCF_E - Eold) < E_conv) and (dRMS < D_conv):\n        break\n\n    Eold = SCF_E\n\n    Cocca = Ca[:, :nalpha]\n    Cvira = Ca[:, nalpha:]\n\n    Coccb = Cb[:, :nbeta]\n    Cvirb = Cb[:, nbeta:]\n\n    # Form gradients from MO Fock matrices: [Helgaker:2000] Eqn. 10.8.34, pp. 484\n    moFa = (Ca.T).dot(Fa).dot(Ca)\n    moFb = (Cb.T).dot(Fb).dot(Cb)\n    grada = -4 * moFa[:nalpha, nalpha:]\n    gradb = -4 * moFb[:nbeta, nbeta:]\n\n    # Form off diagonal contributions to Hessian\n    Jab = 8 * transform(I, Cocca, Cvira, Coccb, Cvirb)\n\n    # Form diagonal alpha contributions\n    MOaa = transform(I, Cocca, Ca, Ca, Ca)\n    Ha  = np.einsum(\'ab,ij->iajb\', moFa[nalpha:, nalpha:], np.diag(np.ones(nalpha)))\n    Ha -= np.einsum(\'ij,ab->iajb\', moFa[:nalpha:, :nalpha], np.diag(np.ones(nbf-nalpha)))\n    Ha += 2 * MOaa[:, nalpha:, :nalpha, nalpha:]\n    Ha -= MOaa[:, nalpha:, :nalpha, nalpha:].swapaxes(0, 2)\n    Ha -= MOaa[:, :nalpha, nalpha:, nalpha:].swapaxes(1, 2)\n    Ha *= 4\n\n    # Form diagonal beta contributions\n    MObb = transform(I, Coccb, Cb, Cb, Cb)\n    Hb  = np.einsum(\'ab,ij->iajb\', moFb[nbeta:, nbeta:], np.diag(np.ones(nbeta)))\n    Hb -= np.einsum(\'ij,ab->iajb\', moFb[:nbeta:, :nbeta], np.diag(np.ones(nbf-nbeta)))\n    Hb += 2 * MObb[:, nbeta:, :nbeta, nbeta:]\n    Hb -= MObb[:, nbeta:, :nbeta, nbeta:].swapaxes(0, 2)\n    Hb -= MObb[:, :nbeta, nbeta:, nbeta:].swapaxes(1, 2)\n    Hb *= 4\n\n    # Build the full Hessian matrix\n    na = Ha.shape[0] * Ha.shape[1]\n    nb = Hb.shape[0] * Hb.shape[1]\n    ntot = na + nb\n\n    #  aa | ab\n    #  -------\n    #  ba | bb\n    Hess = np.zeros((ntot, ntot))\n    Hess[:na,:na] = Ha.reshape(na, na)\n    Hess[:na,na:] = Jab.reshape(na,nb)\n    Hess[na:,:na] = Jab.reshape(na,nb).T\n    Hess[na:,na:] = Hb.reshape(nb, nb)\n\n    # Invert hessian and obtain new vectors\n    Hinv = np.linalg.inv(Hess)\n\n    gradvec = np.hstack((grada.reshape(-1), gradb.reshape(-1)))\n    resultx = np.einsum(\'ij,j->i\', Hinv, gradvec)\n\n    xa = resultx[:na].reshape(Ha.shape[0], Ha.shape[1])\n    xb = resultx[na:].reshape(Hb.shape[0], Hb.shape[1])\n\n    # Rotate the orbitals\n    Ca, Da = rotate_orbs(Ca, xa, nalpha)\n    Cb, Db = rotate_orbs(Cb, xb, nbeta)\n\n    if SCF_ITER == maxiter:\n        clean()\n        raise Exception(""Maximum number of SCF cycles exceeded."")\n\nprint(\'Total time for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\nspin_mat = (Cb[:, :nbeta].T).dot(S).dot(Ca[:, :nalpha])\nspin_contam = min(nalpha, nbeta) - np.vdot(spin_mat, spin_mat)\nprint(\'Spin Contamination Metric: %1.5E\\n\' % spin_contam)\n\nprint(\'Final SCF energy: %.8f hartree\' % SCF_E)\n\n# Compare to Psi4\npsi4.set_options({\'e_convergence\': 1e-8,\n                  \'r_convergence\': 1e-8,\n                  \'scf_type\': \'pk\',\n                  \'maxiter\': 100})\n\nSCF_E_psi = psi4.energy(\'SCF\')\npsi4.compare_values(SCF_E_psi, SCF_E, 6, \'SCF Energy\')\n'"
Self-Consistent-Field/SOUHF_iterative.py,33,"b'""""""\nUnrestricted Hartree--Fock script using iterative second-order\nconvergence acceleration via preconditioned conjugate gradients (PCG).\n\nReferences:\n- UHF equations & algorithms from [Szabo:1996]\n- SO equations from [Helgaker:2000]\n- PCG equations & algorithm from [Shewchuk:1994]\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nimport helper_HF as scf_helper\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\n# Triplet O2, actually very multireference\nmol = psi4.geometry(""""""\n    0 3\n    O\n    O 1 1.2\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'aug-cc-pvdz\',\n                  \'scf_type\': \'df\',\n                  \'e_convergence\': 1e-8,\n                  \'reference\': \'uhf\'})\n\n# Set defaults\nmaxiter = 10\nE_conv = 1.0E-8\nD_conv = 1.0E-5\nmax_micro = 4\nmicro_conv = 5.e-2\nmicro_print = True\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nwfn = psi4.core.Wavefunction.build(mol, psi4.core.get_global_option(\'BASIS\'))\nmints = psi4.core.MintsHelper(wfn.basisset())\nS = np.asarray(mints.ao_overlap())\n\n# Occupations\nnbf = wfn.nso()\nnalpha = wfn.nalpha()\nnbeta = wfn.nbeta()\n\nprint(\'\\nNumber of doubly occupied orbitals: %d\' % nalpha)\nprint(\'\\nNumber of singly occupied orbitals: %d\' % (nalpha - nbeta))\nprint(\'Number of basis functions: %d\' % nbf)\n\nV = np.asarray(mints.ao_potential())\nT = np.asarray(mints.ao_kinetic())\n\nprint(\'\\nTotal time taken for integrals: %.3f seconds.\' % (time.time()-t))\n\nt = time.time()\n\n# Build H_core\nH = T + V\n\n# Orthogonalizer A = S^(-1/2)\nA = mints.ao_overlap()\nA.power(-0.5, 1.e-16)\nA = np.asarray(A)\n\n\ndef diag_H(H, nocc):\n    Hp = A.dot(H).dot(A)\n    e, C2 = np.linalg.eigh(Hp)\n    C = A.dot(C2)\n    Cocc = C[:, :nocc]\n    D = np.einsum(\'pi,qi->pq\', Cocc, Cocc)\n    return (C, D)\n\n\ndef SCF_Hx(xa, xb, moFa, Co_a, Cv_a, moFb, Co_b, Cv_b):\n    """"""\n    Compute the ""matrix-vector"" product between electronic Hessian (rank-4) and\n    matrix of nonredundant orbital rotations (rank-2).\n\n    Parameters\n    ----------\n    x : numpy.array\n        Matrix of nonredundant rotations.\n    moF : numpy.array\n        MO-basis Fock matrix\n    Co : numpy.array\n        Matrix of occupied orbital coefficients.\n    Cv : numpy.array\n        Matrix of virtual orbital coefficients.\n\n    Returns\n    -------\n    F : numpy.array\n        Hessian product tensor\n    """"""\n    Hx_a = np.dot(moFa[:nbeta, :nbeta], xa)\n    Hx_a -= np.dot(xa, moFa[nbeta:, nbeta:])\n\n    Hx_b = np.dot(moFb[:nalpha, :nalpha], xb)\n    Hx_b -= np.dot(xb, moFb[nalpha:, nalpha:])\n\n    # Build two electron part, M = -4 (4 G_{mnip} - g_{mpin} - g_{npim}) K_{ip}\n    # From [Helgaker:2000] Eqn. 10.8.65\n    C_right_a = np.einsum(\'ia,sa->si\', -xa, Cv_a)\n    C_right_b = np.einsum(\'ia,sa->si\', -xb, Cv_b)\n\n    J, K = scf_helper.compute_jk(jk, [Co_a, Co_b], [C_right_a, C_right_b])\n\n    Jab = J[0] + J[1]\n    Hx_a += (Co_a.T).dot(2 * Jab - K[0].T - K[0]).dot(Cv_a)\n    Hx_b += (Co_b.T).dot(2 * Jab - K[1].T - K[1]).dot(Cv_b)\n\n    Hx_a *= -4\n    Hx_b *= -4\n\n    return (Hx_a, Hx_b)\n\nCa, Da = diag_H(H, nbeta)\nCb, Db = diag_H(H, nalpha)\n\nt = time.time()\nE = 0.0\nEnuc = mol.nuclear_repulsion_energy()\nEold = 0.0\n\n# Initialize the JK object\njk = psi4.core.JK.build(wfn.basisset())\njk.initialize()\n\n# Build a DIIS helper object\ndiisa = scf_helper.DIIS_helper()\ndiisb = scf_helper.DIIS_helper()\n\nprint(\'\\nTotal time taken for setup: %.3f seconds\' % (time.time() - t))\n\nprint(\'\\nStart SCF iterations:\\n\')\nt = time.time()\n\nfor SCF_ITER in range(1, maxiter + 1):\n\n    # Build Fock matrices\n    J, K = scf_helper.compute_jk(jk, [Ca[:, :nbeta], Cb[:, :nalpha]])\n    J = J[0] + J[1]\n    Fa = H + J - K[0]\n    Fb = H + J - K[1]\n\n    # DIIS error build and update\n    diisa_e = Fa.dot(Da).dot(S) - S.dot(Da).dot(Fa)\n    diisa_e = (A.T).dot(diisa_e).dot(A)\n    diisa.add(Fa, diisa_e)\n\n    diisb_e = Fb.dot(Db).dot(S) - S.dot(Db).dot(Fb)\n    diisb_e = (A.T).dot(diisb_e).dot(A)\n    diisb.add(Fb, diisb_e)\n\n    # SCF energy and update\n    SCF_E  = np.einsum(\'pq,pq->\', Da + Db, H)\n    SCF_E += np.einsum(\'pq,pq->\', Da, Fa)\n    SCF_E += np.einsum(\'pq,pq->\', Db, Fb)\n    SCF_E *= 0.5\n    SCF_E += Enuc\n\n    dRMS = 0.5 * (np.mean(diisa_e**2)**0.5 + np.mean(diisb_e**2)**0.5)\n    print(\'SCF Iteration %3d: Energy = %4.16f   dE = % 1.5E   dRMS = %1.5E\'\n          % (SCF_ITER, SCF_E, (SCF_E - Eold), dRMS))\n    if (abs(SCF_E - Eold) < E_conv) and (dRMS < D_conv):\n        break\n\n    Eold = SCF_E\n\n    Co_a = Ca[:, :nbeta]\n    Cv_a = Ca[:, nbeta:]\n    moF_a = np.dot(Ca.T, Fa).dot(Ca)\n    gradient_a = -4 * moF_a[:nbeta, nbeta:]\n    gradient_norm_a = np.linalg.norm(gradient_a)\n\n    Co_b = Cb[:, :nalpha]\n    Cv_b = Cb[:, nalpha:]\n    moF_b = np.dot(Cb.T, Fb).dot(Cb)\n    gradient_b = -4 * moF_b[:nalpha, nalpha:]\n    gradient_norm_b = np.linalg.norm(gradient_b)\n\n    gradient_norm = gradient_norm_a + gradient_norm_b\n\n    # Conventional updates\n    if np.any(np.abs(gradient_a) > 0.3) or np.any(np.abs(gradient_b) > 0.3):\n        Fa = diisa.extrapolate()\n        Fb = diisb.extrapolate()\n\n        # Diagonalize Fock matrix\n        Ca, Da = diag_H(Fa, nbeta)\n        Cb, Db = diag_H(Fb, nalpha)\n\n    else:\n        so_diis = scf_helper.DIIS_helper()\n\n        # Initial guess & Jacobi preconditioner for alpha & beta\n        eps_a = np.diag(moF_a)\n        precon_a = -4 * (eps_a[:nbeta].reshape(-1, 1) - eps_a[nbeta:])\n        x_a = gradient_a / precon_a\n\n        eps_b = np.diag(moF_b)\n        precon_b = -4 * (eps_b[:nalpha].reshape(-1, 1) - eps_b[nalpha:])\n        x_b = gradient_b / precon_b\n\n        Hx_a, Hx_b = SCF_Hx(x_a, x_b, moF_a, Co_a, Cv_a, moF_b, Co_b, Cv_b)\n\n        r_a = gradient_a - Hx_a\n        z_a = r_a / precon_a\n        p_a = z_a.copy()\n\n        r_b = gradient_b - Hx_b\n        z_b = r_b / precon_b\n        p_b = z_b.copy()\n\n        # PCG Iterations for alpha & beta\n        for rot_iter in range(max_micro):\n            rz_old = np.vdot(r_a, z_a) + np.vdot(r_b, z_b)\n\n            Hx_a, Hx_b = SCF_Hx(p_a, p_b, moF_a, Co_a, Cv_a, moF_b, Co_b, Cv_b)\n\n            alpha = rz_old / (np.vdot(Hx_a, p_a) + np.vdot(Hx_b, p_b))\n\n            # CG update\n            x_a += alpha * p_a\n            r_a -= alpha * Hx_a\n            z_a = r_a / precon_a\n\n            x_b += alpha * p_b\n            r_b -= alpha * Hx_b\n            z_b = r_b / precon_b\n\n            x_diis = np.hstack((x_a.ravel(), x_b.ravel()))\n            r_diis = np.hstack((r_a.ravel(), r_b.ravel()))\n            so_diis.add(x_diis, r_diis)\n\n            rms_a = (np.linalg.norm(r_a) / gradient_norm_a) ** 0.5\n            rms_b = (np.linalg.norm(r_b) / gradient_norm_b) ** 0.5\n\n            if gradient_norm > 1.e-2:\n                denom = gradient_norm\n            else:\n                denom = 1.e-2\n            rms = ((np.linalg.norm(r_a) + np.linalg.norm(r_b)) / denom) ** 0.5\n\n            if micro_print:\n                print(\'Micro Iteration %2d: Rel. RMS = %1.5e (a: %1.2e, b: %1.2e)\' %  (rot_iter + 1, rms, rms_a, rms_b))\n            if rms < micro_conv:\n                break\n\n            beta = (np.vdot(r_a, z_a) + np.vdot(r_b, z_b)) / rz_old\n\n            p_a = z_a + beta * p_a\n            p_b = z_b + beta * p_b\n\n        x = so_diis.extrapolate()\n        x_a = x[:x_a.size].reshape(x_a.shape)\n        x_b = x[x_a.size:].reshape(x_b.shape)\n\n        # Diagonalize Fock matrix\n        Ca, Da = scf_helper.rotate_orbitals(Ca, x_a, True)\n        Cb, Db = scf_helper.rotate_orbitals(Cb, x_b, True)\n\n    if SCF_ITER == maxiter:\n        psi4.core.clean()\n        raise Exception(""Maximum number of SCF cycles exceeded."")\n\nprint(\'Total time for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\nspin_mat = (Cb[:, :nalpha].T).dot(S).dot(Ca[:, :nbeta])\nspin_contam = min(nbeta, nalpha) - np.vdot(spin_mat, spin_mat)\nprint(\'Spin Contamination Metric: %1.5E\\n\' % spin_contam)\n\nprint(\'Final SCF energy: %.8f hartree\' % SCF_E)\n\n# Compare to Psi4\nSCF_E_psi = psi4.energy(\'SCF\')\npsi4.compare_values(SCF_E_psi, SCF_E, 6, \'SCF Energy\')\n'"
Self-Consistent-Field/UHF_libJK.py,18,"b'""""""\nA unrestricted Hartree-Fock script using DIIS convergence acceleration\nand Psi4\'s libJK\n\nReferences:\n- UHF equations & algorithms from [Szabo:1996]\n- DIIS equations & algorithms from [Sherrill:1998], [Pulay:1980:393], & [Pulay:1969:197]\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nfrom helper_HF import *\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Memory for numpy in GB\nnumpy_memory = 2\n\n# Triplet O2\nmol = psi4.geometry(""""""\n    0 3\n    O\n    O 1 1.2\nsymmetry c1\n"""""")\n\npsi4.set_options({\'guess\':      \'core\',\n                  \'basis\':      \'aug-cc-pvdz\',\n                  \'scf_type\':   \'df\',\n                  \'e_convergence\': 1e-8,\n                  \'reference\':  \'uhf\'})\n\n\n# Set defaults\nmaxiter = 40\nE_conv = 1.0E-8\nD_conv = 1.0E-5\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nwfn = psi4.core.Wavefunction.build(mol, psi4.core.get_global_option(\'BASIS\'))\nmints = psi4.core.MintsHelper(wfn.basisset())\nS = np.asarray(mints.ao_overlap())\n\n# Get nbf and ndocc for closed shell molecules\nnbf = wfn.nso()\nnalpha = wfn.nalpha()\nnbeta = wfn.nbeta()\n\nprint(\'\\nNumber of doubly occupied orbitals: %d\' % nbeta)\nprint(\'Number of singly occupied orbitals: %d\' % (nalpha - nbeta))\nprint(\'Number of basis functions: %d\' % nbf)\n\nV = np.asarray(mints.ao_potential())\nT = np.asarray(mints.ao_kinetic())\n\nprint(\'\\nTotal time taken for integrals: %.3f seconds.\' % (time.time()-t))\n\nt = time.time()\n\n# Build H_core\nH = T + V\n\n# Orthogonalizer A = S^(-1/2)\nA = mints.ao_overlap()\nA.power(-0.5, 1.e-16)\nA = np.asarray(A)\n\ndef diag_H(H, nocc):\n    """"""Diagonalizes provided Fock matrix for orbital coefficients C and density\n    matrix D, using equations from [Szabo:1996] pp. 139 & 145.\n\n    Parameters\n    ----------\n    H : numpy.array\n        Fock matrix to diagonalize. \n    nocc : int\n        Number of occupied molecular orbitals.\n\n    Returns\n    -------\n    C : numpy.array \n        Molecular orbital coefficient matrix\n    D : numpy.array\n        SCF density matrix\n    """"""\n    Hp = A.dot(H).dot(A)        # Eqn. 3.177\n    e, C2 = np.linalg.eigh(Hp)  # Solving Eqn. 1.178\n    C = A.dot(C2)               # Back transformation, Eqn. 3.174\n    Cocc = C[:, :nocc]\n    D = np.einsum(\'pi,qi->pq\', Cocc, Cocc) # Eqn. 3.145\n    return (C, D)\n    \nCa, Da = diag_H(H, nalpha)    \nCb, Db = diag_H(H, nbeta)    \n\nt = time.time()\nE = 0.0\nEnuc = mol.nuclear_repulsion_energy()\nEold = 0.0\n\nFock_list = []\nDIIS_error = []\n\n# Build a C matrix and share data with the numpy array npC\nCocca = psi4.core.Matrix(nbf, nalpha)\nnpCa = np.asarray(Cocca)\nnpCa[:] = Ca[:, :nalpha]\n\nCoccb = psi4.core.Matrix(nbf, nbeta)\nnpCb = np.asarray(Coccb)\nnpCb[:] = Cb[:, :nbeta]\n\n# Initialize the JK object\njk = psi4.core.JK.build(wfn.basisset())\njk.initialize()\njk.C_left_add(Cocca)\njk.C_left_add(Coccb)\n\n# Build a DIIS helper object\ndiisa = DIIS_helper()\ndiisb = DIIS_helper()\n\nprint(\'\\nTotal time taken for setup: %.3f seconds\' % (time.time() - t))\n\nprint(\'\\nStart SCF iterations:\\n\')\nt = time.time()\n\nfor SCF_ITER in range(1, maxiter + 1):\n\n    npCa[:] = Ca[:, :nalpha]\n    npCb[:] = Cb[:, :nbeta]\n    jk.compute()\n\n    # Build alpha & beta Fock matrices using Psi4\'s libJK\n    Ja = np.asarray(jk.J()[0])\n    Jb = np.asarray(jk.J()[1])\n    Ka = np.asarray(jk.K()[0])\n    Kb = np.asarray(jk.K()[1])\n    Fa = H + (Ja + Jb) - Ka\n    Fb = H + (Ja + Jb) - Kb\n\n    # DIIS error build and update\n    diisa_e = Fa.dot(Da).dot(S) - S.dot(Da).dot(Fa)\n    diisa_e = (A.T).dot(diisa_e).dot(A)\n    diisa.add(Fa, diisa_e)\n\n    diisb_e = Fb.dot(Db).dot(S) - S.dot(Db).dot(Fb)\n    diisb_e = (A.T).dot(diisb_e).dot(A)\n    diisb.add(Fb, diisb_e)\n\n    # SCF energy and update: [Szabo:1996], exercise 3.40, pp. 215\n    SCF_E  = np.einsum(\'pq,pq->\', Da + Db, H)\n    SCF_E += np.einsum(\'pq,pq->\', Da, Fa)\n    SCF_E += np.einsum(\'pq,pq->\', Db, Fb)\n    SCF_E *= 0.5\n    SCF_E += Enuc \n\n    dRMS = 0.5 * (np.mean(diisa_e**2)**0.5 + np.mean(diisb_e**2)**0.5)\n    print(\'SCF Iteration %3d: Energy = %4.16f   dE = % 1.5E   dRMS = %1.5E\'\n          % (SCF_ITER, SCF_E, (SCF_E - Eold), dRMS))\n    if (abs(SCF_E - Eold) < E_conv) and (dRMS < D_conv):\n        break\n\n    Eold = SCF_E\n\n    # Extrapolate alpha & beta Fock matrices separately\n    Fa = diisa.extrapolate()\n    Fb = diisb.extrapolate()\n\n    # Diagonalize Fock matrix\n    Ca, Da = diag_H(Fa, nalpha)    \n    Cb, Db = diag_H(Fb, nbeta)    \n\n    if SCF_ITER == maxiter:\n        clean()\n        raise Exception(""Maximum number of SCF cycles exceeded."")\n\nprint(\'Total time for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\nspin_mat = (Cb[:, :nbeta].T).dot(S).dot(Ca[:, :nalpha])\nspin_contam = min(nalpha, nbeta) - np.vdot(spin_mat, spin_mat)\nprint(\'Spin Contamination Metric: %1.5E\\n\' % spin_contam)\n\nprint(\'Final SCF energy: %.8f hartree\' % SCF_E)\n\n# Compare to Psi4\nSCF_E_psi = psi4.energy(\'SCF\')\npsi4.compare_values(SCF_E_psi, SCF_E, 6, \'SCF Energy\')\n'"
Self-Consistent-Field/helper_HF.py,37,"b'""""""\nHelper classes and functions for the SCF folder.\n\nReferences:\n- RHF/UHF equations & algorithms from [Szabo:1996]\n- DIIS equations & algorithm from [Sherrill:1998], [Pulay:1980:393], & [Pulay:1969:197]\n- Orbital rotaion expressions from [Helgaker:2000]\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-9-30""\n\nimport time\nimport numpy as np\nimport psi4\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\n\n\nclass helper_HF(object):\n    """"""\n    A generalized Hartree-Fock helper script.\n\n    Notes\n    -----\n    Equations and algorithms from [Szabo:1996]\n    """"""\n\n    def __init__(self, mol, basis=None, memory=2, ndocc=None, scf_type=\'DF\', guess=\'CORE\'):\n        """"""\n        Initializes the helper_HF object.\n\n        Parameters\n        ----------\n        mol : psi4.core.Molecule or str\n            The molecule to be used for the given helper object.\n        basis : {str, None}, optional\n            The basis string to be used\n        memory : {int, 2}, optional\n            The amount of memory (in GB) to use.\n        ndocc : {int, None}, optional\n            The number of occupied orbitals for the HF helper. Defaults to the number of electrons divided by 2.\n        scf_type : {""DF"", ""PK"", ""OUT_OF_CORE""}, optional\n            The type of JK object to use.\n        guess : {""CORE"", ""SAD""}, optional\n            The initial guess type to attempt.\n\n        Returns\n        ------\n        ret : helper_HF\n            A initialized helper_HF object\n\n        Examples\n        --------\n\n        # Construct the helper object\n        >>> helper = helper_HF(""He\\nHe 1 2.0"", ""cc-pVDZ"")\n\n        # Take a Roothan-Hall step\n        >>> F = helper.build_fock()\n        >>> helper.compute_hf_energy()\n        -5.4764571474633197\n\n\n        # Take a Roothan-Hall step\n        >>> e, C = helper.diag(F)\n        >>> helper.set_Cleft(C)\n        >>> F = helper.build_fock()\n        >>> helper.compute_hf_energy()\n        -5.706674424039214\n\n        """"""\n\n        # Build and store all 2D values\n        print(\'Building rank 2 integrals...\')\n        t = time.time()\n\n        if not isinstance(mol, psi4.core.Molecule):\n            mol = psi4.geometry(mol)\n\n        if basis is None:\n            basis = psi4.core.get_global_option(\'BASIS\')\n        else:\n            psi4.core.set_global_option(""BASIS"", basis)\n\n        wfn = psi4.core.Wavefunction.build(mol, basis)\n        self.wfn = wfn\n        self.mints = psi4.core.MintsHelper(wfn.basisset())\n        self.enuc = mol.nuclear_repulsion_energy()\n\n        # Build out necessary 2D matrices\n        self.S = np.asarray(self.mints.ao_overlap())\n        self.V = np.asarray(self.mints.ao_potential())\n        self.T = np.asarray(self.mints.ao_kinetic())\n        self.H = self.T + self.V\n\n        # Holder objects\n        self.Da = None\n        self.Db = None\n        self.Ca = None\n        self.Cb = None\n\n        self.J = None\n        self.K = None\n\n        # Build symmetric orthoganlizer\n        A = self.mints.ao_overlap()\n        A.power(-0.5, 1.e-14)\n        self.A = np.asarray(A)\n\n        # Get nbf and ndocc for closed shell molecules\n        self.epsilon = None\n        self.nbf = self.S.shape[0]\n        if ndocc:\n            self.ndocc = ndocc\n        else:\n            self.ndocc = int(sum(mol.Z(A) for A in range(mol.natom())) / 2)\n\n        # Only rhf for now\n        self.nvirt = self.nbf - self.ndocc\n\n        print(\'\\nNumber of occupied orbitals: %d\' % self.ndocc)\n        print(\'Number of basis functions: %d\' % self.nbf)\n\n        self.C_left = psi4.core.Matrix(self.nbf, self.ndocc)\n        self.npC_left = np.asarray(self.C_left)\n\n        if guess.upper() == \'CORE\':\n            Xp = self.A.dot(self.H).dot(self.A)\n            e, C2 = np.linalg.eigh(Xp)\n\n            self.Ca = self.A.dot(C2)\n            self.npC_left[:] = self.Ca[:, :self.ndocc]\n            self.epsilon = e\n            self.Da = np.dot(self.npC_left, self.npC_left.T)\n            self.F = self.H\n\n        elif guess.upper() == \'SAD\':\n\n            # Cheat and run a quick SCF calculation\n            psi4.set_options({\'E_CONVERGENCE\': 1, \'D_CONVERGENCE\': 1})\n\n            e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n            self.Ca = np.array(wfn.Ca())\n            self.npC_left[:] = self.Ca[:, :self.ndocc]\n            self.epsilon = np.array(wfn.epsilon_a())\n            self.Da = np.dot(self.npC_left, self.npC_left.T)\n\n            psi4.set_options({\'E_CONVERGENCE\': 6, \'D_CONVERGENCE\': 6})\n\n        else:\n            raise Exception(""Guess %s not yet supported"" % (guess))\n\n        self.DIIS_error = []\n        self.DIIS_F = []\n\n        scf_type = scf_type.upper()\n        if scf_type not in [\'DF\', \'PK\', \'DIRECT\', \'OUT_OF_CORE\']:\n            raise Exception(\'SCF_TYPE %s not supported\' % scf_type)\n        psi4.set_options({\'SCF_TYPE\': scf_type})\n        self.jk = psi4.core.JK.build(wfn.basisset())\n        self.jk.initialize()\n        #        self.jk.C_left().append(self.C_left)\n\n        print(\'...rank 2 integrals built in %.3f seconds.\' % (time.time() - t))\n\n    def set_Cleft(self, C):\n        """"""\n        Sets the current orbital matrix and builds the density from it.\n        """"""\n\n        if (C.shape[1] == self.ndocc):\n            Cocc = C\n        elif (C.shape[1] == self.nbf):\n            self.Ca = C\n            Cocc = C[:, :self.ndocc]\n        else:\n            raise Exception(""Cocc shape is %s, need %s."" % (str(self.npC_left.shape), str(Cocc.shape)))\n        self.npC_left[:] = Cocc\n        self.Da = np.dot(Cocc, Cocc.T)\n\n    def diag(self, F, set_C=False):\n        """"""\n        Diagonalizes the matrix F using the symmetric orthogonalization matrix S^{-1/2}.\n\n        Parameters\n        ----------\n        F : numpy.array\n            Fock matrix to diagonalize according to [Szabo:1996] pp. 145\n        set_C : {True, False}, optional\n            Set the computed C matrix as the Cleft attribute?\n\n        Returns\n        -------\n        e : numpy.array\n            Array of orbital energies (eigenvalues of Fock matrix)\n        C : numpy.array\n            Orbital coefficient matrix\n        """"""\n        Xp = self.A.dot(F).dot(self.A)\n        e, C2 = np.linalg.eigh(Xp)\n        C = self.A.dot(C2)\n        if set_C:\n            self.set_Cleft(C)\n        return e, C\n\n    def build_fock(self):\n        """"""\n        Builds the Fock matrix from the current orbitals\n\n        D = Cocc Cocc.T\n        F = H + 2 * J[D] - K[D]\n        """"""\n\n        self.jk.C_left_add(self.C_left)\n        self.jk.compute()\n        self.jk.C_clear()\n        self.J = np.asarray(self.jk.J()[0])\n        self.K = np.asarray(self.jk.K()[0])\n        self.F = self.H + self.J * 2 - self.K\n        return self.F\n\n    def build_jk(self, C_left, C_right=None):\n        """"""\n        A wrapper to compute the J and K objects.\n        """"""\n        return compute_jk(self.jk, C_left, C_right)\n\n    def compute_hf_energy(self):\n        """"""\n        Computes the current SCF energy (F + H)_pq D_pq + E_nuclear\n        """"""\n        self.scf_e = np.einsum(\'ij,ij->\', self.F + self.H, self.Da) + self.enuc\n        return self.scf_e\n\n\nclass DIIS_helper(object):\n    """"""\n    A helper class to compute DIIS extrapolations.\n\n    Notes\n    -----\n    Equations taken from [Sherrill:1998], [Pulay:1980:393], & [Pulay:1969:197]\n    Algorithms adapted from [Sherrill:1998] & [Pulay:1980:393]\n    """"""\n\n    def __init__(self, max_vec=6):\n        """"""\n        Intializes the DIIS class.\n\n        Parameters\n        ----------\n        max_vec : int (default, 6)\n            The maximum number of vectors to use. The oldest vector will be deleted.\n        """"""\n        self.error = []\n        self.vector = []\n        self.max_vec = max_vec\n\n    def add(self, state, error):\n        """"""\n        Adds a set of error and state vectors to the DIIS object.\n\n        Parameters\n        ----------\n        state : array_like\n            The state vector to add to the DIIS object.\n        error : array_like\n            The error vector to add to the DIIS object.\n\n        Returns\n        ------\n        None\n        """"""\n\n        error = np.array(error)\n        state = np.array(state)\n        if len(self.error) > 1:\n            if self.error[-1].shape[0] != error.size:\n                raise Exception(""Error vector size does not match previous vector."")\n            if self.vector[-1].shape != state.shape:\n                raise Exception(""Vector shape does not match previous vector."")\n\n        self.error.append(error.ravel().copy())\n        self.vector.append(state.copy())\n\n    def extrapolate(self):\n        """"""\n        Performs the DIIS extrapolation for the objects state and error vectors.\n\n        Parameters\n        ----------\n        None\n\n        Returns\n        ------\n        ret : ndarray\n            The extrapolated next state vector\n\n        """"""\n\n        # Limit size of DIIS vector\n        diis_count = len(self.vector)\n\n        if diis_count == 0:\n            raise Exception(""DIIS: No previous vectors."")\n        if diis_count == 1:\n            return self.vector[0]\n\n        if diis_count > self.max_vec:\n            # Remove oldest vector\n            del self.vector[0]\n            del self.error[0]\n            diis_count -= 1\n\n        # Build error matrix B\n        B = np.empty((diis_count + 1, diis_count + 1))\n        B[-1, :] = -1\n        B[:, -1] = -1\n        B[-1, -1] = 0\n        for num1, e1 in enumerate(self.error):\n            B[num1, num1] = np.vdot(e1, e1)\n            for num2, e2 in enumerate(self.error):\n                if num2 >= num1: continue\n                val = np.vdot(e1, e2)\n                B[num1, num2] = B[num2, num1] = val\n\n        # normalize\n        B[abs(B) < 1.e-14] = 1.e-14\n        B[:-1, :-1] /= np.abs(B[:-1, :-1]).max()\n\n        # Build residual vector\n        resid = np.zeros(diis_count + 1)\n        resid[-1] = -1\n\n        # Solve pulay equations\n        ci = np.dot(np.linalg.pinv(B), resid)\n\n        # combination of previous fock matrices\n        V = np.zeros_like(self.vector[-1])\n        for num, c in enumerate(ci[:-1]):\n            V += c * self.vector[num]\n\n        return V\n\n\ndef compute_jk(jk, C_left, C_right=None):\n    """"""\n    A python wrapper for a Psi4 JK object to consume and produce NumPy arrays.\n\n    Computes the following matrices:\n    D = C_left C_right.T\n    J_pq = (pq|rs) D_rs\n    K_pq = (pr|qs) D_rs\n\n    Parameters\n    ----------\n    jk : psi4.core.JK\n        A initialized Psi4 JK object\n    C_left : list of array_like or a array_like object\n        Orbitals used to compute the JK object with\n    C_right : list of array_like (optional, None)\n        Optional C_right orbitals, otherwise it is assumed C_right == C_left\n\n    Returns\n    -------\n    JK : tuple of ndarray\n        Returns the J and K objects\n\n    Notes\n    -----\n    This function uses the Psi4 JK object and will compute the initialized JK type (DF, PK, OUT_OF_CORE, etc)\n\n\n    Examples\n    --------\n\n    ndocc = 5\n    nbf = 15\n\n    Cocc = np.random.rand(nbf, ndocc)\n\n    jk = psi4.core.JK.build(wfn.basisset())\n    jk.set_memory(int(1.25e8))  # 1GB\n    jk.initialize()\n    jk.print_header()\n\n\n    J, K = compute_jk(jk, Cocc)\n\n    J_list, K_list = compute_jk(jk, [Cocc, Cocc])\n    """"""\n\n    # Clear out the matrices\n    jk.C_clear()\n\n    list_input = True\n    if not isinstance(C_left, (list, tuple)):\n        C_left = [C_left]\n        list_input = False\n\n    for c in C_left:\n        mat = psi4.core.Matrix.from_array(c)\n        jk.C_left_add(mat)\n\n    # Do we have C_right?\n    if C_right is not None:\n        if not isinstance(C_right, (list, tuple)):\n            C_right = [C_right]\n\n        if len(C_left) != len(C_right):\n            raise ValueError(""JK: length of left and right matrices is not equal"")\n\n        if not isinstance(C_right, (list, tuple)):\n            C_right = [C_right]\n\n        for c in C_right:\n            mat = psi4.core.Matrix.from_array(c)\n            jk.C_right_add(mat)\n\n    # Compute the JK\n    jk.compute()\n\n    # Unpack\n    J = []\n    K = []\n    for n in range(len(C_left)):\n        J.append(np.array(jk.J()[n]))\n        K.append(np.array(jk.K()[n]))\n\n    jk.C_clear()\n\n    # Duck type the return\n    if list_input:\n        return (J, K)\n    else:\n        return (J[0], K[0])\n\n\ndef rotate_orbitals(C, x, return_d=False):\n    """"""\n    Rotates the orbitals C using the rotation matrix x.\n\n    Using the antisymmetric skew Matrix: U = [x,  0]\n                                             [0, -x]\n\n    C\' = C e^{U}\n\n    Parameters\n    ----------\n    C : array_like\n        The orbital matrix to rotate\n    x : array_like\n        The occupied by virtual orbital rotation matrix\n    return_d : bool (optional, False)\n        Returns the occupied Density matrix of the rotated orbitals if requested\n\n    Returns\n    -------\n    C\' : ndarray\n        The rotated orbital matrix\n\n    Notes\n    -----\n    This function uses a truncated Taylor expansion to approximate the exponential:\n        e^{U} \\approx 1 + U + 0.5 * U U\n\n    Equations from [Helgaker:2000]\n\n    Examples\n    --------\n\n    ndocc = 5\n    nvir = 10\n    nbf = ndocc + nvir\n\n    C = np.random.rand(nbf, nbf)\n    x = np.random.rand(ndocc, nvir)\n\n    Cp = rotate_orbitals(C, x)\n    """"""\n\n    # NumPy Array conversion\n    C = np.asarray(C)\n    x = np.asarray(x)\n\n    rsize = x.shape[0] + x.shape[1]\n    if (rsize) != C.shape[1]:\n        raise ValueError(""rotate_orbitals: shape mismatch"")\n\n    # Build U\n    U = np.zeros((rsize, rsize))\n    ndocc = x.shape[0]\n    U[:ndocc, ndocc:] = x\n    U[ndocc:, :ndocc] = -x.T\n\n    U += 0.5 * np.dot(U, U)\n    U[np.diag_indices_from(U)] += 1\n\n    # Easy access to Schmidt orthogonalization\n    U, r = np.linalg.qr(U.T)\n\n    # Rotate and set orbitals\n    C = C.dot(U)\n    if return_d:\n        Cocc = C[:, :ndocc]\n        return C, np.dot(Cocc, Cocc.T)\n    else:\n        return C\n\n\ndef transform_aotoso(m_ao, transformers):\n    """"""\n    Transform an operator from the atomic orbital to spin orbital basis.\n\n    Parameters\n    ----------\n    m_ao : numpy.ndarray\n        A [nao, nao] matrix\n    transformers : list or tuple of numpy.ndarray\n        Transformation matrices, one for each irrep, with shape [nao, nso in irrep]\n\n    Returns\n    -------\n    tuple of numpy.ndarray\n        One matrix for each irrep with shape [nso in irrep, nso in irrep]\n    """"""\n    return tuple(transformer.T.dot(m_ao).dot(transformer)\n                 for transformer in transformers)\n\n\ndef transform_sotoao(m_so_, transformers):\n    """"""\n    Transform an operator from the spin orbital to the atomic orbital basis.\n\n    Parameters\n    ----------\n    m_so_ : list or tuple of numpy.ndarray\n        Matrices, one for each irrep, with shape [nso in irrep, nso in irrep]\n    transformers : list or tuple of numpy.ndarray\n        Transformation matrices, one for each irrep, with shape [nao, nso in irrep]\n\n    Returns\n    -------\n    numpy.ndarray\n        A [nao, nao] matrix\n    """"""\n    assert len(m_so_) == len(transformers)\n    return sum(transformer.dot(m_so).dot(transformer.T)\n               for transformer, m_so in zip(transformers, m_so_))\n'"
Symmetry-Adapted-Perturbation-Theory/SAPT0.py,55,"b'""""""\nA simple Psi4 script to compute SAPT0 interaction energies.\n\nReferences:\n- Equations and algorithms from [Szalewicz:2005:43], [Jeziorski:1994:1887],\n[Szalewicz:2012:254], and [Hohenstein:2012:304]\n""""""\n\n__authors__   =  ""Daniel G. A. Smith""\n__credits__   =  [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2014-12-01""\n\nimport time\nimport numpy as np\nfrom helper_SAPT import *\nnp.set_printoptions(precision=5, linewidth=200, threshold=2000, suppress=True)\nimport psi4\n\n# Set Psi4 & NumPy Memory Options\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\nnumpy_memory = 2\n\n# Set molecule to dimer\ndimer = psi4.geometry(""""""\nO   -0.066999140   0.000000000   1.494354740\nH    0.815734270   0.000000000   1.865866390\nH    0.068855100   0.000000000   0.539142770\n--\nO    0.062547750   0.000000000  -1.422632080\nH   -0.406965400  -0.760178410  -1.771744500\nH   -0.406965400   0.760178410  -1.771744500\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'jun-cc-pVDZ\',\n                  \'e_convergence\': 1e-8,\n                  \'d_convergence\': 1e-8})\n\nsapt = helper_SAPT(dimer, memory=8)\n\n### Start E100 Electostatics\nelst_timer = sapt_timer(\'electrostatics\')\nElst10 = 4 * np.einsum(\'abab\', sapt.vt(\'abab\'))\nelst_timer.stop()\n### End E100 Electrostatics\n\n### Start E100 Exchange\nexch_timer = sapt_timer(\'exchange\')\nvt_abba = sapt.vt(\'abba\')\nvt_abaa = sapt.vt(\'abaa\')\nvt_abbb = sapt.vt(\'abbb\')\nvt_abab = sapt.vt(\'abab\')\ns_ab = sapt.s(\'ab\')\n\nExch100 = np.einsum(\'abba\', vt_abba)\n\ntmp = 2 * vt_abaa - vt_abaa.swapaxes(2, 3)\nExch100 += np.einsum(\'Ab,abaA\', s_ab, tmp)\n\ntmp = 2 * vt_abbb - vt_abbb.swapaxes(2, 3)\nExch100 += np.einsum(\'Ba,abBb\', s_ab.T, tmp)\n\nExch100 -= 2 * np.einsum(\'Ab,BA,abaB\', s_ab, s_ab.T, vt_abab)\nExch100 -= 2 * np.einsum(\'AB,Ba,abAb\', s_ab, s_ab.T, vt_abab)\nExch100 += np.einsum(\'Ab,Ba,abAB\', s_ab, s_ab.T, vt_abab)\n\nExch100 *= -2\nexch_timer.stop()\n### End E100 (S^2) Exchange\n\n### Start E200 Disp\ndisp_timer = sapt_timer(\'dispersion\')\nv_abrs = sapt.v(\'abrs\')\nv_rsab = sapt.v(\'rsab\')\ne_rsab = 1/(-sapt.eps(\'r\', dim=4) - sapt.eps(\'s\', dim=3) + sapt.eps(\'a\', dim=2) + sapt.eps(\'b\'))\n\nDisp200 = 4 * np.einsum(\'rsab,rsab,abrs->\', e_rsab, v_rsab, v_abrs)\n### End E200 Disp\n\n### Start E200 Exchange-Dispersion\n\n# Build t_rsab\nt_rsab = np.einsum(\'rsab,rsab->rsab\', v_rsab, e_rsab)\n\n# Build h_abrs\nvt_abar = sapt.vt(\'abar\')\nvt_abra = sapt.vt(\'abra\')\nvt_absb = sapt.vt(\'absb\')\nvt_abbs = sapt.vt(\'abbs\')\n\ntmp = 2 * vt_abar - vt_abra.swapaxes(2, 3)\nh_abrs = np.einsum(\'as,AbAr->abrs\', sapt.s(\'as\'), tmp)\n\ntmp = 2 * vt_abra - vt_abar.swapaxes(2, 3)\nh_abrs += np.einsum(\'As,abrA->abrs\', sapt.s(\'as\'), tmp)\n\ntmp = 2 * vt_absb - vt_abbs.swapaxes(2, 3)\nh_abrs += np.einsum(\'br,aBsB->abrs\', sapt.s(\'br\'), tmp)\n\ntmp = 2 * vt_abbs - vt_absb.swapaxes(2, 3)\nh_abrs += np.einsum(\'Br,abBs->abrs\', sapt.s(\'br\'), tmp)\n\n# Build q_abrs\nvt_abas = sapt.vt(\'abas\')\nq_abrs =      np.einsum(\'br,AB,aBAs->abrs\', sapt.s(\'br\'), sapt.s(\'ab\'), vt_abas)\nq_abrs -= 2 * np.einsum(\'Br,AB,abAs->abrs\', sapt.s(\'br\'), sapt.s(\'ab\'), vt_abas)\nq_abrs -= 2 * np.einsum(\'br,aB,ABAs->abrs\', sapt.s(\'br\'), sapt.s(\'ab\'), vt_abas)\nq_abrs += 4 * np.einsum(\'Br,aB,AbAs->abrs\', sapt.s(\'br\'), sapt.s(\'ab\'), vt_abas)\n\nvt_abrb = sapt.vt(\'abrb\')\nq_abrs -= 2 * np.einsum(\'as,bA,ABrB->abrs\', sapt.s(\'as\'), sapt.s(\'ba\'), vt_abrb)\nq_abrs += 4 * np.einsum(\'As,bA,aBrB->abrs\', sapt.s(\'as\'), sapt.s(\'ba\'), vt_abrb)\nq_abrs +=     np.einsum(\'as,BA,AbrB->abrs\', sapt.s(\'as\'), sapt.s(\'ba\'), vt_abrb)\nq_abrs -= 2 * np.einsum(\'As,BA,abrB->abrs\', sapt.s(\'as\'), sapt.s(\'ba\'), vt_abrb)\n\nvt_abab = sapt.vt(\'abab\')\nq_abrs +=     np.einsum(\'Br,As,abAB->abrs\', sapt.s(\'br\'), sapt.s(\'as\'), vt_abab)\nq_abrs -= 2 * np.einsum(\'br,As,aBAB->abrs\', sapt.s(\'br\'), sapt.s(\'as\'), vt_abab)\nq_abrs -= 2 * np.einsum(\'Br,as,AbAB->abrs\', sapt.s(\'br\'), sapt.s(\'as\'), vt_abab)\n\nvt_abrs = sapt.vt(\'abrs\')\nq_abrs +=     np.einsum(\'bA,aB,ABrs->abrs\', sapt.s(\'ba\'), sapt.s(\'ab\'), vt_abrs)\nq_abrs -= 2 * np.einsum(\'bA,AB,aBrs->abrs\', sapt.s(\'ba\'), sapt.s(\'ab\'), vt_abrs)\nq_abrs -= 2 * np.einsum(\'BA,aB,Abrs->abrs\', sapt.s(\'ba\'), sapt.s(\'ab\'), vt_abrs)\n\n# Sum it all together\nxd_absr = sapt.vt(\'absr\')\nxd_absr += h_abrs.swapaxes(2, 3)\nxd_absr += q_abrs.swapaxes(2, 3)\nExchDisp20 = -2 * np.einsum(\'absr,rsab->\', xd_absr, t_rsab)\n\ndisp_timer.stop()\n### End E200 Exchange-Dispersion\n\n\n### Start E200 Induction and Exchange-Induction\n\n# E200Induction and CPHF orbitals\nind_timer = sapt_timer(\'induction\')\n\nCPHF_ra, Ind20_ba = sapt.chf(\'B\', ind=True)\nsapt_printer(\'Ind20,r (A<-B)\', Ind20_ba)\n\nCPHF_sb, Ind20_ab = sapt.chf(\'A\', ind=True)\nsapt_printer(\'Ind20,r (A->B)\', Ind20_ab)\n\nInd20r = Ind20_ba + Ind20_ab\n\n# Exchange-Induction\n\n# A <- B\nvt_abra = sapt.vt(\'abra\')\nvt_abar = sapt.vt(\'abar\')\nExchInd20_ab  =     np.einsum(\'ra,abbr\', CPHF_ra, sapt.vt(\'abbr\'))\nExchInd20_ab += 2 * np.einsum(\'rA,Ab,abar\', CPHF_ra, sapt.s(\'ab\'), vt_abar)\nExchInd20_ab += 2 * np.einsum(\'ra,Ab,abrA\', CPHF_ra, sapt.s(\'ab\'), vt_abra)\nExchInd20_ab -=     np.einsum(\'rA,Ab,abra\', CPHF_ra, sapt.s(\'ab\'), vt_abra)\n\nvt_abbb = sapt.vt(\'abbb\')\nvt_abab = sapt.vt(\'abab\')\nExchInd20_ab -=     np.einsum(\'ra,Ab,abAr\', CPHF_ra, sapt.s(\'ab\'), vt_abar)\nExchInd20_ab += 2 * np.einsum(\'ra,Br,abBb\', CPHF_ra, sapt.s(\'br\'), vt_abbb)\nExchInd20_ab -=     np.einsum(\'ra,Br,abbB\', CPHF_ra, sapt.s(\'br\'), vt_abbb)\nExchInd20_ab -= 2 * np.einsum(\'rA,Ab,Br,abaB\', CPHF_ra, sapt.s(\'ab\'), sapt.s(\'br\'), vt_abab)\n\nvt_abrb = sapt.vt(\'abrb\')\nExchInd20_ab -= 2 * np.einsum(\'ra,Ab,BA,abrB\', CPHF_ra, sapt.s(\'ab\'), sapt.s(\'ba\'), vt_abrb)\nExchInd20_ab -= 2 * np.einsum(\'ra,AB,Br,abAb\', CPHF_ra, sapt.s(\'ab\'), sapt.s(\'br\'), vt_abab)\nExchInd20_ab -= 2 * np.einsum(\'rA,AB,Ba,abrb\', CPHF_ra, sapt.s(\'ab\'), sapt.s(\'ba\'), vt_abrb)\n\nExchInd20_ab +=     np.einsum(\'ra,Ab,Br,abAB\', CPHF_ra, sapt.s(\'ab\'), sapt.s(\'br\'), vt_abab)\nExchInd20_ab +=     np.einsum(\'rA,Ab,Ba,abrB\', CPHF_ra, sapt.s(\'ab\'), sapt.s(\'ba\'), vt_abrb)\n\nExchInd20_ab *= -2\nsapt_printer(\'Exch-Ind20,r (A<-B)\', ExchInd20_ab)\n\n# B <- A\nvt_abbs = sapt.vt(\'abbs\')\nvt_absb = sapt.vt(\'absb\')\nExchInd20_ba  =     np.einsum(\'sb,absa\', CPHF_sb, sapt.vt(\'absa\'))\nExchInd20_ba += 2 * np.einsum(\'sB,Ba,absb\', CPHF_sb, sapt.s(\'ba\'), vt_absb)\nExchInd20_ba += 2 * np.einsum(\'sb,Ba,abBs\', CPHF_sb, sapt.s(\'ba\'), vt_abbs)\nExchInd20_ba -=     np.einsum(\'sB,Ba,abbs\', CPHF_sb, sapt.s(\'ba\'), vt_abbs)\n\nvt_abaa = sapt.vt(\'abaa\')\nvt_abab = sapt.vt(\'abab\')\nExchInd20_ba -=     np.einsum(\'sb,Ba,absB\', CPHF_sb, sapt.s(\'ba\'), vt_absb)\nExchInd20_ba += 2 * np.einsum(\'sb,As,abaA\', CPHF_sb, sapt.s(\'as\'), vt_abaa)\nExchInd20_ba -=     np.einsum(\'sb,As,abAa\', CPHF_sb, sapt.s(\'as\'), vt_abaa)\nExchInd20_ba -= 2 * np.einsum(\'sB,Ba,As,abAb\', CPHF_sb, sapt.s(\'ba\'), sapt.s(\'as\'), vt_abab)\n\nvt_abas = sapt.vt(\'abas\')\nExchInd20_ba -= 2 * np.einsum(\'sb,Ba,AB,abAs\', CPHF_sb, sapt.s(\'ba\'), sapt.s(\'ab\'), vt_abas)\nExchInd20_ba -= 2 * np.einsum(\'sb,BA,As,abaB\', CPHF_sb, sapt.s(\'ba\'), sapt.s(\'as\'), vt_abab)\nExchInd20_ba -= 2 * np.einsum(\'sB,BA,Ab,abas\', CPHF_sb, sapt.s(\'ba\'), sapt.s(\'ab\'), vt_abas)\n\nExchInd20_ba +=     np.einsum(\'sb,Ba,As,abAB\', CPHF_sb, sapt.s(\'ba\'), sapt.s(\'as\'), vt_abab)\nExchInd20_ba +=     np.einsum(\'sB,Ba,Ab,abAs\', CPHF_sb, sapt.s(\'ba\'), sapt.s(\'ab\'), vt_abas)\n\nExchInd20_ba *= -2\nsapt_printer(\'Exch-Ind20,r (A->B)\', ExchInd20_ba)\nExchInd20r = ExchInd20_ba + ExchInd20_ab\n\nind_timer.stop()\n### End E200 Induction and Exchange-Induction\n\nprint(\'\\nSAPT0 Results\')\nprint(\'-\' * 70)\nsapt_printer(\'Exch10 (S^2)\', Exch100)\nsapt_printer(\'Elst10\', Elst10)\nsapt_printer(\'Disp20\', Disp200)\nsapt_printer(\'Exch-Disp20\', ExchDisp20)\nsapt_printer(\'Ind20,r\', Ind20r)\nsapt_printer(\'Exch-Ind20,r\', ExchInd20r)\n\nprint(\'-\' * 70)\nsapt0 = Exch100 + Elst10 + Disp200 + ExchDisp20 + Ind20r + ExchInd20r\nsapt_printer(\'Total SAPT0\', sapt0)\n'"
Symmetry-Adapted-Perturbation-Theory/SAPT0_ROHF.py,896,"b'""""""\nSAPT0(ROHF) script for the oxygen dimer (two triplets making a quintet).\n\nNote: The code is transparent but not optimized in any way, and this test\nmight take up to a couple minutes.\n\nReferences:\n- Equations from [Patkowski:2018:164110]\n""""""\n\n__authors__   =  ""Daniel G. A. Smith""\n__credits__   =  [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2014-12-01""\n\nimport time\nimport numpy as np\nfrom helper_SAPT import *\nnp.set_printoptions(precision=5, linewidth=200, threshold=2000, suppress=True)\nimport psi4\n\n# Set Psi4 & NumPy Memory Options\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\nnumpy_memory = 2\n\n# Set molecule to dimer\ndimer = psi4.geometry(""""""\n#Set the spin of A\n0 3\nO    0.000000000   0.000000000   2.605000000\nO    0.000000000   0.000000000   1.395000000\n--\n#Set the spin of A\n0 3\nO    0.000000000   0.000000000  -1.395000000\nO    0.000000000   0.000000000  -2.605000000\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'jun-cc-pVDZ\',\n                  \'e_convergence\': 1e-8,\n                  \'d_convergence\': 1e-8,\n                  \'scf_type\': \'pk\',\n                  \'reference\': \'rohf\'})\n\nsapt = helper_SAPT(dimer, memory=8, reference=\'ROHF\')\n\n### Start E100 Electostatics\nelst_timer = sapt_timer(\'electrostatics\')\nElst10 = 4 * np.einsum(\'ijij\', sapt.vt(\'ijij\'))\nElst10 += 2 * np.einsum(\'ajaj\', sapt.vt(\'ajaj\'))\nElst10 += 2 * np.einsum(\'ibib\', sapt.vt(\'ibib\'))\nElst10 += np.einsum(\'abab\', sapt.vt(\'abab\'))\nelst_timer.stop()\n### End E100 Electrostatics\n\n### Start E100 Exchange\nexch_timer = sapt_timer(\'exchange\')\ns_ij = sapt.s(\'ij\')\ns_ib = sapt.s(\'ib\')\ns_is = sapt.s(\'is\')\ns_aj = sapt.s(\'aj\')\ns_ab = sapt.s(\'ab\')\ns_as = sapt.s(\'as\')\ns_rj = sapt.s(\'rj\')\ns_rb = sapt.s(\'rb\')\n\nvt_ijji = sapt.vt(\'ijji\')\nvt_ajja = sapt.vt(\'ajja\')\nvt_ibbi = sapt.vt(\'ibbi\')\nvt_abba = sapt.vt(\'abba\')\n\nExch100 = -2 * np.einsum(\'ijji\', vt_ijji)\nExch100 -= np.einsum(\'ajja\', vt_ajja)\nExch100 -= np.einsum(\'ibbi\', vt_ibbi)\nExch100 -= np.einsum(\'abba\', vt_abba)\n#znacznik\n\nvt_ijii = sapt.vt(\'ijii\')\ntemp = -2 * vt_ijii + vt_ijii.swapaxes(2, 3)\nExch100 += 2 * np.einsum(\'ijiI,Ij\', temp, s_ij)\nvt_ibii = sapt.vt(\'ibii\')\ntemp = -2 * vt_ibii + vt_ibii.swapaxes(2, 3)\nExch100 += np.einsum(\'ibiI,Ib\', temp, s_ib)\nvt_ijia = sapt.vt(\'ijia\')\nvt_ijai = sapt.vt(\'ijai\')\nExch100 -= 2 * np.einsum(\'ijia,aj\', vt_ijia, s_aj)\nExch100 += np.einsum(\'ijai,aj\', vt_ijai, s_aj)\nvt_ibia = sapt.vt(\'ibia\')\nvt_ibai = sapt.vt(\'ibai\')\nExch100 -= 2 * np.einsum(\'ibia,ab\', vt_ibia, s_ab)\nExch100 += np.einsum(\'ibai,ab\', vt_ibai, s_ab)\n\nvt_ajai = sapt.vt(\'ajai\')\nvt_ajia = sapt.vt(\'ajia\')\nExch100 -= 2 * np.einsum(\'ajai,ij\', vt_ajai, s_ij)\nExch100 += np.einsum(\'ajia,ij\', vt_ajia, s_ij)\nvt_abai = sapt.vt(\'abai\')\nvt_abia = sapt.vt(\'abia\')\nExch100 -= np.einsum(\'abai,ib\', vt_abai, s_ib)\nExch100 += np.einsum(\'abia,ib\', vt_abia, s_ib)\nvt_ajaa = sapt.vt(\'ajaa\')\ntemp = -vt_ajaa + vt_ajaa.swapaxes(2, 3)\nExch100 += np.einsum(\'ajaA,Aj\', temp, s_aj)\nvt_abaa = sapt.vt(\'abaa\')\ntemp = -vt_abaa + vt_abaa.swapaxes(2, 3)\nExch100 += np.einsum(\'abaA,Ab\', temp, s_ab)\n\nvt_ijjj = sapt.vt(\'ijjj\')\ntemp = -2 * vt_ijjj + vt_ijjj.swapaxes(2, 3)\nExch100 += 2 * np.einsum(\'ijJj,iJ\', temp, s_ij)\nvt_ajjj = sapt.vt(\'ajjj\')\ntemp = -2 * vt_ajjj + vt_ajjj.swapaxes(2, 3)\nExch100 += np.einsum(\'ajJj,aJ\', temp, s_aj)\nvt_ibjb = sapt.vt(\'ibjb\')\nvt_ibbj = sapt.vt(\'ibbj\')\nExch100 -= 2 * np.einsum(\'ibjb,ij\', vt_ibjb, s_ij)\nExch100 += np.einsum(\'ibbj,ij\', vt_ibbj, s_ij)\nvt_abjb = sapt.vt(\'abjb\')\nvt_abbj = sapt.vt(\'abbj\')\nExch100 -= np.einsum(\'abjb,aj\', vt_abjb, s_aj)\nExch100 += np.einsum(\'abbj,aj\', vt_abbj, s_aj)\n\nvt_ijbj = sapt.vt(\'ijbj\')\nvt_ijjb = sapt.vt(\'ijjb\')\nExch100 -= 2 * np.einsum(\'ijbj,ib\', vt_ijbj, s_ib)\nExch100 += np.einsum(\'ijjb,ib\', vt_ijjb, s_ib)\nvt_ajbj = sapt.vt(\'ajbj\')\nvt_ajjb = sapt.vt(\'ajjb\')\nExch100 -= 2 * np.einsum(\'ajbj,ab\', vt_ajbj, s_ab)\nExch100 += np.einsum(\'ajjb,ab\', vt_ajjb, s_ab)\nvt_ibbb = sapt.vt(\'ibbb\')\ntemp = -vt_ibbb + vt_ibbb.swapaxes(2, 3)\nExch100 += np.einsum(\'ibBb,iB\', temp, s_ib)\nvt_abbb = sapt.vt(\'abbb\')\ntemp = -vt_abbb + vt_abbb.swapaxes(2, 3)\nExch100 += np.einsum(\'abBb,aB\', temp, s_ab)\n\nvt_ijij = sapt.vt(\'ijij\')\nExch100 += 4 * np.einsum(\'ijiJ,Ij,IJ\', vt_ijij, s_ij, s_ij)\nExch100 += 2 * np.einsum(\'ijiJ,aj,aJ\', vt_ijij, s_aj, s_aj)\nExch100 += 4 * np.einsum(\'ijIj,IJ,iJ\', vt_ijij, s_ij, s_ij)\nExch100 += 2 * np.einsum(\'ijIj,Ib,ib\', vt_ijij, s_ib, s_ib)\nExch100 -= 2 * np.einsum(\'ijIJ,Ij,iJ\', vt_ijij, s_ij, s_ij)\n\nvt_ibij = sapt.vt(\'ibij\')\nExch100 += 4 * np.einsum(\'ibij,Ib,Ij\', vt_ibij, s_ib, s_ij)\nExch100 += 4 * np.einsum(\'ibij,ab,aj\', vt_ibij, s_ab, s_aj)\nExch100 -= 2 * np.einsum(\'ibIj,Ib,ij\', vt_ibij, s_ib, s_ij)\n\nvt_ajij = sapt.vt(\'ajij\')\nExch100 += 4 * np.einsum(\'ajij,iJ,aJ\', vt_ajij, s_ij, s_aj)\nExch100 += 4 * np.einsum(\'ajij,ib,ab\', vt_ajij, s_ib, s_ab)\nExch100 -= 2 * np.einsum(\'ajiJ,ij,aJ\', vt_ajij, s_ij, s_aj)\n\nvt_abij = sapt.vt(\'abij\')\nExch100 -= 2 * np.einsum(\'abij,ib,aj\', vt_abij, s_ib, s_aj)\nExch100 -= 2 * np.einsum(\'abij,ij,ab\', vt_abij, s_ij, s_ab)\n\nvt_ibib = sapt.vt(\'ibib\')\nExch100 += 2 * np.einsum(\'ibiB,Ib,IB\', vt_ibib, s_ib, s_ib)\nExch100 += 2 * np.einsum(\'ibiB,ab,aB\', vt_ibib, s_ab, s_ab)\nExch100 += 2 * np.einsum(\'ibIb,Ij,ij\', vt_ibib, s_ij, s_ij)\nExch100 += np.einsum(\'ibIb,IB,iB\', vt_ibib, s_ib, s_ib)\nExch100 -= np.einsum(\'ibIB,Ib,iB\', vt_ibib, s_ib, s_ib)\n\nvt_ajaj = sapt.vt(\'ajaj\')\nExch100 += 2 * np.einsum(\'ajAj,AJ,aJ\', vt_ajaj, s_aj, s_aj)\nExch100 += 2 * np.einsum(\'ajAj,Ab,ab\', vt_ajaj, s_ab, s_ab)\nExch100 += 2 * np.einsum(\'ajaJ,ij,iJ\', vt_ajaj, s_ij, s_ij)\nExch100 += np.einsum(\'ajaJ,Aj,AJ\', vt_ajaj, s_aj, s_aj)\nExch100 -= np.einsum(\'ajAJ,Aj,aJ\', vt_ajaj, s_aj, s_aj)\n\nvt_abaj = sapt.vt(\'abaj\')\nExch100 += 2 * np.einsum(\'abaj,ib,ij\', vt_abaj, s_ib, s_ij)\nExch100 += 2 * np.einsum(\'abaj,Ab,Aj\', vt_abaj, s_ab, s_aj)\nExch100 -= 2 * np.einsum(\'abAj,Ab,aj\', vt_abaj, s_ab, s_aj)\n\nvt_abib = sapt.vt(\'abib\')\nExch100 += 2 * np.einsum(\'abib,ij,aj\', vt_abib, s_ij, s_aj)\nExch100 += 2 * np.einsum(\'abib,iB,aB\', vt_abib, s_ib, s_ab)\nExch100 -= 2 * np.einsum(\'abiB,ib,aB\', vt_abib, s_ib, s_ab)\n\nvt_abab = sapt.vt(\'abab\')\nExch100 += np.einsum(\'abaB,ib,iB\', vt_abab, s_ib, s_ib)\nExch100 += np.einsum(\'abaB,Ab,AB\', vt_abab, s_ab, s_ab)\nExch100 += np.einsum(\'abAb,Aj,aj\', vt_abab, s_aj, s_aj)\nExch100 += np.einsum(\'abAb,AB,aB\', vt_abab, s_ab, s_ab)\nExch100 -= np.einsum(\'abAB,Ab,aB\', vt_abab, s_ab, s_ab)\n\nexch_timer.stop()\n### End E100 (S^2) Exchange\n\n### Start E200 Disp\ndisp_timer = sapt_timer(\'dispersion and exchange dispersion\')\nv_rsij = sapt.v(\'rsij\')\nv_rsab = sapt.v(\'rsab\')\nv_rsaj = sapt.v(\'rsaj\')\nv_rsib = sapt.v(\'rsib\')\nv_abij = sapt.v(\'abij\')\nv_rbij = sapt.v(\'rbij\')\nv_asij = sapt.v(\'asij\')\nv_rbaj = sapt.v(\'rbaj\')\nv_asib = sapt.v(\'asib\')\ne_rsij = 1 / (-sapt.eps(\'r\', dim=4) - sapt.eps(\'s\', dim=3) + sapt.eps(\'i\', dim=2) + sapt.eps(\'j\'))\ne_rsab = 1 / (-sapt.eps(\'r\', dim=4) - sapt.eps(\'s\', dim=3) + sapt.eps(\'a\', dim=2) + sapt.eps(\'b\'))\ne_rsaj = 1 / (-sapt.eps(\'r\', dim=4) - sapt.eps(\'s\', dim=3) + sapt.eps(\'a\', dim=2) + sapt.eps(\'j\'))\ne_rsib = 1 / (-sapt.eps(\'r\', dim=4) - sapt.eps(\'s\', dim=3) + sapt.eps(\'i\', dim=2) + sapt.eps(\'b\'))\ne_abij = 1 / (-sapt.eps(\'a\', dim=4) - sapt.eps(\'b\', dim=3) + sapt.eps(\'i\', dim=2) + sapt.eps(\'j\'))\ne_rbij = 1 / (-sapt.eps(\'r\', dim=4) - sapt.eps(\'b\', dim=3) + sapt.eps(\'i\', dim=2) + sapt.eps(\'j\'))\ne_asij = 1 / (-sapt.eps(\'a\', dim=4) - sapt.eps(\'s\', dim=3) + sapt.eps(\'i\', dim=2) + sapt.eps(\'j\'))\ne_rbaj = 1 / (-sapt.eps(\'r\', dim=4) - sapt.eps(\'b\', dim=3) + sapt.eps(\'a\', dim=2) + sapt.eps(\'j\'))\ne_asib = 1 / (-sapt.eps(\'a\', dim=4) - sapt.eps(\'s\', dim=3) + sapt.eps(\'i\', dim=2) + sapt.eps(\'b\'))\nt_rsij = np.einsum(\'rsij,rsij->rsij\', v_rsij, e_rsij)\nt_rsab = np.einsum(\'rsab,rsab->rsab\', v_rsab, e_rsab)\nt_rsaj = np.einsum(\'rsaj,rsaj->rsaj\', v_rsaj, e_rsaj)\nt_rsib = np.einsum(\'rsib,rsib->rsib\', v_rsib, e_rsib)\nt_abij = np.einsum(\'abij,abij->abij\', v_abij, e_abij)\nt_rbij = np.einsum(\'rbij,rbij->rbij\', v_rbij, e_rbij)\nt_asij = np.einsum(\'asij,asij->asij\', v_asij, e_asij)\nt_rbaj = np.einsum(\'rbaj,rbaj->rbaj\', v_rbaj, e_rbaj)\nt_asib = np.einsum(\'asib,asib->asib\', v_asib, e_asib)\n\nDisp200 = 4 * np.einsum(\'rsij,rsij,rsij->\', e_rsij, v_rsij, v_rsij)\nDisp200 += np.einsum(\'rsab,rsab,rsab->\', e_rsab, v_rsab, v_rsab)\nDisp200 += 2 * np.einsum(\'rsaj,rsaj,rsaj->\', e_rsaj, v_rsaj, v_rsaj)\nDisp200 += 2 * np.einsum(\'rsib,rsib,rsib->\', e_rsib, v_rsib, v_rsib)\nDisp200 += np.einsum(\'abij,abij,abij->\', e_abij, v_abij, v_abij)\nDisp200 += 2 * np.einsum(\'rbij,rbij,rbij->\', e_rbij, v_rbij, v_rbij)\nDisp200 += 2 * np.einsum(\'asij,asij,asij->\', e_asij, v_asij, v_asij)\nDisp200 += np.einsum(\'rbaj,rbaj,rbaj->\', e_rbaj, v_rbaj, v_rbaj)\nDisp200 += np.einsum(\'asib,asib,asib->\', e_asib, v_asib, v_asib)\n### End E200 Disp\n\n### Start E200 Exchange-Dispersion\n# the code is brute-force autoimplemented from the auto-gnerated LaTeX formula\nresult = 0.0\ntemp = sapt.vt(\'absr\')\nresult -= np.einsum(\'rsab,absr->\', t_rsab, temp)\ntemp = sapt.vt(\'ajsr\')\nresult -= np.einsum(\'rsaj,ajsr->\', t_rsaj, temp)\ntemp = sapt.vt(\'ibsr\')\nresult -= np.einsum(\'rsib,ibsr->\', t_rsib, temp)\ntemp = sapt.vt(\'ijba\')\nresult -= np.einsum(\'abij,ijba->\', t_abij, temp)\ntemp = sapt.vt(\'ijsa\')\nresult -= np.einsum(\'asij,ijsa->\', t_asij, temp)\ntemp = sapt.vt(\'ijbr\')\nresult -= np.einsum(\'rbij,ijbr->\', t_rbij, temp)\ntemp = sapt.vt(\'ijsr\')\nresult -= 2 * np.einsum(\'rsij,ijsr->\', t_rsij, temp)\ntemp = sapt.vt(\'abar\')\nresult -= np.einsum(\'rsab,as,AbAr->\', t_rsab, s_as, temp)\nresult += np.einsum(\'rsab,As,abAr->\', t_rsab, s_as, temp)\ntemp = sapt.vt(\'abbs\')\nresult += np.einsum(\'rsab,rb,aBBs->\', t_rsab, s_rb, temp)\nresult -= np.einsum(\'rsab,rB,abBs->\', t_rsab, s_rb, temp)\ntemp = sapt.vt(\'abir\')\nresult += np.einsum(\'rsab,Is,abIr->\', t_rsab, s_is, temp)\ntemp = sapt.vt(\'ibir\')\nresult -= 2 * np.einsum(\'rsab,as,IbIr->\', t_rsab, s_as, temp)\ntemp = sapt.vt(\'abjs\')\nresult -= np.einsum(\'rsab,rJ,abJs->\', t_rsab, s_rj, temp)\ntemp = sapt.vt(\'ajjs\')\nresult += np.einsum(\'rsab,rb,aJJs->\', t_rsab, s_rb, temp)\ntemp = sapt.vt(\'abra\')\nresult += np.einsum(\'rsab,as,AbrA->\', t_rsab, s_as, temp)\nresult -= np.einsum(\'rsab,As,abrA->\', t_rsab, s_as, temp)\ntemp = sapt.vt(\'abri\')\nresult -= np.einsum(\'rsab,Is,abrI->\', t_rsab, s_is, temp)\ntemp = sapt.vt(\'ibri\')\nresult += np.einsum(\'rsab,as,IbrI->\', t_rsab, s_as, temp)\ntemp = sapt.vt(\'absb\')\nresult -= np.einsum(\'rsab,rb,aBsB->\', t_rsab, s_rb, temp)\nresult += np.einsum(\'rsab,rB,absB->\', t_rsab, s_rb, temp)\ntemp = sapt.vt(\'absj\')\nresult += np.einsum(\'rsab,rJ,absJ->\', t_rsab, s_rj, temp)\ntemp = sapt.vt(\'ajsj\')\nresult -= 2 * np.einsum(\'rsab,rb,aJsJ->\', t_rsab, s_rb, temp)\ntemp = sapt.vt(\'ajbb\')\nresult -= np.einsum(\'rbaj,rB,ajBb->\', t_rbaj, s_rb, temp)\ntemp = sapt.vt(\'ajjb\')\nresult -= np.einsum(\'rbaj,rJ,ajJb->\', t_rbaj, s_rj, temp)\ntemp = sapt.vt(\'ajri\')\nresult -= np.einsum(\'rbaj,Ib,ajrI->\', t_rbaj, s_ib, temp)\ntemp = sapt.vt(\'ajar\')\nresult -= np.einsum(\'rsaj,as,AjAr->\', t_rsaj, s_as, temp)\nresult += np.einsum(\'rsaj,As,ajAr->\', t_rsaj, s_as, temp)\ntemp = sapt.vt(\'abbs\')\nresult += np.einsum(\'rsaj,rj,aBBs->\', t_rsaj, s_rj, temp)\ntemp = sapt.vt(\'ajbs\')\nresult -= 2 * np.einsum(\'rsaj,rB,ajBs->\', t_rsaj, s_rb, temp)\ntemp = sapt.vt(\'ajir\')\nresult += np.einsum(\'rsaj,Is,ajIr->\', t_rsaj, s_is, temp)\ntemp = sapt.vt(\'ijir\')\nresult -= 2 * np.einsum(\'rsaj,as,IjIr->\', t_rsaj, s_as, temp)\ntemp = sapt.vt(\'ajjs\')\nresult += np.einsum(\'rsaj,rj,aJJs->\', t_rsaj, s_rj, temp)\nresult -= 2 * np.einsum(\'rsaj,rJ,ajJs->\', t_rsaj, s_rj, temp)\ntemp = sapt.vt(\'ajra\')\nresult += np.einsum(\'rsaj,as,AjrA->\', t_rsaj, s_as, temp)\nresult -= np.einsum(\'rsaj,As,ajrA->\', t_rsaj, s_as, temp)\ntemp = sapt.vt(\'ajri\')\nresult -= 2 * np.einsum(\'rsaj,Is,ajrI->\', t_rsaj, s_is, temp)\ntemp = sapt.vt(\'ijri\')\nresult += np.einsum(\'rsaj,as,IjrI->\', t_rsaj, s_as, temp)\ntemp = sapt.vt(\'absb\')\nresult -= np.einsum(\'rsaj,rj,aBsB->\', t_rsaj, s_rj, temp)\ntemp = sapt.vt(\'ajsb\')\nresult += np.einsum(\'rsaj,rB,ajsB->\', t_rsaj, s_rb, temp)\ntemp = sapt.vt(\'ajsj\')\nresult -= 2 * np.einsum(\'rsaj,rj,aJsJ->\', t_rsaj, s_rj, temp)\nresult += np.einsum(\'rsaj,rJ,ajsJ->\', t_rsaj, s_rj, temp)\ntemp = sapt.vt(\'ibaa\')\nresult -= np.einsum(\'asib,As,ibaA->\', t_asib, s_as, temp)\ntemp = sapt.vt(\'ibai\')\nresult -= np.einsum(\'asib,Is,ibaI->\', t_asib, s_is, temp)\ntemp = sapt.vt(\'ibjs\')\nresult -= np.einsum(\'asib,aJ,ibJs->\', t_asib, s_aj, temp)\ntemp = sapt.vt(\'abar\')\nresult -= np.einsum(\'rsib,is,AbAr->\', t_rsib, s_is, temp)\ntemp = sapt.vt(\'ibar\')\nresult += np.einsum(\'rsib,As,ibAr->\', t_rsib, s_as, temp)\ntemp = sapt.vt(\'ibbs\')\nresult += np.einsum(\'rsib,rb,iBBs->\', t_rsib, s_rb, temp)\nresult -= np.einsum(\'rsib,rB,ibBs->\', t_rsib, s_rb, temp)\ntemp = sapt.vt(\'ibir\')\nresult -= 2 * np.einsum(\'rsib,is,IbIr->\', t_rsib, s_is, temp)\nresult += np.einsum(\'rsib,Is,ibIr->\', t_rsib, s_is, temp)\ntemp = sapt.vt(\'ibjs\')\nresult -= 2 * np.einsum(\'rsib,rJ,ibJs->\', t_rsib, s_rj, temp)\ntemp = sapt.vt(\'ijjs\')\nresult += np.einsum(\'rsib,rb,iJJs->\', t_rsib, s_rb, temp)\ntemp = sapt.vt(\'abra\')\nresult += np.einsum(\'rsib,is,AbrA->\', t_rsib, s_is, temp)\ntemp = sapt.vt(\'ibra\')\nresult -= 2 * np.einsum(\'rsib,As,ibrA->\', t_rsib, s_as, temp)\ntemp = sapt.vt(\'ibri\')\nresult += np.einsum(\'rsib,is,IbrI->\', t_rsib, s_is, temp)\nresult -= 2 * np.einsum(\'rsib,Is,ibrI->\', t_rsib, s_is, temp)\ntemp = sapt.vt(\'ibsb\')\nresult -= np.einsum(\'rsib,rb,iBsB->\', t_rsib, s_rb, temp)\nresult += np.einsum(\'rsib,rB,ibsB->\', t_rsib, s_rb, temp)\ntemp = sapt.vt(\'ibsj\')\nresult += np.einsum(\'rsib,rJ,ibsJ->\', t_rsib, s_rj, temp)\ntemp = sapt.vt(\'ijsj\')\nresult -= 2 * np.einsum(\'rsib,rb,iJsJ->\', t_rsib, s_rb, temp)\ntemp = sapt.vt(\'ajaa\')\nresult -= np.einsum(\'abij,ib,AjAa->\', t_abij, s_ib, temp)\ntemp = sapt.vt(\'ijai\')\nresult += np.einsum(\'abij,ib,IjaI->\', t_abij, s_ib, temp)\nresult -= np.einsum(\'abij,Ib,ijaI->\', t_abij, s_ib, temp)\ntemp = sapt.vt(\'ibbb\')\nresult -= np.einsum(\'abij,aj,iBbB->\', t_abij, s_aj, temp)\ntemp = sapt.vt(\'ijbj\')\nresult -= 2 * np.einsum(\'abij,aj,iJbJ->\', t_abij, s_aj, temp)\nresult += np.einsum(\'abij,aJ,ijbJ->\', t_abij, s_aj, temp)\ntemp = sapt.vt(\'ijia\')\nresult -= 2 * np.einsum(\'abij,ib,IjIa->\', t_abij, s_ib, temp)\nresult += np.einsum(\'abij,Ib,ijIa->\', t_abij, s_ib, temp)\ntemp = sapt.vt(\'ijjb\')\nresult += np.einsum(\'abij,aj,iJJb->\', t_abij, s_aj, temp)\nresult -= np.einsum(\'abij,aJ,ijJb->\', t_abij, s_aj, temp)\ntemp = sapt.vt(\'ajaa\')\nresult -= np.einsum(\'asij,is,AjAa->\', t_asij, s_is, temp)\ntemp = sapt.vt(\'ijaa\')\nresult -= np.einsum(\'asij,As,ijaA->\', t_asij, s_as, temp)\ntemp = sapt.vt(\'ijai\')\nresult += np.einsum(\'asij,is,IjaI->\', t_asij, s_is, temp)\nresult -= 2 * np.einsum(\'asij,Is,ijaI->\', t_asij, s_is, temp)\ntemp = sapt.vt(\'ijia\')\nresult -= 2 * np.einsum(\'asij,is,IjIa->\', t_asij, s_is, temp)\nresult += np.einsum(\'asij,Is,ijIa->\', t_asij, s_is, temp)\ntemp = sapt.vt(\'ijjs\')\nresult += np.einsum(\'asij,aj,iJJs->\', t_asij, s_aj, temp)\nresult -= 2 * np.einsum(\'asij,aJ,ijJs->\', t_asij, s_aj, temp)\ntemp = sapt.vt(\'ibsb\')\nresult -= np.einsum(\'asij,aj,iBsB->\', t_asij, s_aj, temp)\ntemp = sapt.vt(\'ijsj\')\nresult -= 2 * np.einsum(\'asij,aj,iJsJ->\', t_asij, s_aj, temp)\nresult += np.einsum(\'asij,aJ,ijsJ->\', t_asij, s_aj, temp)\ntemp = sapt.vt(\'ajar\')\nresult -= np.einsum(\'rbij,ib,AjAr->\', t_rbij, s_ib, temp)\ntemp = sapt.vt(\'ijbb\')\nresult -= np.einsum(\'rbij,rB,ijBb->\', t_rbij, s_rb, temp)\ntemp = sapt.vt(\'ibbb\')\nresult -= np.einsum(\'rbij,rj,iBbB->\', t_rbij, s_rj, temp)\ntemp = sapt.vt(\'ijbj\')\nresult -= 2 * np.einsum(\'rbij,rj,iJbJ->\', t_rbij, s_rj, temp)\nresult += np.einsum(\'rbij,rJ,ijbJ->\', t_rbij, s_rj, temp)\ntemp = sapt.vt(\'ijir\')\nresult -= 2 * np.einsum(\'rbij,ib,IjIr->\', t_rbij, s_ib, temp)\nresult += np.einsum(\'rbij,Ib,ijIr->\', t_rbij, s_ib, temp)\ntemp = sapt.vt(\'ijjb\')\nresult += np.einsum(\'rbij,rj,iJJb->\', t_rbij, s_rj, temp)\nresult -= 2 * np.einsum(\'rbij,rJ,ijJb->\', t_rbij, s_rj, temp)\ntemp = sapt.vt(\'ijri\')\nresult += np.einsum(\'rbij,ib,IjrI->\', t_rbij, s_ib, temp)\nresult -= 2 * np.einsum(\'rbij,Ib,ijrI->\', t_rbij, s_ib, temp)\ntemp = sapt.vt(\'ajar\')\nresult -= 2 * np.einsum(\'rsij,is,AjAr->\', t_rsij, s_is, temp)\ntemp = sapt.vt(\'ijar\')\nresult += np.einsum(\'rsij,As,ijAr->\', t_rsij, s_as, temp)\ntemp = sapt.vt(\'ibbs\')\nresult += np.einsum(\'rsij,rj,iBBs->\', t_rsij, s_rj, temp)\ntemp = sapt.vt(\'ijbs\')\nresult -= 2 * np.einsum(\'rsij,rB,ijBs->\', t_rsij, s_rb, temp)\ntemp = sapt.vt(\'ijir\')\nresult -= 4 * np.einsum(\'rsij,is,IjIr->\', t_rsij, s_is, temp)\nresult += 2 * np.einsum(\'rsij,Is,ijIr->\', t_rsij, s_is, temp)\ntemp = sapt.vt(\'ijjs\')\nresult += 2 * np.einsum(\'rsij,rj,iJJs->\', t_rsij, s_rj, temp)\nresult -= 4 * np.einsum(\'rsij,rJ,ijJs->\', t_rsij, s_rj, temp)\ntemp = sapt.vt(\'ajra\')\nresult += np.einsum(\'rsij,is,AjrA->\', t_rsij, s_is, temp)\ntemp = sapt.vt(\'ijra\')\nresult -= 2 * np.einsum(\'rsij,As,ijrA->\', t_rsij, s_as, temp)\ntemp = sapt.vt(\'ijri\')\nresult += 2 * np.einsum(\'rsij,is,IjrI->\', t_rsij, s_is, temp)\nresult -= 4 * np.einsum(\'rsij,Is,ijrI->\', t_rsij, s_is, temp)\ntemp = sapt.vt(\'ibsb\')\nresult -= 2 * np.einsum(\'rsij,rj,iBsB->\', t_rsij, s_rj, temp)\ntemp = sapt.vt(\'ijsb\')\nresult += np.einsum(\'rsij,rB,ijsB->\', t_rsij, s_rb, temp)\ntemp = sapt.vt(\'ijsj\')\nresult -= 4 * np.einsum(\'rsij,rj,iJsJ->\', t_rsij, s_rj, temp)\nresult += 2 * np.einsum(\'rsij,rJ,ijsJ->\', t_rsij, s_rj, temp)\ntemp = sapt.vt(\'abab\')\nresult += np.einsum(\'rsab,as,rB,AbAB->\', t_rsab, s_as, s_rb, temp)\nresult += np.einsum(\'rsab,As,rb,aBAB->\', t_rsab, s_as, s_rb, temp)\nresult -= np.einsum(\'rsab,As,rB,abAB->\', t_rsab, s_as, s_rb, temp)\ntemp = sapt.vt(\'abaj\')\nresult += np.einsum(\'rsab,as,rJ,AbAJ->\', t_rsab, s_as, s_rj, temp)\nresult -= np.einsum(\'rsab,As,rJ,abAJ->\', t_rsab, s_as, s_rj, temp)\ntemp = sapt.vt(\'ajaj\')\nresult += 2 * np.einsum(\'rsab,As,rb,aJAJ->\', t_rsab, s_as, s_rb, temp)\ntemp = sapt.vt(\'abas\')\nresult += np.einsum(\'rsab,aB,rb,ABAs->\', t_rsab, s_ab, s_rb, temp)\nresult -= np.einsum(\'rsab,aB,rB,AbAs->\', t_rsab, s_ab, s_rb, temp)\nresult -= np.einsum(\'rsab,aJ,rJ,AbAs->\', t_rsab, s_aj, s_rj, temp)\ntemp = sapt.vt(\'ajas\')\nresult += np.einsum(\'rsab,aJ,rb,AJAs->\', t_rsab, s_aj, s_rb, temp)\ntemp = sapt.vt(\'abas\')\nresult -= np.einsum(\'rsab,AB,rb,aBAs->\', t_rsab, s_ab, s_rb, temp)\nresult += np.einsum(\'rsab,AB,rB,abAs->\', t_rsab, s_ab, s_rb, temp)\nresult += np.einsum(\'rsab,AJ,rJ,abAs->\', t_rsab, s_aj, s_rj, temp)\ntemp = sapt.vt(\'ajas\')\nresult -= np.einsum(\'rsab,AJ,rb,aJAs->\', t_rsab, s_aj, s_rb, temp)\ntemp = sapt.vt(\'abib\')\nresult += np.einsum(\'rsab,Is,rb,aBIB->\', t_rsab, s_is, s_rb, temp)\nresult -= np.einsum(\'rsab,Is,rB,abIB->\', t_rsab, s_is, s_rb, temp)\ntemp = sapt.vt(\'ibib\')\nresult += 2 * np.einsum(\'rsab,as,rB,IbIB->\', t_rsab, s_as, s_rb, temp)\ntemp = sapt.vt(\'abij\')\nresult -= np.einsum(\'rsab,Is,rJ,abIJ->\', t_rsab, s_is, s_rj, temp)\ntemp = sapt.vt(\'ajij\')\nresult += 2 * np.einsum(\'rsab,Is,rb,aJIJ->\', t_rsab, s_is, s_rb, temp)\ntemp = sapt.vt(\'ibij\')\nresult += 2 * np.einsum(\'rsab,as,rJ,IbIJ->\', t_rsab, s_as, s_rj, temp)\ntemp = sapt.vt(\'abis\')\nresult -= np.einsum(\'rsab,IB,rb,aBIs->\', t_rsab, s_ib, s_rb, temp)\nresult += np.einsum(\'rsab,IB,rB,abIs->\', t_rsab, s_ib, s_rb, temp)\nresult += np.einsum(\'rsab,IJ,rJ,abIs->\', t_rsab, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ajis\')\nresult -= np.einsum(\'rsab,IJ,rb,aJIs->\', t_rsab, s_ij, s_rb, temp)\ntemp = sapt.vt(\'ibis\')\nresult += 2 * np.einsum(\'rsab,aB,rb,IBIs->\', t_rsab, s_ab, s_rb, temp)\nresult -= 2 * np.einsum(\'rsab,aB,rB,IbIs->\', t_rsab, s_ab, s_rb, temp)\nresult -= 2 * np.einsum(\'rsab,aJ,rJ,IbIs->\', t_rsab, s_aj, s_rj, temp)\ntemp = sapt.vt(\'ijis\')\nresult += 2 * np.einsum(\'rsab,aJ,rb,IJIs->\', t_rsab, s_aj, s_rb, temp)\ntemp = sapt.vt(\'abrb\')\nresult += np.einsum(\'rsab,as,Ab,ABrB->\', t_rsab, s_as, s_ab, temp)\nresult -= np.einsum(\'rsab,as,AB,AbrB->\', t_rsab, s_as, s_ab, temp)\nresult -= np.einsum(\'rsab,As,Ab,aBrB->\', t_rsab, s_as, s_ab, temp)\nresult -= np.einsum(\'rsab,Is,Ib,aBrB->\', t_rsab, s_is, s_ib, temp)\nresult += np.einsum(\'rsab,As,AB,abrB->\', t_rsab, s_as, s_ab, temp)\nresult += np.einsum(\'rsab,Is,IB,abrB->\', t_rsab, s_is, s_ib, temp)\ntemp = sapt.vt(\'ibrb\')\nresult += np.einsum(\'rsab,as,Ib,IBrB->\', t_rsab, s_as, s_ib, temp)\nresult -= np.einsum(\'rsab,as,IB,IbrB->\', t_rsab, s_as, s_ib, temp)\ntemp = sapt.vt(\'abrj\')\nresult -= np.einsum(\'rsab,as,AJ,AbrJ->\', t_rsab, s_as, s_aj, temp)\ntemp = sapt.vt(\'ajrj\')\nresult += 2 * np.einsum(\'rsab,as,Ab,AJrJ->\', t_rsab, s_as, s_ab, temp)\ntemp = sapt.vt(\'abrj\')\nresult += np.einsum(\'rsab,As,AJ,abrJ->\', t_rsab, s_as, s_aj, temp)\nresult += np.einsum(\'rsab,Is,IJ,abrJ->\', t_rsab, s_is, s_ij, temp)\ntemp = sapt.vt(\'ajrj\')\nresult -= 2 * np.einsum(\'rsab,As,Ab,aJrJ->\', t_rsab, s_as, s_ab, temp)\nresult -= 2 * np.einsum(\'rsab,Is,Ib,aJrJ->\', t_rsab, s_is, s_ib, temp)\ntemp = sapt.vt(\'ibrj\')\nresult -= np.einsum(\'rsab,as,IJ,IbrJ->\', t_rsab, s_as, s_ij, temp)\ntemp = sapt.vt(\'ijrj\')\nresult += 2 * np.einsum(\'rsab,as,Ib,IJrJ->\', t_rsab, s_as, s_ib, temp)\ntemp = sapt.vt(\'abrs\')\nresult -= np.einsum(\'rsab,aB,Ab,ABrs->\', t_rsab, s_ab, s_ab, temp)\nresult += np.einsum(\'rsab,aB,AB,Abrs->\', t_rsab, s_ab, s_ab, temp)\nresult += np.einsum(\'rsab,aJ,AJ,Abrs->\', t_rsab, s_aj, s_aj, temp)\ntemp = sapt.vt(\'ajrs\')\nresult -= np.einsum(\'rsab,aJ,Ab,AJrs->\', t_rsab, s_aj, s_ab, temp)\ntemp = sapt.vt(\'abrs\')\nresult += np.einsum(\'rsab,AB,Ab,aBrs->\', t_rsab, s_ab, s_ab, temp)\nresult += np.einsum(\'rsab,IB,Ib,aBrs->\', t_rsab, s_ib, s_ib, temp)\ntemp = sapt.vt(\'ajrs\')\nresult += np.einsum(\'rsab,AJ,Ab,aJrs->\', t_rsab, s_aj, s_ab, temp)\nresult += np.einsum(\'rsab,IJ,Ib,aJrs->\', t_rsab, s_ij, s_ib, temp)\ntemp = sapt.vt(\'ibrs\')\nresult -= np.einsum(\'rsab,aB,Ib,IBrs->\', t_rsab, s_ab, s_ib, temp)\nresult += np.einsum(\'rsab,aB,IB,Ibrs->\', t_rsab, s_ab, s_ib, temp)\nresult += np.einsum(\'rsab,aJ,IJ,Ibrs->\', t_rsab, s_aj, s_ij, temp)\ntemp = sapt.vt(\'ijrs\')\nresult -= np.einsum(\'rsab,aJ,Ib,IJrs->\', t_rsab, s_aj, s_ib, temp)\ntemp = sapt.vt(\'ajab\')\nresult -= np.einsum(\'rbaj,aB,rB,AjAb->\', t_rbaj, s_ab, s_rb, temp)\nresult -= np.einsum(\'rbaj,aJ,rJ,AjAb->\', t_rbaj, s_aj, s_rj, temp)\nresult += np.einsum(\'rbaj,AB,rB,ajAb->\', t_rbaj, s_ab, s_rb, temp)\nresult += np.einsum(\'rbaj,AJ,rJ,ajAb->\', t_rbaj, s_aj, s_rj, temp)\ntemp = sapt.vt(\'ajib\')\nresult += np.einsum(\'rbaj,IB,rB,ajIb->\', t_rbaj, s_ib, s_rb, temp)\nresult += np.einsum(\'rbaj,IJ,rJ,ajIb->\', t_rbaj, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ijib\')\nresult -= 2 * np.einsum(\'rbaj,aB,rB,IjIb->\', t_rbaj, s_ab, s_rb, temp)\nresult -= 2 * np.einsum(\'rbaj,aJ,rJ,IjIb->\', t_rbaj, s_aj, s_rj, temp)\ntemp = sapt.vt(\'abrb\')\nresult -= np.einsum(\'rbaj,Ib,Ij,aBrB->\', t_rbaj, s_ib, s_ij, temp)\ntemp = sapt.vt(\'ajrb\')\nresult += np.einsum(\'rbaj,aB,AB,Ajrb->\', t_rbaj, s_ab, s_ab, temp)\nresult += np.einsum(\'rbaj,aJ,AJ,Ajrb->\', t_rbaj, s_aj, s_aj, temp)\nresult += np.einsum(\'rbaj,IJ,Ij,aJrb->\', t_rbaj, s_ij, s_ij, temp)\ntemp = sapt.vt(\'ijrb\')\nresult += np.einsum(\'rbaj,aB,IB,Ijrb->\', t_rbaj, s_ab, s_ib, temp)\nresult += np.einsum(\'rbaj,aJ,IJ,Ijrb->\', t_rbaj, s_aj, s_ij, temp)\ntemp = sapt.vt(\'ajrj\')\nresult -= 2 * np.einsum(\'rbaj,Ib,Ij,aJrJ->\', t_rbaj, s_ib, s_ij, temp)\nresult += np.einsum(\'rbaj,Ib,IJ,ajrJ->\', t_rbaj, s_ib, s_ij, temp)\ntemp = sapt.vt(\'ajab\')\nresult += np.einsum(\'rsaj,as,rB,AjAB->\', t_rsaj, s_as, s_rb, temp)\ntemp = sapt.vt(\'abab\')\nresult += np.einsum(\'rsaj,As,rj,aBAB->\', t_rsaj, s_as, s_rj, temp)\ntemp = sapt.vt(\'ajab\')\nresult -= np.einsum(\'rsaj,As,rB,ajAB->\', t_rsaj, s_as, s_rb, temp)\ntemp = sapt.vt(\'ajaj\')\nresult += np.einsum(\'rsaj,as,rJ,AjAJ->\', t_rsaj, s_as, s_rj, temp)\nresult += 2 * np.einsum(\'rsaj,As,rj,aJAJ->\', t_rsaj, s_as, s_rj, temp)\nresult -= np.einsum(\'rsaj,As,rJ,ajAJ->\', t_rsaj, s_as, s_rj, temp)\ntemp = sapt.vt(\'abas\')\nresult += np.einsum(\'rsaj,aB,rj,ABAs->\', t_rsaj, s_ab, s_rj, temp)\ntemp = sapt.vt(\'ajas\')\nresult += np.einsum(\'rsaj,aJ,rj,AJAs->\', t_rsaj, s_aj, s_rj, temp)\nresult -= 2 * np.einsum(\'rsaj,aB,rB,AjAs->\', t_rsaj, s_ab, s_rb, temp)\nresult -= 2 * np.einsum(\'rsaj,aJ,rJ,AjAs->\', t_rsaj, s_aj, s_rj, temp)\ntemp = sapt.vt(\'abas\')\nresult -= np.einsum(\'rsaj,AB,rj,aBAs->\', t_rsaj, s_ab, s_rj, temp)\ntemp = sapt.vt(\'ajas\')\nresult -= np.einsum(\'rsaj,AJ,rj,aJAs->\', t_rsaj, s_aj, s_rj, temp)\nresult += 2 * np.einsum(\'rsaj,AB,rB,ajAs->\', t_rsaj, s_ab, s_rb, temp)\nresult += 2 * np.einsum(\'rsaj,AJ,rJ,ajAs->\', t_rsaj, s_aj, s_rj, temp)\ntemp = sapt.vt(\'abib\')\nresult += np.einsum(\'rsaj,Is,rj,aBIB->\', t_rsaj, s_is, s_rj, temp)\ntemp = sapt.vt(\'ajib\')\nresult -= np.einsum(\'rsaj,Is,rB,ajIB->\', t_rsaj, s_is, s_rb, temp)\ntemp = sapt.vt(\'ijib\')\nresult += 2 * np.einsum(\'rsaj,as,rB,IjIB->\', t_rsaj, s_as, s_rb, temp)\ntemp = sapt.vt(\'ajij\')\nresult += 2 * np.einsum(\'rsaj,Is,rj,aJIJ->\', t_rsaj, s_is, s_rj, temp)\nresult -= np.einsum(\'rsaj,Is,rJ,ajIJ->\', t_rsaj, s_is, s_rj, temp)\ntemp = sapt.vt(\'ijij\')\nresult += 2 * np.einsum(\'rsaj,as,rJ,IjIJ->\', t_rsaj, s_as, s_rj, temp)\ntemp = sapt.vt(\'abis\')\nresult -= np.einsum(\'rsaj,IB,rj,aBIs->\', t_rsaj, s_ib, s_rj, temp)\ntemp = sapt.vt(\'ajis\')\nresult -= np.einsum(\'rsaj,IJ,rj,aJIs->\', t_rsaj, s_ij, s_rj, temp)\nresult += 2 * np.einsum(\'rsaj,IB,rB,ajIs->\', t_rsaj, s_ib, s_rb, temp)\nresult += 2 * np.einsum(\'rsaj,IJ,rJ,ajIs->\', t_rsaj, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ibis\')\nresult += 2 * np.einsum(\'rsaj,aB,rj,IBIs->\', t_rsaj, s_ab, s_rj, temp)\ntemp = sapt.vt(\'ijis\')\nresult += 2 * np.einsum(\'rsaj,aJ,rj,IJIs->\', t_rsaj, s_aj, s_rj, temp)\nresult -= 4 * np.einsum(\'rsaj,aB,rB,IjIs->\', t_rsaj, s_ab, s_rb, temp)\nresult -= 4 * np.einsum(\'rsaj,aJ,rJ,IjIs->\', t_rsaj, s_aj, s_rj, temp)\ntemp = sapt.vt(\'abrb\')\nresult += np.einsum(\'rsaj,as,Aj,ABrB->\', t_rsaj, s_as, s_aj, temp)\ntemp = sapt.vt(\'ajrb\')\nresult -= np.einsum(\'rsaj,as,AB,AjrB->\', t_rsaj, s_as, s_ab, temp)\ntemp = sapt.vt(\'abrb\')\nresult -= np.einsum(\'rsaj,As,Aj,aBrB->\', t_rsaj, s_as, s_aj, temp)\nresult -= 2 * np.einsum(\'rsaj,Is,Ij,aBrB->\', t_rsaj, s_is, s_ij, temp)\ntemp = sapt.vt(\'ajrb\')\nresult += np.einsum(\'rsaj,As,AB,ajrB->\', t_rsaj, s_as, s_ab, temp)\nresult += np.einsum(\'rsaj,Is,IB,ajrB->\', t_rsaj, s_is, s_ib, temp)\ntemp = sapt.vt(\'ibrb\')\nresult += np.einsum(\'rsaj,as,Ij,IBrB->\', t_rsaj, s_as, s_ij, temp)\ntemp = sapt.vt(\'ijrb\')\nresult -= np.einsum(\'rsaj,as,IB,IjrB->\', t_rsaj, s_as, s_ib, temp)\ntemp = sapt.vt(\'ajrj\')\nresult += 2 * np.einsum(\'rsaj,as,Aj,AJrJ->\', t_rsaj, s_as, s_aj, temp)\nresult -= np.einsum(\'rsaj,as,AJ,AjrJ->\', t_rsaj, s_as, s_aj, temp)\nresult -= 2 * np.einsum(\'rsaj,As,Aj,aJrJ->\', t_rsaj, s_as, s_aj, temp)\nresult -= 4 * np.einsum(\'rsaj,Is,Ij,aJrJ->\', t_rsaj, s_is, s_ij, temp)\nresult += np.einsum(\'rsaj,As,AJ,ajrJ->\', t_rsaj, s_as, s_aj, temp)\nresult += 2 * np.einsum(\'rsaj,Is,IJ,ajrJ->\', t_rsaj, s_is, s_ij, temp)\ntemp = sapt.vt(\'ijrj\')\nresult += 2 * np.einsum(\'rsaj,as,Ij,IJrJ->\', t_rsaj, s_as, s_ij, temp)\nresult -= np.einsum(\'rsaj,as,IJ,IjrJ->\', t_rsaj, s_as, s_ij, temp)\ntemp = sapt.vt(\'abrs\')\nresult -= np.einsum(\'rsaj,aB,Aj,ABrs->\', t_rsaj, s_ab, s_aj, temp)\ntemp = sapt.vt(\'ajrs\')\nresult -= np.einsum(\'rsaj,aJ,Aj,AJrs->\', t_rsaj, s_aj, s_aj, temp)\nresult += 2 * np.einsum(\'rsaj,aB,AB,Ajrs->\', t_rsaj, s_ab, s_ab, temp)\nresult += 2 * np.einsum(\'rsaj,aJ,AJ,Ajrs->\', t_rsaj, s_aj, s_aj, temp)\ntemp = sapt.vt(\'abrs\')\nresult += np.einsum(\'rsaj,AB,Aj,aBrs->\', t_rsaj, s_ab, s_aj, temp)\nresult += np.einsum(\'rsaj,IB,Ij,aBrs->\', t_rsaj, s_ib, s_ij, temp)\ntemp = sapt.vt(\'ajrs\')\nresult += np.einsum(\'rsaj,AJ,Aj,aJrs->\', t_rsaj, s_aj, s_aj, temp)\nresult += 2 * np.einsum(\'rsaj,IJ,Ij,aJrs->\', t_rsaj, s_ij, s_ij, temp)\ntemp = sapt.vt(\'ibrs\')\nresult -= np.einsum(\'rsaj,aB,Ij,IBrs->\', t_rsaj, s_ab, s_ij, temp)\ntemp = sapt.vt(\'ijrs\')\nresult -= np.einsum(\'rsaj,aJ,Ij,IJrs->\', t_rsaj, s_aj, s_ij, temp)\nresult += 2 * np.einsum(\'rsaj,aB,IB,Ijrs->\', t_rsaj, s_ab, s_ib, temp)\nresult += 2 * np.einsum(\'rsaj,aJ,IJ,Ijrs->\', t_rsaj, s_aj, s_ij, temp)\ntemp = sapt.vt(\'abas\')\nresult -= np.einsum(\'asib,iJ,aJ,AbAs->\', t_asib, s_ij, s_aj, temp)\ntemp = sapt.vt(\'ibab\')\nresult -= np.einsum(\'asib,As,Ab,iBaB->\', t_asib, s_as, s_ab, temp)\nresult -= np.einsum(\'asib,Is,Ib,iBaB->\', t_asib, s_is, s_ib, temp)\nresult += np.einsum(\'asib,As,AB,ibaB->\', t_asib, s_as, s_ab, temp)\nresult += np.einsum(\'asib,Is,IB,ibaB->\', t_asib, s_is, s_ib, temp)\ntemp = sapt.vt(\'ibaj\')\nresult += np.einsum(\'asib,As,AJ,ibaJ->\', t_asib, s_as, s_aj, temp)\nresult += np.einsum(\'asib,Is,IJ,ibaJ->\', t_asib, s_is, s_ij, temp)\ntemp = sapt.vt(\'ijaj\')\nresult -= 2 * np.einsum(\'asib,As,Ab,iJaJ->\', t_asib, s_as, s_ab, temp)\nresult -= 2 * np.einsum(\'asib,Is,Ib,iJaJ->\', t_asib, s_is, s_ib, temp)\ntemp = sapt.vt(\'ibas\')\nresult += np.einsum(\'asib,iJ,IJ,Ibas->\', t_asib, s_ij, s_ij, temp)\nresult += np.einsum(\'asib,AB,Ab,iBas->\', t_asib, s_ab, s_ab, temp)\nresult += np.einsum(\'asib,IB,Ib,iBas->\', t_asib, s_ib, s_ib, temp)\ntemp = sapt.vt(\'ijas\')\nresult += np.einsum(\'asib,AJ,Ab,iJas->\', t_asib, s_aj, s_ab, temp)\nresult += np.einsum(\'asib,IJ,Ib,iJas->\', t_asib, s_ij, s_ib, temp)\ntemp = sapt.vt(\'ibis\')\nresult -= 2 * np.einsum(\'asib,iJ,aJ,IbIs->\', t_asib, s_ij, s_aj, temp)\nresult += np.einsum(\'asib,IJ,aJ,ibIs->\', t_asib, s_ij, s_aj, temp)\ntemp = sapt.vt(\'abab\')\nresult += np.einsum(\'rsib,is,rB,AbAB->\', t_rsib, s_is, s_rb, temp)\ntemp = sapt.vt(\'ibab\')\nresult += np.einsum(\'rsib,As,rb,iBAB->\', t_rsib, s_as, s_rb, temp)\nresult -= np.einsum(\'rsib,As,rB,ibAB->\', t_rsib, s_as, s_rb, temp)\ntemp = sapt.vt(\'abaj\')\nresult += np.einsum(\'rsib,is,rJ,AbAJ->\', t_rsib, s_is, s_rj, temp)\ntemp = sapt.vt(\'ibaj\')\nresult -= np.einsum(\'rsib,As,rJ,ibAJ->\', t_rsib, s_as, s_rj, temp)\ntemp = sapt.vt(\'ijaj\')\nresult += 2 * np.einsum(\'rsib,As,rb,iJAJ->\', t_rsib, s_as, s_rb, temp)\ntemp = sapt.vt(\'abas\')\nresult += np.einsum(\'rsib,iB,rb,ABAs->\', t_rsib, s_ib, s_rb, temp)\nresult -= np.einsum(\'rsib,iB,rB,AbAs->\', t_rsib, s_ib, s_rb, temp)\nresult -= 2 * np.einsum(\'rsib,iJ,rJ,AbAs->\', t_rsib, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ajas\')\nresult += np.einsum(\'rsib,iJ,rb,AJAs->\', t_rsib, s_ij, s_rb, temp)\ntemp = sapt.vt(\'ibas\')\nresult -= np.einsum(\'rsib,AB,rb,iBAs->\', t_rsib, s_ab, s_rb, temp)\nresult += np.einsum(\'rsib,AB,rB,ibAs->\', t_rsib, s_ab, s_rb, temp)\nresult += np.einsum(\'rsib,AJ,rJ,ibAs->\', t_rsib, s_aj, s_rj, temp)\ntemp = sapt.vt(\'ijas\')\nresult -= np.einsum(\'rsib,AJ,rb,iJAs->\', t_rsib, s_aj, s_rb, temp)\ntemp = sapt.vt(\'ibib\')\nresult += 2 * np.einsum(\'rsib,is,rB,IbIB->\', t_rsib, s_is, s_rb, temp)\nresult += np.einsum(\'rsib,Is,rb,iBIB->\', t_rsib, s_is, s_rb, temp)\nresult -= np.einsum(\'rsib,Is,rB,ibIB->\', t_rsib, s_is, s_rb, temp)\ntemp = sapt.vt(\'ibij\')\nresult += 2 * np.einsum(\'rsib,is,rJ,IbIJ->\', t_rsib, s_is, s_rj, temp)\nresult -= np.einsum(\'rsib,Is,rJ,ibIJ->\', t_rsib, s_is, s_rj, temp)\ntemp = sapt.vt(\'ijij\')\nresult += 2 * np.einsum(\'rsib,Is,rb,iJIJ->\', t_rsib, s_is, s_rb, temp)\ntemp = sapt.vt(\'ibis\')\nresult += 2 * np.einsum(\'rsib,iB,rb,IBIs->\', t_rsib, s_ib, s_rb, temp)\nresult -= 2 * np.einsum(\'rsib,iB,rB,IbIs->\', t_rsib, s_ib, s_rb, temp)\nresult -= 4 * np.einsum(\'rsib,iJ,rJ,IbIs->\', t_rsib, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ijis\')\nresult += 2 * np.einsum(\'rsib,iJ,rb,IJIs->\', t_rsib, s_ij, s_rb, temp)\ntemp = sapt.vt(\'ibis\')\nresult -= np.einsum(\'rsib,IB,rb,iBIs->\', t_rsib, s_ib, s_rb, temp)\nresult += np.einsum(\'rsib,IB,rB,ibIs->\', t_rsib, s_ib, s_rb, temp)\nresult += 2 * np.einsum(\'rsib,IJ,rJ,ibIs->\', t_rsib, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ijis\')\nresult -= np.einsum(\'rsib,IJ,rb,iJIs->\', t_rsib, s_ij, s_rb, temp)\ntemp = sapt.vt(\'abrb\')\nresult += np.einsum(\'rsib,is,Ab,ABrB->\', t_rsib, s_is, s_ab, temp)\nresult -= np.einsum(\'rsib,is,AB,AbrB->\', t_rsib, s_is, s_ab, temp)\ntemp = sapt.vt(\'ibrb\')\nresult += np.einsum(\'rsib,is,Ib,IBrB->\', t_rsib, s_is, s_ib, temp)\nresult -= np.einsum(\'rsib,is,IB,IbrB->\', t_rsib, s_is, s_ib, temp)\nresult -= 2 * np.einsum(\'rsib,As,Ab,iBrB->\', t_rsib, s_as, s_ab, temp)\nresult -= 2 * np.einsum(\'rsib,Is,Ib,iBrB->\', t_rsib, s_is, s_ib, temp)\nresult += 2 * np.einsum(\'rsib,As,AB,ibrB->\', t_rsib, s_as, s_ab, temp)\nresult += 2 * np.einsum(\'rsib,Is,IB,ibrB->\', t_rsib, s_is, s_ib, temp)\ntemp = sapt.vt(\'abrj\')\nresult -= np.einsum(\'rsib,is,AJ,AbrJ->\', t_rsib, s_is, s_aj, temp)\ntemp = sapt.vt(\'ajrj\')\nresult += 2 * np.einsum(\'rsib,is,Ab,AJrJ->\', t_rsib, s_is, s_ab, temp)\ntemp = sapt.vt(\'ibrj\')\nresult -= np.einsum(\'rsib,is,IJ,IbrJ->\', t_rsib, s_is, s_ij, temp)\ntemp = sapt.vt(\'ijrj\')\nresult += 2 * np.einsum(\'rsib,is,Ib,IJrJ->\', t_rsib, s_is, s_ib, temp)\ntemp = sapt.vt(\'ibrj\')\nresult += 2 * np.einsum(\'rsib,As,AJ,ibrJ->\', t_rsib, s_as, s_aj, temp)\nresult += 2 * np.einsum(\'rsib,Is,IJ,ibrJ->\', t_rsib, s_is, s_ij, temp)\ntemp = sapt.vt(\'ijrj\')\nresult -= 4 * np.einsum(\'rsib,As,Ab,iJrJ->\', t_rsib, s_as, s_ab, temp)\nresult -= 4 * np.einsum(\'rsib,Is,Ib,iJrJ->\', t_rsib, s_is, s_ib, temp)\ntemp = sapt.vt(\'abrs\')\nresult -= np.einsum(\'rsib,iB,Ab,ABrs->\', t_rsib, s_ib, s_ab, temp)\nresult += np.einsum(\'rsib,iB,AB,Abrs->\', t_rsib, s_ib, s_ab, temp)\nresult += np.einsum(\'rsib,iJ,AJ,Abrs->\', t_rsib, s_ij, s_aj, temp)\ntemp = sapt.vt(\'ajrs\')\nresult -= np.einsum(\'rsib,iJ,Ab,AJrs->\', t_rsib, s_ij, s_ab, temp)\ntemp = sapt.vt(\'ibrs\')\nresult -= np.einsum(\'rsib,iB,Ib,IBrs->\', t_rsib, s_ib, s_ib, temp)\nresult += np.einsum(\'rsib,iB,IB,Ibrs->\', t_rsib, s_ib, s_ib, temp)\nresult += 2 * np.einsum(\'rsib,iJ,IJ,Ibrs->\', t_rsib, s_ij, s_ij, temp)\ntemp = sapt.vt(\'ijrs\')\nresult -= np.einsum(\'rsib,iJ,Ib,IJrs->\', t_rsib, s_ij, s_ib, temp)\ntemp = sapt.vt(\'ibrs\')\nresult += 2 * np.einsum(\'rsib,AB,Ab,iBrs->\', t_rsib, s_ab, s_ab, temp)\nresult += 2 * np.einsum(\'rsib,IB,Ib,iBrs->\', t_rsib, s_ib, s_ib, temp)\ntemp = sapt.vt(\'ijrs\')\nresult += 2 * np.einsum(\'rsib,AJ,Ab,iJrs->\', t_rsib, s_aj, s_ab, temp)\nresult += 2 * np.einsum(\'rsib,IJ,Ib,iJrs->\', t_rsib, s_ij, s_ib, temp)\ntemp = sapt.vt(\'ajab\')\nresult += np.einsum(\'abij,iJ,aj,AJAb->\', t_abij, s_ij, s_aj, temp)\nresult -= np.einsum(\'abij,iJ,aJ,AjAb->\', t_abij, s_ij, s_aj, temp)\ntemp = sapt.vt(\'ajaj\')\nresult += np.einsum(\'abij,ib,aJ,AjAJ->\', t_abij, s_ib, s_aj, temp)\ntemp = sapt.vt(\'ibab\')\nresult += np.einsum(\'abij,ib,Ij,IBaB->\', t_abij, s_ib, s_ij, temp)\nresult -= np.einsum(\'abij,Ib,Ij,iBaB->\', t_abij, s_ib, s_ij, temp)\ntemp = sapt.vt(\'ijab\')\nresult -= np.einsum(\'abij,iJ,Ij,IJab->\', t_abij, s_ij, s_ij, temp)\nresult += np.einsum(\'abij,iJ,IJ,Ijab->\', t_abij, s_ij, s_ij, temp)\nresult += np.einsum(\'abij,IJ,Ij,iJab->\', t_abij, s_ij, s_ij, temp)\ntemp = sapt.vt(\'ijaj\')\nresult += 2 * np.einsum(\'abij,ib,Ij,IJaJ->\', t_abij, s_ib, s_ij, temp)\nresult -= np.einsum(\'abij,ib,IJ,IjaJ->\', t_abij, s_ib, s_ij, temp)\nresult -= 2 * np.einsum(\'abij,Ib,Ij,iJaJ->\', t_abij, s_ib, s_ij, temp)\nresult += np.einsum(\'abij,Ib,IJ,ijaJ->\', t_abij, s_ib, s_ij, temp)\ntemp = sapt.vt(\'ibib\')\nresult += np.einsum(\'abij,Ib,aj,iBIB->\', t_abij, s_ib, s_aj, temp)\ntemp = sapt.vt(\'ijib\')\nresult += 2 * np.einsum(\'abij,iJ,aj,IJIb->\', t_abij, s_ij, s_aj, temp)\nresult -= 2 * np.einsum(\'abij,iJ,aJ,IjIb->\', t_abij, s_ij, s_aj, temp)\nresult -= np.einsum(\'abij,IJ,aj,iJIb->\', t_abij, s_ij, s_aj, temp)\nresult += np.einsum(\'abij,IJ,aJ,ijIb->\', t_abij, s_ij, s_aj, temp)\ntemp = sapt.vt(\'ijij\')\nresult += 2 * np.einsum(\'abij,ib,aJ,IjIJ->\', t_abij, s_ib, s_aj, temp)\nresult += 2 * np.einsum(\'abij,Ib,aj,iJIJ->\', t_abij, s_ib, s_aj, temp)\nresult -= np.einsum(\'abij,Ib,aJ,ijIJ->\', t_abij, s_ib, s_aj, temp)\ntemp = sapt.vt(\'ajaj\')\nresult += np.einsum(\'asij,is,aJ,AjAJ->\', t_asij, s_is, s_aj, temp)\ntemp = sapt.vt(\'ajas\')\nresult += np.einsum(\'asij,iJ,aj,AJAs->\', t_asij, s_ij, s_aj, temp)\nresult -= 2 * np.einsum(\'asij,iJ,aJ,AjAs->\', t_asij, s_ij, s_aj, temp)\ntemp = sapt.vt(\'ibab\')\nresult += np.einsum(\'asij,is,Ij,IBaB->\', t_asij, s_is, s_ij, temp)\nresult -= np.einsum(\'asij,As,Aj,iBaB->\', t_asij, s_as, s_aj, temp)\nresult -= 2 * np.einsum(\'asij,Is,Ij,iBaB->\', t_asij, s_is, s_ij, temp)\ntemp = sapt.vt(\'ijab\')\nresult += np.einsum(\'asij,As,AB,ijaB->\', t_asij, s_as, s_ab, temp)\nresult += np.einsum(\'asij,Is,IB,ijaB->\', t_asij, s_is, s_ib, temp)\ntemp = sapt.vt(\'ijaj\')\nresult += 2 * np.einsum(\'asij,is,Ij,IJaJ->\', t_asij, s_is, s_ij, temp)\nresult -= np.einsum(\'asij,is,IJ,IjaJ->\', t_asij, s_is, s_ij, temp)\nresult -= 2 * np.einsum(\'asij,As,Aj,iJaJ->\', t_asij, s_as, s_aj, temp)\nresult -= 4 * np.einsum(\'asij,Is,Ij,iJaJ->\', t_asij, s_is, s_ij, temp)\nresult += np.einsum(\'asij,As,AJ,ijaJ->\', t_asij, s_as, s_aj, temp)\nresult += 2 * np.einsum(\'asij,Is,IJ,ijaJ->\', t_asij, s_is, s_ij, temp)\ntemp = sapt.vt(\'ijas\')\nresult -= np.einsum(\'asij,iJ,Ij,IJas->\', t_asij, s_ij, s_ij, temp)\nresult += 2 * np.einsum(\'asij,iJ,IJ,Ijas->\', t_asij, s_ij, s_ij, temp)\ntemp = sapt.vt(\'ibas\')\nresult += np.einsum(\'asij,AB,Aj,iBas->\', t_asij, s_ab, s_aj, temp)\nresult += np.einsum(\'asij,IB,Ij,iBas->\', t_asij, s_ib, s_ij, temp)\ntemp = sapt.vt(\'ijas\')\nresult += np.einsum(\'asij,AJ,Aj,iJas->\', t_asij, s_aj, s_aj, temp)\nresult += 2 * np.einsum(\'asij,IJ,Ij,iJas->\', t_asij, s_ij, s_ij, temp)\ntemp = sapt.vt(\'ibib\')\nresult += np.einsum(\'asij,Is,aj,iBIB->\', t_asij, s_is, s_aj, temp)\ntemp = sapt.vt(\'ijij\')\nresult += 2 * np.einsum(\'asij,is,aJ,IjIJ->\', t_asij, s_is, s_aj, temp)\nresult += 2 * np.einsum(\'asij,Is,aj,iJIJ->\', t_asij, s_is, s_aj, temp)\nresult -= np.einsum(\'asij,Is,aJ,ijIJ->\', t_asij, s_is, s_aj, temp)\ntemp = sapt.vt(\'ijis\')\nresult += 2 * np.einsum(\'asij,iJ,aj,IJIs->\', t_asij, s_ij, s_aj, temp)\nresult -= 4 * np.einsum(\'asij,iJ,aJ,IjIs->\', t_asij, s_ij, s_aj, temp)\nresult -= np.einsum(\'asij,IJ,aj,iJIs->\', t_asij, s_ij, s_aj, temp)\nresult += 2 * np.einsum(\'asij,IJ,aJ,ijIs->\', t_asij, s_ij, s_aj, temp)\ntemp = sapt.vt(\'ajab\')\nresult += np.einsum(\'rbij,iJ,rj,AJAb->\', t_rbij, s_ij, s_rj, temp)\nresult -= np.einsum(\'rbij,iB,rB,AjAb->\', t_rbij, s_ib, s_rb, temp)\nresult -= 2 * np.einsum(\'rbij,iJ,rJ,AjAb->\', t_rbij, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ijab\')\nresult += np.einsum(\'rbij,AB,rB,ijAb->\', t_rbij, s_ab, s_rb, temp)\nresult += np.einsum(\'rbij,AJ,rJ,ijAb->\', t_rbij, s_aj, s_rj, temp)\ntemp = sapt.vt(\'ajaj\')\nresult += np.einsum(\'rbij,ib,rJ,AjAJ->\', t_rbij, s_ib, s_rj, temp)\ntemp = sapt.vt(\'ibib\')\nresult += np.einsum(\'rbij,Ib,rj,iBIB->\', t_rbij, s_ib, s_rj, temp)\ntemp = sapt.vt(\'ijib\')\nresult += 2 * np.einsum(\'rbij,iJ,rj,IJIb->\', t_rbij, s_ij, s_rj, temp)\nresult -= 2 * np.einsum(\'rbij,iB,rB,IjIb->\', t_rbij, s_ib, s_rb, temp)\nresult -= 4 * np.einsum(\'rbij,iJ,rJ,IjIb->\', t_rbij, s_ij, s_rj, temp)\nresult -= np.einsum(\'rbij,IJ,rj,iJIb->\', t_rbij, s_ij, s_rj, temp)\nresult += np.einsum(\'rbij,IB,rB,ijIb->\', t_rbij, s_ib, s_rb, temp)\nresult += 2 * np.einsum(\'rbij,IJ,rJ,ijIb->\', t_rbij, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ijij\')\nresult += 2 * np.einsum(\'rbij,ib,rJ,IjIJ->\', t_rbij, s_ib, s_rj, temp)\nresult += 2 * np.einsum(\'rbij,Ib,rj,iJIJ->\', t_rbij, s_ib, s_rj, temp)\nresult -= np.einsum(\'rbij,Ib,rJ,ijIJ->\', t_rbij, s_ib, s_rj, temp)\ntemp = sapt.vt(\'ibrb\')\nresult += np.einsum(\'rbij,ib,Ij,IBrB->\', t_rbij, s_ib, s_ij, temp)\nresult -= 2 * np.einsum(\'rbij,Ib,Ij,iBrB->\', t_rbij, s_ib, s_ij, temp)\ntemp = sapt.vt(\'ajrb\')\nresult += np.einsum(\'rbij,iB,AB,Ajrb->\', t_rbij, s_ib, s_ab, temp)\nresult += np.einsum(\'rbij,iJ,AJ,Ajrb->\', t_rbij, s_ij, s_aj, temp)\ntemp = sapt.vt(\'ijrb\')\nresult -= np.einsum(\'rbij,iJ,Ij,IJrb->\', t_rbij, s_ij, s_ij, temp)\nresult += np.einsum(\'rbij,iB,IB,Ijrb->\', t_rbij, s_ib, s_ib, temp)\nresult += 2 * np.einsum(\'rbij,iJ,IJ,Ijrb->\', t_rbij, s_ij, s_ij, temp)\nresult += 2 * np.einsum(\'rbij,IJ,Ij,iJrb->\', t_rbij, s_ij, s_ij, temp)\ntemp = sapt.vt(\'ijrj\')\nresult += 2 * np.einsum(\'rbij,ib,Ij,IJrJ->\', t_rbij, s_ib, s_ij, temp)\nresult -= np.einsum(\'rbij,ib,IJ,IjrJ->\', t_rbij, s_ib, s_ij, temp)\nresult -= 4 * np.einsum(\'rbij,Ib,Ij,iJrJ->\', t_rbij, s_ib, s_ij, temp)\nresult += 2 * np.einsum(\'rbij,Ib,IJ,ijrJ->\', t_rbij, s_ib, s_ij, temp)\ntemp = sapt.vt(\'ajab\')\nresult += np.einsum(\'rsij,is,rB,AjAB->\', t_rsij, s_is, s_rb, temp)\ntemp = sapt.vt(\'ibab\')\nresult += np.einsum(\'rsij,As,rj,iBAB->\', t_rsij, s_as, s_rj, temp)\ntemp = sapt.vt(\'ijab\')\nresult -= np.einsum(\'rsij,As,rB,ijAB->\', t_rsij, s_as, s_rb, temp)\ntemp = sapt.vt(\'ajaj\')\nresult += 2 * np.einsum(\'rsij,is,rJ,AjAJ->\', t_rsij, s_is, s_rj, temp)\ntemp = sapt.vt(\'ijaj\')\nresult += 2 * np.einsum(\'rsij,As,rj,iJAJ->\', t_rsij, s_as, s_rj, temp)\nresult -= np.einsum(\'rsij,As,rJ,ijAJ->\', t_rsij, s_as, s_rj, temp)\ntemp = sapt.vt(\'abas\')\nresult += np.einsum(\'rsij,iB,rj,ABAs->\', t_rsij, s_ib, s_rj, temp)\ntemp = sapt.vt(\'ajas\')\nresult += 2 * np.einsum(\'rsij,iJ,rj,AJAs->\', t_rsij, s_ij, s_rj, temp)\nresult -= 2 * np.einsum(\'rsij,iB,rB,AjAs->\', t_rsij, s_ib, s_rb, temp)\nresult -= 4 * np.einsum(\'rsij,iJ,rJ,AjAs->\', t_rsij, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ibas\')\nresult -= np.einsum(\'rsij,AB,rj,iBAs->\', t_rsij, s_ab, s_rj, temp)\ntemp = sapt.vt(\'ijas\')\nresult -= np.einsum(\'rsij,AJ,rj,iJAs->\', t_rsij, s_aj, s_rj, temp)\nresult += 2 * np.einsum(\'rsij,AB,rB,ijAs->\', t_rsij, s_ab, s_rb, temp)\nresult += 2 * np.einsum(\'rsij,AJ,rJ,ijAs->\', t_rsij, s_aj, s_rj, temp)\ntemp = sapt.vt(\'ijib\')\nresult += 2 * np.einsum(\'rsij,is,rB,IjIB->\', t_rsij, s_is, s_rb, temp)\ntemp = sapt.vt(\'ibib\')\nresult += 2 * np.einsum(\'rsij,Is,rj,iBIB->\', t_rsij, s_is, s_rj, temp)\ntemp = sapt.vt(\'ijib\')\nresult -= np.einsum(\'rsij,Is,rB,ijIB->\', t_rsij, s_is, s_rb, temp)\ntemp = sapt.vt(\'ijij\')\nresult += 4 * np.einsum(\'rsij,is,rJ,IjIJ->\', t_rsij, s_is, s_rj, temp)\nresult += 4 * np.einsum(\'rsij,Is,rj,iJIJ->\', t_rsij, s_is, s_rj, temp)\nresult -= 2 * np.einsum(\'rsij,Is,rJ,ijIJ->\', t_rsij, s_is, s_rj, temp)\ntemp = sapt.vt(\'ibis\')\nresult += 2 * np.einsum(\'rsij,iB,rj,IBIs->\', t_rsij, s_ib, s_rj, temp)\ntemp = sapt.vt(\'ijis\')\nresult += 4 * np.einsum(\'rsij,iJ,rj,IJIs->\', t_rsij, s_ij, s_rj, temp)\nresult -= 4 * np.einsum(\'rsij,iB,rB,IjIs->\', t_rsij, s_ib, s_rb, temp)\nresult -= 8 * np.einsum(\'rsij,iJ,rJ,IjIs->\', t_rsij, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ibis\')\nresult -= np.einsum(\'rsij,IB,rj,iBIs->\', t_rsij, s_ib, s_rj, temp)\ntemp = sapt.vt(\'ijis\')\nresult -= 2 * np.einsum(\'rsij,IJ,rj,iJIs->\', t_rsij, s_ij, s_rj, temp)\nresult += 2 * np.einsum(\'rsij,IB,rB,ijIs->\', t_rsij, s_ib, s_rb, temp)\nresult += 4 * np.einsum(\'rsij,IJ,rJ,ijIs->\', t_rsij, s_ij, s_rj, temp)\ntemp = sapt.vt(\'abrb\')\nresult += np.einsum(\'rsij,is,Aj,ABrB->\', t_rsij, s_is, s_aj, temp)\ntemp = sapt.vt(\'ajrb\')\nresult -= np.einsum(\'rsij,is,AB,AjrB->\', t_rsij, s_is, s_ab, temp)\ntemp = sapt.vt(\'ibrb\')\nresult += 2 * np.einsum(\'rsij,is,Ij,IBrB->\', t_rsij, s_is, s_ij, temp)\ntemp = sapt.vt(\'ijrb\')\nresult -= np.einsum(\'rsij,is,IB,IjrB->\', t_rsij, s_is, s_ib, temp)\ntemp = sapt.vt(\'ibrb\')\nresult -= 2 * np.einsum(\'rsij,As,Aj,iBrB->\', t_rsij, s_as, s_aj, temp)\nresult -= 4 * np.einsum(\'rsij,Is,Ij,iBrB->\', t_rsij, s_is, s_ij, temp)\ntemp = sapt.vt(\'ijrb\')\nresult += 2 * np.einsum(\'rsij,As,AB,ijrB->\', t_rsij, s_as, s_ab, temp)\nresult += 2 * np.einsum(\'rsij,Is,IB,ijrB->\', t_rsij, s_is, s_ib, temp)\ntemp = sapt.vt(\'ajrj\')\nresult += 2 * np.einsum(\'rsij,is,Aj,AJrJ->\', t_rsij, s_is, s_aj, temp)\nresult -= np.einsum(\'rsij,is,AJ,AjrJ->\', t_rsij, s_is, s_aj, temp)\ntemp = sapt.vt(\'ijrj\')\nresult += 4 * np.einsum(\'rsij,is,Ij,IJrJ->\', t_rsij, s_is, s_ij, temp)\nresult -= 2 * np.einsum(\'rsij,is,IJ,IjrJ->\', t_rsij, s_is, s_ij, temp)\nresult -= 4 * np.einsum(\'rsij,As,Aj,iJrJ->\', t_rsij, s_as, s_aj, temp)\nresult -= 8 * np.einsum(\'rsij,Is,Ij,iJrJ->\', t_rsij, s_is, s_ij, temp)\nresult += 2 * np.einsum(\'rsij,As,AJ,ijrJ->\', t_rsij, s_as, s_aj, temp)\nresult += 4 * np.einsum(\'rsij,Is,IJ,ijrJ->\', t_rsij, s_is, s_ij, temp)\ntemp = sapt.vt(\'abrs\')\nresult -= np.einsum(\'rsij,iB,Aj,ABrs->\', t_rsij, s_ib, s_aj, temp)\ntemp = sapt.vt(\'ajrs\')\nresult -= np.einsum(\'rsij,iJ,Aj,AJrs->\', t_rsij, s_ij, s_aj, temp)\nresult += 2 * np.einsum(\'rsij,iB,AB,Ajrs->\', t_rsij, s_ib, s_ab, temp)\nresult += 2 * np.einsum(\'rsij,iJ,AJ,Ajrs->\', t_rsij, s_ij, s_aj, temp)\ntemp = sapt.vt(\'ibrs\')\nresult -= np.einsum(\'rsij,iB,Ij,IBrs->\', t_rsij, s_ib, s_ij, temp)\ntemp = sapt.vt(\'ijrs\')\nresult -= 2 * np.einsum(\'rsij,iJ,Ij,IJrs->\', t_rsij, s_ij, s_ij, temp)\nresult += 2 * np.einsum(\'rsij,iB,IB,Ijrs->\', t_rsij, s_ib, s_ib, temp)\nresult += 4 * np.einsum(\'rsij,iJ,IJ,Ijrs->\', t_rsij, s_ij, s_ij, temp)\ntemp = sapt.vt(\'ibrs\')\nresult += 2 * np.einsum(\'rsij,AB,Aj,iBrs->\', t_rsij, s_ab, s_aj, temp)\nresult += 2 * np.einsum(\'rsij,IB,Ij,iBrs->\', t_rsij, s_ib, s_ij, temp)\ntemp = sapt.vt(\'ijrs\')\nresult += 2 * np.einsum(\'rsij,AJ,Aj,iJrs->\', t_rsij, s_aj, s_aj, temp)\nresult += 4 * np.einsum(\'rsij,IJ,Ij,iJrs->\', t_rsij, s_ij, s_ij, temp)\n#end autogenerated stuff\n\nExchDisp20 = result\ndisp_timer.stop()\n### End E200 Exchange-Dispersion\n\n### Start E200 Induction and Exchange-Induction\n#in this variant, no CPHF response will be calculated\n\n# E200Induction and CPHF orbitals\nind_timer = sapt_timer(\'induction\')\n\nomb_ir = 2 * np.einsum(\'ijrj->ir\', sapt.vt(\'ijrj\')) + np.einsum(\'ibrb->ir\', sapt.vt(\'ibrb\'))\nomb_ia = 2 * np.einsum(\'ijaj->ia\', sapt.vt(\'ijaj\')) + np.einsum(\'ibab->ia\', sapt.vt(\'ibab\'))\nomb_ar = 2 * np.einsum(\'ajrj->ar\', sapt.vt(\'ajrj\')) + np.einsum(\'abrb->ar\', sapt.vt(\'abrb\'))\noma_js = 2 * np.einsum(\'ijis->js\', sapt.vt(\'ijis\')) + np.einsum(\'ajas->js\', sapt.vt(\'ajas\'))\noma_jb = 2 * np.einsum(\'ijib->jb\', sapt.vt(\'ijib\')) + np.einsum(\'ajab->jb\', sapt.vt(\'ajab\'))\noma_bs = 2 * np.einsum(\'ibis->bs\', sapt.vt(\'ibis\')) + np.einsum(\'abas->bs\', sapt.vt(\'abas\'))\ne_ir = 1 / (sapt.eps(\'i\', dim=2) - sapt.eps(\'r\'))\ne_ia = 1 / (sapt.eps(\'i\', dim=2) - sapt.eps(\'a\'))\ne_ar = 1 / (sapt.eps(\'a\', dim=2) - sapt.eps(\'r\'))\ne_js = 1 / (sapt.eps(\'j\', dim=2) - sapt.eps(\'s\'))\ne_jb = 1 / (sapt.eps(\'j\', dim=2) - sapt.eps(\'b\'))\ne_bs = 1 / (sapt.eps(\'b\', dim=2) - sapt.eps(\'s\'))\nind_ir = np.einsum(\'ir,ir->ir\', omb_ir, e_ir)\nind_ia = np.einsum(\'ia,ia->ia\', omb_ia, e_ia)\nind_ar = np.einsum(\'ar,ar->ar\', omb_ar, e_ar)\nind_js = np.einsum(\'js,js->js\', oma_js, e_js)\nind_jb = np.einsum(\'jb,jb->jb\', oma_jb, e_jb)\nind_bs = np.einsum(\'bs,bs->bs\', oma_bs, e_bs)\n\nInd20_ab = 2 * np.einsum(\'ir,ir->\', omb_ir, ind_ir)\nInd20_ab += np.einsum(\'ia,ia->\', omb_ia, ind_ia)\nInd20_ab += np.einsum(\'ar,ar->\', omb_ar, ind_ar)\nInd20_ba = 2 * np.einsum(\'js,js->\', oma_js, ind_js)\nInd20_ba += np.einsum(\'jb,jb->\', oma_jb, ind_jb)\nInd20_ba += np.einsum(\'bs,bs->\', oma_bs, ind_bs)\n\nInd20r = Ind20_ba + Ind20_ab\n\n# Exchange-Induction\n\n# A <- B\nresult = 0.0\n#automatically programmed stuff below\ntemp = sapt.vt(\'abbr\')\nresult -= np.einsum(\'ar,abbr->\', ind_ar, temp)\ntemp = sapt.vt(\'ajjr\')\nresult -= np.einsum(\'ar,ajjr->\', ind_ar, temp)\ntemp = sapt.vt(\'ijja\')\nresult -= np.einsum(\'ia,ijja->\', ind_ia, temp)\ntemp = sapt.vt(\'ibbr\')\nresult -= np.einsum(\'ir,ibbr->\', ind_ir, temp)\ntemp = sapt.vt(\'ijjr\')\nresult -= 2 * np.einsum(\'ir,ijjr->\', ind_ir, temp)\ntemp = sapt.vt(\'abar\')\nresult += np.einsum(\'ar,Ab,abAr->\', ind_ar, s_ab, temp)\nresult -= np.einsum(\'ar,ab,AbAr->\', ind_ar, s_ab, temp)\nresult -= np.einsum(\'ir,ib,AbAr->\', ind_ir, s_ib, temp)\ntemp = sapt.vt(\'abra\')\nresult -= np.einsum(\'ar,Ab,abrA->\', ind_ar, s_ab, temp)\nresult += np.einsum(\'ar,ab,AbrA->\', ind_ar, s_ab, temp)\nresult += np.einsum(\'ir,ib,AbrA->\', ind_ir, s_ib, temp)\ntemp = sapt.vt(\'ibir\')\nresult -= 2 * np.einsum(\'ar,ab,IbIr->\', ind_ar, s_ab, temp)\nresult += np.einsum(\'ir,Ib,ibIr->\', ind_ir, s_ib, temp)\nresult -= 2 * np.einsum(\'ir,ib,IbIr->\', ind_ir, s_ib, temp)\ntemp = sapt.vt(\'ibri\')\nresult += np.einsum(\'ir,ib,IbrI->\', ind_ir, s_ib, temp)\nresult += np.einsum(\'ar,ab,IbrI->\', ind_ar, s_ab, temp)\nresult -= 2 * np.einsum(\'ir,Ib,ibrI->\', ind_ir, s_ib, temp)\ntemp = sapt.vt(\'abir\')\nresult += np.einsum(\'ar,Ib,abIr->\', ind_ar, s_ib, temp)\ntemp = sapt.vt(\'abri\')\nresult -= np.einsum(\'ar,Ib,abrI->\', ind_ar, s_ib, temp)\ntemp = sapt.vt(\'ibar\')\nresult += np.einsum(\'ir,Ab,ibAr->\', ind_ir, s_ab, temp)\ntemp = sapt.vt(\'ibra\')\nresult -= 2 * np.einsum(\'ir,Ab,ibrA->\', ind_ir, s_ab, temp)\ntemp = sapt.vt(\'ajar\')\nresult += np.einsum(\'ar,Aj,ajAr->\', ind_ar, s_aj, temp)\nresult -= np.einsum(\'ar,aj,AjAr->\', ind_ar, s_aj, temp)\nresult -= 2 * np.einsum(\'ir,ij,AjAr->\', ind_ir, s_ij, temp)\ntemp = sapt.vt(\'ajra\')\nresult -= np.einsum(\'ar,Aj,ajrA->\', ind_ar, s_aj, temp)\nresult += np.einsum(\'ar,aj,AjrA->\', ind_ar, s_aj, temp)\nresult += np.einsum(\'ir,ij,AjrA->\', ind_ir, s_ij, temp)\ntemp = sapt.vt(\'ijir\')\nresult -= 2 * np.einsum(\'ar,aj,IjIr->\', ind_ar, s_aj, temp)\nresult += 2 * np.einsum(\'ir,Ij,ijIr->\', ind_ir, s_ij, temp)\nresult -= 4 * np.einsum(\'ir,ij,IjIr->\', ind_ir, s_ij, temp)\ntemp = sapt.vt(\'ijri\')\nresult += np.einsum(\'ar,aj,IjrI->\', ind_ar, s_aj, temp)\nresult += 2 * np.einsum(\'ir,ij,IjrI->\', ind_ir, s_ij, temp)\nresult -= 4 * np.einsum(\'ir,Ij,ijrI->\', ind_ir, s_ij, temp)\ntemp = sapt.vt(\'ajir\')\nresult += np.einsum(\'ar,Ij,ajIr->\', ind_ar, s_ij, temp)\ntemp = sapt.vt(\'ajri\')\nresult -= 2 * np.einsum(\'ar,Ij,ajrI->\', ind_ar, s_ij, temp)\ntemp = sapt.vt(\'abbb\')\nresult -= np.einsum(\'ar,rB,abBb->\', ind_ar, s_rb, temp)\nresult += np.einsum(\'ar,rb,aBBb->\', ind_ar, s_rb, temp)\ntemp = sapt.vt(\'ibbb\')\nresult -= np.einsum(\'ir,rB,ibBb->\', ind_ir, s_rb, temp)\nresult += np.einsum(\'ir,rb,iBBb->\', ind_ir, s_rb, temp)\ntemp = sapt.vt(\'ajbj\')\nresult -= 2 * np.einsum(\'ar,rB,ajBj->\', ind_ar, s_rb, temp)\ntemp = sapt.vt(\'ajjb\')\nresult += np.einsum(\'ar,rb,aJJb->\', ind_ar, s_rb, temp)\ntemp = sapt.vt(\'abjb\')\nresult -= np.einsum(\'ar,rJ,abJb->\', ind_ar, s_rj, temp)\ntemp = sapt.vt(\'ajjj\')\nresult -= 2 * np.einsum(\'ar,rJ,ajJj->\', ind_ar, s_rj, temp)\ntemp = sapt.vt(\'abbj\')\nresult += np.einsum(\'ar,rj,aBBj->\', ind_ar, s_rj, temp)\ntemp = sapt.vt(\'ajjj\')\nresult += np.einsum(\'ar,rj,aJJj->\', ind_ar, s_rj, temp)\ntemp = sapt.vt(\'ibjb\')\nresult -= np.einsum(\'ia,aJ,ibJb->\', ind_ia, s_aj, temp)\nresult -= 2 * np.einsum(\'ir,rJ,ibJb->\', ind_ir, s_rj, temp)\ntemp = sapt.vt(\'ijjj\')\nresult -= 2 * np.einsum(\'ia,aJ,ijJj->\', ind_ia, s_aj, temp)\nresult += np.einsum(\'ia,aj,iJJj->\', ind_ia, s_aj, temp)\nresult -= 4 * np.einsum(\'ir,rJ,ijJj->\', ind_ir, s_rj, temp)\nresult += 2 * np.einsum(\'ir,rj,iJJj->\', ind_ir, s_rj, temp)\ntemp = sapt.vt(\'ibaa\')\nresult -= np.einsum(\'ia,Ab,ibaA->\', ind_ia, s_ab, temp)\ntemp = sapt.vt(\'ibai\')\nresult -= np.einsum(\'ia,Ib,ibaI->\', ind_ia, s_ib, temp)\ntemp = sapt.vt(\'ijaa\')\nresult -= np.einsum(\'ia,Aj,ijaA->\', ind_ia, s_aj, temp)\ntemp = sapt.vt(\'ijai\')\nresult -= 2 * np.einsum(\'ia,Ij,ijaI->\', ind_ia, s_ij, temp)\nresult += np.einsum(\'ia,ij,IjaI->\', ind_ia, s_ij, temp)\ntemp = sapt.vt(\'ijia\')\nresult += np.einsum(\'ia,Ij,ijIa->\', ind_ia, s_ij, temp)\nresult -= 2 * np.einsum(\'ia,ij,IjIa->\', ind_ia, s_ij, temp)\ntemp = sapt.vt(\'ajaa\')\nresult -= np.einsum(\'ia,ij,AjAa->\', ind_ia, s_ij, temp)\ntemp = sapt.vt(\'ijar\')\nresult += np.einsum(\'ir,Aj,ijAr->\', ind_ir, s_aj, temp)\ntemp = sapt.vt(\'ijra\')\nresult -= 2 * np.einsum(\'ir,Aj,ijrA->\', ind_ir, s_aj, temp)\ntemp = sapt.vt(\'ijbj\')\nresult -= 2 * np.einsum(\'ir,rB,ijBj->\', ind_ir, s_rb, temp)\ntemp = sapt.vt(\'ijjb\')\nresult += np.einsum(\'ir,rb,iJJb->\', ind_ir, s_rb, temp)\ntemp = sapt.vt(\'ibbj\')\nresult += np.einsum(\'ir,rj,iBBj->\', ind_ir, s_rj, temp)\ntemp = sapt.vt(\'abrb\')\nresult += np.einsum(\'ar,AB,Ab,aBrb->\', ind_ar, s_ab, s_ab, temp)\nresult += np.einsum(\'ar,aB,AB,Abrb->\', ind_ar, s_ab, s_ab, temp)\nresult -= np.einsum(\'ar,aB,Ab,ABrb->\', ind_ar, s_ab, s_ab, temp)\nresult += np.einsum(\'ar,IB,Ib,aBrb->\', ind_ar, s_ib, s_ib, temp)\nresult += np.einsum(\'ar,aJ,AJ,Abrb->\', ind_ar, s_aj, s_aj, temp)\nresult += np.einsum(\'ir,iB,AB,Abrb->\', ind_ir, s_ib, s_ab, temp)\nresult -= np.einsum(\'ir,iB,Ab,ABrb->\', ind_ir, s_ib, s_ab, temp)\nresult += np.einsum(\'ir,iJ,AJ,Abrb->\', ind_ir, s_ij, s_aj, temp)\ntemp = sapt.vt(\'abrj\')\nresult -= np.einsum(\'ir,iB,Aj,ABrj->\', ind_ir, s_ib, s_aj, temp)\nresult += np.einsum(\'ar,AB,Aj,aBrj->\', ind_ar, s_ab, s_aj, temp)\nresult -= np.einsum(\'ar,aB,Aj,ABrj->\', ind_ar, s_ab, s_aj, temp)\nresult += np.einsum(\'ar,IB,Ij,aBrj->\', ind_ar, s_ib, s_ij, temp)\ntemp = sapt.vt(\'abab\')\nresult += np.einsum(\'ar,AB,rB,abAb->\', ind_ar, s_ab, s_rb, temp)\nresult += np.einsum(\'ar,aB,rb,ABAb->\', ind_ar, s_ab, s_rb, temp)\nresult -= np.einsum(\'ar,AB,rb,aBAb->\', ind_ar, s_ab, s_rb, temp)\nresult += np.einsum(\'ar,AJ,rJ,abAb->\', ind_ar, s_aj, s_rj, temp)\nresult += np.einsum(\'ir,iB,rb,ABAb->\', ind_ir, s_ib, s_rb, temp)\ntemp = sapt.vt(\'abaj\')\nresult += np.einsum(\'ir,iB,rj,ABAj->\', ind_ir, s_ib, s_rj, temp)\nresult -= np.einsum(\'ar,AB,rj,aBAj->\', ind_ar, s_ab, s_rj, temp)\nresult += np.einsum(\'ar,aB,rj,ABAj->\', ind_ar, s_ab, s_rj, temp)\ntemp = sapt.vt(\'abib\')\nresult += np.einsum(\'ar,IB,rB,abIb->\', ind_ar, s_ib, s_rb, temp)\nresult -= np.einsum(\'ar,IB,rb,aBIb->\', ind_ar, s_ib, s_rb, temp)\nresult += np.einsum(\'ar,IJ,rJ,abIb->\', ind_ar, s_ij, s_rj, temp)\ntemp = sapt.vt(\'abij\')\nresult -= np.einsum(\'ar,IB,rj,aBIj->\', ind_ar, s_ib, s_rj, temp)\ntemp = sapt.vt(\'ajij\')\nresult += 2 * np.einsum(\'ar,IB,rB,ajIj->\', ind_ar, s_ib, s_rb, temp)\nresult += 2 * np.einsum(\'ar,IJ,rJ,ajIj->\', ind_ar, s_ij, s_rj, temp)\nresult -= np.einsum(\'ar,IJ,rj,aJIj->\', ind_ar, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ajib\')\nresult -= np.einsum(\'ar,IJ,rb,aJIb->\', ind_ar, s_ij, s_rb, temp)\ntemp = sapt.vt(\'ajaj\')\nresult += 2 * np.einsum(\'ar,AB,rB,ajAj->\', ind_ar, s_ab, s_rb, temp)\nresult += 2 * np.einsum(\'ar,AJ,rJ,ajAj->\', ind_ar, s_aj, s_rj, temp)\nresult -= np.einsum(\'ar,AJ,rj,aJAj->\', ind_ar, s_aj, s_rj, temp)\nresult += np.einsum(\'ar,aJ,rj,AJAj->\', ind_ar, s_aj, s_rj, temp)\nresult += np.einsum(\'ia,iJ,aj,AJAj->\', ind_ia, s_ij, s_aj, temp)\nresult += 2 * np.einsum(\'ir,iJ,rj,AJAj->\', ind_ir, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ajrj\')\nresult += 2 * np.einsum(\'ar,aB,AB,Ajrj->\', ind_ar, s_ab, s_ab, temp)\nresult += np.einsum(\'ar,AJ,Aj,aJrj->\', ind_ar, s_aj, s_aj, temp)\nresult += 2 * np.einsum(\'ar,aJ,AJ,Ajrj->\', ind_ar, s_aj, s_aj, temp)\nresult -= np.einsum(\'ar,aJ,Aj,AJrj->\', ind_ar, s_aj, s_aj, temp)\nresult += 2 * np.einsum(\'ar,IJ,Ij,aJrj->\', ind_ar, s_ij, s_ij, temp)\nresult += 2 * np.einsum(\'ir,iB,AB,Ajrj->\', ind_ir, s_ib, s_ab, temp)\nresult += 2 * np.einsum(\'ir,iJ,AJ,Ajrj->\', ind_ir, s_ij, s_aj, temp)\nresult -= np.einsum(\'ir,iJ,Aj,AJrj->\', ind_ir, s_ij, s_aj, temp)\ntemp = sapt.vt(\'ajab\')\nresult -= np.einsum(\'ar,AJ,rb,aJAb->\', ind_ar, s_aj, s_rb, temp)\nresult += np.einsum(\'ar,aJ,rb,AJAb->\', ind_ar, s_aj, s_rb, temp)\nresult += np.einsum(\'ir,iJ,rb,AJAb->\', ind_ir, s_ij, s_rb, temp)\ntemp = sapt.vt(\'ajrb\')\nresult += np.einsum(\'ar,AJ,Ab,aJrb->\', ind_ar, s_aj, s_ab, temp)\nresult -= np.einsum(\'ar,aJ,Ab,AJrb->\', ind_ar, s_aj, s_ab, temp)\nresult += np.einsum(\'ar,IJ,Ib,aJrb->\', ind_ar, s_ij, s_ib, temp)\nresult -= np.einsum(\'ir,iJ,Ab,AJrb->\', ind_ir, s_ij, s_ab, temp)\ntemp = sapt.vt(\'ijij\')\nresult += 2 * np.einsum(\'ar,aJ,rj,IJIj->\', ind_ar, s_aj, s_rj, temp)\nresult += 2 * np.einsum(\'ia,IJ,aJ,ijIj->\', ind_ia, s_ij, s_aj, temp)\nresult -= np.einsum(\'ia,IJ,aj,iJIj->\', ind_ia, s_ij, s_aj, temp)\nresult += 2 * np.einsum(\'ia,iJ,aj,IJIj->\', ind_ia, s_ij, s_aj, temp)\nresult += 2 * np.einsum(\'ir,IB,rB,ijIj->\', ind_ir, s_ib, s_rb, temp)\nresult += 4 * np.einsum(\'ir,iJ,rj,IJIj->\', ind_ir, s_ij, s_rj, temp)\nresult += 4 * np.einsum(\'ir,IJ,rJ,ijIj->\', ind_ir, s_ij, s_rj, temp)\nresult -= 2 * np.einsum(\'ir,IJ,rj,iJIj->\', ind_ir, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ijaj\')\nresult += np.einsum(\'ia,AJ,Aj,iJaj->\', ind_ia, s_aj, s_aj, temp)\nresult += 2 * np.einsum(\'ia,IJ,Ij,iJaj->\', ind_ia, s_ij, s_ij, temp)\nresult += 2 * np.einsum(\'ia,iJ,IJ,Ijaj->\', ind_ia, s_ij, s_ij, temp)\nresult -= np.einsum(\'ia,iJ,Ij,IJaj->\', ind_ia, s_ij, s_ij, temp)\nresult += 2 * np.einsum(\'ir,AB,rB,ijAj->\', ind_ir, s_ab, s_rb, temp)\nresult += 2 * np.einsum(\'ir,AJ,rJ,ijAj->\', ind_ir, s_aj, s_rj, temp)\nresult -= np.einsum(\'ir,AJ,rj,iJAj->\', ind_ir, s_aj, s_rj, temp)\ntemp = sapt.vt(\'ijrj\')\nresult += 2 * np.einsum(\'ar,aB,IB,Ijrj->\', ind_ar, s_ab, s_ib, temp)\nresult += 2 * np.einsum(\'ar,aJ,IJ,Ijrj->\', ind_ar, s_aj, s_ij, temp)\nresult -= np.einsum(\'ar,aJ,Ij,IJrj->\', ind_ar, s_aj, s_ij, temp)\nresult += 2 * np.einsum(\'ir,iB,IB,Ijrj->\', ind_ir, s_ib, s_ib, temp)\nresult += 2 * np.einsum(\'ir,AJ,Aj,iJrj->\', ind_ir, s_aj, s_aj, temp)\nresult += 4 * np.einsum(\'ir,iJ,IJ,Ijrj->\', ind_ir, s_ij, s_ij, temp)\nresult -= 2 * np.einsum(\'ir,iJ,Ij,IJrj->\', ind_ir, s_ij, s_ij, temp)\nresult += 4 * np.einsum(\'ir,IJ,Ij,iJrj->\', ind_ir, s_ij, s_ij, temp)\ntemp = sapt.vt(\'ijib\')\nresult += 2 * np.einsum(\'ar,aJ,rb,IJIb->\', ind_ar, s_aj, s_rb, temp)\nresult += 2 * np.einsum(\'ir,iJ,rb,IJIb->\', ind_ir, s_ij, s_rb, temp)\nresult -= np.einsum(\'ir,IJ,rb,iJIb->\', ind_ir, s_ij, s_rb, temp)\ntemp = sapt.vt(\'ijab\')\nresult += np.einsum(\'ia,AJ,Ab,iJab->\', ind_ia, s_aj, s_ab, temp)\nresult += np.einsum(\'ia,IJ,Ib,iJab->\', ind_ia, s_ij, s_ib, temp)\nresult -= np.einsum(\'ir,AJ,rb,iJAb->\', ind_ir, s_aj, s_rb, temp)\ntemp = sapt.vt(\'ijrb\')\nresult -= np.einsum(\'ar,aJ,Ib,IJrb->\', ind_ar, s_aj, s_ib, temp)\nresult += 2 * np.einsum(\'ir,AJ,Ab,iJrb->\', ind_ir, s_aj, s_ab, temp)\nresult += 2 * np.einsum(\'ir,IJ,Ib,iJrb->\', ind_ir, s_ij, s_ib, temp)\nresult -= np.einsum(\'ir,iJ,Ib,IJrb->\', ind_ir, s_ij, s_ib, temp)\ntemp = sapt.vt(\'ibrb\')\nresult -= np.einsum(\'ar,aB,Ib,IBrb->\', ind_ar, s_ab, s_ib, temp)\nresult += np.einsum(\'ar,aB,IB,Ibrb->\', ind_ar, s_ab, s_ib, temp)\nresult += np.einsum(\'ar,aJ,IJ,Ibrb->\', ind_ar, s_aj, s_ij, temp)\nresult += 2 * np.einsum(\'ir,AB,Ab,iBrb->\', ind_ir, s_ab, s_ab, temp)\nresult += 2 * np.einsum(\'ir,IB,Ib,iBrb->\', ind_ir, s_ib, s_ib, temp)\nresult += np.einsum(\'ir,iB,IB,Ibrb->\', ind_ir, s_ib, s_ib, temp)\nresult -= np.einsum(\'ir,iB,Ib,IBrb->\', ind_ir, s_ib, s_ib, temp)\nresult += 2 * np.einsum(\'ir,iJ,IJ,Ibrb->\', ind_ir, s_ij, s_ij, temp)\ntemp = sapt.vt(\'ibrj\')\nresult -= np.einsum(\'ar,aB,Ij,IBrj->\', ind_ar, s_ab, s_ij, temp)\nresult += 2 * np.einsum(\'ir,AB,Aj,iBrj->\', ind_ir, s_ab, s_aj, temp)\nresult += 2 * np.einsum(\'ir,IB,Ij,iBrj->\', ind_ir, s_ib, s_ij, temp)\nresult -= np.einsum(\'ir,iB,Ij,IBrj->\', ind_ir, s_ib, s_ij, temp)\ntemp = sapt.vt(\'ibib\')\nresult += 2 * np.einsum(\'ar,aB,rb,IBIb->\', ind_ar, s_ab, s_rb, temp)\nresult += np.einsum(\'ia,IJ,aJ,ibIb->\', ind_ia, s_ij, s_aj, temp)\nresult += np.einsum(\'ir,IB,rB,ibIb->\', ind_ir, s_ib, s_rb, temp)\nresult -= np.einsum(\'ir,IB,rb,iBIb->\', ind_ir, s_ib, s_rb, temp)\nresult += 2 * np.einsum(\'ir,iB,rb,IBIb->\', ind_ir, s_ib, s_rb, temp)\nresult += 2 * np.einsum(\'ir,IJ,rJ,ibIb->\', ind_ir, s_ij, s_rj, temp)\ntemp = sapt.vt(\'ibij\')\nresult += 2 * np.einsum(\'ar,aB,rj,IBIj->\', ind_ar, s_ab, s_rj, temp)\nresult -= np.einsum(\'ir,IB,rj,iBIj->\', ind_ir, s_ib, s_rj, temp)\nresult += 2 * np.einsum(\'ir,iB,rj,IBIj->\', ind_ir, s_ib, s_rj, temp)\ntemp = sapt.vt(\'ibab\')\nresult += np.einsum(\'ia,AB,Ab,iBab->\', ind_ia, s_ab, s_ab, temp)\nresult += np.einsum(\'ia,IB,Ib,iBab->\', ind_ia, s_ib, s_ib, temp)\nresult += np.einsum(\'ia,iJ,IJ,Ibab->\', ind_ia, s_ij, s_ij, temp)\nresult += np.einsum(\'ir,AB,rB,ibAb->\', ind_ir, s_ab, s_rb, temp)\nresult -= np.einsum(\'ir,AB,rb,iBAb->\', ind_ir, s_ab, s_rb, temp)\nresult += np.einsum(\'ir,AJ,rJ,ibAb->\', ind_ir, s_aj, s_rj, temp)\ntemp = sapt.vt(\'ibaj\')\nresult += np.einsum(\'ia,AB,Aj,iBaj->\', ind_ia, s_ab, s_aj, temp)\nresult += np.einsum(\'ia,IB,Ij,iBaj->\', ind_ia, s_ib, s_ij, temp)\nresult -= np.einsum(\'ir,AB,rj,iBAj->\', ind_ir, s_ab, s_rj, temp)\n#automatically programmed stuff above\nExchInd20_ab = result\n\n# B <- A\nresult = 0.0\n#automatically programmed stuff below\ntemp = sapt.vt(\'absa\')\nresult -= np.einsum(\'bs,absa\', ind_bs, temp)\ntemp = sapt.vt(\'ibsi\')\nresult -= np.einsum(\'bs,ibsi\', ind_bs, temp)\ntemp = sapt.vt(\'ijbi\')\nresult -= np.einsum(\'jb,ijbi\', ind_jb, temp)\ntemp = sapt.vt(\'ajsa\')\nresult -= np.einsum(\'js,ajsa\', ind_js, temp)\ntemp = sapt.vt(\'ijsi\')\nresult -= 2 * np.einsum(\'js,ijsi\', ind_js, temp)\ntemp = sapt.vt(\'absb\')\nresult += np.einsum(\'bs,aB,absB\', ind_bs, s_ab, temp)\nresult -= np.einsum(\'bs,ab,aBsB\', ind_bs, s_ab, temp)\nresult -= np.einsum(\'js,aj,aBsB\', ind_js, s_aj, temp)\ntemp = sapt.vt(\'abbs\')\nresult -= np.einsum(\'bs,aB,abBs\', ind_bs, s_ab, temp)\nresult += np.einsum(\'bs,ab,aBBs\', ind_bs, s_ab, temp)\nresult += np.einsum(\'js,aj,aBBs\', ind_js, s_aj, temp)\ntemp = sapt.vt(\'ajsj\')\nresult -= 2 * np.einsum(\'bs,ab,aJsJ\', ind_bs, s_ab, temp)\nresult += np.einsum(\'js,aJ,ajsJ\', ind_js, s_aj, temp)\nresult -= 2 * np.einsum(\'js,aj,aJsJ\', ind_js, s_aj, temp)\ntemp = sapt.vt(\'ajjs\')\nresult += np.einsum(\'js,aj,aJJs\', ind_js, s_aj, temp)\nresult += np.einsum(\'bs,ab,aJJs\', ind_bs, s_ab, temp)\nresult -= 2 * np.einsum(\'js,aJ,ajJs\', ind_js, s_aj, temp)\ntemp = sapt.vt(\'absj\')\nresult += np.einsum(\'bs,aJ,absJ\', ind_bs, s_aj, temp)\ntemp = sapt.vt(\'abjs\')\nresult -= np.einsum(\'bs,aJ,abJs\', ind_bs, s_aj, temp)\ntemp = sapt.vt(\'ajsb\')\nresult += np.einsum(\'js,aB,ajsB\', ind_js, s_ab, temp)\ntemp = sapt.vt(\'ajbs\')\nresult -= 2 * np.einsum(\'js,aB,ajBs\', ind_js, s_ab, temp)\ntemp = sapt.vt(\'ibsb\')\nresult += np.einsum(\'bs,iB,ibsB\', ind_bs, s_ib, temp)\nresult -= np.einsum(\'bs,ib,iBsB\', ind_bs, s_ib, temp)\nresult -= 2 * np.einsum(\'js,ij,iBsB\', ind_js, s_ij, temp)\ntemp = sapt.vt(\'ibbs\')\nresult -= np.einsum(\'bs,iB,ibBs\', ind_bs, s_ib, temp)\nresult += np.einsum(\'bs,ib,iBBs\', ind_bs, s_ib, temp)\nresult += np.einsum(\'js,ij,iBBs\', ind_js, s_ij, temp)\ntemp = sapt.vt(\'ijsj\')\nresult -= 2 * np.einsum(\'bs,ib,iJsJ\', ind_bs, s_ib, temp)\nresult += 2 * np.einsum(\'js,iJ,ijsJ\', ind_js, s_ij, temp)\nresult -= 4 * np.einsum(\'js,ij,iJsJ\', ind_js, s_ij, temp)\ntemp = sapt.vt(\'ijjs\')\nresult += np.einsum(\'bs,ib,iJJs\', ind_bs, s_ib, temp)\nresult += 2 * np.einsum(\'js,ij,iJJs\', ind_js, s_ij, temp)\nresult -= 4 * np.einsum(\'js,iJ,ijJs\', ind_js, s_ij, temp)\ntemp = sapt.vt(\'ibsj\')\nresult += np.einsum(\'bs,iJ,ibsJ\', ind_bs, s_ij, temp)\ntemp = sapt.vt(\'ibjs\')\nresult -= 2 * np.einsum(\'bs,iJ,ibJs\', ind_bs, s_ij, temp)\ntemp = sapt.vt(\'abaa\')\nresult -= np.einsum(\'bs,As,abaA\', ind_bs, s_as, temp)\nresult += np.einsum(\'bs,as,AbaA\', ind_bs, s_as, temp)\ntemp = sapt.vt(\'ajaa\')\nresult -= np.einsum(\'js,As,ajaA\', ind_js, s_as, temp)\nresult += np.einsum(\'js,as,AjaA\', ind_js, s_as, temp)\ntemp = sapt.vt(\'ibia\')\nresult -= 2 * np.einsum(\'bs,As,ibiA\', ind_bs, s_as, temp)\ntemp = sapt.vt(\'ibai\')\nresult += np.einsum(\'bs,as,IbaI\', ind_bs, s_as, temp)\ntemp = sapt.vt(\'abai\')\nresult -= np.einsum(\'bs,Is,abaI\', ind_bs, s_is, temp)\ntemp = sapt.vt(\'ibii\')\nresult -= 2 * np.einsum(\'bs,Is,ibiI\', ind_bs, s_is, temp)\ntemp = sapt.vt(\'abia\')\nresult += np.einsum(\'bs,is,AbiA\', ind_bs, s_is, temp)\ntemp = sapt.vt(\'ibii\')\nresult += np.einsum(\'bs,is,IbiI\', ind_bs, s_is, temp)\ntemp = sapt.vt(\'ajai\')\nresult -= np.einsum(\'jb,Ib,ajaI\', ind_jb, s_ib, temp)\nresult -= 2 * np.einsum(\'js,Is,ajaI\', ind_js, s_is, temp)\ntemp = sapt.vt(\'ijii\')\nresult -= 2 * np.einsum(\'jb,Ib,ijiI\', ind_jb, s_ib, temp)\nresult += np.einsum(\'jb,ib,IjiI\', ind_jb, s_ib, temp)\nresult -= 4 * np.einsum(\'js,Is,ijiI\', ind_js, s_is, temp)\nresult += 2 * np.einsum(\'js,is,IjiI\', ind_js, s_is, temp)\ntemp = sapt.vt(\'ajbb\')\nresult -= np.einsum(\'jb,aB,ajBb\', ind_jb, s_ab, temp)\ntemp = sapt.vt(\'ajjb\')\nresult -= np.einsum(\'jb,aJ,ajJb\', ind_jb, s_aj, temp)\ntemp = sapt.vt(\'ijbb\')\nresult -= np.einsum(\'jb,iB,ijBb\', ind_jb, s_ib, temp)\ntemp = sapt.vt(\'ijjb\')\nresult -= 2 * np.einsum(\'jb,iJ,ijJb\', ind_jb, s_ij, temp)\nresult += np.einsum(\'jb,ij,iJJb\', ind_jb, s_ij, temp)\ntemp = sapt.vt(\'ijbj\')\nresult += np.einsum(\'jb,iJ,ijbJ\', ind_jb, s_ij, temp)\nresult -= 2 * np.einsum(\'jb,ij,iJbJ\', ind_jb, s_ij, temp)\ntemp = sapt.vt(\'ibbb\')\nresult -= np.einsum(\'jb,ij,iBbB\', ind_jb, s_ij, temp)\ntemp = sapt.vt(\'ijsb\')\nresult += np.einsum(\'js,iB,ijsB\', ind_js, s_ib, temp)\ntemp = sapt.vt(\'ijbs\')\nresult -= 2 * np.einsum(\'js,iB,ijBs\', ind_js, s_ib, temp)\ntemp = sapt.vt(\'ijia\')\nresult -= 2 * np.einsum(\'js,As,ijiA\', ind_js, s_as, temp)\ntemp = sapt.vt(\'ijai\')\nresult += np.einsum(\'js,as,IjaI\', ind_js, s_as, temp)\ntemp = sapt.vt(\'ajia\')\nresult += np.einsum(\'js,is,AjiA\', ind_js, s_is, temp)\ntemp = sapt.vt(\'abas\')\nresult += np.einsum(\'bs,AB,aB,Abas\', ind_bs, s_ab, s_ab, temp)\nresult += np.einsum(\'bs,Ab,AB,aBas\', ind_bs, s_ab, s_ab, temp)\nresult -= np.einsum(\'bs,Ab,aB,ABas\', ind_bs, s_ab, s_ab, temp)\nresult += np.einsum(\'bs,AJ,aJ,Abas\', ind_bs, s_aj, s_aj, temp)\nresult += np.einsum(\'bs,Ib,IB,aBas\', ind_bs, s_ib, s_ib, temp)\nresult += np.einsum(\'js,Aj,AB,aBas\', ind_js, s_aj, s_ab, temp)\nresult -= np.einsum(\'js,Aj,aB,ABas\', ind_js, s_aj, s_ab, temp)\nresult += np.einsum(\'js,Ij,IB,aBas\', ind_js, s_ij, s_ib, temp)\ntemp = sapt.vt(\'abis\')\nresult -= np.einsum(\'js,Aj,iB,ABis\', ind_js, s_aj, s_ib, temp)\nresult += np.einsum(\'bs,AB,iB,Abis\', ind_bs, s_ab, s_ib, temp)\nresult -= np.einsum(\'bs,Ab,iB,ABis\', ind_bs, s_ab, s_ib, temp)\nresult += np.einsum(\'bs,AJ,iJ,Abis\', ind_bs, s_aj, s_ij, temp)\ntemp = sapt.vt(\'abab\')\nresult += np.einsum(\'bs,AB,As,abaB\', ind_bs, s_ab, s_as, temp)\nresult += np.einsum(\'bs,Ab,as,ABaB\', ind_bs, s_ab, s_as, temp)\nresult -= np.einsum(\'bs,AB,as,AbaB\', ind_bs, s_ab, s_as, temp)\nresult += np.einsum(\'bs,IB,Is,abaB\', ind_bs, s_ib, s_is, temp)\nresult += np.einsum(\'js,Aj,as,ABaB\', ind_js, s_aj, s_as, temp)\ntemp = sapt.vt(\'abib\')\nresult += np.einsum(\'js,Aj,is,ABiB\', ind_js, s_aj, s_is, temp)\nresult -= np.einsum(\'bs,AB,is,AbiB\', ind_bs, s_ab, s_is, temp)\nresult += np.einsum(\'bs,Ab,is,ABiB\', ind_bs, s_ab, s_is, temp)\ntemp = sapt.vt(\'abaj\')\nresult += np.einsum(\'bs,AJ,As,abaJ\', ind_bs, s_aj, s_as, temp)\nresult -= np.einsum(\'bs,AJ,as,AbaJ\', ind_bs, s_aj, s_as, temp)\nresult += np.einsum(\'bs,IJ,Is,abaJ\', ind_bs, s_ij, s_is, temp)\ntemp = sapt.vt(\'abij\')\nresult -= np.einsum(\'bs,AJ,is,AbiJ\', ind_bs, s_aj, s_is, temp)\ntemp = sapt.vt(\'ibij\')\nresult += 2 * np.einsum(\'bs,AJ,As,ibiJ\', ind_bs, s_aj, s_as, temp)\nresult += 2 * np.einsum(\'bs,IJ,Is,ibiJ\', ind_bs, s_ij, s_is, temp)\nresult -= np.einsum(\'bs,IJ,is,IbiJ\', ind_bs, s_ij, s_is, temp)\ntemp = sapt.vt(\'ibaj\')\nresult -= np.einsum(\'bs,IJ,as,IbaJ\', ind_bs, s_ij, s_as, temp)\ntemp = sapt.vt(\'ibib\')\nresult += 2 * np.einsum(\'bs,AB,As,ibiB\', ind_bs, s_ab, s_as, temp)\nresult += 2 * np.einsum(\'bs,IB,Is,ibiB\', ind_bs, s_ib, s_is, temp)\nresult -= np.einsum(\'bs,IB,is,IbiB\', ind_bs, s_ib, s_is, temp)\nresult += np.einsum(\'bs,Ib,is,IBiB\', ind_bs, s_ib, s_is, temp)\nresult += np.einsum(\'jb,Ij,ib,IBiB\', ind_jb, s_ij, s_ib, temp)\nresult += 2 * np.einsum(\'js,Ij,is,IBiB\', ind_js, s_ij, s_is, temp)\ntemp = sapt.vt(\'ibis\')\nresult += 2 * np.einsum(\'bs,Ab,AB,iBis\', ind_bs, s_ab, s_ab, temp)\nresult += np.einsum(\'bs,IB,iB,Ibis\', ind_bs, s_ib, s_ib, temp)\nresult += 2 * np.einsum(\'bs,Ib,IB,iBis\', ind_bs, s_ib, s_ib, temp)\nresult -= np.einsum(\'bs,Ib,iB,IBis\', ind_bs, s_ib, s_ib, temp)\nresult += 2 * np.einsum(\'bs,IJ,iJ,Ibis\', ind_bs, s_ij, s_ij, temp)\nresult += 2 * np.einsum(\'js,Aj,AB,iBis\', ind_js, s_aj, s_ab, temp)\nresult += 2 * np.einsum(\'js,Ij,IB,iBis\', ind_js, s_ij, s_ib, temp)\nresult -= np.einsum(\'js,Ij,iB,IBis\', ind_js, s_ij, s_ib, temp)\ntemp = sapt.vt(\'ibab\')\nresult -= np.einsum(\'bs,IB,as,IbaB\', ind_bs, s_ib, s_as, temp)\nresult += np.einsum(\'bs,Ib,as,IBaB\', ind_bs, s_ib, s_as, temp)\nresult += np.einsum(\'js,Ij,as,IBaB\', ind_js, s_ij, s_as, temp)\ntemp = sapt.vt(\'ibas\')\nresult += np.einsum(\'bs,IB,aB,Ibas\', ind_bs, s_ib, s_ab, temp)\nresult -= np.einsum(\'bs,Ib,aB,IBas\', ind_bs, s_ib, s_ab, temp)\nresult += np.einsum(\'bs,IJ,aJ,Ibas\', ind_bs, s_ij, s_aj, temp)\nresult -= np.einsum(\'js,Ij,aB,IBas\', ind_js, s_ij, s_ab, temp)\ntemp = sapt.vt(\'ijij\')\nresult += 2 * np.einsum(\'bs,Ib,is,IJiJ\', ind_bs, s_ib, s_is, temp)\nresult += 2 * np.einsum(\'jb,IJ,Ib,ijiJ\', ind_jb, s_ij, s_ib, temp)\nresult -= np.einsum(\'jb,IJ,ib,IjiJ\', ind_jb, s_ij, s_ib, temp)\nresult += 2 * np.einsum(\'jb,Ij,ib,IJiJ\', ind_jb, s_ij, s_ib, temp)\nresult += 2 * np.einsum(\'js,AJ,As,ijiJ\', ind_js, s_aj, s_as, temp)\nresult += 4 * np.einsum(\'js,Ij,is,IJiJ\', ind_js, s_ij, s_is, temp)\nresult += 4 * np.einsum(\'js,IJ,Is,ijiJ\', ind_js, s_ij, s_is, temp)\nresult -= 2 * np.einsum(\'js,IJ,is,IjiJ\', ind_js, s_ij, s_is, temp)\ntemp = sapt.vt(\'ijib\')\nresult += np.einsum(\'jb,IB,iB,Ijib\', ind_jb, s_ib, s_ib, temp)\nresult += 2 * np.einsum(\'jb,IJ,iJ,Ijib\', ind_jb, s_ij, s_ij, temp)\nresult += 2 * np.einsum(\'jb,Ij,IJ,iJib\', ind_jb, s_ij, s_ij, temp)\nresult -= np.einsum(\'jb,Ij,iJ,IJib\', ind_jb, s_ij, s_ij, temp)\nresult += 2 * np.einsum(\'js,AB,As,ijiB\', ind_js, s_ab, s_as, temp)\nresult += 2 * np.einsum(\'js,IB,Is,ijiB\', ind_js, s_ib, s_is, temp)\nresult -= np.einsum(\'js,IB,is,IjiB\', ind_js, s_ib, s_is, temp)\ntemp = sapt.vt(\'ijis\')\nresult += 2 * np.einsum(\'bs,Ab,AJ,iJis\', ind_bs, s_ab, s_aj, temp)\nresult += 2 * np.einsum(\'bs,Ib,IJ,iJis\', ind_bs, s_ib, s_ij, temp)\nresult -= np.einsum(\'bs,Ib,iJ,IJis\', ind_bs, s_ib, s_ij, temp)\nresult += 2 * np.einsum(\'js,Aj,AJ,iJis\', ind_js, s_aj, s_aj, temp)\nresult += 2 * np.einsum(\'js,IB,iB,Ijis\', ind_js, s_ib, s_ib, temp)\nresult += 4 * np.einsum(\'js,Ij,IJ,iJis\', ind_js, s_ij, s_ij, temp)\nresult -= 2 * np.einsum(\'js,Ij,iJ,IJis\', ind_js, s_ij, s_ij, temp)\nresult += 4 * np.einsum(\'js,IJ,iJ,Ijis\', ind_js, s_ij, s_ij, temp)\ntemp = sapt.vt(\'ijaj\')\nresult += 2 * np.einsum(\'bs,Ib,as,IJaJ\', ind_bs, s_ib, s_as, temp)\nresult += 2 * np.einsum(\'js,Ij,as,IJaJ\', ind_js, s_ij, s_as, temp)\nresult -= np.einsum(\'js,IJ,as,IjaJ\', ind_js, s_ij, s_as, temp)\ntemp = sapt.vt(\'ijab\')\nresult += np.einsum(\'jb,IB,aB,Ijab\', ind_jb, s_ib, s_ab, temp)\nresult += np.einsum(\'jb,IJ,aJ,Ijab\', ind_jb, s_ij, s_aj, temp)\nresult -= np.einsum(\'js,IB,as,IjaB\', ind_js, s_ib, s_as, temp)\ntemp = sapt.vt(\'ijas\')\nresult -= np.einsum(\'bs,Ib,aJ,IJas\', ind_bs, s_ib, s_aj, temp)\nresult += 2 * np.einsum(\'js,IB,aB,Ijas\', ind_js, s_ib, s_ab, temp)\nresult += 2 * np.einsum(\'js,IJ,aJ,Ijas\', ind_js, s_ij, s_aj, temp)\nresult -= np.einsum(\'js,Ij,aJ,IJas\', ind_js, s_ij, s_aj, temp)\ntemp = sapt.vt(\'ajas\')\nresult -= np.einsum(\'bs,Ab,aJ,AJas\', ind_bs, s_ab, s_aj, temp)\nresult += np.einsum(\'bs,Ab,AJ,aJas\', ind_bs, s_ab, s_aj, temp)\nresult += np.einsum(\'bs,Ib,IJ,aJas\', ind_bs, s_ib, s_ij, temp)\nresult += 2 * np.einsum(\'js,AB,aB,Ajas\', ind_js, s_ab, s_ab, temp)\nresult += 2 * np.einsum(\'js,AJ,aJ,Ajas\', ind_js, s_aj, s_aj, temp)\nresult += np.einsum(\'js,Aj,AJ,aJas\', ind_js, s_aj, s_aj, temp)\nresult -= np.einsum(\'js,Aj,aJ,AJas\', ind_js, s_aj, s_aj, temp)\nresult += 2 * np.einsum(\'js,Ij,IJ,aJas\', ind_js, s_ij, s_ij, temp)\ntemp = sapt.vt(\'ajis\')\nresult -= np.einsum(\'bs,Ab,iJ,AJis\', ind_bs, s_ab, s_ij, temp)\nresult += 2 * np.einsum(\'js,AB,iB,Ajis\', ind_js, s_ab, s_ib, temp)\nresult += 2 * np.einsum(\'js,AJ,iJ,Ajis\', ind_js, s_aj, s_ij, temp)\nresult -= np.einsum(\'js,Aj,iJ,AJis\', ind_js, s_aj, s_ij, temp)\ntemp = sapt.vt(\'ajaj\')\nresult += 2 * np.einsum(\'bs,Ab,as,AJaJ\', ind_bs, s_ab, s_as, temp)\nresult += np.einsum(\'jb,IJ,Ib,ajaJ\', ind_jb, s_ij, s_ib, temp)\nresult += np.einsum(\'js,AJ,As,ajaJ\', ind_js, s_aj, s_as, temp)\nresult -= np.einsum(\'js,AJ,as,AjaJ\', ind_js, s_aj, s_as, temp)\nresult += 2 * np.einsum(\'js,Aj,as,AJaJ\', ind_js, s_aj, s_as, temp)\nresult += 2 * np.einsum(\'js,IJ,Is,ajaJ\', ind_js, s_ij, s_is, temp)\ntemp = sapt.vt(\'ajij\')\nresult += 2 * np.einsum(\'bs,Ab,is,AJiJ\', ind_bs, s_ab, s_is, temp)\nresult -= np.einsum(\'js,AJ,is,AjiJ\', ind_js, s_aj, s_is, temp)\nresult += 2 * np.einsum(\'js,Aj,is,AJiJ\', ind_js, s_aj, s_is, temp)\ntemp = sapt.vt(\'ajab\')\nresult += np.einsum(\'jb,AB,aB,Ajab\', ind_jb, s_ab, s_ab, temp)\nresult += np.einsum(\'jb,AJ,aJ,Ajab\', ind_jb, s_aj, s_aj, temp)\nresult += np.einsum(\'jb,Ij,IJ,aJab\', ind_jb, s_ij, s_ij, temp)\nresult += np.einsum(\'js,AB,As,ajaB\', ind_js, s_ab, s_as, temp)\nresult -= np.einsum(\'js,AB,as,AjaB\', ind_js, s_ab, s_as, temp)\nresult += np.einsum(\'js,IB,Is,ajaB\', ind_js, s_ib, s_is, temp)\ntemp = sapt.vt(\'ajib\')\nresult += np.einsum(\'jb,AB,iB,Ajib\', ind_jb, s_ab, s_ib, temp)\nresult += np.einsum(\'jb,AJ,iJ,Ajib\', ind_jb, s_aj, s_ij, temp)\nresult -= np.einsum(\'js,AB,is,AjiB\', ind_js, s_ab, s_is, temp)\n#automatically programmed stuff above\nExchInd20_ba = result\n\n#sapt_printer(\'Exch-Ind20 A<-B\', ExchInd20_ab)\n#sapt_printer(\'Exch-Ind20 B<-A\', ExchInd20_ba)\n\nExchInd20 = ExchInd20_ab + ExchInd20_ba\n\nind_timer.stop()\n### End E200 Induction and Exchange-Induction\n\nprint(\'\\nSAPT0(ROHF) Results\')\nprint(\'-\' * 70)\nsapt_printer(\'Exch10 (S^2)\', Exch100)\nsapt_printer(\'Elst10\', Elst10)\nsapt_printer(\'Disp20\', Disp200)\nsapt_printer(\'Exch-Disp20\', ExchDisp20)\nsapt_printer(\'Ind20\', Ind20r)\nsapt_printer(\'Exch-Ind20\', ExchInd20)\n\nprint(\'-\' * 70)\nsapt0 = Exch100 + Elst10 + Disp200 + ExchDisp20 + Ind20r + ExchInd20\nsapt_printer(\'Total SAPT0(ROHF)\', sapt0)\n\n# ==> Compare to Psi4 <==\n# in Psi4, we can only run SAPT with DF-ROHF\npsi4.set_options({\'df_basis_sapt\': \'aug-cc-pvdz-ri\'})\npsi4.set_options({\'df_basis_scf\': \'aug-cc-pvdz-jkfit\'})\npsi4.set_options({\'scf_type\': \'df\'})\npsi4.energy(\'sapt0\')\nEelst = psi4.variable(\'SAPT ELST ENERGY\')\nEexch = psi4.variable(\'SAPT EXCH10(S^2) ENERGY\')\nEind = psi4.variable(\'SAPT IND20,U ENERGY\')\nEexind = psi4.variable(\'SAPT EXCH-IND20,U ENERGY\')\nEdisp = psi4.variable(\'SAPT DISP20 ENERGY\')\nEexdisp = psi4.variable(\'SAPT EXCH-DISP20 ENERGY\')\npsi4.compare_values(Eelst, Elst10, 5, \'Elst100\')\npsi4.compare_values(Eexch, Exch100, 5, \'Exch100(S^2)\')\npsi4.compare_values(Edisp, Disp200, 5, \'Disp200\')\npsi4.compare_values(Eexdisp, ExchDisp20, 5, \'Exch-Disp200\')\npsi4.compare_values(Eind, Ind20r, 5, \'Ind200,r\')\npsi4.compare_values(Eexind, ExchInd20, 5, \'Exch-Ind200,r\')\n'"
Symmetry-Adapted-Perturbation-Theory/SAPT0_no_S2.py,88,"b'\'\'\'\nA script to compute the SAPT0 interaction energy without the\nSingle-Exchange Approximation.\n\nReferences\nEquations taken from [Jeziorski:1976:281], [Schaffer:2012:1235],\nand [Schaffer:2013:2570].\n\'\'\'\n\n__authors__ = ""Jonathan M. Waldrop""\n__credits__ = [""Jonathan M. Waldrop""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2018-01-09""\n\nimport psi4\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, threshold=2000, suppress=True)\nfrom helper_SAPT import *\n\n# Set Psi4 & NumPy Memory Options\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'sapt0_no_S2.dat\', False)\n\nnumpy_memory = 2\n\n# Set molecule to dimer\ndimer = psi4.geometry(""""""\nO   -0.066999140   0.000000000   1.494354740\nH    0.815734270   0.000000000   1.865866390\nH    0.068855100   0.000000000   0.539142770\n--\nO    0.062547750   0.000000000  -1.422632080\nH   -0.406965400  -0.760178410  -1.771744500\nH   -0.406965400   0.760178410  -1.771744500\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'jun-cc-pVDZ\', \'e_convergence\': 1e-8, \'d_convergence\': 1e-8})\n\nsapt = helper_SAPT(dimer, memory=8)\n\n### Overlap Matrix and Inverse\nS_a = np.concatenate((sapt.s(\'aa\'), sapt.s(\'ab\')), axis=1)\nS_b = np.concatenate((sapt.s(\'ba\'), sapt.s(\'bb\')), axis=1)\nS = np.concatenate((S_a, S_b), axis=0)\n# S_{AA} S_{AB}\n# S_{BA} S_{BB}\n\nD = np.linalg.inv(S)\nD_aa = D[:sapt.ndocc_A, :sapt.ndocc_A]\nD_ab = D[:sapt.ndocc_A, sapt.ndocc_A:sapt.ndocc_A + sapt.ndocc_B]\nD_ba = D[sapt.ndocc_A:sapt.ndocc_A + sapt.ndocc_B, :sapt.ndocc_A]\nD_bb = D[sapt.ndocc_A:, sapt.ndocc_A:]\n\n### E10 Electrostatics\nElst10 = 4 * np.einsum(\'abab\', sapt.vt(\'abab\'))\n\n### Complete E10\nv_abaa = sapt.v(\'abaa\')\nv_abab = sapt.v(\'abab\')\nv_abba = sapt.v(\'abba\')\nv_abbb = sapt.v(\'abbb\')\n\n# E10 Full\ne1_full = sapt.nuc_rep  # Nuclear Repulsion\n\ne1_full += 2 * (np.einsum(\'aA,Aa->\', sapt.potential(\'aa\', \'B\'), D_aa) +\n                np.einsum(\'ab,ba->\', sapt.potential(\'ab\', \'B\'), D_ba))  # B potential\ne1_full += 2 * (np.einsum(\'bB,Bb->\', sapt.potential(\'bb\', \'A\'), D_bb) +\n                np.einsum(\'ba,ab->\', sapt.potential(\'ba\', \'A\'), D_ab))  # A potential\n\ne1_full += 4 * np.einsum(\'ijkl,ki,lj->\', v_abaa, D_aa, D_ab)  # Two electron part\ne1_full += 4 * np.einsum(\'ijkl,ki,lj->\', v_abab, D_aa, D_bb)\ne1_full += 4 * np.einsum(\'ijkl,ki,lj->\', v_abba, D_ba, D_ab)\ne1_full += 4 * np.einsum(\'ijkl,ki,lj->\', v_abbb, D_ba, D_bb)\ne1_full += -2 * np.einsum(\'ijlk,ki,lj->\', v_abaa, D_aa, D_ab)\ne1_full += -2 * np.einsum(\'ijlk,ki,lj->\', v_abba, D_aa, D_bb)\ne1_full += -2 * np.einsum(\'ijlk,ki,lj->\', v_abab, D_ba, D_ab)\ne1_full += -2 * np.einsum(\'ijlk,ki,lj->\', v_abbb, D_ba, D_bb)\n\n# E10 Exchange\nExch10 = e1_full - Elst10\n\n### E20 Induction and Exchange Induction\n\n# E20 Induction\nCPHF_ra, Ind20_ba = sapt.chf(\'B\', ind=True)\nCPHF_sb, Ind20_ab = sapt.chf(\'A\', ind=True)\nInd20r = Ind20_ba + Ind20_ab\n\n# E20 Induction Full\nT_ar = np.einsum(\'ij,jk->ik\', D_ab, sapt.s(\'br\'))\nT_br = np.einsum(\'ij,jk->ik\', D_bb, sapt.s(\'br\'))\nT_as = np.einsum(\'ij,jk->ik\', D_aa, sapt.s(\'as\'))\nT_bs = np.einsum(\'ij,jk->ik\', D_ba, sapt.s(\'as\'))\n\nB_aa = sapt.potential(\'aa\', \'B\')\nB_ab = sapt.potential(\'ab\', \'B\')\nA_ba = sapt.potential(\'ba\', \'A\')\nA_bb = sapt.potential(\'bb\', \'A\')\n\nB_T_ar = np.einsum(\'ij,jk->ik\', B_aa, T_ar) + np.einsum(\'ij,jk->ik\', B_ab, T_br)\nB_T_as = np.einsum(\'ij,jk->ik\', B_aa, T_as) + np.einsum(\'ij,jk->ik\', B_ab, T_bs)\nA_T_br = np.einsum(\'ij,jk->ik\', A_ba, T_ar) + np.einsum(\'ij,jk->ik\', A_bb, T_br)\nA_T_bs = np.einsum(\'ij,jk->ik\', A_ba, T_as) + np.einsum(\'ij,jk->ik\', A_bb, T_bs)\n\nBt_ar = sapt.potential(\'ar\', \'B\') - B_T_ar\nBt_as = sapt.potential(\'as\', \'B\') - B_T_as\nAt_br = sapt.potential(\'br\', \'A\') - A_T_br\nAt_bs = sapt.potential(\'bs\', \'A\') - A_T_bs\n\nv_abaa = sapt.v(\'abaa\')\nv_abab = sapt.v(\'abab\')\nv_abba = sapt.v(\'abba\')\nv_abbb = sapt.v(\'abbb\')\n\nv_abra = sapt.v(\'abra\')\nv_abar = sapt.v(\'abar\')\nv_abrb = sapt.v(\'abrb\')\nv_abbr = sapt.v(\'abbr\')\n\nv_absa = sapt.v(\'absa\')\nv_abas = sapt.v(\'abas\')\nv_absb = sapt.v(\'absb\')\nv_abbs = sapt.v(\'abbs\')\n\nv_T_abra = np.einsum(\'ijkl,ka->ijal\', v_abaa, T_ar) + np.einsum(\'ijkl,ka->ijal\', v_abba, T_br)\nv_T_abrb = np.einsum(\'ijkl,ka->ijal\', v_abab, T_ar) + np.einsum(\'ijkl,ka->ijal\', v_abbb, T_br)\nv_T_abar = np.einsum(\'ijkl,la->ijka\', v_abaa, T_ar) + np.einsum(\'ijkl,la->ijka\', v_abab, T_br)\nv_T_abbr = np.einsum(\'ijkl,la->ijka\', v_abba, T_ar) + np.einsum(\'ijkl,la->ijka\', v_abbb, T_br)\n\nv_T_absa = np.einsum(\'ijkl,ka->ijal\', v_abaa, T_as) + np.einsum(\'ijkl,ka->ijal\', v_abba, T_bs)\nv_T_absb = np.einsum(\'ijkl,ka->ijal\', v_abab, T_as) + np.einsum(\'ijkl,ka->ijal\', v_abbb, T_bs)\nv_T_abas = np.einsum(\'ijkl,la->ijka\', v_abaa, T_as) + np.einsum(\'ijkl,la->ijka\', v_abab, T_bs)\nv_T_abbs = np.einsum(\'ijkl,la->ijka\', v_abba, T_as) + np.einsum(\'ijkl,la->ijka\', v_abbb, T_bs)\n\nvt_abra = v_abra - v_T_abra\nvt_abar = v_abar - v_T_abar\nvt_abrb = v_abrb - v_T_abrb\nvt_abbr = v_abbr - v_T_abbr\n\nvt_absa = v_absa - v_T_absa\nvt_abas = v_abas - v_T_abas\nvt_absb = v_absb - v_T_absb\nvt_abbs = v_abbs - v_T_abbs\n\nO_ar = 2 * np.einsum(\'kj,ik->ij\', Bt_ar, D_aa) + 2 * np.einsum(\'kj,ik->ij\', At_br, D_ab)\nO_ar += 4 * np.einsum(\'ijkl,mi,lj->mk\', vt_abra, D_aa, D_ab)\nO_ar += 4 * np.einsum(\'ijkl,mi,lj->mk\', vt_abrb, D_aa, D_bb)\nO_ar -= 2 * np.einsum(\'ijkl,mj,li->mk\', vt_abra, D_ab, D_aa)\nO_ar -= 2 * np.einsum(\'ijkl,mj,li->mk\', vt_abrb, D_ab, D_ba)\nO_ar -= 2 * np.einsum(\'ijkl,mi,kj->ml\', vt_abar, D_aa, D_ab)\nO_ar -= 2 * np.einsum(\'ijkl,mi,kj->ml\', vt_abbr, D_aa, D_bb)\nO_ar += 4 * np.einsum(\'ijkl,mj,ki->ml\', vt_abar, D_ab, D_aa)\nO_ar += 4 * np.einsum(\'ijkl,mj,ki->ml\', vt_abbr, D_ab, D_ba)\n\nO_bs = 2 * np.einsum(\'kj,ik->ij\', Bt_as, D_ba) + 2 * np.einsum(\'kj,ik->ij\', At_bs, D_bb)\nO_bs += 4 * np.einsum(\'ijkl,mj,ki->ml\', vt_abas, D_bb, D_aa)\nO_bs += 4 * np.einsum(\'ijkl,mj,ki->ml\', vt_abbs, D_bb, D_ba)\nO_bs -= 2 * np.einsum(\'ijkl,mi,kj->ml\', vt_abas, D_ba, D_ab)\nO_bs -= 2 * np.einsum(\'ijkl,mi,kj->ml\', vt_abbs, D_ba, D_bb)\nO_bs -= 2 * np.einsum(\'ijkl,mj,li->mk\', vt_absa, D_bb, D_aa)\nO_bs -= 2 * np.einsum(\'ijkl,mj,li->mk\', vt_absb, D_bb, D_ba)\nO_bs += 4 * np.einsum(\'ijkl,mi,lj->mk\', vt_absa, D_ba, D_ab)\nO_bs += 4 * np.einsum(\'ijkl,mi,lj->mk\', vt_absb, D_ba, D_bb)\n\ne2_ind_full = np.einsum(\'ar,ra->\', O_ar, CPHF_ra) + np.einsum(\'bs,sb->\', O_bs, CPHF_sb)\n\n# E20 Exchange-Induction\nExchInd20r = e2_ind_full - Ind20r\n\n### E20 Dispersion and Exchange-Dispersion\n# E20 Dispersion\nv_abrs = sapt.v(\'abrs\')\nv_rsab = sapt.v(\'rsab\')\ne_rsab = 1 / (-sapt.eps(\'r\', dim=4) - sapt.eps(\'s\', dim=3) + sapt.eps(\'a\', dim=2) + sapt.eps(\'b\'))\n\nDisp20 = 4 * np.einsum(\'rsab,rsab,abrs->\', e_rsab, v_rsab, v_abrs)\n\n# E20 Dispersion Full. Several pieces already produced in E20 Induction Full.\nv_T_abRs = np.einsum(\'ijkl,ka->ijal\', v_abas, T_ar) + np.einsum(\'ijkl,ka->ijal\', v_abbs, T_br)\nv_T_absR = np.einsum(\'ijkl,la->ijka\', v_absa, T_ar) + np.einsum(\'ijkl,la->ijka\', v_absb, T_br)\nv_T_abrS = np.einsum(\'ijkl,la->ijka\', v_abra, T_as) + np.einsum(\'ijkl,la->ijka\', v_abrb, T_bs)\nv_T_abSr = np.einsum(\'ijkl,ka->ijal\', v_abar, T_as) + np.einsum(\'ijkl,ka->ijal\', v_abbr, T_bs)\n\nv_T_T_abRS = (np.einsum(\'ijkl,ka,lb->ijab\', v_abaa, T_ar, T_as) + np.einsum(\'ijkl,ka,lb->ijab\', v_abbb, T_br, T_bs) +\n              np.einsum(\'ijkl,ka,lb->ijab\', v_abba, T_br, T_as) + np.einsum(\'ijkl,ka,lb->ijab\', v_abab, T_ar, T_bs))\nv_T_T_abSR = (np.einsum(\'ijkl,ka,lb->ijab\', v_abaa, T_as, T_ar) + np.einsum(\'ijkl,ka,lb->ijab\', v_abbb, T_bs, T_br) +\n              np.einsum(\'ijkl,ka,lb->ijab\', v_abba, T_bs, T_ar) + np.einsum(\'ijkl,ka,lb->ijab\', v_abab, T_as, T_br))\n\nvt_abrs = sapt.v(\'abrs\') - v_T_abRs - v_T_abrS + v_T_T_abRS\nvt_absr = sapt.v(\'absr\') - v_T_absR - v_T_abSr + v_T_T_abSR\n\nO_as = 2 * np.einsum(\'kj,ik->ij\', Bt_as, D_aa) + 2 * np.einsum(\'kj,ik->ij\', At_bs, D_ab)\nO_as += 4 * np.einsum(\'ijkl,mi,lj->mk\', vt_absa, D_aa, D_ab)\nO_as += 4 * np.einsum(\'ijkl,mi,lj->mk\', vt_absb, D_aa, D_bb)\nO_as -= 2 * np.einsum(\'ijkl,mj,li->mk\', vt_absa, D_ab, D_aa)\nO_as -= 2 * np.einsum(\'ijkl,mj,li->mk\', vt_absb, D_ab, D_ba)\nO_as -= 2 * np.einsum(\'ijkl,mi,kj->ml\', vt_abas, D_aa, D_ab)\nO_as -= 2 * np.einsum(\'ijkl,mi,kj->ml\', vt_abbs, D_aa, D_bb)\nO_as += 4 * np.einsum(\'ijkl,mj,ki->ml\', vt_abas, D_ab, D_aa)\nO_as += 4 * np.einsum(\'ijkl,mj,ki->ml\', vt_abbs, D_ab, D_ba)\n\nO_br = 2 * np.einsum(\'kj,ik->ij\', Bt_ar, D_ba) + 2 * np.einsum(\'kj,ik->ij\', At_br, D_bb)\nO_br += 4 * np.einsum(\'ijkl,mj,ki->ml\', vt_abar, D_bb, D_aa)\nO_br += 4 * np.einsum(\'ijkl,mj,ki->ml\', vt_abbr, D_bb, D_ba)\nO_br -= 2 * np.einsum(\'ijkl,mi,kj->ml\', vt_abar, D_ba, D_ab)\nO_br -= 2 * np.einsum(\'ijkl,mi,kj->ml\', vt_abbr, D_ba, D_bb)\nO_br -= 2 * np.einsum(\'ijkl,mj,li->mk\', vt_abra, D_bb, D_aa)\nO_br -= 2 * np.einsum(\'ijkl,mj,li->mk\', vt_abrb, D_bb, D_ba)\nO_br += 4 * np.einsum(\'ijkl,mi,lj->mk\', vt_abra, D_ba, D_ab)\nO_br += 4 * np.einsum(\'ijkl,mi,lj->mk\', vt_abrb, D_ba, D_bb)\n\ndouble_mod_eri_abrs = 4 * np.einsum(\'ijkl,mi,nj->mnkl\', vt_abrs, D_aa, D_bb)\ndouble_mod_eri_abrs -= 2 * np.einsum(\'ijkl,mj,ni->mnkl\', vt_abrs, D_ab, D_ba)\ndouble_mod_eri_abrs -= 2 * np.einsum(\'ijlk,mi,nj->mnkl\', vt_absr, D_aa, D_bb)\ndouble_mod_eri_abrs += 4 * np.einsum(\'ijlk,mj,ni->mnkl\', vt_absr, D_ab, D_ba)\n\nG_abrs = ( 2 * np.einsum(\'ik,jl->ijkl\', T_ar, O_bs) - np.einsum(\'il,jk->ijkl\', T_as, O_br) +\n          2 * np.einsum(\'jl,ik->ijkl\', T_bs, O_ar) - np.einsum(\'jk,il->ijkl\', T_br, O_as) + double_mod_eri_abrs)\n\nv_rsab = sapt.v(\'rsab\')\ne_rsab = 1 / (-sapt.eps(\'r\', dim=4) - sapt.eps(\'s\', dim=3) + sapt.eps(\'a\', dim=2) + sapt.eps(\'b\'))\nt_rsab = np.einsum(\'rsab,rsab->rsab\', v_rsab, e_rsab)\n\ne2_disp_full = np.einsum(\'ijkl,klij->\', G_abrs, t_rsab)\n\n# E20 Exchange-Dispersion\nExchDisp20 = e2_disp_full - Disp20\n\n### Compare with Psi4\n# Print Psi4Numpy Results\nprint(\'Psi4Numpy SAPT0 Results\')\nprint(\'-\' * 70)\nsapt_printer(\'Elst10\', Elst10)\nsapt_printer(\'Exch10\', Exch10)\nsapt_printer(\'Disp20\', Disp20)\nsapt_printer(\'Exch-Disp20\', ExchDisp20)\nsapt_printer(\'Ind20,r\', Ind20r)\nsapt_printer(\'Exch-Ind20,r\', ExchInd20r)\nprint(\'-\' * 70)\nsapt0_no_S2 = Exch10 + Elst10 + Disp20 + ExchDisp20 + Ind20r + ExchInd20r\nsapt_printer(\'Total SAPT0\', sapt0_no_S2)\nprint(\'\')\n\n# Print Psi4 Results\npsi4.set_options({\'df_basis_sapt\': \'aug-cc-pvtz-ri\'})\npsi4.energy(\'sapt0\')\n\nEelst = psi4.variable(\'SAPT ELST ENERGY\')\nEexch = psi4.variable(\'SAPT EXCH10 ENERGY\')\nEexch_S2 = psi4.variable(\'SAPT EXCH10(S^2) ENERGY\')\nEind = psi4.variable(\'SAPT IND20,R ENERGY\')\nEexind = psi4.variable(\'SAPT EXCH-IND20,R ENERGY\')\nEdisp = psi4.variable(\'SAPT DISP20 ENERGY\')\nEexdisp = psi4.variable(\'SAPT EXCH-DISP20 ENERGY\')\n\nprint(\'Psi4 SAPT0 Results\')\nprint(\'-\' * 70)\nsapt_printer(\'Elst10\', Eelst)\nsapt_printer(\'Exch10\', Eexch)\nsapt_printer(\'Exch10(S^2)\', Eexch_S2)\nsapt_printer(\'Disp20\', Edisp)\nsapt_printer(\'Exch-Disp20(S^2)\', Eexdisp)\nsapt_printer(\'Ind20,r\', Eind)\nsapt_printer(\'Exch-Ind20,r(S^2)\', Eexind)\nprint(\'-\' * 70)\nsapt0 = Eelst + Eexch_S2 + Edisp + Eexdisp + Eind + Eexind\nsapt_printer(\'Total SAPT0(S^2)\', sapt0)\nprint(\'\')\n'"
Symmetry-Adapted-Perturbation-Theory/SAPT0ao.py,68,"b'""""""\nA simple Psi4 input script to compute SAPT0 interaction energies using an\natomic orbital (AO) algorithm.\n\nReferences:\n- Equations and algorithms from [Szalewicz:2005:43], [Jeziorski:1994:1887],\n[Szalewicz:2012:254], and [Hohenstein:2012:304]\n""""""\n\n__authors__   = ""Daniel G. A. Smith""\n__credits__   = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2014-12-01""\n\nimport time\nimport numpy as np\nfrom helper_SAPT import *\nnp.set_printoptions(precision=5, linewidth=200, threshold=2000, suppress=True)\nimport psi4\n\n# Set Psi4 & NumPy Memory Options\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\nnumpy_memory = 2\n\n# Set molecule to dimer\ndimer = psi4.geometry(""""""\nO   -0.066999140   0.000000000   1.494354740\nH    0.815734270   0.000000000   1.865866390\nH    0.068855100   0.000000000   0.539142770\n--\nO    0.062547750   0.000000000  -1.422632080\nH   -0.406965400  -0.760178410  -1.771744500\nH   -0.406965400   0.760178410  -1.771744500\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'jun-cc-pVDZ\',\n                  \'e_convergence\': 1e-8,\n                  \'d_convergence\': 1e-8})\n\nsapt = helper_SAPT(dimer, memory=8, algorithm=\'AO\')\n\n# Build intermediates\nint_timer = sapt_timer(\'intermediates\')\nPi = np.dot(sapt.orbitals[\'a\'], sapt.orbitals[\'a\'].T)\nPj = np.dot(sapt.orbitals[\'b\'], sapt.orbitals[\'b\'].T)\n\nS = sapt.S\nnum_el_A = (2 * sapt.ndocc_A)\nnum_el_B = (2 * sapt.ndocc_B)\n\nCi = sapt.orbitals[\'a\']\nCj = sapt.orbitals[\'b\']\nCr = sapt.orbitals[\'r\']\nCs = sapt.orbitals[\'s\']\n\nI = np.asarray(sapt.mints.ao_eri())\n\nJii, Kii = sapt.compute_sapt_JK(Ci, Ci)\nJjj, Kjj = sapt.compute_sapt_JK(Cj, Cj)\n\nJij, Kij = sapt.compute_sapt_JK(Ci, Cj, tensor=sapt.chain_dot(Ci.T, S, Cj))\n\nw_A = sapt.V_A + 2 * Jii \nw_B = sapt.V_B + 2 * Jjj \n\nh_A = sapt.V_A + 2 * Jii - Kii \nh_B = sapt.V_B + 2 * Jjj - Kjj \n\nint_timer.stop()\n\n### Build electrostatics\nelst_timer = sapt_timer(\'electrostatics\')\ntwo_el = 2 * np.vdot(Pi, Jjj)\natt_a = np.vdot(sapt.V_A, Pj) \natt_b = np.vdot(sapt.V_B, Pi) \nrep = sapt.nuc_rep \nelst_ijij = 2 * (two_el + att_a + att_b) + rep\n\nElst10 = elst_ijij\nsapt_printer(\'Elst10\', Elst10)\nelst_timer.stop()\n### End electrostatics\n\n### Start exchange\nexch_timer = sapt_timer(\'exchange\')\nexch = 0\nexch -= 2 * np.vdot(Pj, Kii)\nexch -= 2 * np.vdot(sapt.chain_dot(Pi, S, Pj), (h_A + h_B))\n\nexch += 2 * np.vdot(sapt.chain_dot(Pj, S, Pi, S, Pj), w_A)\nexch += 2 * np.vdot(sapt.chain_dot(Pi, S, Pj, S, Pi), w_B)\n\nexch -= 2 * np.vdot(sapt.chain_dot(Pi, S, Pj), Kij)\n\nExch100 = exch\nsapt_printer(\'Exch10(S^2)\', Exch100)\nexch_timer.stop()\n### End E100 (S^2) Exchange\n\n### Start E200 Disp\ndisp_timer = sapt_timer(\'dispersion\')\nv_abrs = sapt.v(\'abrs\')\nv_rsab = sapt.v(\'rsab\')\ne_rsab = 1/(-sapt.eps(\'r\', dim=4) - sapt.eps(\'s\', dim=3) + sapt.eps(\'a\', dim=2) + sapt.eps(\'b\'))\n\nDisp200 = 4 * np.einsum(\'rsab,rsab,abrs->\', e_rsab, v_rsab, v_abrs)\nsapt_printer(\'Disp20\', Disp200)\n### End E200 Disp\n\n### Start E200 Exchange-Dispersion\n\n# Build t_rsab\nt_rsab = np.einsum(\'rsab,rsab->rsab\', v_rsab, e_rsab)\n\n#backtransform t_rsab to the AO basis\nt_lsab = np.einsum(\'rsab,rl->lsab\', t_rsab, Cr.T)\nt_lnab = np.einsum(\'lsab,sn->lnab\', t_lsab, Cs.T)\nt_lnkb = np.einsum(\'lnab,ak->lnkb\', t_lnab, Ci.T)\nt_lnkm = np.einsum(\'lnkb,bm->lnkm\', t_lnkb, Cj.T)\n\nExchDisp20 = - 2 * np.einsum(\'lnkm,knml->\', t_lnkm, I)\n\nExchDisp20 -= 2 * np.einsum(\'lnkm,ml,kn->\', t_lnkm, h_A, S) \nExchDisp20 -= 2 * np.einsum(\'lnkm,ml,kn->\', t_lnkm, S, h_B)\n\ninterm = 2 * np.einsum(\'klmq,nq->klmn\', I, np.dot(S, Pi)) \nExchDisp20 -= 2 * np.einsum(\'lnkm,klmn->\', t_lnkm, interm) \nExchDisp20 += np.einsum(\'lnkm,mlkn->\', t_lnkm, interm) \n\ninterm = 2 * np.einsum(\'klmq,nq->klmn\', I, np.dot(S, Pj)) \nExchDisp20 -= 2 * np.einsum(\'lnkm,mnkl->\', t_lnkm, interm) \nExchDisp20 += np.einsum(\'lnkm,knml->\', t_lnkm, interm) \n\nExchDisp20 -= 4 * np.einsum(\'lnkm,mn,kl->\', t_lnkm, w_A, sapt.chain_dot(S, Pj, S))\nExchDisp20 += 2 * np.einsum(\'lnkm,kn,ml->\', t_lnkm, S, sapt.chain_dot(w_A, Pj, S))\nExchDisp20 += 2 * np.einsum(\'lnkm,ml,nk->\', t_lnkm, S, sapt.chain_dot(w_A, Pj, S))\n\nExchDisp20 -= 4 * np.einsum(\'lnkm,kl,mn->\', t_lnkm, w_B, sapt.chain_dot(S, Pi, S))\nExchDisp20 += 2 * np.einsum(\'lnkm,ml,kn->\', t_lnkm, S, sapt.chain_dot(w_B, Pi, S))\nExchDisp20 += 2 * np.einsum(\'lnkm,kn,lm->\', t_lnkm, S, sapt.chain_dot(w_B, Pi, S))\n\nspbspa = sapt.chain_dot(S, Pj, S, Pi)\nspaspb = sapt.chain_dot(S, Pi, S, Pj)\ninterm = np.einsum(\'kqmn,lq->klmn\', I, spbspa)\ninterm += np.einsum(\'plmn,kp->klmn\', I, spbspa)\ninterm += np.einsum(\'klms,ns->klmn\', I, spaspb)\ninterm += np.einsum(\'klrn,mr->klmn\', I, spaspb)\nExchDisp20 += 4 * np.einsum(\'lnkm,klmn->\', t_lnkm, interm)\n\nExchDisp20 -= 2 * np.einsum(\'lnkm,kn,ml->\', t_lnkm, S, Kij.T) \nExchDisp20 -= 2 * np.einsum(\'lnkm,ml,nk->\', t_lnkm, S, Kij.T) \n\nspa = np.dot(S, Pi)\nspb = np.dot(S, Pj)\ninterm = np.einsum(\'kpmq,nq->kpmn\', I, spa)\ninterm = np.einsum(\'kpmn,lp->klmn\', interm, spb)\nExchDisp20 -= 2 * np.einsum(\'lnkm,mlkn->\', t_lnkm, interm)\nExchDisp20 -= 2 * np.einsum(\'lnkm,nklm->\', t_lnkm, interm)\n\nsapt_printer(\'Exch-Disp20\', ExchDisp20)\n\ndisp_timer.stop()\n### End E200 Exchange-Dispersion\n\n\n### Start E200 Induction and Exchange-Induction\n\n# E200Induction and CPHF orbitals\nind_timer = sapt_timer(\'induction\')\n\nCPHF_ra, Ind20_ba = sapt.chf(\'B\', ind=True)\nsapt_printer(\'Ind20,r (A<-B)\', Ind20_ba)\n\nCPHF_sb, Ind20_ab = sapt.chf(\'A\', ind=True)\nsapt_printer(\'Ind20,r (A->B)\', Ind20_ab)\n\nInd20r = Ind20_ba + Ind20_ab\n\n# Exchange-Induction\n\n# A <- B\nCPHFA_ao = sapt.chain_dot(Ci, CPHF_ra.T, Cr.T)\nExchInd20_ab = -2 * np.vdot(CPHFA_ao, Kjj)\nExchInd20_ab -= 2 * np.vdot(CPHFA_ao, sapt.chain_dot(S, Pj, h_A))\nExchInd20_ab -= 2 * np.vdot(CPHFA_ao, sapt.chain_dot(h_B, Pj, S))\n\nExchInd20_ab -= 4 * np.vdot(CPHFA_ao, Jij)\nExchInd20_ab += 2 * np.vdot(CPHFA_ao, Kij)\n\nExchInd20_ab += 2 * np.vdot(CPHFA_ao, sapt.chain_dot(w_B, Pi, S, Pj, S))\nExchInd20_ab += 2 * np.vdot(CPHFA_ao, sapt.chain_dot(S, Pj, S, Pi, w_B))\nExchInd20_ab += 2 * np.vdot(CPHFA_ao, sapt.chain_dot(S, Pj, w_A, Pj, S))\n\nJjij, Kjij = sapt.compute_sapt_JK(Cj, Cj, tensor=sapt.chain_dot(Cj.T, S, Pi, S, Cj))\n\nExchInd20_ab += 4 * np.vdot(CPHFA_ao, Jjij)\nExchInd20_ab -= 2 * np.vdot(CPHFA_ao, sapt.chain_dot(S, Pj, Kij.T))\nExchInd20_ab -= 2 * np.vdot(CPHFA_ao, sapt.chain_dot(Kij, Pj, S))\n\nsapt_printer(\'Exch-Ind20,r (A<-B)\', ExchInd20_ab)\n\n# B <- A\nCPHFB_ao = sapt.chain_dot(Cj, CPHF_sb.T, Cs.T)\nExchInd20_ba = -2 * np.vdot(CPHFB_ao, Kii)\nExchInd20_ba -= 2 * np.vdot(CPHFB_ao, sapt.chain_dot(S, Pi, h_B))\nExchInd20_ba -= 2 * np.vdot(CPHFB_ao, sapt.chain_dot(h_A, Pi, S))\n\nExchInd20_ba -= 4 * np.vdot(CPHFB_ao, Jij)\nExchInd20_ba += 2 * np.vdot(CPHFB_ao, Kij.T)\n\nExchInd20_ba += 2 * np.vdot(CPHFB_ao, sapt.chain_dot(w_A, Pj, S, Pi, S))\nExchInd20_ba += 2 * np.vdot(CPHFB_ao, sapt.chain_dot(S, Pi, S, Pj, w_A))\nExchInd20_ba += 2 * np.vdot(CPHFB_ao, sapt.chain_dot(S, Pi, w_B, Pi, S))\n\nJiji, Kiji = sapt.compute_sapt_JK(Ci, Ci, tensor=sapt.chain_dot(Ci.T, S, Pj, S, Ci))\n\nExchInd20_ba += 4 * np.vdot(CPHFB_ao, Jiji)\nExchInd20_ba -= 2 * np.vdot(CPHFB_ao, sapt.chain_dot(S, Pi, Kij))\nExchInd20_ba -= 2 * np.vdot(CPHFB_ao, sapt.chain_dot(Kij.T, Pi, S))\n\nsapt_printer(\'Exch-Ind20,r (A->B)\', ExchInd20_ba)\nExchInd20r = ExchInd20_ba + ExchInd20_ab\n\nind_timer.stop()\n### End E200 Induction and Exchange-Induction\n\nprint(\'\\nSAPT0 Results\')\nprint(\'-\' * 70)\nsapt_printer(\'Exch10 (S^2)\', Exch100)\nsapt_printer(\'Elst10\', Elst10)\nsapt_printer(\'Disp20\', Disp200)\nsapt_printer(\'Exch-Disp20\', ExchDisp20)\nsapt_printer(\'Ind20,r\', Ind20r)\nsapt_printer(\'Exch-Ind20,r\', ExchInd20r)\n\nprint(\'-\' * 70)\nsapt0 = Exch100 + Elst10 + Disp200 + ExchDisp20 + Ind20r + ExchInd20r\nsapt_printer(\'Total SAPT0\', sapt0)\n'"
Symmetry-Adapted-Perturbation-Theory/helper_SAPT.py,38,"b'""""""\r\nHelper classes and functions for the SAPT directory.\r\n\r\nReferences:\r\n- Equations and algorithms from [Szalewicz:2005:43], [Jeziorski:1994:1887],\r\n[Szalewicz:2012:254], and [Hohenstein:2012:304]\r\n""""""\r\n\r\n__authors__   = ""Daniel G. A. Smith""\r\n__credits__   = [""Daniel G. A. Smith""]\r\n\r\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\r\n__license__   = ""BSD-3-Clause""\r\n__date__      = ""2015-12-01""\r\n\r\nimport numpy as np\r\nimport time\r\nimport psi4\r\n\r\nclass helper_SAPT(object):\r\n\r\n    def __init__(self, dimer, memory=8, algorithm=\'MO\', reference=\'RHF\'):\r\n        print(""\\nInitializing SAPT object...\\n"")\r\n        tinit_start = time.time()\r\n\r\n        # Set a few crucial attributes\r\n        self.alg = algorithm.upper()\r\n        self.reference = reference.upper()\r\n        dimer.reset_point_group(\'c1\')\r\n        dimer.fix_orientation(True)\r\n        dimer.fix_com(True)\r\n        dimer.update_geometry()\r\n        nfrags = dimer.nfragments()\r\n        if nfrags != 2:\r\n            psi4.core.clean()\r\n            raise Exception(""Found %d fragments, must be 2."" % nfrags)\r\n\r\n        # Grab monomers in DCBS\r\n        monomerA = dimer.extract_subsets(1, 2)\r\n        monomerA.set_name(\'monomerA\')\r\n        monomerB = dimer.extract_subsets(2, 1)\r\n        monomerB.set_name(\'monomerB\')\r\n        self.mult_A = monomerA.multiplicity()\r\n        self.mult_B = monomerB.multiplicity()\r\n\r\n        # Compute monomer properties\r\n\r\n        tstart = time.time()\r\n        self.rhfA, self.wfnA = psi4.energy(\'SCF\', return_wfn=True, molecule=monomerA)\r\n        self.V_A = np.asarray(psi4.core.MintsHelper(self.wfnA.basisset()).ao_potential())\r\n        print(""RHF for monomer A finished in %.2f seconds."" % (time.time() - tstart))\r\n\r\n        tstart = time.time()\r\n        self.rhfB, self.wfnB = psi4.energy(\'SCF\', return_wfn=True, molecule=monomerB)\r\n        self.V_B = np.asarray(psi4.core.MintsHelper(self.wfnB.basisset()).ao_potential())\r\n        print(""RHF for monomer B finished in %.2f seconds."" % (time.time() - tstart))\r\n\r\n        # Setup a few variables\r\n        self.memory = memory\r\n        self.nmo = self.wfnA.nmo()\r\n\r\n        # Monomer A\r\n        self.nuc_rep_A = monomerA.nuclear_repulsion_energy()\r\n        self.ndocc_A = self.wfnA.doccpi()[0]\r\n        self.nvirt_A = self.nmo - self.ndocc_A\r\n        if reference == \'ROHF\':\r\n          self.idx_A = [\'i\', \'a\', \'r\']\r\n          self.nsocc_A = self.wfnA.soccpi()[0]\r\n          occA = self.ndocc_A + self.nsocc_A\r\n        else:\r\n          self.idx_A = [\'a\', \'r\']\r\n          self.nsocc_A = 0\r\n          occA = self.ndocc_A \r\n\r\n        self.C_A = np.asarray(self.wfnA.Ca())\r\n        self.Co_A = self.C_A[:, :self.ndocc_A]\r\n        self.Ca_A = self.C_A[:, self.ndocc_A:occA]\r\n        self.Cv_A = self.C_A[:, occA:]\r\n        self.eps_A = np.asarray(self.wfnA.epsilon_a())\r\n\r\n        # Monomer B\r\n        self.nuc_rep_B = monomerB.nuclear_repulsion_energy()\r\n        self.ndocc_B = self.wfnB.doccpi()[0]\r\n        self.nvirt_B = self.nmo - self.ndocc_B\r\n        if reference == \'ROHF\':\r\n          self.idx_B = [\'j\', \'b\', \'s\']\r\n          self.nsocc_B = self.wfnB.soccpi()[0]\r\n          occB = self.ndocc_B + self.nsocc_B\r\n        else:\r\n          self.idx_B = [\'b\', \'s\']\r\n          self.nsocc_B = 0\r\n          occB = self.ndocc_B \r\n\r\n        self.C_B = np.asarray(self.wfnB.Ca())\r\n        self.Co_B = self.C_B[:, :self.ndocc_B]\r\n        self.Ca_B = self.C_B[:, self.ndocc_B:occB]\r\n        self.Cv_B = self.C_B[:, occB:]\r\n        self.eps_B = np.asarray(self.wfnB.epsilon_a())\r\n\r\n        # Dimer\r\n        self.nuc_rep = dimer.nuclear_repulsion_energy() - self.nuc_rep_A - self.nuc_rep_B\r\n        self.vt_nuc_rep = self.nuc_rep / ((2 * self.ndocc_A + self.nsocc_A)\r\n                                           * (2 * self.ndocc_B + self.nsocc_B))\r\n\r\n        # Make slice, orbital, and size dictionaries\r\n        if reference == \'ROHF\':\r\n          self.slices = {\r\n                       \'i\': slice(0, self.ndocc_A),\r\n                       \'a\': slice(self.ndocc_A, occA),\r\n                       \'r\': slice(occA, None),\r\n                       \'j\': slice(0, self.ndocc_B),\r\n                       \'b\': slice(self.ndocc_B, occB),\r\n                       \'s\': slice(occB, None)\r\n                      }\r\n\r\n          self.orbitals = {\'i\': self.Co_A,\r\n                           \'a\': self.Ca_A,\r\n                           \'r\': self.Cv_A,\r\n                           \'j\': self.Co_B,\r\n                           \'b\': self.Ca_B,\r\n                           \'s\': self.Cv_B\r\n                        }\r\n\r\n          self.sizes = {\'i\': self.ndocc_A,\r\n                        \'a\': self.nsocc_A,\r\n                        \'r\': self.nvirt_A,\r\n                        \'j\': self.ndocc_B,\r\n                        \'b\': self.nsocc_B,\r\n                        \'s\': self.nvirt_B}\r\n\r\n        else:\r\n          self.slices = {\r\n                       \'a\': slice(0, self.ndocc_A),\r\n                       \'r\': slice(occA, None),\r\n                       \'b\': slice(0, self.ndocc_B),\r\n                       \'s\': slice(occB, None)\r\n                      }\r\n\r\n          self.orbitals = {\'a\': self.Co_A,\r\n                           \'r\': self.Cv_A,\r\n                           \'b\': self.Co_B,\r\n                           \'s\': self.Cv_B\r\n                        }\r\n\r\n          self.sizes = {\'a\': self.ndocc_A,\r\n                        \'r\': self.nvirt_A,\r\n                        \'b\': self.ndocc_B,\r\n                        \'s\': self.nvirt_B}\r\n\r\n        # Compute size of ERI tensor in GB\r\n        self.dimer_wfn = psi4.core.Wavefunction.build(dimer, psi4.core.get_global_option(\'BASIS\'))\r\n        mints = psi4.core.MintsHelper(self.dimer_wfn.basisset())\r\n        self.mints = mints\r\n        ERI_Size = (self.nmo ** 4) * 8.e-9\r\n        memory_footprint = ERI_Size * 4\r\n        if memory_footprint > self.memory:\r\n            psi4.core.clean()\r\n            raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\r\n                            limit of %4.2f GB."" % (memory_footprint, self.memory))\r\n\r\n        # Integral generation from Psi4\'s MintsHelper\r\n        print(\'Building ERI tensor...\')\r\n        tstart = time.time()\r\n        # Leave ERI as a Psi4 Matrix\r\n        self.I = np.asarray(self.mints.ao_eri()).swapaxes(1,2)\r\n        print(\'...built ERI tensor in %.3f seconds.\' % (time.time() - tstart))\r\n        print(""Size of the ERI tensor is %4.2f GB, %d basis functions."" % (ERI_Size, self.nmo))\r\n        self.S = np.asarray(self.mints.ao_overlap())\r\n\r\n        # Save additional rank 2 tensors\r\n        self.V_A_BB = np.einsum(\'ui,vj,uv->ij\', self.C_B, self.C_B, self.V_A)\r\n        self.V_A_AB = np.einsum(\'ui,vj,uv->ij\', self.C_A, self.C_B, self.V_A)\r\n        self.V_B_AA = np.einsum(\'ui,vj,uv->ij\', self.C_A, self.C_A, self.V_B)\r\n        self.V_B_AB = np.einsum(\'ui,vj,uv->ij\', self.C_A, self.C_B, self.V_B)\r\n\r\n        self.S_AB = np.einsum(\'ui,vj,uv->ij\', self.C_A, self.C_B, self.S)\r\n\r\n        if self.alg == ""AO"":\r\n            tstart = time.time()\r\n            aux_basis = psi4.core.BasisSet.build(self.dimer_wfn.molecule(), ""DF_BASIS_SCF"",\r\n                                            psi4.core.get_option(""SCF"", ""DF_BASIS_SCF""),\r\n                                            ""JKFIT"", psi4.core.get_global_option(\'BASIS\'),\r\n                                            puream=self.dimer_wfn.basisset().has_puream())\r\n\r\n            self.jk = psi4.core.JK.build(self.dimer_wfn.basisset(), aux_basis)\r\n            self.jk.set_memory(int(memory * 1e9))\r\n            self.jk.initialize()\r\n            print(""\\n...initialized JK objects in %5.2f seconds."" % (time.time() - tstart))\r\n\r\n        print(""\\n...finished initializing SAPT object in %5.2f seconds."" % (time.time() - tinit_start))\r\n\r\n    # Compute MO ERI tensor (v) on the fly\r\n    def v(self, string):\r\n        if len(string) != 4:\r\n            psi4.core.clean()\r\n            raise Exception(\'v: string %s does not have 4 elements\' % string)\r\n\r\n        # ERI\'s from mints are of type (11|22) - need <12|12>\r\n        V = np.einsum(\'pA,pqrs->Aqrs\', self.orbitals[string[0]], self.I)\r\n        V = np.einsum(\'qB,Aqrs->ABrs\', self.orbitals[string[1]], V)\r\n        V = np.einsum(\'rC,ABrs->ABCs\', self.orbitals[string[2]], V)\r\n        V = np.einsum(\'sD,ABCs->ABCD\', self.orbitals[string[3]], V)\r\n        return V\r\n\r\n    # Grab MO overlap matrices\r\n    def s(self, string):\r\n        if len(string) != 2:\r\n            psi4.core.clean()\r\n            raise Exception(\'S: string %s does not have 2 elements.\' % string)\r\n\r\n        for alpha in \'ijab\':\r\n            if (alpha in string) and (self.sizes[alpha] == 0):\r\n                return np.array([0]).reshape(1,1)\r\n\r\n        s1 = string[0]\r\n        s2 = string[1]\r\n\r\n        # Compute on the fly\r\n        return (self.orbitals[string[0]].T).dot(self.S).dot(self.orbitals[string[1]])\r\n        #return np.einsum(\'ui,vj,uv->ij\', self.orbitals[string[0]], self.orbitals[string[1]], self.S)\r\n\r\n    # Grab epsilons, reshape if requested\r\n    def eps(self, string, dim=1):\r\n        if len(string) != 1:\r\n            psi4.core.clean()\r\n            raise Exception(\'Epsilon: string %s does not have 1 element.\' % string)\r\n\r\n        shape = (-1,) + tuple([1] * (dim - 1))\r\n\r\n        if (string == \'i\') or (string == \'a\') or (string == \'r\'):\r\n            return self.eps_A[self.slices[string]].reshape(shape)\r\n        elif (string == \'j\') or (string == \'b\') or (string == \'s\'):\r\n            return self.eps_B[self.slices[string]].reshape(shape)\r\n        else:\r\n            psi4.core.clean()\r\n            raise Exception(\'Unknown orbital type in eps: %s.\' % string)\r\n\r\n    # Grab MO potential matrices\r\n    def potential(self, string, side):\r\n        if len(string) != 2:\r\n            psi4.core.clean()\r\n            raise Exception(\'Potential: string %s does not have 2 elements.\' % string)\r\n\r\n        s1 = string[0]\r\n        s2 = string[1]\r\n\r\n        # Two separate cases\r\n        if side == \'A\':\r\n            # Compute on the fly\r\n            return (self.orbitals[string[0]].T).dot(self.V_A).dot(self.orbitals[string[1]])\r\n            #return np.einsum(\'ui,vj,uv->ij\', self.orbitals[s1], self.orbitals[s2], self.V_A)\r\n\r\n        elif side == \'B\':\r\n            # Compute on the fly\r\n            return (self.orbitals[string[0]].T).dot(self.V_B).dot(self.orbitals[string[1]])\r\n            #return np.einsum(\'ui,vj,uv->ij\', self.orbitals[s1], self.orbitals[s2], self.V_B)\r\n        else:\r\n            psi4.core.clean()\r\n            raise Exception(\'helper_SAPT.potential side must be either A or B, not %s.\' % side)\r\n\r\n    # Compute V tilde, Index as V_{1,2}^{3,4}\r\n    def vt(self, string):\r\n        if len(string) != 4:\r\n            psi4.core.clean()\r\n            raise Exception(\'Compute tilde{V}: string %s does not have 4 elements\' % string)\r\n\r\n        for alpha in \'ijab\':\r\n            if (alpha in string) and (self.sizes[alpha] == 0):\r\n                return np.array([0]).reshape(1,1,1,1)\r\n\r\n        # Grab left and right strings\r\n        s_left = string[0] + string[2]\r\n        s_right = string[1] + string[3]\r\n\r\n        # ERI term\r\n        V = self.v(string)\r\n        # Potential A\r\n        S_A = self.s(s_left)\r\n        V_A = self.potential(s_right, \'A\') / (2 * self.ndocc_A + self.nsocc_A)\r\n        V += np.einsum(\'ik,jl->ijkl\', S_A, V_A)\r\n\r\n        # Potential B\r\n        S_B = self.s(s_right)\r\n        V_B = self.potential(s_left, \'B\') / (2 * self.ndocc_B + self.nsocc_B)\r\n        #print s_right, np.abs(V_B).sum()\r\n        V += np.einsum(\'ik,jl->ijkl\', V_B, S_B)\r\n\r\n        # Nuclear\r\n        V += np.einsum(\'ik,jl->ijkl\', S_A, S_B) * self.vt_nuc_rep\r\n\r\n        return V\r\n\r\n    # Compute CPHF orbitals\r\n    def chf(self, monomer, ind=False):\r\n        if monomer not in [\'A\', \'B\']:\r\n            psi4.core.clean()\r\n            raise Exception(\'%s is not a valid monomer for CHF.\' % monomer)\r\n\r\n        if self.reference == \'ROHF\':\r\n            psi4.core.clean()\r\n            raise Exception(\'CPHF for a ROHF reference not implemented yet.\')\r\n\r\n        if monomer == \'A\':\r\n            # Form electrostatic potential\r\n            w_n = 2 * np.einsum(\'saba->bs\', self.v(\'saba\'))\r\n            w_n += self.V_A_BB[self.slices[\'b\'], self.slices[\'s\']]\r\n            eps_ov = (self.eps(\'b\', dim=2) - self.eps(\'s\'))\r\n\r\n            # Set terms\r\n            v_term1 = \'sbbs\'\r\n            v_term2 = \'sbsb\'\r\n            no, nv = self.ndocc_B, self.nvirt_B\r\n\r\n        if monomer == \'B\':\r\n            w_n = 2 * np.einsum(\'rbab->ar\', self.v(\'rbab\'))\r\n            w_n += self.V_B_AA[self.slices[\'a\'], self.slices[\'r\']]\r\n            eps_ov = (self.eps(\'a\', dim=2) - self.eps(\'r\'))\r\n            v_term1 = \'raar\'\r\n            v_term2 = \'rara\'\r\n            no, nv = self.ndocc_A, self.nvirt_A\r\n\r\n        # Form A matrix (LHS)\r\n        voov = self.v(v_term1)\r\n        v_vOoV = 2 * voov - self.v(v_term2).swapaxes(2, 3)\r\n        v_ooaa = voov.swapaxes(1, 3)\r\n        v_vVoO = 2 * v_ooaa - v_ooaa.swapaxes(2, 3)\r\n        A_ovOV = np.einsum(\'vOoV->ovOV\', v_vOoV + v_vVoO.swapaxes(1, 3))\r\n\r\n        # Mangled the indices so badly with strides we need to copy back to C contiguous\r\n        nov = nv * no\r\n        A_ovOV = A_ovOV.reshape(nov, nov).copy(order=\'C\')\r\n        A_ovOV[np.diag_indices_from(A_ovOV)] -= eps_ov.ravel()\r\n\r\n        # Call DGESV, need flat ov array\r\n        B_ov = -1 * w_n.ravel()\r\n        t = np.linalg.solve(A_ovOV, B_ov)\r\n        # Our notation wants vo array\r\n        t = t.reshape(no, nv).T\r\n\r\n        if ind:\r\n            # E200 Induction energy is free at the point\r\n            e20_ind = 2 * np.einsum(\'vo,ov->\', t, w_n)\r\n            return (t, e20_ind)\r\n        else:\r\n            return t\r\n\r\n    def compute_sapt_JK(self, Cleft, Cright, tensor=None):\r\n\r\n        if self.alg != ""AO"":\r\n            raise Exception(""Attempted a call to JK builder in an MO algorithm"")\r\n\r\n        if self.reference == ""ROHF"":\r\n            raise Exception(""AO algorithm not yet implemented for ROHF reference."")\r\n\r\n        return_single = False\r\n        if not isinstance(Cleft, (list, tuple)):\r\n            Cleft = [Cleft]\r\n            return_single = True\r\n        if not isinstance(Cright, (list, tuple)):\r\n            Cright = [Cright]\r\n            return_single = True\r\n        if (not isinstance(tensor, (list, tuple))) and (tensor is not None):\r\n            tensor = [tensor]\r\n            return_single = True\r\n\r\n        if len(Cleft) != len(Cright):\r\n            raise Exception(""Cleft list is not the same length as Cright list"")\r\n\r\n        zero_append = []\r\n        num_compute = 0\r\n\r\n        for num in range(len(Cleft)):\r\n            Cl = Cleft[num]\r\n            Cr = Cright[num]\r\n\r\n            if (Cr.shape[1] == 0) or (Cl.shape[1] == 0):\r\n                zero_append.append(num)\r\n                continue\r\n\r\n            if tensor is not None:\r\n                mol = Cl.shape[1]\r\n                mor = Cr.shape[1]\r\n                \r\n                if (tensor[num].shape[0] != mol) or (tensor[num].shape[1] != mor):\r\n                    raise Exception(""compute_sapt_JK: Tensor size does not match Cl (%d) /Cr (%d) : %s"" %\r\n                                                            (mol, mor, str(tensor[num].shape)))\r\n                if mol < mor:\r\n                    Cl = np.dot(Cl, tensor[num])\r\n                else:\r\n                    Cr = np.dot(Cr, tensor[num].T)\r\n\r\n            Cl = psi4.core.Matrix.from_array(Cl)\r\n            Cr = psi4.core.Matrix.from_array(Cr)\r\n\r\n            self.jk.C_left_add(Cl)\r\n            self.jk.C_right_add(Cr)\r\n            num_compute += 1\r\n        \r\n        self.jk.compute() \r\n\r\n        J_list = []\r\n        K_list = []\r\n        for num in range(num_compute):\r\n            J_list.append(np.array(self.jk.J()[num])) \r\n            K_list.append(np.array(self.jk.K()[num])) \r\n\r\n        self.jk.C_clear()\r\n\r\n        z = np.zeros((self.nmo, self.nmo))\r\n        for num in zero_append:\r\n            J_list.insert(num, z)\r\n            K_list.insert(num, z)\r\n\r\n        if return_single:\r\n            return J_list[0], K_list[0]\r\n        else:\r\n            return J_list, K_list\r\n\r\n    def chain_dot(self, *dot_list):\r\n        result = dot_list[0]\r\n        for x in range(len(dot_list) - 1):\r\n            result = np.dot(result, dot_list[x + 1])\r\n        return result\r\n\r\n# End SAPT helper\r\n\r\nclass sapt_timer(object):\r\n    def __init__(self, name):\r\n        self.name = name\r\n        self.start = time.time()\r\n        print(\'\\nStarting %s...\' % name)\r\n\r\n    def stop(self):\r\n        t = time.time() - self.start\r\n        print(\'...%s took a total of % .2f seconds.\' % (self.name, t))\r\n\r\n\r\ndef sapt_printer(line, value):\r\n    spacer = \' \' * (20 - len(line))\r\n    print(line + spacer + \'% 16.8f mH  % 16.8f kcal/mol\' % (value * 1000, value * 627.509))\r\n# End SAPT helper\r\n'"
tests/addons.py,0,"b'import sys\nimport pytest\n\n\ndef _plugin_import(plug):\n    import sys\n    if sys.version_info >= (3, 4):\n        from importlib import util\n        plug_spec = util.find_spec(plug)\n    else:\n        import pkgutil\n        plug_spec = pkgutil.find_loader(plug)\n    if plug_spec is None:\n        return False\n    else:\n        return True\n\n\ndef is_psi4_new_enough(version_feature_introduced):\n    if not _plugin_import(\'psi4\'):\n        return False\n    import psi4\n    from pkg_resources import parse_version\n    return parse_version(psi4.__version__) >= parse_version(version_feature_introduced)\n\n\ndef is_numpy_new_enough(version_feature_introduced):\n    if not _plugin_import(\'numpy\'):\n        return False\n    import numpy\n    from pkg_resources import parse_version\n    return parse_version(numpy.version.version) >= parse_version(version_feature_introduced)\n\n\nusing_scipy = pytest.mark.skipif(_plugin_import(\'scipy\') is False,\n                                reason=\'Not detecting module scipy. Install package if necessary and add to envvar PYTHONPATH\')\n\nusing_psi4_libxc = pytest.mark.skipif(is_psi4_new_enough(""1.2a1.dev100"") is False,\n                                reason=""Psi4 does not include DFT rewrite to use Libxc. Update to development head"")\n\nusing_psi4_efpmints = pytest.mark.skipif(is_psi4_new_enough(""1.2a1.dev507"") is False,\n                                reason=""Psi4 does not include EFP integrals in mints. Update to development head"")\n\nusing_psi4_python_integral_deriv = pytest.mark.skipif(is_psi4_new_enough(""1.2a1.dev1000"") is False,\n                                reason=""Psi4 does not include derivatives of integrals exported to python. Update to development head"")\n\nusing_numpy_113 = pytest.mark.skipif(is_numpy_new_enough(""1.13.0"") is False,\n                                reason=\'NumPy does not include 1.13 features. Update package and add to envvar PYTHONPATH\')\n\nusing_matplotlib = pytest.mark.skipif(_plugin_import(\'matplotlib\') is False,\n                                reason=\'Note detecting module matplotlib. Install package if necessary and add to envvar PYTHONPATH\')\n\nusing_pylibefp = pytest.mark.skipif(_plugin_import(\'pylibefp\') is False,\n                                reason=\'Not detecting module pylibefp. Install package if necessary and add to envvar PYTHONPATH\')\n\nusing_py3 = pytest.mark.skipif(sys.version_info < (3, 0),\n                                reason=\'Python does not use Py3 features, hurrah!\')\n'"
tests/conftest.py,0,"b'import pytest\n\n\n@pytest.fixture(scope=""session"", autouse=True)\ndef set_up_overall(request):\n    try:\n        import pytest_shutil\n    except ImportError:\n        raise Exception(""Please ``pip install pytest-shutil`` to run the tests."")\n\n\n@pytest.fixture(scope=""function"", autouse=True)\ndef set_up():\n    pass\n\n\ndef tear_down():\n    pass\n'"
tests/test_RESP.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'One-Electron-Property/Restrained-Electrostatic-Potential'\n\ndef test_example(workspace):\n    exe_py(workspace, tdir,'example')\n\ndef test_example2(workspace):\n    exe_py(workspace, tdir,'example2')\n"""
tests/test_RI_CC.py,0,"b'from addons import *\nfrom utils import *\n\n\ntdir = \'Coupled-Cluster\'\n\n\ndef test_CCSD_DIIS(workspace):\n    exe_py(workspace, tdir+""/Spin_Orbitals/CCSD"", \'CCSD_DIIS\')\n\n\ndef test_CCSD(workspace):\n    exe_py(workspace, tdir+""/Spin_Orbitals/CCSD"", \'CCSD\')\n\n\ndef test_CCSD_T(workspace):\n    exe_py(workspace, tdir+""/Spin_Orbitals/CCSD"", \'CCSD_T\')\n\n\ndef test_EOM_CCSD(workspace):\n    exe_py(workspace, tdir+\'/RHF\',\'EOM_CCSD\')\n\n\n#def test_TD_CCSD(workspace):\n#    exe_py(workspace, tdir, \'TD-CCSD\')\n'"
tests/test_RI_CEPA.py,0,"b""from addons import *\nfrom utils import *\nimport pytest\n\n\ntdir = 'Coupled-Electron-Pair-Approximation'\n\n\ndef test_LCCD(workspace):\n    exe_py(workspace, tdir, 'LCCD')\n\n\ndef test_LCCSD(workspace):\n    exe_py(workspace, tdir, 'LCCSD')\n\n\ndef test_OLCCD(workspace):\n    exe_py(workspace, tdir, 'OLCCD')\n\ndef test_DFLCCD(workspace):\n    exe_py(workspace, tdir, 'DF-LCCD')\n\ndef test_DFLCCSD(workspace):\n    exe_py(workspace, tdir, 'DF-LCCSD')\n\n"""
tests/test_RI_CI.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Configuration-Interaction'\n\n\ndef test_CI_DL(workspace):\n    exe_py(workspace, tdir, 'CI_DL')\n\n\n@using_scipy\ndef test_CISD(workspace):\n    exe_py(workspace, tdir, 'CISD')\n\n\ndef test_CIS(workspace):\n    exe_py(workspace, tdir, 'CIS')\n\n\n@using_scipy\ndef test_FCI(workspace):\n    exe_py(workspace, tdir, 'FCI')\n"""
tests/test_RI_EP.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Electron-Propagator'\n\n\ndef test_EP2(workspace):\n    exe_py(workspace, tdir, 'EP2')\n\n\ndef test_EP2_SO(workspace):\n    exe_py(workspace, tdir, 'EP2_SO')\n\n\ndef test_EP3_SO(workspace):\n    exe_py(workspace, tdir, 'EP3_SO')\n"""
tests/test_RI_PT.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Moller-Plesset'\n\n\ndef test_DF_MP2(workspace):\n    exe_py(workspace, tdir, 'DF-MP2')\n\n\ndef test_DF_MP2_NAF(workspace):\n    exe_py(workspace, tdir, 'DF-MP2_NAF')\n\n\ndef test_MP2(workspace):\n    exe_py(workspace, tdir, 'MP2')\n\n\ndef test_sDF_MP2(workspace):\n    exe_py(workspace, tdir, 'sDF-MP2')\n\n\ndef test_MP3(workspace):\n    exe_py(workspace, tdir, 'MP3')\n\n\ndef test_MP3_SO(workspace):\n    exe_py(workspace, tdir, 'MP3-SO')\n\n\ndef test_MPn(workspace):\n    exe_py(workspace, tdir, 'MPn')\n\n\ndef test_MP2_Gradient(workspace):\n    exe_py(workspace, tdir, 'MP2_Gradient')\n\ndef test_MP2_Hessian(workspace):\n    exe_py(workspace, tdir, 'MP2_Hessian')\n"""
tests/test_RI_SAPT.py,0,"b""import pytest\nfrom addons import *\nfrom utils import *\n\n\ntdir = 'Symmetry-Adapted-Perturbation-Theory'\n\n\ndef test_SAPT0ao(workspace):\n    exe_py(workspace, tdir, 'SAPT0ao')\n\n\ndef test_SAPT0(workspace):\n    exe_py(workspace, tdir, 'SAPT0')\n\n\n@pytest.mark.long\ndef test_SAPT0_ROHF(workspace):\n    exe_py(workspace, tdir, 'SAPT0_ROHF')\n\n\ndef test_SAPT0_no_S2(workspace):\n    exe_py(workspace, tdir, 'SAPT0_no_S2')\n"""
tests/test_RI_SCF.py,0,"b""from addons import *\nfrom utils import *\nimport pytest\n\n\ntdir = 'Self-Consistent-Field'\n\n\ndef test_RHF_DIIS(workspace):\n    exe_py(workspace, tdir, 'RHF_DIIS')\n\n\ndef test_RHF_libJK(workspace):\n    exe_py(workspace, tdir, 'RHF_libJK')\n\n\ndef test_RHF(workspace):\n    exe_py(workspace, tdir, 'RHF')\n\n\n@using_psi4_python_integral_deriv\ndef test_RHF_Gradient(workspace):\n    exe_py(workspace, tdir, 'RHF_Gradient')\n\n\n@using_psi4_python_integral_deriv\ndef test_RHF_Hessian(workspace):\n    exe_py(workspace, tdir, 'RHF_Hessian')\n\n\n@using_psi4_efpmints\n@using_pylibefp\ndef test_RHF_EFP(workspace):\n    exe_py(workspace, tdir, 'RHF_EFP')\n\n\ndef test_RHF_symmetry(workspace):\n    exe_py(workspace, tdir, 'RHF_symmetry')\n\n\ndef test_ROHF_libJK(workspace):\n    exe_py(workspace, tdir, 'ROHF_libJK')\n\n\ndef test_SORHF_iterative(workspace):\n    exe_py(workspace, tdir, 'SORHF_iterative')\n\n\ndef test_SORHF(workspace):\n    exe_py(workspace, tdir, 'SORHF')\n\n\n@using_scipy\ndef test_SOROHF_iterative(workspace):\n    exe_py(workspace, tdir, 'SOROHF_iterative')\n\n\ndef test_SOROHF(workspace):\n    exe_py(workspace, tdir, 'SOROHF')\n\n\ndef test_SOUHF_iterative(workspace):\n    exe_py(workspace, tdir, 'SOUHF_iterative')\n\n\ndef test_SOUHF(workspace):\n    exe_py(workspace, tdir, 'SOUHF')\n\n\ndef test_UHF_libJK(workspace):\n    exe_py(workspace, tdir, 'UHF_libJK')\n"""
tests/test_RI_response.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Response-Theory'\n\n\ndef test_beta(workspace):\n    exe_py(workspace, tdir, 'Self-Consistent-Field/beta')\n\n\ndef test_CPHF(workspace):\n    exe_py(workspace, tdir, 'Self-Consistent-Field/CPHF')\n\n\ndef test_helper_CPHF(workspace):\n    exe_py(workspace, tdir, 'Self-Consistent-Field/helper_CPHF')\n\n\ndef test_TDHF(workspace):\n    exe_py(workspace, tdir, 'Self-Consistent-Field/TDHF')\n\n\ndef test_polar_cc(workspace):\n    exe_py(workspace, tdir, 'Coupled-Cluster/RHF/polar')\n\n\ndef test_optrot_cc(workspace):\n    exe_py(workspace, tdir, 'Coupled-Cluster/RHF/optrot')\n"""
tests/test_TU_01.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Tutorials/01_Psi4NumPy-Basics'\n\n\ndef test_1a(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '1a_Getting-Started')\n\n\n@using_matplotlib\ndef test_1b(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '1b_molecule')\n\n\ndef test_1c(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '1c_psi4-numpy-datasharing')\n\n\ndef test_1d(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '1d_wavefunction')\n\n\ndef test_1e(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '1e_mints-helper')\n\n\ndef test_1f(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '1f_tensor-manipulation')\n\n\ndef test_1g(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '1g_basis-sets')\n"""
tests/test_TU_03.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Tutorials/03_Hartree-Fock'\n\n\ndef test_3a(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '3a_restricted-hartree-fock')\n\n\ndef test_3b(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '3b_rhf-diis')\n\n\ndef test_3c(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '3c_unrestricted-hartree-fock')\n\n\ndef test_df(workspace):\n    exe_scriptified_ipynb(workspace, tdir, 'density-fitting')\n"""
tests/test_TU_04.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Tutorials/04_Density_Functional_Theory'\n\n\n@using_matplotlib\n@using_psi4_libxc\ndef test_4a(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '4a_DFT_Grid')\n\n\n@using_psi4_libxc\ndef test_4b(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '4b_LDA_kernel')\n\n\n@using_psi4_libxc\ndef test_4d(workspace):\n    copy_helpers(workspace, tdir, files=['ks_helper.py'])\n    exe_scriptified_ipynb(workspace, tdir, '4d_VV10')\n\n\n@using_matplotlib\n@using_psi4_libxc\ndef test_4e(workspace):\n    copy_helpers(workspace, tdir, files=['ks_helper.py'])\n    exe_scriptified_ipynb(workspace, tdir, '4e_GRAC')\n"""
tests/test_TU_05.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Tutorials/05_Moller-Plesset'\n\n\ndef test_5a(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '5a_conventional-mp2')\n\n\ndef test_5b(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '5b_density-fitted-mp2')\n"""
tests/test_TU_06.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Tutorials/06_Molecular_Properties'\n\n\ndef test_6a(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '6a_CP-SCF')\n\n\ndef test_6b(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '6b_first_hyperpolarizability')\n"""
tests/test_TU_07.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Tutorials/07_Symmetry_Adapted_Perturbation_Theory'\n\n\ndef test_7a(workspace):\n    copy_helpers(workspace, tdir, files=['helper_SAPT.py'])\n    exe_scriptified_ipynb(workspace, tdir, '7a_sapt0_mo')\n\n\ndef test_7b(workspace):\n    copy_helpers(workspace, tdir, files=['helper_SAPT.py'])\n    exe_scriptified_ipynb(workspace, tdir, '7b_sapt0_ao')\n"""
tests/test_TU_08.py,0,"b""import pytest\nfrom addons import *\nfrom utils import *\n\n\ntdir = 'Tutorials/08_CEPA0_and_CCD'\n\n\n@using_numpy_113\ndef test_8a(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '8a_Intro_to_spin_orbital_postHF')\n\n\n@pytest.mark.long\n@using_numpy_113\ndef test_8b(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '8b_CEPA0_and_CCD')\n"""
tests/test_TU_09.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Tutorials/09_Configuration_Interaction'\n\n\n@using_numpy_113\ndef test_9a(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '9a_cis')\n"""
tests/test_TU_10.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Tutorials/10_Orbital_Optimized_Methods'\n\n\n@using_numpy_113\n@using_scipy\ndef test_10a(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '10a_orbital-optimized-mp2')\n"""
tests/test_TU_11.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Tutorials/11_Integrals'\n\n\ndef test_11a(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '11a_1e_Integrals')\n\n\ndef test_11b(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '11b_Appendix')\n"""
tests/test_TU_12.py,0,"b""from addons import *\nfrom utils import *\n\n\ntdir = 'Tutorials/12_MD'\n\n@using_matplotlib\ndef test_12a(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '12a_basics')\n\n@using_matplotlib\n@using_scipy\ndef test_12b(workspace):\n    exe_scriptified_ipynb(workspace, tdir, '12b_ewald')\n\n"""
tests/utils.py,0,"b'import os\nimport re\nimport shutil\nimport tempfile\nfrom contextlib import contextmanager\n\n\nbase_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n\n\n@contextmanager\ndef uplusx(fd):\n    """"""Context Manager to turn ``fd`` executable, then reset it to rw-rw-r--""""""\n    try:\n        os.chmod(fd, 0o744)\n        yield fd\n    finally:\n        os.chmod(fd, 0o664)\n\n\ndef exe_py(workspace, tdir, py):\n    script = base_dir + \'/\' + tdir + \'/\' + py + \'.py\'\n    workspace.run(\'python \' + script)\n\n\ndef exe_scriptified_ipynb(workspace, tdir, ipynb):\n    script = base_dir + \'/\' + tdir + \'/\' + ipynb + \'.ipynb\'\n    path = workspace.workspace\n    workspace.run(\'jupyter nbconvert --to script \' + script + \' --output-dir=\' + path)\n    script_py = path + \'/\' + ipynb + \'.py\'\n    sed_inplace(script_py,\n                r""""""get_ipython\\(\\).magic\\(u?\'matplotlib inline\'\\)"""""",\n                r""""""# <<<  Jupyter magic  >>>  get_ipython().magic(\'matplotlib inline\')\\nimport matplotlib as mpl; mpl.use(\'Agg\')"""""")\n    sed_inplace(script_py,\n                r""""""get_ipython\\(\\).magic\\(u?\'matplotlib notebook\'\\)"""""",\n                r""""""# <<<  Jupyter magic  >>>  get_ipython().magic(\'matplotlib notebook\')\\nimport matplotlib as mpl; mpl.use(\'Agg\')"""""")\n    sed_inplace(script_py,\n                r""""""get_ipython\\(\\).magic\\(u?[\'""]timeit """""",\n                r""""""# <<<  Jupyter magic  >>>"""""")\n    sed_inplace(script_py,\n                r""""""get_ipython\\(\\).run_line_magic\\(u?\'matplotlib\', \'inline\'\\)"""""",\n                r""""""# <<<  Jupyter magic  >>>  get_ipython().run_line_magic(\'matplotlib\', \'inline\')\\nimport matplotlib as mpl; mpl.use(\'Agg\')"""""")\n    sed_inplace(script_py,\n                r""""""get_ipython\\(\\).run_line_magic\\(u?\'matplotlib\', \'notebook\'\\)"""""",\n                r""""""# <<<  Jupyter magic  >>>  get_ipython().run_line_magic(\'matplotlib\', \'notebook\')\\nimport matplotlib as mpl; mpl.use(\'Agg\')"""""")\n    sed_inplace(script_py,\n                r""""""get_ipython\\(\\).run_line_magic\\(u?\'timeit\'"""""",\n                r""""""# <<<  Jupyter magic  >>> get_ipython().run_line_magic(\'timeit\'"""""")\n    # Allow use of __file__ for original notebook path.\n    sed_inplace(script_py,\n                r""""""__file__"""""",\n                """"""\'{}\'"""""".format(os.path.abspath(script)))\n    workspace.run(\'python \' + script_py)\n\n\ndef copy_helpers(workspace, tdir, files):\n    from_dir = base_dir + \'/\' + tdir + \'/\'\n    for fl in files:\n        shutil.copy(from_dir + fl, workspace.workspace)\n\n\n# from https://stackoverflow.com/a/31499114\ndef sed_inplace(filename, pattern, repl):\n    r""""""Perform the pure-Python equivalent of in-place `sed` substitution: e.g.,\n    `sed -i -e \'s/\'${pattern}\'/\'${repl}\' ""${filename}""`.\n\n    Examples\n    --------\n    sed_inplace(\'/etc/apt/sources.list\', r\'^\\# deb\', \'deb\')\n\n    """"""\n    # For efficiency, precompile the passed regular expression.\n    pattern_compiled = re.compile(pattern)\n\n    # For portability, NamedTemporaryFile() defaults to mode ""w+b"" (i.e., binary\n    # writing with updating). This is usually a good thing. In this case,\n    # however, binary writing imposes non-trivial encoding constraints trivially\n    # resolved by switching to text writing. Let\'s do that.\n    with tempfile.NamedTemporaryFile(mode=\'w\', delete=False) as tmp_file:\n        with open(filename) as src_file:\n            for line in src_file:\n                tmp_file.write(pattern_compiled.sub(repl, line))\n\n    # Overwrite the original file with the munged temporary file in a\n    # manner preserving file attributes (e.g., permissions).\n    shutil.copystat(filename, tmp_file.name)\n    shutil.move(tmp_file.name, filename)\n'"
Coupled-Cluster/RHF/EOM_CCSD.py,12,"b'""""""\nA Psi4 input script to compute excitation energies using EOM CCSD.\nThis implementation shows how to use the Davidson method to partially\ndiagonalize the (large) effective Hamiltonian matrix in order to find the lowest\nfew excited states in the context of the EOM_CCSD method.\n\nA description of the Davidson algorithm can be found in Daniel Crawford\'s\nprogramming projects (#13)\nhttps://github.com/CrawfordGroup/ProgrammingProjects/tree/master/Project%2313\n\nSpin orbital sigma equations can be found in I. Shavitt and R. J. Bartlett,\n""Many-Body Methods in Chemistry and Physics: MBPT and Coupled-Cluster Theory"".\nCambridge University Press, 2009.\n\nSpecial thanks to Ashutosh Kumar for Hbar components and help with spin\nadaptation.\n""""""\n\n__authors__ = ""Andrew M. James""\n__credits__ = [""T. Daniel Crawford"", ""Ashutosh Kumar"", ""Andrew M. James""]\n__copyright__ = ""(c) 2017, The Psi4Numpy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2018-1-17""\n\nfrom helper_ccenergy import *\nfrom helper_cchbar import *\nfrom helper_cclambda import *\nfrom helper_cceom import *\nimport psi4\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, threshold=200, suppress=True)\n\n# Psi4 setup\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nnoreorient\nsymmetry c1\n"""""")\n\n# EOM options\ncompare_psi4 = True\nnroot = 3\nnvec_per_root = 30\ne_tol = 1.0e-6\nmax_iter = 80\n\n# roots per irrep must be set to do the eom calculation with psi4\npsi4.set_options({\'basis\': \'cc-pvdz\', \'roots_per_irrep\': [nroot]})\n\n# Compute CCSD energy for required integrals and T-amplitudes\nrhf_e, rhf_wfn = psi4.energy(\'SCF\', return_wfn=True)\nccsd = HelperCCEnergy(mol, rhf_e, rhf_wfn)\nccsd.compute_energy()\n\nccsd_cor_e = ccsd.ccsd_corr_e\nccsd_tot_e = ccsd.ccsd_e\nprint(""\\n"")\nprint(""{}{}"".format(\'Final CCSD correlation energy:\'.ljust(30, \'.\'),\n                    ""{:16.15f}"".format(ccsd_cor_e).rjust(20, \'.\')))\nprint(""{}{}"".format(\'Total CCSD energy:\'.ljust(30, \'.\'),\n                    ""{:16.15f}"".format(ccsd_tot_e).rjust(20, \',\')))\n\ncchbar = HelperCCHbar(ccsd)\n\n# build CIS guess\nndocc = ccsd.ndocc\nnvir = ccsd.nvirt\nnov = ndocc * nvir\nnoovv = nov * nov\nprint(""ndocc = {}"".format(ndocc))\nprint(""nvir = {}"".format(nvir))\nprint(""nov = {}"".format(nov))\n\nhbar_dim = nov + noovv\n# L is the dimension of the guess space, we start with nroot*2 guesses\nL = nroot * 2\n\n# When L exceeds Lmax we will collapse the guess space so our sub-space\n# diagonalization problem does not grow too large\nLmax = nroot * nvec_per_root\n\n# An array to hold the excitation energies\ntheta = [0.0] * L\n\n# build a HelperCCEom object\ncceom = HelperCCEom(ccsd, cchbar)\n\n# Get the approximate diagonal of Hbar\nD = np.hstack((cceom.Dia.flatten(), cceom.Dijab.flatten()))\n\n# We build a guess by selecting the lowest values of the approximate diagonal\n# in the singles space one for each nroot*2 guesses we want,\n# and we insert a guess vector with a 1 in the position corresponding to\n# that single excitation and zeros everywhere else.\n# This is a decent guess, more complicated one such as using CIS\n# eigenvectors are more common in production level codes.\nB_idx = D[:nov].argsort()[:nroot * 2]\nB = np.eye(hbar_dim)[:, B_idx]\n\nconv = False\neom_start = time.time()\n# This is the start of the Davidson iterations\nfor EOMCCSD_iter in range(0, max_iter + 1):\n    # QR decomposition ensures that the columns of B are orthogonal\n    B, R = np.linalg.qr(B)\n    L = B.shape[1]\n    theta_old = theta[:nroot]\n    print(""EOMCCSD: Iter # {:>6} L = {}"".format(EOMCCSD_iter, L))\n    # Build up the matrix S, holding the products Hbar*B, aka sigma vectors\n    S = np.zeros_like(B)\n    for i in range(L):\n        B1 = B[:nov, i].reshape(ndocc, nvir).copy()\n        B2 = B[nov:, i].reshape(ndocc, ndocc, nvir, nvir).copy()\n        S1 = cceom.build_sigma1(B1, B2)\n        S2 = cceom.build_sigma2(B1, B2)\n        S[:nov, i] += S1.flatten()\n        S[nov:, i] += S2.flatten()\n    # Build the subspace Hamiltonian\n    G = np.dot(B.T, S)\n    # Diagonalize it, and sort the eigenvector/eigenvalue pairs\n    theta, alpha = np.linalg.eig(G)\n    idx = theta.argsort()[:nroot]\n    theta = theta[idx]\n    alpha = alpha[:, idx]\n    # This vector will hold the new guess vectors to add to our space\n    add_B = []\n\n    for j in range(nroot):\n        # Compute a residual vector ""w"" for each root we seek\n        # Note: for a more robust convergence criteria you can also check\n        # that the norm of the residual vector is below some threshold.\n        w = np.dot(S, alpha[:, j]) - theta[j] * np.dot(B, alpha[:, j])\n        # Precondition the residual vector to form a correction vector\n        q = w / (theta[j] - D[j])\n        # The correction vectors are added to the set of guesses after each\n        # iterations, so L the guess space dimension grows by nroot at each\n        # iteration\n        add_B.append(q)\n        de = abs(theta[j] - theta_old[j])\n        print(""    Root {}: e = {:>20.12f} de = {:>20.12f} ""\n              ""|r| = {:>20.12f}"".format(j, theta[j], de, np.linalg.norm(w)))\n\n    # check convergence\n    e_norm = np.linalg.norm(theta[:nroot] - theta_old)\n    if (e_norm < e_tol):\n        # If converged exit\n        conv = True\n        break\n\n    else:\n        # if we are not converged\n        # check the subspace dimension, if it has grown too large, collapse\n        # to nroot guesses using the current estimate of the eigenvectors\n        if L >= Lmax:\n            B = np.dot(B, alpha)\n            # These vectors will give the same eigenvalues at the next\n            # iteration so to avoid a false convergence we reset the theta\n            # vector to theta_old\n            theta = theta_old\n        else:\n            # if not we add the preconditioned residuals to the guess\n            # space, and continue. Note that the set will be orthogonalized\n            # at the start of the next iteration\n            Btup = tuple(B[:, i] for i in range(L)) + tuple(add_B)\n            B = np.column_stack(Btup)\nif conv:\n    print(""EOMCCSD Davidson iterations finished in {}s"".format(\n        time.time() - eom_start))\n    print(""Davidson Converged!"")\n    print(""Excitation Energies"")\n    print(""{:>6}  {:^20}  {:^20}"".format(""Root #"", ""Hartree"", ""eV""))\n    print(""{:>6}  {:^20}  {:^20}"".format(""-"" * 6, ""-"" * 20, ""-"" * 20))\n    for i in range(nroot):\n        print(""{:>6}  {:>20.12f}  {:>20.12f}"".format(i, theta[i],\n                                                     theta[i] * 22.211))\nelse:\n    psi4.core.clean()\n    raise Exception(""EOMCCSD Failed -- Iterations exceeded"")\n\n# if requested compare values with psi4\nif compare_psi4:\n    print(""Checking against psi4...."")\n    psi4.energy(\'eom-ccsd\')\n    for i in range(nroot):\n        var_str = ""CC ROOT {} CORRELATION ENERGY"".format(i + 1)\n        e_ex = psi4.core.variable(var_str)\n        psi4.compare_values(e_ex, theta[i], 5, var_str)\n'"
Coupled-Cluster/RHF/helper_ccenergy.py,19,"b'""""""\nA simple python script to compute RHF-CCSD energy. Equations (Spin orbitals) from reference 1\nhave been spin-factored. However, explicit building of Wabef intermediates are avoided here.\n\nReferences: \n1. J.F. Stanton, J. Gauss, J.D. Watts, and R.J. Bartlett, \n   J. Chem. Phys., volume 94, pp. 4334-4345 (1991).\n""""""\n\n__authors__ = ""Ashutosh Kumar""\n__credits__ = [\n    ""T. D. Crawford"", ""Daniel G. A. Smith"", ""Lori A. Burns"", ""Ashutosh Kumar""\n]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-05-17""\n\nimport time\nimport numpy as np\nimport psi4\nfrom utils import ndot\nfrom utils import helper_diis\n\n\nclass HelperCCEnergy(object):\n    def __init__(self, mol, rhf_e, rhf_wfn, memory=2):\n\n        print(""\\nInitalizing CCSD object...\\n"")\n\n        # Integral generation from Psi4\'s MintsHelper\n        time_init = time.time()\n\n        self.rhf_e = rhf_e\n        self.wfn = rhf_wfn\n\n        self.ccsd_corr_e = 0.0\n        self.ccsd_e = 0.0\n\n        self.ndocc = self.wfn.doccpi()[0]\n        self.nmo = self.wfn.nmo()\n        self.memory = memory\n        self.C = self.wfn.Ca()\n        self.npC = np.asarray(self.C)\n\n        self.mints = psi4.core.MintsHelper(self.wfn.basisset())\n        H = np.asarray(self.mints.ao_kinetic()) + np.asarray(\n            self.mints.ao_potential())\n        self.nmo = H.shape[0]\n\n        # Update H, transform to MO basis\n        H = np.einsum(\'uj,vi,uv\', self.npC, self.npC, H)\n\n        print(\'Starting AO ->  MO transformation...\')\n\n        ERI_Size = self.nmo * 128.e-9\n        memory_footprint = ERI_Size * 5\n        if memory_footprint > self.memory:\n            psi.clean()\n            raise Exception(\n                ""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                            limit of %4.2f GB."" % (memory_footprint,\n                                                   self.memory))\n\n        # Integral generation from Psi4\'s MintsHelper\n        self.MO = np.asarray(self.mints.mo_eri(self.C, self.C, self.C, self.C))\n        # Physicist notation\n        self.MO = self.MO.swapaxes(1, 2)\n        print(""Size of the ERI tensor is %4.2f GB, %d basis functions."" %\n              (ERI_Size, self.nmo))\n\n        # Update nocc and nvirt\n        self.nocc = self.ndocc\n        self.nvirt = self.nmo - self.nocc\n\n        # Make slices\n        self.slice_o = slice(0, self.nocc)\n        self.slice_v = slice(self.nocc, self.nmo)\n        self.slice_a = slice(0, self.nmo)\n        self.slice_dict = {\n            \'o\': self.slice_o,\n            \'v\': self.slice_v,\n            \'a\': self.slice_a\n        }\n\n        # Compute Fock matrix\n        self.F = H + 2.0 * np.einsum(\'pmqm->pq\',\n                                     self.MO[:, self.slice_o, :, self.slice_o])\n        self.F -= np.einsum(\'pmmq->pq\',\n                            self.MO[:, self.slice_o, self.slice_o, :])\n\n        ### Occupied and Virtual orbital energies\n        Focc = np.diag(self.F)[self.slice_o]\n        Fvir = np.diag(self.F)[self.slice_v]\n\n        self.Dia = Focc.reshape(-1, 1) - Fvir\n        self.Dijab = Focc.reshape(-1, 1, 1, 1) + Focc.reshape(\n            -1, 1, 1) - Fvir.reshape(-1, 1) - Fvir\n\n        ### Construct initial guess\n        print(\'Building initial guess...\')\n        # t^a_i\n        self.t1 = np.zeros((self.nocc, self.nvirt))\n        # t^{ab}_{ij}\n        self.t2 = self.MO[self.slice_o, self.slice_o, self.slice_v,\n                          self.slice_v] / self.Dijab\n\n        print(\'\\n..initialized CCSD in %.3f seconds.\\n\' %\n              (time.time() - time_init))\n\n    # occ orbitals  : i, j, k, l, m, n\n    # virt orbitals : a, b, c, d, e, f\n    # all oribitals : p, q, r, s, t, u, v\n\n    def get_MO(self, string):\n        if len(string) != 4:\n            psi4.core.clean()\n            raise Exception(\'get_MO: string %s must have 4 elements.\' % string)\n        return self.MO[self.slice_dict[string[0]], self.slice_dict[string[1]],\n                       self.slice_dict[string[2]], self.slice_dict[string[3]]]\n\n    def get_F(self, string):\n        if len(string) != 2:\n            psi4.core.clean()\n            raise Exception(\'get_F: string %s must have 4 elements.\' % string)\n        return self.F[self.slice_dict[string[0]], self.slice_dict[string[1]]]\n\n    #Equations from Reference 1 (Stanton\'s paper)\n\n    #Bulid Eqn 9:\n    def build_tilde_tau(self):\n        ttau = self.t2.copy()\n        tmp = 0.5 * np.einsum(\'ia,jb->ijab\', self.t1, self.t1)\n        ttau += tmp\n        return ttau\n\n    #Build Eqn 10:\n    def build_tau(self):\n        ttau = self.t2.copy()\n        tmp = np.einsum(\'ia,jb->ijab\', self.t1, self.t1)\n        ttau += tmp\n        return ttau\n\n    #Build Eqn 3:\n    def build_Fae(self):\n        Fae = self.get_F(\'vv\').copy()\n        Fae -= ndot(\'me,ma->ae\', self.get_F(\'ov\'), self.t1, prefactor=0.5)\n        Fae += ndot(\'mf,mafe->ae\', self.t1, self.get_MO(\'ovvv\'), prefactor=2.0)\n        Fae += ndot(\n            \'mf,maef->ae\', self.t1, self.get_MO(\'ovvv\'), prefactor=-1.0)\n        Fae -= ndot(\n            \'mnaf,mnef->ae\',\n            self.build_tilde_tau(),\n            self.get_MO(\'oovv\'),\n            prefactor=2.0)\n        Fae -= ndot(\n            \'mnaf,mnfe->ae\',\n            self.build_tilde_tau(),\n            self.get_MO(\'oovv\'),\n            prefactor=-1.0)\n        return Fae\n\n    #Build Eqn 4:\n    def build_Fmi(self):\n        Fmi = self.get_F(\'oo\').copy()\n        Fmi += ndot(\'ie,me->mi\', self.t1, self.get_F(\'ov\'), prefactor=0.5)\n        Fmi += ndot(\'ne,mnie->mi\', self.t1, self.get_MO(\'ooov\'), prefactor=2.0)\n        Fmi += ndot(\n            \'ne,mnei->mi\', self.t1, self.get_MO(\'oovo\'), prefactor=-1.0)\n        Fmi += ndot(\n            \'inef,mnef->mi\',\n            self.build_tilde_tau(),\n            self.get_MO(\'oovv\'),\n            prefactor=2.0)\n        Fmi += ndot(\n            \'inef,mnfe->mi\',\n            self.build_tilde_tau(),\n            self.get_MO(\'oovv\'),\n            prefactor=-1.0)\n        return Fmi\n\n    #Build Eqn 5:\n    def build_Fme(self):\n        Fme = self.get_F(\'ov\').copy()\n        Fme += ndot(\'nf,mnef->me\', self.t1, self.get_MO(\'oovv\'), prefactor=2.0)\n        Fme += ndot(\n            \'nf,mnfe->me\', self.t1, self.get_MO(\'oovv\'), prefactor=-1.0)\n        return Fme\n\n    #Build Eqn 6:\n    def build_Wmnij(self):\n        Wmnij = self.get_MO(\'oooo\').copy()\n        Wmnij += ndot(\'je,mnie->mnij\', self.t1, self.get_MO(\'ooov\'))\n        Wmnij += ndot(\'ie,mnej->mnij\', self.t1, self.get_MO(\'oovo\'))\n        # prefactor of 1 instead of 0.5 below to fold the last term of\n        # 0.5 * tau_ijef Wabef in Wmnij contraction: 0.5 * tau_mnab Wmnij_mnij\n        Wmnij += ndot(\n            \'ijef,mnef->mnij\',\n            self.build_tau(),\n            self.get_MO(\'oovv\'),\n            prefactor=1.0)\n        return Wmnij\n\n    #Build Eqn 8:\n    def build_Wmbej(self):\n        Wmbej = self.get_MO(\'ovvo\').copy()\n        Wmbej += ndot(\'jf,mbef->mbej\', self.t1, self.get_MO(\'ovvv\'))\n        Wmbej -= ndot(\'nb,mnej->mbej\', self.t1, self.get_MO(\'oovo\'))\n        tmp = (0.5 * self.t2)\n        tmp += np.einsum(\'jf,nb->jnfb\', self.t1, self.t1)\n        Wmbej -= ndot(\'jnfb,mnef->mbej\', tmp, self.get_MO(\'oovv\'))\n        Wmbej += ndot(\n            \'njfb,mnef->mbej\', self.t2, self.get_MO(\'oovv\'), prefactor=1.0)\n        Wmbej += ndot(\n            \'njfb,mnfe->mbej\', self.t2, self.get_MO(\'oovv\'), prefactor=-0.5)\n        return Wmbej\n\n    # This intermediate appaears in the spin factorization of Wmbej terms.\n    def build_Wmbje(self):\n        Wmbje = -1.0 * (self.get_MO(\'ovov\').copy())\n        Wmbje -= ndot(\'jf,mbfe->mbje\', self.t1, self.get_MO(\'ovvv\'))\n        Wmbje += ndot(\'nb,mnje->mbje\', self.t1, self.get_MO(\'ooov\'))\n        tmp = (0.5 * self.t2)\n        tmp += np.einsum(\'jf,nb->jnfb\', self.t1, self.t1)\n        Wmbje += ndot(\'jnfb,mnfe->mbje\', tmp, self.get_MO(\'oovv\'))\n        return Wmbje\n\n    # This intermediate is required to build second term of 0.5 * tau_ijef * Wabef,\n    # as explicit construction of Wabef is avoided here.\n    def build_Zmbij(self):\n        Zmbij = 0\n        Zmbij += ndot(\'mbef,ijef->mbij\', self.get_MO(\'ovvv\'), self.build_tau())\n        return Zmbij\n\n    def update(self):\n\n        ### Build OEI intermediates\n        Fae = self.build_Fae()\n        Fmi = self.build_Fmi()\n        Fme = self.build_Fme()\n\n        #### Build residual of T1 equations by spin adaption of  Eqn 1:\n        r_T1 = self.get_F(\'ov\').copy()\n        r_T1 += ndot(\'ie,ae->ia\', self.t1, Fae)\n        r_T1 -= ndot(\'ma,mi->ia\', self.t1, Fmi)\n        r_T1 += ndot(\'imae,me->ia\', self.t2, Fme, prefactor=2.0)\n        r_T1 += ndot(\'imea,me->ia\', self.t2, Fme, prefactor=-1.0)\n        r_T1 += ndot(\n            \'nf,nafi->ia\', self.t1, self.get_MO(\'ovvo\'), prefactor=2.0)\n        r_T1 += ndot(\n            \'nf,naif->ia\', self.t1, self.get_MO(\'ovov\'), prefactor=-1.0)\n        r_T1 += ndot(\n            \'mief,maef->ia\', self.t2, self.get_MO(\'ovvv\'), prefactor=2.0)\n        r_T1 += ndot(\n            \'mife,maef->ia\', self.t2, self.get_MO(\'ovvv\'), prefactor=-1.0)\n        r_T1 -= ndot(\n            \'mnae,nmei->ia\', self.t2, self.get_MO(\'oovo\'), prefactor=2.0)\n        r_T1 -= ndot(\n            \'mnae,nmie->ia\', self.t2, self.get_MO(\'ooov\'), prefactor=-1.0)\n\n        ### Build residual of T2 equations by spin adaptation of Eqn 2:\n        # <ij||ab> ->  <ij|ab>\n        #   spin   ->  spin-adapted (<alpha beta| alpha beta>)\n        r_T2 = self.get_MO(\'oovv\').copy()\n\n        # Conventions used:\n        #   P(ab) f(a,b) = f(a,b) - f(b,a)\n        #   P(ij) f(i,j) = f(i,j) - f(j,i)\n        #   P^(ab)_(ij) f(a,b,i,j) = f(a,b,i,j) + f(b,a,j,i)\n\n        # P(ab) {t_ijae Fae_be}  ->  P^(ab)_(ij) {t_ijae Fae_be}\n        tmp = ndot(\'ijae,be->ijab\', self.t2, Fae)\n        r_T2 += tmp\n        r_T2 += tmp.swapaxes(0, 1).swapaxes(2, 3)\n\n        # P(ab) {-0.5 * t_ijae t_mb Fme_me} -> P^(ab)_(ij) {-0.5 * t_ijae t_mb Fme_me}\n        tmp = ndot(\'mb,me->be\', self.t1, Fme)\n        first = ndot(\'ijae,be->ijab\', self.t2, tmp, prefactor=0.5)\n        r_T2 -= first\n        r_T2 -= first.swapaxes(0, 1).swapaxes(2, 3)\n\n        # P(ij) {-t_imab Fmi_mj}  ->  P^(ab)_(ij) {-t_imab Fmi_mj}\n        tmp = ndot(\'imab,mj->ijab\', self.t2, Fmi, prefactor=1.0)\n        r_T2 -= tmp\n        r_T2 -= tmp.swapaxes(0, 1).swapaxes(2, 3)\n\n        # P(ij) {-0.5 * t_imab t_je Fme_me}  -> P^(ab)_(ij) {-0.5 * t_imab t_je Fme_me}\n        tmp = ndot(\'je,me->jm\', self.t1, Fme)\n        first = ndot(\'imab,jm->ijab\', self.t2, tmp, prefactor=0.5)\n        r_T2 -= first\n        r_T2 -= first.swapaxes(0, 1).swapaxes(2, 3)\n\n        # Build TEI Intermediates\n        tmp_tau = self.build_tau()\n        Wmnij = self.build_Wmnij()\n        Wmbej = self.build_Wmbej()\n        Wmbje = self.build_Wmbje()\n        Zmbij = self.build_Zmbij()\n\n        # 0.5 * tau_mnab Wmnij_mnij  -> tau_mnab Wmnij_mnij\n        # This also includes the last term in 0.5 * tau_ijef Wabef\n        # as Wmnij is modified to include this contribution.\n        r_T2 += ndot(\'mnab,mnij->ijab\', tmp_tau, Wmnij, prefactor=1.0)\n\n        # Wabef used in eqn 2 of reference 1 is very expensive to build and store, so we have\n        # broken down the term , 0.5 * tau_ijef * Wabef (eqn. 7) into different components\n        # The last term in the contraction 0.5 * tau_ijef * Wabef is already accounted\n        # for in the contraction just above.\n\n        # First term: 0.5 * tau_ijef <ab||ef> -> tau_ijef <ab|ef>\n        r_T2 += ndot(\n            \'ijef,abef->ijab\', tmp_tau, self.get_MO(\'vvvv\'), prefactor=1.0)\n\n        # Second term: 0.5 * tau_ijef (-P(ab) t_mb <am||ef>)  -> -P^(ab)_(ij) {t_ma * Zmbij_mbij}\n        # where Zmbij_mbij = <mb|ef> * tau_ijef\n        tmp = ndot(\'ma,mbij->ijab\', self.t1, Zmbij)\n        r_T2 -= tmp\n        r_T2 -= tmp.swapaxes(0, 1).swapaxes(2, 3)\n\n        # P(ij)P(ab) t_imae Wmbej -> Broken down into three terms below\n        # First term: P^(ab)_(ij) {(t_imae - t_imea)* Wmbej_mbej}\n        tmp = ndot(\'imae,mbej->ijab\', self.t2, Wmbej, prefactor=1.0)\n        tmp += ndot(\'imea,mbej->ijab\', self.t2, Wmbej, prefactor=-1.0)\n        r_T2 += tmp\n        r_T2 += tmp.swapaxes(0, 1).swapaxes(2, 3)\n\n        # Second term: P^(ab)_(ij) t_imae * (Wmbej_mbej + Wmbje_mbje)\n        tmp = ndot(\'imae,mbej->ijab\', self.t2, Wmbej, prefactor=1.0)\n        tmp += ndot(\'imae,mbje->ijab\', self.t2, Wmbje, prefactor=1.0)\n        r_T2 += tmp\n        r_T2 += tmp.swapaxes(0, 1).swapaxes(2, 3)\n\n        # Third term: P^(ab)_(ij) t_mjae * Wmbje_mbie\n        tmp = ndot(\'mjae,mbie->ijab\', self.t2, Wmbje, prefactor=1.0)\n        r_T2 += tmp\n        r_T2 += tmp.swapaxes(0, 1).swapaxes(2, 3)\n\n        # -P(ij)P(ab) {-t_ie * t_ma * <mb||ej>} -> P^(ab)_(ij) {-t_ie * t_ma * <mb|ej>\n        #                                                      + t_ie * t_mb * <ma|je>}\n        tmp = ndot(\'ie,ma->imea\', self.t1, self.t1)\n        tmp1 = ndot(\'imea,mbej->ijab\', tmp, self.get_MO(\'ovvo\'))\n        r_T2 -= tmp1\n        r_T2 -= tmp1.swapaxes(0, 1).swapaxes(2, 3)\n        tmp = ndot(\'ie,mb->imeb\', self.t1, self.t1)\n        tmp1 = ndot(\'imeb,maje->ijab\', tmp, self.get_MO(\'ovov\'))\n        r_T2 -= tmp1\n        r_T2 -= tmp1.swapaxes(0, 1).swapaxes(2, 3)\n\n        # P(ij) {t_ie <ab||ej>} -> P^(ab)_(ij) {t_ie <ab|ej>}\n        tmp = ndot(\n            \'ie,abej->ijab\', self.t1, self.get_MO(\'vvvo\'), prefactor=1.0)\n        r_T2 += tmp\n        r_T2 += tmp.swapaxes(0, 1).swapaxes(2, 3)\n\n        # P(ab) {-t_ma <mb||ij>} -> P^(ab)_(ij) {-t_ma <mb|ij>}\n        tmp = ndot(\n            \'ma,mbij->ijab\', self.t1, self.get_MO(\'ovoo\'), prefactor=1.0)\n        r_T2 -= tmp\n        r_T2 -= tmp.swapaxes(0, 1).swapaxes(2, 3)\n\n        ### Update T1 and T2 amplitudes\n        self.t1 += r_T1 / self.Dia\n        self.t2 += r_T2 / self.Dijab\n\n        rms = np.einsum(\'ia,ia->\', r_T1 / self.Dia, r_T1 / self.Dia)\n        rms += np.einsum(\'ijab,ijab->\', r_T2 / self.Dijab, r_T2 / self.Dijab)\n\n        return np.sqrt(rms)\n\n    def compute_corr_energy(self):\n        CCSDcorr_E = 2.0 * np.einsum(\'ia,ia->\', self.get_F(\'ov\'), self.t1)\n        tmp_tau = self.build_tau()\n        CCSDcorr_E += 2.0 * np.einsum(\'ijab,ijab->\', tmp_tau,\n                                      self.get_MO(\'oovv\'))\n        CCSDcorr_E -= 1.0 * np.einsum(\'ijab,ijba->\', tmp_tau,\n                                      self.get_MO(\'oovv\'))\n\n        self.ccsd_corr_e = CCSDcorr_E\n        self.ccsd_e = self.rhf_e + self.ccsd_corr_e\n        return CCSDcorr_E\n\n    def compute_energy(self,\n                       e_conv=1e-7,\n                       r_conv=1e-7,\n                       maxiter=100,\n                       max_diis=8,\n                       start_diis=1):\n\n        ### Start Iterations\n        ccsd_tstart = time.time()\n\n        # Compute MP2 energy\n        CCSDcorr_E_old = self.compute_corr_energy()\n        print(\n            ""CCSD Iteration %3d: CCSD correlation = %.15f   dE = % .5E   MP2"" %\n            (0, CCSDcorr_E_old, -CCSDcorr_E_old))\n\n        # Set up DIIS before iterations begin\n        diis_object = helper_diis(self.t1, self.t2, max_diis)\n\n        # Iterate!\n        for CCSD_iter in range(1, maxiter + 1):\n\n            rms = self.update()\n\n            # Compute CCSD correlation energy\n            CCSDcorr_E = self.compute_corr_energy()\n\n            # Print CCSD iteration information\n            print(\n                \'CCSD Iteration %3d: CCSD correlation = %.15f   dE = % .5E   DIIS = %d\'\n                % (CCSD_iter, CCSDcorr_E, (CCSDcorr_E - CCSDcorr_E_old),\n                   diis_object.diis_size))\n\n            # Check convergence\n            if (abs(CCSDcorr_E - CCSDcorr_E_old) < e_conv and rms < r_conv):\n                print(\'\\nCCSD has converged in %.3f seconds!\' %\n                      (time.time() - ccsd_tstart))\n                return CCSDcorr_E\n\n            # Update old energy\n            CCSDcorr_E_old = CCSDcorr_E\n\n            #  Add the new error vector\n            diis_object.add_error_vector(self.t1, self.t2)\n\n            if CCSD_iter >= start_diis:\n                self.t1, self.t2 = diis_object.extrapolate(self.t1, self.t2)\n\n\n# End HelperCCEnergy class\n'"
Coupled-Cluster/RHF/helper_cceom.py,4,"b'from utils import ndot\n\n\nclass HelperCCEom(object):\n    """"""\n    EOMCCSD helper class for spin adapted EOMCCSD\n\n    """"""\n\n    def __init__(self, ccsd, cchbar):\n        """"""\n        Initializes the HelperCCEom object\n\n        Parameters\n        ----------\n        ccsd: HelperCCSd object\n            Energy should already be computed\n\n        cchbar: HelperCCHbar object\n\n\n        Returns\n        -------\n        ret : HelperCCEom\n            An initialized HelperCCEom object\n\n        Notes\n        -----\n        Spin orbital sigma equations for EOMCCSDT can be found in:\n            I. Shavitt and R. J. Bartlett, ""Many-Body Methods in Chemistry and\n            Physics: MBPT and Coupled-Cluster Theory"", Cambridge University\n            Press, 2009.\n        The relevant contributions for EOMCCSD were extracted and the equations\n        spin adapted to arrive at the equations implemented in this class.\n\n        Special thanks to Ashutosh Kumar for Hbar components and help with spin\n        adaptation.\n\n        """"""\n        # Steal dimensions\n        self.ndocc = ccsd.ndocc\n        self.nmo = ccsd.nmo\n        self.nocc = ccsd.ndocc\n        self.nvir = ccsd.nmo - ccsd.nocc\n        self.nsingles = self.ndocc * self.nvir\n        self.ndoubles = self.ndocc * self.ndocc * self.nvir * self.nvir\n\n        # Steal integrals/amps from ccsd\n        self.MO = ccsd.MO\n        self.F = ccsd.F\n        self.t1 = ccsd.t1\n        self.t2 = ccsd.t2\n\n        # Steal ""ova"" translation\n        self.slice_o = cchbar.slice_o\n        self.slice_v = cchbar.slice_v\n        self.slice_a = cchbar.slice_a\n        self.slice_dict = cchbar.slice_dict\n\n        # Steal Hbar blocks\n        self.Hov = cchbar.Hov\n        self.Hoo = cchbar.Hoo\n        self.Hvv = cchbar.Hvv\n        self.Hoooo = cchbar.Hoooo\n        self.Hvvvv = cchbar.Hvvvv\n        self.Hvovv = cchbar.Hvovv\n        self.Hooov = cchbar.Hooov\n        self.Hovvo = cchbar.Hovvo\n        self.Hovov = cchbar.Hovov\n        self.Hvvvo = cchbar.Hvvvo\n        self.Hovoo = cchbar.Hovoo\n        self.Loovv = cchbar.Loovv\n\n        # Build Approximate Diagonal of Hbar\n        self.Dia = self.Hoo.diagonal().reshape(-1, 1) - self.Hvv.diagonal()\n        self.Dijab = self.Hoo.diagonal().reshape(\n            -1, 1, 1, 1) + self.Hoo.diagonal().reshape(\n                -1, 1, 1) - self.Hvv.diagonal().reshape(\n                    -1, 1) - self.Hvv.diagonal()\n\n    def get_MO(self, string):\n        if len(string) != 4:\n            psi4.core.clean()\n            raise Exception(\'get_MO: string %s must have 4 elements.\' % string)\n        return self.MO[self.slice_dict[string[0]], self.slice_dict[string[1]],\n                       self.slice_dict[string[2]], self.slice_dict[string[3]]]\n\n    def get_F(self, string):\n        if len(string) != 2:\n            psi4.core.clean()\n            raise Exception(\'get_F: string %s must have 4 elements.\' % string)\n        return self.F[self.slice_dict[string[0]], self.slice_dict[string[1]]]\n\n    def build_sigma1(self, B1, B2):\n        """"""\n        Compute the contributions to <ia|Hbar*B|0>\n\n        Parameters\n        ----------\n        B1: array like, shape(ndocc, nvir)\n          The first nsingles elements of a guess vector reshaped to (o,v)\n\n        B2: array like, shape(ndocc,ndocc,nvir,nvir)\n          The last ndoubles elements of a guess vector reshaped to (o,o,v,v)\n\n        Returns\n        -------\n        S1: ndarray shape(ndocc, nvir)\n\n        Examples\n        --------\n\n        >>> # Get some vectors as cols of a 2D numpy array and orthogonalize them\n        >>> c  = np.random.rand(eom.nsingles + eom.ndoubles, 2)\n        >>> c,  = np.linalg.qr(c)\n\n        >>> # Slice out the singles, doubles blocks of the first vector and reshape\n        >>> B1 = c[:,:nsingles].reshape(eom.ndocc, eom.nvir)\n        >>> B2 = c[:,nsingles:].reshape(eom.ndocc, eom.ndocc, eom.nvir, eom.nvir)\n        >>> S1 = eom.build_sigma1(B1, B2)\n\n        """"""\n        S1 = ndot(\'ie,ae->ia\', B1, self.Hvv)\n        S1 -= ndot(\'mi,ma->ia\', self.Hoo, B1)\n        S1 += ndot(\'maei,me->ia\', self.Hovvo, B1, prefactor=2.0)\n        S1 += ndot(\'maie,me->ia\', self.Hovov, B1, prefactor=-1.0)\n        S1 += ndot(\'miea,me->ia\', B2, self.Hov, prefactor=2.0)\n        S1 += ndot(\'imea,me->ia\', B2, self.Hov, prefactor=-1.0)\n        S1 += ndot(\'imef,amef->ia\', B2, self.Hvovv, prefactor=2.0)\n        S1 += ndot(\'imef,amfe->ia\', B2, self.Hvovv, prefactor=-1.0)\n        S1 -= ndot(\'mnie,mnae->ia\', self.Hooov, B2, prefactor=2.0)\n        S1 -= ndot(\'nmie,mnae->ia\', self.Hooov, B2, prefactor=-1.0)\n        return S1\n\n    def build_sigma2(self, B1, B2):\n        """"""\n        Compute the contributions to <ijab|Hbar*B|0>:\n\n        Parameters\n        ----------\n        B1: array like, shape(ndocc, nvir)\n          The first nsingles elements of a guess vector reshaped to (o,v)\n\n        B2: array like, shape(ndocc,ndocc,nvir,nvir)\n          The last ndoubles elements of a guess vector reshaped to (o,o,v,v)\n\n        Returns\n        -------\n        S2: ndarray shape(ndocc, ndocc, nvir, nvir)\n\n        Examples\n        --------\n\n        >>> # Get some vectors as cols of a 2D numpy array and orthogonalize them\n        >>> c  = np.random.rand(eom.nsingles + eom.ndoubles, 2)\n        >>> c,  = np.linalg.qr(c)\n\n        >>> # Slice out the singles, doubles blocks of the first vector and reshape\n        >>> B1 = c[:,:nsingles].reshape(eom.ndocc, eom.nvir)\n        >>> B2 = c[:,nsingles:].reshape(eom.ndocc, eom.ndocc, eom.nvir, eom.nvir)\n        >>> S2 = eom.build_sigma2(B1, B2)\n\n        """"""\n        S_2 = ndot(\'ie,abej->ijab\', B1, self.Hvvvo)\n        S_2 -= ndot(\'mbij,ma->ijab\', self.Hovoo, B1)\n\n        Zvv = ndot(""amef,mf->ae"", self.Hvovv, B1, prefactor=2.0)\n        Zvv += ndot(""amfe,mf->ae"", self.Hvovv, B1, prefactor=-1.0)\n        Zvv -= ndot(\'nmaf,nmef->ae\', B2, self.Loovv)\n        S_2 += ndot(\'ijeb,ae->ijab\', self.t2, Zvv)\n\n        Zoo = ndot(\'mnie,ne->mi\', self.Hooov, B1, prefactor=-2.0)\n        Zoo -= ndot(\'nmie,ne->mi\', self.Hooov, B1, prefactor=-1.0)\n        Zoo -= ndot(\'mnef,inef->mi\', self.Loovv, B2)\n        S_2 += ndot(\'mi,mjab->ijab\', Zoo, self.t2)\n\n        S_2 += ndot(\'ijeb,ae->ijab\', B2, self.Hvv)\n        S_2 -= ndot(\'mi,mjab->ijab\', self.Hoo, B2)\n\n        S_2 += ndot(\'mnij,mnab->ijab\', self.Hoooo, B2, prefactor=0.5)\n        S_2 += ndot(\'ijef,abef->ijab\', B2, self.Hvvvv, prefactor=0.5)\n\n        S_2 -= ndot(\'imeb,maje->ijab\', B2, self.Hovov)\n        S_2 -= ndot(\'imea,mbej->ijab\', B2, self.Hovvo)\n\n        S_2 += ndot(\'miea,mbej->ijab\', B2, self.Hovvo, prefactor=2.0)\n        S_2 += ndot(\'miea,mbje->ijab\', B2, self.Hovov, prefactor=-1.0)\n        return S_2 + S_2.swapaxes(0, 1).swapaxes(2, 3)\n'"
Coupled-Cluster/RHF/helper_cchbar.py,1,"b'"""""" RHF-CCSD similarity transformed Hamiltonian """"""\n\n__authors__ = ""Ashutosh Kumar""\n__credits__ = [\n    ""T. D. Crawford"", ""Daniel G. A. Smith"", ""Lori A. Burns"", ""Ashutosh Kumar""\n]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-05-17""\n\nimport time\nimport numpy as np\nimport psi4\nfrom utils import ndot\n\n\nclass HelperCCHbar(object):\n    """"""\n    This class builds pieces of the similarity transformed hamiltomian,\n    Hbar = e^(-T)He^(T) = H + [H,T] + 1/2![[H,T],T] + 1/3![[[H,T],T],T] + 1/4![[[[H,T],T],T],T]\n    which can be used quite conveniently to solve lambda equations, calculate  excitation energies \n    (EOM-CC sigma equations), CC response properties etc.. Spin orbitals expression of all Hbar \n    components are written in einstein notation in the doctrings of functions below. Ofcourse, \n    we are constructing <p * alpha | Hbar |q * alpha> (or beta) and \n    <p * alpha * q * beta | Hbar | r * alpha * s * beta> components here.\n\n    References:  \n    1. J. Gauss and J.F. Stanton, J. Chem. Phys., volume 103, pp. 3561-3577 (1995). \n    """"""\n\n    def __init__(self, ccsd, memory=2):\n\n        # Start of the cchbar class\n        time_init = time.time()\n\n        self.MO = ccsd.MO\n        self.ndocc = ccsd.ndocc\n        self.nmo = ccsd.nmo\n        self.nocc = ccsd.ndocc\n        self.nvirt = ccsd.nmo - ccsd.nocc\n\n        self.slice_o = slice(0, self.nocc)\n        self.slice_v = slice(self.nocc, self.nmo)\n        self.slice_a = slice(0, self.nmo)\n        self.slice_dict = {\n            \'o\': self.slice_o,\n            \'v\': self.slice_v,\n            \'a\': self.slice_a\n        }\n\n        self.F = ccsd.F\n        self.Dia = ccsd.Dia\n        self.Dijab = ccsd.Dijab\n        self.t1 = ccsd.t1\n        self.t2 = ccsd.t2\n\n        print(\'\\nBuilding HBAR components ...\')\n\n        self.build_Loovv()\n        self.build_Looov()\n        self.build_Lvovv()\n\n        self.build_Hov()\n        self.build_Hoo()\n        self.build_Hvv()\n        self.build_Hoooo()\n        self.build_Hvvvv()\n        self.build_Hvovv()\n        self.build_Hooov()\n        self.build_Hovvo()\n        self.build_Hovov()\n        self.build_Hvvvo()\n        self.build_Hovoo()\n\n        print(\'\\n..HBAR Build completed !!\')\n\n    # occ orbitals i, j, k, l, m, n\n    # virt orbitals a, b, c, d, e, f\n    # all oribitals p, q, r, s, t, u, v\n\n    def get_MO(self, string):\n        if len(string) != 4:\n            psi4.core.clean()\n            raise Exception(\'get_MO: string %s must have 4 elements.\' % string)\n        return self.MO[self.slice_dict[string[0]], self.slice_dict[string[1]],\n                       self.slice_dict[string[2]], self.slice_dict[string[3]]]\n\n    def get_F(self, string):\n        if len(string) != 2:\n            psi4.core.clean()\n            raise Exception(\'get_F: string %s must have 2 elements.\' % string)\n        return self.F[self.slice_dict[string[0]], self.slice_dict[string[1]]]\n\n    def build_Loovv(self):\n        tmp = self.get_MO(\'oovv\').copy()\n        self.Loovv = 2.0 * tmp - tmp.swapaxes(2, 3)\n        return self.Loovv\n\n    def build_Looov(self):\n        tmp = self.get_MO(\'ooov\').copy()\n        self.Looov = 2.0 * tmp - tmp.swapaxes(0, 1)\n        return self.Looov\n\n    def build_Lvovv(self):\n        tmp = self.get_MO(\'vovv\').copy()\n        self.Lvovv = 2.0 * tmp - tmp.swapaxes(2, 3)\n        return self.Lvovv\n\n    def build_tau(self):\n        self.ttau = self.t2.copy()\n        tmp = np.einsum(\'ia,jb->ijab\', self.t1, self.t1)\n        self.ttau += tmp\n        return self.ttau\n\n    # F and W are the one and two body intermediates which appear in the CCSD\n    # T1 and T2 equations. Please refer to helper_ccenergy file for more details.\n\n    def build_Hov(self):\n        """""" <m|Hbar|e> = F_me = f_me + t_nf <mn||ef> """"""\n        self.Hov = self.get_F(\'ov\').copy()\n        self.Hov += ndot(\'nf,mnef->me\', self.t1, self.Loovv)\n        return self.Hov\n\n    def build_Hoo(self):\n        """"""\n            <m|Hbar|i> = F_mi + 0.5 * t_ie F_me = f_mi + t_ie f_me\n                         + t_ne <mn||ie> + tau_inef <mn||ef>\n        """"""\n        self.Hoo = self.get_F(\'oo\').copy()\n        self.Hoo += ndot(\'ie,me->mi\', self.t1, self.get_F(\'ov\'))\n        self.Hoo += ndot(\'ne,mnie->mi\', self.t1, self.Looov)\n        self.Hoo += ndot(\'inef,mnef->mi\', self.build_tau(), self.Loovv)\n        return self.Hoo\n\n    def build_Hvv(self):\n        """"""\n            <a|Hbar|e> = F_ae - 0.5 * t_ma F_me = f_ae - t_ma f_me \n                         + t_mf <am||ef> - tau_mnfa <mn||fe>\n        """"""\n        self.Hvv = self.get_F(\'vv\').copy()\n        self.Hvv -= ndot(\'ma,me->ae\', self.t1, self.get_F(\'ov\'))\n        self.Hvv += ndot(\'mf,amef->ae\', self.t1, self.Lvovv)\n        self.Hvv -= ndot(\'mnfa,mnfe->ae\', self.build_tau(), self.Loovv)\n        return self.Hvv\n\n    def build_Hoooo(self):\n        """""" \n            <mn|Hbar|ij> = W_mnij + 0.25 * tau_ijef <mn||ef> = <mn||ij> \n                           + P(ij) t_je <mn||ie> + 0.5 * tau_ijef <mn||ef>\n        """"""\n        self.Hoooo = self.get_MO(\'oooo\').copy()\n        self.Hoooo += ndot(\'je,mnie->mnij\', self.t1, self.get_MO(\'ooov\'))\n        self.Hoooo += ndot(\'ie,mnej->mnij\', self.t1, self.get_MO(\'oovo\'))\n        self.Hoooo += ndot(\'ijef,mnef->mnij\', self.build_tau(),\n                           self.get_MO(\'oovv\'))\n        return self.Hoooo\n\n    def build_Hvvvv(self):\n        """"""\n            <ab|Hbar|ef> = W_abef + 0.25 * tau_mnab <mn||ef> = <ab||ef> \n                           - P(ab) t_mb <am||ef> + 0.5 * tau_mnab <mn||ef>\n        """"""\n        self.Hvvvv = self.get_MO(\'vvvv\').copy()\n        self.Hvvvv -= ndot(\'mb,amef->abef\', self.t1, self.get_MO(\'vovv\'))\n        self.Hvvvv -= ndot(\'ma,bmfe->abef\', self.t1, self.get_MO(\'vovv\'))\n        self.Hvvvv += ndot(\'mnab,mnef->abef\', self.build_tau(),\n                           self.get_MO(\'oovv\'))\n        return self.Hvvvv\n\n    def build_Hvovv(self):\n        """""" <am|Hbar|ef> = <am||ef> - t_na <nm||ef> """"""\n        self.Hvovv = self.get_MO(\'vovv\').copy()\n        self.Hvovv -= ndot(\'na,nmef->amef\', self.t1, self.get_MO(\'oovv\'))\n        return self.Hvovv\n\n    def build_Hooov(self):\n        """""" <mn|Hbar|ie> = <mn||ie> + t_if <mn||fe> """"""\n        self.Hooov = self.get_MO(\'ooov\').copy()\n        self.Hooov += ndot(\'if,mnfe->mnie\', self.t1, self.get_MO(\'oovv\'))\n        return self.Hooov\n\n    def build_Hovvo(self):\n        """""" \n            <mb|Hbar|ej> = W_mbej - 0.5 * t_jnfb <mn||ef> = <mb||ej> + t_jf <mb||ef> \n                           - t_nb <mn||ej> - (t_jnfb + t_jf t_nb) <nm||fe>\n        """"""\n        self.Hovvo = self.get_MO(\'ovvo\').copy()\n        self.Hovvo += ndot(\'jf,mbef->mbej\', self.t1, self.get_MO(\'ovvv\'))\n        self.Hovvo -= ndot(\'nb,mnej->mbej\', self.t1, self.get_MO(\'oovo\'))\n        self.Hovvo -= ndot(\'jnfb,nmfe->mbej\', self.build_tau(),\n                           self.get_MO(\'oovv\'))\n        self.Hovvo += ndot(\'jnbf,nmfe->mbej\', self.t2, self.Loovv)\n        return self.Hovvo\n\n    def build_Hovov(self):\n        """""" \n            <mb|Hbar|je> = - <mb|Hbar|ej> = <mb||je> + t_jf <bm||ef> - t_nb <mn||je> \n                           - (t_jnfb + t_jf t_nb) <nm||ef>\n        """"""\n        self.Hovov = self.get_MO(\'ovov\').copy()\n        self.Hovov += ndot(\'jf,bmef->mbje\', self.t1, self.get_MO(\'vovv\'))\n        self.Hovov -= ndot(\'nb,mnje->mbje\', self.t1, self.get_MO(\'ooov\'))\n        self.Hovov -= ndot(\'jnfb,nmef->mbje\', self.build_tau(),\n                           self.get_MO(\'oovv\'))\n        return self.Hovov\n\n    def build_Hvvvo(self):\n        """"""\n            <ab|Hbar|ei> = <ab||ei> - F_me t_miab + t_if Wabef + 0.5 * tau_mnab <mn||ei> \n                           - P(ab) t_miaf <mb||ef> - P(ab) t_ma {<mb||ei> - t_nibf <mn||ef>}\n        """"""\n        # <ab||ei>\n\n        self.Hvvvo = self.get_MO(\'vvvo\').copy()\n\n        # - Fme t_miab\n\n        self.Hvvvo -= ndot(\'me,miab->abei\', self.get_F(\'ov\'), self.t2)\n        tmp = ndot(\'mnfe,mf->ne\', self.Loovv, self.t1)\n        self.Hvvvo -= ndot(\'niab,ne->abei\', self.t2, tmp)\n\n        # t_if Wabef\n\n        self.Hvvvo += ndot(\'if,abef->abei\', self.t1, self.get_MO(\'vvvv\'))\n        tmp = ndot(\'if,ma->imfa\', self.t1, self.t1)\n        self.Hvvvo -= ndot(\'imfa,mbef->abei\', tmp, self.get_MO(\'ovvv\'))\n        self.Hvvvo -= ndot(\'imfb,amef->abei\', tmp, self.get_MO(\'vovv\'))\n        tmp = ndot(\'mnef,if->mnei\', self.get_MO(\'oovv\'), self.t1)\n        self.Hvvvo += ndot(\'mnab,mnei->abei\', self.t2, tmp)\n        tmp = ndot(\'if,ma->imfa\', self.t1, self.t1)\n        tmp1 = ndot(\'mnef,nb->mbef\', self.get_MO(\'oovv\'), self.t1)\n        self.Hvvvo += ndot(\'imfa,mbef->abei\', tmp, tmp1)\n\n        # 0.5 * tau_mnab <mn||ei>\n\n        self.Hvvvo += ndot(\'mnab,mnei->abei\', self.build_tau(),\n                           self.get_MO(\'oovo\'))\n\n        # - P(ab) t_miaf <mb||ef>\n\n        self.Hvvvo -= ndot(\'imfa,mbef->abei\', self.t2, self.get_MO(\'ovvv\'))\n        self.Hvvvo -= ndot(\'imfb,amef->abei\', self.t2, self.get_MO(\'vovv\'))\n        self.Hvvvo += ndot(\'mifb,amef->abei\', self.t2, self.Lvovv)\n\n        # - P(ab) t_ma <mb||ei>\n\n        self.Hvvvo -= ndot(\'mb,amei->abei\', self.t1, self.get_MO(\'vovo\'))\n        self.Hvvvo -= ndot(\'ma,bmie->abei\', self.t1, self.get_MO(\'voov\'))\n\n        # P(ab) t_ma * t_nibf <mn||ef>\n\n        tmp = ndot(\'mnef,ma->anef\', self.get_MO(\'oovv\'), self.t1)\n        self.Hvvvo += ndot(\'infb,anef->abei\', self.t2, tmp)\n        tmp = ndot(\'mnef,ma->nafe\', self.Loovv, self.t1)\n        self.Hvvvo -= ndot(\'nifb,nafe->abei\', self.t2, tmp)\n        tmp = ndot(\'nmef,mb->nefb\', self.get_MO(\'oovv\'), self.t1)\n        self.Hvvvo += ndot(\'niaf,nefb->abei\', self.t2, tmp)\n        return self.Hvvvo\n\n    def build_Hovoo(self):\n        """""" \n            <mb|Hbar|ij> = <mb||ij> - Fme t_ijbe - t_nb Wmnij + 0.5 * tau_ijef <mb||ef> \n                           + P(ij) t_jnbe <mn||ie> + P(ij) t_ie {<mb||ej> - t_njbf <mn||ef>}\n        """"""\n        # <mb||ij>\n\n        self.Hovoo = self.get_MO(\'ovoo\').copy()\n\n        # - Fme t_ijbe\n\n        self.Hovoo += ndot(\'me,ijeb->mbij\', self.get_F(\'ov\'), self.t2)\n        tmp = ndot(\'mnef,nf->me\', self.Loovv, self.t1)\n        self.Hovoo += ndot(\'me,ijeb->mbij\', tmp, self.t2)\n\n        # - t_nb Wmnij\n\n        self.Hovoo -= ndot(\'nb,mnij->mbij\', self.t1, self.get_MO(\'oooo\'))\n        tmp = ndot(\'ie,nb->ineb\', self.t1, self.t1)\n        self.Hovoo -= ndot(\'ineb,mnej->mbij\', tmp, self.get_MO(\'oovo\'))\n        self.Hovoo -= ndot(\'jneb,mnie->mbij\', tmp, self.get_MO(\'ooov\'))\n        tmp = ndot(\'nb,mnef->mefb\', self.t1, self.get_MO(\'oovv\'))\n        self.Hovoo -= ndot(\'ijef,mefb->mbij\', self.t2, tmp)\n        tmp = ndot(\'ie,jf->ijef\', self.t1, self.t1)\n        tmp1 = ndot(\'nb,mnef->mbef\', self.t1, self.get_MO(\'oovv\'))\n        self.Hovoo -= ndot(\'mbef,ijef->mbij\', tmp1, tmp)\n\n        # 0.5 * tau_ijef <mb||ef>\n\n        self.Hovoo += ndot(\'ijef,mbef->mbij\', self.build_tau(),\n                           self.get_MO(\'ovvv\'))\n\n        # P(ij) t_jnbe <mn||ie>\n\n        self.Hovoo -= ndot(\'ineb,mnej->mbij\', self.t2, self.get_MO(\'oovo\'))\n        self.Hovoo -= ndot(\'jneb,mnie->mbij\', self.t2, self.get_MO(\'ooov\'))\n        self.Hovoo += ndot(\'jnbe,mnie->mbij\', self.t2, self.Looov)\n\n        # P(ij) t_ie <mb||ej>\n\n        self.Hovoo += ndot(\'je,mbie->mbij\', self.t1, self.get_MO(\'ovov\'))\n        self.Hovoo += ndot(\'ie,mbej->mbij\', self.t1, self.get_MO(\'ovvo\'))\n\n        # - P(ij) t_ie * t_njbf <mn||ef>\n\n        tmp = ndot(\'ie,mnef->mnif\', self.t1, self.get_MO(\'oovv\'))\n        self.Hovoo -= ndot(\'jnfb,mnif->mbij\', self.t2, tmp)\n        tmp = ndot(\'mnef,njfb->mejb\', self.Loovv, self.t2)\n        self.Hovoo += ndot(\'mejb,ie->mbij\', tmp, self.t1)\n        tmp = ndot(\'je,mnfe->mnfj\', self.t1, self.get_MO(\'oovv\'))\n        self.Hovoo -= ndot(\'infb,mnfj->mbij\', self.t2, tmp)\n        return self.Hovoo\n\n\n# End HelperCCHbar class\n'"
Coupled-Cluster/RHF/helper_cclambda.py,3,"b'# -*- coding: utf-8 -*-\n""""""\nA simple python script to calculate RHF-CCSD lambda amplitudes\nusing pieces of the similarity transformed hamiltonian, Hbar.\nEquations were spin-adapted using the unitary group approach. \n\nReferences: \n1. J. Gauss and J.F. Stanton, J. Chem. Phys., volume 103, pp. 3561-3577 (1995). \n2. Chapter 13, ""Molecular Electronic-Structure Theory"", Trygve Helgaker, \n   Poul J\xc3\xb8rgensen and Jeppe Olsen, John Wiley & Sons Ltd.\n3. Dr. Crawford\'s notes on commutators relationships of H with singles excitation \n   operators. (pdf in the current folder)\n    \n""""""\n\n__authors__ = ""Ashutosh Kumar""\n__credits__ = [\n    ""T. D. Crawford"", ""Daniel G. A. Smith"", ""Lori A. Burns"", ""Ashutosh Kumar""\n]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-05-17""\n\nimport time\nimport numpy as np\nimport psi4\nfrom utils import ndot\nfrom utils import helper_diis\n\n\nclass HelperCCLambda(object):\n    def __init__(self, ccsd, hbar):\n\n        # start of the cclambda class\n        time_init = time.time()\n\n        # Grabbing all the info from the wavefunctions passed\n        self.MO = ccsd.MO\n        self.ndocc = ccsd.ndocc\n        self.nmo = ccsd.nmo\n        self.nocc = ccsd.ndocc\n        self.nvirt = ccsd.nmo - ccsd.nocc\n        self.F = ccsd.F\n        self.Dia = ccsd.Dia\n        self.Dijab = ccsd.Dijab\n        self.t1 = ccsd.t1\n        self.t2 = ccsd.t2\n        self.ttau = hbar.ttau\n        self.Loovv = hbar.Loovv\n        self.Looov = hbar.Looov\n        self.Lvovv = hbar.Lvovv\n        self.Hov = hbar.Hov\n        self.Hvv = hbar.Hvv\n        self.Hoo = hbar.Hoo\n        self.Hoooo = hbar.Hoooo\n        self.Hvvvv = hbar.Hvvvv\n        self.Hvovv = hbar.Hvovv\n        self.Hooov = hbar.Hooov\n        self.Hovvo = hbar.Hovvo\n        self.Hovov = hbar.Hovov\n        self.Hvvvo = hbar.Hvvvo\n        self.Hovoo = hbar.Hovoo\n\n        self.slice_o = slice(0, self.nocc)\n        self.slice_v = slice(self.nocc, self.nmo)\n        self.slice_a = slice(0, self.nmo)\n        self.slice_dict = {\n            \'o\': self.slice_o,\n            \'v\': self.slice_v,\n            \'a\': self.slice_a\n        }\n\n        # Guesses for L1 and L2 amplitudes\n        self.l1 = 2.0 * self.t1.copy()\n        self.l2 = 4.0 * self.t2.copy()\n        self.l2 -= 2.0 * self.t2.swapaxes(2, 3)\n\n        # Conventions used :\n        # occ orbitals  : i, j, k, l, m, n\n        # virt orbitals : a, b, c, d, e, f\n        # all oribitals : p, q, r, s, t, u, v\n\n    def get_MO(self, string):\n        if len(string) != 4:\n            psi4.core.clean()\n            raise Exception(\'get_MO: string %s must have 4 elements.\' % string)\n        return self.MO[self.slice_dict[string[0]], self.slice_dict[string[1]],\n                       self.slice_dict[string[2]], self.slice_dict[string[3]]]\n\n    def get_F(self, string):\n        if len(string) != 2:\n            psi4.core.clean()\n            raise Exception(\'get_F: string %s must have 2 elements.\' % string)\n        return self.F[self.slice_dict[string[0]], self.slice_dict[string[1]]]\n\n    def build_Goo(self):\n        self.Goo = 0\n        self.Goo += ndot(\'mjab,ijab->mi\', self.t2, self.l2)\n        return self.Goo\n\n    def build_Gvv(self):\n        self.Gvv = 0\n        self.Gvv -= ndot(\'ijab,ijeb->ae\', self.l2, self.t2)\n        return self.Gvv\n\n    def update(self):\n        """"""\n            l1 and l2  equations can be obtained by taking the derivative of the CCSD Lagrangian wrt. t1 and t2 amplitudes respectively.\n            (Einstein summation):\n            \n            l1: <o|Hbar|phi^a_i>   + l_kc * <phi^c_k|Hbar|phi^a_i>   + l_klcd * <phi^cd_kl|Hbar|phi^a_i> = 0\n            l2: <o|Hbar|phi^ab_ij> + l_kc * <phi^c_k|Hbar|phi^ab_ij> + l_klcd * <phi^cd_kl|Hbar|phi^ab_ij> = 0\n            \n            In Spin orbitals:\n            l1:\n            Hov_ia + l_ie * Hvv_ae - l_ma * Hoo_im + l_me * Hovvo_ieam + 0.5 * l_imef * Hvvvo_efam\n            - 0.5 * l_mnae Hovoo_iemn - Gvv_ef * Hvovv_eifa - Goo_mn * Hooov_mina = 0\n       \n            where, Goo_mn = 0.5 * t_mjab * l_njab,  Gvv_ef = - 0.5 * l_ijeb * t_ijfb\n            Intermediates Goo and Gvv have been built to bypass the construction of\n            3-body Hbar terms like, l1  <-- Hvvooov_beilka * l_lkbe\n                                    l1  <-- Hvvooov_cbijna * l_jncb\n            \n            l2:\n             <ij||ab> + P(ab) l_ijae * Hov_eb - P(ij) l_imab * Hoo_jm + 0.5 * l_mnab * Hoooo_ijmn\n             + 0.5 * Hvvvv_efab l_ijef + P(ij) l_ie * Hvovv_ejab - P(ab) l_ma * Hooov_ijmb\n             + P(ij)P(ab) l_imae * Hovvo_jebm + P(ij)P(ab) l_ia * Hov_jb + P(ab) <ij||ae> * Gvv_be\n             - P(ij) <im||ab> * Goo_mj\n            \n            Here we are using the unitary group approach (UGA) to derive spin adapted equations, please refer to chapter\n            13 of reference 2 and notes in the current folder for more details. Lambda equations derived using UGA differ\n            from the regular spin factorizd equations (PSI4) as follows:\n            l_ia(UGA) = 2.0 * l_ia(PSI4)\n            l_ijab(UGA) = 2.0 * (2.0 * l_ijab - l_ijba)\n            The residual equations (without the preconditioner) follow the same relations as above.\n            Ex. the inhomogenous terms in l1 and l2 equations in UGA are 2 * Hov_ia and 2.0 * (2.0 * <ij|ab> - <ij|ba>)\n            respectively as opposed to Hov_ia and <ij|ab> in PSI4.\n        """"""\n\n        # l1 equations\n        r_l1 = 2.0 * self.Hov.copy()\n        r_l1 += ndot(\'ie,ea->ia\', self.l1, self.Hvv)\n        r_l1 -= ndot(\'im,ma->ia\', self.Hoo, self.l1)\n        r_l1 += ndot(\'ieam,me->ia\', self.Hovvo, self.l1, prefactor=2.0)\n        r_l1 += ndot(\'iema,me->ia\', self.Hovov, self.l1, prefactor=-1.0)\n        r_l1 += ndot(\'imef,efam->ia\', self.l2, self.Hvvvo)\n        r_l1 -= ndot(\'iemn,mnae->ia\', self.Hovoo, self.l2)\n        r_l1 -= ndot(\n            \'eifa,ef->ia\', self.Hvovv, self.build_Gvv(), prefactor=2.0)\n        r_l1 -= ndot(\n            \'eiaf,ef->ia\', self.Hvovv, self.build_Gvv(), prefactor=-1.0)\n        r_l1 -= ndot(\n            \'mina,mn->ia\', self.Hooov, self.build_Goo(), prefactor=2.0)\n        r_l1 -= ndot(\n            \'imna,mn->ia\', self.Hooov, self.build_Goo(), prefactor=-1.0)\n\n        # l2 equations\n        # Final r_l2_ijab = r_l2_ijab + r_l2_jiba\n        r_l2 = self.Loovv.copy()\n        r_l2 += ndot(\'ia,jb->ijab\', self.l1, self.Hov, prefactor=2.0)\n        r_l2 -= ndot(\'ja,ib->ijab\', self.l1, self.Hov)\n        r_l2 += ndot(\'ijeb,ea->ijab\', self.l2, self.Hvv)\n        r_l2 -= ndot(\'im,mjab->ijab\', self.Hoo, self.l2)\n        r_l2 += ndot(\'ijmn,mnab->ijab\', self.Hoooo, self.l2, prefactor=0.5)\n        r_l2 += ndot(\'ijef,efab->ijab\', self.l2, self.Hvvvv, prefactor=0.5)\n        r_l2 += ndot(\'ie,ejab->ijab\', self.l1, self.Hvovv, prefactor=2.0)\n        r_l2 += ndot(\'ie,ejba->ijab\', self.l1, self.Hvovv, prefactor=-1.0)\n        r_l2 -= ndot(\'mb,jima->ijab\', self.l1, self.Hooov, prefactor=2.0)\n        r_l2 -= ndot(\'mb,ijma->ijab\', self.l1, self.Hooov, prefactor=-1.0)\n        r_l2 += ndot(\'ieam,mjeb->ijab\', self.Hovvo, self.l2, prefactor=2.0)\n        r_l2 += ndot(\'iema,mjeb->ijab\', self.Hovov, self.l2, prefactor=-1.0)\n        r_l2 -= ndot(\'mibe,jema->ijab\', self.l2, self.Hovov)\n        r_l2 -= ndot(\'mieb,jeam->ijab\', self.l2, self.Hovvo)\n        r_l2 += ndot(\'ijeb,ae->ijab\', self.Loovv, self.build_Gvv())\n        r_l2 -= ndot(\'mi,mjab->ijab\', self.build_Goo(), self.Loovv)\n\n        old_l2 = self.l2.copy()\n        old_l1 = self.l1.copy()\n\n        # update l1 and l2 amplitudes\n        self.l1 += r_l1 / self.Dia\n        # Final r_l2_ijab = r_l2_ijab + r_l2_jiba\n        tmp = r_l2 / self.Dijab\n        self.l2 += tmp + tmp.swapaxes(0, 1).swapaxes(2, 3)\n\n        # calculate rms from the residual\n        rms = 2.0 * np.einsum(\'ia,ia->\', old_l1 - self.l1, old_l1 - self.l1)\n        rms += np.einsum(\'ijab,ijab->\', old_l2 - self.l2, old_l2 - self.l2)\n        return np.sqrt(rms)\n\n    def pseudoenergy(self):\n        pseudoenergy = 0\n        pseudoenergy += ndot(\n            \'ijab,ijab->\', self.get_MO(\'oovv\'), self.l2, prefactor=0.5)\n        return pseudoenergy\n\n    def compute_lambda(self,\n                       r_conv=1e-7,\n                       maxiter=100,\n                       max_diis=8,\n                       start_diis=1):\n\n        ### Start Iterations\n        cclambda_tstart = time.time()\n\n        pseudoenergy_old = self.pseudoenergy()\n        print(""CCLAMBDA Iteration %3d: pseudoenergy = %.15f   dE = % .5E"" %\n              (0, pseudoenergy_old, -pseudoenergy_old))\n\n        # Set up DIIS before iterations begin\n        diis_object = helper_diis(self.l1, self.l2, max_diis)\n\n        # Iterate!\n        for CCLAMBDA_iter in range(1, maxiter + 1):\n\n            rms = self.update()\n\n            # Compute pseudoenergy\n            pseudoenergy = self.pseudoenergy()\n\n            # Print CCLAMBDA iteration information\n            print(\n                \'CCLAMBDA Iteration %3d: pseudoenergy = %.15f   dE = % .5E   DIIS = %d\'\n                % (CCLAMBDA_iter, pseudoenergy,\n                   (pseudoenergy - pseudoenergy_old), diis_object.diis_size))\n\n            # Check convergence\n            if (rms < r_conv):\n                print(\'\\nCCLAMBDA has converged in %.3f seconds!\' %\n                      (time.time() - cclambda_tstart))\n                return pseudoenergy\n\n            # Update old pseudoenergy\n            pseudoenergy_old = pseudoenergy\n\n            #  Add the new error vector\n            diis_object.add_error_vector(self.l1, self.l2)\n            if CCLAMBDA_iter >= start_diis:\n                self.l1, self.l2 = diis_object.extrapolate(self.l1, self.l2)\n\n\n# End HelperCCLambda class\n'"
Coupled-Cluster/RHF/utils.py,18,"b'import time\nimport numpy as np\nimport psi4\n\n\n# N dimensional dot\n# Like a mini DPD library\ndef ndot(input_string, op1, op2, prefactor=None):\n    """"""\n    No checks, if you get weird errors its up to you to debug.\n\n    ndot(\'abcd,cdef->abef\', arr1, arr2)\n    """"""\n    inp, output_ind = input_string.split(\'->\')\n    input_left, input_right = inp.split(\',\')\n\n    size_dict = {}\n    for s, size in zip(input_left, op1.shape):\n        size_dict[s] = size\n    for s, size in zip(input_right, op2.shape):\n        size_dict[s] = size\n\n    set_left = set(input_left)\n    set_right = set(input_right)\n    set_out = set(output_ind)\n\n    idx_removed = (set_left | set_right) - set_out\n    keep_left = set_left - idx_removed\n    keep_right = set_right - idx_removed\n\n    # Tensordot axes\n    left_pos, right_pos = (), ()\n    for s in idx_removed:\n        left_pos += (input_left.find(s), )\n        right_pos += (input_right.find(s), )\n    tdot_axes = (left_pos, right_pos)\n\n    # Get result ordering\n    tdot_result = input_left + input_right\n    for s in idx_removed:\n        tdot_result = tdot_result.replace(s, \'\')\n\n    rs = len(idx_removed)\n    dim_left, dim_right, dim_removed = 1, 1, 1\n    for key, size in size_dict.items():\n        if key in keep_left:\n            dim_left *= size\n        if key in keep_right:\n            dim_right *= size\n        if key in idx_removed:\n            dim_removed *= size\n\n    shape_result = tuple(size_dict[x] for x in tdot_result)\n    used_einsum = False\n\n    # Matrix multiply\n    # No transpose needed\n    if input_left[-rs:] == input_right[:rs]:\n        new_view = np.dot(\n            op1.reshape(dim_left, dim_removed),\n            op2.reshape(dim_removed, dim_right))\n\n    # Transpose both\n    elif input_left[:rs] == input_right[-rs:]:\n        new_view = np.dot(\n            op1.reshape(dim_removed, dim_left).T,\n            op2.reshape(dim_right, dim_removed).T)\n\n    # Transpose right\n    elif input_left[-rs:] == input_right[-rs:]:\n        new_view = np.dot(\n            op1.reshape(dim_left, dim_removed),\n            op2.reshape(dim_right, dim_removed).T)\n\n    # Tranpose left\n    elif input_left[:rs] == input_right[:rs]:\n        new_view = np.dot(\n            op1.reshape(dim_removed, dim_left).T,\n            op2.reshape(dim_removed, dim_right))\n\n    # If we have to transpose vector-matrix, einsum is faster\n    elif (len(keep_left) == 0) or (len(keep_right) == 0):\n        new_view = np.einsum(input_string, op1, op2)\n        used_einsum = True\n\n    else:\n        new_view = np.tensordot(op1, op2, axes=tdot_axes)\n\n    # Make sure the resulting shape is correct\n    if (new_view.shape != shape_result) and not used_einsum:\n        if (len(shape_result) > 0):\n            new_view = new_view.reshape(shape_result)\n        else:\n            new_view = np.squeeze(new_view)\n\n    # In-place mult by prefactor if requested\n    if prefactor is not None:\n        new_view *= prefactor\n\n    # Do final tranpose if needed\n    if used_einsum:\n        return new_view\n    elif tdot_result == output_ind:\n        return new_view\n    else:\n        return np.einsum(tdot_result + \'->\' + output_ind, new_view)\n\n\nclass helper_diis(object):\n    def __init__(self, t1, t2, max_diis):\n\n        self.oldt1 = t1.copy()\n        self.oldt2 = t2.copy()\n        self.diis_vals_t1 = [t1.copy()]\n        self.diis_vals_t2 = [t2.copy()]\n        self.diis_errors = []\n        self.diis_size = 0\n        self.max_diis = max_diis\n\n    def add_error_vector(self, t1, t2):\n\n        # Add DIIS vectors\n        self.diis_vals_t1.append(t1.copy())\n        self.diis_vals_t2.append(t2.copy())\n        # Add new error vectors\n        error_t1 = (self.diis_vals_t1[-1] - self.oldt1).ravel()\n        error_t2 = (self.diis_vals_t2[-1] - self.oldt2).ravel()\n        self.diis_errors.append(np.concatenate((error_t1, error_t2)))\n        self.oldt1 = t1.copy()\n        self.oldt2 = t2.copy()\n\n    def extrapolate(self, t1, t2):\n\n        # Limit size of DIIS vector\n        if (len(self.diis_vals_t1) > self.max_diis):\n            del self.diis_vals_t1[0]\n            del self.diis_vals_t2[0]\n            del self.diis_errors[0]\n\n        self.diis_size = len(self.diis_vals_t1) - 1\n\n        # Build error matrix B\n        B = np.ones((self.diis_size + 1, self.diis_size + 1)) * -1\n        B[-1, -1] = 0\n\n        for n1, e1 in enumerate(self.diis_errors):\n            B[n1, n1] = np.dot(e1, e1)\n            for n2, e2 in enumerate(self.diis_errors):\n                if n1 >= n2: continue\n                B[n1, n2] = np.dot(e1, e2)\n                B[n2, n1] = B[n1, n2]\n\n        B[:-1, :-1] /= np.abs(B[:-1, :-1]).max()\n\n        # Build residual vector\n        resid = np.zeros(self.diis_size + 1)\n        resid[-1] = -1\n\n        # Solve pulay equations\n        ci = np.linalg.solve(B, resid)\n\n        # Calculate new amplitudes\n        t1 = np.zeros_like(self.oldt1)\n        t2 = np.zeros_like(self.oldt2)\n        for num in range(self.diis_size):\n            t1 += ci[num] * self.diis_vals_t1[num + 1]\n            t2 += ci[num] * self.diis_vals_t2[num + 1]\n\n        # Save extrapolated amplitudes to old_t amplitudes\n        self.oldt1 = t1.copy()\n        self.oldt2 = t2.copy()\n\n        return t1, t2\n'"
One-Electron-Property/Restrained-Electrostatic-Potential/espfit.py,26,"b'""""""\nFitting procedure for RESP charges.\n\nReference: \nEquations taken from [Bayly:93:10269].\n""""""\n\n__authors__   =  ""Asim Alenaizan""\n__credits__   =  [""Asim Alenaizan""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2018-04-28""\n\nimport numpy as np\nimport copy\n\ndef esp_solve(a, b):\n    """"""Solves for point charges: A*q = B\n\n    Parameters\n    ----------\n    a : np.array\n        array of matrix A\n    b : np.array\n        array of matrix B\n    \n    Return\n    ------\n    q : np.array\n        array of charges\n    """"""\n    q = np.linalg.solve(a, b)\n    # Warning for near singular matrix\n    # in case np.linalg.solve does not detect singularity\n    note = \'\'\n    if np.linalg.cond(a) > 1/np.finfo(a.dtype).eps:\n        note = ""Possible fit problem; singular matrix""\n    return q, note\n\ndef restraint(q, akeep, resp_a, resp_b, ihfree, symbols, n_atoms, n_constraints):\n    """"""Adds hyperbolic restraint to matrix A\n\n    Parameters\n    ---------- \n    q : np.array\n        array of charges\n    akeep : np.array\n        array of unrestrained A matrix\n    resp_a : list\n        list of floats of restraint scale a for each molecule\n    resp_b : list\n        list of floats of restraint parabola tightness b for each molecule\n    ihfree : list\n        list of bools on whether hydrogen excluded or included in restraint for each molecule\n    symbols : list\n        list of arrays of element symbols for each molecule\n    n_atoms : list\n        list of the number of atoms in each molecule\n    n_constraints : list\n        list of the number of constraints for each molecule\n\n    Returns\n    -------\n    a : np.array\n        restrained A array\n    """"""\n\n    # hyperbolic Restraint\n    # [Bayly:93:10271] (Eqs. 10, 13)\n    a = copy.deepcopy(akeep)\n    n_mol = len(n_atoms)\n    index = 0\n    index_q = 0\n    for mol in range(n_mol):\n        for i in range(n_atoms[mol]):\n            if not ihfree[mol] or symbols[mol][i] != \'H\':\n                a[index+i, index+i] = akeep[index+i, index+i]\\\n                + resp_a[mol]/np.sqrt(q[index_q]**2 + resp_b[mol]**2)\n            index_q += 1\n        index += n_atoms[mol] + n_constraints[mol]\n    return a\n\ndef iterate(q, akeep, b, resp_a, resp_b, ihfree, symbols, toler,\\\n            maxit, n_atoms, n_constraints, indices):\n    """"""Iterates the RESP fitting procedure\n\n    Parameters\n    ----------\n    q : np.array\n        array of initial charges \n    akeep : np.array\n        array of unrestrained A matrix\n    b : np.array\n        array of matrix B\n    resp_a : list\n        list of floats of restraint scale a for each molecule\n    resp_b : list\n        list of floats of restraint parabola tightness b for each molecule\n    ihfree : list\n        list of bools on whether hydrogen excluded or included in restraint for each molecule\n    symbols : list\n        list of arrays of element symbols for each molecule\n    toler : float\n        tolerance for charges in the fitting\n    maxit : int\n        maximum number of iterations\n    n_atoms : list\n        list of the number of atoms in each molecule\n    n_constraints : list\n        list of the number of constraints for each molecule\n    indices : np.array\n        array of the indices for the atoms in the A and B matrices\n\n    Returns\n    -------\n    q : np.array\n        array of the fitted charges\n    """"""\n    n_mols = len(n_atoms)\n    qkeep = q[indices]\n    niter = 0\n    difm = 1\n    while difm > toler and niter < maxit:\n        index = 0\n        niter += 1\n        a = restraint(q[indices], akeep, resp_a, resp_b, ihfree,\\\n                      symbols, n_atoms, n_constraints)\n        q, note = esp_solve(a, b)\n        q_q = q[indices]\n        difm = 0\n            \n        for i in range(len(q_q)):\n            dif = (q_q[i]-qkeep[i])**2\n            if difm < dif:\n                difm = dif\n        qkeep = copy.deepcopy(q_q)\n        difm = np.sqrt(difm)\n    if difm > toler:\n        note += \'\\nCharge fitting did not converge; \' +\\\n               \'try increasing the maximum number of iterations to \' +\\\n               \'> %i.\' %maxit\n    return q_q, note\n\ndef intramolecular_constraints(constraint_charge, constraint_equal, constraint_groups):\n    """"""Extracts intramolecular constraints from user constraint input\n\n    Parameters\n    ----------\n    constraint_charge : list\n        list of lists of charges and atom indices list\n        e.g. [[0, [1, 2]], [1, [3, 4]]]\n        The sum of charges on 1 and 2 will equal 0\n        The sum of charges on 3 and 4 will equal 1\n    constraint_equal : list\n        list of lists of two lists of indices of atoms to \n        have equal charge element by element\n        e.g. [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n        atoms 1 and 3 will have equal charge\n        atoms 2 and 4 will have equal charge\n        and similarly for 5, 6, 7 and 8\n    constraint_group : list\n        list of lists of indices of atoms to have equal charge\n        e.g. [[1, 2], [3, 4]]\n        atoms 1 and 2 will have equal charge\n        atoms 3 and 4 will have equal charge\n\n    Returns\n    -------\n    constrained_charges : list\n        list of fixed charges \n    constrained_indices : list\n        list of lists of indices of atoms in a constraint\n        negative number before an index means\n        the charge of that atom will be subtracted.\n    \n    Notes\n    -----\n    Atom indices starts with 1 not 0.\n    Total charge constraint is added by default for the first molecule.\n    """"""                \n    constrained_charges = []\n    constrained_indices = []\n    for i in constraint_charge:\n        constrained_charges.append(i[0])\n        group = []\n        for k in i[1]:\n            group.append(k)\n        constrained_indices.append(group)\n\n    for i in constraint_equal:\n        for j in range(len(i[0])):\n            group = []\n            constrained_charges.append(0)\n            group.append(-i[0][j])\n            group.append(i[1][j])\n            constrained_indices.append(group)\n\n    for i in constraint_groups:\n        for j in range(1, len(i)):\n            group = []\n            constrained_charges.append(0)\n            group.append(-i[j-1])\n            group.append(i[j])\n            constrained_indices.append(group)\n    return constrained_charges, constrained_indices\n\ndef intermolecular_constraints(constraint_charge, constraint_equal):\n    """"""Extracts intermolecular constraints from user constraint input\n\n    Parameters\n    ----------\n    constraint_charge : list \n        list of list of lists of charges and atom indices list\n        e.g. [[1, [[1, [1, 2]], [2, [3, 4]]]]]\n        The sum of charges on atoms 1 and 2 of molecule 1\n        and atoms 3 and 4 of molecule 2 will equal 1.\n    constraint_equal : list\n        list of list of list of indices of atoms to have\n        equal charge in two molecules.\n        e.g. [[[1, [1, 2]], [2, [3, 4]]]]\n        charges on atoms 1 and 2 in molecule 1 will equal\n        charges on  atoms 3 and 4 in molecule 2, respectively.\n\n    Returns\n    -------\n    constrained_charges : list\n        list of fixed charges \n    constrained_indices : list \n        list of lists of indices of atoms in a constraint\n        negative number before an index means\n        the charge of that atom will be subtracted.\n    molecules : list\n        list of lists of constrained molecules.\n\n    Note\n    ----\n    Atom indices starts with 1 not 0\n    """"""\n    constrained_charges = []\n    constrained_indices = []\n    molecules = []\n    for i in constraint_charge:\n        constrained_charges.append(i[0])\n        mol = []\n        group_big = []\n        for j in i[1]:\n            mol.append(j[0])\n            group = []\n            for k in j[1]:\n                group.append(k)\n            group_big.append(group)\n        constrained_indices.append(group_big)\n        molecules.append(mol)\n\n    for i in constraint_equal:\n        for j in range(len(i[0][1])):\n            molecules.append([i[0][0], i[1][0]])\n            group = []\n            constrained_charges.append(0)\n            group.append([-i[0][1][j]])\n            group.append([i[1][1][j]])\n            constrained_indices.append(group)\n    return constrained_charges, constrained_indices, molecules\n\n\ndef fit(options, inter_constraint):\n    """"""Performs ESP and RESP fits.\n\n    Parameters\n    ----------\n    options : list\n        list of dictionaries of fitting options and internal data\n    inter_constraint : dict\n        dictionary of user-defined intermolecular constraints.\n\n    Returns\n    -------\n    qf : list\n        list of np.arrays of fitted charges\n    labelf : list\n        list of strings of fitting methods i.e. ESP and RESP\n    notes : list\n        list of strings of notes on the fitting\n    """"""\n    rest = options[0][\'RESTRAINT\'] \n    n_mols = len(options)\n    qf = []\n    labelf = []\n    notes = []\n    invr, coordinates, n_constraint, symbols, n_atoms = [], [], [], [], []\n    constrained_charges, constrained_indices = [], []\n    ndim = 0\n    con_charges_sys, con_indices_sys, con_mol_sys = intermolecular_constraints(\n                                                     inter_constraint[\'CHARGE\'],\n                                                     inter_constraint[\'EQUAL\'])\n    n_sys_constraint = len(con_charges_sys)\n    for mol in range(n_mols):\n        invr.append(options[mol][\'invr\'])\n        coordinates.append(options[mol][\'coordinates\'])\n        symbols.append(options[mol][\'symbols\'])\n        n_atoms.append(len(symbols[mol]))\n        constraint_charge = options[mol][\'CONSTRAINT_CHARGE\']\n        constraint_equal = options[mol][\'CONSTRAINT_EQUAL\']\n        constraint_groups = options[mol][\'CONSTRAINT_GROUP\']\n        # Get user-defined constraints\n        charges, indices = intramolecular_constraints(constraint_charge,\n                                                       constraint_equal,\n                                                       constraint_groups)\n        constrained_charges.append(charges)\n        constrained_indices.append(indices)\n        n_con = len(charges)\n        if mol == 0:\n            n_con += 1\n        n_constraint.append(n_con)\n        ndim += n_atoms[mol] + n_constraint[mol]\n    n_atoms = np.array(n_atoms)\n    n_constraint = np.array(n_constraint)\n    symbols = np.array(symbols, dtype=\'str\')\n    # Additional constraint to make charges in different molecules equal\n    # to the charge in the first molecule\n    # Also, Total charges = molecular charge\n    ndim += n_sys_constraint\n    a = np.zeros((ndim, ndim))\n    b = np.zeros(ndim)\n    \n    edges_i = 0\n    edges_f = 0\n    indices = []\n    # Bayly:93:10271 (Eqs. 12-14)\n    for mol in range(n_mols):\n        indices.append(range(edges_i, edges_i+n_atoms[mol]))\n        # Construct A: A_jk = sum_i [(1/r_ij)*(1/r_ik)]\n        inv = invr[mol].reshape((1, invr[mol].shape[0], invr[mol].shape[1]))\n        a[edges_i:n_atoms[mol]+edges_i,\n          edges_i:n_atoms[mol]+edges_i] = np.einsum(""iwj, iwk -> jk"", inv, inv)\n\n        # Construct B: B_j = sum_i (V_i/r_ij)\n        b[edges_i:n_atoms[mol]+edges_i] = np.dot(options[mol][\'esp_values\'], invr[mol])\n        # Sum of point charges = molecular charge\n        a[edges_i:n_atoms[mol]+edges_i, edges_i:n_atoms[mol]+edges_i] *= options[mol][\'WEIGHT\']**2\n        b[edges_i:n_atoms[mol]+edges_i] *= options[mol][\'WEIGHT\']**2\n        edges_f += n_atoms[mol]\n        if mol == 0:\n            a[:n_atoms[0], n_atoms[0]] = 1\n            a[n_atoms[0], :n_atoms[0]] = 1\n            b[n_atoms[0]] = options[0][\'mol_charge\']\n            edges_f += 1\n\n        # Add constraints to matrices A and B\n        for i in range(1, n_constraint[mol]+1):\n            if mol == 0 and i == n_constraint[mol]:\n                # To account for the total charge constraints in the first molecule\n                break\n            b[edges_f] = constrained_charges[mol][i-1]\n            for k in constrained_indices[mol][i-1]:\n                if k > 0:\n                    a[edges_f, edges_i+k-1] = 1\n                    a[edges_i+k-1, edges_f] = 1\n                else:\n                    a[edges_f, edges_i-k-1] = -1\n                    a[edges_i-k-1, edges_f] = -1\n            edges_f += 1\n        edges_i = edges_f\n    indices = np.array(indices).flatten()\n\n        # Add intermolecular constraints to A and B\n    \n    if n_mols > 1:\n        for i in range(n_sys_constraint):\n            b[edges_f] = con_charges_sys[i]\n            for k in range(len(con_indices_sys[i])):\n                for l in con_indices_sys[i][k]:\n                    index = con_mol_sys[i][k]-1\n                    index = int(np.sum(n_atoms[:index]) + np.sum(n_constraint[:index]))\n                    if l > 0:\n                        a[edges_f, index+l-1] = 1\n                        a[index+l-1, edges_f] = 1\n                    else:\n                        a[edges_f, index-l-1] = -1\n                        a[index-l-1, edges_f] = -1\n            edges_f += 1\n\n    labelf.append(\'ESP\')\n    q, note = esp_solve(a, b)\n    qf.append(q[indices])\n    notes.append(note)\n    if not rest:\n        return qf, labelf, notes\n    else:\n        ihfree, resp_a, resp_b = [], [], []\n        for mol in range(n_mols):\n            ihfree.append(options[mol][\'IHFREE\'])\n            resp_a.append(options[mol][\'RESP_A\'])\n            resp_b.append(options[mol][\'RESP_B\'])\n        toler = options[0][\'TOLER\']\n        maxit = options[0][\'MAX_IT\']\n        # Restrained ESP \n        labelf.append(\'RESP\')\n        q, note = iterate(q, a, b, resp_a, resp_b, ihfree, symbols, toler, maxit,\n                    n_atoms, n_constraint, indices)\n        qf.append(q)\n        notes.append(note)\n        return qf, labelf, notes\n'"
One-Electron-Property/Restrained-Electrostatic-Potential/example.py,4,"b'import psi4\nimport resp_driver\nimport numpy as np\n\n# Initialize molecule\nmol = psi4.geometry("""""" C   1.45051389  -0.06628932   0.00000000\n H   1.75521613  -0.62865986  -0.87500146\n H   1.75521613  -0.62865986   0.87500146\n H   1.92173244   0.90485897   0.00000000\n C  -0.04233122   0.09849378   0.00000000\n O  -0.67064817  -1.07620915   0.00000000\n H  -1.60837259  -0.91016601   0.00000000\n O  -0.62675864   1.13160510   0.00000000"""""")\nmol.update_geometry()\n\n# Specify options\noptions = {\'N_VDW_LAYERS\'       : 4,\n           \'VDW_SCALE_FACTOR\'   : 1.4,\n           \'VDW_INCREMENT\'      : 0.2,\n           \'VDW_POINT_DENSITY\'  : 1.0,\n           \'resp_a\'             : 0.0005,\n           \'RESP_B\'             : 0.1,\n           }\n\n# Call for first stage fit\ncharges1 = resp_driver.resp([mol], [options])\nprint(\'Electrostatic Potential Charges\')\nprint(charges1[0][0])\nprint(\'Restrained Electrostatic Potential Charges\')\nprint(charges1[0][1])\n# Reference charges are generated by the R.E.D.-III.5 tools\n# with GAMESS as the quantum chemistry package\nreference_charges1 = np.array([-0.294974,  0.107114,  0.107114,  0.084795,\n                                0.803999, -0.661279,  0.453270, -0.600039])\nprint(\'Reference RESP Charges\')\nprint(reference_charges1)\nprint(\'Difference\')\nprint(charges1[0][1]-reference_charges1)\nprint(\'Example works?\')\nassert np.allclose(charges1[0][1], reference_charges1, atol=5e-4)\n\n# Change the value of the RESP parameter A\noptions[\'resp_a\'] = 0.001\n\n# Add constraint for atoms fixed in second stage fit\nconstraint_charge = []\nfor i in range(4, 8):\n    constraint_charge.append([charges1[0][1][i], [i+1]])\noptions[\'constraint_charge\'] = constraint_charge\noptions[\'constraint_group\'] = [[2, 3, 4]]\noptions[\'grid\'] = \'1_%s_grid.dat\' %mol.name()\noptions[\'esp\'] = \'1_%s_grid_esp.dat\' %mol.name()\nmol.set_name(\'stage2\')\n\n# Call for second stage fit\ncharges2 = resp_driver.resp([mol], [options])\n\n# Get RESP charges\nprint(""\\nStage Two:\\n"")\nprint(\'RESP Charges\')\nprint(charges2[0][1])\nreference_charges2 = np.array([-0.290893,  0.098314,  0.098314,  0.098314,\n                               0.803999, -0.661279,  0.453270, -0.600039])\nprint(\'Reference RESP Charges\')\nprint(reference_charges2)\nprint(\'Difference\')\nprint(charges2[0][1]-reference_charges2)\nprint(\'Example works?\')\nassert np.allclose(charges2[0][1], reference_charges2, atol=5e-4)\n'"
One-Electron-Property/Restrained-Electrostatic-Potential/example2.py,4,"b'import psi4\nimport resp_driver\nimport resp_helper\nimport numpy as np\n\n# Initialize two different conformations of ethanol\ngeometry = """"""C    0.00000000  0.00000000  0.00000000\nC    1.48805540 -0.00728176  0.39653260\nO    2.04971655  1.37648153  0.25604810\nH    3.06429978  1.37151670  0.52641124\nH    1.58679428 -0.33618761  1.43102358\nH    2.03441010 -0.68906454 -0.25521028\nH   -0.40814044 -1.00553466  0.10208540\nH   -0.54635470  0.68178278  0.65174288\nH   -0.09873888  0.32890585 -1.03449097\n""""""\nmol1 = psi4.geometry(geometry)\nmol1.update_geometry()\nmol1.set_name(\'conformer1\')\n\ngeometry = """"""C    0.00000000  0.00000000  0.00000000\nC    1.48013500 -0.00724300  0.39442200\nO    2.00696300  1.29224100  0.26232800\nH    2.91547900  1.25572900  0.50972300\nH    1.61500700 -0.32678000  1.45587700\nH    2.07197500 -0.68695100 -0.26493400\nH   -0.32500012  1.02293415 -0.30034094\nH   -0.18892141 -0.68463906 -0.85893815\nH   -0.64257065 -0.32709111  0.84987482\n""""""\nmol2 = psi4.geometry(geometry)\nmol2.update_geometry()\nmol2.set_name(\'conformer2\')\n\nmolecules = [mol1, mol2]\n\n# Specify intermolecular constraints\nintermolecular_constraint = {\'EQUAL\': [[[1, range(1, 10)], [2, range(1, 10)]]]}\n\n# Specify options\noptions1 = {\'N_VDW_LAYERS\'       : 4,\n           \'VDW_SCALE_FACTOR\'   : 1.4,\n           \'VDW_INCREMENT\'      : 0.2,\n           \'VDW_POINT_DENSITY\'  : 1.0,\n           \'resp_a\'             : 0.0005,\n           \'RESP_B\'             : 0.1,\n           \'restraint\'          : True,\n           \'ihfree\'             : False,\n           \'WEIGHT\'             : 1,\n           }\noptions2 = {\'WEIGHT\': 1}\noptions = [options1, options2]\n\n# Call for first stage fit\ncharges1 = resp_driver.resp(molecules, options, intermolecular_constraint)\n\nprint(""Restrained Electrostatic Potential Charges"")\nprint(charges1[0][1])\n# Reference Charges are generates with the resp module of Ambertools\n# Grid and ESP values are from this code with Psi4\nreference_charges1 = np.array([-0.149134, 0.274292, -0.630868,  0.377965, -0.011016,\n                               -0.009444,  0.058576,  0.044797,  0.044831])\nprint(""Reference RESP Charges"")\nprint(reference_charges1)\nprint(""Difference"")\nprint(charges1[0][1]-reference_charges1)\nprint(""Example works?"")\nassert np.allclose(charges1[0][1], reference_charges1, atol=2e-5)\n\n# Add constraint for atoms fixed in second stage fit\nstage2 = resp_helper.helper_stage2()\nfor mol in range(len(molecules)):\n    stage2.set_stage2_constraint(molecules[mol], charges1[mol][1], options[mol], cutoff=1.2)\n    options[mol][\'grid\'] = \'%i_%s_grid.dat\' %(mol+1, molecules[mol].name())\n    options[mol][\'esp\'] = \'%i_%s_grid_esp.dat\' %(mol+1, molecules[mol].name())\n    options[0][\'resp_a\'] = 0.001\n    molecules[mol].set_name(\'conformer\' + str(mol+1) + \'_stage2\')\n\n# Add intermolecular constraints\nstage2.stage2_intermolecular_constraint(molecules, cutoff=1.2)\n\n# Call for second stage fit\ncharges2 = resp_driver.resp(molecules, options, stage2.intermolecular_constraint)\nprint(""\\nStage Two\\n"")\nprint(""RESP Charges"")\nprint(charges2[0][1])\nreference_charges2 = np.array([-0.079853, 0.253918, -0.630868, 0.377965, -0.007711,\n                               -0.007711, 0.031420,  0.031420, 0.031420])\nprint(""Reference RESP Charges"")\nprint(reference_charges2)\nprint(""Difference"")\nprint(charges2[0][1]-reference_charges2)\nprint(""Example works?"")\nassert np.allclose(charges2[0][1], reference_charges2, atol=2e-5)\n'"
One-Electron-Property/Restrained-Electrostatic-Potential/resp_driver.py,12,"b'""""""\nDriver for the RESP code.\n""""""\n\n__authors__   =  ""Asim Alenaizan""\n__credits__   =  [""Asim Alenaizan""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2018-04-28""\n\nimport numpy as np\nimport os\nfrom espfit import *\nfrom resp_helper import *\n\nbohr_to_angstrom = 0.52917721092\n\ndef resp(molecules, options_list=[], intermol_constraints={}):\n    """"""RESP code driver.\n\n    Parameters\n    ---------- \n    molecules : list\n        list of psi4.Molecule instances\n    options_list : list, optional\n        list of dictionaries of user\'s defined options\n    intermol_constraints : dict, optional\n        dictionary of options for multi-molecules fitting\n\n    Returns\n    -------\n    charges : list\n        list of charges\n\n    Note\n    ----\n    output files : mol_results.dat: fitting results\n                   mol_grid.dat: grid points in molecule.units\n                   mol_grid_esp.dat: QM esp valuese in a.u. \n    """"""\n    # Check options\n    # Large case keys: resp options\n    # Small case key: internal data\n    check = {}\n    for i in intermol_constraints.keys():\n        check[i.upper()] = intermol_constraints[i]\n    intermol_constraints = check\n    if not (\'CHARGE\' in intermol_constraints.keys()):\n        intermol_constraints[\'CHARGE\'] = [] \n    if not (\'EQUAL\' in intermol_constraints.keys()):\n        intermol_constraints[\'EQUAL\'] = []\n\n    # Check options for first molecule\n    check_options = {}\n    for i in sorted(options_list[0].keys()):\n        check_options[i.upper()] = options_list[0][i]\n    options = check_options\n    # VDW surface options\n    if not (\'ESP\' in options.keys()):\n        options[\'ESP\'] = []\n    if not (\'GRID\' in options.keys()):\n        options[\'GRID\'] = []\n    if not (\'N_VDW_LAYERS\' in options.keys()):\n        options[\'N_VDW_LAYERS\'] = 4\n    if not (\'VDW_SCALE_FACTOR\' in options.keys()):\n        options[\'VDW_SCALE_FACTOR\'] = 1.4\n    if not (\'VDW_INCREMENT\' in options.keys()):\n        options[\'VDW_INCREMENT\'] = 0.2\n    if not (\'VDW_POINT_DENSITY\' in options.keys()):\n        options[\'VDW_POINT_DENSITY\'] = 1.0\n    # Hyperbolic restraint options\n    if not (\'WEIGHT\' in options.keys()):\n        options[\'WEIGHT\'] = 1\n    if not (\'RESTRAINT\' in options.keys()):\n        options[\'RESTRAINT\'] = True\n    if options[\'RESTRAINT\']:\n        if not (\'RESP_A\' in options.keys()):\n            options[\'RESP_A\'] = 0.0005\n        if not (\'RESP_B\' in options.keys()):\n            options[\'RESP_B\'] = 0.1\n        if not (\'IHFREE\' in options.keys()):\n            options[\'IHFREE\'] = True\n        if not (\'TOLER\' in options.keys()):\n            options[\'TOLER\'] = 1e-5\n        if not (\'MAX_IT\' in options.keys()):\n            options[\'MAX_IT\'] = 25\n\n    # QM options\n    if not (\'METHOD_ESP\' in options.keys()):\n        options[\'METHOD_ESP\'] = \'scf\'\n    if not (\'BASIS_ESP\' in options.keys()):\n        options[\'BASIS_ESP\'] = \'6-31g*\'\n\n    options_list[0] = options\n\n    final_options_list = []\n    n_atoms = []\n    symbols_list = []\n    for mol in range(len(molecules)):\n        check_options = {}\n        for i in options_list[mol].keys():\n            check_options[i.upper()] = options_list[mol][i]\n        options = check_options\n        # VDW surface options\n        if not (\'RADIUS\' in options.keys()):\n            options[\'RADIUS\'] = {}\n        radii = {}\n        for i in options[\'RADIUS\'].keys():\n            radii[i.upper()] = options[\'RADIUS\'][i]\n        options[\'RADIUS\'] = radii\n\n        # Constraint options\n        if not (\'CONSTRAINT_CHARGE\' in options.keys()):\n            options[\'CONSTRAINT_CHARGE\'] = []\n        if not (\'CONSTRAINT_GROUP\' in options.keys()):\n            options[\'CONSTRAINT_GROUP\'] = []\n        if not (\'CONSTRAINT_EQUAL\' in options.keys()):\n            options[\'CONSTRAINT_EQUAL\'] = []\n    \n        if mol > 0:\n            for i in final_options_list[0].keys():\n                if i not in options.keys() and i.isupper():\n                    options[i] = final_options_list[0][i] \n\n        options[\'mol_charge\'] = molecules[mol].molecular_charge()\n        n_atoms.append(molecules[mol].natom())\n        coordinates = molecules[mol].geometry()\n        coordinates = coordinates.np.astype(\'float\')*bohr_to_angstrom\n        options[\'coordinates\'] = coordinates\n        symbols = []\n        for i in range(n_atoms[-1]):\n            symbols.append(molecules[mol].symbol(i))\n        options[\'symbols\'] = symbols\n        symbols_list.append(symbols)\n\n        if options[\'GRID\']:\n            # Read grid points\n            points = np.loadtxt(options[\'GRID\'])\n            np.savetxt(\'grid.dat\', points, fmt=\'%15.10f\')\n            if \'Bohr\' in str(molecules[mol].units):\n                points *= bohr_to_angstrom\n\n        else:\n            # Get the points at which we\'re going to calculate the ESP surface\n            points = []\n            surface = helper_VDW_surface()\n            for i in range(options[\'N_VDW_LAYERS\']):\n                scale_factor = options[\'VDW_SCALE_FACTOR\'] + i * options[\'VDW_INCREMENT\']\n                surface.vdw_surface(coordinates, symbols, scale_factor,\n                                    options[\'VDW_POINT_DENSITY\'], options[\'RADIUS\'])\n                points.append(surface.shell)\n            radii = surface.radii\n            points = np.concatenate(points)\n            if \'Bohr\' in str(molecules[mol].units):\n                points /= bohr_to_angstrom\n                np.savetxt(\'grid.dat\', points, fmt=\'%15.10f\')\n                points *= bohr_to_angstrom\n            else:\n                np.savetxt(\'grid.dat\', points, fmt=\'%15.10f\')\n\n        # Calculate ESP values at the grid\n        if options[\'ESP\']:\n            # Read electrostatic potential values\n            options[\'esp_values\'] = np.loadtxt(options[\'ESP\'])\n            np.savetxt(\'grid_esp.dat\', options[\'esp_values\'], fmt=\'%15.10f\')\n        else:\n            import psi4\n            psi4.core.set_active_molecule(molecules[mol])\n            psi4.set_options({\'basis\': options[\'BASIS_ESP\']})\n            psi4.prop(options[\'METHOD_ESP\'], properties=[\'GRID_ESP\'])\n            options[\'esp_values\'] = np.loadtxt(\'grid_esp.dat\')\n            psi4.core.clean()\n            \n        os.system(""mv grid.dat %i_%s_grid.dat"" %(mol+1, molecules[mol].name()))\n        os.system(""mv grid_esp.dat %i_%s_grid_esp.dat"" %(mol+1, molecules[mol].name()))\n        # Build a matrix of the inverse distance from each ESP point to each nucleus\n        invr = np.zeros((len(points), len(coordinates)))\n        for i in range(invr.shape[0]):\n            for j in range(invr.shape[1]):\n                invr[i, j] = 1/np.linalg.norm(points[i]-coordinates[j])\n        options[\'invr\'] = invr*bohr_to_angstrom # convert to atomic units\n        options[\'coordinates\'] /= bohr_to_angstrom # convert to angstroms\n\n        final_options_list.append(options)\n    # Calculate charges\n    qf, labelf, notes = fit(final_options_list, intermol_constraints)\n    index = 0\n    charges = []\n    \n    # Exstract the charges\n    for mol in range(len(molecules)):\n        q = []\n        for i in qf:\n            q.append(i[index:index+n_atoms[mol]])\n        index += n_atoms[mol]\n        charges.append(q)\n\n    for mol in range(len(molecules)):\n        options = final_options_list[mol]\n        # Write the resules to disk\n        f = open(str(mol+1) + \'_\' + molecules[mol].name() + ""_results.out"", ""w"")\n        f.write(""\\n Electrostatic potential parameters\\n"")\n        f.write(""\\n Geometry (see% i_%s.xyz in Angstrom)\\n"" %(mol+1, molecules[mol].name()))\n        f.write(""\\n Grid information (see %i_%s_grid.dat in %s)\\n"" %(mol+1, molecules[mol].name(), molecules[mol].units))\n        f.write(""     van der Waals radii (Angstrom):\\n"")\n        for i, j in radii.items():\n            f.write(""                                %8s%8.3f\\n"" %(i, j/scale_factor))\n        f.write(""     Number of VDW layers:             %d\\n"" %(options[""N_VDW_LAYERS""]))\n        f.write(""     VDW scale facotr:                 %.3f\\n"" %(options[""VDW_SCALE_FACTOR""]))\n        f.write(""     VDW increment:                    %.3f\\n"" %(options[""VDW_INCREMENT""]))\n        f.write(""     VDW point density:                %.3f\\n"" %(options[""VDW_POINT_DENSITY""]))\n        f.write(""     Number of grid points:            %d\\n"" %len(options[\'esp_values\']))\n\n        f.write(""\\n Quantum electrostatic potential (see %i_%s_grid_esp.dat)\\n"" %(mol+1,molecules[0].name()))\n        f.write(""     ESP method:                       %s\\n"" %options[\'METHOD_ESP\'])\n        f.write(""     ESP basis set:                    %s\\n"" %options[\'BASIS_ESP\'])\n\n        f.write(""\\n Constraints\\n"")\n        if options[\'CONSTRAINT_CHARGE\']:\n            f.write(""     Charge constraints\\n"")\n            for i in options[\'CONSTRAINT_CHARGE\']:\n                f.write(""         Total charge of %8.5f on the set"" %i[0])\n                for j in i[1]:\n                    f.write(""%4d"" %j)\n                f.write(""\\n"")\n        if options[\'CONSTRAINT_GROUP\'] or options[\'CONSTRAINT_EQUAL\']:\n            f.write(""     Equality constraints\\n"")\n            f.write(""         Equal charges on atoms\\n"")\n            for i in options[\'CONSTRAINT_GROUP\']:\n                f.write(""                              "")\n                for j in i:\n                    f.write(""%4d"" %j)\n                f.write(""\\n"")\n            for i in options[\'CONSTRAINT_EQUAL\']:\n                for j in range(len(i)):\n                    f.write(""                              "")\n                    f.write(""%4d%4d"" %(i[0][j], i[1][j]))\n                    f.write(""\\n"")\n        if intermol_constraints[\'CHARGE\'] or intermol_constraints[\'EQUAL\']:\n            f.write(\'\\n     Intermolecular constraints\\n\')\n            if intermol_constraints[\'CHARGE\']:\n                f.write(\'         Charge constraints\\n\')\n                for i in intermol_constraints[\'CHARGE\']:\n                    f.write(\'             Total charge of %8.5f on the set:\' %i[0])\n                    for j in i[1]:\n                        f.write(\'\\n                 molecule %4d, atoms\' %j[0])\n                        for k in j[1]:\n                            f.write(\'%4d\' %k)\n                    f.write(\'\\n\')\n            if intermol_constraints[\'EQUAL\']:\n                f.write(\'         Equality constraints\\n\')\n                f.write(\'             Equal charges on\\n\')\n                for i in intermol_constraints[\'EQUAL\']:\n                    f.write(\'                 \')\n                    f.write(\'molecule %4d, atoms\' %i[0][0])\n                    for j in i[0][1]:\n                        f.write(\'%4d\' %j)\n                    f.write(\'\\n                 molecule %4d, atoms\' %i[1][0])\n                    for j in i[1][1]:\n                        f.write(\'%4d\' %j)\n                    f.write(\'\\n\\n\')\n        f.write(""\\n Restraint\\n"")\n        if options[\'RESTRAINT\']:\n            f.write(""     Hyperbolic restraint to a charge of zero\\n"")\n            if options[\'IHFREE\']:\n                f.write(""     Hydrogen atoms are not restrained\\n"")\n            f.write(""     resp_a:                           %.4f\\n"" %(options[""RESP_A""]))\n            f.write(""     resp_b:                           %.4f\\n"" %(options[""RESP_B""]))\n        f.write(""\\n Fit\\n"")\n        for i in notes:\n            if i:\n                f.write(i+\'\\n\')\n        f.write(""\\n Electrostatic Potential Charges\\n"")\n        f.write(""   Center  Symbol"")\n        for i in labelf:\n            f.write(""%10s"" %i)\n        f.write(""\\n"")\n        for i in range(n_atoms[mol]):\n            f.write(""   %5d    %s     "" %(i+1, symbols_list[mol][i]))\n            for j in charges[mol]:\n                f.write(""%10.5f"" %j[i])\n            f.write(""\\n"")\n        f.write("" Total Charge:    "")\n        for i in charges[mol]:\n            f.write(""%10.5f"" %np.sum(i))\n        f.write(\'\\n\')\n        f.close()\n\n    return charges\n'"
One-Electron-Property/Restrained-Electrostatic-Potential/resp_helper.py,19,"b'""""""\nHelper classes and functions for the RESP program. \n\nAssists in generating van der Waals surface, computing the electrostatic\npotential with Psi4, and adding constraints for two-stage fitting procedure.\n""""""\n\n__authors__   =  ""Asim Alenaizan""\n__credits__   =  [""Asim Alenaizan""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2018-04-28""\n\nimport numpy as np\n\nclass helper_VDW_surface(object):\n    """"""\n    A script to generate van der Waals surface of molecules.\n    """"""\n\n    #Van der Waals radii (in angstrom) are taken from GAMESS.\n    vdw_r = {\'H\': 1.20, \'HE\': 1.20,\n             \'LI\': 1.37, \'BE\': 1.45, \'B\': 1.45, \'C\': 1.50,\n             \'N\': 1.50, \'O\': 1.40, \'F\': 1.35, \'NE\': 1.30,\n             \'NA\': 1.57, \'MG\': 1.36, \'AL\': 1.24, \'SI\': 1.17,\n             \'P\': 1.80, \'S\': 1.75, \'CL\': 1.70}\n\n    def _surface(self, n):\n        """"""Computes approximately n points on unit sphere. Code adapted from GAMESS.\n\n        Parameters\n        ----------\n        n : int\n            approximate number of requested surface points\n\n        Returns\n        -------\n        np.array\n            nupmy array of xyz coordinates of surface points\n        """"""\n            \n        u = []\n        eps = 1e-10\n        nequat = int(np.sqrt(np.pi*n))\n        nvert = int(nequat/2)\n        nu = 0\n        for i in range(nvert+1):\n            fi = np.pi*i/nvert\n            z = np.cos(fi)\n            xy = np.sin(fi)\n            nhor = int(nequat*xy+eps)\n            if nhor < 1:\n                nhor = 1\n            for j in range(nhor):\n                fj = 2*np.pi*j/nhor\n                x = np.cos(fj)*xy\n                y = np.sin(fj)*xy\n                if nu >= n:\n                    return np.array(u)\n                nu += 1\n                u.append([x, y, z])\n        return np.array(u) \n\n    def vdw_surface(self, coordinates, elements, scale_factor, density, input_radii):\n        """"""Computes points outside the van der Walls\' surface of molecules.\n\n        Parameters\n        ----------\n        coordinates : np.array\n            cartesian coordinates of the nuclei, in units of angstrom\n        elements : list\n            The symbols (e.g. C, H) for the atoms\n        scale_factor : float\n            The points on the molecular surface are set at a distance of\n            scale_factor * vdw_radius away from each of the atoms.\n        density : float\n            The (approximate) number of points to generate per square angstrom\n            of surface area. 1.0 is the default recommended by Kollman & Singh.\n        input_radii : dict\n            dictionary of user\'s defined VDW radii\n\n        Returns\n        -------\n        radii : dict\n            A dictionary of scaled VDW radii\n        surface_points : np.array\n            array of the coordinates of the points on the surface\n        """"""\n        radii = {}\n        surface_points = []\n        # scale radii\n        for i in elements:\n            if i in radii.keys():\n                continue\n            if i in input_radii.keys():\n                radii[i] = input_radii[i] * scale_factor\n            elif i in self.vdw_r.keys():\n                radii[i] = self.vdw_r[i] * scale_factor\n            else:\n                raise KeyError(\'%s is not a supported element; \' %i\n                             + \'use the ""RADIUS"" option to add \'\n                             + \'its van der Waals radius.\')\n        for i in range(len(coordinates)):\n            # calculate points\n            n_points = int(density * 4.0 * np.pi* np.power(radii[elements[i]], 2))\n            dots = self._surface(n_points)\n            dots = coordinates[i] + radii[elements[i]] * dots\n            for j in range(len(dots)):\n                save = True\n                for k in range(len(coordinates)):\n                    if i == k:\n                        continue\n                    # exclude points within the scaled VDW radius of other atoms\n                    d = np.linalg.norm(dots[j] - coordinates[k])\n                    if d < radii[elements[k]]:\n                        save = False\n                        break\n                if save:\n                    surface_points.append(dots[j])\n        self.radii = radii\n        self.shell = np.array(surface_points)\n\nclass helper_stage2(object):\n    """"""\n    A helper script to facilitate the use of constraints for two-stage fitting.\n    """"""\n\n    def _get_stage2_atoms(self, molecule, cutoff=1.2):\n        """"""Determines atoms for second stage fit. The atoms\n           are identified as C-H bonded groups based and a cutoff distance.\n\n        Parameters\n        ----------\n        molecule : psi4.Molecule instance \n\n        cutoff : float, optional\n            a cutoff distance in Angstroms, exclusive\n\n        Returns\n        -------\n        groups : dict\n            a dictionary whose keys are the indecies+1 of carbon\n            atoms and whose elements are the indecies+1 of the\n            connected hydrogen atoms.\n        """"""\n        bohr_to_angstrom = 0.52917721092\n        coordinates = molecule.geometry()\n        coordinates = coordinates.np.astype(\'float\')*bohr_to_angstrom\n        symbols = []\n        for i in range(molecule.natom()):\n            symbols.append(molecule.symbol(i))\n        l = np.zeros(molecule.natom())\n        groups = {}\n        for i in range(molecule.natom()-1):\n            hydrogens = []\n            for j in range(i+1, molecule.natom()):\n                if (symbols[i] == \'C\' and symbols[j] == \'H\') or \\\n                   (symbols[j] == \'C\' and symbols[i] == \'H\'):\n                    d = np.linalg.norm(coordinates[i]-coordinates[j])\n                    if d < cutoff:\n                        if symbols[i] == \'C\': \n                            if i+1 not in groups.keys():\n                                groups[i+1] = []\n                            groups[i+1].append(j+1)\n                        if symbols[j] == \'C\':\n                            if j+1 not in groups.keys():\n                                groups[j+1] = []\n                            groups[j+1].append(i+1)\n\n        return groups\n\n\n    def set_stage2_constraint(self, molecule, charges, options, cutoff=1.2):\n        """"""Sets default constraints for the second stage fit.\n\n        The default constraints are the following:\n        Atoms that are excluded from the second stage fit are constrained\n        to their charges from the first stage fit. C-H groups that have\n        bonds shorter than the cutoff distance are refitted and the\n        hydrogen atoms connected to the same carbon are constrained to\n        have identical charges. This calls self._get_stage2_atoms.\n\n        Parameters\n        ----------\n        molecule : psi4.Molecule instance\n\n        charges : np.array\n            array containing the charges from the first stage fit\n        options : dict\n            dictionary of the fitting options. To be modified in place.\n        cutoff : float, optional\n            cutoff distance in Angstroms, exclusive\n\n        Return\n        ------\n        None\n        """"""\n        second_stage = self._get_stage2_atoms(molecule, cutoff=cutoff)\n        atoms = list(range(1, molecule.natom()+1))\n        constraint_group = []\n        for i in second_stage.keys():\n            atoms.remove(i)\n            group = []\n            for j in second_stage[i]:\n                atoms.remove(j)\n                group.append(j)\n            constraint_group.append(group)\n        constraint_charge = []\n        for i in atoms:\n            constraint_charge.append([charges[i-1], [i]])\n        options[\'constraint_charge\'] = constraint_charge\n        options[\'constraint_group\'] = constraint_group\n\n\n    def stage2_intermolecular_constraint(self, molecules, cutoff=1.2):\n        """"""Determines the default intermolecular constraint for multi-molecular \n        fit, in the second stage fit.\n\n        The default is that the equivalent carbon atoms in the different\n        molecules are made equivalent, and only one of the hydrogens\n        in a group is made equivalent with the corresponding hydrogen\n        in the other molecule. This calls self.get_stage2_atoms and use\n        the given cutoff distance.\n\n        Parameters\n        ----------\n        molecules : list of psi4.Molecule\n            list of psi4.Molecule instances.\n        cutoff : float, optional\n            cutoff distance in Angstroms, exclusive\n\n        Return\n        ------\n        intermolecular_constraint : dict\n            a dictionary of intermolecular constraint   \n        """"""\n        inter_constraint = []\n        for mol in range(len(molecules)):\n            equals = [mol,[]]\n            second_stage = self._get_stage2_atoms(molecules[mol], cutoff=cutoff)\n            for i in second_stage.keys():\n                equals[1].append(i)\n                try:\n                    equals[1].append(second_stage[i][0])\n                except:\n                    pass\n            inter_constraint.append(equals)\n        inter = []\n        for i in range(1, len(inter_constraint)):\n            inter.append([inter_constraint[0], inter_constraint[i]])\n        intermolecular_constraint = {\'EQUAL\': inter} \n        self.intermolecular_constraint = intermolecular_constraint\n'"
Response-Theory/Self-Consistent-Field/CPHF.py,24,"b'""""""\nA reference implementation of the Hartree-Fock static dipole\npolarizability.\n\nReferences:\n- Equations and algorithms from [Szabo:1996] and Project 3 from\nDaniel Crawford\'s programming website:\nhttp://github.com/CrawfordGroup/ProgrammingProjects\n""""""\n\n__authors__   =  ""Daniel G. A. Smith""\n__credits__   = [""Daniel G. A. Smith"", ""Dominic A. Sirianni"", ""Eric J. Berquist"",\n""Robert M. Parrish""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2017-05-23""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\nimport os.path\nimport sys\ndirname = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(os.path.join(dirname, \'../../Self-Consistent-Field\'))\nfrom helper_HF import DIIS_helper\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(""output.dat"", False)\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\n# Set options for CPHF\npsi4.set_options({""basis"": ""aug-cc-pVDZ"",\n                  ""scf_type"": ""direct"",\n                  ""df_scf_guess"": False,\n                  ""e_convergence"": 1e-9,\n                  ""d_convergence"": 1e-9,\n                  ""cphf_tasks"": [\'polarizability\']})\n\n# Set defaults\n# Can be direct or iterative\nmethod = \'iterative\'\nnumpy_memory = 2\nuse_diis = True\n\n# Iterative settings\nmaxiter = 20\nconv = 1.e-9\n\n# Compute the reference wavefunction and CPHF using Psi\nscf_e, scf_wfn = psi4.energy(\'SCF\', return_wfn=True)\n\nC = scf_wfn.Ca()\nCo = scf_wfn.Ca_subset(""AO"", ""OCC"")\nCv = scf_wfn.Ca_subset(""AO"", ""VIR"")\nepsilon = np.asarray(scf_wfn.epsilon_a())\n\nnbf = scf_wfn.nmo()\nnocc = scf_wfn.nalpha()\nnvir = nbf - nocc\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(scf_wfn.basisset())\nS = np.asarray(mints.ao_overlap())\n\n# Get nbf and ndocc for closed shell molecules\nprint(\'\\nNumber of occupied orbitals: %d\' % nocc)\nprint(\'Number of basis functions: %d\' % nbf)\n\n# Grab perturbation tensors in MO basis\nnCo = np.asarray(Co)\nnCv = np.asarray(Cv)\ntmp_dipoles = mints.so_dipole()\ndipoles_xyz = []\nfor num in range(3):\n    Fso = np.asarray(tmp_dipoles[num])\n    Fia = (nCo.T).dot(Fso).dot(nCv)\n    Fia *= -2\n    dipoles_xyz.append(Fia)\n\nif method == \'direct\':\n    # Run a quick check to make sure everything will fit into memory\n    I_Size = (nbf ** 4) * 8.e-9\n    oNNN_Size = (nocc * nbf ** 3) * 8.e-9\n    ovov_Size = (nocc * nocc * nvir * nvir) * 8.e-9\n    print(""\\nTensor sizes:"")\n    print(""ERI tensor           %4.2f GB."" % I_Size)\n    print(""oNNN MO tensor       %4.2f GB."" % oNNN_Size)\n    print(""ovov Hessian tensor  %4.2f GB."" % ovov_Size)\n\n    # Estimate memory usage\n    memory_footprint = I_Size * 1.5\n    if I_Size > numpy_memory:\n        psi4.core.clean()\n        raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                        limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\n    # Compute electronic hessian\n    print(\'\\nForming hessian...\')\n    t = time.time()\n    docc = np.diag(np.ones(nocc))\n    dvir = np.diag(np.ones(nvir))\n    eps_diag = epsilon[nocc:].reshape(-1, 1) - epsilon[:nocc]\n\n    # Form oNNN MO tensor, oN^4 cost\n    MO = np.asarray(mints.mo_eri(Co, C, C, C))\n\n    H = np.einsum(\'ai,ij,ab->iajb\', eps_diag, docc, dvir)\n    H += 4 * MO[:, nocc:, :nocc, nocc:]\n    H -= MO[:, nocc:, :nocc, nocc:].swapaxes(0, 2)\n    H -= MO[:, :nocc, nocc:, nocc:].swapaxes(1, 2)\n\n    print(\'...formed hessian in %.3f seconds.\' % (time.time() - t))\n\n    # Invert hessian (o^3 v^3)\n    print(\'\\nInverting hessian...\')\n    t = time.time()\n    Hinv = np.linalg.inv(H.reshape(nocc * nvir, -1)).reshape(nocc, nvir, nocc, nvir)\n    print(\'...inverted hessian in %.3f seconds.\' % (time.time() - t))\n\n    # Form perturbation response vector for each dipole component\n    x = []\n    for numx in range(3):\n        xcomp = np.einsum(\'iajb,ia->jb\', Hinv, dipoles_xyz[numx])\n        x.append(xcomp)\n\n\nelif method == \'iterative\':\n\n    # Init JK object\n    jk = psi4.core.JK.build(scf_wfn.basisset())\n    jk.initialize()\n\n    # Add blank matrices to the jk object and numpy hooks to C_right\n    npC_right = []\n    for xyz in range(3):\n        jk.C_left_add(Co)\n        mC = psi4.core.Matrix(nbf, nocc)\n        npC_right.append(np.asarray(mC))\n        jk.C_right_add(mC)\n\n    # Build initial guess, previous vectors, diis object, and C_left updates\n    x = []\n    x_old = []\n    diis = []\n    ia_denom = - epsilon[:nocc].reshape(-1, 1) + epsilon[nocc:]\n    for xyz in range(3):\n        x.append(dipoles_xyz[xyz] / ia_denom)\n        x_old.append(np.zeros(ia_denom.shape))\n        diis.append(DIIS_helper())\n\n    # Convert Co and Cv to numpy arrays\n    mCo = Co\n    Co = np.asarray(Co)\n    Cv = np.asarray(Cv)\n\n    print(\'\\nStarting CPHF iterations:\')\n    t = time.time()\n    for CPHF_ITER in range(1, maxiter + 1):\n\n        # Update jk\'s C_right\n        for xyz in range(3):\n            npC_right[xyz][:] = Cv.dot(x[xyz].T)\n\n        # Compute JK objects\n        jk.compute()\n\n        # Update amplitudes\n        for xyz in range(3):\n            # Build J and K objects\n            J = np.asarray(jk.J()[xyz])\n            K = np.asarray(jk.K()[xyz])\n\n            # Bulid new guess\n            X = dipoles_xyz[xyz].copy()\n            X -= (Co.T).dot(4 * J - K.T - K).dot(Cv)\n            X /= ia_denom\n\n            # DIIS for good measure\n            if use_diis:\n                diis[xyz].add(X, X - x_old[xyz])\n                X = diis[xyz].extrapolate()\n            x[xyz] = X.copy()\n\n        # Check for convergence\n        rms = []\n        for xyz in range(3):\n            rms.append(np.max((x[xyz] - x_old[xyz]) ** 2))\n            x_old[xyz] = x[xyz]\n\n        avg_RMS = sum(rms) / 3\n        max_RMS = max(rms)\n\n        if max_RMS < conv:\n            print(\'CPHF converged in %d iterations and %.2f seconds.\' % (CPHF_ITER, time.time() - t))\n            break\n\n        print(\'CPHF Iteration %3d: Average RMS = %3.8f  Maximum RMS = %3.8f\' %\n                (CPHF_ITER, avg_RMS, max_RMS))\n\n\nelse:\n    raise Exception(""Method %s is not recognized"" % method)\n\n\n# Compute 3x3 polarizability tensor\npolar = np.empty((3, 3))\nfor numx in range(3):\n    for numf in range(3):\n        polar[numx, numf] = np.einsum(\'ia,ia->\', x[numx], dipoles_xyz[numf])\n\n# Compare against reference\nref = np.array([\n    [8.01522720,  0.00000000,  0.00000000],\n    [0.00000000, 12.50372724,  0.00000000],\n    [0.00000000,  0.00000000, 10.04226990]\n])\nassert np.allclose(polar, ref, rtol=0, atol=1.e-3)\n\nprint(\'\\nCPHF Dipole Polarizability:\')\nprint(np.around(polar, 5))\n'"
Response-Theory/Self-Consistent-Field/TDHF.py,33,"b'""""""\nA Psi4 input script to compute TDHF linear response. As a note this is, by far,\nnot the most efficiently algorithm, but certainly the most verbose.\n\nReferences:\n- TDHF equations and algorithms taken from [Amos:1985:2186] and [Helgaker:2000]\n- Gauss-Legendre integration from [Amos:1985:2186] and [Jiemchooroj:2006:124306]\n""""""\n\n__authors__ = ""Daniel G. A. Smith""\n__credits__ = [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-09-30""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, threshold=2000, suppress=True)\nimport psi4\n\n# Set memory & output file\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\n# Set molecule to dimer\nmol = psi4.geometry(""""""\nBe  0  0  0\nsymmetry c1\n"""""")\n\npsi4.set_options({""scf_type"": ""out_of_core"",\n                  ""basis"": ""aug-cc-pVTZ"",\n                  ""e_convergence"": 1e-8,\n                  ""d_convergence"": 1e-8})\n\nt = time.time()\nscf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\nprint(\'SCF took                %5.3f seconds\' % ( time.time() - t))\n\nCo = wfn.Ca_subset(""AO"", ""OCC"")\nCv = wfn.Ca_subset(""AO"", ""VIR"")\nepsilon = np.asarray(wfn.epsilon_a())\n\nnbf = wfn.nmo()\nndocc = wfn.nalpha()\nnvir = nbf - ndocc\nnov = ndocc * nvir\nprint(\'\')\nprint(\'Ndocc: %d\' % ndocc)\nprint(\'Nvir:  %d\' % nvir)\nprint(\'Nrot:  %d\' % nov)\nprint(\'\')\n\neps_v = epsilon[ndocc:]\neps_o = epsilon[:ndocc]\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nS = np.asarray(mints.ao_overlap())\nI = mints.ao_eri()\nv_ijab = np.asarray(mints.mo_transform(I, Co, Co, Cv, Cv))\nv_iajb = np.asarray(mints.mo_transform(I, Co, Cv, Co, Cv))\nCo = np.asarray(Co)\nCv = np.asarray(Cv)\nprint(\'Integral transform took %5.3f seconds\\n\' % ( time.time() - t))\n\n# Grab perturbation tensors in MO basis\ntmp_dipoles = mints.so_dipole()\ndipoles_xyz = []\nfor num in range(3):\n    Fso = np.asarray(tmp_dipoles[num])\n    Fia = (Co.T).dot(Fso).dot(Cv)\n    Fia *= -2\n    dipoles_xyz.append(Fia)\n\n# Build orbital-Hessian\nt = time.time()\nE1  = np.einsum(\'ab,ij->iajb\', np.diag(eps_v), np.diag(np.ones(ndocc)))\nE1 -= np.einsum(\'ij,ab->iajb\', np.diag(eps_o), np.diag(np.ones(nvir)))\nE1 += 4 * v_iajb\nE1 -= v_ijab.swapaxes(1, 2)\nE1 -= v_iajb.swapaxes(0, 2)\nE1 *= 4\n\n\n# Since we are time dependent we need to build the full Hessian:\n# | A B |      | D  S | |  x |   |  b |\n# | B A |  - w | S -D | | -x | = | -b |\n\n# Build A and B blocks\nA11  = np.einsum(\'ab,ij->iajb\', np.diag(eps_v), np.diag(np.ones(ndocc)))\nA11 -= np.einsum(\'ij,ab->iajb\', np.diag(eps_o), np.diag(np.ones(nvir)))\nA11 += 2 * v_iajb\nA11 -= v_ijab.swapaxes(1, 2)\nA11 *= 2\n\nB11  = -2 * v_iajb\nB11 += v_iajb.swapaxes(0, 2)\nB11 *= 2\n\n# The blocks A - B should be equal to E1 / 2\nprint(\'A11 - B11 == E1 / 2?\',  np.allclose(A11 - B11, E1/2))\nprint(\'\')\n\n# Reshape and jam it together\nA11.shape = (nov, nov)\nB11.shape = (nov, nov)\n\nHess1 = np.hstack((A11, B11))\nHess2 = np.hstack((B11, A11))\nHess = np.vstack((Hess1, Hess2))\n\nS11 = np.zeros_like(A11)\nD11 = np.zeros_like(B11)\nS11[np.diag_indices_from(S11)] = 2\n\nS1 = np.hstack((S11, D11))\nS2 = np.hstack((D11, -S11))\nS = np.vstack((S1, S2))\nprint(\'Hessian formation took  %5.3f seconds\\n\' % ( time.time() - t))\n\n\nHess = Hess.astype(np.complex)\nS = S.astype(np.complex)\n\ndip_x = dipoles_xyz[0].astype(np.complex)\nB = np.hstack((dip_x.ravel(), -dip_x.ravel()))\n\nC6 = np.complex(0, 0)\nhyper_polar = np.complex(0, 0)\nleg_points = 10\nfdds_lambda = 0.30\nprint(\'     Omega      value     weight        sum\')\n\n# Integrate over time use a Gauss-Legendre polynomial.\n# Shift from [-1, 1] to [0, inf) by the transform  (1 - x) / (1 + x)\nfor point, weight in zip(*np.polynomial.legendre.leggauss(leg_points)):\n    if point != 0:\n        omega = fdds_lambda * (1.0 - point) / (1.0 + point)\n        lambda_scale = ( (2 * fdds_lambda) / (point + 1) ** 2)\n    else:\n        omega = 0\n        lambda_scale = 0\n\n    Hw = Hess - S * complex(0, omega)\n\n    Z =  np.linalg.solve(Hw, B)\n    value = -np.vdot(Z, B)\n\n    if abs(value.imag) > 1.e-13:\n        print(\'Warning value of imaginary part is large\', value)\n\n    C6 += (value ** 2) * weight * lambda_scale\n    hyper_polar += value * weight * lambda_scale\n    print(\'% .3e % .3e % .3e % .3e\' % (omega, value.real, weight, weight*value.real))\n\nC6 *= 3.0 / np.pi\nprint(\'\\nFull C6 Value: %s\' % str(C6))\n\n# We can solve static using the above with omega = 0. However a simpler way is\n# just to use the reduced form:\ndip_x = dip_x.ravel()\nstatic_polar = 2 * np.dot(dip_x, np.linalg.solve(A11 - B11, dip_x))\n\nprint(\'\\nComputed values:\')\nprint(\'Alpha                 % 10.5f\' % static_polar.real)\nprint(\'C6                    % 10.5f\' % C6.real)\n\nprint(\'\\nBenchmark values:\')\nprint(\'C6 He  Limit          % 10.5f\' % 1.376)\nprint(\'C6 Li+ Limit          % 10.5f\' % 0.076)\nprint(\'C6 Be  Limit          % 10.5f\' % 282.4)\n'"
Response-Theory/Self-Consistent-Field/beta.py,74,"b'""""""\nA reference implementation to compute the first dipole\nhyperpolarizability $\\beta$ from a restricted HF reference using the\n$2n+1$ rule from perturbation theory.\n\nReferences:\n- Equations taken from [Karna:1991:487]\n""""""\n\n__authors__   =  ""Eric J. Berquist""\n__credits__   = [""Eric J. Berquist""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2017-08-26""\n\nfrom itertools import permutations, product\n\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\nfrom helper_CPHF import helper_CPHF\n\n# Memory for Psi4 in GB\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(""output.dat"", False)\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\n# Set options for CPHF\npsi4.set_options({""basis"": ""aug-cc-pvdz"",\n                  ""scf_type"": ""direct"",\n                  ""df_scf_guess"": False,\n                  ""e_convergence"": 1e-9,\n                  ""d_convergence"": 1e-9})\n\n# Compute the (first) hyperpolarizability corresponding to static\n# fields, beta(0;0,0), eqns. (IV-2a) and (VII-4).\n\nhelper = helper_CPHF(mol)\n# For the $2n+1$ rule, the quadratic response starting quantities must\n# come from linear response.\nhelper.run()\n\nna = np.newaxis\nmoenergies = helper.epsilon\nC = np.asarray(helper.C)\nCo = helper.Co\nCv = helper.Cv\nnbf, norb = C.shape\nnocc = Co.shape[1]\nnvir = norb - nocc\nnov = nocc * nvir\nx = np.asarray(helper.x)\nncomp = x.shape[0]\nintegrals_ao = np.asarray([np.asarray(dipole_ao_component)\n                           for dipole_ao_component in helper.tmp_dipoles])\n\n# form full MO-basis dipole integrals\nintegrals_mo = np.empty(shape=(ncomp, norb, norb))\nfor i in range(ncomp):\n    integrals_mo[i] = (C.T).dot(integrals_ao[i]).dot(C)\n\n# repack response vectors to [norb, norb]; 1/2 is due to X + Y\nU = np.zeros_like(integrals_mo)\nfor i in range(ncomp):\n    U[i, :nocc, nocc:] = 0.5 * x[i].reshape(nocc, nvir)\n    U[i, nocc:, :nocc] = -0.5 * x[i].reshape(nocc, nvir).T\n\n# form G matrices from perturbation and generalized Fock matrices; do\n# one more Fock build for each response vector\njk = psi4.core.JK.build(helper.scf_wfn.basisset())\njk.initialize()\nG = np.empty_like(U)\nR = psi4.core.Matrix(nbf, nocc)\nnpR = np.asarray(R)\nfor i in range(ncomp):\n    V = integrals_mo[i]\n\n    # eqn. (III-1b) Note: this simplified handling of the response\n    # vector transformation for the Fock build is insufficient for\n    # frequency-dependent response.\n    jk.C_clear()\n    # Psi4\'s JK builders don\'t take a density, but a left set of\n    # coefficients with shape [nbf, nocc] and a right set of\n    # coefficents with shape [nbf, nocc]. Because the response vector\n    # describes occ -> vir transitions, we perform ([nocc, nvir] *\n    # [nbf, nvir]^T)^T.\n    L = Co\n    npR[:] = x[i].reshape(nocc, nvir).dot(np.asarray(Cv).T).T\n    jk.C_left_add(L)\n    jk.C_right_add(R)\n    jk.compute()\n    # 1/2 is due to X + Y\n    J = 0.5 * np.asarray(jk.J()[0])\n    K = 0.5 * np.asarray(jk.K()[0])\n\n    # eqn. (21b)\n    F = (C.T).dot(4 * J - K.T - K).dot(C)\n    G[i] = V + F\n\n# form epsilon matrices, eqn. (34)\nE = G.copy()\nomega = 0\nfor i in range(ncomp):\n    eoU = (moenergies[..., na] + omega) * U[i]\n    Ue = U[i] * moenergies[na]\n    E[i] += (eoU - Ue)\n\n# Assume some symmetry and calculate only part of the tensor.\n# eqn. (VII-4)\nhyperpolarizability = np.zeros(shape=(6, 3))\noff1 = [0, 1, 2, 0, 0, 1]\noff2 = [0, 1, 2, 1, 2, 2]\nfor r in range(6):\n    b = off1[r]\n    c = off2[r]\n    for a in range(3):\n        tl1 = 2 * np.trace(U[a].dot(G[b]).dot(U[c])[:nocc, :nocc])\n        tl2 = 2 * np.trace(U[a].dot(G[c]).dot(U[b])[:nocc, :nocc])\n        tl3 = 2 * np.trace(U[c].dot(G[a]).dot(U[b])[:nocc, :nocc])\n        tr1 = np.trace(U[c].dot(U[b]).dot(E[a])[:nocc, :nocc])\n        tr2 = np.trace(U[b].dot(U[c]).dot(E[a])[:nocc, :nocc])\n        tr3 = np.trace(U[c].dot(U[a]).dot(E[b])[:nocc, :nocc])\n        tr4 = np.trace(U[a].dot(U[c]).dot(E[b])[:nocc, :nocc])\n        tr5 = np.trace(U[b].dot(U[a]).dot(E[c])[:nocc, :nocc])\n        tr6 = np.trace(U[a].dot(U[b]).dot(E[c])[:nocc, :nocc])\n        tl = tl1 + tl2 + tl3\n        tr = tr1 + tr2 + tr3 + tr4 + tr5 + tr6\n        hyperpolarizability[r, a] = -2 * (tl - tr)\n\nref_static = np.array([\n    [ 0.00000001,   0.00000000,   0.22843772],\n    [ 0.00000000,   0.00000000, -25.35476040],\n    [ 0.00000000,   0.00000000, -10.84023375],\n    [ 0.00000000,   0.00000000,   0.00000000],\n    [ 0.22843772,   0.00000000,   0.00000000],\n    [ 0.00000000, -25.35476040,   0.00000000]\n])\nassert np.allclose(ref_static, hyperpolarizability, rtol=0.0, atol=1.0e-3)\nprint(\'\\nFirst dipole hyperpolarizability (static):\')\nprint(hyperpolarizability)\n\n# Compute the (first) hyperpolarizability corresponding to\n# second-harmonic generation, beta(-2w;w,w), eqns. (IV-2c) and\n# (VII-1). Because two different frequencies are involved, the linear\n# response equations must be solved twice.\n\nprint(\'Setting up for second-harmonic generation (SHG) calculation...\')\n# In SHG, the first frequency is doubled to obtain the second\n# frequency. All variables containing \'1\' correspond to the first\n# (set) frequency, and all variables containing \'2\' correspond to the\n# second (doubled) frequency.\nf1 = 0.0773178\nf2 = 2 * f1\n\nprint(\'\\nForming response vectors for {} a.u.\'.format(f1))\nhelper1 = helper_CPHF(mol)\nhelper1.solve_dynamic_direct(omega=f1)\nhelper1.form_polarizability()\nprint(helper1.polar)\nprint(\'\\nForming response vectors for {} a.u.\'.format(f2))\nhelper2 = helper_CPHF(mol)\nhelper2.solve_dynamic_direct(omega=f2)\nhelper2.form_polarizability()\nprint(helper2.polar)\n\nrspvecs1 = helper1.x\nrspvecs2 = helper2.x\n\n# repack response vectors to [norb, norb]\nU1 = np.zeros_like(integrals_mo)\nU2 = np.zeros_like(integrals_mo)\nfor i in range(ncomp):\n    U1[i, :nocc, nocc:] = rspvecs1[i][nov:].reshape(nocc, nvir)\n    U1[i, nocc:, :nocc] = rspvecs1[i][:nov].reshape(nocc, nvir).T\n    U2[i, :nocc, nocc:] = rspvecs2[i][nov:].reshape(nocc, nvir)\n    U2[i, nocc:, :nocc] = rspvecs2[i][:nov].reshape(nocc, nvir).T\n\nG1 = np.empty_like(U1)\nG2 = np.empty_like(U2)\nR1_l = psi4.core.Matrix(nbf, nocc)\nR1_r = psi4.core.Matrix(nbf, nocc)\nR2_l = psi4.core.Matrix(nbf, nocc)\nR2_r = psi4.core.Matrix(nbf, nocc)\nnpR1_l = np.asarray(R1_l)\nnpR1_r = np.asarray(R1_r)\nnpR2_l = np.asarray(R2_l)\nnpR2_r = np.asarray(R2_r)\njk.C_clear()\njk.C_left_add(Co)\njk.C_right_add(R1_l)\njk.C_left_add(Co)\njk.C_right_add(R1_r)\njk.C_left_add(Co)\njk.C_right_add(R2_l)\njk.C_left_add(Co)\njk.C_right_add(R2_r)\nnCo = np.asarray(Co)\n# Do 4 Fock builds at a time: X/Y vectors for both frequencies; loop\n# over operator components\nfor i in range(3):\n    V = integrals_mo[i]\n\n    x1 = U1[i, :nocc, :]\n    y1 = U1[i, :, :nocc]\n    x2 = U2[i, :nocc, :]\n    y2 = U2[i, :, :nocc]\n    npR1_l[:] = C.dot(x1.T)\n    npR1_r[:] = C.dot(y1)\n    npR2_l[:] = C.dot(x2.T)\n    npR2_r[:] = C.dot(y2)\n\n    jk.compute()\n\n    J1_l = -np.asarray(jk.J()[0])\n    K1_l = -np.asarray(jk.K()[0])\n    J1_r = np.asarray(jk.J()[1])\n    K1_r = np.asarray(jk.K()[1])\n    J2_l = -np.asarray(jk.J()[2])\n    K2_l = -np.asarray(jk.K()[2])\n    J2_r = np.asarray(jk.J()[3])\n    K2_r = np.asarray(jk.K()[3])\n    J1 = J1_l + J1_r\n    J2 = J2_l + J2_r\n    K1 = K1_l + K1_r.T\n    K2 = K2_l + K2_r.T\n\n    F1 = (C.T).dot(2 * J1 - K1).dot(C)\n    F2 = (C.T).dot(2 * J2 - K2).dot(C)\n    G1[i, ...] = V + F1\n    G2[i, ...] = V + F2\n\n# form epsilon matrices, eqn. (34), one for each frequency\nE1 = G1.copy()\nE2 = G2.copy()\nfor i in range(ncomp):\n    eoU1 = (moenergies[..., na] + f1) * U1[i]\n    Ue1 = U1[i] * moenergies[na]\n    E1[i] += (eoU1 - Ue1)\n    eoU2 = (moenergies[..., na] + f2) * U2[i]\n    Ue2 = U2[i] * moenergies[na]\n    E2[i] += (eoU2 - Ue2)\n\n# Assume some symmetry and calculate only part of the tensor.\n\nhyperpolarizability = np.zeros(shape=(6, 3))\nfor r in range(6):\n    b = off1[r]\n    c = off2[r]\n    for a in range(3):\n        tl1 = np.trace(U2[a].T.dot(G1[b]).dot(U1[c])[:nocc, :nocc])\n        tl2 = np.trace(U1[c].dot(G1[b]).dot(U2[a].T)[:nocc, :nocc])\n        tl3 = np.trace(U2[a].T.dot(G1[c]).dot(U1[b])[:nocc, :nocc])\n        tl4 = np.trace(U1[b].dot(G1[c]).dot(U2[a].T)[:nocc, :nocc])\n        tl5 = np.trace(U1[c].dot(-G2[a].T).dot(U1[b])[:nocc, :nocc])\n        tl6 = np.trace(U1[b].dot(-G2[a].T).dot(U1[c])[:nocc, :nocc])\n        tr1 = np.trace(U1[c].dot(U1[b]).dot(-E2[a].T)[:nocc, :nocc])\n        tr2 = np.trace(U1[b].dot(U1[c]).dot(-E2[a].T)[:nocc, :nocc])\n        tr3 = np.trace(U1[c].dot(U2[a].T).dot(E1[b])[:nocc, :nocc])\n        tr4 = np.trace(U2[a].T.dot(U1[c]).dot(E1[b])[:nocc, :nocc])\n        tr5 = np.trace(U1[b].dot(U2[a].T).dot(E1[c])[:nocc, :nocc])\n        tr6 = np.trace(U2[a].T.dot(U1[b]).dot(E1[c])[:nocc, :nocc])\n        tl = tl1 + tl2 + tl3 + tl4 + tl5 + tl6\n        tr = tr1 + tr2 + tr3 + tr4 + tr5 + tr6\n        hyperpolarizability[r, a] = 2 * (tl - tr)\n\n# pylint: disable=C0326\nref = np.array([\n    [ 0.00000000,   0.00000000,   1.92505358],\n    [ 0.00000000,   0.00000000, -31.33652886],\n    [ 0.00000000,   0.00000000, -13.92830863],\n    [ 0.00000000,   0.00000000,   0.00000000],\n    [-1.80626084,   0.00000000,   0.00000000],\n    [ 0.00000000, -31.13504192,   0.00000000]\n])\nref_avgs = np.array([0.00000000, 0.00000000, 45.69300223])\nref_avg = 45.69300223\n\nthresh = 1.0e-2\n# assert np.all(np.abs(ref - hyperpolarizability) < thresh)\n\nprint(\'hyperpolarizability: SHG, (-{}; {}, {}), symmetry-unique components\'.format(f2, f1, f1))\nprint(hyperpolarizability)\nprint(\'ref\')\nprint(ref)\n\n# Transpose all frequency-doubled quantities (+2w) to get -2w.\n\nfor i in range(ncomp):\n    U2[i] = U2[i].T\n    G2[i] = -G2[i].T\n    E2[i] = -E2[i].T\n\n# Assume some symmetry and calculate only part of the tensor. This\n# time, work with the in-place manipulated quantities (this tests\n# their correctness).\n\nmU = (U2, U1)\nmG = (G2, G1)\nme = (E2, E1)\n\nhyperpolarizability = np.zeros(shape=(6, 3))\noff1 = [0, 1, 2, 0, 0, 1]\noff2 = [0, 1, 2, 1, 2, 2]\nfor r in range(6):\n    b = off1[r]\n    c = off2[r]\n    for a in range(3):\n        tl1 = np.trace(mU[0][a].dot(mG[1][b]).dot(mU[1][c])[:nocc, :nocc])\n        tl2 = np.trace(mU[1][c].dot(mG[1][b]).dot(mU[0][a])[:nocc, :nocc])\n        tl3 = np.trace(mU[0][a].dot(mG[1][c]).dot(mU[1][b])[:nocc, :nocc])\n        tl4 = np.trace(mU[1][b].dot(mG[1][c]).dot(mU[0][a])[:nocc, :nocc])\n        tl5 = np.trace(mU[1][c].dot(mG[0][a]).dot(mU[1][b])[:nocc, :nocc])\n        tl6 = np.trace(mU[1][b].dot(mG[0][a]).dot(mU[1][c])[:nocc, :nocc])\n        tr1 = np.trace(mU[1][c].dot(mU[1][b]).dot(me[0][a])[:nocc, :nocc])\n        tr2 = np.trace(mU[1][b].dot(mU[1][c]).dot(me[0][a])[:nocc, :nocc])\n        tr3 = np.trace(mU[1][c].dot(mU[0][a]).dot(me[1][b])[:nocc, :nocc])\n        tr4 = np.trace(mU[0][a].dot(mU[1][c]).dot(me[1][b])[:nocc, :nocc])\n        tr5 = np.trace(mU[1][b].dot(mU[0][a]).dot(me[1][c])[:nocc, :nocc])\n        tr6 = np.trace(mU[0][a].dot(mU[1][b]).dot(me[1][c])[:nocc, :nocc])\n        tl = [tl1, tl2, tl3, tl4, tl5, tl6]\n        tr = [tr1, tr2, tr3, tr4, tr5, tr6]\n        hyperpolarizability[r, a] = 2 * (sum(tl) - sum(tr))\n\nassert np.all(np.abs(ref - hyperpolarizability) < thresh)\n\n# Assume no symmetry and calculate the full tensor.\n\nhyperpolarizability_full = np.zeros(shape=(3, 3, 3))\n\n# components x, y, z\nfor ip, p in enumerate(list(product(range(3), range(3), range(3)))):\n    a, b, c = p\n    tl, tr = [], []\n    # 1st tuple -> index a, b, c (*not* x, y, z!)\n    # 2nd tuple -> index frequency (0 -> -2w, 1 -> +w)\n    for iq, q in enumerate(list(permutations(zip(p, (0, 1, 1)), 3))):\n        d, e, f = q\n        tlp = (mU[d[1]][d[0]]).dot(mG[e[1]][e[0]]).dot(mU[f[1]][f[0]])\n        tle = np.trace(tlp[:nocc, :nocc])\n        tl.append(tle)\n        trp = (mU[d[1]][d[0]]).dot(mU[e[1]][e[0]]).dot(me[f[1]][f[0]])\n        tre = np.trace(trp[:nocc, :nocc])\n        tr.append(tre)\n    hyperpolarizability_full[a, b, c] = 2 * (sum(tl) - sum(tr))\nprint(\'hyperpolarizability: SHG, (-{}; {}, {}), full tensor\'.format(f2, f1, f1))\nprint(hyperpolarizability_full)\n\n# Check that the elements of the reduced and full tensors are\n# equivalent.\n\nfor r in range(6):\n    b = off1[r]\n    c = off2[r]\n    for a in range(3):\n        diff = hyperpolarizability[r, a] - hyperpolarizability_full[a, b, c]\n        assert abs(diff) < 1.0e-13\n'"
Response-Theory/Self-Consistent-Field/helper_CPHF.py,54,"b'""""""\nHelper classes and functions for molecular properties requiring\nsolution of CPHF equations.\n\nReferences:\n- Equations and algorithms from [Szabo:1996] and Project 3 from\nDaniel Crawford\'s programming website:\nhttp://github.com/CrawfordGroup/ProgrammingProjects\n""""""\n\n__authors__   =  ""Daniel G. A. Smith""\n__credits__   = [""Daniel G. A. Smith"", ""Eric J. Berquist""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2017-8-30""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\nimport os.path\nimport sys\ndirname = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(os.path.join(dirname, \'../../Self-Consistent-Field\'))\nfrom helper_HF import DIIS_helper\n\n\nclass helper_CPHF(object):\n\n    def __init__(self, mol, numpy_memory=2):\n\n        self.mol = mol\n        self.numpy_memory = numpy_memory\n\n        # Compute the reference wavefunction and CPHF using Psi\n        scf_e, self.scf_wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n        self.C = self.scf_wfn.Ca()\n        self.Co = self.scf_wfn.Ca_subset(""AO"", ""OCC"")\n        self.Cv = self.scf_wfn.Ca_subset(""AO"", ""VIR"")\n        self.epsilon = np.asarray(self.scf_wfn.epsilon_a())\n\n        self.nbf = self.scf_wfn.nmo()\n        self.nocc = self.scf_wfn.nalpha()\n        self.nvir = self.nbf - self.nocc\n\n        # Integral generation from Psi4\'s MintsHelper\n        self.mints = psi4.core.MintsHelper(self.scf_wfn.basisset())\n\n        # Get nbf and ndocc for closed shell molecules\n        print(\'\\nNumber of occupied orbitals: %d\' % self.nocc)\n        print(\'Number of basis functions: %d\' % self.nbf)\n\n        # Grab perturbation tensors in MO basis\n        nCo = np.asarray(self.Co)\n        nCv = np.asarray(self.Cv)\n        self.tmp_dipoles = self.mints.so_dipole()\n        self.dipoles_xyz = []\n        for num in range(3):\n            Fso = np.asarray(self.tmp_dipoles[num])\n            Fia = (nCo.T).dot(Fso).dot(nCv)\n            Fia *= -2\n            self.dipoles_xyz.append(Fia)\n\n        self.x = None\n        self.rhsvecs = None\n\n    def run(self, method=\'direct\', omega=None):\n        self.method = method\n        if self.method == \'direct\':\n            if not omega:\n                self.solve_static_direct()\n            else:\n                self.solve_dynamic_direct(omega=omega)\n        elif self.method == \'iterative\':\n            if not omega:\n                self.solve_static_iterative()\n            else:\n                self.solve_dynamic_iterative(omega=omega)\n        else:\n            raise Exception(""Method %s is not recognized"" % self.method)\n        self.form_polarizability()\n\n    def solve_static_direct(self):\n        # Run a quick check to make sure everything will fit into memory\n        I_Size = (self.nbf ** 4) * 8.e-9\n        oNNN_Size = (self.nocc * self.nbf ** 3) * 8.e-9\n        ovov_Size = (self.nocc * self.nocc * self.nvir * self.nvir) * 8.e-9\n        print(""\\nTensor sizes:"")\n        print(""ERI tensor           %4.2f GB."" % I_Size)\n        print(""oNNN MO tensor       %4.2f GB."" % oNNN_Size)\n        print(""ovov Hessian tensor  %4.2f GB."" % ovov_Size)\n\n        # Estimate memory usage\n        memory_footprint = I_Size * 1.5\n        if I_Size > self.numpy_memory:\n            psi4.core.clean()\n            raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                            limit of %4.2f GB."" % (memory_footprint, self.numpy_memory))\n\n        # Compute electronic Hessian\n        print(\'\\nForming Hessian...\')\n        t = time.time()\n        docc = np.diag(np.ones(self.nocc))\n        dvir = np.diag(np.ones(self.nvir))\n        eps_diag = self.epsilon[self.nocc:].reshape(-1, 1) - self.epsilon[:self.nocc]\n\n        # Form oNNN MO tensor, oN^4 cost\n        MO = np.asarray(self.mints.mo_eri(self.Co, self.C, self.C, self.C))\n\n        H = np.einsum(\'ai,ij,ab->iajb\', eps_diag, docc, dvir)\n        H += 4 * MO[:, self.nocc:, :self.nocc, self.nocc:]\n        H -= MO[:, self.nocc:, :self.nocc, self.nocc:].swapaxes(0, 2)\n\n\n        H -= MO[:, :self.nocc, self.nocc:, self.nocc:].swapaxes(1, 2)\n\n        print(\'...formed Hessian in %.3f seconds.\' % (time.time() - t))\n\n        # Invert Hessian (o^3 v^3)\n        print(\'\\nInverting Hessian...\')\n        t = time.time()\n        Hinv = np.linalg.inv(H.reshape(self.nocc * self.nvir, -1)).reshape(self.nocc, self.nvir, self.nocc, self.nvir)\n        print(\'...inverted Hessian in %.3f seconds.\' % (time.time() - t))\n\n        # Form perturbation response vector for each dipole component\n        self.x = []\n        for numx in range(3):\n            xcomp = np.einsum(\'iajb,ia->jb\', Hinv, self.dipoles_xyz[numx])\n            self.x.append(xcomp.reshape(-1))\n\n        self.rhsvecs = []\n        for numx in range(3):\n            rhsvec = self.dipoles_xyz[numx].reshape(-1)\n            self.rhsvecs.append(rhsvec)\n\n    def solve_dynamic_direct(self, omega=0.0):\n        # Adapted completely from TDHF.py\n\n        eps_v = self.epsilon[self.nocc:]\n        eps_o = self.epsilon[:self.nocc]\n\n        t = time.time()\n        I = self.mints.ao_eri()\n        v_ijab = np.asarray(self.mints.mo_transform(I, self.Co, self.Co, self.Cv, self.Cv))\n        v_iajb = np.asarray(self.mints.mo_transform(I, self.Co, self.Cv, self.Co, self.Cv))\n        print(\'Integral transform took %.3f seconds\\n\' % (time.time() - t))\n\n        # Since we are time dependent we need to build the full Hessian:\n        # | A B |      | D  S | |  x |   |  b |\n        # | B A |  - w | S -D | | -x | = | -b |\n\n        # Build A and B blocks\n        t = time.time()\n        A11  = np.einsum(\'ab,ij->iajb\', np.diag(eps_v), np.diag(np.ones(self.nocc)))\n        A11 -= np.einsum(\'ij,ab->iajb\', np.diag(eps_o), np.diag(np.ones(self.nvir)))\n        A11 += 2 * v_iajb\n        A11 -= v_ijab.swapaxes(1, 2)\n        A11 *= 2\n\n        B11  = -2 * v_iajb\n        B11 += v_iajb.swapaxes(0, 2)\n        B11 *= 2\n\n        # Reshape and jam it together\n        nov = self.nocc * self.nvir\n        A11.shape = (nov, nov)\n        B11.shape = (nov, nov)\n\n        Hess1 = np.hstack((A11, B11))\n        Hess2 = np.hstack((B11, A11))\n        Hess = np.vstack((Hess1, Hess2))\n\n        S11 = np.zeros_like(A11)\n        D11 = np.zeros_like(B11)\n        S11[np.diag_indices_from(S11)] = 2\n\n        S1 = np.hstack((S11, D11))\n        S2 = np.hstack((D11, -S11))\n        S = np.vstack((S1, S2))\n        S *= omega\n        print(\'Hessian formation took %.3f seconds\\n\' % (time.time() - t))\n\n        t = time.time()\n        Hinv = np.linalg.inv(Hess - S)\n        print(\'Hessian inversion took %.3f seconds\\n\' % (time.time() - t))\n\n        self.x = []\n        self.rhsvecs = []\n        for numx in range(3):\n            rhsvec = self.dipoles_xyz[numx].reshape(-1)\n            rhsvec = np.concatenate((rhsvec, -rhsvec))\n            xcomp = Hinv.dot(rhsvec)\n            self.rhsvecs.append(rhsvec)\n            self.x.append(xcomp)\n\n    def solve_static_iterative(self, maxiter=20, conv=1.e-9, use_diis=True):\n\n        # Init JK object\n        jk = psi4.core.JK.build(self.scf_wfn.basisset())\n        jk.initialize()\n\n        # Add blank matrices to the jk object and numpy hooks to C_right\n        npC_right = []\n        for xyz in range(3):\n            jk.C_left_add(self.Co)\n            mC = psi4.core.Matrix(self.nbf, self.nocc)\n            npC_right.append(np.asarray(mC))\n            jk.C_right_add(mC)\n\n        # Build initial guess, previous vectors, diis object, and C_left updates\n        self.x = []\n        x_old = []\n        diis = []\n        ia_denom = - self.epsilon[:self.nocc].reshape(-1, 1) + self.epsilon[self.nocc:]\n        for xyz in range(3):\n            self.x.append(self.dipoles_xyz[xyz] / ia_denom)\n            x_old.append(np.zeros(ia_denom.shape))\n            diis.append(DIIS_helper())\n\n        # Convert Co and Cv to numpy arrays\n        Co = np.asarray(self.Co)\n        Cv = np.asarray(self.Cv)\n\n        print(\'\\nStarting CPHF iterations:\')\n        t = time.time()\n        for CPHF_ITER in range(1, maxiter + 1):\n\n            # Update jk\'s C_right\n            for xyz in range(3):\n                npC_right[xyz][:] = Cv.dot(self.x[xyz].T)\n\n            # Compute JK objects\n            jk.compute()\n\n            # Update amplitudes\n            for xyz in range(3):\n                # Build J and K objects\n                J = np.asarray(jk.J()[xyz])\n                K = np.asarray(jk.K()[xyz])\n\n                # Bulid new guess\n                X = self.dipoles_xyz[xyz].copy()\n                X -= (Co.T).dot(4 * J - K.T - K).dot(Cv)\n                X /= ia_denom\n\n                # DIIS for good measure\n                if use_diis:\n                    diis[xyz].add(X, X - x_old[xyz])\n                    X = diis[xyz].extrapolate()\n                self.x[xyz] = X.copy()\n\n            # Check for convergence\n            rms = []\n            for xyz in range(3):\n                rms.append(np.max((self.x[xyz] - x_old[xyz]) ** 2))\n                x_old[xyz] = self.x[xyz]\n\n            avg_RMS = sum(rms) / 3\n            max_RMS = max(rms)\n\n            if max_RMS < conv:\n                print(\'CPHF converged in %d iterations and %.2f seconds.\' % (CPHF_ITER, time.time() - t))\n                self.rhsvecs = []\n                for numx in range(3):\n                    rhsvec = self.dipoles_xyz[numx].reshape(-1)\n                    self.rhsvecs.append(rhsvec)\n                    self.x[numx] = self.x[numx].reshape(-1)\n                break\n\n            print(\'CPHF Iteration %3d: Average RMS = %3.8f  Maximum RMS = %3.8f\' %\n                  (CPHF_ITER, avg_RMS, max_RMS))\n\n    def solve_dynamic_iterative(self, omega=0.0, maxiter=20, conv=1.e-9, use_diis=True):\n\n        # Init JK object\n        jk = psi4.core.JK.build(self.scf_wfn.basisset())\n        jk.initialize()\n\n        # Add blank matrices to the JK object and NumPy hooks to\n        # C_right; there are 6 sets of matrices to account for X and Y\n        # vectors separately.\n        npC_right = []\n        for xyz in range(6):\n            jk.C_left_add(self.Co)\n            mC = psi4.core.Matrix(self.nbf, self.nocc)\n            npC_right.append(np.asarray(mC))\n            jk.C_right_add(mC)\n\n        # Build initial guess, previous vectors, diis object, and C_left updates\n        x_l, x_r = [], []\n        x_l_old, x_r_old = [], []\n        diis_l, diis_r = [], []\n        ia_denom_l = self.epsilon[self.nocc:] - self.epsilon[:self.nocc].reshape(-1, 1) - omega\n        ia_denom_r = self.epsilon[self.nocc:] - self.epsilon[:self.nocc].reshape(-1, 1) + omega\n        for xyz in range(3):\n            x_l.append(self.dipoles_xyz[xyz] / ia_denom_l)\n            x_r.append(self.dipoles_xyz[xyz] / ia_denom_r)\n            x_l_old.append(np.zeros(ia_denom_l.shape))\n            x_r_old.append(np.zeros(ia_denom_r.shape))\n            diis_l.append(DIIS_helper())\n            diis_r.append(DIIS_helper())\n\n        # Convert Co and Cv to numpy arrays\n        Co = np.asarray(self.Co)\n        Cv = np.asarray(self.Cv)\n\n        print(\'\\nStarting CPHF iterations:\')\n        t = time.time()\n        for CPHF_ITER in range(1, maxiter + 1):\n\n            # Update jk\'s C_right; ordering is Xx, Xy, Xz, Yx, Yy, Yz\n            for xyz in range(3):\n                npC_right[xyz][:] = Cv.dot(x_l[xyz].T)\n                npC_right[xyz + 3][:] = Cv.dot(x_r[xyz].T)\n\n            # Perform generalized J/K build\n            jk.compute()\n\n            # Update amplitudes\n            for xyz in range(3):\n                # Build J and K objects\n                J_l = np.asarray(jk.J()[xyz])\n                K_l = np.asarray(jk.K()[xyz])\n                J_r = np.asarray(jk.J()[xyz + 3])\n                K_r = np.asarray(jk.K()[xyz + 3])\n\n                # Bulid new guess\n                X_l = self.dipoles_xyz[xyz].copy()\n                X_r = self.dipoles_xyz[xyz].copy()\n                X_l -= (Co.T).dot(2 * J_l - K_l).dot(Cv)\n                X_r -= (Co.T).dot(2 * J_r - K_r).dot(Cv)\n                X_l /= ia_denom_l\n                X_r /= ia_denom_r\n\n                # DIIS for good measure\n                if use_diis:\n                    diis_l[xyz].add(X_l, X_l - x_l_old[xyz])\n                    X_l = diis_l[xyz].extrapolate()\n                    diis_r[xyz].add(X_r, X_r - x_r_old[xyz])\n                    X_r = diis_r[xyz].extrapolate()\n                x_l[xyz] = X_l.copy()\n                x_r[xyz] = X_r.copy()\n\n            # Check for convergence\n            rms = []\n            for xyz in range(3):\n                rms_l = np.max((x_l[xyz] - x_l_old[xyz]) ** 2)\n                rms_r = np.max((x_r[xyz] - x_r_old[xyz]) ** 2)\n                rms.append(max(rms_l, rms_r))\n                x_l_old[xyz] = x_l[xyz]\n                x_r_old[xyz] = x_r[xyz]\n\n            avg_RMS = sum(rms) / 3\n            max_RMS = max(rms)\n\n            if max_RMS < conv:\n                print(\'CPHF converged in %d iterations and %.2f seconds.\' % (CPHF_ITER, time.time() - t))\n                self.rhsvecs = []\n                for numx in range(3):\n                    rhsvec = self.dipoles_xyz[numx].reshape(-1)\n                    self.rhsvecs.append(np.concatenate((rhsvec, -rhsvec)))\n                    self.x.append(np.concatenate((x_l[numx].reshape(-1),\n                                                  x_r[numx].reshape(-1))))\n                break\n\n            print(\'CPHF Iteration %3d: Average RMS = %3.8f  Maximum RMS = %3.8f\' %\n                  (CPHF_ITER, avg_RMS, max_RMS))\n\n    def form_polarizability(self):\n        self.polar = np.empty((3, 3))\n        for numx in range(3):\n            for numf in range(3):\n                self.polar[numx, numf] = self.x[numx].dot(self.rhsvecs[numf])\n\nif __name__ == \'__main__\':\n    print(\'\\n\')\n    print(\'@test_CPHF running CPHF.py\')\n\n    from CPHF import *\n\n    from helper_CPHF import helper_CPHF\n\n    helper = helper_CPHF(mol)\n\n    print(\'\\n\')\n    print(\'@test_CPHF running solve_static_direct\')\n\n    helper.solve_static_direct()\n    helper.form_polarizability()\n    assert np.allclose(polar, helper.polar, rtol=0, atol=1.e-5)\n\n    print(\'\\n\')\n    print(\'@test_CPHF running solve_static_iterative\')\n\n    helper.solve_static_iterative()\n    helper.form_polarizability()\n    assert np.allclose(polar, helper.polar, rtol=0, atol=1.e-5)\n\n    f = 0.0\n\n    print(\'\\n\')\n    print(\'@test_CPHF running solve_dynamic_direct ({})\'.format(f))\n\n    helper.solve_dynamic_direct(omega=f)\n    helper.form_polarizability()\n    assert np.allclose(polar, helper.polar, rtol=0, atol=1.e-5)\n\n    print(\'\\n\')\n    print(\'@test_CPHF running solve_dynamic_iterative ({})\'.format(f))\n\n    helper.solve_dynamic_iterative(omega=f)\n    helper.form_polarizability()\n    assert np.allclose(polar, helper.polar, rtol=0, atol=1.e-5)\n\n    f = 0.0773178\n    ref = np.array([\n        [8.19440121,  0.00000000,  0.00000000],\n        [0.00000000, 12.75967150,  0.00000000],\n        [0.00000000,  0.00000000, 10.25213939]\n    ])\n\n    print(\'\\n\')\n    print(\'@test_CPHF running solve_dynamic_direct ({})\'.format(f))\n\n    helper.solve_dynamic_direct(omega=f)\n    helper.form_polarizability()\n    assert np.allclose(ref, helper.polar, rtol=0, atol=1.e-5)\n\n    print(\'\\n\')\n    print(\'@test_CPHF running solve_dynamic_iterative ({})\'.format(f))\n\n    helper.solve_dynamic_iterative(omega=f)\n    helper.form_polarizability()\n    assert np.allclose(ref, helper.polar, rtol=0, atol=1.e-5)\n'"
Self-Consistent-Field/SAD/external.py,43,"b'import time\nimport numpy as np\n\nclass DIIS_helper(object):\n\n    def __init__(self, max_vec=6):\n        self.error = []\n        self.vector = []\n        self.max_vec = max_vec\n\n    def add(self, matrix, error):\n        if len(self.error) > 1:\n            if self.error[-1].shape[0] != error.size:\n                raise Exception(""Error vector size does not match previous vector."")\n            if self.vector[-1].shape != matrix.shape:\n                raise Exception(""Vector shape does not match previous vector."")\n\n        self.error.append(error.ravel().copy())\n        self.vector.append(matrix.copy())\n\n    def extrapolate(self):\n        # Limit size of DIIS vector\n        diis_count = len(self.vector)\n\n        if diis_count == 0:\n            raise Exception(""DIIS: No previous vectors."")\n        if diis_count == 1:\n            return self.vector[0]\n\n        if diis_count > self.max_vec:\n            # Remove oldest vector\n            del self.vector[0]\n            del self.error[0]\n            diis_count -= 1\n\n        # Build error matrix B\n        B = np.empty((diis_count + 1, diis_count + 1))\n        B[-1, :] = -1\n        B[:, -1] = -1\n        B[-1, -1] = 0\n        for num1, e1 in enumerate(self.error):\n            B[num1, num1] = np.vdot(e1, e1)\n            for num2, e2 in enumerate(self.error):\n                if num2 >= num1: continue\n                val = np.vdot(e1, e2)\n                B[num1, num2] = B[num2, num1] = val\n\n        # normalize\n        B[abs(B) < 1.e-14] = 1.e-14\n        B[:-1, :-1] /= np.abs(B[:-1, :-1]).max()\n        # Build residual vector\n        resid = np.zeros(diis_count + 1)\n        resid[-1] = -1\n\n        # Solve pulay equations\n        ci = np.dot(np.linalg.pinv(B), resid)\n\n        # combination of previous fock matrices\n        V = np.zeros_like(self.vector[-1])\n        for num, c in enumerate(ci[:-1]):\n            V += c * self.vector[num]\n\n        return V\n\ndef uhf(psi4, mol, basis, pop_a=None, pop_b=None, guess_a=None, guess_b=None, do_print=True, E_conv = 1.e-7, D_conv = 1.e-5):\n\n    # Set defaults\n    maxiter = 40\n    #E_conv = 1.0E-7\n    #D_conv = 1.0E-5\n\n    psi4.set_global_option(\'BASIS\', basis)\n    # Integral generation from Psi4\'s MintsHelper\n    t = time.time()\n    wfn = psi4.new_wavefunction(mol, psi4.get_global_option(\'BASIS\'))\n    mints = psi4.MintsHelper(wfn.basisset())\n    S = np.asarray(mints.ao_overlap())\n\n    # Get nbf and ndocc for closed shell molecules\n    nbf = S.shape[0]\n    if pop_a is not None:\n        nocca = pop_a.shape[0]\n        if pop_b is None:\n            noccb = nocca\n            pop_b = noccb\n        else:\n            noccb = pop_b.shape[0]\n    else:\n        nocca = wfn.nalpha()\n        noccb = wfn.nbeta()\n\n    if do_print:\n        print \'\\nNumber of alpha orbitals:   %3d\' % nocca\n        print \'Number of beta orbitals:    %3d\' % noccb\n        print \'Number of basis functions:  %3d\' % nbf\n\n    V = np.asarray(mints.ao_potential())\n    T = np.asarray(mints.ao_kinetic())\n\n    if do_print:\n        print \'\\nTotal time taken for integrals: %.3f seconds.\' % (time.time()-t)\n\n    t = time.time()\n\n    # Build H_core\n    H = T + V\n\n    # Orthogonalizer A = S^(-1/2)\n    A = mints.ao_overlap()\n    A.power(-0.5, 1.e-16)\n    A = np.asarray(A)\n\n    def diag_H(H, nocc, pop=None):\n        Hp = A.dot(H).dot(A)\n        e, C2 = np.linalg.eigh(Hp)\n        C = A.dot(C2)\n        Cocc = C[:, :nocc]\n        if pop is not None:\n            Cocc *= pop\n        D = np.einsum(\'pi,qi->pq\', Cocc, Cocc)\n        return (C, D)\n\n    if guess_a is None:\n        Ca, Da = diag_H(H, nocca, pop_a)\n        Cb, Db = diag_H(H, noccb, pop_b)\n    else:\n        Ca = guess_a\n        if guess_b is None:\n            Cb = guess_a\n        Da = np.einsum(\'pi,qi->pq\', Ca[:, :nocca], Ca[:, :nocca])\n        Db = np.einsum(\'pi,qi->pq\', Ca[:, :noccb], Ca[:, :noccb])\n\n    t = time.time()\n    E = 0.0\n    Enuc = mol.nuclear_repulsion_energy()\n    Eold = 0.0\n\n    Fock_list = []\n    DIIS_error = []\n\n    # Build a C matrix and share data with the numpy array npC\n    Cocca = psi4.Matrix(nbf, nocca)\n    npCa = np.asarray(Cocca)\n    npCa[:] = Ca[:, :nocca]\n\n    Coccb = psi4.Matrix(nbf, noccb)\n    if noccb > 0:\n        npCb = np.asarray(Coccb)\n        npCb[:] = Cb[:, :noccb]\n\n    # Initialize the JK object\n    psi4.set_global_option(\'SCF_TYPE\', ""OUT_OF_CORE"")\n    jk = psi4.JK.build_JK(wfn.basisset())\n    jk.initialize()\n    jk.C_left().append(Cocca)\n    jk.C_left().append(Coccb)\n    jk.print_header()\n\n    # Build a DIIS helper object\n    diisa = DIIS_helper()\n    diisb = DIIS_helper()\n\n    if do_print:\n        print(\'\\nTotal time taken for setup: %.3f seconds\' % (time.time() - t))\n\n        print(\'\\nStart SCF iterations:\\n\')\n\n    t = time.time()\n\n    for SCF_ITER in range(1, maxiter + 1):\n\n        npCa[:] = Ca[:, :nocca]\n        if noccb > 0:\n            npCb[:] = Cb[:, :noccb]\n        #print \'here\'\n        jk.compute()\n        #print \'here\'\n\n        # Build fock matrix\n        Ja = np.asarray(jk.J()[0])\n        Jb = np.asarray(jk.J()[1])\n        Ka = np.asarray(jk.K()[0])\n        Kb = np.asarray(jk.K()[1])\n        Fa = H + (Ja + Jb) - Ka\n        Fb = H + (Ja + Jb) - Kb\n\n        # DIIS error build and update\n        diisa_e = Fa.dot(Da).dot(S) - S.dot(Da).dot(Fa)\n        diisa_e = (A.T).dot(diisa_e).dot(A)\n\n        diisb_e = Fb.dot(Db).dot(S) - S.dot(Db).dot(Fb)\n        diisb_e = (A.T).dot(diisb_e).dot(A)\n\n        if SCF_ITER > 1:\n            diisa.add(Fa, diisa_e)\n            diisb.add(Fb, diisb_e)\n\n        # SCF energy and update\n        SCF_E  = np.einsum(\'pq,pq->\', Da + Db, H)\n        SCF_E += np.einsum(\'pq,pq->\', Da, Fa)\n        SCF_E += np.einsum(\'pq,pq->\', Db, Fb)\n        SCF_E *= 0.5\n        SCF_E += Enuc\n\n        dRMS = 0.5 * (np.mean(diisa_e**2)**0.5 + np.mean(diisb_e**2)**0.5)\n\n        if do_print:\n            print(\'SCF Iteration %3d: Energy = %20.14f   dE = % 1.5E   dRMS = %1.5E\'\n                  % (SCF_ITER, SCF_E, (SCF_E - Eold), dRMS))\n        if (abs(SCF_E - Eold) < E_conv) and (dRMS < D_conv):\n            break\n\n        Eold = SCF_E\n\n        if SCF_ITER > 1:\n            Fa = diisa.extrapolate()\n            Fb = diisb.extrapolate()\n\n        # Diagonalize Fock matrix\n        Ca, Da = diag_H(Fa, nocca, pop_a)\n        Cb, Db = diag_H(Fb, noccb, pop_b)\n\n        if SCF_ITER == maxiter:\n            clean()\n            raise Exception(""Maximum number of SCF cycles exceeded."")\n\n    if do_print:\n        print(\'Total time for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\n        spin_mat = (Cb[:, :noccb].T).dot(S).dot(Ca[:, :nocca])\n        spin_contam = min(nocca, noccb) - np.vdot(spin_mat, spin_mat)\n        print(\'Spin Contamination Metric: %1.5E\\n\' % spin_contam)\n\n    ret = {}\n    ret[""Da""] = Da\n    ret[""Db""] = Da\n    ret[""Ca""] = Ca\n    ret[""Cb""] = Ca\n    return ret\n\ndef sad(psi4, mol, basis, pop_a=None, pop_b=None, do_print=True, E_conv = 1.e-7, D_conv = 1.e-5):\n\n    # Set defaults\n    maxiter = 40\n    #E_conv = 1.0E-7\n    #D_conv = 1.0E-5\n\n    psi4.set_global_option(\'BASIS\', basis)\n    # Integral generation from Psi4\'s MintsHelper\n    t = time.time()\n    wfn = psi4.new_wavefunction(mol, psi4.get_global_option(\'BASIS\'))\n    mints = psi4.MintsHelper(wfn.basisset())\n    S = np.asarray(mints.ao_overlap())\n\n    # Get nbf and ndocc for closed shell molecules\n    nbf = S.shape[0]\n    if pop_a is not None:\n        nocca = pop_a.shape[0]\n        if pop_b is None:\n            noccb = nocca\n            pop_b = noccb\n        else:\n            noccb = pop_b.shape[0]\n    else:\n        nocca = wfn.nalpha()\n        noccb = wfn.nbeta()\n\n    if mol.label(0) == \'C\':\n        nocca = 4\n        noccb = 2\n\n    if do_print:\n        print \'\\nNumber of alpha orbitals:   %3d\' % nocca\n        print \'Number of beta orbitals:    %3d\' % noccb\n        print \'Number of basis functions:  %3d\' % nbf\n\n    V = np.asarray(mints.ao_potential())\n    T = np.asarray(mints.ao_kinetic())\n\n    if do_print:\n        print \'\\nTotal time taken for integrals: %.3f seconds.\' % (time.time()-t)\n\n    t = time.time()\n\n    # Build H_core\n    H = T + V\n\n    # Orthogonalizer A = S^(-1/2)\n    A = mints.ao_overlap()\n    A.power(-0.5, 1.e-16)\n    A = np.asarray(A)\n\n    def diag_H(H, nocc, pop=None):\n        Hp = A.dot(H).dot(A)\n        e, C2 = np.linalg.eigh(Hp)\n        C = A.dot(C2)\n        Cocc = C[:, :nocc]\n        if pop is not None:\n            Cocc *= pop\n        D = np.einsum(\'pi,qi->pq\', Cocc, Cocc)\n        return (C, D)\n\n    Ca, Da = diag_H(H, nocca, pop_a)\n    Cb, Db = diag_H(H, noccb, pop_b)\n\n    t = time.time()\n    E = 0.0\n    Enuc = mol.nuclear_repulsion_energy()\n    Eold = 0.0\n\n    Fock_list = []\n    DIIS_error = []\n\n    # Initialize the JK object\n    I = np.asarray(mints.ao_eri())\n\n    # Build a DIIS helper object\n    diisa = DIIS_helper()\n    diisb = DIIS_helper()\n\n    if do_print:\n        print(\'\\nTotal time taken for setup: %.3f seconds\' % (time.time() - t))\n\n        print(\'\\nStart SCF iterations:\\n\')\n\n    t = time.time()\n\n    for SCF_ITER in range(1, maxiter + 1):\n\n\n        # Build fock matrix\n        Ja = np.einsum(\'pqrs,rs->pq\', I, Da)\n        Jb = np.einsum(\'pqrs,rs->pq\', I, Db)\n        Ka = np.einsum(\'prqs,rs->pq\', I, Da)\n        Kb = np.einsum(\'prqs,rs->pq\', I, Db)\n        Fa = H + (Ja + Jb) - Ka\n        Fb = H + (Ja + Jb) - Kb\n\n        # DIIS error build and update\n        diisa_e = Fa.dot(Da).dot(S) - S.dot(Da).dot(Fa)\n        diisa_e = (A.T).dot(diisa_e).dot(A)\n\n        diisb_e = Fb.dot(Db).dot(S) - S.dot(Db).dot(Fb)\n        diisb_e = (A.T).dot(diisb_e).dot(A)\n\n        if SCF_ITER > 1:\n            diisa.add(Fa, diisa_e)\n            diisb.add(Fb, diisb_e)\n\n        # SCF energy and update\n        SCF_E  = np.einsum(\'pq,pq->\', Da + Db, H)\n        SCF_E += np.einsum(\'pq,pq->\', Da, Fa)\n        SCF_E += np.einsum(\'pq,pq->\', Db, Fb)\n        SCF_E *= 0.5\n        SCF_E += Enuc\n\n        dRMS = 0.5 * (np.mean(diisa_e**2)**0.5 + np.mean(diisb_e**2)**0.5)\n\n        if do_print:\n            print(\'SCF Iteration %3d: Energy = %20.14f   dE = % 1.5E   dRMS = %1.5E\'\n                  % (SCF_ITER, SCF_E, (SCF_E - Eold), dRMS))\n        if (abs(SCF_E - Eold) < E_conv) and (dRMS < D_conv):\n            break\n\n        Eold = SCF_E\n\n        if SCF_ITER > 1:\n            Fa = diisa.extrapolate()\n            Fb = diisb.extrapolate()\n\n        # Diagonalize Fock matrix\n        Ca, Da = diag_H(Fa, nocca, pop_a)\n        Cb, Db = diag_H(Fb, noccb, pop_b)\n\n        if SCF_ITER == maxiter:\n            clean()\n            raise Exception(""Maximum number of SCF cycles exceeded."")\n\n    if do_print:\n        print(\'Total time for SCF iterations: %.3f seconds \\n\' % (time.time() - t))\n\n        spin_mat = (Cb[:, :noccb].T).dot(S).dot(Ca[:, :nocca])\n        spin_contam = min(nocca, noccb) - np.vdot(spin_mat, spin_mat)\n        print(\'Spin Contamination Metric: %1.5E\\n\' % spin_contam)\n\n    ret = {}\n    ret[""Da""] = Da\n    ret[""Db""] = Da\n    ret[""Ca""] = Ca\n    ret[""Cb""] = Ca\n    return ret\n\ndef basis_projection(C, bas1, bas2):\n    mints = MintsHelper(bas1)\n    \n    SBB = mints.ao_overlap(bas2, bas2).to_array()\n    SBA = mints.ao_overlap(bas2, bas1).to_array()\n    SAA = mints.ao_overlap(bas1, bas1).to_array()\n\n    CBBinv = np.linalg.inv(SBB)\n\n    T = C.T.dot(SBA.T).dot(CBBinv).dot(SBA).dot(C)\n    matT = psi4.Matrix.from_array(T)\n    matT.power(-0.5, 1.e-15)\n    Cb = CBBinv.dot(SBA).dot(C).dot(matT)\n    return Cb\n'"
Self-Consistent-Field/SAD/tmp.py,4,"b'\n\nimport numpy as np\n\na = np.random.random((4, 4))\na += np.eye(4)\n\nprint np.linalg.eigh(a)[1]\n\nmat = Matrix.from_array(a)\nprint np.array(mat.partial_cholesky_factorize(1.e-12, False))\n\n\n\n'"
Tutorials/04_Density_Functional_Theory/ks_helper.py,0,"b'#! A simple Psi4 input script to compute a SCF reference using Psi4\'s libJK\n\nimport time\nimport numpy as np\nimport psi4\n\nfrom pkg_resources import parse_version\nif parse_version(psi4.__version__) >= parse_version(\'1.3a1\'):\n    build_superfunctional = psi4.driver.dft.build_superfunctional\nelse:\n    build_superfunctional = psi4.driver.dft_funcs.build_superfunctional\n\n# Diagonalize routine\ndef build_orbitals(diag, A, ndocc):\n    Fp = psi4.core.triplet(A, diag, A, True, False, True)\n\n    nbf = A.shape[0]\n    Cp = psi4.core.Matrix(nbf, nbf)\n    eigvecs = psi4.core.Vector(nbf)\n    Fp.diagonalize(Cp, eigvecs, psi4.core.DiagonalizeOrder.Ascending)\n\n    C = psi4.core.doublet(A, Cp, False, False)\n\n    Cocc = psi4.core.Matrix(nbf, ndocc)\n    Cocc.np[:] = C.np[:, :ndocc]\n\n    D = psi4.core.doublet(Cocc, Cocc, False, True)\n    return C, Cocc, D, eigvecs\n\ndef ks_solver(alias, mol, options, V_builder, jk_type=""DF"", output=""output.dat"", restricted=True):\n\n    # Build our molecule\n    mol = mol.clone()\n    mol.reset_point_group(\'c1\')\n    mol.fix_orientation(True)\n    mol.fix_com(True)\n    mol.update_geometry()\n\n    # Set options\n    psi4.set_output_file(output)\n\n    psi4.core.prepare_options_for_module(""SCF"")\n    psi4.set_options(options)\n    psi4.core.set_global_option(""SCF_TYPE"", jk_type)\n\n    maxiter = 20\n    E_conv = psi4.core.get_option(""SCF"", ""E_CONVERGENCE"") \n    D_conv = psi4.core.get_option(""SCF"", ""D_CONVERGENCE"")\n    \n    # Integral generation from Psi4\'s MintsHelper\n    wfn = psi4.core.Wavefunction.build(mol, psi4.core.get_global_option(""BASIS""))\n    mints = psi4.core.MintsHelper(wfn.basisset())\n    S = mints.ao_overlap()\n\n    # Build the V Potential\n    sup = build_superfunctional(alias, restricted)[0]\n    sup.set_deriv(2)\n    sup.allocate()\n    \n    vname = ""RV""\n    if not restricted:\n        vname = ""UV""\n    Vpot = psi4.core.VBase.build(wfn.basisset(), sup, vname)\n    Vpot.initialize()\n    \n    # Get nbf and ndocc for closed shell molecules\n    nbf = wfn.nso()\n    ndocc = wfn.nalpha()\n    if wfn.nalpha() != wfn.nbeta():\n        raise PsiException(""Only valid for RHF wavefunctions!"")\n    \n    print(\'\\nNumber of occupied orbitals: %d\' % ndocc)\n    print(\'Number of basis functions:   %d\' % nbf)\n    \n    # Build H_core\n    V = mints.ao_potential()\n    T = mints.ao_kinetic()\n    H = T.clone()\n    H.add(V)\n    \n    # Orthogonalizer A = S^(-1/2)\n    A = mints.ao_overlap()\n    A.power(-0.5, 1.e-14)\n    \n    # Build core orbitals\n    C, Cocc, D, eigs = build_orbitals(H, A, ndocc)\n    \n    # Setup data for DIIS\n    t = time.time()\n    E = 0.0\n    Enuc = mol.nuclear_repulsion_energy()\n    Eold = 0.0\n    \n    # Initialize the JK object\n    jk = psi4.core.JK.build(wfn.basisset())\n    jk.set_memory(int(1.25e8))  # 1GB\n    jk.initialize()\n    jk.print_header()\n    \n    diis_obj = psi4.p4util.solvers.DIIS(max_vec=3, removal_policy=""largest"")\n    \n    print(\'\\nTotal time taken for setup: %.3f seconds\' % (time.time() - t))\n    \n    print(\'\\nStarting SCF iterations:\')\n    t = time.time()\n   \n    print(""\\n    Iter            Energy             XC E         Delta E        D RMS\\n"")\n    for SCF_ITER in range(1, maxiter + 1):\n    \n        # Compute JK\n        jk.C_left_add(Cocc)\n        jk.compute()\n        jk.C_clear()\n    \n        # Build Fock matrix\n        F = H.clone()\n        F.axpy(2.0, jk.J()[0])\n        F.axpy(-Vpot.functional().x_alpha(), jk.K()[0])\n\n        # Build V\n        ks_e = 0.0\n\n        Vpot.set_D([D])\n        Vpot.properties()[0].set_pointers(D)\n        V = V_builder(D, Vpot)\n        if V is None:\n            ks_e = 0.0\n        else:\n            ks_e, V = V\n            V = psi4.core.Matrix.from_array(V)\n    \n        F.axpy(1.0, V)\n\n        # DIIS error build and update\n        diis_e = psi4.core.triplet(F, D, S, False, False, False)\n        diis_e.subtract(psi4.core.triplet(S, D, F, False, False, False))\n        diis_e = psi4.core.triplet(A, diis_e, A, False, False, False)\n    \n        diis_obj.add(F, diis_e)\n    \n        dRMS = diis_e.rms()\n\n        # SCF energy and update\n        SCF_E  = 2.0 * H.vector_dot(D)\n        SCF_E += 2.0 * jk.J()[0].vector_dot(D)\n        SCF_E -= Vpot.functional().x_alpha() * jk.K()[0].vector_dot(D)\n        SCF_E += ks_e\n        SCF_E += Enuc\n    \n        print(\'SCF Iter%3d: % 18.14f   % 11.7f   % 1.5E   %1.5E\'\n              % (SCF_ITER, SCF_E, ks_e, (SCF_E - Eold), dRMS))\n        if (abs(SCF_E - Eold) < E_conv) and (dRMS < D_conv):\n            break\n    \n        Eold = SCF_E\n    \n        # DIIS extrapolate\n        F = diis_obj.extrapolate()\n    \n        # Diagonalize Fock matrix\n        C, Cocc, D, eigs = build_orbitals(F, A, ndocc)\n    \n        if SCF_ITER == maxiter:\n            raise Exception(""Maximum number of SCF cycles exceeded."")\n    \n    print(\'\\nTotal time for SCF iterations: %.3f seconds \' % (time.time() - t))\n    \n    print(\'\\nFinal SCF energy: %.8f hartree\' % SCF_E)\n\n    data = {}\n    data[""Da""] = D\n    data[""Ca""] = C\n    data[""eigenvalues""] = eigs\n    return(SCF_E, data)\n'"
Tutorials/07_Symmetry_Adapted_Perturbation_Theory/helper_SAPT.py,38,"b'# A SAPT helper object\r\n#\r\n# Created by: Daniel G. A. Smith\r\n# Date: 12/1/14\r\n# License: GPL v3.0\r\n#\r\n\r\nimport numpy as np\r\nimport time\r\nimport psi4\r\n\r\nclass helper_SAPT(object):\r\n\r\n    def __init__(self, dimer, memory=8, algorithm=\'MO\', reference=\'RHF\'):\r\n        print(""\\nInitializing SAPT object...\\n"")\r\n        tinit_start = time.time()\r\n\r\n        # Set a few crucial attributes\r\n        self.alg = algorithm.upper()\r\n        self.reference = reference.upper()\r\n        dimer.reset_point_group(\'c1\')\r\n        dimer.fix_orientation(True)\r\n        dimer.fix_com(True)\r\n        dimer.update_geometry()\r\n        nfrags = dimer.nfragments()\r\n        if nfrags != 2:\r\n            psi4.core.clean()\r\n            raise Exception(""Found %d fragments, must be 2."" % nfrags)\r\n\r\n        # Grab monomers in DCBS\r\n        monomerA = dimer.extract_subsets(1, 2)\r\n        monomerA.set_name(\'monomerA\')\r\n        monomerB = dimer.extract_subsets(2, 1)\r\n        monomerB.set_name(\'monomerB\')\r\n        self.mult_A = monomerA.multiplicity()\r\n        self.mult_B = monomerB.multiplicity()\r\n\r\n        # Compute monomer properties\r\n\r\n        tstart = time.time()\r\n        self.rhfA, self.wfnA = psi4.energy(\'SCF\', return_wfn=True, molecule=monomerA)\r\n        self.V_A = np.asarray(psi4.core.MintsHelper(self.wfnA.basisset()).ao_potential())\r\n        print(""RHF for monomer A finished in %.2f seconds."" % (time.time() - tstart))\r\n\r\n        tstart = time.time()\r\n        self.rhfB, self.wfnB = psi4.energy(\'SCF\', return_wfn=True, molecule=monomerB)\r\n        self.V_B = np.asarray(psi4.core.MintsHelper(self.wfnB.basisset()).ao_potential())\r\n        print(""RHF for monomer B finished in %.2f seconds."" % (time.time() - tstart))\r\n\r\n        # Setup a few variables\r\n        self.memory = memory\r\n        self.nmo = self.wfnA.nmo()\r\n\r\n        # Monomer A\r\n        self.nuc_rep_A = monomerA.nuclear_repulsion_energy()\r\n        self.ndocc_A = self.wfnA.doccpi()[0]\r\n        self.nvirt_A = self.nmo - self.ndocc_A\r\n        if reference == \'ROHF\':\r\n          self.idx_A = [\'i\', \'a\', \'r\']\r\n          self.nsocc_A = self.wfnA.soccpi()[0]\r\n          occA = self.ndocc_A + self.nsocc_A\r\n        else:\r\n          self.idx_A = [\'a\', \'r\']\r\n          self.nsocc_A = 0\r\n          occA = self.ndocc_A \r\n\r\n        self.C_A = np.asarray(self.wfnA.Ca())\r\n        self.Co_A = self.C_A[:, :self.ndocc_A]\r\n        self.Ca_A = self.C_A[:, self.ndocc_A:occA]\r\n        self.Cv_A = self.C_A[:, occA:]\r\n        self.eps_A = np.asarray(self.wfnA.epsilon_a())\r\n\r\n        # Monomer B\r\n        self.nuc_rep_B = monomerB.nuclear_repulsion_energy()\r\n        self.ndocc_B = self.wfnB.doccpi()[0]\r\n        self.nvirt_B = self.nmo - self.ndocc_B\r\n        if reference == \'ROHF\':\r\n          self.idx_B = [\'j\', \'b\', \'s\']\r\n          self.nsocc_B = self.wfnB.soccpi()[0]\r\n          occB = self.ndocc_B + self.nsocc_B\r\n        else:\r\n          self.idx_B = [\'b\', \'s\']\r\n          self.nsocc_B = 0\r\n          occB = self.ndocc_B \r\n\r\n        self.C_B = np.asarray(self.wfnB.Ca())\r\n        self.Co_B = self.C_B[:, :self.ndocc_B]\r\n        self.Ca_B = self.C_B[:, self.ndocc_B:occB]\r\n        self.Cv_B = self.C_B[:, occB:]\r\n        self.eps_B = np.asarray(self.wfnB.epsilon_a())\r\n\r\n        # Dimer\r\n        self.nuc_rep = dimer.nuclear_repulsion_energy() - self.nuc_rep_A - self.nuc_rep_B\r\n        self.vt_nuc_rep = self.nuc_rep / ((2 * self.ndocc_A + self.nsocc_A)\r\n                                           * (2 * self.ndocc_B + self.nsocc_B))\r\n\r\n        # Make slice, orbital, and size dictionaries\r\n        if reference == \'ROHF\':\r\n          self.slices = {\r\n                       \'i\': slice(0, self.ndocc_A),\r\n                       \'a\': slice(self.ndocc_A, occA),\r\n                       \'r\': slice(occA, None),\r\n                       \'j\': slice(0, self.ndocc_B),\r\n                       \'b\': slice(self.ndocc_B, occB),\r\n                       \'s\': slice(occB, None)\r\n                      }\r\n\r\n          self.orbitals = {\'i\': self.Co_A,\r\n                           \'a\': self.Ca_A,\r\n                           \'r\': self.Cv_A,\r\n                           \'j\': self.Co_B,\r\n                           \'b\': self.Ca_B,\r\n                           \'s\': self.Cv_B\r\n                        }\r\n\r\n          self.sizes = {\'i\': self.ndocc_A,\r\n                        \'a\': self.nsocc_A,\r\n                        \'r\': self.nvirt_A,\r\n                        \'j\': self.ndocc_B,\r\n                        \'b\': self.nsocc_B,\r\n                        \'s\': self.nvirt_B}\r\n\r\n        else:\r\n          self.slices = {\r\n                       \'a\': slice(0, self.ndocc_A),\r\n                       \'r\': slice(occA, None),\r\n                       \'b\': slice(0, self.ndocc_B),\r\n                       \'s\': slice(occB, None)\r\n                      }\r\n\r\n          self.orbitals = {\'a\': self.Co_A,\r\n                           \'r\': self.Cv_A,\r\n                           \'b\': self.Co_B,\r\n                           \'s\': self.Cv_B\r\n                        }\r\n\r\n          self.sizes = {\'a\': self.ndocc_A,\r\n                        \'r\': self.nvirt_A,\r\n                        \'b\': self.ndocc_B,\r\n                        \'s\': self.nvirt_B}\r\n\r\n        # Compute size of ERI tensor in GB\r\n        self.dimer_wfn = psi4.core.Wavefunction.build(dimer, psi4.core.get_global_option(\'BASIS\'))\r\n        mints = psi4.core.MintsHelper(self.dimer_wfn.basisset())\r\n        self.mints = mints\r\n        ERI_Size = (self.nmo ** 4) * 8.e-9\r\n        memory_footprint = ERI_Size * 4\r\n        if memory_footprint > self.memory:\r\n            psi4.core.clean()\r\n            raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\r\n                            limit of %4.2f GB."" % (memory_footprint, self.memory))\r\n\r\n        # Integral generation from Psi4\'s MintsHelper\r\n        print(\'Building ERI tensor...\')\r\n        tstart = time.time()\r\n        # Leave ERI as a Psi4 Matrix\r\n        self.I = np.asarray(self.mints.ao_eri()).swapaxes(1,2)\r\n        print(\'...built ERI tensor in %.3f seconds.\' % (time.time() - tstart))\r\n        print(""Size of the ERI tensor is %4.2f GB, %d basis functions."" % (ERI_Size, self.nmo))\r\n        self.S = np.asarray(self.mints.ao_overlap())\r\n\r\n        # Save additional rank 2 tensors\r\n        self.V_A_BB = np.einsum(\'ui,vj,uv->ij\', self.C_B, self.C_B, self.V_A)\r\n        self.V_A_AB = np.einsum(\'ui,vj,uv->ij\', self.C_A, self.C_B, self.V_A)\r\n        self.V_B_AA = np.einsum(\'ui,vj,uv->ij\', self.C_A, self.C_A, self.V_B)\r\n        self.V_B_AB = np.einsum(\'ui,vj,uv->ij\', self.C_A, self.C_B, self.V_B)\r\n\r\n        self.S_AB = np.einsum(\'ui,vj,uv->ij\', self.C_A, self.C_B, self.S)\r\n\r\n        if self.alg == ""AO"":\r\n            tstart = time.time()\r\n            aux_basis = psi4.core.BasisSet.build(self.dimer_wfn.molecule(), ""DF_BASIS_SCF"",\r\n                                            psi4.core.get_option(""SCF"", ""DF_BASIS_SCF""),\r\n                                            ""JKFIT"", psi4.core.get_global_option(\'BASIS\'),\r\n                                            puream=self.dimer_wfn.basisset().has_puream())\r\n\r\n            self.jk = psi4.core.JK.build(self.dimer_wfn.basisset(), aux_basis)\r\n            self.jk.set_memory(int(memory * 1e9))\r\n            self.jk.initialize()\r\n            print(""\\n...initialized JK objects in %5.2f seconds."" % (time.time() - tstart))\r\n\r\n        print(""\\n...finished initializing SAPT object in %5.2f seconds."" % (time.time() - tinit_start))\r\n\r\n    # Compute MO ERI tensor (v) on the fly\r\n    def v(self, string):\r\n        if len(string) != 4:\r\n            psi4.core.clean()\r\n            raise Exception(\'v: string %s does not have 4 elements\' % string)\r\n\r\n        # ERI\'s from mints are of type (11|22) - need <12|12>\r\n        V = np.einsum(\'pA,pqrs->Aqrs\', self.orbitals[string[0]], self.I)\r\n        V = np.einsum(\'qB,Aqrs->ABrs\', self.orbitals[string[1]], V)\r\n        V = np.einsum(\'rC,ABrs->ABCs\', self.orbitals[string[2]], V)\r\n        V = np.einsum(\'sD,ABCs->ABCD\', self.orbitals[string[3]], V)\r\n        return V\r\n\r\n    # Grab MO overlap matrices\r\n    def s(self, string):\r\n        if len(string) != 2:\r\n            psi4.core.clean()\r\n            raise Exception(\'S: string %s does not have 2 elements.\' % string)\r\n\r\n        for alpha in \'ijab\':\r\n            if (alpha in string) and (self.sizes[alpha] == 0):\r\n                return np.array([0]).reshape(1,1)\r\n\r\n        s1 = string[0]\r\n        s2 = string[1]\r\n\r\n        # Compute on the fly\r\n        return (self.orbitals[string[0]].T).dot(self.S).dot(self.orbitals[string[1]])\r\n        #return np.einsum(\'ui,vj,uv->ij\', self.orbitals[string[0]], self.orbitals[string[1]], self.S)\r\n\r\n    # Grab epsilons, reshape if requested\r\n    def eps(self, string, dim=1):\r\n        if len(string) != 1:\r\n            psi4.core.clean()\r\n            raise Exception(\'Epsilon: string %s does not have 1 element.\' % string)\r\n\r\n        shape = (-1,) + tuple([1] * (dim - 1))\r\n\r\n        if (string == \'i\') or (string == \'a\') or (string == \'r\'):\r\n            return self.eps_A[self.slices[string]].reshape(shape)\r\n        elif (string == \'j\') or (string == \'b\') or (string == \'s\'):\r\n            return self.eps_B[self.slices[string]].reshape(shape)\r\n        else:\r\n            psi4.core.clean()\r\n            raise Exception(\'Unknown orbital type in eps: %s.\' % string)\r\n\r\n    # Grab MO potential matrices\r\n    def potential(self, string, side):\r\n        if len(string) != 2:\r\n            psi4.core.clean()\r\n            raise Exception(\'Potential: string %s does not have 2 elements.\' % string)\r\n\r\n        s1 = string[0]\r\n        s2 = string[1]\r\n\r\n        # Two separate cases\r\n        if side == \'A\':\r\n            # Compute on the fly\r\n            return (self.orbitals[string[0]].T).dot(self.V_A).dot(self.orbitals[string[1]])\r\n            #return np.einsum(\'ui,vj,uv->ij\', self.orbitals[s1], self.orbitals[s2], self.V_A)\r\n\r\n        elif side == \'B\':\r\n            # Compute on the fly\r\n            return (self.orbitals[string[0]].T).dot(self.V_B).dot(self.orbitals[string[1]])\r\n            #return np.einsum(\'ui,vj,uv->ij\', self.orbitals[s1], self.orbitals[s2], self.V_B)\r\n        else:\r\n            psi4.core.clean()\r\n            raise Exception(\'helper_SAPT.potential side must be either A or B, not %s.\' % side)\r\n\r\n    # Compute V tilde, Index as V_{1,2}^{3,4}\r\n    def vt(self, string):\r\n        if len(string) != 4:\r\n            psi4.core.clean()\r\n            raise Exception(\'Compute tilde{V}: string %s does not have 4 elements\' % string)\r\n\r\n        for alpha in \'ijab\':\r\n            if (alpha in string) and (self.sizes[alpha] == 0):\r\n                return np.array([0]).reshape(1,1,1,1)\r\n\r\n        # Grab left and right strings\r\n        s_left = string[0] + string[2]\r\n        s_right = string[1] + string[3]\r\n\r\n        # ERI term\r\n        V = self.v(string)\r\n        # Potential A\r\n        S_A = self.s(s_left)\r\n        V_A = self.potential(s_right, \'A\') / (2 * self.ndocc_A + self.nsocc_A)\r\n        V += np.einsum(\'ik,jl->ijkl\', S_A, V_A)\r\n\r\n        # Potential B\r\n        S_B = self.s(s_right)\r\n        V_B = self.potential(s_left, \'B\') / (2 * self.ndocc_B + self.nsocc_B)\r\n        #print s_right, np.abs(V_B).sum()\r\n        V += np.einsum(\'ik,jl->ijkl\', V_B, S_B)\r\n\r\n        # Nuclear\r\n        V += np.einsum(\'ik,jl->ijkl\', S_A, S_B) * self.vt_nuc_rep\r\n\r\n        return V\r\n\r\n    # Compute CPHF orbitals\r\n    def chf(self, monomer, ind=False):\r\n        if monomer not in [\'A\', \'B\']:\r\n            psi4.core.clean()\r\n            raise Exception(\'%s is not a valid monomer for CHF.\' % monomer)\r\n\r\n        if self.reference == \'ROHF\':\r\n            psi4.core.clean()\r\n            raise Exception(\'CPHF for a ROHF reference not implemented yet.\')\r\n\r\n        if monomer == \'A\':\r\n            # Form electrostatic potential\r\n            w_n = 2 * np.einsum(\'saba->bs\', self.v(\'saba\'))\r\n            w_n += self.V_A_BB[self.slices[\'b\'], self.slices[\'s\']]\r\n            eps_ov = (self.eps(\'b\', dim=2) - self.eps(\'s\'))\r\n\r\n            # Set terms\r\n            v_term1 = \'sbbs\'\r\n            v_term2 = \'sbsb\'\r\n            no, nv = self.ndocc_B, self.nvirt_B\r\n\r\n        if monomer == \'B\':\r\n            w_n = 2 * np.einsum(\'rbab->ar\', self.v(\'rbab\'))\r\n            w_n += self.V_B_AA[self.slices[\'a\'], self.slices[\'r\']]\r\n            eps_ov = (self.eps(\'a\', dim=2) - self.eps(\'r\'))\r\n            v_term1 = \'raar\'\r\n            v_term2 = \'rara\'\r\n            no, nv = self.ndocc_A, self.nvirt_A\r\n\r\n        # Form A matrix (LHS)\r\n        voov = self.v(v_term1)\r\n        v_vOoV = 2 * voov - self.v(v_term2).swapaxes(2, 3)\r\n        v_ooaa = voov.swapaxes(1, 3)\r\n        v_vVoO = 2 * v_ooaa - v_ooaa.swapaxes(2, 3)\r\n        A_ovOV = np.einsum(\'vOoV->ovOV\', v_vOoV + v_vVoO.swapaxes(1, 3))\r\n\r\n        # Mangled the indices so badly with strides we need to copy back to C contiguous\r\n        nov = nv * no\r\n        A_ovOV = A_ovOV.reshape(nov, nov).copy(order=\'C\')\r\n        A_ovOV[np.diag_indices_from(A_ovOV)] -= eps_ov.ravel()\r\n\r\n        # Call DGESV, need flat ov array\r\n        B_ov = -1 * w_n.ravel()\r\n        t = np.linalg.solve(A_ovOV, B_ov)\r\n        # Our notation wants vo array\r\n        t = t.reshape(no, nv).T\r\n\r\n        if ind:\r\n            # E200 Induction energy is free at the point\r\n            e20_ind = 2 * np.einsum(\'vo,ov->\', t, w_n)\r\n            return (t, e20_ind)\r\n        else:\r\n            return t\r\n\r\n    def compute_sapt_JK(self, Cleft, Cright, tensor=None):\r\n\r\n        if self.alg != ""AO"":\r\n            raise Exception(""Attempted a call to JK builder in an MO algorithm"")\r\n\r\n        if self.reference == ""ROHF"":\r\n            raise Exception(""AO algorithm not yet implemented for ROHF reference."")\r\n\r\n        return_single = False\r\n        if not isinstance(Cleft, (list, tuple)):\r\n            Cleft = [Cleft]\r\n            return_single = True\r\n        if not isinstance(Cright, (list, tuple)):\r\n            Cright = [Cright]\r\n            return_single = True\r\n        if (not isinstance(tensor, (list, tuple))) and (tensor is not None):\r\n            tensor = [tensor]\r\n            return_single = True\r\n\r\n        if len(Cleft) != len(Cright):\r\n            raise Exception(""Cleft list is not the same length as Cright list"")\r\n\r\n        zero_append = []\r\n        num_compute = 0\r\n\r\n        for num in range(len(Cleft)):\r\n            Cl = Cleft[num]\r\n            Cr = Cright[num]\r\n\r\n            if (Cr.shape[1] == 0) or (Cl.shape[1] == 0):\r\n                zero_append.append(num)\r\n                continue\r\n\r\n            if tensor is not None:\r\n                mol = Cl.shape[1]\r\n                mor = Cr.shape[1]\r\n                \r\n                if (tensor[num].shape[0] != mol) or (tensor[num].shape[1] != mor):\r\n                    raise Exception(""compute_sapt_JK: Tensor size does not match Cl (%d) /Cr (%d) : %s"" %\r\n                                                            (mol, mor, str(tensor[num].shape)))\r\n                if mol < mor:\r\n                    Cl = np.dot(Cl, tensor[num])\r\n                else:\r\n                    Cr = np.dot(Cr, tensor[num].T)\r\n\r\n            Cl = psi4.core.Matrix.from_array(Cl)\r\n            Cr = psi4.core.Matrix.from_array(Cr)\r\n\r\n            self.jk.C_left_add(Cl)\r\n            self.jk.C_right_add(Cr)\r\n            num_compute += 1\r\n        \r\n        self.jk.compute() \r\n\r\n        J_list = []\r\n        K_list = []\r\n        for num in range(num_compute):\r\n            J_list.append(np.array(self.jk.J()[num])) \r\n            K_list.append(np.array(self.jk.K()[num])) \r\n\r\n        self.jk.C_clear()\r\n\r\n        z = np.zeros((self.nmo, self.nmo))\r\n        for num in zero_append:\r\n            J_list.insert(num, z)\r\n            K_list.insert(num, z)\r\n\r\n        if return_single:\r\n            return J_list[0], K_list[0]\r\n        else:\r\n            return J_list, K_list\r\n\r\n    def chain_dot(self, *dot_list):\r\n        result = dot_list[0]\r\n        for x in range(len(dot_list) - 1):\r\n            result = np.dot(result, dot_list[x + 1])\r\n        return result\r\n\r\n# End SAPT helper\r\n\r\nclass sapt_timer(object):\r\n    def __init__(self, name):\r\n        self.name = name\r\n        self.start = time.time()\r\n        print(\'\\nStarting %s...\' % name)\r\n\r\n    def stop(self):\r\n        t = time.time() - self.start\r\n        print(\'...%s took a total of % .2f seconds.\' % (self.name, t))\r\n\r\n\r\ndef sapt_printer(line, value):\r\n    spacer = \' \' * (20 - len(line))\r\n    print(line + spacer + \'% 16.8f mH  % 16.8f kcal/mol\' % (value * 1000, value * 627.509))\r\n# End SAPT helper\r\n'"
Coupled-Cluster/Spin_Orbitals/CCSD/CCSD.py,59,"b'""""""\nScript to compute the electronic correlation energy using\ncoupled-cluster theory through single and double excitations,\nfrom a RHF reference wavefunction.\n\nReferences:\n- Algorithms from Daniel Crawford\'s programming website:\nhttp://github.com/CrawfordGroup/ProgrammingProjects\n- DPD Formulation of CC Equations: [Stanton:1991:4334]\n""""""\n\n__authors__   =  ""Daniel G. A. Smith""\n__credits__   =  [""Daniel G. A. Smith"", ""Lori A. Burns""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2014-07-29""\n\nimport time\nimport numpy as np\nnp.set_printoptions(precision=8, linewidth=200, suppress=True)\nimport psi4\n\n# Set memory\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'3-21g\',\n                  \'scf_type\': \'pk\',\n                  \'mp2_type\': \'conv\',\n                  \'freeze_core\': \'false\',\n                  \'e_convergence\': 1e-10,\n                  \'d_convergence\': 1e-10})\n\n# CCSD Settings\nE_conv = 1.e-6\nmaxiter = 20\nprint_amps = False\ncompare_psi4 = False\n\n# First compute RHF energy using Psi4\nscf_e, wfn = psi4.energy(\'SCF\', return_wfn=True)\n\n# Grab data from\nC = wfn.Ca()\nndocc = wfn.doccpi()[0]\nnmo = wfn.nmo()\nSCF_E = wfn.energy()\neps = np.asarray(wfn.epsilon_a())\n\n# Compute size of SO-ERI tensor in GB\nERI_Size = (nmo ** 4) * 128e-9\nprint(\'\\nSize of the SO ERI tensor will be %4.2f GB.\' % ERI_Size)\nmemory_footprint = ERI_Size * 5.2\nif memory_footprint > numpy_memory:\n    clean()\n    raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                    limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\n# Integral generation from Psi4\'s MintsHelper\nt = time.time()\nmints = psi4.core.MintsHelper(wfn.basisset())\nH = np.asarray(mints.ao_kinetic()) + np.asarray(mints.ao_potential())\n\nprint(\'\\nTotal time taken for ERI integrals: %.3f seconds.\\n\' % (time.time() - t))\n\n# Make spin-orbital MO antisymmetrized integrals\nprint(\'Starting AO -> spin-orbital MO transformation...\')\nt = time.time()\nMO = np.asarray(mints.mo_spin_eri(C, C))\n\n# Update nocc and nvirt\nnso = nmo * 2\nnocc = ndocc * 2\nnvirt = nso - nocc\n\n# Make slices\no = slice(0, nocc)\nv = slice(nocc, MO.shape[0])\n\n#Extend eigenvalues\neps = np.repeat(eps, 2)\nEocc = eps[o]\nEvirt = eps[v]\n\nprint(\'..finished transformation in %.3f seconds.\\n\' % (time.time() - t))\n\n# DPD approach to CCSD equations from [Stanton:1991:4334]\n\n# occ orbitals i, j, k, l, m, n\n# virt orbitals a, b, c, d, e, f\n# all oribitals p, q, r, s, t, u, v\n\n\n#Bulid Eqn 9: tilde{\\Tau})\ndef build_tilde_tau(t1, t2):\n    """"""Builds [Stanton:1991:4334] Eqn. 9""""""\n    ttau = t2.copy()\n    tmp = 0.5 * np.einsum(\'ia,jb->ijab\', t1, t1)\n    ttau += tmp\n    ttau -= tmp.swapaxes(2, 3)\n    return ttau\n\n\n#Build Eqn 10: \\Tau)\ndef build_tau(t1, t2):\n    """"""Builds [Stanton:1991:4334] Eqn. 10""""""\n    ttau = t2.copy()\n    tmp = np.einsum(\'ia,jb->ijab\', t1, t1)\n    ttau += tmp\n    ttau -= tmp.swapaxes(2, 3)\n    return ttau\n\n\n#Build Eqn 3:\ndef build_Fae(t1, t2):\n    """"""Builds [Stanton:1991:4334] Eqn. 3""""""\n    Fae = F[v, v].copy()\n    Fae[np.diag_indices_from(Fae)] = 0\n\n    Fae -= 0.5 * np.einsum(\'me,ma->ae\', F[o, v], t1)\n    Fae += np.einsum(\'mf,mafe->ae\', t1, MO[o, v, v, v])\n\n    tmp_tau = build_tilde_tau(t1, t2)\n    Fae -= 0.5 * np.einsum(\'mnaf,mnef->ae\', tmp_tau, MO[o, o, v, v])\n    return Fae\n\n\n#Build Eqn 4:\ndef build_Fmi(t1, t2):\n    """"""Builds [Stanton:1991:4334] Eqn. 4""""""\n    Fmi = F[o, o].copy()\n    Fmi[np.diag_indices_from(Fmi)] = 0\n\n    Fmi += 0.5 * np.einsum(\'ie,me->mi\', t1, F[o, v])\n    Fmi += np.einsum(\'ne,mnie->mi\', t1, MO[o, o, o, v])\n\n    tmp_tau = build_tilde_tau(t1, t2)\n    Fmi += 0.5 * np.einsum(\'inef,mnef->mi\', tmp_tau, MO[o, o, v, v])\n    return Fmi\n\n\n#Build Eqn 5:\ndef build_Fme(t1, t2):\n    """"""Builds [Stanton:1991:4334] Eqn. 5""""""\n    Fme = F[o, v].copy()\n    Fme += np.einsum(\'nf,mnef->me\', t1, MO[o, o, v, v])\n    return Fme\n\n\n#Build Eqn 6:\ndef build_Wmnij(t1, t2):\n    """"""Builds [Stanton:1991:4334] Eqn. 6""""""\n    Wmnij = MO[o, o, o, o].copy()\n\n    Pij = np.einsum(\'je,mnie->mnij\', t1, MO[o, o, o, v])\n    Wmnij += Pij\n    Wmnij -= Pij.swapaxes(2, 3)\n\n    tmp_tau = build_tau(t1, t2)\n    Wmnij += 0.25 * np.einsum(\'ijef,mnef->mnij\', tmp_tau, MO[o, o, v, v])\n    return Wmnij\n\n\n#Build Eqn 7:\ndef build_Wabef(t1, t2):\n    """"""Builds [Stanton:1991:4334] Eqn. 7""""""\n    # Rate limiting step written using tensordot, ~10x faster\n    # The commented out lines are consistent with the paper\n\n    Wabef = MO[v, v, v, v].copy()\n\n    Pab = np.einsum(\'baef->abef\', np.tensordot(t1, MO[v, o, v, v], axes=(0, 1)))\n    # Pab = np.einsum(\'mb,amef->abef\', t1, MO[v, o, v, v])\n\n    Wabef -= Pab\n    Wabef += Pab.swapaxes(0, 1)\n\n    tmp_tau = build_tau(t1, t2)\n\n    Wabef += 0.25 * np.tensordot(tmp_tau, MO[v, v, o, o], axes=((0, 1), (2, 3)))\n    # Wabef += 0.25 * np.einsum(\'mnab,mnef->abef\', tmp_tau, MO[o, o, v, v])\n    return Wabef\n\n\n#Build Eqn 8:\ndef build_Wmbej(t1, t2):\n    """"""Builds [Stanton:1991:4334] Eqn. 8""""""\n    Wmbej = MO[o, v, v, o].copy()\n    Wmbej += np.einsum(\'jf,mbef->mbej\', t1, MO[o, v, v, v])\n    Wmbej -= np.einsum(\'nb,mnej->mbej\', t1, MO[o, o, v, o])\n\n    tmp = (0.5 * t2) + np.einsum(\'jf,nb->jnfb\', t1, t1)\n\n    Wmbej -= np.einsum(\'jbme->mbej\', np.tensordot(tmp, MO[o, o, v, v], axes=((1, 2), (1, 3))))\n    # Wmbej -= np.einsum(\'jnfb,mnef->mbej\', tmp, MO[o, o, v, v])\n    return Wmbej\n\n\n### Build so Fock matirx\n\n# Update H, transform to MO basis and tile for alpha/beta spin\nH = np.einsum(\'uj,vi,uv\', C, C, H)\nH = np.repeat(H, 2, axis=0)\nH = np.repeat(H, 2, axis=1)\n\n# Make H block diagonal\nspin_ind = np.arange(H.shape[0], dtype=np.int) % 2\nH *= (spin_ind.reshape(-1, 1) == spin_ind)\n\n# Compute Fock matrix\nF = H + np.einsum(\'pmqm->pq\', MO[:, o, :, o])\n\n### Build D matrices: [Stanton:1991:4334] Eqns. 12 & 13\nFocc = F[np.arange(nocc), np.arange(nocc)].flatten()\nFvirt = F[np.arange(nocc, nvirt + nocc), np.arange(nocc, nvirt + nocc)].flatten()\n\nDia = Focc.reshape(-1, 1) - Fvirt\nDijab = Focc.reshape(-1, 1, 1, 1) + Focc.reshape(-1, 1, 1) - Fvirt.reshape(-1, 1) - Fvirt\n\n### Construct initial guess\n\n# t^a_i\nt1 = np.zeros((nocc, nvirt))\n# t^{ab}_{ij}\nMOijab = MO[o, o, v, v]\nt2 = MOijab / Dijab\n\n### Compute MP2 in MO basis set to make sure the transformation was correct\nMP2corr_E = np.einsum(\'ijab,ijab->\', MOijab, t2) / 4\nMP2_E = SCF_E + MP2corr_E\n\nprint(\'MO based MP2 correlation energy: %.8f\' % MP2corr_E)\nprint(\'MP2 total energy:       %.8f\' % MP2_E)\npsi4.compare_values(psi4.energy(\'mp2\'), MP2_E, 6, \'MP2 Energy\')\n\n### Start CCSD iterations\nprint(\'\\nStarting CCSD iterations\')\nccsd_tstart = time.time()\nCCSDcorr_E_old = 0.0\nfor CCSD_iter in range(1, maxiter + 1):\n    ### Build intermediates: [Stanton:1991:4334] Eqns. 3-8\n    Fae = build_Fae(t1, t2)\n    Fmi = build_Fmi(t1, t2)\n    Fme = build_Fme(t1, t2)\n\n    Wmnij = build_Wmnij(t1, t2)\n    Wabef = build_Wabef(t1, t2)\n    Wmbej = build_Wmbej(t1, t2)\n\n    #### Build RHS side of t1 equations, [Stanton:1991:4334] Eqn. 1\n    rhs_T1  = F[o, v].copy()\n    rhs_T1 += np.einsum(\'ie,ae->ia\', t1, Fae)\n    rhs_T1 -= np.einsum(\'ma,mi->ia\', t1, Fmi)\n    rhs_T1 += np.einsum(\'imae,me->ia\', t2, Fme)\n    rhs_T1 -= np.einsum(\'nf,naif->ia\', t1, MO[o, v, o, v])\n    rhs_T1 -= 0.5 * np.einsum(\'imef,maef->ia\', t2, MO[o, v, v, v])\n    rhs_T1 -= 0.5 * np.einsum(\'mnae,nmei->ia\', t2, MO[o, o, v, o])\n\n    ### Build RHS side of t2 equations, [Stanton:1991:4334] Eqn. 2\n    rhs_T2 = MO[o, o, v, v].copy()\n\n    # P_(ab) t_ijae (F_be - 0.5 t_mb F_me)\n    tmp = Fae - 0.5 * np.einsum(\'mb,me->be\', t1, Fme)\n    Pab = np.einsum(\'ijae,be->ijab\', t2, tmp)\n    rhs_T2 += Pab\n    rhs_T2 -= Pab.swapaxes(2, 3)\n\n    # P_(ij) t_imab (F_mj + 0.5 t_je F_me)\n    tmp = Fmi + 0.5 * np.einsum(\'je,me->mj\', t1, Fme)\n    Pij = np.einsum(\'imab,mj->ijab\', t2, tmp)\n    rhs_T2 -= Pij\n    rhs_T2 += Pij.swapaxes(0, 1)\n\n    tmp_tau = build_tau(t1, t2)\n    rhs_T2 += 0.5 * np.einsum(\'mnab,mnij->ijab\', tmp_tau, Wmnij)\n    rhs_T2 += 0.5 * np.einsum(\'ijef,abef->ijab\', tmp_tau, Wabef)\n\n    # P_(ij) * P_(ab)\n    # (ij - ji) * (ab - ba)\n    # ijab - ijba -jiab + jiba\n    tmp = np.einsum(\'ie,ma,mbej->ijab\', t1, t1, MO[o, v, v, o])\n    Pijab = np.einsum(\'imae,mbej->ijab\', t2, Wmbej)\n    Pijab -= tmp\n\n    rhs_T2 += Pijab\n    rhs_T2 -= Pijab.swapaxes(2, 3)\n    rhs_T2 -= Pijab.swapaxes(0, 1)\n    rhs_T2 += Pijab.swapaxes(0, 1).swapaxes(2, 3)\n\n    Pij = np.einsum(\'ie,abej->ijab\', t1, MO[v, v, v, o])\n    rhs_T2 += Pij\n    rhs_T2 -= Pij.swapaxes(0, 1)\n\n    Pab = np.einsum(\'ma,mbij->ijab\', t1, MO[o, v, o, o])\n    rhs_T2 -= Pab\n    rhs_T2 += Pab.swapaxes(2, 3)\n\n    ### Update t1 and t2 amplitudes\n    t1 = rhs_T1 / Dia\n    t2 = rhs_T2 / Dijab\n\n    ### Compute CCSD correlation energy\n    CCSDcorr_E = np.einsum(\'ia,ia->\', F[o, v], t1)\n    CCSDcorr_E += 0.25 * np.einsum(\'ijab,ijab->\', MO[o, o, v, v], t2)\n    CCSDcorr_E += 0.5 * np.einsum(\'ijab,ia,jb->\', MO[o, o, v, v], t1, t1)\n\n    ### Print CCSD correlation energy\n    print(\'CCSD Iteration %3d: CCSD correlation = %3.12f  \'\\\n          \'dE = %3.5E\' % (CCSD_iter, CCSDcorr_E, (CCSDcorr_E - CCSDcorr_E_old)))\n    if (abs(CCSDcorr_E - CCSDcorr_E_old) < E_conv):\n        break\n\n    CCSDcorr_E_old = CCSDcorr_E\n\nprint(\'CCSD iterations took %.2f seconds.\\n\' % (time.time() - ccsd_tstart))\n\nCCSD_E = SCF_E + CCSDcorr_E\n\nprint(\'\\nFinal CCSD correlation energy:     % 16.10f\' % CCSDcorr_E)\nprint(\'Total CCSD energy:                 % 16.10f\' % CCSD_E)\nif compare_psi4:\n    psi4.compare_values(psi4.energy(\'CCSD\'), CCSD_E, 6, \'CCSD Energy\')\n\nif print_amps:\n    # [::4] take every 4th, [-5:] take last 5, [::-1] reverse order\n    t2_args = np.abs(t2).ravel().argsort()[::2][-5:][::-1]\n    t1_args = np.abs(t1).ravel().argsort()[::4][-5:][::-1]\n\n    print(\'\\nLargest t1 amplitudes\')\n    for pos in t1_args:\n        value = t1.flat[pos]\n        inds = np.unravel_index(pos, t1.shape)\n        print(\'%4d  %4d |   % 5.10f\' % (inds[0], inds[1], value))\n\n    print(\'\\nLargest t2 amplitudes\')\n    for pos in t2_args:\n        value = t2.flat[pos]\n        inds = np.unravel_index(pos, t2.shape)\n        print(\'%4d  %4d  %4d  %4d |   % 5.10f\' % (inds[0], inds[1], inds[2], inds[3], value))\n'"
Coupled-Cluster/Spin_Orbitals/CCSD/CCSD_DIIS.py,7,"b'""""""\nScript to compute CCSD correlation energy from a RHF reference,\nutilizing DIIS convergence acceleration for CCSD amplitude iterations.\n\nReferences:\n- CCSD algorithms from Daniel Crawford\'s programming website:\nhttp://github.com/CrawfordGroup/ProgrammingProjects\n- DPD formulation of CCSD equations from [Stanton:1991:4334]\n- DIIS equations & algorithms from [Sherrill:1998], [Pulay:1980:393], & [Pulay:1969:197]\n""""""\n__authors__   =  ""Daniel G. A. Smith""\n__credits__   =  [""Daniel G. A. Smith"", ""Lori A. Burns""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2014-07-29""\n\nimport time\nimport numpy as np\nfrom helper_CC import *\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'cc-pvdz\'})\n\n# CCSD settings\nE_conv = 1.e-8\nmaxiter = 20\nmax_diis = 8\ncompare_psi4 = True\nfreeze_core = False\n\n# Build CCSD object\nccsd = helper_CCSD(mol, memory=2)\n\n### Setup DIIS\ndiis_vals_t1 = [ccsd.t1.copy()]\ndiis_vals_t2 = [ccsd.t2.copy()]\ndiis_errors = []\n\n### Start Iterations\nccsd_tstart = time.time()\n\n# Compute MP2 energy\nCCSDcorr_E_old = ccsd.compute_corr_energy()\nprint(""CCSD Iteration %3d: CCSD correlation = %.12f    dE = % .5E    \\\nMP2"" % (0, CCSDcorr_E_old, -CCSDcorr_E_old))\n\n# Iterate!\ndiis_size = 0\nfor CCSD_iter in range(1, maxiter + 1):\n\n    # Save new amplitudes\n    oldt1 = ccsd.t1.copy()\n    oldt2 = ccsd.t2.copy()\n\n    ccsd.update()\n\n    # Compute CCSD correlation energy\n    CCSDcorr_E = ccsd.compute_corr_energy()\n\n    # Print CCSD iteration information\n    print(\'CCSD Iteration %3d: CCSD correlation = %.12f    dE = % .5E    DIIS = %d\' % (CCSD_iter, CCSDcorr_E, (CCSDcorr_E - CCSDcorr_E_old), diis_size))\n\n    # Check convergence\n    if (abs(CCSDcorr_E - CCSDcorr_E_old) < E_conv):\n        break\n\n    # Add DIIS vectors\n    diis_vals_t1.append(ccsd.t1.copy())\n    diis_vals_t2.append(ccsd.t2.copy())\n\n    # Build new error vector\n    error_t1 = (ccsd.t1 - oldt1).ravel()\n    error_t2 = (ccsd.t2 - oldt2).ravel()\n    diis_errors.append(np.concatenate((error_t1, error_t2)))\n\n    # Update old energy\n    CCSDcorr_E_old = CCSDcorr_E\n\n    if CCSD_iter >= 1:\n\n        # Limit size of DIIS vector\n        if (len(diis_vals_t1) > max_diis):\n            del diis_vals_t1[0]\n            del diis_vals_t2[0]\n            del diis_errors[0]\n\n        diis_size = len(diis_vals_t1) - 1\n\n        # Build error matrix B, [Pulay:1980:393], Eqn. 6, LHS\n        B = np.ones((diis_size + 1, diis_size + 1)) * -1\n        B[-1, -1] = 0\n\n        for n1, e1 in enumerate(diis_errors):\n            for n2, e2 in enumerate(diis_errors):\n                # Vectordot the error vectors\n                B[n1, n2] = np.dot(e1, e2)\n\n        B[:-1, :-1] /= np.abs(B[:-1, :-1]).max()\n\n        # Build residual vector, [Pulay:1980:393], Eqn. 6, RHS\n        resid = np.zeros(diis_size + 1)\n        resid[-1] = -1\n\n        # Solve Pulay equations, [Pulay:1980:393], Eqn. 6\n        ci = np.linalg.solve(B, resid)\n\n        # Calculate new amplitudes\n        ccsd.t1[:] = 0\n        ccsd.t2[:] = 0\n        for num in range(diis_size):\n            ccsd.t1 += ci[num] * diis_vals_t1[num + 1]\n            ccsd.t2 += ci[num] * diis_vals_t2[num + 1]\n    # End DIIS amplitude update\n\n# Finished CCSD iterations\nprint(\'CCSD iterations took %.2f seconds.\\n\' % (time.time() - ccsd_tstart))\n\nCCSD_E = ccsd.rhf_e + CCSDcorr_E\n\nprint(\'\\nFinal CCSD correlation energy:     % 16.10f\' % CCSDcorr_E)\nprint(\'Total CCSD energy:                 % 16.10f\' % CCSD_E)\n\nif compare_psi4:\n    psi4.compare_values(psi4.energy(\'CCSD\'), CCSD_E, 6, \'CCSD Energy\')\n\n'"
Coupled-Cluster/Spin_Orbitals/CCSD/CCSD_T.py,21,"b'""""""\nScript to compute the CCSD(T) electronic correlation energy,\nfrom a RHF reference wavefunction.\n\nReferences:\n- Algorithms & equations taken directly from Project #6 of \nDaniel Crawford\'s programming website:\nhttp://github.com/CrawfordGroup/ProgrammingProjects\n""""""\n\n__authors__   =  ""Daniel G. A. Smith""\n__credits__   =  [""Daniel G. A. Smith"", ""Lori A. Burns""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2014-07-29""\n\nimport time\nimport numpy as np\nfrom helper_CC import *\nnp.set_printoptions(precision=5, linewidth=200, suppress=True)\nimport psi4\n\npsi4.set_memory(\'2 GB\')\npsi4.core.set_output_file(\'output.dat\', False)\n\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1\n"""""")\n\npsi4.set_options({\'basis\': \'cc-pVDZ\'})\n\n# For numpy\ncompare_psi4 = True\n\n# Compute CCSD\nccsd = helper_CCSD(mol, memory=2)\nccsd.compute_energy()\n\nCCSDcorr_E = ccsd.ccsd_corr_e\nCCSD_E = ccsd.ccsd_e\n\nprint(\'\\nFinal CCSD correlation energy:          % 16.10f\' % CCSDcorr_E)\nprint(\'Total CCSD energy:                      % 16.10f\' % CCSD_E)\n\n# Triples correction required o^3v^3 storage due the noddy algorithm\nT_Size = (ccsd.nocc ** 3 * ccsd.nvirt ** 3) * 8e-9\nprint(""\\nSize of the T3 tensor will be %4.2f GB."" % T_Size)\nmemory_footprint = T_Size * 4.2\nif memory_footprint > numpy_memory:\n    clean()\n    raise Exception(""Estimated memory utilization for pertubative triples (%4.2f GB) exceeds numpy_memory limit of %4.2f GB."" % (memory_footprint, numpy_memory))\n\n# P(i/jk) * P(a/bc)\n# (ijk - jik - kji) * (abc - bac - cba)\n# (ijkabc - ijkbac - ijkcba - jikabc + jikbac + jikcba - kjiabc + kjicac + kjicba)\n\n# Build disconnected t3\nprint(\'\\nBuilding disconnected T3...\')\nt = time.time()\ntmp = np.einsum(\'ia,jkbc->ijkabc\', ccsd.t1, ccsd.get_MO(\'oovv\'))\nt3d = tmp.copy()\nt3d -= np.einsum(\'ijkabc->ijkbac\', tmp)\nt3d -= np.einsum(\'ijkabc->ijkcba\', tmp)\nt3d -= np.einsum(\'ijkabc->jikabc\', tmp)\nt3d += np.einsum(\'ijkabc->jikbac\', tmp)\nt3d += np.einsum(\'ijkabc->jikcba\', tmp)\nt3d -= np.einsum(\'ijkabc->kjiabc\', tmp)\nt3d += np.einsum(\'ijkabc->kjibac\', tmp)\nt3d += np.einsum(\'ijkabc->kjicba\', tmp)\nprint(\'...built disconnected T3 in %.3f seconds.\' % (time.time() - t))\n\n# Build connected t3\nprint(\'\\nBuilding connected T3...\')\nt = time.time()\ntmp = ndot(\'jkae,eibc->ijkabc\', ccsd.t2, ccsd.get_MO(\'vovv\')).copy()\ntmp -= ndot(\'imbc,majk->ijkabc\', ccsd.t2, ccsd.get_MO(\'ovoo\'))\nt3c = tmp.copy()\nt3c -= np.einsum(\'ijkabc->ijkbac\', tmp)\nt3c -= np.einsum(\'ijkabc->ijkcba\', tmp)\nt3c -= np.einsum(\'ijkabc->jikabc\', tmp)\nt3c += np.einsum(\'ijkabc->jikbac\', tmp)\nt3c += np.einsum(\'ijkabc->jikcba\', tmp)\nt3c -= np.einsum(\'ijkabc->kjiabc\', tmp)\nt3c += np.einsum(\'ijkabc->kjibac\', tmp)\nt3c += np.einsum(\'ijkabc->kjicba\', tmp)\nprint(\'...built connected T3 in %.3f seconds.\' % (time.time() - t))\n\n# Form last intermediate\ntmp = t3c + t3d\n\n# Construct D3\nFocc = np.diag(ccsd.get_F(\'oo\'))\nFvir = np.diag(ccsd.get_F(\'vv\'))\nDijkabc = Focc.reshape(-1, 1, 1, 1, 1, 1) + Focc.reshape(-1, 1, 1, 1, 1) + Focc.reshape(-1, 1, 1, 1)\nDijkabc = Dijkabc - Fvir.reshape(-1, 1, 1) - Fvir.reshape(-1, 1) - Fvir\ntmp /= Dijkabc\n\n# Compute energy expression\nPert_T = (1.0/36) * np.einsum(\'ijkabc,ijkabc\', t3c, tmp)\n\nCCSD_T_E = CCSD_E + Pert_T\n\nprint(\'\\nPertubative (T) correlation energy:     % 16.10f\' % Pert_T)\nprint(\'Total CCSD(T) energy:                   % 16.10f\' % CCSD_T_E)\nif compare_psi4:\n    psi4.compare_values(psi4.energy(\'CCSD(T)\'), CCSD_T_E, 6, \'CCSD(T) Energy\')\n\n'"
Coupled-Cluster/Spin_Orbitals/CCSD/TD-CCSD.py,82,"b'""""""\nScript to compute TD-CCSD from a CCSD reference.\n\nThis script runs a post-CCSD computation, using the ERI\ntensor, the T1 and T2 amplitudes as well as the F and W \nintermediates.\n\nReferences:\n- DPD formulation of CC: [Stanton:1991:4334]\n- TD-CCSD equations & algorithms: [Nascimento:2016]\n""""""\n\n__authors__   =  ""Daniel R. Nascimento""\n__credits__   =  [""Daniel R. Nascimento""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2017-04-22""\n\nimport time\nimport numpy as np\nfrom helper_CC import *\nnp.set_printoptions(precision=14, linewidth=200, suppress=True)\nimport psi4\n\n# Set memory\npsi4.set_memory(int(2e9), True)\npsi4.core.set_output_file(\'output.dat\', True)\n\nnumpy_memory = 2\n\nmol = psi4.geometry(""""""\nC\t0.0\t0.0\t0.0\nO\t0.0\t0.0\t1.0\nsymmetry c1\nno_reorient\n"""""")\n\npsi4.set_options({\'basis\': \'sto-3g\',\n                  \'scf_type\': \'pk\',\n                  \'mp2_type\': \'conv\',\n                  \'freeze_core\': \'false\',\n                  \'e_convergence\': 1e-6,\n                  \'d_convergence\': 1e-6})\n\n# LCCSD Settings\nE_conv = 1.e-6\nmaxiter = 50\n\n# TD-CCSD Settings\n### defines the field polarization (0 == x, 1 == y, 2 == z)\npolarization = 1\n### sets the total number of time steps\nsteps_total = 20000\n### sets the length of the time step\ntime_step = 0.05\n\n# Compute CCSD\nccsd = helper_CCSD(mol, memory=2)\nccsd.compute_energy()\n\n# Grab T amplitudes from CCSD\nt1 = ccsd.t1\nt2 = ccsd.t2\n\n# Make slices\no = ccsd.slice_o\nv = ccsd.slice_v\n\n#Step 1: Build one and two-particle elements of the similarity-transformed Hamiltonian\n#Equations from [Gauss:1995:3561], Table III (b) & (c)\n\n#### Note that Eqs. 1 - 6 of Table III (b) only modifies some intermediates that were \n#### already defined during the ground-state CCSD computation!\n\n# 3rd equation\nFme   = ccsd.build_Fme()\n\n# 1st equation\ndef update_Fae():\n    """"""Eqn 1 from [Gauss:1995:3561], Table III (b)""""""\n    Fae  = ccsd.build_Fae()\n    Fae -= 0.5 * np.einsum(\'me,ma->ae\', Fme, t1)\n    return Fae\n\n# 2nd equation\ndef update_Fmi():\n    """"""Eqn 2 from [Gauss:1995:3561], Table III (b)""""""\n    Fmi  = ccsd.build_Fmi()\n    Fmi += 0.5 * np.einsum(\'me,ie->mi\', Fme, t1)\n    return Fmi\n\n# 4th equation\ndef update_Wmnij():\n    """"""Eqn 4 from [Gauss:1995:3561], Table III (b)""""""\n    tmp_tau = ccsd.build_tau()\n\n    Wmnij  = ccsd.build_Wmnij()\n    Wmnij += 0.25 * np.einsum(\'ijef,mnef->mnij\', tmp_tau, ccsd.get_MO(\'oovv\'))\n    return Wmnij\n\n# 5th equation\ndef update_Wabef():\n    """"""Eqn 5 from [Gauss:1995:3561], Table III (b)""""""\n    tmp_tau = ccsd.build_tau()\n\n    Wabef  = ccsd.build_Wabef()\n    Wabef += 0.25 * np.einsum(\'mnab,mnef->abef\', tmp_tau, ccsd.get_MO(\'oovv\'))\n    return Wabef\n\n# 6th equation\ndef update_Wmbej():\n    """"""Eqn 6 from [Gauss:1995:3561], Table III (b)""""""\n    Wmbej  = ccsd.build_Wmbej()\n    Wmbej -= 0.5 * np.einsum(\'jnfb,mnef->mbej\', t2, ccsd.get_MO(\'oovv\'))\n    return Wmbej\n\n#### Eqs. 7 - 10 define new intermediates\n\n# 7th equation\ndef build_Wmnie():\n    """"""Eqn 7 from [Gauss:1995:3561], Table III (b)""""""\n    Wmnie = ccsd.get_MO(\'ooov\').copy()\n    Wmnie += np.einsum(\'if,mnfe->mnie\', t1, ccsd.get_MO(\'oovv\'))\n    return Wmnie\n\n# 8th equation\ndef build_Wamef():\n    """"""Eqn 8 from [Gauss:1995:3561], Table III (b)""""""\n    Wamef = ccsd.get_MO(\'vovv\').copy()\n    Wamef -= np.einsum(\'na,nmef->amef\', t1, ccsd.get_MO(\'oovv\'))\n    return Wamef\n\n# 9th equation\ndef build_Wmbij():\n    """"""Eqn 9 from [Gauss:1995:3561], Table III (b)""""""\n    Wmbij = ccsd.get_MO(\'ovoo\').copy()\n    \n    Wmbij -= np.einsum(\'me,ijbe->mbij\', Fme, t2)\n    Wmbij -= np.einsum(\'nb,mnij->mbij\', t1, Wmnij)\n   \n    temp_tau = ccsd.build_tau() \n    Wmbij += 0.5 * np.einsum(\'mbef,ijef->mbij\', ccsd.get_MO(\'ovvv\'),temp_tau)\n   \n    Pij = np.einsum(\'jnbe,mnie->mbij\', t2, ccsd.get_MO(\'ooov\'))\n    Wmbij += Pij\n    Wmbij -= Pij.swapaxes(2, 3)\n\n    temp_mbej = ccsd.get_MO(\'ovvo\').copy()\n    temp_mbej -= np.einsum(\'njbf,mnef->mbej\', t2, ccsd.get_MO(\'oovv\'))\n    Pij = np.einsum(\'ie,mbej->mbij\', t1, temp_mbej)\n    Wmbij += Pij\n    Wmbij -= Pij.swapaxes(2, 3)\n    return Wmbij\n\n# 10th equation\ndef build_Wabei():\n    """"""Eqn 10 from [Gauss:1995:3561], Table III (b)""""""\n    Wabei = ccsd.get_MO(\'vvvo\').copy()\n\n    Wabei -= np.einsum(\'me,miab->abei\', Fme, t2)\n    Wabei += np.einsum(\'if,abef->abei\', t1, Wabef)\n    \n    temp_tau = ccsd.build_tau() \n    Wabei += 0.5 * np.einsum(\'mnei,mnab->abei\', ccsd.get_MO(\'oovo\'),temp_tau)\n   \n    Pab = np.einsum(\'mbef,miaf->abei\', ccsd.get_MO(\'ovvv\'), t2)\n    Wabei -= Pab\n    Wabei += Pab.swapaxes(0, 1)\n\n    temp_mbei = ccsd.get_MO(\'ovvo\').copy()\n    temp_mbei -= np.einsum(\'nibf,mnef->mbei\', t2, ccsd.get_MO(\'oovv\'))\n    Pab = np.einsum(\'ma,mbei->abei\', t1, temp_mbei)\n    Wabei -= Pab\n    Wabei += Pab.swapaxes(0, 1)\n    return Wabei    \n \n### Build three-body intermediates: [Gauss:1995:3561] Table III (c)\n\n# 1st equation\ndef build_Gae(t2, l2):\n    """"""Eqn 1 from [Gauss:1995:3561], Table III (c)""""""\n    Gae = -0.5 * np.einsum(\'mnef,mnaf->ae\', t2, l2)\n    return Gae\n\n# 2nd equation\ndef build_Gmi(t2, l2):\n    """"""Eqn 2 from [Gauss:1995:3561], Table III (c)""""""\n    Gmi = 0.5 * np.einsum(\'mnef,inef->mi\', t2, l2)\n    return Gmi\n\n### Construct initial guess for lambda amplitudes\nl1 = t1*0\nl2 = t2.copy()\n\n### Update/build intermediates that do not depende on lambda\nFae   = update_Fae()\nFmi   = update_Fmi()\nWmnij = update_Wmnij()\nWabef = update_Wabef()\nWmbej = update_Wmbej()\n\nWmnie = build_Wmnie()\nWamef = build_Wamef()\nWmbij = build_Wmbij()\nWabei = build_Wabei()\n\n### begin LCCSD iterations: Lambda equations from [Gauss:1995:3561] Table II, (a) & (b). \nprint(\'\\nStarting LCCSD iterations\')\nlccsd_tstart = time.time()\nLCCSDcorr_E_old = 0.0\nfor LCCSD_iter in range(1, maxiter + 1):\n\n    # Build intermediates that depend on lambda\n    Gae = build_Gae(t2, l2)\n    Gmi = build_Gmi(t2, l2)\n\n    # Build RHS of l1 equations: Table II (a)\n    rhs_L1  = Fme.copy()\n    rhs_L1 += np.einsum(\'ie,ea->ia\', l1, Fae)\n    rhs_L1 -= np.einsum(\'ma,im->ia\', l1, Fmi)\n    rhs_L1 += np.einsum(\'me,ieam->ia\', l1, Wmbej)\n    rhs_L1 += 0.5 * np.einsum(\'imef,efam->ia\', l2, Wabei)\n    rhs_L1 -= 0.5 * np.einsum(\'mnae,iemn->ia\', l2, Wmbij)\n    rhs_L1 -= np.einsum(\'ef,eifa->ia\', Gae, Wamef)\n    rhs_L1 -= np.einsum(\'mn,mina->ia\', Gmi, Wmnie)\n\n    ### Build RHS of l2 equations\n    ### Table II (b)\n    rhs_L2 = ccsd.get_MO(\'oovv\').copy()\n\n    # P_(ab) l_ijae * F_eb\n    Pab = np.einsum(\'ijae,eb->ijab\', l2, Fae)\n    rhs_L2 += Pab\n    rhs_L2 -= Pab.swapaxes(2, 3)\n\n    # P_(ij) l_imab * F_jm\n    Pij = np.einsum(\'imab,jm->ijab\', l2, Fmi)\n    rhs_L2 -= Pij\n    rhs_L2 += Pij.swapaxes(0, 1)\n\n    # 0.5 * l_mnab * W_ijmn\n    rhs_L2 += 0.5 * np.einsum(\'mnab,ijmn->ijab\', l2, Wmnij)\n\n    # 0.5 * l_ijef * W_efab\n    rhs_L2 += 0.5 * np.einsum(\'ijef,efab->ijab\', l2, Wabef)\n\n    # P_(ij) l_ie W_ejab\n    Pij = np.einsum(\'ie,ejab->ijab\', l1, Wamef)\n    rhs_L2 += Pij\n    rhs_L2 -= Pij.swapaxes(0, 1)\n\n    # P_(ab) l_ma W_ijmb\n    Pab = np.einsum(\'ma,ijmb->ijab\', l1, Wmnie)\n    rhs_L2 -= Pab\n    rhs_L2 += Pab.swapaxes(2, 3)\n   \n    # P_(ij) P_(ab) l_imae W_jebm\n    Pijab = np.einsum(\'imae,jebm->ijab\', l2, Wmbej)\n    rhs_L2 += Pijab\n    rhs_L2 -= Pijab.swapaxes(0, 1)\n    rhs_L2 -= Pijab.swapaxes(2, 3)\n    rhs_L2 += Pijab.swapaxes(0, 1).swapaxes(2, 3)\n     \n    # P_(ij) P_(ab) l_ia F_jb\n    Pijab = np.einsum(\'ia,jb->ijab\', l1, Fme)\n    rhs_L2 += Pijab\n    rhs_L2 -= Pijab.swapaxes(0, 1)\n    rhs_L2 -= Pijab.swapaxes(2, 3)\n    rhs_L2 += Pijab.swapaxes(0, 1).swapaxes(2, 3)\n    \n    # P_(ab) <ij||ae> G_be\n    Pab = np.einsum(\'be,ijae->ijab\', Gae, ccsd.get_MO(\'oovv\'))\n    rhs_L2 += Pab\n    rhs_L2 -= Pab.swapaxes(2, 3)\n\n    # P_(ij) <im||ab> G_mj\n    Pij = np.einsum(\'mj,imab->ijab\', Gmi, ccsd.get_MO(\'oovv\'))\n    rhs_L2 -= Pij\n    rhs_L2 += Pij.swapaxes(0, 1)\n\n    # Update l1 and l2 amplitudes\n    l1 = rhs_L1 / ccsd.Dia\n    l2 = rhs_L2 / ccsd.Dijab\n    \n    # Compute LCCSD pseudoenergy \n    # E = sum_{ia} l_a^i f_{ia} + 1/4 sum_{ijab} l_ab^ij <ij||ab>\n    LCCSDcorr_E = np.einsum(\'ia,ia->\', ccsd.get_F(\'ov\'), l1)\n    LCCSDcorr_E += 0.25 * np.einsum(\'ijab,ijab->\', ccsd.get_MO(\'oovv\'), l2)\n\n    # Print LCCSD pseudoenergy\n    print(\'LCCSD Iteration %3d: LCCSD pseudoenergy = %3.12f  \'\\\n          \'dE = %3.5E\' % (LCCSD_iter, LCCSDcorr_E, (LCCSDcorr_E - LCCSDcorr_E_old)))\n    if (abs(LCCSDcorr_E - LCCSDcorr_E_old) < E_conv):\n        break\n\n    LCCSDcorr_E_old = LCCSDcorr_E\n\nprint(\'LCCSD iterations took %.2f seconds.\\n\' % (time.time() - lccsd_tstart))\n\nLCCSD_E = ccsd.rhf_e + LCCSDcorr_E\n\nprint(\'\\nFinal LCCSD correlation energy:     % 16.10f\' % LCCSDcorr_E)\nprint(\'Total LCCSD energy:                 % 16.10f\' % LCCSD_E)\n\n# Step 2: Build left and right dipole functions for t = 0 \n# Equations from [Nascimento:2016:5834]\n\nprint(\'\\nBuilding dipole functions\')\n\n### Grab dipole integrals and transform to MO basis\n\n# mu in the AO basis\nmints = psi4.core.MintsHelper(ccsd.wfn.basisset())\nmu = np.asarray(mints.ao_dipole()[polarization])\n# AO -> MO transformation\nmu = np.einsum(\'uj,vi,uv\', ccsd.C, ccsd.C, mu)\nmu = np.repeat(mu, 2, axis=0)\nmu = np.repeat(mu, 2, axis=1)\nspin_ind = np.arange(mu.shape[0], dtype=np.int) % 2\nmu *= (spin_ind.reshape(-1, 1) == spin_ind)\n\n### Build dipole functions\ndipole_build_tstart = time.time()\n\n# Right dipole function\n# [Nascimento:2016:5834], in the text below Eqn. 18\ntrace = np.trace(mu[o , o])\nmr0 = trace\nmr1 = mu[o, v].copy()\nmr2 = l2*0.0\n\n# Left dipole function\n\n# [Nascimento:2016:5834], Eqn. 19\nml0  = trace\nml0 += np.einsum(\'ia,ia->\', mu[o, v], l1)\n\n# [Nascimento:2016:5834], Eqn. 20\nml1  = mu[o, v].copy()\nml1 += trace * l1 \nml1 += np.einsum(\'ea,ie->ia\', mu[v, v], l1)\nml1 -= np.einsum(\'im,ma->ia\', mu[o, o], l1)\nml1 += np.einsum(\'imae,em->ia\', l2, mu[v, o])\n\n# [Nascimento:2016:5834], Eqn. 21\nml2  = np.einsum(\'ia,jb->ijab\', l1, mu[o, v])\nml2 -= np.einsum(\'ib,ja->ijab\', l1, mu[o, v])\nml2 += np.einsum(\'jb,ia->ijab\', l1, mu[o, v])\nml2 -= np.einsum(\'ja,ib->ijab\', l1, mu[o, v])\n\nml2 += trace * l2\n\nPab = np.einsum(\'ijeb,ea->ijab\', l2, mu[v, v])\nml2 += Pab\nml2 -= Pab.swapaxes(2, 3)\n\nPij = np.einsum(\'im,mjab->ijab\', mu[o, o], l2)\nml2 -= Pij\nml2 += Pij.swapaxes(0, 1)\n\nprint(\'Dipole function build took %.2f seconds.\\n\' % (time.time() - dipole_build_tstart))\n\n# Step 3: Build the time evolution of the dipole function (right only!)\n# Equations from [Nascimento:2016:5834]\n\n#### Important: Update Fae and Fmi so that they contain the diagonals of the\n#### Fock matrix.\n#### Fae += f_{aa} and Fmi += f_{ii}\nFae += ccsd.get_F(\'vv\')\nFmi += ccsd.get_F(\'oo\')\n\n# [Nascimento:2016:5834], Eqn. 24 \ndef compute_dmr0(Mr1, Mr2):\n    """"""Computes [Nascimento:2016:5834], Eqn. 24""""""\n    dMr0  = np.einsum(\'ia,ia->\',Mr1 , Fme)\n    dMr0 += 0.25 * np.einsum(\'ijab,ijab->\',Mr2, ccsd.get_MO(\'oovv\'))\n    return -1j * dMr0\n\n# [Nascimento:2016:5834], Eqn. 25\ndef compute_dmr1(Mr1, Mr2):\n    """"""Computes [Nascimento:2016:5834], Eqn. 25""""""\n    dMr1  = np.einsum(\'ib,ab->ia\',Mr1 , Fae)\n    dMr1 -= np.einsum(\'ji,ja->ia\',Fmi , Mr1)\n    dMr1 += np.einsum(\'jb,jabi->ia\',Mr1 , Wmbej)\n    dMr1 += np.einsum(\'ijab,jb->ia\',Mr2 , Fme)\n    dMr1 -= 0.5 * np.einsum(\'jkib,jkab->ia\',Wmnie , Mr2)\n    dMr1 += 0.5 * np.einsum(\'ijbc,ajbc->ia\',Mr2 , Wamef)\n    return -1j * dMr1\n\n# [Nascimento:2016:5834], Eqn. 26 \n# (the paper only contains the terms for CC2, here we provide the \n# additional terms for CCSD)\ndef compute_dmr2(Mr1, Mr2):\n    """"""Computes [Nascimento:2016:5834], Eqn. 26\n\n    The paper above only contains terms for CC2; here we provide the\n    additional terms for CCSD.\n    """"""\n    # P_(ab) M_m^b W_{mbij}\n    Pab = np.einsum(\'mb,maij->ijab\', Mr1, Wmbij)\n    dMr2  = Pab\n    dMr2 -= Pab.swapaxes(2, 3)\n\n    # + P_(ij) [M_n^e W_{mnie}] t_{jm}^{ab}\n    temp = np.einsum(\'ne,mnie->im\', Mr1, Wmnie)\n    Pij = np.einsum(\'im,jmab->ijab\', temp, t2)\n    dMr2 += Pij\n    dMr2 -= Pij.swapaxes(0, 1)\n\n    # - P_(ij) M_j^e W_{abei}\n    Pij = np.einsum(\'je,abei->ijab\', Mr1, Wabei)\n    dMr2 -= Pij\n    dMr2 += Pij.swapaxes(0, 1)\n\n    # - P_(ab) [M_m^f W_{amef}] t_{ij}^{be}\n    temp = -1.0 * np.einsum(\'mf,amef->ae\', Mr1, Wamef)\n    Pab = np.einsum(\'ae,ijbe->ijab\', temp, t2)\n    dMr2 += Pab\n    dMr2 -= Pab.swapaxes(2, 3)\n\n    # + P_(ij) M_{jm}^{ab} F_{mi}\n    Pij = np.einsum(\'jmab,mi->ijab\', Mr2, Fmi)\n    dMr2 += Pij\n    dMr2 -= Pij.swapaxes(0, 1)\n    \n    # + 0.5 * P_(ij) [M_{in}^{ef} <mn||ef>] t_{jm}^{ab}\n    temp = 0.5 * np.einsum(\'inef,mnef->im\', Mr2, ccsd.get_MO(\'oovv\'))\n    Pij = np.einsum(\'im,jmab->ijab\', temp, t2)\n    dMr2 += Pij\n    dMr2 -= Pij.swapaxes(0, 1)\n\n    # + P_(ab) M_{ij}^{ae} F_{be}\n    Pab = np.einsum(\'ijae,be->ijab\', Mr2, Fae)\n    dMr2 += Pab\n    dMr2 -= Pab.swapaxes(2, 3)\n\n    # + 0.5 * P_(ab) [M_{mn}^{af} <mn||ef>] t_{ij}^{be}\n    temp = 0.5 * np.einsum(\'mnaf,mnef->ae\', Mr2, ccsd.get_MO(\'oovv\'))\n    Pab = np.einsum(\'ae,ijbe->ijab\',temp , t2)\n    dMr2 += Pab\n    dMr2 -= Pab.swapaxes(2, 3)\n\n    # + P_(ij) P_(ab) M_{mj}^{ae} W_{mbei}\n    Pijab = np.einsum(\'mjae,mbei->ijab\', Mr2, Wmbej)\n    dMr2 += Pijab\n    dMr2 -= Pijab.swapaxes(0, 1)\n    dMr2 -= Pijab.swapaxes(2, 3)\n    dMr2 += Pijab.swapaxes(0, 1).swapaxes(2, 3)\n\n    # + 0.5 * M_{mn}^{ab} W_{mnij}\n    dMr2 += 0.5 * np.einsum(\'mnab,mnij->ijab\', Mr2, Wmnij)\n\n    # + 0.5 * M_{ij}^{ef} W_{abef}\n    dMr2 += 0.5 * np.einsum(\'ijef,abef->ijab\', Mr2, Wabef)\n\n    return -1j * dMr2    \n\n# Step 4: Time propagation. \n# Equations from [Nascimento:2016:5834] & [Cheever:2015]\n\n# Here we will use the 4th-order Runge-Kutta scheme.\n# See ""Fourth"" tab of [Cheever:2015] for details.\n\n# y_{n+1} = y_n + (h/6) * (k_1 + 2k_2 + 2k_3 +k_4)\n# k1 = f(t_n, y_n)\n# k2 = f(t_n + h/2, y_n+ h*k_{1}/2)\n# k3 = f(t_n + h/2, y_n+ h*k_{2}/2)\n# k4 = f(t_n + h, y_n+ h*k_3)\n\n### Time propagation\n\n# Initialize complex dipole function\nM0 = mr0 + 1j * 0\nM1 = mr1 + 1j * 0\nM2 = mr2 + 1j * 0\n\n# Begin propagation \n\nprint(\'Starting time propagation\\n\')\nprint(\'                 Time            Re{<M(0)|M(t)>}      Im{<M(0)|M(t)>}\')\n\npropagation_tstart = time.time()\nfor step in range(0, steps_total + 1):\n\n    curtime = step * time_step\n\n    # compute k1\n    k1_0 = compute_dmr0(M1, M2)\n    k1_1 = compute_dmr1(M1, M2)\n    k1_2 = compute_dmr2(M1, M2)\n\n    temp_0 =  M0 + 0.5 * time_step * k1_0\n    temp_1 =  M1 + 0.5 * time_step * k1_1\n    temp_2 =  M2 + 0.5 * time_step * k1_2\n\n    # compute k2\n    k2_0 = compute_dmr0(temp_1, temp_2) \n    k2_1 = compute_dmr1(temp_1, temp_2) \n    k2_2 = compute_dmr2(temp_1, temp_2) \n\n    temp_0 =  M0 + 0.5 * time_step * k2_0\n    temp_1 =  M1 + 0.5 * time_step * k2_1\n    temp_2 =  M2 + 0.5 * time_step * k2_2\n\n    # compute k3\n    k3_0 = compute_dmr0(temp_1, temp_2) \n    k3_1 = compute_dmr1(temp_1, temp_2) \n    k3_2 = compute_dmr2(temp_1, temp_2) \n\n    temp_0 = M0 + 1.0 * time_step * k3_0\n    temp_1 = M1 + 1.0 * time_step * k3_1\n    temp_2 = M2 + 1.0 * time_step * k3_2\n\n    # compute k4\n    k4_0 = compute_dmr0(temp_1, temp_2) \n    k4_1 = compute_dmr1(temp_1, temp_2) \n    k4_2 = compute_dmr2(temp_1, temp_2) \n\n    # compute dipole function at time t_0 + time_step   \n    M0 += (time_step/6.0) * (k1_0 + 2.0 * k2_0 + 2.0 * k3_0 + 1.0 * k4_0)\n    M1 += (time_step/6.0) * (k1_1 + 2.0 * k2_1 + 2.0 * k3_1 + 1.0 * k4_1)\n    M2 += (time_step/6.0) * (k1_2 + 2.0 * k2_2 + 2.0 * k3_2 + 1.0 * k4_2)\n\n    # compute autocorrelation function <M(0)|M(t)>\n    # [Nascimento:2016:5834], Eqn. 13\n    corr_func  = ml0 * M0\n    corr_func += np.einsum(\'ia,ia->\', ml1, M1)\n    corr_func += 0.25 * np.einsum(\'ijab,ijab->\', ml2, M2)\n\n    print(\'@TIME %20.12f %20.12f %20.12f\' % (curtime, corr_func.real, corr_func.imag))\n\nprint(\'Time-propagation took %.2f seconds.\\n\' % (time.time() - propagation_tstart))\nprint(\'Computation finished!\\n\')\n'"
Coupled-Cluster/Spin_Orbitals/CCSD/helper_CC.py,47,"b'""""""Helper classes and functions for spin-orbital CC module.\n\nReferences:\n- DPD formulation of CCSD equations: [Stanton:1991:4334]\n- CC algorithms from Daniel Crawford\'s programming website:\nhttp://github.com/CrawfordGroup/ProgrammingProjects\n""""""\n\n__authors__   =  ""Daniel G. A. Smith""\n__credits__   =  [""Daniel G. A. Smith""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__   = ""BSD-3-Clause""\n__date__      = ""2014-02-22""\n\nimport time\nimport numpy as np\nimport psi4\n\n\n# N dimensional dot\n# Like a mini DPD library\ndef ndot(input_string, op1, op2, prefactor=None):\n    """"""\n    No checks, if you get weird errors its up to you to debug.\n\n    ndot(\'abcd,cdef->abef\', arr1, arr2)\n    """"""\n    inp, output_ind = input_string.split(\'->\')\n    input_left, input_right = inp.split(\',\')\n\n    size_dict = {}\n    for s, size in zip(input_left, op1.shape):\n        size_dict[s] = size\n    for s, size in zip(input_right, op2.shape):\n        size_dict[s] = size\n\n    set_left = set(input_left)\n    set_right = set(input_right)\n    set_out = set(output_ind)\n\n    idx_removed = (set_left | set_right) - set_out\n    keep_left = set_left - idx_removed\n    keep_right = set_right - idx_removed\n\n    # Tensordot axes\n    left_pos, right_pos = (), ()\n    for s in idx_removed:\n        left_pos += (input_left.find(s), )\n        right_pos += (input_right.find(s), )\n    tdot_axes = (left_pos, right_pos)\n\n    # Get result ordering\n    tdot_result = input_left + input_right\n    for s in idx_removed:\n        tdot_result = tdot_result.replace(s, \'\')\n\n    rs = len(idx_removed)\n    dim_left, dim_right, dim_removed = 1, 1, 1\n    for key, size in size_dict.items():\n        if key in keep_left:\n            dim_left *= size\n        if key in keep_right:\n            dim_right *= size\n        if key in idx_removed:\n            dim_removed *= size\n\n    shape_result = tuple(size_dict[x] for x in tdot_result)\n    used_einsum = False\n\n    # Matrix multiply\n    # No transpose needed\n    if input_left[-rs:] == input_right[:rs]:\n        new_view = np.dot(op1.reshape(dim_left, dim_removed), op2.reshape(dim_removed, dim_right))\n\n    # Transpose both\n    elif input_left[:rs] == input_right[-rs:]:\n        new_view = np.dot(op1.reshape(dim_removed, dim_left).T, op2.reshape(dim_right, dim_removed).T)\n\n    # Transpose right\n    elif input_left[-rs:] == input_right[-rs:]:\n        new_view = np.dot(op1.reshape(dim_left, dim_removed), op2.reshape(dim_right, dim_removed).T)\n\n    # Tranpose left\n    elif input_left[:rs] == input_right[:rs]:\n        new_view = np.dot(op1.reshape(dim_removed, dim_left).T, op2.reshape(dim_removed, dim_right))\n\n    # If we have to transpose vector-matrix, einsum is faster\n    elif (len(keep_left) == 0) or (len(keep_right) == 0):\n        new_view = np.einsum(input_string, op1, op2)\n        used_einsum = True\n\n    else:\n        new_view = np.tensordot(op1, op2, axes=tdot_axes)\n\n    # Make sure the resulting shape is correct\n    if (new_view.shape != shape_result) and not used_einsum:\n        if (len(shape_result) > 0):\n            new_view = new_view.reshape(shape_result)\n        else:\n            new_view = np.squeeze(new_view)\n\n    # In-place mult by prefactor if requested\n    if prefactor is not None:\n        new_view *= prefactor\n\n    # Do final tranpose if needed\n    if used_einsum:\n        return new_view\n    elif tdot_result == output_ind:\n        return new_view\n    else:\n        return np.einsum(tdot_result + \'->\' + output_ind, new_view)\n\n\nclass helper_CCSD(object):\n    def __init__(self, mol, freeze_core=False, memory=2):\n        """"""\n        Initializes the helper_CCSD object.\n\n        Parameters\n        ----------\n        mol : psi4.core.Molecule\n            The molecule to be used for the given helper object.\n        freeze_core : {True, False}, optional\n            Boolean flag indicating presence of frozen core orbitals.  Default: False\n        memory : int or float, optional\n            The total memory, in GB, allotted for the given helper object. Default: 2\n\n        Examples\n        --------\n\n        # Construct the helper object\n        >>> ccsd = helper_CCSD(psi4.geometry(""He\\nHe 1 2.0""))\n\n        # Compute the CCSD total energy\n        >>> total_E = ccsd.compute_energy()\n        """"""\n\n        if freeze_core:\n            raise Exception(""Frozen core doesnt work yet!"")\n        print(""\\nInitalizing CCSD object...\\n"")\n\n        # Integral generation from Psi4\'s MintsHelper\n        time_init = time.time()\n\n        print(\'Computing RHF reference.\')\n        psi4.core.set_active_molecule(mol)\n        psi4.set_module_options(\'SCF\', {\'SCF_TYPE\': \'PK\'})\n        psi4.set_module_options(\'SCF\', {\'E_CONVERGENCE\': 10e-10})\n        psi4.set_module_options(\'SCF\', {\'D_CONVERGENCE\': 10e-10})\n\n        # Core is frozen by default\n        if not freeze_core:\n            psi4.set_module_options(\'CCENERGY\', {\'FREEZE_CORE\': \'FALSE\'})\n\n        self.rhf_e, self.wfn = psi4.energy(\'SCF\', return_wfn=True)\n        print(\'RHF Final Energy                          % 16.10f\\n\' % (self.rhf_e))\n\n        self.ccsd_corr_e = 0.0\n        self.ccsd_e = 0.0\n\n        self.eps = np.asarray(self.wfn.epsilon_a())\n        self.ndocc = self.wfn.doccpi()[0]\n        self.nmo = self.wfn.nmo()\n        self.memory = memory\n        self.nfzc = 0\n\n        # Freeze core\n        if freeze_core:\n            Zlist = np.array([mol.Z(x) for x in range(mol.natom())])\n            self.nfzc = np.sum(Zlist > 2)\n            self.nfzc += np.sum(Zlist > 10) * 4\n            if np.any(Zlist > 18):\n                raise Exception(""Frozen core for Z > 18 not yet implemented"")\n\n            print(""Cutting %d core orbitals."" % self.nfzc)\n\n            # Copy C\n            oldC = np.array(self.wfn.Ca(), copy=True)\n\n            # Build new C matrix and view, set with numpy slicing\n            self.C = psi.Matrix(self.nmo, self.nmo - self.nfzc)\n            self.npC = np.asarray(self.C)\n            self.npC[:] = oldC[:, self.nfzc:]\n\n            # Update epsilon array\n            self.ndocc -= self.nfzc\n\n        else:\n            self.C = self.wfn.Ca()\n            self.npC = np.asarray(self.C)\n\n        mints = psi4.core.MintsHelper(self.wfn.basisset())\n        H = np.asarray(mints.ao_kinetic()) + np.asarray(mints.ao_potential())\n        self.nmo = H.shape[0]\n\n        # Update H, transform to MO basis and tile for alpha/beta spin\n        H = np.einsum(\'uj,vi,uv\', self.npC, self.npC, H)\n        H = np.repeat(H, 2, axis=0)\n        H = np.repeat(H, 2, axis=1)\n\n        # Make H block diagonal\n        spin_ind = np.arange(H.shape[0], dtype=np.int) % 2\n        H *= (spin_ind.reshape(-1, 1) == spin_ind)\n\n        #Make spin-orbital MO\n        print(\'Starting AO -> spin-orbital MO transformation...\')\n\n        ERI_Size = (self.nmo**4) * 128.e-9\n        memory_footprint = ERI_Size * 5\n        if memory_footprint > self.memory:\n            psi.clean()\n            raise Exception(""Estimated memory utilization (%4.2f GB) exceeds numpy_memory \\\n                            limit of %4.2f GB."" % (memory_footprint, self.memory))\n\n        # Integral generation from Psi4\'s MintsHelper\n        self.MO = np.asarray(mints.mo_spin_eri(self.C, self.C))\n        print(""Size of the ERI tensor is %4.2f GB, %d basis functions."" % (ERI_Size, self.nmo))\n\n        # Update nocc and nvirt\n        self.nso = self.nmo * 2\n        self.nfzc = self.nfzc * 2\n        self.nocc = self.ndocc * 2\n        self.nvirt = self.nso - self.nocc - self.nfzc * 2\n\n        # Make slices\n        self.slice_nfzc = slice(0, self.nfzc)\n        self.slice_o = slice(self.nfzc, self.nocc + self.nfzc)\n        self.slice_v = slice(self.nocc + self.nfzc, self.nso)\n        self.slice_a = slice(0, self.nso)\n        self.slice_dict = {\'f\': self.slice_nfzc, \'o\': self.slice_o, \'v\': self.slice_v, \'a\': self.slice_a}\n\n        # Extend eigenvalues\n        self.eps = np.repeat(self.eps, 2)\n\n        # Compute Fock matrix\n        self.F = H + np.einsum(\'pmqm->pq\', self.MO[:, self.slice_o, :, self.slice_o])\n\n        ### Build D matrices\n        print(\'\\nBuilding denominator arrays...\')\n        Focc = np.diag(self.F)[self.slice_o]\n        Fvir = np.diag(self.F)[self.slice_v]\n\n        self.Dia = Focc.reshape(-1, 1) - Fvir\n        self.Dijab = Focc.reshape(-1, 1, 1, 1) + Focc.reshape(-1, 1, 1) - Fvir.reshape(-1, 1) - Fvir\n\n        ### Construct initial guess\n        print(\'Building initial guess...\')\n        # t^a_i\n        self.t1 = np.zeros((self.nocc, self.nvirt))\n        # t^{ab}_{ij}\n        self.t2 = self.MO[self.slice_o, self.slice_o, self.slice_v, self.slice_v] / self.Dijab\n\n        print(\'\\n..initialed CCSD in %.3f seconds.\\n\' % (time.time() - time_init))\n\n    # occ orbitals i, j, k, l, m, n\n    # virt orbitals a, b, c, d, e, f\n    # all oribitals p, q, r, s, t, u, v\n    def get_MO(self, string):\n        if len(string) != 4:\n            psi4.core.clean()\n            raise Exception(\'get_MO: string %s must have 4 elements.\' % string)\n        return self.MO[self.slice_dict[string[0]], self.slice_dict[string[1]], self.slice_dict[string[2]],\n                       self.slice_dict[string[3]]]\n\n    def get_F(self, string):\n        if len(string) != 2:\n            psi4.core.clean()\n            raise Exception(\'get_F: string %s must have 4 elements.\' % string)\n        return self.F[self.slice_dict[string[0]], self.slice_dict[string[1]]]\n\n    #Bulid Eqn 9: tilde{\\Tau})\n    def build_tilde_tau(self):\n        """"""Builds [Stanton:1991:4334] Eqn. 9""""""\n        ttau = self.t2.copy()\n        tmp = 0.5 * np.einsum(\'ia,jb->ijab\', self.t1, self.t1)\n        ttau += tmp\n        ttau -= tmp.swapaxes(2, 3)\n        return ttau\n\n    #Build Eqn 10: \\Tau)\n    def build_tau(self):\n        """"""Builds [Stanton:1991:4334] Eqn. 10""""""\n        ttau = self.t2.copy()\n        tmp = np.einsum(\'ia,jb->ijab\', self.t1, self.t1)\n        ttau += tmp\n        ttau -= tmp.swapaxes(2, 3)\n        return ttau\n\n    #Build Eqn 3:\n    def build_Fae(self):\n        """"""Builds [Stanton:1991:4334] Eqn. 10""""""\n        Fae = self.get_F(\'vv\').copy()\n        Fae[np.diag_indices_from(Fae)] = 0\n\n        Fae -= ndot(\'me,ma->ae\', self.get_F(\'ov\'), self.t1, prefactor=0.5)\n        Fae += ndot(\'mf,mafe->ae\', self.t1, self.get_MO(\'ovvv\'))\n\n        Fae -= ndot(\'mnaf,mnef->ae\', self.build_tilde_tau(), self.get_MO(\'oovv\'), prefactor=0.5)\n        return Fae\n\n    #Build Eqn 4:\n    def build_Fmi(self):\n        """"""Builds [Stanton:1991:4334] Eqn. 4""""""\n        Fmi = self.get_F(\'oo\').copy()\n        Fmi[np.diag_indices_from(Fmi)] = 0\n\n        Fmi += ndot(\'ie,me->mi\', self.t1, self.get_F(\'ov\'), prefactor=0.5)\n        Fmi += ndot(\'ne,mnie->mi\', self.t1, self.get_MO(\'ooov\'))\n\n        Fmi += ndot(\'inef,mnef->mi\', self.build_tilde_tau(), self.get_MO(\'oovv\'), prefactor=0.5)\n        return Fmi\n\n    #Build Eqn 5:\n    def build_Fme(self):\n        """"""Builds [Stanton:1991:4334] Eqn. 5""""""\n        Fme = self.get_F(\'ov\').copy()\n        Fme += ndot(\'nf,mnef->me\', self.t1, self.get_MO(\'oovv\'))\n        return Fme\n\n    #Build Eqn 6:\n    def build_Wmnij(self):\n        """"""Builds [Stanton:1991:4334] Eqn. 6""""""\n        Wmnij = self.get_MO(\'oooo\').copy()\n\n        Pij = ndot(\'je,mnie->mnij\', self.t1, self.get_MO(\'ooov\'))\n        Wmnij += Pij\n        Wmnij -= Pij.swapaxes(2, 3)\n\n        Wmnij += ndot(\'ijef,mnef->mnij\', self.build_tau(), self.get_MO(\'oovv\'), prefactor=0.25)\n        return Wmnij\n\n    #Build Eqn 7:\n    def build_Wabef(self):\n        """"""Builds [Stanton:1991:4334] Eqn. 7""""""\n    # Rate limiting step written using tensordot, ~10x faster\n    # The commented out lines are consistent with the paper\n        Wabef = self.get_MO(\'vvvv\').copy()\n\n        Pab = ndot(\'mb,amef->abef\', self.t1, self.get_MO(\'vovv\'))\n        Wabef -= Pab\n        Wabef += Pab.swapaxes(0, 1)\n\n        Wabef += ndot(\'mnab,mnef->abef\', self.build_tau(), self.get_MO(\'oovv\'), prefactor=0.25)\n        return Wabef\n\n    #Build Eqn 8:\n    def build_Wmbej(self):\n        """"""Builds [Stanton:1991:4334] Eqn. 8""""""\n        Wmbej = self.get_MO(\'ovvo\').copy()\n        Wmbej += ndot(\'jf,mbef->mbej\', self.t1, self.get_MO(\'ovvv\'))\n        Wmbej -= ndot(\'nb,mnej->mbej\', self.t1, self.get_MO(\'oovo\'))\n\n        tmp = (0.5 * self.t2)\n        tmp += np.einsum(\'jf,nb->jnfb\', self.t1, self.t1)\n\n        Wmbej -= ndot(\'jnfb,mnef->mbej\', tmp, self.get_MO(\'oovv\'))\n        return Wmbej\n\n    def update(self):\n        """"""Updates T1 & T2 amplitudes.""""""\n\n        ### Build intermediates: [Stanton:1991:4334] Eqns. 3-8\n        Fae = self.build_Fae()\n        Fmi = self.build_Fmi()\n        Fme = self.build_Fme()\n\n        #### Build RHS side of self.t1 equations, [Stanton:1991:4334] Eqn. 1\n        rhs_T1 = self.get_F(\'ov\').copy()\n        rhs_T1 += ndot(\'ie,ae->ia\', self.t1, Fae)\n        rhs_T1 -= ndot(\'ma,mi->ia\', self.t1, Fmi)\n        rhs_T1 += ndot(\'imae,me->ia\', self.t2, Fme)\n        rhs_T1 -= ndot(\'nf,naif->ia\', self.t1, self.get_MO(\'ovov\'))\n        rhs_T1 -= ndot(\'imef,maef->ia\', self.t2, self.get_MO(\'ovvv\'), prefactor=0.5)\n        rhs_T1 -= ndot(\'mnae,nmei->ia\', self.t2, self.get_MO(\'oovo\'), prefactor=0.5)\n\n        ### Build RHS side of self.t2 equations, [Stanton:1991:4334] Eqn. 2\n        rhs_T2 = self.get_MO(\'oovv\').copy()\n\n        # P_(ab) t_ijae (F_be - 0.5 t_mb F_me)\n        tmp = Fae - 0.5 * ndot(\'mb,me->be\', self.t1, Fme)\n        Pab = ndot(\'ijae,be->ijab\', self.t2, tmp)\n        rhs_T2 += Pab\n        rhs_T2 -= Pab.swapaxes(2, 3)\n\n        # P_(ij) t_imab (F_mj + 0.5 t_je F_me)\n        tmp = Fmi + 0.5 * ndot(\'je,me->mj\', self.t1, Fme)\n        Pij = ndot(\'imab,mj->ijab\', self.t2, tmp)\n        rhs_T2 -= Pij\n        rhs_T2 += Pij.swapaxes(0, 1)\n\n        tmp_tau = self.build_tau()\n        Wmnij = self.build_Wmnij()\n        Wabef = self.build_Wabef()\n        rhs_T2 += ndot(\'mnab,mnij->ijab\', tmp_tau, Wmnij, prefactor=0.5)\n        rhs_T2 += ndot(\'ijef,abef->ijab\', tmp_tau, Wabef, prefactor=0.5)\n\n        # P_(ij) * P_(ab)\n        # (ij - ji) * (ab - ba)\n        # ijab - ijba -jiab + jiba\n        tmp = ndot(\'ie,mbej->mbij\', self.t1, self.get_MO(\'ovvo\'))\n        tmp = ndot(\'ma,mbij->ijab\', self.t1, tmp)\n        Wmbej = self.build_Wmbej()\n        Pijab = ndot(\'imae,mbej->ijab\', self.t2, Wmbej) - tmp\n\n        rhs_T2 += Pijab\n        rhs_T2 -= Pijab.swapaxes(2, 3)\n        rhs_T2 -= Pijab.swapaxes(0, 1)\n        rhs_T2 += Pijab.swapaxes(0, 1).swapaxes(2, 3)\n\n        Pij = ndot(\'ie,abej->ijab\', self.t1, self.get_MO(\'vvvo\'))\n        rhs_T2 += Pij\n        rhs_T2 -= Pij.swapaxes(0, 1)\n\n        Pab = ndot(\'ma,mbij->ijab\', self.t1, self.get_MO(\'ovoo\'))\n        rhs_T2 -= Pab\n        rhs_T2 += Pab.swapaxes(2, 3)\n\n        ### Update T1 and T2 amplitudes\n        self.t1 = rhs_T1 / self.Dia\n        self.t2 = rhs_T2 / self.Dijab\n\n    def compute_corr_energy(self):\n        """"""Compute CCSD correlation energy using current amplitudes.""""""\n        CCSDcorr_E = np.einsum(\'ia,ia->\', self.get_F(\'ov\'), self.t1)\n        CCSDcorr_E += 0.25 * np.einsum(\'ijab,ijab->\', self.get_MO(\'oovv\'), self.t2)\n        CCSDcorr_E += 0.5 * np.einsum(\'ijab,ia,jb->\', self.get_MO(\'oovv\'), self.t1, self.t1)\n\n        self.ccsd_corr_e = CCSDcorr_E\n        self.ccsd_e = self.rhf_e + self.ccsd_corr_e\n        return CCSDcorr_E\n\n    def compute_energy(self, e_conv=1.e-8, maxiter=20, max_diis=8):\n        """"""Computes total CCSD energy.""""""\n        ### Setup DIIS\n        diis_vals_t1 = [self.t1.copy()]\n        diis_vals_t2 = [self.t2.copy()]\n        diis_errors = []\n\n        ### Start Iterations\n        ccsd_tstart = time.time()\n\n        # Compute MP2 energy\n        CCSDcorr_E_old = self.compute_corr_energy()\n        print(""CCSD Iteration %3d: CCSD correlation = %.12f   dE = % .5E   MP2"" % (0, CCSDcorr_E_old, -CCSDcorr_E_old))\n\n        # Iterate!\n        diis_size = 0\n        for CCSD_iter in range(1, maxiter + 1):\n\n            # Save new amplitudes\n            oldt1 = self.t1.copy()\n            oldt2 = self.t2.copy()\n\n            self.update()\n\n            # Compute CCSD correlation energy\n            CCSDcorr_E = self.compute_corr_energy()\n\n            # Print CCSD iteration information\n            print(\'CCSD Iteration %3d: CCSD correlation = %.12f   dE = % .5E   DIIS = %d\' %\n                  (CCSD_iter, CCSDcorr_E, (CCSDcorr_E - CCSDcorr_E_old), diis_size))\n\n            # Check convergence\n            if (abs(CCSDcorr_E - CCSDcorr_E_old) < e_conv):\n                print(\'\\nCCSD has converged in %.3f seconds!\' % (time.time() - ccsd_tstart))\n                return CCSDcorr_E\n\n            # Add DIIS vectors\n            diis_vals_t1.append(self.t1.copy())\n            diis_vals_t2.append(self.t2.copy())\n\n            # Build new error vector\n            error_t1 = (diis_vals_t1[-1] - oldt1).ravel()\n            error_t2 = (diis_vals_t2[-1] - oldt2).ravel()\n            diis_errors.append(np.concatenate((error_t1, error_t2)))\n\n            # Update old energy\n            CCSDcorr_E_old = CCSDcorr_E\n\n            if CCSD_iter >= 1:\n                # Limit size of DIIS vector\n                if (len(diis_vals_t1) > max_diis):\n                    del diis_vals_t1[0]\n                    del diis_vals_t2[0]\n                    del diis_errors[0]\n\n                diis_size = len(diis_vals_t1) - 1\n\n                # Build error matrix B, [Pulay:1980:393], Eqn. 6, LHS\n                B = np.ones((diis_size + 1, diis_size + 1)) * -1\n                B[-1, -1] = 0\n\n                for n1, e1 in enumerate(diis_errors):\n                    B[n1, n1] = np.dot(e1, e1)\n                    for n2, e2 in enumerate(diis_errors):\n                        if n1 >= n2: continue\n                        B[n1, n2] = np.dot(e1, e2)\n                        B[n2, n1] = B[n1, n2]\n\n                B[:-1, :-1] /= np.abs(B[:-1, :-1]).max()\n\n                # Build residual vector, [Pulay:1980:393], Eqn. 6, RHS\n                resid = np.zeros(diis_size + 1)\n                resid[-1] = -1\n\n                # Solve pulay equations, [Pulay:1980:393], Eqn. 6\n                ci = np.linalg.solve(B, resid)\n\n                # Calculate new amplitudes\n                self.t1[:] = 0\n                self.t2[:] = 0\n                for num in range(diis_size):\n                    self.t1 += ci[num] * diis_vals_t1[num + 1]\n                    self.t2 += ci[num] * diis_vals_t2[num + 1]\n\n            # End DIIS amplitude update\n            # End CCSD class\n\n\nif __name__ == ""__main__"":\n    arr4 = np.random.rand(4, 4, 4, 4)\n    arr2 = np.random.rand(4, 4)\n\n    def test_ndot(string, op1, op2):\n        ein_ret = np.einsum(string, op1, op2)\n        ndot_ret = ndot(string, op1, op2)\n        assert np.allclose(ein_ret, ndot_ret)\n\n    test_ndot(\'abcd,cdef->abef\', arr4, arr4)\n    test_ndot(\'acbd,cdef->abef\', arr4, arr4)\n    test_ndot(\'acbd,cdef->abfe\', arr4, arr4)\n    test_ndot(\'mnab,mnij->ijab\', arr4, arr4)\n\n    test_ndot(\'cd,cdef->ef\', arr2, arr4)\n    test_ndot(\'ce,cdef->df\', arr2, arr4)\n    test_ndot(\'nf,naif->ia\', arr2, arr4)\n'"
Response-Theory/Coupled-Cluster/RHF/helper_ccpert.py,6,"b'# -*- coding: utf-8 -*-\n""""""\nA simple python script to compute RHF-CCSD linear response function \nfor calculating properties like dipole polarizabilities, optical\nrotations etc. \n\nReferences: \n- Equations and algoriths from [Koch:1991:3333], [Gwaltney:1996:189], \n[Helgaker:2000], and [Crawford:xxxx]\n\n1. A Whirlwind Introduction to Coupled Cluster Response Theory, T.D. Crawford, Private Notes,\n   (pdf in the current directory).\n2. H. Koch and P. J\xc3\xb8rgensen, J. Chem. Phys. Volume 93, pp. 3333-3344 (1991).\n3. S. R. Gwaltney, M. Nooijen and R.J. Bartlett, Chemical Physics Letters, 248, pp. 189-198 (1996).\n4. Chapter 13, ""Molecular Electronic-Structure Theory"", Trygve Helgaker, \n   Poul J\xc3\xb8rgensen and Jeppe Olsen, John Wiley & Sons Ltd.\n\n""""""\n\n__authors__ = ""Ashutosh Kumar""\n__credits__ = [""Ashutosh Kumar"", ""Daniel G. A. Smith"", ""Lori A. Burns"", ""T. D. Crawford""]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2017-05-17""\n\nimport time\nimport numpy as np\nimport psi4\nimport sys\nsys.path.append(""../../../Coupled-Cluster/RHF"")\nfrom utils import ndot\nfrom utils import helper_diis\n\nclass HelperCCPert(object):\n    def __init__(self, name, pert, ccsd, hbar, cclambda, omega):\n\n        # start of the ccpert class\n        time_init = time.time()\n\n        # Grabbing all the info from the wavefunctions passed\n        self.pert = pert\n        self.name = name\n        self.MO = ccsd.MO\n        self.ndocc = ccsd.ndocc\n        self.nmo = ccsd.nmo\n        self.nocc = ccsd.ndocc\n        self.nvirt = ccsd.nmo - ccsd.nocc \n        self.mints = ccsd.mints\n        self.F = ccsd.F\n        self.t1 = ccsd.t1\n        self.t2 = ccsd.t2\n        self.ttau  =  hbar.ttau\n        self.Loovv =  hbar.Loovv\n        self.Looov =  hbar.Looov\n        self.Lvovv =  hbar.Lvovv\n        self.Hov   =  hbar.Hov\n        self.Hvv   =  hbar.Hvv\n        self.Hoo   =  hbar.Hoo\n        self.Hoooo =  hbar.Hoooo\n        self.Hvvvv =  hbar.Hvvvv\n        self.Hvovv =  hbar.Hvovv\n        self.Hooov =  hbar.Hooov\n        self.Hovvo =  hbar.Hovvo\n        self.Hovov =  hbar.Hovov\n        self.Hvvvo =  hbar.Hvvvo\n        self.Hovoo =  hbar.Hovoo\n        self.l1 = cclambda.l1\n        self.l2 = cclambda.l2\n        self.omega = omega\n\n        self.slice_o = slice(0, self.nocc)\n        self.slice_v = slice(self.nocc, self.nmo)\n        self.slice_a = slice(0, self.nmo)\n        self.slice_dict = {\'o\' : self.slice_o, \'v\' : self.slice_v,\n                           \'a\' : self.slice_a}\n\n        # Build the denominators from diagonal elements of Hbar and omega\n        self.Dia = self.Hoo.diagonal().reshape(-1, 1) - self.Hvv.diagonal()\n        self.Dijab = self.Hoo.diagonal().reshape(-1, 1, 1, 1) + self.Hoo.diagonal().reshape(-1, 1, 1) - self.Hvv.diagonal().reshape(-1, 1) - self.Hvv.diagonal() \n        self.Dia += omega\n        self.Dijab += omega\n        \n        # Guesses for X1 and X2 amplitudes (First order perturbed T amplitudes)\n        self.x1 = self.build_Avo().swapaxes(0,1)/self.Dia\n        self.pertbar_ijab = self.build_Avvoo().swapaxes(0,2).swapaxes(1,3)\n        self.x2 = self.pertbar_ijab.copy()\n        self.x2 += self.pertbar_ijab.swapaxes(0,1).swapaxes(2,3)\n        self.x2 = self.x2/self.Dijab\n       \n        # Guesses for Y1 and Y2 amplitudes (First order perturbed Lambda amplitudes)\n        self.y1 =  2.0 * self.x1.copy() \n        self.y2 =  4.0 * self.x2.copy()    \n        self.y2 -= 2.0 * self.x2.swapaxes(2,3)\n\n        # Conventions used :    \n        # occ orbitals  : i, j, k, l, m, n\n        # virt orbitals : a, b, c, d, e, f\n        # all oribitals : p, q, r, s, t, u, v\n\n    def get_MO(self, string):\n        if len(string) != 4:\n            psi4.core.clean()\n            raise Exception(\'get_MO: string %s must have 4 elements.\' % string)\n        return self.MO[self.slice_dict[string[0]], self.slice_dict[string[1]],\n                       self.slice_dict[string[2]], self.slice_dict[string[3]]]\n\n    def get_F(self, string):\n        if len(string) != 2:\n            psi4.core.clean()\n            raise Exception(\'get_F: string %s must have 2 elements.\' % string)\n        return self.F[self.slice_dict[string[0]], self.slice_dict[string[1]]]\n\n\n    def get_pert(self, string):\n        if len(string) != 2:\n            psi4.core.clean()\n            raise Exception(\'get_pert: string %s must have 2 elements.\' % string)\n        return self.pert[self.slice_dict[string[0]], self.slice_dict[string[1]]]\n\n    # Build different pieces of the similarity transformed perturbation operator\n    # using ground state T amplitudes i.e T(0).\n    # A_bar = e^{-T(0)} A e^{T(0)} = A + [A,T(0)] + 1/2! [[A,T(0)],T(0)] \n    # since A is a one body operator, the expansion truncates at double commutators.\n\n    def build_Aoo(self):\n        Aoo = self.get_pert(\'oo\').copy()\n        Aoo += ndot(\'ie,me->mi\', self.t1, self.get_pert(\'ov\'))\n        return Aoo\n\n    def build_Aov(self):\n        Aov = self.get_pert(\'ov\').copy()\n        return Aov\n\n    def build_Avo(self):\n        Avo =  self.get_pert(\'vo\').copy()\n        Avo += ndot(\'ae,ie->ai\', self.get_pert(\'vv\'), self.t1)\n        Avo -= ndot(\'ma,mi->ai\', self.t1, self.get_pert(\'oo\'))\n        Avo += ndot(\'miea,me->ai\', self.t2, self.get_pert(\'ov\'), prefactor=2.0)\n        Avo += ndot(\'imea,me->ai\', self.t2, self.get_pert(\'ov\'), prefactor=-1.0)\n        tmp = ndot(\'ie,ma->imea\', self.t1, self.t1)\n        Avo -= ndot(\'imea,me->ai\', tmp, self.get_pert(\'ov\'))\n        return Avo\n\n    def build_Avv(self):\n        Avv =  self.get_pert(\'vv\').copy()\n        Avv -= ndot(\'ma,me->ae\', self.t1, self.get_pert(\'ov\'))\n        return Avv\n\n    def build_Aovoo(self):\n        Aovoo = 0\n        Aovoo += ndot(\'ijeb,me->mbij\', self.t2, self.get_pert(\'ov\'))\n        return Aovoo\n\n    def build_Avvvo(self):\n        Avvvo = 0\n        Avvvo -= ndot(\'miab,me->abei\', self.t2, self.get_pert(\'ov\'))\n        return Avvvo\n\n    def build_Avvoo(self):\n        Avvoo = 0\n        Avvoo += ndot(\'ijeb,ae->abij\', self.t2, self.build_Avv())\n        Avvoo -= ndot(\'mjab,mi->abij\', self.t2, self.build_Aoo())\n        return Avvoo\n\n    # Intermediates to avoid construction of 3 body Hbar terms\n    # in solving X amplitude equations.\n    def build_Zvv(self):\n        Zvv = 0\n        Zvv += ndot(\'amef,mf->ae\', self.Hvovv, self.x1, prefactor=2.0)\n        Zvv += ndot(\'amfe,mf->ae\', self.Hvovv, self.x1, prefactor=-1.0)\n        Zvv -= ndot(\'mnaf,mnef->ae\', self.x2, self.Loovv)\n        return Zvv\n\n    def build_Zoo(self):\n        Zoo = 0\n        Zoo -= ndot(\'mnie,ne->mi\', self.Hooov, self.x1, prefactor=2.0)\n        Zoo -= ndot(\'nmie,ne->mi\', self.Hooov, self.x1, prefactor=-1.0)\n        Zoo -= ndot(\'mnef,inef->mi\', self.Loovv, self.x2)\n        return Zoo\n\n    # Intermediates to avoid construction of 3 body Hbar terms\n    # in solving Y amplitude equations (just like in lambda equations).\n    def build_Goo(self, t2, y2):\n        Goo = 0\n        Goo += ndot(\'mjab,ijab->mi\', t2, y2)\n        return Goo\n\n    def build_Gvv(self, y2, t2):\n        Gvv = 0\n        Gvv -= ndot(\'ijab,ijeb->ae\', y2, t2)\n        return Gvv\n\n    def update_X(self):\n        # X1 and X2 amplitudes are the Fourier analogues of first order perturbed T1 and T2 amplitudes, \n        # (eq. 65, [Crawford:xxxx]). For a given perturbation, these amplitudes are frequency dependent and \n        # can be obtained by solving a linear system of equations, (Hbar(0) - omgea * I)X = Hbar(1)\n        # Refer to eq 70 of [Crawford:xxxx]. Writing t_mu^(1)(omega) as X_mu and Hbar^(1)(omega) as A_bar,\n        # X1 equations:\n        # omega * X_ia = <phi^a_i|A_bar|O> + <phi^a_i|Hbar^(0)|phi^c_k> * X_kc + <phi^a_i|Hbar^(0)|phi^cd_kl> * X_klcd\n        # X2 equations:\n        # omega * X_ijab = <phi^ab_ij|A_bar|O> + <phi^ab_ij|Hbar^(0)|phi^c_k> * X_kc + <phi^ab_ij|Hbar^(0)|phi^cd_kl> * X_klcd\n        # Note that the RHS terms have exactly the same structure as EOM-CCSD sigma equations.\n        # Spin Orbital expressions (Einstein summation):\n\n        # X1 equations: \n        # -omega * X_ia + A_bar_ai + X_ie * Hvv_ae - X_ma * Hoo_mi + X_me * Hovvo_maei + X_miea * Hov_me \n        # + 0.5 * X_imef * Hvovv_amef - 0.5 * X_mnae * Hooov_mnie = 0\n\n        # X2 equations:\n        # -omega * X_ijab + A_bar_abij + P(ij) X_ie * Hvvvo_abej - P(ab) X_ma * Hovoo_mbij \n        # + P(ab) X_mf * Hvovv_amef * t_ijeb - P(ij) X_ne * Hooov_mnie * t_mjab \n        # + P(ab) X_ijeb * Hvv_ae  - P(ij) X_mjab * Hov_mi + 0.5 * X_mnab * Hoooo_mnij + 0.5 * X_ijef * Hvvvv_abef \n        # + P(ij) P(ab) X_miea * Hovvo_mbej - 0.5 * P(ab) X_mnaf * Hoovv_mnef * t_ijeb\n        # - 0.5 * P(ij) X_inef * Hoovv_mnef * t_mjab    \n\n        # It should be noted that in order to avoid construction of 3-body Hbar terms appearing in X2 equations like,\n        # Hvvooov_bamjif = Hvovv_amef * t_ijeb, \n        # Hvvooov_banjie = Hooov_mnie * t_mjab,\n        # Hvoooov_bmnjif = Hoovv_mnef * t_ijeb, \n        # Hvvoovv_banjef = Hoovv_mnef * t_mjab,  \n        # we make use of Z intermediates: \n        # Zvv_ae = - Hooov_amef * X_mf - 0.5 * X_mnaf * Hoovv_mnef,  \n        # Zoo_mi = - X_ne * Hooov_mnie - 0.5 * Hoovv_mnef * X_inef,  \n        # And then contract Z with T2 amplitudes.\n           \n        # X1 equations \n        r_x1  = self.build_Avo().swapaxes(0,1).copy()\n        r_x1 -= self.omega * self.x1.copy()\n        r_x1 += ndot(\'ie,ae->ia\', self.x1, self.Hvv)\n        r_x1 -= ndot(\'mi,ma->ia\', self.Hoo, self.x1)\n        r_x1 += ndot(\'maei,me->ia\', self.Hovvo, self.x1, prefactor=2.0)\n        r_x1 += ndot(\'maie,me->ia\', self.Hovov, self.x1, prefactor=-1.0)\n        r_x1 += ndot(\'miea,me->ia\', self.x2, self.Hov, prefactor=2.0)\n        r_x1 += ndot(\'imea,me->ia\', self.x2, self.Hov, prefactor=-1.0)\n        r_x1 += ndot(\'imef,amef->ia\', self.x2, self.Hvovv, prefactor=2.0)\n        r_x1 += ndot(\'imef,amfe->ia\', self.x2, self.Hvovv, prefactor=-1.0)\n        r_x1 -= ndot(\'mnie,mnae->ia\', self.Hooov, self.x2, prefactor=2.0)\n        r_x1 -= ndot(\'nmie,mnae->ia\', self.Hooov, self.x2, prefactor=-1.0)\n        # X1 equations over!    \n\n        # X2 equations \n        # Final r_x2_ijab = r_x2_ijab + r_x2_jiba\n        r_x2 = self.build_Avvoo().swapaxes(0,2).swapaxes(1,3).copy()\n        # a factor of 0.5 because of the comment just above\n        # and due to the fact that X2_ijab = X2_jiba  \n        r_x2 -= 0.5 * self.omega * self.x2\n        r_x2 += ndot(\'ie,abej->ijab\', self.x1, self.Hvvvo)\n        r_x2 -= ndot(\'mbij,ma->ijab\', self.Hovoo, self.x1)\n        r_x2 += ndot(\'ijeb,ae->ijab\', self.x2, self.Hvv)\n        r_x2 -= ndot(\'mi,mjab->ijab\', self.Hoo, self.x2)\n        r_x2 += ndot(\'mnij,mnab->ijab\', self.Hoooo, self.x2, prefactor=0.5)\n        r_x2 += ndot(\'ijef,abef->ijab\', self.x2, self.Hvvvv, prefactor=0.5)\n        r_x2 += ndot(\'miea,mbej->ijab\', self.x2, self.Hovvo, prefactor=2.0)\n        r_x2 += ndot(\'miea,mbje->ijab\', self.x2, self.Hovov, prefactor=-1.0)\n        r_x2 -= ndot(\'imeb,maje->ijab\', self.x2, self.Hovov)\n        r_x2 -= ndot(\'imea,mbej->ijab\', self.x2, self.Hovvo)\n        r_x2 += ndot(\'mi,mjab->ijab\', self.build_Zoo(), self.t2)\n        r_x2 += ndot(\'ijeb,ae->ijab\', self.t2, self.build_Zvv())\n        # X2 equations over!    \n\n        old_x2 = self.x2.copy()\n        old_x1 = self.x1.copy()\n\n        # update X1 and X2\n        self.x1 += r_x1/self.Dia\n        # Final r_x2_ijab = r_x2_ijab + r_x2_jiba\n        tmp = r_x2/self.Dijab\n        self.x2 += tmp + tmp.swapaxes(0,1).swapaxes(2,3)\n\n        # Calcuate rms with the residual \n        rms = 0\n        rms += np.einsum(\'ia,ia->\', old_x1 - self.x1, old_x1 - self.x1)\n        rms += np.einsum(\'ijab,ijab->\', old_x2 - self.x2, old_x2 - self.x2)\n        return np.sqrt(rms)\n\n    def inhomogenous_y2(self):\n\n        # Inhomogenous terms appearing in Y2 equations\n        # <O|L1(0)|A_bar|phi^ab_ij>\n        r_y2  = ndot(\'ia,jb->ijab\', self.l1, self.build_Aov(), prefactor=2.0)\n        r_y2 -= ndot(\'ja,ib->ijab\', self.l1, self.build_Aov()) \n        # <O|L2(0)|A_bar|phi^ab_ij>\n        r_y2 += ndot(\'ijeb,ea->ijab\', self.l2, self.build_Avv())\n        r_y2 -= ndot(\'im,mjab->ijab\', self.build_Aoo(), self.l2)\n        # <O|L1(0)|[Hbar(0), X1]|phi^ab_ij>\n        tmp   = ndot(\'me,ja->meja\', self.x1, self.l1)\n        r_y2 -= ndot(\'mieb,meja->ijab\', self.Loovv, tmp)\n        tmp   = ndot(\'me,mb->eb\', self.x1, self.l1)\n        r_y2 -= ndot(\'ijae,eb->ijab\', self.Loovv, tmp)\n        tmp   = ndot(\'me,ie->mi\', self.x1, self.l1)\n        r_y2 -= ndot(\'mi,jmba->ijab\', tmp, self.Loovv)\n        tmp   = ndot(\'me,jb->mejb\', self.x1, self.l1, prefactor=2.0)\n        r_y2 += ndot(\'imae,mejb->ijab\', self.Loovv, tmp)\n        # <O|L2(0)|[Hbar(0), X1]|phi^ab_ij>\n        tmp   = ndot(\'me,ma->ea\', self.x1, self.Hov)\n        r_y2 -= ndot(\'ijeb,ea->ijab\', self.l2, tmp)\n        tmp   = ndot(\'me,ie->mi\', self.x1, self.Hov)\n        r_y2 -= ndot(\'mi,jmba->ijab\', tmp, self.l2)\n        tmp   = ndot(\'me,ijef->mijf\', self.x1, self.l2)\n        r_y2 -= ndot(\'mijf,fmba->ijab\', tmp, self.Hvovv)\n        tmp   = ndot(\'me,imbf->eibf\', self.x1, self.l2)\n        r_y2 -= ndot(\'eibf,fjea->ijab\', tmp, self.Hvovv)\n        tmp   = ndot(\'me,jmfa->ejfa\', self.x1, self.l2)\n        r_y2 -= ndot(\'fibe,ejfa->ijab\', self.Hvovv, tmp)\n        tmp   = ndot(\'me,fmae->fa\', self.x1, self.Hvovv, prefactor=2.0)\n        tmp  -= ndot(\'me,fmea->fa\', self.x1, self.Hvovv)\n        r_y2 += ndot(\'ijfb,fa->ijab\', self.l2, tmp)\n        tmp   = ndot(\'me,fiea->mfia\', self.x1, self.Hvovv, prefactor=2.0)\n        tmp  -= ndot(\'me,fiae->mfia\', self.x1, self.Hvovv)\n        r_y2 += ndot(\'mfia,jmbf->ijab\', tmp, self.l2)\n        tmp   = ndot(\'me,jmna->ejna\', self.x1, self.Hooov)\n        r_y2 += ndot(\'ineb,ejna->ijab\', self.l2, tmp)\n        tmp   = ndot(\'me,mjna->ejna\', self.x1, self.Hooov)\n        r_y2 += ndot(\'nieb,ejna->ijab\', self.l2, tmp)\n        tmp   = ndot(\'me,nmba->enba\', self.x1, self.l2)\n        r_y2 += ndot(\'jine,enba->ijab\', self.Hooov, tmp)\n        tmp   = ndot(\'me,mina->eina\', self.x1, self.Hooov, prefactor=2.0)\n        tmp  -= ndot(\'me,imna->eina\', self.x1, self.Hooov)\n        r_y2 -= ndot(\'eina,njeb->ijab\', tmp, self.l2)\n        tmp   = ndot(\'me,imne->in\', self.x1, self.Hooov, prefactor=2.0)\n        tmp  -= ndot(\'me,mine->in\', self.x1, self.Hooov)\n        r_y2 -= ndot(\'in,jnba->ijab\', tmp, self.l2)\n        # <O|L2(0)|[Hbar(0), X2]|phi^ab_ij>\n        tmp   = ndot(\'ijef,mnef->ijmn\', self.l2, self.x2, prefactor=0.5)        \n        r_y2 += ndot(\'ijmn,mnab->ijab\', tmp, self.get_MO(\'oovv\'))        \n        tmp   = ndot(\'ijfe,mnef->ijmn\', self.get_MO(\'oovv\'), self.x2, prefactor=0.5)        \n        r_y2 += ndot(\'ijmn,mnba->ijab\', tmp, self.l2)        \n        tmp   = ndot(\'mifb,mnef->ibne\', self.l2, self.x2)        \n        r_y2 += ndot(\'ibne,jnae->ijab\', tmp, self.get_MO(\'oovv\'))        \n        tmp   = ndot(\'imfb,mnef->ibne\', self.l2, self.x2)        \n        r_y2 += ndot(\'ibne,njae->ijab\', tmp, self.get_MO(\'oovv\'))        \n        tmp   = ndot(\'mjfb,mnef->jbne\', self.l2, self.x2)        \n        r_y2 -= ndot(\'jbne,inae->ijab\', tmp, self.Loovv)        \n        r_y2 -=  ndot(\'in,jnba->ijab\', self.build_Goo(self.Loovv, self.x2), self.l2) \n        r_y2 +=  ndot(\'ijfb,af->ijab\', self.l2, self.build_Gvv(self.Loovv, self.x2))\n        r_y2 +=  ndot(\'ijae,be->ijab\', self.Loovv, self.build_Gvv(self.l2, self.x2))\n        r_y2 -=  ndot(\'imab,jm->ijab\', self.Loovv, self.build_Goo(self.l2, self.x2))\n        tmp   = ndot(\'nifb,mnef->ibme\', self.l2, self.x2)\n        r_y2 -= ndot(\'ibme,mjea->ijab\', tmp, self.Loovv)\n        tmp   = ndot(\'njfb,mnef->jbme\', self.l2, self.x2, prefactor=2.0)\n        r_y2 += ndot(\'imae,jbme->ijab\', self.Loovv, tmp)\n\n        return r_y2\n\n\n    def inhomogenous_y1(self):\n        \n        # Inhomogenous terms appearing in Y1 equations\n        # <O|A_bar|phi^a_i>\n        r_y1 = 2.0 * self.build_Aov().copy()\n        # <O|L1(0)|A_bar|phi^a_i>\n        r_y1 -= ndot(\'im,ma->ia\', self.build_Aoo(), self.l1)\n        r_y1 += ndot(\'ie,ea->ia\', self.l1, self.build_Avv())\n        # <O|L2(0)|A_bar|phi^a_i>\n        r_y1 += ndot(\'imfe,feam->ia\', self.l2, self.build_Avvvo())\n        r_y1 -= ndot(\'ienm,mnea->ia\', self.build_Aovoo(), self.l2, prefactor=0.5)\n        r_y1 -= ndot(\'iemn,mnae->ia\', self.build_Aovoo(), self.l2, prefactor=0.5)\n        # <O|[Hbar(0), X1]|phi^a_i>\n        r_y1 +=  ndot(\'imae,me->ia\', self.Loovv, self.x1, prefactor=2.0)\n        # <O|L1(0)|[Hbar(0), X1]|phi^a_i>\n        tmp  = ndot(\'ma,ie->miae\', self.Hov, self.l1, prefactor=-1.0)\n        tmp -= ndot(\'ma,ie->miae\', self.l1, self.Hov)\n        tmp -= ndot(\'mina,ne->miae\', self.Hooov, self.l1, prefactor=2.0)\n        tmp -= ndot(\'imna,ne->miae\', self.Hooov, self.l1, prefactor=-1.0)\n        tmp -= ndot(\'imne,na->miae\', self.Hooov, self.l1, prefactor=2.0)\n        tmp -= ndot(\'mine,na->miae\', self.Hooov, self.l1, prefactor=-1.0)\n        tmp += ndot(\'fmae,if->miae\', self.Hvovv, self.l1, prefactor=2.0)\n        tmp += ndot(\'fmea,if->miae\', self.Hvovv, self.l1, prefactor=-1.0)\n        tmp += ndot(\'fiea,mf->miae\', self.Hvovv, self.l1, prefactor=2.0)\n        tmp += ndot(\'fiae,mf->miae\', self.Hvovv, self.l1, prefactor=-1.0)\n        r_y1 += ndot(\'miae,me->ia\', tmp, self.x1)    \n        # <O|L1(0)|[Hbar(0), X2]|phi^a_i>\n        tmp  = ndot(\'mnef,nf->me\', self.x2, self.l1, prefactor=2.0)\n        tmp  += ndot(\'mnfe,nf->me\', self.x2, self.l1, prefactor=-1.0)\n        r_y1 += ndot(\'imae,me->ia\', self.Loovv, tmp)\n        r_y1 -= ndot(\'ni,na->ia\', self.build_Goo(self.x2, self.Loovv), self.l1)\n        r_y1 += ndot(\'ie,ea->ia\', self.l1, self.build_Gvv(self.x2, self.Loovv))\n        # <O|L2(0)|[Hbar(0), X1]|phi^a_i>\n        tmp   = ndot(\'nief,mfna->iema\', self.l2, self.Hovov, prefactor=-1.0)\n        tmp  -= ndot(\'ifne,nmaf->iema\', self.Hovov, self.l2)\n        tmp  -= ndot(\'inef,mfan->iema\', self.l2, self.Hovvo)\n        tmp  -= ndot(\'ifen,nmfa->iema\', self.Hovvo, self.l2)\n        tmp  += ndot(\'imfg,fgae->iema\', self.l2, self.Hvvvv, prefactor=0.5)\n        tmp  += ndot(\'imgf,fgea->iema\', self.l2, self.Hvvvv, prefactor=0.5)\n        tmp  += ndot(\'imno,onea->iema\', self.Hoooo, self.l2, prefactor=0.5)\n        tmp  += ndot(\'mino,noea->iema\', self.Hoooo, self.l2, prefactor=0.5)\n        r_y1 += ndot(\'iema,me->ia\', tmp, self.x1) \n        tmp  =  ndot(\'nb,fb->nf\', self.x1, self.build_Gvv(self.t2, self.l2))\n        r_y1 += ndot(\'inaf,nf->ia\', self.Loovv, tmp) \n        tmp  =  ndot(\'me,fa->mefa\', self.x1, self.build_Gvv(self.t2, self.l2))\n        r_y1 += ndot(\'mief,mefa->ia\', self.Loovv, tmp)\n        tmp  =  ndot(\'me,ni->meni\', self.x1, self.build_Goo(self.t2, self.l2))\n        r_y1 -= ndot(\'meni,mnea->ia\', tmp, self.Loovv)\n        tmp  =  ndot(\'jf,nj->fn\', self.x1, self.build_Goo(self.t2, self.l2))\n        r_y1 -= ndot(\'inaf,fn->ia\', self.Loovv, tmp)\n        # <O|L2(0)|[Hbar(0), X2]|phi^a_i>\n        r_y1 -= ndot(\'mi,ma->ia\', self.build_Goo(self.x2, self.l2), self.Hov)  \n        r_y1 += ndot(\'ie,ea->ia\', self.Hov, self.build_Gvv(self.x2, self.l2)) \n        tmp   =  ndot(\'imfg,mnef->igne\',self.l2, self.x2)\n        r_y1 -=  ndot(\'igne,gnea->ia\', tmp, self.Hvovv)\n        tmp   =  ndot(\'mifg,mnef->igne\',self.l2, self.x2)\n        r_y1 -=  ndot(\'igne,gnae->ia\', tmp, self.Hvovv)\n        tmp   =  ndot(\'mnga,mnef->gaef\',self.l2, self.x2)\n        r_y1 -=  ndot(\'gief,gaef->ia\', self.Hvovv, tmp)\n        tmp   =  ndot(\'gmae,mnef->ganf\',self.Hvovv, self.x2, prefactor=2.0)\n        tmp  +=  ndot(\'gmea,mnef->ganf\',self.Hvovv, self.x2, prefactor=-1.0)\n        r_y1 +=  ndot(\'nifg,ganf->ia\', self.l2, tmp)\n        r_y1 -=  ndot(\'giea,ge->ia\', self.Hvovv, self.build_Gvv(self.l2, self.x2), prefactor=2.0) \n        r_y1 -=  ndot(\'giae,ge->ia\', self.Hvovv, self.build_Gvv(self.l2, self.x2), prefactor=-1.0)\n        tmp   = ndot(\'oief,mnef->oimn\', self.l2, self.x2) \n        r_y1 += ndot(\'oimn,mnoa->ia\', tmp, self.Hooov)\n        tmp   = ndot(\'mofa,mnef->oane\', self.l2, self.x2) \n        r_y1 += ndot(\'inoe,oane->ia\', self.Hooov, tmp)\n        tmp   = ndot(\'onea,mnef->oamf\', self.l2, self.x2) \n        r_y1 += ndot(\'miof,oamf->ia\', self.Hooov, tmp)\n        r_y1 -=  ndot(\'mioa,mo->ia\', self.Hooov, self.build_Goo(self.x2, self.l2), prefactor=2.0) \n        r_y1 -=  ndot(\'imoa,mo->ia\', self.Hooov, self.build_Goo(self.x2, self.l2), prefactor=-1.0) \n        tmp   = ndot(\'imoe,mnef->ionf\', self.Hooov, self.x2, prefactor=-2.0) \n        tmp  -= ndot(\'mioe,mnef->ionf\', self.Hooov, self.x2, prefactor=-1.0) \n        r_y1 += ndot(\'ionf,nofa->ia\', tmp, self.l2)\n        \n        return r_y1\n\n    def update_Y(self):\n\n        # Y1 and Y2 amplitudes are the Fourier analogues of first order perturbed L1 and L2 amplitudes, \n        # While X amplitudes are referred to as right hand perturbed amplitudes, Y amplitudes are the\n        # left hand perturbed amplitudes. Just like X1 and X2, they can be obtained by solving a linear \n        # sytem of equations. Refer to eq 73 of [Crawford:xxxx]. for Writing l_mu^(1)(omega) as Y_mu, \n        # Y1 equations:\n        # omega * Y_ia + Y_kc * <phi^c_k|Hbar(0)|phi^a_i>  + Y_klcd * <phi^cd_kl|Hbar(0)|phi^a_i> \n        # + <O|(1 + L(0))|Hbar_bar(1)(omega)|phi^a_i> = 0\n        # Y2 equations: \n        # omega * Y_ijab + Y_kc * <phi^c_k|Hbar(0)|phi^ab_ij>  + Y_klcd * <phi^cd_kl|Hbar(0)|phi^ab_ij> \n        # + <O|(1 + L(0))|Hbar_bar(1)(omega)|phi^ab_ij> = 0\n        # where Hbar_bar(1)(omega) = Hbar(1) + [Hbar(0), T(1)] = A_bar + [Hbar(0), X]\n        # Note that the homogenous terms of Y1 and Y2 equations except the omega term are exactly identical in \n        # structure to the L1 and L2 equations and just like lambdas, the equations for these Y amplitudes have \n        # been derived using the unitray group approach. Please refer to helper_cclambda file for a complete  \n        # decsription.\n\n        # Y1 equations\n        # Inhomogenous terms\n        r_y1 = self.im_y1.copy()\n        # Homogenous terms now!\n        r_y1 += self.omega * self.y1\n        r_y1 += ndot(\'ie,ea->ia\', self.y1, self.Hvv)\n        r_y1 -= ndot(\'im,ma->ia\', self.Hoo, self.y1)\n        r_y1 += ndot(\'ieam,me->ia\', self.Hovvo, self.y1, prefactor=2.0)\n        r_y1 += ndot(\'iema,me->ia\', self.Hovov, self.y1, prefactor=-1.0)\n        r_y1 += ndot(\'imef,efam->ia\', self.y2, self.Hvvvo)\n        r_y1 -= ndot(\'iemn,mnae->ia\', self.Hovoo, self.y2)\n        r_y1 -= ndot(\'eifa,ef->ia\', self.Hvovv, self.build_Gvv(self.y2, self.t2), prefactor=2.0)\n        r_y1 -= ndot(\'eiaf,ef->ia\', self.Hvovv, self.build_Gvv(self.y2, self.t2), prefactor=-1.0)\n        r_y1 -= ndot(\'mina,mn->ia\', self.Hooov, self.build_Goo(self.t2, self.y2), prefactor=2.0)\n        r_y1 -= ndot(\'imna,mn->ia\', self.Hooov, self.build_Goo(self.t2, self.y2), prefactor=-1.0)\n        # Y1 equations over!\n\n        # Y2 equations\n        # Final r_y2_ijab = r_y2_ijab + r_y2_jiba\n        # Inhomogenous terms\n        r_y2 = self.im_y2.copy()\n        # Homogenous terms now!\n        # a factor of 0.5 because of the relation/comment just above\n        # and due to the fact that Y2_ijab = Y2_jiba  \n        r_y2 += 0.5 * self.omega * self.y2.copy()\n        r_y2 += ndot(\'ia,jb->ijab\', self.y1, self.Hov, prefactor=2.0)\n        r_y2 -= ndot(\'ja,ib->ijab\', self.y1, self.Hov)\n        r_y2 += ndot(\'ijeb,ea->ijab\', self.y2, self.Hvv)\n        r_y2 -= ndot(\'im,mjab->ijab\', self.Hoo, self.y2)\n        r_y2 += ndot(\'ijmn,mnab->ijab\', self.Hoooo, self.y2, prefactor=0.5)\n        r_y2 += ndot(\'ijef,efab->ijab\', self.y2, self.Hvvvv, prefactor=0.5)\n        r_y2 += ndot(\'ie,ejab->ijab\', self.y1, self.Hvovv, prefactor=2.0)\n        r_y2 += ndot(\'ie,ejba->ijab\', self.y1, self.Hvovv, prefactor=-1.0)\n        r_y2 -= ndot(\'mb,jima->ijab\', self.y1, self.Hooov, prefactor=2.0)\n        r_y2 -= ndot(\'mb,ijma->ijab\', self.y1, self.Hooov, prefactor=-1.0)\n        r_y2 += ndot(\'ieam,mjeb->ijab\', self.Hovvo, self.y2, prefactor=2.0)\n        r_y2 += ndot(\'iema,mjeb->ijab\', self.Hovov, self.y2, prefactor=-1.0)\n        r_y2 -= ndot(\'mibe,jema->ijab\', self.y2, self.Hovov)\n        r_y2 -= ndot(\'mieb,jeam->ijab\', self.y2, self.Hovvo)\n        r_y2 += ndot(\'ijeb,ae->ijab\', self.Loovv, self.build_Gvv(self.y2, self.t2))\n        r_y2 -= ndot(\'mi,mjab->ijab\', self.build_Goo(self.t2, self.y2), self.Loovv)\n        # Y2 equations over!\n\n        old_y1 = self.y1.copy()\n        old_y2 = self.y2.copy()\n\n        # update Y1 and Y2\n        self.y1 += r_y1/self.Dia\n        # Final r_y2_ijab = r_y2_ijab + r_y2_jiba\n        tmp = r_y2/self.Dijab    \n        self.y2 += tmp + tmp.swapaxes(0,1).swapaxes(2,3) \n\n        # Calcuate rms from the residual \n        rms = np.einsum(\'ia,ia->\', r_y1/self.Dia, r_y1/self.Dia)\n        rms += np.einsum(\'ijab,ijab->\', old_y2 - self.y2, old_y2 - self.y2)\n        return np.sqrt(rms)\n\n    def pseudoresponse(self, hand):\n        polar1 = 0\n        polar2 = 0\n        if hand == \'right\':\n            z1 = self.x1 ; z2 = self.x2\n        else:\n            z1 = self.y1 ; z2 = self.y2\n\n        # To match the pseudoresponse values with PSI4\n        polar1 += ndot(\'ia,ai->\', z1, self.build_Avo(), prefactor=2.0)\n        tmp = self.pertbar_ijab + self.pertbar_ijab.swapaxes(0,1).swapaxes(2,3) \n        polar2 += ndot(\'ijab,ijab->\', z2, tmp, prefactor=2.0)\n        polar2 += ndot(\'ijba,ijab->\', z2, tmp, prefactor=-1.0)\n\n        return -2.0 * (polar1 + polar2)\n\n    def solve(self, hand, r_conv=1.e-7, maxiter=100, max_diis=8, start_diis=1):\n\n        ### Start of the solve routine \n        ccpert_tstart = time.time()\n        \n        # calculate the pseudoresponse from guess amplitudes\n        pseudoresponse_old = self.pseudoresponse(hand)\n        print(""CCPERT_%s Iteration %3d: pseudoresponse = %.15f   dE = % .5E "" % (self.name, 0, pseudoresponse_old, -pseudoresponse_old))\n\n        # Set up DIIS before iterations begin\n        if hand == \'right\':\n            diis_object = helper_diis(self.x1, self.x2, max_diis)\n        else:\n            diis_object = helper_diis(self.y1, self.y2, max_diis)\n            # calculate the inhomogenous terms of the left hand amplitudes equation before iterations begin\n            self.im_y1 = self.inhomogenous_y1()\n            self.im_y2 = self.inhomogenous_y2()\n\n        # Iterate!\n        for CCPERT_iter in range(1, maxiter + 1):\n\n            # Residual build and update\n            if hand == \'right\':\n                rms = self.update_X()\n            else:\n                rms = self.update_Y()\n\n            # pseudoresponse with updated amplitudes\n            pseudoresponse = self.pseudoresponse(hand)\n\n            # Print CCPERT iteration information\n            print(\'CCPERT_%s Iteration %3d: pseudoresponse = %.15f   dE = % .5E   DIIS = %d\' % (self.name, CCPERT_iter, pseudoresponse, (pseudoresponse - pseudoresponse_old), diis_object.diis_size))\n\n            # Check convergence\n            if (rms < r_conv):\n                print(\'\\nCCPERT_%s has converged in %.3f seconds!\' % (self.name, time.time() - ccpert_tstart))\n                return pseudoresponse\n\n            # Update old pseudoresponse\n            pseudoresponse_old = pseudoresponse\n\n            #  Add the new error vector\n            if hand == \'right\':\n                diis_object.add_error_vector(self.x1, self.x2)\n            else:\n                diis_object.add_error_vector(self.y1, self.y2)\n\n\n            if CCPERT_iter >= start_diis:\n                if hand == \'right\':    \n                    self.x1, self.x2 = diis_object.extrapolate(self.x1, self.x2)\n                else:    \n                    self.y1, self.y2 = diis_object.extrapolate(self.y1, self.y2)\n\n# End HelperCCPert class\n\nclass HelperCCLinresp(object):\n\n    def __init__(self, cclambda, ccpert_A, ccpert_B):\n\n        # start of the cclinresp class \n        time_init = time.time()\n        # Grab all the info from ccpert obejct, a and b here are the two \n        # perturbations Ex. for dipole polarizabilities, A = mu, B = mu (dipole operator) \n        self.ccpert_A = ccpert_A\n        self.ccpert_B = ccpert_B\n        self.pert_A = ccpert_A.pert\n        self.pert_B = ccpert_B.pert\n        self.l1 = cclambda.l1\n        self.l2 = cclambda.l2\n        # Grab X and Y amplitudes corresponding to perturbation A\n        self.x1_A = ccpert_A.x1\n        self.x2_A = ccpert_A.x2\n        self.y1_A = ccpert_A.y1\n        self.y2_A = ccpert_A.y2\n        # Grab X and Y amplitudes corresponding to perturbation B\n        self.x1_B = ccpert_B.x1\n        self.x2_B = ccpert_B.x2\n        self.y1_B = ccpert_B.y1\n        self.y2_B = ccpert_B.y2\n\n\n    def linresp(self):\n\n        # Please refer to equation 78 of [Crawford:xxxx]. \n        # Writing H(1)(omega) = B, T(1)(omega) = X, L(1)(omega) = Y\n        # <<A;B>> =  <0|Y(B) * A_bar|0> + <0|(1+L(0))[A_bar, X(B)]|0> \n        #                polar1                    polar2\n        self.polar1 = 0\n        self.polar2 = 0\n        # <0|Y1(B) * A_bar|0>\n        self.polar1 += ndot(""ai,ia->"", self.ccpert_A.build_Avo(), self.y1_B)\n        # <0|Y2(B) * A_bar|0>\n        self.polar1 += ndot(""abij,ijab->"", self.ccpert_A.build_Avvoo(), self.y2_B, prefactor=0.5)\n        self.polar1 += ndot(""baji,ijab->"", self.ccpert_A.build_Avvoo(), self.y2_B, prefactor=0.5)\n        # <0|[A_bar, X(B)]|0>\n        self.polar2 += ndot(""ia,ia->"", self.ccpert_A.build_Aov(), self.x1_B, prefactor=2.0)\n        # <0|L1(0)[A_bar, X1(B)]|0>\n        tmp = ndot(\'ia,ic->ac\', self.l1, self.x1_B)\n        self.polar2 += ndot(\'ac,ac->\', tmp, self.ccpert_A.build_Avv())\n        tmp = ndot(\'ia,ka->ik\', self.l1, self.x1_B)\n        self.polar2 -= ndot(\'ik,ki->\', tmp, self.ccpert_A.build_Aoo())\n        # <0|L1(0)[A_bar, X2(B)]|0>\n        tmp = ndot(\'ia,jb->ijab\', self.l1, self.ccpert_A.build_Aov())\n        self.polar2 += ndot(\'ijab,ijab->\', tmp, self.x2_B, prefactor=2.0)\n        self.polar2 += ndot(\'ijab,ijba->\', tmp, self.x2_B, prefactor=-1.0)\n        # <0|L2(0)[A_bar, X1(B)]|0>\n        tmp = ndot(\'ijbc,bcaj->ia\', self.l2, self.ccpert_A.build_Avvvo())\n        self.polar2 += ndot(\'ia,ia->\', tmp, self.x1_B)\n        tmp = ndot(\'ijab,kbij->ak\', self.l2, self.ccpert_A.build_Aovoo())\n        self.polar2 -= ndot(\'ak,ka->\', tmp, self.x1_B, prefactor=0.5)\n        tmp = ndot(\'ijab,kaji->bk\', self.l2, self.ccpert_A.build_Aovoo())\n        self.polar2 -= ndot(\'bk,kb->\', tmp, self.x1_B, prefactor=0.5)\n        # <0|L2(0)[A_bar, X1(B)]|0>\n        tmp = ndot(\'ijab,kjab->ik\', self.l2, self.x2_B)\n        self.polar2 -= ndot(\'ik,ki->\', tmp, self.ccpert_A.build_Aoo(), prefactor=0.5)\n        tmp = ndot(\'ijab,kiba->jk\', self.l2, self.x2_B,)\n        self.polar2 -= ndot(\'jk,kj->\', tmp, self.ccpert_A.build_Aoo(), prefactor=0.5)\n        tmp = ndot(\'ijab,ijac->bc\', self.l2, self.x2_B,)\n        self.polar2 += ndot(\'bc,bc->\', tmp, self.ccpert_A.build_Avv(), prefactor=0.5)\n        tmp = ndot(\'ijab,ijcb->ac\', self.l2, self.x2_B,)\n        self.polar2 += ndot(\'ac,ac->\', tmp, self.ccpert_A.build_Avv(), prefactor=0.5)\n\n        return -1.0*(self.polar1 + self.polar2)\n\n# End HelperCCLinresp class\n'"
Response-Theory/Coupled-Cluster/RHF/optrot.py,13,"b'# -*- coding: utf-8 -*-\n""""""\nA simple python script to calculate RHF-CCSD specific rotation in length, \nvelocity and modified velocity gauge using coupled cluster linear response theory.\n\nReferences: \n1. H. Koch and P. J\xc3\xb8rgensen, J. Chem. Phys. Volume 93, pp. 3333-3344 (1991).\n2. T. B. Pedersen and H. Koch, J. Chem. Phys. Volume 106, pp. 8059-8072 (1997).\n3. T. Daniel Crawford, Theor. Chem. Acc., Volume 115, pp. 227-245 (2006).\n4. T. B. Pedersen, H. Koch, L. Boman, and A. M. J. S\xc3\xa1nchez de Mer\xc3\xa1s, Chem. Phys. Lett.,\n   Volime 393, pp. 319, (2004).\n5. A Whirlwind Introduction to Coupled Cluster Response Theory, T.D. Crawford, Private Notes,\n   (pdf in the current directory).\n""""""\n\n__authors__ = ""Ashutosh Kumar""\n__credits__ = [\n    ""Ashutosh Kumar"", ""Daniel G. A. Smith"", ""Lori A. Burns"", ""T. D. Crawford""\n]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2018-02-20""\n\nimport os.path\nimport sys\ndirname = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(os.path.join(dirname, \'../../../Coupled-Cluster/RHF\'))\nimport numpy as np\nnp.set_printoptions(precision=15, linewidth=200, suppress=True)\nfrom helper_ccenergy import *\nfrom helper_cchbar import *\nfrom helper_cclambda import *\nfrom helper_ccpert import *\n\nimport psi4\nfrom psi4 import constants as pc\n\npsi4.set_memory(int(2e9), False)\npsi4.core.set_output_file(\'output.dat\', False)\n\n# can only handle C1 symmetry\nmol = psi4.geometry(""""""\n O     -0.028962160801    -0.694396279686    -0.049338350190                                                                  \n O      0.028962160801     0.694396279686    -0.049338350190                                                                  \n H      0.350498145881    -0.910645626300     0.783035421467                                                                  \n H     -0.350498145881     0.910645626300     0.783035421467                                                                  \nsymmetry c1        \n"""""")\n\n# setting up SCF options\npsi4.set_options({\n    \'basis\': \'sto-3g\',\n    \'scf_type\': \'PK\',\n    \'d_convergence\': 1e-10,\n    \'e_convergence\': 1e-10,\n})\nrhf_e, rhf_wfn = psi4.energy(\'SCF\', return_wfn=True)\nprint(\'RHF Final Energy                          % 16.10f\\n\' % rhf_e)\n\n# Calculate Ground State CCSD energy\nccsd = HelperCCEnergy(mol, rhf_e, rhf_wfn, memory=2)\nccsd.compute_energy(e_conv=1e-10, r_conv=1e-10)\n\nCCSDcorr_E = ccsd.ccsd_corr_e\nCCSD_E = ccsd.ccsd_e\n\nprint(\'\\nFinal CCSD correlation energy:          % 16.15f\' % CCSDcorr_E)\nprint(\'Total CCSD energy:                      % 16.15f\' % CCSD_E)\n\n# Now that we have T1 and T2 amplitudes, we can construct\n# the pieces of the similarity transformed hamiltonian (Hbar).\ncchbar = HelperCCHbar(ccsd)\n\n# Calculate Lambda amplitudes using Hbar\ncclambda = HelperCCLambda(ccsd, cchbar)\ncclambda.compute_lambda(r_conv=1e-10)\n\n# frequency of calculation\nomega_nm = 589\n\n# convert from nm into hartree\nomega = (pc.c * pc.h * 1e9) / (pc.hartree2J * omega_nm)\nOm = str(omega)\nOm_0 = str(0)\n\ncart = [\'X\', \'Y\', \'Z\']\npert = {}\nccpert = {}\ntensor = {}\ncclinresp = {}\noptrot_lg = np.zeros(9)\noptrot_vg_om = np.zeros(9)\noptrot_vg_0 = np.zeros(9)\n\n###############################################   Length Gauge   ###############################################################\n\n# In length gauge the representation of electric dipole operator is mu i.e. r. So, optical rotation tensor in this gauge\n# representation can be given by -Im <<mu;L>>, where L is the angular momemtum operator, refer to Eqn. 5 of [Crawford:2006:227].\n# For general form of a response function, refer to Eqn. 94 of [Koch:1991:3333].\n\nprint(""\\n\\n Length Gauge Calculations Starting ..\\n\\n"")\n\n# Obtain the required AO Perturabtion Matrices From Mints\n\n# Electric Dipole\ndipole_array = ccsd.mints.ao_dipole()\n\n# Angular Momentum\nangmom_array = ccsd.mints.ao_angular_momentum()\n\nfor i in range(0, 3):\n    Mu = ""MU_"" + cart[i]\n    L = ""L_"" + cart[i]\n\n    # Transform perturbations from AO to MO basis\n    pert[Mu] = np.einsum(\'uj,vi,uv\', ccsd.npC, ccsd.npC,\n                         np.asarray(dipole_array[i]))\n    pert[L] = -0.5 * np.einsum(\'uj,vi,uv\', ccsd.npC, ccsd.npC,\n                               np.asarray(angmom_array[i]))\n\n    # Initializing the perturbation class corresponding to each perturabtion at the given omega\n    ccpert[Mu + Om] = HelperCCPert(Mu, pert[Mu], ccsd, cchbar, cclambda, omega)\n    ccpert[L + Om] = HelperCCPert(L, pert[L], ccsd, cchbar, cclambda, omega)\n\n    # Solve X and Y amplitudes corresponding to each perturabtion at the given omega\n    print(\n        \'\\nsolving right hand perturbed amplitudes for %s @ omega = %s a.u.\\n\'\n        % (Mu, Om))\n    ccpert[Mu + Om].solve(\'right\', r_conv=1e-10)\n\n    print(\n        \'\\nsolving left hand perturbed amplitudes for %s @ omega = %s a.u.\\n\' %\n        (Mu, Om))\n    ccpert[Mu + Om].solve(\'left\', r_conv=1e-10)\n\n    print(\n        \'\\nsolving right hand perturbed amplitudes for %s @ omega = %s a.u.\\n\'\n        % (L, Om))\n    ccpert[L + Om].solve(\'right\', r_conv=1e-10)\n\n    print(\n        \'\\nsolving left hand perturbed amplitudes for %s @ omega = %s a.u.\\n\' %\n        (L, Om))\n    ccpert[L + Om].solve(\'left\', r_conv=1e-10)\n\nfor A in range(0, 3):\n    str_A = ""MU_"" + cart[A]\n    for B in range(0, 3):\n        str_B = ""L_"" + cart[B]\n        str_AB = ""<<"" + str_A + "";"" + str_B + "">>""\n        str_BA = ""<<"" + str_B + "";"" + str_A + "">>""\n\n        # constructing the linear response functions <<MU;L>> and <<L;MU>> @ given omega\n        # The optical rotation tensor beta can be written in length gauge as:\n        # beta_pq = 0.5 * (<<MU_p;L_q>>  - <<L_q;MU_p>), Please refer to eq. 49 of \n        # [Pedersen:1997:8059].\n\n        cclinresp[str_AB] = HelperCCLinresp(cclambda, ccpert[str_A + Om],\n                                            ccpert[str_B + Om])\n        cclinresp[str_BA] = HelperCCLinresp(cclambda, ccpert[str_B + Om],\n                                            ccpert[str_A + Om])\n\n        tensor[str_AB] = cclinresp[str_AB].linresp()\n        tensor[str_BA] = cclinresp[str_BA].linresp()\n\n        optrot_lg[3 * A + B] = 0.5 * (tensor[str_AB] - tensor[str_BA])\n\n# Isotropic optical rotation in length gauge @ given omega\nrlg_au = optrot_lg[0] + optrot_lg[4] + optrot_lg[8]\nrlg_au /= 3\n\nprint(\'\\n CCSD Optical Rotation Tensor (Length Gauge) @ %d nm\' % omega_nm)\nprint(""\\t\\t%s\\t             %s\\t                  %s\\n"" % (cart[0], cart[1],\n                                                           cart[2]))\n\nfor a in range(0, 3):\n    print("" %s %20.10lf %20.10lf %20.10lf\\n"" %\n          (cart[a], optrot_lg[3 * a + 0], optrot_lg[3 * a + 1],\n           optrot_lg[3 * a + 2]))\n\n# convert from a.u. into deg/[dm (g/cm^3)]\n# refer to eq. 4 of [Crawford:1996:189].\nMass = 0\nfor atom in range(mol.natom()):\n    Mass += mol.mass(atom)\nm2a = pc.bohr2angstroms * 1e-10\nhbar = pc.h / (2.0 * np.pi)\nprefactor = 1e-2 * hbar / (pc.c * 2.0 * np.pi * pc.me * (m2a**2))\nprefactor *= prefactor\nprefactor *= 288e-30 * (np.pi**2) * pc.na * (pc.bohr2angstroms**4)\nprefactor *= -1\nspecific_rotation_lg = prefactor * rlg_au * omega / Mass\nprint(""Specific rotation @ %d nm (Length Gauge): %10.5lf deg/[dm (g/cm^3)]"" %\n      (omega_nm, specific_rotation_lg))\n\n###############################################     Velocity Gauge      #########################################################\n\n# In length gauge the representation of electric dipole operator is in terms of p, i,e. the momentum operator.\n# So, optical rotation tensor in this gauge representation can be given by -Im <<P;L>>.\n\nprint(""\\n\\n Velocity Gauge Calculations Starting ..\\n\\n"")\n\n# Grabbing the momentum integrals from mints\nnabla_array = ccsd.mints.ao_nabla()\n\nfor i in range(0, 3):\n    P = ""P_"" + cart[i]\n\n    # Transform momentum from AO to MO basis\n    pert[P] = np.einsum(\'uj,vi,uv\', ccsd.npC, ccsd.npC,\n                        np.asarray(nabla_array[i]))\n\n    # Initializing the perturbation class\n    ccpert[P + Om] = HelperCCPert(P, pert[P], ccsd, cchbar, cclambda, omega)\n\n    # Solve X and Y amplitudes corresponding to the perturabtion at the given omega\n    print(\n        \'\\nsolving right hand perturbed amplitudes for %s @ omega = %s a.u.\\n\'\n        % (P, Om))\n    ccpert[P + Om].solve(\'right\', r_conv=1e-10)\n\n    print(\n        \'\\nsolving left hand perturbed amplitudes for %s @ omega = %s a.u.\\n\' %\n        (P, Om))\n    ccpert[P + Om].solve(\'left\', r_conv=1e-10)\n\nfor A in range(0, 3):\n    str_A = ""P_"" + cart[A]\n    for B in range(0, 3):\n        str_B = ""L_"" + cart[B]\n        str_AB = ""<<"" + str_A + "";"" + str_B + "">>""\n        str_BA = ""<<"" + str_B + "";"" + str_A + "">>""\n\n        # constructing the linear response functions <<P;L>> and <<L;P>> @ given omega\n        # The optical rotation tensor beta can be written in velocity gauge as:\n        # beta_pq = 0.5 * (<<MU_p;L_q>> + <<L_q;MU_p>), Please refer to eq. 49 of \n        # [Pedersen:1991:8059].\n\n        cclinresp[str_AB] = HelperCCLinresp(cclambda, ccpert[str_A + Om],\n                                            ccpert[str_B + Om])\n        cclinresp[str_BA] = HelperCCLinresp(cclambda, ccpert[str_B + Om],\n                                            ccpert[str_A + Om])\n        tensor[str_AB] = cclinresp[str_AB].linresp()\n        tensor[str_BA] = cclinresp[str_BA].linresp()\n        optrot_vg_om[3 * A + B] = 0.5 * (tensor[str_AB] + tensor[str_BA])\n\n# Isotropic optical rotation in velocity gauge @ given omega\nrvg_om_au = optrot_vg_om[0] + optrot_vg_om[4] + optrot_vg_om[8]\nrvg_om_au /= 3\n\nprint(\'\\n CCSD Optical Rotation Tensor (Velocity Gauge) @ %d nm\' % omega_nm)\nprint(""\\t\\t%s\\t             %s\\t                  %s\\n"" % (cart[0], cart[1],\n                                                           cart[2]))\n\nfor a in range(0, 3):\n    print("" %s %20.10lf %20.10lf %20.10lf\\n"" %\n          (cart[a], optrot_vg_om[3 * a + 0], optrot_vg_om[3 * a + 1],\n           optrot_vg_om[3 * a + 2]))\n\nspecific_rotation_vg_om = prefactor * rvg_om_au / Mass\nprint(""Specific rotation @ %d nm (Velocity Gauge): %10.5lf deg/[dm (g/cm^3)]"" %\n      (omega_nm, specific_rotation_vg_om))\n\n###############################################   Modified Velocity Gauge   ######################################################\n#\n# Velocity gauge (VG) representation gives a non-zero optical rotation at zero frequency,\n# which is clearly an unphysical result. [Pedersen:319:2004] proposed the modified\n# velocity gauge (MVG) representation where the VG optical rotation at # zero frequency is subtracted from VG results at a given frequency.\n\nprint(""\\n\\nModified Velocity Gauge Calculations Starting ..\\n\\n"")\n\nOm_0 = str(0)\nfor i in range(0, 3):\n    L = ""L_"" + cart[i]\n    P = ""P_"" + cart[i]\n    Om_0 = str(0)\n\n    # Initializing perturbation classes at zero frequency\n    ccpert[L + Om_0] = HelperCCPert(L, pert[L], ccsd, cchbar, cclambda, 0)\n    ccpert[P + Om_0] = HelperCCPert(P, pert[P], ccsd, cchbar, cclambda, 0)\n\n    # Solving X and Y amplitudes of the perturbation classes at zero frequency\n\n    print(\n        \'\\nsolving right hand perturbed amplitudes for %s @ omega = %s (a.u.)\\n\'\n        % (L, Om_0))\n    ccpert[L + Om_0].solve(\'right\', r_conv=1e-10)\n\n    print(\n        \'\\nsolving left hand perturbed amplitudes for %s @ omega = %s (a.u.)\\n\'\n        % (L, Om_0))\n    ccpert[L + Om_0].solve(\'left\', r_conv=1e-10)\n\n    print(\n        \'\\nsolving right hand perturbed amplitudes for %s @ omega = %s (a.u.)\\n\'\n        % (P, Om_0))\n    ccpert[P + Om_0].solve(\'right\', r_conv=1e-10)\n\n    print(\n        \'\\nsolving left hand perturbed amplitudes for %s @ omega = %s (a.u.)\\n\'\n        % (P, Om_0))\n    ccpert[P + Om_0].solve(\'left\', r_conv=1e-10)\n\nfor A in range(0, 3):\n    str_A = ""P_"" + cart[A]\n    for B in range(0, 3):\n        str_B = ""L_"" + cart[B]\n        str_AB = ""<<"" + str_A + "";"" + str_B + "">>""\n        str_BA = ""<<"" + str_B + "";"" + str_A + "">>""\n\n        # constructing the linear response functions <<P;L>> and <<L;P>> @ zero frequency)\n\n        cclinresp[str_AB] = HelperCCLinresp(cclambda, ccpert[str_A + Om_0],\n                                            ccpert[str_B + Om_0])\n        cclinresp[str_BA] = HelperCCLinresp(cclambda, ccpert[str_B + Om_0],\n                                            ccpert[str_A + Om_0])\n\n        tensor[str_AB] = cclinresp[str_AB].linresp()\n        tensor[str_BA] = cclinresp[str_BA].linresp()\n\n        optrot_vg_0[3 * A + B] = 0.5 * (tensor[str_AB] + tensor[str_BA])\n\n#  MVG(omega) = VG(omega) - VG(0)\noptrot_mvg = optrot_vg_om - optrot_vg_0\n\n# Isotropic optical rotation in modified velocity gauge @ given omega\nrmvg_au = optrot_mvg[0] + optrot_mvg[4] + optrot_mvg[8]\nrmvg_au /= 3\n\nprint(\'\\n CCSD Optical Rotation Tensor (Modified Velocity Gauge) @ %d nm\' %\n      omega_nm)\nprint(""\\t\\t%s\\t             %s\\t                  %s\\n"" % (cart[0], cart[1],\n                                                           cart[2]))\nfor a in range(0, 3):\n    print("" %s %20.10lf %20.10lf %20.10lf\\n"" %\n          (cart[a], optrot_vg_0[3 * a + 0], optrot_vg_0[3 * a + 1],\n           optrot_vg_0[3 * a + 2]))\n\nspecific_rotation_mvg = prefactor * rmvg_au / Mass\nprint(\n    ""Specific rotation @ %d nm (Modified Velocity Gauge): %10.5lf deg/[dm (g/cm^3)]""\n    % (omega_nm, specific_rotation_mvg))\n\n""""""#  Comaprison with PSI4 (if you have near to latest version of psi4)\npsi4.set_options({\'d_convergence\': 1e-10,\n                  \'e_convergence\': 1e-10,\n                  \'r_convergence\': 1e-10,\n                  \'omega\': [589, \'nm\'],  \n                  \'gauge\': \'both\'})  \npsi4.properties(\'ccsd\', properties=[\'rotation\'])\npsi4.compare_values(specific_rotation_lg, psi4.variable(""CCSD SPECIFIC ROTATION (LEN) @ 589NM""), \\\n 5, ""CCSD SPECIFIC ROTATION (LENGTH GAUGE) 589 nm"") #TEST\npsi4.compare_values(specific_rotation_mvg, psi4.variable(""CCSD SPECIFIC ROTATION (MVG) @ 589NM""), \\\n  5, ""CCSD SPECIFIC ROTATION (MODIFIED VELOCITY GAUGE) 589 nm"") #TEST\n""""""\n\npsi4.compare_values(specific_rotation_lg, 7.03123, 5,\n                    ""CCSD SPECIFIC ROTATION (LENGTH GAUGE) 589 nm"")  #TEST\npsi4.compare_values(\n    specific_rotation_mvg, -81.44742, 5,\n    ""CCSD SPECIFIC ROTATION (MODIFIED VELOCITY GAUGE) 589 nm"")  #TEST\n'"
Response-Theory/Coupled-Cluster/RHF/polar.py,3,"b'# -*- coding: utf-8 -*-\n""""""\nA simple python script to calculate RHF-CCSD electric dipole polarizabilities in length\ngauge using coupled cluster linear response theory.\n\nReferences: \n- Equations and algorithms from [Koch:1991:3333] and [Crawford:xxxx]\n""""""\n\n__authors__ = ""Ashutosh Kumar""\n__credits__ = [\n    ""Ashutosh Kumar"", ""Daniel G. A. Smith"", ""Lori A. Burns"", ""T. D. Crawford""\n]\n\n__copyright__ = ""(c) 2014-2018, The Psi4NumPy Developers""\n__license__ = ""BSD-3-Clause""\n__date__ = ""2018-02-20""\n\nimport os.path\nimport sys\ndirname = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(os.path.join(dirname, \'../../../Coupled-Cluster/RHF\'))\nimport numpy as np\nnp.set_printoptions(precision=15, linewidth=200, suppress=True)\n# Import all the coupled cluster utilities\nfrom helper_ccenergy import *\nfrom helper_cchbar import *\nfrom helper_cclambda import *\nfrom helper_ccpert import *\n\nimport psi4\nfrom psi4 import constants as pc\n\npsi4.set_memory(int(2e9), False)\npsi4.core.set_output_file(\'output.dat\', False)\n\n# can only handle C1 symmetry\nmol = psi4.geometry(""""""\nO\nH 1 1.1\nH 1 1.1 2 104\nsymmetry c1  \n"""""")\n\n# setting up SCF options\npsi4.set_options({\n    \'basis\': \'sto-3g\',\n    \'scf_type\': \'PK\',\n    \'d_convergence\': 1e-10,\n    \'e_convergence\': 1e-10,\n})\nrhf_e, rhf_wfn = psi4.energy(\'SCF\', return_wfn=True)\n\nprint(\'RHF Final Energy                          % 16.10f\\n\' % rhf_e)\n\n# Calculate Ground State CCSD energy\nccsd = HelperCCEnergy(mol, rhf_e, rhf_wfn, memory=2)\nccsd.compute_energy(e_conv=1e-10, r_conv=1e-10)\n\nCCSDcorr_E = ccsd.ccsd_corr_e\nCCSD_E = ccsd.ccsd_e\n\nprint(\'\\nFinal CCSD correlation energy:          % 16.15f\' % CCSDcorr_E)\nprint(\'Total CCSD energy:                      % 16.15f\' % CCSD_E)\n\n# Now that we have T1 and T2 amplitudes, we can construct\n# the pieces of the similarity transformed hamiltonian (Hbar).\ncchbar = HelperCCHbar(ccsd)\n\n# Calculate Lambda amplitudes using Hbar\ncclambda = HelperCCLambda(ccsd, cchbar)\ncclambda.compute_lambda(r_conv=1e-10)\n\n# frequency of calculation\nomega_nm = 589\n# conver from nm into hartree\nomega_nm = 589\nomega = (pc.c * pc.h * 1e9) / (pc.hartree2J * omega_nm)\n\ncart = [\'X\', \'Y\', \'Z\']\nMu = {}\nccpert = {}\npolar_AB = {}\n\n# Obtain AO Dipole Matrices From Mints\ndipole_array = ccsd.mints.ao_dipole()\n\nfor i in range(0, 3):\n    string = ""MU_"" + cart[i]\n\n    # Transform dipole integrals from AO to MO basis\n    Mu[string] = np.einsum(\'uj,vi,uv\', ccsd.npC, ccsd.npC,\n                           np.asarray(dipole_array[i]))\n\n    # Initializing the perturbation classs corresponding to dipole perturabtion at the given omega\n    ccpert[string] = HelperCCPert(string, Mu[string], ccsd, cchbar, cclambda,\n                                  omega)\n\n    # Solve X and Y amplitudes corresponding to dipole perturabtion at the given omega\n    print(\'\\nsolving right hand perturbed amplitudes for %s\\n\' % string)\n    ccpert[string].solve(\'right\', r_conv=1e-10)\n\n    print(\'\\nsolving left hand perturbed amplitudes for %s\\n\' % string)\n    ccpert[string].solve(\'left\', r_conv=1e-10)\n\n# Please refer to eq. 94 of [Koch:1991:3333] for the general form of linear response functions.\n# For electric dipole polarizabilities, A = mu[x/y/z] and B = mu[x/y/z],\n# Ex. alpha_xy = <<mu_x;mu_y>>, where mu_x = x and mu_y = y\n\nprint(""\\nComputing <<Mu;Mu> tensor @ %d nm"" % omega_nm)\n\nfor a in range(0, 3):\n    str_a = ""MU_"" + cart[a]\n    for b in range(0, 3):\n        str_b = ""MU_"" + cart[b]\n        # Computing the alpha tensor\n        polar_AB[3 * a + b] = HelperCCLinresp(cclambda, ccpert[str_a],\n                                              ccpert[str_b]).linresp()\n\n# Symmetrizing the tensor\nfor a in range(0, 3):\n    for b in range(0, a + 1):\n        ab = 3 * a + b\n        ba = 3 * b + a\n        if a != b:\n            polar_AB[ab] = 0.5 * (polar_AB[ab] + polar_AB[ba])\n            polar_AB[ba] = polar_AB[ab]\n\nprint(\n    \'\\nCCSD Dipole Polarizability Tensor (Length Gauge) at omega = %8.6lf au, %d nm\\n\'\n    % (omega, omega_nm))\nprint(""\\t\\t%s\\t             %s\\t                  %s\\n"" % (cart[0], cart[1],\n                                                           cart[2]))\n\nfor a in range(0, 3):\n    print("" %s %20.10lf %20.10lf %20.10lf\\n"" %\n          (cart[a], polar_AB[3 * a + 0], polar_AB[3 * a + 1],\n           polar_AB[3 * a + 2]))\n\n# Isotropic polarizability\ntrace = polar_AB[0] + polar_AB[4] + polar_AB[8]\nIsotropic_polar = trace / 3.0\n\nprint(\n    "" Isotropic CCSD Dipole Polarizability @ %d nm (Length Gauge): %20.10lf a.u.""\n    % (omega_nm, Isotropic_polar))\n\n""""""# Comaprison with PSI4 (if you have near to latest version of psi4)\npsi4.set_options({\'d_convergence\': 1e-10})\npsi4.set_options({\'e_convergence\': 1e-10})\npsi4.set_options({\'r_convergence\': 1e-10})\npsi4.set_options({\'omega\': [589, \'nm\']})\npsi4.properties(\'ccsd\', properties=[\'polarizability\'])\npsi4.compare_values(Isotropic_polar, psi4.variable(""CCSD DIPOLE POLARIZABILITY @ 589NM""),  6, ""CCSD Isotropic Dipole Polarizability @ 589 nm (Length Gauge)"") #TEST\n""""""\n\npsi4.compare_values(\n    Isotropic_polar, 3.359649777784, 6,\n    ""CCSD Isotropic Dipole Polarizability @ 589 nm (Length Gauge)"")  #TEST\n'"
Tutorials/13_Geometry_Optimization/opt_helper/__init__.py,0,b''
Tutorials/13_Geometry_Optimization/opt_helper/bend.py,10,"b'from math import sqrt, cos\n\nimport numpy as np\n\nfrom . import covRadii\nfrom . import optExceptions\nfrom . import v3d\nfrom .misc import delta, HguessLindhRho\nfrom .simple import *\n\nfrom psi4 import constants\nBOHR2ANGSTROMS = constants.bohr2angstroms\nHARTREE2AJ = constants.hartree2aJ\n\nclass BEND(SIMPLE):\n    def __init__(self, a, b, c, frozen=False, fixedEqVal=None, bendType=""REGULAR""):\n\n        if a < c: atoms = (a, b, c)\n        else: atoms = (c, b, a)\n\n        self.bendType = bendType\n        self._axes_fixed = False\n        self._x = np.zeros(3, float)\n        self._w = np.zeros(3, float)\n\n        SIMPLE.__init__(self, atoms, frozen, fixedEqVal)\n\n    def __str__(self):\n        if self.frozen: s = \'*\'\n        else: s = \' \'\n\n        if self.bendType == ""REGULAR"":\n            s += ""B""\n        elif self.bendType == ""LINEAR"":\n            s += ""L""\n        elif self.bendType == ""COMPLEMENT"":\n            s += ""l""\n\n        s += ""(%d,%d,%d)"" % (self.A + 1, self.B + 1, self.C + 1)\n        if self.fixedEqVal:\n            s += ""[%.1f]"" % (self.fixedEqVal * self.qShowFactor)\n        return s\n\n    def __eq__(self, other):\n        if self.atoms != other.atoms: return False\n        elif not isinstance(other, BEND): return False\n        elif self.bendType != other.bendType: return False\n        else: return True\n\n    @property\n    def bendType(self):\n        return self._bendType\n\n    @bendType.setter\n    def bendType(self, intype):\n        if intype in ""REGULAR"" ""LINEAR"" ""COMPLEMENT"":\n            self._bendType = intype\n        else:\n            raise optExceptions.OPT_FAIL(\n                ""BEND.bendType must be REGULAR, LINEAR, or COMPLEMENT"")\n\n    def compute_axes(self, geom):\n        check, u = v3d.eAB(geom[self.B], geom[self.A])  # B->A\n        check, v = v3d.eAB(geom[self.B], geom[self.C])  # B->C\n\n        if self._bendType == ""REGULAR"":  # not a linear-bend type\n            self._w[:] = v3d.cross(u, v)  # orthogonal vector\n            v3d.normalize(self._w)\n            self._x[:] = u + v  # angle bisector\n            v3d.normalize(self._x)\n            return\n\n        tv1 = np.array([1, 0, 0], float)  # hope not to create 2 bends that both break\n        tv2 = np.array([0, 1, 1], float)  # a symmetry plane, so 2nd is off-axis\n        v3d.normalize(tv2)\n\n        # handle both types of linear bends\n        if not v3d.are_parallel_or_antiparallel(u, v):\n            self._w[:] = v3d.cross(u, v)  # orthogonal vector\n            v3d.normalize(self._w)\n            self._x[:] = u + v  # angle bisector\n            v3d.normalize(self._x)\n\n        # u || v but not || to tv1.\n        elif not v3d.are_parallel_or_antiparallel(u,tv1)  \\\n         and not v3d.are_parallel_or_antiparallel(v,tv1):\n            self._w[:] = v3d.cross(u, tv1)\n            v3d.normalize(self._w)\n            self._x[:] = v3d.cross(self._w, u)\n            v3d.normalize(self._x)\n\n        # u || v but not || to tv2.\n        elif not v3d.are_parallel_or_antiparallel(u,tv2) \\\n         and not v3d.are_parallel_or_antiparallel(v,tv2):\n            self._w[:] = v3d.cross(u, tv2)\n            v3d.normalize(self._w)\n            self._x[:] = v3d.cross(self._w, u)\n            v3d.normalize(self._x)\n\n        if self._bendType == ""COMPLEMENT"":\n            w2 = np.copy(self._w)  # x_normal -> w_complement\n            self._w[:] = -1.0 * self._x  # -w_normal -> x_complement\n            self._x[:] = w2\n            del w2\n\n        return\n\n    def q(self, geom):\n        #check, phi = v3d.angle(geom[self.A], geom[self.B], geom[self.C])\n        #print(\'Traditional Angle = %15.10f\\n\', phi)\n\n        if not self._axes_fixed:\n            self.compute_axes(geom)\n\n        check, u = v3d.eAB(geom[self.B], geom[self.A])  # B->A\n        check, v = v3d.eAB(geom[self.B], geom[self.C])  # B->C\n\n        # linear bend is sum of 2 angles, u.x + v.x\n        origin = np.zeros(3, float)\n        check, phi = v3d.angle(u, origin, self._x)\n        if not check:\n            raise optExceptions.ALG_FAIL(""BEND.q could not compute linear bend"")\n\n        check, phi2 = v3d.angle(self._x, origin, v)\n        if not check:\n            raise optExceptios.ALG_FAIL(""BEND.q could not compute linear bend"")\n        phi += phi2\n        return phi\n\n    @property\n    def qShowFactor(self):\n        return 180.0 / np.pi\n\n    def qShow(self, geom):  # return in degrees\n        return self.q(geom) * self.qShowFactor\n\n    @property\n    def fShowFactor(self):\n        return HARTREE2AJ * np.pi / 180.0\n\n    @staticmethod\n    def zeta(a, m, n):\n        if a == m: return 1\n        elif a == n: return -1\n        else: return 0\n\n    def fixBendAxes(self, geom):\n        if self.bendType == \'LINEAR\' or self.bendType == \'COMPLEMENT\':\n            self.compute_axes(geom)\n            self._axes_fixed = True\n\n    def unfixBendAxes(self):\n        self._axes_fixed = False\n\n    def DqDx(self, geom, dqdx):\n        if not self._axes_fixed:\n            self.compute_axes(geom)\n\n        u = geom[self.A] - geom[self.B]  # B->A\n        v = geom[self.C] - geom[self.B]  # B->C\n        Lu = v3d.norm(u)  # RBA\n        Lv = v3d.norm(v)  # RBC\n        u[:] *= 1.0 / Lu  # u = eBA\n        v[:] *= 1.0 / Lv  # v = eBC\n\n        uXw = v3d.cross(u, self._w)\n        wXv = v3d.cross(self._w, v)\n\n        # B = overall index of atom; a = 0,1,2 relative index for delta\'s\n        for a, B in enumerate(self.atoms):\n            dqdx[3*B : 3*B+3] = BEND.zeta(a,0,1) * uXw[0:3]/Lu + \\\n                                BEND.zeta(a,2,1) * wXv[0:3]/Lv\n        return\n\n    # Return derivative B matrix elements.  Matrix is cart X cart and passed in.\n    def Dq2Dx2(self, geom, dq2dx2):\n\n        if not self._axes_fixed:\n            self.compute_axes(geom)\n\n        u = geom[self.A] - geom[self.B]  # B->A\n        v = geom[self.C] - geom[self.B]  # B->C\n        Lu = v3d.norm(u)  # RBA\n        Lv = v3d.norm(v)  # RBC\n        u *= 1.0 / Lu  # eBA\n        v *= 1.0 / Lv  # eBC\n\n        uXw = v3d.cross(u, self._w)\n        wXv = v3d.cross(self._w, v)\n\n        # packed, or mini dqdx where columns run only over 3 atoms\n        dqdx = np.zeros(9, float)\n        for a in range(3):\n            dqdx[3*a : 3*a+3] = BEND.zeta(a,0,1) * uXw[0:3]/Lu + \\\n                                BEND.zeta(a,2,1) * wXv[0:3]/Lv\n\n        val = self.q(geom)\n        cos_q = cos(val)  # cos_q = v3d_dot(u,v);\n\n        if 1.0 - cos_q * cos_q <= 1.0e-12:  # leave 2nd derivatives empty - sin 0 = 0 in denominator\n            return\n        sin_q = sqrt(1.0 - cos_q * cos_q)\n\n        for a in range(3):\n            for i in range(3):  #i = a_xyz\n                for b in range(3):\n                    for j in range(3):  #j=b_xyz\n                        tval =  BEND.zeta(a,0,1) * BEND.zeta(b,0,1) * \\\n                          (u[i]*v[j]+u[j]*v[i]-3*u[i]*u[j]*cos_q+delta(i,j)*cos_q) / (Lu*Lu*sin_q)\n\n                        tval += BEND.zeta(a,2,1) * BEND.zeta(b,2,1) * \\\n                          (v[i]*u[j]+v[j]*u[i]-3*v[i]*v[j]*cos_q+delta(i,j)*cos_q) / (Lv*Lv*sin_q)\n\n                        tval += BEND.zeta(a,0,1) * BEND.zeta(b,2,1) * \\\n                          (u[i]*u[j]+v[j]*v[i]-u[i]*v[j]*cos_q-delta(i,j)) / (Lu*Lv*sin_q)\n\n                        tval += BEND.zeta(a,2,1) * BEND.zeta(b,0,1) * \\\n                          (v[i]*v[j]+u[j]*u[i]-v[i]*u[j]*cos_q-delta(i,j)) / (Lu*Lv*sin_q)\n\n                        tval -= cos_q / sin_q * dqdx[3 * a + i] * dqdx[3 * b + j]\n\n                        dq2dx2[3 * self.atoms[a] + i, 3 * self.atoms[b] + j] = tval\n\n        return\n\n    def diagonalHessianGuess(self, geom, Z, connectivity=False, guessType=""SIMPLE""):\n        """""" Generates diagonal empirical Hessians in a.u. such as \n          Schlegel, Theor. Chim. Acta, 66, 333 (1984) and\n          Fischer and Almlof, J. Phys. Chem., 96, 9770 (1992).\n        """"""\n        if guessType == ""SIMPLE"":\n            return 0.2\n\n        elif guessType == ""SCHLEGEL"":\n            if Z[self.A] == 1 or Z[self.C] == 1:\n                return 0.160\n            else:\n                return 0.250\n\n        elif guessType == ""FISCHER"":\n            a = 0.089\n            b = 0.11\n            c = 0.44\n            d = -0.42\n            Rcov_AB = (\n                covRadii.R[int(Z[self.A])] + covRadii.R[int(Z[self.B])]) / BOHR2ANGSTROMS\n            Rcov_BC = (\n                covRadii.R[int(Z[self.C])] + covRadii.R[int(Z[self.B])]) / BOHR2ANGSTROMS\n            R_AB = v3d.dist(geom[self.A], geom[self.B])\n            R_BC = v3d.dist(geom[self.B], geom[self.C])\n            return a + b / (np.power(Rcov_AB * Rcov_BC, d)) * np.exp(\n                -c * (R_AB + R_BC - Rcov_AB - Rcov_BC))\n\n        elif guessType == ""LINDH_SIMPLE"":\n            R_AB = v3d.dist(geom[self.A], geom[self.B])\n            R_BC = v3d.dist(geom[self.B], geom[self.C])\n            k_phi = 0.15\n            Lindh_Rho_AB = HguessLindhRho(Z[self.A], Z[self.B], R_AB)\n            Lindh_Rho_BC = HguessLindhRho(Z[self.B], Z[self.C], R_BC)\n            return k_phi * Lindh_Rho_AB * Lindh_Rho_BC\n\n        else:\n            print(""Warning: Hessian guess encountered unknown coordinate type.\\n"")\n            return 1.0\n'"
Tutorials/13_Geometry_Optimization/opt_helper/covRadii.py,0,"b'""""""\n  This header file contains the covalent radii of the atoms in Angstroms from:\n  ""Covalent radii revisited""  Dalton Trans., 2008, 2832, by\n  B. Cordero  V. Gomez, A. E. Platero-Prats, M. Reves, J. Echeverria,\n  E. Cremades  F. Barragan and S. Alvarez.  The largest values have\n  been chosen for C (sp3) and for Mn  Fe, and Co (high-spin).\n- RAK  May 2008""""""\n\n#define LAST_COV_RADII_INDEX 96\n\nR = (\n    2.0,  # ghost?\n    0.31,  #H\n    0.28,  #He\n    1.28,  #Li\n    0.96,  #Be\n    0.84,  #B\n    0.76,  #C\n    0.71,  #N\n    0.66,  #O\n    0.57,  #F\n    0.58,  #Ne\n    1.66,  #Na\n    1.41,  #Mg\n    1.21,  #Al\n    1.11,  #Si\n    1.07,  #P\n    1.05,  #S\n    1.02,  #Cl\n    1.06,  #Ar\n    2.03,  #K\n    1.76,  #Ca\n    1.70,  #Sc\n    1.60,  #Ti\n    1.53,  #V\n    1.39,  #Cr\n    1.61,  #Mn\n    1.52,  #Fe\n    1.50,  #Co\n    1.24,  #Ni\n    1.32,  #Cu\n    1.22,  #Zn\n    1.22,  #Ga\n    1.20,  #Ge\n    1.19,  #As\n    1.20,  #Se\n    1.20,  #Br\n    1.16,  #Kr\n    2.20,  #Rb\n    1.95,  #Sr\n    1.90,  #Y\n    1.75,  #Zr\n    1.64,  #Nb\n    1.54,  #Mo\n    1.47,  #Tc\n    1.46,  #Ru\n    1.42,  #Rh\n    1.39,  #Pd\n    1.45,  #Ag\n    1.44,  #Cd\n    1.42,  #In\n    1.39,  #Sn\n    1.39,  #Sb\n    1.38,  #Te\n    1.39,  #I\n    1.40,  #Xe\n    2.44,  #Cs\n    2.15,  #Ba\n    2.07,  #La\n    2.04,  #Ce\n    2.03,  #Pr\n    2.01,  #Nd\n    1.99,  #Pm\n    1.98,  #Sm\n    1.98,  #Eu\n    1.96,  #Gd\n    1.94,  #Tb\n    1.92,  #Dy\n    1.92,  #Ho\n    1.89,  #Er\n    1.90,  #Tm\n    1.87,  #Yb\n    1.87,  #Lu\n    1.75,  #Hf\n    1.70,  #Ta\n    1.62,  #W\n    1.51,  #Re\n    1.44,  #Os\n    1.41,  #Ir\n    1.36,  #Pt\n    1.36,  #Au\n    1.32,  #Hg\n    1.45,  #Tl\n    1.46,  #Pb\n    1.48,  #Bi\n    1.40,  #Po\n    1.50,  #At\n    1.50,  #Rn\n    2.60,  #Fr\n    2.21,  #Ra\n    2.15,  #Ac\n    2.06,  #Th\n    2.00,  #Pa\n    1.96,  #U\n    1.90,  #Np\n    1.87,  #Pu\n    1.80,  #Am\n    1.69  #Cm\n)\n'"
Tutorials/13_Geometry_Optimization/opt_helper/displace.py,10,"b'import numpy as np\n\nfrom . import intcosMisc\nfrom . import optExceptions\nfrom .linearAlgebra import absMax, rms, symmMatInv\nfrom .printTools import printArray\n\nPRINT_LVL = 1\nOPT_TYPE = \'MIN\'\n\n# dq : displacements in internal coordinates to be performed.\n#      On exit, overridden to actual displacements performed.\n# fq : internal coordinate forces (used for printing).\n# atom_offset : increment to atom #\'s in the fragment (used for printing)\n# ensure_convergence :\n#   Reduce step size as necessary until back-transformation converges.\n\n\ndef displace(intcos, geom, dq, fq, atom_offset=0, ensure_convergence=False):\n    if not len(intcos) or not len(geom) or not len(dq):\n        dq[:] = 0\n        return\n\n    Nint = len(intcos)\n\n    intcosMisc.updateDihedralOrientations(intcos, geom)\n    geom_orig = np.copy(geom)\n    dq_orig = np.copy(dq)\n    intcosMisc.unfixBendAxes(intcos)\n    q_orig = intcosMisc.qValues(intcos, geom_orig)\n\n    best_geom = np.zeros(geom_orig.shape, float)\n\n    # Do your best to backtransform all internal coordinate displacments.\n    print(""\\tBeginnning displacement in cartesian coordinates..."")\n\n    if ensure_convergence:\n        conv = False\n        cnt = -1\n\n        while not conv:\n            cnt = cnt + 1\n            if cnt > 0:\n                print(""Reducing step-size by a factor of %d.\\n"" % (2 * cnt))\n                dq[:] = dq_orig / (2.0 * cnt)\n\n            intcosMisc.fixBendAxes(intcos, geom)\n            conv = stepIter(intcos, geom, dq)\n            intcosMisc.unfixBendAxes(intcos)\n\n            if not conv:\n                if cnt == 5:\n                    print(\n                        ""\\tUnable to back-transform even 1/10th of the desired step rigorously.\\n""\n                    )\n                    print(""\\tContinuing with best (small) step.\\n"")\n                    break\n                else:\n                    geom[:] = geom_orig  # put original geometry back for next try at smaller step.\n\n        if conv and cnt > 0:  # We were able to take a modest step.  Try to complete it.\n            print(\n                ""\\tAble to take a small step; trying another partial back-transformations.\\n""\n            )\n\n            for j in range(1, 2 * cnt):\n                print(""Mini-step %d of %d.\\n"", (j + 1, 2 * cnt))\n                dq[:] = dq_orig / (2 * cnt)\n\n                best_geom[:] = geom\n\n                intcosMisc.fixBendAxes(intcos, geom)\n                conv = stepIter(intcos, geom, dq)\n                intcosMisc.unfixBendAxes(intcos)\n\n                if not conv:\n                    print(\n                        ""\\tCouldn\'t converge this mini-step, so quitting with previous geometry.\\n""\n                    )\n                    geom[:] = best_geom\n                    break\n\n    else:  # try to back-transform, but continue even if desired dq is not achieved\n        intcosMisc.fixBendAxes(intcos, geom)\n        stepIter(intcos, geom, dq)\n        intcosMisc.unfixBendAxes(intcos)\n\n    # Fix drift/error in any frozen coordinates\n    if any(intco.frozen for intco in intcos):\n\n        # Set dq for unfrozen intcos to zero.\n        dq_adjust_frozen = q_orig - intcosMisc.qValues(intcos, geom)\n\n        for i, intco in enumerate(intcos):\n            if not intco.frozen:\n                dq_adjust_frozen[i] = 0\n\n        print(\n            ""\\n\\tBack-transformation to cartesian coordinates to adjust frozen coordinates...\\n""\n        )\n\n        intcosMisc.fixBendAxes(intcos, geom)\n        check = stepIter(\n            intcos,\n            geom,\n            dq_adjust_frozen,\n            bt_dx_conv=1.0e-12,\n            bt_dx_rms_change_conv=1.0e-12,\n            bt_max_iter=100)\n        intcosMisc.unfixBendAxes(intcos)\n\n        if check: print(""\\tsuccessful.\\n"")\n        else: print(""\\tunsuccessful, but continuing.\\n"")\n\n    # Make sure final Dq is actual change\n    q_final = intcosMisc.qValues(intcos, geom)\n    dq[:] = q_final - q_orig\n\n    if PRINT_LVL > 1:\n        print(""\\n\\tReport of back-transformation: (au)\\n"")\n        print(""\\t  int       q_target          Error\\n"")\n        print(""\\t-----------------------------------\\n"")\n        q_target = q_orig + dq_orig\n        for i in range(Nint):\n            print(""\\t%5d%15.10lf%15.10lf\\n"" % (i + 1, q_target[i],\n                                                   (q_final - q_target)[i]))\n        print(""\\t-----------------------------------\\n"")\n\n    # Set dq to final, total displacement ACHIEVED\n    qShow_final = intcosMisc.qShowValues(intcos, geom)\n    qShow_orig = intcosMisc.qShowValues(intcos, geom_orig)\n    dqShow = qShow_final - qShow_orig\n\n    print(\n        ""\\n\\t       --- Internal Coordinate Step in ANG or DEG, aJ/ANG or AJ/DEG ---"")\n    print(\n        ""\\t-----------------------------------------------------------------------------""\n    )\n    print(\n        ""\\t         Coordinate      Previous         Force        Change          New "")\n    print(\n        ""\\t         ----------      --------        ------        ------        ------"")\n    for i, intco in enumerate(intcos):\n        print(""\\t%19s%14.5f%14.5f%14.5f%14.5f"" % (intco, qShow_orig[i], fq[i],\n                                                        dqShow[i], qShow_final[i]))\n    print(\n        ""\\t-----------------------------------------------------------------------------""\n    )\n\n\ndef stepIter(intcos,\n             geom,\n             dq,\n             bt_dx_conv=None,\n             bt_dx_rms_change_conv=None,\n             bt_max_iter=None):\n    dx_rms_last = -1\n    if bt_dx_conv is None: bt_dx_conv = 1.0e-6\n    if bt_dx_rms_change_conv is None:\n        bt_dx_rms_change_conv = 1.0e-12\n    if bt_max_iter is None: bt_max_iter = 25\n\n    q_orig = intcosMisc.qValues(intcos, geom)\n    q_target = q_orig + dq\n\n    if PRINT_LVL > 1:\n        print(""\\t---------------------------------------------------\\n"")\n        print(""\\t Iter        RMS(dx)        Max(dx)        RMS(dq) \\n"")\n        print(""\\t---------------------------------------------------\\n"")\n\n    new_geom = np.copy(geom)  # cart geometry to start each iter\n    best_geom = np.zeros(new_geom.shape, float)\n\n    bt_iter_continue = True\n    bt_converged = False\n    bt_iter_cnt = 0\n\n    while bt_iter_continue:\n\n        dq_rms = rms(dq)\n        dx_rms, dx_max = oneStep(intcos, geom, dq, PRINT_LVL > 2)\n\n        # Met convergence thresholds\n        if dx_rms < bt_dx_conv and dx_max < bt_dx_conv:\n            bt_converged = True\n            bt_iter_continue = False\n        # No further progress toward convergence.\n        elif np.absolute(dx_rms - dx_rms_last) < bt_dx_rms_change_conv \\\n          or bt_iter_cnt >= bt_max_iter \\\n          or dx_rms > 100.0:\n            bt_converged = False\n            bt_iter_continue = False\n\n        dx_rms_last = dx_rms\n\n        new_q = intcosMisc.qValues(intcos, geom)\n        dq[:] = q_target - new_q\n        del new_q\n\n        if bt_iter_cnt == 0 or dq_rms < best_dq_rms:\n            best_geom[:] = geom\n            best_dq_rms = dq_rms\n\n        if PRINT_LVL > 1:\n            print(""\\t%5d %14.1e %14.1e %14.1e\\n"" % (bt_iter_cnt + 1, dx_rms, dx_max,\n                                                        dq_rms))\n\n        bt_iter_cnt += 1\n\n    if PRINT_LVL > 1:\n        print(""\\t---------------------------------------------------\\n"")\n\n    if bt_converged: print(""\\tSuccessfully converged to displaced geometry."")\n    else: print(""\\tUnable to completely converge to displaced geometry.\\n"")\n\n    if dq_rms > best_dq_rms:\n        print(\n            ""\\tPrevious geometry is closer to target in internal coordinates, so using that one.\\n""\n        )\n        print(""\\tBest geometry has RMS(Delta(q)) = %8.2e\\n"" % best_dq_rms)\n        geom[:] = best_geom\n\n    if OPT_TYPE == ""IRC"" and not bt_converged:\n        raise optExceptions.OPT_FAIL(\n            ""Could not take constrained step in an IRC computation."")\n\n    return bt_converged\n\n\n# Convert dq to dx.  Geometry is updated.\n# B dx = dq\n# B dx = (B Bt)(B Bt)^-1 dq\n# B (dx) = B * [Bt (B Bt)^-1 dq]\n#   dx = Bt (B Bt)^-1 dq\n#   dx = Bt G^-1 dq, where G = B B^t.\ndef oneStep(intcos, geom, dq, printDetails=False):\n    B = intcosMisc.Bmat(intcos, geom)\n    G = np.dot(B, B.T)\n    Ginv = symmMatInv(G, redundant=True)\n    tmp_v_Nint = np.dot(Ginv, dq)\n    dx = np.zeros(geom.shape[0] * geom.shape[1], float)  # dx is 1D here\n\n    dx[:] = np.dot(B.T, tmp_v_Nint)\n    if printDetails:\n        qOld = intcosMisc.qValues(intcos, geom)\n    geom += dx.reshape(geom.shape)\n\n    if printDetails:\n        qNew = intcosMisc.qValues(intcos, geom)\n        dq_achieved = intcosMisc.qValues(intcos, geom) - qOld\n        printArray(dq_achieved)\n        print(""\\t      Report of Single-step\\n"")\n        print(""\\t  int       dq_achieved        dq_error\\n"")\n        for i in range(len(intcos)):\n            print(""\\t%5d%15.10lf%15.10lf\\n"" % (i + 1, dq_achieved[i],\n                                                   dq_achieved[i] - dq[i]))\n\n    dx_rms = rms(dx)\n    dx_max = absMax(dx)\n    del B, G, Ginv, tmp_v_Nint, dx\n    return dx_rms, dx_max\n'"
Tutorials/13_Geometry_Optimization/opt_helper/intcosMisc.py,26,"b'from math import sqrt\n\nimport numpy as np\n\nfrom . import oofp\nfrom .linearAlgebra import symmMatInv\nfrom .printTools import printMat, printArray\nPRINT_LVL = 1\nFIXED_COORD_FORCE_CONSTANT = 0.5\n\n# q    -> qValues\n# DqDx -> Bmat\ndef qValues(intcos, geom):\n    q = np.zeros((len(intcos)), float)\n    for i, intco in enumerate(intcos):\n        q[i] = intco.q(geom)\n    return q\n\n\ndef qShowValues(intcos, geom):\n    q = np.zeros((len(intcos)), float)\n    for i, intco in enumerate(intcos):\n        q[i] = intco.qShow(geom)\n    return q\n\n\ndef updateDihedralOrientations(intcos, geom):\n    for intco in intcos:\n        if isinstance(intco, tors.TORS) or isinstance(intco, oofp.OOFP):\n            intco.updateOrientation(geom)\n    return\n\n\ndef fixBendAxes(intcos, geom):\n    for intco in intcos:\n        if isinstance(intco, bend.BEND):\n            intco.fixBendAxes(geom)\n    return\n\n\ndef unfixBendAxes(intcos):\n    for intco in intcos:\n        if isinstance(intco, bend.BEND):\n            intco.unfixBendAxes()\n    return\n\n\ndef Bmat(intcos, geom, masses=None):\n    Nint = len(intcos)\n    Ncart = geom.size\n\n    B = np.zeros((Nint, Ncart), float)\n    for i, intco in enumerate(intcos):\n        intco.DqDx(geom, B[i])\n\n    if masses is not None:\n        print(""mass weighting B matrix\\n"")\n        for i in range(len(intcos)):\n            for a in range(len(geom)):\n                for xyz in range(3):\n                    B[i, 3 * a + xyz] /= sqrt(masses[a])\n\n    return B\n\n\ndef Gmat(intcos, geom, masses=None):\n    B = Bmat(intcos, geom, masses)\n\n    if masses is not None:\n        for i in range(len(intcos)):\n            for a in range(len(geom)):\n                for xyz in range(3):\n                    B[i][3 * a + xyz] /= sqrt(masses[a])\n\n    return np.dot(B, B.T)\n\n\n# Compute forces in internal coordinates in au, f_q = G_inv B u f_x\n# if u is unit matrix, f_q = (BB^T)^(-1) * B f_x\ndef qForces(intcos, geom, gradient_x):\n    if len(intcos) == 0 or len(geom) == 0: return np.zeros(0, float)\n    B = Bmat(intcos, geom)\n    fx = -1.0 * gradient_x  # gradient -> forces\n    temp_arr = np.dot(B, fx.T)\n    del fx\n\n    G = np.dot(B, B.T)\n    del B\n    Ginv = symmMatInv(G, redundant=True)\n    del G\n\n    fq = np.dot(Ginv, temp_arr.T)\n    return fq\n\n\n# Prints them, but does not recompute them.\ndef qShowForces(intcos, forces):\n    qaJ = np.copy(forces)\n    for i, intco in enumerate(intcos):\n        qaJ[i] *= intco.fShowFactor\n    return qaJ\n\n\ndef constraint_matrix(intcos):\n    if not any([coord.frozen for coord in intcos]):\n        return None\n    C = np.zeros((len(intcos), len(intcos)), float)\n    for i, coord in enumerate(intcos):\n        if coord.frozen:\n            C[i, i] = 1.0\n    return C\n\n\n# Project redundancies and constraints out of forces and Hessian.\ndef projectRedundanciesAndConstraints(intcos, geom, fq, H):\n    dim = len(intcos)\n\n    # compute projection matrix = G G^-1\n    G = Gmat(intcos, geom)\n    G_inv = symmMatInv(G, redundant=True)\n    Pprime = np.dot(G, G_inv)\n    if PRINT_LVL >= 3:\n        print(""\\tProjection matrix for redundancies.\\n"")\n        printMat(Pprime)\n\n    # Add constraints to projection matrix\n    C = constraint_matrix(intcos)\n\n    if C is not None:\n        print(""Adding constraints for projection.\\n"")\n        printMat(C)\n        P = np.zeros((len(intcos), len(intcos)), float)\n        #print(np.dot(C, np.dot(Pprime, C)))\n        CPC = np.zeros((len(intcos), len(intcos)), float)\n        CPC[:, :] = np.dot(C, np.dot(Pprime, C))\n        CPC = symmMatInv(CPC, redundant=True)\n        P[:, :] = Pprime - np.dot(Pprime, np.dot(C, np.dot(CPC, np.dot(C, Pprime))))\n        # Project redundancies out of forces.\n        # fq~ = P fq\n        fq[:] = np.dot(P, fq.T)\n\n        if PRINT_LVL >= 3:\n            print(\n                ""\\tInternal forces in au, after projection of redundancies and constraints.\\n""\n            )\n            printArray(fq)\n        # Project redundancies out of Hessian matrix.\n        # Peng, Ayala, Schlegel, JCC 1996 give H -> PHP + 1000(1-P)\n        # The second term appears unnecessary and sometimes messes up Hessian updating.\n        tempMat = np.dot(H, P)\n        H[:, :] = np.dot(P, tempMat)\n        #for i in range(dim)\n        #    H[i,i] += 1000 * (1.0 - P[i,i])\n        #for i in range(dim)\n        #    for j in range(i):\n        #        H[j,i] = H[i,j] = H[i,j] + 1000 * (1.0 - P[i,j])\n        if PRINT_LVL >= 3:\n            print(""Projected (PHP) Hessian matrix\\n"")\n            printMat(H)\n\n\ndef applyFixedForces(Molsys, fq, H, stepNumber):\n    x = Molsys.geom\n    for iF, F in enumerate(Molsys._fragments):\n        for i, intco in enumerate(F.intcos):\n            if intco.fixed:\n                location = Molsys.frag_1st_intco(iF) + i\n                val = intco.q(x)\n                eqVal = intco.fixedEqVal\n\n                # Increase force constant by 5% of initial value per iteration\n                k = (1 + 0.05 * stepNumber) * FIXED_COORD_FORCE_CONSTANT\n                force = k * (eqVal - val)\n                H[location][location] = k\n\n                print(\n                    ""\\n\\tAdding user-defined constraint: Fragment %d; Coordinate %d:\\n"" %\n                    (iF + 1, i + 1))\n                print(""\\t\\tValue = %12.6f; Fixed value    = %12.6f"" % (val, eqVal))\n                print(""\\t\\tForce = %12.6f; Force constant = %12.6f"" % (force, k))\n                fq[location] = force\n\n                # Delete coupling between this coordinate and others.\n                print(\n                    ""\\t\\tRemoving off-diagonal coupling between coordinate %d and others.""\n                    % (location + 1))\n                for j in range(len(H)):  # gives first dimension length\n                    if j != location:\n                        H[j][location] = H[location][j] = 0\n\n    return\n\n\n""""""\ndef massWeightedUMatrixCart(masses): \n    atom = 1 \n    masses = [15.9994, 1.00794, 1.00794]\n    U = np.zeros((3 * nAtom, 3 * nAtom), float)\n    for i in range (0, (3 * nAtom)):\n        U[i][i] = 1 / sqrt(masses[atom - 1])\n        if (i % 3 == 0):\n            nAtom += 1\n    return U\n""""""\n\n\ndef convertHessianToInternals(H, intcos, geom, masses=None, g_x=None):\n    print(""Converting Hessian from cartesians to internals.\\n"")\n\n    G = Gmat(intcos, geom, masses)\n    Ginv = symmMatInv(G)\n    B = Bmat(intcos, geom, masses)\n    Atranspose = np.dot(Ginv, B)\n\n    if g_x is None:  # A^t Hxy A\n        print(\n            ""Neglecting force/B-matrix derivative term, only correct at stationary points.\\n""\n        )\n        Hworking = H\n    else:  # A^t (Hxy - Kxy) A;    K_xy = sum_q ( grad_q[I] d^2(q_I)/(dx dy) )\n        print(""Including force/B-matrix derivative term.\\n"")\n        Hworking = H.copy()\n\n        g_q = np.dot(Atranspose, g_x)\n        Ncart = 3 * len(geom)\n        dq2dx2 = np.zeros((Ncart, Ncart), float)  # should be cart x cart for fragment ?\n\n        for I, q in enumerate(intcos):\n            dq2dx2[:] = 0\n            q.Dq2Dx2(geom, dq2dx2)  # d^2(q_I)/ dx_i dx_j\n\n            for a in range(Ncart):\n                for b in range(Ncart):\n                    Hworking[a, b] -= g_q[I] * dq2dx2[\n                        a, b]  # adjust indices for multiple fragments\n\n    Hq = np.dot(Atranspose, np.dot(Hworking, Atranspose.T))\n    return Hq\n\n\ndef convertHessianToCartesians(Hint, intcos, geom, masses=None, g_q=None):\n    print(""Converting Hessian from internals to cartesians.\\n"")\n\n    B = Bmat(intcos, geom, masses)\n    Hxy = np.dot(B.T, np.dot(Hint, B))\n\n    if g_q is None:  # Hxy =  B^t Hij B\n        print(\n            ""Neglecting force/B-matrix derivative term, only correct at stationary points.\\n""\n        )\n    else:  # Hxy += dE/dq_I d2(q_I)/dxdy\n        print(""Including force/B-matrix derivative term.\\n"")\n        Ncart = 3 * len(geom)\n\n        dq2dx2 = np.zeros((Ncart, Ncart), float)  # should be cart x cart for fragment ?\n        for I, q in enumerate(intcos):\n            dq2dx2[:] = 0\n            q.Dq2Dx2(geom, dq2dx2)\n\n            for a in range(Ncart):\n                for b in range(Ncart):\n                    Hxy[a, b] += g_q[I] * dq2dx2[a, b]\n\n    return Hxy\n\n\n# For given [A,B,C], remove any regular bends as well as any torsions\n# which contain it\nfrom . import bend\nfrom . import tors\n\n\ndef torsContainsBend(b, t):\n    if (b.atoms in [\n            t.atoms[0:3],\n            list(reversed(t.atoms[0:3])), t.atoms[1:4],\n            list(reversed(t.atoms[1:4]))\n    ]):\n        return True\n    return False\n\n\ndef removeOldNowLinearBend(atoms, intcos):\n    b = bend.BEND(atoms[0], atoms[1], atoms[2])\n    print(str(b) + \'\\n\')\n    intcos[:] = [I for I in intcos if not (I == b)]\n    intcos[:] = [\n        I for I in intcos if not (isinstance(I, tors.TORS) and torsContainsBend(b, I))\n    ]\n    #    if b == Coord:\n    #        del intcos[iCoord]\n    #    if isinstance(Coord, tors.TORS):\n    #        if (atoms in [Coord.atoms[0:3], list(reversed(Coord.atoms[0:3])),\n    #                      Coord.atoms[1:4], list(reversed(Coord.atoms[1:4]))]):\n    #            del intcos[iCoord]\n    return\n'"
Tutorials/13_Geometry_Optimization/opt_helper/linearAlgebra.py,14,"b'from math import fabs, sqrt\n\nimport numpy as np\n\nfrom . import optExceptions\n\n\ndef norm(V):\n    return np.linalg.norm(V)\n\n\n### Linear algebra routines.\ndef absMax(V):\n    return max(abs(elem) for elem in V)\n\n\ndef absMin(V):\n    return min(abs(elem) for elem in V)\n\n\ndef rms(V):\n    return np.sqrt(np.mean(V**2))\n\n\ndef signOfDouble(d):\n    if d > 0: return 1\n    elif d < 0: return -1\n    else: return 0\n\n\n# Returns eigenvectors as rows?\ndef symmMatEig(mat):\n    try:\n        evals, evects = np.linalg.eigh(mat)\n    except:\n        raise optExceptions.OPT_FAIL(""symmMatEig: could not compute eigenvectors"")\n        # could be ALG_FAIL ?\n    evects = evects.T\n    return evals, evects\n\n\nimport operator\n\n\n# returns eigenvectors as rows; orders evals\ndef asymmMatEig(mat):\n    try:\n        evals, evects = np.linalg.eig(mat)\n    except:\n        raise optExceptions.OPT_FAIL(""asymmMatEig: could not compute eigenvectors"")\n        # could be ALG_FAIL ?\n\n    evects = evects.T\n    evalsSorted, evectsSorted = zip(*sorted(\n        zip(evals, evects), key=operator.itemgetter(0)))\n    # convert from tuple to array\n    evalsSorted = np.array(evalsSorted, float)\n    evectsSorted = np.array(evectsSorted, float)\n    return evalsSorted, evectsSorted\n\n\n#  Return the inverse of a real, symmetric matrix.  If ""redundant"" == true,\n#  then a generalized inverse is permitted.\ndef symmMatInv(A, redundant=False, redundant_eval_tol=1.0e-10):\n    dim = A.shape[0]\n    if dim <= 0: return np.zeros((0, 0), float)\n    det = 1.0\n\n    try:\n        evals, evects = symmMatEig(A)\n    except:\n        raise optExceptions.OPT_FAIL(""symmMatrixInv: could not compute eigenvectors"")\n        # could be ALG_FAIL ?\n\n    for i in range(dim):\n        det *= evals[i]\n\n    if not redundant and fabs(det) < 1E-10:\n        raise optExceptions.OPT_FAIL(\n            ""symmMatrixInv: non-generalized inverse failed; very small determinant"")\n        # could be ALG_FAIL ?\n\n    diagInv = np.zeros((dim, dim), float)\n\n    if redundant:\n        for i in range(dim):\n            if fabs(evals[i]) > redundant_eval_tol:\n                diagInv[i, i] = 1.0 / evals[i]\n    else:\n        for i in range(dim):\n            diagInv[i, i] = 1.0 / evals[i]\n\n    # A^-1 = P^t D^-1 P\n    tmpMat = np.dot(diagInv, evects)\n    AInv = np.dot(evects.T, tmpMat)\n    return AInv\n\n\ndef symmMatRoot(A, Inverse=None):\n    try:\n        evals, evects = np.linalg.eigh(A)\n    except:\n        raise optExceptions.OPT_FAIL(""symmMatRoot: could not compute eigenvectors"")\n        # could be ALG_FAIL ?\n\n    rootMatrix = np.zeros((len(evals), len(evals)), float)\n    if Inverse:\n        for i in range(0, len(evals)):\n            evals[i] = 1 / evals[i]\n\n    Q = np.zeros((len(evals), len(evals)), float)\n    for i in range(len(evals)):\n        for j in range(len(evects)):\n            Q[j][i] = evects[i][j]\n\n    for i in range(0, len(evals)):\n        rootMatrix[i][i] = sqrt(evals[i])\n\n    A = np.dot(Q, np.dot(rootMatrix, Q.T))\n\n    return A\n'"
Tutorials/13_Geometry_Optimization/opt_helper/misc.py,1,"b'import numpy as np\n\nfrom . import optExceptions\n\ndef delta(i, j):\n    if i == j:\n        return 1\n    else:\n        return 0\n\n\ndef isDqSymmetric(intcos, geom, Dq):\n    print(\'\\tTODO add isDqSymmetric\\n\')\n    return True\n\n\ndef symmetrizeXYZ(XYZ):\n    print(\'\\tTODO add symmetrize XYZ\\n\')\n    return XYZ\n\n\n# return period from atomic number\ndef ZtoPeriod(Z):\n    if Z <= 2: return 1\n    elif Z <= 10: return 2\n    elif Z <= 18: return 3\n    elif Z <= 36: return 4\n    else: return 5\n\n\n# ""Average"" bond length given two periods\n# Values below are from Lindh et al.\n# Based on DZP RHF computations, I suggest: 1.38 1.9 2.53, and 1.9 2.87 3.40\ndef AverageRFromPeriods(perA, perB):\n    if perA == 1:\n        if perB == 1:\n            return 1.35\n        elif perB == 2:\n            return 2.1\n        else:\n            return 2.53\n    elif perA == 2:\n        if perB == 1:\n            return 2.1\n        elif perB == 2:\n            return 2.87\n        else:\n            return 3.40\n    else:\n        if perB == 1:\n            return 2.53\n        else:\n            return 3.40\n\n\n# Return Lindh alpha value from two periods\ndef HguessLindhAlpha(perA, perB):\n    if perA == 1:\n        if perB == 1:\n            return 1.000\n        else:\n            return 0.3949\n    else:\n        if perB == 1:\n            return 0.3949\n        else:\n            return 0.2800\n\n\n# rho_ij = e^(alpha (r^2,ref - r^2))\ndef HguessLindhRho(ZA, ZB, RAB):\n    perA = ZtoPeriod(ZA)\n    perB = ZtoPeriod(ZB)\n\n    alpha = HguessLindhAlpha(perA, perB)\n    r_ref = AverageRFromPeriods(perA, perB)\n\n    return np.exp(-alpha * (RAB * RAB - r_ref * r_ref))\n\n""""""\n\n####\n## params: string of integers corresponding to internal coordinates\n## returns: a list of integers correspoding to an atom\n## removes spaces or non integer characters from string of internal coordinates to be frozen\n####\ndef tokenizeInputString(inString):\n    outString = inString.encode(\'utf-8\').replace(\'(\', \'\').replace(\')\', \'\')\n    return outString.split()\n\n\ndef intList(inList):\n    outList = [int(i) for i in inList]\n    return outList\n\n\ndef intIntFloatList(inList):\n    if len(inList) % 3 != 0:\n        raise optExceptions.OPT_FAIL(""List is not comprised of int-int-float elements"")\n    outList = []\n    for i in range(0, len(inList), 3):\n        outList.append(int(inList[i + 0]))\n        outList.append(int(inList[i + 1]))\n        outList.append(float(inList[i + 2]))\n    return outList\n\n\ndef intIntIntFloatList(inList):\n    if len(inList) % 4 != 0:\n        raise optExceptions.OPT_FAIL(\n            ""List is not comprised of int-int-int-float elements"")\n    outList = []\n    for i in range(0, len(inList), 4):\n        outList.append(int(inList[i + 0]))\n        outList.append(int(inList[i + 1]))\n        outList.append(int(inList[i + 2]))\n        outList.append(float(inList[i + 3]))\n    return outList\n\n\ndef intIntIntIntFloatList(inList):\n    if len(inList) % 5 != 0:\n        raise optExceptions.OPT_FAIL(\n            ""List is not comprised of int-int-int-int-float elements"")\n    outList = []\n    for i in range(0, len(inList), 5):\n        outList.append(int(inList[i + 0]))\n        outList.append(int(inList[i + 1]))\n        outList.append(int(inList[i + 2]))\n        outList.append(int(inList[i + 3]))\n        outList.append(float(inList[i + 4]))\n    return outList\n\ndef int_XYZ_list(inList):\n    if len(inList) % 2 != 0:\n        raise optExceptions.OPT_FAIL(""int-XYZ list does not have even number of entries"")\n    outList = []\n    for i in range(0, len(inList), 2):\n        outList.append(int(inList[i + 0]))\n        cart_string = str(inList[i + 1]).upper()\n        if len(cart_string) > 3 or len(cart_string) < 1:\n            raise optExceptions.OPT_FAIL(""Could not decipher xyz coordinate string"")\n        for c in cart_string:\n            if c not in (\'X\',\'Y\',\'Z\'):\n                raise optExceptions.OPT_FAIL(""Could not decipher xyz coordinate string"")\n        cart_string = sorted(cart_string) # x , then y, then z\n        outList.append(cart_string)\n    return outList\n\n""""""\n\n'"
Tutorials/13_Geometry_Optimization/opt_helper/oofp.py,4,"b'from math import cos, sin, tan\n\nfrom . import optExceptions\nfrom . import v3d\nfrom .simple import *\n\nFIX_VAL_NEAR_PI = 1.57\nfrom psi4 import constants\nHARTREE2AJ = constants.hartree2aJ\n\n# Class for out-of-plane angle.  Definition (A,B,C,D) means angle AB with respect\n# to the CBD plane; canonical order is C < D\n\n\nclass OOFP(SIMPLE):\n    def __init__(self, a, b, c, d, frozen=False, fixedEqVal=None):\n\n        if c < d: atoms = (a, b, c, d)\n        else: atoms = (a, b, d, c)\n        self._near180 = 0\n        SIMPLE.__init__(self, atoms, frozen, fixedEqVal)\n\n    def __str__(self):\n        if self.frozen: s = \'*\'\n        else: s = \' \'\n\n        s += ""O""\n\n        s += ""(%d,%d,%d,%d)"" % (self.A + 1, self.B + 1, self.C + 1, self.D + 1)\n        if self.fixedEqVal:\n            s += ""[%.4f]"" % self.fixedEqVal\n        return s\n\n    def __eq__(self, other):\n        if self.atoms != other.atoms: return False\n        elif not isinstance(other, OOFP): return False\n        else: return True\n\n    @property\n    def near180(self):\n        return self._near180\n\n    def updateOrientation(self, geom):\n        tval = self.q(geom)\n        if tval > FIX_VAL_NEAR_PI:\n            self._near180 = +1\n        elif tval < -1 * FIX_VAL_NEAR_PI:\n            self._near180 = -1\n        else:\n            self._near180 = 0\n        return\n\n    @property\n    def qShowFactor(self):\n        return 180.0 / np.pi\n\n    def qShow(self, geom):  # return in degrees\n        return self.q(geom) * self.qShowFactor\n\n    @property\n    def fShowFactor(self):\n        return HARTREE2AJ * np.pi / 180.0\n\n    # compute angle and return value in radians\n    def q(self, geom):\n        check, tau = v3d.oofp(geom[self.A], geom[self.B], geom[self.C], geom[self.D])\n        if not check:\n            raise optExceptions.ALG_FAIL(\n                ""OOFP::compute.q: unable to compute out-of-plane value"")\n\n        # Extend domain of out-of-plane angles to beyond pi\n        if self._near180 == -1 and tau > FIX_VAL_NEAR_PI:\n            return tau - 2.0 * np.pi\n        elif self._near180 == +1 and tau < -1 * FIX_VAL_NEAR_PI:\n            return tau + 2.0 * np.pi\n        else:\n            return tau\n\n    # out-of-plane is m-o-p-n\n    # Assume angle phi_CBD is OK, or we couldn\'t calculate the value anyway.\n    def DqDx(self, geom, dqdx):\n        eBA = geom[self.A] - geom[self.B]\n        eBC = geom[self.C] - geom[self.B]\n        eBD = geom[self.D] - geom[self.B]\n        rBA = v3d.norm(eBA)\n        rBC = v3d.norm(eBC)\n        rBD = v3d.norm(eBD)\n        eBA *= 1.0 / rBA\n        eBC *= 1.0 / rBC\n        eBD *= 1.0 / rBD\n\n        # compute out-of-plane value, C-B-D angle\n        val = self.q(geom)\n        check, phi_CBD = v3d.angle(geom[self.C], geom[self.B], geom[self.D])\n\n        # S vector for A\n        tmp = v3d.cross(eBC, eBD)\n        tmp /= cos(val) * sin(phi_CBD)\n        tmp2 = tan(val) * eBA\n        dqdx[3 * self.A:3 * self.A + 3] = (tmp - tmp2) / rBA\n\n        # S vector for C\n        tmp = v3d.cross(eBD, eBA)\n        tmp = tmp / (cos(val) * sin(phi_CBD))\n        tmp2 = cos(phi_CBD) * eBD\n        tmp3 = -1.0 * tmp2 + eBC\n        tmp3 *= tan(val) / (sin(phi_CBD) * sin(phi_CBD))\n        dqdx[3 * self.C:3 * self.C + 3] = (tmp - tmp3) / rBC\n\n        # S vector for D\n        tmp = v3d.cross(eBA, eBC)\n        tmp /= cos(val) * sin(phi_CBD)\n        tmp2 = cos(phi_CBD) * eBC\n        tmp3 = -1.0 * tmp2 + eBD\n        tmp3 *= tan(val) / (sin(phi_CBD) * sin(phi_CBD))\n        dqdx[3 * self.D:3 * self.D + 3] = (tmp - tmp3) / rBD\n\n        # S vector for B\n        dqdx[3*self.B:3*self.B+3] = -1.0 * dqdx[3*self.A:3*self.A+3] \\\n           - dqdx[3*self.C:3*self.C+3] - dqdx[3*self.D:3*self.D+3]\n        return\n\n    def Dq2Dx2(self, geom, dqdx):\n        raise optExceptions.ALG_FAIL(\'no derivative B matrices for out-of-plane angles\')\n\n    def diagonalHessianGuess(self, geom, Z, guess=""SIMPLE""):\n        """""" Generates diagonal empirical Hessians in a.u. such as \n          Schlegel, Theor. Chim. Acta, 66, 333 (1984) and\n          Fischer and Almlof, J. Phys. Chem., 96, 9770 (1992).\n        """"""\n        if guess == ""SIMPLE"":\n            return 0.1\n        else:\n            print(""Warning: Hessian guess encountered unknown coordinate type.\\n"")\n            return 1.0\n'"
Tutorials/13_Geometry_Optimization/opt_helper/optExceptions.py,0,"b""\n# We don't catch this one internally.\nclass OPT_FAIL(Exception):\n    def __init__(self, mesg='None given'):\n        print('OPT_FAIL: Optimization has failed.')\n        #Exception.__init__(self, mesg)\n\n\nclass ALG_FAIL(Exception):\n    #maybe generalize later def __init__(self, *args, **kwargs):\n    def __init__(self, mesg='None given', newLinearBends=None):\n        print('ALG_FAIL: Exception created.\\n')\n        if newLinearBends:\n            print('ALG_FAIL: New bends detected.\\n')\n        self.linearBends = newLinearBends\n        self.mesg = mesg\n"""
Tutorials/13_Geometry_Optimization/opt_helper/printTools.py,0,"b'from __future__ import print_function\n\ndef printMat(M, Ncol=7, title=None):\n    if title:\n        print(title + \'\\n\')\n    for row in range(M.shape[0]):\n        tab = 0\n        for col in range(M.shape[1]):\n            tab += 1\n            print("" %10.6f"" % M[row, col])\n            if tab == Ncol and col != (M.shape[1] - 1):\n                print(""\\n"")\n                tab = 0\n        print(""\\n"")\n    return\n\n\ndef printMatString(M, Ncol=7, title=None):\n    if title:\n        print(title + \'\\n\')\n    s = \'\'\n    for row in range(M.shape[0]):\n        tab = 0\n        for col in range(M.shape[1]):\n            tab += 1\n            s += "" %10.6f"" % M[row, col]\n            if tab == Ncol and col != (M.shape[1] - 1):\n                s += \'\\n\'\n                tab = 0\n        s += \'\\n\'\n    return s\n\n\ndef printArray(M, Ncol=7, title=None):\n    if title:\n        print(title + \'\\n\')\n    tab = 0\n    for col, entry in enumerate(M):\n        tab += 1\n        print("" %10.6f"" % M[col])\n        if tab == Ncol and col != (len(M) - 1):\n            print(""\\n"")\n            tab = 0\n    print(""\\n"")\n    return\n\n\ndef printArrayString(M, Ncol=7, title=None):\n    if title:\n        print(title + \'\\n\')\n    tab = 0\n    s = \'\'\n    for i, entry in enumerate(M):\n        tab += 1\n        s += "" %10.6f"" % entry\n        if tab == Ncol and i != (len(M) - 1):\n            s += \'\\n\'\n            tab = 0\n    s += \'\\n\'\n    return s\n\n\ndef printGeomGrad(geom, grad):\n    print(""\\tGeometry and Gradient\\n"")\n    Natom = geom.shape[0]\n\n    for i in range(Natom):\n        print(""\\t%20.10f%20.10f%20.10f\\n"" % (geom[i, 0], geom[i, 1], geom[i, 2]))\n    print(""\\n"")\n    for i in range(Natom):\n        print(""\\t%20.10f%20.10f%20.10f\\n"" % (grad[3 * i + 0], grad[3 * i + 1],\n                                                 grad[3 * i + 2]))\n'"
Tutorials/13_Geometry_Optimization/opt_helper/simple.py,0,"b'from abc import ABCMeta, abstractmethod\nfrom . import optExceptions\n\n\nclass SIMPLE(object):\n    __metaclass__ = ABCMeta\n\n    def __init__(self, atoms, frozen=False, fixedEqVal=None):\n        # these lines use the property\'s and setters below\n        self.atoms = atoms  # atom indices for internal definition\n        self.frozen = frozen  # bool - is internal coordinate frozen?\n        self.fixedEqVal = fixedEqVal  # target value if artificial forces are to be added\n\n    @property\n    def atoms(self):\n        return self._atoms\n\n    @atoms.setter\n    def atoms(self, values):\n        try:\n            for v in values:\n                if int(v) < 0:\n                    raise optExceptions.OPT_FAIL(\'Atom identifier cannot be negative.\')\n        except:\n            raise optExceptions.OPT_FAIL(\'Atoms must be iterable list of whole numbers.\')\n        self._atoms = values\n\n    @property\n    def frozen(self):\n        return self._frozen\n\n    @property\n    def fixed(self):\n        if self._fixedEqVal is None:\n            return False\n        else:\n            return True\n\n    @frozen.setter\n    def frozen(self, setval):\n        self._frozen = bool(setval)\n        return\n\n    @property\n    def fixedEqVal(self):\n        return self._fixedEqVal\n\n    @fixedEqVal.setter\n    def fixedEqVal(self, qTarget=None):\n        if qTarget is not None:\n            try:\n                float(qTarget)\n            except:\n                raise optExceptions.OPT_FAIL(""Eq. value must be a float or None."")\n        self._fixedEqVal = qTarget\n\n    @property\n    def A(self):\n        try:\n            return self.atoms[0]\n        except:\n            raise optExceptions.OPT_FAIL(""A() called but atoms[0] does not exist"")\n\n    @property\n    def B(self):\n        try:\n            return self.atoms[1]\n        except:\n            raise optExceptions.OPT_FAIL(""B() called but atoms[1] does not exist"")\n\n    @property\n    def C(self):\n        try:\n            return self.atoms[2]\n        except:\n            raise optExceptions.OPT_FAIL(""C() called but atoms[2] does not exist"")\n\n    @property\n    def D(self):\n        try:\n            return self.atoms[3]\n        except:\n            raise optExceptions.OPT_FAIL(""D() called but atoms[3] does not exist"")\n\n    # ** constructor + 7 abstract methods are currently required **\n    @abstractmethod  # Given geometry, return value in Bohr or radians\n    def q(self, geom):\n        pass\n\n    @abstractmethod  # Given geometry, return Value in Angstroms or degrees.\n    def qShow(self, geom):\n        pass\n\n    @abstractmethod  # Return the scalar needed to convert value in au to Ang or Deg\n    def qShowFactor(self):\n        pass\n\n    @abstractmethod  # Return the scalar needed to convert force in au to aJ/(Ang or Deg)\n    def fShowFactor(self):\n        pass\n\n    # Modify provided DqDx array with first derivative of value wrt cartesians\n    #  i.e., provide rows of B matrix.\n    #   Num. of rows is len(self._atoms), or Num. of atoms in coordinate definition\n    # By default, col dimension of dqdx is assumed to be 3*(Num. of atoms in fragment,\n    #  or the number of atoms consistent with the values of self._atoms).\n    # If mini==True, then col dimension of dqdx is only 3*len(self._atoms).  For a stretch\n    # then, e.g, DqDx is 2x6.\n    @abstractmethod\n    def DqDx(self, geom, dqdx, mini=False):\n        raise optExceptions.ALG_FAIL(\'no DqDx for this coordinate\')\n\n    # Modify provided Dq2Dx2 array with second derivative of value wrt cartesians\n    #  i.e., provide derivative B matrix for coordinate.\n    # dimension of dq2dx2 is 3*len(self._atoms)x3*len(self._atoms), or\n    # cartesian by cartesian - of minimum size.\n    @abstractmethod  # Derivative of value wrt cartesians, i.e., B-matrix elements.\n    def Dq2Dx2(self, geom, dq2dx2):\n        raise optExceptions.ALG_FAIL(\'no Dq2Dx2 for this coordinate\')\n\n    @abstractmethod  # Diagonal hessian guess\n    def diagonalHessianGuess(geom, Z, connectivity, guessType):\n        raise optExceptions.ALG_FAIL(\'no hessian guess for this coordinate\')\n'"
Tutorials/13_Geometry_Optimization/opt_helper/stre.py,2,"b'import numpy as np\n\nfrom . import covRadii\nfrom . import optExceptions\nfrom . import v3d\nfrom .misc import delta, ZtoPeriod, HguessLindhRho\nfrom .simple import *\n\nfrom psi4 import constants\nBOHR2ANGSTROMS = constants.bohr2angstroms\nHARTREE2AJ = constants.hartree2aJ\n\nclass STRE(SIMPLE):\n    def __init__(self, a, b, frozen=False, fixedEqVal=None, inverse=False):\n\n        self._inverse = inverse  # bool - is really 1/R coordinate?\n\n        if a < b: atoms = (a, b)\n        else: atoms = (b, a)\n\n        SIMPLE.__init__(self, atoms, frozen, fixedEqVal)\n\n    def __str__(self):\n        if self.frozen: s = \'*\'\n        else: s = \' \'\n\n        if self.inverse: s += \'1/R\'\n        else: s += \'R\'\n\n        s += ""(%d,%d)"" % (self.A + 1, self.B + 1)\n        if self.fixedEqVal:\n            s += ""[%.4f]"" % (self.fixedEqVal * self.qShowFactor)\n        return s\n\n    def __eq__(self, other):\n        if self.atoms != other.atoms: return False\n        elif not isinstance(other, STRE): return False\n        elif self.inverse != other.inverse: return False\n        else: return True\n\n    @property\n    def inverse(self):\n        return self._inverse\n\n    @inverse.setter\n    def inverse(self, setval):\n        self._inverse = bool(setval)\n\n    def q(self, geom):\n        return v3d.dist(geom[self.A], geom[self.B])\n\n    def qShow(self, geom):\n        return self.qShowFactor * self.q(geom)\n\n    @property\n    def qShowFactor(self):\n        return BOHR2ANGSTROMS\n\n    @property\n    def fShowFactor(self):\n        return HARTREE2AJ / BOHR2ANGSTROMS\n\n    # If mini == False, dqdx is 1x(3*number of atoms in fragment).\n    # if mini == True, dqdx is 1x6.\n    def DqDx(self, geom, dqdx, mini=False):\n        check, eAB = v3d.eAB(geom[self.A], geom[self.B])  # A->B\n        if not check:\n            raise optExceptions.ALG_FAIL(""STRE.DqDx: could not normalize s vector"")\n\n        if mini:\n            startA = 0\n            startB = 3\n        else:\n            startA = 3 * self.A\n            startB = 3 * self.B\n\n        dqdx[startA:startA + 3] = -1 * eAB[0:3]\n        dqdx[startB:startB + 3] = eAB[0:3]\n\n        if self._inverse:\n            val = self.q(geom)\n            dqdx[startA:startA + 3] *= -1.0 * val * val  # -(1/R)^2 * (dR/da)\n            dqdx[startB:startB + 3] *= -1.0 * val * val\n\n        return\n\n    # Return derivative B matrix elements.  Matrix is cart X cart and passed in.\n    def Dq2Dx2(self, geom, dq2dx2):\n        check, eAB = v3d.eAB(geom[self.A], geom[self.B])  # A->B\n        if not check:\n            raise optExceptions.ALG_FAIL(""STRE.Dq2Dx2: could not normalize s vector"")\n\n        if not self._inverse:\n            length = self.q(geom)\n\n            for a in range(2):\n                for a_xyz in range(3):\n                    for b in range(2):\n                        for b_xyz in range(3):\n                            tval = (\n                                eAB[a_xyz] * eAB[b_xyz] - delta(a_xyz, b_xyz)) / length\n                            if a == b:\n                                tval *= -1.0\n                            dq2dx2[3*self.atoms[a]+a_xyz, \\\n                                3*self.atoms[b]+b_xyz] = tval\n\n        else:  # using 1/R\n            val = self.q(geom)\n\n            dqdx = np.zeros((3 * len(self.atoms)), float)\n            self.DqDx(geom, dqdx, mini=True)  # returned matrix is 1x6 for stre\n\n            for a in range(a):\n                for a_xyz in range(3):\n                    for b in range(b):\n                        for b_xyz in range(3):\n                            dq2dx2[3*self.atoms[a]+a_xyz, 3*self.atoms[b]+b_xyz] \\\n                                = 2.0 / val * dqdx[3*a+a_xyz] * dqdx[3*b+b_xyz]\n\n        return\n\n    def diagonalHessianGuess(self, geom, Z, connectivity=False, guessType=""SIMPLE""):\n        """""" Generates diagonal empirical Hessians in a.u. such as\n\t\t  Schlegel, Theor. Chim. Acta, 66, 333 (1984) and\n\t\t  Fischer and Almlof, J. Phys. Chem., 96, 9770 (1992).\n\t\t""""""\n        if guessType == ""SIMPLE"":\n            return 0.5\n\n        if guessType == ""SCHLEGEL"":\n            R = v3d.dist(geom[self.A], geom[self.B])\n            PerA = ZtoPeriod(Z[self.A])\n            PerB = ZtoPeriod(Z[self.B])\n\n            AA = 1.734\n            if PerA == 1:\n                if PerB == 1:\n                    BB = -0.244\n                elif PerB == 2:\n                    BB = 0.352\n                else:\n                    BB = 0.660\n            elif PerA == 2:\n                if PerB == 1:\n                    BB = 0.352\n                elif PerB == 2:\n                    BB = 1.085\n                else:\n                    BB = 1.522\n            else:\n                if PerB == 1:\n                    BB = 0.660\n                elif PerB == 2:\n                    BB = 1.522\n                else:\n                    BB = 2.068\n\n            F = AA / ((R - BB) * (R - BB) * (R - BB))\n            return F\n\n        elif guessType == ""FISCHER"":\n            Rcov = (\n                covRadii.R[int(Z[self.A])] + covRadii.R[int(Z[self.B])]) / BOHR2ANGSTROMS\n            R = v3d.dist(geom[self.A], geom[self.B])\n            AA = 0.3601\n            BB = 1.944\n            return AA * (np.exp(-BB * (R - Rcov)))\n\n        elif guessType == ""LINDH_SIMPLE"":\n            R = v3d.dist(geom[self.A], geom[self.B])\n            k_r = 0.45\n            return k_r * HguessLindhRho(Z[self.A], Z[self.B], R)\n\n        else:\n            print(""Warning: Hessian guess encountered unknown coordinate type.\\n"")\n            return 1.0\n\n\nclass HBOND(STRE):\n    def __str__(self):\n        if self.frozen: s = \'*\'\n        else: s = \' \'\n\n        if self.inverse: s += \'1/H\'\n        else: s += \'H\'\n\n        s += ""(%d,%d)"" % (self.A + 1, self.B + 1)\n        if self.fixedEqVal:\n            s += ""[%.4f]"" % self.fixedEqVal\n        return s\n\n    # overrides STRE eq in comparisons, regardless of order\n    def __eq__(self, other):\n        if self.atoms != other.atoms: return False\n        elif not isinstance(other, HBOND): return False\n        elif self.inverse != other.inverse: return False\n        else: return True\n\n    def diagonalHessianGuess(self, geom, Z, connectivity, guessType):\n        """""" Generates diagonal empirical Hessians in a.u. such as\n\t\t  Schlegel, Theor. Chim. Acta, 66, 333 (1984) and\n\t\t  Fischer and Almlof, J. Phys. Chem., 96, 9770 (1992).\n\t\t""""""\n        if guess == ""SIMPLE"":\n            return 0.1\n        else:\n            print(""Warning: Hessian guess encountered unknown coordinate type.\\n"")\n            return 1.0\n'"
Tutorials/13_Geometry_Optimization/opt_helper/tors.py,6,"b'from math import sqrt, fabs\n\nimport numpy as np\n\nfrom . import covRadii\nfrom . import optExceptions\nfrom . import v3d\nfrom .misc import HguessLindhRho\nfrom .simple import *\n\nFIX_VAL_NEAR_PI = 1.57\nfrom psi4 import constants\nBOHR2ANGSTROMS = constants.bohr2angstroms\nHARTREE2AJ = constants.hartree2aJ\n\nclass TORS(SIMPLE):\n    def __init__(self, a, b, c, d, frozen=False, fixedEqVal=None):\n\n        if a < d: atoms = (a, b, c, d)\n        else: atoms = (d, c, b, a)\n        self._near180 = 0\n\n        SIMPLE.__init__(self, atoms, frozen, fixedEqVal)\n\n    def __str__(self):\n        if self.frozen: s = \'*\'\n        else: s = \' \'\n\n        s += ""D""\n\n        s += ""(%d,%d,%d,%d)"" % (self.A + 1, self.B + 1, self.C + 1, self.D + 1)\n        if self.fixedEqVal:\n            s += ""[%.1f]"" % (self.fixedEqVal * self.qShowFactor)\n        return s\n\n    def __eq__(self, other):\n        if self.atoms != other.atoms: return False\n        elif not isinstance(other, TORS): return False\n        else: return True\n\n    @property\n    def near180(self):\n        return self._near180\n\n    # keeps track of orientation\n    def updateOrientation(self, geom):\n        tval = self.q(geom)\n        if tval > FIX_VAL_NEAR_PI:\n            self._near180 = +1\n        elif tval < -1 * FIX_VAL_NEAR_PI:\n            self._near180 = -1\n        else:\n            self._near180 = 0\n        return\n\n    @property\n    def qShowFactor(self):\n        return 180.0 / np.pi\n\n    def qShow(self, geom):  # return in degrees\n        return self.q(geom) * self.qShowFactor\n\n    @property\n    def fShowFactor(self):\n        return HARTREE2AJ * np.pi / 180.0\n\n    @staticmethod\n    def zeta(a, m, n):\n        if a == m: return 1\n        elif a == n: return -1\n        else: return 0\n\n    # compute angle and return value in radians\n    def q(self, geom):\n        check, tau = v3d.tors(geom[self.A], geom[self.B], geom[self.C], geom[self.D])\n        if not check:\n            raise optExceptions.ALG_FAIL(""TORS.q: unable to compute torsion value"")\n\n        # Extend values domain of torsion angles beyond pi or -pi, so that\n        # delta(values) can be calculated\n        if self._near180 == -1 and tau > FIX_VAL_NEAR_PI:\n            return tau - 2.0 * np.pi\n        elif self._near180 == +1 and tau < -1 * FIX_VAL_NEAR_PI:\n            return tau + 2.0 * np.pi\n        else:\n            return tau\n\n    def DqDx(self, geom, dqdx, mini=False):\n        u = geom[self.A] - geom[self.B]  # u=m-o eBA\n        v = geom[self.D] - geom[self.C]  # v=n-p eCD\n        w = geom[self.C] - geom[self.B]  # w=p-o eBC\n        Lu = v3d.norm(u)  # RBA\n        Lv = v3d.norm(v)  # RCD\n        Lw = v3d.norm(w)  # RBC\n        u *= 1.0 / Lu  # eBA\n        v *= 1.0 / Lv  # eCD\n        w *= 1.0 / Lw  # eBC\n\n        cos_u = v3d.dot(u, w)\n        cos_v = -v3d.dot(v, w)\n\n        # abort and leave zero if 0 or 180 angle\n        if 1.0 - cos_u * cos_u <= 1.0e-12 or 1.0 - cos_v * cos_v <= 1.0e-12:\n            return\n\n        sin_u = sqrt(1.0 - cos_u * cos_u)\n        sin_v = sqrt(1.0 - cos_v * cos_v)\n        uXw = v3d.cross(u, w)\n        vXw = v3d.cross(v, w)\n\n        # a = relative index; B = full index of atom\n        for a, B in enumerate(self.atoms):\n            for i in range(3):  #i=a_xyz\n                tval = 0.0\n\n                if a == 0 or a == 1:\n                    tval += TORS.zeta(a, 0, 1) * uXw[i] / (Lu * sin_u * sin_u)\n\n                if a == 2 or a == 3:\n                    tval += TORS.zeta(a, 2, 3) * vXw[i] / (Lv * sin_v * sin_v)\n\n                if a == 1 or a == 2:\n                    tval += TORS.zeta(a, 1, 2) * uXw[i] * cos_u / (Lw * sin_u * sin_u)\n\n                # ""+"" sign for zeta(a,2,1)) differs from JCP, 117, 9164 (2002)\n                if a == 1 or a == 2:\n                    tval += -TORS.zeta(a, 2, 1) * vXw[i] * cos_v / (Lw * sin_v * sin_v)\n\n                if not mini:\n                    dqdx[3 * B + i] = tval\n                else:\n                    dqdx[3 * a + i] = tval\n        return\n\n    # There are several errors in JCP, 22, 9164, (2002).\n    # I identified incorrect signs by making the equations invariant to reversing the atom indices\n    # (0,1,2,3) -> (3,2,1,0) and checking terms against finite differences.  Also, the last terms\n    # with sin^2 in the denominator are incorrectly given as only sin^1 in the paper.\n    # Torsion is m-o-p-n.  -RAK 2010\n    def Dq2Dx2(self, geom, dq2dx2):\n        u = geom[self.A] - geom[self.B]  # u=m-o eBA\n        v = geom[self.D] - geom[self.C]  # v=n-p eCD\n        w = geom[self.C] - geom[self.B]  # w=p-o eBC\n        Lu = v3d.norm(u)  # RBA\n        Lv = v3d.norm(v)  # RCD\n        Lw = v3d.norm(w)  # RBC\n        u *= 1.0 / Lu  # eBA\n        v *= 1.0 / Lv  # eCD\n        w *= 1.0 / Lw  # eBC\n\n        cos_u = v3d.dot(u, w)\n        cos_v = -v3d.dot(v, w)\n\n        # Abort and leave zero if 0 or 180 angle\n        if 1.0 - cos_u * cos_u <= 1.0e-12 or 1.0 - cos_v * cos_v <= 1.0e-12:\n            return\n\n        sin_u = sqrt(1.0 - cos_u * cos_u)\n        sin_v = sqrt(1.0 - cos_v * cos_v)\n        uXw = v3d.cross(u, w)\n        vXw = v3d.cross(v, w)\n\n        sinu4 = sin_u * sin_u * sin_u * sin_u\n        sinv4 = sin_v * sin_v * sin_v * sin_v\n        cosu3 = cos_u * cos_u * cos_u\n        cosv3 = cos_v * cos_v * cos_v\n\n        # int k; // cartesian ; not i or j\n        for a in range(4):\n            for b in range(a + 1):\n                for i in range(3):  # i = a_xyz\n                    for j in range(3):  # j=b_xyz\n                        tval = 0\n\n                        if (a == 0 and b == 0) or (a == 1 and b == 0) or (a == 1\n                                                                          and b == 1):\n                            tval +=  TORS.zeta(a,0,1) * TORS.zeta(b,0,1) * \\\n                             (uXw[i]*(w[j]*cos_u-u[j]) + uXw[j]*(w[i]*cos_u-u[i]))/(Lu*Lu*sinu4)\n\n                        # above under reversal of atom indices, u->v ; w->(-w) ; uXw->(-uXw)\n                        if (a == 3 and b == 3) or (a == 3 and b == 2) or (a == 2\n                                                                          and b == 2):\n                            tval += TORS.zeta(a,3,2) * TORS.zeta(b,3,2) * \\\n                             (vXw[i]*(w[j]*cos_v+v[j]) + vXw[j]*(w[i]*cos_v+v[i]))/(Lv*Lv*sinv4)\n\n                        if (a == 1 and b == 1) or (a == 2 and b == 1) or (\n                                a == 2 and b == 0) or (a == 1 and b == 0):\n                            tval += (TORS.zeta(a,0,1) * TORS.zeta(b,1,2) + TORS.zeta(a,2,1) * TORS.zeta(b,1,0))*\\\n                             (uXw[i] * (w[j] - 2*u[j]*cos_u + w[j]*cos_u*cos_u) +\n                              uXw[j] * (w[i] - 2*u[i]*cos_u + w[i]*cos_u*cos_u)) / (2*Lu*Lw*sinu4)\n\n                        if (a == 3 and b == 2) or (a == 3 and b == 1) or (\n                                a == 2 and b == 2) or (a == 2 and b == 1):\n                            tval += (TORS.zeta(a,3,2) * TORS.zeta(b,2,1) + TORS.zeta(a,1,2) * TORS.zeta(b,2,3))*\\\n                             (vXw[i] * (w[j] + 2*v[j]*cos_v + w[j]*cos_v*cos_v) +\n                              vXw[j] * (w[i] + 2*v[i]*cos_v + w[i]*cos_v*cos_v)) / (2*Lv*Lw*sinv4)\n\n                        if (a == 1 and b == 1) or (a == 2 and b == 2) or (a == 2\n                                                                          and b == 1):\n                            tval +=  TORS.zeta(a,1,2) * TORS.zeta(b,2,1) * \\\n                             (uXw[i]*(u[j] + u[j]*cos_u*cos_u - 3*w[j]*cos_u + w[j]*cosu3) +\n                              uXw[j]*(u[i] + u[i]*cos_u*cos_u - 3*w[i]*cos_u + w[i]*cosu3)) / (2*Lw*Lw*sinu4)\n\n                        if (a == 2 and b == 1) or (a == 2 and b == 2) or (a == 1\n                                                                          and b == 1):\n                            tval += TORS.zeta(a,2,1) * TORS.zeta(b,1,2) * \\\n                             (vXw[i]*(-v[j] - v[j]*cos_v*cos_v - 3*w[j]*cos_v + w[j]*cosv3) +\n                              vXw[j]*(-v[i] - v[i]*cos_v*cos_v - 3*w[i]*cos_v + w[i]*cosv3)) / (2*Lw*Lw*sinv4)\n\n                        if (a != b) and (i != j):\n                            if i != 0 and j != 0:\n                                k = 0  # k is unique coordinate not i or j\n                            elif i != 1 and j != 1:\n                                k = 1\n                            else:\n                                k = 2\n                            # TODO are these powers correct ?  -0.5^( |j-i| w[k]cos(u)-u[k], e.g. ?\n\n                            if a == 1 and b == 1:\n                                tval += TORS.zeta(a,0,1) * TORS.zeta(b,1,2) * (j-i) * \\\n                                  pow(-0.5, fabs(j-i)) * (+w[k]*cos_u - u[k]) / (Lu*Lw*sin_u*sin_u)\n\n                            if (a == 3 and b == 2) or (a == 3 and b == 1) or (\n                                    a == 2 and b == 2) or (a == 2 and b == 1):\n                                tval += TORS.zeta(a,3,2) * TORS.zeta(b,2,1) * (j-i) * \\\n                                  pow(-0.5, fabs(j-i)) * (-w[k]*cos_v - v[k]) / (Lv*Lw*sin_v*sin_v)\n\n                            if (a == 2 and b == 1) or (a == 2 and b == 0) or (\n                                    a == 1 and b == 1) or (a == 1 and b == 0):\n                                tval += TORS.zeta(a,2,1) * TORS.zeta(b,1,0) * (j-i) * \\\n                                  pow(-0.5, fabs(j-i)) * (-w[k]*cos_u + u[k]) / (Lu*Lw*sin_u*sin_u)\n\n                            if a == 2 and b == 2:\n                                tval += TORS.zeta(a,1,2) * TORS.zeta(b,2,3) * (j-i) * \\\n                                  pow(-0.5, fabs(j-i)) * (+w[k]*cos_v + v[k]) / (Lv*Lw*sin_v*sin_v)\n\n                        dq2dx2[3*self.atoms[a]+i][3*self.atoms[b]+j] = \\\n                        dq2dx2[3*self.atoms[b]+j][3*self.atoms[a]+i] = tval\n        return\n\n    def diagonalHessianGuess(self, geom, Z, connectivity=False, guessType=""SIMPLE""):\n        """""" Generates diagonal empirical Hessians in a.u. such as \n          Schlegel, Theor. Chim. Acta, 66, 333 (1984) and\n          Fischer and Almlof, J. Phys. Chem., 96, 9770 (1992).\n        """"""\n        if guessType == ""SIMPLE"":\n            return 0.1\n\n        elif guessType == ""SCHLEGEL"":\n            R_BC = v3d.dist(geom[self.B], geom[self.C])\n            Rcov = (\n                covRadii.R[int(Z[self.B])] + covRadii.R[int(Z[self.C])]) / BOHR2ANGSTROMS\n            a = 0.0023\n            b = 0.07\n            if R_BC > (Rcov + a / b):\n                b = 0.0\n            return a - (b * (R_BC - Rcov))\n\n        elif guessType == ""FISCHER"":\n            R = v3d.dist(geom[self.B], geom[self.C])\n            Rcov = (\n                covRadii.R[int(Z[self.B])] + covRadii.R[int(Z[self.C])]) / BOHR2ANGSTROMS\n            a = 0.0015\n            b = 14.0\n            c = 2.85\n            d = 0.57\n            e = 4.00\n\n            # Determine connectivity factor L\n            Brow = connectivity[self.B]\n            Crow = connectivity[self.C]\n            Bbonds = 0\n            Cbonds = 0\n            for i in range(len(Crow)):\n                Bbonds = Bbonds + Brow[i]\n                Cbonds = Cbonds + Crow[i]\n            L = Bbonds + Cbonds - 2\n            print(""Connectivity of central 2 torsional atoms - 2 = L = %d\\n"" % L)\n            return a + b * (np.power(L, d)) / (np.power(R * Rcov, e)) * (\n                np.exp(-c * (R - Rcov)))\n\n        elif guessType == ""LINDH_SIMPLE"":\n\n            R_AB = v3d.dist(geom[self.A], geom[self.B])\n            R_BC = v3d.dist(geom[self.B], geom[self.C])\n            R_CD = v3d.dist(geom[self.C], geom[self.D])\n            k_tau = 0.005\n\n            Lindh_Rho_AB = HguessLindhRho(Z[self.A], Z[self.B], R_AB)\n            Lindh_Rho_BC = HguessLindhRho(Z[self.B], Z[self.C], R_BC)\n            Lindh_Rho_CD = HguessLindhRho(Z[self.C], Z[self.D], R_CD)\n            return k_tau * Lindh_Rho_AB * Lindh_Rho_BC * Lindh_Rho_CD\n\n        else:\n            print(""Warning: Hessian guess encountered unknown coordinate type.\\n"")\n            return 1.0\n'"
Tutorials/13_Geometry_Optimization/opt_helper/v3d.py,2,"b'# Functions to compute properties of 3d vectors, including angles,\n# torsions, out-of-plane angles.  Several return False if the operation\n# cannot be completed numerically, as for example a torsion in which 3\n# points are collinear.\nimport numpy as np\nfrom math import sqrt, fabs, sin, acos, asin, fsum\n\nTORS_ANGLE_LIM = 0.017\nTORS_COS_TOL   = 1e-10\nDOT_PARALLEL_LIMIT = 1.e-10\n\ndef norm(v):\n    return sqrt(v[0] * v[0] + v[1] * v[1] + v[2] * v[2])\n\n\ndef dot(v1, v2, length=None):\n    if length is None:\n        return v1[0] * v2[0] + v1[1] * v2[1] + v1[2] * v2[2]\n    else:\n        return fsum([v1[i] * v2[i] for i in range(length)])\n\n\ndef dist(v1, v2):\n    return sqrt((v2[0] - v1[0])**2 + (v2[1] - v1[1])**2 + (v2[2] - v1[2])**2)\n\n\n# Normalize vector in place.  If norm exceeds thresholds, don\'t normalize and return False..\ndef normalize(v1, Rmin=1.0e-8, Rmax=1.0e15):\n    n = norm(v1)\n    if n < Rmin or n > Rmax:\n        return False\n    else:\n        v1 /= n\n        return True\n\n\ndef axpy(a, X, Y):\n    Z = np.zeros(Y.shape, float)\n    Z = a * X + Y\n    return Z\n\n\n# Compute and return normalized vector from point p1 to point p2.\n# If norm is too small, don\'t normalize and return check as False.\ndef eAB(p1, p2):\n    eAB = p2 - p1\n    check = normalize(eAB)\n    return check, eAB\n\n\n# Compute and return cross-product.\ndef cross(u, v):\n    X = np.zeros(3, float)\n    X[0] = u[1] * v[2] - u[2] * v[1]\n    X[1] = -u[0] * v[2] + u[2] * v[0]\n    X[2] = u[0] * v[1] - u[1] * v[0]\n    return X\n\n\n# Are two vectors parallel?\ndef are_parallel(u, v):\n    if fabs(dot(u, v) - 1.0e0) < DOT_PARALLEL_LIMIT: return True\n    else: return False\n\n\n# Are two vectors parallel?\ndef are_antiparallel(u, v):\n    if fabs(dot(u, v) + 1.0e0) < DOT_PARALLEL_LIMIT: return True\n    else: return False\n\n\ndef are_parallel_or_antiparallel(u, v):\n    return are_parallel(u, v) or are_antiparallel(u, v)\n\n\n# Compute and return angle in radians A-B-C (between vector B->A and vector B->C)\n# If points are absurdly close or far apart, returns False\n# tol is nearness of cos to 1/-1 to set angle 0/pi.\n# Returns boolean check and value.\ndef angle(A, B, C, tol=1.0e-14):\n    check, eBA = eAB(B, A)\n    if not check:\n        print(""Warning: could not normalize eBA in angle()\\n"")\n        return False, 0.0\n\n    check, eBC = eAB(B, C)\n    if not check:\n        print(""Warning: could not normalize eBC in angle()\\n"")\n        return False, 0.0\n\n    dotprod = dot(eBA, eBC)\n\n    if dotprod > 1.0 - tol:\n        phi = 0.0\n    elif dotprod < -1.0 + tol:\n        phi = acos(-1.0)\n    else:\n        phi = acos(dotprod)\n\n    return True, phi\n\n\n# Compute and return angle in dihedral angle in radians A-B-C-D\n# returns false if bond angles are too large for good torsion definition\ndef tors(A, B, C, D):\n    phi_lim = TORS_ANGLE_LIM\n    tors_cos_tol   = TORS_COS_TOL\n\n    # Form e vectors\n    check1, EAB = eAB(A, B)\n    check2, EBC = eAB(B, C)\n    check3, ECD = eAB(C, D)\n\n    if not check1 or not check2 or not check3:\n        return False, 0.0\n\n    # Compute bond angles\n    check1, phi_123 = angle(A, B, C)\n    check2, phi_234 = angle(B, C, D)\n\n    if not check1 or not check2:\n        return False, 0.0\n\n    if phi_123 < phi_lim or phi_123 > (acos(-1) - phi_lim) or \\\n       phi_234 < phi_lim or phi_234 > (acos(-1) - phi_lim):\n        return False, 0.0\n\n    tmp = cross(EAB, EBC)\n    tmp2 = cross(EBC, ECD)\n    tval = dot(tmp, tmp2) / (sin(phi_123) * sin(phi_234))\n\n    if tval >= 1.0 - tors_cos_tol:  # accounts for numerical leaking out of range\n        tau = 0.0\n    elif tval <= -1.0 + tors_cos_tol:\n        tau = acos(-1)\n    else:\n        tau = acos(tval)\n\n    # determine sign of torsion ; this convention matches Wilson, Decius and Cross\n    if tau != acos(-1):  # no torsion will get value of -pi; Range is (-pi,pi].\n        tmp = cross(EBC, ECD)\n        tval = dot(EAB, tmp)\n        if tval < 0:\n            tau *= -1\n\n    return True, tau\n\n\n# Compute and return angle in dihedral angle in radians A-B-C-D\n# returns false if bond angles are too large for good torsion definition\ndef oofp(A, B, C, D):\n    check1, eBA = eAB(B, A)\n    check2, eBC = eAB(B, C)\n    check3, eBD = eAB(B, D)\n    if not check1 or not check2 or not check3:\n        return False, 0.0\n\n    check1, phi_CBD = angle(C, B, D)\n    if not check1:\n        return False, 0.0\n\n    # This shouldn\'t happen unless angle B-C-D -> 0,\n    if sin(phi_CBD) < op.Params.v3d_tors_cos_tol:  #reusing parameter\n        return False, 0.0\n\n    dotprod = dot(cross(eBC, eBD), eBA) / sin(phi_CBD)\n\n    if dotprod > 1.0: tau = acos(-1)\n    elif dotprod < -1.0: tau = -1 * acos(-1)\n    else: tau = asin(dotprod)\n    return True, tau\n'"
