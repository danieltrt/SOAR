file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python\n\nimport os\nimport platform\nimport shutil\nimport sys\nfrom distutils.command.config import config as _config\nfrom subprocess import check_output\n\nfrom setuptools import Command, find_packages, setup\nfrom setuptools.command.build_ext import build_ext as _build_ext\nfrom setuptools.extension import Extension\n\nimport versioneer\n\n\nclass config(_config):\n    def run(self):\n        from bn_config import create_config_h\n\n        create_config_h(self)\n\n\nclass clean(Command):\n    user_options = [(""all"", ""a"", """")]\n\n    def initialize_options(self):\n        self.all = True\n        self.delete_dirs = []\n        self.delete_files = []\n\n        for root, dirs, files in os.walk(""bottleneck""):\n            for d in dirs:\n                if d == ""__pycache__"":\n                    self.delete_dirs.append(os.path.join(root, d))\n\n            if ""__pycache__"" in root:\n                continue\n\n            for f in files:\n                if f.endswith("".pyc"") or f.endswith("".so""):\n                    self.delete_files.append(os.path.join(root, f))\n\n                if f.endswith("".c"") and ""template"" in f:\n                    generated_file = os.path.join(root, f.replace(""_template"", """"))\n                    if os.path.exists(generated_file):\n                        self.delete_files.append(generated_file)\n\n        config_h = ""bottleneck/src/bn_config.h""\n        if os.path.exists(config_h):\n            self.delete_files.append(config_h)\n\n        if os.path.exists(""build""):\n            self.delete_dirs.append(""build"")\n\n    def finalize_options(self):\n        pass\n\n    def run(self):\n        for delete_dir in self.delete_dirs:\n            shutil.rmtree(delete_dir)\n        for delete_file in self.delete_files:\n            os.unlink(delete_file)\n\n\n# workaround for installing bottleneck when numpy is not present\nclass build_ext(_build_ext):\n    # taken from: stackoverflow.com/questions/19919905/\n    # how-to-bootstrap-numpy-installation-in-setup-py#21621689\n    def finalize_options(self):\n        _build_ext.finalize_options(self)\n        # prevent numpy from thinking it is still in its setup process\n        if sys.version_info < (3,):\n            import __builtin__ as builtins\n        else:\n            import builtins\n        builtins.__NUMPY_SETUP__ = False\n        import numpy\n\n        # place numpy includes first, see gh #156\n        self.include_dirs.insert(0, numpy.get_include())\n        self.include_dirs.append(""bottleneck/src"")\n\n    def build_extensions(self):\n        from bn_template import make_c_files\n\n        self.run_command(""config"")\n        make_c_files()\n\n        _build_ext.build_extensions(self)\n\n\ncmdclass = versioneer.get_cmdclass()\ncmdclass[""build_ext""] = build_ext\ncmdclass[""clean""] = clean\ncmdclass[""config""] = config\n\n\ndef is_old_gcc() -> bool:\n    if sys.platform != ""win32"":\n        gcc_version = check_output([""gcc"", ""-dumpversion""]).decode(""utf8"").split(""."")[0]\n        if int(gcc_version) < 5:\n            return True\n    return False\n\n\nIS_OLD_GCC = is_old_gcc()\nDEFAULT_FLAGS = [""-O2""]\nif IS_OLD_GCC:\n    DEFAULT_FLAGS.append(""-std=gnu11"")\n\n# Add our template path to the path so that we don\'t have a circular reference\n# of working install to be able to re-compile\nsys.path.append(os.path.join(os.path.dirname(__file__), ""bottleneck/src""))\n\n\ndef get_cpu_arch_flags():\n    if platform.processor() == ""ppc64le"":\n        # Needed to support SSE2 intrinsics\n        return [""-DNO_WARN_X86_INTRINSICS""]\n    else:\n        return []\n\n\ndef prepare_modules():\n    base_includes = [\n        ""bottleneck/src/bottleneck.h"",\n        ""bottleneck/src/bn_config.h"",\n        ""bottleneck/src/iterators.h"",\n    ]\n\n    arch_flags = get_cpu_arch_flags()\n\n    ext = [\n        Extension(\n            ""bottleneck.reduce"",\n            sources=[""bottleneck/src/reduce.c""],\n            depends=base_includes,\n            extra_compile_args=DEFAULT_FLAGS + arch_flags,\n        )\n    ]\n    ext += [\n        Extension(\n            ""bottleneck.move"",\n            sources=[\n                ""bottleneck/src/move.c"",\n                ""bottleneck/src/move_median/move_median.c"",\n            ],\n            depends=base_includes + [""bottleneck/src/move_median/move_median.h""],\n            extra_compile_args=DEFAULT_FLAGS + arch_flags,\n        )\n    ]\n    ext += [\n        Extension(\n            ""bottleneck.nonreduce"",\n            sources=[""bottleneck/src/nonreduce.c""],\n            depends=base_includes,\n            extra_compile_args=DEFAULT_FLAGS + arch_flags,\n        )\n    ]\n    ext += [\n        Extension(\n            ""bottleneck.nonreduce_axis"",\n            sources=[""bottleneck/src/nonreduce_axis.c""],\n            depends=base_includes,\n            extra_compile_args=DEFAULT_FLAGS + arch_flags,\n        )\n    ]\n    return ext\n\n\ndef get_long_description():\n    with open(""README.rst"", ""r"") as fid:\n        long_description = fid.read()\n    idx = max(0, long_description.find(""Bottleneck is a collection""))\n    long_description = long_description[idx:]\n    return long_description\n\n\nCLASSIFIERS = [\n    ""Development Status :: 5 - Production/Stable"",\n    ""Environment :: Console"",\n    ""Intended Audience :: Science/Research"",\n    ""Intended Audience :: Financial and Insurance Industry"",\n    ""License :: OSI Approved :: BSD License"",\n    ""Operating System :: OS Independent"",\n    ""Programming Language :: C"",\n    ""Programming Language :: Python"",\n    ""Programming Language :: Python :: 3"",\n    ""Programming Language :: Python :: 3.6"",\n    ""Programming Language :: Python :: 3.7"",\n    ""Programming Language :: Python :: 3.8"",\n    ""Topic :: Scientific/Engineering"",\n    ""Topic :: Scientific/Engineering"",\n]\n\n\nmetadata = dict(\n    name=""Bottleneck"",\n    maintainer=""Christopher Whelan"",\n    maintainer_email=""bottle-neck@googlegroups.com"",\n    description=""Fast NumPy array functions written in C"",\n    long_description=get_long_description(),\n    long_description_content_type=""text/x-rst"",\n    url=""https://github.com/pydata/bottleneck"",\n    download_url=""http://pypi.python.org/pypi/Bottleneck"",\n    license=""Simplified BSD"",\n    classifiers=CLASSIFIERS,\n    platforms=""OS Independent"",\n    version=versioneer.get_version(),\n    packages=find_packages(),\n    package_data={""bottleneck"": [""LICENSE"", ""tests/data/**/*.c""]},\n    requires=[""numpy""],\n    install_requires=[""numpy""],\n    extras_require={""doc"": [""numpydoc"", ""sphinx"", ""gitpython""]},\n    cmdclass=cmdclass,\n    setup_requires=[""numpy""],\n    ext_modules=prepare_modules(),\n    python_requires="">=3.6"",\n    zip_safe=False,\n)\n\n\nsetup(**metadata)\n'"
versioneer.py,0,"b'# Version: 0.18\n\n""""""The Versioneer - like a rocketeer, but for versions.\n\nThe Versioneer\n==============\n\n* like a rocketeer, but for versions!\n* https://github.com/warner/python-versioneer\n* Brian Warner\n* License: Public Domain\n* Compatible With: python2.6, 2.7, 3.2, 3.3, 3.4, 3.5, 3.6, and pypy\n* [![Latest Version]\n(https://pypip.in/version/versioneer/badge.svg?style=flat)\n](https://pypi.python.org/pypi/versioneer/)\n* [![Build Status]\n(https://travis-ci.org/warner/python-versioneer.png?branch=master)\n](https://travis-ci.org/warner/python-versioneer)\n\nThis is a tool for managing a recorded version number in distutils-based\npython projects. The goal is to remove the tedious and error-prone ""update\nthe embedded version string"" step from your release process. Making a new\nrelease should be as easy as recording a new tag in your version-control\nsystem, and maybe making new tarballs.\n\n\n## Quick Install\n\n* `pip install versioneer` to somewhere to your $PATH\n* add a `[versioneer]` section to your setup.cfg (see below)\n* run `versioneer install` in your source tree, commit the results\n\n## Version Identifiers\n\nSource trees come from a variety of places:\n\n* a version-control system checkout (mostly used by developers)\n* a nightly tarball, produced by build automation\n* a snapshot tarball, produced by a web-based VCS browser, like github\'s\n  ""tarball from tag"" feature\n* a release tarball, produced by ""setup.py sdist"", distributed through PyPI\n\nWithin each source tree, the version identifier (either a string or a number,\nthis tool is format-agnostic) can come from a variety of places:\n\n* ask the VCS tool itself, e.g. ""git describe"" (for checkouts), which knows\n  about recent ""tags"" and an absolute revision-id\n* the name of the directory into which the tarball was unpacked\n* an expanded VCS keyword ($Id$, etc)\n* a `_version.py` created by some earlier build step\n\nFor released software, the version identifier is closely related to a VCS\ntag. Some projects use tag names that include more than just the version\nstring (e.g. ""myproject-1.2"" instead of just ""1.2""), in which case the tool\nneeds to strip the tag prefix to extract the version identifier. For\nunreleased software (between tags), the version identifier should provide\nenough information to help developers recreate the same tree, while also\ngiving them an idea of roughly how old the tree is (after version 1.2, before\nversion 1.3). Many VCS systems can report a description that captures this,\nfor example `git describe --tags --dirty --always` reports things like\n""0.7-1-g574ab98-dirty"" to indicate that the checkout is one revision past the\n0.7 tag, has a unique revision id of ""574ab98"", and is ""dirty"" (it has\nuncommitted changes.\n\nThe version identifier is used for multiple purposes:\n\n* to allow the module to self-identify its version: `myproject.__version__`\n* to choose a name and prefix for a \'setup.py sdist\' tarball\n\n## Theory of Operation\n\nVersioneer works by adding a special `_version.py` file into your source\ntree, where your `__init__.py` can import it. This `_version.py` knows how to\ndynamically ask the VCS tool for version information at import time.\n\n`_version.py` also contains `$Revision$` markers, and the installation\nprocess marks `_version.py` to have this marker rewritten with a tag name\nduring the `git archive` command. As a result, generated tarballs will\ncontain enough information to get the proper version.\n\nTo allow `setup.py` to compute a version too, a `versioneer.py` is added to\nthe top level of your source tree, next to `setup.py` and the `setup.cfg`\nthat configures it. This overrides several distutils/setuptools commands to\ncompute the version when invoked, and changes `setup.py build` and `setup.py\nsdist` to replace `_version.py` with a small static file that contains just\nthe generated version data.\n\n## Installation\n\nSee [INSTALL.md](./INSTALL.md) for detailed installation instructions.\n\n## Version-String Flavors\n\nCode which uses Versioneer can learn about its version string at runtime by\nimporting `_version` from your main `__init__.py` file and running the\n`get_versions()` function. From the ""outside"" (e.g. in `setup.py`), you can\nimport the top-level `versioneer.py` and run `get_versions()`.\n\nBoth functions return a dictionary with different flavors of version\ninformation:\n\n* `[\'version\']`: A condensed version string, rendered using the selected\n  style. This is the most commonly used value for the project\'s version\n  string. The default ""pep440"" style yields strings like `0.11`,\n  `0.11+2.g1076c97`, or `0.11+2.g1076c97.dirty`. See the ""Styles"" section\n  below for alternative styles.\n\n* `[\'full-revisionid\']`: detailed revision identifier. For Git, this is the\n  full SHA1 commit id, e.g. ""1076c978a8d3cfc70f408fe5974aa6c092c949ac"".\n\n* `[\'date\']`: Date and time of the latest `HEAD` commit. For Git, it is the\n  commit date in ISO 8601 format. This will be None if the date is not\n  available.\n\n* `[\'dirty\']`: a boolean, True if the tree has uncommitted changes. Note that\n  this is only accurate if run in a VCS checkout, otherwise it is likely to\n  be False or None\n\n* `[\'error\']`: if the version string could not be computed, this will be set\n  to a string describing the problem, otherwise it will be None. It may be\n  useful to throw an exception in setup.py if this is set, to avoid e.g.\n  creating tarballs with a version string of ""unknown"".\n\nSome variants are more useful than others. Including `full-revisionid` in a\nbug report should allow developers to reconstruct the exact code being tested\n(or indicate the presence of local changes that should be shared with the\ndevelopers). `version` is suitable for display in an ""about"" box or a CLI\n`--version` output: it can be easily compared against release notes and lists\nof bugs fixed in various releases.\n\nThe installer adds the following text to your `__init__.py` to place a basic\nversion in `YOURPROJECT.__version__`:\n\n    from ._version import get_versions\n    __version__ = get_versions()[\'version\']\n    del get_versions\n\n## Styles\n\nThe setup.cfg `style=` configuration controls how the VCS information is\nrendered into a version string.\n\nThe default style, ""pep440"", produces a PEP440-compliant string, equal to the\nun-prefixed tag name for actual releases, and containing an additional ""local\nversion"" section with more detail for in-between builds. For Git, this is\nTAG[+DISTANCE.gHEX[.dirty]] , using information from `git describe --tags\n--dirty --always`. For example ""0.11+2.g1076c97.dirty"" indicates that the\ntree is like the ""1076c97"" commit but has uncommitted changes ("".dirty""), and\nthat this commit is two revisions (""+2"") beyond the ""0.11"" tag. For released\nsoftware (exactly equal to a known tag), the identifier will only contain the\nstripped tag, e.g. ""0.11"".\n\nOther styles are available. See [details.md](details.md) in the Versioneer\nsource tree for descriptions.\n\n## Debugging\n\nVersioneer tries to avoid fatal errors: if something goes wrong, it will tend\nto return a version of ""0+unknown"". To investigate the problem, run `setup.py\nversion`, which will run the version-lookup code in a verbose mode, and will\ndisplay the full contents of `get_versions()` (including the `error` string,\nwhich may help identify what went wrong).\n\n## Known Limitations\n\nSome situations are known to cause problems for Versioneer. This details the\nmost significant ones. More can be found on Github\n[issues page](https://github.com/warner/python-versioneer/issues).\n\n### Subprojects\n\nVersioneer has limited support for source trees in which `setup.py` is not in\nthe root directory (e.g. `setup.py` and `.git/` are *not* siblings). The are\ntwo common reasons why `setup.py` might not be in the root:\n\n* Source trees which contain multiple subprojects, such as\n  [Buildbot](https://github.com/buildbot/buildbot), which contains both\n  ""master"" and ""slave"" subprojects, each with their own `setup.py`,\n  `setup.cfg`, and `tox.ini`. Projects like these produce multiple PyPI\n  distributions (and upload multiple independently-installable tarballs).\n* Source trees whose main purpose is to contain a C library, but which also\n  provide bindings to Python (and perhaps other langauges) in subdirectories.\n\nVersioneer will look for `.git` in parent directories, and most operations\nshould get the right version string. However `pip` and `setuptools` have bugs\nand implementation details which frequently cause `pip install .` from a\nsubproject directory to fail to find a correct version string (so it usually\ndefaults to `0+unknown`).\n\n`pip install --editable .` should work correctly. `setup.py install` might\nwork too.\n\nPip-8.1.1 is known to have this problem, but hopefully it will get fixed in\nsome later version.\n\n[Bug #38](https://github.com/warner/python-versioneer/issues/38) is tracking\nthis issue. The discussion in\n[PR #61](https://github.com/warner/python-versioneer/pull/61) describes the\nissue from the Versioneer side in more detail.\n[pip PR#3176](https://github.com/pypa/pip/pull/3176) and\n[pip PR#3615](https://github.com/pypa/pip/pull/3615) contain work to improve\npip to let Versioneer work correctly.\n\nVersioneer-0.16 and earlier only looked for a `.git` directory next to the\n`setup.cfg`, so subprojects were completely unsupported with those releases.\n\n### Editable installs with setuptools <= 18.5\n\n`setup.py develop` and `pip install --editable .` allow you to install a\nproject into a virtualenv once, then continue editing the source code (and\ntest) without re-installing after every change.\n\n""Entry-point scripts"" (`setup(entry_points={""console_scripts"": ..})`) are a\nconvenient way to specify executable scripts that should be installed along\nwith the python package.\n\nThese both work as expected when using modern setuptools. When using\nsetuptools-18.5 or earlier, however, certain operations will cause\n`pkg_resources.DistributionNotFound` errors when running the entrypoint\nscript, which must be resolved by re-installing the package. This happens\nwhen the install happens with one version, then the egg_info data is\nregenerated while a different version is checked out. Many setup.py commands\ncause egg_info to be rebuilt (including `sdist`, `wheel`, and installing into\na different virtualenv), so this can be surprising.\n\n[Bug #83](https://github.com/warner/python-versioneer/issues/83) describes\nthis one, but upgrading to a newer version of setuptools should probably\nresolve it.\n\n### Unicode version strings\n\nWhile Versioneer works (and is continually tested) with both Python 2 and\nPython 3, it is not entirely consistent with bytes-vs-unicode distinctions.\nNewer releases probably generate unicode version strings on py2. It\'s not\nclear that this is wrong, but it may be surprising for applications when then\nwrite these strings to a network connection or include them in bytes-oriented\nAPIs like cryptographic checksums.\n\n[Bug #71](https://github.com/warner/python-versioneer/issues/71) investigates\nthis question.\n\n\n## Updating Versioneer\n\nTo upgrade your project to a new release of Versioneer, do the following:\n\n* install the new Versioneer (`pip install -U versioneer` or equivalent)\n* edit `setup.cfg`, if necessary, to include any new configuration settings\n  indicated by the release notes. See [UPGRADING](./UPGRADING.md) for details.\n* re-run `versioneer install` in your source tree, to replace\n  `SRC/_version.py`\n* commit any changed files\n\n## Future Directions\n\nThis tool is designed to make it easily extended to other version-control\nsystems: all VCS-specific components are in separate directories like\nsrc/git/ . The top-level `versioneer.py` script is assembled from these\ncomponents by running make-versioneer.py . In the future, make-versioneer.py\nwill take a VCS name as an argument, and will construct a version of\n`versioneer.py` that is specific to the given VCS. It might also take the\nconfiguration arguments that are currently provided manually during\ninstallation by editing setup.py . Alternatively, it might go the other\ndirection and include code from all supported VCS systems, reducing the\nnumber of intermediate scripts.\n\n\n## License\n\nTo make Versioneer easier to embed, all its code is dedicated to the public\ndomain. The `_version.py` that it creates is also in the public domain.\nSpecifically, both are released under the Creative Commons ""Public Domain\nDedication"" license (CC0-1.0), as described in\nhttps://creativecommons.org/publicdomain/zero/1.0/ .\n\n""""""\n\nfrom __future__ import print_function\n\nimport errno\nimport json\nimport os\nimport re\nimport subprocess\nimport sys\n\ntry:\n    import configparser\nexcept ImportError:\n    import ConfigParser as configparser\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_root():\n    """"""Get the project root directory.\n\n    We require that all commands are run from the project root, i.e. the\n    directory that contains setup.py, setup.cfg, and versioneer.py .\n    """"""\n    root = os.path.realpath(os.path.abspath(os.getcwd()))\n    setup_py = os.path.join(root, ""setup.py"")\n    versioneer_py = os.path.join(root, ""versioneer.py"")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        # allow \'python path/to/setup.py COMMAND\'\n        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))\n        setup_py = os.path.join(root, ""setup.py"")\n        versioneer_py = os.path.join(root, ""versioneer.py"")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        err = (\n            ""Versioneer was unable to run the project root directory. ""\n            ""Versioneer requires setup.py to be executed from ""\n            ""its immediate directory (like \'python setup.py COMMAND\'), ""\n            ""or in a way that lets it use sys.argv[0] to find the root ""\n            ""(like \'python path/to/setup.py COMMAND\').""\n        )\n        raise VersioneerBadRootError(err)\n    try:\n        # Certain runtime workflows (setup.py install/develop in a setuptools\n        # tree) execute all dependencies in a single python process, so\n        # ""versioneer"" may be imported multiple times, and python\'s shared\n        # module-import table will cache the first one. So we can\'t use\n        # os.path.dirname(__file__), as that will find whichever\n        # versioneer.py was first imported, even in later projects.\n        me = os.path.realpath(os.path.abspath(__file__))\n        me_dir = os.path.normcase(os.path.splitext(me)[0])\n        vsr_dir = os.path.normcase(os.path.splitext(versioneer_py)[0])\n        if me_dir != vsr_dir:\n            print(\n                ""Warning: build in %s is using versioneer.py from %s""\n                % (os.path.dirname(me), versioneer_py)\n            )\n    except NameError:\n        pass\n    return root\n\n\ndef get_config_from_root(root):\n    """"""Read the project setup.cfg file to determine Versioneer config.""""""\n    # This might raise EnvironmentError (if setup.cfg is missing), or\n    # configparser.NoSectionError (if it lacks a [versioneer] section), or\n    # configparser.NoOptionError (if it lacks ""VCS=""). See the docstring at\n    # the top of versioneer.py for instructions on writing your setup.cfg .\n    setup_cfg = os.path.join(root, ""setup.cfg"")\n    parser = configparser.SafeConfigParser()\n    with open(setup_cfg, ""r"") as f:\n        parser.readfp(f)\n    VCS = parser.get(""versioneer"", ""VCS"")  # mandatory\n\n    def get(parser, name):\n        if parser.has_option(""versioneer"", name):\n            return parser.get(""versioneer"", name)\n        return None\n\n    cfg = VersioneerConfig()\n    cfg.VCS = VCS\n    cfg.style = get(parser, ""style"") or """"\n    cfg.versionfile_source = get(parser, ""versionfile_source"")\n    cfg.versionfile_build = get(parser, ""versionfile_build"")\n    cfg.tag_prefix = get(parser, ""tag_prefix"")\n    if cfg.tag_prefix in (""\'\'"", \'""""\'):\n        cfg.tag_prefix = """"\n    cfg.parentdir_prefix = get(parser, ""parentdir_prefix"")\n    cfg.verbose = get(parser, ""verbose"")\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\n# these dictionaries contain VCS-specific tools\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen(\n                [c] + args,\n                cwd=cwd,\n                env=env,\n                stdout=subprocess.PIPE,\n                stderr=(subprocess.PIPE if hide_stderr else None),\n            )\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %s"" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %s"" % (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %s (error)"" % dispcmd)\n            print(""stdout was %s"" % stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\nLONG_VERSION_PY[\n    ""git""\n] = \'\'\'\n# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain. Generated by\n# versioneer-0.18 (https://github.com/warner/python-versioneer)\n\n""""""Git implementation of _version.py.""""""\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\n\n\ndef get_keywords():\n    """"""Get the keywords needed to look up the version information.""""""\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = ""%(DOLLAR)sFormat:%%d%(DOLLAR)s""\n    git_full = ""%(DOLLAR)sFormat:%%H%(DOLLAR)s""\n    git_date = ""%(DOLLAR)sFormat:%%ci%(DOLLAR)s""\n    keywords = {""refnames"": git_refnames, ""full"": git_full, ""date"": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_config():\n    """"""Create, populate and return the VersioneerConfig() object.""""""\n    # these strings are filled in when \'setup.py versioneer\' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = ""git""\n    cfg.style = ""%(STYLE)s""\n    cfg.tag_prefix = ""%(TAG_PREFIX)s""\n    cfg.parentdir_prefix = ""%(PARENTDIR_PREFIX)s""\n    cfg.versionfile_source = ""%(VERSIONFILE_SOURCE)s""\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n                env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %%s"" %% dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %%s"" %% (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %%s (error)"" %% dispcmd)\n            print(""stdout was %%s"" %% stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {""version"": dirname[len(parentdir_prefix):],\n                    ""full-revisionid"": None,\n                    ""dirty"": False, ""error"": None, ""date"": None}\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(""Tried directories %%s but none started with prefix %%s"" %%\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %%d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r\'\\d\', r)])\n        if verbose:\n            print(""discarding \'%%s\', no digits"" %% "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %%s"" %% "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(""picking %%s"" %% r)\n            return {""version"": r,\n                    ""full-revisionid"": keywords[""full""].strip(),\n                    ""dirty"": False, ""error"": None,\n                    ""date"": date}\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {""version"": ""0+unknown"",\n            ""full-revisionid"": keywords[""full""].strip(),\n            ""dirty"": False, ""error"": ""no suitable tags"", ""date"": None}\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n                          hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %%s not under git control"" %% root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty"",\n                                          ""--always"", ""--long"",\n                                          ""--match"", ""%%s*"" %% tag_prefix],\n                                   cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\'^(.+)-(\\d+)-g([0-9a-f]+)$\', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = (""unable to parse git-describe output: \'%%s\'""\n                               %% describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%%s\' doesn\'t start with prefix \'%%s\'""\n                print(fmt %% (full_tag, tag_prefix))\n            pieces[""error""] = (""tag \'%%s\' doesn\'t start with prefix \'%%s\'""\n                               %% (full_tag, tag_prefix))\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n                                    cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%%ci"", ""HEAD""],\n                       cwd=root)[0].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%%d.g%%s"" %% (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%%d.g%%s"" %% (pieces[""distance""],\n                                          pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%%d"" %% pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%%d"" %% pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%%d"" %% pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%%s"" %% pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%%d"" %% pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%%s"" %% pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%%d"" %% pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%%d"" %% pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%%d-g%%s"" %% (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%%d-g%%s"" %% (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {""version"": ""unknown"",\n                ""full-revisionid"": pieces.get(""long""),\n                ""dirty"": None,\n                ""error"": pieces[""error""],\n                ""date"": None}\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%%s\'"" %% style)\n\n    return {""version"": rendered, ""full-revisionid"": pieces[""long""],\n            ""dirty"": pieces[""dirty""], ""error"": None,\n            ""date"": pieces.get(""date"")}\n\n\ndef get_versions():\n    """"""Get version information or return default if unable to do so.""""""\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don\'t do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split(\'/\'):\n            root = os.path.dirname(root)\n    except NameError:\n        return {""version"": ""0+unknown"", ""full-revisionid"": None,\n                ""dirty"": None,\n                ""error"": ""unable to find root of source tree"",\n                ""date"": None}\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {""version"": ""0+unknown"", ""full-revisionid"": None,\n            ""dirty"": None,\n            ""error"": ""unable to compute version"", ""date"": None}\n\'\'\'\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG) :] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r""\\d"", r)])\n        if verbose:\n            print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %s"" % "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix) :]\n            if verbose:\n                print(""picking %s"" % r)\n            return {\n                ""version"": r,\n                ""full-revisionid"": keywords[""full""].strip(),\n                ""dirty"": False,\n                ""error"": None,\n                ""date"": date,\n            }\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {\n        ""version"": ""0+unknown"",\n        ""full-revisionid"": keywords[""full""].strip(),\n        ""dirty"": False,\n        ""error"": ""no suitable tags"",\n        ""date"": None,\n    }\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root, hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %s not under git control"" % root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(\n        GITS,\n        [\n            ""describe"",\n            ""--tags"",\n            ""--dirty"",\n            ""--always"",\n            ""--long"",\n            ""--match"",\n            ""%s*"" % tag_prefix,\n        ],\n        cwd=root,\n    )\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[: git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r""^(.+)-(\\d+)-g([0-9a-f]+)$"", git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = ""unable to parse git-describe output: \'%s\'"" % describe_out\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                print(fmt % (full_tag, tag_prefix))\n            pieces[""error""] = ""tag \'%s\' doesn\'t start with prefix \'%s\'"" % (\n                full_tag,\n                tag_prefix,\n            )\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix) :]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""], cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""], cwd=root)[\n        0\n    ].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef do_vcs_install(manifest_in, versionfile_source, ipy):\n    """"""Git-specific installation logic for Versioneer.\n\n    For Git, this means creating/changing .gitattributes to mark _version.py\n    for export-subst keyword substitution.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n    files = [manifest_in, versionfile_source]\n    if ipy:\n        files.append(ipy)\n    try:\n        me = __file__\n        if me.endswith("".pyc"") or me.endswith("".pyo""):\n            me = os.path.splitext(me)[0] + "".py""\n        versioneer_file = os.path.relpath(me)\n    except NameError:\n        versioneer_file = ""versioneer.py""\n    files.append(versioneer_file)\n    present = False\n    try:\n        f = open("".gitattributes"", ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(versionfile_source):\n                if ""export-subst"" in line.strip().split()[1:]:\n                    present = True\n        f.close()\n    except EnvironmentError:\n        pass\n    if not present:\n        f = open("".gitattributes"", ""a+"")\n        f.write(""%s export-subst\\n"" % versionfile_source)\n        f.close()\n        files.append("".gitattributes"")\n    run_command(GITS, [""add"", ""--""] + files)\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {\n                ""version"": dirname[len(parentdir_prefix) :],\n                ""full-revisionid"": None,\n                ""dirty"": False,\n                ""error"": None,\n                ""date"": None,\n            }\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(\n            ""Tried directories %s but none started with prefix %s""\n            % (str(rootdirs), parentdir_prefix)\n        )\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\nSHORT_VERSION_PY = """"""\n# This file was generated by \'versioneer.py\' (0.18) from\n# revision-control system data, or from the parent directory name of an\n# unpacked source archive. Distribution tarballs contain a pre-generated copy\n# of this file.\n\nimport json\n\nversion_json = \'\'\'\n%s\n\'\'\'  # END VERSION_JSON\n\n\ndef get_versions():\n    return json.loads(version_json)\n""""""\n\n\ndef versions_from_file(filename):\n    """"""Try to determine the version from _version.py if present.""""""\n    try:\n        with open(filename) as f:\n            contents = f.read()\n    except EnvironmentError:\n        raise NotThisMethod(""unable to read _version.py"")\n    mo = re.search(\n        r""version_json = \'\'\'\\n(.*)\'\'\'  # END VERSION_JSON"", contents, re.M | re.S\n    )\n    if not mo:\n        mo = re.search(\n            r""version_json = \'\'\'\\r\\n(.*)\'\'\'  # END VERSION_JSON"", contents, re.M | re.S\n        )\n    if not mo:\n        raise NotThisMethod(""no version_json in _version.py"")\n    return json.loads(mo.group(1))\n\n\ndef write_to_version_file(filename, versions):\n    """"""Write the given version number to the given _version.py file.""""""\n    os.unlink(filename)\n    contents = json.dumps(versions, sort_keys=True, indent=1, separators=("","", "": ""))\n    with open(filename, ""w"") as f:\n        f.write(SHORT_VERSION_PY % contents)\n\n    print(""set %s to \'%s\'"" % (filename, versions[""version""]))\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%d.g%s"" % (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%d.g%s"" % (pieces[""distance""], pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%d"" % pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%d"" % pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%s"" % pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%s"" % pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {\n            ""version"": ""unknown"",\n            ""full-revisionid"": pieces.get(""long""),\n            ""dirty"": None,\n            ""error"": pieces[""error""],\n            ""date"": None,\n        }\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%s\'"" % style)\n\n    return {\n        ""version"": rendered,\n        ""full-revisionid"": pieces[""long""],\n        ""dirty"": pieces[""dirty""],\n        ""error"": None,\n        ""date"": pieces.get(""date""),\n    }\n\n\nclass VersioneerBadRootError(Exception):\n    """"""The project root directory is unknown or missing key files.""""""\n\n\ndef get_versions(verbose=False):\n    """"""Get the project version from whatever source is available.\n\n    Returns dict with two keys: \'version\' and \'full\'.\n    """"""\n    if ""versioneer"" in sys.modules:\n        # see the discussion in cmdclass.py:get_cmdclass()\n        del sys.modules[""versioneer""]\n\n    root = get_root()\n    cfg = get_config_from_root(root)\n\n    assert cfg.VCS is not None, ""please set [versioneer]VCS= in setup.cfg""\n    handlers = HANDLERS.get(cfg.VCS)\n    assert handlers, ""unrecognized VCS \'%s\'"" % cfg.VCS\n    verbose = verbose or cfg.verbose\n    assert (\n        cfg.versionfile_source is not None\n    ), ""please set versioneer.versionfile_source""\n    assert cfg.tag_prefix is not None, ""please set versioneer.tag_prefix""\n\n    versionfile_abs = os.path.join(root, cfg.versionfile_source)\n\n    # extract version from first of: _version.py, VCS command (e.g. \'git\n    # describe\'), parentdir. This is meant to work for developers using a\n    # source checkout, for users of a tarball created by \'setup.py sdist\',\n    # and for users of a tarball/zipball created by \'git archive\' or github\'s\n    # download-from-tag feature or the equivalent in other VCSes.\n\n    get_keywords_f = handlers.get(""get_keywords"")\n    from_keywords_f = handlers.get(""keywords"")\n    if get_keywords_f and from_keywords_f:\n        try:\n            keywords = get_keywords_f(versionfile_abs)\n            ver = from_keywords_f(keywords, cfg.tag_prefix, verbose)\n            if verbose:\n                print(""got version from expanded keyword %s"" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        ver = versions_from_file(versionfile_abs)\n        if verbose:\n            print(""got version from file %s %s"" % (versionfile_abs, ver))\n        return ver\n    except NotThisMethod:\n        pass\n\n    from_vcs_f = handlers.get(""pieces_from_vcs"")\n    if from_vcs_f:\n        try:\n            pieces = from_vcs_f(cfg.tag_prefix, root, verbose)\n            ver = render(pieces, cfg.style)\n            if verbose:\n                print(""got version from VCS %s"" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        if cfg.parentdir_prefix:\n            ver = versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n            if verbose:\n                print(""got version from parentdir %s"" % ver)\n            return ver\n    except NotThisMethod:\n        pass\n\n    if verbose:\n        print(""unable to compute version"")\n\n    return {\n        ""version"": ""0+unknown"",\n        ""full-revisionid"": None,\n        ""dirty"": None,\n        ""error"": ""unable to compute version"",\n        ""date"": None,\n    }\n\n\ndef get_version():\n    """"""Get the short version string for this project.""""""\n    return get_versions()[""version""]\n\n\ndef get_cmdclass():\n    """"""Get the custom setuptools/distutils subclasses used by Versioneer.""""""\n    if ""versioneer"" in sys.modules:\n        del sys.modules[""versioneer""]\n        # this fixes the ""python setup.py develop"" case (also \'install\' and\n        # \'easy_install .\'), in which subdependencies of the main project are\n        # built (using setup.py bdist_egg) in the same python process. Assume\n        # a main project A and a dependency B, which use different versions\n        # of Versioneer. A\'s setup.py imports A\'s Versioneer, leaving it in\n        # sys.modules by the time B\'s setup.py is executed, causing B to run\n        # with the wrong versioneer. Setuptools wraps the sub-dep builds in a\n        # sandbox that restores sys.modules to it\'s pre-build state, so the\n        # parent is protected against the child\'s ""import versioneer"". By\n        # removing ourselves from sys.modules here, before the child build\n        # happens, we protect the child from the parent\'s versioneer too.\n        # Also see https://github.com/warner/python-versioneer/issues/52\n\n    cmds = {}\n\n    # we add ""version"" to both distutils and setuptools\n    from distutils.core import Command\n\n    class cmd_version(Command):\n        description = ""report generated version string""\n        user_options = []\n        boolean_options = []\n\n        def initialize_options(self):\n            pass\n\n        def finalize_options(self):\n            pass\n\n        def run(self):\n            vers = get_versions(verbose=True)\n            print(""Version: %s"" % vers[""version""])\n            print("" full-revisionid: %s"" % vers.get(""full-revisionid""))\n            print("" dirty: %s"" % vers.get(""dirty""))\n            print("" date: %s"" % vers.get(""date""))\n            if vers[""error""]:\n                print("" error: %s"" % vers[""error""])\n\n    cmds[""version""] = cmd_version\n\n    # we override ""build_py"" in both distutils and setuptools\n    #\n    # most invocation pathways end up running build_py:\n    #  distutils/build -> build_py\n    #  distutils/install -> distutils/build ->..\n    #  setuptools/bdist_wheel -> distutils/install ->..\n    #  setuptools/bdist_egg -> distutils/install_lib -> build_py\n    #  setuptools/install -> bdist_egg ->..\n    #  setuptools/develop -> ?\n    #  pip install:\n    #   copies source tree to a tempdir before running egg_info/etc\n    #   if .git isn\'t copied too, \'git describe\' will fail\n    #   then does setup.py bdist_wheel, or sometimes setup.py install\n    #  setup.py egg_info -> ?\n\n    # we override different ""build_py"" commands for both environments\n    if ""setuptools"" in sys.modules:\n        from setuptools.command.build_py import build_py as _build_py\n    else:\n        from distutils.command.build_py import build_py as _build_py\n\n    class cmd_build_py(_build_py):\n        def run(self):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_py.run(self)\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            if cfg.versionfile_build:\n                target_versionfile = os.path.join(self.build_lib, cfg.versionfile_build)\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n    cmds[""build_py""] = cmd_build_py\n\n    if ""cx_Freeze"" in sys.modules:  # cx_freeze enabled?\n        from cx_Freeze.dist import build_exe as _build_exe\n\n        # nczeczulin reports that py2exe won\'t like the pep440-style string\n        # as FILEVERSION, but it can be used for PRODUCTVERSION, e.g.\n        # setup(console=[{\n        #   ""version"": versioneer.get_version().split(""+"", 1)[0], # FILEVERSION\n        #   ""product_version"": versioneer.get_version(),\n        #   ...\n\n        class cmd_build_exe(_build_exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _build_exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, ""w"") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(\n                        LONG\n                        % {\n                            ""DOLLAR"": ""$"",\n                            ""STYLE"": cfg.style,\n                            ""TAG_PREFIX"": cfg.tag_prefix,\n                            ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                            ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                        }\n                    )\n\n        cmds[""build_exe""] = cmd_build_exe\n        del cmds[""build_py""]\n\n    if ""py2exe"" in sys.modules:  # py2exe enabled?\n        try:\n            from py2exe.distutils_buildexe import py2exe as _py2exe  # py3\n        except ImportError:\n            from py2exe.build_exe import py2exe as _py2exe  # py2\n\n        class cmd_py2exe(_py2exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _py2exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, ""w"") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(\n                        LONG\n                        % {\n                            ""DOLLAR"": ""$"",\n                            ""STYLE"": cfg.style,\n                            ""TAG_PREFIX"": cfg.tag_prefix,\n                            ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                            ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                        }\n                    )\n\n        cmds[""py2exe""] = cmd_py2exe\n\n    # we override different ""sdist"" commands for both environments\n    if ""setuptools"" in sys.modules:\n        from setuptools.command.sdist import sdist as _sdist\n    else:\n        from distutils.command.sdist import sdist as _sdist\n\n    class cmd_sdist(_sdist):\n        def run(self):\n            versions = get_versions()\n            self._versioneer_generated_versions = versions\n            # unless we update this, the command will keep using the old\n            # version\n            self.distribution.metadata.version = versions[""version""]\n            return _sdist.run(self)\n\n        def make_release_tree(self, base_dir, files):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            _sdist.make_release_tree(self, base_dir, files)\n            # now locate _version.py in the new base_dir directory\n            # (remembering that it may be a hardlink) and replace it with an\n            # updated value\n            target_versionfile = os.path.join(base_dir, cfg.versionfile_source)\n            print(""UPDATING %s"" % target_versionfile)\n            write_to_version_file(\n                target_versionfile, self._versioneer_generated_versions\n            )\n\n    cmds[""sdist""] = cmd_sdist\n\n    return cmds\n\n\nCONFIG_ERROR = """"""\nsetup.cfg is missing the necessary Versioneer configuration. You need\na section like:\n\n [versioneer]\n VCS = git\n style = pep440\n versionfile_source = src/myproject/_version.py\n versionfile_build = myproject/_version.py\n tag_prefix =\n parentdir_prefix = myproject-\n\nYou will also need to edit your setup.py to use the results:\n\n import versioneer\n setup(version=versioneer.get_version(),\n       cmdclass=versioneer.get_cmdclass(), ...)\n\nPlease read the docstring in ./versioneer.py for configuration instructions,\nedit setup.cfg, and re-run the installer or \'python versioneer.py setup\'.\n""""""\n\nSAMPLE_CONFIG = """"""\n# See the docstring in versioneer.py for instructions. Note that you must\n# re-run \'versioneer.py setup\' after changing this section, and commit the\n# resulting files.\n\n[versioneer]\n#VCS = git\n#style = pep440\n#versionfile_source =\n#versionfile_build =\n#tag_prefix =\n#parentdir_prefix =\n\n""""""\n\nINIT_PY_SNIPPET = """"""\nfrom ._version import get_versions\n__version__ = get_versions()[\'version\']\ndel get_versions\n""""""\n\n\ndef do_setup():\n    """"""Main VCS-independent setup function for installing Versioneer.""""""\n    root = get_root()\n    try:\n        cfg = get_config_from_root(root)\n    except (\n        EnvironmentError,\n        configparser.NoSectionError,\n        configparser.NoOptionError,\n    ) as e:\n        if isinstance(e, (EnvironmentError, configparser.NoSectionError)):\n            print(""Adding sample versioneer config to setup.cfg"", file=sys.stderr)\n            with open(os.path.join(root, ""setup.cfg""), ""a"") as f:\n                f.write(SAMPLE_CONFIG)\n        print(CONFIG_ERROR, file=sys.stderr)\n        return 1\n\n    print("" creating %s"" % cfg.versionfile_source)\n    with open(cfg.versionfile_source, ""w"") as f:\n        LONG = LONG_VERSION_PY[cfg.VCS]\n        f.write(\n            LONG\n            % {\n                ""DOLLAR"": ""$"",\n                ""STYLE"": cfg.style,\n                ""TAG_PREFIX"": cfg.tag_prefix,\n                ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n            }\n        )\n\n    ipy = os.path.join(os.path.dirname(cfg.versionfile_source), ""__init__.py"")\n    if os.path.exists(ipy):\n        try:\n            with open(ipy, ""r"") as f:\n                old = f.read()\n        except EnvironmentError:\n            old = """"\n        if INIT_PY_SNIPPET not in old:\n            print("" appending to %s"" % ipy)\n            with open(ipy, ""a"") as f:\n                f.write(INIT_PY_SNIPPET)\n        else:\n            print("" %s unmodified"" % ipy)\n    else:\n        print("" %s doesn\'t exist, ok"" % ipy)\n        ipy = None\n\n    # Make sure both the top-level ""versioneer.py"" and versionfile_source\n    # (PKG/_version.py, used by runtime code) are in MANIFEST.in, so\n    # they\'ll be copied into source distributions. Pip won\'t be able to\n    # install the package without this.\n    manifest_in = os.path.join(root, ""MANIFEST.in"")\n    simple_includes = set()\n    try:\n        with open(manifest_in, ""r"") as f:\n            for line in f:\n                if line.startswith(""include ""):\n                    for include in line.split()[1:]:\n                        simple_includes.add(include)\n    except EnvironmentError:\n        pass\n    # That doesn\'t cover everything MANIFEST.in can do\n    # (http://docs.python.org/2/distutils/sourcedist.html#commands), so\n    # it might give some false negatives. Appending redundant \'include\'\n    # lines is safe, though.\n    if ""versioneer.py"" not in simple_includes:\n        print("" appending \'versioneer.py\' to MANIFEST.in"")\n        with open(manifest_in, ""a"") as f:\n            f.write(""include versioneer.py\\n"")\n    else:\n        print("" \'versioneer.py\' already in MANIFEST.in"")\n    if cfg.versionfile_source not in simple_includes:\n        print(\n            "" appending versionfile_source (\'%s\') to MANIFEST.in""\n            % cfg.versionfile_source\n        )\n        with open(manifest_in, ""a"") as f:\n            f.write(""include %s\\n"" % cfg.versionfile_source)\n    else:\n        print("" versionfile_source already in MANIFEST.in"")\n\n    # Make VCS-specific changes. For git, this means creating/changing\n    # .gitattributes to mark _version.py for export-subst keyword\n    # substitution.\n    do_vcs_install(manifest_in, cfg.versionfile_source, ipy)\n    return 0\n\n\ndef scan_setup_py():\n    """"""Validate the contents of setup.py against Versioneer\'s expectations.""""""\n    found = set()\n    setters = False\n    errors = 0\n    with open(""setup.py"", ""r"") as f:\n        for line in f.readlines():\n            if ""import versioneer"" in line:\n                found.add(""import"")\n            if ""versioneer.get_cmdclass()"" in line:\n                found.add(""cmdclass"")\n            if ""versioneer.get_version()"" in line:\n                found.add(""get_version"")\n            if ""versioneer.VCS"" in line:\n                setters = True\n            if ""versioneer.versionfile_source"" in line:\n                setters = True\n    if len(found) != 3:\n        print("""")\n        print(""Your setup.py appears to be missing some important items"")\n        print(""(but I might be wrong). Please make sure it has something"")\n        print(""roughly like the following:"")\n        print("""")\n        print("" import versioneer"")\n        print("" setup( version=versioneer.get_version(),"")\n        print(""        cmdclass=versioneer.get_cmdclass(),  ...)"")\n        print("""")\n        errors += 1\n    if setters:\n        print(""You should remove lines like \'versioneer.VCS = \' and"")\n        print(""\'versioneer.versionfile_source = \' . This configuration"")\n        print(""now lives in setup.cfg, and should be removed from setup.py"")\n        print("""")\n        errors += 1\n    return errors\n\n\nif __name__ == ""__main__"":\n    cmd = sys.argv[1]\n    if cmd == ""setup"":\n        errors = do_setup()\n        errors += scan_setup_py()\n        if errors:\n            sys.exit(1)\n'"
bottleneck/__init__.py,0,"b'try:\n    from .reduce import (\n        nansum,\n        nanmean,\n        nanstd,\n        nanvar,\n        nanmin,\n        nanmax,\n        median,\n        nanmedian,\n        ss,\n        nanargmin,\n        nanargmax,\n        anynan,\n        allnan,\n    )\n    from .nonreduce import replace\n    from .nonreduce_axis import partition, argpartition, rankdata, nanrankdata, push\n    from .move import (\n        move_sum,\n        move_mean,\n        move_std,\n        move_var,\n        move_min,\n        move_max,\n        move_argmin,\n        move_argmax,\n        move_median,\n        move_rank,\n    )\n\n    from . import slow\n\nexcept ImportError:\n    raise ImportError(\n        ""bottleneck modules failed to import, likely due to a ""\n        ""mismatch in NumPy versions. Either upgrade numpy to ""\n        ""1.16+ or install with:\\n\\t""\n        ""pip install --no-build-isolation --no-cache-dir ""\n        ""bottleneck""\n    )\n\nfrom bottleneck.benchmark.bench import bench\nfrom bottleneck.benchmark.bench_detailed import bench_detailed\nfrom bottleneck.tests.util import get_functions\nfrom ._pytesttester import PytestTester\nfrom ._version import get_versions  # noqa: E402\n\ntest = PytestTester(__name__)\ndel PytestTester\n\n\n__version__ = get_versions()[""version""]  # type: ignore\ndel get_versions\n'"
bottleneck/_pytesttester.py,0,"b'""""""\nGeneric test utilities.\n\nBased on scipy._libs._testutils\n""""""\n\nimport os\nimport sys\nfrom typing import List, Optional\n\n__all__ = [""PytestTester""]\n\n\nclass PytestTester(object):\n    """"""\n    Pytest test runner entry point.\n    """"""\n\n    def __init__(self, module_name: str) -> None:\n        self.module_name = module_name\n\n    def __call__(\n        self,\n        label: str = ""fast"",\n        verbose: int = 1,\n        extra_argv: Optional[List[str]] = None,\n        doctests: bool = False,\n        coverage: bool = False,\n        tests: Optional[List[str]] = None,\n        parallel: Optional[int] = None,\n    ) -> bool:\n        import pytest\n\n        module = sys.modules[self.module_name]\n        module_path = os.path.abspath(module.__path__[0])\n\n        pytest_args = [""-l""]\n\n        if doctests:\n            raise ValueError(""Doctests not supported"")\n\n        if extra_argv:\n            pytest_args += list(extra_argv)\n\n        if verbose and int(verbose) > 1:\n            pytest_args += [""-"" + ""v"" * (int(verbose) - 1)]\n\n        if coverage:\n            pytest_args += [""--cov="" + module_path]\n\n        if label == ""fast"":\n            pytest_args += [""-m"", ""not slow""]\n        elif label != ""full"":\n            pytest_args += [""-m"", label]\n\n        if tests is None:\n            tests = [self.module_name]\n\n        if parallel is not None and parallel > 1:\n            if _pytest_has_xdist():\n                pytest_args += [""-n"", str(parallel)]\n            else:\n                import warnings\n\n                warnings.warn(\n                    ""Could not run tests in parallel because ""\n                    ""pytest-xdist plugin is not available.""\n                )\n\n        pytest_args += [""--pyargs""] + list(tests)\n\n        try:\n            code = pytest.main(pytest_args)\n        except SystemExit as exc:\n            code = exc.code\n\n        return code == 0\n\n\ndef _pytest_has_xdist() -> bool:\n    """"""\n    Check if the pytest-xdist plugin is installed, providing parallel tests\n    """"""\n    # Check xdist exists without importing, otherwise pytests emits warnings\n    from importlib.util import find_spec\n\n    return find_spec(""xdist"") is not None\n'"
bottleneck/_version.py,0,"b'# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain. Generated by\n# versioneer-0.18 (https://github.com/warner/python-versioneer)\n\n""""""Git implementation of _version.py.""""""\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\n\n\ndef get_keywords():\n    """"""Get the keywords needed to look up the version information.""""""\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = ""$Format:%d$""\n    git_full = ""$Format:%H$""\n    git_date = ""$Format:%ci$""\n    keywords = {""refnames"": git_refnames, ""full"": git_full, ""date"": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_config():\n    """"""Create, populate and return the VersioneerConfig() object.""""""\n    # these strings are filled in when \'setup.py versioneer\' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = ""git""\n    cfg.style = ""pep440""\n    cfg.tag_prefix = ""v""\n    cfg.parentdir_prefix = ""bottleneck-""\n    cfg.versionfile_source = ""bottleneck/_version.py""\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen(\n                [c] + args,\n                cwd=cwd,\n                env=env,\n                stdout=subprocess.PIPE,\n                stderr=(subprocess.PIPE if hide_stderr else None),\n            )\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %s"" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %s"" % (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %s (error)"" % dispcmd)\n            print(""stdout was %s"" % stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {\n                ""version"": dirname[len(parentdir_prefix) :],\n                ""full-revisionid"": None,\n                ""dirty"": False,\n                ""error"": None,\n                ""date"": None,\n            }\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(\n            ""Tried directories %s but none started with prefix %s""\n            % (str(rootdirs), parentdir_prefix)\n        )\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG) :] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r""\\d"", r)])\n        if verbose:\n            print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %s"" % "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix) :]\n            if verbose:\n                print(""picking %s"" % r)\n            return {\n                ""version"": r,\n                ""full-revisionid"": keywords[""full""].strip(),\n                ""dirty"": False,\n                ""error"": None,\n                ""date"": date,\n            }\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {\n        ""version"": ""0+unknown"",\n        ""full-revisionid"": keywords[""full""].strip(),\n        ""dirty"": False,\n        ""error"": ""no suitable tags"",\n        ""date"": None,\n    }\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root, hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %s not under git control"" % root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(\n        GITS,\n        [\n            ""describe"",\n            ""--tags"",\n            ""--dirty"",\n            ""--always"",\n            ""--long"",\n            ""--match"",\n            ""%s*"" % tag_prefix,\n        ],\n        cwd=root,\n    )\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[: git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r""^(.+)-(\\d+)-g([0-9a-f]+)$"", git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = ""unable to parse git-describe output: \'%s\'"" % describe_out\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                print(fmt % (full_tag, tag_prefix))\n            pieces[""error""] = ""tag \'%s\' doesn\'t start with prefix \'%s\'"" % (\n                full_tag,\n                tag_prefix,\n            )\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix) :]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""], cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""], cwd=root)[\n        0\n    ].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%d.g%s"" % (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%d.g%s"" % (pieces[""distance""], pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%d"" % pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%d"" % pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%s"" % pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%s"" % pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {\n            ""version"": ""unknown"",\n            ""full-revisionid"": pieces.get(""long""),\n            ""dirty"": None,\n            ""error"": pieces[""error""],\n            ""date"": None,\n        }\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%s\'"" % style)\n\n    return {\n        ""version"": rendered,\n        ""full-revisionid"": pieces[""long""],\n        ""dirty"": pieces[""dirty""],\n        ""error"": None,\n        ""date"": pieces.get(""date""),\n    }\n\n\ndef get_versions():\n    """"""Get version information or return default if unable to do so.""""""\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don\'t do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix, verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split(""/""):\n            root = os.path.dirname(root)\n    except NameError:\n        return {\n            ""version"": ""0+unknown"",\n            ""full-revisionid"": None,\n            ""dirty"": None,\n            ""error"": ""unable to find root of source tree"",\n            ""date"": None,\n        }\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {\n        ""version"": ""0+unknown"",\n        ""full-revisionid"": None,\n        ""dirty"": None,\n        ""error"": ""unable to compute version"",\n        ""date"": None,\n    }\n'"
tools/test-installed-bottleneck.py,0,"b'#!/usr/bin/env python\n\nfrom __future__ import division\n\nimport sys\nfrom optparse import OptionParser\n\nimport bottleneck\n\n# This file is a modified version of the original numpy file:\n# test-installed-numpy.py\n\n# A simple script to test the installed version of bottleneck by calling\n# \'bottleneck.test()\'. Key features:\n#   -- convenient command-line syntax\n#   -- sets exit status appropriately, useful for automated test environments\n\n# It would be better to set this up as a module in the bottleneck namespace, so\n# that it could be run as:\n#   python -m numpy.run_tests <args>\n# But, python2.4\'s -m switch only works with top-level modules, not modules\n# that are inside packages. So, once we drop 2.4 support, maybe...\n# TODO: Bottleneck doesn\'t support python 2.4\n\n# In case we are run from the source directory, we don\'t want to import\n# bottleneck from there, we want to import the installed version:\nsys.path.pop(0)\n\nparser = OptionParser(""usage: %prog [options] -- [nosetests options]"")\nparser.add_option(\n    ""-v"",\n    ""--verbose"",\n    action=""count"",\n    dest=""verbose"",\n    default=1,\n    help=""increase verbosity"",\n)\nparser.add_option(\n    ""--doctests"",\n    action=""store_true"",\n    dest=""doctests"",\n    default=False,\n    help=""Run doctests in module"",\n)\nparser.add_option(\n    ""--coverage"",\n    action=""store_true"",\n    dest=""coverage"",\n    default=False,\n    help=""report coverage requires \'coverage\' module"",\n)\nparser.add_option(\n    ""-m"",\n    ""--mode"",\n    action=""store"",\n    dest=""mode"",\n    default=""fast"",\n    help=""\'fast\', \'full\', or something that could be ""\n    ""passed to nosetests -A [default: %default]"",\n)\n(options, args) = parser.parse_args()\n\nresult = bottleneck.test(\n    options.mode,\n    verbose=options.verbose,\n    extra_argv=args,\n    doctests=options.doctests,\n    coverage=options.coverage,\n)\n\nif result:\n    sys.exit(0)\nelse:\n    sys.exit(1)\n'"
tools/update_readme.py,0,"b'import os\nimport sys\nfrom io import StringIO\n\nimport bottleneck as bn\n\n\ndef update_readme():\n\n    # run benchmark suite while capturing output; indent\n    with Capturing() as bench_list:\n        bn.bench()\n    bench_list = [""    "" + b for b in bench_list]\n\n    # read readme\n    cwd = os.path.dirname(__file__)\n    readme_path = os.path.join(cwd, ""../README.rst"")\n    with open(readme_path) as f:\n        readme_list = f.readlines()\n    readme_list = [r.strip(""\\n"") for r in readme_list]\n\n    # remove old benchmark result from readme\n    idx1 = readme_list.index(""    Bottleneck performance benchmark"")\n    idx2 = [i for i, line in enumerate(readme_list) if line == """"]\n    idx2 = [i for i in idx2 if i > idx1]\n    idx2 = idx2[1]\n    del readme_list[idx1:idx2]\n\n    # insert new benchmark result into readme; remove trailing whitespace\n    readme_list = readme_list[:idx1] + bench_list + readme_list[idx1:]\n    readme_list = [r.rstrip() for r in readme_list]\n\n    # replace readme file\n    os.remove(readme_path)\n    with open(readme_path, ""w"") as f:\n        f.write(""\\n"".join(readme_list))\n\n\n# ---------------------------------------------------------------------------\n# Capturing class taken from\n# http://stackoverflow.com/questions/16571150/\n# how-to-capture-stdout-output-from-a-python-function-call\n\n\nclass Capturing(list):\n    def __enter__(self):\n        self._stdout = sys.stdout\n        sys.stdout = self._stringio = StringIO()\n        return self\n\n    def __exit__(self, *args):\n        self.extend(self._stringio.getvalue().splitlines())\n        sys.stdout = self._stdout\n\n\nif __name__ == ""__main__"":\n    update_readme()\n'"
asv_bench/benchmarks/__init__.py,0,b''
asv_bench/benchmarks/memory.py,1,"b'import numpy as np\n\nimport bottleneck as bn\n\n\nclass Memory:\n    def peakmem_nanmedian(self):\n        arr = np.arange(1).reshape((1, 1))\n        for i in range(1000000):\n            bn.nanmedian(arr)\n'"
asv_bench/benchmarks/move.py,0,"b'import bottleneck as bn\nfrom .reduce import get_cached_rand_array\n\n\nclass Time1DMove:\n    params = [\n        [""int32"", ""int64"", ""float32"", ""float64""],\n        [(10 ** 3,), (10 ** 5,), (10 ** 7,)],\n        [10],\n    ]\n    param_names = [""dtype"", ""shape"", ""window""]\n\n    def setup(self, dtype, shape, window):\n        self.arr = get_cached_rand_array(shape, dtype, ""C"")\n\n    def time_move_sum(self, dtype, shape, window):\n        bn.move_sum(self.arr, window)\n\n    def time_move_mean(self, dtype, shape, window):\n        bn.move_mean(self.arr, window)\n\n    def time_move_std(self, dtype, shape, window):\n        bn.move_std(self.arr, window)\n\n    def time_move_var(self, dtype, shape, window):\n        bn.move_var(self.arr, window)\n\n    def time_move_min(self, dtype, shape, window):\n        bn.move_min(self.arr, window)\n\n    def time_move_max(self, dtype, shape, window):\n        bn.move_max(self.arr, window)\n\n    def time_move_argmin(self, dtype, shape, window):\n        bn.move_argmin(self.arr, window)\n\n    def time_move_argmax(self, dtype, shape, window):\n        bn.move_argmax(self.arr, window)\n\n    def time_move_median(self, dtype, shape, window):\n        bn.move_median(self.arr, window)\n\n    def time_move_rank(self, dtype, shape, window):\n        bn.move_rank(self.arr, window)\n\n\nclass Time2DMove:\n    params = [\n        [""int32"", ""int64"", ""float32"", ""float64""],\n        [(10 ** 3, 10 ** 3)],\n        [""C"", ""F""],\n        [0, 1],\n        [10],\n    ]\n    param_names = [""dtype"", ""shape"", ""order"", ""axis"", ""window""]\n\n    def setup(self, dtype, shape, order, axis, window):\n        self.arr = get_cached_rand_array(shape, dtype, order)\n\n    def time_move_sum(self, dtype, shape, order, axis, window):\n        bn.move_sum(self.arr, window, axis=axis)\n\n    def time_move_mean(self, dtype, shape, order, axis, window):\n        bn.move_mean(self.arr, window, axis=axis)\n\n    def time_move_std(self, dtype, shape, order, axis, window):\n        bn.move_std(self.arr, window, axis=axis)\n\n    def time_move_var(self, dtype, shape, order, axis, window):\n        bn.move_var(self.arr, window, axis=axis)\n\n    def time_move_min(self, dtype, shape, order, axis, window):\n        bn.move_min(self.arr, window, axis=axis)\n\n    def time_move_max(self, dtype, shape, order, axis, window):\n        bn.move_max(self.arr, window, axis=axis)\n\n    def time_move_argmin(self, dtype, shape, order, axis, window):\n        bn.move_argmin(self.arr, window, axis=axis)\n\n    def time_move_argmax(self, dtype, shape, order, axis, window):\n        bn.move_argmax(self.arr, window, axis=axis)\n\n    def time_move_median(self, dtype, shape, order, axis, window):\n        bn.move_median(self.arr, window, axis=axis)\n\n    def time_move_rank(self, dtype, shape, order, axis, window):\n        bn.move_rank(self.arr, window, axis=axis)\n'"
asv_bench/benchmarks/nonreduce.py,1,"b'import numpy as np\n\nimport bottleneck as bn\n\n\nclass TimeReplace2D:\n    params = [\n        [""int32"", ""int64"", ""float32"", ""float64""],\n        [(10 ** 3, 10 ** 3)],\n        [""C"", ""F""],\n    ]\n    param_names = [""dtype"", ""shape"", ""order""]\n\n    def setup(self, dtype, shape, order):\n        self.arr = np.full(shape, 0, dtype=dtype, order=order)\n\n        assert self.arr.flags[order + ""_CONTIGUOUS""]\n\n        self.old = 0\n        self.new = 1\n\n    def time_replace(self, dtype, shape, order):\n        bn.replace(self.arr, self.old, self.new)\n'"
asv_bench/benchmarks/nonreduce_axis.py,0,"b'import bottleneck as bn\nfrom .reduce import get_cached_rand_array\n\n\nclass Time1DNonreduceAxis:\n    params = [\n        [""int32"", ""int64"", ""float32"", ""float64""],\n        [(10 ** 3,), (10 ** 5,), (10 ** 7,)],\n    ]\n    param_names = [""dtype"", ""shape""]\n\n    def setup(self, dtype, shape):\n        self.arr = get_cached_rand_array(shape, dtype, ""C"")\n        self.half = shape[0] // 2\n\n    def time_partition(self, dtype, shape):\n        bn.partition(self.arr, self.half)\n\n    def time_argpartition(self, dtype, shape):\n        bn.argpartition(self.arr, self.half)\n\n    def time_rankdata(self, dtype, shape):\n        bn.rankdata(self.arr)\n\n    def time_nanrankdata(self, dtype, shape):\n        bn.nanrankdata(self.arr)\n\n    def time_push(self, dtype, shape):\n        bn.push(self.arr)\n'"
asv_bench/benchmarks/reduce.py,7,"b'import numpy as np\n\nimport bottleneck as bn\n\nRAND_ARRAY_CACHE = {}\n\n\ndef get_cached_rand_array(shape, dtype, order):\n    key = (shape, dtype, order)\n    if key not in RAND_ARRAY_CACHE:\n        assert order in [""C"", ""F""]\n        random_state = np.random.RandomState(1234)\n        if ""int"" in shape:\n            dtype_info = np.iinfo(dtype)\n            arr = random_state.randint(\n                dtype_info.min, dtype_info.max, size=shape, dtype=dtype\n            )\n        else:\n            arr = 10000 * random_state.standard_normal(shape).astype(dtype)\n\n        if order == ""F"":\n            arr = np.asfortranarray(arr)\n\n        assert arr.flags[order + ""_CONTIGUOUS""]\n\n        RAND_ARRAY_CACHE[key] = arr\n\n    return RAND_ARRAY_CACHE[key].copy(order=order)\n\n\nclass Time1DReductions:\n    params = [\n        [""int32"", ""int64"", ""float32"", ""float64""],\n        [(10 ** 3,), (10 ** 5,), (10 ** 7,)],\n    ]\n    param_names = [""dtype"", ""shape""]\n\n    def setup(self, dtype, shape):\n        self.arr = get_cached_rand_array(shape, dtype, ""C"")\n\n    def time_nanmin(self, dtype, shape):\n        bn.nanmin(self.arr)\n\n    def time_nanmax(self, dtype, shape):\n        bn.nanmin(self.arr)\n\n    def time_nanargmin(self, dtype, shape):\n        bn.nanargmin(self.arr)\n\n    def time_nanargmax(self, dtype, shape):\n        bn.nanargmax(self.arr)\n\n    def time_nansum(self, dtype, shape):\n        bn.nansum(self.arr)\n\n    def time_nanmean(self, dtype, shape):\n        bn.nanmean(self.arr)\n\n    def time_nanstd(self, dtype, shape):\n        bn.nanstd(self.arr)\n\n    def time_nanvar(self, dtype, shape):\n        bn.nanvar(self.arr)\n\n    def time_median(self, dtype, shape):\n        bn.median(self.arr)\n\n    def time_nanmedian(self, dtype, shape):\n        bn.nanmedian(self.arr)\n\n    def time_ss(self, dtype, shape):\n        bn.ss(self.arr)\n\n\nclass Time2DReductions:\n    params = [\n        [""int32"", ""int64"", ""float32"", ""float64""],\n        [(10 ** 3, 10 ** 3)],\n        [""C"", ""F""],\n        [None, 0, 1],\n    ]\n    param_names = [""dtype"", ""shape"", ""order"", ""axis""]\n\n    def setup(self, dtype, shape, order, axis):\n        self.arr = get_cached_rand_array(shape, dtype, order)\n\n    def time_nanmin(self, dtype, shape, order, axis):\n        bn.nanmin(self.arr, axis=axis)\n\n    def time_nanmax(self, dtype, shape, order, axis):\n        bn.nanmin(self.arr, axis=axis)\n\n    def time_nanargmin(self, dtype, shape, order, axis):\n        bn.nanargmin(self.arr, axis=axis)\n\n    def time_nanargmax(self, dtype, shape, order, axis):\n        bn.nanargmax(self.arr, axis=axis)\n\n    def time_nansum(self, dtype, shape, order, axis):\n        bn.nansum(self.arr, axis=axis)\n\n    def time_nanmean(self, dtype, shape, order, axis):\n        bn.nanmean(self.arr, axis=axis)\n\n    def time_nanstd(self, dtype, shape, order, axis):\n        bn.nanstd(self.arr, axis=axis)\n\n    def time_nanvar(self, dtype, shape, order, axis):\n        bn.nanvar(self.arr, axis=axis)\n\n    def time_median(self, dtype, shape, order, axis):\n        bn.median(self.arr, axis=axis)\n\n    def time_nanmedian(self, dtype, shape, order, axis):\n        bn.nanmedian(self.arr, axis=axis)\n\n    def time_ss(self, dtype, shape, order, axis):\n        bn.ss(self.arr, axis=axis)\n\n\nclass TimeAnyNan2D:\n    params = [\n        [""int32"", ""int64"", ""float32"", ""float64""],\n        [(10 ** 3, 10 ** 3)],\n        [""C"", ""F""],\n        [None, 0, 1],\n        [""fast"", ""slow""],\n    ]\n    param_names = [""dtype"", ""shape"", ""order"", ""axis"", ""case""]\n\n    def setup(self, dtype, shape, order, axis, case):\n        self.arr = np.full(shape, 0, dtype=dtype, order=order)\n\n        if ""float"" in dtype:\n            if case == ""fast"":\n                self.arr[:] = np.nan\n\n        assert self.arr.flags[order + ""_CONTIGUOUS""]\n\n    def time_anynan(self, dtype, shape, order, axis, case):\n        bn.anynan(self.arr, axis=axis)\n\n\nclass TimeAllNan2D:\n    params = [\n        [""int32"", ""int64"", ""float32"", ""float64""],\n        [(10 ** 3, 10 ** 3)],\n        [""C"", ""F""],\n        [None, 0, 1],\n        [""fast"", ""slow""],\n    ]\n    param_names = [""dtype"", ""shape"", ""order"", ""axis"", ""case""]\n\n    def setup(self, dtype, shape, order, axis, case):\n        self.arr = np.full(shape, 0, dtype=dtype, order=order)\n\n        if ""float"" in dtype:\n            if case == ""slow"":\n                self.arr[:] = np.nan\n\n        assert self.arr.flags[order + ""_CONTIGUOUS""]\n\n    def time_allnan(self, dtype, shape, order, axis, case):\n        bn.allnan(self.arr, axis=axis)\n'"
bottleneck/benchmark/__init__.py,0,b''
bottleneck/benchmark/autotimeit.py,0,"b'import timeit\nfrom typing import Tuple\n\n\ndef autotimeit(\n    stmt: str, setup: str = ""pass"", repeat: int = 3, mintime: float = 0.2\n) -> float:\n    timer = timeit.Timer(stmt, setup)\n    number, time1 = autoscaler(timer, mintime)\n    time2 = timer.repeat(repeat=repeat - 1, number=number)\n    return min(time2 + [time1]) / number\n\n\ndef autoscaler(timer: timeit.Timer, mintime: float) -> Tuple[int, float]:\n    number = 1\n    for _ in range(12):\n        time = timer.timeit(number)\n        if time > mintime:\n            return number, time\n        number *= 10\n    raise RuntimeError(""function is too fast to test"")\n'"
bottleneck/benchmark/bench.py,8,"b'import numpy as np\n\nimport bottleneck as bn\nfrom .autotimeit import autotimeit\n\n__all__ = [""bench""]\n\nARRAY_CACHE = {}\n\n\ndef bench(\n    shapes=[\n        (100,),\n        (1000, 1000),\n        (1000, 1000),\n        (1000, 1000),\n        (1000, 1000),\n        (1000, 1000),\n    ],\n    axes=[0, None, 0, 0, 1, 1],\n    nans=[False, True, False, True, False, True],\n    dtype=""float64"",\n    order=""C"",\n    functions=None,\n):\n    """"""\n    Bottleneck benchmark.\n\n    Parameters\n    ----------\n    shapes : list, optional\n        A list of tuple shapes of input arrays to use in the benchmark.\n    axes : list, optional\n        List of axes along which to perform the calculations that are being\n        benchmarked.\n    nans : list, optional\n        A list of the bools (True or False), one for each tuple in the\n        `shapes` list, that tells whether the input arrays should be randomly\n        filled with one-fifth NaNs.\n    dtype : str, optional\n        Data type string such as \'float64\', which is the default.\n    order : {\'C\', \'F\'}, optional\n        Whether to store multidimensional data in C- or Fortran-contiguous\n        (row- or column-wise) order in memory.\n    functions : {list, None}, optional\n        A list of strings specifying which functions to include in the\n        benchmark. By default (None) all functions are included in the\n        benchmark.\n\n    Returns\n    -------\n    A benchmark report is printed to stdout.\n\n    """"""\n\n    if len(shapes) != len(nans):\n        raise ValueError(""`shapes` and `nans` must have the same length"")\n    if len(shapes) != len(axes):\n        raise ValueError(""`shapes` and `axes` must have the same length"")\n\n    # Header\n    print(""Bottleneck performance benchmark"")\n    print(""    Bottleneck %s; Numpy %s"" % (bn.__version__, np.__version__))\n    print(""    Speed is NumPy time divided by Bottleneck time"")\n    print(""    NaN means approx one-fifth NaNs; %s used"" % str(dtype))\n\n    print("""")\n    header = ["" "" * 11]\n    for nan in nans:\n        if nan:\n            header.append(""NaN"".center(11))\n        else:\n            header.append(""no NaN"".center(11))\n    print("""".join(header))\n    header = ["""".join(str(shape).split("" "")).center(11) for shape in shapes]\n    header = ["" "" * 12] + header\n    print("""".join(header))\n    header = ["""".join((""axis="" + str(axis)).split("" "")).center(11) for axis in axes]\n    header = ["" "" * 12] + header\n    print("""".join(header))\n\n    suite = benchsuite(shapes, dtype, nans, axes, order, functions)\n    for test in suite:\n        name = test[""name""].ljust(12)\n        fmt = name + ""%7.1f"" + ""%11.1f"" * (len(shapes) - 1)\n        speed = timer(test[""statements""], test[""setups""])\n        print(fmt % tuple(speed))\n\n\ndef timer(statements, setups):\n    speed = []\n    if len(statements) != 2:\n        raise ValueError(""Two statements needed."")\n    for setup in setups:\n        with np.errstate(invalid=""ignore""):\n            t0 = autotimeit(statements[0], setup)\n            t1 = autotimeit(statements[1], setup)\n        speed.append(t1 / t0)\n    return speed\n\n\ndef getarray(shape, dtype, nans, order, allnans=False):\n    key = (tuple(shape), dtype, nans, order, allnans)\n    if key not in ARRAY_CACHE:\n        a = np.arange(np.prod(shape), dtype=dtype)\n        if issubclass(a.dtype.type, np.inexact):\n            if nans:\n                a[::5] = np.nan\n            if allnans:\n                a[:] = np.nan\n        rs = np.random.RandomState(shape)\n        rs.shuffle(a)\n        ARRAY_CACHE[key] = np.array(a.reshape(*shape), order=order)\n\n    return ARRAY_CACHE[key].copy(order=order)\n\n\ndef benchsuite(shapes, dtype, nans, axes, order, functions):\n\n    suite = []\n\n    def getsetups(setup, shapes, nans, axes, dtype, order, allnan=False):\n        setups = []\n        for shape, axis, nan in zip(shapes, axes, nans):\n            s = f""""""\nfrom bottleneck.benchmark.bench import getarray\na = getarray({shape}, \'{dtype}\', {nan}, \'{order}\', allnans={allnan})\naxis={axis}\n{setup}""""""\n            s = ""\\n"".join([line.strip() for line in s.split(""\\n"")])\n            setups.append(s)\n        return setups\n\n    # non-moving window functions\n    funcs = bn.get_functions(""reduce"", as_string=True)\n    # Handle all/any separately\n    funcs = sorted(set(funcs) - set([""allnan"", ""anynan""]))\n    funcs += [""rankdata"", ""nanrankdata""]\n    for func in funcs:\n        if functions is not None and func not in functions:\n            continue\n        run = {}\n        run[""name""] = func\n        run[""statements""] = [""bn_func(a, axis)"", ""sl_func(a, axis)""]\n        setup = """"""\n            from bottleneck import %s as bn_func\n            try: from numpy import %s as sl_func\n            except ImportError: from bottleneck.slow import %s as sl_func\n            if ""%s"" == ""median"": from bottleneck.slow import median as sl_func\n        """""" % (\n            func,\n            func,\n            func,\n            func,\n        )\n        run[""setups""] = getsetups(setup, shapes, nans, axes, dtype, order)\n        suite.append(run)\n\n    for func in [""allnan"", ""anynan""]:\n        if functions is not None and func not in functions:\n            continue\n        for case in ["""", ""_fast"", ""_slow""]:\n            run = {}\n            run[""name""] = func + case\n            run[""statements""] = [""bn_func(a, axis)"", ""sl_func(a, axis)""]\n            setup = """"""\n            from bottleneck import %s as bn_func\n            try: from numpy import %s as sl_func\n            except ImportError: from bottleneck.slow import %s as sl_func\n            if ""%s"" == ""median"": from bottleneck.slow import median as sl_func\n        """""" % (\n                func,\n                func,\n                func,\n                func,\n            )\n            if case:\n                if func == ""allnan"":\n                    allnan_case = ""slow"" in case\n                else:\n                    allnan_case = ""fast"" in case\n\n                new_nans = [allnan_case] * len(nans)\n            else:\n                new_nans = nans\n                allnan_case = False\n            run[""setups""] = getsetups(\n                setup, shapes, new_nans, axes, dtype, order, allnan=allnan_case\n            )\n            suite.append(run)\n\n    # partition, argpartition\n    funcs = [""partition"", ""argpartition""]\n    for func in funcs:\n        if functions is not None and func not in functions:\n            continue\n        run = {}\n        run[""name""] = func\n        run[""statements""] = [""bn_func(a, n, axis)"", ""sl_func(a, n, axis)""]\n        setup = """"""\n            from bottleneck import %s as bn_func\n            from bottleneck.slow import %s as sl_func\n            if axis is None: n = a.size\n            else: n = a.shape[axis] - 1\n            n = max(n // 2, 0)\n        """""" % (\n            func,\n            func,\n        )\n        run[""setups""] = getsetups(setup, shapes, nans, axes, dtype, order)\n        suite.append(run)\n\n    # replace, push\n    funcs = [""replace"", ""push""]\n    for func in funcs:\n        if functions is not None and func not in functions:\n            continue\n        run = {}\n        run[""name""] = func\n        if func == ""replace"":\n            run[""statements""] = [""bn_func(a, nan, 0)"", ""slow_func(a, nan, 0)""]\n        elif func == ""push"":\n            run[""statements""] = [""bn_func(a, 5, axis)"", ""slow_func(a, 5, axis)""]\n        else:\n            raise ValueError(""Unknow function name"")\n        setup = """"""\n            from numpy import nan\n            from bottleneck import %s as bn_func\n            from bottleneck.slow import %s as slow_func\n        """""" % (\n            func,\n            func,\n        )\n        run[""setups""] = getsetups(setup, shapes, nans, axes, dtype, order)\n        suite.append(run)\n\n    # moving window functions\n    funcs = bn.get_functions(""move"", as_string=True)\n    for func in funcs:\n        if functions is not None and func not in functions:\n            continue\n        run = {}\n        run[""name""] = func\n        run[""statements""] = [""bn_func(a, w, 1, axis)"", ""sw_func(a, w, 1, axis)""]\n        setup = """"""\n            from bottleneck.slow.move import %s as sw_func\n            from bottleneck import %s as bn_func\n            w = a.shape[axis] // 5\n        """""" % (\n            func,\n            func,\n        )\n        run[""setups""] = getsetups(setup, shapes, nans, axes, dtype, order)\n        suite.append(run)\n\n    return suite\n'"
bottleneck/benchmark/bench_detailed.py,12,"b'import numpy as np\n\nimport bottleneck as bn\nfrom .autotimeit import autotimeit\n\n__all__ = [""bench_detailed""]\n\n\ndef bench_detailed(function=""nansum"", fraction_nan=0.0):\n    """"""\n    Benchmark a single function in detail or, optionally, all functions.\n\n    Parameters\n    ----------\n    function : str, optional\n        Name of function, as a string, to benchmark. Default (\'nansum\') is\n        to benchmark bn.nansum. If `function` is \'all\' then detailed\n        benchmarks are run on all bottleneck functions.\n    fraction_nan : float, optional\n        Fraction of array elements that should, on average, be NaN. The\n        default (0.0) is not to set any elements to NaN.\n\n    Returns\n    -------\n    A benchmark report is printed to stdout.\n\n    """"""\n\n    if function == ""all"":\n        # benchmark all bottleneck functions\n        funcs = bn.get_functions(""all"", as_string=True)\n        funcs.sort()\n        for func in funcs:\n            bench_detailed(func, fraction_nan)\n\n    if fraction_nan < 0 or fraction_nan > 1:\n        raise ValueError(""`fraction_nan` must be between 0 and 1, inclusive"")\n\n    tab = ""    ""\n\n    # Header\n    print(""%s benchmark"" % function)\n    print(""%sBottleneck %s; Numpy %s"" % (tab, bn.__version__, np.__version__))\n    print(""%sSpeed is NumPy time divided by Bottleneck time"" % tab)\n    if fraction_nan == 0:\n        print(""%sNone of the array elements are NaN"" % tab)\n    else:\n        print(\n            ""%s%.1f%% of the array elements are NaN (on average)""\n            % (tab, fraction_nan * 100)\n        )\n    print("""")\n\n    print(""   Speed  Call                          Array"")\n    suite = benchsuite(function, fraction_nan)\n    for test in suite:\n        name = test[""name""]\n        speed = timer(test[""statements""], test[""setup""], test[""repeat""])\n        print(""%8.1f  %s   %s"" % (speed, name[0].ljust(27), name[1]))\n\n\ndef timer(statements, setup, repeat):\n    if len(statements) != 2:\n        raise ValueError(""Two statements needed."")\n    with np.errstate(invalid=""ignore""):\n        t0 = autotimeit(statements[0], setup, repeat=repeat)\n        t1 = autotimeit(statements[1], setup, repeat=repeat)\n    speed = t1 / t0\n    return speed\n\n\ndef benchsuite(function, fraction_nan):\n\n    # setup is called before each run of each function\n    setup = """"""\n        from bottleneck import %s as bn_fn\n        try: from numpy import %s as sl_fn\n        except ImportError: from bottleneck.slow import %s as sl_fn\n\n        # avoid all-nan slice warnings from np.median and np.nanmedian\n        if ""%s"" == ""median"": from bottleneck.slow import median as sl_fn\n        if ""%s"" == ""nanmedian"": from bottleneck.slow import nanmedian as sl_fn\n\n        from numpy import array, nan\n        from numpy.random import RandomState\n        rand = RandomState(123).rand\n\n        a = %s\n        if %s != 0: a[a < %s] = nan\n    """"""\n    setup = ""\\n"".join([s.strip() for s in setup.split(""\\n"")])\n\n    # what kind of function signature do we need to use?\n    if function in bn.get_functions(""reduce"", as_string=True):\n        index = 0\n    elif function in [""rankdata"", ""nanrankdata""]:\n        index = 0\n    elif function in bn.get_functions(""move"", as_string=True):\n        index = 1\n    elif function in [""partition"", ""argpartition"", ""push""]:\n        index = 2\n    elif function == ""replace"":\n        index = 3\n    else:\n        raise ValueError(""`function` (%s) not recognized"" % function)\n\n    # create benchmark suite\n    instructions = get_instructions()\n    f = function\n    suite = []\n    for instruction in instructions:\n        signature = instruction[index + 1]\n        if signature is None:\n            continue\n        array = instruction[0]\n        repeat = instruction[-1]\n        run = {}\n        run[""name""] = [f + signature, array]\n        run[""statements""] = [""bn_fn"" + signature, ""sl_fn"" + signature]\n        run[""setup""] = setup % (f, f, f, f, f, array, fraction_nan, fraction_nan)\n        run[""repeat""] = repeat\n        suite.append(run)\n\n    return suite\n\n\ndef get_instructions():\n\n    instructions = [\n        # 1d input array\n        (\n            ""rand(1)"",\n            ""(a)"",  # reduce + (nan)rankdata\n            ""(a, 1)"",  # move\n            ""(a, 0)"",  # (arg)partition\n            ""(a, np.nan, 0)"",  # replace\n            10,\n        ),\n        (""rand(10)"", ""(a)"", ""(a, 2)"", ""(a, 2)"", ""(a, np.nan, 0)"", 10),\n        (""rand(100)"", ""(a)"", ""(a, 20)"", ""(a, 20)"", ""(a, np.nan, 0)"", 6),\n        (""rand(1000)"", ""(a)"", ""(a, 200)"", ""(a, 200)"", ""(a, np.nan, 0)"", 3),\n        (""rand(1000000)"", ""(a)"", ""(a, 200)"", ""(a, 200)"", ""(a, np.nan, 0)"", 2),\n        # 2d input array\n        (""rand(10, 10)"", ""(a)"", ""(a, 2)"", ""(a, 2)"", ""(a, np.nan, 0)"", 6),\n        (""rand(100, 100)"", ""(a)"", ""(a, 20)"", ""(a, 20)"", ""(a, np.nan, 0)"", 3),\n        (""rand(1000, 1000)"", ""(a)"", ""(a, 200)"", ""(a, 200)"", ""(a, np.nan, 0)"", 2),\n        (""rand(10, 10)"", ""(a, 1)"", None, None, None, 6),\n        (""rand(100, 100)"", ""(a, 1)"", None, None, None, 3),\n        (""rand(1000, 1000)"", ""(a, 1)"", None, None, None, 2),\n        (""rand(100000, 2)"", ""(a, 1)"", ""(a, 1)"", ""(a, 1)"", None, 2),\n        (""rand(10, 10)"", ""(a, 0)"", None, None, None, 6),\n        (""rand(100, 100)"", ""(a, 0)"", ""(a, 20, axis=0)"", None, None, 3),\n        (""rand(1000, 1000)"", ""(a, 0)"", ""(a, 200, axis=0)"", None, None, 2),\n        # 3d input array\n        (\n            ""rand(100, 100, 100)"",\n            ""(a, 0)"",\n            ""(a, 20, axis=0)"",\n            ""(a, 20, axis=0)"",\n            None,\n            2,\n        ),\n        (\n            ""rand(100, 100, 100)"",\n            ""(a, 1)"",\n            ""(a, 20, axis=1)"",\n            ""(a, 20, axis=1)"",\n            None,\n            2,\n        ),\n        (\n            ""rand(100, 100, 100)"",\n            ""(a, 2)"",\n            ""(a, 20, axis=2)"",\n            ""(a, 20, axis=2)"",\n            ""(a, np.nan, 0)"",\n            2,\n        ),\n        # 0d input array\n        (""array(1.0)"", ""(a)"", None, None, ""(a, 0, 2)"", 10),\n    ]\n\n    return instructions\n'"
bottleneck/slow/__init__.py,0,b'# flake8: noqa\n\nfrom bottleneck.slow.move import *\nfrom bottleneck.slow.nonreduce import *\nfrom bottleneck.slow.nonreduce_axis import *\nfrom bottleneck.slow.reduce import *\n'
bottleneck/slow/move.py,41,"b'""Alternative methods of calculating moving window statistics.""\n\nimport warnings\n\nimport numpy as np\n\n__all__ = [\n    ""move_sum"",\n    ""move_mean"",\n    ""move_std"",\n    ""move_var"",\n    ""move_min"",\n    ""move_max"",\n    ""move_argmin"",\n    ""move_argmax"",\n    ""move_median"",\n    ""move_rank"",\n]\n\n\ndef move_sum(a, window, min_count=None, axis=-1):\n    ""Slow move_sum for unaccelerated dtype""\n    return move_func(np.nansum, a, window, min_count, axis=axis)\n\n\ndef move_mean(a, window, min_count=None, axis=-1):\n    ""Slow move_mean for unaccelerated dtype""\n    return move_func(np.nanmean, a, window, min_count, axis=axis)\n\n\ndef move_std(a, window, min_count=None, axis=-1, ddof=0):\n    ""Slow move_std for unaccelerated dtype""\n    return move_func(np.nanstd, a, window, min_count, axis=axis, ddof=ddof)\n\n\ndef move_var(a, window, min_count=None, axis=-1, ddof=0):\n    ""Slow move_var for unaccelerated dtype""\n    return move_func(np.nanvar, a, window, min_count, axis=axis, ddof=ddof)\n\n\ndef move_min(a, window, min_count=None, axis=-1):\n    ""Slow move_min for unaccelerated dtype""\n    return move_func(np.nanmin, a, window, min_count, axis=axis)\n\n\ndef move_max(a, window, min_count=None, axis=-1):\n    ""Slow move_max for unaccelerated dtype""\n    return move_func(np.nanmax, a, window, min_count, axis=axis)\n\n\ndef move_argmin(a, window, min_count=None, axis=-1):\n    ""Slow move_argmin for unaccelerated dtype""\n\n    def argmin(a, axis):\n        a = np.array(a, copy=False)\n        flip = [slice(None)] * a.ndim\n        flip[axis] = slice(None, None, -1)\n        a = a[flip]  # if tie, pick index of rightmost tie\n        try:\n            idx = np.nanargmin(a, axis=axis)\n        except ValueError:\n            # an all nan slice encountered\n            a = a.copy()\n            mask = np.isnan(a)\n            np.copyto(a, np.inf, where=mask)\n            idx = np.argmin(a, axis=axis).astype(np.float64)\n            if idx.ndim == 0:\n                idx = np.nan\n            else:\n                mask = np.all(mask, axis=axis)\n                idx[mask] = np.nan\n        return idx\n\n    return move_func(argmin, a, window, min_count, axis=axis)\n\n\ndef move_argmax(a, window, min_count=None, axis=-1):\n    ""Slow move_argmax for unaccelerated dtype""\n\n    def argmax(a, axis):\n        a = np.array(a, copy=False)\n        flip = [slice(None)] * a.ndim\n        flip[axis] = slice(None, None, -1)\n        a = a[flip]  # if tie, pick index of rightmost tie\n        try:\n            idx = np.nanargmax(a, axis=axis)\n        except ValueError:\n            # an all nan slice encountered\n            a = a.copy()\n            mask = np.isnan(a)\n            np.copyto(a, -np.inf, where=mask)\n            idx = np.argmax(a, axis=axis).astype(np.float64)\n            if idx.ndim == 0:\n                idx = np.nan\n            else:\n                mask = np.all(mask, axis=axis)\n                idx[mask] = np.nan\n        return idx\n\n    return move_func(argmax, a, window, min_count, axis=axis)\n\n\ndef move_median(a, window, min_count=None, axis=-1):\n    ""Slow move_median for unaccelerated dtype""\n    return move_func(np.nanmedian, a, window, min_count, axis=axis)\n\n\ndef move_rank(a, window, min_count=None, axis=-1):\n    ""Slow move_rank for unaccelerated dtype""\n    return move_func(lastrank, a, window, min_count, axis=axis)\n\n\n# magic utility functions ---------------------------------------------------\n\n\ndef move_func(func, a, window, min_count=None, axis=-1, **kwargs):\n    ""Generic moving window function implemented with a python loop.""\n    a = np.array(a, copy=False)\n    if min_count is None:\n        mc = window\n    else:\n        mc = min_count\n        if mc > window:\n            msg = ""min_count (%d) cannot be greater than window (%d)""\n            raise ValueError(msg % (mc, window))\n        elif mc <= 0:\n            raise ValueError(""`min_count` must be greater than zero."")\n    if a.ndim == 0:\n        raise ValueError(""moving window functions require ndim > 0"")\n    if axis is None:\n        raise ValueError(""An `axis` value of None is not supported."")\n    if window < 1:\n        raise ValueError(""`window` must be at least 1."")\n    if window > a.shape[axis]:\n        raise ValueError(""`window` is too long."")\n    if issubclass(a.dtype.type, np.inexact):\n        y = np.empty_like(a)\n    else:\n        y = np.empty(a.shape)\n    idx1 = [slice(None)] * a.ndim\n    idx2 = list(idx1)\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        for i in range(a.shape[axis]):\n            win = min(window, i + 1)\n            idx1[axis] = slice(i + 1 - win, i + 1)\n            idx2[axis] = i\n            y[tuple(idx2)] = func(a[tuple(idx1)], axis=axis, **kwargs)\n    idx = _mask(a, window, mc, axis)\n    y[idx] = np.nan\n    return y\n\n\ndef _mask(a, window, min_count, axis):\n    n = (a == a).cumsum(axis)\n    idx1 = [slice(None)] * a.ndim\n    idx2 = [slice(None)] * a.ndim\n    idx3 = [slice(None)] * a.ndim\n    idx1[axis] = slice(window, None)\n    idx2[axis] = slice(None, -window)\n    idx3[axis] = slice(None, window)\n    idx1 = tuple(idx1)\n    idx2 = tuple(idx2)\n    idx3 = tuple(idx3)\n    nidx1 = n[idx1]\n    nidx1 = nidx1 - n[idx2]\n    idx = np.empty(a.shape, dtype=np.bool)\n    idx[idx1] = nidx1 < min_count\n    idx[idx3] = n[idx3] < min_count\n    return idx\n\n\n# ---------------------------------------------------------------------------\n\n\ndef lastrank(a, axis=-1):\n    """"""\n    The ranking of the last element along the axis, ignoring NaNs.\n\n    The ranking is normalized to be between -1 and 1 instead of the more\n    common 1 and N. The results are adjusted for ties.\n\n    Parameters\n    ----------\n    a : ndarray\n        Input array. If `a` is not an array, a conversion is attempted.\n    axis : int, optional\n        The axis over which to rank. By default (axis=-1) the ranking\n        (and reducing) is performed over the last axis.\n\n    Returns\n    -------\n    d : array\n        In the case of, for example, a 2d array of shape (n, m) and\n        axis=1, the output will contain the rank (normalized to be between\n        -1 and 1 and adjusted for ties) of the the last element of each row.\n        The output in this example will have shape (n,).\n\n    Examples\n    --------\n    Create an array:\n\n    >>> y1 = larry([1, 2, 3])\n\n    What is the rank of the last element (the value 3 in this example)?\n    It is the largest element so the rank is 1.0:\n\n    >>> import numpy as np\n    >>> from la.afunc import lastrank\n    >>> x1 = np.array([1, 2, 3])\n    >>> lastrank(x1)\n    1.0\n\n    Now let\'s try an example where the last element has the smallest\n    value:\n\n    >>> x2 = np.array([3, 2, 1])\n    >>> lastrank(x2)\n    -1.0\n\n    Here\'s an example where the last element is not the minimum or maximum\n    value:\n\n    >>> x3 = np.array([1, 3, 4, 5, 2])\n    >>> lastrank(x3)\n    -0.5\n\n    """"""\n    a = np.array(a, copy=False)\n    ndim = a.ndim\n    if a.size == 0:\n        # At least one dimension has length 0\n        shape = list(a.shape)\n        shape.pop(axis)\n        r = np.empty(shape, dtype=a.dtype)\n        r.fill(np.nan)\n        if (r.ndim == 0) and (r.size == 1):\n            r = np.nan\n        return r\n    indlast = [slice(None)] * ndim\n    indlast[axis] = slice(-1, None)\n    indlast = tuple(indlast)\n    indlast2 = [slice(None)] * ndim\n    indlast2[axis] = -1\n    indlast2 = tuple(indlast2)\n    n = (~np.isnan(a)).sum(axis)\n    a_indlast = a[indlast]\n    g = (a_indlast > a).sum(axis)\n    e = (a_indlast == a).sum(axis)\n    r = (g + g + e - 1.0) / 2.0\n    r = r / (n - 1.0)\n    r = 2.0 * (r - 0.5)\n    if ndim == 1:\n        if n == 1:\n            r = 0\n        if np.isnan(a[indlast2]):  # elif?\n            r = np.nan\n    else:\n        np.putmask(r, n == 1, 0)\n        np.putmask(r, np.isnan(a[indlast2]), np.nan)\n    return r\n'"
bottleneck/slow/nonreduce.py,5,"b'from typing import Union\n\nimport numpy as np\n\n__all__ = [""replace""]\n\n\ndef replace(a: np.ndarray, old: Union[int, float], new: Union[int, float]) -> None:\n    ""Slow replace (inplace) used for unaccelerated dtypes.""\n    if type(a) is not np.ndarray:\n        raise TypeError(""`a` must be a numpy array."")\n    if not issubclass(a.dtype.type, np.inexact):\n        if old != old:\n            # int arrays do not contain NaN\n            return\n        if int(old) != old:\n            raise ValueError(""Cannot safely cast `old` to int."")\n        if int(new) != new:\n            raise ValueError(""Cannot safely cast `new` to int."")\n    if old != old:\n        mask = np.isnan(a)\n    else:\n        mask = a == old\n    np.putmask(a, mask, new)\n'"
bottleneck/slow/nonreduce_axis.py,25,"b'import numpy as np\nfrom numpy import argpartition, partition\n\n__all__ = [""rankdata"", ""nanrankdata"", ""partition"", ""argpartition"", ""push""]\n\n\ndef rankdata(a, axis=None):\n    ""Slow rankdata function used for unaccelerated dtypes.""\n    return _rank(scipy_rankdata, a, axis)\n\n\ndef nanrankdata(a, axis=None):\n    ""Slow nanrankdata function used for unaccelerated dtypes.""\n    return _rank(_nanrankdata_1d, a, axis)\n\n\ndef _rank(func1d, a, axis):\n    a = np.array(a, copy=False)\n    if axis is None:\n        a = a.ravel()\n        axis = 0\n    if a.size == 0:\n        y = a.astype(np.float64, copy=True)\n    else:\n        y = np.apply_along_axis(func1d, axis, a)\n        if a.dtype != np.float64:\n            y = y.astype(np.float64)\n    return y\n\n\ndef _nanrankdata_1d(a):\n    y = np.empty(a.shape, dtype=np.float64)\n    y.fill(np.nan)\n    idx = ~np.isnan(a)\n    y[idx] = scipy_rankdata(a[idx])\n    return y\n\n\ndef push(a, n=None, axis=-1):\n    ""Slow push used for unaccelerated dtypes.""\n    if n is None:\n        n = np.inf\n    y = np.array(a)\n    ndim = y.ndim\n    if axis != -1 or axis != ndim - 1:\n        y = np.rollaxis(y, axis, ndim)\n    if ndim == 1:\n        y = y[None, :]\n    elif ndim == 0:\n        return y\n    fidx = ~np.isnan(y)\n    recent = np.empty(y.shape[:-1])\n    count = np.empty(y.shape[:-1])\n    recent.fill(np.nan)\n    count.fill(np.nan)\n    with np.errstate(invalid=""ignore""):\n        for i in range(y.shape[-1]):\n            idx = (i - count) > n\n            recent[idx] = np.nan\n            idx = ~fidx[..., i]\n            y[idx, i] = recent[idx]\n            idx = fidx[..., i]\n            count[idx] = i\n            recent[idx] = y[idx, i]\n    if axis != -1 or axis != ndim - 1:\n        y = np.rollaxis(y, ndim - 1, axis)\n    if ndim == 1:\n        return y[0]\n    return y\n\n\n# ---------------------------------------------------------------------------\n#\n# SciPy\n#\n# Local copy of SciPy\'s rankdata to avoid a SciPy dependency. The SciPy\n# license is included in the Bottleneck license file, which is distributed\n# with Bottleneck.\n#\n# Code taken from scipy master branch on Aug 31, 2016.\n\n\ndef scipy_rankdata(a, method=""average""):\n    """"""\n    rankdata(a, method=\'average\')\n    Assign ranks to data, dealing with ties appropriately.\n    Ranks begin at 1.  The `method` argument controls how ranks are assigned\n    to equal values.  See [1]_ for further discussion of ranking methods.\n    Parameters\n    ----------\n    a : array_like\n        The array of values to be ranked.  The array is first flattened.\n    method : str, optional\n        The method used to assign ranks to tied elements.\n        The options are \'average\', \'min\', \'max\', \'dense\' and \'ordinal\'.\n        \'average\':\n            The average of the ranks that would have been assigned to\n            all the tied values is assigned to each value.\n        \'min\':\n            The minimum of the ranks that would have been assigned to all\n            the tied values is assigned to each value.  (This is also\n            referred to as ""competition"" ranking.)\n        \'max\':\n            The maximum of the ranks that would have been assigned to all\n            the tied values is assigned to each value.\n        \'dense\':\n            Like \'min\', but the rank of the next highest element is assigned\n            the rank immediately after those assigned to the tied elements.\n        \'ordinal\':\n            All values are given a distinct rank, corresponding to the order\n            that the values occur in `a`.\n        The default is \'average\'.\n    Returns\n    -------\n    ranks : ndarray\n         An array of length equal to the size of `a`, containing rank\n         scores.\n    References\n    ----------\n    .. [1] ""Ranking"", http://en.wikipedia.org/wiki/Ranking\n    Examples\n    --------\n    >>> from scipy.stats import rankdata\n    >>> rankdata([0, 2, 3, 2])\n    array([ 1. ,  2.5,  4. ,  2.5])\n    >>> rankdata([0, 2, 3, 2], method=\'min\')\n    array([ 1,  2,  4,  2])\n    >>> rankdata([0, 2, 3, 2], method=\'max\')\n    array([ 1,  3,  4,  3])\n    >>> rankdata([0, 2, 3, 2], method=\'dense\')\n    array([ 1,  2,  3,  2])\n    >>> rankdata([0, 2, 3, 2], method=\'ordinal\')\n    array([ 1,  2,  4,  3])\n    """"""\n    if method not in (""average"", ""min"", ""max"", ""dense"", ""ordinal""):\n        raise ValueError(\'unknown method ""{0}""\'.format(method))\n\n    a = np.ravel(np.asarray(a))\n    algo = ""mergesort"" if method == ""ordinal"" else ""quicksort""\n    sorter = np.argsort(a, kind=algo)\n\n    inv = np.empty(sorter.size, dtype=np.intp)\n    inv[sorter] = np.arange(sorter.size, dtype=np.intp)\n\n    if method == ""ordinal"":\n        return inv + 1\n\n    a = a[sorter]\n    obs = np.r_[True, a[1:] != a[:-1]]\n    dense = obs.cumsum()[inv]\n\n    if method == ""dense"":\n        return dense\n\n    # cumulative counts of each unique value\n    count = np.r_[np.nonzero(obs)[0], len(obs)]\n\n    if method == ""max"":\n        return count[dense]\n\n    if method == ""min"":\n        return count[dense - 1] + 1\n\n    # average method\n    return 0.5 * (count[dense] + count[dense - 1] + 1)\n'"
bottleneck/slow/reduce.py,25,"b'import warnings\nfrom typing import Optional, Union\n\nimport numpy as np\nfrom numpy import nanmean, nansum\n\n__all__ = [\n    ""median"",\n    ""nanmedian"",\n    ""nansum"",\n    ""nanmean"",\n    ""nanvar"",\n    ""nanstd"",\n    ""nanmin"",\n    ""nanmax"",\n    ""nanargmin"",\n    ""nanargmax"",\n    ""ss"",\n    ""anynan"",\n    ""allnan"",\n]\n\n\ndef nanargmin(a: np.ndarray, axis: Optional[int] = None) -> Union[int, np.ndarray]:\n    ""Slow nanargmin function used for unaccelerated dtypes.""\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        return np.nanargmin(a, axis=axis)\n\n\ndef nanargmax(a: np.ndarray, axis: Optional[int] = None) -> Union[int, np.ndarray]:\n    ""Slow nanargmax function used for unaccelerated dtypes.""\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        return np.nanargmax(a, axis=axis)\n\n\ndef nanvar(\n    a: np.ndarray, axis: Optional[int] = None, ddof: int = 0\n) -> Union[float, np.ndarray]:\n    ""Slow nanvar function used for unaccelerated dtypes.""\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        return np.nanvar(a, axis=axis, ddof=ddof)\n\n\ndef nanstd(\n    a: np.ndarray, axis: Optional[int] = None, ddof: int = 0\n) -> Union[float, np.ndarray]:\n    ""Slow nanstd function used for unaccelerated dtypes.""\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        return np.nanstd(a, axis=axis, ddof=ddof)\n\n\ndef nanmin(a: np.ndarray, axis: Optional[int] = None) -> Union[int, float, np.ndarray]:\n    ""Slow nanmin function used for unaccelerated dtypes.""\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        return np.nanmin(a, axis=axis)\n\n\ndef nanmax(a: np.ndarray, axis: Optional[int] = None) -> Union[int, float, np.ndarray]:\n    ""Slow nanmax function used for unaccelerated dtypes.""\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        return np.nanmax(a, axis=axis)\n\n\ndef median(a: np.ndarray, axis: Optional[int] = None) -> Union[float, np.ndarray]:\n    ""Slow median function used for unaccelerated dtypes.""\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        return np.median(a, axis=axis)\n\n\ndef nanmedian(a: np.ndarray, axis: Optional[int] = None) -> Union[float, np.ndarray]:\n    ""Slow nanmedian function used for unaccelerated dtypes.""\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        return np.nanmedian(a, axis=axis)\n\n\ndef ss(a: np.ndarray, axis: Optional[int] = None) -> Union[int, float, np.ndarray]:\n    ""Slow sum of squares used for unaccelerated dtypes.""\n    a = np.asarray(a)\n    y = np.multiply(a, a).sum(axis)\n    return y\n\n\ndef anynan(a: np.ndarray, axis: Optional[int] = None) -> Union[bool, np.ndarray]:\n    ""Slow check for Nans used for unaccelerated dtypes.""\n    return np.isnan(a).any(axis)\n\n\ndef allnan(a: np.ndarray, axis: Optional[int] = None) -> Union[bool, np.ndarray]:\n    ""Slow check for all Nans used for unaccelerated dtypes.""\n    return np.isnan(a).all(axis)\n'"
bottleneck/src/__init__.py,0,b''
bottleneck/src/bn_config.py,0,"b'"""""" Based on numpy\'s approach to exposing compiler features via a config header.\nUnfortunately that file is not exposed, so re-implement the portions we need.\n""""""\nimport os\nimport sys\nimport textwrap\nfrom distutils.command.config import config as Config\nfrom typing import List\n\nOPTIONAL_FUNCTION_ATTRIBUTES = [\n    (""HAVE_ATTRIBUTE_OPTIMIZE_OPT_3"", \'__attribute__((optimize(""O3"")))\')\n]\n\nOPTIONAL_HEADERS = [(""HAVE_SSE2"", ""emmintrin.h"")]\n\nOPTIONAL_INTRINSICS = [\n    (""HAVE___BUILTIN_ISNAN"", ""__builtin_isnan"", ""0.""),\n    (""HAVE_ISNAN"", ""isnan"", ""0.""),\n    (""HAVE__ISNAN"", ""_isnan"", ""0.""),\n]\n\n\ndef get_python_header_include() -> List[str]:\n    if sys.platform == ""win32"":\n        suffix = [""include""]\n    else:\n        suffix = [""include"", ""python"" + sys.version[:3] + sys.abiflags]\n\n    results = []\n    for prefix in [sys.prefix, sys.exec_prefix]:\n        results.append(os.path.join(prefix, *suffix))\n\n    return results\n\n\ndef _get_compiler_list(cmd: Config) -> str:\n    """""" Return the compiler command as a list of strings. Distutils provides a\n    wildly inconsistent API here:\n      - UnixCCompiler returns a list\n      - MSVCCompiler intentionally doesn\'t set this variable\n      - CygwinCompiler returns a string\n\n    As we are focused on identifying gcc vs clang right now, we ignore MSVC\'s\n    bad result and convert all results into lists of strings\n    """"""\n    compiler = getattr(cmd.compiler, ""compiler"", """")\n    if isinstance(compiler, str):\n        compiler = compiler.split()\n    return compiler\n\n\ndef is_gcc(cmd: Config) -> bool:\n    return any(""gcc"" in x for x in _get_compiler_list(cmd))\n\n\ndef is_clang(cmd: Config) -> bool:\n    return any(""clang"" in x for x in _get_compiler_list(cmd))\n\n\ndef check_inline(cmd: Config) -> str:\n    """"""Return the inline identifier (may be empty).""""""\n    body = textwrap.dedent(\n        """"""\n        #ifndef __cplusplus\n        static %(inline)s int static_func (void)\n        {\n            return 0;\n        }\n        %(inline)s int nostatic_func (void)\n        {\n            return 0;\n        }\n        #endif\n        int main(void) {\n            int r1 = static_func();\n            int r2 = nostatic_func();\n            return r1 + r2;\n        }\n        """"""\n    )\n\n    for kw in [""inline"", ""__inline__"", ""__inline""]:\n        st = cmd.try_compile(body % {""inline"": kw}, None, None)\n        if st:\n            return kw\n\n    return """"\n\n\ndef check_gcc_function_attribute(cmd: Config, attribute: str, name: str) -> bool:\n    """"""Return True if the given function attribute is supported.""""""\n    if is_gcc(cmd):\n        pragma = \'#pragma GCC diagnostic error ""-Wattributes""\'\n    elif is_clang(cmd):\n        pragma = \'#pragma clang diagnostic error ""-Wattributes""\'\n    else:\n        pragma = """"\n\n    body = (\n        textwrap.dedent(\n            """"""\n        %s\n\n        int %s %s(void*);\n\n        int main(void)\n        {\n            return 0;\n        }\n        """"""\n        )\n        % (pragma, attribute, name)\n    )\n    if cmd.try_compile(body, None, None):\n        return True\n    else:\n        return False\n\n\ndef check_gcc_header(cmd: Config, header: str) -> bool:\n    return cmd.check_header(header, include_dirs=get_python_header_include(),)\n\n\ndef check_gcc_intrinsic(cmd: Config, intrinsic: str, value: str) -> bool:\n    """"""Return True if the given intrinsic is supported.""""""\n    body = (\n        textwrap.dedent(\n            """"""\n        int check(void) {\n            return %s(%s);\n        }\n\n        int main(void)\n        {\n            return check();\n        }\n        """"""\n        )\n        % (intrinsic, value)\n    )\n    if cmd.try_link(body, headers=[""math.h""]):\n        return True\n    else:\n        return False\n\n\ndef create_config_h(config: Config) -> None:\n    dirname = os.path.dirname(__file__)\n    config_h = os.path.join(dirname, ""bn_config.h"")\n\n    if (\n        os.path.exists(config_h)\n        and os.stat(__file__).st_mtime < os.stat(config_h).st_mtime\n    ):\n        return\n\n    if not check_gcc_header(config, ""Python.h""):\n        raise ValueError(\n            """"""Cannot compile a trivial program with Python.h! Please check the following:\n - A supported compiler is installed\n - Python development libraries are installed\n\n For detailed installation instructions, please see:\n https://bottleneck.readthedocs.io/en/latest/installing.html\n""""""\n        )\n\n    output = []\n\n    for config_attr, func_attr in OPTIONAL_FUNCTION_ATTRIBUTES:\n        if check_gcc_function_attribute(config, func_attr, config_attr.lower()):\n            output.append((config_attr, ""1""))\n        else:\n            output.append((config_attr, ""0""))\n\n    for config_attr, header in OPTIONAL_HEADERS:\n        if check_gcc_header(config, header):\n            output.append((config_attr, ""1""))\n        else:\n            output.append((config_attr, ""0""))\n\n    for config_attr, intrinsic, value in OPTIONAL_INTRINSICS:\n        if check_gcc_intrinsic(config, intrinsic, value):\n            output.append((config_attr, ""1""))\n        else:\n            output.append((config_attr, ""0""))\n\n    inline_alias = check_inline(config)\n\n    with open(config_h, ""w"") as f:\n        for setting in output:\n            f.write(""#define {} {}\\n"".format(*setting))\n\n        if inline_alias == ""inline"":\n            f.write(""/* undef inline */\\n"")\n        else:\n            f.write(""#define inline {}\\n"".format(inline_alias))\n\n        # ISO C requires every translation unit to have 1+ declarations\n        f.write(""typedef int _make_iso_compilers_happy;\\n"")\n'"
bottleneck/src/bn_template.py,0,"b'import ast\nimport os\nimport posixpath as path\nimport re\nfrom typing import Dict, List, Optional, Pattern, Tuple\n\n\ndef make_c_files(\n    dirpath: Optional[str] = None, modules: Optional[List[str]] = None\n) -> None:\n    if modules is None:\n        modules = [""reduce"", ""move"", ""nonreduce"", ""nonreduce_axis""]\n    if dirpath is None:\n        dirpath = os.path.dirname(__file__)\n    for module in modules:\n        template_file = os.path.join(dirpath, module + ""_template.c"")\n        posix_template = path.relpath(path.join(dirpath, module + ""_template.c""))\n        target_file = os.path.join(dirpath, module + "".c"")\n\n        if (\n            os.path.exists(target_file)\n            and os.stat(template_file).st_mtime < os.stat(target_file).st_mtime\n        ):\n            continue\n\n        with open(template_file, ""r"") as f:\n            src_str = f.read()\n        src_str = \'#line 1 ""{}""\\n\'.format(posix_template) + template(src_str)\n        if len(src_str) and src_str[-1] != ""\\n"":\n            src_str += ""\\n""\n        with open(target_file, ""w"") as f:\n            f.write(src_str)\n\n\ndef template(src_str: str) -> str:\n    src_list = src_str.splitlines()\n    line_numbers = []\n    last_empty_ind = 0\n    for i, l in enumerate(src_list):\n        if l.strip().endswith(""{"") and not l.startswith("" ""):\n            line_numbers.append(last_empty_ind)\n\n        if len(l.strip()) == 0 or ""*/"" in l:\n            last_empty_ind = i + 1\n\n    distinct_line_numbers = set(line_numbers)\n    new_src_list = []\n    for i, l in enumerate(src_list):\n        if i in distinct_line_numbers:\n            new_src_list.append(""#line {}"".format(i + 1))\n        new_src_list.append(l)\n\n    src_list = repeat_templating(new_src_list)\n    src_list = dtype_templating(src_list)\n    src_list = string_templating(src_list)\n    src_str = ""\\n"".join(src_list)\n    src_str = re.sub(r""\\n\\s*\\n\\s*\\n"", r""\\n\\n"", src_str)\n    return src_str\n\n\n# repeat --------------------------------------------------------------------\n\nREPEAT_BEGIN = re.compile(r""^/\\*\\s*repeat\\s*=\\s*"")\nREPEAT_END = re.compile(r""^/\\*\\s*repeat end"")\nCOMMENT_END = re.compile(r"".*\\*\\/.*"")\n\n\ndef repeat_templating(lines: List[str]) -> List[str]:\n    index = 0\n    while True:\n        idx0, idx1 = next_block(lines, index, REPEAT_BEGIN, REPEAT_END)\n        if idx0 is None or idx1 is None:\n            break\n        func_list = lines[idx0:idx1]\n        func_list = expand_functions_repeat(func_list)\n        # the +1 below is to skip the /* repeat end */ line\n        lines = lines[:idx0] + func_list + lines[idx1 + 1 :]\n        index = idx0\n    return lines\n\n\ndef expand_functions_repeat(lines: List[str]) -> List[str]:\n    idx = first_occurence(COMMENT_END, lines)\n    repeat_dict = repeat_info(lines[: idx + 1])\n    lines = lines[idx + 1 :]\n    func_str = ""\\n"".join(lines)\n    func_list = expand_repeat(func_str, repeat_dict)\n    return func_list\n\n\ndef repeat_info(lines: List[str]) -> Dict[str, str]:\n    line = """".join(lines)\n    repeat = re.findall(r""\\{.*\\}"", line)\n    repeat_dict: Dict[str, str] = ast.literal_eval(repeat[0])\n    return repeat_dict\n\n\ndef expand_repeat(func_str: str, repeat_dict: Dict[str, str]) -> List[str]:\n    nrepeats = [len(repeat_dict[key]) for key in repeat_dict]\n    if len(set(nrepeats)) != 1:\n        raise ValueError(""All repeat lists must be the same length"")\n    nrepeat = nrepeats[0]\n    func_list = []\n    for i in range(nrepeat):\n        f = func_str[:]\n        for key in repeat_dict:\n            f = f.replace(key, repeat_dict[key][i])\n        func_list.append(""\\n"" + f)\n    func_list = ("""".join(func_list)).splitlines()\n    return func_list\n\n\n# dtype ---------------------------------------------------------------------\n\nDTYPE_BEGIN = re.compile(r""^/\\*\\s*dtype\\s*=\\s*"")\nDTYPE_END = re.compile(r""^/\\*\\s*dtype end"")\n\n\ndef dtype_templating(lines: List[str]) -> List[str]:\n    index = 0\n    while True:\n        idx0, idx1 = next_block(lines, index, DTYPE_BEGIN, DTYPE_END)\n        if idx0 is None or idx1 is None:\n            break\n        func_list = lines[idx0:idx1]\n        func_list = expand_functions_dtype(func_list)\n        # the +1 below is to skip the /* dtype end */ line\n        lines = lines[:idx0] + func_list + lines[idx1 + 1 :]\n        index = idx0\n    return lines\n\n\ndef expand_functions_dtype(lines: List[str]) -> List[str]:\n    idx = first_occurence(COMMENT_END, lines)\n    dtypes = dtype_info(lines[: idx + 1])\n    lines = lines[idx + 1 :]\n    func_str = ""\\n"".join(lines)\n    func_list = expand_dtypes(func_str, dtypes)\n    return func_list\n\n\ndef dtype_info(lines: List[str]) -> List[str]:\n    line = """".join(lines)\n    dtypes = re.findall(r""\\[.*\\]"", line)\n    if len(dtypes) != 1:\n        raise ValueError(""expecting exactly one dtype specification"")\n    dtypes = ast.literal_eval(dtypes[0])\n    return dtypes\n\n\ndef expand_dtypes(func_str: str, dtypes: List[str]) -> List[str]:\n    if ""DTYPE"" not in func_str:\n        raise ValueError(""cannot find dtype marker"")\n    func_list = []\n    for dtype in dtypes:\n        f = func_str[:]\n        for i, dt in enumerate(dtype):\n            f = f.replace(""DTYPE%d"" % i, dt)\n            if i > 0:\n                f = f + ""\\n""\n        func_list.append(""\\n\\n"" + f)\n    return func_list\n\n\n# multiline strings ---------------------------------------------------------\n\nSTRING_BEGIN = re.compile(r"".*MULTILINE STRING BEGIN.*"")\nSTRING_END = re.compile(r"".*MULTILINE STRING END.*"")\n\n\ndef string_templating(lines: List[str]) -> List[str]:\n    index = 0\n    while True:\n        idx0, idx1 = next_block(lines, index, STRING_BEGIN, STRING_END)\n        if idx0 is None or idx1 is None:\n            break\n        str_list = lines[idx0 + 1 : idx1]\n        str_list = quote_string(str_list)\n        lines = lines[:idx0] + str_list + lines[idx1 + 1 :]\n        index = idx0\n    return lines\n\n\ndef quote_string(lines: List[str]) -> List[str]:\n    for i in range(len(lines)):\n        lines[i] = \'""\' + lines[i] + r""\\n"" + \'""\'\n    lines[-1] = lines[-1] + "";""\n    return lines\n\n\n# utility -------------------------------------------------------------------\n\n\ndef first_occurence(pattern: Pattern[str], lines: List[str]) -> int:\n    for i in range(len(lines)):\n        if re.match(pattern, lines[i]):\n            return i\n    raise ValueError(""`pattern` not found"")\n\n\ndef next_block(\n    lines: List[str], index: int, begin_pattern: Pattern[str], end_pattern: Pattern[str]\n) -> Tuple[Optional[int], Optional[int]]:\n    idx = None\n    for i in range(index, len(lines)):\n        line = lines[i]\n        if re.match(begin_pattern, line):\n            idx = i\n        elif re.match(end_pattern, line):\n            if idx is None:\n                raise ValueError(""found end of function before beginning"")\n            return idx, i\n    return None, None\n'"
bottleneck/tests/__init__.py,0,b''
bottleneck/tests/input_modification_test.py,2,"b'""""""Test functions.""""""\n\nimport warnings\nfrom typing import List, Optional\n\nimport hypothesis\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_equal\n\nfrom .util import get_functions, hy_array_gen\n\n\n@pytest.mark.parametrize(""func"", get_functions(""all""), ids=lambda x: x.__name__)\n@hypothesis.given(array=hy_array_gen)\ndef test_modification(func, array):\n    """"""Test that bn.xxx gives the same output as np.xxx.""""""\n    name = func.__name__\n    if name == ""replace"":\n        return\n    msg = ""\\nInput array modified by %s.\\n\\n""\n    msg += ""input array before:\\n%s\\nafter:\\n%s\\n""\n    axes: List[Optional[int]] = list(range(-array.ndim, array.ndim))\n    if all(x not in name for x in [""push"", ""move"", ""sort"", ""partition""]):\n        axes += [None]\n\n    second_arg = 1\n    if ""partition"" in name:\n        second_arg = 0\n\n    for axis in axes:\n        with np.errstate(invalid=""ignore""):\n            a1 = array.copy()\n            a2 = array.copy()\n            if any(x in name for x in [""move"", ""sort"", ""partition""]):\n                with warnings.catch_warnings():\n                    warnings.simplefilter(""ignore"")\n                    func(a1, second_arg, axis=axis)\n            else:\n                try:\n                    with warnings.catch_warnings():\n                        warnings.simplefilter(""ignore"")\n                        func(a1, axis=axis)\n                except ValueError as e:\n                    if name.startswith(""nanarg"") and ""All-NaN slice encountered"" in str(\n                        e\n                    ):\n                        continue\n            assert_equal(a1, a2, msg % (name, a1, a2))\n'"
bottleneck/tests/list_input_test.py,2,"b'""""""Check that functions can handle list input""""""\n\nimport warnings\n\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_array_almost_equal\n\nimport bottleneck as bn\nfrom .util import DTYPES\n\n\ndef lists(dtypes=DTYPES):\n    """"""Iterator that yields lists to use for unit testing.""""""\n    ss = {}\n    ss[1] = {""size"": 4, ""shapes"": [(4,)]}\n    ss[2] = {""size"": 6, ""shapes"": [(1, 6), (2, 3)]}\n    ss[3] = {""size"": 6, ""shapes"": [(1, 2, 3)]}\n    ss[4] = {""size"": 24, ""shapes"": [(1, 2, 3, 4)]}\n    for ndim in ss:\n        size = ss[ndim][""size""]\n        shapes = ss[ndim][""shapes""]\n        a = np.arange(size)\n        for shape in shapes:\n            a = a.reshape(shape)\n            for dtype in dtypes:\n                yield a.astype(dtype).tolist()\n\n\n@pytest.mark.parametrize(""func"", bn.get_functions(""all""), ids=lambda x: x.__name__)\ndef test_list_input(func):\n    """"""Test that bn.xxx gives the same output as bn.slow.xxx for list input.""""""\n    msg = ""\\nfunc %s | input %s (%s) | shape %s\\n""\n    msg += ""\\nInput array:\\n%s\\n""\n    name = func.__name__\n    if name == ""replace"":\n        return\n    func0 = eval(""bn.slow.%s"" % name)\n    for i, a in enumerate(lists()):\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"")\n            try:\n                actual = func(a)\n                desired = func0(a)\n            except TypeError:\n                actual = func(a, 2)\n                desired = func0(a, 2)\n        a = np.array(a)\n        tup = (name, ""a"" + str(i), str(a.dtype), str(a.shape), a)\n        err_msg = msg % tup\n        assert_array_almost_equal(actual, desired, err_msg=err_msg)\n'"
bottleneck/tests/memory_test.py,1,"b'import sys\n\nimport numpy as np\nimport pytest\n\nimport bottleneck as bn\n\n\n@pytest.mark.skipif(\n    sys.platform.startswith(""win""), reason=""resource module not available on windows""\n)\ndef test_memory_leak() -> None:\n    import resource\n\n    arr = np.arange(1).reshape((1, 1))\n\n    n_attempts = 3\n    results = []\n\n    for _ in range(n_attempts):\n        starting = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n\n        for _ in range(1000):\n            for axis in [None, 0, 1]:\n                bn.nansum(arr, axis=axis)\n                bn.nanargmax(arr, axis=axis)\n                bn.nanargmin(arr, axis=axis)\n                bn.nanmedian(arr, axis=axis)\n                bn.nansum(arr, axis=axis)\n                bn.nanmean(arr, axis=axis)\n                bn.nanmin(arr, axis=axis)\n                bn.nanmax(arr, axis=axis)\n                bn.nanvar(arr, axis=axis)\n\n        ending = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n\n        diff = ending - starting\n        diff_bytes = diff * resource.getpagesize()\n        # For 1.3.0 release, this had value of ~100kB\n        if diff_bytes:\n            results.append(diff_bytes)\n        else:\n            break\n\n    assert len(results) < n_attempts\n'"
bottleneck/tests/move_test.py,13,"b'""""""Test moving window functions.""""""\n\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_array_almost_equal, assert_equal, assert_raises\n\nimport bottleneck as bn\nfrom .util import array_order, arrays\n\n\n@pytest.mark.parametrize(""func"", bn.get_functions(""move""), ids=lambda x: x.__name__)\ndef test_move(func):\n    """"""Test that bn.xxx gives the same output as a reference function.""""""\n    fmt = (\n        ""\\nfunc %s | window %d | min_count %s | input %s (%s) | shape %s | ""\n        ""axis %s | order %s\\n""\n    )\n    fmt += ""\\nInput array:\\n%s\\n""\n    aaae = assert_array_almost_equal\n    func_name = func.__name__\n    func0 = eval(""bn.slow.%s"" % func_name)\n    if func_name == ""move_var"":\n        decimal = 3\n    else:\n        decimal = 5\n    for i, a in enumerate(arrays(func_name)):\n        axes = range(-1, a.ndim)\n        for axis in axes:\n            windows = range(1, a.shape[axis])\n            for window in windows:\n                min_counts = list(range(1, window + 1)) + [None]\n                for min_count in min_counts:\n                    actual = func(a, window, min_count, axis=axis)\n                    desired = func0(a, window, min_count, axis=axis)\n                    tup = (\n                        func_name,\n                        window,\n                        str(min_count),\n                        ""a"" + str(i),\n                        str(a.dtype),\n                        str(a.shape),\n                        str(axis),\n                        array_order(a),\n                        a,\n                    )\n                    err_msg = fmt % tup\n                    aaae(actual, desired, decimal, err_msg)\n                    err_msg += ""\\n dtype mismatch %s %s""\n                    da = actual.dtype\n                    dd = desired.dtype\n                    assert_equal(da, dd, err_msg % (da, dd))\n\n\n# ---------------------------------------------------------------------------\n# Test argument parsing\n\n\n@pytest.mark.parametrize(""func"", bn.get_functions(""move""), ids=lambda x: x.__name__)\ndef test_arg_parsing(func, decimal=5):\n    """"""test argument parsing.""""""\n\n    name = func.__name__\n    func0 = eval(""bn.slow.%s"" % name)\n\n    a = np.array([1.0, 2, 3])\n\n    fmt = ""\\n%s"" % func\n    fmt += ""%s\\n""\n    fmt += ""\\nInput array:\\n%s\\n"" % a\n\n    actual = func(a, 2)\n    desired = func0(a, 2)\n    err_msg = fmt % ""(a, 2)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    actual = func(a, 2, 1)\n    desired = func0(a, 2, 1)\n    err_msg = fmt % ""(a, 2, 1)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    actual = func(a, window=2)\n    desired = func0(a, window=2)\n    err_msg = fmt % ""(a, window=2)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    actual = func(a, window=2, min_count=1)\n    desired = func0(a, window=2, min_count=1)\n    err_msg = fmt % ""(a, window=2, min_count=1)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    actual = func(a, window=2, min_count=1, axis=0)\n    desired = func0(a, window=2, min_count=1, axis=0)\n    err_msg = fmt % ""(a, window=2, min_count=1, axis=0)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    actual = func(a, min_count=1, window=2, axis=0)\n    desired = func0(a, min_count=1, window=2, axis=0)\n    err_msg = fmt % ""(a, min_count=1, window=2, axis=0)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    actual = func(a, axis=-1, min_count=None, window=2)\n    desired = func0(a, axis=-1, min_count=None, window=2)\n    err_msg = fmt % ""(a, axis=-1, min_count=None, window=2)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    actual = func(a=a, axis=-1, min_count=None, window=2)\n    desired = func0(a=a, axis=-1, min_count=None, window=2)\n    err_msg = fmt % ""(a=a, axis=-1, min_count=None, window=2)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    if name in (""move_std"", ""move_var""):\n        actual = func(a, 2, 1, -1, ddof=1)\n        desired = func0(a, 2, 1, -1, ddof=1)\n        err_msg = fmt % ""(a, 2, 1, -1, ddof=1)""\n        assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    # regression test: make sure len(kwargs) == 0 doesn\'t raise\n    args = (a, 1, 1, -1)\n    kwargs = {}\n    func(*args, **kwargs)\n\n\n@pytest.mark.parametrize(""func"", bn.get_functions(""move""), ids=lambda x: x.__name__)\ndef test_arg_parse_raises(func):\n    """"""test argument parsing raises in move""""""\n    a = np.array([1.0, 2, 3])\n    assert_raises(TypeError, func)\n    assert_raises(TypeError, func, axis=a)\n    assert_raises(TypeError, func, a, 2, axis=0, extra=0)\n    assert_raises(TypeError, func, a, 2, axis=0, a=a)\n    assert_raises(TypeError, func, a, 2, 2, 0, 0, 0)\n    assert_raises(TypeError, func, a, 2, axis=""0"")\n    assert_raises(TypeError, func, a, 1, min_count=""1"")\n    if func.__name__ not in (""move_std"", ""move_var""):\n        assert_raises(TypeError, func, a, 2, ddof=0)\n\n\n# ---------------------------------------------------------------------------\n# move_median.c is complicated. Let\'s do some more testing.\n#\n# If you make changes to move_median.c then do lots of tests by increasing\n# range(100) in the two functions below to range(10000). And for extra credit\n# increase size to 30. With those two changes the unit tests will take a\n# LONG time to run.\n\n\ndef test_move_median_with_nans():\n    """"""test move_median.c with nans""""""\n    fmt = ""\\nfunc %s | window %d | min_count %s\\n\\nInput array:\\n%s\\n""\n    aaae = assert_array_almost_equal\n    min_count = 1\n    size = 10\n    func = bn.move_median\n    func0 = bn.slow.move_median\n    rs = np.random.RandomState([1, 2, 3])\n    for i in range(100):\n        a = np.arange(size, dtype=np.float64)\n        idx = rs.rand(*a.shape) < 0.1\n        a[idx] = np.inf\n        idx = rs.rand(*a.shape) < 0.2\n        a[idx] = np.nan\n        rs.shuffle(a)\n        for window in range(2, size + 1):\n            actual = func(a, window=window, min_count=min_count)\n            desired = func0(a, window=window, min_count=min_count)\n            err_msg = fmt % (func.__name__, window, min_count, a)\n            aaae(actual, desired, decimal=5, err_msg=err_msg)\n\n\ndef test_move_median_without_nans():\n    """"""test move_median.c without nans""""""\n    fmt = ""\\nfunc %s | window %d | min_count %s\\n\\nInput array:\\n%s\\n""\n    aaae = assert_array_almost_equal\n    min_count = 1\n    size = 10\n    func = bn.move_median\n    func0 = bn.slow.move_median\n    rs = np.random.RandomState([1, 2, 3])\n    for i in range(100):\n        a = np.arange(size, dtype=np.int64)\n        rs.shuffle(a)\n        for window in range(2, size + 1):\n            actual = func(a, window=window, min_count=min_count)\n            desired = func0(a, window=window, min_count=min_count)\n            err_msg = fmt % (func.__name__, window, min_count, a)\n            aaae(actual, desired, decimal=5, err_msg=err_msg)\n\n\n# ----------------------------------------------------------------------------\n# Regression test for square roots of negative numbers\n\n\ndef test_move_std_sqrt():\n    """"""Test move_std for neg sqrt.""""""\n\n    a = [\n        0.0011448196318903589,\n        0.00028718669878572767,\n        0.00028718669878572767,\n        0.00028718669878572767,\n        0.00028718669878572767,\n    ]\n    err_msg = ""Square root of negative number. ndim = %d""\n    b = bn.move_std(a, window=3)\n    assert np.isfinite(b[2:]).all(), err_msg % 1\n\n    a2 = np.array([a, a])\n    b = bn.move_std(a2, window=3, axis=1)\n    assert np.isfinite(b[:, 2:]).all(), err_msg % 2\n\n    a3 = np.array([[a, a], [a, a]])\n    b = bn.move_std(a3, window=3, axis=2)\n    assert np.isfinite(b[:, :, 2:]).all(), err_msg % 3\n'"
bottleneck/tests/nonreduce_axis_test.py,9,"b'import numpy as np\nimport pytest\nfrom numpy.testing import (\n    assert_array_almost_equal,\n    assert_array_equal,\n    assert_equal,\n    assert_raises,\n)\n\nimport bottleneck as bn\nfrom .reduce_test import unit_maker as reduce_unit_maker\nfrom .reduce_test import unit_maker_argparse as unit_maker_parse_rankdata\nfrom .util import DTYPES, array_order, arrays\n\n# ---------------------------------------------------------------------------\n# partition, argpartition\n\n\n@pytest.mark.parametrize(\n    ""func"", (bn.partition, bn.argpartition), ids=lambda x: x.__name__\n)\ndef test_partition_and_argpartition(func):\n    """"""test partition or argpartition""""""\n\n    msg = ""\\nfunc %s | input %s (%s) | shape %s | n %d | axis %s | order %s\\n""\n    msg += ""\\nInput array:\\n%s\\n""\n\n    name = func.__name__\n    func0 = eval(""bn.slow.%s"" % name)\n\n    rs = np.random.RandomState([1, 2, 3])\n    for i, a in enumerate(arrays(name)):\n        if a.ndim == 0 or a.size == 0 or a.ndim > 3:\n            continue\n        for axis in list(range(-1, a.ndim)) + [None]:\n            if axis is None:\n                nmax = a.size - 1\n            else:\n                nmax = a.shape[axis] - 1\n            if nmax < 1:\n                continue\n            n = rs.randint(nmax)\n            s0 = func0(a, n, axis)\n            s1 = func(a, n, axis)\n            if name == ""argpartition"":\n                s0 = complete_the_argpartition(s0, a, n, axis)\n                s1 = complete_the_argpartition(s1, a, n, axis)\n            else:\n                s0 = complete_the_partition(s0, n, axis)\n                s1 = complete_the_partition(s1, n, axis)\n            tup = (\n                name,\n                ""a"" + str(i),\n                str(a.dtype),\n                str(a.shape),\n                n,\n                str(axis),\n                array_order(a),\n                a,\n            )\n            err_msg = msg % tup\n            assert_array_equal(s1, s0, err_msg)\n\n\ndef complete_the_partition(a, n, axis):\n    def func1d(a, n):\n        a[:n] = np.sort(a[:n])\n        a[n + 1 :] = np.sort(a[n + 1 :])\n        return a\n\n    a = a.copy()\n    ndim = a.ndim\n    if axis is None:\n        if ndim != 1:\n            raise ValueError(""`a` must be 1d when axis is None"")\n        axis = 0\n    elif axis < 0:\n        axis += ndim\n        if axis < 0:\n            raise ValueError(""`axis` out of range"")\n    a = np.apply_along_axis(func1d, axis, a, n)\n    return a\n\n\ndef complete_the_argpartition(index, a, n, axis):\n    a = a.copy()\n    ndim = a.ndim\n    if axis is None:\n        if index.ndim != 1:\n            raise ValueError(""`index` must be 1d when axis is None"")\n        axis = 0\n        ndim = 1\n        a = a.reshape(-1)\n    elif axis < 0:\n        axis += ndim\n        if axis < 0:\n            raise ValueError(""`axis` out of range"")\n    if ndim == 1:\n        a = a[index]\n    elif ndim == 2:\n        if axis == 0:\n            for i in range(a.shape[1]):\n                a[:, i] = a[index[:, i], i]\n        elif axis == 1:\n            for i in range(a.shape[0]):\n                a[i] = a[i, index[i]]\n        else:\n            raise ValueError(""`axis` out of range"")\n    elif ndim == 3:\n        if axis == 0:\n            for i in range(a.shape[1]):\n                for j in range(a.shape[2]):\n                    a[:, i, j] = a[index[:, i, j], i, j]\n        elif axis == 1:\n            for i in range(a.shape[0]):\n                for j in range(a.shape[2]):\n                    a[i, :, j] = a[i, index[i, :, j], j]\n        elif axis == 2:\n            for i in range(a.shape[0]):\n                for j in range(a.shape[1]):\n                    a[i, j, :] = a[i, j, index[i, j, :]]\n        else:\n            raise ValueError(""`axis` out of range"")\n    else:\n        raise ValueError(""`a.ndim` must be 1, 2, or 3"")\n    a = complete_the_partition(a, n, axis)\n    return a\n\n\ndef test_transpose():\n    """"""partition transpose test""""""\n    a = np.arange(12).reshape(4, 3)\n    actual = bn.partition(a.T, 2, -1).T\n    desired = bn.slow.partition(a.T, 2, -1).T\n    assert_equal(actual, desired, ""partition transpose test"")\n\n\n# ---------------------------------------------------------------------------\n# rankdata, nanrankdata, push\n\n\n@pytest.mark.parametrize(\n    ""func"", (bn.rankdata, bn.nanrankdata, bn.push), ids=lambda x: x.__name__\n)\ndef test_nonreduce_axis(func):\n    """"""Test nonreduce axis functions""""""\n    return reduce_unit_maker(func)\n\n\ndef test_push():\n    """"""Test push""""""\n    ns = (0, 1, 2, 3, 4, 5, None)\n    a = np.array([np.nan, 1, 2, np.nan, np.nan, np.nan, np.nan, 3, np.nan])\n    for n in ns:\n        actual = bn.push(a.copy(), n=n)\n        desired = bn.slow.push(a.copy(), n=n)\n        assert_array_equal(actual, desired, ""failed on n=%s"" % str(n))\n\n\n# ---------------------------------------------------------------------------\n# Test argument parsing\n\n\n@pytest.mark.parametrize(\n    ""func"", bn.get_functions(""nonreduce_axis""), ids=lambda x: x.__name__\n)\ndef test_arg_parsing(func):\n    """"""test argument parsing in nonreduce_axis""""""\n    name = func.__name__\n    if name in (""partition"", ""argpartition""):\n        return unit_maker_parse(func)\n    elif name in (""push""):\n        return unit_maker_parse(func)\n    elif name in (""rankdata"", ""nanrankdata""):\n        return unit_maker_parse_rankdata(func)\n    else:\n        fmt = ""``%s` is an unknown nonreduce_axis function""\n        raise ValueError(fmt % name)\n\n\n@pytest.mark.parametrize(\n    ""func"", bn.get_functions(""nonreduce_axis""), ids=lambda x: x.__name__\n)\ndef test_arg_raises(func):\n    return unit_maker_raises(func)\n\n\ndef unit_maker_parse(func, decimal=5):\n    """"""test argument parsing.""""""\n\n    name = func.__name__\n    func0 = eval(""bn.slow.%s"" % name)\n\n    a = np.array([1.0, 2, 3])\n\n    fmt = ""\\n%s"" % func\n    fmt += ""%s\\n""\n    fmt += ""\\nInput array:\\n%s\\n"" % a\n\n    actual = func(a, 1)\n    desired = func0(a, 1)\n    err_msg = fmt % ""(a, 1)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    actual = func(a, 1, axis=0)\n    desired = func0(a, 1, axis=0)\n    err_msg = fmt % ""(a, 1, axis=0)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    if name != ""push"":\n\n        actual = func(a, 2, None)\n        desired = func0(a, 2, None)\n        err_msg = fmt % ""(a, 2, None)""\n        assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n        actual = func(a, 1, axis=None)\n        desired = func0(a, 1, axis=None)\n        err_msg = fmt % ""(a, 1, axis=None)""\n        assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n        # regression test: make sure len(kwargs) == 0 doesn\'t raise\n        args = (a, 1, -1)\n        kwargs = {}\n        func(*args, **kwargs)\n\n    else:\n\n        # regression test: make sure len(kwargs) == 0 doesn\'t raise\n        args = (a, 1)\n        kwargs = {}\n        func(*args, **kwargs)\n\n\ndef unit_maker_raises(func):\n    """"""test argument parsing raises in nonreduce_axis""""""\n    a = np.array([1.0, 2, 3])\n    assert_raises(TypeError, func)\n    assert_raises(TypeError, func, axis=a)\n    assert_raises(TypeError, func, a, axis=0, extra=0)\n    assert_raises(TypeError, func, a, axis=0, a=a)\n    if func.__name__ in (""partition"", ""argpartition""):\n        assert_raises(TypeError, func, a, 0, 0, 0, 0, 0)\n        assert_raises(TypeError, func, a, axis=""0"")\n\n\n@pytest.mark.parametrize(""dtype"", DTYPES)\n@pytest.mark.parametrize(\n    ""func"", (bn.partition, bn.argpartition), ids=lambda x: x.__name__\n)\ndef test_out_of_bounds_raises(func, dtype):\n    array = np.ones((10, 10), dtype=dtype)\n    for axis in [None, 0, 1, -1]:\n        with pytest.raises(ValueError, match=""must be between""):\n            func(array, 1000, axis=axis)\n\n        with pytest.raises(ValueError, match=""must be between""):\n            func(array, -1, axis=axis)\n'"
bottleneck/tests/nonreduce_test.py,13,"b'""""""Test replace().""""""\n\nimport warnings\n\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_array_equal, assert_equal, assert_raises\n\nimport bottleneck as bn\nfrom .util import DTYPES, INT_DTYPES, array_order, arrays\n\n\n@pytest.mark.parametrize(\n    ""func"", bn.get_functions(""nonreduce""), ids=lambda x: x.__name__\n)\ndef test_nonreduce(func):\n    """"""Test that bn.xxx gives the same output as np.xxx.""""""\n    msg = ""\\nfunc %s | input %s (%s) | shape %s | old %f | new %f | order %s\\n""\n    msg += ""\\nInput array:\\n%s\\n""\n    name = func.__name__\n    func0 = eval(""bn.slow.%s"" % name)\n    rs = np.random.RandomState([1, 2, 3])\n    news = [1, 0, np.nan, -np.inf]\n    for i, arr in enumerate(arrays(name)):\n        for idx in range(2):\n            if arr.size == 0:\n                old = 0\n            else:\n                idx = rs.randint(max(arr.size, 1))\n                old = arr.flat[idx]\n            for new in news:\n                if not issubclass(arr.dtype.type, np.inexact):\n                    if not np.isfinite(old):\n                        # Cannot safely cast to int\n                        continue\n                    if not np.isfinite(new):\n                        # Cannot safely cast to int\n                        continue\n                actual = arr.copy()\n                with warnings.catch_warnings():\n                    warnings.simplefilter(""ignore"")\n                    func(actual, old, new)\n                desired = arr.copy()\n                with warnings.catch_warnings():\n                    warnings.simplefilter(""ignore"")\n                    func0(desired, old, new)\n                tup = (\n                    name,\n                    ""a"" + str(i),\n                    str(arr.dtype),\n                    str(arr.shape),\n                    old,\n                    new,\n                    array_order(arr),\n                    arr,\n                )\n                err_msg = msg % tup\n                assert_array_equal(actual, desired, err_msg=err_msg)\n                err_msg += ""\\n dtype mismatch %s %s""\n                if hasattr(actual, ""dtype"") or hasattr(desired, ""dtype""):\n                    da = actual.dtype\n                    dd = desired.dtype\n                    assert_equal(da, dd, err_msg % (da, dd))\n\n\n# ---------------------------------------------------------------------------\n# Check that exceptions are raised\n\n\ndef test_replace_unsafe_cast():\n    """"""Test replace for unsafe casts""""""\n    dtypes = INT_DTYPES\n    for dtype in dtypes:\n        a = np.zeros(3, dtype=dtype)\n        assert_raises(ValueError, bn.replace, a.copy(), 0.1, 0)\n        assert_raises(ValueError, bn.replace, a.copy(), 0, 0.1)\n        assert_raises(ValueError, bn.slow.replace, a.copy(), 0.1, 0)\n        assert_raises(ValueError, bn.slow.replace, a.copy(), 0, 0.1)\n\n\ndef test_non_array():\n    """"""Test that non-array input raises""""""\n    a = [1, 2, 3]\n    assert_raises(TypeError, bn.replace, a, 0, 1)\n    a = (1, 2, 3)\n    assert_raises(TypeError, bn.replace, a, 0, 1)\n\n\n# ---------------------------------------------------------------------------\n# Make sure bn.replace and bn.slow.replace can handle int arrays where\n# user wants to replace nans\n\n\n@pytest.mark.parametrize(""dtype"", INT_DTYPES)\ndef test_replace_nan_int(dtype):\n    """"""Test replace, int array, old=nan, new=0""""""\n    a = np.arange(2 * 3 * 4, dtype=dtype).reshape(2, 3, 4)\n    actual = a.copy()\n    bn.replace(actual, np.nan, 0)\n    desired = a.copy()\n    msg = ""replace failed on int input looking for nans""\n    assert_array_equal(actual, desired, err_msg=msg)\n    actual = a.copy()\n    bn.slow.replace(actual, np.nan, 0)\n    msg = ""slow.replace failed on int input looking for nans""\n    assert_array_equal(actual, desired, err_msg=msg)\n\n\ndef test_replace_bad_args():\n    array = np.ones((10, 10))\n    bad_vals = [None, """", [0], ""0""]\n    for bad_val in bad_vals:\n        with pytest.raises(TypeError, match=""`old` must be a number""):\n            bn.replace(array, bad_val, 0)\n\n        with pytest.raises(TypeError, match=""`new` must be a number""):\n            bn.replace(array, 0, bad_val)\n\n    with pytest.raises(TypeError, match=""Cannot find `a` keyword input""):\n        bn.replace(foo=array)\n\n    with pytest.raises(TypeError, match=""Cannot find `old` keyword input""):\n        bn.replace(a=array)\n\n    with pytest.raises(TypeError, match=""Cannot find `new` keyword input""):\n        bn.replace(a=array, old=0)\n\n    with pytest.raises(TypeError, match=""wrong number of arguments 4""):\n        bn.replace(array, 0)\n\n    with pytest.raises(TypeError, match=""wrong number of arguments 4""):\n        bn.replace(array, 0, 0, 0)\n\n\n@pytest.mark.parametrize(""dtype"", DTYPES)\ndef test_replace_newaxis(dtype):\n    array = np.ones((2, 2), dtype=dtype)[..., np.newaxis]\n    result = bn.replace(array, 1, 2)\n    assert (result == 2).all().all()\n\n\n@pytest.mark.parametrize(""dtype"", DTYPES)\ndef test_replace_view(dtype):\n    array = np.arange(20, dtype=dtype)\n    view = array[::2]\n\n    bn.replace(view, 5, -1)\n    assert view.min() == 0\n    assert array.min() == 0\n'"
bottleneck/tests/reduce_test.py,28,"b'""""""Test reduce functions.""""""\n\nimport traceback\nimport warnings\nfrom typing import Callable, List, Optional, Union\n\nimport hypothesis\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_array_almost_equal, assert_equal, assert_raises\n\nimport bottleneck as bn\nfrom .util import DTYPES, array_order, arrays, hy_array_gen, hy_int_array_gen\n\n\ndef _hypothesis_helper(\n    func: Callable[[np.ndarray], Union[int, float, np.ndarray]],\n    array: np.ndarray,\n    skip_all_nans: bool = False,\n) -> None:\n    slow_func = eval(""bn.slow.%s"" % func.__name__)\n    ndim = array.ndim\n    axes: List[Optional[int]] = list(range(-ndim, ndim)) + [None]\n    for order in [""C"", ""F""]:\n        if order == ""F"":\n            arr = np.asfortranarray(array)\n        else:\n            arr = np.ascontiguousarray(array)\n\n        for axis in axes:\n            if skip_all_nans:\n                if not np.isfinite(arr).all(axis=axis).all():\n                    # The documentation for numpy.nanargmin/max has the following\n                    # errata:\n                    #\n                    # Warning: the results cannot be trusted if a slice contains only\n                    # NaNs and Infs.\n                    #\n                    # So skip in that case, as it is definitely wrong\n                    continue\n            try:\n                bn_result = func(arr, axis=axis)\n            except ValueError:\n                try:\n                    slow_result = slow_func(arr, axis=axis)\n                    assert False\n                except ValueError:\n                    return\n\n            slow_result = slow_func(arr, axis=axis)\n\n            hypothesis.note(f""axis: {axis}"")\n            assert_array_almost_equal(bn_result, slow_result)\n\n\n@pytest.mark.parametrize(\n    ""func"", (bn.nanmin, bn.nanmax, bn.anynan, bn.allnan), ids=lambda x: x.__name__\n)\n@hypothesis.given(array=hy_array_gen)\n@hypothesis.settings(max_examples=500)\ndef test_reduce_hypothesis(func, array):\n    _hypothesis_helper(func, array)\n\n\n@pytest.mark.parametrize(""func"", (bn.ss, bn.nansum), ids=lambda x: x.__name__)\n@hypothesis.given(array=hy_int_array_gen)\n@hypothesis.settings(max_examples=500)\ndef test_reduce_hypothesis_ints_only(func, array):\n    _hypothesis_helper(func, array)\n\n\n@pytest.mark.parametrize(""func"", (bn.nanargmin, bn.nanargmax), ids=lambda x: x.__name__)\n@hypothesis.given(array=hy_array_gen)\n@hypothesis.settings(max_examples=500)\ndef test_reduce_hypothesis_errata(func, array):\n    _hypothesis_helper(func, array, skip_all_nans=True)\n\n\n@pytest.mark.parametrize(""func"", bn.get_functions(""reduce""), ids=lambda x: x.__name__)\ndef test_reduce(func):\n    """"""test reduce functions""""""\n    return unit_maker(func)\n\n\ndef unit_maker(func, decimal=5, skip_dtype=(""nansum"", ""ss"")):\n    """"""Test that bn.xxx gives the same output as bn.slow.xxx.""""""\n    fmt = ""\\nfunc %s | input %s (%s) | shape %s | axis %s | order %s\\n""\n    fmt += ""\\nInput array:\\n%s\\n""\n    name = func.__name__\n    func0 = eval(""bn.slow.%s"" % name)\n    for i, a in enumerate(arrays(name)):\n        if a.ndim == 0:\n            axes = [None]  # numpy can\'t handle e.g. np.nanmean(9, axis=-1)\n        else:\n            axes = list(range(-1, a.ndim)) + [None]\n        for axis in axes:\n            actual = ""Crashed""\n            desired = ""Crashed""\n            actualraised = False\n            try:\n                # do not use a.copy() here because it will C order the array\n                actual = func(a, axis=axis)\n            except:  # noqa\n                actualraised = True\n            desiredraised = False\n            try:\n                with warnings.catch_warnings():\n                    warnings.simplefilter(""ignore"")\n                    desired = func0(a, axis=axis)\n            except:  # noqa\n                desiredraised = True\n            if actualraised and desiredraised:\n                pass\n            else:\n                tup = (\n                    name,\n                    ""a"" + str(i),\n                    str(a.dtype),\n                    str(a.shape),\n                    str(axis),\n                    array_order(a),\n                    a,\n                )\n                err_msg = fmt % tup\n                if actualraised != desiredraised:\n                    if actualraised:\n                        fmt2 = ""\\nbn.%s raised\\nbn.slow.%s ran\\n\\n%s""\n                    else:\n                        fmt2 = ""\\nbn.%s ran\\nbn.slow.%s raised\\n\\n%s""\n                    msg = fmt2 % (name, name, traceback.format_exc())\n                    err_msg += msg\n                    assert False, err_msg\n                assert_array_almost_equal(actual, desired, decimal, err_msg)\n                err_msg += ""\\n dtype mismatch %s %s""\n                if name not in skip_dtype:\n                    if hasattr(actual, ""dtype"") and hasattr(desired, ""dtype""):\n                        da = actual.dtype\n                        dd = desired.dtype\n                        assert_equal(da, dd, err_msg % (da, dd))\n\n\n# ---------------------------------------------------------------------------\n# Test argument parsing\n\n\n@pytest.mark.parametrize(""func"", bn.get_functions(""reduce""), ids=lambda x: x.__name__)\ndef test_arg_parsing(func):\n    """"""test argument parsing""""""\n    return unit_maker_argparse(func)\n\n\ndef unit_maker_argparse(func, decimal=5):\n    """"""test argument parsing.""""""\n\n    name = func.__name__\n    func0 = eval(""bn.slow.%s"" % name)\n\n    a = np.array([1.0, 2, 3])\n\n    fmt = ""\\n%s"" % func\n    fmt += ""%s\\n""\n    fmt += ""\\nInput array:\\n%s\\n"" % a\n\n    actual = func(a)\n    desired = func0(a)\n    err_msg = fmt % ""(a)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    actual = func(a, 0)\n    desired = func0(a, 0)\n    err_msg = fmt % ""(a, 0)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    actual = func(a, None)\n    desired = func0(a, None)\n    err_msg = fmt % ""(a, None)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    actual = func(a, axis=0)\n    desired = func0(a, axis=0)\n    err_msg = fmt % ""(a, axis=0)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    actual = func(a, axis=None)\n    desired = func0(a, axis=None)\n    err_msg = fmt % ""(a, axis=None)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    actual = func(a=a)\n    desired = func0(a=a)\n    err_msg = fmt % ""(a)""\n    assert_array_almost_equal(actual, desired, decimal, err_msg)\n\n    # regression test: make sure len(kwargs) == 0 doesn\'t raise\n    args = (a, 0)\n    kwargs = {}\n    func(*args, **kwargs)\n\n\n@pytest.mark.parametrize(""func"", bn.get_functions(""reduce""))\ndef test_arg_parse_raises(func):\n    """"""test argument parsing raises in reduce""""""\n    return unit_maker_argparse_raises(func)\n\n\ndef unit_maker_argparse_raises(func):\n    """"""test argument parsing raises in reduce""""""\n    a = np.array([1.0, 2, 3])\n    assert_raises(TypeError, func)\n    assert_raises(TypeError, func, axis=a)\n    assert_raises(TypeError, func, a, axis=0, extra=0)\n    assert_raises(TypeError, func, a, axis=0, a=a)\n    assert_raises(TypeError, func, a, 0, 0, 0, 0, 0)\n    assert_raises(TypeError, func, a, axis=""0"")\n    if func.__name__ not in (""nanstd"", ""nanvar""):\n        assert_raises(TypeError, func, a, ddof=0)\n    assert_raises(TypeError, func, a, a)\n    # assert_raises(TypeError, func, None) results vary\n\n\n# ---------------------------------------------------------------------------\n# Check that exceptions are raised\n\n\ndef test_nanmax_size_zero(dtypes=DTYPES):\n    """"""Test nanmax for size zero input arrays.""""""\n    shapes = [(0,), (2, 0), (1, 2, 0)]\n    for shape in shapes:\n        for dtype in dtypes:\n            a = np.zeros(shape, dtype=dtype)\n            assert_raises(ValueError, bn.nanmax, a)\n            assert_raises(ValueError, bn.slow.nanmax, a)\n\n\ndef test_nanmin_size_zero(dtypes=DTYPES):\n    """"""Test nanmin for size zero input arrays.""""""\n    shapes = [(0,), (2, 0), (1, 2, 0)]\n    for shape in shapes:\n        for dtype in dtypes:\n            a = np.zeros(shape, dtype=dtype)\n            assert_raises(ValueError, bn.nanmin, a)\n            assert_raises(ValueError, bn.slow.nanmin, a)\n\n\n# ---------------------------------------------------------------------------\n# nanstd and nanvar regression test (issue #60)\n\n\ndef test_nanstd_issue60():\n    """"""nanstd regression test (issue #60)""""""\n\n    f = bn.nanstd([1.0], ddof=1)\n    with np.errstate(invalid=""ignore""):\n        s = bn.slow.nanstd([1.0], ddof=1)\n    assert_equal(f, s, err_msg=""bn.nanstd([1.0], ddof=1) wrong"")\n\n    f = bn.nanstd([1], ddof=1)\n    with np.errstate(invalid=""ignore""):\n        s = bn.slow.nanstd([1], ddof=1)\n    assert_equal(f, s, err_msg=""bn.nanstd([1], ddof=1) wrong"")\n\n    f = bn.nanstd([1, np.nan], ddof=1)\n    with np.errstate(invalid=""ignore""):\n        s = bn.slow.nanstd([1, np.nan], ddof=1)\n    assert_equal(f, s, err_msg=""bn.nanstd([1, nan], ddof=1) wrong"")\n\n    f = bn.nanstd([[1, np.nan], [np.nan, 1]], axis=0, ddof=1)\n    with np.errstate(invalid=""ignore""):\n        s = bn.slow.nanstd([[1, np.nan], [np.nan, 1]], axis=0, ddof=1)\n    assert_equal(f, s, err_msg=""issue #60 regression"")\n\n\ndef test_nanvar_issue60():\n    """"""nanvar regression test (issue #60)""""""\n\n    f = bn.nanvar([1.0], ddof=1)\n    with np.errstate(invalid=""ignore""):\n        s = bn.slow.nanvar([1.0], ddof=1)\n    assert_equal(f, s, err_msg=""bn.nanvar([1.0], ddof=1) wrong"")\n\n    f = bn.nanvar([1], ddof=1)\n    with np.errstate(invalid=""ignore""):\n        s = bn.slow.nanvar([1], ddof=1)\n    assert_equal(f, s, err_msg=""bn.nanvar([1], ddof=1) wrong"")\n\n    f = bn.nanvar([1, np.nan], ddof=1)\n    with np.errstate(invalid=""ignore""):\n        s = bn.slow.nanvar([1, np.nan], ddof=1)\n    assert_equal(f, s, err_msg=""bn.nanvar([1, nan], ddof=1) wrong"")\n\n    f = bn.nanvar([[1, np.nan], [np.nan, 1]], axis=0, ddof=1)\n    with np.errstate(invalid=""ignore""):\n        s = bn.slow.nanvar([[1, np.nan], [np.nan, 1]], axis=0, ddof=1)\n    assert_equal(f, s, err_msg=""issue #60 regression"")\n\n\n@pytest.mark.parametrize(""dtype"", DTYPES)\n@pytest.mark.parametrize(""func"", (bn.nanstd, bn.nanvar), ids=lambda x: x.__name__)\ndef test_ddof_nans(func, dtype):\n    array = np.ones((1, 1), dtype=dtype)\n    for axis in [None, 0, 1, -1]:\n        result = func(array, axis=axis, ddof=3)\n        assert np.isnan(result)\n'"
bottleneck/tests/scalar_input_test.py,2,"b'""""""Check that functions can handle scalar input""""""\n\nfrom typing import Callable, Union\n\nimport hypothesis\nimport numpy as np\nimport pytest\nfrom hypothesis.strategies import floats, integers, one_of\nfrom numpy.testing import assert_array_almost_equal\n\nimport bottleneck as bn  # noqa: F401\nfrom .util import get_functions\n\nint64_iinfo = np.iinfo(np.int64)\n\n\nscalars = one_of(\n    [integers(min_value=int64_iinfo.min, max_value=int64_iinfo.max), floats()]\n)\n\n\n@hypothesis.given(scalar=scalars)\n@pytest.mark.parametrize(\n    ""func"",\n    get_functions(""reduce"") + get_functions(""nonreduce_axis""),\n    ids=lambda x: x.__name__,\n)\ndef test_scalar_input(\n    func: Callable[[np.array], Union[int, float, np.array]], scalar: Union[int, float]\n) -> None:\n    """"""Test that bn.xxx gives the same output as bn.slow.xxx for scalar input.""""""\n    if func.__name__ in (""partition"", ""argpartition"", ""push""):\n        return\n    func0 = eval(""bn.slow.%s"" % func.__name__)\n    msg = ""\\nfunc %s | input %s\\n""\n    actual_raised = False\n    desired_raised = False\n\n    try:\n        actual = func(scalar)\n    except ValueError:\n        actual_raised = True\n\n    try:\n        desired = func0(scalar)\n    except ValueError:\n        desired_raised = True\n\n    if desired_raised or actual_raised:\n        assert actual_raised and desired_raised\n    else:\n        err_msg = msg % (func.__name__, scalar)\n        assert_array_almost_equal(actual, desired, err_msg=err_msg)\n'"
bottleneck/tests/test_template.py,0,"b'import os\nimport posixpath as path\n\nfrom ..src.bn_template import make_c_files\n\n\ndef test_make_c_files():\n    dirpath = os.path.join(os.path.dirname(__file__), ""data/template_test/"")\n    modules = [""test""]\n    test_input = os.path.join(dirpath, ""test.c"")\n    if os.path.exists(test_input):\n        os.remove(test_input)\n\n    make_c_files(dirpath=dirpath, modules=modules)\n\n    with open(os.path.join(dirpath, ""truth.c"")) as f:\n        truth = f.read()\n\n    with open(os.path.join(dirpath, ""test.c"")) as f:\n        test = f.read()\n    test = test.replace(path.relpath(dirpath), ""{DIRPATH}"")\n\n    assert truth == test\n\n    os.remove(test_input)\n'"
bottleneck/tests/util.py,35,"b'from typing import Callable, List, Union\n\nimport numpy as np\nfrom hypothesis.extra.numpy import array_shapes\nfrom hypothesis.extra.numpy import arrays as hy_arrays\nfrom hypothesis.extra.numpy import floating_dtypes, integer_dtypes\nfrom hypothesis.strategies import one_of\n\nimport bottleneck as bn\n\nINT_DTYPES = [np.int64, np.int32]\nFLOAT_DTYPES = [np.float64, np.float32]\nDTYPES = tuple(FLOAT_DTYPES + INT_DTYPES)\n\n\nhy_array_gen = hy_arrays(\n    dtype=one_of(integer_dtypes(sizes=(32, 64)), floating_dtypes(sizes=(32, 64))),\n    shape=array_shapes(),\n)\n\nhy_int_array_gen = hy_arrays(\n    dtype=integer_dtypes(sizes=(32, 64)), shape=array_shapes(),\n)\n\n\ndef get_functions(\n    module_name: str, as_string: bool = False\n) -> List[Union[str, Callable[[np.array], Union[int, float, np.array]]]]:\n    """"""Returns a list of functions, optionally as string function names""""""\n    if module_name == ""all"":\n        funcs = []\n        funcs_in_dict = func_dict()\n        for key in funcs_in_dict:\n            for func in funcs_in_dict[key]:\n                funcs.append(func)\n    else:\n        funcs = func_dict()[module_name]\n    if as_string:\n        funcs = [f.__name__ for f in funcs]\n    return funcs\n\n\ndef func_dict():\n    d = {}\n    d[""reduce""] = [\n        bn.nansum,\n        bn.nanmean,\n        bn.nanstd,\n        bn.nanvar,\n        bn.nanmin,\n        bn.nanmax,\n        bn.median,\n        bn.nanmedian,\n        bn.ss,\n        bn.nanargmin,\n        bn.nanargmax,\n        bn.anynan,\n        bn.allnan,\n    ]\n    d[""move""] = [\n        bn.move_sum,\n        bn.move_mean,\n        bn.move_std,\n        bn.move_var,\n        bn.move_min,\n        bn.move_max,\n        bn.move_argmin,\n        bn.move_argmax,\n        bn.move_median,\n        bn.move_rank,\n    ]\n    d[""nonreduce""] = [bn.replace]\n    d[""nonreduce_axis""] = [\n        bn.partition,\n        bn.argpartition,\n        bn.rankdata,\n        bn.nanrankdata,\n        bn.push,\n    ]\n    return d\n\n\n# ---------------------------------------------------------------------------\n\n\ndef arrays(func_name, dtypes=DTYPES):\n    return array_iter(array_generator, func_name, dtypes)\n\n\ndef array_iter(arrays_func, *args):\n    for a in arrays_func(*args):\n        if a.ndim < 2:\n            yield a\n        #  this is good for an extra check but in everyday development it\n        #  is a pain because it doubles the unit test run time\n        #  elif a.ndim == 3:\n        #      for axes in permutations(range(a.ndim)):\n        #          yield np.transpose(a, axes)\n        else:\n            yield a\n            yield a.T\n\n\ndef array_generator(func_name, dtypes):\n    """"""Iterator that yields arrays to use for unit testing.""""""\n\n    f_dtypes = list(set(dtypes) & set(FLOAT_DTYPES))\n\n    # define nan and inf\n    if func_name in (""partition"", ""argpartition""):\n        nan = 0\n    else:\n        nan = np.nan\n    if func_name in (""move_sum"", ""move_mean"", ""move_std"", ""move_var""):\n        # these functions can\'t handle inf\n        inf = 8\n    else:\n        inf = np.inf\n\n    # nan and inf\n    for dtype in f_dtypes:\n        yield np.array([inf, nan], dtype=dtype)\n        yield np.array([inf, -inf], dtype=dtype)\n        yield np.array([nan, 2, 3], dtype=dtype)\n        yield np.array([-inf, 2, 3], dtype=dtype)\n        if func_name != ""nanargmin"":\n            yield np.array([nan, inf], dtype=dtype)\n\n    # byte swapped\n    yield np.array([1, 2, 3], dtype="">f4"")\n    yield np.array([1, 2, 3], dtype=""<f4"")\n\n    # make sure slow is callable\n    yield np.array([1, 2, 3], dtype=np.float16)\n\n    # regression tests\n    for dtype in dtypes:\n        yield np.array([1, 2, 3], dtype=dtype) + 1e9  # check that move_std is robust\n        yield np.array([0, 0, 0], dtype=dtype)  # nanargmax/nanargmin\n\n    for dtype in f_dtypes:\n        yield np.array([1, nan, nan, 2], dtype=dtype)  # nanmedian\n\n    yield np.array([2 ** 31], dtype=np.int64)  # overflows on windows\n\n    for dtype in dtypes:\n        yield np.array([[1, 2], [3, 4]], dtype=dtype)[..., np.newaxis]  # issue #183\n\n    # ties\n    for dtype in dtypes:\n        yield np.array([0, 0, 0], dtype=dtype)\n        yield np.array([1, 1, 1], dtype=dtype)\n\n    # 0d input\n    if not func_name.startswith(""move""):\n        for dtype in dtypes:\n            yield np.array(-9, dtype=dtype)\n            yield np.array(0, dtype=dtype)\n            yield np.array(9, dtype=dtype)\n            if dtype in f_dtypes:\n                yield np.array(-inf, dtype=dtype)\n                yield np.array(inf, dtype=dtype)\n                yield np.array(nan, dtype=dtype)\n\n    # automate a bunch of arrays to test\n    ss = {}\n    ss[0] = {""size"": 0, ""shapes"": [(0,), (0, 0), (2, 0), (2, 0, 1)]}\n    ss[1] = {""size"": 8, ""shapes"": [(8,)]}\n    ss[2] = {""size"": 12, ""shapes"": [(2, 6), (3, 4)]}\n    ss[3] = {""size"": 16, ""shapes"": [(2, 2, 4)]}\n    ss[4] = {""size"": 24, ""shapes"": [(1, 2, 3, 4)]}\n    for seed in (1, 2):\n        rs = np.random.RandomState(seed)\n        for ndim in ss:\n            size = ss[ndim][""size""]\n            shapes = ss[ndim][""shapes""]\n            for dtype in dtypes:\n                a = np.arange(size, dtype=dtype)\n                if issubclass(a.dtype.type, np.inexact):\n                    if func_name not in (""nanargmin"", ""nanargmax""):\n                        # numpy can\'t handle eg np.nanargmin([np.nan, np.inf])\n                        idx = rs.rand(*a.shape) < 0.2\n                        a[idx] = inf\n                    idx = rs.rand(*a.shape) < 0.2\n                    a[idx] = nan\n                    idx = rs.rand(*a.shape) < 0.2\n                    a[idx] *= -1\n                rs.shuffle(a)\n                for shape in shapes:\n                    yield a.reshape(shape)\n\n    # non-contiguous arrays\n    for dtype in dtypes:\n        yield np.array([[1, 2], [3, 4]], dtype=dtype)[:, [1]]  # gh 161\n\n    for dtype in dtypes:\n        # 1d\n        a = np.arange(12).astype(dtype)\n        for start in range(3):\n            for step in range(1, 3):\n                yield a[start::step]  # don\'t use astype here; copy created\n    for dtype in dtypes:\n        # 2d\n        a = np.arange(12).reshape(4, 3).astype(dtype)\n        yield a[::2]\n        yield a[:, ::2]\n        yield a[::2][:, ::2]\n    for dtype in dtypes:\n        # 3d\n        a = np.arange(24).reshape(2, 3, 4).astype(dtype)\n        for start in range(2):\n            for step in range(1, 2):\n                yield a[start::step]\n                yield a[:, start::step]\n                yield a[:, :, start::step]\n                yield a[start::step][::2]\n                yield a[start::step][::2][:, ::2]\n\n\ndef array_order(a):\n    f = a.flags\n    string = []\n    if f.c_contiguous:\n        string.append(""C"")\n    if f.f_contiguous:\n        string.append(""F"")\n    if len(string) == 0:\n        string.append(""N"")\n    return "","".join(string)\n'"
doc/source/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# la documentation build configuration file, created by\n# sphinx-quickstart on Thu Jan 14 16:31:34 2010.\n#\n# This file is execfile()d with the current directory set to its containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport os\nimport sys\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n# sys.path.append(os.path.abspath(\'.\'))\nsys.path.insert(0, os.path.abspath(""../sphinxext""))\nif ""READTHEDOCS"" not in os.environ or not os.environ[""READTHEDOCS""]:\n    sys.path.insert(0, os.path.join(os.path.dirname(__file__), ""../..""))\n\nimport bottleneck  # isort:skip\n\n# -- General configuration -----------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be extensions\n# coming with Sphinx (named \'sphinx.ext.*\') or your custom ones.\nextensions = [\n    ""sphinx.ext.autodoc"",\n    ""sphinx.ext.githubpages"",\n    ""sphinx.ext.extlinks"",\n    ""sphinx.ext.intersphinx"",\n    ""numpydoc"",\n    ""contributors"",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [""_templates""]\n\n# The suffix of source filenames.\nsource_suffix = "".rst""\n\n# The encoding of source files.\n# source_encoding = \'utf-8\'\n\n# The master toctree document.\nmaster_doc = ""index""\n\n# General information about the project.\nproject = u""Bottleneck""\ncopyright = u""2010-2019 Keith Goodman, 2019 Bottleneck Developers""\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = bottleneck.__version__\n# The full version, including alpha/beta/rc tags.\nrelease = bottleneck.__version__\n\n# JP: added from sphinxdocs\n# autosummary_generate = True\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n# language = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n# today = \'\'\n# Else, today_fmt is used as the format for a strftime call.\n# today_fmt = \'%B %d, %Y\'\n\n# List of documents that shouldn\'t be included in the build.\n# unused_docs = []\n\n# List of directories, relative to source directory, that shouldn\'t be searched\n# for source files.\nexclude_trees = []\n\n# The reST default role (used for this markup: `text`) to use for all documents.\n# default_role = None\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n# add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n# add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n# show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = ""sphinx""\n\n# A list of ignored prefixes for module index sorting.\n# modindex_common_prefix = []\n\n\n# -- Options for HTML output ---------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  Major themes that come with\n# Sphinx are currently \'default\' and \'sphinxdoc\'.\nhtml_theme = ""alabaster""\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n# html_theme_options = {\n#     ""headtextcolor"": ""#333333"",\n#     ""sidebarbgcolor"": ""#dddddd"",\n#     ""footerbgcolor"": ""#cccccc"",\n#     ""footertextcolor"": ""black"",\n#     ""headbgcolor"": ""#cccccc"",\n#     ""sidebartextcolor"": ""#333333"",\n#     ""sidebarlinkcolor"": ""default"",\n#     ""relbarbgcolor"": ""#cccccc"",\n#     ""relbartextcolor"": ""default"",\n#     ""relbarlinkcolor"": ""default"",\n#     ""codebgcolor"": ""#ffffff"",\n#     ""textcolor"": ""#333333"",\n#     ""bgcolor"": ""#f5f5f5"",\n# }\n\nhtml_theme_options = {\n    ""show_powered_by"": True,\n    ""github_user"": ""pydata"",\n    ""github_repo"": ""bottleneck"",\n    ""github_banner"": True,\n    ""show_related"": True,\n    ""travis_button"": True,\n    ""codecov_button"": True,\n}\n\n# Add any paths that contain custom themes here, relative to this directory.\n# html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# ""<project> v<release> documentation"".\n# html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n# html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\nhtml_logo = ""../image/icon.png""\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n# html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\n# html_static_path = [\'_static\']\n\n# If not \'\', a \'Last updated on:\' timestamp is inserted at every page bottom,\n# using the given strftime format.\n# html_last_updated_fmt = \'%b %d, %Y\'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n# html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n# html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n# html_additional_pages = {}\n\n# If false, no module index is generated.\n# html_use_modindex = True\n\n# If false, no index is generated.\n# html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n# html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n# html_show_sourcelink = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n# html_use_opensearch = \'\'\n\n# If nonempty, this is the file name suffix for HTML files (e.g. "".xhtml"").\n# html_file_suffix = \'\'\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = ""bottleneckdoc""\n\n\n# -- Options for LaTeX output --------------------------------------------------\n\n# The paper size (\'letter\' or \'a4\').\n# latex_paper_size = \'letter\'\n\n# The font size (\'10pt\', \'11pt\' or \'12pt\').\n# latex_font_size = \'10pt\'\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass [howto/manual]).\nlatex_documents = [\n    (\n        ""index"",\n        ""bottleneck.tex"",\n        u""bottleneck Documentation"",\n        u""Keith Goodman and Bottleneck Developers"",\n        ""manual"",\n    )\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n# latex_logo = None\n\n# For ""manual"" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n# latex_use_parts = False\n\n# Additional stuff for the LaTeX preamble.\n# latex_preamble = \'\'\n\n# Documents to append as an appendix to all manuals.\n# latex_appendices = []\n\n# If false, no module index is generated.\n# latex_use_modindex = True\n\nextlinks = {""issue"": (""https://github.com/pydata/bottleneck/issues/%s"", ""#"")}\nintersphinx_mapping = {\n    ""numpy"": (""https://docs.scipy.org/doc/numpy/"", None),\n    ""numpydoc"": (""https://numpydoc.readthedocs.io/en/latest/"", None),\n}\n'"
doc/sphinxext/announce.py,0,"b'#!/usr/bin/env python\n# -*- encoding:utf-8 -*-\n""""""\nThis file was copied from pandas.doc.sphinxext.announce\n\nScript to generate contributor and pull request lists\n\nThis script generates contributor and pull request lists for release\nannouncements using Github v3 protocol. Use requires an authentication token in\norder to have sufficient bandwidth, you can get one following the directions at\n`<https://help.github.com/articles/creating-an-access-token-for-command-line-use/>_\nDon\'t add any scope, as the default is read access to public information. The\ntoken may be stored in an environment variable as you only get one chance to\nsee it.\n\nUsage::\n\n    $ ./scripts/announce.py <token> <revision range>\n\nThe output is utf8 rst.\n\nDependencies\n------------\n\n- gitpython\n- pygithub\n\nSome code was copied from scipy `tools/gh_lists.py` and `tools/authors.py`.\n\nExamples\n--------\n\nFrom the bash command line with $GITHUB token.\n\n    $ ./scripts/announce.py $GITHUB v1.11.0..v1.11.1 > announce.rst\n\n""""""\nimport codecs\nimport os\nimport re\nimport textwrap\n\nfrom git import Repo\n\nUTF8Writer = codecs.getwriter(""utf8"")\nthis_repo = Repo(os.path.join(os.path.dirname(__file__), "".."", ""..""))\n\nauthor_msg = """"""\\\nA total of %d people contributed patches to this release.  People with a\n""+"" by their names contributed a patch for the first time.\n""""""\n\npull_request_msg = """"""\\\nA total of %d pull requests were merged for this release.\n""""""\n\n\ndef get_authors(revision_range):\n    pat = ""^.*\\\\t(.*)$""\n    lst_release, cur_release = [r.strip() for r in revision_range.split("".."")]\n\n    # authors, in current release and previous to current release.\n    cur = set(re.findall(pat, this_repo.git.shortlog(""-s"", revision_range), re.M))\n    pre = set(re.findall(pat, this_repo.git.shortlog(""-s"", lst_release), re.M))\n\n    # Homu is the author of auto merges, clean him out.\n    cur.discard(""Homu"")\n    pre.discard(""Homu"")\n\n    # Append \'+\' to new authors.\n    authors = [s + "" +"" for s in cur - pre] + [s for s in cur & pre]\n    authors.sort()\n    return authors\n\n\ndef get_pull_requests(repo, revision_range):\n    prnums = []\n\n    # From regular merges\n    merges = this_repo.git.log(""--oneline"", ""--merges"", revision_range)\n    issues = re.findall(""Merge pull request \\\\#(\\\\d*)"", merges)\n    prnums.extend(int(s) for s in issues)\n\n    # From Homu merges (Auto merges)\n    issues = re.findall(""Auto merge of \\\\#(\\\\d*)"", merges)\n    prnums.extend(int(s) for s in issues)\n\n    # From fast forward squash-merges\n    commits = this_repo.git.log(\n        ""--oneline"", ""--no-merges"", ""--first-parent"", revision_range\n    )\n    issues = re.findall(""^.*\\\\(\\\\#(\\\\d+)\\\\)$"", commits, re.M)\n    prnums.extend(int(s) for s in issues)\n\n    # get PR data from github repo\n    prnums.sort()\n    prs = [repo.get_pull(n) for n in prnums]\n    return prs\n\n\ndef build_components(revision_range, heading=""Contributors""):\n    lst_release, cur_release = [r.strip() for r in revision_range.split("".."")]\n    authors = get_authors(revision_range)\n\n    return {\n        ""heading"": heading,\n        ""author_message"": author_msg % len(authors),\n        ""authors"": authors,\n    }\n\n\ndef build_string(revision_range, heading=""Contributors""):\n    components = build_components(revision_range, heading=heading)\n    components[""uline""] = ""="" * len(components[""heading""])\n    components[""authors""] = ""* "" + ""\\n* "".join(components[""authors""])\n\n    tpl = textwrap.dedent(\n        """"""\\\n    {heading}\n    {uline}\n\n    {author_message}\n    {authors}""""""\n    ).format(**components)\n    return tpl\n\n\ndef main(revision_range):\n    # document authors\n    text = build_string(revision_range)\n    print(text)\n\n\nif __name__ == ""__main__"":\n    from argparse import ArgumentParser\n\n    parser = ArgumentParser(description=""Generate author lists for release"")\n    parser.add_argument(""revision_range"", help=""<revision>..<revision>"")\n    args = parser.parse_args()\n    main(args.revision_range)\n'"
doc/sphinxext/contributors.py,0,"b'""""""This file is copied from pandas.doc.sphinxext.contributors\n\nSphinx extension for listing code contributors to a release.\n\nUsage::\n\n   .. contributors:: v0.23.0..v0.23.1\n\nThis will be replaced with a message indicating the number of\ncode contributors and commits, and then list each contributor\nindividually.\n""""""\nimport git\nfrom docutils import nodes\nfrom docutils.parsers.rst import Directive\n\nfrom announce import build_components\n\n\nclass ContributorsDirective(Directive):\n    required_arguments = 1\n    name = ""contributors""\n\n    def run(self):\n        range_ = self.arguments[0]\n        if range_.endswith(""x..HEAD""):\n            return [nodes.paragraph(), nodes.bullet_list()]\n        try:\n            components = build_components(range_)\n        except git.GitCommandError as exc:\n            return [\n                self.state.document.reporter.warning(\n                    ""Cannot find contributors for range \'{}\': {}"".format(range_, exc),\n                    line=self.lineno,\n                )\n            ]\n        else:\n            message = nodes.paragraph()\n            message += nodes.Text(components[""author_message""])\n\n            listnode = nodes.bullet_list()\n\n            for author in components[""authors""]:\n                para = nodes.paragraph()\n                para += nodes.Text(author)\n                listnode += nodes.list_item("""", para)\n\n        return [message, listnode]\n\n\ndef setup(app):\n    app.add_directive(""contributors"", ContributorsDirective)\n\n    return {""version"": ""0.1"", ""parallel_read_safe"": True, ""parallel_write_safe"": True}\n'"
tools/appveyor/conda_setup.py,0,"b'# -*- coding: utf-8 -*-\n\n\nfrom __future__ import absolute_import\n\nimport logging\nfrom os import environ\n\nfrom conda_wrapper import CondaWrapper\n\nif __name__ == ""__main__"":\n    logging.basicConfig(level=logging.INFO)\n    with CondaWrapper(\n        environ[""PYTHON_VERSION""], environ[""CONDA_HOME""], environ[""CONDA_VENV""]\n    ) as conda:\n        conda.configure()\n        conda.update()\n        conda.create(*environ[""DEPS""].split("" ""))\n    logging.shutdown()\n'"
tools/appveyor/conda_wrapper.py,0,"b'# -*- coding: utf-8 -*-\n\nfrom __future__ import absolute_import\n\nimport logging\nimport sys\nfrom subprocess import check_output\n\nif sys.version_info[0] == 2:\n\n    def decode(string):\n        return string\n\n\nelse:\n\n    def decode(string):\n        return string.decode()\n\n\nclass CondaWrapper(object):\n    """"""Manage the AppVeyor Miniconda installation through Python.\n\n    AppVeyor has pre-installed Python 2.7.x as well as Miniconda (2 and 3).\n    Thus we only need to configure that properly and create the desired\n    environment.\n    """"""\n\n    def __init__(self, version, home, venv, **kw_args):\n        super(CondaWrapper, self).__init__(**kw_args)\n        self.logger = logging.getLogger(\n            ""{}.{}"".format(__name__, self.__class__.__name__)\n        )\n        self.version = version\n        self.home = home\n        self.venv = venv\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        return False  # False reraises the exception\n\n    def configure(self):\n        self.logger.info(""Configuring \'%s\'..."", self.home)\n        cmd = [\n            ""conda"",\n            ""config"",\n            ""--set"",\n            ""always_yes"",\n            ""yes"",\n            ""--set"",\n            ""changeps1"",\n            ""no"",\n        ]\n        msg = check_output(cmd, shell=True)\n        self.logger.debug(decode(msg))\n        self.logger.info(""Done."")\n\n    def update(self):\n        self.logger.info(""Updating \'%s\'..."", self.home)\n        cmd = [""conda"", ""update"", ""-q"", ""conda""]\n        msg = check_output(cmd, shell=True)\n        self.logger.debug(decode(msg))\n        self.logger.info(""Done."")\n\n    def create(self, *args):\n        self.logger.info(""Creating environment \'%s\'..."", self.venv)\n        cmd = [\n            ""conda"",\n            ""create"",\n            ""-q"",\n            ""-n"",\n            self.venv,\n            ""python="" + self.version,\n        ] + list(args)\n        msg = check_output(cmd, shell=True)\n        self.logger.debug(decode(msg))\n        cmd = [""activate"", self.venv]\n        msg = check_output(cmd, shell=True)\n        self.logger.debug(decode(msg))\n        # consider only for debugging\n        cmd = [""conda"", ""info"", ""-a""]\n        msg = check_output(cmd, shell=True)\n        self.logger.debug(decode(msg))\n        cmd = [""conda"", ""list""]\n        msg = check_output(cmd, shell=True)\n        self.logger.debug(decode(msg))\n        self.logger.info(""Done."")\n'"
