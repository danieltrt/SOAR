file_path,api_count,code
django/django.py,0,b'# *****************************************************************************\n# CODING STYLE > MAKING YOUR CODE READABLE\n# *****************************************************************************\n\n\n# 1. Avoid abbreviating variable names.\n# 2. Write out your function argument names.\n# 3. Document your classes and methods.\n# 4. Comment your code.\n# 5. Refactor repeated lines of code into reusable functions or methods.\n# 6. Keep functions and methods short. A good rule of thumb is that scrolling\n# should not be necessary to read an entire function or method.\n\n# TIP: Use Flake8 for Checking Code Quality.\n\n\n# *****************************************************************************\n# CODING STYLE > THE WORD ON IMPORTS\n# *****************************************************************************\n\n\n# Imports should be grouped in the following order:\n\n# 1. Standard library imports.\n# 2. Core Django imports.\n# 3. Third-party app imports.\n# 4. Imports from your apps.\n\n# Use explicit relative imports.\n# Avoid using import *\n\n\n# *****************************************************************************\n# CODING STYLE > OTHERS\n# *****************************************************************************\n\n\n# Use underscores in URL pattern names rather than dashes.\n\n\n# *****************************************************************************\n# DJANGO-ADMIN\n# *****************************************************************************\n\n\ndjango-admin startproject <ProjectName>  # create a new project directory structure\ndjango-admin startapp <Appname>          # create a new django application with the specified name\ndjango-admin migrate                     # synchronize the database state with your current state project models and migrations\ndjango-admin makemigrations              # create new migrations to the database based on the changes detected in the models\ndjango-admin runserver                   # start the development webserver at 127.0.0.1 with the port 8000\n'
machine learning/Algorithms/KNN/KNN.py,3,"b'\n# coding: utf-8\n\n# In[5]:\n\n\nimport numpy as np\nfrom collections import Counter\n\n\n# In[ ]:\n\n\ndef distance(instance1, instance2):\n    # just in case, if the instances are lists or tuples:\n    instance1 = np.array(instance1) \n    instance2 = np.array(instance2)\n    return np.linalg.norm(instance1 - instance2)\n\n\n# In[4]:\n\n\ndef get_neighbors(training_set,labels, test_instance, k,distance=distance):\n    distances = []\n    for index in range(len(training_set)):\n        dist = distance(test_instance, training_set[index])\n        distances.append((training_set[index], dist, labels[index]))\n    distances.sort(key=lambda x: x[1])\n    neighbors = distances[:k]\n    return neighbors\n\n\n# In[ ]:\n\n\ndef vote(neighbors):\n    class_counter = Counter()\n    for neighbor in neighbors:\n        class_counter[neighbor[2]] += 1\n    return class_counter.most_common(1)[0][0]\n\n'"
machine learning/Algorithms/Naive bayes/Naive_bayes.py,8,"b'\n# coding: utf-8\n\n# In[81]:\n\n\ndef createVocabList(dataSet):\n    vocabSet = set([])\n    for document in dataSet:\n        vocabSet = vocabSet | set(document)\n    return list(vocabSet)\n\n\n# In[82]:\n\n\ndef setOfWords2Vec(vocabList, inputSet):\n    returnVec = [0]*len(vocabList)\n    for word in inputSet:\n        if word in vocabList:\n            returnVec[vocabList.index(word)] += 1\n        else: \n            print (""the word: %s is not in my Vocabulary!"" % word)\n    return returnVec\n\n\n# In[83]:\n\n\nimport numpy as np\ndef train(trainMatrix,trainCategory):\n    numTrainDocs = len(trainMatrix)\n    numWords = len(trainMatrix[0])\n    pAbusive = sum(trainCategory)/float(numTrainDocs)\n    p0Num = np.ones(numWords); p1Num = np.ones(numWords)\n    p0Denom = 2.0; p1Denom = 2.0\n    for i in range(numTrainDocs):\n        if trainCategory[i] == 1:\n            p1Num += trainMatrix[i]\n            p1Denom += sum(trainMatrix[i])\n        else:\n            p0Num += trainMatrix[i]\n            p0Denom += sum(trainMatrix[i])\n    p1Vect = np.log(p1Num/p1Denom) #change to log()\n    p0Vect = np.log(p0Num/p0Denom) #change to log()\n    return p0Vect,p1Vect,pAbusive\n\n\n# In[88]:\n\n\ndef test(sentences,classes,testEntry1,testEntry2):\n    listOPosts,listClasses = sentences,classes\n    myVocabList = createVocabList(listOPosts)\n    trainMat=[]\n    for postinDoc in listOPosts:\n        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))\n    p0V,p1V,pAb = train(np.array(trainMat),np.array(listClasses))\n    thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry1))\n    print (testEntry1,\'classified as: \',classify(thisDoc,p0V,p1V,pAb))\n    thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry2))\n    print(testEntry2,""classified as:"",classify(thisDoc,p0V,p1V,pAb))\n\n\n# In[85]:\n\n\ndef classify(vec2Classify, p0Vec, p1Vec, pClass1):\n    p1 = sum(vec2Classify * p1Vec) + np.log(pClass1)\n    p0 = sum(vec2Classify * p0Vec) + np.log(1.0 - pClass1)\n    if p1 > p0:\n        return \'Positive\'\n    else:\n        return \'Negative\'\n\n'"
machine learning/Algorithms/svm/__init__.py,0,"b'from .svm import SVMTrainer, SVMPredictor\nfrom .kernel import Kernel\n'"
machine learning/Algorithms/svm/kernel.py,2,"b'import numpy as np\n\n\nclass Kernel(object):\n    """"""Check kernels here https://en.wikipedia.org/wiki/Support_vector_machine""""""\n    @staticmethod\n    def linear():\n        return lambda x, y: np.inner(x, y)\n\n    @staticmethod\n    def gaussian(sigma):\n        return lambda x,y: np.exp(-sigma * np.linalg.norm(x-y)**2)'"
machine learning/Algorithms/svm/svm.py,14,"b'import numpy as np\nimport cvxopt.solvers\nimport logging\n\n\nMIN_SUPPORT_VECTOR_MULTIPLIER = 1e-5\n\n\nclass SVMTrainer(object):\n    def __init__(self, kernel, c=0.1):\n        self._kernel = kernel\n        self._c = c\n\n\n    def train(self, X, y):\n        """"""\n            X: martix of features\n            y: vector of labels\n\n            next step: Compute lagrange multipliers by calling _compute_lagrange_multipliers method\n            retrun:    Return Predictor object by calling _create_predictor method\n        """"""\n        lagrange_multipliers = self._compute_lagrange_multipliers(X, y)\n        return self._create_predictor(X, y, lagrange_multipliers)\n\n\n    def _kernel_matrix(self, X):\n        """"""\n            X: martix of features\n\n            next step: Get number of samples\n            next step: Create zero matrix of quadratic shape of number of samples \n            next step: Calculate kernels\n            retrun:    Return Kernels matrix\n        """"""\n        n_samples = X.shape[0]\n\n        K = np.zeros((n_samples, n_samples))\n\n        print(X)\n\n        for i, x_i in enumerate(X):\n            for j, x_j in enumerate(X):\n                K[i, j] = self._kernel(x_i, x_j)\n\n        return K\n\n\n    def _create_predictor(self, X, y, lagrange_multipliers):\n        """"""\n            X: martix of features\n            y: vector of labels\n            lagrange_multipliers: vector of langrange multipliers\n\n            next step: Get non-zero lagrange multipliers indicies\n            next step: Get non-zero lagrange multipliers\n            next step: Get support vecorts\n            next step: Get support vecort labels\n            next step: \xd0\xa1ompute bias (use avg trick)\n            retrun   : Return SVMPredictor object\n        """"""\n\n        support_vector_indices = lagrange_multipliers > MIN_SUPPORT_VECTOR_MULTIPLIER\n\n        support_multipliers = lagrange_multipliers[support_vector_indices]\n\n        support_vectors = X[support_vector_indices]\n\n        support_vector_labels = y[support_vector_indices]\n\n        bias = np.mean(\n            [y_k - SVMPredictor(\n                    kernel=self._kernel,\n                    bias=0.0,\n                    weights=support_multipliers,\n                    support_vectors=support_vectors,\n                    support_vector_labels=support_vector_labels\n                ).predict(x_k) for (y_k, x_k) in zip(support_vector_labels, support_vectors)\n            ]\n        )\n\n        return SVMPredictor(\n            kernel=self._kernel,\n            bias=0.0,\n            weights=support_multipliers,\n            support_vectors=support_vectors,\n            support_vector_labels=support_vector_labels\n        )\n\n\n    def _compute_lagrange_multipliers(self, X, y):\n        """"""\n            X: martix of features\n            y: vector of labels\n\n\n            Need to Solve\n                min 1/2 x^T P x + q^T x (aplha is x)\n                s.t.\n                    Gx <= h (alpha >= 0)\n                    Ax = b (y^T * alpha = 0)\n\n\n            next step: Get number of samples\n            next step: Create Kernel matrix by calling _kernel_matrix method\n            next step: Create create quadratic term P based on Kernel matrix\n            next step: Create linear term q\n            next step: Create G, h, A, b\n            next step: Solve with - cvxopt.solvers.qp(P, q, G, h, A, b)\n            retrun:    Return flatten solution[\'x\']\n        """"""\n\n\n        n_samples = X.shape[0]\n\n        K = self._kernel_matrix(X)\n\n        P = cvxopt.matrix(np.outer(y, y) * K)\n\n        q = cvxopt.matrix(-1 * np.ones(n_samples))\n\n        G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n\n        h = cvxopt.matrix(np.zeros(n_samples))\n\n        A = cvxopt.matrix(y, (1, n_samples))\n\n        b = cvxopt.matrix(0.0)\n\n\n        # Check this\n\n        # -a_i \\leq 0\n        # G_std = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n        # h_std = cvxopt.matrix(np.zeros(n_samples))\n\n        # # a_i \\leq c\n        # G_slack = cvxopt.matrix(np.diag(np.ones(n_samples)))\n        # h_slack = cvxopt.matrix(np.ones(n_samples) * self._c)\n\n        # G = cvxopt.matrix(np.vstack((G_std, G_slack)))\n        # h = cvxopt.matrix(np.vstack((h_std, h_slack)))\n\n        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n\n        return np.ravel(solution[\'x\'])\n\n\nclass SVMPredictor(object):\n    def __init__(\n                self,\n                kernel,\n                bias,\n                weights,\n                support_vectors,\n                support_vector_labels\n            ):\n        \n        self._kernel = kernel\n        self._bias = bias\n        self._weights = weights\n        self._support_vectors = support_vectors\n        self._support_vector_labels = support_vector_labels\n\n\n        assert len(support_vectors) == len(support_vector_labels)\n        assert len(weights) == len(support_vector_labels)\n\n\n        logging.info(""Bias: %s"", self._bias)\n        logging.info(""Weights: %s"", self._weights)\n        logging.info(""Support vectors: %s"", self._support_vectors)\n        logging.info(""Support vector labels: %s"", self._support_vector_labels)\n\n    def predict(self, x):\n        """"""\n        Computes the SVM prediction on the given features x.\n        """"""\n        result = self._bias\n        for w_i, x_i, y_i in zip(self._weights,\n                                 self._support_vectors,\n                                 self._support_vector_labels):\n            result += w_i * y_i * self._kernel(x_i, x)\n\n        return np.sign(result).item()\n'"
