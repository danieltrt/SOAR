file_path,api_count,code
setup.py,0,"b""import os\n\nfrom setuptools import setup, find_packages\n\n\ndef read(name):\n    return open(os.path.join(os.path.dirname(__file__), name)).read()\n\n\nsetup(\n    name='baloo',\n    description='Implementing the bare necessities of Pandas with the lazy evaluating and optimizing Weld framework.',\n    long_description=read('README.md'),\n    long_description_content_type='text/markdown',\n    version='0.0.5',\n    license='BSD 3-Clause',\n    packages=find_packages(),\n    package_data={'baloo.weld.libs': ['libweld.so', 'numpy_weld_convertor.so', 'LICENSE'],\n    \t\t\t  'baloo.weld.pyweld': ['LICENSE'], \n    \t\t\t  'baloo.weld.convertors': ['LICENSE']},\n    include_package_data=True,\n    url='https://github.com/radujica/baloo',\n    author='Radu Jica',\n    author_email='radu.jica+code@gmail.com',\n    install_requires=['pandas', 'numpy', 'tabulate'],\n    platforms='linux',\n    python_requires='>=3.0'\n)\n"""
baloo/__init__.py,0,b'from .core import *\nfrom .functions import *\nfrom .io.parsers import *\n'
baloo/config.py,0,"b""import os\n\nimport tabulate\n\n# While not explicit, the code here gets executed on baloo import because of pyweld and convertors importing from here\ntabulate.PRESERVE_WHITESPACE = True\n\nROOT_DIR = os.path.dirname(os.path.abspath(__file__))\nLIBS_DIR = ROOT_DIR + '/weld/libs'\n# TODO: If adding support for Windows/MAC, should check here file extension (check history of bindings.py)\nWELD_PATH = os.path.join(LIBS_DIR, 'libweld.so')\nENCODERS_PATH = os.path.join(LIBS_DIR, 'numpy_weld_convertor.so')\n"""
benchmarks/__init__.py,0,b''
benchmarks/pipeline.py,5,"b'import timeit\nfrom collections import OrderedDict\n\nimport numpy as np\n\n\ndef generate_data(scale=1):\n    np.random.seed(42)\n    n = 1000\n\n    data = OrderedDict((\n        (\'col1\', np.random.randn(n * scale) * 17),\n        (\'col2\', np.random.randn(n * scale) * 29),\n        (\'col3\', np.random.randint(100, size=n*scale, dtype=np.int64)),\n        (\'col4\', np.random.randint(200, size=n*scale, dtype=np.int32))\n    ))\n\n    return data\n\n\ndef pandas_pipeline(data):\n    from pandas import DataFrame\n    from numpy import exp\n\n    df = DataFrame(data)\n\n    df = df[(df[\'col1\'] > 0) & (df[\'col2\'] >= 10) & (df[\'col3\'] < 30)]\n    df[\'col5\'] = (df[\'col1\'] + df[\'col2\']) * 0.1\n    df[\'col6\'] = df[\'col5\'].apply(exp)\n\n    df.groupby([\'col2\', \'col4\']).var()\n\n\ndef baloo_pipeline(data):\n    from baloo import DataFrame, exp\n\n    df = DataFrame(data)\n\n    df = df[(df[\'col1\'] > 0) & (df[\'col2\'] >= 10) & (df[\'col3\'] < 30)]\n    df[\'col5\'] = (df[\'col1\'] + df[\'col2\']) * 0.1\n    df[\'col6\'] = df[\'col5\'].apply(exp)\n\n    df.groupby([\'col2\', \'col4\']).var().evaluate()\n\n\ndata_setup = """"""\nfrom __main__ import generate_data\n\ndata = generate_data(scale=20000)""""""\n\npandas_setup = ""from __main__ import pandas_pipeline""\nbaloo_setup = ""from __main__ import baloo_pipeline""\n\n\n# TODO: this is not finished\nif __name__ == \'__main__\':\n    number = 2\n\n    pandas_time = timeit.timeit(""pandas_pipeline(data)"", setup=pandas_setup + data_setup, number=number)\n    print(""Pandas: {time}"".format(time=pandas_time / number))\n\n    baloo_time = timeit.timeit(""baloo_pipeline(data)"", setup=baloo_setup + data_setup, number=number)\n    print(""Baloo: {time}"".format(time=baloo_time / number))\n'"
benchmarks/run.py,3,"b'# Weld is expected to outperform Pandas on 1GB+ of data.\n# My VM does not have enough memory for numbers that large.\n# Main time hog in Weld is compilation.\nimport io\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom benchmarks.utils import run_benchmarks, benchmark, run_correctness_checks, profile_memory_usage\n\noperations = [\n    ""df = df[(df[\'col1\'] > 0) & (df[\'col2\'] >= 10) & (df[\'col3\'] < 30)]"",\n    ""df = df.agg([\'min\', \'prod\', \'mean\', \'std\'])"",\n    ""df[\'col4\'] = df[\'col1\'] * 2 + 1 - 23"",\n    ""df[\'col5\'] = df[\'col1\'].apply(np.exp)"",\n    ""df = df.groupby([\'col2\', \'col4\']).var()"",\n    ""df = df[[\'col3\', \'col1\']].join(df[[\'col3\', \'col2\']], on=\'col3\', rsuffix=\'_r\')""\n]\n\n\ndef plot_scalability(operation):\n    scales = [1, 10, 100, 1000, 10000, 20000, 40000]\n    sizes = [0.028, 0.28, 2.8, 28., 280., 560., 1120.]  # modify this if changing the generated data!\n    output_file = io.StringIO()\n    for scale in scales:\n        benchmark(operation, scale, 5, output_file)\n\n    output = output_file.getvalue()\n    df = pd.DataFrame(output.split(\'\\n\'), columns=[\'output\'])\n    df[\'op\'], df[\'time\'] = df[\'output\'].str.split(\':\', 1).str\n    df = df.drop(\'output\', axis=1).dropna()\n    df[\'time\'] = df[\'time\'].map(lambda x: x.split()[0]).astype(np.float64)\n    df = df.groupby(\'op\')\n    data = {group: data.reset_index().drop(\'index\', axis=1) for group, data in df}\n\n    fig, ax = plt.subplots()\n    scatter1 = ax.plot(data[\'pandas\'].index.values, data[\'pandas\'][\'time\'], color=\'r\')\n    scatter2 = ax.plot(data[\'baloo\'].index.values, data[\'baloo\'][\'time\'], color=\'g\')\n\n    ax.set_ylabel(\'Time (s)\')\n    ax.set_xlabel(\'Scale (MB)\')\n    ax.set_xticks(data[\'pandas\'].index.values)\n    ax.set_xticklabels(sizes)\n    ax.set_title(\'Average execution time of 3x operations\')\n    ax.legend((scatter1[0], scatter2[0]), (\'pandas\', \'baloo\'))\n\n    # plt.show()\n    plt.savefig(\'scalability.png\')\n\n\ndef plot_benchmarks(scale=1, runs=5):\n    output_file = io.StringIO()\n    run_benchmarks(operations, scale=scale, runs=runs, file=output_file)\n    output = output_file.getvalue()\n    df = pd.DataFrame(output.split(\'\\n\'), columns=[\'output\'])\n    df[\'op\'], df[\'time\'] = df[\'output\'].str.split(\':\', 1).str\n    df = df.drop(\'output\', axis=1).dropna()\n    df[\'time\'] = df[\'time\'].map(lambda x: x.split()[0]).astype(np.float64)\n    df = df.groupby(\'op\')       # groupby maintains the order of operations\n    data = {group: data.reset_index().drop(\'index\', axis=1) for group, data in df}\n\n    width = 0.35\n    fig, ax = plt.subplots()\n    rects1 = ax.bar(data[\'pandas\'].index, data[\'pandas\'][\'time\'], width, color=\'r\')\n    rects2 = ax.bar(data[\'baloo\'].index + width, data[\'baloo\'][\'time\'], width, color=\'g\')\n\n    ax.set_ylabel(\'Time (s)\')\n    ax.set_title(\'Average execution time for specific operations\')\n    ax.set_xticks(data[\'pandas\'].index + width / 2)\n    ax.set_xticklabels((\'filter\', \'4x agg\', \'3x op\', \'udf\', \'groupby\', \'join\'))\n\n    ax.legend((rects1[0], rects2[0]), (\'pandas\', \'baloo\'))\n\n    # plt.show()\n    plt.savefig(\'benchmarks-{}.png\'.format(str(scale)))\n\n\n# run_correctness_checks(operations, scale=20000)\n# plot_benchmarks(scale=20000)\n# plot_scalability(operations[2])\n# profile_memory_usage(operations[5], scale=20000)\n'"
benchmarks/utils.py,7,"b""import contextlib\nimport io\nimport sys\nimport time\nfrom collections import OrderedDict\nfrom functools import wraps\n\nimport numpy as np\nimport pandas as pd\nfrom memory_profiler import profile\n\nimport baloo as bl\n\n\ndef generate_data(scale=1):\n    np.random.seed(42)\n    n = 1000\n\n    print('Generating data...')\n\n    data = OrderedDict((\n        ('col1', np.random.randn(n * scale) * 17),\n        ('col2', np.random.randn(n * scale) * 29),\n        ('col3', np.random.randint(100, size=n*scale, dtype=np.int64)),\n        ('col4', np.random.randint(200, size=n*scale, dtype=np.int32))\n    ))\n    size = sum(arr.nbytes for arr in data.values())\n\n    print('Data size in MB: {}'.format(size / 1000000))\n\n    return data\n\n\n# decorator to time a function\ndef timer(runs=5, file=sys.stdout):\n    def function_timer(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            return_values = []\n            runtimes = []\n            for i in range(runs):\n                start = time.time()\n                return_value = func(*args, **kwargs)\n                end = time.time()\n                runtimes.append(float(end) - start)\n                return_values.append(return_value)\n\n            msg = '{func}: {time:.8f} seconds'\n            print(msg.format(func=func.__name__,\n                             time=sum(runtimes) / runs,\n                             runs=runs),\n                  file=file)\n\n            return return_values\n        return wrapper\n    return function_timer\n\n\n# summarizes the time spend in each Weld step\ndef _process_weld_output(weld_output):\n    df = pd.DataFrame(weld_output.split('\\n'), columns=['output'])\n    df['op'], df['time'] = df['output'].str.split(':', 1).str\n    df = df.drop('output', axis=1).dropna()\n    df['time'] = df['time'].astype(np.float64)\n    df = df.groupby('op').sum()\n\n    return df\n\n\n# evaluates with verbose=true to print time spent in each compilation step; further processed by process_weld_output\ndef _record_verbose_weld_output(df):\n    f = io.StringIO()\n    original = sys.stdout\n    sys.stdout = f\n    df = df.evaluate(verbose=True)\n    sys.stdout = original\n    verbose_output = f.getvalue()\n    f.close()\n\n    return df, verbose_output\n\n\n# averages the Weld compilation times output of multiple runs and prints it to stdout\ndef _average_weld_output(dfs):\n    weld_output = dfs[0]\n    for out in dfs[1:]:\n        weld_output = weld_output.append(out)\n    weld_output = weld_output.groupby('op').mean()\n\n    print(weld_output)\n\n\n# executes the operation on baloo while gathering verbose statistics\ndef verbose_baloo(operation, scale=1, runs=5):\n    assert runs > 0\n\n    print('Running verbose benchmark on: {}'.format(operation))\n    print('Averaging over {} runs'.format((str(runs))))\n    data = generate_data(scale=scale)\n\n    @timer()\n    def run():\n        df = bl.DataFrame(data)\n        exec(operation)\n        df = df.sum()\n\n        df, verbose_output = _record_verbose_weld_output(df)\n        with contextlib.redirect_stdout(None):\n            print(df.values)\n\n        return verbose_output\n\n    verbose_outputs = run()\n    _average_weld_output([_process_weld_output(out) for out in verbose_outputs])\n\n\n# only checks if series are equal, which makes sense given the sum aggregation\ndef check_correctness(operation, scale=1):\n    print('Checking correctness of: {}'.format(operation))\n    generated_data = generate_data(scale=scale)\n\n    def pandas(op, data):\n        df = pd.DataFrame(data)\n        exec(op)\n        df = df.sum()\n\n        return df.values\n\n    def baloo(op, data):\n        df = bl.DataFrame(data)\n        # temp workaround\n        op = op.replace('np', 'bl')\n        exec(op)\n        df = df.sum()\n\n        return df.evaluate().values\n\n    result_pandas = pandas(operation, generated_data)\n    result_baloo = baloo(operation, generated_data)\n\n    np.testing.assert_allclose(result_pandas, result_baloo)\n\n    print('All good!\\n')\n\n\ndef run_correctness_checks(operations, scale=1):\n    for operation in operations:\n        check_correctness(operation, scale)\n\n\n# runs the operation on both pandas and baloo while profiling memory usage\ndef profile_memory_usage(operation, scale=1):\n    print('Running memory profiling on: {}'.format(operation))\n    generated_data = generate_data(scale=scale)\n\n    @profile\n    def pandas(op, data):\n        df = pd.DataFrame(data)\n        exec(op)\n        df = df.sum()\n\n        with contextlib.redirect_stdout(None):\n            print(df.values)\n\n    @profile\n    def baloo(op, data):\n        df = bl.DataFrame(data)\n        # temp workaround\n        op = op.replace('np', 'bl')\n        exec(op)\n        df = df.sum()\n\n        with contextlib.redirect_stdout(None):\n            print(df.evaluate().values)\n\n    print('pandas:')\n    pandas(operation, generated_data)\n    print('baloo:')\n    baloo(operation, generated_data)\n\n\n# evaluation is forced by performing a sum aggregation;\n# pretty-print overhead (mostly) avoided by using .values;\n# note that data caching has little effect on these numbers (as manually tested);\n# data in memory anyway and CPU cache hard to manipulate\ndef benchmark(operation, scale=1, runs=5, file=sys.stdout):\n    assert runs > 0\n\n    print('Running benchmark on: {}'.format(operation))\n    print('Averaging over {} runs'.format((str(runs))))\n    generated_data = generate_data(scale=scale)\n\n    @timer(runs=runs, file=file)\n    def pandas(op, data):\n        df = pd.DataFrame(data)\n        exec(op)\n        df = df.sum()\n\n        with contextlib.redirect_stdout(None):\n            print(df.values)\n\n    @timer(runs=runs, file=file)\n    def baloo(op, data):\n        df = bl.DataFrame(data)\n        # temp workaround\n        op = op.replace('np', 'bl')\n        exec(op)\n        df = df.sum()\n\n        with contextlib.redirect_stdout(None):\n            print(df.evaluate().values)\n\n    pandas(operation, generated_data)\n    baloo(operation, generated_data)\n\n    print('Done')\n\n\ndef run_benchmarks(operations, scale=1, runs=5, file=sys.stdout):\n    for operation in operations:\n        benchmark(operation, scale, runs, file)\n"""
tests/__init__.py,0,b''
tests/conftest.py,18,"b""from collections import OrderedDict\n\nimport numpy as np\nimport pytest\n\nfrom baloo import Series, Index, DataFrame, MultiIndex, RangeIndex\nfrom baloo.weld import create_placeholder_weld_object\n\n\n# TODO: perhaps figure out autouse\n# TODO: add nulls to the data and make sure all ops still work\n# TODO: could maybe test with names also?\n@pytest.fixture(scope='module')\ndef data_f32():\n    return np.arange(1, 6, dtype=np.float32)\n\n\n@pytest.fixture(scope='module')\ndef data_i64():\n    return np.arange(1, 6, dtype=np.int64)\n\n\n@pytest.fixture(scope='module')\ndef data_i64_lazy(data_i64):\n    return create_placeholder_weld_object(data_i64)\n\n\n@pytest.fixture(scope='module')\ndef data_str():\n    return np.array(['a', 'Abc', 'goosfraba', '   dC  ', 'secrETariat'], dtype=np.bytes_)\n\n\n@pytest.fixture(scope='module')\ndef series_str(data_str, index_i64):\n    return Series(data_str, index_i64, np.bytes_)\n\n\n@pytest.fixture(scope='module')\ndef series_str_2(index_i64):\n    return Series([b'abz', b'zabz', b'zab', b'  ab  ', b'a'], index_i64, np.bytes_)\n\n\n@pytest.fixture(scope='module')\ndef index_i64():\n    return Index(np.arange(5), np.dtype(np.int64))\n\n\n@pytest.fixture(scope='module')\ndef range_index():\n    return RangeIndex(0, 5, 1)\n\n\n@pytest.fixture(scope='module')\ndef series_f32(data_f32, index_i64):\n    return Series(data_f32, index_i64, np.dtype(np.float32))\n\n\n@pytest.fixture(scope='module')\ndef series_i64(data_i64_lazy, index_i64):\n    return Series(data_i64_lazy, index_i64, np.dtype(np.int64))\n\n\n@pytest.fixture(scope='module')\ndef series_str(data_str, index_i64):\n    return Series(data_str, index_i64, data_str.dtype)\n\n\n@pytest.fixture(scope='module')\ndef op_array_other():\n    return Series(np.array([2] * 5).astype(np.float32))\n\n\n@pytest.fixture(scope='module')\ndef df_small(data_f32, series_i64, series_str, index_i64):\n    return DataFrame(OrderedDict((('a', data_f32), ('b', series_i64), ('c', series_str))), index_i64)\n\n\n@pytest.fixture(scope='module')\ndef df_small_columns():\n    return Index(np.array(['a', 'b', 'c'], dtype=np.bytes_))\n\n\n@pytest.fixture(scope='module')\ndef df_empty():\n    return DataFrame()\n\n\n@pytest.fixture(scope='module')\ndef index_i64_2():\n    return Index(np.arange(2, 7), np.dtype(np.int64))\n\n\n@pytest.fixture(scope='module')\ndef df1(data_f32, index_i64_2):\n    return DataFrame(OrderedDict((('a', Series(np.arange(5))), ('b', data_f32))), index_i64_2)\n\n\n@pytest.fixture(scope='module')\ndef df2():\n    return DataFrame(OrderedDict((('b', np.arange(3, 6, dtype=np.float32)), ('c', np.arange(4, 7)))),\n                     MultiIndex([np.array([1, 3, 5]),\n                                 Index(np.array(['abc', 'def', 'efgh'], dtype=np.bytes_))],\n                                ['a', 'd']))\n\n\n@pytest.fixture(scope='module')\ndef df_dupl(series_i64, index_i64):\n    return DataFrame(OrderedDict((('a', np.array([0, 1, 1, 2, 3], dtype=np.float32)),\n                                  ('b', [4, 5, 5, 6, 6]),\n                                  ('c', series_i64))),\n                     index_i64)\n\n\n@pytest.fixture(scope='module')\ndef df_dupl_exp_ind():\n    return Index(np.array([4, 5, 6]), np.dtype(np.int64), 'b')\n\n\n@pytest.fixture(scope='module')\ndef series_unsorted(index_i64):\n    return Series(np.array([5, 2, 3, 1, 4], dtype=np.float32), index_i64, np.dtype(np.float32))\n"""
baloo/core/__init__.py,0,"b""from .frame import DataFrame\nfrom .indexes import *\nfrom .series import Series\n\n# TODO: perhaps add 'release' mode to disable type checks -O ~ __debug__\n"""
baloo/core/frame.py,17,"b'from collections import OrderedDict\nfrom functools import reduce\n\nimport numpy as np\nfrom tabulate import tabulate\n\nfrom .generic import BinaryOps, BalooCommon\nfrom .indexes import Index, MultiIndex\nfrom .series import Series, _series_slice, _series_filter, _series_element_wise_op, _series_agg, _series_tail, \\\n    _series_iloc, _series_iloc_with_missing, _series_from_pandas\nfrom .utils import check_type, is_scalar, check_inner_types, infer_length, shorten_data, \\\n    check_weld_bit_array, check_valid_int_slice, as_list, default_index, same_index, check_str_or_list_str\nfrom ..weld import LazyArrayResult, weld_to_numpy_dtype, weld_combine_scalars, weld_count, \\\n    weld_cast_double, WeldDouble, weld_sort, LazyLongResult, weld_merge_join, weld_iloc_indices, \\\n    weld_merge_outer_join, weld_align, weld_drop_duplicates\n\n\nclass DataFrame(BinaryOps, BalooCommon):\n    """""" Weld-ed pandas DataFrame.\n\n    Attributes\n    ----------\n    index\n    dtypes\n    columns\n    iloc\n\n    See Also\n    --------\n    pandas.DataFrame : https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n\n    Examples\n    --------\n    >>> import baloo as bl\n    >>> import numpy as np\n    >>> from collections import OrderedDict\n    >>> df = bl.DataFrame(OrderedDict(((\'a\', np.arange(5, 8)), (\'b\', [1, 0, 2]))))\n    >>> df.index  # repr\n    RangeIndex(start=0, stop=3, step=1)\n    >>> df  # repr\n    DataFrame(index=RangeIndex(start=0, stop=3, step=1), columns=[a: int64, b: int64])\n    >>> print(df.evaluate())  # omitting evaluate would trigger exception as index is now an unevaluated RangeIndex\n           a    b\n    ---  ---  ---\n      0    5    1\n      1    6    0\n      2    7    2\n    >>> print(len(df))\n    3\n    >>> print((df * 2).evaluate())\n           a    b\n    ---  ---  ---\n      0   10    2\n      1   12    0\n      2   14    4\n    >>> print((df * [2, 3]).evaluate())\n           a    b\n    ---  ---  ---\n      0   10    3\n      1   12    0\n      2   14    6\n    >>> print(df.min().evaluate())\n    <BLANKLINE>\n    ---  --\n    a     5\n    b     0\n    >>> print(df.mean().evaluate())\n    <BLANKLINE>\n    ---  --\n    a     6\n    b     1\n    >>> print(df.agg([\'var\', \'count\']).evaluate())\n             a    b\n    -----  ---  ---\n    var      1    1\n    count    3    3\n    >>> df.rename({\'a\': \'c\'})\n    DataFrame(index=RangeIndex(start=0, stop=3, step=1), columns=[c: int64, b: int64])\n    >>> df.drop(\'a\')\n    DataFrame(index=RangeIndex(start=0, stop=3, step=1), columns=[b: int64])\n    >>> print(df.reset_index().evaluate())\n           index    a    b\n    ---  -------  ---  ---\n      0        0    5    1\n      1        1    6    0\n      2        2    7    2\n    >>> print(df.set_index(\'b\').evaluate())\n      b    a\n    ---  ---\n      1    5\n      0    6\n      2    7\n    >>> print(df.sort_values(\'b\').evaluate())\n           a    b\n    ---  ---  ---\n      1    6    0\n      0    5    1\n      2    7    2\n    >>> df2 = bl.DataFrame({\'b\': np.array([0, 2])})\n    >>> print(df.merge(df2, on=\'b\').evaluate())\n      b    index_x    a    index_y\n    ---  ---------  ---  ---------\n      0          1    6          0\n      2          2    7          1\n    >>> df3 = bl.DataFrame({\'a\': [1., -999., 3.]}, bl.Index([-999, 1, 2]))\n    >>> print(df3.dropna().evaluate())\n            a\n    ----  ---\n    -999    1\n       2    3\n    >>> print(df3.fillna({\'a\': 15}).evaluate())\n            a\n    ----  ---\n    -999    1\n       1   15\n       2    3\n    >>> print(bl.DataFrame({\'a\': [0, 1, 1, 2], \'b\': [1, 2, 3, 4]}).groupby(\'a\').sum().evaluate())\n      a    b\n    ---  ---\n      0    1\n      2    4\n      1    5\n\n    """"""\n    _empty_text = \'Empty DataFrame\'\n\n    def __init__(self, data=None, index=None):\n        """"""Initialize a DataFrame object.\n\n        Note that (unlike pandas) there\'s currently no index inference or alignment between the indexes of any Series\n        passed as data. That is, all data, be it raw or Series, inherits the index of the DataFrame. Alignment\n        is currently restricted to setitem\n\n        Parameters\n        ----------\n        data : dict, optional\n            Data as a dict of str -> np.ndarray or Series or list.\n        index : Index or RangeIndex or MultiIndex, optional\n            Index linked to the data; it is assumed to be of the same length.\n            RangeIndex by default.\n\n        """"""\n        data = _check_input_data(data)\n        self._length = _infer_length(index, data)\n        self.index = _process_index(index, data, self._length)\n        self._data = _process_data(data, self.index)\n\n    @property\n    def values(self):\n        """"""Alias for `data` attribute.\n\n        Returns\n        -------\n        dict\n            The internal dict data representation.\n\n        """"""\n        return self._data\n\n    @property\n    def empty(self):\n        return self.index.empty and (len(self._data) == 0 or all(series.empty for series in self._iter()))\n\n    def _gather_dtypes(self):\n        return OrderedDict(((k, v.dtype) for k, v in self._data.items()))\n\n    @property\n    def dtypes(self):\n        """"""Series of NumPy dtypes present in the DataFrame with index of column names.\n\n        Returns\n        -------\n        Series\n\n        """"""\n        return Series(np.array(list(self._gather_dtypes().values()), dtype=np.bytes_),\n                      self.keys())\n\n    def _gather_column_names(self):\n        return list(self._data.keys())\n\n    @property\n    def columns(self):\n        """"""Index of the column names present in the DataFrame in order.\n\n        Returns\n        -------\n        Index\n\n        """"""\n        return Index(np.array(self._gather_column_names(), dtype=np.bytes_), np.dtype(np.bytes_))\n\n    def _gather_data_for_weld(self):\n        return [column.weld_expr for column in self._data.values()]\n\n    def _gather_weld_types(self):\n        return [column.weld_type for column in self._data.values()]\n\n    def __len__(self):\n        """"""Eagerly get the length of the DataFrame.\n\n        Note that if the length is unknown (such as for WeldObjects),\n        it will be eagerly computed.\n\n        Returns\n        -------\n        int\n            Length of the DataFrame.\n\n        """"""\n        self._length = LazyLongResult(_obtain_length(self._length, self._data)).evaluate()\n\n        return self._length\n\n    @property\n    def iloc(self):\n        """"""Retrieve Indexer by index.\n\n        Supported iloc functionality exemplified below.\n\n        Examples\n        --------\n        >>> df = bl.DataFrame(OrderedDict(((\'a\', np.arange(5, 8)), (\'b\', np.array([1, 0, 2])))))\n        >>> print(df.iloc[0:2].evaluate())\n               a    b\n        ---  ---  ---\n          0    5    1\n          1    6    0\n        >>> print(df.iloc[bl.Series(np.array([0, 2]))].evaluate())\n               a    b\n        ---  ---  ---\n          0    5    1\n          2    7    2\n\n        """"""\n        from .indexing import _ILocIndexer\n\n        return _ILocIndexer(self)\n\n    def __repr__(self):\n        columns = \'[\' + \', \'.join([\'{}: {}\'.format(k, v) for k, v in self._gather_dtypes().items()]) + \']\'\n\n        return ""{}(index={}, columns={})"".format(self.__class__.__name__,\n                                                 repr(self.index),\n                                                 columns)\n\n    # TODO: extend tabulate to e.g. insert a line between index and values\n    def __str__(self):\n        if self.empty:\n            return self._empty_text\n\n        default_index_name = \' \'\n        str_data = OrderedDict()\n        str_data.update((name, shorten_data(data.values))\n                        for name, data in self.index._gather_data(default_index_name).items())\n        str_data.update((column.name, shorten_data(column.values)) for column in self._iter())\n\n        return tabulate(str_data, headers=\'keys\')\n\n    def _comparison(self, other, comparison):\n        if other is None or is_scalar(other):\n            df = _drop_str_columns(self)\n            new_data = OrderedDict((column.name, column._comparison(other, comparison))\n                                   for column in df._iter())\n\n            return DataFrame(new_data, self.index)\n        else:\n            raise TypeError(\'Can currently only compare with scalars\')\n\n    def _element_wise_operation(self, other, operation):\n        if isinstance(other, list):\n            check_inner_types(other, (int, float))\n\n            df = _drop_str_columns(self)\n            if len(other) != len(df._gather_column_names()):\n                raise ValueError(\'Expected same number of values in other as the number of non-string columns\')\n\n            new_data = OrderedDict((column.name, _series_element_wise_op(column, scalar, operation))\n                                   for column, scalar in zip(df._iter(), other))\n\n            return DataFrame(new_data, self.index)\n        elif is_scalar(other):\n            df = _drop_str_columns(self)\n            new_data = OrderedDict((column.name, _series_element_wise_op(column, other, operation))\n                                   for column in df._iter())\n\n            return DataFrame(new_data, self.index)\n        else:\n            raise TypeError(\'Can only apply operation with scalar or LazyArrayResult\')\n\n    def astype(self, dtype):\n        """"""Cast DataFrame columns to given dtype.\n\n        Parameters\n        ----------\n        dtype : numpy.dtype or dict\n            Dtype or column_name -> dtype mapping to cast columns to. Note index is excluded.\n\n        Returns\n        -------\n        DataFrame\n            With casted columns.\n\n        """"""\n        if isinstance(dtype, np.dtype):\n            new_data = OrderedDict((column.name, column.astype(dtype))\n                                   for column in self._iter())\n\n            return DataFrame(new_data, self.index)\n        elif isinstance(dtype, dict):\n            check_inner_types(dtype.values(), np.dtype)\n\n            new_data = OrderedDict(self._data)\n            for column in self._iter():\n                column_name = column.name\n                if column_name in dtype:\n                    new_data[column_name] = column.astype(dtype[column_name])\n\n            return DataFrame(new_data, self.index)\n        else:\n            raise TypeError(\'Expected numpy.dtype or dict mapping column names to dtypes\')\n\n    def __getitem__(self, item):\n        """"""Select from the DataFrame.\n\n        Supported functionality exemplified below.\n\n        Examples\n        --------\n        >>> df = bl.DataFrame(OrderedDict({\'a\': np.arange(5, 8)}))\n        >>> print(df[\'a\'].evaluate())\n               a\n        ---  ---\n          0    5\n          1    6\n          2    7\n        >>> print(df[[\'a\']].evaluate())\n               a\n        ---  ---\n          0    5\n          1    6\n          2    7\n        >>> print(df[df[\'a\'] < 7].evaluate())\n               a\n        ---  ---\n          0    5\n          1    6\n\n        """"""\n        if isinstance(item, str):\n            return self._data[item]\n        elif isinstance(item, list):\n            check_inner_types(item, str)\n            new_data = OrderedDict()\n\n            for column_name in item:\n                if column_name not in self:\n                    raise KeyError(\'Column name not in DataFrame: {}\'.format(str(column_name)))\n\n                new_data[column_name] = self._data[column_name]\n\n            return DataFrame(new_data, self.index)\n        elif isinstance(item, LazyArrayResult):\n            check_weld_bit_array(item)\n\n            new_index = self.index[item]\n            new_data = OrderedDict((column.name, _series_filter(column, item, new_index))\n                                   for column in self._iter())\n\n            return DataFrame(new_data, new_index)\n        elif isinstance(item, slice):\n            check_valid_int_slice(item)\n\n            new_index = self.index[item]\n            new_data = OrderedDict((column.name, _series_slice(column, item, new_index))\n                                   for column in self._iter())\n\n            return DataFrame(new_data, new_index)\n        else:\n            raise TypeError(\'Expected a column name, list of columns, LazyArrayResult, or a slice\')\n\n    def __setitem__(self, key, value):\n        """"""Add/update DataFrame column.\n\n        Note that for raw data, it does NOT check for the same length with the DataFrame due to possibly not knowing\n        the length before evaluation. Hence, columns of different lengths are possible if using raw data which might\n        lead to unexpected behavior. To avoid this, use the more expensive setitem by wrapping with a Series.\n        This, in turn, means that if knowing the indexes match and the data has the same length as the DataFrame,\n        it is more efficient to setitem using the raw data.\n\n        Parameters\n        ----------\n        key : str\n            Column name.\n        value : numpy.ndarray or Series\n            If a Series, the data will be aligned based on the index of the DataFrame,\n            i.e. df.index left join sr.index.\n\n        Examples\n        --------\n        >>> df = bl.DataFrame(OrderedDict({\'a\': np.arange(5, 8)}))\n        >>> df[\'b\'] = np.arange(3)\n        >>> print(df.evaluate())\n               a    b\n        ---  ---  ---\n          0    5    0\n          1    6    1\n          2    7    2\n\n        """"""\n        key = check_type(key, str)\n        value = check_type(value, (np.ndarray, Series))\n\n        if isinstance(value, Series):\n            if not same_index(self.index, value.index):\n                value = Series(weld_align(self.index._gather_data_for_weld(),\n                                          self.index._gather_weld_types(),\n                                          value.index._gather_data_for_weld(),\n                                          value.index._gather_weld_types(),\n                                          value.values,\n                                          value.weld_type),\n                               self.index,\n                               value.dtype,\n                               key)\n                # else keep as is\n        else:\n            value = Series(value, self.index, value.dtype, key)\n\n        self._data[key] = value\n\n    def _iter(self):\n        for column in self._data.values():\n            yield column\n\n    def __iter__(self):\n        for column_name in self._data:\n            yield column_name\n\n    def __contains__(self, item):\n        return item in self._data\n\n    def evaluate(self, verbose=False, decode=True, passes=None, num_threads=1, apply_experimental=True):\n        """"""Evaluates by creating a DataFrame containing evaluated data and index.\n\n        See `LazyResult`\n\n        Returns\n        -------\n        DataFrame\n            DataFrame with evaluated data and index.\n\n        """"""\n        evaluated_index = self.index.evaluate(verbose, decode, passes, num_threads, apply_experimental)\n        evaluated_data = OrderedDict((column.name, column.evaluate(verbose, decode, passes,\n                                                                   num_threads, apply_experimental))\n                                     for column in self._iter())\n\n        return DataFrame(evaluated_data, evaluated_index)\n\n    def head(self, n=5):\n        """"""Return DataFrame with first n values per column.\n\n        Parameters\n        ----------\n        n : int\n            Number of values.\n\n        Returns\n        -------\n        DataFrame\n            DataFrame containing the first n values per column.\n\n        Examples\n        --------\n        >>> df = bl.DataFrame(OrderedDict(((\'a\', np.arange(5, 8)), (\'b\', np.arange(3)))))\n        >>> print(df.head(2).evaluate())\n               a    b\n        ---  ---  ---\n          0    5    0\n          1    6    1\n\n        """"""\n        return self[:n]\n\n    def tail(self, n=5):\n        """"""Return DataFrame with last n values per column.\n\n        Parameters\n        ----------\n        n : int\n            Number of values.\n\n        Returns\n        -------\n        DataFrame\n            DataFrame containing the last n values per column.\n\n        Examples\n        --------\n        >>> df = bl.DataFrame(OrderedDict(((\'a\', np.arange(5, 8)), (\'b\', np.arange(3)))))\n        >>> print(df.tail(2).evaluate())\n               a    b\n        ---  ---  ---\n          1    6    1\n          2    7    2\n\n        """"""\n        length = _obtain_length(self._length, self._data)\n\n        new_index = self.index.tail(n)\n        new_data = OrderedDict((column.name, _series_tail(column, new_index, length, n))\n                               for column in self._iter())\n\n        return DataFrame(new_data, new_index)\n\n    def keys(self):\n        """"""Retrieve column names as Index, i.e. for axis=1.\n\n        Returns\n        -------\n        Index\n             Column names as an Index.\n\n        """"""\n        return self.columns\n\n    def rename(self, columns):\n        """"""Returns a new DataFrame with renamed columns.\n\n        Currently a simplified version of Pandas\' rename.\n\n        Parameters\n        ----------\n        columns : dict\n            Old names to new names.\n\n        Returns\n        -------\n        DataFrame\n            With columns renamed, if found.\n\n        """"""\n        new_data = OrderedDict()\n        for column_name in self:\n            if column_name in columns.keys():\n                column = self._data[column_name]\n                new_name = columns[column_name]\n                new_data[new_name] = Series(column.values, column.index, column.dtype, new_name)\n            else:\n                new_data[column_name] = self._data[column_name]\n\n        return DataFrame(new_data, self.index)\n\n    def drop(self, columns):\n        """"""Drop 1 or more columns. Any column which does not exist in the DataFrame is skipped, i.e. not removed,\n        without raising an exception.\n\n        Unlike Pandas\' drop, this is currently restricted to dropping columns.\n\n        Parameters\n        ----------\n        columns : str or list of str\n            Column name or list of column names to drop.\n\n        Returns\n        -------\n        DataFrame\n            A new DataFrame without these columns.\n\n        """"""\n        if isinstance(columns, str):\n            new_data = OrderedDict()\n            if columns not in self._gather_column_names():\n                raise KeyError(\'Key {} not found\'.format(columns))\n\n            for column_name in self:\n                if column_name != columns:\n                    new_data[column_name] = self._data[column_name]\n\n            return DataFrame(new_data, self.index)\n        elif isinstance(columns, list):\n            check_inner_types(columns, str)\n\n            df = self\n            for column in columns:\n                df = df.drop(column)\n\n            return df\n        else:\n            raise TypeError(\'Expected columns as a str or a list of str\')\n\n    # TODO: currently if the data has multiple types, the results are casted to f64; perhaps be more flexible about it\n    # TODO: cast data to relevant 64-bit format pre-aggregation? ~ i16, i32 -> i64, f32 -> f64\n    def _aggregate_columns(self, func_name):\n        df = _drop_str_columns(self)\n        if len(df._data) == 0:\n            return Series()\n\n        new_index = df.keys()\n\n        agg_lazy_results = [getattr(column, func_name)() for column in df._iter()]\n\n        # if there are multiple types, cast to float64\n        if len(set(df._gather_dtypes().values())) > 1:\n            weld_type = WeldDouble()\n            dtype = weld_to_numpy_dtype(weld_type)\n            agg_lazy_results = (weld_cast_double(result.weld_expr) for result in agg_lazy_results)\n        else:\n            weld_type = agg_lazy_results[0].weld_type\n            dtype = weld_to_numpy_dtype(weld_type)\n            agg_lazy_results = (agg.weld_expr for agg in agg_lazy_results)\n\n        new_data = weld_combine_scalars(agg_lazy_results, weld_type)\n\n        return Series(new_data, new_index, dtype)\n\n    def min(self):\n        return self._aggregate_columns(\'min\')\n\n    def max(self):\n        return self._aggregate_columns(\'max\')\n\n    def sum(self):\n        return self._aggregate_columns(\'sum\')\n\n    def prod(self):\n        return self._aggregate_columns(\'prod\')\n\n    def count(self):\n        return self._aggregate_columns(\'count\')\n\n    def mean(self):\n        return self._aggregate_columns(\'mean\')\n\n    def var(self):\n        return self._aggregate_columns(\'var\')\n\n    def std(self):\n        return self._aggregate_columns(\'std\')\n\n    def agg(self, aggregations):\n        """"""Multiple aggregations optimized.\n\n        Parameters\n        ----------\n        aggregations : list of str\n            Which aggregations to perform.\n\n        Returns\n        -------\n        DataFrame\n            DataFrame with the aggregations per column.\n\n        """"""\n        check_type(aggregations, list)\n\n        df = _drop_str_columns(self)\n        if len(df._data) == 0:\n            # conforming to what pandas does\n            raise ValueError(\'No results\')\n\n        new_index = Index(np.array(aggregations, dtype=np.bytes_), np.dtype(np.bytes_))\n        new_data = OrderedDict((column.name, _series_agg(column, aggregations, new_index))\n                               for column in df._iter())\n\n        return DataFrame(new_data, new_index)\n\n    def reset_index(self):\n        """"""Returns a new DataFrame with previous index as column(s).\n\n        Returns\n        -------\n        DataFrame\n            DataFrame with the new index a RangeIndex of its length.\n\n        """"""\n        new_columns = OrderedDict()\n\n        new_index = default_index(_obtain_length(self._length, self._data))\n\n        new_columns.update((name, Series(data.values, new_index, data.dtype, name))\n                           for name, data in self.index._gather_data().items())\n\n        # the data/columns\n        new_columns.update((sr.name, Series(sr.values, new_index, sr.dtype, sr.name))\n                           for sr in self._iter())\n\n        return DataFrame(new_columns, new_index)\n\n    def set_index(self, keys):\n        """"""Set the index of the DataFrame to be the keys columns.\n\n        Note this means that the old index is removed.\n\n        Parameters\n        ----------\n        keys : str or list of str\n            Which column(s) to set as the index.\n\n        Returns\n        -------\n        DataFrame\n            DataFrame with the index set to the column(s) corresponding to the keys.\n\n        """"""\n        if isinstance(keys, str):\n            column = self._data[keys]\n            new_index = Index(column.values, column.dtype, column.name)\n\n            new_data = OrderedDict((sr.name, Series(sr.values, new_index, sr.dtype, sr.name))\n                                   for sr in self._iter())\n            del new_data[keys]\n\n            return DataFrame(new_data, new_index)\n        elif isinstance(keys, list):\n            check_inner_types(keys, str)\n\n            new_index_data = []\n            for column_name in keys:\n                column = self._data[column_name]\n                new_index_data.append(Index(column.values, column.dtype, column.name))\n            new_index = MultiIndex(new_index_data, keys)\n\n            new_data = OrderedDict((sr.name, Series(sr.values, new_index, sr.dtype, sr.name))\n                                   for sr in self._iter())\n            for column_name in keys:\n                del new_data[column_name]\n\n            return DataFrame(new_data, new_index)\n        else:\n            raise TypeError(\'Expected a string or a list of strings\')\n\n    def sort_index(self, ascending=True):\n        """"""Sort the index of the DataFrame.\n\n        Currently MultiIndex is not supported since Weld is missing multiple-column sort.\n\n        Note this is an expensive operation (brings all data to Weld).\n\n        Parameters\n        ----------\n        ascending : bool, optional\n\n        Returns\n        -------\n        DataFrame\n            DataFrame sorted according to the index.\n\n        """"""\n        if isinstance(self.index, MultiIndex):\n            raise NotImplementedError(\'Weld does not yet support sorting on multiple columns\')\n\n        return self.sort_values(self.index._gather_names(), ascending)\n\n    def sort_values(self, by, ascending=True):\n        """"""Sort the DataFrame based on a column.\n\n        Unlike Pandas, one can sort by data from both index and regular columns.\n\n        Currently possible to sort only on a single column since Weld is missing multiple-column sort.\n        Note this is an expensive operation (brings all data to Weld).\n\n        Parameters\n        ----------\n        by : str or list of str\n            Column names to sort.\n        ascending : bool, optional\n\n        Returns\n        -------\n        DataFrame\n            DataFrame sorted according to the column.\n\n        """"""\n        check_type(ascending, bool)\n        check_str_or_list_str(by)\n        by = as_list(by)\n\n        if len(by) > 1:\n            raise NotImplementedError(\'Weld does not yet support sorting on multiple columns\')\n\n        all_data = self.reset_index()\n        by_data = all_data[by]\n\n        sorted_indices = weld_sort(by_data._gather_data_for_weld(),\n                                   by_data._gather_weld_types(),\n                                   \'sort_index\',\n                                   ascending=ascending)\n\n        new_index = self.index._iloc_indices(sorted_indices)\n        new_columns = list(self._iter())\n        new_column_names = [column.name for column in new_columns]\n        new_columns = [_series_iloc(column, sorted_indices, new_index) for column in new_columns]\n        new_data = OrderedDict(zip(new_column_names, new_columns))\n\n        return DataFrame(new_data, new_index)\n\n    def merge(self, other, how=\'inner\', on=None, suffixes=(\'_x\', \'_y\'),\n              algorithm=\'merge\', is_on_sorted=False, is_on_unique=True):\n        """"""Database-like join this DataFrame with the other DataFrame.\n\n        Currently assumes the on-column(s) values are unique!\n\n        Note there\'s no automatic cast if the type of the on columns differs.\n\n        Algorithms and limitations:\n\n        - Merge algorithms: merge-join or hash-join. Typical pros and cons apply when choosing between the two.\n          Merge-join shall be used on fairly equally-sized DataFrames while a hash-join would be better when\n          one of the DataFrames is (much) smaller.\n        - Limitations:\n\n          + Hash-join requires the (smaller) hashed DataFrame\n            (more precisely, the on columns) to contain no duplicates!\n          + Merge-join requires the on-columns to be sorted!\n          + For unsorted data can only sort a single column! (current Weld limitation)\n\n        - Sortedness. If the on-columns are sorted, merge-join does not require to sort the data so it can be\n          significantly faster. Do add is_on_sorted=True if this is known to be true!\n        - Uniqueness. If the on-columns data contains duplicates, the algorithm is more complicated, i.e. slow.\n          Also hash-join cannot be used on a hashed (smaller) DataFrame with duplicates. Do add is_on_unique=True\n          if this is known to be true!\n        - Setting the above 2 flags incorrectly, e.g. is_on_sorted to True when data is in fact not sorted,\n          will produce undefined results.\n\n        Parameters\n        ----------\n        other : DataFrame\n            With which to merge.\n        how : {\'inner\', \'left\', \'right\', \'outer\'}, optional\n            Which kind of join to do.\n        on : str or list or None, optional\n            The columns from both DataFrames on which to join.\n            If None, will join on the index if it has the same name.\n        suffixes : tuple of str, optional\n            To append on columns not in `on` that have the same name in the DataFrames.\n        algorithm : {\'merge\', \'hash\'}, optional\n            Which algorithm to use. Note that for \'hash\', the `other` DataFrame is the one hashed.\n        is_on_sorted : bool, optional\n            If we know that the on columns are already sorted, can employ faster algorithm. If False,\n            the DataFrame will first be sorted by the on columns.\n        is_on_unique : bool, optional\n            If we know that the values are unique, can employ faster algorithm.\n\n        Returns\n        -------\n        DataFrame\n            DataFrame containing the merge result, with the `on` columns as index.\n\n        """"""\n        check_type(other, DataFrame)\n        check_type(how, str)\n        check_type(algorithm, str)\n        check_str_or_list_str(on)\n        check_inner_types(check_type(suffixes, tuple), str)\n        check_type(is_on_sorted, bool)\n        check_type(is_on_unique, bool)\n\n        # TODO: change defaults on flag & remove after implementation\n        assert is_on_unique\n\n        # TODO: this materialization/cache step could be skipped by encoding the whole sort + merge;\n        # TODO this would use the sorted on columns from weld_sort ($.1) in the join to obtain join-output-indices\n        # TODO which would then be passed through a \'translation table\' (of $.0) to obtain the original indices to keep\n        if not is_on_sorted:\n            self_df = self.sort_values(on)\n            other_df = other.sort_values(on)\n        else:\n            self_df = self\n            other_df = other\n\n        self_reset = self_df.reset_index()\n        other_reset = other_df.reset_index()\n        on = _compute_on(self_df, other_df, on,\n                         self_reset._gather_column_names(),\n                         other_reset._gather_column_names())\n        self_on_cols = self_reset[on]\n        other_on_cols = other_reset[on]\n\n        if algorithm == \'merge\':\n            # for left and right joins, the on columns can just be copied; no need for filter\n            def fake_filter_func(x, y, z):\n                return x\n\n            if how == \'inner\':\n                index_filter_func = weld_iloc_indices\n                data_filter_func = _series_iloc\n                weld_merge_func = weld_merge_join\n            elif how in {\'left\', \'right\'}:\n                index_filter_func = fake_filter_func\n                data_filter_func = _series_iloc_with_missing\n                weld_merge_func = weld_merge_join\n            else:\n                index_filter_func = fake_filter_func\n                data_filter_func = _series_iloc_with_missing\n                weld_merge_func = weld_merge_outer_join\n\n            weld_objects_indexes = weld_merge_func(self_on_cols._gather_data_for_weld(),\n                                                   self_on_cols._gather_weld_types(),\n                                                   other_on_cols._gather_data_for_weld(),\n                                                   other_on_cols._gather_weld_types(),\n                                                   how, is_on_sorted, is_on_unique, \'merge-join\')\n\n            new_index = _compute_new_index(weld_objects_indexes, how, on,\n                                           self_on_cols, other_on_cols,\n                                           index_filter_func)\n\n            new_data = OrderedDict()\n            self_no_on = self_reset.drop(on)\n            other_no_on = other_reset.drop(on)\n            self_new_names, other_new_names = _compute_new_names(self_no_on._gather_column_names(),\n                                                                 other_no_on._gather_column_names(),\n                                                                 suffixes)\n\n            for column_name, new_name in zip(self_no_on, self_new_names):\n                new_data[new_name] = data_filter_func(self_no_on[column_name], weld_objects_indexes[0], new_index)\n\n            for column_name, new_name in zip(other_no_on, other_new_names):\n                new_data[new_name] = data_filter_func(other_no_on[column_name], weld_objects_indexes[1], new_index)\n\n            return DataFrame(new_data, new_index)\n        elif algorithm == \'hash\':\n            raise NotImplementedError(\'Not yet supported\')\n        else:\n            raise NotImplementedError(\'Only merge- and hash-join algorithms are supported\')\n\n    def join(self, other, on=None, how=\'left\', lsuffix=None, rsuffix=None,\n             algorithm=\'merge\', is_on_sorted=True, is_on_unique=True):\n        """"""Database-like join this DataFrame with the other DataFrame.\n\n        Currently assumes the `on` columns are sorted and the on-column(s) values are unique!\n        Next work handles the other cases.\n\n        Note there\'s no automatic cast if the type of the on columns differs.\n\n        Check DataFrame.merge() for more details.\n\n        Parameters\n        ----------\n        other : DataFrame\n            With which to merge.\n        on : str or list or None, optional\n            The columns from both DataFrames on which to join.\n            If None, will join on the index if it has the same name.\n        how : {\'inner\', \'left\', \'right\', \'outer\'}, optional\n            Which kind of join to do.\n        lsuffix : str, optional\n            Suffix to use on columns that overlap from self.\n        rsuffix : str, optional\n            Suffix to use on columns that overlap from other.\n        algorithm : {\'merge\', \'hash\'}, optional\n            Which algorithm to use. Note that for \'hash\', the `other` DataFrame is the one hashed.\n        is_on_sorted : bool, optional\n            If we know that the on columns are already sorted, can employ faster algorithm.\n        is_on_unique : bool, optional\n            If we know that the values are unique, can employ faster algorithm.\n\n        Returns\n        -------\n        DataFrame\n            DataFrame containing the merge result, with the `on` columns as index.\n\n        """"""\n        check_type(lsuffix, str)\n        check_type(rsuffix, str)\n\n        self_names = self._gather_column_names()\n        other_names = other._gather_column_names()\n        common_names = set(self_names).intersection(set(other_names))\n        if len(common_names) > 0 and lsuffix is None and rsuffix is None:\n            raise ValueError(\'Columns overlap but no suffixes supplied\')\n\n        # need to ensure that some str suffixes are passed to merge\n        lsuffix = \'\' if lsuffix is None else lsuffix\n        rsuffix = \'\' if rsuffix is None else rsuffix\n\n        # TODO: pandas is more flexible, e.g. allows the index names to be different when joining on index\n        # TODO i.e. df(ind + a, b) join df(ind2 + b, c) does work and the index is now called ind\n\n        return self.merge(other, how, on, (lsuffix, rsuffix), algorithm, is_on_sorted, is_on_unique)\n\n    def drop_duplicates(self, subset=None, keep=\'min\'):\n        """"""Return DataFrame with duplicate rows (excluding index) removed,\n        optionally only considering subset columns.\n\n        Note that the row order is NOT maintained due to hashing.\n\n        Parameters\n        ----------\n        subset : list of str, optional\n            Which columns to consider\n        keep : {\'+\', \'*\', \'min\', \'max\'}, optional\n            What to select from the duplicate rows. These correspond to the possible merge operations in Weld.\n            Note that \'+\' and \'-\' might produce unexpected results for strings.\n\n        Returns\n        -------\n        DataFrame\n            DataFrame without duplicate rows.\n\n        """"""\n        subset = check_and_obtain_subset_columns(subset, self)\n\n        df = self.reset_index()\n        df_names = df._gather_column_names()\n        subset_indices = [df_names.index(col_name) for col_name in subset]\n\n        weld_objects = weld_drop_duplicates(df._gather_data_for_weld(),\n                                            df._gather_weld_types(),\n                                            subset_indices,\n                                            keep)\n\n        index_data = self.index._gather_data(name=None)\n        new_index = [Index(weld_objects[i], v.dtype, k)\n                     for i, k, v in zip(list(range(len(index_data))), index_data.keys(), index_data.values())]\n        if len(new_index) > 1:\n            new_index = MultiIndex(new_index, self.index._gather_names())\n        else:\n            new_index = new_index[0]\n\n        new_data = OrderedDict((sr.name, Series(obj, new_index, sr.dtype, sr.name))\n                               for sr, obj in zip(self._iter(), weld_objects[len(index_data):]))\n\n        return DataFrame(new_data, new_index)\n\n    def dropna(self, subset=None):\n        """"""Remove missing values according to Baloo\'s convention.\n\n        Parameters\n        ----------\n        subset : list of str, optional\n            Which columns to check for missing values in.\n\n        Returns\n        -------\n        DataFrame\n            DataFrame with no null values in columns.\n\n        """"""\n        subset = check_and_obtain_subset_columns(subset, self)\n        not_nas = [v.notna() for v in self[subset]._iter()]\n        and_filter = reduce(lambda x, y: x & y, not_nas)\n\n        return self[and_filter]\n\n    def fillna(self, value):\n        """"""Returns DataFrame with missing values replaced with value.\n\n        Parameters\n        ----------\n        value : {int, float, bytes, bool} or dict\n            Scalar value to replace missing values with. If dict, replaces missing values\n            only in the key columns with the value scalar.\n\n        Returns\n        -------\n        DataFrame\n            With missing values replaced.\n\n        """"""\n        if is_scalar(value):\n            new_data = OrderedDict((column.name, column.fillna(value))\n                                   for column in self._iter())\n\n            return DataFrame(new_data, self.index)\n        elif isinstance(value, dict):\n            new_data = OrderedDict((column.name, column.fillna(value[column.name]) if column.name in value else column)\n                                   for column in self._iter())\n\n            return DataFrame(new_data, self.index)\n        else:\n            raise TypeError(\'Can only fill na given a scalar or a dict mapping columns to their respective scalar\')\n\n    def groupby(self, by):\n        """"""Group by certain columns, excluding index.\n\n        Simply reset_index if desiring to group by some index column too.\n\n        Parameters\n        ----------\n        by  : str or list of str\n            Column(s) to groupby.\n\n        Returns\n        -------\n        DataFrameGroupBy\n            Object encoding the groupby operation.\n\n        """"""\n        check_str_or_list_str(by)\n        by = as_list(by)\n        if len(set(by)) == len(self._data):\n            raise ValueError(\'Cannot groupby all columns\')\n\n        from .groupby import DataFrameGroupBy\n\n        return DataFrameGroupBy(self, by)\n\n    @classmethod\n    def from_pandas(cls, df):\n        """"""Create baloo DataFrame from pandas DataFrame.\n\n        Parameters\n        ----------\n        df : pandas.frame.DataFrame\n\n        Returns\n        -------\n        DataFrame\n\n        """"""\n        from pandas import DataFrame as PandasDataFrame, Index as PandasIndex, MultiIndex as PandasMultiIndex\n\n        check_type(df, PandasDataFrame)\n\n        if isinstance(df.index, PandasIndex):\n            baloo_index = Index.from_pandas(df.index)\n        elif isinstance(df.index, PandasMultiIndex):\n            baloo_index = MultiIndex.from_pandas(df.index)\n        else:\n            raise TypeError(\'Cannot convert pandas index of type={} to baloo\'.format(type(df.index)))\n\n        baloo_data = OrderedDict((column_name, _series_from_pandas(df[column_name], baloo_index))\n                                 for column_name in df)\n\n        return DataFrame(baloo_data, baloo_index)\n\n    def to_pandas(self):\n        """"""Convert to pandas DataFrame.\n\n        Note the data is expected to be evaluated.\n\n        Returns\n        -------\n        pandas.frame.DataFrame\n\n        """"""\n        from pandas import DataFrame as PandasDataFrame\n\n        pandas_index = self.index.to_pandas()\n        pandas_data = OrderedDict((column.name, column.to_pandas())\n                                  for column in self._iter())\n\n        return PandasDataFrame(pandas_data, pandas_index)\n\n    # TODO: once more are implemented, perhaps move to a mixin-like class for io\n    def to_csv(self, filepath, sep=\',\', header=True, index=True):\n        """"""Save DataFrame as csv.\n\n        Parameters\n        ----------\n        filepath : str\n        sep : str, optional\n            Separator used between values.\n        header : bool, optional\n            Whether to save the header.\n        index : bool, optional\n            Whether to save the index columns.\n\n        Returns\n        -------\n        None\n\n        """"""\n        from ..io import to_csv\n\n        return to_csv(self, filepath, sep=sep, header=header, index=index)\n\n\ndef _default_index(dataframe_data, length):\n    if length is not None:\n        return default_index(length)\n    else:\n        if len(dataframe_data) == 0:\n            return default_index(0)\n        else:\n            # must encode from a random column then\n            return default_index(dataframe_data[list(dataframe_data.keys())[0]])\n\n\n# TODO: if there\'s no index, pandas tries to get an index from the data\n# TODO if there are multiple indexes, there\'s an outer join on the index;\n# TODO: if an index is passed though, it overrides any index inferences ^\ndef _process_index(index, data, length):\n    if index is None:\n        return _default_index(data, length)\n    else:\n        return check_type(index, (Index, MultiIndex))\n\n\ndef _check_input_data(data):\n    if data is None:\n        return OrderedDict()\n    else:\n        check_type(data, dict)\n        check_inner_types(data.values(), (np.ndarray, Series, list))\n\n        return data\n\n\ndef _process_data(data, index):\n    for k, v in data.items():\n        # TODO: pandas does alignment here\n        if isinstance(v, Series):\n            v.name = k\n            v.index = index\n        else:\n            # must be ndarray or list\n            data[k] = Series(v, index, name=k)\n\n    return data\n\n\ndef _infer_length(index, data):\n    index_length = None\n    if index is not None:\n        index_length = infer_length(index._gather_data().values())\n\n    if index_length is not None:\n        return index_length\n    else:\n        return infer_length(data.values())\n\n\ndef _obtain_length(length, dataframe_data):\n    if length is not None:\n        return length\n    else:\n        # first check again for raw data\n        length = infer_length(dataframe_data.values())\n        if length is None:\n            keys = list(dataframe_data.keys())\n            # empty DataFrame\n            if len(keys) == 0:\n                return 0\n            # pick first column (which is a Series) and encode its length\n            length = weld_count(dataframe_data[keys[0]].weld_expr)\n\n        return length\n\n\ndef _compute_on(self, other, on, all_names_self, all_names_other):\n    if on is None:\n        self_index_names = self.index._gather_names()\n        other_index_names = other.index._gather_names()\n\n        if len(self_index_names) != len(other_index_names):\n            raise ValueError(\'Expected indexes to be of the same dimensions when on=None\')\n        elif self_index_names != other_index_names:\n            raise ValueError(\'When on=None, the names of both indexes must be the same\')\n        else:\n            return self_index_names\n    else:\n        on = as_list(on)\n        set_on = set(on)\n\n        if not set_on.issubset(set(all_names_self)):\n            raise ValueError(\'On column(s) not included in the self DataFrame\')\n        elif not set_on.issubset(set(all_names_other)):\n            raise ValueError(\'On column(s) not included in the other DataFrame\')\n        else:\n            return on\n\n\ndef _compute_new_names(names_self, names_other, suffixes):\n    common_names = set(names_self).intersection(set(names_other))\n    self_new_names = names_self\n    other_new_names = names_other\n\n    if len(common_names) != 0:\n        for name in common_names:\n            self_new_names[self_new_names.index(name)] += suffixes[0]\n            other_new_names[other_new_names.index(name)] += suffixes[1]\n\n    return self_new_names, other_new_names\n\n\n# TODO: perhaps just split into 4 methods for each join type\ndef _compute_new_index(weld_objects_indexes, how, on, self_on_cols, other_on_cols, filter_func):\n    if how in [\'inner\', \'left\']:\n        extract_index_from = self_on_cols\n        index_index = 0\n    else:\n        extract_index_from = other_on_cols\n        index_index = 1\n\n    if how == \'outer\':\n        data_arg = \'weld_objects_indexes[2]\'\n    else:\n        data_arg = \'column.weld_expr\'\n\n    new_indexes = []\n    data_arg = data_arg if how != \'outer\' else data_arg + \'[i]\'\n    for i, column_name in enumerate(on):\n        column = extract_index_from._data[column_name]\n        new_indexes.append(Index(filter_func(eval(data_arg),\n                                             column.weld_type,\n                                             weld_objects_indexes[index_index]),\n                                 column.dtype,\n                                 column.name))\n    if len(on) > 1:\n        new_index = MultiIndex(new_indexes, on)\n    else:\n        new_index = new_indexes[0]\n\n    return new_index\n\n\ndef _drop_str_columns(df):\n    """"""\n\n    Parameters\n    ----------\n    df : DataFrame\n\n    Returns\n    -------\n\n    """"""\n    str_columns = filter(lambda pair: pair[1].char == \'S\', df._gather_dtypes().items())\n    str_column_names = list(map(lambda pair: pair[0], str_columns))\n\n    return df.drop(str_column_names)\n\n\ndef check_and_obtain_subset_columns(columns, df):\n    check_type(columns, list)\n    check_inner_types(columns, str)\n\n    if columns is None:\n        return df._gather_column_names()\n    elif len(columns) < 1:\n        raise ValueError(\'Need at least one column\')\n    elif not set(columns).issubset(set(df._gather_column_names())):\n        raise ValueError(\'Subset={} is not all part of the columns={}\'.format(columns, df._gather_column_names()))\n    else:\n        return columns\n'"
baloo/core/generic.py,0,"b'import abc\n\n\n# To enforce the implementation of these methods such that convention is maintained.\n# Note: inherit from this AFTER any other class that might implement desired default behavior.\nclass BalooCommon(abc.ABC):\n    @property\n    @abc.abstractmethod\n    def values(self):\n        """"""The internal data representation.""""""\n        raise NotImplementedError\n\n    @property\n    @abc.abstractmethod\n    def empty(self):\n        """"""Check whether the data structure is empty.\n\n        Returns\n        -------\n        bool\n\n        """"""\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def __len__(self):\n        # eager operation returning the length of the internal data\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def __repr__(self):\n        # lazy repr without any actual raw/lazy data\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def __str__(self):\n        # eager representation including data\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def evaluate(self):\n        """"""Evaluate by returning object of the same type but now containing raw data.""""""\n        raise NotImplementedError\n\n\nclass BinaryOps(abc.ABC):\n    @abc.abstractmethod\n    def _comparison(self, other, comparison):\n        raise NotImplementedError\n\n    def __lt__(self, other):\n        return self._comparison(other, \'<\')\n\n    def __le__(self, other):\n        return self._comparison(other, \'<=\')\n\n    def __eq__(self, other):\n        return self._comparison(other, \'==\')\n\n    def __ne__(self, other):\n        return self._comparison(other, \'!=\')\n\n    def __ge__(self, other):\n        return self._comparison(other, \'>=\')\n\n    def __gt__(self, other):\n        return self._comparison(other, \'>\')\n\n    def isna(self):\n        return self._comparison(None, \'==\')\n\n    def notna(self):\n        return self._comparison(None, \'!=\')\n\n    @abc.abstractmethod\n    def _element_wise_operation(self, other, operation):\n        raise NotImplementedError\n\n    def __add__(self, other):\n        return self._element_wise_operation(other, \'+\')\n\n    def __sub__(self, other):\n        return self._element_wise_operation(other, \'-\')\n\n    def __mul__(self, other):\n        return self._element_wise_operation(other, \'*\')\n\n    def __truediv__(self, other):\n        return self._element_wise_operation(other, \'/\')\n\n    def __pow__(self, other):\n        return self._element_wise_operation(other, \'pow\')\n\n\nclass BitOps(abc.ABC):\n    @abc.abstractmethod\n    def _bitwise_operation(self, other, operation):\n        raise NotImplementedError\n\n    def __and__(self, other):\n        return self._bitwise_operation(other, \'&&\')\n\n    def __or__(self, other):\n        return self._bitwise_operation(other, \'||\')\n\n\nclass IndexCommon(abc.ABC):\n    @property\n    @abc.abstractmethod\n    def name(self):\n        """"""Name of the Index.\n\n        Returns\n        -------\n        str\n            name\n\n        """"""\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def _iloc_indices(self, indices):\n        """"""Filter based on indices.\n\n        Parameters\n        ----------\n        indices : numpy.ndarray or WeldObject\n\n        """"""\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def _iloc_indices_with_missing(self, indices):\n        """"""Filter based on indices, where an index > length signifies missing data.\n\n        Parameters\n        ----------\n        indices : numpy.ndarray or WeldObject\n\n        """"""\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def _gather_names(self):\n        # returns the names of the index columns as a list replacing None\'s with default values\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def _gather_data_for_weld(self):\n        # returns the raw/WeldObjects in a list s.t. can be passed directly to weld_* methods\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def _gather_data(self):\n        # returns a dict of names to Indexes, not to raw data for Weld\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def _gather_weld_types(self):\n        # returns the raw/WeldObjects in a list s.t. can be passed directly to weld_* methods\n        raise NotImplementedError\n'"
baloo/core/groupby.py,0,"b'from collections import OrderedDict\n\nfrom .frame import DataFrame\nfrom .indexes import Index, MultiIndex\nfrom .series import Series\nfrom ..weld import weld_groupby, weld_groupby_aggregate, weld_vec_of_struct_to_struct_of_vec, LazyStructOfVecResult, \\\n    Cache, extract_placeholder_weld_objects, weld_to_numpy_dtype, WeldDouble, WeldLong, \\\n    weld_groupby_aggregate_dictmerger\n\n\nclass DataFrameGroupBy(object):\n    """"""Object encoding a groupby operation.""""""\n    _dictmerger_aggregations = {\'+\', \'*\', \'min\', \'max\'}\n\n    def __init__(self, df, by):\n        """"""Create a groupby object.\n\n        Parameters\n        ----------\n        df : DataFrame\n            Which will be grouped by.\n        by : list of str\n            Which columns to group by.\n\n        """"""\n        self._index_df = df[by]\n        self._columns_df = df.drop(by)\n        self._data_for_weld = df._gather_data_for_weld()\n        self._weld_types = df._gather_weld_types()\n        self._by = by\n        self._by_indices = _compute_by_indices(self._by, df)\n\n    def _group_dictmerger(self, aggregation):\n        return weld_groupby_aggregate_dictmerger(self._data_for_weld,\n                                                 self._weld_types,\n                                                 self._by_indices,\n                                                 aggregation)\n\n    def _group_groupmerger(self, aggregation, result_type=None):\n        grouped = weld_groupby(self._data_for_weld,\n                               self._weld_types,\n                               self._by_indices)\n\n        return weld_groupby_aggregate(grouped,\n                                      self._weld_types,\n                                      self._by_indices,\n                                      aggregation,\n                                      result_type)\n\n    def _group_aggregate(self, aggregation, result_type=None):\n        if aggregation in self._dictmerger_aggregations:\n            return self._group_dictmerger(aggregation)\n        else:\n            return self._group_groupmerger(aggregation, result_type)\n\n    def _aggregate(self, aggregation, result_type=None):\n        weld_types, vec_of_struct = self._group_aggregate(aggregation, result_type)\n        struct_of_vec = weld_vec_of_struct_to_struct_of_vec(vec_of_struct, weld_types)\n        intermediate_result = LazyStructOfVecResult(struct_of_vec, weld_types)\n        dependency_name = Cache.cache_intermediate_result(intermediate_result, \'group_aggr\')\n\n        weld_objects = extract_placeholder_weld_objects(dependency_name, len(weld_types), \'group_aggr\')\n\n        new_index = [Index(weld_objects[i], v, k)\n                     for i, k, v in zip(list(range(len(self._index_df._data))),\n                                        self._index_df._gather_column_names(),\n                                        self._index_df._gather_dtypes().values())]\n        if len(new_index) > 1:\n            new_index = MultiIndex(new_index, [index.name for index in new_index])\n        else:\n            new_index = new_index[0]\n\n        new_dtypes = self._columns_df._gather_dtypes().values() if result_type is None \\\n            else (weld_to_numpy_dtype(result_type) for _ in weld_types)\n        new_data = OrderedDict((name, Series(obj, new_index, dtype, name))\n                               for name, obj, dtype in zip(self._columns_df._gather_column_names(),\n                                                           weld_objects[len(self._by):],\n                                                           new_dtypes))\n\n        return DataFrame(new_data, new_index)\n\n    def min(self):\n        return self._aggregate(\'min\')\n\n    def max(self):\n        return self._aggregate(\'max\')\n\n    def sum(self):\n        return self._aggregate(\'+\')\n\n    def prod(self):\n        return self._aggregate(\'*\')\n\n    def mean(self):\n        return self._aggregate(\'mean\', result_type=WeldDouble())\n\n    def var(self):\n        return self._aggregate(\'var\', result_type=WeldDouble())\n\n    def std(self):\n        return self._aggregate(\'std\', result_type=WeldDouble())\n\n    def size(self):\n        return self._aggregate(\'size\', result_type=WeldLong())\n\n\ndef _compute_by_indices(by, df):\n    column_names = df._gather_column_names()\n\n    return [column_names.index(column_name) for column_name in by]\n'"
baloo/core/indexing.py,0,"b'from collections import OrderedDict\n\nfrom .frame import DataFrame\nfrom .series import Series, _series_iloc, _series_iloc_with_missing\nfrom .utils import check_type, check_weld_long_array\nfrom ..weld import LazyScalarResult, weld_iloc_int, LazyArrayResult\n\n\nclass _ILocIndexer(object):\n    """"""Implements iloc indexing.\n\n    Attributes\n    ----------\n    data : Series or DataFrame\n        Which data to select from by int/slice indexing.\n\n    """"""\n    def __init__(self, data):\n        self.data = check_type(data, (Series, DataFrame))\n\n    def __getitem__(self, item):\n        if isinstance(item, int):\n            if isinstance(self.data, Series):\n                return LazyScalarResult(weld_iloc_int(self.data.weld_expr,\n                                                      item),\n                                        self.data.weld_type)\n            elif isinstance(self.data, DataFrame):\n                # requires the supertype \'object\' in a numpy array which perhaps in Weld could be strings;\n                # this is because the expected return is a Series and method needs to put ints/floats/strings in the\n                # same data structure, i.e. the same numpy ndarray\n                raise NotImplementedError()\n        elif isinstance(item, slice):\n            return self.data[item]\n        elif isinstance(item, LazyArrayResult):\n            check_weld_long_array(item)\n            item = item.weld_expr\n\n            if isinstance(self.data, Series):\n                return _series_iloc(self.data, item, self.data.index._iloc_indices(item))\n            elif isinstance(self.data, DataFrame):\n                new_index = self.data.index._iloc_indices(item)\n\n                new_data = OrderedDict((column.name, _series_iloc(column, item, new_index))\n                                       for column in self.data._iter())\n\n                return DataFrame(new_data, new_index)\n        else:\n            raise TypeError(\'Expected an int, slice, or indices array\')\n\n    def _iloc_with_missing(self, item):\n        if isinstance(self.data, Series):\n            return _series_iloc_with_missing(self.data, item, self.data.index._iloc_indices_with_missing(item))\n        elif isinstance(self.data, DataFrame):\n            raise NotImplementedError()\n'"
baloo/core/series.py,20,"b'from collections import OrderedDict\n\nimport numpy as np\nfrom pandas import Series as PandasSeries\nfrom tabulate import tabulate\n\nfrom .generic import BinaryOps, BitOps, BalooCommon\nfrom .indexes import Index, MultiIndex\nfrom .utils import infer_dtype, default_index, check_type, is_scalar, check_valid_int_slice, check_weld_bit_array, \\\n    convert_to_numpy, check_dtype, shorten_data\nfrom ..weld import LazyArrayResult, weld_compare, numpy_to_weld_type, weld_filter, \\\n    weld_slice, weld_array_op, weld_invert, weld_tail, weld_element_wise_op, LazyDoubleResult, LazyScalarResult, \\\n    weld_mean, weld_variance, weld_standard_deviation, WeldObject, weld_agg, weld_iloc_indices, \\\n    weld_iloc_indices_with_missing, weld_unique, default_missing_data_literal, weld_replace, weld_udf\n\n\nclass Series(LazyArrayResult, BinaryOps, BitOps, BalooCommon):\n    """"""Weld-ed Pandas Series.\n\n    Attributes\n    ----------\n    index\n    dtype\n    name\n    iloc\n\n    See Also\n    --------\n    pandas.Series : https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html\n\n    Examples\n    --------\n    >>> import baloo as bl\n    >>> import numpy as np\n    >>> sr = bl.Series([0, 1, 2])\n    >>> sr\n    Series(name=None, dtype=int64)\n    >>> sr.index\n    RangeIndex(start=0, stop=3, step=1)\n    >>> sr = sr.evaluate()\n    >>> sr  # repr\n    Series(name=None, dtype=int64)\n    >>> print(sr)  # str\n    <BLANKLINE>\n    ---  --\n      0   0\n      1   1\n      2   2\n    >>> sr.index\n    Index(name=None, dtype=int64)\n    >>> print(sr.index)\n    [0 1 2]\n    >>> len(sr)  # eager computation\n    3\n    >>> sr.values\n    array([0, 1, 2])\n    >>> (sr + 2).evaluate().values\n    array([2, 3, 4])\n    >>> (sr - bl.Index(np.arange(3))).evaluate().values\n    array([0, 0, 0])\n    >>> print(sr.max().evaluate())\n    2\n    >>> print(sr.var().evaluate())\n    1.0\n    >>> print(sr.agg([\'min\', \'std\']).evaluate())\n    <BLANKLINE>\n    ---  --\n    min   0\n    std   1\n\n    """"""\n    _empty_text = \'Empty Series\'\n\n    # TODO: Fix en/decoding string\'s dtype; e.g. filter returns max length dtype (|S11) even if actual result is |S7\n    def __init__(self, data=None, index=None, dtype=None, name=None):\n        """"""Initialize a Series object.\n\n        Parameters\n        ----------\n        data : numpy.ndarray or WeldObject or list, optional\n            Raw data or Weld expression.\n        index : Index or RangeIndex or MultiIndex, optional\n            Index linked to the data; it is assumed to be of the same length.\n            RangeIndex by default.\n        dtype : numpy.dtype or type, optional\n            Desired Numpy dtype for the elements. If type, it must be a NumPy type, e.g. np.float32.\n            If data is np.ndarray with a dtype different to dtype argument,\n            it is astype\'d to the argument dtype. Note that if data is WeldObject, one must explicitly astype\n            to convert type. Inferred from `data` by default.\n        name : str, optional\n            Name of the Series.\n\n        """"""\n        data, dtype = _process_input(data, dtype)\n        self.index = _process_index(index, data)\n        self.dtype = dtype\n        self.name = check_type(name, str)\n        # TODO: this should be used to annotate Weld code for speedups\n        self._length = len(data) if isinstance(data, np.ndarray) else None\n\n        super(Series, self).__init__(data, numpy_to_weld_type(self.dtype))\n\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, value):\n        self._name = value\n\n    @property\n    def iloc(self):\n        """"""Retrieve Indexer by index.\n\n        Supported iloc functionality exemplified below.\n\n        Returns\n        -------\n        _ILocIndexer\n\n        Examples\n        --------\n        >>> sr = bl.Series(np.arange(3))\n        >>> print(sr.iloc[2].evaluate())\n        2\n        >>> print(sr.iloc[0:2].evaluate())\n        <BLANKLINE>\n        ---  --\n          0   0\n          1   1\n        >>> print(sr.iloc[bl.Series(np.array([0, 2]))].evaluate())\n        <BLANKLINE>\n        ---  --\n          0   0\n          2   2\n\n        """"""\n        from .indexing import _ILocIndexer\n\n        return _ILocIndexer(self)\n\n    @property\n    def str(self):\n        """"""Get Access to string functions.\n\n        Returns\n        -------\n        StringMethods\n\n        Examples\n        --------\n        >>> sr = bl.Series([b\' aB \', b\'GoOsfrABA\'])\n        >>> print(sr.str.lower().evaluate())\n        <BLANKLINE>\n        ---  ---------\n          0   ab\n          1  goosfraba\n\n        """"""\n        if self.dtype.char != \'S\':\n            raise AttributeError(\'Can only use .str when data is of type np.bytes_\')\n\n        from .strings import StringMethods\n\n        return StringMethods(self)\n\n    def __repr__(self):\n        return ""{}(name={}, dtype={})"".format(self.__class__.__name__,\n                                              self.name,\n                                              self.dtype)\n\n    def __str__(self):\n        if self.empty:\n            return self._empty_text\n\n        # index\n        str_data = OrderedDict()\n        str_data.update((name, shorten_data(data.values)) for name, data in self.index._gather_data(\' \').items())\n\n        # self data\n        name = \'\' if self.name is None else self.name\n        str_data[name] = shorten_data(self.values)\n\n        return tabulate(str_data, headers=\'keys\')\n\n    def _comparison(self, other, comparison):\n        if other is None:\n            other = default_missing_data_literal(self.weld_type)\n\n            return _series_compare(self, other, comparison)\n        elif is_scalar(other):\n            return _series_compare(self, other, comparison)\n        else:\n            raise TypeError(\'Can currently only compare with scalars\')\n\n    def _bitwise_operation(self, other, operation):\n        check_type(other, LazyArrayResult)\n        check_weld_bit_array(other)\n        check_weld_bit_array(self)\n\n        return _series_array_op(self, other, operation)\n\n    def _element_wise_operation(self, other, operation):\n        if isinstance(other, LazyArrayResult):\n            return _series_array_op(self, other, operation)\n        elif is_scalar(other):\n            return _series_element_wise_op(self, other, operation)\n        else:\n            raise TypeError(\'Can only apply operation with scalar or Series\')\n\n    def astype(self, dtype):\n        check_dtype(dtype)\n\n        return Series(self._astype(dtype),\n                      self.index,\n                      dtype,\n                      self.name)\n\n    def __getitem__(self, item):\n        """"""Select from the Series.\n\n        Supported selection functionality exemplified below.\n\n        Examples\n        --------\n        >>> sr = bl.Series(np.arange(5, dtype=np.float32), name=\'Test\')\n        >>> sr = sr[sr > 0]\n        >>> sr\n        Series(name=Test, dtype=float32)\n        >>> print(sr.evaluate())\n               Test\n        ---  ------\n          1       1\n          2       2\n          3       3\n          4       4\n        >>> sr = sr[(sr != 1) & ~(sr > 3)]\n        >>> print(sr.evaluate())\n               Test\n        ---  ------\n          2       2\n          3       3\n        >>> print(sr[:1].evaluate())\n               Test\n        ---  ------\n          2       2\n\n        """"""\n        if isinstance(item, LazyArrayResult):\n            check_weld_bit_array(item)\n\n            return _series_filter(self, item, self.index[item])\n        elif isinstance(item, slice):\n            check_valid_int_slice(item)\n\n            return _series_slice(self, item, self.index[item])\n        else:\n            raise TypeError(\'Expected a LazyArrayResult or a slice\')\n\n    def __invert__(self):\n        check_weld_bit_array(self)\n\n        return Series(weld_invert(self.weld_expr),\n                      self.index,\n                      self.dtype,\n                      self.name)\n\n    # TODO: perhaps skip making a new object if data is raw already?\n    def evaluate(self, verbose=False, decode=True, passes=None, num_threads=1, apply_experimental=True):\n        """"""Evaluates by creating a Series containing evaluated data and index.\n\n        See `LazyResult`\n\n        Returns\n        -------\n        Series\n            Series with evaluated data and index.\n\n        Examples\n        --------\n        >>> sr = bl.Series(np.arange(3)) > 0\n        >>> weld_code = sr.values  # accessing values now returns the weld code as a string\n        >>> sr = sr.evaluate()\n        >>> sr.values  # now it is evaluated to raw data\n        array([False,  True,  True])\n\n        """"""\n        # TODO: work on masking (branch masking) ~ evaluate the mask first and use on both index and data;\n        # TODO right now the filter gets computed twice, once for index and once for the data\n        evaluated_data = super(Series, self).evaluate(verbose, decode, passes, num_threads, apply_experimental)\n        evaluated_index = self.index.evaluate(verbose, decode, passes, num_threads, apply_experimental)\n\n        return Series(evaluated_data, evaluated_index, self.dtype, self.name)\n\n    def head(self, n=5):\n        """"""Return Series with first n values.\n\n        Parameters\n        ----------\n        n : int\n            Number of values.\n\n        Returns\n        -------\n        Series\n            Series containing the first n values.\n\n        Examples\n        --------\n        >>> sr = bl.Series(np.arange(3))\n        >>> print(sr.head(2).evaluate())\n        <BLANKLINE>\n        ---  --\n          0   0\n          1   1\n\n        """"""\n        return self[:n]\n\n    def tail(self, n=5):\n        """"""Return Series with the last n values.\n\n        Parameters\n        ----------\n        n : int\n            Number of values.\n\n        Returns\n        -------\n        Series\n            Series containing the last n values.\n\n        Examples\n        --------\n        >>> sr = bl.Series(np.arange(3))\n        >>> print(sr.tail(2).evaluate())\n        <BLANKLINE>\n        ---  --\n          1   1\n          2   2\n\n        """"""\n        if self._length is not None:\n            length = self._length\n        else:\n            length = self._lazy_len().weld_expr\n\n        return _series_tail(self, self.index.tail(n), length, n)\n\n    def sum(self):\n        return LazyScalarResult(self._aggregate(\'+\').weld_expr, self.weld_type)\n\n    def prod(self):\n        return LazyScalarResult(self._aggregate(\'*\').weld_expr, self.weld_type)\n\n    def count(self):\n        return self._lazy_len()\n\n    def mean(self):\n        return LazyDoubleResult(weld_mean(self.weld_expr, self.weld_type))\n\n    def var(self):\n        return LazyDoubleResult(weld_variance(self.weld_expr, self.weld_type))\n\n    def std(self):\n        return LazyDoubleResult(weld_standard_deviation(self.weld_expr, self.weld_type))\n\n    # TODO: currently casting everything to float64 (even if already f64 ~ weld_aggs TODO);\n    # TODO maybe for min/max/count/sum/prod/.. cast ints to int64 like pandas does\n    def agg(self, aggregations):\n        """"""Multiple aggregations optimized.\n\n        Parameters\n        ----------\n        aggregations : list of str\n            Which aggregations to perform.\n\n        Returns\n        -------\n        Series\n            Series with resulting aggregations.\n\n        """"""\n        check_type(aggregations, list)\n\n        new_index = Index(np.array(aggregations, dtype=np.bytes_), np.dtype(np.bytes_))\n\n        return _series_agg(self, aggregations, new_index)\n\n    def unique(self):\n        """"""Return unique values in the Series.\n\n        Note that because it is hash-based, the result will NOT be in the same order (unlike pandas).\n\n        Returns\n        -------\n        LazyArrayResult\n            Unique values in random order.\n\n        """"""\n        return LazyArrayResult(weld_unique(self.values,\n                                           self.weld_type),\n                               self.weld_type)\n\n    def dropna(self):\n        """"""Returns Series without null values according to Baloo\'s convention.\n\n        Returns\n        -------\n        Series\n            Series with no null values.\n\n        """"""\n        return self[self.notna()]\n\n    def fillna(self, value):\n        """"""Returns Series with missing values replaced with value.\n\n        Parameters\n        ----------\n        value : {int, float, bytes, bool}\n            Scalar value to replace missing values with.\n\n        Returns\n        -------\n        Series\n            With missing values replaced.\n\n        """"""\n        if not is_scalar(value):\n            raise TypeError(\'Value to replace with is not a valid scalar\')\n\n        return Series(weld_replace(self.weld_expr,\n                                   self.weld_type,\n                                   default_missing_data_literal(self.weld_type),\n                                   value),\n                      self.index,\n                      self.dtype,\n                      self.name)\n\n    def apply(self, func, mapping=None, new_dtype=None, **kwargs):\n        """"""Apply an element-wise UDF to the Series.\n\n        There are currently 6 options for using a UDF. First 4 are lazy,\n        other 2 are eager and require the use of the raw decorator:\n\n        - One of the predefined functions in baloo.functions.\n        - Implementing a function which encodes the result. kwargs are automatically passed to it.\n        - Pure Weld code and mapping.\n        - Weld code and mapping along with a dynamically linked C++ lib containing the UDF.\n        - Using a NumPy function, which however is EAGER and hence requires self.values to be raw. Additionally, NumPy\n            does not support kwargs in (all) functions so must use raw decorator to strip away weld_type.\n        - Implementing an eager function with the same precondition as above. Use the raw decorator to check this.\n\n        Parameters\n        ----------\n        func : function or str\n            Weld code as a str to encode or function from baloo.functions.\n        mapping : dict, optional\n            Additional mappings in the weld_template to replace on execution.\n            self is added by default to reference to this Series.\n        new_dtype : numpy.dtype, optional\n            Specify the new dtype of the result Series.\n            If None, it assumes it\'s the same dtype as before the apply.\n\n        Returns\n        -------\n        Series\n            With UDF result.\n\n        Examples\n        --------\n        >>> import baloo as bl\n        >>> sr = bl.Series([1, 2, 3])\n        >>> weld_template = \'map({self}, |e| e + {scalar})\'\n        >>> mapping = {\'scalar\': \'2L\'}\n        >>> print(sr.apply(weld_template, mapping).evaluate())\n        <BLANKLINE>\n        ---  --\n          0   3\n          1   4\n          2   5\n        >>> weld_template2 = \'map({self}, |e| e + 3L)\'\n        >>> print(sr.apply(weld_template2).evaluate())\n        <BLANKLINE>\n        ---  --\n          0   4\n          1   5\n          2   6\n        >>> print(bl.Series([1., 4., 100.]).apply(bl.sqrt).evaluate())  # lazy predefined function\n        <BLANKLINE>\n        ---  --\n          0   1\n          1   2\n          2  10\n        >>> sr = bl.Series([4, 2, 3, 1])\n        >>> print(sr.apply(bl.sort, kind=\'q\').evaluate())  # eager wrapper over np.sort (which uses raw decorator)\n        <BLANKLINE>\n        ---  --\n          0   1\n          1   2\n          2   3\n          3   4\n        >>> print(sr.apply(bl.raw(np.sort, kind=\'q\')).evaluate())  # np.sort directly\n        <BLANKLINE>\n        ---  --\n          0   1\n          1   2\n          2   3\n          3   4\n        >>> print(sr.apply(bl.raw(lambda x: np.sort(x, kind=\'q\'))).evaluate())  # lambda also works, with x = np.array\n        <BLANKLINE>\n        ---  --\n          0   1\n          1   2\n          2   3\n          3   4\n\n        # check tests/core/cudf/* and tests/core/test_series.test_cudf for C UDF example\n\n        """"""\n        if callable(func):\n            return Series(func(self.values,\n                               weld_type=self.weld_type,\n                               **kwargs),\n                          self.index,\n                          self.dtype,\n                          self.name)\n        elif isinstance(func, str):\n            check_type(mapping, dict)\n            check_dtype(new_dtype)\n\n            default_mapping = {\'self\': self.values}\n            if mapping is None:\n                mapping = default_mapping\n            else:\n                mapping.update(default_mapping)\n\n            if new_dtype is None:\n                new_dtype = self.dtype\n\n            return Series(weld_udf(func,\n                                   mapping),\n                          self.index,\n                          new_dtype,\n                          self.name)\n        else:\n            raise TypeError(\'Expected function or str defining a weld_template\')\n\n    @classmethod\n    def from_pandas(cls, series):\n        """"""Create baloo Series from pandas Series.\n\n        Parameters\n        ----------\n        series : pandas.series.Series\n\n        Returns\n        -------\n        Series\n\n        """"""\n        from pandas import Index as PandasIndex, MultiIndex as PandasMultiIndex\n\n        if isinstance(series.index, PandasIndex):\n            baloo_index = Index.from_pandas(series.index)\n        elif isinstance(series.index, PandasMultiIndex):\n            baloo_index = MultiIndex.from_pandas(series.index)\n        else:\n            raise TypeError(\'Cannot convert pandas index of type={} to baloo\'.format(type(series.index)))\n\n        return _series_from_pandas(series, baloo_index)\n\n    def to_pandas(self):\n        """"""Convert to pandas Series\n\n        Returns\n        -------\n        pandas.series.Series\n\n        """"""\n        pandas_index = self.index.to_pandas()\n\n        return _series_to_pandas(self, pandas_index)\n\n\ndef _process_input(data, dtype):\n    if data is None:\n        return np.empty(0), np.dtype(np.float64)\n    else:\n        check_type(data, (np.ndarray, WeldObject, list))\n        check_dtype(dtype)\n\n        if isinstance(data, list):\n            data = convert_to_numpy(data)\n\n        inferred_dtype = infer_dtype(data, dtype)\n        if isinstance(data, np.ndarray) and data.dtype.char != inferred_dtype.char:\n            data = data.astype(inferred_dtype)\n\n        return data, inferred_dtype\n\n\ndef _process_index(index, data):\n    if index is None:\n        return default_index(data)\n    else:\n        return check_type(index, (Index, MultiIndex))\n\n\ndef _series_compare(series, other, comparison):\n    return Series(weld_compare(series.weld_expr,\n                               other,\n                               comparison,\n                               series.weld_type),\n                  series.index,\n                  np.dtype(np.bool),\n                  series.name)\n\n\n# the following methods are shortcuts for DataFrame ops to avoid e.g. recomputing index\ndef _series_agg(series, aggregations, index):\n    return Series(weld_agg(series.weld_expr,\n                           series.weld_type,\n                           aggregations),\n                  index,\n                  np.dtype(np.float64))\n\n\ndef _series_array_op(series, other, operation):\n    return Series(weld_array_op(series.weld_expr,\n                                other.weld_expr,\n                                series.weld_type,\n                                operation),\n                  series.index,\n                  series.dtype,\n                  series.name)\n\n\ndef _series_element_wise_op(series, other, operation):\n    return Series(weld_element_wise_op(series.weld_expr,\n                                       series.weld_type,\n                                       other,\n                                       operation),\n                  series.index,\n                  series.dtype,\n                  series.name)\n\n\ndef _series_filter(series, item, index):\n    return Series(weld_filter(series.weld_expr,\n                              series.weld_type,\n                              item.weld_expr),\n                  index,\n                  series.dtype,\n                  series.name)\n\n\ndef _series_slice(series, item, index):\n    return Series(weld_slice(series.weld_expr,\n                             series.weld_type,\n                             item),\n                  index,\n                  series.dtype,\n                  series.name)\n\n\ndef _series_tail(series, index, length, n):\n    return Series(weld_tail(series.weld_expr, length, n),\n                  index,\n                  series.dtype,\n                  series.name)\n\n\ndef _series_iloc(series, item, new_index):\n    return Series(weld_iloc_indices(series.weld_expr,\n                                    series.weld_type,\n                                    item),\n                  new_index,\n                  series.dtype,\n                  series.name)\n\n\ndef _series_iloc_with_missing(series, item, new_index):\n    return Series(weld_iloc_indices_with_missing(series.weld_expr,\n                                                 series.weld_type,\n                                                 item),\n                  new_index,\n                  series.dtype,\n                  series.name)\n\n\ndef _series_from_pandas(series, baloo_index):\n    return Series(series.values,\n                  baloo_index,\n                  series.dtype,\n                  series.name)\n\n\ndef _series_to_pandas(series, pandas_index):\n    return PandasSeries(series.values,\n                        pandas_index,\n                        series.dtype,\n                        series.name)\n'"
baloo/core/strings.py,0,"b'from .series import Series\nfrom .utils import check_type\nfrom ..weld import weld_str_lower, weld_str_upper, weld_str_capitalize, weld_str_get, weld_str_strip, weld_str_slice, \\\n    weld_str_contains, weld_to_numpy_dtype, WeldBit, weld_str_startswith, weld_str_endswith, weld_str_find, WeldLong, \\\n    weld_str_replace, weld_str_split\n\n\nclass StringMethods(object):\n    def __init__(self, data):\n        self._data = check_type(data, Series)\n\n    def lower(self):\n        """"""Convert all characters to lowercase.\n\n        Returns\n        -------\n        Series\n\n        """"""\n        return _series_str_result(self, weld_str_lower)\n\n    def upper(self):\n        """"""Convert all characters to uppercase.\n\n        Returns\n        -------\n        Series\n\n        """"""\n        return _series_str_result(self, weld_str_upper)\n\n    def capitalize(self):\n        """"""Convert first character to uppercase and remainder to lowercase.\n\n        Returns\n        -------\n        Series\n\n        """"""\n        return _series_str_result(self, weld_str_capitalize)\n\n    def get(self, i):\n        """"""Extract i\'th character of each element.\n\n        Parameters\n        ----------\n        i : int\n\n        Returns\n        -------\n        Series\n\n        """"""\n        check_type(i, int)\n\n        return _series_str_result(self, weld_str_get, i=i)\n\n    def strip(self):\n        """"""Strip whitespace from start and end of each element.\n\n        Note it currently only looks for whitespace (ASCII 32), not tabs or EOL.\n\n        Returns\n        -------\n        Series\n\n        """"""\n        return _series_str_result(self, weld_str_strip)\n\n    def slice(self, start=None, stop=None, step=None):\n        """"""Slice substrings from each element.\n\n        Note that negative step is currently not supported.\n\n        Parameters\n        ----------\n        start : int\n        stop : int\n        step : int\n\n        Returns\n        -------\n        Series\n\n        """"""\n        check_type(start, int)\n        check_type(stop, int)\n        check_type(step, int)\n\n        if step is not None and step < 0:\n            raise ValueError(\'Only positive steps are currently supported\')\n\n        return _series_str_result(self, weld_str_slice, start=start, stop=stop, step=step)\n\n    def contains(self, pat):\n        """"""Test if pat is included within elements.\n\n        Parameters\n        ----------\n        pat : str\n\n        Returns\n        -------\n        Series\n\n        """"""\n        check_type(pat, str)\n\n        return _series_bool_result(self, weld_str_contains, pat=pat)\n\n    def startswith(self, pat):\n        """"""Test if elements start with pat.\n\n        Parameters\n        ----------\n        pat : str\n\n        Returns\n        -------\n        Series\n\n        """"""\n        check_type(pat, str)\n\n        return _series_bool_result(self, weld_str_startswith, pat=pat)\n\n    def endswith(self, pat):\n        """"""Test if elements end with pat.\n\n        Parameters\n        ----------\n        pat : str\n\n        Returns\n        -------\n        Series\n\n        """"""\n        check_type(pat, str)\n\n        return _series_bool_result(self, weld_str_endswith, pat=pat)\n\n    def find(self, sub, start=0, end=None):\n        """"""Test if elements contain substring.\n\n        Parameters\n        ----------\n        sub : str\n        start : int, optional\n            Index to start searching from.\n        end : int, optional\n            Index to stop searching from.\n\n        Returns\n        -------\n        Series\n\n        """"""\n        check_type(sub, str)\n        check_type(start, int)\n        check_type(end, int)\n\n        if end is not None and start >= end:\n            raise ValueError(\'End must be greater than start\')\n\n        return Series(weld_str_find(self._data.values, sub, start, end),\n                      self._data.index,\n                      weld_to_numpy_dtype(WeldLong()),\n                      self._data.name)\n\n    # TODO: replace multiple occurrences, not just first\n    def replace(self, pat, rep):\n        """"""Replace first occurrence of pat with rep in each element.\n\n        Parameters\n        ----------\n        pat : str\n        rep : str\n\n        Returns\n        -------\n        Series\n\n        """"""\n        check_type(pat, str)\n        check_type(rep, str)\n\n        return _series_str_result(self, weld_str_replace, pat=pat, rep=rep)\n\n    # TODO: rsplit\n    def split(self, pat, side=\'left\'):\n        """"""Split once each element from the left and select a side to return.\n\n        Note this is unlike pandas split in that it essentially combines the split with a select.\n\n        Parameters\n        ----------\n        pat : str\n        side : {\'left\', \'right\'}\n            Which side of the split to select and return in each element.\n\n        Returns\n        -------\n        Series\n\n        """"""\n        check_type(pat, str)\n        check_type(side, str)\n\n        # don\'t want this made with the object\n        _split_mapping = {\n            \'left\': 0,\n            \'right\': 1\n        }\n\n        if side not in _split_mapping:\n            raise ValueError(\'Can only select left or right side of split\')\n\n        return _series_str_result(self, weld_str_split, pat=pat, side=_split_mapping[side])\n\n\ndef _series_str_result(series, func, **kwargs):\n    return Series(func(series._data.values, **kwargs),\n                  series._data.index,\n                  series._data.dtype,\n                  series._data.name)\n\n\ndef _series_bool_result(series, func, **kwargs):\n    return Series(func(series._data.values, **kwargs),\n                  series._data.index,\n                  weld_to_numpy_dtype(WeldBit()),\n                  series._data.name)\n'"
baloo/core/utils.py,13,"b""import numpy as np\n\nfrom ..weld import WeldObject, weld_count, WeldBit, WeldLong, LazyResult, supported_dtype_chars\n\n\ndef check_type(data, expected_types):\n    if data is not None and not isinstance(data, expected_types):\n        raise TypeError('Expected: {}'.format(str(expected_types)))\n\n    return data\n\n\ndef check_dtype(data):\n    # silently allow and convert bool\n    if data == bool:\n        return np.bool_\n\n    if data is not None and not (isinstance(data, np.dtype) or data.__module__ == np.__name__):\n        raise TypeError('Expected a valid NumPy dtype, received: {}'.format(str(data)))\n\n    return data\n\n\ndef check_inner_types(data, expected_types):\n    if data is not None:\n        for value in data:\n            check_type(value, expected_types)\n\n    return data\n\n\ndef check_str_or_list_str(data):\n    check_type(data, (list, str))\n    if data is not None:\n        check_inner_types(as_list(data), str)\n\n    return data\n\n\ndef check_weld_bit_array(data):\n    return check_type(data.weld_type, WeldBit)\n\n\ndef check_weld_long_array(data):\n    return check_type(data.weld_type, WeldLong)\n\n\ndef infer_dtype(data, arg_dtype):\n    if arg_dtype is not None:\n        if not isinstance(arg_dtype, np.dtype):\n            arg_dtype = np.dtype(arg_dtype)\n\n        return arg_dtype\n    else:\n        if isinstance(data, np.ndarray):\n            return data.dtype\n        elif isinstance(data, WeldObject):\n            # if WeldObject data then arg_dtype must have been passed as argument\n            raise ValueError('Using WeldObject as data requires the dtype as argument')\n        else:\n            raise ValueError('Unsupported data type: {}'.format(str(type(data))))\n\n\ndef infer_length(data):\n    if len(data) == 0:\n        return 0\n    else:\n        for value in data:\n            if isinstance(value, (np.ndarray, list)):\n                return len(value)\n            # Series then\n            elif isinstance(value.values, np.ndarray):\n                return len(value.values)\n\n        return None\n\n\ndef default_index(data):\n    from .indexes import RangeIndex\n\n    if isinstance(data, int):\n        return RangeIndex(data)\n    elif isinstance(data, np.ndarray):\n        return RangeIndex(len(data))\n    elif isinstance(data, WeldObject):\n        # must be WeldObject then\n        return RangeIndex(weld_count(data))\n    elif isinstance(data, LazyResult):\n        return RangeIndex(weld_count(data.values))\n    else:\n        raise ValueError('Unsupported data type: {}'.format(str(type(data))))\n\n\ndef is_scalar(data):\n    return isinstance(data, (int, float, str, bytes, bool))\n\n\ndef _is_int_or_none(value):\n    return value is None or isinstance(value, int)\n\n\ndef _valid_int_slice(slice_):\n    return all([_is_int_or_none(v) for v in [slice_.start, slice_.stop, slice_.step]])\n\n\ndef check_valid_int_slice(slice_):\n    if not _valid_int_slice(slice_):\n        raise ValueError('Can currently only slice with integers')\n\n\ndef shorten_data(data):\n    if not isinstance(data, np.ndarray):\n        raise TypeError('Cannot shorten unevaluated data. First call evaluate()')\n\n    if len(data) > 50:\n        return list(np.concatenate([data[:20], np.array(['...']), data[-20:]]))\n    else:\n        return data\n\n\ndef as_list(data):\n    if isinstance(data, list):\n        return data\n    else:\n        return [data]\n\n\ndef replace_if_none(value, default):\n    return default if value is None else value\n\n\ndef replace_slice_defaults(slice_, default_start, default_stop, default_step):\n    start = replace_if_none(slice_.start, default_start)\n    stop = replace_if_none(slice_.stop, default_stop)\n    step = replace_if_none(slice_.step, default_step)\n\n    return slice(start, stop, step)\n\n\ndef convert_to_numpy(data):\n    data = np.array(data)\n    if data.dtype.char not in supported_dtype_chars:\n        raise TypeError('dtype {} is not supported'.format(data.dtype))\n\n    return data\n\n\ndef same_index(index1, index2):\n    if not isinstance(index1, type(index2)):\n        return False\n    elif index1._gather_names() != index2._gather_names():\n        return False\n    elif index1._gather_weld_types() != index2._gather_weld_types():\n        return False\n    else:\n        # should be Indexes\n        data1 = index1._gather_data().values()\n        data2 = index2._gather_data().values()\n\n        for d1, d2 in zip(data1, data2):\n            if not isinstance(d1.values, type(d2.values)):\n                return False\n            elif isinstance(d1.values, np.ndarray):\n                if not np.array_equal(d1.values, d2.values):\n                    return False\n            # else they're WeldObjects so can only assume they're the same\n\n    return True\n"""
baloo/functions/__init__.py,0,"b'from .raw import *\nfrom .unary import exp, log, sqrt, sin, cos, tan, asin, acos, atan, sinh, cosh, tanh, erf\nfrom .utils import load_cudf, raw\n'"
baloo/functions/raw.py,1,"b'import numpy as np\n\nfrom .utils import raw\n\n\n@raw\ndef sort(array, **kwargs):\n    return np.sort(array, **kwargs)\n'"
baloo/functions/unary.py,0,"b'from ..weld import create_weld_object, WeldDouble, WeldFloat\n\n\ndef _weld_unary(array, weld_type, operation):\n    """"""Apply operation on each element in the array.\n\n    As mentioned by Weld, the operations follow the behavior of the equivalent C functions from math.h\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Data\n    weld_type : WeldType\n        Of the data\n    operation : {\'exp\', \'log\', \'sqrt\', \'sin\', \'cos\', \'tan\', \'asin\', \'acos\', \'atan\', \'sinh\', \'cosh\', \'tanh\', \'erf\'}\n        Which unary operation to apply.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    if weld_type not in {WeldFloat(), WeldDouble()}:\n        raise TypeError(\'Unary operation supported only on scalar f32 or f64\')\n\n    obj_id, weld_obj = create_weld_object(array)\n    weld_template = \'map({array}, |e: {type}| {op}(e))\'\n    weld_obj.weld_code = weld_template.format(array=obj_id, type=weld_type, op=operation)\n\n    return weld_obj\n\n\ndef exp(array, weld_type):\n    return _weld_unary(array, weld_type, \'exp\')\n\n\ndef log(array, weld_type):\n    return _weld_unary(array, weld_type, \'log\')\n\n\ndef sqrt(array, weld_type):\n    return _weld_unary(array, weld_type, \'sqrt\')\n\n\ndef sin(array, weld_type):\n    return _weld_unary(array, weld_type, \'sin\')\n\n\ndef cos(array, weld_type):\n    return _weld_unary(array, weld_type, \'cos\')\n\n\ndef tan(array, weld_type):\n    return _weld_unary(array, weld_type, \'tan\')\n\n\ndef asin(array, weld_type):\n    return _weld_unary(array, weld_type, \'asin\')\n\n\ndef acos(array, weld_type):\n    return _weld_unary(array, weld_type, \'acos\')\n\n\ndef atan(array, weld_type):\n    return _weld_unary(array, weld_type, \'atan\')\n\n\ndef sinh(array, weld_type):\n    return _weld_unary(array, weld_type, \'sinh\')\n\n\ndef cosh(array, weld_type):\n    return _weld_unary(array, weld_type, \'cosh\')\n\n\ndef tanh(array, weld_type):\n    return _weld_unary(array, weld_type, \'tanh\')\n\n\ndef erf(array, weld_type):\n    return _weld_unary(array, weld_type, \'erf\')\n'"
baloo/functions/utils.py,0,"b'from ctypes import CDLL\nfrom functools import wraps\nfrom os import RTLD_GLOBAL\n\nfrom ..weld import WeldObject\n\n\ndef load_cudf(path_to_so):\n    """"""Dynamically load a C UDF.\n\n    Parameters\n    ----------\n    path_to_so : str\n        Absolute path to so.\n\n    Returns\n    -------\n\n    """"""\n    CDLL(path_to_so, mode=RTLD_GLOBAL)\n\n\ndef raw(func, **func_args):\n    """"""Decorator for eager functions checking input array\n    and stripping away the weld_type.\n\n    Stripping the weld_type is required to keep the same code in Series.apply and because\n    Numpy functions don\'t (all) have kwargs. Passing weld_type to NumPy functions is unexpected\n    and raises ValueError.\n\n    Parameters\n    ----------\n    func : function\n        Function to execute eagerly over raw data.\n    func_args : kwargs\n        Arguments to pass to func, if any.\n\n    Returns\n    -------\n    function\n\n    """"""\n    if len(func_args) == 0:\n        @wraps(func)\n        def wrapper(array, **kwargs):\n            if isinstance(array, WeldObject):\n                raise TypeError(\'Can only perform operation on raw data\')\n            # need to not pass weld_type to whatever function\n            if \'weld_type\' in kwargs:\n                del kwargs[\'weld_type\']\n            return func(array, **kwargs)\n        return wrapper\n    else:\n        # here kwargs is only kept s.t. Series can still pass the weld_type\n        @wraps(func)\n        def wrapper(array, **kwargs):\n            if isinstance(array, WeldObject):\n                raise TypeError(\'Can only perform operation on raw data\')\n            return func(array, **func_args)\n        return wrapper\n'"
baloo/io/__init__.py,0,b'from .csv import *\n'
baloo/io/csv.py,0,"b'from pandas import read_csv as pd_read_csv\n\nfrom ..core import DataFrame\n\n\ndef read_csv(filepath, sep=\',\', header=\'infer\', names=None, usecols=None, dtype=None, converters=None,\n             skiprows=None, nrows=None):\n    """"""Read CSV into DataFrame.\n\n    Eager implementation using pandas, i.e. entire file is read at this point. Only common/relevant parameters\n    available at the moment; for full list, could use pandas directly and then convert to baloo.\n\n    Parameters\n    ----------\n    filepath : str\n    sep : str, optional\n        Separator used between values.\n    header : \'infer\' or None, optional\n        Whether to infer the column names from the first row or not.\n    names : list of str, optional\n        List of column names to use. Overrides inferred header.\n    usecols : list of (int or str), optional\n        Which columns to parse.\n    dtype : dict, optional\n        Dict of column -> type to parse as.\n    converters : dict, optional\n        Dict of functions for converting values in certain columns.\n    skiprows : int, optional\n        Number of lines to skip at start of file.\n    nrows : int, optional\n        Number of rows to read.\n\n    Returns\n    -------\n    DataFrame\n\n    See Also\n    --------\n    pandas.read_csv : https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n\n    """"""\n    pd_df = pd_read_csv(filepath,\n                        sep=sep,\n                        header=header,\n                        names=names,\n                        usecols=usecols,\n                        dtype=dtype,\n                        converters=converters,\n                        skiprows=skiprows,\n                        nrows=nrows)\n\n    return DataFrame.from_pandas(pd_df)\n\n\n# TODO: should avoid going to Pandas\ndef to_csv(df, filepath, sep=\',\', header=True, index=True):\n    """"""Save DataFrame as csv.\n\n    Note data is expected to be evaluated.\n\n    Currently delegates to Pandas.\n\n    Parameters\n    ----------\n    df : DataFrame\n    filepath : str\n    sep : str, optional\n        Separator used between values.\n    header : bool, optional\n        Whether to save the header.\n    index : bool, optional\n        Whether to save the index columns.\n\n    Returns\n    -------\n    None\n\n    See Also\n    --------\n    pandas.DataFrame.to_csv : https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html\n\n    """"""\n    df.to_pandas().to_csv(filepath,\n                          sep=sep,\n                          header=header,\n                          index=index)\n'"
baloo/io/parsers.py,0,"b'from .csv import read_csv\n\n# TODO: could implement more io by just delegating to pandas, but do we really want that (now)?\n# TODO: parsers could be lazy, i.e. only read header and metadata, however this only defers parsing to later\n'"
baloo/weld/__init__.py,0,b'from .cache import Cache\nfrom .convertors import *\nfrom .lazy_result import *\nfrom .pyweld import *\nfrom .weld_aggs import *\nfrom .weld_group import *\nfrom .weld_joins import *\nfrom .weld_ops import *\nfrom .weld_str import *\nfrom .weld_utils import *\n\n# Weld types can be inferred in many places however were included for performance reasons.\n# TODO: perhaps revisit this choice\n# TODO: perhaps find a faster string (Weld code) building/formatting method?\n'
baloo/weld/cache.py,2,"b'import abc\n\n\n# TODO 1: implement a flush-like method which clears both this cache and the values it added to WeldObject._registry?\n# TODO garbage collection should then kick in and remove intermediate results from memory;\n# TODO though probably need to implement `del df/sr/etc` to make this possible\n# TODO 2: would be nice if there could be a \'cache()\' operator which is detected in weld_code at evaluate;\n# TODO though at the Python side (not weld/rust) since caching violates the Weld stateless principle...\n# TODO 3: re-using the WeldObject.dependencies could be more natural instead of fake inputs\nclass Cache(object):\n    """"""Cache for intermediate results. Acts as a singleton.\n\n    The idea is to track weld_input_ids -> intermediate results for intermediate data which only gets computed\n    upon evaluation. For this to work, we treat intermediate results as new \'fake\' inputs to Weld. This means that\n    intermediate results can now exist within WeldObject.context as lazy inputs/data represented with a placeholder.\n\n    For example, a context could be: {\'_inp0\': np.array([1, 2, 3]), \'_inp1\': \'inter_result_join\'}.\n\n    Typically, the cache shall be used to cache an entire DataFrame which would actually be tuples of columns.\n    To be able to lazily encode this into future WeldObjects which would hence depend on it,\n    we either need to be able to encode a tuple, or provide further functionality in the Cache. Second option is\n    chosen by having the _FakeWeldInputs contain a dependency on another intermediate results, here the entire\n    DataFrame as a tuple of columns.\n\n    The placeholder is merely used to be informative to the user. On evaluation, the cache is checked for\n    intermediate results and if found, the context is replaced with the actual, i.e. raw, data. If it\'s the first\n    time the intermediate result is required, it is evaluated and replaced in the cache such that future uses\n    can retrieve the already computed data.\n\n    For example, the context could now be: {\'_inp0\': np.array([1, 2, 3]), \'_inp1\': np.array([4., 5., 6.])}\n\n    With a now valid context, the LazyResult can now be evaluated.\n\n    Lastly, the context of the WeldObject is reverted to its original state to avoid polluting the context\n    unnecessarily. If not doing this, this and future dependencies on the WeldObject will have outdated data\n    in the context (while maintaining an unnecessary reference to the data, working against the garbage collector\n    ~ future work)\n\n    Currently contains a few sanity checks, aka asserts. Could remove later.\n\n    tl;dr How to use:\n\n    1. Cache.cache_intermediate_result(LazyResult) => returns placeholder; cache this LazyResult.\n        Internally, add placeholder -> LazyResult to _intermediate_results.\n    2. Cache.create_fake_array_input(placeholder, index=Optional) => returns a _FakeWeldInput.\n    3. WeldObject().update(_FakeWeldInput) => returns weld id for this fake input as _inpX (raw data);\n        _FakeWeldInput acts as a regular input to any further WeldObjects. Through update, the\n        input internally becomes registered in WeldObject._registry as _FakeWeldInput -> _inpX\n    4. Cache.cache_fake_input(id, _FakeWeldInput); the _FakeWeldInput (corresponding to a _inpX) is now cached\n        and can be seen by LazyResult.evaluate(). Internally, add _inpX -> _FakeWeldInput to _cache. On evaluate,\n        LazyResult replaced the placeholder in the WeldObject.context with the actual data, evaluating if necessary.\n    5. Use the weld id in weld_code as desired.\n\n    """"""\n    _counter = 0\n    # actual intermediate results, weld_input_name -> LazyResult\n    _intermediate_results = {}\n    # the fake inputs used during evaluation, weld_input_name -> FakeWeldInput\n    _cache = {}\n\n    @staticmethod\n    def _generate_placeholder(readable_text=None):\n        """"""Generate a placeholder name to use while updating WeldObject.\n\n        Parameters\n        ----------\n        readable_text : str, optional\n            Appended to the name for a more understandable placeholder.\n\n        Returns\n        -------\n        str\n            Placeholder.\n\n        """"""\n        name = \'_interm_\' + str(Cache._counter)\n        Cache._counter += 1\n\n        if readable_text is not None:\n            assert isinstance(readable_text, str)\n            name += \'_\' + readable_text\n\n        return name\n\n    # returns the evaluated intermediate result\n    @classmethod\n    def _get_intermediate_result(cls, weld_input_name):\n        from .lazy_result import LazyResult\n\n        intermediate_result = Cache._intermediate_results[weld_input_name]\n        # if not yet evaluated, do so and cache the result\n        if isinstance(intermediate_result, LazyResult):\n            intermediate_result = intermediate_result.evaluate()\n            Cache._intermediate_results[weld_input_name] = intermediate_result\n\n        return intermediate_result\n\n    @classmethod\n    def contains(cls, item):\n        assert isinstance(item, str)\n\n        return item in cls._cache\n\n    @classmethod\n    def cache_intermediate_result(cls, result, readable_name=None):\n        """"""Add result to the cached data.\n\n        Parameters\n        ----------\n        result : LazyResult\n            Data to cache.\n        readable_name : str\n            Will be used when generating a name for this intermediate result.\n\n        Returns\n        -------\n        str\n            A generated placeholder name uniquely identifying this intermediate result.\n\n        """"""\n        from .lazy_result import LazyResult\n        assert isinstance(result, LazyResult)\n\n        dependency_name = Cache._generate_placeholder(readable_name)\n        Cache._intermediate_results[dependency_name] = result\n\n        return dependency_name\n\n    @classmethod\n    def create_fake_array_input(cls, dependency, readable_name, index=None):\n        """"""Create fake Weld inputs to be used in future WeldObjects.\n\n        Parameters\n        ----------\n        dependency : str\n            The Weld input name of the actual intermediate result, obtained from cache_intermediate_result.\n        readable_name : str\n            User-friendly string that will be used to generate a unique placeholder name. This placeholder\n            will be seen in the WeldObject.context.\n        index : tuple, optional\n            If passed, it means the intermediate result dependency is in fact a struct/tuple, so this fake input\n            shall be able to select the required array from the tuple. Note that it can work through multiple levels,\n            i.e. passing (1, 0) would essentially select 2 from (1, (2, 3)).\n\n        Returns\n        -------\n        FakeWeldInput\n            An instance representing the fake Weld input to be used when generating the WeldObjects relying on it.\n\n        """"""\n        assert dependency in Cache._intermediate_results\n        assert isinstance(readable_name, str)\n\n        name = Cache._generate_placeholder(readable_name)\n\n        if index is None:\n            fake_weld_input = _FakeArray(dependency, name)\n        else:\n            assert isinstance(index, tuple)\n            fake_weld_input = _FakeStructMember(dependency, index, name)\n\n        return fake_weld_input\n\n    @classmethod\n    def cache_fake_input(cls, weld_input_id, fake_weld_input):\n        """"""Cache the fake Weld input to be seen by LazyResult.evaluate\n\n        Parameters\n        ----------\n        weld_input_id : str\n            Generated when registering the fake_weld_input in WeldObject.update.\n        fake_weld_input : _FakeWeldInput\n            The fake Weld input previously generated by create_fake_array_input.\n\n        """"""\n        assert isinstance(weld_input_id, str)\n        assert isinstance(fake_weld_input, _FakeWeldInput)\n\n        Cache._cache[weld_input_id] = fake_weld_input\n\n    @classmethod\n    def get(cls, key):\n        """"""Retrieve a fake Weld input. Evaluate its intermediate result dependency if not yet done.\n\n        Parameters\n        ----------\n        key : str\n            Weld input name previously obtained through create_fake_array_input.\n\n        Returns\n        -------\n        numpy.ndarray or tuple\n            The corresponding data.\n\n        """"""\n        assert isinstance(key, str)\n\n        data = cls._cache[key]\n        if isinstance(data, _FakeWeldInput):\n            data = data.retrieve()\n\n        cls._cache[key] = data\n\n        return data\n\n\nclass _FakeWeldInput(abc.ABC):\n    def __init__(self, dependency, readable_name):\n        assert isinstance(dependency, str)\n        assert isinstance(readable_name, str)\n\n        self.dependency = dependency\n        self.name = readable_name\n\n    def __repr__(self):\n        return \'_FakeWeldInput(dependency={}, name={})\'.format(self.dependency, self.name)\n\n    # the str representation is added to WeldObject._registry\n    def __str__(self):\n        return self.name\n\n    def _evaluate_dependency(self):\n        return Cache._get_intermediate_result(self.dependency)\n\n    @abc.abstractmethod\n    def retrieve(self):\n        raise NotImplementedError\n\n\nclass _FakeArray(_FakeWeldInput):\n    def __init__(self, dependency, readable_name):\n        super(_FakeArray, self).__init__(dependency, readable_name)\n\n    def retrieve(self):\n        return self._evaluate_dependency()\n\n\nclass _FakeStructMember(_FakeWeldInput):\n    def __init__(self, dependency, index, readable_name):\n        assert isinstance(index, tuple)\n\n        self.index = index\n\n        super(_FakeStructMember, self).__init__(dependency, readable_name)\n\n    def __repr__(self):\n        return \'_FakeStructMember(dependency={}, index={}, name={})\'.format(self.dependency, self.index, self.name)\n\n    def retrieve(self):\n        result = self._evaluate_dependency()\n        for i in self.index:\n            result = result[i]\n\n        return result\n'"
baloo/weld/lazy_result.py,0,"b'from .cache import Cache\nfrom .convertors import numpy_to_weld_type\nfrom .convertors.utils import to_weld_vec\nfrom .pyweld.types import WeldStruct, WeldVec, WeldLong, WeldDouble\nfrom .pyweld.weldobject import WeldObject\nfrom .weld_aggs import weld_aggregate, weld_count\nfrom .weld_utils import weld_cast_array\n\n\nclass LazyResult(object):\n    """"""Wrapper class around a yet un-evaluated Weld result.\n\n    Attributes\n    ----------\n    weld_expr : WeldObject or numpy.ndarray\n        Expression that needs to be evaluated.\n    weld_type : WeldType\n        Type of the output.\n    ndim : int\n        Dimensionality of the output.\n\n    """"""\n    _cache = Cache()\n\n    def __init__(self, weld_expr, weld_type, ndim):\n        self.weld_expr = weld_expr\n        self.weld_type = weld_type\n        self.ndim = ndim\n\n    def __repr__(self):\n        return ""{}(weld_type={}, ndim={})"".format(self.__class__.__name__,\n                                                  self.weld_type,\n                                                  self.ndim)\n\n    def __str__(self):\n        return str(self.weld_expr)\n\n    @property\n    def values(self):\n        """"""The internal data representation.\n\n        Returns\n        -------\n        numpy.ndarray or WeldObject\n            The internal data representation.\n\n        """"""\n        return self.weld_expr\n\n    def is_raw(self):\n        return not isinstance(self.weld_expr, WeldObject)\n\n    def evaluate(self, verbose=False, decode=True, passes=None, num_threads=1,\n                 apply_experimental_transforms=True):\n        """"""Evaluate the stored expression.\n\n        Parameters\n        ----------\n        verbose : bool, optional\n            Whether to print output for each Weld compilation step.\n        decode : bool, optional\n            Whether to decode the result\n        passes : list, optional\n            Which Weld optimization passes to apply\n        num_threads : int, optional\n            On how many threads to run Weld\n        apply_experimental_transforms : bool\n            Whether to apply the experimental Weld transforms.\n\n        Returns\n        -------\n        numpy.ndarray\n            Output of the evaluated expression.\n\n        """"""\n        if isinstance(self.weld_expr, WeldObject):\n            old_context = dict(self.weld_expr.context)\n\n            for key in self.weld_expr.context.keys():\n                if LazyResult._cache.contains(key):\n                    self.weld_expr.context[key] = LazyResult._cache.get(key)\n\n            evaluated = self.weld_expr.evaluate(to_weld_vec(self.weld_type,\n                                                            self.ndim),\n                                                verbose,\n                                                decode,\n                                                passes,\n                                                num_threads,\n                                                apply_experimental_transforms)\n\n            self.weld_expr.context = old_context\n\n            return evaluated\n        else:\n            return self.weld_expr\n\n\n# TODO: not really happy having functionality here; maybe have e.g. LazyArray(LazyArrayResult) adding the functionality?\nclass LazyArrayResult(LazyResult):\n    def __init__(self, weld_expr, weld_type):\n        super(LazyArrayResult, self).__init__(weld_expr, weld_type, 1)\n\n    @property\n    def empty(self):\n        if self.is_raw():\n            return len(self.weld_expr) == 0\n        else:\n            return False\n\n    def _aggregate(self, operation):\n        return LazyScalarResult(weld_aggregate(self.weld_expr,\n                                               self.weld_type,\n                                               operation),\n                                self.weld_type)\n\n    def min(self):\n        """"""Returns the minimum value.\n\n        Returns\n        -------\n        LazyScalarResult\n            The minimum value.\n\n        """"""\n        return self._aggregate(\'min\')\n\n    def max(self):\n        """"""Returns the maximum value.\n\n        Returns\n        -------\n        LazyScalarResult\n            The maximum value.\n\n        """"""\n        return self._aggregate(\'max\')\n\n    def _lazy_len(self):\n        return LazyLongResult(weld_count(self.weld_expr))\n\n    def __len__(self):\n        """"""Eagerly get the length.\n\n        Note that if the length is unknown (such as for a WeldObject stop),\n        it will be eagerly computed by evaluating the data!\n\n        Returns\n        -------\n        int\n            Length.\n\n        """"""\n        if self._length is None:\n            self._length = self._lazy_len().evaluate()\n\n        return self._length\n\n    def _astype(self, dtype):\n        return weld_cast_array(self.values,\n                               self.weld_type,\n                               numpy_to_weld_type(dtype))\n\n\n# could make all subclasses but seems rather unnecessary atm\nclass LazyScalarResult(LazyResult):\n    def __init__(self, weld_expr, weld_type):\n        super(LazyScalarResult, self).__init__(weld_expr, weld_type, 0)\n\n\nclass LazyLongResult(LazyScalarResult):\n    def __init__(self, weld_expr):\n        super(LazyScalarResult, self).__init__(weld_expr, WeldLong(), 0)\n\n\nclass LazyDoubleResult(LazyScalarResult):\n    def __init__(self, weld_expr):\n        super(LazyScalarResult, self).__init__(weld_expr, WeldDouble(), 0)\n\n\nclass LazyStructResult(LazyResult):\n    # weld_types should be a list of the Weld types in the struct\n    def __init__(self, weld_expr, weld_types):\n        super(LazyStructResult, self).__init__(weld_expr, WeldStruct(weld_types), 0)\n\n\nclass LazyStructOfVecResult(LazyStructResult):\n    # weld_types should be a list of the Weld types in the struct\n    def __init__(self, weld_expr, weld_types):\n        weld_vec_types = [WeldVec(weld_type) for weld_type in weld_types]\n\n        super(LazyStructOfVecResult, self).__init__(weld_expr, weld_vec_types)\n'"
baloo/weld/weld_aggs.py,0,"b'from .weld_utils import create_weld_object, get_weld_obj_id\n\n# TODO: don\'t cast to f64 if data is already f64\n\n\n_weld_count_code = \'len({array})\'\n\n\ndef weld_count(array):\n    """"""Returns the length of the array.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input array.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = _weld_count_code\n\n    weld_obj.weld_code = weld_template.format(array=obj_id)\n\n    return weld_obj\n\n\n_weld_aggregate_code = """"""result(\n    for(\n        {array},\n        merger[{type}, {operation}],\n        |b: merger[{type}, {operation}], i: i64, e: {type}| \n            merge(b, e)\n    )\n)""""""\n\n\n_weld_aggregate_code_f64 = """"""result(\n    for(\n        {array},\n        merger[f64, {operation}],\n        |b: merger[f64, {operation}], i: i64, e: {type}| \n            merge(b, f64(e))\n    )\n)""""""\n\n\ndef weld_aggregate(array, weld_type, operation):\n    """"""Returns operation on the elements in the array.\n\n    Arguments\n    ---------\n    array : WeldObject or numpy.ndarray\n        Input array.\n    weld_type : WeldType\n        Weld type of each element in the input array.\n    operation : {\'+\', \'*\', \'min\', \'max\'}\n        Operation to apply.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = _weld_aggregate_code\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type,\n                                              operation=operation)\n\n    return weld_obj\n\n\n_weld_mean_code = \'f64({sum}) / f64(len({array}))\'\n\n\ndef weld_mean(array, weld_type):\n    """"""Returns the mean of the array.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input array.\n    weld_type : WeldType\n        Type of each element in the input array.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    weld_obj_sum = weld_aggregate(array, weld_type, \'+\')\n\n    obj_id, weld_obj = create_weld_object(array)\n    weld_obj_sum_id = get_weld_obj_id(weld_obj, weld_obj_sum)\n\n    weld_template = _weld_mean_code\n\n    weld_obj.weld_code = weld_template.format(sum=weld_obj_sum_id,\n                                              array=obj_id)\n\n    return weld_obj\n\n\n_weld_variance_code = """"""result(\n    for(\n        {array},\n        merger[f64, +],\n        |b: merger[f64, +], i: i64, n: {type}|\n             merge(b, pow(f64(n) - {mean}, 2.0))\n    )\n) / f64(len({array}) - 1L)\n""""""\n\n\ndef weld_variance(array, weld_type):\n    """"""Returns the variance of the array.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input array.\n    weld_type : WeldType\n        Type of each element in the input array.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    weld_obj_mean = weld_mean(array, weld_type)\n\n    obj_id, weld_obj = create_weld_object(array)\n    weld_obj_mean_id = get_weld_obj_id(weld_obj, weld_obj_mean)\n\n    weld_template = _weld_variance_code\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type,\n                                              mean=weld_obj_mean_id)\n\n    return weld_obj\n\n\n_weld_std_code = \'sqrt({var})\'\n\n\ndef weld_standard_deviation(array, weld_type):\n    """"""Returns the *sample* standard deviation of the array.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input array.\n    weld_type : WeldType\n        Type of each element in the input array.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    weld_obj_var = weld_variance(array, weld_type)\n\n    obj_id, weld_obj = create_weld_object(weld_obj_var)\n    weld_obj_var_id = get_weld_obj_id(weld_obj, weld_obj_var)\n\n    weld_template = _weld_std_code\n\n    weld_obj.weld_code = weld_template.format(var=weld_obj_var_id)\n\n    return weld_obj\n\n\n# full dependencies of each aggregation\n_agg_dependencies = {\n    \'min\': set(),\n    \'max\': set(),\n    \'count\': set(),\n    \'sum\': set(),\n    \'prod\': set(),\n    \'mean\': {\'sum\'},\n    \'var\': {\'sum\', \'mean\'},\n    \'std\': {\'sum\', \'mean\', \'var\'}\n}\n\n# to order the aggregations; lower means it comes first\n_agg_priorities = {\n    \'min\': 1,\n    \'max\': 1,\n    \'count\': 1,\n    \'sum\': 1,\n    \'prod\': 1,\n    \'mean\': 2,\n    \'var\': 3,\n    \'std\': 4\n}\n\n_agg_code = {\n    \'min\': _weld_aggregate_code_f64.replace(\'{operation}\', \'min\'),\n    \'max\': _weld_aggregate_code_f64.replace(\'{operation}\', \'max\'),\n    \'count\': \'f64({})\'.format(_weld_count_code),\n    \'sum\': _weld_aggregate_code_f64.replace(\'{operation}\', \'+\'),\n    \'prod\': _weld_aggregate_code_f64.replace(\'{operation}\', \'*\'),\n    \'mean\': _weld_mean_code.replace(\'{sum}\', \'agg_sum\'),\n    \'var\': _weld_variance_code.replace(\'{mean}\', \'agg_mean\'),\n    \'std\': _weld_std_code.replace(\'{var}\', \'agg_var\')\n}\n\n\n# not using the methods above because we don\'t want duplicate code chunks;\n# for example, asking for sum and mean would make 2 weldobjects both computing the sum\n# (+ 3rd computing the mean and using one of the sum objects);\n# this method avoids that\ndef weld_agg(array, weld_type, aggregations):\n    """"""Multiple aggregations, optimized.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input array.\n    weld_type : WeldType\n        Type of each element in the input array.\n    aggregations : list of str\n        Which aggregations to compute.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    from functools import reduce\n\n    obj_id, weld_obj = create_weld_object(array)\n\n    # find which aggregation computations are actually needed\n    to_compute = reduce(lambda x, y: x | y, ({agg} | _agg_dependencies[agg] for agg in aggregations))\n    # get priorities and sort in the proper order of computation\n    to_compute = sorted(((agg, _agg_priorities[agg]) for agg in to_compute), key=lambda x: x[1])\n    # remove the priorities\n    to_compute = (agg_pair[0] for agg_pair in to_compute)\n    aggs = \'\\n\'.join((\'let agg_{} = {};\'.format(agg, _agg_code[agg]) for agg in to_compute))\n\n    # these are the aggregations requested\n    merges = \'\\n\'.join((\'let res = merge(res, {});\'.format(\'agg_{}\'.format(agg)) for agg in aggregations))\n    mergers = """"""let res = appender[f64];\n{merges}\nresult(res)\n""""""\n    mergers = mergers.format(merges=merges)\n\n    weld_template = \'{}\\n{}\'.format(aggs, mergers)\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type)\n\n    return weld_obj\n'"
baloo/weld/weld_group.py,0,"b'from .weld_utils import weld_arrays_to_vec_of_struct, create_weld_object, struct_of\n\n\ndef weld_groupby_aggregate_dictmerger(arrays, weld_types, by_indices, operation):\n    """"""Groups by the columns in by.\n\n    Parameters\n    ----------\n    arrays : list of (numpy.ndarray or WeldObject)\n        Entire DataFrame data.\n    weld_types : list of WeldType\n        Corresponding to data.\n    by_indices : list of int\n        Indices of which arrays to group by.\n    operation : {\'+\', \'*\', \'min\', \'max\'}\n        Aggregation.\n\n    Returns\n    -------\n    WeldObject\n        Representation of the computation.\n\n    """"""\n    weld_struct = weld_arrays_to_vec_of_struct(arrays, weld_types)\n\n    obj_id, weld_obj = create_weld_object(weld_struct)\n\n    all_indices = list(range(len(arrays)))\n    column_indices = list(filter(lambda x: x not in by_indices, all_indices))\n    by_weld_types = [weld_types[i] for i in by_indices]\n    column_weld_types = [weld_types[i] for i in column_indices]\n\n    by_types = struct_of(\'{e}\', by_weld_types)\n    column_types = struct_of(\'{e}\', column_weld_types)\n    all_types = struct_of(\'{e}\', weld_types)\n    by_select = struct_of(\'e.${e}\', by_indices)\n    column_select = struct_of(\'e.${e}\', column_indices)\n    res = \'{{{}}}\'.format(\', \'.join([\'e.$0.${}\'.format(i) for i in range(len(by_weld_types))] +\n                                    [\'e.$1.${}\'.format(i) for i in range(len(column_weld_types))]))\n\n    weld_template = """"""map(\n    tovec(\n        result(\n            for(\n                {arrays},\n                dictmerger[{by_types}, {column_types}, {operation}],\n                |b: dictmerger[{by_types}, {column_types}, {operation}], i: i64, e: {all_types}|\n                    merge(b, {{{by_select}, {column_select}}})\n            )\n        )\n    ),\n    |e: {{{by_types}, {column_types}}}|\n        {res}\n)""""""\n\n    weld_obj.weld_code = weld_template.format(arrays=obj_id,\n                                              by_types=by_types,\n                                              column_types=column_types,\n                                              all_types=all_types,\n                                              by_select=by_select,\n                                              column_select=column_select,\n                                              operation=operation,\n                                              res=res)\n\n    return by_weld_types + column_weld_types, weld_obj\n\n\ndef weld_groupby(arrays, weld_types, by_indices):\n    """"""Groups by the columns in by.\n\n    Parameters\n    ----------\n    arrays : list of (numpy.ndarray or WeldObject)\n        Entire DataFrame data.\n    weld_types : list of WeldType\n        Corresponding to data.\n    by_indices : list of int\n        Indices of which arrays to group by.\n\n    Returns\n    -------\n    WeldObject\n        Representation of the computation.\n\n    """"""\n    weld_struct = weld_arrays_to_vec_of_struct(arrays, weld_types)\n\n    obj_id, weld_obj = create_weld_object(weld_struct)\n\n    all_indices = list(range(len(arrays)))\n    column_indices = list(filter(lambda x: x not in by_indices, all_indices))\n    by_weld_types = [weld_types[i] for i in by_indices]\n    column_weld_types = [weld_types[i] for i in column_indices]\n\n    by_types = struct_of(\'{e}\', by_weld_types)\n    column_types = struct_of(\'{e}\', column_weld_types)\n    all_types = struct_of(\'{e}\', weld_types)\n    by_select = struct_of(\'e.${e}\', by_indices)\n    column_select = struct_of(\'e.${e}\', column_indices)\n\n    weld_template = """"""tovec(\n    result(\n        for(\n            {arrays},\n            groupmerger[{by_types}, {column_types}],\n            |b: groupmerger[{by_types}, {column_types}], i: i64, e: {all_types}|\n                merge(b, {{{by_select}, {column_select}}})\n        )\n    )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(arrays=obj_id,\n                                              by_types=by_types,\n                                              column_types=column_types,\n                                              all_types=all_types,\n                                              by_select=by_select,\n                                              column_select=column_select)\n\n    return weld_obj\n\n\n_dictmerger_ops = {\'+\', \'*\', \'min\', \'max\'}\n\n\n# all _assemble_aggregation_* end with let group = {<scalars>};\ndef _assemble_aggregation_simple(column_weld_types, aggregation):\n    template = """"""let sums = for(\n                        e.$1,\n                        {mergers},\n                        |c: {mergers}, j: i64, f: {column_types}|\n                            {merger_ops}\n                    );\n                    let group = {sums_res};""""""\n    mergers_template = \'merger[{e}, {aggr}]\'.replace(\'{aggr}\', aggregation, 1)\n    mergers = struct_of(mergers_template, column_weld_types)\n    merger_ops = struct_of(\'merge(c.${i}, f.${i})\', column_weld_types)\n    sums_res = struct_of(\'result(sums.${i})\', column_weld_types)\n\n    return template.replace(\'mergers\', mergers, 2) \\\n        .replace(\'merger_ops\', merger_ops, 1) \\\n        .replace(\'sums_res\', sums_res, 1)\n\n\ndef _assemble_aggregation_size(column_weld_types):\n    template = """"""let group = {lengths};""""""\n    lengths = struct_of(\'len(e.$1)\', column_weld_types)\n\n    return template.replace(\'lengths\', lengths, 1)\n\n\ndef _assemble_aggregation_mean(column_weld_types, new_column_weld_types):\n    template = """"""sums\n                    let length = len(e.$1);\n                    let group = {means_res};""""""\n    sums = _assemble_aggregation(\'+\', column_weld_types, new_column_weld_types)\n    means_res = struct_of(\'f64(group.${i}) / f64(length)\', column_weld_types)\n\n    return template.replace(\'sums\', sums, 2) \\\n        .replace(\'means_res\', means_res, 1)\n\n\ndef _assemble_aggregation_var(column_weld_types, new_column_weld_types):\n    template = """"""means\n                    let sqdevs = for(\n                        e.$1,\n                        {mergers},\n                        |c: {mergers}, j: i64, f: {column_types}|\n                            {merger_ops}\n                    );\n                    let group = {sqdevs_res};""""""\n    means = _assemble_aggregation(\'mean\', column_weld_types, new_column_weld_types)\n    mergers = struct_of(\'merger[{e}, +]\', new_column_weld_types)\n    merger_ops = struct_of(\'merge(c.${i}, pow(f64(f.${i}) - group.${i}, 2.0))\', column_weld_types)\n    sqdevs_res = struct_of(\'result(sqdevs.${i})\', column_weld_types)\n\n    return template.replace(\'means\', means, 1) \\\n        .replace(\'mergers\', mergers, 2) \\\n        .replace(\'merger_ops\', merger_ops, 1) \\\n        .replace(\'sqdevs_res\', sqdevs_res, 1)\n\n\ndef _assemble_aggregation_std(column_weld_types, new_column_weld_types):\n    template = """"""vars\n                    let group = {vars_res};""""""\n    vars_ = _assemble_aggregation(\'var\', column_weld_types, new_column_weld_types)\n    vars_res = struct_of(\'sqrt(group.${i})\', column_weld_types)\n\n    return template.replace(\'vars\', vars_, 1)\\\n        .replace(\'vars_res\', vars_res, 1)\n\n\n# TODO: this could be a dict if all functions accepted the same params\ndef _assemble_aggregation(aggregation, column_weld_types, new_column_weld_types):\n    if aggregation in _dictmerger_ops:\n        return _assemble_aggregation_simple(column_weld_types, aggregation)\n    elif aggregation == \'size\':\n        return _assemble_aggregation_size(column_weld_types)\n    elif aggregation == \'mean\':\n        return _assemble_aggregation_mean(column_weld_types, new_column_weld_types)\n    elif aggregation == \'var\':\n        return _assemble_aggregation_var(column_weld_types, new_column_weld_types)\n    elif aggregation == \'std\':\n        return _assemble_aggregation_std(column_weld_types, new_column_weld_types)\n    else:\n        raise NotImplementedError(\'Oops\')\n\n\ndef _assemble_computation(aggregation, column_weld_types, new_column_weld_types):\n    template = """"""aggregation\n                    merge(b, {{e.$0, {group_res}}})""""""\n\n    aggregation_template = _assemble_aggregation(aggregation, column_weld_types, new_column_weld_types)\n    group_res = struct_of(\'group.${i}\', column_weld_types)\n\n    return template.replace(\'aggregation\', aggregation_template, 1)\\\n        .replace(\'group_res\', group_res, 1)\n\n\ndef weld_groupby_aggregate(grouped_df, weld_types, by_indices, aggregation, result_type=None):\n    """"""Perform aggregation on grouped data.\n\n    Parameters\n    ----------\n    grouped_df : WeldObject\n        DataFrame which has been grouped through weld_groupby.\n    weld_types : list of WeldType\n        Corresponding to data.\n    by_indices : list of int\n        Indices of which arrays to group by.\n    aggregation : {\'+\', \'*\', \'min\', \'max\', \'mean\', \'var\', \'std\'}\n        What operation to apply to grouped rows.\n    result_type : WeldType, optional\n        Whether the result shall be (casted to) some specific type.\n\n    Returns\n    -------\n    (list of WeldType, WeldObject)\n        Tuple of newly ordered Weld types and the WeldObject representation of the computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(grouped_df)\n\n    all_indices = list(range(len(weld_types)))\n    column_indices = list(filter(lambda x: x not in by_indices, all_indices))\n    by_weld_types = [weld_types[i] for i in by_indices]\n    column_weld_types = [weld_types[i] for i in column_indices]\n    new_column_weld_types = column_weld_types if result_type is None else [result_type for _ in column_weld_types]\n\n    by_types = struct_of(\'{e}\', by_weld_types)\n    column_types = struct_of(\'{e}\', column_weld_types)\n    new_column_types = struct_of(\'{e}\', new_column_weld_types)\n    grouped_df_types = \'{{{}, {}}}\'.format(by_types, column_types)\n    res = \'{{{}}}\'.format(\', \'.join([\'e.$0.${}\'.format(i) for i in range(len(by_weld_types))] +\n                                    [\'e.$1.${}\'.format(i) for i in range(len(column_weld_types))]))\n\n    weld_template = """"""map(\n    tovec(\n        result(\n            for(\n                {grouped_df},\n                dictmerger[{by_types}, {new_column_types}, +],\n                |b: dictmerger[{by_types}, {new_column_types}, +], i: i64, e: {{{by_types}, vec[{column_types}]}}|\n                    {computation}\n            )\n        )\n    ),\n    |e: {{{by_types}, {new_column_types}}}|\n        {res}\n)""""""\n\n    weld_template = weld_template.replace(\'{computation}\',\n                                          _assemble_computation(aggregation,\n                                                                column_weld_types,\n                                                                new_column_weld_types),\n                                          1)\n\n    weld_obj.weld_code = weld_template.format(grouped_df=obj_id,\n                                              by_types=by_types,\n                                              column_types=column_types,\n                                              new_column_types=new_column_types,\n                                              grouped_df_types=grouped_df_types,\n                                              res=res)\n\n    return by_weld_types + new_column_weld_types, weld_obj\n'"
baloo/weld/weld_joins.py,0,"b'from .cache import Cache\nfrom .convertors import default_missing_data_literal\nfrom .lazy_result import LazyStructOfVecResult, LazyStructResult\nfrom .pyweld import WeldLong, WeldStruct, WeldVec, WeldChar\nfrom .weld_utils import weld_arrays_to_vec_of_struct, create_empty_weld_object, get_weld_obj_id, \\\n    extract_placeholder_weld_objects, extract_placeholder_weld_objects_from_index, weld_data_to_dict, struct_of\n\n\n# e.g. n is the number of if statements;\n# use recur placeholder for what is recursive, and n for iteration number\ndef _recurse_template_internal(text, n, orig_n, end):\n    if n == 0:\n        return end\n\n    n_format = orig_n - n\n\n    return text.format(n=n_format, recur=_recurse_template_internal(text, n - 1, orig_n, end), t=\'\\t\' * n_format)\n\n\ndef _recursive_template(text, n, end):\n    return _recurse_template_internal(text, n, n, end)\n\n\n_individual_merges = {\n    \'inner\': \'p.$2, p.$3\',\n    \'left\': \'merge(p.$2, p.$0), merge(p.$3, none_elem2)\',\n    \'right\': \'merge(p.$2, none_elem1), merge(p.$3, p.$1)\',\n}\n\n_merges_less = {\n    \'inner\': _individual_merges[\'inner\'],\n    \'left\': _individual_merges[\'left\'],\n    \'right\': _individual_merges[\'inner\'],\n}\n_merges_greater = {\n    \'inner\': _individual_merges[\'inner\'],\n    \'left\': _individual_merges[\'inner\'],\n    \'right\': _individual_merges[\'right\'],\n}\n\n_remaining_missing = {\n    \'inner\': \'\',\n    \'left\': """"""let res = if (res.$0 < len1, iterate(res,\n        |p|\n            {\n                {p.$0 + 1L, p.$1, merge(p.$2, p.$0), merge(p.$3, none_elem2)},\n                p.$0 + 1L < len1\n            }\n), res);"""""",\n    \'right\': """"""let res = if (res.$1 < len2, iterate(res,\n        |p|\n            {\n                {p.$0, p.$1 + 1L, merge(p.$2, none_elem1), merge(p.$3, p.$1)},\n                p.$1 + 1L < len2\n            }\n), res);""""""\n}\n\n\ndef _generate_checks(how, separator_index):\n    checks = """"""if(val1.${n} == val2.${n},\n                {t}{recur},\n                {t}if(val1.${n} < val2.${n},  \n                    {t}{{p.$0 + 1L, p.$1, merge_less}},\n                    {t}{{p.$0, p.$1 + 1L, merge_greater}}\n                {t})\n            {t})""""""\n    checks = checks.replace(\'merge_less\', _merges_less[how], 1).replace(\'merge_greater\', _merges_greater[how], 1)\n\n    end = \'{p.$0 + 1L, p.$1 + 1L, merge(p.$2, p.$0), merge(p.$3, p.$1)}\'\n    checks = _recursive_template(checks, separator_index, end)\n\n    return checks\n\n\ndef _weld_merge_join(vec_of_struct_self, vec_of_struct_other, separator_index, how, is_on_unique):\n    weld_obj = create_empty_weld_object()\n    weld_obj_id_self = get_weld_obj_id(weld_obj, vec_of_struct_self)\n    weld_obj_id_other = get_weld_obj_id(weld_obj, vec_of_struct_other)\n\n    checks = _generate_checks(how, separator_index)\n\n    weld_template = """"""let len1 = len({self});\nlet len2 = len({other});\nlet none_elem1 = len1 + 1L;\nlet none_elem2 = len2 + 1L;\nlet res = iterate({{0L, 0L, appender[i64], appender[i64]}},\n    |p|\n        let val1 = lookup({self}, p.$0);\n        let val2 = lookup({other}, p.$1);\n        let iter_output = \n            {checks};\n        {{\n            iter_output,\n            iter_output.$0 < len1 && \n            iter_output.$1 < len2\n        }}\n);\n{remaining}\n{{result(res.$2), result(res.$3)}}""""""\n\n    weld_obj.weld_code = weld_template.format(self=weld_obj_id_self,\n                                              other=weld_obj_id_other,\n                                              checks=checks,\n                                              remaining=_remaining_missing[how])\n\n    return weld_obj\n\n\ndef weld_merge_join(arrays_self, weld_types_self, arrays_other, weld_types_other,\n                    how, is_on_sorted, is_on_unique, readable_text):\n    """"""Applies merge-join on the arrays returning indices from each to keep in the resulting\n\n    Parameters\n    ----------\n    arrays_self : list of (numpy.ndarray or WeldObject)\n        Columns from the self DataFrame on which to join.\n    weld_types_self : list of WeldType\n        Corresponding Weld types.\n    arrays_other : list of (numpy.ndarray or WeldObject)\n        Columns from the other DataFrame on which to join.\n    weld_types_other : list of WeldType\n        Corresponding Weld types.\n    how : {\'inner\', \'left\', \'right\'}\n        Which kind of join to do.\n    is_on_sorted : bool\n        If we know that the on columns are already sorted, can employ faster algorithm.\n    is_on_unique : bool\n        If we know that the values are unique, can employ faster algorithm.\n    readable_text : str\n        Explanatory string to add in the Weld placeholder.\n\n    Returns\n    -------\n    tuple of WeldObject\n        Two columns of indices from the input arrays, indices of the rows from self and other that should be\n        available in the resulting joined DataFrame.\n\n    """"""\n    assert is_on_unique\n\n    weld_obj_vec_of_struct_self = weld_arrays_to_vec_of_struct(arrays_self, weld_types_self)\n    weld_obj_vec_of_struct_other = weld_arrays_to_vec_of_struct(arrays_other, weld_types_other)\n\n    weld_obj_join = _weld_merge_join(weld_obj_vec_of_struct_self,\n                                     weld_obj_vec_of_struct_other,\n                                     len(arrays_self),\n                                     how,\n                                     is_on_unique)\n\n    intermediate_result = LazyStructOfVecResult(weld_obj_join, [WeldLong(), WeldLong()])\n    dependency_name = Cache.cache_intermediate_result(intermediate_result, readable_text)\n\n    weld_objects = extract_placeholder_weld_objects(dependency_name, 2, readable_text)\n\n    return weld_objects\n\n\ndef _weld_merge_outer_join(vec_of_struct_self, vec_of_struct_other, weld_types,\n                           separator_index, is_on_unique):\n    weld_obj = create_empty_weld_object()\n    weld_obj_id_self = get_weld_obj_id(weld_obj, vec_of_struct_self)\n    weld_obj_id_other = get_weld_obj_id(weld_obj, vec_of_struct_other)\n\n    new_index_appenders = struct_of(\'appender[{e}]\', weld_types)\n    new_index_results = struct_of(\'result(res.$4.${i})\', weld_types)\n\n    to_merge = struct_of(\'merge(p.$4.${i}, val.${i})\', weld_types)\n    to_merge_less = \'{}, {}\'.format(_merges_less[\'left\'], to_merge.replace(\'val\', \'val1\', 1))\n    to_merge_greater = \'{}, {}\'.format(_merges_greater[\'right\'], to_merge.replace(\'val\', \'val2\', 1))\n\n    checks_to_merge_less = \'{}, {{{}}}\'.format(_merges_less[\'left\'], to_merge.replace(\'val\', \'val1\', 1))\n    checks_to_merge_greater = \'{}, {{{}}}\'.format(_merges_greater[\'right\'], to_merge.replace(\'val\', \'val2\', 1))\n    checks = """"""if(val1.${n} == val2.${n},\n                {t}{recur},\n                {t}if(val1.${n} < val2.${n},  \n                    {t}{{p.$0 + 1L, p.$1, to_merge_less}},\n                    {t}{{p.$0, p.$1 + 1L, to_merge_greater}}\n                {t})\n            {t})""""""\n    checks = checks.replace(\'to_merge_less\', checks_to_merge_less, 1)\\\n        .replace(\'to_merge_greater\', checks_to_merge_greater, 1)\n    end = \'{{p.$0 + 1L, p.$1 + 1L, merge(p.$2, p.$0), merge(p.$3, p.$1), {}}}\'\\\n        .format(to_merge.replace(\'val\', \'val1\', 1))\n    checks = _recursive_template(checks, separator_index, end)\n\n    weld_template = """"""let len1 = len({self});\nlet len2 = len({other});\nlet none_elem1 = len1 + 1L;\nlet none_elem2 = len2 + 1L;\nlet res = iterate({{0L, 0L, appender[i64], appender[i64], {new_index_appenders}}},\n    |p|\n        let val1 = lookup({self}, p.$0);\n        let val2 = lookup({other}, p.$1);\n        let iter_output = \n            {checks};\n        {{\n            iter_output,\n            iter_output.$0 < len1 && \n            iter_output.$1 < len2\n        }}\n);\nlet res = if (res.$0 < len1, iterate(res,\n        |p|\n            let val1 = lookup({self}, p.$0);\n            {{\n                {{p.$0 + 1L, p.$1, {to_merge_less}}},\n                p.$0 + 1L < len1\n            }}\n), res);\nlet res = if (res.$1 < len2, iterate(res,\n        |p|\n            let val2 = lookup({other}, p.$1);\n            {{\n                {{p.$0, p.$1 + 1L, {to_merge_greater}}},\n                p.$1 + 1L < len2\n            }}\n), res);\n{{result(res.$2), result(res.$3), {new_index_results}}}""""""\n\n    weld_obj.weld_code = weld_template.format(self=weld_obj_id_self,\n                                              other=weld_obj_id_other,\n                                              checks=checks,\n                                              to_merge_less=to_merge_less,\n                                              to_merge_greater=to_merge_greater,\n                                              new_index_appenders=new_index_appenders,\n                                              new_index_results=new_index_results)\n\n    return weld_obj\n\n\ndef weld_merge_outer_join(arrays_self, weld_types_self, arrays_other, weld_types_other,\n                          how, is_on_sorted, is_on_unique, readable_text):\n    """"""Applies merge-join on the arrays returning indices from each to keep in the resulting\n\n    Parameters\n    ----------\n    arrays_self : list of (numpy.ndarray or WeldObject)\n        Columns from the self DataFrame on which to join.\n    weld_types_self : list of WeldType\n        Corresponding Weld types.\n    arrays_other : list of (numpy.ndarray or WeldObject)\n        Columns from the other DataFrame on which to join.\n    weld_types_other : list of WeldType\n        Corresponding Weld types.\n    how : {\'outer\'}\n        Here it is not used but kept to maintain same method signature as weld_merge_join\n    is_on_sorted : bool\n        If we know that the on columns are already sorted, can employ faster algorithm.\n    is_on_unique : bool\n        If we know that the values are unique, can employ faster algorithm.\n    readable_text : str\n        Explanatory string to add in the Weld placeholder.\n\n    Returns\n    -------\n    tuple of WeldObject\n        Three objects: first 2 are indices from the input arrays, indices of the rows from self and other that should be\n        available in the resulting joined DataFrame. The last object will be a tuple containing the new index with\n        actual values, not indices to other rows.\n\n    """"""\n    assert is_on_unique\n\n    weld_obj_vec_of_struct_self = weld_arrays_to_vec_of_struct(arrays_self, weld_types_self)\n    weld_obj_vec_of_struct_other = weld_arrays_to_vec_of_struct(arrays_other, weld_types_other)\n\n    weld_obj_join = _weld_merge_outer_join(weld_obj_vec_of_struct_self,\n                                           weld_obj_vec_of_struct_other,\n                                           weld_types_self,\n                                           len(arrays_self),\n                                           is_on_unique)\n\n    intermediate_result = LazyStructResult(weld_obj_join, [WeldVec(WeldLong()),\n                                                           WeldVec(WeldLong()),\n                                                           WeldStruct([WeldVec(weld_type)\n                                                                       for weld_type in weld_types_self])])\n    dependency_name = Cache.cache_intermediate_result(intermediate_result, readable_text)\n\n    weld_objects_indexes = extract_placeholder_weld_objects(dependency_name, 2, readable_text)\n    weld_objects_new_index = extract_placeholder_weld_objects_from_index(dependency_name,\n                                                                         len(weld_types_self),\n                                                                         readable_text,\n                                                                         2)\n\n    return weld_objects_indexes + [weld_objects_new_index]\n\n\ndef weld_align(df_index_arrays, df_index_weld_types,\n               series_index_arrays, series_index_weld_types,\n               series_data, series_weld_type):\n    """"""Returns the data from the Series aligned to the DataFrame index.\n\n    Parameters\n    ----------\n    df_index_arrays : list of (numpy.ndarray or WeldObject)\n        The index columns as a list.\n    df_index_weld_types : list of WeldType\n    series_index_arrays : numpy.ndarray or WeldObject\n        The index of the Series.\n    series_index_weld_types : list of WeldType\n    series_data : numpy.ndarray or WeldObject\n        The data of the Series.\n    series_weld_type : WeldType\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    weld_obj_index_df = weld_arrays_to_vec_of_struct(df_index_arrays, df_index_weld_types)\n    weld_obj_series_dict = weld_data_to_dict(series_index_arrays,\n                                             series_index_weld_types,\n                                             series_data,\n                                             series_weld_type)\n\n    weld_obj = create_empty_weld_object()\n    df_index_obj_id = get_weld_obj_id(weld_obj, weld_obj_index_df)\n    series_dict_obj_id = get_weld_obj_id(weld_obj, weld_obj_series_dict)\n\n    index_type = struct_of(\'{e}\', df_index_weld_types)\n    missing_literal = default_missing_data_literal(series_weld_type)\n    if series_weld_type == WeldVec(WeldChar()):\n        missing_literal = get_weld_obj_id(weld_obj, missing_literal)\n\n    weld_template = """"""result(\n    for({df_index},\n        appender[{data_type}],\n        |b: appender[{data_type}], i: i64, e: {index_type}|\n            if(keyexists({series_dict}, e),\n                merge(b, lookup({series_dict}, e)),\n                merge(b, {missing})\n            )\n    )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(series_dict=series_dict_obj_id,\n                                              df_index=df_index_obj_id,\n                                              index_type=index_type,\n                                              data_type=series_weld_type,\n                                              missing=missing_literal)\n\n    return weld_obj\n'"
baloo/weld/weld_ops.py,1,"b'import numpy as np\n\nfrom .convertors import default_missing_data_literal\nfrom .lazy_result import LazyArrayResult, LazyStructOfVecResult\nfrom .pyweld import WeldVec, WeldChar, WeldLong, WeldObject\nfrom .weld_utils import get_weld_obj_id, create_weld_object, to_weld_literal, create_empty_weld_object, \\\n    weld_arrays_to_vec_of_struct, weld_vec_of_struct_to_struct_of_vec, Cache, weld_select_from_struct, \\\n    extract_placeholder_weld_objects, struct_of\n\n\ndef weld_range(start, stop, step):\n    """"""Create a vector for the range parameters above.\n\n    Parameters\n    ----------\n    start : int\n    stop : int or WeldObject\n        Could be the lazily computed length of a WeldObject vec.\n    step : int\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    if isinstance(stop, WeldObject):\n        obj_id, weld_obj = create_weld_object(stop)\n        stop = obj_id\n    else:\n        weld_obj = create_empty_weld_object()\n\n    weld_template = """"""result(\n    for(\n        rangeiter({start}L, {stop}, {step}L),\n        appender[i64],\n        |b: appender[i64], i: i64, e: i64| \n            merge(b, e)\n    )\n)""""""\n\n    stop = \'{}L\'.format(stop) if isinstance(stop, int) else stop\n\n    weld_obj.weld_code = weld_template.format(start=start,\n                                              stop=stop,\n                                              step=step)\n\n    return weld_obj\n\n\ndef weld_compare(array, scalar, operation, weld_type):\n    """"""Applies comparison operation between each element in the array with scalar.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    scalar : {int, float, str, bool, bytes_}\n        Value to compare with; must be same type as the values in the array. If not a str,\n        it is casted to weld_type (allowing one to write e.g. native Python int).\n    operation : str\n        Operation to do out of: {<, <=, ==, !=, >=, >}.\n    weld_type : WeldType\n        Type of the elements in the input array.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n\n    if not isinstance(scalar, str):\n        scalar = to_weld_literal(scalar, weld_type)\n\n    cast = \'{type}({scalar})\'.format(type=weld_type, scalar=scalar)\n    # actually checking WeldVec(WeldChar)\n    if isinstance(weld_type, WeldVec):\n        cast = get_weld_obj_id(weld_obj, scalar)\n\n    # TODO: there should be no casting! requires Weld fix\n    weld_template = """"""map(\n    {array},\n    |a: {type}| \n        a {operation} {cast}\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              operation=operation,\n                                              type=weld_type,\n                                              cast=cast)\n\n    return weld_obj\n\n\ndef weld_filter(array, weld_type, bool_array):\n    """"""Returns a new array only with the elements with a corresponding True in bool_array.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    weld_type : WeldType\n        Type of the elements in the input array.\n    bool_array : numpy.ndarray or WeldObject\n        Array of bool with True for elements in array desired in the result array.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n    bool_obj_id = get_weld_obj_id(weld_obj, bool_array)\n\n    weld_template = """"""result(\n    for(\n        zip({array}, {bool_array}),\n        appender[{type}],\n        |b: appender[{type}], i: i64, e: {{{type}, bool}}| \n            if (e.$1, \n                merge(b, e.$0), \n                b)\n    )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              bool_array=bool_obj_id,\n                                              type=weld_type)\n\n    return weld_obj\n\n\ndef weld_slice(array, weld_type, slice_, default_start=0, default_stop=0, default_step=1):\n    """"""Returns a new array according to the given slice.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        1-dimensional array.\n    weld_type : WeldType\n        Type of the elements in the input array.\n    slice_ : slice\n        Subset to return. Assumed valid slice.\n    default_start : int, optional\n        Default value to slice start.\n    default_stop : int, optional\n        Default value to slice stop.\n    default_step : int, optional\n        Default value to slice step.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    from ..core.utils import replace_slice_defaults\n\n    slice_ = replace_slice_defaults(slice_, default_start, default_stop, default_step)\n    obj_id, weld_obj = create_weld_object(array)\n\n    if slice_.step == 1:\n        weld_template = """"""slice(\n    {array},\n    {slice_start},\n    {slice_stop}\n)""""""\n    else:\n        weld_template = """"""result(\n    for(\n        iter({array}, {slice_start}, {slice_stop}, {slice_step}),\n        appender[{type}],\n        |b: appender[{type}], i: i64, e: {type}| \n            merge(b, n)\n    )  \n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type,\n                                              slice_start=\'{}L\'.format(slice_.start),\n                                              slice_stop=\'{}L\'.format(slice_.stop - slice_.start),\n                                              slice_step=\'{}L\'.format(slice_.step))\n\n    return weld_obj\n\n\n# TODO: could generalize weld_slice to accept slice with possible WeldObjects\ndef weld_tail(array, length, n):\n    """"""Return the last n elements.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Array to select from.\n    length : int or WeldObject\n        Length of the array. Int if already known can simplify the computation.\n    n : int\n        How many values.\n\n    Returns\n    -------\n    WeldObject\n        Representation of the computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n    if isinstance(length, WeldObject):\n        length = get_weld_obj_id(weld_obj, length)\n        slice_start = \'{} - {}L\'.format(length, n)\n        slice_stop = \'{}\'.format(length)\n    else:\n        slice_start = \'{}L - {}L\'.format(length, n)\n        slice_stop = \'{}L\'.format(length)\n\n    weld_template = """"""slice(\n    {array},\n    {slice_start},\n    {slice_stop}\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              slice_start=slice_start,\n                                              slice_stop=slice_stop)\n\n    return weld_obj\n\n\n# TODO: what happens if not?\ndef weld_array_op(array1, array2, result_type, operation):\n    """"""Applies operation to each pair of elements in the arrays.\n\n    Their lengths and types are assumed to be the same.\n\n    Parameters\n    ----------\n    array1 : numpy.ndarray or WeldObject\n        Input array.\n    array2 : numpy.ndarray or WeldObject\n        Second input array.\n    result_type : WeldType\n        Weld type of the result. Expected to be the same as both input arrays.\n    operation : {\'+\', \'-\', \'*\', \'/\', \'&&\', \'||\', \'pow\'}\n        Which operation to apply. Note bitwise operations (not included) seem to be bugged at the LLVM level.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id1, weld_obj = create_weld_object(array1)\n    obj_id2 = get_weld_obj_id(weld_obj, array2)\n\n    if operation == \'pow\':\n        action = \'pow(e.$0, e.$1)\'\n    else:\n        action = \'e.$0 {operation} e.$1\'.format(operation=operation)\n\n    weld_template = """"""result(\n    for(zip({array1}, {array2}), \n        appender[{type}], \n        |b: appender[{type}], i: i64, e: {{{type}, {type}}}| \n            merge(b, {action})\n    )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array1=obj_id1,\n                                              array2=obj_id2,\n                                              type=result_type,\n                                              action=action)\n\n    return weld_obj\n\n\ndef weld_invert(array):\n    """"""Inverts a bool array.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data. Assumed to be bool data.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = """"""result(\n    for({array},\n        appender[bool],\n        |b: appender[bool], i: i64, e: bool|\n            if(e, merge(b, false), merge(b, true))\n    )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id)\n\n    return weld_obj\n\n\ndef weld_iloc_int(array, index):\n    """"""Retrieves the value at index.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data. Assumed to be bool data.\n    index : int\n        The array index from which to retrieve value.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = \'lookup({array}, {index}L)\'\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              index=index)\n\n    return weld_obj\n\n\ndef weld_iloc_indices(array, weld_type, indices):\n    """"""Retrieve the values at indices.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data. Assumed to be bool data.\n    weld_type : WeldType\n        The WeldType of the array data.\n    indices : numpy.ndarray or WeldObject\n        The indices to lookup.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    weld_obj = create_empty_weld_object()\n    weld_obj_id_array = get_weld_obj_id(weld_obj, array)\n    weld_obj_id_indices = get_weld_obj_id(weld_obj, indices)\n\n    weld_template = """"""result(\n    for({indices},\n        appender[{type}],\n        |b: appender[{type}], i: i64, e: i64|\n            merge(b, lookup({array}, e))\n    )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=weld_obj_id_array,\n                                              indices=weld_obj_id_indices,\n                                              type=weld_type)\n\n    return weld_obj\n\n\ndef weld_iloc_indices_with_missing(array, weld_type, indices):\n    """"""Retrieve the values at indices. Indices greater than array length get replaced with\n    a corresponding-type missing value literal.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data. Assumed to be bool data.\n    weld_type : WeldType\n        The WeldType of the array data.\n    indices : numpy.ndarray or WeldObject\n        The indices to lookup.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    weld_obj = create_empty_weld_object()\n    weld_obj_id_array = get_weld_obj_id(weld_obj, array)\n    weld_obj_id_indices = get_weld_obj_id(weld_obj, indices)\n\n    missing_literal = default_missing_data_literal(weld_type)\n    if weld_type == WeldVec(WeldChar()):\n        missing_literal = get_weld_obj_id(weld_obj, missing_literal)\n\n    weld_template = """"""let len_array = len({array});\nresult(\n    for({indices},\n        appender[{type}],\n        |b: appender[{type}], i: i64, e: i64|\n            if(e >= len_array,\n                merge(b, {missing}),\n                merge(b, lookup({array}, e))\n            )\n    )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=weld_obj_id_array,\n                                              indices=weld_obj_id_indices,\n                                              type=weld_type,\n                                              missing=missing_literal)\n\n    return weld_obj\n\n\ndef weld_element_wise_op(array, weld_type, scalar, operation):\n    """"""Applies operation to each element in the array with scalar.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input array.\n    weld_type : WeldType\n        Type of each element in the input array.\n    scalar : {int, float, str, bool, bytes_}\n        Value to compare with; must be same type as the values in the array. If not a str,\n        it is casted to weld_type (allowing one to write e.g. native Python int).\n    operation : {+, -, *, /, pow}\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n\n    scalar = to_weld_literal(scalar, weld_type)\n\n    if operation == \'pow\':\n        action = \'pow(e, {scalar})\'.format(scalar=scalar)\n    else:\n        action = \'e {operation} {scalar}\'.format(scalar=scalar,\n                                                 operation=operation)\n\n    weld_template = """"""result(\n    for({array}, \n        appender[{type}], \n        |b: appender[{type}], i: i64, e: {type}| \n            merge(b, {action})\n    )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type,\n                                              action=action)\n\n    return weld_obj\n\n\n# this function does the actual sorting\n# TODO: descending sort on strings might not work\ndef _weld_sort(arrays, weld_types, ascending=True):\n    obj_id, index_obj = create_weld_object(arrays[0])\n    index_obj.weld_code = \'len({})\'.format(obj_id)\n    # get indexes that will be sorted and returned\n    index_column = weld_range(0, index_obj, 1)\n\n    arrays.insert(0, index_column)\n    weld_types.insert(0, WeldLong())\n    weld_obj_vec_of_struct = weld_arrays_to_vec_of_struct(arrays, weld_types)\n\n    weld_obj = create_empty_weld_object()\n    weld_obj_vec_of_struct_id = get_weld_obj_id(weld_obj, weld_obj_vec_of_struct)\n\n    types = struct_of(\'{e}\', weld_types)\n    # TODO: update here when sorting on structs is possible\n    ascending_sort_func = \'{}\'.format(\', \'.join((\'e.${}\'.format(i) for i in range(1, len(arrays)))))\n    zero_literals = dict(enumerate([to_weld_literal(0, weld_type) for weld_type in weld_types]))\n    descending_sort_func = \'{}\'.format(\', \'.join((\'{} - e.${}\'.format(zero_literals[i], i)\n                                                  for i in range(1, len(arrays)))))\n    sort_func = ascending_sort_func if ascending else descending_sort_func\n\n    weld_template = \'sort({struct}, |e: {types}| {sort_func})\'\n\n    weld_obj.weld_code = weld_template.format(struct=weld_obj_vec_of_struct_id,\n                                              types=types,\n                                              sort_func=sort_func)\n\n    return weld_obj\n\n\n# TODO: further optimization is to skip creating struct of vec when it\'s a single column\ndef weld_sort(arrays, weld_types, readable_text, ascending=True):\n    """"""Sort the arrays.\n\n    Parameters\n    ----------\n    arrays : list of (numpy.ndarray or WeldObject)\n        Arrays to put in a struct.\n    weld_types : list of WeldType\n        The Weld types of the arrays in the same order.\n    readable_text : str\n        Explanatory string to add in the Weld placeholder.\n    ascending : bool, optional\n\n    Returns\n    -------\n    list of WeldObject\n        Representation of this computation.\n\n    """"""\n    weld_obj_sort = _weld_sort(arrays, weld_types, ascending)\n    weld_obj_struct = weld_vec_of_struct_to_struct_of_vec(weld_obj_sort, weld_types)\n    weld_obj_indices = weld_select_from_struct(weld_obj_struct, 0)\n\n    intermediate_result = LazyArrayResult(weld_obj_indices, WeldLong())\n    dependency_name = Cache.cache_intermediate_result(intermediate_result, readable_text)\n\n    fake_weld_input = Cache.create_fake_array_input(dependency_name, readable_text + \'_indices\')\n    obj_id, weld_obj = create_weld_object(fake_weld_input)\n    weld_obj.weld_code = \'{}\'.format(obj_id)\n    Cache.cache_fake_input(obj_id, fake_weld_input)\n\n    return weld_obj\n\n\ndef weld_unique(array, weld_type):\n    """"""Return the unique elements of the array.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input array.\n    weld_type : WeldType\n        Type of each element in the input array.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = """"""map(\n    tovec(\n        result(\n            for(\n                map(\n                    {array},\n                    |e| \n                        {{e, 0si}}\n                ),\n                dictmerger[{type}, i16, +],\n                |b: dictmerger[{type}, i16, +], i: i64, e: {{{type}, i16}}| \n                    merge(b, e)\n            )\n        )\n    ),\n    |e| \n        e.$0\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type)\n\n    return weld_obj\n\n\ndef weld_drop_duplicates(arrays, weld_types, subset_indices, keep):\n    """"""Return the unique elements of the array.\n\n    Parameters\n    ----------\n    arrays : list of (numpy.ndarray or WeldObject)\n        Input arrays.\n    weld_types : list of WeldType\n        Type of elements in the input arrays.\n    subset_indices : list of int\n        Indices of which arrays to consider from arrays when checking duplicates.\n    keep : {\'+\', \'*\', \'min\', \'max\'}\n        Which merger to apply.\n\n    Returns\n    -------\n    list of WeldObject\n        New columns with those not included in subset returned as is.\n\n    """"""\n    weld_obj_struct = weld_arrays_to_vec_of_struct(arrays, weld_types)\n\n    obj_id, weld_obj = create_weld_object(weld_obj_struct)\n\n    all_indices = list(range(len(arrays)))\n    value_indices = list(filter(lambda x: x not in subset_indices, all_indices))\n    key_weld_types = [weld_types[i] for i in subset_indices]\n    value_weld_types = [weld_types[i] for i in value_indices]\n\n    key_types = struct_of(\'{e}\', key_weld_types)\n    value_types = struct_of(\'{e}\', value_weld_types)\n    all_types = struct_of(\'{e}\', weld_types)\n    key_merges = struct_of(\'e.${e}\', subset_indices)\n    value_merges = struct_of(\'e.${e}\', value_indices)\n\n    # flattening the struct of struct\n    results = []\n    key_i = 0\n    value_i = 0\n    for i in all_indices:\n        if i in subset_indices:\n            results.append(\'e.${}.${}\'.format(0, key_i))\n            key_i += 1\n        else:\n            results.append(\'e.${}.${}\'.format(1, value_i))\n            value_i += 1\n    res = \'{{{}}}\'.format(\', \'.join(results))\n\n    weld_template = """"""map(\n    tovec(\n        result(\n            for(\n                map(\n                    {arrays},\n                    |e: {all_types}| \n                        {{{key_merges}, {value_merges}}}\n                ),\n                dictmerger[{key_types}, {value_types}, {keep}],\n                |b: dictmerger[{key_types}, {value_types}, {keep}], i: i64, e: {{{key_types}, {value_types}}}| \n                    merge(b, e)\n            )\n        )\n    ),\n    |e: {{{key_types}, {value_types}}}| \n        {res}\n)""""""\n\n    weld_obj.weld_code = weld_template.format(arrays=obj_id,\n                                              all_types=all_types,\n                                              key_types=key_types,\n                                              value_types=value_types,\n                                              key_merges=key_merges,\n                                              value_merges=value_merges,\n                                              keep=keep,\n                                              res=res)\n\n    weld_struct_of_vec = weld_vec_of_struct_to_struct_of_vec(weld_obj, weld_types)\n\n    intermediate_result = LazyStructOfVecResult(weld_struct_of_vec, weld_types)\n    dependency_name = Cache.cache_intermediate_result(intermediate_result, \'drop_dupl\')\n\n    weld_objects = extract_placeholder_weld_objects(dependency_name, len(arrays), \'drop_dupl\')\n\n    return weld_objects\n\n\ndef weld_replace(array, weld_type, this, to):\n    """"""Replaces \'this\' values to \'to\' value.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input array.\n    weld_type : WeldType\n        Type of the data in the array.\n    this : {int, float, str, bool, bytes}\n        Scalar to replace.\n    to : {int, float, str, bool, bytes}\n        Scalar to replace with.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    if not isinstance(this, str):\n        this = to_weld_literal(this, weld_type)\n    to = to_weld_literal(to, weld_type)\n\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = """"""map({array},\n    |e: {type}|\n        if(e == {this},\n            {to},\n            e\n        )    \n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type,\n                                              this=this,\n                                              to=to)\n\n    return weld_obj\n\n\ndef weld_udf(weld_template, mapping):\n    """"""Create WeldObject to encode weld_template code given mapping.\n\n    Parameters\n    ----------\n    weld_template : str\n        Weld code to encode.\n    mapping : dict\n        Which substitutions to make in the weld_template.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    weld_obj = create_empty_weld_object()\n\n    for k, v in mapping.items():\n        if isinstance(v, (np.ndarray, WeldObject)):\n            obj_id = get_weld_obj_id(weld_obj, v)\n            mapping.update({k: obj_id})\n\n    weld_obj.weld_code = weld_template.format(**mapping)\n\n    return weld_obj\n'"
baloo/weld/weld_str.py,0,"b'from .convertors import default_missing_data_literal\nfrom .pyweld import WeldLong, WeldVec, WeldChar\nfrom .weld_utils import create_weld_object, to_weld_literal, get_weld_obj_id\n\n\ndef weld_str_lower(array):\n    """"""Convert values to lowercase.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = """"""map(\n    {array},\n    |e: vec[i8]|\n        result(\n            for(e,\n                appender[i8],\n                |c: appender[i8], j: i64, f: i8|\n                    if(f > 64c && f < 91c,\n                        merge(c, f + 32c),\n                        merge(c, f))\n            )\n        )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id)\n\n    return weld_obj\n\n\ndef weld_str_upper(array):\n    """"""Convert values to uppercase.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = """"""map(\n    {array},\n    |e: vec[i8]|\n        result(\n            for(e,\n                appender[i8],\n                |c: appender[i8], j: i64, f: i8|\n                    if(f > 96c && f < 123c,\n                        merge(c, f - 32c),\n                        merge(c, f))\n            )\n        )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id)\n\n    return weld_obj\n\n\ndef weld_str_capitalize(array):\n    """"""Capitalize first letter.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = """"""map(\n    {array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        if(lenString > 0L,\n            let res = appender[i8];\n            let firstChar = lookup(e, 0L);\n            let res = if(firstChar > 96c && firstChar < 123c, merge(res, firstChar - 32c), merge(res, firstChar));\n            result(\n                for(slice(e, 1L, lenString - 1L),\n                    res,\n                    |c: appender[i8], j: i64, f: i8|\n                        if(f > 64c && f < 91c,\n                            merge(c, f + 32c),\n                            merge(c, f)\n                        )\n                )\n            ),\n            e)\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id)\n\n    return weld_obj\n\n\ndef weld_str_get(array, i):\n    """"""Retrieve character at index i.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    i : int\n        Index of character to retrieve. If greater than length of string, returns None.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n    index_literal = to_weld_literal(i, WeldLong())\n    missing_literal = default_missing_data_literal(WeldVec(WeldChar()))\n    missing_literal_id = get_weld_obj_id(weld_obj, missing_literal)\n\n    weld_template = """"""map(\n    {array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        if({i} >= lenString,\n            {missing},\n            if({i} > 0L,\n                result(merge(appender[i8], lookup(slice(e, 0L, lenString), {i}))),\n                result(merge(appender[i8], lookup(slice(e, lenString, {i}), {i})))\n            )\n        )\n)""""""\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              i=index_literal,\n                                              missing=missing_literal_id)\n\n    return weld_obj\n\n\ndef weld_str_strip(array):\n    """"""Strip whitespace from start and end of elements.\n\n    Note it currently only looks for whitespace (Ascii 32), not tabs or EOL.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n\n    # +3L = +1 compensate start_i already +1\'ed, +1 compensate end_i already -1\'ed, +1 compensate for slice with size\n    weld_template = """"""map(\n    {array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        let res = appender[i8];\n        let start_i = iterate(0L, |p| {{p + 1L, lookup(e, p) == 32c}});\n        let end_i = iterate(lenString - 1L, |p| {{p - 1L, lookup(e, p) == 32c && p > 0L}});\n        slice(e, start_i - 1L, end_i - start_i + 3L)\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id)\n\n    return weld_obj\n\n\ndef _prepare_slice(i, default):\n    if i is None:\n        return default\n    else:\n        return to_weld_literal(i, WeldLong())\n\n\n# TODO: check & allow negative step ~ requires Weld fix\ndef weld_str_slice(array, start=None, stop=None, step=None):\n    """"""Slice each element.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    start : int, optional\n    stop : int, optional\n    step : int, optional\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n    start = _prepare_slice(start, \'0L\')\n    stop = _prepare_slice(stop, \'lenString\')\n    step = _prepare_slice(step, \'1L\')\n\n    weld_template = """"""map(\n    {array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        let stop = if({stop} > lenString, lenString, {stop});\n        result(\n            for(iter(e, {start}, stop, {step}),\n                appender[i8],\n                |c: appender[i8], j: i64, f: i8| \n                    merge(c, f)\n            )\n        ) \n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              start=start,\n                                              stop=stop,\n                                              step=step)\n\n    return weld_obj\n\n\ndef weld_str_contains(array, pat):\n    """"""Check which elements contain pat.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    pat : str\n        To check for.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n    pat_id = get_weld_obj_id(weld_obj, pat)\n\n    weld_template = """"""let lenPat = len({pat});\nmap({array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        if(lenPat > lenString,\n            false,\n            # start by assuming pat is not found, until proven it is\n            let words_iter_res = iterate({{0L, false}}, \n                |p| \n                    let e_i = p.$0;\n                    let pat_i = 0L;\n                    # start by assuming the substring and pat are the same, until proven otherwise\n                    let word_check_res = iterate({{e_i, pat_i, true}}, \n                        |q| \n                            let found = lookup(e, q.$0) == lookup({pat}, q.$1);\n                            {{\n                                {{q.$0 + 1L, q.$1 + 1L, found}}, \n                                q.$1 + 1L < lenPat &&\n                                found == true\n                            }}\n                    ).$2;\n                    {{\n                        {{p.$0 + 1L, word_check_res}}, \n                        p.$0 + lenPat < lenString &&\n                        word_check_res == false\n                    }}\n            ).$1;\n            words_iter_res\n        )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              pat=pat_id)\n\n    return weld_obj\n\n\ndef weld_str_startswith(array, pat):\n    """"""Check which elements start with pattern.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    pat : str\n        To check for.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n    pat_id = get_weld_obj_id(weld_obj, pat)\n\n    """"""alternative implementation for reference\n    let res = result(\n        for(zip(slice(e, 0L, lenPat), {pat}),\n            merger[i64, +],\n            |b: merger[i64, +], i: i64, e: {{i8, i8}}|\n                if(e.$0 == e.$1, \n                    merge(b, 1L), \n                    merge(b, 0L)\n                )\n        )\n    );\n    res == lenPat\n    """"""\n\n    weld_template = """"""let lenPat = len({pat});\nmap({array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        if(lenPat > lenString,\n            false,\n            iterate({{0L, true}}, \n                |q| \n                    let found = lookup(e, q.$0) == lookup({pat}, q.$0);\n                    {{\n                        {{q.$0 + 1L, found}}, \n                        q.$0 + 1L < lenPat &&\n                        found == true\n                    }}\n            ).$1\n        )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              pat=pat_id)\n\n    return weld_obj\n\n\ndef weld_str_endswith(array, pat):\n    """"""Check which elements end with pattern.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    pat : str\n        To check for.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n    pat_id = get_weld_obj_id(weld_obj, pat)\n\n    weld_template = """"""let lenPat = len({pat});\nmap({array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        if(lenPat > lenString,\n            false,\n            iterate({{lenString - lenPat, 0L, true}}, \n                |q| \n                    let found = lookup(e, q.$0) == lookup({pat}, q.$1);\n                    {{\n                        {{q.$0 + 1L, q.$1 + 1L, found}}, \n                        q.$1 + 1L < lenPat &&\n                        found == true\n                    }}\n            ).$2\n        )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              pat=pat_id)\n\n    return weld_obj\n\n\ndef weld_str_find(array, sub, start, end):\n    """"""Return index of sub in elements if found, else -1.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    sub : str\n        To check for.\n    start : int\n        Start index for searching.\n    end : int or None\n        Stop index for searching.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n    sub_id = get_weld_obj_id(weld_obj, sub)\n\n    if end is None:\n        end = \'len(e)\'\n    else:\n        end = to_weld_literal(end, WeldLong())\n\n    start = to_weld_literal(start, WeldLong())\n\n    # TODO: maybe be more friendly and fix end >= len(e) to be len(e) - 1?\n    weld_template = """"""let lenSub = len({sub});\nmap({array},\n    |e: vec[i8]|\n        let start = {start};\n        let size = {end} - start;\n        let string = slice(e, start, size);\n        let lenString = len(string);\n        if(lenSub > lenString,\n            -1L,\n            # start by assuming sub is not found, until proven it is\n            let words_iter_res = iterate({{0L, false}}, \n                |p| \n                    let e_i = p.$0;\n                    let pat_i = 0L;\n                    # start by assuming the substring and sub are the same, until proven otherwise\n                    let word_check_res = iterate({{e_i, pat_i, true}}, \n                        |q| \n                            let found = lookup(string, q.$0) == lookup({sub}, q.$1);\n                            {{\n                                {{q.$0 + 1L, q.$1 + 1L, found}}, \n                                q.$1 + 1L < lenSub &&\n                                found == true\n                            }}\n                    ).$2;\n                    {{\n                        {{p.$0 + 1L, word_check_res}}, \n                        p.$0 + lenSub < lenString &&\n                        word_check_res == false\n                    }}\n            );\n            if(words_iter_res.$1 == true,\n                words_iter_res.$0 - 1L + start,\n                -1L\n            )\n        )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              sub=sub_id,\n                                              start=start,\n                                              end=end)\n\n    return weld_obj\n\n\ndef weld_str_replace(array, pat, rep):\n    """"""Replace first occurrence of pat with rep.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    pat : str\n        To find.\n    rep : str\n        To replace with.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n    pat_id = get_weld_obj_id(weld_obj, pat)\n    rep_id = get_weld_obj_id(weld_obj, rep)\n\n    weld_template = """"""let lenPat = len({pat});\nmap({array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        if(lenPat > lenString,\n            e,\n            # start by assuming sub is not found, until proven it is\n            let words_iter_res = iterate({{0L, false}}, \n                |p| \n                    let e_i = p.$0;\n                    let pat_i = 0L;\n                    # start by assuming the substring and sub are the same, until proven otherwise\n                    let word_check_res = iterate({{e_i, pat_i, true}}, \n                        |q| \n                            let found = lookup(e, q.$0) == lookup({pat}, q.$1);\n                            {{\n                                {{q.$0 + 1L, q.$1 + 1L, found}}, \n                                q.$1 + 1L < lenPat &&\n                                found == true\n                            }}\n                    ).$2;\n                    {{\n                        {{p.$0 + 1L, word_check_res}}, \n                        p.$0 + lenPat < lenString &&\n                        word_check_res == false\n                    }}\n            );\n            if(words_iter_res.$1 == true,\n                let rep_from = words_iter_res.$0 - 1L;\n                let rep_to = rep_from + lenPat;\n                let res = appender[i8];\n                let res = for(slice(e, 0L, rep_from),\n                    res,\n                    |c: appender[i8], j: i64, f: i8|\n                        merge(c, f)                    \n                );\n                let res = for({rep},\n                    res,\n                    |c: appender[i8], j: i64, f: i8|\n                        merge(c, f)                    \n                );\n                let res = for(slice(e, rep_to, lenString),\n                    res,\n                    |c: appender[i8], j: i64, f: i8|\n                        merge(c, f)                    \n                );\n                result(res),\n                e\n            )\n        )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              pat=pat_id,\n                                              rep=rep_id)\n\n    return weld_obj\n\n\ndef weld_str_split(array, pat, side):\n    """"""Split on pat and return side.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    pat : str\n        To find.\n    side : {0, 1}\n        Which side to return, with 0 being left and 1 being right\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(array)\n    pat_id = get_weld_obj_id(weld_obj, pat)\n\n    left_side_template = """"""let pat_start_index = words_iter_res.$0 - 1L;\nresult(\n    for(slice(e, 0L, pat_start_index),\n        appender[i8],\n        |c: appender[i8], j: i64, f: i8|\n            merge(c, f)   \n    )                 \n)""""""\n    right_side_template = """"""let start_index = words_iter_res.$0 - 1L + lenPat;\nresult(\n    for(slice(e, start_index, lenString),\n        appender[i8],\n        |c: appender[i8], j: i64, f: i8|\n            merge(c, f)   \n    )                 \n)""""""\n\n    weld_template = """"""let lenPat = len({pat});\nmap({array},\n    |e: vec[i8]|\n        let lenString = len(e);\n        if(lenPat > lenString,\n            e,\n            # start by assuming sub is not found, until proven it is\n            let words_iter_res = iterate({{0L, false}}, \n                |p| \n                    let e_i = p.$0;\n                    let pat_i = 0L;\n                    # start by assuming the substring and sub are the same, until proven otherwise\n                    let word_check_res = iterate({{e_i, pat_i, true}}, \n                        |q| \n                            let found = lookup(e, q.$0) == lookup({pat}, q.$1);\n                            {{\n                                {{q.$0 + 1L, q.$1 + 1L, found}}, \n                                q.$1 + 1L < lenPat &&\n                                found == true\n                            }}\n                    ).$2;\n                    {{\n                        {{p.$0 + 1L, word_check_res}}, \n                        p.$0 + lenPat < lenString &&\n                        word_check_res == false\n                    }}\n            );\n            if(words_iter_res.$1 == true,\n                {side},\n                e\n            )\n        )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              pat=pat_id,\n                                              side=left_side_template if side == 0 else right_side_template)\n\n    return weld_obj\n'"
baloo/weld/weld_utils.py,0,"b'from .cache import Cache\nfrom .convertors import NumPyEncoder, NumPyDecoder\nfrom .pyweld.types import WeldInt16, WeldLong, WeldFloat, WeldBit, WeldDouble, WeldInt\nfrom .pyweld.weldobject import WeldObject\n\n_encoder = NumPyEncoder()\n_decoder = NumPyDecoder()\n\n\ndef create_empty_weld_object():\n    return WeldObject(_encoder, _decoder)\n\n\ndef get_weld_obj_id(weld_obj, data):\n    """"""Helper method to update WeldObject with some data.\n\n    Parameters\n    ----------\n    weld_obj : WeldObject\n        WeldObject to update.\n    data : numpy.ndarray or WeldObject or str\n        Data for which to get an id. If str, it is a placeholder or \'str\' literal.\n\n    Returns\n    -------\n    str\n        The id of the data, e.g. _inp0 for raw data, obj101 for WeldObject\n\n    """"""\n    obj_id = weld_obj.update(data)\n    if isinstance(data, WeldObject):\n        obj_id = data.obj_id\n        weld_obj.dependencies[obj_id] = data\n\n    return obj_id\n\n\ndef create_weld_object(data):\n    """"""Helper method to create a WeldObject and update with data.\n\n    Parameters\n    ----------\n    data : numpy.ndarray or WeldObject or str\n        Data to include in newly created object. If str, it is a placeholder or \'str\' literal.\n\n    Returns\n    -------\n    (str, WeldObject)\n        Object id for the data to use in the Weld code and\n        the WeldObject updated with the data.\n\n    """"""\n    weld_obj = create_empty_weld_object()\n    obj_id = get_weld_obj_id(weld_obj, data)\n\n    return obj_id, weld_obj\n\n\ndef create_placeholder_weld_object(data):\n    """"""Helper method that creates a WeldObject that evaluates to itself.\n\n    Parameters\n    ----------\n    data : numpy.ndarray or WeldObject or str\n        Data to wrap around. If str, it is a placeholder or \'str\' literal.\n\n    Returns\n    -------\n    WeldObject\n        WeldObject wrapped around data.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(data)\n    weld_obj.weld_code = \'{}\'.format(str(obj_id))\n\n    return weld_obj\n\n\ndef _extract_placeholder_weld_objects_at_index(dependency_name, length, readable_text, index):\n    """"""Helper method that creates a WeldObject for each component of dependency.\n\n    Parameters\n    ----------\n    dependency_name : str\n        The name of the dependency evaluating to a tuple.\n    length : int\n        Number of components to create WeldObjects for\n    readable_text : str\n        Used when creating the placeholders in WeldObject.context.\n    index : str\n        Representing a tuple of ints used to select from the struct.\n\n    Returns\n    -------\n    list of WeldObject\n\n    """"""\n    weld_objects = []\n\n    for i in range(length):\n        fake_weld_input = Cache.create_fake_array_input(dependency_name, readable_text + \'_\' + str(i), eval(index))\n        obj_id, weld_obj = create_weld_object(fake_weld_input)\n        weld_obj.weld_code = \'{}\'.format(obj_id)\n        weld_objects.append(weld_obj)\n\n        Cache.cache_fake_input(obj_id, fake_weld_input)\n\n    return weld_objects\n\n\ndef extract_placeholder_weld_objects(dependency_name, length, readable_text):\n    return _extract_placeholder_weld_objects_at_index(dependency_name, length, readable_text, \'(i, )\')\n\n\ndef extract_placeholder_weld_objects_from_index(dependency_name, length, readable_text, index):\n    return _extract_placeholder_weld_objects_at_index(dependency_name, length, readable_text, \'({}, i)\'.format(index))\n\n\ndef struct_of(text, array):\n    return \'{{{}}}\'.format(\', \'.join(text.format(i=i, e=elem) for i, elem in enumerate(array)))\n\n\n# an attempt to avoid expensive casting\ndef to_weld_literal(scalar, weld_type):\n    """"""Return scalar formatted for Weld.\n\n    Parameters\n    ----------\n    scalar : {int, float, str, bool}\n        Scalar data to convert to weld literal.\n    weld_type : WeldType\n        Desired Weld type.\n\n    Returns\n    -------\n    str\n        String of the scalar to use in Weld code.\n\n    Examples\n    --------\n    >>> to_weld_literal(4, WeldLong())\n    \'4L\'\n\n    """"""\n    try:\n        if isinstance(scalar, int):\n            if isinstance(weld_type, WeldInt16):\n                return \'{}si\'.format(str(scalar))\n            elif isinstance(weld_type, WeldInt):\n                return str(scalar)\n            elif isinstance(weld_type, WeldLong):\n                return \'{}L\'.format(str(scalar))\n            elif isinstance(weld_type, WeldFloat):\n                return \'{}f\'.format(str(scalar))\n            elif isinstance(weld_type, WeldDouble):\n                return \'{}.0\'.format(str(scalar))\n            else:\n                raise TypeError()\n        elif isinstance(scalar, float):\n            if isinstance(weld_type, WeldFloat):\n                return \'{}f\'.format(str(scalar))\n            elif isinstance(weld_type, WeldDouble):\n                return str(scalar)\n            else:\n                raise TypeError()\n        elif isinstance(scalar, str):\n            if str(weld_type) == \'vec[i8]\':\n                return str(scalar)\n            else:\n                raise TypeError()\n        elif isinstance(scalar, bool):\n            if isinstance(weld_type, WeldBit):\n                return str(scalar).lower()\n            else:\n                raise TypeError()\n        else:\n            raise TypeError()\n    except TypeError:\n        raise TypeError(\'Cannot convert scalar:{} to type:{}\'.format(scalar, weld_type))\n\n\ndef weld_combine_scalars(scalars, weld_type):\n    """"""Combine column-wise aggregations (so resulting scalars) into a single array.\n\n    Parameters\n    ----------\n    scalars : tuple of WeldObjects\n        WeldObjects to combine.\n    weld_type : WeldType\n        The Weld type of the result. Currently expecting scalars to be of the same type.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    weld_obj = create_empty_weld_object()\n    obj_ids = (get_weld_obj_id(weld_obj, scalar) for scalar in scalars)\n\n    merges = \'\\n\'.join((\'let res = merge(res, {});\'.format(obj_id) for obj_id in obj_ids))\n\n    weld_template = """"""let res = appender[{type}];\n{merges}\nresult(res)\n""""""\n\n    weld_obj.weld_code = weld_template.format(type=weld_type,\n                                              merges=merges)\n\n    return weld_obj\n\n\n_numeric_types = {WeldInt16(), WeldInt(), WeldLong(), WeldFloat(), WeldDouble(), WeldBit()}\n\n\ndef is_numeric(weld_type):\n    """"""Checks whether the WeldType is a numeric type.\n\n    Parameters\n    ----------\n    weld_type : WeldType\n        To check.\n\n    Returns\n    -------\n    bool\n        Whether the Weld type is numeric or not.\n\n    """"""\n    return weld_type in _numeric_types\n\n\ndef _not_possible_to_cast(scalar, to_weld_type):\n    return not isinstance(scalar, (int, float, WeldObject)) or \\\n           isinstance(scalar, bool) or \\\n           not is_numeric(to_weld_type)\n\n\ndef weld_cast_scalar(scalar, to_weld_type):\n    """"""Returns the scalar casted to the request Weld type.\n\n    Parameters\n    ----------\n    scalar : {int, float, WeldObject}\n        Input array.\n    to_weld_type : WeldType\n        Type of each element in the input array.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    if _not_possible_to_cast(scalar, to_weld_type):\n        raise TypeError(\'Cannot cast scalar of type={} to type={}\'.format(type(scalar), to_weld_type))\n\n    weld_obj = create_empty_weld_object()\n    if isinstance(scalar, WeldObject):\n        scalar = get_weld_obj_id(weld_obj, scalar)\n\n    weld_template = \'{type}({scalar})\'\n\n    weld_obj.weld_code = weld_template.format(scalar=scalar,\n                                              type=to_weld_type)\n\n    return weld_obj\n\n\n# this is fairly common so make separate method\ndef weld_cast_double(scalar):\n    return weld_cast_scalar(scalar, WeldDouble())\n\n\ndef weld_cast_array(array, weld_type, to_weld_type):\n    """"""Cast array to a different type.\n\n    Parameters\n    ----------\n    array : numpy.ndarray or WeldObject\n        Input data.\n    weld_type : WeldType\n        Type of each element in the input array.\n    to_weld_type : WeldType\n        Desired type.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    if not is_numeric(weld_type) or not is_numeric(to_weld_type):\n        raise TypeError(\'Cannot cast array of type={} to type={}\'.format(weld_type, to_weld_type))\n\n    obj_id, weld_obj = create_weld_object(array)\n\n    weld_template = """"""map(\n    {array},\n    |e: {type}|\n        {to}(e)\n)""""""\n\n    weld_obj.weld_code = weld_template.format(array=obj_id,\n                                              type=weld_type,\n                                              to=to_weld_type)\n\n    return weld_obj\n\n\n# essentially switching from columns to rows ~ axis 0 to 1\ndef weld_arrays_to_vec_of_struct(arrays, weld_types):\n    """"""Create a vector of structs from multiple vectors.\n\n    Parameters\n    ----------\n    arrays : list of (numpy.ndarray or WeldObject)\n        Arrays to put in a struct.\n    weld_types : list of WeldType\n        The Weld types of the arrays in the same order.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    weld_obj = create_empty_weld_object()\n    obj_ids = [get_weld_obj_id(weld_obj, array) for array in arrays]\n\n    arrays = \'zip({})\'.format(\', \'.join(obj_ids)) if len(obj_ids) > 1 else \'{}\'.format(obj_ids[0])\n    input_types = struct_of(\'{e}\', weld_types) if len(obj_ids) > 1 else \'{}\'.format(weld_types[0])\n    res_types = struct_of(\'{e}\', weld_types)\n    to_merge = \'e\' if len(obj_ids) > 1 else \'{e}\'\n\n    weld_template = """"""result(\n    for({arrays},\n        appender[{res_types}],\n        |b: appender[{res_types}], i: i64, e: {input_types}|\n            merge(b, {to_merge})\n    )    \n)""""""\n\n    weld_obj.weld_code = weld_template.format(arrays=arrays,\n                                              input_types=input_types,\n                                              res_types=res_types,\n                                              to_merge=to_merge)\n\n    return weld_obj\n\n\n# essentially switching from rows to columns ~ axis 1 to 0\ndef weld_vec_of_struct_to_struct_of_vec(vec_of_structs, weld_types):\n    """"""Create a struct of vectors.\n\n    Parameters\n    ----------\n    vec_of_structs : WeldObject\n        Encoding a vector of structs.\n    weld_types : list of WeldType\n        The Weld types of the arrays in the same order.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(vec_of_structs)\n\n    appenders = struct_of(\'appender[{e}]\', weld_types)\n    types = struct_of(\'{e}\', weld_types)\n    merges = struct_of(\'merge(b.${i}, e.${i})\', weld_types)\n    result = struct_of(\'result(vecs.${i})\', weld_types)\n\n    weld_template = """"""let vecs = for({vec_of_struct},\n    {appenders},\n    |b: {appenders}, i: i64, e: {types}|\n        {merges}\n);\n{result}\n""""""\n\n    weld_obj.weld_code = weld_template.format(vec_of_struct=obj_id,\n                                              appenders=appenders,\n                                              types=types,\n                                              merges=merges,\n                                              result=result)\n\n    return weld_obj\n\n\ndef weld_select_from_struct(struct_of_vec, index_to_select):\n    """"""Select a single vector from the struct of vectors.\n\n    Parameters\n    ----------\n    struct_of_vec : WeldObject\n        Encoding a struct of vectors.\n    index_to_select : int\n        Which vec to select from the struct.\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    obj_id, weld_obj = create_weld_object(struct_of_vec)\n\n    weld_template = \'{struct}.${index}\'\n\n    weld_obj.weld_code = weld_template.format(struct=obj_id,\n                                              index=index_to_select)\n\n    return weld_obj\n\n\n# TODO: support multiple values\ndef weld_data_to_dict(keys, keys_weld_types, values, values_weld_types):\n    """"""Adds the key-value pairs in a dictionary. Overlapping keys are max-ed.\n\n    Note this cannot be evaluated!\n\n    Parameters\n    ----------\n    keys : list of (numpy.ndarray or WeldObject)\n    keys_weld_types : list of WeldType\n    values : numpy.ndarray or WeldObject\n    values_weld_types : WeldType\n\n    Returns\n    -------\n    WeldObject\n        Representation of this computation.\n\n    """"""\n    weld_obj_keys = weld_arrays_to_vec_of_struct(keys, keys_weld_types)\n\n    weld_obj = create_empty_weld_object()\n    keys_obj_id = get_weld_obj_id(weld_obj, weld_obj_keys)\n    values_obj_id = get_weld_obj_id(weld_obj, values)\n\n    keys_types = struct_of(\'{e}\', keys_weld_types)\n    values_types = values_weld_types\n\n    weld_template = """"""result(\n    for(\n        zip({keys}, {values}),\n        dictmerger[{keys_types}, {values_types}, max],\n        |b: dictmerger[{keys_types}, {values_types}, max], i: i64, e: {{{keys_types}, {values_types}}}|\n            merge(b, e)\n    )\n)""""""\n\n    weld_obj.weld_code = weld_template.format(keys=keys_obj_id,\n                                              values=values_obj_id,\n                                              keys_types=keys_types,\n                                              values_types=values_types)\n\n    return weld_obj\n'"
doc/source/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath(\'../..\'))\n\n# doctest runs in the source directories, not at install location, so the .so is missing\n# (unless changing the path above to point to the install location)\n# TODO: maybe not rebuild every time; should not even have to, but should use installed code; not a problem when\n# TODO installed with -e, i.e. IN this download folder\nos.system(\'make -C ../../baloo/weld/convertors\')\n\n\n# -- Project information -----------------------------------------------------\n\nproject = \'Baloo\'\ncopyright = \'2018, Radu Jica\'\nauthor = \'Radu Jica\'\n\n# The short X.Y version\nversion = \'\'\n# The full version, including alpha/beta/rc tags\nrelease = \'0.0.1\'\n\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.doctest\',\n    \'sphinx.ext.coverage\',\n    \'sphinx.ext.viewcode\',\n    \'sphinx.ext.githubpages\',\n    \'sphinx.ext.intersphinx\',\n    \'numpydoc\'\n]\n\nnumpydoc_show_class_members = False\n\nintersphinx_mappings = {\n    \'Python 3.5\': (\'https://docs.python.org/3.5\', None),\n    \'NumPy [latest]\': (\'http://docs.scipy.org/doc/numpy/\', None),\n    \'Pandas [latest]\': (\'http://pandas.pydata.org/pandas-docs/stable/\', None)\n}\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path .\nexclude_patterns = []\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'alabaster\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don\'t match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``[\'localtoc.html\', \'relations.html\', \'sourcelink.html\',\n# \'searchbox.html\']``.\n#\n# html_sidebars = {}\n\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'Baloodoc\'\n\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'Baloo.tex\', \'Baloo Documentation\',\n     \'Radu Jica\', \'manual\'),\n]\n\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'baloo\', \'Baloo Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'Baloo\', \'Baloo Documentation\',\n     author, \'Baloo\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n\n# -- Options for Epub output -------------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = project\nepub_author = author\nepub_publisher = author\nepub_copyright = copyright\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#\n# epub_identifier = \'\'\n\n# A unique identification for the text.\n#\n# epub_uid = \'\'\n\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = [\'search.html\']\n\n\n# -- Extension configuration -------------------------------------------------\n'"
tests/core/__init__.py,0,b''
tests/core/test_empty.py,5,"b'import numpy as np\nimport pytest\n\nfrom baloo import Index, Series, RangeIndex, DataFrame\nfrom .indexes.utils import assert_indexes_equal\nfrom .test_frame import assert_dataframe_equal\nfrom .test_series import assert_series_equal\n\n\nclass TestEmptyDataFrame(object):\n    def test_aggregation_empty(self, df_empty):\n        assert_series_equal(df_empty.min(), Series(np.empty(0)))\n\n    @pytest.mark.parametrize(\'op,expected\', [\n        (\'df < 2\', \'df\'),\n        (\'df[2:]\', \'df\'),\n        (\'df * 2\', \'df\'),\n        (\'df.head()\', \'df\'),\n        (\'df.tail()\', \'df\'),\n        (\'df.sort_index()\', \'df\'),\n        (\'df.reset_index()\', \'DataFrame({""index"": np.empty(0, dtype=np.int64)}, RangeIndex(0, 0, 1))\')\n    ])\n    def test_empty_ops(self, df_empty, op, expected):\n        df = df_empty\n        assert_dataframe_equal(eval(op), eval(expected))\n\n    @pytest.mark.parametrize(\'op,exception\', [\n        (\'df.agg([""mean"", ""var""])\', ValueError),\n        (\'df[""a""]\', KeyError),\n        (\'df[[""a"", ""b""]]\', KeyError),\n        (\'df.drop(""a"")\', KeyError),\n        (\'df.drop([""a"", ""b""])\', KeyError)\n    ])\n    def test_empty_exceptions(self, df_empty, op, exception):\n        df = df_empty\n\n        with pytest.raises(exception):\n            eval(op)\n\n    def test_keys_empty(self, df_empty):\n        assert_indexes_equal(df_empty.keys(), Index(np.empty(0, dtype=np.dtype(\'S\'))))\n\n\ndef test_empty_series_init():\n    assert_series_equal(Series(), Series(np.empty(0), RangeIndex(0, 0, 1), np.dtype(np.float64)))\n\n\ndef test_empty_dataframe_init():\n    assert_dataframe_equal(DataFrame(), DataFrame({}, Index(np.empty(0, dtype=np.int64))))\n'"
tests/core/test_frame.py,86,"b""from collections import OrderedDict\n\nimport numpy as np\nimport pytest\n\nfrom baloo import DataFrame, Index, Series, MultiIndex\nfrom .indexes.utils import assert_indexes_equal\nfrom .test_series import assert_series_equal\n\n\ndef assert_dataframe_equal(actual, expected, almost=None, sort=False):\n    actual = actual.evaluate()\n    expected = expected.evaluate()\n\n    assert actual._length == expected._length\n    assert len(actual) == len(expected)\n    assert_series_equal(actual.dtypes, expected.dtypes, sort=sort)\n    assert_indexes_equal(actual.index, expected.index, sort=sort)\n    assert_indexes_equal(actual.columns, expected.columns)\n    assert len(actual._data) == len(expected._data)\n    assert actual._data.keys() == expected._data.keys()\n    for column_name in actual:\n        assert_series_equal(actual._data[column_name], expected._data[column_name], almost=almost, sort=sort)\n\n\n# TODO: fix |S11!!\nclass TestDataFrame(object):\n    def test_init_list(self):\n        data = [1, 2, 3]\n        actual = DataFrame({'a': data})\n        expected = DataFrame({'a': np.array(data)})\n\n        assert_dataframe_equal(actual, expected)\n\n    # just testing if they don't crash\n    def test_repr_str(self, df_small):\n        df = df_small.evaluate()\n        repr(df)\n        str(df)\n\n    @pytest.mark.parametrize('size', [10, 1001])\n    def test_evaluate(self, size, data_str):\n        data_a = np.arange(size)\n        data_b = np.random.choice(data_str, size)\n        actual = DataFrame({'a': data_a, 'b': data_b})\n\n        actual = actual.evaluate()\n        assert len(actual) == size\n        repr(actual)\n        str(actual)\n\n        expected = DataFrame({'a': data_a, 'b': data_b}, Index(np.arange(size)))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_len_lazy(self, series_i64):\n        size = 5\n        df = DataFrame({'a': series_i64})\n\n        assert df._length is None\n        assert len(df) == size\n        assert df._length == size\n\n    def test_getitem_str(self, df_small, data_f32, index_i64):\n        actual = df_small['a']\n        expected = Series(data_f32, index_i64, np.dtype(np.float32), 'a')\n\n        assert_series_equal(actual, expected)\n\n        with pytest.raises(KeyError):\n            var = df_small['z']\n\n    def test_getitem_list(self, df_small, data_f32, data_str):\n        actual = df_small[['a', 'c']]\n        expected = DataFrame(OrderedDict((('a', data_f32), ('c', data_str))))\n\n        assert_dataframe_equal(actual, expected)\n\n        with pytest.raises(TypeError):\n            result = df_small[[1]]\n\n        with pytest.raises(KeyError):\n            result = df_small[['z']]\n\n    def test_comparison(self, df_small, index_i64):\n        actual = df_small < 3\n        expected = DataFrame(OrderedDict((('a', np.array([True, True, False, False, False])),\n                                          ('b', np.array([True, True, False, False, False])))),\n                             index_i64)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_filter(self, df_small):\n        actual = df_small[Series(np.array([False, True, True, False, False]))]\n        data = [2, 3]\n        expected = DataFrame(OrderedDict((('a', np.array(data, dtype=np.float32)),\n                                          ('b', np.array(data)),\n                                          ('c', np.array(['Abc', 'goosfraba'], dtype=np.dtype('|S11'))))),\n                             Index(np.array([1, 2])))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_slice(self, df_small):\n        actual = df_small[1:3]\n        data = [2, 3]\n        expected = DataFrame(OrderedDict((('a', np.array(data, dtype=np.float32)),\n                                          ('b', np.array(data)),\n                                          ('c', np.array(['Abc', 'goosfraba'], dtype=np.dtype('|S11'))))),\n                             Index(np.array([1, 2])))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_setitem_new_col(self, data_f32, series_i64, index_i64):\n        actual = DataFrame(OrderedDict({'a': data_f32}))\n\n        actual['b'] = series_i64\n        expected = DataFrame(OrderedDict((('a', data_f32),\n                                          ('b', series_i64))),\n                             index_i64)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_setitem_existing_col(self, data_f32, series_i64, data_str, index_i64):\n        actual = DataFrame(OrderedDict((('a', data_f32),\n                                        ('b', data_str))))\n\n        actual['b'] = series_i64\n        expected = DataFrame(OrderedDict((('a', data_f32),\n                                          ('b', series_i64))),\n                             index_i64)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_setitem_alignment_needed(self, data_f32, index_i64):\n        df = DataFrame({'a': data_f32}, index_i64)\n\n        df['b'] = Series(np.array([4, 7, 5, 6, 8]), Index(np.array([0, 3, 1, 2, 5])))\n        actual = df\n        expected = DataFrame({'a': data_f32,\n                              'b': np.array([4, 5, 6, 7, -999])},\n                             index_i64)\n\n        # so is WeldObject which was aligned\n        assert not isinstance(df['b'].values, np.ndarray)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_setitem_alignment_not_needed(self, data_f32, data_i64, index_i64):\n        df = DataFrame({'a': data_f32}, index_i64)\n\n        df['b'] = Series(data_i64, index_i64)\n\n        # so was directly added, no alignment\n        assert isinstance(df['b'].values, np.ndarray)\n\n    def test_head(self, df_small):\n        actual = df_small.head(2)\n        data = [1, 2]\n        expected = DataFrame(OrderedDict((('a', np.array(data, dtype=np.float32)),\n                                          ('b', np.array(data)),\n                                          ('c', np.array(['a', 'Abc'], dtype=np.dtype('|S11'))))),\n                             Index(np.array([0, 1])))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_tail(self, df_small):\n        actual = df_small.tail(2)\n        data = [4, 5]\n        expected = DataFrame(OrderedDict((('a', np.array(data, dtype=np.float32)),\n                                          ('b', np.array(data)),\n                                          ('c', np.array(['   dC  ', 'secrETariat'], dtype=np.dtype('|S11'))))),\n                             Index(np.array([3, 4])))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_iloc_indices(self, df_small):\n        indices = Series(np.array([0, 2, 3]))\n\n        actual = df_small.iloc[indices]\n        data = [1, 3, 4]\n        expected = DataFrame(OrderedDict((('a', np.array(data, dtype=np.float32)),\n                                          ('b', np.array(data)),\n                                          ('c', np.array(['a', 'goosfraba', '   dC  '], dtype=np.dtype('|S11'))))),\n                             Index(np.array([0, 2, 3])))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_keys(self, df_small, df_small_columns):\n        assert_indexes_equal(df_small.keys(), df_small_columns)\n\n    def test_op_array(self, df_small, index_i64, op_array_other):\n        actual = df_small * [2, 3]\n        expected = DataFrame(OrderedDict((('a', np.array([2, 4, 6, 8, 10], dtype=np.float32)),\n                                          ('b', np.array([3, 6, 9, 12, 15])))),\n                             index_i64)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_op_scalar(self, df_small, index_i64):\n        actual = df_small * 2\n        data = [2, 4, 6, 8, 10]\n        expected = DataFrame(OrderedDict((('a', np.array(data, dtype=np.float32)),\n                                          ('b', np.array(data)))),\n                             index_i64)\n\n        assert_dataframe_equal(actual, expected)\n\n    @pytest.mark.parametrize('aggregation, expected_data', [\n        ('min', np.array([1., 1.])),\n        ('max', np.array([5., 5.])),\n        ('sum', np.array([15., 15.])),\n        ('prod', np.array([120., 120.])),\n        ('count', np.array([5., 5.])),\n        ('var', np.array([2.5, 2.5])),\n        ('std', np.array([1.581139, 1.581139]))\n    ])\n    def test_aggregations(self, aggregation, expected_data, df_small):\n        actual = getattr(df_small, aggregation)()\n        expected = Series(expected_data, Index(np.array(['a', 'b'], dtype=np.bytes_)))\n\n        assert_series_equal(actual, expected, 5)\n\n    def test_agg(self, df_small):\n        aggregations = ['max', 'var', 'count', 'mean']\n\n        actual = df_small.agg(aggregations)\n        expected = DataFrame(OrderedDict((('a', np.array([5, 2.5, 5, 3], dtype=np.float64)),\n                                          ('b', np.array([5, 2.5, 5, 3], dtype=np.float64)))),\n                             Index(np.array(aggregations, dtype=np.bytes_), np.dtype(np.bytes_)))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_rename(self, df_small, data_f32, series_i64, data_str, index_i64):\n        actual = df_small.rename({'a': 'd', 'd': 'nooo'})\n        expected = DataFrame(OrderedDict((('d', data_f32),\n                                          ('b', series_i64),\n                                          ('c', data_str))),\n                             index_i64)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_drop_single(self, df_small, data_f32, series_i64, index_i64):\n        actual = df_small.drop('c')\n        expected = DataFrame(OrderedDict((('a', data_f32),\n                                          ('b', series_i64))),\n                             index_i64)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_drop_multi(self, df_small, series_i64, index_i64):\n        actual = df_small.drop(['a', 'c'])\n        expected = DataFrame({'b': series_i64})\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_reset_index(self, df_small, index_i64, data_f32, series_i64, data_str):\n        actual = df_small.reset_index()\n        expected = DataFrame(OrderedDict((('index', np.arange(5)),\n                                          ('a', data_f32),\n                                          ('b', series_i64),\n                                          ('c', data_str))),\n                             index_i64)\n\n        assert_dataframe_equal(actual, expected)\n\n    @pytest.mark.parametrize('names,expected_names', [\n        (None, ['level_0', 'level_1']),\n        (['i1', 'i2'], ['i1', 'i2'])\n    ])\n    def test_reset_multi_index(self, data_f32, data_i64, data_str, index_i64, names, expected_names):\n        df = DataFrame(OrderedDict({'c': data_str}),\n                       MultiIndex([data_f32, data_i64], names=names))\n\n        actual = df.reset_index()\n        expected = DataFrame(OrderedDict(((expected_names[0], data_f32),\n                                          (expected_names[1], data_i64),\n                                          ('c', data_str))),\n                             index_i64)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_set_index(self, df_small, data_f32, data_i64, data_str):\n        actual = df_small.set_index('b')\n        expected = DataFrame(OrderedDict((('a', data_f32),\n                                          ('c', data_str))),\n                             Index(data_i64, np.dtype(np.int64), 'b'))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_set_multi_index(self, df_small, data_f32, data_i64, data_str):\n        actual = df_small.set_index(['b', 'c'])\n        expected = DataFrame({'a': data_f32},\n                             MultiIndex([Index(data_i64, np.dtype(np.int64), 'b'),\n                                         Index(data_str, name='c')],\n                                        ['b', 'c']))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_sort_index_index_ascending(self, data_f32, series_i64):\n        data = [data_f32, series_i64]\n        df = DataFrame(OrderedDict((('a', data[0]),\n                                    ('b', data[1]))),\n                       Index(np.array([3, 1, 2, 5, 4])))\n\n        actual = df.sort_index()\n\n        expected_index = Index(np.arange(1, 6), np.dtype(np.int64))\n        expected_data = [Series(np.array([2, 3, 1, 5, 4], dtype=np.float32), expected_index, np.dtype(np.float32), 'a'),\n                         Series(np.array([2, 3, 1, 5, 4], dtype=np.int64), expected_index, np.dtype(np.int64), 'b')]\n        expected = DataFrame(OrderedDict((('a', expected_data[0]),\n                                          ('b', expected_data[1]))),\n                             expected_index)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_sort_index_index_descending(self, data_f32, series_i64):\n        data = [data_f32, series_i64]\n        df = DataFrame(OrderedDict((('a', data[0]),\n                                    ('b', data[1]))),\n                       Index(np.array([3, 1, 2, 5, 4])))\n\n        actual = df.sort_index(ascending=False)\n\n        expected_index = Index(np.arange(5, 0, -1), np.dtype(np.int64))\n        expected_data = [Series(np.array([4, 5, 1, 3, 2], dtype=np.float32), expected_index, np.dtype(np.float32), 'a'),\n                         Series(np.array([4, 5, 1, 3, 2], dtype=np.int64), expected_index, np.dtype(np.int64), 'b')]\n        expected = DataFrame(OrderedDict((('a', expected_data[0]),\n                                          ('b', expected_data[1]))),\n                             expected_index)\n\n        assert_dataframe_equal(actual, expected)\n\n    # TODO: uncomment & refactor when implemented\n    # def test_sort_index_multi_index_ascending(self):\n    #     data = [np.array([1, 2, 3, 4, 5], dtype=np.float32), Series(np.arange(5))]\n    #     df = DataFrame(OrderedDict((('a', data[0]),\n    #                                 ('b', data[1]))),\n    #                    MultiIndex([np.array([2, 3, 3, 1, 1]), np.array([2, 2, 1, 0, 3], dtype=np.float64)]))\n    #\n    #     actual = df.sort_index()\n    #     expected_index = MultiIndex([np.array([1, 1, 2, 3, 3]), np.array([0, 3, 2, 1, 2], dtype=np.float64)])\n    #     expected_data = [Series(np.array([4, 5, 1, 3, 2], dtype=np.float32), expected_index, np.dtype(np.float32), 'a'),\n    #                      Series(np.array([3, 4, 0, 2, 1], dtype=np.int64), expected_index, np.dtype(np.int64), 'b')]\n    #     expected = DataFrame(OrderedDict((('a', expected_data[0]),\n    #                                       ('b', expected_data[1]))),\n    #                          expected_index)\n    #\n    #     assert_dataframe_equal(actual, expected)\n\n    def test_sort_values(self, data_f32, series_i64, data_i64):\n        data = [np.array([3, 1, 2, 5, 4], dtype=np.float32), series_i64]\n        df = DataFrame(OrderedDict((('a', data[0]),\n                                    ('b', data[1]))),\n                       Index(data_i64))\n\n        actual = df.sort_values('a')\n\n        expected_index = Index(np.array([2, 3, 1, 5, 4]), np.dtype(np.int64))\n        expected_data = [Series(data_f32, expected_index, np.dtype(np.float32), 'a'),\n                         Series(np.array([2, 3, 1, 5, 4], dtype=np.int64), expected_index, np.dtype(np.int64), 'b')]\n        expected = DataFrame(OrderedDict((('a', expected_data[0]),\n                                          ('b', expected_data[1]))),\n                             expected_index)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_drop_duplicates_all(self, index_i64):\n        df = DataFrame(OrderedDict((('a', np.array([0, 1, 1, 2, 3], dtype=np.float32)),\n                                    ('b', [4, 5, 5, 6, 6]))),\n                       index_i64)\n\n        actual = df.drop_duplicates()\n        expected = DataFrame(OrderedDict((('a', np.array([0, 1, 2, 3], dtype=np.float32)),\n                                          ('b', [4, 5, 6, 6]))),\n                             Index([0, 1, 3, 4]))\n\n        assert_dataframe_equal(actual, expected, sort=True)\n\n    def test_drop_duplicates_subset(self, index_i64):\n        df = DataFrame(OrderedDict((('a', np.array([0, 1, 1, 2, 3], dtype=np.float32)),\n                                    ('b', [4, 5, 5, 6, 6]))),\n                       index_i64)\n\n        actual = df.drop_duplicates(subset=['b'])\n        expected = DataFrame(OrderedDict((('a', np.array([0, 1, 2], dtype=np.float32)),\n                                          ('b', [4, 5, 6]))),\n                             Index([0, 1, 3]))\n\n        assert_dataframe_equal(actual, expected, sort=True)\n\n    # TODO: update the following tests with fixture (also series and base)\n    def test_isna(self, index_i64):\n        df = DataFrame(OrderedDict((('a', np.array([0, 1, -999, 2, -999], dtype=np.float32)),\n                                    ('b', [4, -999, -999, 6, 6]))),\n                       index_i64)\n\n        actual = df.isna()\n        expected = DataFrame(OrderedDict((('a', np.array([False, False, True, False, True])),\n                                          ('b', [False, True, True, False, False]))),\n                             index_i64)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_dropna(self, index_i64):\n        df = DataFrame(OrderedDict((('a', np.array([0, 1, -999, 2, -999], dtype=np.float32)),\n                                    ('b', [4, -999, -999, 6, 6]))),\n                       index_i64)\n\n        actual = df.dropna()\n        expected = DataFrame(OrderedDict((('a', np.array([0, 2], dtype=np.float32)),\n                                          ('b', [4, 6]))),\n                             Index([0, 3]))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_dropna_subset(self, index_i64):\n        df = DataFrame(OrderedDict((('a', np.array([0, 1, -999, 2, -999], dtype=np.float32)),\n                                    ('b', [4, -999, -999, 6, 6]))),\n                       index_i64)\n\n        actual = df.dropna(subset=['a'])\n        expected = DataFrame(OrderedDict((('a', np.array([0, 1, 2], dtype=np.float32)),\n                                          ('b', [4, -999, 6]))),\n                             Index([0, 1, 3]))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_fillna_scalar(self, index_i64):\n        df = DataFrame(OrderedDict((('a', np.array([0, 1, -999, 2, -999], dtype=np.float32)),\n                                    ('b', [4, -999, -999, 6, 6]))),\n                       index_i64)\n\n        actual = df.fillna(15)\n        expected = DataFrame(OrderedDict((('a', np.array([0, 1, 15, 2, 15], dtype=np.float32)),\n                                          ('b', [4, 15, 15, 6, 6]))),\n                             index_i64)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_fillna_dict(self, index_i64):\n        df = DataFrame(OrderedDict((('a', np.array([0, 1, -999, 2, -999], dtype=np.float32)),\n                                    ('b', [4, -999, -999, 6, 6]))),\n                       index_i64)\n\n        actual = df.fillna({'a': 15})\n        expected = DataFrame(OrderedDict((('a', np.array([0, 1, 15, 2, 15], dtype=np.float32)),\n                                          ('b', [4, -999, -999, 6, 6]))),\n                             index_i64)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_astype_dtype(self, df1, data_i64, index_i64_2):\n        actual = df1.astype(np.dtype(np.int64))\n        expected = DataFrame(OrderedDict((('a', np.arange(5)),\n                                          ('b', data_i64))),\n                             index_i64_2)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_astype_dict(self, df1, data_f32, index_i64_2):\n        actual = df1.astype({'a': np.dtype(np.float32)})\n        expected = DataFrame(OrderedDict((('a', np.arange(5, dtype=np.float32)),\n                                          ('b', data_f32))),\n                             index_i64_2)\n\n        assert_dataframe_equal(actual, expected)\n"""
tests/core/test_functions.py,7,"b""import numpy as np\nimport pytest\n\nimport baloo as bl\nfrom .test_series import assert_series_equal\n\n\nclass TestUnary(object):\n    def test_sqrt(self, series_f32, index_i64):\n        actual = series_f32.apply(bl.sqrt)\n        expected = bl.Series(np.array([1., 1.414214, 1.732051, 2., 2.236068], dtype=np.float32), index_i64)\n\n        assert_series_equal(actual, expected, almost=5)\n\n\nclass TestRaw(object):\n    def test_deco_no_args(self, series_unsorted, series_f32):\n        actual = series_unsorted.apply(bl.sort)\n        expected = series_f32\n\n        assert_series_equal(actual, expected)\n\n    def test_deco_good_args(self, series_unsorted, series_f32):\n        actual = series_unsorted.apply(bl.sort, kind='q')\n        expected = series_f32\n\n        assert_series_equal(actual, expected)\n\n    def test_deco_bad_args(self, series_unsorted):\n        with pytest.raises(ValueError):\n            series_unsorted.apply(bl.sort, kind='bla')\n\n    def test_deco_unevaluated_data(self, series_unsorted):\n        with pytest.raises(TypeError):\n            series_unsorted.apply(bl.sqrt).apply(bl.sort, kind='bla')\n\n    def test_deco_inline_no_args(self, series_unsorted, series_f32):\n        actual = series_unsorted.apply(bl.raw(np.sort))\n        expected = series_f32\n\n        assert_series_equal(actual, expected)\n\n    def test_deco_inline_good_args(self, series_unsorted, series_f32):\n        actual = series_unsorted.apply(bl.raw(np.sort, kind='quicksort'))\n        expected = series_f32\n\n        assert_series_equal(actual, expected)\n\n    def test_deco_inline_bad_args(self, series_unsorted):\n        with pytest.raises(ValueError):\n            series_unsorted.apply(bl.raw(np.sort, kind='bla'))\n\n    def test_deco_inline_unevaluated_data(self, series_unsorted):\n        with pytest.raises(TypeError):\n            series_unsorted.apply(bl.sqrt).apply(bl.raw(np.sort, kind='bla'))\n\n    def test_deco_inline_lambda(self, series_unsorted, series_f32):\n        actual = series_unsorted.apply(bl.raw(lambda x: np.sort(x, kind='q')))\n        expected = series_f32\n\n        assert_series_equal(actual, expected)\n\n    def test_deco_inline_lambda_bad_args(self, series_unsorted):\n        with pytest.raises(ValueError):\n            print(series_unsorted.apply(bl.raw(lambda x: np.sort(x, kind='bla'))))\n"""
tests/core/test_group.py,3,"b""from collections import OrderedDict\n\nimport numpy as np\n\nfrom baloo import DataFrame, Index, MultiIndex\nfrom .test_frame import assert_dataframe_equal\n\n\nclass TestGroupBy(object):\n    def test_groupby_single(self, index_i64, series_i64, df_dupl, df_dupl_exp_ind):\n        actual = df_dupl.groupby('b').sum()\n        expected = DataFrame(OrderedDict((('a', np.array([0, 2, 5], dtype=np.float32)),\n                                          ('c', [1, 5, 9]))),\n                             df_dupl_exp_ind)\n\n        assert_dataframe_equal(actual, expected, sort=True)\n\n    def test_groupby_single_mean(self, index_i64, series_i64, df_dupl, df_dupl_exp_ind):\n        actual = df_dupl.groupby('b').mean()\n        expected = DataFrame(OrderedDict((('a', [0., 1., 2.5]),\n                                          ('c', [1., 2.5, 4.5]))),\n                             df_dupl_exp_ind)\n\n        assert_dataframe_equal(actual, expected, sort=True)\n\n    def test_groupby_single_var(self, index_i64, series_i64, df_dupl, df_dupl_exp_ind):\n        actual = df_dupl.groupby('b').var()\n        expected = DataFrame(OrderedDict((('a', [0., 0., 0.5]),\n                                          ('c', [0., 0.5, 0.5]))),\n                             df_dupl_exp_ind)\n\n        assert_dataframe_equal(actual, expected, almost=5, sort=True)\n\n    def test_groupby_single_std(self, index_i64, series_i64, df_dupl, df_dupl_exp_ind):\n        actual = df_dupl.groupby('b').std()\n        expected = DataFrame(OrderedDict((('a', [0., 0., 0.707107]),\n                                          ('c', [0., 0.70711, 0.70711]))),\n                             df_dupl_exp_ind)\n\n        assert_dataframe_equal(actual, expected, almost=5, sort=True)\n\n    def test_groupby_single_size(self, index_i64, series_i64, df_dupl, df_dupl_exp_ind):\n        actual = df_dupl.groupby('b').size()\n        expected = DataFrame(OrderedDict((('a', [1, 2, 2]),\n                                          ('c', [1, 2, 2]))),\n                             df_dupl_exp_ind)\n\n        assert_dataframe_equal(actual, expected, sort=True)\n\n    def test_groupby_multi(self, index_i64, series_i64, df_dupl):\n        actual = df_dupl.groupby(['a', 'b']).min()\n        expected = DataFrame(OrderedDict({'c': [1, 2, 4, 5]}),\n                             MultiIndex([Index(np.array([0, 1, 2, 3], dtype=np.float32), np.dtype(np.float32), 'a'),\n                                         Index([4, 5, 6, 6], np.dtype(np.int64), 'b')], ['a', 'b']))\n\n        assert_dataframe_equal(actual, expected, sort=True)\n"""
tests/core/test_join.py,45,"b""from collections import OrderedDict\n\nimport numpy as np\n\nfrom baloo import DataFrame, Index, MultiIndex, Series\nfrom .test_frame import assert_dataframe_equal\n\n\n# TODO: fix |S4!!\nclass TestJoins(object):\n    def test_merge_sorted_unique_single_on_inner(self, df1, df2):\n        actual = df1.merge(df2, on='a')\n        expected = DataFrame(OrderedDict((('index', np.array([3, 5])),\n                                          ('b_x', np.array([2, 4], dtype=np.float32)),\n                                          ('d', np.array(['abc', 'def'], dtype=np.dtype('|S4'))),\n                                          ('b_y', Series(np.arange(3, 5, dtype=np.float32))),\n                                          ('c', np.arange(4, 6)))),\n                             Index(np.array([1, 3]), np.dtype(np.int64), 'a'))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_merge_sorted_unique_multi_on_inner(self, df1, df2):\n        actual = df1.merge(df2, on=['a', 'b'], is_on_sorted=True)\n        expected = DataFrame(OrderedDict((('index', np.array([5])),\n                                          ('d', np.array(['def'], dtype=np.dtype('|S4'))),\n                                          ('c', np.array([5])))),\n                             MultiIndex([np.array([3]), np.array([4], dtype=np.float32)], ['a', 'b']))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_merge_sorted_unique_single_on_left(self, df1, df2):\n        actual = df1.merge(df2, on='a', how='left')\n        expected = DataFrame(OrderedDict((('index', np.arange(2, 7)),\n                                          ('b_x', np.arange(1, 6, dtype=np.float32)),\n                                          ('d', np.array(['None', 'abc', 'None', 'def', 'None'], dtype=np.bytes_)),\n                                          ('b_y', Series(np.array([-999., 3., -999., 4., -999.], dtype=np.float32))),\n                                          ('c', np.array([-999, 4, -999, 5, -999])))),\n                             Index(np.arange(5), np.dtype(np.int64), 'a'))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_merge_sorted_unique_single_on_right(self, df1, df2):\n        actual = df1.merge(df2, on='a', how='right')\n        expected = DataFrame(OrderedDict((('index', np.array([3, 5, -999])),\n                                          ('b_x', np.array([2, 4, -999.], dtype=np.float32)),\n                                          ('d', np.array(['abc', 'def', 'efgh'], dtype=np.dtype('|S4'))),\n                                          ('b_y', Series(np.array([3., 4., 5.], dtype=np.float32))),\n                                          ('c', np.array([4, 5, 6])))),\n                             Index(np.array([1, 3, 5]), np.dtype(np.int64), 'a'))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_merge_sorted_unique_single_on_outer(self, df1, df2):\n        actual = df1.merge(df2, on='a', how='outer')\n        expected = DataFrame(OrderedDict((('index', np.array([2, 3, 4, 5, 6, -999])),\n                                          ('b_x', np.array([1, 2, 3, 4, 5, -999.], dtype=np.float32)),\n                                          ('d', np.array(['None', 'abc', 'None', 'def', 'None', 'efgh'], dtype=np.dtype('|S4'))),\n                                          ('b_y', Series(np.array([-999., 3., -999., 4., -999., 5.], dtype=np.float32))),\n                                          ('c', np.array([-999, 4, -999, 5, -999, 6])))),\n                             Index(np.arange(0, 6), np.dtype(np.int64), 'a'))\n\n        assert_dataframe_equal(actual, expected)\n\n    # seems unnecessary to run for all cases since join just delegates to merge\n    def test_join(self):\n        df1 = DataFrame(OrderedDict((('a', np.arange(5)), ('b', np.arange(1, 6, dtype=np.float64)))),\n                        Index(np.arange(0, 5)))\n        df2 = DataFrame(OrderedDict((('b', np.arange(3, 6, dtype=np.float32)), ('c', np.arange(4, 7)))),\n                        Index(np.array(np.array([1, 3, 5]))))\n\n        actual = df1.join(df2, lsuffix='_x')\n        expected = DataFrame(OrderedDict((('a', np.arange(5)),\n                                          ('b_x', np.arange(1, 6, dtype=np.float64)),\n                                          ('b', Series(np.array([-999., 3., -999., 4., -999.], dtype=np.float32))),\n                                          ('c', np.array([-999, 4, -999, 5, -999])))),\n                             Index(np.arange(0, 5), np.dtype(np.int64), 'index'))\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_merge_unsorted_unique_single_on_inner(self, df2, data_f32, index_i64_2):\n        df1 = DataFrame(OrderedDict((('a', Series(np.array([3, 2, 0, 4, 1]))),\n                                     ('b', np.array([4, 3, 1, 5, 2], dtype=np.float32)))),\n                        Index([5, 4, 2, 6, 3]))\n\n        actual = df1.merge(df2, on='a')\n        expected = DataFrame(OrderedDict((('index', np.array([3, 5])),\n                                          ('b_x', np.array([2, 4], dtype=np.float32)),\n                                          ('d', np.array(['abc', 'def'], dtype=np.dtype('|S4'))),\n                                          ('b_y', Series(np.arange(3, 5, dtype=np.float32))),\n                                          ('c', np.arange(4, 6)))),\n                             Index(np.array([1, 3]), np.dtype(np.int64), 'a'))\n\n        assert_dataframe_equal(actual, expected)\n"""
tests/core/test_pandas.py,0,"b""import pandas as pd\n\nfrom baloo import Index, MultiIndex, Series, DataFrame\nfrom .indexes.test_base import assert_index_equal\nfrom .indexes.test_multi import assert_multiindex_equal\nfrom .test_frame import assert_dataframe_equal\nfrom .test_series import assert_series_equal\n\n\nclass TestPandasConversions(object):\n    def test_from_pandas_index(self, index_i64):\n        pandas_index = pd.Index([0, 1, 2, 3, 4])\n\n        actual = Index.from_pandas(pandas_index)\n        expected = index_i64\n\n        assert_index_equal(actual, expected)\n\n    def test_from_pandas_multiindex(self):\n        pandas_index = pd.MultiIndex.from_product([[0, 1], [2., 3.]])\n\n        actual = MultiIndex.from_pandas(pandas_index)\n        expected = MultiIndex([[0, 0, 1, 1], [2., 3., 2., 3.]])\n\n        assert_multiindex_equal(actual, expected)\n\n    def test_from_pandas_series(self, data_i64, series_i64):\n        pandas_series = pd.Series(data_i64)\n\n        actual = Series.from_pandas(pandas_series)\n        expected = series_i64\n\n        assert_series_equal(actual, expected)\n\n    def test_from_pandas_df(self, data_f32, df1):\n        pandas_df = pd.DataFrame({'a': [0, 1, 2, 3, 4], 'b': data_f32}, pd.Index([2, 3, 4, 5, 6]))\n\n        actual = DataFrame.from_pandas(pandas_df)\n        expected = df1\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_to_pandas_index(self, index_i64):\n        actual = index_i64.to_pandas()\n        expected = pd.Index([0, 1, 2, 3, 4])\n\n        assert actual.equals(expected)\n\n    def test_to_pandas_multiindex(self):\n        data = [[0, 0, 1, 1], [2., 3., 2., 3.]]\n        mi = MultiIndex(data)\n\n        actual = mi.to_pandas()\n        expected = pd.MultiIndex.from_arrays(data)\n\n        assert actual.equals(expected)\n\n    def test_to_pandas_series(self, data_f32, series_f32):\n        actual = series_f32.to_pandas()\n        expected = pd.Series(data_f32)\n\n        assert actual.equals(expected)\n\n    def test_to_pandas_df(self, df1, data_f32):\n        actual = df1.to_pandas()\n        expected = pd.DataFrame({'a': [0, 1, 2, 3, 4], 'b': data_f32}, pd.Index([2, 3, 4, 5, 6]))\n\n        assert actual.equals(expected)\n"""
tests/core/test_series.py,65,"b'import numpy as np\nimport pytest\n\nfrom baloo import Series, RangeIndex, Index, load_cudf, log\nfrom baloo.weld import create_placeholder_weld_object\nfrom .indexes.utils import assert_indexes_equal\n\n\ndef assert_series_equal(actual, expected, almost=None, sort=False):\n    actual = actual.evaluate()\n    expected = expected.evaluate()\n\n    actual_values = actual.values\n    expected_values = expected.values\n    if sort:\n        actual_values = np.sort(actual_values)\n        expected_values = np.sort(expected_values)\n\n    # for checking floats\n    if almost is not None:\n        np.testing.assert_array_almost_equal(actual_values, expected_values, almost)\n    else:\n        np.testing.assert_array_equal(actual_values, expected_values)\n    assert actual.dtype.char == expected.dtype.char\n    assert actual._length == expected._length\n    # might seem redundant but testing the __len__ function\n    assert len(actual) == len(expected)\n    assert actual.name == expected.name\n    assert_indexes_equal(actual.index, expected.index, sort=sort)\n\n\nclass TestSeries(object):\n    def test_evaluate(self, data_i64):\n        actual = Series(data_i64)\n        expected = Series(data_i64, RangeIndex(5))\n\n        assert_series_equal(actual, expected)\n\n    def test_init_raw_cast_type(self, data_i64, index_i64, data_f32):\n        actual = Series(data_i64, index_i64, np.dtype(np.float32))\n        expected = Series(data_f32, index_i64, np.dtype(np.float32))\n\n        assert_series_equal(actual, expected)\n\n    def test_len_raw(self, series_i64):\n        actual = len(series_i64)\n        expected = 5\n\n        assert actual == expected\n\n    def test_init_weld_object_no_dtype(self, data_i64_lazy):\n        with pytest.raises(ValueError):\n            Series(data_i64_lazy)\n\n    def test_init_list(self):\n        data = [1, 2, 3]\n        sr = Series(data)\n\n        np.testing.assert_array_equal(sr.values, np.array(data))\n        assert sr.dtype == np.dtype(np.int64)\n\n    def test_init_list_wrong_dtype(self):\n        data = [1, 2, \'abc\']\n        with pytest.raises(TypeError):\n            Series(data)\n\n    def test_len_lazy(self, data_i64):\n        weld_obj = create_placeholder_weld_object(data_i64)\n        sr = Series(weld_obj, dtype=np.dtype(np.int64))\n\n        actual = len(sr)\n        expected = 5\n\n        assert actual == expected\n\n    @pytest.mark.parametrize(\'comparison, expected_data\', [\n        (\'<\', np.array([True, False, False, False, False])),\n        (\'<=\', np.array([True, True, False, False, False])),\n        (\'==\', np.array([False, True, False, False, False])),\n        (\'!=\', np.array([True, False, True, True, True])),\n        (\'>=\', np.array([False, True, True, True, True])),\n        (\'>\', np.array([False, False, True, True, True]))\n    ])\n    def test_comparison(self, comparison, expected_data, series_i64, index_i64):\n        actual = eval(\'series_i64 {} 2\'.format(comparison))\n        expected = Series(expected_data, index_i64, np.dtype(np.bool))\n\n        assert_series_equal(actual, expected)\n\n    def test_filter(self, series_i64):\n        actual = series_i64[series_i64 != 2]\n        expected = Series(np.array([1, 3, 4, 5]), Index(np.array([0, 2, 3, 4])), np.dtype(np.int64))\n\n        assert_series_equal(actual, expected)\n\n    def test_filter_combined(self, series_i64):\n        actual = series_i64[(series_i64 != 2) & (series_i64 != 4)]\n        expected = Series(np.array([1, 3, 5]), Index(np.array([0, 2, 4])), np.dtype(np.int64))\n\n        assert_series_equal(actual, expected)\n\n    def test_filter_str(self, series_str):\n        actual = series_str[series_str != \'Abc\']\n        expected = Series(np.array([\'a\', \'goosfraba\', \'   dC  \', \'secrETariat\'], dtype=np.bytes_),\n                          Index(np.array([0, 2, 3, 4])), np.dtype(np.bytes_))\n\n        assert_series_equal(actual, expected)\n\n    def test_slice(self, series_f32):\n        actual = series_f32[1:3]\n        expected = Series(np.array([2, 3]), Index(np.array([1, 2])), np.dtype(np.float32))\n\n        assert_series_equal(actual, expected)\n\n    @pytest.mark.parametrize(\'operation, expected_data\', [\n        (\'&\', np.array([True, False, False, False, False])),\n        (\'|\', np.array([True, True, True, False, False]))\n    ])\n    def test_bool_operations(self, operation, expected_data, index_i64):\n        sr1 = Series(np.array([True, True, False, False, False]), index_i64, np.dtype(np.bool))\n        sr2 = Series(np.array([True, False, True, False, False]), index_i64, np.dtype(np.bool))\n\n        actual = eval(\'sr1 {} sr2\'.format(operation))\n        expected = Series(expected_data, index_i64, np.dtype(np.bool))\n\n        assert_series_equal(actual, expected)\n\n    def test_invert(self, index_i64):\n        sr = Series(np.array([True, False, True, False, False]), index_i64, np.dtype(np.bool))\n\n        actual = ~sr\n        expected = Series(np.array([False, True, False, True, True]), index_i64, np.dtype(np.bool))\n\n        assert_series_equal(actual, expected)\n\n    def test_head(self, series_f32):\n        actual = series_f32.head(2)\n        expected = Series(np.array([1, 2]), RangeIndex(2), np.dtype(np.float32))\n\n        assert_series_equal(actual, expected)\n\n    def test_tail(self, series_f32):\n        actual = series_f32.tail(2)\n        expected = Series(np.array([4, 5]), Index(np.array([3, 4])), np.dtype(np.float32))\n\n        assert_series_equal(actual, expected)\n\n    def test_iloc_int(self, series_f32):\n        actual = series_f32.iloc[2].evaluate()\n        expected = 3\n\n        assert actual == expected\n\n    def test_iloc_slice(self, series_f32):\n        actual = series_f32.iloc[1:3]\n        expected = Series(np.array([2, 3]), Index(np.array([1, 2])), np.dtype(np.float32))\n\n        assert_series_equal(actual, expected)\n\n    def test_iloc_indices(self, series_f32):\n        indices = Series(np.array([0, 3, 4]))\n\n        actual = series_f32.iloc[indices]\n        expected = Series(np.array([1, 4, 5], dtype=np.float32), Index(np.array([0, 3, 4])), np.dtype(np.float32))\n\n        assert_series_equal(actual, expected)\n\n    def test_iloc_indices_missing(self, series_f32):\n        indices = Series(np.array([0, 3, 5]))\n\n        actual = series_f32.iloc._iloc_with_missing(indices.weld_expr)\n        expected = Series(np.array([1, 4, -999], dtype=np.float32), Index(np.array([0, 3, -999])), np.dtype(np.float32))\n\n        assert_series_equal(actual, expected)\n\n    @pytest.mark.parametrize(\'operation, expected_data\', [\n        (\'+\', np.array(np.arange(3, 8), dtype=np.float32)),\n        (\'-\', np.array(np.arange(-1, 4), dtype=np.float32)),\n        (\'*\', np.array(np.arange(2, 11, 2), dtype=np.float32)),\n        (\'/\', np.array([0.5, 1, 1.5, 2, 2.5], dtype=np.float32)),\n        (\'**\', np.array([1, 4, 9, 16, 25], dtype=np.float32))\n    ])\n    def test_op_array(self, operation, expected_data, series_f32, index_i64, op_array_other):\n        actual = eval(\'series_f32 {} op_array_other\'.format(operation))\n        expected = Series(expected_data, index_i64, np.dtype(np.float32))\n\n        assert_series_equal(actual, expected)\n\n    @pytest.mark.parametrize(\'operation, expected_data\', [\n        (\'+\', np.array(np.arange(3, 8))),\n        (\'-\', np.array(np.arange(-1, 4))),\n        (\'*\', np.array(np.arange(2, 11, 2))),\n        (\'/\', np.array([0.5, 1, 1.5, 2, 2.5])),\n        (\'**\', np.array([1, 4, 9, 16, 25]))\n    ])\n    def test_op_scalar(self, operation, expected_data, index_i64, series_f32):\n        actual = eval(\'series_f32 {} 2\'.format(operation))\n        expected = Series(expected_data, index_i64, np.dtype(np.float32))\n\n        assert_series_equal(actual, expected)\n\n    @pytest.mark.parametrize(\'aggregation, expected\', [\n        (\'min\', 1),\n        (\'max\', 5),\n        (\'sum\', 15),\n        (\'prod\', 120),\n        (\'count\', 5),\n        (\'mean\', 3.0),\n        (\'var\', 2.5),\n        (\'std\', 1.5811388)\n    ])\n    def test_aggregation(self, aggregation, expected, series_i64):\n        actual = getattr(series_i64, aggregation)().evaluate()\n\n        np.testing.assert_almost_equal(actual, expected, 5)\n\n    def test_agg(self, series_f32):\n        aggregations = [\'max\', \'var\', \'count\', \'mean\']\n        actual = series_f32.agg(aggregations)\n\n        expected = Series(np.array([5, 2.5, 5, 3], dtype=np.float64),\n                          Index(np.array(aggregations, dtype=np.bytes_)),\n                          np.dtype(np.float64))\n\n        assert_series_equal(actual, expected)\n\n    def test_unique(self):\n        sr = Series([3, 2, 2, 5, 6, 6, 6])\n\n        actual = sr.unique().evaluate()\n        expected = np.array([3, 2, 5, 6])\n\n        np.testing.assert_array_equal(np.sort(actual), np.sort(expected))\n\n    def test_isna(self, index_i64):\n        sr = Series([3, 2, -999, 4, -999], index_i64, dtype=np.dtype(np.int64))\n\n        actual = sr.isna()\n        expected = Series([False, False, True, False, True], index_i64, np.dtype(np.bool))\n\n        assert_series_equal(actual, expected)\n\n    def test_notna(self, index_i64):\n        sr = Series([3, 2, -999, 4, -999], index_i64, dtype=np.dtype(np.int64))\n\n        actual = sr.notna()\n        expected = Series([True, True, False, True, False], index_i64, np.dtype(np.bool))\n\n        assert_series_equal(actual, expected)\n\n    def test_dropna(self, index_i64):\n        sr = Series([3, 2, -999, 4, -999], index_i64, dtype=np.dtype(np.int64))\n\n        actual = sr.dropna()\n        expected = Series([3, 2, 4], Index([0, 1, 3]), np.dtype(np.int64))\n\n        assert_series_equal(actual, expected)\n\n    def test_fillna(self, index_i64):\n        sr = Series([3, 2, -999, 4, -999], index_i64, dtype=np.dtype(np.int64))\n\n        actual = sr.fillna(15)\n        expected = Series([3, 2, 15, 4, 15], index_i64, np.dtype(np.int64))\n\n        assert_series_equal(actual, expected)\n\n    def test_udf(self, series_i64, index_i64):\n        weld_template = ""map({self}, |e| e + {scalar})""\n        mapping = {\'scalar\': \'2L\'}\n\n        actual = series_i64.apply(weld_template, mapping)\n        expected = Series([3, 4, 5, 6, 7], index_i64)\n\n        assert_series_equal(actual, expected)\n\n    # More details at https://github.com/weld-project/weld/blob/master/docs/language.md#user-defined-functions\n    def test_cudf(self, series_i64, index_i64):\n        from os import path\n        load_cudf(path.dirname(__file__) + \'/cudf/udf_c.so\')\n\n        # cudf[name, return_type](args)\n        weld_template = ""cudf[udf_add, vec[i64]]({self}, {scalar})""\n        mapping = {\'scalar\': \'2L\'}\n\n        actual = series_i64.apply(weld_template, mapping)\n        expected = Series([3, 4, 5, 6, 7], index_i64)\n\n        assert_series_equal(actual, expected)\n\n    def test_udf_func(self, data_f32, index_i64):\n        sr = Series(data_f32, index_i64, np.dtype(np.float32))\n\n        actual = sr.apply(log)\n        expected = Series(np.array([0., 0.693147, 1.098612, 1.386294, 1.609438], dtype=np.float32), index_i64)\n\n        assert_series_equal(actual, expected, 5)\n\n    def test_astype(self, series_f32, data_i64, index_i64):\n        actual = series_f32.astype(np.dtype(np.int64))\n        expected = Series(data_i64, index_i64, np.dtype(np.int64))\n\n        assert_series_equal(actual, expected)\n'"
tests/core/test_series_str.py,1,"b""import numpy as np\nimport pytest\n\nfrom baloo import Series\nfrom .test_series import assert_series_equal\n\n\nclass TestSeriesStr(object):\n    @pytest.mark.parametrize('func, kwargs, expected_data', [\n        ('lower', {}, [b'a', b'abc', b'goosfraba', b'   dc  ', b'secretariat']),\n        ('upper', {}, [b'A', b'ABC', b'GOOSFRABA', b'   DC  ', b'SECRETARIAT']),\n        ('capitalize', {}, [b'A', b'Abc', b'Goosfraba', b'   dc  ', b'Secretariat']),\n        ('get', {'i': 1}, [b'None', b'b', b'o', b' ', b'e']),\n        ('get', {'i': -1}, [b'a', b'c', b'a', b' ', b't']),\n        ('slice', {'start': 1, 'stop': 5, 'step': 2}, [b'', b'b', b'os', b' d', b'er'])\n    ])\n    def test_str_operations(self, func, kwargs, expected_data, series_str, index_i64):\n        actual = getattr(series_str.str, func)(**kwargs)\n        expected = Series(expected_data, index_i64, np.bytes_)\n\n        assert_series_equal(actual, expected)\n\n    @pytest.mark.parametrize('func, kwargs, expected_data', [\n        ('contains', {'pat': 'ab'}, [True, True, True, True, False]),\n        ('startswith', {'pat': 'za'}, [False, True, True, False, False]),\n        ('endswith', {'pat': 'bz'}, [True, True, False, False, False]),\n        ('find', {'sub': 'ab'}, [0, 1, 1, 2, -1]),\n        ('find', {'sub': 'ab', 'start': 1, 'end': 3}, [-1, 1, 1, -1, -1]),\n        ('replace', {'pat': 'ab', 'rep': 'x'}, [b'xz', b'zxz', b'zx', b'  x  ', b'a']),\n        ('split', {'pat': 'ab', 'side': 'left'}, [b'', b'z', b'z', b'  ', b'a']),\n        ('split', {'pat': 'ab', 'side': 'right'}, [b'z', b'z', b'', b'  ', b'a'])\n    ])\n    def test_str_operations_other(self, func, kwargs, expected_data, series_str_2, index_i64):\n        actual = getattr(series_str_2.str, func)(**kwargs)\n        expected = Series(expected_data, index_i64)\n\n        assert_series_equal(actual, expected)\n\n    def test_strip(self, series_str, index_i64):\n        actual = Series([b' a', b'Abc ', b'  dC   ', b'  ', b'secrET ariat'], index_i64).str.strip()\n        expected = Series([b'a', b'Abc', b'dC', b'', b'secrET ariat'], index_i64)\n\n        assert_series_equal(actual, expected)\n"""
tests/io/__init__.py,0,b''
tests/io/test_csv.py,1,"b""import os\n\nimport numpy as np\n\nfrom baloo import read_csv\nfrom ..core.test_frame import assert_dataframe_equal\n\n\nclass TestCSV(object):\n    # TODO: maybe make a utils file with this and others\n    _df1_path = os.path.dirname(__file__) + '/files/df1.csv'\n\n    def test_read_csv(self, df1):\n        actual = read_csv(self._df1_path).set_index('Unnamed: 0')\n        expected = df1\n        expected.index.name = 'Unnamed: 0'\n        expected['b'] = expected['b'].astype(np.float64)\n\n        assert_dataframe_equal(actual, expected)\n\n    def test_to_csv(self, df1):\n        path = os.path.dirname(__file__) + '/files/df1_test.csv'\n        df1.evaluate().to_csv(path)\n\n        try:\n            actual = read_csv(path)\n            expected = read_csv(self._df1_path)\n\n            assert_dataframe_equal(actual, expected)\n        finally:\n            # make sure just created file is deleted\n            os.remove(path)\n"""
tests/weld/test_cache.py,13,"b""import numpy as np\n\nfrom baloo.weld import LazyArrayResult, WeldLong, Cache, LazyStructOfVecResult\nfrom baloo.weld.cache import _FakeArray, _FakeStructMember\nfrom baloo.weld.weld_utils import create_placeholder_weld_object, create_weld_object\n\n\nclass TestCache(object):\n    def test_cache_intermediate_result(self):\n        data = np.arange(5)\n        weld_obj = create_placeholder_weld_object(data)\n        intermediate_result = LazyArrayResult(weld_obj, WeldLong())\n\n        dependency_name = Cache.cache_intermediate_result(intermediate_result, 'test')\n\n        assert dependency_name in Cache._intermediate_results\n        assert Cache._intermediate_results[dependency_name] == intermediate_result\n        assert dependency_name.startswith('_interm_') and dependency_name.endswith('_test')\n\n    def test_create_fake_array_input(self):\n        data = np.arange(5)\n        weld_obj = create_placeholder_weld_object(data)\n        intermediate_result = LazyArrayResult(weld_obj, WeldLong())\n        dependency_name = Cache.cache_intermediate_result(intermediate_result, 'test')\n        fake_weld_input = Cache.create_fake_array_input(dependency_name, 'test_array')\n\n        assert isinstance(fake_weld_input, _FakeArray)\n        assert fake_weld_input.dependency == dependency_name\n        assert fake_weld_input.name.startswith('_interm_') and fake_weld_input.name.endswith('_test_array')\n\n    def test_create_fake_array_input_tuple(self):\n        data = np.arange(5)\n        obj_id, weld_obj = create_weld_object(data)\n        weld_obj.weld_code = '{{{obj_id}, {obj_id}}}'.format(obj_id=obj_id)\n        intermediate_result = LazyStructOfVecResult(weld_obj, [WeldLong(), WeldLong()])\n        dependency_name = Cache.cache_intermediate_result(intermediate_result, 'test')\n        fake_weld_input1 = Cache.create_fake_array_input(dependency_name, 'test_struct_1', (0, ))\n        fake_weld_input2 = Cache.create_fake_array_input(dependency_name, 'test_struct_2', (1, ))\n\n        assert isinstance(fake_weld_input1, _FakeStructMember)\n        assert isinstance(fake_weld_input2, _FakeStructMember)\n        assert fake_weld_input1.dependency == dependency_name\n        assert fake_weld_input2.dependency == dependency_name\n        assert fake_weld_input1.name.startswith('_interm_') and fake_weld_input1.name.endswith('_test_struct_1')\n        assert fake_weld_input2.name.startswith('_interm_') and fake_weld_input2.name.endswith('_test_struct_2')\n        assert fake_weld_input1.index == (0, )\n        assert fake_weld_input2.index == (1, )\n\n    def test_integration_array(self):\n        data = np.arange(5)\n        weld_obj = create_placeholder_weld_object(data)\n        intermediate_result = LazyArrayResult(weld_obj, WeldLong())\n        dependency_name = Cache.cache_intermediate_result(intermediate_result, 'test')\n        fake_weld_input = Cache.create_fake_array_input(dependency_name, 'test_array')\n\n        obj_id, weld_obj = create_weld_object(fake_weld_input)\n        Cache.cache_fake_input(obj_id, fake_weld_input)\n\n        assert Cache.contains(obj_id)\n\n        weld_template = 'result(for({interm}, appender, |b, i, e| merge(b, e + 1L)))'\n        weld_obj.weld_code = weld_template.format(interm=obj_id)\n        actual = LazyArrayResult(weld_obj, WeldLong())\n\n        actual = actual.evaluate()\n        expected = np.arange(1, 6)\n\n        np.testing.assert_array_equal(actual, expected)\n        np.testing.assert_array_equal(Cache._cache[obj_id], data)\n        np.testing.assert_array_equal(Cache._intermediate_results[dependency_name], data)\n\n    def test_integration_tuple(self):\n        data = np.arange(5)\n        obj_id, weld_obj = create_weld_object(data)\n        weld_obj.weld_code = '{{{obj_id}, {obj_id}}}'.format(obj_id=obj_id)\n        intermediate_result = LazyStructOfVecResult(weld_obj, [WeldLong(), WeldLong()])\n        dependency_name = Cache.cache_intermediate_result(intermediate_result, 'test')\n        fake_weld_input1 = Cache.create_fake_array_input(dependency_name, 'test_struct_1', (0, ))\n        # fake_weld_input2 = Cache.create_fake_array_input(dependency_name, 'test_struct_2', 1)\n\n        obj_id, weld_obj = create_weld_object(fake_weld_input1)\n        Cache.cache_fake_input(obj_id, fake_weld_input1)\n\n        assert Cache.contains(obj_id)\n\n        weld_template = 'result(for({interm}, appender, |b, i, e| merge(b, e + 1L)))'\n        weld_obj.weld_code = weld_template.format(interm=obj_id)\n        actual = LazyArrayResult(weld_obj, WeldLong())\n\n        actual = actual.evaluate()\n        expected = np.arange(1, 6)\n\n        np.testing.assert_array_equal(actual, expected)\n        np.testing.assert_array_equal(Cache._cache[obj_id], data)\n        np.testing.assert_array_equal(Cache._intermediate_results[dependency_name], [data, data])\n"""
tests/weld/test_encoders.py,20,"b""import numpy as np\nimport pytest\n\nfrom baloo.weld import LazyResult, NumPyEncoder, NumPyDecoder\nfrom baloo.weld.pyweld import *\n\n\n# TODO: should be restricted to the encoders, i.e. not through LazyResult/WeldObject\nclass TestNumPyEncoders(object):\n    _encoder = NumPyEncoder()\n    _decoder = NumPyDecoder()\n\n    @pytest.mark.parametrize('data, weld_type', [\n        (np.array([1, 2, 3], dtype=np.int16), WeldInt16()),\n        (np.array([1, 2, 3], dtype=np.int32), WeldInt()),\n        (np.array([1, 2, 3], dtype=np.int64), WeldLong()),\n        (np.array([1, 2, 3], dtype=np.float32), WeldFloat()),\n        (np.array([1, 2, 3], dtype=np.float64), WeldDouble()),\n        (np.array([True, True, False], dtype=np.bool), WeldBit()),\n        (np.array(['aaa', 'bb', 'c'], dtype=np.bytes_), WeldVec(WeldChar()))\n    ])\n    def test_array(self, data, weld_type):\n        weld_obj = WeldObject(self._encoder, self._decoder)\n        obj_id = weld_obj.update(data)\n        weld_obj.weld_code = '{}'.format(obj_id)\n        lazy_result = LazyResult(weld_obj, weld_type, 1)\n\n        evaluated = lazy_result.evaluate()\n        expected = data\n\n        np.testing.assert_array_equal(evaluated, expected)\n\n    @pytest.mark.parametrize('data, weld_type', [\n        (np.array([1, np.nan, 3], dtype=np.float32), WeldFloat()),\n        (np.array([1, np.nan, 3], dtype=np.float64), WeldDouble())\n    ])\n    def test_array_with_missing(self, data, weld_type):\n        weld_obj = WeldObject(self._encoder, self._decoder)\n        obj_id = weld_obj.update(data)\n        weld_obj.weld_code = '{}'.format(obj_id)\n        lazy_result = LazyResult(weld_obj, weld_type, 1)\n\n        evaluated = lazy_result.evaluate()\n        expected = data\n\n        np.testing.assert_array_equal(evaluated, expected)\n\n    @pytest.mark.parametrize('data, weld_type, expected', [\n        (np.array([1, 2, 3], dtype=np.int16), WeldInt16(), np.int16(6)),\n        (np.array([1, 2, 3], dtype=np.int32), WeldInt(), np.int32(6)),\n        (np.array([1, 2, 3], dtype=np.int64), WeldLong(), np.int64(6)),\n        (np.array([1, 2, 3], dtype=np.float32), WeldFloat(), np.float32(6)),\n        (np.array([1, 2, 3], dtype=np.float64), WeldDouble(), np.float64(6))\n    ])\n    def test_scalar(self, data, weld_type, expected):\n        weld_obj = WeldObject(self._encoder, self._decoder)\n        obj_id = weld_obj.update(data)\n        weld_obj.weld_code = 'result(for({}, merger[{}, +], |b, i, e| merge(b, e)))'.format(obj_id, str(weld_type))\n        lazy_result = LazyResult(weld_obj, weld_type, 0)\n\n        evaluated = lazy_result.evaluate()\n\n        assert evaluated == expected\n\n    def test_str(self):\n        data = 'abc'\n        weld_obj = WeldObject(self._encoder, self._decoder)\n        obj_id = weld_obj.update(data)\n        weld_obj.weld_code = '{}'.format(obj_id)\n        res = LazyResult(weld_obj, WeldChar(), 1)\n\n        actual = res.evaluate()\n        expected = data\n\n        assert actual == expected\n\n    def test_struct(self):\n        data1 = np.array([1, 2, 3], dtype=np.int64)\n        data2 = np.array([2, 3, 4], dtype=np.int64)\n\n        weld_obj = WeldObject(self._encoder, self._decoder)\n        obj_id1 = weld_obj.update(data1)\n        obj_id2 = weld_obj.update(data2)\n        weld_obj.weld_code = '{{{}, {}}}'.format(obj_id1, obj_id2)\n        lazy_result = LazyResult(weld_obj, WeldStruct([WeldVec(WeldLong()), WeldVec(WeldLong())]), 0)\n\n        evaluated = lazy_result.evaluate()\n        expected = (data1, data2)\n\n        np.testing.assert_array_equal(evaluated[0], expected[0])\n        np.testing.assert_array_equal(evaluated[1], expected[1])\n"""
tests/weld/test_lazy_result.py,4,"b""import numpy as np\n\nfrom baloo.weld import NumPyDecoder, NumPyEncoder, LazyResult, WeldLong, WeldObject\n\n\nclass TestLazyResult(object):\n    def test_lazy_result_evaluate_raw(self):\n        raw = np.array([1, 2, 3], dtype=np.int64)\n        lazy_result = LazyResult(raw, WeldLong(), 1)\n\n        evaluated = lazy_result.evaluate()\n        expected = raw\n\n        np.testing.assert_array_equal(evaluated, expected)\n\n    def test_lazy_result_evaluate_lazy(self):\n        raw = np.array([1, 2, 3], dtype=np.int64)\n        weld_obj = WeldObject(NumPyEncoder(), NumPyDecoder())\n        obj_id = weld_obj.update(raw)\n        weld_obj.weld_code = '{}'.format(obj_id)\n        lazy_result = LazyResult(weld_obj, WeldLong(), 1)\n\n        evaluated = lazy_result.evaluate()\n        expected = raw\n\n        np.testing.assert_array_equal(evaluated, expected)\n"""
tests/weld/test_utils.py,14,"b""import numpy as np\nimport pytest\n\nfrom baloo.weld.convertors import numpy_to_weld_type, weld_to_numpy_dtype\nfrom baloo.weld.convertors.encoders import _numpy_to_weld_type_mapping\nfrom baloo.weld.convertors.utils import to_weld_vec\nfrom baloo.weld.lazy_result import LazyResult, LazyArrayResult\nfrom baloo.weld.pyweld import *\nfrom baloo.weld.weld_utils import weld_cast_scalar, weld_cast_array\n\n\nclass TestUtils(object):\n    @pytest.mark.parametrize('ndim, expected', [\n        (0, WeldLong()),\n        (1, WeldVec(WeldLong())),\n        (2, WeldVec(WeldVec(WeldLong())))\n    ])\n    def test_to_weld_vec(self, ndim, expected):\n        result = to_weld_vec(WeldLong(), ndim)\n\n        assert result == expected\n\n    @pytest.mark.parametrize('np_dtype, weld_type',\n                             list(_numpy_to_weld_type_mapping.items()))\n    def test_numpy_to_weld_type(self, np_dtype, weld_type):\n        result = numpy_to_weld_type(np_dtype)\n\n        assert result == weld_type\n\n    @pytest.mark.parametrize('np_dtype_str, weld_type', [\n        ('S', WeldVec(WeldChar())),\n        ('bytes_', WeldVec(WeldChar())),\n        ('int16', WeldInt16()),\n        ('int32', WeldInt()),\n        ('int64', WeldLong()),\n        ('float32', WeldFloat()),\n        ('float64', WeldDouble()),\n        ('bool', WeldBit())\n    ])\n    def test_numpy_to_weld_type_str(self, np_dtype_str, weld_type):\n        result = numpy_to_weld_type(np_dtype_str)\n\n        assert result == weld_type\n\n    @pytest.mark.parametrize('scalar, weld_type', [\n        (2.0, WeldInt16()),\n        (2.0, WeldInt()),\n        (2.0, WeldLong()),\n        (2, WeldFloat()),\n        (2, WeldDouble()),\n        (1, WeldBit())\n    ])\n    def test_cast_scalar(self, scalar, weld_type):\n        lazy_res = LazyResult(weld_cast_scalar(scalar, weld_type), weld_type, 0)\n\n        assert scalar == lazy_res.evaluate()\n\n    @pytest.mark.parametrize('scalar, weld_type', [\n        (1, WeldVec(WeldBit())),\n        (1, WeldChar()),\n        ('str', WeldLong()),\n        (b'bytes', WeldLong()),\n        (True, WeldLong())\n    ])\n    def test_cast_scalar_not_supported(self, scalar, weld_type):\n        with pytest.raises(TypeError):\n            weld_cast_scalar(scalar, weld_type)\n\n    @pytest.mark.parametrize('array_data, dtype, to_weld_type', [\n        ([2.0, 3.0], np.float64, WeldInt16()),\n        ([2.0, 3.0], np.float64, WeldInt()),\n        ([2.0, 3.0], np.float64, WeldLong()),\n        ([2, 3], np.int32, WeldFloat()),\n        ([2, 3], np.int32, WeldDouble()),\n        ([1, 0], np.int32, WeldBit())\n    ])\n    def test_cast_array(self, array_data, dtype, to_weld_type):\n        data = np.array(array_data, dtype=dtype)\n\n        actual = LazyArrayResult(weld_cast_array(data,\n                                                 numpy_to_weld_type(np.dtype(dtype)),\n                                                 to_weld_type),\n                                 to_weld_type)\n        expected = np.array(array_data, dtype=weld_to_numpy_dtype(to_weld_type))\n\n        np.testing.assert_array_equal(actual.evaluate(), expected)\n\n    @pytest.mark.parametrize('array_data, dtype, to_weld_type', [\n        (['abc', 'def'], np.bytes_, WeldInt()),\n        ([2.0, 3.0], np.float64, WeldChar())\n    ])\n    def test_cast_array_not_supported(self, array_data, dtype, to_weld_type):\n        data = np.array(array_data, dtype=dtype)\n\n        with pytest.raises(TypeError):\n            weld_cast_array(data,\n                            numpy_to_weld_type(np.dtype(dtype)),\n                            to_weld_type)\n"""
baloo/core/indexes/__init__.py,0,b'from .base import Index\nfrom .multi import MultiIndex\nfrom .range import RangeIndex\n'
baloo/core/indexes/base.py,10,"b'import numpy as np\n\nfrom ..generic import BinaryOps, IndexCommon, BalooCommon, BitOps\nfrom ...core.utils import check_type, infer_dtype, is_scalar, check_weld_bit_array, check_valid_int_slice, \\\n    convert_to_numpy, check_dtype\nfrom ...weld import LazyArrayResult, numpy_to_weld_type, weld_filter, weld_slice, \\\n    weld_compare, weld_tail, weld_array_op, weld_element_wise_op, WeldObject, weld_iloc_indices, \\\n    weld_iloc_indices_with_missing, default_missing_data_literal, weld_replace\n\n\nclass Index(LazyArrayResult, BinaryOps, BitOps, IndexCommon, BalooCommon):\n    """"""Weld-ed Pandas Index.\n\n    Attributes\n    ----------\n    dtype\n    name\n\n    See Also\n    --------\n    pandas.Index : https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Index.html\n\n    Examples\n    --------\n    >>> import baloo as bl\n    >>> import numpy as np\n    >>> ind = bl.Index(np.array([\'a\', \'b\', \'c\'], dtype=np.dtype(np.bytes_)))\n    >>> ind  # repr\n    Index(name=None, dtype=|S1)\n    >>> print(ind)  # str\n    [b\'a\' b\'b\' b\'c\']\n    >>> ind.values\n    array([b\'a\', b\'b\', b\'c\'], dtype=\'|S1\')\n    >>> len(ind)  # eager\n    3\n\n    """"""\n    def __init__(self, data, dtype=None, name=None):\n        """"""Initialize an Index object.\n\n        Parameters\n        ----------\n        data : np.ndarray or WeldObject or list\n            Raw data or Weld expression.\n        dtype : np.dtype, optional\n            Numpy dtype of the elements. Inferred from `data` by default.\n        name : str, optional\n            Name of the Index.\n\n        """"""\n        data, dtype = _process_input_data(data, dtype)\n        self.dtype = dtype\n        self.name = check_type(name, str)\n        self._length = len(data) if isinstance(data, np.ndarray) else None\n\n        super(Index, self).__init__(data, numpy_to_weld_type(self.dtype))\n\n    def __repr__(self):\n        return ""{}(name={}, dtype={})"".format(self.__class__.__name__,\n                                              self.name,\n                                              self.dtype)\n\n    def _comparison(self, other, comparison):\n        if other is None:\n            other = default_missing_data_literal(self.weld_type)\n\n            return _index_compare(self, other, comparison)\n        elif is_scalar(other):\n            return _index_compare(self, other, comparison)\n        else:\n            raise TypeError(\'Can currently only compare with scalars\')\n\n    def _bitwise_operation(self, other, operation):\n        check_type(other, LazyArrayResult)\n        check_weld_bit_array(other)\n        check_weld_bit_array(self)\n\n        return Index(weld_array_op(self.weld_expr,\n                                   other.weld_expr,\n                                   self.weld_type,\n                                   operation),\n                     self.dtype,\n                     self.name)\n\n    def _element_wise_operation(self, other, operation):\n        # Pandas converts result to a Series; unclear why atm\n        if isinstance(other, LazyArrayResult):\n            return Index(weld_array_op(self.weld_expr,\n                                       other.weld_expr,\n                                       self.weld_type,\n                                       operation),\n                         self.dtype,\n                         self.name)\n        elif is_scalar(other):\n            return Index(weld_element_wise_op(self.weld_expr,\n                                              self.weld_type,\n                                              other,\n                                              operation),\n                         self.dtype,\n                         self.name)\n        else:\n            raise TypeError(\'Can only apply operation with scalar or LazyArrayResult\')\n\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, value):\n        self._name = value\n\n    def _gather_names(self, name=\'index\'):\n        return [name if self.name is None else self.name]\n\n    def _gather_data_for_weld(self):\n        return [self.weld_expr]\n\n    def _gather_weld_types(self):\n        return [self.weld_type]\n\n    def _gather_data(self, name=\'index\'):\n        return {self._gather_names(name)[0]: self}\n\n    def _iloc_indices(self, indices):\n        return Index(weld_iloc_indices(self.weld_expr,\n                                       self.weld_type,\n                                       indices),\n                     self.dtype,\n                     self.name)\n\n    def _iloc_indices_with_missing(self, indices):\n        return Index(weld_iloc_indices_with_missing(self.weld_expr,\n                                                    self.weld_type,\n                                                    indices),\n                     self.dtype,\n                     self.name)\n\n    def astype(self, dtype):\n        check_dtype(dtype)\n\n        return Index(self._astype(dtype),\n                     dtype,\n                     self.name)\n\n    def __getitem__(self, item):\n        """"""Select from the Index. Currently used internally through DataFrame and Series.\n\n        Supported selection functionality exemplified below.\n\n        Examples\n        --------\n        >>> ind = bl.Index(np.arange(3))\n        >>> print(ind[ind < 2].evaluate())\n        [0 1]\n        >>> print(ind[1:2].evaluate())\n        [1]\n\n        """"""\n        if isinstance(item, LazyArrayResult):\n            check_weld_bit_array(item)\n\n            return Index(weld_filter(self.weld_expr,\n                                     self.weld_type,\n                                     item.weld_expr),\n                         self.dtype,\n                         self.name)\n        elif isinstance(item, slice):\n            check_valid_int_slice(item)\n            if self.empty:\n                return self\n            else:\n                return Index(weld_slice(self.weld_expr,\n                                        self.weld_type,\n                                        item),\n                             self.dtype,\n                             self.name)\n        else:\n            raise TypeError(\'Expected LazyArrayResult or slice\')\n\n    def evaluate(self, verbose=False, decode=True, passes=None, num_threads=1, apply_experimental=True):\n        """"""Evaluates by creating an Index containing evaluated data.\n\n        See `LazyResult`\n\n        Returns\n        -------\n        Index\n            Index with evaluated data.\n\n        """"""\n        evaluated_data = super(Index, self).evaluate(verbose, decode, passes, num_threads, apply_experimental)\n\n        return Index(evaluated_data, self.dtype, self.name)\n\n    def head(self, n=5):\n        """"""Return Index with first n values.\n\n        Parameters\n        ----------\n        n : int\n            Number of values.\n\n        Returns\n        -------\n        Series\n            Index containing the first n values.\n\n        Examples\n        --------\n        >>> ind = bl.Index(np.arange(3, dtype=np.float64))\n        >>> print(ind.head(2).evaluate())\n        [0. 1.]\n\n        """"""\n        return self[:n]\n\n    def tail(self, n=5):\n        """"""Return Index with the last n values.\n\n        Parameters\n        ----------\n        n : int\n            Number of values.\n\n        Returns\n        -------\n        Series\n            Index containing the last n values.\n\n        Examples\n        --------\n        >>> ind = bl.Index(np.arange(3, dtype=np.float64))\n        >>> print(ind.tail(2).evaluate())\n        [1. 2.]\n\n        """"""\n        if self.empty:\n            return self\n        else:\n            if self._length is not None:\n                length = self._length\n            else:\n                length = self._lazy_len().weld_expr\n\n            # not computing slice here to use with __getitem__ because we\'d need to use len which is eager\n            return Index(weld_tail(self.weld_expr, length, n),\n                         self.dtype,\n                         self.name)\n\n    def dropna(self):\n        """"""Returns Index without null values according to Baloo\'s convention.\n\n        Returns\n        -------\n        Index\n            Index with no null values.\n\n        """"""\n        return self[self.notna()]\n\n    def fillna(self, value):\n        """"""Returns Index with missing values replaced with value.\n\n        Parameters\n        ----------\n        value : {int, float, bytes, bool}\n            Scalar value to replace missing values with.\n\n        Returns\n        -------\n        Index\n            With missing values replaced.\n\n        """"""\n        if not is_scalar(value):\n            raise TypeError(\'Value to replace with is not a valid scalar\')\n\n        return Index(weld_replace(self.weld_expr,\n                                  self.weld_type,\n                                  default_missing_data_literal(self.weld_type),\n                                  value),\n                     self.dtype,\n                     self.name)\n\n    @classmethod\n    def from_pandas(cls, index):\n        """"""Create baloo Index from pandas Index.\n\n        Parameters\n        ----------\n        index : pandas.base.Index\n\n        Returns\n        -------\n        Index\n\n        """"""\n        from pandas import Index as PandasIndex\n        check_type(index, PandasIndex)\n\n        return Index(index.values,\n                     index.dtype,\n                     index.name)\n\n    def to_pandas(self):\n        """"""Convert to pandas Index.\n\n        Returns\n        -------\n        pandas.base.Index\n\n        """"""\n        if not self.is_raw():\n            raise ValueError(\'Cannot convert to pandas Index if not evaluated.\')\n\n        from pandas import Index as PandasIndex\n\n        return PandasIndex(self.values,\n                           self.dtype,\n                           name=self.name)\n\n\ndef _process_input_data(data, dtype):\n    check_type(data, (np.ndarray, WeldObject, list))\n\n    if isinstance(data, list):\n        data = convert_to_numpy(data)\n\n    inferred_dtype = infer_dtype(data, dtype)\n    if isinstance(data, np.ndarray) and data.dtype.char != inferred_dtype.char:\n        data = data.astype(inferred_dtype)\n\n    return data, inferred_dtype\n\n\ndef _index_compare(index, other, comparison):\n    return Index(weld_compare(index.weld_expr,\n                              other,\n                              comparison,\n                              index.weld_type),\n                 np.dtype(np.bool),\n                 index.name)\n'"
baloo/core/indexes/multi.py,4,"b'from collections import OrderedDict\nfrom functools import reduce\n\nimport numpy as np\nfrom tabulate import tabulate\n\nfrom .base import Index\nfrom ..generic import IndexCommon, BalooCommon\nfrom ..utils import check_inner_types, check_type, infer_length, shorten_data, check_weld_bit_array, \\\n    check_valid_int_slice\nfrom ...weld import LazyArrayResult\n\n\nclass MultiIndex(IndexCommon, BalooCommon):\n    """"""Weld-ed MultiIndex, however completely different to Pandas.\n\n    This version merely groups a few columns together to act as an index\n    and hence does not follow the labels/levels approach of Pandas.\n\n    Attributes\n    ----------\n    names\n    dtypes\n\n    Examples\n    --------\n    >>> import baloo as bl\n    >>> import numpy as np\n    >>> ind = bl.MultiIndex([[1, 2, 3], np.array([4, 5, 6], dtype=np.float64)], names=[\'i1\', \'i2\'])\n    >>> ind  # repr\n    MultiIndex(names=[\'i1\', \'i2\'], dtypes=[dtype(\'int64\'), dtype(\'float64\')])\n    >>> print(ind)  # str\n      i1    i2\n    ----  ----\n       1     4\n       2     5\n       3     6\n    >>> ind.values\n    [Index(name=i1, dtype=int64), Index(name=i2, dtype=float64)]\n    >>> len(ind)  # eager\n    3\n\n    """"""\n    def __init__(self, data, names=None):\n        """"""Initialize a MultiIndex object.\n\n        Parameters\n        ----------\n        data : list of (numpy.ndarray or Index or list)\n            The internal data.\n        names : list of str, optional\n            The names of the data.\n\n        """"""\n        check_inner_types(check_type(data, list), (np.ndarray, Index, list))\n        self._length = infer_length(data)\n        self.name = None\n        self.names = _init_names(len(data), names)\n        self._data = _init_indexes(data, self.names)\n\n    @property\n    def values(self):\n        """"""Retrieve internal data.\n\n        Returns\n        -------\n        list\n            The internal list data representation.\n\n        """"""\n        return self._data\n\n    @property\n    def empty(self):\n        return len(self._data) == 0 or all(index.empty for index in self._data)\n\n    @property\n    def dtypes(self):\n        return [v.dtype for v in self.values]\n\n    def __len__(self):\n        """"""Eagerly get the length of the MultiIndex.\n\n        Note that if the length is unknown (such as for WeldObjects),\n        it will be eagerly computed.\n\n        Returns\n        -------\n        int\n            Length of the MultiIndex.\n\n        """"""\n        if self._length is not None:\n            return self._length\n        else:\n            # first check again for raw data\n            length = infer_length(self.values)\n            if length is None:\n                # empty DataFrame\n                if len(self.values) == 0:\n                    return 0\n\n                # use the first column to compute the length\n                length = len(self.values[0])\n\n            self._length = length\n\n            return length\n\n    def __repr__(self):\n        return ""{}(names={}, dtypes={})"".format(self.__class__.__name__,\n                                                self.names,\n                                                self.dtypes)\n\n    def __str__(self):\n        str_data = OrderedDict(((k, shorten_data(v.values)) for k, v in zip(self.names, self.values)))\n\n        return tabulate(str_data, headers=\'keys\')\n\n    def evaluate(self, verbose=False, decode=True, passes=None, num_threads=1, apply_experimental=True):\n        """"""Evaluates by creating a MultiIndex containing evaluated data and index.\n\n        See `LazyResult`\n\n        Returns\n        -------\n        MultiIndex\n            MultiIndex with evaluated data.\n\n        """"""\n        evaluated_data = [v.evaluate(verbose, decode, passes, num_threads, apply_experimental) for v in self.values]\n\n        return MultiIndex(evaluated_data, self.names)\n\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, value):\n        self._name = value\n\n    def _gather_names(self, name=\'level_\'):\n        names = [None] * len(self.values) if self.names is None else self.names\n        return [name + str(i) if n is None else n for i, n in enumerate(names)]\n\n    def _gather_data_for_weld(self):\n        return [index.weld_expr for index in self._data]\n\n    def _gather_data(self, name=\'level_\'):\n        return OrderedDict(zip(self._gather_names(name), self._data))\n\n    def _gather_weld_types(self):\n        return [index.weld_type for index in self._data]\n\n    def _iloc_indices(self, indices):\n        return MultiIndex([index._iloc_indices(indices) for index in self.values], self.names)\n\n    def _iloc_indices_with_missing(self, indices):\n        return MultiIndex([index._iloc_indices_with_missing(indices) for index in self.values], self.names)\n\n    def __getitem__(self, item):\n        """"""Select from the MultiIndex.\n\n        Supported functionality exemplified below.\n\n        Examples\n        --------\n        >>> mi = bl.MultiIndex([np.array([1, 2, 3]), np.array([4., 5., 6.])], names=[\'i1\', \'i2\'])\n        >>> print(mi.values[0])\n        [1 2 3]\n        >>> print(mi[:2].evaluate())\n          i1    i2\n        ----  ----\n           1     4\n           2     5\n        >>> print(mi[mi.values[0] != 2].evaluate())\n          i1    i2\n        ----  ----\n           1     4\n           3     6\n\n        """"""\n        if isinstance(item, LazyArrayResult):\n            check_weld_bit_array(item)\n\n            return MultiIndex([column[item] for column in self.values], self.names)\n        elif isinstance(item, slice):\n            check_valid_int_slice(item)\n\n            return MultiIndex([column[item] for column in self.values], self.names)\n        else:\n            raise TypeError(\'Expected LazyArrayResult or slice\')\n\n    # this method shouldn\'t exist however is kept to avoid checking for MultiIndex in DataFrame.tail() ~ generalizing\n    def tail(self, n=5):\n        """"""Return MultiIndex with the last n values in each column.\n\n        Parameters\n        ----------\n        n : int\n            Number of values.\n\n        Returns\n        -------\n        MultiIndex\n            MultiIndex containing the last n values in each column.\n\n        """"""\n        # not computing slice here to use with __getitem__ because we\'d need to use len which is eager\n        return MultiIndex([v.tail(n) for v in self.values], self.names)\n\n    def dropna(self):\n        """"""Returns MultiIndex without any rows containing null values according to Baloo\'s convention.\n\n        Returns\n        -------\n        MultiIndex\n            MultiIndex with no null values.\n\n        """"""\n        not_nas = [v.notna() for v in self.values]\n        and_filter = reduce(lambda x, y: x & y, not_nas)\n\n        return self[and_filter]\n\n    @classmethod\n    def from_pandas(cls, index):\n        """"""Create baloo MultiIndex from pandas MultiIndex.\n\n        Parameters\n        ----------\n        index : pandas.multi.MultiIndex\n\n        Returns\n        -------\n        MultiIndex\n\n        """"""\n        from pandas import MultiIndex as PandasMultiIndex\n        check_type(index, PandasMultiIndex)\n\n        baloo_level_values = [Index.from_pandas(index.get_level_values(level))\n                              for level in range(len(index.levels))]\n\n        return MultiIndex(baloo_level_values, list(index.names))\n\n    def to_pandas(self):\n        """"""Convert to pandas MultiIndex.\n\n        Returns\n        -------\n        pandas.base.MultiIndex\n\n        """"""\n        if not all(ind.is_raw() for ind in self.values):\n            raise ValueError(\'Cannot convert to pandas MultiIndex if not evaluated.\')\n\n        from pandas import MultiIndex as PandasMultiIndex\n\n        arrays = [ind.values for ind in self.values]\n\n        return PandasMultiIndex.from_arrays(arrays, names=self.names)\n\n\ndef _init_names(number_columns, names):\n    check_inner_types(check_type(names, list), str)\n\n    if names is None:\n        names = [None] * number_columns\n    elif number_columns != len(names):\n        raise ValueError(\'Expected all or none of the columns to be named\')\n\n    return names\n\n\ndef _init_indexes(data, names):\n    data_as_indexes = []\n    for n, v in zip(names, data):\n        if isinstance(v, np.ndarray):\n            v = Index(v, v.dtype, n)\n        elif isinstance(v, list):\n            v = Index(v, name=n)\n        data_as_indexes.append(v)\n\n    return data_as_indexes\n'"
baloo/core/indexes/range.py,4,"b'import numpy as np\n\nfrom .base import Index\nfrom ..utils import check_type, replace_if_none\nfrom ...weld import weld_range, WeldObject\n\n\nclass RangeIndex(Index):\n    """"""Weld-ed Pandas RangeIndex.\n\n    Attributes\n    ----------\n    start\n    stop\n    step\n    dtype\n\n    See Also\n    --------\n    pandas.RangeIndex : https://pandas.pydata.org/pandas-docs/stable/generated/pandas.RangeIndex.html#pandas.RangeIndex\n\n    Examples\n    --------\n    >>> import baloo as bl\n    >>> import numpy as np\n    >>> ind = bl.RangeIndex(3)\n    >>> ind  # repr\n    RangeIndex(start=0, stop=3, step=1)\n    >>> weld_code = str(ind)  # weld_code\n    >>> ind.evaluate()\n    Index(name=None, dtype=int64)\n    >>> print(ind.evaluate())\n    [0 1 2]\n    >>> len(ind)  # eager\n    3\n    >>> (ind * 2).evaluate().values\n    array([0, 2, 4])\n    >>> (ind - bl.Series(np.arange(1, 4))).evaluate().values\n    array([-1, -1, -1])\n\n    """"""\n    # TODO: implement negative step!\n    def __init__(self, start=None, stop=None, step=None, name=None):\n        """"""Initialize a RangeIndex object.\n\n        If only 1 value (`start`) is passed, it will be considered the `stop` value.\n        Note that this 1 value may also be a WeldObject for cases such as creating\n        a Series with no index as argument.\n\n        Parameters\n        ----------\n        start : int or WeldObject\n        stop : int or WeldObject, optional\n        step : int, optional\n\n        """"""\n        self.start, self.stop, self.step = _check_input(start, stop, step)\n        self.name = check_type(name, str)\n        self.dtype = np.dtype(np.int64)\n\n        self._length = len(range(self.start, self.stop, self.step)) if isinstance(stop, int) else None\n\n        super(RangeIndex, self).__init__(weld_range(self.start, self.stop, self.step), np.dtype(np.int64))\n\n    def __repr__(self):\n        return ""{}(start={}, stop={}, step={})"".format(self.__class__.__name__,\n                                                       self.start,\n                                                       self.stop,\n                                                       self.step)\n\n    def _comparison(self, other, comparison):\n        if isinstance(other, int):\n            return super(RangeIndex, self)._comparison(other, comparison)\n        else:\n            raise TypeError(\'Can only compare with integers\')\n\n    @property\n    def empty(self):\n        return self.start == 0 and self.stop == 0\n\n    def evaluate(self, verbose=False, decode=True, passes=None, num_threads=1, apply_experimental=True):\n        """"""Evaluates by creating an Index containing evaluated data.\n\n        See `LazyResult`\n\n        Returns\n        -------\n        Index\n            Index with evaluated data.\n\n        """"""\n        if self.start == 0 and self.stop == 0:\n            evaluated_data = np.empty(0, dtype=np.int64)\n        else:\n            evaluated_data = super(Index, self).evaluate(verbose, decode, passes, num_threads, apply_experimental)\n\n        return Index(evaluated_data, self.dtype, self.name)\n\n\ndef _check_input(start, stop, step):\n    if start is None and stop is None and step is None:\n        raise TypeError(\'Must be called with at least one integer\')\n    elif step is not None and step < 0:\n        raise ValueError(\'Only positive steps are currently supported\')\n    elif start is not None and stop is None and step is None:\n        stop = start\n        start = None\n\n    check_type(start, int)\n    check_type(stop, (int, WeldObject))\n    check_type(step, int)\n\n    start = replace_if_none(start, 0)\n    stop = replace_if_none(stop, 0)\n    step = replace_if_none(step, 1)\n\n    return start, stop, step\n'"
baloo/weld/convertors/__init__.py,0,"b'from .encoders import NumPyEncoder, NumPyDecoder, numpy_to_weld_type, weld_to_numpy_dtype, \\\n    default_missing_data_literal, supported_dtype_chars\n'"
baloo/weld/convertors/encoders.py,18,"b'import ctypes\n\nimport numpy as np\n\nfrom .utils import to_weld_vec\nfrom ..pyweld.types import *\nfrom ..pyweld.weldobject import WeldObjectDecoder, WeldObjectEncoder, cweld\nfrom ...config import ENCODERS_PATH\n\n# Python3: str _is_ unicode -> \'B\xc3\xbcrgermeister\'.encode() => b\'B\\xc3\\xbcrgermeister\'\n# Python2: str is ascii -> \'B\xc3\xbcrgermeister\' does not exist; u\'B\xc3\xbcrgermeister\'.encode() => \'B\\xc3\\xbcrgermeister\'\n\nsupported_dtype_chars = {\'h\', \'i\', \'l\', \'f\', \'d\', \'?\', \'S\'}\n\n# TODO: datetime support\n_numpy_to_weld_type_mapping = {\n    \'S\': WeldVec(WeldChar()),\n    \'h\': WeldInt16(),\n    \'i\': WeldInt(),\n    \'l\': WeldLong(),\n    \'f\': WeldFloat(),\n    \'d\': WeldDouble(),\n    \'?\': WeldBit()\n}\n\n\ndef numpy_to_weld_type(np_dtype):\n    """"""Convert from NumPy dtype to Weld type.\n\n    Note that support for strings is intended to be only for\n    Python 2 str and Python 3 bytes. No unicode.\n\n    Parameters\n    ----------\n    np_dtype : numpy.dtype or str\n        NumPy dtype.\n\n    Returns\n    -------\n    WeldType\n        Corresponding WeldType.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from baloo.weld import numpy_to_weld_type\n    >>> str(numpy_to_weld_type(np.dtype(np.int64)))\n    \'i64\'\n    >>> str(numpy_to_weld_type(\'?\'))\n    \'bool\'\n\n    """"""\n    if not isinstance(np_dtype, (str, bytes, np.dtype, type)):\n        raise TypeError(\'Can only convert np.dtype or str\')\n\n    if isinstance(np_dtype, (str, bytes, type)):\n        np_dtype = np.dtype(np_dtype)\n\n    return _numpy_to_weld_type_mapping[np_dtype.char]\n\n\n_weld_to_numpy_type_mapping = {\n    WeldVec(WeldChar()): \'S\',\n    WeldInt16(): \'h\',\n    WeldInt(): \'i\',\n    WeldLong(): \'l\',\n    WeldFloat(): \'f\',\n    WeldDouble(): \'d\',\n    WeldBit(): \'?\'\n}\n\n\ndef weld_to_numpy_dtype(weld_type):\n    """"""Convert from Weld type to NumPy dtype.\n\n    Note that support for strings is intended to be only for\n    Python 2 str and Python 3 bytes. No unicode.\n\n    Parameters\n    ----------\n    weld_type : WeldType\n        Weld type.\n\n    Returns\n    -------\n    numpy.dtype\n        Corresponding Numpy dtype.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from baloo.weld import weld_to_numpy_dtype, WeldFloat\n    >>> weld_to_numpy_dtype(WeldFloat())\n    dtype(\'float32\')\n\n    """"""\n    return np.dtype(_weld_to_numpy_type_mapping[weld_type])\n\n\n# TODO: make np.nan work?\n_default_missing_mapping = {\n    WeldVec(WeldChar()): \'None\',\n    WeldInt16(): \'-999si\',\n    WeldInt(): \'-999\',\n    WeldLong(): \'-999L\',\n    WeldFloat(): \'-999f\',\n    WeldDouble(): \'-999.0\',\n    WeldBit(): \'false\'\n}\n\n\ndef default_missing_data_literal(weld_type):\n    """"""Convert from Weld type to missing literal placeholder.\n\n    Parameters\n    ----------\n    weld_type : WeldType\n        Weld type.\n\n    Returns\n    -------\n    str\n        Literal for missing data.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from baloo.weld import default_missing_data_literal, WeldDouble\n    >>> default_missing_data_literal(WeldDouble())\n    \'-999.0\'\n\n    """"""\n    return _default_missing_mapping[weld_type]\n\n\nclass NumPyEncoder(WeldObjectEncoder):\n    def __init__(self):\n        self.utils = ctypes.PyDLL(ENCODERS_PATH)\n\n    def py_to_weld_type(self, obj):\n        if isinstance(obj, np.ndarray):\n            base = numpy_to_weld_type(obj.dtype)\n            base = to_weld_vec(base, obj.ndim)\n\n            return base\n        elif isinstance(obj, str):\n            return WeldVec(WeldChar())\n        else:\n            raise TypeError(\'Unable to infer weld type from obj of type={}\'.format(str(type(obj))))\n\n    def _numpy_to_weld_func(self, obj):\n        if obj.ndim == 1:\n            if obj.dtype == \'int16\':\n                numpy_to_weld = self.utils.numpy_to_weld_int16_arr\n            elif obj.dtype == \'int32\':\n                numpy_to_weld = self.utils.numpy_to_weld_int_arr\n            elif obj.dtype == \'int64\':\n                numpy_to_weld = self.utils.numpy_to_weld_long_arr\n            elif obj.dtype == \'float32\':\n                numpy_to_weld = self.utils.numpy_to_weld_float_arr\n            elif obj.dtype == \'float64\':\n                numpy_to_weld = self.utils.numpy_to_weld_double_arr\n            elif obj.dtype == \'bool\':\n                numpy_to_weld = self.utils.numpy_to_weld_bool_arr\n            elif obj.dtype.char == \'S\':\n                numpy_to_weld = self.utils.numpy_to_weld_char_arr_arr\n            else:\n                raise TypeError(\'Unable to encode np.ndarray of 1 dimension with dtype={}\'.format(str(obj.dtype)))\n        elif obj.ndim == 2:\n            if obj.dtype == \'int16\':\n                numpy_to_weld = self.utils.numpy_to_weld_int16_arr_arr\n            elif obj.dtype == \'int32\':\n                numpy_to_weld = self.utils.numpy_to_weld_int_arr_arr\n            elif obj.dtype == \'int64\':\n                numpy_to_weld = self.utils.numpy_to_weld_long_arr_arr\n            elif obj.dtype == \'float32\':\n                numpy_to_weld = self.utils.numpy_to_weld_float_arr_arr\n            elif obj.dtype == \'float64\':\n                numpy_to_weld = self.utils.numpy_to_weld_double_arr_arr\n            elif obj.dtype == \'bool\':\n                numpy_to_weld = self.utils.numpy_to_weld_bool_arr_arr\n            else:\n                raise TypeError(\'Unable to encode np.ndarray of 2 dimensions with dtype={}\'.format(str(obj.dtype)))\n        else:\n            raise ValueError(\'Can only encode np.ndarray of 1 or 2 dimensions\')\n\n        return numpy_to_weld\n\n    def encode(self, obj):\n        if isinstance(obj, np.ndarray):\n            numpy_to_weld = self._numpy_to_weld_func(obj)\n            numpy_to_weld.restype = self.py_to_weld_type(obj).ctype_class\n            numpy_to_weld.argtypes = [py_object]\n\n            return numpy_to_weld(obj)\n        elif isinstance(obj, str):\n            numpy_to_weld = self.utils.str_to_weld_char_arr\n            numpy_to_weld.restype = WeldVec(WeldChar()).ctype_class\n            numpy_to_weld.argtypes = [py_object]\n\n            return numpy_to_weld(obj.encode(\'ascii\'))\n        else:\n            raise TypeError(\'Unable to encode obj of type={}\'.format(str(type(obj))))\n\n\nclass NumPyDecoder(WeldObjectDecoder):\n    def __init__(self):\n        self.utils = ctypes.PyDLL(ENCODERS_PATH)\n\n    def _try_decode_scalar(self, data, restype):\n        if restype == WeldInt16():\n            result = ctypes.cast(data, ctypes.POINTER(c_int16)).contents.value\n            return np.int16(result)\n        elif restype == WeldInt():\n            result = ctypes.cast(data, ctypes.POINTER(c_int)).contents.value\n            return np.int32(result)\n        elif restype == WeldLong():\n            result = ctypes.cast(data, ctypes.POINTER(c_long)).contents.value\n            return np.int64(result)\n        elif restype == WeldFloat():\n            result = ctypes.cast(data, ctypes.POINTER(c_float)).contents.value\n            return np.float32(result)\n        elif restype == WeldDouble():\n            result = ctypes.cast(data, ctypes.POINTER(c_double)).contents.value\n            return np.float64(result)\n        elif restype == WeldBit():\n            result = ctypes.cast(data, ctypes.POINTER(c_bool)).contents.value\n            return np.bool(result)\n        elif restype == WeldVec(WeldChar()):\n            weld_to_numpy = self.utils.weld_to_str\n            weld_to_numpy.restype = py_object\n            weld_to_numpy.argtypes = [restype.ctype_class]\n            result = ctypes.cast(data, ctypes.POINTER(restype.ctype_class)).contents\n\n            return weld_to_numpy(result).decode(\'ascii\')\n        else:\n            return None\n\n    def _weld_to_numpy_func(self, restype):\n        if restype == WeldVec(WeldInt16()):\n            return self.utils.weld_to_numpy_int16_arr\n        elif restype == WeldVec(WeldInt()):\n            return self.utils.weld_to_numpy_int_arr\n        elif restype == WeldVec(WeldLong()):\n            return self.utils.weld_to_numpy_long_arr\n        elif restype == WeldVec(WeldFloat()):\n            return self.utils.weld_to_numpy_float_arr\n        elif restype == WeldVec(WeldDouble()):\n            return self.utils.weld_to_numpy_double_arr\n        elif restype == WeldVec(WeldBit()):\n            return self.utils.weld_to_numpy_bool_arr\n        elif restype == WeldVec(WeldVec(WeldChar())):\n            return self.utils.weld_to_numpy_char_arr_arr\n        elif restype == WeldVec(WeldVec(WeldInt16())):\n            return self.utils.weld_to_numpy_int16_arr_arr\n        elif restype == WeldVec(WeldVec(WeldInt())):\n            return self.utils.weld_to_numpy_int_arr_arr\n        elif restype == WeldVec(WeldVec(WeldLong())):\n            return self.utils.weld_to_numpy_long_arr_arr\n        elif restype == WeldVec(WeldVec(WeldFloat())):\n            return self.utils.weld_to_numpy_float_arr_arr\n        elif restype == WeldVec(WeldVec(WeldDouble())):\n            return self.utils.weld_to_numpy_double_arr_arr\n        elif restype == WeldVec(WeldVec(WeldBit())):\n            return self.utils.weld_to_numpy_bool_arr_arr\n        else:\n            return None\n\n    def _try_decode_array(self, data, restype):\n        weld_to_numpy = self._weld_to_numpy_func(restype)\n\n        if weld_to_numpy is not None:\n            weld_to_numpy.restype = py_object\n            weld_to_numpy.argtypes = [restype.ctype_class]\n            result = ctypes.cast(data, ctypes.POINTER(restype.ctype_class)).contents\n\n            res = weld_to_numpy(result)\n            # TODO: this might be a bug waiting to happen; the dtype is |S0 despite actually being e.g. |S9\n            if restype == WeldVec(WeldVec(WeldChar())):\n                res = res.astype(np.bytes_)\n\n            return res\n        else:\n            return None\n\n    def _try_decode_struct(self, data, restype):\n        if isinstance(restype, WeldStruct):\n            results = []\n            # Iterate through all fields in the struct and recursively decode\n            for field_type in restype.field_types:\n                result = self.decode(data, field_type, raw_ptr=True)\n                data += sizeof(field_type.ctype_class())\n                results.append(result)\n\n            return tuple(results)\n        else:\n            return None\n\n    def decode(self, obj, restype, raw_ptr=False):\n        if raw_ptr:\n            data = obj\n        else:\n            data = cweld.WeldValue(obj).data()\n\n        decoded_scalar = self._try_decode_scalar(data, restype)\n        if decoded_scalar is not None:\n            return decoded_scalar\n\n        decoded_array = self._try_decode_array(data, restype)\n        if decoded_array is not None:\n            return decoded_array\n\n        decoded_struct = self._try_decode_struct(data, restype)\n        if decoded_struct is not None:\n            return decoded_struct\n        else:\n            raise TypeError(\'Unable to decode obj with restype={}\'.format(str(restype)))\n'"
baloo/weld/convertors/utils.py,0,"b'import sys\n\nfrom ..pyweld.types import WeldVec\n\n\ndef to_weld_vec(weld_type, ndim):\n    """"""Convert multi-dimensional data to WeldVec types.\n\n    Parameters\n    ----------\n    weld_type : WeldType\n        WeldType of data.\n    ndim : int\n        Number of dimensions.\n\n    Returns\n    -------\n    WeldVec\n        WeldVec of 1 or more dimensions.\n\n    """"""\n    for i in range(ndim):\n        weld_type = WeldVec(weld_type)\n    return weld_type\n\n\ndef to_shared_lib(name):\n    """"""Return library name depending on platform.\n\n    Parameters\n    ----------\n    name : str\n        Name of library.\n\n    Returns\n    -------\n    str\n        Name of library with extension.\n\n    """"""\n    if sys.platform.startswith(\'linux\'):\n        return name + \'.so\'\n    elif sys.platform.startswith(\'darwin\'):\n        return name + \'.dylib\'\n    elif sys.platform.startswith(\'win\'):\n        return name + \'.dll\'\n    else:\n        sys.exit(1)\n'"
baloo/weld/libs/__init__.py,0,b''
baloo/weld/pyweld/__init__.py,0,"b'from .types import WeldLong, WeldBit, WeldDouble, WeldFloat, WeldInt, WeldInt16, WeldChar, WeldVec, WeldStruct\nfrom .weldobject import WeldObject\n'"
baloo/weld/pyweld/bindings.py,0,"b'import copy\nfrom ctypes import *\n\nfrom ...config import WELD_PATH\n\n# Implements a wrapper around the Weld API.\nweld = CDLL(WELD_PATH, mode=RTLD_GLOBAL)\n\n\n# Used for some type checking carried out by ctypes\nclass c_weld_module(c_void_p):\n    pass\n\n\nclass c_weld_conf(c_void_p):\n    pass\n\n\nclass c_weld_err(c_void_p):\n    pass\n\n\nclass c_weld_value(c_void_p):\n    pass\n\n\nclass WeldModule(c_void_p):\n    def __init__(self, code, conf, err):\n        weld_module_compile = weld.weld_module_compile\n        weld_module_compile.argtypes = [c_char_p, c_weld_conf, c_weld_err]\n        weld_module_compile.restype = c_weld_module\n\n        code = c_char_p(code.encode(\'ascii\'))\n\n        self.module = weld_module_compile(code, conf.conf, err.error)\n\n    def run(self, conf, arg, err):\n        weld_module_run = weld.weld_module_run\n        # module, conf, arg, &err\n        weld_module_run.argtypes = [c_weld_module, c_weld_conf, c_weld_value, c_weld_err]\n        weld_module_run.restype = c_weld_value\n        ret = weld_module_run(self.module, conf.conf, arg.val, err.error)\n\n        return WeldValue(ret, assign=True)\n\n    def __del__(self):\n        weld_module_free = weld.weld_module_free\n        weld_module_free.argtypes = [c_weld_module]\n        weld_module_free.restype = None\n        weld_module_free(self.module)\n\n\nclass WeldValue(c_void_p):\n    def __init__(self, value, assign=False):\n        if assign is False:\n            weld_value_new = weld.weld_value_new\n            weld_value_new.argtypes = [c_void_p]\n            weld_value_new.restype = c_weld_value\n            value = weld_value_new(value)\n\n        self.val = value\n        self.freed = False\n\n    def _check(self):\n        if self.freed:\n            raise ValueError(""Attempted to use freed WeldValue"")\n\n    def data(self):\n        self._check()\n        weld_value_data = weld.weld_value_data\n        weld_value_data.argtypes = [c_weld_value]\n        weld_value_data.restype = c_void_p\n\n        return weld_value_data(self.val)\n\n    def memory_usage(self):\n        self._check()\n        weld_value_memory_usage = weld.weld_value_memory_usage\n        weld_value_memory_usage.argtypes = [c_weld_value]\n        weld_value_memory_usage.restype = c_int64\n\n        return weld_value_memory_usage(self.val)\n\n    def free(self):\n        self._check()\n        weld_value_free = weld.weld_value_free\n        weld_value_free.argtypes = [c_weld_value]\n        weld_value_free.restype = None\n\n        self.freed = True\n\n        return weld_value_free(self.val)\n\n\nclass WeldConf(c_void_p):\n    def __init__(self):\n        weld_conf_new = weld.weld_conf_new\n        weld_conf_new.argtypes = []\n        weld_conf_new.restype = c_weld_conf\n\n        self.conf = weld_conf_new()\n\n    def get(self, key):\n        key = c_char_p(key.encode(\'ascii\'))\n        weld_conf_get = weld.weld_conf_get\n        weld_conf_get.argtypes = [c_weld_conf, c_char_p]\n        weld_conf_get.restype = c_char_p\n        val = weld_conf_get(self.conf, key)\n\n        return copy.copy(val)\n\n    def set(self, key, value):\n        key = c_char_p(key.encode(\'ascii\'))\n        value = c_char_p(value.encode(\'ascii\'))\n        weld_conf_set = weld.weld_conf_set\n        weld_conf_set.argtypes = [c_weld_conf, c_char_p, c_char_p]\n        weld_conf_set.restype = None\n        weld_conf_set(self.conf, key, value)\n\n    def __del__(self):\n        weld_conf_free = weld.weld_conf_free\n        weld_conf_free.argtypes = [c_weld_conf]\n        weld_conf_free.restype = None\n\n        weld_conf_free(self.conf)\n\n\nclass WeldError(c_void_p):\n    def __init__(self):\n        weld_error_new = weld.weld_error_new\n        weld_error_new.argtypes = []\n        weld_error_new.restype = c_weld_err\n\n        self.error = weld_error_new()\n\n    def code(self):\n        weld_error_code = weld.weld_error_code\n        weld_error_code.argtypes = [c_weld_err]\n        weld_error_code.restype = c_uint64\n\n        return weld_error_code(self.error)\n\n    def message(self):\n        weld_error_message = weld.weld_error_message\n        weld_error_message.argtypes = [c_weld_err]\n        weld_error_message.restype = c_char_p\n        val = weld_error_message(self.error)\n\n        return copy.copy(val)\n\n    def __del__(self):\n        weld_error_free = weld.weld_error_free\n        weld_error_free.argtypes = [c_weld_err]\n        weld_error_free.restype = None\n        weld_error_free(self.error)\n\n\nWeldLogLevelOff = 0\nWeldLogLevelError = 1\nWeldLogLevelWarn = 2\nWeldLogLevelInfo = 3\nWeldLogLevelDebug = 4\nWeldLogLevelTrace = 5\n\n\ndef weld_set_log_level(log_level):\n    """"""\n    Sets the log_level for Weld:\n       0 = No Logs,\n       1 = Error,\n       2 = Warn,\n       3 = Info,\n       4 = Debug,\n       5 = Trace.\n    """"""\n    weld.weld_set_log_level(log_level)\n'"
baloo/weld/pyweld/types.py,0,"b'from ctypes import *\n\n\n# Wrappers for types in NVL\nclass WeldType(object):\n    def __str__(self):\n        return ""type""\n\n    def __hash__(self):\n        return hash(str(self))\n\n    def __eq__(self, other):\n        return hash(other) == hash(self)\n\n    def __ne__(self, other):\n        return hash(other) != hash(self)\n\n    @property\n    def ctype_class(self):\n        """"""Returns a class representing this type\'s ctype representation.""""""\n        raise NotImplementedError\n\n\nclass WeldChar(WeldType):\n    def __str__(self):\n        return ""i8""\n\n    @property\n    def ctype_class(self):\n        return c_wchar_p\n\n\nclass WeldBit(WeldType):\n    def __str__(self):\n        return ""bool""\n\n    @property\n    def ctype_class(self):\n        return c_bool\n\n\nclass WeldInt16(WeldType):\n    def __str__(self):\n        return \'i16\'\n\n    @property\n    def ctype_class(self):\n        return c_int16\n\n\nclass WeldInt(WeldType):\n    def __str__(self):\n        return ""i32""\n\n    @property\n    def ctype_class(self):\n        return c_int\n\n\nclass WeldLong(WeldType):\n    def __str__(self):\n        return ""i64""\n\n    @property\n    def ctype_class(self):\n        return c_long\n\n\nclass WeldFloat(WeldType):\n    def __str__(self):\n        return ""f32""\n\n    @property\n    def ctype_class(self):\n        return c_float\n\n\nclass WeldDouble(WeldType):\n    def __str__(self):\n        return ""f64""\n\n    @property\n    def ctype_class(self):\n        return c_double\n\n\nclass WeldVec(WeldType):\n    # Kind of a hack, but ctypes requires that the class instance returned is\n    # the same object. Every time we create a new Vec instance (templatized by\n    # type), we cache it here.\n    _singletons = {}\n\n    def __init__(self, elem_type):\n        self.elemType = elem_type\n\n    def __str__(self):\n        return ""vec[%s]"" % str(self.elemType)\n\n    @property\n    def ctype_class(self):\n        def vec_factory(elem_type):\n            class Vec(Structure):\n                _fields_ = [\n                    (""ptr"", POINTER(elem_type.ctype_class)),\n                    (""size"", c_long),\n                ]\n\n            return Vec\n\n        if self.elemType not in WeldVec._singletons:\n            WeldVec._singletons[self.elemType] = vec_factory(self.elemType)\n\n        return WeldVec._singletons[self.elemType]\n\n\nclass WeldStruct(WeldType):\n    _singletons = {}\n\n    def __init__(self, field_types):\n        assert False not in [isinstance(e, WeldType) for e in field_types]\n\n        self.field_types = field_types\n\n    def __str__(self):\n        return ""{"" + "","".join([str(f) for f in self.field_types]) + ""}""\n\n    @property\n    def ctype_class(self):\n        def struct_factory(field_types):\n            class Struct(Structure):\n                _fields_ = [(str(i), t.ctype_class)\n                            for i, t in enumerate(field_types)]\n\n            return Struct\n\n        if frozenset(self.field_types) not in WeldVec._singletons:\n            WeldStruct._singletons[\n                frozenset(self.field_types)] = struct_factory(self.field_types)\n\n        return WeldStruct._singletons[frozenset(self.field_types)]\n'"
baloo/weld/pyweld/weldobject.py,0,"b'from __future__ import print_function\n\nimport ctypes\nimport time\n\nfrom . import bindings as cweld\nfrom .types import *\n\n\nclass WeldObjectEncoder(object):\n    """"""An abstract class that must be overridden by libraries. This class\n    is used to marshall objects from Python types to Weld types.""""""\n    def encode(self, obj):\n        """"""Encodes an object. All objects encode-able by this encoder should return\n        a valid Weld type using py_to_weld_type.""""""\n        raise NotImplementedError\n\n    def py_to_weld_type(self, obj):\n        """"""Returns a WeldType corresponding to a Python object.""""""\n        raise NotImplementedError\n\n\nclass WeldObjectDecoder(object):\n    """"""An abstract class that must be overridden by libraries. This class\n    is used to marshall objects from Weld types to Python types.""""""\n    def decode(self, obj, restype):\n        """"""Decodes obj, assuming object is of type `restype`. obj\'s Python\n        type is ctypes.POINTER(restype.ctype_class).""""""\n        raise NotImplementedError\n\n\nclass WeldObject(object):\n    """"""Holds a Weld program to be lazily compiled and evaluated,\n    along with any context required to evaluate the program.\n\n    Libraries that use the Weld API return WeldObjects, which represent\n    ""lazy executions"" of programs. WeldObjects can build on top of each other,\n    i.e. libraries should be implemented so they can accept both their\n    native types and WeldObjects.\n\n    An WeldObject contains a Weld program as a string, along with a context.\n    The context maps names in the Weld program to concrete values.\n    When a WeldObject is evaluated, it uses its encode and decode functions to\n    marshall native library types into types that Weld understands. The basic\n    flow of evaluating a Weld expression is thus:\n    1. ""Finish"" the Weld program by adding a function header\n    2. Compile the Weld program and load it as a dynamic library\n    3. For each argument, run object.encoder on each argument. See\n       WeldObjectEncoder for details on how this works\n    4. Pass the encoded arguments to Weld\n    5. Run the decoder on the return value. See WeldObjectDecoder for details\n       on how this works.\n    6. Return the decoded value.\n    """"""\n\n    # Counter for assigning variable names\n    _var_num = 0\n    _obj_id = 100\n    _registry = {}\n\n    def __init__(self, encoder, decoder):\n        self.encoder = encoder\n        self.decoder = decoder\n\n        # Weld program\n        self.weld_code = """"\n        self.dependencies = {}\n\n        # Assign a unique ID to the context\n        self.obj_id = ""obj%d"" % WeldObject._obj_id\n        WeldObject._obj_id += 1\n\n        # Maps name -> input data\n        self.context = {}\n        # Maps name -> arg type (for arguments that don\'t need to be encoded)\n        self.argtypes = {}\n\n    def __repr__(self):\n        return self.weld_code + "" "" + str(self.context) + "" "" + str([obj_id for obj_id in self.dependencies])\n\n    @staticmethod\n    def generate_input_name(value_str):\n        name = ""_inp%d"" % WeldObject._var_num\n        WeldObject._var_num += 1\n        WeldObject._registry[value_str] = name\n\n        return name\n\n    def update(self, value, tys=None, override=True):\n        """"""Update this context.\n\n        If value is another context,\n        the names from that context are added into this one.\n        Otherwise, a new name is assigned and returned.\n        TODO tys for inputs.\n        """"""\n        if isinstance(value, WeldObject):\n            self.context.update(value.context)\n        else:\n            # Ensure that the same inputs always have same names\n            value_str = str(value)\n            if value_str in WeldObject._registry:\n                name = WeldObject._registry[value_str]\n            else:\n                name = WeldObject.generate_input_name(value_str)\n            self.context[name] = value\n            if tys is not None and not override:\n                self.argtypes[name] = tys\n\n            return name\n\n    def get_let_statements(self):\n        queue = [self]\n        visited = set()\n        let_statements = []\n        is_first = True\n        while len(queue) > 0:\n            cur_obj = queue.pop()\n            cur_obj_id = cur_obj.obj_id\n            if cur_obj_id in visited:\n                continue\n            if not is_first:\n                let_statements.insert(0, ""let %s = (%s);"" % (cur_obj_id, cur_obj.weld_code))\n            is_first = False\n            for key in sorted(cur_obj.dependencies.keys()):\n                queue.append(cur_obj.dependencies[key])\n            visited.add(cur_obj_id)\n        let_statements.sort()  # To ensure that let statements are in the right order in the final generated program\n\n        return ""\\n"".join(let_statements)\n\n    def to_weld_func(self):\n        names = sorted(self.context.keys())\n        arg_strs = [""{0}: {1}"".format(str(name),\n                                      str(self.encoder.py_to_weld_type(self.context[name])))\n                    for name in names]\n        header = ""|"" + "", "".join(arg_strs) + ""|""\n        text = header + "" "" + self.get_let_statements() + ""\\n"" + self.weld_code\n\n        return text\n\n    def evaluate(self, restype, verbose=True, decode=True, passes=None,\n                 num_threads=1, apply_experimental_transforms=False):\n        func = self.to_weld_func()\n\n        # Returns a wrapped ctypes Structure\n        def args_factory(encoded_fields):\n            class Args(ctypes.Structure):\n                _fields_ = [e for e in encoded_fields]\n\n            return Args\n\n        # Encode each input argument. This is the positional argument list\n        # which will be wrapped into a Weld struct and passed to the Weld API.\n        names = sorted(self.context.keys())\n\n        start = time.time()\n        encoded = []\n        argtypes = []\n        for name in names:\n            if name in self.argtypes:\n                argtypes.append(self.argtypes[name].ctype_class)\n                encoded.append(self.context[name])\n            else:\n                argtypes.append(self.encoder.py_to_weld_type(\n                    self.context[name]).ctype_class)\n                encoded.append(self.encoder.encode(self.context[name]))\n        end = time.time()\n\n        if verbose:\n            print(""Python->Weld:"", end - start)\n\n        args = args_factory(zip(names, argtypes))\n        weld_args = args()\n        for name, value in zip(names, encoded):\n            setattr(weld_args, name, value)\n\n        start = time.time()\n        void_ptr = ctypes.cast(ctypes.byref(weld_args), ctypes.c_void_p)\n        arg = cweld.WeldValue(void_ptr)\n        conf = cweld.WeldConf()\n        err = cweld.WeldError()\n\n        if passes is not None:\n            passes = "","".join(passes)\n            passes = passes.strip()\n            if passes != """":\n                conf.set(""weld.optimization.passes"", passes)\n\n        module = cweld.WeldModule(func, conf, err)\n        if err.code() != 0:\n            raise ValueError(""Could not compile function {}: {}"".format(\n                func, err.message()))\n        end = time.time()\n\n        if verbose:\n            print(""Weld compile time:"", end - start)\n\n        start = time.time()\n        conf = cweld.WeldConf()\n        conf.set(""weld.threads"", str(num_threads))\n        conf.set(""weld.memory.limit"", ""100000000000"")\n        conf.set(""weld.optimization.applyExperimentalTransforms"",\n                 ""true"" if apply_experimental_transforms else ""false"")\n        err = cweld.WeldError()\n        weld_ret = module.run(conf, arg, err)\n        if err.code() != 0:\n            raise ValueError((""Error while running function,\\n{}\\n\\n""\n                              ""Error message: {}"").format(\n                func, err.message()))\n        ptrtype = POINTER(restype.ctype_class)\n        data = ctypes.cast(weld_ret.data(), ptrtype)\n        end = time.time()\n\n        if verbose:\n            print(""Weld:"", end - start)\n\n        start = time.time()\n        if decode:\n            result = self.decoder.decode(data, restype)\n        else:\n            data = cweld.WeldValue(weld_ret).data()\n            result = ctypes.cast(data, ctypes.POINTER(\n                ctypes.c_int64)).contents.value\n        end = time.time()\n\n        if verbose:\n            print(""Weld->Python:"", end - start)\n\n        return result\n'"
tests/core/cudf/__init__.py,0,b''
tests/core/indexes/__init__.py,0,b''
tests/core/indexes/test_base.py,28,"b""import numpy as np\nimport pytest\n\nfrom baloo import Index\n\n\ndef assert_index_equal(actual, expected, sort=False):\n    actual = actual.evaluate()\n    expected = expected.evaluate()\n\n    actual_values = actual.values\n    expected_values = expected.values\n    if sort:\n        actual_values = np.sort(actual_values)\n        expected_values = np.sort(expected_values)\n    np.testing.assert_array_equal(actual_values, expected_values)\n\n    assert actual.dtype.char == expected.dtype.char\n    assert actual._length == expected._length\n    # might seem redundant but testing the __len__ function\n    assert len(actual) == len(expected)\n    assert actual.name == expected.name\n\n\nclass TestBaseIndex(object):\n    def test_init_list(self):\n        data = [1, 2, 3]\n        actual = Index(data)\n        expected = Index(np.array(data))\n\n        assert_index_equal(actual, expected)\n\n    def test_evaluate(self, data_i64):\n        actual = Index(data_i64)\n        expected = Index(data_i64, np.dtype(np.int64), None)\n\n        assert_index_equal(actual, expected)\n\n    def test_len_raw(self, data_i64):\n        ind = Index(data_i64, np.dtype(np.int64))\n\n        actual = len(ind)\n        expected = 5\n\n        assert actual == expected\n\n    def test_len_lazy(self, data_i64_lazy):\n        ind = Index(data_i64_lazy, np.dtype(np.int64))\n\n        actual = len(ind)\n        expected = 5\n\n        assert actual == expected\n\n    def test_comparison(self, index_i64):\n        actual = index_i64 < 3\n        expected = Index(np.array([True, True, True, False, False]))\n\n        assert_index_equal(actual, expected)\n\n    def test_filter(self, index_i64):\n        actual = index_i64[Index(np.array([False, True, True, False, False]))]\n        expected = Index(np.array([1, 2]), np.dtype(np.int64))\n\n        assert_index_equal(actual, expected)\n\n    def test_slice(self, index_i64):\n        actual = index_i64[1:3]\n        expected = Index(np.array([1, 2]), np.dtype(np.int64))\n\n        assert_index_equal(actual, expected)\n\n    def test_head(self, index_i64):\n        actual = index_i64.head(2)\n        expected = Index(np.array([0, 1]), np.dtype(np.int64))\n\n        assert_index_equal(actual, expected)\n\n    def test_tail(self, index_i64):\n        actual = index_i64.tail(2)\n        expected = Index(np.array([3, 4]), np.dtype(np.int64))\n\n        assert_index_equal(actual, expected)\n\n    # implicitly tests if one can apply operation with Series too\n    @pytest.mark.parametrize('operation, expected_data', [\n        ('+', np.arange(3, 8, dtype=np.float32)),\n        ('-', np.arange(-1, 4, dtype=np.float32)),\n        ('*', np.arange(2, 11, 2, dtype=np.float32)),\n        ('/', np.array([0.5, 1, 1.5, 2, 2.5], dtype=np.float32)),\n        ('**', np.array([1, 4, 9, 16, 25], dtype=np.float32))\n    ])\n    def test_op_array(self, operation, expected_data, data_f32, op_array_other):\n        data = Index(data_f32)\n\n        actual = eval('data {} op_array_other'.format(operation))\n        expected = Index(expected_data, np.dtype(np.float32))\n\n        assert_index_equal(actual, expected)\n\n    @pytest.mark.parametrize('operation, expected_data', [\n        ('+', np.arange(3, 8, dtype=np.float32)),\n        ('-', np.arange(-1, 4, dtype=np.float32)),\n        ('*', np.arange(2, 11, 2, dtype=np.float32)),\n        ('/', np.array([0.5, 1, 1.5, 2, 2.5], dtype=np.float32)),\n        ('**', np.array([1, 4, 9, 16, 25], dtype=np.float32))\n    ])\n    def test_op_scalar(self, operation, expected_data, data_f32):\n        ind = Index(data_f32)\n\n        actual = eval('ind {} 2'.format(operation))\n        expected = Index(expected_data, np.dtype(np.float32))\n\n        assert_index_equal(actual, expected)\n\n    def test_isna(self):\n        ind = Index([3, 2, -999, 4, -999])\n\n        actual = ind.isna()\n        expected = Index([False, False, True, False, True], np.dtype(np.bool))\n\n        assert_index_equal(actual, expected)\n\n    def test_dropna(self):\n        ind = Index([3, 2, -999, 4, -999])\n\n        actual = ind.dropna()\n        expected = Index([3, 2, 4], np.dtype(np.int64))\n\n        assert_index_equal(actual, expected)\n\n    def test_fillna(self):\n        ind = Index([3, 2, -999, 4, -999])\n\n        actual = ind.fillna(15)\n        expected = Index([3, 2, 15, 4, 15], np.dtype(np.int64))\n\n        assert_index_equal(actual, expected)\n"""
tests/core/indexes/test_multi.py,7,"b'import numpy as np\n\nfrom baloo import MultiIndex, Index\nfrom .test_base import assert_index_equal\n\n\ndef assert_multiindex_equal(actual, expected, sort=False):\n    actual = actual.evaluate()\n    expected = expected.evaluate()\n\n    assert actual._length == expected._length\n    assert len(actual) == len(expected)\n    assert actual.names == expected.names\n    assert actual.dtypes == expected.dtypes\n    for i in range(len(actual.values)):\n        assert_index_equal(actual.values[i], expected.values[i], sort=sort)\n\n\nclass TestMultiIndex(object):\n    def test_evaluate(self, data_f32, index_i64):\n        actual = MultiIndex([data_f32, index_i64]).evaluate()\n        expected = MultiIndex([Index(data_f32, np.dtype(np.float32)), index_i64])\n\n        assert_multiindex_equal(actual, expected)\n\n    def test_len_raw(self, data_f32, data_i64):\n        ind = MultiIndex([data_f32, data_i64])\n\n        actual = len(ind)\n        expected = 5\n\n        assert actual == expected\n\n    def test_filter(self, data_f32, index_i64):\n        mi = MultiIndex([data_f32, index_i64])\n\n        actual = mi[Index(np.array([False, True, True, False, False]))]\n        expected = MultiIndex([Index(np.array([2, 3], dtype=np.float32), np.dtype(np.float32)),\n                               Index(np.array([1, 2], dtype=np.int64), np.dtype(np.int64))])\n\n        assert_multiindex_equal(actual, expected)\n\n    def test_slice(self, data_f32, index_i64):\n        mi = MultiIndex([data_f32, index_i64])\n\n        actual = mi[1:3]\n        expected = MultiIndex([Index(np.array([2, 3], dtype=np.float32), np.dtype(np.float32)),\n                               Index(np.array([1, 2], dtype=np.int64), np.dtype(np.int64))])\n\n        assert_multiindex_equal(actual, expected)\n\n    def test_dropna(self):\n        mi = MultiIndex([[0, -999, 2, -999], Index([1., -999., -999., 3.], dtype=np.dtype(np.float64))])\n\n        actual = mi.dropna()\n        expected = MultiIndex([[0], [1.]])\n\n        assert_multiindex_equal(actual, expected)\n'"
tests/core/indexes/test_range.py,17,"b""import numpy as np\nimport pytest\n\nfrom baloo import RangeIndex, Index\nfrom baloo.weld import create_placeholder_weld_object, WeldObject, WeldLong\nfrom .test_base import assert_index_equal\n\n\ndef assert_range_equal(actual, expected):\n    assert actual.start == expected.start\n\n    if isinstance(actual.stop, WeldObject):\n        actual.stop = actual.stop.evaluate(WeldLong(), verbose=False)\n    assert actual.stop == expected.stop\n\n    if isinstance(expected.stop, WeldObject):\n        expected.stop = expected.stop.evaluate(WeldLong(), verbose=False)\n    assert actual.step == expected.step\n\n    actual = actual.evaluate()\n    expected = expected.evaluate()\n\n    assert_index_equal(actual, expected)\n\n\nclass TestRangeIndex(object):\n    def test_init_single_arg(self, range_index):\n        assert_range_equal(RangeIndex(5), range_index)\n\n    def test_init_single_arg_lazy(self, data_i64, range_index):\n        weld_obj = create_placeholder_weld_object(data_i64)\n        weld_obj.weld_code = 'len({})'.format(weld_obj.weld_code)\n        actual = RangeIndex(weld_obj)\n\n        assert_range_equal(actual, range_index)\n\n    # TODO: change when implemented\n    def test_init_negative_step(self):\n        with pytest.raises(ValueError):\n            RangeIndex(5, 0, -1)\n\n    def test_evaluate(self, index_i64, range_index):\n        actual = range_index.evaluate()\n        expected = index_i64\n\n        assert_index_equal(actual, expected)\n\n    def test_len_raw(self, range_index):\n        actual = len(range_index)\n        expected = 5\n\n        assert actual == expected\n\n    def test_len_lazy(self, data_i64):\n        weld_obj = create_placeholder_weld_object(data_i64)\n        weld_obj.weld_code = 'len({})'.format(weld_obj.weld_code)\n        ind = RangeIndex(weld_obj)\n\n        actual = len(ind)\n        expected = 5\n\n        assert actual == expected\n\n    def test_comparison(self, range_index):\n        actual = range_index < 3\n        expected = Index(np.array([True, True, True, False, False]))\n\n        assert_index_equal(actual, expected)\n\n        with pytest.raises(TypeError):\n            range_index < 3.0\n\n    def test_filter(self, range_index):\n        actual = range_index[Index(np.array([False, True, True, False, False]))]\n        expected = Index(np.array([1, 2]), np.dtype(np.int64))\n\n        assert_index_equal(actual, expected)\n\n    def test_slice(self, range_index):\n        actual = range_index[1:3]\n        expected = Index(np.array([1, 2]), np.dtype(np.int64))\n\n        assert_index_equal(actual, expected)\n\n    def test_head(self, range_index):\n        actual = range_index.head(2)\n        expected = Index(np.array([0, 1]))\n\n        assert_index_equal(actual, expected)\n\n    def test_tail(self, range_index):\n        actual = range_index.tail(2)\n        expected = Index(np.array([3, 4]))\n\n        assert_index_equal(actual, expected)\n\n    @pytest.mark.parametrize('operation, expected_data', [\n        ('+', np.array(np.arange(2, 7))),\n        ('-', np.array(np.arange(-2, 3))),\n        ('*', np.array(np.arange(0, 9, 2))),\n        ('/', np.array([0, 0, 1, 1, 2]))\n    ])\n    def test_op_array(self, operation, expected_data, range_index):\n        other = Index(np.array([2] * 5))\n\n        actual = eval('range_index {} other'.format(operation))\n        expected = Index(expected_data, np.dtype(np.int64))\n\n        assert_index_equal(actual, expected)\n\n    @pytest.mark.parametrize('operation, expected_data', [\n        ('+', np.array(np.arange(2, 7))),\n        ('-', np.array(np.arange(-2, 3))),\n        ('*', np.array(np.arange(0, 9, 2))),\n        ('/', np.array([0, 0, 1, 1, 2]))\n    ])\n    def test_op_scalar(self, operation, expected_data, range_index):\n        actual = eval('range_index {} 2'.format(operation))\n        expected = Index(expected_data, np.dtype(np.int64))\n\n        assert_index_equal(actual, expected)\n"""
tests/core/indexes/utils.py,0,"b""from baloo import RangeIndex, Index, MultiIndex\n\n\ndef assert_indexes_equal(actual, expected, sort=False):\n    if type(actual) != type(expected):\n        raise AssertionError('Expected indexes of the same type')\n\n    from .test_base import assert_index_equal\n    from .test_range import assert_range_equal\n    from .test_multi import assert_multiindex_equal\n\n    if isinstance(actual, RangeIndex):\n        assert_range_equal(actual, expected)\n    elif isinstance(actual, Index):\n        assert_index_equal(actual, expected, sort=sort)\n    elif isinstance(actual, MultiIndex):\n        assert_multiindex_equal(actual, expected, sort=sort)\n"""
