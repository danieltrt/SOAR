file_path,api_count,code
eulerian.py,3,"b'import numpy as np\nimport scipy.fftpack as fftpack\n\n\n# Temporal bandpass filter with Fast-Fourier Transform\ndef fft_filter(video, freq_min, freq_max, fps):\n    fft = fftpack.fft(video, axis=0)\n    frequencies = fftpack.fftfreq(video.shape[0], d=1.0 / fps)\n    bound_low = (np.abs(frequencies - freq_min)).argmin()\n    bound_high = (np.abs(frequencies - freq_max)).argmin()\n    fft[:bound_low] = 0\n    fft[bound_high:-bound_high] = 0\n    fft[-bound_low:] = 0\n    iff = fftpack.ifft(fft, axis=0)\n    result = np.abs(iff)\n    result *= 100  # Amplification factor\n\n    return result, fft, frequencies'"
heartrate.py,0,"b'from scipy import signal\n\n\n# Calculate heart rate from FFT peaks\ndef find_heart_rate(fft, freqs, freq_min, freq_max):\n    fft_maximums = []\n\n    for i in range(fft.shape[0]):\n        if freq_min <= freqs[i] <= freq_max:\n            fftMap = abs(fft[i])\n            fft_maximums.append(fftMap.max())\n        else:\n            fft_maximums.append(0)\n\n    peaks, properties = signal.find_peaks(fft_maximums)\n    max_peak = -1\n    max_freq = 0\n\n    # Find frequency with max amplitude in peaks\n    for peak in peaks:\n        if fft_maximums[peak] > max_freq:\n            max_freq = fft_maximums[peak]\n            max_peak = peak\n\n    return freqs[max_peak] * 60\n'"
main.py,0,"b'import cv2\nimport pyramids\nimport heartrate\nimport preprocessing\nimport eulerian\n\n# Frequency range for Fast-Fourier Transform\nfreq_min = 1\nfreq_max = 1.8\n\n# Preprocessing phase\nprint(""Reading + preprocessing video..."")\nvideo_frames, frame_ct, fps = preprocessing.read_video(""videos/rohin_active.mov"")\n\n# Build Laplacian video pyramid\nprint(""Building Laplacian video pyramid..."")\nlap_video = pyramids.build_video_pyramid(video_frames)\n\namplified_video_pyramid = []\n\nfor i, video in enumerate(lap_video):\n    if i == 0 or i == len(lap_video)-1:\n        continue\n\n    # Eulerian magnification with temporal FFT filtering\n    print(""Running FFT and Eulerian magnification..."")\n    result, fft, frequencies = eulerian.fft_filter(video, freq_min, freq_max, fps)\n    lap_video[i] += result\n\n    # Calculate heart rate\n    print(""Calculating heart rate..."")\n    heart_rate = heartrate.find_heart_rate(fft, frequencies, freq_min, freq_max)\n\n# Collapse laplacian pyramid to generate final video\nprint(""Rebuilding final video..."")\namplified_frames = pyramids.collapse_laplacian_video_pyramid(lap_video, frame_ct)\n\n# Output heart rate and final video\nprint(""Heart rate: "", heart_rate, ""bpm"")\nprint(""Displaying final video..."")\n\nfor frame in amplified_frames:\n    cv2.imshow(""frame"", frame)\n    cv2.waitKey(20)\n\n\n'"
preprocessing.py,1,"b'import cv2\nimport numpy as np\n\nfaceCascade = cv2.CascadeClassifier(""haarcascades/haarcascade_frontalface_alt0.xml"")\n\n\n# Read in and simultaneously preprocess video\ndef read_video(path):\n    cap = cv2.VideoCapture(path)\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    video_frames = []\n    face_rects = ()\n\n    while cap.isOpened():\n        ret, img = cap.read()\n        if not ret:\n            break\n        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        roi_frame = img\n\n        # Detect face\n        if len(video_frames) == 0:\n            face_rects = faceCascade.detectMultiScale(gray, 1.3, 5)\n\n        # Select ROI\n        if len(face_rects) > 0:\n            for (x, y, w, h) in face_rects:\n                roi_frame = img[y:y + h, x:x + w]\n            if roi_frame.size != img.size:\n                roi_frame = cv2.resize(roi_frame, (500, 500))\n                frame = np.ndarray(shape=roi_frame.shape, dtype=""float"")\n                frame[:] = roi_frame * (1. / 255)\n                video_frames.append(frame)\n\n    frame_ct = len(video_frames)\n    cap.release()\n\n    return video_frames, frame_ct, fps\n'"
pyramids.py,2,"b'import cv2\nimport numpy as np\n\n\n# Build Gaussian image pyramid\ndef build_gaussian_pyramid(img, levels):\n    float_img = np.ndarray(shape=img.shape, dtype=""float"")\n    float_img[:] = img\n    pyramid = [float_img]\n\n    for i in range(levels-1):\n        float_img = cv2.pyrDown(float_img)\n        pyramid.append(float_img)\n\n    return pyramid\n\n\n# Build Laplacian image pyramid from Gaussian pyramid\ndef build_laplacian_pyramid(img, levels):\n    gaussian_pyramid = build_gaussian_pyramid(img, levels)\n    laplacian_pyramid = []\n\n    for i in range(levels-1):\n        upsampled = cv2.pyrUp(gaussian_pyramid[i+1])\n        (height, width, depth) = upsampled.shape\n        gaussian_pyramid[i] = cv2.resize(gaussian_pyramid[i], (height, width))\n        diff = cv2.subtract(gaussian_pyramid[i],upsampled)\n        laplacian_pyramid.append(diff)\n\n    laplacian_pyramid.append(gaussian_pyramid[-1])\n\n    return laplacian_pyramid\n\n\n# Build video pyramid by building Laplacian pyramid for each frame\ndef build_video_pyramid(frames):\n    lap_video = []\n\n    for i, frame in enumerate(frames):\n        pyramid = build_laplacian_pyramid(frame, 3)\n        for j in range(3):\n            if i == 0:\n                lap_video.append(np.zeros((len(frames), pyramid[j].shape[0], pyramid[j].shape[1], 3)))\n            lap_video[j][i] = pyramid[j]\n\n    return lap_video\n\n\n# Collapse video pyramid by collapsing each frame\'s Laplacian pyramid\ndef collapse_laplacian_video_pyramid(video, frame_ct):\n    collapsed_video = []\n\n    for i in range(frame_ct):\n        prev_frame = video[-1][i]\n\n        for level in range(len(video) - 1, 0, -1):\n            pyr_up_frame = cv2.pyrUp(prev_frame)\n            (height, width, depth) = pyr_up_frame.shape\n            prev_level_frame = video[level - 1][i]\n            prev_level_frame = cv2.resize(prev_level_frame, (height, width))\n            prev_frame = pyr_up_frame + prev_level_frame\n\n        # Normalize pixel values\n        min_val = min(0.0, prev_frame.min())\n        prev_frame = prev_frame + min_val\n        max_val = max(1.0, prev_frame.max())\n        prev_frame = prev_frame / max_val\n        prev_frame = prev_frame * 255\n\n        prev_frame = cv2.convertScaleAbs(prev_frame)\n        collapsed_video.append(prev_frame)\n\n    return collapsed_video\n'"
