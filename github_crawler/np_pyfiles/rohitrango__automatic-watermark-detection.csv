file_path,api_count,code
main.py,3,"b""from src import *\n\ngx, gy, gxlist, gylist = estimate_watermark('images/fotolia_processed')\n\n# est = poisson_reconstruct(gx, gy, np.zeros(gx.shape)[:,:,0])\ncropped_gx, cropped_gy = crop_watermark(gx, gy)\nW_m = poisson_reconstruct(cropped_gx, cropped_gy)\n\n# random photo\nimg = cv2.imread('images/fotolia_processed/fotolia_137840645.jpg')\nim, start, end = watermark_detector(img, cropped_gx, cropped_gy)\n\n# plt.imshow(im)\n# plt.show()\n# We are done with watermark estimation\n# W_m is the cropped watermark\nnum_images = len(gxlist)\n\nJ, img_paths = get_cropped_images('images/fotolia_processed', num_images, start, end, cropped_gx.shape)\n# get a random subset of J\nidx = [389, 144, 147, 468, 423, 92, 3, 354, 196, 53, 470, 445, 314, 349, 105, 366, 56, 168, 351, 15, 465, 368, 90, 96, 202, 54, 295, 137, 17, 79, 214, 413, 454, 305, 187, 4, 458, 330, 290, 73, 220, 118, 125, 180, 247, 243, 257, 194, 117, 320, 104, 252, 87, 95, 228, 324, 271, 398, 334, 148, 425, 190, 78, 151, 34, 310, 122, 376, 102, 260]\nidx = idx[:25]\n# Wm = (255*PlotImage(W_m))\nWm = W_m - W_m.min()\n\n# get threshold of W_m for alpha matte estimate\nalph_est = estimate_normalized_alpha(J, Wm)\nalph = np.stack([alph_est, alph_est, alph_est], axis=2)\nC, est_Ik = estimate_blend_factor(J, Wm, alph)\n\nalpha = alph.copy()\nfor i in xrange(3):\n\talpha[:,:,i] = C[i]*alpha[:,:,i]\n\nWm = Wm + alpha*est_Ik\n\nW = Wm.copy()\nfor i in xrange(3):\n\tW[:,:,i]/=C[i]\n\nJt = J[:25]\n# now we have the values of alpha, Wm, J\n# Solve for all images\nWk, Ik, W, alpha1 = solve_images(Jt, W_m, alpha, W)\n# W_m_threshold = (255*PlotImage(np.average(W_m, axis=2))).astype(np.uint8)\n# ret, thr = cv2.threshold(W_m_threshold, 127, 255, cv2.THRESH_BINARY)  \n\n"""
main_cocoset.py,4,"b'\'\'\'\nThis main file is for the Microsoft Coco dataset\n\'\'\'\nfrom src import *\n\nIMAGE_FOLDER = ""/media/rohitrango/2EC8DBB2C8DB7715/""\nIMG_LOC = ""coco_dataset""\nIMG_PROCESSED_LOC = ""coco_dataset_processed""\n\ndef get_alpha_matte(watermark, threshold=128):\n\tw = np.average(watermark, axis=2)\n\t_, w = cv2.threshold(w, threshold, 255, cv2.THRESH_BINARY_INV)\n\treturn PlotImage(w)\n\ndef P(img,e=None):\n    if e is None:\n        plt.imshow(PlotImage(img)); plt.show()\n    else:\n        plt.imshow(PlotImage(img),\'gray\'); plt.show()\n\ndef bgr2rgb(img):\n\treturn img[:,:,[2, 1, 0]]\n\'\'\'\nGround Truth values\nalpha -> coco_dataset/alpha.png\ncopyright -> coco_dataset/copyright.png\nc = .45\n\nExperiments: Threshold for estimating initial alpha -> 153, and then subtract 1 from alpha\n\'\'\'\nif __name__ == ""__main__"":\n\t# watermark = cv2.imread(\'coco_dataset/watermark.png\')\n\t# alpha = get_alpha_matte(watermark)\n\tfoldername = os.path.join(IMAGE_FOLDER, IMG_PROCESSED_LOC)\n\tgx, gy, gxlist, gylist = estimate_watermark(foldername)\n\n\t# est = poisson_reconstruct(gx, gy, np.zeros(gx.shape)[:,:,0])\n\tcropped_gx, cropped_gy = crop_watermark(gx, gy)\n\tW_m = poisson_reconstruct(cropped_gx, cropped_gy, num_iters=5000)\n\n\t# random photo\n\timg = cv2.imread(os.path.join(foldername, \'000000051008.jpg\'))\n\tim, start, end = watermark_detector(img, cropped_gx, cropped_gy)\n\tnum_images = len(gxlist)\n\n\tJ, img_paths = get_cropped_images(foldername, num_images, start, end, cropped_gx.shape)\n\t# get a random subset of J\n\tidx = [389, 144, 147, 468, 423, 92, 3, 354, 196, 53, 470, 445, 314, 349, 105, 366, 56, 168, 351, 15, 465, 368, 90, 96, 202, 54, 295, 137, 17, 79, 214, 413, 454, 305, 187, 4, 458, 330, 290, 73, 220, 118, 125, 180, 247, 243, 257, 194, 117, 320, 104, 252, 87, 95, 228, 324, 271, 398, 334, 148, 425, 190, 78, 151, 34, 310, 122, 376, 102, 260]\n\tidx = idx[:25]\n\t# Wm = (255*PlotImage(W_m))\n\tWm = W_m - W_m.min()\n\n\t# get threshold of W_m for alpha matte estimate\n\talph_est = estimate_normalized_alpha(J, Wm, num_images=15, threshold=125, invert=False, adaptive=False)\n\talph = np.stack([alph_est, alph_est, alph_est], axis=2)\n\tC, est_Ik = estimate_blend_factor(J, Wm, alph)\n\n\talpha = alph.copy()\n\tfor i in xrange(3):\n\t\talpha[:,:,i] = C[i]*alpha[:,:,i]\n\n\t# Wm = Wm + alpha*est_Ik\n\n\tW = Wm.copy()\n\tfor i in xrange(3):\n\t\tW[:,:,i]/=C[i]\n\n\tJt = J[idx]\n\t# now we have the values of alpha, Wm, J\n\t# Solve for all images\n\tWk, Ik, W, alpha1 = solve_images(Jt, W_m, alpha, W)\n\t# W_m_threshold = (255*PlotImage(np.average(W_m, axis=2))).astype(np.uint8)\n\t# ret, thr = cv2.threshold(W_m_threshold, 127, 255, cv2.THRESH_BINARY)  \n\n\n\t'"
src/__init__.py,0,b'from estimate_watermark import *\nfrom preprocess import *\nfrom image_crawler import *\nfrom watermark_reconstruct import *\n'
src/closed_form_matting.py,10,"b'from __future__ import division\n\nimport numpy as np\nimport scipy.sparse\nimport scipy\nfrom scipy.sparse import *\nfrom numpy.lib.stride_tricks import as_strided\n\n\ndef rolling_block(A, block=(3, 3)):\n    shape = (A.shape[0] - block[0] + 1, A.shape[1] - block[1] + 1) + block\n    strides = (A.strides[0], A.strides[1]) + A.strides\n    return as_strided(A, shape=shape, strides=strides)\n\n\n# Returns sparse matting laplacian\ndef computeLaplacian(img, eps=10**(-7), win_rad=1):\n    win_size = (win_rad*2+1)**2\n    h, w, d = img.shape\n    # Number of window centre indices in h, w axes\n    c_h, c_w = h - 2*win_rad, w - 2*win_rad\n    win_diam = win_rad*2+1\n\n    indsM = np.arange(h*w).reshape((h, w))\n    ravelImg = img.reshape(h*w, d)\n    win_inds = rolling_block(indsM, block=(win_diam, win_diam))\n\n    win_inds = win_inds.reshape(c_h, c_w, win_size)\n    winI = ravelImg[win_inds]\n\n    win_mu = np.mean(winI, axis=2, keepdims=True)\n    win_var = np.einsum(\'...ji,...jk ->...ik\', winI, winI)/win_size - np.einsum(\'...ji,...jk ->...ik\', win_mu, win_mu)\n\n    inv = np.linalg.inv(win_var + (eps/win_size)*np.eye(3))\n\n    X = np.einsum(\'...ij,...jk->...ik\', winI - win_mu, inv)\n    vals = np.eye(win_size) - (1/win_size)*(1 + np.einsum(\'...ij,...kj->...ik\', X, winI - win_mu))\n\n    nz_indsCol = np.tile(win_inds, win_size).ravel()\n    nz_indsRow = np.repeat(win_inds, win_size).ravel()\n    nz_indsVal = vals.ravel()\n    L = scipy.sparse.coo_matrix((nz_indsVal, (nz_indsRow, nz_indsCol)), shape=(h*w, h*w))\n    return L\n\n\ndef closed_form_matte(img, scribbled_img, mylambda=100):\n    h, w,c  = img.shape\n    consts_map = (np.sum(abs(img - scribbled_img), axis=-1)>0.001).astype(np.float64)\n    #scribbled_img = rgb2gray(scribbled_img)\n\n    consts_vals = scribbled_img[:,:,0]*consts_map\n    D_s = consts_map.ravel()\n    b_s = consts_vals.ravel()\n    # print(""Computing Matting Laplacian"")\n    L = computeLaplacian(img)\n    sD_s = scipy.sparse.diags(D_s)\n    # print(""Solving for alpha"")\n    x = scipy.sparse.linalg.spsolve(L + mylambda*sD_s, mylambda*b_s)\n    alpha = np.minimum(np.maximum(x.reshape(h, w), 0), 1)\n    return alpha\n'"
src/estimate_watermark.py,14,"b'import sys, os\nimport cv2\nimport numpy as np\nimport warnings\nfrom matplotlib import pyplot as plt\nimport math\nimport numpy\nimport scipy, scipy.fftpack\n\n# Variables\nKERNEL_SIZE = 3\n\ndef estimate_watermark(foldername):\n\t""""""\n\tGiven a folder, estimate the watermark (grad(W) = median(grad(J)))\n\tAlso, give the list of gradients, so that further processing can be done on it\n\t""""""\n\tif not os.path.exists(foldername):\n\t\twarnings.warn(""Folder does not exist."", UserWarning)\n\t\treturn None\n\n\timages = []\n\tfor r, dirs, files in os.walk(foldername):\n\t\t# Get all the images\n\t\tfor file in files:\n\t\t\timg = cv2.imread(os.sep.join([r, file]))\n\t\t\tif img is not None:\n\t\t\t\timages.append(img)\n\t\t\telse:\n\t\t\t\tprint(""%s not found.""%(file))\n\n\t# Compute gradients\n\tprint(""Computing gradients."")\n\tgradx = map(lambda x: cv2.Sobel(x, cv2.CV_64F, 1, 0, ksize=KERNEL_SIZE), images)\n\tgrady = map(lambda x: cv2.Sobel(x, cv2.CV_64F, 0, 1, ksize=KERNEL_SIZE), images)\n\n\t# Compute median of grads\n\tprint(""Computing median gradients."")\n\tWm_x = np.median(np.array(gradx), axis=0) \t\t\t\t\t\n\tWm_y = np.median(np.array(grady), axis=0)\n\n\treturn (Wm_x, Wm_y, gradx, grady)\n\n\ndef PlotImage(image):\n\t"""""" \n\tPlotImage: Give a normalized image matrix which can be used with implot, etc.\n\tMaps to [0, 1]\n\t""""""\n\tim = image.astype(float)\n\treturn (im - np.min(im))/(np.max(im) - np.min(im))\n\n\ndef poisson_reconstruct2(gradx, grady, boundarysrc):\n\t# Thanks to Dr. Ramesh Raskar for providing the original matlab code from which this is derived\n\t# Dr. Raskar\'s version is available here: http://web.media.mit.edu/~raskar/photo/code.pdf\n\n\t# Laplacian\n\tgyy = grady[1:,:-1] - grady[:-1,:-1]\n\tgxx = gradx[:-1,1:] - gradx[:-1,:-1]\n\tf = numpy.zeros(boundarysrc.shape)\n\tf[:-1,1:] += gxx\n\tf[1:,:-1] += gyy\n\n\t# Boundary image\n\tboundary = boundarysrc.copy()\n\tboundary[1:-1,1:-1] = 0;\n\n\t# Subtract boundary contribution\n\tf_bp = -4*boundary[1:-1,1:-1] + boundary[1:-1,2:] + boundary[1:-1,0:-2] + boundary[2:,1:-1] + boundary[0:-2,1:-1]\n\tf = f[1:-1,1:-1] - f_bp\n\n\t# Discrete Sine Transform\n\ttt = scipy.fftpack.dst(f, norm=\'ortho\')\n\tfsin = scipy.fftpack.dst(tt.T, norm=\'ortho\').T\n\n\t# Eigenvalues\n\t(x,y) = numpy.meshgrid(range(1,f.shape[1]+1), range(1,f.shape[0]+1), copy=True)\n\tdenom = (2*numpy.cos(math.pi*x/(f.shape[1]+2))-2) + (2*numpy.cos(math.pi*y/(f.shape[0]+2)) - 2)\n\n\tf = fsin/denom\n\n\t# Inverse Discrete Sine Transform\n\ttt = scipy.fftpack.idst(f, norm=\'ortho\')\n\timg_tt = scipy.fftpack.idst(tt.T, norm=\'ortho\').T\n\n\t# New center + old boundary\n\tresult = boundary\n\tresult[1:-1,1:-1] = img_tt\n\n\treturn result\n\n\ndef poisson_reconstruct(gradx, grady, kernel_size=KERNEL_SIZE, num_iters=100, h=0.1, \n\t\tboundary_image=None, boundary_zero=True):\n\t""""""\n\tIterative algorithm for Poisson reconstruction. \n\tGiven the gradx and grady values, find laplacian, and solve for image\n\tAlso return the squared difference of every step.\n\th = convergence rate\n\t""""""\n\tfxx = cv2.Sobel(gradx, cv2.CV_64F, 1, 0, ksize=kernel_size)\n\tfyy = cv2.Sobel(grady, cv2.CV_64F, 0, 1, ksize=kernel_size)\n\tlaplacian = fxx + fyy\n\tm,n,p = laplacian.shape\n\n\tif boundary_zero == True:\n\t\test = np.zeros(laplacian.shape)\n\telse:\n\t\tassert(boundary_image is not None)\n\t\tassert(boundary_image.shape == laplacian.shape)\n\t\test = boundary_image.copy()\n\n\test[1:-1, 1:-1, :] = np.random.random((m-2, n-2, p))\n\tloss = []\n\n\tfor i in xrange(num_iters):\n\t\told_est = est.copy()\n\t\test[1:-1, 1:-1, :] = 0.25*(est[0:-2, 1:-1, :] + est[1:-1, 0:-2, :] + est[2:, 1:-1, :] + est[1:-1, 2:, :] - h*h*laplacian[1:-1, 1:-1, :])\n\t\terror = np.sum(np.square(est-old_est))\n\t\tloss.append(error)\n\n\treturn (est)\n\n\ndef image_threshold(image, threshold=0.5):\n\t\'\'\'\n\tThreshold the image to make all its elements greater than threshold*MAX = 1\n\t\'\'\'\n\tm, M = np.min(image), np.max(image)\n\tim = PlotImage(image)\n\tim[im >= threshold] = 1\n\tim[im < 1] = 0\n\treturn im\n\n\ndef crop_watermark(gradx, grady, threshold=0.4, boundary_size=2):\n\t""""""\n\tCrops the watermark by taking the edge map of magnitude of grad(W)\n\tAssumes the gradx and grady to be in 3 channels\n\t@param: threshold - gives the threshold param\n\t@param: boundary_size - boundary around cropped image\n\t""""""\n\tW_mod = np.sqrt(np.square(gradx) + np.square(grady))\n\tW_mod = PlotImage(W_mod)\n\tW_gray = image_threshold(np.average(W_mod, axis=2), threshold=threshold)\n\tx, y = np.where(W_gray == 1)\n\n\txm, xM = np.min(x) - boundary_size - 1, np.max(x) + boundary_size + 1\n\tym, yM = np.min(y) - boundary_size - 1, np.max(y) + boundary_size + 1\n\n\treturn gradx[xm:xM, ym:yM, :] , grady[xm:xM, ym:yM, :]\n\n\ndef normalized(img):\n\t""""""\n\tReturn the image between -1 to 1 so that its easier to find out things like \n\tcorrelation between images, convolutionss, etc.\n\tCurrently required for Chamfer distance for template matching.\n\t""""""\n\treturn (2*PlotImage(img)-1)\n\ndef watermark_detector(img, gx, gy, thresh_low=200, thresh_high=220, printval=False):\n\t""""""\n\tCompute a verbose edge map using Canny edge detector, take its magnitude.\n\tAssuming cropped values of gradients are given.\n\tReturns image, start and end coordinates\n\t""""""\n\tWm = (np.average(np.sqrt(np.square(gx) + np.square(gy)), axis=2))\n\n\timg_edgemap = (cv2.Canny(img, thresh_low, thresh_high))\n\tchamfer_dist = cv2.filter2D(img_edgemap.astype(float), -1, Wm)\n\n\trect = Wm.shape\n\tindex = np.unravel_index(np.argmax(chamfer_dist), img.shape[:-1])\n\tif printval:\n\t\tprint(index)\n\n\tx,y = (index[0]-rect[0]/2), (index[1]-rect[1]/2)\n\tim = img.copy()\n\tcv2.rectangle(im, (y, x), (y+rect[1], x+rect[0]), (255, 0, 0))\n\treturn (im, (x, y), (rect[0], rect[1]))\n'"
src/image_crawler.py,0,"b'import requests\nimport os\nimport argparse\nimport sys\nfrom time import sleep\n\nimport requests\nfrom bs4 import BeautifulSoup as bs\nfrom threading import Thread \n\n## variables\nfotolia_download_button = \'comp-download-buttons row-large\'\nistock_base_download_button = \'asset-link draggable\'\n\n## get the url of the image\ndef _get_image_url_fotolia(base_url, minVal, directory, index=0, num_retries = 5):\n\timg_url = """"\n\tretries = 0\n\twhile retries < num_retries:\n\t\t# try\n\t\tr = requests.get(base_url + str(minVal + index))\n\t\tif r.status_code == 200:\n\t\t\tsoup = bs(r.content, \'lxml\')\n\t\t\trow = soup.find_all(attrs={\'class\': fotolia_download_button})\n\t\t\t# check row\n\t\t\tif len(row) > 0:\n\t\t\t\tlink = row[0].findChildren()[0]\n\t\t\t\tif(link.attrs.has_key(\'href\')):\n\t\t\t\t\timg_url = link.attrs[\'href\']\n\t\t\t\t\t__download_and_save_image(img_url, directory)\n\t\t\t\telse:\n\t\t\t\t\tprint(""Error, check: "")\n\t\t\t\t\tprint(link)\n\t\t\telse:\n\t\t\t\tprint(""There is no image download button."")\n\n\t\t\tbreak\n\t\telse:\n\t\t\tretries += 1\n\n\treturn img_url\n\t\t\n# get the link\ndef _get_istock_page_and_download(link, directory):\n\t_media_url = ""media.istockphoto.com""\n\tr = requests.get(link)\n\tif r.status_code == 200:\n\t\tsoup = bs(r.content, \'lxml\')\n\t\timg = []\n\t\timg = filter(lambda x: _media_url in x.attrs[\'src\'], filter(lambda x: x.attrs.has_key(\'src\'), soup.find_all(\'img\')))\n\t\tif img == []:\n\t\t\tprint(""Cannot find image."")\n\t\telse:\n\t\t\timg_link = img[0].attrs[\'src\']\n\t\t\t__download_and_save_image(img_link, directory, src=\'istock\')\n\telse:\n\t\tprint(""Cannot connect to : "" + link)\n\n# download and save a given image\ndef __download_and_save_image(link, directory, src=\'fotolia\'):\n\tprint(""Attempting to download: "" + link)\n\tr = requests.get(link)\n\tif r.status_code == 200:\n\t\t\n\t\t# depends on source\n\t\tif src == \'fotolia\':\n\t\t\ttry:\n\t\t\t\tfilename = r.headers[\'Content-Disposition\'].split(\'filename=""\')[1][:-2]\n\t\t\texcept:\n\t\t\t\tprint(""No Content-Disposition header present."")\n\t\t\t\treturn\n\t\telif src == \'istock\':\n\t\t\ttry:\n\t\t\t\tfilename = r.headers[\'Content-Disposition\'].split(\'filename=\')[1]\n\t\t\texcept:\n\t\t\t\tprint(""No Content-Disposition header present."")\n\t\t\t\treturn\n\n\t\tfilename = os.sep.join([directory, filename])\n\t\tprint(""Saving to filename: %s ""%(filename))\n\t\twith open(filename, \'wb\') as f:\n\t\t\tf.write(r.content)\n\telse:\n\t\tprint(""Couldn\'t download from link: "" + link)\n\n\n# function to scrape from fotolia\ndef fotolia_scrape(directory, minVal=137840645, n_images=100):\n\t# make the dir first\n\tif not os.path.isdir(directory):\n\t\tos.mkdir(directory)\n\n\tbase_url = ""https://www.fotolia.com/Content/Comp/""\n\timage_url_list = [] \n\tindex = 0\n\n\t# check thread list\n\tthread_list = []\n\n\t# start threads\n\tfor index in xrange(n_images):\n\t\tth = Thread(target=_get_image_url_fotolia, args=(base_url, minVal, directory, index))\n\t\tthread_list.append(th)\n\t\tth.start()\n\n\t# join\n\tfor th in thread_list:\n\t\tth.join()\n\n\n# function to scrape from istock\ndef istock_scrape(directory, topic=""abstract"", n_images=100):\n\n\t## iStock blocks you, be careful\n\t# raise NotImplementedError(""iStockPhotos blocks you, be careful."")\n\n\twebpage = ""https://www.istockphoto.com""\n\tbase_search_url = ""http://www.istockphoto.com/in/photos/%s""%topic\n\n\tr = requests.get(base_search_url)\n\tlinks_list = []\n\tif r.status_code == 200:\n\t\tsoup = bs(r.content, \'lxml\')\n\t\tlinks = map(lambda x: webpage + x.attrs[\'href\'], soup.find_all(attrs={\'class\': istock_base_download_button}))\n\t\tlinks_list += links\n\n\t\tnextPageLink = soup.find_all(attrs={\'id\':\'next-gallery-page\'})\n\t\tprint(""Moving to next page."")\n\t\tsleep(0.5)\n\n\t\twhile(nextPageLink != [] and len(links_list) < n_images):\n\t\t\thref = webpage + nextPageLink[0].attrs[\'href\']\n\t\t\tr = requests.get(href)\n\t\t\tif r.status_code == 200:\n\t\t\t\tsoup = bs(r.content, \'lxml\')\n\t\t\t\tlinks = map(lambda x: webpage + x.attrs[\'href\'], soup.find_all(attrs={\'class\': istock_base_download_button}))\n\t\t\t\tlinks_list += links\n\t\t\t\tnextPageLink = soup.find_all(attrs={\'id\':\'next-gallery-page\'})\n\t\t\t\tprint(""Moving to next page."")\n\t\t\telse:\n\t\t\t\tnextPageLink = []\n\t\t\t\tprint(""No next page found."")\n\n\t\tthread_list = []\n\t\t## we have the list of link, go to each link and download it\n\t\tfor link in links_list:\n\t\t\tth  = Thread(target=_get_istock_page_and_download, args=(link, directory))\n\t\t\tthread_list.append(th)\n\t\t\tth.start()\n\t\t\tth.join()\n\t\t\tsleep(1)\n\n\t\t# for th in thread_list:\n\t\t# \tth.join()\n\n\n\'\'\' \nMain function here\n\'\'\'\nif __name__ == ""__main__"":\n\tparser = argparse.ArgumentParser(description=\'Scrape from stock images\')\n\tparser.add_argument(\'-f\', dest=\'folder\', help=\'Specify the folder where to place the images.\')\n\tparser.add_argument(\'-u\', dest=\'url\', help=\'Specify the place from where to scrape.\')\n\targs = parser.parse_args()\n\n\tif args.url is None:\n\t\tparser.print_help()\n\t\tsys.exit(0)\n\telse:\n\t\t# define the folder\n\t\tif args.folder is None:\n\t\t\tdirectory = "".""\n\t\telse:\n\t\t\tdirectory = args.folder\n\n\t\t# check for the param\n\t\tif ""fotolia"" in args.url:\n\t\t\tfotolia_scrape(directory, n_images=100)\n\n\t\telif ""istock"" in args.url:\n\t\t\tistock_scrape(directory, n_images=150, topic=\'mountains\')\n\n\n\t\tprint(""Done."")\n\n\t\t'"
src/preprocess.py,1,"b'import sys, os\nimport cv2\nimport numpy as np\n\n\ndef preprocess(foldername, size=500, suffix=""_processed""):\n\n\tdest_folder = foldername + suffix\n\tprocessed=os.path.abspath(dest_folder)\n\n\tif os.path.exists(processed):\n\t\tprint (""Directory %s already exists.""%(processed))\n\t\treturn None\n\t\t\n\tos.mkdir(dest_folder)\n\n\tfor root, dirs, files in os.walk(foldername):\n\t\tfor file in files:\n\t\t\tpath = (os.sep.join([os.path.abspath(root), file]))\n\t\t\timg = cv2.imread(path)\n\t\t\tif img is not None:\n\t\t\t\tm,n,p = img.shape\n\t\t\t\tm_t, n_t = (size-m)/2, (size-n)/2\n\t\t\t\tfinal_img = np.pad(img, ((m_t, size-m-m_t), (n_t, size-n-n_t), (0, 0)), mode=\'constant\')\n\t\t\t\tcv2.imwrite(os.sep.join([dest_folder, file]), final_img)\n\t\t\t\tprint(""Saved to : %s""%(file))\n\t\t\t\tprint(final_img.shape)\n\n\nif __name__ == ""__main__"":\n\tif len(sys.argv) < 2:\n\t\tprint(""Format : %s <foldername>""%(sys.argv[0]))\n\telse:\n\t\tpreprocess(sys.argv[1])'"
src/tensorflow_experiments.py,3,"b'import tensorflow as tf\nimport numpy as np\nimport cv2\nimport os\nimport scipy\nfrom scipy.sparse import *\n\n# helpers that are going to be useful here\nsobel_x = tf.constant([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], tf.float32)\nsobel_y = tf.transpose(sobel_x)\n\nsobel_x_filter = tf.stack([sobel_x, sobel_x, sobel_x])\nsobel_x_filter = tf.stack([sobel_x_filter, sobel_x_filter, sobel_x_filter])\n\nsobel_y_filter = tf.stack([sobel_y, sobel_y, sobel_y])\nsobel_y_filter = tf.stack([sobel_y_filter, sobel_y_filter, sobel_y_filter])\n\ndef phi_func(mtensor, epsilon=0.001):\n    return tf.sqrt(mtensor + epsilon**2)\n    \n# E_data\ndef E_data(I, W, J, alpha):\n    est_error = tf.multiply(alpha, W) + tf.multiply(1-alpha, I) - J\n    est_error = phi_func(tf.square(est_error))\n    est_error = tf.reduce_mean(est_error)\n    return est_error\n\n# regularizer term for I, W\ndef E_reg(I, alpha):\n    alpha_ = tf.expand_dims(alpha, 0)\n    ax = tf.nn.conv2d(alpha_, sobel_x_filter, strides=[1, 1, 1, 1], padding=""SAME"")\n    ay = tf.nn.conv2d(alpha_, sobel_y_filter, strides=[1, 1, 1, 1], padding=""SAME"")\n    Ix2 = tf.square(tf.nn.conv2d(I, sobel_x_filter, strides=[1, 1, 1, 1], padding=""SAME""))\n    Iy2 = tf.square(tf.nn.conv2d(I, sobel_y_filter, strides=[1, 1, 1, 1], padding=""SAME""))\n    est_error = tf.multiply(tf.abs(ax), Ix2) + tf.multiply(tf.abs(ay), Iy2)\n    est_error = tf.reduce_mean(phi_func(est_error))\n    return est_error\n\n# regularization term for alpha\ndef E_reg_alpha(alpha):\n    alpha_ = tf.expand_dims(alpha, 0)\n    ax2 = tf.square(tf.nn.conv2d(alpha_, sobel_x_filter, strides=[1, 1, 1, 1], padding=""SAME""))\n    ay2 = tf.square(tf.nn.conv2d(alpha_, sobel_y_filter, strides=[1, 1, 1, 1], padding=""SAME""))\n    est_error = tf.reduce_mean(phi_func(ax2 + ay2))\n    return est_error\n\n# fidelity term\n# W = all watermarks, or W_median\ndef E_f(alpha, W, W_m):\n    aW = tf.multiply(alpha, W)\n    shape = aW.shape.as_list()\n    if len(shape) == 3:\n        aW = tf.expand_dims(aW, 0)\n    # find edge map of alpha*W\n    aWx = tf.nn.conv2d(aW, sobel_x_filter, strides=[1, 1, 1, 1], padding=""SAME"")\n    aWy = tf.nn.conv2d(aW, sobel_y_filter, strides=[1, 1, 1, 1], padding=""SAME"")\n    aW_ = tf.sqrt(tf.square(aWx) + tf.square(aWy))\n    \n    # find edge map of W_m\n    W_m__ = tf.expand_dims(W_m, 0)\n    W_mx = tf.nn.conv2d(W_m__, sobel_x_filter, strides=[1, 1, 1, 1], padding=""SAME"")\n    W_my = tf.nn.conv2d(W_m__, sobel_y_filter, strides=[1, 1, 1, 1], padding=""SAME"")\n    W_m_ = tf.sqrt(tf.square(W_mx) + tf.square(W_my))\n    \n    return tf.reduce_mean(phi_func(tf.square(aW_ - W_m_)))\n\n# auxiliary term\ndef E_aux(W, W_k):\n    return tf.reduce_mean(tf.abs(W - W_k))\n\n# We try to use Tensorflow to perform the 3 steps\ndef image_watermark_decompose_model(num_images, m, n, chan=3, l_i=1, l_w=1, l_alpha=1, beta=1, gamma=1, lr=0.07):\n    # We have the following parameters\n    # num_images = number of images, m, n, number of channels\n    # lambda_i, lambda_w, lambda_alpha, beta, and gamma are parameters\n    # Input to network: \n    #    J(k) = (num_images, m, n, chan) -> all the images\n    #    W_m = (m, n, chan)   -> estimate of the watermark obtained before\n    #    W_median =   (m, n, chan)   -> new estimate of W\n    #    alpha = (m, n, chan) -> estimate of alpha matte\n    # Entities to estimate\n    #    I(k) = (num_images, m, n, chan) -> all watermarked images\n    #    W(k) = (num_images, m, n, chan) -> all watermarks\n    \n    # All placeholders\n    J = tf.placeholder(tf.float32, shape=(num_images, m, n, chan), name=\'J\')\n    alpha = tf.placeholder(tf.float32, shape=(m, n, chan), name=\'alpha\')\n    W_m = tf.placeholder(tf.float32, shape=(m, n, chan), name=\'W_m\')\n    W_median = tf.placeholder(tf.float32, shape=(m, n, chan), name=\'W_median\')\n    \n    # All variables\n    I = tf.Variable(np.random.randn(num_images, m, n, chan), name=\'I\', dtype=tf.float32)\n    W = tf.Variable(np.random.randn(num_images, m, n, chan), name=\'W\', dtype=tf.float32)\n    \n    # compute loss\n    loss = E_data(I, W, J, alpha) + l_i*E_reg(I, alpha) + l_w*E_reg(W, alpha) \\\n            + beta*E_f(alpha, W, W_m) + gamma*E_aux(W_median, W)\n    \n    optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n    return {\n        \'J\': J,\n        \'alpha\': alpha,\n        \'W_m\': W_m,\n        \'W_median\': W_median, \n        \'I\': I,\n        \'W\': W,\n        \'loss\': loss,\n        \'step\': optimizer,\n    }\n\n\n# matte update\ndef matte_update_model(num_images, m, n, chan=3, l_alpha=1, beta=1, lr=0.07):\n    # We use the rest of the items as constants and only estimate alpha\n\n    # All placeholders\n    J = tf.placeholder(tf.float32, shape=(num_images, m, n, chan), name=\'J\')\n    W_m = tf.placeholder(tf.float32, shape=(m, n, chan), name=\'W_m\')\n    W_median = tf.placeholder(tf.float32, shape=(m, n, chan), name=\'W_median\')\n    I = tf.placeholder(tf.float32, shape=(num_images, m, n, chan), name=\'I\')\n    W = tf.placeholder(tf.float32, shape=(num_images, m, n, chan), name=\'W\')\n\n    alpha = tf.Variable(np.random.randn(m, n, chan), dtype=tf.float32)\n\n    loss = E_data(I, W, J, alpha) + l_alpha*E_reg_alpha(alpha) + beta*E_f(alpha, W_median, W_m)\n    optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n\n    return {\n        \'J\': J,\n        \'alpha\': alpha,\n        \'W_m\': W_m,\n        \'W_median\': W_median, \n        \'I\': I,\n        \'W\': W,\n        \'loss\': loss,\n        \'step\': optimizer,\n    }\n'"
src/watermark_reconstruct.py,27,"b'import numpy as np\nimport cv2\nimport os\nimport scipy\nfrom scipy.sparse import *\nfrom scipy.sparse import linalg\nfrom estimate_watermark import *\nfrom closed_form_matting import *\nfrom numpy import nan, isnan\n\ndef get_cropped_images(foldername, num_images, start, end, shape):\n    \'\'\'\n    This is the part where we get all the images, extract their parts, and then add it to our matrix\n    \'\'\'\n    images_cropped = np.zeros((num_images,) + shape)\n    # get images\n    # Store all the watermarked images\n    # start, and end are already stored\n    # just crop and store image\n    image_paths = []\n    _s, _e = start, end\n    index = 0\n\n    # Iterate over all images\n    for r, dirs, files in os.walk(foldername):\n\n        for file in files:\n            _img = cv2.imread(os.sep.join([r, file]))\n            if _img is not None:\n                # estimate the watermark part\n                image_paths.append(os.sep.join([r, file]))\n                _img = _img[_s[0]:(_s[0]+_e[0]), _s[1]:(_s[1]+_e[1]), :]\n                # add to list images\n                images_cropped[index, :, :, :] = _img\n                index+=1\n            else:\n                print(""%s not found.""%(file))\n\n    return (images_cropped, image_paths)\n\n\n# get sobel coordinates for y\ndef _get_ysobel_coord(coord, shape):\n    i, j, k = coord\n    m, n, p = shape\n    return [\n        (i-1, j, k, -2), (i-1, j-1, k, -1), (i-1, j+1, k, -1),\n        (i+1, j, k,  2), (i+1, j-1, k,  1), (i+1, j+1, k,  1)\n    ]\n\n# get sobel coordinates for x\ndef _get_xsobel_coord(coord, shape):\n    i, j, k = coord\n    m, n, p = shape\n    return [\n        (i, j-1, k, -2), (i-1, j-1, k, -1), (i-1, j+1, k, -1),\n        (i, j+1, k,  2), (i+1, j-1, k,  1), (i+1, j+1, k,  1)\n    ]\n\n# filter\ndef _filter_list_item(coord, shape):\n    i, j, k, v = coord\n    m, n, p = shape\n    if i>=0 and i<m and j>=0 and j<n:\n        return True\n\n# Change to ravel index\n# also filters the wrong guys\ndef _change_to_ravel_index(li, shape):\n    li = filter(lambda x: _filter_list_item(x, shape), li)\n    i, j, k, v = zip(*li)\n    return zip(np.ravel_multi_index((i, j, k), shape), v)\n\n# TODO: Consider wrap around of indices to remove the edge at the end of sobel\n# get Sobel sparse matrix for Y\ndef get_ySobel_matrix(m, n, p):\n    size = m*n*p\n    shape = (m, n, p)\n    i, j, k = np.unravel_index(np.arange(size), (m, n, p))\n    ijk = zip(list(i), list(j), list(k))\n    ijk_nbrs = map(lambda x: _get_ysobel_coord(x, shape), ijk)\n    ijk_nbrs_to_index = map(lambda l: _change_to_ravel_index(l, shape), ijk_nbrs)\n    # we get a list of idx, values for a particular idx\n    # we have got the complete list now, map it to actual index\n    actual_map = []\n    for i, list_of_coords in enumerate(ijk_nbrs_to_index):\n        for coord in list_of_coords:\n            actual_map.append((i, coord[0], coord[1]))\n\n    i, j, vals = zip(*actual_map)\n    return coo_matrix((vals, (i, j)), shape=(size, size))\n\n\n# get Sobel sparse matrix for X\ndef get_xSobel_matrix(m, n, p):\n    size = m*n*p\n    shape = (m, n, p)\n    i, j, k = np.unravel_index(np.arange(size), (m, n, p))\n    ijk = zip(list(i), list(j), list(k))\n    ijk_nbrs = map(lambda x: _get_xsobel_coord(x, shape), ijk)\n    ijk_nbrs_to_index = map(lambda l: _change_to_ravel_index(l, shape), ijk_nbrs)\n    # we get a list of idx, values for a particular idx\n    # we have got the complete list now, map it to actual index\n    actual_map = []\n    for i, list_of_coords in enumerate(ijk_nbrs_to_index):\n        for coord in list_of_coords:\n            actual_map.append((i, coord[0], coord[1]))\n\n    i, j, vals = zip(*actual_map)\n    return coo_matrix((vals, (i, j)), shape=(size, size))\n\n# get estimated normalized alpha matte\ndef estimate_normalized_alpha(J, W_m, num_images=30, threshold=170, invert=False, adaptive=False, adaptive_threshold=21, c2=10):\n    _Wm = (255*PlotImage(np.average(W_m, axis=2))).astype(np.uint8)\n    if adaptive:\n        thr = cv2.adaptiveThreshold(_Wm, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, adaptive_threshold, c2)\n    else:\n        ret, thr = cv2.threshold(_Wm, threshold, 255, cv2.THRESH_BINARY)\n\n    if invert:\n        thr = 255-thr\n    thr = np.stack([thr, thr, thr], axis=2)\n\n    num, m, n, p = J.shape\n    alpha = np.zeros((num_images, m, n))\n    iterpatch = 900\n\n    print(""Estimating normalized alpha using %d images.""%(num_images))\n    # for all images, calculate alpha\n    for idx in xrange(num_images):\n        imgcopy = thr\n        alph = closed_form_matte(J[idx], imgcopy)\n        alpha[idx] = alph\n\n    alpha = np.median(alpha, axis=0)\n    return alpha\n\ndef estimate_blend_factor(J, W_m, alph, threshold=0.01*255):\n    K, m, n, p = J.shape\n    Jm = (J - W_m)\n    gx_jm = np.zeros(J.shape)\n    gy_jm = np.zeros(J.shape)\n\n    for i in xrange(K):\n        gx_jm[i] = cv2.Sobel(Jm[i], cv2.CV_64F, 1, 0, 3)\n        gy_jm[i] = cv2.Sobel(Jm[i], cv2.CV_64F, 0, 1, 3)\n\n    Jm_grad = np.sqrt(gx_jm**2 + gy_jm**2)\n\n    est_Ik = alph*np.median(J, axis=0)\n    gx_estIk = cv2.Sobel(est_Ik, cv2.CV_64F, 1, 0, 3)\n    gy_estIk = cv2.Sobel(est_Ik, cv2.CV_64F, 0, 1, 3)\n    estIk_grad = np.sqrt(gx_estIk**2 + gy_estIk**2)\n\n    C = []\n    for i in xrange(3):\n        c_i = np.sum(Jm_grad[:,:,:,i]*estIk_grad[:,:,i])/np.sum(np.square(estIk_grad[:,:,i]))/K\n        print(c_i)\n        C.append(c_i)\n\n    return C, est_Ik\n\n\ndef Func_Phi(X, epsilon=1e-3):\n    return np.sqrt(X + epsilon**2)\n\ndef Func_Phi_deriv(X, epsilon=1e-3):\n    return 0.5/Func_Phi(X, epsilon)\n\ndef solve_images(J, W_m, alpha, W_init, gamma=1, beta=1, lambda_w=0.005, lambda_i=1, lambda_a=0.01, iters=4):\n    \'\'\'\n    Master solver, follows the algorithm given in the supplementary.\n    W_init: Initial value of W\n    Step 1: Image Watermark decomposition\n    \'\'\'\n    # prepare variables\n    K, m, n, p = J.shape\n    size = m*n*p\n\n    sobelx = get_xSobel_matrix(m, n, p)\n    sobely = get_ySobel_matrix(m, n, p)\n    Ik = np.zeros(J.shape)\n    Wk = np.zeros(J.shape)\n    for i in xrange(K):\n        Ik[i] = J[i] - W_m\n        Wk[i] = W_init.copy()\n\n    # This is for median images\n    W = W_init.copy()\n\n    # Iterations\n    for _ in xrange(iters):\n\n        print(""------------------------------------"")\n        print(""Iteration: %d""%(_))\n\n        # Step 1\n        print(""Step 1"")\n        alpha_gx = cv2.Sobel(alpha, cv2.CV_64F, 1, 0, 3)\n        alpha_gy = cv2.Sobel(alpha, cv2.CV_64F, 0, 1, 3)\n\n        Wm_gx = cv2.Sobel(W_m, cv2.CV_64F, 1, 0, 3)\n        Wm_gy = cv2.Sobel(W_m, cv2.CV_64F, 0, 1, 3)\n\n        cx = diags(np.abs(alpha_gx).reshape(-1))\n        cy = diags(np.abs(alpha_gy).reshape(-1))\n\n        alpha_diag = diags(alpha.reshape(-1))\n        alpha_bar_diag = diags((1-alpha).reshape(-1))\n\n        for i in xrange(K):\n            # prep vars\n            Wkx = cv2.Sobel(Wk[i], cv2.CV_64F, 1, 0, 3)\n            Wky = cv2.Sobel(Wk[i], cv2.CV_64F, 0, 1, 3)\n\n            Ikx = cv2.Sobel(Ik[i], cv2.CV_64F, 1, 0, 3)\n            Iky = cv2.Sobel(Ik[i], cv2.CV_64F, 0, 1, 3)\n\n            alphaWk = alpha*Wk[i]\n            alphaWk_gx = cv2.Sobel(alphaWk, cv2.CV_64F, 1, 0, 3)\n            alphaWk_gy = cv2.Sobel(alphaWk, cv2.CV_64F, 0, 1, 3)        \n\n            phi_data = diags( Func_Phi_deriv(np.square(alpha*Wk[i] + (1-alpha)*Ik[i] - J[i]).reshape(-1)) )\n            phi_W = diags( Func_Phi_deriv(np.square( np.abs(alpha_gx)*Wkx + np.abs(alpha_gy)*Wky  ).reshape(-1)) )\n            phi_I = diags( Func_Phi_deriv(np.square( np.abs(alpha_gx)*Ikx + np.abs(alpha_gy)*Iky  ).reshape(-1)) )\n            phi_f = diags( Func_Phi_deriv( ((Wm_gx - alphaWk_gx)**2 + (Wm_gy - alphaWk_gy)**2 ).reshape(-1)) )\n            phi_aux = diags( Func_Phi_deriv(np.square(Wk[i] - W).reshape(-1)) )\n            phi_rI = diags( Func_Phi_deriv( np.abs(alpha_gx)*(Ikx**2) + np.abs(alpha_gy)*(Iky**2) ).reshape(-1) )\n            phi_rW = diags( Func_Phi_deriv( np.abs(alpha_gx)*(Wkx**2) + np.abs(alpha_gy)*(Wky**2) ).reshape(-1) )\n\n            L_i = sobelx.T.dot(cx*phi_rI).dot(sobelx) + sobely.T.dot(cy*phi_rI).dot(sobely)\n            L_w = sobelx.T.dot(cx*phi_rW).dot(sobelx) + sobely.T.dot(cy*phi_rW).dot(sobely)\n            L_f = sobelx.T.dot(phi_f).dot(sobelx) + sobely.T.dot(phi_f).dot(sobely)\n            A_f = alpha_diag.T.dot(L_f).dot(alpha_diag) + gamma*phi_aux\n\n            bW = alpha_diag.dot(phi_data).dot(J[i].reshape(-1)) + beta*L_f.dot(W_m.reshape(-1)) + gamma*phi_aux.dot(W.reshape(-1))\n            bI = alpha_bar_diag.dot(phi_data).dot(J[i].reshape(-1))\n\n            A = vstack([hstack([(alpha_diag**2)*phi_data + lambda_w*L_w + beta*A_f, alpha_diag*alpha_bar_diag*phi_data]), \\\n                         hstack([alpha_diag*alpha_bar_diag*phi_data, (alpha_bar_diag**2)*phi_data + lambda_i*L_i])]).tocsr()\n\n            b = np.hstack([bW, bI])\n            x = linalg.spsolve(A, b)\n            \n            Wk[i] = x[:size].reshape(m, n, p)\n            Ik[i] = x[size:].reshape(m, n, p)\n            plt.subplot(3,1,1); plt.imshow(PlotImage(J[i]))\n            plt.subplot(3,1,2); plt.imshow(PlotImage(Wk[i]))\n            plt.subplot(3,1,3); plt.imshow(PlotImage(Ik[i]))\n            plt.draw()\n            plt.pause(0.001)\n            print(i)\n\n        # Step 2\n        print(""Step 2"")\n        W = np.median(Wk, axis=0)\n\n        plt.imshow(PlotImage(W))\n        plt.draw()\n        plt.pause(0.001)\n        \n        # Step 3\n        print(""Step 3"")\n        W_diag = diags(W.reshape(-1))\n        \n        for i in range(K):\n            alphaWk = alpha*Wk[i]\n            alphaWk_gx = cv2.Sobel(alphaWk, cv2.CV_64F, 1, 0, 3)\n            alphaWk_gy = cv2.Sobel(alphaWk, cv2.CV_64F, 0, 1, 3)        \n            phi_f = diags( Func_Phi_deriv( ((Wm_gx - alphaWk_gx)**2 + (Wm_gy - alphaWk_gy)**2 ).reshape(-1)) )\n            \n            phi_kA = diags(( (Func_Phi_deriv((((alpha*Wk[i] + (1-alpha)*Ik[i] - J[i])**2)))) * ((W-Ik[i])**2)  ).reshape(-1))\n            phi_kB = (( (Func_Phi_deriv((((alpha*Wk[i] + (1-alpha)*Ik[i] - J[i])**2))))*(W-Ik[i])*(J[i]-Ik[i])  ).reshape(-1))\n\n            phi_alpha = diags(Func_Phi_deriv(alpha_gx**2 + alpha_gy**2).reshape(-1))\n            L_alpha = sobelx.T.dot(phi_alpha.dot(sobelx)) + sobely.T.dot(phi_alpha.dot(sobely))\n\n            L_f = sobelx.T.dot(phi_f).dot(sobelx) + sobely.T.dot(phi_f).dot(sobely)\n            A_tilde_f = W_diag.T.dot(L_f).dot(W_diag)\n            # Ax = b, setting up A\n            if i==0:\n                A1 = phi_kA + lambda_a*L_alpha + beta*A_tilde_f\n                b1 = phi_kB + beta*W_diag.dot(L_f).dot(W_m.reshape(-1))\n            else:\n                A1 += (phi_kA + lambda_a*L_alpha + beta*A_tilde_f)\n                b1 += (phi_kB + beta*W_diag.T.dot(L_f).dot(W_m.reshape(-1)))\n\n        alpha = linalg.spsolve(A1, b1).reshape(m,n,p)\n\n        plt.imshow(PlotImage(alpha))\n        plt.draw()\n        plt.pause(0.001)\n    \n    return (Wk, Ik, W, alpha)\n\n\ndef changeContrastImage(J, I):\n    cJ1 = J[0, 0, :]\n    cJ2 = J[-1, -1, :]\n\n    cI1 = I[0, 0, :]\n    cI2 = I[-1,-1, :]\n\n    I_m = cJ1 + (I-cI1)/(cI2-cI1)*(cJ2-cJ1)\n    return I_m'"
