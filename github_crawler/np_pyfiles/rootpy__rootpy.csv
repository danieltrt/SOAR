file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python\n\nimport sys\n\n# check Python version\nif sys.version_info < (2, 6):\n    sys.exit(""rootpy only supports python 2.6 and above"")\n\n# check that ROOT can be imported\ntry:\n    import ROOT\nexcept ImportError:\n    sys.exit(""ROOT cannot be imported. Is ROOT installed with PyROOT enabled?"")\n\nROOT.PyConfig.IgnoreCommandLineOptions = True\n\n# check that we have at least the minimum required version of ROOT\nif ROOT.gROOT.GetVersionInt() < 52800:\n    sys.exit(""rootpy requires at least ROOT 5.28/00; ""\n             ""You have ROOT {0}."".format(ROOT.gROOT.GetVersion()))\n\nimport os\n# Prevent distutils from trying to create hard links\n# which are not allowed on AFS between directories.\n# This is a hack to force copying.\ntry:\n    del os.link\nexcept AttributeError:\n    pass\n\ntry:\n    import setuptools\n    from pkg_resources import parse_version, get_distribution\n    # check that we have setuptools after the merge with distribute\n    setuptools_dist = get_distribution(\'setuptools\')\n    if setuptools_dist.parsed_version < parse_version(\'0.7\'):\n        raise ImportError(\n            ""setuptools {0} is currently installed"".format(\n                setuptools_dist.version))\nexcept ImportError as ex:\n    sys.exit(\n        ""{0}\\n\\n""\n        ""rootpy requires that at least setuptools 0.7 is installed:\\n\\n""\n        ""wget https://bootstrap.pypa.io/ez_setup.py\\n""\n        ""python ez_setup.py --user\\n\\n""\n        ""You might need to add the --insecure option to the last command above ""\n        ""if using an old version of wget.\\n\\n""\n        ""If you previously had distribute installed, ""\n        ""you might need to manually uninstall the distribute-patched ""\n        ""setuptools before upgrading your setuptools. ""\n        ""See https://pypi.python.org/pypi/setuptools ""\n        ""for further details."".format(ex))\n\nfrom setuptools import setup, find_packages\nfrom glob import glob\nfrom os.path import join, abspath, dirname, isfile, isdir\n\nlocal_path = dirname(abspath(__file__))\n# setup.py can be called from outside the rootpy directory\nos.chdir(local_path)\nsys.path.insert(0, local_path)\n\n# check for custom args\n# we should instead extend distutils...\nfiltered_args = []\nrelease = False\ndevscripts = False\nfor arg in sys.argv:\n    if arg == \'--release\':\n        # --release sets the version number before installing\n        release = True\n    elif arg == \'--devscripts\':\n        devscripts = True\n    else:\n        filtered_args.append(arg)\nsys.argv = filtered_args\n\nif release:\n    # remove dev from version in rootpy/info.py\n    import shutil\n    shutil.move(\'rootpy/info.py\', \'info.tmp\')\n    dev_info = \'\'.join(open(\'info.tmp\', \'r\').readlines())\n    open(\'rootpy/info.py\', \'w\').write(\n        dev_info.replace(\'.dev0\', \'\'))\n    exclude = []\nelif sys.version_info < (3, 0):\n    exclude = [\'*.byteplay3\']\nelse:\n    exclude = [\'*.byteplay2\']\n\nexec(open(\'rootpy/info.py\').read())\nif \'install\' in sys.argv:\n    print(__doc__)\n\nscripts = glob(\'scripts/*\')\nif __version__ == \'dev\' and devscripts:\n    scripts.extend(glob(\'devscripts/*\'))\n\n\ndef strip_comments(l):\n    return l.split(\'#\', 1)[0].strip()\n\n\ndef reqs(*f):\n    return list(filter(None, [strip_comments(l) for l in open(\n        join(os.getcwd(), \'requirements\', *f)).readlines()]))\n\n\nsetup(\n    name=\'rootpy\',\n    version=__version__,\n    description=""A pythonic layer on top of the ""\n                ""ROOT framework\'s PyROOT bindings."",\n    long_description=\'\'.join(open(\'README.rst\').readlines()[7:]),\n    author=\'the rootpy developers\',\n    author_email=\'rootpy-dev@googlegroups.com\',\n    maintainer=\'Noel Dawe\',\n    maintainer_email=\'noel@dawe.me\',\n    license=\'new BSD\',\n    url=__url__,\n    download_url=__download_url__,\n    packages=find_packages(exclude=exclude),\n    extras_require={\n        \'tables\': reqs(\'tables.txt\'),\n        \'array\': reqs(\'array.txt\'),\n        \'matplotlib\': reqs(\'matplotlib.txt\'),\n        \'roosh\': reqs(\'roosh.txt\'),\n        \'stats\': reqs(\'stats.txt\'),\n        },\n    scripts=scripts,\n    entry_points={\n        \'console_scripts\': [\n            \'root2hdf5 = rootpy.root2hdf5:main\',\n            \'roosh = rootpy.roosh:main\',\n            ]\n        },\n    package_data={\'\': [\n        \'etc/*\',\n        \'testdata/*.root\',\n        \'testdata/*.txt\',\n        \'tests/test_compiled.cxx\',\n        ]},\n    classifiers=[\n        \'Intended Audience :: Science/Research\',\n        \'Intended Audience :: Developers\',\n        \'Topic :: Software Development\',\n        \'Topic :: Scientific/Engineering\',\n        \'Topic :: Utilities\',\n        \'Operating System :: POSIX\',\n        \'Operating System :: Unix\',\n        \'Operating System :: MacOS\',\n        \'License :: OSI Approved :: BSD License\',\n        \'Programming Language :: Python\',\n        \'Programming Language :: Python :: 2\',\n        \'Programming Language :: Python :: 3\',\n        \'Development Status :: 4 - Beta\',\n    ])\n\nif release:\n    # revert rootpy/info.py\n    shutil.move(\'info.tmp\', \'rootpy/info.py\')\n'"
docs/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# rootpy documentation build configuration file, created by\n# sphinx-quickstart on Fri Oct 14 23:01:54 2011.\n#\n# This file is execfile()d with the current directory set to its containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys, os\nfrom os import path\nimport datetime\nnow = datetime.datetime.now()\n\nHERE = path.dirname(path.abspath(__file__))\nrootpy_root = path.abspath(path.join(HERE, path.pardir))\n\nexec(open(path.join(rootpy_root, \'rootpy\', \'info.py\')).read())\n\n# put rootpy at the front of sys.path\nsys.path.insert(0, rootpy_root)\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\nsys.path.insert(1, path.join(HERE, \'sphinxext\'))\n\n# -- General configuration -----------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be extensions\n# coming with Sphinx (named \'sphinx.ext.*\') or your custom ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.autosummary\',\n    \'sphinx.ext.doctest\',\n    #\'sphinx.ext.intersphinx\',\n    #\'sphinx.ext.todo\',\n    #\'sphinx.ext.coverage\',\n    #\'sphinx.ext.pngmath\',\n    #\'sphinx.ext.ifconfig\',\n    \'sphinx.ext.viewcode\',\n    \'ipython_console_highlighting\',\n    \'numpydoc\',\n    #\'sphinxcontrib.ansi\',\n    \'sphinxcontrib.programoutput\',\n    ]\n\n#programoutput_use_ansi = True\n\n# Suppress numpydoc warnings as suggested here:\n# https://github.com/phn/pytpm/issues/3\nnumpydoc_show_class_members = False\n\nON_RTD = os.environ.get(\'READTHEDOCS\', None) == \'True\'\nif not ON_RTD:\n    extensions += [\'gen_rst\']\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'templates\']\n\nautodoc_default_flags = [\'members\']\n\n# generate autosummary even if no references\nautosummary_generate = True\n\n# The suffix of source filenames.\nsource_suffix = \'.rst\'\n\n# The encoding of source files.\n#source_encoding = \'utf-8-sig\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = u\'rootpy\'\ncopyright = u\'%d, rootpy developers\' % now.year\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = __version__\n# The full version, including alpha/beta/rc tags.\nrelease = __version__\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#language = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = \'\'\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = \'%B %d, %Y\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\'README*\']\nexclude_trees = [\'_build\', \'templates\', \'themes\']\n\n# The reST default role (used for this markup: `text`) to use for all documents.\n#default_role = None\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n\n\n# -- Options for HTML output --------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \'readthedocs\'\n\n# (Optional) Logo. Should be exactly 24x24 px to fit the nav. bar.\n# Path should be relative to the static files directory.\n#html_logo = ""my_logo.png""\n\n# Theme options are theme-specific and customize the look and feel of a\n# theme further.\nhtml_theme_options = {\n    \'custom_css\': \'rootpy.css\',\n    \'show_sphinx\': False,\n    \'analytics_code\': \'UA-39364267-1\',\n}\n\n# Add any paths that contain custom themes here, relative to this directory.\nhtml_theme_path = [\'themes\']\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# ""<project> v<release> documentation"".\n#html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\nhtml_logo = \'_static/rootpy-logo-80dpi.png\'\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# If not \'\', a \'Last updated on:\' timestamp is inserted at every page bottom,\n# using the given strftime format.\n#html_last_updated_fmt = \'%b %d, %Y\'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n#html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n\n# If false, no module index is generated.\n#html_domain_indices = True\n\n# If false, no index is generated.\n#html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\nhtml_show_sourcelink = False\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.\n#html_show_sphinx = True\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.\n#html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = \'\'\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n#html_file_suffix = None\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'rootpydoc\'\n\n\n# -- Options for LaTeX output --------------------------------------------------\n\nlatex_elements = {\n# The paper size (\'letterpaper\' or \'a4paper\').\n#\'papersize\': \'letterpaper\',\n\n# The font size (\'10pt\', \'11pt\' or \'12pt\').\n#\'pointsize\': \'10pt\',\n\n# Additional stuff for the LaTeX preamble.\n#\'preamble\': \'\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass [howto/manual]).\nlatex_documents = [\n  (\'index2\', \'rootpy.tex\', u\'rootpy Documentation\',\n   u\'rootpy developers\', \'manual\'),\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n# latex_logo = \'logos/rootpy-logo.png\'\n\n# For ""manual"" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n#latex_use_parts = False\n\n# If true, show page references after internal links.\n#latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n#latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n#latex_appendices = []\n\n# If false, no module index is generated.\n#latex_domain_indices = True\n\n\n# -- Options for manual page output --------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (\'index2\', \'rootpy\', u\'rootpy Documentation\',\n     [u\'rootpy developers\'], 1)\n]\n\n# If true, show URL addresses after external links.\n#man_show_urls = False\n\n\n# -- Options for Texinfo output ------------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n  (\'index2\', \'rootpy\', u\'rootpy Documentation\', u\'rootpy developers\',\n   \'rootpy\', \'One line description of project.\', \'Miscellaneous\'),\n]\n\n# Documents to append as an appendix to all manuals.\n#texinfo_appendices = []\n\n# If false, no module index is generated.\n#texinfo_domain_indices = True\n\n# How to display URL addresses: \'footnote\', \'no\', or \'inline\'.\n#texinfo_show_urls = \'footnote\'\n\n\n# -- Options for Epub output ---------------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = u\'rootpy\'\nepub_author = u\'rootpy developers\'\nepub_publisher = u\'rootpy developers\'\nepub_copyright = u\'%d, rootpy developers\' % now.year\n\n# The language of the text. It defaults to the language option\n# or en if the language is not set.\n#epub_language = \'\'\n\n# The scheme of the identifier. Typical schemes are ISBN or URL.\n#epub_scheme = \'\'\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#epub_identifier = \'\'\n\n# A unique identification for the text.\n#epub_uid = \'\'\n\n# A tuple containing the cover image and cover page html template filenames.\n#epub_cover = ()\n\n# HTML files that should be inserted before the pages created by sphinx.\n# The format is a list of tuples containing the path and title.\n#epub_pre_files = []\n\n# HTML files shat should be inserted after the pages created by sphinx.\n# The format is a list of tuples containing the path and title.\n#epub_post_files = []\n\n# A list of files that should not be packed into the epub file.\n#epub_exclude_files = []\n\n# The depth of the table of contents in toc.ncx.\n#epub_tocdepth = 3\n\n# Allow duplicate toc entries.\n#epub_tocdup = True\n\n\n# Configuration for intersphinx\nintersphinx_mapping = {\n    \'python\' : (\'http://docs.python.org/2\', None),\n    \'matplotlib\' : (\'http://matplotlib.sourceforge.net/\', None),\n    }\n\n# Taken from http://read-the-docs.readthedocs.org/en/latest/faq.html#i-get-import-errors-on-libraries-that-depend-on-c-modules\n\nfrom itertools import product\nhists = [""TH{0}{1}"".format(a, b) for a, b, in product((1, 2, 3), ""CSIFD"")]\n\nROOT_CLASSES = set(\n    ""TPad TCanvas TGraphAsymmErrors TGraph2D TEfficiency THStack TLegend ""\n    ""TDirectoryFile TFile TEllipse TTree""\n    .split()\n    + hists)\n\nclass MockROOT(object):\n    def __init__(self, *args, **kwargs):\n        pass\n\n    def __call__(self, *args, **kwargs):\n        return MockROOT()\n\n    def __iter__(self):\n        return iter([])\n\n    def __getitem__(self, i):\n        return MockROOT()\n\n    def GetDynamicPath(*args):\n        return """"\n\n    @classmethod\n    def __getattr__(cls, name):\n        if name in (\'__file__\', \'__path__\'):\n            return \'/dev/null\'\n        elif name in ROOT_CLASSES:\n            mockType = type(name, (), {})\n            mockType.__module__ = __name__\n            return mockType\n        else:\n            return MockROOT()\n\nclass Mock(object):\n    def __init__(self, *args, **kwargs):\n        pass\n\n    def __call__(self, *args, **kwargs):\n        return Mock()\n\n    @classmethod\n    def __getattr__(cls, name):\n        if name in (\'__file__\', \'__path__\'):\n            return \'/dev/null\'\n        elif name[0] == name[0].upper():\n            mockType = type(name, (), {})\n            mockType.__module__ = __name__\n            return mockType\n        else:\n            return Mock()\n\nif ON_RTD:\n    MOCK_MODULES = \'ROOT\'.split()\n    for mod_name in MOCK_MODULES:\n        sys.modules[mod_name] = MockROOT()\n\n    MOCK_MODULES = \'numpy numpy.lib numpy.core.multiarray numpy.ma matplotlib.cbook tables\'.split()\n    for mod_name in MOCK_MODULES:\n        sys.modules[mod_name] = Mock()\nelse:\n    import ROOT\n\n    def skip_ROOT_member(app, what, name, obj, skip, options):\n        return skip or isinstance(obj, ROOT.MethodProxy)\n\n    def setup(app):\n        app.connect(\'autodoc-skip-member\', skip_ROOT_member)\n'"
rootpy/ROOT.py,0,"b'""""""\n:py:mod:`rootpy.ROOT`\n=====================\n\nThis module is intended to be a drop-in replacement for ordinary\nPyROOT imports by mimicking PyROOT\'s interface. If you find a case where it is\nnot, please report an issue to the rootpy developers.\n\nBoth ROOT and rootpy classes can be accessed in a harmonized way through this\nmodule. This means you can take advantage of rootpy classes automatically by\nreplacing ``import ROOT`` with ``import rootpy.ROOT as ROOT`` or\n``from rootpy import ROOT`` in your code, while maintaining backward\ncompatibility with existing use of ROOT\'s classes.\n\nROOT classes are automatically ""asrootpy\'d"" *after* the constructor in ROOT has\nbeen called:\n\n.. sourcecode:: python\n\n   >>> import rootpy.ROOT as ROOT\n   >>> h = ROOT.TH1F(\'name\', \'title\', 10, 0, 1)\n   >>> h\n   Hist(\'name\')\n   >>> h.TYPE\n   \'F\'\n\nAlso access rootpy classes under this same module without needing to remember\nwhere to import them from in rootpy:\n\n.. sourcecode:: python\n\n   >>> import rootpy.ROOT as ROOT\n   >>> h = ROOT.Hist(10, 0, 1, name=\'name\', type=\'F\')\n   >>> h\n   Hist(\'name\')\n   >>> h.TYPE\n   \'F\'\n\nPlain old ROOT can still be accessed through the ``R`` property:\n\n.. sourcecode:: python\n\n   >>> from rootpy import ROOT\n   >>> ROOT.R.TFile\n   <class \'ROOT.TFile\'>\n\n""""""\nfrom __future__ import absolute_import\n\nfrom copy import copy\n\nimport ROOT\n\nfrom . import asrootpy, lookup_rootpy, ROOT_VERSION\nfrom . import QROOT, stl\nfrom .utils.module_facade import Facade\n\n__all__ = []\n\n\ndef proxy_global(name, no_expand_macro=False, fname=\'func\', args=()):\n    """"""\n    Used to automatically asrootpy ROOT\'s thread local variables\n    """"""\n    if no_expand_macro:  # pragma: no cover\n        # handle older ROOT versions without _ExpandMacroFunction wrapping\n        @property\n        def gSomething_no_func(self):\n            glob = self(getattr(ROOT, name))\n            # create a fake func() that just returns self\n            def func():\n                return glob\n            glob.func = func\n            return glob\n        return gSomething_no_func\n\n    @property\n    def gSomething(self):\n        obj_func = getattr(getattr(ROOT, name), fname)\n        try:\n            obj = obj_func(*args)\n        except ReferenceError:  # null pointer\n            return None\n        # asrootpy\n        return self(obj)\n\n    return gSomething\n\n\n@Facade(__name__, expose_internal=False)\nclass Module(object):\n\n    __version__ = ROOT_VERSION\n\n    def __call__(self, arg, after_init=False):\n        return asrootpy(arg, warn=False, after_init=after_init)\n\n    def __getattr__(self, what):\n        try:\n            # check ROOT\n            result = self(getattr(ROOT, what), after_init=True)\n        except AttributeError:\n            # check rootpy\n            result = lookup_rootpy(what)\n            if result is None:\n                raise AttributeError(\n                    \'ROOT does not have the attribute `{0}` \'\n                    \'and rootpy does not contain the class `{0}`\'.format(what))\n            return result\n\n        try:\n            # Memoize\n            setattr(self, what, result)\n        except AttributeError:\n            # Oops... Oh well. I tried.\n            pass\n\n        return result\n\n    @property\n    def R(self):\n        return ROOT\n\n    gPad = proxy_global(""gPad"",\n        fname=\'GetPad\' if ROOT_VERSION >= (6, 9, 2) else \'func\',\n        args=(0,) if ROOT_VERSION >= (6, 9, 2) else ())\n    gVirtualX = proxy_global(""gVirtualX"")\n\n    if ROOT_VERSION < (5, 32, 0):  # pragma: no cover\n        gDirectory = proxy_global(""gDirectory"", no_expand_macro=True)\n        gFile = proxy_global(""gFile"", no_expand_macro=True)\n        gInterpreter = proxy_global(""gInterpreter"", no_expand_macro=True)\n    else:\n        gDirectory = proxy_global(""gDirectory"",\n            fname=\'CurrentDirectory\' if ROOT_VERSION >= (6, 9, 2) else \'func\')\n        gFile = proxy_global(""gFile"",\n            fname=\'CurrentFile\' if ROOT_VERSION >= (6, 9, 2) else \'func\')\n        gInterpreter = proxy_global(""gInterpreter"",\n            no_expand_macro=ROOT_VERSION >= (6, 9, 2))\n\n    # use the smart template STL types from rootpy.stl instead\n    for t in QROOT.std.stlclasses:\n        locals()[t] = getattr(stl, t)\n    del t\n'"
rootpy/__init__.py,0,"b'from __future__ import absolute_import\nimport sys\n\nIN_NOSETESTS = False\nif sys.argv and sys.argv[0].endswith(\'nosetests\'):  # pragma: no cover\n    IN_NOSETESTS = True\n\nIN_IPYTHON = \'__IPYTHON__\' in __builtins__\nif IN_IPYTHON:  # pragma: no cover\n    try:\n        # try to import OutStream from ipykernel if possible\n        try:\n            from ipykernel.iostream import OutStream\n        except ImportError:\n            from IPython.kernel.zmq.iostream import OutStream\n        IN_IPYTHON_NOTEBOOK = isinstance(sys.stdout, OutStream)\n    except ImportError: # pyzmq not installed?\n        IN_IPYTHON_NOTEBOOK = False\nelse:\n    IN_IPYTHON_NOTEBOOK = False\n\nfrom collections import namedtuple\n\n# DO NOT expose ROOT at module level here since that conflicts with rootpy.ROOT\n# See issue https://github.com/rootpy/rootpy/issues/343\nimport ROOT as R\n\nfrom .extern.six import string_types\nfrom .logger import log\n# Needed for ""from rootpy import QROOT"" by other modules\nfrom .utils import quickroot as QROOT\nfrom . import defaults\nfrom .base import Object\nfrom .info import __version__\n\n__all__ = [\n    \'log\',\n    \'ROOT_VERSION\',\n    \'QROOT\',\n    \'asrootpy\',\n    \'lookup\',\n    \'lookup_by_name\',\n    \'lookup_rootpy\',\n    \'register\',\n    \'create\',\n]\n\n\nclass ROOTVersion(namedtuple(\'_ROOTVersionBase\',\n                             [\'major\', \'minor\', \'micro\'])):\n\n    def __new__(cls, version):\n        if version < 1E4:\n            raise ValueError(\n                ""{0:d} is not a valid ROOT version integer"".format(version))\n        return super(ROOTVersion, cls).__new__(\n            cls,\n            int(version / 1E4), int((version / 1E2) % 100), int(version % 100))\n\n    def __repr__(self):\n        return str(self)\n\n    def __str__(self):\n        return \'{0:d}.{1:02d}/{2:02d}\'.format(*self)\n\n\n# Note: requires defaults import\nROOT_VERSION = ROOTVersion(QROOT.gROOT.GetVersionInt())\nlog.debug(""Using ROOT {0}"".format(ROOT_VERSION))\n\n\nclass ROOTError(RuntimeError):\n    """"""\n    Exception class representing a ROOT error/warning message.\n    """"""\n    def __init__(self, level, location, msg):\n        self.level, self.location, self.msg = level, location, msg\n\n    def __str__(self):\n        return ""level={0}, loc=\'{1}\', msg=\'{2}\'"".format(\n            self.level, self.location, self.msg)\n\n\ndef rootpy_source_dir():\n    import rootpy\n    from os.path import abspath, dirname\n    from inspect import getfile\n    from sys import modules\n    path = dirname(getfile(modules[__name__]))\n    absp = abspath(path)\n    return path, absp\n\n\n_ROOTPY_SOURCE_PATH, _ROOTPY_SOURCE_ABSPATH = rootpy_source_dir()\ndel rootpy_source_dir\n\n""""""\nAll rootpy wrappers are registered below. This dict maps the ROOT class name to\nthe path to the rootpy class or a tuple of both the path and keyword arguments\nused in the dynamic_cls classmethod (see the ``Hist``, ``Hist2D`` and\n``Hist3D`` classes in ``plotting.hist``).\n\nThis way rootpy is aware of all classes that inherit from ROOT classes without\nneeding to import everything when rootpy is first imported. This registry is\nrequired to cast ROOT objects into the rootpy form when extracted from a ROOT\nTFile, for example.\n""""""\nINIT_REGISTRY = {\n\n    \'TList\': \'collection.List\',\n    \'TObjArray\': \'collection.ObjArray\',\n\n    \'TTree\': \'tree.tree.Tree\',\n    \'TNtuple\': \'tree.tree.Ntuple\',\n\n    \'TKey\': \'io.file.Key\',\n    \'TDirectoryFile\': \'io.file.Directory\',\n    \'TFile\': \'io.file.File\',\n    \'TMemFile\': \'io.file.MemFile\',\n\n    \'TStyle\': \'plotting.style.Style\',\n    \'TCanvas\': \'plotting.canvas.Canvas\',\n    \'TPad\': \'plotting.canvas.Pad\',\n    \'TPave\': \'plotting.box.Pave\',\n    \'TPaveStats\': \'plotting.box.PaveStats\',\n    \'TLegend\': \'plotting.legend.Legend\',\n    \'TEllipse\': \'plotting.shapes.Ellipse\',\n    \'TLine\': \'plotting.shapes.Line\',\n    \'TArrow\': \'plotting.shapes.Arrow\',\n\n    \'TF1\': \'plotting.func.F1\',\n    \'TF2\': \'plotting.func.F2\',\n    \'TF3\': \'plotting.func.F3\',\n\n    \'TGraph\': (\'plotting.graph.Graph\', dict(type=\'default\')),\n    \'TGraphErrors\': (\'plotting.graph.Graph\', dict(type=\'errors\')),\n    \'TGraphAsymmErrors\': (\'plotting.graph.Graph\', dict(type=\'asymm\')),\n    \'TGraphBentErrors\': (\'plotting.graph.Graph\', dict(type=\'benterrors\')),\n\n    \'TGraph2D\': (\'plotting.graph.Graph2D\', dict(type=\'default\')),\n    \'TGraph2DErrors\': (\'plotting.graph.Graph2D\', dict(type=\'errors\')),\n\n    \'TProfile\': \'plotting.profile.Profile\',\n    \'TProfile2D\': \'plotting.profile.Profile2D\',\n    \'TProfile3D\': \'plotting.profile.Profile3D\',\n\n    \'TH1C\': (\'plotting.hist.Hist\', dict(type=\'C\')),\n    \'TH1S\': (\'plotting.hist.Hist\', dict(type=\'S\')),\n    \'TH1I\': (\'plotting.hist.Hist\', dict(type=\'I\')),\n    \'TH1F\': (\'plotting.hist.Hist\', dict(type=\'F\')),\n    \'TH1D\': (\'plotting.hist.Hist\', dict(type=\'D\')),\n\n    \'TH2C\': (\'plotting.hist.Hist2D\', dict(type=\'C\')),\n    \'TH2S\': (\'plotting.hist.Hist2D\', dict(type=\'S\')),\n    \'TH2I\': (\'plotting.hist.Hist2D\', dict(type=\'I\')),\n    \'TH2F\': (\'plotting.hist.Hist2D\', dict(type=\'F\')),\n    \'TH2D\': (\'plotting.hist.Hist2D\', dict(type=\'D\')),\n\n    \'TH3C\': (\'plotting.hist.Hist3D\', dict(type=\'C\')),\n    \'TH3S\': (\'plotting.hist.Hist3D\', dict(type=\'S\')),\n    \'TH3I\': (\'plotting.hist.Hist3D\', dict(type=\'I\')),\n    \'TH3F\': (\'plotting.hist.Hist3D\', dict(type=\'F\')),\n    \'TH3D\': (\'plotting.hist.Hist3D\', dict(type=\'D\')),\n\n    \'TEfficiency\': \'plotting.hist.Efficiency\',\n\n    \'THStack\': \'plotting.hist.HistStack\',\n\n    \'TAxis\': \'plotting.axis.Axis\',\n\n    \'TVector2\': \'vector.Vector2\',\n    \'TVector3\': \'vector.Vector3\',\n    \'TLorentzVector\': \'vector.LorentzVector\',\n    \'TRotation\': \'vector.Rotation\',\n    \'TLorentzRotation\': \'vector.LorentzRotation\',\n\n    \'TMatrixT<float>\': (\'matrix.Matrix\', dict(type=\'float\')),\n    \'TMatrixT<double>\': (\'matrix.Matrix\', dict(type=\'double\')),\n    \'TMatrixTSym<float>\': (\'matrix.SymmetricMatrix\', dict(type=\'float\')),\n    \'TMatrixTSym<double>\': (\'matrix.SymmetricMatrix\', dict(type=\'double\')),\n\n    \'RooWorkspace\': \'stats.workspace.Workspace\',\n    \'RooStats::ModelConfig\': \'stats.modelconfig.ModelConfig\',\n    \'RooArgSet\': \'stats.collection.ArgSet\',\n    \'RooArgList\': \'stats.collection.ArgList\',\n    \'RooRealVar\': \'stats.value.RealVar\',\n    \'RooSimultaneous\': \'stats.pdf.Simultaneous\',\n    \'RooAddPdf\': \'stats.pdf.AddPdf\',\n    \'RooProdPdf\': \'stats.pdf.ProdPdf\',\n    \'RooCatType\': \'stats.category.CatType\',\n    \'RooCategory\': \'stats.category.Category\',\n    \'RooDataSet\': \'stats.dataset.DataSet\',\n    \'RooMinimizer\': \'stats.fit.Minimizer\',\n    \'RooFitResult\': \'stats.fit.FitResult\',\n    \'RooPlot\': \'stats.plottable.Plot\',\n    \'RooCurve\': \'stats.plottable.Curve\',\n    \'RooHist\': \'stats.plottable.DataHist\',\n\n    \'RooStats::HistFactory::Data\': \'stats.histfactory.Data\',\n    \'RooStats::HistFactory::Sample\': \'stats.histfactory.Sample\',\n    \'RooStats::HistFactory::HistoSys\': \'stats.histfactory.HistoSys\',\n    \'RooStats::HistFactory::HistoFactor\': \'stats.histfactory.HistoFactor\',\n    \'RooStats::HistFactory::OverallSys\': \'stats.histfactory.OverallSys\',\n    \'RooStats::HistFactory::NormFactor\': \'stats.histfactory.NormFactor\',\n    \'RooStats::HistFactory::ShapeSys\': \'stats.histfactory.ShapeSys\',\n    \'RooStats::HistFactory::ShapeFactor\': \'stats.histfactory.ShapeFactor\',\n    \'RooStats::HistFactory::Channel\': \'stats.histfactory.Channel\',\n    \'RooStats::HistFactory::Measurement\': \'stats.histfactory.Measurement\',\n}\n\n# map rootpy name to location in rootpy (i.e. Axis -> plotting.axis)\nINIT_REGISTRY_ROOTPY = {}\nfor rtype, rptype in INIT_REGISTRY.items():\n    if isinstance(rptype, tuple):\n        rptype = rptype[0]\n    cls_path, _, cls_name = rptype.rpartition(\'.\')\n    INIT_REGISTRY_ROOTPY[cls_name] = cls_path\n\n# these dicts are populated as classes are registered at runtime\n# ROOT class name -> rootpy class\nREGISTRY = {}\n# rootpy class name -> rootpy class\nREGISTRY_ROOTPY = {}\n\n\ndef asrootpy(thing, **kwargs):\n    # is this thing already converted?\n    if isinstance(thing, Object):\n        return thing\n\n    warn = kwargs.pop(\'warn\', False)\n    after_init = kwargs.pop(\'after_init\', False)\n\n    # is this thing a class?\n    if isinstance(thing, QROOT.PyRootType):\n        if issubclass(thing, Object):\n            return thing\n        result = lookup(thing)\n        if result is None:\n            if warn:\n                log.warn(\n                    ""There is no rootpy implementation ""\n                    ""of the class `{0}`"".format(thing.__name__))\n            return thing\n        if after_init:\n            # preserve ROOT\'s __init__\n            class asrootpy_cls(result):\n                def __new__(self, *args, **kwargs):\n                    return asrootpy(thing(*args, **kwargs), warn=warn)\n            asrootpy_cls.__name__ = \'{0}_asrootpy\'.format(thing.__name__)\n            return asrootpy_cls\n        return result\n\n    thing_cls = thing.__class__\n    rootpy_cls = lookup(thing_cls)\n    if rootpy_cls is None:\n        if warn:\n            log.warn(\n                ""A subclass of `{0}` is not ""\n                ""implemented in rootpy"".format(\n                    thing_cls.__name__))\n        return thing\n\n    # cast\n    thing.__class__ = rootpy_cls\n    if hasattr(rootpy_cls, \'_post_init\'):\n        if hasattr(rootpy_cls, \'_clone_post_init\'):\n            kwargs.setdefault(\'obj\', thing)\n        thing._post_init(**kwargs)\n\n    return thing\n\n\ndef _get_class(path, name):\n    rootpy_module = __import__(\n        \'rootpy.\' + path, globals(), locals(), [name], 0)\n    return getattr(rootpy_module, name)\n\n\ndef lookup(cls):\n    cls_name = cls.__name__\n    return lookup_by_name(cls_name)\n\n\ndef lookup_by_name(cls_name):\n    if cls_name in REGISTRY:\n        return REGISTRY[cls_name]\n    if cls_name not in INIT_REGISTRY:\n        return None\n    entry = INIT_REGISTRY[cls_name]\n    if isinstance(entry, tuple):\n        path, dynamic_kwargs = entry\n    elif isinstance(entry, string_types):\n        path = entry\n        dynamic_kwargs = None\n    cls_path, _, rootpy_cls_name = path.rpartition(\'.\')\n\n    rootpy_cls = _get_class(cls_path, rootpy_cls_name)\n\n    if dynamic_kwargs is not None:\n        rootpy_cls = rootpy_cls.dynamic_cls(**dynamic_kwargs)\n    REGISTRY[cls_name] = rootpy_cls\n    return rootpy_cls\n\n\ndef lookup_rootpy(rootpy_cls_name):\n    rootpy_cls = REGISTRY_ROOTPY.get(rootpy_cls_name, None)\n    if rootpy_cls is not None:\n        return rootpy_cls\n    cls_path = INIT_REGISTRY_ROOTPY.get(rootpy_cls_name, None)\n    if cls_path is None:\n        return None\n\n    rootpy_cls = _get_class(cls_path, rootpy_cls_name)\n\n    REGISTRY_ROOTPY[rootpy_cls_name] = rootpy_cls\n    return rootpy_cls\n\n\nclass register(object):\n\n    def __init__(self, names=None, builtin=False):\n        if names is not None:\n            if type(names) not in (list, tuple):\n                names = [names]\n        self.names = names\n        self.builtin = builtin\n\n    def __call__(self, cls):\n        if issubclass(cls, Object):\n            # all rootpy classes which inherit from ROOT classes\n            # must place the ROOT base class as the last class\n            # in the inheritance list and inherit from Object\n            rootbase = cls.__bases__[-1]\n            cls_names = [rootbase.__name__]\n        else:\n            cls_names = [cls.__name__]\n\n        if self.names is not None:\n            cls_names += self.names\n\n        for name in cls_names:\n            if name in REGISTRY:\n                log.debug(\n                    ""duplicate registration of ""\n                    ""class `{0}`"".format(name))\n            REGISTRY[name] = cls\n        return cls\n\n\ndef create(cls_name, *args, **kwargs):\n    cls = getattr(R, cls_name, None)\n    if cls is None:\n        return None\n    try:\n        obj = cls(*args, **kwargs)\n        return asrootpy(obj)\n    except TypeError:\n        return None\n\n\n# missing __hash__ for ROOT <= 6.04 (?) in python 3\n# https://sft.its.cern.ch/jira/browse/ROOT-7365\nif sys.version_info[0] >= 3:\n    if not QROOT.TObject.__hash__:\n        QROOT.TObject.__hash__ = object.__hash__\n'"
rootpy/base.py,0,"b'""""""\nThis module contains base classes defining core functionality\n""""""\nfrom __future__ import absolute_import\n\nfrom .extern.shortuuid import uuid\n\n__all__ = [\n    \'Object\',\n    \'NamedObject\',\n    \'NameOnlyObject\',\n    \'NamelessConstructorObject\',\n]\n\n\nclass Object(object):\n    """"""\n    The rootpy-side base class of all ROOT subclasses in rootpy\n    Classes that inherit from this class must also inherit from ROOT.TObject.\n    """"""\n    def Clone(self, name=None, title=None, shallow=False, **kwargs):\n        if name is None:\n            name = \'{0}_{1}\'.format(self.__class__.__name__, uuid())\n        if shallow:\n            # use the copy constructor\n            clone = self._ROOT(self)\n            clone.SetName(name)\n        else:\n            # a complete clone\n            clone = super(Object, self).Clone(name)\n        # cast\n        clone.__class__ = self.__class__\n        if title is not None:\n            clone.SetTitle(title)\n        if hasattr(clone, \'_clone_post_init\'):\n            clone._clone_post_init(obj=self, **kwargs)\n        elif hasattr(clone, \'_post_init\'):\n            clone._post_init(**kwargs)\n        return clone\n\n    def copy_from(self, other):\n        # not all classes implement Copy() correctly in ROOT, so use copy\n        # constructor directly. Then again, not all classes in ROOT implement a\n        # copy constructor or implement one correctly, so this might not work\n        # everywhere...\n        self._ROOT.__init__(self, other)\n\n    @property\n    def name(self):\n        return self.GetName()\n\n    @name.setter\n    def name(self, _name):\n        self.SetName(_name)\n\n    @property\n    def title(self):\n        return self.GetTitle()\n\n    @title.setter\n    def title(self, _title):\n        self.SetTitle(_title)\n\n    def __copy__(self):\n        return self.Clone(shallow=True)\n\n    def __deepcopy__(self, memo):\n        return self.Clone()\n\n    def __str__(self):\n        return self.__repr__()\n\n    def __repr__(self):\n        return ""{0}(\'{1}\')"".format(\n            self.__class__.__name__, self.GetName())\n\n\nclass NamedObject(Object):\n    """"""\n    Name and title for TNamed-derived classes are optional. If no name is\n    specified, a UUID is used to ensure uniqueness.\n    """"""\n    def __init__(self, *args, **kwargs):\n        name = kwargs.pop(\'name\', None)\n        title = kwargs.pop(\'title\', None)\n        if name is None:\n            name = \'{0}_{1}\'.format(self.__class__.__name__, uuid())\n        if title is None:\n            title = \'\'\n        super(NamedObject, self).__init__(name, title, *args, **kwargs)\n\n\nclass NameOnlyObject(Object):\n    """"""\n    Handle special cases like TF1 where the constructor only takes a name.\n    """"""\n    def __init__(self, *args, **kwargs):\n        name = kwargs.pop(\'name\', None)\n        if name is None:\n            name = \'{0}_{1}\'.format(self.__class__.__name__, uuid())\n        super(NameOnlyObject, self).__init__(name, *args, **kwargs)\n\n\nclass NamelessConstructorObject(Object):\n    """"""\n    Handle special cases like TGraph where the ROOT constructor does not\n    take name/title.\n    """"""\n    def __init__(self, *args, **kwargs):\n        name = kwargs.pop(\'name\', None)\n        title = kwargs.pop(\'title\', None)\n        if name is None:\n            name = \'{0}_{1}\'.format(self.__class__.__name__, uuid())\n        if title is None:\n            title = \'\'\n        super(NamelessConstructorObject, self).__init__(*args, **kwargs)\n        self.SetName(name)\n        self.SetTitle(title)\n'"
rootpy/collection.py,0,"b'from __future__ import absolute_import\n\nfrom collections import namedtuple\n\nimport ROOT\n\nfrom . import QROOT, asrootpy\nfrom .extern.six.moves import range\nfrom .base import Object\n\n__all__ = [\n    \'List\',\n    \'ObjArray\',\n]\n\n\nTListItemWithOption = namedtuple(""TListItemWithOption"", ""item option"")\n\n\nclass List(Object, QROOT.TList):\n    """"""\n    rootpy wrapper on ROOT\'s TList. Primarily provides the ability to do slice\n    assignments whilst preserving options, which makes it useful for\n    manipulating TLists such as ROOT\'s ``TCanvas::GetListOfPrimitives``.\n\n    Note: this class is rather inefficient as is only intended for manipulating\n    small numbers of objects. In modern computing, a linked list wouldn\'t be\n    used in this case. Since a TList is what we have, this provides some sane\n    ways to use them.\n    """"""\n    _ROOT = QROOT.TList\n\n    @property\n    def as_list_with_options(self):\n        """"""\n        Similar to list(self) except elements which have an option associated\n        with them are returned as a ``TListItemWithOption``\n        """"""\n        it = ROOT.TIter(self)\n        elem = it.Next()\n        result = []\n        while elem:\n            if it.GetOption():\n                result.append(TListItemWithOption(elem, it.GetOption()))\n            else:\n                result.append(elem)\n            elem = it.Next()\n        return result\n\n    def Add(self, value, *optional):\n        """"""\n        Overload ROOT\'s basic TList::Add to support supplying\n        TListItemWithOption\n        """"""\n        if isinstance(value, TListItemWithOption):\n            if optional:\n                raise RuntimeError(\n                    ""option specified along with ""\n                    ""TListItemWithOption. Specify one or the ""\n                    ""other but not both."")\n            return super(List, self).Add(value.item, value.option)\n        return super(List, self).Add(value, *optional)\n\n    def __setitem__(self, idx, desired):\n        """"""\n        Support slice assignment to a TList\n        """"""\n        if not isinstance(idx, slice):\n            super(List, self)[idx] = desired\n\n        if not isinstance(desired, (list, tuple)):\n            raise NotImplementedError(\n                ""Only support list or tuple in slice assignment"")\n\n        # Implementation: completely clear the list and rebuild it.\n        # If we own objects, manually delete the ones which don\'t get re-added\n        # to the list.\n\n        original_values = self.as_list_with_options\n\n        self.Clear(""nodelete"")\n\n        first_idx, last_idx, stride = idx.indices(len(original_values))\n\n        newlist = (original_values[:first_idx:stride]\n                   + list(desired)\n                   + original_values[last_idx::stride])\n\n        for item in newlist:\n            # TODO: Potentially fix up the ""same"" keyword intelligently *if*\n            #       the first item is a TFrame, we know we\'re probably a list\n            #       of items which is being drawn. For example, we might want\n            #       objects which are specified repeatedly to use the ""same""\n            #       keyword the second time, or to ensure that the first\n            #       does not have the ""same"" keyword.\n            pass\n\n        # Set of objects which were used (and don\'t need deleting)\n        added = set()\n\n        # Rebuild the list\n        for value in newlist:\n            self.Add(value)\n            added.add(value)\n\n        to_disown = set(original_values) - set(added)\n        if self.IsOwner() and to_disown:\n            # These items need deleting if we own them.\n            # Add them to a temporary TList which we then delete in order to\n            # get the correct deletion semantics.\n\n            templist = List()\n            templist.SetOwner()\n            for item in to_disown:\n                templist.Add(item)\n\n            # Causes deletion of heap based objects with the usual root\n            # semantics.\n            templist.Clear()\n\n    def __getitem__(self, idx):\n        """"""\n        Similar to list(self)[idx] except it uses\n        ``List.as_list_with_options``.\n        """"""\n        return self.as_list_with_options[idx]\n\n    def __iter__(self):\n        for item in super(List, self).__iter__():\n            yield asrootpy(item)\n\n    def __repr__(self):\n        return ""rootpy.List{0}"".format(list(self))\n\n\nclass ObjArray(Object, QROOT.TObjArray):\n    """"""\n    Make ObjArray return asrootpy\'d versions of the objects contained within.\n    """"""\n    _ROOT = QROOT.TObjArray\n\n    # TODO: override other TObjArray methods which return TObject*\n    def At(self, idx):\n        return asrootpy(super(ObjArray, self).At(idx))\n\n    def __getitem__(self, idx):\n        if isinstance(idx, slice):\n            return [self[i] for i in range(*idx.indices(len(self)))]\n        return self.At(idx)\n\n    def __iter__(self):\n        for item in super(ObjArray, self).__iter__():\n            yield asrootpy(item)\n'"
rootpy/compiled.py,0,"b'""""""\nEasily compile and load C++ code from multiline Python strings or from external\nC++ files. The compiled libraries are cached in ``~/.cache/rootpy`` and loaded\nfrom there when requested again.\n\nExamples\n--------\n\nCreate the file ``test_compiled.cxx`` containing:\n\n.. sourcecode:: c++\n\n   int AnswerToLtUaE() {\n       return 42;\n   }\n\n   class RootpyTestCompiled {\n   public:\n       int blah() { return 84; }\n   };\n\n\nNow automatically compile and load that file or C++ code in a string with:\n\n.. sourcecode:: python\n\n   >>> import rootpy.compiled as C\n   >>> C.register_file(""test_compiled.cxx"",\n   ...                 [""AnswerToLtUaE"", ""RootpyTestCompiled""])\n   >>> C.register_code(\\""\\""\\""\n   ... #include <string>\n   ... std::string _rootpy_test() { return ""Hello, world""; }\n   ... \\""\\""\\"", [""_rootpy_test""])\n   >>> C.AnswerToLtUaE()\n   42\n   >>> C.RootpyTestCompiled().blah()\n   84\n   >>> C._rootpy_test()\n   \'Hello, world\'\n\n""""""\nfrom __future__ import absolute_import\n\nimport hashlib\nimport inspect\nimport os\nimport pkg_resources\nimport sys\nimport textwrap\nfrom os.path import basename, dirname, exists, join as pjoin\n\nimport ROOT\n\nfrom .utils.module_facade import Facade, computed_once_classproperty\n\nfrom . import userdata\nfrom .utils.path import mkdir_p\nfrom .utils.lock import lock\nfrom . import log; log = log[__name__]\nfrom . import QROOT\nfrom .defaults import extra_initialization\n\n__all__ = []\n\n\ndef mtime(path):\n    return os.stat(path).st_mtime\n\nMODULES_PATH = pjoin(userdata.BINARY_PATH, \'modules\')\nif not exists(MODULES_PATH):\n    # avoid race condition by ignoring OSError if path exists by the time we\n    # try to create it. See https://github.com/rootpy/rootpy/issues/328\n    mkdir_p(MODULES_PATH)\n\n\n@extra_initialization\ndef initialize():\n    # Used instead of AddDynamicPath for ordering\n    path = "":"".join([MODULES_PATH, ROOT.gSystem.GetDynamicPath()])\n    ROOT.gSystem.SetDynamicPath(path)\n\n\nclass Namespace(object):\n    """"""\n    Represents a sub-namespace\n    """"""\n\n\nclass FileCode(object):\n\n    def __init__(self, filename, callermodule):\n        self.filename = filename\n        self.module = callermodule\n        self.name = self.module + ""."" + basename(self.filename)\n        self.loaded = False\n\n    @property\n    def mtime(self):\n        return mtime(self.filename)\n\n    @property\n    def compiled_path(self):\n        ext = ""."" + ROOT.gSystem.GetSoExt()\n        return pjoin(MODULES_PATH, self.name + ext)\n\n    @property\n    def compiled(self):\n        return (exists(self.compiled_path) and\n                mtime(self.compiled_path) > self.mtime)\n\n    def load(self):\n        if not self.compiled:\n            log.info(""Compiling {0}"".format(self.compiled_path))\n            with lock(pjoin(MODULES_PATH, ""lock""), poll_interval=5, max_age=60):\n                ROOT.gSystem.CompileMacro(self.filename, \'k-\',\n                                          self.name, MODULES_PATH)\n        else:\n            log.debug(""Loading existing {0}"".format(self.compiled_path))\n            ROOT.gInterpreter.Load(self.compiled_path)\n        self.loaded = True\n\n    def get(self, name):\n        if not self.loaded:\n            self.load()\n        return getattr(ROOT, name)\n\n\n@Facade(__name__, expose_internal=False)\nclass Compiled(object):\n\n    registered_code = {}\n    debug = False\n    optimize = True\n\n    def caller_location(self, depth=0):\n        caller = sys._getframe(depth+2)\n        caller_file = inspect.getfile(caller)\n        caller_module = inspect.getmodule(caller)\n        if caller_module:\n            caller_module = caller_module.__name__\n            # Note: caller_file may be a relative path from $PWD at python\n            # startup, therefore, to get a solid abspath:\n            caller_directory = pkg_resources.get_provider(\n                caller_module).module_path\n        else:\n            caller_module = ""..unknown..""\n            caller_directory = dirname(caller_file)\n\n        return caller_directory, caller_module, caller.f_lineno\n\n    def get_symbol(self, symbol):\n        if symbol in self.registered_code:\n            return self.registered_code[symbol].get(symbol)\n\n    def __getattr__(self, what):\n        return self.get_symbol(what)\n\n    def register_code(self, code, symbols):\n        """"""Register C++ code in a multiline string\n\n        Parameters\n        ----------\n        code : str\n            A string containing the C++ code\n        symbols : list\n            A list of symbol names to extract from the compiled C++ code\n\n        Notes\n        -----\n        This assumes that call site occurs exactly once.\n        If you don\'t do that, you\'re better off writing to a temporary\n        file and calling `register_file`\n        """"""\n        if sys.version_info[0] >= 3:\n            filename = hashlib.sha1(code.encode(\'utf-8\')).hexdigest()[:8] + "".cxx""\n        else:\n            filename = hashlib.sha1(code).hexdigest()[:8] + "".cxx""\n        filepath = pjoin(MODULES_PATH, filename)\n\n        _, caller_modulename, lineno = self.caller_location()\n\n        #code += ""#line {0} {1}"".format(caller_modulename, lineno)\n        if not exists(filepath):\n            # Only write it if it doesn\'t exist\n            # (1/4billion chance of collision)\n            with open(filepath, ""w"") as fd:\n                fd.write(textwrap.dedent(code))\n\n        code = FileCode(filepath, caller_modulename)\n        self.register(code, symbols)\n\n    def register(self, code, symbols):\n        for s in symbols:\n            self.registered_code[s] = code\n\n    def register_file(self, filename, symbols):\n        """"""Register C++ code in an external C++ file\n\n        Parameters\n        ----------\n        filename : str\n            The path to a file containing C++ code\n        symbols : list\n            A list of symbol names to extract from the compiled C++ code\n        """"""\n        caller_directory, caller_modulename, _ = self.caller_location()\n\n        absfile = pjoin(caller_directory, filename)\n\n        if not exists(absfile):\n            raise RuntimeError(""Can\'t find file {0}"".format(absfile))\n\n        code = FileCode(absfile, caller_modulename)\n        self.register(code, symbols)\n\n    @computed_once_classproperty\n    def python_include_path(self):\n        """"""\n        Determine the path to Python.h\n        """"""\n        from distutils import sysconfig\n\n        pydir = ""python{0.major}.{0.minor}"".format(sys.version_info)\n        if sys.version_info[0] > 2:\n            pydir += ""m""\n        real_prefix = None\n        if hasattr(sys, ""real_prefix""):\n            real_prefix = pjoin(sys.real_prefix, ""include"")\n\n        paths = [\n            sysconfig.get_config_var(\'INCLUDEDIR\'),\n            real_prefix,\n            pjoin(sys.prefix, ""include""),\n            pjoin(sys.exec_prefix, ""include""),\n        ]\n\n        # Try each path in turn, call it if callable,\n        # skip it if it doesn\'t exist\n        for path in paths:\n            if not path:\n                continue\n            incdir = pjoin(path, pydir)\n            py_h = pjoin(incdir, ""Python.h"")\n            if exists(py_h):\n                return incdir\n        raise RuntimeError(""BUG: Unable to determine Python.h include path."")\n\n    def add_python_includepath(self):\n        """"""\n        Add Python.h to the include path\n        """"""\n        if hasattr(self, ""_add_python_includepath_done""):\n            return\n        self._add_python_includepath_done = True\n        QROOT.gSystem.AddIncludePath(\n            \'-I""{0}""\'.format(self.python_include_path))\n'"
rootpy/context.py,0,"b'from __future__ import absolute_import\n\nimport os\nfrom contextlib import contextmanager\n# Note about locks: we don\'t need this in cases where ROOT has a\n# thread-specific variable, so gDirectory and gPad are safe.\n# Not so for gStyle, IsBatch and TH1.AddDirectory, so we use a lock in these\n# cases. To prevent out-of-order lock grabbing, just use one reentrant lock for\n# all of them.\nimport threading\nLOCK = threading.RLock()\n\nfrom . import ROOT\nfrom . import log; log = log[__name__]\n\n__all__ = [\n    \'preserve_current_style\',\n    \'preserve_current_canvas\',\n    \'preserve_current_directory\',\n    \'preserve_batch_state\',\n    \'invisible_canvas\',\n    \'thread_specific_tmprootdir\',\n    \'set_directory\',\n    \'preserve_set_th1_add_directory\',\n    \'working_directory\',\n    \'do_nothing\',\n]\n\n\n@contextmanager\ndef preserve_current_style():\n    """"""\n    Context manager which ensures that the current style remains the current\n    style when the context is left.\n    """"""\n    # this should be \'Modern\' by default\n    with LOCK:\n        old = ROOT.gStyle\n        try:\n            yield\n        finally:\n            old.cd()\n\n\n@contextmanager\ndef preserve_current_canvas():\n    """"""\n    Context manager which ensures that the current canvas remains the current\n    canvas when the context is left.\n    """"""\n    old = ROOT.gPad\n    try:\n        yield\n    finally:\n        if old:\n            old.cd()\n        elif ROOT.gPad:\n            # Put things back how they were before.\n            with invisible_canvas():\n                # This is a round-about way of resetting gPad to None.\n                # No other technique I tried could do it.\n                pass\n\n\n@contextmanager\ndef preserve_current_directory():\n    """"""\n    Context manager which ensures that the current directory remains the\n    current directory when the context is left.\n    """"""\n    old = ROOT.gDirectory\n    try:\n        yield\n    finally:\n        assert old, ""BUG: assumptions were invalid. Please report this""\n        # old is always valid and refers to ROOT.TROOT if no file is created.\n        old.cd()\n\n\n@contextmanager\ndef preserve_batch_state():\n    """"""\n    Context manager which ensures the batch state is the same on exit as it was\n    on entry.\n    """"""\n    with LOCK:\n        old = ROOT.gROOT.IsBatch()\n        try:\n            yield\n        finally:\n            ROOT.gROOT.SetBatch(old)\n\n\n@contextmanager\ndef invisible_canvas():\n    """"""\n    Context manager yielding a temporary canvas drawn in batch mode, invisible\n    to the user. Original state is restored on exit.\n\n    Example use; obtain X axis object without interfering with anything::\n\n        with invisible_canvas() as c:\n            efficiency.Draw()\n            g = efficiency.GetPaintedGraph()\n            return g.GetXaxis()\n    """"""\n    with preserve_current_canvas():\n        with preserve_batch_state():\n            ROOT.gROOT.SetBatch()\n            c = ROOT.TCanvas()\n        try:\n            c.cd()\n            yield c\n        finally:\n            c.Close()\n            c.IsA().Destructor(c)\n\n\n@contextmanager\ndef thread_specific_tmprootdir():\n    """"""\n    Context manager which makes a thread specific gDirectory to avoid\n    interfering with the current file.\n\n    Use cases:\n\n        A TTree Draw function which doesn\'t want to interfere with whatever\n        gDirectory happens to be.\n\n        Multi-threading where there are two threads creating objects with the\n        same name which must reside in a directory. (again, this happens with\n        TTree draw)\n    """"""\n    with preserve_current_directory():\n        dname = ""rootpy-tmp/thread/{0}"".format(\n                threading.current_thread().ident)\n        d = ROOT.gROOT.mkdir(dname)\n        if not d:\n            d = ROOT.gROOT.GetDirectory(dname)\n            assert d, ""Unexpected failure, can\'t cd to tmpdir.""\n        d.cd()\n        yield d\n\n\n@contextmanager\ndef set_directory(robject):\n    """"""\n    Context manager to temporarily set the directory of a ROOT object\n    (if possible)\n    """"""\n    if (not hasattr(robject, \'GetDirectory\') or\n        not hasattr(robject, \'SetDirectory\')):\n        log.warning(""Cannot set the directory of a `{0}`"".format(\n            type(robject)))\n        # Do nothing\n        yield\n    else:\n        old_dir = robject.GetDirectory()\n        try:\n            robject.SetDirectory(ROOT.gDirectory)\n            yield\n        finally:\n            robject.SetDirectory(old_dir)\n\n\n@contextmanager\ndef preserve_set_th1_add_directory(state=True):\n    """"""\n    Context manager to temporarily set TH1.AddDirectory() state\n    """"""\n    with LOCK:\n        status = ROOT.TH1.AddDirectoryStatus()\n        try:\n            ROOT.TH1.AddDirectory(state)\n            yield\n        finally:\n            ROOT.TH1.AddDirectory(status)\n\n\n@contextmanager\ndef working_directory(path):\n    """"""\n    A context manager that changes the working directory to the given\n    path, and then changes it back to its previous value on exit.\n    """"""\n    prev_cwd = os.getcwd()\n    os.chdir(path)\n    try:\n        yield\n    finally:\n        os.chdir(prev_cwd)\n\n\n@contextmanager\ndef do_nothing(*args, **kwargs):\n    """"""\n    A context manager that does... nothing!\n    """"""\n    yield\n'"
rootpy/decorators.py,0,"b'from __future__ import absolute_import\n\nimport os\nimport re\nimport inspect\nimport warnings\nfrom functools import wraps\n\nfrom .context import preserve_current_directory\nfrom . import ROOT, ROOT_VERSION\n\n__all__ = [\n    \'requires_ROOT\',\n    \'method_file_check\',\n    \'method_file_cd\',\n    \'chainable\',\n    \'camel_to_snake\',\n    \'snake_case_methods\',\n    \'sync\',\n    \'cached_property\',\n]\n\n\nCONVERT_SNAKE_CASE = os.getenv(\'NO_ROOTPY_SNAKE_CASE\', False) is False\n\n\ndef requires_ROOT(version, exception=False):\n    """"""\n    A decorator for functions or methods that require a minimum ROOT version.\n    If `exception` is False (the default) a warning is issued and None is\n    returned, otherwise a `NotImplementedError` exception is raised.\n    `exception` may also be an `Exception` in which case it will be raised\n    instead of `NotImplementedError`.\n    """"""\n    def decorator(f):\n        @wraps(f)\n        def wrapper(*args, **kwargs):\n            if ROOT_VERSION < version:\n                msg = (""{0} requires at least ROOT {1} ""\n                    ""but you are using {2}"".format(\n                        f.__name__, version, ROOT_VERSION))\n                if inspect.isclass(exception) and issubclass(exception, Exception):\n                    raise exception\n                elif exception:\n                    raise NotImplementedError(msg)\n                warnings.warn(msg)\n                return None\n            return f(*args, **kwargs)\n    return decorator\n\n\ndef _get_qualified_name(thing):\n    if inspect.ismodule(thing):\n        return thing.__file__\n    if inspect.isclass(thing):\n        return \'{0}.{1}\'.format(thing.__module__, thing.__name__)\n    if inspect.ismethod(thing):\n        return \'{0}.{1}\'.format(thing.im_class.__name__, thing.__name__)\n    if inspect.isfunction(thing):\n        return thing.__name__\n    return repr(thing)\n\n\ndef method_file_check(f):\n    """"""\n    A decorator to check that a TFile as been created before f is called.\n    This function can decorate methods.\n\n    This requires special treatment since in Python 3 unbound methods are\n    just functions: http://stackoverflow.com/a/3589335/1002176 but to get\n    consistent access to the class in both 2.x and 3.x, we need self.\n    """"""\n    @wraps(f)\n    def wrapper(self, *args, **kwargs):\n        curr_dir = ROOT.gDirectory\n        if isinstance(curr_dir, ROOT.TROOT) or not curr_dir:\n            raise RuntimeError(\n                ""You must first create a File before calling {0}.{1}"".format(\n                    self.__class__.__name__, _get_qualified_name(f)))\n        if not curr_dir.IsWritable():\n            raise RuntimeError(\n                ""Calling {0}.{1} requires that the ""\n                ""current File is writable"".format(\n                    self.__class__.__name__, _get_qualified_name(f)))\n        return f(self, *args, **kwargs)\n    return wrapper\n\n\ndef method_file_cd(f):\n    """"""\n    A decorator to cd back to the original directory where this object was\n    created (useful for any calls to TObject.Write).\n    This function can decorate methods.\n    """"""\n    @wraps(f)\n    def wrapper(self, *args, **kwargs):\n        with preserve_current_directory():\n            self.GetDirectory().cd()\n            return f(self, *args, **kwargs)\n    return wrapper\n\n\ndef chainable(f):\n    """"""\n    Decorator which causes a \'void\' function to return self\n\n    Allows chaining of multiple modifier class methods.\n    """"""\n    @wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # perform action\n        f(self, *args, **kwargs)\n        # return reference to class.\n        return self\n    return wrapper\n\n\nFIRST_CAP_RE = re.compile(\'(.)([A-Z][a-z]+)\')\nALL_CAP_RE = re.compile(\'([a-z0-9])([A-Z])\')\n\n\ndef camel_to_snake(name):\n    """"""\n    http://stackoverflow.com/questions/1175208/\n    elegant-python-function-to-convert-camelcase-to-camel-case\n    """"""\n    s1 = FIRST_CAP_RE.sub(r\'\\1_\\2\', name)\n    return ALL_CAP_RE.sub(r\'\\1_\\2\', s1).lower()\n\n\ndef snake_case_methods(cls, debug=False):\n    """"""\n    A class decorator adding snake_case methods\n    that alias capitalized ROOT methods. cls must subclass\n    a ROOT class and define the _ROOT class variable.\n    """"""\n    if not CONVERT_SNAKE_CASE:\n        return cls\n    # get the ROOT base class\n    root_base = cls._ROOT\n    members = inspect.getmembers(root_base)\n    # filter out any methods that already exist in lower and uppercase forms\n    # i.e. TDirectory::cd and Cd...\n    names = {}\n    for name, member in members:\n        lower_name = name.lower()\n        if lower_name in names:\n            del names[lower_name]\n        else:\n            names[lower_name] = None\n\n    for name, member in members:\n        if name.lower() not in names:\n            continue\n        # Don\'t touch special methods or methods without cap letters\n        if name[0] == \'_\' or name.islower():\n            continue\n        # Is this a method of the ROOT base class?\n        if not inspect.ismethod(member) and not inspect.isfunction(member):\n            continue\n        # convert CamelCase to snake_case\n        new_name = camel_to_snake(name)\n        # Use a __dict__ lookup rather than getattr because we _want_ to\n        # obtain the _descriptor_, and not what the descriptor gives us\n        # when it is `getattr`\'d.\n        value = None\n        skip = False\n        for c in cls.mro():\n            # skip methods that are already overridden\n            if new_name in c.__dict__:\n                skip = True\n                break\n            if name in c.__dict__:\n                value = c.__dict__[name]\n                break\n        # <neo>Woah, a use for for-else</neo>\n        else:\n            # Weird. Maybe the item lives somewhere else, such as on the\n            # metaclass?\n            value = getattr(cls, name)\n        if skip:\n            continue\n        setattr(cls, new_name, value)\n    return cls\n\n\ndef sync(lock):\n    """"""\n    A synchronization decorator\n    """"""\n    def sync(f):\n        @wraps(f)\n        def new_function(*args, **kwargs):\n            lock.acquire()\n            try:\n                return f(*args, **kwargs)\n            finally:\n                lock.release()\n        return new_function\n    return sync\n\n\nclass cached_property(object):\n    """"""\n    Computes attribute value and caches it in the instance.\n    Written by Denis Otkidach and published in the Python Cookbook.\n    This decorator allows you to create a property which can be computed once\n    and accessed many times. Sort of like memoization.\n    """"""\n    def __init__(self, method, name=None):\n        # record the unbound-method and the name\n        self.method = method\n        self.name = name or method.__name__\n        self.__doc__ = method.__doc__\n\n    def __get__(self, inst, cls):\n        # self: <__main__.cache object at 0xb781340c>\n        # inst: <__main__.Foo object at 0xb781348c>\n        # cls: <class \'__main__.Foo\'>\n        if inst is None:\n            # instance attribute accessed on class, return self\n            # You get here if you write `Foo.bar`\n            return self\n        # compute, cache and return the instance\'s attribute value\n        result = self.method(inst)\n        # setattr redefines the instance\'s attribute so this doesn\'t get called again\n        setattr(inst, self.name, result)\n        return result\n'"
rootpy/defaults.py,0,"b'from __future__ import absolute_import\n\nimport sys\nimport ctypes as C\nimport os\nfrom functools import wraps\n\nimport ROOT\n# This doesn\'t trigger finalSetup()\nROOT.PyConfig.IgnoreCommandLineOptions = True\n\nfrom . import log; log = log[__name__]\nfrom . import QROOT, IN_NOSETESTS\nfrom .logger import set_error_handler, python_logging_error_handler\nfrom .logger.magic import DANGER, fix_ipython_startup\n\n\n__all__ = []\n\n\nif not log[""/""].has_handlers():\n    # The root logger doesn\'t have any handlers.\n    # Therefore, the application hasn\'t specified any behaviour, and rootpy\n    # uses maximum verbosity.\n    log[""/""].setLevel(log.NOTSET)\n\nuse_rootpy_handler = not os.environ.get(\'NO_ROOTPY_HANDLER\', False)\n# rootpy\'s logger magic is not safe in Python 3, yet\nuse_rootpy_magic = not os.environ.get(\'NO_ROOTPY_MAGIC\', False) and sys.version_info[0] < 3\n\nif use_rootpy_handler:\n    if use_rootpy_magic:\n        # See magic module for more details\n        DANGER.enabled = True\n    else:\n        log.debug(\'logger magic disabled\')\n        DANGER.enabled = False\n    # Show python backtrace if there is a segfault\n    log[""/ROOT.TUnixSystem.DispatchSignals""].show_stack(min_level=log.ERROR)\n    orig_error_handler = set_error_handler(python_logging_error_handler)\nelse:\n    log.debug(\'ROOT error handler disabled\')\n\nDICTS_PATH = MODS_PATH = None\n\n# Activate the storage of the sum of squares of errors by default.\nQROOT.TH1.SetDefaultSumw2(True)\n# Activate use of underflows and overflows in `Fill()` in the\n# computation of statistics (mean value, RMS) by default.\nQROOT.TH1.StatOverflows(True)\n# Setting the above static parameters below in the configure_defaults function\n# may be too late. For example, the first histogram will be inited before these\n# are set.\n\n_initializations = []\n\n\ndef extra_initialization(fn):\n    """"""\n    Function decorator which adds `fn` to the list of functions to be called\n    at some point after ROOT has been initialized.\n    """"""\n    if initialized:\n        fn()\n    else:\n        _initializations.append(fn)\n    return fn\n\n\ndef configure_defaults():\n    """"""\n    This function is executed immediately after ROOT\'s finalSetup\n    """"""\n    log.debug(""configure_defaults()"")\n\n    global initialized\n    initialized = True\n\n    if use_rootpy_handler:\n        # Need to do it again here, since it is overridden by ROOT.\n        set_error_handler(python_logging_error_handler)\n\n    if os.environ.get(\'ROOTPY_BATCH\', False) or IN_NOSETESTS:\n        ROOT.gROOT.SetBatch(True)\n        log.debug(\'ROOT is running in batch mode\')\n\n    ROOT.gErrorIgnoreLevel = 0\n\n    this_dll = C.CDLL(None)\n    try:\n        EnableAutoDictionary = C.c_int.in_dll(\n            this_dll, ""G__EnableAutoDictionary"")\n    except ValueError:\n        pass\n    else:\n        # Disable automatic dictionary generation\n        EnableAutoDictionary.value = 0\n\n    # TODO(pwaller): idea, `execfile(""userdata/initrc.py"")` here?\n    #                note: that wouldn\'t allow the user to override the default\n    #                      canvas size, for example.\n\n    for init in _initializations:\n        init()\n\n\ndef rp_module_level_in_stack():\n    """"""\n    Returns true if we\'re during a rootpy import\n    """"""\n    from traceback import extract_stack\n    from rootpy import _ROOTPY_SOURCE_PATH\n    modlevel_files = [filename for filename, _, func, _ in extract_stack()\n                      if func == ""<module>""]\n\n    return any(path.startswith(_ROOTPY_SOURCE_PATH) for path in modlevel_files)\n\n\n# Check in case the horse has already bolted.\n# If initialization has already taken place, we can\'t wrap it.\nif hasattr(ROOT.__class__, ""_ModuleFacade__finalSetup""):\n    initialized = False\n\n    # Inject our own wrapper in place of ROOT\'s finalSetup so that we can\n    # trigger our default options then.\n\n    finalSetup = ROOT.__class__._ModuleFacade__finalSetup\n\n    @wraps(finalSetup)\n    def wrapFinalSetup(*args, **kwargs):\n\n        log.debug(""PyROOT\'s finalSetup() has been triggered"")\n\n        if os.environ.get(""ROOTPY_DEBUG"", None) and rp_module_level_in_stack():\n            # Check to see if we\'re at module level anywhere in rootpy.\n            # If so, that\'s not ideal.\n            l = log[""bug""]\n            l.show_stack()\n            l.debug(""PyROOT\'s finalSetup() triggered from rootpy at ""\n                    ""module-level. Please report this."")\n\n        # if running in the ATLAS environment suppress a known harmless warning\n        if os.environ.get(""AtlasVersion"", None):\n            regex = ""^duplicate entry .* vectorbool.dll> for level 0; ignored$""\n            c = log[""/ROOT.TEnvRec.ChangeValue""].ignore(regex)\n            with c:\n                result = finalSetup(*args, **kwargs)\n        else:\n            result = finalSetup(*args, **kwargs)\n\n        log.debug(\n            ""PyROOT\'s finalSetup() has been called ""\n            ""(gROOT.IsBatch()=={0})"".format(ROOT.gROOT.IsBatch()))\n\n        configure_defaults()\n\n        return result\n\n    wrapFinalSetup._orig_func = finalSetup\n\n    ROOT.__class__._ModuleFacade__finalSetup = wrapFinalSetup\n\n    if \'__IPYTHON__\' in __builtins__:\n        # ROOT has a bug causing it to print (Bool_t)1 to the console.\n        fix_ipython_startup(finalSetup)\n\nelse:\n    initialized = True\n    configure_defaults()\n'"
rootpy/info.py,0,"b'""""""\n                 _\n _ __ ___   ___ | |_ _ __  _   _\n| \'__/ _ \\ / _ \\| __| \'_ \\| | | |\n| | | (_) | (_) | |_| |_) | |_| |\n|_|  \\___/ \\___/ \\__| .__/ \\__, |\n                    |_|    |___/\n      {0}\n""""""\n__version__ = \'1.0.0.dev0\'\n__url__ = \'http://rootpy.github.com/rootpy\'\n__repo_url__ = \'https://github.com/rootpy/rootpy/\'\n__download_url__ = (\'http://pypi.python.org/packages/source/r/\'\n                    \'rootpy/rootpy-{0}.tar.gz\').format(__version__)\n__doc__ = __doc__.format(__version__)\n'"
rootpy/matrix.py,1,"b'from __future__ import absolute_import\n\nfrom . import QROOT\nfrom .extern.six.moves import range\n\n__all__ = [\n    \'Matrix\',\n    \'SymmetricMatrix\',\n]\n\n\nclass _MatrixBase(object):\n\n    def __getitem__(self, loc):\n        if isinstance(loc, tuple):\n            i, j = loc\n            return self(i, j)\n        return super(_MatrixBase, self).__getitem__(loc)\n\n    def __setitem__(self, loc, value):\n        if isinstance(loc, tuple):\n            i, j = loc\n            # this is slow due to creation of temporaries\n            self[i][j] = value\n            return\n        return super(_MatrixBase, self).__setitem__(loc, value)\n\n    def to_numpy(self):\n        """"""\n        Convert this matrix into a\n        `numpy.matrix <http://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.html>`_.\n        """"""\n        import numpy as np\n        cols, rows = self.GetNcols(), self.GetNrows()\n        return np.matrix([[self(i, j)\n            for j in range(cols)]\n            for i in range(rows)])\n\n\nclass Matrix(_MatrixBase):\n    """"""\n    A factory of subclasses of the template class\n    `ROOT.TMatrixT <http://root.cern.ch/root/html/TMatrixT_float_.html>`_.\n\n    Parameters\n    ----------\n\n    type : string, optional (default=\'float\')\n        The type of the matrix elements.\n\n    """"""\n    @classmethod\n    def dynamic_cls(cls, type=\'float\'):\n\n        class Matrix(_MatrixBase, QROOT.TMatrixT(type)):\n            _ROOT = QROOT.TMatrixT(type)\n\n        return Matrix\n\n    def __new__(cls, *args, **kwargs):\n        type = kwargs.pop(\'type\', \'float\')\n        return cls.dynamic_cls(type)(*args, **kwargs)\n\n\nclass SymmetricMatrix(Matrix):\n    """"""\n    A factory of subclasses of the template class\n    `ROOT.TMatrixTSym <http://root.cern.ch/root/html/TMatrixTSym_float_.html>`_.\n\n    Parameters\n    ----------\n\n    type : string, optional (default=\'float\')\n        The type of the matrix elements.\n\n    """"""\n    @classmethod\n    def dynamic_cls(cls, type=\'float\'):\n\n        class SymmetricMatrix(_MatrixBase, QROOT.TMatrixTSym(type)):\n            _ROOT = QROOT.TMatrixTSym(type)\n\n        return SymmetricMatrix\n'"
rootpy/roosh.py,0,"b'from __future__ import absolute_import, print_function\n\nimport os\nimport sys\nimport readline\nimport cmd\nimport subprocess\nimport re\nfrom fnmatch import fnmatch\nfrom glob import glob\nimport traceback\n# Try and get the termcolor module - pip install termcolor\ntry:\n    from termcolor import colored\nexcept ImportError:\n    # Make a dummy function which does not color the text\n    def colored(text, *args, **kwargs):\n        return text\n\nfrom .extern.argparse import ArgumentParser\n\nfrom . import ROOT\nfrom . import log; log = log[__name__]\nfrom . import __version__\nfrom .io import root_open, DoesNotExist\nfrom .io.file import _DirectoryBase\nfrom .userdata import DATA_ROOT\nfrom .plotting import Canvas\nfrom .plotting.style import set_style\nfrom .logger.utils import check_tty\nfrom .extern.six.moves import input\n\n__all__ = [\n    \'ROOSH\',\n]\n\nEXEC_CMD = re.compile(\'(?P<name>\\w+)\\.(?P<call>\\S+)\')\nASSIGN_CMD = re.compile(\'\\w+\\s*((\\+=)|(-=)|(=))\\s*\\w+\')\nGET_CMD = re.compile(\'^(?P<name>\\S+)(:?\\s+as\\s+(?P<alias>\\S+))?$\')\n\n_COLOR_MATCHER = [\n    (re.compile(\'^TH[123][CSIDF]\'), \'red\'),\n    (re.compile(\'^TTree\'), \'green\'),\n    (re.compile(\'^TChain\'), \'green\'),\n    (re.compile(\'^TDirectory\'), \'blue\'),\n]\n\n\ndef color_key(tkey):\n    """"""\n    Function which returns a colorized TKey name given its type\n    """"""\n    name = tkey.GetName()\n    classname = tkey.GetClassName()\n    for class_regex, color in _COLOR_MATCHER:\n        if class_regex.match(classname):\n            return colored(name, color=color)\n    return name\n\n\ndef prompt(vars, message):\n    prompt_message = message\n    try:\n        from IPython.Shell import IPShellEmbed\n        ipshell = IPShellEmbed(\n            argv=[\'\'],\n            banner=prompt_message, exit_msg=""Goodbye"")\n        return ipshell\n    except ImportError:\n        # this doesn\'t quite work right, in that it doesn\'t go to the right env\n        # so we just fail.\n        import code\n        import rlcompleter\n        readline.parse_and_bind(""tab: complete"")\n        # calling this with globals ensures we can see the environment\n        if prompt_message:\n            print(prompt_message)\n        shell = code.InteractiveConsole(vars)\n        return shell.interact\n\n\ndef ioctl_GWINSZ(fd):\n    try:\n        import fcntl\n        import termios\n        import struct\n        cr = struct.unpack(\'hh\', fcntl.ioctl(fd, termios.TIOCGWINSZ, \'1234\'))\n    except:\n        return None\n    return cr\n\n\ndef get_terminal_size():\n    cr = ioctl_GWINSZ(0) or ioctl_GWINSZ(1) or ioctl_GWINSZ(2)\n    if not cr:\n        try:\n            fd = os.open(os.ctermid(), os.O_RDONLY)\n            cr = ioctl_GWINSZ(fd)\n            os.close(fd)\n        except:\n            pass\n    if not cr:\n        try:\n            cr = (env[\'LINES\'], env[\'COLUMNS\'])\n        except:\n            cr = (25, 80)\n    return int(cr[1]), int(cr[0])\n\n\ndef make_identifier(name):\n    # Replace invalid characters with \'_\'\n    name = re.sub(\'[^0-9a-zA-Z_]\', \'_\', name)\n    # Remove leading characters until we find a letter or underscore\n    return re.sub(\'^[^a-zA-Z_]+\', \'\', name)\n\n\ndef is_valid_identifier(name):\n    return name == make_identifier(name)\n\n\nclass shell_cmd(cmd.Cmd, object):\n\n    def do_shell(self, s):\n        subprocess.call(s, shell=True)\n\n    def help_shell(self):\n        print(""execute commands in your $SHELL (i.e. bash)"")\n\n\nclass empty_cmd(cmd.Cmd, object):\n\n    def emptyline(self):\n        pass\n\n\nclass exit_cmd(cmd.Cmd, object):\n\n    def can_exit(self):\n        return True\n\n    def onecmd(self, line):\n        r = super(exit_cmd, self).onecmd(line)\n        if (r and (self.can_exit() or\n                   input(\'exit anyway ? (yes/no):\') == \'yes\')):\n            return True\n        return False\n\n    def do_exit(self, s):\n        return True\n\n    def help_exit(self):\n        print(""Exit the interpreter."")\n        print(""You can also use the Ctrl-D shortcut."")\n\n    def do_EOF(self, s):\n        if not self.script:\n            print()\n        return True\n\n    help_EOF = help_exit\n\n\ndef root_glob(directory, pattern):\n\n    matches = []\n    for dirpath, dirnames, filenames in \\\n            directory.walk(maxdepth=pattern.count(os.path.sep)):\n        for dirname in dirnames:\n            dirname = os.path.join(dirpath, dirname)\n            if fnmatch(dirname, pattern):\n                matches.append(dirname)\n        for filename in filenames:\n            filename = os.path.join(dirpath, filename)\n            if fnmatch(filename, pattern):\n                matches.append(filename)\n    return matches\n\n\ndef show_exception(e, debug=False, show_type=False):\n\n    if debug:\n        traceback.print_exception(*sys.exc_info())\n    elif show_type:\n        print(""{0}: {1}"".format(e.__class__.__name__, e))\n    else:\n        print(e)\n\n\nclass LazyNamespace(dict):\n\n    def __init__(self, roosh):\n        self.roosh = roosh\n        super(LazyNamespace, self).__init__()\n\n    def __getitem__(self, key):\n        if key in self.roosh.pwd:\n            value = self.roosh.pwd[key]\n            self.__setitem__(key, value)\n            return value\n        try:\n            return super(LazyNamespace, self).__getitem__(key)\n        except KeyError as e:\n            if key == \'P\':\n                pad = ROOT.gPad\n                if pad:\n                    return pad\n                raise\n            elif key == \'C\':\n                pad = ROOT.gPad\n                if pad:\n                    return pad.GetCanvas()\n                raise\n            elif key == \'D\':\n                return self.roosh.pwd\n            if key in __builtins__:\n                return __builtins__[key]\n            try:\n                return getattr(ROOT, key)\n            except AttributeError:\n                pass\n            raise e\n\n\nclass ROOSH(exit_cmd, shell_cmd, empty_cmd):\n\n    ls_parser = ArgumentParser()\n    ls_parser.add_argument(\'-l\', action=\'store_true\',\n                           dest=\'showtype\', default=False)\n    ls_parser.add_argument(\'files\', nargs=\'*\')\n\n    mkdir_parser = ArgumentParser()\n    mkdir_parser.add_argument(\'-p\', action=\'store_true\',\n                              dest=\'recurse\', default=False,\n                              help=""create parent directories as required"")\n    mkdir_parser.add_argument(\'paths\', nargs=\'*\')\n\n    def __init__(self, filename, mode=\'READ\',\n                 stdin=None, stdout=None,\n                 script=False,\n                 debug=False):\n        if stdin is None:\n            stdin = sys.stdin\n        if stdout is None:\n            stdout = sys.stdout\n        super(ROOSH, self).__init__(stdin=stdin, stdout=stdout)\n\n        self.script = script\n        self.debug = debug\n\n        root_file = root_open(filename, mode)\n        self.files = {}\n        self.files[filename] = root_file\n        self.pwd = root_file\n        self.prev_pwd = root_file\n        self.current_file = root_file\n\n        self.namespace = LazyNamespace(self)\n        if script:\n            self.prompt = \'\'\n        else:\n            self.__update_prompt()\n\n    def __update_prompt(self):\n        if self.script:\n            return\n        dirname = os.path.basename(self.pwd._path)\n        if len(dirname) > 20:\n            dirname = (dirname[:10] + \'..\' + dirname[-10:])\n        self.prompt = \'{0} > \'.format(dirname)\n\n    def do_env(self, s):\n        for name, value in self.namespace.items():\n            if name == \'__builtins__\':\n                continue\n            print(""{0}\\t{1}"".format(name, value))\n\n    def help_env(self):\n        print(""print all variable names and values in current environment"")\n        print(""object (excluding directories) contained within the"")\n        print(""current directory are automatically included by name"")\n\n    def do_get(self, name):\n        try:\n            match = re.match(GET_CMD, name)\n            if match:\n                name = match.group(\'name\')\n                alias = match.group(\'alias\')\n                if alias is None:\n                    alias = make_identifier(os.path.basename(name))\n                # check that alias is a valid identifier\n                elif not is_valid_identifier(alias):\n                    print(""{0} is not a valid identifier"".format(alias))\n                    return\n                self.namespace[alias] = self.pwd.Get(name)\n            else:\n                self.default(name)\n        except DoesNotExist as e:\n            show_exception(e, debug=self.debug)\n\n    def complete_get(self, text, line, begidx, endidx):\n        return self.completion_helper(text, line, begidx, endidx)\n\n    def help_get(self):\n        print(\n            ""load the specified object into the current namespace\\n""\n            ""Use \'get foo as bar\' to alias the object named foo as bar"")\n\n    def do_cd(self, path):\n        prev_pwd = self.pwd\n        if path == \'.\':\n            return\n            self.prev_pwd = self.pwd\n        try:\n            if not path:\n                self.pwd = self.current_file\n            elif path == \'-\':\n                self.pwd = self.prev_pwd\n                self.do_pwd()\n            else:\n                self.pwd = self.pwd.GetDirectory(path)\n            self.pwd.cd()\n            self.__update_prompt()\n            self.prev_pwd = prev_pwd\n        except DoesNotExist as e:\n            show_exception(e, debug=self.debug)\n\n    def complete_cd(self, text, line, begidx, endidx):\n        return self.completion_helper(\n            text, line, begidx, endidx, \'TDirectoryFile\')\n\n    def help_cd(self):\n        print(\n            ""change the current directory\\n""\n            ""\'cd -\' will change to the previous directory\\n""\n            ""\'cd\' (with no path) will change to the root directory\\n"")\n\n    def do_ls(self, args=None):\n        if args is None:\n            args = \'\'\n        args = ROOSH.ls_parser.parse_args(args.split())\n        if not args.files:\n            args.files = [\'\']\n        for i, path in enumerate(args.files):\n            if \'*\' in path:\n                paths = root_glob(self.pwd, path)\n                if not paths:\n                    paths = [path]\n            else:\n                paths = [path]\n            for path in paths:\n                _dir = self.pwd\n                if path:\n                    try:\n                        _dir = self.pwd.Get(path)\n                    except DoesNotExist as e:\n                        show_exception(e, debug=self.debug)\n                        continue\n                if isinstance(_dir, _DirectoryBase):\n                    if len(args.files) > 1:\n                        if i > 0:\n                            print()\n                        print(""{0}:"".format(_dir.GetName()))\n                    keys = sorted(_dir.keys(latest=True), key=lambda key: key.GetName())\n                    things = [color_key(key) for key in keys]\n                    if things:\n                        self.columnize(things)\n                else:\n                    print(path)\n\n    def complete_ls(self, text, line, begidx, endidx):\n        return self.completion_helper(text, line, begidx, endidx)\n\n    def help_ls(self):\n        print(""list items contained in a directory"")\n\n    def do_mkdir(self, args=None):\n        if args is None:\n            args = \'\'\n        args = ROOSH.mkdir_parser.parse_args(args.split())\n\n        for path in args.paths:\n            try:\n                self.pwd.mkdir(path, recurse=args.recurse)\n            except Exception as e:\n                show_exception(e, debug=self.debug)\n\n    def complete_mkdir(self, text, line, begidx, endidx):\n        return self.completion_helper(text, line, begidx, endidx,\n                                      typename=\'TDirectoryFile\')\n\n    def do_rm(self, path):\n        try:\n            self.pwd.rm(path)\n        except Exception as e:\n            show_exception(e, debug=self.debug)\n\n    def complete_rm(self, text, line, begidx, endidx):\n        return self.completion_helper(text, line, begidx, endidx)\n\n    def do_cp(self, args):\n        try:\n            thing, dest = args.split()\n            self.pwd.copytree(dest, src=thing)\n        except Exception as e:\n            show_exception(e, debug=self.debug)\n\n    def complete_cp(self, text, line, begidx, endidx):\n        return self.completion_helper(text, line, begidx, endidx)\n\n    def completion_helper(self, text, line, begidx, endidx, typename=None):\n        things = []\n        directory = self.pwd\n        head = \'\'\n        if begidx != endidx:\n            prefix = line[begidx: endidx]\n            head, prefix = os.path.split(prefix)\n            if head:\n                try:\n                    directory = directory.GetDirectory(head)\n                except DoesNotExist:\n                    return []\n        else:\n            prefix = \'\'\n        for key in directory.GetListOfKeys():\n            if typename is not None:\n                if key.GetClassName() != typename:\n                    continue\n            name = key.GetName()\n            if prefix and not name.startswith(prefix):\n                continue\n            if key.GetClassName() == \'TDirectoryFile\':\n                things.append(os.path.join(head, \'{0}/\'.format(name)))\n            else:\n                things.append(os.path.join(head, name))\n        return things\n\n    def do_pwd(self, s=None):\n        print(self.pwd._path)\n\n    def help_pwd(self):\n        print(""print the current directory"")\n\n    def help_help(self):\n        print(""\'help CMD\' will print help for a command"")\n        print(""\'help\' will print all available commands"")\n\n    def do_python(self, s=None):\n        prompt(self.namespace, \'\')()\n\n    def help_python(self):\n        print(""drop into an interactive Python shell"")\n        print(""anything loaded into your current namespace"")\n        print(""will be handed over to Python"")\n\n    @property\n    def current_pad(self):\n        pad = ROOT.gPad\n        if pad:\n            return pad\n        return None\n\n    @property\n    def current_canvas(self):\n        pad = self.current_pad\n        if pad:\n            return pad.GetCanvas()\n        return None\n\n    @property\n    def canvases(self):\n        return ROOT.gROOT.GetListOfCanvases()\n\n    def do_canvas(self, name=None):\n        current_pad = self.current_pad\n        current_canvas = self.current_canvas\n        canvases = self.canvases\n\n        if not name:\n            # print list of existing canvases\n            if not current_pad:\n                print(""no canvases exist, create a new one by ""\n                      ""specifying name: canvas mycanvas"")\n                return\n            for c in canvases:\n                if c is current_canvas:\n                    print(""* {0}"".format(c.GetName()))\n                else:\n                    print(""  {0}"".format(c.GetName()))\n            return\n\n        for c in canvases:\n            if c.GetName() == name:\n                c.cd()\n                print(""switching to previous canvas \'{0}\'"".format(name))\n                return\n\n        print(""switching to new canvas \'{0}\'"".format(name))\n        canvas = Canvas(name=name, title=name)\n        canvas.cd()\n\n    def help_canvas(self):\n        print(""switch to a new or previous canvas"")\n\n    def complete_canvas(self, text, line, begidx, endidx):\n        names = []\n        if begidx != endidx:\n            prefix = line[begidx: endidx]\n        else:\n            prefix = \'\'\n        for c in self.canvases:\n            name = c.GetName()\n            if prefix and not name.startswith(prefix):\n                continue\n            names.append(name)\n        return names\n\n    def do_clear(self, *args):\n        canvas = self.current_canvas\n        if canvas is not None:\n            canvas.Clear()\n            canvas.Update()\n\n    def help_clear(self):\n        print(""clear the current canvas"")\n\n    @property\n    def styles(self):\n        return ROOT.gROOT.GetListOfStyles()\n\n    @property\n    def current_style(self):\n        return ROOT.gStyle\n\n    def do_style(self, name):\n\n        current_style = self.current_style\n        styles = self.styles\n        if not name:\n            # print list of existing styles\n            for s in styles:\n                if s.GetName() == current_style.GetName():\n                    print(""* {0}"".format(s.GetName()))\n                else:\n                    print(""  {0}"".format(s.GetName()))\n            return\n        try:\n            set_style(name)\n        except ValueError as e:\n            show_exception(e)\n        else:\n            canvas = self.current_canvas\n            if canvas is not None:\n                canvas.UseCurrentStyle()\n                canvas.Modified()\n                canvas.Update()\n                canvas.Modified()\n                canvas.Update()\n\n    def complete_style(self, text, line, begidx, endidx):\n        names = []\n        if begidx != endidx:\n            prefix = line[begidx: endidx]\n        else:\n            prefix = \'\'\n        if not prefix:\n            return names\n        for s in self.styles:\n            name = s.GetName()\n            if name.startswith(prefix) or name.lower().startswith(prefix):\n                names.append(name)\n        return names\n\n    def help_style(self):\n        print(""set the current style"")\n\n    def do_roosh(self, filename=None):\n        if not filename:\n            for name, rfile in self.files.items():\n                if rfile is self.current_file:\n                    print(""* {0}"".format(name))\n                else:\n                    print(""  {0}"".format(name))\n            return\n        if not os.path.isfile(filename):\n            print(""file \'{0}\' does not exist"".format(filename))\n            return\n        prev_pwd = self.pwd\n        if filename not in self.files:\n            print(""switching to new file {0}"".format(filename))\n            rfile = root_open(filename)\n            self.files[filename] = rfile\n        else:\n            print(""switching to previous file {0}"".format(filename))\n            rfile = self.files[filename]\n        self.pwd = rfile\n        self.current_file = rfile\n        self.pwd.cd()\n        self.__update_prompt()\n        self.prev_pwd = prev_pwd\n\n    def help_roosh(self):\n        print(""switch to a new or previous file"")\n\n    def complete_roosh(self, text, line, begidx, endidx):\n        names = []\n        if begidx != endidx:\n            prefix = line[begidx: endidx]\n        else:\n            prefix = \'\'\n        for name in glob(prefix + \'*\'):\n            if os.path.isdir(name) or fnmatch(name, \'*.root*\'):\n                names.append(name)\n        if len(names) == 1 and os.path.isdir(names[0]):\n            names[0] = os.path.normpath(names[0]) + os.path.sep\n        return names\n\n    def completenames(self, text, *ignored):\n        dotext = \'do_\' + text\n        cmds = [a[3:] for a in self.get_names() if a.startswith(dotext)]\n        objects = [\n            key.name for key in self.pwd.keys() if key.name.startswith(text)]\n        return cmds + objects\n\n    def completedefault(self, text, line, begidx, endidx):\n        return self.completion_helper(text, line, begidx, endidx)\n\n    def default(self, line):\n        if line.lstrip().startswith(\'#\'):\n            return\n        try:\n            if not re.match(ASSIGN_CMD, line):\n                line = line.strip()\n                if (not line.startswith(\'print\') and\n                        not line.startswith(\'from \') and\n                        not line.startswith(\'import \') and\n                        not line.startswith(\'with \') and\n                        not line.startswith(\'if \')):\n                    line = \'__ = \' + line\n            exec(line, self.namespace)\n            if \'__\' in self.namespace:\n                if self.namespace[\'__\'] is not None:\n                    print(repr(self.namespace[\'__\']))\n                del self.namespace[\'__\']\n            return\n        except Exception as e:\n            show_exception(e, debug=self.debug, show_type=True)\n            return\n        return super(ROOSH, self).default(line)\n\n\ndef main():\n    parser = ArgumentParser()\n    parser.add_argument(\'--version\', action=\'version\',\n                        version=__version__,\n                        help=""show the version number and exit"")\n    parser.add_argument(\'script\', nargs=\'?\', default=None,\n                        help=""read input from this file instead of stdin"")\n    parser.add_argument(\'-l\', action=\'store_true\',\n                        dest=\'nointro\', default=False,\n                        help=""don\'t print the intro message"")\n    parser.add_argument(\'-u\', \'--update\', action=\'store_true\', default=False,\n                        help=""open the file in UPDATE mode (default: READ)"")\n    parser.add_argument(\'-d\', \'--debug\', action=\'store_true\', default=False,\n                        help=""print stack traces"")\n    parser.add_argument(\'filename\', help=""a ROOT file"")\n    parser.add_argument(\'libs\', nargs=\'*\',\n                        help=""libraries required to read ""\n                            ""contents of the ROOT file"")\n    args = parser.parse_args()\n\n    if not args.filename.startswith(\'root://\') and not os.path.isfile(args.filename) and not args.update:\n        sys.exit(""File {0} does not exist"".format(args.filename))\n\n    if args.libs:\n        for lib in args.libs:\n            log.info(""loading {0}"".format(lib))\n            ROOT.gSystem.Load(lib)\n\n    history_file = os.path.join(DATA_ROOT, \'roosh_history\')\n    if os.path.exists(history_file):\n        readline.read_history_file(history_file)\n    history_size = os.getenv(\'ROOSH_HISTORY_SIZE\', 500)\n    readline.set_history_length(history_size)\n\n    try:\n        if args.script is not None:\n            scriptmode = True\n            stdin = open(args.script, \'r\')\n        else:\n            scriptmode = False\n            stdin = sys.stdin\n\n        terminal = ROOSH(\n            args.filename,\n            mode=\'UPDATE\' if args.update else \'READ\',\n            stdin=stdin,\n            script=scriptmode,\n            debug=args.debug)\n\n        if scriptmode:\n            terminal.use_rawinput = False\n\n        if args.nointro or scriptmode:\n            terminal.cmdloop()\n        else:\n            terminal.cmdloop(\n                ""Welcome to the ROOSH terminal\\ntype help for help"")\n        if not scriptmode:\n            readline.write_history_file(history_file)\n    except Exception as e:\n        if not scriptmode:\n            readline.write_history_file(history_file)\n        show_exception(e, debug=args.debug)\n        sys.exit(e)\n'"
rootpy/root2hdf5.py,0,"b'""""""\nThis module handles conversion of ROOT\'s TFile and\ncontained TTrees into HDF5 format with PyTables\n""""""\nfrom __future__ import absolute_import\n\nimport os\nimport sys\nimport warnings\nfrom pkg_resources import parse_version\n\nimport tables\nTABLES_NEW_API = parse_version(tables.__version__) >= parse_version(\'3\')\nif TABLES_NEW_API:\n    tables_open = tables.open_file\nelse:\n    tables_open = tables.openFile\n\nfrom root_numpy import tree2array, RootNumpyUnconvertibleWarning\nfrom numpy.lib import recfunctions\n\nfrom .io import root_open, TemporaryFile\nfrom . import log; log = log[__name__]\nfrom .extern.progressbar import ProgressBar, Bar, ETA, Percentage\nfrom .extern.six import string_types\nfrom .logger.utils import check_tty\n\nfrom . import QROOT\n\n__all__ = [\n    \'tree2hdf5\',\n    \'root2hdf5\',\n]\n\n\ndef _drop_object_col(rec, warn=True):\n    # ignore columns of type `object` since PyTables does not support these\n    if rec.dtype.hasobject:\n        object_fields = []\n        fields = rec.dtype.fields\n        for name in rec.dtype.names:\n            if fields[name][0].kind == \'O\':\n                object_fields.append(name)\n                if warn:\n                    log.warning(\n                        ""ignoring unsupported object branch \'{0}\'"".format(\n                            name))\n        # NumPy 1.7.1: TypeError: Cannot change data-type for object array.\n        #return rec[non_object_fields]\n        if object_fields:\n            rec = recfunctions.rec_drop_fields(rec, object_fields)\n    return rec\n\n\ndef tree2hdf5(tree, hfile, group=None,\n              entries=-1, show_progress=False, **kwargs):\n    """"""\n    Convert a TTree into a HDF5 table.\n\n    Parameters\n    ----------\n\n    tree : ROOT.TTree\n        A ROOT TTree.\n\n    hfile : string or PyTables HDF5 File\n        A PyTables HDF5 File handle or string path to an existing HDF5 file.\n\n    group : string or PyTables Group instance, optional (default=None)\n        Write the table at this location in the HDF5 file.\n\n    entries : int, optional (default=-1)\n        The number of entries to read at once while converting a ROOT TTree\n        into an HDF5 table. By default read the entire TTree into memory (this\n        may not be desired if your TTrees are large).\n\n    show_progress : bool, optional (default=False)\n        If True, then display and update a progress bar on stdout as the TTree\n        is converted.\n\n    kwargs : dict, optional\n        Additional keyword arguments for the tree2array function.\n\n    """"""\n    show_progress = show_progress and check_tty(sys.stdout)\n    if show_progress:\n        widgets = [Percentage(), \' \', Bar(), \' \', ETA()]\n\n    own_h5file = False\n    if isinstance(hfile, string_types):\n        hfile = tables_open(filename=hfile, mode=""w"", title=""Data"")\n        own_h5file = True\n\n    log.info(""Converting tree \'{0}\' with {1:d} entries ..."".format(\n        tree.GetName(),\n        tree.GetEntries()))\n\n    if not group:\n        group = hfile.root\n    elif isinstance(group, string_types):\n        group_where = \'/\' + os.path.dirname(group)\n        group_name = os.path.basename(group)\n        if TABLES_NEW_API:\n            group = hfile.create_group(group_where, group_name,\n                                       createparents=True)\n        else:\n            group = hfile.createGroup(group_where, group_name)\n\n    if tree.GetName() in group:\n        log.warning(\n            ""Tree \'{0}\' already exists ""\n            ""in the output file"".format(tree.GetName()))\n        return\n\n    total_entries = tree.GetEntries()\n    pbar = None\n    if show_progress and total_entries > 0:\n        pbar = ProgressBar(widgets=widgets, maxval=total_entries)\n\n    if entries <= 0:\n        # read the entire tree\n        if pbar is not None:\n            pbar.start()\n        array = tree2array(tree, **kwargs)\n        array = _drop_object_col(array)\n        if TABLES_NEW_API:\n            table = hfile.create_table(\n                group, tree.GetName(),\n                array, tree.GetTitle())\n        else:\n            table = hfile.createTable(\n                group, tree.GetName(),\n                array, tree.GetTitle())\n        # flush data in the table\n        table.flush()\n        # flush all pending data\n        hfile.flush()\n    else:\n        # read the tree in chunks\n        start = 0\n        while start < total_entries or start == 0:\n            if start > 0:\n                with warnings.catch_warnings():\n                    warnings.simplefilter(\n                        ""ignore"",\n                        RootNumpyUnconvertibleWarning)\n                    warnings.simplefilter(\n                        ""ignore"",\n                        tables.NaturalNameWarning)\n                    array = tree2array(\n                        tree,\n                        start=start,\n                        stop=start + entries,\n                        **kwargs)\n                array = _drop_object_col(array, warn=False)\n                table.append(array)\n            else:\n                array = tree2array(\n                    tree,\n                    start=start,\n                    stop=start + entries,\n                    **kwargs)\n                array = _drop_object_col(array)\n                if pbar is not None:\n                    # start after any output from root_numpy\n                    pbar.start()\n                if TABLES_NEW_API:\n                    table = hfile.create_table(\n                        group, tree.GetName(),\n                        array, tree.GetTitle())\n                else:\n                    table = hfile.createTable(\n                        group, tree.GetName(),\n                        array, tree.GetTitle())\n            start += entries\n            if start <= total_entries and pbar is not None:\n                pbar.update(start)\n            # flush data in the table\n            table.flush()\n            # flush all pending data\n            hfile.flush()\n\n    if pbar is not None:\n        pbar.finish()\n\n    if own_h5file:\n        hfile.close()\n\n\ndef root2hdf5(rfile, hfile, rpath=\'\',\n              entries=-1, userfunc=None,\n              show_progress=False,\n              ignore_exception=False,\n              **kwargs):\n    """"""\n    Convert all trees in a ROOT file into tables in an HDF5 file.\n\n    Parameters\n    ----------\n\n    rfile : string or asrootpy\'d ROOT File\n        A ROOT File handle or string path to an existing ROOT file.\n\n    hfile : string or PyTables HDF5 File\n        A PyTables HDF5 File handle or string path to an existing HDF5 file.\n\n    rpath : string, optional (default=\'\')\n        Top level path to begin traversal through the ROOT file. By default\n        convert everything in and below the root directory.\n\n    entries : int, optional (default=-1)\n        The number of entries to read at once while converting a ROOT TTree\n        into an HDF5 table. By default read the entire TTree into memory (this\n        may not be desired if your TTrees are large).\n\n    userfunc : callable, optional (default=None)\n        A function that will be called on every tree and that must return a\n        tree or list of trees that will be converted instead of the original\n        tree.\n\n    show_progress : bool, optional (default=False)\n        If True, then display and update a progress bar on stdout as each tree\n        is converted.\n\n    ignore_exception : bool, optional (default=False)\n        If True, then ignore exceptions raised in converting trees and instead\n        skip such trees.\n\n    kwargs : dict, optional\n        Additional keyword arguments for the tree2array function.\n\n    """"""\n    own_rootfile = False\n    if isinstance(rfile, string_types):\n        rfile = root_open(rfile)\n        own_rootfile = True\n\n    own_h5file = False\n    if isinstance(hfile, string_types):\n        hfile = tables_open(filename=hfile, mode=""w"", title=""Data"")\n        own_h5file = True\n\n    for dirpath, dirnames, treenames in rfile.walk(\n            rpath, class_ref=QROOT.TTree):\n\n        # skip directories w/o trees\n        if not treenames:\n            continue\n\n        treenames.sort()\n\n        group_where = \'/\' + os.path.dirname(dirpath)\n        group_name = os.path.basename(dirpath)\n\n        if not group_name:\n            group = hfile.root\n        elif TABLES_NEW_API:\n            group = hfile.create_group(group_where, group_name,\n                                       createparents=True)\n        else:\n            group = hfile.createGroup(group_where, group_name)\n\n        ntrees = len(treenames)\n        log.info(\n            ""Will convert {0:d} tree{1} in {2}"".format(\n                ntrees, \'s\' if ntrees != 1 else \'\',\n                os.path.join(group_where, group_name)))\n\n        for treename in treenames:\n\n            input_tree = rfile.Get(os.path.join(dirpath, treename))\n\n            if userfunc is not None:\n                tmp_file = TemporaryFile()\n                # call user-defined function on tree and get output trees\n                log.info(""Calling user function on tree \'{0}\'"".format(\n                    input_tree.GetName()))\n                trees = userfunc(input_tree)\n\n                if not isinstance(trees, list):\n                    trees = [trees]\n\n            else:\n                trees = [input_tree]\n                tmp_file = None\n\n            for tree in trees:\n                try:\n                    tree2hdf5(tree, hfile, group=group,\n                              entries=entries,\n                              show_progress=show_progress,\n                              **kwargs)\n                except Exception as e:\n                    if ignore_exception:\n                        log.error(""Failed to convert tree \'{0}\': {1}"".format(\n                            tree.GetName(), str(e)))\n                    else:\n                        raise\n\n            input_tree.Delete()\n\n            if userfunc is not None:\n                for tree in trees:\n                    tree.Delete()\n                tmp_file.Close()\n\n    if own_h5file:\n        hfile.close()\n    if own_rootfile:\n        rfile.Close()\n\n\ndef main():\n\n    import rootpy\n    from rootpy.extern.argparse import (\n        ArgumentParser,\n        ArgumentDefaultsHelpFormatter, RawTextHelpFormatter)\n\n    class formatter_class(ArgumentDefaultsHelpFormatter,\n                          RawTextHelpFormatter):\n        pass\n\n    parser = ArgumentParser(formatter_class=formatter_class,\n        description=""Convert ROOT files containing TTrees into HDF5 files ""\n                    ""containing HDF5 tables"")\n    parser.add_argument(\'--version\', action=\'version\',\n                        version=rootpy.__version__,\n                        help=""show the version number and exit"")\n    parser.add_argument(\'-n\', \'--entries\', type=int, default=100000,\n                        help=""number of entries to read at once"")\n    parser.add_argument(\'-f\', \'--force\', action=\'store_true\', default=False,\n                        help=""overwrite existing output files"")\n    parser.add_argument(\'-u\', \'--update\', action=\'store_true\', default=False,\n                        help=""update existing output files"")\n    parser.add_argument(\'--ext\', default=\'h5\',\n                        help=""output file extension"")\n    parser.add_argument(\'-c\', \'--complevel\', type=int, default=5,\n                        choices=range(0, 10),\n                        help=""compression level"")\n    parser.add_argument(\'-l\', \'--complib\', default=\'zlib\',\n                        choices=(\'zlib\', \'lzo\', \'bzip2\', \'blosc\'),\n                        help=""compression algorithm"")\n    parser.add_argument(\'-s\', \'--selection\', default=None,\n                        help=""apply a selection on each ""\n                             ""tree with a cut expression"")\n    parser.add_argument(\n        \'--script\', default=None,\n        help=""Python script containing a function with the same name \\n""\n             ""that will be called on each tree and must return a tree or \\n""\n             ""list of trees that will be converted instead of the \\n""\n             ""original tree"")\n    parser.add_argument(\'-q\', \'--quiet\', action=\'store_true\', default=False,\n                        help=""suppress all warnings"")\n    parser.add_argument(\'-d\', \'--debug\', action=\'store_true\', default=False,\n                        help=""show stack trace in the event of ""\n                             ""an uncaught exception"")\n    parser.add_argument(\'--no-progress-bar\', action=\'store_true\', default=False,\n                        help=""do not show the progress bar"")\n    parser.add_argument(\'--ignore-exception\', action=\'store_true\',\n                        default=False,\n                        help=""ignore exceptions raised in converting trees ""\n                             ""and instead skip such trees"")\n    parser.add_argument(\'files\', nargs=\'+\')\n    args = parser.parse_args()\n\n    import logging\n    if hasattr(logging, \'captureWarnings\'):\n        logging.captureWarnings(True)\n\n    def formatwarning(message, category, filename, lineno, line=None):\n        return ""{0}: {1}"".format(category.__name__, message)\n\n    warnings.formatwarning = formatwarning\n    args.ext = args.ext.strip(\'.\')\n\n    if args.quiet:\n        warnings.simplefilter(\n            ""ignore"",\n            RootNumpyUnconvertibleWarning)\n        warnings.simplefilter(\n            ""ignore"",\n            tables.NaturalNameWarning)\n\n    userfunc = None\n    if args.script is not None:\n        # get user-defined function\n        try:\n            exec(compile(open(args.script).read(), args.script, \'exec\'),\n                 globals(), locals())\n        except IOError:\n            sys.exit(\'Could not open script {0}\'.format(args.script))\n        funcname = os.path.splitext(os.path.basename(args.script))[0]\n        try:\n            userfunc = locals()[funcname]\n        except KeyError:\n            sys.exit(\n                ""Could not find the function \'{0}\' in the script {1}"".format(\n                    funcname, args.script))\n\n    for inputname in args.files:\n        outputname = os.path.splitext(inputname)[0] + \'.\' + args.ext\n        output_exists = os.path.exists(outputname)\n        if output_exists and not (args.force or args.update):\n            sys.exit(\n                ""Output {0} already exists. ""\n                ""Use the --force option to overwrite it"".format(outputname))\n        try:\n            rootfile = root_open(inputname)\n        except IOError:\n            sys.exit(""Could not open {0}"".format(inputname))\n        try:\n            if args.complevel > 0:\n                filters = tables.Filters(complib=args.complib,\n                                         complevel=args.complevel)\n            else:\n                filters = None\n            hd5file = tables_open(filename=outputname,\n                                  mode=\'a\' if args.update else \'w\',\n                                  title=\'Data\', filters=filters)\n        except IOError:\n            sys.exit(""Could not create {0}"".format(outputname))\n        try:\n            log.info(""Converting {0} ..."".format(inputname))\n            root2hdf5(rootfile, hd5file,\n                      entries=args.entries,\n                      userfunc=userfunc,\n                      selection=args.selection,\n                      show_progress=not args.no_progress_bar,\n                      ignore_exception=args.ignore_exception)\n            log.info(""{0} {1}"".format(\n                ""Updated"" if output_exists and args.update else ""Created"",\n                outputname))\n        except KeyboardInterrupt:\n            log.info(""Caught Ctrl-c ... cleaning up"")\n            hd5file.close()\n            rootfile.Close()\n            if not output_exists:\n                log.info(""Removing {0}"".format(outputname))\n                os.unlink(outputname)\n            sys.exit(1)\n        except Exception as e:\n            if args.debug:\n                # If in debug mode show full stack trace\n                import traceback\n                traceback.print_exception(*sys.exc_info())\n            log.error(str(e))\n            sys.exit(1)\n        finally:\n            hd5file.close()\n            rootfile.Close()\n'"
rootpy/stl.py,0,"b'""""""\nThis module allows C++ template types to be generated on demand with ease,\nautomatically building dictionaries with ROOT\'s ACLiC as necessary.  Unlike\nvanilla ACLiC, rootpy\'s stl module generates and compiles dictionaries without\ncreating a mess of temporary files in your current working directory.\nDictionaries are also cached in ``~/.cache/rootpy/`` and used by any future\nrequest for the same dictionary instead of compiling from scratch again.\nTemplates can be arbitrarily nested, limited only by what ACLiC and CINT can\nhandle.\n\nExamples\n--------\n\n.. sourcecode:: python\n\n    import rootpy.stl as stl, ROOT\n\n    # Create a vector type\n    StrVector = stl.vector(stl.string)\n    # Instantiate\n    strvector = StrVector()\n    strvector.push_back(""Hello"")\n\n    MapStrRoot = stl.map(stl.string, ROOT.TH1D)\n    MapStrRootPtr = stl.map(stl.string, ""TH1D*"")\n\n\nDictionary generation type inference is flexible and can be nested::\n\n    >>> import rootpy.stl as stl\n    >>> import ROOT\n    >>> from rootpy.plotting import Hist\n    >>> stl.vector(\'int\')\n    <class \'ROOT.vector<int,allocator<int> >\'>\n    >>> stl.vector(int)\n    <class \'ROOT.vector<int,allocator<int> >\'>\n    >>> stl.vector(long)\n    <class \'ROOT.vector<long,allocator<long> >\'>\n    >>> stl.vector(\'vector<int>\')\n    <class \'ROOT.vector<vector<int,allocator<int> >,allocator<vector<int,allocator<int> > > >\'>\n    >>> stl.vector(stl.vector(\'int\'))\n    <class \'ROOT.vector<vector<int,allocator<int> >,allocator<vector<int,allocator<int> > > >\'>\n    >>> stl.vector(stl.vector(stl.vector(int)))\n    <class \'ROOT.vector<vector<vector<int,allocator<int> >,allocator<vector<int,allocator<int> > > > >\'>\n    >>> stl.map(\'string,int\')\n    <class \'ROOT.map<string,int,less<string>,allocator<pair<const string,int> > >\'>\n    >>> stl.map(\'string\', \'int\')\n    <class \'ROOT.map<string,int,less<string>,allocator<pair<const string,int> > >\'>\n    >>> stl.map(stl.string, int)\n    <class \'ROOT.map<string,int,less<string>,allocator<pair<const string,int> > >\'>\n    >>> stl.map(str, int)\n    <class \'ROOT.map<string,int,less<string>,allocator<pair<const string,int> > >\'>\n    >>> stl.map(str, stl.map(int, stl.vector(float)))\n    <class \'ROOT.map<string,map<int,vector<float,allocator<float> > > >\'>\n    >>> stl.map(str, Hist)\n    <class \'ROOT.map<string,TH1,less<string>,allocator<pair<const string,TH1> > >\'>\n    >>> stl.map(str, ROOT.TH1)\n    <class \'ROOT.map<string,TH1,less<string>,allocator<pair<const string,TH1> > >\'>\n    >>> stl.map(str, \'TH1*\')\n    <class \'ROOT.map<string,TH1*,less<string>,allocator<pair<const string,TH1*> > >\'>\n\n""""""\nfrom __future__ import absolute_import\n\nimport sys\nimport inspect\nimport hashlib\nimport os\nimport re\nfrom os.path import join as pjoin, exists\n\nimport ROOT\n\nfrom .extern.pyparsing import ParseException\nfrom .extern.six import string_types\n\nfrom .base import Object\nfrom .defaults import extra_initialization\nfrom .utils.cpp import CPPGrammar\nfrom .utils.path import mkdir_p\nfrom .utils.lock import lock\nfrom . import compiled\nfrom . import userdata\nfrom . import lookup_by_name, register, QROOT\nfrom . import log; log = log[__name__]\n\n__all__ = []\n\nSTL = QROOT.std.stlclasses\n\nHAS_ITERATORS = [\n    \'map\',\n    \'vector\',\n    \'list\'\n]\n\nKNOWN_TYPES = {\n    # Specify class names and headers to use here. ROOT classes beginning ""T""\n    # and having a header called {class}.h are picked up automatically.\n    # \'TLorentzVector\': \'TLorentzVector.h\',\n    ""pair"": ""<utility>"",\n    ""string"": ""<string>"",\n}\n\n\n# FIXME: _rootpy_dictionary_already_exists returns false positives\n# if a third-party module provides ""incomplete"" dictionaries.\ncompiled.register_code(""""""\n    #include <string>\n\n    // PyROOT builtin\n    namespace PyROOT { namespace Utility {\n        const std::string ResolveTypedef( const std::string& name );\n    } }\n\n    // cint magic\n    int G__defined_tagname(const char*, int);\n\n    // Returns true if the given type does not require a dictionary\n    bool _rootpy_dictionary_already_exists(const char* type) {\n        const std::string full_typedef = PyROOT::Utility::ResolveTypedef(type);\n        return G__defined_tagname(full_typedef.c_str(), 4) != -1;\n    }\n"""""", [""_rootpy_dictionary_already_exists""])\n\nLINKDEF = \'\'\'\\\n%(includes)s\n#ifdef __CINT__\n#pragma link off all globals;\n#pragma link off all classes;\n#pragma link off all functions;\n#pragma link C++ nestedclasses;\n#pragma link C++ nestedtypedefs;\n#pragma link C++ class %(declaration)s;\n#pragma link C++ class %(declaration)s::*;\n#ifdef HAS_ITERATOR\n#pragma link C++ operators %(declaration)s::iterator;\n#pragma link C++ operators %(declaration)s::const_iterator;\n#pragma link C++ operators %(declaration)s::reverse_iterator;\n#pragma link C++ operators %(declaration)s::const_reverse_iterator;\n#endif\n#endif\n\'\'\'\n\nNEW_DICTS = False\nLOOKUP_TABLE_NAME = \'lookup\'\n\n# Initialized in initialize()\nLOADED_DICTS = {}\n\nDICTS_PATH = os.path.join(userdata.BINARY_PATH, \'dicts\')\nif not os.path.exists(DICTS_PATH):\n    # avoid race condition by ignoring OSError if path exists by the time we\n    # try to create it. See https://github.com/rootpy/rootpy/issues/328\n    mkdir_p(DICTS_PATH)\n\ninclude_list = os.path.join(userdata.BINARY_PATH, \'include_paths.list\')\nlog.debug(\'Using {0} to get additional include paths\'.format(include_list))\nif os.path.exists(include_list):\n    with open(include_list) as inc_list:\n        for line in inc_list:\n            line = line.strip()\n            log.debug(\'adding {0} to the include paths\'.format(line))\n            ROOT.gInterpreter.AddIncludePath(line)\n\n@extra_initialization\ndef initialize():\n    global DICTS_PATH\n    # Used insetad of AddDynamicPath for ordering\n    path = "":"".join([DICTS_PATH, ROOT.gSystem.GetDynamicPath()])\n    ROOT.gSystem.SetDynamicPath(path)\n    ROOT.gSystem.AddLinkedLibs(""-Wl,-rpath,{0}"".format(DICTS_PATH))\n\n\nclass CPPType(CPPGrammar):\n    """"""\n    Grammar and representation of a C++ template type. Can handle arbitrary\n    nesting and namespaces.\n    """"""\n    def __init__(self, parse_result):\n        self.parse_result = parse_result\n        self.prefix = parse_result.type_prefix\n        self.name = \' \'.join(parse_result.type_name)\n        self.params = parse_result.template_params\n        self.member = parse_result.template_member\n        self.suffix = parse_result.type_suffix\n\n    def __repr__(self):\n        return self.parse_result.dump()\n\n    @classmethod\n    def make(cls, string, location, tokens):\n        return cls(tokens)\n\n    @property\n    def is_template(self):\n        """"""\n        Is this a template type? (Does it have template parameters?)\n        """"""\n        return bool(self.params)\n\n    def ensure_built(self, headers=None):\n        """"""\n        Make sure that a dictionary exists for this type.\n        """"""\n        if not self.params:\n            return\n        else:\n            for child in self.params:\n                child.ensure_built(headers=headers)\n        if headers is None:\n            headers = self.guess_headers\n        generate(str(self), headers,\n                 has_iterators=self.name in HAS_ITERATORS)\n\n    @property\n    def guess_headers(self):\n        """"""\n        Attempt to guess what headers may be required in order to use this\n        type. Returns `guess_headers` of all children recursively.\n\n        * If the typename is in the :const:`KNOWN_TYPES` dictionary, use the\n            header specified there\n        * If it\'s an STL type, include <{type}>\n        * If it exists in the ROOT namespace and begins with T,\n          include <{type}.h>\n        """"""\n        name = self.name.replace(""*"", """")\n        headers = []\n        if name in KNOWN_TYPES:\n            headers.append(KNOWN_TYPES[name])\n        elif name in STL:\n            headers.append(\'<{0}>\'.format(name))\n        elif hasattr(ROOT, name) and name.startswith(""T""):\n            headers.append(\'<{0}.h>\'.format(name))\n        elif \'::\' in name:\n            headers.append(\'<{0}.h>\'.format(name.replace(\'::\', \'/\')))\n        elif name == \'allocator\':\n            headers.append(\'<memory>\')\n        else:\n            try:\n                # is this just a basic type?\n                CPPGrammar.BASIC_TYPE.parseString(name, parseAll=True)\n            except ParseException as e:\n                # nope... I don\'t know what it is\n                log.warning(\n                    ""unable to guess headers required for {0}"".format(name))\n        if self.params:\n            for child in self.params:\n                headers.extend(child.guess_headers)\n        # remove duplicates\n        return list(set(headers))\n\n    @property\n    def cls(self):\n        """"""\n        Return the class definition for this type\n        """"""\n        # TODO: register the resulting type?\n        return SmartTemplate(self.name)("", "".join(map(str, self.params)))\n\n    @classmethod\n    def try_parse(cls, string):\n        """"""\n        Try to parse ``string`` as a C++ type, returning :const:`None` on\n        failure.\n        """"""\n        try:\n            with log.ignore(""^Failed to parse.*$""):\n                return cls.from_string(string)\n        except ParseException:\n            return None\n\n    @classmethod\n    def from_string(cls, string):\n        """"""\n        Parse ``string`` into a CPPType instance\n        """"""\n        cls.TYPE.setParseAction(cls.make)\n        try:\n            return cls.TYPE.parseString(string, parseAll=True)[0]\n        except ParseException:\n            log.error(""Failed to parse \'{0}\'"".format(string))\n            raise\n\n    def __str__(self):\n        """"""\n        Returns the C++ code representation of this type\n        """"""\n        prefix = \' \'.join(self.prefix)\n        if prefix:\n            prefix += \' \'\n        name = self.name\n        args = [str(p) for p in self.params] if self.params else []\n        templatize = \'<{0} >\' if args and args[-1].endswith(\'>\') else \'<{0}>\'\n        args = \'\' if not self.params else templatize.format(\', \'.join(args))\n        member = (\'::\' + self.member[0]) if self.member else \'\'\n        suffix = \' \'.join(self.suffix)\n        return ""{0}{1}{2}{3}{4}"".format(prefix, name, args, member, suffix)\n\n\ndef make_string(obj):\n    """"""\n    If ``obj`` is a string, return that, otherwise attempt to figure out the\n    name of a type.\n    """"""\n    if inspect.isclass(obj):\n        if issubclass(obj, Object):\n            return obj._ROOT.__name__\n        if issubclass(obj, string_types):\n            return \'string\'\n        return obj.__name__\n    if not isinstance(obj, string_types):\n        raise TypeError(""expected string or class"")\n    return obj\n\n\ndef generate(declaration, headers=None, has_iterators=False):\n    """"""Compile and load the reflection dictionary for a type.\n\n    If the requested dictionary has already been cached, then load that instead.\n\n    Parameters\n    ----------\n    declaration : str\n        A type declaration (for example ""vector<int>"")\n    headers : str or list of str\n        A header file or list of header files required to compile the dictionary\n        for this type.\n    has_iterators : bool\n        If True, then include iterators in the dictionary generation.\n    """"""\n    global NEW_DICTS\n    # FIXME: _rootpy_dictionary_already_exists returns false positives\n    # if a third-party module provides ""incomplete"" dictionaries.\n    #if compiled._rootpy_dictionary_already_exists(declaration):\n    #    log.debug(""generate({0}) => already available"".format(declaration))\n    #    return\n    log.debug(""requesting dictionary for {0}"".format(declaration))\n    if headers:\n        if isinstance(headers, string_types):\n            headers = sorted(headers.split(\';\'))\n        log.debug(""using the headers {0}"".format(\', \'.join(headers)))\n        unique_name = \';\'.join([declaration] + headers)\n    else:\n        unique_name = declaration\n    unique_name = unique_name.replace(\' \', \'\')\n\n    # If the library is already loaded, do nothing\n    if unique_name in LOADED_DICTS:\n        log.debug(""dictionary for {0} is already loaded"".format(declaration))\n        return\n\n    if sys.version_info[0] < 3:\n        libname = hashlib.sha512(unique_name).hexdigest()[:16]\n    else:\n        libname = hashlib.sha512(unique_name.encode(\'utf-8\')).hexdigest()[:16]\n    libnameso = libname + "".so""\n\n    if ROOT.gROOT.GetVersionInt() < 53403:\n        # check for this class in the global TClass list and remove it\n        # fixes infinite recursion in ROOT < 5.34.03\n        # (exact ROOT versions where this is required is unknown)\n        cls = ROOT.gROOT.GetClass(declaration)\n        if cls and not cls.IsLoaded():\n            log.debug(""removing {0} from gROOT.GetListOfClasses()"".format(\n                declaration))\n            ROOT.gROOT.GetListOfClasses().Remove(cls)\n\n    # If a .so already exists for this class, use it.\n    if exists(pjoin(DICTS_PATH, libnameso)):\n        log.debug(""loading previously generated dictionary for {0}""\n                    .format(declaration))\n        if (ROOT.gInterpreter.Load(pjoin(DICTS_PATH, libnameso))\n                not in (0, 1)):\n            raise RuntimeError(\n                ""failed to load the library for \'{0}\' @ {1}"".format(\n                    declaration, libname))\n        LOADED_DICTS[unique_name] = None\n        return\n\n    with lock(pjoin(DICTS_PATH, ""lock""), poll_interval=5, max_age=60):\n        # This dict was not previously generated so we must create it now\n        log.info(""generating dictionary for {0} ..."".format(declaration))\n        includes = \'\'\n        if headers is not None:\n            for header in headers:\n                if re.match(\'^<.+>$\', header):\n                    includes += \'#include {0}\\n\'.format(header)\n                else:\n                    includes += \'#include ""{0}""\\n\'.format(header)\n        source = LINKDEF % locals()\n        sourcepath = os.path.join(DICTS_PATH, \'{0}.C\'.format(libname))\n        log.debug(""source path: {0}"".format(sourcepath))\n        with open(sourcepath, \'w\') as sourcefile:\n            sourcefile.write(source)\n        log.debug(""include path: {0}"".format(\n            ROOT.gSystem.GetIncludePath()))\n        if (ROOT.gSystem.CompileMacro(\n                sourcepath, \'k-\', libname, DICTS_PATH) != 1):\n            raise RuntimeError(\n                ""failed to compile the library for \'{0}\'"".format(\n                    sourcepath))\n\n    LOADED_DICTS[unique_name] = None\n    NEW_DICTS = True\n\n\nTemplate = QROOT.Template\n\n\nclass SmartTemplate(Template):\n    """"""\n    Behaves like ROOT\'s Template class, except it will build dictionaries on\n    demand.\n    """"""\n    def __call__(self, *params, **kwargs):\n        """"""\n        Instantiate the template represented by ``self`` with the template\n        arguments specified by ``params``.\n        """"""\n        headers = kwargs.pop(\'headers\', None)\n        params = "", "".join(make_string(p) for p in params)\n        typ = self.__name__\n        if params:\n            typ = \'{0}<{1}>\'.format(typ, params)\n        cpptype = CPPType.from_string(typ)\n        str_name = str(cpptype)\n        # check registry\n        cls = lookup_by_name(str_name)\n        if cls is None:\n            cpptype.ensure_built(headers=headers)\n            cls = Template.__call__(self, params)\n            register(names=str_name, builtin=True)(cls)\n        return cls\n\n\nfrom .utils.module_facade import Facade\n\n\n@Facade(__name__, expose_internal=False)\nclass STLWrapper(object):\n    # Base types\n    for t in STL:\n        locals()[t] = SmartTemplate(t)\n    del t\n    string = QROOT.string\n    CPPType = CPPType\n    generate = staticmethod(generate)\n'"
rootpy/userdata.py,0,"b'""""""\nThis module handles creation of the user-data area\n""""""\nfrom __future__ import absolute_import\n\nimport os\nimport tempfile\nimport atexit\nfrom os.path import expanduser, expandvars, exists, isdir, join as pjoin\nfrom platform import machine\n\nfrom . import log; log = log[__name__]\nfrom . import QROOT, IN_NOSETESTS\nfrom .utils.path import mkdir_p\nfrom .defaults import extra_initialization\n\n__all__ = [\n    \'DATA_ROOT\',\n    \'CONFIG_ROOT\',\n    \'BINARY_PATH\',\n    \'ARCH\',\n]\n\nif ""XDG_CONFIG_HOME"" not in os.environ:\n    os.environ[""XDG_CONFIG_HOME""] = expanduser(\'~/.config\')\nif ""XDG_CACHE_HOME"" not in os.environ:\n    os.environ[""XDG_CACHE_HOME""] = expanduser(\'~/.cache\')\n\n\ndef ensure_directory(variable, default):\n    path = os.getenv(variable)\n    if path is None:\n        path = expandvars(default)\n    else:\n        path = expandvars(expanduser(path))\n    # check if expanduser failed:\n    if path.startswith(\'~\'):\n        path = None\n    elif not exists(path):\n        mkdir_p(path)\n    elif not isdir(path):\n        # A file at path already exists\n        path = None\n    return path\n\n\nDATA_ROOT = CONFIG_ROOT = None\nGRID_MODE = os.getenv(\'ROOTPY_GRIDMODE\') in (\'1\', \'true\')\n\nif (os.getenv(\'DEBUG\', None) or not (GRID_MODE or IN_NOSETESTS)):\n    DATA_ROOT = ensure_directory(\n        \'ROOTPY_DATA\', \'${XDG_CACHE_HOME}/rootpy\')\n    CONFIG_ROOT = ensure_directory(\n        \'ROOTPY_CONFIG\', \'${XDG_CONFIG_HOME}/rootpy\')\n\nif DATA_ROOT is None:\n    log.info(""Placing user data in /tmp."")\n    log.warning(\n        ""Make sure \'~/.cache/rootpy\' or $ROOTPY_DATA is a writable ""\n        ""directory so that it isn\'t necessary to recreate all user ""\n        ""data each time"")\n\n    DATA_ROOT = tempfile.mkdtemp()\n\n    @atexit.register\n    def __cleanup():\n        import shutil\n        shutil.rmtree(DATA_ROOT)\n\nBINARY_PATH = None\n\nARCH = ""{0}-{1}"".format(machine(), QROOT.gROOT.GetVersionInt())\nif BINARY_PATH is None:\n    BINARY_PATH = pjoin(DATA_ROOT, ARCH)\n\n\n@extra_initialization\ndef show_binary_path():\n    log.debug(""Using binary path: {0}"".format(BINARY_PATH))\n'"
rootpy/vector.py,0,"b'from __future__ import absolute_import\n\nimport ROOT\n\nimport numbers\nfrom copy import copy\n\nfrom . import QROOT\nfrom .base import Object\nfrom .decorators import snake_case_methods\n\n__all__ = [\n    \'Vector2\',\n    \'Vector3\',\n    \'LorentzVector\',\n    \'Rotation\',\n    \'LorentzRotation\',\n]\n\n\nclass _arithmetic_mixin:\n\n    def __mul__(self, other):\n        try:\n            prod = self.__class__.__bases__[-1].__mul__(self, other)\n            if isinstance(prod, self.__class__.__bases__[-1]):\n                prod.__class__ = self.__class__\n        except TypeError:\n            raise TypeError(\n                ""unsupported operand type(s) for *: \'{0}\' and \'{1}\'"".format(\n                    self.__class__.__name__, other.__class__.__name__))\n        return prod\n\n    def __imul__(self, other):\n        if isinstance(other, self.__class__):\n            raise TypeError(""Attemping to set vector to scalar quantity"")\n        try:\n            prod = self * other\n        except TypeError:\n            raise TypeError(\n                ""unsupported operand type(s) for *: \'{0}\' and \'{1}\'"".format(\n                    self.__class__.__name__, other.__class__.__name__))\n        self = prod\n        return self\n\n    def __rmul__(self, other):\n        try:\n            return self * other\n        except TypeError:\n            raise TypeError(\n                ""unsupported operand type(s) for *: \'{0}\' and \'{1}\'"".format(\n                    other.__class__.__name__, self.__class__.__name__))\n\n    def __add__(self, other):\n        if other == 0:\n            return copy(self)\n        try:\n            clone = self.__class__.__bases__[-1].__add__(self, other)\n            clone.__class__ = self.__class__\n        except TypeError:\n            raise TypeError(\n                ""unsupported operand type(s) for +: \'{0}\' and \'{1}\'"".format(\n                    self.__class__.__name__, other.__class__.__name__))\n        return clone\n\n    def __radd__(self, other):\n        if other == 0:\n            return copy(self)\n        raise TypeError(\n            ""unsupported operand type(s) for +: \'{0}\' and \'{1}\'"".format(\n                other.__class__.__name__, self.__class__.__name__))\n\n    def __iadd__(self, other):\n        try:\n            _sum = self + other\n        except TypeError:\n            raise TypeError(\n                ""unsupported operand type(s) for +: \'{0}\' and \'{1}\'"".format(\n                    self.__class__.__name__, other.__class__.__name__))\n        self = _sum\n        return self\n\n    def __sub__(self, other):\n        if other == 0:\n            return copy(self)\n        try:\n            clone = self.__class__.__bases__[-1].__sub__(self, other)\n            clone.__class__ = self.__class__\n        except TypeError:\n            raise TypeError(\n                ""unsupported operand type(s) for -: \'{0}\' and \'{1}\'"".format(\n                    self.__class__.__name__, other.__class__.__name__))\n        return clone\n\n    def __rsub__(self, other):\n        if other == 0:\n            return copy(self)\n        raise TypeError(\n                ""unsupported operand type(s) for -: \'{0}\' and \'{1}\'"".format(\n                    other.__class__.__name__, self.__class__.__name__))\n\n    def __isub__(self, other):\n        try:\n            diff = self - other\n        except TypeError:\n            raise TypeError(\n                ""unsupported operand type(s) for -: \'{0}\' and \'{1}\'"".format(\n                    self.__class__.__name__, other.__class__.__name__))\n        self = diff\n        return self\n\n    def __copy__(self):\n        _copy = self.__class__.__bases__[-1](self)\n        _copy.__class__ = self.__class__\n        return _copy\n\n\n@snake_case_methods\nclass Vector2(_arithmetic_mixin, Object, QROOT.TVector2):\n    """"""\n    A subclass of `ROOT.TVector2 <http://root.cern.ch/root/html/TVector2.html>`_.\n\n    Examples\n    --------\n\n    >>> from rootpy.vector import Vector2\n    >>> vect = Vector2(2, 4)\n    >>> vect\n    Vector2(x=2.000000, y=4.000000)\n\n    """"""\n    _ROOT = QROOT.TVector2\n\n    @property\n    def x(self):\n        return self.X()\n\n    @property\n    def y(self):\n        return self.Y()\n\n    def __getitem__(self, i):\n        if i == 0:\n            return self.X()\n        elif i == 1:\n            return self.Y()\n        raise IndexError(""index {0:d} out of bounds"".format(i))\n\n    def __repr__(self):\n        return \'{0}(x={1:f}, y={2:f})\'.format(\n            self.__class__.__name__, self.X(), self.Y())\n\n    def __mul__(self, other):\n        if isinstance(other, self.__class__):\n            prod = self.X() * other.X() + \\\n                   self.Y() * other.Y()\n        elif isinstance(other, numbers.Real):\n            prod = Vector2(other * self.X(), other * self.Y())\n        else:\n            raise TypeError(\n                ""unsupported operand type(s) for *: \'{0}\' and \'{1}\'"".format(\n                    self.__class__.__name__, other.__class__.__name__))\n        return prod\n\n    def __add__(self, other):\n        if isinstance(other, ROOT.TVector2):\n            _sum = Vector3(self.X() + other.X(),\n                           self.Y() + other.Y())\n        else:\n            raise TypeError(\n                ""unsupported operand type(s) for *: \'{0}\' and \'{1}\'"".format(\n                    self.__class__.__name__, other.__class__.__name__))\n        return _sum\n\n\n@snake_case_methods\nclass Vector3(_arithmetic_mixin, Object, QROOT.TVector3):\n    """"""\n    A subclass of `ROOT.TVector3 <http://root.cern.ch/root/html/TVector3.html>`_.\n\n    Examples\n    --------\n\n    >>> from rootpy.vector import Vector3\n    >>> vect = Vector3(1, 2, 3)\n    >>> vect\n    Vector3(x=1.000000, y=2.000000, z=3.000000)\n\n    """"""\n    _ROOT = QROOT.TVector3\n\n    @property\n    def x(self):\n        return self.X()\n\n    @property\n    def y(self):\n        return self.Y()\n\n    @property\n    def z(self):\n        return self.Z()\n\n    def __getitem__(self, i):\n        if i == 0:\n            return self.X()\n        elif i == 1:\n            return self.Y()\n        elif i == 2:\n            return self.Z()\n        raise IndexError(""index {0:d} out of bounds"".format(i))\n\n    def __repr__(self):\n        return \'{0}(x={1:f}, y={2:f}, z={3:f})\'.format(\n            self.__class__.__name__, self.X(), self.Y(), self.Z())\n\n    def Angle(self, other):\n        if isinstance(other, LorentzVector):\n            return other.Angle(self)\n        return ROOT.TVector3.Angle(self, other)\n\n    def __mul__(self, other):\n        if isinstance(other, ROOT.TVector3):\n            prod = self.X() * other.X() + \\\n                   self.Y() * other.Y() + \\\n                   self.Z() * other.Z()\n        elif isinstance(other, numbers.Real):\n            prod = Vector3(other * self.X(), other * self.Y(), other * self.Z())\n        else:\n            raise TypeError(\n                ""unsupported operand type(s) for *: \'{0}\' and \'{1}\'"".format(\n                    self.__class__.__name__, other.__class__.__name__))\n        return prod\n\n    def __add__(self, other):\n        if isinstance(other, ROOT.TVector3):\n            _sum = Vector3(self.X() + other.X(),\n                           self.Y() + other.Y(),\n                           self.Z() + other.Z())\n        else:\n            raise TypeError(\n                ""unsupported operand type(s) for +: \'{0}\' and \'{1}\'"".format(\n                    self.__class__.__name__, other.__class__.__name__))\n        return _sum\n\n    def __sub__(self, other):\n        if isinstance(other, ROOT.TVector3):\n            _dif = Vector3(self.X() - other.X(),\n                           self.Y() - other.Y(),\n                           self.Z() - other.Z())\n        else:\n            raise TypeError(\n                ""unsupported operand type(s) for -: \'{0}\' and \'{1}\'"".format(\n                    self.__class__.__name__, other.__class__.__name__))\n        return _dif\n\n\n@snake_case_methods\nclass LorentzVector(_arithmetic_mixin, Object, QROOT.TLorentzVector):\n    """"""\n    A subclass of `ROOT.TLorentzVector <http://root.cern.ch/root/html/TLorentzVector.html>`_.\n\n    Examples\n    --------\n\n    >>> from rootpy.vector import LorentzVector\n    >>> vect = LorentzVector(1, 2, 3, 4)\n    >>> vect\n    LorentzVector(px=1.000000, py=2.000000, pz=3.000000, E=4.000000)\n\n    """"""\n    _ROOT = QROOT.TLorentzVector\n\n    @property\n    def px(self):\n        return self.Px()\n\n    @property\n    def py(self):\n        return self.Py()\n\n    @property\n    def pz(self):\n        return self.Pz()\n\n    @property\n    def e(self):\n        return self.E()\n\n    def __getitem__(self, i):\n        if i == 0:\n            return self.Px()\n        elif i == 1:\n            return self.Py()\n        elif i == 2:\n            return self.Pz()\n        elif i == 3:\n            return self.E()\n        raise IndexError(""index {0:d} out of bounds"".format(i))\n\n    def __repr__(self):\n        return ""{0}(px={1:f}, py={2:f}, pz={3:f}, E={4:f})"".format(\n            self.__class__.__name__,\n            self.Px(), self.Py(), self.Pz(), self.E())\n\n    def Angle(self, other):\n        if isinstance(other, ROOT.TLorentzVector):\n            return ROOT.TLorentzVector.Angle(self, other.Vect())\n        return ROOT.TLorentzVector.Angle(self, other)\n\n    def BoostVector(self):\n        vector = ROOT.TLorentzVector.BoostVector(self)\n        vector.__class__ = Vector3\n        return vector\n\n\n@snake_case_methods\nclass Rotation(_arithmetic_mixin, Object, QROOT.TRotation):\n    """"""\n    A subclass of `ROOT.TRotation <http://root.cern.ch/root/html/TRotation.html>`_.\n    """"""\n    _ROOT = QROOT.TRotation\n\n    def __repr__(self):\n        return (""[[{0:f}, {1:f}, {2:f}],\\n""\n                "" [{3:f}, {4:f}, {5:f}],\\n""\n                "" [{6:f}, {7:f}, {8:f}]]"").format(\n                    self.XX(), self.XY(), self.XZ(),\n                    self.YX(), self.YY(), self.YZ(),\n                    self.ZX(), self.ZY(), self.ZZ())\n\n\n@snake_case_methods\nclass LorentzRotation(_arithmetic_mixin, Object, QROOT.TLorentzRotation):\n    """"""\n    A subclass of `ROOT.TLorentzRotation <http://root.cern.ch/root/html/TLorentzRotation.html>`_.\n    """"""\n    _ROOT = QROOT.TLorentzRotation\n\n    def __repr__(self):\n        return (""[[{0:f},  {1:f},  {2:f},  {3:f}],\\n""\n                "" [{4:f},  {5:f},  {6:f},  {7:f}],\\n""\n                "" [{8:f},  {9:f},  {10:f},  {11:f}],\\n""\n                "" [{12:f},  {13:f},  {14:f},  {15:f}]]"").format(\n                    self.XX(), self.XY(), self.XZ(), self.XT(),\n                    self.YX(), self.YY(), self.YZ(), self.YT(),\n                    self.ZX(), self.ZY(), self.ZZ(), self.ZT(),\n                    self.TX(), self.TY(), self.TZ(), self.TT())\n'"
docs/sphinxext/gen_rst.py,0,"b'""""""\nExample generation for rootpy\n\nGenerate the rst files for the examples by iterating over the python\nexample files.\n\nFiles that generate images should start with \'plot\'\n""""""\nfrom time import time\nimport os\nimport shutil\nimport traceback\nimport glob\nimport sys\nfrom StringIO import StringIO\nimport token\nimport tokenize\n\nimport matplotlib\nmatplotlib.use(\'Agg\')\n\nimport ROOT\nROOT.gROOT.SetBatch(True)\n\n\n###############################################################################\n# A tee object to redict streams to multiple outputs\n\nclass Tee(object):\n\n    def __init__(self, file1, file2):\n        self.file1 = file1\n        self.file2 = file2\n\n    def write(self, data):\n        self.file1.write(data)\n        self.file2.write(data)\n\n    def flush(self):\n        self.file1.flush()\n        self.file2.flush()\n\n###############################################################################\nrst_template = """"""\n\n.. _example_%(short_fname)s:\n\n%(docstring)s\n\n**Python source code:** :download:`%(fname)s <%(fname)s>`\n\n.. literalinclude:: %(fname)s\n    :lines: %(end_row)s-\n    """"""\n\nplot_rst_template = """"""\n\n.. _example_%(short_fname)s:\n\n%(docstring)s\n\n%(image_list)s\n\n%(stdout)s\n\n**Python source code:** :download:`%(fname)s <%(fname)s>`\n\n.. literalinclude:: %(fname)s\n    :lines: %(end_row)s-\n\n**Total running time of the example:** %(time_elapsed) .2f seconds\n    """"""\n\n# The following strings are used when we have several pictures: we use\n# an html div tag that our CSS uses to turn the lists into horizontal\n# lists.\nHLIST_HEADER = """"""\n.. rst-class:: horizontal\n\n""""""\n\nHLIST_IMAGE_TEMPLATE = """"""\n.. image:: images/%s\n   :scale: 50\n""""""\n\nSINGLE_IMAGE = """"""\n.. image:: images/%s\n   :align: center\n""""""\n\n\ndef extract_docstring(filename):\n    """""" Extract a module-level docstring, if any\n    """"""\n    lines = file(filename).readlines()\n    start_row = 0\n    if lines[0].startswith(\'#!\'):\n        lines.pop(0)\n        start_row = 1\n\n    docstring = \'\'\n    first_par = \'\'\n    tokens = tokenize.generate_tokens(iter(lines).next)\n    for tok_type, tok_content, _, (erow, _), _ in tokens:\n        tok_type = token.tok_name[tok_type]\n        if tok_type in (\'NEWLINE\', \'COMMENT\', \'NL\', \'INDENT\', \'DEDENT\'):\n            continue\n        elif tok_type == \'STRING\':\n            docstring = eval(tok_content)\n            # If the docstring is formatted with several paragraphs, extract\n            # the first one:\n            paragraphs = \'\\n\'.join(line.rstrip()\n                              for line in docstring.split(\'\\n\')).split(\'\\n\\n\')\n            if len(paragraphs) > 0:\n                first_par = paragraphs[0]\n        break\n    end_row = erow + 1 + start_row\n    if lines and lines[end_row - 2] == \'print __doc__\\n\':\n        end_row += 1\n    return docstring, first_par, end_row\n\n\ndef generate_example_rst(app):\n    """""" Generate the list of examples, as well as the contents of\n        examples.\n    """"""\n    root_dir = os.path.join(app.builder.srcdir, \'auto_examples\')\n    example_dir = os.path.abspath(app.builder.srcdir + \'/../\' + \'examples\')\n    try:\n        plot_gallery = eval(app.builder.config.plot_gallery)\n    except TypeError:\n        plot_gallery = bool(app.builder.config.plot_gallery)\n    if not os.path.exists(example_dir):\n        os.makedirs(example_dir)\n    if not os.path.exists(root_dir):\n        os.makedirs(root_dir)\n\n    # we create an index.rst with all examples\n    fhindex = file(os.path.join(root_dir, \'index.rst\'), \'w\')\n    #Note: The sidebar button has been removed from the examples page for now\n    #      due to how it messes up the layout. Will be fixed at a later point\n    fhindex.write(""""""\\\n\n.. raw:: html\n\n\n    <style type=""text/css"">\n\n    div#sidebarbutton {\n        display: none;\n    }\n\n    .figure {\n        float: left;\n        margin: 10px;\n        width: auto;\n        height: 200px;\n        width: 180px;\n    }\n\n    .figure img {\n        display: inline;\n        }\n\n    .figure .caption {\n        width: 170px;\n        text-align: center !important;\n    }\n    </style>\n\n.. _examples-index:\n"""""")\n    # Here we don\'t use an os.walk, but we recurse only twice: flat is\n    # better than nested.\n    generate_dir_rst(\'.\', fhindex, example_dir, root_dir, plot_gallery)\n    for dir in sorted(os.listdir(example_dir)):\n        if os.path.isdir(os.path.join(example_dir, dir)):\n            generate_dir_rst(dir, fhindex, example_dir, root_dir, plot_gallery)\n    fhindex.flush()\n\n\ndef generate_dir_rst(dir, fhindex, example_dir, root_dir, plot_gallery):\n    """""" Generate the rst file for an example directory.\n    """"""\n    if not dir == \'.\':\n        target_dir = os.path.join(root_dir, dir)\n        src_dir = os.path.join(example_dir, dir)\n    else:\n        target_dir = root_dir\n        src_dir = example_dir\n    if not os.path.exists(os.path.join(src_dir, \'README.txt\')):\n        print 80 * \'_\'\n        print (\'Example directory %s does not have a README.txt file\'\n                        % src_dir)\n        print \'Skipping this directory\'\n        print 80 * \'_\'\n        return\n    fhindex.write(""""""\n\n\n%s\n\n\n"""""" % file(os.path.join(src_dir, \'README.txt\')).read())\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    def sort_key(a):\n        # put last elements without a plot\n        if not a.startswith(\'plot\') and a.endswith(\'.py\'):\n            return \'zz\' + a\n        return a\n    for fname in sorted(os.listdir(src_dir), key=sort_key):\n        if fname.endswith(\'py\'):\n            generate_file_rst(fname, target_dir, src_dir, plot_gallery)\n            #thumb = os.path.join(dir, \'images\', \'thumb\', fname[:-3] + \'.png\')\n            link_name = os.path.join(dir, fname).replace(os.path.sep, \'_\')\n            #fhindex.write(\'.. figure:: %s\\n\' % thumb)\n            #if link_name.startswith(\'._\'):\n            #    link_name = link_name[2:]\n            #if dir != \'.\':\n            #    fhindex.write(\'   :target: ./%s/%s.html\\n\\n\' % (dir,\n            #                                                   fname[:-3]))\n            #else:\n            #    fhindex.write(\'   :target: ./%s.html\\n\\n\' % link_name[:-3])\n            fhindex.write(""""""\n\n.. toctree::\n\n   %s/%s\n\n"""""" % (dir, fname[:-3]))\n    fhindex.write(""""""\n.. raw:: html\n\n    <div style=""clear: both""></div>\n    """""")  # clear at the end of the section\n\n\ndef generate_file_rst(fname, target_dir, src_dir, plot_gallery):\n    """""" Generate the rst file for a given example.\n    """"""\n    base_image_name = os.path.splitext(fname)[0]\n    image_fname = \'%s_%%s.png\' % base_image_name\n    root_image_fname = \'root_%s_%%s.png\' % base_image_name\n    root_fig_num = 1\n\n    this_template = rst_template\n    last_dir = os.path.split(src_dir)[-1]\n    # to avoid leading . in file names, and wrong names in links\n    if last_dir == \'.\' or last_dir == \'examples\':\n        last_dir = \'\'\n    else:\n        last_dir += \'_\'\n    short_fname = last_dir + fname\n    src_file = os.path.join(src_dir, fname)\n    example_file = os.path.join(target_dir, fname)\n    shutil.copyfile(src_file, example_file)\n\n    # The following is a list containing all the figure names\n    figure_list = []\n\n    image_dir = os.path.join(target_dir, \'images\')\n    thumb_dir = os.path.join(image_dir, \'thumb\')\n    if not os.path.exists(image_dir):\n        os.makedirs(image_dir)\n    if not os.path.exists(thumb_dir):\n        os.makedirs(thumb_dir)\n    image_path = os.path.join(image_dir, image_fname)\n    root_image_path = os.path.join(image_dir, root_image_fname)\n\n    stdout_path = os.path.join(image_dir,\n                               \'stdout_%s.txt\' % base_image_name)\n    time_path = os.path.join(image_dir,\n                               \'time_%s.txt\' % base_image_name)\n    thumb_file = os.path.join(thumb_dir, fname[:-3] + \'.png\')\n    time_elapsed = 0\n    if plot_gallery and fname.startswith(\'plot\'):\n        # generate the plot as png image if file name\n        # starts with plot and if it is more recent than an\n        # existing image.\n        first_image_file = image_path % 1\n        first_root_image_file = root_image_path % 1\n        if os.path.exists(stdout_path):\n            stdout = open(stdout_path).read()\n        else:\n            stdout = \'\'\n        if os.path.exists(time_path):\n            time_elapsed = float(open(time_path).read())\n\n        if (not os.path.exists(first_image_file) or\n            not os.path.exists(first_root_image_file) or\n                os.stat(first_image_file).st_mtime <=\n                                    os.stat(src_file).st_mtime):\n            # We need to execute the code\n            print \'plotting %s\' % fname\n            t0 = time()\n            import matplotlib.pyplot as plt\n            plt.close(\'all\')\n            cwd = os.getcwd()\n            try:\n                # First CD in the original example dir, so that any file\n                # created by the example get created in this directory\n                orig_stdout = sys.stdout\n                os.chdir(os.path.dirname(src_file))\n                my_buffer = StringIO()\n                my_stdout = Tee(sys.stdout, my_buffer)\n                sys.stdout = my_stdout\n                my_globals = {\'pl\': plt}\n                execfile(os.path.basename(src_file), my_globals)\n                time_elapsed = time() - t0\n                sys.stdout = orig_stdout\n                my_stdout = my_buffer.getvalue()\n                if \'__doc__\' in my_globals:\n                    # The __doc__ is often printed in the example, we\n                    # don\'t with to echo it\n                    my_stdout = my_stdout.replace(\n                                            my_globals[\'__doc__\'],\n                                            \'\')\n                my_stdout = my_stdout.strip()\n                if my_stdout:\n                    stdout = \'**Script output**::\\n\\n  %s\\n\\n\' % (\n                        \'\\n  \'.join(my_stdout.split(\'\\n\')))\n                open(stdout_path, \'w\').write(stdout)\n                open(time_path, \'w\').write(\'%f\' % time_elapsed)\n                os.chdir(cwd)\n\n                # In order to save every figure we have two solutions :\n                # * iterate from 1 to infinity and call plt.fignum_exists(n)\n                #   (this requires the figures to be numbered\n                #    incrementally: 1, 2, 3 and not 1, 2, 5)\n                # * iterate over [fig_mngr.num for fig_mngr in\n                #   matplotlib._pylab_helpers.Gcf.get_all_fig_managers()]\n                for fig_num in (fig_mngr.num for fig_mngr in\n                        matplotlib._pylab_helpers.Gcf.get_all_fig_managers()):\n                    # Set the fig_num figure as the current figure as we can\'t\n                    # save a figure that\'s not the current figure.\n                    plt.figure(fig_num)\n                    plt.savefig(image_path % fig_num)\n                    figure_list.append(image_fname % fig_num)\n                for canvas in ROOT.gROOT.GetListOfCanvases():\n                    canvas.SaveAs(root_image_path % root_fig_num)\n                    canvas.Close()\n                    figure_list.append(root_image_fname % root_fig_num)\n                    root_fig_num += 1\n            except:\n                print 80 * \'_\'\n                print \'%s is not compiling:\' % fname\n                traceback.print_exc()\n                print 80 * \'_\'\n            finally:\n                os.chdir(cwd)\n                sys.stdout = orig_stdout\n\n            print "" - time elapsed : %.2g sec"" % time_elapsed\n        else:\n            figure_list = [f[len(image_dir):]\n                            for f in glob.glob(image_path % \'[1-9]\')]\n                            #for f in glob.glob(image_path % \'*\')]\n\n        # generate thumb file\n        this_template = plot_rst_template\n        from matplotlib import image\n        if os.path.exists(first_image_file):\n            image.thumbnail(first_image_file, thumb_file, 0.2)\n        elif os.path.exists(first_root_image_file):\n            image.thumbnail(first_root_image_file, thumb_file, 0.2)\n\n    if not os.path.exists(thumb_file):\n        # create something not to replace the thumbnail\n        shutil.copy(\'images/blank_image.png\', thumb_file)\n\n    docstring, short_desc, end_row = extract_docstring(example_file)\n\n    # Depending on whether we have one or more figures, we\'re using a\n    # horizontal list or a single rst call to \'image\'.\n    if len(figure_list) == 1:\n        figure_name = figure_list[0]\n        image_list = SINGLE_IMAGE % figure_name.lstrip(\'/\')\n    else:\n        image_list = HLIST_HEADER\n        for figure_name in figure_list:\n            image_list += HLIST_IMAGE_TEMPLATE % figure_name.lstrip(\'/\')\n\n    f = open(os.path.join(target_dir, fname[:-2] + \'rst\'), \'w\')\n    f.write(this_template % locals())\n    f.flush()\n\n\ndef setup(app):\n    app.connect(\'builder-inited\', generate_example_rst)\n    app.add_config_value(\'plot_gallery\', True, \'html\')\n\n    # Sphinx hack: sphinx copies generated images to the build directory\n    #  each time the docs are made.  If the desired image name already\n    #  exists, it appends a digit to prevent overwrites.  The problem is,\n    #  the directory is never cleared.  This means that each time you build\n    #  the docs, the number of images in the directory grows.\n    #\n    # This question has been asked on the sphinx development list, but there\n    #  was no response: http://osdir.com/ml/sphinx-dev/2011-02/msg00123.html\n    #\n    # The following is a hack that prevents this behavior by clearing the\n    #  image build directory each time the docs are built.  If sphinx\n    #  changes their layout between versions, this will not work (though\n    #  it should probably not cause a crash).  Tested successfully\n    #  on Sphinx 1.0.7\n    build_image_dir = \'_build/html/_images\'\n    if os.path.exists(build_image_dir):\n        filelist = os.listdir(build_image_dir)\n        for filename in filelist:\n            if filename.endswith(\'png\'):\n                os.remove(os.path.join(build_image_dir, filename))\n'"
docs/sphinxext/ipython_console_highlighting.py,0,"b'""""""reST directive for syntax-highlighting ipython interactive sessions.\n\nXXX - See what improvements can be made based on the new (as of Sept 2009)\n\'pycon\' lexer for the python console.  At the very least it will give better\nhighlighted tracebacks.\n""""""\n\n#-----------------------------------------------------------------------------\n# Needed modules\n\n# Standard library\nimport re\n\n# Third party\nfrom pygments.lexer import Lexer, do_insertions\nfrom pygments.lexers.agile import (PythonConsoleLexer, PythonLexer,\n                                   PythonTracebackLexer)\nfrom pygments.token import Comment, Generic\n\nfrom sphinx import highlighting\n\n#-----------------------------------------------------------------------------\n# Global constants\nline_re = re.compile(\'.*?\\n\')\n\n#-----------------------------------------------------------------------------\n# Code begins - classes and functions\n\nclass IPythonConsoleLexer(Lexer):\n    """"""\n    For IPython console output or doctests, such as:\n\n    .. sourcecode:: ipython\n\n      In [1]: a = \'foo\'\n\n      In [2]: a\n      Out[2]: \'foo\'\n\n      In [3]: print a\n      foo\n\n      In [4]: 1 / 0\n\n    Notes:\n\n      - Tracebacks are not currently supported.\n\n      - It assumes the default IPython prompts, not customized ones.\n    """"""\n\n    name = \'IPython console session\'\n    aliases = [\'ipython\']\n    mimetypes = [\'text/x-ipython-console\']\n    input_prompt = re.compile(""(In \\[[0-9]+\\]: )|(   \\.\\.\\.+:)"")\n    output_prompt = re.compile(""(Out\\[[0-9]+\\]: )|(   \\.\\.\\.+:)"")\n    continue_prompt = re.compile(""   \\.\\.\\.+:"")\n    tb_start = re.compile(""\\-+"")\n\n    def get_tokens_unprocessed(self, text):\n        pylexer = PythonLexer(**self.options)\n        tblexer = PythonTracebackLexer(**self.options)\n\n        curcode = \'\'\n        insertions = []\n        for match in line_re.finditer(text):\n            line = match.group()\n            input_prompt = self.input_prompt.match(line)\n            continue_prompt = self.continue_prompt.match(line.rstrip())\n            output_prompt = self.output_prompt.match(line)\n            if line.startswith(""#""):\n                insertions.append((len(curcode),\n                                   [(0, Comment, line)]))\n            elif input_prompt is not None:\n                insertions.append((len(curcode),\n                                   [(0, Generic.Prompt, input_prompt.group())]))\n                curcode += line[input_prompt.end():]\n            elif continue_prompt is not None:\n                insertions.append((len(curcode),\n                                   [(0, Generic.Prompt, continue_prompt.group())]))\n                curcode += line[continue_prompt.end():]\n            elif output_prompt is not None:\n                # Use the \'error\' token for output.  We should probably make\n                # our own token, but error is typicaly in a bright color like\n                # red, so it works fine for our output prompts.\n                insertions.append((len(curcode),\n                                   [(0, Generic.Error, output_prompt.group())]))\n                curcode += line[output_prompt.end():]\n            else:\n                if curcode:\n                    for item in do_insertions(insertions,\n                                              pylexer.get_tokens_unprocessed(curcode)):\n                        yield item\n                        curcode = \'\'\n                        insertions = []\n                yield match.start(), Generic.Output, line\n        if curcode:\n            for item in do_insertions(insertions,\n                                      pylexer.get_tokens_unprocessed(curcode)):\n                yield item\n\n\ndef setup(app):\n    """"""Setup as a sphinx extension.""""""\n\n    # This is only a lexer, so adding it below to pygments appears sufficient.\n    # But if somebody knows that the right API usage should be to do that via\n    # sphinx, by all means fix it here.  At least having this setup.py\n    # suppresses the sphinx warning we\'d get without it.\n    pass\n\n#-----------------------------------------------------------------------------\n# Register the extension as a valid pygments lexer\nhighlighting.lexers[\'ipython\'] = IPythonConsoleLexer()\n'"
docs/sphinxext/ipython_directive.py,3,"b'# -*- coding: utf-8 -*-\n""""""Sphinx directive to support embedded IPython code.\n\nThis directive allows pasting of entire interactive IPython sessions, prompts\nand all, and their code will actually get re-executed at doc build time, with\nall prompts renumbered sequentially. It also allows you to input code as a pure\npython input by giving the argument python to the directive. The output looks\nlike an interactive ipython section.\n\nTo enable this directive, simply list it in your Sphinx ``conf.py`` file\n(making sure the directory where you placed it is visible to sphinx, as is\nneeded for all Sphinx directives).\n\nBy default this directive assumes that your prompts are unchanged IPython ones,\nbut this can be customized. The configurable options that can be placed in\nconf.py are\n\nipython_savefig_dir:\n    The directory in which to save the figures. This is relative to the\n    Sphinx source directory. The default is `html_static_path`.\nipython_rgxin:\n    The compiled regular expression to denote the start of IPython input\n    lines. The default is re.compile(\'In \\[(\\d+)\\]:\\s?(.*)\\s*\'). You\n    shouldn\'t need to change this.\nipython_rgxout:\n    The compiled regular expression to denote the start of IPython output\n    lines. The default is re.compile(\'Out\\[(\\d+)\\]:\\s?(.*)\\s*\'). You\n    shouldn\'t need to change this.\nipython_promptin:\n    The string to represent the IPython input prompt in the generated ReST.\n    The default is \'In [%d]:\'. This expects that the line numbers are used\n    in the prompt.\nipython_promptout:\n\n    The string to represent the IPython prompt in the generated ReST. The\n    default is \'Out [%d]:\'. This expects that the line numbers are used\n    in the prompt.\n\nToDo\n----\n\n- Turn the ad-hoc test() function into a real test suite.\n- Break up ipython-specific functionality from matplotlib stuff into better\n  separated code.\n\nAuthors\n-------\n\n- John D Hunter: orignal author.\n- Fernando Perez: refactoring, documentation, cleanups, port to 0.11.\n- V\xc3\xa1clav\xc5\xa0milauer <eudoxos-AT-arcig.cz>: Prompt generalizations.\n- Skipper Seabold, refactoring, cleanups, pure python addition\n""""""\n\n#-----------------------------------------------------------------------------\n# Imports\n#-----------------------------------------------------------------------------\n\n# Stdlib\nimport cStringIO\nimport os\nimport re\nimport sys\nimport tempfile\nimport ast\n\n# To keep compatibility with various python versions\ntry:\n    from hashlib import md5\nexcept ImportError:\n    from md5 import md5\n\n# Third-party\nimport matplotlib\nimport sphinx\nfrom docutils.parsers.rst import directives\nfrom docutils import nodes\nfrom docutils.parsers.rst import Directive\n\nmatplotlib.use(\'Agg\')\n\n# Our own\nfrom IPython import Config, InteractiveShell\nfrom IPython.core.profiledir import ProfileDir\nfrom IPython.utils import io\n\n#-----------------------------------------------------------------------------\n# Globals\n#-----------------------------------------------------------------------------\n# for tokenizing blocks\nCOMMENT, INPUT, OUTPUT =  range(3)\n\n#-----------------------------------------------------------------------------\n# Functions and class declarations\n#-----------------------------------------------------------------------------\ndef block_parser(part, rgxin, rgxout, fmtin, fmtout):\n    """"""\n    part is a string of ipython text, comprised of at most one\n    input, one ouput, comments, and blank lines.  The block parser\n    parses the text into a list of::\n\n      blocks = [ (TOKEN0, data0), (TOKEN1, data1), ...]\n\n    where TOKEN is one of [COMMENT | INPUT | OUTPUT ] and\n    data is, depending on the type of token::\n\n      COMMENT : the comment string\n\n      INPUT: the (DECORATOR, INPUT_LINE, REST) where\n         DECORATOR: the input decorator (or None)\n         INPUT_LINE: the input as string (possibly multi-line)\n         REST : any stdout generated by the input line (not OUTPUT)\n\n\n      OUTPUT: the output string, possibly multi-line\n    """"""\n\n    block = []\n    lines = part.split(\'\\n\')\n    N = len(lines)\n    i = 0\n    decorator = None\n    while 1:\n\n        if i==N:\n            # nothing left to parse -- the last line\n            break\n\n        line = lines[i]\n        i += 1\n        line_stripped = line.strip()\n        if line_stripped.startswith(\'#\'):\n            block.append((COMMENT, line))\n            continue\n\n        if line_stripped.startswith(\'@\'):\n            # we\'re assuming at most one decorator -- may need to\n            # rethink\n            decorator = line_stripped\n            continue\n\n        # does this look like an input line?\n        matchin = rgxin.match(line)\n        if matchin:\n            lineno, inputline = int(matchin.group(1)), matchin.group(2)\n\n            # the ....: continuation string\n            continuation = \'   %s:\'%\'\'.join([\'.\']*(len(str(lineno))+2))\n            Nc = len(continuation)\n            # input lines can continue on for more than one line, if\n            # we have a \'\\\' line continuation char or a function call\n            # echo line \'print\'.  The input line can only be\n            # terminated by the end of the block or an output line, so\n            # we parse out the rest of the input line if it is\n            # multiline as well as any echo text\n\n            rest = []\n            while i<N:\n\n                # look ahead; if the next line is blank, or a comment, or\n                # an output line, we\'re done\n\n                nextline = lines[i]\n                matchout = rgxout.match(nextline)\n                #print ""nextline=%s, continuation=%s, starts=%s""%(nextline, continuation, nextline.startswith(continuation))\n                if matchout or nextline.startswith(\'#\'):\n                    break\n                elif nextline.startswith(continuation):\n                    inputline += \'\\n\' + nextline[Nc:]\n                else:\n                    rest.append(nextline)\n                i+= 1\n\n            block.append((INPUT, (decorator, inputline, \'\\n\'.join(rest))))\n            continue\n\n        # if it looks like an output line grab all the text to the end\n        # of the block\n        matchout = rgxout.match(line)\n        if matchout:\n            lineno, output = int(matchout.group(1)), matchout.group(2)\n            if i<N-1:\n                output = \'\\n\'.join([output] + lines[i:])\n\n            block.append((OUTPUT, output))\n            break\n\n    return block\n\nclass EmbeddedSphinxShell(object):\n    """"""An embedded IPython instance to run inside Sphinx""""""\n\n    def __init__(self):\n\n        self.cout = cStringIO.StringIO()\n\n\n        # Create config object for IPython\n        config = Config()\n        config.Global.display_banner = False\n        config.Global.exec_lines = [\'import numpy as np\',\n                                    \'from pylab import *\'\n                                    ]\n        config.InteractiveShell.autocall = False\n        config.InteractiveShell.autoindent = False\n        config.InteractiveShell.colors = \'NoColor\'\n\n        # create a profile so instance history isn\'t saved\n        tmp_profile_dir = tempfile.mkdtemp(prefix=\'profile_\')\n        profname = \'auto_profile_sphinx_build\'\n        pdir = os.path.join(tmp_profile_dir,profname)\n        profile = ProfileDir.create_profile_dir(pdir)\n\n        # Create and initialize ipython, but don\'t start its mainloop\n        IP = InteractiveShell.instance(config=config, profile_dir=profile)\n        # io.stdout redirect must be done *after* instantiating InteractiveShell\n        io.stdout = self.cout\n        io.stderr = self.cout\n\n        # For debugging, so we can see normal output, use this:\n        #from IPython.utils.io import Tee\n        #io.stdout = Tee(self.cout, channel=\'stdout\') # dbg\n        #io.stderr = Tee(self.cout, channel=\'stderr\') # dbg\n\n        # Store a few parts of IPython we\'ll need.\n        self.IP = IP\n        self.user_ns = self.IP.user_ns\n        self.user_global_ns = self.IP.user_global_ns\n\n        self.input = \'\'\n        self.output = \'\'\n\n        self.is_verbatim = False\n        self.is_doctest = False\n        self.is_suppress = False\n\n        # on the first call to the savefig decorator, we\'ll import\n        # pyplot as plt so we can make a call to the plt.gcf().savefig\n        self._pyplot_imported = False\n\n    def clear_cout(self):\n        self.cout.seek(0)\n        self.cout.truncate(0)\n\n    def process_input_line(self, line, store_history=True):\n        """"""process the input, capturing stdout""""""\n        #print ""input=\'%s\'""%self.input\n        stdout = sys.stdout\n        splitter = self.IP.input_splitter\n        try:\n            sys.stdout = self.cout\n            splitter.push(line)\n            more = splitter.push_accepts_more()\n            if not more:\n                source_raw = splitter.source_raw_reset()[1]\n                self.IP.run_cell(source_raw, store_history=store_history)\n        finally:\n            sys.stdout = stdout\n\n    def process_image(self, decorator):\n        """"""\n        # build out an image directive like\n        # .. image:: somefile.png\n        #    :width 4in\n        #\n        # from an input like\n        # savefig somefile.png width=4in\n        """"""\n        savefig_dir = self.savefig_dir\n        source_dir = self.source_dir\n        saveargs = decorator.split(\' \')\n        filename = saveargs[1]\n        # insert relative path to image file in source\n        outfile = os.path.relpath(os.path.join(savefig_dir,filename),\n                    source_dir)\n\n        imagerows = [\'.. image:: %s\'%outfile]\n\n        for kwarg in saveargs[2:]:\n            arg, val = kwarg.split(\'=\')\n            arg = arg.strip()\n            val = val.strip()\n            imagerows.append(\'   :%s: %s\'%(arg, val))\n\n        image_file = os.path.basename(outfile) # only return file name\n        image_directive = \'\\n\'.join(imagerows)\n        return image_file, image_directive\n\n\n    # Callbacks for each type of token\n    def process_input(self, data, input_prompt, lineno):\n        """"""Process data block for INPUT token.""""""\n        decorator, input, rest = data\n        image_file = None\n        image_directive = None\n        #print \'INPUT:\', data  # dbg\n        is_verbatim = decorator==\'@verbatim\' or self.is_verbatim\n        is_doctest = decorator==\'@doctest\' or self.is_doctest\n        is_suppress = decorator==\'@suppress\' or self.is_suppress\n        is_savefig = decorator is not None and \\\n                     decorator.startswith(\'@savefig\')\n\n        input_lines = input.split(\'\\n\')\n        if len(input_lines) > 1:\n            if input_lines[-1] != """":\n                input_lines.append(\'\') # make sure there\'s a blank line\n                                       # so splitter buffer gets reset\n\n        continuation = \'   %s:\'%\'\'.join([\'.\']*(len(str(lineno))+2))\n        Nc = len(continuation)\n\n        if is_savefig:\n            image_file, image_directive = self.process_image(decorator)\n\n        ret = []\n        is_semicolon = False\n\n        for i, line in enumerate(input_lines):\n            if line.endswith(\';\'):\n                is_semicolon = True\n\n            if i==0:\n                # process the first input line\n                if is_verbatim:\n                    self.process_input_line(\'\')\n                    self.IP.execution_count += 1 # increment it anyway\n                else:\n                    # only submit the line in non-verbatim mode\n                    self.process_input_line(line, store_history=True)\n                formatted_line = \'%s %s\'%(input_prompt, line)\n            else:\n                # process a continuation line\n                if not is_verbatim:\n                    self.process_input_line(line, store_history=True)\n\n                formatted_line = \'%s %s\'%(continuation, line)\n\n            if not is_suppress:\n                ret.append(formatted_line)\n\n        if not is_suppress and len(rest.strip()) and is_verbatim:\n            # the ""rest"" is the standard output of the\n            # input, which needs to be added in\n            # verbatim mode\n            ret.append(rest)\n\n        self.cout.seek(0)\n        output = self.cout.read()\n        if not is_suppress and not is_semicolon:\n            ret.append(output)\n        elif is_semicolon: # get spacing right\n            ret.append(\'\')\n\n        self.cout.truncate(0)\n        return (ret, input_lines, output, is_doctest, image_file,\n                    image_directive)\n        #print \'OUTPUT\', output  # dbg\n\n    def process_output(self, data, output_prompt,\n                       input_lines, output, is_doctest, image_file):\n        """"""Process data block for OUTPUT token.""""""\n        if is_doctest:\n            submitted = data.strip()\n            found = output\n            if found is not None:\n                found = found.strip()\n\n                # XXX - fperez: in 0.11, \'output\' never comes with the prompt\n                # in it, just the actual output text.  So I think all this code\n                # can be nuked...\n\n                # the above comment does not appear to be accurate... (minrk)\n\n                ind = found.find(output_prompt)\n                if ind<0:\n                    e=\'output prompt=""%s"" does not match out line=%s\' % \\\n                       (output_prompt, found)\n                    raise RuntimeError(e)\n                found = found[len(output_prompt):].strip()\n\n                if found!=submitted:\n                    e = (\'doctest failure for input_lines=""%s"" with \'\n                         \'found_output=""%s"" and submitted output=""%s""\' %\n                         (input_lines, found, submitted) )\n                    raise RuntimeError(e)\n                #print \'doctest PASSED for input_lines=""%s"" with found_output=""%s"" and submitted output=""%s""\'%(input_lines, found, submitted)\n\n    def process_comment(self, data):\n        """"""Process data fPblock for COMMENT token.""""""\n        if not self.is_suppress:\n            return [data]\n\n    def save_image(self, image_file):\n        """"""\n        Saves the image file to disk.\n        """"""\n        self.ensure_pyplot()\n        command = \'plt.gcf().savefig(""%s"")\'%image_file\n        #print \'SAVEFIG\', command  # dbg\n        self.process_input_line(\'bookmark ipy_thisdir\', store_history=False)\n        self.process_input_line(\'cd -b ipy_savedir\', store_history=False)\n        self.process_input_line(command, store_history=False)\n        self.process_input_line(\'cd -b ipy_thisdir\', store_history=False)\n        self.process_input_line(\'bookmark -d ipy_thisdir\', store_history=False)\n        self.clear_cout()\n\n\n    def process_block(self, block):\n        """"""\n        process block from the block_parser and return a list of processed lines\n        """"""\n        ret = []\n        output = None\n        input_lines = None\n        lineno = self.IP.execution_count\n\n        input_prompt = self.promptin%lineno\n        output_prompt = self.promptout%lineno\n        image_file = None\n        image_directive = None\n\n        for token, data in block:\n            if token==COMMENT:\n                out_data = self.process_comment(data)\n            elif token==INPUT:\n                (out_data, input_lines, output, is_doctest, image_file,\n                    image_directive) = \\\n                          self.process_input(data, input_prompt, lineno)\n            elif token==OUTPUT:\n                out_data = \\\n                    self.process_output(data, output_prompt,\n                                        input_lines, output, is_doctest,\n                                        image_file)\n            if out_data:\n                ret.extend(out_data)\n\n        # save the image files\n        if image_file is not None:\n            self.save_image(image_file)\n\n        return ret, image_directive\n\n    def ensure_pyplot(self):\n        if self._pyplot_imported:\n            return\n        self.process_input_line(\'import matplotlib.pyplot as plt\',\n                                store_history=False)\n\n    def process_pure_python(self, content):\n        """"""\n        content is a list of strings. it is unedited directive conent\n\n        This runs it line by line in the InteractiveShell, prepends\n        prompts as needed capturing stderr and stdout, then returns\n        the content as a list as if it were ipython code\n        """"""\n        output = []\n        savefig = False # keep up with this to clear figure\n        multiline = False # to handle line continuation\n        multiline_start = None\n        fmtin = self.promptin\n\n        ct = 0\n\n        for lineno, line in enumerate(content):\n\n            line_stripped = line.strip()\n            if not len(line):\n                output.append(line)\n                continue\n\n            # handle decorators\n            if line_stripped.startswith(\'@\'):\n                output.extend([line])\n                if \'savefig\' in line:\n                    savefig = True # and need to clear figure\n                continue\n\n            # handle comments\n            if line_stripped.startswith(\'#\'):\n                output.extend([line])\n                continue\n\n            # deal with lines checking for multiline\n            continuation  = u\'   %s:\'% \'\'.join([\'.\']*(len(str(ct))+2))\n            if not multiline:\n                modified = u""%s %s"" % (fmtin % ct, line_stripped)\n                output.append(modified)\n                ct += 1\n                try:\n                    ast.parse(line_stripped)\n                    output.append(u\'\')\n                except Exception: # on a multiline\n                    multiline = True\n                    multiline_start = lineno\n            else: # still on a multiline\n                modified = u\'%s %s\' % (continuation, line)\n                output.append(modified)\n                try:\n                    mod = ast.parse(\n                            \'\\n\'.join(content[multiline_start:lineno+1]))\n                    if isinstance(mod.body[0], ast.FunctionDef):\n                        # check to see if we have the whole function\n                        for element in mod.body[0].body:\n                            if isinstance(element, ast.Return):\n                                multiline = False\n                    else:\n                        output.append(u\'\')\n                        multiline = False\n                except Exception:\n                    pass\n\n            if savefig: # clear figure if plotted\n                self.ensure_pyplot()\n                self.process_input_line(\'plt.clf()\', store_history=False)\n                self.clear_cout()\n                savefig = False\n\n        return output\n\nclass IpythonDirective(Directive):\n\n    has_content = True\n    required_arguments = 0\n    optional_arguments = 4 # python, suppress, verbatim, doctest\n    final_argumuent_whitespace = True\n    option_spec = { \'python\': directives.unchanged,\n                    \'suppress\' : directives.flag,\n                    \'verbatim\' : directives.flag,\n                    \'doctest\' : directives.flag,\n                  }\n\n    shell = EmbeddedSphinxShell()\n\n    def get_config_options(self):\n        # contains sphinx configuration variables\n        config = self.state.document.settings.env.config\n\n        # get config variables to set figure output directory\n        confdir = self.state.document.settings.env.app.confdir\n        savefig_dir = config.ipython_savefig_dir\n        source_dir = os.path.dirname(self.state.document.current_source)\n        if savefig_dir is None:\n            savefig_dir = config.html_static_path\n        if isinstance(savefig_dir, list):\n            savefig_dir = savefig_dir[0] # safe to assume only one path?\n        savefig_dir = os.path.join(confdir, savefig_dir)\n\n        # get regex and prompt stuff\n        rgxin     = config.ipython_rgxin\n        rgxout    = config.ipython_rgxout\n        promptin  = config.ipython_promptin\n        promptout = config.ipython_promptout\n\n        return savefig_dir, source_dir, rgxin, rgxout, promptin, promptout\n\n    def setup(self):\n        # reset the execution count if we haven\'t processed this doc\n        #NOTE: this may be borked if there are multiple seen_doc tmp files\n        #check time stamp?\n        seen_docs = [i for i in os.listdir(tempfile.tempdir)\n            if i.startswith(\'seen_doc\')]\n        if seen_docs:\n            fname = os.path.join(tempfile.tempdir, seen_docs[0])\n            docs = open(fname).read().split(\'\\n\')\n            if not self.state.document.current_source in docs:\n                self.shell.IP.history_manager.reset()\n                self.shell.IP.execution_count = 1\n        else: # haven\'t processed any docs yet\n            docs = []\n\n\n        # get config values\n        (savefig_dir, source_dir, rgxin,\n                rgxout, promptin, promptout) = self.get_config_options()\n\n        # and attach to shell so we don\'t have to pass them around\n        self.shell.rgxin = rgxin\n        self.shell.rgxout = rgxout\n        self.shell.promptin = promptin\n        self.shell.promptout = promptout\n        self.shell.savefig_dir = savefig_dir\n        self.shell.source_dir = source_dir\n\n        # setup bookmark for saving figures directory\n\n        self.shell.process_input_line(\'bookmark ipy_savedir %s\'%savefig_dir,\n                                      store_history=False)\n        self.shell.clear_cout()\n\n        # write the filename to a tempfile because it\'s been ""seen"" now\n        if not self.state.document.current_source in docs:\n            fd, fname = tempfile.mkstemp(prefix=""seen_doc"", text=True)\n            fout = open(fname, \'a\')\n            fout.write(self.state.document.current_source+\'\\n\')\n            fout.close()\n\n        return rgxin, rgxout, promptin, promptout\n\n\n    def teardown(self):\n        # delete last bookmark\n        self.shell.process_input_line(\'bookmark -d ipy_savedir\',\n                                      store_history=False)\n        self.shell.clear_cout()\n\n    def run(self):\n        debug = False\n\n        #TODO, any reason block_parser can\'t be a method of embeddable shell\n        # then we wouldn\'t have to carry these around\n        rgxin, rgxout, promptin, promptout = self.setup()\n\n        options = self.options\n        self.shell.is_suppress = \'suppress\' in options\n        self.shell.is_doctest = \'doctest\' in options\n        self.shell.is_verbatim = \'verbatim\' in options\n\n\n        # handle pure python code\n        if \'python\' in self.arguments:\n            content = self.content\n            self.content = self.shell.process_pure_python(content)\n\n        parts = \'\\n\'.join(self.content).split(\'\\n\\n\')\n\n        lines = [\'.. code-block:: ipython\',\'\']\n        figures = []\n\n        for part in parts:\n\n            block = block_parser(part, rgxin, rgxout, promptin, promptout)\n\n            if len(block):\n                rows, figure = self.shell.process_block(block)\n                for row in rows:\n                    lines.extend([\'   %s\'%line for line in row.split(\'\\n\')])\n\n                if figure is not None:\n                    figures.append(figure)\n\n        #text = \'\\n\'.join(lines)\n        #figs = \'\\n\'.join(figures)\n\n        for figure in figures:\n            lines.append(\'\')\n            lines.extend(figure.split(\'\\n\'))\n            lines.append(\'\')\n\n        #print lines\n        if len(lines)>2:\n            if debug:\n                print \'\\n\'.join(lines)\n            else: #NOTE: this raises some errors, what\'s it for?\n                #print \'INSERTING %d lines\'%len(lines)\n                self.state_machine.insert_input(\n                    lines, self.state_machine.input_lines.source(0))\n\n        text = \'\\n\'.join(lines)\n        txtnode = nodes.literal_block(text, text)\n        txtnode[\'language\'] = \'ipython\'\n        #imgnode = nodes.image(figs)\n\n        # cleanup\n        self.teardown()\n\n        return []#, imgnode]\n\n# Enable as a proper Sphinx directive\ndef setup(app):\n    setup.app = app\n\n    app.add_directive(\'ipython\', IpythonDirective)\n    app.add_config_value(\'ipython_savefig_dir\', None, True)\n    app.add_config_value(\'ipython_rgxin\',\n                         re.compile(\'In \\[(\\d+)\\]:\\s?(.*)\\s*\'), True)\n    app.add_config_value(\'ipython_rgxout\',\n                         re.compile(\'Out\\[(\\d+)\\]:\\s?(.*)\\s*\'), True)\n    app.add_config_value(\'ipython_promptin\', \'In [%d]:\', True)\n    app.add_config_value(\'ipython_promptout\', \'Out[%d]:\', True)\n\n\n# Simple smoke test, needs to be converted to a proper automatic test.\ndef test():\n\n    examples = [\n        r""""""\nIn [9]: pwd\nOut[9]: \'/home/jdhunter/py4science/book\'\n\nIn [10]: cd bookdata/\n/home/jdhunter/py4science/book/bookdata\n\nIn [2]: from pylab import *\n\nIn [2]: ion()\n\nIn [3]: im = imread(\'stinkbug.png\')\n\n@savefig mystinkbug.png width=4in\nIn [4]: imshow(im)\nOut[4]: <matplotlib.image.AxesImage object at 0x39ea850>\n\n"""""",\n        r""""""\n\nIn [1]: x = \'hello world\'\n\n# string methods can be\n# used to alter the string\n@doctest\nIn [2]: x.upper()\nOut[2]: \'HELLO WORLD\'\n\n@verbatim\nIn [3]: x.st<TAB>\nx.startswith  x.strip\n"""""",\n    r""""""\n\nIn [130]: url = \'http://ichart.finance.yahoo.com/table.csv?s=CROX\\\n   .....: &d=9&e=22&f=2009&g=d&a=1&br=8&c=2006&ignore=.csv\'\n\nIn [131]: print url.split(\'&\')\n[\'http://ichart.finance.yahoo.com/table.csv?s=CROX\', \'d=9\', \'e=22\', \'f=2009\', \'g=d\', \'a=1\', \'b=8\', \'c=2006\', \'ignore=.csv\']\n\nIn [60]: import urllib\n\n"""""",\n    r""""""\\\n\nIn [133]: import numpy.random\n\n@suppress\nIn [134]: numpy.random.seed(2358)\n\n@doctest\nIn [135]: numpy.random.rand(10,2)\nOut[135]:\narray([[ 0.64524308,  0.59943846],\n       [ 0.47102322,  0.8715456 ],\n       [ 0.29370834,  0.74776844],\n       [ 0.99539577,  0.1313423 ],\n       [ 0.16250302,  0.21103583],\n       [ 0.81626524,  0.1312433 ],\n       [ 0.67338089,  0.72302393],\n       [ 0.7566368 ,  0.07033696],\n       [ 0.22591016,  0.77731835],\n       [ 0.0072729 ,  0.34273127]])\n\n"""""",\n\n    r""""""\nIn [106]: print x\njdh\n\nIn [109]: for i in range(10):\n   .....:     print i\n   .....:\n   .....:\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n"""""",\n\n        r""""""\n\nIn [144]: from pylab import *\n\nIn [145]: ion()\n\n# use a semicolon to suppress the output\n@savefig test_hist.png width=4in\nIn [151]: hist(np.random.randn(10000), 100);\n\n\n@savefig test_plot.png width=4in\nIn [151]: plot(np.random.randn(10000), \'o\');\n   """""",\n\n        r""""""\n# use a semicolon to suppress the output\nIn [151]: plt.clf()\n\n@savefig plot_simple.png width=4in\nIn [151]: plot([1,2,3])\n\n@savefig hist_simple.png width=4in\nIn [151]: hist(np.random.randn(10000), 100);\n\n"""""",\n     r""""""\n# update the current fig\nIn [151]: ylabel(\'number\')\n\nIn [152]: title(\'normal distribution\')\n\n\n@savefig hist_with_text.png\nIn [153]: grid(True)\n\n        """""",\n        ]\n    # skip local-file depending first example:\n    examples = examples[1:]\n\n    #ipython_directive.DEBUG = True  # dbg\n    #options = dict(suppress=True)  # dbg\n    options = dict()\n    for example in examples:\n        content = example.split(\'\\n\')\n        ipython_directive(\'debug\', arguments=None, options=options,\n                          content=content, lineno=0,\n                          content_offset=None, block_text=None,\n                          state=None, state_machine=None,\n                          )\n\n# Run test suite as a script\nif __name__==\'__main__\':\n    if not os.path.isdir(\'_static\'):\n        os.mkdir(\'_static\')\n    test()\n    print \'All OK? Check figures in _static/\'\n'"
examples/io/file.py,0,"b'#!/usr/bin/env python\n""""""\n==============================\nROOT.TFile made easy by rootpy\n==============================\n\nThis example demonstrates how basic file operations are made easier in rootpy.\n""""""\nprint(__doc__)\nimport os\nimport shutil\nfrom rootpy.io import root_open, DoesNotExist\nfrom rootpy.plotting import Hist, Hist2D\nfrom rootpy import testdata\nfrom rootpy import asrootpy\n\nshutil.copyfile(testdata.get_filepath(\'test_file_2.root\'), \'data.root\')\nf = root_open(\'data.root\')\n\nprint(f.a)\nprint(f.a.b)\n\ntry:\n    print(f.a.b.c.d.e.f)\nexcept AttributeError as e:\n    print(e)\n\nfor thing in f.walk():\n    print(thing)\n\nf.close()\n\n# supports with statements\nwith root_open(\'data.root\', \'update\') as f:\n    print(f)\n\n    # write some histograms\n    h1 = Hist(100, 0, 100, name=\'h1\', type=\'I\')\n    # variable bin widths\n    h2 = Hist2D((0,3,5,20,50), (10,20,30,40,1000), name=\'h2\')\n\n    h1.Write()\n    h2.Write()\n# file is automatically closed after with statement\n\n# retrieve the histograms previously saved\nwith root_open(\'data.root\') as f:\n\n    h1 = f.h1\n    # or h1 = f.Get(\'h1\')\n    h2 = f.h2\n    # or h2 = f.Get(\'h2\')\n\n    # ROOT classes are automatically converted into\n    # rootpy form when retrieved from a ROOT file as\n    # long as their module was previously imported\n    print(h1.__class__.__name__)\n    print(h2.__class__.__name__)\n\n    # you may also do this to convert an object into\n    # rootpy form (again, assuming the relevant module\n    # was previously imported)\n    h1 = asrootpy(h1)\n    # if it is already in rootpy form or if no rootpy form\n    # exists then asrootpy does nothing\n    print(h1.__class__.__name__)\n\nos.unlink(\'data.root\')\n'"
examples/plotting/plot_autobinning.py,6,"b'#!/usr/bin/env python\n""""""\n==================================================\nFill histograms from arrays with automatic binning\n==================================================\n\nThis example demonstrates how to fill a histogram from an array of data\nand to automatically choose a binning with various methods.\n\nThe automatic binning requires numpy/scipy\n""""""\nprint(__doc__)\nfrom rootpy.plotting import histogram, Canvas\nfrom rootpy.interactive import wait\nimport time\n\nimport ROOT\nimport numpy as np\n\nROOT.gStyle.SetOptStat(0)\n\n\nclass Timer(object):\n    def __enter__(self):\n        self.__start = time.time()\n\n    def __exit__(self, type, value, traceback):\n        self.__finish = time.time()\n\n    def duration_in_seconds(self):\n        return self.__finish - self.__start\n\n\ndata0 = ""normal_small"", np.random.normal(0.5, 1, 200)\ndata1 = ""normal"", np.random.normal(0.5, 1, 100000)\ndata2 = ""uniform"", np.random.random(100000)\ndata3 = ""normal+uniform"", np.concatenate((data1[1], 10 * data2[1]))\ndata4 = ""normal+normal"", np.concatenate((data1[1], np.random.normal(2.5, 0.1, 100000)))\n\nif ROOT.gROOT.IsBatch():\n    datas = (data0, data1)\nelse:\n    datas = (data0, data1, data2, data3, data4)\n\nrecipes = (\n    ""manual1"", ""sturges"", ""sturges-doane"", ""scott"", ""sqrt"",\n    ""doane"", ""freedman-diaconis"", ""risk"", ""knuth"")\nobjs = []\ncanvas = Canvas()\ncanvas.Divide(len(recipes), len(datas), 1E-3, 1E-3)\nprint(\'-\' * 57)\nprint(\'\\t\\t{0:<20s}{1:>10s}   {2:<6s}\'.format(\'method\', \'bins\', \'time [s]\'))\nprint(\'-\' * 57)\nfor id, (dataname, d) in enumerate(datas):\n    print(dataname)\n    for ir, r in enumerate(recipes):\n        canvas.cd(id * len(recipes) + ir + 1)\n        timer = Timer()\n        if r == ""manual1"":\n            with timer:\n                bins, h = histogram(d, 50, np.min(d), np.max(d),\n                                    drawstyle=\'hist\')\n        else:\n            with timer:\n                bins, h = histogram(d, binning=r, drawstyle=\'hist\')\n        print(\'\\t\\t{0:<20s}{1:>10d}   {2:<6.2f}\'.format(\n            r, h.GetNbinsX(), timer.duration_in_seconds()))\n        h.Draw()\n        h.GetYaxis().SetRangeUser(0, h.GetMaximum() * 1.2)\n        l = ROOT.TLatex(0.15, 0.8, ""{0}: {1:d}"".format(r, h.GetNbinsX()))\n        l.SetNDC()\n        l.SetTextSize(0.1)\n        l.Draw()\n        canvas.Update()\n\nwait()\n'"
examples/plotting/plot_bin_merging.py,2,"b'#!/usr/bin/env python\n""""""\n=====================\nMerge Histograms Bins\n=====================\n\nrootpy implements an additional histogram bin merging method making it easier\nto merge bins in specified windows of bin indices.\n""""""\nprint(__doc__)\nimport ROOT\nfrom rootpy.interactive import wait\nfrom rootpy.plotting import Canvas, Hist, Hist2D\nfrom rootpy.plotting.style import set_style\nimport numpy as np\nfrom random import randint, choice\nimport time\nimport os\n\nset_style(\'ATLAS\')\nBATCH = ROOT.gROOT.IsBatch()\n\n\ndef random_bin_merge(h):\n    # randomly choose axis\n    if h.GetDimension() > 1:\n        axis = choice([\n            axis for axis in range(h.GetDimension()) if h.nbins(axis) > 1])\n    else:\n        axis = 0\n    # randomly choose starting bin\n    start = randint(1, h.nbins(axis) - 1)\n    end = randint(start + 1, min(start + 5 * h.GetDimension(), h.nbins(axis)))\n    return h.merge_bins([(start, end)], axis=axis)\n\n# create an animation of a 1D histogram\nc1 = Canvas()\nif not BATCH and os.path.isfile(\'binmerge1d.gif\'):\n    os.unlink(\'binmerge1d.gif\')\na = Hist(100, -5, 5)\na.fill_array(np.random.randn(10000))\nwhile a.nbins(0) > 1:\n    a = random_bin_merge(a)\n    a.Draw(\'hist\')\n    if not BATCH:\n        c1.Print(\'binmerge1d.gif+20\')\n        time.sleep(.1)\nif not BATCH:\n    c1.Print(\'binmerge1d.gif++\')\n\n# create an animation of a 2D histogram\nc2 = Canvas()\nif not BATCH and os.path.isfile(\'binmerge2d.gif\'):\n    os.unlink(\'binmerge2d.gif\')\nc2.SetRightMargin(0.1)\nb = Hist2D(100, -5, 5, 100, -5, 5)\nb.fill_array(np.random.randn(10000, 2))\nwhile b.nbins(0) > 1 or b.nbins(1) > 1:\n    b = random_bin_merge(b)\n    b.Draw(\'LEGO20\')\n    if not BATCH:\n        c2.Print(\'binmerge2d.gif+20\')\n        time.sleep(.1)\nif not BATCH:\n    c2.Print(\'binmerge2d.gif++\')\n'"
examples/plotting/plot_hist.py,0,"b'#!/usr/bin/env python\n""""""\n============================\nWorking with ROOT histograms\n============================\n\nThis example demonstrates how to create and work with ROOT histogram in rootpy.\n""""""\nprint(__doc__)\nfrom rootpy.extern.six.moves import range\nfrom rootpy.plotting import Hist, Hist2D, Hist3D, HistStack, Legend, Canvas\nfrom rootpy.interactive import wait\nimport random\n\n# create a simple 1D histogram with 10 constant-width bins between 0 and 1\nh_simple = Hist(10, 0, 1)\nprint(h_simple.name)\n\n# If the name is not specified, a UUID is used so that ROOT never complains\n# about two histograms having the same name.\n# Alternatively you can specify the name (and the title or any other style\n# attributes) in the constructor:\nh_simple = Hist(10, -4, 12, name=\'my hist\', title=\'Some Data\',\n                drawstyle=\'hist\',\n                legendstyle=\'F\',\n                fillstyle=\'/\')\n\n# fill the histogram\nfor i in range(1000):\n    # all ROOT CamelCase methods are aliased by equivalent snake_case methods\n    # so you can call fill() instead of Fill()\n    h_simple.Fill(random.gauss(4, 3))\n\n# easily set visual attributes\nh_simple.linecolor = \'blue\'\nh_simple.fillcolor = \'green\'\nh_simple.fillstyle = \'/\'\n\n# attributes may be accessed in the same way\nprint(h_simple.name)\nprint(h_simple.title)\nprint(h_simple.markersize)\n\n# plot\ncanvas = Canvas(width=700, height=500)\ncanvas.SetLeftMargin(0.15)\ncanvas.SetBottomMargin(0.15)\ncanvas.SetTopMargin(0.10)\ncanvas.SetRightMargin(0.05)\nh_simple.Draw()\n\n# create the legend\nlegend = Legend([h_simple], pad=canvas,\n                header=\'Header\',\n                leftmargin=0.05,\n                rightmargin=0.5)\nlegend.Draw()\n\n# 2D and 3D histograms are handled in the same way\n# the constructor arguments are repetitions of #bins, left bound, right bound.\nh2d = Hist2D(10, 0, 1, 50, -40, 10, name=\'2d hist\')\nh3d = Hist3D(3, -1, 4, 10, -1000, -200, 2, 0, 1, name=\'3d hist\')\n\n# variable-width bins may be created by passing the bin edges directly:\nh1d_variable = Hist([1, 4, 10, 100])\nh2d_variable = Hist2D([2, 4, 7, 100, 200], [-100, -50, 0, 10, 20])\nh3d_variable = Hist3D([1, 3, 10], [20, 50, 100], [-10, -5, 10, 20])\n\n# variable-width and constant-width bins can be mixed:\nh2d_mixed = Hist2D([2, 10, 30], 10, 1, 5)\n\n# wait for you to close all open canvases before exiting\n# wait() will have no effect if ROOT is in batch mode:\n# ROOT.gROOT.SetBatch(True)\nwait()\n'"
examples/plotting/plot_matplotlib_graph.py,3,"b'#!/usr/bin/env python\n""""""\n=====================================\nPlot a ROOT graph with matplotlib\n=====================================\n\nThis example demonstrates how a ROOT graph can be styled with simple\nattributes and displayed via ROOT or matplotlib.\n""""""\nprint(__doc__)\nimport ROOT\nimport numpy as np\nfrom rootpy.plotting import Canvas, Graph\nfrom rootpy.plotting.style import get_style, set_style\nfrom rootpy.interactive import wait\nimport rootpy.plotting.root2matplotlib as rplt\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import AutoMinorLocator, MultipleLocator\n\n# set the random seed\nROOT.gRandom.SetSeed(42)\nnp.random.seed(42)\n\n# points\nx = np.sort(np.random.random(10)) * 3500\ny = np.random.random(10)\n\n# set style for ROOT\nset_style(\'ATLAS\')\n\n# create graph\ngraph = Graph(x.shape[0])\nfor i, (xx, yy) in enumerate(zip(x, y)):\n    graph.SetPoint(i, xx, yy)\n\n# set visual attributes\ngraph.linecolor = \'blue\'\ngraph.markercolor = \'blue\'\ngraph.xaxis.SetTitle(""E_{T} [GeV]"")\ngraph.yaxis.SetTitle(""d#sigma_{jet}/dE_{T,jet} [fb/GeV]"")\ngraph.xaxis.SetRangeUser(0, 3500)\ngraph.yaxis.SetRangeUser(0, 1)\n\n# plot with ROOT\ncanvas = Canvas()\ngraph.Draw(""APL"")\n\nlabel = ROOT.TText(0.4, 0.8, ""ROOT"")\nlabel.SetTextFont(43)\nlabel.SetTextSize(25)\nlabel.SetNDC()\nlabel.Draw()\ncanvas.Modified()\ncanvas.Update()\n\n# plot with matplotlib\n\ndef plot_with_matplotlib():\n    fig, axes = plt.subplots()\n\n    axes.plot(x, y, \'o-\', markeredgewidth=0)\n    axes.set_xlabel(r""$E_T$ [GeV]"",\n                    horizontalalignment=""right"", x=1, labelpad=20)\n    axes.set_ylabel(r""$d\\sigma_{jet}/dE_{T,jet}$ [fb/GeV]"",\n                    horizontalalignment=""right"", y=1, labelpad=32)\n    axes.set_xlim(0, 3500)\n    axes.set_ylim(0, 1)\n\n    return fig, axes\n\n# plot without style\nfig1, axes1 = plot_with_matplotlib()\naxes1.text(0.4, 0.8, \'matplotlib (no style)\',\n           verticalalignment=\'center\', horizontalalignment=\'center\',\n           transform=axes1.transAxes, fontsize=20)\n\n# plot with ATLAS style\nset_style(\'ATLAS\', mpl=True)\nfig2, axes2 = plot_with_matplotlib()\naxes2.text(0.4, 0.8, \'matplotlib\',\n           verticalalignment=\'center\', horizontalalignment=\'center\',\n           transform=axes2.transAxes, fontsize=20)\naxes2.xaxis.set_minor_locator(AutoMinorLocator())\naxes2.yaxis.set_minor_locator(AutoMinorLocator())\n\nif not ROOT.gROOT.IsBatch():\n    plt.show()\n\n# wait for you to close the canvas before exiting\nwait(True)\n'"
examples/plotting/plot_matplotlib_hist.py,3,"b'#!/usr/bin/env python\n""""""\n=====================================\nPlot a ROOT histogram with matplotlib\n=====================================\n\nThis example demonstrates how a ROOT histogram can be styled with simple\nattributes and displayed via ROOT or matplotlib.\n""""""\nprint(__doc__)\nimport ROOT\nimport numpy as np\nfrom rootpy.plotting import Hist, HistStack, Legend, Canvas\nfrom rootpy.plotting.style import get_style, set_style\nfrom rootpy.plotting.utils import draw\nfrom rootpy.interactive import wait\nimport rootpy.plotting.root2matplotlib as rplt\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import AutoMinorLocator, MultipleLocator\n\n# set the style\nstyle = get_style(\'ATLAS\')\nstyle.SetEndErrorSize(3)\nset_style(style)\n\n# set the random seed\nROOT.gRandom.SetSeed(42)\nnp.random.seed(42)\n\n# signal distribution\nsignal = 126 + 10 * np.random.randn(100)\nsignal_obs = 126 + 10 * np.random.randn(100)\n\n# create histograms\nh1 = Hist(30, 40, 200, title=\'Background\', markersize=0, legendstyle=\'F\')\nh2 = h1.Clone(title=\'Signal\')\nh3 = h1.Clone(title=\'Data\', drawstyle=\'E1 X0\', legendstyle=\'LEP\')\nh3.markersize = 1.2\n\n# fill the histograms with our distributions\nh1.FillRandom(\'landau\', 1000)\nmap(h2.Fill, signal)\nh3.FillRandom(\'landau\', 1000)\nmap(h3.Fill, signal_obs)\n\n# set visual attributes\nh1.fillstyle = \'solid\'\nh1.fillcolor = \'green\'\nh1.linecolor = \'green\'\nh1.linewidth = 0\n\nh2.fillstyle = \'solid\'\nh2.fillcolor = \'red\'\nh2.linecolor = \'red\'\nh2.linewidth = 0\n\nstack = HistStack([h1, h2], drawstyle=\'HIST E1 X0\')\n\n# plot with ROOT\ncanvas = Canvas(width=700, height=500)\ndraw([stack, h3], xtitle=\'Mass\', ytitle=\'Events\', pad=canvas)\n# set the number of expected legend entries\nlegend = Legend([h1, h2, h3], leftmargin=0.45, margin=0.3)\nlegend.Draw()\nlabel = ROOT.TText(0.3, 0.8, \'ROOT\')\nlabel.SetTextFont(43)\nlabel.SetTextSize(25)\nlabel.SetNDC()\nlabel.Draw()\ncanvas.Modified()\ncanvas.Update()\n\n# plot with matplotlib\nset_style(\'ATLAS\', mpl=True)\nfig = plt.figure(figsize=(7, 5), dpi=100)\naxes = plt.axes()\naxes.xaxis.set_minor_locator(AutoMinorLocator())\naxes.yaxis.set_minor_locator(AutoMinorLocator())\naxes.yaxis.set_major_locator(MultipleLocator(20))\nrplt.bar(stack, stacked=True, axes=axes)\nrplt.errorbar(h3, xerr=False, emptybins=False, axes=axes)\nplt.xlabel(\'Mass\', position=(1., 0.), va=\'bottom\', ha=\'right\')\nplt.ylabel(\'Events\', position=(0., 1.), va=\'top\', ha=\'right\')\naxes.xaxis.set_label_coords(1., -0.20)\naxes.yaxis.set_label_coords(-0.18, 1.)\nleg = plt.legend()\naxes.text(0.3, 0.8, \'matplotlib\',\n          verticalalignment=\'center\', horizontalalignment=\'center\',\n          transform=axes.transAxes, fontsize=20)\n\nif not ROOT.gROOT.IsBatch():\n    plt.show()\n    # wait for you to close the ROOT canvas before exiting\n    wait(True)\n'"
examples/plotting/plot_matplotlib_hist2d.py,1,"b'#!/usr/bin/env python\n""""""\n========================================\nPlot a 2D ROOT histogram with matplotlib\n========================================\n\nThis example demonstrates how a 2D ROOT histogram can be displayed with\nmatplotlib.\n""""""\nprint(__doc__)\nimport ROOT\nfrom matplotlib import pyplot as plt\nfrom rootpy.plotting import root2matplotlib as rplt\nfrom rootpy.plotting import Hist2D\nimport numpy as np\n\na = Hist2D(100, -3, 3, 100, 0, 6)\na.fill_array(np.random.multivariate_normal(\n    mean=(0, 3),\n    cov=[[1, .5], [.5, 1]],\n    size=(1000000,)))\n\nfig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n\nax1.set_title(\'hist2d\')\nrplt.hist2d(a, axes=ax1)\n\nax2.set_title(\'imshow\')\nim = rplt.imshow(a, axes=ax2)\n\nax3.set_title(\'contour\')\nrplt.contour(a, axes=ax3)\n\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\nfig.colorbar(im, cax=cbar_ax)\n\nif not ROOT.gROOT.IsBatch():\n    plt.show()\n'"
examples/plotting/plot_overlay.py,0,"b'#!/usr/bin/env python\n""""""\n============================\nOverlay Histograms or Graphs\n============================\n\nThis example demonstrates how to overlay multiple histograms or graphs while\nautomatically setting axis limits that are visually pleasing.\n""""""\nprint(__doc__)\nfrom rootpy.plotting import F1, Hist, HistStack, Graph, Canvas, set_style\nfrom rootpy.plotting.utils import draw\nfrom rootpy.interactive import wait\nfrom math import sin\n\nset_style(\'ATLAS\')\n\nmus = (0, -1, 2)\nsigmas = (2, 1, 0.5)\nevents = (1000, 2000, 100)\ncolors = (\'lawngreen\', \'forestgreen\', \'mistyrose\')\nstyles = (\'\\\\\', \'/\', \'-\')\n\ncanvas = Canvas()\nobjects = []\n\n# create a stack\nstack = HistStack()\nstack.Add(Hist(100, -5, 5, color=\'salmon\', drawstyle=\'hist\').FillRandom(\n          F1(\'TMath::Gaus(x, 2, 1)\'), 500))\nstack.Add(Hist(100, -5, 5, color=\'powderblue\', drawstyle=\'hist\').FillRandom(\n          F1(\'TMath::Gaus(x, 2, 0.6)\'), 300))\nobjects.append(stack)\n\n# create some random histograms\nfor i, (mu, sigma, n, c, s) in enumerate(zip(mus, sigmas, events, colors, styles)):\n    hist = Hist(100, -5, 5, color=c, fillstyle=s, drawstyle=\'hist\' if i % 2 == 0 else \'\')\n    hist.FillRandom(F1(\'TMath::Gaus(x,{0},{1})\'.format(mu, sigma)), n)\n    objects.append(hist)\n\n# create a graph\ngraph = Graph(10, drawstyle=\'P\')\nfor i in range(10):\n    x = -2 + i * 4 / 10.\n    graph.SetPoint(i, x, 40 + 10 * sin(x))\nobjects.append(graph)\n\ndraw(objects, xtitle=\'Some Variable [Units]\', ytitle=\'Events\', ypadding=0.05)\n# see rootpy.plotting.utils.get_limits for details on what arguments are\n# supported for setting the axes ranges.\nwait()\n'"
examples/plotting/plot_style.py,0,"b'#!/usr/bin/env python\n""""""\n==========================\nSetting the plotting style\n==========================\n\nThis example demonstrates how to set the plotting style.\n""""""\nprint(__doc__)\n\nfrom rootpy.extern.argparse import ArgumentParser\n\nparser = ArgumentParser()\nparser.add_argument(\'style\', default=\'ATLAS\', nargs=\'?\')\nargs, extra = parser.parse_known_args()\n\nimport ROOT\nfrom rootpy.plotting import Canvas, Hist\nfrom rootpy.plotting.style import get_style\nfrom rootpy.interactive import wait\nfrom rootpy.extern.six.moves import range\n\ntry:\n    kwargs = {}\n    for arg in extra:\n        name, value = arg.lstrip(\'--\').split(\'=\')\n        kwargs[name] = value\nexcept ValueError:\n    print(""specify style parameters with --name=value"")\n\ntry:\n    style = get_style(args.style, **kwargs)\nexcept ValueError:\n    print(\'Invalid style: `{0}`. Using the `ATLAS` style.\'.format(args.style))\n    style = get_style(\'ATLAS\')\n\n# Use styles as context managers. The selected style will only apply\n# within the following context:\nwith style:\n    c = Canvas()\n    hpx = Hist(100, -4, 4, name=""hpx"", title=""This is the px distribution"")\n    # generate some random data\n    ROOT.gRandom.SetSeed()\n    for i in range(25000):\n        hpx.Fill(ROOT.gRandom.Gaus())\n    hpx.GetXaxis().SetTitle(""random variable [unit]"")\n    hpx.GetYaxis().SetTitle(""#frac{dN}{dr} [unit^{-1}]"")\n    hpx.SetMaximum(1000.)\n    hpx.Draw()\n    wait()\n'"
examples/stats/plot_quantiles.py,0,"b'#!/usr/bin/env python\n""""""\n=================================================\nDraw a Quantile-Quantile Plot and Confidence Band\n=================================================\n\nThis is an example of drawing a quantile-quantile plot with a confidence level\n(CL) band.\n""""""\nprint(__doc__)\nimport ROOT\nfrom rootpy.interactive import wait\nfrom rootpy.plotting import Hist, Canvas, Legend, set_style\nfrom rootpy.plotting.contrib.quantiles import qqgraph\nfrom rootpy.extern.six.moves import range\n\nset_style(\'ATLAS\')\n\nc = Canvas(width=1200, height=600)\nc.Divide(2, 1, 1e-3, 1e-3)\n\nrand = ROOT.TRandom3()\nh1 = Hist(100, -5, 5, name=""h1"", title=""Histogram 1"",\n          linecolor=\'red\', legendstyle=\'l\')\nh2 = Hist(100, -5, 5, name=""h2"", title=""Histogram 2"",\n          linecolor=\'blue\', legendstyle=\'l\')\n\nfor ievt in range(10000):\n    h1.Fill(rand.Gaus(0, 0.8))\n    h2.Fill(rand.Gaus(0, 1))\n\npad = c.cd(1)\n\nh1.Draw(\'hist\')\nh2.Draw(\'hist same\')\n\nleg = Legend([h1, h2], pad=pad, leftmargin=0.5,\n             topmargin=0.11, rightmargin=0.05,\n             textsize=20)\nleg.Draw()\n\npad = c.cd(2)\n\ngr = qqgraph(h1, h2)\n\ngr.xaxis.title = h1.title\ngr.yaxis.title = h2.title\ngr.fillcolor = 17\ngr.fillstyle = \'solid\'\ngr.linecolor = 17\ngr.markercolor = \'darkred\'\ngr.markerstyle = 20\ngr.title = ""QQ with CL""\n\ngr.Draw(""ap"")\nx_min = gr.GetXaxis().GetXmin()\nx_max = gr.GetXaxis().GetXmax()\ny_min = gr.GetXaxis().GetXmin()\ny_max = gr.GetXaxis().GetXmax()\ngr.Draw(\'a3\')\ngr.Draw(\'Xp same\')\n\n# a straight line y=x to be a reference\nf_dia = ROOT.TF1(""f_dia"", ""x"",\n                 h1.GetXaxis().GetXmin(),\n                 h1.GetXaxis().GetXmax())\nf_dia.SetLineColor(9)\nf_dia.SetLineWidth(2)\nf_dia.SetLineStyle(2)\nf_dia.Draw(""same"")\n\nleg = Legend(3, pad=pad, leftmargin=0.45,\n             topmargin=0.45, rightmargin=0.05,\n             textsize=20)\nleg.AddEntry(gr, ""QQ points"", ""p"")\nleg.AddEntry(gr, ""68% CL band"", ""f"")\nleg.AddEntry(f_dia, ""Diagonal line"", ""l"")\nleg.Draw()\n\nc.Modified()\nc.Update()\nc.Draw()\nwait()\n'"
examples/tree/chain.py,0,"b'#!/usr/bin/env python\n""""""\n=============================================\nThe TreeChain class, a replacement for TChain\n=============================================\n\nThis example demonstrates how to use the TreeChain class, a more Python-friendly\nTChain replacement.\n""""""\nprint(__doc__)\nfrom random import gauss\nfrom rootpy.io import root_open\nfrom rootpy.tree import Tree, TreeChain\nfrom rootpy.plotting import Hist\nfrom rootpy.extern.six.moves import range\n\n# Make two files, each with a Tree called ""test""\n\nprint(""Creating test tree in chaintest1.root"")\nf = root_open(""chaintest1.root"", ""recreate"")\n\ntree = Tree(""test"")\nbranches = {\n    \'x\': \'F\',\n    \'y\': \'F\',\n    \'z\': \'F\',\n    \'i\': \'I\'}\ntree.create_branches(branches)\n\nfor i in range(10000):\n    tree.x = gauss(.5, 1.)\n    tree.y = gauss(.3, 2.)\n    tree.z = gauss(13., 42.)\n    tree.i = i\n    tree.fill()\n\n# Make a histogram of x when y > 1\nhist1 = Hist(100, -10, 10, name=\'hist1\')\ntree.Draw(\'x\', \'y > 1\', hist=hist1)\nhist1.SetDirectory(0) # memory resident\nprint(""The first tree has {0:f} entries where y > 1"".format(hist1.Integral()))\n\ntree.write()\nf.close()\n\nprint(""Creating test tree in chaintest2.root"")\nf = root_open(""chaintest2.root"", ""recreate"")\n\ntree = Tree(""test"")\ntree.create_branches(branches)\n\nfor i in range(10000):\n    tree.x = gauss(.5, 1.)\n    tree.y = gauss(.3, 2.)\n    tree.z = gauss(13., 42.)\n    tree.i = i\n    tree.fill()\ntree.write()\n\n# Make a histogram of the second tree\nhist2 = Hist(100, -10, 10, name=\'hist2\')\ntree.Draw(\'x\', \'y > 1\', hist=hist2)\nhist2.SetDirectory(0) # memory resident\nprint(""The second tree has {0:f} entries where y > 1"".format(hist2.Integral()))\nf.close()\n\ncombined_hist = hist1 + hist2\n\nprint(""Building TreeChain"")\nchain = TreeChain(\'test\', [\'chaintest2.root\', \'chaintest1.root\'])\n# Make the equivalent of the combined_hist\ncombined_hist_chain = Hist(100, -10, 10, name=\'combined\')\nchain.Draw(\'x\', \'y > 1\', hist=combined_hist_chain)\n\nresidual = combined_hist_chain - combined_hist\nprint(\n    ""The combined histogram (separately) minus ""\n    ""the combined from the chain has {0:f} entries"".format(\n        residual.Integral()))\n'"
examples/tree/chain_overwrite.py,0,"b'#!/usr/bin/env python\n""""""\n============================================\nCopy a tree chain while overwriting branches\n============================================\n\nThis is an example showing how to copy a tree chain while overwriting one or\nmore of its branches with new values.\n""""""\nprint(__doc__)\nfrom rootpy.tree import Tree, TreeModel, TreeChain, FloatCol, IntCol\nfrom rootpy.io import root_open\nfrom random import gauss\n\n""""""\nThis first section of code only creates an example tree chain.\n""""""\n\nclass Event(TreeModel):\n    """"""Event model definition""""""\n    x = FloatCol()\n    y = FloatCol()\n    z = FloatCol()\n    i = IntCol()\n\n# first create several example trees in separate files\nfnames = [""test_{0:d}.root"".format(i) for i in range(5)]\n\nfor fname in fnames:\n    with root_open(fname, ""recreate"") as f:\n\n        tree = Tree(""test"", model=Event)\n\n        # fill the tree\n        for i in range(100):\n            tree.x = gauss(.5, 1.)\n            tree.y = gauss(.3, 2.)\n            tree.z = gauss(13., 42.)\n            tree.i = i\n            tree.fill()\n        tree.write()\n\n""""""\nThis section below takes the example trees and copies it while overwriting a\nbranch with new values.\n""""""\n\n# first define the chain of trees\nchain = TreeChain(name=""test"", files=fnames)\n\n# Now we want to copy the tree above into a new file while overwriting a branch\n# First create a new file to save the new tree in:\nf_copy = root_open(""test_copy.root"", ""recreate"")\n\n# You may not know the entire model of the original tree but only the branches\n# you intend to overwrite, so I am not specifying the model=Event below as an\n# example of how to deal with this in general:\ntree_copy = Tree(""test_copy"")\n\n# If the original tree was not handed to you through rootpy don\'t forget to:\n# >>> from rootpy import asrootpy\n# >>> tree = asrootpy(tree)\n\n# Here we specify the buffer for the new tree to use. We use the same buffer as\n# the original tree. This creates all the same branches in the new tree but\n# their addresses point to the same memory used by the original tree.\ntree_copy.set_buffer(\n        chain._buffer,\n        create_branches=True)\n\n# Now loop over the original tree and fill the new tree\nfor entry in chain:\n    # Overwrite a branch value. This changes the value that will be written to\n    # the new tree but leaves the value unchanged in the original tree on disk.\n    entry.x = 3.141\n    # ""entry"" is actually the buffer, which is shared between both trees.\n    tree_copy.Fill()\n\n# tree_copy is now a copy of tree where the ""x"" branch has been overwritten\n# with new values\ntree_copy.Write()\nf_copy.Close()\n'"
examples/tree/model.py,0,"b'#!/usr/bin/env python\n""""""\n==================================\nTree models and object collections\n==================================\n\nThis example demonstrates how to define a tree model and collections of objects\nassociated to sets of tree branches.\n""""""\nprint(__doc__)\nfrom rootpy.tree import Tree, TreeModel, FloatCol, IntCol\nfrom rootpy.io import root_open\nfrom rootpy.vector import LorentzVector\nfrom rootpy import stl\nfrom random import gauss, randint\n\n\nf = root_open(""test.root"", ""recreate"")\n\n# define the model\nclass Point(TreeModel):\n    x = FloatCol()\n    y = FloatCol()\n    z = FloatCol()\n\nclass Event(Point.prefix(\'a_\'), Point.prefix(\'b_\')):\n    # a_x, a_y, a_z and b_x, b_y, b_z are implicitly included here\n    # define vector branches\n    col_x = stl.vector(""float"")\n    col_y = stl.vector(""float"")\n    col_z = stl.vector(""float"")\n    col_n = IntCol()\n    # a TLorentzVector\n    p = LorentzVector\n    i = IntCol()\n\ntree = Tree(""test"", model=Event)\n\n# fill the tree\nfor i in range(10):\n    tree.a_x = gauss(.5, 1.)\n    tree.a_y = gauss(.3, 2.)\n    tree.a_z = gauss(13., 42.)\n\n    tree.b_x = gauss(.5, 1.)\n    tree.b_y = gauss(.3, 2.)\n    tree.b_z = gauss(13., 42.)\n\n    n = randint(1, 10)\n    for j in range(n):\n        tree.col_x.push_back(gauss(.5, 1.))\n        tree.col_y.push_back(gauss(.3, 2.))\n        tree.col_z.push_back(gauss(13., 42.))\n    tree.col_n = n\n\n    tree.p.SetPtEtaPhiM(gauss(.5, 1.),\n                        gauss(.5, 1.),\n                        gauss(.5, 1.),\n                        gauss(.5, 1.))\n\n    tree.i = i\n    tree.fill(reset=True)\ntree.write()\n\nf.close()\nf = root_open(""test.root"")\n\ntree = f.test\n\n# define objects by prefix:\ntree.define_object(name=\'a\', prefix=\'a_\')\ntree.define_object(name=\'b\', prefix=\'b_\')\n\n# define a mixin class to add functionality to a tree object\nclass Particle(object):\n    def who_is_your_daddy(self):\n        print(""You are!"")\n\n# define collections of objects by prefix\ntree.define_collection(name=\'particles\',\n                       prefix=\'col_\',\n                       size=\'col_n\',\n                       mix=Particle)\n\n# loop over ""events"" in tree\nfor event in tree:\n    print(""a.x: {0:f}"".format(event.a.x))\n    print(""b.y: {0:f}"".format(event.b.y))\n    # loop over ""particles"" in current event\n    for p in event.particles:\n        print(""p.x: {0:f}"".format(p.x))\n        p.who_is_your_daddy()\n    print(event.p.Eta())\n\nf.close()\n'"
examples/tree/model_simple.py,0,"b'#!/usr/bin/env python\n""""""\n===================\nA simple tree model\n===================\n\nThis example demonstrates how to define a simple tree model.\n""""""\nprint(__doc__)\nfrom rootpy.tree import Tree, TreeModel\nfrom rootpy.tree import IntCol, FloatCol, FloatArrayCol, CharCol, CharArrayCol\nfrom rootpy.io import root_open\nfrom random import gauss, choice, sample\nfrom string import ascii_letters\n\nf = root_open(""test.root"", ""recreate"")\n\n# define the model\nclass Event(TreeModel):\n    s = CharCol()\n    string = CharArrayCol(5)\n    x = FloatCol()\n    y = FloatCol()\n    z = FloatCol()\n    f = FloatArrayCol(5)\n    num_vals = IntCol()\n    # variable-length array\n    vals = FloatArrayCol(5, length_name=\'num_vals\')\n\ntree = Tree(""test"", model=Event)\n\n# fill the tree\nfor i in range(5):\n    tree.s = ord(choice(ascii_letters))\n    tree.string = (u\'\'.join(sample(ascii_letters, 4))).encode(\'ascii\')\n    tree.x = gauss(.5, 1.)\n    tree.y = gauss(.3, 2.)\n    tree.z = gauss(13., 42.)\n    for j in range(5):\n        tree.f[j] = gauss(-2, 5)\n    tree.num_vals = i\n    for j in range(i):\n        tree.vals[j] = j\n    tree.fill()\ntree.write()\ntree.vals.reset()\n\n# print tree contents in CSV format\ntree.csv()\n\nf.close()\n'"
examples/tree/ntuple.py,0,"b'#!/usr/bin/env python\n""""""\n=======================\nA simple Ntuple example\n=======================\n\nThis example demonstrates how to create a simple Ntuple.\n""""""\nprint(__doc__)\nfrom rootpy.tree import Ntuple\nfrom rootpy.io import root_open\nfrom random import gauss\n\nf = root_open(""test.root"", ""recreate"")\n\n# create an ntuple with three float fields: a, b, c\nntuple = Ntuple((\'a\', \'b\', \'c\'), name=""test"")\n\n# fill the ntuple with random data\nfor i in range(20):\n    ntuple.Fill(gauss(.5, 1.), gauss(.3, 2.), gauss(13., 42.))\nntuple.write()\n\n# write as CSV\nntuple.csv()\n\nf.close()\n'"
examples/tree/object_branch.py,0,"b'#!/usr/bin/env python\n""""""\n===============\nObject branches\n===============\n\nThis simple example demonstrates how to define a TreeModel with a branch of type\nstd::vector<TLorentzVector>.\n""""""\nprint(__doc__)\nfrom rootpy.vector import LorentzVector\nfrom rootpy.tree import Tree, TreeModel, IntCol\nfrom rootpy.io import root_open\nfrom rootpy import stl\nfrom random import gauss\n\n\nf = root_open(""test.root"", ""recreate"")\n\n# define the model\nclass Event(TreeModel):\n    x = stl.vector(\'TLorentzVector\')\n    i = IntCol()\n\ntree = Tree(""test"", model=Event)\n\n# fill the tree\nfor i in range(100):\n    tree.x.clear()\n    for j in range(5):\n        vect = LorentzVector(\n            gauss(.5, 1.),\n            gauss(.5, 1.),\n            gauss(.5, 1.),\n            gauss(.5, 1.))\n        tree.x.push_back(vect)\n    tree.i = i\n    tree.fill()\n\ntree.write()\nf.close()\n'"
examples/tree/overwrite.py,0,"b'#!/usr/bin/env python\n""""""\n======================================\nCopy a tree while overwriting branches\n======================================\n\nThis is an example showing how to copy a tree while overwriting one or more of\nits branches with new values.\n""""""\nprint(__doc__)\nfrom rootpy.tree import Tree, TreeModel, FloatCol, IntCol\nfrom rootpy.io import root_open\nfrom random import gauss\n\n""""""\nThis first section of code only creates an example tree.\n""""""\n\n# define the model\nclass Event(TreeModel):\n    x = FloatCol()\n    y = FloatCol()\n    z = FloatCol()\n    i = IntCol()\n\n# first create a tree ""test"" in a file ""test.root""\nf = root_open(""test.root"", ""recreate"")\n\ntree = Tree(""test"", model=Event)\n\n# fill the tree\nfor i in range(100):\n    tree.x = gauss(.5, 1.)\n    tree.y = gauss(.3, 2.)\n    tree.z = gauss(13., 42.)\n    tree.i = i\n    tree.fill()\ntree.write()\n\n""""""\nThis section below takes the example tree and copies it while overwriting a\nbranch with new values.\n""""""\n\n# Now we want to copy the tree above into a new file while overwriting a branch\n# First create a new file to save the new tree in:\nf_copy = root_open(""test_copy.root"", ""recreate"")\n\n# You may not know the entire model of the original tree but only the branches\n# you intend to overwrite, so I am not specifying the model=Event below as an\n# example of how to deal with this in general:\ntree_copy = Tree(""test_copy"")\n\n# Here we specify the buffer for the new tree to use. We use the same buffer as\n# the original tree. This creates all the same branches in the new tree but\n# their addresses point to the same memory used by the original tree.\ntree_copy.set_buffer(tree._buffer, create_branches=True)\n\n# Now loop over the original tree and fill the new tree\nfor entry in tree:\n    # Overwrite a branch value. This changes the value that will be written to\n    # the new tree but leaves the value unchanged in the original tree on disk.\n    entry.x = 3.141\n    # ""entry"" is actually the buffer, which is shared between both trees.\n    tree_copy.Fill()\n\n# tree_copy is now a copy of tree where the ""x"" branch has been overwritten\n# with new values\ntree_copy.Write()\nf_copy.Close()\nf.Close()\n'"
examples/tree/user_object.py,0,"b'#!/usr/bin/env python\n""""""\n================================================\nCreate trees with branches of user-defined types\n================================================\n\nThis example demonstrates how to fill and read trees with branches containing\nuser-defined types.\n""""""\nprint(__doc__)\nfrom rootpy.tree import Tree, TreeModel, IntCol, ObjectCol\nfrom rootpy.io import root_open\nimport rootpy.compiled as C\nfrom random import gauss\n\n# compile our new type\nC.register_code(""""""\n\nclass Thingy {\n    public:\n        int i;\n        float x;\n        double y;\n};\n\n"""""", [""Thingy""])\n\n# alternatively you can ROOT.gSystem.Load() your library\n\n# define the model\nclass Event(TreeModel):\n    event_number = IntCol()\n    thingy = ObjectCol(C.Thingy)\n\n\nf = root_open(""test.root"", ""recreate"")\ntree = Tree(""test"", model=Event)\n\n# fill the tree\nfor i in range(20):\n    tree.event_number = i\n    tree.thingy.i = i\n    tree.thingy.x = gauss(.3, 2.)\n    tree.thingy.y = gauss(13., 42.)\n    tree.fill()\n\ntree.write()\nf.close()\n\n# now to read the same tree\nwith root_open(""test.root"") as f:\n    tree = f.test\n    for event in tree:\n        thing = event.thingy\n        print(""{0} {1} {2} {3}"".format(\n            event.event_number, thing.i, thing.x, thing.y))\n'"
examples/tree/vararray.py,0,"b'#!/usr/bin/env python\n""""""\n=================================\nTrees with variable-length arrays\n=================================\n\nThis example demonstrates how to create a tree with a variable-length array.\n""""""\nprint(__doc__)\n\nfrom rootpy.tree import Tree, TreeModel, IntCol, FloatArrayCol\nfrom rootpy.io import root_open\n\nclass Event(TreeModel):\n    num_vals = IntCol()\n    vals = FloatArrayCol(10, length_name=\'num_vals\')\n\nrfile = root_open(\'test.root\', \'w\')\ntree = Tree(\'events\', model=Event)\n\nfor i in range(10):\n    tree.num_vals = i + 1\n    for j in range(i + 1):\n        tree.vals[j] = j\n    tree.fill()\n\ntree.write()\ntree.vals.reset()\ntree.csv()\nrfile.close()\nprint(""==="")\n\n# CSV output from tree read from file should match above output\nroot_open(\'test.root\', \'r\').events.csv()\n'"
rootpy/extern/__init__.py,0,"b'""""""\nThis packages contains copies of python packages that are bundled\nwith rootpy but are external to rootpy, and hence are developed\nin a separate source tree.\n\nThe reason to include these packages in rootpy is to have fewer\ndependencies, i.e. fewer things to install for the end user.\nAnd sometimes there are bugs that only surface with certain\ncombinations of packages, having everyone use the same version\nof the external packages reduces this problem.\n""""""\n'"
rootpy/extern/argparse.py,0,"b'# Author: Steven J. Bethard <steven.bethard@gmail.com>.\n\n""""""Command-line parsing library\n\nThis module is an optparse-inspired command-line parsing library that:\n\n    - handles both optional and positional arguments\n    - produces highly informative usage messages\n    - supports parsers that dispatch to sub-parsers\n\nThe following is a simple usage example that sums integers from the\ncommand-line and writes the result to a file::\n\n    parser = argparse.ArgumentParser(\n        description=\'sum the integers at the command line\')\n    parser.add_argument(\n        \'integers\', metavar=\'int\', nargs=\'+\', type=int,\n        help=\'an integer to be summed\')\n    parser.add_argument(\n        \'--log\', default=sys.stdout, type=argparse.FileType(\'w\'),\n        help=\'the file where the sum should be written\')\n    args = parser.parse_args()\n    args.log.write(\'%s\' % sum(args.integers))\n    args.log.close()\n\nThe module contains the following public classes:\n\n    - ArgumentParser -- The main entry point for command-line parsing. As the\n        example above shows, the add_argument() method is used to populate\n        the parser with actions for optional and positional arguments. Then\n        the parse_args() method is invoked to convert the args at the\n        command-line into an object with attributes.\n\n    - ArgumentError -- The exception raised by ArgumentParser objects when\n        there are errors with the parser\'s actions. Errors raised while\n        parsing the command-line are caught by ArgumentParser and emitted\n        as command-line messages.\n\n    - FileType -- A factory for defining types of files to be created. As the\n        example above shows, instances of FileType are typically passed as\n        the type= argument of add_argument() calls.\n\n    - Action -- The base class for parser actions. Typically actions are\n        selected by passing strings like \'store_true\' or \'append_const\' to\n        the action= argument of add_argument(). However, for greater\n        customization of ArgumentParser actions, subclasses of Action may\n        be defined and passed as the action= argument.\n\n    - HelpFormatter, RawDescriptionHelpFormatter, RawTextHelpFormatter,\n        ArgumentDefaultsHelpFormatter -- Formatter classes which\n        may be passed as the formatter_class= argument to the\n        ArgumentParser constructor. HelpFormatter is the default,\n        RawDescriptionHelpFormatter and RawTextHelpFormatter tell the parser\n        not to change the formatting for help text, and\n        ArgumentDefaultsHelpFormatter adds information about argument defaults\n        to the help.\n\nAll other classes in this module are considered implementation details.\n(Also note that HelpFormatter and RawDescriptionHelpFormatter are only\nconsidered public as object names -- the API of the formatter objects is\nstill considered an implementation detail.)\n""""""\n\n__version__ = \'1.2.1\'\n__all__ = [\n    \'ArgumentParser\',\n    \'ArgumentError\',\n    \'ArgumentTypeError\',\n    \'FileType\',\n    \'HelpFormatter\',\n    \'ArgumentDefaultsHelpFormatter\',\n    \'RawDescriptionHelpFormatter\',\n    \'RawTextHelpFormatter\',\n    \'Namespace\',\n    \'Action\',\n    \'ONE_OR_MORE\',\n    \'OPTIONAL\',\n    \'PARSER\',\n    \'REMAINDER\',\n    \'SUPPRESS\',\n    \'ZERO_OR_MORE\',\n]\n\n\nimport copy as _copy\nimport os as _os\nimport re as _re\nimport sys as _sys\nimport textwrap as _textwrap\n\nfrom gettext import gettext as _\n\ntry:\n    set\nexcept NameError:\n    # for python < 2.4 compatibility (sets module is there since 2.3):\n    from sets import Set as set\n\ntry:\n    basestring\nexcept NameError:\n    basestring = str\n\ntry:\n    sorted\nexcept NameError:\n    # for python < 2.4 compatibility:\n    def sorted(iterable, reverse=False):\n        result = list(iterable)\n        result.sort()\n        if reverse:\n            result.reverse()\n        return result\n\n\ndef _callable(obj):\n    return hasattr(obj, \'__call__\') or hasattr(obj, \'__bases__\')\n\n\nSUPPRESS = \'==SUPPRESS==\'\n\nOPTIONAL = \'?\'\nZERO_OR_MORE = \'*\'\nONE_OR_MORE = \'+\'\nPARSER = \'A...\'\nREMAINDER = \'...\'\n_UNRECOGNIZED_ARGS_ATTR = \'_unrecognized_args\'\n\n# =============================\n# Utility functions and classes\n# =============================\n\nclass _AttributeHolder(object):\n    """"""Abstract base class that provides __repr__.\n\n    The __repr__ method returns a string in the format::\n        ClassName(attr=name, attr=name, ...)\n    The attributes are determined either by a class-level attribute,\n    \'_kwarg_names\', or by inspecting the instance __dict__.\n    """"""\n\n    def __repr__(self):\n        type_name = type(self).__name__\n        arg_strings = []\n        for arg in self._get_args():\n            arg_strings.append(repr(arg))\n        for name, value in self._get_kwargs():\n            arg_strings.append(\'%s=%r\' % (name, value))\n        return \'%s(%s)\' % (type_name, \', \'.join(arg_strings))\n\n    def _get_kwargs(self):\n        return sorted(self.__dict__.items())\n\n    def _get_args(self):\n        return []\n\n\ndef _ensure_value(namespace, name, value):\n    if getattr(namespace, name, None) is None:\n        setattr(namespace, name, value)\n    return getattr(namespace, name)\n\n\n# ===============\n# Formatting Help\n# ===============\n\nclass HelpFormatter(object):\n    """"""Formatter for generating usage messages and argument help strings.\n\n    Only the name of this class is considered a public API. All the methods\n    provided by the class are considered an implementation detail.\n    """"""\n\n    def __init__(self,\n                 prog,\n                 indent_increment=2,\n                 max_help_position=24,\n                 width=None):\n\n        # default setting for width\n        if width is None:\n            try:\n                width = int(_os.environ[\'COLUMNS\'])\n            except (KeyError, ValueError):\n                width = 80\n            width -= 2\n\n        self._prog = prog\n        self._indent_increment = indent_increment\n        self._max_help_position = max_help_position\n        self._width = width\n\n        self._current_indent = 0\n        self._level = 0\n        self._action_max_length = 0\n\n        self._root_section = self._Section(self, None)\n        self._current_section = self._root_section\n\n        self._whitespace_matcher = _re.compile(r\'\\s+\')\n        self._long_break_matcher = _re.compile(r\'\\n\\n\\n+\')\n\n    # ===============================\n    # Section and indentation methods\n    # ===============================\n    def _indent(self):\n        self._current_indent += self._indent_increment\n        self._level += 1\n\n    def _dedent(self):\n        self._current_indent -= self._indent_increment\n        assert self._current_indent >= 0, \'Indent decreased below 0.\'\n        self._level -= 1\n\n    class _Section(object):\n\n        def __init__(self, formatter, parent, heading=None):\n            self.formatter = formatter\n            self.parent = parent\n            self.heading = heading\n            self.items = []\n\n        def format_help(self):\n            # format the indented section\n            if self.parent is not None:\n                self.formatter._indent()\n            join = self.formatter._join_parts\n            for func, args in self.items:\n                func(*args)\n            item_help = join([func(*args) for func, args in self.items])\n            if self.parent is not None:\n                self.formatter._dedent()\n\n            # return nothing if the section was empty\n            if not item_help:\n                return \'\'\n\n            # add the heading if the section was non-empty\n            if self.heading is not SUPPRESS and self.heading is not None:\n                current_indent = self.formatter._current_indent\n                heading = \'%*s%s:\\n\' % (current_indent, \'\', self.heading)\n            else:\n                heading = \'\'\n\n            # join the section-initial newline, the heading and the help\n            return join([\'\\n\', heading, item_help, \'\\n\'])\n\n    def _add_item(self, func, args):\n        self._current_section.items.append((func, args))\n\n    # ========================\n    # Message building methods\n    # ========================\n    def start_section(self, heading):\n        self._indent()\n        section = self._Section(self, self._current_section, heading)\n        self._add_item(section.format_help, [])\n        self._current_section = section\n\n    def end_section(self):\n        self._current_section = self._current_section.parent\n        self._dedent()\n\n    def add_text(self, text):\n        if text is not SUPPRESS and text is not None:\n            self._add_item(self._format_text, [text])\n\n    def add_usage(self, usage, actions, groups, prefix=None):\n        if usage is not SUPPRESS:\n            args = usage, actions, groups, prefix\n            self._add_item(self._format_usage, args)\n\n    def add_argument(self, action):\n        if action.help is not SUPPRESS:\n\n            # find all invocations\n            get_invocation = self._format_action_invocation\n            invocations = [get_invocation(action)]\n            for subaction in self._iter_indented_subactions(action):\n                invocations.append(get_invocation(subaction))\n\n            # update the maximum item length\n            invocation_length = max([len(s) for s in invocations])\n            action_length = invocation_length + self._current_indent\n            self._action_max_length = max(self._action_max_length,\n                                          action_length)\n\n            # add the item to the list\n            self._add_item(self._format_action, [action])\n\n    def add_arguments(self, actions):\n        for action in actions:\n            self.add_argument(action)\n\n    # =======================\n    # Help-formatting methods\n    # =======================\n    def format_help(self):\n        help = self._root_section.format_help()\n        if help:\n            help = self._long_break_matcher.sub(\'\\n\\n\', help)\n            help = help.strip(\'\\n\') + \'\\n\'\n        return help\n\n    def _join_parts(self, part_strings):\n        return \'\'.join([part\n                        for part in part_strings\n                        if part and part is not SUPPRESS])\n\n    def _format_usage(self, usage, actions, groups, prefix):\n        if prefix is None:\n            prefix = _(\'usage: \')\n\n        # if usage is specified, use that\n        if usage is not None:\n            usage = usage % dict(prog=self._prog)\n\n        # if no optionals or positionals are available, usage is just prog\n        elif usage is None and not actions:\n            usage = \'%(prog)s\' % dict(prog=self._prog)\n\n        # if optionals and positionals are available, calculate usage\n        elif usage is None:\n            prog = \'%(prog)s\' % dict(prog=self._prog)\n\n            # split optionals from positionals\n            optionals = []\n            positionals = []\n            for action in actions:\n                if action.option_strings:\n                    optionals.append(action)\n                else:\n                    positionals.append(action)\n\n            # build full usage string\n            format = self._format_actions_usage\n            action_usage = format(optionals + positionals, groups)\n            usage = \' \'.join([s for s in [prog, action_usage] if s])\n\n            # wrap the usage parts if it\'s too long\n            text_width = self._width - self._current_indent\n            if len(prefix) + len(usage) > text_width:\n\n                # break usage into wrappable parts\n                part_regexp = r\'\\(.*?\\)+|\\[.*?\\]+|\\S+\'\n                opt_usage = format(optionals, groups)\n                pos_usage = format(positionals, groups)\n                opt_parts = _re.findall(part_regexp, opt_usage)\n                pos_parts = _re.findall(part_regexp, pos_usage)\n                assert \' \'.join(opt_parts) == opt_usage\n                assert \' \'.join(pos_parts) == pos_usage\n\n                # helper for wrapping lines\n                def get_lines(parts, indent, prefix=None):\n                    lines = []\n                    line = []\n                    if prefix is not None:\n                        line_len = len(prefix) - 1\n                    else:\n                        line_len = len(indent) - 1\n                    for part in parts:\n                        if line_len + 1 + len(part) > text_width:\n                            lines.append(indent + \' \'.join(line))\n                            line = []\n                            line_len = len(indent) - 1\n                        line.append(part)\n                        line_len += len(part) + 1\n                    if line:\n                        lines.append(indent + \' \'.join(line))\n                    if prefix is not None:\n                        lines[0] = lines[0][len(indent):]\n                    return lines\n\n                # if prog is short, follow it with optionals or positionals\n                if len(prefix) + len(prog) <= 0.75 * text_width:\n                    indent = \' \' * (len(prefix) + len(prog) + 1)\n                    if opt_parts:\n                        lines = get_lines([prog] + opt_parts, indent, prefix)\n                        lines.extend(get_lines(pos_parts, indent))\n                    elif pos_parts:\n                        lines = get_lines([prog] + pos_parts, indent, prefix)\n                    else:\n                        lines = [prog]\n\n                # if prog is long, put it on its own line\n                else:\n                    indent = \' \' * len(prefix)\n                    parts = opt_parts + pos_parts\n                    lines = get_lines(parts, indent)\n                    if len(lines) > 1:\n                        lines = []\n                        lines.extend(get_lines(opt_parts, indent))\n                        lines.extend(get_lines(pos_parts, indent))\n                    lines = [prog] + lines\n\n                # join lines into usage\n                usage = \'\\n\'.join(lines)\n\n        # prefix with \'usage:\'\n        return \'%s%s\\n\\n\' % (prefix, usage)\n\n    def _format_actions_usage(self, actions, groups):\n        # find group indices and identify actions in groups\n        group_actions = set()\n        inserts = {}\n        for group in groups:\n            try:\n                start = actions.index(group._group_actions[0])\n            except ValueError:\n                continue\n            else:\n                end = start + len(group._group_actions)\n                if actions[start:end] == group._group_actions:\n                    for action in group._group_actions:\n                        group_actions.add(action)\n                    if not group.required:\n                        if start in inserts:\n                            inserts[start] += \' [\'\n                        else:\n                            inserts[start] = \'[\'\n                        inserts[end] = \']\'\n                    else:\n                        if start in inserts:\n                            inserts[start] += \' (\'\n                        else:\n                            inserts[start] = \'(\'\n                        inserts[end] = \')\'\n                    for i in range(start + 1, end):\n                        inserts[i] = \'|\'\n\n        # collect all actions format strings\n        parts = []\n        for i, action in enumerate(actions):\n\n            # suppressed arguments are marked with None\n            # remove | separators for suppressed arguments\n            if action.help is SUPPRESS:\n                parts.append(None)\n                if inserts.get(i) == \'|\':\n                    inserts.pop(i)\n                elif inserts.get(i + 1) == \'|\':\n                    inserts.pop(i + 1)\n\n            # produce all arg strings\n            elif not action.option_strings:\n                part = self._format_args(action, action.dest)\n\n                # if it\'s in a group, strip the outer []\n                if action in group_actions:\n                    if part[0] == \'[\' and part[-1] == \']\':\n                        part = part[1:-1]\n\n                # add the action string to the list\n                parts.append(part)\n\n            # produce the first way to invoke the option in brackets\n            else:\n                option_string = action.option_strings[0]\n\n                # if the Optional doesn\'t take a value, format is:\n                #    -s or --long\n                if action.nargs == 0:\n                    part = \'%s\' % option_string\n\n                # if the Optional takes a value, format is:\n                #    -s ARGS or --long ARGS\n                else:\n                    default = action.dest.upper()\n                    args_string = self._format_args(action, default)\n                    part = \'%s %s\' % (option_string, args_string)\n\n                # make it look optional if it\'s not required or in a group\n                if not action.required and action not in group_actions:\n                    part = \'[%s]\' % part\n\n                # add the action string to the list\n                parts.append(part)\n\n        # insert things at the necessary indices\n        for i in sorted(inserts, reverse=True):\n            parts[i:i] = [inserts[i]]\n\n        # join all the action items with spaces\n        text = \' \'.join([item for item in parts if item is not None])\n\n        # clean up separators for mutually exclusive groups\n        open = r\'[\\[(]\'\n        close = r\'[\\])]\'\n        text = _re.sub(r\'(%s) \' % open, r\'\\1\', text)\n        text = _re.sub(r\' (%s)\' % close, r\'\\1\', text)\n        text = _re.sub(r\'%s *%s\' % (open, close), r\'\', text)\n        text = _re.sub(r\'\\(([^|]*)\\)\', r\'\\1\', text)\n        text = text.strip()\n\n        # return the text\n        return text\n\n    def _format_text(self, text):\n        if \'%(prog)\' in text:\n            text = text % dict(prog=self._prog)\n        text_width = self._width - self._current_indent\n        indent = \' \' * self._current_indent\n        return self._fill_text(text, text_width, indent) + \'\\n\\n\'\n\n    def _format_action(self, action):\n        # determine the required width and the entry label\n        help_position = min(self._action_max_length + 2,\n                            self._max_help_position)\n        help_width = self._width - help_position\n        action_width = help_position - self._current_indent - 2\n        action_header = self._format_action_invocation(action)\n\n        # ho nelp; start on same line and add a final newline\n        if not action.help:\n            tup = self._current_indent, \'\', action_header\n            action_header = \'%*s%s\\n\' % tup\n\n        # short action name; start on the same line and pad two spaces\n        elif len(action_header) <= action_width:\n            tup = self._current_indent, \'\', action_width, action_header\n            action_header = \'%*s%-*s  \' % tup\n            indent_first = 0\n\n        # long action name; start on the next line\n        else:\n            tup = self._current_indent, \'\', action_header\n            action_header = \'%*s%s\\n\' % tup\n            indent_first = help_position\n\n        # collect the pieces of the action help\n        parts = [action_header]\n\n        # if there was help for the action, add lines of help text\n        if action.help:\n            help_text = self._expand_help(action)\n            help_lines = self._split_lines(help_text, help_width)\n            parts.append(\'%*s%s\\n\' % (indent_first, \'\', help_lines[0]))\n            for line in help_lines[1:]:\n                parts.append(\'%*s%s\\n\' % (help_position, \'\', line))\n\n        # or add a newline if the description doesn\'t end with one\n        elif not action_header.endswith(\'\\n\'):\n            parts.append(\'\\n\')\n\n        # if there are any sub-actions, add their help as well\n        for subaction in self._iter_indented_subactions(action):\n            parts.append(self._format_action(subaction))\n\n        # return a single string\n        return self._join_parts(parts)\n\n    def _format_action_invocation(self, action):\n        if not action.option_strings:\n            metavar, = self._metavar_formatter(action, action.dest)(1)\n            return metavar\n\n        else:\n            parts = []\n\n            # if the Optional doesn\'t take a value, format is:\n            #    -s, --long\n            if action.nargs == 0:\n                parts.extend(action.option_strings)\n\n            # if the Optional takes a value, format is:\n            #    -s ARGS, --long ARGS\n            else:\n                default = action.dest.upper()\n                args_string = self._format_args(action, default)\n                for option_string in action.option_strings:\n                    parts.append(\'%s %s\' % (option_string, args_string))\n\n            return \', \'.join(parts)\n\n    def _metavar_formatter(self, action, default_metavar):\n        if action.metavar is not None:\n            result = action.metavar\n        elif action.choices is not None:\n            choice_strs = [str(choice) for choice in action.choices]\n            result = \'{%s}\' % \',\'.join(choice_strs)\n        else:\n            result = default_metavar\n\n        def format(tuple_size):\n            if isinstance(result, tuple):\n                return result\n            else:\n                return (result, ) * tuple_size\n        return format\n\n    def _format_args(self, action, default_metavar):\n        get_metavar = self._metavar_formatter(action, default_metavar)\n        if action.nargs is None:\n            result = \'%s\' % get_metavar(1)\n        elif action.nargs == OPTIONAL:\n            result = \'[%s]\' % get_metavar(1)\n        elif action.nargs == ZERO_OR_MORE:\n            result = \'[%s [%s ...]]\' % get_metavar(2)\n        elif action.nargs == ONE_OR_MORE:\n            result = \'%s [%s ...]\' % get_metavar(2)\n        elif action.nargs == REMAINDER:\n            result = \'...\'\n        elif action.nargs == PARSER:\n            result = \'%s ...\' % get_metavar(1)\n        else:\n            formats = [\'%s\' for _ in range(action.nargs)]\n            result = \' \'.join(formats) % get_metavar(action.nargs)\n        return result\n\n    def _expand_help(self, action):\n        params = dict(vars(action), prog=self._prog)\n        for name in list(params):\n            if params[name] is SUPPRESS:\n                del params[name]\n        for name in list(params):\n            if hasattr(params[name], \'__name__\'):\n                params[name] = params[name].__name__\n        if params.get(\'choices\') is not None:\n            choices_str = \', \'.join([str(c) for c in params[\'choices\']])\n            params[\'choices\'] = choices_str\n        return self._get_help_string(action) % params\n\n    def _iter_indented_subactions(self, action):\n        try:\n            get_subactions = action._get_subactions\n        except AttributeError:\n            pass\n        else:\n            self._indent()\n            for subaction in get_subactions():\n                yield subaction\n            self._dedent()\n\n    def _split_lines(self, text, width):\n        text = self._whitespace_matcher.sub(\' \', text).strip()\n        return _textwrap.wrap(text, width)\n\n    def _fill_text(self, text, width, indent):\n        text = self._whitespace_matcher.sub(\' \', text).strip()\n        return _textwrap.fill(text, width, initial_indent=indent,\n                                           subsequent_indent=indent)\n\n    def _get_help_string(self, action):\n        return action.help\n\n\nclass RawDescriptionHelpFormatter(HelpFormatter):\n    """"""Help message formatter which retains any formatting in descriptions.\n\n    Only the name of this class is considered a public API. All the methods\n    provided by the class are considered an implementation detail.\n    """"""\n\n    def _fill_text(self, text, width, indent):\n        return \'\'.join([indent + line for line in text.splitlines(True)])\n\n\nclass RawTextHelpFormatter(RawDescriptionHelpFormatter):\n    """"""Help message formatter which retains formatting of all help text.\n\n    Only the name of this class is considered a public API. All the methods\n    provided by the class are considered an implementation detail.\n    """"""\n\n    def _split_lines(self, text, width):\n        return text.splitlines()\n\n\nclass ArgumentDefaultsHelpFormatter(HelpFormatter):\n    """"""Help message formatter which adds default values to argument help.\n\n    Only the name of this class is considered a public API. All the methods\n    provided by the class are considered an implementation detail.\n    """"""\n\n    def _get_help_string(self, action):\n        help = action.help\n        if \'%(default)\' not in action.help:\n            if action.default is not SUPPRESS:\n                defaulting_nargs = [OPTIONAL, ZERO_OR_MORE]\n                if action.option_strings or action.nargs in defaulting_nargs:\n                    help += \' (default: %(default)s)\'\n        return help\n\n\n# =====================\n# Options and Arguments\n# =====================\n\ndef _get_action_name(argument):\n    if argument is None:\n        return None\n    elif argument.option_strings:\n        return  \'/\'.join(argument.option_strings)\n    elif argument.metavar not in (None, SUPPRESS):\n        return argument.metavar\n    elif argument.dest not in (None, SUPPRESS):\n        return argument.dest\n    else:\n        return None\n\n\nclass ArgumentError(Exception):\n    """"""An error from creating or using an argument (optional or positional).\n\n    The string value of this exception is the message, augmented with\n    information about the argument that caused it.\n    """"""\n\n    def __init__(self, argument, message):\n        self.argument_name = _get_action_name(argument)\n        self.message = message\n\n    def __str__(self):\n        if self.argument_name is None:\n            format = \'%(message)s\'\n        else:\n            format = \'argument %(argument_name)s: %(message)s\'\n        return format % dict(message=self.message,\n                             argument_name=self.argument_name)\n\n\nclass ArgumentTypeError(Exception):\n    """"""An error from trying to convert a command line string to a type.""""""\n    pass\n\n\n# ==============\n# Action classes\n# ==============\n\nclass Action(_AttributeHolder):\n    """"""Information about how to convert command line strings to Python objects.\n\n    Action objects are used by an ArgumentParser to represent the information\n    needed to parse a single argument from one or more strings from the\n    command line. The keyword arguments to the Action constructor are also\n    all attributes of Action instances.\n\n    Keyword Arguments:\n\n        - option_strings -- A list of command-line option strings which\n            should be associated with this action.\n\n        - dest -- The name of the attribute to hold the created object(s)\n\n        - nargs -- The number of command-line arguments that should be\n            consumed. By default, one argument will be consumed and a single\n            value will be produced.  Other values include:\n                - N (an integer) consumes N arguments (and produces a list)\n                - \'?\' consumes zero or one arguments\n                - \'*\' consumes zero or more arguments (and produces a list)\n                - \'+\' consumes one or more arguments (and produces a list)\n            Note that the difference between the default and nargs=1 is that\n            with the default, a single value will be produced, while with\n            nargs=1, a list containing a single value will be produced.\n\n        - const -- The value to be produced if the option is specified and the\n            option uses an action that takes no values.\n\n        - default -- The value to be produced if the option is not specified.\n\n        - type -- The type which the command-line arguments should be converted\n            to, should be one of \'string\', \'int\', \'float\', \'complex\' or a\n            callable object that accepts a single string argument. If None,\n            \'string\' is assumed.\n\n        - choices -- A container of values that should be allowed. If not None,\n            after a command-line argument has been converted to the appropriate\n            type, an exception will be raised if it is not a member of this\n            collection.\n\n        - required -- True if the action must always be specified at the\n            command line. This is only meaningful for optional command-line\n            arguments.\n\n        - help -- The help string describing the argument.\n\n        - metavar -- The name to be used for the option\'s argument with the\n            help string. If None, the \'dest\' value will be used as the name.\n    """"""\n\n    def __init__(self,\n                 option_strings,\n                 dest,\n                 nargs=None,\n                 const=None,\n                 default=None,\n                 type=None,\n                 choices=None,\n                 required=False,\n                 help=None,\n                 metavar=None):\n        self.option_strings = option_strings\n        self.dest = dest\n        self.nargs = nargs\n        self.const = const\n        self.default = default\n        self.type = type\n        self.choices = choices\n        self.required = required\n        self.help = help\n        self.metavar = metavar\n\n    def _get_kwargs(self):\n        names = [\n            \'option_strings\',\n            \'dest\',\n            \'nargs\',\n            \'const\',\n            \'default\',\n            \'type\',\n            \'choices\',\n            \'help\',\n            \'metavar\',\n        ]\n        return [(name, getattr(self, name)) for name in names]\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        raise NotImplementedError(_(\'.__call__() not defined\'))\n\n\nclass _StoreAction(Action):\n\n    def __init__(self,\n                 option_strings,\n                 dest,\n                 nargs=None,\n                 const=None,\n                 default=None,\n                 type=None,\n                 choices=None,\n                 required=False,\n                 help=None,\n                 metavar=None):\n        if nargs == 0:\n            raise ValueError(\'nargs for store actions must be > 0; if you \'\n                             \'have nothing to store, actions such as store \'\n                             \'true or store const may be more appropriate\')\n        if const is not None and nargs != OPTIONAL:\n            raise ValueError(\'nargs must be %r to supply const\' % OPTIONAL)\n        super(_StoreAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=nargs,\n            const=const,\n            default=default,\n            type=type,\n            choices=choices,\n            required=required,\n            help=help,\n            metavar=metavar)\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        setattr(namespace, self.dest, values)\n\n\nclass _StoreConstAction(Action):\n\n    def __init__(self,\n                 option_strings,\n                 dest,\n                 const,\n                 default=None,\n                 required=False,\n                 help=None,\n                 metavar=None):\n        super(_StoreConstAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=0,\n            const=const,\n            default=default,\n            required=required,\n            help=help)\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        setattr(namespace, self.dest, self.const)\n\n\nclass _StoreTrueAction(_StoreConstAction):\n\n    def __init__(self,\n                 option_strings,\n                 dest,\n                 default=False,\n                 required=False,\n                 help=None):\n        super(_StoreTrueAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            const=True,\n            default=default,\n            required=required,\n            help=help)\n\n\nclass _StoreFalseAction(_StoreConstAction):\n\n    def __init__(self,\n                 option_strings,\n                 dest,\n                 default=True,\n                 required=False,\n                 help=None):\n        super(_StoreFalseAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            const=False,\n            default=default,\n            required=required,\n            help=help)\n\n\nclass _AppendAction(Action):\n\n    def __init__(self,\n                 option_strings,\n                 dest,\n                 nargs=None,\n                 const=None,\n                 default=None,\n                 type=None,\n                 choices=None,\n                 required=False,\n                 help=None,\n                 metavar=None):\n        if nargs == 0:\n            raise ValueError(\'nargs for append actions must be > 0; if arg \'\n                             \'strings are not supplying the value to append, \'\n                             \'the append const action may be more appropriate\')\n        if const is not None and nargs != OPTIONAL:\n            raise ValueError(\'nargs must be %r to supply const\' % OPTIONAL)\n        super(_AppendAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=nargs,\n            const=const,\n            default=default,\n            type=type,\n            choices=choices,\n            required=required,\n            help=help,\n            metavar=metavar)\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        items = _copy.copy(_ensure_value(namespace, self.dest, []))\n        items.append(values)\n        setattr(namespace, self.dest, items)\n\n\nclass _AppendConstAction(Action):\n\n    def __init__(self,\n                 option_strings,\n                 dest,\n                 const,\n                 default=None,\n                 required=False,\n                 help=None,\n                 metavar=None):\n        super(_AppendConstAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=0,\n            const=const,\n            default=default,\n            required=required,\n            help=help,\n            metavar=metavar)\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        items = _copy.copy(_ensure_value(namespace, self.dest, []))\n        items.append(self.const)\n        setattr(namespace, self.dest, items)\n\n\nclass _CountAction(Action):\n\n    def __init__(self,\n                 option_strings,\n                 dest,\n                 default=None,\n                 required=False,\n                 help=None):\n        super(_CountAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=0,\n            default=default,\n            required=required,\n            help=help)\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        new_count = _ensure_value(namespace, self.dest, 0) + 1\n        setattr(namespace, self.dest, new_count)\n\n\nclass _HelpAction(Action):\n\n    def __init__(self,\n                 option_strings,\n                 dest=SUPPRESS,\n                 default=SUPPRESS,\n                 help=None):\n        super(_HelpAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            default=default,\n            nargs=0,\n            help=help)\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        parser.print_help()\n        parser.exit()\n\n\nclass _VersionAction(Action):\n\n    def __init__(self,\n                 option_strings,\n                 version=None,\n                 dest=SUPPRESS,\n                 default=SUPPRESS,\n                 help=""show program\'s version number and exit""):\n        super(_VersionAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            default=default,\n            nargs=0,\n            help=help)\n        self.version = version\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        version = self.version\n        if version is None:\n            version = parser.version\n        formatter = parser._get_formatter()\n        formatter.add_text(version)\n        parser.exit(message=formatter.format_help())\n\n\nclass _SubParsersAction(Action):\n\n    class _ChoicesPseudoAction(Action):\n\n        def __init__(self, name, help):\n            sup = super(_SubParsersAction._ChoicesPseudoAction, self)\n            sup.__init__(option_strings=[], dest=name, help=help)\n\n    def __init__(self,\n                 option_strings,\n                 prog,\n                 parser_class,\n                 dest=SUPPRESS,\n                 help=None,\n                 metavar=None):\n\n        self._prog_prefix = prog\n        self._parser_class = parser_class\n        self._name_parser_map = {}\n        self._choices_actions = []\n\n        super(_SubParsersAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=PARSER,\n            choices=self._name_parser_map,\n            help=help,\n            metavar=metavar)\n\n    def add_parser(self, name, **kwargs):\n        # set prog from the existing prefix\n        if kwargs.get(\'prog\') is None:\n            kwargs[\'prog\'] = \'%s %s\' % (self._prog_prefix, name)\n\n        # create a pseudo-action to hold the choice help\n        if \'help\' in kwargs:\n            help = kwargs.pop(\'help\')\n            choice_action = self._ChoicesPseudoAction(name, help)\n            self._choices_actions.append(choice_action)\n\n        # create the parser and add it to the map\n        parser = self._parser_class(**kwargs)\n        self._name_parser_map[name] = parser\n        return parser\n\n    def _get_subactions(self):\n        return self._choices_actions\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        parser_name = values[0]\n        arg_strings = values[1:]\n\n        # set the parser name if requested\n        if self.dest is not SUPPRESS:\n            setattr(namespace, self.dest, parser_name)\n\n        # select the parser\n        try:\n            parser = self._name_parser_map[parser_name]\n        except KeyError:\n            tup = parser_name, \', \'.join(self._name_parser_map)\n            msg = _(\'unknown parser %r (choices: %s)\' % tup)\n            raise ArgumentError(self, msg)\n\n        # parse all the remaining options into the namespace\n        # store any unrecognized options on the object, so that the top\n        # level parser can decide what to do with them\n        namespace, arg_strings = parser.parse_known_args(arg_strings, namespace)\n        if arg_strings:\n            vars(namespace).setdefault(_UNRECOGNIZED_ARGS_ATTR, [])\n            getattr(namespace, _UNRECOGNIZED_ARGS_ATTR).extend(arg_strings)\n\n\n# ==============\n# Type classes\n# ==============\n\nclass FileType(object):\n    """"""Factory for creating file object types\n\n    Instances of FileType are typically passed as type= arguments to the\n    ArgumentParser add_argument() method.\n\n    Keyword Arguments:\n        - mode -- A string indicating how the file is to be opened. Accepts the\n            same values as the builtin open() function.\n        - bufsize -- The file\'s desired buffer size. Accepts the same values as\n            the builtin open() function.\n    """"""\n\n    def __init__(self, mode=\'r\', bufsize=None):\n        self._mode = mode\n        self._bufsize = bufsize\n\n    def __call__(self, string):\n        # the special argument ""-"" means sys.std{in,out}\n        if string == \'-\':\n            if \'r\' in self._mode:\n                return _sys.stdin\n            elif \'w\' in self._mode:\n                return _sys.stdout\n            else:\n                msg = _(\'argument ""-"" with mode %r\' % self._mode)\n                raise ValueError(msg)\n\n        # all other arguments are used as file names\n        if self._bufsize:\n            return open(string, self._mode, self._bufsize)\n        else:\n            return open(string, self._mode)\n\n    def __repr__(self):\n        args = [self._mode, self._bufsize]\n        args_str = \', \'.join([repr(arg) for arg in args if arg is not None])\n        return \'%s(%s)\' % (type(self).__name__, args_str)\n\n# ===========================\n# Optional and Positional Parsing\n# ===========================\n\nclass Namespace(_AttributeHolder):\n    """"""Simple object for storing attributes.\n\n    Implements equality by attribute names and values, and provides a simple\n    string representation.\n    """"""\n\n    def __init__(self, **kwargs):\n        for name in kwargs:\n            setattr(self, name, kwargs[name])\n\n    __hash__ = None\n\n    def __eq__(self, other):\n        return vars(self) == vars(other)\n\n    def __ne__(self, other):\n        return not (self == other)\n\n    def __contains__(self, key):\n        return key in self.__dict__\n\n\nclass _ActionsContainer(object):\n\n    def __init__(self,\n                 description,\n                 prefix_chars,\n                 argument_default,\n                 conflict_handler):\n        super(_ActionsContainer, self).__init__()\n\n        self.description = description\n        self.argument_default = argument_default\n        self.prefix_chars = prefix_chars\n        self.conflict_handler = conflict_handler\n\n        # set up registries\n        self._registries = {}\n\n        # register actions\n        self.register(\'action\', None, _StoreAction)\n        self.register(\'action\', \'store\', _StoreAction)\n        self.register(\'action\', \'store_const\', _StoreConstAction)\n        self.register(\'action\', \'store_true\', _StoreTrueAction)\n        self.register(\'action\', \'store_false\', _StoreFalseAction)\n        self.register(\'action\', \'append\', _AppendAction)\n        self.register(\'action\', \'append_const\', _AppendConstAction)\n        self.register(\'action\', \'count\', _CountAction)\n        self.register(\'action\', \'help\', _HelpAction)\n        self.register(\'action\', \'version\', _VersionAction)\n        self.register(\'action\', \'parsers\', _SubParsersAction)\n\n        # raise an exception if the conflict handler is invalid\n        self._get_handler()\n\n        # action storage\n        self._actions = []\n        self._option_string_actions = {}\n\n        # groups\n        self._action_groups = []\n        self._mutually_exclusive_groups = []\n\n        # defaults storage\n        self._defaults = {}\n\n        # determines whether an ""option"" looks like a negative number\n        self._negative_number_matcher = _re.compile(r\'^-\\d+$|^-\\d*\\.\\d+$\')\n\n        # whether or not there are any optionals that look like negative\n        # numbers -- uses a list so it can be shared and edited\n        self._has_negative_number_optionals = []\n\n    # ====================\n    # Registration methods\n    # ====================\n    def register(self, registry_name, value, object):\n        registry = self._registries.setdefault(registry_name, {})\n        registry[value] = object\n\n    def _registry_get(self, registry_name, value, default=None):\n        return self._registries[registry_name].get(value, default)\n\n    # ==================================\n    # Namespace default accessor methods\n    # ==================================\n    def set_defaults(self, **kwargs):\n        self._defaults.update(kwargs)\n\n        # if these defaults match any existing arguments, replace\n        # the previous default on the object with the new one\n        for action in self._actions:\n            if action.dest in kwargs:\n                action.default = kwargs[action.dest]\n\n    def get_default(self, dest):\n        for action in self._actions:\n            if action.dest == dest and action.default is not None:\n                return action.default\n        return self._defaults.get(dest, None)\n\n\n    # =======================\n    # Adding argument actions\n    # =======================\n    def add_argument(self, *args, **kwargs):\n        """"""\n        add_argument(dest, ..., name=value, ...)\n        add_argument(option_string, option_string, ..., name=value, ...)\n        """"""\n\n        # if no positional args are supplied or only one is supplied and\n        # it doesn\'t look like an option string, parse a positional\n        # argument\n        chars = self.prefix_chars\n        if not args or len(args) == 1 and args[0][0] not in chars:\n            if args and \'dest\' in kwargs:\n                raise ValueError(\'dest supplied twice for positional argument\')\n            kwargs = self._get_positional_kwargs(*args, **kwargs)\n\n        # otherwise, we\'re adding an optional argument\n        else:\n            kwargs = self._get_optional_kwargs(*args, **kwargs)\n\n        # if no default was supplied, use the parser-level default\n        if \'default\' not in kwargs:\n            dest = kwargs[\'dest\']\n            if dest in self._defaults:\n                kwargs[\'default\'] = self._defaults[dest]\n            elif self.argument_default is not None:\n                kwargs[\'default\'] = self.argument_default\n\n        # create the action object, and add it to the parser\n        action_class = self._pop_action_class(kwargs)\n        if not _callable(action_class):\n            raise ValueError(\'unknown action ""%s""\' % action_class)\n        action = action_class(**kwargs)\n\n        # raise an error if the action type is not callable\n        type_func = self._registry_get(\'type\', action.type, action.type)\n        if not _callable(type_func):\n            raise ValueError(\'%r is not callable\' % type_func)\n\n        return self._add_action(action)\n\n    def add_argument_group(self, *args, **kwargs):\n        group = _ArgumentGroup(self, *args, **kwargs)\n        self._action_groups.append(group)\n        return group\n\n    def add_mutually_exclusive_group(self, **kwargs):\n        group = _MutuallyExclusiveGroup(self, **kwargs)\n        self._mutually_exclusive_groups.append(group)\n        return group\n\n    def _add_action(self, action):\n        # resolve any conflicts\n        self._check_conflict(action)\n\n        # add to actions list\n        self._actions.append(action)\n        action.container = self\n\n        # index the action by any option strings it has\n        for option_string in action.option_strings:\n            self._option_string_actions[option_string] = action\n\n        # set the flag if any option strings look like negative numbers\n        for option_string in action.option_strings:\n            if self._negative_number_matcher.match(option_string):\n                if not self._has_negative_number_optionals:\n                    self._has_negative_number_optionals.append(True)\n\n        # return the created action\n        return action\n\n    def _remove_action(self, action):\n        self._actions.remove(action)\n\n    def _add_container_actions(self, container):\n        # collect groups by titles\n        title_group_map = {}\n        for group in self._action_groups:\n            if group.title in title_group_map:\n                msg = _(\'cannot merge actions - two groups are named %r\')\n                raise ValueError(msg % (group.title))\n            title_group_map[group.title] = group\n\n        # map each action to its group\n        group_map = {}\n        for group in container._action_groups:\n\n            # if a group with the title exists, use that, otherwise\n            # create a new group matching the container\'s group\n            if group.title not in title_group_map:\n                title_group_map[group.title] = self.add_argument_group(\n                    title=group.title,\n                    description=group.description,\n                    conflict_handler=group.conflict_handler)\n\n            # map the actions to their new group\n            for action in group._group_actions:\n                group_map[action] = title_group_map[group.title]\n\n        # add container\'s mutually exclusive groups\n        # NOTE: if add_mutually_exclusive_group ever gains title= and\n        # description= then this code will need to be expanded as above\n        for group in container._mutually_exclusive_groups:\n            mutex_group = self.add_mutually_exclusive_group(\n                required=group.required)\n\n            # map the actions to their new mutex group\n            for action in group._group_actions:\n                group_map[action] = mutex_group\n\n        # add all actions to this container or their group\n        for action in container._actions:\n            group_map.get(action, self)._add_action(action)\n\n    def _get_positional_kwargs(self, dest, **kwargs):\n        # make sure required is not specified\n        if \'required\' in kwargs:\n            msg = _(""\'required\' is an invalid argument for positionals"")\n            raise TypeError(msg)\n\n        # mark positional arguments as required if at least one is\n        # always required\n        if kwargs.get(\'nargs\') not in [OPTIONAL, ZERO_OR_MORE]:\n            kwargs[\'required\'] = True\n        if kwargs.get(\'nargs\') == ZERO_OR_MORE and \'default\' not in kwargs:\n            kwargs[\'required\'] = True\n\n        # return the keyword arguments with no option strings\n        return dict(kwargs, dest=dest, option_strings=[])\n\n    def _get_optional_kwargs(self, *args, **kwargs):\n        # determine short and long option strings\n        option_strings = []\n        long_option_strings = []\n        for option_string in args:\n            # error on strings that don\'t start with an appropriate prefix\n            if not option_string[0] in self.prefix_chars:\n                msg = _(\'invalid option string %r: \'\n                        \'must start with a character %r\')\n                tup = option_string, self.prefix_chars\n                raise ValueError(msg % tup)\n\n            # strings starting with two prefix characters are long options\n            option_strings.append(option_string)\n            if option_string[0] in self.prefix_chars:\n                if len(option_string) > 1:\n                    if option_string[1] in self.prefix_chars:\n                        long_option_strings.append(option_string)\n\n        # infer destination, \'--foo-bar\' -> \'foo_bar\' and \'-x\' -> \'x\'\n        dest = kwargs.pop(\'dest\', None)\n        if dest is None:\n            if long_option_strings:\n                dest_option_string = long_option_strings[0]\n            else:\n                dest_option_string = option_strings[0]\n            dest = dest_option_string.lstrip(self.prefix_chars)\n            if not dest:\n                msg = _(\'dest= is required for options like %r\')\n                raise ValueError(msg % option_string)\n            dest = dest.replace(\'-\', \'_\')\n\n        # return the updated keyword arguments\n        return dict(kwargs, dest=dest, option_strings=option_strings)\n\n    def _pop_action_class(self, kwargs, default=None):\n        action = kwargs.pop(\'action\', default)\n        return self._registry_get(\'action\', action, action)\n\n    def _get_handler(self):\n        # determine function from conflict handler string\n        handler_func_name = \'_handle_conflict_%s\' % self.conflict_handler\n        try:\n            return getattr(self, handler_func_name)\n        except AttributeError:\n            msg = _(\'invalid conflict_resolution value: %r\')\n            raise ValueError(msg % self.conflict_handler)\n\n    def _check_conflict(self, action):\n\n        # find all options that conflict with this option\n        confl_optionals = []\n        for option_string in action.option_strings:\n            if option_string in self._option_string_actions:\n                confl_optional = self._option_string_actions[option_string]\n                confl_optionals.append((option_string, confl_optional))\n\n        # resolve any conflicts\n        if confl_optionals:\n            conflict_handler = self._get_handler()\n            conflict_handler(action, confl_optionals)\n\n    def _handle_conflict_error(self, action, conflicting_actions):\n        message = _(\'conflicting option string(s): %s\')\n        conflict_string = \', \'.join([option_string\n                                     for option_string, action\n                                     in conflicting_actions])\n        raise ArgumentError(action, message % conflict_string)\n\n    def _handle_conflict_resolve(self, action, conflicting_actions):\n\n        # remove all conflicting options\n        for option_string, action in conflicting_actions:\n\n            # remove the conflicting option\n            action.option_strings.remove(option_string)\n            self._option_string_actions.pop(option_string, None)\n\n            # if the option now has no option string, remove it from the\n            # container holding it\n            if not action.option_strings:\n                action.container._remove_action(action)\n\n\nclass _ArgumentGroup(_ActionsContainer):\n\n    def __init__(self, container, title=None, description=None, **kwargs):\n        # add any missing keyword arguments by checking the container\n        update = kwargs.setdefault\n        update(\'conflict_handler\', container.conflict_handler)\n        update(\'prefix_chars\', container.prefix_chars)\n        update(\'argument_default\', container.argument_default)\n        super_init = super(_ArgumentGroup, self).__init__\n        super_init(description=description, **kwargs)\n\n        # group attributes\n        self.title = title\n        self._group_actions = []\n\n        # share most attributes with the container\n        self._registries = container._registries\n        self._actions = container._actions\n        self._option_string_actions = container._option_string_actions\n        self._defaults = container._defaults\n        self._has_negative_number_optionals = \\\n            container._has_negative_number_optionals\n\n    def _add_action(self, action):\n        action = super(_ArgumentGroup, self)._add_action(action)\n        self._group_actions.append(action)\n        return action\n\n    def _remove_action(self, action):\n        super(_ArgumentGroup, self)._remove_action(action)\n        self._group_actions.remove(action)\n\n\nclass _MutuallyExclusiveGroup(_ArgumentGroup):\n\n    def __init__(self, container, required=False):\n        super(_MutuallyExclusiveGroup, self).__init__(container)\n        self.required = required\n        self._container = container\n\n    def _add_action(self, action):\n        if action.required:\n            msg = _(\'mutually exclusive arguments must be optional\')\n            raise ValueError(msg)\n        action = self._container._add_action(action)\n        self._group_actions.append(action)\n        return action\n\n    def _remove_action(self, action):\n        self._container._remove_action(action)\n        self._group_actions.remove(action)\n\n\nclass ArgumentParser(_AttributeHolder, _ActionsContainer):\n    """"""Object for parsing command line strings into Python objects.\n\n    Keyword Arguments:\n        - prog -- The name of the program (default: sys.argv[0])\n        - usage -- A usage message (default: auto-generated from arguments)\n        - description -- A description of what the program does\n        - epilog -- Text following the argument descriptions\n        - parents -- Parsers whose arguments should be copied into this one\n        - formatter_class -- HelpFormatter class for printing help messages\n        - prefix_chars -- Characters that prefix optional arguments\n        - fromfile_prefix_chars -- Characters that prefix files containing\n            additional arguments\n        - argument_default -- The default value for all arguments\n        - conflict_handler -- String indicating how to handle conflicts\n        - add_help -- Add a -h/-help option\n    """"""\n\n    def __init__(self,\n                 prog=None,\n                 usage=None,\n                 description=None,\n                 epilog=None,\n                 version=None,\n                 parents=[],\n                 formatter_class=HelpFormatter,\n                 prefix_chars=\'-\',\n                 fromfile_prefix_chars=None,\n                 argument_default=None,\n                 conflict_handler=\'error\',\n                 add_help=True):\n\n        if version is not None:\n            import warnings\n            warnings.warn(\n                """"""The ""version"" argument to ArgumentParser is deprecated. """"""\n                """"""Please use """"""\n                """"""""add_argument(..., action=\'version\', version=""N"", ...)"" """"""\n                """"""instead"""""", DeprecationWarning)\n\n        superinit = super(ArgumentParser, self).__init__\n        superinit(description=description,\n                  prefix_chars=prefix_chars,\n                  argument_default=argument_default,\n                  conflict_handler=conflict_handler)\n\n        # default setting for prog\n        if prog is None:\n            prog = _os.path.basename(_sys.argv[0])\n\n        self.prog = prog\n        self.usage = usage\n        self.epilog = epilog\n        self.version = version\n        self.formatter_class = formatter_class\n        self.fromfile_prefix_chars = fromfile_prefix_chars\n        self.add_help = add_help\n\n        add_group = self.add_argument_group\n        self._positionals = add_group(_(\'positional arguments\'))\n        self._optionals = add_group(_(\'optional arguments\'))\n        self._subparsers = None\n\n        # register types\n        def identity(string):\n            return string\n        self.register(\'type\', None, identity)\n\n        # add help and version arguments if necessary\n        # (using explicit default to override global argument_default)\n        if \'-\' in prefix_chars:\n            default_prefix = \'-\'\n        else:\n            default_prefix = prefix_chars[0]\n        if self.add_help:\n            self.add_argument(\n                default_prefix+\'h\', default_prefix*2+\'help\',\n                action=\'help\', default=SUPPRESS,\n                help=_(\'show this help message and exit\'))\n        if self.version:\n            self.add_argument(\n                default_prefix+\'v\', default_prefix*2+\'version\',\n                action=\'version\', default=SUPPRESS,\n                version=self.version,\n                help=_(""show program\'s version number and exit""))\n\n        # add parent arguments and defaults\n        for parent in parents:\n            self._add_container_actions(parent)\n            try:\n                defaults = parent._defaults\n            except AttributeError:\n                pass\n            else:\n                self._defaults.update(defaults)\n\n    # =======================\n    # Pretty __repr__ methods\n    # =======================\n    def _get_kwargs(self):\n        names = [\n            \'prog\',\n            \'usage\',\n            \'description\',\n            \'version\',\n            \'formatter_class\',\n            \'conflict_handler\',\n            \'add_help\',\n        ]\n        return [(name, getattr(self, name)) for name in names]\n\n    # ==================================\n    # Optional/Positional adding methods\n    # ==================================\n    def add_subparsers(self, **kwargs):\n        if self._subparsers is not None:\n            self.error(_(\'cannot have multiple subparser arguments\'))\n\n        # add the parser class to the arguments if it\'s not present\n        kwargs.setdefault(\'parser_class\', type(self))\n\n        if \'title\' in kwargs or \'description\' in kwargs:\n            title = _(kwargs.pop(\'title\', \'subcommands\'))\n            description = _(kwargs.pop(\'description\', None))\n            self._subparsers = self.add_argument_group(title, description)\n        else:\n            self._subparsers = self._positionals\n\n        # prog defaults to the usage message of this parser, skipping\n        # optional arguments and with no ""usage:"" prefix\n        if kwargs.get(\'prog\') is None:\n            formatter = self._get_formatter()\n            positionals = self._get_positional_actions()\n            groups = self._mutually_exclusive_groups\n            formatter.add_usage(self.usage, positionals, groups, \'\')\n            kwargs[\'prog\'] = formatter.format_help().strip()\n\n        # create the parsers action and add it to the positionals list\n        parsers_class = self._pop_action_class(kwargs, \'parsers\')\n        action = parsers_class(option_strings=[], **kwargs)\n        self._subparsers._add_action(action)\n\n        # return the created parsers action\n        return action\n\n    def _add_action(self, action):\n        if action.option_strings:\n            self._optionals._add_action(action)\n        else:\n            self._positionals._add_action(action)\n        return action\n\n    def _get_optional_actions(self):\n        return [action\n                for action in self._actions\n                if action.option_strings]\n\n    def _get_positional_actions(self):\n        return [action\n                for action in self._actions\n                if not action.option_strings]\n\n    # =====================================\n    # Command line argument parsing methods\n    # =====================================\n    def parse_args(self, args=None, namespace=None):\n        args, argv = self.parse_known_args(args, namespace)\n        if argv:\n            msg = _(\'unrecognized arguments: %s\')\n            self.error(msg % \' \'.join(argv))\n        return args\n\n    def parse_known_args(self, args=None, namespace=None):\n        # args default to the system args\n        if args is None:\n            args = _sys.argv[1:]\n\n        # default Namespace built from parser defaults\n        if namespace is None:\n            namespace = Namespace()\n\n        # add any action defaults that aren\'t present\n        for action in self._actions:\n            if action.dest is not SUPPRESS:\n                if not hasattr(namespace, action.dest):\n                    if action.default is not SUPPRESS:\n                        default = action.default\n                        if isinstance(action.default, basestring):\n                            default = self._get_value(action, default)\n                        setattr(namespace, action.dest, default)\n\n        # add any parser defaults that aren\'t present\n        for dest in self._defaults:\n            if not hasattr(namespace, dest):\n                setattr(namespace, dest, self._defaults[dest])\n\n        # parse the arguments and exit if there are any errors\n        try:\n            namespace, args = self._parse_known_args(args, namespace)\n            if hasattr(namespace, _UNRECOGNIZED_ARGS_ATTR):\n                args.extend(getattr(namespace, _UNRECOGNIZED_ARGS_ATTR))\n                delattr(namespace, _UNRECOGNIZED_ARGS_ATTR)\n            return namespace, args\n        except ArgumentError:\n            err = _sys.exc_info()[1]\n            self.error(str(err))\n\n    def _parse_known_args(self, arg_strings, namespace):\n        # replace arg strings that are file references\n        if self.fromfile_prefix_chars is not None:\n            arg_strings = self._read_args_from_files(arg_strings)\n\n        # map all mutually exclusive arguments to the other arguments\n        # they can\'t occur with\n        action_conflicts = {}\n        for mutex_group in self._mutually_exclusive_groups:\n            group_actions = mutex_group._group_actions\n            for i, mutex_action in enumerate(mutex_group._group_actions):\n                conflicts = action_conflicts.setdefault(mutex_action, [])\n                conflicts.extend(group_actions[:i])\n                conflicts.extend(group_actions[i + 1:])\n\n        # find all option indices, and determine the arg_string_pattern\n        # which has an \'O\' if there is an option at an index,\n        # an \'A\' if there is an argument, or a \'-\' if there is a \'--\'\n        option_string_indices = {}\n        arg_string_pattern_parts = []\n        arg_strings_iter = iter(arg_strings)\n        for i, arg_string in enumerate(arg_strings_iter):\n\n            # all args after -- are non-options\n            if arg_string == \'--\':\n                arg_string_pattern_parts.append(\'-\')\n                for arg_string in arg_strings_iter:\n                    arg_string_pattern_parts.append(\'A\')\n\n            # otherwise, add the arg to the arg strings\n            # and note the index if it was an option\n            else:\n                option_tuple = self._parse_optional(arg_string)\n                if option_tuple is None:\n                    pattern = \'A\'\n                else:\n                    option_string_indices[i] = option_tuple\n                    pattern = \'O\'\n                arg_string_pattern_parts.append(pattern)\n\n        # join the pieces together to form the pattern\n        arg_strings_pattern = \'\'.join(arg_string_pattern_parts)\n\n        # converts arg strings to the appropriate and then takes the action\n        seen_actions = set()\n        seen_non_default_actions = set()\n\n        def take_action(action, argument_strings, option_string=None):\n            seen_actions.add(action)\n            argument_values = self._get_values(action, argument_strings)\n\n            # error if this argument is not allowed with other previously\n            # seen arguments, assuming that actions that use the default\n            # value don\'t really count as ""present""\n            if argument_values is not action.default:\n                seen_non_default_actions.add(action)\n                for conflict_action in action_conflicts.get(action, []):\n                    if conflict_action in seen_non_default_actions:\n                        msg = _(\'not allowed with argument %s\')\n                        action_name = _get_action_name(conflict_action)\n                        raise ArgumentError(action, msg % action_name)\n\n            # take the action if we didn\'t receive a SUPPRESS value\n            # (e.g. from a default)\n            if argument_values is not SUPPRESS:\n                action(self, namespace, argument_values, option_string)\n\n        # function to convert arg_strings into an optional action\n        def consume_optional(start_index):\n\n            # get the optional identified at this index\n            option_tuple = option_string_indices[start_index]\n            action, option_string, explicit_arg = option_tuple\n\n            # identify additional optionals in the same arg string\n            # (e.g. -xyz is the same as -x -y -z if no args are required)\n            match_argument = self._match_argument\n            action_tuples = []\n            while True:\n\n                # if we found no optional action, skip it\n                if action is None:\n                    extras.append(arg_strings[start_index])\n                    return start_index + 1\n\n                # if there is an explicit argument, try to match the\n                # optional\'s string arguments to only this\n                if explicit_arg is not None:\n                    arg_count = match_argument(action, \'A\')\n\n                    # if the action is a single-dash option and takes no\n                    # arguments, try to parse more single-dash options out\n                    # of the tail of the option string\n                    chars = self.prefix_chars\n                    if arg_count == 0 and option_string[1] not in chars:\n                        action_tuples.append((action, [], option_string))\n                        char = option_string[0]\n                        option_string = char + explicit_arg[0]\n                        new_explicit_arg = explicit_arg[1:] or None\n                        optionals_map = self._option_string_actions\n                        if option_string in optionals_map:\n                            action = optionals_map[option_string]\n                            explicit_arg = new_explicit_arg\n                        else:\n                            msg = _(\'ignored explicit argument %r\')\n                            raise ArgumentError(action, msg % explicit_arg)\n\n                    # if the action expect exactly one argument, we\'ve\n                    # successfully matched the option; exit the loop\n                    elif arg_count == 1:\n                        stop = start_index + 1\n                        args = [explicit_arg]\n                        action_tuples.append((action, args, option_string))\n                        break\n\n                    # error if a double-dash option did not use the\n                    # explicit argument\n                    else:\n                        msg = _(\'ignored explicit argument %r\')\n                        raise ArgumentError(action, msg % explicit_arg)\n\n                # if there is no explicit argument, try to match the\n                # optional\'s string arguments with the following strings\n                # if successful, exit the loop\n                else:\n                    start = start_index + 1\n                    selected_patterns = arg_strings_pattern[start:]\n                    arg_count = match_argument(action, selected_patterns)\n                    stop = start + arg_count\n                    args = arg_strings[start:stop]\n                    action_tuples.append((action, args, option_string))\n                    break\n\n            # add the Optional to the list and return the index at which\n            # the Optional\'s string args stopped\n            assert action_tuples\n            for action, args, option_string in action_tuples:\n                take_action(action, args, option_string)\n            return stop\n\n        # the list of Positionals left to be parsed; this is modified\n        # by consume_positionals()\n        positionals = self._get_positional_actions()\n\n        # function to convert arg_strings into positional actions\n        def consume_positionals(start_index):\n            # match as many Positionals as possible\n            match_partial = self._match_arguments_partial\n            selected_pattern = arg_strings_pattern[start_index:]\n            arg_counts = match_partial(positionals, selected_pattern)\n\n            # slice off the appropriate arg strings for each Positional\n            # and add the Positional and its args to the list\n            for action, arg_count in zip(positionals, arg_counts):\n                args = arg_strings[start_index: start_index + arg_count]\n                start_index += arg_count\n                take_action(action, args)\n\n            # slice off the Positionals that we just parsed and return the\n            # index at which the Positionals\' string args stopped\n            positionals[:] = positionals[len(arg_counts):]\n            return start_index\n\n        # consume Positionals and Optionals alternately, until we have\n        # passed the last option string\n        extras = []\n        start_index = 0\n        if option_string_indices:\n            max_option_string_index = max(option_string_indices)\n        else:\n            max_option_string_index = -1\n        while start_index <= max_option_string_index:\n\n            # consume any Positionals preceding the next option\n            next_option_string_index = min([\n                index\n                for index in option_string_indices\n                if index >= start_index])\n            if start_index != next_option_string_index:\n                positionals_end_index = consume_positionals(start_index)\n\n                # only try to parse the next optional if we didn\'t consume\n                # the option string during the positionals parsing\n                if positionals_end_index > start_index:\n                    start_index = positionals_end_index\n                    continue\n                else:\n                    start_index = positionals_end_index\n\n            # if we consumed all the positionals we could and we\'re not\n            # at the index of an option string, there were extra arguments\n            if start_index not in option_string_indices:\n                strings = arg_strings[start_index:next_option_string_index]\n                extras.extend(strings)\n                start_index = next_option_string_index\n\n            # consume the next optional and any arguments for it\n            start_index = consume_optional(start_index)\n\n        # consume any positionals following the last Optional\n        stop_index = consume_positionals(start_index)\n\n        # if we didn\'t consume all the argument strings, there were extras\n        extras.extend(arg_strings[stop_index:])\n\n        # if we didn\'t use all the Positional objects, there were too few\n        # arg strings supplied.\n        if positionals:\n            self.error(_(\'too few arguments\'))\n\n        # make sure all required actions were present\n        for action in self._actions:\n            if action.required:\n                if action not in seen_actions:\n                    name = _get_action_name(action)\n                    self.error(_(\'argument %s is required\') % name)\n\n        # make sure all required groups had one option present\n        for group in self._mutually_exclusive_groups:\n            if group.required:\n                for action in group._group_actions:\n                    if action in seen_non_default_actions:\n                        break\n\n                # if no actions were used, report the error\n                else:\n                    names = [_get_action_name(action)\n                             for action in group._group_actions\n                             if action.help is not SUPPRESS]\n                    msg = _(\'one of the arguments %s is required\')\n                    self.error(msg % \' \'.join(names))\n\n        # return the updated namespace and the extra arguments\n        return namespace, extras\n\n    def _read_args_from_files(self, arg_strings):\n        # expand arguments referencing files\n        new_arg_strings = []\n        for arg_string in arg_strings:\n\n            # for regular arguments, just add them back into the list\n            if arg_string[0] not in self.fromfile_prefix_chars:\n                new_arg_strings.append(arg_string)\n\n            # replace arguments referencing files with the file content\n            else:\n                try:\n                    args_file = open(arg_string[1:])\n                    try:\n                        arg_strings = []\n                        for arg_line in args_file.read().splitlines():\n                            for arg in self.convert_arg_line_to_args(arg_line):\n                                arg_strings.append(arg)\n                        arg_strings = self._read_args_from_files(arg_strings)\n                        new_arg_strings.extend(arg_strings)\n                    finally:\n                        args_file.close()\n                except IOError:\n                    err = _sys.exc_info()[1]\n                    self.error(str(err))\n\n        # return the modified argument list\n        return new_arg_strings\n\n    def convert_arg_line_to_args(self, arg_line):\n        return [arg_line]\n\n    def _match_argument(self, action, arg_strings_pattern):\n        # match the pattern for this action to the arg strings\n        nargs_pattern = self._get_nargs_pattern(action)\n        match = _re.match(nargs_pattern, arg_strings_pattern)\n\n        # raise an exception if we weren\'t able to find a match\n        if match is None:\n            nargs_errors = {\n                None: _(\'expected one argument\'),\n                OPTIONAL: _(\'expected at most one argument\'),\n                ONE_OR_MORE: _(\'expected at least one argument\'),\n            }\n            default = _(\'expected %s argument(s)\') % action.nargs\n            msg = nargs_errors.get(action.nargs, default)\n            raise ArgumentError(action, msg)\n\n        # return the number of arguments matched\n        return len(match.group(1))\n\n    def _match_arguments_partial(self, actions, arg_strings_pattern):\n        # progressively shorten the actions list by slicing off the\n        # final actions until we find a match\n        result = []\n        for i in range(len(actions), 0, -1):\n            actions_slice = actions[:i]\n            pattern = \'\'.join([self._get_nargs_pattern(action)\n                               for action in actions_slice])\n            match = _re.match(pattern, arg_strings_pattern)\n            if match is not None:\n                result.extend([len(string) for string in match.groups()])\n                break\n\n        # return the list of arg string counts\n        return result\n\n    def _parse_optional(self, arg_string):\n        # if it\'s an empty string, it was meant to be a positional\n        if not arg_string:\n            return None\n\n        # if it doesn\'t start with a prefix, it was meant to be positional\n        if not arg_string[0] in self.prefix_chars:\n            return None\n\n        # if the option string is present in the parser, return the action\n        if arg_string in self._option_string_actions:\n            action = self._option_string_actions[arg_string]\n            return action, arg_string, None\n\n        # if it\'s just a single character, it was meant to be positional\n        if len(arg_string) == 1:\n            return None\n\n        # if the option string before the ""="" is present, return the action\n        if \'=\' in arg_string:\n            option_string, explicit_arg = arg_string.split(\'=\', 1)\n            if option_string in self._option_string_actions:\n                action = self._option_string_actions[option_string]\n                return action, option_string, explicit_arg\n\n        # search through all possible prefixes of the option string\n        # and all actions in the parser for possible interpretations\n        option_tuples = self._get_option_tuples(arg_string)\n\n        # if multiple actions match, the option string was ambiguous\n        if len(option_tuples) > 1:\n            options = \', \'.join([option_string\n                for action, option_string, explicit_arg in option_tuples])\n            tup = arg_string, options\n            self.error(_(\'ambiguous option: %s could match %s\') % tup)\n\n        # if exactly one action matched, this segmentation is good,\n        # so return the parsed action\n        elif len(option_tuples) == 1:\n            option_tuple, = option_tuples\n            return option_tuple\n\n        # if it was not found as an option, but it looks like a negative\n        # number, it was meant to be positional\n        # unless there are negative-number-like options\n        if self._negative_number_matcher.match(arg_string):\n            if not self._has_negative_number_optionals:\n                return None\n\n        # if it contains a space, it was meant to be a positional\n        if \' \' in arg_string:\n            return None\n\n        # it was meant to be an optional but there is no such option\n        # in this parser (though it might be a valid option in a subparser)\n        return None, arg_string, None\n\n    def _get_option_tuples(self, option_string):\n        result = []\n\n        # option strings starting with two prefix characters are only\n        # split at the \'=\'\n        chars = self.prefix_chars\n        if option_string[0] in chars and option_string[1] in chars:\n            if \'=\' in option_string:\n                option_prefix, explicit_arg = option_string.split(\'=\', 1)\n            else:\n                option_prefix = option_string\n                explicit_arg = None\n            for option_string in self._option_string_actions:\n                if option_string.startswith(option_prefix):\n                    action = self._option_string_actions[option_string]\n                    tup = action, option_string, explicit_arg\n                    result.append(tup)\n\n        # single character options can be concatenated with their arguments\n        # but multiple character options always have to have their argument\n        # separate\n        elif option_string[0] in chars and option_string[1] not in chars:\n            option_prefix = option_string\n            explicit_arg = None\n            short_option_prefix = option_string[:2]\n            short_explicit_arg = option_string[2:]\n\n            for option_string in self._option_string_actions:\n                if option_string == short_option_prefix:\n                    action = self._option_string_actions[option_string]\n                    tup = action, option_string, short_explicit_arg\n                    result.append(tup)\n                elif option_string.startswith(option_prefix):\n                    action = self._option_string_actions[option_string]\n                    tup = action, option_string, explicit_arg\n                    result.append(tup)\n\n        # shouldn\'t ever get here\n        else:\n            self.error(_(\'unexpected option string: %s\') % option_string)\n\n        # return the collected option tuples\n        return result\n\n    def _get_nargs_pattern(self, action):\n        # in all examples below, we have to allow for \'--\' args\n        # which are represented as \'-\' in the pattern\n        nargs = action.nargs\n\n        # the default (None) is assumed to be a single argument\n        if nargs is None:\n            nargs_pattern = \'(-*A-*)\'\n\n        # allow zero or one arguments\n        elif nargs == OPTIONAL:\n            nargs_pattern = \'(-*A?-*)\'\n\n        # allow zero or more arguments\n        elif nargs == ZERO_OR_MORE:\n            nargs_pattern = \'(-*[A-]*)\'\n\n        # allow one or more arguments\n        elif nargs == ONE_OR_MORE:\n            nargs_pattern = \'(-*A[A-]*)\'\n\n        # allow any number of options or arguments\n        elif nargs == REMAINDER:\n            nargs_pattern = \'([-AO]*)\'\n\n        # allow one argument followed by any number of options or arguments\n        elif nargs == PARSER:\n            nargs_pattern = \'(-*A[-AO]*)\'\n\n        # all others should be integers\n        else:\n            nargs_pattern = \'(-*%s-*)\' % \'-*\'.join(\'A\' * nargs)\n\n        # if this is an optional action, -- is not allowed\n        if action.option_strings:\n            nargs_pattern = nargs_pattern.replace(\'-*\', \'\')\n            nargs_pattern = nargs_pattern.replace(\'-\', \'\')\n\n        # return the pattern\n        return nargs_pattern\n\n    # ========================\n    # Value conversion methods\n    # ========================\n    def _get_values(self, action, arg_strings):\n        # for everything but PARSER args, strip out \'--\'\n        if action.nargs not in [PARSER, REMAINDER]:\n            arg_strings = [s for s in arg_strings if s != \'--\']\n\n        # optional argument produces a default when not present\n        if not arg_strings and action.nargs == OPTIONAL:\n            if action.option_strings:\n                value = action.const\n            else:\n                value = action.default\n            if isinstance(value, basestring):\n                value = self._get_value(action, value)\n                self._check_value(action, value)\n\n        # when nargs=\'*\' on a positional, if there were no command-line\n        # args, use the default if it is anything other than None\n        elif (not arg_strings and action.nargs == ZERO_OR_MORE and\n              not action.option_strings):\n            if action.default is not None:\n                value = action.default\n            else:\n                value = arg_strings\n            self._check_value(action, value)\n\n        # single argument or optional argument produces a single value\n        elif len(arg_strings) == 1 and action.nargs in [None, OPTIONAL]:\n            arg_string, = arg_strings\n            value = self._get_value(action, arg_string)\n            self._check_value(action, value)\n\n        # REMAINDER arguments convert all values, checking none\n        elif action.nargs == REMAINDER:\n            value = [self._get_value(action, v) for v in arg_strings]\n\n        # PARSER arguments convert all values, but check only the first\n        elif action.nargs == PARSER:\n            value = [self._get_value(action, v) for v in arg_strings]\n            self._check_value(action, value[0])\n\n        # all other types of nargs produce a list\n        else:\n            value = [self._get_value(action, v) for v in arg_strings]\n            for v in value:\n                self._check_value(action, v)\n\n        # return the converted value\n        return value\n\n    def _get_value(self, action, arg_string):\n        type_func = self._registry_get(\'type\', action.type, action.type)\n        if not _callable(type_func):\n            msg = _(\'%r is not callable\')\n            raise ArgumentError(action, msg % type_func)\n\n        # convert the value to the appropriate type\n        try:\n            result = type_func(arg_string)\n\n        # ArgumentTypeErrors indicate errors\n        except ArgumentTypeError:\n            name = getattr(action.type, \'__name__\', repr(action.type))\n            msg = str(_sys.exc_info()[1])\n            raise ArgumentError(action, msg)\n\n        # TypeErrors or ValueErrors also indicate errors\n        except (TypeError, ValueError):\n            name = getattr(action.type, \'__name__\', repr(action.type))\n            msg = _(\'invalid %s value: %r\')\n            raise ArgumentError(action, msg % (name, arg_string))\n\n        # return the converted value\n        return result\n\n    def _check_value(self, action, value):\n        # converted value must be one of the choices (if specified)\n        if action.choices is not None and value not in action.choices:\n            tup = value, \', \'.join(map(repr, action.choices))\n            msg = _(\'invalid choice: %r (choose from %s)\') % tup\n            raise ArgumentError(action, msg)\n\n    # =======================\n    # Help-formatting methods\n    # =======================\n    def format_usage(self):\n        formatter = self._get_formatter()\n        formatter.add_usage(self.usage, self._actions,\n                            self._mutually_exclusive_groups)\n        return formatter.format_help()\n\n    def format_help(self):\n        formatter = self._get_formatter()\n\n        # usage\n        formatter.add_usage(self.usage, self._actions,\n                            self._mutually_exclusive_groups)\n\n        # description\n        formatter.add_text(self.description)\n\n        # positionals, optionals and user-defined groups\n        for action_group in self._action_groups:\n            formatter.start_section(action_group.title)\n            formatter.add_text(action_group.description)\n            formatter.add_arguments(action_group._group_actions)\n            formatter.end_section()\n\n        # epilog\n        formatter.add_text(self.epilog)\n\n        # determine help from format above\n        return formatter.format_help()\n\n    def format_version(self):\n        import warnings\n        warnings.warn(\n            \'The format_version method is deprecated -- the ""version"" \'\n            \'argument to ArgumentParser is no longer supported.\',\n            DeprecationWarning)\n        formatter = self._get_formatter()\n        formatter.add_text(self.version)\n        return formatter.format_help()\n\n    def _get_formatter(self):\n        return self.formatter_class(prog=self.prog)\n\n    # =====================\n    # Help-printing methods\n    # =====================\n    def print_usage(self, file=None):\n        if file is None:\n            file = _sys.stdout\n        self._print_message(self.format_usage(), file)\n\n    def print_help(self, file=None):\n        if file is None:\n            file = _sys.stdout\n        self._print_message(self.format_help(), file)\n\n    def print_version(self, file=None):\n        import warnings\n        warnings.warn(\n            \'The print_version method is deprecated -- the ""version"" \'\n            \'argument to ArgumentParser is no longer supported.\',\n            DeprecationWarning)\n        self._print_message(self.format_version(), file)\n\n    def _print_message(self, message, file=None):\n        if message:\n            if file is None:\n                file = _sys.stderr\n            file.write(message)\n\n    # ===============\n    # Exiting methods\n    # ===============\n    def exit(self, status=0, message=None):\n        if message:\n            self._print_message(message, _sys.stderr)\n        _sys.exit(status)\n\n    def error(self, message):\n        """"""error(message: string)\n\n        Prints a usage message incorporating the message to stderr and\n        exits.\n\n        If you override this in a subclass, it should not return -- it\n        should either exit or raise an exception.\n        """"""\n        self.print_usage(_sys.stderr)\n        self.exit(2, _(\'%s: error: %s\\n\') % (self.prog, message))\n'"
rootpy/extern/close_variable.py,0,"b'# Code taken from http://stackoverflow.com/questions/3908335/python-function-local-name-binding-from-an-outer-scope\n\nfrom .six.moves import range\n\n# Opcode constants used for comparison and replacecment\nLOAD_FAST = opcode.opmap[\'LOAD_FAST\']\nLOAD_GLOBAL = opcode.opmap[\'LOAD_GLOBAL\']\nSTORE_FAST = opcode.opmap[\'STORE_FAST\']\n\nDEBUGGING = True\n\ndef append_arguments(code_obj, new_locals):\n    co_varnames = code_obj.co_varnames   # Old locals\n    co_names = code_obj.co_names      # Old globals\n    co_argcount = code_obj.co_argcount     # Argument count\n    co_code = code_obj.co_code         # The actual bytecode as a string\n\n    # Make one pass over the bytecode to identify names that should be\n    # left in code_obj.co_names.\n    not_removed = set(opcode.hasname) - set([LOAD_GLOBAL])\n    saved_names = set()\n    for inst in instructions(co_code):\n        if inst[0] in not_removed:\n            saved_names.add(co_names[inst[1]])\n\n    # Build co_names for the new code object. This should consist of\n    # globals that were only accessed via LOAD_GLOBAL\n    names = tuple(name for name in co_names\n                  if name not in set(new_locals) - saved_names)\n\n    # Build a dictionary that maps the indices of the entries in co_names\n    # to their entry in the new co_names\n    name_translations = dict((co_names.index(name), i)\n                             for i, name in enumerate(names))\n\n    # Build co_varnames for the new code object. This should consist of\n    # the entirety of co_varnames with new_locals spliced in after the\n    # arguments\n    new_locals_len = len(new_locals)\n    varnames = (co_varnames[:co_argcount] + new_locals +\n                co_varnames[co_argcount:])\n\n    # Build the dictionary that maps indices of entries in the old co_varnames\n    # to their indices in the new co_varnames\n    range1, range2 = range(co_argcount), range(co_argcount, len(co_varnames))\n    varname_translations = dict((i, i) for i in range1)\n    varname_translations.update((i, i + new_locals_len) for i in range2)\n\n    # Build the dictionary that maps indices of deleted entries of co_names\n    # to their indices in the new co_varnames\n    names_to_varnames = dict((co_names.index(name), varnames.index(name))\n                             for name in new_locals)\n\n    # Now we modify the actual bytecode\n    modified = []\n    for inst in instructions(code_obj.co_code):\n        # If the instruction is a LOAD_GLOBAL, we have to check to see if\n        # it\'s one of the globals that we are replacing. Either way,\n        # update its arg using the appropriate dict.\n        if inst[0] == LOAD_GLOBAL:\n            print(""LOAD_GLOBAL: {0}"".format(inst[1]))\n            if inst[1] in names_to_varnames:\n                print(""replacing with {0}: "".format(names_to_varnames[inst[1]]))\n                inst[0] = LOAD_FAST\n                inst[1] = names_to_varnames[inst[1]]\n            elif inst[1] in name_translations:\n                inst[1] = name_translations[inst[1]]\n            else:\n                raise ValueError(""a name was lost in translation"")\n        # If it accesses co_varnames or co_names then update its argument.\n        elif inst[0] in opcode.haslocal:\n            inst[1] = varname_translations[inst[1]]\n        elif inst[0] in opcode.hasname:\n            inst[1] = name_translations[inst[1]]\n        modified.extend(write_instruction(inst))\n\n    code = \'\'.join(modified)\n    # Done modifying codestring - make the code object\n\n    return types.CodeType(co_argcount + new_locals_len,\n                          code_obj.co_nlocals + new_locals_len,\n                          code_obj.co_stacksize,\n                          code_obj.co_flags,\n                          code,\n                          code_obj.co_consts,\n                          names,\n                          varnames,\n                          code_obj.co_filename,\n                          code_obj.co_name,\n                          code_obj.co_firstlineno,\n                          code_obj.co_lnotab)\n\ndef instructions(code):\n    code = map(ord, code)\n    i, L = 0, len(code)\n    extended_arg = 0\n    while i < L:\n        op = code[i]\n        i+= 1\n        if op < opcode.HAVE_ARGUMENT:\n            yield [op, None]\n            continue\n        oparg = code[i] + (code[i+1] << 8) + extended_arg\n        extended_arg = 0\n        i += 2\n        if op == opcode.EXTENDED_ARG:\n            extended_arg = oparg << 16\n            continue\n        yield [op, oparg]\n'"
rootpy/extern/ordereddict.py,0,"b'# Copyright (c) 2009 Raymond Hettinger\r\n#\r\n# Permission is hereby granted, free of charge, to any person\r\n# obtaining a copy of this software and associated documentation files\r\n# (the ""Software""), to deal in the Software without restriction,\r\n# including without limitation the rights to use, copy, modify, merge,\r\n# publish, distribute, sublicense, and/or sell copies of the Software,\r\n# and to permit persons to whom the Software is furnished to do so,\r\n# subject to the following conditions:\r\n#\r\n#     The above copyright notice and this permission notice shall be\r\n#     included in all copies or substantial portions of the Software.\r\n#\r\n#     THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,\r\n#     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\r\n#     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n#     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\r\n#     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\r\n#     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\r\n#     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\r\n#     OTHER DEALINGS IN THE SOFTWARE.\r\n\r\nfrom UserDict import DictMixin\r\n\r\nclass OrderedDict(dict, DictMixin):\r\n\r\n    def __init__(self, *args, **kwds):\r\n        if len(args) > 1:\r\n            raise TypeError(\'expected at most 1 arguments, got %d\' % len(args))\r\n        try:\r\n            self.__end\r\n        except AttributeError:\r\n            self.clear()\r\n        self.update(*args, **kwds)\r\n\r\n    def clear(self):\r\n        self.__end = end = []\r\n        end += [None, end, end]         # sentinel node for doubly linked list\r\n        self.__map = {}                 # key --> [key, prev, next]\r\n        dict.clear(self)\r\n\r\n    def __setitem__(self, key, value):\r\n        if key not in self:\r\n            end = self.__end\r\n            curr = end[1]\r\n            curr[2] = end[1] = self.__map[key] = [key, curr, end]\r\n        dict.__setitem__(self, key, value)\r\n\r\n    def __delitem__(self, key):\r\n        dict.__delitem__(self, key)\r\n        key, prev, next = self.__map.pop(key)\r\n        prev[2] = next\r\n        next[1] = prev\r\n\r\n    def __iter__(self):\r\n        end = self.__end\r\n        curr = end[2]\r\n        while curr is not end:\r\n            yield curr[0]\r\n            curr = curr[2]\r\n\r\n    def __reversed__(self):\r\n        end = self.__end\r\n        curr = end[1]\r\n        while curr is not end:\r\n            yield curr[0]\r\n            curr = curr[1]\r\n\r\n    def popitem(self, last=True):\r\n        if not self:\r\n            raise KeyError(\'dictionary is empty\')\r\n        if last:\r\n            key = reversed(self).next()\r\n        else:\r\n            key = iter(self).next()\r\n        value = self.pop(key)\r\n        return key, value\r\n\r\n    def __reduce__(self):\r\n        items = [[k, self[k]] for k in self]\r\n        tmp = self.__map, self.__end\r\n        del self.__map, self.__end\r\n        inst_dict = vars(self).copy()\r\n        self.__map, self.__end = tmp\r\n        if inst_dict:\r\n            return (self.__class__, (items,), inst_dict)\r\n        return self.__class__, (items,)\r\n\r\n    def keys(self):\r\n        return list(self)\r\n\r\n    setdefault = DictMixin.setdefault\r\n    update = DictMixin.update\r\n    pop = DictMixin.pop\r\n    values = DictMixin.values\r\n    items = DictMixin.items\r\n    iterkeys = DictMixin.iterkeys\r\n    itervalues = DictMixin.itervalues\r\n    iteritems = DictMixin.iteritems\r\n\r\n    def __repr__(self):\r\n        if not self:\r\n            return \'%s()\' % (self.__class__.__name__,)\r\n        return \'%s(%r)\' % (self.__class__.__name__, self.items())\r\n\r\n    def copy(self):\r\n        return self.__class__(self)\r\n\r\n    @classmethod\r\n    def fromkeys(cls, iterable, value=None):\r\n        d = cls()\r\n        for key in iterable:\r\n            d[key] = value\r\n        return d\r\n\r\n    def __eq__(self, other):\r\n        if isinstance(other, OrderedDict):\r\n            if len(self) != len(other):\r\n                return False\r\n            for p, q in  zip(self.items(), other.items()):\r\n                if p != q:\r\n                    return False\r\n            return True\r\n        return dict.__eq__(self, other)\r\n\r\n    def __ne__(self, other):\r\n        return not self == other\r\n'"
rootpy/extern/pyparsing.py,0,"b'# module pyparsing.py\r\n#\r\n# Copyright (c) 2003-2013  Paul T. McGuire\r\n#\r\n# Permission is hereby granted, free of charge, to any person obtaining\r\n# a copy of this software and associated documentation files (the\r\n# ""Software""), to deal in the Software without restriction, including\r\n# without limitation the rights to use, copy, modify, merge, publish,\r\n# distribute, sublicense, and/or sell copies of the Software, and to\r\n# permit persons to whom the Software is furnished to do so, subject to\r\n# the following conditions:\r\n#\r\n# The above copyright notice and this permission notice shall be\r\n# included in all copies or substantial portions of the Software.\r\n#\r\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,\r\n# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\r\n# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\r\n# CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\r\n# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\r\n# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n#\r\n\r\n__doc__ = \\\r\n""""""\r\npyparsing module - Classes and methods to define and execute parsing grammars\r\n\r\nThe pyparsing module is an alternative approach to creating and executing simple grammars,\r\nvs. the traditional lex/yacc approach, or the use of regular expressions.  With pyparsing, you\r\ndon\'t need to learn a new syntax for defining grammars or matching expressions - the parsing module\r\nprovides a library of classes that you use to construct the grammar directly in Python.\r\n\r\nHere is a program to parse ""Hello, World!"" (or any greeting of the form C{""<salutation>, <addressee>!""})::\r\n\r\n    from pyparsing import Word, alphas\r\n\r\n    # define grammar of a greeting\r\n    greet = Word( alphas ) + "","" + Word( alphas ) + ""!""\r\n\r\n    hello = ""Hello, World!""\r\n    print (hello, ""->"", greet.parseString( hello ))\r\n\r\nThe program outputs the following::\r\n\r\n    Hello, World! -> [\'Hello\', \',\', \'World\', \'!\']\r\n\r\nThe Python representation of the grammar is quite readable, owing to the self-explanatory\r\nclass names, and the use of \'+\', \'|\' and \'^\' operators.\r\n\r\nThe parsed results returned from C{parseString()} can be accessed as a nested list, a dictionary, or an\r\nobject with named attributes.\r\n\r\nThe pyparsing module handles some of the problems that are typically vexing when writing text parsers:\r\n - extra or missing whitespace (the above program will also handle ""Hello,World!"", ""Hello  ,  World  !"", etc.)\r\n - quoted strings\r\n - embedded comments\r\n""""""\r\n\r\n__version__ = ""2.0.3""\r\n__versionTime__ = ""16 Aug 2014 00:12""\r\n__author__ = ""Paul McGuire <ptmcg@users.sourceforge.net>""\r\n\r\nimport string\r\nfrom weakref import ref as wkref\r\nimport copy\r\nimport sys\r\nimport warnings\r\nimport re\r\nimport sre_constants\r\nimport collections\r\nimport pprint\r\n#~ sys.stderr.write( ""testing pyparsing module, version %s, %s\\n"" % (__version__,__versionTime__ ) )\r\n\r\n__all__ = [\r\n\'And\', \'CaselessKeyword\', \'CaselessLiteral\', \'CharsNotIn\', \'Combine\', \'Dict\', \'Each\', \'Empty\',\r\n\'FollowedBy\', \'Forward\', \'GoToColumn\', \'Group\', \'Keyword\', \'LineEnd\', \'LineStart\', \'Literal\',\r\n\'MatchFirst\', \'NoMatch\', \'NotAny\', \'OneOrMore\', \'OnlyOnce\', \'Optional\', \'Or\',\r\n\'ParseBaseException\', \'ParseElementEnhance\', \'ParseException\', \'ParseExpression\', \'ParseFatalException\',\r\n\'ParseResults\', \'ParseSyntaxException\', \'ParserElement\', \'QuotedString\', \'RecursiveGrammarException\',\r\n\'Regex\', \'SkipTo\', \'StringEnd\', \'StringStart\', \'Suppress\', \'Token\', \'TokenConverter\', \'Upcase\',\r\n\'White\', \'Word\', \'WordEnd\', \'WordStart\', \'ZeroOrMore\',\r\n\'alphanums\', \'alphas\', \'alphas8bit\', \'anyCloseTag\', \'anyOpenTag\', \'cStyleComment\', \'col\',\r\n\'commaSeparatedList\', \'commonHTMLEntity\', \'countedArray\', \'cppStyleComment\', \'dblQuotedString\',\r\n\'dblSlashComment\', \'delimitedList\', \'dictOf\', \'downcaseTokens\', \'empty\', \'hexnums\',\r\n\'htmlComment\', \'javaStyleComment\', \'keepOriginalText\', \'line\', \'lineEnd\', \'lineStart\', \'lineno\',\r\n\'makeHTMLTags\', \'makeXMLTags\', \'matchOnlyAtCol\', \'matchPreviousExpr\', \'matchPreviousLiteral\',\r\n\'nestedExpr\', \'nullDebugAction\', \'nums\', \'oneOf\', \'opAssoc\', \'operatorPrecedence\', \'printables\',\r\n\'punc8bit\', \'pythonStyleComment\', \'quotedString\', \'removeQuotes\', \'replaceHTMLEntity\', \r\n\'replaceWith\', \'restOfLine\', \'sglQuotedString\', \'srange\', \'stringEnd\',\r\n\'stringStart\', \'traceParseAction\', \'unicodeString\', \'upcaseTokens\', \'withAttribute\',\r\n\'indentedBlock\', \'originalTextFor\', \'ungroup\', \'infixNotation\',\'locatedExpr\',\r\n]\r\n\r\nPY_3 = sys.version.startswith(\'3\')\r\nif PY_3:\r\n    _MAX_INT = sys.maxsize\r\n    basestring = str\r\n    unichr = chr\r\n    _ustr = str\r\n\r\n    # build list of single arg builtins, that can be used as parse actions\r\n    singleArgBuiltins = [sum, len, sorted, reversed, list, tuple, set, any, all, min, max]\r\n\r\nelse:\r\n    _MAX_INT = sys.maxint\r\n    range = xrange\r\n\r\n    def _ustr(obj):\r\n        """"""Drop-in replacement for str(obj) that tries to be Unicode friendly. It first tries\r\n           str(obj). If that fails with a UnicodeEncodeError, then it tries unicode(obj). It\r\n           then < returns the unicode object | encodes it with the default encoding | ... >.\r\n        """"""\r\n        if isinstance(obj,unicode):\r\n            return obj\r\n\r\n        try:\r\n            # If this works, then _ustr(obj) has the same behaviour as str(obj), so\r\n            # it won\'t break any existing code.\r\n            return str(obj)\r\n\r\n        except UnicodeEncodeError:\r\n            # The Python docs (http://docs.python.org/ref/customization.html#l2h-182)\r\n            # state that ""The return value must be a string object"". However, does a\r\n            # unicode object (being a subclass of basestring) count as a ""string\r\n            # object""?\r\n            # If so, then return a unicode object:\r\n            return unicode(obj)\r\n            # Else encode it... but how? There are many choices... :)\r\n            # Replace unprintables with escape codes?\r\n            #return unicode(obj).encode(sys.getdefaultencoding(), \'backslashreplace_errors\')\r\n            # Replace unprintables with question marks?\r\n            #return unicode(obj).encode(sys.getdefaultencoding(), \'replace\')\r\n            # ...\r\n\r\n    # build list of single arg builtins, tolerant of Python version, that can be used as parse actions\r\n    singleArgBuiltins = []\r\n    import __builtin__\r\n    for fname in ""sum len sorted reversed list tuple set any all min max"".split():\r\n        try:\r\n            singleArgBuiltins.append(getattr(__builtin__,fname))\r\n        except AttributeError:\r\n            continue\r\n            \r\n_generatorType = type((y for y in range(1)))\r\n \r\ndef _xml_escape(data):\r\n    """"""Escape &, <, >, "", \', etc. in a string of data.""""""\r\n\r\n    # ampersand must be replaced first\r\n    from_symbols = \'&><""\\\'\'\r\n    to_symbols = (\'&\'+s+\';\' for s in ""amp gt lt quot apos"".split())\r\n    for from_,to_ in zip(from_symbols, to_symbols):\r\n        data = data.replace(from_, to_)\r\n    return data\r\n\r\nclass _Constants(object):\r\n    pass\r\n\r\nalphas = string.ascii_lowercase + string.ascii_uppercase\r\nnums       = ""0123456789""\r\nhexnums    = nums + ""ABCDEFabcdef""\r\nalphanums  = alphas + nums\r\n_bslash    = chr(92)\r\nprintables = """".join(c for c in string.printable if c not in string.whitespace)\r\n\r\nclass ParseBaseException(Exception):\r\n    """"""base exception class for all parsing runtime exceptions""""""\r\n    # Performance tuning: we construct a *lot* of these, so keep this\r\n    # constructor as small and fast as possible\r\n    def __init__( self, pstr, loc=0, msg=None, elem=None ):\r\n        self.loc = loc\r\n        if msg is None:\r\n            self.msg = pstr\r\n            self.pstr = """"\r\n        else:\r\n            self.msg = msg\r\n            self.pstr = pstr\r\n        self.parserElement = elem\r\n\r\n    def __getattr__( self, aname ):\r\n        """"""supported attributes by name are:\r\n            - lineno - returns the line number of the exception text\r\n            - col - returns the column number of the exception text\r\n            - line - returns the line containing the exception text\r\n        """"""\r\n        if( aname == ""lineno"" ):\r\n            return lineno( self.loc, self.pstr )\r\n        elif( aname in (""col"", ""column"") ):\r\n            return col( self.loc, self.pstr )\r\n        elif( aname == ""line"" ):\r\n            return line( self.loc, self.pstr )\r\n        else:\r\n            raise AttributeError(aname)\r\n\r\n    def __str__( self ):\r\n        return ""%s (at char %d), (line:%d, col:%d)"" % \\\r\n                ( self.msg, self.loc, self.lineno, self.column )\r\n    def __repr__( self ):\r\n        return _ustr(self)\r\n    def markInputline( self, markerString = "">!<"" ):\r\n        """"""Extracts the exception line from the input string, and marks\r\n           the location of the exception with a special symbol.\r\n        """"""\r\n        line_str = self.line\r\n        line_column = self.column - 1\r\n        if markerString:\r\n            line_str = """".join((line_str[:line_column],\r\n                                markerString, line_str[line_column:]))\r\n        return line_str.strip()\r\n    def __dir__(self):\r\n        return ""loc msg pstr parserElement lineno col line "" \\\r\n               ""markInputline __str__ __repr__"".split()\r\n\r\nclass ParseException(ParseBaseException):\r\n    """"""exception thrown when parse expressions don\'t match class;\r\n       supported attributes by name are:\r\n        - lineno - returns the line number of the exception text\r\n        - col - returns the column number of the exception text\r\n        - line - returns the line containing the exception text\r\n    """"""\r\n    pass\r\n\r\nclass ParseFatalException(ParseBaseException):\r\n    """"""user-throwable exception thrown when inconsistent parse content\r\n       is found; stops all parsing immediately""""""\r\n    pass\r\n\r\nclass ParseSyntaxException(ParseFatalException):\r\n    """"""just like C{L{ParseFatalException}}, but thrown internally when an\r\n       C{L{ErrorStop<And._ErrorStop>}} (\'-\' operator) indicates that parsing is to stop immediately because\r\n       an unbacktrackable syntax error has been found""""""\r\n    def __init__(self, pe):\r\n        super(ParseSyntaxException, self).__init__(\r\n                                    pe.pstr, pe.loc, pe.msg, pe.parserElement)\r\n\r\n#~ class ReparseException(ParseBaseException):\r\n    #~ """"""Experimental class - parse actions can raise this exception to cause\r\n       #~ pyparsing to reparse the input string:\r\n        #~ - with a modified input string, and/or\r\n        #~ - with a modified start location\r\n       #~ Set the values of the ReparseException in the constructor, and raise the\r\n       #~ exception in a parse action to cause pyparsing to use the new string/location.\r\n       #~ Setting the values as None causes no change to be made.\r\n       #~ """"""\r\n    #~ def __init_( self, newstring, restartLoc ):\r\n        #~ self.newParseText = newstring\r\n        #~ self.reparseLoc = restartLoc\r\n\r\nclass RecursiveGrammarException(Exception):\r\n    """"""exception thrown by C{validate()} if the grammar could be improperly recursive""""""\r\n    def __init__( self, parseElementList ):\r\n        self.parseElementTrace = parseElementList\r\n\r\n    def __str__( self ):\r\n        return ""RecursiveGrammarException: %s"" % self.parseElementTrace\r\n\r\nclass _ParseResultsWithOffset(object):\r\n    def __init__(self,p1,p2):\r\n        self.tup = (p1,p2)\r\n    def __getitem__(self,i):\r\n        return self.tup[i]\r\n    def __repr__(self):\r\n        return repr(self.tup)\r\n    def setOffset(self,i):\r\n        self.tup = (self.tup[0],i)\r\n\r\nclass ParseResults(object):\r\n    """"""Structured parse results, to provide multiple means of access to the parsed data:\r\n       - as a list (C{len(results)})\r\n       - by list index (C{results[0], results[1]}, etc.)\r\n       - by attribute (C{results.<resultsName>})\r\n       """"""\r\n    def __new__(cls, toklist, name=None, asList=True, modal=True ):\r\n        if isinstance(toklist, cls):\r\n            return toklist\r\n        retobj = object.__new__(cls)\r\n        retobj.__doinit = True\r\n        return retobj\r\n\r\n    # Performance tuning: we construct a *lot* of these, so keep this\r\n    # constructor as small and fast as possible\r\n    def __init__( self, toklist, name=None, asList=True, modal=True, isinstance=isinstance ):\r\n        if self.__doinit:\r\n            self.__doinit = False\r\n            self.__name = None\r\n            self.__parent = None\r\n            self.__accumNames = {}\r\n            if isinstance(toklist, list):\r\n                self.__toklist = toklist[:]\r\n            elif isinstance(toklist, _generatorType):\r\n                self.__toklist = list(toklist)\r\n            else:\r\n                self.__toklist = [toklist]\r\n            self.__tokdict = dict()\r\n\r\n        if name is not None and name:\r\n            if not modal:\r\n                self.__accumNames[name] = 0\r\n            if isinstance(name,int):\r\n                name = _ustr(name) # will always return a str, but use _ustr for consistency\r\n            self.__name = name\r\n            if not (isinstance(toklist, (type(None), basestring, list)) and toklist in (None,\'\',[])):\r\n                if isinstance(toklist,basestring):\r\n                    toklist = [ toklist ]\r\n                if asList:\r\n                    if isinstance(toklist,ParseResults):\r\n                        self[name] = _ParseResultsWithOffset(toklist.copy(),0)\r\n                    else:\r\n                        self[name] = _ParseResultsWithOffset(ParseResults(toklist[0]),0)\r\n                    self[name].__name = name\r\n                else:\r\n                    try:\r\n                        self[name] = toklist[0]\r\n                    except (KeyError,TypeError,IndexError):\r\n                        self[name] = toklist\r\n\r\n    def __getitem__( self, i ):\r\n        if isinstance( i, (int,slice) ):\r\n            return self.__toklist[i]\r\n        else:\r\n            if i not in self.__accumNames:\r\n                return self.__tokdict[i][-1][0]\r\n            else:\r\n                return ParseResults([ v[0] for v in self.__tokdict[i] ])\r\n\r\n    def __setitem__( self, k, v, isinstance=isinstance ):\r\n        if isinstance(v,_ParseResultsWithOffset):\r\n            self.__tokdict[k] = self.__tokdict.get(k,list()) + [v]\r\n            sub = v[0]\r\n        elif isinstance(k,int):\r\n            self.__toklist[k] = v\r\n            sub = v\r\n        else:\r\n            self.__tokdict[k] = self.__tokdict.get(k,list()) + [_ParseResultsWithOffset(v,0)]\r\n            sub = v\r\n        if isinstance(sub,ParseResults):\r\n            sub.__parent = wkref(self)\r\n\r\n    def __delitem__( self, i ):\r\n        if isinstance(i,(int,slice)):\r\n            mylen = len( self.__toklist )\r\n            del self.__toklist[i]\r\n\r\n            # convert int to slice\r\n            if isinstance(i, int):\r\n                if i < 0:\r\n                    i += mylen\r\n                i = slice(i, i+1)\r\n            # get removed indices\r\n            removed = list(range(*i.indices(mylen)))\r\n            removed.reverse()\r\n            # fixup indices in token dictionary\r\n            for name in self.__tokdict:\r\n                occurrences = self.__tokdict[name]\r\n                for j in removed:\r\n                    for k, (value, position) in enumerate(occurrences):\r\n                        occurrences[k] = _ParseResultsWithOffset(value, position - (position > j))\r\n        else:\r\n            del self.__tokdict[i]\r\n\r\n    def __contains__( self, k ):\r\n        return k in self.__tokdict\r\n\r\n    def __len__( self ): return len( self.__toklist )\r\n    def __bool__(self): return len( self.__toklist ) > 0\r\n    __nonzero__ = __bool__\r\n    def __iter__( self ): return iter( self.__toklist )\r\n    def __reversed__( self ): return iter( self.__toklist[::-1] )\r\n    def iterkeys( self ):\r\n        """"""Returns all named result keys.""""""\r\n        if hasattr(self.__tokdict, ""iterkeys""):\r\n            return self.__tokdict.iterkeys()\r\n        else:\r\n            return iter(self.__tokdict)\r\n\r\n    def itervalues( self ):\r\n        """"""Returns all named result values.""""""\r\n        return (self[k] for k in self.iterkeys())\r\n            \r\n    def iteritems( self ):\r\n        return ((k, self[k]) for k in self.iterkeys())\r\n\r\n    if PY_3:\r\n        keys = iterkeys\r\n        values = itervalues\r\n        items = iteritems\r\n    else:\r\n        def keys( self ):\r\n            """"""Returns all named result keys.""""""\r\n            return list(self.iterkeys())\r\n\r\n        def values( self ):\r\n            """"""Returns all named result values.""""""\r\n            return list(self.itervalues())\r\n                \r\n        def items( self ):\r\n            """"""Returns all named result keys and values as a list of tuples.""""""\r\n            return list(self.iteritems())\r\n\r\n    def haskeys( self ):\r\n        """"""Since keys() returns an iterator, this method is helpful in bypassing\r\n           code that looks for the existence of any defined results names.""""""\r\n        return bool(self.__tokdict)\r\n        \r\n    def pop( self, *args, **kwargs):\r\n        """"""Removes and returns item at specified index (default=last).\r\n           Supports both list and dict semantics for pop(). If passed no\r\n           argument or an integer argument, it will use list semantics\r\n           and pop tokens from the list of parsed tokens. If passed a \r\n           non-integer argument (most likely a string), it will use dict\r\n           semantics and pop the corresponding value from any defined \r\n           results names. A second default return value argument is \r\n           supported, just as in dict.pop().""""""\r\n        if not args:\r\n            args = [-1]\r\n        for k,v in kwargs.items():\r\n            if k == \'default\':\r\n                args = (args[0], v)\r\n            else:\r\n                raise TypeError(""pop() got an unexpected keyword argument \'%s\'"" % k)\r\n        if (isinstance(args[0], int) or \r\n                        len(args) == 1 or \r\n                        args[0] in self):\r\n            index = args[0]\r\n            ret = self[index]\r\n            del self[index]\r\n            return ret\r\n        else:\r\n            defaultvalue = args[1]\r\n            return defaultvalue\r\n\r\n    def get(self, key, defaultValue=None):\r\n        """"""Returns named result matching the given key, or if there is no\r\n           such name, then returns the given C{defaultValue} or C{None} if no\r\n           C{defaultValue} is specified.""""""\r\n        if key in self:\r\n            return self[key]\r\n        else:\r\n            return defaultValue\r\n\r\n    def insert( self, index, insStr ):\r\n        """"""Inserts new element at location index in the list of parsed tokens.""""""\r\n        self.__toklist.insert(index, insStr)\r\n        # fixup indices in token dictionary\r\n        for name in self.__tokdict:\r\n            occurrences = self.__tokdict[name]\r\n            for k, (value, position) in enumerate(occurrences):\r\n                occurrences[k] = _ParseResultsWithOffset(value, position + (position > index))\r\n\r\n    def append( self, item ):\r\n        """"""Add single element to end of ParseResults list of elements.""""""\r\n        self.__toklist.append(item)\r\n\r\n    def extend( self, itemseq ):\r\n        """"""Add sequence of elements to end of ParseResults list of elements.""""""\r\n        if isinstance(itemseq, ParseResults):\r\n            self += itemseq\r\n        else:\r\n            self.__toklist.extend(itemseq)\r\n\r\n    def clear( self ):\r\n        """"""Clear all elements and results names.""""""\r\n        del self.__toklist[:]\r\n        self.__tokdict.clear()\r\n\r\n    def __getattr__( self, name ):\r\n        try:\r\n            return self[name]\r\n        except KeyError:\r\n            return """"\r\n            \r\n        if name in self.__tokdict:\r\n            if name not in self.__accumNames:\r\n                return self.__tokdict[name][-1][0]\r\n            else:\r\n                return ParseResults([ v[0] for v in self.__tokdict[name] ])\r\n        else:\r\n            return """"\r\n\r\n    def __add__( self, other ):\r\n        ret = self.copy()\r\n        ret += other\r\n        return ret\r\n\r\n    def __iadd__( self, other ):\r\n        if other.__tokdict:\r\n            offset = len(self.__toklist)\r\n            addoffset = ( lambda a: (a<0 and offset) or (a+offset) )\r\n            otheritems = other.__tokdict.items()\r\n            otherdictitems = [(k, _ParseResultsWithOffset(v[0],addoffset(v[1])) )\r\n                                for (k,vlist) in otheritems for v in vlist]\r\n            for k,v in otherdictitems:\r\n                self[k] = v\r\n                if isinstance(v[0],ParseResults):\r\n                    v[0].__parent = wkref(self)\r\n            \r\n        self.__toklist += other.__toklist\r\n        self.__accumNames.update( other.__accumNames )\r\n        return self\r\n\r\n    def __radd__(self, other):\r\n        if isinstance(other,int) and other == 0:\r\n            return self.copy()\r\n        \r\n    def __repr__( self ):\r\n        return ""(%s, %s)"" % ( repr( self.__toklist ), repr( self.__tokdict ) )\r\n\r\n    def __str__( self ):\r\n        out = []\r\n        for i in self.__toklist:\r\n            if isinstance(i, ParseResults):\r\n                out.append(_ustr(i))\r\n            else:\r\n                out.append(repr(i))\r\n        return \'[\' + \', \'.join(out) + \']\'\r\n\r\n    def _asStringList( self, sep=\'\' ):\r\n        out = []\r\n        for item in self.__toklist:\r\n            if out and sep:\r\n                out.append(sep)\r\n            if isinstance( item, ParseResults ):\r\n                out += item._asStringList()\r\n            else:\r\n                out.append( _ustr(item) )\r\n        return out\r\n\r\n    def asList( self ):\r\n        """"""Returns the parse results as a nested list of matching tokens, all converted to strings.""""""\r\n        out = []\r\n        for res in self.__toklist:\r\n            if isinstance(res,ParseResults):\r\n                out.append( res.asList() )\r\n            else:\r\n                out.append( res )\r\n        return out\r\n\r\n    def asDict( self ):\r\n        """"""Returns the named parse results as dictionary.""""""\r\n        if PY_3:\r\n            return dict( self.items() )\r\n        else:\r\n            return dict( self.iteritems() )\r\n\r\n    def copy( self ):\r\n        """"""Returns a new copy of a C{ParseResults} object.""""""\r\n        ret = ParseResults( self.__toklist )\r\n        ret.__tokdict = self.__tokdict.copy()\r\n        ret.__parent = self.__parent\r\n        ret.__accumNames.update( self.__accumNames )\r\n        ret.__name = self.__name\r\n        return ret\r\n\r\n    def asXML( self, doctag=None, namedItemsOnly=False, indent="""", formatted=True ):\r\n        """"""Returns the parse results as XML. Tags are created for tokens and lists that have defined results names.""""""\r\n        nl = ""\\n""\r\n        out = []\r\n        namedItems = dict((v[1],k) for (k,vlist) in self.__tokdict.items()\r\n                                                            for v in vlist)\r\n        nextLevelIndent = indent + ""  ""\r\n\r\n        # collapse out indents if formatting is not desired\r\n        if not formatted:\r\n            indent = """"\r\n            nextLevelIndent = """"\r\n            nl = """"\r\n\r\n        selfTag = None\r\n        if doctag is not None:\r\n            selfTag = doctag\r\n        else:\r\n            if self.__name:\r\n                selfTag = self.__name\r\n\r\n        if not selfTag:\r\n            if namedItemsOnly:\r\n                return """"\r\n            else:\r\n                selfTag = ""ITEM""\r\n\r\n        out += [ nl, indent, ""<"", selfTag, "">"" ]\r\n\r\n        worklist = self.__toklist\r\n        for i,res in enumerate(worklist):\r\n            if isinstance(res,ParseResults):\r\n                if i in namedItems:\r\n                    out += [ res.asXML(namedItems[i],\r\n                                        namedItemsOnly and doctag is None,\r\n                                        nextLevelIndent,\r\n                                        formatted)]\r\n                else:\r\n                    out += [ res.asXML(None,\r\n                                        namedItemsOnly and doctag is None,\r\n                                        nextLevelIndent,\r\n                                        formatted)]\r\n            else:\r\n                # individual token, see if there is a name for it\r\n                resTag = None\r\n                if i in namedItems:\r\n                    resTag = namedItems[i]\r\n                if not resTag:\r\n                    if namedItemsOnly:\r\n                        continue\r\n                    else:\r\n                        resTag = ""ITEM""\r\n                xmlBodyText = _xml_escape(_ustr(res))\r\n                out += [ nl, nextLevelIndent, ""<"", resTag, "">"",\r\n                                                xmlBodyText,\r\n                                                ""</"", resTag, "">"" ]\r\n\r\n        out += [ nl, indent, ""</"", selfTag, "">"" ]\r\n        return """".join(out)\r\n\r\n    def __lookup(self,sub):\r\n        for k,vlist in self.__tokdict.items():\r\n            for v,loc in vlist:\r\n                if sub is v:\r\n                    return k\r\n        return None\r\n\r\n    def getName(self):\r\n        """"""Returns the results name for this token expression.""""""\r\n        if self.__name:\r\n            return self.__name\r\n        elif self.__parent:\r\n            par = self.__parent()\r\n            if par:\r\n                return par.__lookup(self)\r\n            else:\r\n                return None\r\n        elif (len(self) == 1 and\r\n               len(self.__tokdict) == 1 and\r\n               self.__tokdict.values()[0][0][1] in (0,-1)):\r\n            return self.__tokdict.keys()[0]\r\n        else:\r\n            return None\r\n\r\n    def dump(self,indent=\'\',depth=0):\r\n        """"""Diagnostic method for listing out the contents of a C{ParseResults}.\r\n           Accepts an optional C{indent} argument so that this string can be embedded\r\n           in a nested display of other data.""""""\r\n        out = []\r\n        NL = \'\\n\'\r\n        out.append( indent+_ustr(self.asList()) )\r\n        items = sorted(self.items())\r\n        for k,v in items:\r\n            if out:\r\n                out.append(NL)\r\n            out.append( ""%s%s- %s: "" % (indent,(\'  \'*depth), k) )\r\n            if isinstance(v,ParseResults):\r\n                if v:\r\n                    if v.haskeys():\r\n                        out.append( v.dump(indent,depth+1) )\r\n                    elif any(isinstance(vv,ParseResults) for vv in v):\r\n                        for i,vv in enumerate(v):\r\n                            if isinstance(vv,ParseResults):\r\n                                out.append(""\\n%s%s[%d]:\\n%s%s%s"" % (indent,(\'  \'*(depth+1)),i,indent,(\'  \'*(depth+2)),vv.dump(indent,depth+2) ))\r\n                            else:\r\n                                out.append(""\\n%s%s[%d]:\\n%s%s%s"" % (indent,(\'  \'*(depth+1)),i,indent,(\'  \'*(depth+2)),_ustr(vv)))\r\n                    else:\r\n                        out.append(_ustr(v))\r\n                else:\r\n                    out.append(_ustr(v))\r\n            else:\r\n                out.append(_ustr(v))\r\n        return """".join(out)\r\n\r\n    def pprint(self, *args, **kwargs):\r\n        """"""Pretty-printer for parsed results as a list, using the C{pprint} module.\r\n           Accepts additional positional or keyword args as defined for the \r\n           C{pprint.pprint} method. (U{http://docs.python.org/3/library/pprint.html#pprint.pprint})""""""\r\n        pprint.pprint(self.asList(), *args, **kwargs)\r\n\r\n    # add support for pickle protocol\r\n    def __getstate__(self):\r\n        return ( self.__toklist,\r\n                 ( self.__tokdict.copy(),\r\n                   self.__parent is not None and self.__parent() or None,\r\n                   self.__accumNames,\r\n                   self.__name ) )\r\n\r\n    def __setstate__(self,state):\r\n        self.__toklist = state[0]\r\n        (self.__tokdict,\r\n         par,\r\n         inAccumNames,\r\n         self.__name) = state[1]\r\n        self.__accumNames = {}\r\n        self.__accumNames.update(inAccumNames)\r\n        if par is not None:\r\n            self.__parent = wkref(par)\r\n        else:\r\n            self.__parent = None\r\n\r\n    def __dir__(self):\r\n        return dir(super(ParseResults,self)) + list(self.keys())\r\n\r\ncollections.MutableMapping.register(ParseResults)\r\n\r\ndef col (loc,strg):\r\n    """"""Returns current column within a string, counting newlines as line separators.\r\n   The first column is number 1.\r\n\r\n   Note: the default parsing behavior is to expand tabs in the input string\r\n   before starting the parsing process.  See L{I{ParserElement.parseString}<ParserElement.parseString>} for more information\r\n   on parsing strings containing C{<TAB>}s, and suggested methods to maintain a\r\n   consistent view of the parsed string, the parse location, and line and column\r\n   positions within the parsed string.\r\n   """"""\r\n    return (loc<len(strg) and strg[loc] == \'\\n\') and 1 or loc - strg.rfind(""\\n"", 0, loc)\r\n\r\ndef lineno(loc,strg):\r\n    """"""Returns current line number within a string, counting newlines as line separators.\r\n   The first line is number 1.\r\n\r\n   Note: the default parsing behavior is to expand tabs in the input string\r\n   before starting the parsing process.  See L{I{ParserElement.parseString}<ParserElement.parseString>} for more information\r\n   on parsing strings containing C{<TAB>}s, and suggested methods to maintain a\r\n   consistent view of the parsed string, the parse location, and line and column\r\n   positions within the parsed string.\r\n   """"""\r\n    return strg.count(""\\n"",0,loc) + 1\r\n\r\ndef line( loc, strg ):\r\n    """"""Returns the line of text containing loc within a string, counting newlines as line separators.\r\n       """"""\r\n    lastCR = strg.rfind(""\\n"", 0, loc)\r\n    nextCR = strg.find(""\\n"", loc)\r\n    if nextCR >= 0:\r\n        return strg[lastCR+1:nextCR]\r\n    else:\r\n        return strg[lastCR+1:]\r\n\r\ndef _defaultStartDebugAction( instring, loc, expr ):\r\n    print ((""Match "" + _ustr(expr) + "" at loc "" + _ustr(loc) + ""(%d,%d)"" % ( lineno(loc,instring), col(loc,instring) )))\r\n\r\ndef _defaultSuccessDebugAction( instring, startloc, endloc, expr, toks ):\r\n    print (""Matched "" + _ustr(expr) + "" -> "" + str(toks.asList()))\r\n\r\ndef _defaultExceptionDebugAction( instring, loc, expr, exc ):\r\n    print (""Exception raised:"" + _ustr(exc))\r\n\r\ndef nullDebugAction(*args):\r\n    """"""\'Do-nothing\' debug action, to suppress debugging output during parsing.""""""\r\n    pass\r\n\r\n# Only works on Python 3.x - nonlocal is toxic to Python 2 installs\r\n#~ \'decorator to trim function calls to match the arity of the target\'\r\n#~ def _trim_arity(func, maxargs=3):\r\n    #~ if func in singleArgBuiltins:\r\n        #~ return lambda s,l,t: func(t)\r\n    #~ limit = 0\r\n    #~ foundArity = False\r\n    #~ def wrapper(*args):\r\n        #~ nonlocal limit,foundArity\r\n        #~ while 1:\r\n            #~ try:\r\n                #~ ret = func(*args[limit:])\r\n                #~ foundArity = True\r\n                #~ return ret\r\n            #~ except TypeError:\r\n                #~ if limit == maxargs or foundArity:\r\n                    #~ raise\r\n                #~ limit += 1\r\n                #~ continue\r\n    #~ return wrapper\r\n\r\n# this version is Python 2.x-3.x cross-compatible\r\n\'decorator to trim function calls to match the arity of the target\'\r\ndef _trim_arity(func, maxargs=2):\r\n    if func in singleArgBuiltins:\r\n        return lambda s,l,t: func(t)\r\n    limit = [0]\r\n    foundArity = [False]\r\n    def wrapper(*args):\r\n        while 1:\r\n            try:\r\n                ret = func(*args[limit[0]:])\r\n                foundArity[0] = True\r\n                return ret\r\n            except TypeError:\r\n                if limit[0] <= maxargs and not foundArity[0]:\r\n                    limit[0] += 1\r\n                    continue\r\n                raise\r\n    return wrapper\r\n \r\nclass ParserElement(object):\r\n    """"""Abstract base level parser element class.""""""\r\n    DEFAULT_WHITE_CHARS = "" \\n\\t\\r""\r\n    verbose_stacktrace = False\r\n\r\n    def setDefaultWhitespaceChars( chars ):\r\n        """"""Overrides the default whitespace chars\r\n        """"""\r\n        ParserElement.DEFAULT_WHITE_CHARS = chars\r\n    setDefaultWhitespaceChars = staticmethod(setDefaultWhitespaceChars)\r\n\r\n    def inlineLiteralsUsing(cls):\r\n        """"""\r\n        Set class to be used for inclusion of string literals into a parser.\r\n        """"""\r\n        ParserElement.literalStringClass = cls\r\n    inlineLiteralsUsing = staticmethod(inlineLiteralsUsing)\r\n\r\n    def __init__( self, savelist=False ):\r\n        self.parseAction = list()\r\n        self.failAction = None\r\n        #~ self.name = ""<unknown>""  # don\'t define self.name, let subclasses try/except upcall\r\n        self.strRepr = None\r\n        self.resultsName = None\r\n        self.saveAsList = savelist\r\n        self.skipWhitespace = True\r\n        self.whiteChars = ParserElement.DEFAULT_WHITE_CHARS\r\n        self.copyDefaultWhiteChars = True\r\n        self.mayReturnEmpty = False # used when checking for left-recursion\r\n        self.keepTabs = False\r\n        self.ignoreExprs = list()\r\n        self.debug = False\r\n        self.streamlined = False\r\n        self.mayIndexError = True # used to optimize exception handling for subclasses that don\'t advance parse index\r\n        self.errmsg = """"\r\n        self.modalResults = True # used to mark results names as modal (report only last) or cumulative (list all)\r\n        self.debugActions = ( None, None, None ) #custom debug actions\r\n        self.re = None\r\n        self.callPreparse = True # used to avoid redundant calls to preParse\r\n        self.callDuringTry = False\r\n\r\n    def copy( self ):\r\n        """"""Make a copy of this C{ParserElement}.  Useful for defining different parse actions\r\n           for the same parsing pattern, using copies of the original parse element.""""""\r\n        cpy = copy.copy( self )\r\n        cpy.parseAction = self.parseAction[:]\r\n        cpy.ignoreExprs = self.ignoreExprs[:]\r\n        if self.copyDefaultWhiteChars:\r\n            cpy.whiteChars = ParserElement.DEFAULT_WHITE_CHARS\r\n        return cpy\r\n\r\n    def setName( self, name ):\r\n        """"""Define name for this expression, for use in debugging.""""""\r\n        self.name = name\r\n        self.errmsg = ""Expected "" + self.name\r\n        if hasattr(self,""exception""):\r\n            self.exception.msg = self.errmsg\r\n        return self\r\n\r\n    def setResultsName( self, name, listAllMatches=False ):\r\n        """"""Define name for referencing matching tokens as a nested attribute\r\n           of the returned parse results.\r\n           NOTE: this returns a *copy* of the original C{ParserElement} object;\r\n           this is so that the client can define a basic element, such as an\r\n           integer, and reference it in multiple places with different names.\r\n           \r\n           You can also set results names using the abbreviated syntax,\r\n           C{expr(""name"")} in place of C{expr.setResultsName(""name"")} - \r\n           see L{I{__call__}<__call__>}.\r\n        """"""\r\n        newself = self.copy()\r\n        if name.endswith(""*""):\r\n            name = name[:-1]\r\n            listAllMatches=True\r\n        newself.resultsName = name\r\n        newself.modalResults = not listAllMatches\r\n        return newself\r\n\r\n    def setBreak(self,breakFlag = True):\r\n        """"""Method to invoke the Python pdb debugger when this element is\r\n           about to be parsed. Set C{breakFlag} to True to enable, False to\r\n           disable.\r\n        """"""\r\n        if breakFlag:\r\n            _parseMethod = self._parse\r\n            def breaker(instring, loc, doActions=True, callPreParse=True):\r\n                import pdb\r\n                pdb.set_trace()\r\n                return _parseMethod( instring, loc, doActions, callPreParse )\r\n            breaker._originalParseMethod = _parseMethod\r\n            self._parse = breaker\r\n        else:\r\n            if hasattr(self._parse,""_originalParseMethod""):\r\n                self._parse = self._parse._originalParseMethod\r\n        return self\r\n\r\n    def setParseAction( self, *fns, **kwargs ):\r\n        """"""Define action to perform when successfully matching parse element definition.\r\n           Parse action fn is a callable method with 0-3 arguments, called as C{fn(s,loc,toks)},\r\n           C{fn(loc,toks)}, C{fn(toks)}, or just C{fn()}, where:\r\n            - s   = the original string being parsed (see note below)\r\n            - loc = the location of the matching substring\r\n            - toks = a list of the matched tokens, packaged as a C{L{ParseResults}} object\r\n           If the functions in fns modify the tokens, they can return them as the return\r\n           value from fn, and the modified list of tokens will replace the original.\r\n           Otherwise, fn does not need to return any value.\r\n\r\n           Note: the default parsing behavior is to expand tabs in the input string\r\n           before starting the parsing process.  See L{I{parseString}<parseString>} for more information\r\n           on parsing strings containing C{<TAB>}s, and suggested methods to maintain a\r\n           consistent view of the parsed string, the parse location, and line and column\r\n           positions within the parsed string.\r\n           """"""\r\n        self.parseAction = list(map(_trim_arity, list(fns)))\r\n        self.callDuringTry = (""callDuringTry"" in kwargs and kwargs[""callDuringTry""])\r\n        return self\r\n\r\n    def addParseAction( self, *fns, **kwargs ):\r\n        """"""Add parse action to expression\'s list of parse actions. See L{I{setParseAction}<setParseAction>}.""""""\r\n        self.parseAction += list(map(_trim_arity, list(fns)))\r\n        self.callDuringTry = self.callDuringTry or (""callDuringTry"" in kwargs and kwargs[""callDuringTry""])\r\n        return self\r\n\r\n    def setFailAction( self, fn ):\r\n        """"""Define action to perform if parsing fails at this expression.\r\n           Fail acton fn is a callable function that takes the arguments\r\n           C{fn(s,loc,expr,err)} where:\r\n            - s = string being parsed\r\n            - loc = location where expression match was attempted and failed\r\n            - expr = the parse expression that failed\r\n            - err = the exception thrown\r\n           The function returns no value.  It may throw C{L{ParseFatalException}}\r\n           if it is desired to stop parsing immediately.""""""\r\n        self.failAction = fn\r\n        return self\r\n\r\n    def _skipIgnorables( self, instring, loc ):\r\n        exprsFound = True\r\n        while exprsFound:\r\n            exprsFound = False\r\n            for e in self.ignoreExprs:\r\n                try:\r\n                    while 1:\r\n                        loc,dummy = e._parse( instring, loc )\r\n                        exprsFound = True\r\n                except ParseException:\r\n                    pass\r\n        return loc\r\n\r\n    def preParse( self, instring, loc ):\r\n        if self.ignoreExprs:\r\n            loc = self._skipIgnorables( instring, loc )\r\n\r\n        if self.skipWhitespace:\r\n            wt = self.whiteChars\r\n            instrlen = len(instring)\r\n            while loc < instrlen and instring[loc] in wt:\r\n                loc += 1\r\n\r\n        return loc\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        return loc, []\r\n\r\n    def postParse( self, instring, loc, tokenlist ):\r\n        return tokenlist\r\n\r\n    #~ @profile\r\n    def _parseNoCache( self, instring, loc, doActions=True, callPreParse=True ):\r\n        debugging = ( self.debug ) #and doActions )\r\n\r\n        if debugging or self.failAction:\r\n            #~ print (""Match"",self,""at loc"",loc,""(%d,%d)"" % ( lineno(loc,instring), col(loc,instring) ))\r\n            if (self.debugActions[0] ):\r\n                self.debugActions[0]( instring, loc, self )\r\n            if callPreParse and self.callPreparse:\r\n                preloc = self.preParse( instring, loc )\r\n            else:\r\n                preloc = loc\r\n            tokensStart = preloc\r\n            try:\r\n                try:\r\n                    loc,tokens = self.parseImpl( instring, preloc, doActions )\r\n                except IndexError:\r\n                    raise ParseException( instring, len(instring), self.errmsg, self )\r\n            except ParseBaseException as err:\r\n                #~ print (""Exception raised:"", err)\r\n                if self.debugActions[2]:\r\n                    self.debugActions[2]( instring, tokensStart, self, err )\r\n                if self.failAction:\r\n                    self.failAction( instring, tokensStart, self, err )\r\n                raise\r\n        else:\r\n            if callPreParse and self.callPreparse:\r\n                preloc = self.preParse( instring, loc )\r\n            else:\r\n                preloc = loc\r\n            tokensStart = preloc\r\n            if self.mayIndexError or loc >= len(instring):\r\n                try:\r\n                    loc,tokens = self.parseImpl( instring, preloc, doActions )\r\n                except IndexError:\r\n                    raise ParseException( instring, len(instring), self.errmsg, self )\r\n            else:\r\n                loc,tokens = self.parseImpl( instring, preloc, doActions )\r\n\r\n        tokens = self.postParse( instring, loc, tokens )\r\n\r\n        retTokens = ParseResults( tokens, self.resultsName, asList=self.saveAsList, modal=self.modalResults )\r\n        if self.parseAction and (doActions or self.callDuringTry):\r\n            if debugging:\r\n                try:\r\n                    for fn in self.parseAction:\r\n                        tokens = fn( instring, tokensStart, retTokens )\r\n                        if tokens is not None:\r\n                            retTokens = ParseResults( tokens,\r\n                                                      self.resultsName,\r\n                                                      asList=self.saveAsList and isinstance(tokens,(ParseResults,list)),\r\n                                                      modal=self.modalResults )\r\n                except ParseBaseException as err:\r\n                    #~ print ""Exception raised in user parse action:"", err\r\n                    if (self.debugActions[2] ):\r\n                        self.debugActions[2]( instring, tokensStart, self, err )\r\n                    raise\r\n            else:\r\n                for fn in self.parseAction:\r\n                    tokens = fn( instring, tokensStart, retTokens )\r\n                    if tokens is not None:\r\n                        retTokens = ParseResults( tokens,\r\n                                                  self.resultsName,\r\n                                                  asList=self.saveAsList and isinstance(tokens,(ParseResults,list)),\r\n                                                  modal=self.modalResults )\r\n\r\n        if debugging:\r\n            #~ print (""Matched"",self,""->"",retTokens.asList())\r\n            if (self.debugActions[1] ):\r\n                self.debugActions[1]( instring, tokensStart, loc, self, retTokens )\r\n\r\n        return loc, retTokens\r\n\r\n    def tryParse( self, instring, loc ):\r\n        try:\r\n            return self._parse( instring, loc, doActions=False )[0]\r\n        except ParseFatalException:\r\n            raise ParseException( instring, loc, self.errmsg, self)\r\n\r\n    # this method gets repeatedly called during backtracking with the same arguments -\r\n    # we can cache these arguments and save ourselves the trouble of re-parsing the contained expression\r\n    def _parseCache( self, instring, loc, doActions=True, callPreParse=True ):\r\n        lookup = (self,instring,loc,callPreParse,doActions)\r\n        if lookup in ParserElement._exprArgCache:\r\n            value = ParserElement._exprArgCache[ lookup ]\r\n            if isinstance(value, Exception):\r\n                raise value\r\n            return (value[0],value[1].copy())\r\n        else:\r\n            try:\r\n                value = self._parseNoCache( instring, loc, doActions, callPreParse )\r\n                ParserElement._exprArgCache[ lookup ] = (value[0],value[1].copy())\r\n                return value\r\n            except ParseBaseException as pe:\r\n                pe.__traceback__ = None\r\n                ParserElement._exprArgCache[ lookup ] = pe\r\n                raise\r\n\r\n    _parse = _parseNoCache\r\n\r\n    # argument cache for optimizing repeated calls when backtracking through recursive expressions\r\n    _exprArgCache = {}\r\n    def resetCache():\r\n        ParserElement._exprArgCache.clear()\r\n    resetCache = staticmethod(resetCache)\r\n\r\n    _packratEnabled = False\r\n    def enablePackrat():\r\n        """"""Enables ""packrat"" parsing, which adds memoizing to the parsing logic.\r\n           Repeated parse attempts at the same string location (which happens\r\n           often in many complex grammars) can immediately return a cached value,\r\n           instead of re-executing parsing/validating code.  Memoizing is done of\r\n           both valid results and parsing exceptions.\r\n\r\n           This speedup may break existing programs that use parse actions that\r\n           have side-effects.  For this reason, packrat parsing is disabled when\r\n           you first import pyparsing.  To activate the packrat feature, your\r\n           program must call the class method C{ParserElement.enablePackrat()}.  If\r\n           your program uses C{psyco} to ""compile as you go"", you must call\r\n           C{enablePackrat} before calling C{psyco.full()}.  If you do not do this,\r\n           Python will crash.  For best results, call C{enablePackrat()} immediately\r\n           after importing pyparsing.\r\n        """"""\r\n        if not ParserElement._packratEnabled:\r\n            ParserElement._packratEnabled = True\r\n            ParserElement._parse = ParserElement._parseCache\r\n    enablePackrat = staticmethod(enablePackrat)\r\n\r\n    def parseString( self, instring, parseAll=False ):\r\n        """"""Execute the parse expression with the given string.\r\n           This is the main interface to the client code, once the complete\r\n           expression has been built.\r\n\r\n           If you want the grammar to require that the entire input string be\r\n           successfully parsed, then set C{parseAll} to True (equivalent to ending\r\n           the grammar with C{L{StringEnd()}}).\r\n\r\n           Note: C{parseString} implicitly calls C{expandtabs()} on the input string,\r\n           in order to report proper column numbers in parse actions.\r\n           If the input string contains tabs and\r\n           the grammar uses parse actions that use the C{loc} argument to index into the\r\n           string being parsed, you can ensure you have a consistent view of the input\r\n           string by:\r\n            - calling C{parseWithTabs} on your grammar before calling C{parseString}\r\n              (see L{I{parseWithTabs}<parseWithTabs>})\r\n            - define your parse action using the full C{(s,loc,toks)} signature, and\r\n              reference the input string using the parse action\'s C{s} argument\r\n            - explictly expand the tabs in your input string before calling\r\n              C{parseString}\r\n        """"""\r\n        ParserElement.resetCache()\r\n        if not self.streamlined:\r\n            self.streamline()\r\n            #~ self.saveAsList = True\r\n        for e in self.ignoreExprs:\r\n            e.streamline()\r\n        if not self.keepTabs:\r\n            instring = instring.expandtabs()\r\n        try:\r\n            loc, tokens = self._parse( instring, 0 )\r\n            if parseAll:\r\n                loc = self.preParse( instring, loc )\r\n                se = Empty() + StringEnd()\r\n                se._parse( instring, loc )\r\n        except ParseBaseException as exc:\r\n            if ParserElement.verbose_stacktrace:\r\n                raise\r\n            else:\r\n                # catch and re-raise exception from here, clears out pyparsing internal stack trace\r\n                raise exc\r\n        else:\r\n            return tokens\r\n\r\n    def scanString( self, instring, maxMatches=_MAX_INT, overlap=False ):\r\n        """"""Scan the input string for expression matches.  Each match will return the\r\n           matching tokens, start location, and end location.  May be called with optional\r\n           C{maxMatches} argument, to clip scanning after \'n\' matches are found.  If\r\n           C{overlap} is specified, then overlapping matches will be reported.\r\n\r\n           Note that the start and end locations are reported relative to the string\r\n           being parsed.  See L{I{parseString}<parseString>} for more information on parsing\r\n           strings with embedded tabs.""""""\r\n        if not self.streamlined:\r\n            self.streamline()\r\n        for e in self.ignoreExprs:\r\n            e.streamline()\r\n\r\n        if not self.keepTabs:\r\n            instring = _ustr(instring).expandtabs()\r\n        instrlen = len(instring)\r\n        loc = 0\r\n        preparseFn = self.preParse\r\n        parseFn = self._parse\r\n        ParserElement.resetCache()\r\n        matches = 0\r\n        try:\r\n            while loc <= instrlen and matches < maxMatches:\r\n                try:\r\n                    preloc = preparseFn( instring, loc )\r\n                    nextLoc,tokens = parseFn( instring, preloc, callPreParse=False )\r\n                except ParseException:\r\n                    loc = preloc+1\r\n                else:\r\n                    if nextLoc > loc:\r\n                        matches += 1\r\n                        yield tokens, preloc, nextLoc\r\n                        if overlap:\r\n                            nextloc = preparseFn( instring, loc )\r\n                            if nextloc > loc:\r\n                                loc = nextLoc\r\n                            else:\r\n                                loc += 1\r\n                        else:\r\n                            loc = nextLoc\r\n                    else:\r\n                        loc = preloc+1\r\n        except ParseBaseException as exc:\r\n            if ParserElement.verbose_stacktrace:\r\n                raise\r\n            else:\r\n                # catch and re-raise exception from here, clears out pyparsing internal stack trace\r\n                raise exc\r\n\r\n    def transformString( self, instring ):\r\n        """"""Extension to C{L{scanString}}, to modify matching text with modified tokens that may\r\n           be returned from a parse action.  To use C{transformString}, define a grammar and\r\n           attach a parse action to it that modifies the returned token list.\r\n           Invoking C{transformString()} on a target string will then scan for matches,\r\n           and replace the matched text patterns according to the logic in the parse\r\n           action.  C{transformString()} returns the resulting transformed string.""""""\r\n        out = []\r\n        lastE = 0\r\n        # force preservation of <TAB>s, to minimize unwanted transformation of string, and to\r\n        # keep string locs straight between transformString and scanString\r\n        self.keepTabs = True\r\n        try:\r\n            for t,s,e in self.scanString( instring ):\r\n                out.append( instring[lastE:s] )\r\n                if t:\r\n                    if isinstance(t,ParseResults):\r\n                        out += t.asList()\r\n                    elif isinstance(t,list):\r\n                        out += t\r\n                    else:\r\n                        out.append(t)\r\n                lastE = e\r\n            out.append(instring[lastE:])\r\n            out = [o for o in out if o]\r\n            return """".join(map(_ustr,_flatten(out)))\r\n        except ParseBaseException as exc:\r\n            if ParserElement.verbose_stacktrace:\r\n                raise\r\n            else:\r\n                # catch and re-raise exception from here, clears out pyparsing internal stack trace\r\n                raise exc\r\n\r\n    def searchString( self, instring, maxMatches=_MAX_INT ):\r\n        """"""Another extension to C{L{scanString}}, simplifying the access to the tokens found\r\n           to match the given parse expression.  May be called with optional\r\n           C{maxMatches} argument, to clip searching after \'n\' matches are found.\r\n        """"""\r\n        try:\r\n            return ParseResults([ t for t,s,e in self.scanString( instring, maxMatches ) ])\r\n        except ParseBaseException as exc:\r\n            if ParserElement.verbose_stacktrace:\r\n                raise\r\n            else:\r\n                # catch and re-raise exception from here, clears out pyparsing internal stack trace\r\n                raise exc\r\n\r\n    def __add__(self, other ):\r\n        """"""Implementation of + operator - returns C{L{And}}""""""\r\n        if isinstance( other, basestring ):\r\n            other = ParserElement.literalStringClass( other )\r\n        if not isinstance( other, ParserElement ):\r\n            warnings.warn(""Cannot combine element of type %s with ParserElement"" % type(other),\r\n                    SyntaxWarning, stacklevel=2)\r\n            return None\r\n        return And( [ self, other ] )\r\n\r\n    def __radd__(self, other ):\r\n        """"""Implementation of + operator when left operand is not a C{L{ParserElement}}""""""\r\n        if isinstance( other, basestring ):\r\n            other = ParserElement.literalStringClass( other )\r\n        if not isinstance( other, ParserElement ):\r\n            warnings.warn(""Cannot combine element of type %s with ParserElement"" % type(other),\r\n                    SyntaxWarning, stacklevel=2)\r\n            return None\r\n        return other + self\r\n\r\n    def __sub__(self, other):\r\n        """"""Implementation of - operator, returns C{L{And}} with error stop""""""\r\n        if isinstance( other, basestring ):\r\n            other = ParserElement.literalStringClass( other )\r\n        if not isinstance( other, ParserElement ):\r\n            warnings.warn(""Cannot combine element of type %s with ParserElement"" % type(other),\r\n                    SyntaxWarning, stacklevel=2)\r\n            return None\r\n        return And( [ self, And._ErrorStop(), other ] )\r\n\r\n    def __rsub__(self, other ):\r\n        """"""Implementation of - operator when left operand is not a C{L{ParserElement}}""""""\r\n        if isinstance( other, basestring ):\r\n            other = ParserElement.literalStringClass( other )\r\n        if not isinstance( other, ParserElement ):\r\n            warnings.warn(""Cannot combine element of type %s with ParserElement"" % type(other),\r\n                    SyntaxWarning, stacklevel=2)\r\n            return None\r\n        return other - self\r\n\r\n    def __mul__(self,other):\r\n        """"""Implementation of * operator, allows use of C{expr * 3} in place of\r\n           C{expr + expr + expr}.  Expressions may also me multiplied by a 2-integer\r\n           tuple, similar to C{{min,max}} multipliers in regular expressions.  Tuples\r\n           may also include C{None} as in:\r\n            - C{expr*(n,None)} or C{expr*(n,)} is equivalent\r\n              to C{expr*n + L{ZeroOrMore}(expr)}\r\n              (read as ""at least n instances of C{expr}"")\r\n            - C{expr*(None,n)} is equivalent to C{expr*(0,n)}\r\n              (read as ""0 to n instances of C{expr}"")\r\n            - C{expr*(None,None)} is equivalent to C{L{ZeroOrMore}(expr)}\r\n            - C{expr*(1,None)} is equivalent to C{L{OneOrMore}(expr)}\r\n\r\n           Note that C{expr*(None,n)} does not raise an exception if\r\n           more than n exprs exist in the input stream; that is,\r\n           C{expr*(None,n)} does not enforce a maximum number of expr\r\n           occurrences.  If this behavior is desired, then write\r\n           C{expr*(None,n) + ~expr}\r\n\r\n        """"""\r\n        if isinstance(other,int):\r\n            minElements, optElements = other,0\r\n        elif isinstance(other,tuple):\r\n            other = (other + (None, None))[:2]\r\n            if other[0] is None:\r\n                other = (0, other[1])\r\n            if isinstance(other[0],int) and other[1] is None:\r\n                if other[0] == 0:\r\n                    return ZeroOrMore(self)\r\n                if other[0] == 1:\r\n                    return OneOrMore(self)\r\n                else:\r\n                    return self*other[0] + ZeroOrMore(self)\r\n            elif isinstance(other[0],int) and isinstance(other[1],int):\r\n                minElements, optElements = other\r\n                optElements -= minElements\r\n            else:\r\n                raise TypeError(""cannot multiply \'ParserElement\' and (\'%s\',\'%s\') objects"", type(other[0]),type(other[1]))\r\n        else:\r\n            raise TypeError(""cannot multiply \'ParserElement\' and \'%s\' objects"", type(other))\r\n\r\n        if minElements < 0:\r\n            raise ValueError(""cannot multiply ParserElement by negative value"")\r\n        if optElements < 0:\r\n            raise ValueError(""second tuple value must be greater or equal to first tuple value"")\r\n        if minElements == optElements == 0:\r\n            raise ValueError(""cannot multiply ParserElement by 0 or (0,0)"")\r\n\r\n        if (optElements):\r\n            def makeOptionalList(n):\r\n                if n>1:\r\n                    return Optional(self + makeOptionalList(n-1))\r\n                else:\r\n                    return Optional(self)\r\n            if minElements:\r\n                if minElements == 1:\r\n                    ret = self + makeOptionalList(optElements)\r\n                else:\r\n                    ret = And([self]*minElements) + makeOptionalList(optElements)\r\n            else:\r\n                ret = makeOptionalList(optElements)\r\n        else:\r\n            if minElements == 1:\r\n                ret = self\r\n            else:\r\n                ret = And([self]*minElements)\r\n        return ret\r\n\r\n    def __rmul__(self, other):\r\n        return self.__mul__(other)\r\n\r\n    def __or__(self, other ):\r\n        """"""Implementation of | operator - returns C{L{MatchFirst}}""""""\r\n        if isinstance( other, basestring ):\r\n            other = ParserElement.literalStringClass( other )\r\n        if not isinstance( other, ParserElement ):\r\n            warnings.warn(""Cannot combine element of type %s with ParserElement"" % type(other),\r\n                    SyntaxWarning, stacklevel=2)\r\n            return None\r\n        return MatchFirst( [ self, other ] )\r\n\r\n    def __ror__(self, other ):\r\n        """"""Implementation of | operator when left operand is not a C{L{ParserElement}}""""""\r\n        if isinstance( other, basestring ):\r\n            other = ParserElement.literalStringClass( other )\r\n        if not isinstance( other, ParserElement ):\r\n            warnings.warn(""Cannot combine element of type %s with ParserElement"" % type(other),\r\n                    SyntaxWarning, stacklevel=2)\r\n            return None\r\n        return other | self\r\n\r\n    def __xor__(self, other ):\r\n        """"""Implementation of ^ operator - returns C{L{Or}}""""""\r\n        if isinstance( other, basestring ):\r\n            other = ParserElement.literalStringClass( other )\r\n        if not isinstance( other, ParserElement ):\r\n            warnings.warn(""Cannot combine element of type %s with ParserElement"" % type(other),\r\n                    SyntaxWarning, stacklevel=2)\r\n            return None\r\n        return Or( [ self, other ] )\r\n\r\n    def __rxor__(self, other ):\r\n        """"""Implementation of ^ operator when left operand is not a C{L{ParserElement}}""""""\r\n        if isinstance( other, basestring ):\r\n            other = ParserElement.literalStringClass( other )\r\n        if not isinstance( other, ParserElement ):\r\n            warnings.warn(""Cannot combine element of type %s with ParserElement"" % type(other),\r\n                    SyntaxWarning, stacklevel=2)\r\n            return None\r\n        return other ^ self\r\n\r\n    def __and__(self, other ):\r\n        """"""Implementation of & operator - returns C{L{Each}}""""""\r\n        if isinstance( other, basestring ):\r\n            other = ParserElement.literalStringClass( other )\r\n        if not isinstance( other, ParserElement ):\r\n            warnings.warn(""Cannot combine element of type %s with ParserElement"" % type(other),\r\n                    SyntaxWarning, stacklevel=2)\r\n            return None\r\n        return Each( [ self, other ] )\r\n\r\n    def __rand__(self, other ):\r\n        """"""Implementation of & operator when left operand is not a C{L{ParserElement}}""""""\r\n        if isinstance( other, basestring ):\r\n            other = ParserElement.literalStringClass( other )\r\n        if not isinstance( other, ParserElement ):\r\n            warnings.warn(""Cannot combine element of type %s with ParserElement"" % type(other),\r\n                    SyntaxWarning, stacklevel=2)\r\n            return None\r\n        return other & self\r\n\r\n    def __invert__( self ):\r\n        """"""Implementation of ~ operator - returns C{L{NotAny}}""""""\r\n        return NotAny( self )\r\n\r\n    def __call__(self, name=None):\r\n        """"""Shortcut for C{L{setResultsName}}, with C{listAllMatches=default}::\r\n             userdata = Word(alphas).setResultsName(""name"") + Word(nums+""-"").setResultsName(""socsecno"")\r\n           could be written as::\r\n             userdata = Word(alphas)(""name"") + Word(nums+""-"")(""socsecno"")\r\n             \r\n           If C{name} is given with a trailing C{\'*\'} character, then C{listAllMatches} will be\r\n           passed as C{True}.\r\n           \r\n           If C{name} is omitted, same as calling C{L{copy}}.\r\n           """"""\r\n        if name is not None:\r\n            return self.setResultsName(name)\r\n        else:\r\n            return self.copy()\r\n\r\n    def suppress( self ):\r\n        """"""Suppresses the output of this C{ParserElement}; useful to keep punctuation from\r\n           cluttering up returned output.\r\n        """"""\r\n        return Suppress( self )\r\n\r\n    def leaveWhitespace( self ):\r\n        """"""Disables the skipping of whitespace before matching the characters in the\r\n           C{ParserElement}\'s defined pattern.  This is normally only used internally by\r\n           the pyparsing module, but may be needed in some whitespace-sensitive grammars.\r\n        """"""\r\n        self.skipWhitespace = False\r\n        return self\r\n\r\n    def setWhitespaceChars( self, chars ):\r\n        """"""Overrides the default whitespace chars\r\n        """"""\r\n        self.skipWhitespace = True\r\n        self.whiteChars = chars\r\n        self.copyDefaultWhiteChars = False\r\n        return self\r\n\r\n    def parseWithTabs( self ):\r\n        """"""Overrides default behavior to expand C{<TAB>}s to spaces before parsing the input string.\r\n           Must be called before C{parseString} when the input grammar contains elements that\r\n           match C{<TAB>} characters.""""""\r\n        self.keepTabs = True\r\n        return self\r\n\r\n    def ignore( self, other ):\r\n        """"""Define expression to be ignored (e.g., comments) while doing pattern\r\n           matching; may be called repeatedly, to define multiple comment or other\r\n           ignorable patterns.\r\n        """"""\r\n        if isinstance( other, Suppress ):\r\n            if other not in self.ignoreExprs:\r\n                self.ignoreExprs.append( other.copy() )\r\n        else:\r\n            self.ignoreExprs.append( Suppress( other.copy() ) )\r\n        return self\r\n\r\n    def setDebugActions( self, startAction, successAction, exceptionAction ):\r\n        """"""Enable display of debugging messages while doing pattern matching.""""""\r\n        self.debugActions = (startAction or _defaultStartDebugAction,\r\n                             successAction or _defaultSuccessDebugAction,\r\n                             exceptionAction or _defaultExceptionDebugAction)\r\n        self.debug = True\r\n        return self\r\n\r\n    def setDebug( self, flag=True ):\r\n        """"""Enable display of debugging messages while doing pattern matching.\r\n           Set C{flag} to True to enable, False to disable.""""""\r\n        if flag:\r\n            self.setDebugActions( _defaultStartDebugAction, _defaultSuccessDebugAction, _defaultExceptionDebugAction )\r\n        else:\r\n            self.debug = False\r\n        return self\r\n\r\n    def __str__( self ):\r\n        return self.name\r\n\r\n    def __repr__( self ):\r\n        return _ustr(self)\r\n\r\n    def streamline( self ):\r\n        self.streamlined = True\r\n        self.strRepr = None\r\n        return self\r\n\r\n    def checkRecursion( self, parseElementList ):\r\n        pass\r\n\r\n    def validate( self, validateTrace=[] ):\r\n        """"""Check defined expressions for valid structure, check for infinite recursive definitions.""""""\r\n        self.checkRecursion( [] )\r\n\r\n    def parseFile( self, file_or_filename, parseAll=False ):\r\n        """"""Execute the parse expression on the given file or filename.\r\n           If a filename is specified (instead of a file object),\r\n           the entire file is opened, read, and closed before parsing.\r\n        """"""\r\n        try:\r\n            file_contents = file_or_filename.read()\r\n        except AttributeError:\r\n            f = open(file_or_filename, ""r"")\r\n            file_contents = f.read()\r\n            f.close()\r\n        try:\r\n            return self.parseString(file_contents, parseAll)\r\n        except ParseBaseException as exc:\r\n            if ParserElement.verbose_stacktrace:\r\n                raise\r\n            else:\r\n                # catch and re-raise exception from here, clears out pyparsing internal stack trace\r\n                raise exc\r\n\r\n    def __eq__(self,other):\r\n        if isinstance(other, ParserElement):\r\n            return self is other or self.__dict__ == other.__dict__\r\n        elif isinstance(other, basestring):\r\n            try:\r\n                self.parseString(_ustr(other), parseAll=True)\r\n                return True\r\n            except ParseBaseException:\r\n                return False\r\n        else:\r\n            return super(ParserElement,self)==other\r\n\r\n    def __ne__(self,other):\r\n        return not (self == other)\r\n\r\n    def __hash__(self):\r\n        return hash(id(self))\r\n\r\n    def __req__(self,other):\r\n        return self == other\r\n\r\n    def __rne__(self,other):\r\n        return not (self == other)\r\n\r\n\r\nclass Token(ParserElement):\r\n    """"""Abstract C{ParserElement} subclass, for defining atomic matching patterns.""""""\r\n    def __init__( self ):\r\n        super(Token,self).__init__( savelist=False )\r\n\r\n    def setName(self, name):\r\n        s = super(Token,self).setName(name)\r\n        self.errmsg = ""Expected "" + self.name\r\n        return s\r\n\r\n\r\nclass Empty(Token):\r\n    """"""An empty token, will always match.""""""\r\n    def __init__( self ):\r\n        super(Empty,self).__init__()\r\n        self.name = ""Empty""\r\n        self.mayReturnEmpty = True\r\n        self.mayIndexError = False\r\n\r\n\r\nclass NoMatch(Token):\r\n    """"""A token that will never match.""""""\r\n    def __init__( self ):\r\n        super(NoMatch,self).__init__()\r\n        self.name = ""NoMatch""\r\n        self.mayReturnEmpty = True\r\n        self.mayIndexError = False\r\n        self.errmsg = ""Unmatchable token""\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        raise ParseException(instring, loc, self.errmsg, self)\r\n\r\n\r\nclass Literal(Token):\r\n    """"""Token to exactly match a specified string.""""""\r\n    def __init__( self, matchString ):\r\n        super(Literal,self).__init__()\r\n        self.match = matchString\r\n        self.matchLen = len(matchString)\r\n        try:\r\n            self.firstMatchChar = matchString[0]\r\n        except IndexError:\r\n            warnings.warn(""null string passed to Literal; use Empty() instead"",\r\n                            SyntaxWarning, stacklevel=2)\r\n            self.__class__ = Empty\r\n        self.name = \'""%s""\' % _ustr(self.match)\r\n        self.errmsg = ""Expected "" + self.name\r\n        self.mayReturnEmpty = False\r\n        self.mayIndexError = False\r\n\r\n    # Performance tuning: this routine gets called a *lot*\r\n    # if this is a single character match string  and the first character matches,\r\n    # short-circuit as quickly as possible, and avoid calling startswith\r\n    #~ @profile\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        if (instring[loc] == self.firstMatchChar and\r\n            (self.matchLen==1 or instring.startswith(self.match,loc)) ):\r\n            return loc+self.matchLen, self.match\r\n        raise ParseException(instring, loc, self.errmsg, self)\r\n_L = Literal\r\nParserElement.literalStringClass = Literal\r\n\r\nclass Keyword(Token):\r\n    """"""Token to exactly match a specified string as a keyword, that is, it must be\r\n       immediately followed by a non-keyword character.  Compare with C{L{Literal}}::\r\n         Literal(""if"") will match the leading C{\'if\'} in C{\'ifAndOnlyIf\'}.\r\n         Keyword(""if"") will not; it will only match the leading C{\'if\'} in C{\'if x=1\'}, or C{\'if(y==2)\'}\r\n       Accepts two optional constructor arguments in addition to the keyword string:\r\n       C{identChars} is a string of characters that would be valid identifier characters,\r\n       defaulting to all alphanumerics + ""_"" and ""$""; C{caseless} allows case-insensitive\r\n       matching, default is C{False}.\r\n    """"""\r\n    DEFAULT_KEYWORD_CHARS = alphanums+""_$""\r\n\r\n    def __init__( self, matchString, identChars=DEFAULT_KEYWORD_CHARS, caseless=False ):\r\n        super(Keyword,self).__init__()\r\n        self.match = matchString\r\n        self.matchLen = len(matchString)\r\n        try:\r\n            self.firstMatchChar = matchString[0]\r\n        except IndexError:\r\n            warnings.warn(""null string passed to Keyword; use Empty() instead"",\r\n                            SyntaxWarning, stacklevel=2)\r\n        self.name = \'""%s""\' % self.match\r\n        self.errmsg = ""Expected "" + self.name\r\n        self.mayReturnEmpty = False\r\n        self.mayIndexError = False\r\n        self.caseless = caseless\r\n        if caseless:\r\n            self.caselessmatch = matchString.upper()\r\n            identChars = identChars.upper()\r\n        self.identChars = set(identChars)\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        if self.caseless:\r\n            if ( (instring[ loc:loc+self.matchLen ].upper() == self.caselessmatch) and\r\n                 (loc >= len(instring)-self.matchLen or instring[loc+self.matchLen].upper() not in self.identChars) and\r\n                 (loc == 0 or instring[loc-1].upper() not in self.identChars) ):\r\n                return loc+self.matchLen, self.match\r\n        else:\r\n            if (instring[loc] == self.firstMatchChar and\r\n                (self.matchLen==1 or instring.startswith(self.match,loc)) and\r\n                (loc >= len(instring)-self.matchLen or instring[loc+self.matchLen] not in self.identChars) and\r\n                (loc == 0 or instring[loc-1] not in self.identChars) ):\r\n                return loc+self.matchLen, self.match\r\n        raise ParseException(instring, loc, self.errmsg, self)\r\n\r\n    def copy(self):\r\n        c = super(Keyword,self).copy()\r\n        c.identChars = Keyword.DEFAULT_KEYWORD_CHARS\r\n        return c\r\n\r\n    def setDefaultKeywordChars( chars ):\r\n        """"""Overrides the default Keyword chars\r\n        """"""\r\n        Keyword.DEFAULT_KEYWORD_CHARS = chars\r\n    setDefaultKeywordChars = staticmethod(setDefaultKeywordChars)\r\n\r\nclass CaselessLiteral(Literal):\r\n    """"""Token to match a specified string, ignoring case of letters.\r\n       Note: the matched results will always be in the case of the given\r\n       match string, NOT the case of the input text.\r\n    """"""\r\n    def __init__( self, matchString ):\r\n        super(CaselessLiteral,self).__init__( matchString.upper() )\r\n        # Preserve the defining literal.\r\n        self.returnString = matchString\r\n        self.name = ""\'%s\'"" % self.returnString\r\n        self.errmsg = ""Expected "" + self.name\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        if instring[ loc:loc+self.matchLen ].upper() == self.match:\r\n            return loc+self.matchLen, self.returnString\r\n        raise ParseException(instring, loc, self.errmsg, self)\r\n\r\nclass CaselessKeyword(Keyword):\r\n    def __init__( self, matchString, identChars=Keyword.DEFAULT_KEYWORD_CHARS ):\r\n        super(CaselessKeyword,self).__init__( matchString, identChars, caseless=True )\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        if ( (instring[ loc:loc+self.matchLen ].upper() == self.caselessmatch) and\r\n             (loc >= len(instring)-self.matchLen or instring[loc+self.matchLen].upper() not in self.identChars) ):\r\n            return loc+self.matchLen, self.match\r\n        raise ParseException(instring, loc, self.errmsg, self)\r\n\r\nclass Word(Token):\r\n    """"""Token for matching words composed of allowed character sets.\r\n       Defined with string containing all allowed initial characters,\r\n       an optional string containing allowed body characters (if omitted,\r\n       defaults to the initial character set), and an optional minimum,\r\n       maximum, and/or exact length.  The default value for C{min} is 1 (a\r\n       minimum value < 1 is not valid); the default values for C{max} and C{exact}\r\n       are 0, meaning no maximum or exact length restriction. An optional\r\n       C{exclude} parameter can list characters that might be found in \r\n       the input C{bodyChars} string; useful to define a word of all printables\r\n       except for one or two characters, for instance.\r\n    """"""\r\n    def __init__( self, initChars, bodyChars=None, min=1, max=0, exact=0, asKeyword=False, excludeChars=None ):\r\n        super(Word,self).__init__()\r\n        if excludeChars:\r\n            initChars = \'\'.join(c for c in initChars if c not in excludeChars)\r\n            if bodyChars:\r\n                bodyChars = \'\'.join(c for c in bodyChars if c not in excludeChars)\r\n        self.initCharsOrig = initChars\r\n        self.initChars = set(initChars)\r\n        if bodyChars :\r\n            self.bodyCharsOrig = bodyChars\r\n            self.bodyChars = set(bodyChars)\r\n        else:\r\n            self.bodyCharsOrig = initChars\r\n            self.bodyChars = set(initChars)\r\n\r\n        self.maxSpecified = max > 0\r\n\r\n        if min < 1:\r\n            raise ValueError(""cannot specify a minimum length < 1; use Optional(Word()) if zero-length word is permitted"")\r\n\r\n        self.minLen = min\r\n\r\n        if max > 0:\r\n            self.maxLen = max\r\n        else:\r\n            self.maxLen = _MAX_INT\r\n\r\n        if exact > 0:\r\n            self.maxLen = exact\r\n            self.minLen = exact\r\n\r\n        self.name = _ustr(self)\r\n        self.errmsg = ""Expected "" + self.name\r\n        self.mayIndexError = False\r\n        self.asKeyword = asKeyword\r\n\r\n        if \' \' not in self.initCharsOrig+self.bodyCharsOrig and (min==1 and max==0 and exact==0):\r\n            if self.bodyCharsOrig == self.initCharsOrig:\r\n                self.reString = ""[%s]+"" % _escapeRegexRangeChars(self.initCharsOrig)\r\n            elif len(self.bodyCharsOrig) == 1:\r\n                self.reString = ""%s[%s]*"" % \\\r\n                                      (re.escape(self.initCharsOrig),\r\n                                      _escapeRegexRangeChars(self.bodyCharsOrig),)\r\n            else:\r\n                self.reString = ""[%s][%s]*"" % \\\r\n                                      (_escapeRegexRangeChars(self.initCharsOrig),\r\n                                      _escapeRegexRangeChars(self.bodyCharsOrig),)\r\n            if self.asKeyword:\r\n                self.reString = r""\\b""+self.reString+r""\\b""\r\n            try:\r\n                self.re = re.compile( self.reString )\r\n            except:\r\n                self.re = None\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        if self.re:\r\n            result = self.re.match(instring,loc)\r\n            if not result:\r\n                raise ParseException(instring, loc, self.errmsg, self)\r\n\r\n            loc = result.end()\r\n            return loc, result.group()\r\n\r\n        if not(instring[ loc ] in self.initChars):\r\n            raise ParseException(instring, loc, self.errmsg, self)\r\n\r\n        start = loc\r\n        loc += 1\r\n        instrlen = len(instring)\r\n        bodychars = self.bodyChars\r\n        maxloc = start + self.maxLen\r\n        maxloc = min( maxloc, instrlen )\r\n        while loc < maxloc and instring[loc] in bodychars:\r\n            loc += 1\r\n\r\n        throwException = False\r\n        if loc - start < self.minLen:\r\n            throwException = True\r\n        if self.maxSpecified and loc < instrlen and instring[loc] in bodychars:\r\n            throwException = True\r\n        if self.asKeyword:\r\n            if (start>0 and instring[start-1] in bodychars) or (loc<instrlen and instring[loc] in bodychars):\r\n                throwException = True\r\n\r\n        if throwException:\r\n            raise ParseException(instring, loc, self.errmsg, self)\r\n\r\n        return loc, instring[start:loc]\r\n\r\n    def __str__( self ):\r\n        try:\r\n            return super(Word,self).__str__()\r\n        except:\r\n            pass\r\n\r\n\r\n        if self.strRepr is None:\r\n\r\n            def charsAsStr(s):\r\n                if len(s)>4:\r\n                    return s[:4]+""...""\r\n                else:\r\n                    return s\r\n\r\n            if ( self.initCharsOrig != self.bodyCharsOrig ):\r\n                self.strRepr = ""W:(%s,%s)"" % ( charsAsStr(self.initCharsOrig), charsAsStr(self.bodyCharsOrig) )\r\n            else:\r\n                self.strRepr = ""W:(%s)"" % charsAsStr(self.initCharsOrig)\r\n\r\n        return self.strRepr\r\n\r\n\r\nclass Regex(Token):\r\n    """"""Token for matching strings that match a given regular expression.\r\n       Defined with string specifying the regular expression in a form recognized by the inbuilt Python re module.\r\n    """"""\r\n    compiledREtype = type(re.compile(""[A-Z]""))\r\n    def __init__( self, pattern, flags=0):\r\n        """"""The parameters C{pattern} and C{flags} are passed to the C{re.compile()} function as-is. See the Python C{re} module for an explanation of the acceptable patterns and flags.""""""\r\n        super(Regex,self).__init__()\r\n\r\n        if isinstance(pattern, basestring):\r\n            if len(pattern) == 0:\r\n                warnings.warn(""null string passed to Regex; use Empty() instead"",\r\n                        SyntaxWarning, stacklevel=2)\r\n\r\n            self.pattern = pattern\r\n            self.flags = flags\r\n\r\n            try:\r\n                self.re = re.compile(self.pattern, self.flags)\r\n                self.reString = self.pattern\r\n            except sre_constants.error:\r\n                warnings.warn(""invalid pattern (%s) passed to Regex"" % pattern,\r\n                    SyntaxWarning, stacklevel=2)\r\n                raise\r\n\r\n        elif isinstance(pattern, Regex.compiledREtype):\r\n            self.re = pattern\r\n            self.pattern = \\\r\n            self.reString = str(pattern)\r\n            self.flags = flags\r\n            \r\n        else:\r\n            raise ValueError(""Regex may only be constructed with a string or a compiled RE object"")\r\n\r\n        self.name = _ustr(self)\r\n        self.errmsg = ""Expected "" + self.name\r\n        self.mayIndexError = False\r\n        self.mayReturnEmpty = True\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        result = self.re.match(instring,loc)\r\n        if not result:\r\n            raise ParseException(instring, loc, self.errmsg, self)\r\n\r\n        loc = result.end()\r\n        d = result.groupdict()\r\n        ret = ParseResults(result.group())\r\n        if d:\r\n            for k in d:\r\n                ret[k] = d[k]\r\n        return loc,ret\r\n\r\n    def __str__( self ):\r\n        try:\r\n            return super(Regex,self).__str__()\r\n        except:\r\n            pass\r\n\r\n        if self.strRepr is None:\r\n            self.strRepr = ""Re:(%s)"" % repr(self.pattern)\r\n\r\n        return self.strRepr\r\n\r\n\r\nclass QuotedString(Token):\r\n    """"""Token for matching strings that are delimited by quoting characters.\r\n    """"""\r\n    def __init__( self, quoteChar, escChar=None, escQuote=None, multiline=False, unquoteResults=True, endQuoteChar=None):\r\n        """"""\r\n           Defined with the following parameters:\r\n            - quoteChar - string of one or more characters defining the quote delimiting string\r\n            - escChar - character to escape quotes, typically backslash (default=None)\r\n            - escQuote - special quote sequence to escape an embedded quote string (such as SQL\'s """" to escape an embedded "") (default=None)\r\n            - multiline - boolean indicating whether quotes can span multiple lines (default=C{False})\r\n            - unquoteResults - boolean indicating whether the matched text should be unquoted (default=C{True})\r\n            - endQuoteChar - string of one or more characters defining the end of the quote delimited string (default=C{None} => same as quoteChar)\r\n        """"""\r\n        super(QuotedString,self).__init__()\r\n\r\n        # remove white space from quote chars - wont work anyway\r\n        quoteChar = quoteChar.strip()\r\n        if len(quoteChar) == 0:\r\n            warnings.warn(""quoteChar cannot be the empty string"",SyntaxWarning,stacklevel=2)\r\n            raise SyntaxError()\r\n\r\n        if endQuoteChar is None:\r\n            endQuoteChar = quoteChar\r\n        else:\r\n            endQuoteChar = endQuoteChar.strip()\r\n            if len(endQuoteChar) == 0:\r\n                warnings.warn(""endQuoteChar cannot be the empty string"",SyntaxWarning,stacklevel=2)\r\n                raise SyntaxError()\r\n\r\n        self.quoteChar = quoteChar\r\n        self.quoteCharLen = len(quoteChar)\r\n        self.firstQuoteChar = quoteChar[0]\r\n        self.endQuoteChar = endQuoteChar\r\n        self.endQuoteCharLen = len(endQuoteChar)\r\n        self.escChar = escChar\r\n        self.escQuote = escQuote\r\n        self.unquoteResults = unquoteResults\r\n\r\n        if multiline:\r\n            self.flags = re.MULTILINE | re.DOTALL\r\n            self.pattern = r\'%s(?:[^%s%s]\' % \\\r\n                ( re.escape(self.quoteChar),\r\n                  _escapeRegexRangeChars(self.endQuoteChar[0]),\r\n                  (escChar is not None and _escapeRegexRangeChars(escChar) or \'\') )\r\n        else:\r\n            self.flags = 0\r\n            self.pattern = r\'%s(?:[^%s\\n\\r%s]\' % \\\r\n                ( re.escape(self.quoteChar),\r\n                  _escapeRegexRangeChars(self.endQuoteChar[0]),\r\n                  (escChar is not None and _escapeRegexRangeChars(escChar) or \'\') )\r\n        if len(self.endQuoteChar) > 1:\r\n            self.pattern += (\r\n                \'|(?:\' + \')|(?:\'.join(""%s[^%s]"" % (re.escape(self.endQuoteChar[:i]),\r\n                                               _escapeRegexRangeChars(self.endQuoteChar[i]))\r\n                                    for i in range(len(self.endQuoteChar)-1,0,-1)) + \')\'\r\n                )\r\n        if escQuote:\r\n            self.pattern += (r\'|(?:%s)\' % re.escape(escQuote))\r\n        if escChar:\r\n            self.pattern += (r\'|(?:%s.)\' % re.escape(escChar))\r\n            self.escCharReplacePattern = re.escape(self.escChar)+""(.)""\r\n        self.pattern += (r\')*%s\' % re.escape(self.endQuoteChar))\r\n\r\n        try:\r\n            self.re = re.compile(self.pattern, self.flags)\r\n            self.reString = self.pattern\r\n        except sre_constants.error:\r\n            warnings.warn(""invalid pattern (%s) passed to Regex"" % self.pattern,\r\n                SyntaxWarning, stacklevel=2)\r\n            raise\r\n\r\n        self.name = _ustr(self)\r\n        self.errmsg = ""Expected "" + self.name\r\n        self.mayIndexError = False\r\n        self.mayReturnEmpty = True\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        result = instring[loc] == self.firstQuoteChar and self.re.match(instring,loc) or None\r\n        if not result:\r\n            raise ParseException(instring, loc, self.errmsg, self)\r\n\r\n        loc = result.end()\r\n        ret = result.group()\r\n\r\n        if self.unquoteResults:\r\n\r\n            # strip off quotes\r\n            ret = ret[self.quoteCharLen:-self.endQuoteCharLen]\r\n\r\n            if isinstance(ret,basestring):\r\n                # replace escaped characters\r\n                if self.escChar:\r\n                    ret = re.sub(self.escCharReplacePattern,""\\g<1>"",ret)\r\n\r\n                # replace escaped quotes\r\n                if self.escQuote:\r\n                    ret = ret.replace(self.escQuote, self.endQuoteChar)\r\n\r\n        return loc, ret\r\n\r\n    def __str__( self ):\r\n        try:\r\n            return super(QuotedString,self).__str__()\r\n        except:\r\n            pass\r\n\r\n        if self.strRepr is None:\r\n            self.strRepr = ""quoted string, starting with %s ending with %s"" % (self.quoteChar, self.endQuoteChar)\r\n\r\n        return self.strRepr\r\n\r\n\r\nclass CharsNotIn(Token):\r\n    """"""Token for matching words composed of characters *not* in a given set.\r\n       Defined with string containing all disallowed characters, and an optional\r\n       minimum, maximum, and/or exact length.  The default value for C{min} is 1 (a\r\n       minimum value < 1 is not valid); the default values for C{max} and C{exact}\r\n       are 0, meaning no maximum or exact length restriction.\r\n    """"""\r\n    def __init__( self, notChars, min=1, max=0, exact=0 ):\r\n        super(CharsNotIn,self).__init__()\r\n        self.skipWhitespace = False\r\n        self.notChars = notChars\r\n\r\n        if min < 1:\r\n            raise ValueError(""cannot specify a minimum length < 1; use Optional(CharsNotIn()) if zero-length char group is permitted"")\r\n\r\n        self.minLen = min\r\n\r\n        if max > 0:\r\n            self.maxLen = max\r\n        else:\r\n            self.maxLen = _MAX_INT\r\n\r\n        if exact > 0:\r\n            self.maxLen = exact\r\n            self.minLen = exact\r\n\r\n        self.name = _ustr(self)\r\n        self.errmsg = ""Expected "" + self.name\r\n        self.mayReturnEmpty = ( self.minLen == 0 )\r\n        self.mayIndexError = False\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        if instring[loc] in self.notChars:\r\n            raise ParseException(instring, loc, self.errmsg, self)\r\n\r\n        start = loc\r\n        loc += 1\r\n        notchars = self.notChars\r\n        maxlen = min( start+self.maxLen, len(instring) )\r\n        while loc < maxlen and \\\r\n              (instring[loc] not in notchars):\r\n            loc += 1\r\n\r\n        if loc - start < self.minLen:\r\n            raise ParseException(instring, loc, self.errmsg, self)\r\n\r\n        return loc, instring[start:loc]\r\n\r\n    def __str__( self ):\r\n        try:\r\n            return super(CharsNotIn, self).__str__()\r\n        except:\r\n            pass\r\n\r\n        if self.strRepr is None:\r\n            if len(self.notChars) > 4:\r\n                self.strRepr = ""!W:(%s...)"" % self.notChars[:4]\r\n            else:\r\n                self.strRepr = ""!W:(%s)"" % self.notChars\r\n\r\n        return self.strRepr\r\n\r\nclass White(Token):\r\n    """"""Special matching class for matching whitespace.  Normally, whitespace is ignored\r\n       by pyparsing grammars.  This class is included when some whitespace structures\r\n       are significant.  Define with a string containing the whitespace characters to be\r\n       matched; default is C{"" \\\\t\\\\r\\\\n""}.  Also takes optional C{min}, C{max}, and C{exact} arguments,\r\n       as defined for the C{L{Word}} class.""""""\r\n    whiteStrs = {\r\n        "" "" : ""<SPC>"",\r\n        ""\\t"": ""<TAB>"",\r\n        ""\\n"": ""<LF>"",\r\n        ""\\r"": ""<CR>"",\r\n        ""\\f"": ""<FF>"",\r\n        }\r\n    def __init__(self, ws="" \\t\\r\\n"", min=1, max=0, exact=0):\r\n        super(White,self).__init__()\r\n        self.matchWhite = ws\r\n        self.setWhitespaceChars( """".join(c for c in self.whiteChars if c not in self.matchWhite) )\r\n        #~ self.leaveWhitespace()\r\n        self.name = ("""".join(White.whiteStrs[c] for c in self.matchWhite))\r\n        self.mayReturnEmpty = True\r\n        self.errmsg = ""Expected "" + self.name\r\n\r\n        self.minLen = min\r\n\r\n        if max > 0:\r\n            self.maxLen = max\r\n        else:\r\n            self.maxLen = _MAX_INT\r\n\r\n        if exact > 0:\r\n            self.maxLen = exact\r\n            self.minLen = exact\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        if not(instring[ loc ] in self.matchWhite):\r\n            raise ParseException(instring, loc, self.errmsg, self)\r\n        start = loc\r\n        loc += 1\r\n        maxloc = start + self.maxLen\r\n        maxloc = min( maxloc, len(instring) )\r\n        while loc < maxloc and instring[loc] in self.matchWhite:\r\n            loc += 1\r\n\r\n        if loc - start < self.minLen:\r\n            raise ParseException(instring, loc, self.errmsg, self)\r\n\r\n        return loc, instring[start:loc]\r\n\r\n\r\nclass _PositionToken(Token):\r\n    def __init__( self ):\r\n        super(_PositionToken,self).__init__()\r\n        self.name=self.__class__.__name__\r\n        self.mayReturnEmpty = True\r\n        self.mayIndexError = False\r\n\r\nclass GoToColumn(_PositionToken):\r\n    """"""Token to advance to a specific column of input text; useful for tabular report scraping.""""""\r\n    def __init__( self, colno ):\r\n        super(GoToColumn,self).__init__()\r\n        self.col = colno\r\n\r\n    def preParse( self, instring, loc ):\r\n        if col(loc,instring) != self.col:\r\n            instrlen = len(instring)\r\n            if self.ignoreExprs:\r\n                loc = self._skipIgnorables( instring, loc )\r\n            while loc < instrlen and instring[loc].isspace() and col( loc, instring ) != self.col :\r\n                loc += 1\r\n        return loc\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        thiscol = col( loc, instring )\r\n        if thiscol > self.col:\r\n            raise ParseException( instring, loc, ""Text not in expected column"", self )\r\n        newloc = loc + self.col - thiscol\r\n        ret = instring[ loc: newloc ]\r\n        return newloc, ret\r\n\r\nclass LineStart(_PositionToken):\r\n    """"""Matches if current position is at the beginning of a line within the parse string""""""\r\n    def __init__( self ):\r\n        super(LineStart,self).__init__()\r\n        self.setWhitespaceChars( ParserElement.DEFAULT_WHITE_CHARS.replace(""\\n"","""") )\r\n        self.errmsg = ""Expected start of line""\r\n\r\n    def preParse( self, instring, loc ):\r\n        preloc = super(LineStart,self).preParse(instring,loc)\r\n        if instring[preloc] == ""\\n"":\r\n            loc += 1\r\n        return loc\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        if not( loc==0 or\r\n            (loc == self.preParse( instring, 0 )) or\r\n            (instring[loc-1] == ""\\n"") ): #col(loc, instring) != 1:\r\n            raise ParseException(instring, loc, self.errmsg, self)\r\n        return loc, []\r\n\r\nclass LineEnd(_PositionToken):\r\n    """"""Matches if current position is at the end of a line within the parse string""""""\r\n    def __init__( self ):\r\n        super(LineEnd,self).__init__()\r\n        self.setWhitespaceChars( ParserElement.DEFAULT_WHITE_CHARS.replace(""\\n"","""") )\r\n        self.errmsg = ""Expected end of line""\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        if loc<len(instring):\r\n            if instring[loc] == ""\\n"":\r\n                return loc+1, ""\\n""\r\n            else:\r\n                raise ParseException(instring, loc, self.errmsg, self)\r\n        elif loc == len(instring):\r\n            return loc+1, []\r\n        else:\r\n            raise ParseException(instring, loc, self.errmsg, self)\r\n\r\nclass StringStart(_PositionToken):\r\n    """"""Matches if current position is at the beginning of the parse string""""""\r\n    def __init__( self ):\r\n        super(StringStart,self).__init__()\r\n        self.errmsg = ""Expected start of text""\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        if loc != 0:\r\n            # see if entire string up to here is just whitespace and ignoreables\r\n            if loc != self.preParse( instring, 0 ):\r\n                raise ParseException(instring, loc, self.errmsg, self)\r\n        return loc, []\r\n\r\nclass StringEnd(_PositionToken):\r\n    """"""Matches if current position is at the end of the parse string""""""\r\n    def __init__( self ):\r\n        super(StringEnd,self).__init__()\r\n        self.errmsg = ""Expected end of text""\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        if loc < len(instring):\r\n            raise ParseException(instring, loc, self.errmsg, self)\r\n        elif loc == len(instring):\r\n            return loc+1, []\r\n        elif loc > len(instring):\r\n            return loc, []\r\n        else:\r\n            raise ParseException(instring, loc, self.errmsg, self)\r\n\r\nclass WordStart(_PositionToken):\r\n    """"""Matches if the current position is at the beginning of a Word, and\r\n       is not preceded by any character in a given set of C{wordChars}\r\n       (default=C{printables}). To emulate the C{\\b} behavior of regular expressions,\r\n       use C{WordStart(alphanums)}. C{WordStart} will also match at the beginning of\r\n       the string being parsed, or at the beginning of a line.\r\n    """"""\r\n    def __init__(self, wordChars = printables):\r\n        super(WordStart,self).__init__()\r\n        self.wordChars = set(wordChars)\r\n        self.errmsg = ""Not at the start of a word""\r\n\r\n    def parseImpl(self, instring, loc, doActions=True ):\r\n        if loc != 0:\r\n            if (instring[loc-1] in self.wordChars or\r\n                instring[loc] not in self.wordChars):\r\n                raise ParseException(instring, loc, self.errmsg, self)\r\n        return loc, []\r\n\r\nclass WordEnd(_PositionToken):\r\n    """"""Matches if the current position is at the end of a Word, and\r\n       is not followed by any character in a given set of C{wordChars}\r\n       (default=C{printables}). To emulate the C{\\b} behavior of regular expressions,\r\n       use C{WordEnd(alphanums)}. C{WordEnd} will also match at the end of\r\n       the string being parsed, or at the end of a line.\r\n    """"""\r\n    def __init__(self, wordChars = printables):\r\n        super(WordEnd,self).__init__()\r\n        self.wordChars = set(wordChars)\r\n        self.skipWhitespace = False\r\n        self.errmsg = ""Not at the end of a word""\r\n\r\n    def parseImpl(self, instring, loc, doActions=True ):\r\n        instrlen = len(instring)\r\n        if instrlen>0 and loc<instrlen:\r\n            if (instring[loc] in self.wordChars or\r\n                instring[loc-1] not in self.wordChars):\r\n                raise ParseException(instring, loc, self.errmsg, self)\r\n        return loc, []\r\n\r\n\r\nclass ParseExpression(ParserElement):\r\n    """"""Abstract subclass of ParserElement, for combining and post-processing parsed tokens.""""""\r\n    def __init__( self, exprs, savelist = False ):\r\n        super(ParseExpression,self).__init__(savelist)\r\n        if isinstance( exprs, _generatorType ):\r\n            exprs = list(exprs)\r\n\r\n        if isinstance( exprs, basestring ):\r\n            self.exprs = [ Literal( exprs ) ]\r\n        elif isinstance( exprs, collections.Sequence ):\r\n            # if sequence of strings provided, wrap with Literal\r\n            if all(isinstance(expr, basestring) for expr in exprs):\r\n                exprs = map(Literal, exprs)\r\n            self.exprs = list(exprs)\r\n        else:\r\n            try:\r\n                self.exprs = list( exprs )\r\n            except TypeError:\r\n                self.exprs = [ exprs ]\r\n        self.callPreparse = False\r\n\r\n    def __getitem__( self, i ):\r\n        return self.exprs[i]\r\n\r\n    def append( self, other ):\r\n        self.exprs.append( other )\r\n        self.strRepr = None\r\n        return self\r\n\r\n    def leaveWhitespace( self ):\r\n        """"""Extends C{leaveWhitespace} defined in base class, and also invokes C{leaveWhitespace} on\r\n           all contained expressions.""""""\r\n        self.skipWhitespace = False\r\n        self.exprs = [ e.copy() for e in self.exprs ]\r\n        for e in self.exprs:\r\n            e.leaveWhitespace()\r\n        return self\r\n\r\n    def ignore( self, other ):\r\n        if isinstance( other, Suppress ):\r\n            if other not in self.ignoreExprs:\r\n                super( ParseExpression, self).ignore( other )\r\n                for e in self.exprs:\r\n                    e.ignore( self.ignoreExprs[-1] )\r\n        else:\r\n            super( ParseExpression, self).ignore( other )\r\n            for e in self.exprs:\r\n                e.ignore( self.ignoreExprs[-1] )\r\n        return self\r\n\r\n    def __str__( self ):\r\n        try:\r\n            return super(ParseExpression,self).__str__()\r\n        except:\r\n            pass\r\n\r\n        if self.strRepr is None:\r\n            self.strRepr = ""%s:(%s)"" % ( self.__class__.__name__, _ustr(self.exprs) )\r\n        return self.strRepr\r\n\r\n    def streamline( self ):\r\n        super(ParseExpression,self).streamline()\r\n\r\n        for e in self.exprs:\r\n            e.streamline()\r\n\r\n        # collapse nested And\'s of the form And( And( And( a,b), c), d) to And( a,b,c,d )\r\n        # but only if there are no parse actions or resultsNames on the nested And\'s\r\n        # (likewise for Or\'s and MatchFirst\'s)\r\n        if ( len(self.exprs) == 2 ):\r\n            other = self.exprs[0]\r\n            if ( isinstance( other, self.__class__ ) and\r\n                  not(other.parseAction) and\r\n                  other.resultsName is None and\r\n                  not other.debug ):\r\n                self.exprs = other.exprs[:] + [ self.exprs[1] ]\r\n                self.strRepr = None\r\n                self.mayReturnEmpty |= other.mayReturnEmpty\r\n                self.mayIndexError  |= other.mayIndexError\r\n\r\n            other = self.exprs[-1]\r\n            if ( isinstance( other, self.__class__ ) and\r\n                  not(other.parseAction) and\r\n                  other.resultsName is None and\r\n                  not other.debug ):\r\n                self.exprs = self.exprs[:-1] + other.exprs[:]\r\n                self.strRepr = None\r\n                self.mayReturnEmpty |= other.mayReturnEmpty\r\n                self.mayIndexError  |= other.mayIndexError\r\n\r\n        return self\r\n\r\n    def setResultsName( self, name, listAllMatches=False ):\r\n        ret = super(ParseExpression,self).setResultsName(name,listAllMatches)\r\n        return ret\r\n\r\n    def validate( self, validateTrace=[] ):\r\n        tmp = validateTrace[:]+[self]\r\n        for e in self.exprs:\r\n            e.validate(tmp)\r\n        self.checkRecursion( [] )\r\n        \r\n    def copy(self):\r\n        ret = super(ParseExpression,self).copy()\r\n        ret.exprs = [e.copy() for e in self.exprs]\r\n        return ret\r\n\r\nclass And(ParseExpression):\r\n    """"""Requires all given C{ParseExpression}s to be found in the given order.\r\n       Expressions may be separated by whitespace.\r\n       May be constructed using the C{\'+\'} operator.\r\n    """"""\r\n\r\n    class _ErrorStop(Empty):\r\n        def __init__(self, *args, **kwargs):\r\n            super(And._ErrorStop,self).__init__(*args, **kwargs)\r\n            self.name = \'-\'\r\n            self.leaveWhitespace()\r\n\r\n    def __init__( self, exprs, savelist = True ):\r\n        super(And,self).__init__(exprs, savelist)\r\n        self.mayReturnEmpty = all(e.mayReturnEmpty for e in self.exprs)\r\n        self.setWhitespaceChars( self.exprs[0].whiteChars )\r\n        self.skipWhitespace = self.exprs[0].skipWhitespace\r\n        self.callPreparse = True\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        # pass False as last arg to _parse for first element, since we already\r\n        # pre-parsed the string as part of our And pre-parsing\r\n        loc, resultlist = self.exprs[0]._parse( instring, loc, doActions, callPreParse=False )\r\n        errorStop = False\r\n        for e in self.exprs[1:]:\r\n            if isinstance(e, And._ErrorStop):\r\n                errorStop = True\r\n                continue\r\n            if errorStop:\r\n                try:\r\n                    loc, exprtokens = e._parse( instring, loc, doActions )\r\n                except ParseSyntaxException:\r\n                    raise\r\n                except ParseBaseException as pe:\r\n                    pe.__traceback__ = None\r\n                    raise ParseSyntaxException(pe)\r\n                except IndexError:\r\n                    raise ParseSyntaxException( ParseException(instring, len(instring), self.errmsg, self) )\r\n            else:\r\n                loc, exprtokens = e._parse( instring, loc, doActions )\r\n            if exprtokens or exprtokens.haskeys():\r\n                resultlist += exprtokens\r\n        return loc, resultlist\r\n\r\n    def __iadd__(self, other ):\r\n        if isinstance( other, basestring ):\r\n            other = Literal( other )\r\n        return self.append( other ) #And( [ self, other ] )\r\n\r\n    def checkRecursion( self, parseElementList ):\r\n        subRecCheckList = parseElementList[:] + [ self ]\r\n        for e in self.exprs:\r\n            e.checkRecursion( subRecCheckList )\r\n            if not e.mayReturnEmpty:\r\n                break\r\n\r\n    def __str__( self ):\r\n        if hasattr(self,""name""):\r\n            return self.name\r\n\r\n        if self.strRepr is None:\r\n            self.strRepr = ""{"" + "" "".join(_ustr(e) for e in self.exprs) + ""}""\r\n\r\n        return self.strRepr\r\n\r\n\r\nclass Or(ParseExpression):\r\n    """"""Requires that at least one C{ParseExpression} is found.\r\n       If two expressions match, the expression that matches the longest string will be used.\r\n       May be constructed using the C{\'^\'} operator.\r\n    """"""\r\n    def __init__( self, exprs, savelist = False ):\r\n        super(Or,self).__init__(exprs, savelist)\r\n        if self.exprs:\r\n            self.mayReturnEmpty = any(e.mayReturnEmpty for e in self.exprs)\r\n        else:\r\n            self.mayReturnEmpty = True\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        maxExcLoc = -1\r\n        maxMatchLoc = -1\r\n        maxException = None\r\n        for e in self.exprs:\r\n            try:\r\n                loc2 = e.tryParse( instring, loc )\r\n            except ParseException as err:\r\n                err.__traceback__ = None\r\n                if err.loc > maxExcLoc:\r\n                    maxException = err\r\n                    maxExcLoc = err.loc\r\n            except IndexError:\r\n                if len(instring) > maxExcLoc:\r\n                    maxException = ParseException(instring,len(instring),e.errmsg,self)\r\n                    maxExcLoc = len(instring)\r\n            else:\r\n                if loc2 > maxMatchLoc:\r\n                    maxMatchLoc = loc2\r\n                    maxMatchExp = e\r\n\r\n        if maxMatchLoc < 0:\r\n            if maxException is not None:\r\n                raise maxException\r\n            else:\r\n                raise ParseException(instring, loc, ""no defined alternatives to match"", self)\r\n\r\n        return maxMatchExp._parse( instring, loc, doActions )\r\n\r\n    def __ixor__(self, other ):\r\n        if isinstance( other, basestring ):\r\n            other = ParserElement.literalStringClass( other )\r\n        return self.append( other ) #Or( [ self, other ] )\r\n\r\n    def __str__( self ):\r\n        if hasattr(self,""name""):\r\n            return self.name\r\n\r\n        if self.strRepr is None:\r\n            self.strRepr = ""{"" + "" ^ "".join(_ustr(e) for e in self.exprs) + ""}""\r\n\r\n        return self.strRepr\r\n\r\n    def checkRecursion( self, parseElementList ):\r\n        subRecCheckList = parseElementList[:] + [ self ]\r\n        for e in self.exprs:\r\n            e.checkRecursion( subRecCheckList )\r\n\r\n\r\nclass MatchFirst(ParseExpression):\r\n    """"""Requires that at least one C{ParseExpression} is found.\r\n       If two expressions match, the first one listed is the one that will match.\r\n       May be constructed using the C{\'|\'} operator.\r\n    """"""\r\n    def __init__( self, exprs, savelist = False ):\r\n        super(MatchFirst,self).__init__(exprs, savelist)\r\n        if self.exprs:\r\n            self.mayReturnEmpty = any(e.mayReturnEmpty for e in self.exprs)\r\n        else:\r\n            self.mayReturnEmpty = True\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        maxExcLoc = -1\r\n        maxException = None\r\n        for e in self.exprs:\r\n            try:\r\n                ret = e._parse( instring, loc, doActions )\r\n                return ret\r\n            except ParseException as err:\r\n                if err.loc > maxExcLoc:\r\n                    maxException = err\r\n                    maxExcLoc = err.loc\r\n            except IndexError:\r\n                if len(instring) > maxExcLoc:\r\n                    maxException = ParseException(instring,len(instring),e.errmsg,self)\r\n                    maxExcLoc = len(instring)\r\n\r\n        # only got here if no expression matched, raise exception for match that made it the furthest\r\n        else:\r\n            if maxException is not None:\r\n                raise maxException\r\n            else:\r\n                raise ParseException(instring, loc, ""no defined alternatives to match"", self)\r\n\r\n    def __ior__(self, other ):\r\n        if isinstance( other, basestring ):\r\n            other = ParserElement.literalStringClass( other )\r\n        return self.append( other ) #MatchFirst( [ self, other ] )\r\n\r\n    def __str__( self ):\r\n        if hasattr(self,""name""):\r\n            return self.name\r\n\r\n        if self.strRepr is None:\r\n            self.strRepr = ""{"" + "" | "".join(_ustr(e) for e in self.exprs) + ""}""\r\n\r\n        return self.strRepr\r\n\r\n    def checkRecursion( self, parseElementList ):\r\n        subRecCheckList = parseElementList[:] + [ self ]\r\n        for e in self.exprs:\r\n            e.checkRecursion( subRecCheckList )\r\n\r\n\r\nclass Each(ParseExpression):\r\n    """"""Requires all given C{ParseExpression}s to be found, but in any order.\r\n       Expressions may be separated by whitespace.\r\n       May be constructed using the C{\'&\'} operator.\r\n    """"""\r\n    def __init__( self, exprs, savelist = True ):\r\n        super(Each,self).__init__(exprs, savelist)\r\n        self.mayReturnEmpty = all(e.mayReturnEmpty for e in self.exprs)\r\n        self.skipWhitespace = True\r\n        self.initExprGroups = True\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        if self.initExprGroups:\r\n            opt1 = [ e.expr for e in self.exprs if isinstance(e,Optional) ]\r\n            opt2 = [ e for e in self.exprs if e.mayReturnEmpty and e not in opt1 ]\r\n            self.optionals = opt1 + opt2\r\n            self.multioptionals = [ e.expr for e in self.exprs if isinstance(e,ZeroOrMore) ]\r\n            self.multirequired = [ e.expr for e in self.exprs if isinstance(e,OneOrMore) ]\r\n            self.required = [ e for e in self.exprs if not isinstance(e,(Optional,ZeroOrMore,OneOrMore)) ]\r\n            self.required += self.multirequired\r\n            self.initExprGroups = False\r\n        tmpLoc = loc\r\n        tmpReqd = self.required[:]\r\n        tmpOpt  = self.optionals[:]\r\n        matchOrder = []\r\n\r\n        keepMatching = True\r\n        while keepMatching:\r\n            tmpExprs = tmpReqd + tmpOpt + self.multioptionals + self.multirequired\r\n            failed = []\r\n            for e in tmpExprs:\r\n                try:\r\n                    tmpLoc = e.tryParse( instring, tmpLoc )\r\n                except ParseException:\r\n                    failed.append(e)\r\n                else:\r\n                    matchOrder.append(e)\r\n                    if e in tmpReqd:\r\n                        tmpReqd.remove(e)\r\n                    elif e in tmpOpt:\r\n                        tmpOpt.remove(e)\r\n            if len(failed) == len(tmpExprs):\r\n                keepMatching = False\r\n\r\n        if tmpReqd:\r\n            missing = "", "".join(_ustr(e) for e in tmpReqd)\r\n            raise ParseException(instring,loc,""Missing one or more required elements (%s)"" % missing )\r\n\r\n        # add any unmatched Optionals, in case they have default values defined\r\n        matchOrder += [e for e in self.exprs if isinstance(e,Optional) and e.expr in tmpOpt]\r\n\r\n        resultlist = []\r\n        for e in matchOrder:\r\n            loc,results = e._parse(instring,loc,doActions)\r\n            resultlist.append(results)\r\n\r\n        finalResults = ParseResults([])\r\n        for r in resultlist:\r\n            dups = {}\r\n            for k in r.keys():\r\n                if k in finalResults:\r\n                    tmp = ParseResults(finalResults[k])\r\n                    tmp += ParseResults(r[k])\r\n                    dups[k] = tmp\r\n            finalResults += ParseResults(r)\r\n            for k,v in dups.items():\r\n                finalResults[k] = v\r\n        return loc, finalResults\r\n\r\n    def __str__( self ):\r\n        if hasattr(self,""name""):\r\n            return self.name\r\n\r\n        if self.strRepr is None:\r\n            self.strRepr = ""{"" + "" & "".join(_ustr(e) for e in self.exprs) + ""}""\r\n\r\n        return self.strRepr\r\n\r\n    def checkRecursion( self, parseElementList ):\r\n        subRecCheckList = parseElementList[:] + [ self ]\r\n        for e in self.exprs:\r\n            e.checkRecursion( subRecCheckList )\r\n\r\n\r\nclass ParseElementEnhance(ParserElement):\r\n    """"""Abstract subclass of C{ParserElement}, for combining and post-processing parsed tokens.""""""\r\n    def __init__( self, expr, savelist=False ):\r\n        super(ParseElementEnhance,self).__init__(savelist)\r\n        if isinstance( expr, basestring ):\r\n            expr = Literal(expr)\r\n        self.expr = expr\r\n        self.strRepr = None\r\n        if expr is not None:\r\n            self.mayIndexError = expr.mayIndexError\r\n            self.mayReturnEmpty = expr.mayReturnEmpty\r\n            self.setWhitespaceChars( expr.whiteChars )\r\n            self.skipWhitespace = expr.skipWhitespace\r\n            self.saveAsList = expr.saveAsList\r\n            self.callPreparse = expr.callPreparse\r\n            self.ignoreExprs.extend(expr.ignoreExprs)\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        if self.expr is not None:\r\n            return self.expr._parse( instring, loc, doActions, callPreParse=False )\r\n        else:\r\n            raise ParseException("""",loc,self.errmsg,self)\r\n\r\n    def leaveWhitespace( self ):\r\n        self.skipWhitespace = False\r\n        self.expr = self.expr.copy()\r\n        if self.expr is not None:\r\n            self.expr.leaveWhitespace()\r\n        return self\r\n\r\n    def ignore( self, other ):\r\n        if isinstance( other, Suppress ):\r\n            if other not in self.ignoreExprs:\r\n                super( ParseElementEnhance, self).ignore( other )\r\n                if self.expr is not None:\r\n                    self.expr.ignore( self.ignoreExprs[-1] )\r\n        else:\r\n            super( ParseElementEnhance, self).ignore( other )\r\n            if self.expr is not None:\r\n                self.expr.ignore( self.ignoreExprs[-1] )\r\n        return self\r\n\r\n    def streamline( self ):\r\n        super(ParseElementEnhance,self).streamline()\r\n        if self.expr is not None:\r\n            self.expr.streamline()\r\n        return self\r\n\r\n    def checkRecursion( self, parseElementList ):\r\n        if self in parseElementList:\r\n            raise RecursiveGrammarException( parseElementList+[self] )\r\n        subRecCheckList = parseElementList[:] + [ self ]\r\n        if self.expr is not None:\r\n            self.expr.checkRecursion( subRecCheckList )\r\n\r\n    def validate( self, validateTrace=[] ):\r\n        tmp = validateTrace[:]+[self]\r\n        if self.expr is not None:\r\n            self.expr.validate(tmp)\r\n        self.checkRecursion( [] )\r\n\r\n    def __str__( self ):\r\n        try:\r\n            return super(ParseElementEnhance,self).__str__()\r\n        except:\r\n            pass\r\n\r\n        if self.strRepr is None and self.expr is not None:\r\n            self.strRepr = ""%s:(%s)"" % ( self.__class__.__name__, _ustr(self.expr) )\r\n        return self.strRepr\r\n\r\n\r\nclass FollowedBy(ParseElementEnhance):\r\n    """"""Lookahead matching of the given parse expression.  C{FollowedBy}\r\n    does *not* advance the parsing position within the input string, it only\r\n    verifies that the specified parse expression matches at the current\r\n    position.  C{FollowedBy} always returns a null token list.""""""\r\n    def __init__( self, expr ):\r\n        super(FollowedBy,self).__init__(expr)\r\n        self.mayReturnEmpty = True\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        self.expr.tryParse( instring, loc )\r\n        return loc, []\r\n\r\n\r\nclass NotAny(ParseElementEnhance):\r\n    """"""Lookahead to disallow matching with the given parse expression.  C{NotAny}\r\n    does *not* advance the parsing position within the input string, it only\r\n    verifies that the specified parse expression does *not* match at the current\r\n    position.  Also, C{NotAny} does *not* skip over leading whitespace. C{NotAny}\r\n    always returns a null token list.  May be constructed using the \'~\' operator.""""""\r\n    def __init__( self, expr ):\r\n        super(NotAny,self).__init__(expr)\r\n        #~ self.leaveWhitespace()\r\n        self.skipWhitespace = False  # do NOT use self.leaveWhitespace(), don\'t want to propagate to exprs\r\n        self.mayReturnEmpty = True\r\n        self.errmsg = ""Found unwanted token, ""+_ustr(self.expr)\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        try:\r\n            self.expr.tryParse( instring, loc )\r\n        except (ParseException,IndexError):\r\n            pass\r\n        else:\r\n            raise ParseException(instring, loc, self.errmsg, self)\r\n        return loc, []\r\n\r\n    def __str__( self ):\r\n        if hasattr(self,""name""):\r\n            return self.name\r\n\r\n        if self.strRepr is None:\r\n            self.strRepr = ""~{"" + _ustr(self.expr) + ""}""\r\n\r\n        return self.strRepr\r\n\r\n\r\nclass ZeroOrMore(ParseElementEnhance):\r\n    """"""Optional repetition of zero or more of the given expression.""""""\r\n    def __init__( self, expr ):\r\n        super(ZeroOrMore,self).__init__(expr)\r\n        self.mayReturnEmpty = True\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        tokens = []\r\n        try:\r\n            loc, tokens = self.expr._parse( instring, loc, doActions, callPreParse=False )\r\n            hasIgnoreExprs = ( len(self.ignoreExprs) > 0 )\r\n            while 1:\r\n                if hasIgnoreExprs:\r\n                    preloc = self._skipIgnorables( instring, loc )\r\n                else:\r\n                    preloc = loc\r\n                loc, tmptokens = self.expr._parse( instring, preloc, doActions )\r\n                if tmptokens or tmptokens.haskeys():\r\n                    tokens += tmptokens\r\n        except (ParseException,IndexError):\r\n            pass\r\n\r\n        return loc, tokens\r\n\r\n    def __str__( self ):\r\n        if hasattr(self,""name""):\r\n            return self.name\r\n\r\n        if self.strRepr is None:\r\n            self.strRepr = ""["" + _ustr(self.expr) + ""]...""\r\n\r\n        return self.strRepr\r\n\r\n    def setResultsName( self, name, listAllMatches=False ):\r\n        ret = super(ZeroOrMore,self).setResultsName(name,listAllMatches)\r\n        ret.saveAsList = True\r\n        return ret\r\n\r\n\r\nclass OneOrMore(ParseElementEnhance):\r\n    """"""Repetition of one or more of the given expression.""""""\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        # must be at least one\r\n        loc, tokens = self.expr._parse( instring, loc, doActions, callPreParse=False )\r\n        try:\r\n            hasIgnoreExprs = ( len(self.ignoreExprs) > 0 )\r\n            while 1:\r\n                if hasIgnoreExprs:\r\n                    preloc = self._skipIgnorables( instring, loc )\r\n                else:\r\n                    preloc = loc\r\n                loc, tmptokens = self.expr._parse( instring, preloc, doActions )\r\n                if tmptokens or tmptokens.haskeys():\r\n                    tokens += tmptokens\r\n        except (ParseException,IndexError):\r\n            pass\r\n\r\n        return loc, tokens\r\n\r\n    def __str__( self ):\r\n        if hasattr(self,""name""):\r\n            return self.name\r\n\r\n        if self.strRepr is None:\r\n            self.strRepr = ""{"" + _ustr(self.expr) + ""}...""\r\n\r\n        return self.strRepr\r\n\r\n    def setResultsName( self, name, listAllMatches=False ):\r\n        ret = super(OneOrMore,self).setResultsName(name,listAllMatches)\r\n        ret.saveAsList = True\r\n        return ret\r\n\r\nclass _NullToken(object):\r\n    def __bool__(self):\r\n        return False\r\n    __nonzero__ = __bool__\r\n    def __str__(self):\r\n        return """"\r\n\r\n_optionalNotMatched = _NullToken()\r\nclass Optional(ParseElementEnhance):\r\n    """"""Optional matching of the given expression.\r\n       A default return string can also be specified, if the optional expression\r\n       is not found.\r\n    """"""\r\n    def __init__( self, expr, default=_optionalNotMatched ):\r\n        super(Optional,self).__init__( expr, savelist=False )\r\n        self.defaultValue = default\r\n        self.mayReturnEmpty = True\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        try:\r\n            loc, tokens = self.expr._parse( instring, loc, doActions, callPreParse=False )\r\n        except (ParseException,IndexError):\r\n            if self.defaultValue is not _optionalNotMatched:\r\n                if self.expr.resultsName:\r\n                    tokens = ParseResults([ self.defaultValue ])\r\n                    tokens[self.expr.resultsName] = self.defaultValue\r\n                else:\r\n                    tokens = [ self.defaultValue ]\r\n            else:\r\n                tokens = []\r\n        return loc, tokens\r\n\r\n    def __str__( self ):\r\n        if hasattr(self,""name""):\r\n            return self.name\r\n\r\n        if self.strRepr is None:\r\n            self.strRepr = ""["" + _ustr(self.expr) + ""]""\r\n\r\n        return self.strRepr\r\n\r\n\r\nclass SkipTo(ParseElementEnhance):\r\n    """"""Token for skipping over all undefined text until the matched expression is found.\r\n       If C{include} is set to true, the matched expression is also parsed (the skipped text\r\n       and matched expression are returned as a 2-element list).  The C{ignore}\r\n       argument is used to define grammars (typically quoted strings and comments) that\r\n       might contain false matches.\r\n    """"""\r\n    def __init__( self, other, include=False, ignore=None, failOn=None ):\r\n        super( SkipTo, self ).__init__( other )\r\n        self.ignoreExpr = ignore\r\n        self.mayReturnEmpty = True\r\n        self.mayIndexError = False\r\n        self.includeMatch = include\r\n        self.asList = False\r\n        if failOn is not None and isinstance(failOn, basestring):\r\n            self.failOn = Literal(failOn)\r\n        else:\r\n            self.failOn = failOn\r\n        self.errmsg = ""No match found for ""+_ustr(self.expr)\r\n\r\n    def parseImpl( self, instring, loc, doActions=True ):\r\n        startLoc = loc\r\n        instrlen = len(instring)\r\n        expr = self.expr\r\n        failParse = False\r\n        while loc <= instrlen:\r\n            try:\r\n                if self.failOn:\r\n                    try:\r\n                        self.failOn.tryParse(instring, loc)\r\n                    except ParseBaseException:\r\n                        pass\r\n                    else:\r\n                        failParse = True\r\n                        raise ParseException(instring, loc, ""Found expression "" + str(self.failOn))\r\n                    failParse = False\r\n                if self.ignoreExpr is not None:\r\n                    while 1:\r\n                        try:\r\n                            loc = self.ignoreExpr.tryParse(instring,loc)\r\n                            # print(""found ignoreExpr, advance to"", loc)\r\n                        except ParseBaseException:\r\n                            break\r\n                expr._parse( instring, loc, doActions=False, callPreParse=False )\r\n                skipText = instring[startLoc:loc]\r\n                if self.includeMatch:\r\n                    loc,mat = expr._parse(instring,loc,doActions,callPreParse=False)\r\n                    if mat:\r\n                        skipRes = ParseResults( skipText )\r\n                        skipRes += mat\r\n                        return loc, [ skipRes ]\r\n                    else:\r\n                        return loc, [ skipText ]\r\n                else:\r\n                    return loc, [ skipText ]\r\n            except (ParseException,IndexError):\r\n                if failParse:\r\n                    raise\r\n                else:\r\n                    loc += 1\r\n        raise ParseException(instring, loc, self.errmsg, self)\r\n\r\nclass Forward(ParseElementEnhance):\r\n    """"""Forward declaration of an expression to be defined later -\r\n       used for recursive grammars, such as algebraic infix notation.\r\n       When the expression is known, it is assigned to the C{Forward} variable using the \'<<\' operator.\r\n\r\n       Note: take care when assigning to C{Forward} not to overlook precedence of operators.\r\n       Specifically, \'|\' has a lower precedence than \'<<\', so that::\r\n          fwdExpr << a | b | c\r\n       will actually be evaluated as::\r\n          (fwdExpr << a) | b | c\r\n       thereby leaving b and c out as parseable alternatives.  It is recommended that you\r\n       explicitly group the values inserted into the C{Forward}::\r\n          fwdExpr << (a | b | c)\r\n       Converting to use the \'<<=\' operator instead will avoid this problem.\r\n    """"""\r\n    def __init__( self, other=None ):\r\n        super(Forward,self).__init__( other, savelist=False )\r\n\r\n    def __lshift__( self, other ):\r\n        if isinstance( other, basestring ):\r\n            other = ParserElement.literalStringClass(other)\r\n        self.expr = other\r\n        self.mayReturnEmpty = other.mayReturnEmpty\r\n        self.strRepr = None\r\n        self.mayIndexError = self.expr.mayIndexError\r\n        self.mayReturnEmpty = self.expr.mayReturnEmpty\r\n        self.setWhitespaceChars( self.expr.whiteChars )\r\n        self.skipWhitespace = self.expr.skipWhitespace\r\n        self.saveAsList = self.expr.saveAsList\r\n        self.ignoreExprs.extend(self.expr.ignoreExprs)\r\n        return self\r\n        \r\n    def __ilshift__(self, other):\r\n        return self << other\r\n    \r\n    def leaveWhitespace( self ):\r\n        self.skipWhitespace = False\r\n        return self\r\n\r\n    def streamline( self ):\r\n        if not self.streamlined:\r\n            self.streamlined = True\r\n            if self.expr is not None:\r\n                self.expr.streamline()\r\n        return self\r\n\r\n    def validate( self, validateTrace=[] ):\r\n        if self not in validateTrace:\r\n            tmp = validateTrace[:]+[self]\r\n            if self.expr is not None:\r\n                self.expr.validate(tmp)\r\n        self.checkRecursion([])\r\n\r\n    def __str__( self ):\r\n        if hasattr(self,""name""):\r\n            return self.name\r\n\r\n        self._revertClass = self.__class__\r\n        self.__class__ = _ForwardNoRecurse\r\n        try:\r\n            if self.expr is not None:\r\n                retString = _ustr(self.expr)\r\n            else:\r\n                retString = ""None""\r\n        finally:\r\n            self.__class__ = self._revertClass\r\n        return self.__class__.__name__ + "": "" + retString\r\n\r\n    def copy(self):\r\n        if self.expr is not None:\r\n            return super(Forward,self).copy()\r\n        else:\r\n            ret = Forward()\r\n            ret <<= self\r\n            return ret\r\n\r\nclass _ForwardNoRecurse(Forward):\r\n    def __str__( self ):\r\n        return ""...""\r\n\r\nclass TokenConverter(ParseElementEnhance):\r\n    """"""Abstract subclass of C{ParseExpression}, for converting parsed results.""""""\r\n    def __init__( self, expr, savelist=False ):\r\n        super(TokenConverter,self).__init__( expr )#, savelist )\r\n        self.saveAsList = False\r\n\r\nclass Upcase(TokenConverter):\r\n    """"""Converter to upper case all matching tokens.""""""\r\n    def __init__(self, *args):\r\n        super(Upcase,self).__init__(*args)\r\n        warnings.warn(""Upcase class is deprecated, use upcaseTokens parse action instead"",\r\n                       DeprecationWarning,stacklevel=2)\r\n\r\n    def postParse( self, instring, loc, tokenlist ):\r\n        return list(map( str.upper, tokenlist ))\r\n\r\n\r\nclass Combine(TokenConverter):\r\n    """"""Converter to concatenate all matching tokens to a single string.\r\n       By default, the matching patterns must also be contiguous in the input string;\r\n       this can be disabled by specifying C{\'adjacent=False\'} in the constructor.\r\n    """"""\r\n    def __init__( self, expr, joinString="""", adjacent=True ):\r\n        super(Combine,self).__init__( expr )\r\n        # suppress whitespace-stripping in contained parse expressions, but re-enable it on the Combine itself\r\n        if adjacent:\r\n            self.leaveWhitespace()\r\n        self.adjacent = adjacent\r\n        self.skipWhitespace = True\r\n        self.joinString = joinString\r\n        self.callPreparse = True\r\n\r\n    def ignore( self, other ):\r\n        if self.adjacent:\r\n            ParserElement.ignore(self, other)\r\n        else:\r\n            super( Combine, self).ignore( other )\r\n        return self\r\n\r\n    def postParse( self, instring, loc, tokenlist ):\r\n        retToks = tokenlist.copy()\r\n        del retToks[:]\r\n        retToks += ParseResults([ """".join(tokenlist._asStringList(self.joinString)) ], modal=self.modalResults)\r\n\r\n        if self.resultsName and retToks.haskeys():\r\n            return [ retToks ]\r\n        else:\r\n            return retToks\r\n\r\nclass Group(TokenConverter):\r\n    """"""Converter to return the matched tokens as a list - useful for returning tokens of C{L{ZeroOrMore}} and C{L{OneOrMore}} expressions.""""""\r\n    def __init__( self, expr ):\r\n        super(Group,self).__init__( expr )\r\n        self.saveAsList = True\r\n\r\n    def postParse( self, instring, loc, tokenlist ):\r\n        return [ tokenlist ]\r\n\r\nclass Dict(TokenConverter):\r\n    """"""Converter to return a repetitive expression as a list, but also as a dictionary.\r\n       Each element can also be referenced using the first token in the expression as its key.\r\n       Useful for tabular report scraping when the first column can be used as a item key.\r\n    """"""\r\n    def __init__( self, expr ):\r\n        super(Dict,self).__init__( expr )\r\n        self.saveAsList = True\r\n\r\n    def postParse( self, instring, loc, tokenlist ):\r\n        for i,tok in enumerate(tokenlist):\r\n            if len(tok) == 0:\r\n                continue\r\n            ikey = tok[0]\r\n            if isinstance(ikey,int):\r\n                ikey = _ustr(tok[0]).strip()\r\n            if len(tok)==1:\r\n                tokenlist[ikey] = _ParseResultsWithOffset("""",i)\r\n            elif len(tok)==2 and not isinstance(tok[1],ParseResults):\r\n                tokenlist[ikey] = _ParseResultsWithOffset(tok[1],i)\r\n            else:\r\n                dictvalue = tok.copy() #ParseResults(i)\r\n                del dictvalue[0]\r\n                if len(dictvalue)!= 1 or (isinstance(dictvalue,ParseResults) and dictvalue.haskeys()):\r\n                    tokenlist[ikey] = _ParseResultsWithOffset(dictvalue,i)\r\n                else:\r\n                    tokenlist[ikey] = _ParseResultsWithOffset(dictvalue[0],i)\r\n\r\n        if self.resultsName:\r\n            return [ tokenlist ]\r\n        else:\r\n            return tokenlist\r\n\r\n\r\nclass Suppress(TokenConverter):\r\n    """"""Converter for ignoring the results of a parsed expression.""""""\r\n    def postParse( self, instring, loc, tokenlist ):\r\n        return []\r\n\r\n    def suppress( self ):\r\n        return self\r\n\r\n\r\nclass OnlyOnce(object):\r\n    """"""Wrapper for parse actions, to ensure they are only called once.""""""\r\n    def __init__(self, methodCall):\r\n        self.callable = _trim_arity(methodCall)\r\n        self.called = False\r\n    def __call__(self,s,l,t):\r\n        if not self.called:\r\n            results = self.callable(s,l,t)\r\n            self.called = True\r\n            return results\r\n        raise ParseException(s,l,"""")\r\n    def reset(self):\r\n        self.called = False\r\n\r\ndef traceParseAction(f):\r\n    """"""Decorator for debugging parse actions.""""""\r\n    f = _trim_arity(f)\r\n    def z(*paArgs):\r\n        thisFunc = f.func_name\r\n        s,l,t = paArgs[-3:]\r\n        if len(paArgs)>3:\r\n            thisFunc = paArgs[0].__class__.__name__ + \'.\' + thisFunc\r\n        sys.stderr.write( "">>entering %s(line: \'%s\', %d, %s)\\n"" % (thisFunc,line(l,s),l,t) )\r\n        try:\r\n            ret = f(*paArgs)\r\n        except Exception as exc:\r\n            sys.stderr.write( ""<<leaving %s (exception: %s)\\n"" % (thisFunc,exc) )\r\n            raise\r\n        sys.stderr.write( ""<<leaving %s (ret: %s)\\n"" % (thisFunc,ret) )\r\n        return ret\r\n    try:\r\n        z.__name__ = f.__name__\r\n    except AttributeError:\r\n        pass\r\n    return z\r\n\r\n#\r\n# global helpers\r\n#\r\ndef delimitedList( expr, delim="","", combine=False ):\r\n    """"""Helper to define a delimited list of expressions - the delimiter defaults to \',\'.\r\n       By default, the list elements and delimiters can have intervening whitespace, and\r\n       comments, but this can be overridden by passing C{combine=True} in the constructor.\r\n       If C{combine} is set to C{True}, the matching tokens are returned as a single token\r\n       string, with the delimiters included; otherwise, the matching tokens are returned\r\n       as a list of tokens, with the delimiters suppressed.\r\n    """"""\r\n    dlName = _ustr(expr)+"" [""+_ustr(delim)+"" ""+_ustr(expr)+""]...""\r\n    if combine:\r\n        return Combine( expr + ZeroOrMore( delim + expr ) ).setName(dlName)\r\n    else:\r\n        return ( expr + ZeroOrMore( Suppress( delim ) + expr ) ).setName(dlName)\r\n\r\ndef countedArray( expr, intExpr=None ):\r\n    """"""Helper to define a counted list of expressions.\r\n       This helper defines a pattern of the form::\r\n           integer expr expr expr...\r\n       where the leading integer tells how many expr expressions follow.\r\n       The matched tokens returns the array of expr tokens as a list - the leading count token is suppressed.\r\n    """"""\r\n    arrayExpr = Forward()\r\n    def countFieldParseAction(s,l,t):\r\n        n = t[0]\r\n        arrayExpr << (n and Group(And([expr]*n)) or Group(empty))\r\n        return []\r\n    if intExpr is None:\r\n        intExpr = Word(nums).setParseAction(lambda t:int(t[0]))\r\n    else:\r\n        intExpr = intExpr.copy()\r\n    intExpr.setName(""arrayLen"")\r\n    intExpr.addParseAction(countFieldParseAction, callDuringTry=True)\r\n    return ( intExpr + arrayExpr )\r\n\r\ndef _flatten(L):\r\n    ret = []\r\n    for i in L:\r\n        if isinstance(i,list):\r\n            ret.extend(_flatten(i))\r\n        else:\r\n            ret.append(i)\r\n    return ret\r\n\r\ndef matchPreviousLiteral(expr):\r\n    """"""Helper to define an expression that is indirectly defined from\r\n       the tokens matched in a previous expression, that is, it looks\r\n       for a \'repeat\' of a previous expression.  For example::\r\n           first = Word(nums)\r\n           second = matchPreviousLiteral(first)\r\n           matchExpr = first + "":"" + second\r\n       will match C{""1:1""}, but not C{""1:2""}.  Because this matches a\r\n       previous literal, will also match the leading C{""1:1""} in C{""1:10""}.\r\n       If this is not desired, use C{matchPreviousExpr}.\r\n       Do *not* use with packrat parsing enabled.\r\n    """"""\r\n    rep = Forward()\r\n    def copyTokenToRepeater(s,l,t):\r\n        if t:\r\n            if len(t) == 1:\r\n                rep << t[0]\r\n            else:\r\n                # flatten t tokens\r\n                tflat = _flatten(t.asList())\r\n                rep << And( [ Literal(tt) for tt in tflat ] )\r\n        else:\r\n            rep << Empty()\r\n    expr.addParseAction(copyTokenToRepeater, callDuringTry=True)\r\n    return rep\r\n\r\ndef matchPreviousExpr(expr):\r\n    """"""Helper to define an expression that is indirectly defined from\r\n       the tokens matched in a previous expression, that is, it looks\r\n       for a \'repeat\' of a previous expression.  For example::\r\n           first = Word(nums)\r\n           second = matchPreviousExpr(first)\r\n           matchExpr = first + "":"" + second\r\n       will match C{""1:1""}, but not C{""1:2""}.  Because this matches by\r\n       expressions, will *not* match the leading C{""1:1""} in C{""1:10""};\r\n       the expressions are evaluated first, and then compared, so\r\n       C{""1""} is compared with C{""10""}.\r\n       Do *not* use with packrat parsing enabled.\r\n    """"""\r\n    rep = Forward()\r\n    e2 = expr.copy()\r\n    rep <<= e2\r\n    def copyTokenToRepeater(s,l,t):\r\n        matchTokens = _flatten(t.asList())\r\n        def mustMatchTheseTokens(s,l,t):\r\n            theseTokens = _flatten(t.asList())\r\n            if  theseTokens != matchTokens:\r\n                raise ParseException("""",0,"""")\r\n        rep.setParseAction( mustMatchTheseTokens, callDuringTry=True )\r\n    expr.addParseAction(copyTokenToRepeater, callDuringTry=True)\r\n    return rep\r\n\r\ndef _escapeRegexRangeChars(s):\r\n    #~  escape these chars: ^-]\r\n    for c in r""\\^-]"":\r\n        s = s.replace(c,_bslash+c)\r\n    s = s.replace(""\\n"",r""\\n"")\r\n    s = s.replace(""\\t"",r""\\t"")\r\n    return _ustr(s)\r\n\r\ndef oneOf( strs, caseless=False, useRegex=True ):\r\n    """"""Helper to quickly define a set of alternative Literals, and makes sure to do\r\n       longest-first testing when there is a conflict, regardless of the input order,\r\n       but returns a C{L{MatchFirst}} for best performance.\r\n\r\n       Parameters:\r\n        - strs - a string of space-delimited literals, or a list of string literals\r\n        - caseless - (default=False) - treat all literals as caseless\r\n        - useRegex - (default=True) - as an optimization, will generate a Regex\r\n          object; otherwise, will generate a C{MatchFirst} object (if C{caseless=True}, or\r\n          if creating a C{Regex} raises an exception)\r\n    """"""\r\n    if caseless:\r\n        isequal = ( lambda a,b: a.upper() == b.upper() )\r\n        masks = ( lambda a,b: b.upper().startswith(a.upper()) )\r\n        parseElementClass = CaselessLiteral\r\n    else:\r\n        isequal = ( lambda a,b: a == b )\r\n        masks = ( lambda a,b: b.startswith(a) )\r\n        parseElementClass = Literal\r\n\r\n    symbols = []\r\n    if isinstance(strs,basestring):\r\n        symbols = strs.split()\r\n    elif isinstance(strs, collections.Sequence):\r\n        symbols = list(strs[:])\r\n    elif isinstance(strs, _generatorType):\r\n        symbols = list(strs)\r\n    else:\r\n        warnings.warn(""Invalid argument to oneOf, expected string or list"",\r\n                SyntaxWarning, stacklevel=2)\r\n    if not symbols:\r\n        return NoMatch()\r\n\r\n    i = 0\r\n    while i < len(symbols)-1:\r\n        cur = symbols[i]\r\n        for j,other in enumerate(symbols[i+1:]):\r\n            if ( isequal(other, cur) ):\r\n                del symbols[i+j+1]\r\n                break\r\n            elif ( masks(cur, other) ):\r\n                del symbols[i+j+1]\r\n                symbols.insert(i,other)\r\n                cur = other\r\n                break\r\n        else:\r\n            i += 1\r\n\r\n    if not caseless and useRegex:\r\n        #~ print (strs,""->"", ""|"".join( [ _escapeRegexChars(sym) for sym in symbols] ))\r\n        try:\r\n            if len(symbols)==len("""".join(symbols)):\r\n                return Regex( ""[%s]"" % """".join(_escapeRegexRangeChars(sym) for sym in symbols) )\r\n            else:\r\n                return Regex( ""|"".join(re.escape(sym) for sym in symbols) )\r\n        except:\r\n            warnings.warn(""Exception creating Regex for oneOf, building MatchFirst"",\r\n                    SyntaxWarning, stacklevel=2)\r\n\r\n\r\n    # last resort, just use MatchFirst\r\n    return MatchFirst( [ parseElementClass(sym) for sym in symbols ] )\r\n\r\ndef dictOf( key, value ):\r\n    """"""Helper to easily and clearly define a dictionary by specifying the respective patterns\r\n       for the key and value.  Takes care of defining the C{L{Dict}}, C{L{ZeroOrMore}}, and C{L{Group}} tokens\r\n       in the proper order.  The key pattern can include delimiting markers or punctuation,\r\n       as long as they are suppressed, thereby leaving the significant key text.  The value\r\n       pattern can include named results, so that the C{Dict} results can include named token\r\n       fields.\r\n    """"""\r\n    return Dict( ZeroOrMore( Group ( key + value ) ) )\r\n\r\ndef originalTextFor(expr, asString=True):\r\n    """"""Helper to return the original, untokenized text for a given expression.  Useful to\r\n       restore the parsed fields of an HTML start tag into the raw tag text itself, or to\r\n       revert separate tokens with intervening whitespace back to the original matching\r\n       input text. Simpler to use than the parse action C{L{keepOriginalText}}, and does not\r\n       require the inspect module to chase up the call stack.  By default, returns a \r\n       string containing the original parsed text.  \r\n       \r\n       If the optional C{asString} argument is passed as C{False}, then the return value is a \r\n       C{L{ParseResults}} containing any results names that were originally matched, and a \r\n       single token containing the original matched text from the input string.  So if \r\n       the expression passed to C{L{originalTextFor}} contains expressions with defined\r\n       results names, you must set C{asString} to C{False} if you want to preserve those\r\n       results name values.""""""\r\n    locMarker = Empty().setParseAction(lambda s,loc,t: loc)\r\n    endlocMarker = locMarker.copy()\r\n    endlocMarker.callPreparse = False\r\n    matchExpr = locMarker(""_original_start"") + expr + endlocMarker(""_original_end"")\r\n    if asString:\r\n        extractText = lambda s,l,t: s[t._original_start:t._original_end]\r\n    else:\r\n        def extractText(s,l,t):\r\n            del t[:]\r\n            t.insert(0, s[t._original_start:t._original_end])\r\n            del t[""_original_start""]\r\n            del t[""_original_end""]\r\n    matchExpr.setParseAction(extractText)\r\n    return matchExpr\r\n\r\ndef ungroup(expr): \r\n    """"""Helper to undo pyparsing\'s default grouping of And expressions, even\r\n       if all but one are non-empty.""""""\r\n    return TokenConverter(expr).setParseAction(lambda t:t[0])\r\n\r\ndef locatedExpr(expr):\r\n    """"""Helper to decorate a returned token with its starting and ending locations in the input string.\r\n       This helper adds the following results names:\r\n        - locn_start = location where matched expression begins\r\n        - locn_end = location where matched expression ends\r\n        - value = the actual parsed results\r\n\r\n       Be careful if the input text contains C{<TAB>} characters, you may want to call\r\n       C{L{ParserElement.parseWithTabs}}\r\n    """"""\r\n    locator = Empty().setParseAction(lambda s,l,t: l)\r\n    return Group(locator(""locn_start"") + expr(""value"") + locator.copy().leaveWhitespace()(""locn_end""))\r\n\r\n\r\n# convenience constants for positional expressions\r\nempty       = Empty().setName(""empty"")\r\nlineStart   = LineStart().setName(""lineStart"")\r\nlineEnd     = LineEnd().setName(""lineEnd"")\r\nstringStart = StringStart().setName(""stringStart"")\r\nstringEnd   = StringEnd().setName(""stringEnd"")\r\n\r\n_escapedPunc = Word( _bslash, r""\\[]-*.$+^?()~ "", exact=2 ).setParseAction(lambda s,l,t:t[0][1])\r\n_escapedHexChar = Regex(r""\\\\0?[xX][0-9a-fA-F]+"").setParseAction(lambda s,l,t:unichr(int(t[0].lstrip(r\'\\0x\'),16)))\r\n_escapedOctChar = Regex(r""\\\\0[0-7]+"").setParseAction(lambda s,l,t:unichr(int(t[0][1:],8)))\r\n_singleChar = _escapedPunc | _escapedHexChar | _escapedOctChar | Word(printables, excludeChars=r\'\\]\', exact=1)\r\n_charRange = Group(_singleChar + Suppress(""-"") + _singleChar)\r\n_reBracketExpr = Literal(""["") + Optional(""^"").setResultsName(""negate"") + Group( OneOrMore( _charRange | _singleChar ) ).setResultsName(""body"") + ""]""\r\n\r\ndef srange(s):\r\n    r""""""Helper to easily define string ranges for use in Word construction.  Borrows\r\n       syntax from regexp \'[]\' string range definitions::\r\n          srange(""[0-9]"")   -> ""0123456789""\r\n          srange(""[a-z]"")   -> ""abcdefghijklmnopqrstuvwxyz""\r\n          srange(""[a-z$_]"") -> ""abcdefghijklmnopqrstuvwxyz$_""\r\n       The input string must be enclosed in []\'s, and the returned string is the expanded\r\n       character set joined into a single string.\r\n       The values enclosed in the []\'s may be::\r\n          a single character\r\n          an escaped character with a leading backslash (such as \\- or \\])\r\n          an escaped hex character with a leading \'\\x\' (\\x21, which is a \'!\' character) \r\n            (\\0x## is also supported for backwards compatibility) \r\n          an escaped octal character with a leading \'\\0\' (\\041, which is a \'!\' character)\r\n          a range of any of the above, separated by a dash (\'a-z\', etc.)\r\n          any combination of the above (\'aeiouy\', \'a-zA-Z0-9_$\', etc.)\r\n    """"""\r\n    _expanded = lambda p: p if not isinstance(p,ParseResults) else \'\'.join(unichr(c) for c in range(ord(p[0]),ord(p[1])+1))\r\n    try:\r\n        return """".join(_expanded(part) for part in _reBracketExpr.parseString(s).body)\r\n    except:\r\n        return """"\r\n\r\ndef matchOnlyAtCol(n):\r\n    """"""Helper method for defining parse actions that require matching at a specific\r\n       column in the input text.\r\n    """"""\r\n    def verifyCol(strg,locn,toks):\r\n        if col(locn,strg) != n:\r\n            raise ParseException(strg,locn,""matched token not at column %d"" % n)\r\n    return verifyCol\r\n\r\ndef replaceWith(replStr):\r\n    """"""Helper method for common parse actions that simply return a literal value.  Especially\r\n       useful when used with C{L{transformString<ParserElement.transformString>}()}.\r\n    """"""\r\n    def _replFunc(*args):\r\n        return [replStr]\r\n    return _replFunc\r\n\r\ndef removeQuotes(s,l,t):\r\n    """"""Helper parse action for removing quotation marks from parsed quoted strings.\r\n       To use, add this parse action to quoted string using::\r\n         quotedString.setParseAction( removeQuotes )\r\n    """"""\r\n    return t[0][1:-1]\r\n\r\ndef upcaseTokens(s,l,t):\r\n    """"""Helper parse action to convert tokens to upper case.""""""\r\n    return [ tt.upper() for tt in map(_ustr,t) ]\r\n\r\ndef downcaseTokens(s,l,t):\r\n    """"""Helper parse action to convert tokens to lower case.""""""\r\n    return [ tt.lower() for tt in map(_ustr,t) ]\r\n\r\ndef keepOriginalText(s,startLoc,t):\r\n    """"""DEPRECATED - use new helper method C{L{originalTextFor}}.\r\n       Helper parse action to preserve original parsed text,\r\n       overriding any nested parse actions.""""""\r\n    try:\r\n        endloc = getTokensEndLoc()\r\n    except ParseException:\r\n        raise ParseFatalException(""incorrect usage of keepOriginalText - may only be called as a parse action"")\r\n    del t[:]\r\n    t += ParseResults(s[startLoc:endloc])\r\n    return t\r\n\r\ndef getTokensEndLoc():\r\n    """"""Method to be called from within a parse action to determine the end\r\n       location of the parsed tokens.""""""\r\n    import inspect\r\n    fstack = inspect.stack()\r\n    try:\r\n        # search up the stack (through intervening argument normalizers) for correct calling routine\r\n        for f in fstack[2:]:\r\n            if f[3] == ""_parseNoCache"":\r\n                endloc = f[0].f_locals[""loc""]\r\n                return endloc\r\n        else:\r\n            raise ParseFatalException(""incorrect usage of getTokensEndLoc - may only be called from within a parse action"")\r\n    finally:\r\n        del fstack\r\n\r\ndef _makeTags(tagStr, xml):\r\n    """"""Internal helper to construct opening and closing tag expressions, given a tag name""""""\r\n    if isinstance(tagStr,basestring):\r\n        resname = tagStr\r\n        tagStr = Keyword(tagStr, caseless=not xml)\r\n    else:\r\n        resname = tagStr.name\r\n\r\n    tagAttrName = Word(alphas,alphanums+""_-:"")\r\n    if (xml):\r\n        tagAttrValue = dblQuotedString.copy().setParseAction( removeQuotes )\r\n        openTag = Suppress(""<"") + tagStr(""tag"") + \\\r\n                Dict(ZeroOrMore(Group( tagAttrName + Suppress(""="") + tagAttrValue ))) + \\\r\n                Optional(""/"",default=[False]).setResultsName(""empty"").setParseAction(lambda s,l,t:t[0]==\'/\') + Suppress("">"")\r\n    else:\r\n        printablesLessRAbrack = """".join(c for c in printables if c not in "">"")\r\n        tagAttrValue = quotedString.copy().setParseAction( removeQuotes ) | Word(printablesLessRAbrack)\r\n        openTag = Suppress(""<"") + tagStr(""tag"") + \\\r\n                Dict(ZeroOrMore(Group( tagAttrName.setParseAction(downcaseTokens) + \\\r\n                Optional( Suppress(""="") + tagAttrValue ) ))) + \\\r\n                Optional(""/"",default=[False]).setResultsName(""empty"").setParseAction(lambda s,l,t:t[0]==\'/\') + Suppress("">"")\r\n    closeTag = Combine(_L(""</"") + tagStr + "">"")\r\n\r\n    openTag = openTag.setResultsName(""start""+"""".join(resname.replace("":"","" "").title().split())).setName(""<%s>"" % tagStr)\r\n    closeTag = closeTag.setResultsName(""end""+"""".join(resname.replace("":"","" "").title().split())).setName(""</%s>"" % tagStr)\r\n    openTag.tag = resname\r\n    closeTag.tag = resname\r\n    return openTag, closeTag\r\n\r\ndef makeHTMLTags(tagStr):\r\n    """"""Helper to construct opening and closing tag expressions for HTML, given a tag name""""""\r\n    return _makeTags( tagStr, False )\r\n\r\ndef makeXMLTags(tagStr):\r\n    """"""Helper to construct opening and closing tag expressions for XML, given a tag name""""""\r\n    return _makeTags( tagStr, True )\r\n\r\ndef withAttribute(*args,**attrDict):\r\n    """"""Helper to create a validating parse action to be used with start tags created\r\n       with C{L{makeXMLTags}} or C{L{makeHTMLTags}}. Use C{withAttribute} to qualify a starting tag\r\n       with a required attribute value, to avoid false matches on common tags such as\r\n       C{<TD>} or C{<DIV>}.\r\n\r\n       Call C{withAttribute} with a series of attribute names and values. Specify the list\r\n       of filter attributes names and values as:\r\n        - keyword arguments, as in C{(align=""right"")}, or\r\n        - as an explicit dict with C{**} operator, when an attribute name is also a Python\r\n          reserved word, as in C{**{""class"":""Customer"", ""align"":""right""}}\r\n        - a list of name-value tuples, as in ( (""ns1:class"", ""Customer""), (""ns2:align"",""right"") )\r\n       For attribute names with a namespace prefix, you must use the second form.  Attribute\r\n       names are matched insensitive to upper/lower case.\r\n\r\n       To verify that the attribute exists, but without specifying a value, pass\r\n       C{withAttribute.ANY_VALUE} as the value.\r\n       """"""\r\n    if args:\r\n        attrs = args[:]\r\n    else:\r\n        attrs = attrDict.items()\r\n    attrs = [(k,v) for k,v in attrs]\r\n    def pa(s,l,tokens):\r\n        for attrName,attrValue in attrs:\r\n            if attrName not in tokens:\r\n                raise ParseException(s,l,""no matching attribute "" + attrName)\r\n            if attrValue != withAttribute.ANY_VALUE and tokens[attrName] != attrValue:\r\n                raise ParseException(s,l,""attribute \'%s\' has value \'%s\', must be \'%s\'"" %\r\n                                            (attrName, tokens[attrName], attrValue))\r\n    return pa\r\nwithAttribute.ANY_VALUE = object()\r\n\r\nopAssoc = _Constants()\r\nopAssoc.LEFT = object()\r\nopAssoc.RIGHT = object()\r\n\r\ndef infixNotation( baseExpr, opList, lpar=Suppress(\'(\'), rpar=Suppress(\')\') ):\r\n    """"""Helper method for constructing grammars of expressions made up of\r\n       operators working in a precedence hierarchy.  Operators may be unary or\r\n       binary, left- or right-associative.  Parse actions can also be attached\r\n       to operator expressions.\r\n\r\n       Parameters:\r\n        - baseExpr - expression representing the most basic element for the nested\r\n        - opList - list of tuples, one for each operator precedence level in the\r\n          expression grammar; each tuple is of the form\r\n          (opExpr, numTerms, rightLeftAssoc, parseAction), where:\r\n           - opExpr is the pyparsing expression for the operator;\r\n              may also be a string, which will be converted to a Literal;\r\n              if numTerms is 3, opExpr is a tuple of two expressions, for the\r\n              two operators separating the 3 terms\r\n           - numTerms is the number of terms for this operator (must\r\n              be 1, 2, or 3)\r\n           - rightLeftAssoc is the indicator whether the operator is\r\n              right or left associative, using the pyparsing-defined\r\n              constants C{opAssoc.RIGHT} and C{opAssoc.LEFT}.\r\n           - parseAction is the parse action to be associated with\r\n              expressions matching this operator expression (the\r\n              parse action tuple member may be omitted)\r\n        - lpar - expression for matching left-parentheses (default=Suppress(\'(\'))\r\n        - rpar - expression for matching right-parentheses (default=Suppress(\')\'))\r\n    """"""\r\n    ret = Forward()\r\n    lastExpr = baseExpr | ( lpar + ret + rpar )\r\n    for i,operDef in enumerate(opList):\r\n        opExpr,arity,rightLeftAssoc,pa = (operDef + (None,))[:4]\r\n        if arity == 3:\r\n            if opExpr is None or len(opExpr) != 2:\r\n                raise ValueError(""if numterms=3, opExpr must be a tuple or list of two expressions"")\r\n            opExpr1, opExpr2 = opExpr\r\n        thisExpr = Forward()#.setName(""expr%d"" % i)\r\n        if rightLeftAssoc == opAssoc.LEFT:\r\n            if arity == 1:\r\n                matchExpr = FollowedBy(lastExpr + opExpr) + Group( lastExpr + OneOrMore( opExpr ) )\r\n            elif arity == 2:\r\n                if opExpr is not None:\r\n                    matchExpr = FollowedBy(lastExpr + opExpr + lastExpr) + Group( lastExpr + OneOrMore( opExpr + lastExpr ) )\r\n                else:\r\n                    matchExpr = FollowedBy(lastExpr+lastExpr) + Group( lastExpr + OneOrMore(lastExpr) )\r\n            elif arity == 3:\r\n                matchExpr = FollowedBy(lastExpr + opExpr1 + lastExpr + opExpr2 + lastExpr) + \\\r\n                            Group( lastExpr + opExpr1 + lastExpr + opExpr2 + lastExpr )\r\n            else:\r\n                raise ValueError(""operator must be unary (1), binary (2), or ternary (3)"")\r\n        elif rightLeftAssoc == opAssoc.RIGHT:\r\n            if arity == 1:\r\n                # try to avoid LR with this extra test\r\n                if not isinstance(opExpr, Optional):\r\n                    opExpr = Optional(opExpr)\r\n                matchExpr = FollowedBy(opExpr.expr + thisExpr) + Group( opExpr + thisExpr )\r\n            elif arity == 2:\r\n                if opExpr is not None:\r\n                    matchExpr = FollowedBy(lastExpr + opExpr + thisExpr) + Group( lastExpr + OneOrMore( opExpr + thisExpr ) )\r\n                else:\r\n                    matchExpr = FollowedBy(lastExpr + thisExpr) + Group( lastExpr + OneOrMore( thisExpr ) )\r\n            elif arity == 3:\r\n                matchExpr = FollowedBy(lastExpr + opExpr1 + thisExpr + opExpr2 + thisExpr) + \\\r\n                            Group( lastExpr + opExpr1 + thisExpr + opExpr2 + thisExpr )\r\n            else:\r\n                raise ValueError(""operator must be unary (1), binary (2), or ternary (3)"")\r\n        else:\r\n            raise ValueError(""operator must indicate right or left associativity"")\r\n        if pa:\r\n            matchExpr.setParseAction( pa )\r\n        thisExpr <<= ( matchExpr | lastExpr )\r\n        lastExpr = thisExpr\r\n    ret <<= lastExpr\r\n    return ret\r\noperatorPrecedence = infixNotation\r\n\r\ndblQuotedString = Regex(r\'""(?:[^""\\n\\r\\\\]|(?:"""")|(?:\\\\x[0-9a-fA-F]+)|(?:\\\\.))*""\').setName(""string enclosed in double quotes"")\r\nsglQuotedString = Regex(r""\'(?:[^\'\\n\\r\\\\]|(?:\'\')|(?:\\\\x[0-9a-fA-F]+)|(?:\\\\.))*\'"").setName(""string enclosed in single quotes"")\r\nquotedString = Regex(r\'\'\'(?:""(?:[^""\\n\\r\\\\]|(?:"""")|(?:\\\\x[0-9a-fA-F]+)|(?:\\\\.))*"")|(?:\'(?:[^\'\\n\\r\\\\]|(?:\'\')|(?:\\\\x[0-9a-fA-F]+)|(?:\\\\.))*\')\'\'\').setName(""quotedString using single or double quotes"")\r\nunicodeString = Combine(_L(\'u\') + quotedString.copy())\r\n\r\ndef nestedExpr(opener=""("", closer="")"", content=None, ignoreExpr=quotedString.copy()):\r\n    """"""Helper method for defining nested lists enclosed in opening and closing\r\n       delimiters (""("" and "")"" are the default).\r\n\r\n       Parameters:\r\n        - opener - opening character for a nested list (default=""(""); can also be a pyparsing expression\r\n        - closer - closing character for a nested list (default="")""); can also be a pyparsing expression\r\n        - content - expression for items within the nested lists (default=None)\r\n        - ignoreExpr - expression for ignoring opening and closing delimiters (default=quotedString)\r\n\r\n       If an expression is not provided for the content argument, the nested\r\n       expression will capture all whitespace-delimited content between delimiters\r\n       as a list of separate values.\r\n\r\n       Use the C{ignoreExpr} argument to define expressions that may contain\r\n       opening or closing characters that should not be treated as opening\r\n       or closing characters for nesting, such as quotedString or a comment\r\n       expression.  Specify multiple expressions using an C{L{Or}} or C{L{MatchFirst}}.\r\n       The default is L{quotedString}, but if no expressions are to be ignored,\r\n       then pass C{None} for this argument.\r\n    """"""\r\n    if opener == closer:\r\n        raise ValueError(""opening and closing strings cannot be the same"")\r\n    if content is None:\r\n        if isinstance(opener,basestring) and isinstance(closer,basestring):\r\n            if len(opener) == 1 and len(closer)==1:\r\n                if ignoreExpr is not None:\r\n                    content = (Combine(OneOrMore(~ignoreExpr +\r\n                                    CharsNotIn(opener+closer+ParserElement.DEFAULT_WHITE_CHARS,exact=1))\r\n                                ).setParseAction(lambda t:t[0].strip()))\r\n                else:\r\n                    content = (empty.copy()+CharsNotIn(opener+closer+ParserElement.DEFAULT_WHITE_CHARS\r\n                                ).setParseAction(lambda t:t[0].strip()))\r\n            else:\r\n                if ignoreExpr is not None:\r\n                    content = (Combine(OneOrMore(~ignoreExpr + \r\n                                    ~Literal(opener) + ~Literal(closer) +\r\n                                    CharsNotIn(ParserElement.DEFAULT_WHITE_CHARS,exact=1))\r\n                                ).setParseAction(lambda t:t[0].strip()))\r\n                else:\r\n                    content = (Combine(OneOrMore(~Literal(opener) + ~Literal(closer) +\r\n                                    CharsNotIn(ParserElement.DEFAULT_WHITE_CHARS,exact=1))\r\n                                ).setParseAction(lambda t:t[0].strip()))\r\n        else:\r\n            raise ValueError(""opening and closing arguments must be strings if no content expression is given"")\r\n    ret = Forward()\r\n    if ignoreExpr is not None:\r\n        ret <<= Group( Suppress(opener) + ZeroOrMore( ignoreExpr | ret | content ) + Suppress(closer) )\r\n    else:\r\n        ret <<= Group( Suppress(opener) + ZeroOrMore( ret | content )  + Suppress(closer) )\r\n    return ret\r\n\r\ndef indentedBlock(blockStatementExpr, indentStack, indent=True):\r\n    """"""Helper method for defining space-delimited indentation blocks, such as\r\n       those used to define block statements in Python source code.\r\n\r\n       Parameters:\r\n        - blockStatementExpr - expression defining syntax of statement that\r\n            is repeated within the indented block\r\n        - indentStack - list created by caller to manage indentation stack\r\n            (multiple statementWithIndentedBlock expressions within a single grammar\r\n            should share a common indentStack)\r\n        - indent - boolean indicating whether block must be indented beyond the\r\n            the current level; set to False for block of left-most statements\r\n            (default=True)\r\n\r\n       A valid block must contain at least one C{blockStatement}.\r\n    """"""\r\n    def checkPeerIndent(s,l,t):\r\n        if l >= len(s): return\r\n        curCol = col(l,s)\r\n        if curCol != indentStack[-1]:\r\n            if curCol > indentStack[-1]:\r\n                raise ParseFatalException(s,l,""illegal nesting"")\r\n            raise ParseException(s,l,""not a peer entry"")\r\n\r\n    def checkSubIndent(s,l,t):\r\n        curCol = col(l,s)\r\n        if curCol > indentStack[-1]:\r\n            indentStack.append( curCol )\r\n        else:\r\n            raise ParseException(s,l,""not a subentry"")\r\n\r\n    def checkUnindent(s,l,t):\r\n        if l >= len(s): return\r\n        curCol = col(l,s)\r\n        if not(indentStack and curCol < indentStack[-1] and curCol <= indentStack[-2]):\r\n            raise ParseException(s,l,""not an unindent"")\r\n        indentStack.pop()\r\n\r\n    NL = OneOrMore(LineEnd().setWhitespaceChars(""\\t "").suppress())\r\n    INDENT = Empty() + Empty().setParseAction(checkSubIndent)\r\n    PEER   = Empty().setParseAction(checkPeerIndent)\r\n    UNDENT = Empty().setParseAction(checkUnindent)\r\n    if indent:\r\n        smExpr = Group( Optional(NL) +\r\n            #~ FollowedBy(blockStatementExpr) +\r\n            INDENT + (OneOrMore( PEER + Group(blockStatementExpr) + Optional(NL) )) + UNDENT)\r\n    else:\r\n        smExpr = Group( Optional(NL) +\r\n            (OneOrMore( PEER + Group(blockStatementExpr) + Optional(NL) )) )\r\n    blockStatementExpr.ignore(_bslash + LineEnd())\r\n    return smExpr\r\n\r\nalphas8bit = srange(r""[\\0xc0-\\0xd6\\0xd8-\\0xf6\\0xf8-\\0xff]"")\r\npunc8bit = srange(r""[\\0xa1-\\0xbf\\0xd7\\0xf7]"")\r\n\r\nanyOpenTag,anyCloseTag = makeHTMLTags(Word(alphas,alphanums+""_:""))\r\ncommonHTMLEntity = Combine(_L(""&"") + oneOf(""gt lt amp nbsp quot"").setResultsName(""entity"") +"";"").streamline()\r\n_htmlEntityMap = dict(zip(""gt lt amp nbsp quot"".split(),\'><& ""\'))\r\nreplaceHTMLEntity = lambda t : t.entity in _htmlEntityMap and _htmlEntityMap[t.entity] or None\r\n\r\n# it\'s easy to get these comment structures wrong - they\'re very common, so may as well make them available\r\ncStyleComment = Regex(r""/\\*(?:[^*]*\\*+)+?/"").setName(""C style comment"")\r\n\r\nhtmlComment = Regex(r""<!--[\\s\\S]*?-->"")\r\nrestOfLine = Regex(r"".*"").leaveWhitespace()\r\ndblSlashComment = Regex(r""\\/\\/(\\\\\\n|.)*"").setName(""// comment"")\r\ncppStyleComment = Regex(r""/(?:\\*(?:[^*]*\\*+)+?/|/[^\\n]*(?:\\n[^\\n]*)*?(?:(?<!\\\\)|\\Z))"").setName(""C++ style comment"")\r\n\r\njavaStyleComment = cppStyleComment\r\npythonStyleComment = Regex(r""#.*"").setName(""Python style comment"")\r\n_commasepitem = Combine(OneOrMore(Word(printables, excludeChars=\',\') +\r\n                                  Optional( Word("" \\t"") +\r\n                                            ~Literal("","") + ~LineEnd() ) ) ).streamline().setName(""commaItem"")\r\ncommaSeparatedList = delimitedList( Optional( quotedString.copy() | _commasepitem, default="""") ).setName(""commaSeparatedList"")\r\n\r\n\r\nif __name__ == ""__main__"":\r\n\r\n    def test( teststring ):\r\n        try:\r\n            tokens = simpleSQL.parseString( teststring )\r\n            tokenlist = tokens.asList()\r\n            print (teststring + ""->""   + str(tokenlist))\r\n            print (""tokens = ""         + str(tokens))\r\n            print (""tokens.columns = "" + str(tokens.columns))\r\n            print (""tokens.tables = ""  + str(tokens.tables))\r\n            print (tokens.asXML(""SQL"",True))\r\n        except ParseBaseException as err:\r\n            print (teststring + ""->"")\r\n            print (err.line)\r\n            print ("" ""*(err.column-1) + ""^"")\r\n            print (err)\r\n        print()\r\n\r\n    selectToken    = CaselessLiteral( ""select"" )\r\n    fromToken      = CaselessLiteral( ""from"" )\r\n\r\n    ident          = Word( alphas, alphanums + ""_$"" )\r\n    columnName     = delimitedList( ident, ""."", combine=True ).setParseAction( upcaseTokens )\r\n    columnNameList = Group( delimitedList( columnName ) )#.setName(""columns"")\r\n    tableName      = delimitedList( ident, ""."", combine=True ).setParseAction( upcaseTokens )\r\n    tableNameList  = Group( delimitedList( tableName ) )#.setName(""tables"")\r\n    simpleSQL      = ( selectToken + \\\r\n                     ( \'*\' | columnNameList ).setResultsName( ""columns"" ) + \\\r\n                     fromToken + \\\r\n                     tableNameList.setResultsName( ""tables"" ) )\r\n\r\n    test( ""SELECT * from XYZZY, ABC"" )\r\n    test( ""select * from SYS.XYZZY"" )\r\n    test( ""Select A from Sys.dual"" )\r\n    test( ""Select AA,BB,CC from Sys.dual"" )\r\n    test( ""Select A, B, C from Sys.dual"" )\r\n    test( ""Select A, B, C from Sys.dual"" )\r\n    test( ""Xelect A, B, C from Sys.dual"" )\r\n    test( ""Select A, B, C frox Sys.dual"" )\r\n    test( ""Select"" )\r\n    test( ""Select ^^^ frox Sys.dual"" )\r\n    test( ""Select A, B, C from Sys.dual, Table2   "" )\r\n'"
rootpy/extern/six.py,0,"b'""""""Utilities for writing code that runs on Python 2 and 3""""""\n\n# Copyright (c) 2010-2015 Benjamin Peterson\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nfrom __future__ import absolute_import\n\nimport functools\nimport itertools\nimport operator\nimport sys\nimport types\n\n__author__ = ""Benjamin Peterson <benjamin@python.org>""\n__version__ = ""1.10.0""\n\n\n# Useful for very coarse version differentiation.\nPY2 = sys.version_info[0] == 2\nPY3 = sys.version_info[0] == 3\nPY34 = sys.version_info[0:2] >= (3, 4)\n\nif PY3:\n    string_types = str,\n    integer_types = int,\n    class_types = type,\n    text_type = str\n    binary_type = bytes\n\n    MAXSIZE = sys.maxsize\nelse:\n    string_types = basestring,\n    integer_types = (int, long)\n    class_types = (type, types.ClassType)\n    text_type = unicode\n    binary_type = str\n\n    if sys.platform.startswith(""java""):\n        # Jython always uses 32 bits.\n        MAXSIZE = int((1 << 31) - 1)\n    else:\n        # It\'s possible to have sizeof(long) != sizeof(Py_ssize_t).\n        class X(object):\n\n            def __len__(self):\n                return 1 << 31\n        try:\n            len(X())\n        except OverflowError:\n            # 32-bit\n            MAXSIZE = int((1 << 31) - 1)\n        else:\n            # 64-bit\n            MAXSIZE = int((1 << 63) - 1)\n        del X\n\n\ndef _add_doc(func, doc):\n    """"""Add documentation to a function.""""""\n    func.__doc__ = doc\n\n\ndef _import_module(name):\n    """"""Import module, returning the module after the last dot.""""""\n    __import__(name)\n    return sys.modules[name]\n\n\nclass _LazyDescr(object):\n\n    def __init__(self, name):\n        self.name = name\n\n    def __get__(self, obj, tp):\n        result = self._resolve()\n        setattr(obj, self.name, result)  # Invokes __set__.\n        try:\n            # This is a bit ugly, but it avoids running this again by\n            # removing this descriptor.\n            delattr(obj.__class__, self.name)\n        except AttributeError:\n            pass\n        return result\n\n\nclass MovedModule(_LazyDescr):\n\n    def __init__(self, name, old, new=None):\n        super(MovedModule, self).__init__(name)\n        if PY3:\n            if new is None:\n                new = name\n            self.mod = new\n        else:\n            self.mod = old\n\n    def _resolve(self):\n        return _import_module(self.mod)\n\n    def __getattr__(self, attr):\n        _module = self._resolve()\n        value = getattr(_module, attr)\n        setattr(self, attr, value)\n        return value\n\n\nclass _LazyModule(types.ModuleType):\n\n    def __init__(self, name):\n        super(_LazyModule, self).__init__(name)\n        self.__doc__ = self.__class__.__doc__\n\n    def __dir__(self):\n        attrs = [""__doc__"", ""__name__""]\n        attrs += [attr.name for attr in self._moved_attributes]\n        return attrs\n\n    # Subclasses should override this\n    _moved_attributes = []\n\n\nclass MovedAttribute(_LazyDescr):\n\n    def __init__(self, name, old_mod, new_mod, old_attr=None, new_attr=None):\n        super(MovedAttribute, self).__init__(name)\n        if PY3:\n            if new_mod is None:\n                new_mod = name\n            self.mod = new_mod\n            if new_attr is None:\n                if old_attr is None:\n                    new_attr = name\n                else:\n                    new_attr = old_attr\n            self.attr = new_attr\n        else:\n            self.mod = old_mod\n            if old_attr is None:\n                old_attr = name\n            self.attr = old_attr\n\n    def _resolve(self):\n        module = _import_module(self.mod)\n        return getattr(module, self.attr)\n\n\nclass _SixMetaPathImporter(object):\n\n    """"""\n    A meta path importer to import six.moves and its submodules.\n\n    This class implements a PEP302 finder and loader. It should be compatible\n    with Python 2.5 and all existing versions of Python3\n    """"""\n\n    def __init__(self, six_module_name):\n        self.name = six_module_name\n        self.known_modules = {}\n\n    def _add_module(self, mod, *fullnames):\n        for fullname in fullnames:\n            self.known_modules[self.name + ""."" + fullname] = mod\n\n    def _get_module(self, fullname):\n        return self.known_modules[self.name + ""."" + fullname]\n\n    def find_module(self, fullname, path=None):\n        if fullname in self.known_modules:\n            return self\n        return None\n\n    def __get_module(self, fullname):\n        try:\n            return self.known_modules[fullname]\n        except KeyError:\n            raise ImportError(""This loader does not know module "" + fullname)\n\n    def load_module(self, fullname):\n        try:\n            # in case of a reload\n            return sys.modules[fullname]\n        except KeyError:\n            pass\n        mod = self.__get_module(fullname)\n        if isinstance(mod, MovedModule):\n            mod = mod._resolve()\n        else:\n            mod.__loader__ = self\n        sys.modules[fullname] = mod\n        return mod\n\n    def is_package(self, fullname):\n        """"""\n        Return true, if the named module is a package.\n\n        We need this method to get correct spec objects with\n        Python 3.4 (see PEP451)\n        """"""\n        return hasattr(self.__get_module(fullname), ""__path__"")\n\n    def get_code(self, fullname):\n        """"""Return None\n\n        Required, if is_package is implemented""""""\n        self.__get_module(fullname)  # eventually raises ImportError\n        return None\n    get_source = get_code  # same as get_code\n\n_importer = _SixMetaPathImporter(__name__)\n\n\nclass _MovedItems(_LazyModule):\n\n    """"""Lazy loading of moved objects""""""\n    __path__ = []  # mark as package\n\n\n_moved_attributes = [\n    MovedAttribute(""cStringIO"", ""cStringIO"", ""io"", ""StringIO""),\n    MovedAttribute(""filter"", ""itertools"", ""builtins"", ""ifilter"", ""filter""),\n    MovedAttribute(""filterfalse"", ""itertools"", ""itertools"", ""ifilterfalse"", ""filterfalse""),\n    MovedAttribute(""input"", ""__builtin__"", ""builtins"", ""raw_input"", ""input""),\n    MovedAttribute(""intern"", ""__builtin__"", ""sys""),\n    MovedAttribute(""map"", ""itertools"", ""builtins"", ""imap"", ""map""),\n    MovedAttribute(""getcwd"", ""os"", ""os"", ""getcwdu"", ""getcwd""),\n    MovedAttribute(""getcwdb"", ""os"", ""os"", ""getcwd"", ""getcwdb""),\n    MovedAttribute(""range"", ""__builtin__"", ""builtins"", ""xrange"", ""range""),\n    MovedAttribute(""reload_module"", ""__builtin__"", ""importlib"" if PY34 else ""imp"", ""reload""),\n    MovedAttribute(""reduce"", ""__builtin__"", ""functools""),\n    MovedAttribute(""shlex_quote"", ""pipes"", ""shlex"", ""quote""),\n    MovedAttribute(""StringIO"", ""StringIO"", ""io""),\n    MovedAttribute(""UserDict"", ""UserDict"", ""collections""),\n    MovedAttribute(""UserList"", ""UserList"", ""collections""),\n    MovedAttribute(""UserString"", ""UserString"", ""collections""),\n    MovedAttribute(""xrange"", ""__builtin__"", ""builtins"", ""xrange"", ""range""),\n    MovedAttribute(""zip"", ""itertools"", ""builtins"", ""izip"", ""zip""),\n    MovedAttribute(""zip_longest"", ""itertools"", ""itertools"", ""izip_longest"", ""zip_longest""),\n    MovedModule(""builtins"", ""__builtin__""),\n    MovedModule(""configparser"", ""ConfigParser""),\n    MovedModule(""copyreg"", ""copy_reg""),\n    MovedModule(""dbm_gnu"", ""gdbm"", ""dbm.gnu""),\n    MovedModule(""_dummy_thread"", ""dummy_thread"", ""_dummy_thread""),\n    MovedModule(""http_cookiejar"", ""cookielib"", ""http.cookiejar""),\n    MovedModule(""http_cookies"", ""Cookie"", ""http.cookies""),\n    MovedModule(""html_entities"", ""htmlentitydefs"", ""html.entities""),\n    MovedModule(""html_parser"", ""HTMLParser"", ""html.parser""),\n    MovedModule(""http_client"", ""httplib"", ""http.client""),\n    MovedModule(""email_mime_multipart"", ""email.MIMEMultipart"", ""email.mime.multipart""),\n    MovedModule(""email_mime_nonmultipart"", ""email.MIMENonMultipart"", ""email.mime.nonmultipart""),\n    MovedModule(""email_mime_text"", ""email.MIMEText"", ""email.mime.text""),\n    MovedModule(""email_mime_base"", ""email.MIMEBase"", ""email.mime.base""),\n    MovedModule(""BaseHTTPServer"", ""BaseHTTPServer"", ""http.server""),\n    MovedModule(""CGIHTTPServer"", ""CGIHTTPServer"", ""http.server""),\n    MovedModule(""SimpleHTTPServer"", ""SimpleHTTPServer"", ""http.server""),\n    MovedModule(""cPickle"", ""cPickle"", ""pickle""),\n    MovedModule(""queue"", ""Queue""),\n    MovedModule(""reprlib"", ""repr""),\n    MovedModule(""socketserver"", ""SocketServer""),\n    MovedModule(""_thread"", ""thread"", ""_thread""),\n    MovedModule(""tkinter"", ""Tkinter""),\n    MovedModule(""tkinter_dialog"", ""Dialog"", ""tkinter.dialog""),\n    MovedModule(""tkinter_filedialog"", ""FileDialog"", ""tkinter.filedialog""),\n    MovedModule(""tkinter_scrolledtext"", ""ScrolledText"", ""tkinter.scrolledtext""),\n    MovedModule(""tkinter_simpledialog"", ""SimpleDialog"", ""tkinter.simpledialog""),\n    MovedModule(""tkinter_tix"", ""Tix"", ""tkinter.tix""),\n    MovedModule(""tkinter_ttk"", ""ttk"", ""tkinter.ttk""),\n    MovedModule(""tkinter_constants"", ""Tkconstants"", ""tkinter.constants""),\n    MovedModule(""tkinter_dnd"", ""Tkdnd"", ""tkinter.dnd""),\n    MovedModule(""tkinter_colorchooser"", ""tkColorChooser"",\n                ""tkinter.colorchooser""),\n    MovedModule(""tkinter_commondialog"", ""tkCommonDialog"",\n                ""tkinter.commondialog""),\n    MovedModule(""tkinter_tkfiledialog"", ""tkFileDialog"", ""tkinter.filedialog""),\n    MovedModule(""tkinter_font"", ""tkFont"", ""tkinter.font""),\n    MovedModule(""tkinter_messagebox"", ""tkMessageBox"", ""tkinter.messagebox""),\n    MovedModule(""tkinter_tksimpledialog"", ""tkSimpleDialog"",\n                ""tkinter.simpledialog""),\n    MovedModule(""urllib_parse"", __name__ + "".moves.urllib_parse"", ""urllib.parse""),\n    MovedModule(""urllib_error"", __name__ + "".moves.urllib_error"", ""urllib.error""),\n    MovedModule(""urllib"", __name__ + "".moves.urllib"", __name__ + "".moves.urllib""),\n    MovedModule(""urllib_robotparser"", ""robotparser"", ""urllib.robotparser""),\n    MovedModule(""xmlrpc_client"", ""xmlrpclib"", ""xmlrpc.client""),\n    MovedModule(""xmlrpc_server"", ""SimpleXMLRPCServer"", ""xmlrpc.server""),\n]\n# Add windows specific modules.\nif sys.platform == ""win32"":\n    _moved_attributes += [\n        MovedModule(""winreg"", ""_winreg""),\n    ]\n\nfor attr in _moved_attributes:\n    setattr(_MovedItems, attr.name, attr)\n    if isinstance(attr, MovedModule):\n        _importer._add_module(attr, ""moves."" + attr.name)\ndel attr\n\n_MovedItems._moved_attributes = _moved_attributes\n\nmoves = _MovedItems(__name__ + "".moves"")\n_importer._add_module(moves, ""moves"")\n\n\nclass Module_six_moves_urllib_parse(_LazyModule):\n\n    """"""Lazy loading of moved objects in six.moves.urllib_parse""""""\n\n\n_urllib_parse_moved_attributes = [\n    MovedAttribute(""ParseResult"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""SplitResult"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""parse_qs"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""parse_qsl"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""urldefrag"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""urljoin"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""urlparse"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""urlsplit"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""urlunparse"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""urlunsplit"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""quote"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""quote_plus"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""unquote"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""unquote_plus"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""urlencode"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""splitquery"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""splittag"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""splituser"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""uses_fragment"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""uses_netloc"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""uses_params"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""uses_query"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""uses_relative"", ""urlparse"", ""urllib.parse""),\n]\nfor attr in _urllib_parse_moved_attributes:\n    setattr(Module_six_moves_urllib_parse, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_parse._moved_attributes = _urllib_parse_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_parse(__name__ + "".moves.urllib_parse""),\n                      ""moves.urllib_parse"", ""moves.urllib.parse"")\n\n\nclass Module_six_moves_urllib_error(_LazyModule):\n\n    """"""Lazy loading of moved objects in six.moves.urllib_error""""""\n\n\n_urllib_error_moved_attributes = [\n    MovedAttribute(""URLError"", ""urllib2"", ""urllib.error""),\n    MovedAttribute(""HTTPError"", ""urllib2"", ""urllib.error""),\n    MovedAttribute(""ContentTooShortError"", ""urllib"", ""urllib.error""),\n]\nfor attr in _urllib_error_moved_attributes:\n    setattr(Module_six_moves_urllib_error, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_error(__name__ + "".moves.urllib.error""),\n                      ""moves.urllib_error"", ""moves.urllib.error"")\n\n\nclass Module_six_moves_urllib_request(_LazyModule):\n\n    """"""Lazy loading of moved objects in six.moves.urllib_request""""""\n\n\n_urllib_request_moved_attributes = [\n    MovedAttribute(""urlopen"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""install_opener"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""build_opener"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""pathname2url"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""url2pathname"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""getproxies"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""Request"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""OpenerDirector"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPDefaultErrorHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPRedirectHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPCookieProcessor"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""ProxyHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""BaseHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPPasswordMgr"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPPasswordMgrWithDefaultRealm"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""AbstractBasicAuthHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPBasicAuthHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""ProxyBasicAuthHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""AbstractDigestAuthHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPDigestAuthHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""ProxyDigestAuthHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPSHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""FileHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""FTPHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""CacheFTPHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""UnknownHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPErrorProcessor"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""urlretrieve"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""urlcleanup"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""URLopener"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""FancyURLopener"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""proxy_bypass"", ""urllib"", ""urllib.request""),\n]\nfor attr in _urllib_request_moved_attributes:\n    setattr(Module_six_moves_urllib_request, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_request._moved_attributes = _urllib_request_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_request(__name__ + "".moves.urllib.request""),\n                      ""moves.urllib_request"", ""moves.urllib.request"")\n\n\nclass Module_six_moves_urllib_response(_LazyModule):\n\n    """"""Lazy loading of moved objects in six.moves.urllib_response""""""\n\n\n_urllib_response_moved_attributes = [\n    MovedAttribute(""addbase"", ""urllib"", ""urllib.response""),\n    MovedAttribute(""addclosehook"", ""urllib"", ""urllib.response""),\n    MovedAttribute(""addinfo"", ""urllib"", ""urllib.response""),\n    MovedAttribute(""addinfourl"", ""urllib"", ""urllib.response""),\n]\nfor attr in _urllib_response_moved_attributes:\n    setattr(Module_six_moves_urllib_response, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_response(__name__ + "".moves.urllib.response""),\n                      ""moves.urllib_response"", ""moves.urllib.response"")\n\n\nclass Module_six_moves_urllib_robotparser(_LazyModule):\n\n    """"""Lazy loading of moved objects in six.moves.urllib_robotparser""""""\n\n\n_urllib_robotparser_moved_attributes = [\n    MovedAttribute(""RobotFileParser"", ""robotparser"", ""urllib.robotparser""),\n]\nfor attr in _urllib_robotparser_moved_attributes:\n    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + "".moves.urllib.robotparser""),\n                      ""moves.urllib_robotparser"", ""moves.urllib.robotparser"")\n\n\nclass Module_six_moves_urllib(types.ModuleType):\n\n    """"""Create a six.moves.urllib namespace that resembles the Python 3 namespace""""""\n    __path__ = []  # mark as package\n    parse = _importer._get_module(""moves.urllib_parse"")\n    error = _importer._get_module(""moves.urllib_error"")\n    request = _importer._get_module(""moves.urllib_request"")\n    response = _importer._get_module(""moves.urllib_response"")\n    robotparser = _importer._get_module(""moves.urllib_robotparser"")\n\n    def __dir__(self):\n        return [\'parse\', \'error\', \'request\', \'response\', \'robotparser\']\n\n_importer._add_module(Module_six_moves_urllib(__name__ + "".moves.urllib""),\n                      ""moves.urllib"")\n\n\ndef add_move(move):\n    """"""Add an item to six.moves.""""""\n    setattr(_MovedItems, move.name, move)\n\n\ndef remove_move(name):\n    """"""Remove item from six.moves.""""""\n    try:\n        delattr(_MovedItems, name)\n    except AttributeError:\n        try:\n            del moves.__dict__[name]\n        except KeyError:\n            raise AttributeError(""no such move, %r"" % (name,))\n\n\nif PY3:\n    _meth_func = ""__func__""\n    _meth_self = ""__self__""\n\n    _func_closure = ""__closure__""\n    _func_code = ""__code__""\n    _func_defaults = ""__defaults__""\n    _func_globals = ""__globals__""\nelse:\n    _meth_func = ""im_func""\n    _meth_self = ""im_self""\n\n    _func_closure = ""func_closure""\n    _func_code = ""func_code""\n    _func_defaults = ""func_defaults""\n    _func_globals = ""func_globals""\n\n\ntry:\n    advance_iterator = next\nexcept NameError:\n    def advance_iterator(it):\n        return it.next()\nnext = advance_iterator\n\n\ntry:\n    callable = callable\nexcept NameError:\n    def callable(obj):\n        return any(""__call__"" in klass.__dict__ for klass in type(obj).__mro__)\n\n\nif PY3:\n    def get_unbound_function(unbound):\n        return unbound\n\n    create_bound_method = types.MethodType\n\n    def create_unbound_method(func, cls):\n        return func\n\n    Iterator = object\nelse:\n    def get_unbound_function(unbound):\n        return unbound.im_func\n\n    def create_bound_method(func, obj):\n        return types.MethodType(func, obj, obj.__class__)\n\n    def create_unbound_method(func, cls):\n        return types.MethodType(func, None, cls)\n\n    class Iterator(object):\n\n        def next(self):\n            return type(self).__next__(self)\n\n    callable = callable\n_add_doc(get_unbound_function,\n         """"""Get the function out of a possibly unbound function"""""")\n\n\nget_method_function = operator.attrgetter(_meth_func)\nget_method_self = operator.attrgetter(_meth_self)\nget_function_closure = operator.attrgetter(_func_closure)\nget_function_code = operator.attrgetter(_func_code)\nget_function_defaults = operator.attrgetter(_func_defaults)\nget_function_globals = operator.attrgetter(_func_globals)\n\n\nif PY3:\n    def iterkeys(d, **kw):\n        return iter(d.keys(**kw))\n\n    def itervalues(d, **kw):\n        return iter(d.values(**kw))\n\n    def iteritems(d, **kw):\n        return iter(d.items(**kw))\n\n    def iterlists(d, **kw):\n        return iter(d.lists(**kw))\n\n    viewkeys = operator.methodcaller(""keys"")\n\n    viewvalues = operator.methodcaller(""values"")\n\n    viewitems = operator.methodcaller(""items"")\nelse:\n    def iterkeys(d, **kw):\n        return d.iterkeys(**kw)\n\n    def itervalues(d, **kw):\n        return d.itervalues(**kw)\n\n    def iteritems(d, **kw):\n        return d.iteritems(**kw)\n\n    def iterlists(d, **kw):\n        return d.iterlists(**kw)\n\n    viewkeys = operator.methodcaller(""viewkeys"")\n\n    viewvalues = operator.methodcaller(""viewvalues"")\n\n    viewitems = operator.methodcaller(""viewitems"")\n\n_add_doc(iterkeys, ""Return an iterator over the keys of a dictionary."")\n_add_doc(itervalues, ""Return an iterator over the values of a dictionary."")\n_add_doc(iteritems,\n         ""Return an iterator over the (key, value) pairs of a dictionary."")\n_add_doc(iterlists,\n         ""Return an iterator over the (key, [values]) pairs of a dictionary."")\n\n\nif PY3:\n    def b(s):\n        return s.encode(""latin-1"")\n\n    def u(s):\n        return s\n    unichr = chr\n    import struct\n    int2byte = struct.Struct("">B"").pack\n    del struct\n    byte2int = operator.itemgetter(0)\n    indexbytes = operator.getitem\n    iterbytes = iter\n    import io\n    StringIO = io.StringIO\n    BytesIO = io.BytesIO\n    _assertCountEqual = ""assertCountEqual""\n    if sys.version_info[1] <= 1:\n        _assertRaisesRegex = ""assertRaisesRegexp""\n        _assertRegex = ""assertRegexpMatches""\n    else:\n        _assertRaisesRegex = ""assertRaisesRegex""\n        _assertRegex = ""assertRegex""\nelse:\n    def b(s):\n        return s\n    # Workaround for standalone backslash\n\n    def u(s):\n        return unicode(s.replace(r\'\\\\\', r\'\\\\\\\\\'), ""unicode_escape"")\n    unichr = unichr\n    int2byte = chr\n\n    def byte2int(bs):\n        return ord(bs[0])\n\n    def indexbytes(buf, i):\n        return ord(buf[i])\n    iterbytes = functools.partial(itertools.imap, ord)\n    import StringIO\n    StringIO = BytesIO = StringIO.StringIO\n    _assertCountEqual = ""assertItemsEqual""\n    _assertRaisesRegex = ""assertRaisesRegexp""\n    _assertRegex = ""assertRegexpMatches""\n_add_doc(b, """"""Byte literal"""""")\n_add_doc(u, """"""Text literal"""""")\n\n\ndef assertCountEqual(self, *args, **kwargs):\n    return getattr(self, _assertCountEqual)(*args, **kwargs)\n\n\ndef assertRaisesRegex(self, *args, **kwargs):\n    return getattr(self, _assertRaisesRegex)(*args, **kwargs)\n\n\ndef assertRegex(self, *args, **kwargs):\n    return getattr(self, _assertRegex)(*args, **kwargs)\n\n\nif PY3:\n    exec_ = getattr(moves.builtins, ""exec"")\n\n    def reraise(tp, value, tb=None):\n        if value is None:\n            value = tp()\n        if value.__traceback__ is not tb:\n            raise value.with_traceback(tb)\n        raise value\n\nelse:\n    def exec_(_code_, _globs_=None, _locs_=None):\n        """"""Execute code in a namespace.""""""\n        if _globs_ is None:\n            frame = sys._getframe(1)\n            _globs_ = frame.f_globals\n            if _locs_ is None:\n                _locs_ = frame.f_locals\n            del frame\n        elif _locs_ is None:\n            _locs_ = _globs_\n        exec(""""""exec _code_ in _globs_, _locs_"""""")\n\n    exec_(""""""def reraise(tp, value, tb=None):\n    raise tp, value, tb\n"""""")\n\n\nif sys.version_info[:2] == (3, 2):\n    exec_(""""""def raise_from(value, from_value):\n    if from_value is None:\n        raise value\n    raise value from from_value\n"""""")\nelif sys.version_info[:2] > (3, 2):\n    exec_(""""""def raise_from(value, from_value):\n    raise value from from_value\n"""""")\nelse:\n    def raise_from(value, from_value):\n        raise value\n\n\nprint_ = getattr(moves.builtins, ""print"", None)\nif print_ is None:\n    def print_(*args, **kwargs):\n        """"""The new-style print function for Python 2.4 and 2.5.""""""\n        fp = kwargs.pop(""file"", sys.stdout)\n        if fp is None:\n            return\n\n        def write(data):\n            if not isinstance(data, basestring):\n                data = str(data)\n            # If the file has an encoding, encode unicode with it.\n            if (isinstance(fp, file) and\n                    isinstance(data, unicode) and\n                    fp.encoding is not None):\n                errors = getattr(fp, ""errors"", None)\n                if errors is None:\n                    errors = ""strict""\n                data = data.encode(fp.encoding, errors)\n            fp.write(data)\n        want_unicode = False\n        sep = kwargs.pop(""sep"", None)\n        if sep is not None:\n            if isinstance(sep, unicode):\n                want_unicode = True\n            elif not isinstance(sep, str):\n                raise TypeError(""sep must be None or a string"")\n        end = kwargs.pop(""end"", None)\n        if end is not None:\n            if isinstance(end, unicode):\n                want_unicode = True\n            elif not isinstance(end, str):\n                raise TypeError(""end must be None or a string"")\n        if kwargs:\n            raise TypeError(""invalid keyword arguments to print()"")\n        if not want_unicode:\n            for arg in args:\n                if isinstance(arg, unicode):\n                    want_unicode = True\n                    break\n        if want_unicode:\n            newline = unicode(""\\n"")\n            space = unicode("" "")\n        else:\n            newline = ""\\n""\n            space = "" ""\n        if sep is None:\n            sep = space\n        if end is None:\n            end = newline\n        for i, arg in enumerate(args):\n            if i:\n                write(sep)\n            write(arg)\n        write(end)\nif sys.version_info[:2] < (3, 3):\n    _print = print_\n\n    def print_(*args, **kwargs):\n        fp = kwargs.get(""file"", sys.stdout)\n        flush = kwargs.pop(""flush"", False)\n        _print(*args, **kwargs)\n        if flush and fp is not None:\n            fp.flush()\n\n_add_doc(reraise, """"""Reraise an exception."""""")\n\nif sys.version_info[0:2] < (3, 4):\n    def wraps(wrapped, assigned=functools.WRAPPER_ASSIGNMENTS,\n              updated=functools.WRAPPER_UPDATES):\n        def wrapper(f):\n            f = functools.wraps(wrapped, assigned, updated)(f)\n            f.__wrapped__ = wrapped\n            return f\n        return wrapper\nelse:\n    wraps = functools.wraps\n\n\ndef with_metaclass(meta, *bases):\n    """"""Create a base class with a metaclass.""""""\n    # This requires a bit of explanation: the basic idea is to make a dummy\n    # metaclass for one level of class instantiation that replaces itself with\n    # the actual metaclass.\n    class metaclass(meta):\n\n        def __new__(cls, name, this_bases, d):\n            return meta(name, bases, d)\n    return type.__new__(metaclass, \'temporary_class\', (), {})\n\n\ndef add_metaclass(metaclass):\n    """"""Class decorator for creating a class with a metaclass.""""""\n    def wrapper(cls):\n        orig_vars = cls.__dict__.copy()\n        slots = orig_vars.get(\'__slots__\')\n        if slots is not None:\n            if isinstance(slots, str):\n                slots = [slots]\n            for slots_var in slots:\n                orig_vars.pop(slots_var)\n        orig_vars.pop(\'__dict__\', None)\n        orig_vars.pop(\'__weakref__\', None)\n        return metaclass(cls.__name__, cls.__bases__, orig_vars)\n    return wrapper\n\n\ndef python_2_unicode_compatible(klass):\n    """"""\n    A decorator that defines __unicode__ and __str__ methods under Python 2.\n    Under Python 3 it does nothing.\n\n    To support Python 2 and 3 with a single code base, define a __str__ method\n    returning text and apply this decorator to the class.\n    """"""\n    if PY2:\n        if \'__str__\' not in klass.__dict__:\n            raise ValueError(""@python_2_unicode_compatible cannot be applied ""\n                             ""to %s because it doesn\'t define __str__()."" %\n                             klass.__name__)\n        klass.__unicode__ = klass.__str__\n        klass.__str__ = lambda self: self.__unicode__().encode(\'utf-8\')\n    return klass\n\n\n# Complete the moves implementation.\n# This code is at the end of this module to speed up module loading.\n# Turn this module into a package.\n__path__ = []  # required for PEP 302 and PEP 451\n__package__ = __name__  # see PEP 366 @ReservedAssignment\nif globals().get(""__spec__"") is not None:\n    __spec__.submodule_search_locations = []  # PEP 451 @UndefinedVariable\n# Remove other six meta path importers, since they cause problems. This can\n# happen if six is removed from sys.modules and then reloaded. (Setuptools does\n# this for some reason.)\nif sys.meta_path:\n    for i, importer in enumerate(sys.meta_path):\n        # Here\'s some real nastiness: Another ""instance"" of the six module might\n        # be floating around. Therefore, we can\'t use isinstance() to check for\n        # the six meta path importer, since the other six instance will have\n        # inserted an importer with different class.\n        if (type(importer).__name__ == ""_SixMetaPathImporter"" and\n                importer.name == __name__):\n            del sys.meta_path[i]\n            break\n    del i, importer\n# Finally, add the importer to the meta path import hook.\nsys.meta_path.append(_importer)\n'"
rootpy/interactive/__init__.py,0,"b'""""""\nProvide some features for writing scripts which provide interactive features\n\nwait: Keeps root alive until ctrl-c is pressed or all canvases are closed\ninteract: Starts a python console at the call site\n""""""\nfrom __future__ import absolute_import\n\nfrom .. import log; log = log[__name__]\nfrom .console import interact\nfrom .rootwait import wait, wait_for_zero_canvases, wait_for_browser_close\nfrom .notebook import configure as configure_notebook\n\n__all__ = [\n    \'interact\',\n    \'wait\', \'wait_for_zero_canvases\', \'wait_for_browser_close\',\n    \'configure_notebook\',\n]\n'"
rootpy/interactive/canvas_events.py,0,"b'from __future__ import absolute_import\n\nimport ROOT\n\nfrom .. import compiled as C\n\n__all__ = [\n    \'close_on_esc_or_middlemouse\',\n    \'attach_event_handler\',\n]\n\nC.register_code(""""""\n#include <TPython.h>\n#include <TPyDispatcher.h>\n\nclass TPyDispatcherProcessedEvent : public TPyDispatcher {\npublic:\n    TPyDispatcherProcessedEvent(PyObject* callable) : TPyDispatcher(callable){}\n\n    PyObject* Dispatch(int p1, int p2, int p3, void* p4) {\n        if (!p4) return NULL;\n        PyObject* p4_aspyobj = TPython::ObjectProxy_FromVoidPtr(p4,\n            reinterpret_cast<TObject*>(p4)->ClassName());\n        PyObject* result = DispatchVA(""lllO"", p1, p2, p3, p4_aspyobj);\n        return result;\n    }\n\n    ClassDef(TPyDispatcherProcessedEvent, 0);\n};\n\nClassImp(TPyDispatcherProcessedEvent);\n"""""", [""TPyDispatcherProcessedEvent""])\n\n\ndef close_on_esc_or_middlemouse(event, x, y, obj):\n    """"""\n    Closes canvases when escape is pressed or the canvas area is clicked with\n    the middle mouse button. (ROOT requires that the mouse is over the canvas\n    area itself before sending signals of any kind.)\n    """"""\n    #print ""Event handler called:"", args\n\n    if (event == ROOT.kButton2Down\n            # User pressed middle mouse\n        or (event == ROOT.kMouseMotion and\n            x == y == 0 and\n            # User pressed escape. Yes. Don\'t ask me why kMouseMotion.\n            ROOT.gROOT.IsEscaped())):\n\n        # Defer the close because otherwise root segfaults when it tries to\n        # run gPad->Modified()\n        obj._py_closetimer = ROOT.TTimer()\n        obj._py_closetimer.Connect(""Timeout()"", ""TCanvas"", obj, ""Close()"")\n        # Single shot after 10ms\n        obj._py_closetimer.Start(10, ROOT.kTRUE)\n\n\ndef attach_event_handler(canvas, handler=close_on_esc_or_middlemouse):\n    """"""\n    Attach a handler function to the ProcessedEvent slot, defaulting to\n    closing when middle mouse is clicked or escape is pressed\n\n    Note that escape only works if the pad has focus, which in ROOT-land means\n    the mouse has to be over the canvas area.\n    """"""\n    if getattr(canvas, ""_py_event_dispatcher_attached"", None):\n        return\n\n    event_dispatcher = C.TPyDispatcherProcessedEvent(handler)\n    canvas.Connect(""ProcessedEvent(int,int,int,TObject*)"",\n                   ""TPyDispatcherProcessedEvent"", event_dispatcher,\n                   ""Dispatch(int,int,int,TObject*)"")\n\n    # Attach a handler only once to each canvas, and keep the dispatcher alive\n    canvas._py_event_dispatcher_attached = event_dispatcher\n'"
rootpy/interactive/console.py,0,"b'""""""\nSpawn an interactive python console in the current frame.\n\nFor example::\n\n    from rootpy.interactive import interact\n    x = 1\n    interact()\n    # Now you\'re in a python console.\n\n""""""\nfrom __future__ import absolute_import\n\nimport code\nimport readline\nimport sys\n\nimport ROOT as R\n\nfrom ..logger.magic import fix_ipython_startup\n\n__all__ = [\n    \'interact\',\n]\n\n# overridden if importing ipython is successful\nhave_ipython = False\n\n# Make it so that a subsequent \\n has no effect\nUP_LINE = \'\\r\\x1b[1A\'\n\n\ndef interact_plain(header=UP_LINE, local_ns=None,\n                   module=None, dummy=None,\n                   stack_depth=1, global_ns=None):\n    """"""\n    Create an interactive python console\n    """"""\n    frame = sys._getframe(stack_depth)\n\n    variables = {}\n\n    if local_ns is not None:\n        variables.update(local_ns)\n    else:\n        variables.update(frame.f_locals)\n\n    if global_ns is not None:\n        variables.update(local_ns)\n    else:\n        variables.update(frame.f_globals)\n\n    shell = code.InteractiveConsole(variables)\n    return shell.interact(banner=header)\n\ntry:\n    from IPython.terminal.embed import InteractiveShellEmbed\n    have_ipython = True\n\nexcept ImportError:\n    interact = interact_plain\n\nelse:\n    # ROOT has a bug causing it to print (Bool_t)1 to the console.\n    # This is fixed in defaults.py if rootpy is imported under the ipython\n    # interpreter, but at this point that is too late, so we need to try again\n    _finalSetup = getattr(R.__class__, ""_ModuleFacade__finalSetup"", None)\n    if _finalSetup:\n        _orig_func = getattr(_finalSetup, ""_orig_func"", None)\n        if _orig_func:\n            _finalSetup = _orig_func\n        fix_ipython_startup(_finalSetup)\n\n    interact_ipython_ = None\n\n    def interact_ipython(header=\'\', *args, **kwargs):\n        global interact_ipython_\n\n        def pre_prompt_hook(_):\n            R.gInterpreter.EndOfLineAction()\n\n        # Interact is a callable which starts an ipython shell\n        if not interact_ipython_:\n            interact_ipython_ = InteractiveShellEmbed(banner1=UP_LINE)\n        # needed for graphics to work correctly\n        interact_ipython_.set_hook(\'pre_prompt_hook\', pre_prompt_hook)\n        stack_depth = kwargs.pop(""stack_depth"", 0) + 2\n        kwargs[""stack_depth""] = stack_depth\n        interact_ipython_(header, *args, **kwargs)\n\n    interact = interact_ipython\n'"
rootpy/interactive/notebook.py,0,"b'""""""\nRegister display formatters for ROOT objects when running in an interactive\nIPython notebook.\n\nBased on an implementation here: https://gist.github.com/mazurov/6194738\n""""""\nimport tempfile\n\nfrom .. import IN_IPYTHON\nfrom ..plotting import Canvas\nfrom ..context import preserve_current_canvas\nfrom ..utils.hook import classhook, super_overridden\n\nif IN_IPYTHON:\n    from IPython.core import display\n\n__all__ = [\n    \'configure\',\n]\n\n\ndef _display_canvas(canvas):\n    file_handle = tempfile.NamedTemporaryFile(suffix=\'.png\')\n    canvas.SaveAs(file_handle.name)\n    ip_img = display.Image(filename=file_handle.name, format=\'png\', embed=True)\n    return ip_img._repr_png_()\n\n\ndef _draw_image(meth, *args, **kwargs):\n    file_handle = tempfile.NamedTemporaryFile(suffix=\'.png\')\n    with preserve_current_canvas():\n        canvas = Canvas()\n        meth(*args, **kwargs)\n        canvas.SaveAs(file_handle.name)\n    return display.Image(filename=file_handle.name, format=\'png\', embed=True)\n\n\ndef _display_any(obj):\n    return _draw_image(obj.Draw)._repr_png_()\n\n\ndef configure():\n    if not IN_IPYTHON:\n        raise RuntimeError(""not currently running in IPython"")\n    import ROOT\n    # trigger PyROOT\'s finalSetup()\n    ROOT.kTRUE\n    # canvases will be displayed inline\n    ROOT.gROOT.SetBatch()\n    try:\n        # only available if running in IPython:\n        shell = get_ipython()\n    except NameError:\n        # must be in non-interactive mode (ipcluster?)\n        return\n    # register display functions with PNG formatter:\n    png_formatter = shell.display_formatter.formatters[\'image/png\']\n    png_formatter.for_type(ROOT.TCanvas, _display_canvas)\n    png_formatter.for_type(ROOT.TF1, _display_any)\n    png_formatter.for_type(ROOT.TH1, _display_any)\n    png_formatter.for_type(ROOT.THStack, _display_any)\n    png_formatter.for_type(ROOT.TGraph, _display_any)\n    png_formatter.for_type(ROOT.TGraph2D, _display_any)\n'"
rootpy/interactive/rootwait.py,0,"b'""""""\nThe functions in this module provide a way of pausing code execution until\ncanvases are closed. This can be useful when testing code and you don\'t want to\nkeep the objects alive outside of your function.\n\nThe wait function can be called repeatedly to pause multiple times.\n\nwait_for_zero_canvases()\n    Keeps root alive until CTRL-c is pressed or all canvases are closed\n\nwait_for_zero_canvases(middle_mouse_close=True)\n    allows canvases to be closed with the middle mouse button (see below)\n\nwait is shorthand for wait_for_zero_canvases\n\nExamples\n--------\n\n    from rootpy.plotting import Canvas\n    from rootpy.interactive import wait\n\n    c = Canvas()\n    c.Update()\n    wait()\n\n    c2 = Canvas()\n    c2.Update()\n    wait(True)\n    # This canvas can be killed by middle clicking on it or hitting\n    # escape whilst it has focus\n\n""""""\nfrom __future__ import absolute_import\n\nimport threading\nfrom atexit import register\n\nimport ROOT\n\nfrom . import log; log = log[__name__]\nfrom ..defaults import extra_initialization\nfrom ..memory.keepalive import keepalive\nfrom .. import IN_IPYTHON_NOTEBOOK\nfrom .canvas_events import attach_event_handler\nfrom ..extern.six.moves import input\n\n__all__ = [\n    \'wait_for_zero_canvases\',\n    \'wait_for_browser_close\',\n    \'wait\',\n]\n\n_processRootEvents = None\n_finishSchedule = None\n__ACTIVE = False\n\n\n@extra_initialization\ndef fetch_vars():\n    global _processRootEvents, _finishSchedule, __ACTIVE\n    PyGUIThread = getattr(ROOT, \'PyGUIThread\', None)\n    if PyGUIThread is not None:\n        _processRootEvents = getattr(PyGUIThread, ""_Thread__target"", None)\n        _finishSchedule = getattr(PyGUIThread, ""finishSchedule"", None)\n    if _processRootEvents is None:\n        if not IN_IPYTHON_NOTEBOOK:\n            log.warning(\n                """"""unable to access ROOT\'s GUI thread either because PyROOT\'s\n                finalSetup() was called while in batch mode or because PyROOT\n                is using the new PyOS_InputHook-based mechanism that is not yet\n                supported in rootpy (PyConfig.StartGuiThread == \'inputhook\' or\n                gSystem.InheritsFrom(\'TMacOSXSystem\')). wait() etc. will\n                instead call input() and wait for [Enter]"""""")\n    else:\n        __ACTIVE = True\n\n\ndef wait_failover(caller):\n    if not ROOT.gROOT.IsBatch():\n        log.warning(\n            ""{0} is failing over to input()"".format(caller.__name__))\n        input(""press [Enter] to continue"")\n\n\ndef start_new_gui_thread():\n    """"""\n    Attempt to start a new GUI thread, if possible.\n\n    It is only possible to start one if there was one running on module import.\n    """"""\n    PyGUIThread = getattr(ROOT, \'PyGUIThread\', None)\n\n    if PyGUIThread is not None:\n        assert not PyGUIThread.isAlive(), ""GUI thread already running!""\n\n    assert _processRootEvents, (\n        ""GUI thread wasn\'t started when rootwait was imported, ""\n        ""so it can\'t be restarted"")\n\n    ROOT.keeppolling = 1\n    ROOT.PyGUIThread = threading.Thread(\n        None, _processRootEvents, None, (ROOT,))\n\n    ROOT.PyGUIThread.finishSchedule = _finishSchedule\n    ROOT.PyGUIThread.setDaemon(1)\n    ROOT.PyGUIThread.start()\n    log.debug(""successfully started a new GUI thread"")\n\n\ndef stop_gui_thread():\n    """"""\n    Try to stop the GUI thread. If it was running returns True,\n    otherwise False.\n    """"""\n    PyGUIThread = getattr(ROOT, \'PyGUIThread\', None)\n\n    if PyGUIThread is None or not PyGUIThread.isAlive():\n        log.debug(""no existing GUI thread is runnng"")\n        return False\n\n    ROOT.keeppolling = 0\n    try:\n        PyGUIThread.finishSchedule()\n    except AttributeError:\n        log.debug(""unable to call finishSchedule() on PyGUIThread"")\n        pass\n    PyGUIThread.join()\n    log.debug(""successfully stopped the existing GUI thread"")\n    return True\n\n\ndef get_visible_canvases():\n    """"""\n    Return a list of active GUI canvases\n    (as opposed to invisible Batch canvases)\n    """"""\n    try:\n        return [c for c in ROOT.gROOT.GetListOfCanvases() if not c.IsBatch()]\n    except AttributeError:\n        # We might be exiting and ROOT.gROOT will raise an AttributeError\n        return []\n\n\ndef run_application_until_done():\n\n    had_gui_thread = stop_gui_thread()\n\n    ROOT.gApplication._threaded = True\n    ROOT.gApplication.Run(True)\n\n    if had_gui_thread:\n        start_new_gui_thread()\n\n\ndef dispatcher(f):\n    disp = ROOT.TPyDispatcher(f)\n    keepalive(disp, f)\n    return disp\n\n\ndef wait_for_zero_canvases(middle_mouse_close=False):\n    """"""\n    Wait for all canvases to be closed, or CTRL-c.\n\n    If `middle_mouse_close`, middle click will shut the canvas.\n\n    incpy.ignore\n    """"""\n    if not __ACTIVE:\n        wait_failover(wait_for_zero_canvases)\n        return\n\n    @dispatcher\n    def count_canvases():\n        """"""\n        Count the number of active canvases and finish gApplication.Run()\n        if there are none remaining.\n\n        incpy.ignore\n        """"""\n        if not get_visible_canvases():\n            try:\n                ROOT.gSystem.ExitLoop()\n            except AttributeError:\n                # We might be exiting and ROOT.gROOT will raise an AttributeError\n                pass\n\n    @dispatcher\n    def exit_application_loop():\n        """"""\n        Signal handler for CTRL-c to cause gApplication.Run() to finish.\n\n        incpy.ignore\n        """"""\n        ROOT.gSystem.ExitLoop()\n\n    # Handle CTRL-c\n    sh = ROOT.TSignalHandler(ROOT.kSigInterrupt, True)\n    sh.Add()\n    sh.Connect(""Notified()"", ""TPyDispatcher"",\n               exit_application_loop, ""Dispatch()"")\n\n    visible_canvases = get_visible_canvases()\n\n    for canvas in visible_canvases:\n        log.debug(""waiting for canvas {0} to close"".format(canvas.GetName()))\n        canvas.Update()\n\n        if middle_mouse_close:\n            attach_event_handler(canvas)\n\n        if not getattr(canvas, ""_py_close_dispatcher_attached"", False):\n            # Attach a handler only once to each canvas\n            canvas._py_close_dispatcher_attached = True\n            canvas.Connect(""Closed()"", ""TPyDispatcher"",\n                           count_canvases, ""Dispatch()"")\n            keepalive(canvas, count_canvases)\n\n    if visible_canvases and not ROOT.gROOT.IsBatch():\n        run_application_until_done()\n\n        # Disconnect from canvases\n        for canvas in visible_canvases:\n            if getattr(canvas, ""_py_close_dispatcher_attached"", False):\n                canvas._py_close_dispatcher_attached = False\n                canvas.Disconnect(""Closed()"", count_canvases, ""Dispatch()"")\n\nwait = wait_for_zero_canvases\n\n\ndef wait_for_frame(frame):\n    """"""\n    wait until a TGMainFrame is closed or ctrl-c\n    """"""\n    if not frame:\n        # It\'s already closed or maybe we\'re in batch mode\n        return\n\n    @dispatcher\n    def close():\n        ROOT.gSystem.ExitLoop()\n\n    if not getattr(frame, ""_py_close_dispatcher_attached"", False):\n        frame._py_close_dispatcher_attached = True\n        frame.Connect(""CloseWindow()"", ""TPyDispatcher"", close, ""Dispatch()"")\n\n    @dispatcher\n    def exit_application_loop():\n        """"""\n        Signal handler for CTRL-c to cause gApplication.Run() to finish.\n\n        incpy.ignore\n        """"""\n        ROOT.gSystem.ExitLoop()\n\n    # Handle CTRL-c\n    sh = ROOT.TSignalHandler(ROOT.kSigInterrupt, True)\n    sh.Add()\n    sh.Connect(""Notified()"", ""TPyDispatcher"",\n               exit_application_loop, ""Dispatch()"")\n\n    if not ROOT.gROOT.IsBatch():\n        run_application_until_done()\n        # Need to disconnect to prevent close handler from running when python\n        # teardown has already commenced.\n        frame.Disconnect(""CloseWindow()"", close, ""Dispatch()"")\n\n\ndef wait_for_browser_close(b):\n    """"""\n    Can be used to wait until a TBrowser is closed\n    """"""\n    if b:\n        if not __ACTIVE:\n            wait_failover(wait_for_browser_close)\n            return\n        wait_for_frame(b.GetBrowserImp().GetMainFrame())\n\n\ndef prevent_close_with_canvases():\n    """"""\n    Register a handler which prevents python from exiting until\n    all canvases are closed\n    """"""\n    register(wait_for_zero_canvases)\n'"
rootpy/io/__init__.py,0,"b""from __future__ import absolute_import\n\nfrom .. import log; log = log[__name__]\nfrom .file import (\n    DoesNotExist, Key, Directory, File,\n    MemFile, TemporaryFile, root_open)\n\n__all__ = [\n    'DoesNotExist',\n    'Key',\n    'Directory',\n    'File',\n    'MemFile',\n    'TemporaryFile',\n    'root_open',\n]\n"""
rootpy/io/file.py,0,"b'""""""\nThis module enhances IO-related ROOT functionality\n""""""\nfrom __future__ import absolute_import\n\nimport os\nimport re\nimport tempfile\nfrom fnmatch import fnmatch\nfrom collections import defaultdict\n\nfrom .. import ROOT\nfrom .. import asrootpy, QROOT\nfrom ..base import Object, NamedObject\nfrom ..decorators import snake_case_methods\nfrom ..context import preserve_current_directory\nfrom ..utils.path import expand as expand_path\nfrom ..memory.keepalive import keepalive\nfrom ..extern.shortuuid import uuid\nfrom ..extern.six import string_types\n\n\n__all__ = [\n    \'DoesNotExist\',\n    \'Key\',\n    \'Directory\',\n    \'File\',\n    \'MemFile\',\n    \'TemporaryFile\',\n    \'root_open\',\n]\n\n\nVALIDPATH = \'^(?P<file>.+.root)(?:[/](?P<path>.+))?$\'\n\n\nclass DoesNotExist(Exception):\n    """"""\n    This exception is raised if an attempt is made to access an object\n    that does not exist in a directory.\n    """"""\n    pass\n\n\ndef autovivitree():\n    # http://en.wikipedia.org/wiki/Autovivification#Python\n    return defaultdict(autovivitree)\n\n\ndef splitfile(path):\n    filename, _, path = path.partition(\':\' + os.path.sep)\n    return filename, os.path.sep + path\n\n\ndef wrap_path_handling(f):\n    def get(self, name, *args, **kwargs):\n        _name = os.path.normpath(name)\n        if _name == \'.\':\n            return self\n        if _name == \'..\':\n            return self._parent\n        try:\n            dirpath, _, path = _name.partition(os.path.sep)\n            if path:\n                if dirpath == \'..\':\n                    return self._parent.Get(path, *args, **kwargs)\n                else:\n                    _dir = self.Get(dirpath)\n                    if not isinstance(_dir, _DirectoryBase):\n                        raise DoesNotExist\n                    _dir._parent = self\n                    _dir._path = os.path.join(self._path, dirpath)\n                    thing = get(_dir, path, *args, **kwargs)\n            else:\n                thing = f(self, _name, *args, **kwargs)\n                if isinstance(thing, _DirectoryBase):\n                    thing._parent = self\n            if isinstance(thing, _DirectoryBase):\n                if isinstance(self, File):\n                    thing._path = os.path.normpath(\n                        (\':\' + os.path.sep).join([self._path, _name]))\n                else:\n                    thing._path = os.path.normpath(\n                        os.path.join(self._path, _name))\n            return thing\n        except DoesNotExist:\n            raise DoesNotExist(\n                ""requested path \'{0}\' does not exist in {1}"".format(\n                    name, self._path))\n    return get\n\n\ndef root_open(filename, mode=\'\'):\n    """"""\n    Open a ROOT file via ROOT\'s static ROOT.TFile.Open [1] function and return\n    an asrootpy\'d File.\n\n    Parameters\n    ----------\n\n    filename : string\n        The absolute or relative path to the ROOT file.\n\n    mode : string, optional (default=\'\')\n        Mode indicating how the file is to be opened.  This can be either one\n        of the options supported by ROOT.TFile.Open [2], or one of `a`, `a+`,\n        `r`, `r+`, `w` or `w+`, with meanings as for the built-in `open()`\n        function [3].\n\n    Returns\n    -------\n\n    root_file : File\n        an instance of rootpy\'s File subclass of ROOT\'s TFile.\n\n    References\n    ----------\n\n    .. [1] http://root.cern.ch/root/html/TFile.html#TFile:Open\n    .. [2] http://root.cern.ch/root/html/TFile.html#TFile:TFile@2\n    .. [3] https://docs.python.org/2/library/functions.html#open\n\n    """"""\n    mode_map = {\'a\': \'UPDATE\',\n                \'a+\': \'UPDATE\',\n                \'r\': \'READ\',\n                \'r+\': \'UPDATE\',\n                \'w\': \'RECREATE\',\n                \'w+\': \'RECREATE\'}\n\n    if mode in mode_map:\n        mode = mode_map[mode]\n\n    filename = expand_path(filename)\n    prev_dir = ROOT.gDirectory\n    root_file = ROOT.R.TFile.Open(filename, mode)\n    if not root_file:\n        raise IOError(""could not open file: \'{0}\'"".format(filename))\n    root_file.__class__ = File\n    root_file._path = filename\n    root_file._parent = root_file\n    root_file._prev_dir = prev_dir\n    # give Python ownership of the TFile so we can delete it\n    ROOT.SetOwnership(root_file, True)\n    return root_file\n\n\n@snake_case_methods\nclass Key(NamedObject, QROOT.TKey):\n    """"""\n    A subclass of ROOT\'s TKey [1]\n\n    References\n    ----------\n\n    .. [1] http://root.cern.ch/root/html/TKey.html\n\n    """"""\n    _ROOT = QROOT.TKey\n\n\nclass _DirectoryBase(Object):\n\n    def __str__(self):\n        return ""{0}(\'{1}\')"".format(self.__class__.__name__, self._path)\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __getattr__(self, attr):\n        """"""\n        Natural naming support. Now you can get an object from a\n        File/Directory with::\n\n            myfile.somedir.otherdir.histname\n        """"""\n        # Be careful! If ``__getattr__`` ends up being called again here,\n        # this can end up in an ""infinite"" recursion and stack overflow.\n\n        # Directly call ROOT\'s Get() here since ``attr`` must anyway be a valid\n        # identifier (not a path including subdirectories).\n        thing = super(_DirectoryBase, self).Get(attr)\n        if not thing:\n            raise AttributeError(\n                ""{0} has no attribute \'{1}\'"".format(self, attr))\n        thing = asrootpy(thing)\n        if isinstance(thing, Directory):\n            thing._path = os.path.join(self._path, thing.GetName())\n            thing._parent = self\n        return thing\n\n    def __setattr__(self, attr, value):\n        """"""\n        Allow writing objects in a file with ``myfile.thing = myobject``\n        """"""\n        if (attr.startswith(\'_\')  # PyROOT also sets __lifeline\n                or attr in self.__dict__\n                or not isinstance(value, ROOT.R.TObject)):\n            # not fully initialized so use regular setattr\n            return super(_DirectoryBase, self).__setattr__(attr, value)\n        # pass to setitem\n        self.__setitem__(attr, value)\n\n    def __getitem__(self, name):\n        return self.Get(name)\n\n    def __setitem__(self, name, thing):\n        """"""\n        Allow writing objects in a file with ``myfile[\'thing\'] = myobject``\n        """"""\n        with preserve_current_directory():\n            self.cd()\n            thing.Write(name)\n\n    def __iter__(self):\n        return self.objects()\n\n    def __enter__(self):\n        curr_dir = ROOT.gDirectory\n        if curr_dir != self:\n            self._prev_dir = curr_dir\n        self.cd()\n        return self\n\n    def __exit__(self, type, value, traceback):\n        self.Close()\n        return False\n\n    def cd_previous(self):\n        """"""\n        cd to the gDirectory before this file was open.\n        """"""\n        if self._prev_dir is None or isinstance(self._prev_dir, ROOT.TROOT):\n            return False\n        if isinstance(self._prev_dir, ROOT.TFile):\n            if self._prev_dir.IsOpen() and self._prev_dir.IsWritable():\n                self._prev_dir.cd()\n                return True\n            return False\n        if not self._prev_dir.IsWritable():\n            # avoid warning from ROOT stating file is not writable\n            return False\n        prev_file = self._prev_dir.GetFile()\n        if prev_file and prev_file.IsOpen():\n            self._prev_dir.cd()\n            return True\n        return False\n\n    def Close(self, *args):\n        """"""\n        Like ROOT\'s Close but reverts to the gDirectory before this file was\n        opened.\n        """"""\n        super(_DirectoryBase, self).Close(*args)\n        return self.cd_previous()\n\n    def objects(self, cls=None):\n        """"""\n        Return an iterater over all objects in this directory which are\n        instances of `cls`. By default, iterate over all objects (`cls=None`).\n\n        Parameters\n        ----------\n\n        cls : a class, optional (default=None)\n            If a class is specified, only iterate over objects that are\n            instances of this class.\n\n        Returns\n        -------\n\n        A generator over the objects in this directory.\n\n        Examples\n        --------\n\n            $ rootpy browse myfile.root\n\n            In [1]: list(f1.objects(R.Directory))\n            Out[1]: [Directory(\'mydirectory\')]\n\n        """"""\n        objs = (asrootpy(x.ReadObj(), warn=False)\n                for x in self.GetListOfKeys())\n        if cls is not None:\n            objs = (obj for obj in objs if isinstance(obj, cls))\n        return objs\n\n    def keys(self, latest=False):\n        """"""\n        Return a list of the keys in this directory.\n\n        Parameters\n        ----------\n\n        latest : bool, optional (default=False)\n            If True then return a list of keys with unique names where only the\n            key with the highest cycle number is included where multiple keys\n            exist with the same name.\n\n        Returns\n        -------\n\n        keys : list\n            List of keys\n\n        """"""\n        if latest:\n            keys = {}\n            for key in self.keys():\n                name = key.GetName()\n                if name in keys:\n                    if key.GetCycle() > keys[name].GetCycle():\n                        keys[name] = key\n                else:\n                    keys[name] = key\n            return keys.values()\n        return [asrootpy(key) for key in self.GetListOfKeys()]\n\n    @wrap_path_handling\n    def Get(self, path, rootpy=True, **kwargs):\n        """"""\n        Return the requested object cast as its corresponding subclass in\n        rootpy if one exists and ``rootpy=True``, otherwise return the\n        unadulterated TObject.\n        """"""\n        thing = super(_DirectoryBase, self).Get(path)\n        if not thing:\n            raise DoesNotExist\n\n        # Ensure that the file we took the object from is alive at least as\n        # long as the object being taken from it.\n\n        # Note, Python does *not* own `thing`, it is ROOT\'s responsibility to\n        # delete it in the C++ sense. (SetOwnership is False). However, ROOT\n        # will delete the object when the TFile\'s destructor is run.\n        # Therefore, when `thing` goes out of scope and the file referred to\n        # by `this` has no references left, the file is destructed and calls\n        # `thing`\'s delete.\n\n        # (this is thanks to the fact that weak referents (used by keepalive)\n        #  are notified when they are dead).\n\n        keepalive(thing, self)\n\n        if rootpy:\n            return asrootpy(thing, **kwargs)\n        return thing\n\n    @wrap_path_handling\n    def GetDirectory(self, path, rootpy=True, **kwargs):\n        rdir = super(_DirectoryBase, self).GetDirectory(path)\n        if not rdir:\n            raise DoesNotExist\n        if rootpy:\n            return asrootpy(rdir, **kwargs)\n        return rdir\n\n    @wrap_path_handling\n    def GetKey(self, path, cycle=9999, rootpy=True, **kwargs):\n        """"""\n        Override TDirectory\'s GetKey and also handle accessing keys nested\n        arbitrarily deep in subdirectories.\n        """"""\n        key = super(_DirectoryBase, self).GetKey(path, cycle)\n        if not key:\n            raise DoesNotExist\n        if rootpy:\n            return asrootpy(key, **kwargs)\n        return key\n\n    def __contains__(self, path):\n        """"""\n        Determine if a an object exists in the file at the path `path`::\n\n            if \'some/thing\' in file:\n                # do something\n        """"""\n        try:\n            self.GetKey(path)\n            return True\n        except DoesNotExist:\n            return False\n\n    def mkdir(self, path, title="""", recurse=False):\n        """"""\n        Make a new directory. If recurse is True, create parent directories\n        as required. Return the newly created TDirectory.\n        """"""\n        head, tail = os.path.split(os.path.normpath(path))\n        if tail == """":\n            raise ValueError(""invalid directory name: {0}"".format(path))\n        with preserve_current_directory():\n            dest = self\n            if recurse:\n                parent_dirs = head.split(os.path.sep)\n                for parent_dir in parent_dirs:\n                    try:\n                        newdest = dest.GetDirectory(parent_dir)\n                        dest = newdest\n                    except DoesNotExist:\n                        dest = dest.mkdir(parent_dir)\n            elif head != """":\n                dest = dest.GetDirectory(head)\n            if tail in dest:\n                raise ValueError(""{0} already exists"".format(path))\n            newdir = asrootpy(super(_DirectoryBase, dest).mkdir(tail, title))\n        return newdir\n\n    def rm(self, path, cycle=\';*\'):\n        """"""\n        Delete an object at `path` relative to this directory\n        """"""\n        rdir = self\n        with preserve_current_directory():\n            dirname, objname = os.path.split(os.path.normpath(path))\n            if dirname:\n                rdir = rdir.Get(dirname)\n            rdir.Delete(objname + cycle)\n\n    # TODO:\n    # def move(self, src, dest, newname=None):\n\n    def copytree(self, dest_dir, src=None, newname=None,\n                 exclude=None, overwrite=False):\n        """"""\n        Copy this directory or just one contained object into another\n        directory.\n\n        Parameters\n        ----------\n\n        dest_dir : string or Directory\n            The destination directory.\n\n        src : string, optional (default=None)\n            If ``src`` is None then this entire directory is copied recursively\n            otherwise if ``src`` is a string path to an object relative to this\n            directory, only that object will be copied. The copied object can\n            optionally be given a ``newname``.\n\n        newname : string, optional (default=None)\n            An optional new name for the copied object.\n\n        exclude : callable, optional (default=None)\n            ``exclude`` can optionally be a function which takes\n            ``(path, object_name)`` and if returns True excludes\n            objects from being copied if the entire directory is being copied\n            recursively.\n\n        overwrite : bool, optional (default=False)\n            If True, then overwrite existing objects with the same name.\n\n        """"""\n        def copy_object(obj, dest, name=None):\n            if name is None:\n                name = obj.GetName()\n            if not overwrite and name in dest:\n                raise ValueError(\n                    ""{0} already exists in {1} and `overwrite=False`"".format(\n                        name, dest._path))\n            dest.cd()\n            if isinstance(obj, ROOT.R.TTree):\n                new_obj = obj.CloneTree(-1, ""fast"")\n                new_obj.Write(name, ROOT.R.TObject.kOverwrite)\n            else:\n                obj.Write(name, ROOT.R.TObject.kOverwrite)\n\n        with preserve_current_directory():\n            if isinstance(src, string_types):\n                src = asrootpy(self.Get(src))\n            else:\n                src = self\n            if isinstance(dest_dir, string_types):\n                try:\n                    dest_dir = asrootpy(self.GetDirectory(dest_dir))\n                except DoesNotExist:\n                    dest_dir = self.mkdir(dest_dir)\n            if isinstance(src, ROOT.R.TDirectory):\n                # Copy a directory\n                cp_name = newname if newname is not None else src.GetName()\n                # See if the directory already exists\n                if cp_name not in dest_dir:\n                    # Destination directory doesn\'t exist, so make a new one\n                    new_dir = dest_dir.mkdir(cp_name)\n                else:\n                    new_dir = dest_dir.get(cp_name)\n                # Copy everything in the src directory to the destination\n                for (path, dirnames, objects) in src.walk(maxdepth=0):\n                    # Copy all the objects\n                    for object_name in objects:\n                        if exclude and exclude(path, object_name):\n                            continue\n                        thing = src.Get(object_name)\n                        copy_object(thing, new_dir)\n                    for dirname in dirnames:\n                        if exclude and exclude(path, dirname):\n                            continue\n                        rdir = src.GetDirectory(dirname)\n                        # Recursively copy objects in subdirectories\n                        rdir.copytree(\n                            new_dir,\n                            exclude=exclude, overwrite=overwrite)\n            else:\n                # Copy an object\n                copy_object(src, dest_dir, name=newname)\n\n    def walk(self,\n             top=None,\n             path=None,\n             depth=0,\n             maxdepth=-1,\n             class_ref=None,\n             class_pattern=None,\n             return_classname=False,\n             treat_dirs_as_objs=False):\n        """"""\n        Walk the directory structure and content in and below a directory.\n        For each directory in the directory tree rooted at ``top`` (including\n        ``top`` itself, but excluding \'.\' and \'..\'), yield a 3-tuple\n        ``dirpath, dirnames, filenames``.\n\n        Parameters\n        ----------\n\n        top : string, optional (default=None)\n            A path to a starting directory relative to this directory,\n            otherwise start at this directory.\n\n        path : string, optional (default=None)\n            A path prepended as a prefix on the ``dirpath``. This argument is\n            used internally as the recursion traverses down through\n            subdirectories.\n\n        depth : int, optional (default=0)\n            The current depth, used internally as the recursion traverses down\n            through subdirectories.\n\n        max_depth : int, optional (default=-1)\n            The maximum depth in the directory hierarchy to traverse. There is\n            no limit applied by default.\n\n        class_ref : class, optional (default=None)\n            If not None then only include objects that are instances of\n            ``class_ref``.\n\n        class_pattern : string, optional (default=None)\n            If not None then only include objects in ``filenames`` with class\n            names that match ``class_pattern``. ``class_pattern`` should be a\n            Unix shell-style wildcarded string.\n\n        return_classname : bool, optional (default=False)\n            If True, then each entry in ``filenames`` is a tuple of\n            the form ``(filename, classname)``.\n\n        treat_dirs_as_objs : bool, optional (default=False)\n            If True, ``filenames`` contains directories as well.\n\n        Returns\n        -------\n\n        dirpath, dirnames, filenames : iterator\n            An iterator over the 3-tuples ``dirpath, dirnames, filenames``.\n            ``dirpath`` is a string, the path to the directory. ``dirnames`` is\n            a list of the names of the subdirectories in ``dirpath``\n            (excluding \'.\' and \'..\'). ``filenames`` is a list of the names of\n            the non-directory files/objects in ``dirpath``.\n\n        Notes\n        -----\n\n        The names in the lists are just names, with no path components.\n        To get a full path (which begins with top) to a file or directory\n        in ``dirpath``, use ``os.path.join(dirpath, name)``.\n\n        """"""\n        dirnames, objectnames = [], []\n        tdirectory = self.GetDirectory(top) if top else self\n        for key in tdirectory.keys(latest=True):\n            name = key.GetName()\n            classname = key.GetClassName()\n            is_directory = classname.startswith(\'TDirectory\')\n            if is_directory:\n                dirnames.append(name)\n            if not is_directory or treat_dirs_as_objs:\n                if class_ref is not None:\n                    tclass = ROOT.TClass.GetClass(classname, True, True)\n                    if not tclass or not tclass.InheritsFrom(class_ref.Class()):\n                        continue\n                if class_pattern is not None:\n                    if not fnmatch(classname, class_pattern):\n                        continue\n                name = (name if not return_classname else (name, classname))\n                objectnames.append(name)\n        if path:\n            dirpath = os.path.join(path, tdirectory.GetName())\n        elif not isinstance(tdirectory, ROOT.R.TFile):\n            dirpath = tdirectory.GetName()\n        else:\n            dirpath = \'\'\n        yield dirpath, dirnames, objectnames\n        if depth == maxdepth:\n            return\n        for dirname in dirnames:\n            rdir = tdirectory.GetDirectory(dirname)\n            for x in rdir.walk(\n                    class_ref=class_ref,\n                    class_pattern=class_pattern,\n                    depth=depth + 1,\n                    maxdepth=maxdepth,\n                    path=dirpath,\n                    return_classname=return_classname,\n                    treat_dirs_as_objs=treat_dirs_as_objs):\n                yield x\n\n\n@snake_case_methods\nclass Directory(_DirectoryBase, QROOT.TDirectoryFile):\n    """"""\n    A subclass of ROOT\'s TDirectoryFile [1]\n\n    References\n    ----------\n\n    .. [1] http://root.cern.ch/root/html/TDirectoryFile.html\n\n    """"""\n    _ROOT = QROOT.TDirectoryFile\n\n    def __init__(self, name, title=None, classname=\'\', parent=None):\n        if title is None:\n            title = name\n        # grab previous directory before creating self\n        self._prev_dir = ROOT.gDirectory\n        self._parent = parent or self._prev_dir\n        super(Directory, self).__init__(name, title, classname, parent or 0)\n        self._post_init()\n\n    def _post_init(self):\n        self._path = self.GetName()\n        # need to set _prev_dir here again if using rootpy.ROOT.TDirectory\n        self._prev_dir = getattr(self, \'_prev_dir\', None)\n        self._parent = getattr(self, \'_parent\', self._prev_dir)\n\n\nclass _FileBase(_DirectoryBase):\n\n    def __init__(self, name, *args, **kwargs):\n        # trigger finalSetup\n        ROOT.R.kTRUE\n        # grab previous directory before creating self\n        self._prev_dir = ROOT.gDirectory\n        super(_FileBase, self).__init__(name, *args, **kwargs)\n        self._post_init()\n\n    def _post_init(self):\n        self._path = self.GetName()\n        # need to set _prev_dir here again if using rootpy.ROOT.TFile\n        self._prev_dir = getattr(self, \'_prev_dir\', None)\n        self._parent = self\n\n    def _populate_cache(self):\n        """"""\n        Walk through the whole file and populate the cache\n        all objects below the current path are added, i.e.\n        for the contents with ina, inb and inab TH1F histograms::\n\n           /a/ina\n           /b/inb\n           /a/b/inab\n\n        the cache is (omitting the directories)::\n\n            cache[""""][""obj""] = [(""a"", (""ina"", ""TH1F"")),\n                                (""b"", (""inb"", ""TH1F"")),\n                                (""a/b"", (""inab"", ""TH1F""))]\n\n            ...\n\n            cache[""""][""a""][""b""][""obj""] = [(""a/b"", (""inab"", ""TH1F""))]\n\n        """"""\n        self.cache = autovivitree()\n\n        for path, dirs, objects in self.walk(return_classname=True,\n                                             treat_dirs_as_objs=True):\n            b = self.cache\n            for d in [\'\']+path.split(\'/\'):\n                b = b[d]\n                obj = [(path, o) for o in objects]\n                if \'obj\' in b:\n                    b[\'obj\'] += obj\n                else:\n                    b[\'obj\'] = obj\n\n    def find(self,\n             regexp, negate_regexp=False,\n             class_pattern=None,\n             find_fnc=re.search,\n             refresh_cache=False):\n        """"""\n        yield the full path of the matching regular expression and the\n        match itself\n        """"""\n        if refresh_cache or not hasattr(self, \'cache\'):\n            self._populate_cache()\n\n        b = self.cache\n        split_regexp = regexp.split(\'/\')\n\n        # traverse as deep as possible in the cache\n        # special case if the first character is not the root, i.e. not """"\n        if split_regexp[0] == \'\':\n            for d in split_regexp:\n                if d in b:\n                    b = b[d]\n                else:\n                    break\n        else:\n            b = b[\'\']\n\n        # perform the search\n        for path, (obj, classname) in b[\'obj\']:\n            if class_pattern:\n                if not fnmatch(classname, class_pattern):\n                    continue\n            joined_path = os.path.join(*[\'/\', path, obj])\n            result = find_fnc(regexp, joined_path)\n            if (result is not None) ^ negate_regexp:\n                yield joined_path, result\n\n\n@snake_case_methods\nclass File(_FileBase, QROOT.TFile):\n    """"""\n    A subclass of ROOT\'s TFile [1]\n\n    Examples\n    --------\n\n    >>> from rootpy.io import File\n    >>> from rootpy.testdata import get_filepath\n    >>> f = File(get_filepath(), \'read\')\n    >>> list(f)\n    [Directory(\'means\'), Directory(\'scales\'), Directory(\'gaps\'), Directory(\'efficiencies\'), Directory(\'dimensions\'), Directory(\'graphs\')]\n    >>> f.means\n    Directory(\'rootpy/testdata/test_file.root/means\')\n\n    References\n    ----------\n\n    .. [1] http://root.cern.ch/root/html/TFile.html\n\n    """"""\n    _ROOT = QROOT.TFile\n    # Override .Open\n    open = staticmethod(root_open)\n    Open = staticmethod(root_open)\n\n\n@snake_case_methods\nclass MemFile(_FileBase, QROOT.TMemFile):\n    """"""\n    A subclass of ROOT\'s TMemFile [1]\n\n    Examples\n    --------\n\n    >>> from rootpy.io import MemFile\n    >>> f = MemFile()\n\n    References\n    ----------\n\n    .. [1] http://root.cern.ch/root/html/TMemFile.html\n\n    """"""\n    _ROOT = QROOT.TMemFile\n\n    def __init__(self, name=None, mode=\'recreate\'):\n        if name is None:\n            name = \'{0}_{1}\'.format(self.__class__.__name__, uuid())\n        super(MemFile, self).__init__(name, mode)\n\n\n@snake_case_methods\nclass TemporaryFile(File):\n    """"""\n    A temporary ROOT file that is automatically deleted when closed.\n    Python\'s :func:`tempfile.mkstemp` [1] is used to obtain a temporary file\n    in the most secure manner possible.\n\n    Keyword arguments are passed directly to :func:`tempfile.mkstemp` [1]\n\n    References\n    ----------\n\n    .. [1] http://docs.python.org/2/library/tempfile.html#tempfile.mkstemp\n\n    """"""\n    def __init__(self, suffix=\'.root\', **kwargs):\n        self.__fd, self.__tmp_path = tempfile.mkstemp(suffix=suffix, **kwargs)\n        super(TemporaryFile, self).__init__(self.__tmp_path, \'recreate\')\n\n    def Close(self):\n        """"""\n        The physical file is automatically deleted after being closed.\n        """"""\n        super(TemporaryFile, self).Close()\n        os.close(self.__fd)\n        os.remove(self.__tmp_path)\n'"
rootpy/io/pickler.py,0,"b'# Original author: Scott Snyder scott.snyder(a)cern.ch, 2004.\n""""""Pickle python data into a ROOT file, preserving references to ROOT objects.\n\nThis module allows pickling python objects into a ROOT file. The python\nobjects may contain references to named ROOT objects. If one has set up a\nstructure of python objects to hold ROOT histograms, this provides a convenient\nway of saving and restoring your histograms. The pickled python data are\nstored in an additional string object in the ROOT file; any ROOT objects are\nstored as usual. (Thus, ROOT files written by the pickler can be read just\nlike any other ROOT file if you don\'t care about the python data.)\n\nHere\'s an example of writing a pickle::\n\n   from rootpy.plotting import Hist\n   from rootpy.io.pickler import dump\n   hlist = []\n   for i in range(10):\n       hlist.append(Hist(10, 0, 10))\n   dump(hlist, \'test.root\')\n\nThis writes a list of histograms to test.root. The histograms may be read back\nlike this::\n\n   from rootpy.io.pickler import load\n   hlist = load(\'test.root\')\n\nThe following additional notes apply:\n\n* Pickling may not always work correctly for the case of python objects\n  deriving from ROOT objects. It will probably also not work for the case of\n  ROOT objects which do not derive from TObject.\n\n* When the pickled data are being read, if a class doesn\'t exist,\n  a dummy class with no methods will be used instead. This is different\n  from the standard pickle behavior (where it would be an error), but it\n  simplifies usage in the common case where the class is being used to hold\n  histograms, and its methods are entirely concerned with filling the\n  histograms.\n\n* When restoring a reference to a ROOT object, the default behavior\n  is to not read the ROOT object itself, but instead to create a proxy. The\n  ROOT object will then be read the first time the proxy is accessed. This can\n  help significantly with time and memory usage if you\'re only accessing a\n  small fraction of the ROOT objects, but it does mean that you need to keep\n  the ROOT file open. Pass use_proxy=False to disable this behavior.\n\n""""""\nfrom __future__ import absolute_import\n\nimport sys\nif sys.version_info[0] < 3:\n    from cStringIO import StringIO\nelse:\n    from io import StringIO\n\n# need subclassing ability in 2.x\nimport pickle\n\nimport ROOT\n\nfrom . import log; log = log[__name__]\nfrom . import root_open\nfrom ..context import preserve_current_directory\nfrom ..extern.six import string_types\n\n\n__all__ = [\n    \'dump\',\n    \'load\',\n    \'compat_hooks\',\n]\n\n\n_compat_hooks = None\nxdict = {}\nxserial = 0\n\n""""""\nArgh!  We can\'t store NULs in TObjStrings.\nBut pickle protocols > 0 are binary protocols, and will get corrupted\nif we truncate at a NUL.\nSo, when we save the pickle data, make the mappings:\n\n   0x00 -> 0xff 0x01\n   0xff -> 0xff 0xfe\n\n""""""\n\n\ndef _protect(s):\n    return s.replace(b\'\\377\', b\'\\377\\376\').replace(b\'\\000\', b\'\\377\\001\')\n\n\ndef _restore(s):\n    return s.replace(b\'\\377\\001\', b\'\\000\').replace(b\'\\377\\376\', b\'\\377\')\n\n\nclass IO_Wrapper:\n    def __init__(self):\n        return self.reopen()\n\n    def write(self, s):\n        return self.__s.write(_protect(s).decode(\'utf-8\'))\n\n    def read(self, i):\n        return self.__s.read(i).encode(\'utf-8\')\n\n    def readline(self):\n        return self.__s.readline().encode(\'utf-8\')\n\n    def getvalue(self):\n        return self.__s.getvalue()\n\n    def setvalue(self, s):\n        self.__s = StringIO(_restore(s.encode(\'utf-8\')).decode(\'utf-8\'))\n        return\n\n    def reopen(self):\n        self.__s = StringIO()\n        return\n\n\nclass ROOT_Proxy:\n    def __init__(self, f, pid):\n        self.__f = f\n        self.__pid = pid\n        self.__o = None\n\n    def __getattr__(self, a):\n        if self.__o is None:\n            log.debug(""unpickler proxy reading {0}"".format(self.__pid))\n            self.__o = self.__f.Get(self.__pid)\n            self.__o.__class__.__module__ = \'ROOT\'\n        return getattr(self.__o, a)\n\n    def __obj(self):\n        if self.__o is None:\n            log.debug(""unpickler proxy reading {0}"".format(self.__pid))\n            self.__o = self.__f.Get(self.__pid)\n            self.__o.__class__.__module__ = \'ROOT\'\n        return self.__o\n\n\nclass Pickler(pickle.Pickler):\n    def __init__(self, file, proto=0):\n        """"""Create a root pickler.\n        `file` should be a ROOT TFile. `proto` is the python pickle protocol\n        version to use.  The python part will be pickled to a ROOT\n        TObjString called _pickle; it will contain references to the\n        ROOT objects.\n        """"""\n        self.__file = file\n        self.__keys = file.GetListOfKeys()\n        self.__io = IO_Wrapper()\n        self.__pmap = {}\n        if sys.version_info[0] < 3:\n            # 2.X old-style classobj\n            pickle.Pickler.__init__(self, self.__io, proto)\n        else:\n            super(Pickler, self).__init__(self.__io, proto)\n\n    def dump(self, obj, key=None):\n        """"""Write a pickled representation of obj to the open TFile.""""""\n        if key is None:\n            key = \'_pickle\'\n        with preserve_current_directory():\n            self.__file.cd()\n            if sys.version_info[0] < 3:\n                pickle.Pickler.dump(self, obj)\n            else:\n                super(Pickler, self).dump(obj)\n            s = ROOT.TObjString(self.__io.getvalue())\n            self.__io.reopen()\n            s.Write(key)\n            self.__file.GetFile().Flush()\n            self.__pmap.clear()\n\n    def clear_memo(self):\n        """"""Clears the pickler\'s internal memo.""""""\n        self.__pickle.memo.clear()\n\n    def persistent_id(self, obj):\n        if hasattr(obj, \'_ROOT_Proxy__obj\'):\n            obj = obj._ROOT_Proxy__obj()\n        if isinstance(obj, ROOT.TObject):\n            """"""\n            Write the object, and return the resulting NAME;CYCLE.\n            We used to do this::\n\n               o.Write()\n               k = self.__file.GetKey(o.GetName())\n               pid = ""{0};{1:d}"".format(k.GetName(), k.GetCycle())\n\n            It turns out, though, that destroying the python objects\n            referencing the TKeys is quite expensive (O(logN) where N is the\n            total number of pyroot objects?).  Although we want to allow for\n            the case of saving multiple objects with the same name, the most\n            common case is that the name has not already been written to the\n            file.  So we optimize for that case, doing the key lookup before we\n            write the object, not after.  (Note further: GetKey() is very slow\n            if the key does not actually exist, as it does a linear search of\n            the key list.  We use FindObject instead for the initial\n            lookup, which is a hashed lookup, but it is not guaranteed to\n            find the highest cycle.  So if we do find an existing key, we\n            need to look up again using GetKey.\n            """"""\n            nm = obj.GetName()\n            key = self.__keys.FindObject(nm)\n            obj.Write()\n            if key:\n                key = self.__file.GetKey(nm)\n                pid = \'{0};{1:d}\'.format(nm, key.GetCycle())\n            else:\n                pid = nm + \';1\'\n            return pid\n\n\nclass Unpickler(pickle.Unpickler):\n    def __init__(self, root_file, use_proxy=True, use_hash=False):\n        """"""Create a ROOT unpickler.\n        `file` should be a ROOT TFile.\n        """"""\n        global xserial\n        xserial += 1\n        self.__use_proxy = use_proxy\n        self.__file = root_file\n        self.__io = IO_Wrapper()\n        self.__n = 0\n        self.__serial = \'{0:d}-\'.format(xserial).encode(\'utf-8\')\n        xdict[self.__serial] = root_file\n        if sys.version_info[0] < 3:\n            pickle.Unpickler.__init__(self, self.__io)\n        else:\n            super(Unpickler, self).__init__(self.__io)\n\n        if use_hash:\n            htab = {}\n            ctab = {}\n            for k in root_file.GetListOfKeys():\n                nm = k.GetName()\n                cy = k.GetCycle()\n                htab[(nm, cy)] = k\n                if cy > ctab.get(nm, 0):\n                    ctab[nm] = cy\n                    htab[(nm, 9999)] = k\n            root_file._htab = htab\n            oget = root_file.Get\n\n            def xget(nm0):\n                nm = nm0\n                ipos = nm.find(\';\')\n                if ipos >= 0:\n                    cy = nm[ipos+1]\n                    if cy == \'*\':\n                        cy = 10000\n                    else:\n                        cy = int(cy)\n                    nm = nm[:ipos - 1]\n                else:\n                    cy = 9999\n                ret = htab.get((nm, cy), None)\n                if not ret:\n                    log.warning(\n                        ""did\'t find {0} {1} {2}"".format(nm, cy, len(htab)))\n                    return oget(nm0)\n                #ctx = ROOT.TDirectory.TContext(file)\n                ret = ret.ReadObj()\n                #del ctx\n                return ret\n            root_file.Get = xget\n\n    def load(self, key=None):\n        """"""Read a pickled object representation from the open file.""""""\n        if key is None:\n            key = \'_pickle\'\n        obj = None\n        if _compat_hooks:\n            save = _compat_hooks[0]()\n        try:\n            self.__n += 1\n            s = self.__file.Get(key + \';{0:d}\'.format(self.__n))\n            self.__io.setvalue(s.GetName())\n            if sys.version_info[0] < 3:\n                obj = pickle.Unpickler.load(self)\n            else:\n                obj = super(Unpickler, self).load()\n            self.__io.reopen()\n        finally:\n            if _compat_hooks:\n                save = _compat_hooks[1](save)\n        return obj\n\n    def persistent_load(self, pid):\n        if sys.version_info[0] >= 3:\n            pid = pid.decode(\'utf-8\')\n        log.debug(""unpickler reading {0}"".format(pid))\n        if self.__use_proxy:\n            obj = ROOT_Proxy(self.__file, pid)\n        else:\n            obj = self.__file.Get(pid)\n        xdict[self.__serial + pid.encode(\'utf-8\')] = obj\n        return obj\n\n    def find_class(self, module, name):\n        try:\n            try:\n                __import__(module)\n                mod = sys.modules[module]\n            except ImportError:\n                log.info(""Making dummy module {0}"".format(module))\n\n                class DummyModule:\n                    pass\n\n                mod = DummyModule()\n                sys.modules[module] = mod\n            klass = getattr(mod, name)\n            return klass\n        except AttributeError:\n            log.info(""Making dummy class {0}.{1}"".format(module, name))\n            mod = sys.modules[module]\n\n            class Dummy(object):\n                pass\n\n            setattr(mod, name, Dummy)\n            return Dummy\n\n    # Python 2.x\n    find_global = find_class\n\n\ndef compat_hooks(hooks):\n    """"""Set compatibility hooks.\n    If this is set, then hooks[0] is called before loading, and hooks[1] is\n    called after loading.  hooks[1] is called with the return value of hooks[0]\n    as an argument.  This is useful for backwards compatibility in some\n    situations.\n    """"""\n    global _compat_hooks\n    _compat_hooks = hooks\n\n\ndef dump(obj, root_file, proto=0, key=None):\n    """"""Dump an object into a ROOT TFile.\n\n    `root_file` may be an open ROOT file or directory, or a string path to an\n    existing ROOT file.\n    """"""\n    if isinstance(root_file, string_types):\n        root_file = root_open(root_file, \'recreate\')\n        own_file = True\n    else:\n        own_file = False\n    ret = Pickler(root_file, proto).dump(obj, key)\n    if own_file:\n        root_file.Close()\n    return ret\n\n\ndef load(root_file, use_proxy=True, key=None):\n    """"""Load an object from a ROOT TFile.\n\n    `root_file` may be an open ROOT file or directory, or a string path to an\n    existing ROOT file.\n    """"""\n    if isinstance(root_file, string_types):\n        root_file = root_open(root_file)\n        own_file = True\n    else:\n        own_file = False\n    obj = Unpickler(root_file, use_proxy).load(key)\n    if own_file:\n        root_file.Close()\n    return obj\n'"
rootpy/logger/__init__.py,0,"b'""""""\n:py:mod:`rootpy` overrides the default logging class, inserting a check that\nthere exists a default logging handler. If there is not, it adds one.\n\nIn additon, this can be used to intercept ROOT\'s log messages and redirect them\nthrough python\'s logging subsystem\n\nExample use:\n\n.. sourcecode:: python\n\n    # Disable colored logging (not needed if writing into a file,\n    # this is automatic).\n    # Must be done before :py:mod:`rootpy` logs any messages.\n    import logging; logging.basicConfig(level=logging.DEBUG)\n\n    from rootpy import log; log = log[""/myapp""]\n    log.debug(""Hello"") # Results in ""DEBUG:myapp] Hello""\n\n    # Suppress all myapp debug and info messages\n    log.setLevel(log.WARNING)\n    log.debug(""Hello"") # No effect\n\n    mymod = log[""mymod""]\n    mymod.warning(""Hello"") # Results in ""WARNING:myapp.mymod] Hello""\n\n    # Suppress all rootpy debug and info messages\n    log[""/rootpy""].setLevel(log.WARNING)\n\n    # Suppress messages coming from TCanvas like\n    # INFO:ROOT.TCanvas.Print] png file /path/to/file.png has been created\n    log[""/ROOT.TCanvas.Print""].setLevel(log.WARNING)\n\n    # Suppress warning messages coming the ``TClass`` constructor:\n    log[""/ROOT.TClass.TClass""].setLevel(log.ERROR)\n\n    # Precisely remove messages containing the text ""no dictionary for class""\n    # (doesn\'t work when attached to parent logger)\n    import logging\n    class NoDictMessagesFilter(logging.Filter):\n        def filter(self, record):\n            return ""no dictionary for class"" not in record.msg\n    log[""/ROOT.TClass.TClass""].addFilter(NoDictMessagesFilter())\n\n    # Turn ROOT errors into exceptions\n    from rootpy.logger.magic import DANGER\n    DANGER.enable = True\n\n    import ROOT\n    ROOT.Error(""test"", ""Test fatal"")\n    # Result:\n    # ERROR:ROOT.test] Test fatal\n    # Traceback (most recent call last):\n    #   File ""test.py"", line 36, in <module>\n    #     ROOT.Fatal(""test"", ""Test fatal"")\n    #   File ""test.py"", line 36, in <module>\n    #     ROOT.Fatal(""test"", ""Test fatal"")\n    #   File ""rootpy/logger/roothandler.py"", line 40, in python_logging_error_handler\n    #     raise ROOTError(level, location, msg)\n    # rootpy.ROOTError: level=6000, loc=\'test\', msg=\'Test fatal\'\n\n    # Primitive function tracing:\n    @log.trace()\n    def salut():\n        return\n\n    @log.trace()\n    def hello(what):\n        salut()\n        return ""42""\n\n    hello(""world"")\n    # Result:\n    #   DEBUG:myapp.trace.hello] > (\'world\',) {}\n    #   DEBUG:myapp.trace.salut]  > () {}\n    #   DEBUG:myapp.trace.salut]  < return None [0.00 sec]\n    #   DEBUG:myapp.trace.hello] < return 42 [0.00 sec]\n\n\n""""""\nfrom __future__ import absolute_import\n\nimport logging\nimport os\nimport re\nimport sys\nimport threading\nfrom functools import wraps\nfrom time import time\n\nfrom .utils import check_tty\nfrom .extended_logger import ExtendedLogger\n\nlogging.setLoggerClass(ExtendedLogger)\nlog = logging.getLogger(""rootpy"")\nif not os.environ.get(""DEBUG"", False):\n    log.setLevel(log.INFO)\n\nfrom .formatter import CustomFormatter, CustomColoredFormatter\n\ndef check_tty_handler(handler):\n    if not hasattr(handler, ""stream""):\n        return False\n    return check_tty(handler.stream)\n\nlog_root = logging.getLogger()\nif not log_root.handlers:\n    # Add a handler to the top-level logger if it doesn\'t already have one\n    handler = logging.StreamHandler()\n    if check_tty_handler(handler):\n        handler.setFormatter(CustomColoredFormatter())\n    else:\n        handler.setFormatter(CustomFormatter())\n    log_root.addHandler(handler)\n    # Make the top-level logger as verbose as possible.\n    # Log messages that make it to the screen are controlled by the handler\n    log_root.setLevel(logging.DEBUG)\n    l = logging.getLogger(""rootpy.logger"")\n    l.debug(""Adding rootpy\'s default logging handler to the root logger"")\n\n\nfrom .magic import set_error_handler\nfrom .roothandler import python_logging_error_handler\n\n__all__ = [\n    \'log_trace\',\n    \'set_error_handler\',\n    \'python_logging_error_handler\',\n    \'LogFilter\',\n    \'LiteralFilter\',\n]\n\n\nclass TraceDepth(threading.local):\n    value = -1\n\ntrace_depth = TraceDepth()\n\n\ndef log_trace(logger, level=logging.DEBUG, show_enter=True, show_exit=True):\n    """"""\n    log a statement on function entry and exit\n    """"""\n    def wrap(function):\n        l = logger.getChild(function.__name__).log\n        @wraps(function)\n        def thunk(*args, **kwargs):\n            global trace_depth\n            trace_depth.value += 1\n            try:\n                start = time()\n                if show_enter:\n                    l(level, ""{0}> {1} {2}"".format("" ""*trace_depth.value,\n                                                   args, kwargs))\n                try:\n                    result = function(*args, **kwargs)\n                except:\n                    _, result, _ = sys.exc_info()\n                    raise\n                finally:\n                    if show_exit:\n                        l(level, ""{0}< return {1} [{2:.2f} sec]"".format(\n                            "" ""*trace_depth.value, result, time() - start))\n            finally:\n                trace_depth.value -= 1\n            return result\n        return thunk\n    return wrap\n\n\nclass LogFilter(logging.Filter):\n    def __init__(self, logger, message_regex):\n        logging.Filter.__init__(self)\n        self.logger = logger\n        self.message_regex = re.compile(message_regex)\n\n    def __enter__(self):\n        self.logger.addFilter(self)\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.logger.removeFilter(self)\n\n    def filter(self, record):\n        return not self.message_regex.match(record.getMessage())\n\n\nclass LiteralFilter(logging.Filter):\n    def __init__(self, literals):\n        logging.Filter.__init__(self)\n        self.literals = literals\n\n    def filter(self, record):\n        return record.getMessage() not in self.literals\n\n\n# filter superfluous ROOT warnings\nfor histtype in \'CSIFD\':\n    for dimen in \'123\':\n        log[""/ROOT.TH{0}{1}.Add"".format(dimen, histtype)].addFilter(\n            LiteralFilter([\n                ""Attempt to add histograms with different axis limits"",]))\n        log[""/ROOT.TH{0}{1}.Divide"".format(dimen, histtype)].addFilter(\n            LiteralFilter([\n                ""Attempt to divide histograms with different axis limits"",]))\n        log[""/ROOT.TH{0}{1}.Multiply"".format(dimen, histtype)].addFilter(\n            LiteralFilter([\n                ""Attempt to multiply histograms with different axis limits"",]))\n'"
rootpy/logger/extended_logger.py,0,"b'from __future__ import absolute_import\n\nimport logging\nimport re\nimport sys\nimport traceback\nimport types\nimport threading\n\n__all__ = [\n    \'log_stack\',\n    \'ExtendedLogger\',\n    \'RootLoggerWrapper\',\n]\n\nLoggerClass = logging.getLoggerClass()\n\n\nclass ShowingStack(threading.local):\n    inside = False\n\nshowing_stack = ShowingStack()\n\n\ndef log_stack(logger, level=logging.INFO, limit=None, frame=None):\n    """"""\n    Display the current stack on ``logger``.\n\n    This function is designed to be used during emission of log messages, so it\n    won\'t call itself.\n    """"""\n    if showing_stack.inside:\n        return\n    showing_stack.inside = True\n    try:\n        if frame is None:\n            frame = sys._getframe(1)\n        stack = """".join(traceback.format_stack(frame, limit))\n        for line in (l[2:] for l in stack.split(""\\n"") if l.strip()):\n            logger.log(level, line)\n    finally:\n        showing_stack.inside = False\n\n\nclass ExtendedLogger(LoggerClass):\n    """"""\n    A logger class which provides a few niceties, including automatically\n    enabling logging if no handlers are available.\n    """"""\n    def __init__(self, name, *args, **kwargs):\n        LoggerClass.__init__(self, name, *args, **kwargs)\n        self._init(self)\n\n    @staticmethod\n    def _init(self):\n        if hasattr(self, ""shown_stack_frames""):\n            # Don\'t double _init the root logger\n            return\n        if sys.version_info >= (3, 4):\n            self.__dict__.update(logging._levelToName)\n            self.__dict__.update(logging._nameToLevel)\n        else:\n            self.__dict__.update(logging._levelNames)\n        self.show_stack_regexes = []\n        self.shown_stack_frames = set()\n\n    def showdeletion(self, *objects):\n        """"""\n        Record a stack trace at the point when an ROOT TObject is deleted\n        """"""\n        from ..memory import showdeletion as S\n        for o in objects:\n            S.monitor_object_cleanup(o)\n\n    def ignore(self, message_regex):\n        """"""\n        Gives a context manager which filters out messages exactly matching\n        ``message_regex`` on the current filter.\n\n        Example:\n\n        .. sourcecode:: python\n\n            with log[""/ROOT""].ignore(""^this message is ignored$""):\n                ROOT.Warning(""location"", ""this message is ignored"")\n\n        """"""\n        from . import LogFilter\n        return LogFilter(self, message_regex)\n\n    def trace(self, level=logging.DEBUG, show_enter=True, show_exit=True):\n        """"""\n        Functions decorated with this function show function entry and exit with\n        values, defaults to debug log level.\n\n        :param level: log severity to use for function tracing\n        :param show_enter: log function entry\n        :param show_enter: log function exit\n\n        Example use:\n\n        .. sourcecode:: python\n\n            log = rootpy.log[""/myapp""]\n            @log.trace()\n            def salut():\n                return\n\n            @log.trace()\n            def hello(what):\n                salut()\n                return ""42""\n\n            hello(""world"")\n            # Result:\n            #   DEBUG:myapp.trace.hello] > (\'world\',) {}\n            #   DEBUG:myapp.trace.salut]  > () {}\n            #   DEBUG:myapp.trace.salut]  < return None [0.00 sec]\n            #   DEBUG:myapp.trace.hello] < return 42 [0.00 sec]\n\n        Output:\n\n        .. sourcecode:: none\n\n        """"""\n        from . import log_trace\n        return log_trace(self, level, show_enter, show_exit)\n\n    def has_handlers(self):\n        logger = self\n        while logger:\n            if logger.handlers:\n                return True\n            if not logger.propagate:\n                break\n            logger = logger.parent\n        return False\n\n    def show_stack(self, message_regex=""^.*$"", min_level=logging.DEBUG,\n        limit=4096, once=True):\n        """"""\n        Enable showing the origin of log messages by dumping a stack trace into\n        the ``stack`` logger at the :const:``logging.INFO`` severity.\n\n        :param message_regex: is a full-line regex which the message must\n            satisfy in order to trigger stack dump\n        :param min_level: the minimum severity the message must have in order to\n            trigger the stack dump\n        :param limit: Maximum stack depth to show\n        :param once: Only show the stack once per unique ``(logger, origin line\n            of code)``\n        """"""\n        value = re.compile(message_regex), limit, once, min_level\n        self.show_stack_regexes.append(value)\n\n    @staticmethod\n    def frame_unique(f):\n        """"""\n        A tuple representing a value which is unique to a given frame\'s line of\n        execution\n        """"""\n        return f.f_code.co_filename, f.f_code.co_name, f.f_lineno\n\n    def show_stack_depth(self, record, frame):\n        """"""\n        Compute the maximum stack depth to show requested by any hooks,\n        returning -1 if there are none matching, or if we\'ve already emitted\n        one for the line of code referred to.\n        """"""\n        logger = self\n\n        depths = [-1]\n        msg = record.getMessage()\n\n        # For each logger in the hierarchy\n        while logger:\n            to_match = getattr(logger, ""show_stack_regexes"", ())\n            for regex, depth, once, min_level in to_match:\n                if record.levelno < min_level:\n                    continue\n                if not regex.match(record.msg):\n                    continue\n                # Only for a given regex, line number and logger\n                unique = regex, self.frame_unique(frame), record.name\n                if once:\n                    if unique in logger.shown_stack_frames:\n                        # We\'ve shown this one already.\n                        continue\n                    # Prevent this stack frame from being shown again\n                    logger.shown_stack_frames.add(unique)\n                depths.append(depth)\n            logger = logger.parent\n        return max(depths)\n\n    def maybe_show_stack(self, record):\n        frame = sys._getframe(5)\n        if frame.f_code.co_name == ""python_logging_error_handler"":\n            # Special case, don\'t show python message handler in backtrace\n            frame = frame.f_back\n        depth = self.show_stack_depth(record, frame)\n        if depth > 0:\n            log_stack(self[""/stack""], record.levelno, limit=depth, frame=frame)\n\n    def callHandlers(self, record):\n        result = LoggerClass.callHandlers(self, record)\n        self.maybe_show_stack(record)\n        return result\n\n    def getLogger(self, name):\n        if not name:\n            # The root logger is special, and always has the same class.\n            # Therefore, we wrap it here to give it nice methods.\n            return RootLoggerWrapper(logging.getLogger())\n        return logging.getLogger(name)\n\n    def __getitem__(self, suffix):\n        """"""\n        Provides ``log[""child""]`` syntactic sugar to obtain a child logger, or\n        ``log[""/absolute""]`` to get a logger with respect to the root logger.\n        """"""\n        if suffix.startswith(""/""):\n            return self.getLogger(suffix[1:])\n        return self.getChild(suffix)\n\n    def getChild(self, suffix):\n        """"""\n        Taken from CPython 2.7, modified to remove duplicate prefix and suffixes\n        """"""\n        if suffix is None:\n            return self\n        if self.root is not self:\n            if suffix.startswith(self.name + "".""):\n                # Remove duplicate prefix\n                suffix = suffix[len(self.name + "".""):]\n                suf_parts = suffix.split(""."")\n                if len(suf_parts) > 1 and suf_parts[-1] == suf_parts[-2]:\n                    # If we have a submodule\'s name equal to the parent\'s name,\n                    # omit it.\n                    suffix = ""."".join(suf_parts[:-1])\n            suffix = \'.\'.join((self.name, suffix))\n        return self.manager.getLogger(suffix)\n\n    def __repr__(self):\n        return ""<ExtendedLogger {0} at 0x{1:x}>"".format(self.name, id(self))\n\n\nclass RootLoggerWrapper(ExtendedLogger):\n    """"""\n    Wraps python\'s ``logging.RootLogger`` with our nicer methods.\n\n    RootLoggerWrapper is obtained through ``log[""/""]``\n    """"""\n    def __init__(self, root_logger):\n        self.__dict__[""__root_logger""] = root_logger\n        self._init(root_logger)\n\n    def __getattr__(self, key):\n        return getattr(self.__dict__[""__root_logger""], key)\n\n    def __setattr__(self, key, value):\n        return setattr(self.__dict__[""__root_logger""], key, value)\n\n    def __repr__(self):\n        return ""<RootLoggerWrapper {0} at 0x{1:x}>"".format(self.name, id(self))\n'"
rootpy/logger/formatter.py,0,"b'""""""\nProvides a ``CustomFormatter`` and ``CustomColoredFormatter`` which are enable\nto insert ANSI color codes.\n""""""\nfrom __future__ import absolute_import\n\nimport logging\n\n__all__ = [\n    \'CustomFormatter\',\n    \'CustomColoredFormatter\',\n]\n\n# The background is set with 40 plus the number of the color, and the foreground with 30\nRED, YELLOW, BLUE, WHITE = 1, 3, 4, 7\n\n# These are the sequences need to get colored ouput\nRESET_SEQ = ""\\033[0m""\nCOLOR_SEQ = ""\\033[1;%dm""\nBOLD_SEQ = ""\\033[1m""\nFORMAT = ""{color}{levelname}$RESET:$BOLD{name}$RESET] {message}""\n\ndef insert_seqs(message):\n    return message.replace(""$RESET"", RESET_SEQ).replace(""$BOLD"", BOLD_SEQ)\n\ndef remove_seqs(message):\n    return message.replace(""$RESET"", """").replace(""$BOLD"", """")\n\nCOLORS = {\n    \'DEBUG\'      : BLUE,\n    \'INFO\'       : WHITE,\n    \'WARNING\'    : YELLOW,\n    \'ERROR\'      : RED,\n    \'CRITICAL\'   : RED,\n}\n\n\nclass CustomFormatter(logging.Formatter):\n    def __init__(self, fmt=remove_seqs(FORMAT), datefmt=None):\n        logging.Formatter.__init__(self, fmt, datefmt)\n\n    def format(self, record):\n        if not hasattr(record, ""message""):\n            record.message = record.getMessage()\n        record.asctime = self.formatTime(record, self.datefmt)\n        return self._fmt.format(color="""", **record.__dict__)\n\n\nclass CustomColoredFormatter(CustomFormatter):\n    def __init__(self, fmt=insert_seqs(FORMAT), datefmt=None, use_color=True):\n        CustomFormatter.__init__(self, fmt, datefmt)\n        self.use_color = use_color\n\n    def format(self, record):\n        levelname = record.levelname\n        if self.use_color and levelname in COLORS:\n            record.color = COLOR_SEQ % (30 + COLORS[levelname])\n        else:\n            record.color = """"\n        if not hasattr(record, ""message""):\n            record.message = record.getMessage()\n        record.asctime = self.formatTime(record, self.datefmt)\n        return self._fmt.format(**record.__dict__)\n'"
rootpy/logger/magic.py,0,"b'""""""\nHere be dragons.\n\nThis module contains hackery to bend the CPython interpreter to our will.\n\nIt\'s necessary because it\'s not possible to throw an exception from within a\nctypes callback. Instead, the exception is thrown from a line tracer which we\nforcibly insert into the appropriate frame. Then we make that frame\'s next\nopcode a ``JUMP_ABSOLUTE`` to the last line of code. Yes.\n\nThis is a bad idea and should never be used anywhere important where\nreliability is a concern. Also, if you like your sanity. This thing *will*\nbreak backtraces when you least expect it, leading to you looking at the wrong\nthing.\n\nWhat lies within is the product of a sick mind and should never be exposed to\nhumanity.\n""""""\nfrom __future__ import absolute_import\n\nimport ctypes\nimport ctypes.util\nimport dis\nimport logging\nimport opcode\nimport os\nimport struct\nimport sys\nfrom ctypes import POINTER, Structure, py_object, c_byte, c_int, c_voidp\nfrom traceback import print_stack\n\nfrom . import log; log = log[__name__]\nfrom ..extern.six.moves import range\n\n\n__all__ = [\n    \'get_dll\',\n    \'get_seh\',\n    \'set_error_handler\',\n    \'get_f_code_idx\',\n    \'get_frame_pointers\',\n    \'set_linetrace_on_frame\',\n    \'re_execute_with_exception\',\n    \'fix_ipython_startup\',\n]\n\n# Set this to true if you\'re feeling lucky.\n# (Otherwise the crash-debug-headache code is turned off)\nclass DANGER:\n    enabled = False\n\nctypes.pythonapi.Py_IncRef.argtypes = ctypes.py_object,\nctypes.pythonapi.Py_DecRef.argtypes = ctypes.py_object,\n\nsvp = ctypes.sizeof(ctypes.c_voidp)\n_keep_alive = []\n\nON_RTD = os.environ.get(\'READTHEDOCS\', None) == \'True\'\n\n\ndef get_dll(name):\n    prefixes = [\'\'] + [path_element + \'/\' for path_element in sys.path]\n    for prefix in prefixes:\n        base_name = prefix + name\n        try:\n            return ctypes.cdll.LoadLibrary(base_name + "".so"")\n        except OSError:\n            pass\n\n        if sys.platform == ""darwin"":\n            try:\n                return ctypes.cdll.LoadLibrary(base_name + "".dylib"")\n            except OSError:\n                pass\n        elif sys.platform in (""win32"", ""cygwin""):\n            try:\n                return ctypes.cdll.LoadLibrary(base_name + "".dll"")\n            except OSError:\n                pass\n\n    raise RuntimeError(""Unable to find shared object {0}.{{so,dylib,dll}}. ""\n                       ""Did you source thisroot.sh?"".format(name))\n\n\ndef get_seh():\n    """"""\n    Makes a function which can be used to set the ROOT error handler with a\n    python function and returns the existing error handler.\n    """"""\n    if ON_RTD:\n        return lambda x: x\n\n    ErrorHandlerFunc_t = ctypes.CFUNCTYPE(\n        None, ctypes.c_int, ctypes.c_bool,\n        ctypes.c_char_p, ctypes.c_char_p)\n\n    # Required to avoid strange dynamic linker problem on OSX.\n    # See https://github.com/rootpy/rootpy/issues/256\n    import ROOT\n\n    dll = get_dll(""libCore"")\n\n    SetErrorHandler = None\n    try:\n        if dll:\n            SetErrorHandler = dll._Z15SetErrorHandlerPFvibPKcS0_E\n    except AttributeError:\n        pass\n\n    if not SetErrorHandler:\n        log.warning(\n            ""Couldn\'t find SetErrorHandler. ""\n            ""Please submit a rootpy bug report."")\n        return lambda x: None\n\n    SetErrorHandler.restype = ErrorHandlerFunc_t\n    SetErrorHandler.argtypes = ErrorHandlerFunc_t,\n\n    def _SetErrorHandler(fn):\n        """"""\n        Set ROOT\'s warning/error handler. Returns the existing one.\n        """"""\n        log.debug(""called SetErrorHandler()"")\n        eh = ErrorHandlerFunc_t(fn)\n        # ``eh`` can get garbage collected unless kept alive, leading to a segfault.\n        _keep_alive.append(eh)\n        return SetErrorHandler(eh)\n\n    return _SetErrorHandler\n\n\nif not os.environ.get(\'NO_ROOTPY_HANDLER\', False):\n    set_error_handler = get_seh()\nelse:\n    set_error_handler = None\n\n\ndef get_f_code_idx():\n    """"""\n    How many pointers into PyFrame is the ``f_code`` variable?\n    """"""\n    frame = sys._getframe()\n    frame_ptr = id(frame)\n\n    LARGE_ENOUGH = 20\n\n    # Look through the frame object until we find the f_tstate variable, whose\n    # value we know from above.\n    ptrs = [ctypes.c_voidp.from_address(frame_ptr+i*svp)\n            for i in range(LARGE_ENOUGH)]\n\n    # Find its index into the structure\n    ptrs = [p.value for p in ptrs]\n\n    fcode_ptr = id(frame.f_code)\n    try:\n        threadstate_idx = ptrs.index(fcode_ptr)\n    except ValueError:\n        log.critical(""rootpy bug! Please report this."")\n        raise\n    return threadstate_idx\n\nF_CODE_IDX = get_f_code_idx()\n\n\ndef get_frame_pointers(frame=None):\n    """"""\n    Obtain writable pointers to ``frame.f_trace`` and ``frame.f_lineno``.\n\n    Very dangerous. Unlikely to be portable between python implementations.\n\n    This is hard in general because the ``PyFrameObject`` can have a variable size\n    depending on the build configuration. We can get it reliably because we can\n    determine the offset to ``f_tstate`` by searching for the value of that pointer.\n    """"""\n    if frame is None:\n        frame = sys._getframe(2)\n    frame = id(frame)\n\n    # http://hg.python.org/cpython/file/3aa530c2db06/Include/frameobject.h#l28\n    F_TRACE_OFFSET = 6\n    Ppy_object = ctypes.POINTER(ctypes.py_object)\n    trace = Ppy_object.from_address(frame+(F_CODE_IDX+F_TRACE_OFFSET)*svp)\n\n    LASTI_OFFSET = F_TRACE_OFFSET + 4\n\n    lasti_addr  = LASTI_OFFSET\n    lineno_addr = LASTI_OFFSET + ctypes.sizeof(ctypes.c_int)\n\n    f_lineno = ctypes.c_int.from_address(lineno_addr)\n    f_lasti = ctypes.c_int.from_address(lasti_addr)\n\n    return trace, f_lineno, f_lasti\n\n\ndef set_linetrace_on_frame(f, localtrace=None):\n    """"""\n    Non-portable function to modify linetracing.\n\n    Remember to enable global tracing with :py:func:`sys.settrace`, otherwise no\n    effect!\n    """"""\n    traceptr, _, _ = get_frame_pointers(f)\n    if localtrace is not None:\n        # Need to incref to avoid the frame causing a double-delete\n        ctypes.pythonapi.Py_IncRef(localtrace)\n        # Not sure if this is the best way to do this, but it works.\n        addr = id(localtrace)\n    else:\n        addr = 0\n\n    traceptr.contents = ctypes.py_object.from_address(addr)\n\n\ndef globaltrace(f, why, arg):\n    pass\n\n\ndef re_execute_with_exception(frame, exception, traceback):\n    """"""\n    Dark magic. Causes ``frame`` to raise an exception at the current location\n    with ``traceback`` appended to it.\n\n    Note that since the line tracer is raising an exception, the interpreter\n    disables the global trace, so it\'s not possible to restore the previous\n    tracing conditions.\n    """"""\n    if sys.gettrace() == globaltrace:\n        # If our trace handler is already installed, that means that this\n        # function has been called twice before the line tracer had a chance to\n        # run. That can happen if more than one exception was logged.\n        return\n\n    call_lineno = frame.f_lineno\n\n    def intercept_next_line(f, why, *args):\n        if f is not frame:\n            return\n        set_linetrace_on_frame(f)\n        # Undo modifications to the callers code (ick ick ick)\n        back_like_nothing_happened()\n        # Raise exception in (almost) the perfect place (except for duplication)\n        if sys.version_info[0] < 3:\n            #raise exception.__class__, exception, traceback\n            raise exception\n        raise exception.with_traceback(traceback)\n\n    set_linetrace_on_frame(frame, intercept_next_line)\n\n    linestarts = list(dis.findlinestarts(frame.f_code))\n    linestarts = [a for a, l in linestarts if l >= call_lineno]\n\n    # Jump target\n    dest = linestarts[0]\n\n    oc = frame.f_code.co_code[frame.f_lasti]\n    if sys.version_info[0] < 3:\n        oc = ord(oc)\n    opcode_size = 2 if oc >= opcode.HAVE_ARGUMENT else 0\n    # Opcode to overwrite\n    where = frame.f_lasti + 1 + opcode_size\n\n    #dis.disco(frame.f_code)\n    pc = PyCodeObject.from_address(id(frame.f_code))\n    back_like_nothing_happened = pc.co_code.contents.inject_jump(where, dest)\n    #print(""#""*100)\n    #dis.disco(frame.f_code)\n\n    sys.settrace(globaltrace)\n\n\ndef _inject_jump(self, where, dest):\n    """"""\n    Monkeypatch bytecode at ``where`` to force it to jump to ``dest``.\n\n    Returns function which puts things back to how they were.\n    """"""\n    # We\'re about to do dangerous things to a function\'s code content.\n    # We can\'t make a lock to prevent the interpreter from using those\n    # bytes, so the best we can do is to set the check interval to be high\n    # and just pray that this keeps other threads at bay.\n    if sys.version_info[0] < 3:\n        old_check_interval = sys.getcheckinterval()\n        sys.setcheckinterval(2**20)\n    else:\n        old_check_interval = sys.getswitchinterval()\n        sys.setswitchinterval(1000)\n\n    pb = ctypes.pointer(self.ob_sval)\n    orig_bytes = [pb[where + i][0] for i in range(3)]\n\n    v = struct.pack(""<BH"", opcode.opmap[""JUMP_ABSOLUTE""], dest)\n\n    # Overwrite code to cause it to jump to the target\n    if sys.version_info[0] < 3:\n        for i in range(3):\n            pb[where + i][0] = ord(v[i])\n    else:\n        for i in range(3):\n            pb[where + i][0] = v[i]\n\n    def tidy_up():\n        """"""\n        Put the bytecode back to how it was. Good as new.\n        """"""\n        if sys.version_info[0] < 3:\n            sys.setcheckinterval(old_check_interval)\n        else:\n            sys.setswitchinterval(old_check_interval)\n        for i in range(3):\n            pb[where + i][0] = orig_bytes[i]\n\n    return tidy_up\n\n\n# The following code allows direct access to a python strings\' bytes.\n# Expect bad things to happen if you use this.\n# It\'s necessary because you can\'t ordinarily modify strings in place, and we\n# need it to modify the callers\' code.\nPyObject_HEAD = ""PyObject_HEAD"", c_byte * object.__basicsize__\n\nif sys.version_info[0] < 3:\n    # http://svn.python.org/projects/python/trunk/Include/stringobject.h\n    class PyStringObject(Structure):\n        _fields_ = [(""_"", ctypes.c_long),\n                    (""_"", ctypes.c_int),\n                    (""_"", ctypes.c_ubyte * 1)]\n\n    # Determine size of PyObject_VAR_HEAD\n    PyObject_VAR_HEAD = (""PyObject_VAR_HEAD"",\n        c_byte * (str.__basicsize__ - ctypes.sizeof(PyStringObject)))\n\n    class PyStringObject(Structure):\n        _fields_ = [PyObject_VAR_HEAD,\n                    (""ob_shash"", ctypes.c_long),\n                    (""ob_sstate"", ctypes.c_int),\n                    (""ob_sval"", ctypes.c_ubyte * 1)]\n        inject_jump = _inject_jump\n\n    class PyCodeObject(Structure):\n        _fields_ = [PyObject_HEAD,\n                    (""co_argcount"", c_int),\n                    (""co_nlocals"", c_int),\n                    (""co_stacksize"", c_int),\n                    (""co_flags"", c_int),\n                    (""co_code"", POINTER(PyStringObject))]\n\nelse:\n    # https://github.com/python/cpython/blob/master/Include/bytesobject.h\n    class PyBytesObject(Structure):\n        _fields_ = [(""_"", ctypes.c_long),\n                    (""_"", ctypes.c_ubyte * 1)]\n\n    # Determine size of PyObject_VAR_HEAD\n    PyObject_VAR_HEAD = (""PyObject_VAR_HEAD"",\n        c_byte * (bytes.__basicsize__ - ctypes.sizeof(PyBytesObject)))\n\n    class PyBytesObject(Structure):\n        _fields_ = [PyObject_VAR_HEAD,\n                    (""ob_shash"", ctypes.c_long),\n                    (""ob_sval"", ctypes.c_ubyte * 1)]\n        inject_jump = _inject_jump\n\n    class PyCodeObject(Structure):\n        _fields_ = [PyObject_HEAD,\n                    (""co_argcount"", c_int),\n                    (""co_kwonlyargcount"", c_int),\n                    (""co_nlocals"", c_int),\n                    (""co_stacksize"", c_int),\n                    (""co_flags"", c_int),\n                    (""co_code"", POINTER(PyBytesObject))]\n\n\ndef fix_ipython_startup(fn):\n    """"""\n    Attempt to fix IPython startup to not print (Bool_t)1\n    """"""\n    BADSTR = \'TPython::Exec( """" )\'\n    GOODSTR = \'TPython::Exec( """" );\'\n    if sys.version_info[0] < 3:\n        consts = fn.im_func.func_code.co_consts\n    else:\n        consts = fn.__code__.co_consts\n    if BADSTR not in consts:\n        return\n    idx = consts.index(BADSTR)\n    orig_refcount = sys.getrefcount(consts)\n    del consts\n\n    PyTuple_SetItem = ctypes.pythonapi.PyTuple_SetItem\n    PyTuple_SetItem.argtypes = (ctypes.py_object,\n                                ctypes.c_size_t,\n                                ctypes.py_object)\n\n    if sys.version_info[0] < 3:\n        consts = ctypes.py_object(fn.im_func.func_code.co_consts)\n    else:\n        consts = ctypes.py_object(fn.im_func.__code__.co_consts)\n\n    for _ in range(orig_refcount - 2):\n        ctypes.pythonapi.Py_DecRef(consts)\n    try:\n        ctypes.pythonapi.Py_IncRef(GOODSTR)\n        PyTuple_SetItem(consts, idx, GOODSTR)\n    finally:\n        for _ in range(orig_refcount - 2):\n            ctypes.pythonapi.Py_IncRef(consts)\n'"
rootpy/logger/roothandler.py,0,"b'from __future__ import absolute_import\n\nimport ctypes\nimport logging\nimport re\nimport sys\n\nfrom . import log\nfrom .magic import DANGER, set_error_handler, re_execute_with_exception\n\n__all__ = [\n    \'fixup_msg\',\n    \'python_logging_error_handler\',\n]\n\nROOT_log = logging.getLogger(""ROOT"")\n\n\nclass SHOWTRACE:\n    enabled = False\n\nSANE_REGEX = re.compile(""^[^\\x80-\\xFF]*$"")\n\n\nclass Initialized:\n    value = False\n\nABORT_LEVEL = log.ERROR\n\n\ndef fixup_msg(lvl, msg):\n    """"""\n    Fixup for this ERROR to a WARNING because it has a reasonable fallback.\n    WARNING:ROOT.TGClient.TGClient] can\'t open display ""localhost:10.0"", switching to batch mode...\n    In case you run from a remote ssh session, reconnect with ssh -Y\n    """"""\n    if ""switching to batch mode..."" in msg and lvl == logging.ERROR:\n        return logging.WARNING, msg\n    return lvl, msg\n\n\ndef python_logging_error_handler(level, root_says_abort, location, msg):\n    """"""\n    A python error handler for ROOT which maps ROOT\'s errors and warnings on\n    to python\'s.\n    """"""\n    from ..utils import quickroot as QROOT\n\n    if not Initialized.value:\n        try:\n            QROOT.kTRUE\n        except AttributeError:\n            # Python is exiting. Do nothing.\n            return\n        QROOT.kInfo, QROOT.kWarning, QROOT.kError, QROOT.kFatal, QROOT.kSysError\n        QROOT.gErrorIgnoreLevel\n        Initialized.value = True\n\n    try:\n        QROOT.kTRUE\n    except RuntimeError:\n        # Note: If the above causes us problems, it\'s because this logging\n        #       handler has been called multiple times already with an\n        #       exception. In that case we need to force upstream to raise it.\n        _, exc, traceback = sys.exc_info()\n        caller = sys._getframe(2)\n        re_execute_with_exception(caller, exc, traceback)\n\n    if level < QROOT.gErrorIgnoreLevel:\n        # Needed to silence some ""normal"" startup warnings\n        # (copied from PyROOT Utility.cxx)\n        return\n\n    if sys.version_info[0] >= 3:\n        location = location.decode(\'utf-8\')\n        msg = msg.decode(\'utf-8\')\n\n    log = ROOT_log.getChild(location.replace(""::"", "".""))\n\n    if level >= QROOT.kSysError or level >= QROOT.kFatal:\n        lvl = logging.CRITICAL\n    elif level >= QROOT.kError:\n        lvl = logging.ERROR\n    elif level >= QROOT.kWarning:\n        lvl = logging.WARNING\n    elif level >= QROOT.kInfo:\n        lvl = logging.INFO\n    else:\n        lvl = logging.DEBUG\n\n    if not SANE_REGEX.match(msg):\n        # Not ASCII characters. Escape them.\n        msg = repr(msg)[1:-1]\n\n    # Apply fixups to improve consistency of errors/warnings\n    lvl, msg = fixup_msg(lvl, msg)\n\n    log.log(lvl, msg)\n\n    # String checks are used because we need a way of (un)forcing abort without\n    # modifying a global variable (gErrorAbortLevel) for the multithread tests\n    abort = lvl >= ABORT_LEVEL or ""rootpy.ALWAYSABORT"" in msg or root_says_abort\n    if abort and not ""rootpy.NEVERABORT"" in msg:\n        caller = sys._getframe(1)\n\n        try:\n            # We can\'t raise an exception from here because ctypes/PyROOT swallows it.\n            # Hence the need for dark magic, we re-raise it within a trace.\n            from .. import ROOTError\n            raise ROOTError(level, location, msg)\n        except RuntimeError:\n            _, exc, traceback = sys.exc_info()\n\n        if SHOWTRACE.enabled:\n            from traceback import print_stack\n            print_stack(caller)\n\n        if DANGER.enabled:\n            # Avert your eyes, dark magic be within...\n            re_execute_with_exception(caller, exc, traceback)\n\n    if root_says_abort:\n        log.critical(""abort().. expect a stack trace"")\n        ctypes.CDLL(None).abort()\n'"
rootpy/logger/utils.py,0,"b""from __future__ import absolute_import\n\nimport os\n\n__all__ = [\n    'check_tty',\n]\n\n\ndef check_tty(stream):\n    if not hasattr(stream, 'fileno'):\n        return False\n    try:\n        fileno = stream.fileno()\n        return os.isatty(fileno)\n    except (OSError, IOError):\n        return False\n"""
rootpy/memory/__init__.py,0,"b""from .. import log; log = log[__name__]\n\nfrom .keepalive import keepalive, KEEPALIVE\n\n__all__ = [\n    'keepalive',\n]\n"""
rootpy/memory/deletion.py,0,"b'""""""\nThis module supports monitoring TObject deletions.\n\n.. warning::\n   This is not recommended for production\n\n""""""\nfrom __future__ import absolute_import\n\nfrom weakref import ref\nimport ctypes\nfrom ctypes import CFUNCTYPE, py_object, addressof, c_int\n\nfrom .. import compiled as C\nfrom .. import QROOT, log\nfrom ..utils.cinterface import callback, objectproxy_realaddress\n\n\n__all__ = [\n    \'monitor_deletion\',\n    \'monitor_object_deletion\',\n]\n\n\ndef monitor_deletion():\n    """"""\n    Function for checking for correct deletion of weakref-able objects.\n\n    Example usage::\n\n        monitor, is_alive = monitor_deletion()\n        obj = set()\n        monitor(obj, ""obj"")\n        assert is_alive(""obj"") # True because there is a ref to `obj` is_alive\n        del obj\n        assert not is_alive(""obj"") # True because there `obj` is deleted\n\n    """"""\n    monitors = {}\n\n    def set_deleted(x):\n        def _(weakref):\n            del monitors[x]\n        return _\n\n    def monitor(item, name):\n        monitors[name] = ref(item, set_deleted(name))\n\n    def is_alive(name):\n        return monitors.get(name, None) is not None\n\n    return monitor, is_alive\n\n\ncleanuplog = log[""memory.cleanup""]\ncleanuplog.show_stack()\n\n# Add python to the include path\nC.add_python_includepath()\n\nC.register_code(""""""\n    #ifndef __CINT__\n    #include <Python.h>\n    #endif\n    #include <TObject.h>\n    #include <TPython.h>\n\n    class RootpyObjectCleanup : public TObject {\n    public:\n        typedef void (*CleanupCallback)(PyObject*);\n        CleanupCallback _callback;\n\n        RootpyObjectCleanup(CleanupCallback callback) : _callback(callback) {}\n\n        virtual void RecursiveRemove(TObject* object) {\n            // When arriving here, object->ClassName() will _always_ be TObject\n            // since we\'re called by ~TObject, and virtual method calls don\'t\n            // work as expected from there.\n            PyObject* o = TPython::ObjectProxy_FromVoidPtr(object, ""TObject"");\n\n            PyGILState_STATE gstate;\n            gstate = PyGILState_Ensure();\n            PyObject *ptype, *pvalue, *ptraceback;\n            PyErr_Fetch(&ptype, &pvalue, &ptraceback);\n\n            _callback(o);\n\n            PyErr_Restore(ptype, pvalue, ptraceback);\n            PyGILState_Release(gstate);\n        }\n\n        ClassDef(RootpyObjectCleanup, 0);\n    };\n\n    ClassImp(RootpyObjectCleanup);\n\n"""""", [""RootpyObjectCleanup""])\n\nMONITORED = {}\n\n\n@CFUNCTYPE(None, py_object)\ndef on_cleanup(tobject):\n    # Note, when we arrive here, tobject is in its ~TObject, and hence the\n    # subclass part of the object doesn\'t exist, in some sense. Hence why we\n    # store information about the object on the MONITORED dict.\n    addr = objectproxy_realaddress(tobject)\n    if addr in MONITORED:\n        args = MONITORED[addr]\n        fn, args = args[0], args[1:]\n        fn(tobject, *args)\n        del MONITORED[addr]\n\ninitialized = False\n\n\ndef init():\n    global initialized\n    if initialized: return\n    initialized = True\n\n    cleanup = C.RootpyObjectCleanup(callback(on_cleanup))\n\n    cleanups = QROOT.gROOT.GetListOfCleanups()\n    cleanups.Add(cleanup)\n\n    import atexit\n\n    @atexit.register\n    def exit():\n        # Needed to ensure we don\'t get called after ROOT has gone away\n        cleanups.RecursiveRemove(cleanup)\n\n\ndef monitor_object_deletion(o, fn=lambda *args: None):\n\n    init()\n\n    # Required so that GetListOfCleanups().RecursiveRemove() is called.\n    o.SetBit(o.kMustCleanup)\n\n    args = fn, type(o).__name__, o.GetName(), o.GetTitle(), repr(o)\n    MONITORED[objectproxy_realaddress(o)] = args\n'"
rootpy/memory/keepalive.py,0,"b'from __future__ import absolute_import\n\nimport sys\nimport weakref\nimport os\n\nfrom . import log; log = log[__name__]\n\n__all__ = [\n    \'keepalive\',\n]\n\nKEEPALIVE = weakref.WeakKeyDictionary()\nDISABLED = \'NO_ROOTPY_KEEPALIVE\' in os.environ\n\n\ndef hashable(v):\n    """"""Determine whether `v` can be hashed.""""""\n    try:\n        hash(v)\n    except:\n        return False\n    return True\n\n\ndef keepalive(nurse, *patients):\n    """"""\n    Keep ``patients`` alive at least as long as ``nurse`` is around using a\n    ``WeakKeyDictionary``.\n    """"""\n    if DISABLED:\n        return\n    if hashable(nurse):\n        hashable_patients = []\n        for p in patients:\n            if hashable(p):\n                log.debug(""Keeping {0} alive for lifetime of {1}"".format(p, nurse))\n                hashable_patients.append(p)\n            else:\n                log.warning(""Unable to keep unhashable object {0} ""\n                            ""alive for lifetime of {1}"".format(p, nurse))\n        KEEPALIVE.setdefault(nurse, set()).update(hashable_patients)\n    else:\n        log.warning(""Unable to keep objects alive for lifetime of ""\n                    ""unhashable object {0}"".format(nurse))\n'"
rootpy/memory/ownership.py,0,"b'from __future__ import absolute_import\n\nfrom .. import compiled as C\n\n__all__ = [\n    \'GetOwnership\',\n]\n\nC.register_code(""""""\n    #include <sys/types.h>       // for ssize_t\n\n    struct _object;\n\n    struct TFakeObjectProxy {\n       ssize_t fRefCnt;          // PyObject_HEAD\n       void* fPyType;            // PyObject_HEAD\n       void* fRootObj;\n       int fFlags;\n    };\n\n    bool GetOwnership(_object* obj) {\n       return (reinterpret_cast<TFakeObjectProxy*>(obj))->fFlags & 0x0001;\n    }\n"""""", [""GetOwnership""])\n\n\ndef GetOwnership(obj):\n    """"""\n    The analagous function to :func:``ROOT.SetOwnership``.\n    This function is intended for diagnostic purposes and is not guaranteed to\n    keep working.\n    """"""\n    # This is not a straight assignment because C.GetOwnership causes\n    # finalsetup and compilation.\n    return C.GetOwnership(obj)\n'"
rootpy/plotting/__init__.py,0,"b""from __future__ import absolute_import\n\nfrom .. import log; log = log[__name__]\nfrom .. import IN_IPYTHON_NOTEBOOK\nfrom .. import QROOT, ROOT\nfrom ..utils.hook import classhook, super_overridden\nfrom ..memory.keepalive import keepalive\nfrom .hist import Hist, Hist1D, Hist2D, Hist3D, Efficiency, HistStack, histogram\nfrom .graph import Graph, Graph1D, Graph2D\nfrom .profile import Profile, Profile1D, Profile2D, Profile3D\nfrom .func import F1, F2, F3\nfrom .legend import Legend\nfrom .canvas import Canvas, Pad\nfrom .style import Style, get_style, set_style\n\n__all__ = [\n    'Hist', 'Hist1D', 'Hist2D', 'Hist3D', 'HistStack',\n    'Efficiency', 'histogram',\n    'Graph', 'Graph1D', 'Graph2D',\n    'Profile', 'Profile1D', 'Profile2D', 'Profile3D',\n    'F1', 'F2', 'F3',\n    'Legend', 'Canvas', 'Pad',\n    'Style', 'get_style', 'set_style',\n]\n\nif IN_IPYTHON_NOTEBOOK:\n    from ..interactive import notebook\n    notebook.configure()\n\n@classhook(QROOT.TH1, QROOT.TF1,\n           QROOT.THStack,\n           QROOT.TGraph, QROOT.TGraph2D,\n           QROOT.TBox, QROOT.TText,\n           QROOT.TLegend,\n           QROOT.TLine, QROOT.TEllipse, QROOT.TArrow)\n@super_overridden\nclass DrawableKeepAlive(object):\n    def Draw(self, *args, **kwargs):\n        keepalive(ROOT.gPad, self)\n        return super(DrawableKeepAlive, self).Draw(*args, **kwargs)\n"""
rootpy/plotting/autobinning.py,25,"b'from __future__ import absolute_import\n\nimport types\nimport numpy as np\n\n\n__all__ = [\n    \'autobinning\',\n]\n\n\ndef autobinning(data, method=""freedman_diaconis""):\n    """"""\n    This method determines the optimal binning for histogramming.\n\n    Parameters\n    ----------\n    data: 1D array-like\n          Input data.\n    method: string, one of the following:\n          - sturges\n          - sturges-doane\n          - scott\n          - sqrt\n          - doane\n          - freedman-diaconis\n          - risk\n          - knuth\n\n    Returns\n    -------\n    (nbins, min, max): int, type(data), type(data)\n         nbins is the optimal number of bin estimated by the method\n         min is the minimum of data\n         max is the maximum of data\n\n    Notes\n    -----\n    If the length of data is less than 4 the method retun nbins = 1\n    """"""\n    name = method.replace(""-"", ""_"")\n    try:\n        method = getattr(BinningMethods, name)\n        if not isinstance(method, types.FunctionType):\n            raise AttributeError\n    except AttributeError:\n        raise ValueError(""`{0}` is not a valid binning method"".format(name))\n    if len(data) < 4:\n        return 1, np.min(data), np.max(data)\n    return int(np.ceil(method(data))), np.min(data), np.max(data)\n\n\nclass BinningMethods(object):\n    """"""\n    Static methods on this class are available as methods for ``autobinning``.\n    """"""\n    @classmethod\n    def all_methods(cls):\n        """"""\n        Return the names of all available binning methods\n        """"""\n        def name(fn):\n            return fn.__get__(cls).__name__.replace(""_"", ""-"")\n        return sorted(name(f) for f in cls.__dict__.values()\n                      if isinstance(f, staticmethod))\n\n    @staticmethod\n    def sturges(data):\n        n = len(data)\n        return np.log2(n) + 1\n\n    @staticmethod\n    def sturges_doane(data):\n        """"""\n        References\n        ----------\n        .. [1] D. Wilkinson, ""The Grammar of Graphics"", 2005.\n               http://books.google.it/books?id=_kRX4LoFfGQC&lpg=PA133&ots=APHb0-p6tY&dq=doane%20binning%20histogram&hl=it&pg=PA133#v=onepage&q=doane%20binning%20histogram&f=false\n        """"""\n        n = len(data)\n        return np.log10(n) * np.log2(n) + 3\n\n    @staticmethod\n    def doane(data):\n        """"""\n        Modified Doane modified\n        """"""\n        from scipy.stats import skew\n        n = len(data)\n        sigma = np.sqrt(6. * (n - 2.) / (n + 1.) / (n + 3.))\n        return 1 + np.log2(n) + \\\n            np.log2(1 + np.abs(skew(data)) / sigma)\n\n    @staticmethod\n    def scott(data):\n        sigma = np.std(data)\n        n = len(data)\n        h = 3.49 * sigma * n ** (-1. / 3.)\n        return (np.max(data) - np.min(data)) / h\n\n    @staticmethod\n    def sqrt(data):\n        return np.sqrt(len(data))\n\n    @staticmethod\n    def freedman_diaconis(data):\n        from scipy.stats.mstats import mquantiles\n        q = mquantiles(data, prob=[0.25, 0.75])\n        IQR = q[1] - q[0]  # interquartile range\n        n = len(data)\n        h = 2 * IQR / n ** (1. / 3.)\n        return (np.max(data) - np.min(data)) / h\n\n    @staticmethod\n    def risk(data):\n        import scipy.optimize as optimize\n\n        m, M = np.min(data), np.max(data)\n\n        def f(data):\n            def fff(x):  # h is spacing\n                h = x[0]\n                nbins = (M - m) / h\n                binning = np.arange(m, M, h)\n                if not len(binning):\n                    return float(""+inf"")\n                histo, bincenters = np.histogram(data, binning)\n                bincenters = 0.5 * (bincenters[1:] + bincenters[:-1])\n                mean = 1. / nbins * np.sum(histo)\n                v2 = 1. / nbins * np.sum((histo - mean) ** 2)\n                return (2 * mean - v2) / h ** 2\n            return fff\n\n        k0 = np.sqrt(len(data))\n        h0 = (M - m) / k0\n        h = optimize.fmin(f(data), np.array([h0]), disp=False)[0]\n        return (M - m) / h\n\n    @staticmethod\n    def knuth(data):\n        """"""\n        References\n        ----------\n        .. [1] K. Knuth, ""Optimal Data-Based Binning for Histograms"", 2006.\n               http://arxiv.org/pdf/physics/0605197v1.pdf\n        """"""\n        import scipy.optimize as optimize\n\n        def f(data):\n            from scipy.special import gammaln\n\n            m, M = np.min(data), np.max(data)\n            n = len(data)\n\n            def fff(x):\n                k = x[0]  # number of bins\n                if k <= 0:\n                    return float(""+inf"")\n                binning = np.linspace(m, M, k + 1)\n                histo, bincenters = np.histogram(data, binning)\n\n                return -(n * np.log(k) + gammaln(k / 2.) - gammaln(n + k / 2.) +\n                         k * gammaln(1. / 2.) + np.sum(gammaln(histo + 0.5)))\n            return fff\n\n        k0 = np.sqrt(len(data))\n        return optimize.fmin(f(data), np.array([k0]), disp=False)[0]\n\n    @staticmethod\n    def wand(data):\n        """"""\n        References\n        ----------\n        .. [1] M. Wand, ""Statistical Computing and Graphics"", 1997.\n               http://web.ipac.caltech.edu/staff/fmasci/home/statistics_refs/OptimumHistogram.pdf\n        """"""\n        raise NotImplementedError\n'"
rootpy/plotting/axis.py,0,"b'from __future__ import absolute_import\n\nfrom .. import QROOT\nfrom ..base import NamedObject\nfrom ..decorators import snake_case_methods\nfrom .utils import canvases_with\n\n__all__ = [\n    \'Axis\',\n]\n\n\n@snake_case_methods\nclass Axis(NamedObject, QROOT.TAxis):\n    _ROOT = QROOT.TAxis\n\n    def __init__(self, name=None, title=None):\n        super(Axis, self).__init__(name=name, title=title)\n\n    @property\n    def range_user(self):\n        first, last = self.GetFirst(), self.GetLast()\n        return self.GetBinLowEdge(first), self.GetBinUpEdge(last)\n\n    @range_user.setter\n    def range_user(self, r):\n        low, high = r\n        self.SetRangeUser(low, high)\n\n    def SetRangeUser(self, low, high, update=True):\n        if high <= low:\n            raise ValueError(""high must be greater than low"")\n        super(Axis, self).SetRangeUser(low, high)\n        # Notify relevant canvases that they are modified.\n        # Note: some might be missed if our parent is encapsulated in some\n        #       other class.\n        if not update:\n            return\n        for c in canvases_with(self.GetParent()):\n            c.Modified()\n            c.Update()\n\n    @property\n    def limits(self):\n        return self.GetXmin(), self.GetXmax()\n\n    @limits.setter\n    def limits(self, r):\n        low, high = r\n        self.SetLimits(low, high)\n\n    def SetLimits(self, low, high, update=True):\n        if high <= low:\n            raise ValueError(""high must be greater than low"")\n        super(Axis, self).SetLimits(low, high)\n        # Notify relevant canvases that they are modified.\n        # Note: some might be missed if our parent is encapsulated in some\n        #       other class.\n        if not update:\n            return\n        for c in canvases_with(self.GetParent()):\n            c.Modified()\n            c.Update()\n\n    @property\n    def min(self):\n        return self.GetXmin()\n\n    @property\n    def max(self):\n        return self.GetXmax()\n\n    @min.setter\n    def min(self, value):\n        # no SetXmin() in ROOT\n        self.SetLimits(value, self.GetXmax(), update=False)\n        self.SetRangeUser(value, self.GetXmax())\n\n    @max.setter\n    def max(self, value):\n        # no SetXmax() in ROOT\n        self.SetLimits(self.GetXmin(), value, update=False)\n        self.SetRangeUser(self.GetXmin(), value)\n\n    @property\n    def divisions(self):\n        return self.GetNdivisions()\n\n    @divisions.setter\n    def divisions(self, value):\n        self.SetNdivisions(value)\n'"
rootpy/plotting/base.py,0,"b'""""""\nThis module contains base classes defining core funcionality\n""""""\nfrom __future__ import absolute_import\n\nfrom functools import wraps\nimport warnings\nimport sys\n\nfrom .. import asrootpy, ROOT\nfrom ..decorators import chainable\nfrom ..memory.keepalive import keepalive\nfrom ..extern.six import string_types\n\n__all__ = [\n    \'dim\',\n    \'Plottable\',\n]\n\n\ndef dim(thing):\n    if hasattr(thing.__class__, \'DIM\'):\n        return thing.__class__.DIM\n    elif hasattr(thing, \'__dim__\'):\n        return thing.__dim__()\n    elif hasattr(thing, \'GetDimension\'):\n        return thing.GetDimension()\n    else:\n        raise TypeError(\n            ""Unable to determine dimensionality of ""\n            ""object of type {0}"".format(type(thing)))\n\n\nclass Plottable(object):\n    """"""\n    This is a mixin to provide additional attributes for plottable classes\n    and to override ROOT TAttXXX and Draw methods.\n    """"""\n    EXTRA_ATTRS = {\n        \'norm\': None,\n        \'drawstyle\': \'\',\n        \'legendstyle\': \'P\',\n        \'integermode\': False,\n        \'visible\': True,\n        \'inlegend\': True,\n        }\n\n    EXTRA_ATTRS_DEPRECATED = {\n        \'format\': \'drawstyle\',\n        \'intmode\': \'integermode\',\n        }\n\n    EXTRA_SETTERS = [\n        \'color\',\n        ]\n\n    # TODO: respect current TStyle\n    DEFAULT_DECOR = {\n        \'markerstyle\': \'circle\',\n        \'markercolor\': \'black\',\n        \'markersize\': 1,\n        \'fillcolor\': \'white\',\n        \'fillstyle\': \'hollow\',\n        \'linecolor\': \'black\',\n        \'linestyle\': \'solid\',\n        \'linewidth\': 1,\n        }\n\n    @classmethod\n    def _get_attr_depr(cls, depattr, newattr):\n        def f(self):\n            warnings.warn(\n                ""`{0}` is deprecated and will be removed in ""\n                ""future versions. Use `{1}` instead"".format(\n                    depattr, newattr),\n                DeprecationWarning)\n            return getattr(self, newattr)\n        return f\n\n    @classmethod\n    def _set_attr_depr(cls, depattr, newattr):\n        def f(self, value):\n            warnings.warn(\n                ""`{0}` is deprecated and will be removed in ""\n                ""future versions. Use `{1}` instead"".format(\n                    depattr, newattr),\n                DeprecationWarning)\n            setattr(self, newattr, value)\n        return f\n\n    def _post_init(self, **kwargs):\n        self._clone_post_init(**kwargs)\n\n    def _clone_post_init(self, obj=None, **kwargs):\n        """"""\n        obj must be another Plottable instance. obj is used by Clone to properly\n        transfer all attributes onto this object.\n        """"""\n        # Initialize the extra attributes\n        if obj is None or obj is self:\n            # We must be asrootpy-ing a ROOT object\n            # or freshly init-ing a rootpy object\n            for attr, value in Plottable.EXTRA_ATTRS.items():\n                # Use the default value\n                setattr(self, attr, value)\n        else:\n            for attr, value in Plottable.EXTRA_ATTRS.items():\n                setattr(self, attr, getattr(obj, attr))\n\n        # Create aliases from deprecated to current attributes\n        for depattr, newattr in Plottable.EXTRA_ATTRS_DEPRECATED.items():\n            setattr(Plottable, depattr,\n                    property(\n                        fget=Plottable._get_attr_depr(depattr, newattr),\n                        fset=Plottable._set_attr_depr(depattr, newattr)))\n\n        if obj is None or obj is self:\n            # We must be asrootpy-ing a ROOT object\n            # or freshly init-ing a rootpy object\n            # Initialize style attrs to style of TObject\n            if isinstance(self, ROOT.TAttLine):\n                self._linecolor = Color(ROOT.TAttLine.GetLineColor(self))\n                self._linestyle = LineStyle(ROOT.TAttLine.GetLineStyle(self))\n                self._linewidth = ROOT.TAttLine.GetLineWidth(self)\n            else:  # HistStack\n                self._linecolor = Color(Plottable.DEFAULT_DECOR[\'linecolor\'])\n                self._linestyle = LineStyle(Plottable.DEFAULT_DECOR[\'linestyle\'])\n                self._linewidth = Plottable.DEFAULT_DECOR[\'linewidth\']\n\n            if isinstance(self, ROOT.TAttFill):\n                self._fillcolor = Color(ROOT.TAttFill.GetFillColor(self))\n                self._fillstyle = FillStyle(ROOT.TAttFill.GetFillStyle(self))\n            else:  # HistStack\n                self._fillcolor = Color(Plottable.DEFAULT_DECOR[\'fillcolor\'])\n                self._fillstyle = FillStyle(Plottable.DEFAULT_DECOR[\'fillstyle\'])\n\n            if isinstance(self, ROOT.TAttMarker):\n                self._markercolor = Color(ROOT.TAttMarker.GetMarkerColor(self))\n                self._markerstyle = MarkerStyle(ROOT.TAttMarker.GetMarkerStyle(self))\n                self._markersize = ROOT.TAttMarker.GetMarkerSize(self)\n            else:  # HistStack\n                self._markercolor = Color(Plottable.DEFAULT_DECOR[\'markercolor\'])\n                self._markerstyle = MarkerStyle(Plottable.DEFAULT_DECOR[\'markerstyle\'])\n                self._markersize = Plottable.DEFAULT_DECOR[\'markersize\']\n\n            if obj is None:\n                # Populate defaults if we are not asrootpy-ing existing object\n                decor = dict(**Plottable.DEFAULT_DECOR)\n                decor.update(Plottable.EXTRA_ATTRS)\n                if \'color\' in kwargs:\n                    decor.pop(\'linecolor\', None)\n                    decor.pop(\'fillcolor\', None)\n                    decor.pop(\'markercolor\', None)\n                decor.update(kwargs)\n                self.decorate(**decor)\n\n        else:\n            # Initialize style attrs to style of the other object\n            if isinstance(obj, ROOT.TAttLine):\n                self.SetLineColor(obj.GetLineColor())\n                self.SetLineStyle(obj.GetLineStyle())\n                self.SetLineWidth(obj.GetLineWidth())\n            if isinstance(obj, ROOT.TAttFill):\n                self.SetFillColor(obj.GetFillColor())\n                self.SetFillStyle(obj.GetFillStyle())\n            if isinstance(obj, ROOT.TAttMarker):\n                self.SetMarkerColor(obj.GetMarkerColor())\n                self.SetMarkerStyle(obj.GetMarkerStyle())\n                self.SetMarkerSize(obj.GetMarkerSize())\n            if kwargs:\n                self.decorate(**kwargs)\n\n    #TODO: @chainable\n    def decorate(self, other=None, **kwargs):\n        """"""\n        Apply style options to a Plottable object.\n\n        Returns a reference to self.\n        """"""\n        if \'color\' in kwargs:\n            incompatible = []\n            for othercolor in (\'linecolor\', \'fillcolor\', \'markercolor\'):\n                if othercolor in kwargs:\n                    incompatible.append(othercolor)\n            if incompatible:\n                raise ValueError(\n                    ""Setting both the `color` and the `{0}` attribute{1} ""\n                    ""is ambiguous. Please set only one."".format(\n                        \', \'.join(incompatible),\n                        \'s\' if len(incompatible) != 1 else \'\'))\n        if other is not None:\n            decor = other.decorators\n            if \'color\' in kwargs:\n                decor.pop(\'linecolor\', None)\n                decor.pop(\'fillcolor\', None)\n                decor.pop(\'markercolor\', None)\n            decor.update(kwargs)\n            kwargs = decor\n        for key, value in kwargs.items():\n            if key in Plottable.EXTRA_ATTRS_DEPRECATED:\n                newkey = Plottable.EXTRA_ATTRS_DEPRECATED[key]\n                warnings.warn(\n                    ""`{0}` is deprecated and will be removed in ""\n                    ""future versions. Use `{1}` instead"".format(\n                        key, newkey),\n                    DeprecationWarning)\n                key = newkey\n            if key in Plottable.EXTRA_ATTRS:\n                setattr(self, key, value)\n            elif key == \'markerstyle\':\n                self.SetMarkerStyle(value)\n            elif key == \'markercolor\':\n                self.SetMarkerColor(value)\n            elif key == \'markersize\':\n                self.SetMarkerSize(value)\n            elif key == \'fillcolor\':\n                self.SetFillColor(value)\n            elif key == \'fillstyle\':\n                self.SetFillStyle(value)\n            elif key == \'linecolor\':\n                self.SetLineColor(value)\n            elif key == \'linestyle\':\n                self.SetLineStyle(value)\n            elif key == \'linewidth\':\n                self.SetLineWidth(value)\n            elif key == \'color\':\n                self.SetColor(value)\n            else:\n                raise AttributeError(\n                    ""unknown decoration attribute: `{0}`"".format(key))\n        return self\n\n    @property\n    def decorators(self):\n        return {\n            ""norm"": self.norm,\n            ""drawstyle"": self.drawstyle,\n            ""legendstyle"": self.legendstyle,\n            ""integermode"": self.integermode,\n            ""visible"": self.visible,\n            ""inlegend"": self.inlegend,\n            ""markercolor"": self.GetMarkerColor(),\n            ""markerstyle"": self.GetMarkerStyle(),\n            ""markersize"": self.GetMarkerSize(),\n            ""fillcolor"": self.GetFillColor(),\n            ""fillstyle"": self.GetFillStyle(),\n            ""linecolor"": self.GetLineColor(),\n            ""linestyle"": self.GetLineStyle(),\n            ""linewidth"": self.GetLineWidth(),\n        }\n\n    def SetLineColor(self, color):\n        """"""\n        *color* may be any color understood by ROOT or matplotlib.\n\n        For full documentation of accepted *color* arguments, see\n        :class:`rootpy.plotting.style.Color`.\n        """"""\n        self._linecolor = Color(color)\n        if isinstance(self, ROOT.TAttLine):\n            ROOT.TAttLine.SetLineColor(self, self._linecolor(\'root\'))\n\n    def GetLineColor(self, mode=None):\n        """"""\n        *mode* may be \'root\', \'mpl\', or None to return the ROOT, matplotlib,\n        or input value.\n        """"""\n        return self._linecolor(mode)\n\n    @property\n    def linecolor(self):\n        return self.GetLineColor()\n\n    @linecolor.setter\n    def linecolor(self, color):\n        self.SetLineColor(color)\n\n    def SetLineStyle(self, style):\n        """"""\n        *style* may be any line style understood by ROOT or matplotlib.\n\n        For full documentation of accepted *style* arguments, see\n        :class:`rootpy.plotting.style.LineStyle`.\n        """"""\n        self._linestyle = LineStyle(style)\n        if isinstance(self, ROOT.TAttLine):\n            ROOT.TAttLine.SetLineStyle(self, self._linestyle(\'root\'))\n\n    def GetLineStyle(self, mode=None):\n        """"""\n        *mode* may be \'root\', \'mpl\', or None to return the ROOT, matplotlib,\n        or input value.\n        """"""\n        return self._linestyle(mode)\n\n    @property\n    def linestyle(self):\n        return self.GetLineStyle()\n\n    @linestyle.setter\n    def linestyle(self, style):\n        self.SetLineStyle(style)\n\n    def SetLineWidth(self, width):\n        if isinstance(self, ROOT.TAttLine):\n            ROOT.TAttLine.SetLineWidth(self, width)\n        else:\n            self._linewidth = width\n\n    def GetLineWidth(self):\n        if isinstance(self, ROOT.TAttLine):\n            return ROOT.TAttLine.GetLineWidth(self)\n        else:\n            return self._linewidth\n\n    @property\n    def linewidth(self):\n        return self.GetLineWidth()\n\n    @linewidth.setter\n    def linewidth(self, width):\n        self.SetLineWidth(width)\n\n    def SetFillColor(self, color):\n        """"""\n        *color* may be any color understood by ROOT or matplotlib.\n\n        For full documentation of accepted *color* arguments, see\n        :class:`rootpy.plotting.style.Color`.\n        """"""\n        self._fillcolor = Color(color)\n        if isinstance(self, ROOT.TAttFill):\n            ROOT.TAttFill.SetFillColor(self, self._fillcolor(\'root\'))\n\n    def GetFillColor(self, mode=None):\n        """"""\n        *mode* may be \'root\', \'mpl\', or None to return the ROOT, matplotlib,\n        or input value.\n        """"""\n        return self._fillcolor(mode)\n\n    @property\n    def fillcolor(self):\n        return self.GetFillColor()\n\n    @fillcolor.setter\n    def fillcolor(self, color):\n        self.SetFillColor(color)\n\n    def SetFillStyle(self, style):\n        """"""\n        *style* may be any fill style understood by ROOT or matplotlib.\n\n        For full documentation of accepted *style* arguments, see\n        :class:`rootpy.plotting.style.FillStyle`.\n        """"""\n        self._fillstyle = FillStyle(style)\n        if isinstance(self, ROOT.TAttFill):\n            ROOT.TAttFill.SetFillStyle(self, self._fillstyle(\'root\'))\n\n    def GetFillStyle(self, mode=None):\n        """"""\n        *mode* may be \'root\', \'mpl\', or None to return the ROOT, matplotlib,\n        or input value.\n        """"""\n        return self._fillstyle(mode)\n\n    @property\n    def fillstyle(self):\n        return self.GetFillStyle()\n\n    @fillstyle.setter\n    def fillstyle(self, style):\n        self.SetFillStyle(style)\n\n    def SetMarkerColor(self, color):\n        """"""\n        *color* may be any color understood by ROOT or matplotlib.\n\n        For full documentation of accepted *color* arguments, see\n        :class:`rootpy.plotting.style.Color`.\n        """"""\n        self._markercolor = Color(color)\n        if isinstance(self, ROOT.TAttMarker):\n            ROOT.TAttMarker.SetMarkerColor(self, self._markercolor(\'root\'))\n\n    def GetMarkerColor(self, mode=None):\n        """"""\n        *mode* may be \'root\', \'mpl\', or None to return the ROOT, matplotlib,\n        or input value.\n        """"""\n        return self._markercolor(mode)\n\n    @property\n    def markercolor(self):\n        return self.GetMarkerColor()\n\n    @markercolor.setter\n    def markercolor(self, color):\n        self.SetMarkerColor(color)\n\n    def SetMarkerStyle(self, style):\n        """"""\n        *style* may be any marker style understood by ROOT or matplotlib.\n\n        For full documentation of accepted *style* arguments, see\n        :class:`rootpy.plotting.style.MarkerStyle`.\n        """"""\n        self._markerstyle = MarkerStyle(style)\n        if isinstance(self, ROOT.TAttMarker):\n            ROOT.TAttMarker.SetMarkerStyle(self, self._markerstyle(\'root\'))\n\n    def GetMarkerStyle(self, mode=None):\n        """"""\n        *mode* may be \'root\', \'mpl\', or None to return the ROOT, matplotlib,\n        or input value.\n        """"""\n        return self._markerstyle(mode)\n\n    @property\n    def markerstyle(self):\n        return self.GetMarkerStyle()\n\n    @markerstyle.setter\n    def markerstyle(self, style):\n        self.SetMarkerStyle(style)\n\n    def SetMarkerSize(self, size):\n        if isinstance(self, ROOT.TAttMarker):\n            ROOT.TAttMarker.SetMarkerSize(self, size)\n        else:\n            self._markersize = size\n\n    def GetMarkerSize(self):\n        if isinstance(self, ROOT.TAttMarker):\n            return ROOT.TAttMarker.GetMarkerSize(self)\n        else:\n            return self._markersize\n\n    @property\n    def markersize(self):\n        return self.GetMarkerSize()\n\n    @markersize.setter\n    def markersize(self, size):\n        self.SetMarkerSize(size)\n\n    def SetColor(self, color):\n        """"""\n        *color* may be any color understood by ROOT or matplotlib.\n\n        Set all color attributes with one method call.\n\n        For full documentation of accepted *color* arguments, see\n        :class:`rootpy.plotting.style.Color`.\n        """"""\n        self.SetFillColor(color)\n        self.SetLineColor(color)\n        self.SetMarkerColor(color)\n\n    def GetColor(self):\n        return self.GetMarkerColor(), self.GetLineColor(), self.GetFillColor()\n\n    @property\n    def color(self):\n        return self.GetColor()\n\n    @color.setter\n    def color(self, color):\n        self.SetColor(color)\n\n    @property\n    def xaxis(self):\n        return asrootpy(self.GetXaxis())\n\n    @property\n    def yaxis(self):\n        return asrootpy(self.GetYaxis())\n\n    @property\n    def zaxis(self):\n        return asrootpy(self.GetZaxis())\n\n    def Draw(self, *args, **kwargs):\n        """"""\n        Parameters\n        ----------\n        args : positional arguments\n            Positional arguments are passed directly to ROOT\'s Draw\n        kwargs : keyword arguments\n            If keyword arguments are present, then a clone is drawn instead\n            with DrawCopy, where the name, title, and style attributes are\n            taken from ``kwargs``.\n\n        Returns\n        -------\n        If ``kwargs`` is not empty and a clone is drawn, then the clone is\n        returned, otherwise None is returned.\n        """"""\n        if kwargs:\n            return self.DrawCopy(*args, **kwargs)\n\n        pad = ROOT.gPad\n        own_pad = False\n        if not pad:\n            # avoid circular import by delaying import until needed here\n            from .canvas import Canvas\n            pad = Canvas()\n            own_pad = True\n        if self.visible:\n            if self.drawstyle:\n                self.__class__.__bases__[-1].Draw(self,\n                    "" "".join((self.drawstyle, ) + args))\n            else:\n                self.__class__.__bases__[-1].Draw(self, "" "".join(args))\n            pad.Modified()\n            pad.Update()\n        if own_pad:\n            keepalive(self, pad)\n\n    def DrawCopy(self, *args, **kwargs):\n        """"""\n        Parameters\n        ----------\n        args : positional arguments\n            Positional arguments are passed directly to ROOT\'s Draw\n        kwargs : keyword arguments\n            The name, title, and style attributes of the clone are\n            taken from ``kwargs``.\n\n        Returns\n        -------\n        The clone.\n        """"""\n        copy = self.Clone(**kwargs)\n        copy.Draw(*args)\n        return copy\n\n\nclass _StyleContainer(object):\n    """"""\n    Base class for grouping together an input style with ROOT and matplotlib\n    styles.\n    """"""\n    def __init__(self, value, function):\n        self._input = value\n        self._root = function(value, \'root\')\n        try:\n            self._mpl = function(value, \'mpl\')\n        except ValueError:\n            self._mpl = self._root\n\n    def __call__(self, output_type=None):\n        if not output_type:\n            output_type = \'input\'\n        return getattr(self, \'_\' + output_type)\n\n    def __repr__(self):\n        return str(self._input)\n\n\n##############################\n#### Markers #################\n\nmarkerstyles_root2mpl = {\n    1: \'.\',\n    2: \'+\',\n    3: \'*\',\n    4: \'o\',\n    5: \'x\',\n    20: \'o\',\n    21: \'s\',\n    22: \'^\',\n    23: \'v\',\n    24: \'o\',\n    25: \'s\',\n    26: \'^\',\n    27: \'d\',\n    28: \'+\',\n    29: \'*\',\n    30: \'*\',\n    31: \'*\',\n    32: \'v\',\n    33: \'D\',\n    34: \'+\',\n    }\nfor i in range(6, 20):\n    markerstyles_root2mpl[i] = \'.\'\n\nmarkerstyles_mpl2root = {\n    \'.\': 1,\n    \',\': 1,\n    \'o\': 4,\n    \'v\': 23,\n    \'^\': 22,\n    \'<\': 23,\n    \'>\': 22,\n    \'1\': 23,\n    \'2\': 22,\n    \'3\': 23,\n    \'4\': 22,\n    \'s\': 25,\n    \'p\': 25,\n    \'*\': 3,\n    \'h\': 25,\n    \'H\': 25,\n    \'+\': 2,\n    \'x\': 5,\n    \'D\': 33,\n    \'d\': 27,\n    \'|\': 2,\n    \'_\': 2,\n    0: 1,  # TICKLEFT\n    1: 1,  # TICKRIGHT\n    2: 1,  # TICKUP\n    3: 1,  # TICKDOWN\n    4: 1,  # CARETLEFT\n    5: 1,  # CARETRIGHT\n    6: 1,  # CARETUP\n    7: 1,  # CARETDOWN\n    \'None\': \'.\',\n    \' \': \'.\',\n    \'\': \'.\',\n    }\n\nmarkerstyles_text2root = {\n    ""smalldot"": 6,\n    ""mediumdot"": 7,\n    ""largedot"": 8,\n    ""dot"": 9,\n    ""circle"": 20,\n    ""square"": 21,\n    ""triangle"": 22,\n    ""triangleup"": 22,\n    ""triangledown"": 23,\n    ""opencircle"": 24,\n    ""opensquare"": 25,\n    ""opentriangle"": 26,\n    ""opendiamond"": 27,\n    ""diamond"": 33,\n    ""opencross"": 28,\n    ""cross"": 34,\n    ""openstar"": 29,\n    ""fullstar"": 30,\n    ""star"": 29,\n    }\n\n\ndef convert_markerstyle(inputstyle, mode, inputmode=None):\n    """"""\n    Convert *inputstyle* to ROOT or matplotlib format.\n\n    Output format is determined by *mode* (\'root\' or \'mpl\').  The *inputstyle*\n    may be a ROOT marker style, a matplotlib marker style, or a description\n    such as \'star\' or \'square\'.\n    """"""\n    mode = mode.lower()\n    if mode not in (\'mpl\', \'root\'):\n        raise ValueError(""`{0}` is not valid `mode`"".format(mode))\n    if inputmode is None:\n        if inputstyle in markerstyles_root2mpl:\n            inputmode = \'root\'\n        elif inputstyle in markerstyles_mpl2root or \'$\' in str(inputstyle):\n            inputmode = \'mpl\'\n        elif inputstyle in markerstyles_text2root:\n            inputmode = \'root\'\n            inputstyle = markerstyles_text2root[inputstyle]\n        else:\n            raise ValueError(\n                ""`{0}` is not a valid `markerstyle`"".format(inputstyle))\n    if inputmode == \'root\':\n        if inputstyle not in markerstyles_root2mpl:\n            raise ValueError(\n                ""`{0}` is not a valid ROOT `markerstyle`"".format(\n                    inputstyle))\n        if mode == \'root\':\n            return inputstyle\n        return markerstyles_root2mpl[inputstyle]\n    else:\n        if \'$\' in str(inputstyle):\n            if mode == \'root\':\n                return 1\n            else:\n                return inputstyle\n        if inputstyle not in markerstyles_mpl2root:\n            raise ValueError(\n                ""`{0}` is not a valid matplotlib `markerstyle`"".format(\n                    inputstyle))\n        if mode == \'mpl\':\n            return inputstyle\n        return markerstyles_mpl2root[inputstyle]\n\n\nclass MarkerStyle(_StyleContainer):\n    """"""\n    Container for grouping together ROOT and matplotlib marker styles.\n\n    The *style* argument to the constructor may be a ROOT marker style,\n    a matplotlib marker style, or one of the following descriptions:\n    """"""\n    __doc__ = __doc__[:__doc__.rfind(\'\\n\') + 1]\n    __doc__ += \'\\n\'.join([""    \'{0}\'"".format(x)\n                          for x in markerstyles_text2root])\n    if sys.version_info[0] < 3:\n        del x\n    __doc__ += """"""\n\n    Examples\n    --------\n\n       >>> style = MarkerStyle(\'opentriangle\')\n       >>> style(\'root\')\n       26\n       >>> style(\'mpl\')\n       \'^\'\n\n    """"""\n    def __init__(self, style):\n        _StyleContainer.__init__(self, style, convert_markerstyle)\n\n\n##############################\n#### Lines ###################\n\nlinestyles_root2mpl = {\n    1: \'solid\',\n    2: \'dashed\',\n    3: \'dotted\',\n    4: \'dashdot\',\n    5: \'dashdot\',\n    6: \'dashdot\',\n    7: \'dashed\',\n    8: \'dashdot\',\n    9: \'dashed\',\n    10: \'dashdot\',\n    }\n\nlinestyles_mpl2root = {\n    \'solid\': 1,\n    \'dashed\': 2,\n    \'dotted\': 3,\n    \'dashdot\': 4,\n    }\n\nlinestyles_text2root = {\n    \'solid\': 1,\n    \'dashed\': 2,\n    \'dotted\': 3,\n    \'dashdot\': 4,\n    \'longdashdot\': 5,\n    \'longdashdotdotdot\': 6,\n    \'longdash\': 7,\n    \'longdashdotdot\': 8,\n    \'verylongdash\': 9,\n    \'verylongdashdot\': 10\n    }\n\n\ndef convert_linestyle(inputstyle, mode, inputmode=None):\n    """"""\n    Convert *inputstyle* to ROOT or matplotlib format.\n\n    Output format is determined by *mode* (\'root\' or \'mpl\').  The *inputstyle*\n    may be a ROOT line style, a matplotlib line style, or a description\n    such as \'solid\' or \'dotted\'.\n    """"""\n    mode = mode.lower()\n    if mode not in (\'mpl\', \'root\'):\n        raise ValueError(\n            ""`{0}` is not a valid `mode`"".format(mode))\n    try:\n        inputstyle = int(inputstyle)\n        if inputstyle < 1:\n            inputstyle = 1\n    except (TypeError, ValueError):\n        pass\n    if inputmode is None:\n        if inputstyle in linestyles_root2mpl:\n            inputmode = \'root\'\n        elif inputstyle in linestyles_mpl2root:\n            inputmode = \'mpl\'\n        elif inputstyle in linestyles_text2root:\n            inputmode = \'root\'\n            inputstyle = linestyles_text2root[inputstyle]\n        else:\n            raise ValueError(\n                ""`{0}` is not a valid `linestyle`"".format(\n                    inputstyle))\n    if inputmode == \'root\':\n        if inputstyle not in linestyles_root2mpl:\n            raise ValueError(\n                ""`{0}` is not a valid ROOT `linestyle`"".format(\n                    inputstyle))\n        if mode == \'root\':\n            return inputstyle\n        return linestyles_root2mpl[inputstyle]\n    else:\n        if inputstyle not in linestyles_mpl2root:\n            raise ValueError(\n                ""`{0}` is not a valid matplotlib `linestyle`"".format(\n                    inputstyle))\n        if mode == \'mpl\':\n            return inputstyle\n        return linestyles_mpl2root[inputstyle]\n\n\nclass LineStyle(_StyleContainer):\n    """"""\n    Container for grouping together ROOT and matplotlib line styles.\n\n    The *style* argument to the constructor may be a ROOT line style,\n    a matplotlib line style, or one of the following descriptions:\n    """"""\n    __doc__ = __doc__[:__doc__.rfind(\'\\n\') + 1]\n    __doc__ += \'\\n\'.join([""    \'{0}\'"".format(x)\n                          for x in linestyles_text2root])\n    if sys.version_info[0] < 3:\n        del x\n    __doc__ += """"""\n\n    Examples\n    --------\n\n       >>> style = LineStyle(\'verylongdashdot\')\n       >>> style(\'root\')\n       10\n       >>> style(\'mpl\')\n       \'dashdot\'\n\n    """"""\n    def __init__(self, style):\n        _StyleContainer.__init__(self, style, convert_linestyle)\n\n\n##############################\n#### Fills ###################\n\nfillstyles_root2mpl = {\n    0: None,\n    1001: None,\n    3003: \'.\',\n    3345: \'\\\\\',\n    3354: \'/\',\n    3006: \'|\',\n    3007: \'-\',\n    3011: \'*\',\n    3012: \'o\',\n    3013: \'x\',\n    3019: \'O\',\n    }\n\nfillstyles_mpl2root = {}\nfor key, value in fillstyles_root2mpl.items():\n    fillstyles_mpl2root[value] = key\nfillstyles_mpl2root[None] = 0\n\nfillstyles_text2root = {\n    \'hollow\': 0,\n    \'none\': 0,\n    \'solid\': 1001,\n    }\n\n\ndef convert_fillstyle(inputstyle, mode, inputmode=None):\n    """"""\n    Convert *inputstyle* to ROOT or matplotlib format.\n\n    Output format is determined by *mode* (\'root\' or \'mpl\').  The *inputstyle*\n    may be a ROOT fill style, a matplotlib hatch style, None, \'none\', \'hollow\',\n    or \'solid\'.\n    """"""\n    mode = mode.lower()\n    if mode not in (\'mpl\', \'root\'):\n        raise ValueError(""`{0}` is not a valid `mode`"".format(mode))\n    if inputmode is None:\n        try:\n            # inputstyle is a ROOT linestyle\n            inputstyle = int(inputstyle)\n            inputmode = \'root\'\n        except (TypeError, ValueError):\n            if inputstyle is None:\n                inputmode = \'mpl\'\n            elif inputstyle in fillstyles_text2root:\n                inputmode = \'root\'\n                inputstyle = fillstyles_text2root[inputstyle]\n            elif inputstyle[0] in fillstyles_mpl2root:\n                inputmode = \'mpl\'\n            else:\n                raise ValueError(\n                    ""`{0}` is not a valid `fillstyle`"".format(inputstyle))\n    if inputmode == \'root\':\n        if mode == \'root\':\n            return inputstyle\n        if inputstyle in fillstyles_root2mpl:\n            return fillstyles_root2mpl[inputstyle]\n        raise ValueError(\n            ""`{0}` is not a valid `fillstyle`"".format(inputstyle))\n    else:\n        if inputstyle is not None and inputstyle[0] not in fillstyles_mpl2root:\n            raise ValueError(\n                ""`{0}` is not a valid matplotlib `fillstyle`"".format(\n                    inputstyle))\n        if mode == \'mpl\':\n            return inputstyle\n        if inputstyle is None:\n            return fillstyles_mpl2root[inputstyle]\n        return fillstyles_mpl2root[inputstyle[0]]\n\n\nclass FillStyle(_StyleContainer):\n    """"""\n    Container for grouping together ROOT and matplotlib fill styles.\n\n    The *style* argument to the constructor may be a ROOT fill style,\n    a matplotlib fill style, or one of the following descriptions:\n    """"""\n    __doc__ = __doc__[:__doc__.rfind(\'\\n\') + 1]\n    __doc__ += \'\\n\'.join([""    \'{0}\'"".format(x)\n                          for x in fillstyles_text2root])\n    if sys.version_info[0] < 3:\n        del x\n    __doc__ += """"""\n\n    For an input value of \'solid\', the matplotlib hatch value will be set to\n    None, which is the same value as for \'hollow\'.  The root2matplotlib\n    functions will all check the ROOT value to see whether to make the fill\n    solid or hollow.\n\n    Examples\n    --------\n\n       >>> style = FillStyle(\'hollow\')\n       >>> style(\'root\')\n       0\n       >>> print style(\'mpl\')\n       None\n\n    """"""\n    def __init__(self, style):\n        _StyleContainer.__init__(self, style, convert_fillstyle)\n\n\n##############################\n#### Colors ##################\n\n_cnames = {\n    \'r\'                    : \'#FF0000\', #@IgnorePep8\n    \'g\'                    : \'#00FF00\',\n    \'b\'                    : \'#0000FF\',\n    \'c\'                    : \'#00BFBF\',\n    \'m\'                    : \'#BF00BF\',\n    \'y\'                    : \'#BFBF00\',\n    \'k\'                    : \'#000000\',\n    \'w\'                    : \'#FFFFFF\',\n    \'aliceblue\'            : \'#F0F8FF\',\n    \'antiquewhite\'         : \'#FAEBD7\',\n    \'aqua\'                 : \'#00FFFF\',\n    \'aquamarine\'           : \'#7FFFD4\',\n    \'azure\'                : \'#F0FFFF\',\n    \'beige\'                : \'#F5F5DC\',\n    \'bisque\'               : \'#FFE4C4\',\n    \'black\'                : \'#000000\',\n    \'blanchedalmond\'       : \'#FFEBCD\',\n    \'blue\'                 : \'#0000FF\',\n    \'blueviolet\'           : \'#8A2BE2\',\n    \'brown\'                : \'#A52A2A\',\n    \'burlywood\'            : \'#DEB887\',\n    \'cadetblue\'            : \'#5F9EA0\',\n    \'chartreuse\'           : \'#7FFF00\',\n    \'chocolate\'            : \'#D2691E\',\n    \'coral\'                : \'#FF7F50\',\n    \'cornflowerblue\'       : \'#6495ED\',\n    \'cornsilk\'             : \'#FFF8DC\',\n    \'crimson\'              : \'#DC143C\',\n    \'cyan\'                 : \'#00FFFF\',\n    \'darkblue\'             : \'#00008B\',\n    \'darkcyan\'             : \'#008B8B\',\n    \'darkgoldenrod\'        : \'#B8860B\',\n    \'darkgray\'             : \'#A9A9A9\',\n    \'darkgreen\'            : \'#006400\',\n    \'darkkhaki\'            : \'#BDB76B\',\n    \'darkmagenta\'          : \'#8B008B\',\n    \'darkolivegreen\'       : \'#556B2F\',\n    \'darkorange\'           : \'#FF8C00\',\n    \'darkorchid\'           : \'#9932CC\',\n    \'darkred\'              : \'#8B0000\',\n    \'darksalmon\'           : \'#E9967A\',\n    \'darkseagreen\'         : \'#8FBC8F\',\n    \'darkslateblue\'        : \'#483D8B\',\n    \'darkslategray\'        : \'#2F4F4F\',\n    \'darkturquoise\'        : \'#00CED1\',\n    \'darkviolet\'           : \'#9400D3\',\n    \'deeppink\'             : \'#FF1493\',\n    \'deepskyblue\'          : \'#00BFFF\',\n    \'dimgray\'              : \'#696969\',\n    \'dodgerblue\'           : \'#1E90FF\',\n    \'firebrick\'            : \'#B22222\',\n    \'floralwhite\'          : \'#FFFAF0\',\n    \'forestgreen\'          : \'#228B22\',\n    \'fuchsia\'              : \'#FF00FF\',\n    \'gainsboro\'            : \'#DCDCDC\',\n    \'ghostwhite\'           : \'#F8F8FF\',\n    \'gold\'                 : \'#FFD700\',\n    \'goldenrod\'            : \'#DAA520\',\n    \'gray\'                 : \'#808080\',\n    \'green\'                : \'#008000\',\n    \'greenyellow\'          : \'#ADFF2F\',\n    \'honeydew\'             : \'#F0FFF0\',\n    \'hotpink\'              : \'#FF69B4\',\n    \'indianred\'            : \'#CD5C5C\',\n    \'indigo\'               : \'#4B0082\',\n    \'ivory\'                : \'#FFFFF0\',\n    \'khaki\'                : \'#F0E68C\',\n    \'lavender\'             : \'#E6E6FA\',\n    \'lavenderblush\'        : \'#FFF0F5\',\n    \'lawngreen\'            : \'#7CFC00\',\n    \'lemonchiffon\'         : \'#FFFACD\',\n    \'lightblue\'            : \'#ADD8E6\',\n    \'lightcoral\'           : \'#F08080\',\n    \'lightcyan\'            : \'#E0FFFF\',\n    \'lightgoldenrodyellow\' : \'#FAFAD2\',\n    \'lightgreen\'           : \'#90EE90\',\n    \'lightgrey\'            : \'#D3D3D3\',\n    \'lightpink\'            : \'#FFB6C1\',\n    \'lightsalmon\'          : \'#FFA07A\',\n    \'lightseagreen\'        : \'#20B2AA\',\n    \'lightskyblue\'         : \'#87CEFA\',\n    \'lightslategray\'       : \'#778899\',\n    \'lightsteelblue\'       : \'#B0C4DE\',\n    \'lightyellow\'          : \'#FFFFE0\',\n    \'lime\'                 : \'#00FF00\',\n    \'limegreen\'            : \'#32CD32\',\n    \'linen\'                : \'#FAF0E6\',\n    \'magenta\'              : \'#FF00FF\',\n    \'maroon\'               : \'#800000\',\n    \'mediumaquamarine\'     : \'#66CDAA\',\n    \'mediumblue\'           : \'#0000CD\',\n    \'mediumorchid\'         : \'#BA55D3\',\n    \'mediumpurple\'         : \'#9370DB\',\n    \'mediumseagreen\'       : \'#3CB371\',\n    \'mediumslateblue\'      : \'#7B68EE\',\n    \'mediumspringgreen\'    : \'#00FA9A\',\n    \'mediumturquoise\'      : \'#48D1CC\',\n    \'mediumvioletred\'      : \'#C71585\',\n    \'midnightblue\'         : \'#191970\',\n    \'mintcream\'            : \'#F5FFFA\',\n    \'mistyrose\'            : \'#FFE4E1\',\n    \'moccasin\'             : \'#FFE4B5\',\n    \'navajowhite\'          : \'#FFDEAD\',\n    \'navy\'                 : \'#000080\',\n    \'oldlace\'              : \'#FDF5E6\',\n    \'olive\'                : \'#808000\',\n    \'olivedrab\'            : \'#6B8E23\',\n    \'orange\'               : \'#FFA500\',\n    \'orangered\'            : \'#FF4500\',\n    \'orchid\'               : \'#DA70D6\',\n    \'palegoldenrod\'        : \'#EEE8AA\',\n    \'palegreen\'            : \'#98FB98\',\n    \'palevioletred\'        : \'#AFEEEE\',\n    \'papayawhip\'           : \'#FFEFD5\',\n    \'peachpuff\'            : \'#FFDAB9\',\n    \'peru\'                 : \'#CD853F\',\n    \'pink\'                 : \'#FFC0CB\',\n    \'plum\'                 : \'#DDA0DD\',\n    \'powderblue\'           : \'#B0E0E6\',\n    \'purple\'               : \'#800080\',\n    \'red\'                  : \'#FF0000\',\n    \'rosybrown\'            : \'#BC8F8F\',\n    \'royalblue\'            : \'#4169E1\',\n    \'saddlebrown\'          : \'#8B4513\',\n    \'salmon\'               : \'#FA8072\',\n    \'sandybrown\'           : \'#FAA460\',\n    \'seagreen\'             : \'#2E8B57\',\n    \'seashell\'             : \'#FFF5EE\',\n    \'sienna\'               : \'#A0522D\',\n    \'silver\'               : \'#C0C0C0\',\n    \'skyblue\'              : \'#87CEEB\',\n    \'slateblue\'            : \'#6A5ACD\',\n    \'slategray\'            : \'#708090\',\n    \'snow\'                 : \'#FFFAFA\',\n    \'springgreen\'          : \'#00FF7F\',\n    \'steelblue\'            : \'#4682B4\',\n    \'tan\'                  : \'#D2B48C\',\n    \'teal\'                 : \'#008080\',\n    \'thistle\'              : \'#D8BFD8\',\n    \'tomato\'               : \'#FF6347\',\n    \'turquoise\'            : \'#40E0D0\',\n    \'violet\'               : \'#EE82EE\',\n    \'wheat\'                : \'#F5DEB3\',\n    \'white\'                : \'#FFFFFF\',\n    \'whitesmoke\'           : \'#F5F5F5\',\n    \'yellow\'               : \'#FFFF00\',\n    \'yellowgreen\'          : \'#9ACD32\',\n    }\n\n\ndef convert_color(color, mode):\n    """"""\n    Convert *color* to a TColor if *mode=\'root\'* or to (r,g,b) if \'mpl\'.\n\n    The *color* argument can be a ROOT TColor or color index, an *RGB*\n    or *RGBA* sequence or a string in any of several forms:\n\n        1) a letter from the set \'rgbcmykw\'\n        2) a hex color string, like \'#00FFFF\'\n        3) a standard name, like \'aqua\'\n        4) a float, like \'0.4\', indicating gray on a 0-1 scale\n\n    if *arg* is *RGBA*, the transparency value will be ignored.\n    """"""\n    mode = mode.lower()\n    if mode not in (\'mpl\', \'root\'):\n        raise ValueError(\n            ""`{0}` is not a valid `mode`"".format(mode))\n    try:\n        # color is an r,g,b tuple\n        color = tuple([float(x) for x in color[:3]])\n        if max(color) > 1.:\n            color = tuple([x / 255. for x in color])\n        if mode == \'root\':\n            return ROOT.TColor.GetColor(*color)\n        return color\n    except (ValueError, TypeError):\n        pass\n    if isinstance(color, string_types):\n        if color in _cnames:\n            # color is a matplotlib letter or an html color name\n            color = _cnames[color]\n        if color[0] == \'#\':\n            # color is a hex value\n            color = color.lstrip(\'#\')\n            lv = len(color)\n            color = tuple(int(color[i:i + lv // 3], 16)\n                          for i in range(0, lv, lv // 3))\n            if lv == 3:\n                color = tuple(x * 16 + x for x in color)\n            return convert_color(color, mode)\n        # color is a shade of gray, i.e. \'0.3\'\n        return convert_color((color, color, color), mode)\n    try:\n        # color is a TColor\n        color = ROOT.TColor(color)\n        color = color.GetRed(), color.GetGreen(), color.GetBlue()\n        return convert_color(color, mode)\n    except (TypeError, ReferenceError):\n        pass\n    try:\n        # color is a ROOT color index\n        if color < 0:\n            color = 0\n        color = ROOT.gROOT.GetColor(color)\n        # Protect against the case a histogram with a custom color\n        # is saved in a ROOT file\n        if not color:\n            # Just return black\n            color = ROOT.gROOT.GetColor(1)\n        color = color.GetRed(), color.GetGreen(), color.GetBlue()\n        return convert_color(color, mode)\n    except (TypeError, ReferenceError):\n        pass\n    raise ValueError(""\'{0!s}\' is not a valid `color`"".format(color))\n\n\nclass Color(_StyleContainer):\n    """"""\n    Container for grouping together ROOT and matplotlib colors.\n\n    The *color* argument to the constructor can be a ROOT TColor or color index.\n    If matplotlib is available, it can also accept an *RGB* or *RGBA* sequence,\n    or a string in any of several forms:\n\n        1) a letter from the set \'rgbcmykw\'\n        2) a hex color string, like \'#00FFFF\'\n        3) a standard name, like \'aqua\'\n        4) a float, like \'0.4\', indicating gray on a 0-1 scale\n\n    if *color* is *RGBA*, the *A* will simply be discarded.\n\n    Examples\n    --------\n\n       >>> color = Color(2)\n       >>> color()\n       2\n       >>> color(\'mpl\')\n       (1.0, 0.0, 0.0)\n       >>> color = Color(\'blue\')\n       >>> color(\'root\')\n       4\n       >>> color(\'mpl\')\n       (0.0, 0.0, 1.0)\n       >>> color = Color(\'0.25\')\n       >>> color(\'mpl\')\n       (0.25, 0.25, 0.25)\n       >>> color(\'root\')\n       924\n\n    """"""\n    def __init__(self, color):\n        _StyleContainer.__init__(self, color, convert_color)\n'"
rootpy/plotting/box.py,0,"b'from __future__ import absolute_import\n\nfrom .. import ROOT, QROOT, asrootpy\nfrom ..base import Object\nfrom .utils import canvases_with\n\n__all__ = [\n    \'Pave\',\n    \'PaveStats\',\n]\n\nANCHORS = (\n    \'upper left\', \'upper right\',\n    \'lower left\', \'lower right\',\n)\n\n\n# This is another _PadBase hack. See this comment on github\n# https://github.com/rootpy/rootpy/pull/342#issuecomment-19864883\n\nclass _Positionable(object):\n\n    def __init__(self, *args, **kwargs):\n        self.anchor = kwargs.pop(\'anchor\', \'upper left\')\n        if self.anchor not in ANCHORS:\n            raise ValueError(\n                ""\'{0}\' is not a valid anchor position. Use one of {1}"".format(\n                    self.anchor, \', \'.join(ANCHORS)))\n        super(_Positionable, self).__init__(*args, **kwargs)\n\n    @property\n    def x1(self):\n        return self.GetX1()\n\n    @property\n    def x2(self):\n        return self.GetX2()\n\n    @property\n    def y1(self):\n        return self.GetY1()\n\n    @property\n    def y2(self):\n        return self.GetY2()\n\n    @x1.setter\n    def x1(self, value):\n        self.SetX1(value)\n\n    @x2.setter\n    def x2(self, value):\n        self.SetX2(value)\n\n    @y1.setter\n    def y1(self, value):\n        self.SetY1(value)\n\n    @y2.setter\n    def y2(self, value):\n        self.SetY2(value)\n\n    @property\n    def x1_pixels(self):\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before setting position in pixels"")\n        width = float(pad.width_pixels)\n        return int(self.GetX1() * width)\n\n    @property\n    def x2_pixels(self):\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before setting position in pixels"")\n        width = float(pad.width_pixels)\n        return int(self.GetX2() * width)\n\n    @property\n    def y1_pixels(self):\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before setting position in pixels"")\n        height = float(pad.height_pixels)\n        return int(self.GetY1() * height)\n\n    @property\n    def y2_pixels(self):\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before setting position in pixels"")\n        height = float(pad.height_pixels)\n        return int(self.GetY2() * height)\n\n    @x1_pixels.setter\n    def x1_pixels(self, value):\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before setting position in pixels"")\n        width = float(pad.width_pixels)\n        self.SetX1(value / width)\n\n    @x2_pixels.setter\n    def x2_pixels(self, value):\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before setting position in pixels"")\n        width = float(pad.width_pixels)\n        self.SetX2(value / width)\n\n    @y1_pixels.setter\n    def y1_pixels(self, value):\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before setting position in pixels"")\n        height = float(pad.height_pixels)\n        self.SetY1(value / height)\n\n    @y2_pixels.setter\n    def y2_pixels(self, value):\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before setting position in pixels"")\n        height = float(pad.height_pixels)\n        self.SetY2(value / height)\n\n    @property\n    def position(self):\n        return (self.GetX1(), self.GetY1(),\n                self.GetX2(), self.GetY2())\n\n    @position.setter\n    def position(self, value):\n        x1, y1, x2, y2 = value\n        self.SetX1(x1)\n        self.SetY1(y1)\n        self.SetX2(x2)\n        self.SetY2(y2)\n        for c in canvases_with(self):\n            c.Modified()\n\n    @property\n    def position_pixels(self):\n        x1, y1, x2, y2 = self.position\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before setting position in pixels"")\n        width = pad.width_pixels\n        height = pad.height_pixels\n        return (int(x1 * width), int(y1 * height),\n                int(x2 * width), int(y2 * height))\n\n    @position_pixels.setter\n    def position_pixels(self, value):\n        x1, y1, x2, y2 = value\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before getting position in pixels"")\n        width = float(pad.width_pixels)\n        height = float(pad.height_pixels)\n        self.position = (x1 / width, y1 / height,\n                         x2 / width, y2 / height)\n\n    @property\n    def height(self):\n        return abs(self.GetY2() - self.GetY1())\n\n    @property\n    def width(self):\n        return abs(self.GetX2() - self.GetX1())\n\n    @height.setter\n    def height(self, value):\n        if \'upper\' in self.anchor:\n            self.SetY1(self.GetY2() - value)\n        else:\n            self.SetY2(self.GetY1() + value)\n\n    @width.setter\n    def width(self, value):\n        if \'left\' in self.anchor:\n            self.SetX2(self.GetX1() + value)\n        else:\n            self.SetX1(self.GetX2() - value)\n\n    @property\n    def height_pixels(self):\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before getting position in pixels"")\n        return int(self.height * pad.height_pixels)\n\n    @property\n    def width_pixels(self):\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before getting position in pixels"")\n        return int(self.width * pad.width_pixels)\n\n    @height_pixels.setter\n    def height_pixels(self, value):\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before getting position in pixels"")\n        if \'upper\' in self.anchor:\n            self.SetY1(self.GetY2() - value / float(pad.height_pixels))\n        else:\n            self.SetY2(self.GetY1() + value / float(pad.height_pixels))\n\n    @width_pixels.setter\n    def width_pixels(self, value):\n        pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(\n                ""create a pad before getting position in pixels"")\n        if \'left\' in self.anchor:\n            self.SetX2(self.GetX1() + value / float(pad.width_pixels))\n        else:\n            self.SetX1(self.GetX2() - value / float(pad.width_pixels))\n\n\nclass Pave(_Positionable, Object, QROOT.TPave):\n    _ROOT = QROOT.TPave\n\n\nclass PaveStats(_Positionable, Object, QROOT.TPaveStats):\n    _ROOT = QROOT.TPaveStats\n'"
rootpy/plotting/canvas.py,0,"b'""""""\nThis module implements python classes which inherit from\nand extend the functionality of the ROOT canvas classes.\n""""""\nfrom __future__ import absolute_import\n\nfrom .. import ROOT, QROOT, asrootpy\nfrom .base import convert_color\nfrom ..base import NamedObject\nfrom ..context import invisible_canvas\nfrom ..decorators import snake_case_methods\nfrom ..memory.keepalive import keepalive\n\nfrom array import array\n\n__all__ = [\n    \'Pad\',\n    \'Canvas\',\n]\n\n\nclass _PadBase(NamedObject):\n\n    # https://sft.its.cern.ch/jira/browse/ROOT-9007\n    # can remove this after 6.10/04\n    EmitVA = None\n\n    def cd(self, *args):\n        pad = asrootpy(super(_PadBase, self).cd(*args))\n        if pad and pad is not self:\n            keepalive(self, pad)\n        return pad\n\n    def axes(self, ndim=1,\n             xlimits=None, ylimits=None, zlimits=None,\n             xbins=1, ybins=1, zbins=1):\n        """"""\n        Create and return axes on this pad\n        """"""\n        if xlimits is None:\n            xlimits = (0, 1)\n        if ylimits is None:\n            ylimits = (0, 1)\n        if zlimits is None:\n            zlimits = (0, 1)\n        if ndim == 1:\n            from .hist import Hist\n            hist = Hist(1, xlimits[0], xlimits[1])\n        elif ndim == 2:\n            from .hist import Hist2D\n            hist = Hist2D(1, xlimits[0], xlimits[1],\n                          1, ylimits[0], ylimits[1])\n        elif ndim == 3:\n            from .hist import Hist3D\n            hist = Hist3D(1, xlimits[0], xlimits[1],\n                          1, ylimits[0], ylimits[1],\n                          1, zlimits[0], zlimits[1])\n        else:\n            raise ValueError(""ndim must be 1, 2, or 3"")\n        with self:\n            hist.Draw(\'AXIS\')\n        xaxis = hist.xaxis\n        yaxis = hist.yaxis\n        if isinstance(xbins, (list, tuple)):\n            xbins = array(\'d\', xbins)\n        if hasattr(xbins, \'__iter__\'):\n            xaxis.Set(len(xbins) - 1, xbins)\n        else:\n            xaxis.Set(xbins, *xlimits)\n        if ndim > 1:\n            if isinstance(ybins, (list, tuple)):\n                ybins = array(\'d\', ybins)\n            if hasattr(ybins, \'__iter__\'):\n                yaxis.Set(len(ybins) - 1, ybins)\n            else:\n                yaxis.Set(ybins, *ylimits)\n        else:\n            yaxis.limits = ylimits\n            yaxis.range_user = ylimits\n        if ndim > 1:\n            zaxis = hist.zaxis\n            if ndim == 3:\n                if isinstance(zbins, (list, tuple)):\n                    zbins = array(\'d\', zbins)\n                if hasattr(zbins, \'__iter__\'):\n                    zaxis.Set(len(zbins) - 1, zbins)\n                else:\n                    zaxis.Set(zbins, *zlimits)\n            else:\n                zaxis.limits = zlimits\n                zaxis.range_user = zlimits\n            return xaxis, yaxis, zaxis\n        return xaxis, yaxis\n\n    @property\n    def primitives(self):\n        return asrootpy(self.GetListOfPrimitives())\n\n    def find_all_primitives(self):\n        """"""\n        Recursively find all primities on a pad, even those hiding behind a\n        GetListOfFunctions() of a primitive\n        """"""\n        # delayed import to avoid circular import\n        from .utils import find_all_primitives\n        return find_all_primitives(self)\n\n    @property\n    def canvas(self):\n        return asrootpy(self.GetCanvas())\n\n    @property\n    def mother(self):\n        return asrootpy(self.GetMother())\n\n    @property\n    def margin(self):\n        return (self.GetLeftMargin(), self.GetRightMargin(),\n                self.GetBottomMargin(), self.GetTopMargin())\n\n    @margin.setter\n    def margin(self, bounds):\n        left, right, bottom, top = bounds\n        super(_PadBase, self).SetMargin(left, right, bottom, top)\n\n    @property\n    def margin_pixels(self):\n        left, right, bottom, top = self.margin\n        width = self.width_pixels\n        height = self.height_pixels\n        return (int(left * width), int(right * width),\n                int(bottom * height), int(top * height))\n\n    @margin_pixels.setter\n    def margin_pixels(self, bounds):\n        left, right, bottom, top = bounds\n        width = float(self.width_pixels)\n        height = float(self.height_pixels)\n        super(_PadBase, self).SetMargin(left / width, right / width,\n                                        bottom / height, top / height)\n\n    @property\n    def range(self):\n        x1, y1 = ROOT.Double(), ROOT.Double()\n        x2, y2 = ROOT.Double(), ROOT.Double()\n        super(_PadBase, self).GetRange(x1, y1, x2, y2)\n        return x1, y1, x2, y2\n\n    @range.setter\n    def range(self, bounds):\n        x1, y1, x2, y2 = bounds\n        super(_PadBase, self).Range(x1, y1, x2, y2)\n\n    @property\n    def range_axis(self):\n        x1, y1 = ROOT.Double(), ROOT.Double()\n        x2, y2 = ROOT.Double(), ROOT.Double()\n        super(_PadBase, self).GetRangeAxis(x1, y1, x2, y2)\n        return x1, y1, x2, y2\n\n    @range_axis.setter\n    def range_axis(self, bounds):\n        x1, y1, x2, y2 = bounds\n        super(_PadBase, self).RangeAxis(x1, y1, x2, y2)\n\n    def __enter__(self):\n        self._prev_pad = ROOT.gPad\n        self.cd()\n        return self\n\n    def __exit__(self, type, value, traceback):\n        # similar to preserve_current_canvas in rootpy/context.py\n        if self._prev_pad:\n            self._prev_pad.cd()\n        elif ROOT.gPad:\n            # Put things back how they were before.\n            with invisible_canvas():\n                # This is a round-about way of resetting gPad to None.\n                # No other technique I tried could do it.\n                pass\n        self._prev_pad = None\n        return False\n\n\n@snake_case_methods\nclass Pad(_PadBase, QROOT.TPad):\n    _ROOT = QROOT.TPad\n\n    def __init__(self, xlow, ylow, xup, yup,\n                 color=-1,\n                 bordersize=-1,\n                 bordermode=-2,\n                 name=None,\n                 title=None):\n        color = convert_color(color, \'root\')\n        super(Pad, self).__init__(xlow, ylow, xup, yup,\n                                  color, bordersize, bordermode,\n                                  name=name,\n                                  title=title)\n\n    def Draw(self, *args):\n        ret = super(Pad, self).Draw(*args)\n        canvas = self.GetCanvas()\n        keepalive(canvas, self)\n        return ret\n\n    @property\n    def width(self):\n        return self.GetWNDC()\n\n    @property\n    def height(self):\n        return self.GetHNDC()\n\n    @property\n    def width_pixels(self):\n        mother = self.mother\n        canvas = self.canvas\n        w = self.GetWNDC()\n        while mother is not canvas:\n            w *= mother.GetWNDC()\n            mother = mother.mother\n        return int(w * mother.width)\n\n    @property\n    def height_pixels(self):\n        mother = self.mother\n        canvas = self.canvas\n        h = self.GetHNDC()\n        while mother is not canvas:\n            h *= mother.GetHNDC()\n            mother = mother.mother\n        return int(h * mother.height)\n\n\n@snake_case_methods\nclass Canvas(_PadBase, QROOT.TCanvas):\n    _ROOT = QROOT.TCanvas\n\n    def __init__(self,\n                 width=None, height=None,\n                 x=None, y=None,\n                 name=None, title=None,\n                 size_includes_decorations=False):\n        # The following line will trigger finalSetup and start the graphics\n        # thread if not started already\n        style = ROOT.gStyle\n        if width is None:\n            width = style.GetCanvasDefW()\n        if height is None:\n            height = style.GetCanvasDefH()\n        if x is None:\n            x = style.GetCanvasDefX()\n        if y is None:\n            y = style.GetCanvasDefY()\n        super(Canvas, self).__init__(x, y, width, height,\n                                     name=name, title=title)\n        if not size_includes_decorations:\n            # Canvas dimensions include the window manager\'s decorations by\n            # default in vanilla ROOT. I think this is a bad default.\n            # Since in the most common case I don\'t care about the window\n            # decorations, the default will be to set the dimensions of the\n            # paintable area of the canvas.\n            if self.IsBatch():\n                self.SetCanvasSize(width, height)\n            else:\n                self.SetWindowSize(width + (width - self.GetWw()),\n                                   height + (height - self.GetWh()))\n        self.size_includes_decorations = size_includes_decorations\n\n    @property\n    def width(self):\n        return self.GetWw()\n\n    @width.setter\n    def width(self, value):\n        value = int(value)\n        if self.IsBatch():\n            self.SetCanvasSize(value, self.GetWh())\n        else:\n            curr_height = self.GetWh()\n            self.SetWindowSize(value, curr_height)\n            if not getattr(self, \'size_includes_decorations\', False):\n                self.SetWindowSize(value + (value - self.GetWw()),\n                                   curr_height + (curr_height - self.GetWh()))\n\n    @property\n    def width_pixels(self):\n        return self.GetWw()\n\n    @width_pixels.setter\n    def width_pixels(self, value):\n        self.width = value\n\n    @property\n    def height(self):\n        return self.GetWh()\n\n    @height.setter\n    def height(self, value):\n        value = int(value)\n        if self.IsBatch():\n            self.SetCanvasSize(self.GetWw(), value)\n        else:\n            curr_width = self.GetWw()\n            self.SetWindowSize(curr_width, value)\n            if not getattr(self, \'size_includes_decorations\', False):\n                self.SetWindowSize(curr_width + (curr_width - self.GetWw()),\n                                   value + (value - self.GetWh()))\n\n    @property\n    def height_pixels(self):\n        return self.GetWh()\n\n    @height_pixels.setter\n    def height_pixels(self, value):\n        self.height = value\n'"
rootpy/plotting/func.py,0,"b""from __future__ import absolute_import\n\nfrom .. import QROOT\nfrom ..decorators import snake_case_methods\nfrom .base import Plottable\nfrom ..base import NameOnlyObject\nimport six\n\n__all__ = [\n    'F1',\n    'F2',\n    'F3',\n]\n\nclass BaseFunction(object):\n    class ParProxy(object):\n        def __init__(self, fcn, idx):\n            self.fcn_ = fcn\n            self.idx_ = idx\n\n        @property\n        def index(self):\n            return self.idx_\n\n        @property\n        def name(self):\n            return self.fcn_.GetParName(self.idx_)\n\n        @name.setter\n        def name(self, val):\n            return self.fcn_.SetParName(self.idx_, val)\n\n        @property\n        def value(self):\n            return self.fcn_.GetParameter(self.idx_)\n\n        @value.setter\n        def value(self, val):\n            self.fcn_.SetParameter(self.idx_, val)\n\n        @property\n        def error(self):\n            return self.fcn_.GetParError(self.idx_)\n\n        @error.setter\n        def error(self, val):\n            return self.fcn_.SetParError(self.idx_, val)\n\n        @property\n        def limits(self):\n            m = QROOT.Double()\n            M = QROOT.Double()\n            self.fcn_.GetParLimits(self.idx_, m, M)\n            return float(m), float(M)\n\n        @limits.setter\n        def limits(self, val):\n            if not hasattr(val, '__len__') and len(val) != 2:\n                raise RuntimeError('Function limits must be a tuple size 2')\n            self.fcn_.SetParLimits(self.idx_, val[0], val[1])\n\n    def __getitem__(self, value):\n        if isinstance(value, six.string_types):\n            idx = self.GetParNumber(value)\n        elif isinstance(value, six.integer_types):\n            idx = value\n        else:\n            raise ValueError('Function index must be a integer or a string')\n        return BaseFunction.ParProxy(self, idx)\n\n\n@snake_case_methods\nclass F1(Plottable, NameOnlyObject, BaseFunction, QROOT.TF1):\n    _ROOT = QROOT.TF1\n\n    def __init__(self, *args, **kwargs):\n        name = kwargs.pop('name', None)\n        super(F1, self).__init__(*args, name=name)\n        self._post_init(**kwargs)\n\n\n@snake_case_methods\nclass F2(Plottable, NameOnlyObject, BaseFunction, QROOT.TF2):\n    _ROOT = QROOT.TF2\n\n    def __init__(self, *args, **kwargs):\n        name = kwargs.pop('name', None)\n        super(F2, self).__init__(*args, name=name)\n        self._post_init(**kwargs)\n\n\n@snake_case_methods\nclass F3(Plottable, NameOnlyObject, BaseFunction, QROOT.TF3):\n    _ROOT = QROOT.TF3\n\n    def __init__(self, *args, **kwargs):\n        name = kwargs.pop('name', None)\n        super(F3, self).__init__(*args, name=name)\n        self._post_init(**kwargs)\n"""
rootpy/plotting/graph.py,0,"b'from __future__ import absolute_import\n\nimport math\nimport numbers\nfrom operator import add, sub\n\nimport ROOT\n\nfrom .. import log; log = log[__name__]\nfrom .. import QROOT\nfrom ..extern.six.moves import range\nfrom ..base import NamelessConstructorObject\nfrom ..decorators import snake_case_methods\nfrom .base import Plottable\n\n__all__ = [\n    \'Graph\',\n    \'Graph1D\',\n    \'Graph2D\',\n]\n\n\nclass _GraphBase(object):\n\n    class GraphPoint(object):\n        """"""\n\tClass similar to BinProxy for histograms, useful for\n\tgetting single point information\n\t""""""\n        class Measurement(object):\n            """"""\n\t    Generalized measusement class, each graph point\n\t    has one for each axis\n\t    """"""\n            def __init__(self, graph, axis, idx):\n                self.isdefault = not hasattr(graph, axis)\n                self.axis_ = axis\n                self.index_ = idx\n                self.graph_ = graph\n\n            @property\n            def value(self):\n                return 0. if self.isdefault else getattr(self.graph_, self.axis_)(self.index_)\n\n            @value.setter\n            def value(self, value):\n                axes = [\'x\', \'y\']\n                if hasattr(self.graph_, \'z\'):\n                    axes.append(\'z\')\n                vals = []\n                for axis in axes:\n                    if axis == self.axis_:\n                        vals.append(value)\n                    else:\n                        vals.append(\n                            getattr(\n                                self.graph_,\n                                axis)(self.index_)\n                            )\n                self.graph_.SetPoint(self.index_, *vals)\n\n            @property\n            def error(self):\n                return 0. if self.isdefault else getattr(\n                    self.graph_,\n                    \'{0}err\'.format(self.axis_)\n                    )(self.index_)\n\n            @property\n            def error_hi(self):\n                return 0. if self.isdefault else getattr(\n                    self.graph_,\n                    \'{0}errh\'.format(self.axis_)\n                    )(self.index_)\n\n            @error_hi.setter\n            def error_hi(self, val):\n                if self.isdefault: return\n                getattr(\n                    self.graph_,\n                    \'SetPointE{0}high\'.format(self.axis_.upper())\n                    )(self.index_, val)\n\n            @property\n            def error_low(self):\n                return 0. if self.isdefault else getattr(\n                    self.graph_,\n                    \'{0}errl\'.format(self.axis_)\n                    )(self.index_)\n\n            @error_low.setter\n            def error_low(self, val):\n                if self.isdefault: return\n                getattr(\n                    self.graph_,\n                    \'SetPointE{0}low\'.format(self.axis_.upper())\n                    )(self.index_, val)\n\n\n            @property\n            def error_avg(self):\n                return 0. if self.isdefault else getattr(\n                    self.graph_,\n                    \'{0}erravg\'.format(self.axis_)\n                    )(self.index_)\n\n            @property\n            def error_max(self):\n                return 0. if self.isdefault else getattr(\n                    self.graph_,\n                    \'{0}errmax\'.format(self.axis_)\n                    )(self.index_)\n\n        def __init__(self, graph, idx):\n            self.graph_ = graph\n            self.idx_ = idx\n\n        @property\n        def x(self):\n            """"""returns the x coordinate\n            """"""\n            return _GraphBase.GraphPoint.Measurement(self.graph_, \'x\', self.idx_)\n\n        @property\n        def y(self):\n            """"""returns the y coordinate\n            """"""\n            return _GraphBase.GraphPoint.Measurement(self.graph_, \'y\', self.idx_)\n\n        @property\n        def z(self):\n            """"""returns the z coordinate\n            """"""\n            return _GraphBase.GraphPoint.Measurement(self.graph_, \'z\', self.idx_)\n\n    @classmethod\n    def from_file(cls, filename, sep=\' \', name=None, title=None):\n        with open(filename, \'r\') as gfile:\n            lines = gfile.readlines()\n        numpoints = len(lines)\n        graph = cls(numpoints, name=name, title=title)\n        for idx, line in enumerate(lines):\n            point = list(map(float, line.rstrip().split(sep)))\n            if len(point) != cls.DIM + 1:\n                raise ValueError(\n                    ""line {0:d} does not contain ""\n                    ""{1:d} values: {2}"".format(\n                        idx + 1, cls.DIM + 1, line))\n            graph.SetPoint(idx, *point)\n        graph.Set(numpoints)\n        return graph\n\n    def __len__(self):\n        return self.GetN()\n\n    def __iter__(self):\n        for index in range(len(self)):\n            yield self[index]\n\n    @property\n    def num_points(self):\n        return self.GetN()\n\n    @num_points.setter\n    def num_points(self, n):\n        if n < 0:\n            raise ValueError(""number of points in a graph must ""\n                             ""be non-negative"")\n        # ROOT, why not SetN with GetN?\n        self.Set(n)\n\n    def x(self, index=None):\n        if index is None:\n            return (self.GetX()[i] for i in range(self.GetN()))\n        index = index % len(self)\n        return self.GetX()[index]\n\n    def xerr(self, index=None):\n        if index is None:\n            return ((self.GetEXlow()[i], self.GetEXhigh()[i])\n                    for i in range(self.GetN()))\n        index = index % len(self)\n        return (self.GetErrorXlow(index), self.GetErrorXhigh(index))\n\n    def xerrh(self, index=None):\n        if index is None:\n            return (self.GetEXhigh()[i] for i in range(self.GetN()))\n        index = index % len(self)\n        return self.GetErrorXhigh(index)\n\n    def xerrl(self, index=None):\n        if index is None:\n            return (self.GetEXlow()[i] for i in range(self.GetN()))\n        index = index % len(self)\n        return self.GetErrorXlow(index)\n\n    def xerravg(self, index=None):\n        if index is None:\n            return (self.xerravg(i) for i in range(self.GetN()))\n        index = index % len(self)\n        return math.sqrt(self.GetErrorXhigh(index) ** 2 +\n                         self.GetErrorXlow(index) ** 2)\n\n    def xerrmax(self, index=None):\n        if index is None:\n            return (self.xerravg(i) for i in range(self.GetN()))\n        index = index % len(self)\n        return max(self.GetErrorXhigh(index),\n                   self.GetErrorXlow(index))\n\n    def y(self, index=None):\n        if index is None:\n            return (self.GetY()[i] for i in range(self.GetN()))\n        index = index % len(self)\n        return self.GetY()[index]\n\n    def yerr(self, index=None):\n        if index is None:\n            return (self.yerr(i) for i in range(self.GetN()))\n        index = index % len(self)\n        return (self.GetErrorYlow(index), self.GetErrorYhigh(index))\n\n    def yerrh(self, index=None):\n        if index is None:\n            return (self.GetEYhigh()[i] for i in range(self.GetN()))\n        index = index % len(self)\n        return self.GetEYhigh()[index]\n\n    def yerrl(self, index=None):\n        if index is None:\n            return (self.GetEYlow()[i] for i in range(self.GetN()))\n        index = index % len(self)\n        return self.GetEYlow()[index]\n\n    def yerravg(self, index=None):\n        if index is None:\n            return (self.yerravg()[i] for i in range(self.GetN()))\n        index = index % len(self)\n        return math.sqrt(self.GetEYhigh()[index] ** 2 +\n                         self.GetEYlow()[index] ** 2)\n\n    def yerravg(self, index=None):\n        if index is None:\n            return (self.yerravg()[i] for i in range(self.GetN()))\n        index = index % len(self)\n        return max(self.GetEYhigh()[index],\n                   self.GetEYlow()[index])\n\n    def __getitem__(self, idx):\n        return _GraphBase.GraphPoint(self, idx)\n\n    def __setitem__(self, index, point):\n        if not 0 <= index <= self.GetN():\n            raise IndexError(""graph point index out of range"")\n        self.SetPoint(index, *point)\n\n\nclass _Graph1DBase(_GraphBase):\n\n    @classmethod\n    def divide(cls, top, bottom, option=\'cp\'):\n        from .hist import Hist\n        if isinstance(top, _Graph1DBase):\n            top = Hist(top)\n        if isinstance(bottom, _Graph1DBase):\n            bottom = Hist(bottom)\n        ratio = Graph(type=\'asymm\')\n        ratio.Divide(top, bottom, option)\n        return ratio\n\n    def __add__(self, other):\n        copy = self.Clone()\n        copy += other\n        return copy\n\n    def __radd__(self, other):\n        return self + other\n\n    def __sub__(self, other):\n        copy = self.Clone()\n        copy -= other\n        return copy\n\n    def __rsub__(self, other):\n        return -1 * (self - other)\n\n    def __div__(self, other):\n        copy = self.Clone()\n        copy /= other\n        return copy\n\n    __truediv__ = __div__\n\n    def __mul__(self, other):\n        copy = self.Clone()\n        copy *= other\n        return copy\n\n    def __rmul__(self, other):\n        return self * other\n\n    def __iadd__(self, other):\n        if isinstance(other, numbers.Real):\n            for index in range(len(self)):\n                point = self[index]\n                self.SetPoint(index, point.x.value, point.y.value + other)\n            return self\n        for index in range(len(self)):\n            mypoint = self[index]\n            otherpoint = other[index]\n            xlow = self.GetEXlow()[index]\n            xhigh = self.GetEXhigh()[index]\n            ylow = math.sqrt((self.GetEYlow()[index]) ** 2 +\n                            (other.GetEYlow()[index]) ** 2)\n            yhigh = math.sqrt((self.GetEYhigh()[index]) ** 2 +\n                                (other.GetEYhigh()[index]) ** 2)\n            self.SetPoint(index, mypoint.x.value, mypoint.y.value + otherpoint.y.value)\n            self.SetPointError(index, xlow, xhigh, ylow, yhigh)\n        return self\n\n    def __isub__(self, other):\n        if isinstance(other, numbers.Real):\n            for index in range(len(self)):\n                point = self[index]\n                self.SetPoint(index, point.x.value, point.y.value - other)\n            return self\n        for index in range(len(self)):\n            mypoint = self[index]\n            otherpoint = other[index]\n            xlow = self.GetEXlow()[index]\n            xhigh = self.GetEXhigh()[index]\n            ylow = math.sqrt((self.GetEYlow()[index]) ** 2 +\n                            (other.GetEYlow()[index]) ** 2)\n            yhigh = math.sqrt((self.GetEYhigh()[index]) ** 2 +\n                                (other.GetEYhigh()[index]) ** 2)\n            self.SetPoint(index, mypoint.x.value, mypoint.y.value - otherpoint.y.value)\n            self.SetPointError(index, xlow, xhigh, ylow, yhigh)\n        return self\n\n    def __idiv__(self, other):\n        if isinstance(other, numbers.Real):\n            for index in range(len(self)):\n                point = self[index]\n                ylow, yhigh = self.GetEYlow()[index], self.GetEYhigh()[index]\n                xlow, xhigh = self.GetEXlow()[index], self.GetEXhigh()[index]\n                self.SetPoint(index, point.x.value, point.y.value / other)\n                self.SetPointError(index, xlow, xhigh,\n                                   ylow / other, yhigh / other)\n            return self\n        for index in range(len(self)):\n            mypoint = self[index]\n            otherpoint = other[index]\n            xlow = self.GetEXlow()[index]\n            xhigh = self.GetEXhigh()[index]\n            ylow = (\n                (mypoint.y.value / otherpoint.y.value) *\n                math.sqrt((self.GetEYlow()[index] / mypoint.y.value) ** 2 +\n                            (other.GetEYlow()[index] /\n                                otherpoint.y.value) ** 2))\n            yhigh = (\n                (mypoint.y.value / otherpoint.y.value) *\n                math.sqrt((self.GetEYhigh()[index] / mypoint.y.value) ** 2 +\n                            (other.GetEYhigh()[index] /\n                                otherpoint.y.value) ** 2))\n            self.SetPoint(index, mypoint.x.value, mypoint.y.value / otherpoint.y.value)\n            self.SetPointError(index, xlow, xhigh, ylow, yhigh)\n        return self\n\n    __itruediv__ = __idiv__\n\n    def __imul__(self, other):\n        if isinstance(other, numbers.Real):\n            for index in range(len(self)):\n                point = self[index]\n                ylow, yhigh = self.GetEYlow()[index], self.GetEYhigh()[index]\n                xlow, xhigh = self.GetEXlow()[index], self.GetEXhigh()[index]\n                self.SetPoint(index, point.x.value, point.y.value * other)\n                self.SetPointError(index, xlow, xhigh,\n                                   ylow * other, yhigh * other)\n            return self\n        for index in range(len(self)):\n            mypoint = self[index]\n            otherpoint = other[index]\n            xlow = self.GetEXlow()[index]\n            xhigh = self.GetEXhigh()[index]\n            ylow = (\n                (mypoint.y.value * otherpoint.y.value) *\n                math.sqrt((self.GetEYlow()[index] / mypoint.y.value) ** 2 +\n                            (other.GetEYlow()[index] / otherpoint.y.value) ** 2))\n            yhigh = (\n                (mypoint.y.value * otherpoint.y.value) *\n                math.sqrt((self.GetEYhigh()[index] / mypoint.y.value) ** 2 +\n                            (other.GetEYhigh()[index] / otherpoint.y.value) ** 2))\n            self.SetPoint(index, mypoint.x.value, mypoint.y.value * otherpoint.y.value)\n            self.SetPointError(index, xlow, xhigh, ylow, yhigh)\n        return self\n\n    def GetMaximum(self, include_error=False):\n        if not include_error:\n            return self.GetYmax()\n        summed = map(add, self.y(), self.yerrh())\n        return max(summed)\n\n    def GetMinimum(self, include_error=False):\n        if not include_error:\n            return self.GetYmin()\n        summed = map(sub, self.y(), self.yerrl())\n        return min(summed)\n\n    def GetXmin(self):\n        if len(self) == 0:\n            raise ValueError(""Attemping to get xmin of empty graph"")\n        return min(list(self.x()))\n\n    def GetXmax(self):\n        if len(self) == 0:\n            raise ValueError(""Attempting to get xmax of empty graph"")\n        return max(list(self.x()))\n\n    def GetYmin(self):\n        if len(self) == 0:\n            raise ValueError(""Attempting to get ymin of empty graph"")\n        return min(list(self.y()))\n\n    def GetYmax(self):\n        if len(self) == 0:\n            raise ValueError(""Attempting to get ymax of empty graph!"")\n        return max(list(self.y()))\n\n    def GetEXhigh(self):\n        if isinstance(self, ROOT.TGraphErrors):\n            return self.GetEX()\n        return super(_Graph1DBase, self).GetEXhigh()\n\n    def GetEXlow(self):\n        if isinstance(self, ROOT.TGraphErrors):\n            return self.GetEX()\n        return super(_Graph1DBase, self).GetEXlow()\n\n    def GetEYhigh(self):\n        if isinstance(self, ROOT.TGraphErrors):\n            return self.GetEY()\n        return super(_Graph1DBase, self).GetEYhigh()\n\n    def GetEYlow(self):\n        if isinstance(self, ROOT.TGraphErrors):\n            return self.GetEY()\n        return super(_Graph1DBase, self).GetEYlow()\n\n    def Crop(self, x1, x2, copy=False):\n        """"""\n        Remove points which lie outside of [x1, x2].\n        If x1 and/or x2 is below/above the current lowest/highest\n        x-coordinates, additional points are added to the graph using a\n        linear interpolation\n        """"""\n        numPoints = self.GetN()\n        if copy:\n            cropGraph = self.Clone()\n            copyGraph = self\n        else:\n            cropGraph = self\n            copyGraph = self.Clone()\n        cropGraph.Set(0)\n        X = copyGraph.GetX()\n        EXlow = copyGraph.GetEXlow()\n        EXhigh = copyGraph.GetEXhigh()\n        Y = copyGraph.GetY()\n        EYlow = copyGraph.GetEYlow()\n        EYhigh = copyGraph.GetEYhigh()\n        xmin = copyGraph.GetXmin()\n        if x1 < xmin-EXlow[0]:\n            cropGraph.Set(numPoints + 1)\n        xmax = copyGraph.GetXmax()\n        if x2 > xmax+EXhigh[numPoints-1]:\n            cropGraph.Set(numPoints + 1)\n        index = 0\n        for i in range(numPoints):\n            if i == 0 and x1 < xmin:\n                cropGraph.SetPoint(0, x1, copyGraph.Eval(x1))\n                index += 1\n            elif i == numPoints-1 and x2 > xmax+EXhigh[i]:\n                cropGraph.SetPoint(i, x2, copyGraph.Eval(x2))\n            if x1<=X[i]-EXlow[i] and X[i]+EXhigh[i]<=x2:\n                cropGraph.SetPoint(index, X[i], Y[i])\n                cropGraph.SetPointError(\n                    index,\n                    EXlow[i], EXhigh[i],\n                    EYlow[i], EYhigh[i])\n                index += 1\n        return cropGraph\n\n    def Reverse(self, copy=False):\n        """"""\n        Reverse the order of the points\n        """"""\n        numPoints = self.GetN()\n        if copy:\n            revGraph = self.Clone()\n        else:\n            revGraph = self\n        X = self.GetX()\n        EXlow = self.GetEXlow()\n        EXhigh = self.GetEXhigh()\n        Y = self.GetY()\n        EYlow = self.GetEYlow()\n        EYhigh = self.GetEYhigh()\n        for i in range(numPoints):\n            index = numPoints - 1 - i\n            revGraph.SetPoint(i, X[index], Y[index])\n            revGraph.SetPointError(\n                i,\n                EXlow[index], EXhigh[index],\n                EYlow[index], EYhigh[index])\n        return revGraph\n\n    def Invert(self, copy=False):\n        """"""\n        Interchange the x and y coordinates of all points\n        """"""\n        numPoints = self.GetN()\n        if copy:\n            invGraph = self.Clone()\n        else:\n            invGraph = self\n        X = self.GetX()\n        EXlow = self.GetEXlow()\n        EXhigh = self.GetEXhigh()\n        Y = self.GetY()\n        EYlow = self.GetEYlow()\n        EYhigh = self.GetEYhigh()\n        for i in range(numPoints):\n            invGraph.SetPoint(i, Y[i], X[i])\n            invGraph.SetPointError(\n                i,\n                EYlow[i], EYhigh[i],\n                EXlow[i], EXhigh[i])\n        return invGraph\n\n    def Scale(self, value, copy=False):\n        """"""\n        Scale the graph vertically by value\n        """"""\n        numPoints = self.GetN()\n        if copy:\n            scaleGraph = self.Clone()\n        else:\n            scaleGraph = self\n        X = self.GetX()\n        EXlow = self.GetEXlow()\n        EXhigh = self.GetEXhigh()\n        Y = self.GetY()\n        EYlow = self.GetEYlow()\n        EYhigh = self.GetEYhigh()\n        for i in range(numPoints):\n            scaleGraph.SetPoint(i, X[i], Y[i] * value)\n            scaleGraph.SetPointError(\n                i,\n                EXlow[i], EXhigh[i],\n                EYlow[i] * value, EYhigh[i] * value)\n        return scaleGraph\n\n    def Stretch(self, value, copy=False):\n        """"""\n        Stretch the graph horizontally by a factor of value\n        """"""\n        numPoints = self.GetN()\n        if copy:\n            stretchGraph = self.Clone()\n        else:\n            stretchGraph = self\n        X = self.GetX()\n        EXlow = self.GetEXlow()\n        EXhigh = self.GetEXhigh()\n        Y = self.GetY()\n        EYlow = self.GetEYlow()\n        EYhigh = self.GetEYhigh()\n        for i in range(numPoints):\n            stretchGraph.SetPoint(i, X[i] * value, Y[i])\n            stretchGraph.SetPointError(\n                i,\n                EXlow[i] * value, EXhigh[i] * value,\n                EYlow[i], EYhigh[i])\n        return stretchGraph\n\n    def Shift(self, value, copy=False):\n        """"""\n        Shift the graph left or right by value\n        """"""\n        numPoints = self.GetN()\n        if copy:\n            shiftGraph = self.Clone()\n        else:\n            shiftGraph = self\n        X = self.GetX()\n        EXlow = self.GetEXlow()\n        EXhigh = self.GetEXhigh()\n        Y = self.GetY()\n        EYlow = self.GetEYlow()\n        EYhigh = self.GetEYhigh()\n        for i in range(numPoints):\n            shiftGraph.SetPoint(i, X[i] + value, Y[i])\n            shiftGraph.SetPointError(\n                i,\n                EXlow[i], EXhigh[i],\n                EYlow[i], EYhigh[i])\n        return shiftGraph\n\n    def Integrate(self):\n        """"""\n        Integrate using the trapazoidal method\n        """"""\n        area = 0.\n        X = self.GetX()\n        Y = self.GetY()\n        for i in range(self.GetN() - 1):\n            area += (X[i + 1] - X[i]) * (Y[i] + Y[i + 1]) / 2.\n        return area\n\n    def Append(self, other):\n        """"""\n        Append points from another graph\n        """"""\n        orig_len = len(self)\n        self.Set(orig_len + len(other))\n        ipoint = orig_len\n        if hasattr(self, \'SetPointError\'):\n            for point in other:\n                self.SetPoint(ipoint, point.x.value, point.y.value)\n                self.SetPointError(\n                    ipoint,\n                    point.x.error_low, point.x.error_hi,\n                    point.y.error_low, point.y.error_hi)\n                ipoint += 1\n        else:\n            for point in other:\n                self.SetPoint(ipoint, point.x.value, point.y.value)\n                ipoint += 1\n\n\nclass _Graph2DBase(_GraphBase):\n\n    def z(self, index=None):\n        if index is None:\n            return (self.GetZ()[i] for i in range(self.GetN()))\n        index = index % len(self)\n        return self.GetZ()[index]\n\n    def zerr(self, index=None):\n        if index is None:\n            return (self.zerr(i) for i in range(self.GetN()))\n        index = index % len(self)\n        return self.GetErrorZ(index)\n\n\n_GRAPH1D_BASES = {\n    \'default\': QROOT.TGraph,\n    \'asymm\': QROOT.TGraphAsymmErrors,\n    \'errors\': QROOT.TGraphErrors,\n    \'benterrors\': QROOT.TGraphBentErrors,\n}\n_GRAPH1D_CLASSES = {}\n\n\ndef _Graph_class(base):\n\n    class Graph(_Graph1DBase, Plottable, NamelessConstructorObject,\n                base):\n        _ROOT = base\n        DIM = 1\n\n        def __init__(self, npoints_or_hist=None,\n                     name=None, title=None, **kwargs):\n            if npoints_or_hist is not None:\n                super(Graph, self).__init__(npoints_or_hist,\n                                            name=name, title=title)\n            else:\n                super(Graph, self).__init__(name=name, title=title)\n            self._post_init(**kwargs)\n\n    return Graph\n\nfor name, base in _GRAPH1D_BASES.items():\n    _GRAPH1D_CLASSES[name] = snake_case_methods(_Graph_class(base))\n\n\nclass Graph(_Graph1DBase, QROOT.TGraph):\n    """"""\n    Returns a Graph object which inherits from the associated\n    ROOT.TGraph* class (TGraph, TGraphErrors, TGraphAsymmErrors)\n    """"""\n    _ROOT = QROOT.TGraph\n    DIM = 1\n\n    @classmethod\n    def dynamic_cls(cls, type=\'asymm\'):\n        return _GRAPH1D_CLASSES[type]\n\n    def __new__(cls, *args, **kwargs):\n        type = kwargs.pop(\'type\', \'asymm\').lower()\n        return cls.dynamic_cls(type)(\n            *args, **kwargs)\n\n\n# alias Graph1D -> Graph\nGraph1D = Graph\n\n_GRAPH2D_BASES = {\n    \'default\': QROOT.TGraph2D,\n    \'errors\': QROOT.TGraph2DErrors,\n}\n_GRAPH2D_CLASSES = {}\n\n\ndef _Graph2D_class(base):\n\n    class Graph2D(_Graph2DBase, Plottable, NamelessConstructorObject,\n                base):\n        _ROOT = base\n        DIM = 2\n\n        def __init__(self, npoints_or_hist=None,\n                     name=None, title=None, **kwargs):\n            if npoints_or_hist is not None:\n                super(Graph2D, self).__init__(npoints_or_hist,\n                                              name=name, title=title)\n            else:\n                super(Graph2D, self).__init__(name=name, title=title)\n            if isinstance(npoints_or_hist, int):\n                # ROOT bug in TGraph2D\n                self.Set(npoints_or_hist)\n            self._post_init(**kwargs)\n\n    return Graph2D\n\nfor name, base in _GRAPH2D_BASES.items():\n    _GRAPH2D_CLASSES[name] = snake_case_methods(_Graph2D_class(base))\n\n\nclass Graph2D(_Graph2DBase, QROOT.TGraph2D):\n    """"""\n    Returns a Graph2D object which inherits from the associated\n    ROOT.TGraph2D* class (TGraph2D, TGraph2DErrors)\n    """"""\n    _ROOT = QROOT.TGraph2D\n    DIM = 2\n\n    @classmethod\n    def dynamic_cls(cls, type=\'errors\'):\n        return _GRAPH2D_CLASSES[type]\n\n    def __new__(cls, *args, **kwargs):\n        type = kwargs.pop(\'type\', \'errors\').lower()\n        return cls.dynamic_cls(type)(\n            *args, **kwargs)\n'"
rootpy/plotting/hist.py,8,"b'from __future__ import absolute_import\n\nfrom array import array\nfrom math import sqrt\nfrom itertools import product\nimport operator\nimport numbers\ntry:\n    from itertools import izip as zip\nexcept ImportError: # will be 3.x series\n    pass\n\nimport ROOT\n\nfrom .. import asrootpy, QROOT, log; log = log[__name__]\nfrom ..extern.six.moves import range\nfrom ..base import NamedObject, NamelessConstructorObject\nfrom ..decorators import snake_case_methods, cached_property\nfrom ..context import invisible_canvas\nfrom ..utils.extras import izip_exact\nfrom ..extern.shortuuid import uuid\nfrom .base import Plottable, dim\nfrom .graph import Graph, _Graph1DBase\n\n\n__all__ = [\n    \'Hist\',\n    \'Hist1D\',\n    \'Hist2D\',\n    \'Hist3D\',\n    \'HistStack\',\n    \'Efficiency\',\n    \'histogram\',\n]\n\n\ndef canonify_slice(s, n):\n    """"""\n    Convert a slice object into a canonical form\n    to simplify treatment in histogram bin content\n    and edge slicing.\n    """"""\n    if isinstance(s, (int, long)):\n        return canonify_slice(slice(s, s + 1, None), n)\n    start = s.start % n if s.start is not None else 0\n    stop = s.stop % n if s.stop is not None else n\n    step = s.step if s.step is not None else 1\n    return slice(start, stop, step)\n\n\ndef bin_to_edge_slice(s, n):\n    """"""\n    Convert a bin slice into a bin edge slice.\n    """"""\n    s = canonify_slice(s, n)\n    start = s.start\n    stop = s.stop\n    if start > stop:\n        _stop = start + 1\n        start = stop + 1\n        stop = _stop\n    start = max(start - 1, 0)\n    step = abs(s.step)\n    if stop <= 1 or start >= n - 1 or stop == start + 1:\n        return slice(0, None, min(step, n - 2))\n    s = slice(start, stop, abs(s.step))\n    if len(range(*s.indices(n - 1))) < 2:\n        return slice(start, stop, stop - start - 1)\n    return s\n\n\nclass _HistViewBase(object):\n\n    @staticmethod\n    def _slice_repr(s):\n        if isinstance(s, slice):\n            return \'[start={0}, stop={1}, step={2}]\'.format(\n                s.start, s.stop, s.step)\n        else:\n            return \'{0}\'.format(s)\n\n\nclass HistIndexView(_HistViewBase):\n\n    def __init__(self, hist, idx):\n        if idx.step is not None and abs(idx.step) != 1:\n            raise ValueError(\n                ""rebinning using the global histogram bin ""\n                ""indices is not supported"")\n        self.hist = hist\n        self.idx = idx\n\n    def __iter__(self):\n        return self.hist.bins(idx=self.idx, overflow=True)\n\n    def __repr__(self):\n        return \'{0}({1}, idx={2})\'.format(\n            self.__class__.__name__, self.hist, self._slice_repr(self.idx))\n\n\nclass HistView(_HistViewBase):\n\n    def __init__(self, hist, x):\n        if isinstance(x, slice) and x.step == 0:\n            raise ValueError(""rebin cannot be zero"")\n        self.hist = hist\n        self.x = x\n\n    @cached_property\n    def xedges(self):\n        return list(self.hist.xedges())[\n            bin_to_edge_slice(self.x, self.hist.nbins(axis=0, overflow=True))]\n\n    @property\n    def points(self):\n        return self.hist.bins_xyz(ix=self.x, proxy=False)\n\n    def __iter__(self):\n        return self.hist.bins_xyz(ix=self.x)\n\n    def __repr__(self):\n        return \'{0}({1}, x={2})\'.format(\n            self.__class__.__name__, self.hist, self._slice_repr(self.x))\n\n\nclass Hist2DView(_HistViewBase):\n\n    def __init__(self, hist, x, y):\n        if isinstance(x, slice) and x.step == 0:\n            raise ValueError(""rebin along x cannot be zero"")\n        if isinstance(y, slice) and y.step == 0:\n            raise ValueError(""rebin along y cannot be zero"")\n        self.hist = hist\n        self.x = x\n        self.y = y\n\n    @cached_property\n    def xedges(self):\n        return list(self.hist.xedges())[\n            bin_to_edge_slice(self.x, self.hist.nbins(axis=0, overflow=True))]\n\n    @cached_property\n    def yedges(self):\n        return list(self.hist.yedges())[\n            bin_to_edge_slice(self.y, self.hist.nbins(axis=1, overflow=True))]\n\n    @property\n    def points(self):\n        return self.hist.bins_xyz(ix=self.x, iy=self.y, proxy=False)\n\n    def __iter__(self):\n        return self.hist.bins_xyz(ix=self.x, iy=self.y)\n\n    def __repr__(self):\n        return \'{0}({1}, x={2}, y={3})\'.format(\n            self.__class__.__name__, self.hist,\n            self._slice_repr(self.x),\n            self._slice_repr(self.y))\n\n\nclass Hist3DView(_HistViewBase):\n\n    def __init__(self, hist, x, y, z):\n        if isinstance(x, slice) and x.step == 0:\n            raise ValueError(""rebin along x cannot be zero"")\n        if isinstance(y, slice) and y.step == 0:\n            raise ValueError(""rebin along y cannot be zero"")\n        if isinstance(z, slice) and z.step == 0:\n            raise ValueError(""rebin along z cannot be zero"")\n        self.hist = hist\n        self.x = x\n        self.y = y\n        self.z = z\n\n    @cached_property\n    def xedges(self):\n        return list(self.hist.xedges())[\n            bin_to_edge_slice(self.x, self.hist.nbins(axis=0, overflow=True))]\n\n    @cached_property\n    def yedges(self):\n        return list(self.hist.yedges())[\n            bin_to_edge_slice(self.y, self.hist.nbins(axis=1, overflow=True))]\n\n    @cached_property\n    def zedges(self):\n        return list(self.hist.zedges())[\n            bin_to_edge_slice(self.z, self.hist.nbins(axis=2, overflow=True))]\n\n    @property\n    def points(self):\n        return self.hist.bins_xyz(ix=self.x, iy=self.y, iz=self.z, proxy=False)\n\n    def __iter__(self):\n        return self.hist.bins_xyz(ix=self.x, iy=self.y, iz=self.z)\n\n    def __repr__(self):\n        return \'{0}({1}, x={2}, y={3}, z={4})\'.format(\n            self.__class__.__name__, self.hist,\n            self._slice_repr(self.x),\n            self._slice_repr(self.y),\n            self._slice_repr(self.z))\n\n\nclass BinProxy(object):\n\n    def __init__(self, hist, idx):\n        self.hist = hist\n        self.idx = idx\n        self._sum_w2 = hist.GetSumw2()\n\n    @property\n    def xyz(self):\n        return self.hist.xyz(self.idx)\n\n    @cached_property\n    def overflow(self):\n        """"""\n        Returns true if this BinProxy is for an overflow bin\n        """"""\n        indices = self.hist.xyz(self.idx)\n        for i in range(self.hist.GetDimension()):\n            if indices[i] == 0 or indices[i] == self.hist.nbins(i) + 1:\n                return True\n        return False\n\n    @property\n    def x(self):\n        return self.hist.axis_bininfo(0, self.xyz[0])\n\n    @property\n    def y(self):\n        return self.hist.axis_bininfo(1, self.xyz[1])\n\n    @property\n    def z(self):\n        return self.hist.axis_bininfo(2, self.xyz[2])\n\n    @property\n    def value(self):\n        return self.hist.GetBinContent(self.idx)\n\n    @value.setter\n    def value(self, v):\n        return self.hist.SetBinContent(self.idx, v)\n\n    @property\n    def error(self):\n        return self.hist.GetBinError(self.idx)\n\n    @error.setter\n    def error(self, e):\n        return self.hist.SetBinError(self.idx, e)\n\n    @property\n    def sum_w2(self):\n        return self._sum_w2.At(self.idx)\n\n    @sum_w2.setter\n    def sum_w2(self, w):\n        self._sum_w2.SetAt(w, self.idx)\n\n    @property\n    def effective_entries(self):\n        """"""\n        Number of effective entries in this bin.\n        The number of unweighted entries this bin would need to\n        contain in order to have the same statistical power as this\n        bin with possibly weighted entries, estimated by:\n\n            (sum of weights) ** 2 / (sum of squares of weights)\n\n        """"""\n        sum_w2 = self.sum_w2\n        if sum_w2 == 0:\n            return abs(self.value)\n        return (self.value ** 2) / sum_w2\n\n    def __iadd__(self, other):\n        self.value += other.value\n        self.sum_w2 += other.sum_w2\n        return self\n\n    def __imul__(self, v):\n        self.value *= v\n        self.error *= v\n        return self\n\n    def __idiv__(self, v):\n        self.value /= v\n        self.error /= v\n        return self\n\n    def __ipow__(self, v):\n        cur_value = self.value\n        if cur_value == 0:\n            return self\n        new_value = cur_value ** v\n        self.value = new_value\n        self.error *= new_value / cur_value\n        return self\n\n    def __repr__(self):\n        return \'{0}({1}, {2})\'.format(\n            self.__class__.__name__, self.hist, self.idx)\n\n\nclass _HistBase(Plottable, NamedObject):\n\n    TYPES = dict(\n        (c, [getattr(QROOT, ""TH{0}{1}"".format(d, c)) for d in (1, 2, 3)])\n            for c in ""CSIFD"")\n\n    def _parse_args(self, args, ignore_extras=False):\n        params = [{\n            \'bins\': None,\n            \'nbins\': None,\n            \'low\': None,\n            \'high\': None} for _ in range(dim(self))]\n\n        for param in params:\n            if len(args) == 0:\n                raise TypeError(""did not receive expected number of arguments"")\n            if hasattr(args[0], \'__iter__\'):\n                edges = list(args[0])\n                if len(edges) < 2:\n                    raise ValueError(\n                        ""specify at least two bin edges"")\n                if sorted(edges) != edges:\n                    raise ValueError(\n                        ""bin edges must be sorted in ascending order"")\n                if len(set(args[0])) != len(args[0]):\n                    raise ValueError(""bin edges must not be repeated"")\n                param[\'bins\'] = args[0]\n                param[\'nbins\'] = len(args[0]) - 1\n                args = args[1:]\n            elif len(args) >= 3:\n                nbins = args[0]\n                if not isinstance(nbins, int):\n                    raise TypeError(\n                        ""number of bins must be an integer"")\n                if nbins < 1:\n                    raise ValueError(\n                        ""number of bins must be positive"")\n                low = args[1]\n                if not isinstance(low, numbers.Real):\n                    raise TypeError(\n                        ""lower bound must be an int, float, or long"")\n                high = args[2]\n                if not isinstance(high, numbers.Real):\n                    raise TypeError(\n                        ""upper bound must be an int, float, or long"")\n                param[\'nbins\'] = nbins\n                param[\'low\'] = low\n                param[\'high\'] = high\n                if low >= high:\n                    raise ValueError(\n                        ""upper bound (you gave {0:f}) ""\n                        ""must be greater than lower ""\n                        ""bound (you gave {1:f})"".format(\n                            float(low), float(high)))\n                args = args[3:]\n            else:\n                raise TypeError(\n                    ""did not receive expected number of arguments"")\n\n        if ignore_extras:\n            # used by Profile where range of profiled axis may be specified\n            return params, args\n\n        if len(args) != 0:\n            raise TypeError(\n                ""did not receive expected number of arguments"")\n\n        return params\n\n    def xyz(self, idx):\n        """"""\n        return binx, biny, binz corresponding to the global bin number\n        """"""\n        # Not implemented for Python 3:\n        # GetBinXYZ(i, x, y, z)\n        nx  = self.GetNbinsX() + 2\n        ny  = self.GetNbinsY() + 2\n        ndim = self.GetDimension()\n        if ndim < 2:\n            binx = idx % nx\n            biny = 0\n            binz = 0\n        elif ndim < 3:\n            binx = idx % nx\n            biny = ((idx - binx) // nx) % ny\n            binz = 0\n        elif ndim < 4:\n            binx = idx % nx\n            biny = ((idx - binx) // nx) % ny\n            binz = ((idx - binx) // nx - biny) // ny\n        else:\n            raise NotImplementedError\n        return binx, biny, binz\n\n    def axis_bininfo(self, axi, i):\n        class bi:\n            axis = self.axis(axi)\n            low = axis.GetBinLowEdge(i)\n            center = axis.GetBinCenter(i)\n            high = axis.GetBinUpEdge(i)\n            width = axis.GetBinWidth(i)\n        return bi\n\n    def bins(self, idx=None, overflow=False):\n        if idx is None:\n            idx = range(self.GetSize())\n        elif isinstance(idx, slice):\n            idx = range(*idx.indices(self.GetSize()))\n            overflow = True\n        else:\n            idx = [self._range_check(idx)]\n            overflow = True\n        for i in idx:\n            bproxy = BinProxy(self, i)\n            if not overflow and bproxy.overflow:\n                continue\n            yield bproxy\n\n    def bins_xyz(self, ix, iy=0, iz=0, proxy=True):\n        xl = self.nbins(axis=0, overflow=True)\n        yl = self.nbins(axis=1, overflow=True)\n        zl = self.nbins(axis=2, overflow=True)\n        if isinstance(ix, slice):\n            ix = range(*ix.indices(xl))\n        else:\n            ix = [self._range_check(ix, axis=0)]\n        if isinstance(iy, slice):\n            iy = range(*iy.indices(yl))\n        else:\n            iy = [self._range_check(iy, axis=1)]\n        if isinstance(iz, slice):\n            iz = range(*iz.indices(zl))\n        else:\n            iz = [self._range_check(iz, axis=2)]\n        if proxy:\n            for x, y, z in product(ix, iy, iz):\n                yield BinProxy(self, xl * yl * z + xl * y + x)\n        else:\n            for point in product(ix, iy, iz):\n                yield point\n\n    @classmethod\n    def divide(cls, h1, h2, c1=1., c2=1., option=\'\', fill_value=None):\n        if hasattr(h1, \'GetHistogram\'):\n            h1 = h1.GetHistogram()\n        if hasattr(h2, \'GetHistogram\'):\n            h2 = h2.GetHistogram()\n        ratio = h1.Clone()\n        ROOT.TH1.Divide(ratio, h1, h2, c1, c2, option)\n        if fill_value is not None:\n            for ratiobin, h2bin in zip(ratio.bins(), h2.bins()):\n                if h2bin.value == 0:\n                    ratiobin.value = fill_value\n        return ratio\n\n    def nbins(self, axis=0, overflow=False):\n        """"""\n        Get the number of bins along an axis\n        """"""\n        if axis == 0:\n            nbins = self.GetNbinsX()\n        elif axis == 1:\n            nbins = self.GetNbinsY()\n        elif axis == 2:\n            nbins = self.GetNbinsZ()\n        else:\n            raise ValueError(""axis must be 0, 1, or 2"")\n        if overflow:\n            nbins += 2\n        return nbins\n\n    def bins_range(self, axis=0, overflow=False):\n        """"""\n        Return a range of bin indices for iterating along an axis\n\n        Parameters\n        ----------\n\n        axis : int, optional (default=1)\n            The axis (0, 1 or 2).\n\n        overflow : bool, optional (default=False)\n            If True then include the underflow and overflow bins\n            otherwise only include the visible bins.\n\n        Returns\n        -------\n\n        an range object of bin indices\n\n        """"""\n        nbins = self.nbins(axis=axis, overflow=False)\n        if overflow:\n            start = 0\n            end_offset = 2\n        else:\n            start = 1\n            end_offset = 1\n        return range(start, nbins + end_offset)\n\n    @property\n    def axes(self):\n        return [self.axis(i) for i in range(self.GetDimension())]\n\n    def axis(self, axis=0):\n        if axis == 0:\n            return self.GetXaxis()\n        elif axis == 1:\n            return self.GetYaxis()\n        elif axis == 2:\n            return self.GetZaxis()\n        else:\n            raise ValueError(""axis must be 0, 1, or 2"")\n\n    @property\n    def entries(self):\n        return self.GetEntries()\n\n    @entries.setter\n    def entries(self, value):\n        self.SetEntries(value)\n\n    def __len__(self):\n        """"""\n        The total number of bins, including overflow bins\n        """"""\n        return self.GetSize()\n\n    def __iter__(self):\n        """"""\n        Iterate over the bin proxies\n        """"""\n        return self.bins(overflow=True)\n\n    def _range_check(self, index, axis=None):\n\n        if axis is None:\n            size = self.GetSize()\n        else:\n            size = self.nbins(axis=axis)\n            if axis < self.GetDimension():\n                size += 2\n        try:\n            if index < 0:\n                if index < - size:\n                    raise IndexError\n                return index % size\n            elif index >= size:\n                raise IndexError\n        except IndexError:\n            if axis is None:\n                raise IndexError(\n                    ""global bin index {0:d} is out of range"".format(index))\n            else:\n                raise IndexError(\n                    ""bin index {0:d} along axis {1:d} is out of range"".format(\n                        index, axis))\n        return index\n\n    def GetBin(self, ix, iy=0, iz=0):\n        ix = self._range_check(ix, axis=0)\n        iy = self._range_check(iy, axis=1)\n        iz = self._range_check(iz, axis=2)\n        return super(_HistBase, self).GetBin(ix, iy, iz)\n\n    def __getitem__(self, index):\n        """"""\n        Return a BinProxy or list of BinProxies if index is a slice.\n        """"""\n        if isinstance(index, slice):\n            if isinstance(self, _Hist):\n                return HistView(self, index)\n            return HistIndexView(self, index)\n        if isinstance(index, tuple):\n            ix, iy, iz = 0, 0, 0\n            ndim = self.GetDimension()\n            view = False\n            if ndim == 2:\n                try:\n                    ix, iy = index\n                except ValueError:\n                    raise IndexError(\n                        ""must index along only two ""\n                        ""axes of a 2D histogram"")\n                if isinstance(ix, slice) or isinstance(iy, slice):\n                    return Hist2DView(self, x=ix, y=iy)\n            elif ndim == 3:\n                try:\n                    ix, iy, iz = index\n                except ValueError:\n                    raise IndexError(\n                        ""must index along exactly three ""\n                        ""axes of a 3D histogram"")\n                if (isinstance(ix, slice) or isinstance(iy, slice)\n                        or isinstance(iz, slice)):\n                    return Hist3DView(self, x=ix, y=iy, z=iz)\n            else:\n                raise IndexError(\n                    ""must index along only one ""\n                    ""axis of a 1D histogram"")\n            index = self.GetBin(ix, iy, iz)\n        else:\n            index = self._range_check(index)\n        return BinProxy(self, index)\n\n    def __setitem__(self, index, value):\n        """"""\n        Set bin contents and additionally bin errors if value is a BinProxy or\n        a 2-tuple containing the value and error.\n        If index is a slice then value must be a list of values, BinProxies, or\n        2-tuples of the same length as the slice.\n        """"""\n        is_slice = isinstance(index, slice)\n        is_tuple = (not is_slice) and isinstance(index, tuple)\n        if is_slice or is_tuple:\n\n            if isinstance(value, _HistBase):\n                self[index] = value[index]\n                return\n\n            if is_slice:\n                indices = range(*index.indices(self.GetSize()))\n\n            else:\n                ndim = self.GetDimension()\n                xl = self.nbins(0, overflow=True)\n                yl = self.nbins(1, overflow=True)\n                if ndim == 2:\n                    try:\n                        ix, iy = index\n                    except ValueError:\n                        raise IndexError(\n                            ""must index along only two ""\n                            ""axes of a 2D histogram"")\n                    if isinstance(ix, slice):\n                        ix = range(*ix.indices(xl))\n                    else:\n                        ix = [self._range_check(ix, axis=0)]\n                    if isinstance(iy, slice):\n                        iy = range(*iy.indices(yl))\n                    else:\n                        iy = [self._range_check(iy, axis=1)]\n                    iz = [0]\n                elif ndim == 3:\n                    try:\n                        ix, iy, iz = index\n                    except ValueError:\n                        raise IndexError(\n                            ""must index along exactly three ""\n                            ""axes of a 3D histogram"")\n                    if isinstance(ix, slice):\n                        ix = range(*ix.indices(xl))\n                    else:\n                        ix = [self._range_check(ix, axis=0)]\n                    if isinstance(iy, slice):\n                        iy = range(*iy.indices(yl))\n                    else:\n                        iy = [self._range_check(iy, axis=1)]\n                    if isinstance(iz, slice):\n                        iz = range(*iz.indices(self.nbins(2, overflow=True)))\n                    else:\n                        iz = [self._range_check(iz, axis=2)]\n                else:\n                    raise IndexError(\n                        ""must index along only one ""\n                        ""axis of a 1D histogram"")\n                indices = (xl * yl * z + xl * y + x\n                    for (x, y, z) in product(ix, iy, iz))\n\n            if isinstance(value, _HistViewBase):\n                for i, v in izip_exact(indices, value):\n                    self.SetBinContent(i, v.value)\n                    self.SetBinError(i, v.error)\n            elif hasattr(value, \'__iter__\') and not isinstance(value, tuple):\n                if isinstance(value[0], tuple):\n                    for i, v in izip_exact(indices, value):\n                        _value, _error = v\n                        self.SetBinContent(i, _value)\n                        self.SetBinError(i, _error)\n                else:\n                    for i, v in izip_exact(indices, value):\n                        self.SetBinContent(i, v)\n            elif isinstance(value, BinProxy):\n                v, e = value.value, value.error\n                for i in indices:\n                    self.SetBinContent(i, v)\n                    self.SetBinError(i, e)\n            elif isinstance(value, tuple):\n                _value, _error = value\n                for i in indices:\n                    self.SetBinContent(i, _value)\n                    self.SetBinError(i, _error)\n            else:\n                for i in indices:\n                    self.SetBinContent(i, value)\n            return\n\n        index = self._range_check(index)\n\n        if isinstance(value, BinProxy):\n            self.SetBinContent(index, value.value)\n            self.SetBinError(index, value.error)\n        elif isinstance(value, tuple):\n            value, error = value\n            self.SetBinContent(index, value)\n            self.SetBinError(index, error)\n        else:\n            self.SetBinContent(index, value)\n\n    def uniform(self, axis=None, precision=1E-7):\n        """"""\n        Return True if the binning is uniform along the specified axis.\n        If axis is None (the default), then return True if the binning is\n        uniform along all axes. Otherwise return False.\n\n        Parameters\n        ----------\n\n        axis : int (default=None)\n            Axis along which to check if the binning is uniform. If None,\n            then check all axes.\n\n        precision : float (default=1E-7)\n            The threshold below which differences in bin widths are ignored and\n            treated as equal.\n\n        Returns\n        -------\n\n        True if the binning is uniform, otherwise False.\n\n        """"""\n        if axis is None:\n            for axis in range(self.GetDimension()):\n                widths = list(self._width(axis=axis))\n                if not all(abs(x - widths[0]) < precision for x in widths):\n                    return False\n            return True\n        widths = list(self._width(axis=axis))\n        return all(abs(x - widths[0]) < precision for x in widths)\n\n    def uniform_binned(self, name=None):\n        """"""\n        Return a new histogram with constant width bins along all axes by\n        using the bin indices as the bin edges of the new histogram.\n        """"""\n        if self.GetDimension() == 1:\n            new_hist = Hist(\n                self.GetNbinsX(), 0, self.GetNbinsX(),\n                name=name, type=self.TYPE)\n        elif self.GetDimension() == 2:\n            new_hist = Hist2D(\n                self.GetNbinsX(), 0, self.GetNbinsX(),\n                self.GetNbinsY(), 0, self.GetNbinsY(),\n                name=name, type=self.TYPE)\n        else:\n            new_hist = Hist3D(\n                self.GetNbinsX(), 0, self.GetNbinsX(),\n                self.GetNbinsY(), 0, self.GetNbinsY(),\n                self.GetNbinsZ(), 0, self.GetNbinsZ(),\n                name=name, type=self.TYPE)\n        # copy over the bin contents and errors\n        for outbin, inbin in zip(new_hist.bins(), self.bins()):\n            outbin.value = inbin.value\n            outbin.error = inbin.error\n        new_hist.decorate(self)\n        new_hist.entries = self.entries\n        return new_hist\n\n    def underflow(self, axis=0):\n        """"""\n        Return the underflow for the given axis.\n\n        Depending on the dimension of the histogram, may return an array.\n        """"""\n        if axis not in range(3):\n            raise ValueError(""axis must be 0, 1, or 2"")\n        if self.DIM == 1:\n            return self.GetBinContent(0)\n        elif self.DIM == 2:\n            def idx(i):\n                arg = [i]\n                arg.insert(axis, 0)\n                return arg\n            return [\n                self.GetBinContent(*idx(i))\n                for i in self.bins_range(axis=(axis + 1) % 2, overflow=True)]\n        elif self.DIM == 3:\n            axes = [0, 1, 2]\n            axes.remove(axis)\n            axis2, axis3 = axes\n            def idx(i, j):\n                arg = [i, j]\n                arg.insert(axis, 0)\n                return arg\n            return [[\n                self.GetBinContent(*idx(i, j))\n                for i in self.bins_range(axis=axis2, overflow=True)]\n                for j in self.bins_range(axis=axis3, overflow=True)]\n\n    def overflow(self, axis=0):\n        """"""\n        Return the overflow for the given axis.\n\n        Depending on the dimension of the histogram, may return an array.\n        """"""\n        if axis not in range(3):\n            raise ValueError(""axis must be 0, 1, or 2"")\n        if self.DIM == 1:\n            return self.GetBinContent(self.nbins(0) + 1)\n        elif self.DIM == 2:\n            axes = [0, 1]\n            axes.remove(axis)\n            axis2 = axes[0]\n            nbins_axis = self.nbins(axis)\n            def idx(i):\n                arg = [i]\n                arg.insert(axis, nbins_axis + 1)\n                return arg\n            return [\n                self.GetBinContent(*idx(i))\n                for i in self.bins_range(axis=axis2, overflow=True)]\n        elif self.DIM == 3:\n            axes = [0, 1, 2]\n            axes.remove(axis)\n            axis2, axis3 = axes\n            nbins_axis = self.nbins(axis)\n            def idx(i, j):\n                arg = [i, j]\n                arg.insert(axis, nbins_axis + 1)\n                return arg\n            return [[\n                self.GetBinContent(*idx(i, j))\n                for i in self.bins_range(axis=axis2, overflow=True)]\n                for j in self.bins_range(axis=axis3, overflow=True)]\n\n    def lowerbound(self, axis=0):\n        """"""\n        Get the lower bound of the binning along an axis\n        """"""\n        if not 0 <= axis < self.GetDimension():\n            raise ValueError(\n                ""axis must be a non-negative integer less than ""\n                ""the dimensionality of the histogram"")\n        if axis == 0:\n            return self.xedges(1)\n        if axis == 1:\n            return self.yedges(1)\n        if axis == 2:\n            return self.zedges(1)\n        raise TypeError(""axis must be an integer"")\n\n    def upperbound(self, axis=0):\n        """"""\n        Get the upper bound of the binning along an axis\n        """"""\n        if not 0 <= axis < self.GetDimension():\n            raise ValueError(\n                ""axis must be a non-negative integer less than ""\n                ""the dimensionality of the histogram"")\n        if axis == 0:\n            return self.xedges(-2)\n        if axis == 1:\n            return self.yedges(-2)\n        if axis == 2:\n            return self.zedges(-2)\n        raise TypeError(""axis must be an integer"")\n\n    def bounds(self, axis=0):\n        """"""\n        Get the lower and upper bounds of the binning along an axis\n        """"""\n        if not 0 <= axis < self.GetDimension():\n            raise ValueError(\n                ""axis must be a non-negative integer less than ""\n                ""the dimensionality of the histogram"")\n        if axis == 0:\n            return self.xedges(1), self.xedges(-2)\n        if axis == 1:\n            return self.yedges(1), self.yedges(-2)\n        if axis == 2:\n            return self.zedges(1), self.zedges(-2)\n        raise TypeError(""axis must be an integer"")\n\n    def _centers(self, axis, index=None, overflow=False):\n        nbins = self.nbins(axis)\n        ax = self.axis(axis)\n        if index is None:\n            def temp_generator():\n                if overflow:\n                    yield float(\'-inf\')\n                for index in range(1, nbins + 1):\n                    yield ax.GetBinCenter(index)\n                if overflow:\n                    yield float(\'+inf\')\n            return temp_generator()\n        index = index % (nbins + 2)\n        if index == 0:\n            return float(\'-inf\')\n        elif index == nbins + 1:\n            return float(\'+inf\')\n        return ax.GetBinCenter(index)\n\n    def _edgesl(self, axis, index=None, overflow=False):\n        nbins = self.nbins(axis)\n        ax = self.axis(axis)\n        if index is None:\n            def temp_generator():\n                if overflow:\n                    yield float(\'-inf\')\n                for index in range(1, nbins + 1):\n                    yield ax.GetBinLowEdge(index)\n                if overflow:\n                    yield ax.GetBinUpEdge(index)\n            return temp_generator()\n        index = index % (nbins + 2)\n        if index == 0:\n            return float(\'-inf\')\n        return ax.GetBinLowEdge(index)\n\n    def _edgesh(self, axis, index=None, overflow=False):\n        nbins = self.nbins(axis)\n        ax = self.axis(axis)\n        if index is None:\n            def temp_generator():\n                if overflow:\n                    yield ax.GetBinUpEdge(0)\n                for index in range(1, nbins + 1):\n                    yield ax.GetBinUpEdge(index)\n                if overflow:\n                    yield float(\'+inf\')\n            return temp_generator()\n        index = index % (nbins + 2)\n        if index == nbins + 1:\n            return float(\'+inf\')\n        return ax.GetBinUpEdge(index)\n\n    def _edges(self, axis, index=None, overflow=False):\n        nbins = self.nbins(axis)\n        ax = self.axis(axis)\n        if index is None:\n            def temp_generator():\n                if overflow:\n                    yield float(\'-inf\')\n                for index in range(1, nbins + 1):\n                    yield ax.GetBinLowEdge(index)\n                yield ax.GetBinUpEdge(nbins)\n                if overflow:\n                    yield float(\'+inf\')\n            return temp_generator()\n        index = index % (nbins + 3)\n        if index == 0:\n            return float(\'-inf\')\n        if index == nbins + 2:\n            return float(\'+inf\')\n        return ax.GetBinLowEdge(index)\n\n    def _width(self, axis, index=None, overflow=False):\n        nbins = self.nbins(axis)\n        ax = self.axis(axis)\n        if index is None:\n            def temp_generator():\n                if overflow:\n                    yield float(\'+inf\')\n                for index in range(1, nbins + 1):\n                    yield ax.GetBinWidth(index)\n                if overflow:\n                    yield float(\'+inf\')\n            return temp_generator()\n        index = index % (nbins + 2)\n        if index in (0, nbins + 1):\n            return float(\'+inf\')\n        return ax.GetBinWidth(index)\n\n    def _erravg(self, axis, index=None, overflow=False):\n        nbins = self.nbins(axis)\n        ax = self.axis(axis)\n        if index is None:\n            def temp_generator():\n                if overflow:\n                    yield float(\'+inf\')\n                for index in range(1, nbins + 1):\n                    yield ax.GetBinWidth(index) / 2.\n                if overflow:\n                    yield float(\'+inf\')\n            return temp_generator()\n        index = index % (nbins + 2)\n        if index in (0, nbins + 1):\n            return float(\'+inf\')\n        return ax.GetBinWidth(index) / 2.\n\n    def _err(self, axis, index=None, overflow=False):\n        nbins = self.nbins(axis)\n        ax = self.axis(axis)\n        if index is None:\n            def temp_generator():\n                if overflow:\n                    yield (float(\'+inf\'), float(\'+inf\'))\n                for index in range(1, nbins + 1):\n                    w = ax.GetBinWidth(index) / 2.\n                    yield (w, w)\n                if overflow:\n                    yield (float(\'+inf\'), float(\'+inf\'))\n            return temp_generator()\n        index = index % (nbins + 2)\n        if index in (0, nbins + 1):\n            return (float(\'+inf\'), float(\'+inf\'))\n        w = ax.GetBinWidth(index) / 2.\n        return (w, w)\n\n    def check_compatibility(self, other, check_edges=False, precision=1E-7):\n        """"""\n        Test whether two histograms are considered compatible by the number of\n        dimensions, number of bins along each axis, and optionally the bin\n        edges.\n\n        Parameters\n        ----------\n\n        other : histogram\n            A rootpy histogram\n\n        check_edges : bool, optional (default=False)\n            If True then also check that the bin edges are equal within\n            the specified precision.\n\n        precision : float, optional (default=1E-7)\n            The value below which differences between floats are treated as\n            nil when comparing bin edges.\n\n        Raises\n        ------\n\n        TypeError\n            If the histogram dimensionalities do not match\n\n        ValueError\n            If the histogram sizes, number of bins along an axis, or\n            optionally the bin edges do not match\n\n        """"""\n        if self.GetDimension() != other.GetDimension():\n            raise TypeError(""histogram dimensionalities do not match"")\n        if len(self) != len(other):\n            raise ValueError(""histogram sizes do not match"")\n        for axis in range(self.GetDimension()):\n            if self.nbins(axis=axis) != other.nbins(axis=axis):\n                raise ValueError(\n                    ""numbers of bins along axis {0:d} do not match"".format(\n                        axis))\n        if check_edges:\n            for axis in range(self.GetDimension()):\n                if not all([abs(l - r) < precision\n                    for l, r in zip(self._edges(axis), other._edges(axis))]):\n                    raise ValueError(\n                        ""edges do not match along axis {0:d}"".format(axis))\n\n    def compatible(self, other, check_edges=False, precision=1E-7):\n        try:\n            self.check_compatibility(other,\n                check_edges=check_edges, precision=precision)\n        except (TypeError, ValueError):\n            return False\n        return True\n\n    def __add__(self, other):\n        copy = self.Clone()\n        copy += other\n        return copy\n\n    def __iadd__(self, other):\n        if isinstance(other, numbers.Real):\n            if other != 0:\n                for bin in self.bins(overflow=True):\n                    bin.value += other\n        else:\n            self.Add(other)\n        return self\n\n    def __radd__(self, other):\n        if isinstance(other, numbers.Real):\n            copy = self.Clone()\n            if other != 0:\n                copy += other\n            return copy\n        return NotImplemented\n\n    def __sub__(self, other):\n        copy = self.Clone()\n        copy -= other\n        return copy\n\n    def __isub__(self, other):\n        if isinstance(other, numbers.Real):\n            if other != 0:\n                for bin in self.bins(overflow=True):\n                    bin.value -= other\n        else:\n            self.Add(other, -1.)\n        return self\n\n    def __rsub__(self, other):\n        if isinstance(other, numbers.Real):\n            copy = self.Clone()\n            if other != 0:\n                for bin in copy.bins(overflow=True):\n                    bin.value = other - bin.value\n            return copy\n        return NotImplemented\n\n    def __mul__(self, other):\n        copy = self.Clone()\n        copy *= other\n        return copy\n\n    def __imul__(self, other):\n        if isinstance(other, numbers.Real):\n            self.Scale(other)\n            return self\n        self.Multiply(other)\n        return self\n\n    def __rmul__(self, other):\n        if isinstance(other, numbers.Real):\n            copy = self.Clone()\n            if other != 1:\n                copy *= other\n            return copy\n        return NotImplemented\n\n    def __div__(self, other):\n        copy = self.Clone()\n        copy /= other\n        return copy\n\n    __truediv__ = __div__\n\n    def __idiv__(self, other):\n        if isinstance(other, numbers.Real):\n            if other == 0:\n                raise ZeroDivisionError(\n                    ""attempting to divide histogram by zero"")\n            self.Scale(1. / other)\n            return self\n        self.Divide(other)\n        return self\n\n    __itruediv__ = __idiv__\n\n    def __rdiv__(self, other):\n        if isinstance(other, numbers.Real):\n            copy = self.Clone()\n            for bin in copy.bins(overflow=True):\n                v = bin.value\n                if v != 0:\n                    bin.value = other / v\n            return copy\n        return NotImplemented\n\n    __rtruediv__ = __rdiv__\n\n    def __ipow__(self, other, modulo=None):\n        if modulo is not None:\n            return NotImplemented\n        if isinstance(other, numbers.Real):\n            for bin in self.bins(overflow=True):\n                bin **= other\n        elif isinstance(other, _HistBase):\n            self.check_compatibility(other)\n            for this_bin, other_bin in zip(\n                    self.bins(overflow=True),\n                    other.bins(overflow=True)):\n                this_bin **= other_bin.value\n        else:\n            return NotImplemented\n        return self\n\n    def __pow__(self, other, modulo=None):\n        if modulo is not None:\n            return NotImplemented\n        copy = self.Clone()\n        copy **= other\n        return copy\n\n    def fill_array(self, array, weights=None):\n        """"""\n        Fill this histogram with a NumPy array\n        """"""\n        try:\n            try:\n                from root_numpy import fill_hist as fill_func\n            except ImportError:\n                from root_numpy import fill_array as fill_func\n        except ImportError:\n            log.critical(\n                ""root_numpy is needed for Hist*.fill_array. ""\n                ""Is it installed and importable?"")\n            raise\n        fill_func(self, array, weights=weights)\n\n    def fill_view(self, view):\n        """"""\n        Fill this histogram from a view of another histogram\n        """"""\n        other = view.hist\n        _other_x_center = other.axis(0).GetBinCenter\n        _other_y_center = other.axis(1).GetBinCenter\n        _other_z_center = other.axis(2).GetBinCenter\n        _other_get = other.GetBinContent\n        _other_get_bin = super(_HistBase, other).GetBin\n        other_sum_w2 = other.GetSumw2()\n        _other_sum_w2_at = other_sum_w2.At\n\n        _find = self.FindBin\n        sum_w2 = self.GetSumw2()\n        _sum_w2_at = sum_w2.At\n        _sum_w2_setat = sum_w2.SetAt\n        _set = self.SetBinContent\n        _get = self.GetBinContent\n\n        for x, y, z in view.points:\n            idx = _find(\n                _other_x_center(x),\n                _other_y_center(y),\n                _other_z_center(z))\n            other_idx = _other_get_bin(x, y, z)\n            _set(idx, _get(idx) + _other_get(other_idx))\n            _sum_w2_setat(\n                _sum_w2_at(idx) + _other_sum_w2_at(other_idx),\n                idx)\n\n    def FillRandom(self, func, ntimes=5000):\n        if isinstance(func, QROOT.TF1):\n            func = func.GetName()\n        super(_HistBase, self).FillRandom(func, ntimes)\n        return self\n\n    def get_sum_w2(self, ix, iy=0, iz=0):\n        """"""\n        Obtain the true number of entries in the bin weighted by w^2\n        """"""\n        if self.GetSumw2N() == 0:\n            raise RuntimeError(\n                ""Attempting to access Sumw2 in histogram ""\n                ""where weights were not stored"")\n        xl = self.nbins(axis=0, overflow=True)\n        yl = self.nbins(axis=1, overflow=True)\n        idx = xl * yl * iz + xl * iy + ix\n        if not 0 <= idx < self.GetSumw2N():\n            raise IndexError(""bin index out of range"")\n        return self.GetSumw2().At(idx)\n\n    def set_sum_w2(self, w, ix, iy=0, iz=0):\n        """"""\n        Sets the true number of entries in the bin weighted by w^2\n        """"""\n        if self.GetSumw2N() == 0:\n            raise RuntimeError(\n                ""Attempting to access Sumw2 in histogram ""\n                ""where weights were not stored"")\n        xl = self.nbins(axis=0, overflow=True)\n        yl = self.nbins(axis=1, overflow=True)\n        idx = xl * yl * iz + xl * iy + ix\n        if not 0 <= idx < self.GetSumw2N():\n            raise IndexError(""bin index out of range"")\n        self.GetSumw2().SetAt(w, idx)\n\n    def merge_bins(self, bin_ranges, axis=0):\n        """"""\n        Merge bins in bin ranges\n\n        Parameters\n        ----------\n\n        bin_ranges : list of tuples\n            A list of tuples of bin indices for each bin range to be merged\n            into one bin.\n\n        axis : int (default=1)\n            The integer identifying the axis to merge bins along.\n\n        Returns\n        -------\n\n        hist : TH1\n            The rebinned histogram.\n\n        Examples\n        --------\n\n        Merge the overflow bins into the first and last real bins::\n\n            newhist = hist.merge_bins([(0, 1), (-2, -1)])\n\n        """"""\n        ndim = self.GetDimension()\n        if axis > ndim - 1:\n            raise ValueError(\n                ""axis is out of range"")\n        axis_bins = self.nbins(axis=axis, overflow=True)\n\n        # collect the indices along this axis to be merged\n        # support negative indices via slicing\n        windows = []\n        for window in bin_ranges:\n            if len(window) != 2:\n                raise ValueError(\n                    ""bin range tuples must contain ""\n                    ""two elements: {0!r}"".format(window))\n            l, r = window\n            if l == r:\n                raise ValueError(\n                    ""bin indices must not be equal ""\n                    ""in a merging window: {0!r}"".format(window))\n            if (l < 0 and r >= 0) or (l > 0 and r > 0 and l > r):\n                raise ValueError(\n                    ""invalid bin range: {0!r}"".format(window))\n            if r == -1:\n                r = axis_bins\n            else:\n                r += 1\n            bin_idx = range(*slice(l, r).indices(axis_bins))\n            if bin_idx: # skip []\n                windows.append(list(bin_idx))\n\n        if not windows:\n            # no merging will take place so return a clone\n            return self.Clone()\n\n        # check that windows do not overlap\n        if len(windows) > 1:\n            flattened = [idx for window in windows for idx in window]\n            if len(flattened) != len(set(flattened)):\n                raise ValueError(\n                    ""bin index windows overlap: {0!r}"".format(bin_ranges))\n\n        # construct a mapping from old to new bin index along this axis\n        windows.sort()\n        mapping = {}\n        left_idx = {}\n        offset = 0\n        for window in windows:\n            # put underflow in first bin\n            new_idx = window[0] - offset or 1\n            left_idx[window[0] or 1] = None\n            for idx in window:\n                mapping[idx] = new_idx\n            offset += len(window) - 1\n            if window[0] == 0:\n                offset -= 1\n\n        new_axis_bins = axis_bins - offset\n\n        # construct new bin edges\n        new_edges = []\n        for i, edge in enumerate(self._edges(axis)):\n            if (i != axis_bins - 2 and i + 1 in mapping\n                and i + 1 not in left_idx):\n                continue\n            new_edges.append(edge)\n\n        # construct new histogram and fill\n        new_hist = self.empty_clone(binning=new_edges, axis=axis)\n\n        this_axis = self.axis(axis)\n        new_axis = new_hist.axis(axis)\n\n        def translate(idx):\n            if idx in mapping:\n                return mapping[idx]\n            if idx == 0:\n                return 0\n            # use TH1.FindBin to determine where the bins should be merged\n            return new_axis.FindBin(this_axis.GetBinCenter(idx))\n\n        for bin in self.bins(overflow=True):\n            xyz = bin.xyz\n            new_xyz = list(xyz)\n            new_xyz[axis] = translate(int(xyz[axis]))\n\n            x, y, z = new_xyz\n\n            new_v = new_hist.GetBinContent(x, y, z)\n            new_hist.SetBinContent(x, y, z, new_v + bin.value)\n\n            sum_w2 = self.get_sum_w2(*xyz)\n            new_sum_w2 = new_hist.get_sum_w2(x, y, z)\n            new_hist.set_sum_w2(sum_w2 + new_sum_w2, x, y, z)\n\n        # transfer stats info\n        stat_array = array(\'d\', [0.] * 10)\n        self.GetStats(stat_array)\n        new_hist.PutStats(stat_array)\n        entries = self.GetEntries()\n        new_hist.SetEntries(entries)\n        return new_hist\n\n    def rebinned(self, bins, axis=0):\n        """"""\n        Return a new rebinned histogram\n\n        Parameters\n        ----------\n\n        bins : int, tuple, or iterable\n            If ``bins`` is an int, then return a histogram that is rebinned by\n            grouping N=``bins`` bins together along the axis ``axis``.\n            If ``bins`` is a tuple, then it must contain the same number of\n            elements as there are dimensions of this histogram and each element\n            will be used to rebin along the associated axis.\n            If ``bins`` is another iterable, then it will define the bin\n            edges along the axis ``axis`` in the new rebinned histogram.\n\n        axis : int, optional (default=0)\n            The axis to rebin along.\n\n        Returns\n        -------\n\n        The rebinned histogram\n\n        """"""\n        ndim = self.GetDimension()\n        if axis >= ndim:\n            raise ValueError(\n                ""axis must be less than the dimensionality of the histogram"")\n\n        if isinstance(bins, int):\n            _bins = [1] * ndim\n            try:\n                _bins[axis] = bins\n            except IndexError:\n                raise ValueError(""axis must be 0, 1, or 2"")\n            bins = tuple(_bins)\n\n        if isinstance(bins, tuple):\n            if len(bins) != ndim:\n                raise ValueError(\n                    ""bins must be a tuple with the same ""\n                    ""number of elements as histogram axes"")\n            newname = \'{0}_{1}\'.format(self.__class__.__name__, uuid())\n            if ndim == 1:\n                hist = self.Rebin(bins[0], newname)\n            elif ndim == 2:\n                hist = self.Rebin2D(bins[0], bins[1], newname)\n            else:\n                hist = self.Rebin3D(bins[0], bins[1], bins[2], newname)\n            hist = asrootpy(hist)\n        elif hasattr(bins, \'__iter__\'):\n            hist = self.empty_clone(bins, axis=axis)\n            nbinsx = self.nbins(0)\n            nbinsy = self.nbins(1)\n            nbinsz = self.nbins(2)\n            xaxis = self.xaxis\n            yaxis = self.yaxis\n            zaxis = self.zaxis\n            sum_w2 = self.GetSumw2()\n            _sum_w2_at = sum_w2.At\n            new_sum_w2 = hist.GetSumw2()\n            _new_sum_w2_at = new_sum_w2.At\n            _new_sum_w2_setat = new_sum_w2.SetAt\n            _x_center = xaxis.GetBinCenter\n            _y_center = yaxis.GetBinCenter\n            _z_center = zaxis.GetBinCenter\n            _find = hist.FindBin\n            _set = hist.SetBinContent\n            _get = hist.GetBinContent\n            _this_get = self.GetBinContent\n            _get_bin = super(_HistBase, self).GetBin\n            for z in range(1, nbinsz + 1):\n                for y in range(1, nbinsy + 1):\n                    for x in range(1, nbinsx + 1):\n                        newbin = _find(\n                            _x_center(x), _y_center(y), _z_center(z))\n                        idx = _get_bin(x, y, z)\n                        _set(newbin, _get(newbin) + _this_get(idx))\n                        _new_sum_w2_setat(\n                            _new_sum_w2_at(newbin) + _sum_w2_at(idx),\n                            newbin)\n            hist.SetEntries(self.GetEntries())\n        else:\n            raise TypeError(\n                ""bins must either be an integer, a tuple, or an iterable"")\n        return hist\n\n    def smoothed(self, iterations=1):\n        """"""\n        Return a smoothed copy of this histogram\n\n        Parameters\n        ----------\n\n        iterations : int, optional (default=1)\n            The number of smoothing iterations\n\n        Returns\n        -------\n\n        hist : asrootpy\'d histogram\n            The smoothed histogram\n\n        """"""\n        copy = self.Clone(shallow=True)\n        copy.Smooth(iterations)\n        return copy\n\n    def empty_clone(self, binning=None, axis=0, type=None, **kwargs):\n        """"""\n        Return a new empty histogram. The binning may be modified\n        along one axis by specifying the binning and axis arguments.\n        If binning is False, then the corresponding axis is dropped\n        from the returned histogram.\n        """"""\n        ndim = self.GetDimension()\n        if binning is False and ndim == 1:\n            raise ValueError(\n                ""cannot remove the x-axis of a 1D histogram"")\n        args = []\n        for iaxis in range(ndim):\n            if iaxis == axis:\n                if binning is False:\n                    # skip this axis\n                    continue\n                elif binning is not None:\n                    if hasattr(binning, \'__iter__\'):\n                        binning = (binning,)\n                    args.extend(binning)\n                    continue\n            args.append(list(self._edges(axis=iaxis)))\n        if type is None:\n            type = self.TYPE\n        if binning is False:\n            ndim -= 1\n        cls = [Hist, Hist2D, Hist3D][ndim - 1]\n        return cls(*args, type=type, **kwargs)\n\n    def quantiles(self, quantiles,\n                  axis=0, strict=False,\n                  recompute_integral=False):\n        """"""\n        Calculate the quantiles of this histogram.\n\n        Parameters\n        ----------\n\n        quantiles : list or int\n            A list of cumulative probabilities or an integer used to determine\n            equally spaced values between 0 and 1 (inclusive).\n\n        axis : int, optional (default=0)\n            The axis to compute the quantiles along. 2D and 3D histograms are\n            first projected along the desired axis before computing the\n            quantiles.\n\n        strict : bool, optional (default=False)\n            If True, then return the sorted unique quantiles corresponding\n            exactly to bin edges of this histogram.\n\n        recompute_integral : bool, optional (default=False)\n            If this histogram was filled with SetBinContent instead of Fill,\n            then the integral must be computed before calculating the\n            quantiles.\n\n        Returns\n        -------\n\n        output : list or numpy array\n            If NumPy is importable then an array of the quantiles is returned,\n            otherwise a list is returned.\n\n        """"""\n        if axis >= self.GetDimension():\n            raise ValueError(\n                ""axis must be less than the dimensionality of the histogram"")\n        if recompute_integral:\n            self.ComputeIntegral()\n        if isinstance(self, _Hist2D):\n            newname = \'{0}_{1}\'.format(self.__class__.__name__, uuid())\n            if axis == 0:\n                proj = self.ProjectionX(newname, 1, self.nbins(1))\n            elif axis == 1:\n                proj = self.ProjectionY(newname, 1, self.nbins(0))\n            else:\n                raise ValueError(""axis must be 0 or 1"")\n            return asrootpy(proj).quantiles(\n                quantiles, strict=strict, recompute_integral=False)\n        elif isinstance(self, _Hist3D):\n            newname = \'{0}_{1}\'.format(self.__class__.__name__, uuid())\n            if axis == 0:\n                proj = self.ProjectionX(\n                    newname, 1, self.nbins(1), 1, self.nbins(2))\n            elif axis == 1:\n                proj = self.ProjectionY(\n                    newname, 1, self.nbins(0), 1, self.nbins(2))\n            elif axis == 2:\n                proj = self.ProjectionZ(\n                    newname, 1, self.nbins(0), 1, self.nbins(1))\n            else:\n                raise ValueError(""axis must be 0, 1, or 2"")\n            return asrootpy(proj).quantiles(\n                quantiles, strict=strict, recompute_integral=False)\n        try:\n            import numpy as np\n        except ImportError:\n            # use python implementation\n            use_numpy = False\n        else:\n            use_numpy = True\n        if isinstance(quantiles, int):\n            num_quantiles = quantiles\n            if use_numpy:\n                qs = np.linspace(0, 1, num_quantiles)\n                output = np.empty(num_quantiles, dtype=float)\n            else:\n                def linspace(start, stop, n):\n                    if n == 1:\n                        yield start\n                        return\n                    h = float(stop - start) / (n - 1)\n                    for i in range(n):\n                        yield start + h * i\n                quantiles = list(linspace(0, 1, num_quantiles))\n                qs = array(\'d\', quantiles)\n                output = array(\'d\', [0.] * num_quantiles)\n        else:\n            num_quantiles = len(quantiles)\n            if use_numpy:\n                qs = np.array(quantiles, dtype=float)\n                output = np.empty(num_quantiles, dtype=float)\n            else:\n                qs = array(\'d\', quantiles)\n                output = array(\'d\', [0.] * num_quantiles)\n        if strict:\n            integral = self.GetIntegral()\n            nbins = self.nbins(0)\n            if use_numpy:\n                edges = np.empty(nbins + 1, dtype=float)\n                self.GetLowEdge(edges)\n                edges[-1] = edges[-2] + self.GetBinWidth(nbins)\n                integral = np.ndarray((nbins + 1,), dtype=float, buffer=integral)\n                idx = np.searchsorted(integral, qs, side=\'left\')\n                output = np.unique(np.take(edges, idx))\n            else:\n                quantiles = list(set(qs))\n                quantiles.sort()\n                output = []\n                ibin = 0\n                for quant in quantiles:\n                    # find first bin greater than or equal to quant\n                    while integral[ibin] < quant and ibin < nbins + 1:\n                        ibin += 1\n                    edge = self.GetBinLowEdge(ibin + 1)\n                    output.append(edge)\n                    if ibin >= nbins + 1:\n                        break\n                output = list(set(output))\n                output.sort()\n            return output\n        self.GetQuantiles(num_quantiles, output, qs)\n        if use_numpy:\n            return output\n        return list(output)\n\n    def max(self, include_error=False):\n        if not include_error:\n            return self.GetBinContent(self.GetMaximumBin())\n        clone = self.Clone(shallow=True)\n        for i in range(self.GetSize()):\n            clone.SetBinContent(\n                i, clone.GetBinContent(i) + clone.GetBinError(i))\n        return clone.GetBinContent(clone.GetMaximumBin())\n\n    def min(self, include_error=False):\n        if not include_error:\n            return self.GetBinContent(self.GetMinimumBin())\n        clone = self.Clone(shallow=True)\n        for i in range(self.GetSize()):\n            clone.SetBinContent(\n                i, clone.GetBinContent(i) - clone.GetBinError(i))\n        return clone.GetBinContent(clone.GetMinimumBin())\n\n\nclass _Hist(_HistBase):\n\n    DIM = 1\n\n    def x(self, index=None, overflow=False):\n        return self._centers(0, index, overflow=overflow)\n\n    def xerravg(self, index=None, overflow=False):\n        return self._erravg(0, index, overflow=overflow)\n\n    def xerrl(self, index=None, overflow=False):\n        return self._erravg(0, index, overflow=overflow)\n\n    def xerrh(self, index=None, overflow=False):\n        return self._erravg(0, index, overflow=overflow)\n\n    def xerr(self, index=None, overflow=False):\n        return self._err(0, index, overflow=overflow)\n\n    def xwidth(self, index=None, overflow=False):\n        return self._width(0, index, overflow=overflow)\n\n    def xedgesl(self, index=None, overflow=False):\n        return self._edgesl(0, index, overflow=overflow)\n\n    def xedgesh(self, index=None, overflow=False):\n        return self._edgesh(0, index, overflow=overflow)\n\n    def xedges(self, index=None, overflow=False):\n        return self._edges(0, index, overflow=overflow)\n\n    def yerrh(self, index=None, overflow=False):\n        return self.yerravg(index, overflow=overflow)\n\n    def yerrl(self, index=None, overflow=False):\n        return self.yerravg(index, overflow=overflow)\n\n    def y(self, index=None, overflow=False):\n        if index is None:\n            return (self.GetBinContent(i)\n                    for i in self.bins_range(axis=0, overflow=overflow))\n        index = index % self.nbins(axis=0, overflow=True)\n        return self.GetBinContent(index)\n\n    def yerravg(self, index=None, overflow=False):\n        if index is None:\n            return (self.GetBinError(i)\n                    for i in self.bins_range(axis=0, overflow=overflow))\n        index = index % self.nbins(axis=0, overflow=True)\n        return self.GetBinError(index)\n\n    def yerr(self, index=None, overflow=False):\n        if index is None:\n            return ((self.yerrl(i), self.yerrh(i))\n                    for i in self.bins_range(axis=0, overflow=overflow))\n        index = index % self.nbins(axis=0, overflow=True)\n        return (self.yerrl(index), self.yerrh(index))\n\n    def expectation(self, startbin=1, endbin=None):\n        if endbin is not None and endbin < startbin:\n            raise ValueError(""``endbin`` should be greated than ``startbin``"")\n        if endbin is None:\n            endbin = self.nbins(0)\n        expect = 0.\n        norm = 0.\n        for index in range(startbin, endbin + 1):\n            val = self[index]\n            expect += val * self.x(index)\n            norm += val\n        if norm > 0:\n            return expect / norm\n        else:\n            return (self.xedges(endbin + 1) + self.xedges(startbin)) / 2\n\n    def integral(self, xbin1=None, xbin2=None,\n                 width=False, error=False, overflow=False):\n        """"""\n        Compute the integral and error over a range of bins\n        """"""\n        if xbin1 is None:\n            xbin1 = 0 if overflow else 1\n        if xbin2 is None:\n            xbin2 = -1 if overflow else -2\n        nbinsx = self.nbins(axis=0, overflow=True)\n        xbin1 %= nbinsx\n        xbin2 %= nbinsx\n        options = \'width\' if width else \'\'\n        if error:\n            error = ROOT.Double()\n            integral = super(_Hist, self).IntegralAndError(\n                xbin1, xbin2, error, options)\n            return integral, error\n        return super(_Hist, self).Integral(xbin1, xbin2, options)\n\n    def poisson_errors(self):\n        """"""\n        Return a TGraphAsymmErrors representation of this histogram where the\n        point y errors are Poisson.\n        """"""\n        graph = Graph(self.nbins(axis=0), type=\'asymm\')\n        graph.SetLineWidth(self.GetLineWidth())\n        graph.SetMarkerSize(self.GetMarkerSize())\n        chisqr = ROOT.TMath.ChisquareQuantile\n        npoints = 0\n        for bin in self.bins(overflow=False):\n            entries = bin.effective_entries\n            if entries <= 0:\n                continue\n            ey_low = entries - 0.5 * chisqr(0.1586555, 2. * entries)\n            ey_high = 0.5 * chisqr(\n                1. - 0.1586555, 2. * (entries + 1)) - entries\n            ex = bin.x.width / 2.\n            graph.SetPoint(npoints, bin.x.center, bin.value)\n            graph.SetPointEXlow(npoints, ex)\n            graph.SetPointEXhigh(npoints, ex)\n            graph.SetPointEYlow(npoints, ey_low)\n            graph.SetPointEYhigh(npoints, ey_high)\n            npoints += 1\n        graph.Set(npoints)\n        return graph\n\n\nclass _Hist2D(_HistBase):\n\n    DIM = 2\n\n    def x(self, index=None, overflow=False):\n        return self._centers(0, index, overflow=overflow)\n\n    def xerravg(self, index=None, overflow=False):\n        return self._erravg(0, index, overflow=overflow)\n\n    def xerrl(self, index=None, overflow=False):\n        return self._erravg(0, index, overflow=overflow)\n\n    def xerrh(self, index=None, overflow=False):\n        return self._erravg(0, index, overflow=overflow)\n\n    def xerr(self, index=None, overflow=False):\n        return self._err(0, index, overflow=overflow)\n\n    def xwidth(self, index=None, overflow=False):\n        return self._width(0, index, overflow=overflow)\n\n    def xedgesl(self, index=None, overflow=False):\n        return self._edgesl(0, index, overflow=overflow)\n\n    def xedgesh(self, index=None, overflow=False):\n        return self._edgesh(0, index, overflow=overflow)\n\n    def xedges(self, index=None, overflow=False):\n        return self._edges(0, index, overflow=overflow)\n\n    def y(self, index=None, overflow=False):\n        return self._centers(1, index, overflow=overflow)\n\n    def yerravg(self, index=None, overflow=False):\n        return self._erravg(1, index, overflow=overflow)\n\n    def yerrl(self, index=None, overflow=False):\n        return self._erravg(1, index, overflow=overflow)\n\n    def yerrh(self, index=None, overflow=False):\n        return self._erravg(1, index, overflow=overflow)\n\n    def yerr(self, index=None, overflow=False):\n        return self._err(1, index, overflow=overflow)\n\n    def ywidth(self, index=None, overflow=False):\n        return self._width(1, index, overflow=overflow)\n\n    def yedgesl(self, index=None, overflow=False):\n        return self._edgesl(1, index, overflow=overflow)\n\n    def yedgesh(self, index=None, overflow=False):\n        return self._edgesh(1, index, overflow=overflow)\n\n    def yedges(self, index=None, overflow=False):\n        return self._edges(1, index, overflow=overflow)\n\n    def zerrh(self, index=None, overflow=False):\n        return self.zerravg(index, overflow=overflow)\n\n    def zerrl(self, index=None, overflow=False):\n        return self.zerravg(index, overflow=overflow)\n\n    def z(self, ix=None, iy=None, overflow=False):\n        if ix is None and iy is None:\n            return [[self.GetBinContent(ix, iy)\n                    for iy in self.bins_range(axis=1, overflow=overflow)]\n                    for ix in self.bins_range(axis=0, overflow=overflow)]\n        ix = ix % self.nbins(axis=0, overflow=True)\n        iy = iy % self.nbins(axis=1, overflow=True)\n        return self.GetBinContent(ix, iy)\n\n    def zerravg(self, ix=None, iy=None, overflow=False):\n        if ix is None and iy is None:\n            return [[self.GetBinError(ix, iy)\n                    for iy in self.bins_range(axis=1, overflow=overflow)]\n                    for ix in self.bins_range(axis=0, overflow=overflow)]\n        ix = ix % self.nbins(axis=0, overflow=True)\n        iy = iy % self.nbins(axis=1, overflow=True)\n        return self.GetBinError(ix, iy)\n\n    def zerr(self, ix=None, iy=None, overflow=False):\n        if ix is None and iy is None:\n            return [[(self.GetBinError(ix, iy), self.GetBinError(ix, iy))\n                    for iy in self.bins_range(axis=1, overflow=overflow)]\n                    for ix in self.bins_range(axis=0, overflow=overflow)]\n        ix = ix % self.nbins(axis=0, overflow=True)\n        iy = iy % self.nbins(axis=1, overflow=True)\n        return (self.GetBinError(ix, iy),\n                self.GetBinError(ix, iy))\n\n    def ravel(self, name=None):\n        """"""\n        Convert 2D histogram into 1D histogram with the y-axis repeated along\n        the x-axis, similar to NumPy\'s ravel().\n        """"""\n        nbinsx = self.nbins(0)\n        nbinsy = self.nbins(1)\n        left_edge = self.xedgesl(1)\n        right_edge = self.xedgesh(nbinsx)\n        out = Hist(nbinsx * nbinsy,\n                   left_edge, nbinsy * (right_edge - left_edge) + left_edge,\n                   type=self.TYPE,\n                   name=name,\n                   title=self.title,\n                   **self.decorators)\n        for i, bin in enumerate(self.bins(overflow=False)):\n            out.SetBinContent(i + 1, bin.value)\n            out.SetBinError(i + 1, bin.error)\n        return out\n\n    def integral(self,\n                 xbin1=None, xbin2=None,\n                 ybin1=None, ybin2=None,\n                 width=False,\n                 error=False,\n                 overflow=False):\n        """"""\n        Compute the integral and error over a range of bins\n        """"""\n        if xbin1 is None:\n            xbin1 = 0 if overflow else 1\n        if xbin2 is None:\n            xbin2 = -1 if overflow else -2\n        if ybin1 is None:\n            ybin1 = 0 if overflow else 1\n        if ybin2 is None:\n            ybin2 = -1 if overflow else -2\n        nbinsx = self.nbins(axis=0, overflow=True)\n        xbin1 %= nbinsx\n        xbin2 %= nbinsx\n        nbinsy = self.nbins(axis=1, overflow=True)\n        ybin1 %= nbinsy\n        ybin2 %= nbinsy\n        options = \'width\' if width else \'\'\n        if error:\n            error = ROOT.Double()\n            integral = super(_Hist2D, self).IntegralAndError(\n                xbin1, xbin2, ybin1, ybin2, error, options)\n            return integral, error\n        return super(_Hist2D, self).Integral(\n            xbin1, xbin2, ybin1, ybin2, options)\n\n\nclass _Hist3D(_HistBase):\n\n    DIM = 3\n\n    def x(self, index=None, overflow=False):\n        return self._centers(0, index, overflow=overflow)\n\n    def xerravg(self, index=None, overflow=False):\n        return self._erravg(0, index, overflow=overflow)\n\n    def xerrl(self, index=None, overflow=False):\n        return self._erravg(0, index, overflow=overflow)\n\n    def xerrh(self, index=None, overflow=False):\n        return self._erravg(0, index, overflow=overflow)\n\n    def xerr(self, index=None, overflow=False):\n        return self._err(0, index, overflow=overflow)\n\n    def xwidth(self, index=None, overflow=False):\n        return self._width(0, index, overflow=overflow)\n\n    def xedgesl(self, index=None, overflow=False):\n        return self._edgesl(0, index, overflow=overflow)\n\n    def xedgesh(self, index=None, overflow=False):\n        return self._edgesh(0, index, overflow=overflow)\n\n    def xedges(self, index=None, overflow=False):\n        return self._edges(0, index, overflow=overflow)\n\n    def y(self, index=None, overflow=False):\n        return self._centers(1, index, overflow=overflow)\n\n    def yerravg(self, index=None, overflow=False):\n        return self._erravg(1, index, overflow=overflow)\n\n    def yerrl(self, index=None, overflow=False):\n        return self._erravg(1, index, overflow=overflow)\n\n    def yerrh(self, index=None, overflow=False):\n        return self._erravg(1, index, overflow=overflow)\n\n    def yerr(self, index=None, overflow=False):\n        return self._err(1, index, overflow=overflow)\n\n    def ywidth(self, index=None, overflow=False):\n        return self._width(1, index, overflow=overflow)\n\n    def yedgesl(self, index=None, overflow=False):\n        return self._edgesl(1, index, overflow=overflow)\n\n    def yedgesh(self, index=None, overflow=False):\n        return self._edgesh(1, index, overflow=overflow)\n\n    def yedges(self, index=None, overflow=False):\n        return self._edges(1, index, overflow=overflow)\n\n    def z(self, index=None, overflow=False):\n        return self._centers(2, index, overflow=overflow)\n\n    def zerravg(self, index=None, overflow=False):\n        return self._erravg(2, index, overflow=overflow)\n\n    def zerrl(self, index=None, overflow=False):\n        return self._erravg(2, index, overflow=overflow)\n\n    def zerrh(self, index=None, overflow=False):\n        return self._erravg(2, index, overflow=overflow)\n\n    def zerr(self, index=None, overflow=False):\n        return self._err(2, index, overflow=overflow)\n\n    def zwidth(self, index=None, overflow=False):\n        return self._width(2, index, overflow=overflow)\n\n    def zedgesl(self, index=None, overflow=False):\n        return self._edgesl(2, index, overflow=overflow)\n\n    def zedgesh(self, index=None, overflow=False):\n        return self._edgesh(2, index, overflow=overflow)\n\n    def zedges(self, index=None, overflow=False):\n        return self._edges(2, index, overflow=overflow)\n\n    def werrh(self, index=None, overflow=False):\n        return self.werravg(index, overflow=overflow)\n\n    def werrl(self, index=None, overflow=False):\n        return self.werravg(index, overflow=overflow)\n\n    def w(self, ix=None, iy=None, iz=None, overflow=False):\n        if ix is None and iy is None and iz is None:\n            return [[[self.GetBinContent(ix, iy, iz)\n                    for iz in self.bins_range(axis=2, overflow=overflow)]\n                    for iy in self.bins_range(axis=1, overflow=overflow)]\n                    for ix in self.bins_range(axis=0, overflow=overflow)]\n        ix = ix % self.nbins(axis=0, overflow=True)\n        iy = iy % self.nbins(axis=1, overflow=True)\n        iz = iz % self.nbins(axis=2, overflow=True)\n        return self.GetBinContent(ix, iy, iz)\n\n    def werravg(self, ix=None, iy=None, iz=None, overflow=False):\n        if ix is None and iy is None and iz is None:\n            return [[[self.GetBinError(ix, iy, iz)\n                    for iz in self.bins_range(axis=2, overflow=overflow)]\n                    for iy in self.bins_range(axis=1, overflow=overflow)]\n                    for ix in self.bins_range(axis=0, overflow=overflow)]\n        ix = ix % self.nbins(axis=0, overflow=True)\n        iy = iy % self.nbins(axis=1, overflow=True)\n        iz = iz % self.nbins(axis=2, overflow=True)\n        return self.GetBinError(ix, iy, iz)\n\n    def werr(self, ix=None, iy=None, iz=None, overflow=False):\n        if ix is None and iy is None and iz is None:\n            return [[[\n                (self.GetBinError(ix, iy, iz), self.GetBinError(ix, iy, iz))\n                for iz in self.bins_range(axis=2, overflow=overflow)]\n                for iy in self.bins_range(axis=1, overflow=overflow)]\n                for ix in self.bins_range(axis=0, overflow=overflow)]\n        ix = ix % self.nbins(axis=0, overflow=True)\n        iy = iy % self.nbins(axis=1, overflow=True)\n        iz = iz % self.nbins(axis=2, overflow=True)\n        return (self.GetBinError(ix, iy, iz),\n                self.GetBinError(ix, iy, iz))\n\n    def integral(self,\n                 xbin1=1, xbin2=-2,\n                 ybin1=1, ybin2=-2,\n                 zbin1=1, zbin2=-2,\n                 width=False,\n                 error=False,\n                 overflow=False):\n        """"""\n        Compute the integral and error over a range of bins\n        """"""\n        if xbin1 is None:\n            xbin1 = 0 if overflow else 1\n        if xbin2 is None:\n            xbin2 = -1 if overflow else -2\n        if ybin1 is None:\n            ybin1 = 0 if overflow else 1\n        if ybin2 is None:\n            ybin2 = -1 if overflow else -2\n        if zbin1 is None:\n            zbin1 = 0 if overflow else 1\n        if zbin2 is None:\n            zbin2 = -1 if overflow else -2\n        nbinsx = self.nbins(axis=0, overflow=True)\n        xbin1 %= nbinsx\n        xbin2 %= nbinsx\n        nbinsy = self.nbins(axis=1, overflow=True)\n        ybin1 %= nbinsy\n        ybin2 %= nbinsy\n        nbinsz = self.nbins(axis=2, overflow=True)\n        zbin1 %= nbinsz\n        zbin2 %= nbinsz\n        options = \'width\' if width else \'\'\n        if error:\n            error = ROOT.Double()\n            integral = super(_Hist3D, self).IntegralAndError(\n                xbin1, xbin2, ybin1, ybin2, zbin1, zbin2, error, options)\n            return integral, error\n        return super(_Hist3D, self).Integral(\n            xbin1, xbin2, ybin1, ybin2, zbin1, zbin2, options)\n\n\ndef _Hist_class(type=\'F\'):\n    type = type.upper()\n    if type not in _HistBase.TYPES:\n        raise TypeError(\n            ""No histogram available with bin type {0}"".format(type))\n    rootclass = _HistBase.TYPES[type][0]\n\n    class Hist(_Hist, rootclass):\n        _ROOT = rootclass\n        TYPE = type\n\n        def __init__(self, *args, **kwargs):\n            params = self._parse_args(args)\n            name = kwargs.pop(\'name\', None)\n            title = kwargs.pop(\'title\', None)\n            if params[0][\'bins\'] is None:\n                super(Hist, self).__init__(\n                    params[0][\'nbins\'], params[0][\'low\'], params[0][\'high\'],\n                    name=name, title=title)\n            else:\n                super(Hist, self).__init__(\n                    params[0][\'nbins\'], array(\'d\', params[0][\'bins\']),\n                    name=name, title=title)\n            self._post_init(**kwargs)\n\n    return Hist\n\n\ndef _Hist2D_class(type=\'F\'):\n    type = type.upper()\n    if type not in _HistBase.TYPES:\n        raise TypeError(\n            ""No histogram available with bin type {0}"".format(type))\n    rootclass = _HistBase.TYPES[type][1]\n\n    class Hist2D(_Hist2D, rootclass):\n        _ROOT = rootclass\n        TYPE = type\n\n        def __init__(self, *args, **kwargs):\n            params = self._parse_args(args)\n            name = kwargs.pop(\'name\', None)\n            title = kwargs.pop(\'title\', None)\n            if params[0][\'bins\'] is None and params[1][\'bins\'] is None:\n                super(Hist2D, self).__init__(\n                    params[0][\'nbins\'], params[0][\'low\'], params[0][\'high\'],\n                    params[1][\'nbins\'], params[1][\'low\'], params[1][\'high\'],\n                    name=name, title=title)\n            elif params[0][\'bins\'] is None and params[1][\'bins\'] is not None:\n                super(Hist2D, self).__init__(\n                    params[0][\'nbins\'], params[0][\'low\'], params[0][\'high\'],\n                    params[1][\'nbins\'], array(\'d\', params[1][\'bins\']),\n                    name=name, title=title)\n            elif params[0][\'bins\'] is not None and params[1][\'bins\'] is None:\n                super(Hist2D, self).__init__(\n                    params[0][\'nbins\'], array(\'d\', params[0][\'bins\']),\n                    params[1][\'nbins\'], params[1][\'low\'], params[1][\'high\'],\n                    name=name, title=title)\n            else:\n                super(Hist2D, self).__init__(\n                    params[0][\'nbins\'], array(\'d\', params[0][\'bins\']),\n                    params[1][\'nbins\'], array(\'d\', params[1][\'bins\']),\n                    name=name, title=title)\n            self._post_init(**kwargs)\n\n    return Hist2D\n\n\ndef _Hist3D_class(type=\'F\'):\n    type = type.upper()\n    if type not in _HistBase.TYPES:\n        raise TypeError(\n            ""No histogram available with bin type {0}"".format(type))\n    rootclass = _HistBase.TYPES[type][2]\n\n    class Hist3D(_Hist3D, rootclass):\n        _ROOT = rootclass\n        TYPE = type\n\n        def __init__(self, *args, **kwargs):\n            params = self._parse_args(args)\n            name = kwargs.pop(\'name\', None)\n            title = kwargs.pop(\'title\', None)\n            # ROOT is missing constructors for TH3...\n            if (params[0][\'bins\'] is None and\n                    params[1][\'bins\'] is None and\n                    params[2][\'bins\'] is None):\n                super(Hist3D, self).__init__(\n                    params[0][\'nbins\'], params[0][\'low\'], params[0][\'high\'],\n                    params[1][\'nbins\'], params[1][\'low\'], params[1][\'high\'],\n                    params[2][\'nbins\'], params[2][\'low\'], params[2][\'high\'],\n                    name=name, title=title)\n            else:\n                if params[0][\'bins\'] is None:\n                    step = ((params[0][\'high\'] - params[0][\'low\'])\n                            / float(params[0][\'nbins\']))\n                    params[0][\'bins\'] = [\n                        params[0][\'low\'] + n * step\n                        for n in range(params[0][\'nbins\'] + 1)]\n                if params[1][\'bins\'] is None:\n                    step = ((params[1][\'high\'] - params[1][\'low\'])\n                            / float(params[1][\'nbins\']))\n                    params[1][\'bins\'] = [\n                        params[1][\'low\'] + n * step\n                        for n in range(params[1][\'nbins\'] + 1)]\n                if params[2][\'bins\'] is None:\n                    step = ((params[2][\'high\'] - params[2][\'low\'])\n                            / float(params[2][\'nbins\']))\n                    params[2][\'bins\'] = [\n                        params[2][\'low\'] + n * step\n                        for n in range(params[2][\'nbins\'] + 1)]\n                super(Hist3D, self).__init__(\n                    params[0][\'nbins\'], array(\'d\', params[0][\'bins\']),\n                    params[1][\'nbins\'], array(\'d\', params[1][\'bins\']),\n                    params[2][\'nbins\'], array(\'d\', params[2][\'bins\']),\n                    name=name, title=title)\n            self._post_init(**kwargs)\n\n    return Hist3D\n\n\n_HIST_CLASSES_1D = {}\n_HIST_CLASSES_2D = {}\n_HIST_CLASSES_3D = {}\n\nfor bintype in _HistBase.TYPES.keys():\n    cls = _Hist_class(type=bintype)\n    snake_case_methods(cls)\n    _HIST_CLASSES_1D[bintype] = cls\n\n    cls = _Hist2D_class(type=bintype)\n    snake_case_methods(cls)\n    _HIST_CLASSES_2D[bintype] = cls\n\n    cls = _Hist3D_class(type=bintype)\n    snake_case_methods(cls)\n    _HIST_CLASSES_3D[bintype] = cls\n\n\nclass Hist(_Hist, QROOT.TH1):\n    """"""\n    Returns a 1-dimensional Hist object which inherits from the associated\n    ROOT.TH1* class (where * is C, S, I, F, or D depending on the type\n    keyword argument)\n    """"""\n    _ROOT = QROOT.TH1\n\n    @classmethod\n    def dynamic_cls(cls, type=\'F\'):\n        return _HIST_CLASSES_1D[type]\n\n    def __new__(cls, *args, **kwargs):\n        if len(args) == 1:\n            other = args[0]\n            kwargs.setdefault(\'type\', \'F\')\n            if isinstance(other, HistView):\n                obj = Hist(other.xedges, **kwargs)\n                obj.fill_view(other.hist[:])\n                obj.entries = other.hist.entries\n                return obj\n            elif isinstance(other, _Hist):\n                obj = other.empty_clone(**kwargs)\n                obj[:] = other[:]\n                obj.entries = other.entries\n                return obj\n            elif isinstance(other, _Graph1DBase):\n                # attempt to convert graph to histogram\n                if len(other) == 0:\n                    raise ValueError(""cannot construct a histogram ""\n                                     ""from an empty graph"")\n                edges = [other.x(0) - other.xerrl(0)] # first edge\n                values = []\n                errors = []\n                for ipoint in range(len(other)):\n                    edges.append(other.x(ipoint) + other.xerrh(ipoint))\n                    values.append(other.y(ipoint))\n                    errors.append(max(abs(other.yerrh(ipoint)),\n                                      abs(other.yerrl(ipoint))))\n                obj = Hist(edges, **kwargs)\n                for idx, (y, yerr) in enumerate(zip(values, errors)):\n                    obj[idx + 1] = (y, yerr)\n                return obj\n\n        type = kwargs.pop(\'type\', \'F\').upper()\n        return cls.dynamic_cls(type)(*args, **kwargs)\n\n\n# alias Hist1D -> Hist\nHist1D = Hist\n\n\nclass Hist2D(_Hist2D, QROOT.TH2):\n    """"""\n    Returns a 2-dimensional Hist object which inherits from the associated\n    ROOT.TH1* class (where * is C, S, I, F, or D depending on the type\n    keyword argument)\n    """"""\n    _ROOT = QROOT.TH2\n\n    @classmethod\n    def dynamic_cls(cls, type=\'F\'):\n        return _HIST_CLASSES_2D[type]\n\n    def __new__(cls, *args, **kwargs):\n        if len(args) == 1:\n            other = args[0]\n            kwargs.setdefault(\'type\', \'F\')\n            if isinstance(other, Hist2DView):\n                obj = Hist2D(other.xedges, other.yedges, **kwargs)\n                obj.fill_view(other.hist[:,:])\n                obj.entries = other.hist.entries\n                return obj\n            elif isinstance(other, _Hist2D):\n                obj = other.empty_clone(**kwargs)\n                obj[:] = other[:]\n                obj.entries = other.entries\n                return obj\n        type = kwargs.pop(\'type\', \'F\').upper()\n        return cls.dynamic_cls(type)(*args, **kwargs)\n\n\nclass Hist3D(_Hist3D, QROOT.TH3):\n    """"""\n    Returns a 3-dimensional Hist object which inherits from the associated\n    ROOT.TH1* class (where * is C, S, I, F, or D depending on the type\n    keyword argument)\n    """"""\n    _ROOT = QROOT.TH3\n\n    @classmethod\n    def dynamic_cls(cls, type=\'F\'):\n        return _HIST_CLASSES_3D[type]\n\n    def __new__(cls, *args, **kwargs):\n        if len(args) == 1:\n            other = args[0]\n            kwargs.setdefault(\'type\', \'F\')\n            if isinstance(other, Hist3DView):\n                obj = Hist3D(other.xedges, other.yedges, other.zedges, **kwargs)\n                obj.fill_view(other.hist[:,:,:])\n                obj.entries = other.hist.entries\n                return obj\n            elif isinstance(other, _Hist3D):\n                obj = other.empty_clone(**kwargs)\n                obj[:] = other[:]\n                obj.entries = other.entries\n                return obj\n        type = kwargs.pop(\'type\', \'F\').upper()\n        return cls.dynamic_cls(type)(\n            *args, **kwargs)\n\n\nclass HistStack(Plottable, NamedObject, QROOT.THStack):\n\n    _ROOT = QROOT.THStack\n\n    def __init__(self, hists=None, name=None, title=None,\n                 stacked=True, **kwargs):\n        super(HistStack, self).__init__(name=name, title=title)\n        self._post_init(hists=hists, stacked=stacked, **kwargs)\n\n    def _post_init(self, hists=None, stacked=True, **kwargs):\n        super(HistStack, self)._post_init(**kwargs)\n        self.hists = []\n        self.dim = 1\n        current_hists = super(HistStack, self).GetHists()\n        if current_hists:\n            for i, hist in enumerate(current_hists):\n                hist = asrootpy(hist)\n                if i == 0:\n                    self.dim = dim(hist)\n                elif dim(hist) != self.dim:\n                    raise TypeError(\n                        ""Dimensions of the contained histograms are not equal"")\n                self.hists.append(hist)\n        self.stacked = stacked\n        if stacked:\n            # histogram binning must be identical\n            self.sum = sum(self.hists) if self.hists else None\n        if hists:\n            for h in hists:\n                self.Add(h)\n\n    def __dim__(self):\n        return self.dim\n\n    def GetHists(self):\n        return [hist for hist in self.hists]\n\n    def Add(self, hist):\n        if isinstance(hist, _Hist) or isinstance(hist, _Hist2D):\n            if not self:\n                self.dim = dim(hist)\n                if self.stacked:\n                    self.sum = hist.Clone()\n            elif dim(self) != dim(hist):\n                raise TypeError(\n                    ""Dimension of histogram does not match dimension ""\n                    ""of already contained histograms"")\n            elif self.stacked:\n                self.sum += hist\n            self.hists.append(hist)\n            super(HistStack, self).Add(hist, hist.drawstyle)\n        else:\n            raise TypeError(\n                ""Only 1D and 2D histograms are supported"")\n\n    def __add__(self, other):\n        if not isinstance(other, HistStack):\n            raise TypeError(\n                ""Addition not supported for HistStack and {0}"".format(\n                    other.__class__.__name__))\n        clone = HistStack()\n        for hist in self:\n            clone.Add(hist)\n        for hist in other:\n            clone.Add(hist)\n        return clone\n\n    def __iadd__(self, other):\n        if not isinstance(other, HistStack):\n            raise TypeError(\n                ""Addition not supported for HistStack and {0}"".format(\n                    other.__class__.__name__))\n        for hist in other:\n            self.Add(hist)\n        return self\n\n    def __len__(self):\n        return len(self.GetHists())\n\n    def __getitem__(self, index):\n        return self.GetHists()[index]\n\n    def __iter__(self):\n        for hist in self.hists:\n            yield hist\n\n    def __nonzero__(self):\n        return len(self) != 0\n\n    __bool__ = __nonzero__\n\n    def Scale(self, value):\n        for hist in self:\n            hist.Scale(value)\n\n    def Integral(self, start=None, end=None):\n        integral = 0\n        if start is not None and end is not None:\n            for hist in self:\n                integral += hist.Integral(start, end)\n        else:\n            for hist in self:\n                integral += hist.Integral()\n        return integral\n\n    def lowerbound(self, axis=0):\n        if not self:\n            return None  # negative infinity\n        return min(hist.lowerbound(axis=axis) for hist in self)\n\n    def upperbound(self, axis=0):\n        if not self:\n            return ()  # positive infinity\n        return max(hist.upperbound(axis=axis) for hist in self)\n\n    def max(self, include_error=False):\n        if not self:\n            return 0\n        if self.stacked:\n            return self.sum.max(include_error=include_error)\n        return max([hist.max(include_error=include_error)\n                    for hist in self.hists])\n\n    def min(self, include_error=False):\n        if not self:\n            return 0\n        if self.stacked:\n            return self.sum.min(include_error=include_error)\n        return min([hist.min(include_error=include_error)\n                    for hist in self.hists])\n\n    def Clone(self, name=None):\n        clone = HistStack(name=name,\n                          title=self.GetTitle(),\n                          stacked=self.stacked,\n                          **self.decorators)\n        for hist in self:\n            clone.Add(hist.Clone())\n        return clone\n\n    def GetHistogram(self):\n        return asrootpy(super(HistStack, self).GetHistogram())\n\n    def GetZaxis(self):\n        # ROOT is missing this method...\n        return self.GetHistogram().zaxis\n\n\n@snake_case_methods\nclass Efficiency(Plottable, NamelessConstructorObject, QROOT.TEfficiency):\n    _ROOT = QROOT.TEfficiency\n\n    def __init__(self, passed, total, name=None, title=None, **kwargs):\n        super(Efficiency, self).__init__(passed, total, name=name, title=title)\n        self._post_init(**kwargs)\n\n    @property\n    def passed(self):\n        return asrootpy(self.GetPassedHistogram())\n\n    @passed.setter\n    def passed(self, hist):\n        self.SetPassedHistogram(hist, \'f\')\n\n    @property\n    def total(self):\n        return asrootpy(self.GetTotalHistogram())\n\n    @total.setter\n    def total(self, hist):\n        self.SetTotalHistogram(hist, \'f\')\n\n    def __len__(self):\n        return len(self.total)\n\n    def __getitem__(self, idx):\n        return self.GetEfficiency(idx)\n\n    def __add__(self, other):\n        copy = self.Clone()\n        copy.Add(other)\n        return copy\n\n    def __iadd__(self, other):\n        super(Efficiency, self).Add(other)\n        return self\n\n    def __iter__(self):\n        for idx in range(len(self)):\n            yield self.GetEfficiency(idx)\n\n    def efficiencies(self, overflow=False):\n        if overflow:\n            start = 0\n            end = len(self)\n        else:\n            start = 1\n            end = len(self) - 1\n        for idx in range(start, end):\n            yield self.GetEfficiency(idx)\n\n    def errors(self, overflow=False):\n        if overflow:\n            start = 0\n            end = len(self)\n        else:\n            start = 1\n            end = len(self) - 1\n        for idx in range(start, end):\n            yield (\n                self.GetEfficiencyErrorLow(idx),\n                self.GetEfficiencyErrorUp(idx))\n\n    def overall_efficiency(self, overflow=False):\n        if self.total.Integral() == 0:\n            return 0\n\n        nbins = self.passed.nbins()\n        if overflow:\n            bins_to_merge = (0, nbins+1)\n        else:\n            bins_to_merge = (1, nbins)\n\n        hpass = self.passed.merge_bins([bins_to_merge])\n        htot = self.total.merge_bins([bins_to_merge])\n        tot_eff = Efficiency(hpass, htot)\n        return (tot_eff.GetEfficiency(1),\n                tot_eff.GetEfficiencyErrorLow(1),\n                tot_eff.GetEfficiencyErrorUp(1))\n\n    @property\n    def graph(self):\n        """""" Create and return the graph for a 1D TEfficiency """"""\n        return asrootpy(self.CreateGraph())\n\n    @property\n    def painted_graph(self):\n        """"""\n        Returns the painted graph for a 1D TEfficiency, or if it isn\'t\n        available, generates one on an `invisible_canvas`.\n        """"""\n        if not self.GetPaintedGraph():\n            with invisible_canvas():\n                self.Draw()\n        assert self.GetPaintedGraph(), (\n            ""Failed to create TEfficiency::GetPaintedGraph"")\n        the_graph = asrootpy(self.GetPaintedGraph())\n        # Ensure it has the same style as this one.\n        the_graph.decorate(**self.decorators)\n        return the_graph\n\n    @property\n    def histogram(self):\n        """""" Create and return the histogram for a 2D TEfficiency """"""\n        return asrootpy(self.CreateHistogram())\n\n    @property\n    def painted_histogram(self):\n        """"""\n        Returns the painted histogram for a 2D TEfficiency, or if it isn\'t\n        available, generates one on an `invisible_canvas`.\n        """"""\n        if not self.GetPaintedHistogram():\n            with invisible_canvas():\n                self.Draw()\n        assert self.GetPaintedHistogram(), (\n            ""Failed to create TEfficiency::GetPaintedHistogram"")\n        the_hist = asrootpy(self.GetPaintedHistogram())\n        # Ensure it has the same style as this one.\n        the_hist.decorate(**self.decorators)\n        return the_hist\n\n\ndef histogram(data, *args, **kwargs):\n    """"""\n    Create and fill a one-dimensional histogram.\n\n    The same arguments as the ``Hist`` class are expected.\n    If the number of bins and the ranges are not specified they are\n    automatically deduced with the ``autobinning`` function using the method\n    specified by the ``binning`` argument. Only one-dimensional histogramming\n    is supported.\n    """"""\n    from .autobinning import autobinning\n    dim = kwargs.pop(\'dim\', 1)\n    if dim != 1:\n        raise NotImplementedError\n    if \'binning\' in kwargs:\n        args = autobinning(data, kwargs[\'binning\'])\n        del kwargs[\'binning\']\n    histo = Hist(*args, **kwargs)\n    for d in data:\n        histo.Fill(d)\n    return list(histo.xedgesl()), histo\n'"
rootpy/plotting/legend.py,0,"b'from __future__ import absolute_import\n\nimport numbers\n\nfrom .. import ROOT, QROOT, asrootpy\nfrom ..base import Object\nfrom .hist import HistStack\nfrom .box import _Positionable\nfrom ..memory.keepalive import keepalive\n\n__all__ = [\n    \'Legend\',\n]\n\n\nclass Legend(_Positionable, Object, QROOT.TLegend):\n    _ROOT = QROOT.TLegend\n\n    def __init__(self, entries,\n                 pad=None,\n                 leftmargin=0.5,\n                 topmargin=0.05,\n                 rightmargin=0.05,\n                 entryheight=0.06,\n                 entrysep=0.02,\n                 margin=0.3,\n                 textfont=None,\n                 textsize=None,\n                 header=None):\n        if pad is None:\n            pad = ROOT.gPad\n        if not pad:\n            raise RuntimeError(""create a pad before a legend"")\n\n        entries_is_list = False\n        if isinstance(entries, numbers.Integral):\n            # entries is the expected number of entries that will be included\n            # in the legend\n            nentries = entries\n        else:\n            # entries is a list of objects to become entries in the legend\n            entries_is_list = True\n            nentries = len(entries)\n\n        if header is not None:\n            nentries += 1\n        height = (entryheight + entrysep) * nentries - entrysep\n\n        super(Legend, self).__init__(\n            pad.GetLeftMargin() + leftmargin,\n            (1. - pad.GetTopMargin() - topmargin) - height,\n            1. - pad.GetRightMargin() - rightmargin,\n            ((1. - pad.GetTopMargin()) - topmargin))\n\n        self.SetEntrySeparation(entrysep)\n        self.SetMargin(margin)\n        if header is not None:\n            self.SetHeader(header)\n\n        # ROOT, why are you filling my legend with a\n        # grey background by default?\n        self.SetFillStyle(0)\n        self.SetFillColor(0)\n\n        if textfont is None:\n            textfont = ROOT.gStyle.GetLegendFont()\n        if textsize is None:\n            textsize = ROOT.gStyle.GetTextSize()\n\n        self.SetTextFont(textfont)\n        self.SetTextSize(textsize)\n\n        if entries_is_list:\n            for thing in entries:\n                self.AddEntry(thing)\n\n    def Height(self):\n        return abs(self.GetY2() - self.GetY1())\n\n    def Width(self):\n        return abs(self.GetX2() - self.GetX1())\n\n    def Draw(self, *args, **kwargs):\n        self.UseCurrentStyle()\n        super(Legend, self).Draw(*args, **kwargs)\n\n    def AddEntry(self, thing, label=None, style=None):\n        """"""\n        Add an entry to the legend.\n\n        If `label` is None, `thing.GetTitle()` will be used as the label.\n\n        If `style` is None, `thing.legendstyle` is used if present,\n        otherwise `P`.\n        """"""\n        if isinstance(thing, HistStack):\n            things = thing\n        else:\n            things = [thing]\n        for thing in things:\n            if getattr(thing, \'inlegend\', True):\n                thing_label = thing.GetTitle() if label is None else label\n                thing_style = getattr(thing, \'legendstyle\', \'P\') if style is None else style\n                super(Legend, self).AddEntry(thing, thing_label, thing_style)\n                keepalive(self, thing)\n\n    @property\n    def primitives(self):\n        return asrootpy(self.GetListOfPrimitives())\n'"
rootpy/plotting/profile.py,0,"b'from __future__ import absolute_import\n\nfrom array import array\n\nfrom .. import QROOT, log; log = log[__name__]\nfrom ..extern.six.moves import range\nfrom .hist import _Hist, _Hist2D, _Hist3D\n\n__all__ = [\n    \'Profile\',\n    \'Profile1D\',\n    \'Profile2D\',\n    \'Profile3D\',\n]\n\n\nclass _ProfileBase(object):\n    pass\n\n\nclass Profile(_ProfileBase, _Hist, QROOT.TProfile):\n    _ROOT = QROOT.TProfile\n\n    def __init__(self, *args, **kwargs):\n        option = kwargs.pop(\'option\', \'\')\n        name = kwargs.pop(\'name\', None)\n        title = kwargs.pop(\'title\', None)\n        params, args = self._parse_args(args, ignore_extras=True)\n        if args:\n            if len(args) != 2:\n                raise TypeError(""Did not receive expected number of arguments"")\n            low, high = args\n            if low >= high:\n                raise ValueError(\n                    ""Upper bound (you gave {0:f}) must be greater than lower ""\n                    ""bound (you gave {1:f})"".format(float(low), float(high)))\n        args = list(args)\n        args.append(option)\n        if params[0][\'bins\'] is None:\n            super(Profile, self).__init__(\n                params[0][\'nbins\'], params[0][\'low\'], params[0][\'high\'],\n                *args, name=name, title=title)\n        else:\n            super(Profile, self).__init__(\n                params[0][\'nbins\'], array(\'d\', params[0][\'bins\']),\n                *args, name=name, title=title)\n        self._post_init(**kwargs)\n\n\n# alias Profile1D -> Profile\nProfile1D = Profile\n\n\nclass Profile2D(_ProfileBase, _Hist2D, QROOT.TProfile2D):\n    _ROOT = QROOT.TProfile2D\n\n    def __init__(self, *args, **kwargs):\n        option = kwargs.pop(\'option\', \'\')\n        name = kwargs.pop(\'name\', None)\n        title = kwargs.pop(\'title\', None)\n        params, args = self._parse_args(args, ignore_extras=True)\n        if args:\n            if len(args) != 2:\n                raise TypeError(""Did not receive expected number of arguments"")\n            low, high = args\n            if low >= high:\n                raise ValueError(\n                    ""Upper bound (you gave {0:f}) must be greater than lower ""\n                    ""bound (you gave {1:f})"".format(float(low), float(high)))\n        args = list(args)\n        args.append(option)\n        if params[0][\'bins\'] is None and params[1][\'bins\'] is None:\n            super(Profile2D, self).__init__(\n                params[0][\'nbins\'], params[0][\'low\'], params[0][\'high\'],\n                params[1][\'nbins\'], params[1][\'low\'], params[1][\'high\'],\n                *args, name=name, title=title)\n        elif params[0][\'bins\'] is None and params[1][\'bins\'] is not None:\n            super(Profile2D, self).__init__(\n                params[0][\'nbins\'], params[0][\'low\'], params[0][\'high\'],\n                params[1][\'nbins\'], array(\'d\', params[1][\'bins\']),\n                *args, name=name, title=title)\n        elif params[0][\'bins\'] is not None and params[1][\'bins\'] is None:\n            super(Profile2D, self).__init__(\n                params[0][\'nbins\'], array(\'d\', params[0][\'bins\']),\n                params[1][\'nbins\'], params[1][\'low\'], params[1][\'high\'],\n                *args, name=name, title=title)\n        else:\n            super(Profile2D, self).__init__(\n                params[0][\'nbins\'], array(\'d\', params[0][\'bins\']),\n                params[1][\'nbins\'], array(\'d\', params[1][\'bins\']),\n                *args, name=name, title=title)\n        self._post_init(**kwargs)\n\n\nclass Profile3D(_ProfileBase, _Hist3D, QROOT.TProfile3D):\n    _ROOT = QROOT.TProfile3D\n\n    def __init__(self, *args, **kwargs):\n        option = kwargs.pop(\'option\', \'\')\n        name = kwargs.pop(\'name\', None)\n        title = kwargs.pop(\'title\', None)\n        # Profile3D does not support t_low, t_up\n        params = self._parse_args(args)\n        # ROOT is missing constructors for TH3...\n        if (params[0][\'bins\'] is None and\n                params[1][\'bins\'] is None and\n                params[2][\'bins\'] is None):\n            super(Profile3D, self).__init__(\n                params[0][\'nbins\'], params[0][\'low\'], params[0][\'high\'],\n                params[1][\'nbins\'], params[1][\'low\'], params[1][\'high\'],\n                params[2][\'nbins\'], params[2][\'low\'], params[2][\'high\'],\n                option, name=name, title=title)\n        else:\n            if params[0][\'bins\'] is None:\n                step = ((params[0][\'high\'] - params[0][\'low\'])\n                        / float(params[0][\'nbins\']))\n                params[0][\'bins\'] = [\n                    params[0][\'low\'] + n * step\n                    for n in range(params[0][\'nbins\'] + 1)]\n            if params[1][\'bins\'] is None:\n                step = ((params[1][\'high\'] - params[1][\'low\'])\n                        / float(params[1][\'nbins\']))\n                params[1][\'bins\'] = [\n                    params[1][\'low\'] + n * step\n                    for n in range(params[1][\'nbins\'] + 1)]\n            if params[2][\'bins\'] is None:\n                step = ((params[2][\'high\'] - params[2][\'low\'])\n                        / float(params[2][\'nbins\']))\n                params[2][\'bins\'] = [\n                    params[2][\'low\'] + n * step\n                    for n in range(params[2][\'nbins\'] + 1)]\n            super(Profile3D, self).__init__(\n                params[0][\'nbins\'], array(\'d\', params[0][\'bins\']),\n                params[1][\'nbins\'], array(\'d\', params[1][\'bins\']),\n                params[2][\'nbins\'], array(\'d\', params[2][\'bins\']),\n                option, name=name, title=title)\n        self._post_init(**kwargs)\n'"
rootpy/plotting/root2matplotlib.py,19,"b'""""""\nThis module provides functions that allow the plotting of ROOT histograms and\ngraphs with `matplotlib <http://matplotlib.org/>`_.\n\nIf you just want to save image files and don\'t want matplotlib to attempt to\ncreate a graphical window, tell matplotlib to use a non-interactive backend\nsuch as ``Agg`` when importing it for the first time (i.e. before importing\nrootpy.plotting.root2matplotlib)::\n\n   import matplotlib\n   matplotlib.use(\'Agg\') # do this before importing pyplot or root2matplotlib\n\nThis puts matplotlib in a batch state similar to ``ROOT.gROOT.SetBatch(True)``.\n""""""\nfrom __future__ import absolute_import\n\n# trigger ROOT\'s finalSetup (GUI thread) before matplotlib\'s\nimport ROOT\nROOT.kTRUE\n\nfrom math import sqrt\ntry:\n    from itertools import izip as zip\nexcept ImportError: # will be 3.x series\n    pass\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom ..extern.six.moves import range\nfrom .hist import _Hist\nfrom .graph import _Graph1DBase\nfrom .utils import get_limits\n\n\n__all__ = [\n    \'hist\',\n    \'bar\',\n    \'errorbar\',\n    \'fill_between\',\n    \'step\',\n    \'hist2d\',\n    \'imshow\',\n    \'contour\',\n]\n\n\ndef _set_defaults(obj, kwargs, types=[\'common\']):\n    defaults = {}\n    for key in types:\n        if key == \'common\':\n            defaults[\'label\'] = obj.GetTitle()\n            defaults[\'visible\'] = getattr(obj, \'visible\', True)\n            defaults[\'alpha\'] = getattr(obj, \'alpha\', None)\n        elif key == \'line\':\n            defaults[\'linestyle\'] = obj.GetLineStyle(\'mpl\')\n            defaults[\'linewidth\'] = obj.GetLineWidth()\n        elif key == \'fill\':\n            defaults[\'edgecolor\'] = kwargs.get(\'color\', obj.GetLineColor(\'mpl\'))\n            defaults[\'facecolor\'] = kwargs.get(\'color\', obj.GetFillColor(\'mpl\'))\n            root_fillstyle = obj.GetFillStyle(\'root\')\n            if root_fillstyle == 0:\n                if not kwargs.get(\'fill\'):\n                    defaults[\'facecolor\'] = \'none\'\n                defaults[\'fill\'] = False\n            elif root_fillstyle == 1001:\n                defaults[\'fill\'] = True\n            else:\n                defaults[\'hatch\'] = obj.GetFillStyle(\'mpl\')\n                defaults[\'facecolor\'] = \'none\'\n        elif key == \'marker\':\n            defaults[\'marker\'] = obj.GetMarkerStyle(\'mpl\')\n            defaults[\'markersize\'] = obj.GetMarkerSize() * 5\n            defaults[\'markeredgecolor\'] = obj.GetMarkerColor(\'mpl\')\n            defaults[\'markerfacecolor\'] = obj.GetMarkerColor(\'mpl\')\n        elif key == \'errors\':\n            defaults[\'ecolor\'] = obj.GetLineColor(\'mpl\')\n        elif key == \'errorbar\':\n            defaults[\'fmt\'] = obj.GetMarkerStyle(\'mpl\')\n    for key, value in defaults.items():\n        if key not in kwargs:\n            kwargs[key] = value\n\n\ndef _set_bounds(h,\n                axes=None,\n                was_empty=True,\n                prev_xlim=None,\n                prev_ylim=None,\n                xpadding=0,\n                ypadding=.1,\n                xerror_in_padding=True,\n                yerror_in_padding=True,\n                snap=True,\n                logx=None,\n                logy=None):\n    if axes is None:\n        axes = plt.gca()\n    if prev_xlim is None:\n        prev_xlim = plt.xlim()\n    if prev_ylim is None:\n        prev_ylim = plt.ylim()\n    if logx is None:\n        logx = axes.get_xscale() == \'log\'\n    if logy is None:\n        logy = axes.get_yscale() == \'log\'\n    xmin, xmax, ymin, ymax = get_limits(\n        h,\n        xpadding=xpadding,\n        ypadding=ypadding,\n        xerror_in_padding=xerror_in_padding,\n        yerror_in_padding=yerror_in_padding,\n        snap=snap,\n        logx=logx,\n        logy=logy)\n    if was_empty:\n        axes.set_xlim([xmin, xmax])\n        axes.set_ylim([ymin, ymax])\n    else:\n        prev_xmin, prev_xmax = prev_xlim\n        if logx and prev_xmin <= 0:\n            axes.set_xlim([xmin, max(prev_xmax, xmax)])\n        else:\n            axes.set_xlim([min(prev_xmin, xmin), max(prev_xmax, xmax)])\n        prev_ymin, prev_ymax = prev_ylim\n        if logy and prev_ymin <= 0:\n            axes.set_ylim([ymin, max(prev_ymax, ymax)])\n        else:\n            axes.set_ylim([min(prev_ymin, ymin), max(prev_ymax, ymax)])\n\n\ndef _get_highest_zorder(axes):\n    return max([c.get_zorder() for c in axes.get_children()])\n\n\ndef _maybe_reversed(x, reverse=False):\n    if reverse:\n        return reversed(x)\n    return x\n\n\ndef hist(hists,\n         stacked=True,\n         reverse=False,\n         xpadding=0, ypadding=.1,\n         yerror_in_padding=True,\n         logy=None,\n         snap=True,\n         axes=None,\n         **kwargs):\n    """"""\n    Make a matplotlib hist plot from a ROOT histogram, stack or\n    list of histograms.\n\n    Parameters\n    ----------\n\n    hists : Hist, list of Hist, HistStack\n        The histogram(s) to be plotted\n\n    stacked : bool, optional (default=True)\n        If True then stack the histograms with the first histogram on the\n        bottom, otherwise overlay them with the first histogram in the\n        background.\n\n    reverse : bool, optional (default=False)\n        If True then reverse the order of the stack or overlay.\n\n    xpadding : float or 2-tuple of floats, optional (default=0)\n        Padding to add on the left and right sides of the plot as a fraction of\n        the axes width after the padding has been added. Specify unique left\n        and right padding with a 2-tuple.\n\n    ypadding : float or 2-tuple of floats, optional (default=.1)\n        Padding to add on the top and bottom of the plot as a fraction of\n        the axes height after the padding has been added. Specify unique top\n        and bottom padding with a 2-tuple.\n\n    yerror_in_padding : bool, optional (default=True)\n        If True then make the padding inclusive of the y errors otherwise\n        only pad around the y values.\n\n    logy : bool, optional (default=None)\n        Apply special treatment of a log-scale y-axis to display the histogram\n        correctly. If None (the default) then automatically determine if the\n        y-axis is log-scale.\n\n    snap : bool, optional (default=True)\n        If True (the default) then the origin is an implicit lower bound of the\n        histogram unless the histogram has both positive and negative bins.\n\n    axes : matplotlib Axes instance, optional (default=None)\n        The axes to plot on. If None then use the global current axes.\n\n    kwargs : additional keyword arguments, optional\n        All additional keyword arguments are passed to matplotlib\'s\n        fill_between for the filled regions and matplotlib\'s step function\n        for the edges.\n\n    Returns\n    -------\n\n    The return value from matplotlib\'s hist function, or list of such return\n    values if a stack or list of histograms was plotted.\n\n    """"""\n    if axes is None:\n        axes = plt.gca()\n    if logy is None:\n        logy = axes.get_yscale() == \'log\'\n    curr_xlim = axes.get_xlim()\n    curr_ylim = axes.get_ylim()\n    was_empty = not axes.has_data()\n    returns = []\n    if isinstance(hists, _Hist):\n        # This is a single plottable object.\n        returns = _hist(hists, axes=axes, logy=logy, **kwargs)\n        _set_bounds(hists, axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    elif stacked:\n        # draw the top histogram first so its edges don\'t cover the histograms\n        # beneath it in the stack\n        if not reverse:\n            hists = list(hists)[::-1]\n        for i, h in enumerate(hists):\n            kwargs_local = kwargs.copy()\n            if i == len(hists) - 1:\n                low = h.Clone()\n                low.Reset()\n            else:\n                low = sum(hists[i + 1:])\n            high = h + low\n            high.alpha = getattr(h, \'alpha\', None)\n            proxy = _hist(high, bottom=low, axes=axes, logy=logy, **kwargs)\n            returns.append(proxy)\n        if not reverse:\n            returns = returns[::-1]\n        _set_bounds(sum(hists), axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    else:\n        for h in _maybe_reversed(hists, reverse):\n            returns.append(_hist(h, axes=axes, logy=logy, **kwargs))\n        if reverse:\n            returns = returns[::-1]\n        _set_bounds(hists[max(range(len(hists)), key=lambda idx: hists[idx].max())],\n                    axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    return returns\n\n\ndef _hist(h, axes=None, bottom=None, logy=None, zorder=None, **kwargs):\n    if axes is None:\n        axes = plt.gca()\n    if zorder is None:\n        zorder = _get_highest_zorder(axes) + 1\n    _set_defaults(h, kwargs, [\'common\', \'line\', \'fill\'])\n    kwargs_proxy = kwargs.copy()\n    fill = kwargs.pop(\'fill\', False) or (\'hatch\' in kwargs)\n    if fill:\n        # draw the fill without the edge\n        if bottom is None:\n            bottom = h.Clone()\n            bottom.Reset()\n        fill_between(bottom, h, axes=axes, logy=logy, linewidth=0,\n                     facecolor=kwargs[\'facecolor\'],\n                     edgecolor=kwargs[\'edgecolor\'],\n                     hatch=kwargs.get(\'hatch\', None),\n                     alpha=kwargs[\'alpha\'],\n                     zorder=zorder)\n    # draw the edge\n    s = step(h, axes=axes, logy=logy, label=None,\n         zorder=zorder + 1, alpha=kwargs[\'alpha\'],\n         color=kwargs.get(\'color\'))\n    # draw the legend proxy\n    if getattr(h, \'legendstyle\', \'\').upper() == \'F\':\n        proxy = plt.Rectangle((0, 0), 0, 0, **kwargs_proxy)\n        axes.add_patch(proxy)\n    else:\n        # be sure the linewidth is greater than zero...\n        proxy = plt.Line2D((0, 0), (0, 0),\n                           linestyle=kwargs_proxy[\'linestyle\'],\n                           linewidth=kwargs_proxy[\'linewidth\'],\n                           color=kwargs_proxy[\'edgecolor\'],\n                           alpha=kwargs[\'alpha\'],\n                           label=kwargs_proxy[\'label\'])\n        axes.add_line(proxy)\n    return proxy, s[0]\n\n\ndef bar(hists,\n        stacked=True,\n        reverse=False,\n        xerr=False, yerr=True,\n        xpadding=0, ypadding=.1,\n        yerror_in_padding=True,\n        rwidth=0.8,\n        snap=True,\n        axes=None,\n        **kwargs):\n    """"""\n    Make a matplotlib bar plot from a ROOT histogram, stack or\n    list of histograms.\n\n    Parameters\n    ----------\n\n    hists : Hist, list of Hist, HistStack\n        The histogram(s) to be plotted\n\n    stacked : bool or string, optional (default=True)\n        If True then stack the histograms with the first histogram on the\n        bottom, otherwise overlay them with the first histogram in the\n        background. If \'cluster\', then the bars will be arranged side-by-side.\n\n    reverse : bool, optional (default=False)\n        If True then reverse the order of the stack or overlay.\n\n    xerr : bool, optional (default=False)\n        If True, x error bars will be displayed.\n\n    yerr : bool or string, optional (default=True)\n        If False, no y errors are displayed.  If True, an individual y\n        error will be displayed for each hist in the stack.  If \'linear\' or\n        \'quadratic\', a single error bar will be displayed with either the\n        linear or quadratic sum of the individual errors.\n\n    xpadding : float or 2-tuple of floats, optional (default=0)\n        Padding to add on the left and right sides of the plot as a fraction of\n        the axes width after the padding has been added. Specify unique left\n        and right padding with a 2-tuple.\n\n    ypadding : float or 2-tuple of floats, optional (default=.1)\n        Padding to add on the top and bottom of the plot as a fraction of\n        the axes height after the padding has been added. Specify unique top\n        and bottom padding with a 2-tuple.\n\n    yerror_in_padding : bool, optional (default=True)\n        If True then make the padding inclusive of the y errors otherwise\n        only pad around the y values.\n\n    rwidth : float, optional (default=0.8)\n        The relative width of the bars as a fraction of the bin width.\n\n    snap : bool, optional (default=True)\n        If True (the default) then the origin is an implicit lower bound of the\n        histogram unless the histogram has both positive and negative bins.\n\n    axes : matplotlib Axes instance, optional (default=None)\n        The axes to plot on. If None then use the global current axes.\n\n    kwargs : additional keyword arguments, optional\n        All additional keyword arguments are passed to matplotlib\'s bar\n        function.\n\n    Returns\n    -------\n\n    The return value from matplotlib\'s bar function, or list of such return\n    values if a stack or list of histograms was plotted.\n\n    """"""\n    if axes is None:\n        axes = plt.gca()\n    curr_xlim = axes.get_xlim()\n    curr_ylim = axes.get_ylim()\n    was_empty = not axes.has_data()\n    logy = kwargs.pop(\'log\', axes.get_yscale() == \'log\')\n    kwargs[\'log\'] = logy\n    returns = []\n    if isinstance(hists, _Hist):\n        # This is a single histogram.\n        returns = _bar(hists, xerr=xerr, yerr=yerr,\n                       axes=axes, **kwargs)\n        _set_bounds(hists, axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    elif stacked == \'cluster\':\n        nhists = len(hists)\n        hlist = _maybe_reversed(hists, reverse)\n        for i, h in enumerate(hlist):\n            width = rwidth / nhists\n            offset = (1 - rwidth) / 2 + i * width\n            returns.append(_bar(\n                h, offset, width,\n                xerr=xerr, yerr=yerr, axes=axes, **kwargs))\n        _set_bounds(sum(hists), axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    elif stacked is True:\n        nhists = len(hists)\n        hlist = _maybe_reversed(hists, reverse)\n        toterr = bottom = None\n        if yerr == \'linear\':\n            toterr = [sum([h.GetBinError(i) for h in hists])\n                      for i in range(1, hists[0].nbins(0) + 1)]\n        elif yerr == \'quadratic\':\n            toterr = [sqrt(sum([h.GetBinError(i) ** 2 for h in hists]))\n                      for i in range(1, hists[0].nbins(0) + 1)]\n        for i, h in enumerate(hlist):\n            err = None\n            if yerr is True:\n                err = True\n            elif yerr and i == (nhists - 1):\n                err = toterr\n            returns.append(_bar(\n                h,\n                xerr=xerr, yerr=err,\n                bottom=list(bottom.y()) if bottom else None,\n                axes=axes, **kwargs))\n            if bottom is None:\n                bottom = h.Clone()\n            else:\n                bottom += h\n        _set_bounds(bottom, axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    else:\n        hlist = _maybe_reversed(hists, reverse)\n        for h in hlist:\n            returns.append(_bar(h, xerr=xerr, yerr=yerr,\n                                axes=axes, **kwargs))\n        _set_bounds(hists[max(range(len(hists)), key=lambda idx: hists[idx].max())],\n                    axes=axes,\n                    was_empty=was_empty,\n                    prev_xlim=curr_xlim,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap,\n                    logy=logy)\n    return returns\n\n\ndef _bar(h, roffset=0., rwidth=1., xerr=None, yerr=None, axes=None, **kwargs):\n    if axes is None:\n        axes = plt.gca()\n    if xerr:\n        xerr = np.array([list(h.xerrl()), list(h.xerrh())])\n    if yerr:\n        yerr = np.array([list(h.yerrl()), list(h.yerrh())])\n    _set_defaults(h, kwargs, [\'common\', \'line\', \'fill\', \'errors\'])\n    width = [x * rwidth for x in h.xwidth()]\n    left = [h.xedgesl(i) + h.xwidth(i) * roffset\n            for i in range(1, h.nbins(0) + 1)]\n    height = list(h.y())\n    return axes.bar(left, height, width=width, xerr=xerr, yerr=yerr, **kwargs)\n\n\ndef errorbar(hists,\n             xerr=True, yerr=True,\n             xpadding=0, ypadding=.1,\n             xerror_in_padding=True,\n             yerror_in_padding=True,\n             emptybins=True,\n             snap=True,\n             axes=None,\n             **kwargs):\n    """"""\n    Make a matplotlib errorbar plot from a ROOT histogram or graph\n    or list of histograms and graphs.\n\n    Parameters\n    ----------\n\n    hists : Hist, Graph or list of Hist and Graph\n        The histogram(s) and/or Graph(s) to be plotted\n\n    xerr : bool, optional (default=True)\n        If True, x error bars will be displayed.\n\n    yerr : bool or string, optional (default=True)\n        If False, no y errors are displayed.  If True, an individual y\n        error will be displayed for each hist in the stack.  If \'linear\' or\n        \'quadratic\', a single error bar will be displayed with either the\n        linear or quadratic sum of the individual errors.\n\n    xpadding : float or 2-tuple of floats, optional (default=0)\n        Padding to add on the left and right sides of the plot as a fraction of\n        the axes width after the padding has been added. Specify unique left\n        and right padding with a 2-tuple.\n\n    ypadding : float or 2-tuple of floats, optional (default=.1)\n        Padding to add on the top and bottom of the plot as a fraction of\n        the axes height after the padding has been added. Specify unique top\n        and bottom padding with a 2-tuple.\n\n    xerror_in_padding : bool, optional (default=True)\n        If True then make the padding inclusive of the x errors otherwise\n        only pad around the x values.\n\n    yerror_in_padding : bool, optional (default=True)\n        If True then make the padding inclusive of the y errors otherwise\n        only pad around the y values.\n\n    emptybins : bool, optional (default=True)\n        If True (the default) then plot bins with zero content otherwise only\n        show bins with nonzero content.\n\n    snap : bool, optional (default=True)\n        If True (the default) then the origin is an implicit lower bound of the\n        histogram unless the histogram has both positive and negative bins.\n\n    axes : matplotlib Axes instance, optional (default=None)\n        The axes to plot on. If None then use the global current axes.\n\n    kwargs : additional keyword arguments, optional\n        All additional keyword arguments are passed to matplotlib\'s errorbar\n        function.\n\n    Returns\n    -------\n\n    The return value from matplotlib\'s errorbar function, or list of such\n    return values if a list of histograms and/or graphs was plotted.\n\n    """"""\n    if axes is None:\n        axes = plt.gca()\n    curr_xlim = axes.get_xlim()\n    curr_ylim = axes.get_ylim()\n    was_empty = not axes.has_data()\n    if isinstance(hists, (_Hist, _Graph1DBase)):\n        # This is a single plottable object.\n        returns = _errorbar(\n            hists, xerr, yerr,\n            axes=axes, emptybins=emptybins, **kwargs)\n        _set_bounds(hists, axes=axes,\n                    was_empty=was_empty,\n                    prev_ylim=curr_ylim,\n                    xpadding=xpadding, ypadding=ypadding,\n                    xerror_in_padding=xerror_in_padding,\n                    yerror_in_padding=yerror_in_padding,\n                    snap=snap)\n    else:\n        returns = []\n        for h in hists:\n            returns.append(errorbar(\n                h, xerr=xerr, yerr=yerr, axes=axes,\n                xpadding=xpadding, ypadding=ypadding,\n                xerror_in_padding=xerror_in_padding,\n                yerror_in_padding=yerror_in_padding,\n                snap=snap,\n                emptybins=emptybins,\n                **kwargs))\n    return returns\n\n\ndef _errorbar(h, xerr, yerr, axes=None, emptybins=True, zorder=None, **kwargs):\n    if axes is None:\n        axes = plt.gca()\n    if zorder is None:\n        zorder = _get_highest_zorder(axes) + 1\n    _set_defaults(h, kwargs, [\'common\', \'errors\', \'errorbar\', \'marker\'])\n    if xerr:\n        xerr = np.array([list(h.xerrl()), list(h.xerrh())])\n    if yerr:\n        yerr = np.array([list(h.yerrl()), list(h.yerrh())])\n    x = np.array(list(h.x()))\n    y = np.array(list(h.y()))\n    if not emptybins:\n        nonempty = y != 0\n        x = x[nonempty]\n        y = y[nonempty]\n        if xerr is not False and xerr is not None:\n            xerr = xerr[:, nonempty]\n        if yerr is not False and yerr is not None:\n            yerr = yerr[:, nonempty]\n    return axes.errorbar(x, y, xerr=xerr, yerr=yerr, zorder=zorder, **kwargs)\n\n\ndef step(h, logy=None, axes=None, **kwargs):\n    """"""\n    Make a matplotlib step plot from a ROOT histogram.\n\n    Parameters\n    ----------\n\n    h : Hist\n        A rootpy Hist\n\n    logy : bool, optional (default=None)\n        If True then clip the y range between 1E-300 and 1E300.\n        If None (the default) then automatically determine if the axes are\n        log-scale and if this clipping should be performed.\n\n    axes : matplotlib Axes instance, optional (default=None)\n        The axes to plot on. If None then use the global current axes.\n\n    kwargs : additional keyword arguments, optional\n        Additional keyword arguments are passed directly to\n        matplotlib\'s fill_between function.\n\n    Returns\n    -------\n\n    Returns the value from matplotlib\'s fill_between function.\n\n    """"""\n    if axes is None:\n        axes = plt.gca()\n    if logy is None:\n        logy = axes.get_yscale() == \'log\'\n    _set_defaults(h, kwargs, [\'common\', \'line\'])\n    if kwargs.get(\'color\') is None:\n        kwargs[\'color\'] = h.GetLineColor(\'mpl\')\n    y = np.array(list(h.y()) + [0.])\n    if logy:\n        np.clip(y, 1E-300, 1E300, out=y)\n    return axes.step(list(h.xedges()), y, where=\'post\', **kwargs)\n\n\ndef fill_between(a, b, logy=None, axes=None, **kwargs):\n    """"""\n    Fill the region between two histograms or graphs.\n\n    Parameters\n    ----------\n\n    a : Hist\n        A rootpy Hist\n\n    b : Hist\n        A rootpy Hist\n\n    logy : bool, optional (default=None)\n        If True then clip the region between 1E-300 and 1E300.\n        If None (the default) then automatically determine if the axes are\n        log-scale and if this clipping should be performed.\n\n    axes : matplotlib Axes instance, optional (default=None)\n        The axes to plot on. If None then use the global current axes.\n\n    kwargs : additional keyword arguments, optional\n        Additional keyword arguments are passed directly to\n        matplotlib\'s fill_between function.\n\n    Returns\n    -------\n\n    Returns the value from matplotlib\'s fill_between function.\n\n    """"""\n    if axes is None:\n        axes = plt.gca()\n    if logy is None:\n        logy = axes.get_yscale() == \'log\'\n    if not isinstance(a, _Hist) or not isinstance(b, _Hist):\n        raise TypeError(\n            ""fill_between only operates on 1D histograms"")\n    a.check_compatibility(b, check_edges=True)\n    x = []\n    top = []\n    bottom = []\n    for abin, bbin in zip(a.bins(overflow=False), b.bins(overflow=False)):\n        up = max(abin.value, bbin.value)\n        dn = min(abin.value, bbin.value)\n        x.extend([abin.x.low, abin.x.high])\n        top.extend([up, up])\n        bottom.extend([dn, dn])\n    x = np.array(x)\n    top = np.array(top)\n    bottom = np.array(bottom)\n    if logy:\n        np.clip(top, 1E-300, 1E300, out=top)\n        np.clip(bottom, 1E-300, 1E300, out=bottom)\n    return axes.fill_between(x, top, bottom, **kwargs)\n\n\ndef hist2d(h, axes=None, colorbar=False, **kwargs):\n    """"""\n    Draw a 2D matplotlib histogram plot from a 2D ROOT histogram.\n\n    Parameters\n    ----------\n\n    h : Hist2D\n        A rootpy Hist2D\n\n    axes : matplotlib Axes instance, optional (default=None)\n        The axes to plot on. If None then use the global current axes.\n\n    colorbar : Boolean, optional (default=False)\n        If True, include a colorbar in the produced plot\n\n    kwargs : additional keyword arguments, optional\n        Additional keyword arguments are passed directly to\n        matplotlib\'s hist2d function.\n\n    Returns\n    -------\n\n    Returns the value from matplotlib\'s hist2d function.\n\n    """"""\n    if axes is None:\n        axes = plt.gca()\n    X, Y = np.meshgrid(list(h.x()), list(h.y()))\n    x = X.ravel()\n    y = Y.ravel()\n    z = np.array(h.z()).T\n    # returns of hist2d: (counts, xedges, yedges, Image)\n    return_values = axes.hist2d(x, y, weights=z.ravel(),\n                                bins=(list(h.xedges()), list(h.yedges())),\n                                **kwargs)\n    if colorbar:\n        mappable = return_values[-1]\n        plt.colorbar(mappable, ax=axes)\n    return return_values\n\n\ndef imshow(h, axes=None, colorbar=False, **kwargs):\n    """"""\n    Draw a matplotlib imshow plot from a 2D ROOT histogram.\n\n    Parameters\n    ----------\n\n    h : Hist2D\n        A rootpy Hist2D\n\n    axes : matplotlib Axes instance, optional (default=None)\n        The axes to plot on. If None then use the global current axes.\n\n    colorbar : Boolean, optional (default=False)\n        If True, include a colorbar in the produced plot\n\n    kwargs : additional keyword arguments, optional\n        Additional keyword arguments are passed directly to\n        matplotlib\'s imshow function.\n\n    Returns\n    -------\n\n    Returns the value from matplotlib\'s imshow function.\n\n    """"""\n    kwargs.setdefault(\'aspect\', \'auto\')\n\n    if axes is None:\n        axes = plt.gca()\n    z = np.array(h.z()).T\n\n    axis_image= axes.imshow(\n        z,\n        extent=[\n            h.xedges(1), h.xedges(h.nbins(0) + 1),\n            h.yedges(1), h.yedges(h.nbins(1) + 1)],\n        interpolation=\'nearest\',\n        origin=\'lower\',\n        **kwargs)\n    if colorbar:\n        plt.colorbar(axis_image, ax=axes)\n    return axis_image\n\n\ndef contour(h, axes=None, zoom=None, label_contour=False, **kwargs):\n    """"""\n    Draw a matplotlib contour plot from a 2D ROOT histogram.\n\n    Parameters\n    ----------\n\n    h : Hist2D\n        A rootpy Hist2D\n\n    axes : matplotlib Axes instance, optional (default=None)\n        The axes to plot on. If None then use the global current axes.\n\n    zoom : float or sequence, optional (default=None)\n        The zoom factor along the axes. If a float, zoom is the same for each\n        axis. If a sequence, zoom should contain one value for each axis.\n        The histogram is zoomed using a cubic spline interpolation to create\n        smooth contours.\n\n    label_contour : Boolean, optional (default=False)\n        If True, labels are printed on the contour lines.\n\n    kwargs : additional keyword arguments, optional\n        Additional keyword arguments are passed directly to\n        matplotlib\'s contour function.\n\n    Returns\n    -------\n\n    Returns the value from matplotlib\'s contour function.\n\n    """"""\n    if axes is None:\n        axes = plt.gca()\n    x = np.array(list(h.x()))\n    y = np.array(list(h.y()))\n    z = np.array(h.z()).T\n    if zoom is not None:\n        from scipy import ndimage\n        if hasattr(zoom, \'__iter__\'):\n            zoom = list(zoom)\n            x = ndimage.zoom(x, zoom[0])\n            y = ndimage.zoom(y, zoom[1])\n        else:\n            x = ndimage.zoom(x, zoom)\n            y = ndimage.zoom(y, zoom)\n        z = ndimage.zoom(z, zoom)\n    return_values = axes.contour(x, y, z, **kwargs)\n    if label_contour:\n        plt.clabel(return_values)\n    return return_values\n'"
rootpy/plotting/shapes.py,0,"b""from __future__ import absolute_import\n\nfrom .. import QROOT\nfrom ..decorators import snake_case_methods\nfrom .base import Plottable\n\n__all__ = [\n    'Line',\n    'Ellipse',\n    'Arrow',\n]\n\n\n@snake_case_methods\nclass Line(Plottable, QROOT.TLine):\n    _ROOT = QROOT.TLine\n\n    def __init__(self, *args, **kwargs):\n        super(Line, self).__init__(*args)\n        self._post_init(**kwargs)\n\n\n@snake_case_methods\nclass Ellipse(Plottable, QROOT.TEllipse):\n    _ROOT = QROOT.TEllipse\n\n    def __init__(self, *args, **kwargs):\n        super(Ellipse, self).__init__(*args)\n        self._post_init(**kwargs)\n\n\n@snake_case_methods\nclass Arrow(QROOT.TArrow):\n    _ROOT = QROOT.TArrow\n"""
rootpy/plotting/text.py,0,"b'from __future__ import absolute_import\n\nfrom .base import _StyleContainer\nfrom ..extern.six import string_types\n\n__all__ = [\n    \'Font\',\n]\n\nfonts_root2text = {\n    1: \'times-medium-i-normal\',\n    2: \'times-bold-r-normal\',\n    3: \'times-bold-i-normal\',\n    4: \'helvetica-medium-r-normal\',\n    5: \'helvetica-medium-o-normal\',\n    6: \'helvetica-bold-r-normal\',\n    7: \'helvetica-bold-o-normal\',\n    8: \'courier-medium-r-normal\',\n    9: \'courier-medium-o-normal\',\n    10: \'courier-bold-r-normal\',\n    11: \'courier-bold-o-normal\',\n    12: \'symbol-medium-r-normal\',\n    13: \'times-medium-r-normal\',\n    14: \'wingdings\',\n    15: \'symbol-italic\',\n    }\n\nfonts_text2root = dict([\n    (value, key) for key, value in fonts_root2text.items()])\n\n\nclass Font(_StyleContainer):\n\n    def __init__(self, font, prec=3):\n        self._input = font\n        if isinstance(font, string_types):\n            if font not in fonts_text2root:\n                raise ValueError(""font \'{0}\' is not understood"".format(font))\n            self._root = fonts_text2root[font]\n        else:\n            if font not in fonts_root2text:\n                raise ValueError(""font \'{0}\' is not understood"".format(font))\n            self._root = font\n        self._root *= 10\n        self._root += prec\n        # conversion to mpl not implemented\n        self._mpl = None\n\n\nif __name__ == \'__main__\':\n    # Example from http://root.cern.ch/root/html/TAttText.html#T5\n    from rootpy.plotting import Canvas\n    from rootpy.interactive import wait\n    from ROOT import TLatex\n\n    c = Canvas(500, 700, name=""ROOT Fonts"", title=""ROOT Fonts"")\n    c.Range(0, 0, 1, 1)\n    c.SetBorderSize(2)\n    c.SetFrameFillColor(0)\n\n    def get_text(x, y, f, s):\n        t = TLatex(x, y, ""#font[41]{{0:d} :} {1}"".format(f(), s))\n        t.SetTextFont(f(\'root\'))\n        t.SetTextAlign(12)\n        t.SetTextSize(0.048)\n        return t\n\n    y = 0.95\n    prec = 2\n    for font in sorted(fonts_root2text.keys()):\n        f = Font(font, prec)\n        if font != 14:\n            t = get_text(0.02, y, f, ""ABCDEFGH abcdefgh 0123456789 @#$"")\n        else:\n            t = get_text(0.02, y, f, ""ABCD efgh 01234 @#$"")\n        t.Draw()\n        y -= 0.065\n    wait()\n'"
rootpy/plotting/utils.py,6,"b'from __future__ import absolute_import\n\nfrom math import log\nimport operator\n\nfrom .. import ROOT\nfrom .canvas import _PadBase\nfrom .hist import _Hist, Hist, HistStack\nfrom .graph import _Graph1DBase, Graph\nfrom ..context import preserve_current_canvas, do_nothing\nfrom ..extern.six.moves import range\n\n__all__ = [\n    \'draw\',\n    \'get_limits\',\n    \'get_band\',\n    \'canvases_with\',\n    \'find_all_primitives\',\n    \'tick_length_pixels\',\n]\n\n\ndef draw(plottables, pad=None, same=False,\n         xaxis=None, yaxis=None,\n         xtitle=None, ytitle=None,\n         xlimits=None, ylimits=None,\n         xdivisions=None, ydivisions=None,\n         logx=False, logy=False,\n         **kwargs):\n    """"""\n    Draw a list of histograms, stacks, and/or graphs.\n\n    Parameters\n    ----------\n    plottables : Hist, Graph, HistStack, or list of such objects\n        List of objects to draw.\n\n    pad : Pad or Canvas, optional (default=None)\n        The pad to draw onto. If None then use the current global pad.\n\n    same : bool, optional (default=False)\n        If True then use \'SAME\' draw option for all objects instead of\n        all but the first. Use this option if you are drawing onto a pad\n        that already holds drawn objects.\n\n    xaxis : TAxis, optional (default=None)\n        Use this x-axis or use the x-axis of the first plottable if None.\n\n    yaxis : TAxis, optional (default=None)\n        Use this y-axis or use the y-axis of the first plottable if None.\n\n    xtitle : str, optional (default=None)\n        Set the x-axis title.\n\n    ytitle : str, optional (default=None)\n        Set the y-axis title.\n\n    xlimits : tuple, optional (default=None)\n        Set the x-axis limits with a 2-tuple of (min, max)\n\n    ylimits : tuple, optional (default=None)\n        Set the y-axis limits with a 2-tuple of (min, max)\n\n    xdivisions : int, optional (default=None)\n        Set the number of divisions for the x-axis\n\n    ydivisions : int, optional (default=None)\n        Set the number of divisions for the y-axis\n\n    logx : bool, optional (default=False)\n        If True, then set the x-axis to log scale.\n\n    logy : bool, optional (default=False)\n        If True, then set the y-axis to log scale.\n\n    kwargs : dict\n        All extra arguments are passed to get_limits when determining the axis\n        limits.\n\n    Returns\n    -------\n    (xaxis, yaxis), (xmin, xmax, ymin, ymax) : tuple\n        The axes and axes bounds.\n\n    See Also\n    --------\n    get_limits\n\n    """"""\n    context = preserve_current_canvas if pad else do_nothing\n    if not isinstance(plottables, (tuple, list)):\n        plottables = [plottables]\n    elif not plottables:\n        raise ValueError(""plottables is empty"")\n    with context():\n        if pad is not None:\n            pad.cd()\n        # get the axes limits\n        xmin, xmax, ymin, ymax = get_limits(plottables,\n                                            logx=logx, logy=logy,\n                                            **kwargs)\n        if xlimits is not None:\n            xmin, xmax = xlimits\n        if ylimits is not None:\n            ymin, ymax = ylimits\n        if not same:\n            obj = plottables.pop(0)\n            if isinstance(obj, ROOT.THStack):\n                obj.SetMinimum(ymin)\n                obj.SetMaximum(ymax)\n            obj.Draw()\n            xaxis = obj.xaxis\n            yaxis = obj.yaxis\n        # draw the plottables\n        for i, obj in enumerate(plottables):\n            if i == 0 and isinstance(obj, ROOT.THStack):\n                # use SetMin/Max for y-axis\n                obj.SetMinimum(ymin)\n                obj.SetMaximum(ymax)\n                # ROOT: please fix this...\n            obj.Draw(\'SAME\')\n        # set the axes limits and titles\n        if xaxis is not None:\n            xaxis.SetLimits(xmin, xmax)\n            xaxis.SetRangeUser(xmin, xmax)\n            if xtitle is not None:\n                xaxis.SetTitle(xtitle)\n            if xdivisions is not None:\n                xaxis.SetNdivisions(xdivisions)\n        if yaxis is not None:\n            yaxis.SetLimits(ymin, ymax)\n            yaxis.SetRangeUser(ymin, ymax)\n            if ytitle is not None:\n                yaxis.SetTitle(ytitle)\n            if ydivisions is not None:\n                yaxis.SetNdivisions(ydivisions)\n        if pad is None:\n            pad = ROOT.gPad\n        pad.SetLogx(bool(logx))\n        pad.SetLogy(bool(logy))\n        # redraw axes on top\n        # axes ticks sometimes get hidden by filled histograms\n        pad.RedrawAxis()\n    return (xaxis, yaxis), (xmin, xmax, ymin, ymax)\n\n\nmultiadd = lambda a, b: map(operator.add, a, b)\nmultisub = lambda a, b: map(operator.sub, a, b)\n\n\ndef _limits_helper(x1, x2, a, b, snap=False):\n    """"""\n    Given x1, x2, a, b, where:\n\n        x1 - x0         x3 - x2\n    a = ------- ,   b = -------\n        x3 - x0         x3 - x0\n\n    determine the points x0 and x3:\n\n    x0         x1                x2       x3\n    |----------|-----------------|--------|\n\n    """"""\n    if x2 < x1:\n        raise ValueError(""x2 < x1"")\n    if a + b >= 1:\n        raise ValueError(""a + b >= 1"")\n    if a < 0:\n        raise ValueError(""a < 0"")\n    if b < 0:\n        raise ValueError(""b < 0"")\n    if snap:\n        if x1 >= 0:\n            x1 = 0\n            a = 0\n        elif x2 <= 0:\n            x2 = 0\n            b = 0\n        if x1 == x2 == 0:\n            # garbage in garbage out\n            return 0., 1.\n    elif x1 == x2:\n        # garbage in garbage out\n        return x1 - 1., x1 + 1.\n    if a == 0 and b == 0:\n        return x1, x2\n    elif a == 0:\n        return x1, (x2 - b * x1) / (1 - b)\n    elif b == 0:\n        return (x1 - a * x2) / (1 - a), x2\n    x0 = ((b / a) * x1 + x2 - (x2 - x1) / (1 - a - b)) / (1 + b / a)\n    x3 = (x2 - x1) / (1 - a - b) + x0\n    return x0, x3\n\n\ndef get_limits(plottables,\n               xpadding=0,\n               ypadding=0.1,\n               xerror_in_padding=True,\n               yerror_in_padding=True,\n               snap=True,\n               logx=False,\n               logy=False,\n               logx_crop_value=1E-5,\n               logy_crop_value=1E-5,\n               logx_base=10,\n               logy_base=10):\n    """"""\n    Get the axes limits that should be used for a 1D histogram, graph, or stack\n    of histograms.\n\n    Parameters\n    ----------\n\n    plottables : Hist, Graph, HistStack, or list of such objects\n        The object(s) for which visually pleasing plot boundaries are\n        requested.\n\n    xpadding : float or 2-tuple, optional (default=0)\n        The horizontal padding as a fraction of the final plot width.\n\n    ypadding : float or 2-tuple, optional (default=0.1)\n        The vertical padding as a fraction of the final plot height.\n\n    xerror_in_padding : bool, optional (default=True)\n        If False then exclude the x error bars from the calculation of the plot\n        width.\n\n    yerror_in_padding : bool, optional (default=True)\n        If False then exclude the y error bars from the calculation of the plot\n        height.\n\n    snap : bool, optional (default=True)\n        Make the minimum or maximum of the vertical range the x-axis depending\n        on if the plot maximum and minimum are above or below the x-axis. If\n        the plot maximum is above the x-axis while the minimum is below the\n        x-axis, then this option will have no effect.\n\n    logx : bool, optional (default=False)\n        If True, then the x-axis is log scale.\n\n    logy : bool, optional (default=False)\n        If True, then the y-axis is log scale.\n\n    logx_crop_value : float, optional (default=1E-5)\n        If an x-axis is using a logarithmic scale then crop all non-positive\n        values with this value.\n\n    logy_crop_value : float, optional (default=1E-5)\n        If the y-axis is using a logarithmic scale then crop all non-positive\n        values with this value.\n\n    logx_base : float, optional (default=10)\n        The base used for the logarithmic scale of the x-axis.\n\n    logy_base : float, optional (default=10)\n        The base used for the logarithmic scale of the y-axis.\n\n    Returns\n    -------\n\n    xmin, xmax, ymin, ymax : tuple of plot boundaries\n        The computed x and y-axis ranges.\n\n    """"""\n    try:\n        import numpy as np\n        use_numpy = True\n    except ImportError:\n        use_numpy = False\n\n    if not isinstance(plottables, (list, tuple)):\n        plottables = [plottables]\n\n    xmin = float(\'+inf\')\n    xmax = float(\'-inf\')\n    ymin = float(\'+inf\')\n    ymax = float(\'-inf\')\n\n    for h in plottables:\n\n        if isinstance(h, HistStack):\n            h = h.sum\n\n        if not isinstance(h, (_Hist, _Graph1DBase)):\n            raise TypeError(\n                ""unable to determine plot axes ranges ""\n                ""from object of type `{0}`"".format(\n                    type(h)))\n\n        if use_numpy:\n            y_array_min = y_array_max = np.array(list(h.y()))\n            if yerror_in_padding:\n                y_array_min = y_array_min - np.array(list(h.yerrl()))\n                y_array_max = y_array_max + np.array(list(h.yerrh()))\n            _ymin = y_array_min.min()\n            _ymax = y_array_max.max()\n        else:\n            y_array_min = y_array_max = list(h.y())\n            if yerror_in_padding:\n                y_array_min = multisub(y_array_min, list(h.yerrl()))\n                y_array_max = multiadd(y_array_max, list(h.yerrh()))\n            _ymin = min(y_array_min)\n            _ymax = max(y_array_max)\n\n        if isinstance(h, _Graph1DBase):\n            if use_numpy:\n                x_array_min = x_array_max = np.array(list(h.x()))\n                if xerror_in_padding:\n                    x_array_min = x_array_min - np.array(list(h.xerrl()))\n                    x_array_max = x_array_max + np.array(list(h.xerrh()))\n                _xmin = x_array_min.min()\n                _xmax = x_array_max.max()\n            else:\n                x_array_min = x_array_max = list(h.x())\n                if xerror_in_padding:\n                    x_array_min = multisub(x_array_min, list(h.xerrl()))\n                    x_array_max = multiadd(x_array_max, list(h.xerrh()))\n                _xmin = min(x_array_min)\n                _xmax = max(x_array_max)\n        else:\n            _xmin = h.xedgesl(1)\n            _xmax = h.xedgesh(h.nbins(0))\n\n        if logy:\n            _ymin = max(logy_crop_value, _ymin)\n            _ymax = max(logy_crop_value, _ymax)\n        if logx:\n            _xmin = max(logx_crop_value, _xmin)\n            _xmax = max(logx_crop_value, _xmax)\n\n        if _xmin < xmin:\n            xmin = _xmin\n        if _xmax > xmax:\n            xmax = _xmax\n        if _ymin < ymin:\n            ymin = _ymin\n        if _ymax > ymax:\n            ymax = _ymax\n\n    if isinstance(xpadding, (list, tuple)):\n        if len(xpadding) != 2:\n            raise ValueError(""xpadding must be of length 2"")\n        xpadding_left = xpadding[0]\n        xpadding_right = xpadding[1]\n    else:\n        xpadding_left = xpadding_right = xpadding\n\n    if isinstance(ypadding, (list, tuple)):\n        if len(ypadding) != 2:\n            raise ValueError(""ypadding must be of length 2"")\n        ypadding_top = ypadding[0]\n        ypadding_bottom = ypadding[1]\n    else:\n        ypadding_top = ypadding_bottom = ypadding\n\n    if logx:\n        x0, x3 = _limits_helper(\n            log(xmin, logx_base), log(xmax, logx_base),\n            xpadding_left, xpadding_right)\n        xmin = logx_base ** x0\n        xmax = logx_base ** x3\n    else:\n        xmin, xmax = _limits_helper(\n            xmin, xmax, xpadding_left, xpadding_right)\n\n    if logy:\n        y0, y3 = _limits_helper(\n            log(ymin, logy_base), log(ymax, logy_base),\n            ypadding_bottom, ypadding_top, snap=False)\n        ymin = logy_base ** y0\n        ymax = logy_base ** y3\n    else:\n        ymin, ymax = _limits_helper(\n            ymin, ymax, ypadding_bottom, ypadding_top, snap=snap)\n\n    return xmin, xmax, ymin, ymax\n\n\ndef get_band(low_hist, high_hist, middle_hist=None):\n    """"""\n    Convert the low and high histograms into a TGraphAsymmErrors centered at\n    the middle histogram if not None otherwise the middle between the low and\n    high points, to be used to draw a (possibly asymmetric) error band.\n    """"""\n    npoints = low_hist.nbins(0)\n    band = Graph(npoints)\n    for i in range(npoints):\n        center = low_hist.x(i + 1)\n        width = low_hist.xwidth(i + 1)\n        low, high = low_hist.y(i + 1), high_hist.y(i + 1)\n        if middle_hist is not None:\n            middle = middle_hist.y(i + 1)\n        else:\n            middle = (low + high) / 2.\n        yerrh = max(high - middle, low - middle, 0)\n        yerrl = abs(min(high - middle, low - middle, 0))\n        band.SetPoint(i, center, middle)\n        band.SetPointError(i, width / 2., width / 2.,\n                           yerrl, yerrh)\n    return band\n\n\ndef canvases_with(drawable):\n    """"""\n    Return a list of all canvases where `drawable` has been painted.\n\n    Note: This function is inefficient because it inspects all objects on all\n          canvases, recursively. Avoid calling it if you have a large number of\n          canvases and primitives.\n    """"""\n    return [c for c in ROOT.gROOT.GetListOfCanvases()\n            if drawable in find_all_primitives(c)]\n\n\ndef find_all_primitives(pad):\n    """"""\n    Recursively find all primities on a pad, even those hiding behind a\n    GetListOfFunctions() of a primitive\n    """"""\n    result = []\n    for primitive in pad.GetListOfPrimitives():\n        result.append(primitive)\n        if hasattr(primitive, ""GetListOfFunctions""):\n            result.extend(primitive.GetListOfFunctions())\n        if hasattr(primitive, ""GetHistogram""):\n            p = primitive.GetHistogram()\n            if p:\n                result.append(p)\n        if isinstance(primitive, ROOT.TPad):\n            result.extend(find_all_primitives(primitive))\n    return result\n\n\ndef tick_length_pixels(pad, xaxis, yaxis, xlength, ylength=None):\n    """"""\n    Set the axes tick lengths in pixels\n    """"""\n    if ylength is None:\n        ylength = xlength\n    xaxis.SetTickLength(xlength / float(pad.height_pixels))\n    yaxis.SetTickLength(ylength / float(pad.width_pixels))\n'"
rootpy/plotting/views.py,0,"b'\'\'\'\n\n=====================\nFolder ""View"" Classes\n=====================\n\nThese classes wrap Directories and perform automatic actions\nto Histograms retrieved from them.  The different views can be composited and\nlayered.\n\nSummary of views:\n\n- ScaleView: scale histogram normalization\n- NormalizeView: normalize histograms\n- SumView: sum histograms from different folders together\n- StyleView: apply a style to histograms\n- StackView: build THStacks using histograms from different folders\n- TitleView: change the title of histograms\n- FunctorView: apply a arbitrary transformation function to the histograms\n- MultiFunctorView: apply a arbitrary transformation function to a collection\n  of histograms\n- SubdirectoryView: A view of a subdirectory, which maintains the same view as\n  the base.\n\nExample use case\n================\n\nOne has a ROOT file with the following content::\n\n    zjets/mutau_mass\n    zz/mutau_mass\n    wz/mutau_mass\n    data_2010/mutau_mass\n    data_2011/mutau_mass\n\nand wants to do the following:\n\n1. Merge the two data taking periods together\n2. Scale the Z, WZ, and ZZ simulated results to the appropriate int. lumi.\n3. Combine WZ and ZZ into a single diboson sample\n4. Apply different colors to the MC samples\n5. Make a Stack of the expected yields from different simulated processes\n\nThis example can be tested by running::\n\n    python -m rootpy.plotting.views\n\n>>> # Mock up the example test case\n>>> import rootpy.io as io\n>>> # We have to keep these, to make sure PyROOT doesn\'t garbage collect them\n>>> keep = []\n>>> zjets_dir = io.Directory(\'zjets\', \'Zjets directory\')\n>>> zz_dir = io.Directory(\'zz\', \'ZZ directory\')\n>>> wz_dir = io.Directory(\'wz\', \'WZ directory\')\n>>> data2010_dir = io.Directory(\'data2010\', \'data2010 directory\')\n>>> data2011_dir = io.Directory(\'data2011\', \'data2011 directory\')\n>>> # Make the Zjets case\n>>> _ = zjets_dir.cd()\n>>> zjets_hist = ROOT.TH1F(""mutau_mass"", ""Mu-Tau mass"", 100, 0, 100)\n>>> zjets_hist.FillRandom(\'gaus\', 5000)\n>>> keep.append(zjets_hist)\n>>> # Make the ZZ case\n>>> _ = zz_dir.cd()\n>>> zz_hist = ROOT.TH1F(""mutau_mass"", ""Mu-Tau mass"", 100, 0, 100)\n>>> zz_hist.FillRandom(\'gaus\', 5000)\n>>> keep.append(zz_hist)\n>>> # Make the WZ case\n>>> _ = wz_dir.cd()\n>>> wz_hist = ROOT.TH1F(""mutau_mass"", ""Mu-Tau mass"", 100, 0, 100)\n>>> wz_hist.FillRandom(\'gaus\', 5000)\n>>> keep.append(wz_hist)\n>>> # Make the 2010 data case\n>>> _ = data2010_dir.cd()\n>>> data2010_hist = ROOT.TH1F(""mutau_mass"", ""Mu-Tau mass"", 100, 0, 100)\n>>> data2010_hist.FillRandom(\'gaus\', 30)\n>>> keep.append(data2010_hist)\n>>> # Make the 2011 data case\n>>> _ = data2011_dir.cd()\n>>> data2011_hist = ROOT.TH1F(""mutau_mass"", ""Mu-Tau mass"", 100, 0, 100)\n>>> data2011_hist.FillRandom(\'gaus\', 51)\n>>> keep.append(data2011_hist)\n\nSumView\n-------\n\nWe can merge the two data periods into a single case using a SumView.\n\n>>> data = SumView(data2010_dir, data2011_dir)\n>>> data_hist = data.Get(""mutau_mass"")\n>>> data_hist.Integral()\n81.0\n>>> data_hist.Integral() == data2010_hist.Integral() + data2011_hist.Integral()\nTrue\n\nScaleView\n---------\n\nThe simulated results (Z & diboson) can be scaled to the expected integrated\nluminosity using ScaleViews.\n\n>>> zjets = ScaleView(zjets_dir, 0.01)\n>>> zjets_hist = zjets.Get(""mutau_mass"")\n>>> abs(zjets_hist.Integral() - 50.0) < 1e-5\nTrue\n>>> # Scale the diboson contribution\n>>> zz = ScaleView(zz_dir, 0.001)\n>>> wz = ScaleView(wz_dir, 0.003)\n\nCombining views\n---------------\n\nThe dibosons individually are tiny, let\'s put them together using a SumView.\nNote that this operation nests two ScaleViews into a SumView.\n\n>>> dibosons = SumView(zz, wz)\n>>> # We expect 5000*0.001 + 5000*0.003 = 20 events\n>>> dibosons_hist = dibosons.Get(""mutau_mass"")\n>>> abs(dibosons_hist.Integral() - 20) < 1e-4\nTrue\n\nStyleView\n---------\n\nA style view automatically applies a style to retrieved Plottable objects.\nThe style is specified using the same arguments as the Plottable.decorate.\nLet\'s make the Z background red and the diboson background blue.\n\n>>> zjets = StyleView(zjets, fillcolor=ROOT.EColor.kRed)\n>>> dibosons = StyleView(dibosons, fillcolor=ROOT.EColor.kBlue)\n>>> zjets_hist = zjets.Get(""mutau_mass"")\n>>> zjets_hist.GetFillColor() == ROOT.EColor.kRed\nTrue\n>>> dibosons_hist = dibosons.Get(""mutau_mass"")\n>>> dibosons_hist.GetFillColor() == ROOT.EColor.kBlue\nTrue\n\nStackView\n---------\n\nThe StackView combines multiple items into a HistStack.  In our example\nwe stack the SM backgrounds to compare to the data.\n\n>>> sm_bkg = StackView(zjets, dibosons)\n>>> sm_bkg_stack = sm_bkg.Get(""mutau_mass"")\n>>> \'%0.0f\' % sm_bkg_stack.Integral()\n\'70\'\n\nLooks like we have an excess of 11 events - must be the Higgs.\n\n\nOther Examples\n==============\n\nNormalizeView\n-------------\n\nThe normalization view renormalizes histograms to a given value (default 1.0).\nHere is an example of using the NormalizeView to compare the Z and diboson\nshapes.\n\n>>> z_shape = NormalizeView(zjets)\n>>> z_shape_hist = z_shape.Get(""mutau_mass"")\n>>> abs(1 - z_shape_hist.Integral()) < 1e-5\nTrue\n>>> # Let\'s compare the shapes using a HistStack, using the ""nostack"" option.\n>>> diboson_shape = NormalizeView(dibosons)\n>>> shape_comparison = StackView(z_shape, diboson_shape)\n>>> # To draw the comparison:\n>>> # shape_comparison.Get(""mutau_mass"").Draw(\'nostack\')\n\nFunctorView\n-----------\n\nFunctorView allows you to apply an arbitrary transformation to the object.\nHere we show how you can change the axis range for all histograms in a\ndirectory.\n\n>>> rebin = lambda x: x.Rebin(2)\n>>> zjets_rebinned = FunctorView(zjets, rebin)\n>>> zjets.Get(""mutau_mass"").GetNbinsX()\n100\n>>> zjets_rebinned.Get(""mutau_mass"").GetNbinsX()\n50\n\nThe functor doesn\'t have to return a histogram.\n\n>>> mean_getter = lambda x: x.GetMean()\n>>> mean = zjets.Get(""mutau_mass"").GetMean()\n>>> zjets_mean = FunctorView(zjets, mean_getter)\n>>> zjets_mean.Get(""mutau_mass"") == mean\nTrue\n\n\nMultiFunctorView\n----------------\n\nMultiFunctorView is similar except that it operates on a group of histograms.\nThe functor should take one argument, a *generator* of the sub-objects.\n\nHere\'s an example to get the integral of the biggest histogram in a set:\n\n>>> biggest_histo = lambda objects: max(y.Integral() for y in objects)\n>>> biggest = MultiFunctorView(biggest_histo, zjets, dibosons)\n>>> biggest.Get(""mutau_mass"") == zjets.Get(""mutau_mass"").Integral()\nTrue\n\nSubdirectoryView\n----------------\n\nIf you\'d like to ""cd"" into a lower subdirectory, while still maintaining\nthe same view, use a SubdirectoryView.\n\n>>> basedir = io.Directory(\'base\', \'base directory\')\n>>> _ = basedir.cd()\n>>> subdir1 = io.Directory(\'subdir1\', \'subdir directory in 1\')\n>>> _ = subdir1.cd()\n>>> hist = ROOT.TH1F(""mutau_mass"", ""Mu-Tau mass"", 100, 0, 100)\n>>> hist.FillRandom(\'gaus\', 2000)\n>>> keep.append(hist)\n>>> _ = basedir.cd()\n>>> subdir2 = io.Directory(\'subdir2\', \'subdir directory 2\')\n>>> _ = subdir2.cd()\n>>> hist = ROOT.TH1F(""mutau_mass"", ""Mu-Tau mass"", 100, 0, 100)\n>>> hist.FillRandom(\'gaus\', 5000)\n>>> keep.append(hist)\n\nThe directory structure is now::\n    base/subdir1/hist\n    base/subdir2/hist\n\nSubdirectory views work on top of other views.\n\n>>> baseview = ScaleView(basedir, 0.1)\n>>> subdir1view = SubdirectoryView(baseview, \'subdir1\')\n>>> subdir2view = SubdirectoryView(baseview, \'subdir2\')\n>>> histo1 = subdir1view.Get(\'mutau_mass\')\n>>> histo2 = subdir2view.Get(\'mutau_mass\')\n>>> exp_histo1 = baseview.Get(""subdir1/mutau_mass"")\n>>> exp_histo2 = baseview.Get(""subdir2/mutau_mass"")\n>>> def equivalent(h1, h2):\n...     return (abs(h1.GetMean() - h2.GetMean()) < 1e-4 and\n...             abs(h1.GetRMS() - h2.GetRMS()) < 1e-4 and\n...             abs(h1.Integral() - h2.Integral()) < 1e-4)\n>>> equivalent(exp_histo1, histo1)\nTrue\n>>> equivalent(exp_histo2, histo2)\nTrue\n>>> equivalent(histo1, histo2)\nFalse\n\n\'\'\'\nfrom __future__ import absolute_import\n\nimport os\nimport ROOT\n\nfrom .base import Plottable\nfrom .hist import HistStack\nfrom ..io import Directory, DoesNotExist\n\n__all__ = [\n    \'ScaleView\',\n    \'NormalizeView\',\n    \'StyleView\',\n    \'TitleView\',\n    \'SumView\',\n    \'StackView\',\n    \'FunctorView\',\n    \'MultiFunctorView\',\n    \'PathModifierView\',\n    \'SubdirectoryView\',\n]\n\n\nclass _FolderView(object):\n    \'\'\'\n    Abstract view of an individual folder\n\n    Provides one interface: Get(path) which returns a modified version\n    of whatever exists at path.  Subclasses should define::\n\n        apply_view(self, obj)\n\n    which should return the modified [object] as necessary.\n\n    The subclass can get access to the queried path via the self.getting\n    variable.\n    \'\'\'\n    def __init__(self, directory):\n        \'\'\' Initialize with the directory to be wrapped \'\'\'\n        self.dir = directory\n\n    def path(self):\n        \'\'\' Get the path of the wrapped folder \'\'\'\n        if isinstance(self.dir, Directory):\n            return self.dir._path\n        elif isinstance(self.dir, ROOT.TDirectory):\n            return self.dir.GetPath()\n        elif isinstance(self.dir, _FolderView):\n            return self.dir.path()\n        else:\n            return str(self.dir)\n\n    def __str__(self):\n        return ""{0}(\'{1}\')"".format(self.__class__.__name__, self.path())\n\n    def Get(self, path):\n        \'\'\' Get the (modified) object from path \'\'\'\n        self.getting = path\n        try:\n            obj = self.dir.Get(path)\n            return self.apply_view(obj)\n        except DoesNotExist as dne:\n            #print dir(dne)\n            raise DoesNotExist(\n                str(dne) + ""[{0}]"".format(self.__class__.__name__))\n\n\nclass _MultiFolderView(object):\n    \'\'\'\n    Abstract view of a collection of folders\n\n    Applies some type of ""merge"" operation to the result of the get from each\n    folder.  Subclasses should define::\n\n        merge_views(self, objects)\n\n    which takes a *generator* of objects returns a merged object.\n\n    The subclass can get access to the queried path via the self.getting\n    variable.\n    \'\'\'\n    def __init__(self, *directories):\n        self.dirs = directories\n\n    def __str__(self):\n        return ""{0}({1})"".format(\n            self.__class__.__name__,\n            \',\'.join(str(x) for x in self.dirs))\n\n    def Get(self, path):\n        \'\'\' Merge the objects at path in all subdirectories \'\'\'\n        return self.merge_views(x.Get(path) for x in self.dirs)\n\n\nclass ScaleView(_FolderView):\n    \'\'\' View of a folder which applies a scaling factor to histograms. \'\'\'\n    def __init__(self, directory, scale_factor):\n        super(ScaleView, self).__init__(directory)\n        self.factor = scale_factor\n\n    def apply_view(self, obj):\n        if not hasattr(obj, \'Scale\'):\n            raise ValueError(\n                ""`ScaleView` can\'t determine how to handle""\n                ""an object of type `{0}`; ""\n                ""it has no `Scale` method"".format(type(obj)))\n        clone = obj.Clone()\n        clone.Scale(self.factor)\n        return clone\n\n\nclass NormalizeView(ScaleView):\n    \'\'\' Normalize histograms to a constant value \'\'\'\n    def __init__(self, directory, normalization=1.0):\n        # Initialize the scale view with a dummy scale factor.\n        # The scale factor is changed dynamically for each histogram.\n        super(NormalizeView, self).__init__(directory, None)\n        self.norm = normalization\n\n    def apply_view(self, obj):\n        current_norm = obj.Integral()\n        # Update the scale factor (in the base)\n        if current_norm > 0:\n            self.factor = self.norm / current_norm\n        else:\n            self.factor = 0\n        return super(NormalizeView, self).apply_view(obj)\n\n\nclass StyleView(_FolderView):\n    \'\'\'\n    View of a folder which applies a style to Plottable objects.\n\n    The kwargs are passed to Plottable.decorate\n    \'\'\'\n    def __init__(self, directory, **kwargs):\n        super(StyleView, self).__init__(directory)\n        self.kwargs = kwargs\n\n    def apply_view(self, obj):\n        if not isinstance(obj, Plottable):\n            raise TypeError(\n                ""`ScaleView` can\'t determine how to handle ""\n                ""an object of type `{0}`; it is not a subclass of ""\n                ""`Plottable`"".format(type(obj)))\n        clone = obj.Clone()\n        clone.decorate(**self.kwargs)\n        return clone\n\n\nclass TitleView(_FolderView):\n    \'\'\' Override the title of gotten histograms \'\'\'\n    def __init__(self, directory, title):\n        self.title = title\n        super(TitleView, self).__init__(directory)\n\n    def apply_view(self, obj):\n        clone = obj.Clone()\n        clone.SetTitle(self.title)\n        return clone\n\n\nclass SumView(_MultiFolderView):\n    \'\'\' Add a collection of histograms together \'\'\'\n    def __init__(self, *directories):\n        super(SumView, self).__init__(*directories)\n\n    def merge_views(self, objects):\n        output = None\n        for obj in objects:\n            if output is None:\n                output = obj.Clone()\n            else:\n                output += obj\n        return output\n\n\nclass StackView(_MultiFolderView):\n    \'\'\'\n    Build a HistStack from the input histograms\n\n    The default draw option that histograms will use is ""hist"".\n\n    One can override this for all histograms by passing a string.\n    Individual behavior can be controlled by passing a list of draw options,\n    corresponding to the input directories. In this case the option for\n    all histograms must be specified.\n\n    The name and title of the HistStack is taken from the first histogram in\n    the list.\n\n    Normally the histograms will be added to the stack in the order\n    of the constructor.  Optionally, one can add them in order of ascending\n    integral by passing the kwarg sorted=True.\n    \'\'\'\n    def __init__(self, *directories, **kwargs):\n        super(StackView, self).__init__(*directories)\n        self.sort = kwargs.get(sorted, False)\n\n    def merge_views(self, objects):\n        output = None\n        if self.sort:\n            objects = sorted(objects, key=lambda x: x.Integral())\n        for obj in objects:\n            if output is None:\n                output = HistStack(name=obj.GetName(),\n                                   title=obj.GetTitle())\n            output.Add(obj)\n        return output\n\n\nclass FunctorView(_FolderView):\n    \'\'\'\n    Apply an arbitrary function to the output histogram.\n\n    The histogram is always cloned before it is passed to the function.\n    \'\'\'\n    def __init__(self, directory, function):\n        self.f = function\n        super(FunctorView, self).__init__(directory)\n\n    def apply_view(self, obj):\n        clone = obj.Clone()\n        return self.f(clone)\n\n\nclass MultiFunctorView(_MultiFolderView):\n    \'\'\'\n    Apply an arbitrary function to the output histograms.\n\n    The function must take one argument, a generator of objects.\n    \'\'\'\n    def __init__(self, f, *directories):\n        self.f = f\n        super(MultiFunctorView, self).__init__(*directories)\n\n    def merge_views(self, objects):\n        return self.f(objects)\n\n\nclass PathModifierView(_FolderView):\n    \'\'\'\n    Does some magic to the path\n\n    User should supply a functor which transforms the path argument\n    passed to Get(...)\n    \'\'\'\n    def __init__(self, dir, path_modifier):\n        self.path_modifier = path_modifier\n        super(PathModifierView, self).__init__(dir)\n\n    def Get(self, path):\n        newpath = self.path_modifier(path)\n        return super(PathModifierView, self).Get(newpath)\n\n    def apply_view(self, obj):\n        \'\'\' Do nothing \'\'\'\n        return obj\n\n\nclass SubdirectoryView(PathModifierView):\n    \'\'\'\n    Add some base directories to the path of Get()\n\n    <subdir> is the directory you want to \'cd\' too.\n    \'\'\'\n    def __init__(self, dir, subdirpath):\n        functor = lambda path: os.path.join(subdirpath, path)\n        super(SubdirectoryView, self).__init__(dir, functor)\n\n\nif __name__ == ""__main__"":\n    import doctest\n    doctest.testmod()\n'"
rootpy/stats/__init__.py,0,"b'from __future__ import absolute_import\n\nfrom .. import log; log = log[__name__]\nfrom .. import QROOT, IN_NOSETESTS, ROOTError\nfrom ..context import do_nothing\nfrom ..utils.silence import silence_sout\n\ntry:\n    context = silence_sout if IN_NOSETESTS else do_nothing\n    with context():\n        QROOT.RooFit\n        QROOT.RooMsgService\n\nexcept (AttributeError, ROOTError):\n    import warnings\n    warnings.warn(\n        ""rootpy.stats requires libRooFit and libRooStats. ""\n        ""Please recompile ROOT with roofit enabled"")\n    __all__ = []\n\nelse:\n    import os\n    from .. import stl\n\n    # generate dictionaries\n    stl.stack(\'RooAbsArg*,deque<RooAbsArg*>\',\n              headers=\'<stack>;<deque>;RooRealVar.h\')\n\n    from .workspace import Workspace\n    from .modelconfig import ModelConfig\n    from .collection import ArgSet, ArgList\n    from .value import RealVar\n    from .pdf import Simultaneous, AddPdf, ProdPdf\n\n    __all__ = [\n        \'mute_roostats\',\n        \'Workspace\',\n        \'ModelConfig\',\n        \'ArgSet\',\n        \'ArgList\',\n        \'RealVar\',\n        \'Simultaneous\',\n        \'AddPdf\',\n        \'ProdPdf\',\n    ]\n\n\n    def mute_roostats():\n        """"""\n        suppress RooStats\' rather verbose INFO messages unless DEBUG is set\n        """"""\n        if not os.environ.get(\'DEBUG\', False):\n            log.debug(""suppressing RooStats messages below the WARNING level"")\n            QROOT.RooMsgService.instance().setGlobalKillBelow(\n                QROOT.RooFit.WARNING)\n'"
rootpy/stats/category.py,0,"b""from __future__ import absolute_import\n\nimport ROOT\n\nfrom . import log; log = log[__name__]\nfrom .. import QROOT, asrootpy\nfrom ..base import NamedObject\nfrom .value import AbsArg\n\n__all__ = [\n    'CatType',\n    'Category',\n]\n\n\nclass CatType(NamedObject, QROOT.RooCatType):\n    _ROOT = QROOT.RooCatType\n\n    @property\n    def value(self):\n        return self.getVal()\n\n    @value.setter\n    def value(self, val):\n        self.setVal(val)\n\n\nclass Category(NamedObject, AbsArg, QROOT.RooCategory):\n    _ROOT = QROOT.RooCategory\n\n    @property\n    def index(self):\n        return self.getIndex()\n\n    @index.setter\n    def index(self, value):\n        return self.setIndex(value)\n\n    @property\n    def label(self):\n        return self.getLabel()\n\n    @index.setter\n    def label(self, value):\n        return self.setLabel(value)\n"""
rootpy/stats/collection.py,0,"b'from __future__ import absolute_import\n\nimport ROOT\n\nfrom . import log; log = log[__name__]\nfrom ..extern.six.moves import range\nfrom ..extern.six import string_types\nfrom ..base import Object\nfrom .. import QROOT, asrootpy\n\n__all__ = [\n    \'ArgSet\',\n    \'ArgList\',\n]\n\n\nclass _CollectionBase(object):\n\n    def __getitem__(self, name):\n        thing = self.find(name)\n        if thing == None:\n            raise ValueError(\n                ""argument \'{0}\' is not contained ""\n                ""in the RooArgSet \'{1}\'"".format(name, self.GetName()))\n        return asrootpy(thing, warn=False)\n\n    def __contains__(self, value):\n        if isinstance(value, string_types):\n            try:\n                thing = self[value]\n            except ValueError:\n                return False\n            return True\n        # RooAbsArg\n        return self.contains(value)\n\n    def __iter__(self):\n        start = self.fwdIterator()\n        for i in range(len(self)):\n            yield asrootpy(start.next(), warn=False)\n\n    def __len__(self):\n        return self.getSize()\n\n    def __eq__(self, other):\n        return self.equals(other)\n\n    def find(self, name):\n        thing = super(_CollectionBase, self).find(name)\n        if thing == None:\n            return None\n        return asrootpy(thing, warn=False)\n\n    def first(self):\n        thing = super(_CollectionBase, self).first()\n        if thing == None:\n            return None\n        return asrootpy(thing, warn=False)\n\n    def __repr__(self):\n        return ""{0}(name=\'{1}\', {2})"".format(\n            self.__class__.__name__,\n            self.GetName(),\n            repr(list(self)))\n\n    @property\n    def name(self):\n        return self.GetName()\n\n    @name.setter\n    def name(self, value):\n        # ROOT, why is your API so inconsistent?\n        # We have GetName() and setName() here...\n        self.setName(value)\n\n\nclass ArgSet(_CollectionBase, Object, QROOT.RooArgSet):\n    _ROOT = QROOT.RooArgSet\n\n\nclass ArgList(_CollectionBase, Object, QROOT.RooArgList):\n    _ROOT = QROOT.RooArgList\n'"
rootpy/stats/correlated_values.py,0,"b'from __future__ import absolute_import\n\nimport uncertainties as U\n\nfrom .. import asrootpy\n\n__all__ = [\n    \'as_ufloat\',\n    \'correlated_values\',\n]\n\n\ndef as_ufloat(roorealvar):\n    """"""\n    Cast a `RooRealVar` to an `uncertainties.ufloat`\n    """"""\n    if isinstance(roorealvar, (U.AffineScalarFunc, U.Variable)):\n        return roorealvar\n    return U.ufloat((roorealvar.getVal(), roorealvar.getError()))\n\n\ndef correlated_values(param_names, roofitresult):\n    """"""\n    Return symbolic values from a `RooFitResult` taking into account covariance\n\n    This is useful for numerically computing the uncertainties for expressions\n    using correlated values arising from a fit.\n\n    Parameters\n    ----------\n\n    param_names: list of strings\n        A list of parameters to extract from the result. The order of the names\n        is the order of the return value.\n\n    roofitresult : RooFitResult\n        A RooFitResult from a fit.\n\n    Returns\n    -------\n\n    list of correlated values from the uncertainties package.\n\n    Examples\n    --------\n\n    .. sourcecode:: python\n\n        # Fit a pdf to a histogram\n        pdf = some_roofit_pdf_with_variables(""f(x, a, b, c)"")\n        fitresult = pdf.fitTo(histogram, ROOT.RooFit.Save())\n        a, b, c = correlated_values([""a"", ""b"", ""c""], fitresult)\n        # Arbitrary math expression according to what the `uncertainties`\n        # package supports, automatically computes correct error propagation\n        sum_value = a + b + c\n        value, error = sum_value.nominal_value, sum_value.std_dev()\n\n    """"""\n    pars = roofitresult.floatParsFinal()\n    #pars.Print()\n    pars = [pars[i] for i in range(pars.getSize())]\n    parnames = [p.GetName() for p in pars]\n\n    values = [(p.getVal(), p.getError()) for p in pars]\n    #values = [as_ufloat(p) for p in pars]\n    matrix = asrootpy(roofitresult.correlationMatrix()).to_numpy()\n\n    uvalues = U.correlated_values_norm(values, matrix.tolist())\n    uvalues = dict((n, v) for n, v in zip(parnames, uvalues))\n\n    assert all(n in uvalues for n in parnames), (\n        ""name {0} isn\'t in parameter list {1}"".format(n, parnames))\n\n    # Return a tuple in the order it was asked for\n    return tuple(uvalues[n] for n in param_names)\n'"
rootpy/stats/dataset.py,0,"b""from __future__ import absolute_import\n\nimport ROOT\n\nfrom . import log; log = log[__name__]\nfrom .. import QROOT, asrootpy\nfrom ..base import NamedObject\nfrom ..extern.six import string_types\n\n__all__ = [\n    'DataSet',\n]\n\nclass DataSet(NamedObject, QROOT.RooDataSet):\n    _ROOT = QROOT.RooDataSet\n    class Entry(object):\n        def __init__(self, idx, dataset):\n            self.idx_ = idx\n            self.dataset_ = dataset\n            \n        @property\n        def fields(self):\n            return asrootpy(self.dataset_.get(self.idx_))\n        \n        @property\n        def weight(self):\n            self.dataset_.get(self.idx_) #set current event\n            return self.dataset_.weight()\n\n    def __len__(self):\n        return self.numEntries()\n\n    def __getitem__(self, idx):\n        return DataSet.Entry(idx, self)\n\n    def __iter__(self):\n        for idx in range(len(self)):\n            yield DataSet.Entry(idx, self)\n\n    def createHistogram(self, *args, **kwargs):\n        if args and isinstance(args[0], string_types):\n            return ROOT.RooAbsData.createHistogram(self, *args, **kwargs)\n        return super(DataSet, self).createHistogram(*args, **kwargs)\n\n    def reduce(self, *args, **kwargs):\n        return asrootpy(super(DataSet, self).reduce(*args, **kwargs))\n"""
rootpy/stats/fit.py,0,"b'from __future__ import absolute_import\n\nimport ROOT\n\nfrom . import log; log = log[__name__]\nfrom .. import QROOT, asrootpy\n\n__all__ = [\n    \'minimize\',\n    \'Minimizer\',\n    \'FitResult\',\n]\n\n\ndef minimize(func,\n             minimizer_type=None,\n             minimizer_algo=None,\n             strategy=None,\n             retry=0,\n             scan=False,\n             print_level=None):\n    """"""\n    Minimize a RooAbsReal function\n\n    Parameters\n    ----------\n\n    func : RooAbsReal\n        The function to minimize\n\n    minimizer_type : string, optional (default=None)\n        The minimizer type: ""Minuit"" or ""Minuit2"".\n        If None (the default) then use the current global default value.\n\n    minimizer_algo : string, optional (default=None)\n        The minimizer algorithm: ""Migrad"", etc.\n        If None (the default) then use the current global default value.\n\n    strategy : int, optional (default=None)\n        Set the MINUIT strategy. Accepted values\n        are 0, 1, and 2 and represent MINUIT strategies for dealing\n        most efficiently with fast FCNs (0), expensive FCNs (2)\n        and \'intermediate\' FCNs (1). If None (the default) then use\n        the current global default value.\n\n    retry : int, optional (default=0)\n        Number of times to retry failed minimizations. The strategy is\n        incremented to a maximum of 2 from its initial value and remains at 2\n        for additional retries.\n\n    scan : bool, optional (default=False)\n        If True then run Minuit2\'s scan algorithm before running the main\n        ``minimizer_algo`` (""Migrad"").\n\n    print_level : int, optional (default=None)\n        The verbosity level for the minimizer algorithm.\n        If None (the default) then use the global default print level.\n        If negative then all non-fatal messages will be suppressed.\n\n    Returns\n    -------\n\n    minimizer : RooMinimizer\n        The minimizer. Get the RooFitResult with ``minimizer.save()``.\n\n    """"""\n    llog = log[\'minimize\']\n\n    min_opts = ROOT.Math.MinimizerOptions\n    if minimizer_type is None:\n        minimizer_type = min_opts.DefaultMinimizerType()\n    if minimizer_algo is None:\n        minimizer_algo = min_opts.DefaultMinimizerAlgo()\n    if strategy is None:\n        strategy = min_opts.DefaultStrategy()\n    if print_level is None:\n        print_level = min_opts.DefaultPrintLevel()\n\n    if print_level < 0:\n        msg_service = ROOT.RooMsgService.instance()\n        msg_level = msg_service.globalKillBelow()\n        msg_service.setGlobalKillBelow(ROOT.RooFit.FATAL)\n\n    minim = Minimizer(func)\n    minim.setPrintLevel(print_level)\n    minim.setStrategy(strategy)\n\n    if scan:\n        llog.info(""running scan algorithm ..."")\n        minim.minimize(\'Minuit2\', \'Scan\')\n\n    llog.info(""minimizing with {0} {1} using strategy {2}"".format(\n        minimizer_type, minimizer_algo, strategy))\n    status = minim.minimize(minimizer_type, minimizer_algo)\n\n    iretry = 0\n    while iretry < retry and status not in (0, 1):\n        if strategy < 2:\n            strategy += 1\n            minim.setStrategy(strategy)\n        llog.warning(""minimization failed with status {0:d}"".format(status))\n        llog.info(""retrying minimization with strategy {0:d}"".format(strategy))\n        status = minim.minimize(minimizer_type, minimizer_algo)\n\n    if status in (0, 1):\n        llog.info(""found minimum"")\n    else:\n        llog.warning(""minimization failed with status {0:d}"".format(status))\n\n    if print_level < 0:\n        msg_service.setGlobalKillBelow(msg_level)\n\n    return minim\n\n\nclass Minimizer(QROOT.RooMinimizer):\n    _ROOT = QROOT.RooMinimizer\n\n    def save(self, *args, **kwargs):\n        return asrootpy(super(Minimizer, self).save(*args, **kwargs))\n\n\nclass FitResult(QROOT.RooFitResult):\n    _ROOT = QROOT.RooFitResult\n\n    @property\n    def constant_params(self):\n        return asrootpy(super(FitResult, self).constPars())\n\n    @property\n    def final_params(self):\n        return asrootpy(super(FitResult, self).floatParsFinal())\n\n    @property\n    def initial_params(self):\n        return asrootpy(super(FitResult, self).floatParsInit())\n\n    @property\n    def covariance_matrix(self):\n        return asrootpy(super(FitResult, self).covarianceMatrix())\n\n    @property\n    def correlation_matrix(self):\n        return asrootpy(super(FitResult, self).correlationMatrix())\n\n    def reduced_covariance_matrix(self, params):\n        return asrootpy(\n            super(FitResult, self).reducedCovarianceMatrix(params))\n\n    def conditional_covariance_matrix(self, params):\n        return asrootpy(\n            super(FitResult, self).conditionalCovarianceMatrix(params))\n'"
rootpy/stats/modelconfig.py,0,"b""from __future__ import absolute_import\n\nimport ROOT\n\nfrom . import log; log = log[__name__]\nfrom .. import QROOT, asrootpy\nfrom ..base import NamedObject\n\n__all__ = [\n    'ModelConfig',\n]\n\n\nclass ModelConfig(NamedObject, QROOT.RooStats.ModelConfig):\n    _ROOT = QROOT.RooStats.ModelConfig\n\n    def GetPdf(self):\n        return asrootpy(super(ModelConfig, self).GetPdf())\n\n    @property\n    def workspace(self):\n        return asrootpy(self.GetWorkspace())\n\n    @workspace.setter\n    def workspace(self, value):\n        self.SetWorkspace(value)\n\n    @property\n    def pdf(self):\n        return self.GetPdf()\n\n    @pdf.setter\n    def pdf(self, value):\n        self.SetPdf(value)\n\n    @property\n    def prior_pdf(self):\n        return self.GetPriorPdf()\n\n    @prior_pdf.setter\n    def prior_pdf(self, value):\n        self.SetPriorPdf(value)\n\n    @property\n    def proto_data(self):\n        return self.GetProtoData()\n\n    @proto_data.setter\n    def proto_data(self, value):\n        self.SetProtoData(value)\n\n    @property\n    def snapshot(self):\n        return self.GetSnapshot()\n\n    @snapshot.setter\n    def snapshot(self, value):\n        self.SetSnapshot(value)\n\n    @property\n    def conditional_observables(self):\n        return asrootpy(self.GetConditionalObservables())\n\n    @conditional_observables.setter\n    def conditional_observables(self, value):\n        self.SetConditionalObservables(value)\n\n    @property\n    def constraint_parameters(self):\n        return asrootpy(self.GetConstraintParameters())\n\n    @constraint_parameters.setter\n    def constraint_parameters(self, value):\n        self.SetConstraintParameters(value)\n\n    @property\n    def global_observables(self):\n        return asrootpy(self.GetGlobalObservables())\n\n    @global_observables.setter\n    def global_observables(self, value):\n        self.SetGlobalObservables(value)\n\n    @property\n    def nuisance_parameters(self):\n        return asrootpy(self.GetNuisanceParameters())\n\n    @nuisance_parameters.setter\n    def nuisance_parameters(self, value):\n        self.SetNuisanceParameters(value)\n\n    @property\n    def observables(self):\n        return asrootpy(self.GetObservables())\n\n    @observables.setter\n    def observables(self, value):\n        self.SetObservables(value)\n\n    @property\n    def poi(self):\n        return asrootpy(self.GetParametersOfInterest())\n\n    @poi.setter\n    def poi(self, value):\n        self.SetParametersOfInterest(value)\n"""
rootpy/stats/pdf.py,0,"b""from __future__ import absolute_import\n\nimport ROOT\n\nfrom . import log; log = log[__name__]\nfrom .. import QROOT, asrootpy\nfrom ..base import NamedObject\n\nfrom .value import AbsArg\n\n__all__ = [\n    'Simultaneous',\n    'AddPdf',\n    'ProdPdf',\n]\n\n\nclass Simultaneous(NamedObject, AbsArg, QROOT.RooSimultaneous):\n    _ROOT = QROOT.RooSimultaneous\n\n    def __iter__(self):\n        iterator = self.indexCat().typeIterator()\n        category = iterator.Next()\n        while category:\n            yield asrootpy(category)\n            category = iterator.Next()\n\n    def getPdf(self, category):\n        if isinstance(category, ROOT.RooCatType):\n            category = category.GetName()\n        return asrootpy(super(Simultaneous, self).getPdf(category))\n\n    def pdf(self, category):\n        return self.getPdf(category)\n\n    def indexCat(self):\n        return asrootpy(super(Simultaneous, self).indexCat())\n\n    @property\n    def index_category(self):\n        return self.indexCat()\n\n\nclass AddPdf(NamedObject, AbsArg, QROOT.RooAddPdf):\n    _ROOT = QROOT.RooAddPdf\n\n\nclass ProdPdf(NamedObject, AbsArg, QROOT.RooProdPdf):\n    _ROOT = QROOT.RooProdPdf\n"""
rootpy/stats/plottable.py,0,"b""from __future__ import absolute_import\n\nimport ROOT\n\nfrom . import log; log = log[__name__]\nfrom .. import QROOT, asrootpy\nfrom ..base import NamedObject\nfrom ..plotting import Graph\nfrom ..extern.six.moves import range\n\n__all__ = [\n    'Plot',\n    'Curve',\n    'DataHist',\n]\n\n\nclass Plot(NamedObject, QROOT.RooPlot):\n    _ROOT = QROOT.RooPlot\n\n    @property\n    def objects(self):\n        for i in range(int(self.numItems())):\n            yield asrootpy(self.getObject(i))\n\n    @property\n    def curves(self):\n        for obj in self.objects:\n            if isinstance(obj, Curve):\n                yield obj\n\n    @property\n    def data_hists(self):\n        for obj in self.objects:\n            if isinstance(obj, DataHist):\n                yield obj\n\n    @property\n    def plotvar(self):\n        return asrootpy(self.getPlotVar())\n\n\nclass Curve(NamedObject, Graph, QROOT.RooCurve):\n    _ROOT = QROOT.RooCurve\n\n\nclass DataHist(NamedObject, Graph, QROOT.RooHist):\n    _ROOT = QROOT.RooHist\n"""
rootpy/stats/value.py,0,"b'from __future__ import absolute_import\n\nimport ROOT\n\nfrom . import log; log = log[__name__]\nfrom ..base import NamedObject\nfrom .. import QROOT, asrootpy\n\n__all__ = [\n    \'RealVar\',\n]\n\n\nclass AbsArg(object):\n    """"""\n    Use with classes inheriting from RooAbsArg\n    """"""\n    def getComponents(self):\n        return asrootpy(super(AbsArg, self).getComponents())\n\n    def components(self):\n        return self.getComponents()\n\n    def getDependents(self, *args, **kwargs):\n        return asrootpy(super(AbsArg, self).getDependents(*args, **kwargs))\n\n    def dependents(self, *args, **kwargs):\n        return self.getDependents(*args, **kwargs)\n\n    def getObservables(self, *args, **kwargs):\n        return asrootpy(super(AbsArg, self).getObservables(*args, **kwargs))\n\n    def observables(self, *args, **kwargs):\n        return self.getObservables(*args, **kwargs)\n\n    def getParameters(self, *args, **kwargs):\n        return asrootpy(super(AbsArg, self).getParameters(*args, **kwargs))\n\n    def parameters(self, *args, **kwargs):\n        return self.getParameters(*args, **kwargs)\n\n\nclass _ValueBase(object):\n\n    @property\n    def value(self):\n        return self.getVal()\n\n    @value.setter\n    def value(self, newvalue):\n        self.setVal(newvalue)\n\n    @property\n    def error(self):\n        if self.hasAsymError():\n            return self.getErrorHi(), self.getErrorLo()\n        return self.getError()\n\n    @error.setter\n    def error(self, value):\n        if self.hasAsymError():\n            # high, low -> low, high\n            self.setAsymError(value[1], value[0])\n        else:\n            self.setError(value)\n\n    @property\n    def max(self):\n        return self.getMax()\n\n    @max.setter\n    def max(self, value):\n        self.setMax(value)\n\n    @property\n    def min(self):\n        return self.getMin()\n\n    @min.setter\n    def min(self, value):\n        self.setMin(value)\n\n    @property\n    def constant(self):\n        return self.getAttribute(\'Constant\')\n\n    @constant.setter\n    def constant(self, value):\n        self.setConstant(value)\n\n\nclass RealVar(_ValueBase, NamedObject, QROOT.RooRealVar):\n    _ROOT = QROOT.RooRealVar\n'"
rootpy/stats/workspace.py,0,"b'from __future__ import absolute_import\n\nimport multiprocessing\n\nimport ROOT\n\nfrom . import log; log = log[__name__]\nfrom .. import QROOT, asrootpy\nfrom ..extern.six import string_types\nfrom ..base import NamedObject\nfrom .fit import minimize\n\n__all__ = [\n    \'Workspace\',\n]\n\nNCPU = multiprocessing.cpu_count()\n\n\nclass Workspace(NamedObject, QROOT.RooWorkspace):\n    _ROOT = QROOT.RooWorkspace\n\n    def __call__(self, *args):\n        """"""\n        Need to provide an alternative to RooWorkspace::import since import is\n        a reserved word in Python and would be a syntax error.\n        """"""\n        return getattr(super(Workspace, self), \'import\')(*args)\n\n    def __getitem__(self, name):\n        thing = super(Workspace, self).obj(name)\n        if thing == None:\n            raise ValueError(\n                ""object named \'{0}\' does not exist ""\n                ""in the workspace \'{1}\'"".format(name, self.name))\n        return asrootpy(thing, warn=False)\n\n    def __contains__(self, name):\n        thing = super(Workspace, self).obj(name)\n        if thing:\n            return True\n        return False\n\n    def obj(self, name, cls=None):\n        thing = super(Workspace, self).obj(name)\n        if thing == None:\n            raise ValueError(\n                ""object named \'{0}\' does not exist ""\n                ""in the workspace \'{1}\'"".format(name, self.name))\n        thing = asrootpy(thing, warn=False)\n        if cls is not None and not isinstance(thing, cls):\n            raise TypeError(\n                ""object named \'{0}\' is not of the correct type: ""\n                ""{1} does not subclass {2}"".format(name, thing.__class__, cls))\n        return thing\n\n    @property\n    def category_functions(self):\n        return asrootpy(self.allCatFunctions())\n\n    @property\n    def categories(self):\n        return asrootpy(self.allCats())\n\n    @property\n    def datas(self):\n        return self.allData()\n\n    @property\n    def functions(self):\n        return asrootpy(self.allFunctions())\n\n    @property\n    def generic_objects(self):\n        return self.allGenericObjects()\n\n    @property\n    def pdfs(self):\n        return asrootpy(self.allPdfs())\n\n    @property\n    def resolution_models(self):\n        return asrootpy(self.allResolutionModels())\n\n    @property\n    def vars(self):\n        return asrootpy(self.allVars())\n\n    def arg(self, name):\n        thing = super(Workspace, self).arg(name)\n        if thing == None:\n            raise ValueError(\n                ""RooAbsArg named \'{0}\' does not exist ""\n                ""in the workspace \'{1}\'"".format(name, self.name))\n        return asrootpy(thing)\n\n    def argset(self, name):\n        thing = super(Workspace, self).argSet(name)\n        if thing == None:\n            raise ValueError(\n                ""RooArgSet named \'{0}\' does not exist ""\n                ""in the workspace \'{1}\'"".format(name, self.name))\n        return asrootpy(thing)\n\n    def category(self, name):\n        thing = super(Workspace, self).cat(name)\n        if thing == None:\n            raise ValueError(\n                ""RooCategory named \'{0}\' does not exist ""\n                ""in the workspace \'{1}\'"".format(name, self.name))\n        return asrootpy(thing)\n\n    def category_function(self, name):\n        # Dear RooStats, use camelCase consistently...\n        thing = super(Workspace, self).catfunc(name)\n        if thing == None:\n            raise ValueError(\n                ""RooAbsCategory named \'{0}\' does not exist ""\n                ""in the workspace \'{1}\'"".format(name, self.name))\n        return thing\n\n    def data(self, name):\n        thing = super(Workspace, self).data(name)\n        if thing == None:\n            raise ValueError(\n                ""RooAbsData named \'{0}\' does not exist ""\n                ""in the workspace \'{1}\'"".format(name, self.name))\n        return asrootpy(thing)\n\n    def function(self, name):\n        thing = super(Workspace, self).function(name)\n        if thing == None:\n            raise ValueError(\n                ""RooAbsReal named \'{0}\' does not exist ""\n                ""in the workspace \'{1}\'"".format(name, self.name))\n        return thing\n\n    def pdf(self, name):\n        thing = super(Workspace, self).pdf(name)\n        if thing == None:\n            raise ValueError(\n                ""RooAbsPdf named \'{0}\' does not exist ""\n                ""in the workspace \'{1}\'"".format(name, self.name))\n        return asrootpy(thing)\n\n    def set(self, name):\n        thing = super(Workspace, self).set(name)\n        if thing == None:\n            raise ValueError(\n                ""RooArgSet named \'{0}\' does not exist ""\n                ""in the workspace \'{1}\'"".format(name, self.name))\n        return asrootpy(thing)\n\n    def var(self, name):\n        thing = super(Workspace, self).var(name)\n        if thing == None:\n            raise ValueError(\n                ""RooRealVar named \'{0}\' does not exist ""\n                ""in the workspace \'{1}\'"".format(name, self.name))\n        return asrootpy(thing)\n\n    def fit(self,\n            data=\'obsData\',\n            model_config=\'ModelConfig\',\n            param_const=None,\n            param_values=None,\n            param_ranges=None,\n            poi_const=False,\n            poi_value=None,\n            poi_range=None,\n            extended=False,\n            num_cpu=1,\n            process_strategy=0,\n            offset=False,\n            print_level=None,\n            return_nll=False,\n            **kwargs):\n        """"""\n        Fit a pdf to data in a workspace\n\n        Parameters\n        ----------\n\n        workspace : RooWorkspace\n            The workspace\n\n        data : str or RooAbsData, optional (default=\'obsData\')\n            The name of the data or a RooAbsData instance.\n\n        model_config : str or ModelConfig, optional (default=\'ModelConfig\')\n            The name of the ModelConfig in the workspace or a\n            ModelConfig instance.\n\n        param_const : dict, optional (default=None)\n            A dict mapping parameter names to booleans setting\n            the const state of the parameter\n\n        param_values : dict, optional (default=None)\n            A dict mapping parameter names to values\n\n        param_ranges : dict, optional (default=None)\n            A dict mapping parameter names to 2-tuples defining the ranges\n\n        poi_const : bool, optional (default=False)\n            If True, then make the parameter of interest (POI) constant\n\n        poi_value : float, optional (default=None)\n            If not None, then set the POI to this value\n\n        poi_range : tuple, optional (default=None)\n            If not None, then set the range of the POI with this 2-tuple\n\n        extended : bool, optional (default=False)\n            If True, add extended likelihood term (False by default)\n\n        num_cpu : int, optional (default=1)\n            Parallelize NLL calculation on multiple CPU cores.\n            If negative then use all CPU cores.\n            By default use only one CPU core.\n\n        process_strategy : int, optional (default=0)\n            **Strategy 0:** Divide events into N equal chunks.\n\n            **Strategy 1:** Process event i%N in process N. Recommended for\n            binned data with a substantial number of zero-bins, which will be\n            distributed across processes more equitably in this strategy.\n\n            **Strategy 2:** Process each component likelihood of a\n            RooSimultaneous fully in a single process and distribute components\n            over processes. This approach can be benificial if normalization\n            calculation time dominates the total computation time of a\n            component (since the normalization calculation must be performed\n            in each process in strategies 0 and 1. However beware that if the\n            RooSimultaneous components do not share many parameters this\n            strategy is inefficient: as most minuit-induced likelihood\n            calculations involve changing a single parameter, only 1 of the N\n            processes will be active most of the time if RooSimultaneous\n            components do not share many parameters.\n\n            **Strategy 3:** Follow strategy 0 for all RooSimultaneous\n            components, except those with less than 30 dataset entries,\n            for which strategy 2 is followed.\n\n        offset : bool, optional (default=False)\n            Offset likelihood by initial value (so that starting value of FCN\n            in minuit is zero). This can improve numeric stability in\n            simultaneously fits with components with large likelihood values.\n\n        print_level : int, optional (default=None)\n            The verbosity level for the minimizer algorithm.\n            If None (the default) then use the global default print level.\n            If negative then all non-fatal messages will be suppressed.\n\n        return_nll : bool, optional (default=False)\n            If True then also return the RooAbsReal NLL function that was\n            minimized.\n\n        kwargs : dict, optional\n            Remaining keyword arguments are passed to the minimize function\n\n        Returns\n        -------\n\n        result : RooFitResult\n            The fit result.\n\n        func : RooAbsReal\n            If return_nll is True, the NLL function is also returned.\n\n        See Also\n        --------\n\n        minimize\n\n        """"""\n        if isinstance(model_config, string_types):\n            model_config = self.obj(\n                model_config, cls=ROOT.RooStats.ModelConfig)\n        if isinstance(data, string_types):\n            data = self.data(data)\n        pdf = model_config.GetPdf()\n\n        pois = model_config.GetParametersOfInterest()\n        if pois.getSize() > 0:\n            poi = pois.first()\n            poi.setConstant(poi_const)\n            if poi_value is not None:\n                poi.setVal(poi_value)\n            if poi_range is not None:\n                poi.setRange(*poi_range)\n\n        if param_const is not None:\n            for param_name, const in param_const.items():\n                var = self.var(param_name)\n                var.setConstant(const)\n        if param_values is not None:\n            for param_name, param_value in param_values.items():\n                var = self.var(param_name)\n                var.setVal(param_value)\n        if param_ranges is not None:\n            for param_name, param_range in param_ranges.items():\n                var = self.var(param_name)\n                var.setRange(*param_range)\n\n        if print_level < 0:\n            msg_service = ROOT.RooMsgService.instance()\n            msg_level = msg_service.globalKillBelow()\n            msg_service.setGlobalKillBelow(ROOT.RooFit.FATAL)\n\n        args = [\n            ROOT.RooFit.Constrain(model_config.GetNuisanceParameters()),\n            ROOT.RooFit.GlobalObservables(model_config.GetGlobalObservables())]\n        if extended:\n            args.append(ROOT.RooFit.Extended(True))\n        if offset:\n            args.append(ROOT.RooFit.Offset(True))\n        if num_cpu != 1:\n            if num_cpu == 0:\n                raise ValueError(""num_cpu must be non-zero"")\n            if num_cpu < 0:\n                num_cpu = NCPU\n            args.append(ROOT.RooFit.NumCPU(num_cpu, process_strategy))\n\n        func = pdf.createNLL(data, *args)\n\n        if print_level < 0:\n            msg_service.setGlobalKillBelow(msg_level)\n\n        result = minimize(func, print_level=print_level, **kwargs)\n\n        if return_nll:\n            return result, func\n        return result\n'"
rootpy/testdata/__init__.py,0,"b'from __future__ import absolute_import\n\nimport os\nfrom pkg_resources import resource_filename\n\nfrom ..io import File\n\n__all__ = [\n    \'get_filepath\',\n    \'get_file\',\n]\n\n\ndef get_filepath(name=\'test_file.root\'):\n    return resource_filename(\'rootpy\', os.path.join(\'testdata\', name))\n\n\ndef get_file(name=\'test_file.root\'):\n    filepath = get_filepath(name)\n    if not os.path.isfile(filepath):\n        raise ValueError(\n            ""rootpy test data file {0} does not exist"".format(filepath))\n    return File(filepath, \'read\')\n'"
rootpy/tests/__init__.py,0,b'from .. import log; log = log[__name__]\n'
rootpy/tests/test_ROOT.py,0,"b'from rootpy import ROOT\nfrom rootpy.plotting.hist import _Hist\nfrom nose.tools import assert_equal, assert_true\n\n\ndef test_ROOT():\n\n    a = ROOT.TH1F(""a"", ""a"", 10, 0, 1)\n    assert_true(isinstance(a, _Hist))\n\n    b = ROOT.Hist(10, 0, 1, type=\'F\')\n    assert_equal(a.TYPE, b.TYPE)\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/tests/test_base.py,0,"b'import ROOT\nfrom rootpy.base import Object\nfrom rootpy.tests.utils import iter_rootpy_classes\nfrom rootpy import asrootpy\nfrom rootpy.io import MemFile\nfrom nose.tools import assert_equal, assert_true\n\n\ndef test_object():\n    with MemFile(\'test\', \'recreate\'):\n        for cls in iter_rootpy_classes():\n            # avoid RooStats bugs for now\n            if getattr(cls, \'_ROOT\', object).__name__.startswith(\'Roo\'):\n                continue\n            if hasattr(cls, \'dynamic_cls\'):\n                cls = cls.dynamic_cls()\n            assert hasattr(cls, \'_ROOT\'), \\\n                ""rootpy class {0} does not have a _ROOT attribute"".format(\n                    cls.__name__)\n            if issubclass(cls, ROOT.TDirectory):\n                continue\n\n            obj = asrootpy(cls._ROOT())\n            if isinstance(obj, Object):\n                clone = obj.Clone()\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/tests/test_compiled.py,0,"b'import rootpy.compiled as C\n\nC.register_file(""test_compiled.cxx"",\n                [""AnswerToLtUaE"", ""RootpyTestCompiled""])\n\nC.register_code(""""""\n\n    #include <string>\n    std::string _rootpy_test() { return ""Hello, world""; }\n\n"""""", ""_rootpy_test"".split())\n\n\ndef test_compiled():\n    assert C.AnswerToLtUaE() == 42\n    assert C.RootpyTestCompiled().blah() == 84\n    assert C._rootpy_test() == ""Hello, world""\n'"
rootpy/tests/test_context.py,0,"b'from rootpy import ROOT\nfrom rootpy.context import *\nfrom rootpy.plotting import Canvas\nfrom rootpy.io import TemporaryFile\nfrom nose.tools import assert_equal, assert_true, raises\n\n\ndef test_preserve_current_directory():\n    with preserve_current_directory():\n        f = TemporaryFile()\n        f.Close()\n\n    f = TemporaryFile()\n    with preserve_current_directory():\n        with TemporaryFile() as g:\n            assert_true(g.GetName() == ROOT.gDirectory.GetName())\n    assert_true(f.GetName() == ROOT.gDirectory.GetName())\n\n\ndef test_preserve_current_canvas():\n    with preserve_current_canvas():\n        c = Canvas()\n\n    c = Canvas(name=\'c\')\n    with preserve_current_canvas():\n        d = Canvas(name=\'d\')\n        assert_true(d.GetName() == ROOT.gPad.GetName())\n    assert_true(c.GetName() == ROOT.gPad.GetName())\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/tests/test_decorators.py,0,"b'from rootpy import ROOT\nfrom rootpy.base import Object\nfrom rootpy.decorators import (method_file_check, method_file_cd,\n                               snake_case_methods)\nfrom rootpy.io import TemporaryFile\nimport rootpy\nfrom nose.tools import assert_equal, assert_true, raises\n\n\ndef test_snake_case_methods():\n\n    class A(object):\n        def SomeMethod(self): pass\n        def some_method(self): pass\n        def OtherMethod(self): pass\n        def Write(self): pass\n        def Cd(self): pass\n        def cd(self): pass\n        def LongMethodName(self): pass\n\n    @snake_case_methods\n    class B(A):\n        _ROOT = A\n        def write(self): pass\n\n    assert_true(hasattr(B, \'some_method\'))\n    assert_true(hasattr(B, \'cd\'))\n    assert_true(hasattr(B, \'long_method_name\'))\n    assert_true(hasattr(B, \'write\'))\n    assert_true(hasattr(B, \'other_method\'))\n\n\ndef test_snake_case_methods_descriptor():\n\n    def f(_): pass\n\n    class A(object):\n        Prop = property(f)\n        Sm = staticmethod(f)\n        Cm = classmethod(f)\n        M = f\n\n    class B(A):\n        cm = A.__dict__[""Cm""]\n        m = A.__dict__[""M""]\n        prop = A.__dict__[""Prop""]\n        sm = A.__dict__[""Sm""]\n\n    @snake_case_methods\n    class snakeB(A):\n        _ROOT = A\n\n    # Ensure that no accidental descriptor dereferences happened inside\n    # `snake_case_methods`. This is checked by making sure that the types\n    # are the same between B and snakeB.\n\n    for member in dir(snakeB):\n        if member.startswith(""_""): continue\n        assert_equal(type(getattr(B, member)), type(getattr(snakeB, member)))\n\n\nclass Foo(Object, ROOT.R.TH1D):\n\n    @method_file_check\n    def something(self, foo):\n        self.file = ROOT.gDirectory\n        return foo\n\n    @method_file_cd\n    def write(self):\n        assert_true(self.GetDirectory() == ROOT.gDirectory)\n\n\ndef test_method_file_check_good():\n    foo = Foo()\n    with TemporaryFile():\n        foo.something(42)\n\n\n#@raises(RuntimeError)\n#def test_method_file_check_bad():\n#    foo = Foo()\n#    foo.something(42)\n\n\ndef test_method_file_cd():\n    file1 = TemporaryFile()\n    foo = Foo()\n    foo.SetDirectory(file1)\n    file2 = TemporaryFile()\n    foo.write()\n    file1.Close()\n    file2.Close()\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/tests/test_root2hdf5.py,0,"b'from rootpy.testdata import get_file\n\nfrom nose.tools import assert_equal, with_setup\nfrom nose.plugins.skip import SkipTest\n\nfrom tempfile import mkdtemp\nimport os\nimport shutil\n\n\nTEMPDIR = None\n\n\ndef setup_func():\n    global TEMPDIR\n    TEMPDIR = mkdtemp()\n\n\ndef teardown_func():\n    shutil.rmtree(TEMPDIR)\n\n\n@with_setup(setup_func, teardown_func)\ndef test_root2hdf5():\n    try:\n        import tables\n    except ImportError:\n        raise SkipTest\n\n    from rootpy.root2hdf5 import root2hdf5, tables_open\n\n    rfile = get_file(\'test_tree.root\')\n    hfilename = os.path.join(TEMPDIR, \'out.h5\')\n    root2hdf5(rfile, hfilename)\n\n    hfile = tables_open(hfilename)\n    assert_equal(len(hfile.root.test), 1000)\n    hfile.close()\n\n\n@with_setup(setup_func, teardown_func)\ndef test_root2hdf5_chunked():\n    try:\n        import tables\n    except ImportError:\n        raise SkipTest\n\n    from rootpy.root2hdf5 import root2hdf5, tables_open\n\n    rfile = get_file(\'test_tree.root\')\n    hfilename = os.path.join(TEMPDIR, \'out.h5\')\n    root2hdf5(rfile, hfilename, entries=10)\n\n    hfile = tables_open(hfilename)\n    assert_equal(len(hfile.root.test), 1000)\n    hfile.close()\n\n\n@with_setup(setup_func, teardown_func)\ndef test_root2hdf5_chunked_selected():\n    try:\n        import tables\n    except ImportError:\n        raise SkipTest\n\n    from rootpy.root2hdf5 import root2hdf5, tables_open\n\n    rfile = get_file(\'test_tree.root\')\n    hfilename = os.path.join(TEMPDIR, \'out.h5\')\n    root2hdf5(rfile, hfilename, entries=90, selection=\'i % 2 == 0\')\n\n    hfile = tables_open(hfilename)\n    assert_equal(len(hfile.root.test), 500)\n    hfile.close()\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/tests/test_stl.py,0,"b'import ROOT\nfrom rootpy import stl\nfrom rootpy.stl import CPPType, generate\nfrom rootpy.testdata import get_file\nfrom rootpy.extern.pyparsing import ParseException\n\nfrom nose.plugins.attrib import attr\nfrom nose.tools import assert_raises, assert_equal\n\nfrom multiprocessing import Pool\n\n\nGOOD = [\n    \'std::pair<vector<const int*>, double>*\',\n    \'pair<vector<int>, vector<double> >\',\n    \'vector<vector<vector<double> > >::iterator*\',\n    \'map<int, string>\',\n    \'map<int, vector<double> >\',\n    \'map<int, vector<vector<double> > >\',\n    \'vector<unsigned int>\',\n    \'vector<const int*>\',\n    \'vector<unsigned int>\',\n]\n\nBAD = [\n    \'pair<vector<int>,double>>\',\n    \'pair<vector<int>,,vector<double> >\',\n    \'vector<<vector<vector<double> > >\',\n    \'int,string\',\n    \'int,vector<double> >\',\n    \'vector<double> >\',\n    \'map<int,vector<vector<double> > >,\',\n]\n\n\ndef test_parse():\n    for template in GOOD:\n        assert_equal(template, str(CPPType.from_string(template)))\n    for template in BAD:\n        assert_raises(ParseException, CPPType.from_string, template)\n\n\n@attr(\'slow\')\ndef test_stl():\n    generate(\'map<int,vector<float> >\', \'<vector>;<map>\')\n    generate(\'map<int,vector<int> >\', \'<vector>;<map>\')\n    generate(\'vector<TLorentzVector>\', \'<vector>;TLorentzVector.h\')\n\n    ROOT.std.map(\'int,vector<float>\')\n    ROOT.std.map(\'int,vector<int>\')\n    ROOT.std.vector(\'TLorentzVector\')\n\n    temp = CPPType.from_string(\'vector<vector<vector<int> > >\')\n    temp.ensure_built()\n\n    stl.vector(\'vector<map<int, string> >\')\n    stl.vector(stl.string)()\n    stl.vector(\'string\')()\n    stl.vector(int)\n\n    stl.map(""string"", ""string"")\n    stl.map(stl.string, stl.string)\n    stl.map(int, stl.string)\n    stl.map(stl.string, int)\n    stl.map(""string"", ROOT.TLorentzVector)\n\n    histmap = stl.map(""string"", ROOT.TH1D)()\n    a = ROOT.TH1D(""a"", ""a"", 10, -1, 1)\n    histmap[""a""] = a\n\n    StrHist = stl.pair(stl.string, ""TH1*"")\n\n    generate(\'pair<map<string,TH1*>::iterator,bool>\', \'<map>;<TH1.h>\')\n    histptrmap = stl.map(stl.string, ""TH1*"")()\n    histptrmap.insert(StrHist(""test"", a))\n\n    assert histptrmap[""test""] is a\n\n""""""\nThis test frequently fails on Travis due to os.fork() not being able to\nallocate memory. Disabling it for now until a solution is found.\n\ndef load_tree(*args):\n    with get_file(\'test_dicts.root\') as f:\n        t = f.data\n        # this will trigger the generation of the required dicts\n        t.create_buffer()\n\n\ndef test_dict_load():\n    # test file locking\n    po = Pool()\n    po.map(load_tree, range(3))\n""""""\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/tests/utils.py,0,"b'from __future__ import absolute_import\n\nfrom . import log; log = log[__name__]\nfrom .. import _get_class, INIT_REGISTRY_ROOTPY\n\n__all__ = [\n    \'iter_rootpy_classes\',\n]\n\n\ndef iter_rootpy_classes():\n    for name, path in INIT_REGISTRY_ROOTPY.items():\n        try:\n            cls = _get_class(path, name)\n        except:\n            log.warning(\n                ""unable to get class {0} at {1}"".format(name, path))\n            continue\n        else:\n            yield cls\n'"
rootpy/tree/__init__.py,0,"b""from __future__ import absolute_import\n\nfrom .. import log; log = log[__name__]\n\nfrom .treetypes import (\n    ObjectCol,\n    BoolCol, BoolArrayCol,\n    CharCol, CharArrayCol,\n    UCharCol, UCharArrayCol,\n    ShortCol, ShortArrayCol,\n    UShortCol, UShortArrayCol,\n    IntCol, IntArrayCol,\n    UIntCol, UIntArrayCol,\n    LongCol, LongArrayCol,\n    ULongCol, ULongArrayCol,\n    FloatCol, FloatArrayCol,\n    DoubleCol, DoubleArrayCol)\n\nfrom .tree import Tree, Ntuple\nfrom .treebuffer import TreeBuffer\nfrom .treemodel import TreeModel\nfrom .chain import TreeChain, TreeQueue\nfrom .cut import Cut\nfrom .categories import Categories\n\n__all__ = [\n    'ObjectCol',\n    'BoolCol', 'BoolArrayCol',\n    'CharCol', 'CharArrayCol',\n    'UCharCol', 'UCharArrayCol',\n    'ShortCol', 'ShortArrayCol',\n    'UShortCol', 'UShortArrayCol',\n    'IntCol', 'IntArrayCol',\n    'UIntCol', 'UIntArrayCol',\n    'LongCol', 'LongArrayCol',\n    'ULongCol', 'ULongArrayCol',\n    'FloatCol', 'FloatArrayCol',\n    'DoubleCol', 'DoubleArrayCol',\n    'Tree',\n    'Ntuple',\n    'TreeBuffer',\n    'TreeModel',\n    'TreeChain',\n    'TreeQueue',\n    'Cut',\n    'Categories',\n]\n"""
rootpy/tree/categories.py,0,"b'from __future__ import absolute_import\n\nimport re\n\nfrom .cut import Cut\n\n__all__ = [\n    \'Categories\',\n]\n\n\nclass Categories(object):\n    """"""\n    Implements a mechanism to ease the creation of cuts that describe\n    non-overlapping categories.\n    """"""\n    #TODO: use pyparsing\n    CUT_REGEX = \'[-+]?[0-9]*\\.?[0-9]+([eE][-+]?[0-9]+)?\'\n    NODE_PATTERN = re.compile(\n        \'^{(?P<variable>[^:|]+)(?::(?P<type>[IFif]))?\\|\'\n        \'(?P<leftchild>{.+})?(?P<cut>\' + CUT_REGEX + \')\'\n        \'(?P<rightchild>{.+})?}$\')\n    CATEGORY_PATTERN = re.compile(\n        \'^(?P<left>{.+})(?:x(?P<right>{.+}(?:x{.+})*))$\')\n    CATEGORY_NODE_PATTERN = re.compile(\n        \'^{(?P<variable>[^:|]+)(?::(?P<type>[IFif]))?\\|\'\n        \'(?P<cuts>[\\*]?(?:\' + CUT_REGEX + \')(?:,\' + CUT_REGEX + \')*[\\*]?)}$\')\n\n    @classmethod\n    def from_string(cls, string, variables=None):\n        node = None\n        if variables is None:\n            variables = []\n        nodematch = re.match(Categories.NODE_PATTERN, string)\n        categorymatch = re.match(Categories.CATEGORY_PATTERN, string)\n        categorynodematch = re.match(Categories.CATEGORY_NODE_PATTERN, string)\n        if categorymatch:\n            node = Categories.from_string(categorymatch.group(\'left\'), variables)\n            subtree = Categories.from_string(categorymatch.group(\'right\'), variables)\n            incompletenodes = node.get_incomplete_children()\n            for child in incompletenodes:\n                if not child.leftchild and not child.forbidleft:\n                    clone = subtree.clone()\n                    child.set_left(clone)\n                if not child.rightchild and not child.forbidright:\n                    clone = subtree.clone()\n                    child.set_right(clone)\n        elif categorynodematch:\n            var_type = \'F\'\n            if categorynodematch.group(\'type\'):\n                var_type = categorynodematch.group(\'type\').upper()\n            variable = (categorynodematch.group(\'variable\'), var_type)\n            if variable not in variables:\n                variables.append(variable)\n            cuts = categorynodematch.group(\'cuts\').split(\',\')\n            if len(cuts) != len(set(cuts)):\n                raise SyntaxError(\n                    ""repeated cuts in \'{0}\'"".format(\n                        categorynodematch.group(\'cuts\')))\n            if sorted(cuts) != cuts:\n                raise SyntaxError(\n                    ""cuts not in ascending order in \'{0}\'"".format(\n                        categorynodematch.group(\'cuts\')))\n            nodes = []\n            for cut in cuts:\n                actual_cut = cut.replace(\'*\', \'\')\n                node = Categories(\n                    feature=variables.index(variable),\n                    data=actual_cut,\n                    variables=variables)\n                if cut.startswith(\'*\'):\n                    node.forbidleft = True\n                if cut.endswith(\'*\'):\n                    node.forbidright = True\n                nodes.append(node)\n            node = Categories.make_balanced_tree(nodes)\n        elif nodematch:\n            var_type = \'F\'\n            if nodematch.group(\'type\'):\n                var_type = nodematch.group(\'type\').upper()\n            variable = (nodematch.group(\'variable\'), var_type)\n            if variable not in variables:\n                variables.append(variable)\n            node = Categories(\n                feature=variables.index(variable),\n                data=nodematch.group(\'cut\'),\n                variables=variables)\n            if nodematch.group(\'leftchild\'):\n                leftchild = Categories.from_string(\n                    nodematch.group(\'leftchild\'), variables)\n                node.set_left(leftchild)\n            if nodematch.group(\'rightchild\'):\n                rightchild = Categories.from_string(\n                    nodematch.group(\'rightchild\'), variables)\n                node.set_right(rightchild)\n        else:\n            raise SyntaxError(\n                ""{0} is not valid category tree syntax"".format(string))\n        return node\n\n    @classmethod\n    def make_balanced_tree(cls, nodes):\n        if len(nodes) == 0:\n            return None\n        if len(nodes) == 1:\n            return nodes[0]\n        center = len(nodes) // 2\n        leftnodes = nodes[:center]\n        rightnodes = nodes[center + 1:]\n        node = nodes[center]\n        leftchild = Categories.make_balanced_tree(leftnodes)\n        rightchild = Categories.make_balanced_tree(rightnodes)\n        node.set_left(leftchild)\n        node.set_right(rightchild)\n        return node\n\n    def __init__(self,\n                 feature,\n                 data,\n                 variables,\n                 leftchild=None,\n                 rightchild=None,\n                 parent=None,\n                 forbidleft=False,\n                 forbidright=False):\n        self.feature = feature\n        self.data = data\n        self.variables = variables\n        self.leftchild = leftchild\n        self.rightchild = rightchild\n        self.parent = parent\n        self.forbidleft = forbidleft\n        self.forbidright = forbidright\n\n    def clone(self):\n        leftclone = None\n        if self.leftchild is not None:\n            leftclone = self.leftchild.clone()\n        rightclone = None\n        if self.rightchild is not None:\n            rightclone = self.rightchild.clone()\n        return Categories(\n            self.feature,\n            self.data,\n            self.variables,\n            leftclone,\n            rightclone,\n            self.parent,\n            self.forbidleft,\n            self.forbidright)\n\n    def __str__(self):\n        leftstr = \'\'\n        rightstr = \'\'\n        if self.forbidleft:\n            leftstr = \'*\'\n        elif self.leftchild is not None:\n            leftstr = str(self.leftchild)\n        if self.forbidright:\n            rightstr = \'*\'\n        elif self.rightchild is not None:\n            rightstr = str(self.rightchild)\n        if self.feature >= 0:\n            return \'{{0}:{1}|{2}{3}{4}}\'.format(\n                self.variables[self.feature],\n                leftstr, str(self.data), rightstr)\n        return \'{<<leaf>>|{0}}\'.format(str(self.data))\n\n    def __repr__(self):\n        return self.__str__()\n\n    def set_left(self, child):\n        if child is self:\n            raise ValueError(""attempted to set self as left child!"")\n        self.leftchild = child\n        if child is not None:\n            child.parent = self\n\n    def set_right(self, child):\n        if child is self:\n            raise ValueError(""attempted to set self as right child!"")\n        self.rightchild = child\n        if child is not None:\n            child.parent = self\n\n    def is_leaf(self):\n        return self.leftchild is None and self.rightchild is None\n\n    def is_complete(self):\n        return self.leftchild is not None and self.rightchild is not None\n\n    def depth(self):\n        leftdepth = 0\n        if self.leftchild is not None:\n            leftdepth = self.leftchild.depth() + 1\n        rightdepth = 0\n        if self.rightchild is not None:\n            rightdepth = self.rightchild.depth() + 1\n        return max(leftdepth, rightdepth)\n\n    def balance(self):\n        leftdepth = 0\n        rightdepth = 0\n        if self.leftchild is not None:\n            leftdepth = self.leftchild.depth() + 1\n        if self.rightchild is not None:\n            rightdepth = self.rightchild.depth() + 1\n        return rightdepth - leftdepth\n\n    def get_leaves(self):\n        if self.is_leaf():\n            return [self]\n        leftleaves = []\n        if self.leftchild is not None:\n            leftleaves = self.leftchild.get_leaves()\n        rightleaves = []\n        if self.rightchild is not None:\n            rightleaves = self.rightchild.get_leaves()\n        return leftleaves + rightleaves\n\n    def get_incomplete_children(self):\n        children = []\n        if not self.is_complete():\n            children.append(self)\n        if self.leftchild is not None:\n            children += self.leftchild.get_incomplete_children()\n        if self.rightchild is not None:\n            children += self.rightchild.get_incomplete_children()\n        return children\n\n    def __len__(self):\n        """"""\n        Number of categories beneath current node\n        """"""\n        if self.is_leaf():\n            total = 0\n            if not self.forbidleft:\n                total += 1\n            if not self.forbidright:\n                total += 1\n            return total\n        total = 0\n        if not self.forbidleft and self.leftchild is not None:\n            total += len(self.leftchild)\n        if not self.forbidright and self.rightchild is not None:\n            total += len(self.rightchild)\n        return total\n\n    def walk(self, expression=None):\n        if expression is None:\n            expression = Cut()\n        if self.feature < 0:\n            if expression:\n                yield expression\n        if not self.forbidleft:\n            leftcondition = expression & Cut(\n                \'{0}<={1}\'.format(\n                    self.variables[self.feature][0], self.data))\n            if self.leftchild is not None:\n                for condition in self.leftchild.walk(leftcondition):\n                    yield condition\n            else:\n                yield leftcondition\n        if not self.forbidright:\n            rightcondition = expression & Cut(\n                \'{0}>{1}\'.format(\n                    self.variables[self.feature][0], self.data))\n            if self.rightchild is not None:\n                for condition in self.rightchild.walk(rightcondition):\n                    yield condition\n            else:\n                yield rightcondition\n\n    def __iter__(self):\n        """"""\n        Iterator over leaf conditions\n        """"""\n        for category in self.walk():\n            yield category\n'"
rootpy/tree/chain.py,0,"b'from __future__ import absolute_import\n\nimport multiprocessing\nimport time\n\nfrom .. import log; log = log[__name__]\nfrom .. import QROOT\nfrom ..io import root_open, DoesNotExist\nfrom ..utils.extras import humanize_bytes\nfrom ..context import preserve_current_directory\nfrom ..plotting.graph import _GraphBase\nfrom ..extern.six import string_types\nfrom .filtering import EventFilterList\n\n__all__ = [\n    \'TreeChain\',\n    \'TreeQueue\',\n]\n\n\nclass BaseTreeChain(object):\n\n    def __init__(self, name,\n                 treebuffer=None,\n                 branches=None,\n                 ignore_branches=None,\n                 events=-1,\n                 onfilechange=None,\n                 read_branches_on_demand=False,\n                 cache=False,\n                 # 30 MB cache by default\n                 cache_size=30000000,\n                 learn_entries=10,\n                 always_read=None,\n                 ignore_unsupported=False,\n                 filters=None):\n        self._name = name\n        self._buffer = treebuffer\n        self._branches = branches\n        self._ignore_branches = ignore_branches\n        self._tree = None\n        self._file = None\n        self._events = events\n        self._total_events = 0\n        self._ignore_unsupported = ignore_unsupported\n        self._initialized = False\n        if filters is None:\n            self._filters = EventFilterList([])\n        else:\n            self._filters = filters\n        if onfilechange is None:\n            onfilechange = []\n        self._filechange_hooks = onfilechange\n\n        self._read_branches_on_demand = read_branches_on_demand\n        self._use_cache = cache\n        self._cache_size = cache_size\n        self._learn_entries = learn_entries\n\n        self.weight = 1.\n        self.userdata = {}\n\n        if not self._rollover():\n            raise RuntimeError(""unable to initialize TreeChain"")\n\n        if always_read is None:\n            self._always_read = []\n        elif isinstance(always_read, string_types):\n            if \'*\' in always_read:\n                always_read = self._tree.glob(always_read)\n            else:\n                always_read = [always_read]\n            self.always_read(always_read)\n        else:\n            branches = []\n            for branch in always_read:\n                if \'*\' in branch:\n                    branches += self._tree.glob(branch)\n                else:\n                    branches.append(branch)\n            self.always_read(branches)\n\n    def __nonzero__(self):\n        return len(self) > 0\n\n    __bool__ = __nonzero__\n\n    def _next_file(self):\n        """"""\n        Override in subclasses\n        """"""\n        return None\n\n    def always_read(self, branches):\n        self._always_read = branches\n        self._tree.always_read(branches)\n\n    def reset(self):\n        if self._tree is not None:\n            self._tree = None\n        if self._file is not None:\n            self._file.Close()\n            self._file = None\n\n    def Draw(self, *args, **kwargs):\n        """"""\n        Loop over subfiles, draw each, and sum the output into a single\n        histogram.\n        """"""\n        self.reset()\n        output = None\n        while self._rollover():\n            if output is None:\n                # Make our own copy of the drawn histogram\n                output = self._tree.Draw(*args, **kwargs)\n                if output is not None:\n                    output = output.Clone()\n                    # Make it memory resident (histograms)\n                    if hasattr(output, \'SetDirectory\'):\n                        output.SetDirectory(0)\n            else:\n                newoutput = self._tree.Draw(*args, **kwargs)\n                if newoutput is not None:\n                    if isinstance(output, _GraphBase):\n                        output.Append(newoutput)\n                    else:  # histogram\n                        output += newoutput\n        return output\n\n    draw = Draw\n\n    def __getattr__(self, attr):\n        try:\n            return getattr(self._tree, attr)\n        except AttributeError:\n            raise AttributeError(""{0} instance has no attribute \'{1}\'"".format(\n                self.__class__.__name__, attr))\n\n    def __getitem__(self, item):\n        return self._tree.__getitem__(item)\n\n    def __contains__(self, branch):\n        return self._tree.__contains__(branch)\n\n    def __iter__(self):\n        passed_events = 0\n        self.reset()\n        while self._rollover():\n            entries = 0\n            total_entries = float(self._tree.GetEntries())\n            t1 = time.time()\n            t2 = t1\n            for entry in self._tree:\n                entries += 1\n                self.userdata = {}\n                if self._filters(entry):\n                    yield entry\n                    passed_events += 1\n                    if self._events == passed_events:\n                        break\n                if time.time() - t2 > 60:\n                    entry_rate = int(entries / (time.time() - t1))\n                    log.info(\n                        ""{0:d} entr{1} per second. ""\n                        ""{2:.0f}% done current tree."".format(\n                            entry_rate,\n                            \'ies\' if entry_rate != 1 else \'y\',\n                            100 * entries / total_entries))\n                    t2 = time.time()\n            if self._events == passed_events:\n                break\n            log.info(""{0:d} entries per second"".format(\n                int(entries / (time.time() - t1))))\n            log.info(""read {0:d} bytes in {1:d} transactions"".format(\n                self._file.GetBytesRead(),\n                self._file.GetReadCalls()))\n            self._total_events += entries\n        self._filters.finalize()\n\n    def _rollover(self):\n        filename = self._next_file()\n        if filename is None:\n            return False\n        log.info(""current file: {0}"".format(filename))\n        try:\n            with preserve_current_directory():\n                if self._file is not None:\n                    self._file.Close()\n                self._file = root_open(filename)\n        except IOError:\n            self._file = None\n            log.warning(""could not open file {0} (skipping)"".format(filename))\n            return self._rollover()\n        try:\n            self._tree = self._file.Get(self._name)\n        except DoesNotExist:\n            log.warning(\n                ""tree {0} does not exist in file {1} (skipping)"".format(\n                    self._name, filename))\n            return self._rollover()\n        if len(self._tree.GetListOfBranches()) == 0:\n            log.warning(""tree with no branches in file {0} (skipping)"".format(\n                filename))\n            return self._rollover()\n        if self._branches is not None:\n            self._tree.activate(self._branches, exclusive=True)\n        if self._ignore_branches is not None:\n            self._tree.deactivate(self._ignore_branches, exclusive=False)\n        if self._buffer is None:\n            self._tree.create_buffer(self._ignore_unsupported)\n            self._buffer = self._tree._buffer\n        else:\n            self._tree.set_buffer(\n                self._buffer,\n                ignore_missing=True,\n                transfer_objects=True)\n            self._buffer = self._tree._buffer\n        if self._use_cache:\n            # enable TTreeCache for this tree\n            log.info(\n                ""enabling a {0} TTreeCache for the current tree ""\n                ""({1:d} learning entries)"".format(\n                    humanize_bytes(self._cache_size), self._learn_entries))\n            self._tree.SetCacheSize(self._cache_size)\n            self._tree.SetCacheLearnEntries(self._learn_entries)\n        self._tree.read_branches_on_demand = self._read_branches_on_demand\n        self._tree.always_read(self._always_read)\n        self.weight = self._tree.GetWeight()\n        for target, args in self._filechange_hooks:\n            # run any user-defined functions\n            target(*args, name=self._name, file=self._file, tree=self._tree)\n        return True\n\n\nclass TreeChain(BaseTreeChain):\n    """"""\n    A ROOT.TChain replacement\n    """"""\n    def __init__(self, name, files, **kwargs):\n        if isinstance(files, tuple):\n            files = list(files)\n        elif not isinstance(files, list):\n            files = [files]\n        else:\n            files = files[:]\n        if not files:\n            raise RuntimeError(\n                ""unable to initialize TreeChain: no files"")\n        self._files = files\n        self.curr_file_idx = 0\n        super(TreeChain, self).__init__(name, **kwargs)\n        self._tchain = QROOT.TChain(name)\n        for filename in self._files:\n            self._tchain.Add(filename)\n\n    def GetEntries(self, *args, **kwargs):\n        return self._tchain.GetEntries(*args, **kwargs)\n\n    def GetEntriesFast(self, *args, **kwargs):\n        return self._tchain.GetEntriesFast(*args, **kwargs)\n\n    def reset(self):\n        """"""\n        Reset the chain to the first file\n        Note: not valid when in queue mode\n        """"""\n        super(TreeChain, self).reset()\n        self.curr_file_idx = 0\n\n    def __len__(self):\n        return len(self._files)\n\n    def _next_file(self):\n        if self.curr_file_idx >= len(self._files):\n            return None\n        filename = self._files[self.curr_file_idx]\n        nfiles_remaining = len(self._files) - self.curr_file_idx\n        log.info(""{0:d} file{1} remaining"".format(\n            nfiles_remaining,\n            \'s\' if nfiles_remaining > 1 else \'\'))\n        self.curr_file_idx += 1\n        return filename\n\n\nclass TreeQueue(BaseTreeChain):\n    """"""\n    A chain of files in a multiprocessing Queue.\n\n    Note that asking for the number of files in the queue with len(treequeue)\n    can be unreliable. Also, methods not overridden by TreeQueue will always be\n    called on the current tree, so GetEntries will give you the number of\n    entries in the current tree.\n    """"""\n    SENTINEL = None\n\n    def __init__(self, name, files, **kwargs):\n        # multiprocessing.queues d.n.e. until one has been created\n        multiprocessing.Queue()\n        if not isinstance(files, multiprocessing.queues.Queue):\n            raise TypeError(""files must be a multiprocessing.Queue"")\n        self._files = files\n\n        super(TreeQueue, self).__init__(name, **kwargs)\n\n    def __len__(self):\n        # not reliable\n        return self._files.qsize()\n\n    def __nonzero__(self):\n        # not reliable\n        return not self._files.empty()\n\n    __bool__ = __nonzero__\n\n    def _next_file(self):\n        filename = self._files.get()\n        if filename == self.SENTINEL:\n            return None\n        return filename\n'"
rootpy/tree/cut.py,0,"b'from __future__ import absolute_import\n\nimport re\nimport sys\nif sys.version_info[0] >= 3:\n    import io\n    file = io.TextIOBase\n\nimport ROOT\n\nfrom .. import log; log = log[__name__]\nfrom .. import QROOT\nfrom ..utils import path\nfrom ..extern.six import string_types\n\n\n__all__ = [\n    \'Cut\',\n]\n\n\ndef cutop(func):\n    def foo(self, other):\n        other = Cut.convert(other)\n        if not self:\n            return other\n        if not other:\n            return self\n        return func(self, other)\n    return foo\n\n\ndef icutop(func):\n    def foo(self, other):\n        other = Cut.convert(other)\n        if not self:\n            self.SetTitle(other.GetTitle())\n            return self\n        if not other:\n            return self\n        return func(self, other)\n    return foo\n\n\ndef _expand_ternary(match):\n    return \'({0}{1})&&({1}{2})\'.format(\n        match.group(\'left\'),\n        match.group(\'name\'),\n        match.group(\'right\'))\n\n\n_TERNARY = re.compile(\n    \'(?P<left>[a-zA-Z0-9_\\.\\+\\-\\*\\/]+[<>=]+)\'\n    \'(?P<name>[\\w\\.\\+\\-\\*\\/\\(\\)]+)\'\n    \'(?P<right>[<>=]+[a-zA-Z0-9_\\.\\+\\-\\*\\/]+)\')\n\n\n\n\nclass Cut(QROOT.TCut):\n    """"""\n    Inherits from ROOT.TCut and implements logical operators\n    """"""\n    _ROOT = QROOT.TCut\n\n    def __init__(self, cut=\'\', from_file=False):\n        if cut != \'\':\n            if cut is None:\n                cut = \'\'\n            elif isinstance(cut, file):\n                cut = \'\'.join(line.strip() for line in cut.readlines())\n            elif isinstance(cut, string_types) and from_file:\n                ifile = open(path.expand(cut))\n                cut = \'\'.join(line.strip() for line in ifile.readlines())\n                ifile.close()\n            elif isinstance(cut, Cut):\n                cut = cut.GetTitle()\n            # remove whitespace\n            cut = cut.replace(\' \', \'\')\n            # expand ternary operations (i.e. 3<A<8)\n            cut = re.sub(_TERNARY, _expand_ternary, cut)\n        super(Cut, self).__init__(cut)\n\n    @staticmethod\n    def convert(thing):\n        if isinstance(thing, Cut):\n            return thing\n        elif isinstance(thing, string_types):\n            return Cut(thing)\n        elif thing is None:\n            return Cut()\n        return Cut(str(thing))\n\n    @property\n    def str(self):\n        return self.GetTitle()\n\n    @str.setter\n    def str(self, content):\n        self.SetTitle(str(content))\n\n    def __mod__(self, other):\n        if isinstance(other, Cut):\n            other = str(other)\n        return Cut(str(self) % other)\n\n    def __imod__(self, other):\n        if isinstance(other, Cut):\n            other = str(other)\n        self.SetTitle(str(self) % other)\n        return self\n\n    @cutop\n    def __and__(self, other):\n        """"""\n        Return a new cut which is the logical AND of this cut and another\n        """"""\n        return Cut(\'({0!s})&&({1!s})\'.format(self, other))\n\n    @cutop\n    def __rand__(self, other):\n        return self & other\n\n    @cutop\n    def __mul__(self, other):\n        """"""\n        Return a new cut which is the product of this cut and another\n        """"""\n        return Cut(\'({0!s})*({1!s})\'.format(self, other))\n\n    @cutop\n    def __rmul__(self, other):\n        return self * other\n\n    @icutop\n    def __imul__(self, other):\n        """"""\n        Multiply other cut with self and return self\n        """"""\n        self.SetTitle(\'({0!s})*({1!s})\'.format(self, other))\n        return self\n\n    @cutop\n    def __or__(self, other):\n        """"""\n        Return a new cut which is the logical OR of this cut and another\n        """"""\n        return Cut(\'({0!s})||({1!s})\'.format(self, other))\n\n    @cutop\n    def __ror__(self, other):\n        return self | other\n\n    @cutop\n    def __add__(self, other):\n        """"""\n        Return a new cut which is the sum of this cut and another\n        """"""\n        return Cut(\'({0!s})+({1!s})\'.format(self, other))\n\n    @cutop\n    def __radd__(self, other):\n        return self + other\n\n    @icutop\n    def __iadd__(self, other):\n        """"""\n        Add other cut to self and return self\n        """"""\n        self.SetTitle(\'({0!s})+({1!s})\'.format(self, other))\n        return self\n\n    @cutop\n    def __sub__(self, other):\n        """"""\n        Return a new cut which is the difference of this cut and another\n        """"""\n        return Cut(\'({0!s})-({1!s})\'.format(self, other))\n\n    @cutop\n    def __rsub__(self, other):\n        return self - other\n\n    @icutop\n    def __isub__(self, other):\n        """"""\n        Subtract other cut to self and return self\n        """"""\n        self.SetTitle(\'({0!s})-({1!s})\'.format(self, other))\n        return self\n\n    def __neg__(self):\n        """"""\n        Return a new cut which is the negation of this cut\n        """"""\n        if not self:\n            return Cut()\n        return Cut(\'!({0!s})\'.format(self))\n\n    def __pos__(self):\n        return Cut(self)\n\n    def __str__(self):\n        return self.GetTitle()\n\n    def __repr__(self):\n        return ""\'{0!s}\'"".format(self)\n\n    def __nonzero__(self):\n        """"""\n        A cut evaluates to False if it is empty (null cut).\n        This has no affect on its actual boolean value within the context of\n        a ROOT.TTree selection.\n        """"""\n        return str(self) != \'\'\n\n    __bool__ = __nonzero__\n\n    def __contains__(self, other):\n        return str(other) in str(self)\n\n    def safe(self, parentheses=True):\n        """"""\n        Returns a string representation with special characters\n        replaced by safer characters for use in file names.\n        """"""\n        if not self:\n            return """"\n        string = str(self)\n        string = string.replace(""**"", ""_pow_"")\n        string = string.replace(""*"", ""_mul_"")\n        string = string.replace(""/"", ""_div_"")\n        string = string.replace(""=="", ""_eq_"")\n        string = string.replace(""<="", ""_leq_"")\n        string = string.replace("">="", ""_geq_"")\n        string = string.replace(""<"", ""_lt_"")\n        string = string.replace("">"", ""_gt_"")\n        string = string.replace(""&&"", ""_and_"")\n        string = string.replace(""||"", ""_or_"")\n        string = string.replace(""!"", ""not_"")\n        if parentheses:\n            string = string.replace(""("", ""L"")\n            string = string.replace("")"", ""R"")\n        else:\n            string = string.replace(""("", """")\n            string = string.replace("")"", """")\n        string = string.replace("" "", """")\n        return string\n\n    def latex(self):\n        """"""\n        Returns a string representation for use in LaTeX\n        """"""\n        if not self:\n            return """"\n        s = str(self)\n        s = s.replace(""=="", "" = "")\n        s = s.replace(""<="", "" \\leq "")\n        s = s.replace("">="", "" \\geq "")\n        s = s.replace(""&&"", r"" \\text{ and } "")\n        s = s.replace(""||"", r"" \\text{ or } "")\n        return s\n\n    def where(self):\n        """"""\n        Return string compatible with PyTable\'s Table.where syntax:\n        http://pytables.github.com/usersguide/libref.html#tables.Table.where\n        """"""\n        return re.sub(\n            \'!(?!=)\', \'~\',\n            str(self).replace(\'&&\', \'&\').replace(\'||\', \'|\'))\n\n    def replace(self, name, newname):\n        """"""\n        Replace all occurrences of name with newname\n        """"""\n        if not re.match(""[a-zA-Z]\\w*"", name):\n            return None\n        if not re.match(""[a-zA-Z]\\w*"", newname):\n            return None\n\n        def _replace(match):\n            return match.group(0).replace(match.group(\'name\'), newname)\n\n        pattern = re.compile(""(\\W|^)(?P<name>"" + name + "")(\\W|$)"")\n        cut = re.sub(pattern, _replace, str(self))\n        return Cut(cut)\n'"
rootpy/tree/filtering.py,0,"b'""""""\nThis module defines a framework for filtering Trees.\nThe user must write a class which inherits from Filter and\n""""""\nfrom __future__ import absolute_import\n\n#from ..extern.tabulartext import PrettyTable\nfrom . import log; log = log[__name__]\n\n__all__ = [\n    \'Filter\',\n    \'FilterHook\',\n    \'EventFilter\',\n    \'ObjectFilter\',\n    \'FilterList\',\n    \'EventFilterList\',\n    \'ObjectFilterList\',\n]\n\n\nclass Filter(object):\n    """"""\n    The base class from which all filter classes must inherit from.\n    The derived class must override the passes method which returns True\n    if ths event passes and returns False if not.\n    The number of passing and failing events are recorded and may be used\n    later to create a cut-flow.\n    """"""\n    def __init__(self,\n                 hooks=None,\n                 passthrough=False,\n                 name=None,\n                 count_funcs=None):\n        self.total = 0\n        self.passing = 0\n        self.count_funcs_total = {}\n        self.count_funcs_passing = {}\n\n        if count_funcs is not None:\n            self.count_funcs = count_funcs\n        else:\n            self.count_funcs = {}\n\n        for func_name in self.count_funcs.iterkeys():\n            self.count_funcs_total[func_name] = 0.\n            self.count_funcs_passing[func_name] = 0.\n\n        self.details = {}\n        if name is None:\n            self.name = self.__class__.__name__\n        else:\n            self.name = name\n\n        self.hooks = hooks\n        self.passthrough = passthrough\n        self.was_passed = False\n        if self.passthrough:\n            log.info(\n                ""Filter {0} will run in pass-through mode"".format(\n                    self.__class__.__name__))\n        else:\n            log.info(\n                ""Filter {0} is activated"".format(\n                    self.__class__.__name__))\n\n    def __str__(self):\n        return self.__repr__()\n\n    def __getstate__(self):\n        return {\n            ""name"": self.name,\n            ""total"": self.total,\n            ""passing"": self.passing,\n            ""details"": self.details,\n            ""count_funcs"": dict([\n                (name, None) for name in self.count_funcs.keys()]),\n            ""count_funcs_total"": self.count_funcs_total,\n            ""count_funcs_passing"": self.count_funcs_passing}\n\n    def __setstate__(self, state):\n        self.name = state[\'name\']\n        self.total = state[\'total\']\n        self.passing = state[\'passing\']\n        self.details = state[\'details\']\n        self.count_funcs = state[\'count_funcs\']\n        self.count_funcs_total = state[\'count_funcs_total\']\n        self.count_funcs_passing = state[\'count_funcs_passing\']\n\n    def __repr__(self):\n        return (""Filter {0}\\n""\n                ""Total: {1:d}\\n""\n                ""Pass:  {2:d}"").format(\n                    self.name,\n                    self.total,\n                    self.passing)\n\n    @classmethod\n    def add(cls, left, right):\n        if left.name != right.name:\n            raise ValueError(""Attemping to add filters with different names"")\n        newfilter = Filter()\n        newfilter.name = left.name\n        newfilter.total = left.total + right.total\n        newfilter.passing = left.passing + right.passing\n        newfilter.details = dict([\n            (detail, left.details[detail] + right.details[detail])\n            for detail in left.details.keys()])\n        # sum count_funcs\n        for func_name in left.count_funcs.keys():\n            if func_name not in right.count_funcs:\n                raise ValueError(\n                    ""{0} count is not defined ""\n                    ""for both filters"".format(func_name))\n            newfilter.count_funcs[func_name] = left.count_funcs[func_name]\n            newfilter.count_funcs_total[func_name] = (\n                left.count_funcs_total[func_name] +\n                right.count_funcs_total[func_name])\n            newfilter.count_funcs_passing[func_name] = (\n                left.count_funcs_passing[func_name] +\n                right.count_funcs_passing[func_name])\n        return newfilter\n\n    def __add__(self, other):\n        return Filter.add(self, other)\n\n    def passed(self, event):\n        self.total += 1\n        self.passing += 1\n        for name, func in self.count_funcs.items():\n            count = func(event)\n            self.count_funcs_total[name] += count\n            self.count_funcs_passing[name] += count\n        self.was_passed = True\n\n    def failed(self, event):\n        self.total += 1\n        for name, func in self.count_funcs.items():\n            count = func(event)\n            self.count_funcs_total[name] += count\n        self.was_passed = False\n\n\nclass FilterHook(object):\n\n    def __init__(self, target, args):\n        self.target = target\n        self.args = args\n\n    def __call__(self):\n        self.target(*self.args)\n\n\nclass EventFilter(Filter):\n\n    def __call__(self, event):\n        if self.passthrough:\n            if self.hooks:\n                for hook in self.hooks:\n                    hook()\n            self.passed(event)\n            return True\n        _passes = self.passes(event)\n        if _passes is None:\n            # event is not counted in total\n            log.warning(\n                ""Filter {0} returned None so event will not ""\n                ""contribute to cut-flow. Use True to accept event, ""\n                ""otherwise False."".format(self.__class__.__name__))\n            return False\n        elif _passes:\n            if self.hooks:\n                for hook in self.hooks:\n                    hook()\n            self.passed(event)\n            return True\n        self.failed(event)\n        return False\n\n    def passes(self, event):\n        """"""\n        You should override this method in your derived class\n        """"""\n        return True\n\n    def finalize(self):\n        """"""\n        You should override this method in your derived class\n        """"""\n        pass\n\n\nclass ObjectFilter(Filter):\n\n    def __init__(self, count_events=False, **kwargs):\n        self.count_events = count_events\n        super(ObjectFilter, self).__init__(**kwargs)\n\n    def __call__(self, event, collection):\n        self.was_passed = False\n        if self.count_events:\n            self.total += 1\n        else:\n            self.total += len(collection)\n        if not self.passthrough:\n            collection = self.filtered(event, collection)\n        if len(collection) > 0:\n            self.was_passed = True\n            if self.count_events:\n                self.passing += 1\n            else:\n                self.passing += len(collection)\n        return collection\n\n    def filtered(self, event, collection):\n        """"""\n        You should override this method in your derived class\n        """"""\n        return collection\n\n\nclass FilterList(list):\n    """"""\n    Creates a list of Filters for convenient evaluation of a\n    sequence of Filters.\n    """"""\n    @classmethod\n    def merge(cls, list1, list2):\n        if not isinstance(list1, list):\n            raise TypeError(""list1 must be a FilterList or list"")\n        if not isinstance(list2, list):\n            raise TypeError(""list2 must be a FilterList or list"")\n        filterlist = FilterList()\n        for f1, f2 in zip(list1, list2):\n            if isinstance(f1, dict):\n                _f1 = Filter()\n                _f1.__setstate__(f1)\n                f1 = _f1\n            if isinstance(f2, dict):\n                _f2 = Filter()\n                _f2.__setstate__(f2)\n                f2 = _f2\n            filterlist.append(f1 + f2)\n        return filterlist\n\n    @property\n    def total(self):\n        if len(self) > 0:\n            return self[0].total\n        return 0\n\n    @property\n    def passing(self):\n        if len(self) > 0:\n            return self[-1].passing\n        return 0\n\n    def basic(self):\n        """"""\n        Return all filters as simple dicts for pickling.\n        Removes all dependence on this module.\n        """"""\n        return [filter.__getstate__() for filter in self]\n\n    def __setitem__(self, filter):\n        if not isinstance(filter, (Filter, dict)):\n            raise TypeError(\n                ""FilterList can only hold objects ""\n                ""inheriting from Filter or dict"")\n        super(FilterList, self).__setitem__(filter)\n\n    def append(self, filter):\n        if not isinstance(filter, (Filter, dict)):\n            raise TypeError(\n                ""FilterList can only hold objects ""\n                ""inheriting from Filter or dict"")\n        super(FilterList, self).append(filter)\n\n    def __str__(self):\n        return self.__repr__()\n\n    """"""\n    def __repr__(self):\n        if len(self) > 0:\n            table = PrettyTable([""Filter"", ""Pass""])\n            table.align[""Filter""] = ""l""\n            table.align[""Pass""] = ""l""\n            table.add_row([""Total"", self[0].total])\n            for filter in self:\n                table.add_row([filter.name, filter.passing])\n            _str = str(table)\n            # print count_funcs\n            # assume same count_funcs in all filters\n            # TODO: support possibly different/missing/extra count_funcs\n            for func_name in self[0].count_funcs.keys():\n                _str += ""\\n{0} counts\\n"".format(func_name)\n                table = PrettyTable([""Filter"", ""Pass""])\n                table.align[""Filter""] = ""l""\n                table.align[""Pass""] = ""l""\n                table.add_row([""Total"", self[0].count_funcs_total[func_name]])\n                for filter in self:\n                    table.add_row([\n                        filter.name,\n                        filter.count_funcs_passing[func_name]])\n                _str += str(table)\n            for filter in self:\n                if filter.details:\n                    _str += ""\\n{0} Details\\n"".format(filter.name)\n                    details_table = PrettyTable([""Detail"", ""Value""])\n                    for key, value in filter.details.items():\n                        details_table.add_row([key, value])\n                    _str += str(details_table)\n            return _str\n        return ""Empty FilterList""\n    """"""\n\nclass EventFilterList(FilterList):\n\n    def __call__(self, event):\n        for filter in self:\n            if not filter(event):\n                return False\n        return True\n\n    def __setitem__(self, filter):\n        if not isinstance(filter, EventFilter):\n            raise TypeError(\n                ""EventFilterList can only hold objects ""\n                ""inheriting from EventFilter"")\n        super(EventFilterList, self).__setitem__(filter)\n\n    def append(self, filter):\n        if not isinstance(filter, EventFilter):\n            raise TypeError(\n                ""EventFilterList can only hold objects ""\n                ""inheriting from EventFilter"")\n        super(EventFilterList, self).append(filter)\n\n    def finalize(self):\n        for filter in self:\n            filter.finalize()\n\n\nclass ObjectFilterList(FilterList):\n\n    def __call__(self, event, collection):\n        passing_objects = collection\n        for filter in self:\n            passing_objects = filter(event, passing_objects)\n            if not passing_objects:\n                return []\n        return passing_objects\n\n    def __setitem__(self, filter):\n        if not isinstance(filter, ObjectFilter):\n            raise TypeError(\n                ""ObjectFilterList can only hold objects ""\n                ""inheriting from ObjectFilter"")\n        super(ObjectFilterList, self).__setitem__(filter)\n\n    def append(self, filter):\n        if not isinstance(filter, ObjectFilter):\n            raise TypeError(\n                ""ObjectFilterList can only hold objects ""\n                ""inheriting from ObjectFilter"")\n        super(ObjectFilterList, self).append(filter)\n'"
rootpy/tree/texttree.py,0,"b'# Adds Text-based access to trees\n\nfrom .cut import Cut\n\nclass TextBranch(str):\n    def __lt__(self, other):\n        return Cut(\'({0}<({1}))\'.format(self, other))\n    def __gt__(self, other):\n        return Cut(\'({0}>({1}))\'.format(self, other))\n    def __le__(self, other):\n        return Cut(\'({0}<=({1}))\'.format(self, other))\n    def __ge__(self, other):\n        return Cut(\'({0}>=({1}))\'.format(self, other))\n    def __eq__(self, other):\n        return Cut(\'({0}==({1}))\'.format(self, other))\n    def __neq__(self, other):\n        return Cut(\'({0}!=({1}))\'.format(self, other))\n    def __sub__(self, other):\n        return self.__class__(\'({0}-{1})\'.format(self, other))\n    def __rsub__(self, other):\n        return self.__class__(\'({1}-{0})\'.format(self, other))\n    def __add__(self, other):\n        return self.__class__(\'({0}+{1})\'.format(self, other))\n    def __radd__(self, other):\n        return self.__class__(\'({1}+{0})\'.format(self, other))\n    def __mul__(self, other):\n        return self.__class__(\'({0}*{1})\'.format(self, other))\n    def __rmul__(self, other):\n        return self.__class__(\'({1}*{0})\'.format(self, other))\n    def __div__(self, other):\n        return self.__class__(\'({0}/{1})\'.format(self, other))\n    def __rdiv__(self, other):\n        return self.__class__(\'({1}/{0})\'.format(self, other))\n    def __truediv__(self, other):\n        return self.__class__(\'({0}/{1})\'.format(self, other))\n    def __rtruediv__(self, other):\n        return self.__class__(\'({1}/{0})\'.format(self, other))\n    def __abs__(self):\n        return self.__class__(\'abs({0})\'.format(self))\n    def __rshift__(self, tup):\n        if len(tup) == 3:\n            return \'{0}>>({1[0]},{1[1]},{1[2]})\'.format(self,tup)\n        elif len(tup) == 4:\n            return \'{0}>>{1[0]}({1[1]},{1[2]},{1[3]})\'.format(self,tup)\n        else:\n            raise RuntimeError(""Must shift a len 3 or 4 tuple"")\n\n\nclass TextTree(object):\n    def __init__(self, tree):\n        self._tree = tree\n        self._branch_names = [b.GetName() for b in tree.GetListOfBranches()]\n        for name in self._branch_names:\n            setattr(self, name, TextBranch(name))\n    def __iter__(self):\n        return iter(self._branch_names)\n'"
rootpy/tree/tree.py,0,"b'from __future__ import absolute_import, print_function\n\nimport sys\nimport re\nimport fnmatch\n\ntry:\n    from collections import OrderedDict\nexcept ImportError: # py 2.6\n    from ..extern.ordereddict import OrderedDict\n\nfrom .. import log; log = log[__name__]\nfrom .. import asrootpy, QROOT, ROOT\nfrom .. import stl\nfrom ..extern.shortuuid import uuid\nfrom ..extern.six.moves import range\nfrom ..extern.six import string_types\nfrom ..context import set_directory, thread_specific_tmprootdir, do_nothing\nfrom ..base import NamedObject\nfrom ..decorators import snake_case_methods, method_file_check, method_file_cd\nfrom ..plotting.base import Plottable\nfrom ..plotting import Hist, Canvas\nfrom ..memory.keepalive import keepalive\nfrom .cut import Cut\nfrom .treebuffer import TreeBuffer\nfrom .treemodel import TreeModel\nfrom .treetypes import Scalar, Array, BaseChar\nfrom .texttree import TextTree, TextBranch\n\n\n__all__ = [\n    \'Tree\',\n    \'Ntuple\',\n]\n\n\nclass UserData(object):\n    pass\n\n\nclass BaseTree(NamedObject):\n\n    DRAW_PATTERN = re.compile(\n        \'^(?P<branches>.+?)\'\n        \'(?P<redirect>\\>\\>[\\+]?\'\n        \'(?P<name>[^\\(]+)\'\n        \'(?P<binning>.+)?)?$\')\n\n    def _post_init(self):\n        """"""\n        The standard rootpy _post_init method that is used to initialize both\n        new Trees and Trees retrieved from a File.\n        """"""\n        if not hasattr(self, \'_buffer\'):\n            # only set _buffer if model was not specified in the __init__\n            self._buffer = TreeBuffer()\n        self.read_branches_on_demand = False\n        self._branch_cache = {}\n        self._current_entry = 0\n        self._always_read = []\n        self.userdata = UserData()\n        self._inited = True\n\n    def always_read(self, branches):\n        """"""\n        Always read these branches, even when in caching mode. Maybe you have\n        caching enabled and there are branches you want to be updated for each\n        entry even though you never access them directly. This is useful if you\n        are iterating over an input tree and writing to an output tree sharing\n        the same TreeBuffer and you want a direct copy of certain branches. If\n        you have caching enabled but these branches are not specified here and\n        never accessed then they will never be read from disk, so the values of\n        branches in memory will remain unchanged.\n\n        Parameters\n        ----------\n        branches : list, tuple\n            these branches will always be read from disk for every GetEntry\n        """"""\n        if type(branches) not in (list, tuple):\n            raise TypeError(""branches must be a list or tuple"")\n        self._always_read = branches\n\n    @classmethod\n    def branch_type(cls, branch):\n        """"""\n        Return the string representation for the type of a branch\n        """"""\n        typename = branch.GetClassName()\n        if not typename:\n            leaf = branch.GetListOfLeaves()[0]\n            typename = leaf.GetTypeName()\n            # check if leaf has multiple elements\n            leaf_count = leaf.GetLeafCount()\n            if leaf_count:\n                length = leaf_count.GetMaximum()\n            else:\n                length = leaf.GetLen()\n            if length > 1:\n                typename = \'{0}[{1:d}]\'.format(typename, length)\n        return typename\n\n    @classmethod\n    def branch_is_supported(cls, branch):\n        """"""\n        Currently the branch must only have one leaf but the leaf may have one\n        or multiple elements\n        """"""\n        return branch.GetNleaves() == 1\n\n    def create_buffer(self, ignore_unsupported=False):\n        """"""\n        Create this tree\'s TreeBuffer\n        """"""\n        bufferdict = OrderedDict()\n        for branch in self.iterbranches():\n            # only include activated branches\n            if not self.GetBranchStatus(branch.GetName()):\n                continue\n            if not BaseTree.branch_is_supported(branch):\n                log.warning(\n                    ""ignore unsupported branch `{0}`"".format(branch.GetName()))\n                continue\n            bufferdict[branch.GetName()] = Tree.branch_type(branch)\n        self.set_buffer(TreeBuffer(\n            bufferdict,\n            ignore_unsupported=ignore_unsupported))\n\n    def create_branches(self, branches):\n        """"""\n        Create branches from a TreeBuffer or dict mapping names to type names\n\n        Parameters\n        ----------\n        branches : TreeBuffer or dict\n        """"""\n        if not isinstance(branches, TreeBuffer):\n            branches = TreeBuffer(branches)\n        self.set_buffer(branches, create_branches=True)\n\n    def update_buffer(self, treebuffer, transfer_objects=False):\n        """"""\n        Merge items from a TreeBuffer into this Tree\'s TreeBuffer\n\n        Parameters\n        ----------\n        buffer : rootpy.tree.buffer.TreeBuffer\n            The TreeBuffer to merge into this Tree\'s buffer\n\n        transfer_objects : bool, optional (default=False)\n            If True then all objects and collections on the input buffer will\n            be transferred to this Tree\'s buffer.\n        """"""\n        self._buffer.update(treebuffer)\n        if transfer_objects:\n            self._buffer.set_objects(treebuffer)\n\n    def set_buffer(self, treebuffer,\n                   branches=None,\n                   ignore_branches=None,\n                   create_branches=False,\n                   visible=True,\n                   ignore_missing=False,\n                   ignore_duplicates=False,\n                   transfer_objects=False):\n        """"""\n        Set the Tree buffer\n\n        Parameters\n        ----------\n        treebuffer : rootpy.tree.buffer.TreeBuffer\n            a TreeBuffer\n\n        branches : list, optional (default=None)\n            only include these branches from the TreeBuffer\n\n        ignore_branches : list, optional (default=None)\n            ignore these branches from the TreeBuffer\n\n        create_branches : bool, optional (default=False)\n            If True then the branches in the TreeBuffer should be created.\n            Use this option if initializing the Tree. A ValueError is raised\n            if an attempt is made to create a branch with the same name as one\n            that already exists in the Tree. If False the addresses of existing\n            branches will be set to point at the addresses in this buffer.\n\n        visible : bool, optional (default=True)\n            If True then the branches will be added to the buffer and will be\n            accessible as attributes of the Tree.\n\n        ignore_missing : bool, optional (default=False)\n            If True then any branches in this buffer that do not exist in the\n            Tree will be ignored, otherwise a ValueError will be raised. This\n            option is only valid when ``create_branches`` is False.\n\n        ignore_duplicates : bool, optional (default=False)\n            If False then raise a ValueError if the tree already has a branch\n            with the same name as an entry in the buffer. If True then skip\n            branches that already exist. This option is only valid when\n            ``create_branches`` is True.\n\n        transfer_objects : bool, optional (default=False)\n            If True, all tree objects and collections will be transferred from\n            the buffer into this Tree\'s buffer.\n        """"""\n        # determine branches to keep while preserving branch order\n        if branches is None:\n            branches = treebuffer.keys()\n        if ignore_branches is not None:\n            branches = [b for b in branches if b not in ignore_branches]\n\n        if create_branches:\n            for name in branches:\n                value = treebuffer[name]\n                if self.has_branch(name):\n                    if ignore_duplicates:\n                        log.warning(\n                            ""Skipping entry in buffer with the same name ""\n                            ""as an existing branch: `{0}`"".format(name))\n                        continue\n                    raise ValueError(\n                        ""Attempting to create two branches ""\n                        ""with the same name: `{0}`"".format(name))\n                if isinstance(value, Scalar):\n                    self.Branch(name, value,\n                        \'{0}/{1}\'.format(\n                            name, value.type))\n                elif isinstance(value, Array):\n                    length = value.length_name or len(value)\n                    self.Branch(name, value,\n                        \'{0}[{2}]/{1}\'.format(\n                            name, value.type, length))\n                else:\n                    self.Branch(name, value)\n        else:\n            for name in branches:\n                value = treebuffer[name]\n                if self.has_branch(name):\n                    self.SetBranchAddress(name, value)\n                elif not ignore_missing:\n                    raise ValueError(\n                        ""Attempting to set address for ""\n                        ""branch `{0}` which does not exist"".format(name))\n                else:\n                    log.warning(\n                        ""Skipping entry in buffer for which no ""\n                        ""corresponding branch in the ""\n                        ""tree exists: `{0}`"".format(name))\n        if visible:\n            newbuffer = TreeBuffer()\n            for branch in branches:\n                if branch in treebuffer:\n                    newbuffer[branch] = treebuffer[branch]\n            newbuffer.set_objects(treebuffer)\n            self.update_buffer(newbuffer, transfer_objects=transfer_objects)\n\n    def activate(self, branches, exclusive=False):\n        """"""\n        Activate branches\n\n        Parameters\n        ----------\n        branches : str or list\n            branch or list of branches to activate\n\n        exclusive : bool, optional (default=False)\n            if True deactivate the remaining branches\n        """"""\n        if exclusive:\n            self.SetBranchStatus(\'*\', 0)\n        if isinstance(branches, string_types):\n            branches = [branches]\n        for branch in branches:\n            if \'*\' in branch:\n                matched_branches = self.glob(branch)\n                for b in matched_branches:\n                    self.SetBranchStatus(b, 1)\n            elif self.has_branch(branch):\n                self.SetBranchStatus(branch, 1)\n\n    def deactivate(self, branches, exclusive=False):\n        """"""\n        Deactivate branches\n\n        Parameters\n        ----------\n        branches : str or list\n            branch or list of branches to deactivate\n\n        exclusive : bool, optional (default=False)\n            if True activate the remaining branches\n        """"""\n        if exclusive:\n            self.SetBranchStatus(\'*\', 1)\n        if isinstance(branches, string_types):\n            branches = [branches]\n        for branch in branches:\n            if \'*\' in branch:\n                matched_branches = self.glob(branch)\n                for b in matched_branches:\n                    self.SetBranchStatus(b, 0)\n            elif self.has_branch(branch):\n                self.SetBranchStatus(branch, 0)\n\n    @property\n    def branches(self):\n        """"""\n        List of the branches\n        """"""\n        return [branch for branch in self.GetListOfBranches()]\n\n    def iterbranches(self):\n        """"""\n        Iterator over the branches\n        """"""\n        for branch in self.GetListOfBranches():\n            yield branch\n\n    @property\n    def b(self):\n        return TextTree(self)\n\n    @property\n    def branchnames(self):\n        """"""\n        List of branch names\n        """"""\n        return [branch.GetName() for branch in self.GetListOfBranches()]\n\n    def iterbranchnames(self):\n        """"""\n        Iterator over the branch names\n        """"""\n        for branch in self.iterbranches():\n            yield branch.GetName()\n\n    def glob(self, patterns, exclude=None):\n        """"""\n        Return a list of branch names that match ``pattern``.\n        Exclude all matched branch names which also match a pattern in\n        ``exclude``. ``exclude`` may be a string or list of strings.\n\n        Parameters\n        ----------\n        patterns: str or list\n            branches are matched against this pattern or list of patterns where\n            globbing is performed with \'*\'.\n\n        exclude : str or list, optional (default=None)\n            branches matching this pattern or list of patterns are excluded\n            even if they match a pattern in ``patterns``.\n\n        Returns\n        -------\n        matches : list\n            List of matching branch names\n        """"""\n        if isinstance(patterns, string_types):\n            patterns = [patterns]\n        if isinstance(exclude, string_types):\n            exclude = [exclude]\n        matches = []\n        for pattern in patterns:\n            matches += fnmatch.filter(self.iterbranchnames(), pattern)\n            if exclude is not None:\n                for exclude_pattern in exclude:\n                    matches = [match for match in matches\n                               if not fnmatch.fnmatch(match, exclude_pattern)]\n        return matches\n\n    def __getitem__(self, item):\n        """"""\n        Get an entry in the tree or a branch\n\n        Parameters\n        ----------\n        item : str or int\n            if item is a str then return the value of the branch with that name\n            if item is an int then call GetEntry\n        """"""\n        if isinstance(item, string_types):\n            return self._buffer[item]\n        self.GetEntry(item)\n        return self\n\n    def GetEntry(self, entry):\n        """"""\n        Get an entry. Tree collections are reset\n        (see ``rootpy.tree.treeobject``)\n\n        Parameters\n        ----------\n        entry : int\n            entry index\n\n        Returns\n        -------\n        ROOT.TTree.GetEntry : int\n            The number of bytes read\n        """"""\n        if not (0 <= entry < self.GetEntries()):\n            raise IndexError(""entry index out of range: {0:d}"".format(entry))\n        self._buffer.reset_collections()\n        return super(BaseTree, self).GetEntry(entry)\n\n    def __iter__(self):\n        """"""\n        Iterator over the entries in the Tree.\n        """"""\n        if not self._buffer:\n            self.create_buffer()\n        if self.read_branches_on_demand:\n            self._buffer.set_tree(self)\n            # drop all branches from the cache\n            self.DropBranchFromCache(\'*\')\n            for attr in self._always_read:\n                try:\n                    branch = self._branch_cache[attr]\n                except KeyError:  # one-time hit\n                    branch = self.GetBranch(attr)\n                    if not branch:\n                        raise AttributeError(\n                            ""branch `{0}` specified in ""\n                            ""`always_read` does not exist"".format(attr))\n                    self._branch_cache[attr] = branch\n                # add branches that we should always read to cache\n                self.AddBranchToCache(branch)\n\n            for i in range(self.GetEntries()):\n                # Only increment current entry.\n                # getattr on a branch will then GetEntry on only that branch\n                # see ``TreeBuffer.get_with_read_if_cached``.\n                self._current_entry = i\n                self.LoadTree(i)\n                for attr in self._always_read:\n                    # Always read branched in ``self._always_read`` since\n                    # these branches may never be getattr\'d but the TreeBuffer\n                    # should always be updated to reflect their current values.\n                    # This is useful if you are iterating over an input tree\n                    # and writing to an output tree that shares the same\n                    # TreeBuffer but you don\'t getattr on all branches of the\n                    # input tree in the logic that determines which entries\n                    # to keep.\n                    self._branch_cache[attr].GetEntry(i)\n                self._buffer._entry.set(i)\n                yield self._buffer\n                self._buffer.next_entry()\n                self._buffer.reset_collections()\n        else:\n            for i in range(self.GetEntries()):\n                # Read all activated branches (can be slow!).\n                super(BaseTree, self).GetEntry(i)\n                self._buffer._entry.set(i)\n                yield self._buffer\n                self._buffer.reset_collections()\n\n    def __setattr__(self, attr, value):\n        if \'_inited\' not in self.__dict__ or attr in self.__dict__:\n            return super(BaseTree, self).__setattr__(attr, value)\n        try:\n            return self._buffer.__setattr__(attr, value)\n        except AttributeError:\n            raise AttributeError(\n                ""`{0}` instance has no attribute `{1}`"".format(\n                    self.__class__.__name__, attr))\n\n    def __getattr__(self, attr):\n        if \'_inited\' not in self.__dict__:\n            raise AttributeError(\n                ""`{0}` instance has no attribute `{1}`"".format(\n                    self.__class__.__name__, attr))\n        try:\n            return getattr(self._buffer, attr)\n        except AttributeError:\n            raise AttributeError(\n                ""`{0}` instance has no attribute `{1}`"".format(\n                    self.__class__.__name__, attr))\n\n    def __setitem__(self, item, value):\n        self._buffer[item] = value\n\n    def __len__(self):\n        """"""\n        Same as GetEntries\n        """"""\n        return self.GetEntries()\n\n    def __contains__(self, branch):\n        """"""\n        Same as has_branch\n        """"""\n        return self.has_branch(branch)\n\n    def has_branch(self, branch):\n        """"""\n        Determine if this Tree contains a branch with the name ``branch``\n\n        Parameters\n        ----------\n        branch : str\n            branch name\n\n        Returns\n        -------\n        has_branch : bool\n            True if this Tree contains a branch with the name ``branch`` or\n            False otherwise.\n        """"""\n        return not not self.GetBranch(branch)\n\n    def csv(self, sep=\',\', branches=None,\n            include_labels=True, limit=None,\n            stream=None):\n        """"""\n        Print csv representation of tree only including branches\n        of basic types (no objects, vectors, etc..)\n\n        Parameters\n        ----------\n        sep : str, optional (default=\',\')\n            The delimiter used to separate columns\n\n        branches : list, optional (default=None)\n            Only include these branches in the CSV output. If None, then all\n            basic types will be included.\n\n        include_labels : bool, optional (default=True)\n            Include a first row of branch names labelling each column.\n\n        limit : int, optional (default=None)\n            Only include up to a maximum of ``limit`` rows in the CSV.\n\n        stream : file, (default=None)\n            Stream to write the CSV output on. By default the CSV will be\n            written to ``sys.stdout``.\n        """"""\n        supported_types = (Scalar, Array, stl.string)\n        if stream is None:\n            stream = sys.stdout\n        if not self._buffer:\n            self.create_buffer(ignore_unsupported=True)\n        if branches is None:\n            branchdict = OrderedDict([\n                (name, self._buffer[name])\n                for name in self.iterbranchnames()\n                if isinstance(self._buffer[name], supported_types)])\n        else:\n            branchdict = OrderedDict()\n            for name in branches:\n                if not isinstance(self._buffer[name], supported_types):\n                    raise TypeError(\n                        ""selected branch `{0}` ""\n                        ""is not a scalar or array type"".format(name))\n                branchdict[name] = self._buffer[name]\n        if not branchdict:\n            raise RuntimeError(\n                ""no branches selected or no ""\n                ""branches of scalar or array types exist"")\n        if include_labels:\n            # expand array types to f[0],f[1],f[2],...\n            print(sep.join(\n                name if isinstance(value, (Scalar, BaseChar, stl.string))\n                    else sep.join(\'{0}[{1:d}]\'.format(name, idx)\n                                  for idx in range(len(value)))\n                        for name, value in branchdict.items()),\n                file=stream)\n        # even though \'entry\' is not used, enumerate or simply iterating over\n        # self is required to update the buffer with the new branch values at\n        # each tree entry.\n        for i, entry in enumerate(self):\n            line = []\n            for value in branchdict.values():\n                if isinstance(value, (Scalar, BaseChar)):\n                    token = str(value.value)\n                elif isinstance(value, stl.string):\n                    token = str(value)\n                else:\n                    token = sep.join(map(str, value))\n                line.append(token)\n            print(sep.join(line), file=stream)\n            if limit is not None and i + 1 == limit:\n                break\n\n    def Scale(self, value):\n        """"""\n        Scale the weight of the Tree by ``value``\n\n        Parameters\n        ----------\n        value : int, float\n            Scale the Tree weight by this value\n        """"""\n        self.SetWeight(self.GetWeight() * value)\n\n    def GetEntries(self, cut=None, weighted_cut=None, weighted=False):\n        """"""\n        Get the number of (weighted) entries in the Tree\n\n        Parameters\n        ----------\n        cut : str or rootpy.tree.cut.Cut, optional (default=None)\n            Only entries passing this cut will be included in the count\n\n        weighted_cut : str or rootpy.tree.cut.Cut, optional (default=None)\n            Apply a weighted selection and determine the weighted number of\n            entries.\n\n        weighted : bool, optional (default=False)\n            Multiply the number of (weighted) entries by the Tree weight.\n        """"""\n        if weighted_cut:\n            hist = Hist(1, -1, 2)\n            branch = self.GetListOfBranches()[0].GetName()\n            weight = self.GetWeight()\n            self.SetWeight(1)\n            self.Draw(\'{0}=={1}>>{2}\'.format(branch, branch, hist.GetName()),\n                      weighted_cut * cut)\n            self.SetWeight(weight)\n            entries = hist.Integral()\n        elif cut:\n            entries = super(BaseTree, self).GetEntries(str(cut))\n        else:\n            entries = super(BaseTree, self).GetEntries()\n        if weighted:\n            entries *= self.GetWeight()\n        return entries\n\n    def GetMaximum(self, expression, cut=None):\n        """"""\n        TODO: we need a better way of determining the maximum value of an\n        expression.\n        """"""\n        if cut:\n            self.Draw(expression, cut, \'goff\')\n        else:\n            self.Draw(expression, \'\', \'goff\')\n        vals = self.GetV1()\n        n = self.GetSelectedRows()\n        vals = [vals[i] for i in range(min(n, 10000))]\n        return max(vals)\n\n    def GetMinimum(self, expression, cut=None):\n        """"""\n        TODO: we need a better way of determining the minimum value of an\n        expression.\n        """"""\n        if cut:\n            self.Draw(expression, cut, ""goff"")\n        else:\n            self.Draw(expression, """", ""goff"")\n        vals = self.GetV1()\n        n = self.GetSelectedRows()\n        vals = [vals[i] for i in range(min(n, 10000))]\n        return min(vals)\n\n    def CopyTree(self, selection, *args, **kwargs):\n        """"""\n        Copy the tree while supporting a rootpy.tree.cut.Cut selection in\n        addition to a simple string.\n        """"""\n        return super(BaseTree, self).CopyTree(str(selection), *args, **kwargs)\n\n    def reset_branch_values(self):\n        """"""\n        Reset all values in the buffer to their default values\n        """"""\n        self._buffer.reset()\n\n    @method_file_cd\n    def Write(self, *args, **kwargs):\n        super(BaseTree, self).Write(*args, **kwargs)\n\n    def Draw(self,\n             expression,\n             selection="""",\n             options="""",\n             hist=None,\n             create_hist=False,\n             **kwargs):\n        """"""\n        Draw a TTree with a selection as usual, but return the created\n        histogram.\n\n        Parameters\n        ----------\n        expression : str\n            The expression to draw. Multidimensional expressions are separated\n            by "":"". rootpy reverses the expressions along each dimension so the\n            order matches the order of the elements identifying a location in\n            the resulting histogram. By default ROOT takes the expression ""Y:X""\n            to mean Y versus X but we argue that this is counterintuitive and\n            that the order should be ""X:Y"" so that the expression along the\n            first dimension identifies the location along the first axis, etc.\n\n        selection : str or rootpy.tree.Cut, optional (default="""")\n            The cut expression. Only entries satisfying this selection are\n            included in the filled histogram.\n\n        options : str, optional (default="""")\n            Draw options passed to ROOT.TTree.Draw\n\n        hist : ROOT.TH1, optional (default=None)\n            The histogram to be filled. If not specified, rootpy will attempt\n            to find what ROOT created and return that.\n\n        create_hist : bool (default=False)\n            If True and `hist`` is not specified and a histogram name is not\n            specified in the draw expression, then override ROOT\'s\n            default behaviour and fill a new histogram. ROOT will otherwise add\n            points to a TGraph or TPolyMarker3D if not drawing in more than\n            two dimensions.\n\n        kwargs : dict, optional\n            Remaining keword arguments are used to set the style attributes of\n            the histogram.\n\n        Returns\n        -------\n        If ``hist`` is specified, None is returned. If ``hist`` is left\n        unspecified, an attempt is made to retrieve the generated histogram\n        which is then returned.\n\n        """"""\n        if isinstance(expression, string_types):\n            # Check that we have a valid draw expression\n            exprmatch = re.match(BaseTree.DRAW_PATTERN, expression)\n            if not exprmatch:\n                raise ValueError(\n                    ""not a valid draw expression: `{0}`"".format(expression))\n            exprdict = exprmatch.groupdict()\n\n            # Reverse variable order to match order in hist constructor\n            fields = re.split(\'(?<!:):(?!:)\', exprdict[\'branches\'])\n            num_dimensions = len(fields)\n            expression = \':\'.join(fields[:3][::-1] + fields[3:])\n            if exprdict[\'redirect\'] is not None:\n                expression += exprdict[\'redirect\']\n\n        else:  # expression is list, tuple, ...\n            fields = expression\n            num_dimensions = len(fields)\n            expression = \':\'.join(fields[:3][::-1] + fields[3:])\n            exprdict = {\n                \'branches\': None,\n                \'redirect\': None,\n                \'name\': None,\n                \'binning\': None,\n                }\n\n        if not isinstance(selection, Cut):\n            # Let Cut handle any extra processing (i.e. ternary operators)\n            selection = Cut(selection)\n\n        graphics = \'goff\' not in options\n\n        if hist is not None:\n            if not isinstance(hist, ROOT.TH1):\n                raise TypeError(""Cannot draw into a `{0}`"".format(type(hist)))\n\n            # Check that the dimensionality of the expression and object match\n            if num_dimensions != hist.GetDimension():\n                raise TypeError(\n                    ""The dimensionality of the expression `{0}` ({1:d}) ""\n                    ""does not match the dimensionality of a `{2}`"".format(\n                        expression, num_dimensions, hist.__class__.__name__))\n            # Handle graphics ourselves\n            if graphics:\n                if options:\n                    options += \' \'\n                options += \'goff\'\n            if exprdict[\'name\'] is None:\n                # Draw into histogram supplied by user\n                expression = \'{0}>>+{1}\'.format(expression, hist.GetName())\n            else:\n                if exprdict[\'name\'] != hist.GetName():\n                    # If the user specified a name to draw into then check that\n                    # this is consistent with the specified object.\n                    raise ValueError(\n                        ""The name specified in the draw ""\n                        ""expression `{0}` does not match the ""\n                        ""name of the specified object `{1}`"".format(\n                            exprdict[\'name\'],\n                            hist.GetName()))\n                # Check that binning is not specified\n                if exprdict[\'binning\'] is not None:\n                    raise ValueError(\n                        ""When specifying the object to draw into, do not ""\n                        ""specify a binning in the draw expression"")\n        else:\n            if create_hist and exprdict[\'name\'] is None:\n                if num_dimensions > 4:\n                    raise ValueError(\n                        ""Cannot create a histogram for expressions with ""\n                        ""more than 4 dimensions"")\n                newname = \'{0}_{1}\'.format(self.__class__.__name__, uuid())\n                expression += \'>>{0}\'.format(newname)\n                exprdict[\'name\'] = newname\n\n            pad = ROOT.gPad\n            own_pad = False\n\n            if graphics and not pad:\n                # Create a new canvas if one doesn\'t exist yet\n                own_pad = True\n                pad = Canvas()\n\n        #  Note: TTree.Draw() pollutes gDirectory, make a temporary one\n        with thread_specific_tmprootdir():\n            if hist is not None:\n                # If a custom histogram is specified (i.e, it\'s not being\n                # created root side), then temporarily put it into the\n                # temporary thread-specific directory.\n                context = set_directory(hist)\n            else:\n                context = do_nothing()\n            with context:\n                super(BaseTree, self).Draw(expression, selection, options)\n\n        if hist is None:\n            # Retrieve histogram made by TTree.Draw\n            if num_dimensions == 1 or exprdict[\'name\'] is not None:\n                # a TH1\n                hist = asrootpy(self.GetHistogram(), warn=False)\n            elif num_dimensions == 2:\n                # a TGraph\n                hist = asrootpy(pad.GetPrimitive(\'Graph\'), warn=False)\n            else:\n                # ROOT: For a three and four dimensional Draw the TPolyMarker3D\n                # is unnamed, and cannot be retrieved. Why, ROOT?\n                log.warning(\n                    ""Cannot retrieve the TPolyMarker3D for ""\n                    ""3D and 4D expressions"")\n                if graphics and own_pad:\n                    # Since we cannot access the TPolyMarker3D we use self to\n                    # keep the canvas alive\n                    keepalive(self, pad)\n            if hist: # is not None\n                if isinstance(hist, Plottable):\n                    hist.decorate(**kwargs)\n                # ROOT, don\'t try to delete this object! (See issue #277)\n                hist.SetBit(ROOT.kCanDelete, False)\n                if graphics:\n                    if own_pad:\n                        # The usual bug is that the histogram is garbage\n                        # collected and we want the canvas to keep the\n                        # histogram alive, but here the canvas has been\n                        # created locally and we are returning the histogram,\n                        # so we want the histogram to keep the canvas alive.\n                        keepalive(hist, pad)\n                    # Redraw the histogram since we may have specified style\n                    # attributes in **kwargs\n                    hist.Draw()\n            if graphics:\n                pad.Modified()\n                pad.Update()\n        return hist\n\n    def to_array(self, *args, **kwargs):\n        """"""\n        Convert this tree into a NumPy structured array\n        """"""\n        from root_numpy import tree2array\n        return tree2array(self, *args, **kwargs)\n\n\n@snake_case_methods\nclass Tree(BaseTree, QROOT.TTree):\n    """"""\n    Inherits from TTree so all regular TTree methods are available\n    but certain methods (i.e. Draw) have been overridden\n    to improve usage in Python.\n\n    Parameters\n    ----------\n    name : str, optional (default=None)\n        The Tree name (a UUID if None)\n\n    title : str, optional (default=None)\n        The Tree title (empty string if None)\n\n    model : TreeModel, optional (default=None)\n        If specified then this TreeModel will be used to create the branches\n    """"""\n    _ROOT = QROOT.TTree\n\n    @method_file_check\n    def __init__(self, name=None, title=None, model=None):\n        super(Tree, self).__init__(name=name, title=title)\n        self._buffer = TreeBuffer()\n        if model is not None:\n            if not issubclass(model, TreeModel):\n                raise TypeError(""the model must subclass TreeModel"")\n            self.set_buffer(model(), create_branches=True)\n        self._post_init()\n\n    def Fill(self, reset=False):\n        """"""\n        Fill the Tree with the current values in the buffer\n\n        Parameters\n        ----------\n        reset : bool, optional (default=False)\n            Reset the values in the buffer to their default values after\n            filling.\n        """"""\n        super(Tree, self).Fill()\n        # reset all branches\n        if reset:\n            self._buffer.reset()\n\n\n@snake_case_methods\nclass Ntuple(BaseTree, QROOT.TNtuple):\n    """"""\n    Inherits from TNtuple so all regular TNtuple/TTree methods are available\n    but certain methods (i.e. Draw) have been overridden\n    to improve usage in Python.\n\n    Parameters\n    ----------\n    varlist : list of str\n        A list of the field names\n\n    name : str, optional (default=None)\n        The Ntuple name (a UUID if None)\n\n    title : str, optional (default=None)\n        The Ntuple title (empty string if None)\n\n    bufsize : int, optional (default=32000)\n        Basket buffer size\n    """"""\n    _ROOT = QROOT.TNtuple\n\n    @method_file_check\n    def __init__(self, varlist, name=None, title=None, bufsize=32000):\n        super(Ntuple, self).__init__(\':\'.join(varlist), bufsize,\n                                     name=name,\n                                     title=title)\n        self._post_init()\n'"
rootpy/tree/treebuffer.py,0,"b'from __future__ import absolute_import\n\nimport sys\nimport re\nimport inspect\n\nimport ROOT\n\ntry:\n    from collections import OrderedDict\nexcept ImportError: # py 2.6\n    from ..extern.ordereddict import OrderedDict\n\nfrom . import log\nfrom .. import lookup_by_name, create, stl\nfrom ..base import Object\nfrom ..extern.six import string_types\nfrom .treetypes import Column, Scalar, Array, Int, Char, UChar, BaseCharArray\nfrom .treeobject import TreeCollection, TreeObject, mix_classes\n\n\n__all__ = [\n    \'TreeBuffer\',\n]\n\n\nclass TreeBuffer(OrderedDict):\n    """"""\n    A dictionary mapping branch names to values\n    """"""\n    ARRAY_PATTERN = re.compile(\'^(?P<type>[^\\[]+)\\[(?P<length>\\d+)\\]$\')\n\n    def __init__(self,\n                 branches=None,\n                 tree=None,\n                 ignore_unsupported=False):\n        super(TreeBuffer, self).__init__()\n        self._fixed_names = {}\n        self._branch_cache = {}\n        self._branch_cache_event = {}\n        self._tree = tree\n        self._ignore_unsupported = ignore_unsupported\n        self._current_entry = 0\n        self._collections = {}\n        self._objects = []\n        self._entry = Int(0)\n        self.__process(branches)\n        self._inited = True\n\n    @classmethod\n    def __clean(cls, branchname):\n        # Replace invalid characters with \'_\'\n        branchname = re.sub(\'[^0-9a-zA-Z_]\', \'_\', branchname)\n        # Remove leading characters until we find a letter or underscore\n        return re.sub(\'^[^a-zA-Z_]+\', \'\', branchname)\n\n    def __process(self, branches):\n        if not branches:\n            return\n        if not isinstance(branches, dict):\n            try:\n                branches = dict(branches)\n            except TypeError:\n                raise TypeError(\n                    ""branches must be a dict or anything ""\n                    ""the dict constructor accepts"")\n        processed = []\n        for name, vtype in branches.items():\n            if name in processed:\n                raise ValueError(\n                    ""duplicate branch name `{0}`"".format(name))\n            processed.append(name)\n            obj = None\n            if isinstance(vtype, string_types):\n                array_match = re.match(TreeBuffer.ARRAY_PATTERN, vtype)\n                if array_match:\n                    vtype = array_match.group(\'type\') + \'[]\'\n                    length = int(array_match.group(\'length\'))\n                    # try to lookup type in registry\n                    cls = lookup_by_name(vtype)\n                    if cls is not None:\n                        # special case for [U]Char and [U]CharArray with\n                        # null-termination\n                        if issubclass(cls, BaseCharArray):\n                            if length == 2:\n                                obj = cls.scalar()\n                            elif length == 1:\n                                raise ValueError(\n                                    ""char branch `{0}` is not ""\n                                    ""null-terminated"".format(name))\n                            else:\n                                # leave slot for null-termination\n                                obj = cls(length)\n                        else:\n                            obj = cls(length)\n                else:\n                    # try to lookup type in registry\n                    cls = lookup_by_name(vtype)\n                    if cls is not None:\n                        obj = cls()\n                    else:\n                        # try to create ROOT.\'vtype\'\n                        obj = create(vtype)\n                        if obj is None:\n                            # try to generate this type\n                            cpptype = stl.CPPType.try_parse(vtype)\n                            if cpptype and cpptype.is_template:\n                                obj = cpptype.cls()\n            elif (isinstance(vtype, Column) or\n                    (inspect.isclass(vtype) and\n                        issubclass(vtype, (ROOT.TObject, ROOT.ObjectProxy)))):\n                # vtype is the class itself or a Column so just create it\n                obj = vtype()\n            if obj is None:\n                if not self._ignore_unsupported:\n                    raise TypeError(\n                        ""branch `{0}` has unsupported ""\n                        ""type `{1}`"".format(name, vtype))\n                else:\n                    log.warning(\n                        ""ignoring branch `{0}` with ""\n                        ""unsupported type `{1}`"".format(name, vtype))\n            else:\n                self[name] = obj\n\n    def reset(self):\n        if sys.version_info[0] < 3:\n            iter_values = self.itervalues()\n        else:\n            iter_values = self.values()\n        for value in iter_values:\n            if isinstance(value, (Scalar, Array)):\n                value.reset()\n            elif isinstance(value, Object):\n                value._ROOT.__init__(value)\n            elif isinstance(value, (ROOT.TObject, ROOT.ObjectProxy)):\n                value.__init__()\n            else:\n                # there should be no other types of objects in the buffer\n                raise TypeError(\n                    ""cannot reset object of type `{0}`"".format(type(value)))\n\n    def update(self, branches=None):\n        if isinstance(branches, TreeBuffer):\n            self._entry = branches._entry\n            for name, value in branches.items():\n                super(TreeBuffer, self).__setitem__(name, value)\n            self._fixed_names.update(branches._fixed_names)\n        else:\n            self.__process(branches)\n\n    def set_tree(self, tree=None):\n        self._branch_cache = {}\n        self._branch_cache_event = {}\n        self._tree = tree\n        self._current_entry = 0\n\n    def next_entry(self):\n        super(TreeBuffer, self).__setattr__(\'_branch_cache_event\', {})\n        self._current_entry += 1\n\n    def get_with_read_if_cached(self, attr):\n        if self._tree is not None:\n            try:\n                branch = self._branch_cache[attr]\n            except KeyError:\n                # branch is being accessed for the first time\n                branch = self._tree.GetBranch(attr)\n                if not branch:\n                    raise AttributeError\n                self._branch_cache[attr] = branch\n                self._tree.AddBranchToCache(branch)\n            if branch not in self._branch_cache_event:\n                # branch is being accessed for the first time in this entry\n                branch.GetEntry(self._current_entry)\n                self._branch_cache_event[branch] = None\n        return super(TreeBuffer, self).__getitem__(attr)\n\n    def __setitem__(self, name, value):\n        # for a key to be used as an attr it must be a valid Python identifier\n        fixed_name = TreeBuffer.__clean(name)\n        if fixed_name in dir(self) or fixed_name.startswith(\'_\'):\n            raise ValueError(""illegal branch name: `{0}`"".format(name))\n        if fixed_name != name:\n            self._fixed_names[fixed_name] = name\n        super(TreeBuffer, self).__setitem__(name, value)\n\n    def __getitem__(self, name):\n        return self.get_with_read_if_cached(name)\n\n    def __setattr__(self, attr, value):\n        """"""\n        Maps attributes to values.\n        Only if we are initialized\n        """"""\n        # this test allows attributes to be set in the __init__ method\n        # any normal attributes are handled normally\n        if \'_inited\' not in self.__dict__ or attr in self.__dict__:\n            return super(TreeBuffer, self).__setattr__(attr, value)\n        elif attr in self:\n            variable = self.get_with_read_if_cached(attr)\n            if isinstance(variable, (Scalar, Array)):\n                variable.set(value)\n                return\n            elif isinstance(variable, Object):\n                variable.copy_from(value)\n                return\n            elif isinstance(variable, (ROOT.TObject, ROOT.ObjectProxy)):\n                # copy constructor\n                variable.__init__(value)\n                return\n            raise TypeError(\n                ""cannot set attribute `{0}` of `{1}` instance"".format(\n                    attr, self.__class__.__name__))\n        raise AttributeError(\n            ""`{0}` instance has no attribute `{1}`"".format(\n                self.__class__.__name__, attr))\n\n    def __getattr__(self, attr):\n        if \'_inited\' not in self.__dict__:\n            raise AttributeError(\n                ""`{0}` instance has no attribute `{1}`"".format(\n                    self.__class__.__name__, attr))\n        if attr in self._fixed_names:\n            attr = self._fixed_names[attr]\n        try:\n            variable = self.get_with_read_if_cached(attr)\n            if isinstance(variable, Scalar):\n                return variable.value\n            return variable\n        except (KeyError, AttributeError):\n            raise AttributeError(\n                ""{0} instance has no attribute `{1}`"".format(\n                    self.__class__.__name__, attr))\n\n    def reset_collections(self):\n        if sys.version_info[0] < 3:\n            for coll in self._collections.iterkeys():\n                coll.reset()\n        else:\n            for coll in self._collections.keys():\n                coll.reset()\n\n    def define_collection(self, name, prefix, size, mix=None):\n        coll = TreeCollection(self, name, prefix, size, mix=mix)\n        object.__setattr__(self, name, coll)\n        self._collections[coll] = (name, prefix, size, mix)\n        return coll\n\n    def define_object(self, name, prefix, mix=None):\n        cls = TreeObject\n        if mix is not None:\n            cls = mix_classes(TreeObject, mix)\n        obj = cls(self, name, prefix)\n        object.__setattr__(self, name, obj)\n        self._objects.append((name, prefix, mix))\n        return obj\n\n    def set_objects(self, other):\n        for args in other._objects:\n            self.define_object(*args)\n        if sys.version_info[0] < 3:\n            for args in other._collections.itervalues():\n                self.define_collection(*args)\n        else:\n            for args in other._collections.values():\n                self.define_collection(*args)\n\n    def __str__(self):\n        return self.__repr__()\n\n    def __repr__(self):\n        rep = \'\'\n        for name, value in self.items():\n            rep += \'{0} -> {1}\\n\'.format(name, repr(value))\n        return rep\n'"
rootpy/tree/treemodel.py,0,"b'from __future__ import absolute_import, print_function\n\nimport sys\nimport inspect\nimport types\nif sys.version_info[0] < 3:\n    from cStringIO import StringIO\nelse:\n    from io import StringIO\n\nimport ROOT\n\nfrom .. import log; log = log[__name__]\nfrom .treetypes import Column\nfrom .treebuffer import TreeBuffer\n\n__all__ = [\n    \'TreeModel\',\n]\n\n\nclass TreeModelMeta(type):\n    """"""\n    Metaclass for all TreeModels\n    Addition/subtraction of TreeModels is handled\n    as set union and difference of class attributes\n    """"""\n    def __new__(cls, name, bases, dct):\n        for attr, value in dct.items():\n            TreeModelMeta.checkattr(attr, value)\n        return type.__new__(cls, name, bases, dct)\n\n    def __add__(cls, other):\n        return type(\'_\'.join([cls.__name__, other.__name__]),\n                    (cls, other), {})\n\n    def __iadd__(cls, other):\n        return cls.__add__(other)\n\n    def __sub__(cls, other):\n        attrs = dict(set(cls.get_attrs()).difference(set(other.get_attrs())))\n        return type(\'_\'.join([cls.__name__, other.__name__]),\n                    (TreeModel,), attrs)\n\n    def __isub__(cls, other):\n        return cls.__sub__(other)\n\n    def __setattr__(cls, attr, value):\n        TreeModelMeta.checkattr(attr, value)\n        type.__setattr__(cls, attr, value)\n\n    @classmethod\n    def checkattr(metacls, attr, value):\n        """"""\n        Only allow class attributes that are instances of\n        rootpy.types.Column, ROOT.TObject, or ROOT.ObjectProxy\n        """"""\n        if not isinstance(value, (\n                types.MethodType,\n                types.FunctionType,\n                classmethod,\n                staticmethod,\n                property)):\n            if attr in dir(type(\'dummy\', (object,), {})) + \\\n                    [\'__metaclass__\', \'__qualname__\']:\n                return\n            if attr.startswith(\'_\'):\n                raise SyntaxError(\n                    ""TreeModel attribute `{0}` ""\n                    ""must not start with `_`"".format(attr))\n            if not inspect.isclass(value):\n                if not isinstance(value, Column):\n                    raise TypeError(\n                        ""TreeModel attribute `{0}` ""\n                        ""must be an instance of ""\n                        ""`rootpy.tree.treetypes.Column`"".format(attr))\n                return\n            if not issubclass(value, (ROOT.TObject, ROOT.ObjectProxy)):\n                raise TypeError(\n                    ""TreeModel attribute `{0}` must inherit ""\n                    ""from `ROOT.TObject` or `ROOT.ObjectProxy`"".format(\n                        attr))\n\n    def prefix(cls, name):\n        """"""\n        Create a new TreeModel where class attribute\n        names are prefixed with ``name``\n        """"""\n        attrs = dict([(name + attr, value) for attr, value in cls.get_attrs()])\n        return TreeModelMeta(\n            \'_\'.join([name, cls.__name__]),\n            (TreeModel,), attrs)\n\n    def suffix(cls, name):\n        """"""\n        Create a new TreeModel where class attribute\n        names are suffixed with ``name``\n        """"""\n        attrs = dict([(attr + name, value) for attr, value in cls.get_attrs()])\n        return TreeModelMeta(\n            \'_\'.join([cls.__name__, name]),\n            (TreeModel,), attrs)\n\n    def get_attrs(cls):\n        """"""\n        Get all class attributes ordered by definition\n        """"""\n        ignore = dir(type(\'dummy\', (object,), {})) + [\'__metaclass__\']\n        attrs = [\n            item for item in inspect.getmembers(cls) if item[0] not in ignore\n            and not isinstance(\n                item[1], (\n                    types.FunctionType,\n                    types.MethodType,\n                    classmethod,\n                    staticmethod,\n                    property))]\n        # sort by idx and use attribute name to break ties\n        attrs.sort(key=lambda attr: (getattr(attr[1], \'idx\', -1), attr[0]))\n        return attrs\n\n    def to_struct(cls, name=None):\n        """"""\n        Convert the TreeModel into a compiled C struct\n        """"""\n        if name is None:\n            name = cls.__name__\n        basic_attrs = dict([(attr_name, value)\n                            for attr_name, value in cls.get_attrs()\n                            if isinstance(value, Column)])\n        if not basic_attrs:\n            return None\n        src = \'struct {0} {{\'.format(name)\n        for attr_name, value in basic_attrs.items():\n            src += \'{0} {1};\'.format(value.type.typename, attr_name)\n        src += \'};\'\n        if ROOT.gROOT.ProcessLine(src) != 0:\n            return None\n        return getattr(ROOT, name, None)\n\n    def __repr__(cls):\n        out = StringIO()\n        for name, value in cls.get_attrs():\n            print(\'{0} -> {1}\'.format(name, value), file=out)\n        return out.getvalue()[:-1]\n\n    def __str__(cls):\n        return repr(cls)\n\n\n# TreeModel.__new__\ndef __new__(cls):\n    """"""\n    Return a TreeBuffer for this TreeModel\n    """"""\n    treebuffer = TreeBuffer()\n    for name, attr in cls.get_attrs():\n        treebuffer[name] = attr()\n    return treebuffer\n\n\n# metaclass syntax compatible with both Python 2 and Python 3\nTreeModel = TreeModelMeta(\'TreeModel\', (object,), {\'__new__\': __new__})\n'"
rootpy/tree/treeobject.py,0,"b'from __future__ import absolute_import\n\nfrom copy import deepcopy\n\nfrom ..extern.six.moves import range\n\n__all__ = [\n    \'TreeObject\',\n    \'TreeCollectionObject\',\n    \'TreeCollection\',\n]\n\n__MIXINS__ = {}\n\n\ndef mix_classes(cls, mixins):\n    if not isinstance(mixins, tuple):\n        mixins = (mixins,)\n    classes = (cls,) + mixins\n    cls_names = [cls.__name__] + [m.__name__ for m in mixins]\n    mixed_name = \'_\'.join(cls_names)\n    inheritance = \', \'.join(cls_names)\n    inits = \'{cls.__name__}.__init__(self, *args, **kwargs)\\n\'.format(cls=cls)\n    inits += \'\\n\'.join([\'        {0}.__init__(self)\'.format(m.__name__)\n                        for m in mixins])\n    cls_def = \'\'\'class {mixed_name}({inheritance}):\n    def __init__(self, *args, **kwargs):\n        {inits}\'\'\'.format(\n            mixed_name=mixed_name,\n            inheritance=inheritance,\n            inits=inits)\n    namespace = dict([(c.__name__, c) for c in classes])\n    exec(cls_def, namespace)\n    return namespace[mixed_name]\n\n\nclass TreeObject(object):\n\n    def __init__(self, tree, name, prefix):\n        self.tree = tree\n        self.name = name\n        self.prefix = prefix\n        self._inited = True\n\n    def __eq__(self, other):\n        return (isinstance(other, self.__class__) and\n                self.name == other.name and\n                self.prefix == other.prefix)\n\n    def __hash__(self):\n        return hash((\n            self.__class__.__name__,\n            self.name,\n            self.prefix))\n\n    def __getitem__(self, attr):\n        return getattr(self, attr)\n\n    def __setitem__(self, attr, value):\n        setattr(self.tree, self.prefix + attr, value)\n\n    def __getattr__(self, attr):\n        return getattr(self.tree, self.prefix + attr)\n\n    def __setattr__(self, attr, value):\n        if \'_inited\' not in self.__dict__:\n            return object.__setattr__(self, attr, value)\n        try:\n            setattr(self.tree, self.prefix + attr, value)\n        except AttributeError:\n            return object.__setattr__(self, attr, value)\n\n    def define_object(self, name, prefix):\n        obj = TreeObject(self, name, prefix)\n        object.__setattr__(self, name, obj)\n        return obj\n\n\nclass TreeCollectionObject(TreeObject):\n\n    def __init__(self, tree, name, prefix, index):\n        self.index = index\n        super(TreeCollectionObject, self).__init__(tree, name, prefix)\n        self._inited = True\n\n    def __eq__(self, other):\n        return TreeObject.__eq__(self, other) and self.index == other.index\n\n    def __hash__(self):\n        return hash((\n            self.__class__.__name__,\n            self.name,\n            self.prefix,\n            self.index))\n\n    def __getattr__(self, attr):\n        try:\n            return getattr(self.tree, self.prefix + attr)[self.index]\n        except IndexError:\n            raise IndexError(\n                ""index {0:d} out of range for ""\n                ""attribute `{1}` of collection `{2}` of size {3:d}"".format(\n                    self.index, attr, self.prefix,\n                    len(getattr(self.tree, self.prefix + attr))))\n\n    def __setattr__(self, attr, value):\n        if \'_inited\' not in self.__dict__:\n            return object.__setattr__(self, attr, value)\n        try:\n            getattr(self.tree, self.prefix + attr)[self.index] = value\n        except IndexError:\n            raise IndexError(\n                ""index {0:d} out of range for ""\n                ""attribute `{1}` of collection `{2}` of size {3:d}"".format(\n                    self.index, attr, self.prefix,\n                    len(getattr(self.tree, self.prefix + attr))))\n        except AttributeError:\n            return object.__setattr__(self, attr, value)\n\n\nclass TreeCollection(object):\n\n    def __init__(self, tree, name, prefix, size, mix=None, cache=True):\n        self.tree = tree\n        self.name = name\n        self.prefix = prefix\n        self.size = size\n        self.selection = None\n\n        self.__cache_objects = cache\n        self.__cache = {}\n\n        self.tree_object_cls = TreeCollectionObject\n        if mix is not None:\n            if mix in __MIXINS__:\n                self.tree_object_cls = __MIXINS__[mix]\n            else:\n                self.tree_object_cls = mix_classes(TreeCollectionObject, mix)\n                __MIXINS__[mix] = self.tree_object_cls\n\n    def __nonzero__(self):\n        return len(self) > 0\n\n    __bool__ = __nonzero__\n\n    def reset(self):\n        self.reset_selection()\n        self.reset_cache()\n\n    def reset_selection(self):\n        self.selection = None\n\n    def reset_cache(self):\n        self.__cache = {}\n\n    def remove(self, thing):\n        if self.selection is None:\n            self.selection = range(len(self))\n        for i, other in enumerate(self):\n            if thing == other:\n                self.selection.pop(i)\n                break\n\n    def pop(self, index):\n        if self.selection is None:\n            self.selection = range(len(self))\n        thing = self[index]\n        self.selection.pop(index)\n        return thing\n\n    def select(self, func):\n        if self.selection is None:\n            self.selection = range(len(self))\n        self.selection = [\n            i for i, thing in zip(self.selection, self)\n            if func(thing)]\n\n    def select_indices(self, indices):\n        if self.selection is None:\n            self.selection = range(len(self))\n        self.selection = [self.selection[i] for i in indices]\n\n    def mask(self, func):\n        if self.selection is None:\n            self.selection = range(len(self))\n        self.selection = [\n            i for i, thing in zip(self.selection, self)\n            if not func(thing)]\n\n    def mask_indices(self, indices):\n        if self.selection is None:\n            self.selection = range(len(self))\n        self.selection = [\n            j for i, j in enumerate(self.selection)\n            if i not in indices]\n\n    def _wrap_sort_key(self, key):\n        def wrapped_key(index):\n            return key(self.getitem(index))\n        return wrapped_key\n\n    def sort(self, key, **kwargs):\n        if self.selection is None:\n            self.selection = range(len(self))\n        self.selection.sort(key=self._wrap_sort_key(key), **kwargs)\n\n    def slice(self, start=0, stop=None, step=1):\n        if self.selection is None:\n            self.selection = range(len(self))\n        self.selection = self.selection[slice(start, stop, step)]\n\n    def make_persistent(self):\n        """"""\n        Perform actual selection and sorting on underlying\n        attribute vectors\n        """"""\n        pass\n\n    def getitem(self, index):\n        """"""\n        direct access without going through self.selection\n        """"""\n        if index >= getattr(self.tree, self.size):\n            raise IndexError(index)\n        if self.__cache_objects and index in self.__cache:\n            return self.__cache[index]\n        obj = self.tree_object_cls(self.tree, self.name, self.prefix, index)\n        if self.__cache_objects:\n            self.__cache[index] = obj\n        return obj\n\n    def __getitem__(self, index):\n        if isinstance(index, slice):\n            return [self[i] for i in range(*index.indices(len(self)))]\n        if index >= len(self):\n            raise IndexError(index)\n        if self.selection is not None:\n            index = self.selection[index]\n        if self.__cache_objects and index in self.__cache:\n            return self.__cache[index]\n        obj = self.tree_object_cls(self.tree, self.name, self.prefix, index)\n        if self.__cache_objects:\n            self.__cache[index] = obj\n        return obj\n\n    def len(self):\n        """"""\n        length of original collection\n        """"""\n        return getattr(self.tree, self.size)\n\n    def __len__(self):\n        if self.selection is not None:\n            return len(self.selection)\n        return getattr(self.tree, self.size)\n\n    def __iter__(self):\n        for index in range(len(self)):\n            yield self.__getitem__(index)\n\n\ndef one_to_one_assoc(name, collection, index_branch):\n    collection = deepcopy(collection)\n    collection.reset()\n    cls_def = \\\n    \'\'\'class OneToOne{name}(object):\n    @property\n    def {name}(self):\n        return collection[self.{index_branch}]\n    \'\'\'.format(name=name, index_branch=index_branch)\n    namespace = {}\n    eval(cls_def, namespace)\n    return namespace[\'OneToOne{name}\'.format(name=name)]\n\n\ndef one_to_many_assoc(name, collection, index_branch):\n    collection = deepcopy(collection)\n    collection.reset()\n    cls_def = \\\n    \'\'\'class OneToMany{name}(object):\n    def __init__(self):\n        self.{name} = deepcopy(collection)\n        self.{name}.reset()\n        self.{name}.select_indices(self.{index_branch})\n    \'\'\'.format(name=name, index_branch=index_branch)\n    namespace = {}\n    eval(cls_def, namespace)\n    return namespace[\'OneToMany{name}\'.format(name=name)]\n'"
rootpy/tree/treetypes.py,0,"b'""""""\nWrappers for basic types that are compatible with ROOT TTrees\n""""""\nfrom __future__ import absolute_import\n\nimport itertools\nfrom array import array\nimport sys\nif sys.version_info[0] >= 3:\n    long = int\n\nfrom ..extern.six.moves import range\nfrom .. import register\n\n# only list Column subclasses here\n__all__ = [\n    \'ObjectCol\',\n    \'BoolCol\',\n    \'BoolArrayCol\',\n    \'CharCol\',\n    \'CharArrayCol\',\n    \'UCharCol\',\n    \'UCharArrayCol\',\n    \'ShortCol\',\n    \'ShortArrayCol\',\n    \'UShortCol\',\n    \'UShortArrayCol\',\n    \'IntCol\',\n    \'IntArrayCol\',\n    \'UIntCol\',\n    \'UIntArrayCol\',\n    \'LongCol\',\n    \'LongArrayCol\',\n    \'ULongCol\',\n    \'ULongArrayCol\',\n    \'FloatCol\',\n    \'FloatArrayCol\',\n    \'DoubleCol\',\n    \'DoubleArrayCol\',\n]\n\n\nclass Column(object):\n    _counter = itertools.count()\n\n    def __init__(self, *args, **kwargs):\n        self.idx = next(Column._counter)\n        self.args = args\n        self.kwargs = kwargs\n\n    def __call__(self):\n        return self.type(*self.args, **self.kwargs)\n\n    def __repr__(self):\n        arg_params = \', \'.join([str(a) for a in self.args])\n        kwd_params = \', \'.join([\'{0}={1}\'.format(name, value)\n                                for name, value in self.kwargs.items()])\n        params = []\n        if arg_params:\n            params.append(arg_params)\n        if kwd_params:\n            params.append(kwd_params)\n        return ""{0}({1})"".format(\n            self.__class__.__name__, \', \'.join(params))\n\n    def __str__(self):\n        return repr(self)\n\n\nclass ObjectCol(Column):\n\n    def __init__(self, cls, *args, **kwargs):\n        self.type = cls\n        Column.__init__(self, *args, **kwargs)\n\n\nclass Scalar(object):\n\n    def clear(self):\n        """"""Supplied to match the interface of ROOT.vector""""""\n        self.reset()\n\n\nclass BaseScalar(Scalar, array):\n    """"""This is the base class for all variables""""""\n\n    def __init__(self, resetable=True):\n        array.__init__(self)\n        self.resetable = resetable\n\n    def reset(self):\n        """"""Reset the value to the default""""""\n        if self.resetable:\n            self[0] = self.default\n\n    @property\n    def value(self):\n        """"""The current value""""""\n        return self[0]\n\n    def set(self, value):\n        """"""Set the value""""""\n        if isinstance(value, BaseScalar):\n            self[0] = self.convert(value.value)\n        else:\n            self[0] = self.convert(value)\n\n    def __str__(self):\n        return self.__repr__()\n\n    def __repr__(self):\n        return ""{0}({1}) at {2}"".format(\n            self.__class__.__name__, repr(self.value), hex(id(self)))\n\n    def __getitem__(self, i):\n        return array.__getitem__(self, 0)\n\n    def __setitem__(self, i, value):\n        if isinstance(value, BaseScalar):\n            array.__setitem__(self, 0, value.value)\n        else:\n            array.__setitem__(self, 0, value)\n\n    def __lt__(self, value):\n        if isinstance(value, BaseScalar):\n            return self.value < value.value\n        return self.value < value\n\n    def __le__(self, value):\n        if isinstance(value, BaseScalar):\n            return self.value <= value.value\n        return self.value <= value\n\n    def __eq__(self, value):\n        if isinstance(value, BaseScalar):\n            return self.value == value.value\n        return self.value == value\n\n    def __ne__(self, value):\n        if isinstance(value, BaseScalar):\n            return self.value != value.value\n        return self.value != value\n\n    def __gt__(self, value):\n        if isinstance(value, BaseScalar):\n            return self.value > value.value\n        return self.value > value\n\n    def __ge__(self, value):\n        if isinstance(value, BaseScalar):\n            return self.value >= value.value\n        return self.value >= value\n\n    def __nonzero__(self):\n        return self.value != 0\n\n    __bool__ = __nonzero__\n\n    def __add__(self, other):\n        if isinstance(other, BaseScalar):\n            return self.value + other.value\n        return self.value + other\n\n    def __radd__(self, other):\n        return self + other\n\n    def __sub__(self, other):\n        if isinstance(other, BaseScalar):\n            return self.value - other.value\n        return self.value - other\n\n    def __rsub__(self, other):\n        return other - self.value\n\n    def __mul__(self, other):\n        if isinstance(other, BaseScalar):\n            return self.value * other.value\n        return self.value * other\n\n    def __rmul__(self, other):\n        return self * other\n\n    def __div__(self, other):\n        if isinstance(other, BaseScalar):\n            return self.value / other.value\n        return self.value / other\n\n    def __rdiv__(self, other):\n        return other / self.value\n\n\nclass Array(object):\n\n    def __init__(self, resetable=True, length_name=None):\n        self.resetable = resetable\n        self.length_name = length_name\n\n    def clear(self):\n        """"""Supplied to match the interface of ROOT.vector""""""\n        self.reset()\n\n\nclass BaseArray(Array, array):\n    """"""This is the base class for all array variables""""""\n\n    def __init__(self, **kwargs):\n        array.__init__(self)\n        Array.__init__(self, **kwargs)\n\n    def reset(self):\n        """"""Reset the value to the default""""""\n        if self.resetable:\n            for i in range(len(self)):\n                self[i] = self.default\n\n    def set(self, other):\n        for i, thing in enumerate(other):\n            self[i] = self.convert(thing)\n        for i in range(i + 1, len(self)):\n            self[i] = self.default\n\n    def __str__(self):\n        return self.__repr__()\n\n    def __repr__(self):\n        return ""{0}[{1}] at {2}"".format(\n            self.__class__.__name__,\n            \', \'.join(map(str, self)),\n            hex(id(self)))\n\n\nclass BaseChar(object):\n\n    @property\n    def value(self):\n        return str(self.rstrip(b\'\\0\').decode(\'ascii\'))\n\n    def __str__(self):\n        return self.value\n\n    def __repr__(self):\n        return ""{0}[{1}] at {2}"".format(\n            self.__class__.__name__,\n            repr(str(self)),\n            hex(id(self)))\n\n\nclass BaseCharScalar(BaseChar, Scalar, bytearray):\n    """"""This is the base class for all char variables""""""\n\n    def __init__(self, resetable=True):\n        bytearray.__init__(self, 2)\n        self.resetable = resetable\n\n    def reset(self):\n        """"""Reset the value to the default""""""\n        if self.resetable:\n            # reset to null bytes\n            self[0] = 0\n\n    def set(self, other):\n        self[0] = other\n\n\nclass BaseCharArray(BaseChar, Array, bytearray):\n    """"""This is the base class for all char array variables""""""\n\n    def __init__(self, length, **kwargs):\n        if not isinstance(length, int):\n            raise TypeError(""char array length must be an int"")\n        if length < 2:\n            raise ValueError(\n                ""char array length must be at least 2 ""\n                ""to include null-termination"")\n        bytearray.__init__(self, length)\n        Array.__init__(self, **kwargs)\n\n    def reset(self):\n        """"""Reset the value to the default""""""\n        if self.resetable:\n            # reset to null bytes\n            self[:] = bytearray(len(self))\n\n    def set(self, other):\n        # leave the null-termination untouched\n        if len(other) >= len(self):\n            raise ValueError(\n                ""string of length {0:d} is too long to ""\n                ""fit in array of length {1:d} with null-termination"".format(\n                    len(other), len(self)))\n        self[:len(other)] = other\n\n\n@register(names=(\'B\', \'Bool_t\'), builtin=True)\nclass Bool(BaseScalar):\n    """"""\n    This is a variable containing a Boolean type\n    """"""\n    # The ROOT character representation of the Boolean type\n    type = \'O\'\n    typename = \'Bool_t\'\n\n    def __new__(cls, default=False, **kwargs):\n        return BaseScalar.__new__(cls, \'B\', [Bool.convert(default)])\n\n    def __init__(self, default=False, **kwargs):\n        BaseScalar.__init__(self, **kwargs)\n        self.default = Bool.convert(default)\n\n    @classmethod\n    def convert(cls, value):\n        return int(bool(value))\n\n\nclass BoolCol(Column):\n    type = Bool\n\n\n@register(names=(\'B[]\', \'Bool_t[]\'), builtin=True)\nclass BoolArray(BaseArray):\n    """"""\n    This is an array of Booleans\n    """"""\n    # The ROOT character representation of the Boolean type\n    type = \'O\'\n    typename = \'Bool_t\'\n    convert = Bool.convert\n\n    def __new__(cls, length, default=False, **kwargs):\n        return BaseArray.__new__(\n            cls, \'B\',\n            [Bool.convert(default)] * length)\n\n    def __init__(self, length, default=False, **kwargs):\n        BaseArray.__init__(self, **kwargs)\n        self.default = Bool.convert(default)\n\n\nclass BoolArrayCol(Column):\n    type = BoolArray\n\n\n@register(names=(\'C\', \'Char_t\'), builtin=True)\nclass Char(BaseCharScalar):\n    """"""\n    This is a variable containing a character type\n    """"""\n    # The ROOT character representation of the char type\n    type = \'C\'\n    typename = \'Char_t\'\n\n\nclass CharCol(Column):\n    type = Char\n\n\n@register(names=(\'C[]\', \'Char_t[]\'), builtin=True)\nclass CharArray(BaseCharArray):\n    """"""\n    This is an array of characters\n    """"""\n    # The ROOT character representation of the char type\n    type = \'C\'\n    typename = \'Char_t\'\n    scalar = Char\n\n\nclass CharArrayCol(Column):\n    type = CharArray\n\n\n@register(names=(\'UC\', \'UChar_t\'), builtin=True)\nclass UChar(BaseCharScalar):\n    """"""\n    This is a variable containing an unsigned character type\n    """"""\n    # The ROOT character representation of the unsigned char type\n    type = \'c\'\n    typename = \'UChar_t\'\n\n\nclass UCharCol(Column):\n    type = UChar\n\n\n@register(names=(\'UC[]\', \'UChar_t[]\'), builtin=True)\nclass UCharArray(BaseCharArray):\n    """"""\n    This is an array of unsigned characters\n    """"""\n    # The ROOT character representation of the unsigned char type\n    type = \'c\'\n    typename = \'UChar_t\'\n    scalar = UChar\n\n\nclass UCharArrayCol(Column):\n    type = UCharArray\n\n\n@register(names=(\'S\', \'Short_t\'), builtin=True)\nclass Short(BaseScalar):\n    """"""\n    This is a variable containing an integer\n    """"""\n    # The ROOT character representation of the short type\n    type = \'S\'\n    typename = \'Short_t\'\n\n    def __new__(cls, default=0, **kwargs):\n        return BaseScalar.__new__(cls, \'h\', [Short.convert(default)])\n\n    def __init__(self, default=0, **kwargs):\n        BaseScalar.__init__(self, **kwargs)\n        self.default = Short.convert(default)\n\n    @classmethod\n    def convert(cls, value):\n        return int(value)\n\n\nclass ShortCol(Column):\n    type = Short\n\n\n@register(names=(\'S[]\', \'Short_t[]\'), builtin=True)\nclass ShortArray(BaseArray):\n    """"""\n    This is an array of integers\n    """"""\n    # The ROOT character representation of the short type\n    type = \'S\'\n    typename = \'Short_t\'\n    convert = Short.convert\n\n    def __new__(cls, length, default=0, **kwargs):\n        return BaseArray.__new__(\n            cls, \'h\',\n            [Short.convert(default)] * length)\n\n    def __init__(self, length, default=0, **kwargs):\n        BaseArray.__init__(self, **kwargs)\n        self.default = Short.convert(default)\n\n\nclass ShortArrayCol(Column):\n    type = ShortArray\n\n\n@register(names=(\'US\', \'UShort_t\'), builtin=True)\nclass UShort(BaseScalar):\n    """"""\n    This is a variable containing a short\n    """"""\n    # The ROOT character representation of the unsigned short type\n    type = \'s\'\n    typename = \'UShort_t\'\n\n    def __new__(cls, default=0, **kwargs):\n        return BaseScalar.__new__(cls, \'H\', [UShort.convert(default)])\n\n    def __init__(self, default=0, **kwargs):\n        BaseScalar.__init__(self, **kwargs)\n        self.default = UShort.convert(default)\n\n    @classmethod\n    def convert(cls, value):\n        if value < 0:\n            raise ValueError(\n                ""Assigning negative value ({0:d}) ""\n                ""to unsigned type"".format(value))\n        return int(value)\n\n\nclass UShortCol(Column):\n    type = UShort\n\n\n@register(names=(\'US[]\', \'UShort_t[]\'), builtin=True)\nclass UShortArray(BaseArray):\n    """"""\n    This is an array of unsigned shorts\n    """"""\n    # The ROOT character representation of the unsigned short type\n    type = \'s\'\n    typename = \'UShort_t\'\n    convert = UShort.convert\n\n    def __new__(cls, length, default=0, **kwargs):\n        return BaseArray.__new__(\n            cls, \'H\',\n            [UShort.convert(default)] * length)\n\n    def __init__(self, length, default=0, **kwargs):\n        BaseArray.__init__(self, **kwargs)\n        self.default = UShort.convert(default)\n\n\nclass UShortArrayCol(Column):\n    type = UShortArray\n\n\n@register(names=(\'I\', \'Int_t\'), builtin=True)\nclass Int(BaseScalar):\n    """"""\n    This is a variable containing an integer\n    """"""\n    # The ROOT character representation of the integer type\n    type = \'I\'\n    typename = \'Int_t\'\n\n    def __new__(cls, default=0, **kwargs):\n        return BaseScalar.__new__(cls, \'i\', [Int.convert(default)])\n\n    def __init__(self, default=0, **kwargs):\n        BaseScalar.__init__(self, **kwargs)\n        self.default = Int.convert(default)\n\n    @classmethod\n    def convert(cls, value):\n        return int(value)\n\n\nclass IntCol(Column):\n    type = Int\n\n\n@register(names=(\'I[]\', \'Int_t[]\'), builtin=True)\nclass IntArray(BaseArray):\n    """"""\n    This is an array of integers\n    """"""\n    # The ROOT character representation of the integer type\n    type = \'I\'\n    typename = \'Int_t\'\n    convert = Int.convert\n\n    def __new__(cls, length, default=0, **kwargs):\n        return BaseArray.__new__(\n            cls, \'i\',\n            [Int.convert(default)] * length)\n\n    def __init__(self, length, default=0, **kwargs):\n        BaseArray.__init__(self, **kwargs)\n        self.default = Int.convert(default)\n\n\nclass IntArrayCol(Column):\n    type = IntArray\n\n\n@register(names=(\'UI\', \'UInt_t\'), builtin=True)\nclass UInt(BaseScalar):\n    """"""\n    This is a variable containing an unsigned integer\n    """"""\n    # The ROOT character representation of the unsigned integer type\n    type = \'i\'\n    typename = \'UInt_t\'\n\n    def __new__(cls, default=0, **kwargs):\n        return BaseScalar.__new__(cls, \'I\', [UInt.convert(default)])\n\n    def __init__(self, default=0, **kwargs):\n        BaseScalar.__init__(self, **kwargs)\n        self.default = UInt.convert(default)\n\n    @classmethod\n    def convert(cls, value):\n        if value < 0:\n            raise ValueError(\n                ""Assigning negative value ({0:d}) ""\n                ""to unsigned type"".format(value))\n        return long(value)\n\n\nclass UIntCol(Column):\n    type = UInt\n\n\n@register(names=(\'UI[]\', \'UInt_t[]\'), builtin=True)\nclass UIntArray(BaseArray):\n    """"""\n    This is an array of unsigned integers\n    """"""\n    # The ROOT character representation of the unsigned integer type\n    type = \'i\'\n    typename = \'UInt_t\'\n    convert = UInt.convert\n\n    def __new__(cls, length, default=0, **kwargs):\n        return BaseArray.__new__(\n            cls, \'I\',\n            [UInt.convert(default)] * length)\n\n    def __init__(self, length, default=0, **kwargs):\n        BaseArray.__init__(self, **kwargs)\n        self.default = UInt.convert(default)\n\n\nclass UIntArrayCol(Column):\n    type = UIntArray\n\n\n@register(names=(\'L\', \'Long64_t\'), builtin=True)\nclass Long(BaseScalar):\n    """"""\n    This is a variable containing a long\n    """"""\n    # The ROOT character representation of the long type\n    type = \'L\'\n    typename = \'Long64_t\'\n\n    def __new__(cls, default=0, **kwargs):\n        return BaseScalar.__new__(cls, \'l\', [Long.convert(default)])\n\n    def __init__(self, default=0, **kwargs):\n        BaseScalar.__init__(self, **kwargs)\n        self.default = Long.convert(default)\n\n    @classmethod\n    def convert(cls, value):\n        return long(value)\n\n\nclass LongCol(Column):\n    type = Long\n\n\n@register(names=(\'L[]\', \'Long64_t[]\'), builtin=True)\nclass LongArray(BaseArray):\n    """"""\n    This is an array of longs\n    """"""\n    # The ROOT character representation of the long type\n    type = \'L\'\n    typename = \'Long64_t\'\n    convert = Long.convert\n\n    def __new__(cls, length, default=0, **kwargs):\n        return BaseArray.__new__(\n            cls, \'l\',\n            [Long.convert(default)] * length)\n\n    def __init__(self, length, default=0, **kwargs):\n        BaseArray.__init__(self, **kwargs)\n        self.default = Long.convert(default)\n\n\nclass LongArrayCol(Column):\n    type = LongArray\n\n\n@register(names=(\'UL\', \'ULong64_t\'), builtin=True)\nclass ULong(BaseScalar):\n    """"""\n    This is a variable containing an unsigned long\n    """"""\n    # The ROOT character representation of the long type\n    type = \'l\'\n    typename = \'ULong64_t\'\n\n    def __new__(cls, default=0, **kwargs):\n        return BaseScalar.__new__(cls, \'L\', [ULong.convert(default)])\n\n    def __init__(self, default=0, **kwargs):\n        BaseScalar.__init__(self, **kwargs)\n        self.default = ULong.convert(default)\n\n    @classmethod\n    def convert(cls, value):\n        if value < 0:\n            raise ValueError(\n                ""Assigning negative value ({0:d}) ""\n                ""to unsigned type"".format(value))\n        return long(value)\n\n\nclass ULongCol(Column):\n    type = ULong\n\n\n@register(names=(\'UL[]\', \'ULong64_t[]\'), builtin=True)\nclass ULongArray(BaseArray):\n    """"""\n    This is of unsigned longs\n    """"""\n    # The ROOT character representation of the long type\n    type = \'l\'\n    typename = \'ULong64_t\'\n    convert = ULong.convert\n\n    def __new__(cls, length, default=0, **kwargs):\n        return BaseArray.__new__(\n            cls, \'L\',\n            [ULong.convert(default)] * length)\n\n    def __init__(self, length, default=0, **kwargs):\n        BaseArray.__init__(self, **kwargs)\n        self.default = ULong.convert(default)\n\n\nclass ULongArrayCol(Column):\n    type = ULongArray\n\n\n@register(names=(\'F\', \'Float_t\'), builtin=True)\nclass Float(BaseScalar):\n    """"""\n    This is a variable containing a float\n    """"""\n    # The ROOT character representation of the float type\n    type = \'F\'\n    typename = \'Float_t\'\n\n    def __new__(cls, default=0., **kwargs):\n        return BaseScalar.__new__(cls, \'f\', [Float.convert(default)])\n\n    def __init__(self, default=0., **kwargs):\n        BaseScalar.__init__(self, **kwargs)\n        self.default = Float.convert(default)\n\n    @classmethod\n    def convert(cls, value):\n        return float(value)\n\n\nclass FloatCol(Column):\n    type = Float\n\n\n@register(names=(\'F[]\', \'Float_t[]\'), builtin=True)\nclass FloatArray(BaseArray):\n    """"""\n    This is an array of floats\n    """"""\n    # The ROOT character representation of the float type\n    type = \'F\'\n    typename = \'Float_t\'\n    convert = Float.convert\n\n    def __new__(cls, length, default=0., **kwargs):\n        return BaseArray.__new__(\n            cls, \'f\',\n            [Float.convert(default)] * length)\n\n    def __init__(self, length, default=0., **kwargs):\n        BaseArray.__init__(self, **kwargs)\n        self.default = Float.convert(default)\n\n\nclass FloatArrayCol(Column):\n    type = FloatArray\n\n\n@register(names=(\'D\', \'Double_t\'), builtin=True)\nclass Double(BaseScalar):\n    """"""\n    This is a variable containing a double\n    """"""\n    # The ROOT character representation of the double type\n    type = \'D\'\n    typename = \'Double_t\'\n\n    def __new__(cls, default=0., **kwargs):\n        return BaseScalar.__new__(cls, \'d\', [Double.convert(default)])\n\n    def __init__(self, default=0., **kwargs):\n        BaseScalar.__init__(self, **kwargs)\n        self.default = Double.convert(default)\n\n    @classmethod\n    def convert(cls, value):\n        return float(value)\n\n\nclass DoubleCol(Column):\n    type = Double\n\n\n@register(names=(\'D[]\', \'Double_t[]\'), builtin=True)\nclass DoubleArray(BaseArray):\n    """"""\n    This is an array of doubles\n    """"""\n    # The ROOT character representation of the double type\n    type = \'D\'\n    typename = \'Double_t\'\n    convert = Double.convert\n\n    def __new__(cls, length, default=0., **kwargs):\n        return BaseArray.__new__(\n            cls, \'d\',\n            [Double.convert(default)] * length)\n\n    def __init__(self, length, default=0., **kwargs):\n        BaseArray.__init__(self, **kwargs)\n        self.default = Double.convert(default)\n\n\nclass DoubleArrayCol(Column):\n    type = DoubleArray\n\n\n# ROOT type codes:\nroot_type_codes = \'\'\'\\\nO       a boolean (Bool_t) (see note 1)\nB       an 8 bit signed integer (Char_t)\nb       an 8 bit unsigned integer (UChar_t)\nS       a 16 bit signed integer (Short_t)\ns       a 16 bit unsigned integer (UShort_t)\nI       a 32 bit signed integer (Int_t)\ni       a 32 bit unsigned integer (UInt_t)\nL       a 64 bit signed integer (Long64_t)\nl       a 64 bit unsigned integer (ULong64_t)\nF       a 32 bit floating point (Float_t)\nD       a 64 bit floating point (Double_t)\\\n\'\'\'\n\nroot_type_codes = [line.split()[0] for line in root_type_codes.split(\'\\n\')]\n\n# ROOT type names:\nroot_type_names = \'\'\'\\\nBool_t\nChar_t\nUChar_t\nShort_t\nUShort_t\nInt_t\nUInt_t\nLong64_t\nULong64_t\nFloat_t\nDouble_t\\\n\'\'\'\n\nroot_type_names = [line.split()[0] for line in root_type_names.split(\'\\n\')]\n\n# Python array:\npython_codes = \'\'\'\\\nB       unsigned char   int                 1 (used as boolean)\nb       signed char     int                 1\nB       unsigned char   int                 1\nh       signed short    int                 2\nH       unsigned short  int                 2\ni       signed int      int                 2\nI       unsigned int    long                2\nl       signed long     int                 4\nL       unsigned long   long                4\nf       float           float               4\nd       double          float               8\\\n\'\'\'\n\npython_codes = [line.split()[0] for line in python_codes.split(\'\\n\')]\n\n# Python NumPy array:\nnumpy_codes = \'\'\'\\\nb       Boolean\ni1      Char\nu1      Unsigned Char\ni2      Short Integer\nu2      Unsigned Short integer\ni4      Integer\nu4      Unsigned integer\ni8      Long Integer\nu8      Unsigned Long integer\nf4      Floating point\nf8      Double Floating point\\\n\'\'\'\n\nnumpy_codes = [line.split()[0] for line in numpy_codes.split(\'\\n\')]\n\n\ndef convert(origin, target, type):\n    """"""\n    convert type from origin to target\n    origin/target must be ROOTCODE, ROOTNAME, ARRAY, or NUMPY\n    """"""\n    _origin = origin.upper()\n    if _origin == \'ROOTCODE\':\n        _origin = root_type_codes\n    elif _origin == \'ROOTNAME\':\n        _origin = root_type_names\n    elif _origin == \'ARRAY\':\n        _origin = python_codes\n    elif _origin == \'NUMPY\':\n        _origin = numpy_codes\n    else:\n        raise ValueError(""{0} is not a valid type"".format(origin))\n\n    _target = target.upper()\n    if _target == \'ROOTCODE\':\n        _target = root_type_codes\n    elif _target == \'ROOTNAME\':\n        _target = root_type_names\n    elif _target == \'ARRAY\':\n        _target = python_codes\n    elif _target == \'NUMPY\':\n        _target = numpy_codes\n    else:\n        raise ValueError(""{0} is not a valid type"".format(target))\n\n    if type not in _origin:\n        raise ValueError(""{0} is not a valid {1} type"".format(type, origin))\n\n    return _target[_origin.index(type)]\n'"
rootpy/utils/__init__.py,0,b'from .. import log; log = log[__name__]\n\n__all__ = []\n'
rootpy/utils/cinterface.py,0,"b'""""""\nFunctions useful for interfacing with C/C++ functions:\n\n* ``callback`` => Allows you to pass ctypes CFUNCTYPE objects as parameters to\n              PyROOT functions\n* ``objectproxy_realaddress`` => Determine the real address of a ROOT objects\n    (useful because multiple ObjectProxies can point to the same underlying object)\n""""""\nfrom __future__ import absolute_import\n\nimport ctypes as C\n\nfrom . import quickroot as QROOT\n\n__all__ = [\n    \'callback\',\n    \'objectproxy_realaddress\',\n]\n\n\ndef callback(cfunc):\n    """"""\n    Turn a ctypes CFUNCTYPE instance into a value which can be passed into PyROOT\n    """"""\n    # Note:\n    # ROOT wants a c_voidp whose addressof() == the call site of the target\n    # function. This hackery is necessary to achieve that.\n    return C.c_voidp.from_address(C.cast(cfunc, C.c_voidp).value)\n\n\ndef objectproxy_realaddress(obj):\n    """"""\n    Obtain a real address as an integer from an objectproxy.\n    """"""\n    voidp = QROOT.TPython.ObjectProxy_AsVoidPtr(obj)\n    return C.addressof(C.c_char.from_buffer(voidp))\n'"
rootpy/utils/cpp.py,0,"b'from __future__ import absolute_import\n\nimport re\n\nfrom ..extern.pyparsing import (\n    Optional, Keyword, Literal, Combine, Word, OneOrMore, QuotedString,\n    delimitedList, ParseException, nums, alphas, alphanums, Group, Forward,\n    Regex)\nfrom .. import log; log = log[__name__]\n\n__all__  = [\n    \'CPPGrammar\',\n]\n\n\nclass CPPGrammar(object):\n    """"""\n    A grammar for parsing C++ method/function signatures and types\n    """"""\n    ERROR_PATTERN = re.compile(\'\\(line:\\d+, col:(\\d+)\\)\')\n\n    QUOTED_STRING = (\n        QuotedString(\'""\', escChar=\'\\\\\') | Literal(\'""""\') |\n        QuotedString(""\'"", escChar=\'\\\\\') | Literal(""\'\'""))\n\n    PTR = Combine(OneOrMore(Word(""*"") | Word(""&"")), adjacent=False)\n    SIGN = Optional(Literal(\'+\') | Literal(\'-\'))\n    CONST = Keyword(""const"")\n    SIGNED = Optional(Keyword(\'signed\') | Keyword(\'unsigned\'))\n    STATIC = Keyword(\'static\')\n    VOID = Combine(Literal(\'void\') + Optional(PTR), adjacent=False)\n\n    BASIC_TYPE = Group(\n        Keyword(\'bool\') |\n        (SIGNED + Keyword(\'char\')) |\n        (SIGNED + Keyword(\'short\')) |\n        (SIGNED + Keyword(\'int\')) |\n        (SIGNED + Keyword(\'long\') + Optional(Keyword(\'long\'))) |\n        Keyword(\'enum\') |\n        Keyword(\'float\') |\n        (Optional(\'long\') + Keyword(\'double\')))(\'type_name\')\n\n    IDENTIFIER = Word(alphas + ""_"", alphanums + ""_"").setName(""identifier"")\n\n    hexnums = nums + ""abcdefABCDEF"" + ""_?""\n    base = Regex(""\'[bBoOdDhH]"").setName(""base"")\n    BASEDNUMBER = Combine(\n        Optional(Word(nums + ""_"")) + base +\n        Word(hexnums + ""xXzZ""),\n        joinString="" "", adjacent=False).setName(""based number"")\n    NUMBER = (\n        BASEDNUMBER |\n        Regex(r""[-+]?([0-9]*\\.[0-9]+|[0-9]+\\.?)([Ee][-+]?[0-9]+)?"")\n        ).setName(""numeric"")\n\n    ARITH_OPERATOR = Word(""*/+-"").setName(\'arith op\')\n    BIT_OPERATOR = Word(\'&|\').setName(\'bit op\')\n    BIT_EXPRESSION = (IDENTIFIER +\n        OneOrMore(BIT_OPERATOR + IDENTIFIER)).setName(\'bit_expression\')\n    EXPRESSION = OneOrMore(\n        NUMBER | ARITH_OPERATOR | IDENTIFIER).setName(\'expression\')\n    FULL_EXPRESSION = OneOrMore(\n        NUMBER | ARITH_OPERATOR |\n        Literal(\'(\') | Literal(\')\')).setName(\'full_expression\')\n\n    NAMESPACED_NAME = (Optional(Literal(\'::\')).suppress() +\n            delimitedList(IDENTIFIER, delim=\'::\', combine=True))\n\n    TYPE = Forward()\n\n    TEMPLATE_PARAMS = (\n        Literal(""<"").suppress() +\n        Group(delimitedList(TYPE | FULL_EXPRESSION))(""template_params"") +\n        Literal("">"").suppress())\n\n    CLASS_MEMBER = (\n        Literal(\'::\').suppress() +\n        NAMESPACED_NAME)(""template_member"")\n\n    COMPLEX_TYPE = (\n        Group(NAMESPACED_NAME)(\'type_name\') +\n        Optional(TEMPLATE_PARAMS + Optional(CLASS_MEMBER)))\n\n    TYPE << (\n        Group(Optional(CONST))(\'type_prefix\') +\n        (BASIC_TYPE | COMPLEX_TYPE) +\n        Group(Optional(PTR + Optional(CONST)))(\'type_suffix\'))\n\n    TYPE_EXPRESSION = (\n        Optional(NUMBER + ARITH_OPERATOR) + TYPE)(\'type_expression\')\n\n    SIMPLE_ARG_DEFAULT = Forward()\n    ARG_LIST = delimitedList(SIMPLE_ARG_DEFAULT)(\'arg_list\')\n    SIMPLE_ARG_DEFAULT << (\n        QUOTED_STRING | BIT_EXPRESSION | (TYPE_EXPRESSION +\n        Optional(\n            Literal(\'(\').suppress() +\n            Optional(ARG_LIST) +\n            Literal(\')\').suppress())) |\n        EXPRESSION)\n\n    FUNC_ARG_DEFAULT = (Literal(\'&\') + TYPE_EXPRESSION +\n        Optional(Literal(\'(\').suppress() +\n        Optional(ARG_LIST) +\n        Literal(\')\').suppress()))\n\n    METHOD_ARGS = Forward()\n\n    SIMPLE_ARG = (Optional(Optional(IDENTIFIER(\'arg_name\')) +\n        Optional(Literal(\'=\').suppress() +\n            SIMPLE_ARG_DEFAULT(\'arg_default\'))))\n\n    FUNC_ARG = (Literal(\'(*)\') +\n        Literal(""("").suppress() +\n        Optional(METHOD_ARGS)(\'func_arg_signature\') +\n        Literal("")"").suppress() +\n        Optional(Optional(IDENTIFIER)(\'arg_name\') +\n            Optional(Literal(\'=\').suppress() +\n                FUNC_ARG_DEFAULT(\'arg_default\'))))\n\n    METHOD_ARG = Group((VOID(\'arg_type\') | TYPE(\'arg_type\')) +\n        (FUNC_ARG | SIMPLE_ARG))(\'arg\')\n\n    METHOD_ARGS << (delimitedList(METHOD_ARG) | Literal(\'...\'))\n\n    METHOD_SIGNATURE = (\n        Optional(STATIC) +\n        ((VOID(\'return\') + COMPLEX_TYPE(\'name\')) |\n         (TYPE(\'return\') + COMPLEX_TYPE(\'name\')) |\n         COMPLEX_TYPE(\'name\')) +\n        Literal(""("").suppress() +\n        Optional(Group(METHOD_ARGS)(\'args\')) +\n        Literal("")"").suppress())\n\n    @classmethod\n    def _parse(cls, grammar, string, raise_exception=False, silent=True):\n        try:\n            return grammar.parseString(string, parseAll=True)\n        except ParseException as e:\n            if not silent:\n                log.warning(string)\n                str_e = str(e)\n                match = re.search(cls.ERROR_PATTERN, str_e)\n                if match:\n                    log.warning("" "" * (int(match.group(1)) - 1) + \'^\')\n            if raise_exception:\n                raise\n            if not silent:\n                log.warning(e)\n            return None\n\n    @classmethod\n    def parse_type(cls, string, raise_exception=False, silent=True):\n        return cls._parse(cls.TYPE, string,\n                          raise_exception, silent)\n\n    @classmethod\n    def parse_method(cls, string, raise_exception=False, silent=True):\n        return cls._parse(cls.METHOD_SIGNATURE,\n                          string, raise_exception, silent)\n'"
rootpy/utils/ext_glob.py,0,"b'""""""\nReproduce the standard glob package behaviour but use TSystem to be able to\nquery remote file systems such as xrootd\n""""""\nfrom __future__ import print_function\nfrom rootpy.ROOT import gSystem\nimport glob as gl\nimport os.path\nimport fnmatch\n\n\n__all__ = [""glob"", ""iglob""]\n\n\ndef __directory_iter(directory):\n    while True:\n        try:\n            file = gSystem.GetDirEntry(directory)\n            if not file:\n                break\n            yield file\n        except TypeError:\n            break\n\n\ndef glob(pathname):\n    # Let normal python glob try first\n    try_glob = gl.glob(pathname)\n    if try_glob:\n        return try_glob\n\n    # If pathname does not contain a wildcard:\n    if not gl.has_magic(pathname):\n        return [pathname]\n\n    # Else use ROOT\'s remote system querying\n    return root_glob(pathname)\n\n\ndef root_glob(pathname):\n    # Split the pathname into a directory and basename\n    # (which should include the wild-card)\n    dirs, basename = os.path.split(pathname)\n\n    if gl.has_magic(dirs):\n        dirs = root_glob(dirs)\n    else:\n        dirs = [dirs]\n\n    files = []\n    for dirname in dirs:\n        # Uses `TSystem` to open the directory.\n        # TSystem itself wraps up the calls needed to query xrootd.\n        dirname = gSystem.ExpandPathName(dirname)\n        directory = gSystem.OpenDirectory(dirname)\n\n        if directory:\n            for file in __directory_iter(directory):\n                if file in [""."", ""..""]:\n                    continue\n                if not fnmatch.fnmatchcase(file, basename):\n                    continue\n                files.append(os.path.join(dirname, file))\n            try:\n                gSystem.FreeDirectory(directory)\n            except TypeError:\n                pass\n    return files\n\n\ndef iglob(pathname):\n    for name in glob(pathname):\n        yield name\n\n\nif __name__ == ""__main__"":\n    test_paths = [\n        ""*.*"",\n        ""*/*.txt"",\n        ""data/L1Ntuple_test_3.root"",\n        """"""root://eoscms.cern.ch//eos/cms/store/group/dpg_trigger/""""""\n        """"""comm_trigger/L1Trigger/L1Menu2016/Stage2/""""""\n        """"""l1t-integration-v88p1-CMSSW-8021/SingleMuon/""""""\n        """"""crab_l1t-integration-v88p1-CMSSW-8021__SingleMuon_2016H_v2/""""""\n        """"""161031_120512/0000/L1Ntuple_999.root"""""",\n        """"""root://eoscms.cern.ch//eos/cms/store/group/dpg_trigger/""""""\n        """"""comm_trigger/L1Trigger/L1Menu2016/Stage2/""""""\n        """"""l1t-integration-v88p1-CMSSW-8021/SingleMuon/""""""\n        """"""crab_l1t-integration-v88p1-CMSSW-8021__SingleMuon_2016H_v2/""""""\n        """"""161031_120512/0000/L1Ntuple_99*.root"""""",\n        """"""root://eoscms.cern.ch//eos/cms/store/group/dpg_trigger/""""""\n        """"""comm_trigger/L1Trigger/L1Menu2016/Stage2/""""""\n        """"""l1t-integration-v88p1-CMSSW-8021/SingleMuon/""""""\n        """"""crab_l1t-integration-v88p1-CMSSW-8021__SingleMuon_2016H_v*/""""""\n        """"""161031_120*/0000/L1Ntuple_99*.root"""""",\n        """"""root://eoscms.cern.ch//eos/cms/store/group/dpg_trigger/""""""\n        """"""comm_trigger/L1Trigger/L1Menu2016/Stage2/""""""\n        """"""l1t-integration-v88p1-CMSSW-8021/SingleMuon/""""""\n        """"""crab_l1t-integration-v88p1-CMSSW-8021__SingleMuon_2016H_v*/""""""\n        """"""161031_120*"""""",\n    ]\n    import pprint\n    for i, path in enumerate(test_paths):\n        print(path, ""=>"")\n        expanded = glob(path)\n        print(len(expanded), ""files:"", pprint.pformat(expanded))\n'"
rootpy/utils/extras.py,0,"b'from __future__ import absolute_import\n\nimport sys\nif sys.version_info[0] >= 3:\n    from urllib.request import urlopen\nelse:\n    from urllib2 import urlopen\nimport xml.dom.minidom as minidom\nfrom itertools import chain\ntry:\n    from itertools import izip as zip\nexcept ImportError: # will be 3.x series\n    pass\n\nfrom .. import log; log = log[__name__]\nfrom . import quickroot as QROOT\n\n__all__ = [\n    \'iter_ROOT_classes\',\n    \'humanize_bytes\',\n    \'print_table\',\n    \'izip_exact\',\n    \'LengthMismatch\',\n]\n\n\ndef iter_ROOT_classes():\n    """"""\n    Iterator over all available ROOT classes\n    """"""\n    class_index = ""http://root.cern.ch/root/html/ClassIndex.html""\n    for s in minidom.parse(urlopen(class_index)).getElementsByTagName(""span""):\n        if (""class"", ""typename"") in s.attributes.items():\n            class_name = s.childNodes[0].nodeValue\n            try:\n                yield getattr(QROOT, class_name)\n            except AttributeError:\n                pass\n\n\ndef humanize_bytes(value, precision=1):\n    abbrevs = (\n        (1<<50, \'PB\'),\n        (1<<40, \'TB\'),\n        (1<<30, \'GB\'),\n        (1<<20, \'MB\'),\n        (1<<10, \'kB\'),\n        (1, \'bytes\'))\n    if value == 1:\n        return \'1 byte\'\n    for factor, suffix in abbrevs:\n        if value >= factor:\n            break\n    return \'%.*f %s\' % (precision, value / factor, suffix)\n\n\ndef print_table(table, sep=\'  \'):\n    # Reorganize data by columns\n    cols = zip(*table)\n    # Compute column widths by taking maximum length of values per column\n    col_widths = [max(len(value) for value in col) for col in cols]\n    # Create a suitable format string\n    fmt = sep.join([\'%%-%ds\' % width for width in col_widths])\n    # Print each row using the computed format\n    for row in table:\n        print(fmt % tuple(row))\n\n\nclass LengthMismatch(Exception):\n    pass\n\n\ndef _throw():\n    raise LengthMismatch\n    yield None # unreachable\n\n\ndef _check(rest):\n    for i in rest:\n        try:\n            next(i)\n        except LengthMismatch:\n            pass\n        else:\n            raise LengthMismatch\n    return\n    yield None # unreachable\n\n\ndef izip_exact(*iterables):\n    """"""\n    A lazy izip() that ensures that all iterables have the same length.\n    A LengthMismatch exception is raised if the iterables\' lengths differ.\n\n    Examples\n    --------\n\n        >>> list(zip_exc([]))\n        []\n        >>> list(zip_exc((), (), ()))\n        []\n        >>> list(zip_exc(""abc"", range(3)))\n        [(\'a\', 0), (\'b\', 1), (\'c\', 2)]\n        >>> try:\n        ...     list(zip_exc("""", range(3)))\n        ... except LengthMismatch:\n        ...     print ""mismatch""\n        mismatch\n        >>> try:\n        ...     list(zip_exc(range(3), ()))\n        ... except LengthMismatch:\n        ...     print ""mismatch""\n        mismatch\n        >>> try:\n        ...     list(zip_exc(range(3), range(2), range(4)))\n        ... except LengthMismatch:\n        ...     print ""mismatch""\n        mismatch\n        >>> items = zip_exc(range(3), range(2), range(4))\n        >>> next(items)\n        (0, 0, 0)\n        >>> next(items)\n        (1, 1, 1)\n        >>> try: next(items)\n        ... except LengthMismatch: print ""mismatch""\n        mismatch\n\n    References\n    ----------\n\n    [1] http://code.activestate.com/recipes/497006-zip_exc-a-lazy-zip-that-ensures-that-all-iterables/\n\n    """"""\n    rest = [chain(i, _throw()) for i in iterables[1:]]\n    first = chain(iterables[0], _check(rest))\n    return zip(*[first] + rest)\n'"
rootpy/utils/hook.py,0,"b'from __future__ import absolute_import\n\nimport types\nimport sys\n\nfrom .inject_closure import inject_closure_values\nfrom . import log; log = log[__name__]\n\n__all__ = [\n    \'super_overridden\',\n    \'uses_super\',\n    \'classhook\',\n    \'appendclass\',\n]\n\n# The below code is here for reference:\n# How to hook anything you want..\n# TODO(pwaller): Delete this if no-one needs it after a month or two.\n""""""\nfrom .. import QROOT\n\nHOOKED_CLASSES = {}\n\nTObject_meta = type(QROOT.TObject)\n\norig_meta_getattribute = TObject_meta.__getattribute__\ndef new_meta_getattribute(cls, name):\n    #print cls, name\n    if cls in HOOKED_CLASSES:\n        hook = HOOKED_METHODS.get((cls, name), None)\n        if hook:\n            hook(orig_getattribute)\n    return orig_meta_getattribute(cls, name)\nTObject_meta.__getattribute__ = new_meta_getattribute\n\norig_getattribute = QROOT.TObject.__getattribute__\ndef new_getattribute(cls, name):\n    x = orig_getattribute(cls, name)\n    return x\nQROOT.TObject.__getattribute__ = new_getattribute\n""""""\n\nINTERESTING = (\n    types.FunctionType, types.MethodType,\n    property, staticmethod, classmethod)\n\n\ndef super_overridden(cls):\n    """"""\n    This decorator just serves as a reminder that the super function behaves\n    differently. It doesn\'t actually do anything, that happens inside\n    ``classhook.hook_class``.\n    """"""\n    cls.__rootpy_have_super_overridden = True\n    return cls\n\n\ndef uses_super(func):\n    """"""\n    Check if the function/property/classmethod/staticmethod uses the `super` builtin\n    """"""\n    if isinstance(func, property):\n        return any(uses_super(f) for f in (func.fget, func.fset, func.fdel) if f)\n    elif isinstance(func, (staticmethod, classmethod)):\n        if sys.version_info >= (2, 7):\n            func = func.__func__\n        elif isinstance(func, staticmethod):\n            func = func.__get__(True)\n        else: # classmethod\n            func = func.__get__(True).im_func\n    if sys.version_info[0] >= 3:\n        return \'super\' in func.__code__.co_names\n    return \'super\' in func.func_code.co_names\n\n\nclass classhook(object):\n    """"""\n    Interpose the `hook` classes\' methods onto the target `classes`.\n\n    Note, it is also necessary to decorate these classes with @super_overridden\n    to indicate at the usage site that the super method may behave differently\n    than you expect.\n\n    The trick is that we want the hook function to call `super(ClassBeingHooked, self)`,\n    but there are potentially multiple ClassesBeingHooked. Therefore, instead\n    you must write `super(MyHookClass, self)` and the super method is replaced\n    at hook-time through bytecode modification with another one which does the\n    right thing.\n\n    Example usage:\n\n    @classhook(ROOT.TH1)\n    @super_overridden\n    class ChangeBehaviour(object):\n        def Draw(self, *args):\n            # Call the original draw function\n            result = super(ChangeBehaviour, self).Draw(*args)\n            # do something with the result here\n            return result\n    """"""\n    def overridden_super(self, target, realclass):\n        class rootpy_overridden_super(super):\n            def __init__(self, cls, *args):\n                if cls is target:\n                    cls = realclass\n                super(rootpy_overridden_super, self).__init__(cls, *args)\n        return rootpy_overridden_super\n\n    def __init__(self, *classes):\n        self.classes = classes\n\n    def hook_class(self, cls, hook):\n        # Attach a new class type with the original methods on it so that\n        # super() works as expected.\n        hookname = ""_rootpy_{0}_OrigMethods"".format(cls.__name__)\n        newcls = type(hookname, (), {})\n        cls.__bases__ = (newcls,) + cls.__bases__\n\n        # For every function-like (or property), replace `cls`\'s methods\n        for key, value in hook.__dict__.items():\n            if not isinstance(value, INTERESTING):\n                continue\n\n            # Save the original methods onto the newcls which has been\n            # injected onto our bases, so that the originals can be called with\n            # super().\n            orig_method = getattr(cls, key, None)\n            if orig_method:\n                setattr(newcls, key, orig_method)\n                #newcls.__dict__[key] = orig_method\n\n            newmeth = value\n            if uses_super(newmeth):\n                assert getattr(hook, ""__rootpy_have_super_overridden"", None), (\n                    ""Hook class {0} is not decorated with @super_overridden! ""\n                    ""See the ``hook`` module to understand why this must be ""\n                    ""the case for all classes overridden with @classhook""\n                    .format(hook))\n                # Make super behave as though the class hierarchy is what we\'d\n                # like.\n                newsuper = self.overridden_super(hook, cls)\n                newmeth = inject_closure_values(value, super=newsuper)\n            setattr(cls, key, newmeth)\n\n    def __call__(self, hook):\n        """"""\n        Hook the decorated class onto all `classes`.\n        """"""\n        for cls in self.classes:\n            self.hook_class(cls, hook)\n        return hook\n\n\nclass appendclass(object):\n    """"""\n    Append the methods/properties of `appender` onto `classes`. The methods\n    being appended must not exist on any of the target classes.\n    """"""\n    def __init__(self, *classes):\n        self.classes = classes\n\n    def __call__(self, appender):\n        for appendee in self.classes:\n            for key, value in appender.__dict__.items():\n                if not isinstance(value, INTERESTING):\n                    continue\n                assert not hasattr(appendee, key), (\n                    ""Don\'t override existing methods with appendclass"")\n                assert not uses_super(value), (""Don\'t use the super class with ""\n                    ""@appendclass, use @classhook instead"")\n                setattr(appendee, key, value)\n                continue\n        return appender\n'"
rootpy/utils/inject_closure.py,0,"b'import types\nimport sys\n\nif sys.version_info[0] >= 3:\n    from ..extern import byteplay3 as byteplay\n    if sys.version_info[1] >= 6:  # MAKE_CLOSURE removed in 3.6\n        MAKE_CLOSURE = byteplay.MAKE_FUNCTION\n    else:\n        MAKE_CLOSURE = byteplay.MAKE_CLOSURE\n    OPCODE_OFFSET = 1  # additional LOAD_CONST in 3.X\nelse:\n    from ..extern import byteplay2 as byteplay\n    MAKE_CLOSURE = byteplay.MAKE_CLOSURE\n    OPCODE_OFFSET = 0\n\nfrom ..extern.six.moves import range\n\n\ndef new_closure(vals):\n    """"""\n    Build a new closure\n    """"""\n    args = \',\'.join(\'x%i\' % i for i in range(len(vals)))\n    f = eval(""lambda %s:lambda:(%s)"" % (args, args))\n    if sys.version_info[0] >= 3:\n        return f(*vals).__closure__\n    return f(*vals).func_closure\n\n\ndef _inject_closure_values_fix_closures(c, injected, **kwargs):\n    """"""\n    Recursively fix closures\n\n    Python bytecode for a closure looks like::\n\n       LOAD_CLOSURE    var1\n       BUILD_TUPLE     <n_of_vars_closed_over>\n       LOAD_CONST      <code_object_containing_closure>\n       MAKE_CLOSURE\n\n    or this in 3.6 (MAKE_CLOSURE is no longer an opcode)::\n\n       LOAD_CLOSURE    var1\n       BUILD_TUPLE     <n_of_vars_closed_over>\n       LOAD_CONST      <code_object_containing_closure>\n       LOAD_CONST      <locals>\n       MAKE_FUNCTION\n\n    This function finds closures and adds the injected closed variables in the\n    right place.\n    """"""\n    code = c.code\n    orig_len = len(code)\n    for iback, (opcode, value) in enumerate(reversed(code)):\n        i = orig_len - iback - 1\n\n        if opcode != MAKE_CLOSURE:\n            continue\n\n        codeobj = code[i-1-OPCODE_OFFSET]\n        assert codeobj[0] == byteplay.LOAD_CONST\n\n        build_tuple = code[i-2-OPCODE_OFFSET]\n        assert build_tuple[0] == byteplay.BUILD_TUPLE\n        n_closed = build_tuple[1]\n\n        load_closures = code[i-2-OPCODE_OFFSET-n_closed:i-2-OPCODE_OFFSET]\n        assert all(o == byteplay.LOAD_CLOSURE for o, _ in load_closures)\n\n        newlcs = [(byteplay.LOAD_CLOSURE, inj) for inj in injected]\n\n        code[i-2-OPCODE_OFFSET] = byteplay.BUILD_TUPLE, n_closed + len(injected)\n        code[i-2-OPCODE_OFFSET:i-2-OPCODE_OFFSET] = newlcs\n\n        _inject_closure_values_fix_code(codeobj[1], injected, **kwargs)\n\n\ndef _inject_closure_values_fix_code(c, injected, **kwargs):\n    """"""\n    Fix code objects, recursively fixing any closures\n    """"""\n    # Add more closure variables\n    c.freevars += injected\n\n    # Replace LOAD_GLOBAL with LOAD_DEREF (fetch from closure cells)\n    # for named variables\n    for i, (opcode, value) in enumerate(c.code):\n        if opcode == byteplay.LOAD_GLOBAL and value in kwargs:\n            c.code[i] = byteplay.LOAD_DEREF, value\n\n    _inject_closure_values_fix_closures(c, injected, **kwargs)\n\n    return c\n\n\ndef _inject_closure_values(func, **kwargs):\n    for name in kwargs:\n        if sys.version_info[0] >= 3:\n            co_freevars = func.__code__.co_freevars\n        else:\n            co_freevars = func.func_code.co_freevars\n        assert name not in co_freevars, (""BUG! Tried to inject ""\n            ""closure variable where there is already a closure variable of the ""\n            ""same name: {0}"".format(name))\n\n    cellvalues = []\n    if sys.version_info[0] >= 3:\n        func_closure = func.__closure__\n        func_code = func.__code__\n        func_globals = func.__globals__\n        func_name = func.__name__\n        func_defaults = func.__defaults__\n    else:\n        func_closure = func.func_closure\n        func_code = func.func_code\n        func_globals = func.func_globals\n        func_name = func.func_name\n        func_defaults = func.func_defaults\n    if func_closure:\n        cellvalues = [c.cell_contents for c in func_closure]\n\n    injected = tuple(sorted(kwargs))\n    # Insert the closure values into the new cells\n    cellvalues.extend(kwargs[key] for key in injected)\n\n    c = byteplay.Code.from_code(func_code)\n\n    _inject_closure_values_fix_code(c, injected, **kwargs)\n\n    code = c.to_code()\n    closure = new_closure(cellvalues)\n\n    args = code, func_globals, func_name, func_defaults, closure\n    return types.FunctionType(*args)\n\n\ndef inject_closure_values(func, **kwargs):\n    """"""\n    Returns a new function identical to the previous one except that it acts as\n    though global variables named in `kwargs` have been closed over with the\n    values specified in the `kwargs` dictionary.\n\n    Works on properties, class/static methods and functions.\n\n    This can be useful for mocking and other nefarious activities.\n    """"""\n    wrapped_by = None\n\n    if isinstance(func, property):\n        fget, fset, fdel = func.fget, func.fset, func.fdel\n        if fget: fget = fix_func(fget, **kwargs)\n        if fset: fset = fix_func(fset, **kwargs)\n        if fdel: fdel = fix_func(fdel, **kwargs)\n        wrapped_by = type(func)\n        return wrapped_by(fget, fset, fdel)\n\n    elif isinstance(func, (staticmethod, classmethod)):\n        func = func.__func__\n        wrapped_by = type(func)\n\n    newfunc = _inject_closure_values(func, **kwargs)\n\n    if wrapped_by:\n        newfunc = wrapped_by(newfunc)\n    return newfunc\n'"
rootpy/utils/lock.py,0,"b'from __future__ import absolute_import\n\nimport os\nimport stat\nimport time\nimport platform\nfrom contextlib import contextmanager\n\nfrom ..extern.lockfile import LockFile, LockTimeout\nfrom . import log; log = log[__name__]\n\n__all__ = [\n    \'lock\',\n]\n\n\n@contextmanager\ndef lock(path, poll_interval=5, max_age=60):\n    """"""\n    Aquire a file lock in a thread-safe manner that also reaps stale locks\n    possibly left behind by processes that crashed hard.\n    """"""\n    if max_age < 30:\n        raise ValueError(""`max_age` must be at least 30 seconds"")\n    if poll_interval < 1:\n        raise ValueError(""`poll_interval` must be at least 1 second"")\n    if poll_interval >= max_age:\n        raise ValueError(""`poll_interval` must be less than `max_age`"")\n    proc = \'{0:d}@{1}\'.format(os.getpid(), platform.node())\n    lock = LockFile(path)\n    log.debug(""{0} attempting to lock {1}"".format(proc, path))\n    while not lock.i_am_locking():\n        if lock.is_locked():\n            # Protect against race condition\n            try:\n                # Check age of the lock file\n                age = time.time() - os.stat(lock.lock_file)[stat.ST_MTIME]\n                # Break the lock if too old (considered stale)\n                if age > max_age:\n                    lock.break_lock()\n                    # What if lock was released and reacquired in the meantime?\n                    # We don\'t want to break a fresh lock!\n                    # If a lock is stale then we may have many threads\n                    # attempting to break it here at the ""same time"".\n                    # Avoid the possibility of some thread trying to break the\n                    # lock after it has already been broken and after the first\n                    # other thread attempting to acquire the lock by sleeping\n                    # for 0.5 seconds below.\n                    log.warning(\n                        ""{0} broke lock on {1} ""\n                        ""that is {2:d} seconds old"".format(\n                            proc, path, int(age)))\n            except OSError:\n                # Lock was released just now\n                # os.path.exists(lock.lock_file) is False\n                # OSError may be raised by os.stat() or lock.break_lock() above\n                pass\n        time.sleep(0.5)\n        try:\n            log.debug(\n                ""{0} waiting for {1:d} seconds ""\n                ""for lock on {2} to be released"".format(\n                    proc, poll_interval, path))\n            # Use float() here since acquire sleeps for timeout/10\n            lock.acquire(timeout=float(poll_interval))\n        except LockTimeout:\n            pass\n    log.debug(""{0} locked {1}"".format(proc, path))\n    yield lock\n    lock.release()\n    log.debug(""{0} released lock on {1}"".format(proc, path))\n'"
rootpy/utils/module_facade.py,0,"b'import sys\n\nfrom inspect import getfile\nfrom types import ModuleType\n\nfrom .. import log; log = log[__name__]\n\nlog.show_stack(limit=2)\n\n\nclass computed_once_classproperty(property):\n    """"""\n    A property whose value is computed exactly once, then saved onto the target\n    class.\n    """"""\n    def __get__(self, object_, type_=None):\n        result = super(computed_once_classproperty, self).__get__(object_, type_)\n        propname = self.fget.__name__\n        # Remove the property from the class itself\n        setattr(type_, propname, result)\n        return result\n\n\nclass ModuleFacade(object):\n    def __repr__(self):\n        orig = super(ModuleFacade, self).__repr__()\n        return ""{0}({1})"".format(type(self).__name__, orig)\n\n\nclass Facade(object):\n\n    def __init__(self, name, **kwargs):\n        """"""\n        Use kwargs to force user to write them out for explicitness.\n        """"""\n        self.name = name\n        _, _, self.name_lastpart = name.rpartition(""."")\n        self.expose_internal = kwargs.pop(""expose_internal"", True)\n        self.submodule = kwargs.pop(""submodule"", False)\n\n    def __call__(self, cls):\n        """"""\n        Decorate `cls`\n        """"""\n        expose_internal = self.expose_internal\n\n        if self.submodule:\n            self.name += ""."" + cls.__name__\n\n        if self.name not in sys.modules:\n            orig = ModuleType(self.name)\n            orig.__name__ = self.name\n            orig.__file__ = getfile(cls)\n        else:\n            orig = sys.modules[self.name]\n\n        if isinstance(orig, ModuleFacade):\n            raise TypeError(""Facade() used inside module which is already ""\n                              ""wrapped - only once Facade() allowed per module.""\n                              "" inside {0}"".format(orig))\n\n        class _wrapper_cls(cls, ModuleFacade, ModuleType, object):\n            _facade_wrapped = orig\n            _facade_cls = cls\n\n            def __dir__(self):\n                items = set()\n                items.update(self.__dict__)\n                items.update(self._facade_cls.__dict__)\n\n                if hasattr(self._facade_cls, ""__dir__""):\n                    items.update(self._facade_cls.__dir__(self))\n\n                if expose_internal:\n                    items.update(orig.__dict__)\n\n                return sorted(items)\n\n            def __getattr__(self, key):\n                if expose_internal and hasattr(orig, key):\n                    return getattr(orig, key)\n                sup = super(_wrapper_cls, self)\n                if hasattr(sup, ""__getattr__""):\n                    result = sup.__getattr__(key)\n                    if result is not None:\n                        return result\n                raise AttributeError(""\'{0}\' object has no attribute \'{1}\'""\n                    .format(self, key))\n\n        _wrapper_cls.__name__ = ""ModuleFacade({0})"".format(cls.__name__)\n        inst = _wrapper_cls(self.name)\n        sys.modules[self.name] = inst\n\n        for key in ""__name__ __doc__ __file__ __path__"".split():\n            if hasattr(orig, key):\n                setattr(inst, key, getattr(orig, key))\n\n        return inst\n'"
rootpy/utils/path.py,0,"b'from __future__ import absolute_import\n\nimport glob\nimport os\nimport errno\n\n__all__ = [\n    \'expand\',\n    \'expand_and_glob\',\n    \'expand_and_glob_all\',\n    \'mkdir_p\',\n]\n\n\ndef expand(s):\n    return os.path.expanduser(os.path.expandvars(s))\n\n\ndef expand_and_glob(s):\n    return glob.glob(expand(s))\n\n\ndef expand_and_glob_all(s):\n    files = []\n    for name in s:\n        files += expand_and_glob(name)\n    return files\n\n\ndef mkdir_p(path):\n    """"""\n    mkdir -p functionality\n    http://stackoverflow.com/questions/600268/mkdir-p-functionality-in-python\n\n    In rootpy, this function should be used when creating directories in a\n    multithreaded environment to avoid race conditions when checking if a\n    directory exists before creating it.\n    """"""\n    try:\n        os.makedirs(path)\n    except OSError as exc:\n        if exc.errno == errno.EEXIST and os.path.isdir(path):\n            pass\n        else:\n            raise\n'"
rootpy/utils/quickroot.py,0,"b'""""""\nQuickly load ROOT symbols without triggering PyROOT\'s finalSetup().\nThe main principle is that appropriate dictionaries first need to be loaded.\n""""""\nfrom __future__ import absolute_import\n\nimport ROOT\n\nfrom .. import log; log = log[__name__]\nfrom .module_facade import Facade\n\n__all__ = []\n\n\nroot_module = ROOT.module._root\nif hasattr(root_module, \'LookupCppEntity\'):  # pragma: no cover\n    lookup_func = \'LookupCppEntity\'\nelse:  # pragma: no cover\n    lookup_func = \'LookupRootEntity\'\n\n# Quick\'s __name__ needs to be the ROOT module for this to be transparent.\n# The below is one way of obtaining such a function\n# First determine the ROOT version without triggering PyROOT\'s finalSetup()\nQuick = eval(\'lambda symbol: module._root.{0}(symbol)\'.format(lookup_func),\n             ROOT.__dict__)\n\n_gSystem = Quick(""gSystem"")\nLoad = _gSystem.Load\n\n# It is not vital to list _all_ symbols in here, just enough that a library\n# will be loaded by the time it is needed.\nSYMBOLS = dict(\n    Hist=\'TH1 TGraph TGraphAsymmErrors\',\n    Tree=\'TCut TTree\',\n    Gui=\'TPad TCanvas\',\n    Graf=\'TLegend TLine TEllipse\',\n    Physics=\'TVector2 TVector3 TLorentzVector TRotation TLorentzRotation\',\n    Matrix=\'TMatrixT\',\n    RooStats=\'RooStats RooMsgService\',\n    RooFit=\'RooFit RooWorkspace\',\n)\n\n# Mapping of symbols to libraries which need to be loaded\nSYMBOLS_TO_LIB = dict(\n    (sym, lib) for lib, syms in SYMBOLS.items() for sym in syms.split())\n\n# If you encounter problems with particular symbols, add them to this set.\nSLOW = set("""".split())\n\n\n@Facade(__name__, expose_internal=False)\nclass QuickROOT(object):\n    def __getattr__(self, symbol):\n        if symbol in SLOW:  # pragma: no cover\n            log.warning(\n                ""Tried to quickly load {0} which is always slow"".format(symbol))\n\n        lib = SYMBOLS_TO_LIB.get(symbol, None)\n        if lib:\n            # Load() doesn\'t cost anything if the library is already loaded\n            libname = ""lib{0}"".format(lib)\n            if libname not in _gSystem.GetLibraries():\n                regex = ""^duplicate entry .* for level 0; ignored$""\n                with log[""/ROOT.TEnvRec.ChangeValue""].ignore(regex):\n                    if Load(libname) == 0:\n                        log.debug(""Loaded {0} (required by {1})"".format(\n                            libname, symbol))\n                    elif lib == \'Gui\':\n                        # Possibly no X11 forwarding\n                        log.debug(""Unable to load {0} (required by {1}). ""\n                                  ""Putting ROOT in batch mode."".format(\n                            libname, symbol))\n                        ROOT.gROOT.SetBatch(True)\n                    else: # pragma: no cover\n                        raise RuntimeError(\n                            ""Unable to load {0} (required by {1})"".format(\n                                libname, symbol))\n\n        try:\n            thing = Quick(symbol)\n        except NameError:  # pragma: no cover\n            # NameError: global name \'module\' is not defined\n            # Python must be exiting...\n            return None\n        if isinstance(thing, root_module.PropertyProxy):  # descriptor\n            setattr(self.__class__, symbol, thing)\n            return getattr(self, symbol)\n        # normal member\n        return thing\n'"
rootpy/utils/silence.py,0,"b'""""""\nThis module provides context managers for silencing output from external\ncompiled libraries on stdout, stderr, or both. Probably the most common use\nis to completely silence output on stdout and/or stderr with the\n`silence_sout_serr` function.\n\n.. warning::\n    There is the possibility that normal output may not be restored to the\n    output stream and content may be unintentionally silenced. Only use these\n    functions if you absolutely need them and beware of using them in large\n    frameworks where debugging may be difficult if problems do occur.\n\n""""""\nfrom contextlib import contextmanager\nimport os\nimport sys\nimport threading\nLOCK = threading.RLock()\n\n__all__ = [\n    \'silence_sout\',\n    \'silence_serr\',\n    \'silence_sout_serr\',\n]\n\n\n@contextmanager\ndef silence_sout():\n    LOCK.acquire()\n    sys.__stdout__.flush()\n    origstdout = sys.__stdout__\n    oldstdout_fno = os.dup(sys.__stdout__.fileno())\n    devnull = os.open(os.devnull, os.O_WRONLY)\n    newstdout = os.dup(1)\n    os.dup2(devnull, 1)\n    os.close(devnull)\n    sys.__stdout__ = os.fdopen(newstdout, \'w\')\n    try:\n        yield\n    finally:\n        sys.__stdout__ = origstdout\n        sys.__stdout__.flush()\n        os.dup2(oldstdout_fno, 1)\n        LOCK.release()\n\n\n@contextmanager\ndef silence_serr():\n    LOCK.acquire()\n    sys.__stderr__.flush()\n    origstderr = sys.__stderr__\n    oldstderr_fno = os.dup(sys.__stderr__.fileno())\n    devnull = os.open(os.devnull, os.O_WRONLY)\n    newstderr = os.dup(2)\n    os.dup2(devnull, 2)\n    os.close(devnull)\n    sys.__stderr__ = os.fdopen(newstderr, \'w\')\n    try:\n        yield\n    finally:\n        sys.__stderr__ = origstderr\n        sys.__stderr__.flush()\n        os.dup2(oldstderr_fno, 2)\n        LOCK.release()\n\n\n@contextmanager\ndef silence_sout_serr():\n    with silence_sout():\n        with silence_serr():\n            yield\n'"
rootpy/extern/byteplay2/__init__.py,0,"b'# byteplay - Python bytecode assembler/disassembler.\n# Copyright (C) 2006-2010 Noam Yorav-Raphael\n# Homepage: http://code.google.com/p/byteplay\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n#\n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA\n\n# Many thanks to Greg X for adding support for Python 2.6 and 2.7!\n\n__version__ = \'0.2\'\n\n__all__ = [\'opmap\', \'opname\', \'opcodes\',\n           \'cmp_op\', \'hasarg\', \'hasname\', \'hasjrel\', \'hasjabs\',\n           \'hasjump\', \'haslocal\', \'hascompare\', \'hasfree\', \'hascode\',\n           \'hasflow\', \'getse\',\n           \'Opcode\', \'SetLineno\', \'Label\', \'isopcode\', \'Code\',\n           \'CodeList\', \'printcodelist\']\n\nimport opcode\nfrom dis import findlabels\nimport types\nfrom array import array\nimport operator\nimport itertools\nimport sys\nimport warnings\nfrom cStringIO import StringIO\n\n######################################################################\n# Define opcodes and information about them\n\npython_version = \'.\'.join(str(x) for x in sys.version_info[:2])\nif python_version not in (\'2.4\', \'2.5\', \'2.6\', \'2.7\'):\n    warnings.warn(""byteplay doesn\'t support Python version ""+python_version)\n\nclass Opcode(int):\n    """"""An int which represents an opcode - has a nicer repr.""""""\n    def __repr__(self):\n        return opname[self]\n    __str__ = __repr__\n\nclass CodeList(list):\n    """"""A list for storing opcode tuples - has a nicer __str__.""""""\n    def __str__(self):\n        f = StringIO()\n        printcodelist(self, f)\n        return f.getvalue()\n\nopmap = dict((name.replace(\'+\', \'_\'), Opcode(code))\n             for name, code in opcode.opmap.iteritems()\n             if name != \'EXTENDED_ARG\')\nopname = dict((code, name) for name, code in opmap.iteritems())\nopcodes = set(opname)\n\ndef globalize_opcodes():\n    for name, code in opmap.iteritems():\n        globals()[name] = code\n        __all__.append(name)\nglobalize_opcodes()\n\ncmp_op = opcode.cmp_op\n\nhasarg = set(x for x in opcodes if x >= opcode.HAVE_ARGUMENT)\nhasconst = set(Opcode(x) for x in opcode.hasconst)\nhasname = set(Opcode(x) for x in opcode.hasname)\nhasjrel = set(Opcode(x) for x in opcode.hasjrel)\nhasjabs = set(Opcode(x) for x in opcode.hasjabs)\nhasjump = hasjrel.union(hasjabs)\nhaslocal = set(Opcode(x) for x in opcode.haslocal)\nhascompare = set(Opcode(x) for x in opcode.hascompare)\nhasfree = set(Opcode(x) for x in opcode.hasfree)\nhascode = set([MAKE_FUNCTION, MAKE_CLOSURE])\n\nclass _se:\n    """"""Quick way of defining static stack effects of opcodes""""""\n    # Taken from assembler.py by Phillip J. Eby\n    NOP       = 0,0\n\n    POP_TOP   = 1,0\n    ROT_TWO   = 2,2\n    ROT_THREE = 3,3\n    ROT_FOUR  = 4,4\n    DUP_TOP   = 1,2\n\n    UNARY_POSITIVE = UNARY_NEGATIVE = UNARY_NOT = UNARY_CONVERT = \\\n        UNARY_INVERT = GET_ITER = LOAD_ATTR = 1,1\n\n    IMPORT_FROM = 1,2\n\n    BINARY_POWER = BINARY_MULTIPLY = BINARY_DIVIDE = BINARY_FLOOR_DIVIDE = \\\n        BINARY_TRUE_DIVIDE = BINARY_MODULO = BINARY_ADD = BINARY_SUBTRACT = \\\n        BINARY_SUBSCR = BINARY_LSHIFT = BINARY_RSHIFT = BINARY_AND = \\\n        BINARY_XOR = BINARY_OR = COMPARE_OP = 2,1\n\n    INPLACE_POWER = INPLACE_MULTIPLY = INPLACE_DIVIDE = \\\n        INPLACE_FLOOR_DIVIDE = INPLACE_TRUE_DIVIDE = INPLACE_MODULO = \\\n        INPLACE_ADD = INPLACE_SUBTRACT = INPLACE_LSHIFT = INPLACE_RSHIFT = \\\n        INPLACE_AND = INPLACE_XOR = INPLACE_OR = 2,1\n\n    SLICE_0, SLICE_1, SLICE_2, SLICE_3 = \\\n        (1,1),(2,1),(2,1),(3,1)\n    STORE_SLICE_0, STORE_SLICE_1, STORE_SLICE_2, STORE_SLICE_3 = \\\n        (2,0),(3,0),(3,0),(4,0)\n    DELETE_SLICE_0, DELETE_SLICE_1, DELETE_SLICE_2, DELETE_SLICE_3 = \\\n        (1,0),(2,0),(2,0),(3,0)\n\n    STORE_SUBSCR = 3,0\n    DELETE_SUBSCR = STORE_ATTR = 2,0\n    DELETE_ATTR = STORE_DEREF = 1,0\n    PRINT_NEWLINE = 0,0\n    PRINT_EXPR = PRINT_ITEM = PRINT_NEWLINE_TO = IMPORT_STAR = 1,0\n    STORE_NAME = STORE_GLOBAL = STORE_FAST = 1,0\n    PRINT_ITEM_TO = 2,0\n\n    LOAD_LOCALS = LOAD_CONST = LOAD_NAME = LOAD_GLOBAL = LOAD_FAST = \\\n        LOAD_CLOSURE = LOAD_DEREF = BUILD_MAP = 0,1\n\n    DELETE_FAST = DELETE_GLOBAL = DELETE_NAME = 0,0\n\n    EXEC_STMT = 3,0\n    BUILD_CLASS = 3,1\n\n    STORE_MAP = MAP_ADD = 2,0\n    SET_ADD = 1,0\n\n    if   python_version == \'2.4\':\n      YIELD_VALUE = 1,0\n      IMPORT_NAME = 1,1\n      LIST_APPEND = 2,0\n    elif python_version == \'2.5\':\n      YIELD_VALUE = 1,1\n      IMPORT_NAME = 2,1\n      LIST_APPEND = 2,0\n    elif python_version == \'2.6\':\n      YIELD_VALUE = 1,1\n      IMPORT_NAME = 2,1\n      LIST_APPEND = 2,0\n    elif python_version == \'2.7\':\n      YIELD_VALUE = 1,1\n      IMPORT_NAME = 2,1\n      LIST_APPEND = 1,0\n\n\n_se = dict((op, getattr(_se, opname[op]))\n           for op in opcodes\n           if hasattr(_se, opname[op]))\n\nhasflow = opcodes - set(_se) - \\\n          set([CALL_FUNCTION, CALL_FUNCTION_VAR, CALL_FUNCTION_KW,\n               CALL_FUNCTION_VAR_KW, BUILD_TUPLE, BUILD_LIST,\n               UNPACK_SEQUENCE, BUILD_SLICE, DUP_TOPX,\n               RAISE_VARARGS, MAKE_FUNCTION, MAKE_CLOSURE])\nif python_version == \'2.7\':\n  hasflow = hasflow - set([BUILD_SET])\n\ndef getse(op, arg=None):\n    """"""Get the stack effect of an opcode, as a (pop, push) tuple.\n\n    If an arg is needed and is not given, a ValueError is raised.\n    If op isn\'t a simple opcode, that is, the flow doesn\'t always continue\n    to the next opcode, a ValueError is raised.\n    """"""\n    try:\n        return _se[op]\n    except KeyError:\n        # Continue to opcodes with an effect that depends on arg\n        pass\n\n    if arg is None:\n        raise ValueError(""Opcode stack behaviour depends on arg"")\n\n    def get_func_tup(arg, nextra):\n        if arg > 0xFFFF:\n            raise ValueError(""Can only split a two-byte argument"")\n        return (nextra + 1 + (arg & 0xFF) + 2*((arg >> 8) & 0xFF),\n                1)\n\n    if op == CALL_FUNCTION:\n        return get_func_tup(arg, 0)\n    elif op == CALL_FUNCTION_VAR:\n        return get_func_tup(arg, 1)\n    elif op == CALL_FUNCTION_KW:\n        return get_func_tup(arg, 1)\n    elif op == CALL_FUNCTION_VAR_KW:\n        return get_func_tup(arg, 2)\n\n    elif op == BUILD_TUPLE:\n        return arg, 1\n    elif op == BUILD_LIST:\n        return arg, 1\n    elif python_version == \'2.7\' and op == BUILD_SET:\n        return arg, 1\n    elif op == UNPACK_SEQUENCE:\n        return 1, arg\n    elif op == BUILD_SLICE:\n        return arg, 1\n    elif op == DUP_TOPX:\n        return arg, arg*2\n    elif op == RAISE_VARARGS:\n        return 1+arg, 1\n    elif op == MAKE_FUNCTION:\n        return 1+arg, 1\n    elif op == MAKE_CLOSURE:\n        if python_version == \'2.4\':\n            raise ValueError(""The stack effect of MAKE_CLOSURE depends on TOS"")\n        else:\n            return 2+arg, 1\n    else:\n        raise ValueError(""The opcode %r isn\'t recognized or has a special ""\n                         ""flow control"" % op)\n\nclass SetLinenoType(object):\n    def __repr__(self):\n        return \'SetLineno\'\nSetLineno = SetLinenoType()\n\nclass Label(object):\n    pass\n\ndef isopcode(obj):\n    """"""Return whether obj is an opcode - not SetLineno or Label""""""\n    return obj is not SetLineno and not isinstance(obj, Label)\n\n# Flags from code.h\nCO_OPTIMIZED              = 0x0001      # use LOAD/STORE_FAST instead of _NAME\nCO_NEWLOCALS              = 0x0002      # only cleared for module/exec code\nCO_VARARGS                = 0x0004\nCO_VARKEYWORDS            = 0x0008\nCO_NESTED                 = 0x0010      # ???\nCO_GENERATOR              = 0x0020\nCO_NOFREE                 = 0x0040      # set if no free or cell vars\nCO_GENERATOR_ALLOWED      = 0x1000      # unused\n# The future flags are only used on code generation, so we can ignore them.\n# (It does cause some warnings, though.)\nCO_FUTURE_DIVISION        = 0x2000\nCO_FUTURE_ABSOLUTE_IMPORT = 0x4000\nCO_FUTURE_WITH_STATEMENT  = 0x8000\n\n\n######################################################################\n# Define the Code class\n\nclass Code(object):\n    """"""An object which holds all the information which a Python code object\n    holds, but in an easy-to-play-with representation.\n\n    The attributes are:\n\n    Affecting action\n    ----------------\n    code - list of 2-tuples: the code\n    freevars - list of strings: the free vars of the code (those are names\n               of variables created in outer functions and used in the function)\n    args - list of strings: the arguments of the code\n    varargs - boolean: Does args end with a \'*args\' argument\n    varkwargs - boolean: Does args end with a \'**kwargs\' argument\n    newlocals - boolean: Should a new local namespace be created.\n                (True in functions, False for module and exec code)\n\n    Not affecting action\n    --------------------\n    name - string: the name of the code (co_name)\n    filename - string: the file name of the code (co_filename)\n    firstlineno - int: the first line number (co_firstlineno)\n    docstring - string or None: the docstring (the first item of co_consts,\n                if it\'s str or unicode)\n\n    code is a list of 2-tuples. The first item is an opcode, or SetLineno, or a\n    Label instance. The second item is the argument, if applicable, or None.\n    code can be a CodeList instance, which will produce nicer output when\n    being printed.\n    """"""\n    def __init__(self, code, freevars, args, varargs, varkwargs, newlocals,\n                 name, filename, firstlineno, docstring):\n        self.code = code\n        self.freevars = freevars\n        self.args = args\n        self.varargs = varargs\n        self.varkwargs = varkwargs\n        self.newlocals = newlocals\n        self.name = name\n        self.filename = filename\n        self.firstlineno = firstlineno\n        self.docstring = docstring\n\n    @staticmethod\n    def _findlinestarts(code):\n        """"""Find the offsets in a byte code which are start of lines in the\n        source.\n\n        Generate pairs (offset, lineno) as described in Python/compile.c.\n\n        This is a modified version of dis.findlinestarts, which allows multiple\n        ""line starts"" with the same line number.\n        """"""\n        byte_increments = [ord(c) for c in code.co_lnotab[0::2]]\n        line_increments = [ord(c) for c in code.co_lnotab[1::2]]\n\n        lineno = code.co_firstlineno\n        addr = 0\n        for byte_incr, line_incr in zip(byte_increments, line_increments):\n            if byte_incr:\n                yield (addr, lineno)\n                addr += byte_incr\n            lineno += line_incr\n        yield (addr, lineno)\n\n    @classmethod\n    def from_code(cls, co):\n        """"""Disassemble a Python code object into a Code object.""""""\n        co_code = co.co_code\n        labels = dict((addr, Label()) for addr in findlabels(co_code))\n        linestarts = dict(cls._findlinestarts(co))\n        cellfree = co.co_cellvars + co.co_freevars\n\n        code = CodeList()\n        n = len(co_code)\n        i = 0\n        extended_arg = 0\n        while i < n:\n            op = Opcode(ord(co_code[i]))\n            if i in labels:\n                code.append((labels[i], None))\n            if i in linestarts:\n                code.append((SetLineno, linestarts[i]))\n            i += 1\n            if op in hascode:\n                lastop, lastarg = code[-1]\n                if lastop != LOAD_CONST:\n                    raise ValueError(\n                        ""%s should be preceded by LOAD_CONST code"" % op)\n                code[-1] = (LOAD_CONST, Code.from_code(lastarg))\n            if op not in hasarg:\n                code.append((op, None))\n            else:\n                arg = ord(co_code[i]) + ord(co_code[i+1])*256 + extended_arg\n                extended_arg = 0\n                i += 2\n                if op == opcode.EXTENDED_ARG:\n                    extended_arg = arg << 16\n                elif op in hasconst:\n                    code.append((op, co.co_consts[arg]))\n                elif op in hasname:\n                    code.append((op, co.co_names[arg]))\n                elif op in hasjabs:\n                    code.append((op, labels[arg]))\n                elif op in hasjrel:\n                    code.append((op, labels[i + arg]))\n                elif op in haslocal:\n                    code.append((op, co.co_varnames[arg]))\n                elif op in hascompare:\n                    code.append((op, cmp_op[arg]))\n                elif op in hasfree:\n                    code.append((op, cellfree[arg]))\n                else:\n                    code.append((op, arg))\n\n        varargs = bool(co.co_flags & CO_VARARGS)\n        varkwargs = bool(co.co_flags & CO_VARKEYWORDS)\n        newlocals = bool(co.co_flags & CO_NEWLOCALS)\n        args = co.co_varnames[:co.co_argcount + varargs + varkwargs]\n        if co.co_consts and isinstance(co.co_consts[0], basestring):\n            docstring = co.co_consts[0]\n        else:\n            docstring = None\n        return cls(code = code,\n                   freevars = co.co_freevars,\n                   args = args,\n                   varargs = varargs,\n                   varkwargs = varkwargs,\n                   newlocals = newlocals,\n                   name = co.co_name,\n                   filename = co.co_filename,\n                   firstlineno = co.co_firstlineno,\n                   docstring = docstring,\n                   )\n\n    def __eq__(self, other):\n        if (self.freevars != other.freevars or\n            self.args != other.args or\n            self.varargs != other.varargs or\n            self.varkwargs != other.varkwargs or\n            self.newlocals != other.newlocals or\n            self.name != other.name or\n            self.filename != other.filename or\n            self.firstlineno != other.firstlineno or\n            self.docstring != other.docstring or\n            len(self.code) != len(other.code)\n            ):\n            return False\n\n        # Compare code. This isn\'t trivial because labels should be matching,\n        # not equal.\n        labelmapping = {}\n        for (op1, arg1), (op2, arg2) in itertools.izip(self.code, other.code):\n            if isinstance(op1, Label):\n                if labelmapping.setdefault(op1, op2) is not op2:\n                    return False\n            else:\n                if op1 != op2:\n                    return False\n                if op1 in hasjump:\n                    if labelmapping.setdefault(arg1, arg2) is not arg2:\n                        return False\n                elif op1 in hasarg:\n                    if arg1 != arg2:\n                        return False\n        return True\n\n    def _compute_flags(self):\n        opcodes = set(op for op, arg in self.code if isopcode(op))\n\n        optimized = (STORE_NAME not in opcodes and\n                     LOAD_NAME not in opcodes and\n                     DELETE_NAME not in opcodes)\n        generator = (YIELD_VALUE in opcodes)\n        nofree = not (opcodes.intersection(hasfree))\n\n        flags = 0\n        if optimized: flags |= CO_OPTIMIZED\n        if self.newlocals: flags |= CO_NEWLOCALS\n        if self.varargs: flags |= CO_VARARGS\n        if self.varkwargs: flags |= CO_VARKEYWORDS\n        if generator: flags |= CO_GENERATOR\n        if nofree: flags |= CO_NOFREE\n        return flags\n\n    def _compute_stacksize(self):\n        """"""Get a code list, compute its maximal stack usage.""""""\n        # This is done by scanning the code, and computing for each opcode\n        # the stack state at the opcode.\n        code = self.code\n\n        # A mapping from labels to their positions in the code list\n        label_pos = dict((op, pos)\n                         for pos, (op, arg) in enumerate(code)\n                         if isinstance(op, Label))\n\n        # sf_targets are the targets of SETUP_FINALLY opcodes. They are recorded\n        # because they have special stack behaviour. If an exception was raised\n        # in the block pushed by a SETUP_FINALLY opcode, the block is popped\n        # and 3 objects are pushed. On return or continue, the block is popped\n        # and 2 objects are pushed. If nothing happened, the block is popped by\n        # a POP_BLOCK opcode and 1 object is pushed by a (LOAD_CONST, None)\n        # operation.\n        #\n        # Our solution is to record the stack state of SETUP_FINALLY targets\n        # as having 3 objects pushed, which is the maximum. However, to make\n        # stack recording consistent, the get_next_stacks function will always\n        # yield the stack state of the target as if 1 object was pushed, but\n        # this will be corrected in the actual stack recording.\n\n        sf_targets = set(label_pos[arg]\n                         for op, arg in code\n                         if op == SETUP_FINALLY)\n\n        # What we compute - for each opcode, its stack state, as an n-tuple.\n        # n is the number of blocks pushed. For each block, we record the number\n        # of objects pushed.\n        stacks = [None] * len(code)\n\n        def get_next_stacks(pos, curstack):\n            """"""Get a code position and the stack state before the operation\n            was done, and yield pairs (pos, curstack) for the next positions\n            to be explored - those are the positions to which you can get\n            from the given (pos, curstack).\n\n            If the given position was already explored, nothing will be yielded.\n            """"""\n            op, arg = code[pos]\n\n            if isinstance(op, Label):\n                # We should check if we already reached a node only if it is\n                # a label.\n                if pos in sf_targets:\n                    curstack = curstack[:-1] + (curstack[-1] + 2,)\n                if stacks[pos] is None:\n                    stacks[pos] = curstack\n                else:\n                    if stacks[pos] != curstack:\n                        raise ValueError(""Inconsistent code"")\n                    return\n\n            def newstack(n):\n                # Return a new stack, modified by adding n elements to the last\n                # block\n                if curstack[-1] + n < 0:\n                    raise ValueError(""Popped a non-existing element"")\n                return curstack[:-1] + (curstack[-1]+n,)\n\n            if not isopcode(op):\n                # label or SetLineno - just continue to next line\n                yield pos+1, curstack\n\n            elif op in (STOP_CODE, RETURN_VALUE, RAISE_VARARGS):\n                # No place in particular to continue to\n                pass\n\n            elif op == MAKE_CLOSURE and python_version == \'2.4\':\n                # This is only relevant in Python 2.4 - in Python 2.5 the stack\n                # effect of MAKE_CLOSURE can be calculated from the arg.\n                # In Python 2.4, it depends on the number of freevars of TOS,\n                # which should be a code object.\n                if pos == 0:\n                    raise ValueError(""MAKE_CLOSURE can\'t be the first opcode"")\n                lastop, lastarg = code[pos-1]\n                if lastop != LOAD_CONST:\n                    raise ValueError(\n                        ""MAKE_CLOSURE should come after a LOAD_CONST op"")\n                try:\n                    nextrapops = len(lastarg.freevars)\n                except AttributeError:\n                    try:\n                        nextrapops = len(lastarg.co_freevars)\n                    except AttributeError:\n                        raise ValueError(\n                            ""MAKE_CLOSURE preceding const should ""\n                            ""be a code or a Code object"")\n\n                yield pos+1, newstack(-arg-nextrapops)\n\n            elif op not in hasflow:\n                # Simple change of stack\n                pop, push = getse(op, arg)\n                yield pos+1, newstack(push - pop)\n\n            elif op in (JUMP_FORWARD, JUMP_ABSOLUTE):\n                # One possibility for a jump\n                yield label_pos[arg], curstack\n\n            elif python_version < \'2.7\' and op in (JUMP_IF_FALSE, JUMP_IF_TRUE):\n                # Two possibilities for a jump\n                yield label_pos[arg], curstack\n                yield pos+1, curstack\n\n            elif python_version >= \'2.7\' and op in (POP_JUMP_IF_FALSE, POP_JUMP_IF_TRUE):\n                # Two possibilities for a jump\n                yield label_pos[arg], newstack(-1)\n                yield pos+1, newstack(-1)\n\n            elif python_version >= \'2.7\' and op in (JUMP_IF_TRUE_OR_POP, JUMP_IF_FALSE_OR_POP):\n                # Two possibilities for a jump\n                yield label_pos[arg], curstack\n                yield pos+1, newstack(-1)\n\n            elif op == FOR_ITER:\n                # FOR_ITER pushes next(TOS) on success, and pops TOS and jumps\n                # on failure\n                yield label_pos[arg], newstack(-1)\n                yield pos+1, newstack(1)\n\n            elif op == BREAK_LOOP:\n                # BREAK_LOOP jumps to a place specified on block creation, so\n                # it is ignored here\n                pass\n\n            elif op == CONTINUE_LOOP:\n                # CONTINUE_LOOP jumps to the beginning of a loop which should\n                # already ave been discovered, but we verify anyway.\n                # It pops a block.\n                if python_version == \'2.6\':\n                  pos, stack = label_pos[arg], curstack[:-1]\n                  if stacks[pos] != stack: #this could be a loop with a \'with\' inside\n                    yield pos, stack[:-1] + (stack[-1]-1,)\n                  else:\n                    yield pos, stack\n                else:\n                  yield label_pos[arg], curstack[:-1]\n\n            elif op == SETUP_LOOP:\n                # We continue with a new block.\n                # On break, we jump to the label and return to current stack\n                # state.\n                yield label_pos[arg], curstack\n                yield pos+1, curstack + (0,)\n\n            elif op == SETUP_EXCEPT:\n                # We continue with a new block.\n                # On exception, we jump to the label with 3 extra objects on\n                # stack\n                yield label_pos[arg], newstack(3)\n                yield pos+1, curstack + (0,)\n\n            elif op == SETUP_FINALLY:\n                # We continue with a new block.\n                # On exception, we jump to the label with 3 extra objects on\n                # stack, but to keep stack recording consistent, we behave as\n                # if we add only 1 object. Extra 2 will be added to the actual\n                # recording.\n                yield label_pos[arg], newstack(1)\n                yield pos+1, curstack + (0,)\n\n            elif python_version == \'2.7\' and op == SETUP_WITH:\n                yield label_pos[arg], curstack\n                yield pos+1, newstack(-1) + (1,)\n\n            elif op == POP_BLOCK:\n                # Just pop the block\n                yield pos+1, curstack[:-1]\n\n            elif op == END_FINALLY:\n                # Since stack recording of SETUP_FINALLY targets is of 3 pushed\n                # objects (as when an exception is raised), we pop 3 objects.\n                yield pos+1, newstack(-3)\n\n            elif op == WITH_CLEANUP:\n                # Since WITH_CLEANUP is always found after SETUP_FINALLY\n                # targets, and the stack recording is that of a raised\n                # exception, we can simply pop 1 object and let END_FINALLY\n                # pop the remaining 3.\n                if python_version == \'2.7\':\n                  yield pos+1, newstack(2)\n                else:\n                  yield pos+1, newstack(-1)\n\n            else:\n                assert False, ""Unhandled opcode: %r"" % op\n\n\n        # Now comes the calculation: open_positions holds positions which are\n        # yet to be explored. In each step we take one open position, and\n        # explore it by adding the positions to which you can get from it, to\n        # open_positions. On the way, we update maxsize.\n        # open_positions is a list of tuples: (pos, stack state)\n        maxsize = 0\n        open_positions = [(0, (0,))]\n        while open_positions:\n            pos, curstack = open_positions.pop()\n            maxsize = max(maxsize, sum(curstack))\n            open_positions.extend(get_next_stacks(pos, curstack))\n\n        return maxsize\n\n    def to_code(self):\n        """"""Assemble a Python code object from a Code object.""""""\n        co_argcount = len(self.args) - self.varargs - self.varkwargs\n        co_stacksize = self._compute_stacksize()\n        co_flags = self._compute_flags()\n\n        co_consts = [self.docstring]\n        co_names = []\n        co_varnames = list(self.args)\n\n        co_freevars = tuple(self.freevars)\n\n        # We find all cellvars beforehand, for two reasons:\n        # 1. We need the number of them to construct the numeric argument\n        #    for ops in ""hasfree"".\n        # 2. We need to put arguments which are cell vars in the beginning\n        #    of co_cellvars\n        cellvars = set(arg for op, arg in self.code\n                       if isopcode(op) and op in hasfree\n                       and arg not in co_freevars)\n        co_cellvars = [x for x in self.args if x in cellvars]\n\n        def index(seq, item, eq=operator.eq, can_append=True):\n            """"""Find the index of item in a sequence and return it.\n            If it is not found in the sequence, and can_append is True,\n            it is appended to the sequence.\n\n            eq is the equality operator to use.\n            """"""\n            for i, x in enumerate(seq):\n                if eq(x, item):\n                    return i\n            else:\n                if can_append:\n                    seq.append(item)\n                    return len(seq) - 1\n                else:\n                    raise IndexError(""Item not found"")\n\n        # List of tuples (pos, label) to be filled later\n        jumps = []\n        # A mapping from a label to its position\n        label_pos = {}\n        # Last SetLineno\n        lastlineno = self.firstlineno\n        lastlinepos = 0\n\n        co_code = array(\'B\')\n        co_lnotab = array(\'B\')\n        for i, (op, arg) in enumerate(self.code):\n            if isinstance(op, Label):\n                label_pos[op] = len(co_code)\n\n            elif op is SetLineno:\n                incr_lineno = arg - lastlineno\n                incr_pos = len(co_code) - lastlinepos\n                lastlineno = arg\n                lastlinepos = len(co_code)\n\n                if incr_lineno == 0 and incr_pos == 0:\n                    co_lnotab.append(0)\n                    co_lnotab.append(0)\n                else:\n                    while incr_pos > 255:\n                        co_lnotab.append(255)\n                        co_lnotab.append(0)\n                        incr_pos -= 255\n                    while incr_lineno > 255:\n                        co_lnotab.append(incr_pos)\n                        co_lnotab.append(255)\n                        incr_pos = 0\n                        incr_lineno -= 255\n                    if incr_pos or incr_lineno:\n                        co_lnotab.append(incr_pos)\n                        co_lnotab.append(incr_lineno)\n\n            elif op == opcode.EXTENDED_ARG:\n                raise ValueError(""EXTENDED_ARG not supported in Code objects"")\n\n            elif not op in hasarg:\n                co_code.append(op)\n\n            else:\n                if op in hasconst:\n                    if isinstance(arg, Code) and i < len(self.code)-1 and \\\n                       self.code[i+1][0] in hascode:\n                        arg = arg.to_code()\n                    arg = index(co_consts, arg, operator.is_)\n                elif op in hasname:\n                    arg = index(co_names, arg)\n                elif op in hasjump:\n                    # arg will be filled later\n                    jumps.append((len(co_code), arg))\n                    arg = 0\n                elif op in haslocal:\n                    arg = index(co_varnames, arg)\n                elif op in hascompare:\n                    arg = index(cmp_op, arg, can_append=False)\n                elif op in hasfree:\n                    try:\n                        arg = index(co_freevars, arg, can_append=False) \\\n                              + len(cellvars)\n                    except IndexError:\n                        arg = index(co_cellvars, arg)\n                else:\n                    # arg is ok\n                    pass\n\n                if arg > 0xFFFF:\n                    co_code.append(opcode.EXTENDED_ARG)\n                    co_code.append((arg >> 16) & 0xFF)\n                    co_code.append((arg >> 24) & 0xFF)\n                co_code.append(op)\n                co_code.append(arg & 0xFF)\n                co_code.append((arg >> 8) & 0xFF)\n\n        for pos, label in jumps:\n            jump = label_pos[label]\n            if co_code[pos] in hasjrel:\n                jump -= pos+3\n            if jump > 0xFFFF:\n                raise NotImplementedError(""Extended jumps not implemented"")\n            co_code[pos+1] = jump & 0xFF\n            co_code[pos+2] = (jump >> 8) & 0xFF\n\n        co_code = co_code.tostring()\n        co_lnotab = co_lnotab.tostring()\n\n        co_consts = tuple(co_consts)\n        co_names = tuple(co_names)\n        co_varnames = tuple(co_varnames)\n        co_nlocals = len(co_varnames)\n        co_cellvars = tuple(co_cellvars)\n\n        return types.CodeType(co_argcount, co_nlocals, co_stacksize, co_flags,\n                              co_code, co_consts, co_names, co_varnames,\n                              self.filename, self.name, self.firstlineno, co_lnotab,\n                              co_freevars, co_cellvars)\n\n\ndef printcodelist(codelist, to=sys.stdout):\n    """"""Get a code list. Print it nicely.""""""\n\n    labeldict = {}\n    pendinglabels = []\n    for i, (op, arg) in enumerate(codelist):\n        if isinstance(op, Label):\n            pendinglabels.append(op)\n        elif op is SetLineno:\n            pass\n        else:\n            while pendinglabels:\n                labeldict[pendinglabels.pop()] = i\n\n    lineno = None\n    islabel = False\n    for i, (op, arg) in enumerate(codelist):\n        if op is SetLineno:\n            lineno = arg\n            print >> to\n            continue\n\n        if isinstance(op, Label):\n            islabel = True\n            continue\n\n        if lineno is None:\n            linenostr = \'\'\n        else:\n            linenostr = str(lineno)\n            lineno = None\n\n        if islabel:\n            islabelstr = \'>>\'\n            islabel = False\n        else:\n            islabelstr = \'\'\n\n        if op in hasconst:\n            argstr = repr(arg)\n        elif op in hasjump:\n            try:\n                argstr = \'to \' + str(labeldict[arg])\n            except KeyError:\n                argstr = repr(arg)\n        elif op in hasarg:\n            argstr = str(arg)\n        else:\n            argstr = \'\'\n\n        print >> to, \'%3s     %2s %4d %-20s %s\' % (\n            linenostr,\n            islabelstr,\n            i,\n            op,\n            argstr)\n\ndef recompile(filename):\n    """"""Create a .pyc by disassembling the file and assembling it again, printing\n    a message that the reassembled file was loaded.""""""\n    # Most of the code here based on the compile.py module.\n    import os\n    import imp\n    import marshal\n    import struct\n\n    f = open(filename, \'U\')\n    try:\n        timestamp = long(os.fstat(f.fileno()).st_mtime)\n    except AttributeError:\n        timestamp = long(os.stat(filename).st_mtime)\n    codestring = f.read()\n    f.close()\n    if codestring and codestring[-1] != \'\\n\':\n        codestring = codestring + \'\\n\'\n    try:\n        codeobject = compile(codestring, filename, \'exec\')\n    except SyntaxError:\n        print >> sys.stderr, ""Skipping %s - syntax error."" % filename\n        return\n    cod = Code.from_code(codeobject)\n    message = ""reassembled %r imported.\\n"" % filename\n    cod.code[:0] = [ # __import__(\'sys\').stderr.write(message)\n        (LOAD_GLOBAL, \'__import__\'),\n        (LOAD_CONST, \'sys\'),\n        (CALL_FUNCTION, 1),\n        (LOAD_ATTR, \'stderr\'),\n        (LOAD_ATTR, \'write\'),\n        (LOAD_CONST, message),\n        (CALL_FUNCTION, 1),\n        (POP_TOP, None),\n        ]\n    codeobject2 = cod.to_code()\n    fc = open(filename+\'c\', \'wb\')\n    fc.write(\'\\0\\0\\0\\0\')\n    fc.write(struct.pack(\'<l\', timestamp))\n    marshal.dump(codeobject2, fc)\n    fc.flush()\n    fc.seek(0, 0)\n    fc.write(imp.get_magic())\n    fc.close()\n\ndef recompile_all(path):\n    """"""recursively recompile all .py files in the directory""""""\n    import os\n    if os.path.isdir(path):\n        for root, dirs, files in os.walk(path):\n            for name in files:\n                if name.endswith(\'.py\'):\n                    filename = os.path.abspath(os.path.join(root, name))\n                    print >> sys.stderr, filename\n                    recompile(filename)\n    else:\n        filename = os.path.abspath(path)\n        recompile(filename)\n\ndef main():\n    import os\n    if len(sys.argv) != 2 or not os.path.exists(sys.argv[1]):\n        print(""""""\\\nUsage: %s dir\n\nSearch recursively for *.py in the given directory, disassemble and assemble\nthem, adding a note when each file is imported.\n\nUse it to test byteplay like this:\n> byteplay.py Lib\n> make test\n\nSome FutureWarnings may be raised, but that\'s expected.\n\nTip: before doing this, check to see which tests fail even without reassembling\nthem...\n"""""" % sys.argv[0])\n        sys.exit(1)\n    recompile_all(sys.argv[1])\n\nif __name__ == \'__main__\':\n    main()\n'"
rootpy/extern/byteplay3/__init__.py,0,"b'from sys import version_info\n\nif version_info.major < 3:\n    raise ImportError(""byteplay3 requires python 3"")\n\nif version_info.minor < 6:\n    from .byteplay import *\nelse:\n    from .wbyteplay import *\n'"
rootpy/extern/byteplay3/byteplay.py,0,"b'# byteplay: CPython assembler/disassembler\n# Copyright (C) 2006 Noam Raphael | Version: http://code.google.com/p/byteplay\n# Rewritten 2009 Demur Rumed | Version: http://github.com/serprex/byteplay\n#                            Screwed the style over, modified stack logic to be more flexible, updated to Python 3\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n#\n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA\n\n__version__ = \'0.4\'\n__all__ = [\n    \'opmap\',\n    \'opname\',\n    \'opcodes\',\n    \'hasflow\',\n    \'stack_effect\',\n    \'cmp_op\',\n    \'hasarg\',\n    \'hasname\',\n    \'hasjrel\',\n    \'hasjabs\',\n    \'hasjump\',\n    \'haslocal\',\n    \'hascompare\',\n    \'hasfree\',\n    \'hascode\',\n    \'hasconst\',\n    \'Opcode\',\n    \'SetLineno\',\n    \'Label\',\n    \'isopcode\',\n    \'Code\']\n\n\nfrom sys import version_info\nif version_info < (3, 4):\n    raise NotImplementedError(""Currently only Python versions 3.4 and 3.5 are supported!"")\n\nimport opcode\nfrom dis import findlabels\nfrom types import CodeType\nfrom enum import Enum\n\n\nclass Opcode(int):\n    __str__ = __repr__ = lambda s: opname[s]\n\n\nopmap = {name.replace(\'+\', \'_\'): Opcode(code) for name, code in opcode.opmap.items()}\nopname = {code: name for name, code in opmap.items()}\nopcodes = set(opname)\nfor cmp_op, hasarg in opmap.items():\n    globals()[cmp_op] = hasarg\n    __all__.append(cmp_op)\ncmp_op = opcode.cmp_op\n\nhasarg = {x for x in opcodes if x >= opcode.HAVE_ARGUMENT}\nhasconst = {Opcode(x) for x in opcode.hasconst}\nhasname = {Opcode(x) for x in opcode.hasname}\nhasjrel = {Opcode(x) for x in opcode.hasjrel}\nhasjabs = {Opcode(x) for x in opcode.hasjabs}\nhasjump = hasjabs | hasjrel\nhaslocal = {Opcode(x) for x in opcode.haslocal}\nhascompare = {Opcode(x) for x in opcode.hascompare}\nhasfree = {Opcode(x) for x in opcode.hasfree}\nhascode = {MAKE_FUNCTION, MAKE_CLOSURE}\n\nif version_info.minor > 2:\n    STOP_CODE = -1\nif version_info.minor < 4:\n    _se = {\n        IMPORT_FROM: 1,\n        DUP_TOP: 1,\n        LOAD_CONST: 1,\n        LOAD_NAME: 1,\n        LOAD_GLOBAL: 1,\n        LOAD_FAST: 1,\n        LOAD_CLOSURE: 1,\n        LOAD_DEREF: 1,\n        BUILD_MAP: 1,\n        LOAD_BUILD_CLASS: 1,\n        YIELD_VALUE: 0,\n        UNARY_POSITIVE: 0,\n        UNARY_NEGATIVE: 0,\n        UNARY_NOT: 0,\n        UNARY_INVERT: 0,\n        GET_ITER: 0,\n        LOAD_ATTR: 0,\n        IMPORT_NAME: 0,\n        ROT_TWO: 0,\n        ROT_THREE: 0,\n        NOP: 0,\n        DELETE_GLOBAL: 0,\n        DELETE_NAME: 0,\n        DELETE_FAST: 0,\n        STORE_LOCALS: 0,\n        IMPORT_NAME: -1,\n        POP_TOP: -1,\n        PRINT_EXPR: -1,\n        IMPORT_STAR: -1,\n        DELETE_ATTR: -1,\n        STORE_DEREF: -1,\n        STORE_NAME: -1,\n        STORE_GLOBAL: -1,\n        STORE_FAST: -1,\n        BINARY_POWER: -1,\n        BINARY_MULTIPLY: -1,\n        BINARY_FLOOR_DIVIDE: -1,\n        BINARY_TRUE_DIVIDE: -1,\n        BINARY_MODULO: -1,\n        BINARY_ADD: -1,\n        BINARY_SUBTRACT: -1,\n        BINARY_SUBSCR: -1,\n        BINARY_LSHIFT: -1,\n        BINARY_RSHIFT: -1,\n        BINARY_AND: -1,\n        BINARY_XOR: -1,\n        BINARY_OR: -1,\n        COMPARE_OP: -1,\n        INPLACE_POWER: -1,\n        INPLACE_MULTIPLY: -1,\n        INPLACE_FLOOR_DIVIDE: -1,\n        INPLACE_TRUE_DIVIDE: -1,\n        INPLACE_MODULO: -1,\n        INPLACE_ADD: -1,\n        INPLACE_SUBTRACT: -1,\n        INPLACE_LSHIFT: -1,\n        INPLACE_RSHIFT: -1,\n        INPLACE_AND: -1,\n        INPLACE_XOR: -1,\n        INPLACE_OR: -1,\n        LIST_APPEND: -1,\n        SET_ADD: -1,\n        DELETE_SUBSCR: -2,\n        STORE_ATTR: -2,\n        STORE_MAP: -2,\n        MAP_ADD: -2,\n        STORE_SUBSCR: -3}\n    _rf = {CALL_FUNCTION: lambda x: -((x & 0xFF00) >> 7) - (x & 0xFF),\n           CALL_FUNCTION_VAR_KW: lambda x: -((x & 0xFF00) >> 7) - (x & 0xFF) - 2,\n           CALL_FUNCTION_VAR: lambda x: -((x & 0xFF00) >> 7 | 1) - (x & 0xFF),\n           CALL_FUNCTION_KW: lambda x: -((x & 0xFF00) >> 7 | 1) - (x & 0xFF),\n           RAISE_VARARGS: lambda x: x,\n           MAKE_FUNCTION: lambda x: x,\n           UNPACK_EX: lambda x: (x & 0xFF) + (x >> 8),\n           UNPACK_SEQUENCE: lambda x: x - 1,\n           MAKE_CLOSURE: lambda x: x - 1,\n           BUILD_TUPLE: lambda x: 1 - x,\n           BUILD_LIST: lambda x: 1 - x,\n           BUILD_SET: lambda x: 1 - x,\n           BUILD_SLICE: lambda x: 1 - x}\n    if version_info.minor > 1:\n        _se[DUP_TOP_TWO] = 2\n        _se[DELETE_DEREF] = 0\n    else:\n        _se[ROT_FOUR] = 0\n        _rf[DUP_TOPX] = lambda x: x\n\n    def stack_effect(op, arg=None):\n        if op in _se:\n            return _se[op]\n        if arg is None:\n            raise ValueError(""%s requires arg"" % op)\n        if op in _rf:\n            return _rf[op](arg)\n        raise ValueError(""Unknown %s %s"" % (op, arg))\nelse:\n    from dis import stack_effect\n\nhasflow = hasjump | {\n    POP_BLOCK,\n    END_FINALLY,\n    BREAK_LOOP,\n    RETURN_VALUE,\n    RAISE_VARARGS,\n    STOP_CODE,\n    POP_EXCEPT}\n\nif version_info < (3, 5):\n    hasflow |= {WITH_CLEANUP}\nelse:\n    hasflow |= {WITH_CLEANUP_START, WITH_CLEANUP_FINISH, SETUP_ASYNC_WITH}\n    coroutine_opcodes = {GET_AWAITABLE, GET_AITER, GET_ANEXT, BEFORE_ASYNC_WITH, SETUP_ASYNC_WITH}\n\n\nclass Label:\n    pass\n\n\nclass SetLinenoType:\n    def __repr__(self):\n        return \'SetLineno\'\nSetLineno = SetLinenoType()\n\n\ndef isopcode(x):\n    return x is not SetLineno and not isinstance(x, Label)\n\n\n# Flags for codeobject.co_flags, taken from Include/code.h, other flags are no longer used\nCO_OPTIMIZED   = 0x0001\nCO_NEWLOCALS   = 0x0002\nCO_VARARGS     = 0x0004\nCO_VARKEYWORDS = 0x0008\nCO_NESTED      = 0x0010\nCO_GENERATOR   = 0x0020\nCO_NOFREE      = 0x0040\n\nif version_info >= (3, 5):\n    CO_COROUTINE          = 0x0080\n    CO_ITERABLE_COROUTINE = 0x0100\n\nCO_FUTURE_BARRY_AS_BDFL = 0x40000\n\nif version_info >= (3, 5):\n    CO_FUTURE_GENERATOR_STOP = 0x80000\n\n\nclass Code(object):\n    """"""An object which holds all the information which a Python code object\n    holds, but in an easy-to-play-with representation\n\n    The attributes are:\n\n    Affecting action\n    code - list of 2-tuples: the code\n    freevars - list of strings: the free vars of the code (those are names\n               of variables created in outer functions and used in the function)\n    args - list of strings: the arguments of the code\n    kwonly - number of keyword only arguments\n    varargs - boolean: Does args end with a \'*args\' argument\n    varkwargs - boolean: Does args end with a \'**kwargs\' argument\n    newlocals - boolean: Should a new local namespace be created\n                (True in functions, False for module and exec code)\n\n    force_generator - set CO_GENERATOR in co_flags for generator Code objects without generator-specific code\n    Python 3.5:\n        force_coroutine - set CO_COROUTINE in co_flags for coroutine Code objects (native coroutines) without coroutine-specific code\n        force_iterable_coroutine - set CO_ITERABLE_COROUTINE in co_flags for generator-based coroutine Code objects\n        future_generator_stop - set CO_FUTURE_GENERATOR_STOP flag (see PEP-479)\n\n    Not affecting action\n    name - string: the name of the code (co_name)\n    filename - string: the file name of the code (co_filename)\n    firstlineno - int: the first line number (co_firstlineno)\n    docstring - string or None: the docstring (the first item of co_consts,\n                if it\'s str)\n\n    code is a list of 2-tuples. The first item is an opcode, or SetLineno, or a\n    Label instance. The second item is the argument, if applicable, or None""""""\n\n    def __init__(self, code, freevars, args, kwonly, varargs, varkwargs, newlocals,\n                 name, filename, firstlineno, docstring,\n                 force_generator=False,\n                 *, force_coroutine=None, force_iterable_coroutine=None, future_generator_stop=None):\n        self.code = code\n        self.freevars = freevars\n        self.args = args\n        self.kwonly = kwonly\n        self.varargs = varargs\n        self.varkwargs = varkwargs\n        self.newlocals = newlocals\n        self.name = name\n        self.filename = filename\n        self.firstlineno = firstlineno\n        self.docstring = docstring\n        self.force_generator = force_generator\n        if version_info < (3, 5):\n            # Flags unsupported in earlier versions\n            assert force_coroutine is None and force_iterable_coroutine is None and future_generator_stop is None\n        else:\n            self.force_coroutine = force_coroutine\n            self.force_iterable_coroutine = force_iterable_coroutine\n            self.future_generator_stop = future_generator_stop\n\n    @staticmethod\n    def _findlinestarts(code):\n        """"""Find the offsets in a byte code which are start of lines in the source\n        Generate pairs offset,lineno as described in Python/compile.c\n        This is a modified version of dis.findlinestarts, which allows multiplelinestarts\n        with the same line number""""""\n        lineno = code.co_firstlineno\n        addr = 0\n        for byte_incr, line_incr in zip(code.co_lnotab[0::2], code.co_lnotab[1::2]):\n            if byte_incr:\n                yield addr, lineno\n                addr += byte_incr\n            lineno += line_incr\n        yield addr, lineno\n\n    @classmethod\n    def from_code(cls, co):\n        """"""Disassemble a Python code object into a Code object""""""\n        free_cell_isection = set(co.co_cellvars) & set(co.co_freevars)\n        if free_cell_isection:\n            print(co.co_name + \': has non-empty co.co_cellvars & co.co_freevars\', free_cell_isection)\n            return None\n\n        co_code = co.co_code\n        labels = {addr: Label() for addr in findlabels(co_code)}\n        linestarts = dict(cls._findlinestarts(co))\n        cellfree = co.co_cellvars + co.co_freevars\n        code = []\n        n = len(co_code)\n        i = extended_arg = 0\n        is_generator = False\n        if version_info >= (3, 5):\n            is_coroutine = False\n\n        while i < n:\n            op = Opcode(co_code[i])\n            if i in labels:\n                code.append((labels[i], None))\n            if i in linestarts:\n                code.append((SetLineno, linestarts[i]))\n            i += 1\n            if op in hascode:\n                lastop, lastarg = code[-2]\n                if lastop != LOAD_CONST:\n                    raise ValueError(""%s should be preceded by LOAD_CONST"" % op)\n\n                sub_code = Code.from_code(lastarg)\n                if sub_code is None:\n                    print(co.co_name + \': has unexpected subcode block\')\n                    return None\n\n                code[-2] = (LOAD_CONST, sub_code)\n            if op not in hasarg:\n                code.append((op, None))\n            else:\n                arg = co_code[i] | co_code[i + 1] << 8 | extended_arg\n                extended_arg = 0\n                i += 2\n                if op == opcode.EXTENDED_ARG:\n                    extended_arg = arg << 16\n                else:\n                    byteplay_arg = co.co_consts[arg] if op in hasconst else \\\n                                   co.co_names[arg] if op in hasname else \\\n                                   labels[arg] if op in hasjabs else \\\n                                   labels[i + arg] if op in hasjrel else \\\n                                   co.co_varnames[arg] if op in haslocal else \\\n                                   cmp_op[arg] if op in hascompare else \\\n                                   cellfree[arg] if op in hasfree else \\\n                                   arg\n                    code.append((op, byteplay_arg))\n\n            if op == YIELD_VALUE or op == YIELD_FROM:\n                is_generator = True\n\n            if version_info >= (3, 5) and op in coroutine_opcodes:\n                is_coroutine = True\n\n        varargs = not not co.co_flags & CO_VARARGS\n        varkwargs = not not co.co_flags & CO_VARKEYWORDS\n        force_generator = not is_generator and (co.co_flags & CO_GENERATOR)\n\n        if version_info >= (3, 5):\n            force_coroutine = not is_coroutine and (co.co_flags & CO_COROUTINE)\n            force_iterable_coroutine = co.co_flags & CO_ITERABLE_COROUTINE\n            assert not (force_coroutine and force_iterable_coroutine)\n            future_generator_stop = co.co_flags & CO_FUTURE_GENERATOR_STOP\n        else:\n            force_coroutine = None\n            force_iterable_coroutine =None\n            future_generator_stop = None\n\n        return cls(code=code,\n                   freevars=co.co_freevars,\n                   args=co.co_varnames[:co.co_argcount + varargs + varkwargs + co.co_kwonlyargcount],\n                   kwonly=co.co_kwonlyargcount,\n                   varargs=varargs,\n                   varkwargs=varkwargs,\n                   newlocals=not not co.co_flags & CO_NEWLOCALS,\n                   name=co.co_name,\n                   filename=co.co_filename,\n                   firstlineno=co.co_firstlineno,\n                   docstring=co.co_consts[0] if co.co_consts and isinstance(co.co_consts[0], str) else None,\n                   force_generator=force_generator,\n                   force_coroutine=force_coroutine,\n                   force_iterable_coroutine=force_iterable_coroutine,\n                   future_generator_stop=future_generator_stop)\n\n    def __eq__(self, other):\n        try:\n            if (self.freevars != other.freevars or\n                    self.args != other.args or\n                    self.kwonly != other.kwonly or\n                    self.varargs != other.varargs or\n                    self.varkwargs != other.varkwargs or\n                    self.newlocals != other.newlocals or\n                    self.name != other.name or\n                    self.filename != other.filename or\n                    self.firstlineno != other.firstlineno or\n                    self.docstring != other.docstring or\n                    self.force_generator != other.force_generator or\n                    len(self.code) != len(other.code)):\n                return False\n            elif version_info >= (3, 5):\n                if (self.force_coroutine != other.force_coroutine or\n                        self.force_iterable_coroutine != other.force_iterable_coroutine or\n                        self.future_generator_stop != other.future_generator_stop):\n                    return False\n\n\n            # This isn\'t trivial due to labels\n            lmap = {}\n            for (op1, arg1), (op2, arg2) in zip(self.code, other.code):\n                if isinstance(op1, Label):\n                    if lmap.setdefault(arg1, arg2) is not arg2:\n                        return False\n                else:\n                    if op1 != op2:\n                        return False\n                    if op1 in hasjump:\n                        if lmap.setdefault(arg1, arg2) is not arg2:\n                            return False\n                    elif arg1 != arg2:\n                        return False\n\n            return True\n        except:\n            return False\n\n    def _compute_stacksize(self, logging=False):\n        code = self.code\n        label_pos = {op[0]: pos for pos, op in enumerate(code) if isinstance(op[0], Label)}\n        # sf_targets are the targets of SETUP_FINALLY opcodes. They are recorded\n        # because they have special stack behaviour. If an exception was raised\n        # in the block pushed by a SETUP_FINALLY opcode, the block is popped\n        # and 3 objects are pushed. On return or continue, the block is popped\n        # and 2 objects are pushed. If nothing happened, the block is popped by\n        # a POP_BLOCK opcode and 1 object is pushed by a (LOAD_CONST, None)\n        # operation\n        # Our solution is to record the stack state of SETUP_FINALLY targets\n        # as having 3 objects pushed, which is the maximum. However, to make\n        # stack recording consistent, the get_next_stacks function will always\n        # yield the stack state of the target as if 1 object was pushed, but\n        # this will be corrected in the actual stack recording\n        if version_info < (3, 5):\n            sf_targets = {label_pos[arg] for op, arg in code\n                          if (op == SETUP_FINALLY or op == SETUP_WITH)}\n        else:\n            sf_targets = {label_pos[arg] for op, arg in code\n                          if (op == SETUP_FINALLY or op == SETUP_WITH or op == SETUP_ASYNC_WITH)}\n\n        states = [None] * len(code)\n        maxsize = 0\n\n        class BlockType(Enum):\n            DEFAULT = 0,\n            TRY_FINALLY = 1,\n            TRY_EXCEPT = 2,\n            LOOP_BODY = 3,\n            WITH_BLOCK = 4,\n            EXCEPTION = 5,\n            SILENCED_EXCEPTION_BLOCK = 6,\n\n        class State:\n\n            def __init__(self, pos=0, stack=(0,), block_stack=(BlockType.DEFAULT,), log=[]):\n                self._pos = pos\n                self._stack = stack\n                self._block_stack = block_stack\n                self._log = log\n\n            @property\n            def pos(self):\n                return self._pos\n\n            @property\n            def stack(self):\n                return self._stack\n\n            @stack.setter\n            def stack(self, val):\n                self._stack = val\n\n            def newstack(self, n):\n                if self._stack[-1] < -n:\n                    raise ValueError(""Popped a non-existing element at %s %s"" %\n                                     (self._pos, code[self._pos - 4: self._pos + 3]))\n                return self._stack[:-1] + (self._stack[-1] + n,)\n\n            @property\n            def block_stack(self):\n                return self._block_stack\n\n            @property\n            def log(self):\n                return self._log\n\n            def newlog(self, msg):\n                if not logging:\n                    return None\n\n                log_msg = str(self._pos) + "": "" + msg\n                if self._stack:\n                    log_msg += "" (on stack: ""\n                    log_depth = 2\n                    log_depth = min(log_depth, len(self._stack))\n                    for pos in range(-1, -log_depth, -1):\n                        log_msg += str(self._stack[pos]) + "", ""\n                    log_msg += str(self._stack[-log_depth])\n                    log_msg += "")""\n                else:\n                    log_msg += "" (empty stack)""\n                return [log_msg] + self._log\n\n        op = [State()]\n\n        while op:\n            cur_state = op.pop()\n            o = sum(cur_state.stack)\n            if o > maxsize:\n                maxsize = o\n\n            o, arg = code[cur_state.pos]\n\n            if isinstance(o, Label):\n                if cur_state.pos in sf_targets:\n                    cur_state.stack = cur_state.newstack(5)\n                if states[cur_state.pos] is None:\n                    states[cur_state.pos] = cur_state\n                elif states[cur_state.pos].stack != cur_state.stack:\n                    check_pos = cur_state.pos + 1\n                    while code[check_pos][0] not in hasflow:\n                        check_pos += 1\n                    if code[check_pos][0] not in (RETURN_VALUE, RAISE_VARARGS, STOP_CODE):\n                        if cur_state.pos not in sf_targets:\n                            raise ValueError(""Inconsistent code at %s %s %s\\n%s"" %\n                                             (cur_state.pos, cur_state.stack, states[cur_state.pos].stack,\n                                              code[cur_state.pos - 5:cur_state.pos + 4]))\n                        else:\n                            # SETUP_FINALLY target inconsistent code!\n                            #\n                            # Since Python 3.2 assigned exception is cleared at the end of\n                            # the except clause (named exception handler).\n                            # To perform this CPython (checked in version 3.4.3) adds special\n                            # bytecode in exception handler which currently breaks \'regularity\' of bytecode.\n                            # Exception handler is wrapped in try/finally block and POP_EXCEPT opcode\n                            # is inserted before END_FINALLY, as a result cleanup-finally block is executed outside\n                            # except handler. It\'s not a bug, as it doesn\'t cause any problems during execution, but\n                            # it breaks \'regularity\' and we can\'t check inconsistency here. Maybe issue should be\n                            # posted to Python bug tracker.\n                            pass\n                    continue\n                else:\n                    continue\n\n            if o not in (BREAK_LOOP, RETURN_VALUE, RAISE_VARARGS, STOP_CODE):\n                next_pos = cur_state.pos + 1\n\n                if not isopcode(o):\n                    op += State(next_pos, cur_state.stack, cur_state.block_stack, cur_state.log),\n\n                elif o not in hasflow:\n                    if o in (LOAD_GLOBAL, LOAD_CONST, LOAD_NAME, LOAD_FAST, LOAD_ATTR, LOAD_DEREF,\n                             LOAD_CLASSDEREF, LOAD_CLOSURE,\n                             STORE_GLOBAL, STORE_NAME, STORE_FAST, STORE_ATTR, STORE_DEREF,\n                             DELETE_GLOBAL, DELETE_NAME, DELETE_FAST, DELETE_ATTR, DELETE_DEREF,\n                             IMPORT_NAME, IMPORT_FROM, COMPARE_OP):\n                        se = stack_effect(o, 0)\n                    else:\n                        se = stack_effect(o, arg)\n\n                    log = cur_state.newlog(""non-flow command ("" + str(o) + "", se = "" + str(se) + "")"")\n                    op += State(next_pos, cur_state.newstack(se), cur_state.block_stack, log),\n\n                elif o == FOR_ITER:\n                    inside_for_log = cur_state.newlog(""FOR_ITER (+1)"")\n                    op += State(label_pos[arg], cur_state.newstack(-1), cur_state.block_stack, cur_state.log),\\\n                          State(next_pos, cur_state.newstack(1), cur_state.block_stack, inside_for_log)\n\n                elif o in (JUMP_FORWARD, JUMP_ABSOLUTE):\n                    after_jump_log = cur_state.newlog(str(o))\n                    op += State(label_pos[arg], cur_state.stack, cur_state.block_stack, after_jump_log),\n\n                elif o in (JUMP_IF_FALSE_OR_POP, JUMP_IF_TRUE_OR_POP):\n                    after_jump_log = cur_state.newlog(str(o) + "", jumped"")\n                    log = cur_state.newlog(str(o) + "", not jumped (-1)"")\n                    op += State(label_pos[arg], cur_state.stack, cur_state.block_stack, after_jump_log),\\\n                          State(next_pos, cur_state.newstack(-1), cur_state.block_stack, log)\n\n                elif o in (POP_JUMP_IF_TRUE, POP_JUMP_IF_FALSE):\n                    after_jump_log = cur_state.newlog(str(o) + "", jumped (-1)"")\n                    log = cur_state.newlog(str(o) + "", not jumped (-1)"")\n                    op += State(label_pos[arg], cur_state.newstack(-1), cur_state.block_stack, after_jump_log),\\\n                          State(next_pos, cur_state.newstack(-1), cur_state.block_stack, log)\n\n                elif o == CONTINUE_LOOP:\n                    next_stack, next_block_stack = cur_state.stack, cur_state.block_stack\n                    last_popped_block = None\n                    while next_block_stack[-1] != BlockType.LOOP_BODY:\n                        last_popped_block = next_block_stack[-1]\n                        next_stack, next_block_stack = next_stack[:-1], next_block_stack[:-1]\n\n                    if next_stack != cur_state.stack:\n                        log = cur_state.newlog(""CONTINUE_LOOP, from non-loop block"")\n                    else:\n                        log = cur_state.newlog(""CONTINUE_LOOP"")\n\n                    jump_to_pos = label_pos[arg]\n                    if last_popped_block == BlockType.WITH_BLOCK:\n                        next_stack = next_stack[:-1] + (next_stack[-1] - 1,)\n                    op += State(jump_to_pos, next_stack, next_block_stack, log),\n\n                elif o == SETUP_LOOP:\n                    inside_loop_log = cur_state.newlog(""SETUP_LOOP (+block)"")\n                    op += State(label_pos[arg], cur_state.stack, cur_state.block_stack, cur_state.log),\\\n                          State(next_pos, cur_state.stack + (0,), cur_state.block_stack + (BlockType.LOOP_BODY,), inside_loop_log)\n\n                elif o == SETUP_EXCEPT:\n                    inside_except_log = cur_state.newlog(""SETUP_EXCEPT, exception (+6, +block)"")\n                    inside_try_log = cur_state.newlog(""SETUP_EXCEPT, try-block (+block)"")\n                    op += State(label_pos[arg], cur_state.stack + (6,), cur_state.block_stack + (BlockType.EXCEPTION,), inside_except_log),\\\n                          State(next_pos, cur_state.stack + (0,), cur_state.block_stack + (BlockType.TRY_EXCEPT,), inside_try_log)\n\n                elif o == SETUP_FINALLY:\n                    inside_finally_block = cur_state.newlog(""SETUP_FINALLY (+1)"")\n                    inside_try_log = cur_state.newlog(""SETUP_FINALLY try-block (+block)"")\n                    op += State(label_pos[arg], cur_state.newstack(1), cur_state.block_stack, inside_finally_block),\\\n                          State(next_pos, cur_state.stack + (0,), cur_state.block_stack + (BlockType.TRY_FINALLY,), inside_try_log)\n\n                elif o == POP_BLOCK:\n                    log = cur_state.newlog(""POP_BLOCK (-block)"")\n                    op += State(next_pos, cur_state.stack[:-1], cur_state.block_stack[:-1], log),\n\n                elif o == POP_EXCEPT:\n                    log = cur_state.newlog(""POP_EXCEPT (-block)"")\n                    op += State(next_pos, cur_state.stack[:-1], cur_state.block_stack[:-1], log),\n\n                elif o == END_FINALLY:\n                    if cur_state.block_stack[-1] == BlockType.SILENCED_EXCEPTION_BLOCK:\n                        log = cur_state.newlog(""END_FINALLY pop silenced exception block (-block)"")\n                        op += State(next_pos, cur_state.stack[:-1], cur_state.block_stack[:-1], log),\n                    elif cur_state.block_stack[-1] == BlockType.EXCEPTION:\n                        # Reraise exception\n                        pass\n                    else:\n                        log = cur_state.newlog(""END_FINALLY (-6)"")\n                        op += State(next_pos, cur_state.newstack(-6), cur_state.block_stack, log),\n\n                elif o == SETUP_WITH or (version_info >= (3, 5) and o == SETUP_ASYNC_WITH):\n                    inside_with_block = cur_state.newlog(""SETUP_WITH, with-block (+1, +block)"")\n                    inside_finally_block = cur_state.newlog(""SETUP_WITH, finally (+1)"")\n                    op += State(label_pos[arg], cur_state.newstack(1), cur_state.block_stack, inside_finally_block),\\\n                          State(next_pos, cur_state.stack + (1,), cur_state.block_stack + (BlockType.WITH_BLOCK,), inside_with_block)\n\n                elif version_info < (3, 5) and o == WITH_CLEANUP:\n                    # There is special case when \'with\' __exit__ function returns True,\n                    # that\'s the signal to silence exception, in this case additional element is pushed\n                    # and next END_FINALLY command won\'t reraise exception.\n                    log = cur_state.newlog(""WITH_CLEANUP (-1)"")\n                    silenced_exception_log = cur_state.newlog(""WITH_CLEANUP silenced_exception (+1, +block)"")\n                    op += State(next_pos, cur_state.newstack(-1), cur_state.block_stack, log),\\\n                          State(next_pos, cur_state.newstack(-7) + (8,), cur_state.block_stack + (BlockType.SILENCED_EXCEPTION_BLOCK,), silenced_exception_log)\n\n                elif version_info >= (3, 5) and o == WITH_CLEANUP_START:\n                    # There is special case when \'with\' __exit__ function returns True,\n                    # that\'s the signal to silence exception, in this case additional element is pushed\n                    # and next END_FINALLY command won\'t reraise exception.\n                    # Emulate this situation on WITH_CLEANUP_START with creating special block which will be\n                    # handled differently by WITH_CLEANUP_FINISH and will cause END_FINALLY not to reraise exception.\n                    log = cur_state.newlog(""WITH_CLEANUP_START (+1)"")\n                    silenced_exception_log = cur_state.newlog(""WITH_CLEANUP_START silenced_exception (+block)"")\n                    op += State(next_pos, cur_state.newstack(1), cur_state.block_stack, log),\\\n                          State(next_pos, cur_state.newstack(-7) + (9,), cur_state.block_stack + (BlockType.SILENCED_EXCEPTION_BLOCK,), silenced_exception_log)\n\n                elif version_info >= (3, 5) and o == WITH_CLEANUP_FINISH:\n                    if cur_state.block_stack[-1] == BlockType.SILENCED_EXCEPTION_BLOCK:\n                        # See comment in WITH_CLEANUP_START handler\n                        log = cur_state.newlog(""WITH_CLEANUP_FINISH silenced_exception (-1)"")\n                        op += State(next_pos, cur_state.newstack(-1), cur_state.block_stack, log),\n                    else:\n                        log = cur_state.newlog(""WITH_CLEANUP_FINISH (-2)"")\n                        op += State(next_pos, cur_state.newstack(-2), cur_state.block_stack, log),\n\n                else:\n                    raise ValueError(""Unhandled opcode %s"" % o)\n\n        return maxsize + 6  # for exception raise in deepest place\n\n    def to_code(self, from_function=False):\n        """"""Assemble a Python code object from a Code object""""""\n\n        num_fastnames = sum(1 for op, arg in self.code if isopcode(op) and op in haslocal)\n        is_function = self.newlocals or num_fastnames > 0 or len(self.args) > 0\n        nested = is_function and from_function\n\n        co_flags = {op[0] for op in self.code}\n\n        is_generator = self.force_generator or (YIELD_VALUE in co_flags or YIELD_FROM in co_flags)\n        no_free = (not self.freevars) and (not co_flags & hasfree)\n\n        if version_info >= (3, 5):\n            is_native_coroutine = bool(self.force_coroutine or (co_flags & coroutine_opcodes))\n            assert not (is_native_coroutine and self.force_iterable_coroutine)\n\n        co_flags =\\\n            (not(STORE_NAME in co_flags or LOAD_NAME in co_flags or DELETE_NAME in co_flags)) |\\\n            (self.newlocals and CO_NEWLOCALS) |\\\n            (self.varargs and CO_VARARGS) |\\\n            (self.varkwargs and CO_VARKEYWORDS) |\\\n            (is_generator and CO_GENERATOR) |\\\n            (no_free and CO_NOFREE) |\\\n            (nested and CO_NESTED)\n\n        if version_info >= (3, 5):\n            co_flags |= (is_native_coroutine and CO_COROUTINE) |\\\n                        (self.force_iterable_coroutine and CO_ITERABLE_COROUTINE) |\\\n                        (self.future_generator_stop and CO_FUTURE_GENERATOR_STOP)\n\n        co_consts = [self.docstring]\n        co_names = []\n        co_varnames = list(self.args)\n        co_freevars = tuple(self.freevars)\n\n        # Find all cellvars beforehand for two reasons\n        # Need the number of them to construct the numeric arg for ops in hasfree\n        # Need to put args which are cells in the beginning of co_cellvars\n        cellvars = {arg for op, arg in self.code\n                    if isopcode(op) and op in hasfree\n                    and arg not in co_freevars}\n        co_cellvars = [jumps for jumps in self.args if jumps in cellvars]\n\n        def index(seq, item, eq=True, can_append=True):\n            for i, x in enumerate(seq):\n                if x == item if eq else x is item:\n                    return i\n            if can_append:\n                seq.append(item)\n                return len(seq) - 1\n            else:\n                raise IndexError(""Item not found"")\n\n        jumps = []\n        label_pos = {}\n        lastlineno = self.firstlineno\n        lastlinepos = 0\n        co_code = bytearray()\n        co_lnotab = bytearray()\n\n        for i, (op, arg) in enumerate(self.code):\n            if isinstance(op, Label):\n                label_pos[op] = len(co_code)\n            elif op is SetLineno:\n                incr_lineno = arg - lastlineno\n                incr_pos = len(co_code) - lastlinepos\n                lastlineno = arg\n                lastlinepos += incr_pos\n                if incr_lineno != 0 or incr_pos != 0:\n                    while incr_pos > 255:\n                        co_lnotab += b""\\xFF\\0""\n                        incr_pos -= 255\n                    while incr_lineno > 255:\n                        co_lnotab += (0xFF00|incr_pos).to_bytes(2, ""little"")\n                        incr_pos = 0\n                        incr_lineno -= 255\n                    if incr_pos or incr_lineno:\n                        co_lnotab += bytes((incr_pos, incr_lineno))\n            elif op == opcode.EXTENDED_ARG:\n                self.code[i + 1][1] |= 1 << 32\n            elif op not in hasarg:\n                co_code.append(op)\n            else:\n                if op in hasconst:\n                    if isinstance(arg, Code) and\\\n                            i + 2 < len(self.code) and self.code[i + 2][0] in hascode:\n                        arg = arg.to_code(from_function=is_function)\n                        assert arg is not None\n                    arg = index(co_consts, arg, 0)\n                elif op in hasname:\n                    arg = index(co_names, arg)\n                elif op in hasjump:\n                    jumps.append((len(co_code), arg))\n                    co_code += op.to_bytes(3, ""little"")\n                    continue\n                elif op in haslocal:\n                    arg = index(co_varnames, arg)\n                elif op in hascompare:\n                    arg = index(cmp_op, arg, can_append=False)\n                elif op in hasfree:\n                    try:\n                        arg = index(co_freevars, arg, can_append=False) + len(cellvars)\n                    except IndexError:\n                        arg = index(co_cellvars, arg)\n                if arg > 0xFFFF:\n                    co_code += (opcode.EXTENDED_ARG | ((arg & 0xFFFF0000) >> 8)).to_bytes(3, ""little"")\n                co_code += (op | (arg << 8)).to_bytes(3, ""little"")\n\n        for pos, label in jumps:\n            jump = label_pos[label]\n            if co_code[pos] in hasjrel:\n                jump -= pos + 3\n            if jump > 0xFFFF:\n                raise NotImplementedError(""Extended jumps not implemented"")\n            co_code[pos + 1] = jump & 0xFF\n            co_code[pos + 2] = jump >> 8\n\n        co_argcount = len(self.args) - self.varargs - self.varkwargs - self.kwonly\n        co_stacksize = self._compute_stacksize()\n\n        return CodeType(co_argcount, self.kwonly, len(co_varnames), co_stacksize, co_flags,\n                        bytes(co_code), tuple(co_consts), tuple(co_names), tuple(co_varnames),\n                        self.filename, self.name, self.firstlineno, bytes(co_lnotab), co_freevars,\n                        tuple(co_cellvars))\n'"
rootpy/extern/byteplay3/wbyteplay.py,0,"b'# byteplay: CPython assembler/disassembler\n# Copyright (C) 2006 Noam Raphael | Version: http://code.google.com/p/byteplay\n# Rewritten 2009 Demur Rumed | Version: http://github.com/serprex/byteplay\n#                            Screwed the style over, modified stack logic to be more flexible, updated to Python 3\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n#\n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA\n\n__version__ = \'1.0\'\n__all__ = [\n    \'opmap\',\n    \'opname\',\n    \'opcodes\',\n    \'hasflow\',\n    \'stack_effect\',\n    \'cmp_op\',\n    \'hasarg\',\n    \'hasname\',\n    \'hasjrel\',\n    \'hasjabs\',\n    \'hasjump\',\n    \'haslocal\',\n    \'hascompare\',\n    \'hasfree\',\n    \'hasconst\',\n    \'hascode\',\n    \'Opcode\',\n    \'SetLineno\',\n    \'Label\',\n    \'isopcode\',\n    \'Code\']\n\n\nfrom sys import version_info\nif version_info < (3, 6):\n    raise NotImplementedError(""Currently only Python versions >3.5 are supported!"")\n\nimport opcode\nfrom dis import findlabels\nfrom types import CodeType\nfrom enum import Enum\n\n\nclass Opcode(int):\n    __str__ = __repr__ = lambda s: opname[s]\n\n\nopmap = {name.replace(\'+\', \'_\'): Opcode(code) for name, code in opcode.opmap.items()}\nopname = {code: name for name, code in opmap.items()}\nopcodes = set(opname)\nfor cmp_op, hasname in opmap.items():\n    globals()[cmp_op] = hasname\n    __all__.append(cmp_op)\ncmp_op = opcode.cmp_op\n\n\nhasarg = {x for x in opcodes if x >= opcode.HAVE_ARGUMENT}\nhasconst = {Opcode(x) for x in opcode.hasconst}\nhasname = {Opcode(x) for x in opcode.hasname}\nhasjrel = {Opcode(x) for x in opcode.hasjrel}\nhasjabs = {Opcode(x) for x in opcode.hasjabs}\nhasjump = hasjabs | hasjrel\nhaslocal = {Opcode(x) for x in opcode.haslocal}\nhascompare = {Opcode(x) for x in opcode.hascompare}\nhasfree = {Opcode(x) for x in opcode.hasfree}\nhascode = {MAKE_FUNCTION}\n\nSTOP_CODE = -1\nimport dis\n\n# Fix bug in Python 3.6.0 (fixed in 3.6.1)\nif (3, 6, 0) <= version_info < (3, 6, 1):\n    def stack_effect(o, arg):\n        return (dis.stack_effect(o, arg) if o != CALL_FUNCTION_EX else\n                -2 if arg else -1)\nelse:\n    stack_effect = dis.stack_effect\n\nhasflow = hasjump | {\n    POP_BLOCK,\n    END_FINALLY,\n    BREAK_LOOP,\n    RETURN_VALUE,\n    RAISE_VARARGS,\n    STOP_CODE,\n    POP_EXCEPT,\n    WITH_CLEANUP_START,\n    WITH_CLEANUP_FINISH,\n    SETUP_ASYNC_WITH}\ncoroutine_opcodes = {GET_AWAITABLE, GET_AITER, GET_ANEXT, BEFORE_ASYNC_WITH, SETUP_ASYNC_WITH}\n\n\nclass Label:\n    pass\n\n\nclass SetLinenoType:\n    def __repr__(self):\n        return \'SetLineno\'\nSetLineno = SetLinenoType()\n\n\ndef isopcode(x):\n    return x is not SetLineno and not isinstance(x, Label)\n\n\n# Flags for codeobject.co_flags, taken from Include/code.h, other flags are no longer used\nCO_OPTIMIZED          = 0x0001\nCO_NEWLOCALS          = 0x0002\nCO_VARARGS            = 0x0004\nCO_VARKEYWORDS        = 0x0008\nCO_NESTED             = 0x0010\nCO_GENERATOR          = 0x0020\nCO_NOFREE             = 0x0040\nCO_COROUTINE          = 0x0080\nCO_ITERABLE_COROUTINE = 0x0100\nCO_ASYNC_GENERATOR    = 0x0200\n\nCO_FUTURE_BARRY_AS_BDFL = 0x40000\n\nCO_FUTURE_GENERATOR_STOP = 0x80000\n\n\nclass Code(object):\n    """"""An object which holds all the information which a Python code object\n    holds, but in an easy-to-play-with representation\n\n    The attributes are:\n\n    Affecting action\n    code - list of 2-tuples: the code\n    freevars - list of strings: the free vars of the code (those are names\n               of variables created in outer functions and used in the function)\n    args - list of strings: the arguments of the code\n    kwonly - number of keyword only arguments\n    varargs - boolean: Does args end with a \'*args\' argument\n    varkwargs - boolean: Does args end with a \'**kwargs\' argument\n    newlocals - boolean: Should a new local namespace be created\n                (True in functions, False for module and exec code)\n\n    force_generator - set CO_GENERATOR in co_flags for generator Code objects without generator-specific code\n    Python 3.5:\n        force_coroutine - set CO_COROUTINE in co_flags for coroutine Code objects (native coroutines) without coroutine-specific code\n        force_iterable_coroutine - set CO_ITERABLE_COROUTINE in co_flags for generator-based coroutine Code objects\n        future_generator_stop - set CO_FUTURE_GENERATOR_STOP flag (see PEP-479)\n    Python 3.6:\n        force_async_generator - set CO_ASYNC_GENERATOR in co_flags\n\n    Not affecting action\n    name - string: the name of the code (co_name)\n    filename - string: the file name of the code (co_filename)\n    firstlineno - int: the first line number (co_firstlineno)\n    docstring - string or None: the docstring (the first item of co_consts,\n                if it\'s str)\n\n    code is a list of 2-tuples. The first item is an opcode, or SetLineno, or a\n    Label instance. The second item is the argument, if applicable, or None""""""\n\n    def __init__(self, code, freevars, args, kwonly, varargs, varkwargs, newlocals,\n                 name, filename, firstlineno, docstring,\n                 force_generator=False,\n                 *, force_coroutine=False, force_iterable_coroutine=False,\n                 force_async_generator=False, future_generator_stop=False):\n        self.code = code\n        self.freevars = freevars\n        self.args = args\n        self.kwonly = kwonly\n        self.varargs = varargs\n        self.varkwargs = varkwargs\n        self.newlocals = newlocals\n        self.name = name\n        self.filename = filename\n        self.firstlineno = firstlineno\n        self.docstring = docstring\n        self.force_generator = force_generator\n        self.force_coroutine = force_coroutine\n        self.force_iterable_coroutine = force_iterable_coroutine\n        self.force_async_generator = force_async_generator\n        self.future_generator_stop = future_generator_stop\n\n    @staticmethod\n    def _findlinestarts(code):\n        """"""Find the offsets in a byte code which are start of lines in the source\n        Generate pairs offset,lineno as described in Python/compile.c\n        This is a modified version of dis.findlinestarts, which allows multiplelinestarts\n        with the same line number""""""\n        lineno = code.co_firstlineno\n        addr = 0\n        for byte_incr, line_incr in zip(code.co_lnotab[0::2], code.co_lnotab[1::2]):\n            if byte_incr:\n                yield addr, lineno\n                addr += byte_incr\n            lineno += line_incr\n        yield addr, lineno\n\n    @classmethod\n    def from_code(cls, co):\n        """"""Disassemble a Python code object into a Code object""""""\n        free_cell_isection = set(co.co_cellvars) & set(co.co_freevars)\n        if free_cell_isection:\n            print(co.co_name + \': has non-empty co.co_cellvars & co.co_freevars\', free_cell_isection)\n            return None\n\n        co_code = co.co_code\n        labels = {addr: Label() for addr in findlabels(co_code)}\n        linestarts = dict(cls._findlinestarts(co))\n        cellfree = co.co_cellvars + co.co_freevars\n        code = []\n        extended_arg = 0\n        is_generator = False\n        is_coroutine = False\n\n        for i in range(0, len(co_code), 2):\n            if i in labels:\n                code.append((labels[i], None))\n            if i in linestarts:\n                code.append((SetLineno, linestarts[i]))\n            op = Opcode(co_code[i])\n            arg = co_code[i+1] | extended_arg\n            if op in hascode:\n                lastop, lastarg = code[-2]\n                if lastop != LOAD_CONST:\n                    raise ValueError(""%s should be preceded by LOAD_CONST"" % op)\n\n                sub_code = Code.from_code(lastarg)\n                if sub_code is None:\n                    print(co.co_name + \': has unexpected subcode block\')\n                    return None\n\n                code[-2] = (LOAD_CONST, sub_code)\n            if op == opcode.EXTENDED_ARG:\n                extended_arg = arg << 8\n            else:\n                if op not in hasarg:\n                    code.append((op, None))\n                    continue\n                extended_arg = 0\n                byteplay_arg = co.co_consts[arg] if op in hasconst else \\\n                               co.co_names[arg] if op in hasname else \\\n                               labels[arg] if op in hasjabs else \\\n                               labels[i + 2 + arg] if op in hasjrel else \\\n                               co.co_varnames[arg] if op in haslocal else \\\n                               cmp_op[arg] if op in hascompare else \\\n                               cellfree[arg] if op in hasfree else \\\n                               arg\n                code.append((op, byteplay_arg))\n\n            if op == YIELD_VALUE or op == YIELD_FROM:\n                is_generator = True\n\n            if op in coroutine_opcodes:\n                is_coroutine = True\n\n        varargs = not not co.co_flags & CO_VARARGS\n        varkwargs = not not co.co_flags & CO_VARKEYWORDS\n\n        force_coroutine = not is_coroutine and (co.co_flags & CO_COROUTINE)\n        force_iterable_coroutine = co.co_flags & CO_ITERABLE_COROUTINE\n        force_async_generator = co.co_flags & CO_ASYNC_GENERATOR\n\n        is_generator = False if force_async_generator else is_generator\n        force_generator = not is_generator and (co.co_flags & CO_GENERATOR)\n\n        assert not (force_coroutine and force_iterable_coroutine)\n        assert not (force_coroutine and force_async_generator)\n        assert not (force_iterable_coroutine and force_async_generator)\n        future_generator_stop = co.co_flags & CO_FUTURE_GENERATOR_STOP\n\n        return cls(code=code,\n                   freevars=co.co_freevars,\n                   args=co.co_varnames[:co.co_argcount + varargs + varkwargs + co.co_kwonlyargcount],\n                   kwonly=co.co_kwonlyargcount,\n                   varargs=varargs,\n                   varkwargs=varkwargs,\n                   newlocals=not not co.co_flags & CO_NEWLOCALS,\n                   name=co.co_name,\n                   filename=co.co_filename,\n                   firstlineno=co.co_firstlineno,\n                   docstring=co.co_consts[0] if co.co_consts and isinstance(co.co_consts[0], str) else None,\n                   force_generator=force_generator,\n                   force_coroutine=force_coroutine,\n                   force_iterable_coroutine=force_iterable_coroutine,\n                   force_async_generator=force_async_generator,\n                   future_generator_stop=future_generator_stop)\n\n    def __eq__(self, other):\n        try:\n            if (self.freevars != other.freevars or\n                    self.args != other.args or\n                    self.kwonly != other.kwonly or\n                    self.varargs != other.varargs or\n                    self.varkwargs != other.varkwargs or\n                    self.newlocals != other.newlocals or\n                    self.name != other.name or\n                    self.filename != other.filename or\n                    self.firstlineno != other.firstlineno or\n                    self.docstring != other.docstring or\n                    self.force_generator != other.force_generator or\n                    len(self.code) != len(other.code)):\n                return False\n            else:\n                if (self.force_coroutine != other.force_coroutine or\n                        self.force_iterable_coroutine != other.force_iterable_coroutine or\n                        self.future_generator_stop != other.future_generator_stop or\n                        self.force_async_generator != other.force_async_generator):\n                    return False\n\n\n            # This isn\'t trivial due to labels\n            lmap = {}\n            for (op1, arg1), (op2, arg2) in zip(self.code, other.code):\n                if isinstance(op1, Label):\n                    if lmap.setdefault(arg1, arg2) is not arg2:\n                        return False\n                else:\n                    if op1 != op2:\n                        return False\n                    if op1 in hasjump:\n                        if lmap.setdefault(arg1, arg2) is not arg2:\n                            return False\n                    elif arg1 != arg2:\n                        return False\n\n            return True\n        except:\n            return False\n\n    def _compute_stacksize(self, logging=False):\n        code = self.code\n        label_pos = {op[0]: pos for pos, op in enumerate(code) if isinstance(op[0], Label)}\n        # sf_targets are the targets of SETUP_FINALLY opcodes. They are recorded\n        # because they have special stack behaviour. If an exception was raised\n        # in the block pushed by a SETUP_FINALLY opcode, the block is popped\n        # and 3 objects are pushed. On return or continue, the block is popped\n        # and 2 objects are pushed. If nothing happened, the block is popped by\n        # a POP_BLOCK opcode and 1 object is pushed by a (LOAD_CONST, None)\n        # operation\n        # Our solution is to record the stack state of SETUP_FINALLY targets\n        # as having 3 objects pushed, which is the maximum. However, to make\n        # stack recording consistent, the get_next_stacks function will always\n        # yield the stack state of the target as if 1 object was pushed, but\n        # this will be corrected in the actual stack recording\n        sf_targets = {label_pos[arg] for op, arg in code\n                      if (op == SETUP_FINALLY or op == SETUP_WITH or op == SETUP_ASYNC_WITH)}\n\n        states = [None] * len(code)\n        maxsize = 0\n\n        class BlockType(Enum):\n            DEFAULT = 0,\n            TRY_FINALLY = 1,\n            TRY_EXCEPT = 2,\n            LOOP_BODY = 3,\n            WITH_BLOCK = 4,\n            EXCEPTION = 5,\n            SILENCED_EXCEPTION_BLOCK = 6,\n\n        class State:\n\n            def __init__(self, pos=0, stack=(0,), block_stack=(BlockType.DEFAULT,), log=[]):\n                self._pos = pos\n                self._stack = stack\n                self._block_stack = block_stack\n                self._log = log\n\n            @property\n            def pos(self):\n                return self._pos\n\n            @property\n            def stack(self):\n                return self._stack\n\n            @stack.setter\n            def stack(self, val):\n                self._stack = val\n\n            def newstack(self, n):\n                if self._stack[-1] < -n:\n                    raise ValueError(""Popped a non-existing element at %s %s"" %\n                                     (self._pos, code[self._pos - 4: self._pos + 3]))\n                return self._stack[:-1] + (self._stack[-1] + n,)\n\n            @property\n            def block_stack(self):\n                return self._block_stack\n\n            @property\n            def log(self):\n                return self._log\n\n            def newlog(self, msg):\n                if not logging:\n                    return None\n\n                log_msg = str(self._pos) + "": "" + msg\n                if self._stack:\n                    log_msg += "" (on stack: ""\n                    log_depth = 2\n                    log_depth = min(log_depth, len(self._stack))\n                    for pos in range(-1, -log_depth, -1):\n                        log_msg += str(self._stack[pos]) + "", ""\n                    log_msg += str(self._stack[-log_depth])\n                    log_msg += "")""\n                else:\n                    log_msg += "" (empty stack)""\n                return [log_msg] + self._log\n\n        op = [State()]\n\n        while op:\n            cur_state = op.pop()\n            o = sum(cur_state.stack)\n            if o > maxsize:\n                maxsize = o\n\n            o, arg = code[cur_state.pos]\n\n            if isinstance(o, Label):\n                if cur_state.pos in sf_targets:\n                    cur_state.stack = cur_state.newstack(5)\n                if states[cur_state.pos] is None:\n                    states[cur_state.pos] = cur_state\n                elif states[cur_state.pos].stack != cur_state.stack:\n                    check_pos = cur_state.pos + 1\n                    while code[check_pos][0] not in hasflow:\n                        check_pos += 1\n                    if code[check_pos][0] not in (RETURN_VALUE, RAISE_VARARGS, STOP_CODE):\n                        if cur_state.pos not in sf_targets:\n                            raise ValueError(""Inconsistent code at %s %s %s\\n%s"" %\n                                             (cur_state.pos, cur_state.stack, states[cur_state.pos].stack,\n                                              code[cur_state.pos - 5:cur_state.pos + 4]))\n                        else:\n                            # SETUP_FINALLY target inconsistent code!\n                            #\n                            # Since Python 3.2 assigned exception is cleared at the end of\n                            # the except clause (named exception handler).\n                            # To perform this CPython (checked in version 3.4.3) adds special\n                            # bytecode in exception handler which currently breaks \'regularity\' of bytecode.\n                            # Exception handler is wrapped in try/finally block and POP_EXCEPT opcode\n                            # is inserted before END_FINALLY, as a result cleanup-finally block is executed outside\n                            # except handler. It\'s not a bug, as it doesn\'t cause any problems during execution, but\n                            # it breaks \'regularity\' and we can\'t check inconsistency here. Maybe issue should be\n                            # posted to Python bug tracker.\n                            pass\n                    continue\n                else:\n                    continue\n\n            if o not in (BREAK_LOOP, RETURN_VALUE, RAISE_VARARGS, STOP_CODE):\n                next_pos = cur_state.pos + 1\n\n                if not isopcode(o):\n                    op += State(next_pos, cur_state.stack, cur_state.block_stack, cur_state.log),\n\n                elif o not in hasflow:\n                    if o in hasarg and not isinstance(arg, int):\n                        se = stack_effect(o, 0)\n                    else:\n                        se = stack_effect(o, arg)\n\n                    log = cur_state.newlog(""non-flow command ("" + str(o) + "", se = "" + str(se) + "")"")\n                    op += State(next_pos, cur_state.newstack(se), cur_state.block_stack, log),\n\n                elif o == FOR_ITER:\n                    inside_for_log = cur_state.newlog(""FOR_ITER (+1)"")\n                    op += State(label_pos[arg], cur_state.newstack(-1), cur_state.block_stack, cur_state.log),\\\n                          State(next_pos, cur_state.newstack(1), cur_state.block_stack, inside_for_log)\n\n                elif o in (JUMP_FORWARD, JUMP_ABSOLUTE):\n                    after_jump_log = cur_state.newlog(str(o))\n                    op += State(label_pos[arg], cur_state.stack, cur_state.block_stack, after_jump_log),\n\n                elif o in (JUMP_IF_FALSE_OR_POP, JUMP_IF_TRUE_OR_POP):\n                    after_jump_log = cur_state.newlog(str(o) + "", jumped"")\n                    log = cur_state.newlog(str(o) + "", not jumped (-1)"")\n                    op += State(label_pos[arg], cur_state.stack, cur_state.block_stack, after_jump_log),\\\n                          State(next_pos, cur_state.newstack(-1), cur_state.block_stack, log)\n\n                elif o in {POP_JUMP_IF_TRUE, POP_JUMP_IF_FALSE}:\n                    after_jump_log = cur_state.newlog(str(o) + "", jumped (-1)"")\n                    log = cur_state.newlog(str(o) + "", not jumped (-1)"")\n                    op += State(label_pos[arg], cur_state.newstack(-1), cur_state.block_stack, after_jump_log),\\\n                          State(next_pos, cur_state.newstack(-1), cur_state.block_stack, log)\n\n                elif o == CONTINUE_LOOP:\n                    next_stack, next_block_stack = cur_state.stack, cur_state.block_stack\n                    last_popped_block = None\n                    while next_block_stack[-1] != BlockType.LOOP_BODY:\n                        last_popped_block = next_block_stack[-1]\n                        next_stack, next_block_stack = next_stack[:-1], next_block_stack[:-1]\n\n                    if next_stack != cur_state.stack:\n                        log = cur_state.newlog(""CONTINUE_LOOP, from non-loop block"")\n                    else:\n                        log = cur_state.newlog(""CONTINUE_LOOP"")\n\n                    jump_to_pos = label_pos[arg]\n                    if last_popped_block == BlockType.WITH_BLOCK:\n                        next_stack = next_stack[:-1] + (next_stack[-1] - 1,)\n                    op += State(jump_to_pos, next_stack, next_block_stack, log),\n\n                elif o == SETUP_LOOP:\n                    inside_loop_log = cur_state.newlog(""SETUP_LOOP (+block)"")\n                    op += State(label_pos[arg], cur_state.stack, cur_state.block_stack, cur_state.log),\\\n                          State(next_pos, cur_state.stack + (0,), cur_state.block_stack + (BlockType.LOOP_BODY,), inside_loop_log)\n\n                elif o == SETUP_EXCEPT:\n                    inside_except_log = cur_state.newlog(""SETUP_EXCEPT, exception (+6, +block)"")\n                    inside_try_log = cur_state.newlog(""SETUP_EXCEPT, try-block (+block)"")\n                    op += State(label_pos[arg], cur_state.stack + (6,), cur_state.block_stack + (BlockType.EXCEPTION,), inside_except_log),\\\n                          State(next_pos, cur_state.stack + (0,), cur_state.block_stack + (BlockType.TRY_EXCEPT,), inside_try_log)\n\n                elif o == SETUP_FINALLY:\n                    inside_finally_block = cur_state.newlog(""SETUP_FINALLY (+1)"")\n                    inside_try_log = cur_state.newlog(""SETUP_FINALLY try-block (+block)"")\n                    op += State(label_pos[arg], cur_state.newstack(1), cur_state.block_stack, inside_finally_block),\\\n                          State(next_pos, cur_state.stack + (0,), cur_state.block_stack + (BlockType.TRY_FINALLY,), inside_try_log)\n\n                elif o == POP_BLOCK:\n                    log = cur_state.newlog(""POP_BLOCK (-block)"")\n                    op += State(next_pos, cur_state.stack[:-1], cur_state.block_stack[:-1], log),\n\n                elif o == POP_EXCEPT:\n                    log = cur_state.newlog(""POP_EXCEPT (-block)"")\n                    op += State(next_pos, cur_state.stack[:-1], cur_state.block_stack[:-1], log),\n\n                elif o == END_FINALLY:\n                    if cur_state.block_stack[-1] == BlockType.SILENCED_EXCEPTION_BLOCK:\n                        log = cur_state.newlog(""END_FINALLY pop silenced exception block (-block)"")\n                        op += State(next_pos, cur_state.stack[:-1], cur_state.block_stack[:-1], log),\n                    elif cur_state.block_stack[-1] == BlockType.EXCEPTION:\n                        # Reraise exception\n                        pass\n                    else:\n                        log = cur_state.newlog(""END_FINALLY (-6)"")\n                        op += State(next_pos, cur_state.newstack(-6), cur_state.block_stack, log),\n\n                elif o == SETUP_WITH or o == SETUP_ASYNC_WITH:\n                    inside_with_block = cur_state.newlog(""SETUP_WITH, with-block (+1, +block)"")\n                    inside_finally_block = cur_state.newlog(""SETUP_WITH, finally (+1)"")\n                    op += State(label_pos[arg], cur_state.newstack(1), cur_state.block_stack, inside_finally_block),\\\n                          State(next_pos, cur_state.stack + (1,), cur_state.block_stack + (BlockType.WITH_BLOCK,), inside_with_block)\n\n                elif o == WITH_CLEANUP_START:\n                    # There is special case when \'with\' __exit__ function returns True,\n                    # that\'s the signal to silence exception, in this case additional element is pushed\n                    # and next END_FINALLY command won\'t reraise exception.\n                    # Emulate this situation on WITH_CLEANUP_START with creating special block which will be\n                    # handled differently by WITH_CLEANUP_FINISH and will cause END_FINALLY not to reraise exception.\n                    log = cur_state.newlog(""WITH_CLEANUP_START (+1)"")\n                    silenced_exception_log = cur_state.newlog(""WITH_CLEANUP_START silenced_exception (+block)"")\n                    op += State(next_pos, cur_state.newstack(1), cur_state.block_stack, log),\\\n                          State(next_pos, cur_state.newstack(-7) + (9,), cur_state.block_stack + (BlockType.SILENCED_EXCEPTION_BLOCK,), silenced_exception_log)\n\n                elif o == WITH_CLEANUP_FINISH:\n                    if cur_state.block_stack[-1] == BlockType.SILENCED_EXCEPTION_BLOCK:\n                        # See comment in WITH_CLEANUP_START handler\n                        log = cur_state.newlog(""WITH_CLEANUP_FINISH silenced_exception (-1)"")\n                        op += State(next_pos, cur_state.newstack(-1), cur_state.block_stack, log),\n                    else:\n                        log = cur_state.newlog(""WITH_CLEANUP_FINISH (-2)"")\n                        op += State(next_pos, cur_state.newstack(-2), cur_state.block_stack, log),\n\n                else:\n                    raise ValueError(""Unhandled opcode %s"" % o)\n\n        return maxsize + 6  # for exception raise in deepest place\n\n    def to_code(self, from_function=False):\n        """"""Assemble a Python code object from a Code object""""""\n\n        num_fastnames = sum(1 for op, arg in self.code if isopcode(op) and op in haslocal)\n        is_function = self.newlocals or num_fastnames > 0 or len(self.args) > 0\n        nested = is_function and from_function\n\n        co_flags = {op[0] for op in self.code}\n\n        if not self.force_async_generator:\n            is_generator = (self.force_generator or\n                            (YIELD_VALUE in co_flags or YIELD_FROM in co_flags)\n                            )\n        else:\n            is_generator = False\n        no_free = (not self.freevars) and (not co_flags & hasfree)\n\n        is_native_coroutine = bool(self.force_coroutine or (co_flags & coroutine_opcodes))\n        assert not (is_native_coroutine and self.force_iterable_coroutine)\n        assert not (is_native_coroutine and self.force_async_generator)\n\n        co_flags =\\\n            (not(STORE_NAME in co_flags or LOAD_NAME in co_flags or DELETE_NAME in co_flags)) |\\\n            (self.newlocals and CO_NEWLOCALS) |\\\n            (self.varargs and CO_VARARGS) |\\\n            (self.varkwargs and CO_VARKEYWORDS) |\\\n            (is_generator and CO_GENERATOR) |\\\n            (no_free and CO_NOFREE) |\\\n            (nested and CO_NESTED)\n\n        co_flags |= (is_native_coroutine and CO_COROUTINE) |\\\n                    (self.force_iterable_coroutine and CO_ITERABLE_COROUTINE) |\\\n                    (self.future_generator_stop and CO_FUTURE_GENERATOR_STOP) |\\\n                    (self.force_async_generator and CO_ASYNC_GENERATOR)\n\n        co_consts = [self.docstring]\n        co_names = []\n        co_varnames = list(self.args)\n        co_freevars = tuple(self.freevars)\n\n        # Find all cellvars beforehand for two reasons\n        # Need the number of them to construct the numeric arg for ops in hasfree\n        # Need to put args which are cells in the beginning of co_cellvars\n        cellvars = {arg for op, arg in self.code\n                    if isopcode(op) and op in hasfree\n                    and arg not in co_freevars}\n        co_cellvars = [jumps for jumps in self.args if jumps in cellvars]\n\n        def index(seq, item, eq=True, can_append=True):\n            for i, x in enumerate(seq):\n                if x == item if eq else x is item:\n                    return i\n            if can_append:\n                seq.append(item)\n                return len(seq) - 1\n            else:\n                raise IndexError(""Item not found"")\n\n        jumps = []\n        label_pos = {}\n        lastlineno = self.firstlineno\n        lastlinepos = 0\n        co_code = bytearray()\n        co_lnotab = bytearray()\n\n        for i, (op, arg) in enumerate(self.code):\n            if isinstance(op, Label):\n                label_pos[op] = len(co_code)\n            elif op is SetLineno:\n                incr_lineno = arg - lastlineno\n                incr_pos = len(co_code) - lastlinepos\n                lastlineno = arg\n                lastlinepos += incr_pos\n                if incr_lineno != 0 or incr_pos != 0:\n                    while incr_pos > 255:\n                        co_lnotab += b""\\xFF\\0""\n                        incr_pos -= 255\n                    while incr_lineno > 255:\n                        co_lnotab += bytes((incr_pos, 255))\n                        incr_pos = 0\n                        incr_lineno -= 255\n                    if incr_pos or incr_lineno:\n                        co_lnotab += bytes((incr_pos, incr_lineno))\n            elif op == opcode.EXTENDED_ARG:\n                self.code[i + 1][1] |= 1 << 32\n            else:\n                if op in hasconst:\n                    if (isinstance(arg, Code) and\n                            i + 2 < len(self.code) and\n                            self.code[i + 2][0] in hascode):\n                        arg = arg.to_code(from_function=is_function)\n                        assert arg is not None\n                    arg = index(co_consts, arg, 0)\n                elif op in hasname:\n                    arg = index(co_names, arg)\n                elif op in hasjump:\n                    jumps.append((len(co_code), arg))\n                    co_code += bytes((0x90, 0, op, 0))\n                    continue\n                elif op in haslocal:\n                    arg = index(co_varnames, arg)\n                elif op in hascompare:\n                    arg = index(cmp_op, arg, can_append=False)\n                elif op in hasfree:\n                    try:\n                        arg = index(co_freevars, arg, can_append=False) + len(cellvars)\n                    except IndexError:\n                        arg = index(co_cellvars, arg)\n                if arg is None:\n                    arg = 0\n                if arg > 0xFFFFFF:\n                    co_code += (opcode.EXTENDED_ARG | (arg >> 16 & 0xFF00)).to_bytes(2, ""little"")\n                if arg > 0xFFFF:\n                    co_code += (opcode.EXTENDED_ARG | (arg >> 8 & 0xFF00)).to_bytes(2, ""little"")\n                if arg > 0xFF:\n                    co_code += (opcode.EXTENDED_ARG | (arg & 0xFF00)).to_bytes(2, ""little"")\n                co_code += (op | (arg & 0xFF) << 8).to_bytes(2, ""little"")\n\n        for pos, label in jumps:\n            jump = label_pos[label]\n            if co_code[pos+2] in hasjrel:\n                jump -= pos + 4\n            if jump > 0xFFFF:\n                raise NotImplementedError(""Multiple EXTENDED_ARG jumps not implemented"")\n            co_code[pos + 3] = jump & 0xFF\n            co_code[pos + 1] = jump >> 8 & 0xFF\n\n        co_argcount = len(self.args) - self.varargs - self.varkwargs - self.kwonly\n        co_stacksize = self._compute_stacksize()\n\n        return CodeType(co_argcount, self.kwonly, len(co_varnames), co_stacksize, co_flags,\n                        bytes(co_code), tuple(co_consts), tuple(co_names), tuple(co_varnames),\n                        self.filename, self.name, self.firstlineno, bytes(co_lnotab), co_freevars,\n                        tuple(co_cellvars))\n'"
rootpy/extern/hep/__init__.py,0,b''
rootpy/extern/hep/pdg.py,0,"b'#\n# $Id: PDG.py,v 1.5 2009-01-26 03:05:43 ssnyder Exp $\n# File: PDG.py\n# Created: sss, Mar 2005\n# Purpose: Define PDG ID codes.\n#\n""""""\nThis module contains names for the various PDG particle ID codes.\nThe names are the same as in EventKernel/PdtPdg.h.\n\nThis module also contains a dictionary pdgid_names mapping ID codes\nback to printable strings, and a function pdgid_to_name to do this\nconversion.  Similarly, root_names and pdgid_to_root_name translate to\nstrings with root markup.\n""""""\nfrom __future__ import absolute_import\n\nfrom ROOT import TDatabasePDG\nfrom pkg_resources import resource_filename\nimport os\n\ndb = TDatabasePDG()\ndb.ReadPDGTable(resource_filename(\'rootpy\', \'etc/pdg_table.txt\'))\n\n\ndef GetParticle(id):\n    return db.GetParticle(id)\n\n# Table to translate from PDG IDs to printable strings.\npdgid_names = {}\n\n# Table to translate from PDG IDs to strings with root markup.\nroot_names = {}\n\n\ndef id_to_name(id):\n    """"""\n    Convert a PDG ID to a printable string.\n    """"""\n    name = pdgid_names.get(id)\n    if not name:\n        name = repr(id)\n    return name\n\n\ndef id_to_root_name(id):\n    """"""\n    Convert a PDG ID to a string with root markup.\n    """"""\n    name = root_names.get(id)\n    if not name:\n        name = repr(id)\n    return name\n\n#\n# Table of PDG IDs, associating the ID codes with up to several names.\n# This is formatted as one big string to make it easier to maintain\n# (don\'t need to quote everything individually).\n# The format of each line is like this:\n#\n#    mname = id     pname   rname\n#\n# An attribute mname will be added to this module with a value of id.\n# These names are intended to match those in PdgPdt.h.\n# pname is a printable name for the entry, and rname is a name\n# with root-style markup.  These names will be put into the pdgid_names\n# and root_names dictionaries, respectively.  They can be left as `!\'\n# if no name is available.  pname and rname should not contain spaces.\n# Blank lines or those starting with `#\' will be ignored.\n#\n_pdgtable = \\\n""""""\nd = 1                                 D            d\nanti_d = -1                           DBAR         #bar{d}\nu = 2                                 U            u\nanti_u = -2                           UBAR         #bar{u}\ns = 3                                 S            s\nanti_s = -3                           SBAR         #bar{s}\nc = 4                                 C            c\nanti_c = -4                           CBAR         #bar{c}\nb = 5                                 B            b\nanti_b = -5                           BBAR         #bar{b}\nt = 6                                 T            t\nanti_t = -6                           TBAR         #bar{t}\nl = 7                                 LPRIME       !\nanti_l = -7                           LPRIMEBAR    !\nh = 8                                 !            !\nanti_h = -8                           !            !\ng = 21                                GLUE         g\ne_minus = 11                          E-           e^{-}\ne_plus = -11                          E+           e^{+}\nnu_e = 12                             NUE          #nu_{e}\nanti_nu_e = -12                       ANUE         #bar{#nu}_{e}\nmu_minus = 13                         MU-          #mu^{-}\nmu_plus = -13                         MU+          #mu^{+}\nnu_mu = 14                            NUM          #nu_{#mu}\nanti_nu_mu = -14                      ANUM         #bar{#nu}_{#mu}\ntau_minus = 15                        TAU-         #tau^{-}\ntau_plus = -15                        TAU+         #tau^{+}\nnu_tau = 16                           NUT          #nu_{#tau}\nanti_nu_tau = -16                     ANUT         #bar{nu}_{#tau}\nL_minus = 17                          !            !\nL_plus = -17                          !            !\nnu_L = 18                             !            !\nanti_nu_L = -18                       !            !\ngamma = 22                            PHOT         #gamma\nZ0 = 23                               Z0           Z\nW_plus = 24                           W+           W^{+}\nW_minus = -24                         W-           W^{-}\nHiggs0 = 25                           H0           h^{0}\nreggeon = 28                          !            !\npomeron = 29                          !            !\nZ_prime0 = 32                         !            !\nZ_prime_prime0 = 33                   !            !\nW_prime_plus = 34                     !            !\nW_prime_minus = -34                   !            !\nHiggs_prime0 = 35                     !            !\nA0 = 36                               !            !\nHiggs_plus = 37                       !            !\nHiggs_minus = -37                     !            !\nR0 = 40                               !            !\nanti_R0 = -40                         !            !\nspecflav = 81                         !            !\nrndmflav = 82                         !            !\nanti_rndmflav = -82                   !            !\nphasespa = 83                         !            !\nc_minushadron = 84                    !            !\nanti_c_minushadron = -84              !            !\nb_minushadron = 85                    !            !\nanti_b_minushadron = -85              !            !\nt_minushadron = 86                    !            !\nanti_t_minushadron = -86              !            !\nWvirt_plus = 89                       !            !\nWvirt_minus = -89                     !            !\ndiquark = 90                          !            !\nanti_diquark = -90                    !            !\ncluster = 91                          CLUSTER      cluster\nstring = 92                           !            !\nindep = 93                            !            !\nCMshower = 94                         !            !\nSPHEaxis = 95                         !            !\nTHRUaxis = 96                         !            !\nCLUSjet = 97                          !            !\nCELLjet = 98                          !            !\ntable = 99                            !            !\npi0 = 111                             PI0          #pi^{0}\npi_plus = 211                         PI+          #pi^{+}\npi_minus = -211                       PI-          #pi^{-}\npi_diffr_plus = 210                   !            !\npi_diffr_minus = -210                 !            !\npi_2S0 = 20111                        !            !\npi_2S_plus = 20211                    !            !\npi_2S_minus = -20211                  !            !\neta = 221                             ETA          #eta\neta_2S = 20221                        !            !\neta_prime = 331                       !            !\nrho0 = 113                            !            #rho^{0}\nrho_plus = 213                        RHO+         #rho^{+}\nrho_minus = -213                      RHO-         #rho^{-}\nrho_2S0 = 30113                       !            !\nrho_2S_plus = 30213                   !            !\nrho_2S_minus = -30213                 !            !\nrho_3S0 = 40113                       !            !\nrho_3S_plus = 40213                   !            !\nrho_3S_minus = -40213                 !            !\nomega = 223                           !            !\nomega_2S = 30223                      !            !\nphi = 333                             PHI          #phi\na_00 = 10111                          !            !\na_0_plus = 10211                      !            !\na_0_minus = -10211                    !            !\nf_0 = 10221                           !            !\nf_prime_0 = 10331                     !            !\nb_10 = 10113                          !            !\nb_1_plus = 10213                      !            !\nb_1_minus = -10213                    !            !\nh_1 = 10223                           h_1          h_{1}\nh_prime_1 = 10333                     !            !\na_10 = 20113                          !            !\na_1_plus = 20213                      !            !\na_1_minus = -20213                    !            !\nf_1 = 20223                           !            !\nf_prime_1 = 20333                     !            !\na_20 = 115                            !            !\na_2_plus = 215                        a_2+         a_{2}^{+}\na_2_minus = -215                      a_2-         a_{2}^{-}\nf_2 = 225                             !            !\nf_prime_2 = 335                       !            !\nK0 = 311                              K0           K^{0}\nanti_K0 = -311                        K0BAR        #bar{K}^0\nK_S0 = 310                            K_S0         K_{S}^{0}\nK_L0 = 130                            K_L0         K_{L}^{0}\nK_plus = 321                          K+           K^{+}\nK_minus = -321                        K-           K^{-}\nK_star0 = 313                         K*           K^{*}\nanti_K_star0 = -313                   K*BAR        #bar{K}^{*}\nK_star_plus = 323                     !            !\nK_star_minus = -323                   !            !\nK_0_star0 = 10311                     !            !\nanti_K_0_star0 = -10311               !            !\nK_0_star_plus = 10321                 !            !\nK_0_star_minus = -10321               !            !\nK_10 = 10313                          !            !\nanti_K_10 = -10313                    !            !\nK_1_plus = 10323                      !            !\nK_1_minus = -10323                    !            !\nK_2_star0 = 315                       !            !\nanti_K_2_star0 = -315                 !            !\nK_2_star_plus = 325                   K_2*+        K_{2}^{*+}\nK_2_star_minus = -325                 K_2*-        K_{2}^{*-}\nK_prime_10 = 20313                    !            !\nanti_K_prime_10 = -20313              !            !\nK_prime_1_plus = 20323                !            !\nK_prime_1_minus = -20323              !            !\nD_plus = 411                          D+           D^{+}\nD_minus = -411                        D-           D^{-}\nD0 = 421                              D0           D^{0}\nanti_D0 = -421                        D0BAR        #bar{D}^{0}\nD_star_plus = 413                     !            !\nD_star_minus = -413                   !            !\nD_star0 = 423                         !            !\nanti_D_star0 = -423                   !            !\nD_0_star_plus = 10411                 !            !\nD_0_star_minus = -10411               !            !\nD_0_star0 = 10421                     !            !\nanti_D_0_star0 = -10421               !            !\nD_1_plus = 10413                      !            !\nD_1_minus = -10413                    !            !\nD_10 = 10423                          !            !\nanti_D_10 = -10423                    !            !\nD_2_star_plus = 415                   !            !\nD_2_star_minus = -415                 !            !\nD_2_star0 = 425                       !            !\nanti_D_2_star0 = -425                 !            !\nD_prime_1_plus = 20413                !            !\nD_prime_1_minus = -20413              !            !\nD_prime_10 = 20423                    !            !\nanti_D_prime_10 = -20423              !            !\nD_s_plus = 431                        D_S+         D_{s}^{+}\nD_s_minus = -431                      D_S-         D_{s}^{-}\nD_s_star_plus = 433                   !            !\nD_s_star_minus = -433                 !            !\nD_s0_star_plus = 10431                !            !\nD_s0_star_minus = -10431              !            !\nD_s1_plus = 10433                     !            !\nD_s1_minus = -10433                   !            !\nD_s2_star_plus = 435                  !            !\nD_s2_star_minus = -435                !            !\nD_prime_s1_plus = 20433               !            !\nD_prime_s1_minus = -20433             !            !\nB0 = 511                              B0           B^{0}\nanti_B0 = -511                        B0BAR        #bar{B}^{0}\nB_plus = 521                          B+           B^{+}\nB_minus = -521                        B-           B^{-}\nB_star0 = 513                         !            !\nanti_B_star0 = -513                   !            !\nB_star_plus = 523                     !            !\nB_star_minus = -523                   !            !\nB_0_star0 = 10511                     !            !\nanti_B_0_star0 = -10511               !            !\nB_0_star_plus = 10521                 !            !\nB_0_star_minus = -10521               !            !\nB_10 = 10513                          !            !\nanti_B_10 = -10513                    !            !\nB_1_plus = 10523                      !            !\nB_1_minus = -10523                    !            !\nB_2_star0 = 515                       !            !\nanti_B_2_star0 = -515                 !            !\nB_2_star_plus = 525                   !            !\nB_2_star_minus = -525                 !            !\nB_prime_10 = 20513                    !            !\nanti_B_prime_10 = -20513              !            !\nB_prime_1_plus = 20523                !            !\nB_prime_1_minus = -20523              !            !\nB_s0 = 531                            B_S0         B_{s}^{0}\nanti_B_s0 = -531                      B_S0BAR      #bar{B}_{s}^{0}\nB_s_star0 = 533                       !            !\nanti_B_s_star0 = -533                 !            !\nB_s0_star0 = 10531                    !            !\nanti_B_s0_star0 = -10531              !            !\nB_s10 = 10533                         !            !\nanti_B_s10 = -10533                   !            !\nB_s2_star0 = 535                      !            !\nanti_B_s2_star0 = -535                !            !\nB_prime_s10 = 20533                   !            !\nanti_B_prime_s10 = -20533             !            !\nB_c_plus = 541                        BC+          B_{c}^{+}\nB_c_minus = -541                      BC-          B_{c}^{-}\nB_c_star_plus = 543                   BC*+         B_{c}^{*+}\nB_c_star_minus = -543                 BC*-         B_{c}^{*-}\nB_c0_star_plus = 10541                !            !\nB_c0_star_minus = -10541              !            !\nB_c1_plus = 10543                     !            !\nB_c1_minus = -10543                   !            !\nB_c2_star_plus = 545                  !            !\nB_c2_star_minus = -545                !            !\nB_prime_c1_plus = 20543               !            !\nB_prime_c1_minus = -20543             !            !\neta_c = 441                           !            !\neta_c_2S = 20441                      !            !\nJ_psi = 443                           JPSI         J/#psi\npsi_2S = 20443                        !            !\nchi_c0 = 10441                        !            !\nchi_c1 = 10443                        !            !\nchi_c2 = 445                          !            !\neta_b_2S = 20551                      !            !\neta_b_3S = 40551                      !            !\nUpsilon = 553                         !            !\nUpsilon_2S = 20553                    !            !\nUpsilon_3S = 60553                    !            !\nUpsilon_4S = 70553                    !            !\nUpsilon_5S = 80553                    !            !\nh_b = 10553                           !            !\nh_b_2P = 40553                        !            !\nh_b_3P = 100553                       !            !\nchi_b0 = 551                          !            !\nchi_b1 = 20553                        !            !\nchi_b2 = 555                          !            !\nchi_b0_2P = 30551                     !            !\nchi_b1_2P = 50553                     !            !\nchi_b2_2P = 10555                     !            !\nchi_b0_3P = 50551                     !            !\nchi_b1_3P = 110553                    !            !\nchi_b2_3P = 20555                     !            !\neta_b2_1D = 40555                     !            !\neta_b2_2D = 60555                     !            !\nUpsilon_1_1D = 120553                 !            !\nUpsilon_2_1D = 30555                  !            !\nUpsilon_3_1D = 557                    !            !\nUpsilon_1_2D = 130553                 !            !\nUpsilon_2_2D = 50555                  !            !\nUpsilon_3_2D = 10557                  !            !\nDelta_minus = 1114                    DELTA-       #Delta^{-}\nanti_Delta_plus = -1114               DELTA+       #Delta^{+}\nn_diffr = 2110                        !            !\nanti_n_diffr = -2110                  !            !\nn0 = 2112                             N            n\nanti_n0 = -2112                       NBAR         #bar{n}\nDelta0 = 2114                         !            !\nanti_Delta0 = -2114                   !            !\np_diffr_plus = 2210                   !            !\nanti_p_diffr_minus = -2210            !            !\np_plus = 2212                         P+           p^{+}\nanti_p_minus = -2212                  P-           p^{-}\nDelta_plus = 2214                     !            !\nanti_Delta_minus = -2214              !            !\nDelta_plus_plus = 2224                !            !\nanti_Delta_minus_minus = -2224        !            !\nSigma_minus = 3112                    SIGMA-       #Sigma^{-}\nanti_Sigma_plus = -3112               SIGMABAR+    #bar{#Sigma}^{+}\nSigma_star_minus = 3114               !            !\nanti_Sigma_star_plus = -3114          !            !\nLambda0 = 3122                        LAMBDA_D0    #Lambda^{0}\nanti_Lambda0 = -3122                  LAMBDABAR_D0 #bar{#Lambda}^{0}\nSigma0 = 3212                         !            !\nanti_Sigma0 = -3212                   !            !\nSigma_star0 = 3214                    !            !\nanti_Sigma_star0 = -3214              !            !\nSigma_plus = 3222                     SIGMA+       #Sigma^{+}\nanti_Sigma_minus = -3222              SIGMABAR-    #bar{#Sigma}^{-}\nSigma_star_plus = 3224                !            !\nanti_Sigma_star_minus = -3224         !            !\nXi_minus = 3312                       XI-          #Xi^{-}\nanti_Xi_plus = -3312                  XI+          #Xi^{+}\nXi_star_minus = 3314                  !            !\nanti_Xi_star_plus = -3314             !            !\nXi0 = 3322                            XI0          #Xi^{0}\nanti_Xi0 = -3322                      XIBAR0       #bar{Xi}^{0}\nXi_star0 = 3324                       !            !\nanti_Xi_star0 = -3324                 !            !\nOmega_minus = 3334                    !            !\nanti_Omega_plus = -3334               !            !\nSigma_c0 = 4112                       !            !\nanti_Sigma_c0 = -4112                 !            !\nSigma_c_star0 = 4114                  SIGMA_C0*    #Sigma_{c}^{*0}\nanti_Sigma_c_star0 = -4114            SIGMABAR_C0* #bar{#Sigma}_{c}^{*0}\nLambda_c_plus = 4122                  LAMBDA_C+    #Lambda_{c}^{+}\nanti_Lambda_c_minus = -4122           LAMBDA_C-    #Lambda_{c}^{-}\nXi_c0 = 4132                          XI_C0        #Xi_{c}^{0}\nanti_Xi_c0 = -4132                    XIBAR_C0     #bar{#Xi}_{c}^{0}\nSigma_c_plus = 4212                   SIGMA_C+     #Sigma_{c}^{+}\nanti_Sigma_c_minus = -4212            SIGMA_C-     #Sigma_{c}^{-}\nSigma_c_star_plus = 4214              SIGMA_C+*    #Sigma_{c}^{*+}\nanti_Sigma_c_star_minus = -4214       SIGMA_C-*    #Sigma_{c}^{*-}\nSigma_c_plus_plus = 4222              SIGMA_C++    #Sigma_{c}^{++}\nanti_Sigma_c_minus_minus = -4222      SIGMA_C--    #Sigma_{c}^{--}\nSigma_c_star_plus_plus = 4224         SIGMA_C++*   #Sigma_{c}^{*++}\nanti_Sigma_c_star_minus_minus = -4224 SIGMA_C--*   #Sigma_{c}^{*--}\nXi_c_plus = 4322                      XI_C+        #Xi_{c}^{+}\nanti_Xi_c_minus = -4322               XI_C-        #Xi_{c}^{-}\nXi_prime_c0 = 4312                    XI\'_C0       #Xi\\\'_{c}^{0}\nXi_primeanti__c0 = -4312              XIBAR\'_C0    #bar{#Xi}\\\'_{c}^{0}\nXi_c_star0 = 4314                     XI_C0*       #Xi_{c}^{*0}\nanti_Xi_c_star0 = -4314               XIBAR_C0*    #bar{#Xi}_{c}^{*0}\nXi_prime_c_plus = 4232                XI\'_C+       #Xi\\\'_{c}^{+}\nXi_primeanti__c_minus = -4232         XIBAR\'_C-    #Xi\\\'_{c}^{-}\nXi_c_star_plus = 4324                 XI_C+*       #Xi_{c}^{*+}\nanti_Xi_c_star_minus = -4324          XI_C-*       #Xi_{c}^{*-}\nOmega_c0 = 4332                       OMEGA_C0     #Omega_{c}^{0}\nanti_Omega_c0 = -4332                 OMEGABAR_C0  #bar{#Omega}_{c}^{0}\nOmega_c_star0 = 4334                  OMEGA_C0*    #Omega_{c}^{*0}\nanti_Omega_c_star0 = -4334            OMEGA_C0*    #bar{#Omega}_{c}^{*0}\nSigma_b_minus = 5112                  SIGMA_B-     #Sigma_{b}^{-}\'\nanti_Sigma_b_plus = -5112             SIGMA_B+     #Sigma_{b}^{+}\'\nSigma_b_star_minus = 5114             !            !\nanti_Sigma_b_star_plus = -5114        !            !\nLambda_b0 = 5122                      LAMBDA_B0    #Lambda_{b}^{0}\nanti_Lambda_b0 = -5122                LAMBDA_B0BAR #bar{#Lambda}_{b}^0\nXi_b_minus = 5132                     !            !\nanti_Xi_b_plus = -5132                !            !\nSigma_b0 = 5212                       SIGMA_B0     #Sigma_{b}^{0}\nanti_Sigma_b0 = -5212                 SIGMABAR_B0  #bar{#Sigma}_{b}^{0}\nSigma_b_star0 = 5214                  !            !\nanti_Sigma_b_star0 = -5214            !            !\nSigma_b_plus = 5222                   !            !\nanti_Sigma_b_minus = -5222            !            !\nSigma_star_ = 5224                    !            !\nanti_Sigma_b_star_minus = -5224       !            !\nXi_b0 = 5232                          XI_B0        #Xi_b^{0}\nanti_Xi_b0 = -5232                    XIBAR_B0     #bar{#Xi}_b^{0}\nXi_prime_b_minus = 5312               !            !\nanti_Xi_prime_b_plus = -5312          !            !\nXi_b_star_minus = 5314                !            !\nanti_Xi_b_star_plus = -5314           !            !\nXi_prime_b0 = 5322                    !            !\nanti_Xi_prime_b0 = -5322              !            !\nXi_b_star0 = 5324                     !            !\nanti_Xi_b_star0 = -5324               !            !\nOmega_b_minus = 5332                  !            !\nanti_Omega_b_plus = -5332             !            !\nOmega_b_star_minus = 5334             !            !\nanti_Omega_b_star_plus = -5334        !            !\ndd_0 = 1101                           !            !\nanti_dd_0 = -1101                     !            !\nud_0 = 2101                           UD0          !\nanti_ud_0 = -2101                     UD0BAR       !\nuu_0 = 2201                           !            !\nanti_uu_0 = -2201                     !            !\nsd_0 = 3101                           !            !\nanti_sd_0 = -3101                     !            !\nsu_0 = 3201                           !            !\nanti_su_0 = -3201                     !            !\nss_0 = 3301                           !            !\nanti_ss_0 = -3301                     !            !\ncd_0 = 4101                           !            !\nanti_cd_0 = -4101                     !            !\ncu_0 = 4201                           !            !\nanti_cu_0 = -4201                     !            !\ncs_0 = 4301                           !            !\nanti_cs_0 = -4301                     !            !\ncc_0 = 4401                           !            !\nanti_cc_0 = -4401                     !            !\nbd_0 = 5101                           !            !\nanti_bd_0 = -5101                     !            !\nbu_0 = 5201                           !            !\nanti_bu_0 = -5201                     !            !\nbs_0 = 5301                           !            !\nanti_bs_0 = -5301                     !            !\nbc_0 = 5401                           !            !\nanti_bc_0 = -5401                     !            !\nbb_0 = 5501                           !            !\nanti_bb_0 = -5501                     !            !\ndd_1 = 1103                           !            !\nanti_dd_1 = -1103                     !            !\nud_1 = 2103                           !            !\nanti_ud_1 = -2103                     !            !\nuu_1 = 2203                           !            !\nanti_uu_1 = -2203                     !            !\nsd_1 = 3103                           !            !\nanti_sd_1 = -3103                     !            !\nsu_1 = 3203                           !            !\nanti_su_1 = -3203                     !            !\nss_1 = 3303                           !            !\nanti_ss_1 = -3303                     !            !\ncd_1 = 4103                           !            !\nanti_cd_1 = -4103                     !            !\ncu_1 = 4203                           !            !\nanti_cu_1 = -4203                     !            !\ncs_1 = 4303                           !            !\nanti_cs_1 = -4303                     !            !\ncc_1 = 4403                           !            !\nanti_cc_1 = -4403                     !            !\nbd_1 = 5103                           !            !\nanti_bd_1 = -5103                     !            !\nbu_1 = 5203                           !            !\nanti_bu_1 = -5203                     !            !\nbs_1 = 5303                           !            !\nanti_bs_1 = -5303                     !            !\nbc_1 = 5403                           !            !\nanti_bc_1 = -5403                     !            !\nbb_1 = 5503                           !            !\nanti_bb_1 = -5503                     !            !\n\n# SUSY Particles names modified from /Control/AthenaCommon/PDGTABLE.MeV\n# naming convention change\n#      \'~\' to \'s_\'\n#      \'(\' to \'_\'\n#      \')\' to nothing\n#      \'+\' to \'plus\'\n#      \'\' to \'_\'\n#      for the negatively charged particles so I add ""minus"" to the name and a corresponding ""plus"" entry with -pdg code\n#      for the neutrals I add a corresponding ""anti"" entry with -pdg code\n#      for the particles with positive charge entries I add a corresponding ""minus"" entry with -pdg code\n# ************ (the above is not consistent with the convention that minus=particle plus=anti-particle\n#\n#      Next remove Majorana particles and rename L-R stau to mass eigenstates.\n#\n#      This is all ugly but sort of consistent with previous naming convention\n\ns_e_minus_L    =1000011               !            !\ns_e_plus_L     =-1000011              !            !\n\ns_nu_e_L       =1000012               !            !\ns_anti_nu_e_L  =-1000012              !            !\n\ns_mu_minus_L   =1000013               !            !\ns_mu_plus_L    =-1000013              !            !\n\ns_nu_mu_L      =1000014               !            !\ns_anti_nu_mu_L =-1000014              !            !\n\n#    s_tau_minus_L  =1000015\n#    s_tau_plus_L   =-1000015\n\n# L-R mixing significant use _1 and _2 for names instead\ns_tau_minus_1  =1000015               !            !\ns_tau_plus_1   =-1000015              !            !\n\ns_nu_tau_L     =1000016               !            !\ns_anti_nu_tau_L=-1000016              !            !\n\ns_e_minus_R    =2000011               !            !\ns_e_plus_R     =-2000011              !            !\n\ns_mu_minus_R   =2000013               !            !\ns_mu_plus_R    =-2000013              !            !\n\ns_tau_minus_2  =2000015               !            !\ns_tau_plus_2   =-2000015              !            !\n\ns_g            =1000021               !            !\n#    s_anti_g       =-1000021 # Majorana\n\ns_chi_0_1      =1000022               !            !\n#    s_anti_chi_0_1 =-1000022 # Majorana\n\ns_chi_0_2      =1000023               !            !\n#    s_anti_chi_0_2 =-1000023 # Majorana\n\ns_chi_plus_1   =1000024               !            !\n# Majorana\ns_chi_minus_1  =-1000024              !            !\n\ns_chi_0_3      =1000025               !            !\n#    s_anti_chi_0_3 =-1000025 # Majorana\n\ns_chi_0_4      =1000035               !            !\n#    s_anti_chi_0_4 =-1000035 # Majorana\n\ns_chi_plus_2   =1000037               !            !\ns_chi_minus_2  =-1000037              !            !\n\ns_G            =1000039               !            !\n#    s_anti_G       =-1000039 # Majorana\n\n# note mismatch with PDGTable and pre-existing PdtPdg.h\n#M     999                          0.E+00         +0.0E+00 -0.0E+00 Geantino        0\n#W     999                          0.E+00         +0.0E+00 -0.0E+00 Geantino        0\n\n# doubly charged Higgs\nHiggs_plus_plus_L = 9900041           !            !\nHiggs_minus_minus_L = -9900041        !            !\nHiggs_plus_plus_R = 9900042           !            !\nHiggs_minus_minus_R = -9900042        !            !\n\n\n# Null particles\ndeuteron = 0                          !            !\ntritium = 0                           !            !\nalpha = 0                             !            !\ngeantino = 0                          !            !\nHe3 = 0                               !            !\nCerenkov = 0                          !            !\nnull = 0                              !            !\n\n\n# Some extra particles that weren\'t in PdgPdt.h\nXi_cc_plus = 4412                     XI_CC+       #Xi_{cc}^{+}\nanti_Xi_cc_minus = -4412              XI_CC-       #Xi_{cc}^{-}\nXi_cc_plus_plus = 4422                XI_CC++      #Xi_{cc}^{++}\nanti_Xi_cc_minus_minus = -4422        XI_CC--      #Xi_{cc}^{--}\nXi_cc_star_plus = 4414                XI_CC+*      #Xi_{cc}^{*+}\nanti_Xi_cc_star_minus = -4414         XI_CC-*      #Xi_{cc}^{*-}\nXi_cc_star_plus_plus = 4424           XI_CC++*     #Xi_{cc}^{*++}\nanti_Xi_cc_star_minus_minus = -4424   XI_CC--*     #Xi_{cc}^{*--}\nOmega_cc_plus = 4432                  OMEGA_CC+    #Omega_{cc}^{+}\nanti_Omega_cc_minus = -4432           OMEGA_CC-    #Omega_{cc}^{-}\nOmega_cc_star_plus = 4434             OMEGA_CC+*   #Omega_{cc}^{*+}\nanti_Omega_cc_star_minus = -4434      OMEGA_CC-*   #Omega_{cc}^{*-}\nOmega_ccc_plus_plus = 4444            OMEGA_CCC++  #Omega_{ccc}^{++}\nanti_Omega_ccc_minus_minus = -4444    OMEGA_CCC--  #Omega_{ccc}^{--}\n\n\n# A couple extra synonyms that weren\'t in PdgPdt.h.\ne = e_minus                           !            !\nmu = mu_minus                         !            !\ntau = tau_minus                       !            !\nW = W_plus                            !            !\n""""""\n\n\n# Parse _pdgtable and fill in dictionaries.\ndef _fill_dicts():\n    import string\n    pdgid_names.clear()\n    root_names.clear()\n    for line in _pdgtable.split (\'\\n\'):\n        line = line.strip()\n        if len(line) == 0 or line[0] == \'#\': continue\n        ll = line.split(\'=\', 1)\n        if len(ll) < 2:\n            print(\'bad line: {0}\'.format(line))\n            continue\n        mname = string.strip(ll[0])\n        ll = ll[1].split()\n        if len(ll) < 1:\n            print(\'bad line: {0}\'.format(line))\n            continue\n        id = ll[0]\n        pname = None\n        if len(ll) >= 2 and ll[1] != \'!\':\n            pname = ll[1]\n        rname = None\n        if len(ll) >= 3 and ll[2] != \'!\':\n            rname = ll[2]\n        try:\n            id = int(id)\n        except ValueError:\n            id = globals().get(id)\n            if id == None:\n                print(\'bad line: {0}\'.format(line))\n                continue\n\n        if pname == None:\n            pname = mname\n        if rname == None:\n            rname = pname\n\n        globals()[mname] = id\n        if not pdgid_names.has_key(id):\n            pdgid_names[id] = pname\n        if not root_names.has_key(id):\n            root_names[id] = rname\n    return\n\n# Fill the dictionaries.\n_fill_dicts()\n\n# Kill these now to save memory.\ndel _pdgtable\ndel _fill_dicts\n'"
rootpy/extern/lockfile/__init__.py,0,"b'""""""\nlockfile.py - Platform-independent advisory file locks.\n\nRequires Python 2.5 unless you apply 2.4.diff\nLocking is done on a per-thread basis instead of a per-process basis.\n\nUsage:\n\n>>> lock = LockFile(\'somefile\')\n>>> try:\n...     lock.acquire()\n... except AlreadyLocked:\n...     print \'somefile\', \'is locked already.\'\n... except LockFailed:\n...     print \'somefile\', \'can\\\\\'t be locked.\'\n... else:\n...     print \'got lock\'\ngot lock\n>>> print lock.is_locked()\nTrue\n>>> lock.release()\n\n>>> lock = LockFile(\'somefile\')\n>>> print lock.is_locked()\nFalse\n>>> with lock:\n...    print lock.is_locked()\nTrue\n>>> print lock.is_locked()\nFalse\n\n>>> lock = LockFile(\'somefile\')\n>>> # It is okay to lock twice from the same thread...\n>>> with lock:\n...     lock.acquire()\n...\n>>> # Though no counter is kept, so you can\'t unlock multiple times...\n>>> print lock.is_locked()\nFalse\n\nExceptions:\n\n    Error - base class for other exceptions\n        LockError - base class for all locking exceptions\n            AlreadyLocked - Another thread or process already holds the lock\n            LockFailed - Lock failed for some other reason\n        UnlockError - base class for all unlocking exceptions\n            AlreadyUnlocked - File was not locked.\n            NotMyLock - File was locked but not by the current thread/process\n""""""\n\nfrom __future__ import absolute_import\n\nimport sys\nimport socket\nimport os\nimport threading\nimport time\nimport urllib\nimport warnings\nimport functools\n\n# Work with PEP8 and non-PEP8 versions of threading module.\nif not hasattr(threading, ""current_thread""):\n    threading.current_thread = threading.currentThread\nif not hasattr(threading.Thread, ""get_name""):\n    threading.Thread.get_name = threading.Thread.getName\n\n__all__ = [\'Error\', \'LockError\', \'LockTimeout\', \'AlreadyLocked\',\n           \'LockFailed\', \'UnlockError\', \'NotLocked\', \'NotMyLock\',\n           \'LinkLockFile\', \'MkdirLockFile\', \'SQLiteLockFile\',\n           \'LockBase\', \'locked\']\n\nclass Error(Exception):\n    """"""\n    Base class for other exceptions.\n\n    >>> try:\n    ...   raise Error\n    ... except Exception:\n    ...   pass\n    """"""\n    pass\n\nclass LockError(Error):\n    """"""\n    Base class for error arising from attempts to acquire the lock.\n\n    >>> try:\n    ...   raise LockError\n    ... except Error:\n    ...   pass\n    """"""\n    pass\n\nclass LockTimeout(LockError):\n    """"""Raised when lock creation fails within a user-defined period of time.\n\n    >>> try:\n    ...   raise LockTimeout\n    ... except LockError:\n    ...   pass\n    """"""\n    pass\n\nclass AlreadyLocked(LockError):\n    """"""Some other thread/process is locking the file.\n\n    >>> try:\n    ...   raise AlreadyLocked\n    ... except LockError:\n    ...   pass\n    """"""\n    pass\n\nclass LockFailed(LockError):\n    """"""Lock file creation failed for some other reason.\n\n    >>> try:\n    ...   raise LockFailed\n    ... except LockError:\n    ...   pass\n    """"""\n    pass\n\nclass UnlockError(Error):\n    """"""\n    Base class for errors arising from attempts to release the lock.\n\n    >>> try:\n    ...   raise UnlockError\n    ... except Error:\n    ...   pass\n    """"""\n    pass\n\nclass NotLocked(UnlockError):\n    """"""Raised when an attempt is made to unlock an unlocked file.\n\n    >>> try:\n    ...   raise NotLocked\n    ... except UnlockError:\n    ...   pass\n    """"""\n    pass\n\nclass NotMyLock(UnlockError):\n    """"""Raised when an attempt is made to unlock a file someone else locked.\n\n    >>> try:\n    ...   raise NotMyLock\n    ... except UnlockError:\n    ...   pass\n    """"""\n    pass\n\nclass LockBase:\n    """"""Base class for platform-specific lock classes.""""""\n    def __init__(self, path, threaded=True, timeout=None):\n        """"""\n        >>> lock = LockBase(\'somefile\')\n        >>> lock = LockBase(\'somefile\', threaded=False)\n        """"""\n        self.path = path\n        self.lock_file = os.path.abspath(path) + "".lock""\n        self.hostname = socket.gethostname()\n        self.pid = os.getpid()\n        if threaded:\n            t = threading.current_thread()\n            # Thread objects in Python 2.4 and earlier do not have ident\n            # attrs.  Worm around that.\n            ident = getattr(t, ""ident"", hash(t))\n            self.tname = ""-%x"" % (ident & 0xffffffff)\n        else:\n            self.tname = """"\n        dirname = os.path.dirname(self.lock_file)\n\n        # unique name is mostly about the current process, but must\n        # also contain the path -- otherwise, two adjacent locked\n        # files conflict (one file gets locked, creating lock-file and\n        # unique file, the other one gets locked, creating lock-file\n        # and overwriting the already existing lock-file, then one\n        # gets unlocked, deleting both lock-file and unique file,\n        # finally the last lock errors out upon releasing.\n        self.unique_name = os.path.join(dirname,\n                                        ""%s%s.%s%s"" % (self.hostname,\n                                                       self.tname,\n                                                       self.pid,\n                                                       hash(self.path)))\n        self.timeout = timeout\n\n    def acquire(self, timeout=None):\n        """"""\n        Acquire the lock.\n\n        * If timeout is omitted (or None), wait forever trying to lock the\n          file.\n\n        * If timeout > 0, try to acquire the lock for that many seconds.  If\n          the lock period expires and the file is still locked, raise\n          LockTimeout.\n\n        * If timeout <= 0, raise AlreadyLocked immediately if the file is\n          already locked.\n        """"""\n        raise NotImplemented(""implement in subclass"")\n\n    def release(self):\n        """"""\n        Release the lock.\n\n        If the file is not locked, raise NotLocked.\n        """"""\n        raise NotImplemented(""implement in subclass"")\n\n    def is_locked(self):\n        """"""\n        Tell whether or not the file is locked.\n        """"""\n        raise NotImplemented(""implement in subclass"")\n\n    def i_am_locking(self):\n        """"""\n        Return True if this object is locking the file.\n        """"""\n        raise NotImplemented(""implement in subclass"")\n\n    def break_lock(self):\n        """"""\n        Remove a lock.  Useful if a locking thread failed to unlock.\n        """"""\n        raise NotImplemented(""implement in subclass"")\n\n    def __enter__(self):\n        """"""\n        Context manager support.\n        """"""\n        self.acquire()\n        return self\n\n    def __exit__(self, *_exc):\n        """"""\n        Context manager support.\n        """"""\n        self.release()\n\n    def __repr__(self):\n        return ""<%s: %r -- %r>"" % (self.__class__.__name__, self.unique_name,\n                                   self.path)\n\ndef _fl_helper(cls, mod, *args, **kwds):\n    warnings.warn(""Import from %s module instead of lockfile package"" % mod,\n                  DeprecationWarning, stacklevel=2)\n    # This is a bit funky, but it\'s only for awhile.  The way the unit tests\n    # are constructed this function winds up as an unbound method, so it\n    # actually takes three args, not two.  We want to toss out self.\n    if not isinstance(args[0], str):\n        # We are testing, avoid the first arg\n        args = args[1:]\n    if len(args) == 1 and not kwds:\n        kwds[""threaded""] = True\n    return cls(*args, **kwds)\n\ndef LinkFileLock(*args, **kwds):\n    """"""Factory function provided for backwards compatibility.\n\n    Do not use in new code.  Instead, import LinkLockFile from the\n    lockfile.linklockfile module.\n    """"""\n    from . import linklockfile\n    return _fl_helper(linklockfile.LinkLockFile, ""lockfile.linklockfile"",\n                      *args, **kwds)\n\ndef MkdirFileLock(*args, **kwds):\n    """"""Factory function provided for backwards compatibility.\n\n    Do not use in new code.  Instead, import MkdirLockFile from the\n    lockfile.mkdirlockfile module.\n    """"""\n    from . import mkdirlockfile\n    return _fl_helper(mkdirlockfile.MkdirLockFile, ""lockfile.mkdirlockfile"",\n                      *args, **kwds)\n\ndef SQLiteFileLock(*args, **kwds):\n    """"""Factory function provided for backwards compatibility.\n\n    Do not use in new code.  Instead, import SQLiteLockFile from the\n    lockfile.mkdirlockfile module.\n    """"""\n    from . import sqlitelockfile\n    return _fl_helper(sqlitelockfile.SQLiteLockFile, ""lockfile.sqlitelockfile"",\n                      *args, **kwds)\n\ndef locked(path, timeout=None):\n    """"""Decorator which enables locks for decorated function.\n\n    Arguments:\n     - path: path for lockfile.\n     - timeout (optional): Timeout for acquiring lock.\n\n     Usage:\n         @locked(\'/var/run/myname\', timeout=0)\n         def myname(...):\n             ...\n    """"""\n    def decor(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            lock = FileLock(path, timeout=timeout)\n            lock.acquire()\n            try:\n                return func(*args, **kwargs)\n            finally:\n                lock.release()\n        return wrapper\n    return decor\n\nif hasattr(os, ""link""):\n    from . import linklockfile as _llf\n    LockFile = _llf.LinkLockFile\nelse:\n    from . import mkdirlockfile as _mlf\n    LockFile = _mlf.MkdirLockFile\n\nFileLock = LockFile\n\n'"
rootpy/extern/lockfile/linklockfile.py,0,"b'from __future__ import absolute_import\n\nimport time\nimport os\n\nfrom . import (LockBase, LockFailed, NotLocked, NotMyLock, LockTimeout,\n               AlreadyLocked)\n\nclass LinkLockFile(LockBase):\n    """"""Lock access to a file using atomic property of link(2).\n\n    >>> lock = LinkLockFile(\'somefile\')\n    >>> lock = LinkLockFile(\'somefile\', threaded=False)\n    """"""\n\n    def acquire(self, timeout=None):\n        try:\n            open(self.unique_name, ""wb"").close()\n        except IOError:\n            raise LockFailed(""failed to create %s"" % self.unique_name)\n\n        timeout = timeout is not None and timeout or self.timeout\n        end_time = time.time()\n        if timeout is not None and timeout > 0:\n            end_time += timeout\n\n        while True:\n            # Try and create a hard link to it.\n            try:\n                os.link(self.unique_name, self.lock_file)\n            except OSError:\n                # Link creation failed.  Maybe we\'ve double-locked?\n                nlinks = os.stat(self.unique_name).st_nlink\n                if nlinks == 2:\n                    # The original link plus the one I created == 2.  We\'re\n                    # good to go.\n                    return\n                else:\n                    # Otherwise the lock creation failed.\n                    if timeout is not None and time.time() > end_time:\n                        os.unlink(self.unique_name)\n                        if timeout > 0:\n                            raise LockTimeout(""Timeout waiting to acquire""\n                                              "" lock for %s"" %\n                                              self.path)\n                        else:\n                            raise AlreadyLocked(""%s is already locked"" %\n                                                self.path)\n                    time.sleep(timeout is not None and timeout/10 or 0.1)\n            else:\n                # Link creation succeeded.  We\'re good to go.\n                return\n\n    def release(self):\n        if not self.is_locked():\n            raise NotLocked(""%s is not locked"" % self.path)\n        elif not os.path.exists(self.unique_name):\n            raise NotMyLock(""%s is locked, but not by me"" % self.path)\n        os.unlink(self.unique_name)\n        os.unlink(self.lock_file)\n\n    def is_locked(self):\n        return os.path.exists(self.lock_file)\n\n    def i_am_locking(self):\n        return (self.is_locked() and\n                os.path.exists(self.unique_name) and\n                os.stat(self.unique_name).st_nlink == 2)\n\n    def break_lock(self):\n        if os.path.exists(self.lock_file):\n            os.unlink(self.lock_file)\n\n'"
rootpy/extern/lockfile/mkdirlockfile.py,0,"b'from __future__ import absolute_import, division\n\nimport time\nimport os\nimport sys\nimport errno\n\nfrom . import (LockBase, LockFailed, NotLocked, NotMyLock, LockTimeout,\n               AlreadyLocked)\n\nclass MkdirLockFile(LockBase):\n    """"""Lock file by creating a directory.""""""\n    def __init__(self, path, threaded=True, timeout=None):\n        """"""\n        >>> lock = MkdirLockFile(\'somefile\')\n        >>> lock = MkdirLockFile(\'somefile\', threaded=False)\n        """"""\n        LockBase.__init__(self, path, threaded, timeout)\n        # Lock file itself is a directory.  Place the unique file name into\n        # it.\n        self.unique_name  = os.path.join(self.lock_file,\n                                         ""%s.%s%s"" % (self.hostname,\n                                                      self.tname,\n                                                      self.pid))\n\n    def acquire(self, timeout=None):\n        timeout = timeout is not None and timeout or self.timeout\n        end_time = time.time()\n        if timeout is not None and timeout > 0:\n            end_time += timeout\n\n        if timeout is None:\n            wait = 0.1\n        else:\n            wait = max(0, timeout / 10)\n\n        while True:\n            try:\n                os.mkdir(self.lock_file)\n            except OSError:\n                err = sys.exc_info()[1]\n                if err.errno == errno.EEXIST:\n                    # Already locked.\n                    if os.path.exists(self.unique_name):\n                        # Already locked by me.\n                        return\n                    if timeout is not None and time.time() > end_time:\n                        if timeout > 0:\n                            raise LockTimeout(""Timeout waiting to acquire""\n                                              "" lock for %s"" %\n                                              self.path)\n                        else:\n                            # Someone else has the lock.\n                            raise AlreadyLocked(""%s is already locked"" %\n                                                self.path)\n                    time.sleep(wait)\n                else:\n                    # Couldn\'t create the lock for some other reason\n                    raise LockFailed(""failed to create %s"" % self.lock_file)\n            else:\n                open(self.unique_name, ""wb"").close()\n                return\n\n    def release(self):\n        if not self.is_locked():\n            raise NotLocked(""%s is not locked"" % self.path)\n        elif not os.path.exists(self.unique_name):\n            raise NotMyLock(""%s is locked, but not by me"" % self.path)\n        os.unlink(self.unique_name)\n        os.rmdir(self.lock_file)\n\n    def is_locked(self):\n        return os.path.exists(self.lock_file)\n\n    def i_am_locking(self):\n        return (self.is_locked() and\n                os.path.exists(self.unique_name))\n\n    def break_lock(self):\n        if os.path.exists(self.lock_file):\n            for name in os.listdir(self.lock_file):\n                os.unlink(os.path.join(self.lock_file, name))\n            os.rmdir(self.lock_file)\n'"
rootpy/extern/lockfile/pidlockfile.py,0,"b'# -*- coding: utf-8 -*-\n\n# pidlockfile.py\n#\n# Copyright \xc2\xa9 2008\xe2\x80\x932009 Ben Finney <ben+python@benfinney.id.au>\n#\n# This is free software: you may copy, modify, and/or distribute this work\n# under the terms of the Python Software Foundation License, version 2 or\n# later as published by the Python Software Foundation.\n# No warranty expressed or implied. See the file LICENSE.PSF-2 for details.\n\n"""""" Lockfile behaviour implemented via Unix PID files.\n    """"""\n\nfrom __future__ import absolute_import\n\nimport os\nimport sys\nimport errno\nimport time\n\nfrom . import (LockBase, AlreadyLocked, LockFailed, NotLocked, NotMyLock,\n               LockTimeout)\n\n\x0c\nclass PIDLockFile(LockBase):\n    """""" Lockfile implemented as a Unix PID file.\n\n    The lock file is a normal file named by the attribute `path`.\n    A lock\'s PID file contains a single line of text, containing\n    the process ID (PID) of the process that acquired the lock.\n\n    >>> lock = PIDLockFile(\'somefile\')\n    >>> lock = PIDLockFile(\'somefile\')\n    """"""\n\n    def __init__(self, path, threaded=False, timeout=None):\n        # pid lockfiles don\'t support threaded operation, so always force\n        # False as the threaded arg.\n        LockBase.__init__(self, path, False, timeout)\n        dirname = os.path.dirname(self.lock_file)\n        basename = os.path.split(self.path)[-1]\n        self.unique_name = self.path\n\n    def read_pid(self):\n        """""" Get the PID from the lock file.\n            """"""\n        return read_pid_from_pidfile(self.path)\n\n    def is_locked(self):\n        """""" Test if the lock is currently held.\n\n            The lock is held if the PID file for this lock exists.\n\n            """"""\n        return os.path.exists(self.path)\n\n    def i_am_locking(self):\n        """""" Test if the lock is held by the current process.\n\n        Returns ``True`` if the current process ID matches the\n        number stored in the PID file.\n        """"""\n        return self.is_locked() and os.getpid() == self.read_pid()\n\n    def acquire(self, timeout=None):\n        """""" Acquire the lock.\n\n        Creates the PID file for this lock, or raises an error if\n        the lock could not be acquired.\n        """"""\n\n        timeout = timeout is not None and timeout or self.timeout\n        end_time = time.time()\n        if timeout is not None and timeout > 0:\n            end_time += timeout\n\n        while True:\n            try:\n                write_pid_to_pidfile(self.path)\n            except OSError as exc:\n                if exc.errno == errno.EEXIST:\n                    # The lock creation failed.  Maybe sleep a bit.\n                    if timeout is not None and time.time() > end_time:\n                        if timeout > 0:\n                            raise LockTimeout(""Timeout waiting to acquire""\n                                              "" lock for %s"" %\n                                              self.path)\n                        else:\n                            raise AlreadyLocked(""%s is already locked"" %\n                                                self.path)\n                    time.sleep(timeout is not None and timeout/10 or 0.1)\n                else:\n                    raise LockFailed(""failed to create %s"" % self.path)\n            else:\n                return\n\n    def release(self):\n        """""" Release the lock.\n\n            Removes the PID file to release the lock, or raises an\n            error if the current process does not hold the lock.\n\n            """"""\n        if not self.is_locked():\n            raise NotLocked(""%s is not locked"" % self.path)\n        if not self.i_am_locking():\n            raise NotMyLock(""%s is locked, but not by me"" % self.path)\n        remove_existing_pidfile(self.path)\n\n    def break_lock(self):\n        """""" Break an existing lock.\n\n            Removes the PID file if it already exists, otherwise does\n            nothing.\n\n            """"""\n        remove_existing_pidfile(self.path)\n\ndef read_pid_from_pidfile(pidfile_path):\n    """""" Read the PID recorded in the named PID file.\n\n        Read and return the numeric PID recorded as text in the named\n        PID file. If the PID file cannot be read, or if the content is\n        not a valid PID, return ``None``.\n\n        """"""\n    pid = None\n    try:\n        pidfile = open(pidfile_path, \'r\')\n    except IOError:\n        pass\n    else:\n        # According to the FHS 2.3 section on PID files in /var/run:\n        # \n        #   The file must consist of the process identifier in\n        #   ASCII-encoded decimal, followed by a newline character.\n        # \n        #   Programs that read PID files should be somewhat flexible\n        #   in what they accept; i.e., they should ignore extra\n        #   whitespace, leading zeroes, absence of the trailing\n        #   newline, or additional lines in the PID file.\n\n        line = pidfile.readline().strip()\n        try:\n            pid = int(line)\n        except ValueError:\n            pass\n        pidfile.close()\n\n    return pid\n\n\ndef write_pid_to_pidfile(pidfile_path):\n    """""" Write the PID in the named PID file.\n\n        Get the numeric process ID (\xe2\x80\x9cPID\xe2\x80\x9d) of the current process\n        and write it to the named file as a line of text.\n\n        """"""\n    open_flags = (os.O_CREAT | os.O_EXCL | os.O_WRONLY)\n    open_mode = 0o644\n    pidfile_fd = os.open(pidfile_path, open_flags, open_mode)\n    pidfile = os.fdopen(pidfile_fd, \'w\')\n\n    # According to the FHS 2.3 section on PID files in /var/run:\n    #\n    #   The file must consist of the process identifier in\n    #   ASCII-encoded decimal, followed by a newline character. For\n    #   example, if crond was process number 25, /var/run/crond.pid\n    #   would contain three characters: two, five, and newline.\n\n    pid = os.getpid()\n    line = ""%(pid)d\\n"" % vars()\n    pidfile.write(line)\n    pidfile.close()\n\n\ndef remove_existing_pidfile(pidfile_path):\n    """""" Remove the named PID file if it exists.\n\n        Removing a PID file that doesn\'t already exist puts us in the\n        desired state, so we ignore the condition if the file does not\n        exist.\n\n        """"""\n    try:\n        os.remove(pidfile_path)\n    except OSError as exc:\n        if exc.errno == errno.ENOENT:\n            pass\n        else:\n            raise\n'"
rootpy/extern/lockfile/sqlitelockfile.py,0,"b'from __future__ import absolute_import, division\n\nimport time\nimport os\n\ntry:\n    unicode\nexcept NameError:\n    unicode = str\n\nfrom . import LockBase, NotLocked, NotMyLock, LockTimeout, AlreadyLocked\n\nclass SQLiteLockFile(LockBase):\n    ""Demonstrate SQL-based locking.""\n\n    testdb = None\n\n    def __init__(self, path, threaded=True, timeout=None):\n        """"""\n        >>> lock = SQLiteLockFile(\'somefile\')\n        >>> lock = SQLiteLockFile(\'somefile\', threaded=False)\n        """"""\n        LockBase.__init__(self, path, threaded, timeout)\n        self.lock_file = unicode(self.lock_file)\n        self.unique_name = unicode(self.unique_name)\n\n        if SQLiteLockFile.testdb is None:\n            import tempfile\n            _fd, testdb = tempfile.mkstemp()\n            os.close(_fd)\n            os.unlink(testdb)\n            del _fd, tempfile\n            SQLiteLockFile.testdb = testdb\n\n        import sqlite3\n        self.connection = sqlite3.connect(SQLiteLockFile.testdb)\n        \n        c = self.connection.cursor()\n        try:\n            c.execute(""create table locks""\n                      ""(""\n                      ""   lock_file varchar(32),""\n                      ""   unique_name varchar(32)""\n                      "")"")\n        except sqlite3.OperationalError:\n            pass\n        else:\n            self.connection.commit()\n            import atexit\n            atexit.register(os.unlink, SQLiteLockFile.testdb)\n\n    def acquire(self, timeout=None):\n        timeout = timeout is not None and timeout or self.timeout\n        end_time = time.time()\n        if timeout is not None and timeout > 0:\n            end_time += timeout\n\n        if timeout is None:\n            wait = 0.1\n        elif timeout <= 0:\n            wait = 0\n        else:\n            wait = timeout / 10\n\n        cursor = self.connection.cursor()\n\n        while True:\n            if not self.is_locked():\n                # Not locked.  Try to lock it.\n                cursor.execute(""insert into locks""\n                               ""  (lock_file, unique_name)""\n                               ""  values""\n                               ""  (?, ?)"",\n                               (self.lock_file, self.unique_name))\n                self.connection.commit()\n\n                # Check to see if we are the only lock holder.\n                cursor.execute(""select * from locks""\n                               ""  where unique_name = ?"",\n                               (self.unique_name,))\n                rows = cursor.fetchall()\n                if len(rows) > 1:\n                    # Nope.  Someone else got there.  Remove our lock.\n                    cursor.execute(""delete from locks""\n                                   ""  where unique_name = ?"",\n                                   (self.unique_name,))\n                    self.connection.commit()\n                else:\n                    # Yup.  We\'re done, so go home.\n                    return\n            else:\n                # Check to see if we are the only lock holder.\n                cursor.execute(""select * from locks""\n                               ""  where unique_name = ?"",\n                               (self.unique_name,))\n                rows = cursor.fetchall()\n                if len(rows) == 1:\n                    # We\'re the locker, so go home.\n                    return\n                    \n            # Maybe we should wait a bit longer.\n            if timeout is not None and time.time() > end_time:\n                if timeout > 0:\n                    # No more waiting.\n                    raise LockTimeout(""Timeout waiting to acquire""\n                                      "" lock for %s"" %\n                                      self.path)\n                else:\n                    # Someone else has the lock and we are impatient..\n                    raise AlreadyLocked(""%s is already locked"" % self.path)\n\n            # Well, okay.  We\'ll give it a bit longer.\n            time.sleep(wait)\n\n    def release(self):\n        if not self.is_locked():\n            raise NotLocked(""%s is not locked"" % self.path)\n        if not self.i_am_locking():\n            raise NotMyLock(""%s is locked, but not by me (by %s)"" %\n                            (self.unique_name, self._who_is_locking()))\n        cursor = self.connection.cursor()\n        cursor.execute(""delete from locks""\n                       ""  where unique_name = ?"",\n                       (self.unique_name,))\n        self.connection.commit()\n\n    def _who_is_locking(self):\n        cursor = self.connection.cursor()\n        cursor.execute(""select unique_name from locks""\n                       ""  where lock_file = ?"",\n                       (self.lock_file,))\n        return cursor.fetchone()[0]\n        \n    def is_locked(self):\n        cursor = self.connection.cursor()\n        cursor.execute(""select * from locks""\n                       ""  where lock_file = ?"",\n                       (self.lock_file,))\n        rows = cursor.fetchall()\n        return not not rows\n\n    def i_am_locking(self):\n        cursor = self.connection.cursor()\n        cursor.execute(""select * from locks""\n                       ""  where lock_file = ?""\n                       ""    and unique_name = ?"",\n                       (self.lock_file, self.unique_name))\n        return not not cursor.fetchall()\n\n    def break_lock(self):\n        cursor = self.connection.cursor()\n        cursor.execute(""delete from locks""\n                       ""  where lock_file = ?"",\n                       (self.lock_file,))\n        self.connection.commit()\n'"
rootpy/extern/lockfile/symlinklockfile.py,0,"b'from __future__ import absolute_import\n\nimport time\nimport os\n\nfrom . import (LockBase, LockFailed, NotLocked, NotMyLock, LockTimeout,\n               AlreadyLocked)\n\nclass SymlinkLockFile(LockBase):\n    """"""Lock access to a file using symlink(2).""""""\n\n    def __init__(self, path, threaded=True, timeout=None):\n        # super(SymlinkLockFile).__init(...)\n        LockBase.__init__(self, path, threaded, timeout)\n        # split it back!\n        self.unique_name = os.path.split(self.unique_name)[1]\n\n    def acquire(self, timeout=None):\n        # Hopefully unnecessary for symlink.\n        #try:\n        #    open(self.unique_name, ""wb"").close()\n        #except IOError:\n        #    raise LockFailed(""failed to create %s"" % self.unique_name)\n        timeout = timeout is not None and timeout or self.timeout\n        end_time = time.time()\n        if timeout is not None and timeout > 0:\n            end_time += timeout\n\n        while True:\n            # Try and create a symbolic link to it.\n            try:\n                os.symlink(self.unique_name, self.lock_file)\n            except OSError:\n                # Link creation failed.  Maybe we\'ve double-locked?\n                if self.i_am_locking():\n                    # Linked to out unique name. Proceed.\n                    return\n                else:\n                    # Otherwise the lock creation failed.\n                    if timeout is not None and time.time() > end_time:\n                        if timeout > 0:\n                            raise LockTimeout(""Timeout waiting to acquire""\n                                              "" lock for %s"" %\n                                              self.path)\n                        else:\n                            raise AlreadyLocked(""%s is already locked"" %\n                                                self.path)\n                    time.sleep(timeout/10 if timeout is not None else 0.1)\n            else:\n                # Link creation succeeded.  We\'re good to go.\n                return\n\n    def release(self):\n        if not self.is_locked():\n            raise NotLocked(""%s is not locked"" % self.path)\n        elif not self.i_am_locking():\n            raise NotMyLock(""%s is locked, but not by me"" % self.path)\n        os.unlink(self.lock_file)\n\n    def is_locked(self):\n        return os.path.islink(self.lock_file)\n\n    def i_am_locking(self):\n        return os.path.islink(self.lock_file) and \\\n         os.readlink(self.lock_file) == self.unique_name\n\n    def break_lock(self):\n        if os.path.islink(self.lock_file):  # exists && link\n            os.unlink(self.lock_file)\n'"
rootpy/extern/progressbar/__init__.py,0,"b""#!/usr/bin/python\n# -*- coding: utf-8 -*-\n#\n# progressbar  - Text progress bar library for Python.\n# Copyright (c) 2005 Nilton Volpato\n# Copyright (c) 2012 Rick van Hattem\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n#\n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n\n\n'''Text progress bar library for Python.\n\nA text progress bar is typically used to display the progress of a long\nrunning operation, providing a visual cue that processing is underway.\n\nThe ProgressBar class manages the current progress, and the format of the line\nis given by a number of widgets. A widget is an object that may display\ndifferently depending on the state of the progress bar. There are three types\nof widgets:\n\n - a string, which always shows itself\n\n - a ProgressBarWidget, which may return a different value every time its\n   update method is called\n\n - a ProgressBarWidgetHFill, which is like ProgressBarWidget, except it\n   expands to fill the remaining width of the line.\n\nThe progressbar module is very easy to use, yet very powerful. It will also\nautomatically enable features like auto-resizing when the system supports it.\n'''\n\nfrom __future__ import division, absolute_import, with_statement\n\nimport math\nimport os\nimport signal\nimport sys\nimport time\nfrom datetime import date\n\ntry:\n    from fcntl import ioctl\n    from array import array\n    import termios\nexcept ImportError:  # pragma: no cover\n    pass\n\ntry:\n    from cStringIO import StringIO\nexcept ImportError:  # pragma: no cover\n    try:\n        from StringIO import StringIO\n    except ImportError:\n        from io import StringIO\n\nfrom .widgets import *\n\n__author__ = 'Rick van Hattem'\n__author_email__ = 'Rick.van.Hattem@Fawo.nl'\n__date__ = str(date.today())\n__version__ = '2.7.3'\n\n\nclass UnknownLength:\n    pass\n\n\nclass ProgressBar(object):\n\n    '''The ProgressBar class which updates and prints the bar.\n\n    A common way of using it is like:\n\n    >>> pbar = ProgressBar().start()\n    >>> for i in range(100):\n    ...     pbar.update(i+1)\n    ...     # do something\n    ...\n    >>> pbar.finish()\n\n    You can also use a ProgressBar as an iterator:\n\n    >>> progress = ProgressBar()\n    >>> some_iterable = range(100)\n    >>> for i in progress(some_iterable):\n    ...     # do something\n    ...     pass\n    ...\n\n    Since the progress bar is incredibly customizable you can specify\n    different widgets of any type in any order. You can even write your own\n    widgets! However, since there are already a good number of widgets you\n    should probably play around with them before moving on to create your own\n    widgets.\n\n    The term_width parameter represents the current terminal width. If the\n    parameter is set to an integer then the progress bar will use that,\n    otherwise it will attempt to determine the terminal width falling back to\n    80 columns if the width cannot be determined.\n\n    When implementing a widget's update method you are passed a reference to\n    the current progress bar. As a result, you have access to the\n    ProgressBar's methods and attributes. Although there is nothing preventing\n    you from changing the ProgressBar you should treat it as read only.\n\n    Useful methods and attributes include (Public API):\n     - currval: current progress (0 <= currval <= maxval)\n     - maxval: maximum (and final) value\n     - finished: True if the bar has finished (reached 100%)\n     - start_time: the time when start() method of ProgressBar was called\n     - seconds_elapsed: seconds elapsed since start_time and last call to\n                        update\n     - percentage(): progress in percent [0..100]\n    '''\n\n    _DEFAULT_MAXVAL = 100\n    _DEFAULT_TERMSIZE = 80\n\n    def __init__(self, maxval=None, widgets=None, term_width=None, poll=0.1,\n                 left_justify=True, fd=sys.stderr, redirect_stderr=False,\n                 redirect_stdout=False):\n        '''Initializes a progress bar with sane defaults'''\n\n        if widgets is None:\n            # Don't share widgets with any other progress bars\n            widgets = self.default_widgets()\n\n        self.maxval = maxval\n        self.widgets = widgets\n        self.fd = fd\n        self.left_justify = left_justify\n        self.redirect_stderr = redirect_stderr\n        self.redirect_stdout = redirect_stdout\n\n        self.signal_set = False\n        if term_width is not None:\n            self.term_width = term_width\n        else:\n            try:\n                self._handle_resize()\n                signal.signal(signal.SIGWINCH, self._handle_resize)\n                self.signal_set = True\n            except (SystemExit, KeyboardInterrupt):  # pragma: no cover\n                raise\n            except:  # pragma: no cover\n                self.term_width = self._env_size()\n\n        self.__iterable = None\n        self._update_widgets()\n        self.currval = 0\n        self.finished = False\n        self.last_update_time = None\n        self.poll = poll\n        self.seconds_elapsed = 0\n        self.start_time = None\n        self.update_interval = 1\n\n    def default_widgets(self):\n        return [\n            Percentage(), ' (', SimpleProgress(), ')', ' ', Bar(), ' ',\n            Timer(), ' ', AdaptiveETA(),\n        ]\n\n    def __call__(self, iterable, maxval=None):\n        'Use a ProgressBar to iterate through an iterable'\n        if maxval is None:\n            try:\n                self.maxval = len(iterable)\n            except:\n                if self.maxval is None:\n                    self.maxval = UnknownLength\n        else:\n            self.maxval = maxval\n\n        self.__iterable = iter(iterable)\n        return self\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        try:\n            value = next(self.__iterable)\n            if self.start_time is None:\n                self.start()\n            else:\n                self.update(self.currval + 1)\n            return value\n        except StopIteration:\n            self.finish()\n            raise\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.finish()\n\n    def __enter__(self):\n        return self.start()\n\n    # Create an alias so that Python 2.x won't complain about not being\n    # an iterator.\n    next = __next__\n\n    def __iadd__(self, value):\n        'Updates the ProgressBar by adding a new value.'\n        self.update(self.currval + value)\n        return self\n\n    def _env_size(self):\n        'Tries to find the term_width from the environment.'\n\n        return int(os.environ.get('COLUMNS', self._DEFAULT_TERMSIZE)) - 1\n\n    def _handle_resize(self, signum=None, frame=None):\n        'Tries to catch resize signals sent from the terminal.'\n\n        h, w = array('h', ioctl(self.fd, termios.TIOCGWINSZ, '\\0' * 8))[:2]\n        self.term_width = w\n\n    def percentage(self):\n        'Returns the progress as a percentage.'\n        return self.currval * 100.0 / (self.maxval or 1)\n\n    percent = property(percentage)\n\n    def _format_widgets(self):\n        result = []\n        expanding = []\n        width = self.term_width\n\n        for index, widget in enumerate(self.widgets):\n            if isinstance(widget, WidgetHFill):\n                result.append(widget)\n                expanding.insert(0, index)\n            else:\n                widget = format_updatable(widget, self)\n                result.append(widget)\n                width -= len(widget)\n\n        count = len(expanding)\n        while count:\n            portion = max(int(math.ceil(width * 1. / count)), 0)\n            index = expanding.pop()\n            count -= 1\n\n            widget = result[index].update(self, portion)\n            width -= len(widget)\n            result[index] = widget\n\n        return result\n\n    def _format_line(self):\n        'Joins the widgets and justifies the line'\n\n        widgets = ''.join(self._format_widgets())\n\n        if self.left_justify:\n            return widgets.ljust(self.term_width)\n        else:\n            return widgets.rjust(self.term_width)\n\n    def _need_update(self):\n        'Returns whether the ProgressBar should redraw the line.'\n        if self.currval >= self.next_update or self.finished:\n            return True\n\n        delta = time.time() - self.last_update_time\n        return self._time_sensitive and delta > self.poll\n\n    def _update_widgets(self):\n        'Checks all widgets for the time sensitive bit'\n\n        self._time_sensitive = any(getattr(w, 'TIME_SENSITIVE', False)\n                                   for w in self.widgets)\n\n    def update(self, value=None):\n        'Updates the ProgressBar to a new value.'\n\n        if value is not None and value is not UnknownLength:\n            if (self.maxval is not UnknownLength\n                    and not 0 <= value <= self.maxval\n                    and not value < self.currval):\n\n                raise ValueError('Value out of range')\n\n            self.currval = value\n\n        if self.start_time is None:\n            self.start()\n            self.update(value)\n        if not self._need_update():\n            return\n\n        if self.redirect_stderr and sys.stderr.tell():\n            self.fd.write('\\r' + ' ' * self.term_width + '\\r')\n            self._stderr.write(sys.stderr.getvalue())\n            self._stderr.flush()\n            sys.stderr = StringIO()\n\n        if self.redirect_stdout and sys.stdout.tell():\n            self.fd.write('\\r' + ' ' * self.term_width + '\\r')\n            self._stdout.write(sys.stdout.getvalue())\n            self._stdout.flush()\n            sys.stdout = StringIO()\n\n        now = time.time()\n        self.seconds_elapsed = now - self.start_time\n        self.next_update = self.currval + self.update_interval\n        self.fd.write('\\r' + self._format_line())\n        self.last_update_time = now\n\n    def start(self):\n        '''Starts measuring time, and prints the bar at 0%.\n\n        It returns self so you can use it like this:\n\n        >>> pbar = ProgressBar().start()\n        >>> for i in range(100):\n        ...    # do something\n        ...    pbar.update(i+1)\n        ...\n        >>> pbar.finish()\n        '''\n\n        if self.redirect_stderr:\n            self._stderr = sys.stderr\n            sys.stderr = StringIO()\n\n        if self.redirect_stdout:\n            self._stdout = sys.stdout\n            sys.stdout = StringIO()\n\n        if self.maxval is None:\n            self.maxval = self._DEFAULT_MAXVAL\n\n        self.num_intervals = max(100, self.term_width)\n        self.next_update = 0\n\n        if self.maxval is not UnknownLength:\n            if self.maxval < 0:\n                raise ValueError('Value out of range')\n            self.update_interval = self.maxval / self.num_intervals\n\n        self.start_time = self.last_update_time = time.time()\n        self.update(0)\n\n        return self\n\n    def finish(self):\n        'Puts the ProgressBar bar in the finished state.'\n\n        self.finished = True\n        self.update(self.maxval)\n        self.fd.write('\\n')\n        if self.signal_set:\n            signal.signal(signal.SIGWINCH, signal.SIG_DFL)\n\n        if self.redirect_stderr:\n            self._stderr.write(sys.stderr.getvalue())\n            sys.stderr = self._stderr\n\n        if self.redirect_stdout:\n            self._stdout.write(sys.stdout.getvalue())\n            sys.stdout = self._stdout\n"""
rootpy/extern/progressbar/widgets.py,0,"b'#!/usr/bin/python\n# -*- coding: utf-8 -*-\n#\n# progressbar  - Text progress bar library for Python.\n# Copyright (c) 2005 Nilton Volpato\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n#\n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA\n\n\'\'\'Default ProgressBar widgets\'\'\'\n\nfrom __future__ import division, absolute_import, with_statement\n\nimport datetime\nimport math\nimport abc\n\n\nclass AbstractWidget(object):\n    __metaclass__ = abc.ABCMeta\n\n\ndef format_updatable(updatable, pbar):\n    if hasattr(updatable, \'update\'):\n        return updatable.update(pbar)\n    else:\n        return updatable\n\n\nclass Widget(AbstractWidget):\n\n    \'\'\'The base class for all widgets\n\n    The ProgressBar will call the widget\'s update value when the widget should\n    be updated. The widget\'s size may change between calls, but the widget may\n    display incorrectly if the size changes drastically and repeatedly.\n\n    The boolean TIME_SENSITIVE informs the ProgressBar that it should be\n    updated more often because it is time sensitive.\n    \'\'\'\n\n    TIME_SENSITIVE = False\n\n    @abc.abstractmethod\n    def update(self, pbar):\n        \'\'\'Updates the widget.\n\n        pbar - a reference to the calling ProgressBar\n        \'\'\'\n\n\nclass WidgetHFill(Widget):\n\n    \'\'\'The base class for all variable width widgets.\n\n    This widget is much like the \\\\hfill command in TeX, it will expand to\n    fill the line. You can use more than one in the same line, and they will\n    all have the same width, and together will fill the line.\n    \'\'\'\n\n    @abc.abstractmethod\n    def update(self, pbar, width):\n        \'\'\'Updates the widget providing the total width the widget must fill.\n\n        pbar - a reference to the calling ProgressBar\n        width - The total width the widget must fill\n        \'\'\'\n\n\nclass Timer(Widget):\n\n    \'Widget which displays the elapsed seconds.\'\n\n    TIME_SENSITIVE = True\n\n    def __init__(self, format=\'Elapsed Time: %s\'):\n        self.format = format\n\n    @staticmethod\n    def format_time(seconds):\n        \'Formats time as the string ""HH:MM:SS"".\'\n\n        return str(datetime.timedelta(seconds=int(seconds)))\n\n    def update(self, pbar):\n        \'Updates the widget to show the elapsed time.\'\n\n        return self.format % self.format_time(pbar.seconds_elapsed)\n\n\nclass ETA(Timer):\n\n    \'Widget which attempts to estimate the time of arrival.\'\n\n    TIME_SENSITIVE = True\n\n    def _eta(self, pbar):\n        elapsed = pbar.seconds_elapsed\n        return elapsed * pbar.maxval / pbar.currval - elapsed\n\n    def update(self, pbar):\n        \'Updates the widget to show the ETA or total time when finished.\'\n\n        if pbar.currval == 0:\n            return \'ETA:  --:--:--\'\n        elif pbar.finished:\n            return \'Time: %s\' % self.format_time(pbar.seconds_elapsed)\n        else:\n            return \'ETA:  %s\' % self.format_time(self._eta(pbar))\n\n\nclass AdaptiveETA(ETA):\n    \'\'\'Widget which attempts to estimate the time of arrival.\n\n    Uses a sampled average of the speed based on the 10 last updates.\n    Very convenient for resuming the progress halfway.\n    \'\'\'\n\n    TIME_SENSITIVE = True\n\n    def __init__(self, num_samples=10, **kwargs):\n        ETA.__init__(self, **kwargs)\n        self.num_samples = num_samples\n        self.samples = []\n        self.sample_vals = []\n        self.last_sample_val = None\n\n    def _eta(self, pbar):\n        samples = self.samples\n        sample_vals = self.sample_vals\n        if pbar.currval != self.last_sample_val:\n            # Update the last sample counter, we only update if currval has\n            # changed\n            self.last_sample_val = pbar.currval\n\n            # Add a sample but limit the size to `num_samples`\n            samples.append(pbar.seconds_elapsed)\n            sample_vals.append(pbar.currval)\n            if len(samples) > self.num_samples:\n                samples.pop(0)\n                sample_vals.pop(0)\n\n        if len(samples) <= 1:\n            # No samples so just return the normal ETA calculation\n            return ETA._eta(self, pbar)\n\n        todo = pbar.maxval - pbar.currval\n        items = sample_vals[-1] - sample_vals[0]\n        duration = float(samples[-1] - samples[0])\n        per_item = duration / items\n        return todo * per_item\n\n\nclass FileTransferSpeed(Widget):\n\n    \'Widget for showing the transfer speed (useful for file transfers).\'\n\n    format = \'%6.2f %s%s/s\'\n    prefixes = \' kMGTPEZY\'\n\n    def __init__(self, unit=\'B\'):\n        self.unit = unit\n\n    def _speed(self, pbar):\n        speed = pbar.currval / pbar.seconds_elapsed\n        power = int(math.log(speed, 1000))\n        scaled = speed / 1000. ** power\n        return scaled, power\n\n    def update(self, pbar):\n        \'Updates the widget with the current SI prefixed speed.\'\n\n        if pbar.seconds_elapsed < 2e-6 or pbar.currval < 2e-6:  # =~ 0\n            scaled = power = 0\n        else:\n            scaled, power = self._speed(pbar)\n\n        return self.format % (scaled, self.prefixes[power], self.unit)\n\n\nclass AdaptiveTransferSpeed(FileTransferSpeed):\n\n    \'Widget for showing the transfer speed, based on the last X samples\'\n\n    def __init__(self, num_samples=10):\n        FileTransferSpeed.__init__(self)\n        self.num_samples = num_samples\n        self.samples = []\n        self.sample_vals = []\n        self.last_sample_val = None\n\n    def _speed(self, pbar):\n        samples = self.samples\n        sample_vals = self.sample_vals\n        if pbar.currval != self.last_sample_val:\n            # Update the last sample counter, we only update if currval has\n            # changed\n            self.last_sample_val = pbar.currval\n\n            # Add a sample but limit the size to `num_samples`\n            samples.append(pbar.seconds_elapsed)\n            sample_vals.append(pbar.currval)\n            if len(samples) > self.num_samples:\n                samples.pop(0)\n                sample_vals.pop(0)\n\n        if len(samples) <= 1:\n            # No samples so just return the parent\'s calculation\n            return FileTransferSpeed._speed(self, pbar)\n\n        items = sample_vals[-1] - sample_vals[0]\n        duration = float(samples[-1] - samples[0])\n        speed = items / duration\n        power = int(math.log(speed, 1000))\n        scaled = speed / 1000. ** power\n        return scaled, power\n\n\nclass AnimatedMarker(Widget):\n\n    \'\'\'An animated marker for the progress bar which defaults to appear as if\n    it were rotating.\n    \'\'\'\n\n    def __init__(self, markers=\'|/-\\\\\'):\n        self.markers = markers\n        self.curmark = -1\n\n    def update(self, pbar):\n        \'\'\'Updates the widget to show the next marker or the first marker when\n        finished\'\'\'\n\n        if pbar.finished:\n            return self.markers[0]\n\n        self.curmark = (self.curmark + 1) % len(self.markers)\n        return self.markers[self.curmark]\n\n# Alias for backwards compatibility\nRotatingMarker = AnimatedMarker\n\n\nclass Counter(Widget):\n\n    \'Displays the current count\'\n\n    def __init__(self, format=\'%d\'):\n        self.format = format\n\n    def update(self, pbar):\n        return self.format % pbar.currval\n\n\nclass Percentage(Widget):\n\n    \'Displays the current percentage as a number with a percent sign.\'\n\n    def update(self, pbar):\n        return \'%3d%%\' % pbar.percentage()\n\n\nclass FormatLabel(Timer):\n\n    \'Displays a formatted label\'\n\n    mapping = {\n        \'elapsed\': (\'seconds_elapsed\', Timer.format_time),\n        \'finished\': (\'finished\', None),\n        \'last_update\': (\'last_update_time\', None),\n        \'max\': (\'maxval\', None),\n        \'seconds\': (\'seconds_elapsed\', None),\n        \'start\': (\'start_time\', None),\n        \'value\': (\'currval\', None)\n    }\n\n    def __init__(self, format):\n        self.format = format\n\n    def update(self, pbar):\n        context = {}\n        for name, (key, transform) in self.mapping.items():\n            try:\n                value = getattr(pbar, key)\n\n                if transform is None:\n                    context[name] = value\n                else:\n                    context[name] = transform(value)\n            except:  # pragma: no cover\n                pass\n\n        return self.format % context\n\n\nclass SimpleProgress(Widget):\n\n    \'Returns progress as a count of the total (e.g.: ""5 of 47"")\'\n\n    def __init__(self, sep=\' of \'):\n        self.sep = sep\n\n    def update(self, pbar):\n        return \'%d%s%d\' % (pbar.currval, self.sep, pbar.maxval)\n\n\nclass Bar(WidgetHFill):\n\n    \'A progress bar which stretches to fill the line.\'\n\n    def __init__(self, marker=\'#\', left=\'|\', right=\'|\', fill=\' \',\n                 fill_left=True):\n        \'\'\'Creates a customizable progress bar.\n\n        marker - string or updatable object to use as a marker\n        left - string or updatable object to use as a left border\n        right - string or updatable object to use as a right border\n        fill - character to use for the empty part of the progress bar\n        fill_left - whether to fill from the left or the right\n        \'\'\'\n        self.marker = marker\n        self.left = left\n        self.right = right\n        self.fill = fill\n        self.fill_left = fill_left\n\n    def update(self, pbar, width):\n        \'Updates the progress bar and its subcomponents\'\n\n        left, marked, right = (format_updatable(i, pbar) for i in\n                               (self.left, self.marker, self.right))\n\n        width -= len(left) + len(right)\n        # Marked must *always* have length of 1\n        if pbar.maxval:\n            marked *= int(pbar.currval / pbar.maxval * width)\n        else:  # pragma: no cover\n            marked = \'\'\n\n        if self.fill_left:\n            return \'%s%s%s\' % (left, marked.ljust(width, self.fill), right)\n        else:\n            return \'%s%s%s\' % (left, marked.rjust(width, self.fill), right)\n\n\nclass ReverseBar(Bar):\n\n    \'A bar which has a marker which bounces from side to side.\'\n\n    def __init__(self, marker=\'#\', left=\'|\', right=\'|\', fill=\' \',\n                 fill_left=False):\n        \'\'\'Creates a customizable progress bar.\n\n        marker - string or updatable object to use as a marker\n        left - string or updatable object to use as a left border\n        right - string or updatable object to use as a right border\n        fill - character to use for the empty part of the progress bar\n        fill_left - whether to fill from the left or the right\n        \'\'\'\n        self.marker = marker\n        self.left = left\n        self.right = right\n        self.fill = fill\n        self.fill_left = fill_left\n\n\nclass BouncingBar(Bar):\n\n    def update(self, pbar, width):\n        \'Updates the progress bar and its subcomponents\'\n\n        left, marker, right = (format_updatable(i, pbar) for i in\n                               (self.left, self.marker, self.right))\n\n        width -= len(left) + len(right)\n\n        if pbar.finished:\n            return \'%s%s%s\' % (left, width * marker, right)\n\n        position = int(pbar.currval % (width * 2 - 1))\n        if position > width:\n            position = width * 2 - position\n        lpad = self.fill * (position - 1)\n        rpad = self.fill * (width - len(marker) - len(lpad))\n\n        # Swap if we want to bounce the other way\n        if not self.fill_left:\n            rpad, lpad = lpad, rpad\n\n        return \'%s%s%s%s%s\' % (left, lpad, marker, rpad, right)\n'"
rootpy/extern/shortuuid/__init__.py,0,"b'"""""" Concise UUID generation. """"""\n\nimport binascii\nimport math\nimport os\nimport uuid as _uu\n\n\nclass ShortUUID(object):\n    def __init__(self, alphabet=None):\n        if alphabet is None:\n            alphabet = list(""23456789ABCDEFGHJKLMNPQRSTUVWXYZ""\n                            ""abcdefghijkmnopqrstuvwxyz"")\n\n        self.set_alphabet(alphabet)\n\n    def _num_to_string(self, number, pad_to_length=None):\n        """"""\n        Convert a number to a string, using the given alphabet.\n        """"""\n        output = """"\n        while number:\n            number, digit = divmod(number, self._alpha_len)\n            output += self._alphabet[digit]\n        if pad_to_length:\n            remainder = max(pad_to_length - len(output), 0)\n            output = output + self._alphabet[0] * remainder\n        return output\n\n    def _string_to_int(self, string):\n        """"""\n        Convert a string to a number, using the given alphabet..\n        """"""\n        number = 0\n        for char in string[::-1]:\n            number = number * self._alpha_len + self._alphabet.index(char)\n        return number\n\n    def encode(self, uuid, pad_length=22):\n        """"""\n        Encodes a UUID into a string (LSB first) according to the alphabet\n        If leftmost (MSB) bits 0, string might be shorter\n        """"""\n        return self._num_to_string(uuid.int, pad_to_length=pad_length)\n\n    def decode(self, string):\n        """"""\n        Decodes a string according to the current alphabet into a UUID\n        Raises ValueError when encountering illegal characters\n        or too long string\n        If string too short, fills leftmost (MSB) bits with 0.\n        """"""\n        return _uu.UUID(int=self._string_to_int(string))\n\n    def uuid(self, name=None, pad_length=22):\n        """"""\n        Generate and return a UUID.\n\n        If the name parameter is provided, set the namespace to the provided\n        name and generate a UUID.\n        """"""\n        # If no name is given, generate a random UUID.\n        if name is None:\n            uuid = _uu.uuid4()\n        elif ""http"" not in name.lower():\n            uuid = _uu.uuid5(_uu.NAMESPACE_DNS, name)\n        else:\n            uuid = _uu.uuid5(_uu.NAMESPACE_URL, name)\n        return self.encode(uuid, pad_length)\n\n    def random(self, length=22):\n        """"""\n        Generate and return a cryptographically-secure short random string\n        of the specified length.\n        """"""\n        random_num = int(binascii.b2a_hex(os.urandom(length)), 16)\n        return self._num_to_string(random_num, pad_to_length=length)[:length]\n\n    def get_alphabet(self):\n        """"""Return the current alphabet used for new UUIDs.""""""\n        return \'\'.join(self._alphabet)\n\n    def set_alphabet(self, alphabet):\n        """"""Set the alphabet to be used for new UUIDs.""""""\n\n        # Turn the alphabet into a set and sort it to prevent duplicates\n        # and ensure reproducibility.\n        new_alphabet = list(sorted(set(alphabet)))\n        if len(new_alphabet) > 1:\n            self._alphabet = new_alphabet\n            self._alpha_len = len(self._alphabet)\n        else:\n            raise ValueError(""Alphabet with more than ""\n                             ""one unique symbols required."")\n\n    def encoded_length(self, num_bytes=16):\n        """"""\n        Returns the string length of the shortened UUID.\n        """"""\n        factor = math.log(256) / math.log(self._alpha_len)\n        return int(math.ceil(factor * num_bytes))\n\n\n# For backwards compatibility\n_global_instance = ShortUUID()\nencode = _global_instance.encode\ndecode = _global_instance.decode\nuuid = _global_instance.uuid\nrandom = _global_instance.random\nget_alphabet = _global_instance.get_alphabet\nset_alphabet = _global_instance.set_alphabet\n'"
rootpy/io/tests/__init__.py,0,b''
rootpy/io/tests/test_file.py,0,"b'""""""\nTests for the file module.\n""""""\n\nfrom rootpy.context import invisible_canvas\nfrom rootpy.io import TemporaryFile, DoesNotExist, MemFile, File, Directory\nfrom rootpy.io import root_open\nfrom rootpy.plotting import Hist\nfrom rootpy.testdata import get_file\nfrom rootpy import ROOT\n\nfrom nose.tools import assert_raises, assert_equal, assert_true\n\nimport gc\nimport os\n\nimport ROOT as R\n\n\ndef test_tempfile():\n    with TemporaryFile() as f:\n        assert_equal(os.path.isfile(f.GetName()), True)\n        assert_raises(DoesNotExist, f.Get, \'blah\')\n        hist = Hist(1, 0, 1, name=\'test\')\n        hist.Write()\n        hist2 = f.test\n        assert_equal(hist2.__class__, hist.__class__)\n    assert_equal(os.path.isfile(f.GetName()), False)\n\n\ndef test_memfile():\n    with MemFile() as f:\n        hist = Hist(1, 0, 1, name=\'test\')\n        hist.Write()\n        assert_equal(f[\'test\'], hist)\n\n\ndef test_file_open():\n    fname = \'test_file_open.root\'\n    with File.open(fname, \'w\'):\n        pass\n    with root_open(fname, \'r\'):\n        pass\n    with root_open(fname):\n        pass\n    with ROOT.TFile(fname, \'recreate\') as f:\n        assert_true(isinstance(f, File))\n    os.unlink(fname)\n\n\ndef test_context():\n    with MemFile() as a:\n        assert_equal(ROOT.gDirectory, a)\n        with MemFile() as b:\n            d = Directory(\'test\')\n            with d:\n                assert_equal(ROOT.gDirectory, d)\n            assert_equal(ROOT.gDirectory, b)\n        assert_equal(ROOT.gDirectory, a)\n\n    # test out of order\n    f1 = MemFile()\n    f2 = MemFile()\n    with f1:\n        assert_equal(ROOT.gDirectory, f1)\n    assert_equal(ROOT.gDirectory, f2)\n    f1.Close()\n    f2.Close()\n\n    d = Directory(\'test\')\n    d.cd()\n\n    # test without with statement\n    f1 = MemFile()\n    f2 = TemporaryFile()\n    assert_equal(ROOT.gDirectory, f2)\n    f2.Close()\n    assert_equal(ROOT.gDirectory, f1)\n    f1.Close()\n\n\ndef test_file_get():\n    with get_file() as f:\n        d = f.Get(\'means\', rootpy=False)\n        assert_equal(d.__class__.__name__, \'TDirectoryFile\')\n        d = f.Get(\'means\')\n        assert_equal(d.__class__.__name__, \'Directory\')\n        h = f.Get(\'means/hist1\', rootpy=False)\n        assert_equal(h.__class__.__name__, \'TH1F\')\n        h = f.Get(\'means/hist1\')\n        assert_equal(h.__class__.__name__, \'Hist\')\n\n\ndef test_file_item():\n    with TemporaryFile() as f:\n        h = Hist(1, 0, 1, name=\'test\')\n        f[\'myhist\'] = h\n        f.myhist\n        assert_equal(f[\'myhist\'].name, \'test\')\n\n\ndef test_file_attr():\n    with TemporaryFile() as f:\n        h = Hist(1, 0, 1, name=\'test\')\n        f.myhist = h\n        f.Get(\'myhist\')\n        assert_equal(f.myhist.name, \'test\')\n        f.something = 123\n        f.mkdir(\'hello\')\n        f.hello.something = h\n        assert_equal(f[\'hello/something\'].name, \'test\')\n\n\ndef test_file_contains():\n    with TemporaryFile() as f:\n        assert_equal(\'some/thing\' in f, False)\n        rdir = f.mkdir(\'some\')\n        thing = Hist(10, 0, 1, name=\'thing\')\n        rdir.thing = thing\n        assert_true(\'some/thing\' in f)\n        assert_true(\'thing\' in rdir)\n        f.mkdir(\'a/b/c\', recurse=True)\n        assert_true(\'a/b/c\' in f)\n\n\ndef test_no_dangling_files():\n\n    def foo():\n        f = MemFile()\n\n    foo()\n\n    g = root_open(\'test_no_dangling_files.root\', \'recreate\')\n    os.unlink(\'test_no_dangling_files.root\')\n    del g\n\n    gc.collect()\n    assert list(R.gROOT.GetListOfFiles()) == [], ""There exist open ROOT files when there should not be""\n\n\ndef test_keepalive():\n    gc.collect()\n    assert list(R.gROOT.GetListOfFiles()) == [], ""There exist open ROOT files when there should not be""\n\n    # Ordinarily this would lead to h with a value of `None`, since the file\n    # gets garbage collected. However, File.Get uses keepalive to prevent this.\n    # The purpose of this test is to ensure that everything is working as\n    # expected.\n    h = get_file().Get(""means/hist1"")\n    gc.collect()\n    assert h, ""hist1 is not being kept alive""\n    assert list(R.gROOT.GetListOfFiles()) != [], ""Expected an open ROOT file..""\n\n    h = None\n    gc.collect()\n    assert list(R.gROOT.GetListOfFiles()) == [], ""There exist open ROOT files when there should not be""\n\n\ndef test_keepalive_canvas():\n\n    gc.collect()\n    assert list(R.gROOT.GetListOfFiles()) == [], ""There exist open ROOT files when there should not be""\n\n    with invisible_canvas() as c:\n        get_file().Get(""means/hist1"").Draw()\n        gc.collect()\n        assert list(R.gROOT.GetListOfFiles()) != [], ""Expected an open ROOT file..""\n\n    gc.collect()\n    assert list(R.gROOT.GetListOfFiles()) == [], ""There exist open ROOT files when there should not be""\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/io/tests/test_pickler.py,0,"b'""""""\nTests for the file module.\n""""""\n\nfrom rootpy.io import root_open, TemporaryFile\nfrom rootpy.io.pickler import load, dump\nfrom rootpy.plotting import Hist\nimport random\nimport tempfile\nfrom nose.tools import assert_equal, assert_true, assert_false\n\n\ndef test_pickler():\n    hlist = list()\n    for i in range(10):\n        hlist.append(Hist(10, 0, 10))\n\n    with TemporaryFile() as tmpfile:\n        dump(hlist, tmpfile)\n        hlist_out = load(tmpfile)\n        assert_equal([h.name for h in hlist_out], [h.name for h in hlist])\n\n    hdict = dict()\n    for i in range(100):\n        hist = Hist(10, 0, 1, type=random.choice(\'CSIFD\'))\n        hdict[hist.name] = hist\n\n    with TemporaryFile() as tmpfile:\n        rdir = tmpfile.mkdir(\'pickle\')\n        dump(hdict, rdir)\n        hdict_out = load(rdir)\n        assert_equal(len(hdict_out), 100)\n        for name, hist in hdict_out.items():\n            assert_equal(name, hist.name)\n            assert_equal(hist.TYPE, hdict[hist.name].TYPE)\n\n\ndef test_pickler_proxy():\n    h = Hist(5, 0, 1, name=\'hist\')\n    f = tempfile.NamedTemporaryFile(suffix=\'.root\')\n\n    with root_open(f.name, \'recreate\') as outfile:\n        dump([h], outfile)\n\n    class IsCalled(object):\n        def __init__(self, func):\n            self.func = func\n            self.called = False\n\n        def __call__(self, path):\n            if path != \'_pickle;1\':\n                self.called = True\n            return self.func(path)\n\n    with root_open(f.name) as infile:\n        infile.Get = IsCalled(infile.Get)\n        hlist = load(infile, use_proxy=False)\n        assert_true(infile.Get.called)\n\n    with root_open(f.name) as infile:\n        infile.Get = IsCalled(infile.Get)\n        hlist = load(infile, use_proxy=True)\n        assert_false(infile.Get.called)\n        assert_equal(hlist[0].name, \'hist\')\n        assert_true(infile.Get.called)\n\n    f.close()\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/logger/tests/__init__.py,0,b''
rootpy/logger/tests/logcheck.py,0,"b'import logging\nimport re\n\nfrom functools import wraps\n\nimport rootpy\n\nclass LogCapture(logging.Handler):\n    def __init__(self, logger):\n        logging.Handler.__init__(self)\n        self.records = []\n        self.logger = logger\n\n    def __enter__(self):\n        self.logger.addHandler(self)\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.logger.removeHandler(self)\n\n    def emit(self, record):\n        self.records.append(record)\n\n    def contains(self, level, message_re):\n        return any(r.levelname == level and message_re.search(r.getMessage())\n                   for r in self.records)\n\nclass EnsureLogContains(object):\n    def __init__(self, level, message_pattern):\n        self.level = level\n        self.message_pattern = message_pattern\n        self.msg_re = re.compile(message_pattern)\n\n    def __call__(self, func):\n        @wraps(func)\n        def wrapped(*args, **kwargs):\n\n            with LogCapture(rootpy.log[""/ROOT""]) as captured:\n                try:\n                    return func(*args, **kwargs)\n                finally:\n                    assert captured.contains(self.level, self.msg_re), (\n                        ""Expected `{0}` to emit a {1} message matching \'{2}\'. ""\n                        ""It did not.""\n                        .format(func.__name__, self.level, self.message_pattern)\n                    )\n\n        return wrapped'"
rootpy/logger/tests/test_roothandler.py,0,"b'from rootpy.defaults import use_rootpy_handler, use_rootpy_magic\n\nif not use_rootpy_handler or not use_rootpy_magic:\n    from nose.plugins.skip import SkipTest\n    raise SkipTest()\n\nimport logging\nimport sys\n\nfrom nose.tools import raises\n\nimport ROOT\n\nimport rootpy\nimport rootpy.logger.magic as M\n\nfrom rootpy import ROOTError\nfrom .logcheck import EnsureLogContains\n\nM.DANGER.enabled = True\n\nNONEXISTENT_FILE = ""this-file-should-never-exist-7b078562896325fa8007a0eb0.root""\n\n#rootpy.log[""/ROOT.rootpy""].show_stack("".*tracing.*"")\n\n\n@EnsureLogContains(""WARNING"", ""^This is a test message$"")\ndef test_logging_root_messages():\n    ROOT.Warning(""rootpy.logger.tests"", ""This is a test message"")\n\n\n@raises(ROOTError)\ndef test_root_error():\n    ROOT.Error(""rootpy.logger.tests"", ""This is a test exception"")\n\n\n@raises(ROOTError)\ndef test_nonexistent_file():\n    ROOT.TFile(NONEXISTENT_FILE)\n\n\n@raises(ROOTError)\ndef test_error_finally():\n    try:\n        ROOT.Error(""test"", ""finally"")\n    finally:\n        test = 1\n\n\n@raises(ROOTError)\ndef test_gdebug_finally():\n    ROOT.gDebug = 1\n    try:\n        ROOT.Error(""test"", ""finally [rootpy.ALWAYSABORT]"")\n    finally:\n        ROOT.gDebug = 0\n\n\ndef test_nonexistent_file_redux():\n    try:\n        ROOT.TFile(NONEXISTENT_FILE)\n    except ROOTError as e:\n        assert e.location == ""TFile::TFile""\n        assert e.level == 3000\n        assert NONEXISTENT_FILE in e.msg\n        assert ""does not exist"" in e.msg\n    else:\n        assert False, ""Should have thrown""\n\n# The following tests ensure that things work as expected with different\n# constructs\n\n@raises(ROOTError)\ndef test_nonexistent_file_redux_part_2():\n    if True:\n        ROOT.TFile(NONEXISTENT_FILE)\n\n\n@raises(ROOTError)\ndef test_nonexistent_file_redux_part_3_the_loopening():\n    for i in range(10):\n        ROOT.TFile(NONEXISTENT_FILE)\n\n\n@raises(ROOTError)\ndef test_nonexistent_file_redux_part_4_the_withinating():\n    class Context(object):\n        def __enter__(*args): pass\n        def __exit__(*args): pass\n\n    with Context():\n        ROOT.TFile(NONEXISTENT_FILE)\n\n\ndef test_correct_bytecode_functioning():\n    # This test ensures that we don\'t break opcodes which follow exceptions\n\n    fail = True\n    class Continued:\n        success = False\n\n    def try_fail():\n        if fail:\n            ROOT.Error(""rooypy.logger.tests"", ""TEST"")\n        Continued.success = True\n\n    if sys.version_info[0] < 3:\n        orig_code_bytes = [ord(i) for i in try_fail.func_code.co_code]\n    else:\n        orig_code_bytes = try_fail.__code__.co_code\n\n    #import dis\n    #dis.dis(try_fail)\n\n    try:\n        try_fail()\n    except ROOTError:\n        pass\n    else:\n        assert False, ""Should have thrown""\n\n    #print ""#""*80\n    #dis.dis(try_fail)\n    if sys.version_info[0] < 3:\n        new_code_bytes = [ord(i) for i in try_fail.func_code.co_code]\n    else:\n        new_code_bytes = try_fail.__code__.co_code\n\n    assert orig_code_bytes == new_code_bytes\n\n    fail = False\n    try_fail()\n\n    assert Continued.success\n\n\ndef test_tracing_is_broken():\n    def mytrace(*args):\n        pass\n\n    orig_trace = sys.gettrace()\n    sys.settrace(mytrace)\n\n    try:\n        ROOT.Error(""rootpy.logger.tests"", ""Test tracing OK"")\n    except ROOTError:\n        pass\n    else:\n        assert False, ""Should have thrown""\n\n    should_be_mytrace = sys.gettrace()\n    sys.settrace(orig_trace)\n\n    assert should_be_mytrace != mytrace, ""Tracing is fixed?! Awesome. Now fix the test.""\n'"
rootpy/logger/tests/test_threading.py,0,"b'from __future__ import division\n\nimport itertools\nimport sys\nimport os\nimport os.path\nimport platform\nimport resource\nimport threading\nimport time\n\nfrom math import ceil\nfrom random import random\nfrom nose.plugins.skip import SkipTest\n\nimport ROOT\n\nimport rootpy; log = rootpy.log[""rootpy.logger.test.threading""]\n\nfrom .logcheck import EnsureLogContains\n\n\ndef optional_fatal(abort=True):\n    msg = ""[rootpy.ALWAYSABORT]"" if abort else ""[rootpy.NEVERABORT]""\n    ROOT.Error(""rootpy.logger.test"", msg)\n\n\nf = optional_fatal\nif sys.version_info[0] < 3:\n    optional_fatal._bytecode = lambda: list(map(ord, f.func_code.co_code))\nelse:\n    optional_fatal._bytecode = lambda: list(f.__code__.co_code)\noptional_fatal._ORIG_BYTECODE = optional_fatal._bytecode()\noptional_fatal._unmodified = lambda: f._bytecode() == f._ORIG_BYTECODE\n\n\ndef optional_fatal_bytecode_check():\n    assert optional_fatal._unmodified(), (\n        ""Detected modified bytecode. This should never happen.\\n""\n        ""{0}\\n""\n        ""=======\\n""\n        ""{1}"".format(optional_fatal._bytecode(), optional_fatal._ORIG_BYTECODE))\n\n\nnumber_of_fatals = itertools.count()\ntotal = itertools.count()\n\n\ndef maybe_fatal():\n    try:\n        # Throw exceptions 80% of the time\n        optional_fatal(random() < 0.8)\n    except rootpy.ROOTError:\n        next(number_of_fatals)\n    finally:\n        next(total)\n        optional_fatal_bytecode_check()\n\n\ndef randomfatal(should_exit):\n    while not should_exit.is_set():\n        maybe_fatal()\n\n\ndef spareprocs():\n    """"""\n    Compute the maximum number of threads we can start up according to ulimit\n    """"""\n    if not os.path.exists(""/proc""):\n        # Return a decent small value, we just want it to run, more grindy tests\n        # can take place on other machines.\n        return 10\n\n    nmax, _ = resource.getrlimit(resource.RLIMIT_NPROC)\n    me = os.geteuid()\n    return nmax - sum(1 for p in os.listdir(""/proc"")\n                       if p.isdigit() and os.stat(""/proc/"" + p).st_uid == me)\n\n\ndef test_multithread_exceptions():\n    from rootpy.defaults import use_rootpy_handler, use_rootpy_magic\n\n    if not use_rootpy_handler or not use_rootpy_magic:\n        raise SkipTest()\n\n    rootpy.logger.magic.DANGER.enabled = True\n\n    should_exit = threading.Event()\n\n    sup_logger = log[""/ROOT.rootpy.logger.test""]\n    old_level = sup_logger.level\n    # Suppress test warnings\n    sup_logger.setLevel(log.CRITICAL)\n\n    # Run for 1/4 second or 10s if LONG_TESTS is in the environment\n    length = float(os.environ.get(""TEST_TIME"", 0.25))\n\n    try:\n        threads = []\n        for i in range(min(100, int(ceil(spareprocs() * 0.8)))):\n            t = threading.Thread(target=randomfatal, args=(should_exit,))\n            try:\n                t.start()\n                threads.append(t)\n            except thread.error:\n                log.warning(""Unable to start thread"")\n                break\n\n        assert threads, ""Didn\'t manage to start any threads!""\n\n        time.sleep(length)\n\n        should_exit.set()\n        for t in threads:\n            t.join()\n\n    finally:\n        sup_logger.setLevel(old_level)\n\n    tot = next(total)-1\n    fatals = next(number_of_fatals) - 1\n    fmt = ""Success raising exceptions in {0} threads: total: {1} (fatals {2:%})""\n    log.debug(fmt.format(len(threads), tot, fatals / tot))\n'"
rootpy/memory/tests/__init__.py,0,b''
rootpy/memory/tests/test_getownership.py,0,"b'from rootpy.memory.ownership import GetOwnership\n\nimport ROOT as R\n\ndef test_getownership():\n    o = R.TObject()\n    assert GetOwnership(o)\n    R.SetOwnership(o, False)\n    assert not GetOwnership(o)\n'"
rootpy/memory/tests/test_keepalive.py,0,"b'import gc\nimport weakref\n\nimport rootpy.plotting\nfrom rootpy.context import invisible_canvas\nfrom rootpy.memory.deletion import monitor_deletion\nfrom rootpy import QROOT as R\n\n\ndef test_keepalive():\n    class went_away:\n        value = False\n\n    def callback(*args):\n        went_away.value = True\n\n    with invisible_canvas() as c:\n        c.cd()\n\n        # No primitives to start with\n        assert c.GetListOfPrimitives().GetSize() == 0\n\n        h = R.TH1F()\n        h.Draw()\n\n        hproxy = weakref.proxy(h, callback)\n\n        # Now we\'ve got one primitive on the canvas\n        assert c.GetListOfPrimitives().GetSize() == 1\n\n        del h\n        gc.collect()\n        # We should still have it due to the keepalive\n        assert c.GetListOfPrimitives().GetSize() == 1\n\n    # Canvas should now have gone away\n    assert not c\n\n    # And so should the histogram object\n    assert went_away.value\n\n\ndef test_nokeepalive():\n    with invisible_canvas() as c:\n\n        assert c.GetListOfPrimitives().GetSize() == 0\n\n        h = R.TH1F()\n        h.Draw()\n\n        assert c.GetListOfPrimitives().GetSize() == 1\n        del h\n        from rootpy.memory import KEEPALIVE\n        KEEPALIVE.clear()\n\n        # ROOT automatically cleans things up like this on deletion, and since\n        # we cleared the keepalive dictionary, they should have gone away.\n        assert c.GetListOfPrimitives().GetSize() == 0\n\n\ndef test_canvas_divide():\n    monitor, is_alive = monitor_deletion()\n\n    with invisible_canvas() as c:\n        monitor(c, ""c"")\n\n        c.Divide(2)\n\n        p = c.cd(1)\n\n        monitor(p, ""p"")\n        assert is_alive(""p"")\n\n        h = R.TH1F()\n        h.Draw()\n        monitor(h, ""h"")\n\n        assert is_alive(""h"")\n        del h\n        assert is_alive(""h"")\n\n        del p\n        # p should be kept alive because of the canvas\n        assert is_alive(""p"")\n        # h should still be alive because of the pad\n        assert is_alive(""h"")\n\n        c.Clear()\n\n        # clearing the canvas means that the pad (and therefore the hist) should\n        # be deleted.\n        assert not is_alive(""p"")\n        assert not is_alive(""h"")\n\n        # -------------\n        # Next test, check that when the canvas is deleted, everything goes away\n\n        p = c.cd(2)\n        h = R.TH1F()\n        h.Draw()\n\n        monitor(p, ""p"")\n        monitor(p, ""h"")\n\n        del p\n        del h\n\n        assert is_alive(""p"")\n        assert is_alive(""h"")\n\n    # The canvas is deleted by exiting the with statement.\n    # Everything should go away.\n    assert not is_alive(""c"")\n    assert not is_alive(""p"")\n    assert not is_alive(""h"")\n'"
rootpy/plotting/contrib/__init__.py,0,"b""from __future__ import absolute_import\n\nfrom .. import log; log = log[__name__]\nfrom .plot_contour_matrix import plot_contour_matrix\nfrom .plot_corrcoef_matrix import plot_corrcoef_matrix\n\n__all__ = [\n    'plot_contour_matrix',\n    'plot_corrcoef_matrix',\n]\n"""
rootpy/plotting/contrib/gif.py,0,"b'from __future__ import absolute_import\n\nimport subprocess\nimport os\n\nfrom . import log; log = log[__name__]\n\n__all__ = [\n    \'GIF\',\n]\n\n\nclass GIF(object):\n\n    def __init__(self):\n\n        self.images = []\n\n    def add_frame(self, image):\n\n        self.images.append(image)\n\n    def add_frames(self, images):\n\n        self.images.extend(images)\n\n    def write(self, outname, delay=10, loop=0):\n\n        if not self.images:\n            raise RuntimeError(\n                ""attempting to create an animated GIF without frames"")\n        name, ext = os.path.splitext(outname)\n        if ext != \'.gif\':\n            raise ValueError(""output filename must have the .gif extension"")\n        cmd = [\n            \'convert\',\n            \'-delay\', \'{0:d}\'.format(delay),\n            \'-loop\', \'{0:d}\'.format(loop)] + self.images + [outname]\n        log.info(""creating gif: {0}"".format(\' \'.join(cmd)))\n        p = subprocess.Popen(cmd)\n        if p.wait():\n            raise RuntimeError(\n                ""failed to create animated GIF: {0}. ""\n                ""Do you have ImageMagick imstalled?"".format(outname))\n\n    def clean(self):\n\n        for image in self.images:\n            os.unlink(image)\n        self.images = []\n'"
rootpy/plotting/contrib/plot_contour_matrix.py,8,"b'from __future__ import absolute_import\n\nimport os\nimport tempfile\nimport shutil\n\nfrom . import log; log = log[__name__]\nfrom .. import Hist2D\nfrom .gif import GIF\n\n__all__ = [\n    \'plot_contour_matrix\',\n]\n\nLINES = [\'dashed\', \'solid\', \'dashdot\', \'dotted\']\n\n\ndef plot_contour_matrix(arrays,\n                        fields,\n                        filename,\n                        weights=None,\n                        sample_names=None,\n                        sample_lines=None,\n                        sample_colors=None,\n                        color_map=None,\n                        num_bins=20,\n                        num_contours=3,\n                        cell_width=2,\n                        cell_height=2,\n                        cell_margin_x=0.05,\n                        cell_margin_y=0.05,\n                        dpi=100,\n                        padding=0,\n                        animate_field=None,\n                        animate_steps=10,\n                        animate_delay=20,\n                        animate_loop=0):\n    """"""\n    Create a matrix of contour plots showing all possible 2D projections of a\n    multivariate dataset. You may optionally animate the contours as a cut on\n    one of the fields is increased. ImageMagick must be installed to produce\n    animations.\n\n    Parameters\n    ----------\n\n    arrays : list of arrays of shape [n_samples, n_fields]\n        A list of 2D NumPy arrays for each sample. All arrays must have the\n        same number of columns.\n\n    fields : list of strings\n        A list of the field names.\n\n    filename : string\n        The output filename. If animatation is enabled\n        ``animate_field is not None`` then ``filename`` must have the .gif\n        extension.\n\n    weights : list of arrays, optional (default=None)\n        List of 1D NumPy arrays of sample weights corresponding to the arrays\n        in ``arrays``.\n\n    sample_names : list of strings, optional (default=None)\n        A list of the sample names for the legend. If None, then no legend will\n        be shown.\n\n    sample_lines : list of strings, optional (default=None)\n        A list of matplotlib line styles for each sample. If None then line\n        styles will cycle through \'dashed\', \'solid\', \'dashdot\', and \'dotted\'.\n        Elements of this list may also be a list of line styles which will be\n        cycled through for the contour lines of the corresponding sample.\n\n    sample_colors : list of matplotlib colors, optional (default=None)\n        The color of the contours for each sample. If None, then colors will be\n        selected according to regular intervals along the ``color_map``.\n\n    color_map : a matplotlib color map, optional (default=None)\n        If ``sample_colors is None`` then select colors according to regular\n        intervals along this matplotlib color map. If ``color_map`` is None,\n        then the spectral color map is used.\n\n    num_bins : int, optional (default=20)\n        The number of bins along both axes of the 2D histograms.\n\n    num_contours : int, optional (default=3)\n        The number of contour line to show for each sample.\n\n    cell_width : float, optional (default=2)\n        The width, in inches, of each subplot in the matrix.\n\n    cell_height : float, optional (default=2)\n        The height, in inches, of each subplot in the matrix.\n\n    cell_margin_x : float, optional (default=0.05)\n        The horizontal margin between adjacent subplots, as a fraction\n        of the subplot size.\n\n    cell_margin_y : float, optional (default=0.05)\n        The vertical margin between adjacent subplots, as a fraction\n        of the subplot size.\n\n    dpi : int, optional (default=100)\n        The number of pixels per inch.\n\n    padding : float, optional (default=0)\n        The padding, as a fraction of the range of the value along each axes to\n        guarantee around each sample\'s contour plot.\n\n    animate_field : string, optional (default=None)\n        The field to animate a cut along. By default no animation is produced.\n        If ``animate_field is not None`` then ``filename`` must end in the .gif\n        extension and an animated GIF is produced.\n\n    animate_steps : int, optional (default=10)\n        The number of frames in the animation, corresponding to the number of\n        regularly spaced cut values to show along the range of the\n        ``animate_field``.\n\n    animate_delay : int, optional (default=20)\n        The duration that each frame is shown in the animation as a multiple of\n        1 / 100 of a second.\n\n    animate_loop : int, optional (default=0)\n        The number of times to loop the animation. If zero, then loop forever.\n\n    Notes\n    -----\n\n    NumPy and matplotlib are required\n\n    """"""\n    import numpy as np\n    from .. import root2matplotlib as r2m\n    import matplotlib.pyplot as plt\n    from matplotlib.ticker import MaxNLocator\n    from matplotlib import cm\n    from matplotlib.lines import Line2D\n\n    # we must have at least two fields (columns)\n    num_fields = len(fields)\n    if num_fields < 2:\n        raise ValueError(\n            ""record arrays must have at least two fields"")\n    # check that all arrays have the same number of columns\n    for array in arrays:\n        if array.shape[1] != num_fields:\n            raise ValueError(\n                ""number of array columns does not match number of fields"")\n\n    if sample_colors is None:\n        if color_map is None:\n            color_map = cm.spectral\n        steps = np.linspace(0, 1, len(arrays) + 2)[1:-1]\n        sample_colors = [color_map(s) for s in steps]\n\n    # determine range of each field\n    low = np.vstack([a.min(axis=0) for a in arrays]).min(axis=0)\n    high = np.vstack([a.max(axis=0) for a in arrays]).max(axis=0)\n    width = np.abs(high - low)\n    width *= padding\n    low -= width\n    high += width\n\n    def single_frame(arrays, filename, label=None):\n\n        # create the canvas and divide into matrix\n        fig, axes = plt.subplots(\n            nrows=num_fields,\n            ncols=num_fields,\n            figsize=(cell_width * num_fields, cell_height * num_fields))\n        fig.subplots_adjust(hspace=cell_margin_y, wspace=cell_margin_x)\n\n        for ax in axes.flat:\n            # only show the left and bottom axes ticks and labels\n            if ax.is_last_row() and not ax.is_last_col():\n                ax.xaxis.set_visible(True)\n                ax.xaxis.set_ticks_position(\'bottom\')\n                ax.xaxis.set_major_locator(MaxNLocator(4, prune=\'both\'))\n                for tick in ax.xaxis.get_major_ticks():\n                    tick.label.set_rotation(\'vertical\')\n            else:\n                ax.xaxis.set_visible(False)\n\n            if ax.is_first_col() and not ax.is_first_row():\n                ax.yaxis.set_visible(True)\n                ax.yaxis.set_ticks_position(\'left\')\n                ax.yaxis.set_major_locator(MaxNLocator(4, prune=\'both\'))\n            else:\n                ax.yaxis.set_visible(False)\n\n        # turn off axes frames in upper triangular matrix\n        for ix, iy in zip(*np.triu_indices_from(axes, k=0)):\n            axes[ix, iy].axis(\'off\')\n\n        levels = np.linspace(0, 1, num_contours + 2)[1:-1]\n\n        # plot the data\n        for iy, ix in zip(*np.tril_indices_from(axes, k=-1)):\n            ymin = float(low[iy])\n            ymax = float(high[iy])\n            xmin = float(low[ix])\n            xmax = float(high[ix])\n            for isample, a in enumerate(arrays):\n                hist = Hist2D(\n                    num_bins, xmin, xmax,\n                    num_bins, ymin, ymax)\n                if weights is not None:\n                    hist.fill_array(a[:, [ix, iy]], weights[isample])\n                else:\n                    hist.fill_array(a[:, [ix, iy]])\n                # normalize so maximum is 1.0\n                _max = hist.GetMaximum()\n                if _max != 0:\n                    hist /= _max\n                r2m.contour(hist,\n                    axes=axes[iy, ix],\n                    levels=levels,\n                    linestyles=sample_lines[isample] if sample_lines else LINES,\n                    colors=sample_colors[isample])\n\n        # label the diagonal subplots\n        for i, field in enumerate(fields):\n            axes[i, i].annotate(field,\n                (0.1, 0.2),\n                rotation=45,\n                xycoords=\'axes fraction\',\n                ha=\'left\', va=\'center\')\n\n        # make proxy artists for legend\n        lines = []\n        for color in sample_colors:\n            lines.append(Line2D([0, 0], [0, 0], color=color))\n\n        if sample_names is not None:\n            # draw the legend\n            leg = fig.legend(lines, sample_names, loc=(0.65, 0.8))\n            leg.set_frame_on(False)\n\n        if label is not None:\n            axes[0, 0].annotate(label, (0, 1),\n                ha=\'left\', va=\'top\',\n                xycoords=\'axes fraction\')\n\n        fig.savefig(filename, bbox_inches=\'tight\', dpi=dpi)\n        plt.close(fig)\n\n    if animate_field is not None:\n        _, ext = os.path.splitext(filename)\n        if ext != \'.gif\':\n            raise ValueError(\n                ""animation is only supported for .gif files"")\n        field_idx = fields.index(animate_field)\n        cuts = np.linspace(\n            low[field_idx],\n            high[field_idx],\n            animate_steps + 1)[:-1]\n        gif = GIF()\n        temp_dir = tempfile.mkdtemp()\n        for i, cut in enumerate(cuts):\n            frame_filename = os.path.join(temp_dir, \'frame_{0:d}.png\'.format(i))\n            label = \'{0} > {1:.2f}\'.format(animate_field, cut)\n            log.info(""creating frame for {0} ..."".format(label))\n            new_arrays = []\n            for array in arrays:\n                new_arrays.append(array[array[:, field_idx] > cut])\n            single_frame(new_arrays,\n                filename=frame_filename,\n                label=label)\n            gif.add_frame(frame_filename)\n        gif.write(filename, delay=animate_delay, loop=animate_loop)\n        shutil.rmtree(temp_dir)\n    else:\n        single_frame(arrays, filename=filename)\n'"
rootpy/plotting/contrib/plot_corrcoef_matrix.py,22,"b'from __future__ import absolute_import\nfrom ...extern.six.moves import range\nfrom ...extern.six import string_types\n\n\n__all__ = [\n    \'plot_corrcoef_matrix\',\n    \'corrcoef\',\n    \'cov\',\n]\n\n\ndef plot_corrcoef_matrix(matrix, names=None,\n                         cmap=None, cmap_text=None,\n                         fontsize=12, grid=False,\n                         axes=None):\n    """"""\n    This function will draw a lower-triangular correlation matrix\n\n    Parameters\n    ----------\n\n    matrix : 2-dimensional numpy array/matrix\n        A correlation coefficient matrix\n\n    names : list of strings, optional (default=None)\n        List of the parameter names corresponding to the rows in ``matrix``.\n\n    cmap : matplotlib color map, optional (default=None)\n        Color map used to color the matrix cells.\n\n    cmap_text : matplotlib color map, optional (default=None)\n        Color map used to color the cell value text. If None, then\n        all values will be black.\n\n    fontsize : int, optional (default=12)\n        Font size of parameter name and correlation value text.\n\n    grid : bool, optional (default=False)\n        If True, then draw dashed grid lines around the matrix elements.\n\n    axes : matplotlib Axes instance, optional (default=None)\n        The axes to plot on. If None then use the global current axes.\n\n    Notes\n    -----\n\n    NumPy and matplotlib are required\n\n    Examples\n    --------\n\n    >>> matrix = corrcoef(data.T, weights=weights)\n    >>> plot_corrcoef_matrix(matrix, names)\n\n    """"""\n    import numpy as np\n    from matplotlib import pyplot as plt\n    from matplotlib import cm\n\n    if axes is None:\n        axes = plt.gca()\n\n    matrix = np.asarray(matrix)\n\n    if matrix.ndim != 2:\n        raise ValueError(""matrix is not a 2-dimensional array or matrix"")\n    if matrix.shape[0] != matrix.shape[1]:\n        raise ValueError(""matrix is not square"")\n    if names is not None and len(names) != matrix.shape[0]:\n        raise ValueError(""the number of names does not match the number of ""\n                         ""rows/columns in the matrix"")\n\n    # mask out the upper triangular matrix\n    matrix[np.triu_indices(matrix.shape[0])] = np.nan\n\n    if isinstance(cmap_text, string_types):\n        cmap_text = cm.get_cmap(cmap_text, 201)\n    if cmap is None:\n        cmap = cm.get_cmap(\'jet\', 201)\n    elif isinstance(cmap, string_types):\n        cmap = cm.get_cmap(cmap, 201)\n    # make NaN pixels white\n    cmap.set_bad(\'w\')\n\n    axes.imshow(matrix, interpolation=\'nearest\',\n                cmap=cmap, origin=\'upper\',\n                vmin=-1, vmax=1)\n\n    axes.set_frame_on(False)\n    plt.setp(axes.get_yticklabels(), visible=False)\n    plt.setp(axes.get_yticklines(), visible=False)\n    plt.setp(axes.get_xticklabels(), visible=False)\n    plt.setp(axes.get_xticklines(), visible=False)\n\n    if grid:\n        # draw grid lines\n        for slot in range(1, matrix.shape[0] - 1):\n            # vertical\n            axes.plot((slot - 0.5, slot - 0.5),\n                      (slot - 0.5, matrix.shape[0] - 0.5), \'k:\', linewidth=1)\n            # horizontal\n            axes.plot((-0.5, slot + 0.5),\n                      (slot + 0.5, slot + 0.5), \'k:\', linewidth=1)\n        if names is not None:\n            for slot in range(1, matrix.shape[0]):\n                # diagonal\n                axes.plot((slot - 0.5, slot + 1.5),\n                          (slot - 0.5, slot - 2.5), \'k:\', linewidth=1)\n\n    # label cell values\n    for row, col in zip(*np.tril_indices(matrix.shape[0], k=-1)):\n        value = matrix[row][col]\n        if cmap_text is not None:\n            color = cmap_text((value + 1.) / 2.)\n        else:\n            color = \'black\'\n        axes.text(\n            col, row,\n            ""{0:d}%"".format(int(value * 100)),\n            color=color,\n            ha=\'center\', va=\'center\',\n            fontsize=fontsize)\n\n    if names is not None:\n        # write parameter names\n        for i, name in enumerate(names):\n            axes.annotate(\n                name, (i, i),\n                rotation=45,\n                ha=\'left\', va=\'bottom\',\n                transform=axes.transData,\n                fontsize=fontsize)\n\n\ndef cov(m, y=None, rowvar=1, bias=0, ddof=None, weights=None, repeat_weights=0):\n    """"""\n    Estimate a covariance matrix, given data.\n\n    Covariance indicates the level to which two variables vary together.\n    If we examine N-dimensional samples, :math:`X = [x_1, x_2, ... x_N]^T`,\n    then the covariance matrix element :math:`C_{ij}` is the covariance of\n    :math:`x_i` and :math:`x_j`. The element :math:`C_{ii}` is the variance\n    of :math:`x_i`.\n\n    Parameters\n    ----------\n    m : array_like\n        A 1-D or 2-D array containing multiple variables and observations.\n        Each row of `m` represents a variable, and each column a single\n        observation of all those variables. Also see `rowvar` below.\n    y : array_like, optional\n        An additional set of variables and observations. `y` has the same\n        form as that of `m`.\n    rowvar : int, optional\n        If `rowvar` is non-zero (default), then each row represents a\n        variable, with observations in the columns. Otherwise, the relationship\n        is transposed: each column represents a variable, while the rows\n        contain observations.\n    bias : int, optional\n        Default normalization is by ``(N - 1)``, where ``N`` is the number of\n        observations given (unbiased estimate). If `bias` is 1, then\n        normalization is by ``N``. These values can be overridden by using\n        the keyword ``ddof`` in numpy versions >= 1.5.\n    ddof : int, optional\n        .. versionadded:: 1.5\n        If not ``None`` normalization is by ``(N - ddof)``, where ``N`` is\n        the number of observations; this overrides the value implied by\n        ``bias``. The default value is ``None``.\n    weights : array-like, optional\n        A 1-D array of weights with a length equal to the number of\n        observations.\n    repeat_weights : int, optional\n        The default treatment of weights in the weighted covariance is to first\n        normalize them to unit sum and use the biased weighted covariance\n        equation. If `repeat_weights` is 1 then the weights must represent an\n        integer number of occurrences of each observation and both a biased and\n        unbiased weighted covariance is defined because the total sample size\n        can be determined.\n\n    Returns\n    -------\n    out : ndarray\n        The covariance matrix of the variables.\n\n    See Also\n    --------\n    corrcoef : Normalized covariance matrix\n\n    Examples\n    --------\n    Consider two variables, :math:`x_0` and :math:`x_1`, which\n    correlate perfectly, but in opposite directions:\n\n    >>> x = np.array([[0, 2], [1, 1], [2, 0]]).T\n    >>> x\n    array([[0, 1, 2],\n           [2, 1, 0]])\n\n    Note how :math:`x_0` increases while :math:`x_1` decreases. The covariance\n    matrix shows this clearly:\n\n    >>> np.cov(x)\n    array([[ 1., -1.],\n           [-1.,  1.]])\n\n    Note that element :math:`C_{0,1}`, which shows the correlation between\n    :math:`x_0` and :math:`x_1`, is negative.\n\n    Further, note how `x` and `y` are combined:\n\n    >>> x = [-2.1, -1,  4.3]\n    >>> y = [3,  1.1,  0.12]\n    >>> X = np.vstack((x,y))\n    >>> print np.cov(X)\n    [[ 11.71        -4.286     ]\n     [ -4.286        2.14413333]]\n    >>> print np.cov(x, y)\n    [[ 11.71        -4.286     ]\n     [ -4.286        2.14413333]]\n    >>> print np.cov(x)\n    11.71\n\n    """"""\n    import numpy as np\n    # Check inputs\n    if ddof is not None and ddof != int(ddof):\n        raise ValueError(\n            ""ddof must be integer"")\n\n    X = np.array(m, ndmin=2, dtype=float)\n    if X.size == 0:\n        # handle empty arrays\n        return np.array(m)\n    if X.shape[0] == 1:\n        rowvar = 1\n    if rowvar:\n        axis = 0\n        tup = (slice(None), np.newaxis)\n    else:\n        axis = 1\n        tup = (np.newaxis, slice(None))\n\n    if y is not None:\n        y = np.array(y, copy=False, ndmin=2, dtype=float)\n        X = np.concatenate((X, y), axis)\n\n    if ddof is None:\n        if bias == 0:\n            ddof = 1\n        else:\n            ddof = 0\n\n    if weights is not None:\n        weights = np.array(weights, dtype=float)\n        weights_sum = weights.sum()\n        if weights_sum <= 0:\n            raise ValueError(\n                ""sum of weights is non-positive"")\n        X -= np.average(X, axis=1-axis, weights=weights)[tup]\n\n        if repeat_weights:\n            # each weight represents a number of repetitions of an observation\n            # the total sample size can be determined in this case and we have\n            # both an unbiased and biased weighted covariance\n            fact = weights_sum - ddof\n        else:\n            # normalize weights so they sum to unity\n            weights /= weights_sum\n            # unbiased weighted covariance is not defined if the weights are\n            # not integral frequencies (repeat-type)\n            fact = (1. - np.power(weights, 2).sum())\n    else:\n        weights = 1\n        X -= X.mean(axis=1-axis)[tup]\n        if rowvar:\n            N = X.shape[1]\n        else:\n            N = X.shape[0]\n        fact = float(N - ddof)\n\n    if not rowvar:\n        return (np.dot(weights * X.T, X.conj()) / fact).squeeze()\n    else:\n        return (np.dot(weights * X, X.T.conj()) / fact).squeeze()\n\n\ndef corrcoef(x, y=None, rowvar=1, bias=0, ddof=None, weights=None,\n             repeat_weights=0):\n    """"""\n    Return correlation coefficients.\n\n    Please refer to the documentation for `cov` for more detail.  The\n    relationship between the correlation coefficient matrix, `P`, and the\n    covariance matrix, `C`, is\n\n    .. math:: P_{ij} = \\\\frac{ C_{ij} } { \\\\sqrt{ C_{ii} * C_{jj} } }\n\n    The values of `P` are between -1 and 1, inclusive.\n\n    Parameters\n    ----------\n    x : array_like\n        A 1-D or 2-D array containing multiple variables and observations.\n        Each row of `m` represents a variable, and each column a single\n        observation of all those variables. Also see `rowvar` below.\n    y : array_like, optional\n        An additional set of variables and observations. `y` has the same\n        shape as `m`.\n    rowvar : int, optional\n        If `rowvar` is non-zero (default), then each row represents a\n        variable, with observations in the columns. Otherwise, the relationship\n        is transposed: each column represents a variable, while the rows\n        contain observations.\n    bias : int, optional\n        Default normalization is by ``(N - 1)``, where ``N`` is the number of\n        observations (unbiased estimate). If `bias` is 1, then\n        normalization is by ``N``. These values can be overridden by using\n        the keyword ``ddof`` in numpy versions >= 1.5.\n    ddof : {None, int}, optional\n        .. versionadded:: 1.5\n        If not ``None`` normalization is by ``(N - ddof)``, where ``N`` is\n        the number of observations; this overrides the value implied by\n        ``bias``. The default value is ``None``.\n    weights : array-like, optional\n        A 1-D array of weights with a length equal to the number of\n        observations.\n    repeat_weights : int, optional\n        The default treatment of weights in the weighted covariance is to first\n        normalize them to unit sum and use the biased weighted covariance\n        equation. If `repeat_weights` is 1 then the weights must represent an\n        integer number of occurrences of each observation and both a biased and\n        unbiased weighted covariance is defined because the total sample size\n        can be determined.\n\n    Returns\n    -------\n    out : ndarray\n        The correlation coefficient matrix of the variables.\n\n    See Also\n    --------\n    cov : Covariance matrix\n\n    """"""\n    import numpy as np\n    c = cov(x, y, rowvar, bias, ddof, weights, repeat_weights)\n    if c.size == 0:\n        # handle empty arrays\n        return c\n    try:\n        d = np.diag(c)\n    except ValueError:  # scalar covariance\n        return 1\n    return c / np.sqrt(np.multiply.outer(d, d))\n'"
rootpy/plotting/contrib/quantiles.py,0,"b'""""""\nTaken from example by Zhiyi Liu, zhiyil@fnal.gov\nhere: http://root.cern.ch/phpBB3/viewtopic.php?f=3&t=6865\nand converted into Python\n""""""\nfrom __future__ import absolute_import\n\nimport ROOT\n\nfrom math import sqrt\nfrom array import array\n\nfrom .. import Graph\nfrom ...extern.six.moves import range\n\n__all__ = [\n    \'qqgraph\',\n]\n\n\ndef qqgraph(h1, h2, quantiles=None):\n    """"""\n    Return a Graph of a quantile-quantile (QQ) plot and confidence band\n    """"""\n    if quantiles is None:\n        quantiles = max(min(len(h1), len(h2)) / 2, 1)\n    nq = quantiles\n    # position where to compute the quantiles in [0, 1]\n    xq = array(\'d\', [0.] * nq)\n    # array to contain the quantiles\n    yq1 = array(\'d\', [0.] * nq)\n    # array to contain the quantiles\n    yq2 = array(\'d\', [0.] * nq)\n\n    for i in range(nq):\n        xq[i] = float(i + 1) / nq\n\n    h1.GetQuantiles(nq, yq1, xq)\n    h2.GetQuantiles(nq, yq2, xq)\n\n    xq_plus = array(\'d\', [0.] * nq)\n    xq_minus = array(\'d\', [0.] * nq)\n    yq2_plus = array(\'d\', [0.] * nq)\n    yq2_minus = array(\'d\', [0.] * nq)\n\n    """"""\n    KS_cv: KS critical value\n\n               1.36\n    KS_cv = -----------\n             sqrt( N )\n\n    Where 1.36 is for alpha = 0.05 (confidence level 1-5%=95%, about 2 sigma)\n\n    For 1 sigma (alpha=0.32, CL=68%), the value in the nominator is 0.9561,\n    it is gotten by GetCriticalValue(1, 1 - 0.68).\n\n    Notes\n    -----\n\n    * For 1-sample KS test (data and theoretic), N should be n\n\n    * For 2-sample KS test (2 data set), N should be sqrt(m*n/(m+n))!\n      Here is the case m or n (size of samples) should be effective size\n      for a histogram\n\n    * Critical value here is valid for only for sample size >= 80 (some\n      references say 35) which means, for example, for a unweighted histogram,\n      it must have more than 80 (or 35) entries filled and then confidence\n      band is reliable.\n\n    """"""\n\n    esum1 = effective_sample_size(h1)\n    esum2 = effective_sample_size(h2)\n\n    # one sigma band\n    KS_cv = (critical_value(1, 1 - 0.68) /\n             sqrt((esum1 * esum2) / (esum1 + esum2)))\n\n    for i in range(nq):\n        # upper limit\n        xq_plus[i] = float(xq[i] + KS_cv)\n        # lower limit\n        xq_minus[i] = float(xq[i] - KS_cv)\n\n    h2.GetQuantiles(nq, yq2_plus, xq_plus)\n    h2.GetQuantiles(nq, yq2_minus, xq_minus)\n\n    yq2_err_plus = array(\'d\', [0.] * nq)\n    yq2_err_minus = array(\'d\', [0.] * nq)\n    for i in range(nq):\n        yq2_err_plus[i] = yq2_plus[i] - yq2[i]\n        yq2_err_minus[i] = yq2[i] - yq2_minus[i]\n\n    # forget the last point, so number of points: (nq - 1)\n    gr = Graph(nq - 1)\n    for i in range(nq - 1):\n        gr[i] = (yq1[i], yq2[i])\n        # confidence level band\n        gr.SetPointEYlow(i, yq2_err_minus[i])\n        gr.SetPointEYhigh(i, yq2_err_plus[i])\n\n    return gr\n\n\ndef effective_sample_size(h):\n    """"""\n    Calculate the effective sample size for a histogram\n    the same way as ROOT does.\n    """"""\n    sum = 0\n    ew = 0\n    w = 0\n    for bin in h.bins(overflow=False):\n        sum += bin.value\n        ew = bin.error\n        w += ew * ew\n    esum = sum * sum / w\n    return esum\n\n\ndef critical_value(n, p):\n    """"""\n    This function calculates the critical value given\n    n and p, and confidence level = 1 - p.\n    """"""\n    dn = 1\n    delta = 0.5\n    res = ROOT.TMath.KolmogorovProb(dn * sqrt(n))\n    while res > 1.0001 * p or res < 0.9999 * p:\n        if (res > 1.0001 * p):\n            dn = dn + delta\n        if (res < 0.9999 * p):\n            dn = dn - delta\n        delta = delta / 2.\n        res = ROOT.TMath.KolmogorovProb(dn * sqrt(n))\n    return dn\n'"
rootpy/plotting/style/__init__.py,0,"b'from __future__ import absolute_import\n\nimport ROOT\n\nfrom ... import log; log = log[__name__]\nfrom ... import asrootpy, QROOT\nfrom ...base import Object\nfrom ...extern.six import string_types\n\n__all__ = [\n    \'get_style\',\n    \'set_style\',\n    \'Style\',\n]\n\n\ndef _kwargs_to_name(name, **kwargs):\n    if not kwargs:\n        return name.upper()\n    return \'{0}({1})\'.format(name.upper(), \', \'.join([\n        \'=\'.join(map(str, item))\n            for item in sorted(kwargs.items())]))\n\n\ndef get_style(name, mpl=False, **kwargs):\n    if mpl:\n        try:\n            module = __import__(\n                \'rootpy.plotting.style.{0}.style_mpl\'.format(name.lower()),\n                globals(), locals(), [\'STYLE\'], 0)\n            style_func = getattr(module, \'style_mpl\')\n        except (ImportError, AttributeError):\n            raise ValueError(\n                ""matplotlib style \'{0}\' is not defined"".format(name))\n        style = style_func(**kwargs)\n    else:\n        # is the style already created?\n        for s in ROOT.gROOT.GetListOfStyles():\n            # make search case-insensitive\n            if s.GetName().lower() == name.lower():\n                return asrootpy(s)\n        # if not then attempt to locate it in rootpy\n        try:\n            module = __import__(\n                \'rootpy.plotting.style.{0}.style\'.format(name.lower()),\n                globals(), locals(), [\'style\'], 0)\n            style_func = getattr(module, \'style\')\n        except (ImportError, AttributeError):\n            raise ValueError(\n                ""ROOT style \'{0}\' is not defined"".format(name))\n        name = _kwargs_to_name(name, **kwargs)\n        style = style_func(name, **kwargs)\n    return style\n\n\ndef set_style(style, mpl=False, **kwargs):\n    """"""\n    If mpl is False accept either style name or a TStyle instance.\n    If mpl is True accept either style name or a matplotlib.rcParams-like\n    dictionary\n    """"""\n    if mpl:\n        import matplotlib as mpl\n\n        style_dictionary = {}\n        if isinstance(style, string_types):\n            style_dictionary = get_style(style, mpl=True, **kwargs)\n            log.info(""using matplotlib style \'{0}\'"".format(style))\n        elif isinstance(style, dict):\n            style_dictionary = style\n            log.info(""using user-defined matplotlib style"")\n        else:\n            raise TypeError(""style must be a matplotlib style name or dict"")\n        for k, v in style_dictionary.items():\n            mpl.rcParams[k] = v\n    else:\n        if isinstance(style, string_types):\n            style = get_style(style, **kwargs)\n        log.info(""using ROOT style \'{0}\'"".format(style.GetName()))\n        style.cd()\n\n\nclass Style(Object, QROOT.TStyle):\n    _ROOT = QROOT.TStyle\n\n    def __enter__(self):\n        set_style(self)\n        return self\n\n    def __exit__(self, type, value, traceback):\n        return False\n'"
rootpy/plotting/tests/__init__.py,0,b'from .. import log; log = log[__name__]\n'
rootpy/plotting/tests/test_graph.py,0,"b'from rootpy.plotting import Graph, Graph2D, Hist\nimport tempfile\nfrom random import random\nfrom nose.tools import assert_equal\n\n\ndef test_init():\n    g = Graph(10, name=\'test\')\n    assert_equal(len(g), 10)\n    g2d = Graph2D(10, name=\'test2d\')\n\n\ndef test_init_from_hist():\n    h = Hist(100, -10, 10)\n    h.FillRandom(\'gaus\')\n    g = Graph(h)\n\n\ndef test_init_from_file_1d():\n    with tempfile.NamedTemporaryFile() as f:\n        for i in range(100):\n            f.write(\'{0:.3f},{1:.3f}\\n\'.format(\n                random(), random()).encode(\'utf-8\'))\n        f.flush()\n        g = Graph.from_file(f.name, sep=\',\')\n        assert_equal(len(g), 100)\n\n\ndef test_init_from_file_2d():\n    with tempfile.NamedTemporaryFile() as f:\n        for i in range(100):\n            f.write(\'{0:.3f},{1:.3f},{2:.3f}\\n\'.format(\n                random(), random(), random()).encode(\'utf-8\'))\n        f.flush()\n        g = Graph2D.from_file(f.name, sep=\',\')\n        assert_equal(len(g), 100)\n\n\ndef test_xerr():\n    g = Graph(10)\n    list(g.xerr())\n\n    g = Graph(10, type=\'errors\')\n    list(g.xerr())\n\n    g = Graph(10, type=\'asymm\')\n    list(g.xerr())\n\n\ndef test_static_divide():\n    Graph.divide(Graph(Hist(10, 0, 1).FillRandom(\'gaus\')),\n                 Hist(10, 0, 1).FillRandom(\'gaus\'), \'pois\')\n\n\ndef test_operators():\n    h = Hist(10, -2, 2).FillRandom(\'gaus\')\n    g = Graph(h)\n    g *= 2\n    g /= 2\n    g += 2\n    g -= 2\n    for point in g:\n        assert_equal(point.y.value, h[point.idx_ + 1].value)\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/plotting/tests/test_hist.py,0,"b'from random import gauss, uniform\nfrom rootpy import ROOTVersion, ROOT_VERSION\nfrom rootpy.plotting import Hist, Hist2D, Hist3D, HistStack, Efficiency, Graph\nfrom rootpy.plotting import F2, F3\nfrom rootpy.utils.extras import LengthMismatch\nfrom rootpy.extern.six.moves import range\nfrom nose.tools import (raises, assert_equal, assert_almost_equal,\n                        assert_raises, assert_true, assert_false)\n\n\ndef test_init():\n    # constructor arguments are repetitions of #bins, left bound, right bound.\n    h2d = Hist2D(10, 0, 1, 50, -40, 10, name=\'2d hist\')\n    h3d = Hist3D(3, -1, 4, 10, -1000, -200, 2, 0, 1, name=\'3d hist\')\n\n    # variable-width bins may be created by passing the bin edges directly:\n    h1d_variable = Hist([1, 4, 10, 100])\n    h2d_variable = Hist2D([2, 4, 7, 100, 200], [-100, -50, 0, 10, 20])\n    h3d_variable = Hist3D([1, 3, 10], [20, 50, 100], [-10, -5, 10, 20])\n\n    # variable-width and constant-width bins can be mixed:\n    h2d_mixed = Hist2D([2, 10, 30], 10, 1, 5)\n\n\ndef test_init_from_graph():\n    hist = Hist(10, 0, 1)\n    hist.FillRandom(\'gaus\')\n    graph = Graph(hist)\n    hist2 = Hist(graph)\n    # TODO\n    #assert_almost_equal(list(hist.xedges()), list(hist2.xedges()))\n    #assert_almost_equal(list(hist.y()), list(hist2.y()))\n    #assert_almost_equal(list(hist.yerr()), list(hist2.yerr()))\n\n\n@raises(ValueError)\ndef test_init_edge_order():\n    # bin edges must be in ascending order\n    Hist2D([10, 2, 30], 10, 1, 5)\n\n\n@raises(ValueError)\ndef test_init_edge_repeated():\n    # bin edges must not be repeated\n    Hist([10, 10, 30])\n\n\ndef test_edges():\n    h = Hist([1, 2, 3, 4])\n    assert_equal(list(h.xedges()), [1, 2, 3, 4])\n    assert_equal(list(h.xedges(overflow=True)),\n                 [float(\'-inf\'), 1, 2, 3, 4, float(\'inf\')])\n    assert_equal(h.xedges(0), float(\'-inf\'))\n    assert_equal(h.xedges(-1), float(\'inf\'))\n    assert_equal(h.xedges(5), float(\'inf\'))\n    # wrap around\n    assert_equal(h.xedges(6), float(\'-inf\'))\n    for i in range(1, h.nbins() + 1):\n        assert_equal(h.xedges(i), i)\n\n\ndef test_edgesl():\n    h = Hist([1, 2, 3, 4])\n    assert_equal(list(h.xedgesl()), [1, 2, 3])\n    assert_equal(list(h.xedgesl(overflow=True)),\n                 [float(\'-inf\'), 1, 2, 3, 4])\n    assert_equal(h.xedgesl(0), float(\'-inf\'))\n    assert_equal(h.xedgesl(-1), 4)\n    assert_equal(h.xedgesl(4), 4)\n    # wrap around\n    assert_equal(h.xedgesl(5), float(\'-inf\'))\n    for i in range(1, h.nbins()):\n        assert_equal(h.xedgesl(i), i)\n\n\ndef test_edgesh():\n    h = Hist([1, 2, 3, 4])\n    assert_equal(list(h.xedgesh()), [2, 3, 4])\n    assert_equal(list(h.xedgesh(overflow=True)),\n                 [1, 2, 3, 4, float(\'inf\')])\n    assert_equal(h.xedgesh(0), 1)\n    assert_equal(h.xedgesh(-1), float(\'inf\'))\n    assert_equal(h.xedgesh(4), float(\'inf\'))\n    # wrap around\n    assert_equal(h.xedgesh(5), 1)\n    for i in range(1, h.nbins()):\n        assert_equal(h.xedgesh(i), i + 1)\n\n\ndef test_width():\n    h = Hist([1, 2, 4, 8])\n    assert_equal(list(h.xwidth()), [1, 2, 4])\n    assert_equal(list(h.xwidth(overflow=True)),\n                 [float(\'inf\'), 1, 2, 4, float(\'inf\')])\n\n\ndef test_bounds():\n    h = Hist(10, 0, 1)\n    assert_equal(h.bounds(), (0, 1))\n    h = Hist2D(10, 0, 1, 10, 1, 2)\n    assert_equal(h.bounds(axis=0), (0, 1))\n    assert_equal(h.bounds(axis=1), (1, 2))\n    h = Hist3D(10, 0, 1, 10, 1, 2, 10, 2, 3)\n    assert_equal(h.bounds(axis=0), (0, 1))\n    assert_equal(h.bounds(axis=1), (1, 2))\n    assert_equal(h.bounds(axis=2), (2, 3))\n\n\ndef test_ravel():\n    hist = Hist2D(3, 0, 1, 4, 0, 1)\n    for i, bin in enumerate(hist.bins()):\n        bin.value = i\n        bin.error = i\n    rhist = hist.ravel()\n    assert_equal(list(rhist.y()), list(range(12)))\n    assert_equal(list(rhist.yerrh()), list(range(12)))\n\n\ndef test_uniform():\n    hist = Hist(10, 0, 1)\n    assert_true(hist.uniform())\n    hist = Hist2D(10, 0, 1, [1, 10, 100])\n    assert_false(hist.uniform())\n    assert_true(hist.uniform(axis=0))\n\n\ndef test_stack():\n    stack = HistStack()\n    assert_equal(len(stack), 0)\n    stack.Add(Hist(10, 0, 1, fillstyle=\'solid\', color=\'red\'))\n    stack.Add(Hist(10, 0, 1, fillstyle=\'solid\', color=\'blue\'))\n    stack.Add(Hist(10, 0, 1, fillstyle=\'solid\', color=\'green\'))\n    assert_equal(len(stack), 3)\n    stack2 = stack.Clone()\n    assert_equal(stack2[2].linecolor, \'green\')\n\n    # test stacked=True\n    a = Hist(2, 0, 1)\n    b = Hist(2, 0, 1)\n    a.Fill(0.2)\n    b.Fill(0.2)\n    b.Fill(0.8, 5)\n    stack = HistStack([a, b])\n    assert_equal(stack.min(), 2)\n    assert_equal(stack.max(), 5)\n\n    # test stacked=False\n    a = Hist(2, 0, 20)\n    b = Hist(2, 10, 20)  # binning may be different\n    a.Fill(0.2)\n    b.Fill(15, 5)\n    stack = HistStack([a, b], stacked=False)\n    assert_equal(stack.min(), 0)\n    assert_equal(stack.max(), 5)\n\n\ndef test_indexing():\n    hist = Hist(10, 0, 1)\n    hist.Fill(0.5)\n    assert_equal(hist[6].value, 1)\n    assert_equal(hist[10].value, 0)\n    assert_raises(IndexError, hist.__getitem__, -13)\n    assert_raises(IndexError, hist.__getitem__, 12)\n\n\ndef test_slice_assign():\n    hist = Hist(10, 0, 1)\n    hist[:] = [i for i in range(len(hist))]\n    assert all([a.value == b for a, b in zip(hist, range(len(hist)))])\n    clone = hist.Clone()\n    # reverse bins\n    hist[:] = clone[::-1]\n    assert all([a.value == b.value for a, b in zip(hist, clone[::-1])])\n\n\ndef test_slice_assign_error():\n    hist = Hist(10, 0, 1)\n    hist[:] = [(i, i/2.) for i in range(len(hist))]\n    assert all([a.value == b for a, b in zip(hist, range(len(hist)))])\n    assert all([a.error == b/2. for a, b in zip(hist, range(len(hist)))])\n\n\n@raises(LengthMismatch)\ndef test_slice_assign_bad():\n    hist = Hist(10, 0, 1)\n    hist[:] = range(len(hist) + 1)\n\n\ndef test_overflow_underflow():\n    h1d = Hist(10, 0, 1)\n    h1d.Fill(-1)\n    h1d.Fill(2)\n    assert_equal(h1d.underflow(), 1)\n    assert_equal(h1d.overflow(), 1)\n\n    h2d = Hist2D(10, 0, 1, 10, 0, 1)\n    h2d.Fill(-1, .5)\n    h2d.Fill(2, .5)\n    assert_equal(h2d.underflow()[h2d.axis(1).FindBin(.5)], 1)\n    assert_equal(h2d.overflow()[h2d.axis(1).FindBin(.5)], 1)\n    h2d.Fill(.5, -1)\n    h2d.Fill(.5, 2)\n    assert_equal(h2d.underflow(axis=1)[h2d.axis(0).FindBin(.5)], 1)\n    assert_equal(h2d.overflow(axis=1)[h2d.axis(0).FindBin(.5)], 1)\n\n    h3d = Hist3D(10, 0, 1, 10, 0, 1, 10, 0, 1)\n    h3d.Fill(-1, .5, .5)\n    h3d.Fill(2, .5, .5)\n    assert_equal(h3d.underflow()[h3d.axis(1).FindBin(.5)][h3d.axis(2).FindBin(.5)], 1)\n    assert_equal(h3d.overflow()[h3d.axis(1).FindBin(.5)][h3d.axis(2).FindBin(.5)], 1)\n    h3d.Fill(.5, -1, .5)\n    h3d.Fill(.5, 2, .5)\n    assert_equal(h3d.underflow(axis=1)[h3d.axis(0).FindBin(.5)][h3d.axis(2).FindBin(.5)], 1)\n    assert_equal(h3d.overflow(axis=1)[h3d.axis(0).FindBin(.5)][h3d.axis(2).FindBin(.5)], 1)\n    h3d.Fill(.5, .5, -1)\n    h3d.Fill(.5, .5, 2)\n    assert_equal(h3d.underflow(axis=2)[h3d.axis(0).FindBin(.5)][h3d.axis(1).FindBin(.5)], 1)\n    assert_equal(h3d.overflow(axis=2)[h3d.axis(0).FindBin(.5)][h3d.axis(1).FindBin(.5)], 1)\n\n\ndef test_merge_bins():\n    h1d = Hist(10, 0, 1)\n    h1d.FillRandom(\'gaus\', 1000)\n    h1d_merged = h1d.merge_bins([(0, -1)])\n    assert_equal(h1d_merged.nbins(0), 1)\n\n    h3d = Hist3D(10, 0, 1, 10, 0, 1, 10, 0, 1)\n    h3d.FillRandom(\'gaus\')\n    h3d_merged = h3d.merge_bins([(1, 3), (-4, -2)], axis=1)\n    assert_equal(h3d.GetEntries(), h3d_merged.GetEntries())\n    assert_equal(h3d.GetSumOfWeights(), h3d_merged.GetSumOfWeights())\n    assert_equal(h3d_merged.nbins(1), 6)\n\n    h = Hist(4, 0, 1)\n    h.Fill(-1)\n    h.Fill(2)\n    h.Fill(0.8, 2)\n    h.Fill(0.5, 1)\n\n    # invalid ranges\n    assert_raises(ValueError, h.merge_bins, [(0, 0)])\n    assert_raises(ValueError, h.merge_bins, [(0, 1, 2)])\n    assert_raises(ValueError, h.merge_bins, [(2, 1)])\n    assert_raises(ValueError, h.merge_bins, [(-2, 1)])\n    # overlapping windows\n    assert_raises(ValueError, h.merge_bins, [(0, 1), (1, 2)])\n\n    assert_equal(list(h.y(overflow=True)), [1., 0., 0., 1., 2., 1.])\n    assert_equal(list(h.merge_bins([(1, 2)]).y(overflow=True)), [1., 0., 1., 2., 1.])\n    assert_equal(list(h.merge_bins([(-3, -2)]).y(overflow=True)), [1., 0., 0., 3., 1.] )\n    assert_equal(list(h.merge_bins([(-2, -1)]).y(overflow=True)), [1., 0., 0., 1., 3., 0.])\n    assert_equal(list(h.merge_bins([(0, 1), (-2, -1)]).y(overflow=True)), [0., 1., 0., 1., 3., 0.])\n    assert_equal(list(h.merge_bins([(0, 1)]).merge_bins([(-2, -1)]).y(overflow=True)), [0., 1., 0., 1., 3., 0.])\n    assert_equal(list(h.merge_bins([(1, 2), (3, 4)]).y(overflow=True)), [1., 0., 3., 1.])\n\n\ndef test_rebinning():\n    h1d = Hist(100, 0, 1)\n    h1d.FillRandom(\'gaus\')\n    assert_equal(h1d.rebinned(2).nbins(0), 50)\n    assert_equal(h1d.rebinned((2,)).nbins(0), 50)\n    assert_equal(h1d.rebinned([0, .5, 1]).nbins(0), 2)\n\n    h3d = Hist3D(10, 0, 1, 10, 0, 1, 10, 0, 1)\n    h3d.FillRandom(\'gaus\')\n    assert_equal(h3d.rebinned(2).nbins(0), 5)\n    new = h3d.rebinned((2, 5, 1))\n    assert_equal(new.nbins(0), 5)\n    assert_equal(new.nbins(1), 2)\n    assert_equal(new.nbins(2), 10)\n    new = h3d.rebinned([0, 5, 10], axis=1)\n    assert_equal(new.nbins(1), 2)\n\n\ndef test_quantiles():\n    h3d = Hist3D(10, 0, 1, 10, 0, 1, 10, 0, 1)\n    h3d.FillRandom(\'gaus\')\n    h3d.quantiles(2)\n    h3d.quantiles(2, axis=1)\n    h3d.quantiles([0, .5, 1], axis=2)\n\n    h2d = Hist2D(100, 0, 1, 100, 0, 1)\n    h2d.FillRandom(F2(\'x+y\'))\n    h2d.quantiles(4, axis=0)\n    h2d.quantiles(4, axis=1)\n\n\ndef test_compatibility():\n    a = Hist(10, 0, 1)\n    b = Hist(10, 0, 1)\n    c = Hist(10, 1, 2)\n    d = Hist2D(10, 0, 1, 10, 0, 1)\n\n    assert_true(a.compatible(a))\n    assert_true(a.compatible(b))\n    assert_true(a.compatible(c))\n    assert_false(a.compatible(c, check_edges=True))\n    assert_false(a.compatible(d))\n\ndef test_power():\n    h = Hist2D(10, 0, 1, 10, 0, 1)\n    h.FillRandom(F2(\'x+y\'))\n    p = h.Clone()\n    p /= h.Integral()\n    pow(h, 2)\n    h**2\n    h**p\n    assert_raises(ValueError, pow, h, Hist2D(20, 0, 1, 10, 0, 1))\n    assert_raises(TypeError, pow, h, Hist(10, 0, 1))\n    h**=2\n\n\ndef test_integral():\n    h = Hist(10, 0, 1)\n    h.FillRandom(\'gaus\', 100)\n    h[0].value = 2\n    h[-1].value = 4\n    assert_equal(h.integral(), 100)\n    assert_equal(h.integral(overflow=True), 106)\n    assert_equal(h.integral(xbin1=1, overflow=True), 104)\n    assert_equal(h.integral(xbin2=-2, overflow=True), 102)\n\n\ndef test_integral_error():\n    h = Hist(1, 0, 1)\n    h.FillRandom(\'gaus\')\n    ref_integral, ref_error = h.integral(error=True)\n\n    h1 = Hist(10, 0, 1)\n    h1.FillRandom(\'gaus\')\n    integral, error = h1.integral(error=True)\n    assert_almost_equal(integral, ref_integral)\n    assert_almost_equal(error, ref_error)\n\n    h2 = Hist2D(10, 0, 1, 10, 0, 1)\n    h2.FillRandom(F2(\'x+y\'))\n    integral, error = h2.integral(error=True)\n    assert_almost_equal(integral, ref_integral)\n    assert_almost_equal(error, ref_error)\n\n    h3 = Hist3D(10, 0, 1, 10, 0, 1, 10, 0, 1)\n    h3.FillRandom(F3(\'x+y+z\'))\n    integral, error = h3.integral(error=True)\n    assert_almost_equal(integral, ref_integral)\n    assert_almost_equal(error, ref_error)\n\n\ndef test_poisson_errors():\n    h = Hist(20, -3, 3)\n    h.FillRandom(\'gaus\')\n    g = h.poisson_errors()\n\n\ndef test_overall_efficiency():\n    for stat_op in range(0, 8):\n        Eff = Efficiency(Hist(20, -3, 3), Hist(20, -3, 3))\n        Eff_1bin = Efficiency(Hist(1, -3, 3), Hist(1, -3, 3))\n        Eff.SetStatisticOption(stat_op)\n        Eff_1bin.SetStatisticOption(stat_op)\n\n        for i in range(1000):\n            x = gauss(0, 3.6)\n            w = uniform(0, 1)\n            passed = w > 0.5\n            Eff.Fill(passed, x)\n            Eff_1bin.Fill(passed, x)\n\n        assert_almost_equal(Eff.overall_efficiency(overflow=True)[0],\n                            Eff_1bin.overall_efficiency(overflow=True)[0])\n        assert_almost_equal(Eff.overall_efficiency(overflow=True)[1],\n                            Eff_1bin.overall_efficiency(overflow=True)[1])\n        assert_almost_equal(Eff.overall_efficiency(overflow=True)[2],\n                            Eff_1bin.overall_efficiency(overflow=True)[2])\n\n\ndef test_efficiency():\n    # 1D\n    eff = Efficiency(Hist(10, 0, 1), Hist(10, 0, 1))\n    eff.Fill(False, 0.1)\n    eff.Fill(True, 0.8)\n    assert_equal(len(eff), len(eff.total))\n    if ROOT_VERSION >= ROOTVersion(53417):\n        assert eff.graph\n    assert eff.painted_graph\n    assert_equal(len(list(eff.efficiencies())), 10)\n    assert_equal(len(list(eff.efficiencies(overflow=True))), 12)\n    assert_equal(len(list(eff.errors())), 10)\n    assert_equal(len(list(eff.errors(overflow=True))), 12)\n    # 2D\n    eff = Efficiency(Hist2D(10, 0, 1, 10, 0, 1), Hist2D(10, 0, 1, 10, 0, 1))\n    eff.Fill(False, 0.1)\n    eff.Fill(True, 0.8)\n    assert_equal(len(eff), len(eff.total))\n    if ROOT_VERSION >= ROOTVersion(53417):\n        assert eff.histogram\n    assert eff.painted_histogram\n\n\ndef test_uniform_binned():\n    h = Hist([-5, -4, -1, 2, 5])\n    assert_true(not h.uniform())\n    h.FillRandom(\'gaus\')\n    h_uniform = h.uniform_binned()\n    assert_true(h_uniform.uniform())\n    assert_equal(h_uniform.entries, h.entries)\n    assert_equal(h.integral(), h_uniform.integral())\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/plotting/tests/test_legend.py,0,"b'from ROOT import TH1D\nfrom rootpy.plotting import Hist, Legend\nfrom rootpy.context import invisible_canvas\n\n\ndef test_init():\n\n    with invisible_canvas():\n        l = Legend(2)\n        h = Hist(10, 0, 1)\n        l.AddEntry(h)\n        hr = TH1D(""test"", """", 10, 0, 1)\n        l.AddEntry(hr)\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/plotting/tests/test_plottable.py,0,"b'from rootpy.plotting import Hist\nfrom rootpy import asrootpy\nimport ROOT\nfrom nose.tools import assert_equals, raises\n\n\ndef test_plottable_clone():\n\n    a = Hist(10, 0, 1, linecolor=\'blue\', drawstyle=\'same\')\n\n    b = a.Clone(fillstyle=\'solid\')\n    assert_equals(b.fillstyle, \'solid\')\n    assert_equals(b.linecolor, \'blue\')\n    assert_equals(b.drawstyle, \'same\')\n\n    c = a.Clone(color=\'red\')\n    assert_equals(c.linecolor, \'red\')\n    assert_equals(c.fillcolor, \'red\')\n    assert_equals(c.markercolor, \'red\')\n\n\n@raises(ValueError)\ndef test_ambiguous_color():\n    Hist(10, 0, 1, color=\'red\', fillcolor=\'blue\')\n\n\ndef test_plottable_asrootpy():\n    hist = ROOT.TH1D(""hist"", """", 10, 0, 1)\n    hist.SetLineColor(3)\n    hist = asrootpy(hist)\n    assert_equals(hist.linecolor, 3)\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/plotting/tests/test_profile.py,0,"b'from rootpy.plotting import Profile, Profile2D, Profile3D\nfrom nose.tools import raises\n\n\ndef test_init():\n    # constructor arguments are repetitions of #bins, left bound, right bound.\n    p2d = Profile2D(10, 0, 1, 50, -40, 10, name=\'2d profile\')\n    p3d = Profile3D(3, -1, 4, 10, -1000, -200, 2, 0, 1, name=\'3d profile\')\n\n    # variable-width bins may be created by passing the bin edges directly:\n    p1d_variable = Profile([1, 4, 10, 100])\n    p2d_variable = Profile2D([2, 4, 7, 100, 200], [-100, -50, 0, 10, 20])\n    p3d_variable = Profile3D([1, 3, 10], [20, 50, 100], [-10, -5, 10, 20])\n\n    # variable-width and constant-width bins can be mixed:\n    p2d_mixed = Profile2D([2, 10, 30], 10, 1, 5)\n\ndef test_init_profiled_edges():\n    # specifying the profiled axis bounds is optional\n    p1d_variable = Profile([1, 4, 10, 100], 0, 1)\n    # ROOTBUG: missing constructor:\n    #p2d_variable = Profile2D([2, 4, 7, 100, 200], [-100, -50, 0, 10, 20], 0, 1)\n    #p3d_variable = Profile3D([1, 3, 10], [20, 50, 100], [-10, -5, 10, 20], 0, 1)\n\ndef test_init_option():\n    # specifying profile options is optional\n    p1d_variable = Profile([1, 4, 10, 100], option=\'s\')\n    p2d_variable = Profile2D([2, 4, 7, 100, 200], [-100, -50, 0, 10, 20],\n            option=\'s\')\n    p3d_variable = Profile3D([1, 3, 10], [20, 50, 100], [-10, -5, 10, 20],\n            option=\'s\')\n    p1d_variable = Profile([1, 4, 10, 100], 0, 1, option=\'s\')\n    # ROOTBUG: missing constructor:\n    #p2d_variable = Profile2D([2, 4, 7, 100, 200], [-100, -50, 0, 10, 20], 0, 1,\n    #        option=\'s\')\n    p3d_variable = Profile3D([1, 3, 10], [20, 50, 100], [-10, -5, 10, 20],\n            option=\'s\')\n\n@raises(ValueError)\ndef test_init_edge_order():\n    # bin edges must be in ascending order\n    Profile2D([10, 2, 30], 10, 1, 5)\n\n@raises(ValueError)\ndef test_init_edge_repeated():\n    # bin edges must not be repeated\n    Profile([10, 10, 30])\n\n@raises(ValueError)\ndef test_init_profiled_edge_order():\n    # profiled axis edges must be in ascending order\n    Profile2D([10, 2, 30], 10, 1, 5, 3, 1)\n\n@raises(ValueError)\ndef test_init_profiled_edge_repeated():\n    # bin edges must not be repeated\n    Profile([1, 10, 30], 1, 1)\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/plotting/tests/test_root2matplotlib.py,3,"b'from rootpy.plotting import Hist, Hist2D, HistStack, Graph\nfrom nose.plugins.skip import SkipTest\nfrom nose.tools import with_setup\n\n\ndef setup_func():\n    try:\n        import matplotlib\n    except ImportError:\n        raise SkipTest(""matplotlib is not importable"")\n    matplotlib.use(\'Agg\')\n    from matplotlib import pyplot\n    pyplot.ioff()\n\n\n@with_setup(setup_func)\ndef test_errorbar():\n    from rootpy.plotting import root2matplotlib as rplt\n    h = Hist(100, -5, 5)\n    h.FillRandom(\'gaus\')\n    g = Graph(h)\n    rplt.errorbar(g)\n    rplt.errorbar(h)\n\n\n@with_setup(setup_func)\ndef test_bar():\n    from rootpy.plotting import root2matplotlib as rplt\n    h = Hist(100, -5, 5)\n    h.FillRandom(\'gaus\')\n    rplt.bar(h)\n\n    # stack\n    h1 = h.Clone()\n    stack = HistStack([h, h1])\n    rplt.bar(stack)\n    rplt.bar([h, h1], stacked=True)\n    rplt.bar([h, h1], stacked=False)\n    rplt.bar([h, h1], stacked=False, reverse=True)\n\n\n@with_setup(setup_func)\ndef test_hist():\n    from rootpy.plotting import root2matplotlib as rplt\n    h = Hist(100, -5, 5)\n    h.FillRandom(\'gaus\')\n    rplt.hist(h)\n\n    # stack\n    h1 = h.Clone()\n    stack = HistStack([h, h1])\n    rplt.hist(stack)\n    rplt.hist([h, h1])\n\n\n@with_setup(setup_func)\ndef test_hist2d():\n    from rootpy.plotting import root2matplotlib as rplt\n    from matplotlib import pyplot\n    import numpy as np\n    if not hasattr(pyplot, \'hist2d\'):\n        raise SkipTest(""matplotlib is too old"")\n    a = Hist2D(100, -3, 3, 100, 0, 6)\n    a.fill_array(np.random.multivariate_normal(\n        mean=(0, 3),\n        cov=[[1, .5], [.5, 1]],\n        size=(1000,)))\n    rplt.hist2d(a)\n\n\n@with_setup(setup_func)\ndef test_imshow():\n    from rootpy.plotting import root2matplotlib as rplt\n    import numpy as np\n    a = Hist2D(100, -3, 3, 100, 0, 6)\n    a.fill_array(np.random.multivariate_normal(\n        mean=(0, 3),\n        cov=[[1, .5], [.5, 1]],\n        size=(1000,)))\n    rplt.imshow(a)\n\n\n@with_setup(setup_func)\ndef test_contour():\n    from rootpy.plotting import root2matplotlib as rplt\n    import numpy as np\n    a = Hist2D(100, -3, 3, 100, 0, 6)\n    a.fill_array(np.random.multivariate_normal(\n        mean=(0, 3),\n        cov=[[1, .5], [.5, 1]],\n        size=(1000,)))\n    rplt.contour(a)\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/plotting/tests/test_utils.py,0,"b'from rootpy.plotting.utils import _limits_helper\nfrom nose.tools import assert_equal, assert_raises\n\n\ndef test_limits():\n    assert_equal(_limits_helper(0, 1, 0, 0), (0, 1))\n    assert_equal(_limits_helper(1, 1, 0, 0, snap=True), (0, 1))\n    assert_equal(_limits_helper(-2, -1, 0, 0, snap=True), (-2, 0))\n    assert_equal(_limits_helper(-1, 1, .1, .1, snap=True), (-1.25, 1.25))\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/stats/histfactory/__init__.py,0,"b'from __future__ import absolute_import\n\nfrom .. import log; log = log[__name__]\nfrom ... import ROOT_VERSION, ROOTVersion\n\nMIN_ROOT_VERSION = ROOTVersion(53404)\n\nif ROOT_VERSION >= MIN_ROOT_VERSION:\n    from .histfactory import (Constraint,\n                              Data,\n                              Sample,\n                              HistoSys,\n                              HistoFactor,\n                              NormFactor,\n                              OverallSys,\n                              ShapeFactor,\n                              ShapeSys,\n                              Channel,\n                              Measurement)\n\n    from .utils import (make_channel,\n                        make_measurement,\n                        make_workspace,\n                        measurements_from_xml,\n                        write_measurement,\n                        patch_xml,\n                        split_norm_shape)\n\n    __all__ = [\n        \'Constraint\',\n        \'Data\',\n        \'Sample\',\n        \'HistoSys\',\n        \'HistoFactor\',\n        \'NormFactor\',\n        \'OverallSys\',\n        \'ShapeFactor\',\n        \'ShapeSys\',\n        \'Channel\',\n        \'Measurement\',\n        \'make_channel\',\n        \'make_measurement\',\n        \'make_workspace\',\n        \'measurements_from_xml\',\n        \'write_measurement\',\n        \'patch_xml\',\n        \'split_norm_shape\',\n    ]\n\n    from ... import stl\n\n    # generate required dictionaries\n    stl.vector(\'RooStats::HistFactory::HistoSys\',\n               headers=\'<vector>;<RooStats/HistFactory/Systematics.h>\')\n    stl.vector(\'RooStats::HistFactory::HistoFactor\',\n               headers=\'<vector>;<RooStats/HistFactory/Systematics.h>\')\n    stl.vector(\'RooStats::HistFactory::NormFactor\',\n               headers=\'<vector>;<RooStats/HistFactory/Systematics.h>\')\n    stl.vector(\'RooStats::HistFactory::OverallSys\',\n               headers=\'<vector>;<RooStats/HistFactory/Systematics.h>\')\n    stl.vector(\'RooStats::HistFactory::ShapeFactor\',\n               headers=\'<vector>;<RooStats/HistFactory/Systematics.h>\')\n    stl.vector(\'RooStats::HistFactory::ShapeSys\',\n               headers=\'<vector>;<RooStats/HistFactory/Systematics.h>\')\n    stl.vector(\'RooStats::HistFactory::Sample\')\n    stl.vector(\'RooStats::HistFactory::Data\')\n    stl.vector(\'RooStats::HistFactory::Channel\')\n    stl.vector(\'RooStats::HistFactory::Measurement\')\n\nelse:\n    import warnings\n    warnings.warn(\n        ""histfactory requires ROOT {0} but you are using {1}"".format(\n            MIN_ROOT_VERSION, ROOT_VERSION))\n    __all__ = []\n'"
rootpy/stats/histfactory/histfactory.py,0,"b'from __future__ import absolute_import\n\nfrom math import sqrt\n\nimport ROOT\n\nfrom . import log; log = log[__name__]\nfrom . import MIN_ROOT_VERSION\nfrom ...extern.six import string_types\nfrom ...memory.keepalive import keepalive\nfrom ...base import NamedObject\nfrom ... import asrootpy, QROOT, ROOT_VERSION, ROOTError, IN_NOSETESTS\n\nif ROOT_VERSION < MIN_ROOT_VERSION:\n    raise NotImplementedError(\n        ""histfactory requires ROOT {0} but you are using {1}"".format(\n            MIN_ROOT_VERSION, ROOT_VERSION))\n\ntry:\n    HistFactory = QROOT.RooStats.HistFactory\nexcept ROOTError:\n    if IN_NOSETESTS:\n        from nose.plugins.skip import SkipTest\n        raise SkipTest(""ROOT is not compiled with RooStats enabled"")\n    raise\nConstraint = HistFactory.Constraint\n\n__all__ = [\n    \'Constraint\',\n    \'Data\',\n    \'Sample\',\n    \'HistoSys\',\n    \'HistoFactor\',\n    \'NormFactor\',\n    \'OverallSys\',\n    \'ShapeFactor\',\n    \'ShapeSys\',\n    \'Channel\',\n    \'Measurement\',\n]\n\n\nclass _Named(object):\n\n    @property\n    def name(self):\n        return self.GetName()\n\n    @name.setter\n    def name(self, n):\n        self.SetName(n)\n\n    def __str__(self):\n        return self.__repr__()\n\n    def __repr__(self):\n        return ""{0}(\'{1}\')"".format(\n            self.__class__.__name__, self.GetName())\n\n\nclass _HistNamePathFile(object):\n\n    @property\n    def hist_name(self):\n        return self.GetHistoName()\n\n    @hist_name.setter\n    def hist_name(self, name):\n        self.SetHistoName(name)\n\n    @property\n    def hist_path(self):\n        return self.GetHistoPath()\n\n    @hist_path.setter\n    def hist_path(self, path):\n        self.SetHistoPath(path)\n\n    @property\n    def hist_file(self):\n        return self.GetInputFile()\n\n    @hist_file.setter\n    def hist_file(self, infile):\n        self.SetInputFile(infile)\n\n\nclass _SampleBase(_Named, _HistNamePathFile):\n\n    def SetHisto(self, hist):\n        super(_SampleBase, self).SetHisto(hist)\n        self.SetHistoName(hist.name)\n        keepalive(self, hist)\n\n    def GetHisto(self):\n        hist = super(_SampleBase, self).GetHisto()\n        # NULL pointer check\n        if hist == None:\n            return None\n        return asrootpy(hist)\n\n    @property\n    def hist(self):\n        return self.GetHisto()\n\n    @hist.setter\n    def hist(self, h):\n        self.SetHisto(h)\n\n    def __add__(self, other):\n        if self.name != other.name:\n            raise ValueError(""attempting to add samples with different names"")\n        hist1 = self.GetHisto()\n        hist2 = other.GetHisto()\n        sample = self.__class__(self.name)\n        if hist1 is not None and hist2 is not None:\n            hist3 = hist1 + hist2\n            hist3.name = \'{0}_plus_{1}\'.format(hist1.name, hist2.name)\n            sample.SetHisto(hist3)\n        return sample\n\n\nclass Data(_SampleBase, HistFactory.Data):\n    _ROOT = HistFactory.Data\n\n    def __init__(self, name, hist=None):\n        # require a name\n        super(Data, self).__init__()\n        self.name = name\n        if hist is not None:\n            self.SetHisto(hist)\n\n    def total(self, xbin1=1, xbin2=-2):\n        """"""\n        Return the total yield and its associated statistical uncertainty.\n        """"""\n        return self.hist.integral(xbin1=xbin1, xbin2=xbin2, error=True)\n\n    def Clone(self):\n        clone = Data(self.name)\n        hist = self.hist\n        if hist is not None:\n            clone.hist = hist.Clone(shallow=True)\n        return clone\n\n\nclass Sample(_SampleBase, HistFactory.Sample):\n    _ROOT = HistFactory.Sample\n\n    def __init__(self, name, hist=None):\n        # require a sample name\n        super(Sample, self).__init__(name)\n        if hist is not None:\n            self.SetHisto(hist)\n\n    def __add__(self, other):\n        if self.GetHistoFactorList() or other.GetHistoFactorList():\n            raise NotImplementedError(\n                ""Samples cannot be summed if ""\n                ""they contain HistoFactors"")\n\n        if self.GetShapeFactorList() or other.GetShapeFactorList():\n            raise NotImplementedError(\n                ""Samples cannot be summed if ""\n                ""they contain ShapeFactors"")\n\n        if self.GetShapeSysList() or other.GetShapeSysList():\n            raise NotImplementedError(\n                ""Samples cannot be summed if ""\n                ""they contain ShapeSys"")\n\n        if self.GetNormalizeByTheory() != other.GetNormalizeByTheory():\n            raise ValueError(\n                ""attempting to sum samples with ""\n                ""inconsistent NormalizeByTheory"")\n\n        sample = super(Sample, self).__add__(other)\n        sample.SetNormalizeByTheory(self.GetNormalizeByTheory())\n\n        # sum the histosys\n        syslist1 = self.GetHistoSysList()\n        syslist2 = other.GetHistoSysList()\n        if len(syslist1) != len(syslist2):\n            raise ValueError(\n                ""attempting to sum Samples with HistoSys lists of ""\n                ""differing lengths"")\n        for sys1, sys2 in zip(syslist1, syslist2):\n            sample.AddHistoSys(sys1 + sys2)\n\n        # include the overallsys\n        overall1 = self.GetOverallSysList()\n        overall2 = other.GetOverallSysList()\n        if len(overall1) != len(overall2):\n            raise ValueError(\n                ""attempting to sum Samples with OverallSys lists of ""\n                ""differing lengths"")\n        for o1, o2 in zip(overall1, overall2):\n            if o1.name != o2.name:\n                raise ValueError(\n                    ""attempting to sum Samples containing OverallSys ""\n                    ""with differing names: {0}, {1}"".format(\n                        o1.name, o2.name))\n            # TODO check equality of value, low and high\n            sample.AddOverallSys(o1)\n\n        # include the normfactors\n        norms1 = self.GetNormFactorList()\n        norms2 = other.GetNormFactorList()\n        if len(norms1) != len(norms2):\n            raise ValueError(\n                ""attempting to sum Samples with NormFactor lists of ""\n                ""differing lengths"")\n        for norm1, norm2 in zip(norms1, norms2):\n            if norm1.name != norm2.name:\n                raise ValueError(\n                    ""attempting to sum Samples containing NormFactors ""\n                    ""with differing names: {0}, {1}"".format(\n                        norm1.name, norm2.name))\n            # TODO check equality of value, low and high\n            sample.AddNormFactor(norm1)\n        return sample\n\n    def __radd__(self, other):\n        # support sum([list of Samples])\n        if other == 0:\n            return self\n        raise TypeError(\n            ""unsupported operand type(s) for +: \'{0}\' and \'{1}\'"".format(\n                other.__class__.__name__, self.__class__.__name__))\n\n    def __mul__(self, scale):\n        clone = self.Clone()\n        clone *= scale\n        return clone\n\n    def __imul__(self, scale):\n        hist = self.hist\n        if hist is not None:\n            hist *= scale\n        for hsys in self.histo_sys:\n            low = hsys.low\n            high = hsys.high\n            if low is not None:\n                low *= scale\n            if high is not None:\n                high *= scale\n        return self\n\n    def sys_names(self):\n        """"""\n        Return a list of unique systematic names from OverallSys and HistoSys\n        """"""\n        names = {}\n        for osys in self.overall_sys:\n            names[osys.name] = None\n        for hsys in self.histo_sys:\n            names[hsys.name] = None\n        return names.keys()\n\n    def iter_sys(self):\n        """"""\n        Iterate over sys_name, overall_sys, histo_sys.\n        overall_sys or histo_sys may be None for any given sys_name.\n        """"""\n        names = self.sys_names()\n        for name in names:\n            osys = self.GetOverallSys(name)\n            hsys = self.GetHistoSys(name)\n            yield name, osys, hsys\n\n    def sys_hist(self, name=None):\n        """"""\n        Return the effective low and high histogram for a given systematic.\n        If this sample does not contain the named systematic then return\n        the nominal histogram for both low and high variations.\n        """"""\n        if name is None:\n            low = self.hist.Clone(shallow=True)\n            high = self.hist.Clone(shallow=True)\n            return low, high\n        osys = self.GetOverallSys(name)\n        hsys = self.GetHistoSys(name)\n        if osys is None:\n            osys_high, osys_low = 1., 1.\n        else:\n            osys_high, osys_low = osys.high, osys.low\n        if hsys is None:\n            hsys_high = self.hist.Clone(shallow=True)\n            hsys_low = self.hist.Clone(shallow=True)\n        else:\n            hsys_high = hsys.high.Clone(shallow=True)\n            hsys_low = hsys.low.Clone(shallow=True)\n        return hsys_low * osys_low, hsys_high * osys_high\n\n    def has_sys(self, name):\n        return (self.GetOverallSys(name) is not None or\n                self.GetHistoSys(name) is not None)\n\n    def total(self, xbin1=1, xbin2=-2):\n        """"""\n        Return the total yield and its associated statistical and\n        systematic uncertainties.\n        """"""\n        integral, stat_error = self.hist.integral(\n            xbin1=xbin1, xbin2=xbin2, error=True)\n        # sum systematics in quadrature\n        ups = [0]\n        dns = [0]\n        for sys_name in self.sys_names():\n            sys_low, sys_high = self.sys_hist(sys_name)\n            up = sys_high.integral(xbin1=xbin1, xbin2=xbin2) - integral\n            dn = sys_low.integral(xbin1=xbin1, xbin2=xbin2) - integral\n            if up > 0:\n                ups.append(up**2)\n            else:\n                dns.append(up**2)\n            if dn > 0:\n                ups.append(dn**2)\n            else:\n                dns.append(dn**2)\n        syst_error = (sqrt(sum(ups)), sqrt(sum(dns)))\n        return integral, stat_error, syst_error\n\n    ###########################\n    # HistoSys\n    ###########################\n    def AddHistoSys(self, *args):\n        super(Sample, self).AddHistoSys(*args)\n        if len(args) == 1:\n            # args is a HistoSys\n            keepalive(self, args[0])\n\n    def RemoveHistoSys(self, name):\n        histosys_vect = super(Sample, self).GetHistoSysList()\n        ivect = histosys_vect.begin()\n        for histosys in histosys_vect:\n            if histosys.GetName() == name:\n                histosys_vect.erase(ivect)\n                break\n            ivect.__preinc__()\n\n    def GetHistoSys(self, name):\n        histosys_vect = super(Sample, self).GetHistoSysList()\n        for histosys in histosys_vect:\n            if histosys.GetName() == name:\n                return asrootpy(histosys)\n        return None\n\n    def GetHistoSysList(self):\n        return [asrootpy(syst) for syst in\n                super(Sample, self).GetHistoSysList()]\n\n    @property\n    def histo_sys(self):\n        return self.GetHistoSysList()\n\n    ###########################\n    # HistoFactor\n    ###########################\n    def AddHistoFactor(self, *args):\n        super(Sample, self).AddHistoFactor(*args)\n        if len(args) == 1:\n            # args is a HistoFactor\n            keepalive(self, args[0])\n\n    def RemoveHistoFactor(self, name):\n        histofactor_vect = super(Sample, self).GetHistoFactorList()\n        ivect = histosys_factor.begin()\n        for histofactor in histofactor_vect:\n            if histofactor.GetName() == name:\n                histofactor_vect.erase(ivect)\n                break\n            ivect.__preinc__()\n\n    def GetHistoFactor(self, name):\n        histofactor_vect = super(Sample, self).GetHistoFactorList()\n        for histofactor in histofactor_vect:\n            if histofactor.GetName() == name:\n                return asrootpy(histofactor)\n        return None\n\n    def GetHistoFactorList(self):\n        return [asrootpy(syst) for syst in\n                super(Sample, self).GetHistoFactorList()]\n\n    @property\n    def histo_factors(self):\n        return self.GetHistoFactorList()\n\n    ###########################\n    # NormFactor\n    ###########################\n    def AddNormFactor(self, *args):\n        super(Sample, self).AddNormFactor(*args)\n        if len(args) == 1:\n            # args is a NormFactor\n            keepalive(self, args[0])\n\n    def RemoveNormFactor(self, name):\n        normfactor_vect = super(Sample, self).GetNormFactorList()\n        ivect = normfactor_vect.begin()\n        for normfactor in normfactor_vect:\n            if normfactor.GetName() == name:\n                normfactor_vect.erase(ivect)\n                break\n            ivect.__preinc__()\n\n    def GetNormFactor(self, name):\n        normfactor_vect = super(Sample, self).GetNormFactorList()\n        for normfactor in normfactor_vect:\n            if normfactor.GetName() == name:\n                return asrootpy(normfactor)\n        return None\n\n    def GetNormFactorList(self):\n        return [asrootpy(norm) for norm in\n                super(Sample, self).GetNormFactorList()]\n\n    @property\n    def norm_factors(self):\n        return self.GetNormFactorList()\n\n    ###########################\n    # OverallSys\n    ###########################\n    def AddOverallSys(self, *args):\n        super(Sample, self).AddOverallSys(*args)\n        if len(args) == 1:\n            # args is a OverallSys\n            keepalive(self, args[0])\n\n    def RemoveOverallSys(self, name):\n        overallsys_vect = super(Sample, self).GetOverallSysList()\n        ivect = overallsys_vect.begin()\n        for overallsys in overallsys_vect:\n            if overallsys.GetName() == name:\n                overallsys_vect.erase(ivect)\n                break\n            ivect.__preinc__()\n\n    def GetOverallSys(self, name):\n        overallsys_vect = super(Sample, self).GetOverallSysList()\n        for overallsys in overallsys_vect:\n            if overallsys.GetName() == name:\n                return asrootpy(overallsys)\n        return None\n\n    def GetOverallSysList(self):\n        return [asrootpy(syst) for syst in\n                super(Sample, self).GetOverallSysList()]\n\n    @property\n    def overall_sys(self):\n        return self.GetOverallSysList()\n\n    ###########################\n    # ShapeFactor\n    ###########################\n    def AddShapeFactor(self, shapefactor):\n        super(Sample, self).AddShapeFactor(shapefactor)\n        if isinstance(shapefactor, ROOT.RooStats.HistFactory.ShapeFactor):\n            keepalive(self, shapefactor)\n\n    def RemoveShapeFactor(self, name):\n        shapefactor_vect = super(Sample, self).GetShapeFactorList()\n        ivect = shapefactor_vect.begin()\n        for shapefactor in shapefactor_vect:\n            if shapefactor.GetName() == name:\n                shapefactor_vect.erase(ivect)\n                break\n            ivect.__preinc__()\n\n    def GetShapeFactor(self, name):\n        shapefactor_vect = super(Sample, self).GetShapeFactorList()\n        for shapefactor in shapefactor_vect:\n            if shapefactor.GetName() == name:\n                return asrootpy(shapefactor)\n        return None\n\n    def GetShapeFactorList(self):\n        return [asrootpy(sf) for sf in\n                super(Sample, self).GetShapeFactorList()]\n\n    @property\n    def shape_factors(self):\n        return self.GetShapeFactorList()\n\n    ###########################\n    # ShapeSys\n    ###########################\n    def AddShapeSys(self, *args):\n        super(Sample, self).AddShapeSys(*args)\n        if len(args) == 1:\n            # args is a ShapeSys\n            keepalive(self, args[0])\n\n    def RemoveShapeSys(self, name):\n        shapesys_vect = super(Sample, self).GetShapeSysList()\n        ivect = shapesys_vect.begin()\n        for shapesys in shapesys_vect:\n            if shapesys.GetName() == name:\n                shapesys_vect.erase(ivect)\n                break\n            ivect.__preinc__()\n\n    def GetShapeSys(self, name):\n        shapesys_vect = super(Sample, self).GetShapeSysList()\n        for shapesys in shapesys_vect:\n            if shapesys.GetName() == name:\n                return asrootpy(shapesys)\n        return None\n\n    def GetShapeSysList(self):\n        return [asrootpy(ss) for ss in\n                super(Sample, self).GetShapeSysList()]\n\n    @property\n    def shape_sys(self):\n        return self.GetShapeSysList()\n\n    def Clone(self):\n        clone = self.__class__(self.name)\n        hist = self.hist\n        if hist is not None:\n            clone.hist = hist.Clone(shallow=True)\n        # HistoSys\n        for hsys in self.histo_sys:\n            clone.AddHistoSys(hsys.Clone())\n        # HistoFactor\n        for hfact in self.histo_factors:\n            clone.AddHistoFactor(hfact.Clone())\n        # NormFactor\n        for norm in self.norm_factors:\n            clone.AddNormFactor(norm.Clone())\n        # OverallSys\n        for osys in self.overall_sys:\n            clone.AddOverallSys(osys.Clone())\n        # ShapeFactor\n        for sfact in self.shape_factors:\n            clone.AddShapeFactor(sfact.Clone())\n        # ShapeSys\n        for ssys in self.shape_sys:\n            clone.AddShapeSys(ssys.Clone())\n        return clone\n\n\nclass _HistoSysBase(object):\n\n    def SetHistoHigh(self, hist):\n        super(_HistoSysBase, self).SetHistoHigh(hist)\n        self.SetHistoNameHigh(hist.name)\n        keepalive(self, hist)\n\n    def SetHistoLow(self, hist):\n        super(_HistoSysBase, self).SetHistoLow(hist)\n        self.SetHistoNameLow(hist.name)\n        keepalive(self, hist)\n\n    def GetHistoHigh(self):\n        hist = super(_HistoSysBase, self).GetHistoHigh()\n        # NULL pointer check\n        if hist == None:\n            return None\n        return asrootpy(hist)\n\n    def GetHistoLow(self):\n        hist = super(_HistoSysBase, self).GetHistoLow()\n        # NULL pointer check\n        if hist == None:\n            return None\n        return asrootpy(hist)\n\n    @property\n    def low(self):\n        return self.GetHistoLow()\n\n    @low.setter\n    def low(self, h):\n        self.SetHistoLow(h)\n\n    @property\n    def high(self):\n        return self.GetHistoHigh()\n\n    @high.setter\n    def high(self, h):\n        self.SetHistoHigh(h)\n\n    @property\n    def low_name(self):\n        return self.GetHistoNameLow()\n\n    @low_name.setter\n    def low_name(self, name):\n        self.SetHistoNameLow(name)\n\n    @property\n    def high_name(self):\n        return self.GetHistoNameHigh()\n\n    @high_name.setter\n    def high_name(self, name):\n        self.SetHistoNameHigh(name)\n\n    @property\n    def low_path(self):\n        return self.GetHistoPathLow()\n\n    @low_path.setter\n    def low_path(self, path):\n        self.SetHistoPathLow(path)\n\n    @property\n    def high_path(self):\n        return self.GetHistoPathHigh()\n\n    @high_path.setter\n    def high_path(self, path):\n        self.SetHistoPathHigh(path)\n\n    @property\n    def low_file(self):\n        return self.GetInputFileLow()\n\n    @low_file.setter\n    def low_file(self, infile):\n        self.SetInputFileLow(infile)\n\n    @property\n    def high_file(self):\n        return self.GetInputFileHigh()\n\n    @high_file.setter\n    def high_file(self, infile):\n        self.SetInputFileHigh(infile)\n\n    def Clone(self):\n        clone = self.__class__(self.name)\n        low = self.low\n        high = self.high\n        if low is not None:\n            clone.low = low.Clone(shallow=True)\n        if high is not None:\n            clone.high = high.Clone(shallow=True)\n        clone.low_name = self.low_name\n        clone.high_name = self.high_name\n        clone.low_path = self.low_path\n        clone.high_path = self.high_path\n        clone.low_file = self.low_file\n        clone.high_file = self.high_file\n        return clone\n\n\nclass HistoSys(_Named, _HistoSysBase, HistFactory.HistoSys):\n    _ROOT = HistFactory.HistoSys\n\n    def __init__(self, name, low=None, high=None):\n        # require a name\n        super(HistoSys, self).__init__(name)\n        if low is not None:\n            self.low = low\n        if high is not None:\n            self.high = high\n\n    def __add__(self, other):\n        if self.name != other.name:\n            raise ValueError(""attempting to add HistoSys with different names"")\n        histosys = HistoSys(self.name)\n        low = self.low + other.low\n        low.name = \'{0}_plus_{1}\'.format(self.low.name, other.low.name)\n        histosys.low = low\n        high = self.high + other.high\n        high.name = \'{0}_plus_{1}\'.format(self.high.name, other.high.name)\n        histosys.high = high\n        return histosys\n\n\nclass HistoFactor(_Named, _HistoSysBase,\n                  HistFactory.HistoFactor):\n    _ROOT = HistFactory.HistoFactor\n\n    def __init__(self, name, low=None, high=None):\n        # require a name\n        super(HistoFactor, self).__init__(name)\n        if low is not None:\n            self.low = low\n        if high is not None:\n            self.high = high\n\n    def __add__(self, other):\n        raise NotImplementedError(""HistoFactors cannot be summed"")\n\n\nclass NormFactor(_Named, HistFactory.NormFactor):\n    _ROOT = HistFactory.NormFactor\n\n    def __init__(self, name, value=None, low=None, high=None, const=None):\n        super(NormFactor, self).__init__()\n        self.name = name\n        if value is not None:\n            self.value = value\n        if low is not None:\n            self.low = low\n        if high is not None:\n            self.high = high\n        if const is not None:\n            self.const = const\n\n    @property\n    def const(self):\n        return self.GetConst()\n\n    @const.setter\n    def const(self, value):\n        self.SetConst(value)\n\n    @property\n    def value(self):\n        return self.GetVal()\n\n    @value.setter\n    def value(self, value):\n        self.SetVal(value)\n\n    @property\n    def low(self):\n        return self.GetLow()\n\n    @low.setter\n    def low(self, value):\n        self.SetLow(value)\n\n    @property\n    def high(self):\n        return self.GetHigh()\n\n    @high.setter\n    def high(self, value):\n        self.SetHigh(value)\n\n    def Clone(self):\n        return NormFactor(self.name,\n            value=self.value,\n            low=self.low,\n            high=self.high,\n            const=self.const)\n\n\nclass OverallSys(_Named, HistFactory.OverallSys):\n    _ROOT = HistFactory.OverallSys\n\n    def __init__(self, name, low=None, high=None):\n        # require a name\n        super(OverallSys, self).__init__()\n        self.name = name\n        if low is not None:\n            self.low = low\n        if high is not None:\n            self.high = high\n\n    @property\n    def low(self):\n        return self.GetLow()\n\n    @low.setter\n    def low(self, value):\n        self.SetLow(value)\n\n    @property\n    def high(self):\n        return self.GetHigh()\n\n    @high.setter\n    def high(self, value):\n        self.SetHigh(value)\n\n    def Clone(self):\n        return OverallSys(self.name, low=self.low, high=self.high)\n\n\nclass ShapeFactor(_Named, HistFactory.ShapeFactor):\n    _ROOT = HistFactory.ShapeFactor\n\n    def __init__(self, name):\n        # require a name\n        super(ShapeFactor, self).__init__()\n        self.name = name\n\n    def Clone(self):\n        return ShapeFactor(self.name)\n\n\nclass ShapeSys(_Named, _HistNamePathFile, HistFactory.ShapeSys):\n    _ROOT = HistFactory.ShapeSys\n\n    def __init__(self, name):\n        # require a name\n        super(ShapeSys, self).__init__()\n        self.name = name\n        # ConstraintType not initialized correctly on C++ side\n        # ROOT.RooStats.HistFactory.Constraint.Gaussian\n        super(ShapeSys, self).SetConstraintType(Constraint.Gaussian)\n\n    def SetConstraintType(self, value):\n        _value = value.lower() if isinstance(value, string_types) else value\n        if _value in (Constraint.Gaussian, \'gauss\', \'gaussian\'):\n            super(ShapeSys, self).SetConstraintType(Constraint.Gaussian)\n        elif _value in (Constraint.Poisson, \'pois\', \'poisson\'):\n            super(ShapeSys, self).SetConstraintType(Constraint.Poisson)\n        else:\n            raise ValueError(\n                ""\'{0}\' is not a valid constraint"".format(value))\n\n    @property\n    def constraint(self):\n        return super(ShapeSys, self).GetConstraintType()\n\n    @constraint.setter\n    def constraint(self, value):\n        self.SetConstraintType(value)\n\n    def GetErrorHist(self):\n        hist = super(ShapeSys, self).GetErrorHist()\n        # NULL pointer check\n        if hist == None:\n            return None\n        return asrootpy(hist)\n\n    def SetErrorHist(self, hist):\n        super(ShapeSys, self).SetErrorHist(hist)\n        self.SetHistoName(hist.name)\n        keepalive(self, hist)\n\n    @property\n    def hist(self):\n        self.GetErrorHist()\n\n    @hist.setter\n    def hist(self, h):\n        self.SetErrorHist(h)\n\n    def Clone(self):\n        clone = ShapeSys(self.name)\n        hist = self.hist\n        if hist is not None:\n            clone.hist = hist.Clone(shallow=True)\n        return clone\n\n\nclass Channel(_Named, HistFactory.Channel):\n    _ROOT = HistFactory.Channel\n\n    def __init__(self, name, samples=None, data=None, inputfile=""""):\n        # require a name\n        super(Channel, self).__init__(name, inputfile)\n        if samples is not None:\n            for sample in samples:\n                self.AddSample(sample)\n        if data is not None:\n            self.SetData(data)\n\n    def __add__(self, other):\n        channel = Channel(\'{0}_plus_{1}\'.format(self.name, other.name))\n        channel.SetData(self.data + other.data)\n        samples1 = self.samples\n        samples2 = other.samples\n        if len(samples1) != len(samples2):\n            raise ValueError(\n                ""attempting to add Channels containing differing numbers of ""\n                ""Samples"")\n        for s1, s2 in zip(samples1, samples2):\n            # samples must be compatible\n            channel.AddSample(s1 + s2)\n        channel.SetStatErrorConfig(self.GetStatErrorConfig())\n        return channel\n\n    def __radd__(self, other):\n        # support sum([list of Channels])\n        if other == 0:\n            return self\n        raise TypeError(\n            ""unsupported operand type(s) for +: \'{0}\' and \'{1}\'"".format(\n                other.__class__.__name__, self.__class__.__name__))\n\n    def sys_names(self):\n        """"""\n        Return a list of unique systematic names from OverallSys and HistoSys\n        """"""\n        names = []\n        for sample in self.samples:\n            names.extend(sample.sys_names())\n        return list(set(names))\n\n    def sys_hist(self, name=None, where=None):\n        """"""\n        Return the effective total low and high histogram for a given\n        systematic over samples in this channel.\n        If a sample does not contain the named systematic then its nominal\n        histogram is used for both low and high variations.\n\n        Parameters\n        ----------\n\n        name : string, optional (default=None)\n            The systematic name otherwise nominal if None\n\n        where : callable, optional (default=None)\n            A callable taking one argument: the sample, and returns True if\n            this sample should be included in the total.\n\n        Returns\n        -------\n\n        total_low, total_high : histograms\n            The total low and high histograms for this systematic\n\n        """"""\n        total_low, total_high = None, None\n        for sample in self.samples:\n            if where is not None and not where(sample):\n                continue\n            low, high = sample.sys_hist(name)\n            if total_low is None:\n                total_low = low.Clone(shallow=True)\n            else:\n                total_low += low\n            if total_high is None:\n                total_high = high.Clone(shallow=True)\n            else:\n                total_high += high\n        return total_low, total_high\n\n    def has_sample(self, name):\n        for sample in self.samples:\n            if sample.name == name:\n                return True\n        return False\n\n    def has_sample_where(self, func):\n        for sample in self.samples:\n            if func(sample):\n                return True\n        return False\n\n    def total(self, where=None, xbin1=1, xbin2=-2):\n        """"""\n        Return the total yield and its associated statistical and\n        systematic uncertainties.\n        """"""\n        nominal, _ = self.sys_hist(None, where=where)\n        integral, stat_error = nominal.integral(\n            xbin1=xbin1, xbin2=xbin2, error=True)\n        ups = [0]\n        dns = [0]\n        for sys_name in self.sys_names():\n            low, high = self.sys_hist(sys_name, where=where)\n            up = high.integral(xbin1=xbin1, xbin2=xbin2) - integral\n            dn = low.integral(xbin1=xbin1, xbin2=xbin2) - integral\n            if up > 0:\n                ups.append(up**2)\n            else:\n                dns.append(up**2)\n            if dn > 0:\n                ups.append(dn**2)\n            else:\n                dns.append(dn**2)\n        syst_error = (sqrt(sum(ups)), sqrt(sum(dns)))\n        return integral, stat_error, syst_error\n\n    def SetData(self, data):\n        super(Channel, self).SetData(data)\n        if isinstance(data, ROOT.TH1):\n            keepalive(self, data)\n\n    def GetData(self):\n        return asrootpy(super(Channel, self).GetData())\n\n    @property\n    def data(self):\n        return self.GetData()\n\n    @data.setter\n    def data(self, d):\n        self.SetData(d)\n\n    def AddSample(self, sample):\n        super(Channel, self).AddSample(sample)\n        keepalive(self, sample)\n\n    def RemoveSample(self, name):\n        sample_vect = super(Channel, self).GetSamples()\n        ivect = sample_vect.begin()\n        for sample in sample_vect:\n            if sample.GetName() == name:\n                sample_vect.erase(ivect)\n                break\n            ivect.__preinc__()\n\n    def GetSample(self, name):\n        samples = super(Channel, self).GetSamples()\n        for sample in samples:\n            if sample.GetName() == name:\n                return asrootpy(sample)\n        return None\n\n    def GetSamples(self):\n        return [asrootpy(s) for s in super(Channel, self).GetSamples()]\n\n    def AddAdditionalData(self, data):\n        super(Channel, self).AddAdditionalData(data)\n        keepalive(self, data)\n\n    def GetAdditionalData(self):\n        return [asrootpy(d) for d in super(Channel, self).GetAdditionalData()]\n\n    @property\n    def samples(self):\n        return self.GetSamples()\n\n    @property\n    def additional_data(self):\n        return self.GetAdditionalData()\n\n    @property\n    def hist_path(self):\n        return self.GetHistoPath()\n\n    @hist_path.setter\n    def hist_path(self, path):\n        self.SetHistoPath(path)\n\n    @property\n    def hist_file(self):\n        return self.GetInputFile()\n\n    @hist_file.setter\n    def hist_file(self, infile):\n        self.SetInputFile(infile)\n\n    def apply_snapshot(self, argset):\n        """"""\n        Create a clone of this Channel where histograms are modified according\n        to the values of the nuisance parameters in the snapshot. This is\n        useful when creating post-fit distribution plots.\n\n        Parameters\n        ----------\n\n        argset : RooArtSet\n            A RooArgSet of RooRealVar nuisance parameters\n\n        Returns\n        -------\n\n        channel : Channel\n            The modified channel\n\n        """"""\n        clone = self.Clone()\n        args = [var for var in argset if not (\n            var.name.startswith(\'binWidth_obs_x_\') or\n            var.name.startswith(\'gamma_stat\') or\n            var.name.startswith(\'nom_\'))]\n        # handle NormFactors first\n        nargs = []\n        for var in args:\n            is_norm = False\n            name = var.name.replace(\'alpha_\', \'\')\n            for sample in clone.samples:\n                if sample.GetNormFactor(name) is not None:\n                    log.info(""applying snapshot of {0} on sample {1}"".format(\n                        name, sample.name))\n                    is_norm = True\n                    # scale the entire sample\n                    sample *= var.value\n                    # add an OverallSys for the error\n                    osys = OverallSys(name,\n                        low=1. - var.error / var.value,\n                        high=1. + var.error / var.value)\n                    sample.AddOverallSys(osys)\n                    # remove the NormFactor\n                    sample.RemoveNormFactor(name)\n            if not is_norm:\n                nargs.append(var)\n        # modify the nominal shape and systematics\n        for sample in clone.samples:\n            # check that hist is not NULL\n            if sample.hist is None:\n                raise RuntimeError(\n                    ""sample {0} does not have a ""\n                    ""nominal histogram"".format(sample.name))\n            nominal = sample.hist.Clone(shallow=True)\n            for var in nargs:\n                name = var.name.replace(\'alpha_\', \'\')\n                if not sample.has_sys(name):\n                    continue\n                log.info(""applying snapshot of {0} on sample {1}"".format(\n                    name, sample.name))\n                low, high = sample.sys_hist(name)\n                # modify nominal\n                val = var.value\n                if val > 0:\n                    sample.hist += (high - nominal) * val\n                elif val < 0:\n                    sample.hist += (nominal - low) * val\n                # TODO:\n                # modify OverallSys\n                # modify HistoSys\n        return clone\n\n    def Clone(self):\n        clone = Channel(self.name)\n        data = self.data\n        if data:\n            clone.data = data.Clone()\n        for sample in self.samples:\n            clone.AddSample(sample.Clone())\n        clone.hist_path = self.hist_path\n        clone.hist_file = self.hist_file\n        return clone\n\n    def __iter__(self):\n        for sample in super(Channel, self).GetSamples():\n            yield asrootpy(sample)\n\n    def __len__(self):\n        return len(super(Channel, self).GetSamples())\n\n\nclass Measurement(NamedObject, HistFactory.Measurement):\n    _ROOT = HistFactory.Measurement\n\n    def __init__(self, name, channels=None, title=""""):\n        # require a name\n        super(Measurement, self).__init__(name=name, title=title)\n        self.SetExportOnly(True)\n        if channels is not None:\n            for channel in channels:\n                self.AddChannel(channel)\n\n    @property\n    def lumi(self):\n        return self.GetLumi()\n\n    @lumi.setter\n    def lumi(self, l):\n        self.SetLumi(l)\n\n    @property\n    def lumi_rel_error(self):\n        return self.GetLumiRelErr()\n\n    @lumi_rel_error.setter\n    def lumi_rel_error(self, err):\n        self.SetLumiRelErr(err)\n\n    @property\n    def poi(self):\n        return list(self.GetPOIList())\n\n    @poi.setter\n    def poi(self, p):\n        # this also adds a new POI so calling this multiple times will add\n        # multiple POIs\n        self.SetPOI(p)\n\n    def AddChannel(self, channel):\n        super(Measurement, self).AddChannel(channel)\n        keepalive(self, channel)\n\n    def RemoveChannel(self, name):\n        channel_vect = super(Measurement, self).GetChannels()\n        ivect = channel_vect.begin()\n        for channel in channel_vect:\n            if channel.GetName() == name:\n                channel_vect.erase(ivect)\n                break\n            ivect.__preinc__()\n\n    def GetChannel(self, name):\n        channels = super(Measurement, self).GetChannels()\n        for channel in channels:\n            if channel.GetName() == name:\n                return asrootpy(channel)\n        return None\n\n    def GetChannels(self):\n        return [asrootpy(c) for c in super(Measurement, self).GetChannels()]\n\n    @property\n    def channels(self):\n        return self.GetChannels()\n\n    def GetConstantParams(self):\n        return list(super(Measurement, self).GetConstantParams())\n\n    @property\n    def const_params(self):\n        return self.GetConstantParams()\n\n    def Clone(self):\n        clone = Measurement(self.name, self.title)\n        clone.lumi = self.lumi\n        clone.lumi_rel_error = self.lumi_rel_error\n        for channel in self.channels:\n            clone.AddChannel(channel.Clone())\n        for poi in self.GetPOIList():\n            clone.AddPOI(poi)\n        for const_param in self.const_params:\n            clone.AddConstantParam(const_param)\n        return clone\n\n    def __iter__(self):\n        for channel in super(Measurement, self).GetChannels():\n            yield asrootpy(channel)\n\n    def __len__(self):\n        return len(super(Measurement, self).GetChannels())\n'"
rootpy/stats/histfactory/utils.py,0,"b'from __future__ import absolute_import\n\nimport os\nimport re\nimport shutil\nfrom glob import glob\n\nimport ROOT\n\nfrom . import log; log = log[__name__]\nfrom ...extern.six import string_types\nfrom ...memory.keepalive import keepalive\nfrom ...utils.silence import silence_sout_serr\nfrom ...utils.path import mkdir_p\nfrom ...context import (\n    do_nothing, working_directory, preserve_current_directory)\nfrom ...io import root_open\nfrom ... import asrootpy\nfrom . import Channel, Measurement, HistoSys, OverallSys\n\n__all__ = [\n    \'make_channel\',\n    \'make_measurement\',\n    \'make_workspace\',\n    \'measurements_from_xml\',\n    \'write_measurement\',\n    \'patch_xml\',\n    \'split_norm_shape\',\n]\n\n\ndef make_channel(name, samples, data=None, verbose=False):\n    """"""\n    Create a Channel from a list of Samples\n    """"""\n    if verbose:\n        llog = log[\'make_channel\']\n        llog.info(""creating channel {0}"".format(name))\n    # avoid segfault if name begins with a digit by using ""channel_"" prefix\n    chan = Channel(\'channel_{0}\'.format(name))\n    chan.SetStatErrorConfig(0.05, ""Poisson"")\n\n    if data is not None:\n        if verbose:\n            llog.info(""setting data"")\n        chan.SetData(data)\n\n    for sample in samples:\n        if verbose:\n            llog.info(""adding sample {0}"".format(sample.GetName()))\n        chan.AddSample(sample)\n\n    return chan\n\n\ndef make_measurement(name,\n                     channels,\n                     lumi=1.0, lumi_rel_error=0.1,\n                     output_prefix=\'./histfactory\',\n                     POI=None,\n                     const_params=None,\n                     verbose=False):\n    """"""\n    Create a Measurement from a list of Channels\n    """"""\n    if verbose:\n        llog = log[\'make_measurement\']\n        llog.info(""creating measurement {0}"".format(name))\n\n    if not isinstance(channels, (list, tuple)):\n        channels = [channels]\n\n    # Create the measurement\n    meas = Measurement(\'measurement_{0}\'.format(name), \'\')\n    meas.SetOutputFilePrefix(output_prefix)\n    if POI is not None:\n        if isinstance(POI, string_types):\n            if verbose:\n                llog.info(""setting POI {0}"".format(POI))\n            meas.SetPOI(POI)\n        else:\n            if verbose:\n                llog.info(""adding POIs {0}"".format(\', \'.join(POI)))\n            for p in POI:\n                meas.AddPOI(p)\n\n    if verbose:\n        llog.info(""setting lumi={0:f} +/- {1:f}"".format(lumi, lumi_rel_error))\n    meas.lumi = lumi\n    meas.lumi_rel_error = lumi_rel_error\n\n    for channel in channels:\n        if verbose:\n            llog.info(""adding channel {0}"".format(channel.GetName()))\n        meas.AddChannel(channel)\n\n    if const_params is not None:\n        if verbose:\n            llog.info(""adding constant parameters {0}"".format(\n                \', \'.join(const_params)))\n        for param in const_params:\n            meas.AddConstantParam(param)\n\n    return meas\n\n\ndef make_workspace(measurement, channel=None, name=None, silence=False):\n    """"""\n    Create a workspace containing the model for a measurement\n\n    If `channel` is None then include all channels in the model\n\n    If `silence` is True, then silence HistFactory\'s output on\n    stdout and stderr.\n    """"""\n    context = silence_sout_serr if silence else do_nothing\n    with context():\n        hist2workspace = ROOT.RooStats.HistFactory.HistoToWorkspaceFactoryFast(\n            measurement)\n        if channel is not None:\n            workspace = hist2workspace.MakeSingleChannelModel(\n                measurement, channel)\n        else:\n            workspace = hist2workspace.MakeCombinedModel(measurement)\n    workspace = asrootpy(workspace)\n    keepalive(workspace, measurement)\n    if name is not None:\n        workspace.SetName(\'workspace_{0}\'.format(name))\n    return workspace\n\n\ndef measurements_from_xml(filename,\n                          collect_histograms=True,\n                          cd_parent=False,\n                          silence=False):\n    """"""\n    Read in a list of Measurements from XML\n    """"""\n    if not os.path.isfile(filename):\n        raise OSError(""the file {0} does not exist"".format(filename))\n    silence_context = silence_sout_serr if silence else do_nothing\n\n    filename = os.path.abspath(os.path.normpath(filename))\n\n    if cd_parent:\n        xml_directory = os.path.dirname(filename)\n        parent = os.path.abspath(os.path.join(xml_directory, os.pardir))\n        cd_context = working_directory\n    else:\n        parent = None\n        cd_context = do_nothing\n\n    log.info(""parsing XML in {0} ..."".format(filename))\n    with cd_context(parent):\n        parser = ROOT.RooStats.HistFactory.ConfigParser()\n        with silence_context():\n            measurements_vect = parser.GetMeasurementsFromXML(filename)\n        # prevent measurements_vect from being garbage collected\n        ROOT.SetOwnership(measurements_vect, False)\n        measurements = []\n        for m in measurements_vect:\n            if collect_histograms:\n                with silence_context():\n                    m.CollectHistograms()\n            measurements.append(asrootpy(m))\n    return measurements\n\n\ndef write_measurement(measurement,\n                      root_file=None,\n                      xml_path=None,\n                      output_path=None,\n                      output_suffix=None,\n                      write_workspaces=False,\n                      apply_xml_patches=True,\n                      silence=False):\n    """"""\n    Write a measurement and RooWorkspaces for all contained channels\n    into a ROOT file and write the XML files into a directory.\n\n    Parameters\n    ----------\n\n    measurement : HistFactory::Measurement\n        An asrootpy\'d ``HistFactory::Measurement`` object\n\n    root_file : ROOT TFile or string, optional (default=None)\n        A ROOT file or string file name. The measurement and workspaces\n        will be written to this file. If ``root_file is None`` then a\n        new file will be created with the same name as the measurement and\n        with the prefix ``ws_``.\n\n    xml_path : string, optional (default=None)\n        A directory path to write the XML into. If None, a new directory with\n        the same name as the measurement and with the prefix ``xml_`` will be\n        created.\n\n    output_path : string, optional (default=None)\n        If ``root_file is None``, create the ROOT file under this path.\n        If ``xml_path is None``, create the XML directory under this path.\n\n    output_suffix : string, optional (default=None)\n        If ``root_file is None`` then a new file is created with the same name\n        as the measurement and with the prefix ``ws_``. ``output_suffix`` will\n        append a suffix to this file name (before the .root extension).\n        If ``xml_path is None``, then a new directory is created with the\n        same name as the measurement and with the prefix ``xml_``.\n        ``output_suffix`` will append a suffix to this directory name.\n\n    write_workspaces : bool, optional (default=False)\n        If True then also write a RooWorkspace for each channel and for all\n        channels combined.\n\n    apply_xml_patches : bool, optional (default=True)\n        Apply fixes on the output of ``Measurement::PrintXML()`` to avoid known\n        HistFactory bugs. Some of the patches assume that the ROOT file\n        containing the histograms will exist one directory level up from the\n        XML and that hist2workspace, or any tool that later reads the XML will\n        run from that same directory containing the ROOT file.\n\n    silence : bool, optional (default=False)\n        If True then capture and silence all stdout/stderr output from\n        HistFactory.\n\n    """"""\n    context = silence_sout_serr if silence else do_nothing\n\n    output_name = measurement.name\n    if output_suffix is not None:\n        output_name += \'_{0}\'.format(output_suffix)\n    output_name = output_name.replace(\' \', \'_\')\n\n    if xml_path is None:\n        xml_path = \'xml_{0}\'.format(output_name)\n        if output_path is not None:\n            xml_path = os.path.join(output_path, xml_path)\n\n    if not os.path.exists(xml_path):\n        mkdir_p(xml_path)\n\n    if root_file is None:\n        root_file = \'ws_{0}.root\'.format(output_name)\n        if output_path is not None:\n            root_file = os.path.join(output_path, root_file)\n\n    own_file = False\n    if isinstance(root_file, string_types):\n        root_file = root_open(root_file, \'recreate\')\n        own_file = True\n\n    with preserve_current_directory():\n        root_file.cd()\n\n        log.info(""writing histograms and measurement in {0} ..."".format(\n            root_file.GetName()))\n        with context():\n            measurement.writeToFile(root_file)\n        # get modified measurement\n        out_m = root_file.Get(measurement.name)\n        log.info(""writing XML in {0} ..."".format(xml_path))\n        with context():\n            out_m.PrintXML(xml_path)\n\n        if write_workspaces:\n            log.info(""writing combined model in {0} ..."".format(\n                root_file.GetName()))\n            workspace = make_workspace(measurement, silence=silence)\n            workspace.Write()\n            for channel in measurement.channels:\n                log.info(""writing model for channel `{0}` in {1} ..."".format(\n                    channel.name, root_file.GetName()))\n                workspace = make_workspace(\n                    measurement, channel=channel, silence=silence)\n                workspace.Write()\n\n    if apply_xml_patches:\n        # patch the output XML to avoid HistFactory bugs\n        patch_xml(glob(os.path.join(xml_path, \'*.xml\')),\n                  root_file=os.path.basename(root_file.GetName()))\n\n    if own_file:\n        root_file.Close()\n\n\ndef patch_xml(files, root_file=None, float_precision=3):\n    """"""\n    Apply patches to HistFactory XML output from PrintXML\n    """"""\n    if float_precision < 0:\n        raise ValueError(""precision must be greater than 0"")\n\n    def fix_path(match):\n        path = match.group(1)\n        if path:\n            head, tail = os.path.split(path)\n            new_path = os.path.join(os.path.basename(head), tail)\n        else:\n            new_path = \'\'\n        return \'<Input>{0}</Input>\'.format(new_path)\n\n    for xmlfilename in files:\n        xmlfilename = os.path.abspath(os.path.normpath(xmlfilename))\n        patched_xmlfilename = \'{0}.tmp\'.format(xmlfilename)\n        log.info(""patching {0} ..."".format(xmlfilename))\n        fin = open(xmlfilename, \'r\')\n        fout = open(patched_xmlfilename, \'w\')\n        for line in fin:\n            if root_file is not None:\n                line = re.sub(\n                    \'InputFile=""[^""]*""\',\n                    \'InputFile=""{0}""\'.format(root_file), line)\n            line = line.replace(\n                \'<StatError Activate=""True""  InputFile=""""  \'\n                \'HistoName=""""  HistoPath=""""  />\',\n                \'<StatError Activate=""True"" />\')\n            line = re.sub(\n                \'<Combination OutputFilePrefix=""(\\S*)"" >\',\n                \'<Combination OutputFilePrefix=""hist2workspace"" >\', line)\n            line = re.sub(\'\\w+=""""\', \'\', line)\n            line = re.sub(\'\\s+/>\', \' />\', line)\n            line = re.sub(\'(\\S)\\s+</\', r\'\\1</\', line)\n            # HistFactory bug:\n            line = re.sub(\'InputFileHigh=""\\S+""\', \'\', line)\n            line = re.sub(\'InputFileLow=""\\S+""\', \'\', line)\n            # HistFactory bug:\n            line = line.replace(\n                \'<ParamSetting Const=""True""></ParamSetting>\', \'\')\n            # chop off floats to desired precision\n            line = re.sub(\n                r\'""(\\d*\\.\\d{{{0:d},}})""\'.format(float_precision + 1),\n                lambda x: \'""{0}""\'.format(\n                    str(round(float(x.group(1)), float_precision))),\n                line)\n            line = re.sub(\'""\\s\\s+(\\S)\', r\'"" \\1\', line)\n            line = re.sub(\'<Input>(.*)</Input>\', fix_path, line)\n            fout.write(line)\n        fin.close()\n        fout.close()\n        shutil.move(patched_xmlfilename, xmlfilename)\n        if not os.path.isfile(os.path.join(\n                              os.path.dirname(xmlfilename),\n                              \'HistFactorySchema.dtd\')):\n            rootsys = os.getenv(\'ROOTSYS\', None)\n            if rootsys is not None:\n                dtdfile = os.path.join(rootsys, \'etc/HistFactorySchema.dtd\')\n                target = os.path.dirname(xmlfilename)\n                if os.path.isfile(dtdfile):\n                    log.info(""copying {0} to {1} ..."".format(dtdfile, target))\n                    shutil.copy(dtdfile, target)\n                else:\n                    log.warning(""{0} does not exist"".format(dtdfile))\n            else:\n                log.warning(\n                    ""$ROOTSYS is not set so cannot find HistFactorySchema.dtd"")\n\n\ndef split_norm_shape(histosys, nominal_hist):\n    """"""\n    Split a HistoSys into normalization (OverallSys) and shape (HistoSys)\n    components.\n\n    It is recommended to use OverallSys as much as possible, which tries to\n    enforce continuity up to the second derivative during\n    interpolation/extrapolation. So, if there is indeed a shape variation, then\n    factorize it into shape and normalization components.\n    """"""\n    up = histosys.GetHistoHigh()\n    dn = histosys.GetHistoLow()\n    up = up.Clone(name=up.name + \'_shape\')\n    dn = dn.Clone(name=dn.name + \'_shape\')\n    n_nominal = nominal_hist.integral(overflow=True)\n    n_up = up.integral(overflow=True)\n    n_dn = dn.integral(overflow=True)\n    if n_up != 0:\n        up.Scale(n_nominal / n_up)\n    if n_dn != 0:\n        dn.Scale(n_nominal / n_dn)\n    shape = HistoSys(histosys.GetName(), low=dn, high=up)\n    norm = OverallSys(histosys.GetName(),\n                      low=n_dn / n_nominal if n_nominal != 0 else 1.,\n                      high=n_up / n_nominal if n_nominal != 0 else 1.)\n    return norm, shape\n'"
rootpy/stats/tests/__init__.py,0,b''
rootpy/stats/tests/test_correlated_values.py,0,"b'from nose.plugins.skip import SkipTest\nfrom rootpy.utils.silence import silence_sout\nfrom rootpy import ROOTError\n\ntry:\n    with silence_sout():\n        from ROOT import (RooFit, RooRealVar, RooGaussian, RooArgusBG,\n                          RooAddPdf, RooArgList, RooArgSet)\n    from rootpy.stats import mute_roostats; mute_roostats()\n    from rootpy.stats import Workspace\nexcept (ImportError, ROOTError):\n    raise SkipTest(""ROOT is not compiled with RooFit and RooStats enabled"")\n\nfrom rootpy.io import TemporaryFile\nfrom nose.tools import assert_false\n\n\ndef test_correlated_values():\n\n    try:\n        import uncertainties\n    except ImportError:\n        raise SkipTest(""uncertainties package is not installed"")\n    from rootpy.stats.correlated_values import correlated_values\n\n    # construct pdf and toy data following example at\n    # http://root.cern.ch/drupal/content/roofit\n\n    # --- Observable ---\n    mes = RooRealVar(""mes"", ""m_{ES} (GeV)"", 5.20, 5.30)\n\n    # --- Parameters ---\n    sigmean = RooRealVar(""sigmean"", ""B^{#pm} mass"", 5.28, 5.20, 5.30)\n    sigwidth = RooRealVar(""sigwidth"", ""B^{#pm} width"", 0.0027, 0.001, 1.)\n\n    # --- Build Gaussian PDF ---\n    signal = RooGaussian(""signal"", ""signal PDF"", mes, sigmean, sigwidth)\n\n    # --- Build Argus background PDF ---\n    argpar = RooRealVar(""argpar"", ""argus shape parameter"", -20.0, -100., -1.)\n    background = RooArgusBG(""background"", ""Argus PDF"",\n                            mes, RooFit.RooConst(5.291), argpar)\n\n    # --- Construct signal+background PDF ---\n    nsig = RooRealVar(""nsig"", ""#signal events"", 200, 0., 10000)\n    nbkg = RooRealVar(""nbkg"", ""#background events"", 800, 0., 10000)\n    model = RooAddPdf(""model"", ""g+a"",\n                      RooArgList(signal,background),\n                      RooArgList(nsig,nbkg))\n\n    # --- Generate a toyMC sample from composite PDF ---\n    data = model.generate(RooArgSet(mes), 2000)\n\n    # --- Perform extended ML fit of composite PDF to toy data ---\n    fitresult = model.fitTo(data, RooFit.Save(), RooFit.PrintLevel(-1))\n\n    nsig, nbkg = correlated_values([""nsig"", ""nbkg""], fitresult)\n\n    # Arbitrary math expression according to what the `uncertainties`\n    # package supports, automatically computes correct error propagation\n    sum_value = nsig + nbkg\n    value, error = sum_value.nominal_value, sum_value.std_dev\n\n    workspace = Workspace(name=\'workspace\')\n    # import the data\n    assert_false(workspace(data))\n    with TemporaryFile():\n        workspace.Write()\n'"
rootpy/stats/tests/test_plottable.py,0,"b'from nose.plugins.skip import SkipTest\nfrom rootpy.utils.silence import silence_sout\nfrom rootpy import ROOTError\n\ntry:\n    with silence_sout():\n        import ROOT\n        from ROOT import (RooFit, RooRealVar, RooGaussian, RooArgusBG,\n                          RooAddPdf, RooArgList, RooArgSet, RooAbsData)\n    from rootpy.stats import mute_roostats; mute_roostats()\n    from rootpy import asrootpy\n\nexcept (ImportError, ROOTError):\n    raise SkipTest(""ROOT is not compiled with RooFit and RooStats enabled"")\n\nfrom rootpy.io import TemporaryFile\nfrom nose.tools import assert_true\n\n\ndef test_plottable():\n\n    # construct pdf and toy data following example at\n    # http://root.cern.ch/drupal/content/roofit\n\n    # Observable\n    mes = RooRealVar(""mes"", ""m_{ES} (GeV)"", 5.20, 5.30)\n\n    # Parameters\n    sigmean = RooRealVar(""sigmean"", ""B^{#pm} mass"", 5.28, 5.20, 5.30)\n    sigwidth = RooRealVar(""sigwidth"", ""B^{#pm} width"", 0.0027, 0.001, 1.)\n\n    # Build Gaussian PDF\n    signal = RooGaussian(""signal"", ""signal PDF"", mes, sigmean, sigwidth)\n\n    # Build Argus background PDF\n    argpar = RooRealVar(""argpar"", ""argus shape parameter"", -20.0, -100., -1.)\n    background = RooArgusBG(""background"", ""Argus PDF"",\n                            mes, RooFit.RooConst(5.291), argpar)\n\n    # Construct signal+background PDF\n    nsig = RooRealVar(""nsig"", ""#signal events"", 200, 0., 10000)\n    nbkg = RooRealVar(""nbkg"", ""#background events"", 800, 0., 10000)\n    model = RooAddPdf(""model"", ""g+a"",\n                      RooArgList(signal, background),\n                      RooArgList(nsig, nbkg))\n\n    # Generate a toyMC sample from composite PDF\n    data = model.generate(RooArgSet(mes), 2000)\n\n    # Perform extended ML fit of composite PDF to toy data\n    fitresult = model.fitTo(data, RooFit.Save(), RooFit.PrintLevel(-1))\n\n    # Plot toy data and composite PDF overlaid\n    mesframe = asrootpy(mes.frame())\n    data.plotOn(mesframe)\n    model.plotOn(mesframe)\n\n    for obj in mesframe.objects:\n        assert_true(obj)\n    for curve in mesframe.curves:\n        assert_true(curve)\n    for hist in mesframe.data_hists:\n        assert_true(hist)\n    assert_true(mesframe.plotvar)\n    with TemporaryFile():\n        mesframe.Write()\n'"
rootpy/tree/tests/__init__.py,0,b''
rootpy/tree/tests/test_categories.py,0,"b'from rootpy.tree.categories import Categories\nfrom nose.tools import assert_raises\n\nGOOD = [\n    \'{a|1,2,3}\',\n    \'{var1|1,2,3}x{var2|-10,10.3,100*}x{var3|100}\',\n]\n\nBAD = [\n    \'{1,2,3}\',\n    \'{a|3,2,1}\',\n    \'{var1|1,2*,3}\',\n]\n\ndef test_from_string():\n\n    for s in GOOD:\n        Categories.from_string(s)\n    for s in BAD:\n        assert_raises(SyntaxError, Categories.from_string, s)\n\ndef test_len():\n\n    c = Categories.from_string(\'{a|1,2,3}\')\n    assert len(c) == 4\n    assert len(c) == len(list(c))\n\n    c = Categories.from_string(\'{a|1,2,3}x{b|4,5,6}\')\n    assert len(c) == 16\n\n    c = Categories.from_string(\'{a|1,2,3}x{b|4,5,6*}\')\n    assert len(c) == 12\n\n    c = Categories.from_string(\'{a|1,2,3}x{b|*4,5,6*}\')\n    assert len(c) == 8\n\n    c = Categories.from_string(\'{a|1,2,3*}x{b|*4,5,6*}\')\n    assert len(c) == 6\n\n    c = Categories.from_string(\'{a|*1,2,3*}x{b|*4,5,6*}\')\n    assert len(c) == 4\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/tree/tests/test_cut.py,0,"b'# Copyright 2014 the rootpy developers\n\nfrom rootpy.tree import Cut\nfrom nose.tools import assert_equal\n\n\ndef test_safe():\n    assert_equal(Cut(""var**2"").safe(), ""var_pow_2"")\n    assert_equal(Cut(""var*2"").safe(), ""var_mul_2"")\n    assert_equal(Cut(""2*var**2"").safe(), ""2_mul_var_pow_2"")\n    assert_equal(Cut(""-4+1<fabs(var)*1e-3<4*10"").safe(), ""L-4+1_lt_fabsLvarR_mul_1e-3R_and_LfabsLvarR_mul_1e-3_lt_4_mul_10R"")\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/tree/tests/test_tree.py,0,"b'import ROOT\n\nfrom rootpy.vector import LorentzVector\nfrom rootpy.tree import Tree, Ntuple, TreeModel, TreeChain\nfrom rootpy.io import root_open, TemporaryFile\nfrom rootpy.tree.treetypes import FloatCol, IntCol\nfrom rootpy.plotting import Hist, Hist2D, Hist3D\nfrom rootpy.plotting.graph import _GraphBase\nfrom rootpy import testdata\nfrom rootpy import stl\n\nfrom random import gauss, randint, random\nimport re\nimport os\nimport sys\nif sys.version_info[0] < 3:\n    from cStringIO import StringIO\nelse:\n    from io import StringIO\n\nfrom nose.plugins.skip import SkipTest\nfrom nose.tools import (assert_raises, assert_true, assert_almost_equal,\n                        assert_equal, raises, with_setup)\n\n\nFILES = []\nFILE_PATHS = []\n\n\ndef create_model():\n\n    class ObjectA(TreeModel):\n        # A simple tree object\n        x = FloatCol()\n        y = FloatCol()\n        z = FloatCol()\n        vect = LorentzVector\n\n    class ObjectB(TreeModel):\n        # A tree object collection\n        x = stl.vector(\'int\')\n        y = stl.vector(\'float\')\n        vect = stl.vector(\'TLorentzVector\')\n        # collection size\n        n = IntCol()\n\n    class Event(ObjectA.prefix(\'a_\') + ObjectB.prefix(\'b_\')):\n        i = IntCol()\n\n    return Event\n\n\ndef create_tree(entries=100):\n    f = TemporaryFile()\n    tree = Tree(""tree"", model=create_model())\n    # fill the tree\n    for i in range(entries):\n        assert_equal(tree.a_vect, LorentzVector(0, 0, 0, 0))\n        random_vect = LorentzVector(\n            gauss(.5, 1.),\n            gauss(.5, 1.),\n            gauss(.5, 1.),\n            gauss(.5, 1.))\n        tree.a_vect.copy_from(random_vect)\n        assert_equal(tree.a_vect, random_vect)\n        tree.a_x = gauss(.5, 1.)\n        tree.a_y = gauss(.3, 2.)\n        tree.a_z = gauss(13., 42.)\n        tree.b_n = randint(1, 5)\n        for j in range(tree.b_n):\n            vect = LorentzVector(\n                gauss(.5, 1.),\n                gauss(.5, 1.),\n                gauss(.5, 1.),\n                gauss(.5, 1.))\n            tree.b_vect.push_back(vect)\n            tree.b_x.push_back(randint(1, 10))\n            tree.b_y.push_back(gauss(.3, 2.))\n        tree.i = i\n        assert_equal(tree.b_n, tree.b_vect.size())\n        assert_equal(tree.b_n, tree.b_x.size())\n        assert_equal(tree.b_n, tree.b_y.size())\n        tree.fill(reset=True)\n    tree.write()\n    # TFile.Close the file but keep the underlying\n    # tempfile file descriptor open\n    ROOT.TFile.Close(f)\n    FILES.append(f)\n    FILE_PATHS.append(f.GetName())\n\n\ndef create_chain(entries_per_tree=100):\n    for i in range(3):\n        create_tree(entries=entries_per_tree)\n\n\ndef cleanup():\n    global FILES\n    global FILE_PATHS\n\n    for f in FILES:\n        f.close()\n\n    FILES = []\n    FILE_PATHS = []\n\n\n@with_setup(create_tree, cleanup)\ndef test_attrs():\n    with root_open(FILE_PATHS[0]) as f:\n        tree = f.tree\n        tree.read_branches_on_demand = True\n        tree.define_object(\'a\', \'a_\')\n        tree.define_collection(\'b\', \'b_\', \'b_n\')\n        for event in tree:\n            # test a setattr before a getattr with caching\n            new_a_y = random()\n            event.a_y = new_a_y\n            assert_almost_equal(event.a_y, new_a_y)\n\n            assert_equal(event.a_x, event.a.x)\n            assert_equal(len(event.b) > 0, True)\n\n\n@with_setup(create_tree, cleanup)\ndef test_draw():\n    with root_open(FILE_PATHS[0]) as f:\n        tree = f.tree\n\n        tree.draw(\'a_x\')\n        tree.draw(\'a_x:a_y\')\n        tree.draw(\'a_x:TMath::Exp(a_y)\')\n        tree.draw(\'a_x:a_y:a_z\')\n        tree.draw(\'a_x:a_y:a_z:b_x\')\n        tree.draw(\'a_x:a_y:a_z:b_x:b_y\', options=\'para\')\n\n        h1 = Hist(10, -10, 10, name=\'h1\')\n        h2 = Hist2D(10, -10, 10, 10, -10, 10)\n        h3 = Hist3D(10, -10, 10, 10, -10, 10, 10, -10, 10)\n\n        # dimensionality does not match\n        assert_raises(TypeError, tree.draw, \'a_x:a_y\', hist=h1)\n\n        # name does not match\n        assert_raises(ValueError, tree.draw, \'a_x>>+something\', hist=h1)\n\n        # hist is not a TH1\n        assert_raises(TypeError, tree.draw, \'a_x:a_y\', hist=ROOT.TGraph())\n\n        # name does match and is fine (just redundant)\n        tree.draw(\'a_x>>h1\', hist=h1)\n        assert_equal(h1.Integral() > 0, True)\n        h1.Reset()\n        tree.draw(\'a_x>>+h1\', hist=h1)\n        assert_equal(h1.Integral() > 0, True)\n        h1.Reset()\n\n        # both binning and hist are specified\n        assert_raises(ValueError, tree.draw, \'a_x>>+h1(10, 0, 1)\', hist=h1)\n\n        tree.draw(\'a_x\', hist=h1)\n        assert_equal(h1.Integral() > 0, True)\n        tree.draw(\'a_x:a_y\', hist=h2)\n        assert_equal(h2.Integral() > 0, True)\n        tree.draw(\'a_x:a_y:a_z\', hist=h3)\n        assert_equal(h3.Integral() > 0, True)\n\n        h3.Reset()\n        tree.draw(\'a_x>0:a_y/2:a_z*2\', hist=h3)\n        assert_equal(h3.Integral() > 0, True)\n\n        # create a histogram\n        hist = tree.draw(\'a_x:a_y:a_z\', create_hist=True)\n        assert_equal(hist.Integral() > 0, True)\n\n        hist = tree.draw(\'a_x:a_y:a_z>>new_hist_1\')\n        assert_equal(hist.Integral() > 0, True)\n        assert_equal(hist.name, \'new_hist_1\')\n\n        # create_hist=True is redundant here\n        hist = tree.draw(\'a_x:a_y:a_z>>new_hist_2\', create_hist=True)\n        assert_equal(hist.Integral() > 0, True)\n        assert_equal(hist.name, \'new_hist_2\')\n\n        # test list/tuple expression\n        hist1 = tree.draw(\'a_x:a_y:a_z\', create_hist=True)\n        hist2 = tree.draw([\'a_x\', \'a_y\', \'a_z\'], create_hist=True)\n        hist3 = tree.draw((\'a_x\', \'a_y\', \'a_z\'), create_hist=True)\n        assert_equal(hist1.Integral() > 0, True)\n        assert_equal(hist2.Integral(), hist1.Integral())\n        assert_equal(hist3.Integral(), hist1.Integral())\n\n\n@with_setup(create_chain, cleanup)\ndef test_chain_iter():\n    if sys.version_info[0] >= 3:\n        raise SkipTest(""Python 3 support not implemented"")\n    chain = TreeChain(\'tree\', FILE_PATHS)\n    assert_equal(len(chain), 3)  # 3 files\n    entries = 0\n    for entry in chain:\n        entries += 1\n    assert_equal(entries, 300)\n    entries = 0\n    for entry in chain:\n        entries += 1\n    assert_equal(entries, 300)\n    assert_equal(chain.GetEntries(), 300)\n    assert_equal(chain.GetEntriesFast(), 300)\n\n\n@with_setup(create_chain, cleanup)\ndef test_chain_draw():\n    if sys.version_info[0] >= 3:\n        raise SkipTest(""Python 3 support not implemented"")\n    chain = TreeChain(\'tree\', FILE_PATHS)\n    hist = Hist(100, 0, 1)\n    chain.draw(\'a_x\', hist=hist)\n    assert_equal(hist.Integral() > 0, True)\n    assert_equal(hist.GetEntries(), 300)\n\n    # check that Draw can be repeated\n    hist2 = Hist(100, 0, 1)\n    chain.draw(\'a_x\', hist=hist2)\n    assert_equal(hist.Integral(), hist2.Integral())\n\n    # draw into a graph\n    graph = chain.draw(""a_x:a_y"")\n    assert_true(isinstance(graph, _GraphBase))\n    assert_equal(len(graph), chain.GetEntries())\n    assert_equal(len(graph), 300)\n\n\n@with_setup(create_chain, cleanup)\ndef test_chain_draw_hist_init_first():\n    if sys.version_info[0] >= 3:\n        raise SkipTest(""Python 3 support not implemented"")\n    hist = Hist(100, 0, 1)\n    chain = TreeChain(\'tree\', FILE_PATHS)\n    chain.draw(\'a_x\', hist=hist)\n    assert_equal(hist.Integral() > 0, True)\n\n\n@raises(RuntimeError)\ndef test_require_file_bad():\n    t = Tree()\n\n\ndef test_require_file_good():\n    with TemporaryFile():\n        t = Tree()\n\n\n@raises(RuntimeError)\ndef test_require_file_not_writable():\n    with testdata.get_file():\n        t = Tree()\n\n\ndef test_draw_regex():\n    p = Tree.DRAW_PATTERN\n    m = re.match\n    assert_equal(m(p, \'a\') is not None, True)\n    assert_equal(m(p, \'somebranch\') is not None, True)\n    assert_equal(m(p, \'x:y\') is not None, True)\n    assert_equal(m(p, \'xbranch:y\') is not None, True)\n    assert_equal(m(p, \'x:y:z\') is not None, True)\n\n    expr = \'(x%2)>0:sqrt(y)>4:z/3\'\n    assert_equal(m(p, expr) is not None, True)\n\n    redirect = \'>>+histname(10, 0, 1)\'\n    expr_redirect = expr + redirect\n    match = m(p, expr_redirect)\n    groupdict = match.groupdict()\n    assert_equal(groupdict[\'branches\'], expr)\n    assert_equal(groupdict[\'redirect\'], redirect)\n    assert_equal(groupdict[\'name\'], \'histname\')\n\n\ndef test_file_assoc():\n    with TemporaryFile() as f1:\n        t = Tree()\n        with TemporaryFile() as f2:\n            pass\n        #f1.cd() <== this should not be needed!\n        # the tree should ""remember"" what file it was created in\n        t.Write()\n\n\ndef test_csv():\n    f = testdata.get_file(\'test_csv.root\')\n    tree = f.ParTree_Postselect\n    tree.create_buffer(ignore_unsupported=True)\n    output = StringIO()\n    tree.csv(stream=output)\n    f.close()\n    # compare with existing txt output\n    if sys.version_info[0] < 3:\n        true_output_filename = testdata.get_filepath(\'test_csv.txt\')\n    else:\n        true_output_filename = testdata.get_filepath(\'test_csv_new.txt\')\n    with open(true_output_filename, \'r\') as true_output_file:\n        true_output = true_output_file.read()\n        assert_equal(output.getvalue(), true_output)\n\n\ndef test_ntuple():\n    with TemporaryFile():\n        ntuple = Ntuple((\'a\', \'b\', \'c\'), name=\'test\')\n        for i in range(100):\n            ntuple.Fill(gauss(.3, 2.), gauss(0, 1.), gauss(-1., 5))\n        ntuple.Write()\n\n\nif __name__ == \'__main__\':\n    import nose\n    nose.runmodule()\n'"
rootpy/tree/tests/test_treetypes.py,0,"b'from rootpy.tree.treetypes import convert\nfrom nose.tools import assert_equal\n\n\ndef test_convert():\n\n    assert_equal(convert(\'ROOTNAME\', \'NUMPY\', \'Bool_t\'), \'b\')\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/utils/tests/__init__.py,0,b''
rootpy/utils/tests/facade_example.py,0,"b'from rootpy.utils.module_facade import Facade\n\n\ndef module_level_function(what):\n    return what\n\nmodule_level_constant = ""MODULE_LEVEL_CONSTANT""\n\n\n@Facade(__name__, expose_internal=False, submodule=True)\nclass internal(object):\n    @property\n    def hello(self):\n        return ""hello""\n\n\n@Facade(__name__, expose_internal=True)\nclass ExampleModuleFacade(object):\n    class_level = ""class_level""\n\n    @property\n    def hello(self):\n        return ""hello""\n\n    def __getattr__(self, key):\n        if key == ""something"":\n            return ""something""\n\n    def __getitem__(self, key):\n        return key\n\n    def __dir__(self):\n        return [""something""]\n\n    def attach_thing(self, param):\n        return param\n'"
rootpy/utils/tests/test_cpp.py,0,"b'from __future__ import print_function\nimport sys\nfrom ROOT import MethodProxy\nimport inspect\nfrom rootpy.utils.cpp import CPPGrammar\nfrom rootpy.utils.extras import iter_ROOT_classes\nfrom nose.plugins.attrib import attr\n\n\n@attr(\'slow\')\ndef test_cpp():\n\n    i = 0\n    num_methods = 0\n\n    for cls in iter_ROOT_classes():\n        members = inspect.getmembers(cls)\n        # filter out those starting with ""_"" or ""operator ""\n        # and non-method members\n        # also split overloaded methods\n        methods = {}\n        for name, func in members:\n            if name.startswith(\'_\') or name.startswith(\'operator\'):\n                continue\n            if not isinstance(func, MethodProxy):\n                continue\n            methods[name] = (func, func.func_doc.split(\'\\n\'))\n\n        for name, (func, sigs) in methods.items():\n            for sig in sigs:\n                num_methods += 1\n                if CPPGrammar.parse_method(sig, silent=False):\n                    i += 1\n            print(""{0} / {1}"".format(i, num_methods), end=\'\\r\')\n            sys.stdout.flush()\n    print(""{0} / {1}"".format(i, num_methods))\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/utils/tests/test_ext_glob.py,0,"b'import os\nfrom glob import glob as py_glob\nfrom nose.tools import assert_equal, assert_true\nfrom nose.plugins.attrib import attr\nfrom rootpy.utils.ext_glob import glob as ext_glob\n\n\n# It\'s conceivable that these parameters might be worth overloading / changing\n# from a config file or command line option, particulary the remote_directory\nthis_directory = os.path.dirname(os.path.abspath(__file__))\nremote_directory = ""root://eospublic.cern.ch//eos/report/eospublic/2015/11""\n\n\ndef test_local_glob_none():\n    filename = os.path.join(this_directory, ""test_ext_glob.py"")\n    assert_equal([filename], ext_glob(filename))\n\n\ndef test_local_glob_basename():\n    filename = os.path.join(this_directory, ""*.py"")\n    assert_equal(ext_glob(filename), py_glob(filename))\n\n\ndef test_local_glob_dirname():\n    filename = os.path.join(os.path.dirname(this_directory), ""*"")\n    assert_equal(ext_glob(filename), py_glob(filename))\n\n\ndef test_local_glob_both():\n    filename = os.path.join(os.path.dirname(this_directory), ""*"", ""*.py"")\n    assert_equal(ext_glob(filename), py_glob(filename))\n\n\ndef test_xrootd_glob_none():\n    filename = remote_directory\n    assert_equal(ext_glob(filename),[filename])\n\n\n@attr(\'network\')\ndef test_xrootd_glob_single():\n    filename = ""/"".join([remote_directory, \'*\'])\n    assert_true(len(ext_glob(filename)) >= 1)\n\n\n@attr(\'network\')\ndef test_xrootd_glob_multiple():\n    filename = os.path.dirname(remote_directory)\n    filename = ""/"".join([filename, \'*\', \'*\'])\n    assert_true(len(ext_glob(filename)) >= 2)\n'"
rootpy/utils/tests/test_hook.py,0,"b'from rootpy import QROOT\nfrom rootpy.utils.hook import classhook, appendclass, super_overridden\nfrom rootpy.context import invisible_canvas\nimport rootpy.utils.hook as H\n\nimport ROOT\n\n\nVALUE = 1\nANOTHER = 42\n\n\ndef basicfunc():\n    return VALUE, ANOTHER\n\n\ndef wrap():\n    a = 1\n    def outer(VALUE):\n        y = a\n        z = 2\n        def inner(x):\n            return a, x, y, z, VALUE, ANOTHER, nonexist\n        return inner\n    return outer\n\n\ndef test_inject():\n    assert (VALUE, ANOTHER) == (1, 42)\n    assert basicfunc() == (VALUE, ANOTHER)\n\n    # Basic injection test\n    NEWVALUE = 2\n    injected = H.inject_closure_values(basicfunc, VALUE=NEWVALUE)\n    assert injected() == (NEWVALUE, ANOTHER)\n\n    # Check that\n    try:\n        wrap()(1)(2)\n    except NameError as e:\n        assert ""nonexist"" in e.args[0]\n    else:\n        assert False, ""expected a NameError""\n\n    global nonexist\n    nonexist = 999\n    # Test the unmodified version of the function\n    correct = wrap()(1)(2)\n    del nonexist\n\n    # Test that we can really replace globals\n    NEWANOTHER = 43\n    newvalue = tuple(a if a != ANOTHER else NEWANOTHER for a in correct)\n\n    hooked = H.inject_closure_values(wrap, ANOTHER=NEWANOTHER, nonexist=999)\n    result = hooked()(1)(2)\n\n    assert result == newvalue, (""Closure injection is not working properly"")\n\n\n@classhook(QROOT.TH1)\n@super_overridden\nclass TH1(object):\n    def SetTitle(self, *args):\n        super(TH1, self).SetTitle(*args)\n        return ""SUCCESS""\n\n    @classmethod\n    def _rootpy_hook_test(cls):\n        return ""SUCCESS""\n\n    def _rootpy_test_super_draw(self, *args, **kwargs):\n        super(TH1, self).Draw(*args, **kwargs)\n        return ""SUCCESS""\n\n\n@appendclass(QROOT.TAttLine)\nclass TAttLine(object):\n    @property\n    def _rootpy_hook_test_prop(self):\n        return ""SUCCESS""\n\n    @staticmethod\n    def _rootpy_hook_test_static():\n        return ""SUCCESS""\n\n    @classmethod\n    def _rootpy_hook_test_clsmeth(cls):\n        return ""SUCCESS""\n\n    def _rootpy_hook_test_method(self):\n        return ""SUCCESS""\n\n\ndef test_hooks():\n    h = ROOT.TH1D()\n\n    newtitle = ""Hello, world""\n    assert h.SetTitle(newtitle) == ""SUCCESS""\n    assert h.GetTitle() == newtitle\n\n    with invisible_canvas() as c:\n        assert c.GetListOfPrimitives().GetSize() == 0\n        assert h._rootpy_test_super_draw() == ""SUCCESS""\n        assert c.GetListOfPrimitives().GetSize() == 1\n\n    assert h._rootpy_hook_test_prop == ""SUCCESS""\n    assert h._rootpy_hook_test_method() == ""SUCCESS""\n    assert h._rootpy_hook_test_static() == ""SUCCESS""\n    assert h._rootpy_hook_test_clsmeth() == ""SUCCESS""\n'"
rootpy/utils/tests/test_module_facade.py,0,"b'import rootpy.utils.tests.facade_example as F\n\ndef test_module_facade():\n    assert F.hello == ""hello""\n    assert F.something == ""something""\n    assert F.attach_thing(""thing"") == ""thing""\n    assert F.class_level == ""class_level""\n    assert ""something"" in dir(F)\n    assert F[""item""] == ""item""\n    assert F.module_level_constant == ""MODULE_LEVEL_CONSTANT""\n    assert ""module_level_constant"" in dir(F)\n    assert F.module_level_function(""a"") == ""a""\n    assert ""module_level_function"" in dir(F)\n\ndef test_internal_facade():\n    from rootpy.utils.tests.facade_example.internal import hello\n    assert hello == ""hello""\n    assert F.internal.hello == ""hello""\n    assert dir(hello)\n\n'"
rootpy/plotting/contrib/tests/__init__.py,0,b''
rootpy/plotting/contrib/tests/test_plot_contour_matrix.py,5,"b""import string\nfrom rootpy.plotting.contrib import plot_contour_matrix\n\n\nif __name__ == '__main__':\n\n    import numpy as np\n\n    n_vars = 5\n    var_names = ['var_%s' % s for s in string.lowercase[:n_vars]]\n\n    def random_symm(n):\n        a = np.random.random_integers(-10, 10, size=(n, n))\n        return (a + a.T) / 2\n\n    data_a = np.random.multivariate_normal(\n        -np.random.random(n_vars) * 3, cov=random_symm(n_vars), size=100000)\n    data_b = np.random.multivariate_normal(\n        np.random.random(n_vars) * 3, cov=random_symm(n_vars), size=100000)\n\n    plot_contour_matrix(\n        [data_a, data_b],\n        var_names,\n        'out.gif',\n        sample_names='A B'.split(),\n        sample_colors='red blue'.split(),\n        sample_lines='solid dashed'.split(),\n        num_contours=5,\n        cell_width=2,\n        cell_height=2,\n        animate_field='var_a',\n        animate_steps=20)\n"""
rootpy/plotting/contrib/tests/test_plot_corrcoef_matrix.py,4,"b""import string\nfrom rootpy.plotting.contrib import plot_corrcoef_matrix\n\n\nif __name__ == '__main__':\n\n    import numpy as np\n\n    n_vars = 10\n    var_names = ['var_%s' % s for s in string.lowercase[:n_vars]]\n\n    def random_symm(n):\n        a = np.random.random_integers(-10, 10, size=(n, n))\n        return (a + a.T) / 2\n\n    data = np.random.multivariate_normal(\n        -np.random.random(n_vars) * 3, cov=random_symm(n_vars), size=100000)\n    weights = np.random.randint(1, 10, 100000)\n\n    plot_corrcoef_matrix(\n        data, var_names, 'correlations.png',\n        weights=weights, title='correlations')\n"""
rootpy/plotting/style/atlas/__init__.py,0,"b""from __future__ import absolute_import\n\nfrom .style import style as ATLAS_style\nfrom .style_mpl import style_mpl as ATLAS_style_mpl\nfrom .labels import ATLAS_label\n\n__all__ = [\n    'ATLAS_style',\n    'ATLAS_style_mpl',\n    'ATLAS_label',\n]\n"""
rootpy/plotting/style/atlas/labels.py,0,"b'from __future__ import absolute_import\n\nfrom .... import ROOT\nfrom ....context import preserve_current_canvas\nfrom ....memory.keepalive import keepalive\n\n__all__ = [\n    \'ATLAS_label\',\n]\n\n\ndef ATLAS_label(x, y, text=""Preliminary 20XX"", sqrts=8,\n                pad=None,\n                expfont=73, labelfont=43,\n                textsize=20, sep=None):\n\n    if pad is None:\n        pad = ROOT.gPad\n    with preserve_current_canvas():\n        pad.cd()\n        l = ROOT.TLatex(x, y, ""ATLAS"")\n        #l.SetTextAlign(12)\n        #l.SetTextSize(tsize)\n        l.SetNDC()\n        l.SetTextFont(expfont)\n        l.SetTextSize(textsize)\n        l.SetTextColor(1)\n        l.Draw()\n        keepalive(pad, l)\n        if sep is None:\n            # guess\n            sep = 0.115 * 696 * pad.GetWh() / (472 * pad.GetWw())\n        if text is not None:\n            if sqrts is not None:\n                text = text + "" #sqrt{{s}}={0:d}TeV"".format(sqrts)\n            p = ROOT.TLatex(x + sep, y, text)\n            p.SetNDC()\n            p.SetTextFont(labelfont)\n            p.SetTextSize(textsize)\n            p.SetTextColor(1)\n            p.Draw()\n            keepalive(pad, p)\n        else:\n            p = None\n        pad.Modified()\n        pad.Update()\n    return l, p\n'"
rootpy/plotting/style/atlas/style.py,0,"b'""""""\nATLAS Style, based on a style file from BaBar\n""""""\nfrom __future__ import absolute_import\n\nfrom .. import Style\n\n__all__ = [\n    \'style\',\n]\n\ndef style(name=\'ATLAS\', shape=\'rect\', orientation=\'landscape\'):\n\n    STYLE = Style(name, \'ATLAS Style\')\n\n    # turn off borders\n    STYLE.SetCanvasBorderMode(0)\n    STYLE.SetFrameBorderMode(0)\n    STYLE.SetPadBorderMode(0)\n\n    # default canvas size and position\n    if shape == \'rect\':\n        if orientation == \'landscape\':\n            h = 600\n            w = 800\n            mtop = 0.05\n            mright = 0.04\n            mbottom = 0.16\n            mleft = 0.16\n            xoffset = 1.4\n            yoffset = 1.5\n        elif orientation == \'portrait\':\n            h = 800\n            w = 600\n            mtop = 0.04\n            mright = 0.05\n            mbottom = 0.12\n            mleft = 0.21\n            xoffset = 1.4\n            yoffset = 2.6\n        else:\n            raise ValueError(""orientation must be \'landscape\' or \'portrait\'"")\n    elif shape == \'square\':\n        h = 600\n        w = 600\n        mtop = 0.05\n        mright = 0.05\n        mbottom = 0.16\n        mleft = 0.21\n        xoffset = 1.4\n        yoffset = 2.\n    else:\n        raise ValueError(""shape must be \'square\' or \'rect\'"")\n\n    STYLE.SetCanvasDefH(h)\n    STYLE.SetCanvasDefW(w)\n    STYLE.SetCanvasDefX(0)\n    STYLE.SetCanvasDefY(0)\n\n    # set margin sizes\n    STYLE.SetPadTopMargin(mtop)\n    STYLE.SetPadRightMargin(mright)\n    STYLE.SetPadBottomMargin(mbottom)\n    STYLE.SetPadLeftMargin(mleft)\n\n    # set title offsets (for axis label)\n    STYLE.SetTitleXOffset(xoffset)\n    STYLE.SetTitleYOffset(yoffset)\n\n    # use plain black on white colors\n    STYLE.SetFrameFillColor(0)\n    STYLE.SetCanvasColor(0)\n    STYLE.SetPadColor(0)\n    STYLE.SetStatColor(0)\n\n    # don\'t use white fill color for *all* objects\n    #STYLE.SetFillColor(0)\n\n    # NOTE: the following is missing from the official ATLAS style\n    STYLE.SetLegendBorderSize(0)\n    STYLE.SetLegendFillColor(0)\n\n    # set the paper & margin sizes\n    STYLE.SetPaperSize(20,26)\n\n    # use large fonts\n    #font = 72 # Helvetica italics\n    # NOTE: the official ATLAS style uses 42 here but it is preferred to specify the\n    # font size in pixels, independent of the canvas size\n    font = 43 # Helvetica\n    tsize = 30\n    STYLE.SetTextFont(font)\n    STYLE.SetLegendFont(font)\n\n    STYLE.SetTextSize(tsize)\n    STYLE.SetLabelFont(font, ""x"")\n    STYLE.SetTitleFont(font, ""x"")\n    STYLE.SetLabelFont(font, ""y"")\n    STYLE.SetTitleFont(font, ""y"")\n    STYLE.SetLabelFont(font, ""z"")\n    STYLE.SetTitleFont(font, ""z"")\n\n    STYLE.SetLabelSize(tsize, ""x"")\n    STYLE.SetTitleSize(tsize, ""x"")\n    STYLE.SetLabelSize(tsize, ""y"")\n    STYLE.SetTitleSize(tsize, ""y"")\n    STYLE.SetLabelSize(tsize, ""z"")\n    STYLE.SetTitleSize(tsize, ""z"")\n\n    # use bold lines and markers\n    STYLE.SetMarkerStyle(20)\n    STYLE.SetMarkerSize(1.2)\n    STYLE.SetHistLineWidth(2)\n    STYLE.SetLineStyleString(2, ""[12 12]"") # postscript dashes\n\n    # get rid of X error bars\n    #STYLE.SetErrorX(0.001)\n    # get rid of error bar caps\n    STYLE.SetEndErrorSize(0.)\n\n    # do not display any of the standard histogram decorations\n    STYLE.SetOptTitle(0)\n    #STYLE.SetOptStat(1111)\n    STYLE.SetOptStat(0)\n    #STYLE.SetOptFit(1111)\n    STYLE.SetOptFit(0)\n\n    # put tick marks on top and RHS of plots\n    STYLE.SetPadTickX(1)\n    STYLE.SetPadTickY(1)\n\n    STYLE.SetPalette(1)\n\n    return STYLE\n'"
rootpy/plotting/style/atlas/style_mpl.py,0,"b'""""""\nATLAS-like style for matplotlib\n""""""\n__all__ = [\n    \'style_mpl\',\n]\n\ndef style_mpl():\n\n    STYLE = {}\n\n    STYLE[\'lines.linewidth\'] = 1\n\n    # font\n    STYLE[\'font.family\'] = \'sans-serif\'\n    STYLE[\'mathtext.fontset\'] = \'stixsans\'\n    STYLE[\'mathtext.default\'] = \'rm\'\n    # helvetica usually not present on linux\n    STYLE[\'font.sans-serif\'] = \'helvetica, Helvetica, Nimbus Sans L, Mukti Narrow, FreeSans\'\n\n    # figure layout\n    STYLE[\'figure.figsize\'] = 8.75, 5.92\n    #   atlasStyle->SetPaperSize(20,26); # in cm\n    # STYLE[\'figure.figsize\'] =  10.2362205, 7.874015 # in inc, not working\n    STYLE[\'figure.facecolor\'] = \'white\'\n    STYLE[\'figure.subplot.bottom\'] = 0.16\n    STYLE[\'figure.subplot.top\'] = 0.95\n    STYLE[\'figure.subplot.left\'] = 0.16\n    STYLE[\'figure.subplot.right\'] = 0.95\n\n    # axes\n    STYLE[\'axes.labelsize\'] = 20\n    STYLE[\'xtick.labelsize\'] = 19\n    STYLE[\'xtick.major.size\'] = 12\n    STYLE[\'xtick.minor.size\'] = 6\n    STYLE[\'ytick.labelsize\'] = 19\n    STYLE[\'ytick.major.size\'] = 14\n    STYLE[\'ytick.minor.size\'] = 7\n    STYLE[\'lines.markersize\'] = 8\n    # STYLE[\'lines.markeredgewidth\'] = 0. # not working, it changes other stuff\n\n    # legend\n    STYLE[\'legend.numpoints\'] = 1\n    STYLE[\'legend.fontsize\'] = 19\n    STYLE[\'legend.labelspacing\'] = 0.3\n    STYLE[\'legend.frameon\'] = False\n\n    # what cannot be set with rcParams:\n    # * markeredgewidth\n    # * axis-label alignment\n    # * axis-label offset\n    # * axis-ticks\n\n    return STYLE\n'"
rootpy/plotting/style/atlas/test.py,0,"b'import ROOT\nfrom rootpy.plotting import Canvas, Hist\nfrom rootpy.plotting.style import get_style\nfrom rootpy.plotting.style.atlas.labels import ATLAS_label\nfrom rootpy.interactive import wait\n\nINTERACTIVE = False\n\n""""""\ndef test_atlas():\n    style = get_style(\'ATLAS\')\n    with style:\n        canvas = Canvas()\n        hpx = Hist(100, -4, 4, name=""hpx"", title=""This is the px distribution"")\n        ROOT.gRandom.SetSeed()\n        for i in range(1000):\n            hpx.Fill(ROOT.gRandom.Gaus())\n        hpx.GetXaxis().SetTitle(""random variable [unit]"")\n        hpx.GetYaxis().SetTitle(""#frac{dN}{dr} [unit^{-1}]"")\n        hpx.SetMaximum(80.)\n        hpx.Draw()\n        ATLAS_label(.4, .8)\n        if INTERACTIVE:\n            wait()\n""""""\n\nif __name__ == ""__main__"":\n    import nose\n    INTERACTIVE = True\n    nose.runmodule()\n'"
rootpy/plotting/style/cmstdr/__init__.py,0,"b""from __future__ import absolute_import\n\nfrom .style import style as CMS_style\nfrom .labels import CMS_label\n\n__all__ = [\n    'CMS_style',\n    'CMS_label',\n]\n"""
rootpy/plotting/style/cmstdr/labels.py,0,"b'""""""\nAdd the ""CMS Preliminary"" and \\sqrt{s} blurbs to CMS plots.\n""""""\nfrom __future__ import absolute_import\n\nfrom .... import ROOT\nfrom ....context import preserve_current_canvas\nfrom ....memory.keepalive import keepalive\n\n__all__ = [\n    \'CMS_label\',\n]\n\n\ndef CMS_label(text=""Preliminary 2012"", sqrts=8, pad=None):\n    """""" Add a \'CMS Preliminary\' style label to the current Pad.\n\n    The blurbs are drawn in the top margin.  The label ""CMS "" + text is drawn\n    in the upper left.  If sqrts is None, it will be omitted.  Otherwise, it\n    will be drawn in the upper right.\n    """"""\n    if pad is None:\n        pad = ROOT.gPad\n    with preserve_current_canvas():\n        pad.cd()\n        left_margin = pad.GetLeftMargin()\n        top_margin = pad.GetTopMargin()\n        ypos = 1 - top_margin / 2.\n        l = ROOT.TLatex(left_margin, ypos, ""CMS "" + text)\n        l.SetTextAlign(12) # left-middle\n        l.SetNDC()\n        # The text is 90% as tall as the margin it lives in.\n        l.SetTextSize(0.90 * top_margin)\n        l.Draw()\n        keepalive(pad, l)\n        # Draw sqrt(s) label, if desired\n        if sqrts:\n            right_margin = pad.GetRightMargin()\n            p = ROOT.TLatex(1 - right_margin, ypos,\n                            ""#sqrt{{s}}={0:d}TeV"".format(sqrts))\n            p.SetTextAlign(32) # right-middle\n            p.SetNDC()\n            p.SetTextSize(0.90 * top_margin)\n            p.Draw()\n            keepalive(pad, p)\n        else:\n            p = None\n        pad.Modified()\n        pad.Update()\n    return l, p\n'"
rootpy/plotting/style/cmstdr/style.py,0,"b'""""""\nCMS style from http://cmssw.cvs.cern.ch/cgi-bin/cmssw.cgi/UserCode/RootMacros/style-CMSTDR.C\n""""""\nfrom __future__ import absolute_import\n\nfrom .. import Style\n\n__all__ = [\n    \'style\',\n]\n\n\ndef style(name=\'CMSTDR\'):\n\n    STYLE = Style(name, ""Style for CMS P-TDR"")\n\n    # For the canvas:\n    STYLE.SetCanvasBorderMode(0)\n    STYLE.SetCanvasColor(0)\n    STYLE.SetCanvasDefH(600) # Height of canvas\n    STYLE.SetCanvasDefW(600) # Width of canvas\n    STYLE.SetCanvasDefX(0)   # Position on screen\n    STYLE.SetCanvasDefY(0)\n\n    # For the Pad:\n    STYLE.SetPadBorderMode(0)\n    # STYLE.SetPadBorderSize(Width_t size = 1)\n    STYLE.SetPadColor(0)\n    STYLE.SetPadGridX(False)\n    STYLE.SetPadGridY(False)\n    STYLE.SetGridColor(0)\n    STYLE.SetGridStyle(3)\n    STYLE.SetGridWidth(1)\n\n    # For the frame:\n    STYLE.SetFrameBorderMode(0)\n    STYLE.SetFrameBorderSize(1)\n    STYLE.SetFrameFillColor(0)\n    STYLE.SetFrameFillStyle(0)\n    STYLE.SetFrameLineColor(1)\n    STYLE.SetFrameLineStyle(1)\n    STYLE.SetFrameLineWidth(1)\n\n    # For the histo:\n    # STYLE.SetHistFillColor(1)\n    # STYLE.SetHistFillStyle(0)\n    STYLE.SetHistLineColor(1)\n    STYLE.SetHistLineStyle(0)\n    STYLE.SetHistLineWidth(1)\n    # STYLE.SetLegoInnerR(Float_t rad = 0.5)\n    # STYLE.SetNumberContours(Int_t number = 20)\n\n    STYLE.SetEndErrorSize(2)\n    #STYLE.SetErrorMarker(20)  # Seems to give an error\n    STYLE.SetErrorX(0.)\n\n    STYLE.SetMarkerStyle(20)\n\n    #For the fit/function:\n    STYLE.SetOptFit(1)\n    STYLE.SetFitFormat(""5.4g"")\n    STYLE.SetFuncColor(2)\n    STYLE.SetFuncStyle(1)\n    STYLE.SetFuncWidth(1)\n\n    #For the date:\n    STYLE.SetOptDate(0)\n    # STYLE.SetDateX(Float_t x = 0.01)\n    # STYLE.SetDateY(Float_t y = 0.01)\n\n    # For the statistics box:\n    STYLE.SetOptFile(0)\n    STYLE.SetOptStat(0) # To display the mean and RMS:   SetOptStat(""mr"")\n    STYLE.SetStatColor(0)\n    STYLE.SetStatFont(42)\n    STYLE.SetStatFontSize(0.025)\n    STYLE.SetStatTextColor(1)\n    STYLE.SetStatFormat(""6.4g"")\n    STYLE.SetStatBorderSize(1)\n    STYLE.SetStatH(0.1)\n    STYLE.SetStatW(0.15)\n    # STYLE.SetStatStyle(Style_t style = 1001)\n    # STYLE.SetStatX(Float_t x = 0)\n    # STYLE.SetStatY(Float_t y = 0)\n\n    # Margins:\n    STYLE.SetPadTopMargin(0.05)\n    STYLE.SetPadBottomMargin(0.13)\n    STYLE.SetPadLeftMargin(0.16)\n    STYLE.SetPadRightMargin(0.02)\n\n    # For the Global title:\n    STYLE.SetOptTitle(0)    # 0=No Title\n    STYLE.SetTitleFont(42)\n    STYLE.SetTitleColor(1)\n    STYLE.SetTitleTextColor(1)\n    STYLE.SetTitleFillColor(10)\n    STYLE.SetTitleFontSize(0.05)\n    # STYLE.SetTitleH(0) # Set the height of the title box\n    # STYLE.SetTitleW(0) # Set the width of the title box\n    # STYLE.SetTitleX(0) # Set the position of the title box\n    # STYLE.SetTitleY(0.985) # Set the position of the title box\n    # STYLE.SetTitleStyle(Style_t style = 1001)\n    # STYLE.SetTitleBorderSize(2)\n\n    # For the axis titles:\n    STYLE.SetTitleColor(1, ""XYZ"")\n    STYLE.SetTitleFont(42, ""XYZ"")\n    STYLE.SetTitleSize(0.05, ""XYZ"")\n    # STYLE.SetTitleXSize(Float_t size = 0.02) # Another way to set the size?\n    # STYLE.SetTitleYSize(Float_t size = 0.02)\n    STYLE.SetTitleXOffset(1.0)\n    STYLE.SetTitleYOffset(1.35)\n    # STYLE.SetTitleOffset(1.1, ""Y"") # Another way to set the Offset\n\n    # For the axis labels:\n    STYLE.SetLabelColor(1, ""XYZ"")\n    STYLE.SetLabelFont(42, ""XYZ"")\n    STYLE.SetLabelOffset(0.007, ""XYZ"")\n    STYLE.SetLabelSize(0.04, ""XYZ"")\n\n    # For the axis:\n    STYLE.SetAxisColor(1, ""XYZ"")\n    STYLE.SetStripDecimals(True)\n    STYLE.SetTickLength(0.03, ""XYZ"")\n    STYLE.SetNdivisions(510, ""XYZ"")\n    STYLE.SetPadTickX(1)  # 0=Text labels (and tics) only on bottom, 1=Text labels on top and bottom\n    STYLE.SetPadTickY(1)\n\n    # Change for log plots:\n    STYLE.SetOptLogx(0)\n    STYLE.SetOptLogy(0)\n    STYLE.SetOptLogz(0)\n\n    # Postscript options:\n    STYLE.SetPaperSize(20.,20.)\n    # STYLE.SetLineScalePS(Float_t scale = 3)\n    # STYLE.SetLineStyleString(Int_t i, const char* text)\n    # STYLE.SetHeaderPS(const char* header)\n    # STYLE.SetTitlePS(const char* pstitle)\n\n    # STYLE.SetBarOffset(Float_t baroff = 0.5)\n    # STYLE.SetBarWidth(Float_t barwidth = 0.5)\n    # STYLE.SetPaintTextFormat(const char* format = ""g"")\n    # STYLE.SetPalette(Int_t ncolors = 0, Int_t* colors = 0)\n    # STYLE.SetTimeOffset(Double_t toffset)\n    # STYLE.SetHistMinimumZero(True)\n\n    STYLE.SetPalette(1)\n\n    return STYLE\n'"
rootpy/plotting/style/cmstdr/test.py,0,"b'import ROOT\nfrom rootpy.plotting import Canvas, Hist\nfrom rootpy.plotting.style import get_style\nfrom rootpy.plotting.style.cmstdr.labels import CMS_label\nfrom rootpy.interactive import wait\n\nINTERACTIVE = False\n\n""""""\ndef test_cmstdr():\n    style = get_style(\'CMSTDR\')\n    with style:\n        canvas = Canvas()\n        hpx = Hist(100, -4, 4, name=""hpx"", title=""This is the px distribution"")\n        ROOT.gRandom.SetSeed()\n        for i in range(1000):\n            hpx.Fill(ROOT.gRandom.Gaus())\n        hpx.GetXaxis().SetTitle(""random variable [unit]"")\n        hpx.GetYaxis().SetTitle(""#frac{dN}{dr} [unit^{-1}]"")\n        hpx.SetMaximum(100.)\n        hpx.Draw()\n        CMS_label(""Testing 2050"", sqrts=100)\n        if INTERACTIVE:\n            wait()\n""""""\n\nif __name__ == ""__main__"":\n    import nose\n    INTERACTIVE = True\n    nose.runmodule()\n'"
rootpy/plotting/style/default/__init__.py,0,b''
rootpy/plotting/style/default/style.py,0,"b'from __future__ import absolute_import\n\nfrom .. import Style\n\n__all__ = [\n    \'style\',\n]\n\ndef style(name=\'DEFAULT\'):\n    return Style(""DEFAULT"", ""Default Style"")\n'"
rootpy/plotting/style/lhcb/__init__.py,0,"b""from __future__ import absolute_import\n\nfrom .style import style as LHCb_style\nfrom .labels import LHCb_label\n\n__all__ = [\n    'LHCb_style',\n    'LHCb_label',\n]\n"""
rootpy/plotting/style/lhcb/labels.py,0,"b'# Copyright 2013 the rootpy developers\n\n""""""\nAdd an \'LHCb (Preliminary|Unofficial)\' label to plots.\n""""""\nfrom __future__ import absolute_import\n\nfrom .... import ROOT\nfrom ....context import preserve_current_canvas\nfrom ....memory.keepalive import keepalive\n\n__all__ = [\n    \'LHCb_label\',\n]\n\n\ndef LHCb_label(side=""L"", status=""final"", text="""", pad=None):\n    """"""Add an \'LHCb (Preliminary|Unofficial)\' label to the current pad.""""""\n\n    if pad is None:\n        pad = ROOT.gPad\n\n    with preserve_current_canvas():\n        pad.cd()\n        if side == ""L"":\n            l = ROOT.TPaveText(pad.GetLeftMargin() + 0.05,\n                               0.87 - pad.GetTopMargin(),\n                               pad.GetLeftMargin() + 0.30,\n                               0.95 - pad.GetTopMargin(),\n                               ""BRNDC"")\n        elif side == ""R"":\n            l = ROOT.TPaveText(0.70 - pad.GetRightMargin(),\n                               0.75 - pad.GetTopMargin(),\n                               0.95 - pad.GetRightMargin(),\n                               0.85 - pad.GetTopMargin(),\n                               ""BRNDC"")\n        else:\n            raise TypeError(""Unknown side \'{0}\'"".format(side))\n\n        if status == ""final"":\n            l.AddText(""LHCb"")\n        elif status == ""preliminary"":\n            l.AddText(""#splitline{LHCb}{#scale[1.0]{Preliminary}}"")\n        elif status == ""unofficial"":\n            l.AddText(""#splitline{LHCb}{#scale[1.0]{Unofficial}}"")\n        elif status == ""custom"":\n            l.AddText(text)\n        else:\n            raise TypeError(""Unknown status \'{0}\'"".format(status))\n\n        l.SetFillColor(0)\n        l.SetTextAlign(12)\n        l.SetBorderSize(0)\n        l.Draw()\n\n        keepalive(pad, l)\n\n        pad.Modified()\n        pad.Update()\n\n    return l, None\n'"
rootpy/plotting/style/lhcb/style.py,0,"b'# Copyright 2013 the rootpy developers\n\n""""""\nLHCb style from lhcbStyle.C\n""""""\nfrom __future__ import absolute_import\n\nfrom .. import Style\n\n__all__ = [\n    \'style\',\n]\n\n\ndef style(name=\'LHCb\'):\n\n    STYLE = Style(name, \'LHCb Style\')\n\n    font = 132\n    line_width = 2\n    text_size = 0.06\n\n    # Default canvas size and position.\n    STYLE.SetCanvasDefH(600)\n    STYLE.SetCanvasDefW(800)\n    STYLE.SetCanvasDefX(0)\n    STYLE.SetCanvasDefY(0)\n\n    # Colours.\n    STYLE.SetCanvasBorderMode(0)\n    STYLE.SetCanvasColor(0)\n    STYLE.SetFillColor(1)\n    STYLE.SetFillStyle(1001)\n    STYLE.SetFrameBorderMode(0)\n    STYLE.SetFrameFillColor(0)\n    STYLE.SetLegendBorderSize(0)\n    STYLE.SetPadBorderMode(0)\n    STYLE.SetPadColor(0)\n    STYLE.SetPalette(1)\n    STYLE.SetStatColor(0)\n\n    # Paper and margin sizes.\n    STYLE.SetPadBottomMargin(0.16)\n    STYLE.SetPadLeftMargin(0.14)\n    STYLE.SetPadRightMargin(0.05)\n    STYLE.SetPadTopMargin(0.05)\n    STYLE.SetPaperSize(20, 26)\n\n    # Font.\n    STYLE.SetLabelFont(font, ""x"")\n    STYLE.SetLabelFont(font, ""y"")\n    STYLE.SetLabelFont(font, ""z"")\n    STYLE.SetLabelSize(text_size, ""x"")\n    STYLE.SetLabelSize(text_size, ""y"")\n    STYLE.SetLabelSize(text_size, ""z"")\n    STYLE.SetTextFont(font)\n    STYLE.SetTextSize(text_size)\n    STYLE.SetTitleFont(font)\n    STYLE.SetTitleFont(font, ""x"")\n    STYLE.SetTitleFont(font, ""y"")\n    STYLE.SetTitleFont(font, ""z"")\n    STYLE.SetTitleSize(1.2*text_size, ""x"")\n    STYLE.SetTitleSize(1.2*text_size, ""y"")\n    STYLE.SetTitleSize(1.2*text_size, ""z"")\n\n    # Lines and markers.\n    STYLE.SetFrameLineWidth(line_width)\n    STYLE.SetFuncWidth(line_width)\n    STYLE.SetGridWidth(line_width)\n    STYLE.SetHistLineWidth(line_width)\n    STYLE.SetLineStyleString(2, ""[12 12]"")\n    STYLE.SetLineWidth(line_width)\n    STYLE.SetMarkerSize(1.0)\n    STYLE.SetMarkerStyle(20)\n\n    # Label offsets.\n    STYLE.SetLabelOffset(0.010, ""X"")\n    STYLE.SetLabelOffset(0.010, ""Y"")\n\n    # Decorations.\n    STYLE.SetOptFit(0)\n    STYLE.SetOptStat(0)\n    STYLE.SetOptTitle(0)\n    STYLE.SetStatFormat(""6.3g"")\n\n    # Titles.\n    STYLE.SetTitleBorderSize(0)\n    STYLE.SetTitleFillColor(0)\n    STYLE.SetTitleFont(font, ""title"")\n    STYLE.SetTitleH(0.05)\n    STYLE.SetTitleOffset(0.95, ""X"")\n    STYLE.SetTitleOffset(0.95, ""Y"")\n    STYLE.SetTitleOffset(1.2, ""Z"")\n    STYLE.SetTitleStyle(0)\n    STYLE.SetTitleW(1.0)\n    STYLE.SetTitleX(0.0)\n    STYLE.SetTitleY(1.0)\n\n    # Statistics box.\n    STYLE.SetStatBorderSize(0)\n    STYLE.SetStatFont(font)\n    STYLE.SetStatFontSize(0.05)\n    STYLE.SetStatH(0.15)\n    STYLE.SetStatW(0.25)\n    STYLE.SetStatX(0.9)\n    STYLE.SetStatY(0.9)\n\n    # Tick marks.\n    STYLE.SetPadTickX(1)\n    STYLE.SetPadTickY(1)\n\n    # Divisions: only 5 in x to avoid label overlaps.\n    STYLE.SetNdivisions(505, ""x"")\n    STYLE.SetNdivisions(510, ""y"")\n\n    return STYLE\n'"
rootpy/plotting/style/lhcb/test.py,0,"b'# Copyright 2013 the rootpy developers\n\nimport ROOT\nfrom rootpy.plotting import Canvas, Hist\nfrom rootpy.plotting.style import get_style\nfrom rootpy.plotting.style.lhcb.labels import LHCb_label\nfrom rootpy.interactive import wait\n\nINTERACTIVE = False\n\n""""""\ndef test_lhcb():\n    style = get_style(\'LHCb\')\n    with style:\n        canvas = Canvas()\n        hpx = Hist(100, -4, 4, name=""hpx"", title=""This is the px distribution"")\n        ROOT.gRandom.SetSeed()\n        for i in range(1000):\n            hpx.Fill(ROOT.gRandom.Gaus())\n        hpx.GetXaxis().SetTitle(""random variable [unit]"")\n        hpx.GetYaxis().SetTitle(""#frac{dN}{dr} [unit^{-1}]"")\n        hpx.SetMaximum(80.)\n        hpx.Draw()\n        LHCb_label(""R"", ""preliminary"")\n        if INTERACTIVE:\n            wait()\n""""""\n\nif __name__ == ""__main__"":\n    import nose\n    INTERACTIVE = True\n    nose.runmodule()\n'"
rootpy/plotting/style/tests/__init__.py,0,b''
rootpy/plotting/style/tests/test_style.py,0,"b'from rootpy.plotting.style import Style, get_style\nfrom ROOT import TStyle\n\n\ndef test_get_style():\n\n    mystyle = TStyle(\'mystyle\', \'some style\')\n    assert(isinstance(get_style(\'mystyle\'), Style))\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
rootpy/stats/histfactory/tests/__init__.py,0,b''
rootpy/stats/histfactory/tests/test_histfactory.py,0,"b'from nose.plugins.skip import SkipTest\n\ntry:\n    from rootpy.stats import mute_roostats; mute_roostats()\nexcept ImportError:\n    raise SkipTest(""ROOT is not compiled with RooFit and RooStats enabled"")\n\nfrom rootpy.io import TemporaryFile\nfrom rootpy.plotting import Hist\nfrom rootpy.decorators import requires_ROOT\nfrom rootpy.stats.histfactory import *\nfrom rootpy.stats import histfactory\n\nfrom nose.plugins.attrib import attr\nfrom nose.tools import assert_raises, assert_equal, assert_true\n\n\ndef get_random_hist():\n    h = Hist(10, -5, 5)\n    h.FillRandom(\'gaus\')\n    return h\n\n@requires_ROOT(histfactory.MIN_ROOT_VERSION, exception=SkipTest)\ndef test_histfactory():\n\n    # create some Samples\n    data = Data(\'data\')\n    data.hist = get_random_hist()\n    a = Sample(\'QCD\')\n    b = Sample(\'QCD\')\n\n    for sample in (a, b):\n        sample.hist = get_random_hist()\n        # include some histosysts\n        for sysname in (\'x\', \'y\', \'z\'):\n            histosys = HistoSys(sysname)\n            histosys.high = get_random_hist()\n            histosys.low = get_random_hist()\n            sample.AddHistoSys(histosys)\n        # include some normfactors\n        for normname in (\'x\', \'y\', \'z\'):\n            norm = NormFactor(normname)\n            norm.value = 1\n            norm.high = 2\n            norm.low = 0\n            norm.const = False\n            sample.AddNormFactor(norm)\n\n    # samples must be compatible here\n    c = a + b\n    c = sum([a, b])\n\n    # create Channels\n    channel_a = Channel(\'VBF\')\n    channel_a.data = data\n    channel_a.AddSample(a)\n\n    channel_b = Channel(\'VBF\')\n    channel_b.data = data\n    channel_b.AddSample(b)\n\n    combined_channel = channel_a + channel_b\n    combined_channel = sum([channel_a, channel_b])\n\n    # create a Measurement\n    meas = Measurement(\'MyAnalysis\')\n    meas.AddChannel(channel_a)\n\n    # create the workspace containing the model\n    workspace = make_workspace(meas, silence=True)\n    with TemporaryFile():\n        workspace.Write()\n\n    assert_true(channel_a.GetSample(a.name) is not None)\n    channel_a.RemoveSample(a.name)\n    assert_true(channel_a.GetSample(a.name) is None)\n\n    assert_true(meas.GetChannel(channel_a.name) is not None)\n    meas.RemoveChannel(channel_a.name)\n    assert_true(meas.GetChannel(channel_a.name) is None)\n\n    # test split_norm_shape\n    nominal = Hist(1, 0, 1)\n    nominal.FillRandom(\'gaus\')\n    hsys = HistoSys(\'shape\', high=nominal * 1.5, low=nominal * 0.9)\n    norm, shape = split_norm_shape(hsys, nominal)\n    assert_equal(norm.low, 0.9)\n    assert_equal(norm.high, 1.5)\n    assert_equal(shape.high[1].value, nominal[1].value)\n    assert_equal(shape.low[1].value, nominal[1].value)\n\n\nif __name__ == ""__main__"":\n    import nose\n    nose.runmodule()\n'"
