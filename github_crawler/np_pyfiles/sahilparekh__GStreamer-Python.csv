file_path,api_count,code
main_prg.py,0,"b'\n\'\'\'\\\nThis Simple program Demonstrates how to use G-Streamer and capture RTSP Frames in Opencv using Python\n- Sahil Parekh\n\'\'\'\n\nimport multiprocessing as mp\nimport time\nimport vid_streamv3 as vs\nimport cv2\nimport sys\n\n\'\'\'\nMain class\n\'\'\'\nclass mainStreamClass:\n    def __init__(self):\n\n        #Current Cam\n        self.camProcess = None\n        self.cam_queue = None\n        self.stopbit = None\n        self.camlink = \'\' #Add your RTSP cam link\n        self.framerate = 6\n    \n    def startMain(self):\n\n        #set  queue size\n        self.cam_queue = mp.Queue(maxsize=100)\n\n        #get all cams\n        time.sleep(3)\n\n        self.stopbit = mp.Event()\n        self.camProcess = vs.StreamCapture(self.camlink,\n                             self.stopbit,\n                             self.cam_queue,\n                            self.framerate)\n        self.camProcess.start()\n\n        # calculate FPS\n        lastFTime = time.time()\n\n        try:\n            while True:\n\n                if not self.cam_queue.empty():\n                    # print(\'Got frame\')\n                    cmd, val = self.cam_queue.get()\n\n                    \'\'\'\n                    #calculate FPS\n                    diffTime = time.time() - lastFTime`\n                    fps = 1 / diffTime\n                    # print(fps)\n                    \n                    \'\'\'\n                    lastFTime = time.time()\n\n                    # if cmd == vs.StreamCommands.RESOLUTION:\n                    #     pass #print(val)\n\n                    if cmd == vs.StreamCommands.FRAME:\n                        if val is not None:\n                            cv2.imshow(\'Cam: \' + self.camlink, val)\n                            cv2.waitKey(1)\n\n        except KeyboardInterrupt:\n            print(\'Caught Keyboard interrupt\')\n\n        except:\n            e = sys.exc_info()\n            print(\'Caught Main Exception\')\n            print(e)\n\n        self.stopCamStream()\n        cv2.destroyAllWindows()\n\n\n    def stopCamStream(self):\n        print(\'in stopCamStream\')\n\n        if self.stopbit is not None:\n            self.stopbit.set()\n            while not self.cam_queue.empty():\n                try:\n                    _ = self.cam_queue.get()\n                except:\n                    break\n                self.cam_queue.close()\n\n            self.camProcess.join()\n\n\nif __name__ == ""__main__"":\n    mc = mainStreamClass()\n    mc.startMain()'"
vid_streamv3.py,2,"b'#cython: language_level=3, boundscheck=False\nimport multiprocessing as mp\nfrom enum import Enum\nimport numpy as np\nimport gi\ngi.require_version(\'Gst\', \'1.0\')\nfrom gi.repository import Gst\nGst.init(None)\n\n\'\'\'Konwn issues\n\n* if format changes at run time system hangs\n\'\'\'\n\nclass StreamMode(Enum):\n    INIT_STREAM = 1\n    SETUP_STREAM = 1\n    READ_STREAM = 2\n\n\nclass StreamCommands(Enum):\n    FRAME = 1\n    ERROR = 2\n    HEARTBEAT = 3\n    RESOLUTION = 4\n    STOP = 5\n\n\nclass StreamCapture(mp.Process):\n\n    def __init__(self, link, stop, outQueue, framerate):\n        """"""\n        Initialize the stream capturing process\n        link - rstp link of stream\n        stop - to send commands to this process\n        outPipe - this process can send commands outside\n        """"""\n\n        super().__init__()\n        self.streamLink = link\n        self.stop = stop\n        self.outQueue = outQueue\n        self.framerate = framerate\n        self.currentState = StreamMode.INIT_STREAM\n        self.pipeline = None\n        self.source = None\n        self.decode = None\n        self.convert = None\n        self.sink = None\n        self.image_arr = None\n        self.newImage = False\n        self.frame1 = None\n        self.frame2 = None\n        self.num_unexpected_tot = 40\n        self.unexpected_cnt = 0\n\n\n\n    def gst_to_opencv(self, sample):\n        buf = sample.get_buffer()\n        caps = sample.get_caps()\n\n        # Print Height, Width and Format\n        # print(caps.get_structure(0).get_value(\'format\'))\n        # print(caps.get_structure(0).get_value(\'height\'))\n        # print(caps.get_structure(0).get_value(\'width\'))\n\n        arr = np.ndarray(\n            (caps.get_structure(0).get_value(\'height\'),\n             caps.get_structure(0).get_value(\'width\'),\n             3),\n            buffer=buf.extract_dup(0, buf.get_size()),\n            dtype=np.uint8)\n        return arr\n\n    def new_buffer(self, sink, _):\n        sample = sink.emit(""pull-sample"")\n        arr = self.gst_to_opencv(sample)\n        self.image_arr = arr\n        self.newImage = True\n        return Gst.FlowReturn.OK\n\n    def run(self):\n        # Create the empty pipeline\n        self.pipeline = Gst.parse_launch(\n            \'rtspsrc name=m_rtspsrc ! rtph264depay name=m_rtph264depay ! avdec_h264 name=m_avdech264 ! videoconvert name=m_videoconvert ! videorate name=m_videorate ! appsink name=m_appsink\')\n\n        # source params\n        self.source = self.pipeline.get_by_name(\'m_rtspsrc\')\n        self.source.set_property(\'latency\', 0)\n        self.source.set_property(\'location\', self.streamLink)\n        self.source.set_property(\'protocols\', \'tcp\')\n        self.source.set_property(\'retry\', 50)\n        self.source.set_property(\'timeout\', 50)\n        self.source.set_property(\'tcp-timeout\', 5000000)\n        self.source.set_property(\'drop-on-latency\', \'true\')\n\n        # decode params\n        self.decode = self.pipeline.get_by_name(\'m_avdech264\')\n        self.decode.set_property(\'max-threads\', 2)\n        self.decode.set_property(\'output-corrupt\', \'false\')\n\n        # convert params\n        self.convert = self.pipeline.get_by_name(\'m_videoconvert\')\n\n        #framerate parameters\n        self.framerate_ctr = self.pipeline.get_by_name(\'m_videorate\')\n        self.framerate_ctr.set_property(\'max-rate\', self.framerate/1)\n        self.framerate_ctr.set_property(\'drop-only\', \'true\')\n\n        # sink params\n        self.sink = self.pipeline.get_by_name(\'m_appsink\')\n\n        # Maximum number of nanoseconds that a buffer can be late before it is dropped (-1 unlimited)\n        # flags: readable, writable\n        # Integer64. Range: -1 - 9223372036854775807 Default: -1\n        self.sink.set_property(\'max-lateness\', 500000000)\n\n        # The maximum number of buffers to queue internally (0 = unlimited)\n        # flags: readable, writable\n        # Unsigned Integer. Range: 0 - 4294967295 Default: 0\n        self.sink.set_property(\'max-buffers\', 5)\n\n        # Drop old buffers when the buffer queue is filled\n        # flags: readable, writable\n        # Boolean. Default: false\n        self.sink.set_property(\'drop\', \'true\')\n\n        # Emit new-preroll and new-sample signals\n        # flags: readable, writable\n        # Boolean. Default: false\n        self.sink.set_property(\'emit-signals\', True)\n\n        # # sink.set_property(\'drop\', True)\n        # # sink.set_property(\'sync\', False)\n\n        # The allowed caps for the sink pad\n        # flags: readable, writable\n        # Caps (NULL)\n        caps = Gst.caps_from_string(\n            \'video/x-raw, format=(string){BGR, GRAY8}; video/x-bayer,format=(string){rggb,bggr,grbg,gbrg}\')\n        self.sink.set_property(\'caps\', caps)\n\n        if not self.source or not self.sink or not self.pipeline or not self.decode or not self.convert:\n            print(""Not all elements could be created."")\n            self.stop.set()\n\n        self.sink.connect(""new-sample"", self.new_buffer, self.sink)\n\n        # Start playing\n        ret = self.pipeline.set_state(Gst.State.PLAYING)\n        if ret == Gst.StateChangeReturn.FAILURE:\n            print(""Unable to set the pipeline to the playing state."")\n            self.stop.set()\n\n        # Wait until error or EOS\n        bus = self.pipeline.get_bus()\n\n        while True:\n\n            if self.stop.is_set():\n                print(\'Stopping CAM Stream by main process\')\n                break\n\n            message = bus.timed_pop_filtered(10000, Gst.MessageType.ANY)\n            # print ""image_arr: "", image_arr\n            if self.image_arr is not None and self.newImage is True:\n\n                if not self.outQueue.full():\n\n                    # print(""\\r adding to queue of size{}"".format(self.outQueue.qsize()), end=\'\\r\')\n                    self.outQueue.put((StreamCommands.FRAME, self.image_arr), block=False)\n\n                self.image_arr = None\n                self.unexpected_cnt = 0\n\n\n            if message:\n                if message.type == Gst.MessageType.ERROR:\n                    err, debug = message.parse_error()\n                    print(""Error received from element %s: %s"" % (\n                        message.src.get_name(), err))\n                    print(""Debugging information: %s"" % debug)\n                    break\n                elif message.type == Gst.MessageType.EOS:\n                    print(""End-Of-Stream reached."")\n                    break\n                elif message.type == Gst.MessageType.STATE_CHANGED:\n                    if isinstance(message.src, Gst.Pipeline):\n                        old_state, new_state, pending_state = message.parse_state_changed()\n                        print(""Pipeline state changed from %s to %s."" %\n                              (old_state.value_nick, new_state.value_nick))\n                else:\n                    print(""Unexpected message received."")\n                    self.unexpected_cnt = self.unexpected_cnt + 1\n                    if self.unexpected_cnt == self.num_unexpected_tot:\n                        break\n\n\n        print(\'terminating cam pipe\')\n        self.stop.set()\n        self.pipeline.set_state(Gst.State.NULL)'"
