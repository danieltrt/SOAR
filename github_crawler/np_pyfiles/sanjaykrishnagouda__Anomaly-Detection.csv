file_path,api_count,code
cc.py,12,"b'import numpy as np\nimport pandas as pd\nimport operator\nimport tensorflow as tf\nfrom sklearn import linear_model\nfrom sklearn.svm import SVC \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV,train_test_split,KFold, cross_val_score\nimport sklearn,matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report\ndef load(str):\n\tdata = pd.read_csv(str)\n\t# dropping two columns : \n\tdata[\'normAmount\'] = StandardScaler().fit_transform(data[\'Amount\'].values.reshape(-1,1))\n\tdata = data.drop([\'Time\',\'Amount\'], axis = 1)\n\tx = data.ix[:,data.columns != \'Class\']\n\ty = data.ix[:,data.columns == \'Class\']\n\treturn data,x,y\n\ndef sampling_data(matrix, input, output):\n\t\n\ta = matrix[matrix.Class ==1]\n\tnumber_records_fraud = len(a)\n\tfraud_indices = np.array(a.index)\n\n\t# picking normal classes\n\n\tnonfraud_indices = matrix[matrix.Class == 0].index\n\n\t# selecting fraud number of normal samples\n\trandom_normal_samples = np.random.choice(nonfraud_indices,\n\t\tnumber_records_fraud,replace = False)\n\trandom_normal_samples = np.array(random_normal_samples)\n\n\tunder_sample_indices = np.concatenate([fraud_indices,random_normal_samples])\n\n\t# collecting corresponding data\n\n\tunder_sample_data = matrix.iloc[under_sample_indices,:]\n\tX_undersample = under_sample_data.ix[:, under_sample_data.columns != \'Class\']\n\ty_undersample = under_sample_data.ix[:, under_sample_data.columns == \'Class\']\n\t#print(""Percentage of normal transactions: "", len(under_sample_data[under_sample_data.Class == 0])/len(under_sample_data))\n\t#print(""Resampled data:"", len(under_sample_data[under_sample_data.Class == 1])/len(under_sample_data))\n\t#print(""Total number of transactions in resampled data: "", len(under_sample_data)) # so we now have equal number of \n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  # fraud and normal examples!\n\n\t#splitting entire dataset into training and testing blocks\n\n\tX_train, X_test, y_train, y_test = train_test_split(input,output,test_size = 0.3, random_state = 0)\n\t#print(\'training block size: %i\\ntesting block size: %i\\ntotal: %i samples\'%(len(X_train),len(X_test),len(X_train)+len(X_test)))\n\n\t#splitting undersampled dataset similarly\n\tX_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample,y_undersample,\n\t\ttest_size = 0.3, random_state = 0)\n\t#print(\'For the undersampled data:\\n training block size: %i\\ntesting block size: %i\\ntotal: %i samples\'\n\t\t#%(len(X_train_undersample),len(X_test_undersample),len(X_train_undersample)+len(X_test_undersample)))\n\n\treturn(X_train,y_train,X_train_undersample,y_train_undersample)\n\ndef printing_Kfold_scores(x_train_data,y_train_data):\n   \t\n    kf = KFold(n_splits = 7)\n    # Different C parameters, C = 1/lambda \n    #c_param_range = [0.0001,0.001,0.01,0.1,1,10,100]\n\n    c_param_range = []\n    \n    t=0.0000001\n    while t<=10:\n    \tc_param_range.append(t)\n    \tt*=10\n\n\n    results_table = pd.DataFrame(index = range(len(c_param_range),2), columns = [\'C_parameter\',\'Mean recall score\'])\n    results_table[\'C_parameter\'] = c_param_range\n    results_table_svm = pd.DataFrame(index = range(len(c_param_range),2), columns = [\'C_parameter\',\'Mean recall score\'])\n    results_table_svm[\'C_parameter\'] = c_param_range\n    # the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n    j = 0\n    recall_dict={}\n    recall_dict_svm={}\n    for c_param in c_param_range:\n        #print(\'-------------------------------------------\')\n        #print(\'C parameter: \', c_param)\n        #print(\'-------------------------------------------\')\n        #print(\'\')\n\n        recall_accs = []\n        recall_accs_svm = []\n        for iteration, (train,test) in enumerate(kf.split(x_train_data,y_train_data)):\n        \t\n            lr = LogisticRegression(C = c_param, penalty = \'l2\')\n            lr.fit(x_train_data.iloc[train],y_train_data.iloc[train].values.ravel())\n            #clf = SVC(C = c_param, kernel = \'rbf\')\n            #clf.fit(x_train_data.iloc[train],y_train_data.iloc[train].values.ravel())\n\n            # Predict values using the test indices in the training data\n            y_pred_undersample = lr.predict(x_train_data.iloc[test].values)\n            #y_pred_undersample_svm = clf.predict(x_train_data.iloc[test].values)\n\n\n            # Calculate the recall score and append it to a list for recall scores representing the current c_parameter\n            recall_acc = recall_score(y_train_data.iloc[test].values,y_pred_undersample)\n            recall_accs.append(recall_acc)\n            \n            #recall_acc_svm = recall_score(y_train_data.iloc[test].values,y_pred_undersample_svm)\n            #recall_accs_svm.append(recall_acc_svm)\n            #print(\'Iteration \', iteration,\': recall score = \', recall_acc)\n\n        # The mean value of those recall scores is the metric we want to save and get hold of.\n        \n        recall_dict[c_param]=np.mean(recall_accs)\n        results_table.ix[j,\'Mean recall score\'] = np.mean(recall_accs)\n        \n        #recall_dict_svm[c_param]=np.mean(recall_accs_svm)\n        #results_table_svm.ix[j,\'Mean recall score\'] = np.mean(recall_accs_svm)\n        j += 1\n        #print(\'\')\n        #print(\'Mean recall score using log reg\', np.mean(recall_accs))\n        #print(\'Mean recall score using SVM\', np.mean(recall_accs_svm))\n        #print(\'\')\n\n    best_c = results_table.loc[results_table[\'Mean recall score\'].idxmax()][\'C_parameter\']\n    print(""USING Logistic Regression::\\nBest Mean: %f with inverse regularization strength %.4f""%(max(recall_dict.items(),key = operator.itemgetter(1))[1],\n    \tmax(recall_dict.items(),key = operator.itemgetter(1))[0]))\n\n    #best_c_svm = results_table_svm.loc[results_table_svm[\'Mean recall score\'].idxmax()][\'C_parameter\']\n    #print(""USING SVM :\\nBest Mean: %f with inverse regularization strength %.4f""%(max(recall_dict_svm.items(),key = operator.itemgetter(1))[1],\n    \t#max(recall_dict_svm.items(),key = operator.itemgetter(1))[0]))\n    # Finally, we can check which C parameter is the best amongst the chosen.\n    #print(\'*********************************************************************************\')\n    #print(\'Best model to choose from cross validation is with C parameter = \', best_c)\n    #print(\'*********************************************************************************\')\n    #print(\'Best Mean Recall Score is :%i\\n\'%(results_table[best_c]))\n    #lists = sorted(recall_dict_svm.items())\n    #x,y = zip(*lists)\n    lists2 = sorted(recall_dict.items())\n    x2,y2 = zip(*lists2)\n    #plt.plot(x,y)\n    #plt.ion()\n    plt.plot(x2,y2)\n    plt.legend([\'Logistic Regression\'],loc=\'lower right\')\n    plt.show()\n    #return best_c,best_c_svm\n    return best_c\n\n\n\ndef using_SVM(x_train_data,y_train_data,k):\n    kernel = str(k)\n    kf = KFold(n_splits = 5)\n    c_param_range = []\n    t=0.0001\n    while t<=1000:\n    \tc_param_range.append(t)\n    \tt*=2\n\n\n    results_table_svm = pd.DataFrame(index = range(len(c_param_range),2), columns = [\'C_parameter\',\'Mean recall score\'])\n    results_table_svm[\'C_parameter\'] = c_param_range\n    # the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n    j = 0\n    recall_dict={}\n    recall_dict_svm={}\n    for c_param in c_param_range:\n        \n        #print(\'C parameter: \', c_param)\n        \n        recall_accs_svm = []\n        for iteration, (train,test) in enumerate(kf.split(x_train_data,y_train_data)):\n        \t\n            clf = SVC(C = c_param, kernel = kernel)\n            clf.fit(x_train_data.iloc[train],y_train_data.iloc[train].values.ravel())\n\n            y_pred_undersample_svm = clf.predict(x_train_data.iloc[test].values)\n            \n            recall_acc_svm = recall_score(y_train_data.iloc[test].values,y_pred_undersample_svm)\n            recall_accs_svm.append(recall_acc_svm)\n            \n        \n        recall_dict_svm[c_param]=np.mean(recall_accs_svm)\n        results_table_svm.ix[j,\'Mean recall score\'] = np.mean(recall_accs_svm)\n        j += 1\n    \n\n    best_c_svm = results_table_svm.loc[results_table_svm[\'Mean recall score\'].idxmax()][\'C_parameter\']\n    print(""USING SVM :\\nBest Mean: %f with inverse regularization strength %.4f using %s kernel""%(max(recall_dict_svm.items(),key = operator.itemgetter(1))[1],\n    \tmax(recall_dict_svm.items(),key = operator.itemgetter(1))[0],kernel))\n    return recall_dict_svm,best_c_svm\n\n\n\ndef diff_kerns(x,y):\n\tkernels = [\'rbf\',\'linear\',\'sigmoid\',\'poly\']\n\tarr =[]\n\tfor i in kernels:\n\t\ta=using_SVM(x,y,i)\n\t\ttemp_dict,temp_best = a[0],a[1]\n\t\tarr.append(temp_dict[temp_best])\n\t#plt.hist(arr)\n\t#plt.xticks(arr,kernels)\n\t#plt.plot([1,2,3,4],arr)\n\t#plt.bar([1,2,3,4],arr, align = \'center\')\n\tplt.scatter([1,2,3,4],arr)\n\tplt.xticks([1,2,3,4],kernels)\n\tplt.ylabel(""Mean Recall of 7 iterations"")\n\tplt.show()\n\t\n\n\na,b,c = load(\'creditcard.csv\')\ntemp = sampling_data(a,b,c)\n#printing_Kfold_scores(temp[0],temp[1]) # USING COMPLETE DATASET\nprinting_Kfold_scores(temp[2],temp[3]) # USING UNDERSAMPLED DATASET\n#using_SVM(temp[2],temp[3])\ndiff_kerns(temp[2],temp[3])'"
cc_2.py,8,"b'import warnings\nwarnings.filterwarnings(""ignore"", category = RuntimeWarning)\nimport numpy as np\nimport time\nimport pandas as pd\nimport operator\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier\nfrom sklearn import linear_model\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV,train_test_split,KFold, cross_val_score\nimport sklearn,matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report\nfrom sklearn.utils.testing import ignore_warnings, assert_raises\ndef load(str):\n\tdata = pd.read_csv(str)\n\t# dropping two columns : \n\tdata[\'normAmount\'] = StandardScaler().fit_transform(data[\'Amount\'].values.reshape(-1,1))\n\tdata = data.drop([\'Time\',\'Amount\'], axis = 1)\n\tx = data.ix[:,data.columns != \'Class\']\n\ty = data.ix[:,data.columns == \'Class\']\n\treturn data,x,y\n\ndef sampling_data(matrix, input, output):\n\t\n\ta = matrix[matrix.Class ==1]\n\tnumber_records_fraud = len(a)\n\tfraud_indices = np.array(a.index)\n\n\t# picking normal classes\n\n\tnonfraud_indices = matrix[matrix.Class == 0].index\n\n\t# selecting fraud number of normal samples\n\trandom_normal_samples = np.random.choice(nonfraud_indices,\n\t\tnumber_records_fraud,replace = False)\n\trandom_normal_samples = np.array(random_normal_samples)\n\n\tunder_sample_indices = np.concatenate([fraud_indices,random_normal_samples])\n\n\t# collecting corresponding data\n\n\tunder_sample_data = matrix.iloc[under_sample_indices,:]\n\tX_undersample = under_sample_data.ix[:, under_sample_data.columns != \'Class\']\n\ty_undersample = under_sample_data.ix[:, under_sample_data.columns == \'Class\']\n\n\n\tX_train, X_test, y_train, y_test = train_test_split(input,output,test_size = 0.3, random_state = 0)\n\n\tX_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample,y_undersample,\n\t\ttest_size = 0.3, random_state = 0)\n\n\treturn(X_train,y_train,X_train_undersample,y_train_undersample)\n@ignore_warnings\ndef printing_Kfold_scores(x_train_data,y_train_data): # LOGISTIC REGRESSION WITH 7 FOLD CV\n\tstart = time.time()\n\tkf = KFold(n_splits = 7)\n\tc_param_range,t = [],0.0001\n\t#t=0.0001\n\twhile t<=pow(10,1):\n\t\tc_param_range.append(t)\n\t\tt*=10\n\n\n\tresults_table = pd.DataFrame(index = range(len(c_param_range),2), columns = [\'C_parameter\',\'Mean recall score\'])\n\tresults_table[\'C_parameter\'] = c_param_range\n\tresults_table_svm = pd.DataFrame(index = range(len(c_param_range),2), columns = [\'C_parameter\',\'Mean recall score\'])\n\tresults_table_svm[\'C_parameter\'] = c_param_range\n\t# the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n\tj = 0\n\trecall_dict={}\n\trecall_dict_svm={}\n\tfor c_param in c_param_range:\n\n\t\trecall_accs = []\n\t\trecall_accs_svm = []\n\t\tfor iteration, (train,test) in enumerate(kf.split(x_train_data,y_train_data)):\n\t\t\tlr = LogisticRegression(C = c_param, penalty = \'l2\')\n\t\t\tlr.fit(x_train_data.iloc[train],y_train_data.iloc[train].values.ravel())\n\t\t\ty_pred_undersample = lr.predict(x_train_data.iloc[test].values)\n\t\t\t# Calculate the recall score and append it to a list for recall scores representing the current c_parameter\n\t\t\trecall_acc = recall_score(y_train_data.iloc[test].values,y_pred_undersample)\n\t\t\trecall_accs.append(recall_acc)\n\t        \n\n\t\trecall_dict[c_param]=np.mean(recall_accs)\n\t\tresults_table.ix[j,\'Mean recall score\'] = np.mean(recall_accs)\n\n\t\tj += 1\n\n\n\tbest_c = results_table.loc[results_table[\'Mean recall score\'].idxmax()][\'C_parameter\']\n\tprint(""USING Logistic Regression::\\nBest Mean: %f with inverse regularization strength %f""%(max(recall_dict.items(),key = operator.itemgetter(1))[1],\n\t\tmax(recall_dict.items(),key = operator.itemgetter(1))[0]))\n\n\n\tlists2 = sorted(recall_dict.items())\n\tx2,y2 = zip(*lists2)\n\tplt.plot(x2,y2)\n\tplt.legend([\'Logistic Regression\'],loc=\'lower right\')\n\tplt.draw()\n\t#return best_c,best_c_svm\n\tend = time.time()\n\tprint(""Logistic regressions took"",end-start)\n\treturn best_c\n\n\n@ignore_warnings\ndef using_SVM(x_train_data,y_train_data,k):\n\tkernel = str(k)\n\tkf = KFold(n_splits = 5)\n\tc_param_range = []\n\tt=0.01\n\twhile t<=2:\n\t\tc_param_range.append(t)\n\t\tt*=2\n\n\n\tresults_table_svm = pd.DataFrame(index = range(len(c_param_range),2), columns = [\'C_parameter\',\'Mean recall score\'])\n\tresults_table_svm[\'C_parameter\'] = c_param_range\n\t# the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n\tj = 0\n\t\n\trecall_dict_svm={}\n\tfor c_param in c_param_range:\n\t\t\n\t\t#print(\'C parameter: \', c_param,\'\\t kernel\',kernel)\n\t\t\n\t\trecall_accs_svm = []\n\t\tfor iteration, (train,test) in enumerate(kf.split(x_train_data,y_train_data)):\n\t\t\tif kernel!=\'linear\':\n\t\t\t\tclf = BaggingClassifier(SVC(C = c_param, kernel = kernel, verbose = False, max_iter = 1000),n_jobs=-1)\n\t\t\tif kernel == \'linear\':\n\t\t\t\tclf = BaggingClassifier(LinearSVC(C = c_param, max_iter = 1000), n_jobs = 2)\n\t\t\tclf.fit(x_train_data.iloc[train],y_train_data.iloc[train].values.ravel())\n\n\t\t\ty_pred_undersample_svm = clf.predict(x_train_data.iloc[test].values)\n\n\t\t\trecall_acc_svm = recall_score(y_train_data.iloc[test].values,y_pred_undersample_svm)\n\t\t\trecall_accs_svm.append(recall_acc_svm)\n\n\n\t\trecall_dict_svm[c_param]=np.mean(recall_accs_svm)\n\t\tresults_table_svm.ix[j,\'Mean recall score\'] = np.mean(recall_accs_svm)\n\t\tj += 1\n\n\n\tbest_c_svm = results_table_svm.loc[results_table_svm[\'Mean recall score\'].idxmax()][\'C_parameter\']\n\tprint(""USING SVM :\\nBest Mean: %f with inverse regularization strength %.4f using %s kernel""%(max(recall_dict_svm.items(),key = operator.itemgetter(1))[1],\n\t\tmax(recall_dict_svm.items(),key = operator.itemgetter(1))[0],kernel))\n\treturn recall_dict_svm,best_c_svm\n\n\n@ignore_warnings\ndef diff_kerns(x,y):\n\t\n\tkernels = [\'rbf\',\'linear\',\'sigmoid\',\'poly\']\n\t\n\tarr =[]\n\tfor i in kernels:\n\t\tstart = time.time()\n\t\tprint(""currently running "",i,""kernel"")\n\t\ta=using_SVM(x,y,i)\n\t\ttemp_dict,temp_best = a[0],a[1]\n\t\tarr.append(temp_dict[temp_best])\n\t\tend = time.time()\n\t\tprint(i,""took %.2f seconds for completion.""%(end-start))\n\tplt.scatter([1,2,3,4],arr)\n\tplt.xticks([1,2,3,4],kernels)\n\tplt.ylabel(""Mean Recall of 7 iterations"")\n\t\n\tplt.show()\n\t\ndef RandomForest(x,y):\n\t#first lets try GMM\n\tpass\ndef main(_):\t\n\ta,b,c = load(\'creditcard.csv\')\n\ttemp = sampling_data(a,b,c)\n\t#printing_Kfold_scores(temp[0],temp[1]) # USING COMPLETE DATASET Logistic Regression\n\tdiff_kerns(temp[0],temp[1]) # SVM with various kernels on complete dataset.\n\t#printing_Kfold_scores(temp[2],temp[3]) # USING UNDERSAMPLED DATASET Logistic Regression\n\t#diff_kerns(temp[2],temp[3]) # SVM with various kernels, run for 5 iterations\n\t#\nif __name__ == ""__main__"":\n\tmain(2)'"
