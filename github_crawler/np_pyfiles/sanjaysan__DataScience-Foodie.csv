file_path,api_count,code
Classifiers/DecisionTree.py,5,"b'import numpy as np\nfrom sklearn import tree\nfrom sklearn.model_selection import KFold\n\n# Training features(x) and labels(y)\nx = np.load(\'../Data/Training/features.npy\')\ny = np.load(\'../Data/Training/target_label.npy\')\n\n# Setting up 10-fold cross validation\nkf = KFold(n_splits=10)\nkf.get_n_splits(x)\n\nprecisionSum, recallSum = 0, 0\nfor train, test in kf.split(x):\n    # Initializing the Decision Tree Classifier\n    clf = tree.DecisionTreeClassifier(max_depth=8)\n\n    # Fitting the training data on the model\n    clf.fit(x[train], y[train])\n\n    # Prediciting the test label\n    predicted_label = clf.predict(x[test])\n\n    # Calculating out the number of positive predictions\n    num_pos_predictions = (predicted_label == 1).sum()\n\n    num_correct_pos_predictions = 0.0\n    for i in range(len(predicted_label)):\n        # Comparing the predicted label with the test label to find out the number of correct\n        # positive predictions\n        if predicted_label[i] == 1 and predicted_label[i] == y[test][i]:\n            num_correct_pos_predictions += 1\n\n    # Calculating out the number of actual positives\n    num_actual_positives = (y[test] == 1).sum()\n\n    # Calculating precision and recall for each fold\n    precision = (num_correct_pos_predictions * 100 / num_pos_predictions)\n    recall = (num_correct_pos_predictions * 100 / num_actual_positives)\n\n    precisionSum = precisionSum + precision\n    recallSum = recallSum + recall\n\n# Calculating the average precision and recall\nprecisionAvg = precisionSum / 10\nrecallAvg = recallSum / 10\nprint ""Precision: "", precisionAvg\nprint ""Recall: "", recallAvg\n\n# Calculating the F1 Measure as (2 PR)/ (P + R)\nf1 = (2 * precisionAvg * recallAvg) / (recallAvg + precisionAvg)\nprint ""F1 Measure: "", f1\n# import numpy as np\n# from sklearn import svm\n# from sklearn.model_selection import KFold\n# from sklearn import tree\n# from sklearn.naive_bayes import GaussianNB\n# import pydotplus\n# import os\n#\n# features = np.load(\'../Data/Training/features.npy\')\n# labels = np.load(\'../Data/Training/target_label.npy\')\n# training_words = np.load(\'../Data/Training/training_words.npy\')\n#\n# clf = tree.DecisionTreeClassifier()\n# clf = clf.fit(features, labels)\n#\n# clf.predict(features)\n#\n# with open(""iris.dot"", \'w\') as f:\n#     f = tree.export_graphviz(clf, out_file=f)\n'"
Classifiers/LinearRegression.py,5,"b'import numpy as np\nfrom sklearn import linear_model\nfrom sklearn.model_selection import KFold\n\n# Training features(x) and labels(y)\nx = np.load(\'../Data/Training/features.npy\')\ny = np.load(\'../Data/Training/target_label.npy\')\n\n# Initializing the Linear Regression Classifier\nclf = linear_model.LinearRegression()\n# Setting up 10-fold cross validation\nkf = KFold(n_splits=10)\n\nprecision, recall = [], []\nfor train, test in kf.split(x):\n    # Fitting the training data on the model\n    clf.fit(x[train], y[train])\n\n    # Selecting only those features for which the predicted value is above the threshold 0.705\n    predicted_label = [1 if predicted_val > 0.703 else 0 for predicted_val in clf.predict(x[test])]\n    num_correct_pos_predictions = 0.0\n\n    # Calculating out the number of positive predictions\n    num_pos_predictions = np.sum(predicted_label)\n    for i in range(len(predicted_label)):\n        # Comparing the predicted label with the test label to find out the number of correct\n        # positive predictions\n        if predicted_label[i] == 1 and y[test][i] == 1:\n            num_correct_pos_predictions += 1\n\n    # Calculating out the number of actual positives\n    num_actual_positives = (y[test] == 1).sum()\n\n    # Calculating precision and recall for each fold\n    precision.append(((num_correct_pos_predictions / num_pos_predictions) * 100))\n    recall.append(((num_correct_pos_predictions / num_actual_positives) * 100))\n\n# Calculating the average precision and recall\naverage_precision = np.mean(precision)\naverage_recall = np.mean(recall)\n\n# Calculating the F1 Measure as (2 PR)/ (P + R)\nf1 = (2 * average_precision * average_recall) / (average_precision + average_recall)\nprint ""Precision: "", average_precision\nprint ""Recall: "", average_recall\nprint ""F1 Measure: "", f1\n'"
Classifiers/LogisticRegression.py,5,"b'import numpy as np\nfrom sklearn import linear_model\nfrom sklearn.model_selection import KFold\n\n# Training features(x) and labels(y)\nx = np.load(\'../Data/Training/features.npy\')\ny = np.load(\'../Data/Training/target_label.npy\')\n\n# Setting up 10-fold cross validation\nkf = KFold(n_splits=10)\nkf.get_n_splits(x)\n\nprecisionList, recallList = [], []\nfor train, test in kf.split(x):\n    # Initializing the Logistic Regression Classifier\n    clf = linear_model.LogisticRegression(class_weight = {0:1, 1:1})\n    print clf.get_params(True)\n\n    # Fitting the training data on the model\n    clf.fit(x[train], y[train])\n\n    # Running the decision function to find out the predicted score\n    prediction_score = clf.decision_function(x[test])\n\n    # Setting the minimum threshold\n    min_threshold = 0.96\n\n    # Selecting only those features for which the predicted value is above the minimum threshold\n    predicted_label = [1 if y_s > min_threshold else 0 for y_s in prediction_score]\n\n    # Calculating out the number of positive predictions\n    num_pos_predictions = np.sum(predicted_label)\n\n    num_correct_pos_predictions = 0.0\n    for i in range(len(predicted_label)):\n        # Comparing the predicted label with the test label to find out the number of correct\n        # positive predictions\n        if predicted_label[i] == 1 and predicted_label[i] == y[test][i]:\n            num_correct_pos_predictions += 1\n\n    # Calculating out the number of actual positives\n    num_actual_positives = (y[test] == 1).sum()\n\n    # Calculating precision and recall for each fold\n    precision = (num_correct_pos_predictions * 100 / num_pos_predictions)\n    recall = (num_correct_pos_predictions * 100 / num_actual_positives)\n\n    precisionList.append(precision)\n    recallList.append(recall)\n\n# Calculating the average precision and recall\naverage_precision = np.mean(precisionList)\naverage_recall = np.mean(recallList)\nprint ""Precision: "", average_precision\nprint ""Recall: "", average_recall\n\n# Calculating the F1 Measure as (2 PR)/ (P + R)\nf1 = (2 * average_precision * average_recall) / (average_precision + average_recall)\nprint ""F1 Measure: "", f1\n'"
Classifiers/RandomForest.py,5,"b'import numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\nfeatures = np.load(\'../Data/Training/features.npy\')\nlabels = np.load(\'../Data/Training/target_label.npy\')\n\nclf = RandomForestClassifier(max_depth=10, min_samples_split=10, min_samples_leaf=1)\nprint clf.get_params()\n\n# 5-fold cross validation to get precision\nscores = cross_val_score(clf, features, labels, cv=5, scoring=\'precision\')\nprint ""Precision: "", np.mean(scores)\n\n# 5-fold cross validation to get precision\nscores = cross_val_score(clf, features, labels, cv=5, scoring=\'recall\')\nprint ""Recall: "", np.mean(scores)\n\n# 5-fold cross validation to get precision\nscores = cross_val_score(clf, features, labels, cv=5, scoring=\'f1_macro\')\nprint ""F1 Measure: "", np.mean(scores)\n'"
Classifiers/SVM.py,3,"b'import numpy as np\nfrom sklearn import svm\nfrom sklearn.model_selection import KFold\n\n# Training features(x) and labels(y)\nx = np.load(\'../Data/Training/features.npy\')\ny = np.load(\'../Data/Training/target_label.npy\')\n\n# Setting up 10-fold cross validation\nkf = KFold(n_splits=10)\nkf.get_n_splits(x)\n\naverage_precision = 0\naverage_recall = 0\n\nfor train, test in kf.split(x):\n    # Initializing the Support Vector Machines Classifier\n    clf = svm.SVC()\n\n    # Fitting the training data on the model\n    clf.fit(x[train], y[train])\n\n    # Running the decision function to find out the predicted score\n    predicted_score = clf.decision_function(x[test])\n\n    # Setting the minimum threshold\n    min_threshold = 0.98\n\n    # Selecting only those features for which the predicted value is above the minimum threshold\n    predicted_label = [1 if y_s > min_threshold else 0 for y_s in predicted_score]\n\n    # Calculating out the number of positive predictions\n    num_pos_predictions = np.sum(predicted_label)\n\n    num_correct_pos_predictions = 0.0\n    for i in range(len(predicted_label)):\n        # Comparing the predicted label with the test label to find out the number of correct\n        # positive predictions\n        if predicted_label[i] == 1 and predicted_label[i] == y[test][i]:\n            num_correct_pos_predictions += 1\n\n    # Calculating out the number of actual positives\n    num_actual_positives = (y[test] == 1).sum()\n\n    # Calculating precision and recall for each fold\n    precision = (num_correct_pos_predictions * 100 / num_pos_predictions)\n    recall = (num_correct_pos_predictions * 100 / num_actual_positives)\n\n    average_precision += precision\n    average_recall += recall\n\n# Calculating the average precision and recall\naverage_precision /= 10\naverage_recall /= 10\n\n# Calculating the F1 Measure as (2 PR)/ (P + R)\nf1 = (2 * average_precision * average_recall) / (average_precision + average_recall)\n\nprint ""Precision: "", average_precision\nprint ""Recall: "", average_recall\nprint ""F1 Measure: "", f1\n'"
Classifiers/__init__.py,0,b''
Classifiers/test_RandomForest.py,7,"b""import numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\n\nfeatures = np.load('Data/Training/features.npy')\nlabels = np.load('Data/Training/target_label.npy')\ntraining_words = np.load('Data/Training/training_words.npy')\n\nclf_test = RandomForestClassifier(max_depth=10, min_samples_split=10, min_samples_leaf=1)\nclf_test = clf_test.fit(features, labels)\n\ntest_features = np.load('Data/Testing/test_features.npy')\ntest_labels = np.load('Data/Testing/test_target_label.npy')\ntest_words = np.load('Data/Testing/testing_words.npy')\n\nprediction_label = clf_test.predict( test_features )\n\nnum_pos_predictions = np.sum(prediction_label)\n\nnum_correct_pos_predictions = 0.0\n\nfor k in range(len(prediction_label)):\n\n    if prediction_label[k] == 1 and prediction_label[k] == test_labels[k]:\n        num_correct_pos_predictions += 1\n\nprecision = (num_correct_pos_predictions * 100 / num_pos_predictions)\n\nnum_actual_positives = (test_labels == 1).sum()\nrecall = (num_correct_pos_predictions * 100 / num_actual_positives)\n\nf1 = (2 * precision * recall) / (precision + recall)\n\nprint precision, recall, f1\n"""
Classifiers/test_classifier.py,7,"b""import numpy as np\nfrom sklearn import svm\nfrom sklearn import linear_model\n\nfeatures = np.load('../Data/Training/features.npy')\nlabels = np.load('../Data/Training/target_label.npy')\ntraining_words = np.load('../Data/Training/training_words.npy')\n\n# clf_test = svm.SVC()\nclf_test = linear_model.LinearRegression()\nclf_test = clf_test.fit(features, labels)\n\ntest_features = np.load('../Data/Testing/test_features.npy')\ntest_labels = np.load('../Data/Testing/test_target_label.npy')\ntest_words = np.load('../Data/Testing/testing_words.npy')\n\n# prediction_score = clf_test.decision_function(test_features)\nprediction_label = clf_test.predict(test_features)\nmin_threshold = 0.63\n\nprediction_label = [1 if y_s > min_threshold else 0 for y_s in prediction_label]\n\nnum_pos_predictions = np.sum(prediction_label)\n\nnum_correct_pos_predictions = 0.0\n\nfor k in range(len(prediction_label)):\n\n    if prediction_label[k] == 1 and prediction_label[k] == test_labels[k]:\n        num_correct_pos_predictions += 1\n\nprecision = (num_correct_pos_predictions * 100 / num_pos_predictions)\n\nnum_actual_positives = (test_labels == 1).sum()\nrecall = (num_correct_pos_predictions * 100 / num_actual_positives)\n\nf1 = (2 * precision * recall) / (precision + recall)\n\nprint precision, recall, f1\n"""
Classifiers/train_classifier.py,8,"b'import numpy as np\nfrom sklearn import svm\nfrom sklearn.model_selection import KFold\n\nfeatures = np.load(\'Data/Training/features.npy\')\nlabels = np.load(\'Data/Training/target_label.npy\')\ntraining_words = np.load(\'Data/Training/training_words.npy\')\n\n""""""\nfeatures = SelectKBest(chi2,k=6).fit_transform(features_load,labels)\n""""""\n\nkf = KFold(n_splits=10)\nkf.get_n_splits(features)\n\naverage_precision = 0\naverage_recall = 0\nfor train_index, test_index in kf.split(features):\n    F_train, F_test = features[train_index], features[test_index]\n    L_train, L_test = labels[train_index], labels[test_index]\n    clf = svm.SVC()\n    clf.fit(F_train, L_train)\n\n    prediction_score = clf.decision_function(F_test)\n    min_threshold = 0.96\n\n    prediction_label = [1 if y_s > min_threshold else 0 for y_s in prediction_score]\n\n    num_pos_predictions = np.sum(prediction_label)\n\n    num_correct_pos_predictions = 0.0\n\n    for k in range(len(prediction_label)):\n\n        if prediction_label[k] == 1 and prediction_label[k] == L_test[k]:\n            num_correct_pos_predictions += 1\n\n    precision = (num_correct_pos_predictions * 100 / num_pos_predictions)\n\n    num_actual_positives = (L_test == 1).sum()\n    recall = (num_correct_pos_predictions * 100 / num_actual_positives)\n\n    average_precision += precision\n    average_recall += recall\n\naverage_precision /= 10\naverage_recall /= 10\n\n# Calculating the F1 Measure as (2 PR)/ (P + R)\nf1 = (2 * average_precision * average_recall) / (average_precision + average_recall)\n\nprint ""Precision: "", average_precision\nprint ""Recall: "", average_recall\nprint ""F1 Measure: "", f1\n\n""""""\n\n\nclf_test = svm.SVC()\nclf_test = clf_test.fit(features,labels)\n\ntest_features = np.load(\'Data/Testing/test_features.npy\')\ntest_labels   = np.load(\'Data/Testing/test_target_label.npy\')\ntest_words    = np.load(\'Data/Testing/testing_words.npy\')\n\n\n\nprediction_score = clf_test.decision_function( test_features )\nmin_threshold = 0.8\n\t\nprediction_label = [1 if y_s > min_threshold else 0 for y_s in prediction_score]\n\nnum_pos_predictions = np.sum ( prediction_label )\n\nnum_correct_pos_predictions = 0.0\n\t\nfor k in range( len(prediction_label) ):\n\n\tif prediction_label[k] == 1 and prediction_label[k] == test_labels[k] :\n\n\t\tnum_correct_pos_predictions+=1\n\nprecision = (num_correct_pos_predictions*100/num_pos_predictions)\n\nnum_actual_positives = (test_labels == 1).sum()\nrecall \t  = (num_correct_pos_predictions*100/num_actual_positives)\n\nprint precision,recall\n\n\n\t\noutFile = open(\'false_negatives.txt\',\'w+\')\n\nfor k in range ( len(prediction_label) ):\n\t\n\tif prediction_label[k] == 0 and L_test[k] == 1:\n\n\t\toutFile.write(""\\n"" + training_words[k] + "" "" )\n\t\tfor item in features[k]:\n\t\t\toutFile.write(""%s,"" % item)\n\nbreak \n""""""\n\n""""""\nfor train_index,test_index in kf.split(features):\n\tF_train,F_test = features[train_index],features[test_index]\n\tL_train,L_test = labels[train_index],labels[test_index]\n\tclf = tree.DecisionTreeClassifier()\n\tclf.fit(F_train,L_train)\n\tprediction_label = clf.predict(F_test)\n\tnum_pos_predictions = ( prediction_label==1 ).sum()\n\t\n\tnum_correct_pos_predictions = 0.0\n\n\tfor k in range( len(prediction_label) ):\n\n\t\tif prediction_label[k] == 1 and prediction_label[k] == L_test[k] :\n\n\t\t\tnum_correct_pos_predictions+=1\n\n\tprecision = (num_correct_pos_predictions*100/num_pos_predictions)\n\n\tnum_actual_positives = (L_test == 1).sum()\n\trecall \t  = (num_correct_pos_predictions*100/num_actual_positives)\n\n\tprint precision,recall\n\t\n\nfor train_index,test_index in kf.split(features):\n\tF_train,F_test = features[train_index],features[test_index]\n\tL_train,L_test = labels[train_index],labels[test_index]\n\tclf = GaussianNB()\n\tclf.fit(F_train,L_train)\n\tprediction_label = clf.predict(F_test)\n\tnum_pos_predictions = ( prediction_label==1 ).sum()\n\t\n\tnum_correct_pos_predictions = 0.0\n\n\tfor k in range( len(prediction_label) ):\n\n\t\tif prediction_label[k] == 1 and prediction_label[k] == L_test[k] :\n\n\t\t\tnum_correct_pos_predictions+=1\n\n\tprecision = (num_correct_pos_predictions*100/num_pos_predictions)\n\n\tnum_actual_positives = (L_test == 1).sum()\n\trecall \t  = (num_correct_pos_predictions*100/num_actual_positives)\n\n\tprint precision,recall\n\n\n""""""\n'"
DataMerging/data_merge.py,3,"b'import numpy as np\nimport pandas as pd\nimport py_entitymatching as em\n\n### Reading the necessary data ###\n\n# Loading candidate set data\nC = pd.read_pickle(\'./candidate_set.pkl\')\n\n# Loading candidate set predictions (obtained after applying the trained classifier to candidate set)\nCpred = pd.read_pickle(\'./candidate_set_predictions.pkl\')\n\n### Creating the matched data frame ###\n\n# Columns for the new data frame which will hold the merged data\ncolumns = [\'number_of_reviews\', \'price_range\', \'ratingValue\', \'name\', \'address\']\nnum_matches = len(Cpred[(Cpred[\'predicted\'] == 1)])\n\n# Index range for data frame\nindx_range = range(num_matches)\n\n# New data frame to hold merged data\nmatch = pd.DataFrame(index=indx_range, columns=columns)\n\n### Merging data ###\n\n# Iterating over tuples in Cpred to find predicted matches\nmatch_table_id = 0\nfor index, row in Cpred.iterrows():\n\n    # Extracting only those tuples which are classified as a match by the trained classifier\n    if int(row[\'predicted\']) == 1:\n        id = int(row[\'_id\'])\n\n        # Populating match data frame\n        # Computing Jaccard over 3-gram J(3g) tokenization score for name\n        name_match_score = em.jaccard(em.tok_qgram(C.iloc[id][\'ltable_name\'], 3),\n                                      em.tok_qgram(C.iloc[id][\'rtable_name\'], 3))\n\n        # Those names whose J(3g) score > 0.3 are considered matches\n        if (name_match_score > 0.3):\n            # For tuples whose J(3g(name)) is > 0.3, J(3g) is computed on address\n            address_match_score = em.jaccard(em.tok_qgram(C.iloc[id][\'ltable_address\'], 3),\n                                             em.tok_qgram(C.iloc[id][\'rtable_address\'], 3))\n            if (address_match_score > 0.3):\n                # For those tuples whose J(3g(name)) and J(3g(address)) > 0.3\n\n                # Rules for picking the restaurant name from the two tables\n                if C.iloc[id][\'ltable_name\'] == C.iloc[id][\'rtable_name\']:\n                    match.iloc[match_table_id][\'name\'] = C.iloc[id][\'ltable_name\']\n                else:\n                    # Picking the longer name from the two tables\n                    if len(C.iloc[id][\'ltable_name\']) > len(C.iloc[id][\'rtable_name\']):\n                        match.iloc[match_table_id][\'name\'] = C.iloc[id][\'ltable_name\']\n                    else:\n                        match.iloc[match_table_id][\'name\'] = C.iloc[id][\'rtable_name\']\n\n                # Rules for picking the restaurant address from the two tables\n                if C.iloc[id][\'ltable_address\'] == C.iloc[id][\'rtable_address\']:\n                    match.iloc[match_table_id][\'address\'] = C.iloc[id][\'ltable_address\']\n                else:\n                    # Picking the longer address from the two tables\n                    if len(C.iloc[id][\'ltable_address\']) > len(C.iloc[id][\'rtable_address\']):\n                        match.iloc[match_table_id][\'address\'] = C.iloc[id][\'ltable_address\']\n                    else:\n                        match.iloc[match_table_id][\'address\'] = C.iloc[id][\'rtable_address\']\n\n                # Rules for picking the number of reviews for a restaurant from the two tables\n                # Picking the one which has higher number of reviews\n                if C.iloc[id][\'ltable_number_of_reviews\'] > C.iloc[id][\'rtable_number_of_reviews\']:\n                    match.iloc[match_table_id][\'number_of_reviews\'] = C.iloc[id][\'ltable_number_of_reviews\']\n                else:\n                    match.iloc[match_table_id][\'number_of_reviews\'] = C.iloc[id][\'rtable_number_of_reviews\']\n\n                # Rules for picking the price range for a restaurant from the two tables\n                # Computing and storing the average of the two price ranges in the merged table\n                if C.iloc[id][\'ltable_price_range\'] == C.iloc[id][\'rtable_price_range\']:\n                    match.iloc[match_table_id][\'price_range\'] = C.iloc[id][\'ltable_price_range\']\n                else:\n                    match.iloc[match_table_id][\'price_range\'] = np.mean(np.array(\n                        [np.float(C.iloc[id][\'ltable_price_range\'][1:]),\n                         np.float(C.iloc[id][\'rtable_price_range\'][1:])]))\n\n                # Rules for picking the rating value for a restaurant from the two tables\n\n                # If both tables have non-null values for rating, pick the highest rating out of the two values\n                if (C.iloc[id][\'ltable_ratingValue\'] != \'-\' and C.iloc[id][\'rtable_ratingValue\'] != \'-\'):\n                    if (float(C.iloc[id][\'ltable_ratingValue\'][1:]) > float(C.iloc[id][\'rtable_ratingValue\'][1:])):\n                        match.iloc[match_table_id][\'ratingValue\'] = C.iloc[id][\'ltable_ratingValue\']\n                    else:\n                        match.iloc[match_table_id][\'ratingValue\'] = C.iloc[id][\'rtable_ratingValue\']\n\n                # If there are null values in either table, pick the non-null values\n                elif (C.iloc[id][\'ltable_ratingValue\'] == \'-\' and C.iloc[id][\'rtable_ratingValue\'] != \'-\'):\n                    match.iloc[match_table_id][\'ratingValue\'] = C.iloc[id][\'rtable_ratingValue\']\n                elif (C.iloc[id][\'ltable_ratingValue\'] != \'-\' and C.iloc[id][\'rtable_ratingValue\'] == \'-\'):\n                    match.iloc[match_table_id][\'ratingValue\'] = C.iloc[id][\'ltable_ratingValue\']\n                else:\n                    # If both tables have null values for rating, then choose either\n                    match.iloc[match_table_id][\'ratingValue\'] = C.iloc[id][\'ltable_ratingValue\']\n            match_table_id += 1\n\n# Filtering out only the tuples which have non-null values for the ""name"" attribute\nmatch = match[pd.notnull(match[\'name\'])]\n\n# Storing the merged dataframe in a pickle and csv file\nmatch.to_pickle(\'./match_data.pkl\')\nmatch.to_csv(\'./match_data.csv\')\n'"
DataMerging/process_match_data.py,2,"b'import pandas as pd\nimport numpy as np\nfrom nltk import word_tokenize, pos_tag\n\n## Python script used to process merged data [ processing - split address fields ]\n\nmatch_data = pd.read_csv(\'./match_data.csv\')\n\ncolumns = [\'number_of_reviews\', \'price_range\', \'ratingValue\', \'name\', \'street\', \'city\', \'state\', \'zipcode\']\nnum_matches = len(match_data)\n\n# Index range for data frame\nindx_range = range(num_matches)\n\n# New data frame to hold address in separate fields\nmatch_processed = pd.DataFrame(index=indx_range, columns=columns)\n\ncity_dict = {\n    ""Jose"" : ""San Jose"",\n    ""City"" : ""Long Island City"",\n    ""York"" : ""New York""\n}\n\nmatch_table_id = 0\nfor index, row in match_data.iterrows():\n\n    # Copying all non-address fields from original match_data\n    match_processed.iloc[match_table_id][\'number_of_reviews\'] = match_data.iloc[index][\'number_of_reviews\']\n    match_processed.iloc[match_table_id][\'price_range\'] = np.float(match_data.iloc[index][\'price_range\'][1:])\n    match_processed.iloc[match_table_id][\'ratingValue\'] = np.float(match_data.iloc[index][\'ratingValue\'])\n    match_processed.iloc[match_table_id][\'name\'] = match_data.iloc[index][\'name\'].decode(\'utf-8\')\n\n    # Processing address string and splitting into fields based on space\n    address_list = match_data.iloc[index][\'address\'].split("" "")\n\n    street = """"\n\n    # Finding city names using prefix\n    city_prefix = [""San"", ""New""]\n\n    if any(str in city_prefix for str in address_list[-4]):\n        # If any of the prefixes are present, then skip the word before\n        # the prefix. So if -4th index has the prefix, then skip -5 and\n        # consider from -6 to beginning\n        itr_limit = len(address_list) - 5\n    elif ""Island"" in address_list[-4]:\n        # Specific case - If Island is present in index -4, then skip the\n        # next two indexes(""Island"" and ""Long"") as they will be part of\n        # the city name. Start from -7 to beginning.\n        itr_limit = len(address_list) - 6\n    else:\n        # If the prefixes or Island is not present, then it is a one word\n        # city name. Hence, start from the -5th index\n        itr_limit = len(address_list) - 4\n\n    for i in range(itr_limit):\n        street += address_list[i]\n        if i < itr_limit - 1:\n            street += "" ""\n\n    zipcode = address_list[-1]\n    state = address_list[-2]\n\n    city_val = address_list[-3]\n    if city_val in city_dict:\n        # If the city prefix is present as a key in the dictionary,\n        # refer its value, that is, the full name of the city\n        city = city_dict[city_val]\n    else:\n        # Else just take the city name as it is\n        city = city_val\n\n    match_processed.iloc[match_table_id][\'street\'] = street\n    match_processed.iloc[match_table_id][\'city\'] = city\n    match_processed.iloc[match_table_id][\'state\'] = state\n    match_processed.iloc[match_table_id][\'zipcode\'] = zipcode\n\n    match_table_id += 1\n\nmatch_processed.to_csv(\'../OLAPExploration/restaurant_details.csv\', encoding=\'utf-8\')\n'"
EntityMatching/EM_restaurants.py,0,"b'\n# coding: utf-8\n\n# <h1>Project Stage3 Entity Matching Workflow for Restaurant Data set\n\n# **Introduction**\n# \n# This IPython notebook explains a basic workflow two tables using py_entitymatching. \n# Our goal is to come up with a workflow to match restaurants from Yelp and Zomato sites.\n# Specifically, we want to have precision of atleast 90 percent and as high recall as possible.\n# \n# First, we need to import py_entitymatching package and other libraries as follows:\n\n# In[76]:\n\nimport sys\nsys.path.append(\'/usr/local/lib/python2.7/dist-packages/\')\n\nimport py_entitymatching as em\nimport pandas as pd\nimport os,sys\nimport math\n\n\n# In[77]:\n\n##Display the versions\nprint(\'python version: \' + sys.version )\nprint(\'pandas version: \' + pd.__version__ )\nprint(\'magellan version: \' + em.__version__ )\n\n\n# **Matching two tables typically consists of the following three steps**\n# \n# 1. Reading the input tables\n# \n# 2. Blocking the input tables to get a candidate set\n# \n# 3. Matching the tuple pairs in the candidate set\n# \n\n# <h1> Read the input tables </h1>\n# \n# We begin by loading the input tables\n\n# In[78]:\n\n## Reading csv tables into pandas dataframe and set the key attribute in the dataframe\n\nA=em.read_csv_metadata(\'../Data/csv/yelp_list.csv\')\nA[\'ID\'] = range(0,len(A))\nem.set_key(A,\'ID\')\n\n\nB=em.read_csv_metadata(\'../Data/csv/zomato_list.csv\')\nB[\'ID\'] = range(0,len(B))\nem.set_key(B,\'ID\')\n\n\n# In[79]:\n\nprint(\'Number of tuples in A: \' + str(len(A)))\nprint(\'Number of tuples in B: \' + str(len(B)))\nprint(\'Number of tuples in A X B (i.e the cartesian product): \' + str(len(A)*len(B)))\n\n\n# In[80]:\n\n## Sample tuples in A ( yelp_list )\nA.head(2)\n\n\n# In[81]:\n\n## Sample tuples in B (zomato_list)\nB.head(2)\n\n\n# In[82]:\n\n# Display the keys of the input tables\nem.get_key(A), em.get_key(B)\n\n\n# <h1> Data Cleaning \n\n# Some attributes of the table are cleaned for easier comparison. \n# Examples : \n#     * Price Range of yelp list is converted into a number (as it is in zomato)\n#     * If the word ""restaurant"" appears as a last word in the restaurant name, it is removed.\n\n# In[83]:\n\n##Data Cleaning1: Converting  price range to an absolute number. Will be applied for yelp list \n\n\ndef clean_price_range( price_str ):\n\n    avg_price = \'\'\n    \n    if not isinstance(price_str,basestring)  and  math.isnan(price_str):\n        return price_str\n\n    str2 = price_str.replace(\'$\',\'\')\n        \n    if \'-\' in str2:\n        num_l = int(str2.split(\'-\')[0])\n        num_r = int(str2.split(\'-\')[1])\n        num_avg = (num_l+num_r)/2\n        avg_price = \'$\' + str(num_avg)\n\n    else:\n        str_word = str2.split()[0].lower()\n        num_price  = int(str2.split()[1])\n        \n        if str_word == \'above\':\n            num_avg = int(num_price + num_price/2)\n            avg_price = \'$\' + str(num_avg)\n\n        else:\n            num_avg = num_price/2\n            avg_price = \'$\' + str(num_avg)\n            \n    return avg_price\n\n\n# In[84]:\n\n##Data Cleaning2: Removing ""reviews"" string from num_reviews column. Will be applied for zomato list\n\n\ndef clean_num_reviews(review_string) :\n      return int(review_string.split()[0])\n\n\n# In[85]:\n\n##Data Cleaning3: Removing ""restaurant"" if it is the last word in restaurant name. to prevent inconsistentcy.\n## Will be applied for both lists\n\n\ndef clean_name( name_str):\n\n    name_lower = name_str.lower()\n\n    name_2 = name_lower.split()[-1]\n    \n    if name_2 == \'restaurant\':\n        name_lower = name_lower.replace(\'restaurant\',\'\')\n        \n    return name_lower\n\n\n# In[86]:\n\n##Data Cleaning4: Removing quotes and shortening some words in address.Will be applied for zomato list \n\ndef clean_address( address ):\n    addr_2 = address.replace(\'\\""\',\'\')\n    addr_3 = addr_2.replace(\',\',\'\')\n    if ""Street"" in addr_3:\n        addr_3 = addr_3.replace(\'Street\',\'St\')\n    if ""Boulevard"" in addr_3:\n        addr_3 = addr_3.replace(\'Boulevard\',\'Blvd\')\n        \n    return addr_3\n\n\n# In[87]:\n\n## Data Cleaning5: Convert rating value into string type\ndef clean_rating_value(ratingValue):\n    return str(ratingValue)\n\n\n# In[88]:\n\n## Apply Data Cleaning to tables\n\nA[\'price_range\'] = A[\'price_range\'].apply( clean_price_range )\nA[\'name\'] = A[\'name\'].apply( clean_name )\nA[\'ratingValue\'] = A[\'ratingValue\'].apply(clean_rating_value)\n\n\n\nB[\'name\'] = B[\'name\'].apply( clean_name )\nB[\'address\'] = B[\'address\'].apply( clean_address )\nB[\'number_of_reviews\'] = B[\'number_of_reviews\'].apply( clean_num_reviews )\nB[\'ratingValue\'] = B[\'ratingValue\'].apply(clean_rating_value)\n\n\n# <h1> Block tables to get candidate set\n\n# Before we do the matching, we would like to remove the obviously non-matching tuple pairs from the input tables. \n# This would reduce the number of tuple pairs considered for matching\n# \n# We have first used a blackbox based blocker which looks at zipcode equivalence to obtain candidate sets.\n# Further these candidate sets are pruned based on name similarity.\n# \n# We use the entitymatching get_features routine to automatically generate features and choose the relevant ones \n# for blocking.\n# \n\n# In[90]:\n\n# Get features for blocking\n\nblock_f = em.get_features_for_blocking(A,B)\n\n\n# In[91]:\n\n# List the names of the features generated\nblock_f[\'feature_name\']\n\n\n# In[92]:\n\n## Routine to block based on zipcode equivalence\n\ndef zipcode_match(x, y):\n    # x, y will be of type pandas series\n    \n    # get address attribute\n    x_address = x[\'address\']\n    y_address = y[\'address\']\n    \n    # get the zipcode\n    x_split, y_split = x_address.split(), y_address.split()\n    x_zipcode = x_split[len(x_split) - 1]\n    y_zipcode = y_split[len(y_split) - 1]\n    \n    # check if the zipcode match\n    if x_zipcode != y_zipcode:\n        return True\n    else:\n        return False\n\n\n# In[93]:\n\n## Instantiate blackbox blocker\nbb = em.BlackBoxBlocker()\n\n## Set the black box function\nbb.set_black_box_function(zipcode_match)\n\n\n# In[94]:\n\n##Rule based on restaurant name similarity\nrb1 = em.RuleBasedBlocker()\nrule1 = \'name_name_lev_sim(ltuple,rtuple) < 0.60\'\nrb1.add_rule(rule1, block_f )\n\n\n# In[95]:\n\n## Blocking Pipeline- First block based on zip code then block based on name similarity##\n\nC1 = bb.block_tables(A,B,l_output_attrs=[\'ID\',\'name\',\'address\',\'ratingValue\',\'price_range\',\'number_of_reviews\'],r_output_attrs=[\'ID\',\'name\',\'address\',\'ratingValue\',\'price_range\',\'number_of_reviews\'],n_jobs=-1)\n\nC2 = rb1.block_candset(C1,n_jobs=-1)\n\n\n# In[96]:\n\n## Number of tuple pairs in C2\nlen(C2)\n\n\n# <h1> Debug Blocker Output\n# \n\n# The number of tuple pairs considered for matching is reduced to  (from 10536512 to 953), \n# but we would want to make sure that the blocker did not drop any potential matches.\n# We could debug the blocker output in py_entitymatching as follows:\n\n# In[97]:\n\n# Debug blocker output\ndbg = em.debug_blocker(C2, A, B, output_size=200)\n\n\n# In[98]:\n\n# Display first few tuple pairs from the debug_blocker\'s output\ndbg.head()\n\n\n# From the debug blocker\'s output we observe that the current blocker drops quite a few potential matches. \n# We would want to update the blocking sequence to avoid dropping these potential matches.\n# \n# For the considered dataset, we know that for the restaurants to match, the address should be similar.\n# We could use rule based blocker with address similarity for this purpose.\n# Finally, we would want to union the outputs from the name similarity blocker and the address blocker to get a consolidated candidate set.\n# \n\n# In[99]:\n\n##Rule based on address similarity\nrb2 = em.RuleBasedBlocker()\nrule2 = \'address_address_jac_qgm_3_qgm_3(ltuple,rtuple) < 0.8\'\nrb2.add_rule(rule2,block_f)\n\n\n# In[100]:\n\n###Address based blocker###\nC3 = rb2.block_candset(C1,n_jobs=-1)\n\nlen(C3)\n\n\n# In[71]:\n\n## Display first two rows of C3\nC3.head(2)\n\n\n# In[101]:\n\n## Combine blocker outputs\nC4 = em.combine_blocker_outputs_via_union([C2, C3])\n\n\n# In[102]:\n\nlen(C4)\n\n\n# We observe that the number of tuple pairs considered for matching is increased to 2048 (from 953). \n# Now let us debug the blocker output again to check if the current blocker sequence is dropping any potential matches.\n\n# In[103]:\n\n# Debug again\ndbg = em.debug_blocker(C4, A, B)\n\n\n# In[104]:\n\n# Display first few rows from the debugger output\ndbg.head(3)\n\n\n# We observe that the current blocker sequence does not drop obvious potential matches, and we can proceed with the matching step now. \n\n# <h1>  Matching tuple pairs in the candidate set\n\n# \n# \n# In this step, we would want to match the tuple pairs in the candidate set. Specifically, we use learning-based method for matching purposes. This typically involves the following five steps:\n# \n# * Sampling and labeling the candidate set\n# * Splitting the labeled data into development and evaluation set\n# * Selecting the best learning based matcher using the development set\n# * Evaluating the selected matcher using the evaluation set\n# \n# \n\n# <h1> Sampling and labeling the candidate set\n\n# First, we randomly sample 350 tuple pairs for labeling purposes.\n\n# In[105]:\n\n##Sample candidate set\nS = em.sample_table(C4, 350)\n\n\n# In[23]:\n\n##Label S \nG = em.label_table(S, \'gold_labels\')\n\n\n# Load labeled data fom previous session\n\n# In[105]:\n\nG = em.load_object(\'./GoldenData.pkl\')\nlen(G)\n\n\n# In[106]:\n\n## Loading G into em catalog\n\nem.set_fk_ltable(G, \'ltable_ID\')\nem.set_fk_rtable(G, \'rtable_ID\')\nem.set_key(G, \'_id\')\nem.set_ltable(G, A)\nem.set_rtable(G, B)\n\n\n# In[107]:\n\n## Find number of positive and negative examples \nG.groupby(\'gold_labels\').count()\n\n\n# <h1> Splitting the labeled data into development and evaluation set\n# \n# \n# \n\n# In this step, we split the labeled data into two sets: development (I) and evaluation (J). Specifically, the development set is used to come up with the best learning-based matcher and the evaluation set used to evaluate the selected matcher on unseen data.\n\n# In[109]:\n\n# Split S into development set (I) and evaluation set (J)\ntrain_test = em.split_train_test(G, train_proportion=0.7)\nI = train_test[\'train\']\nJ = train_test[\'test\']\n\n\n# <h1>  Selecting the best learning-based matcher\n\n# Selecting the best learning-based matcher typically involves the following steps:\n# \n# * Creating a set of learning-based matchers\n# * Creating features\n# * Converting the development set into feature vectors\n# * Selecting the best learning-based matcher using k-fold cross validation\n# \n\n# Creating a set of learning-based matchers\n# ------------------\n\n# In[111]:\n\n## Create a set of ML Matchers\ndt = em.DTMatcher()\nrf = em.RFMatcher()\nnb = em.NBMatcher()\nlogreg = em.LogRegMatcher()\nlinreg = em.LinRegMatcher()\nsvm = em.SVMMatcher()\n\n\n# Creating features\n# ------------------\n\n# Next, we need to create a set of features for the development set. py_entitymatching provides a way to automatically generate features based on the attributes in the input tables. We drop the unwanted features from the feature table\n\n# In[113]:\n\n## Generate features\nmatch_f = em.get_features_for_matching(A, B)\nmatch_f.drop([13,14,15,16], inplace = True)\n\n\n# In[114]:\n\n# List the names of the features generated\nmatch_f[\'feature_name\']\n\n\n# Converting the development set to feature vectors\n# ------------------\n\n# In[116]:\n\n# Convert the I into a set of feature vectors using F\n\nH = em.extract_feature_vecs(I, feature_table=match_f, attrs_after=[\'gold_labels\'])\n\n\n# In[117]:\n\n## Display first three rows\nH.head(3)\n\n\n# Selecting the best matcher using cross-validation\n# ------------------\n\n# Now, we select the best matcher using k-fold cross-validation.\n# For the purposes of this guide, we use ten fold cross validation and use \'precision\' and \'recall\' metric to select the best matcher\n\n# In[120]:\n\n## Select the best ML matcher using CV\n\nresult_precision = em.select_matcher(matchers=[dt, rf, nb, logreg, linreg, svm], table=H, exclude_attrs=[], target_attr=\'gold_labels\', metric=\'precision\', k=10)\nresult_precision[\'cv_stats\']\n\n\n# In[121]:\n\n# Measuring recall\nresult_recall = em.select_matcher(matchers=[dt, rf, nb, logreg, linreg, svm], table=H, exclude_attrs=[], target_attr=\'gold_labels\', metric=\'recall\', k=10)\nresult_recall[\'cv_stats\']\n\n\n# Debugging Matcher\n# ------------------\n\n# We observe that the best matcher is either Linear Regression or Random Forest.\n# We debug the RandomForest matcher to see what might be wrong( since it easier to debug). \n# To do this, first we split the feature vectors into train and test.\n\n# In[126]:\n\n## Split feature vectors (H) into train and test\nrf = em.RFMatcher()\nUV = em.split_train_test(H, train_proportion=0.5)\nU = UV[\'train\']\nV = UV[\'test\']\n\n\n# Next, we debug the matcher using GUI. \n\n# In[85]:\n\n# Debug random forest using GUI\n\nem.vis_debug_rf(rf,U,V,\n               exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n               target_attr=\'gold_labels\')\n\n\n# From the debugger we notice there are many false negatives due to incorrect labeling\n\n# In[106]:\n\n## Relabel the sample\nG2 = em.label_table(S, \'gold_labels\')\n\n\n# In[128]:\n\n#load labeled data from previous session\nG2 = em.load_object(\'./GoldenData2.pkl\')\nlen(G2)\n\n\n# In[129]:\n\n## Load G2 into em catalog\nem.set_fk_ltable(G2, \'ltable_ID\')\nem.set_fk_rtable(G2, \'rtable_ID\')\nem.set_key(G2, \'_id\')\nem.set_ltable(G2, A)\nem.set_rtable(G2, B)\n\n\n# In[130]:\n\n## Split into train and test set\ntrain_test = em.split_train_test(G2, train_proportion=0.7)\nI2 = train_test[\'train\']\nJ2 = train_test[\'test\']\n\n\n# In[131]:\n\n## Extract features\nH2 = em.extract_feature_vecs(I2, feature_table=match_f, attrs_after=[\'gold_labels\'])\n\n\n# In[132]:\n\n## Cross validation score\nresult = em.select_matcher(matchers=[dt, rf, nb, logreg, linreg, svm], table=H2, exclude_attrs=[], target_attr=\'gold_labels\', metric=\'precision\', k=10)\nresult[\'cv_stats\']\n\n\n# In[133]:\n\n## Cross validation score for recall\nresult_recall_2 = em.select_matcher(matchers=[dt, rf, nb, logreg, linreg, svm], table=H, exclude_attrs=[], target_attr=\'gold_labels\', metric=\'recall\', k=10)\nresult_recall_2[\'cv_stats\']\n\n\n# We observe that due to relabeling both precision and recall have improved.Now we can further debug and look for improvements\n\n# Debugging Matcher\n# ------------------\n\n# We debug the RandomForest matcher to see what might be wrong(since it easier to debug). To do this, first we split the feature vectors into train and test.\n\n# In[135]:\n\n## Split feature vectors (H) into train and test\nUV2 = em.split_train_test(H, train_proportion=0.5)\nU2 = UV2[\'train\']\nV2 = UV2[\'test\']\n\n\n# Next, we debug the matcher using GUI. \n\n# In[116]:\n\n# Debug random forest using GUI\n\nem.vis_debug_rf(rf,U2,V2,\n               exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n               target_attr=\'gold_labels\')\n\n\n# From the GUI, we observe that there are just few false positives and negatives. We can proceed for evaluation.\n# \n\n# <h1> Evaluating the matching output\n\n# Form feature vectors for the test set J\n\n# In[136]:\n\nL2 = em.extract_feature_vecs(J2, feature_table=match_f, attrs_after=[\'gold_labels\'])\n\n\n# Here we train the machine learning classifiers on the train set I\n\n# In[147]:\n\n# Train random forest using feature vectors from I\nrf.fit(table = H2,\n        exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n        target_attr=\'gold_labels\')\n\n\n# In[146]:\n\n# Train decision tree using feature vectors from I\ndt.fit(table = H2,\n        exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n        target_attr=\'gold_labels\')\n\n\n# In[145]:\n\n# Train Naive Bayesian\nnb.fit(table = H2,\n        exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n        target_attr=\'gold_labels\')\n\n\n# In[149]:\n\n# Train linear regression\nlinreg.fit(table = H2,\n        exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n        target_attr=\'gold_labels\')\n\n\n# In[150]:\n\n# Train logistic regression\nlogreg.fit(table = H2,\n        exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n        target_attr=\'gold_labels\')\n\n\n# In[151]:\n\n# Train SVM\nsvm.fit(table = H2,\n        exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n        target_attr=\'gold_labels\')\n\n\n# Here we use the above trained machine learning algorithms to predict the label for the test set J\n\n# In[153]:\n\n# Evaluate Random Forest\npredictions_rf = rf.predict(table = L2,\n                        exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n                        append = True, target_attr=\'predicted\', inplace=False)\n\n\n# In[154]:\n\neval_result = em.eval_matches(predictions_rf, \'gold_labels\', \'predicted\')\nem.print_eval_summary(eval_result)\n\n\n# In[157]:\n\n# Evaluate Linear Regression\npredictions_linreg = linreg.predict(table = L2,\n                        exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n                        append = True, target_attr=\'predicted\', inplace=False)\n\n\n# In[158]:\n\neval_result = em.eval_matches(predictions_linreg, \'gold_labels\', \'predicted\')\nem.print_eval_summary(eval_result)\n\n\n# In[159]:\n\n# Evaluate Logistic Regression\npredictions_logreg = logreg.predict(table = L2,\n                        exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n                        append = True, target_attr=\'predicted\', inplace=False)\n\n\n# In[160]:\n\neval_result = em.eval_matches(predictions_logreg, \'gold_labels\', \'predicted\')\nem.print_eval_summary(eval_result)\n\n\n# In[161]:\n\n# Evaluate Decision Tree\npredictions_dt = dt.predict(table = L2,\n                        exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n                        append = True, target_attr=\'predicted\', inplace=False)\n\n\n# In[162]:\n\neval_result = em.eval_matches(predictions_dt, \'gold_labels\', \'predicted\')\nem.print_eval_summary(eval_result)\n\n\n# In[164]:\n\n# Evaluate Naive Bayesian\npredictions_nb = nb.predict(table = L2,\n                        exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n                        append = True, target_attr=\'predicted\', inplace=False)\n\n\n# In[165]:\n\neval_result = em.eval_matches(predictions_nb, \'gold_labels\', \'predicted\')\nem.print_eval_summary(eval_result)\n\n\n# In[166]:\n\n# Evaluate SVM\npredictions_svm = svm.predict(table = L2,\n                        exclude_attrs=[\'_id\',\'ltable_ID\',\'rtable_ID\',\'gold_labels\'],\n                        append = True, target_attr=\'predicted\', inplace=False)\n\n\n# In[169]:\n\neval_result = em.eval_matches(predictions_svm, \'gold_labels\', \'predicted\')\nem.print_eval_summary(eval_result)\n\n\n# From the results, we observe that Linear Regression is the best classifier. Below are the P, R, F1 scores for the same.\n\n# In[170]:\n\n## Thus the best matcher is linear regression based with precision,recall and F1 scores given below\neval_result = em.eval_matches(predictions_linreg, \'gold_labels\', \'predicted\')\nem.print_eval_summary(eval_result)\n\n'"
EntityMatching/blocking.py,0,"b'\n# coding: utf-8\n\n# In[14]:\n\nimport py_entitymatching as em\nimport pandas as pd\nimport os,sys\nimport math\n\n\n# In[76]:\n\nA=em.read_csv_metadata(\'Data/csv/yelp_list.csv\')\nA[\'ID\'] = range(0,len(A))\nem.set_key(A,\'ID\')\n\n\nB=em.read_csv_metadata(\'Data/csv/zomato_list.csv\')\nB[\'ID\'] = range(0,len(B))\nem.set_key(B,\'ID\')\n\n\n# In[3]:\n\nA\n\n\n# In[4]:\n\nB\n\n\n# In[33]:\n\ndef clean_price_range( price_str ):\n\n    avg_price = \'\'\n    \n    if not isinstance(price_str,basestring)  and  math.isnan(price_str):\n        return price_str\n\n    str2 = price_str.replace(\'$\',\'\')\n        \n    if \'-\' in str2:\n        num_l = int(str2.split(\'-\')[0])\n        num_r = int(str2.split(\'-\')[1])\n        num_avg = (num_l+num_r)/2\n        avg_price = \'$\' + str(num_avg)\n\n    else:\n        str_word = str2.split()[0].lower()\n        num_price  = int(str2.split()[1])\n        \n        if str_word == \'above\':\n            num_avg = int(num_price + num_price/2)\n            avg_price = \'$\' + str(num_avg)\n\n        else:\n            num_avg = num_price/2\n            avg_price = \'$\' + str(num_avg)\n            \n    return avg_price\n\n\n# In[6]:\n\ndef clean_num_reviews(review_string) :\n     return review_string.split()[0]\n\n\n# In[37]:\n\ndef clean_name( name_str):\n\n\tname_lower = name_str.lower()\n\t\n\tif ""restaurant"" not in name_lower and ""restaurants"" not in name_lower:\n\t\tname_lower = name_lower + "" restaurant""\n\n\treturn name_lower\n\n\n\n# In[77]:\n\ndef clean_address( address ):\n    addr_2 = address.replace(\'\\""\',\'\')\n    addr_3 = addr_2.replace(\',\',\'\')\n    if ""Street"" in addr_3:\n        addr_3 = addr_3.replace(\'Street\',\'St\')\n        \n    return addr_3\n\n\n# In[78]:\n\n########## DATA CLEANING ################\n\n##Converting A\'s price range to an absolute number\nA[\'price_range\'] = A[\'price_range\'].apply( clean_price_range )\n\n##Cleaning restaurant name of A\nA[\'name\'] = A[\'name\'].apply( clean_name )\n\nB[\'name\'] = B[\'name\'].apply( clean_name )\nB[\'address\'] = B[\'address\'].apply( clean_address )\nB[\'number_of_reviews\'] = B[\'number_of_reviews\'].apply( clean_num_reviews )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# In[35]:\n\nA[\'price_range\']\n\n\n# In[19]:\n\nA.isnull().sum\n\n\n\n# In[20]:\n\nlen(A.id) - A.count()\n\n\n# In[21]:\n\nlen(A.ID) - A.count()\n\n\n# In[22]:\n\nlen(B.ID) - B.count()\n\n\n# In[41]:\n\nA\n\n\n\n# In[79]:\n\nblock_f = em.get_features_for_blocking(A,B)\n\n\n# In[80]:\n\nblock_f\n\n\n\n\n# In[81]:\n\nrb1 = em.RuleBasedBlocker()\nrule1 = \'name_name_lev_sim(ltuple,rtuple) < 0.8\'\nrb1.add_rule(rule1, block_f )\n\nrb2 = em.RuleBasedBlocker()\nrule2 = \'address_address_jac_qgm_3_qgm_3(ltuple,rtuple) < 0.9\'\nrb2.add_rule(rule2,block_f)\n\n\n# In[63]:\n\nC1 = rb1.block_tables(A,B,l_output_attrs=[\'ID\',\'name\',\'address\',\'ratingValue\',\'price_range\',\'number_of_reviews\'],r_output_attrs=[\'ID\',\'name\',\'address\',\'ratingValue\',\'price_range\',\'number_of_reviews\'])\nC2 = rb2.block_tables(A,B,l_output_attrs=[\'ID\',\'name\',\'address\',\'ratingValue\',\'price_range\',\'number_of_reviews\'],r_output_attrs=[\'ID\',\'name\',\'address\',\'ratingValue\',\'price_range\',\'number_of_reviews\'])\n\n\n\n# In[64]:\n\nC2\n\n\n\n\n# In[50]:\n\nC\n\n\n# In[56]:\n\ndbg = em.debug_blocker(C,A,B,output_size=200)\n\n\n# In[57]:\n\ndbg\n\n\n# In[ ]:\n\n\n\n'"
OLAPExploration/aggregate.py,0,"b'from __future__ import print_function\nfrom cubes import Workspace, Cell, PointCut\nimport warnings\n\nwarnings.filterwarnings(\'ignore\')\ncount = 1\n\ndef rollup(cell, dimension):\n    result = browser.aggregate(cell, drilldown=[dimension])\n    for row in result.table_rows(dimension):\n        print(row.label)\n        print(""-"" * 2)\n        print(""Total Number of reviews: "", row.record[""total_number_of_reviews""])\n        print(""Price average: $"", row.record[""price_average""])\n        print(""Rating average: "", row.record[""rating_average""])\n        print(""\\n"")\n\n\n""""""Drill-down and aggregate recursively through als levels of `dimension`.\n\n* `cell` - cube cell to drill-down\n* `dimension` - dimension to be traversed through all levels\n\n""""""\n\n\ndef drilldown(cell, dimension, level):\n    global count\n\n    result = browser.aggregate(cell, drilldown=[dimension])\n    for row in result.table_rows(dimension):\n        indent = ""    "" * (len(row.path) - 1)\n        print(indent, row.label)\n        print(indent, ""-"" * 3)\n        print(indent, ""Total Number of reviews: "", row.record[""total_number_of_reviews""])\n        print(indent, ""Price average: $"", row.record[""price_average""])\n        print(indent, ""Rating average: "", row.record[""rating_average""])\n        print(""\\n"")\n\n        count += 1\n        if (count >= level):\n            count = 1\n            break\n        new_cell = cell.drilldown(dimension, row.key)\n        drilldown(new_cell, dimension, level)\n\n\n# 1. Creating a workspace\nworkspace = Workspace()\nworkspace.register_default_store(""sql"", url=""sqlite:///restaurant.sqlite"")\nworkspace.import_model(""model.json"")\n\n# 2. Getting a browser\ncube = workspace.cube(""restaurant_details"")\nbrowser = workspace.browser(cube)\ndimension = cube.dimension(""location"")\n\n\n# Rolling up to State\nprint(""\\n""\n      ""Roll up to state\\n""\n      ""================"")\n\ncell = Cell(browser.cube)\nrollup(cell, ""location"")\n\n\n# Drilling down into the cities of each state\nprint(""\\n""\n      ""Drill down by state\\n""\n      ""==================="")\ndrilldown(cell, ""location"", 3)\n\n\n# Slicing by a particular state\nprint(""\\n""\n      ""Slice by State\\n""\n      ""=============="")\ncell = cell.slice(PointCut(""location"", [""CA""]))\ndrilldown(cell, ""location"", 2)\n'"
OLAPExploration/prepare_data.py,0,"b'from cubes.tutorial.sql import create_table_from_csv\nfrom sqlalchemy import create_engine\nimport sys\n\n# Setting encoding to UTF-8\nreload(sys)\nsys.setdefaultencoding(\'utf8\')\n\n# FACT table name\nFACT_TABLE = ""restaurant_details""\nprint(""preparing data..."")\nengine = create_engine(\'sqlite:///restaurant.sqlite\')\n\n# Creating fact table from restaurant_details.csv\ncreate_table_from_csv(engine,\n                      ""./restaurant_details.csv"",\n                      table_name=FACT_TABLE,\n                      fields=[\n                          (""id"", ""integer""),\n                          (""number_of_reviews"", ""integer""),\n                          (""price_range"", ""float""),\n                          (""ratingValue"", ""float""),\n                          (""name"", ""string""),\n                          (""street"", ""string""),\n                          (""city"", ""string""),\n                          (""state"", ""string""),\n                          (""zipcode"", ""integer"")]\n                      )\n\nprint(""restaurant.sqlite created"")\n'"
Scripts/TagAdjectives.py,0,"b'import fileinput\nimport os\nimport re\n\nimport nltk\n\ndirectory = ""../Data/Test Set""\nfileCount = 0\nfor filename in os.listdir(directory):\n    f = fileinput.input(os.path.join(directory, filename), inplace=True)\n\n    # Marking up train set (200 files)\n    fileCount += 1\n    if fileCount > 200:\n        f.close()\n        break\n\n    tagged = None\n    for line in f:\n\n        # Changing to lower case\n        line = line.lower()\n\n        # Removing the new line character at the end of the line\n        line = line.rstrip(\'\\n\')\n\n        # Removing special characters specific to regex matching\n        # (*, +, [, ]) from line\n        line = re.sub(r\'\\*\', \'\', line)\n        line = re.sub(r\'\\[\', \'(\', line)\n        line = re.sub(r\'\\]\', \')\', line)\n        line = re.sub(r\'\\+\', \'-\', line)\n\n        # Splitting the words in the line into tokens\n        tokens = nltk.word_tokenize(line)\n\n        # POS Tagging the tokens\n        tagged = nltk.pos_tag(tokens)\n\n        # Keeping a list of already tagged adjectives so that duplicates don\'t get\n        # tagged again\n        tagged_adjectives = []\n        text_to_replace = None\n        for i in range(0, len(tagged)):\n\n            if (tagged[i][0] not in tagged_adjectives) \\\n                    and (tagged[i][1] == \'JJ\' or tagged[i][1] == \'JJR\' or tagged[i][1] == \'JJS\'):\n                # Surrounding the identified adjective with <adj>...</adj> tags\n                # original_text\n                text_to_replace = ""<adj> "" + tagged[i][0] + "" </adj>""\n\n                # Marking up the adjective with <adj>...</adj> tags\n                line = re.sub(r""\\b%s\\b"" % tagged[i][0], text_to_replace, line)\n\n                # Adding the word to the list of tagged adjectives\n                tagged_adjectives.append(tagged[i][0])\n        if line != \'\\n\':\n            # Writing back to the file\n            print line\n    f.close()\n'"
Data/Features/__init__.py,0,b''
Data/Features/gen_fys_test.py,0,"b'"""""" Take a text document \n1) look for words withing tag\n2) extract features and populate vector for each adjective\n""""""\n\nimport os\nimport re\nfrom collections import defaultdict\nfrom sets import Set\n\nimport nltk\nimport numpy\n\n\ndef hasNumbers(inputString):\n    return any(char.isdigit() for char in inputString)\n\n\ndef GenNegFys(list_of_words, noun_set, adj_list):\n    features = []\n    negative_words = []\n\n    tag1 = ""<adj>""\n    tag2 = ""</adj>""\n    tag_set = Set([tag1, tag2])\n\n    for windx in range(len(list_of_words)):\n\n        prev_word_indx = windx - 1\n\n        if prev_word_indx >= 0 and list_of_words[windx] not in tag_set and tag1 not in list_of_words[\n            windx] and tag2 not in list_of_words[windx]:\n\n            """""" Feature - len in chars """"""\n\n            fys_list = []\n\n            fys_list.append(len(list_of_words[windx]))\n\n            """""" Feature-Preceded by another adj """"""\n\n            prev_word_indx_2 = prev_word_indx - 1\n            prev_word_2 = """"\n\n            if prev_word_indx_2 > 0:\n                prev_word_2 = list_of_words[prev_word_indx_2]\n\n            if prev_word_2 in adj_list:\n\n                fys_list.append(int(1))\n            else:\n                fys_list.append(int(0))\n\n            """""" Feature- Rest of them """"""\n\n            prev_word = list_of_words[prev_word_indx]\n\n            if prev_word.lower() == ""a"" or prev_word.lower() == ""an"" or prev_word_2.lower() == ""a"" or prev_word_2.lower() == ""an"":\n\n                fys_list.append(int(1))\n\n            else:\n                fys_list.append(int(0))\n\n            if prev_word.lower() == ""was"" or prev_word.lower() == ""is"" or prev_word_2.lower() == ""was"" or prev_word_2.lower() == ""is"":\n\n                fys_list.append(int(1))\n\n            else:\n                fys_list.append(int(0))\n\n            if prev_word.lower() == ""are"" or prev_word.lower() == ""were"" or prev_word_2.lower() == ""are"" or prev_word_2.lower() == ""were"":\n\n                fys_list.append(int(1))\n\n            else:\n                fys_list.append(int(0))\n\n            if prev_word.lower() == ""so"" or prev_word_2.lower() == ""so"":\n\n                fys_list.append(int(1))\n\n            else:\n                fys_list.append(int(0))\n\n            if prev_word.lower() == ""super"" or prev_word_2.lower() == ""super"":\n\n                fys_list.append(int(1))\n\n            else:\n                fys_list.append(int(0))\n\n            if prev_word.lower() == ""very"" or prev_word_2.lower() == ""very"":\n\n                fys_list.append(int(1))\n            else:\n\n                fys_list.append(int(0))\n\n            suc_word_indx = windx + 1\n            suc_word = """"\n\n            if suc_word_indx < len(list_of_words):\n                suc_word = list_of_words[suc_word_indx]\n\n            if suc_word in noun_set:\n\n                fys_list.append(int(1))\n            else:\n\n                fys_list.append(int(0))\n\n            if sum(fys_list[1:8]) >= 1:\n                features.append(fys_list)\n                negative_words.append(list_of_words[windx])\n\n    return features, negative_words\n\n\n"""""" An adjective is only one word long """"""\n\np = re.compile(""<adj> (\\w+) </adj>"")\n\ntesting_words = []\nfeatures = []\ntarget_label = []\n\nlist_indx = 0\n\ndirectory = ""/home/sabareesh/DataScience/DataScience-Foodie/Data/Test_Set/""\n\nfile_count = 0\n\nfor filename in os.listdir(directory):\n\n    filepath = directory + filename\n\n    file_count += 1\n\n    with open(filepath, \'r\') as myFile:\n        data = myFile.read().replace(\'\\n\', \'\')\n\n    """""" Same adjective may appear multiple times with\n        different features thus a default dictionary\n        is created with key=word and value=tuple consisting of\n        (list_indx,visited_flag). Thus a key will point to a list\n        if multiple occurences are present """"""\n\n    tokens = nltk.word_tokenize(data)\n    tagged = nltk.pos_tag(tokens)\n    nouns = [word for word, pos in tagged if pos.startswith(\'N\')]\n    cleaned_nouns = [word for word in nouns if word != \'>\' and word != \'<\' and word != \'/adj\' and word != \'adj\']\n    noun_set = Set(cleaned_nouns)\n\n    list_of_words = data.split()\n\n    index_list = list(range(0, len(list_of_words)))\n    flag_list = [0] * len(list_of_words)\n\n    index_flag_list = zip(index_list, flag_list)\n\n    word_dict = defaultdict(list)\n\n    for i in range(len(list_of_words)):\n        word_dict[list_of_words[i]].append(index_flag_list[i])\n\n    adj_list = p.findall(data)\n\n    positive_words = []\n\n    for adj in adj_list:\n\n        if len(adj) >= 4:\n\n            positive_words.append(adj)\n\n            """""" Length """"""\n\n            features.append([])\n\n            features[list_indx].append(len(adj))\n\n            """""" Finding index,visited list from dictionary """"""\n\n            cur_indx = list_of_words.index(adj)\n\n            indx_visited_list = word_dict[adj]\n\n            for i in range(len(indx_visited_list)):\n\n                if indx_visited_list[i][1] == 0:\n                    cur_indx = indx_visited_list[i][0]\n                    indx_visited_list[i] = (cur_indx, 1)\n                    break\n\n            """""" Updating word_dict with visited information """"""\n\n            word_dict[adj] = indx_visited_list\n\n            prev_word_indx = cur_indx - 2\n            prev_word_indx_2 = prev_word_indx - 1\n\n            suc_word_indx = cur_indx + 2\n            prev_word = """"\n            prev_word_2 = """"\n\n            if prev_word_indx_2 >= 0:\n                prev_word_2 = list_of_words[prev_word_indx_2]\n\n            if prev_word_indx >= 0:\n                prev_word = list_of_words[prev_word_indx]\n\n            """""" Preceded by another adjective """"""\n\n            if prev_word_2 in adj_list:\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            """""" Preceded by was/a/.. """"""\n\n            if prev_word.lower() == ""a"" or prev_word.lower() == ""an"" or prev_word_2.lower() == ""a"" or prev_word_2.lower() == ""an"":\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            if prev_word.lower() == ""was"" or prev_word.lower() == ""is"" or prev_word_2.lower() == ""was"" or prev_word_2.lower() == ""is"":\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            if prev_word.lower() == ""are"" or prev_word.lower() == ""were"" or prev_word_2.lower() == ""are"" or prev_word_2.lower() == ""were"":\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            if prev_word.lower() == ""so"" or prev_word_2.lower() == ""so"":\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            if prev_word.lower() == ""super"" or prev_word_2.lower() == ""super"":\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            """""" Preceded by very """"""\n\n            if prev_word.lower() == ""very"" or prev_word_2.lower() == ""very"":\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            """""" Succeded by noun """"""\n\n            if suc_word_indx < len(list_of_words):\n                suc_word = list_of_words[suc_word_indx]\n\n            if suc_word in noun_set:\n\n                features[list_indx].append(int(1))\n            else:\n\n                features[list_indx].append(int(0))\n\n            list_indx += 1\n\n    [negative_fys, negative_words] = GenNegFys(list_of_words, noun_set, adj_list)\n    features = features + negative_fys\n    list_indx = list_indx + len(negative_fys)\n    target_label = target_label + [1] * len(positive_words) + [0] * len(negative_words)\n    testing_words = testing_words + positive_words + negative_words\n\n    if file_count == 100:\n        break\n\nprint target_label.count(1)\nprint target_label.count(0)\n\nnumpy.save(\'Data/Testing/test_features.npy\', features)\nnumpy.savetxt(\'Data/Testing/test_features.txt\', features)\n\nnumpy.save(\'Data/Testing/test_target_label.npy\', target_label)\nnumpy.savetxt(\'Data/Testing/test_target_label.txt\', target_label)\n\nnumpy.savetxt(\'Data/Testing/testing_words.txt\', testing_words, fmt=\'%s\')\nnumpy.save(\'Data/Testing/testing_words.npy\', testing_words)\n'"
Data/Features/gen_neg_fys.py,0,"b'"""""" Take a text document\n1) Ignore words in the adj tag\n2) Prune the negative examples\n\t- those that are atleast 4 chars long and have atleast one of ""preceding chars"" features set\n""""""\n\nfrom sets import Set\n\n\ndef GenNegFys(list_of_words, target_num, noun_set, adj_list):\n    features = []\n    negative_words = []\n\n    tag1 = ""<adj>""\n    tag2 = ""</adj>""\n    tag_set = Set([tag1, tag2])\n\n    num_negative = 0\n\n    for windx in range(len(list_of_words)):\n\n        prev_word_indx = windx - 1\n\n        if num_negative > target_num:\n            break\n\n        if prev_word_indx >= 0 and list_of_words[windx] not in tag_set and tag1 not in list_of_words[\n            windx] and tag2 not in list_of_words[windx]:\n\n            """""" Feature - len in chars """"""\n\n            fys_list = []\n\n            fys_list.append(len(list_of_words[windx]))\n\n            """""" Feature-Preceded by another adj """"""\n\n            prev_word_indx_2 = prev_word_indx - 1\n            prev_word_2 = """"\n\n            if prev_word_indx_2 > 0:\n                prev_word_2 = list_of_words[prev_word_indx_2]\n\n            if prev_word_2 in adj_list:\n\n                fys_list.append(int(1))\n            else:\n                fys_list.append(int(0))\n\n            """""" Feature- Rest of them """"""\n\n            prev_word = list_of_words[prev_word_indx]\n\n            if prev_word.lower() == ""a"" or prev_word.lower() == ""an"" or prev_word_2.lower() == ""a"" or prev_word_2.lower() == ""an"":\n\n                fys_list.append(int(1))\n\n            else:\n                fys_list.append(int(0))\n\n            if prev_word.lower() == ""was"" or prev_word.lower() == ""is"" or prev_word_2.lower() == ""was"" or prev_word_2.lower() == ""is"":\n\n                fys_list.append(int(1))\n\n            else:\n                fys_list.append(int(0))\n\n            if prev_word.lower() == ""are"" or prev_word.lower() == ""were"" or prev_word_2.lower() == ""are"" or prev_word_2.lower() == ""were"":\n\n                fys_list.append(int(1))\n\n            else:\n                fys_list.append(int(0))\n\n            if prev_word.lower() == ""so"" or prev_word_2.lower() == ""so"":\n\n                fys_list.append(int(1))\n\n            else:\n                fys_list.append(int(0))\n\n            if prev_word.lower() == ""super"" or prev_word_2.lower() == ""super"":\n\n                fys_list.append(int(1))\n\n            else:\n                fys_list.append(int(0))\n\n            if prev_word.lower() == ""very"" or prev_word_2.lower() == ""very"":\n\n                fys_list.append(int(1))\n            else:\n\n                fys_list.append(int(0))\n\n            suc_word_indx = windx + 1\n            suc_word = """"\n\n            if suc_word_indx < len(list_of_words):\n                suc_word = list_of_words[suc_word_indx]\n\n            if suc_word in noun_set:\n                fys_list.append(int(1))\n            else:\n                fys_list.append(int(0))\n\n            """""" Pruning examples""""""\n\n            if sum(fys_list[1:8]) >= 1:\n                features.append(fys_list)\n                negative_words.append(list_of_words[windx])\n                num_negative += 1\n\n    if num_negative < target_num:\n\n        negative_word_set = Set(negative_words)\n\n        for windx in range(len(list_of_words)):\n\n            prev_word_indx = windx - 1\n\n            if num_negative >= target_num:\n                break\n\n            if prev_word_indx >= 0 and list_of_words[windx] not in tag_set and list_of_words[\n                windx] not in negative_word_set and tag1 not in list_of_words[windx] and tag2 not in list_of_words[\n                windx]:\n\n                if (len(list_of_words[windx]) >= 4):\n                    fys_list = [len(list_of_words[windx]), 0, 0, 0, 0, 0, 0, 0, 0]\n                    features.append(fys_list)\n                    negative_words.append(list_of_words[windx])\n                    num_negative += 1\n\n    return features, negative_words\n'"
Data/Features/gen_pos_fys.py,0,"b'"""""" Take a text document \n1) look for words withing tag\n2) extract features and populate vector for each adjective\n""""""\n\nimport os\nimport re\nfrom collections import defaultdict\nfrom sets import Set\n\nimport nltk\nimport numpy\n\nfrom gen_neg_fys import GenNegFys\n\n"""""" An adjective is only one word long """"""\n\np = re.compile(""<adj> (\\w+) </adj>"")\n\ntraining_words = []\nfeatures = []\nfeature_names = []\ntarget_label = []\n\nfeature_names.append(""Length in chars"")\nfeature_names.append(""Is preceded by another adj"")\nfeature_names.append(""Is preceded by a/an "")\nfeature_names.append(""Is preceded by was/is"")\nfeature_names.append(""Is preceded by are/were"")\nfeature_names.append(""Is preceded by so"")\nfeature_names.append(""Is preceded by super"")\nfeature_names.append(""Is preceded by very"")\nfeature_names.append(""Is succeded by noun"")\n\nlist_indx = 0\n\ndirectory = ""/home/sabareesh/DataScience/DataScience-Foodie/Data/Dev_Set/""\n\nit = 0\n\nfor filename in os.listdir(directory):\n\n    filepath = directory + filename\n\n    with open(filepath, \'r\') as myFile:\n        data = myFile.read().replace(\'\\n\', \'\')\n\n    """""" Same adjective may appear multiple times with\n        different features thus a default dictionary\n        is created with key=word and value=tuple consisting of\n        (list_indx,visited_flag). Thus a key will point to a list\n        if multiple occurences are present """"""\n\n    tokens = nltk.word_tokenize(data)\n    tagged = nltk.pos_tag(tokens)\n    nouns = [word for word, pos in tagged if pos.startswith(\'N\')]\n    cleaned_nouns = [word for word in nouns if word != \'>\' and word != \'<\' and word != \'/adj\' and word != \'adj\']\n    noun_set = Set(cleaned_nouns)\n\n    list_of_words = data.split()\n\n    index_list = list(range(0, len(list_of_words)))\n    flag_list = [0] * len(list_of_words)\n\n    index_flag_list = zip(index_list, flag_list)\n\n    word_dict = defaultdict(list)\n\n    for i in range(len(list_of_words)):\n        word_dict[list_of_words[i]].append(index_flag_list[i])\n\n    adj_list = p.findall(data)\n\n    positive_words = []\n\n    for adj in adj_list:\n\n        if len(adj) >= 4:\n\n            positive_words.append(adj)\n\n            """""" Length """"""\n\n            features.append([])\n\n            features[list_indx].append(len(adj))\n\n            """""" Finding index,visited list from dictionary """"""\n\n            cur_indx = list_of_words.index(adj)\n\n            indx_visited_list = word_dict[adj]\n\n            for i in range(len(indx_visited_list)):\n\n                if indx_visited_list[i][1] == 0:\n                    cur_indx = indx_visited_list[i][0]\n                    indx_visited_list[i] = (cur_indx, 1)\n                    break\n\n            """""" Updating word_dict with visited information """"""\n\n            word_dict[adj] = indx_visited_list\n\n            prev_word_indx = cur_indx - 2\n            prev_word_indx_2 = prev_word_indx - 1\n\n            prev_word = """"\n            prev_word_2 = """"\n\n            suc_word_indx = cur_indx + 2\n            suc_word = """"\n\n            if prev_word_indx_2 >= 0:\n                prev_word_2 = list_of_words[prev_word_indx_2]\n\n            if prev_word_indx >= 0:\n                prev_word = list_of_words[prev_word_indx]\n\n            """""" Preceded by another adjective """"""\n\n            if prev_word_2 in adj_list:\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            """""" Preceded by was/a/.. """"""\n\n            if prev_word.lower() == ""a"" or prev_word.lower() == ""an"" or prev_word_2.lower() == ""a"" or prev_word_2.lower() == ""an"":\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            if prev_word.lower() == ""was"" or prev_word.lower() == ""is"" or prev_word_2.lower() == ""was"" or prev_word_2.lower() == ""is"":\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            if prev_word.lower() == ""are"" or prev_word.lower() == ""were"" or prev_word_2.lower() == ""are"" or prev_word_2.lower() == ""were"":\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            if prev_word.lower() == ""so"" or prev_word_2.lower() == ""so"":\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            if prev_word.lower() == ""super"" or prev_word_2.lower() == ""super"":\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            """""" Preceded by very """"""\n\n            if prev_word.lower() == ""very"" or prev_word_2.lower() == ""very"":\n\n                features[list_indx].append(int(1))\n\n            else:\n                features[list_indx].append(int(0))\n\n            """""" Succeded by noun """"""\n\n            if suc_word_indx < len(list_of_words):\n                suc_word = list_of_words[suc_word_indx]\n\n            if suc_word in noun_set:\n\n                features[list_indx].append(int(1))\n            else:\n\n                features[list_indx].append(int(0))\n\n            list_indx += 1\n\n    target_num = len(positive_words) + 10\n    [negative_fys, negative_words] = GenNegFys(list_of_words, target_num, noun_set, adj_list)\n    features = features + negative_fys\n    list_indx = list_indx + len(negative_fys)\n    target_label = target_label + [1] * len(positive_words) + [0] * len(negative_words)\n    training_words = training_words + positive_words + negative_words\n\nprint target_label.count(1)\nprint target_label.count(0)\n\nnumpy.save(\'Data/Training/features.npy\', features)\nnumpy.savetxt(\'Data/Training/features.txt\', features)\n\nnumpy.save(\'Data/Training/target_label.npy\', target_label)\nnumpy.savetxt(\'Data/Training/target_label.txt\', target_label)\n\nnumpy.savetxt(\'Data/Training/training_words.txt\', training_words, fmt=\'%s\')\n\nnumpy.savetxt(\'Data/Training/feature_names.txt\', feature_names, fmt=\'%s\')\n\nnumpy.save(\'Data/Training/training_words.npy\', training_words)\n\nnumpy.save(\'Data/Training/feature_names.npy\', feature_names)\n'"
Data/Features/gridsearch_svm.py,3,"b'from __future__ import print_function\n\nimport numpy as np\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\n\nprint(__doc__)\n\nfeatures = np.load(\'Data/Training/features.npy\')\nlabels = np.load(\'Data/Training/target_label.npy\')\ntraining_words = np.load(\'Data/Training/training_words.npy\')\n\nF_train, F_test, L_train, L_test = train_test_split(features, labels, test_size=0.5, random_state=0)\n\ntuned_parameters = [{\'kernel\': [\'rbf\'], \'gamma\': [1e-3, 1e-4],\n                     \'C\': [1, 10, 100, 1000]},\n                    {\'kernel\': [\'linear\'], \'C\': [1, 10, 100, 1000]}]\n\nclf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n                   scoring=\'precision_macro\')\nclf.fit(F_train, L_train)\n\nprint(""Best parameters set found on development set:"")\nprint()\nprint(clf.best_params_)\nprint()\nprint(""Grid scores on development set:"")\nprint()\nmeans = clf.cv_results_[\'mean_test_score\']\nstds = clf.cv_results_[\'std_test_score\']\nfor mean, std, params in zip(means, stds, clf.cv_results_[\'params\']):\n    print(""%0.3f (+/-%0.03f) for %r"" % (mean, std * 2, params))\n\nprint()\n\nprint(""Detailed classification report:"")\nprint()\nprint(""The model is trained on the full development set."")\nprint(""The scores are computed on the full evaluation set."")\nprint()\nL_true, L_pred = L_test, clf.predict(F_test)\nprint(classification_report(L_true, L_pred))\nprint()\n'"
Data/Features/precision_recall_curve.py,3,"b""import numpy as np\nimport sklearn.metrics\nfrom matplotlib import pyplot as plt\n\nfeatures = np.load('Data/Training/features.npy')\nlabels = np.load('Data/Training/target_label.npy')\ntraining_words = np.load('Data/Training/training_words.npy')\n\nclf = sklearn.svm.LinearSVC().fit(features, labels)\ndecision_values = clf.decision_function(features)\n\nprecision, recall, thresholds = sklearn.metrics.precision_recall_curve(labels, decision_values)\n\nmin_prcsn = 0.94\nmin_thrshld = min([thresholds[i] for i in range(len(thresholds)) if precision[i] > min_prcsn])\n\nprint min_thrshld\n\nplt.plot(recall, precision)\nplt.show()\n"""
Data/csv/__init__.py,0,b''
yelp_spider/yelp_spider/__init__.py,0,b''
yelp_spider/yelp_spider/items.py,0,b'# -*- coding: utf-8 -*-\n\n# Define here the models for your scraped items\n#\n# See documentation in:\n# http://doc.scrapy.org/en/latest/topics/items.html\n\nimport scrapy\n\n\nclass YelpSpiderItem(scrapy.Item):\n    # define the fields for your item here like:\n    # name = scrapy.Field()\n    pass\n'
yelp_spider/yelp_spider/middlewares.py,0,"b""# -*- coding: utf-8 -*-\n\n# Define here the models for your spider middleware\n#\n# See documentation in:\n# http://doc.scrapy.org/en/latest/topics/spider-middleware.html\n\nfrom scrapy import signals\n\n\nclass YelpSpiderSpiderMiddleware(object):\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the spider middleware does not modify the\n    # passed objects.\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s\n\n    def process_spider_input(response, spider):\n        # Called for each response that goes through the spider\n        # middleware and into the spider.\n\n        # Should return None or raise an exception.\n        return None\n\n    def process_spider_output(response, result, spider):\n        # Called with the results returned from the Spider, after\n        # it has processed the response.\n\n        # Must return an iterable of Request, dict or Item objects.\n        for i in result:\n            yield i\n\n    def process_spider_exception(response, exception, spider):\n        # Called when a spider or process_spider_input() method\n        # (from other spider middleware) raises an exception.\n\n        # Should return either None or an iterable of Response, dict\n        # or Item objects.\n        pass\n\n    def process_start_requests(start_requests, spider):\n        # Called with the start requests of the spider, and works\n        # similarly to the process_spider_output() method, except\n        # that it doesn\xe2\x80\x99t have a response associated.\n\n        # Must return only requests (not items).\n        for r in start_requests:\n            yield r\n\n    def spider_opened(self, spider):\n        spider.logger.info('Spider opened: %s' % spider.name)\n"""
yelp_spider/yelp_spider/pipelines.py,0,"b""# -*- coding: utf-8 -*-\n\n# Define your item pipelines here\n#\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html\n\n\nclass YelpSpiderPipeline(object):\n    def process_item(self, item, spider):\n        return item\n"""
yelp_spider/yelp_spider/settings.py,0,"b""# -*- coding: utf-8 -*-\n\n# Scrapy settings for yelp_spider project\n#\n# For simplicity, this file contains only settings considered important or\n# commonly used. You can find more settings consulting the documentation:\n#\n#     http://doc.scrapy.org/en/latest/topics/settings.html\n#     http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html\n#     http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html\n\nBOT_NAME = 'yelp_spider'\n\nSPIDER_MODULES = ['yelp_spider.spiders']\nNEWSPIDER_MODULE = 'yelp_spider.spiders'\n\n\n# Crawl responsibly by identifying yourself (and your website) on the user-agent\n#USER_AGENT = 'yelp_spider (+http://www.yourdomain.com)'\n\n# Obey robots.txt rules\nROBOTSTXT_OBEY = False\n\n# Configure maximum concurrent requests performed by Scrapy (default: 16)\n#CONCURRENT_REQUESTS = 32\n\n# Configure a delay for requests for the same website (default: 0)\n# See http://scrapy.readthedocs.org/en/latest/topics/settings.html#download-delay\n# See also autothrottle settings and docs\n#DOWNLOAD_DELAY = 3\n# The download delay setting will honor only one of:\n#CONCURRENT_REQUESTS_PER_DOMAIN = 16\n#CONCURRENT_REQUESTS_PER_IP = 16\n\n# Disable cookies (enabled by default)\n#COOKIES_ENABLED = False\n\n# Disable Telnet Console (enabled by default)\n#TELNETCONSOLE_ENABLED = False\n\n# Override the default request headers:\n#DEFAULT_REQUEST_HEADERS = {\n#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n#   'Accept-Language': 'en',\n#}\n\n# Enable or disable spider middlewares\n# See http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html\n#SPIDER_MIDDLEWARES = {\n#    'yelp_spider.middlewares.YelpSpiderSpiderMiddleware': 543,\n#}\n\n# Enable or disable downloader middlewares\n# See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html\n#DOWNLOADER_MIDDLEWARES = {\n#    'yelp_spider.middlewares.MyCustomDownloaderMiddleware': 543,\n#}\n\n# Enable or disable extensions\n# See http://scrapy.readthedocs.org/en/latest/topics/extensions.html\n#EXTENSIONS = {\n#    'scrapy.extensions.telnet.TelnetConsole': None,\n#}\n\n# Configure item pipelines\n# See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html\n#ITEM_PIPELINES = {\n#    'yelp_spider.pipelines.SomePipeline': 300,\n#}\n\n# Enable and configure the AutoThrottle extension (disabled by default)\n# See http://doc.scrapy.org/en/latest/topics/autothrottle.html\n#AUTOTHROTTLE_ENABLED = True\n# The initial download delay\n#AUTOTHROTTLE_START_DELAY = 5\n# The maximum download delay to be set in case of high latencies\n#AUTOTHROTTLE_MAX_DELAY = 60\n# The average number of requests Scrapy should be sending in parallel to\n# each remote server\n#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\n# Enable showing throttling stats for every response received:\n#AUTOTHROTTLE_DEBUG = False\n\n# Enable and configure HTTP caching (disabled by default)\n# See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings\n#HTTPCACHE_ENABLED = True\n#HTTPCACHE_EXPIRATION_SECS = 0\n#HTTPCACHE_DIR = 'httpcache'\n#HTTPCACHE_IGNORE_HTTP_CODES = []\n#HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'\n"""
zomato_spider/zomato_spider/__init__.py,0,b''
zomato_spider/zomato_spider/items.py,0,b'# -*- coding: utf-8 -*-\n\n# Define here the models for your scraped items\n#\n# See documentation in:\n# http://doc.scrapy.org/en/latest/topics/items.html\n\nimport scrapy\n\n\nclass ZomatoSpiderItem(scrapy.Item):\n    # define the fields for your item here like:\n    # name = scrapy.Field()\n    pass\n'
zomato_spider/zomato_spider/middlewares.py,0,"b""# -*- coding: utf-8 -*-\n\n# Define here the models for your spider middleware\n#\n# See documentation in:\n# http://doc.scrapy.org/en/latest/topics/spider-middleware.html\n\nfrom scrapy import signals\n\n\nclass ZomatoSpiderSpiderMiddleware(object):\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the spider middleware does not modify the\n    # passed objects.\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s\n\n    def process_spider_input(response, spider):\n        # Called for each response that goes through the spider\n        # middleware and into the spider.\n\n        # Should return None or raise an exception.\n        return None\n\n    def process_spider_output(response, result, spider):\n        # Called with the results returned from the Spider, after\n        # it has processed the response.\n\n        # Must return an iterable of Request, dict or Item objects.\n        for i in result:\n            yield i\n\n    def process_spider_exception(response, exception, spider):\n        # Called when a spider or process_spider_input() method\n        # (from other spider middleware) raises an exception.\n\n        # Should return either None or an iterable of Response, dict\n        # or Item objects.\n        pass\n\n    def process_start_requests(start_requests, spider):\n        # Called with the start requests of the spider, and works\n        # similarly to the process_spider_output() method, except\n        # that it doesn\xe2\x80\x99t have a response associated.\n\n        # Must return only requests (not items).\n        for r in start_requests:\n            yield r\n\n    def spider_opened(self, spider):\n        spider.logger.info('Spider opened: %s' % spider.name)\n"""
zomato_spider/zomato_spider/pipelines.py,0,"b""# -*- coding: utf-8 -*-\n\n# Define your item pipelines here\n#\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html\n\n\nclass ZomatoSpiderPipeline(object):\n    def process_item(self, item, spider):\n        return item\n"""
zomato_spider/zomato_spider/settings.py,0,"b""# -*- coding: utf-8 -*-\n\n# Scrapy settings for zomato_spider project\n#\n# For simplicity, this file contains only settings considered important or\n# commonly used. You can find more settings consulting the documentation:\n#\n#     http://doc.scrapy.org/en/latest/topics/settings.html\n#     http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html\n#     http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html\n\nBOT_NAME = 'zomato_spider'\n\nSPIDER_MODULES = ['zomato_spider.spiders']\nNEWSPIDER_MODULE = 'zomato_spider.spiders'\n\n\n# Crawl responsibly by identifying yourself (and your website) on the user-agent\n#USER_AGENT = 'zomato_spider (+http://www.yourdomain.com)'\n\n# Obey robots.txt rules\nROBOTSTXT_OBEY = False\n\n# Configure maximum concurrent requests performed by Scrapy (default: 16)\n#CONCURRENT_REQUESTS = 32\n\n# Configure a delay for requests for the same website (default: 0)\n# See http://scrapy.readthedocs.org/en/latest/topics/settings.html#download-delay\n# See also autothrottle settings and docs\n#DOWNLOAD_DELAY = 3\n# The download delay setting will honor only one of:\n#CONCURRENT_REQUESTS_PER_DOMAIN = 16\n#CONCURRENT_REQUESTS_PER_IP = 16\n\n# Disable cookies (enabled by default)\n#COOKIES_ENABLED = False\n\n# Disable Telnet Console (enabled by default)\n#TELNETCONSOLE_ENABLED = False\n\n# Override the default request headers:\n#DEFAULT_REQUEST_HEADERS = {\n#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n#   'Accept-Language': 'en',\n#}\n\n# Enable or disable spider middlewares\n# See http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html\n#SPIDER_MIDDLEWARES = {\n#    'zomato_spider.middlewares.ZomatoSpiderSpiderMiddleware': 543,\n#}\n\n# Enable or disable downloader middlewares\n# See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html\nDOWNLOADER_MIDDLEWARES = {\n#    'zomato_spider.middlewares.MyCustomDownloaderMiddleware': 543,\n      'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware':None\n}\n\n# Enable or disable extensions\n# See http://scrapy.readthedocs.org/en/latest/topics/extensions.html\n#EXTENSIONS = {\n#    'scrapy.extensions.telnet.TelnetConsole': None,\n#}\n\n# Configure item pipelines\n# See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html\n#ITEM_PIPELINES = {\n#    'zomato_spider.pipelines.SomePipeline': 300,\n#}\n\n# Enable and configure the AutoThrottle extension (disabled by default)\n# See http://doc.scrapy.org/en/latest/topics/autothrottle.html\n#AUTOTHROTTLE_ENABLED = True\n# The initial download delay\n#AUTOTHROTTLE_START_DELAY = 5\n# The maximum download delay to be set in case of high latencies\n#AUTOTHROTTLE_MAX_DELAY = 60\n# The average number of requests Scrapy should be sending in parallel to\n# each remote server\n#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\n# Enable showing throttling stats for every response received:\n#AUTOTHROTTLE_DEBUG = False\n\n# Enable and configure HTTP caching (disabled by default)\n# See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings\n#HTTPCACHE_ENABLED = True\n#HTTPCACHE_EXPIRATION_SECS = 0\n#HTTPCACHE_DIR = 'httpcache'\n#HTTPCACHE_IGNORE_HTTP_CODES = []\n#HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'\n"""
yelp_spider/yelp_spider/spiders/FoodieSpider.py,0,"b'import scrapy\n\nfile_indx = 0;\n\n\nclass FoodieSpider(scrapy.Spider):\n    name = ""Foodie""\n\n    start_urls = [\n        ""https://www.yelp.com/search?cflt=restaurants&find_loc=New+York%2C+NY&start=1"",\n        ""https://www.yelp.com/search?cflt=restaurants&find_loc=San+Jose%2C+CA&start=1"",\n        ""https://www.yelp.com/search?cflt=restaurants&find_loc=Austin%2C+TX&start=1"",\n        ""https://www.yelp.com/search?cflt=restaurants&find_loc=Seattle%2C+WA&start=1"",\n    ]\n\n    for i in range(1, 90):\n        start_urls.append(""https://www.yelp.com/search?cflt=restaurants&find_loc=New+York%2C+NY&start="" + str(i * 10))\n        start_urls.append(""https://www.yelp.com/search?cflt=restaurants&find_loc=San+Jose%2C+CA&start="" + str(i * 10))\n        start_urls.append(""https://www.yelp.com/search?cflt=restaurants&find_loc=Austin%2C+TX&start="" + str(i * 10))\n        start_urls.append(""https://www.yelp.com/search?cflt=restaurants&find_loc=Seattle%2C+WA&start="" + str(i * 10))\n\n    def parse(self, response):\n\n        for href in response.css(\'h3.search-result-title  a::attr(href)\').extract()[1:]:\n            yield scrapy.Request(response.urljoin(href), callback=self.parse_author)\n\n    def parse_author(self, response):\n\n        review_list = response.xpath(\'//p[@itemprop = ""description""]//text()\')\n\n        global file_indx;\n\n        if (file_indx <= 300):\n            for review_text in review_list:\n                filename = ""review"" + str(file_indx)\n                target = open(filename, \'w\')\n                target.write(review_text.extract().encode(\'ascii\', \'ignore\'))\n                target.close()\n                file_indx = file_indx + 1\n\n        address = [response.xpath(\'//span[@itemprop=""streetAddress""]//text()\').extract_first(),\n                   response.xpath(\'//span[@itemprop=""addressLocality""]//text()\').extract_first(),\n                   response.xpath(\'//span[@itemprop=""addressRegion""]//text()\').extract_first(),\n                   response.xpath(\'//span[@itemprop=""postalCode""]//text()\').extract_first(),\n                   ]\n\n        s = "" ""\n\n        yield {\n            \'number_of_reviews\': response.xpath(\'//span[@itemprop=""reviewCount""]//text()\').extract_first(),\n            \'ratingValue\': response.xpath(\'//meta[@itemprop=""ratingValue""]/@content\').extract_first(),\n            \'address\': s.join(address),\n            #\t\'telephone_number\':response.xpath(\'//span[@itemprop=""telephone""]//text()\').extract_first().strip(),\n            \'price_range\': response.xpath(\'//meta[@itemprop=""priceRange""]/@content\').extract_first(),\n            \'name\': response.xpath(\'//meta[@itemprop=""name""]/@content\').extract()[1],\n\n        }\n'"
yelp_spider/yelp_spider/spiders/__init__.py,0,b'# This package will contain the spiders of your Scrapy project\n#\n# Please refer to the documentation for information on how to create and manage\n# your spiders.\n'
zomato_spider/zomato_spider/spiders/FoodieSpider.py,0,"b'import scrapy\n\n\nclass FoodieSpider(scrapy.Spider):\n    name = ""Foodie""\n\n    start_urls = [\n        ""https://www.zomato.com/new-york-city/restaurants?page=1""\n        ""https://www.zomato.com/san-jose/restaurants?page=1""\n        ""https://www.zomato.com/austin/restaurants?page=1""\n        ""https://www.zomato.com/seattle/restaurants?page=1""\n    ]\n\n    for i in range(1, 30):\n        start_urls.append(""https://www.zomato.com/new-york-city/restaurants?page="" + str(i))\n        start_urls.append(""https://www.zomato.com/san-jose/restaurants?page="" + str(i))\n        start_urls.append(""https://www.zomato.com/austin/restaurants?page="" + str(i))\n        start_urls.append(""https://www.zomato.com/seattle/restaurants?page="" + str(i))\n\n    def parse(self, response):\n\n        name = response.css(""div.row a.result-title::text"").extract()\n        address = response.css(""div.row div.col-m-16::text"").extract()\n        price = response.css(""div.res-cost span.col-s-11::text"").extract()\n        rating = response.css(""div.ta-right div.rating-popup::text"").extract()\n        num_reviews = response.css(""div.ta-right a.result-reviews::text"").extract()\n\n        for name_val, address_val, price_val, rating_val, num_review_val in zip(name, address, price, rating,\n                                                                                num_reviews):\n            yield {\n                \'number_of_reviews\': str(num_review_val.strip()),\n                \'ratingValue\': str(rating_val.strip()),\n                \'address\': str(address_val.encode(\'ascii\', \'ignore\').strip()),\n                \'price_range\': str(price_val.strip()),\n                \'name\': str(name_val.encode(\'ascii\', \'ignore\').strip()),\n\n            }\n'"
zomato_spider/zomato_spider/spiders/__init__.py,0,b'# This package will contain the spiders of your Scrapy project\n#\n# Please refer to the documentation for information on how to create and manage\n# your spiders.\n'
