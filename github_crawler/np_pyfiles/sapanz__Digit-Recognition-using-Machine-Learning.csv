file_path,api_count,code
digitrecognition.py,2,"b'# -*- coding: utf-8 -*-\n""""""DigitRecognition.ipynb\n\nAutomatically generated by Colaboratory.\n\nOriginal file is located at\n    https://colab.research.google.com/drive/1F0HwuYpkq4saUi8odvOHCbpZlkHt7e_L\n\n#A simple convnet on the MNIST dataset\n\nThere are 70,000 images in MNIST dataset which are numbers from 0-9 having size 28 X 28 each.\nOur gole is to create a Convolution Neural Network which can classify these images into one of these 10 classes CORRECTLY!\n\nWe will build it 7 EASY steps so, let\'s get started!!\n\n![alt text](https://www.researchgate.net/profile/Pew-Thian_Yap/publication/224466484/figure/fig7/AS:302648906534920@1449168530938/Sample-images-from-the-MNIST-handwritten-digits-database.png)\n\n\n\nThis is how Machine will read number 8\n\n![alt text](https://cdn-images-1.medium.com/max/800/1*zY1qFB9aFfZz66YxxoI2aw.gif)\n""""""\n\n# Import keras, tensorflow and some helpers\nfrom __future__ import print_function\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as Kdff\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport cv2\n\n""""""# STEP 1: Load image data from MNIST""""""\n\n# define parameters for NN\nimg_rows, img_cols = 28, 28\nbatch_size = 128\nnum_classes = 10\nepochs = 12\n\n# load data\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# let\'s plot 4 images and their labels\nplt.subplot(221)\nplt.imshow(x_train[0], cmap=plt.get_cmap(\'gray\'))\nplt.title(y_train[0])\nplt.subplot(222)\nplt.imshow(x_train[1], cmap=plt.get_cmap(\'gray\'))\nplt.title(y_train[1])\nplt.subplot(223)\nplt.imshow(x_train[2], cmap=plt.get_cmap(\'gray\'))\nplt.title(y_train[2])\nplt.subplot(224)\nplt.imshow(x_train[3], cmap=plt.get_cmap(\'gray\'))\nplt.title(y_train[3])\nplt.show()\n\n""""""# STEP 2: Preprocess input data for Keras\n\n1. Reshape\n2. Convert our data type to float32 \n3. Normalize our data values to the range [0, 1]\n""""""\n\nprint(""shape of the image before reshaping it: "", x_train[0].shape)\n\nif K.image_data_format() == \'channels_first\':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nprint(""shape of the image after reshaping it"", x_train[0].shape)\n\nx_train = x_train.astype(\'float32\')\nx_test = x_test.astype(\'float32\')\nx_train /= 255\nx_test /= 255\n\n""""""# STEP 3: Preprocess class labels for Keras\n\nOne hot encoding\n\n![alt text](https://www.machinelearningplus.com/wp-content/uploads/2018/03/one-hot-encoding.png)\n""""""\n\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n\n""""""# STEP 4: Define model architecture\n\n# ![alt text](https://cdn-images-1.medium.com/max/800/1*bGBijVuJnTRj8025et0mcQ.gif)\n""""""\n\n# Keras automatically handles the connections between layers.\nmodel = Sequential()\n\n# number of kernel: 32 | Size: 3 X 3 | Activation function: Relu\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation=\'relu\',\n                 input_shape=input_shape))\n\n# add more layers\nmodel.add(Conv2D(64, (3, 3), activation=\'relu\'))      \nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# regularizing our model in order to prevent overfitting\nmodel.add(Dropout(0.25))\n\n# fully connected layer (1-D)\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation=\'relu\'))\nmodel.add(Dropout(0.5))\n\n# the final layer has an output size of 10, corresponding to the 10 classes of digits\nmodel.add(Dense(num_classes, activation=\'softmax\'))\n\nprint(model.summary())\n\n""""""# STEP 5:  Compile model""""""\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=[\'accuracy\'])\n\n""""""# STEP 6: Fit model on 60k training and Validate it on 10k images""""""\n\nhistory = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_test, y_test))\n\n""""""# STEP: 7 Evaluate model on test data""""""\n\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(\'Test loss:\', score[0])\nprint(\'Test accuracy:\', score[1])\n\n""""""# Test it on own image!!\n\n1. Create an image in paint\n2. Upload it here\n3. Pre-process it\n4. Evaluate on our model\n""""""\n\nimport cv2\nimg = mpimg.imread(\'1.png\')     # read image\nlabel = np.array([4])    # assign corect label to it\n\n# plot input image and label\nplt.imshow(img, cmap=plt.get_cmap(\'gray\'))\nplt.title(label)\n\n# pre-process\nimg = cv2.resize(img,(28,28))\nimg = img[:,:,0]\nimg = img.reshape(1, 28, 28,1)\n\nlabel = keras.utils.to_categorical(label, num_classes)\n\n# evalute on our model\nscore = model.evaluate(img, label, verbose=0)\nprint(\'Test accuracy:\', score[1])\n\npred = model.predict(img)\npredicted = np.argmax(pred, axis=1)\nprint(""Predicted Output: "", predicted)\n\n""""""# Visualization of Model Accuracy and Loss""""""\n\nplt.plot(history.history[""acc""])\nplt.plot(history.history[""val_acc""])\nplt.title(""Model Accuracy"")\nplt.xlabel(""Epoch"")\nplt.ylabel(""Accuracy"")\nplt.legend([""train"", ""validation""], loc=""upper left"")\nplt.show()\n\nplt.plot(history.history[""loss""])\nplt.plot(history.history[""val_loss""])\nplt.title(""Model Loss"")\nplt.xlabel(""Epoch"")\nplt.ylabel(""Loss"")\nplt.legend([""train"", ""validation""], loc=""upper left"")\nplt.show()'"
