file_path,api_count,code
LinearRegression.py,5,"b""from sklearn.datasets import make_regression\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nX, y= make_regression(n_samples=100, n_features=1, noise=0.4, bias=50)\n\n\n\n\ndef plotLine(theta0, theta1, X, y):\n    max_x = np.max(X) + 100\n    min_x = np.min(X) - 100\n\n\n    xplot = np.linspace(min_x, max_x, 1000)\n    yplot = theta0 + theta1 * xplot\n\n\n\n    plt.plot(xplot, yplot, color='#58b970', label='Regression Line')\n\n    plt.scatter(X,y)\n    plt.axis([-10, 10, 0, 200])\n    plt.show()\n\n\n\ndef hypothesis(theta0, theta1, x):\n    return theta0 + (theta1*x) \n\ndef cost(theta0, theta1, X, y):\n    costValue = 0 \n    for (xi, yi) in zip(X, y):\n        costValue += 0.5 * ((hypothesis(theta0, theta1, xi) - yi)**2)\n    return costValue\n\n\n\n\ndef derivatives(theta0, theta1, X, y):\n    dtheta0 = 0\n    dtheta1 = 0\n    for (xi, yi) in zip(X, y):\n        dtheta0 += hypothesis(theta0, theta1, xi) - yi\n        dtheta1 += (hypothesis(theta0, theta1, xi) - yi)*xi\n\n    dtheta0 /= len(X)\n    dtheta1 /= len(X)\n\n    return dtheta0, dtheta1\n\ndef updateParameters(theta0, theta1, X, y, alpha):\n    dtheta0, dtheta1 = derivatives(theta0, theta1, X, y)\n    theta0 = theta0 - (alpha * dtheta0)\n    theta1 = theta1 - (alpha * dtheta1)\n\n    return theta0, theta1\n    \n\ndef LinearRegression(X, y):\n    theta0 = np.random.rand()\n    theta1 = np.random.rand()\n    \n    for i in range(0, 1000):\n        if i % 100 == 0:\n            plotLine(theta0, theta1, X, y)\n        # print(cost(theta0, theta1, X, y))\n        theta0, theta1 = updateParameters(theta0, theta1, X, y, 0.005)\n\n\n\n    \n\n\nLinearRegression(X, y)"""
