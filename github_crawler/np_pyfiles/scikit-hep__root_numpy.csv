file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python\n\nfrom __future__ import print_function\n\nimport sys\n\nif sys.version_info[0] < 3:\n    import __builtin__ as builtins\nelse:\n    import builtins\n\ntry:\n    # Try to use setuptools if installed\n    from setuptools import setup, Extension\n    from pkg_resources import parse_version, get_distribution\n\n    if get_distribution(\'setuptools\').parsed_version < parse_version(\'0.7\'):\n        # setuptools is too old (before merge with distribute)\n        raise ImportError\n\n    from setuptools.command.build_ext import build_ext as _build_ext\n    from setuptools.command.install import install as _install\n    use_setuptools = True\n\nexcept ImportError:\n    # Use distutils instead\n    from distutils.core import setup, Extension\n    from distutils.command.build_ext import build_ext as _build_ext\n    from distutils.command.install import install as _install\n    use_setuptools = False\n\nimport os\nfrom glob import glob\nfrom contextlib import contextmanager\n\nlocal_path = os.path.dirname(os.path.abspath(__file__))\n# setup.py can be called from outside the root_numpy directory\nos.chdir(local_path)\nsys.path.insert(0, local_path)\n\nexec(open(\'root_numpy/setup_utils.py\').read())\n\nrootsys = os.getenv(\'ROOTSYS\', None)\nif rootsys is not None:\n    try:\n        root_config = os.path.join(rootsys, \'bin\', \'root-config\')\n        root_version = root_version_installed(root_config)\n        root_cflags, root_ldflags = root_flags(root_config)\n        has_tmva = root_has_feature(\'tmva\', root_config)\n    except OSError:\n        raise RuntimeError(\n            ""ROOTSYS is {0} but running {1} failed"".format(\n                rootsys, root_config))\nelse:\n    try:\n        root_version = root_version_installed()\n        root_cflags, root_ldflags = root_flags()\n        has_tmva = root_has_feature(\'tmva\')\n    except OSError:\n        raise RuntimeError(\n            ""root-config is not in PATH and ROOTSYS is not set. ""\n            ""Is ROOT installed correctly?"")\n\n@contextmanager\ndef version(release=False):\n    if not release:\n        yield\n    else:\n        # Remove dev from version in root_numpy/info.py\n        import shutil\n        print(""writing release version in \'root_numpy/info.py\'"")\n        shutil.move(\'root_numpy/info.py\', \'info.tmp\')\n        dev_info = \'\'.join(open(\'info.tmp\', \'r\').readlines())\n        open(\'root_numpy/info.py\', \'w\').write(\n            dev_info.replace(\'.dev0\', \'\'))\n        try:\n            yield\n        finally:\n            # Revert root_numpy/info.py\n            print(""restoring dev version in \'root_numpy/info.py\'"")\n            shutil.move(\'info.tmp\', \'root_numpy/info.py\')\n\n\nclass build_ext(_build_ext):\n    def finalize_options(self):\n        _build_ext.finalize_options(self)\n        # Prevent numpy from thinking it is still in its setup process\n        try:\n            del builtins.__NUMPY_SETUP__\n        except AttributeError:\n            pass\n        import numpy\n        self.include_dirs.append(numpy.get_include())\n\n\nclass install(_install):\n    def run(self):\n        print(__doc__)\n        import numpy\n\n        config = {\n            \'ROOT_version\': str(root_version),\n            \'numpy_version\': numpy.__version__,\n        }\n\n        # Write version info in config.json\n        print(""writing \'root_numpy/config.json\'"")\n        import json\n        with open(\'root_numpy/config.json\', \'w\') as config_file:\n            json.dump(config, config_file, indent=4)\n\n        _install.run(self)\n\n        print(""removing \'root_numpy/config.json\'"")\n        os.remove(\'root_numpy/config.json\')\n\n\nlibrootnumpy = Extension(\n    \'root_numpy._librootnumpy\',\n    sources=[\n        \'root_numpy/src/_librootnumpy.cpp\',\n    ],\n    depends=glob(\'root_numpy/src/*.h\'),\n    language=\'c++\',\n    include_dirs=[\n        \'root_numpy/src\',\n    ],\n    extra_compile_args=root_cflags + [\n        \'-Wno-unused-function\',\n        \'-Wno-write-strings\',\n    ],\n    extra_link_args=root_ldflags + [\'-lTreePlayer\'])\n\next_modules = [librootnumpy]\npackages = [\n    \'root_numpy\',\n    \'root_numpy.tests\',\n    \'root_numpy.testdata\',\n    \'root_numpy.extern\',\n    ]\n\nif has_tmva:\n    librootnumpy_tmva = Extension(\n        \'root_numpy.tmva._libtmvanumpy\',\n        sources=[\n            \'root_numpy/tmva/src/_libtmvanumpy.cpp\',\n        ],\n        depends=glob(\'root_numpy/tmva/src/*.h\') + [\n            \'root_numpy/src/2to3.h\',\n        ],\n        language=\'c++\',\n        include_dirs=[\n            \'root_numpy/src\',\n            \'root_numpy/tmva/src\',\n        ],\n        define_macros=[(\'NEW_TMVA_API\', None)] if root_version >= \'6.07/04\' else [],\n        extra_compile_args=root_cflags + [\n            \'-Wno-unused-function\',\n            \'-Wno-write-strings\',\n        ],\n        extra_link_args=root_ldflags + [\'-lTMVA\'])\n    ext_modules.append(librootnumpy_tmva)\n    packages.append(\'root_numpy.tmva\')\n\n\ndef setup_package():\n    if use_setuptools:\n        setuptools_options = dict(\n            setup_requires=[\'numpy\'],\n            install_requires=[\'numpy\'],\n            extras_require={\n                \'with-numpy\': (\'numpy\',),\n            },\n            zip_safe=False,\n        )\n    else:\n        setuptools_options = dict()\n\n    setup(\n        name=\'root_numpy\',\n        version=__version__,\n        description=\'The interface between ROOT and NumPy\',\n        long_description=\'\'.join(open(\'README.rst\').readlines()[7:-4]),\n        author=\'the root_numpy developers\',\n        author_email=\'rootpy-dev@googlegroups.com\',\n        maintainer=\'The scikit-hep developers\',\n        maintainer_email=\'scikit-hep-admins@googlegroups.com\',\n        license=\'new BSD\',\n        url=\'http://scikit-hep.org/root_numpy\',\n        packages=packages,\n        package_data={\n            \'root_numpy\': [\'testdata/*.root\', \'config.json\'],\n        },\n        ext_modules=ext_modules,\n        cmdclass={\n            \'build_ext\': build_ext,\n            \'install\': install,\n        },\n        classifiers=[\n            \'Intended Audience :: Science/Research\',\n            \'Intended Audience :: Developers\',\n            \'Topic :: Software Development\',\n            \'Topic :: Scientific/Engineering\',\n            \'Topic :: Utilities\',\n            \'Operating System :: POSIX\',\n            \'Operating System :: Unix\',\n            \'Operating System :: MacOS\',\n            \'License :: OSI Approved :: BSD License\',\n            \'Programming Language :: Python\',\n            \'Programming Language :: Python :: 2\',\n            \'Programming Language :: Python :: 2.7\',\n            \'Programming Language :: Python :: 3\',\n            \'Programming Language :: Python :: 3.6\',\n            \'Programming Language :: Python :: 3.7\',\n            \'Programming Language :: C++\',\n            \'Programming Language :: Cython\',\n            \'Development Status :: 5 - Production/Stable\',\n        ],\n        **setuptools_options\n    )\n\n\nwith version(release=set([\'sdist\', \'register\']).intersection(sys.argv[1:])):\n    exec(open(\'root_numpy/info.py\').read())\n    setup_package()\n'"
benchmarks/bench_tree2array.py,6,"b'from __future__ import print_function\n\nfrom rootpy.io import TemporaryFile\nimport rootpy\nfrom root_numpy import array2tree, tree2array\nimport numpy as np\nimport uuid\nimport random\nimport string\nimport timeit\nimport pickle\nimport platform\nimport matplotlib.pyplot as plt\nimport os\n\nwith open(\'hardware.pkl\', \'r\') as pkl:\n    info = pickle.load(pkl)\n\n# construct system hardware information string\nhardware = \'{cpu}\\nStorage: {hdd}\\nROOT-{root}\\nPython-{python}\\nNumPy-{numpy}\'.format(\n    cpu=info[\'CPU\'], hdd=info[\'HDD\'],\n    root=rootpy.ROOT_VERSION, python=platform.python_version(),\n    numpy=np.__version__)\n\nrfile = TemporaryFile()\n\ndef randomword(length):\n    return \'\'.join(random.choice(string.lowercase) for i in range(length))\n\ndef make_tree(entries, branches=1, dtype=np.double):\n    dtype = np.dtype([(randomword(20), dtype) for idx in range(branches)])\n    array = np.zeros(entries, dtype=dtype)\n    return array2tree(array, name=uuid.uuid4().hex)\n\n# warm up\nprint(""warming up... "", end="""")\nfor i in range(30):\n    tree = make_tree(100, branches=1)\n    branchname = tree.GetListOfBranches()[0].GetName()\n    tree2array(tree)\n    tree.Draw(branchname, """", ""goff"")\nprint(""done\\n"")\n\n# time vs entries\nnum_entries = np.logspace(1, 7, 20, dtype=np.int)\nroot_numpy_times = []\nroot_times = []\nprint(""{0:>10}  {1:<10}  {2:<10}"".format(""entries"", ""root_numpy"", ""ROOT""))\nfor entries in num_entries:\n    print(""{0:>10}"".format(entries), end="""")\n    if entries < 1e3:\n        iterations = 200\n    elif entries < 1e5:\n        iterations = 20\n    else:\n        iterations = 4\n    tree = make_tree(entries, branches=1)\n    branchname = tree.GetListOfBranches()[0].GetName()\n    root_numpy_times.append(\n        min(timeit.Timer(\'tree2array(tree)\',\n                         setup=\'from root_numpy import tree2array; from __main__ import tree\').repeat(3, iterations)) / iterations)\n    root_times.append(\n        min(timeit.Timer(\'draw(""{0}"", """", ""goff"")\'.format(branchname),\n                         setup=\'from __main__ import tree; draw = tree.Draw\').repeat(3, iterations)) / iterations)\n    print(""  {0:10.5f}"".format(root_numpy_times[-1]), end="""")\n    print(""  {0:10.5f}"".format(root_times[-1]))\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3.5))\n\nax1.plot(num_entries, root_numpy_times, \'-o\', label=\'root_numpy.tree2array()\', linewidth=1.5)\nax1.plot(num_entries, root_times, \'--o\', label=\'ROOT.TTree.Draw()\', linewidth=1.5)\nax1.set_xscale(""log"", nonposx=\'clip\')\nax1.set_yscale(""log"", nonposx=\'clip\')\nax1.legend(loc=(0.03, 0.7), frameon=False, fontsize=10)\nax1.set_ylabel(\'time [s]\')\nax1.set_xlabel(\'number of entries\')\nax1.text(0.03, 0.97, \'tree contains a single branch\',\n         verticalalignment=\'top\', horizontalalignment=\'left\',\n         transform=ax1.transAxes, fontsize=12)\n\n# time vs branches\nnum_branches = np.linspace(1, 10, 10, dtype=np.int)\nroot_numpy_times = []\nroot_times = []\niterations = 10\nprint(""\\n{0:>10}  {1:<10}  {2:<10}"".format(""branches"", ""root_numpy"", ""ROOT""))\nfor branches in num_branches:\n    print(""{0:>10}"".format(branches), end="""")\n    tree = make_tree(1000000, branches=branches)\n    branchnames = [branch.GetName() for branch in tree.GetListOfBranches()]\n    branchname = \':\'.join(branchnames)\n    root_numpy_times.append(\n        min(timeit.Timer(\'tree2array(tree)\',\n                         setup=\'from root_numpy import tree2array; from __main__ import tree\').repeat(3, iterations)) / iterations)\n    opt = \'candle\' if branches > 1 else \'\'\n    root_times.append(\n        min(timeit.Timer(\'draw(""{0}"", """", ""goff {1}"")\'.format(branchname, opt),\n                         setup=\'from __main__ import tree; draw = tree.Draw\').repeat(3, iterations)) / iterations)\n    print(""  {0:10.5f}"".format(root_numpy_times[-1]), end="""")\n    print(""  {0:10.5f}"".format(root_times[-1]))\n\nax2.plot(num_branches, root_numpy_times, \'-o\', label=\'root_numpy.tree2array()\', linewidth=1.5)\nax2.plot(num_branches, root_times, \'--o\', label=\'ROOT.TTree.Draw()\', linewidth=1.5)\n#ax2.legend(loc=\'lower right\', frameon=False, fontsize=12)\nax2.set_ylabel(\'time [s]\')\nax2.set_xlabel(\'number of branches\')\nax2.text(0.03, 0.97, \'tree contains 1M entries per branch\',\n         verticalalignment=\'top\', horizontalalignment=\'left\',\n         transform=ax2.transAxes, fontsize=12)\nax2.text(0.03, 0.87, hardware,\n         verticalalignment=\'top\', horizontalalignment=\'left\',\n         transform=ax2.transAxes, fontsize=10)\n\nfig.tight_layout()\nfname = \'bench_tree2array_{0}.{1}\'\nipng = 0\nwhile os.path.exists(fname.format(ipng, \'png\')):\n    ipng += 1\nfig.savefig(fname.format(ipng, \'png\'), transparent=True)\nfig.savefig(fname.format(ipng, \'pdf\'), transparent=True)\n'"
benchmarks/sysinfo.py,0,"b'""""""\nGet system hardware information\nhttp://stackoverflow.com/a/4194146/1002176\n""""""\nimport cpuinfo  # pip install --user py-cpuinfo\nimport sys, os, fcntl, struct\nimport pickle\n\nif os.geteuid() > 0:\n    print(""ERROR: Must be root to use"")\n    sys.exit(1)\n\nwith open(sys.argv[1], ""rb"") as fd:\n    # tediously derived from the monster struct defined in <hdreg.h>\n    # see comment at end of file to verify\n    hd_driveid_format_str = ""@ 10H 20s 3H 8s 40s 2B H 2B H 4B 6H 2B I 36H I Q 152H""\n    # Also from <hdreg.h>\n    HDIO_GET_IDENTITY = 0x030d\n    # How big a buffer do we need?\n    sizeof_hd_driveid = struct.calcsize(hd_driveid_format_str)\n\n    # ensure our format string is the correct size\n    # 512 is extracted using sizeof(struct hd_id) in the c code\n    assert sizeof_hd_driveid == 512\n\n    # Call native function\n    buf = fcntl.ioctl(fd, HDIO_GET_IDENTITY, "" "" * sizeof_hd_driveid)\n    fields = struct.unpack(hd_driveid_format_str, buf)\n    hdd = fields[15].strip()\n\ncpu = cpuinfo.get_cpu_info()[\'brand\']\n\nprint(cpu)\nprint(""Hard Drive Model: {0}"".format(hdd))\n\ninfo = {\n    \'CPU\': cpu,\n    \'HDD\': hdd,\n}\n\nwith open(\'hardware.pkl\', \'w\') as pkl:\n    pickle.dump(info, pkl)\n'"
docs/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# root_numpy documentation build configuration file, created by\n# sphinx-quickstart on Wed Nov  7 09:39:46 2012.\n#\n# This file is execfile()d with the current directory set to its containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nfrom __future__ import print_function\n\nimport sys, os\nimport datetime\nnow = datetime.datetime.now()\n\n# put root_numpy at the front of sys.path\nsys.path.insert(0, os.path.abspath(os.path.pardir))\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\nsys.path.insert(1, \'sphinxext\')\n\nimport root_numpy.info\nprint(""building docs for root_numpy {0}"".format(root_numpy.__version__))\n\n# -- General configuration -----------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be extensions\n# coming with Sphinx (named \'sphinx.ext.*\') or your custom ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.autosummary\',\n    \'numpydoc\',\n    \'gen_rst\',\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix of source filenames.\nsource_suffix = \'.rst\'\n\n# The encoding of source files.\n#source_encoding = \'utf-8-sig\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = u\'root_numpy\'\ncopyright = u\'%s, <a target=""_blank"" href=""https://github.com/rootpy/root_numpy/graphs/contributors"">root_numpy developers and contributors</a>\' % now.year\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = root_numpy.info.__version__\n# The full version, including alpha/beta/rc tags.\nrelease = root_numpy.info.__version__\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#language = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = \'\'\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = \'%B %d, %Y\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\'README*\']\nexclude_trees = [\'_build\', \'themes\']\n\n# The reST default role (used for this markup: `text`) to use for all documents.\n#default_role = None\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n\n\n# -- Options for HTML output ---------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \'sphinx_rtd_theme\'\nhtml_style = \'css/root_numpy.css\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\nhtml_theme_options = {\n    \'analytics_id\': \'UA-39364267-1\',\n}\n\n# Add any paths that contain custom themes here, relative to this directory.\nhtml_theme_path = [\'themes\']\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# ""<project> v<release> documentation"".\n#html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n#html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# If not \'\', a \'Last updated on:\' timestamp is inserted at every page bottom,\n# using the given strftime format.\n#html_last_updated_fmt = \'%b %d, %Y\'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n#html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n\n# If false, no module index is generated.\n#html_domain_indices = True\n\n# If false, no index is generated.\n#html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\nhtml_show_sourcelink = False\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.\nhtml_show_sphinx = False\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.\n#html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = \'\'\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n#html_file_suffix = None\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'root_numpydoc\'\n\n#add_module_names = False\nautosummary_generate = True\n'"
root_numpy/__init__.py,0,"b'import sys\n\nIN_NOSETESTS = False\nif sys.argv and sys.argv[0].endswith(\'nosetests\'):  # pragma: no cover\n    IN_NOSETESTS = True\n\nimport warnings\nimport re\n\n# Make sure that DeprecationWarning within this package always gets printed\nwarnings.filterwarnings(\'always\', category=DeprecationWarning,\n                        module=\'^{0}\\.\'.format(re.escape(__name__)))\n\n# Only show ImportWarning if not running in nosetests\nif not IN_NOSETESTS:  # pragma: no cover\n    warnings.filterwarnings(\'always\', category=ImportWarning,\n                            module=\'^{0}\\.\'.format(re.escape(__name__)))\n\nfrom .setup_utils import root_version_active, get_config\n\nROOT_VERSION = root_version_active()\nconfig = get_config()\n\nif config is not None:  # pragma: no cover\n    root_version_at_install = config.get(\'ROOT_version\', ROOT_VERSION)\n\n    if ROOT_VERSION != root_version_at_install:\n        warnings.warn(\n            ""ROOT {0} is currently active but you ""\n            ""installed root_numpy against ROOT {1}. ""\n            ""Please consider reinstalling root_numpy ""\n            ""for this ROOT version."".format(\n                ROOT_VERSION, root_version_at_install),\n            RuntimeWarning)\n\n    import numpy\n    numpy_version_at_install = config.get(\'numpy_version\', numpy.__version__)\n\n    if numpy.__version__ != numpy_version_at_install:\n        warnings.warn(\n            ""numpy {0} is currently installed but you ""\n            ""installed root_numpy against numpy {1}. ""\n            ""Please consider reinstalling root_numpy ""\n            ""for this numpy version."".format(\n                numpy.__version__, numpy_version_at_install),\n            RuntimeWarning)\n\n    del root_version_at_install\n    del numpy_version_at_install\n\nfrom ._tree import (\n    root2array, root2rec,\n    tree2array, tree2rec,\n    array2tree, array2root,\n    list_trees, list_branches,\n    list_directories, list_structures)\nfrom ._hist import fill_hist, fill_profile, hist2array, array2hist\nfrom ._graph import fill_graph\nfrom ._sample import random_sample\nfrom ._array import array\nfrom ._matrix import matrix\nfrom ._evaluate import evaluate\nfrom ._warnings import RootNumpyUnconvertibleWarning\nfrom ._utils import (\n    stretch, blockwise_inner_join,\n    rec2array, stack, dup_idx)\nfrom .info import __version__\n\n\n__all__ = [\n    \'root2array\',\n    \'root2rec\',\n    \'tree2array\',\n    \'tree2rec\',\n    \'array2tree\',\n    \'array2root\',\n    \'hist2array\',\n    \'array2hist\',\n    \'fill_hist\',\n    \'fill_profile\',\n    \'fill_graph\',\n    \'random_sample\',\n    \'array\',\n    \'matrix\',\n    \'evaluate\',\n    \'list_trees\',\n    \'list_branches\',\n    \'list_structures\',\n    \'list_directories\',\n    \'rec2array\',\n    \'stack\',\n    \'stretch\',\n    \'dup_idx\',\n    \'blockwise_inner_join\',\n    \'RootNumpyUnconvertibleWarning\',\n]\n'"
root_numpy/_array.py,1,"b'import numpy as np\nfrom . import _librootnumpy\n\n\n__all__ = [\n    \'array\',\n]\n\n\ndef array(arr, copy=True):\n    """"""Convert a ROOT TArray into a NumPy array.\n\n    Parameters\n    ----------\n    arr : ROOT TArray\n        A ROOT TArrayD, TArrayF, TArrayL, TArrayI or TArrayS\n    copy : bool, optional (default=True)\n        If True (the default) then copy the underlying array, otherwise the\n        NumPy array will view (and not own) the same memory as the ROOT array.\n\n    Returns\n    -------\n    arr : NumPy array\n        A NumPy array\n\n    Examples\n    --------\n    >>> from root_numpy import array\n    >>> from ROOT import TArrayD\n    >>> a = TArrayD(5)\n    >>> a[3] = 3.141\n    >>> array(a)\n    array([ 0.   ,  0.   ,  0.   ,  3.141,  0.   ])\n\n    """"""\n    import ROOT\n    if isinstance(arr, ROOT.TArrayD):\n        arr = _librootnumpy.array_d(ROOT.AsCObject(arr))\n    elif isinstance(arr, ROOT.TArrayF):\n        arr = _librootnumpy.array_f(ROOT.AsCObject(arr))\n    elif isinstance(arr, ROOT.TArrayL):\n        arr = _librootnumpy.array_l(ROOT.AsCObject(arr))\n    elif isinstance(arr, ROOT.TArrayI):\n        arr = _librootnumpy.array_i(ROOT.AsCObject(arr))\n    elif isinstance(arr, ROOT.TArrayS):\n        arr = _librootnumpy.array_s(ROOT.AsCObject(arr))\n    elif isinstance(arr, ROOT.TArrayC):\n        arr = _librootnumpy.array_c(ROOT.AsCObject(arr))\n    else:\n        raise TypeError(\n            ""unable to convert object of type {0} ""\n            ""into a numpy array"".format(type(arr)))\n    if copy:\n        return np.copy(arr)\n    return arr\n'"
root_numpy/_evaluate.py,1,"b'import uuid\nimport numpy as np\n\nfrom .extern.six import string_types\nfrom . import _librootnumpy\n\n\n__all__ = [\n    \'evaluate\',\n]\n\n\ndef evaluate(obj, array):\n    """"""Evaluate a ROOT histogram, function, graph, or spline over an array.\n\n    Parameters\n    ----------\n    obj : TH[1|2|3], TF[1|2|3], TFormula, TGraph, TSpline, or string\n        A ROOT histogram, function, formula, graph, spline, or string. If a\n        string is specified, a TFormula is created.\n    array : ndarray\n        An array containing the values to evaluate the ROOT object on. The\n        shape must match the dimensionality of the ROOT object.\n\n    Returns\n    -------\n    y : array\n        An array containing the values of the ROOT object evaluated at each\n        value in the input array.\n\n    Raises\n    ------\n    TypeError\n        If the ROOT object is not a histogram, function, graph, or spline.\n    ValueError\n        If the shape of the array is not compatible with the dimensionality of\n        the ROOT object being evaluated. If the string expression does not\n        compile to a valid TFormula expression.\n\n    Examples\n    --------\n    >>> from root_numpy import evaluate\n    >>> from ROOT import TF1, TF2\n    >>> func = TF1(""f1"", ""x*x"")\n    >>> evaluate(func, [1, 2, 3, 4])\n    array([  1.,   4.,   9.,  16.])\n    >>> func = TF2(""f2"", ""x*y"")\n    >>> evaluate(func, [[1, 1], [1, 2], [3, 1]])\n    array([ 1.,  2.,  3.])\n    >>> evaluate(""x*y"", [[1, 1], [1, 2], [3, 1]])\n    array([ 1.,  2.,  3.])\n\n    """"""\n    import ROOT\n    array = np.asarray(array, dtype=np.double)\n    if isinstance(obj, ROOT.TH1):\n        if isinstance(obj, ROOT.TH3):\n            if array.ndim != 2:\n                raise ValueError(""array must be 2-dimensional"")\n            if array.shape[1] != 3:\n                raise ValueError(\n                    ""length of the second dimension must equal ""\n                    ""the dimension of the histogram"")\n            return _librootnumpy.evaluate_h3(\n                ROOT.AsCObject(obj), array)\n        elif isinstance(obj, ROOT.TH2):\n            if array.ndim != 2:\n                raise ValueError(""array must be 2-dimensional"")\n            if array.shape[1] != 2:\n                raise ValueError(\n                    ""length of the second dimension must equal ""\n                    ""the dimension of the histogram"")\n            return _librootnumpy.evaluate_h2(\n                ROOT.AsCObject(obj), array)\n        if array.ndim != 1:\n            raise ValueError(""array must be 1-dimensional"")\n        return _librootnumpy.evaluate_h1(\n            ROOT.AsCObject(obj), array)\n    elif isinstance(obj, ROOT.TF1):\n        if isinstance(obj, ROOT.TF3):\n            if array.ndim != 2:\n                raise ValueError(""array must be 2-dimensional"")\n            if array.shape[1] != 3:\n                raise ValueError(\n                    ""length of the second dimension must equal ""\n                    ""the dimension of the function"")\n            return _librootnumpy.evaluate_f3(\n                ROOT.AsCObject(obj), array)\n        elif isinstance(obj, ROOT.TF2):\n            if array.ndim != 2:\n                raise ValueError(""array must be 2-dimensional"")\n            if array.shape[1] != 2:\n                raise ValueError(\n                    ""length of the second dimension must equal ""\n                    ""the dimension of the function"")\n            return _librootnumpy.evaluate_f2(\n                ROOT.AsCObject(obj), array)\n        if array.ndim != 1:\n            raise ValueError(""array must be 1-dimensional"")\n        return _librootnumpy.evaluate_f1(\n            ROOT.AsCObject(obj), array)\n    elif isinstance(obj, (string_types, ROOT.TFormula)):\n        if isinstance(obj, string_types):\n            # attempt to create a formula\n            obj = ROOT.TFormula(uuid.uuid4().hex, obj)\n        ndim = obj.GetNdim()\n        if ndim == 0:\n            raise ValueError(""invalid formula expression"")\n        if ndim == 1:\n            if array.ndim != 1:\n                raise ValueError(""array must be 1-dimensional"")\n            return _librootnumpy.evaluate_formula_1d(\n                ROOT.AsCObject(obj), array)\n        if array.ndim != 2:\n            raise ValueError(""array must be 2-dimensional"")\n        if array.shape[1] != ndim:\n            raise ValueError(\n                ""length of the second dimension must equal ""\n                ""the dimension of the function"")\n        if ndim == 2:\n            return _librootnumpy.evaluate_formula_2d(\n                ROOT.AsCObject(obj), array)\n        elif ndim == 3:\n            return _librootnumpy.evaluate_formula_3d(\n                ROOT.AsCObject(obj), array)\n        # 4d\n        return _librootnumpy.evaluate_formula_4d(\n            ROOT.AsCObject(obj), array)\n    elif isinstance(obj, ROOT.TGraph):\n        if array.ndim != 1:\n            raise ValueError(""array must be 1-dimensional"")\n        return _librootnumpy.evaluate_graph(\n            ROOT.AsCObject(obj), array)\n    elif isinstance(obj, ROOT.TSpline):\n        if array.ndim != 1:\n            raise ValueError(""array must be 1-dimensional"")\n        return _librootnumpy.evaluate_spline(\n            ROOT.AsCObject(obj), array)\n    raise TypeError(\n        ""obj is not a ROOT histogram, function, formula, ""\n        ""graph, spline or string"")\n'"
root_numpy/_graph.py,1,"b'import numpy as np\nfrom . import _librootnumpy\n\n\n__all__ = [\n    \'fill_graph\',\n]\n\n\ndef fill_graph(graph, array):\n    """"""Fill a ROOT graph with a NumPy array.\n\n    Parameters\n    ----------\n    graph : a ROOT TGraph or TGraph2D\n        The ROOT graph to fill.\n    array : numpy array of shape [n_samples, n_dimensions]\n        The values to fill the graph with. The number of columns must match the\n        dimensionality of the graph.\n\n    """"""\n    import ROOT\n    array = np.asarray(array, dtype=np.double)\n    if isinstance(graph, ROOT.TGraph):\n        if array.ndim != 2:\n            raise ValueError(""array must be 2-dimensional"")\n        if array.shape[1] != 2:\n            raise ValueError(\n                ""length of the second dimension must equal ""\n                ""the dimension of the graph"")\n        return _librootnumpy.fill_g1(\n            ROOT.AsCObject(graph), array)\n    elif isinstance(graph, ROOT.TGraph2D):\n        if array.ndim != 2:\n            raise ValueError(""array must be 2-dimensional"")\n        if array.shape[1] != 3:\n            raise ValueError(\n                ""length of the second dimension must equal ""\n                ""the dimension of the graph"")\n        return _librootnumpy.fill_g2(\n            ROOT.AsCObject(graph), array)\n    else:\n        raise TypeError(\n            ""hist must be an instance of ROOT.TGraph or ROOT.TGraph2D"")\n'"
root_numpy/_hist.py,18,"b'import numpy as np\nfrom . import _librootnumpy\n\n\n__all__ = [\n    \'fill_hist\',\n    \'fill_profile\',\n    \'hist2array\',\n    \'array2hist\',\n]\n\nDTYPE_ROOT2NUMPY = dict(C=\'i1\', S=\'i2\', I=\'i4\', L=\'i8\', F=\'f4\', D=\'f8\')\nARRAY_NUMPY2ROOT = dict(\n    [(ndim, dict([\n        (hist_type,\n            getattr(_librootnumpy, \'h{0}{1}_array\'.format(\n                ndim, hist_type.lower())))\n        for hist_type in \'DFISC\']))\n        for ndim in (1, 2, 3)])\n\n\ndef fill_hist(hist, array, weights=None, return_indices=False):\n    """"""Fill a ROOT histogram with a NumPy array.\n\n    Parameters\n    ----------\n    hist : ROOT TH1, TH2, or TH3\n        The ROOT histogram to fill.\n    array : numpy array of shape [n_samples, n_dimensions]\n        The values to fill the histogram with. The number of columns must match\n        the dimensionality of the histogram. Supply a flat numpy array when\n        filling a 1D histogram.\n    weights : numpy array\n        A flat numpy array of weights for each sample in ``array``.\n    return_indices : bool, optional (default=False)\n        If True then return an array of the bin indices filled for each element\n        in ``array``.\n\n    Returns\n    -------\n    indices : numpy array or None\n        If ``return_indices`` is True, then return an array of the bin indices\n        filled for each element in ``array`` otherwise return None.\n\n    """"""\n    import ROOT\n    array = np.asarray(array, dtype=np.double)\n    if weights is not None:\n        weights = np.asarray(weights, dtype=np.double)\n        if weights.shape[0] != array.shape[0]:\n            raise ValueError(""array and weights must have the same length"")\n        if weights.ndim != 1:\n            raise ValueError(""weight must be 1-dimensional"")\n    if isinstance(hist, ROOT.TH3):\n        if array.ndim != 2:\n            raise ValueError(""array must be 2-dimensional"")\n        if array.shape[1] != 3:\n            raise ValueError(\n                ""length of the second dimension must equal ""\n                ""the dimension of the histogram"")\n        return _librootnumpy.fill_h3(\n            ROOT.AsCObject(hist), array, weights, return_indices)\n    elif isinstance(hist, ROOT.TH2):\n        if array.ndim != 2:\n            raise ValueError(""array must be 2-dimensional"")\n        if array.shape[1] != 2:\n            raise ValueError(\n                ""length of the second dimension must equal ""\n                ""the dimension of the histogram"")\n        return _librootnumpy.fill_h2(\n            ROOT.AsCObject(hist), array, weights, return_indices)\n    elif isinstance(hist, ROOT.TH1):\n        if array.ndim != 1:\n            raise ValueError(""array must be 1-dimensional"")\n        return _librootnumpy.fill_h1(\n            ROOT.AsCObject(hist), array, weights, return_indices)\n    raise TypeError(\n        ""hist must be an instance of ROOT.TH1, ROOT.TH2, or ROOT.TH3"")\n\n\ndef fill_profile(profile, array, weights=None, return_indices=False):\n    """"""Fill a ROOT profile with a NumPy array.\n\n    Parameters\n    ----------\n    profile : ROOT TProfile, TProfile2D, or TProfile3D\n        The ROOT profile to fill.\n    array : numpy array of shape [n_samples, n_dimensions]\n        The values to fill the histogram with. There must be one more column\n        than the dimensionality of the profile.\n    weights : numpy array\n        A flat numpy array of weights for each sample in ``array``.\n    return_indices : bool, optional (default=False)\n        If True then return an array of the bin indices filled for each element\n        in ``array``.\n\n    Returns\n    -------\n    indices : numpy array or None\n        If ``return_indices`` is True, then return an array of the bin indices\n        filled for each element in ``array`` otherwise return None.\n\n    """"""\n    import ROOT\n    array = np.asarray(array, dtype=np.double)\n    if array.ndim != 2:\n        raise ValueError(""array must be 2-dimensional"")\n    if array.shape[1] != profile.GetDimension() + 1:\n        raise ValueError(\n            ""there must be one more column than the ""\n            ""dimensionality of the profile"")\n    if weights is not None:\n        weights = np.asarray(weights, dtype=np.double)\n        if weights.shape[0] != array.shape[0]:\n            raise ValueError(""array and weights must have the same length"")\n        if weights.ndim != 1:\n            raise ValueError(""weight must be 1-dimensional"")\n    if isinstance(profile, ROOT.TProfile3D):\n        return _librootnumpy.fill_p3(\n            ROOT.AsCObject(profile), array, weights, return_indices)\n    elif isinstance(profile, ROOT.TProfile2D):\n        return _librootnumpy.fill_p2(\n            ROOT.AsCObject(profile), array, weights, return_indices)\n    elif isinstance(profile, ROOT.TProfile):\n        return _librootnumpy.fill_p1(\n            ROOT.AsCObject(profile), array, weights, return_indices)\n    raise TypeError(\n        ""profile must be an instance of ""\n        ""ROOT.TProfile, ROOT.TProfile2D, or ROOT.TProfile3D"")\n\n\ndef hist2array(hist, include_overflow=False, copy=True, return_edges=False):\n    """"""Convert a ROOT histogram into a NumPy array\n\n    Parameters\n    ----------\n    hist : ROOT TH1, TH2, TH3, THn, or THnSparse\n        The ROOT histogram to convert into an array\n    include_overflow : bool, optional (default=False)\n        If True, the over- and underflow bins will be included in the\n        output numpy array. These bins are excluded by default.\n    copy : bool, optional (default=True)\n        If True (the default) then copy the underlying array, otherwise the\n        NumPy array will view (and not own) the same memory as the ROOT\n        histogram\'s array.\n    return_edges : bool, optional (default=False)\n        If True, also return the bin edges along each axis.\n\n    Returns\n    -------\n    array : numpy array\n        A NumPy array containing the histogram bin values\n    edges : list of numpy arrays\n        A list of numpy arrays where each array contains the bin edges along\n        the corresponding axis of ``hist``. Overflow and underflow bins are not\n        included.\n\n    Raises\n    ------\n    TypeError\n        If hist is not a ROOT histogram.\n\n    See Also\n    --------\n    array2hist\n\n    """"""\n    import ROOT\n    # Determine dimensionality and shape\n    simple_hist = True\n    if isinstance(hist, ROOT.TH3):\n        shape = (hist.GetNbinsZ() + 2,\n                 hist.GetNbinsY() + 2,\n                 hist.GetNbinsX() + 2)\n    elif isinstance(hist, ROOT.TH2):\n        shape = (hist.GetNbinsY() + 2, hist.GetNbinsX() + 2)\n    elif isinstance(hist, ROOT.TH1):\n        shape = (hist.GetNbinsX() + 2,)\n    elif isinstance(hist, ROOT.THnBase):\n        shape = tuple([hist.GetAxis(i).GetNbins() + 2\n                       for i in range(hist.GetNdimensions())])\n        simple_hist = False\n    else:\n        raise TypeError(\n            ""hist must be an instance of ROOT.TH1, ""\n            ""ROOT.TH2, ROOT.TH3, or ROOT.THnBase"")\n\n    # Determine the corresponding numpy dtype\n    if simple_hist:\n        for hist_type in \'DFISC\':\n            if isinstance(hist, getattr(ROOT, \'TArray{0}\'.format(hist_type))):\n                break\n        else:\n            raise AssertionError(\n                ""hist is somehow an instance of TH[1|2|3] ""\n                ""but not TArray[D|F|I|S|C]"")\n    else:  # THn, THnSparse\n        if isinstance(hist, ROOT.THnSparse):\n            cls_string = \'THnSparse{0}\'\n        else:\n            cls_string = \'THn{0}\'\n        for hist_type in \'CSILFD\':\n            if isinstance(hist, getattr(ROOT, cls_string.format(hist_type))):\n                break\n        else:\n            raise AssertionError(\n                ""unsupported THn or THnSparse bin type"")\n\n    if simple_hist:\n        # Constuct a NumPy array viewing the underlying histogram array\n        if hist_type == \'C\':\n            array_func = getattr(_librootnumpy,\n                                 \'array_h{0}c\'.format(len(shape)))\n            array = array_func(ROOT.AsCObject(hist))\n            array.shape = shape\n        else:\n            dtype = np.dtype(DTYPE_ROOT2NUMPY[hist_type])\n            array = np.ndarray(shape=shape, dtype=dtype,\n                               buffer=hist.GetArray())\n    else:  # THn THnSparse\n        dtype = np.dtype(DTYPE_ROOT2NUMPY[hist_type])\n        if isinstance(hist, ROOT.THnSparse):\n            array = _librootnumpy.thnsparse2array(ROOT.AsCObject(hist),\n                                                  shape, dtype)\n        else:\n            array = _librootnumpy.thn2array(ROOT.AsCObject(hist),\n                                            shape, dtype)\n\n    if return_edges:\n        if simple_hist:\n            ndims = hist.GetDimension()\n            axis_getters = [\'GetXaxis\', \'GetYaxis\', \'GetZaxis\'][:ndims]\n        else:\n            ndims = hist.GetNdimensions()\n            axis_getters = [\'GetAxis\'] * ndims\n\n        edges = []\n        for idim, axis_getter in zip(range(ndims), axis_getters):\n            # GetXaxis expects 0 parameters while we need the axis in GetAxis\n            ax = getattr(hist, axis_getter)(*(() if simple_hist else (idim,)))\n            # `edges` is Nbins + 1 in order to have the last bin\'s upper edge as well\n            edges.append(np.empty(ax.GetNbins() + 1, dtype=np.double))\n            # load the lower edges into `edges`\n            ax.GetLowEdge(edges[-1])\n            # Get the upper edge of the last bin\n            edges[-1][-1] = ax.GetBinUpEdge(ax.GetNbins())\n\n    if not include_overflow:\n        # Remove overflow and underflow bins\n        array = array[tuple([slice(1, -1) for idim in range(array.ndim)])]\n\n    if simple_hist:\n        # Preserve x, y, z -> axis 0, 1, 2 order\n        array = np.transpose(array)\n        if copy:\n            array = np.copy(array)\n\n    if return_edges:\n        return array, edges\n    return array\n\n\ndef array2hist(array, hist, errors=None):\n    """"""Convert a NumPy array into a ROOT histogram\n\n    Parameters\n    ----------\n    array : numpy array\n        A 1, 2, or 3-d numpy array that will set the bin contents of the\n        ROOT histogram.\n    hist : ROOT TH1, TH2, or TH3\n        A ROOT histogram.\n    errors : numpy array\n        A numpy array of errors with matching dimensionality as the\n        bin contents array. If not given, no errors are set\n\n    Returns\n    -------\n    hist : ROOT TH1, TH2, or TH3\n        The ROOT histogram with bin contents set from the array.\n\n    Raises\n    ------\n    TypeError\n        If hist is not a ROOT histogram.\n    ValueError\n        If the array and histogram are not compatible in terms of\n        dimensionality or number of bins along any axis.\n\n    Notes\n    -----\n    The NumPy array is copied into the histogram\'s internal array. If the input\n    NumPy array is not of the same data type as the histogram bin contents\n    (i.e. TH1D vs TH1F, etc.) and/or the input array does not contain overflow\n    bins along any of the axes, an additional copy is made into a temporary\n    array with all values converted into the matching data type and with\n    overflow bins included. Avoid this second copy by ensuring that the NumPy\n    array data type matches the histogram data type and that overflow bins are\n    included.\n\n    See Also\n    --------\n    hist2array\n\n    Examples\n    --------\n\n    >>> from root_numpy import array2hist, hist2array\n    >>> import numpy as np\n    >>> from rootpy.plotting import Hist2D\n    >>> hist = Hist2D(5, 0, 1, 3, 0, 1, type=\'F\')\n    >>> array = np.random.randint(0, 10, size=(7, 5))\n    >>> array\n    array([[6, 7, 8, 3, 4],\n           [8, 9, 7, 6, 2],\n           [2, 3, 4, 5, 2],\n           [7, 6, 5, 7, 3],\n           [2, 0, 5, 6, 8],\n           [0, 0, 6, 5, 2],\n           [2, 2, 1, 5, 4]])\n    >>> _ = array2hist(array, hist)\n    >>> # dtype matches histogram type (D, F, I, S, C)\n    >>> hist2array(hist)\n    array([[ 9.,  7.,  6.],\n           [ 3.,  4.,  5.],\n           [ 6.,  5.,  7.],\n           [ 0.,  5.,  6.],\n           [ 0.,  6.,  5.]], dtype=float32)\n    >>> # overflow is excluded by default\n    >>> hist2array(hist, include_overflow=True)\n    array([[ 6.,  7.,  8.,  3.,  4.],\n           [ 8.,  9.,  7.,  6.,  2.],\n           [ 2.,  3.,  4.,  5.,  2.],\n           [ 7.,  6.,  5.,  7.,  3.],\n           [ 2.,  0.,  5.,  6.,  8.],\n           [ 0.,  0.,  6.,  5.,  2.],\n           [ 2.,  2.,  1.,  5.,  4.]], dtype=float32)\n    >>> array2 = hist2array(hist, include_overflow=True, copy=False)\n    >>> hist[2, 2] = -10\n    >>> # array2 views the same memory as hist because copy=False\n    >>> array2\n    array([[  6.,   7.,   8.,   3.,   4.],\n           [  8.,   9.,   7.,   6.,   2.],\n           [  2.,   3., -10.,   5.,   2.],\n           [  7.,   6.,   5.,   7.,   3.],\n           [  2.,   0.,   5.,   6.,   8.],\n           [  0.,   0.,   6.,   5.,   2.],\n           [  2.,   2.,   1.,   5.,   4.]], dtype=float32)\n    >>> # x, y, z axes correspond to axes 0, 1, 2 in numpy\n    >>> hist[2, 3] = -10\n    >>> array2\n    array([[  6.,   7.,   8.,   3.,   4.],\n           [  8.,   9.,   7.,   6.,   2.],\n           [  2.,   3., -10., -10.,   2.],\n           [  7.,   6.,   5.,   7.,   3.],\n           [  2.,   0.,   5.,   6.,   8.],\n           [  0.,   0.,   6.,   5.,   2.],\n           [  2.,   2.,   1.,   5.,   4.]], dtype=float32)\n\n    """"""\n    import ROOT\n    if isinstance(hist, ROOT.TH3):\n        shape = (hist.GetNbinsX() + 2,\n                 hist.GetNbinsY() + 2,\n                 hist.GetNbinsZ() + 2)\n    elif isinstance(hist, ROOT.TH2):\n        shape = (hist.GetNbinsX() + 2, hist.GetNbinsY() + 2)\n    elif isinstance(hist, ROOT.TH1):\n        shape = (hist.GetNbinsX() + 2,)\n    else:\n        raise TypeError(\n            ""hist must be an instance of ROOT.TH1, ROOT.TH2, or ROOT.TH3"")\n\n    # Determine the corresponding numpy dtype\n    for hist_type in \'DFISC\':\n        if isinstance(hist, getattr(ROOT, \'TArray{0}\'.format(hist_type))):\n            break\n    else:\n        raise AssertionError(\n            ""hist is somehow an instance of TH[1|2|3] ""\n            ""but not TArray[D|F|I|S|C]"")\n\n    # Constuct a NumPy array viewing the underlying histogram array\n    dtype = np.dtype(DTYPE_ROOT2NUMPY[hist_type])\n    # No copy is made if the dtype is the same as input\n    _array = np.ascontiguousarray(array, dtype=dtype)\n    if errors is not None:\n        if errors.shape != array.shape:\n            raise ValueError(""Contents and errors are not compatible"")\n        # errors are specified as doubles in SetError function\n        _errors = np.ascontiguousarray(errors, dtype=np.float64)\n    else:\n        _errors = None\n\n    if _array.ndim != len(shape):\n        raise ValueError(\n            ""array and histogram do not have ""\n            ""the same number of dimensions"")\n    if _array.shape != shape:\n        # Check for overflow along each axis\n        slices = []\n        for axis, bins in enumerate(shape):\n            if _array.shape[axis] == bins - 2:\n                slices.append(slice(1, -1))\n            elif _array.shape[axis] == bins:\n                slices.append(slice(None))\n            else:\n                raise ValueError(\n                    ""array and histogram are not compatible along ""\n                    ""the {0}-axis"".format(""xyz""[axis]))\n        array_overflow = np.zeros(shape, dtype=dtype)\n        array_overflow[tuple(slices)] = _array\n        _array = array_overflow\n\n        if _errors is not None:\n            errors_overflow = np.zeros(shape, dtype=np.float64)\n            errors_overflow[tuple(slices)] = _errors\n            _errors = errors_overflow\n\n    ARRAY_NUMPY2ROOT[len(shape)][hist_type](\n        ROOT.AsCObject(hist), np.ravel(np.transpose(_array)))\n    # Set the number of entries to the number of array elements\n    hist.SetEntries(_array.size)\n    if _errors is not None:\n        hist.SetError(np.ravel(_errors.T))\n    return hist\n'"
root_numpy/_matrix.py,0,"b'from . import _librootnumpy\n\n\n__all__ = [\n    \'matrix\',\n]\n\n\ndef matrix(mat):\n    """"""Convert a ROOT TMatrix into a NumPy matrix.\n\n    Parameters\n    ----------\n    mat : ROOT TMatrixT\n        A ROOT TMatrixD or TMatrixF\n\n    Returns\n    -------\n    mat : numpy.matrix\n        A NumPy matrix\n\n    Examples\n    --------\n    >>> from root_numpy import matrix\n    >>> from ROOT import TMatrixD\n    >>> a = TMatrixD(4, 4)\n    >>> a[1][2] = 2\n    >>> matrix(a)\n    matrix([[ 0.,  0.,  0.,  0.],\n            [ 0.,  0.,  2.,  0.],\n            [ 0.,  0.,  0.,  0.],\n            [ 0.,  0.,  0.,  0.]])\n\n    """"""\n    import ROOT\n    if isinstance(mat, (ROOT.TMatrixD, ROOT.TMatrixDSym)):\n        return _librootnumpy.matrix_d(ROOT.AsCObject(mat))\n    elif isinstance(mat, (ROOT.TMatrixF, ROOT.TMatrixFSym)):\n        return _librootnumpy.matrix_f(ROOT.AsCObject(mat))\n    raise TypeError(\n        ""unable to convert object of type {0} ""\n        ""into a numpy matrix"".format(type(mat)))\n'"
root_numpy/_sample.py,0,"b'from . import _librootnumpy\n\n\n__all__ = [\n    \'random_sample\',\n]\n\n\ndef random_sample(obj, n_samples, seed=None):\n    """"""Create a random array by sampling a ROOT function or histogram.\n\n    Parameters\n    ----------\n    obj : TH[1|2|3] or TF[1|2|3]\n        The ROOT function or histogram to sample.\n    n_samples : positive int\n        The number of random samples to generate.\n    seed : None, positive int or 0, optional (default=None)\n        The random seed, set via ROOT.gRandom.SetSeed(seed):\n        http://root.cern.ch/root/html/TRandom3.html#TRandom3:SetSeed\n        If 0, the seed will be random. If None (the default), ROOT.gRandom will\n        not be touched and the current seed will be used.\n\n    Returns\n    -------\n    array : a numpy array\n        A numpy array with a shape corresponding to the dimensionality of the\n        function or histogram. A flat array is returned when sampling TF1 or\n        TH1. An array with shape [n_samples, n_dimensions] is returned when\n        sampling TF2, TF3, TH2, or TH3.\n\n    Examples\n    --------\n    >>> from root_numpy import random_sample\n    >>> from ROOT import TF1, TF2, TF3\n    >>> random_sample(TF1(""f1"", ""TMath::DiLog(x)""), 10000, seed=1)\n    array([ 0.68307934,  0.9988919 ,  0.87198158, ...,  0.50331049,\n            0.53895257,  0.57576984])\n    >>> random_sample(TF2(""f2"", ""sin(x)*sin(y)/(x*y)""), 10000, seed=1)\n    array([[ 0.93425084,  0.39990616],\n           [ 0.00819315,  0.73108525],\n           [ 0.00307176,  0.00427081],\n           ...,\n           [ 0.66931215,  0.0421913 ],\n           [ 0.06469985,  0.10253632],\n           [ 0.31059832,  0.75892702]])\n    >>> random_sample(TF3(""f3"", ""sin(x)*sin(y)*sin(z)/(x*y*z)""), 10000, seed=1)\n    array([[ 0.03323949,  0.95734415,  0.39775191],\n           [ 0.07093748,  0.01007775,  0.03330135],\n           [ 0.80786963,  0.13641129,  0.14655269],\n           ...,\n           [ 0.96223632,  0.43916482,  0.05542078],\n           [ 0.06631163,  0.0015063 ,  0.46550416],\n           [ 0.88154752,  0.24332142,  0.66746564]])\n\n    """"""\n    import ROOT\n    if n_samples <= 0:\n        raise ValueError(""n_samples must be greater than 0"")\n    if seed is not None:\n        if seed < 0:\n            raise ValueError(""seed must be positive or 0"")\n        ROOT.gRandom.SetSeed(seed)\n    # functions\n    if isinstance(obj, ROOT.TF1):\n        if isinstance(obj, ROOT.TF3):\n            return _librootnumpy.sample_f3(\n                ROOT.AsCObject(obj), n_samples)\n        elif isinstance(obj, ROOT.TF2):\n            return _librootnumpy.sample_f2(\n                ROOT.AsCObject(obj), n_samples)\n        return _librootnumpy.sample_f1(ROOT.AsCObject(obj), n_samples)\n    # histograms\n    elif isinstance(obj, ROOT.TH1):\n        if isinstance(obj, ROOT.TH3):\n            return _librootnumpy.sample_h3(\n                ROOT.AsCObject(obj), n_samples)\n        elif isinstance(obj, ROOT.TH2):\n            return _librootnumpy.sample_h2(\n                ROOT.AsCObject(obj), n_samples)\n        return _librootnumpy.sample_h1(ROOT.AsCObject(obj), n_samples)\n    raise TypeError(\n        ""obj must be a ROOT function or histogram"")\n'"
root_numpy/_tree.py,39,"b'import warnings\nfrom glob import glob\nimport numpy as np\n\nfrom .extern.six import string_types\nfrom . import _librootnumpy\n\n\n__all__ = [\n    \'root2array\',\n    \'root2rec\',\n    \'list_trees\',\n    \'list_branches\',\n    \'list_structures\',\n    \'list_directories\',\n    \'tree2array\',\n    \'tree2rec\',\n    \'array2tree\',\n    \'array2root\',\n]\n\n\ndef _glob(filenames):\n    """"""Glob a filename or list of filenames but always return the original\n    string if the glob didn\'t match anything so URLs for remote file access\n    are not clobbered.\n    """"""\n    if isinstance(filenames, string_types):\n        filenames = [filenames]\n    matches = []\n    for name in filenames:\n        matched_names = glob(name)\n        if not matched_names:\n            # use the original string\n            matches.append(name)\n        else:\n            matches.extend(matched_names)\n    return matches\n\n\ndef list_trees(filename):\n    """"""Get list of the tree names in a ROOT file.\n\n    Parameters\n    ----------\n    filename : str\n        Path to ROOT file.\n\n    Returns\n    -------\n    trees : list\n        List of tree names\n\n    """"""\n    return _librootnumpy.list_trees(filename)\n\n\ndef list_branches(filename, treename=None):\n    """"""Get a list of the branch names of a tree in a ROOT file.\n\n    Parameters\n    ----------\n    filename : str\n        Path to ROOT file.\n    treename : str, optional (default=None)\n        Name of tree in the ROOT file.\n        (optional if the ROOT file has only one tree).\n\n    Returns\n    -------\n    branches : list\n        List of branch names\n\n    """"""\n    return _librootnumpy.list_branches(filename, treename)\n\n\ndef list_directories(filename):\n    """"""Get a list of the directories in a ROOT file.\n\n    Parameters\n    ----------\n    filename : str\n        Path to ROOT file.\n\n    Returns\n    -------\n    directories : list\n        List of directory names.\n\n    """"""\n    return _librootnumpy.list_directories(filename)\n\n\ndef list_structures(filename, treename=None):\n    """"""Get a dictionary mapping branch names to leaf structures.\n\n    .. warning:: ``list_structures`` is deprecated and will be removed in\n       release 5.0.0.\n\n    Parameters\n    ----------\n    filename : str\n        Path to ROOT file.\n    treename : str, optional (default=None)\n        Name of tree in the ROOT file\n        (optional if the ROOT file has only one tree).\n\n    Returns\n    -------\n    structures : OrderedDict\n        An ordered dictionary mapping branch names to leaf structures.\n\n    """"""\n    warnings.warn(""list_structures is deprecated and will be ""\n                  ""removed in 5.0.0."", DeprecationWarning)\n    return _librootnumpy.list_structures(filename, treename)\n\n\ndef root2array(filenames,\n               treename=None,\n               branches=None,\n               selection=None,\n               object_selection=None,\n               start=None,\n               stop=None,\n               step=None,\n               include_weight=False,\n               weight_name=\'weight\',\n               cache_size=-1,\n               warn_missing_tree=False):\n    """"""Convert trees in ROOT files into a numpy structured array.\n\n    Refer to the documentation of :func:`tree2array`.\n\n    Parameters\n    ----------\n    filenames : str or list\n        ROOT file name pattern or list of patterns. Wildcarding is supported by\n        Python globbing.\n    treename : str, optional (default=None)\n        Name of the tree to convert (optional if each file contains exactly one\n        tree).\n    branches : list of strings and tuples or a string or tuple, optional (default=None)\n        List of branches and expressions to include as columns of the array or\n        a single branch or expression in which case a nonstructured array is\n        returned. If None then include all branches that can be converted.\n        Branches or expressions that result in variable-length subarrays can be\n        truncated at a fixed length by using the tuple ``(branch_or_expression,\n        fill_value, length)`` or converted into a single value with\n        ``(branch_or_expression, fill_value)`` where ``length==1`` is implied.\n        ``fill_value`` is used when the original array is shorter than\n        ``length``. This truncation is after any object selection performed\n        with the ``object_selection`` argument.\n    selection : str, optional (default=None)\n        Only include entries fulfilling this condition. If the condition\n        evaluates to multiple values per tree entry (e.g. conditions on array\n        branches) then an entry will be included if the condition evaluates to\n        true for at least one array element.\n    object_selection : dict, optional (default=None)\n        A dictionary mapping selection strings to branch names or lists of\n        branch names. Only array elements passing the selection strings will be\n        included in the output array per entry in the tree. The branches\n        specified must be variable-length array-type branches and the length of\n        the selection and branches it acts on must match for each tree entry.\n        For example ``object_selection={\'a > 0\': [\'a\', \'b\']}`` will include all\n        elements of \'a\' and corresponding elements of \'b\' where \'a > 0\' for\n        each tree entry. \'a\' and \'b\' must have the same length in every tree\n        entry.\n    start, stop, step: int, optional (default=None)\n        The meaning of the ``start``, ``stop`` and ``step`` parameters is the\n        same as for Python slices. If a range is supplied (by setting some of\n        the ``start``, ``stop`` or ``step`` parameters), only the entries in\n        that range and fulfilling the ``selection`` condition (if defined) are\n        used.\n    include_weight : bool, optional (default=False)\n        Include a column containing the tree weight ``TTree::GetWeight()``.\n        Note that this will be the same value for all entries unless the tree\n        is actually a TChain containing multiple trees with different weights.\n    weight_name : str, optional (default=\'weight\')\n        The field name for the weight column if ``include_weight=True``.\n    cache_size : int, optional (default=-1)\n        Set the size (in bytes) of the TTreeCache used while reading a TTree. A\n        value of -1 uses ROOT\'s default cache size. A value of 0 disables the\n        cache.\n    warn_missing_tree : bool, optional (default=False)\n        If True, then warn when a tree is missing from an input file instead of\n        raising an IOError.\n\n    Notes\n    -----\n    * Refer to the :ref:`type conversion table <conversion_table>`.\n\n    See Also\n    --------\n    tree2array\n    array2tree\n    array2root\n\n    """"""\n    filenames = _glob(filenames)\n\n    if not filenames:\n        raise ValueError(""specify at least one filename"")\n\n    if treename is None:\n        trees = list_trees(filenames[0])\n        if len(trees) > 1:\n            raise ValueError(\n                ""treename must be specified if the file ""\n                ""contains more than one tree"")\n        elif not trees:\n            raise IOError(\n                ""no trees present in {0}"".format(filenames[0]))\n        treename = trees[0]\n\n    if isinstance(branches, string_types):\n        # single branch selected\n        flatten = branches\n        branches = [branches]\n    elif isinstance(branches, tuple):\n        if len(branches) not in (2, 3):\n            raise ValueError(\n                ""invalid branch tuple: {0}. ""\n                ""A branch tuple must contain two elements ""\n                ""(branch_name, fill_value) or three elements ""\n                ""(branch_name, fill_value, length) ""\n                ""to yield a single value or truncate, respectively"".format(branches))\n        flatten = branches[0]\n        branches = [branches]\n    else:\n        flatten = False\n\n    arr = _librootnumpy.root2array_fromfile(\n        filenames, treename, branches,\n        selection, object_selection,\n        start, stop, step,\n        include_weight,\n        weight_name,\n        cache_size,\n        warn_missing_tree)\n\n    if flatten:\n        # select single column\n        return arr[flatten]\n    return arr\n\n\ndef root2rec(filenames,\n             treename=None,\n             branches=None,\n             selection=None,\n             object_selection=None,\n             start=None,\n             stop=None,\n             step=None,\n             include_weight=False,\n             weight_name=\'weight\',\n             cache_size=-1,\n             warn_missing_tree=False):  # pragma: no cover\n    """"""View the result of :func:`root2array` as a record array.\n\n    .. warning:: ``root2rec`` is deprecated and will be removed in\n       release 5.0.0. Instead use ``root2array(...).view(np.recarray)``.\n\n    Notes\n    -----\n    * This is equivalent to::\n\n        root2array(filenames, treename, branches).view(np.recarray)\n\n    * Refer to the :ref:`type conversion table <conversion_table>`.\n\n    See Also\n    --------\n    root2array\n\n    """"""\n    warnings.warn(""root2rec is deprecated and will be removed in 5.0.0. ""\n                  ""Instead use root2array(...).view(np.recarray)"",\n                  DeprecationWarning)\n    return root2array(filenames, treename,\n                      branches, selection, object_selection,\n                      start, stop, step,\n                      include_weight,\n                      weight_name,\n                      cache_size,\n                      warn_missing_tree).view(np.recarray)\n\n\ndef tree2array(tree,\n               branches=None,\n               selection=None,\n               object_selection=None,\n               start=None,\n               stop=None,\n               step=None,\n               include_weight=False,\n               weight_name=\'weight\',\n               cache_size=-1):\n    """"""Convert a tree into a numpy structured array.\n\n    Convert branches of strings and basic types such as bool, int, float,\n    double, etc. as well as variable-length and fixed-length multidimensional\n    arrays and 1D or 2D vectors of basic types and strings. ``tree2array`` can\n    also create columns in the output array that are expressions involving the\n    TTree branches (i.e. ``\'vect.Pt() / 1000\'``) similar to ``TTree::Draw()``.\n    See the notes below for important details.\n\n    Parameters\n    ----------\n    tree : ROOT TTree instance\n        The ROOT TTree to convert into an array.\n    branches : list of strings and tuples or a string or tuple, optional (default=None)\n        List of branches and expressions to include as columns of the array or\n        a single branch or expression in which case a nonstructured array is\n        returned. If None then include all branches that can be converted.\n        Branches or expressions that result in variable-length subarrays can be\n        truncated at a fixed length by using the tuple ``(branch_or_expression,\n        fill_value, length)`` or converted into a single value with\n        ``(branch_or_expression, fill_value)`` where ``length==1`` is implied.\n        ``fill_value`` is used when the original array is shorter than\n        ``length``. This truncation is after any object selection performed\n        with the ``object_selection`` argument.\n    selection : str, optional (default=None)\n        Only include entries fulfilling this condition. If the condition\n        evaluates to multiple values per tree entry (e.g. conditions on array\n        branches) then an entry will be included if the condition evaluates to\n        true for at least one array element.\n    object_selection : dict, optional (default=None)\n        A dictionary mapping selection strings to branch names or lists of\n        branch names. Only array elements passing the selection strings will be\n        included in the output array per entry in the tree. The branches\n        specified must be variable-length array-type branches and the length of\n        the selection and branches it acts on must match for each tree entry.\n        For example ``object_selection={\'a > 0\': [\'a\', \'b\']}`` will include all\n        elements of \'a\' and corresponding elements of \'b\' where \'a > 0\' for\n        each tree entry. \'a\' and \'b\' must have the same length in every tree\n        entry.\n    start, stop, step: int, optional (default=None)\n        The meaning of the ``start``, ``stop`` and ``step`` parameters is the\n        same as for Python slices. If a range is supplied (by setting some of\n        the ``start``, ``stop`` or ``step`` parameters), only the entries in\n        that range and fulfilling the ``selection`` condition (if defined) are\n        used.\n    include_weight : bool, optional (default=False)\n        Include a column containing the tree weight ``TTree::GetWeight()``.\n        Note that this will be the same value for all entries unless the tree\n        is actually a TChain containing multiple trees with different weights.\n    weight_name : str, optional (default=\'weight\')\n        The field name for the weight column if ``include_weight=True``.\n    cache_size : int, optional (default=-1)\n        Set the size (in bytes) of the TTreeCache used while reading a TTree. A\n        value of -1 uses ROOT\'s default cache size. A value of 0 disables the\n        cache.\n\n    Notes\n    -----\n    Types are converted according to the following table:\n\n    .. _conversion_table:\n\n    ========================  ===============================\n    ROOT                      NumPy\n    ========================  ===============================\n    ``Bool_t``                ``np.bool``\n    ``Char_t``                ``np.int8``\n    ``UChar_t``               ``np.uint8``\n    ``Short_t``               ``np.int16``\n    ``UShort_t``              ``np.uint16``\n    ``Int_t``                 ``np.int32``\n    ``UInt_t``                ``np.uint32``\n    ``Float_t``               ``np.float32``\n    ``Double_t``              ``np.float64``\n    ``Long64_t``              ``np.int64``\n    ``ULong64_t``             ``np.uint64``\n    ``<type>[2][3]...``       ``(<nptype>, (2, 3, ...))``\n    ``<type>[nx][2]...``      ``np.object``\n    ``string``                ``np.object``\n    ``vector<t>``             ``np.object``\n    ``vector<vector<t> >``    ``np.object``\n    ========================  ===============================\n\n    * Variable-length arrays (such as ``x[nx][2]``) and vectors (such as\n      ``vector<int>``) are converted to NumPy arrays of the corresponding\n      types.\n\n    * Fixed-length arrays are converted to fixed-length NumPy array fields.\n\n    **Branches with different lengths:**\n\n    Note that when converting trees that have branches of different lengths\n    into numpy arrays, the shorter branches will be extended to match the\n    length of the longest branch by repeating their last values. If all\n    requested branches are shorter than the longest branch in the tree, this\n    will result in a ""read failure"" since beyond the end of the longest\n    requested branch no additional bytes will be read from the file and\n    root_numpy is unable to distinguish this from other ROOT errors that result\n    in no bytes being read. In this case, explicitly set the ``stop`` argument\n    to the length of the longest requested branch.\n\n\n    See Also\n    --------\n    root2array\n    array2root\n    array2tree\n\n    """"""\n    import ROOT\n    if not isinstance(tree, ROOT.TTree):\n        raise TypeError(""tree must be a ROOT.TTree"")\n    cobj = ROOT.AsCObject(tree)\n\n    if isinstance(branches, string_types):\n        # single branch selected\n        flatten = branches\n        branches = [branches]\n    elif isinstance(branches, tuple):\n        if len(branches) not in (2, 3):\n            raise ValueError(\n                ""invalid branch tuple: {0}. ""\n                ""A branch tuple must contain two elements ""\n                ""(branch_name, fill_value) or three elements ""\n                ""(branch_name, fill_value, length) ""\n                ""to yield a single value or truncate, respectively"".format(branches))\n        flatten = branches[0]\n        branches = [branches]\n    else:\n        flatten = False\n\n    arr = _librootnumpy.root2array_fromtree(\n        cobj, branches, selection, object_selection,\n        start, stop, step,\n        include_weight,\n        weight_name,\n        cache_size)\n\n    if flatten:\n        # select single column\n        return arr[flatten]\n    return arr\n\n\ndef tree2rec(tree,\n             branches=None,\n             selection=None,\n             object_selection=None,\n             start=None,\n             stop=None,\n             step=None,\n             include_weight=False,\n             weight_name=\'weight\',\n             cache_size=-1):  # pragma: no cover\n    """"""View the result of :func:`tree2array` as a record array.\n\n    .. warning:: ``tree2rec`` is deprecated and will be removed in\n       release 5.0.0. Instead use ``tree2array(...).view(np.recarray)``.\n\n    Notes\n    -----\n    * This is equivalent to::\n\n        tree2array(treename, branches).view(np.recarray)\n\n    * Refer to the :ref:`type conversion table <conversion_table>`.\n\n    See Also\n    --------\n    tree2array\n\n    """"""\n    warnings.warn(""tree2rec is deprecated and will be removed in 5.0.0. ""\n                  ""Instead use tree2array(...).view(np.recarray)"",\n                  DeprecationWarning)\n    return tree2array(tree,\n                      branches=branches,\n                      selection=selection,\n                      object_selection=object_selection,\n                      start=start,\n                      stop=stop,\n                      step=step,\n                      include_weight=include_weight,\n                      weight_name=weight_name,\n                      cache_size=cache_size).view(np.recarray)\n\n\ndef array2tree(arr, name=\'tree\', tree=None):\n    """"""Convert a numpy structured array into a ROOT TTree.\n\n    Fields of basic types, strings, and fixed-size subarrays of basic types are\n    supported. ``np.object`` and ``np.float16`` are currently not supported.\n\n    Parameters\n    ----------\n    arr : array\n        A numpy structured array\n    name : str (optional, default=\'tree\')\n        Name of the created ROOT TTree if ``tree`` is None.\n    tree : ROOT TTree (optional, default=None)\n        An existing ROOT TTree to be extended by the numpy array. Any branch\n        with the same name as a field in the numpy array will be extended as\n        long as the types are compatible, otherwise a TypeError is raised. New\n        branches will be created and filled for all new fields.\n\n    Returns\n    -------\n    root_tree : a ROOT TTree\n\n    Notes\n    -----\n    When using the ``tree`` argument to extend and/or add new branches to an\n    existing tree, note that it is possible to create branches of different\n    lengths. This will result in a warning from ROOT when root_numpy calls the\n    tree\'s ``SetEntries()`` method. Beyond that, the tree should still be\n    usable. While it might not be generally recommended to create branches with\n    differing lengths, this behaviour could be required in certain situations.\n    root_numpy makes no attempt to prevent such behaviour as this would be more\n    strict than ROOT itself. Also see the note about converting trees that have\n    branches of different lengths into numpy arrays in the documentation of\n    :func:`tree2array`.\n\n    See Also\n    --------\n    array2root\n    root2array\n    tree2array\n\n    Examples\n    --------\n\n    Convert a numpy array into a tree:\n\n    >>> from root_numpy import array2tree\n    >>> import numpy as np\n    >>>\n    >>> a = np.array([(1, 2.5, 3.4),\n    ...               (4, 5, 6.8)],\n    ...              dtype=[(\'a\', np.int32),\n    ...                     (\'b\', np.float32),\n    ...                     (\'c\', np.float64)])\n    >>> tree = array2tree(a)\n    >>> tree.Scan()\n    ************************************************\n    *    Row   *         a *         b *         c *\n    ************************************************\n    *        0 *         1 *       2.5 *       3.4 *\n    *        1 *         4 *         5 *       6.8 *\n    ************************************************\n\n    Add new branches to an existing tree (continuing from the example above):\n\n    >>> b = np.array([(4, 10),\n    ...               (3, 5)],\n    ...              dtype=[(\'d\', np.int32),\n    ...                     (\'e\', np.int32)])\n    >>> array2tree(b, tree=tree)\n    <ROOT.TTree object (""tree"") at 0x1449970>\n    >>> tree.Scan()\n    ************************************************************************\n    *    Row   *         a *         b *         c *         d *         e *\n    ************************************************************************\n    *        0 *         1 *       2.5 *       3.4 *         4 *        10 *\n    *        1 *         4 *         5 *       6.8 *         3 *         5 *\n    ************************************************************************\n\n    """"""\n    import ROOT\n    if tree is not None:\n        if not isinstance(tree, ROOT.TTree):\n            raise TypeError(""tree must be a ROOT.TTree"")\n        incobj = ROOT.AsCObject(tree)\n    else:\n        incobj = None\n    cobj = _librootnumpy.array2tree_toCObj(arr, name=name, tree=incobj)\n    return ROOT.BindObject(cobj, \'TTree\')\n\n\ndef array2root(arr, filename, treename=\'tree\', mode=\'update\'):\n    """"""Convert a numpy array into a ROOT TTree and save it in a ROOT TFile.\n\n    Fields of basic types, strings, and fixed-size subarrays of basic types are\n    supported. ``np.object`` and ``np.float16`` are currently not supported.\n\n    Parameters\n    ----------\n    arr : array\n        A numpy structured array\n    filename : str\n        Name of the output ROOT TFile. A new file will be created if it doesn\'t\n        already exist.\n    treename : str (optional, default=\'tree\')\n        Name of the ROOT TTree that will be created. If a TTree with the same\n        name already exists in the TFile, it will be extended as documented in\n        :func:`array2tree`.\n    mode : str (optional, default=\'update\')\n        Mode used to open the ROOT TFile (\'update\' or \'recreate\').\n\n    See Also\n    --------\n    array2tree\n    tree2array\n    root2array\n\n    Examples\n    --------\n\n    >>> from root_numpy import array2root, root2array\n    >>> import numpy as np\n    >>>\n    >>> a = np.array([(1, 2.5, 3.4),\n    ...               (4, 5, 6.8)],\n    ...              dtype=[(\'a\', np.int32),\n    ...                     (\'b\', np.float32),\n    ...                     (\'c\', np.float64)])\n    >>> array2root(a, \'test.root\', mode=\'recreate\')\n    >>> root2array(\'test.root\')\n    array([(1, 2.5, 3.4), (4, 5.0, 6.8)],\n          dtype=[(\'a\', \'<i4\'), (\'b\', \'<f4\'), (\'c\', \'<f8\')])\n    >>>\n    >>> a = np.array([\'\', \'a\', \'ab\', \'abc\', \'xyz\', \'\'],\n    ...              dtype=[(\'string\', \'S3\')])\n    >>> array2root(a, \'test.root\', mode=\'recreate\')\n    >>> root2array(\'test.root\')\n    array([(\'\',), (\'a\',), (\'ab\',), (\'abc\',), (\'xyz\',), (\'\',)],\n          dtype=[(\'string\', \'S3\')])\n    >>>\n    >>> a = np.array([([1, 2, 3],),\n    ...               ([4, 5, 6],)],\n    ...              dtype=[(\'array\', np.int32, (3,))])\n    >>> array2root(a, \'test.root\', mode=\'recreate\')\n    >>> root2array(\'test.root\')\n    array([([1, 2, 3],), ([4, 5, 6],)],\n          dtype=[(\'array\', \'<i4\', (3,))])\n\n    """"""\n    _librootnumpy.array2root(arr, filename, treename, mode)\n'"
root_numpy/_utils.py,30,"b'import numpy as np\nimport operator\n\nfrom .extern.six import string_types\nfrom ._librootnumpy import _blockwise_inner_join\n\n\n__all__ = [\n    \'rec2array\',\n    \'stack\',\n    \'stretch\',\n    \'dup_idx\',\n    \'blockwise_inner_join\',\n]\n\n\nVLEN = np.vectorize(len)\n\n\ndef rec2array(rec, fields=None):\n    """"""Convert a record/structured array into an ndarray with a homogeneous data type.\n\n    Parameters\n    ----------\n    rec : NumPy record/structured array\n        A NumPy structured array that will be cast into a homogenous data type.\n    fields : list of strings or string, optional (default=None)\n        The fields to include as columns in the output array. If None, then all\n        columns will be included. All fields must have the same shape.\n        See below regarding the case where ``fields`` is a string.\n\n    Returns\n    -------\n    array : NumPy ndarray\n        A new NumPy ndarray with homogeneous data types for all columns. If the\n        fields are scalars the shape will be ``(len(rec), num_fields)``. If the\n        fields are arrays of length ``num_things`` the shape will be\n        ``(len(rec), num_things, num_fields)``. If ``fields`` is a string (a\n        single field), then the shape will be simplified to remove the last\n        dimension ``num_fields``. This simplification will not occur if\n        ``fields`` is a list containing a single field.\n\n    Examples\n    --------\n\n    >>> from root_numpy import rec2array\n    >>> import numpy as np\n    >>> a = np.array([\n    ...         (12345, 2., 2.1, True),\n    ...         (3, 4., 4.2, False),],\n    ...         dtype=[\n    ...             (\'x\', np.int32),\n    ...             (\'y\', np.float32),\n    ...             (\'z\', np.float64),\n    ...             (\'w\', np.bool)])\n    >>> arr = rec2array(a)\n    >>> arr\n    array([[  1.23450000e+04,   2.00000000e+00,   2.10000000e+00,\n              1.00000000e+00],\n           [  3.00000000e+00,   4.00000000e+00,   4.20000000e+00,\n              0.00000000e+00]])\n    >>> arr.dtype\n    dtype(\'float64\')\n    >>>\n    >>> a = np.array([\n    ...         ([1, 2, 3], [4.5, 6, 9.5],),\n    ...         ([4, 5, 6], [3.3, 7.5, 8.4],),],\n    ...         dtype=[\n    ...             (\'x\', np.int32, (3,)),\n    ...             (\'y\', np.float32, (3,))])\n    >>> arr = rec2array(a)\n    >>> arr\n    array([[[ 1.        ,  4.5       ],\n            [ 2.        ,  6.        ],\n            [ 3.        ,  9.5       ]],\n    <BLANKLINE>\n           [[ 4.        ,  3.29999995],\n            [ 5.        ,  7.5       ],\n            [ 6.        ,  8.39999962]]])\n    >>> arr.shape\n    (2, 3, 2)\n\n    """"""\n    simplify = False\n    if fields is None:\n        fields = rec.dtype.names\n    elif isinstance(fields, string_types):\n        fields = [fields]\n        simplify = True\n    # Creates a copy and casts all data to the same type\n    arr = np.dstack([rec[field] for field in fields])\n    # Check for array-type fields. If none, then remove outer dimension.\n    # Only need to check first field since np.dstack will anyway raise an\n    # exception if the shapes don\'t match\n    # np.dstack will also fail if fields is an empty list\n    if not rec.dtype[fields[0]].shape:\n        arr = arr[0]\n    if simplify:\n        # remove last dimension (will be of size 1)\n        arr = arr.reshape(arr.shape[:-1])\n    return arr\n\n\ndef stack(recs, fields=None):\n    """"""Stack common fields in multiple record arrays (concatenate them).\n\n    Parameters\n    ----------\n    recs : list\n        List of NumPy record arrays\n    fields : list of strings, optional (default=None)\n        The list of fields to include in the stacked array. If None, then\n        include the fields in common to all the record arrays.\n\n    Returns\n    -------\n    rec : NumPy record array\n        The stacked array.\n\n    """"""\n    if fields is None:\n        fields = list(set.intersection(\n            *[set(rec.dtype.names) for rec in recs]))\n        # preserve order of fields wrt first record array\n        if set(fields) == set(recs[0].dtype.names):\n            fields = list(recs[0].dtype.names)\n    return np.hstack([rec[fields] for rec in recs])\n\n\ndef stretch(arr, fields=None, return_indices=False):\n    """"""Stretch an array.\n\n    Stretch an array by ``hstack()``-ing  multiple array fields while\n    preserving column names and record array structure. If a scalar field is\n    specified, it will be stretched along with array fields.\n\n    Parameters\n    ----------\n    arr : NumPy structured or record array\n        The array to be stretched.\n    fields : list of strings or string, optional (default=None)\n        A list of column names or a single column name to stretch.\n        If ``fields`` is a string, then the output array is a one-dimensional\n        unstructured array containing only the stretched elements of that\n        field. If None, then stretch all fields.\n    return_indices : bool, optional (default=False)\n        If True, the array index of each stretched array entry will be\n        returned in addition to the stretched array.\n        This changes the return type of this function to a tuple consisting\n        of a structured array and a numpy int64 array.\n\n    Returns\n    -------\n    ret : A NumPy structured array\n        The stretched array.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from root_numpy import stretch\n    >>> arr = np.empty(2, dtype=[(\'scalar\', np.int), (\'array\', \'O\')])\n    >>> arr[0] = (0, np.array([1, 2, 3], dtype=np.float))\n    >>> arr[1] = (1, np.array([4, 5, 6], dtype=np.float))\n    >>> stretch(arr, [\'scalar\', \'array\'])\n    array([(0, 1.0), (0, 2.0), (0, 3.0), (1, 4.0), (1, 5.0), (1, 6.0)],\n        dtype=[(\'scalar\', \'<i8\'), (\'array\', \'<f8\')])\n\n    """"""\n    dtype = []\n    len_array = None\n\n    flatten = False\n    if fields is None:\n        fields = arr.dtype.names\n    elif isinstance(fields, string_types):\n        fields = [fields]\n        flatten = True\n\n    # Construct dtype and check consistency\n    for field in fields:\n        dt = arr.dtype[field]\n        if dt == \'O\' or len(dt.shape):\n            if dt == \'O\':\n                # Variable-length array field\n                lengths = VLEN(arr[field])\n            else:\n                # Fixed-length array field\n                lengths = np.repeat(dt.shape[0], arr.shape[0])\n            if len_array is None:\n                len_array = lengths\n            elif not np.array_equal(lengths, len_array):\n                raise ValueError(\n                    ""inconsistent lengths of array columns in input"")\n            if dt == \'O\':\n                dtype.append((field, arr[field][0].dtype))\n            else:\n                dtype.append((field, arr[field].dtype, dt.shape[1:]))\n        else:\n            # Scalar field\n            dtype.append((field, dt))\n\n    if len_array is None:\n        raise RuntimeError(""no array column in input"")\n\n    # Build stretched output\n    ret = np.empty(np.sum(len_array), dtype=dtype)\n    for field in fields:\n        dt = arr.dtype[field]\n        if dt == \'O\' or len(dt.shape) == 1:\n            # Variable-length or 1D fixed-length array field\n            ret[field] = np.hstack(arr[field])\n        elif len(dt.shape):\n            # Multidimensional fixed-length array field\n            ret[field] = np.vstack(arr[field])\n        else:\n            # Scalar field\n            ret[field] = np.repeat(arr[field], len_array)\n\n    if flatten:\n        ret = ret[fields[0]]\n\n    if return_indices:\n        idx = np.concatenate(list(map(np.arange, len_array)))\n        return ret, idx\n\n    return ret\n\n\ndef dup_idx(arr):\n    """"""Return the indices of all duplicated array elements.\n\n    Parameters\n    ----------\n    arr : array-like object\n        An array-like object\n\n    Returns\n    -------\n    idx : NumPy array\n        An array containing the indices of the duplicated elements\n\n    Examples\n    --------\n    >>> from root_numpy import dup_idx\n    >>> dup_idx([1, 2, 3, 4, 5])\n    array([], dtype=int64)\n    >>> dup_idx([1, 2, 3, 4, 5, 5])\n    array([4, 5])\n    >>> dup_idx([1, 2, 3, 4, 5, 5, 1])\n    array([0, 4, 5, 6])\n\n    """"""\n    _, b = np.unique(arr, return_inverse=True)\n    return np.nonzero(np.logical_or.reduce(\n        b[:, np.newaxis] == np.nonzero(np.bincount(b) > 1),\n        axis=1))[0]\n\n\ndef blockwise_inner_join(data, left, foreign_key, right,\n                         force_repeat=None,\n                         foreign_key_name=None):\n    """"""Perform a blockwise inner join.\n\n    Perform a blockwise inner join from names specified in ``left`` to\n    ``right`` via ``foreign_key``: left->foreign_key->right.\n\n    Parameters\n    ----------\n    data : array\n        A structured NumPy array.\n    left : array\n        Array of left side column names.\n    foreign_key : array or string\n        NumPy array or string ``foreign_key`` column name. This column can be\n        either an integer or an array of ints. If ``foreign_key`` is an array\n        of int column, left column will be treated according to left column\n        type:\n\n        * Scalar columns or columns in ``force_repeat`` will be repeated\n        * Array columns not in ``force_repeat`` will be assumed to the\n          same length as ``foreign_key`` and will be stretched by index\n    right : array\n        Array of right side column names. These are array columns that each\n        index ``foreign_key`` points to. These columns are assumed to have the\n        same length.\n    force_repeat : array, optional (default=None)\n        Array of left column names that will be forced to stretch even if it\'s\n        an array (useful when you want to emulate a multiple join).\n    foreign_key_name : str, optional (default=None)\n        The name of foreign key column in the output array.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from root_numpy import blockwise_inner_join\n    >>> test_data = np.array([\n    (1.0, np.array([11, 12, 13]), np.array([1, 0, 1]), 0, np.array([1, 2, 3])),\n    (2.0, np.array([21, 22, 23]), np.array([-1, 2, -1]), 1, np.array([31, 32, 33]))],\n    dtype=[(\'sl\', np.float), (\'al\', \'O\'), (\'fk\', \'O\'), (\'s_fk\', np.int), (\'ar\', \'O\')])\n\n    >>> blockwise_inner_join(test_data, [\'sl\', \'al\'], test_data[\'fk\'], [\'ar\'])\n    array([(1.0, 11, 2, 1), (1.0, 12, 1, 0), (1.0, 13, 2, 1), (2.0, 22, 33, 2)],\n    dtype=[(\'sl\', \'<f8\'), (\'al\', \'<i8\'), (\'ar\', \'<i8\'), (\'fk\', \'<i8\')])\n\n    >>> blockwise_inner_join(test_data, [\'sl\', \'al\'], test_data[\'fk\'], [\'ar\'], force_repeat=[\'al\'])\n    array([(1.0, [11, 12, 13], 2, 1), (1.0, [11, 12, 13], 1, 0),\n    (1.0, [11, 12, 13], 2, 1), (2.0, [21, 22, 23], 33, 2)],\n    dtype=[(\'sl\', \'<f8\'), (\'al\', \'|O8\'), (\'ar\', \'<i8\'), (\'fk\', \'<i8\')])\n\n    """"""\n    if isinstance(foreign_key, string_types):\n        foreign_key = data[foreign_key]\n    return _blockwise_inner_join(data, left, foreign_key, right,\n                                 force_repeat, foreign_key_name)\n'"
root_numpy/_warnings.py,0,"b'import warnings\n\n\n__all__ = [\n    \'RootNumpyUnconvertibleWarning\',\n]\n\n\nclass RootNumpyUnconvertibleWarning(RuntimeWarning):\n    """"""\n    This warning is raised when root_numpy is unable to convert a branch into a\n    column of a NumPy array because there is no converter for the type. If the\n    user explicitly requests a branch that cannot be converted, an error is\n    raised. If the user does not specify a list of branches in an attempt to\n    convert all branches, then this warning is raised for each branch that\n    cannot be converted and these branches are merely skipped.\n    """"""\n\nwarnings.simplefilter(\'always\', RootNumpyUnconvertibleWarning)\n'"
root_numpy/info.py,0,"b'""""""\n                 _\n _ __ ___   ___ | |_     _ __  _   _ _ __ ___  _ __  _   _\n| \'__/ _ \\ / _ \\| __|   | \'_ \\| | | | \'_ ` _ \\| \'_ \\| | | |\n| | | (_) | (_) | |_    | | | | |_| | | | | | | |_) | |_| |\n|_|  \\___/ \\___/ \\__|___|_| |_|\\__,_|_| |_| |_| .__/ \\__, |  {0}\n                   |_____|                    |_|    |___/\n""""""\n__version__ = \'4.8.0\'\n__doc__ = __doc__.format(__version__)  # pylint:disable=redefined-builtin\n'"
root_numpy/setup_utils.py,0,"b'import os\nimport sys\nimport re\nimport subprocess\nimport numbers\nfrom collections import namedtuple\n\n\nclass ROOTVersion(namedtuple(\'_ROOTVersionBase\',\n                             [\'major\', \'minor\', \'micro\'])):\n\n    def __new__(cls, *version):\n        if len(version) == 1:\n            version = version[0]\n\n        if isinstance(version, numbers.Integral):\n            if version < 1E4:\n                raise ValueError(\n                    ""{0:d} is not a valid ROOT version integer"".format(version))\n            return super(ROOTVersion, cls).__new__(\n                cls,\n                int(version / 1E4),\n                int((version / 1E2) % 100),\n                int(version % 100))\n\n        if isinstance(version, tuple):\n            return super(ROOTVersion, cls).__new__(cls, *version)\n\n        # parse the string version X.YY/ZZ\n        match = re.match(\n            r""(?P<major>[\\d]+)\\.(?P<minor>[\\d]+)/(?P<micro>[\\d]+)"", version)\n        if not match:\n            raise ValueError(\n                ""\'{0}\' is not a valid ROOT version string"".format(version))\n        return super(ROOTVersion, cls).__new__(\n            cls,\n            int(match.group(\'major\')),\n            int(match.group(\'minor\')),\n            int(match.group(\'micro\')))\n\n\n    def __eq__(self, version):\n        if not isinstance(version, tuple):\n            version = ROOTVersion(version)\n        return super(ROOTVersion, self).__eq__(version)\n\n    def __ne__(self, version):\n        return not self.__eq__(version)\n\n    def __gt__(self, version):\n        if not isinstance(version, tuple):\n            version = ROOTVersion(version)\n        return super(ROOTVersion, self).__gt__(version)\n\n    def __ge__(self, version):\n        if not isinstance(version, tuple):\n            version = ROOTVersion(version)\n        return super(ROOTVersion, self).__ge__(version)\n\n    def __lt__(self, version):\n        if not isinstance(version, tuple):\n            version = ROOTVersion(version)\n        return super(ROOTVersion, self).__lt__(version)\n\n    def __le__(self, version):\n        if not isinstance(version, tuple):\n            version = ROOTVersion(version)\n        return super(ROOTVersion, self).__le__(version)\n\n    def __repr__(self):\n        return str(self)\n\n    def __str__(self):\n        return \'{0:d}.{1:02d}/{2:02d}\'.format(*self)\n\n\ndef root_flags(root_config=\'root-config\'):\n    root_cflags = subprocess.Popen(\n        [root_config, \'--cflags\'],\n        stdout=subprocess.PIPE).communicate()[0].strip()\n    root_ldflags = subprocess.Popen(\n        [root_config, \'--libs\'],\n        stdout=subprocess.PIPE).communicate()[0].strip()\n    if sys.version > \'3\':\n        root_cflags = root_cflags.decode(\'utf-8\')\n        root_ldflags = root_ldflags.decode(\'utf-8\')\n    return root_cflags.split(), root_ldflags.split()\n\n\ndef root_has_feature(feature, root_config=\'root-config\'):\n    if os.getenv(\'NO_ROOT_NUMPY_{0}\'.format(feature.upper())):\n        # override\n        return False\n    has_feature = subprocess.Popen(\n        [root_config, \'--has-{0}\'.format(feature)],\n        stdout=subprocess.PIPE).communicate()[0].strip()\n    if sys.version > \'3\':\n        has_feature = has_feature.decode(\'utf-8\')\n    return has_feature == \'yes\'\n\n\ndef root_version_installed(root_config=\'root-config\'):\n    root_vers = subprocess.Popen(\n        [root_config, \'--version\'],\n        stdout=subprocess.PIPE).communicate()[0].strip()\n    if sys.version > \'3\':\n        root_vers = root_vers.decode(\'utf-8\')\n    return ROOTVersion(root_vers)\n\n\ndef root_version_active():\n    import ROOT\n    return ROOTVersion(ROOT.gROOT.GetVersionInt())\n\n\ndef get_config():\n    from pkg_resources import resource_filename\n    config_path = resource_filename(\'root_numpy\', \'config.json\')\n    if not os.path.isfile(config_path):\n        return None\n    import json\n    with open(config_path, \'r\') as config_file:\n        config = json.load(config_file)\n    return config\n'"
docs/sphinxext/gen_rst.py,0,"b'""""""\nExample generation for root_numpy\n\nGenerate the rst files for the examples by iterating over the python\nexample files.\n\nFiles that generate images should start with \'plot\'\n""""""\nfrom time import time\nimport os\nimport shutil\nimport traceback\nimport glob\nimport sys\nfrom StringIO import StringIO\nimport token\nimport tokenize\n\nimport matplotlib\nmatplotlib.use(\'Agg\')\n\nimport ROOT\nROOT.gROOT.SetBatch(True)\n\n\n###############################################################################\n# A tee object to redict streams to multiple outputs\n\nclass Tee(object):\n\n    def __init__(self, file1, file2):\n        self.file1 = file1\n        self.file2 = file2\n\n    def write(self, data):\n        self.file1.write(data)\n        self.file2.write(data)\n\n    def flush(self):\n        self.file1.flush()\n        self.file2.flush()\n\n###############################################################################\nrst_template = """"""\n\n.. _example_%(short_fname)s:\n\n%(docstring)s\n\n**Python source code:** :download:`%(fname)s <%(fname)s>`\n\n.. literalinclude:: %(fname)s\n    :lines: %(end_row)s-\n    """"""\n\nplot_rst_template = """"""\n\n.. _example_%(short_fname)s:\n\n%(docstring)s\n\n%(image_list)s\n\n%(stdout)s\n\n**Python source code:** :download:`%(fname)s <%(fname)s>`\n\n.. literalinclude:: %(fname)s\n    :lines: %(end_row)s-\n\n**Total running time of the example:** %(time_elapsed) .2f seconds\n    """"""\n\n# The following strings are used when we have several pictures: we use\n# an html div tag that our CSS uses to turn the lists into horizontal\n# lists.\nHLIST_HEADER = """"""\n.. rst-class:: horizontal\n\n""""""\n\nHLIST_IMAGE_TEMPLATE = """"""\n.. image:: images/%s\n   :scale: 50\n""""""\n\nSINGLE_IMAGE = """"""\n.. image:: images/%s\n   :align: center\n   :scale: 80\n""""""\n\n\ndef extract_docstring(filename):\n    """""" Extract a module-level docstring, if any\n    """"""\n    lines = file(filename).readlines()\n    start_row = 0\n    if lines[0].startswith(\'#!\'):\n        lines.pop(0)\n        start_row = 1\n\n    docstring = \'\'\n    first_par = \'\'\n    tokens = tokenize.generate_tokens(iter(lines).next)\n    for tok_type, tok_content, _, (erow, _), _ in tokens:\n        tok_type = token.tok_name[tok_type]\n        if tok_type in (\'NEWLINE\', \'COMMENT\', \'NL\', \'INDENT\', \'DEDENT\'):\n            continue\n        elif tok_type == \'STRING\':\n            docstring = eval(tok_content)\n            # If the docstring is formatted with several paragraphs, extract\n            # the first one:\n            paragraphs = \'\\n\'.join(line.rstrip()\n                              for line in docstring.split(\'\\n\')).split(\'\\n\\n\')\n            if len(paragraphs) > 0:\n                first_par = paragraphs[0]\n        break\n    end_row = erow + 1 + start_row\n    if lines and lines[end_row - 2] == \'print(__doc__)\\n\':\n        end_row += 1\n    return docstring, first_par, end_row\n\n\ndef generate_example_rst(app):\n    """""" Generate the list of examples, as well as the contents of\n        examples.\n    """"""\n    root_dir = os.path.join(app.builder.srcdir, \'auto_examples\')\n    example_dir = os.path.abspath(app.builder.srcdir + \'/../\' + \'examples\')\n    try:\n        plot_gallery = eval(app.builder.config.plot_gallery)\n    except TypeError:\n        plot_gallery = bool(app.builder.config.plot_gallery)\n    if not os.path.exists(example_dir):\n        os.makedirs(example_dir)\n    if not os.path.exists(root_dir):\n        os.makedirs(root_dir)\n\n    # we create an index.rst with all examples\n    fhindex = file(os.path.join(root_dir, \'index.rst\'), \'w\')\n    #Note: The sidebar button has been removed from the examples page for now\n    #      due to how it messes up the layout. Will be fixed at a later point\n    fhindex.write(""""""\\\n\n.. raw:: html\n\n\n    <style type=""text/css"">\n\n    div#sidebarbutton {\n        display: none;\n    }\n\n    .figure {\n        float: left;\n        margin: 10px;\n        width: auto;\n        height: 200px;\n        width: 180px;\n    }\n\n    .figure img {\n        display: inline;\n        }\n\n    .figure .caption {\n        width: 170px;\n        text-align: center !important;\n    }\n    </style>\n\n.. _examples-index:\n\nExamples\n========\n\n"""""")\n    # Here we don\'t use an os.walk, but we recurse only twice: flat is\n    # better than nested.\n    generate_dir_rst(\'.\', fhindex, example_dir, root_dir, plot_gallery)\n    for dir in sorted(os.listdir(example_dir)):\n        if os.path.isdir(os.path.join(example_dir, dir)):\n            generate_dir_rst(dir, fhindex, example_dir, root_dir, plot_gallery)\n    fhindex.flush()\n\n\ndef generate_dir_rst(dir, fhindex, example_dir, root_dir, plot_gallery):\n    """""" Generate the rst file for an example directory.\n    """"""\n    if not dir == \'.\':\n        target_dir = os.path.join(root_dir, dir)\n        src_dir = os.path.join(example_dir, dir)\n    else:\n        target_dir = root_dir\n        src_dir = example_dir\n    if not os.path.exists(os.path.join(src_dir, \'README.txt\')):\n        print(\'Example directory %s does not have a README.txt file\' % src_dir)\n        print(\'Skipping this directory\')\n        print(80 * \'_\')\n        return\n    fhindex.write(""""""\n\n\n%s\n\n\n"""""" % file(os.path.join(src_dir, \'README.txt\')).read())\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    def sort_key(a):\n        # put last elements without a plot\n        if not a.startswith(\'plot\') and a.endswith(\'.py\'):\n            return \'zz\' + a\n        return a\n\n    fhindex.write(""""""\n\n.. toctree::\n\n"""""")\n    for fname in sorted(os.listdir(src_dir), key=sort_key):\n        if fname.endswith(\'py\'):\n            generate_file_rst(fname, target_dir, src_dir, plot_gallery)\n            #thumb = os.path.join(dir, \'images\', \'thumb\', fname[:-3] + \'.png\')\n            link_name = os.path.join(dir, fname).replace(os.path.sep, \'_\')\n            #fhindex.write(\'.. figure:: %s\\n\' % thumb)\n            #if link_name.startswith(\'._\'):\n            #    link_name = link_name[2:]\n            #if dir != \'.\':\n            #    fhindex.write(\'   :target: ./%s/%s.html\\n\\n\' % (dir,\n            #                                                   fname[:-3]))\n            #else:\n            #    fhindex.write(\'   :target: ./%s.html\\n\\n\' % link_name[:-3])\n            fhindex.write(""""""\n   %s/%s\n"""""" % (dir, fname[:-3]))\n    fhindex.write(""""""\n\n.. raw:: html\n\n    <div style=""clear: both""></div>\n    """""")  # clear at the end of the section\n\n\ndef generate_file_rst(fname, target_dir, src_dir, plot_gallery):\n    """""" Generate the rst file for a given example.\n    """"""\n    base_image_name = os.path.splitext(fname)[0]\n    image_fname = \'%s_%%s.png\' % base_image_name\n    root_image_fname = \'root_%s_%%s.png\' % base_image_name\n    root_fig_num = 1\n\n    this_template = rst_template\n    last_dir = os.path.split(src_dir)[-1]\n    # to avoid leading . in file names, and wrong names in links\n    if last_dir == \'.\' or last_dir == \'examples\':\n        last_dir = \'\'\n    else:\n        last_dir += \'_\'\n    short_fname = last_dir + fname\n    src_file = os.path.join(src_dir, fname)\n    example_file = os.path.join(target_dir, fname)\n    shutil.copyfile(src_file, example_file)\n\n    # The following is a list containing all the figure names\n    figure_list = []\n\n    image_dir = os.path.join(target_dir, \'images\')\n    thumb_dir = os.path.join(image_dir, \'thumb\')\n    if not os.path.exists(image_dir):\n        os.makedirs(image_dir)\n    if not os.path.exists(thumb_dir):\n        os.makedirs(thumb_dir)\n    image_path = os.path.join(image_dir, image_fname)\n    root_image_path = os.path.join(image_dir, root_image_fname)\n\n    stdout_path = os.path.join(image_dir,\n                               \'stdout_%s.txt\' % base_image_name)\n    time_path = os.path.join(image_dir,\n                               \'time_%s.txt\' % base_image_name)\n    thumb_file = os.path.join(thumb_dir, fname[:-3] + \'.png\')\n    time_elapsed = 0\n    if plot_gallery and fname.startswith(\'plot\'):\n        # generate the plot as png image if file name\n        # starts with plot and if it is more recent than an\n        # existing image.\n        first_image_file = image_path % 1\n        first_root_image_file = root_image_path % 1\n        if os.path.exists(stdout_path):\n            stdout = open(stdout_path).read()\n        else:\n            stdout = \'\'\n        if os.path.exists(time_path):\n            time_elapsed = float(open(time_path).read())\n\n        if (not os.path.exists(first_image_file) or\n            not os.path.exists(first_root_image_file) or\n                os.stat(first_image_file).st_mtime <=\n                                    os.stat(src_file).st_mtime):\n            # We need to execute the code\n            print(\'plotting %s\' % fname)\n            t0 = time()\n            import matplotlib.pyplot as plt\n            plt.close(\'all\')\n            cwd = os.getcwd()\n            try:\n                # First CD in the original example dir, so that any file\n                # created by the example get created in this directory\n                orig_stdout = sys.stdout\n                os.chdir(os.path.dirname(src_file))\n                my_buffer = StringIO()\n                my_stdout = Tee(sys.stdout, my_buffer)\n                sys.stdout = my_stdout\n                my_globals = {\'pl\': plt}\n                execfile(os.path.basename(src_file), my_globals)\n                time_elapsed = time() - t0\n                sys.stdout = orig_stdout\n                my_stdout = my_buffer.getvalue()\n                if \'__doc__\' in my_globals:\n                    # The __doc__ is often printed in the example, we\n                    # don\'t with to echo it\n                    my_stdout = my_stdout.replace(\n                                            my_globals[\'__doc__\'],\n                                            \'\')\n                my_stdout = my_stdout.strip()\n                if my_stdout:\n                    stdout = \'**Script output**::\\n\\n  %s\\n\\n\' % (\n                        \'\\n  \'.join(my_stdout.split(\'\\n\')))\n                open(stdout_path, \'w\').write(stdout)\n                open(time_path, \'w\').write(\'%f\' % time_elapsed)\n                os.chdir(cwd)\n\n                # In order to save every figure we have two solutions :\n                # * iterate from 1 to infinity and call plt.fignum_exists(n)\n                #   (this requires the figures to be numbered\n                #    incrementally: 1, 2, 3 and not 1, 2, 5)\n                # * iterate over [fig_mngr.num for fig_mngr in\n                #   matplotlib._pylab_helpers.Gcf.get_all_fig_managers()]\n                for fig_num in (fig_mngr.num for fig_mngr in\n                        matplotlib._pylab_helpers.Gcf.get_all_fig_managers()):\n                    # Set the fig_num figure as the current figure as we can\'t\n                    # save a figure that\'s not the current figure.\n                    plt.figure(fig_num)\n                    plt.savefig(image_path % fig_num)\n                    figure_list.append(image_fname % fig_num)\n                for canvas in ROOT.gROOT.GetListOfCanvases():\n                    maybe_root_filename = os.path.join(os.path.dirname(src_file), canvas.name)\n                    if os.path.isfile(maybe_root_filename):\n                        os.rename(maybe_root_filename, os.path.join(image_dir, canvas.name))\n                        figure_list.append(canvas.name)\n                        canvas.Close()\n                    else:\n                        canvas.SaveAs(root_image_path % root_fig_num)\n                        canvas.Close()\n                        figure_list.append(root_image_fname % root_fig_num)\n                        root_fig_num += 1\n            except:\n                print(80 * \'_\')\n                print(\'%s is not compiling:\' % fname)\n                traceback.print_exc()\n                print(80 * \'_\')\n            finally:\n                os.chdir(cwd)\n                sys.stdout = orig_stdout\n\n            print("" - time elapsed : %.2g sec"" % time_elapsed)\n        else:\n            figure_list = [f[len(image_dir):]\n                            for f in glob.glob(image_path % \'[1-9]\')]\n                            #for f in glob.glob(image_path % \'*\')]\n\n        # generate thumb file\n        this_template = plot_rst_template\n        from matplotlib import image\n        if os.path.exists(first_image_file):\n            image.thumbnail(first_image_file, thumb_file, 0.2)\n        elif os.path.exists(first_root_image_file):\n            image.thumbnail(first_root_image_file, thumb_file, 0.2)\n\n    if not os.path.exists(thumb_file):\n        # create something not to replace the thumbnail\n        shutil.copy(\'images/blank_image.png\', thumb_file)\n\n    docstring, short_desc, end_row = extract_docstring(example_file)\n\n    # Depending on whether we have one or more figures, we\'re using a\n    # horizontal list or a single rst call to \'image\'.\n    if len(figure_list) == 1:\n        figure_name = figure_list[0]\n        image_list = SINGLE_IMAGE % figure_name.lstrip(\'/\')\n    else:\n        image_list = HLIST_HEADER\n        for figure_name in figure_list:\n            image_list += HLIST_IMAGE_TEMPLATE % figure_name.lstrip(\'/\')\n\n    f = open(os.path.join(target_dir, fname[:-2] + \'rst\'), \'w\')\n    f.write(this_template % locals())\n    f.flush()\n\n\ndef setup(app):\n    app.connect(\'builder-inited\', generate_example_rst)\n    app.add_config_value(\'plot_gallery\', True, \'html\')\n\n    # Sphinx hack: sphinx copies generated images to the build directory\n    #  each time the docs are made.  If the desired image name already\n    #  exists, it appends a digit to prevent overwrites.  The problem is,\n    #  the directory is never cleared.  This means that each time you build\n    #  the docs, the number of images in the directory grows.\n    #\n    # This question has been asked on the sphinx development list, but there\n    #  was no response: http://osdir.com/ml/sphinx-dev/2011-02/msg00123.html\n    #\n    # The following is a hack that prevents this behavior by clearing the\n    #  image build directory each time the docs are built.  If sphinx\n    #  changes their layout between versions, this will not work (though\n    #  it should probably not cause a crash).  Tested successfully\n    #  on Sphinx 1.0.7\n    build_image_dir = \'_build/html/_images\'\n    if os.path.exists(build_image_dir):\n        filelist = os.listdir(build_image_dir)\n        for filename in filelist:\n            if filename.endswith(\'png\'):\n                os.remove(os.path.join(build_image_dir, filename))\n'"
examples/core/plot_bootstrap.py,2,"b'#!/usr/bin/env python\n""""""\n============================\nBootstrap a TTree with NumPy\n============================\n\nThis example demonstrates how to sample entries in a TTree with replacement\nwith the help of NumPy and root_numpy. This example depends on\n`rootpy <http://www.rootpy.org/>`_ which can be installed with pip::\n\n    pip install --user rootpy\n\n""""""\nfrom rootpy.extern.six.moves import range\nfrom rootpy.tree import Tree, TreeModel, FloatCol\nfrom rootpy.plotting import Canvas, Hist2D, set_style\nfrom rootpy.io import root_open\nfrom root_numpy import root2array, array2tree, rec2array, fill_hist\nimport ROOT\nimport numpy as np\nfrom random import gauss\nimport random\nimport os\n\nROOT.gROOT.SetBatch()\nset_style(\'ATLAS\')\nnp.random.seed(0)\nrandom.seed(0)\n\n# create an example TTree dataset\n\nclass Sample(TreeModel):\n    x = FloatCol()\n    y = FloatCol()\n\n\nwith root_open(\'sample.root\', \'recreate\'):\n    # generate toy data in a TTree\n    tree = Tree(\'sample\', model=Sample)\n    for i in range(500):\n        tree.x = gauss(0, 1)\n        tree.y = gauss(0, 1)\n        tree.Fill()\n    tree.write()\n\n\n# read in the TTree as a NumPy array\narray = root2array(\'sample.root\', \'sample\')\n\nif os.path.exists(\'bootstrap.gif\'):\n    os.remove(\'bootstrap.gif\')\n# Canvas name is set here to aid the automatic documentation generation\n# It needs to take the GIF already saved instead of saving a png of the last\n# frame.\ncanvas = Canvas(width=500, height=400, name=\'bootstrap.gif\')\nhist = Hist2D(10, -3, 3, 10, -3, 3, drawstyle=\'LEGO2\')\n\noutput = root_open(\'bootstrap.root\', \'recreate\')\n\n# bootstrap 10 times\nfor bootstrap_idx in range(10):\n    # sample with replacement\n    # http://docs.scipy.org/doc/numpy-dev/reference/generated/numpy.random.choice.html\n    sample_idx = np.random.choice(len(array), size=len(array), replace=True)\n    array_bootstrapped = array[sample_idx]\n    # convert back to a TTree and write it out\n    tree_bootstrapped = array2tree(\n        array_bootstrapped,\n        name=\'bootstrap_{0}\'.format(bootstrap_idx))\n    tree_bootstrapped.Write()\n    tree_bootstrapped.Delete()\n    # fill the ROOT histogram with the numpy array\n    hist.Reset()\n    fill_hist(hist, rec2array(array_bootstrapped))\n    hist.Draw()\n    hist.xaxis.title = \'x\'\n    hist.yaxis.title = \'y\'\n    hist.zaxis.title = \'Events\'\n    hist.xaxis.limits = (-2.5, 2.5)\n    hist.yaxis.limits = (-2.5, 2.5)\n    hist.zaxis.range_user = (0, 30)\n    hist.xaxis.divisions = 5\n    hist.yaxis.divisions = 5\n    hist.zaxis.divisions = 5\n    canvas.Print(\'bootstrap.gif+50\')\n\n# loop the gif\ncanvas.Print(\'bootstrap.gif++\')\noutput.Close()\n'"
examples/tmva/plot_multiclass.py,10,"b'""""""\n=============================================\nMulticlass Classification with NumPy and TMVA\n=============================================\n""""""\nfrom array import array\nimport numpy as np\nfrom numpy.random import RandomState\nfrom root_numpy.tmva import add_classification_events, evaluate_reader\nfrom root_numpy import ROOT_VERSION\nimport matplotlib.pyplot as plt\nfrom ROOT import TMVA, TFile, TCut\n\nplt.style.use(\'ggplot\')\nRNG = RandomState(42)\n\n# Construct an example multiclass dataset\nn_events = 1000\nclass_0 = RNG.multivariate_normal(\n    [-2, -2], np.diag([1, 1]), n_events)\nclass_1 = RNG.multivariate_normal(\n    [0, 2], np.diag([1, 1]), n_events)\nclass_2 = RNG.multivariate_normal(\n    [2, -2], np.diag([1, 1]), n_events)\nX = np.concatenate([class_0, class_1, class_2])\ny = np.ones(X.shape[0])\nw = RNG.randint(1, 10, n_events * 3)\ny[:class_0.shape[0]] *= 0\ny[-class_2.shape[0]:] *= 2\npermute = RNG.permutation(y.shape[0])\nX = X[permute]\ny = y[permute]\n\n# Split into training and test datasets\nX_train, y_train, w_train = X[:n_events], y[:n_events], w[:n_events]\nX_test, y_test, w_test = X[n_events:], y[n_events:], w[n_events:]\n\noutput = TFile(\'tmva_output.root\', \'recreate\')\nfactory = TMVA.Factory(\'classifier\', output,\n                       \'AnalysisType=Multiclass:\'\n                       \'!V:Silent:!DrawProgressBar\')\n\nif ROOT_VERSION >= \'6.07/04\':\n    data = TMVA.DataLoader(\'.\')\nelse:\n    data = factory\nfor n in range(2):\n    data.AddVariable(\'f{0}\'.format(n), \'F\')\n\n# Call root_numpy\'s utility functions to add events from the arrays\nadd_classification_events(data, X_train, y_train, weights=w_train)\nadd_classification_events(data, X_test, y_test, weights=w_test, test=True)\n# The following line is necessary if events have been added individually:\ndata.PrepareTrainingAndTestTree(TCut(\'1\'), \'NormMode=EqualNumEvents\')\n\n# Train an MLP\nif ROOT_VERSION >= \'6.07/04\':\n    BookMethod = factory.BookMethod\nelse:\n    BookMethod = TMVA.Factory.BookMethod\nBookMethod(data, \'MLP\', \'MLP\',\n           \'NeuronType=tanh:NCycles=200:HiddenLayers=N+2,2:\'\n           \'TestRate=5:EstimatorType=MSE\')\nfactory.TrainAllMethods()\n\n# Classify the test dataset with the BDT\nreader = TMVA.Reader()\nfor n in range(2):\n    reader.AddVariable(\'f{0}\'.format(n), array(\'f\', [0.]))\nreader.BookMVA(\'MLP\', \'weights/classifier_MLP.weights.xml\')\nclass_proba = evaluate_reader(reader, \'MLP\', X_test)\n\n# Plot the decision boundaries\nplot_colors = ""rgb""\nplot_step = 0.02\nclass_names = ""ABC""\ncmap = plt.get_cmap(\'Paired\')\n\nfig = plt.figure(figsize=(5, 5))\nfig.patch.set_alpha(0)\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n                     np.arange(y_min, y_max, plot_step))\n\nZ = evaluate_reader(reader, \'MLP\', np.c_[xx.ravel(), yy.ravel()])\nZ = np.argmax(Z, axis=1) - 1\nZ = Z.reshape(xx.shape)\nplt.contourf(xx, yy, Z, cmap=cmap, alpha=0.5)\nplt.axis(""tight"")\n\n# Plot the training points\nfor i, n, c in zip(range(3), class_names, plot_colors):\n    idx = np.where(y == i)\n    plt.scatter(X[idx, 0], X[idx, 1],\n                c=c, cmap=cmap,\n                label=""Class %s"" % n)\nplt.xlim(x_min, x_max)\nplt.ylim(y_min, y_max)\nplt.legend(loc=\'upper right\')\nplt.xlabel(\'x\')\nplt.ylabel(\'y\')\nplt.title(\'Decision Boundary\')\n\nplt.tight_layout()\nplt.show()\n'"
examples/tmva/plot_regression.py,4,"b'""""""\n==============================\nRegression with NumPy and TMVA\n==============================\n""""""\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom root_numpy.tmva import add_regression_events, evaluate_reader\nfrom root_numpy import ROOT_VERSION\nfrom ROOT import TMVA, TFile, TCut\nfrom array import array\n\nplt.style.use(\'ggplot\')\nRNG = np.random.RandomState(1)\n\n# Create an example regression dataset\nX = np.linspace(0, 6, 100)[:, np.newaxis]\ny = np.sin(X).ravel() + \\\n    np.sin(6 * X).ravel() + \\\n    RNG.normal(0, 0.1, X.shape[0])\n\n# Fit a regression model\noutput = TFile(\'tmva_output.root\', \'recreate\')\nfactory = TMVA.Factory(\'regressor\', output,\n                       \'AnalysisType=Regression:\'\n                       \'!V:Silent:!DrawProgressBar\')\n\nif ROOT_VERSION >= \'6.07/04\':\n    data = TMVA.DataLoader(\'.\')\nelse:\n    data = factory\ndata.AddVariable(\'x\', \'F\')\ndata.AddTarget(\'y\', \'F\')\n\nadd_regression_events(data, X, y)\nadd_regression_events(data, X, y, test=True)\n# The following line is necessary if events have been added individually:\ndata.PrepareTrainingAndTestTree(TCut(\'1\'), \'\')\n\nif ROOT_VERSION >= \'6.07/04\':\n    BookMethod = factory.BookMethod\nelse:\n    BookMethod = TMVA.Factory.BookMethod\nBookMethod(data, \'BDT\', \'BDT1\',\n           \'nCuts=20:NTrees=1:MaxDepth=4:BoostType=AdaBoostR2:\'\n           \'SeparationType=RegressionVariance\')\nBookMethod(data, \'BDT\', \'BDT2\',\n           \'nCuts=20:NTrees=300:MaxDepth=4:BoostType=AdaBoostR2:\'\n           \'SeparationType=RegressionVariance\')\nfactory.TrainAllMethods()\n\n# Predict the regression target\nreader = TMVA.Reader()\nreader.AddVariable(\'x\', array(\'f\', [0.]))\nreader.BookMVA(\'BDT1\', \'weights/regressor_BDT1.weights.xml\')\nreader.BookMVA(\'BDT2\', \'weights/regressor_BDT2.weights.xml\')\ny_1 = evaluate_reader(reader, \'BDT1\', X)\ny_2 = evaluate_reader(reader, \'BDT2\', X)\n\n# Plot the results\nfig = plt.figure()\nfig.patch.set_alpha(0)\nplt.scatter(X, y, c=""k"", label=""training samples"")\nplt.plot(X, y_1, c=""g"", label=""1 tree"", linewidth=2)\nplt.plot(X, y_2, c=""r"", label=""300 trees"", linewidth=2)\nplt.xlabel(""data"")\nplt.ylabel(""target"")\nplt.title(""Boosted Decision Tree Regression"")\nplt.legend()\nplt.show()\n'"
examples/tmva/plot_twoclass.py,9,"b'""""""\n=========================================\nBinary Classification with NumPy and TMVA\n=========================================\n""""""\nfrom array import array\nimport numpy as np\nfrom numpy.random import RandomState\nimport matplotlib.pyplot as plt\nfrom root_numpy.tmva import add_classification_events, evaluate_reader\nfrom root_numpy import ROOT_VERSION\nfrom ROOT import TMVA, TFile, TCut\n\nplt.style.use(\'ggplot\')\nRNG = RandomState(42)\n\n# Construct an example dataset for binary classification\nn_vars = 2\nn_events = 1000\nsignal = RNG.multivariate_normal(\n    np.ones(n_vars), np.diag(np.ones(n_vars)), n_events)\nbackground = RNG.multivariate_normal(\n    np.ones(n_vars) * -1, np.diag(np.ones(n_vars)), n_events)\nX = np.concatenate([signal, background])\ny = np.ones(X.shape[0])\nw = RNG.randint(1, 10, n_events * 2)\ny[signal.shape[0]:] *= -1\npermute = RNG.permutation(y.shape[0])\nX = X[permute]\ny = y[permute]\n\n# Split into training and test datasets\nX_train, y_train, w_train = X[:n_events], y[:n_events], w[:n_events]\nX_test, y_test, w_test = X[n_events:], y[n_events:], w[n_events:]\n\noutput = TFile(\'tmva_output.root\', \'recreate\')\nfactory = TMVA.Factory(\'classifier\', output,\n                       \'AnalysisType=Classification:\'\n                       \'!V:Silent:!DrawProgressBar\')\nif ROOT_VERSION >= \'6.07/04\':\n    data = TMVA.DataLoader(\'.\')\nelse:\n    data = factory\nfor n in range(n_vars):\n    data.AddVariable(\'f{0}\'.format(n), \'F\')\n\n# Call root_numpy\'s utility functions to add events from the arrays\nadd_classification_events(data, X_train, y_train, weights=w_train)\nadd_classification_events(data, X_test, y_test, weights=w_test, test=True)\n# The following line is necessary if events have been added individually:\ndata.PrepareTrainingAndTestTree(TCut(\'1\'), \'NormMode=EqualNumEvents\')\n\n# Train a classifier\nif ROOT_VERSION >= \'6.07/04\':\n    BookMethod = factory.BookMethod\nelse:\n    BookMethod = TMVA.Factory.BookMethod\nBookMethod(data, \'Fisher\', \'Fisher\',\n           \'Fisher:VarTransform=None:CreateMVAPdfs:\'\n           \'PDFInterpolMVAPdf=Spline2:NbinsMVAPdf=50:\'\n           \'NsmoothMVAPdf=10\')\nfactory.TrainAllMethods()\n\n# Classify the test dataset with the classifier\nreader = TMVA.Reader()\nfor n in range(n_vars):\n    reader.AddVariable(\'f{0}\'.format(n), array(\'f\', [0.]))\nreader.BookMVA(\'Fisher\', \'weights/classifier_Fisher.weights.xml\')\ntwoclass_output = evaluate_reader(reader, \'Fisher\', X_test)\n\nplot_colors = ""br""\nplot_step = 0.02\nclass_names = ""AB""\ncmap = plt.get_cmap(\'bwr\')\n\nfig = plt.figure(figsize=(10, 5))\nfig.patch.set_alpha(0)\n\n# Plot the decision boundaries\nplt.subplot(121)\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n                     np.arange(y_min, y_max, plot_step))\n\nZ = evaluate_reader(reader, \'Fisher\', np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\nplt.contourf(xx, yy, Z, cmap=cmap, vmin=Z.min(), vmax=Z.max(),\n             levels=np.linspace(Z.min(), Z.max(), 50))\nplt.contour(xx, yy, Z, levels=[0], linestyles=\'dashed\')\nplt.axis(""tight"")\n\n# Plot the training points\nfor i, n, c in zip([-1, 1], class_names, plot_colors):\n    idx = np.where(y == i)\n    plt.scatter(X[idx, 0], X[idx, 1],\n                c=c, cmap=cmap,\n                label=""Class %s"" % n)\nplt.xlim(x_min, x_max)\nplt.ylim(y_min, y_max)\nplt.legend(loc=\'upper right\')\nplt.xlabel(\'x\')\nplt.ylabel(\'y\')\nplt.title(\'Decision Boundary\')\n\n# Plot the two-class decision scores\nax = plt.subplot(122)\nax.xaxis.grid(False)\nfor i, n, c in zip([-1, 1], class_names, plot_colors):\n    plt.hist(twoclass_output[y_test == i],\n             bins=20,\n             range=(-4, 4),\n             facecolor=c,\n             label=\'Class %s\' % n,\n             alpha=.5, histtype=\'stepfilled\')\nx1, x2, y1, y2 = plt.axis()\nplt.axis((x1, x2, y1, 140))\nplt.legend(loc=\'upper right\')\nplt.ylabel(\'Samples\')\nplt.xlabel(\'Score\')\nplt.title(\'Decision Scores\')\n\nplt.tight_layout()\nplt.subplots_adjust(wspace=0.25)\nplt.show()\n'"
root_numpy/extern/__init__.py,0,b''
root_numpy/extern/ordereddict.py,0,"b'# Copyright (c) 2009 Raymond Hettinger\r\n#\r\n# Permission is hereby granted, free of charge, to any person\r\n# obtaining a copy of this software and associated documentation files\r\n# (the ""Software""), to deal in the Software without restriction,\r\n# including without limitation the rights to use, copy, modify, merge,\r\n# publish, distribute, sublicense, and/or sell copies of the Software,\r\n# and to permit persons to whom the Software is furnished to do so,\r\n# subject to the following conditions:\r\n#\r\n#     The above copyright notice and this permission notice shall be\r\n#     included in all copies or substantial portions of the Software.\r\n#\r\n#     THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,\r\n#     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\r\n#     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n#     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\r\n#     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\r\n#     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\r\n#     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\r\n#     OTHER DEALINGS IN THE SOFTWARE.\r\n\r\nfrom UserDict import DictMixin\r\n\r\nclass OrderedDict(dict, DictMixin):\r\n\r\n    def __init__(self, *args, **kwds):\r\n        if len(args) > 1:\r\n            raise TypeError(\'expected at most 1 arguments, got %d\' % len(args))\r\n        try:\r\n            self.__end\r\n        except AttributeError:\r\n            self.clear()\r\n        self.update(*args, **kwds)\r\n\r\n    def clear(self):\r\n        self.__end = end = []\r\n        end += [None, end, end]         # sentinel node for doubly linked list\r\n        self.__map = {}                 # key --> [key, prev, next]\r\n        dict.clear(self)\r\n\r\n    def __setitem__(self, key, value):\r\n        if key not in self:\r\n            end = self.__end\r\n            curr = end[1]\r\n            curr[2] = end[1] = self.__map[key] = [key, curr, end]\r\n        dict.__setitem__(self, key, value)\r\n\r\n    def __delitem__(self, key):\r\n        dict.__delitem__(self, key)\r\n        key, prev, next = self.__map.pop(key)\r\n        prev[2] = next\r\n        next[1] = prev\r\n\r\n    def __iter__(self):\r\n        end = self.__end\r\n        curr = end[2]\r\n        while curr is not end:\r\n            yield curr[0]\r\n            curr = curr[2]\r\n\r\n    def __reversed__(self):\r\n        end = self.__end\r\n        curr = end[1]\r\n        while curr is not end:\r\n            yield curr[0]\r\n            curr = curr[1]\r\n\r\n    def popitem(self, last=True):\r\n        if not self:\r\n            raise KeyError(\'dictionary is empty\')\r\n        if last:\r\n            key = reversed(self).next()\r\n        else:\r\n            key = iter(self).next()\r\n        value = self.pop(key)\r\n        return key, value\r\n\r\n    def __reduce__(self):\r\n        items = [[k, self[k]] for k in self]\r\n        tmp = self.__map, self.__end\r\n        del self.__map, self.__end\r\n        inst_dict = vars(self).copy()\r\n        self.__map, self.__end = tmp\r\n        if inst_dict:\r\n            return (self.__class__, (items,), inst_dict)\r\n        return self.__class__, (items,)\r\n\r\n    def keys(self):\r\n        return list(self)\r\n\r\n    setdefault = DictMixin.setdefault\r\n    update = DictMixin.update\r\n    pop = DictMixin.pop\r\n    values = DictMixin.values\r\n    items = DictMixin.items\r\n    iterkeys = DictMixin.iterkeys\r\n    itervalues = DictMixin.itervalues\r\n    iteritems = DictMixin.iteritems\r\n\r\n    def __repr__(self):\r\n        if not self:\r\n            return \'%s()\' % (self.__class__.__name__,)\r\n        return \'%s(%r)\' % (self.__class__.__name__, self.items())\r\n\r\n    def copy(self):\r\n        return self.__class__(self)\r\n\r\n    @classmethod\r\n    def fromkeys(cls, iterable, value=None):\r\n        d = cls()\r\n        for key in iterable:\r\n            d[key] = value\r\n        return d\r\n\r\n    def __eq__(self, other):\r\n        if isinstance(other, OrderedDict):\r\n            if len(self) != len(other):\r\n                return False\r\n            for p, q in  zip(self.items(), other.items()):\r\n                if p != q:\r\n                    return False\r\n            return True\r\n        return dict.__eq__(self, other)\r\n\r\n    def __ne__(self, other):\r\n        return not self == other\r\n'"
root_numpy/extern/six.py,0,"b'""""""Utilities for writing code that runs on Python 2 and 3""""""\n\n# Copyright (c) 2010-2015 Benjamin Peterson\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the ""Software""), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nfrom __future__ import absolute_import\n\nimport functools\nimport itertools\nimport operator\nimport sys\nimport types\n\n__author__ = ""Benjamin Peterson <benjamin@python.org>""\n__version__ = ""1.9.0""\n\n\n# Useful for very coarse version differentiation.\nPY2 = sys.version_info[0] == 2\nPY3 = sys.version_info[0] == 3\n\nif PY3:\n    string_types = str,\n    integer_types = int,\n    class_types = type,\n    text_type = str\n    binary_type = bytes\n\n    MAXSIZE = sys.maxsize\nelse:\n    string_types = basestring,\n    integer_types = (int, long)\n    class_types = (type, types.ClassType)\n    text_type = unicode\n    binary_type = str\n\n    if sys.platform.startswith(""java""):\n        # Jython always uses 32 bits.\n        MAXSIZE = int((1 << 31) - 1)\n    else:\n        # It\'s possible to have sizeof(long) != sizeof(Py_ssize_t).\n        class X(object):\n            def __len__(self):\n                return 1 << 31\n        try:\n            len(X())\n        except OverflowError:\n            # 32-bit\n            MAXSIZE = int((1 << 31) - 1)\n        else:\n            # 64-bit\n            MAXSIZE = int((1 << 63) - 1)\n        del X\n\n\ndef _add_doc(func, doc):\n    """"""Add documentation to a function.""""""\n    func.__doc__ = doc\n\n\ndef _import_module(name):\n    """"""Import module, returning the module after the last dot.""""""\n    __import__(name)\n    return sys.modules[name]\n\n\nclass _LazyDescr(object):\n\n    def __init__(self, name):\n        self.name = name\n\n    def __get__(self, obj, tp):\n        result = self._resolve()\n        setattr(obj, self.name, result) # Invokes __set__.\n        try:\n            # This is a bit ugly, but it avoids running this again by\n            # removing this descriptor.\n            delattr(obj.__class__, self.name)\n        except AttributeError:\n            pass\n        return result\n\n\nclass MovedModule(_LazyDescr):\n\n    def __init__(self, name, old, new=None):\n        super(MovedModule, self).__init__(name)\n        if PY3:\n            if new is None:\n                new = name\n            self.mod = new\n        else:\n            self.mod = old\n\n    def _resolve(self):\n        return _import_module(self.mod)\n\n    def __getattr__(self, attr):\n        _module = self._resolve()\n        value = getattr(_module, attr)\n        setattr(self, attr, value)\n        return value\n\n\nclass _LazyModule(types.ModuleType):\n\n    def __init__(self, name):\n        super(_LazyModule, self).__init__(name)\n        self.__doc__ = self.__class__.__doc__\n\n    def __dir__(self):\n        attrs = [""__doc__"", ""__name__""]\n        attrs += [attr.name for attr in self._moved_attributes]\n        return attrs\n\n    # Subclasses should override this\n    _moved_attributes = []\n\n\nclass MovedAttribute(_LazyDescr):\n\n    def __init__(self, name, old_mod, new_mod, old_attr=None, new_attr=None):\n        super(MovedAttribute, self).__init__(name)\n        if PY3:\n            if new_mod is None:\n                new_mod = name\n            self.mod = new_mod\n            if new_attr is None:\n                if old_attr is None:\n                    new_attr = name\n                else:\n                    new_attr = old_attr\n            self.attr = new_attr\n        else:\n            self.mod = old_mod\n            if old_attr is None:\n                old_attr = name\n            self.attr = old_attr\n\n    def _resolve(self):\n        module = _import_module(self.mod)\n        return getattr(module, self.attr)\n\n\nclass _SixMetaPathImporter(object):\n    """"""\n    A meta path importer to import six.moves and its submodules.\n\n    This class implements a PEP302 finder and loader. It should be compatible\n    with Python 2.5 and all existing versions of Python3\n    """"""\n    def __init__(self, six_module_name):\n        self.name = six_module_name\n        self.known_modules = {}\n\n    def _add_module(self, mod, *fullnames):\n        for fullname in fullnames:\n            self.known_modules[self.name + ""."" + fullname] = mod\n\n    def _get_module(self, fullname):\n        return self.known_modules[self.name + ""."" + fullname]\n\n    def find_module(self, fullname, path=None):\n        if fullname in self.known_modules:\n            return self\n        return None\n\n    def __get_module(self, fullname):\n        try:\n            return self.known_modules[fullname]\n        except KeyError:\n            raise ImportError(""This loader does not know module "" + fullname)\n\n    def load_module(self, fullname):\n        try:\n            # in case of a reload\n            return sys.modules[fullname]\n        except KeyError:\n            pass\n        mod = self.__get_module(fullname)\n        if isinstance(mod, MovedModule):\n            mod = mod._resolve()\n        else:\n            mod.__loader__ = self\n        sys.modules[fullname] = mod\n        return mod\n\n    def is_package(self, fullname):\n        """"""\n        Return true, if the named module is a package.\n\n        We need this method to get correct spec objects with\n        Python 3.4 (see PEP451)\n        """"""\n        return hasattr(self.__get_module(fullname), ""__path__"")\n\n    def get_code(self, fullname):\n        """"""Return None\n\n        Required, if is_package is implemented""""""\n        self.__get_module(fullname)  # eventually raises ImportError\n        return None\n    get_source = get_code  # same as get_code\n\n_importer = _SixMetaPathImporter(__name__)\n\n\nclass _MovedItems(_LazyModule):\n    """"""Lazy loading of moved objects""""""\n    __path__ = []  # mark as package\n\n\n_moved_attributes = [\n    MovedAttribute(""cStringIO"", ""cStringIO"", ""io"", ""StringIO""),\n    MovedAttribute(""filter"", ""itertools"", ""builtins"", ""ifilter"", ""filter""),\n    MovedAttribute(""filterfalse"", ""itertools"", ""itertools"", ""ifilterfalse"", ""filterfalse""),\n    MovedAttribute(""input"", ""__builtin__"", ""builtins"", ""raw_input"", ""input""),\n    MovedAttribute(""intern"", ""__builtin__"", ""sys""),\n    MovedAttribute(""map"", ""itertools"", ""builtins"", ""imap"", ""map""),\n    MovedAttribute(""range"", ""__builtin__"", ""builtins"", ""xrange"", ""range""),\n    MovedAttribute(""reload_module"", ""__builtin__"", ""imp"", ""reload""),\n    MovedAttribute(""reduce"", ""__builtin__"", ""functools""),\n    MovedAttribute(""shlex_quote"", ""pipes"", ""shlex"", ""quote""),\n    MovedAttribute(""StringIO"", ""StringIO"", ""io""),\n    MovedAttribute(""UserDict"", ""UserDict"", ""collections""),\n    MovedAttribute(""UserList"", ""UserList"", ""collections""),\n    MovedAttribute(""UserString"", ""UserString"", ""collections""),\n    MovedAttribute(""xrange"", ""__builtin__"", ""builtins"", ""xrange"", ""range""),\n    MovedAttribute(""zip"", ""itertools"", ""builtins"", ""izip"", ""zip""),\n    MovedAttribute(""zip_longest"", ""itertools"", ""itertools"", ""izip_longest"", ""zip_longest""),\n\n    MovedModule(""builtins"", ""__builtin__""),\n    MovedModule(""configparser"", ""ConfigParser""),\n    MovedModule(""copyreg"", ""copy_reg""),\n    MovedModule(""dbm_gnu"", ""gdbm"", ""dbm.gnu""),\n    MovedModule(""_dummy_thread"", ""dummy_thread"", ""_dummy_thread""),\n    MovedModule(""http_cookiejar"", ""cookielib"", ""http.cookiejar""),\n    MovedModule(""http_cookies"", ""Cookie"", ""http.cookies""),\n    MovedModule(""html_entities"", ""htmlentitydefs"", ""html.entities""),\n    MovedModule(""html_parser"", ""HTMLParser"", ""html.parser""),\n    MovedModule(""http_client"", ""httplib"", ""http.client""),\n    MovedModule(""email_mime_multipart"", ""email.MIMEMultipart"", ""email.mime.multipart""),\n    MovedModule(""email_mime_nonmultipart"", ""email.MIMENonMultipart"", ""email.mime.nonmultipart""),\n    MovedModule(""email_mime_text"", ""email.MIMEText"", ""email.mime.text""),\n    MovedModule(""email_mime_base"", ""email.MIMEBase"", ""email.mime.base""),\n    MovedModule(""BaseHTTPServer"", ""BaseHTTPServer"", ""http.server""),\n    MovedModule(""CGIHTTPServer"", ""CGIHTTPServer"", ""http.server""),\n    MovedModule(""SimpleHTTPServer"", ""SimpleHTTPServer"", ""http.server""),\n    MovedModule(""cPickle"", ""cPickle"", ""pickle""),\n    MovedModule(""queue"", ""Queue""),\n    MovedModule(""reprlib"", ""repr""),\n    MovedModule(""socketserver"", ""SocketServer""),\n    MovedModule(""_thread"", ""thread"", ""_thread""),\n    MovedModule(""tkinter"", ""Tkinter""),\n    MovedModule(""tkinter_dialog"", ""Dialog"", ""tkinter.dialog""),\n    MovedModule(""tkinter_filedialog"", ""FileDialog"", ""tkinter.filedialog""),\n    MovedModule(""tkinter_scrolledtext"", ""ScrolledText"", ""tkinter.scrolledtext""),\n    MovedModule(""tkinter_simpledialog"", ""SimpleDialog"", ""tkinter.simpledialog""),\n    MovedModule(""tkinter_tix"", ""Tix"", ""tkinter.tix""),\n    MovedModule(""tkinter_ttk"", ""ttk"", ""tkinter.ttk""),\n    MovedModule(""tkinter_constants"", ""Tkconstants"", ""tkinter.constants""),\n    MovedModule(""tkinter_dnd"", ""Tkdnd"", ""tkinter.dnd""),\n    MovedModule(""tkinter_colorchooser"", ""tkColorChooser"",\n                ""tkinter.colorchooser""),\n    MovedModule(""tkinter_commondialog"", ""tkCommonDialog"",\n                ""tkinter.commondialog""),\n    MovedModule(""tkinter_tkfiledialog"", ""tkFileDialog"", ""tkinter.filedialog""),\n    MovedModule(""tkinter_font"", ""tkFont"", ""tkinter.font""),\n    MovedModule(""tkinter_messagebox"", ""tkMessageBox"", ""tkinter.messagebox""),\n    MovedModule(""tkinter_tksimpledialog"", ""tkSimpleDialog"",\n                ""tkinter.simpledialog""),\n    MovedModule(""urllib_parse"", __name__ + "".moves.urllib_parse"", ""urllib.parse""),\n    MovedModule(""urllib_error"", __name__ + "".moves.urllib_error"", ""urllib.error""),\n    MovedModule(""urllib"", __name__ + "".moves.urllib"", __name__ + "".moves.urllib""),\n    MovedModule(""urllib_robotparser"", ""robotparser"", ""urllib.robotparser""),\n    MovedModule(""xmlrpc_client"", ""xmlrpclib"", ""xmlrpc.client""),\n    MovedModule(""xmlrpc_server"", ""SimpleXMLRPCServer"", ""xmlrpc.server""),\n    MovedModule(""winreg"", ""_winreg""),\n]\nfor attr in _moved_attributes:\n    setattr(_MovedItems, attr.name, attr)\n    if isinstance(attr, MovedModule):\n        _importer._add_module(attr, ""moves."" + attr.name)\ndel attr\n\n_MovedItems._moved_attributes = _moved_attributes\n\nmoves = _MovedItems(__name__ + "".moves"")\n_importer._add_module(moves, ""moves"")\n\n\nclass Module_six_moves_urllib_parse(_LazyModule):\n    """"""Lazy loading of moved objects in six.moves.urllib_parse""""""\n\n\n_urllib_parse_moved_attributes = [\n    MovedAttribute(""ParseResult"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""SplitResult"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""parse_qs"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""parse_qsl"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""urldefrag"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""urljoin"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""urlparse"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""urlsplit"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""urlunparse"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""urlunsplit"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""quote"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""quote_plus"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""unquote"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""unquote_plus"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""urlencode"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""splitquery"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""splittag"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""splituser"", ""urllib"", ""urllib.parse""),\n    MovedAttribute(""uses_fragment"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""uses_netloc"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""uses_params"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""uses_query"", ""urlparse"", ""urllib.parse""),\n    MovedAttribute(""uses_relative"", ""urlparse"", ""urllib.parse""),\n]\nfor attr in _urllib_parse_moved_attributes:\n    setattr(Module_six_moves_urllib_parse, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_parse._moved_attributes = _urllib_parse_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_parse(__name__ + "".moves.urllib_parse""),\n                      ""moves.urllib_parse"", ""moves.urllib.parse"")\n\n\nclass Module_six_moves_urllib_error(_LazyModule):\n    """"""Lazy loading of moved objects in six.moves.urllib_error""""""\n\n\n_urllib_error_moved_attributes = [\n    MovedAttribute(""URLError"", ""urllib2"", ""urllib.error""),\n    MovedAttribute(""HTTPError"", ""urllib2"", ""urllib.error""),\n    MovedAttribute(""ContentTooShortError"", ""urllib"", ""urllib.error""),\n]\nfor attr in _urllib_error_moved_attributes:\n    setattr(Module_six_moves_urllib_error, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_error(__name__ + "".moves.urllib.error""),\n                      ""moves.urllib_error"", ""moves.urllib.error"")\n\n\nclass Module_six_moves_urllib_request(_LazyModule):\n    """"""Lazy loading of moved objects in six.moves.urllib_request""""""\n\n\n_urllib_request_moved_attributes = [\n    MovedAttribute(""urlopen"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""install_opener"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""build_opener"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""pathname2url"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""url2pathname"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""getproxies"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""Request"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""OpenerDirector"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPDefaultErrorHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPRedirectHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPCookieProcessor"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""ProxyHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""BaseHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPPasswordMgr"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPPasswordMgrWithDefaultRealm"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""AbstractBasicAuthHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPBasicAuthHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""ProxyBasicAuthHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""AbstractDigestAuthHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPDigestAuthHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""ProxyDigestAuthHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPSHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""FileHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""FTPHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""CacheFTPHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""UnknownHandler"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""HTTPErrorProcessor"", ""urllib2"", ""urllib.request""),\n    MovedAttribute(""urlretrieve"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""urlcleanup"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""URLopener"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""FancyURLopener"", ""urllib"", ""urllib.request""),\n    MovedAttribute(""proxy_bypass"", ""urllib"", ""urllib.request""),\n]\nfor attr in _urllib_request_moved_attributes:\n    setattr(Module_six_moves_urllib_request, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_request._moved_attributes = _urllib_request_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_request(__name__ + "".moves.urllib.request""),\n                      ""moves.urllib_request"", ""moves.urllib.request"")\n\n\nclass Module_six_moves_urllib_response(_LazyModule):\n    """"""Lazy loading of moved objects in six.moves.urllib_response""""""\n\n\n_urllib_response_moved_attributes = [\n    MovedAttribute(""addbase"", ""urllib"", ""urllib.response""),\n    MovedAttribute(""addclosehook"", ""urllib"", ""urllib.response""),\n    MovedAttribute(""addinfo"", ""urllib"", ""urllib.response""),\n    MovedAttribute(""addinfourl"", ""urllib"", ""urllib.response""),\n]\nfor attr in _urllib_response_moved_attributes:\n    setattr(Module_six_moves_urllib_response, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_response(__name__ + "".moves.urllib.response""),\n                      ""moves.urllib_response"", ""moves.urllib.response"")\n\n\nclass Module_six_moves_urllib_robotparser(_LazyModule):\n    """"""Lazy loading of moved objects in six.moves.urllib_robotparser""""""\n\n\n_urllib_robotparser_moved_attributes = [\n    MovedAttribute(""RobotFileParser"", ""robotparser"", ""urllib.robotparser""),\n]\nfor attr in _urllib_robotparser_moved_attributes:\n    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + "".moves.urllib.robotparser""),\n                      ""moves.urllib_robotparser"", ""moves.urllib.robotparser"")\n\n\nclass Module_six_moves_urllib(types.ModuleType):\n    """"""Create a six.moves.urllib namespace that resembles the Python 3 namespace""""""\n    __path__ = []  # mark as package\n    parse = _importer._get_module(""moves.urllib_parse"")\n    error = _importer._get_module(""moves.urllib_error"")\n    request = _importer._get_module(""moves.urllib_request"")\n    response = _importer._get_module(""moves.urllib_response"")\n    robotparser = _importer._get_module(""moves.urllib_robotparser"")\n\n    def __dir__(self):\n        return [\'parse\', \'error\', \'request\', \'response\', \'robotparser\']\n\n_importer._add_module(Module_six_moves_urllib(__name__ + "".moves.urllib""),\n                      ""moves.urllib"")\n\n\ndef add_move(move):\n    """"""Add an item to six.moves.""""""\n    setattr(_MovedItems, move.name, move)\n\n\ndef remove_move(name):\n    """"""Remove item from six.moves.""""""\n    try:\n        delattr(_MovedItems, name)\n    except AttributeError:\n        try:\n            del moves.__dict__[name]\n        except KeyError:\n            raise AttributeError(""no such move, %r"" % (name,))\n\n\nif PY3:\n    _meth_func = ""__func__""\n    _meth_self = ""__self__""\n\n    _func_closure = ""__closure__""\n    _func_code = ""__code__""\n    _func_defaults = ""__defaults__""\n    _func_globals = ""__globals__""\nelse:\n    _meth_func = ""im_func""\n    _meth_self = ""im_self""\n\n    _func_closure = ""func_closure""\n    _func_code = ""func_code""\n    _func_defaults = ""func_defaults""\n    _func_globals = ""func_globals""\n\n\ntry:\n    advance_iterator = next\nexcept NameError:\n    def advance_iterator(it):\n        return it.next()\nnext = advance_iterator\n\n\ntry:\n    callable = callable\nexcept NameError:\n    def callable(obj):\n        return any(""__call__"" in klass.__dict__ for klass in type(obj).__mro__)\n\n\nif PY3:\n    def get_unbound_function(unbound):\n        return unbound\n\n    create_bound_method = types.MethodType\n\n    Iterator = object\nelse:\n    def get_unbound_function(unbound):\n        return unbound.im_func\n\n    def create_bound_method(func, obj):\n        return types.MethodType(func, obj, obj.__class__)\n\n    class Iterator(object):\n\n        def next(self):\n            return type(self).__next__(self)\n\n    callable = callable\n_add_doc(get_unbound_function,\n         """"""Get the function out of a possibly unbound function"""""")\n\n\nget_method_function = operator.attrgetter(_meth_func)\nget_method_self = operator.attrgetter(_meth_self)\nget_function_closure = operator.attrgetter(_func_closure)\nget_function_code = operator.attrgetter(_func_code)\nget_function_defaults = operator.attrgetter(_func_defaults)\nget_function_globals = operator.attrgetter(_func_globals)\n\n\nif PY3:\n    def iterkeys(d, **kw):\n        return iter(d.keys(**kw))\n\n    def itervalues(d, **kw):\n        return iter(d.values(**kw))\n\n    def iteritems(d, **kw):\n        return iter(d.items(**kw))\n\n    def iterlists(d, **kw):\n        return iter(d.lists(**kw))\n\n    viewkeys = operator.methodcaller(""keys"")\n\n    viewvalues = operator.methodcaller(""values"")\n\n    viewitems = operator.methodcaller(""items"")\nelse:\n    def iterkeys(d, **kw):\n        return iter(d.iterkeys(**kw))\n\n    def itervalues(d, **kw):\n        return iter(d.itervalues(**kw))\n\n    def iteritems(d, **kw):\n        return iter(d.iteritems(**kw))\n\n    def iterlists(d, **kw):\n        return iter(d.iterlists(**kw))\n\n    viewkeys = operator.methodcaller(""viewkeys"")\n\n    viewvalues = operator.methodcaller(""viewvalues"")\n\n    viewitems = operator.methodcaller(""viewitems"")\n\n_add_doc(iterkeys, ""Return an iterator over the keys of a dictionary."")\n_add_doc(itervalues, ""Return an iterator over the values of a dictionary."")\n_add_doc(iteritems,\n         ""Return an iterator over the (key, value) pairs of a dictionary."")\n_add_doc(iterlists,\n         ""Return an iterator over the (key, [values]) pairs of a dictionary."")\n\n\nif PY3:\n    def b(s):\n        return s.encode(""latin-1"")\n    def u(s):\n        return s\n    unichr = chr\n    if sys.version_info[1] <= 1:\n        def int2byte(i):\n            return bytes((i,))\n    else:\n        # This is about 2x faster than the implementation above on 3.2+\n        int2byte = operator.methodcaller(""to_bytes"", 1, ""big"")\n    byte2int = operator.itemgetter(0)\n    indexbytes = operator.getitem\n    iterbytes = iter\n    import io\n    StringIO = io.StringIO\n    BytesIO = io.BytesIO\n    _assertCountEqual = ""assertCountEqual""\n    _assertRaisesRegex = ""assertRaisesRegex""\n    _assertRegex = ""assertRegex""\nelse:\n    def b(s):\n        return s\n    # Workaround for standalone backslash\n    def u(s):\n        return unicode(s.replace(r\'\\\\\', r\'\\\\\\\\\'), ""unicode_escape"")\n    unichr = unichr\n    int2byte = chr\n    def byte2int(bs):\n        return ord(bs[0])\n    def indexbytes(buf, i):\n        return ord(buf[i])\n    iterbytes = functools.partial(itertools.imap, ord)\n    import StringIO\n    StringIO = BytesIO = StringIO.StringIO\n    _assertCountEqual = ""assertItemsEqual""\n    _assertRaisesRegex = ""assertRaisesRegexp""\n    _assertRegex = ""assertRegexpMatches""\n_add_doc(b, """"""Byte literal"""""")\n_add_doc(u, """"""Text literal"""""")\n\n\ndef assertCountEqual(self, *args, **kwargs):\n    return getattr(self, _assertCountEqual)(*args, **kwargs)\n\n\ndef assertRaisesRegex(self, *args, **kwargs):\n    return getattr(self, _assertRaisesRegex)(*args, **kwargs)\n\n\ndef assertRegex(self, *args, **kwargs):\n    return getattr(self, _assertRegex)(*args, **kwargs)\n\n\nif PY3:\n    exec_ = getattr(moves.builtins, ""exec"")\n\n\n    def reraise(tp, value, tb=None):\n        if value is None:\n            value = tp()\n        if value.__traceback__ is not tb:\n            raise value.with_traceback(tb)\n        raise value\n\nelse:\n    def exec_(_code_, _globs_=None, _locs_=None):\n        """"""Execute code in a namespace.""""""\n        if _globs_ is None:\n            frame = sys._getframe(1)\n            _globs_ = frame.f_globals\n            if _locs_ is None:\n                _locs_ = frame.f_locals\n            del frame\n        elif _locs_ is None:\n            _locs_ = _globs_\n        exec(""""""exec _code_ in _globs_, _locs_"""""")\n\n\n    exec_(""""""def reraise(tp, value, tb=None):\n    raise tp, value, tb\n"""""")\n\n\nif sys.version_info[:2] == (3, 2):\n    exec_(""""""def raise_from(value, from_value):\n    if from_value is None:\n        raise value\n    raise value from from_value\n"""""")\nelif sys.version_info[:2] > (3, 2):\n    exec_(""""""def raise_from(value, from_value):\n    raise value from from_value\n"""""")\nelse:\n    def raise_from(value, from_value):\n        raise value\n\n\nprint_ = getattr(moves.builtins, ""print"", None)\nif print_ is None:\n    def print_(*args, **kwargs):\n        """"""The new-style print function for Python 2.4 and 2.5.""""""\n        fp = kwargs.pop(""file"", sys.stdout)\n        if fp is None:\n            return\n        def write(data):\n            if not isinstance(data, basestring):\n                data = str(data)\n            # If the file has an encoding, encode unicode with it.\n            if (isinstance(fp, file) and\n                isinstance(data, unicode) and\n                fp.encoding is not None):\n                errors = getattr(fp, ""errors"", None)\n                if errors is None:\n                    errors = ""strict""\n                data = data.encode(fp.encoding, errors)\n            fp.write(data)\n        want_unicode = False\n        sep = kwargs.pop(""sep"", None)\n        if sep is not None:\n            if isinstance(sep, unicode):\n                want_unicode = True\n            elif not isinstance(sep, str):\n                raise TypeError(""sep must be None or a string"")\n        end = kwargs.pop(""end"", None)\n        if end is not None:\n            if isinstance(end, unicode):\n                want_unicode = True\n            elif not isinstance(end, str):\n                raise TypeError(""end must be None or a string"")\n        if kwargs:\n            raise TypeError(""invalid keyword arguments to print()"")\n        if not want_unicode:\n            for arg in args:\n                if isinstance(arg, unicode):\n                    want_unicode = True\n                    break\n        if want_unicode:\n            newline = unicode(""\\n"")\n            space = unicode("" "")\n        else:\n            newline = ""\\n""\n            space = "" ""\n        if sep is None:\n            sep = space\n        if end is None:\n            end = newline\n        for i, arg in enumerate(args):\n            if i:\n                write(sep)\n            write(arg)\n        write(end)\nif sys.version_info[:2] < (3, 3):\n    _print = print_\n    def print_(*args, **kwargs):\n        fp = kwargs.get(""file"", sys.stdout)\n        flush = kwargs.pop(""flush"", False)\n        _print(*args, **kwargs)\n        if flush and fp is not None:\n            fp.flush()\n\n_add_doc(reraise, """"""Reraise an exception."""""")\n\nif sys.version_info[0:2] < (3, 4):\n    def wraps(wrapped, assigned=functools.WRAPPER_ASSIGNMENTS,\n              updated=functools.WRAPPER_UPDATES):\n        def wrapper(f):\n            f = functools.wraps(wrapped, assigned, updated)(f)\n            f.__wrapped__ = wrapped\n            return f\n        return wrapper\nelse:\n    wraps = functools.wraps\n\ndef with_metaclass(meta, *bases):\n    """"""Create a base class with a metaclass.""""""\n    # This requires a bit of explanation: the basic idea is to make a dummy\n    # metaclass for one level of class instantiation that replaces itself with\n    # the actual metaclass.\n    class metaclass(meta):\n        def __new__(cls, name, this_bases, d):\n            return meta(name, bases, d)\n    return type.__new__(metaclass, \'temporary_class\', (), {})\n\n\ndef add_metaclass(metaclass):\n    """"""Class decorator for creating a class with a metaclass.""""""\n    def wrapper(cls):\n        orig_vars = cls.__dict__.copy()\n        slots = orig_vars.get(\'__slots__\')\n        if slots is not None:\n            if isinstance(slots, str):\n                slots = [slots]\n            for slots_var in slots:\n                orig_vars.pop(slots_var)\n        orig_vars.pop(\'__dict__\', None)\n        orig_vars.pop(\'__weakref__\', None)\n        return metaclass(cls.__name__, cls.__bases__, orig_vars)\n    return wrapper\n\n\ndef python_2_unicode_compatible(klass):\n    """"""\n    A decorator that defines __unicode__ and __str__ methods under Python 2.\n    Under Python 3 it does nothing.\n\n    To support Python 2 and 3 with a single code base, define a __str__ method\n    returning text and apply this decorator to the class.\n    """"""\n    if PY2:\n        if \'__str__\' not in klass.__dict__:\n            raise ValueError(""@python_2_unicode_compatible cannot be applied ""\n                             ""to %s because it doesn\'t define __str__()."" %\n                             klass.__name__)\n        klass.__unicode__ = klass.__str__\n        klass.__str__ = lambda self: self.__unicode__().encode(\'utf-8\')\n    return klass\n\n\n# Complete the moves implementation.\n# This code is at the end of this module to speed up module loading.\n# Turn this module into a package.\n__path__ = []  # required for PEP 302 and PEP 451\n__package__ = __name__  # see PEP 366 @ReservedAssignment\nif globals().get(""__spec__"") is not None:\n    __spec__.submodule_search_locations = []  # PEP 451 @UndefinedVariable\n# Remove other six meta path importers, since they cause problems. This can\n# happen if six is removed from sys.modules and then reloaded. (Setuptools does\n# this for some reason.)\nif sys.meta_path:\n    for i, importer in enumerate(sys.meta_path):\n        # Here\'s some real nastiness: Another ""instance"" of the six module might\n        # be floating around. Therefore, we can\'t use isinstance() to check for\n        # the six meta path importer, since the other six instance will have\n        # inserted an importer with different class.\n        if (type(importer).__name__ == ""_SixMetaPathImporter"" and\n            importer.name == __name__):\n            del sys.meta_path[i]\n            break\n    del i, importer\n# Finally, add the importer to the meta path import hook.\nsys.meta_path.append(_importer)\n'"
root_numpy/testdata/__init__.py,0,"b'import os\nfrom pkg_resources import resource_filename\n\n\n__all__ = [\n    \'get_filepath\',\n    \'get_file\',\n]\n\n\ndef get_filepath(name=\'test.root\'):\n    return resource_filename(\'root_numpy\', os.path.join(\'testdata\', name))\n\n\ndef get_file(name=\'test.root\'):\n    import ROOT\n    filepath = get_filepath(name)\n    if not os.path.isfile(filepath):\n        raise ValueError(\n            ""root_numpy test data file {0} does not exist"".format(filepath))\n    return ROOT.TFile(filepath, \'read\')\n'"
root_numpy/tests/__init__.py,1,"b""import os\nimport sys\nimport warnings\nimport ROOT\nfrom numpy.random import RandomState\nimport tempfile\nfrom contextlib import contextmanager\nimport root_numpy as rnp\nfrom root_numpy.testdata import get_filepath\nimport threading\n\nLOCK = threading.RLock()\n\nROOT.gErrorIgnoreLevel = ROOT.kFatal\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=rnp.RootNumpyUnconvertibleWarning)\nRNG = RandomState(42)\n\n\ndef load(data):\n    if isinstance(data, list):\n        return [get_filepath(x) for x in data]\n    return get_filepath(data)\n\n\n@contextmanager\ndef temp():\n    tmp_fd, tmp_path = tempfile.mkstemp(suffix='.root')\n    tmp_root = ROOT.TFile.Open(tmp_path, 'recreate')\n    try:\n        yield tmp_root\n    finally:\n        tmp_root.Close()\n        os.close(tmp_fd)\n        os.remove(tmp_path)\n\n\n@contextmanager\ndef silence_sout():\n    LOCK.acquire()\n    sys.__stdout__.flush()\n    origstdout = sys.__stdout__\n    oldstdout_fno = os.dup(sys.__stdout__.fileno())\n    devnull = os.open(os.devnull, os.O_WRONLY)\n    newstdout = os.dup(1)\n    os.dup2(devnull, 1)\n    os.close(devnull)\n    sys.__stdout__ = os.fdopen(newstdout, 'w')\n    try:\n        yield\n    finally:\n        sys.__stdout__ = origstdout\n        sys.__stdout__.flush()\n        os.dup2(oldstdout_fno, 1)\n        LOCK.release()\n\n\n@contextmanager\ndef silence_serr():\n    LOCK.acquire()\n    sys.__stderr__.flush()\n    origstderr = sys.__stderr__\n    oldstderr_fno = os.dup(sys.__stderr__.fileno())\n    devnull = os.open(os.devnull, os.O_WRONLY)\n    newstderr = os.dup(2)\n    os.dup2(devnull, 2)\n    os.close(devnull)\n    sys.__stderr__ = os.fdopen(newstderr, 'w')\n    try:\n        yield\n    finally:\n        sys.__stderr__ = origstderr\n        sys.__stderr__.flush()\n        os.dup2(oldstderr_fno, 2)\n        LOCK.release()\n\n\n@contextmanager\ndef silence():\n    with silence_sout():\n        with silence_serr():\n            yield\n"""
root_numpy/tests/test_array.py,6,"b""import ROOT\nimport root_numpy as rnp\nfrom nose.tools import assert_raises, assert_equal\n\n\ndef check_array(cls, copy):\n    a = cls(10)\n    a[2] = 2\n    b = rnp.array(a, copy=copy)\n    assert_equal(b[2], 2)\n    assert_equal(b.shape[0], 10)\n\n\ndef test_array():\n    for copy in (True, False):\n        for cls in (getattr(ROOT, 'TArray{0}'.format(atype))\n                for atype in 'DFLIS'):\n            yield check_array, cls, copy\n        a = ROOT.TArrayC(10)\n        b = rnp.array(a, copy=copy)\n        assert_equal(b.shape[0], 10)\n    assert_raises(TypeError, rnp.array, object)\n\n\ndef check_matrix(cls):\n    mat = cls(5, 5)\n    mat[1][2] = 2\n    np_mat = rnp.matrix(mat)\n    assert_equal(np_mat[1, 2], 2)\n\n\ndef check_matrix_sym(cls):\n    mat = cls(5)\n    mat[2][2] = 2\n    np_mat = rnp.matrix(mat)\n    assert_equal(np_mat[2, 2], 2)\n\n\ndef test_matrix():\n    for cls in (getattr(ROOT, 'TMatrix{0}'.format(atype)) for atype in 'DF'):\n        yield check_matrix, cls\n\n    for cls in (getattr(ROOT, 'TMatrix{0}Sym'.format(atype)) for atype in 'DF'):\n        yield check_matrix_sym, cls\n\n    assert_raises(TypeError, rnp.matrix, object)\n"""
root_numpy/tests/test_evaluate.py,29,"b'import ROOT\nimport root_numpy as rnp\nfrom numpy.testing import assert_array_equal\nfrom nose.tools import assert_raises\nfrom . import RNG, silence_serr\n\n\ndef test_evaluate_func():\n    f1 = ROOT.TF1(""f1"", ""x"")\n    f2 = ROOT.TF2(""f2"", ""x*y"")\n    f3 = ROOT.TF3(""f3"", ""x*y*z"")\n\n    # generate random arrays\n    arr_1d = RNG.rand(5)\n    arr_2d = RNG.rand(5, 2)\n    arr_3d = RNG.rand(5, 3)\n    arr_4d = RNG.rand(5, 4)\n\n    assert_array_equal(rnp.evaluate(f1, arr_1d),\n                       [f1.Eval(x) for x in arr_1d])\n    assert_array_equal(rnp.evaluate(f1.GetTitle(), arr_1d),\n                       [f1.Eval(x) for x in arr_1d])\n    assert_array_equal(rnp.evaluate(f2, arr_2d),\n                       [f2.Eval(*x) for x in arr_2d])\n    assert_array_equal(rnp.evaluate(f2.GetTitle(), arr_2d),\n                       [f2.Eval(*x) for x in arr_2d])\n    assert_array_equal(rnp.evaluate(f3, arr_3d),\n                       [f3.Eval(*x) for x in arr_3d])\n    assert_array_equal(rnp.evaluate(f3.GetTitle(), arr_3d),\n                       [f3.Eval(*x) for x in arr_3d])\n    # 4d formula\n    f4 = ROOT.TFormula(\'test\', \'x*y+z*t\')\n    assert_array_equal(rnp.evaluate(f4, arr_4d),\n                       [f4.Eval(*x) for x in arr_4d])\n\n    assert_raises(ValueError, rnp.evaluate, f1, arr_2d)\n    assert_raises(ValueError, rnp.evaluate, f2, arr_3d)\n    assert_raises(ValueError, rnp.evaluate, f2, arr_1d)\n    assert_raises(ValueError, rnp.evaluate, f3, arr_1d)\n    assert_raises(ValueError, rnp.evaluate, f3, arr_2d)\n\n    with silence_serr():  # silence cling error\n        assert_raises(ValueError, rnp.evaluate, ""f"", arr_1d)\n\n    assert_raises(ValueError, rnp.evaluate, ""x*y"", arr_1d)\n    assert_raises(ValueError, rnp.evaluate, ""x"", arr_2d)\n    assert_raises(ValueError, rnp.evaluate, ""x*y"", arr_3d)\n\n\ndef test_evaluate_hist():\n    h1 = ROOT.TH1D(""h1"", """", 10, 0, 1)\n    h1.FillRandom(""f1"")\n    h2 = ROOT.TH2D(""h2"", """", 10, 0, 1, 10, 0, 1)\n    h2.FillRandom(""f2"")\n    h3 = ROOT.TH3D(""h3"", """", 10, 0, 1, 10, 0, 1, 10, 0, 1)\n    h3.FillRandom(""f3"")\n\n    arr_1d = RNG.rand(5)\n    arr_2d = RNG.rand(5, 2)\n    arr_3d = RNG.rand(5, 3)\n\n    assert_array_equal(rnp.evaluate(h1, arr_1d),\n                       [h1.GetBinContent(h1.FindBin(x)) for x in arr_1d])\n    assert_array_equal(rnp.evaluate(h2, arr_2d),\n                       [h2.GetBinContent(h2.FindBin(*x)) for x in arr_2d])\n    assert_array_equal(rnp.evaluate(h3, arr_3d),\n                       [h3.GetBinContent(h3.FindBin(*x)) for x in arr_3d])\n\n    assert_raises(ValueError, rnp.evaluate, h1, arr_2d)\n    assert_raises(ValueError, rnp.evaluate, h2, arr_3d)\n    assert_raises(ValueError, rnp.evaluate, h2, arr_1d)\n    assert_raises(ValueError, rnp.evaluate, h3, arr_1d)\n    assert_raises(ValueError, rnp.evaluate, h3, arr_2d)\n\n\ndef test_evaluate_graph():\n    g = ROOT.TGraph(2)\n    g.SetPoint(0, 0, 1)\n    g.SetPoint(1, 1, 2)\n    assert_array_equal(rnp.evaluate(g, [0, .5, 1]), [1, 1.5, 2])\n    s = ROOT.TSpline3(""spline"", g)\n    assert_array_equal(rnp.evaluate(s, [0, .5, 1]),\n                       [s.Eval(x) for x in [0, .5, 1]])\n    # test exceptions\n    arr_2d = RNG.rand(5, 2)\n    assert_raises(TypeError, rnp.evaluate, object(), [1, 2, 3])\n    assert_raises(ValueError, rnp.evaluate, g, arr_2d)\n    assert_raises(ValueError, rnp.evaluate, s, arr_2d)\n'"
root_numpy/tests/test_hist.py,67,"b'import ROOT\nimport root_numpy as rnp\nimport numpy as np\nfrom numpy.testing import assert_array_equal, assert_array_almost_equal\nfrom nose.tools import (assert_true, assert_equal,\n                        assert_almost_equal, assert_raises)\nfrom . import RNG\n\n\ndef make_histogram(hist_type, shape, fill=True):\n    # shape=([[z_bins,] y_bins,] x_bins)\n    ndim = len(shape)\n    hist_cls = getattr(ROOT, \'TH{0}{1}\'.format(ndim, hist_type))\n    if ndim == 1:\n        hist = hist_cls(hist_cls.__name__, \'\',\n                        shape[0], 0, shape[0])\n        func = ROOT.TF1(\'func\', \'x\')\n    elif ndim == 2:\n        hist = hist_cls(hist_cls.__name__, \'\',\n                        shape[1], 0, shape[1],\n                        shape[0], 0, shape[0])\n        func = ROOT.TF2(\'func\', \'x*y\')\n    elif ndim == 3:\n        hist = hist_cls(hist_cls.__name__, \'\',\n                        shape[2], 0, shape[2],\n                        shape[1], 0, shape[1],\n                        shape[0], 0, shape[0])\n        func = ROOT.TF3(\'func\', \'x*y*z\')\n    else:\n        raise ValueError(""ndim must be 1, 2, or 3"")  # pragma: no cover\n    if fill:\n        hist.FillRandom(\'func\')\n    return hist\n\n\ndef check_hist2array(hist, include_overflow, copy):\n    array = rnp.hist2array(hist, include_overflow=include_overflow, copy=copy)\n    assert_equal(hist.GetDimension(), array.ndim)\n    for iaxis, axis in enumerate(\'XYZ\'[:array.ndim]):\n        if include_overflow:\n            assert_equal(array.shape[iaxis],\n                         getattr(hist, \'GetNbins{0}\'.format(axis))() + 2)\n        else:\n            assert_equal(array.shape[iaxis],\n                         getattr(hist, \'GetNbins{0}\'.format(axis))())\n    hist_sum = hist.Integral()\n    assert_true(hist_sum > 0)\n    assert_equal(hist_sum, np.sum(array))\n\n\ndef check_hist2array_THn(hist):\n    hist_thn = ROOT.THn.CreateHn("""", """", hist)\n    array = rnp.hist2array(hist)\n    array_thn = rnp.hist2array(hist_thn)\n    # non-zero elements\n    assert_true(np.any(array_thn))\n    # arrays should be identical\n    assert_array_equal(array, array_thn)\n\n\ndef check_hist2array_THnSparse(hist):\n    hist_thnsparse = ROOT.THnSparse.CreateSparse("""", """", hist)\n    array = rnp.hist2array(hist)\n    array_thnsparse = rnp.hist2array(hist_thnsparse)\n    # non-zero elements\n    assert_true(np.any(array_thnsparse))\n    # arrays should be identical\n    assert_array_equal(array, array_thnsparse)\n\n\ndef test_hist2array():\n    assert_raises(TypeError, rnp.hist2array, object())\n    for ndim in (1, 2, 3):\n        for hist_type in \'DFISC\':\n            hist = make_histogram(hist_type, shape=(5,) * ndim)\n            yield check_hist2array, hist, False, False\n            yield check_hist2array, hist, False, True\n            yield check_hist2array, hist, True, False\n            yield check_hist2array, hist, True, True\n            yield check_hist2array_THn, hist\n            # check that the memory was copied\n            arr = rnp.hist2array(hist, copy=True)\n            hist_sum = hist.Integral()\n            assert_true(hist_sum > 0)\n            hist.Reset()\n            assert_equal(np.sum(arr), hist_sum)\n            # check that the memory is shared\n            hist = make_histogram(hist_type, shape=(5,) * ndim)\n            arr = rnp.hist2array(hist, copy=False)\n            hist_sum = hist.Integral()\n            assert_true(hist_sum > 0)\n            assert_true(np.sum(arr) == hist_sum)\n            hist.Reset()\n            assert_true(np.sum(arr) == 0)\n\n\ndef test_hist2array_THn():\n    assert_raises(TypeError, rnp.hist2array, object())\n    for ndim in (1, 2, 3):\n        for hist_type in \'DFISC\':\n            hist = make_histogram(hist_type, shape=(5,) * ndim)\n            yield check_hist2array_THn, hist\n\n\ndef test_hist2array_THnSparse():\n    assert_raises(TypeError, rnp.hist2array, object())\n    for ndim in (1, 2, 3):\n        for hist_type in \'DFISC\':\n            hist = make_histogram(hist_type, shape=(5,) * ndim)\n            yield check_hist2array_THnSparse, hist\n\n\ndef check_hist2array_edges(hist, ndim, bins):\n    _, edges = rnp.hist2array(hist, return_edges=True)\n    assert_equal(len(edges), ndim)\n    for axis_edges in edges:\n        assert_array_equal(axis_edges, np.arange(bins + 1, dtype=np.double))\n\n\ndef test_hist2array_edges():\n    for ndim in (1, 2, 3):\n        for bins in (1, 2, 5):\n            hist = make_histogram(\'D\', shape=(bins,) * ndim)\n            yield check_hist2array_edges, hist, ndim, bins\n            hist = ROOT.THn.CreateHn("""", """", make_histogram(\'D\', shape=(bins,) * ndim))\n            yield check_hist2array_edges, hist, ndim, bins\n            hist = ROOT.THnSparse.CreateSparse("""", """", make_histogram(\'D\', shape=(bins,) * ndim))\n            yield check_hist2array_edges, hist, ndim, bins\n\n\ndef check_array2hist(hist):\n    shape = np.array([hist.GetNbinsX(), hist.GetNbinsY(), hist.GetNbinsZ()])\n    shape = shape[:hist.GetDimension()]\n    arr = RNG.randint(0, 10, size=shape)\n    rnp.array2hist(arr, hist)\n    arr_hist = rnp.hist2array(hist)\n    assert_array_equal(arr_hist, arr)\n\n    # Check behaviour if errors are supplied\n    errors = arr * 0.1\n    _hist = hist.Clone()\n    _hist.Reset()\n    rnp.array2hist(arr, _hist, errors=errors)\n    arr_hist = rnp.hist2array(_hist)\n    assert_array_equal(arr_hist, arr)\n    if hist.GetDimension() == 1:\n        errors_from_hist = np.array([_hist.GetBinError(ix)\n                                     for ix in range(1, _hist.GetNbinsX() + 1)])\n    if hist.GetDimension() == 2:\n        errors_from_hist = np.array([[_hist.GetBinError(ix, iy)\n                                      for iy in range(1, _hist.GetNbinsY() + 1)]\n                                     for ix in range(1, _hist.GetNbinsX() + 1)])\n    if hist.GetDimension() == 3:\n        errors_from_hist = np.array([[[_hist.GetBinError(ix, iy, iz)\n                                       for iz in range(1, _hist.GetNbinsZ() + 1)]\n                                      for iy in range(1, _hist.GetNbinsY() + 1)]\n                                     for ix in range(1, _hist.GetNbinsX() + 1)])\n    assert_array_equal(errors, errors_from_hist)\n\n    shape_overflow = shape + 2\n    arr_overflow = RNG.randint(0, 10, size=shape_overflow)\n    hist_overflow = hist.Clone()\n    hist_overflow.Reset()\n    rnp.array2hist(arr_overflow, hist_overflow)\n    arr_hist_overflow = rnp.hist2array(hist_overflow, include_overflow=True)\n    assert_array_equal(arr_hist_overflow, arr_overflow)\n\n    if len(shape) == 1:\n        return\n\n    # overflow not specified on all axes\n    arr_overflow2 = arr_overflow[1:-1]\n    hist_overflow2 = hist.Clone()\n    hist_overflow2.Reset()\n    rnp.array2hist(arr_overflow2, hist_overflow2)\n    arr_hist_overflow2 = rnp.hist2array(hist_overflow2, include_overflow=True)\n    assert_array_equal(arr_hist_overflow2[1:-1], arr_overflow2)\n\n\ndef test_array2hist():\n    # wrong type\n    assert_raises(TypeError, rnp.array2hist,\n                  object(), ROOT.TH1D(\'test\', \'\', 10, 0, 1))\n    # wrong type\n    assert_raises(TypeError, rnp.array2hist,\n                  np.array([1, 2]), object())\n    # dimensions don\'t match\n    assert_raises(ValueError, rnp.array2hist,\n                  np.arange(4).reshape(2, 2), ROOT.TH1D(\'test\', \'\', 10, 0, 1))\n    # shape not compatible\n    assert_raises(ValueError, rnp.array2hist,\n                  np.arange(4).reshape(2, 2),\n                  ROOT.TH2D(\'test\', \'\', 4, 0, 1, 3, 0, 1))\n    # shape of errors and content array does not match\n    assert_raises(ValueError, rnp.array2hist,\n                  np.arange(4).reshape(2, 2),\n                  ROOT.TH2D(\'test\', \'\', 4, 0, 1, 4, 0, 1),\n                  np.arange(6).reshape(2, 3))\n\n    for ndim in (1, 2, 3):\n        for hist_type in \'DFISC\':\n            hist = make_histogram(hist_type, shape=(5,) * ndim, fill=False)\n            yield check_array2hist, hist\n\n    # Check for histograms with unequal dimensions (reveals issues with transposing)\n    hist = make_histogram(hist_type, shape=(5, 6, 7), fill=False)\n    check_array2hist(hist)\n\n\ndef test_fill_hist():\n    n_samples = 1000\n    data1D = RNG.randn(n_samples)\n    w1D = np.empty(n_samples)\n    w1D.fill(2.)\n    data2D = RNG.randn(n_samples, 2)\n    data3D = RNG.randn(n_samples, 3)\n\n    a = ROOT.TH1D(\'th1d\', \'test\', 100, -5, 5)\n    rnp.fill_hist(a, data1D)\n    assert_almost_equal(a.Integral(), n_samples)\n\n    a_w = ROOT.TH1D(\'th1dw\', \'test\', 100, -5, 5)\n    rnp.fill_hist(a_w, data1D, w1D)\n    assert_almost_equal(a_w.Integral(), n_samples * 2)\n\n    b = ROOT.TH2D(\'th2d\', \'test\', 100, -5, 5, 100, -5, 5)\n    rnp.fill_hist(b, data2D)\n    assert_almost_equal(b.Integral(), n_samples)\n\n    c = ROOT.TH3D(\'th3d\', \'test\', 10, -5, 5, 10, -5, 5, 10, -5, 5)\n    rnp.fill_hist(c, data3D)\n    assert_almost_equal(c.Integral(), n_samples)\n\n    # array and weights lengths do not match\n    assert_raises(ValueError, rnp.fill_hist, c, data3D, np.ones(10))\n\n    # weights is not 1D\n    assert_raises(ValueError, rnp.fill_hist, c, data3D,\n        np.ones((data3D.shape[0], 1)))\n\n    # array not 2-d when filling 2D/3D histogram\n    for h in (b, c):\n        assert_raises(ValueError, rnp.fill_hist, h, RNG.randn(10))\n\n    # length of second axis does not match dimensionality of histogram\n    for h in (a, b, c):\n        assert_raises(ValueError, rnp.fill_hist, h, RNG.randn(10, 4))\n\n    # wrong type\n    h = list()\n    a = RNG.randn(10)\n    assert_raises(TypeError, rnp.fill_hist, h, a)\n\n\ndef test_fill_profile():\n    n_samples = 1000\n    w1D = np.empty(n_samples)\n    w1D.fill(2.)\n    data1D = RNG.randn(n_samples, 2)\n    data2D = RNG.randn(n_samples, 3)\n    data3D = RNG.randn(n_samples, 4)\n\n    a = ROOT.TProfile(\'th1d\', \'test\', 100, -5, 5)\n    rnp.fill_profile(a, data1D)\n    assert_true(a.Integral() != 0)\n\n    a_w = ROOT.TProfile(\'th1dw\', \'test\', 100, -5, 5)\n    rnp.fill_profile(a_w, data1D, w1D)\n    assert_true(a_w.Integral() != 0)\n    assert_equal(a_w.Integral(), a.Integral())\n\n    b = ROOT.TProfile2D(\'th2d\', \'test\', 100, -5, 5, 100, -5, 5)\n    rnp.fill_profile(b, data2D)\n    assert_true(b.Integral() != 0)\n\n    c = ROOT.TProfile3D(\'th3d\', \'test\', 10, -5, 5, 10, -5, 5, 10, -5, 5)\n    rnp.fill_profile(c, data3D)\n    assert_true(c.Integral() != 0)\n\n    # array and weights lengths do not match\n    assert_raises(ValueError, rnp.fill_profile, c, data3D, np.ones(10))\n\n    # weights is not 1D\n    assert_raises(ValueError, rnp.fill_profile, c, data3D,\n                  np.ones((data3D.shape[0], 1)))\n\n    # array is not 2D\n    assert_raises(ValueError, rnp.fill_profile, c, np.ones(10))\n\n    # length of second axis is not one more than dimensionality of the profile\n    for h in (a, b, c):\n        assert_raises(ValueError, rnp.fill_profile, h, RNG.randn(10, 5))\n\n    # wrong type\n    assert_raises(TypeError, rnp.fill_profile,\n                  ROOT.TH1D(""test"", ""test"", 1, 0, 1), data1D)\n\n\ndef test_fill_graph():\n    n_samples = 1000\n    data2D = RNG.randn(n_samples, 2)\n    data3D = RNG.randn(n_samples, 3)\n\n    graph = ROOT.TGraph()\n    rnp.fill_graph(graph, data2D)\n\n    graph2d = ROOT.TGraph2D()\n    rnp.fill_graph(graph2d, data3D)\n\n    # array not 2-d\n    for g in (graph, graph2d):\n        assert_raises(ValueError, rnp.fill_graph, g, RNG.randn(10))\n\n    # length of second axis does not match dimensionality of histogram\n    for g in (graph, graph2d):\n        assert_raises(ValueError, rnp.fill_graph, g, RNG.randn(10, 4))\n\n    # wrong type\n    h = list()\n    a = RNG.randn(10)\n    assert_raises(TypeError, rnp.fill_graph, h, a)\n'"
root_numpy/tests/test_sample.py,7,"b'import ROOT\nimport root_numpy as rnp\nfrom numpy.testing import assert_array_equal\nfrom nose.tools import assert_true, assert_equal, assert_raises\n\n\ndef check_random_sample(obj):\n    sample = rnp.random_sample(obj, 100)\n    ndim = getattr(obj, \'GetDimension\',\n                   getattr(obj, \'GetNdim\', None))()\n    if ndim > 1:\n        assert_equal(sample.shape, (100, ndim))\n    else:\n        assert_equal(sample.shape, (100,))\n    a = rnp.random_sample(obj, 10, seed=1)\n    b = rnp.random_sample(obj, 10, seed=1)\n    c = rnp.random_sample(obj, 10, seed=2)\n    assert_array_equal(a, b)\n    assert_true((a != c).any())\n\n\ndef test_random_sample():\n    funcs = [\n        ROOT.TF1(""f1"", ""TMath::DiLog(x)""),\n        ROOT.TF2(""f2"", ""sin(x)*sin(y)/(x*y)""),\n        ROOT.TF3(""f3"", ""sin(x)*sin(y)*sin(z)/(x*y*z)""),\n    ]\n    hists = [\n        ROOT.TH1D(""h1"", ""h1"", 10, -3, 3),\n        ROOT.TH2D(""h2"", ""h2"", 10, -3, 3, 10, -3, 3),\n        ROOT.TH3D(""h3"", ""h3"", 10, -3, 3, 10, -3, 3, 10, -3, 3),\n    ]\n    for i, hist in enumerate(hists):\n        hist.FillRandom(funcs[i].GetName())\n    for obj in funcs + hists:\n        yield check_random_sample, obj\n\n\ndef test_random_sample_bad_input():\n    func = ROOT.TF1(""f1"", ""TMath::DiLog(x)"")\n    assert_raises(ValueError, rnp.random_sample, func, 0)\n    assert_raises(ValueError, rnp.random_sample, func, 10, seed=-1)\n    assert_raises(TypeError, rnp.random_sample, object(), 10)\n'"
root_numpy/tests/test_tree.py,148,"b'import ROOT\nimport root_numpy as rnp\nfrom root_numpy.testdata import get_file\nimport numpy as np\nfrom numpy.testing import assert_array_equal, assert_array_almost_equal\nfrom nose.tools import (raises, assert_raises, assert_true,\n                        assert_equal, assert_almost_equal)\nimport warnings\nfrom . import load, RNG, temp\n\ntry:\n    from collections import OrderedDict\nexcept ImportError:  # pragma: no cover\n    from root_numpy.extern.ordereddict import OrderedDict\n\n\ndef test_testdata():\n    assert_raises(ValueError, get_file, \'file_does_not_exist.root\')\n\n\ndef check_single(single, n=100, offset=1):\n    assert_equal(\n        single.dtype,\n        [(\'n_int\', \'<i4\'), (\'f_float\', \'<f4\'), (\'d_double\', \'<f8\')])\n    assert_equal(len(single), n)\n    for i in range(len(single)):\n        offset = (i // 100) + 1\n        assert_equal(single[i][0], i % 100 + offset)\n        assert_almost_equal(single[i][1], i % 100 * 2.0 + offset)\n        assert_almost_equal(single[i][2], i % 100 * 3.0 + offset)\n\n\ndef test_list_trees():\n    # TTree\n    trees = rnp.list_trees(load(\'vary1.root\'))\n    assert_equal(trees, [\'tree\'])\n    # TNtuple\n    trees = rnp.list_trees(load(\'ntuple.root\'))\n    assert_equal(trees, [\'ntuple\'])\n    # Multiple key cycles of the same tree\n    with temp() as rfile:\n        tree = ROOT.TTree(\'tree\', \'tree\')\n        rfile.Write()\n        assert_equal(len(rnp.list_trees(rfile.GetName())), 1)\n        rfile.Write()\n        assert_equal(len(rnp.list_trees(rfile.GetName())), 1)\n        rdir = rfile.mkdir(\'dir\')\n        rdir.cd()\n        tree = ROOT.TTree(\'tree\', \'tree\')\n        rfile.Write()\n        assert_equal(set(rnp.list_trees(rfile.GetName())),\n                     set([\'tree\', \'dir/tree\']))\n\n\ndef test_list_branches():\n    branches = rnp.list_branches(load(\'single1.root\'))\n    assert_equal(branches, [\'n_int\', \'f_float\', \'d_double\'])\n\n\ndef test_list_directories():\n    directories = rnp.list_directories(load(\'directories.root\'))\n    assert_equal(set(directories), set([\'Dir1\', \'Dir2\']))\n\n\ndef test_list_structures():\n    structure = rnp.list_structures(load(\'single1.root\'))\n    expected = OrderedDict([\n        (\'n_int\', [(\'n_int\', \'int\')]),\n        (\'f_float\', [(\'f_float\', \'float\')]),\n        (\'d_double\', [(\'d_double\', \'double\')])])\n    assert_equal(structure, expected)\n\n\ndef test_single():\n    f = load(\'single1.root\')\n    a = rnp.root2array(f)\n    check_single(a)\n\n    # specify tree name\n    a = rnp.root2array(f, treename=\'tree\')\n    check_single(a)\n\n    # tree2array\n    f = get_file(\'single1.root\')\n    tree = f.Get(\'tree\')\n    check_single(rnp.tree2array(tree))\n\n\ndef test_chain():\n    chain = ROOT.TChain(\'tree\')\n    chain.Add(load(\'single1.root\'))\n    check_single(rnp.tree2array(chain))\n\n    f = load([\'single1.root\', \'single2.root\'])\n    a = rnp.root2array(f)\n    check_single(a, 200)\n\n\ndef test_ntuple():\n    f = load(\'ntuple.root\')\n    a = rnp.root2array(f)\n    assert_equal(len(a), 10)\n    assert_equal(len(a.dtype.names), 3)\n\n\n@raises(IOError)\ndef test_root2array_single_pattern_DNE():\n    f = load([\'single1.root\', \'does_not_exist.root\'])\n    a = rnp.root2array(f)\n\n\n@raises(ValueError)\ndef test_root2array_no_filename():\n    rnp.root2array([])\n\n\ndef test_root2array_no_trees_in_file():\n    with temp() as tmp:\n        tmp.Close()\n        assert_raises(IOError, rnp.root2array, [tmp.GetName()], treename=None)\n\n\n@raises(IOError)\ndef test_root2array_single_filename_DNE():\n    f = load(\'does_not_exist.root\')\n    a = rnp.root2array(f)\n\n\n@raises(ValueError)\ndef test_root2array_multiple_trees_and_name_not_specified():\n    f = load(\'trees.root\')\n    a = rnp.root2array(f)\n\n\ndef test_empty_branches():\n    f = load(\'single1.root\')\n    assert_raises(ValueError, rnp.root2array, f, branches=[])\n\n\ndef test_tree_without_branches():\n    tree = ROOT.TTree(\'test\', \'test\')\n    assert_raises(ValueError, rnp.tree2array, tree)\n\n\ndef test_empty_tree():\n    from array import array\n    tree = ROOT.TTree(\'tree\', \'tree\')\n    d = array(\'d\', [0.])\n    tree.Branch(\'double\', d, \'double/D\')\n    assert_equal(len(rnp.tree2array(tree)), 0)\n\n\ndef test_duplicate_branch_name():\n    from array import array\n    tree = ROOT.TTree(\'tree\', \'tree\')\n    d = array(\'d\', [0.])\n    tree.Branch(\'double\', d, \'double/D\')\n    tree.Branch(\'double\', d, \'double/D\')\n    tree.Fill()\n\n    # check that a warning was emitted\n    with warnings.catch_warnings(record=True) as w:\n        warnings.simplefilter(""always"")\n        a = rnp.tree2array(tree)\n        assert_equal(len(w), 1)\n        assert_true(issubclass(w[-1].category, RuntimeWarning))\n        assert_true(""ignoring duplicate branch named"" in str(w[-1].message))\n    assert_equal(\n        a.dtype,\n        [(\'double\', \'<f8\')])\n\n\ndef test_unsupported_branch_in_branches():\n    tree = ROOT.TTree(\'test\', \'test\')\n    vect = ROOT.TLorentzVector()\n    double = np.array([0], dtype=float)\n    tree.Branch(\'vector\', vect)\n    tree.Branch(\'double\', double, \'double/D\')\n    rnp.tree2array(tree)\n    assert_raises(TypeError, rnp.tree2array, tree, branches=[\'vector\'])\n\n\ndef test_no_supported_branches():\n    tree = ROOT.TTree(\'test\', \'test\')\n    vect = ROOT.TLorentzVector()\n    tree.Branch(\'vector\', vect)\n    assert_raises(RuntimeError, rnp.tree2array, tree)\n\n\ndef test_preserve_branch_order():\n    a = rnp.root2array(load(\'test.root\'))\n    assert_equal(a.dtype.names, (\'i\', \'x\', \'y\', \'z\'))\n\n    a = rnp.root2array(load(\'test.root\'), branches=[\'y\', \'x\', \'z\'])\n    assert_equal(a.dtype.names, (\'y\', \'x\', \'z\'))\n\n\ndef test_fixed_length_arrays():\n    f = load([\'fixed1.root\', \'fixed2.root\'])\n    a = rnp.root2array(f)\n    assert_equal(\n        a.dtype,\n        [(\'n_int\', \'<i4\', (5,)),\n         (\'f_float\', \'<f4\', (7,)),\n         (\'d_double\', \'<f8\', (10,)),\n         (\'n2_int\', \'<i4\', (5, 2)),\n         (\'f2_float\', \'<f4\', (7, 3)),\n         (\'d2_double\', \'<f8\', (10, 4))])\n\n    # Check values\n    assert_equal(a[\'n_int\'][0][0], 1)\n    assert_equal(a[\'n_int\'][0][1], 2)\n    assert_almost_equal(a[\'d_double\'][-1][-1], 1514.5)\n    assert_array_equal(a[\'n2_int\'][0],\n                       np.array([[1, 2],\n                                 [2, 3],\n                                 [3, 4],\n                                 [4, 5],\n                                 [5, 6]]))\n\n\ndef test_variable_length_arrays():\n    f = load([\'vary1.root\', \'vary2.root\'])\n    a = rnp.root2array(f).view(np.recarray)\n\n    assert_equal(\n        a.dtype,\n        [(\'len_n\', \'<i4\'), (\'len_f\', \'<i4\'), (\'len_d\', \'<i4\'),\n         (\'n_char\', \'O\'), (\'n_uchar\', \'O\'),\n         (\'n_short\', \'O\'), (\'n_ushort\', \'O\'),\n         (\'n_int\', \'O\'), (\'n_uint\', \'O\'),\n         (\'n_long\', \'O\'), (\'n_ulong\', \'O\'),\n         (\'f_float\', \'O\'), (\'d_double\', \'O\'),\n         (\'n2_int\', \'O\'), (\'f2_float\', \'O\'), (\'d2_double\', \'O\')])\n\n    # check lengths\n    for i in range(len(a)):\n        assert_equal(a.len_n[i], len(a.n_int[i]))\n        assert_equal(a.len_f[i], len(a.f_float[i]))\n        assert_equal(a.len_d[i], len(a.d_double[i]))\n\n        assert_equal((a.len_n[i], 2), a.n2_int[i].shape)\n        assert_equal((a.len_f[i], 3), a.f2_float[i].shape)\n        assert_equal((a.len_d[i], 4), a.d2_double[i].shape)\n\n    # check elements\n    assert_equal(a.len_n[0], 0)\n    assert_equal(a.len_f[0], 1)\n    assert_equal(a.len_d[0], 2)\n    assert_equal(a.n_int[-1][-1], 417)\n    assert_equal(a.f_float[-1][0], 380.5)\n    assert_equal(a.f_float[-1][-1], 456.5)\n    assert_equal(a.d_double[-1][0], 380.25)\n    assert_equal(a.d_double[-1][-1], 497.25)\n\n    # read only array without ""length leaf""\n    b = rnp.root2array(f, branches=\'n_int\')\n    for i in range(len(b)):\n        assert_equal(len(b[i]), a.len_n[i])\n\n\ndef test_single_branch():\n    f = get_file(\'single1.root\')\n    tree = f.Get(\'tree\')\n    arr1_1d = rnp.tree2array(tree, branches=\'n_int\')\n    arr2_1d = rnp.root2array(load(\'single1.root\'), branches=\'n_int\')\n    assert_equal(arr1_1d.dtype, np.dtype(\'<i4\'))\n    assert_equal(arr2_1d.dtype, np.dtype(\'<i4\'))\n\n\ndef test_selection():\n    chain = ROOT.TChain(\'tree\')\n    chain.Add(load(\'single1.root\'))\n    chain.Add(load(\'single2.root\'))\n    a = rnp.tree2array(chain)\n    assert_equal((a[\'d_double\'] <= 100).any(), True)\n    a = rnp.tree2array(chain, selection=""d_double > 100"")\n    assert_equal((a[\'d_double\'] <= 100).any(), False)\n\n    # selection with differing variables in branches and expression\n    a = rnp.tree2array(chain,\n        branches=[\'d_double\'],\n        selection=""f_float < 100 && n_int%2 == 1"")\n\n    # selection with TMath\n    a = rnp.tree2array(chain,\n        selection=""TMath::Erf(d_double) < 0.5"")\n\n\ndef test_expression():\n    rec = rnp.root2array(load(\'single*.root\'))\n    rec2 = rnp.root2array(load(\'single*.root\'), branches=[\'f_float*2\'])\n    assert_array_equal(rec[\'f_float\'] * 2, rec2[\'f_float*2\'])\n\n    a = rnp.root2array(load(\'single*.root\'), branches=\'Entry$\')\n    assert_equal(a.dtype, np.int32)\n    assert_array_equal(a, np.arange(a.shape[0]))\n\n\ndef test_selection_and_expression():\n    ref = len(rnp.root2array(\n        load(\'test.root\'), branches=[\'x\', \'y\'], selection=\'z>0\'))\n    assert_equal(ref,\n        len(rnp.root2array(\n            load(\'test.root\'), branches=[\'x\', \'y\', \'z\'], selection=\'z>0\')))\n    assert_equal(ref,\n        len(rnp.root2array(\n            load(\'test.root\'), branches=[\'x\', \'x*y\'], selection=\'z>0\')))\n    assert_equal(ref,\n        len(rnp.root2array(\n            load(\'test.root\'), branches=[\'x\', \'x*z\'], selection=\'z>0\')))\n\n\ndef test_object_expression():\n    rec = rnp.root2array(load([\'object1.root\', \'object2.root\']),\n                       branches=[\'vect.Pt()\'])\n    assert_array_equal(\n        rec[\'vect.Pt()\'],\n        np.concatenate([\n            np.arange(10, dtype=\'d\') + 1,\n            np.arange(10, dtype=\'d\') + 2]))\n\n\ndef test_variable_length_array_expression():\n    # variable length array\n    a = rnp.root2array(load(\'vary*.root\'), branches=\'n_int * 2\')\n    assert_equal(a.ndim, 1)\n    assert_equal(a.dtype, \'O\')\n\n\ndef test_fixed_length_array_expression():\n    # fixed length array\n    a = rnp.root2array(load(\'fixed*.root\'), branches=\'n_int * 2\')\n    assert_equal(a.ndim, 2)\n    assert_equal(a.shape[1], 5)\n    assert_true(np.all(rnp.root2array(load(\'fixed*.root\'), branches=\'Length$(n_int)\') == 5))\n\n\ndef test_object_selection():\n    a = rnp.root2array(load(\'vary*.root\'), branches=\'n_int\',\n                       object_selection={\'n_int % 2 == 0\': \'n_int\'})\n    for suba in a:\n        assert_true((suba % 2 == 0).all())\n\n    # branch does not exist\n    assert_raises(ValueError, rnp.root2array, load(\'vary*.root\'),\n                  branches=\'n_int\', object_selection={\'n_int % 2 == 0\': \'DNE\'})\n\n    # duplicate branch in selection list\n    assert_raises(ValueError, rnp.root2array, load(\'vary*.root\'),\n                  branches=\'n_int\', object_selection={\'n_int % 2 == 0\': [\'n_int\', \'n_int\']})\n\n    # test object selection on variable-length expression\n    a = rnp.root2array(load(\'object*.root\'), branches=\'lines.GetX1()\',\n                       object_selection={\'lines.GetX1() > 3\': \'lines.GetX1()\'})\n\n    for suba in a:\n        assert_true((suba > 3).all())\n\n    # attempting to apply object selection on fixed-length array\n    # currently not implemented since this changes the output type from\n    # fixed-length to variable-length\n    assert_raises(TypeError, rnp.root2array, load(""fixed*.root""),\n                  branches=\'n_int\',\n                  object_selection={\'n_int % 2 == 0\': \'n_int\'})\n\n    # test with vectors\n    a = rnp.root2array(load(\'vector.root\'), branches=\'v_i\',\n                       object_selection={\'v_i % 2 == 0\': \'v_i\'})\n\n    for suba in a:\n        assert_true((suba % 2 == 0).all())\n\n\n@raises(ValueError)\ndef test_branch_DNE():\n    chain = ROOT.TChain(\'tree\')\n    chain.Add(load(\'single1.root\'))\n    rnp.tree2array(chain, branches=[\'my_net_worth\'])\n\n\n@raises(TypeError)\ndef test_tree2array_wrong_type():\n    rnp.tree2array(list())\n\n\ndef test_specific_branch():\n    a = rnp.root2array(load(\'single1.root\'), branches=[\'f_float\'])\n    assert_equal(a.dtype, [(\'f_float\', \'<f4\')])\n\n\ndef test_vector():\n    a = rnp.root2array(load(\'vector.root\')).view(np.recarray)\n    types = [\n        (\'v_i\', \'O\'),\n        (\'v_f\', \'O\'),\n        (\'v_F\', \'O\'),\n        (\'v_d\', \'O\'),\n        (\'v_l\', \'O\'),\n        (\'v_c\', \'O\'),\n        (\'v_b\', \'O\'),\n        (\'vv_i\', \'O\'),\n        (\'vv_f\', \'O\'),\n        (\'vv_F\', \'O\'),\n        (\'vv_d\', \'O\'),\n        (\'vv_l\', \'O\'),\n        (\'vv_c\', \'O\'),\n        (\'vv_b\', \'O\'),\n    ]\n    assert_equal(a.dtype, types)\n\n    assert_equal(a.v_i[0].dtype, np.int32)\n    assert_equal(a.v_f[0].dtype, np.float32)\n    assert_equal(a.v_F[0].dtype, np.float32)\n    assert_equal(a.v_d[0].dtype, np.float64)\n    assert_equal(a.v_l[0].dtype, np.int64)\n    assert_equal(a.v_c[0].dtype, np.int8)\n    assert_equal(a.v_b[0].dtype, np.bool)\n\n    # assert that wrapper array is np.object\n    assert_equal(a.vv_i[0].dtype, np.object)\n    assert_equal(a.vv_f[0].dtype, np.object)\n    assert_equal(a.vv_F[0].dtype, np.object)\n    assert_equal(a.vv_d[0].dtype, np.object)\n    assert_equal(a.vv_l[0].dtype, np.object)\n    assert_equal(a.vv_c[0].dtype, np.object)\n    assert_equal(a.vv_b[0].dtype, np.object)\n\n    assert_equal(a.vv_i[0][0].dtype, np.int32)\n    assert_equal(a.vv_f[0][0].dtype, np.float32)\n    assert_equal(a.vv_F[0][0].dtype, np.float32)\n    assert_equal(a.vv_d[0][0].dtype, np.float64)\n    assert_equal(a.vv_l[0][0].dtype, np.int64)\n    assert_equal(a.vv_c[0][0].dtype, np.int8)\n    assert_equal(a.vv_b[0][0].dtype, np.bool)\n\n    # check a few values\n    assert_equal(a.v_i[0][0], 1)\n    assert_equal(a.v_i[1][1], 3)\n    assert_equal(a.v_i[-2][0], 9)\n    assert_equal(a.v_i[-2][-1], 17)\n\n    assert_equal(a.v_f[0][0], 2.0)\n    assert_equal(a.v_f[1][1], 5.0)\n    assert_equal(a.v_f[-2][0], 18.0)\n    assert_equal(a.v_f[-2][-1], 26.0)\n\n    assert_equal(a.v_F[0][0], 2.0)\n    assert_equal(a.v_F[1][1], 5.0)\n    assert_equal(a.v_F[-2][0], 18.0)\n    assert_equal(a.v_F[-2][-1], 26.0)\n\n    # more strict conditioning for numpy arrays\n    def assert_equal_array(arr1, arr2):\n        return assert_equal((arr1 == arr2).all(), True,\n            ""array mismatch: {0} != {1}"".format(arr1, arr2))\n\n    assert_equal_array(a.vv_i[0][0], np.array([1], dtype=np.int32) )\n    assert_equal_array(a.vv_i[1][1], np.array([2, 3], dtype=np.int32) )\n    assert_equal_array(a.vv_i[-2][0], np.array([9], dtype=np.int32) )\n    assert_equal_array(a.vv_i[-2][-1],\n                       np.array([ 9, 10, 11, 12, 13, 14, 15, 16, 17],\n                                dtype=np.int32))\n\n    assert_equal_array(a.vv_f[0][0], np.array([ 2.], dtype=np.float32) )\n    assert_equal_array(a.vv_f[1][1], np.array([ 4.,  5.], dtype=np.float32) )\n    assert_equal_array(a.vv_f[-2][0], np.array([ 18.], dtype=np.float32) )\n    assert_equal_array(a.vv_f[-2][-1],\n                       np.array([ 18.,  19.,  20.,  21.,  22.,\n                                  23.,  24.,  25.,  26.],\n                                dtype=np.float32))\n\n    assert_equal_array(a.vv_F[0][0], np.array([ 2.], dtype=np.float32) )\n    assert_equal_array(a.vv_F[1][1], np.array([ 4.,  5.], dtype=np.float32) )\n    assert_equal_array(a.vv_F[-2][0], np.array([ 18.], dtype=np.float32) )\n    assert_equal_array(a.vv_F[-2][-1],\n                       np.array([ 18.,  19.,  20.,  21.,  22.,\n                                  23.,  24.,  25.,  26.],\n                                dtype=np.float32))\n\n\ndef test_string():\n    a = rnp.root2array(load(\'string.root\'))\n    types = [\n        (\'message\', \'O\'),\n        (\'vect\', \'O\'),\n        (\'vect2d\', \'O\'),\n    ]\n    assert_equal(a.dtype, types)\n    assert_equal(a[0][0], \'Hello World!\')\n    assert_equal(a[0][1][0], \'Hello!\')\n    assert_equal(a[0][2][0][0], \'Hello!\')\n\n\ndef test_slice():\n    a = rnp.root2array(load(\'single1.root\'), stop=10).view(np.recarray)\n    assert_equal(len(a), 10)\n    assert_equal(a.n_int[-1], 10)\n\n    a = rnp.root2array(load(\'single1.root\'), stop=11, start=1).view(np.recarray)\n    assert_equal(len(a), 10)\n    assert_equal(a.n_int[-1], 11)\n\n    a = rnp.root2array(load(\'single1.root\'), stop=105, start=95).view(np.recarray)\n    assert_equal(len(a), 5)\n    assert_equal(a.n_int[-1], 100)\n\n\ndef test_weights():\n    f = ROOT.TFile(load(\'test.root\'))\n    tree = f.Get(\'tree\')\n    tree.SetWeight(5.)\n    rec = rnp.tree2array(tree, include_weight=True, weight_name=\'treeweight\')\n    assert_array_equal(rec[\'treeweight\'], np.ones(100) * 5)\n    f = load([\'single1.root\', \'single2.root\'])\n    a = rnp.root2array(f, include_weight=True)\n    assert_array_equal(\n        a[\'weight\'],\n        np.concatenate((np.ones(100) * 2., np.ones(100) * 3.)))\n\n\ndef test_struct():\n    assert_array_equal(rnp.root2array(load(\'struct.root\')),\n        np.array([(10, 15.5, 20, 781.2)],\n            dtype=[\n                (\'branch1_intleaf\', \'<i4\'),\n                (\'branch1_floatleaf\', \'<f4\'),\n                (\'branch2_intleaf\', \'<i4\'),\n                (\'branch2_floatleaf\', \'<f4\')]))\n\n\ndef check_truncate_impute(filename):\n    filename = load(filename)\n    # first convert array and find object columns\n    arr = rnp.root2array(filename)\n    assert_true(len(arr))\n    object_fields = [field for field in arr.dtype.names if arr.dtype[field] == \'O\']\n    fields_1d = [field for field in object_fields\n                 if arr[field][0].dtype != \'O\' and len(arr[field][0].shape) == 1]\n    fields_md = list(set(object_fields) - set(fields_1d))\n    assert_true(fields_1d)\n    assert_true(fields_md)\n    fields_1d.sort()\n    fields_md.sort()\n\n    rfile = ROOT.TFile.Open(filename)\n    tree = rfile.Get(rnp.list_trees(filename)[0])\n\n    # test both root2array and tree2array\n    for func, arg in [(rnp.root2array, filename), (rnp.tree2array, tree)]:\n\n        arr1 = func(arg, branches=[(f, 0) for f in fields_1d])\n        assert_true(len(arr1))\n        assert_equal(set(arr1.dtype.names), set(fields_1d))\n        # Giving length of 1 will result in the same output\n        arr2 = func(arg, branches=[(f, 0, 1) for f in fields_1d])\n        assert_array_equal(arr1, arr2)\n        # fill_value of 1 instead of 0 should change output array\n        arr2 = func(arg, branches=[(f, 1, 1) for f in fields_1d])\n        assert_raises(AssertionError, assert_array_equal, arr1, arr2)\n        # check dtype shape\n        arr3 = func(arg, branches=[(f, 0, 3) for f in fields_1d])\n        for field in fields_1d:\n            assert_equal(arr3.dtype[field].shape, (3,))\n\n        # length must be at least 1\n        assert_raises(ValueError, func, arg, branches=[(fields_1d[0], 0, 0)])\n        # tuple is not of length 2 or 3\n        assert_raises(ValueError, func, arg, branches=[(fields_1d[0], 1, 1, 1)])\n        assert_raises(ValueError, func, arg, branches=(fields_1d[0], 1, 1, 1))\n        # can only truncate 1d arrays\n        assert_raises(TypeError, func, arg, branches=(fields_md[0], 0))\n\n        # expressions\n        arr1 = func(arg, branches=\'{0}==0\'.format(fields_1d[0]))\n        assert_equal(arr1.dtype, \'O\')\n        arr2 = func(arg, branches=(\'{0}==0\'.format(fields_1d[0]), 0))\n        assert_equal(arr2.dtype, arr1[0].dtype)\n\n\ndef test_truncate_impute():\n    for filename in [\'vector.root\', \'vary1.root\']:\n        yield check_truncate_impute, filename\n\n\ndef test_array2tree():\n    a = np.array([\n        (12345, 2., 2.1, True),\n        (3, 4., 4.2, False),],\n        dtype=[\n            (\'x\', np.int32),\n            (\'y\', np.float32),\n            (\'z\', np.float64),\n            (\'w\', np.bool)])\n\n    with temp() as tmp:\n        tree = rnp.array2tree(a)\n        a_conv = rnp.tree2array(tree)\n        assert_array_equal(a, a_conv)\n        # extend the tree\n        tree2 = rnp.array2tree(a, tree=tree)\n        assert_equal(tree2.GetEntries(), len(a) * 2)\n        a_conv2 = rnp.tree2array(tree2)\n        assert_array_equal(np.hstack([a, a]), a_conv2)\n\n    assert_raises(TypeError, rnp.array2tree, a, tree=object)\n\n\ndef test_array2tree_charstar():\n    a = np.array([b\'\', b\'a\', b\'ab\', b\'abc\', b\'xyz\', b\'\'],\n                 dtype=[(\'string\', \'S3\')])\n\n    with temp() as tmp:\n        rnp.array2root(a, tmp.GetName(), mode=\'recreate\')\n        a_conv = rnp.root2array(tmp.GetName())\n        assert_array_equal(a, a_conv)\n\n\ndef test_array2tree_fixed_length_arrays():\n    f = load([\'fixed1.root\', \'fixed2.root\'])\n    a = rnp.root2array(f)\n    with temp() as tmp:\n        rnp.array2root(a, tmp.GetName(), mode=\'recreate\')\n        a_conv = rnp.root2array(tmp.GetName())\n        assert_array_equal(a, a_conv)\n\n\ndef test_array2root():\n    a = np.array([\n        (12345, 2., 2.1, True),\n        (3, 4., 4.2, False),],\n        dtype=[\n            (\'x\', np.int32),\n            (\'y\', np.float32),\n            (\'z\', np.float64),\n            (\'w\', np.bool)])\n    with temp() as tmp:\n        rnp.array2root(a, tmp.GetName(), mode=\'recreate\')\n        a_conv = rnp.root2array(tmp.GetName())\n        assert_array_equal(a, a_conv)\n        # extend the tree\n        rnp.array2root(a, tmp.GetName(), mode=\'update\')\n        a_conv2 = rnp.root2array(tmp.GetName())\n        assert_array_equal(np.hstack([a, a]), a_conv2)\n        # write into subdirectory\n        tname = \'root/sub/tree\'\n        rnp.array2root(a, tmp.GetName(), treename=tname, mode=\'update\')\n        a_conv3 = rnp.root2array(tmp.GetName(), treename=tname)\n        assert_array_equal(a, a_conv3)\n        # try creating tree with conflicting name\n        assert_raises(IOError, rnp.array2root, a, tmp.GetName(),\n                treename=\'root/sub\', mode=\'update\')\n        # try creating subdirectory with conflicting name\n        assert_raises(IOError, rnp.array2root, a, tmp.GetName(),\n                treename=\'root/sub/tree/error\', mode=\'update\')\n'"
root_numpy/tests/test_utils.py,84,"b""import numpy as np\nfrom numpy.lib import recfunctions\nimport root_numpy as rnp\nfrom numpy.testing import assert_array_almost_equal, assert_array_equal\nfrom nose.tools import assert_equal, assert_raises\nfrom . import load\n\n\ndef test_rec2array():\n    # scalar fields\n    a = np.array([\n        (12345, 2., 2.1, True),\n        (3, 4., 4.2, False),],\n        dtype=[\n            ('x', np.int32),\n            ('y', np.float32),\n            ('z', np.float64),\n            ('w', np.bool)])\n\n    arr = rnp.rec2array(a)\n    assert_array_equal(arr,\n        np.array([\n            [12345, 2, 2.1, 1],\n            [3, 4, 4.2, 0]]))\n\n    arr = rnp.rec2array(a, fields=['x', 'y'])\n    assert_array_equal(arr,\n        np.array([\n            [12345, 2],\n            [3, 4]]))\n\n    # single scalar field\n    arr = rnp.rec2array(a, fields=['x'])\n    assert_array_equal(arr, np.array([[12345], [3]], dtype=np.int32))\n    # single scalar field simplified\n    arr = rnp.rec2array(a, fields='x')\n    assert_array_equal(arr, np.array([12345, 3], dtype=np.int32))\n\n    # case where array has single record\n    assert_equal(rnp.rec2array(a[:1]).shape, (1, 4))\n    assert_equal(rnp.rec2array(a[:1], fields=['x']).shape, (1, 1))\n    assert_equal(rnp.rec2array(a[:1], fields='x').shape, (1,))\n\n    # array fields\n    a = np.array([\n        ([1, 2, 3], [4.5, 6, 9.5],),\n        ([4, 5, 6], [3.3, 7.5, 8.4],),],\n        dtype=[\n            ('x', np.int32, (3,)),\n            ('y', np.float32, (3,))])\n\n    arr = rnp.rec2array(a)\n    assert_array_almost_equal(arr,\n        np.array([[[1, 4.5],\n                   [2, 6],\n                   [3, 9.5]],\n                  [[4, 3.3],\n                   [5, 7.5],\n                   [6, 8.4]]]))\n\n    # single array field\n    arr = rnp.rec2array(a, fields=['y'])\n    assert_array_almost_equal(arr,\n        np.array([[[4.5], [6], [9.5]],\n                  [[3.3], [7.5], [8.4]]]))\n    # single array field simplified\n    arr = rnp.rec2array(a, fields='y')\n    assert_array_almost_equal(arr,\n        np.array([[4.5, 6, 9.5],\n                  [3.3, 7.5, 8.4]]))\n\n    # case where array has single record\n    assert_equal(rnp.rec2array(a[:1], fields=['y']).shape, (1, 3, 1))\n    assert_equal(rnp.rec2array(a[:1], fields='y').shape, (1, 3))\n\n    # lengths mismatch\n    a = np.array([\n        ([1, 2], [4.5, 6, 9.5],),\n        ([4, 5], [3.3, 7.5, 8.4],),],\n        dtype=[\n            ('x', np.int32, (2,)),\n            ('y', np.float32, (3,))])\n    assert_raises(ValueError, rnp.rec2array, a)\n\n    # mix of scalar and array fields should fail\n    a = np.array([\n        (1, [4.5, 6, 9.5],),\n        (4, [3.3, 7.5, 8.4],),],\n        dtype=[\n            ('x', np.int32),\n            ('y', np.float32, (3,))])\n    assert_raises(ValueError, rnp.rec2array, a)\n\n\ndef test_stack():\n    rec = rnp.root2array(load('test.root'))\n    s = rnp.stack([rec, rec])\n    assert_equal(s.shape[0], 2 * rec.shape[0])\n    assert_equal(s.dtype.names, rec.dtype.names)\n    s = rnp.stack([rec, rec], fields=['x', 'y'])\n    assert_equal(s.shape[0], 2 * rec.shape[0])\n    assert_equal(s.dtype.names, ('x', 'y'))\n    # recs don't have identical fields\n    rec2 = recfunctions.drop_fields(rec, ['i', 'x'])\n    s = rnp.stack([rec, rec2])\n    assert_equal(set(s.dtype.names), set(['y', 'z']))\n\n\ndef test_dup_idx():\n    a = [1, 2, 3, 4, 3, 2]\n    assert_array_equal(rnp.dup_idx(a), [1, 2, 4, 5])\n\n\ndef test_stretch():\n    arr = np.empty(5,\n        dtype=[\n            ('scalar', np.int),\n            ('vl1', 'O'),\n            ('vl2', 'O'),\n            ('vl3', 'O'),\n            ('fl1', np.int, (2, 2)),\n            ('fl2', np.float, (2, 3)),\n            ('fl3', np.double, (3, 2))])\n\n    for i in range(arr.shape[0]):\n        vl1 = np.array(range(i + 1), dtype=np.int)\n        vl2 = np.array(range(i + 2), dtype=np.float) * 2\n        vl3 = np.array(range(2), dtype=np.double) * 3\n        fl1 = np.array(range(4), dtype=np.int).reshape((2, 2))\n        fl2 = np.array(range(6), dtype=np.float).reshape((2, 3))\n        fl3 = np.array(range(6), dtype=np.double).reshape((3, 2))\n        arr[i] = (i, vl1, vl2, vl3, fl1, fl2, fl3)\n\n    # no array columns included\n    assert_raises(RuntimeError, rnp.stretch, arr, ['scalar',])\n\n    # lengths don't match\n    assert_raises(ValueError, rnp.stretch, arr, ['scalar', 'vl1', 'vl2',])\n    assert_raises(ValueError, rnp.stretch, arr, ['scalar', 'fl1', 'fl3',])\n    assert_raises(ValueError, rnp.stretch, arr)\n\n    # variable-length stretch\n    stretched = rnp.stretch(arr, ['scalar', 'vl1',])\n    assert_equal(stretched.dtype,\n                 [('scalar', np.int),\n                  ('vl1', np.int)])\n    assert_equal(stretched.shape[0], 15)\n    assert_array_equal(\n        stretched['scalar'],\n        np.repeat(arr['scalar'], np.vectorize(len)(arr['vl1'])))\n\n    # fixed-length stretch\n    stretched = rnp.stretch(arr, ['scalar', 'vl3', 'fl1', 'fl2',])\n    assert_equal(stretched.dtype,\n                 [('scalar', np.int),\n                  ('vl3', np.double),\n                  ('fl1', np.int, (2,)),\n                  ('fl2', np.float, (3,))])\n    assert_equal(stretched.shape[0], 10)\n    assert_array_equal(\n        stretched['scalar'], np.repeat(arr['scalar'], 2))\n\n    # optional argument return_indices\n    stretched, idx = rnp.stretch(arr, ['scalar', 'vl1'], return_indices=True)\n    assert_equal(stretched.shape[0], idx.shape[0])\n\n    from_arr = list(map(lambda x: x['vl1'][0], arr))\n    from_stretched = stretched[idx == 0]['vl1']\n    assert_array_equal(from_arr, from_stretched)\n\n    # stretch single field and produce unstructured output\n    stretched = rnp.stretch(arr, 'vl1')\n    assert_equal(stretched.dtype, np.int)\n\n\ndef test_blockwise_inner_join():\n    test_data = np.array([\n        (1.0, np.array([11,12,13]), np.array([1,0,1]), 0, np.array([1,2,3])),\n        (2.0, np.array([21,22,23]), np.array([-1,2,-1]), 1, np.array([31,32,33]))],\n        dtype=[\n            ('sl', np.float),\n            ('al', 'O'),\n            ('fk', 'O'),\n            ('s_fk', np.int),\n            ('ar', 'O')])\n    # vector join\n    a1 = rnp.blockwise_inner_join(\n        test_data, ['sl', 'al'], test_data['fk'], ['ar'])\n\n    # specify fk with string\n    a1 = rnp.blockwise_inner_join(\n        test_data, ['sl', 'al'], 'fk', ['ar'])\n\n    exp1 = np.array([\n        (1.0, 11, 2, 1),\n        (1.0, 12, 1, 0),\n        (1.0, 13, 2, 1),\n        (2.0, 22, 33, 2)],\n        dtype=[\n            ('sl', '<f8'),\n            ('al', '<i8'),\n            ('ar', '<i8'),\n            ('fk', '<i8')])\n    assert_array_equal(a1, exp1, verbose=True)\n\n    # vector join with force repeat\n    a2 = rnp.blockwise_inner_join(\n        test_data, ['sl','al'], test_data['fk'], ['ar'], force_repeat=['al'])\n    exp2 = np.array([\n        (1.0, np.array([11, 12, 13]), 2, 1),\n        (1.0, np.array([11, 12, 13]), 1, 0),\n        (1.0, np.array([11, 12, 13]), 2, 1),\n        (2.0, np.array([21, 22, 23]), 33, 2)],\n        dtype=[\n            ('sl', '<f8'),\n            ('al', '|O8'),\n            ('ar', '<i8'),\n            ('fk', '<i8')])\n    assert_array_equal(a2, exp2)\n    assert_equal(a2.dtype, exp2.dtype)\n\n    # scalar join\n    a3 = rnp.blockwise_inner_join(\n        test_data, ['sl', 'al'], test_data['s_fk'], ['ar'])\n    exp3 = np.array([\n        (1.0, [11, 12, 13], 1, 0),\n        (2.0, [21, 22, 23], 32, 1)],\n        dtype=[\n            ('sl', '<f8'),\n            ('al', '|O8'),\n            ('ar', '<i8'),\n            ('fk', '<i8')])\n    assert_array_equal(a3, exp3)\n    assert_equal(a3.dtype, exp3.dtype)\n"""
root_numpy/tmva/__init__.py,0,"b'try:\n    from . import _libtmvanumpy\n\nexcept ImportError:  # pragma: no cover\n    import warnings\n    warnings.warn(\n        ""root_numpy.tmva requires that you install root_numpy with ""\n        ""the tmva interface enabled"", ImportWarning)\n    __all__ = []\n\nelse:\n\n    from ._data import add_classification_events, add_regression_events\n    from ._evaluate import evaluate_reader, evaluate_method\n\n\n    __all__ = [\n        \'add_classification_events\',\n        \'add_regression_events\',\n        \'evaluate_reader\',\n        \'evaluate_method\',\n    ]\n'"
root_numpy/tmva/_data.py,11,"b'import numpy as np\nimport ROOT\nfrom ROOT import TMVA\nfrom . import _libtmvanumpy\nfrom .. import ROOT_VERSION\n\n\n__all__ = [\n    \'add_classification_events\',\n    \'add_regression_events\',\n]\n\nNEW_TMVA_API = ROOT_VERSION >= \'6.07/04\'\n\n\ndef add_classification_events(obj, events, labels, signal_label=None,\n                              weights=None, test=False):\n    """"""Add classification events to a TMVA::Factory or TMVA::DataLoader from NumPy arrays.\n\n    Parameters\n    ----------\n    obj : TMVA::Factory or TMVA::DataLoader\n        A TMVA::Factory or TMVA::DataLoader (TMVA\'s interface as of ROOT\n        6.07/04) instance with variables already booked in exactly the same\n        order as the columns in ``events``.\n    events : numpy array of shape [n_events, n_variables]\n        A two-dimensional NumPy array containing the rows of events and columns\n        of variables. The order of the columns must match the order in which\n        you called ``AddVariable()`` for each variable.\n    labels : numpy array of shape [n_events]\n        The class labels (signal or background) corresponding to each event in\n        ``events``.\n    signal_label : float or int, optional (default=None)\n        The value in ``labels`` for signal events, if ``labels`` contains only\n        two classes. If None, the highest value in ``labels`` is used.\n    weights : numpy array of shape [n_events], optional\n        Event weights.\n    test : bool, optional (default=False)\n        If True, then the events will be added as test events, otherwise they\n        are added as training events by default.\n\n    Notes\n    -----\n    * A TMVA::Factory or TMVA::DataLoader requires you to add both training and\n      test events even if you don\'t intend to call ``TestAllMethods()``.\n\n    * When using MethodCuts, the first event added must be a signal event,\n      otherwise TMVA will fail with ``<FATAL> Interval : maximum lower than\n      minimum``. To place a signal event first::\n\n        # Get index of first signal event\n        first_signal = np.nonzero(labels == signal_label)[0][0]\n        # Swap this with first event\n        events[0], events[first_signal] = events[first_signal].copy(), events[0].copy()\n        labels[0], labels[first_signal] = labels[first_signal], labels[0]\n        weights[0], weights[first_signal] = weights[first_signal], weights[0]\n\n    """"""\n    if NEW_TMVA_API:  # pragma: no cover\n        if not isinstance(obj, TMVA.DataLoader):\n            raise TypeError(\n                ""obj must be a TMVA.DataLoader ""\n                ""instance for ROOT >= 6.07/04"")\n    else:  # pragma: no cover\n        if not isinstance(obj, TMVA.Factory):\n            raise TypeError(\n                ""obj must be a TMVA.Factory instance"")\n    events = np.ascontiguousarray(events, dtype=np.float64)\n    if events.ndim == 1:\n        # convert to 2D\n        events = events[:, np.newaxis]\n    elif events.ndim != 2:\n        raise ValueError(\n            ""events must be a two-dimensional array ""\n            ""with one event per row"")\n    class_labels, class_idx = np.unique(labels, return_inverse=True)\n    if class_idx.shape[0] != events.shape[0]:\n        raise ValueError(""numbers of events and labels do not match"")\n    if weights is not None:\n        weights = np.asarray(weights, dtype=np.float64)\n        if weights.shape[0] != events.shape[0]:\n            raise ValueError(""numbers of events and weights do not match"")\n        if weights.ndim != 1:\n            raise ValueError(""weights must be one-dimensional"")\n    n_classes = class_labels.shape[0]\n    if n_classes > 2:\n        # multiclass classification\n        _libtmvanumpy.add_events_multiclass(\n            ROOT.AsCObject(obj), events, class_idx,\n            weights, test)\n    elif n_classes == 2:\n        # binary classification\n        if signal_label is None:\n            signal_label = class_labels[1]\n        signal_label = np.where(class_labels == signal_label)[0][0]\n        _libtmvanumpy.add_events_twoclass(\n            ROOT.AsCObject(obj), events, class_idx,\n            signal_label, weights, test)\n    else:\n        raise ValueError(""labels must contain at least two classes"")\n\n\ndef add_regression_events(obj, events, targets, weights=None, test=False):\n    """"""Add regression events to a TMVA::Factory or TMVA::DataLoader from NumPy arrays.\n\n    Parameters\n    ----------\n    obj : TMVA::Factory or TMVA::DataLoader\n        A TMVA::Factory or TMVA::DataLoader (TMVA\'s interface as of ROOT\n        6.07/04) instance with variables already\n        booked in exactly the same order as the columns in ``events``.\n    events : numpy array of shape [n_events, n_variables]\n        A two-dimensional NumPy array containing the rows of events and columns\n        of variables. The order of the columns must match the order in which\n        you called ``AddVariable()`` for each variable.\n    targets : numpy array of shape [n_events] or [n_events, n_targets]\n        The target value(s) for each event in ``events``. For multiple target\n        values, ``targets`` must be a two-dimensional array with a column for\n        each target in the same order in which you called ``AddTarget()``.\n    weights : numpy array of shape [n_events], optional\n        Event weights.\n    test : bool, optional (default=False)\n        If True, then the events will be added as test events, otherwise they\n        are added as training events by default.\n\n    Notes\n    -----\n    A TMVA::Factory or TMVA::DataLoader requires you to add both training and\n    test events even if you don\'t intend to call ``TestAllMethods()``.\n\n    """"""\n    if NEW_TMVA_API:  # pragma: no cover\n        if not isinstance(obj, TMVA.DataLoader):\n            raise TypeError(\n                ""obj must be a TMVA.DataLoader ""\n                ""instance for ROOT >= 6.07/04"")\n    else:  # pragma: no cover\n        if not isinstance(obj, TMVA.Factory):\n            raise TypeError(\n                ""obj must be a TMVA.Factory instance"")\n    events = np.ascontiguousarray(events, dtype=np.float64)\n    if events.ndim == 1:\n        # convert to 2D\n        events = events[:, np.newaxis]\n    elif events.ndim != 2:\n        raise ValueError(\n            ""events must be a two-dimensional array ""\n            ""with one event per row"")\n    targets = np.asarray(targets, dtype=np.float64)\n    if targets.shape[0] != events.shape[0]:\n        raise ValueError(""the lengths of events and targets do not match"")\n    if targets.ndim == 1:\n        # convert to 2D\n        targets = targets[:, np.newaxis]\n    elif targets.ndim > 2:\n        raise ValueError(""targets can not have more than two dimensions"")\n    if weights is not None:\n        weights = np.asarray(weights, dtype=np.float64)\n        if weights.shape[0] != events.shape[0]:\n            raise ValueError(""numbers of events and weights do not match"")\n        if weights.ndim != 1:\n            raise ValueError(""weights must be one-dimensional"")\n    _libtmvanumpy.add_events_regression(\n        ROOT.AsCObject(obj), events, targets, weights, test)\n'"
root_numpy/tmva/_evaluate.py,4,"b'import numpy as np\nimport ROOT\nfrom ROOT import TMVA\nfrom . import _libtmvanumpy\n\n\n__all__ = [\n    \'evaluate_reader\',\n    \'evaluate_method\',\n]\n\n\ndef evaluate_reader(reader, name, events, aux=0.):\n    """"""Evaluate a TMVA::Reader over a NumPy array.\n\n    Parameters\n    ----------\n    reader : TMVA::Reader\n        A TMVA::Factory instance with variables booked in exactly the same\n        order as the columns in ``events``.\n    name : string\n        The method name.\n    events : numpy array of shape [n_events, n_variables]\n        A two-dimensional NumPy array containing the rows of events and columns\n        of variables. The order of the columns must match the order in which\n        you called ``AddVariable()`` for each variable.\n    aux : float, optional (default=0.)\n        Auxiliary value used by MethodCuts to set the desired signal\n        efficiency.\n\n    Returns\n    -------\n    output : numpy array of shape [n_events]\n        The method output value for each event\n\n    See Also\n    --------\n    evaluate_method\n\n    """"""\n    if not isinstance(reader, TMVA.Reader):\n        raise TypeError(""reader must be a TMVA.Reader instance"")\n    events = np.ascontiguousarray(events, dtype=np.float64)\n    if events.ndim == 1:\n        # convert to 2D\n        events = events[:, np.newaxis]\n    elif events.ndim != 2:\n        raise ValueError(\n            ""events must be a two-dimensional array ""\n            ""with one event per row"")\n    return _libtmvanumpy.evaluate_reader(\n        ROOT.AsCObject(reader), name, events, aux)\n\n\ndef evaluate_method(method, events, aux=0.):\n    """"""Evaluate a TMVA::MethodBase over a NumPy array.\n\n    .. warning:: TMVA::Reader has known problems with thread safety in versions\n       of ROOT earlier than 6.03. There will potentially be a crash if you call\n       ``method = reader.FindMVA(name)`` in Python and then pass this\n       ``method`` here. Consider using ``evaluate_reader`` instead if you are\n       affected by this crash.\n\n    Parameters\n    ----------\n    method : TMVA::MethodBase\n        A TMVA::MethodBase instance with variables booked in exactly the same\n        order as the columns in ``events``.\n    events : numpy array of shape [n_events, n_variables]\n        A two-dimensional NumPy array containing the rows of events and columns\n        of variables. The order of the columns must match the order in which\n        you called ``AddVariable()`` for each variable.\n    aux : float, optional (default=0.)\n        Auxiliary value used by MethodCuts to set the desired signal\n        efficiency.\n\n    Returns\n    -------\n    output : numpy array of shape [n_events]\n        The method output value for each event\n\n    See Also\n    --------\n    evaluate_reader\n\n    """"""\n    if not isinstance(method, TMVA.MethodBase):\n        raise TypeError(""reader must be a TMVA.MethodBase instance"")\n    events = np.ascontiguousarray(events, dtype=np.float64)\n    if events.ndim == 1:\n        # convert to 2D\n        events = events[:, np.newaxis]\n    elif events.ndim != 2:\n        raise ValueError(\n            ""events must be a two-dimensional array ""\n            ""with one event per row"")\n    return _libtmvanumpy.evaluate_method(ROOT.AsCObject(method), events, aux)\n'"
root_numpy/tmva/tests.py,29,"b'from nose.plugins.skip import SkipTest\n\nSKIP = False\ntry:\n    from root_numpy.tmva import _libtmvanumpy\n    from root_numpy.tmva._data import NEW_TMVA_API\nexcept ImportError:  # pragma: no cover\n    SKIP = True\n    raise\n\nimport os\nimport tempfile\nimport shutil\nfrom array import array\nimport atexit\n\nimport numpy as np\nfrom numpy.testing import assert_array_equal\nfrom numpy.random import RandomState\n\nimport ROOT\nfrom ROOT import TFile, TCut\n\nimport root_numpy as rnp\n\nfrom nose.tools import assert_raises, assert_true, assert_equal\n\n\nROOT.gErrorIgnoreLevel = ROOT.kFatal\nRNG = RandomState(42)\n\n\ndef maybe_skip():\n    if SKIP: # pragma: no cover\n        raise SkipTest(\n            ""root_numpy is compiled with the tmva interface disabled"")\n\n\nclass TMVA_Estimator(object):\n    def __init__(self, name, n_vars, n_targets=1,\n                 method=\'BDT\', task=\'Classification\'):\n        self.name = name\n        self.n_vars = n_vars\n        self.n_targets = n_targets\n        self.method = method\n        self.task = task\n        self.tmpdir = tempfile.mkdtemp()\n        self.output = TFile(os.path.join(self.tmpdir, \'tmva_output.root\'),\n                            \'recreate\')\n        self.factory = ROOT.TMVA.Factory(\n            name, self.output, \'AnalysisType={0}:Silent\'.format(task))\n\n        if not NEW_TMVA_API:  # pragma: no cover\n            for n in range(n_vars):\n                self.factory.AddVariable(\'X_{0}\'.format(n), \'F\')\n            if task == \'Regression\':\n                for n in range(n_targets):\n                    self.factory.AddTarget(\'y_{0}\'.format(n), \'F\')\n\n    def __del__(self):\n        self.output.Close()\n        shutil.rmtree(self.tmpdir)\n\n    def fit(self, X, y, X_test=None, y_test=None,\n            weights=None, weights_test=None,\n            signal_label=None, **kwargs):\n        # (re)configure settings since deleting a previous Factory resets all\n        # this. This is poor design, TMVA.\n        config = ROOT.TMVA.gConfig()\n        config.GetIONames().fWeightFileDir = self.tmpdir\n        config.SetSilent(True)\n        config.SetDrawProgressBar(False)\n        self.factory.DeleteAllMethods()\n\n        if NEW_TMVA_API:  # pragma: no cover\n            # DataLoader name must be an empty string otherwise TMVA tries to\n            # prepend the name to the path where the weights files are located\n            obj = ROOT.TMVA.DataLoader(\'\')\n            for n in range(self.n_vars):\n                obj.AddVariable(\'X_{0}\'.format(n), \'F\')\n            if self.task == \'Regression\':\n                for n in range(self.n_targets):\n                    obj.AddTarget(\'y_{0}\'.format(n), \'F\')\n        else:  # pragma: no cover\n            obj = self.factory\n\n        extra_kwargs = dict()\n        if self.task == \'Regression\':\n            func = rnp.tmva.add_regression_events\n        else:\n            func = rnp.tmva.add_classification_events\n            extra_kwargs[\'signal_label\'] = signal_label\n\n        # test exceptions\n        assert_raises(TypeError, func, object(), X, y)\n        assert_raises(ValueError, func, obj, X, y[:y.shape[0] // 2])\n        if weights is not None:\n            assert_raises(ValueError, func, obj, X, y,\n                          weights=weights[:weights.shape[0] // 2])\n            assert_raises(ValueError, func, obj, X, y,\n                          weights=weights[:, np.newaxis])\n\n        assert_raises(ValueError, func, obj, [[[1, 2]]], [1])\n        assert_raises(ValueError, func, obj, [[1, 2]], [[[1]]])\n\n        func(obj, X, y, weights=weights, **extra_kwargs)\n\n        if X_test is None:\n            X_test = X\n            y_test = y\n            weights_test = weights\n        func(obj, X_test, y_test,\n             weights=weights_test, test=True, **extra_kwargs)\n\n        obj.PrepareTrainingAndTestTree(TCut(\'1\'), \'NormMode=EqualNumEvents\')\n        options = []\n        for param, value in kwargs.items():\n            if value is True:\n                options.append(param)\n            elif value is False:\n                options.append(\'!{0}\'.format(param))\n            else:\n                options.append(\'{0}={1}\'.format(param, value))\n        options = \':\'.join(options)\n        if NEW_TMVA_API:  # pragma: no cover\n            self.factory.BookMethod(obj, self.method, self.method, options)\n        else:  # pragma: no cover\n            self.factory.BookMethod(self.method, self.method, options)\n        self.factory.TrainAllMethods()\n\n    def predict(self, X, aux=0.):\n        reader = ROOT.TMVA.Reader()\n        for n in range(self.n_vars):\n            reader.AddVariable(\'X_{0}\'.format(n), array(\'f\', [0.]))\n        reader.BookMVA(self.method,\n                       os.path.join(self.tmpdir,\n                                    \'{0}_{1}.weights.xml\'.format(\n                                        self.name, self.method)))\n        assert_raises(TypeError, rnp.tmva.evaluate_reader,\n                      object(), self.method, X)\n        assert_raises(ValueError, rnp.tmva.evaluate_reader,\n                      reader, \'DoesNotExist\', X)\n        assert_raises(ValueError, rnp.tmva.evaluate_reader,\n                      reader, self.method, [[[1]]])\n        if self.task != \'Regression\':\n            assert_raises(ValueError, rnp.tmva.evaluate_reader,\n                          reader, self.method, [1, 2, 3])\n        output = rnp.tmva.evaluate_reader(reader, self.method, X, aux)\n        if ROOT.gROOT.GetVersionInt() >= 60300:  # pragma: no cover\n            method = reader.FindMVA(self.method)\n            assert_raises(TypeError, rnp.tmva.evaluate_method,\n                          object(), X)\n            assert_raises(ValueError, rnp.tmva.evaluate_method,\n                          method, [[[1]]])\n            output_method = rnp.tmva.evaluate_method(method, X, aux)\n            assert_array_equal(output, output_method)\n        return output\n\n\ndef make_classification(n_features, n_events_per_class, n_classes):\n    blobs = []\n    for idx in range(n_classes):\n        blob = RNG.multivariate_normal(\n            np.ones(n_features) * idx * 5,\n            np.diag(np.ones(n_features)),\n            n_events_per_class)\n        blobs.append(blob)\n    X = np.concatenate(blobs)\n    # class labels\n    y = np.repeat(np.arange(n_classes), n_events_per_class) * 2 - 1\n    # event weights\n    w = RNG.randint(1, 10, n_events_per_class * n_classes)\n    # shuffle\n    permute = RNG.permutation(y.shape[0])\n    X = X[permute]\n    y = y[permute]\n    return X, y, w\n\n\ndef test_tmva_methodcuts():\n    maybe_skip()\n    X, y, w = make_classification(2, 300, 2)\n    est = TMVA_Estimator(\'Cuts\', 2, method=\'Cuts\')\n    est.fit(X, y,\n            FitMethod=\'MC\', EffSel=True, SampleSize=100,\n            VarProp=\'FSmart\')\n    y_predict_1 = est.predict(X, 0.1)\n    y_predict_9 = est.predict(X, 0.9)\n    assert_true((y_predict_1 != y_predict_9).any())\n    assert_true((y_predict_1 <= y_predict_9).all())\n\n\ndef test_tmva_twoclass():\n    maybe_skip()\n    n_vars = 2\n    n_events = 1000\n    X, y, w = make_classification(n_vars, n_events, 2)\n    X_train, y_train, w_train = X[:n_events], y[:n_events], w[:n_events]\n    X_test, y_test, w_test = X[n_events:], y[n_events:], w[n_events:]\n\n    clf = TMVA_Estimator(\'unweighted\', n_vars)\n    clf.fit(X_train, y_train, X_test=X_test, y_test=y_test,\n            nCuts=20, NTrees=10, MaxDepth=3)\n    y_decision = clf.predict(X_test)\n    y_predicted = 2 * (y_decision > 0) - 1\n    assert_true(np.sum(np.abs(y_predicted - y_test)) < 0.1 * y_test.shape[0])\n\n    clf = TMVA_Estimator(\'unweighted_label\', n_vars)\n    clf.fit(X_train, y_train, X_test=X_test, y_test=y_test, signal_label=1,\n            nCuts=20, NTrees=10, MaxDepth=3)\n    y_decision_label = clf.predict(X_test)\n    assert_array_equal(y_decision_label, y_decision)\n\n    # train with weights\n    clf = TMVA_Estimator(\'weighted\', n_vars)\n    clf.fit(X_train, y_train, X_test=X_test, y_test=y_test,\n            weights=w_train, weights_test=w_test,\n            nCuts=20, NTrees=10, MaxDepth=3)\n    y_decision_weighted = clf.predict(X_test)\n    assert_true(np.any(y_decision_weighted != y_decision))\n\n    # unit weights should not change output\n    clf = TMVA_Estimator(\'unit_weights\', n_vars)\n    clf.fit(X_train, y_train, X_test=X_test, y_test=y_test,\n            weights=np.ones(y_train.shape[0]),\n            weights_test=np.ones(y_test.shape[0]),\n            nCuts=20, NTrees=10, MaxDepth=3)\n    y_decision_unit_weights = clf.predict(X_test)\n    assert_array_equal(y_decision, y_decision_unit_weights)\n\n    # events can be 1D\n    clf = TMVA_Estimator(\'onedim_events\', 1)\n    clf.fit(X_train[:, 0], y_train, X_test=X_test[:, 0], y_test=y_test,\n            nCuts=20, NTrees=10, MaxDepth=3)\n\n\ndef test_tmva_multiclass():\n    maybe_skip()\n    n_vars = 2\n    n_events = 500\n    X, y, w = make_classification(n_vars, n_events, 3)\n\n    # Split into training and test datasets\n    X_train, y_train, w_train = X[:n_events], y[:n_events], w[:n_events]\n    X_test, y_test, w_test = X[n_events:], y[n_events:], w[n_events:]\n\n    clf = TMVA_Estimator(\'unweighted\', n_vars, task=\'Multiclass\')\n    clf.fit(X_train, y_train, X_test=X_test, y_test=y_test,\n            nCuts=20, NTrees=10, MaxDepth=3,\n            BoostType=\'Grad\', Shrinkage=\'0.10\')\n    y_decision = clf.predict(X_test)\n    # Class probabilities should sum to one\n    assert_array_equal(np.sum(y_decision, axis=1),\n                       np.ones(y_decision.shape[0]))\n\n\ndef test_tmva_regression():\n    maybe_skip()\n    X = np.linspace(0, 6, 100)[:, np.newaxis]\n    y = np.sin(X).ravel() + \\\n        np.sin(6 * X).ravel() + \\\n        RNG.normal(0, 0.1, X.shape[0])\n    w = RNG.randint(1, 10, y.shape[0])\n\n    reg = TMVA_Estimator(\'regressor\', 1, task=\'Regression\')\n    reg.fit(np.ravel(X), y, X_test=X, y_test=y,\n            nCuts=20, NTrees=10, MaxDepth=3,\n            boosttype=\'AdaBoostR2\', SeparationType=\'RegressionVariance\')\n    y_predict = reg.predict(np.ravel(X))\n    assert_equal(y_predict.ndim, 1)\n\n    # train with weights\n    reg = TMVA_Estimator(\'regressor_weighted\', 1, task=\'Regression\')\n    reg.fit(X, y, X_test=X, y_test=y, weights=w, weights_test=w,\n            nCuts=20, NTrees=10, MaxDepth=3,\n            boosttype=\'AdaBoostR2\', SeparationType=\'RegressionVariance\')\n    y_predict_weighted = reg.predict(X)\n    assert_true(np.any(y_predict_weighted != y_predict))\n\n    # unit weights should not change output\n    reg = TMVA_Estimator(\'regressor_unit_weights\', 1, task=\'Regression\')\n    reg.fit(X, y, X_test=X, y_test=y,\n            weights=np.ones(y.shape[0]), weights_test=np.ones(y.shape[0]),\n            nCuts=20, NTrees=10, MaxDepth=3,\n            boosttype=\'AdaBoostR2\', SeparationType=\'RegressionVariance\')\n    y_predict_unit_weights = reg.predict(X)\n    assert_array_equal(y_predict_unit_weights, y_predict)\n\n    # Multi-output\n    y_multi = np.c_[y, 1. - y]\n    reg = TMVA_Estimator(\'regressor_multioutput\', 1, n_targets=2,\n                         method=\'KNN\', task=\'Regression\')\n    reg.fit(X, y_multi, X_test=X, y_test=y_multi,\n            nkNN=20, ScaleFrac=0.8, SigmaFact=1.0, Kernel=\'Gaus\', UseKernel=\'F\',\n            UseWeight=\'T\')\n    y_predict = reg.predict(X)\n    assert_equal(y_predict.ndim, 2)\n'"
docs/sphinxext/numpydoc/__init__.py,0,"b'from __future__ import division, absolute_import, print_function\n\nfrom .numpydoc import setup\n'"
docs/sphinxext/numpydoc/comment_eater.py,0,"b'from __future__ import division, absolute_import, print_function\n\nimport sys\nif sys.version_info[0] >= 3:\n    from io import StringIO\nelse:\n    from io import StringIO\n\nimport compiler\nimport inspect\nimport textwrap\nimport tokenize\n\nfrom .compiler_unparse import unparse\n\n\nclass Comment(object):\n    """""" A comment block.\n    """"""\n    is_comment = True\n    def __init__(self, start_lineno, end_lineno, text):\n        # int : The first line number in the block. 1-indexed.\n        self.start_lineno = start_lineno\n        # int : The last line number. Inclusive!\n        self.end_lineno = end_lineno\n        # str : The text block including \'#\' character but not any leading spaces.\n        self.text = text\n\n    def add(self, string, start, end, line):\n        """""" Add a new comment line.\n        """"""\n        self.start_lineno = min(self.start_lineno, start[0])\n        self.end_lineno = max(self.end_lineno, end[0])\n        self.text += string\n\n    def __repr__(self):\n        return \'%s(%r, %r, %r)\' % (self.__class__.__name__, self.start_lineno,\n            self.end_lineno, self.text)\n\n\nclass NonComment(object):\n    """""" A non-comment block of code.\n    """"""\n    is_comment = False\n    def __init__(self, start_lineno, end_lineno):\n        self.start_lineno = start_lineno\n        self.end_lineno = end_lineno\n\n    def add(self, string, start, end, line):\n        """""" Add lines to the block.\n        """"""\n        if string.strip():\n            # Only add if not entirely whitespace.\n            self.start_lineno = min(self.start_lineno, start[0])\n            self.end_lineno = max(self.end_lineno, end[0])\n\n    def __repr__(self):\n        return \'%s(%r, %r)\' % (self.__class__.__name__, self.start_lineno,\n            self.end_lineno)\n\n\nclass CommentBlocker(object):\n    """""" Pull out contiguous comment blocks.\n    """"""\n    def __init__(self):\n        # Start with a dummy.\n        self.current_block = NonComment(0, 0)\n\n        # All of the blocks seen so far.\n        self.blocks = []\n\n        # The index mapping lines of code to their associated comment blocks.\n        self.index = {}\n\n    def process_file(self, file):\n        """""" Process a file object.\n        """"""\n        if sys.version_info[0] >= 3:\n            nxt = file.__next__\n        else:\n            nxt = file.next\n        for token in tokenize.generate_tokens(nxt):\n            self.process_token(*token)\n        self.make_index()\n\n    def process_token(self, kind, string, start, end, line):\n        """""" Process a single token.\n        """"""\n        if self.current_block.is_comment:\n            if kind == tokenize.COMMENT:\n                self.current_block.add(string, start, end, line)\n            else:\n                self.new_noncomment(start[0], end[0])\n        else:\n            if kind == tokenize.COMMENT:\n                self.new_comment(string, start, end, line)\n            else:\n                self.current_block.add(string, start, end, line)\n\n    def new_noncomment(self, start_lineno, end_lineno):\n        """""" We are transitioning from a noncomment to a comment.\n        """"""\n        block = NonComment(start_lineno, end_lineno)\n        self.blocks.append(block)\n        self.current_block = block\n\n    def new_comment(self, string, start, end, line):\n        """""" Possibly add a new comment.\n\n        Only adds a new comment if this comment is the only thing on the line.\n        Otherwise, it extends the noncomment block.\n        """"""\n        prefix = line[:start[1]]\n        if prefix.strip():\n            # Oops! Trailing comment, not a comment block.\n            self.current_block.add(string, start, end, line)\n        else:\n            # A comment block.\n            block = Comment(start[0], end[0], string)\n            self.blocks.append(block)\n            self.current_block = block\n\n    def make_index(self):\n        """""" Make the index mapping lines of actual code to their associated\n        prefix comments.\n        """"""\n        for prev, block in zip(self.blocks[:-1], self.blocks[1:]):\n            if not block.is_comment:\n                self.index[block.start_lineno] = prev\n\n    def search_for_comment(self, lineno, default=None):\n        """""" Find the comment block just before the given line number.\n\n        Returns None (or the specified default) if there is no such block.\n        """"""\n        if not self.index:\n            self.make_index()\n        block = self.index.get(lineno, None)\n        text = getattr(block, \'text\', default)\n        return text\n\n\ndef strip_comment_marker(text):\n    """""" Strip # markers at the front of a block of comment text.\n    """"""\n    lines = []\n    for line in text.splitlines():\n        lines.append(line.lstrip(\'#\'))\n    text = textwrap.dedent(\'\\n\'.join(lines))\n    return text\n\n\ndef get_class_traits(klass):\n    """""" Yield all of the documentation for trait definitions on a class object.\n    """"""\n    # FIXME: gracefully handle errors here or in the caller?\n    source = inspect.getsource(klass)\n    cb = CommentBlocker()\n    cb.process_file(StringIO(source))\n    mod_ast = compiler.parse(source)\n    class_ast = mod_ast.node.nodes[0]\n    for node in class_ast.code.nodes:\n        # FIXME: handle other kinds of assignments?\n        if isinstance(node, compiler.ast.Assign):\n            name = node.nodes[0].name\n            rhs = unparse(node.expr).strip()\n            doc = strip_comment_marker(cb.search_for_comment(node.lineno, default=\'\'))\n            yield name, rhs, doc\n\n'"
docs/sphinxext/numpydoc/compiler_unparse.py,0,"b'"""""" Turn compiler.ast structures back into executable python code.\n\n    The unparse method takes a compiler.ast tree and transforms it back into\n    valid python code.  It is incomplete and currently only works for\n    import statements, function calls, function definitions, assignments, and\n    basic expressions.\n\n    Inspired by python-2.5-svn/Demo/parser/unparse.py\n\n    fixme: We may want to move to using _ast trees because the compiler for\n           them is about 6 times faster than compiler.compile.\n""""""\nfrom __future__ import division, absolute_import, print_function\n\nimport sys\nfrom compiler.ast import Const, Name, Tuple, Div, Mul, Sub, Add\n\nif sys.version_info[0] >= 3:\n    from io import StringIO\nelse:\n    from StringIO import StringIO\n\ndef unparse(ast, single_line_functions=False):\n    s = StringIO()\n    UnparseCompilerAst(ast, s, single_line_functions)\n    return s.getvalue().lstrip()\n\nop_precedence = { \'compiler.ast.Power\':3, \'compiler.ast.Mul\':2, \'compiler.ast.Div\':2,\n                  \'compiler.ast.Add\':1, \'compiler.ast.Sub\':1 }\n\nclass UnparseCompilerAst:\n    """""" Methods in this class recursively traverse an AST and\n        output source code for the abstract syntax; original formatting\n        is disregarged.\n    """"""\n\n    #########################################################################\n    # object interface.\n    #########################################################################\n\n    def __init__(self, tree, file = sys.stdout, single_line_functions=False):\n        """""" Unparser(tree, file=sys.stdout) -> None.\n\n            Print the source for tree to file.\n        """"""\n        self.f = file\n        self._single_func = single_line_functions\n        self._do_indent = True\n        self._indent = 0\n        self._dispatch(tree)\n        self._write(""\\n"")\n        self.f.flush()\n\n    #########################################################################\n    # Unparser private interface.\n    #########################################################################\n\n    ### format, output, and dispatch methods ################################\n\n    def _fill(self, text = """"):\n        ""Indent a piece of text, according to the current indentation level""\n        if self._do_indent:\n            self._write(""\\n""+""    ""*self._indent + text)\n        else:\n            self._write(text)\n\n    def _write(self, text):\n        ""Append a piece of text to the current line.""\n        self.f.write(text)\n\n    def _enter(self):\n        ""Print \':\', and increase the indentation.""\n        self._write("": "")\n        self._indent += 1\n\n    def _leave(self):\n        ""Decrease the indentation level.""\n        self._indent -= 1\n\n    def _dispatch(self, tree):\n        ""_dispatcher function, _dispatching tree type T to method _T.""\n        if isinstance(tree, list):\n            for t in tree:\n                self._dispatch(t)\n            return\n        meth = getattr(self, ""_""+tree.__class__.__name__)\n        if tree.__class__.__name__ == \'NoneType\' and not self._do_indent:\n            return\n        meth(tree)\n\n\n    #########################################################################\n    # compiler.ast unparsing methods.\n    #\n    # There should be one method per concrete grammar type. They are\n    # organized in alphabetical order.\n    #########################################################################\n\n    def _Add(self, t):\n        self.__binary_op(t, \'+\')\n\n    def _And(self, t):\n        self._write("" ("")\n        for i, node in enumerate(t.nodes):\n            self._dispatch(node)\n            if i != len(t.nodes)-1:\n                self._write("") and ("")\n        self._write("")"")\n\n    def _AssAttr(self, t):\n        """""" Handle assigning an attribute of an object\n        """"""\n        self._dispatch(t.expr)\n        self._write(\'.\'+t.attrname)\n\n    def _Assign(self, t):\n        """""" Expression Assignment such as ""a = 1"".\n\n            This only handles assignment in expressions.  Keyword assignment\n            is handled separately.\n        """"""\n        self._fill()\n        for target in t.nodes:\n            self._dispatch(target)\n            self._write("" = "")\n        self._dispatch(t.expr)\n        if not self._do_indent:\n            self._write(\'; \')\n\n    def _AssName(self, t):\n        """""" Name on left hand side of expression.\n\n            Treat just like a name on the right side of an expression.\n        """"""\n        self._Name(t)\n\n    def _AssTuple(self, t):\n        """""" Tuple on left hand side of an expression.\n        """"""\n\n        # _write each elements, separated by a comma.\n        for element in t.nodes[:-1]:\n            self._dispatch(element)\n            self._write("", "")\n\n        # Handle the last one without writing comma\n        last_element = t.nodes[-1]\n        self._dispatch(last_element)\n\n    def _AugAssign(self, t):\n        """""" +=,-=,*=,/=,**=, etc. operations\n        """"""\n\n        self._fill()\n        self._dispatch(t.node)\n        self._write(\' \'+t.op+\' \')\n        self._dispatch(t.expr)\n        if not self._do_indent:\n            self._write(\';\')\n\n    def _Bitand(self, t):\n        """""" Bit and operation.\n        """"""\n\n        for i, node in enumerate(t.nodes):\n            self._write(""("")\n            self._dispatch(node)\n            self._write("")"")\n            if i != len(t.nodes)-1:\n                self._write("" & "")\n\n    def _Bitor(self, t):\n        """""" Bit or operation\n        """"""\n\n        for i, node in enumerate(t.nodes):\n            self._write(""("")\n            self._dispatch(node)\n            self._write("")"")\n            if i != len(t.nodes)-1:\n                self._write("" | "")\n\n    def _CallFunc(self, t):\n        """""" Function call.\n        """"""\n        self._dispatch(t.node)\n        self._write(""("")\n        comma = False\n        for e in t.args:\n            if comma: self._write("", "")\n            else: comma = True\n            self._dispatch(e)\n        if t.star_args:\n            if comma: self._write("", "")\n            else: comma = True\n            self._write(""*"")\n            self._dispatch(t.star_args)\n        if t.dstar_args:\n            if comma: self._write("", "")\n            else: comma = True\n            self._write(""**"")\n            self._dispatch(t.dstar_args)\n        self._write("")"")\n\n    def _Compare(self, t):\n        self._dispatch(t.expr)\n        for op, expr in t.ops:\n            self._write("" "" + op + "" "")\n            self._dispatch(expr)\n\n    def _Const(self, t):\n        """""" A constant value such as an integer value, 3, or a string, ""hello"".\n        """"""\n        self._dispatch(t.value)\n\n    def _Decorators(self, t):\n        """""" Handle function decorators (eg. @has_units)\n        """"""\n        for node in t.nodes:\n            self._dispatch(node)\n\n    def _Dict(self, t):\n        self._write(""{"")\n        for  i, (k, v) in enumerate(t.items):\n            self._dispatch(k)\n            self._write("": "")\n            self._dispatch(v)\n            if i < len(t.items)-1:\n                self._write("", "")\n        self._write(""}"")\n\n    def _Discard(self, t):\n        """""" Node for when return value is ignored such as in ""foo(a)"".\n        """"""\n        self._fill()\n        self._dispatch(t.expr)\n\n    def _Div(self, t):\n        self.__binary_op(t, \'/\')\n\n    def _Ellipsis(self, t):\n        self._write(""..."")\n\n    def _From(self, t):\n        """""" Handle ""from xyz import foo, bar as baz"".\n        """"""\n        # fixme: Are From and ImportFrom handled differently?\n        self._fill(""from "")\n        self._write(t.modname)\n        self._write("" import "")\n        for i, (name,asname) in enumerate(t.names):\n            if i != 0:\n                self._write("", "")\n            self._write(name)\n            if asname is not None:\n                self._write("" as ""+asname)\n\n    def _Function(self, t):\n        """""" Handle function definitions\n        """"""\n        if t.decorators is not None:\n            self._fill(""@"")\n            self._dispatch(t.decorators)\n        self._fill(""def ""+t.name + ""("")\n        defaults = [None] * (len(t.argnames) - len(t.defaults)) + list(t.defaults)\n        for i, arg in enumerate(zip(t.argnames, defaults)):\n            self._write(arg[0])\n            if arg[1] is not None:\n                self._write(\'=\')\n                self._dispatch(arg[1])\n            if i < len(t.argnames)-1:\n                self._write(\', \')\n        self._write("")"")\n        if self._single_func:\n            self._do_indent = False\n        self._enter()\n        self._dispatch(t.code)\n        self._leave()\n        self._do_indent = True\n\n    def _Getattr(self, t):\n        """""" Handle getting an attribute of an object\n        """"""\n        if isinstance(t.expr, (Div, Mul, Sub, Add)):\n            self._write(\'(\')\n            self._dispatch(t.expr)\n            self._write(\')\')\n        else:\n            self._dispatch(t.expr)\n            \n        self._write(\'.\'+t.attrname)\n        \n    def _If(self, t):\n        self._fill()\n        \n        for i, (compare,code) in enumerate(t.tests):\n            if i == 0:\n                self._write(""if "")\n            else:\n                self._write(""elif "")\n            self._dispatch(compare)\n            self._enter()\n            self._fill()\n            self._dispatch(code)\n            self._leave()\n            self._write(""\\n"")\n\n        if t.else_ is not None:\n            self._write(""else"")\n            self._enter()\n            self._fill()\n            self._dispatch(t.else_)\n            self._leave()\n            self._write(""\\n"")\n            \n    def _IfExp(self, t):\n        self._dispatch(t.then)\n        self._write("" if "")\n        self._dispatch(t.test)\n\n        if t.else_ is not None:\n            self._write("" else ("")\n            self._dispatch(t.else_)\n            self._write("")"")\n\n    def _Import(self, t):\n        """""" Handle ""import xyz.foo"".\n        """"""\n        self._fill(""import "")\n        \n        for i, (name,asname) in enumerate(t.names):\n            if i != 0:\n                self._write("", "")\n            self._write(name)\n            if asname is not None:\n                self._write("" as ""+asname)\n\n    def _Keyword(self, t):\n        """""" Keyword value assignment within function calls and definitions.\n        """"""\n        self._write(t.name)\n        self._write(""="")\n        self._dispatch(t.expr)\n        \n    def _List(self, t):\n        self._write(""["")\n        for  i,node in enumerate(t.nodes):\n            self._dispatch(node)\n            if i < len(t.nodes)-1:\n                self._write("", "")\n        self._write(""]"")\n\n    def _Module(self, t):\n        if t.doc is not None:\n            self._dispatch(t.doc)\n        self._dispatch(t.node)\n\n    def _Mul(self, t):\n        self.__binary_op(t, \'*\')\n\n    def _Name(self, t):\n        self._write(t.name)\n\n    def _NoneType(self, t):\n        self._write(""None"")\n        \n    def _Not(self, t):\n        self._write(\'not (\')\n        self._dispatch(t.expr)\n        self._write(\')\')\n        \n    def _Or(self, t):\n        self._write("" ("")\n        for i, node in enumerate(t.nodes):\n            self._dispatch(node)\n            if i != len(t.nodes)-1:\n                self._write("") or ("")\n        self._write("")"")\n                \n    def _Pass(self, t):\n        self._write(""pass\\n"")\n\n    def _Printnl(self, t):\n        self._fill(""print "")\n        if t.dest:\n            self._write("">> "")\n            self._dispatch(t.dest)\n            self._write("", "")\n        comma = False\n        for node in t.nodes:\n            if comma: self._write(\', \')\n            else: comma = True\n            self._dispatch(node)\n\n    def _Power(self, t):\n        self.__binary_op(t, \'**\')\n\n    def _Return(self, t):\n        self._fill(""return "")\n        if t.value:\n            if isinstance(t.value, Tuple):\n                text = \', \'.join([ name.name for name in t.value.asList() ])\n                self._write(text)\n            else:\n                self._dispatch(t.value)\n            if not self._do_indent:\n                self._write(\'; \')\n\n    def _Slice(self, t):\n        self._dispatch(t.expr)\n        self._write(""["")\n        if t.lower:\n            self._dispatch(t.lower)\n        self._write("":"")\n        if t.upper:\n            self._dispatch(t.upper)\n        #if t.step:\n        #    self._write("":"")\n        #    self._dispatch(t.step)\n        self._write(""]"")\n\n    def _Sliceobj(self, t):\n        for i, node in enumerate(t.nodes):\n            if i != 0:\n                self._write("":"")\n            if not (isinstance(node, Const) and node.value is None):\n                self._dispatch(node)\n\n    def _Stmt(self, tree):\n        for node in tree.nodes:\n            self._dispatch(node)\n\n    def _Sub(self, t):\n        self.__binary_op(t, \'-\')\n\n    def _Subscript(self, t):\n        self._dispatch(t.expr)\n        self._write(""["")\n        for i, value in enumerate(t.subs):\n            if i != 0:\n                self._write("","")\n            self._dispatch(value)\n        self._write(""]"")\n\n    def _TryExcept(self, t):\n        self._fill(""try"")\n        self._enter()\n        self._dispatch(t.body)\n        self._leave()\n\n        for handler in t.handlers:\n            self._fill(\'except \')\n            self._dispatch(handler[0])\n            if handler[1] is not None:\n                self._write(\', \')\n                self._dispatch(handler[1])\n            self._enter()\n            self._dispatch(handler[2])\n            self._leave()\n            \n        if t.else_:\n            self._fill(""else"")\n            self._enter()\n            self._dispatch(t.else_)\n            self._leave()\n\n    def _Tuple(self, t):\n\n        if not t.nodes:\n            # Empty tuple.\n            self._write(""()"")\n        else:\n            self._write(""("")\n\n            # _write each elements, separated by a comma.\n            for element in t.nodes[:-1]:\n                self._dispatch(element)\n                self._write("", "")\n\n            # Handle the last one without writing comma\n            last_element = t.nodes[-1]\n            self._dispatch(last_element)\n\n            self._write("")"")\n            \n    def _UnaryAdd(self, t):\n        self._write(""+"")\n        self._dispatch(t.expr)\n        \n    def _UnarySub(self, t):\n        self._write(""-"")\n        self._dispatch(t.expr)        \n\n    def _With(self, t):\n        self._fill(\'with \')\n        self._dispatch(t.expr)\n        if t.vars:\n            self._write(\' as \')\n            self._dispatch(t.vars.name)\n        self._enter()\n        self._dispatch(t.body)\n        self._leave()\n        self._write(\'\\n\')\n        \n    def _int(self, t):\n        self._write(repr(t))\n\n    def __binary_op(self, t, symbol):\n        # Check if parenthesis are needed on left side and then dispatch\n        has_paren = False\n        left_class = str(t.left.__class__)\n        if (left_class in op_precedence.keys() and\n            op_precedence[left_class] < op_precedence[str(t.__class__)]):\n            has_paren = True\n        if has_paren:\n            self._write(\'(\')\n        self._dispatch(t.left)\n        if has_paren:\n            self._write(\')\')\n        # Write the appropriate symbol for operator\n        self._write(symbol)\n        # Check if parenthesis are needed on the right side and then dispatch\n        has_paren = False\n        right_class = str(t.right.__class__)\n        if (right_class in op_precedence.keys() and\n            op_precedence[right_class] < op_precedence[str(t.__class__)]):\n            has_paren = True\n        if has_paren:\n            self._write(\'(\')\n        self._dispatch(t.right)\n        if has_paren:\n            self._write(\')\')\n\n    def _float(self, t):\n        # if t is 0.1, str(t)->\'0.1\' while repr(t)->\'0.1000000000001\'\n        # We prefer str here.\n        self._write(str(t))\n\n    def _str(self, t):\n        self._write(repr(t))\n        \n    def _tuple(self, t):\n        self._write(str(t))\n\n    #########################################################################\n    # These are the methods from the _ast modules unparse.\n    #\n    # As our needs to handle more advanced code increase, we may want to\n    # modify some of the methods below so that they work for compiler.ast.\n    #########################################################################\n\n#    # stmt\n#    def _Expr(self, tree):\n#        self._fill()\n#        self._dispatch(tree.value)\n#\n#    def _Import(self, t):\n#        self._fill(""import "")\n#        first = True\n#        for a in t.names:\n#            if first:\n#                first = False\n#            else:\n#                self._write("", "")\n#            self._write(a.name)\n#            if a.asname:\n#                self._write("" as ""+a.asname)\n#\n##    def _ImportFrom(self, t):\n##        self._fill(""from "")\n##        self._write(t.module)\n##        self._write("" import "")\n##        for i, a in enumerate(t.names):\n##            if i == 0:\n##                self._write("", "")\n##            self._write(a.name)\n##            if a.asname:\n##                self._write("" as ""+a.asname)\n##        # XXX(jpe) what is level for?\n##\n#\n#    def _Break(self, t):\n#        self._fill(""break"")\n#\n#    def _Continue(self, t):\n#        self._fill(""continue"")\n#\n#    def _Delete(self, t):\n#        self._fill(""del "")\n#        self._dispatch(t.targets)\n#\n#    def _Assert(self, t):\n#        self._fill(""assert "")\n#        self._dispatch(t.test)\n#        if t.msg:\n#            self._write("", "")\n#            self._dispatch(t.msg)\n#\n#    def _Exec(self, t):\n#        self._fill(""exec "")\n#        self._dispatch(t.body)\n#        if t.globals:\n#            self._write("" in "")\n#            self._dispatch(t.globals)\n#        if t.locals:\n#            self._write("", "")\n#            self._dispatch(t.locals)\n#\n#    def _Print(self, t):\n#        self._fill(""print "")\n#        do_comma = False\n#        if t.dest:\n#            self._write("">>"")\n#            self._dispatch(t.dest)\n#            do_comma = True\n#        for e in t.values:\n#            if do_comma:self._write("", "")\n#            else:do_comma=True\n#            self._dispatch(e)\n#        if not t.nl:\n#            self._write("","")\n#\n#    def _Global(self, t):\n#        self._fill(""global"")\n#        for i, n in enumerate(t.names):\n#            if i != 0:\n#                self._write("","")\n#            self._write("" "" + n)\n#\n#    def _Yield(self, t):\n#        self._fill(""yield"")\n#        if t.value:\n#            self._write("" ("")\n#            self._dispatch(t.value)\n#            self._write("")"")\n#\n#    def _Raise(self, t):\n#        self._fill(\'raise \')\n#        if t.type:\n#            self._dispatch(t.type)\n#        if t.inst:\n#            self._write("", "")\n#            self._dispatch(t.inst)\n#        if t.tback:\n#            self._write("", "")\n#            self._dispatch(t.tback)\n#\n#\n#    def _TryFinally(self, t):\n#        self._fill(""try"")\n#        self._enter()\n#        self._dispatch(t.body)\n#        self._leave()\n#\n#        self._fill(""finally"")\n#        self._enter()\n#        self._dispatch(t.finalbody)\n#        self._leave()\n#\n#    def _excepthandler(self, t):\n#        self._fill(""except "")\n#        if t.type:\n#            self._dispatch(t.type)\n#        if t.name:\n#            self._write("", "")\n#            self._dispatch(t.name)\n#        self._enter()\n#        self._dispatch(t.body)\n#        self._leave()\n#\n#    def _ClassDef(self, t):\n#        self._write(""\\n"")\n#        self._fill(""class ""+t.name)\n#        if t.bases:\n#            self._write(""("")\n#            for a in t.bases:\n#                self._dispatch(a)\n#                self._write("", "")\n#            self._write("")"")\n#        self._enter()\n#        self._dispatch(t.body)\n#        self._leave()\n#\n#    def _FunctionDef(self, t):\n#        self._write(""\\n"")\n#        for deco in t.decorators:\n#            self._fill(""@"")\n#            self._dispatch(deco)\n#        self._fill(""def ""+t.name + ""("")\n#        self._dispatch(t.args)\n#        self._write("")"")\n#        self._enter()\n#        self._dispatch(t.body)\n#        self._leave()\n#\n#    def _For(self, t):\n#        self._fill(""for "")\n#        self._dispatch(t.target)\n#        self._write("" in "")\n#        self._dispatch(t.iter)\n#        self._enter()\n#        self._dispatch(t.body)\n#        self._leave()\n#        if t.orelse:\n#            self._fill(""else"")\n#            self._enter()\n#            self._dispatch(t.orelse)\n#            self._leave\n#\n#    def _While(self, t):\n#        self._fill(""while "")\n#        self._dispatch(t.test)\n#        self._enter()\n#        self._dispatch(t.body)\n#        self._leave()\n#        if t.orelse:\n#            self._fill(""else"")\n#            self._enter()\n#            self._dispatch(t.orelse)\n#            self._leave\n#\n#    # expr\n#    def _Str(self, tree):\n#        self._write(repr(tree.s))\n##\n#    def _Repr(self, t):\n#        self._write(""`"")\n#        self._dispatch(t.value)\n#        self._write(""`"")\n#\n#    def _Num(self, t):\n#        self._write(repr(t.n))\n#\n#    def _ListComp(self, t):\n#        self._write(""["")\n#        self._dispatch(t.elt)\n#        for gen in t.generators:\n#            self._dispatch(gen)\n#        self._write(""]"")\n#\n#    def _GeneratorExp(self, t):\n#        self._write(""("")\n#        self._dispatch(t.elt)\n#        for gen in t.generators:\n#            self._dispatch(gen)\n#        self._write("")"")\n#\n#    def _comprehension(self, t):\n#        self._write("" for "")\n#        self._dispatch(t.target)\n#        self._write("" in "")\n#        self._dispatch(t.iter)\n#        for if_clause in t.ifs:\n#            self._write("" if "")\n#            self._dispatch(if_clause)\n#\n#    def _IfExp(self, t):\n#        self._dispatch(t.body)\n#        self._write("" if "")\n#        self._dispatch(t.test)\n#        if t.orelse:\n#            self._write("" else "")\n#            self._dispatch(t.orelse)\n#\n#    unop = {""Invert"":""~"", ""Not"": ""not"", ""UAdd"":""+"", ""USub"":""-""}\n#    def _UnaryOp(self, t):\n#        self._write(self.unop[t.op.__class__.__name__])\n#        self._write(""("")\n#        self._dispatch(t.operand)\n#        self._write("")"")\n#\n#    binop = { ""Add"":""+"", ""Sub"":""-"", ""Mult"":""*"", ""Div"":""/"", ""Mod"":""%"",\n#                    ""LShift"":"">>"", ""RShift"":""<<"", ""BitOr"":""|"", ""BitXor"":""^"", ""BitAnd"":""&"",\n#                    ""FloorDiv"":""//"", ""Pow"": ""**""}\n#    def _BinOp(self, t):\n#        self._write(""("")\n#        self._dispatch(t.left)\n#        self._write("")"" + self.binop[t.op.__class__.__name__] + ""("")\n#        self._dispatch(t.right)\n#        self._write("")"")\n#\n#    boolops = {_ast.And: \'and\', _ast.Or: \'or\'}\n#    def _BoolOp(self, t):\n#        self._write(""("")\n#        self._dispatch(t.values[0])\n#        for v in t.values[1:]:\n#            self._write("" %s "" % self.boolops[t.op.__class__])\n#            self._dispatch(v)\n#        self._write("")"")\n#\n#    def _Attribute(self,t):\n#        self._dispatch(t.value)\n#        self._write(""."")\n#        self._write(t.attr)\n#\n##    def _Call(self, t):\n##        self._dispatch(t.func)\n##        self._write(""("")\n##        comma = False\n##        for e in t.args:\n##            if comma: self._write("", "")\n##            else: comma = True\n##            self._dispatch(e)\n##        for e in t.keywords:\n##            if comma: self._write("", "")\n##            else: comma = True\n##            self._dispatch(e)\n##        if t.starargs:\n##            if comma: self._write("", "")\n##            else: comma = True\n##            self._write(""*"")\n##            self._dispatch(t.starargs)\n##        if t.kwargs:\n##            if comma: self._write("", "")\n##            else: comma = True\n##            self._write(""**"")\n##            self._dispatch(t.kwargs)\n##        self._write("")"")\n#\n#    # slice\n#    def _Index(self, t):\n#        self._dispatch(t.value)\n#\n#    def _ExtSlice(self, t):\n#        for i, d in enumerate(t.dims):\n#            if i != 0:\n#                self._write(\': \')\n#            self._dispatch(d)\n#\n#    # others\n#    def _arguments(self, t):\n#        first = True\n#        nonDef = len(t.args)-len(t.defaults)\n#        for a in t.args[0:nonDef]:\n#            if first:first = False\n#            else: self._write("", "")\n#            self._dispatch(a)\n#        for a,d in zip(t.args[nonDef:], t.defaults):\n#            if first:first = False\n#            else: self._write("", "")\n#            self._dispatch(a),\n#            self._write(""="")\n#            self._dispatch(d)\n#        if t.vararg:\n#            if first:first = False\n#            else: self._write("", "")\n#            self._write(""*""+t.vararg)\n#        if t.kwarg:\n#            if first:first = False\n#            else: self._write("", "")\n#            self._write(""**""+t.kwarg)\n#\n##    def _keyword(self, t):\n##        self._write(t.arg)\n##        self._write(""="")\n##        self._dispatch(t.value)\n#\n#    def _Lambda(self, t):\n#        self._write(""lambda "")\n#        self._dispatch(t.args)\n#        self._write("": "")\n#        self._dispatch(t.body)\n\n\n\n'"
docs/sphinxext/numpydoc/docscrape.py,0,"b'""""""Extract reference documentation from the NumPy source tree.\n\n""""""\nfrom __future__ import division, absolute_import, print_function\n\nimport inspect\nimport textwrap\nimport re\nimport pydoc\nfrom warnings import warn\nimport collections\nimport sys\n\n\nclass Reader(object):\n    """"""A line-based string reader.\n\n    """"""\n    def __init__(self, data):\n        """"""\n        Parameters\n        ----------\n        data : str\n           String with lines separated by \'\\n\'.\n\n        """"""\n        if isinstance(data,list):\n            self._str = data\n        else:\n            self._str = data.split(\'\\n\') # store string as list of lines\n\n        self.reset()\n\n    def __getitem__(self, n):\n        return self._str[n]\n\n    def reset(self):\n        self._l = 0 # current line nr\n\n    def read(self):\n        if not self.eof():\n            out = self[self._l]\n            self._l += 1\n            return out\n        else:\n            return \'\'\n\n    def seek_next_non_empty_line(self):\n        for l in self[self._l:]:\n            if l.strip():\n                break\n            else:\n                self._l += 1\n\n    def eof(self):\n        return self._l >= len(self._str)\n\n    def read_to_condition(self, condition_func):\n        start = self._l\n        for line in self[start:]:\n            if condition_func(line):\n                return self[start:self._l]\n            self._l += 1\n            if self.eof():\n                return self[start:self._l+1]\n        return []\n\n    def read_to_next_empty_line(self):\n        self.seek_next_non_empty_line()\n        def is_empty(line):\n            return not line.strip()\n        return self.read_to_condition(is_empty)\n\n    def read_to_next_unindented_line(self):\n        def is_unindented(line):\n            return (line.strip() and (len(line.lstrip()) == len(line)))\n        return self.read_to_condition(is_unindented)\n\n    def peek(self,n=0):\n        if self._l + n < len(self._str):\n            return self[self._l + n]\n        else:\n            return \'\'\n\n    def is_empty(self):\n        return not \'\'.join(self._str).strip()\n\n\nclass NumpyDocString(object):\n    def __init__(self, docstring, config={}):\n        docstring = textwrap.dedent(docstring).split(\'\\n\')\n\n        self._doc = Reader(docstring)\n        self._parsed_data = {\n            \'Signature\': \'\',\n            \'Summary\': [\'\'],\n            \'Extended Summary\': [],\n            \'Parameters\': [],\n            \'Returns\': [],\n            \'Raises\': [],\n            \'Warns\': [],\n            \'Other Parameters\': [],\n            \'Attributes\': [],\n            \'Methods\': [],\n            \'See Also\': [],\n            \'Notes\': [],\n            \'Warnings\': [],\n            \'References\': \'\',\n            \'Examples\': \'\',\n            \'index\': {}\n            }\n\n        self._parse()\n\n    def __getitem__(self,key):\n        return self._parsed_data[key]\n\n    def __setitem__(self,key,val):\n        if key not in self._parsed_data:\n            warn(""Unknown section %s"" % key)\n        else:\n            self._parsed_data[key] = val\n\n    def _is_at_section(self):\n        self._doc.seek_next_non_empty_line()\n\n        if self._doc.eof():\n            return False\n\n        l1 = self._doc.peek().strip()  # e.g. Parameters\n\n        if l1.startswith(\'.. index::\'):\n            return True\n\n        l2 = self._doc.peek(1).strip() #    ---------- or ==========\n        return l2.startswith(\'-\'*len(l1)) or l2.startswith(\'=\'*len(l1))\n\n    def _strip(self,doc):\n        i = 0\n        j = 0\n        for i,line in enumerate(doc):\n            if line.strip(): break\n\n        for j,line in enumerate(doc[::-1]):\n            if line.strip(): break\n\n        return doc[i:len(doc)-j]\n\n    def _read_to_next_section(self):\n        section = self._doc.read_to_next_empty_line()\n\n        while not self._is_at_section() and not self._doc.eof():\n            if not self._doc.peek(-1).strip(): # previous line was empty\n                section += [\'\']\n\n            section += self._doc.read_to_next_empty_line()\n\n        return section\n\n    def _read_sections(self):\n        while not self._doc.eof():\n            data = self._read_to_next_section()\n            name = data[0].strip()\n\n            if name.startswith(\'..\'): # index section\n                yield name, data[1:]\n            elif len(data) < 2:\n                yield StopIteration\n            else:\n                yield name, self._strip(data[2:])\n\n    def _parse_param_list(self,content):\n        r = Reader(content)\n        params = []\n        while not r.eof():\n            header = r.read().strip()\n            if \' : \' in header:\n                arg_name, arg_type = header.split(\' : \')[:2]\n            else:\n                arg_name, arg_type = header, \'\'\n\n            desc = r.read_to_next_unindented_line()\n            desc = dedent_lines(desc)\n\n            params.append((arg_name,arg_type,desc))\n\n        return params\n\n\n    _name_rgx = re.compile(r""^\\s*(:(?P<role>\\w+):`(?P<name>[a-zA-Z0-9_.-]+)`|""\n                           r"" (?P<name2>[a-zA-Z0-9_.-]+))\\s*"", re.X)\n    def _parse_see_also(self, content):\n        """"""\n        func_name : Descriptive text\n            continued text\n        another_func_name : Descriptive text\n        func_name1, func_name2, :meth:`func_name`, func_name3\n\n        """"""\n        items = []\n\n        def parse_item_name(text):\n            """"""Match \':role:`name`\' or \'name\'""""""\n            m = self._name_rgx.match(text)\n            if m:\n                g = m.groups()\n                if g[1] is None:\n                    return g[3], None\n                else:\n                    return g[2], g[1]\n            raise ValueError(""%s is not a item name"" % text)\n\n        def push_item(name, rest):\n            if not name:\n                return\n            name, role = parse_item_name(name)\n            items.append((name, list(rest), role))\n            del rest[:]\n\n        current_func = None\n        rest = []\n\n        for line in content:\n            if not line.strip(): continue\n\n            m = self._name_rgx.match(line)\n            if m and line[m.end():].strip().startswith(\':\'):\n                push_item(current_func, rest)\n                current_func, line = line[:m.end()], line[m.end():]\n                rest = [line.split(\':\', 1)[1].strip()]\n                if not rest[0]:\n                    rest = []\n            elif not line.startswith(\' \'):\n                push_item(current_func, rest)\n                current_func = None\n                if \',\' in line:\n                    for func in line.split(\',\'):\n                        if func.strip():\n                            push_item(func, [])\n                elif line.strip():\n                    current_func = line\n            elif current_func is not None:\n                rest.append(line.strip())\n        push_item(current_func, rest)\n        return items\n\n    def _parse_index(self, section, content):\n        """"""\n        .. index: default\n           :refguide: something, else, and more\n\n        """"""\n        def strip_each_in(lst):\n            return [s.strip() for s in lst]\n\n        out = {}\n        section = section.split(\'::\')\n        if len(section) > 1:\n            out[\'default\'] = strip_each_in(section[1].split(\',\'))[0]\n        for line in content:\n            line = line.split(\':\')\n            if len(line) > 2:\n                out[line[1]] = strip_each_in(line[2].split(\',\'))\n        return out\n\n    def _parse_summary(self):\n        """"""Grab signature (if given) and summary""""""\n        if self._is_at_section():\n            return\n\n        # If several signatures present, take the last one\n        while True:\n            summary = self._doc.read_to_next_empty_line()\n            summary_str = "" "".join([s.strip() for s in summary]).strip()\n            if re.compile(\'^([\\w., ]+=)?\\s*[\\w\\.]+\\(.*\\)$\').match(summary_str):\n                self[\'Signature\'] = summary_str\n                if not self._is_at_section():\n                    continue\n            break\n\n        if summary is not None:\n            self[\'Summary\'] = summary\n\n        if not self._is_at_section():\n            self[\'Extended Summary\'] = self._read_to_next_section()\n\n    def _parse(self):\n        self._doc.reset()\n        self._parse_summary()\n\n        for (section,content) in self._read_sections():\n            if not section.startswith(\'..\'):\n                section = \' \'.join([s.capitalize() for s in section.split(\' \')])\n            if section in (\'Parameters\', \'Returns\', \'Raises\', \'Warns\',\n                           \'Other Parameters\', \'Attributes\', \'Methods\'):\n                self[section] = self._parse_param_list(content)\n            elif section.startswith(\'.. index::\'):\n                self[\'index\'] = self._parse_index(section, content)\n            elif section == \'See Also\':\n                self[\'See Also\'] = self._parse_see_also(content)\n            else:\n                self[section] = content\n\n    # string conversion routines\n\n    def _str_header(self, name, symbol=\'-\'):\n        return [name, len(name)*symbol]\n\n    def _str_indent(self, doc, indent=4):\n        out = []\n        for line in doc:\n            out += [\' \'*indent + line]\n        return out\n\n    def _str_signature(self):\n        if self[\'Signature\']:\n            return [self[\'Signature\'].replace(\'*\',\'\\*\')] + [\'\']\n        else:\n            return [\'\']\n\n    def _str_summary(self):\n        if self[\'Summary\']:\n            return self[\'Summary\'] + [\'\']\n        else:\n            return []\n\n    def _str_extended_summary(self):\n        if self[\'Extended Summary\']:\n            return self[\'Extended Summary\'] + [\'\']\n        else:\n            return []\n\n    def _str_param_list(self, name):\n        out = []\n        if self[name]:\n            out += self._str_header(name)\n            for param,param_type,desc in self[name]:\n                if param_type:\n                    out += [\'%s : %s\' % (param, param_type)]\n                else:\n                    out += [param]\n                out += self._str_indent(desc)\n            out += [\'\']\n        return out\n\n    def _str_section(self, name):\n        out = []\n        if self[name]:\n            out += self._str_header(name)\n            out += self[name]\n            out += [\'\']\n        return out\n\n    def _str_see_also(self, func_role):\n        if not self[\'See Also\']: return []\n        out = []\n        out += self._str_header(""See Also"")\n        last_had_desc = True\n        for func, desc, role in self[\'See Also\']:\n            if role:\n                link = \':%s:`%s`\' % (role, func)\n            elif func_role:\n                link = \':%s:`%s`\' % (func_role, func)\n            else:\n                link = ""`%s`_"" % func\n            if desc or last_had_desc:\n                out += [\'\']\n                out += [link]\n            else:\n                out[-1] += "", %s"" % link\n            if desc:\n                out += self._str_indent([\' \'.join(desc)])\n                last_had_desc = True\n            else:\n                last_had_desc = False\n        out += [\'\']\n        return out\n\n    def _str_index(self):\n        idx = self[\'index\']\n        out = []\n        out += [\'.. index:: %s\' % idx.get(\'default\',\'\')]\n        for section, references in idx.items():\n            if section == \'default\':\n                continue\n            out += [\'   :%s: %s\' % (section, \', \'.join(references))]\n        return out\n\n    def __str__(self, func_role=\'\'):\n        out = []\n        out += self._str_signature()\n        out += self._str_summary()\n        out += self._str_extended_summary()\n        for param_list in (\'Parameters\', \'Returns\', \'Other Parameters\',\n                           \'Raises\', \'Warns\'):\n            out += self._str_param_list(param_list)\n        out += self._str_section(\'Warnings\')\n        out += self._str_see_also(func_role)\n        for s in (\'Notes\',\'References\',\'Examples\'):\n            out += self._str_section(s)\n        for param_list in (\'Attributes\', \'Methods\'):\n            out += self._str_param_list(param_list)\n        out += self._str_index()\n        return \'\\n\'.join(out)\n\n\ndef indent(str,indent=4):\n    indent_str = \' \'*indent\n    if str is None:\n        return indent_str\n    lines = str.split(\'\\n\')\n    return \'\\n\'.join(indent_str + l for l in lines)\n\ndef dedent_lines(lines):\n    """"""Deindent a list of lines maximally""""""\n    return textwrap.dedent(""\\n"".join(lines)).split(""\\n"")\n\ndef header(text, style=\'-\'):\n    return text + \'\\n\' + style*len(text) + \'\\n\'\n\n\nclass FunctionDoc(NumpyDocString):\n    def __init__(self, func, role=\'func\', doc=None, config={}):\n        self._f = func\n        self._role = role # e.g. ""func"" or ""meth""\n\n        if doc is None:\n            if func is None:\n                raise ValueError(""No function or docstring given"")\n            doc = inspect.getdoc(func) or \'\'\n        NumpyDocString.__init__(self, doc)\n\n        if not self[\'Signature\'] and func is not None:\n            func, func_name = self.get_func()\n            try:\n                # try to read signature\n                if sys.version_info[0] >= 3:\n                    argspec = inspect.getfullargspec(func)\n                else:\n                    argspec = inspect.getargspec(func)\n                argspec = inspect.formatargspec(*argspec)\n                argspec = argspec.replace(\'*\',\'\\*\')\n                signature = \'%s%s\' % (func_name, argspec)\n            except TypeError as e:\n                signature = \'%s()\' % func_name\n            self[\'Signature\'] = signature\n\n    def get_func(self):\n        func_name = getattr(self._f, \'__name__\', self.__class__.__name__)\n        if inspect.isclass(self._f):\n            func = getattr(self._f, \'__call__\', self._f.__init__)\n        else:\n            func = self._f\n        return func, func_name\n\n    def __str__(self):\n        out = \'\'\n\n        func, func_name = self.get_func()\n        signature = self[\'Signature\'].replace(\'*\', \'\\*\')\n\n        roles = {\'func\': \'function\',\n                 \'meth\': \'method\'}\n\n        if self._role:\n            if self._role not in roles:\n                print(""Warning: invalid role %s"" % self._role)\n            out += \'.. %s:: %s\\n    \\n\\n\' % (roles.get(self._role,\'\'),\n                                             func_name)\n\n        out += super(FunctionDoc, self).__str__(func_role=self._role)\n        return out\n\n\nclass ClassDoc(NumpyDocString):\n\n    extra_public_methods = [\'__call__\']\n\n    def __init__(self, cls, doc=None, modulename=\'\', func_doc=FunctionDoc,\n                 config={}):\n        if not inspect.isclass(cls) and cls is not None:\n            raise ValueError(""Expected a class or None, but got %r"" % cls)\n        self._cls = cls\n\n        if modulename and not modulename.endswith(\'.\'):\n            modulename += \'.\'\n        self._mod = modulename\n\n        if doc is None:\n            if cls is None:\n                raise ValueError(""No class or documentation string given"")\n            doc = pydoc.getdoc(cls)\n\n        NumpyDocString.__init__(self, doc)\n\n        if config.get(\'show_class_members\', True):\n            def splitlines_x(s):\n                if not s:\n                    return []\n                else:\n                    return s.splitlines()\n\n            for field, items in [(\'Methods\', self.methods),\n                                 (\'Attributes\', self.properties)]:\n                if not self[field]:\n                    doc_list = []\n                    for name in sorted(items):\n                         try:\n                            doc_item = pydoc.getdoc(getattr(self._cls, name))\n                            doc_list.append((name, \'\', splitlines_x(doc_item)))\n                         except AttributeError:\n                            pass # method doesn\'t exist\n                    self[field] = doc_list\n\n    @property\n    def methods(self):\n        if self._cls is None:\n            return []\n        return [name for name,func in inspect.getmembers(self._cls)\n                if ((not name.startswith(\'_\')\n                     or name in self.extra_public_methods)\n                    and isinstance(func, collections.Callable))]\n\n    @property\n    def properties(self):\n        if self._cls is None:\n            return []\n        return [name for name,func in inspect.getmembers(self._cls)\n                if not name.startswith(\'_\') and\n                (func is None or isinstance(func, property) or\n                 inspect.isgetsetdescriptor(func))]\n'"
docs/sphinxext/numpydoc/docscrape_sphinx.py,0,"b'from __future__ import division, absolute_import, print_function\n\nimport sys, re, inspect, textwrap, pydoc\nimport sphinx\nimport collections\nfrom .docscrape import NumpyDocString, FunctionDoc, ClassDoc\n\nif sys.version_info[0] >= 3:\n    sixu = lambda s: s\nelse:\n    sixu = lambda s: unicode(s, \'unicode_escape\')\n\n\nclass SphinxDocString(NumpyDocString):\n    def __init__(self, docstring, config={}):\n        NumpyDocString.__init__(self, docstring, config=config)\n        self.load_config(config)\n\n    def load_config(self, config):\n        self.use_plots = config.get(\'use_plots\', False)\n        self.class_members_toctree = config.get(\'class_members_toctree\', True)\n\n    # string conversion routines\n    def _str_header(self, name, symbol=\'`\'):\n        return [\'.. rubric:: \' + name, \'\']\n\n    def _str_field_list(self, name):\n        return [\':\' + name + \':\']\n\n    def _str_indent(self, doc, indent=4):\n        out = []\n        for line in doc:\n            out += [\' \'*indent + line]\n        return out\n\n    def _str_signature(self):\n        return [\'\']\n        if self[\'Signature\']:\n            return [\'``%s``\' % self[\'Signature\']] + [\'\']\n        else:\n            return [\'\']\n\n    def _str_summary(self):\n        return self[\'Summary\'] + [\'\']\n\n    def _str_extended_summary(self):\n        return self[\'Extended Summary\'] + [\'\']\n\n    def _str_returns(self):\n        out = []\n        if self[\'Returns\']:\n            out += self._str_field_list(\'Returns\')\n            out += [\'\']\n            for param, param_type, desc in self[\'Returns\']:\n                if param_type:\n                    out += self._str_indent([\'**%s** : %s\' % (param.strip(),\n                                                              param_type)])\n                else:\n                    out += self._str_indent([param.strip()])\n                if desc:\n                    out += [\'\']\n                    out += self._str_indent(desc, 8)\n                out += [\'\']\n        return out\n\n    def _str_param_list(self, name):\n        out = []\n        if self[name]:\n            out += self._str_field_list(name)\n            out += [\'\']\n            for param, param_type, desc in self[name]:\n                if param_type:\n                    out += self._str_indent([\'**%s** : %s\' % (param.strip(),\n                                                              param_type)])\n                else:\n                    out += self._str_indent([\'**%s**\' % param.strip()])\n                if desc:\n                    out += [\'\']\n                    out += self._str_indent(desc, 8)\n                out += [\'\']\n        return out\n\n    @property\n    def _obj(self):\n        if hasattr(self, \'_cls\'):\n            return self._cls\n        elif hasattr(self, \'_f\'):\n            return self._f\n        return None\n\n    def _str_member_list(self, name):\n        """"""\n        Generate a member listing, autosummary:: table where possible,\n        and a table where not.\n\n        """"""\n        out = []\n        if self[name]:\n            out += [\'.. rubric:: %s\' % name, \'\']\n            prefix = getattr(self, \'_name\', \'\')\n\n            if prefix:\n                prefix = \'~%s.\' % prefix\n\n            autosum = []\n            others = []\n            for param, param_type, desc in self[name]:\n                param = param.strip()\n\n                # Check if the referenced member can have a docstring or not\n                param_obj = getattr(self._obj, param, None)\n                if not (callable(param_obj)\n                        or isinstance(param_obj, property)\n                        or inspect.isgetsetdescriptor(param_obj)):\n                    param_obj = None\n\n                if param_obj and (pydoc.getdoc(param_obj) or not desc):\n                    # Referenced object has a docstring\n                    autosum += [""   %s%s"" % (prefix, param)]\n                else:\n                    others.append((param, param_type, desc))\n\n            if autosum:\n                out += [\'.. autosummary::\']\n                if self.class_members_toctree:\n                    out += [\'   :toctree:\']\n                out += [\'\'] + autosum\n\n            if others:\n                maxlen_0 = max(3, max([len(x[0]) for x in others]))\n                hdr = sixu(""="")*maxlen_0 + sixu(""  "") + sixu(""="")*10\n                fmt = sixu(\'%%%ds  %%s  \') % (maxlen_0,)\n                out += [\'\', hdr]\n                for param, param_type, desc in others:\n                    desc = sixu("" "").join(x.strip() for x in desc).strip()\n                    if param_type:\n                        desc = ""(%s) %s"" % (param_type, desc)\n                    out += [fmt % (param.strip(), desc)]\n                out += [hdr]\n            out += [\'\']\n        return out\n\n    def _str_section(self, name):\n        out = []\n        if self[name]:\n            out += self._str_header(name)\n            out += [\'\']\n            content = textwrap.dedent(""\\n"".join(self[name])).split(""\\n"")\n            out += content\n            out += [\'\']\n        return out\n\n    def _str_see_also(self, func_role):\n        out = []\n        if self[\'See Also\']:\n            see_also = super(SphinxDocString, self)._str_see_also(func_role)\n            out = [\'.. seealso::\', \'\']\n            out += self._str_indent(see_also[2:])\n        return out\n\n    def _str_warnings(self):\n        out = []\n        if self[\'Warnings\']:\n            out = [\'.. warning::\', \'\']\n            out += self._str_indent(self[\'Warnings\'])\n        return out\n\n    def _str_index(self):\n        idx = self[\'index\']\n        out = []\n        if len(idx) == 0:\n            return out\n\n        out += [\'.. index:: %s\' % idx.get(\'default\',\'\')]\n        for section, references in idx.items():\n            if section == \'default\':\n                continue\n            elif section == \'refguide\':\n                out += [\'   single: %s\' % (\', \'.join(references))]\n            else:\n                out += [\'   %s: %s\' % (section, \',\'.join(references))]\n        return out\n\n    def _str_references(self):\n        out = []\n        if self[\'References\']:\n            out += self._str_header(\'References\')\n            if isinstance(self[\'References\'], str):\n                self[\'References\'] = [self[\'References\']]\n            out.extend(self[\'References\'])\n            out += [\'\']\n            # Latex collects all references to a separate bibliography,\n            # so we need to insert links to it\n            if sphinx.__version__ >= ""0.6"":\n                out += [\'.. only:: latex\',\'\']\n            else:\n                out += [\'.. latexonly::\',\'\']\n            items = []\n            for line in self[\'References\']:\n                m = re.match(r\'.. \\[([a-z0-9._-]+)\\]\', line, re.I)\n                if m:\n                    items.append(m.group(1))\n            out += [\'   \' + "", "".join([""[%s]_"" % item for item in items]), \'\']\n        return out\n\n    def _str_examples(self):\n        examples_str = ""\\n"".join(self[\'Examples\'])\n\n        if (self.use_plots and \'import matplotlib\' in examples_str\n                and \'plot::\' not in examples_str):\n            out = []\n            out += self._str_header(\'Examples\')\n            out += [\'.. plot::\', \'\']\n            out += self._str_indent(self[\'Examples\'])\n            out += [\'\']\n            return out\n        else:\n            return self._str_section(\'Examples\')\n\n    def __str__(self, indent=0, func_role=""obj""):\n        out = []\n        out += self._str_signature()\n        out += self._str_index() + [\'\']\n        out += self._str_summary()\n        out += self._str_extended_summary()\n        out += self._str_param_list(\'Parameters\')\n        out += self._str_returns()\n        for param_list in (\'Other Parameters\', \'Raises\', \'Warns\'):\n            out += self._str_param_list(param_list)\n        out += self._str_warnings()\n        out += self._str_see_also(func_role)\n        out += self._str_section(\'Notes\')\n        out += self._str_references()\n        out += self._str_examples()\n        for param_list in (\'Attributes\', \'Methods\'):\n            out += self._str_member_list(param_list)\n        out = self._str_indent(out,indent)\n        return \'\\n\'.join(out)\n\nclass SphinxFunctionDoc(SphinxDocString, FunctionDoc):\n    def __init__(self, obj, doc=None, config={}):\n        self.load_config(config)\n        FunctionDoc.__init__(self, obj, doc=doc, config=config)\n\nclass SphinxClassDoc(SphinxDocString, ClassDoc):\n    def __init__(self, obj, doc=None, func_doc=None, config={}):\n        self.load_config(config)\n        ClassDoc.__init__(self, obj, doc=doc, func_doc=None, config=config)\n\nclass SphinxObjDoc(SphinxDocString):\n    def __init__(self, obj, doc=None, config={}):\n        self._f = obj\n        self.load_config(config)\n        SphinxDocString.__init__(self, doc, config=config)\n\ndef get_doc_object(obj, what=None, doc=None, config={}):\n    if what is None:\n        if inspect.isclass(obj):\n            what = \'class\'\n        elif inspect.ismodule(obj):\n            what = \'module\'\n        elif isinstance(obj, collections.Callable):\n            what = \'function\'\n        else:\n            what = \'object\'\n    if what == \'class\':\n        return SphinxClassDoc(obj, func_doc=SphinxFunctionDoc, doc=doc,\n                              config=config)\n    elif what in (\'function\', \'method\'):\n        return SphinxFunctionDoc(obj, doc=doc, config=config)\n    else:\n        if doc is None:\n            doc = pydoc.getdoc(obj)\n        return SphinxObjDoc(obj, doc, config=config)\n'"
docs/sphinxext/numpydoc/linkcode.py,0,"b'# -*- coding: utf-8 -*-\n""""""\n    linkcode\n    ~~~~~~~~\n\n    Add external links to module code in Python object descriptions.\n\n    :copyright: Copyright 2007-2011 by the Sphinx team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\n""""""\nfrom __future__ import division, absolute_import, print_function\n\nimport warnings\nimport collections\n\nwarnings.warn(""This extension has been accepted to Sphinx upstream. ""\n              ""Use the version from there (Sphinx >= 1.2) ""\n              ""https://bitbucket.org/birkenfeld/sphinx/pull-request/47/sphinxextlinkcode"",\n              FutureWarning, stacklevel=1)\n\n\nfrom docutils import nodes\n\nfrom sphinx import addnodes\nfrom sphinx.locale import _\nfrom sphinx.errors import SphinxError\n\nclass LinkcodeError(SphinxError):\n    category = ""linkcode error""\n\ndef doctree_read(app, doctree):\n    env = app.builder.env\n\n    resolve_target = getattr(env.config, \'linkcode_resolve\', None)\n    if not isinstance(env.config.linkcode_resolve, collections.Callable):\n        raise LinkcodeError(\n            ""Function `linkcode_resolve` is not given in conf.py"")\n\n    domain_keys = dict(\n        py=[\'module\', \'fullname\'],\n        c=[\'names\'],\n        cpp=[\'names\'],\n        js=[\'object\', \'fullname\'],\n    )\n\n    for objnode in doctree.traverse(addnodes.desc):\n        domain = objnode.get(\'domain\')\n        uris = set()\n        for signode in objnode:\n            if not isinstance(signode, addnodes.desc_signature):\n                continue\n\n            # Convert signode to a specified format\n            info = {}\n            for key in domain_keys.get(domain, []):\n                value = signode.get(key)\n                if not value:\n                    value = \'\'\n                info[key] = value\n            if not info:\n                continue\n\n            # Call user code to resolve the link\n            uri = resolve_target(domain, info)\n            if not uri:\n                # no source\n                continue\n\n            if uri in uris or not uri:\n                # only one link per name, please\n                continue\n            uris.add(uri)\n\n            onlynode = addnodes.only(expr=\'html\')\n            onlynode += nodes.reference(\'\', \'\', internal=False, refuri=uri)\n            onlynode[0] += nodes.inline(\'\', _(\'[source]\'),\n                                        classes=[\'viewcode-link\'])\n            signode += onlynode\n\ndef setup(app):\n    app.connect(\'doctree-read\', doctree_read)\n    app.add_config_value(\'linkcode_resolve\', None, \'\')\n'"
docs/sphinxext/numpydoc/numpydoc.py,0,"b'""""""\n========\nnumpydoc\n========\n\nSphinx extension that handles docstrings in the Numpy standard format. [1]\n\nIt will:\n\n- Convert Parameters etc. sections to field lists.\n- Convert See Also section to a See also entry.\n- Renumber references.\n- Extract the signature from the docstring, if it can\'t be determined otherwise.\n\n.. [1] https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt\n\n""""""\nfrom __future__ import division, absolute_import, print_function\n\nimport os, sys, re, pydoc\nimport sphinx\nimport inspect\nimport collections\n\nif sphinx.__version__ < \'1.0.1\':\n    raise RuntimeError(""Sphinx 1.0.1 or newer is required"")\n\nfrom .docscrape_sphinx import get_doc_object, SphinxDocString\nfrom sphinx.util.compat import Directive\n\nif sys.version_info[0] >= 3:\n    sixu = lambda s: s\nelse:\n    sixu = lambda s: unicode(s, \'unicode_escape\')\n\n\ndef mangle_docstrings(app, what, name, obj, options, lines,\n                      reference_offset=[0]):\n\n    cfg = dict(use_plots=app.config.numpydoc_use_plots,\n               show_class_members=app.config.numpydoc_show_class_members,\n               class_members_toctree=app.config.numpydoc_class_members_toctree,\n              )\n\n    if what == \'module\':\n        # Strip top title\n        title_re = re.compile(sixu(\'^\\\\s*[#*=]{4,}\\\\n[a-z0-9 -]+\\\\n[#*=]{4,}\\\\s*\'),\n                              re.I|re.S)\n        lines[:] = title_re.sub(sixu(\'\'), sixu(""\\n"").join(lines)).split(sixu(""\\n""))\n    else:\n        doc = get_doc_object(obj, what, sixu(""\\n"").join(lines), config=cfg)\n        if sys.version_info[0] >= 3:\n            doc = str(doc)\n        else:\n            doc = unicode(doc)\n        lines[:] = doc.split(sixu(""\\n""))\n\n    if app.config.numpydoc_edit_link and hasattr(obj, \'__name__\') and \\\n           obj.__name__:\n        if hasattr(obj, \'__module__\'):\n            v = dict(full_name=sixu(""%s.%s"") % (obj.__module__, obj.__name__))\n        else:\n            v = dict(full_name=obj.__name__)\n        lines += [sixu(\'\'), sixu(\'.. htmlonly::\'), sixu(\'\')]\n        lines += [sixu(\'    %s\') % x for x in\n                  (app.config.numpydoc_edit_link % v).split(""\\n"")]\n\n    # replace reference numbers so that there are no duplicates\n    references = []\n    for line in lines:\n        line = line.strip()\n        m = re.match(sixu(\'^.. \\\\[([a-z0-9_.-])\\\\]\'), line, re.I)\n        if m:\n            references.append(m.group(1))\n\n    # start renaming from the longest string, to avoid overwriting parts\n    references.sort(key=lambda x: -len(x))\n    if references:\n        for i, line in enumerate(lines):\n            for r in references:\n                if re.match(sixu(\'^\\\\d+$\'), r):\n                    new_r = sixu(""R%d"") % (reference_offset[0] + int(r))\n                else:\n                    new_r = sixu(""%s%d"") % (r, reference_offset[0])\n                lines[i] = lines[i].replace(sixu(\'[%s]_\') % r,\n                                            sixu(\'[%s]_\') % new_r)\n                lines[i] = lines[i].replace(sixu(\'.. [%s]\') % r,\n                                            sixu(\'.. [%s]\') % new_r)\n\n    reference_offset[0] += len(references)\n\ndef mangle_signature(app, what, name, obj, options, sig, retann):\n    # Do not try to inspect classes that don\'t define `__init__`\n    if (inspect.isclass(obj) and\n        (not hasattr(obj, \'__init__\') or\n        \'initializes x; see \' in pydoc.getdoc(obj.__init__))):\n        return \'\', \'\'\n\n    if not (isinstance(obj, collections.Callable) or hasattr(obj, \'__argspec_is_invalid_\')): return\n    if not hasattr(obj, \'__doc__\'): return\n\n    doc = SphinxDocString(pydoc.getdoc(obj))\n    if doc[\'Signature\']:\n        sig = re.sub(sixu(""^[^(]*""), sixu(""""), doc[\'Signature\'])\n        return sig, sixu(\'\')\n\ndef setup(app, get_doc_object_=get_doc_object):\n    if not hasattr(app, \'add_config_value\'):\n        return # probably called by nose, better bail out\n\n    global get_doc_object\n    get_doc_object = get_doc_object_\n\n    app.connect(\'autodoc-process-docstring\', mangle_docstrings)\n    app.connect(\'autodoc-process-signature\', mangle_signature)\n    app.add_config_value(\'numpydoc_edit_link\', None, False)\n    app.add_config_value(\'numpydoc_use_plots\', None, False)\n    app.add_config_value(\'numpydoc_show_class_members\', True, True)\n    app.add_config_value(\'numpydoc_class_members_toctree\', True, True)\n\n    # Extra mangling domains\n    app.add_domain(NumpyPythonDomain)\n    app.add_domain(NumpyCDomain)\n\n#------------------------------------------------------------------------------\n# Docstring-mangling domains\n#------------------------------------------------------------------------------\n\nfrom docutils.statemachine import ViewList\nfrom sphinx.domains.c import CDomain\nfrom sphinx.domains.python import PythonDomain\n\nclass ManglingDomainBase(object):\n    directive_mangling_map = {}\n\n    def __init__(self, *a, **kw):\n        super(ManglingDomainBase, self).__init__(*a, **kw)\n        self.wrap_mangling_directives()\n\n    def wrap_mangling_directives(self):\n        for name, objtype in list(self.directive_mangling_map.items()):\n            self.directives[name] = wrap_mangling_directive(\n                self.directives[name], objtype)\n\nclass NumpyPythonDomain(ManglingDomainBase, PythonDomain):\n    name = \'np\'\n    directive_mangling_map = {\n        \'function\': \'function\',\n        \'class\': \'class\',\n        \'exception\': \'class\',\n        \'method\': \'function\',\n        \'classmethod\': \'function\',\n        \'staticmethod\': \'function\',\n        \'attribute\': \'attribute\',\n    }\n    indices = []\n\nclass NumpyCDomain(ManglingDomainBase, CDomain):\n    name = \'np-c\'\n    directive_mangling_map = {\n        \'function\': \'function\',\n        \'member\': \'attribute\',\n        \'macro\': \'function\',\n        \'type\': \'class\',\n        \'var\': \'object\',\n    }\n\ndef wrap_mangling_directive(base_directive, objtype):\n    class directive(base_directive):\n        def run(self):\n            env = self.state.document.settings.env\n\n            name = None\n            if self.arguments:\n                m = re.match(r\'^(.*\\s+)?(.*?)(\\(.*)?\', self.arguments[0])\n                name = m.group(2).strip()\n\n            if not name:\n                name = self.arguments[0]\n\n            lines = list(self.content)\n            mangle_docstrings(env.app, objtype, name, None, None, lines)\n            self.content = ViewList(lines, self.content.parent)\n\n            return base_directive.run(self)\n\n    return directive\n'"
docs/sphinxext/numpydoc/phantom_import.py,0,"b'""""""\n==============\nphantom_import\n==============\n\nSphinx extension to make directives from ``sphinx.ext.autodoc`` and similar\nextensions to use docstrings loaded from an XML file.\n\nThis extension loads an XML file in the Pydocweb format [1] and\ncreates a dummy module that contains the specified docstrings. This\ncan be used to get the current docstrings from a Pydocweb instance\nwithout needing to rebuild the documented module.\n\n.. [1] http://code.google.com/p/pydocweb\n\n""""""\nfrom __future__ import division, absolute_import, print_function\n\nimport imp, sys, compiler, types, os, inspect, re\n\ndef setup(app):\n    app.connect(\'builder-inited\', initialize)\n    app.add_config_value(\'phantom_import_file\', None, True)\n\ndef initialize(app):\n    fn = app.config.phantom_import_file\n    if (fn and os.path.isfile(fn)):\n        print(""[numpydoc] Phantom importing modules from"", fn, ""..."")\n        import_phantom_module(fn)\n\n#------------------------------------------------------------------------------\n# Creating \'phantom\' modules from an XML description\n#------------------------------------------------------------------------------\ndef import_phantom_module(xml_file):\n    """"""\n    Insert a fake Python module to sys.modules, based on a XML file.\n\n    The XML file is expected to conform to Pydocweb DTD. The fake\n    module will contain dummy objects, which guarantee the following:\n\n    - Docstrings are correct.\n    - Class inheritance relationships are correct (if present in XML).\n    - Function argspec is *NOT* correct (even if present in XML).\n      Instead, the function signature is prepended to the function docstring.\n    - Class attributes are *NOT* correct; instead, they are dummy objects.\n\n    Parameters\n    ----------\n    xml_file : str\n        Name of an XML file to read\n    \n    """"""\n    import lxml.etree as etree\n\n    object_cache = {}\n\n    tree = etree.parse(xml_file)\n    root = tree.getroot()\n\n    # Sort items so that\n    # - Base classes come before classes inherited from them\n    # - Modules come before their contents\n    all_nodes = dict([(n.attrib[\'id\'], n) for n in root])\n    \n    def _get_bases(node, recurse=False):\n        bases = [x.attrib[\'ref\'] for x in node.findall(\'base\')]\n        if recurse:\n            j = 0\n            while True:\n                try:\n                    b = bases[j]\n                except IndexError: break\n                if b in all_nodes:\n                    bases.extend(_get_bases(all_nodes[b]))\n                j += 1\n        return bases\n\n    type_index = [\'module\', \'class\', \'callable\', \'object\']\n    \n    def base_cmp(a, b):\n        x = cmp(type_index.index(a.tag), type_index.index(b.tag))\n        if x != 0: return x\n\n        if a.tag == \'class\' and b.tag == \'class\':\n            a_bases = _get_bases(a, recurse=True)\n            b_bases = _get_bases(b, recurse=True)\n            x = cmp(len(a_bases), len(b_bases))\n            if x != 0: return x\n            if a.attrib[\'id\'] in b_bases: return -1\n            if b.attrib[\'id\'] in a_bases: return 1\n        \n        return cmp(a.attrib[\'id\'].count(\'.\'), b.attrib[\'id\'].count(\'.\'))\n\n    nodes = root.getchildren()\n    nodes.sort(base_cmp)\n\n    # Create phantom items\n    for node in nodes:\n        name = node.attrib[\'id\']\n        doc = (node.text or \'\').decode(\'string-escape\') + ""\\n""\n        if doc == ""\\n"": doc = """"\n\n        # create parent, if missing\n        parent = name\n        while True:\n            parent = \'.\'.join(parent.split(\'.\')[:-1])\n            if not parent: break\n            if parent in object_cache: break\n            obj = imp.new_module(parent)\n            object_cache[parent] = obj\n            sys.modules[parent] = obj\n\n        # create object\n        if node.tag == \'module\':\n            obj = imp.new_module(name)\n            obj.__doc__ = doc\n            sys.modules[name] = obj\n        elif node.tag == \'class\':\n            bases = [object_cache[b] for b in _get_bases(node)\n                     if b in object_cache]\n            bases.append(object)\n            init = lambda self: None\n            init.__doc__ = doc\n            obj = type(name, tuple(bases), {\'__doc__\': doc, \'__init__\': init})\n            obj.__name__ = name.split(\'.\')[-1]\n        elif node.tag == \'callable\':\n            funcname = node.attrib[\'id\'].split(\'.\')[-1]\n            argspec = node.attrib.get(\'argspec\')\n            if argspec:\n                argspec = re.sub(\'^[^(]*\', \'\', argspec)\n                doc = ""%s%s\\n\\n%s"" % (funcname, argspec, doc)\n            obj = lambda: 0\n            obj.__argspec_is_invalid_ = True\n            if sys.version_info[0] >= 3:\n                obj.__name__ = funcname\n            else:\n                obj.func_name = funcname\n            obj.__name__ = name\n            obj.__doc__ = doc\n            if inspect.isclass(object_cache[parent]):\n                obj.__objclass__ = object_cache[parent]\n        else:\n            class Dummy(object): pass\n            obj = Dummy()\n            obj.__name__ = name\n            obj.__doc__ = doc\n            if inspect.isclass(object_cache[parent]):\n                obj.__get__ = lambda: None\n        object_cache[name] = obj\n\n        if parent:\n            if inspect.ismodule(object_cache[parent]):\n                obj.__module__ = parent\n                setattr(object_cache[parent], name.split(\'.\')[-1], obj)\n\n    # Populate items\n    for node in root:\n        obj = object_cache.get(node.attrib[\'id\'])\n        if obj is None: continue\n        for ref in node.findall(\'ref\'):\n            if node.tag == \'class\':\n                if ref.attrib[\'ref\'].startswith(node.attrib[\'id\'] + \'.\'):\n                    setattr(obj, ref.attrib[\'name\'],\n                            object_cache.get(ref.attrib[\'ref\']))\n            else:\n                setattr(obj, ref.attrib[\'name\'],\n                        object_cache.get(ref.attrib[\'ref\']))\n'"
docs/sphinxext/numpydoc/plot_directive.py,0,"b'""""""\nA special directive for generating a matplotlib plot.\n\n.. warning::\n\n   This is a hacked version of plot_directive.py from Matplotlib.\n   It\'s very much subject to change!\n\n\nUsage\n-----\n\nCan be used like this::\n\n    .. plot:: examples/example.py\n\n    .. plot::\n\n       import matplotlib.pyplot as plt\n       plt.plot([1,2,3], [4,5,6])\n\n    .. plot::\n\n       A plotting example:\n\n       >>> import matplotlib.pyplot as plt\n       >>> plt.plot([1,2,3], [4,5,6])\n\nThe content is interpreted as doctest formatted if it has a line starting\nwith ``>>>``.\n\nThe ``plot`` directive supports the options\n\n    format : {\'python\', \'doctest\'}\n        Specify the format of the input\n\n    include-source : bool\n        Whether to display the source code. Default can be changed in conf.py\n\nand the ``image`` directive options ``alt``, ``height``, ``width``,\n``scale``, ``align``, ``class``.\n\nConfiguration options\n---------------------\n\nThe plot directive has the following configuration options:\n\n    plot_include_source\n        Default value for the include-source option\n\n    plot_pre_code\n        Code that should be executed before each plot.\n\n    plot_basedir\n        Base directory, to which plot:: file names are relative to.\n        (If None or empty, file names are relative to the directoly where\n        the file containing the directive is.)\n\n    plot_formats\n        File formats to generate. List of tuples or strings::\n\n            [(suffix, dpi), suffix, ...]\n\n        that determine the file format and the DPI. For entries whose\n        DPI was omitted, sensible defaults are chosen.\n\n    plot_html_show_formats\n        Whether to show links to the files in HTML.\n\nTODO\n----\n\n* Refactor Latex output; now it\'s plain images, but it would be nice\n  to make them appear side-by-side, or in floats.\n\n""""""\nfrom __future__ import division, absolute_import, print_function\n\nimport sys, os, glob, shutil, imp, warnings, re, textwrap, traceback\nimport sphinx\n\nif sys.version_info[0] >= 3:\n    from io import StringIO\nelse:\n    from io import StringIO\n\nimport warnings\nwarnings.warn(""A plot_directive module is also available under ""\n              ""matplotlib.sphinxext; expect this numpydoc.plot_directive ""\n              ""module to be deprecated after relevant features have been ""\n              ""integrated there."",\n              FutureWarning, stacklevel=2)\n\n\n#------------------------------------------------------------------------------\n# Registration hook\n#------------------------------------------------------------------------------\n\ndef setup(app):\n    setup.app = app\n    setup.config = app.config\n    setup.confdir = app.confdir\n\n    app.add_config_value(\'plot_pre_code\', \'\', True)\n    app.add_config_value(\'plot_include_source\', False, True)\n    app.add_config_value(\'plot_formats\', [\'png\', \'hires.png\', \'pdf\'], True)\n    app.add_config_value(\'plot_basedir\', None, True)\n    app.add_config_value(\'plot_html_show_formats\', True, True)\n\n    app.add_directive(\'plot\', plot_directive, True, (0, 1, False),\n                      **plot_directive_options)\n\n#------------------------------------------------------------------------------\n# plot:: directive\n#------------------------------------------------------------------------------\nfrom docutils.parsers.rst import directives\nfrom docutils import nodes\n\ndef plot_directive(name, arguments, options, content, lineno,\n                   content_offset, block_text, state, state_machine):\n    return run(arguments, content, options, state_machine, state, lineno)\nplot_directive.__doc__ = __doc__\n\ndef _option_boolean(arg):\n    if not arg or not arg.strip():\n        # no argument given, assume used as a flag\n        return True\n    elif arg.strip().lower() in (\'no\', \'0\', \'false\'):\n        return False\n    elif arg.strip().lower() in (\'yes\', \'1\', \'true\'):\n        return True\n    else:\n        raise ValueError(\'""%s"" unknown boolean\' % arg)\n\ndef _option_format(arg):\n    return directives.choice(arg, (\'python\', \'lisp\'))\n\ndef _option_align(arg):\n    return directives.choice(arg, (""top"", ""middle"", ""bottom"", ""left"", ""center"",\n                                   ""right""))\n\nplot_directive_options = {\'alt\': directives.unchanged,\n                          \'height\': directives.length_or_unitless,\n                          \'width\': directives.length_or_percentage_or_unitless,\n                          \'scale\': directives.nonnegative_int,\n                          \'align\': _option_align,\n                          \'class\': directives.class_option,\n                          \'include-source\': _option_boolean,\n                          \'format\': _option_format,\n                          }\n\n#------------------------------------------------------------------------------\n# Generating output\n#------------------------------------------------------------------------------\n\nfrom docutils import nodes, utils\n\ntry:\n    # Sphinx depends on either Jinja or Jinja2\n    import jinja2\n    def format_template(template, **kw):\n        return jinja2.Template(template).render(**kw)\nexcept ImportError:\n    import jinja\n    def format_template(template, **kw):\n        return jinja.from_string(template, **kw)\n\nTEMPLATE = """"""\n{{ source_code }}\n\n{{ only_html }}\n\n   {% if source_link or (html_show_formats and not multi_image) %}\n   (\n   {%- if source_link -%}\n   `Source code <{{ source_link }}>`__\n   {%- endif -%}\n   {%- if html_show_formats and not multi_image -%}\n     {%- for img in images -%}\n       {%- for fmt in img.formats -%}\n         {%- if source_link or not loop.first -%}, {% endif -%}\n         `{{ fmt }} <{{ dest_dir }}/{{ img.basename }}.{{ fmt }}>`__\n       {%- endfor -%}\n     {%- endfor -%}\n   {%- endif -%}\n   )\n   {% endif %}\n\n   {% for img in images %}\n   .. figure:: {{ build_dir }}/{{ img.basename }}.png\n      {%- for option in options %}\n      {{ option }}\n      {% endfor %}\n\n      {% if html_show_formats and multi_image -%}\n        (\n        {%- for fmt in img.formats -%}\n        {%- if not loop.first -%}, {% endif -%}\n        `{{ fmt }} <{{ dest_dir }}/{{ img.basename }}.{{ fmt }}>`__\n        {%- endfor -%}\n        )\n      {%- endif -%}\n   {% endfor %}\n\n{{ only_latex }}\n\n   {% for img in images %}\n   .. image:: {{ build_dir }}/{{ img.basename }}.pdf\n   {% endfor %}\n\n""""""\n\nclass ImageFile(object):\n    def __init__(self, basename, dirname):\n        self.basename = basename\n        self.dirname = dirname\n        self.formats = []\n\n    def filename(self, format):\n        return os.path.join(self.dirname, ""%s.%s"" % (self.basename, format))\n\n    def filenames(self):\n        return [self.filename(fmt) for fmt in self.formats]\n\ndef run(arguments, content, options, state_machine, state, lineno):\n    if arguments and content:\n        raise RuntimeError(""plot:: directive can\'t have both args and content"")\n\n    document = state_machine.document\n    config = document.settings.env.config\n\n    options.setdefault(\'include-source\', config.plot_include_source)\n\n    # determine input\n    rst_file = document.attributes[\'source\']\n    rst_dir = os.path.dirname(rst_file)\n\n    if arguments:\n        if not config.plot_basedir:\n            source_file_name = os.path.join(rst_dir,\n                                            directives.uri(arguments[0]))\n        else:\n            source_file_name = os.path.join(setup.confdir, config.plot_basedir,\n                                            directives.uri(arguments[0]))\n        code = open(source_file_name, \'r\').read()\n        output_base = os.path.basename(source_file_name)\n    else:\n        source_file_name = rst_file\n        code = textwrap.dedent(""\\n"".join(map(str, content)))\n        counter = document.attributes.get(\'_plot_counter\', 0) + 1\n        document.attributes[\'_plot_counter\'] = counter\n        base, ext = os.path.splitext(os.path.basename(source_file_name))\n        output_base = \'%s-%d.py\' % (base, counter)\n\n    base, source_ext = os.path.splitext(output_base)\n    if source_ext in (\'.py\', \'.rst\', \'.txt\'):\n        output_base = base\n    else:\n        source_ext = \'\'\n\n    # ensure that LaTeX includegraphics doesn\'t choke in foo.bar.pdf filenames\n    output_base = output_base.replace(\'.\', \'-\')\n\n    # is it in doctest format?\n    is_doctest = contains_doctest(code)\n    if \'format\' in options:\n        if options[\'format\'] == \'python\':\n            is_doctest = False\n        else:\n            is_doctest = True\n\n    # determine output directory name fragment\n    source_rel_name = relpath(source_file_name, setup.confdir)\n    source_rel_dir = os.path.dirname(source_rel_name)\n    while source_rel_dir.startswith(os.path.sep):\n        source_rel_dir = source_rel_dir[1:]\n\n    # build_dir: where to place output files (temporarily)\n    build_dir = os.path.join(os.path.dirname(setup.app.doctreedir),\n                             \'plot_directive\',\n                             source_rel_dir)\n    if not os.path.exists(build_dir):\n        os.makedirs(build_dir)\n\n    # output_dir: final location in the builder\'s directory\n    dest_dir = os.path.abspath(os.path.join(setup.app.builder.outdir,\n                                            source_rel_dir))\n\n    # how to link to files from the RST file\n    dest_dir_link = os.path.join(relpath(setup.confdir, rst_dir),\n                                 source_rel_dir).replace(os.path.sep, \'/\')\n    build_dir_link = relpath(build_dir, rst_dir).replace(os.path.sep, \'/\')\n    source_link = dest_dir_link + \'/\' + output_base + source_ext\n\n    # make figures\n    try:\n        results = makefig(code, source_file_name, build_dir, output_base,\n                          config)\n        errors = []\n    except PlotError as err:\n        reporter = state.memo.reporter\n        sm = reporter.system_message(\n            2, ""Exception occurred in plotting %s: %s"" % (output_base, err),\n            line=lineno)\n        results = [(code, [])]\n        errors = [sm]\n\n    # generate output restructuredtext\n    total_lines = []\n    for j, (code_piece, images) in enumerate(results):\n        if options[\'include-source\']:\n            if is_doctest:\n                lines = [\'\']\n                lines += [row.rstrip() for row in code_piece.split(\'\\n\')]\n            else:\n                lines = [\'.. code-block:: python\', \'\']\n                lines += [\'    %s\' % row.rstrip()\n                          for row in code_piece.split(\'\\n\')]\n            source_code = ""\\n"".join(lines)\n        else:\n            source_code = """"\n\n        opts = [\':%s: %s\' % (key, val) for key, val in list(options.items())\n                if key in (\'alt\', \'height\', \'width\', \'scale\', \'align\', \'class\')]\n\n        only_html = "".. only:: html""\n        only_latex = "".. only:: latex""\n\n        if j == 0:\n            src_link = source_link\n        else:\n            src_link = None\n\n        result = format_template(\n            TEMPLATE,\n            dest_dir=dest_dir_link,\n            build_dir=build_dir_link,\n            source_link=src_link,\n            multi_image=len(images) > 1,\n            only_html=only_html,\n            only_latex=only_latex,\n            options=opts,\n            images=images,\n            source_code=source_code,\n            html_show_formats=config.plot_html_show_formats)\n\n        total_lines.extend(result.split(""\\n""))\n        total_lines.extend(""\\n"")\n\n    if total_lines:\n        state_machine.insert_input(total_lines, source=source_file_name)\n\n    # copy image files to builder\'s output directory\n    if not os.path.exists(dest_dir):\n        os.makedirs(dest_dir)\n\n    for code_piece, images in results:\n        for img in images:\n            for fn in img.filenames():\n                shutil.copyfile(fn, os.path.join(dest_dir,\n                                                 os.path.basename(fn)))\n\n    # copy script (if necessary)\n    if source_file_name == rst_file:\n        target_name = os.path.join(dest_dir, output_base + source_ext)\n        f = open(target_name, \'w\')\n        f.write(unescape_doctest(code))\n        f.close()\n\n    return errors\n\n\n#------------------------------------------------------------------------------\n# Run code and capture figures\n#------------------------------------------------------------------------------\n\nimport matplotlib\nmatplotlib.use(\'Agg\')\nimport matplotlib.pyplot as plt\nimport matplotlib.image as image\nfrom matplotlib import _pylab_helpers\n\nimport exceptions\n\ndef contains_doctest(text):\n    try:\n        # check if it\'s valid Python as-is\n        compile(text, \'<string>\', \'exec\')\n        return False\n    except SyntaxError:\n        pass\n    r = re.compile(r\'^\\s*>>>\', re.M)\n    m = r.search(text)\n    return bool(m)\n\ndef unescape_doctest(text):\n    """"""\n    Extract code from a piece of text, which contains either Python code\n    or doctests.\n\n    """"""\n    if not contains_doctest(text):\n        return text\n\n    code = """"\n    for line in text.split(""\\n""):\n        m = re.match(r\'^\\s*(>>>|\\.\\.\\.) (.*)$\', line)\n        if m:\n            code += m.group(2) + ""\\n""\n        elif line.strip():\n            code += ""# "" + line.strip() + ""\\n""\n        else:\n            code += ""\\n""\n    return code\n\ndef split_code_at_show(text):\n    """"""\n    Split code at plt.show()\n\n    """"""\n\n    parts = []\n    is_doctest = contains_doctest(text)\n\n    part = []\n    for line in text.split(""\\n""):\n        if (not is_doctest and line.strip() == \'plt.show()\') or \\\n               (is_doctest and line.strip() == \'>>> plt.show()\'):\n            part.append(line)\n            parts.append(""\\n"".join(part))\n            part = []\n        else:\n            part.append(line)\n    if ""\\n"".join(part).strip():\n        parts.append(""\\n"".join(part))\n    return parts\n\nclass PlotError(RuntimeError):\n    pass\n\ndef run_code(code, code_path, ns=None):\n    # Change the working directory to the directory of the example, so\n    # it can get at its data files, if any.\n    pwd = os.getcwd()\n    old_sys_path = list(sys.path)\n    if code_path is not None:\n        dirname = os.path.abspath(os.path.dirname(code_path))\n        os.chdir(dirname)\n        sys.path.insert(0, dirname)\n\n    # Redirect stdout\n    stdout = sys.stdout\n    sys.stdout = StringIO()\n\n    # Reset sys.argv\n    old_sys_argv = sys.argv\n    sys.argv = [code_path]\n    \n    try:\n        try:\n            code = unescape_doctest(code)\n            if ns is None:\n                ns = {}\n            if not ns:\n                exec(setup.config.plot_pre_code, ns)\n            exec(code, ns)\n        except (Exception, SystemExit) as err:\n            raise PlotError(traceback.format_exc())\n    finally:\n        os.chdir(pwd)\n        sys.argv = old_sys_argv\n        sys.path[:] = old_sys_path\n        sys.stdout = stdout\n    return ns\n\n\n#------------------------------------------------------------------------------\n# Generating figures\n#------------------------------------------------------------------------------\n\ndef out_of_date(original, derived):\n    """"""\n    Returns True if derivative is out-of-date wrt original,\n    both of which are full file paths.\n    """"""\n    return (not os.path.exists(derived)\n            or os.stat(derived).st_mtime < os.stat(original).st_mtime)\n\n\ndef makefig(code, code_path, output_dir, output_base, config):\n    """"""\n    Run a pyplot script *code* and save the images under *output_dir*\n    with file names derived from *output_base*\n\n    """"""\n\n    # -- Parse format list\n    default_dpi = {\'png\': 80, \'hires.png\': 200, \'pdf\': 50}\n    formats = []\n    for fmt in config.plot_formats:\n        if isinstance(fmt, str):\n            formats.append((fmt, default_dpi.get(fmt, 80)))\n        elif type(fmt) in (tuple, list) and len(fmt)==2:\n            formats.append((str(fmt[0]), int(fmt[1])))\n        else:\n            raise PlotError(\'invalid image format ""%r"" in plot_formats\' % fmt)\n\n    # -- Try to determine if all images already exist\n\n    code_pieces = split_code_at_show(code)\n\n    # Look for single-figure output files first\n    all_exists = True\n    img = ImageFile(output_base, output_dir)\n    for format, dpi in formats:\n        if out_of_date(code_path, img.filename(format)):\n            all_exists = False\n            break\n        img.formats.append(format)\n\n    if all_exists:\n        return [(code, [img])]\n\n    # Then look for multi-figure output files\n    results = []\n    all_exists = True\n    for i, code_piece in enumerate(code_pieces):\n        images = []\n        for j in range(1000):\n            img = ImageFile(\'%s_%02d_%02d\' % (output_base, i, j), output_dir)\n            for format, dpi in formats:\n                if out_of_date(code_path, img.filename(format)):\n                    all_exists = False\n                    break\n                img.formats.append(format)\n\n            # assume that if we have one, we have them all\n            if not all_exists:\n                all_exists = (j > 0)\n                break\n            images.append(img)\n        if not all_exists:\n            break\n        results.append((code_piece, images))\n\n    if all_exists:\n        return results\n\n    # -- We didn\'t find the files, so build them\n\n    results = []\n    ns = {}\n\n    for i, code_piece in enumerate(code_pieces):\n        # Clear between runs\n        plt.close(\'all\')\n\n        # Run code\n        run_code(code_piece, code_path, ns)\n\n        # Collect images\n        images = []\n        fig_managers = _pylab_helpers.Gcf.get_all_fig_managers()\n        for j, figman in enumerate(fig_managers):\n            if len(fig_managers) == 1 and len(code_pieces) == 1:\n                img = ImageFile(output_base, output_dir)\n            else:\n                img = ImageFile(""%s_%02d_%02d"" % (output_base, i, j),\n                                output_dir)\n            images.append(img)\n            for format, dpi in formats:\n                try:\n                    figman.canvas.figure.savefig(img.filename(format), dpi=dpi)\n                except exceptions.BaseException as err:\n                    raise PlotError(traceback.format_exc())\n                img.formats.append(format)\n\n        # Results\n        results.append((code_piece, images))\n\n    return results\n\n\n#------------------------------------------------------------------------------\n# Relative pathnames\n#------------------------------------------------------------------------------\n\ntry:\n    from os.path import relpath\nexcept ImportError:\n    # Copied from Python 2.7\n    if \'posix\' in sys.builtin_module_names:\n        def relpath(path, start=os.path.curdir):\n            """"""Return a relative version of a path""""""\n            from os.path import sep, curdir, join, abspath, commonprefix, \\\n                 pardir\n\n            if not path:\n                raise ValueError(""no path specified"")\n\n            start_list = abspath(start).split(sep)\n            path_list = abspath(path).split(sep)\n\n            # Work out how much of the filepath is shared by start and path.\n            i = len(commonprefix([start_list, path_list]))\n\n            rel_list = [pardir] * (len(start_list)-i) + path_list[i:]\n            if not rel_list:\n                return curdir\n            return join(*rel_list)\n    elif \'nt\' in sys.builtin_module_names:\n        def relpath(path, start=os.path.curdir):\n            """"""Return a relative version of a path""""""\n            from os.path import sep, curdir, join, abspath, commonprefix, \\\n                 pardir, splitunc\n\n            if not path:\n                raise ValueError(""no path specified"")\n            start_list = abspath(start).split(sep)\n            path_list = abspath(path).split(sep)\n            if start_list[0].lower() != path_list[0].lower():\n                unc_path, rest = splitunc(path)\n                unc_start, rest = splitunc(start)\n                if bool(unc_path) ^ bool(unc_start):\n                    raise ValueError(""Cannot mix UNC and non-UNC paths (%s and %s)""\n                                                                        % (path, start))\n                else:\n                    raise ValueError(""path is on drive %s, start on drive %s""\n                                                        % (path_list[0], start_list[0]))\n            # Work out how much of the filepath is shared by start and path.\n            for i in range(min(len(start_list), len(path_list))):\n                if start_list[i].lower() != path_list[i].lower():\n                    break\n            else:\n                i += 1\n\n            rel_list = [pardir] * (len(start_list)-i) + path_list[i:]\n            if not rel_list:\n                return curdir\n            return join(*rel_list)\n    else:\n        raise RuntimeError(""Unsupported platform (no relpath available!)"")\n'"
docs/sphinxext/numpydoc/traitsdoc.py,0,"b'""""""\n=========\ntraitsdoc\n=========\n\nSphinx extension that handles docstrings in the Numpy standard format, [1]\nand support Traits [2].\n\nThis extension can be used as a replacement for ``numpydoc`` when support\nfor Traits is required.\n\n.. [1] http://projects.scipy.org/numpy/wiki/CodingStyleGuidelines#docstring-standard\n.. [2] http://code.enthought.com/projects/traits/\n\n""""""\nfrom __future__ import division, absolute_import, print_function\n\nimport inspect\nimport os\nimport pydoc\nimport collections\n\nfrom . import docscrape\nfrom . import docscrape_sphinx\nfrom .docscrape_sphinx import SphinxClassDoc, SphinxFunctionDoc, SphinxDocString\n\nfrom . import numpydoc\n\nfrom . import comment_eater\n\nclass SphinxTraitsDoc(SphinxClassDoc):\n    def __init__(self, cls, modulename=\'\', func_doc=SphinxFunctionDoc):\n        if not inspect.isclass(cls):\n            raise ValueError(""Initialise using a class. Got %r"" % cls)\n        self._cls = cls\n\n        if modulename and not modulename.endswith(\'.\'):\n            modulename += \'.\'\n        self._mod = modulename\n        self._name = cls.__name__\n        self._func_doc = func_doc\n\n        docstring = pydoc.getdoc(cls)\n        docstring = docstring.split(\'\\n\')\n\n        # De-indent paragraph\n        try:\n            indent = min(len(s) - len(s.lstrip()) for s in docstring\n                         if s.strip())\n        except ValueError:\n            indent = 0\n\n        for n,line in enumerate(docstring):\n            docstring[n] = docstring[n][indent:]\n\n        self._doc = docscrape.Reader(docstring)\n        self._parsed_data = {\n            \'Signature\': \'\',\n            \'Summary\': \'\',\n            \'Description\': [],\n            \'Extended Summary\': [],\n            \'Parameters\': [],\n            \'Returns\': [],\n            \'Raises\': [],\n            \'Warns\': [],\n            \'Other Parameters\': [],\n            \'Traits\': [],\n            \'Methods\': [],\n            \'See Also\': [],\n            \'Notes\': [],\n            \'References\': \'\',\n            \'Example\': \'\',\n            \'Examples\': \'\',\n            \'index\': {}\n            }\n\n        self._parse()\n\n    def _str_summary(self):\n        return self[\'Summary\'] + [\'\']\n\n    def _str_extended_summary(self):\n        return self[\'Description\'] + self[\'Extended Summary\'] + [\'\']\n\n    def __str__(self, indent=0, func_role=""func""):\n        out = []\n        out += self._str_signature()\n        out += self._str_index() + [\'\']\n        out += self._str_summary()\n        out += self._str_extended_summary()\n        for param_list in (\'Parameters\', \'Traits\', \'Methods\',\n                           \'Returns\',\'Raises\'):\n            out += self._str_param_list(param_list)\n        out += self._str_see_also(""obj"")\n        out += self._str_section(\'Notes\')\n        out += self._str_references()\n        out += self._str_section(\'Example\')\n        out += self._str_section(\'Examples\')\n        out = self._str_indent(out,indent)\n        return \'\\n\'.join(out)\n\ndef looks_like_issubclass(obj, classname):\n    """""" Return True if the object has a class or superclass with the given class\n    name.\n\n    Ignores old-style classes.\n    """"""\n    t = obj\n    if t.__name__ == classname:\n        return True\n    for klass in t.__mro__:\n        if klass.__name__ == classname:\n            return True\n    return False\n\ndef get_doc_object(obj, what=None, config=None):\n    if what is None:\n        if inspect.isclass(obj):\n            what = \'class\'\n        elif inspect.ismodule(obj):\n            what = \'module\'\n        elif isinstance(obj, collections.Callable):\n            what = \'function\'\n        else:\n            what = \'object\'\n    if what == \'class\':\n        doc = SphinxTraitsDoc(obj, \'\', func_doc=SphinxFunctionDoc, config=config)\n        if looks_like_issubclass(obj, \'HasTraits\'):\n            for name, trait, comment in comment_eater.get_class_traits(obj):\n                # Exclude private traits.\n                if not name.startswith(\'_\'):\n                    doc[\'Traits\'].append((name, trait, comment.splitlines()))\n        return doc\n    elif what in (\'function\', \'method\'):\n        return SphinxFunctionDoc(obj, \'\', config=config)\n    else:\n        return SphinxDocString(pydoc.getdoc(obj), config=config)\n\ndef setup(app):\n    # init numpydoc\n    numpydoc.setup(app, get_doc_object)\n\n'"
docs/themes/sphinx_rtd_theme/__init__.py,0,"b'""""""Sphinx ReadTheDocs theme.\n\nFrom https://github.com/ryan-roemer/sphinx-bootstrap-theme.\n\n""""""\nimport os\n\nVERSION = (0, 1, 8)\n\n__version__ = ""."".join(str(v) for v in VERSION)\n__version_full__ = __version__\n\n\ndef get_html_theme_path():\n    """"""Return list of HTML theme paths.""""""\n    cur_dir = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))\n    return cur_dir\n'"
docs/sphinxext/numpydoc/tests/test_docscrape.py,0,"b'# -*- encoding:utf-8 -*-\nfrom __future__ import division, absolute_import, print_function\n\nimport sys, textwrap\n\nfrom numpydoc.docscrape import NumpyDocString, FunctionDoc, ClassDoc\nfrom numpydoc.docscrape_sphinx import SphinxDocString, SphinxClassDoc\nfrom nose.tools import *\n\nif sys.version_info[0] >= 3:\n    sixu = lambda s: s\nelse:\n    sixu = lambda s: unicode(s, \'unicode_escape\')\n\n\ndoc_txt = \'\'\'\\\n  numpy.multivariate_normal(mean, cov, shape=None, spam=None)\n\n  Draw values from a multivariate normal distribution with specified\n  mean and covariance.\n\n  The multivariate normal or Gaussian distribution is a generalisation\n  of the one-dimensional normal distribution to higher dimensions.\n\n  Parameters\n  ----------\n  mean : (N,) ndarray\n      Mean of the N-dimensional distribution.\n\n      .. math::\n\n         (1+2+3)/3\n\n  cov : (N, N) ndarray\n      Covariance matrix of the distribution.\n  shape : tuple of ints\n      Given a shape of, for example, (m,n,k), m*n*k samples are\n      generated, and packed in an m-by-n-by-k arrangement.  Because\n      each sample is N-dimensional, the output shape is (m,n,k,N).\n\n  Returns\n  -------\n  out : ndarray\n      The drawn samples, arranged according to `shape`.  If the\n      shape given is (m,n,...), then the shape of `out` is is\n      (m,n,...,N).\n\n      In other words, each entry ``out[i,j,...,:]`` is an N-dimensional\n      value drawn from the distribution.\n  list of str\n      This is not a real return value.  It exists to test\n      anonymous return values.\n\n  Other Parameters\n  ----------------\n  spam : parrot\n      A parrot off its mortal coil.\n\n  Raises\n  ------\n  RuntimeError\n      Some error\n\n  Warns\n  -----\n  RuntimeWarning\n      Some warning\n\n  Warnings\n  --------\n  Certain warnings apply.\n\n  Notes\n  -----\n  Instead of specifying the full covariance matrix, popular\n  approximations include:\n\n    - Spherical covariance (`cov` is a multiple of the identity matrix)\n    - Diagonal covariance (`cov` has non-negative elements only on the diagonal)\n\n  This geometrical property can be seen in two dimensions by plotting\n  generated data-points:\n\n  >>> mean = [0,0]\n  >>> cov = [[1,0],[0,100]] # diagonal covariance, points lie on x or y-axis\n\n  >>> x,y = multivariate_normal(mean,cov,5000).T\n  >>> plt.plot(x,y,\'x\'); plt.axis(\'equal\'); plt.show()\n\n  Note that the covariance matrix must be symmetric and non-negative\n  definite.\n\n  References\n  ----------\n  .. [1] A. Papoulis, ""Probability, Random Variables, and Stochastic\n         Processes,"" 3rd ed., McGraw-Hill Companies, 1991\n  .. [2] R.O. Duda, P.E. Hart, and D.G. Stork, ""Pattern Classification,""\n         2nd ed., Wiley, 2001.\n\n  See Also\n  --------\n  some, other, funcs\n  otherfunc : relationship\n\n  Examples\n  --------\n  >>> mean = (1,2)\n  >>> cov = [[1,0],[1,0]]\n  >>> x = multivariate_normal(mean,cov,(3,3))\n  >>> print x.shape\n  (3, 3, 2)\n\n  The following is probably true, given that 0.6 is roughly twice the\n  standard deviation:\n\n  >>> print list( (x[0,0,:] - mean) < 0.6 )\n  [True, True]\n\n  .. index:: random\n     :refguide: random;distributions, random;gauss\n\n  \'\'\'\ndoc = NumpyDocString(doc_txt)\n\n\ndef test_signature():\n    assert doc[\'Signature\'].startswith(\'numpy.multivariate_normal(\')\n    assert doc[\'Signature\'].endswith(\'spam=None)\')\n\ndef test_summary():\n    assert doc[\'Summary\'][0].startswith(\'Draw values\')\n    assert doc[\'Summary\'][-1].endswith(\'covariance.\')\n\ndef test_extended_summary():\n    assert doc[\'Extended Summary\'][0].startswith(\'The multivariate normal\')\n\ndef test_parameters():\n    assert_equal(len(doc[\'Parameters\']), 3)\n    assert_equal([n for n,_,_ in doc[\'Parameters\']], [\'mean\',\'cov\',\'shape\'])\n\n    arg, arg_type, desc = doc[\'Parameters\'][1]\n    assert_equal(arg_type, \'(N, N) ndarray\')\n    assert desc[0].startswith(\'Covariance matrix\')\n    assert doc[\'Parameters\'][0][-1][-2] == \'   (1+2+3)/3\'\n\ndef test_other_parameters():\n    assert_equal(len(doc[\'Other Parameters\']), 1)\n    assert_equal([n for n,_,_ in doc[\'Other Parameters\']], [\'spam\'])\n    arg, arg_type, desc = doc[\'Other Parameters\'][0]\n    assert_equal(arg_type, \'parrot\')\n    assert desc[0].startswith(\'A parrot off its mortal coil\')\n\ndef test_returns():\n    assert_equal(len(doc[\'Returns\']), 2)\n    arg, arg_type, desc = doc[\'Returns\'][0]\n    assert_equal(arg, \'out\')\n    assert_equal(arg_type, \'ndarray\')\n    assert desc[0].startswith(\'The drawn samples\')\n    assert desc[-1].endswith(\'distribution.\')\n\n    arg, arg_type, desc = doc[\'Returns\'][1]\n    assert_equal(arg, \'list of str\')\n    assert_equal(arg_type, \'\')\n    assert desc[0].startswith(\'This is not a real\')\n    assert desc[-1].endswith(\'anonymous return values.\')\n\ndef test_notes():\n    assert doc[\'Notes\'][0].startswith(\'Instead\')\n    assert doc[\'Notes\'][-1].endswith(\'definite.\')\n    assert_equal(len(doc[\'Notes\']), 17)\n\ndef test_references():\n    assert doc[\'References\'][0].startswith(\'..\')\n    assert doc[\'References\'][-1].endswith(\'2001.\')\n\ndef test_examples():\n    assert doc[\'Examples\'][0].startswith(\'>>>\')\n    assert doc[\'Examples\'][-1].endswith(\'True]\')\n\ndef test_index():\n    assert_equal(doc[\'index\'][\'default\'], \'random\')\n    assert_equal(len(doc[\'index\']), 2)\n    assert_equal(len(doc[\'index\'][\'refguide\']), 2)\n\ndef non_blank_line_by_line_compare(a,b):\n    a = textwrap.dedent(a)\n    b = textwrap.dedent(b)\n    a = [l.rstrip() for l in a.split(\'\\n\') if l.strip()]\n    b = [l.rstrip() for l in b.split(\'\\n\') if l.strip()]\n    for n,line in enumerate(a):\n        if not line == b[n]:\n            raise AssertionError(""Lines %s of a and b differ: ""\n                                 ""\\n>>> %s\\n<<< %s\\n"" %\n                                 (n,line,b[n]))\ndef test_str():\n    non_blank_line_by_line_compare(str(doc),\n""""""numpy.multivariate_normal(mean, cov, shape=None, spam=None)\n\nDraw values from a multivariate normal distribution with specified\nmean and covariance.\n\nThe multivariate normal or Gaussian distribution is a generalisation\nof the one-dimensional normal distribution to higher dimensions.\n\nParameters\n----------\nmean : (N,) ndarray\n    Mean of the N-dimensional distribution.\n\n    .. math::\n\n       (1+2+3)/3\n\ncov : (N, N) ndarray\n    Covariance matrix of the distribution.\nshape : tuple of ints\n    Given a shape of, for example, (m,n,k), m*n*k samples are\n    generated, and packed in an m-by-n-by-k arrangement.  Because\n    each sample is N-dimensional, the output shape is (m,n,k,N).\n\nReturns\n-------\nout : ndarray\n    The drawn samples, arranged according to `shape`.  If the\n    shape given is (m,n,...), then the shape of `out` is is\n    (m,n,...,N).\n\n    In other words, each entry ``out[i,j,...,:]`` is an N-dimensional\n    value drawn from the distribution.\nlist of str\n    This is not a real return value.  It exists to test\n    anonymous return values.\n\nOther Parameters\n----------------\nspam : parrot\n    A parrot off its mortal coil.\n\nRaises\n------\nRuntimeError\n    Some error\n\nWarns\n-----\nRuntimeWarning\n    Some warning\n\nWarnings\n--------\nCertain warnings apply.\n\nSee Also\n--------\n`some`_, `other`_, `funcs`_\n\n`otherfunc`_\n    relationship\n\nNotes\n-----\nInstead of specifying the full covariance matrix, popular\napproximations include:\n\n  - Spherical covariance (`cov` is a multiple of the identity matrix)\n  - Diagonal covariance (`cov` has non-negative elements only on the diagonal)\n\nThis geometrical property can be seen in two dimensions by plotting\ngenerated data-points:\n\n>>> mean = [0,0]\n>>> cov = [[1,0],[0,100]] # diagonal covariance, points lie on x or y-axis\n\n>>> x,y = multivariate_normal(mean,cov,5000).T\n>>> plt.plot(x,y,\'x\'); plt.axis(\'equal\'); plt.show()\n\nNote that the covariance matrix must be symmetric and non-negative\ndefinite.\n\nReferences\n----------\n.. [1] A. Papoulis, ""Probability, Random Variables, and Stochastic\n       Processes,"" 3rd ed., McGraw-Hill Companies, 1991\n.. [2] R.O. Duda, P.E. Hart, and D.G. Stork, ""Pattern Classification,""\n       2nd ed., Wiley, 2001.\n\nExamples\n--------\n>>> mean = (1,2)\n>>> cov = [[1,0],[1,0]]\n>>> x = multivariate_normal(mean,cov,(3,3))\n>>> print x.shape\n(3, 3, 2)\n\nThe following is probably true, given that 0.6 is roughly twice the\nstandard deviation:\n\n>>> print list( (x[0,0,:] - mean) < 0.6 )\n[True, True]\n\n.. index:: random\n   :refguide: random;distributions, random;gauss"""""")\n\n\ndef test_sphinx_str():\n    sphinx_doc = SphinxDocString(doc_txt)\n    non_blank_line_by_line_compare(str(sphinx_doc),\n""""""\n.. index:: random\n   single: random;distributions, random;gauss\n\nDraw values from a multivariate normal distribution with specified\nmean and covariance.\n\nThe multivariate normal or Gaussian distribution is a generalisation\nof the one-dimensional normal distribution to higher dimensions.\n\n:Parameters:\n\n    **mean** : (N,) ndarray\n\n        Mean of the N-dimensional distribution.\n\n        .. math::\n\n           (1+2+3)/3\n\n    **cov** : (N, N) ndarray\n\n        Covariance matrix of the distribution.\n\n    **shape** : tuple of ints\n\n        Given a shape of, for example, (m,n,k), m*n*k samples are\n        generated, and packed in an m-by-n-by-k arrangement.  Because\n        each sample is N-dimensional, the output shape is (m,n,k,N).\n\n:Returns:\n\n    **out** : ndarray\n\n        The drawn samples, arranged according to `shape`.  If the\n        shape given is (m,n,...), then the shape of `out` is is\n        (m,n,...,N).\n\n        In other words, each entry ``out[i,j,...,:]`` is an N-dimensional\n        value drawn from the distribution.\n\n    list of str\n\n        This is not a real return value.  It exists to test\n        anonymous return values.\n\n:Other Parameters:\n\n    **spam** : parrot\n\n        A parrot off its mortal coil.\n\n:Raises:\n\n    **RuntimeError**\n\n        Some error\n\n:Warns:\n\n    **RuntimeWarning**\n\n        Some warning\n\n.. warning::\n\n    Certain warnings apply.\n\n.. seealso::\n\n    :obj:`some`, :obj:`other`, :obj:`funcs`\n\n    :obj:`otherfunc`\n        relationship\n\n.. rubric:: Notes\n\nInstead of specifying the full covariance matrix, popular\napproximations include:\n\n  - Spherical covariance (`cov` is a multiple of the identity matrix)\n  - Diagonal covariance (`cov` has non-negative elements only on the diagonal)\n\nThis geometrical property can be seen in two dimensions by plotting\ngenerated data-points:\n\n>>> mean = [0,0]\n>>> cov = [[1,0],[0,100]] # diagonal covariance, points lie on x or y-axis\n\n>>> x,y = multivariate_normal(mean,cov,5000).T\n>>> plt.plot(x,y,\'x\'); plt.axis(\'equal\'); plt.show()\n\nNote that the covariance matrix must be symmetric and non-negative\ndefinite.\n\n.. rubric:: References\n\n.. [1] A. Papoulis, ""Probability, Random Variables, and Stochastic\n       Processes,"" 3rd ed., McGraw-Hill Companies, 1991\n.. [2] R.O. Duda, P.E. Hart, and D.G. Stork, ""Pattern Classification,""\n       2nd ed., Wiley, 2001.\n\n.. only:: latex\n\n   [1]_, [2]_\n\n.. rubric:: Examples\n\n>>> mean = (1,2)\n>>> cov = [[1,0],[1,0]]\n>>> x = multivariate_normal(mean,cov,(3,3))\n>>> print x.shape\n(3, 3, 2)\n\nThe following is probably true, given that 0.6 is roughly twice the\nstandard deviation:\n\n>>> print list( (x[0,0,:] - mean) < 0.6 )\n[True, True]\n"""""")\n\n\ndoc2 = NumpyDocString(""""""\n    Returns array of indices of the maximum values of along the given axis.\n\n    Parameters\n    ----------\n    a : {array_like}\n        Array to look in.\n    axis : {None, integer}\n        If None, the index is into the flattened array, otherwise along\n        the specified axis"""""")\n\ndef test_parameters_without_extended_description():\n    assert_equal(len(doc2[\'Parameters\']), 2)\n\ndoc3 = NumpyDocString(""""""\n    my_signature(*params, **kwds)\n\n    Return this and that.\n    """""")\n\ndef test_escape_stars():\n    signature = str(doc3).split(\'\\n\')[0]\n    assert_equal(signature, \'my_signature(\\*params, \\*\\*kwds)\')\n\ndoc4 = NumpyDocString(\n    """"""a.conj()\n\n    Return an array with all complex-valued elements conjugated."""""")\n\ndef test_empty_extended_summary():\n    assert_equal(doc4[\'Extended Summary\'], [])\n\ndoc5 = NumpyDocString(\n    """"""\n    a.something()\n\n    Raises\n    ------\n    LinAlgException\n        If array is singular.\n\n    Warns\n    -----\n    SomeWarning\n        If needed\n    """""")\n\ndef test_raises():\n    assert_equal(len(doc5[\'Raises\']), 1)\n    name,_,desc = doc5[\'Raises\'][0]\n    assert_equal(name,\'LinAlgException\')\n    assert_equal(desc,[\'If array is singular.\'])\n\ndef test_warns():\n    assert_equal(len(doc5[\'Warns\']), 1)\n    name,_,desc = doc5[\'Warns\'][0]\n    assert_equal(name,\'SomeWarning\')\n    assert_equal(desc,[\'If needed\'])\n\ndef test_see_also():\n    doc6 = NumpyDocString(\n    """"""\n    z(x,theta)\n\n    See Also\n    --------\n    func_a, func_b, func_c\n    func_d : some equivalent func\n    foo.func_e : some other func over\n             multiple lines\n    func_f, func_g, :meth:`func_h`, func_j,\n    func_k\n    :obj:`baz.obj_q`\n    :class:`class_j`: fubar\n        foobar\n    """""")\n\n    assert len(doc6[\'See Also\']) == 12\n    for func, desc, role in doc6[\'See Also\']:\n        if func in (\'func_a\', \'func_b\', \'func_c\', \'func_f\',\n                    \'func_g\', \'func_h\', \'func_j\', \'func_k\', \'baz.obj_q\'):\n            assert(not desc)\n        else:\n            assert(desc)\n\n        if func == \'func_h\':\n            assert role == \'meth\'\n        elif func == \'baz.obj_q\':\n            assert role == \'obj\'\n        elif func == \'class_j\':\n            assert role == \'class\'\n        else:\n            assert role is None\n\n        if func == \'func_d\':\n            assert desc == [\'some equivalent func\']\n        elif func == \'foo.func_e\':\n            assert desc == [\'some other func over\', \'multiple lines\']\n        elif func == \'class_j\':\n            assert desc == [\'fubar\', \'foobar\']\n\ndef test_see_also_print():\n    class Dummy(object):\n        """"""\n        See Also\n        --------\n        func_a, func_b\n        func_c : some relationship\n                 goes here\n        func_d\n        """"""\n        pass\n\n    obj = Dummy()\n    s = str(FunctionDoc(obj, role=\'func\'))\n    assert(\':func:`func_a`, :func:`func_b`\' in s)\n    assert(\'    some relationship\' in s)\n    assert(\':func:`func_d`\' in s)\n\ndoc7 = NumpyDocString(""""""\n\n        Doc starts on second line.\n\n        """""")\n\ndef test_empty_first_line():\n    assert doc7[\'Summary\'][0].startswith(\'Doc starts\')\n\n\ndef test_no_summary():\n    str(SphinxDocString(""""""\n    Parameters\n    ----------""""""))\n\n\ndef test_unicode():\n    doc = SphinxDocString(""""""\n    \xc3\xb6\xc3\xa4\xc3\xb6\xc3\xa4\xc3\xb6\xc3\xa4\xc3\xb6\xc3\xa4\xc3\xb6\xc3\xa5\xc3\xa5\xc3\xa5\xc3\xa5\n\n    \xc3\xb6\xc3\xa4\xc3\xb6\xc3\xa4\xc3\xb6\xc3\xa4\xc3\xb6\xc3\xb6\xc3\xa4\xc3\xa5\xc3\xa5\xc3\xa5\n\n    Parameters\n    ----------\n    \xc3\xa5\xc3\xa5\xc3\xa5 : \xc3\xa4\xc3\xa4\xc3\xa4\n        \xc3\xb6\xc3\xb6\xc3\xb6\n\n    Returns\n    -------\n    \xc3\xa5\xc3\xa5\xc3\xa5 : \xc3\xb6\xc3\xb6\xc3\xb6\n        \xc3\xa4\xc3\xa4\xc3\xa4\n\n    """""")\n    assert isinstance(doc[\'Summary\'][0], str)\n    assert doc[\'Summary\'][0] == \'\xc3\xb6\xc3\xa4\xc3\xb6\xc3\xa4\xc3\xb6\xc3\xa4\xc3\xb6\xc3\xa4\xc3\xb6\xc3\xa5\xc3\xa5\xc3\xa5\xc3\xa5\'\n\ndef test_plot_examples():\n    cfg = dict(use_plots=True)\n\n    doc = SphinxDocString(""""""\n    Examples\n    --------\n    >>> import matplotlib.pyplot as plt\n    >>> plt.plot([1,2,3],[4,5,6])\n    >>> plt.show()\n    """""", config=cfg)\n    assert \'plot::\' in str(doc), str(doc)\n\n    doc = SphinxDocString(""""""\n    Examples\n    --------\n    .. plot::\n\n       import matplotlib.pyplot as plt\n       plt.plot([1,2,3],[4,5,6])\n       plt.show()\n    """""", config=cfg)\n    assert str(doc).count(\'plot::\') == 1, str(doc)\n\ndef test_class_members():\n\n    class Dummy(object):\n        """"""\n        Dummy class.\n\n        """"""\n        def spam(self, a, b):\n            """"""Spam\\n\\nSpam spam.""""""\n            pass\n        def ham(self, c, d):\n            """"""Cheese\\n\\nNo cheese.""""""\n            pass\n        @property\n        def spammity(self):\n            """"""Spammity index""""""\n            return 0.95\n\n        class Ignorable(object):\n            """"""local class, to be ignored""""""\n            pass\n\n    for cls in (ClassDoc, SphinxClassDoc):\n        doc = cls(Dummy, config=dict(show_class_members=False))\n        assert \'Methods\' not in str(doc), (cls, str(doc))\n        assert \'spam\' not in str(doc), (cls, str(doc))\n        assert \'ham\' not in str(doc), (cls, str(doc))\n        assert \'spammity\' not in str(doc), (cls, str(doc))\n        assert \'Spammity index\' not in str(doc), (cls, str(doc))\n\n        doc = cls(Dummy, config=dict(show_class_members=True))\n        assert \'Methods\' in str(doc), (cls, str(doc))\n        assert \'spam\' in str(doc), (cls, str(doc))\n        assert \'ham\' in str(doc), (cls, str(doc))\n        assert \'spammity\' in str(doc), (cls, str(doc))\n\n        if cls is SphinxClassDoc:\n            assert \'.. autosummary::\' in str(doc), str(doc)\n        else:\n            assert \'Spammity index\' in str(doc), str(doc)\n\ndef test_duplicate_signature():\n    # Duplicate function signatures occur e.g. in ufuncs, when the\n    # automatic mechanism adds one, and a more detailed comes from the\n    # docstring itself.\n\n    doc = NumpyDocString(\n    """"""\n    z(x1, x2)\n\n    z(a, theta)\n    """""")\n\n    assert doc[\'Signature\'].strip() == \'z(a, theta)\'\n\n\nclass_doc_txt = """"""\n    Foo\n\n    Parameters\n    ----------\n    f : callable ``f(t, y, *f_args)``\n        Aaa.\n    jac : callable ``jac(t, y, *jac_args)``\n        Bbb.\n\n    Attributes\n    ----------\n    t : float\n        Current time.\n    y : ndarray\n        Current variable values.\n\n    Methods\n    -------\n    a\n    b\n    c\n\n    Examples\n    --------\n    For usage examples, see `ode`.\n""""""\n\ndef test_class_members_doc():\n    doc = ClassDoc(None, class_doc_txt)\n    non_blank_line_by_line_compare(str(doc),\n    """"""\n    Foo\n\n    Parameters\n    ----------\n    f : callable ``f(t, y, *f_args)``\n        Aaa.\n    jac : callable ``jac(t, y, *jac_args)``\n        Bbb.\n\n    Examples\n    --------\n    For usage examples, see `ode`.\n\n    Attributes\n    ----------\n    t : float\n        Current time.\n    y : ndarray\n        Current variable values.\n\n    Methods\n    -------\n    a\n\n    b\n\n    c\n\n    .. index::\n\n    """""")\n\ndef test_class_members_doc_sphinx():\n    doc = SphinxClassDoc(None, class_doc_txt)\n    non_blank_line_by_line_compare(str(doc),\n    """"""\n    Foo\n\n    :Parameters:\n\n        **f** : callable ``f(t, y, *f_args)``\n\n            Aaa.\n\n        **jac** : callable ``jac(t, y, *jac_args)``\n\n            Bbb.\n\n    .. rubric:: Examples\n\n    For usage examples, see `ode`.\n\n    .. rubric:: Attributes\n\n    ===  ==========\n      t  (float) Current time.\n      y  (ndarray) Current variable values.\n    ===  ==========\n\n    .. rubric:: Methods\n\n    ===  ==========\n      a\n      b\n      c\n    ===  ==========\n\n    """""")\n\nif __name__ == ""__main__"":\n    import nose\n    nose.run()\n'"
docs/sphinxext/numpydoc/tests/test_linkcode.py,0,"b'from __future__ import division, absolute_import, print_function\n\nimport numpydoc.linkcode\n\n# No tests at the moment...\n'"
docs/sphinxext/numpydoc/tests/test_phantom_import.py,0,"b'from __future__ import division, absolute_import, print_function\n\nimport sys\nfrom nose import SkipTest\n\ndef test_import():\n    if sys.version_info[0] >= 3:\n        raise SkipTest(""phantom_import not ported to Py3"")\n\n    import numpydoc.phantom_import\n\n# No tests at the moment...\n'"
docs/sphinxext/numpydoc/tests/test_plot_directive.py,0,"b'from __future__ import division, absolute_import, print_function\n\nimport sys\nfrom nose import SkipTest\n\ndef test_import():\n    if sys.version_info[0] >= 3:\n        raise SkipTest(""plot_directive not ported to Python 3 (use the one from Matplotlib instead)"")\n    import numpydoc.plot_directive\n\n# No tests at the moment...\n'"
docs/sphinxext/numpydoc/tests/test_traitsdoc.py,0,"b'from __future__ import division, absolute_import, print_function\n\nimport sys\nfrom nose import SkipTest\n\ndef test_import():\n    if sys.version_info[0] >= 3:\n        raise SkipTest(""traitsdoc not ported to Python3"")\n    import numpydoc.traitsdoc\n\n# No tests at the moment...\n'"
