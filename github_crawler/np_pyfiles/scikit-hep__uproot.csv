file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nimport sys\nimport os.path\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\ndef get_version():\n    g = {}\n    exec(open(os.path.join(""uproot"", ""version.py"")).read(), g)\n    return g[""__version__""]\n\ndef get_description():\n    description = open(""README.rst"", ""rb"").read().decode(""utf8"", ""ignore"")\n\n    before = """""".. image:: https://raw.githubusercontent.com/scikit-hep/uproot/master/docs/source/logo-300px.png\n   :alt: uproot\n   :target: https://github.com/scikit-hep/uproot\n\n""""""\n\n    start = description.index("".. inclusion-marker-1-5-do-not-remove"")\n    stop = description.index("".. inclusion-marker-3-do-not-remove"")\n    middle = description[start:stop].strip()\n    start_replaceplots = middle.index("".. inclusion-marker-replaceplots-start"")\n    stop_replaceplots = middle.index("".. inclusion-marker-replaceplots-stop"") + len("".. inclusion-marker-replaceplots-stop"")\n    middle = middle[:start_replaceplots] + """"""\n.. image:: https://raw.githubusercontent.com/scikit-hep/uproot/master/docs/root-none-muon.png\n   :width: 350 px\n.. image:: https://raw.githubusercontent.com/scikit-hep/uproot/master/docs/rootnumpy-none-muon.png\n   :width: 350 px\n"""""" + middle[stop_replaceplots:]\n\n    after = """"""\n\nTutorial\n========\n\nSee the `project homepage <https://github.com/scikit-hep/uproot>`__ for a `tutorial <https://github.com/scikit-hep/uproot#tutorial>`__.\n\nRun `that tutorial <https://mybinder.org/v2/gh/scikit-hep/uproot/master?urlpath=lab/tree/binder%2Ftutorial.ipynb>`__ on Binder.\n\n**Tutorial contents:**\n\n* `Introduction <https://github.com/scikit-hep/uproot#introduction>`__\n* `What is uproot? <https://github.com/scikit-hep/uproot#what-is-uproot>`__\n* `Exploring a file <https://github.com/scikit-hep/uproot#exploring-a-file>`__\n\n  - `Compressed objects in ROOT files <https://github.com/scikit-hep/uproot#compressed-objects-in-root-files>`__\n  - `Exploring a TTree <https://github.com/scikit-hep/uproot#exploring-a-ttree>`__\n  - `Some terminology <https://github.com/scikit-hep/uproot#some-terminology>`__\n\n* `Reading arrays from a TTree <https://github.com/scikit-hep/uproot#reading-arrays-from-a-ttree>`__\n* `Caching data <https://github.com/scikit-hep/uproot#caching-data>`__\n\n  - `Automatically managed caches <https://github.com/scikit-hep/uproot#automatically-managed-caches>`__\n  - `Caching at all levels of abstraction <https://github.com/scikit-hep/uproot#caching-at-all-levels-of-abstraction>`__\n\n* `Lazy arrays <https://github.com/scikit-hep/uproot#lazy-arrays>`__\n\n  - `Lazy array of many files <https://github.com/scikit-hep/uproot#lazy-array-of-many-files>`__\n  - `Lazy arrays with caching <https://github.com/scikit-hep/uproot#lazy-arrays-with-caching>`__\n  - `Lazy arrays as lightweight skims <https://github.com/scikit-hep/uproot#lazy-arrays-as-lightweight-skims>`__\n  - `Lazy arrays in Dask <https://github.com/scikit-hep/uproot#lazy-arrays-in-dask>`__\n\n* `Iteration <https://github.com/scikit-hep/uproot#iteration>`__\n\n  - `Filenames and entry numbers while iterating <https://github.com/scikit-hep/uproot#filenames-and-entry-numbers-while-iterating>`__\n  - `Limiting the number of entries to be read <https://github.com/scikit-hep/uproot#limiting-the-number-of-entries-to-be-read>`__\n  - `Controlling lazy chunk and iteration step sizes <https://github.com/scikit-hep/uproot#controlling-lazy-chunk-and-iteration-step-sizes>`__\n  - `Caching and iteration <https://github.com/scikit-hep/uproot#caching-and-iteration>`__\n\n* `Changing the output container type <https://github.com/scikit-hep/uproot#changing-the-output-container-type>`__\n* `Filling Pandas DataFrames <https://github.com/scikit-hep/uproot#filling-pandas-dataframes>`__\n* `Selecting and interpreting branches <https://github.com/scikit-hep/uproot#selecting-and-interpreting-branches>`__\n\n  - `TBranch interpretations <https://github.com/scikit-hep/uproot#tbranch-interpretations>`__\n  - `Reading data into a preexisting array <https://github.com/scikit-hep/uproot#reading-data-into-a-preexisting-array>`__\n  - `Passing many new interpretations in one call <https://github.com/scikit-hep/uproot#passing-many-new-interpretations-in-one-call>`__\n  - `Multiple values per event: fixed size arrays <https://github.com/scikit-hep/uproot#multiple-values-per-event-fixed-size-arrays>`__\n  - `Multiple values per event: leaf-lists <https://github.com/scikit-hep/uproot#multiple-values-per-event-leaf-lists>`__\n  - `Multiple values per event: jagged arrays <https://github.com/scikit-hep/uproot#multiple-values-per-event-jagged-arrays>`__\n  - `Jagged array performance <https://github.com/scikit-hep/uproot#jagged-array-performance>`__\n  - `Special physics objects: Lorentz vectors <https://github.com/scikit-hep/uproot#special-physics-objects-lorentz-vectors>`__\n  - `Variable-width values: strings <https://github.com/scikit-hep/uproot#variable-width-values-strings>`__\n  - `Arbitrary objects in TTrees <https://github.com/scikit-hep/uproot#arbitrary-objects-in-ttrees>`__\n  - `Doubly nested jagged arrays (i.e. std::vector<std::vector<T>>) <https://github.com/scikit-hep/uproot#doubly-nested-jagged-arrays-ie-stdvectorstdvectort>`__\n\n* `Parallel array reading <https://github.com/scikit-hep/uproot#parallel-array-reading>`__\n* `Histograms, TProfiles, TGraphs, and others <https://github.com/scikit-hep/uproot#histograms-tprofiles-tgraphs-and-others>`__\n* `Creating and writing data to ROOT files <https://github.com/scikit-hep/uproot#creating-and-writing-data-to-root-files>`__\n\n  - `Writing histograms <https://github.com/scikit-hep/uproot#writing-histograms>`__\n  - `Writing TTrees <https://github.com/scikit-hep/uproot#writing-ttrees>`__\n\nReference documentation\n=======================\n\n* `Opening files <http://uproot.readthedocs.io/en/latest/opening-files.html>`__\n\n  - `uproot.open <http://uproot.readthedocs.io/en/latest/opening-files.html#uproot-open>`__\n  - `uproot.xrootd <http://uproot.readthedocs.io/en/latest/opening-files.html#uproot-xrootd>`__\n  - `uproot.http <http://uproot.readthedocs.io/en/latest/opening-files.html#uproot-http>`__\n  - `uproot.iterate <http://uproot.readthedocs.io/en/latest/opening-files.html#uproot-iterate>`__\n  - `uproot.pandas.iterate <http://uproot.readthedocs.io/en/latest/opening-files.html#uproot-pandas-iterate>`__\n  - `uproot.lazyarray(s) <http://uproot.readthedocs.io/en/latest/opening-files.html#uproot-lazyarray-and-lazyarrays>`__\n  - `uproot.daskarray/daskframe <http://uproot.readthedocs.io/en/latest/opening-files.html#uproot-daskarray-and-daskframe>`__\n  - `uproot.numentries <http://uproot.readthedocs.io/en/latest/opening-files.html#uproot-numentries>`__\n\n* `ROOT I/O <http://uproot.readthedocs.io/en/latest/root-io.html>`__\n\n  - `uproot.rootio.ROOTDirectory <http://uproot.readthedocs.io/en/latest/root-io.html#uproot-rootio-rootdirectory>`__\n  - `uproot.rootio.ROOTObject <http://uproot.readthedocs.io/en/latest/root-io.html#uproot-rootio-rootobject>`__\n  - `uproot.rootio.ROOTStreamedObject <http://uproot.readthedocs.io/en/latest/root-io.html#uproot-rootio-rootstreamedobject>`__\n\n* `TTree Handling <http://uproot.readthedocs.io/en/latest/ttree-handling.html>`__\n\n  - `uproot.tree.TTreeMethods <http://uproot.readthedocs.io/en/latest/ttree-handling.html#uproot-tree-ttreemethods>`__\n  - `uproot.tree.TBranchMethods <http://uproot.readthedocs.io/en/latest/ttree-handling.html#uproot-tree-tbranchmethods>`__\n\n* `Interpretation <http://uproot.readthedocs.io/en/latest/interpretation.html>`__\n* `Caches <http://uproot.readthedocs.io/en/latest/caches.html>`__\n* `Parallel I/O <http://uproot.readthedocs.io/en/latest/parallel-io.html>`__\n""""""\n    return before + middle + after\n\nsetup(name = ""uproot"",\n      version = get_version(),\n      packages = find_packages(exclude = [""tests""]),\n      scripts = [],\n      description = ""ROOT I/O in pure Python and Numpy."",\n      long_description = get_description(),\n      author = ""Jim Pivarski (IRIS-HEP)"",\n      author_email = ""pivarski@princeton.edu"",\n      maintainer = ""Jim Pivarski (IRIS-HEP)"",\n      maintainer_email = ""pivarski@princeton.edu"",\n      url = ""https://github.com/scikit-hep/uproot"",\n      download_url = ""https://github.com/scikit-hep/uproot/releases"",\n      license = ""BSD 3-clause"",\n      test_suite = ""tests"",\n      python_requires = "">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*"",\n      install_requires = [""numpy>=1.13.1"", ""awkward>=0.12.0,<1.0"", ""uproot-methods>=0.7.0"", ""cachetools""],\n      setup_requires = [""pytest-runner""],\n      extras_require = {\n          ""testing"": [""pytest>=3.9"", ""pkgconfig"", ""lz4"", ""zstandard"", \'backports.lzma;python_version<""3.3""\', ""xxhash"", ""mock"", ""requests""],\n          ""compress"": [""lz4"", ""zstandard"", \'backports.lzma;python_version<""3.3""\', ""xxhash""],\n      },\n      classifiers = [\n          ""Development Status :: 5 - Production/Stable"",\n          ""Intended Audience :: Developers"",\n          ""Intended Audience :: Information Technology"",\n          ""Intended Audience :: Science/Research"",\n          ""License :: OSI Approved :: BSD License"",\n          ""Operating System :: MacOS"",\n          ""Operating System :: POSIX"",\n          ""Operating System :: Unix"",\n          ""Programming Language :: Python"",\n          ""Programming Language :: Python :: 2.7"",\n          ""Programming Language :: Python :: 3.5"",\n          ""Programming Language :: Python :: 3.6"",\n          ""Programming Language :: Python :: 3.7"",\n          ""Programming Language :: Python :: 3.8"",\n          ""Topic :: Scientific/Engineering"",\n          ""Topic :: Scientific/Engineering :: Information Analysis"",\n          ""Topic :: Scientific/Engineering :: Mathematics"",\n          ""Topic :: Scientific/Engineering :: Physics"",\n          ""Topic :: Software Development"",\n          ""Topic :: Utilities"",\n          ],\n      platforms = ""Any"",\n      )\n'"
dev/streamergen.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\n# Run this script from the root directory of the project.\n\nimport sys\nimport os\nsys.path.insert(0, os.path.abspath(""""))\n\nimport uproot\n\nimport subprocess\nimport json\n\n# Make sure c file is named allstreamers.c\nsubprocess.run(""root -l -q dev/allstreamers.c"", shell=True)\n\nf = uproot.open(""dev/allstreamers.root"")\n\n# Check with json\ndata = json.load(open(""dev/streamerversions.json""))\nfor x in f._context.streamerinfos:\n    if data[x._fName.decode(""ascii"")] != x._fClassVersion:\n        print(""Old {0} version = {1}. New {0} version = {2}"".format(x._fName, data[x._fName.decode(""ascii"")], x._fClassVersion))\n\ntkey = uproot.rootio.TKey.read(f._context.source, uproot.source.cursor.Cursor(f._context.tfile[""_fSeekInfo""]), None, None)\nstart = f._context.tfile[""_fSeekInfo""] + tkey._fKeylen\nstreamerlen = tkey._fObjlen\n\nwith open(""dev/allstreamers.root"", ""rb"") as binary_file:\n    binary_file.seek(start)\n    couple_bytes = binary_file.read(streamerlen)\nstreamers = ""streamers = {0}"".format(repr(couple_bytes))\n\nlines = []\nfor line in open(""uproot/write/streamers.py""):\n    if line.startswith(""streamers""):\n        lines.append(streamers)\n    else:\n        lines.append(line)\n\nwith open(""uproot/write/streamers.py"", ""w"") as streamerfile:\n    for line in lines:\n        streamerfile.writelines(line)\n\nos.remove(""dev/allstreamers.root"")\n'"
tests/__init__.py,0,b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n'
tests/test_cache.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nimport uproot\n\nclass Test(object):\n    def test_flat_array(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""i8""]\n        expectation = [-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n\n        cache = {}\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert len(cache) == 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, cache=cache).tolist() == expectation[entrystart:entrystop]\n            assert len(cache) > 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, cache=cache).tolist() == expectation[entrystart:entrystop]\n            cache = {}\n\n        basketcache = {}\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert len(basketcache) == 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, basketcache=basketcache).tolist() == expectation[entrystart:entrystop]\n            assert len(basketcache) > 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, basketcache=basketcache).tolist() == expectation[entrystart:entrystop]\n            basketcache = {}\n\n        keycache = {}\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert len(keycache) == 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, keycache=keycache).tolist() == expectation[entrystart:entrystop]\n            assert len(keycache) > 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, keycache=keycache).tolist() == expectation[entrystart:entrystop]\n            keycache = {}\n\n    def test_regular_array(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""ai8""]\n        expectation = [[-14, -13, -12], [-13, -12, -11], [-12, -11, -10], [-11, -10, -9], [-10, -9, -8], [-9, -8, -7], [-8, -7, -6], [-7, -6, -5], [-6, -5, -4], [-5, -4, -3], [-4, -3, -2], [-3, -2, -1], [-2, -1, 0], [-1, 0, 1], [0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11], [10, 11, 12], [11, 12, 13], [12, 13, 14], [13, 14, 15], [14, 15, 16], [15, 16, 17]]\n\n        cache = {}\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert len(cache) == 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, cache=cache).tolist() == expectation[entrystart:entrystop]\n            assert len(cache) > 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, cache=cache).tolist() == expectation[entrystart:entrystop]\n            cache = {}\n\n        basketcache = {}\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert len(basketcache) == 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, basketcache=basketcache).tolist() == expectation[entrystart:entrystop]\n            assert len(basketcache) > 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, basketcache=basketcache).tolist() == expectation[entrystart:entrystop]\n            basketcache = {}\n\n        keycache = {}\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert len(keycache) == 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, keycache=keycache).tolist() == expectation[entrystart:entrystop]\n            assert len(keycache) > 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, keycache=keycache).tolist() == expectation[entrystart:entrystop]\n            keycache = {}\n\n    def test_irregular_array(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""Ai8""]\n        expectation = [[], [-15], [-15, -13], [-15, -13, -11], [-15, -13, -11, -9], [], [-10], [-10, -8], [-10, -8, -6], [-10, -8, -6, -4], [], [-5], [-5, -3], [-5, -3, -1], [-5, -3, -1, 1], [], [0], [0, 2], [0, 2, 4], [0, 2, 4, 6], [], [5], [5, 7], [5, 7, 9], [5, 7, 9, 11], [], [10], [10, 12], [10, 12, 14], [10, 12, 14, 16]]\n        assert [len(x) for x in expectation] == [0, 1, 2, 3, 4] * 6\n\n        cache = {}\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert len(cache) == 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, cache=cache).tolist() == expectation[entrystart:entrystop]\n            assert len(cache) > 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, cache=cache).tolist() == expectation[entrystart:entrystop]\n            cache = {}\n\n        basketcache = {}\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert len(basketcache) == 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, basketcache=basketcache).tolist() == expectation[entrystart:entrystop]\n            assert len(basketcache) > 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, basketcache=basketcache).tolist() == expectation[entrystart:entrystop]\n            basketcache = {}\n\n        keycache = {}\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert len(keycache) == 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, keycache=keycache).tolist() == expectation[entrystart:entrystop]\n            assert len(keycache) > 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, keycache=keycache).tolist() == expectation[entrystart:entrystop]\n            keycache = {}\n\n    def test_strings_array(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""str""]\n        expectation = [b""hey-0"", b""hey-1"", b""hey-2"", b""hey-3"", b""hey-4"", b""hey-5"", b""hey-6"", b""hey-7"", b""hey-8"", b""hey-9"", b""hey-10"", b""hey-11"", b""hey-12"", b""hey-13"", b""hey-14"", b""hey-15"", b""hey-16"", b""hey-17"", b""hey-18"", b""hey-19"", b""hey-20"", b""hey-21"", b""hey-22"", b""hey-23"", b""hey-24"", b""hey-25"", b""hey-26"", b""hey-27"", b""hey-28"", b""hey-29""]\n\n        cache = {}\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert len(cache) == 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, cache=cache).tolist() == expectation[entrystart:entrystop]\n            assert len(cache) > 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, cache=cache).tolist() == expectation[entrystart:entrystop]\n            cache = {}\n\n        basketcache = {}\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert len(basketcache) == 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, basketcache=basketcache).tolist() == expectation[entrystart:entrystop]\n            assert len(basketcache) > 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, basketcache=basketcache).tolist() == expectation[entrystart:entrystop]\n            basketcache = {}\n\n        keycache = {}\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert len(keycache) == 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, keycache=keycache).tolist() == expectation[entrystart:entrystop]\n            assert len(keycache) > 0\n            assert branch.array(entrystart=entrystart, entrystop=entrystop, keycache=keycache).tolist() == expectation[entrystart:entrystop]\n            keycache = {}\n'"
tests/test_compression.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nimport pytest\ntry:\n    import lzma\nexcept ImportError:\n    lzma = pytest.importorskip(\'backports.lzma\')\nlz4 = pytest.importorskip(\'lz4\')\nzstandard = pytest.importorskip(\'zstandard\')\nimport uproot\n\n\nclass Test(object):\n    def test_compression_identity(self):\n        assert uproot.open(""tests/samples/Zmumu-zlib.root"").compression.algoname == ""zlib""\n        assert uproot.open(""tests/samples/Zmumu-zlib.root"").compression.level == 4\n\n        assert uproot.open(""tests/samples/Zmumu-lzma.root"").compression.algoname == ""lzma""\n        assert uproot.open(""tests/samples/Zmumu-lzma.root"").compression.level == 4\n\n        assert uproot.open(""tests/samples/Zmumu-lz4.root"").compression.algoname == ""lz4""\n        assert uproot.open(""tests/samples/Zmumu-lz4.root"").compression.level == 4\n\n        assert uproot.open(""tests/samples/Zmumu-zstd.root"").compression.algoname == ""zstd""\n        assert uproot.open(""tests/samples/Zmumu-zstd.root"").compression.level == 5\n\n        assert uproot.open(""tests/samples/Zmumu-uncompressed.root"").compression.level == 0\n\n        assert uproot.open(""tests/samples/HZZ-zlib.root"").compression.algoname == ""zlib""\n        assert uproot.open(""tests/samples/HZZ-zlib.root"").compression.level == 4\n\n        assert uproot.open(""tests/samples/HZZ-lzma.root"").compression.algoname == ""lzma""\n        assert uproot.open(""tests/samples/HZZ-lzma.root"").compression.level == 4\n\n        assert uproot.open(""tests/samples/HZZ-lz4.root"").compression.algoname == ""lz4""\n        assert uproot.open(""tests/samples/HZZ-lz4.root"").compression.level == 4\n\n        assert uproot.open(""tests/samples/HZZ-zstd.root"").compression.algoname == ""zstd""\n        assert uproot.open(""tests/samples/HZZ-zstd.root"").compression.level == 5\n\n        assert uproot.open(""tests/samples/HZZ-uncompressed.root"").compression.level == 0\n\n    def test_compression_keys(self):\n        keys = [(n, cls._classname) for n, cls in uproot.open(""tests/samples/Zmumu-uncompressed.root"").allclasses()]\n        assert [(n, cls._classname) for n, cls in uproot.open(""tests/samples/Zmumu-zlib.root"").allclasses()] == keys\n        assert [(n, cls._classname) for n, cls in uproot.open(""tests/samples/Zmumu-lzma.root"").allclasses()] == keys\n        assert [(n, cls._classname) for n, cls in uproot.open(""tests/samples/Zmumu-lz4.root"").allclasses()] == keys\n        assert [(n, cls._classname) for n, cls in uproot.open(""tests/samples/Zmumu-zstd.root"").allclasses()] == keys\n\n        keys = [(n, cls._classname) for n, cls in uproot.open(""tests/samples/HZZ-uncompressed.root"").allclasses()]\n        assert [(n, cls._classname) for n, cls in uproot.open(""tests/samples/HZZ-zlib.root"").allclasses()] == keys\n        assert [(n, cls._classname) for n, cls in uproot.open(""tests/samples/HZZ-lzma.root"").allclasses()] == keys\n        assert [(n, cls._classname) for n, cls in uproot.open(""tests/samples/HZZ-lz4.root"").allclasses()] == keys\n        assert [(n, cls._classname) for n, cls in uproot.open(""tests/samples/HZZ-zstd.root"").allclasses()] == keys\n\n    def test_compression_branches(self):\n        branches = list(uproot.open(""tests/samples/Zmumu-uncompressed.root"")[""events""].keys())\n        assert list(uproot.open(""tests/samples/Zmumu-zlib.root"")[""events""].keys()) == branches\n        assert list(uproot.open(""tests/samples/Zmumu-lzma.root"")[""events""].keys()) == branches\n        assert list(uproot.open(""tests/samples/Zmumu-lz4.root"")[""events""].keys()) == branches\n        assert list(uproot.open(""tests/samples/Zmumu-zstd.root"")[""events""].keys()) == branches\n\n        branches = list(uproot.open(""tests/samples/HZZ-uncompressed.root"")[""events""].keys())\n        assert list(uproot.open(""tests/samples/HZZ-zlib.root"")[""events""].keys()) == branches\n        assert list(uproot.open(""tests/samples/HZZ-lzma.root"")[""events""].keys()) == branches\n        assert list(uproot.open(""tests/samples/HZZ-lz4.root"")[""events""].keys()) == branches\n        assert list(uproot.open(""tests/samples/HZZ-zstd.root"")[""events""].keys()) == branches\n\n    def test_compression_content1(self):\n        for name, array in uproot.open(""tests/samples/Zmumu-uncompressed.root"")[""events""].arrays([""Type"", ""Event"", ""E1"", ""px1"", ""Q1"", ""M""]).items():\n            array = array.tolist()\n            assert uproot.open(""tests/samples/Zmumu-zlib.root"")[""events""].array(name).tolist() == array\n            assert uproot.open(""tests/samples/Zmumu-lzma.root"")[""events""].array(name).tolist() == array\n            assert uproot.open(""tests/samples/Zmumu-lz4.root"")[""events""].array(name).tolist() == array\n            assert uproot.open(""tests/samples/Zmumu-zstd.root"")[""events""].array(name).tolist() == array\n\n    def test_compression_content2(self):\n        array = uproot.open(""tests/samples/HZZ-uncompressed.root"")[""events""].array(""Electron_Px"").tolist()\n        assert uproot.open(""tests/samples/HZZ-zlib.root"")[""events""].array(""Electron_Px"").tolist() == array\n        assert uproot.open(""tests/samples/HZZ-lzma.root"")[""events""].array(""Electron_Px"").tolist() == array\n        assert uproot.open(""tests/samples/HZZ-lz4.root"")[""events""].array(""Electron_Px"").tolist() == array\n        assert uproot.open(""tests/samples/HZZ-zstd.root"")[""events""].array(""Electron_Px"").tolist() == array\n'"
tests/test_http.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nimport pytest\nimport mock\nHTTPError = pytest.importorskip(\'requests.exceptions\').HTTPError\n\nimport uproot\n\nFILE = ""foriter""\nLOCAL = ""tests/samples/{FILE}.root"".format(FILE=FILE)\nURL = ""http://scikit-hep.org/uproot/examples/{FILE}.root"".format(FILE=FILE)\nURL_AUTH = ""http://scikit-hep.org/uproot/authentication/{FILE}.root"".format(FILE=FILE)\nAUTH = (""scikit-hep"", ""uproot"")\n\ndef mock_get_local_instead_of_http(url="""", headers={}, auth=None, **kwargs):\n    class MockResponse:\n        def __init__(self, status_code):\n            self.status_code = status_code\n            if self.status_code == 200:\n                with open(LOCAL, ""rb"") as f:\n                    self.content = f.read()\n                self.headers = {""Content-Range"": str(len(self.content))}\n\n        def raise_for_status(self):\n            if self.status_code == 401:  # Authentication Error\n                raise HTTPError\n            elif self.status_code == 200:  # Ok\n                pass\n\n    if url == URL:\n        return MockResponse(200)\n    elif url == URL_AUTH and auth == None:\n        return MockResponse(401)\n    elif url == URL_AUTH and auth == AUTH:\n        return MockResponse(200)\n    elif url == URL_AUTH:\n        return MockResponse(401)\n\n@mock.patch(""requests.get"", mock_get_local_instead_of_http)\nclass Test(object):\n    def test_no_auth_needed_no_auth(self):\n        f = uproot.open(URL)\n        assert type(f) == uproot.rootio.ROOTDirectory\n\n    def test_no_auth_needed_with_auth(self):\n        f = uproot.open(URL, httpsource={""auth"": AUTH})\n        assert type(f) == uproot.rootio.ROOTDirectory\n\n    def test_auth_needed_no_auth(self):\n        with pytest.raises(HTTPError):\n            f = uproot.open(URL_AUTH)\n\n    def test_auth_needed_correct_auth(self):\n        f = uproot.open(URL_AUTH, httpsource={""auth"": AUTH})\n        assert type(f) == uproot.rootio.ROOTDirectory\n\n    def test_auth_needed_wrong_auth(self):\n        with pytest.raises(HTTPError):\n            f = uproot.open(URL_AUTH, httpsource={""auth"": ("""", """")})\n'"
tests/test_issues.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nimport sys\n\nimport pytest\nimport numpy\n\nimport uproot\nimport awkward\n\nimport uproot_methods.classes.TVector3\nimport uproot_methods.classes.TLorentzVector\n\n\nclass Test(object):\n    def test_issue21(self):\n        t = uproot.open(""tests/samples/issue21.root"")[""nllscan""]\n\n        ### Explicit recover removed\n        # assert t.array(""mH"").tolist() == []\n        # t.recover()\n\n        assert t[""mH""].numbaskets == 1\n        assert t[""mH""].basket_entrystart(0) == 0\n        assert t[""mH""].basket_entrystop(0) == 61\n        assert t[""mH""].basket_numentries(0) == 61\n        assert t.array(""mH"").tolist() == [\n            124.0, 124.09089660644531, 124.18180084228516, 124.27269744873047,\n            124.36360168457031, 124.45449829101562, 124.54550170898438,\n            124.63639831542969, 124.72730255126953, 124.81819915771484,\n            124.87000274658203, 124.87550354003906, 124.88089752197266,\n            124.88639831542969, 124.89179992675781, 124.89730072021484,\n            124.90270233154297, 124.908203125, 124.90910339355469,\n            124.9135971069336, 124.91909790039062, 124.92449951171875,\n            124.93000030517578, 124.98739624023438, 124.9906997680664,\n            124.99349975585938, 124.99590301513672, 124.9977035522461,\n            124.9990005493164, 124.99970245361328, 125.0, 125.00029754638672,\n            125.0009994506836, 125.0022964477539, 125.00409698486328,\n            125.00650024414062, 125.0093002319336, 125.01260375976562,\n            125.06999969482422, 125.07550048828125, 125.08090209960938,\n            125.0864028930664, 125.09089660644531, 125.091796875,\n            125.09729766845703, 125.10269927978516, 125.10820007324219,\n            125.11360168457031, 125.11910247802734, 125.12449645996094,\n            125.12999725341797, 125.18180084228516, 125.27269744873047,\n            125.36360168457031, 125.45449829101562, 125.54550170898438,\n            125.63639831542969, 125.72730255126953, 125.81819915771484,\n            125.90910339355469, 126.0\n        ]\n\n    def test_issue30(self):\n        uproot.open(""tests/samples/issue30.root"")\n\n    def test_issue31(self):\n        t = uproot.open(""tests/samples/issue31.root"")[""T""]\n        assert t.array(""name"").tolist() == [\n            b""one"", b""two"", b""three"", b""four"", b""five""\n        ]\n\n    def test_issue33(self):\n        h = uproot.open(""tests/samples/issue33.root"")[""cutflow""]\n        assert h.xlabels == [\n            ""Dijet"", ""MET"", ""MuonVeto"", ""IsoMuonTrackVeto"", ""ElectronVeto"",\n            ""IsoElectronTrackVeto"", ""IsoPionTrackVeto""\n        ]\n\n    def test_issue38(self):\n        before_hadd = uproot.open(\n            ""tests/samples/issue38a.root"")[""ntupler/tree""]\n        after_hadd = uproot.open(""tests/samples/issue38b.root"")[""ntupler/tree""]\n\n        before = before_hadd.arrays()\n        after = after_hadd.arrays()\n\n        assert set(before.keys())\n        assert set(after.keys())\n\n        for key in before.keys():\n            assert before[key].tolist() * 3 == after[key].tolist()\n\n    def test_issue46(self):\n        t = uproot.open(""tests/samples/issue46.root"")[""tree""]\n        t[""evt""].array(uproot.asdebug)\n\n    def test_issue49(self):\n        t = uproot.open(""tests/samples/issue49.root"")[""nllscan""]\n        t.arrays()\n\n    def test_issue54(self):\n        h = uproot.open(""tests/samples/hepdata-example.root"")[""hpx""]\n        assert h._fFunctions[0]._fParent is h\n\n    def test_issue55(self):\n        withoffsets = uproot.open(\n            ""tests/samples/small-dy-withoffsets.root"")[""tree""]\n        nooffsets = uproot.open(\n            ""tests/samples/small-dy-nooffsets.root"")[""tree""]\n        assert numpy.array_equal(withoffsets.array(""nJet""),\n                                 nooffsets.array(""nJet""))\n        assert numpy.array_equal(withoffsets.array(""nMuon""),\n                                 nooffsets.array(""nMuon""))\n\n        def equal(left, right):\n            if len(left) != len(right):\n                return False\n            for x, y in zip(left, right):\n                if not numpy.array_equal(x, y):\n                    return False\n            return True\n\n        assert equal(withoffsets.array(""Jet_jetId""),\n                     nooffsets.array(""Jet_jetId""))\n        assert equal(withoffsets.array(""Jet_pt""), nooffsets.array(""Jet_pt""))\n        assert equal(withoffsets.array(""MET_pt""), nooffsets.array(""MET_pt""))\n        assert equal(withoffsets.array(""Muon_charge""),\n                     nooffsets.array(""Muon_charge""))\n        assert equal(withoffsets.array(""Muon_pt""), nooffsets.array(""Muon_pt""))\n        assert equal(withoffsets.array(""event""), nooffsets.array(""event""))\n\n    def test_issue57(self):\n        tree = uproot.open(""tests/samples/issue57.root"")[""outtree""]\n        for x in tree[""sel_lep""].array():\n            for y in x:\n                assert isinstance(\n                    y, uproot_methods.classes.TLorentzVector.\n                    Methods) and isinstance(\n                        y._fP, uproot_methods.classes.TVector3.Methods)\n        for x in tree[""selJet""].array():\n            for y in x:\n                assert isinstance(\n                    y, uproot_methods.classes.TLorentzVector.\n                    Methods) and isinstance(\n                        y._fP, uproot_methods.classes.TVector3.Methods)\n\n    def test_issue60(self):\n        t = uproot.open(""tests/samples/issue60.root"")[""nllscan""]\n\n        assert t[""status""].numbaskets == 2\n        assert t[""mH""].numbaskets == 3\n        assert (t[""mH""].basket_entrystart(0), t[""mH""].basket_entrystart(1),\n                t[""mH""].basket_entrystart(2)) == (0, 3990, 7980)\n        assert (t[""mH""].basket_entrystop(0), t[""mH""].basket_entrystop(1),\n                t[""mH""].basket_entrystop(2)) == (3990, 7980, 11535)\n        assert (t[""mH""].basket_numentries(0), t[""mH""].basket_numentries(1),\n                t[""mH""].basket_numentries(2)) == (3990, 3990, 3555)\n        assert t.array(""mH"")[:10].tolist() == [\n            125.3575896071691, 124.75819175713684, 124.79865223661515,\n            125.13239376420276, 125.19612659731995, 125.33001837818416,\n            124.93261741760551, 125.02903289132837, 124.65206649938854,\n            125.50663519903532\n        ]\n        assert t.array(""mH"")[-10:].tolist() == [\n            125.5150930345707, 125.00248572708085, 124.55838505657864,\n            125.03766816520313, 125.27765299737514, 124.9976442776121,\n            124.8339210081154, 124.62415638855144, 125.33988981473144,\n            124.93384515492096\n        ]\n\n    def test_issue63(self):\n        t = uproot.open(""tests/samples/issue63.root"")[""WtLoop_meta""]\n        assert t[""initialState""].array().tolist() == [b""Wt""]\n        assert t[""generator""].array().tolist() == [b""PowhegPythia6""]\n        assert t[""sampleType""].array().tolist() == [b""Nominal""]\n        assert t[""campaign""].array().tolist() == [b""MC16a""]\n\n    def test_issue64(self):\n        t = uproot.open(""tests/samples/issue64.root"")[""events/events""]\n        assert t[""e_pri""].array().tolist() == [0.00698000006377697] * 500\n\n    def test_issue66(self):\n        f = uproot.open(""tests/samples/issue66.root"")\n        h, = f.values()\n        assert h.values.tolist() == [\n            4814.0, 45.0, 45.0, 25.0, 15.0, 4.0, 0.0, 6.0, 7.0, 5.0, 3.0, 3.0,\n            6.0, 3.0, 7.0, 5.0, 7.0, 11.0, 9.0, 5.0, 4.0, 10.0, 12.0, 7.0,\n            10.0, 8.0, 12.0, 11.0, 12.0, 12.0, 14.0, 15.0, 13.0, 14.0, 14.0,\n            20.0, 20.0, 16.0, 21.0, 22.0, 22.0, 28.0, 25.0, 33.0, 26.0, 21.0,\n            42.0, 36.0, 43.0, 42.0, 43.0, 39.0, 42.0, 56.0, 67.0, 50.0, 67.0,\n            71.0, 59.0, 76.0, 73.0, 84.0, 63.0, 76.0, 84.0, 97.0, 91.0, 100.0,\n            108.0, 121.0, 129.0, 137.0, 127.0, 141.0, 152.0, 147.0, 166.0,\n            158.0, 166.0, 159.0, 146.0, 176.0, 189.0, 213.0, 212.0, 228.0,\n            193.0, 232.0, 225.0, 210.0, 211.0, 229.0, 226.0, 237.0, 246.0,\n            243.0, 265.0, 303.0, 248.0, 302.0, 326.0, 318.0, 340.0, 362.0,\n            313.0, 366.0, 379.0, 376.0, 423.0, 433.0, 486.0, 486.0, 482.0,\n            518.0, 548.0, 583.0, 628.0, 705.0, 735.0, 814.0, 852.0, 920.0,\n            1000.0, 1095.0, 1184.0, 1296.0, 1544.0, 1700.0, 2091.0, 2738.0,\n            3794.0, 5591.0, 8640.0, 13619.0, 20171.0, 11051.0, 0.0, 0.0, 0.0,\n            0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n            0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n            0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n            0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n            0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n        ]\n\n    def test_issue70(self):\n        f = uproot.open(""tests/samples/issue70.root"")\n        assert f.keys() == []\n\n    def test_issue74(self):\n        t = uproot.open(""tests/samples/issue74.root"")[""Events""]\n        assert all(\n            isinstance(x[0], uproot_methods.classes.TVector3.Methods)\n            for x in t.array(""bees.xyzPosition""))\n        assert t.array(""bees.xyzPosition""\n                       )[0][0] == uproot_methods.classes.TVector3.TVector3(\n                           1.0, 2.0, -1.0)\n\n    def test_issue76(self):\n        t = uproot.open(""tests/samples/issue76.root"")[""Events""]\n        assert list(t.array(""rootStrings"")[0]) == [b""2"", b""4""]\n        x, y = t.array(""rootStrings"")[0]\n        assert isinstance(x, uproot.rootio.TString)\n\n    def test_issue79(self):\n        t = uproot.open(""tests/samples/issue79.root"")[""taus""]\n        assert t[""pt""].numbaskets == 2\n        baskets = numpy.concatenate([t[""pt""].basket(0), t[""pt""].basket(1)])\n        assert baskets.shape == (t[""pt""].numentries, )\n        assert numpy.array_equal(baskets, t[""pt""].array())\n\n    def test_issue96(self):\n        t = uproot.open(""tests/samples/issue96.root"")[""tree""]\n        assert all(\n            isinstance(x, uproot_methods.classes.TLorentzVector.Methods)\n            for x in t.array(""jet1P4""))\n\n    def test_geant4(self):\n        f = uproot.open(""tests/samples/from-geant4.root"")\n        arrays = f[""Details""].arrays()\n        assert arrays[b""numgood""][0] == 224\n        assert [len(x) for x in f[""HitStrips""].arrays().values()\n                ] == [4808, 4808, 4808]\n        assert sum(f[""edep_inner""].values) == 1547\n        assert sum(sum(x) for x in f[""recon_orig""].values) == 141\n\n    ### file is too big to include\n    # def test_issue168(self):\n    #     t = uproot.open(""tests/samples/issue168.root"")[""Events""]\n    #     a1 = t[""MRawEvtData.fHiGainFadcSamples""].array(t[""MRawEvtData.fHiGainFadcSamples""].interpretation.speedbump(False), entrystop=4)\n    #     assert a1[0]._fArray.shape == (108400,)\n    #     a2 = t[""MRawEvtData.fHiGainPixId""].array(t[""MRawEvtData.fHiGainPixId""].interpretation.speedbump(False))\n    #     assert a2[0]._fArray.shape == (1084,)\n\n    def test_issue187(self):\n        t = uproot.open(""tests/samples/issue187.root"")[""fTreeV0""]\n        assert (t.array(""fMultiplicity"") == -1).all()\n        assert t.array(""V0s.fEtaPos"")[-3].tolist() == [-0.390625, 0.046875]\n\n    def test_issue213(self):\n        pytest.importorskip(""xxhash"")\n        t = uproot.open(""tests/samples/issue213.root"")[""T""]\n        assert t[""fMCHits.fPosition""].array().x.tolist() == [\n            [], [], [], [], [], [], [], [42.17024612426758, 50.63192367553711],\n            [], [], [], [43.292755126953125], [], [], [], [], [], [], [], [],\n            [42.15415954589844], [41.60139083862305], [42.95103454589844], [],\n            [41.55511474609375], [], [], [], [], [], [], [42.549156188964844],\n            [], [], [], [42.80044174194336,\n                         46.136253356933594], [], [], [], [],\n            [41.58171081542969], [], [], [42.741485595703125],\n            [41.228477478027344], [], [], [], [], [], [], [], [], [],\n            [42.518882751464844], [43.34626388549805], [], [],\n            [43.214759826660156], [], [], [], [], [], [], [42.78463363647461],\n            [], [], [], [], [], [], [], [41.927093505859375],\n            [42.65863037109375], [], [42.66266632080078], [], [], [], [], [],\n            [], [], [], [], [], [41.91042709350586,\n                                 41.807674407958984], [], [42.79293441772461],\n            [], [], [], [], [], [], [41.72440719604492], [], [],\n            [41.609615325927734]\n        ]\n\n    def test_issue232(self):\n        pytest.importorskip(""pandas"")\n        t = uproot.open(""tests/samples/issue232.root"")[""fTreeV0""]\n        t.pandas.df(\n            [""V0Hyper.fNsigmaHe3Pos"", ""V0Hyper.fDcaPos2PrimaryVertex""],\n            flatten=True)\n\n    def test_issue240(self):\n        pytest.importorskip(""pyxrootd"")\n        t = uproot.open(\n            ""root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod/Run2012B_DoubleMuParked.root""\n        )[""Events""]\n        assert (abs(t.array(""nMuon"", entrystop=100000)) < 50).all()\n\n    def test_issue243(self):\n        t = uproot.open(""tests/samples/issue243.root"")[""triggerList""]\n        for x in t.array(""triggerMap"", entrystop=100):\n            assert all(y == 1.0 for y in x.values())\n\n    def test_issue243_new(self):\n        t = uproot.open(""tests/samples/issue243-new.root"")[""triggerList""]\n        first = t[""triggerMap.first""].array()\n        second = t[""triggerMap.second""].array()\n        for i in range(t.numentries):\n            x = dict(zip(first[i], second[i]))\n            assert all(y == 1.0 for y in x.values())\n\n    def test_issue327(self):\n        uproot.open(""tests/samples/issue327.root"")[""DstTree""]\n\n    def test_issue371(self):\n        t = uproot.open(""tests/samples/issue371.root"")[""Event""]\n        obj = t[""DRIFT_0.""].array()[0]\n        assert obj._samplerName == b\'DRIFT_0\'\n        assert obj._n == 1\n        assert obj._energy[0] == numpy.array([2.3371024],\n                                             dtype=numpy.float32)[0]\n\n    def test_issue376_simple(self):\n        f = uproot.open(""tests/samples/from-geant4.root"")\n        assert type(f).classname == \'TDirectory\'\n        assert f.classname == \'TDirectory\'\n        real_class_names = [\'TTree\'] * 4 + [\'TH1D\'] * 10 + [\'TH2D\'] * 5\n        assert [\n            classname_two_tuple[1] for classname_two_tuple in f.classnames()\n        ] == real_class_names\n        assert [\n            class_two_tuple[1].classname for class_two_tuple in f.classes()\n        ] == real_class_names\n        assert [value.classname for value in f.values()] == real_class_names\n\n    def test_issue376_nested(self):\n        f = uproot.open(""tests/samples/nesteddirs.root"")\n        top_level_class_names = [\'TDirectory\', \'TDirectory\']\n        recursive_class_names = [\n            \'TDirectory\', \'TDirectory\', \'TTree\', \'TTree\', \'TDirectory\', \'TTree\'\n        ]\n        assert [\n            classname_two_tuple[1]\n            for classname_two_tuple in f.classnames(recursive=False)\n        ] == top_level_class_names\n        assert [\n            classname_two_tuple[1]\n            for classname_two_tuple in f.classnames(recursive=True)\n        ] == recursive_class_names\n        assert [\n            classname_two_tuple[1]\n            for classname_two_tuple in f.allclassnames()\n        ] == recursive_class_names\n\n    def test_issue367(self):\n        t = uproot.open(""tests/samples/issue367.root"")[""tree""]\n        assert awkward.fromiter(\n            t.array(""weights.second""))[0].counts.tolist() == [\n                1000, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n                10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1000, 1000,\n                1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n                100, 100, 100, 1\n            ]\n\n    def test_issue390(self):\n        pytest.importorskip(""pandas"")\n        t = uproot.open(""tests/samples/issue390.root"")[""E""]\n        t.pandas.df(""hits.*"")\n        t.pandas.df(""trks.*"")\n\n    def test_issue399(self):\n        t = uproot.open(""tests/samples/issue399.root"")[""Event""]\n        a = t[""Histos.histograms1D""].array()\n        for i in range(t.numentries):\n            assert [x.title for x in a[i]] == [\n                b""Primary Hits"", b""Primary Loss"", b""Energy Loss"",\n                b""Primary Hits per Element"", b""Primary Loss per Element"",\n                b""Energy Loss per Element""\n            ]\n\n    def test_issue404(self):\n        t = uproot.open(""tests/samples/issue404.root"")[""Beam""]\n        assert t[""Beam.GMAD::BeamBase.beamParticleName""].array().tolist() == [\n            b""proton""\n        ]\n\n    def test_issue124_and_followup_issue419_with_pr420(self):\n        f = uproot.open(""tests/samples/issue124.root"")\n        branch = f[b\'KM3NET_TIMESLICE;1\'][b\'KM3NET_TIMESLICE\']\n        assert branch.interpretation is None\n        assert 0 == branch.compressedbytes()\n        assert 0 == branch.uncompressedbytes()\n        assert 0 == branch.numbaskets\n\n    def test_issue429(self):\n        if sys.version_info[0] >= 3:\n            fix = lambda name: name.decode(""utf-8"")\n        else:\n            fix = lambda name: name\n\n        file = uproot.open(""tests/samples/issue429.root"")\n        tree = file[""data_tr""]\n        branch = tree[""data_ana_kk""]\n        # FIXME: how can uproot.interp.auto.interpret *infer* the 4 bytes of padding?\n        dtype = [(fix(x._fName), ""float32"" if type(x).__name__ == ""TLeafF"" else ""int32"") for x in branch._fLeaves]\n        array = branch.array(uproot.asdtype(dtype + [(""padding"", ""S4"")]))\n        assert (array[""padding""] == b""\\xff\\xff\\xff\\xff"").all()\n\n    def test_issue431(self):\n        file = uproot.open(""tests/samples/issue431.root"")\n        head = file[""Head""]\n        assert head._map_3c_string_2c_string_3e_ == {b\'DAQ\': b\'394\', b\'PDF\': b\'4      58\', b\'XSecFile\': b\'\', b\'can\': b\'0 1027 888.4\', b\'can_user\': b\'0.00 1027.00  888.40\', b\'coord_origin\': b\'0 0 0\', b\'cut_in\': b\'0 0 0 0\', b\'cut_nu\': b\'100 1e+08 -1 1\', b\'cut_primary\': b\'0 0 0 0\', b\'cut_seamuon\': b\'0 0 0 0\', b\'decay\': b\'doesnt happen\', b\'detector\': b\'NOT\', b\'drawing\': b\'Volume\', b\'end_event\': b\'\', b\'genhencut\': b\'2000 0\', b\'genvol\': b\'0 1027 888.4 2.649e+09 100000\', b\'kcut\': b\'2\', b\'livetime\': b\'0 0\', b\'model\': b\'1       2       0       1      12\', b\'muon_desc_file\': b\'\', b\'ngen\': b\'0.1000E+06\', b\'norma\': b\'0 0\', b\'nuflux\': b\'0       3       0 0.500E+00 0.000E+00 0.100E+01 0.300E+01\', b\'physics\': b\'GENHEN 7.2-220514 181116 1138\', b\'seed\': b\'GENHEN 3  305765867         0         0\', b\'simul\': b\'JSirene 11012 11/17/18 07\', b\'sourcemode\': b\'diffuse\', b\'spectrum\': b\'-1.4\', b\'start_run\': b\'1\', b\'target\': b\'isoscalar\', b\'usedetfile\': b\'false\', b\'xlat_user\': b\'0.63297\', b\'xparam\': b\'OFF\', b\'zed_user\': b\'0.00 3450.00\'}\n\n    def test_issue434(self):\n        f = uproot.open(""tests/samples/issue434.root"")\n        fromdtype = [(""pmt"", ""u1""), (""tdc"", ""<u4""), (""tot"", ""u1"")]\n        todtype = [(""pmt"", ""u1""), (""tdc"", "">u4""), (""tot"", ""u1"")]\n        tree = f[b\'KM3NET_TIMESLICE_L1\'][b\'KM3NETDAQ::JDAQTimeslice\']\n        superframes = tree[b\'vector<KM3NETDAQ::JDAQSuperFrame>\']\n        hits_buffer = superframes[b\'vector<KM3NETDAQ::JDAQSuperFrame>.buffer\']\n        hits = hits_buffer.lazyarray(\n                uproot.asjagged(\n                    uproot.astable(\n                        uproot.asdtype(fromdtype, todtype)), skipbytes=6))\n        assert 486480 == hits[\'tdc\'][0][0]\n\n    def test_issue438_accessing_memory_mapped_objects_outside_of_context_raises(self):\n        with uproot.open(""tests/samples/issue434.root"") as f:\n            a = f[\'KM3NET_EVENT\'][\'KM3NET_EVENT\'][\'KM3NETDAQ::JDAQPreamble\'].array()\n            b = f[\'KM3NET_EVENT\'][\'KM3NET_EVENT\'][\'KM3NETDAQ::JDAQPreamble\'].lazyarray()\n        assert 4 == len(a[0])\n        with pytest.raises(IOError):\n            len(b[0])\n\n    def test_issue448(self):\n        pytest.importorskip(""pyxrootd"")\n        f = uproot.open(\'root://eospublic.cern.ch//eos/opendata/cms/Run2010B/MuOnia/AOD/Apr21ReReco-v1/0000/02186E3C-D277-E011-8A05-00215E21D516.root\')\n        tree = f[\'Events\']\n        assert len(tree.arrays(entrystop=0)) == 4179\n        assert len(tree.arrays(\'recoMuons_muons__RECO.*\', entrystop=10)) == 93\n'"
tests/test_jagged.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nimport pytest\n\nimport uproot\n\n\nclass Test(object):\n    @property\n    def sample(self):\n        pytest.importorskip(""pandas"")\n        try:\n            self._sample\n        except AttributeError:\n            self._sample = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""]\n        return self._sample\n\n    def test_flatten_False(self):\n        df = self.sample.pandas.df(flatten=False)\n        assert len(df.keys()) == 57\n        assert ""Af8"" in df\n        assert len(df.at[0, ""Af8""]) == 0\n        assert len(df.at[1, ""Af8""]) == 1\n        assert len(df.at[2, ""Af8""]) == 2\n\n    def test_flatten_None(self):\n        df = self.sample.pandas.df(flatten=None)\n        assert len(df.keys()) == 46\n        assert ""Af8"" not in df\n\n    def test_flatten_True(self):\n        df = self.sample.pandas.df(flatten=True)\n        assert len(df.keys()) == 57\n        assert ""Af8"" in df\n'"
tests/test_rntuple.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nimport os\n\nimport numpy\nimport pytest\n\nimport awkward\nimport uproot\n\nclass Test(object):\n    def test_read_anchor(self):\n        f = uproot.open(""tests/samples/ntpl001_staff.root"")\n        rntuple = f[""Staff""]\n        assert rntuple._fVersion == 0\n        assert rntuple._fSize == 48\n        assert rntuple._fSeekHeader == 854\n        assert rntuple._fNBytesHeader == 537\n        assert rntuple._fLenHeader == 2495\n        assert rntuple._fSeekFooter == 72369\n        assert rntuple._fNBytesFooter == 285\n        assert rntuple._fLenFooter == 804\n        assert rntuple._fReserved == 0\n'"
tests/test_stlvector.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nimport os\n\nimport pytest\n\nimport uproot\n\nclass Test(object):\n    def runTest(self):\n        pass\n\n    def test_vector_of_numbers(self):\n        branch = uproot.open(""tests/samples/small-evnt-tree-fullsplit.root"")[""tree""][""StlVecU32""]\n        a = branch.array()\n        for i in range(100):\n            assert a[i].tolist() == [i] * (i % 10)\n\n        branch = uproot.open(""tests/samples/small-evnt-tree-fullsplit.root"")[""tree""][""StlVecF64""]\n        a = branch.array()\n        for i in range(100):\n            assert a[i].tolist() == [i] * (i % 10)\n\n    def test_vector_of_vector_of_numbers(self):\n        branch = uproot.open(""tests/samples/vectorVectorDouble.root"")[""t""][""x""]\n        assert branch.array().tolist() == [[], [[], []], [[10.0], [], [10.0, 20.0]], [[20.0, -21.0, -22.0]], [[200.0], [-201.0], [202.0]]]\n\n    def test_strings1(self):\n        tree = uproot.open(""tests/samples/small-evnt-tree-fullsplit.root"")[""tree""]\n        assert tree.array(""Str"").tolist() == [b\'evt-000\', b\'evt-001\', b\'evt-002\', b\'evt-003\', b\'evt-004\', b\'evt-005\', b\'evt-006\', b\'evt-007\', b\'evt-008\', b\'evt-009\', b\'evt-010\', b\'evt-011\', b\'evt-012\', b\'evt-013\', b\'evt-014\', b\'evt-015\', b\'evt-016\', b\'evt-017\', b\'evt-018\', b\'evt-019\', b\'evt-020\', b\'evt-021\', b\'evt-022\', b\'evt-023\', b\'evt-024\', b\'evt-025\', b\'evt-026\', b\'evt-027\', b\'evt-028\', b\'evt-029\', b\'evt-030\', b\'evt-031\', b\'evt-032\', b\'evt-033\', b\'evt-034\', b\'evt-035\', b\'evt-036\', b\'evt-037\', b\'evt-038\', b\'evt-039\', b\'evt-040\', b\'evt-041\', b\'evt-042\', b\'evt-043\', b\'evt-044\', b\'evt-045\', b\'evt-046\', b\'evt-047\', b\'evt-048\', b\'evt-049\', b\'evt-050\', b\'evt-051\', b\'evt-052\', b\'evt-053\', b\'evt-054\', b\'evt-055\', b\'evt-056\', b\'evt-057\', b\'evt-058\', b\'evt-059\', b\'evt-060\', b\'evt-061\', b\'evt-062\', b\'evt-063\', b\'evt-064\', b\'evt-065\', b\'evt-066\', b\'evt-067\', b\'evt-068\', b\'evt-069\', b\'evt-070\', b\'evt-071\', b\'evt-072\', b\'evt-073\', b\'evt-074\', b\'evt-075\', b\'evt-076\', b\'evt-077\', b\'evt-078\', b\'evt-079\', b\'evt-080\', b\'evt-081\', b\'evt-082\', b\'evt-083\', b\'evt-084\', b\'evt-085\', b\'evt-086\', b\'evt-087\', b\'evt-088\', b\'evt-089\', b\'evt-090\', b\'evt-091\', b\'evt-092\', b\'evt-093\', b\'evt-094\', b\'evt-095\', b\'evt-096\', b\'evt-097\', b\'evt-098\', b\'evt-099\']\n\n    def test_strings2(self):\n        tree = uproot.open(""tests/samples/small-evnt-tree-fullsplit.root"")[""tree""]\n        assert tree.array(""StdStr"").tolist() == [b\'std-000\', b\'std-001\', b\'std-002\', b\'std-003\', b\'std-004\', b\'std-005\', b\'std-006\', b\'std-007\', b\'std-008\', b\'std-009\', b\'std-010\', b\'std-011\', b\'std-012\', b\'std-013\', b\'std-014\', b\'std-015\', b\'std-016\', b\'std-017\', b\'std-018\', b\'std-019\', b\'std-020\', b\'std-021\', b\'std-022\', b\'std-023\', b\'std-024\', b\'std-025\', b\'std-026\', b\'std-027\', b\'std-028\', b\'std-029\', b\'std-030\', b\'std-031\', b\'std-032\', b\'std-033\', b\'std-034\', b\'std-035\', b\'std-036\', b\'std-037\', b\'std-038\', b\'std-039\', b\'std-040\', b\'std-041\', b\'std-042\', b\'std-043\', b\'std-044\', b\'std-045\', b\'std-046\', b\'std-047\', b\'std-048\', b\'std-049\', b\'std-050\', b\'std-051\', b\'std-052\', b\'std-053\', b\'std-054\', b\'std-055\', b\'std-056\', b\'std-057\', b\'std-058\', b\'std-059\', b\'std-060\', b\'std-061\', b\'std-062\', b\'std-063\', b\'std-064\', b\'std-065\', b\'std-066\', b\'std-067\', b\'std-068\', b\'std-069\', b\'std-070\', b\'std-071\', b\'std-072\', b\'std-073\', b\'std-074\', b\'std-075\', b\'std-076\', b\'std-077\', b\'std-078\', b\'std-079\', b\'std-080\', b\'std-081\', b\'std-082\', b\'std-083\', b\'std-084\', b\'std-085\', b\'std-086\', b\'std-087\', b\'std-088\', b\'std-089\', b\'std-090\', b\'std-091\', b\'std-092\', b\'std-093\', b\'std-094\', b\'std-095\', b\'std-096\', b\'std-097\', b\'std-098\', b\'std-099\']\n\n    def test_strings3(self):\n        tree = uproot.open(""tests/samples/small-evnt-tree-fullsplit.root"")[""tree""]\n        assert tree.array(""StlVecStr"").tolist() == [[], [b\'vec-001\'], [b\'vec-002\', b\'vec-002\'], [b\'vec-003\', b\'vec-003\', b\'vec-003\'], [b\'vec-004\', b\'vec-004\', b\'vec-004\', b\'vec-004\'], [b\'vec-005\', b\'vec-005\', b\'vec-005\', b\'vec-005\', b\'vec-005\'], [b\'vec-006\', b\'vec-006\', b\'vec-006\', b\'vec-006\', b\'vec-006\', b\'vec-006\'], [b\'vec-007\', b\'vec-007\', b\'vec-007\', b\'vec-007\', b\'vec-007\', b\'vec-007\', b\'vec-007\'], [b\'vec-008\', b\'vec-008\', b\'vec-008\', b\'vec-008\', b\'vec-008\', b\'vec-008\', b\'vec-008\', b\'vec-008\'], [b\'vec-009\', b\'vec-009\', b\'vec-009\', b\'vec-009\', b\'vec-009\', b\'vec-009\', b\'vec-009\', b\'vec-009\', b\'vec-009\'], [], [b\'vec-011\'], [b\'vec-012\', b\'vec-012\'], [b\'vec-013\', b\'vec-013\', b\'vec-013\'], [b\'vec-014\', b\'vec-014\', b\'vec-014\', b\'vec-014\'], [b\'vec-015\', b\'vec-015\', b\'vec-015\', b\'vec-015\', b\'vec-015\'], [b\'vec-016\', b\'vec-016\', b\'vec-016\', b\'vec-016\', b\'vec-016\', b\'vec-016\'], [b\'vec-017\', b\'vec-017\', b\'vec-017\', b\'vec-017\', b\'vec-017\', b\'vec-017\', b\'vec-017\'], [b\'vec-018\', b\'vec-018\', b\'vec-018\', b\'vec-018\', b\'vec-018\', b\'vec-018\', b\'vec-018\', b\'vec-018\'], [b\'vec-019\', b\'vec-019\', b\'vec-019\', b\'vec-019\', b\'vec-019\', b\'vec-019\', b\'vec-019\', b\'vec-019\', b\'vec-019\'], [], [b\'vec-021\'], [b\'vec-022\', b\'vec-022\'], [b\'vec-023\', b\'vec-023\', b\'vec-023\'], [b\'vec-024\', b\'vec-024\', b\'vec-024\', b\'vec-024\'], [b\'vec-025\', b\'vec-025\', b\'vec-025\', b\'vec-025\', b\'vec-025\'], [b\'vec-026\', b\'vec-026\', b\'vec-026\', b\'vec-026\', b\'vec-026\', b\'vec-026\'], [b\'vec-027\', b\'vec-027\', b\'vec-027\', b\'vec-027\', b\'vec-027\', b\'vec-027\', b\'vec-027\'], [b\'vec-028\', b\'vec-028\', b\'vec-028\', b\'vec-028\', b\'vec-028\', b\'vec-028\', b\'vec-028\', b\'vec-028\'], [b\'vec-029\', b\'vec-029\', b\'vec-029\', b\'vec-029\', b\'vec-029\', b\'vec-029\', b\'vec-029\', b\'vec-029\', b\'vec-029\'], [], [b\'vec-031\'], [b\'vec-032\', b\'vec-032\'], [b\'vec-033\', b\'vec-033\', b\'vec-033\'], [b\'vec-034\', b\'vec-034\', b\'vec-034\', b\'vec-034\'], [b\'vec-035\', b\'vec-035\', b\'vec-035\', b\'vec-035\', b\'vec-035\'], [b\'vec-036\', b\'vec-036\', b\'vec-036\', b\'vec-036\', b\'vec-036\', b\'vec-036\'], [b\'vec-037\', b\'vec-037\', b\'vec-037\', b\'vec-037\', b\'vec-037\', b\'vec-037\', b\'vec-037\'], [b\'vec-038\', b\'vec-038\', b\'vec-038\', b\'vec-038\', b\'vec-038\', b\'vec-038\', b\'vec-038\', b\'vec-038\'], [b\'vec-039\', b\'vec-039\', b\'vec-039\', b\'vec-039\', b\'vec-039\', b\'vec-039\', b\'vec-039\', b\'vec-039\', b\'vec-039\'], [], [b\'vec-041\'], [b\'vec-042\', b\'vec-042\'], [b\'vec-043\', b\'vec-043\', b\'vec-043\'], [b\'vec-044\', b\'vec-044\', b\'vec-044\', b\'vec-044\'], [b\'vec-045\', b\'vec-045\', b\'vec-045\', b\'vec-045\', b\'vec-045\'], [b\'vec-046\', b\'vec-046\', b\'vec-046\', b\'vec-046\', b\'vec-046\', b\'vec-046\'], [b\'vec-047\', b\'vec-047\', b\'vec-047\', b\'vec-047\', b\'vec-047\', b\'vec-047\', b\'vec-047\'], [b\'vec-048\', b\'vec-048\', b\'vec-048\', b\'vec-048\', b\'vec-048\', b\'vec-048\', b\'vec-048\', b\'vec-048\'], [b\'vec-049\', b\'vec-049\', b\'vec-049\', b\'vec-049\', b\'vec-049\', b\'vec-049\', b\'vec-049\', b\'vec-049\', b\'vec-049\'], [], [b\'vec-051\'], [b\'vec-052\', b\'vec-052\'], [b\'vec-053\', b\'vec-053\', b\'vec-053\'], [b\'vec-054\', b\'vec-054\', b\'vec-054\', b\'vec-054\'], [b\'vec-055\', b\'vec-055\', b\'vec-055\', b\'vec-055\', b\'vec-055\'], [b\'vec-056\', b\'vec-056\', b\'vec-056\', b\'vec-056\', b\'vec-056\', b\'vec-056\'], [b\'vec-057\', b\'vec-057\', b\'vec-057\', b\'vec-057\', b\'vec-057\', b\'vec-057\', b\'vec-057\'], [b\'vec-058\', b\'vec-058\', b\'vec-058\', b\'vec-058\', b\'vec-058\', b\'vec-058\', b\'vec-058\', b\'vec-058\'], [b\'vec-059\', b\'vec-059\', b\'vec-059\', b\'vec-059\', b\'vec-059\', b\'vec-059\', b\'vec-059\', b\'vec-059\', b\'vec-059\'], [], [b\'vec-061\'], [b\'vec-062\', b\'vec-062\'], [b\'vec-063\', b\'vec-063\', b\'vec-063\'], [b\'vec-064\', b\'vec-064\', b\'vec-064\', b\'vec-064\'], [b\'vec-065\', b\'vec-065\', b\'vec-065\', b\'vec-065\', b\'vec-065\'], [b\'vec-066\', b\'vec-066\', b\'vec-066\', b\'vec-066\', b\'vec-066\', b\'vec-066\'], [b\'vec-067\', b\'vec-067\', b\'vec-067\', b\'vec-067\', b\'vec-067\', b\'vec-067\', b\'vec-067\'], [b\'vec-068\', b\'vec-068\', b\'vec-068\', b\'vec-068\', b\'vec-068\', b\'vec-068\', b\'vec-068\', b\'vec-068\'], [b\'vec-069\', b\'vec-069\', b\'vec-069\', b\'vec-069\', b\'vec-069\', b\'vec-069\', b\'vec-069\', b\'vec-069\', b\'vec-069\'], [], [b\'vec-071\'], [b\'vec-072\', b\'vec-072\'], [b\'vec-073\', b\'vec-073\', b\'vec-073\'], [b\'vec-074\', b\'vec-074\', b\'vec-074\', b\'vec-074\'], [b\'vec-075\', b\'vec-075\', b\'vec-075\', b\'vec-075\', b\'vec-075\'], [b\'vec-076\', b\'vec-076\', b\'vec-076\', b\'vec-076\', b\'vec-076\', b\'vec-076\'], [b\'vec-077\', b\'vec-077\', b\'vec-077\', b\'vec-077\', b\'vec-077\', b\'vec-077\', b\'vec-077\'], [b\'vec-078\', b\'vec-078\', b\'vec-078\', b\'vec-078\', b\'vec-078\', b\'vec-078\', b\'vec-078\', b\'vec-078\'], [b\'vec-079\', b\'vec-079\', b\'vec-079\', b\'vec-079\', b\'vec-079\', b\'vec-079\', b\'vec-079\', b\'vec-079\', b\'vec-079\'], [], [b\'vec-081\'], [b\'vec-082\', b\'vec-082\'], [b\'vec-083\', b\'vec-083\', b\'vec-083\'], [b\'vec-084\', b\'vec-084\', b\'vec-084\', b\'vec-084\'], [b\'vec-085\', b\'vec-085\', b\'vec-085\', b\'vec-085\', b\'vec-085\'], [b\'vec-086\', b\'vec-086\', b\'vec-086\', b\'vec-086\', b\'vec-086\', b\'vec-086\'], [b\'vec-087\', b\'vec-087\', b\'vec-087\', b\'vec-087\', b\'vec-087\', b\'vec-087\', b\'vec-087\'], [b\'vec-088\', b\'vec-088\', b\'vec-088\', b\'vec-088\', b\'vec-088\', b\'vec-088\', b\'vec-088\', b\'vec-088\'], [b\'vec-089\', b\'vec-089\', b\'vec-089\', b\'vec-089\', b\'vec-089\', b\'vec-089\', b\'vec-089\', b\'vec-089\', b\'vec-089\'], [], [b\'vec-091\'], [b\'vec-092\', b\'vec-092\'], [b\'vec-093\', b\'vec-093\', b\'vec-093\'], [b\'vec-094\', b\'vec-094\', b\'vec-094\', b\'vec-094\'], [b\'vec-095\', b\'vec-095\', b\'vec-095\', b\'vec-095\', b\'vec-095\'], [b\'vec-096\', b\'vec-096\', b\'vec-096\', b\'vec-096\', b\'vec-096\', b\'vec-096\'], [b\'vec-097\', b\'vec-097\', b\'vec-097\', b\'vec-097\', b\'vec-097\', b\'vec-097\', b\'vec-097\'], [b\'vec-098\', b\'vec-098\', b\'vec-098\', b\'vec-098\', b\'vec-098\', b\'vec-098\', b\'vec-098\', b\'vec-098\'], [b\'vec-099\', b\'vec-099\', b\'vec-099\', b\'vec-099\', b\'vec-099\', b\'vec-099\', b\'vec-099\', b\'vec-099\', b\'vec-099\']]\n\n    @pytest.mark.skipif(os.name == ""nt"", reason=""Windows Python 3 \'long\' is not struct\'s \'i\', \'l\', or \'q\'."")\n    def test_unsplit(self):\n        branch = uproot.open(""tests/samples/small-evnt-tree-nosplit.root"")[""tree""][""evt""]\n        a = branch.array()\n        assert [x._StlVecStr for x in a] == [[], [b\'vec-001\'], [b\'vec-002\', b\'vec-002\'], [b\'vec-003\', b\'vec-003\', b\'vec-003\'], [b\'vec-004\', b\'vec-004\', b\'vec-004\', b\'vec-004\'], [b\'vec-005\', b\'vec-005\', b\'vec-005\', b\'vec-005\', b\'vec-005\'], [b\'vec-006\', b\'vec-006\', b\'vec-006\', b\'vec-006\', b\'vec-006\', b\'vec-006\'], [b\'vec-007\', b\'vec-007\', b\'vec-007\', b\'vec-007\', b\'vec-007\', b\'vec-007\', b\'vec-007\'], [b\'vec-008\', b\'vec-008\', b\'vec-008\', b\'vec-008\', b\'vec-008\', b\'vec-008\', b\'vec-008\', b\'vec-008\'], [b\'vec-009\', b\'vec-009\', b\'vec-009\', b\'vec-009\', b\'vec-009\', b\'vec-009\', b\'vec-009\', b\'vec-009\', b\'vec-009\'], [], [b\'vec-011\'], [b\'vec-012\', b\'vec-012\'], [b\'vec-013\', b\'vec-013\', b\'vec-013\'], [b\'vec-014\', b\'vec-014\', b\'vec-014\', b\'vec-014\'], [b\'vec-015\', b\'vec-015\', b\'vec-015\', b\'vec-015\', b\'vec-015\'], [b\'vec-016\', b\'vec-016\', b\'vec-016\', b\'vec-016\', b\'vec-016\', b\'vec-016\'], [b\'vec-017\', b\'vec-017\', b\'vec-017\', b\'vec-017\', b\'vec-017\', b\'vec-017\', b\'vec-017\'], [b\'vec-018\', b\'vec-018\', b\'vec-018\', b\'vec-018\', b\'vec-018\', b\'vec-018\', b\'vec-018\', b\'vec-018\'], [b\'vec-019\', b\'vec-019\', b\'vec-019\', b\'vec-019\', b\'vec-019\', b\'vec-019\', b\'vec-019\', b\'vec-019\', b\'vec-019\'], [], [b\'vec-021\'], [b\'vec-022\', b\'vec-022\'], [b\'vec-023\', b\'vec-023\', b\'vec-023\'], [b\'vec-024\', b\'vec-024\', b\'vec-024\', b\'vec-024\'], [b\'vec-025\', b\'vec-025\', b\'vec-025\', b\'vec-025\', b\'vec-025\'], [b\'vec-026\', b\'vec-026\', b\'vec-026\', b\'vec-026\', b\'vec-026\', b\'vec-026\'], [b\'vec-027\', b\'vec-027\', b\'vec-027\', b\'vec-027\', b\'vec-027\', b\'vec-027\', b\'vec-027\'], [b\'vec-028\', b\'vec-028\', b\'vec-028\', b\'vec-028\', b\'vec-028\', b\'vec-028\', b\'vec-028\', b\'vec-028\'], [b\'vec-029\', b\'vec-029\', b\'vec-029\', b\'vec-029\', b\'vec-029\', b\'vec-029\', b\'vec-029\', b\'vec-029\', b\'vec-029\'], [], [b\'vec-031\'], [b\'vec-032\', b\'vec-032\'], [b\'vec-033\', b\'vec-033\', b\'vec-033\'], [b\'vec-034\', b\'vec-034\', b\'vec-034\', b\'vec-034\'], [b\'vec-035\', b\'vec-035\', b\'vec-035\', b\'vec-035\', b\'vec-035\'], [b\'vec-036\', b\'vec-036\', b\'vec-036\', b\'vec-036\', b\'vec-036\', b\'vec-036\'], [b\'vec-037\', b\'vec-037\', b\'vec-037\', b\'vec-037\', b\'vec-037\', b\'vec-037\', b\'vec-037\'], [b\'vec-038\', b\'vec-038\', b\'vec-038\', b\'vec-038\', b\'vec-038\', b\'vec-038\', b\'vec-038\', b\'vec-038\'], [b\'vec-039\', b\'vec-039\', b\'vec-039\', b\'vec-039\', b\'vec-039\', b\'vec-039\', b\'vec-039\', b\'vec-039\', b\'vec-039\'], [], [b\'vec-041\'], [b\'vec-042\', b\'vec-042\'], [b\'vec-043\', b\'vec-043\', b\'vec-043\'], [b\'vec-044\', b\'vec-044\', b\'vec-044\', b\'vec-044\'], [b\'vec-045\', b\'vec-045\', b\'vec-045\', b\'vec-045\', b\'vec-045\'], [b\'vec-046\', b\'vec-046\', b\'vec-046\', b\'vec-046\', b\'vec-046\', b\'vec-046\'], [b\'vec-047\', b\'vec-047\', b\'vec-047\', b\'vec-047\', b\'vec-047\', b\'vec-047\', b\'vec-047\'], [b\'vec-048\', b\'vec-048\', b\'vec-048\', b\'vec-048\', b\'vec-048\', b\'vec-048\', b\'vec-048\', b\'vec-048\'], [b\'vec-049\', b\'vec-049\', b\'vec-049\', b\'vec-049\', b\'vec-049\', b\'vec-049\', b\'vec-049\', b\'vec-049\', b\'vec-049\'], [], [b\'vec-051\'], [b\'vec-052\', b\'vec-052\'], [b\'vec-053\', b\'vec-053\', b\'vec-053\'], [b\'vec-054\', b\'vec-054\', b\'vec-054\', b\'vec-054\'], [b\'vec-055\', b\'vec-055\', b\'vec-055\', b\'vec-055\', b\'vec-055\'], [b\'vec-056\', b\'vec-056\', b\'vec-056\', b\'vec-056\', b\'vec-056\', b\'vec-056\'], [b\'vec-057\', b\'vec-057\', b\'vec-057\', b\'vec-057\', b\'vec-057\', b\'vec-057\', b\'vec-057\'], [b\'vec-058\', b\'vec-058\', b\'vec-058\', b\'vec-058\', b\'vec-058\', b\'vec-058\', b\'vec-058\', b\'vec-058\'], [b\'vec-059\', b\'vec-059\', b\'vec-059\', b\'vec-059\', b\'vec-059\', b\'vec-059\', b\'vec-059\', b\'vec-059\', b\'vec-059\'], [], [b\'vec-061\'], [b\'vec-062\', b\'vec-062\'], [b\'vec-063\', b\'vec-063\', b\'vec-063\'], [b\'vec-064\', b\'vec-064\', b\'vec-064\', b\'vec-064\'], [b\'vec-065\', b\'vec-065\', b\'vec-065\', b\'vec-065\', b\'vec-065\'], [b\'vec-066\', b\'vec-066\', b\'vec-066\', b\'vec-066\', b\'vec-066\', b\'vec-066\'], [b\'vec-067\', b\'vec-067\', b\'vec-067\', b\'vec-067\', b\'vec-067\', b\'vec-067\', b\'vec-067\'], [b\'vec-068\', b\'vec-068\', b\'vec-068\', b\'vec-068\', b\'vec-068\', b\'vec-068\', b\'vec-068\', b\'vec-068\'], [b\'vec-069\', b\'vec-069\', b\'vec-069\', b\'vec-069\', b\'vec-069\', b\'vec-069\', b\'vec-069\', b\'vec-069\', b\'vec-069\'], [], [b\'vec-071\'], [b\'vec-072\', b\'vec-072\'], [b\'vec-073\', b\'vec-073\', b\'vec-073\'], [b\'vec-074\', b\'vec-074\', b\'vec-074\', b\'vec-074\'], [b\'vec-075\', b\'vec-075\', b\'vec-075\', b\'vec-075\', b\'vec-075\'], [b\'vec-076\', b\'vec-076\', b\'vec-076\', b\'vec-076\', b\'vec-076\', b\'vec-076\'], [b\'vec-077\', b\'vec-077\', b\'vec-077\', b\'vec-077\', b\'vec-077\', b\'vec-077\', b\'vec-077\'], [b\'vec-078\', b\'vec-078\', b\'vec-078\', b\'vec-078\', b\'vec-078\', b\'vec-078\', b\'vec-078\', b\'vec-078\'], [b\'vec-079\', b\'vec-079\', b\'vec-079\', b\'vec-079\', b\'vec-079\', b\'vec-079\', b\'vec-079\', b\'vec-079\', b\'vec-079\'], [], [b\'vec-081\'], [b\'vec-082\', b\'vec-082\'], [b\'vec-083\', b\'vec-083\', b\'vec-083\'], [b\'vec-084\', b\'vec-084\', b\'vec-084\', b\'vec-084\'], [b\'vec-085\', b\'vec-085\', b\'vec-085\', b\'vec-085\', b\'vec-085\'], [b\'vec-086\', b\'vec-086\', b\'vec-086\', b\'vec-086\', b\'vec-086\', b\'vec-086\'], [b\'vec-087\', b\'vec-087\', b\'vec-087\', b\'vec-087\', b\'vec-087\', b\'vec-087\', b\'vec-087\'], [b\'vec-088\', b\'vec-088\', b\'vec-088\', b\'vec-088\', b\'vec-088\', b\'vec-088\', b\'vec-088\', b\'vec-088\'], [b\'vec-089\', b\'vec-089\', b\'vec-089\', b\'vec-089\', b\'vec-089\', b\'vec-089\', b\'vec-089\', b\'vec-089\', b\'vec-089\'], [], [b\'vec-091\'], [b\'vec-092\', b\'vec-092\'], [b\'vec-093\', b\'vec-093\', b\'vec-093\'], [b\'vec-094\', b\'vec-094\', b\'vec-094\', b\'vec-094\'], [b\'vec-095\', b\'vec-095\', b\'vec-095\', b\'vec-095\', b\'vec-095\'], [b\'vec-096\', b\'vec-096\', b\'vec-096\', b\'vec-096\', b\'vec-096\', b\'vec-096\'], [b\'vec-097\', b\'vec-097\', b\'vec-097\', b\'vec-097\', b\'vec-097\', b\'vec-097\', b\'vec-097\'], [b\'vec-098\', b\'vec-098\', b\'vec-098\', b\'vec-098\', b\'vec-098\', b\'vec-098\', b\'vec-098\', b\'vec-098\'], [b\'vec-099\', b\'vec-099\', b\'vec-099\', b\'vec-099\', b\'vec-099\', b\'vec-099\', b\'vec-099\', b\'vec-099\', b\'vec-099\']]\n\n    def test_array(self):\n        tree = uproot.open(""tests/samples/small-evnt-tree-fullsplit.root"")[""tree""]\n        assert tree.array(""ArrayI16[10]"").tolist() == [[i] * 10 for i in range(100)]\n\n    def test_slice(self):\n        tree = uproot.open(""tests/samples/small-evnt-tree-fullsplit.root"")[""tree""]\n        assert tree.array(""SliceI16"").tolist() == [[], [1], [2, 2], [3, 3, 3], [4, 4, 4, 4], [5, 5, 5, 5, 5], [6, 6, 6, 6, 6, 6], [7, 7, 7, 7, 7, 7, 7], [8, 8, 8, 8, 8, 8, 8, 8], [9, 9, 9, 9, 9, 9, 9, 9, 9], [], [11], [12, 12], [13, 13, 13], [14, 14, 14, 14], [15, 15, 15, 15, 15], [16, 16, 16, 16, 16, 16], [17, 17, 17, 17, 17, 17, 17], [18, 18, 18, 18, 18, 18, 18, 18], [19, 19, 19, 19, 19, 19, 19, 19, 19], [], [21], [22, 22], [23, 23, 23], [24, 24, 24, 24], [25, 25, 25, 25, 25], [26, 26, 26, 26, 26, 26], [27, 27, 27, 27, 27, 27, 27], [28, 28, 28, 28, 28, 28, 28, 28], [29, 29, 29, 29, 29, 29, 29, 29, 29], [], [31], [32, 32], [33, 33, 33], [34, 34, 34, 34], [35, 35, 35, 35, 35], [36, 36, 36, 36, 36, 36], [37, 37, 37, 37, 37, 37, 37], [38, 38, 38, 38, 38, 38, 38, 38], [39, 39, 39, 39, 39, 39, 39, 39, 39], [], [41], [42, 42], [43, 43, 43], [44, 44, 44, 44], [45, 45, 45, 45, 45], [46, 46, 46, 46, 46, 46], [47, 47, 47, 47, 47, 47, 47], [48, 48, 48, 48, 48, 48, 48, 48], [49, 49, 49, 49, 49, 49, 49, 49, 49], [], [51], [52, 52], [53, 53, 53], [54, 54, 54, 54], [55, 55, 55, 55, 55], [56, 56, 56, 56, 56, 56], [57, 57, 57, 57, 57, 57, 57], [58, 58, 58, 58, 58, 58, 58, 58], [59, 59, 59, 59, 59, 59, 59, 59, 59], [], [61], [62, 62], [63, 63, 63], [64, 64, 64, 64], [65, 65, 65, 65, 65], [66, 66, 66, 66, 66, 66], [67, 67, 67, 67, 67, 67, 67], [68, 68, 68, 68, 68, 68, 68, 68], [69, 69, 69, 69, 69, 69, 69, 69, 69], [], [71], [72, 72], [73, 73, 73], [74, 74, 74, 74], [75, 75, 75, 75, 75], [76, 76, 76, 76, 76, 76], [77, 77, 77, 77, 77, 77, 77], [78, 78, 78, 78, 78, 78, 78, 78], [79, 79, 79, 79, 79, 79, 79, 79, 79], [], [81], [82, 82], [83, 83, 83], [84, 84, 84, 84], [85, 85, 85, 85, 85], [86, 86, 86, 86, 86, 86], [87, 87, 87, 87, 87, 87, 87], [88, 88, 88, 88, 88, 88, 88, 88], [89, 89, 89, 89, 89, 89, 89, 89, 89], [], [91], [92, 92], [93, 93, 93], [94, 94, 94, 94], [95, 95, 95, 95, 95], [96, 96, 96, 96, 96, 96], [97, 97, 97, 97, 97, 97, 97], [98, 98, 98, 98, 98, 98, 98, 98], [99, 99, 99, 99, 99, 99, 99, 99, 99]]\n'"
tests/test_tree.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nimport os\nfrom collections import namedtuple\n\nimport numpy\nimport pytest\n\nimport awkward\nimport uproot\n\ndef basest(array):\n    while getattr(array, ""base"", None) is not None:\n        array = array.base\n    return array\n\nclass Test(object):\n    ###################################################### double32\n\n    def test_double32(self):\n        t = uproot.open(""tests/samples/demo-double32.root"")[""T""]\n        fD64 = t.array(""fD64"")\n        fF32 = t.array(""fF32"")\n        fI32 = t.array(""fI32"")\n        fI30 = t.array(""fI30"")\n        fI28 = t.array(""fI28"")\n        ratio_fF32 = fF32 / fD64\n        ratio_fI32 = fI32 / fD64\n        ratio_fI30 = fI30 / fD64\n        ratio_fI28 = fI28 / fD64\n        assert ratio_fF32.min() > 0.9999 and ratio_fF32.max() < 1.0001\n        assert ratio_fI32.min() > 0.9999 and ratio_fI32.max() < 1.0001\n        assert ratio_fI30.min() > 0.9999 and ratio_fI30.max() < 1.0001\n        assert ratio_fI28.min() > 0.9999 and ratio_fI28.max() < 1.0001\n\n    ###################################################### basket\n\n    def test_flat_basket(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""i8""]\n        interpretation = branch._normalize_interpretation(None, awkward)\n        entrystart, entrystop = uproot.tree._normalize_entrystartstop(branch.numentries, None, None)\n        local_entrystart, local_entrystop = branch._localentries(0, entrystart, entrystop)\n\n        one = branch._basket(0, interpretation, local_entrystart, local_entrystop, awkward, None, None)\n        two = branch._basket(0, interpretation, local_entrystart, local_entrystop, awkward, None, None)\n        assert numpy.array_equal(one, numpy.array([-15, -14, -13], dtype="">i8""))\n        assert basest(one) is basest(two)\n\n        three = branch.basket(0)\n        assert numpy.array_equal(three, numpy.array([-15, -14, -13], dtype="">i8""))\n        assert basest(one) is not basest(three)\n\n        buf = numpy.zeros(10, dtype=numpy.float64)\n        four = branch.basket(0, interpretation.toarray(buf))\n        assert numpy.array_equal(four, numpy.array([-15, -14, -13], dtype="">i8""))\n        assert basest(four) is buf\n\n    def test_regular_basket(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""ai8""]\n        interpretation = branch._normalize_interpretation(None, awkward)\n        entrystart, entrystop = uproot.tree._normalize_entrystartstop(branch.numentries, None, None)\n        local_entrystart, local_entrystop = branch._localentries(0, entrystart, entrystop)\n\n        one = branch._basket(0, interpretation, local_entrystart, local_entrystop, awkward, None, None)\n        two = branch._basket(0, interpretation, local_entrystart, local_entrystop, awkward, None, None)\n        assert numpy.array_equal(one, numpy.array([[-14, -13, -12]], dtype="">i8""))\n        assert basest(one) is basest(two)\n\n        three = branch.basket(0)\n        assert numpy.array_equal(three, numpy.array([[-14, -13, -12]], dtype="">i8""))\n        assert basest(one) is not basest(three)\n\n        assert branch.basket(0, interpretation.to(todims=(3,))).shape == (1, 3)\n        assert branch.basket(0, interpretation.to(todims=())).shape == (3,)\n        assert branch.basket(0, interpretation.to(todims=(1,))).shape == (3, 1)\n        assert branch.basket(0, interpretation.to(todims=(1, 1))).shape == (3, 1, 1)\n        assert branch.basket(0, interpretation.to(todims=(1, 3))).shape == (1, 1, 3)\n\n        buf = numpy.zeros(10, dtype=numpy.float64)\n        four = branch.basket(0, interpretation.toarray(buf))\n        assert numpy.array_equal(four, numpy.array([-14, -13, -12], dtype="">i8""))\n        assert basest(four) is buf\n\n    def test_irregular_basket(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""Ai8""]\n        interpretation = branch._normalize_interpretation(None, awkward)\n        entrystart, entrystop = uproot.tree._normalize_entrystartstop(branch.numentries, None, None)\n        local_entrystart, local_entrystop = branch._localentries(0, entrystart, entrystop)\n\n        one = branch._basket(0, interpretation, local_entrystart, local_entrystop, awkward, None, None)\n        two = branch._basket(0, interpretation, local_entrystart, local_entrystop, awkward, None, None)\n        assert numpy.array_equal(one[0], numpy.array([], dtype="">i8""))\n        assert numpy.array_equal(one[1], numpy.array([-15], dtype="">i8""))\n        assert basest(one.content) is basest(two.content)\n\n        three = branch.basket(0)\n        assert numpy.array_equal(three[0], numpy.array([], dtype="">i8""))\n        assert numpy.array_equal(three[1], numpy.array([-15], dtype="">i8""))\n\n    def test_strings_basket(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""str""]\n        interpretation = branch._normalize_interpretation(None, awkward)\n        entrystart, entrystop = uproot.tree._normalize_entrystartstop(branch.numentries, None, None)\n        local_entrystart, local_entrystop = branch._localentries(0, entrystart, entrystop)\n\n        one = branch.basket(0, interpretation, local_entrystart, local_entrystop)\n        two = branch.basket(0, interpretation, local_entrystart, local_entrystop)\n\n        assert one.tolist() == [b""hey-0"", b""hey-1"", b""hey-2"", b""hey-3"", b""hey-4"", b""hey-5""]\n        assert basest(one.content.content) is not basest(two.content.content)\n\n        three = branch.basket(0)\n        assert three.tolist() == [b""hey-0"", b""hey-1"", b""hey-2"", b""hey-3"", b""hey-4"", b""hey-5""]\n\n    ###################################################### baskets\n\n    def test_flat_baskets(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""i8""]\n        expectation = [[-15, -14, -13], [-12, -11, -10], [-9, -8, -7], [-6, -5, -4], [-3, -2, -1], [0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]]\n        assert [x.tolist() for x in branch.baskets()] == expectation\n        assert [x.tolist() for x in branch.iterate_baskets()] == expectation\n\n    def test_regular_baskets(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""ai8""]\n        expectation = [[[-14, -13, -12]], [[-13, -12, -11]], [[-12, -11, -10]], [[-11, -10, -9]], [[-10, -9, -8]], [[-9, -8, -7]], [[-8, -7, -6]], [[-7, -6, -5]], [[-6, -5, -4]], [[-5, -4, -3]], [[-4, -3, -2]], [[-3, -2, -1]], [[-2, -1, 0]], [[-1, 0, 1]], [[0, 1, 2]], [[1, 2, 3]], [[2, 3, 4]], [[3, 4, 5]], [[4, 5, 6]], [[5, 6, 7]], [[6, 7, 8]], [[7, 8, 9]], [[8, 9, 10]], [[9, 10, 11]], [[10, 11, 12]], [[11, 12, 13]], [[12, 13, 14]], [[13, 14, 15]], [[14, 15, 16]], [[15, 16, 17]]]\n        assert [x.tolist() for x in branch.baskets()] == expectation\n        assert [x.tolist() for x in branch.iterate_baskets()] == expectation\n\n    def test_irregular_baskets(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""Ai8""]\n        expectation = [[[], [-15]], [[-15, -13]], [[-15, -13, -11]], [[-15, -13, -11, -9]], [[], [-10]], [[-10, -8]], [[-10, -8, -6]], [[-10, -8, -6, -4]], [[], [-5]], [[-5, -3]], [[-5, -3, -1]], [[-5, -3, -1, 1]], [[], [0]], [[0, 2]], [[0, 2, 4]], [[0, 2, 4, 6]], [[], [5]], [[5, 7]], [[5, 7, 9]], [[5, 7, 9, 11]], [[], [10]], [[10, 12]], [[10, 12, 14]], [[10, 12, 14, 16]]]\n        assert [len(y) for x in expectation for y in x] == [0, 1, 2, 3, 4] * 6\n        assert [x.tolist() for x in branch.baskets()] == expectation\n        assert [x.tolist() for x in branch.iterate_baskets()] == expectation\n\n    def test_strings_baskets(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""str""]\n        expectation = [[b""hey-0"", b""hey-1"", b""hey-2"", b""hey-3"", b""hey-4"", b""hey-5""], [b""hey-6"", b""hey-7"", b""hey-8"", b""hey-9"", b""hey-10""], [b""hey-11"", b""hey-12"", b""hey-13"", b""hey-14"", b""hey-15""], [b""hey-16"", b""hey-17"", b""hey-18"", b""hey-19"", b""hey-20""], [b""hey-21"", b""hey-22"", b""hey-23"", b""hey-24"", b""hey-25""], [b""hey-26"", b""hey-27"", b""hey-28"", b""hey-29""]]\n        assert [x.tolist() for x in branch.baskets()] == expectation\n        assert [x.tolist() for x in branch.iterate_baskets()] == expectation\n\n    ###################################################### array\n\n    def test_flat_array(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""i8""]\n        expectation = [-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert branch.array(entrystart=entrystart, entrystop=entrystop).tolist() == expectation[entrystart:entrystop]\n\n    def test_regular_array(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""ai8""]\n        expectation = [[-14, -13, -12], [-13, -12, -11], [-12, -11, -10], [-11, -10, -9], [-10, -9, -8], [-9, -8, -7], [-8, -7, -6], [-7, -6, -5], [-6, -5, -4], [-5, -4, -3], [-4, -3, -2], [-3, -2, -1], [-2, -1, 0], [-1, 0, 1], [0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11], [10, 11, 12], [11, 12, 13], [12, 13, 14], [13, 14, 15], [14, 15, 16], [15, 16, 17]]\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert branch.array(entrystart=entrystart, entrystop=entrystop).tolist() == expectation[entrystart:entrystop]\n\n    def test_irregular_array(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""Ai8""]\n        expectation = [[], [-15], [-15, -13], [-15, -13, -11], [-15, -13, -11, -9], [], [-10], [-10, -8], [-10, -8, -6], [-10, -8, -6, -4], [], [-5], [-5, -3], [-5, -3, -1], [-5, -3, -1, 1], [], [0], [0, 2], [0, 2, 4], [0, 2, 4, 6], [], [5], [5, 7], [5, 7, 9], [5, 7, 9, 11], [], [10], [10, 12], [10, 12, 14], [10, 12, 14, 16]]\n        assert [len(x) for x in expectation] == [0, 1, 2, 3, 4] * 6\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert branch.array(entrystart=entrystart, entrystop=entrystop).tolist() == expectation[entrystart:entrystop]\n\n    def test_strings_array(self):\n        branch = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""][""str""]\n        expectation = [b""hey-0"", b""hey-1"", b""hey-2"", b""hey-3"", b""hey-4"", b""hey-5"", b""hey-6"", b""hey-7"", b""hey-8"", b""hey-9"", b""hey-10"", b""hey-11"", b""hey-12"", b""hey-13"", b""hey-14"", b""hey-15"", b""hey-16"", b""hey-17"", b""hey-18"", b""hey-19"", b""hey-20"", b""hey-21"", b""hey-22"", b""hey-23"", b""hey-24"", b""hey-25"", b""hey-26"", b""hey-27"", b""hey-28"", b""hey-29""]\n        for entrystart, entrystop in [(None, None), (1, None), (1, 2), (1, 10), (10, 11), (10, 20), (6, 12), (6, 13)]:\n            assert branch.array(entrystart=entrystart, entrystop=entrystop).tolist() == expectation[entrystart:entrystop]\n\n    ###################################################### iterate\n\n    def test_flat_iterate(self):\n        tree = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""]\n        expectation = [-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n        for n in 1000, 5, 6, 7:\n            assert [x.tolist() for (x,) in tree.iterate(""i8"", n, outputtype=tuple)] == [expectation[x : x + n] for x in range(0, len(expectation), n)]\n\n    def test_regular_iterate(self):\n        tree = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""]\n        expectation = [[-14, -13, -12], [-13, -12, -11], [-12, -11, -10], [-11, -10, -9], [-10, -9, -8], [-9, -8, -7], [-8, -7, -6], [-7, -6, -5], [-6, -5, -4], [-5, -4, -3], [-4, -3, -2], [-3, -2, -1], [-2, -1, 0], [-1, 0, 1], [0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11], [10, 11, 12], [11, 12, 13], [12, 13, 14], [13, 14, 15], [14, 15, 16], [15, 16, 17]]\n        for n in 1000, 5, 6, 7:\n            assert [x.tolist() for (x,) in tree.iterate(""ai8"", n, outputtype=tuple)] == [expectation[x : x + n] for x in range(0, len(expectation), n)]\n\n    def test_irregular_iterate(self):\n        tree = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""]\n        expectation = [[], [-15], [-15, -13], [-15, -13, -11], [-15, -13, -11, -9], [], [-10], [-10, -8], [-10, -8, -6], [-10, -8, -6, -4], [], [-5], [-5, -3], [-5, -3, -1], [-5, -3, -1, 1], [], [0], [0, 2], [0, 2, 4], [0, 2, 4, 6], [], [5], [5, 7], [5, 7, 9], [5, 7, 9, 11], [], [10], [10, 12], [10, 12, 14], [10, 12, 14, 16]]\n        for n in 1000, 5, 6, 7:\n            assert [x.tolist() for (x,) in tree.iterate(""Ai8"", n, outputtype=tuple)] == [expectation[x : x + n] for x in range(0, len(expectation), n)]\n\n    def test_strings_iterate(self):\n        tree = uproot.open(""tests/samples/sample-6.10.05-uncompressed.root"")[""sample""]\n        expectation = [b""hey-0"", b""hey-1"", b""hey-2"", b""hey-3"", b""hey-4"", b""hey-5"", b""hey-6"", b""hey-7"", b""hey-8"", b""hey-9"", b""hey-10"", b""hey-11"", b""hey-12"", b""hey-13"", b""hey-14"", b""hey-15"", b""hey-16"", b""hey-17"", b""hey-18"", b""hey-19"", b""hey-20"", b""hey-21"", b""hey-22"", b""hey-23"", b""hey-24"", b""hey-25"", b""hey-26"", b""hey-27"", b""hey-28"", b""hey-29""]\n        for n in 1000, 5, 6, 7:\n            assert [x.tolist() for (x,) in tree.iterate(""str"", n, outputtype=tuple)] == [expectation[x : x + n] for x in range(0, len(expectation), n)]\n\n    ###################################################### old tests\n\n    def test_branch_array(self):\n        file = uproot.open(""tests/samples/simple.root"")\n        repr(file)\n\n        tree = file[""tree""]\n        repr(tree)\n        repr(tree[""one""])\n\n        assert tree[""one""].array().tolist() == [1, 2, 3, 4]\n        assert tree[""two""].array().tolist() == numpy.array([1.1, 2.2, 3.3, 4.4], dtype=numpy.float32).tolist()\n        assert tree[""three""].array().tolist() == [b""uno"", b""dos"", b""tres"", b""quatro""]\n\n        assert tree[""one""].array().tolist() == [1, 2, 3, 4]\n        assert tree[""two""].array().tolist() == numpy.array([1.1, 2.2, 3.3, 4.4], dtype=numpy.float32).tolist()\n        assert tree[""three""].array().tolist() == [b""uno"", b""dos"", b""tres"", b""quatro""]\n\n        tree = file[""tree""]\n        assert tree[""one""].array().tolist() == [1, 2, 3, 4]\n        assert tree[""two""].array().tolist() == numpy.array([1.1, 2.2, 3.3, 4.4], dtype=numpy.float32).tolist()\n        assert tree[""three""].array().tolist() == [b""uno"", b""dos"", b""tres"", b""quatro""]\n\n    def test_tree_arrays(self):\n        file = uproot.open(""tests/samples/simple.root"")\n\n        tree = file[""tree""]\n        arrays = tree.arrays()\n        assert arrays[b""one""].tolist() == [1, 2, 3, 4]\n        assert arrays[b""two""].tolist() == numpy.array([1.1, 2.2, 3.3, 4.4], dtype=numpy.float32).tolist()\n        assert arrays[b""three""].tolist() == [b""uno"", b""dos"", b""tres"", b""quatro""]\n\n        # get arrays again\n        arrays = tree.arrays()\n        assert arrays[b""one""].tolist() == [1, 2, 3, 4]\n        assert arrays[b""two""].tolist() == numpy.array([1.1, 2.2, 3.3, 4.4], dtype=numpy.float32).tolist()\n        assert arrays[b""three""].tolist() == [b""uno"", b""dos"", b""tres"", b""quatro""]\n\n        # get tree again\n        tree = file[""tree""]\n        arrays = tree.arrays()\n        assert arrays[b""one""].tolist() == [1, 2, 3, 4]\n        assert arrays[b""two""].tolist() == numpy.array([1.1, 2.2, 3.3, 4.4], dtype=numpy.float32).tolist()\n        assert arrays[b""three""].tolist() == [b""uno"", b""dos"", b""tres"", b""quatro""]\n\n    def test_tree_arrays_namedecode(self):\n        file = uproot.open(""tests/samples/simple.root"")\n\n        tree = file[""tree""]\n        arrays = tree.arrays(namedecode=""utf-8"")\n        assert arrays[""one""].tolist() == [1, 2, 3, 4]\n        assert arrays[""two""].tolist() == numpy.array([1.1, 2.2, 3.3, 4.4], dtype=numpy.float32).tolist()\n        assert arrays[""three""].tolist() == [b""uno"", b""dos"", b""tres"", b""quatro""]\n\n    def test_tree_iterator1(self):\n        # one big array\n        for arrays in uproot.open(""tests/samples/foriter.root"")[""foriter""].iterate(entrysteps=1000):\n            assert arrays[b""data""].tolist() == list(range(46))\n\n        # size is equal to basket size (for most baskets)\n        i = 0\n        for arrays in uproot.open(""tests/samples/foriter.root"")[""foriter""].iterate(entrysteps=6):\n            assert arrays[b""data""].tolist() == list(range(i, min(i + 6, 46)))\n            i += 6\n\n        # size is smaller\n        i = 0\n        for arrays in uproot.open(""tests/samples/foriter.root"")[""foriter""].iterate(entrysteps=3):\n            assert arrays[b""data""].tolist() == list(range(i, min(i + 3, 46)))\n            i += 3\n        i = 0\n        for arrays in uproot.open(""tests/samples/foriter.root"")[""foriter""].iterate(entrysteps=4):\n            assert arrays[b""data""].tolist() == list(range(i, min(i + 4, 46)))\n            i += 4\n\n        # size is larger\n        i = 0\n        for arrays in uproot.open(""tests/samples/foriter.root"")[""foriter""].iterate(entrysteps=12):\n            assert arrays[b""data""].tolist() == list(range(i, min(i + 12, 46)))\n            i += 12\n        i = 0\n        for arrays in uproot.open(""tests/samples/foriter.root"")[""foriter""].iterate(entrysteps=10):\n            assert arrays[b""data""].tolist() == list(range(i, min(i + 10, 46)))\n            i += 10\n\n        # singleton case\n        i = 0\n        for arrays in uproot.open(""tests/samples/foriter.root"")[""foriter""].iterate(entrysteps=1):\n            assert arrays[b""data""].tolist() == list(range(i, min(i + 1, 46)))\n            i += 1\n\n    def test_tree_iterator2(self):\n        words = [b""zero"", b""one"", b""two"", b""three"", b""four"", b""five"", b""six"", b""seven"", b""eight"", b""nine"", b""ten"", b""eleven"", b""twelve"", b""thirteen"", b""fourteen"", b""fifteen"", b""sixteen"", b""seventeen"", b""eighteen"", b""ninteen"", b""twenty"", b""twenty-one"", b""twenty-two"", b""twenty-three"", b""twenty-four"", b""twenty-five"", b""twenty-six"", b""twenty-seven"", b""twenty-eight"", b""twenty-nine"", b""thirty""]\n\n        # one big array\n        for arrays in uproot.open(""tests/samples/foriter2.root"")[""foriter2""].iterate(entrysteps=1000):\n            assert arrays[b""data""].tolist() == words\n\n        # size is equal to basket size (for most baskets)\n        i = 0\n        for arrays in uproot.open(""tests/samples/foriter2.root"")[""foriter2""].iterate(entrysteps=6):\n            assert arrays[b""data""].tolist() == words[i:i + 6]\n            i += 6\n\n        # size is smaller\n        i = 0\n        for arrays in uproot.open(""tests/samples/foriter2.root"")[""foriter2""].iterate(entrysteps=3):\n            assert arrays[b""data""].tolist() == words[i:i + 3]\n            i += 3\n        i = 0\n        for arrays in uproot.open(""tests/samples/foriter2.root"")[""foriter2""].iterate(entrysteps=4):\n            assert arrays[b""data""].tolist() == words[i:i + 4]\n            i += 4\n\n        # size is larger\n        i = 0\n        for arrays in uproot.open(""tests/samples/foriter2.root"")[""foriter2""].iterate(entrysteps=12):\n            assert arrays[b""data""].tolist() == words[i:i + 12]\n            i += 12\n        i = 0\n        for arrays in uproot.open(""tests/samples/foriter2.root"")[""foriter2""].iterate(entrysteps=10):\n            assert arrays[b""data""].tolist() == words[i:i + 10]\n            i += 10\n\n        # singleton case\n        i = 0\n        for arrays in uproot.open(""tests/samples/foriter2.root"")[""foriter2""].iterate(entrysteps=1):\n            assert arrays[b""data""].tolist() == words[i:i + 1]\n            i += 1\n\n    def test_tree_iterator3(self):\n        source = list(range(46))\n\n        # one big array\n        for arrays in uproot.iterate([""tests/samples/foriter.root"", ""tests/samples/foriter.root""], ""foriter"", entrysteps=1000):\n            assert arrays[b""data""].tolist() == source\n\n        # size is equal to basket size (for most baskets)\n        i = 0\n        for arrays in uproot.iterate([""tests/samples/foriter.root"", ""tests/samples/foriter.root""], ""foriter"", entrysteps=6):\n            assert arrays[b""data""].tolist() == source[i : i + 6]\n            i += 6\n            if i > 45: i = 0\n\n        # size is smaller\n        i = 0\n        for arrays in uproot.iterate([""tests/samples/foriter.root"", ""tests/samples/foriter.root""], ""foriter"", entrysteps=3):\n            assert arrays[b""data""].tolist() == source[i : i + 3]\n            i += 3\n            if i > 45: i = 0\n        i = 0\n        for arrays in uproot.iterate([""tests/samples/foriter.root"", ""tests/samples/foriter.root""], ""foriter"", entrysteps=4):\n            assert arrays[b""data""].tolist() == source[i : i + 4]\n            i += 4\n            if i > 45: i = 0\n\n        # size is larger\n        i = 0\n        for arrays in uproot.iterate([""tests/samples/foriter.root"", ""tests/samples/foriter.root""], ""foriter"", entrysteps=12):\n            assert arrays[b""data""].tolist() == source[i : i + 12]\n            i += 12\n            if i > 45: i = 0\n        i = 0\n        for arrays in uproot.iterate([""tests/samples/foriter.root"", ""tests/samples/foriter.root""], ""foriter"", entrysteps=10):\n            assert arrays[b""data""].tolist() == source[i : i + 10]\n            i += 10\n            if i > 45: i = 0\n\n        # singleton case\n        i = 0\n        for arrays in uproot.iterate([""tests/samples/foriter.root"", ""tests/samples/foriter.root""], ""foriter"", entrysteps=1):\n            assert arrays[b""data""].tolist() == source[i : i + 1]\n            i += 1\n            if i > 45: i = 0\n\n    def test_tree_iterator4(self):\n        words2 = [b""zero"", b""one"", b""two"", b""three"", b""four"", b""five"", b""six"", b""seven"", b""eight"", b""nine"", b""ten"", b""eleven"", b""twelve"", b""thirteen"", b""fourteen"", b""fifteen"", b""sixteen"", b""seventeen"", b""eighteen"", b""ninteen"", b""twenty"", b""twenty-one"", b""twenty-two"", b""twenty-three"", b""twenty-four"", b""twenty-five"", b""twenty-six"", b""twenty-seven"", b""twenty-eight"", b""twenty-nine"", b""thirty""]\n\n        # one big array\n        for arrays in uproot.iterate([""tests/samples/foriter2.root"", ""tests/samples/foriter2.root""], ""foriter2"", entrysteps=1000):\n            assert arrays[b""data""].tolist() == words2\n\n        # size is equal to basket size (for most baskets)\n        i = 0\n        for arrays in uproot.iterate([""tests/samples/foriter2.root"", ""tests/samples/foriter2.root""], ""foriter2"", entrysteps=6):\n            assert arrays[b""data""].tolist() == words2[i : i + 6]\n            i += 6\n            if i > 30: i = 0\n\n        # size is smaller\n        i = 0\n        for arrays in uproot.iterate([""tests/samples/foriter2.root"", ""tests/samples/foriter2.root""], ""foriter2"", entrysteps=3):\n            assert arrays[b""data""].tolist() == words2[i : i + 3]\n            i += 3\n            if i > 30: i = 0\n        i = 0\n        for arrays in uproot.iterate([""tests/samples/foriter2.root"", ""tests/samples/foriter2.root""], ""foriter2"", entrysteps=4):\n            assert arrays[b""data""].tolist() == words2[i : i + 4]\n            i += 4\n            if i > 30: i = 0\n\n        # size is larger\n        i = 0\n        for arrays in uproot.iterate([""tests/samples/foriter2.root"", ""tests/samples/foriter2.root""], ""foriter2"", entrysteps=12):\n            assert arrays[b""data""].tolist() == words2[i : i + 12]\n            i += 12\n            if i > 30: i = 0\n        i = 0\n        for arrays in uproot.iterate([""tests/samples/foriter2.root"", ""tests/samples/foriter2.root""], ""foriter2"", entrysteps=10):\n            assert arrays[b""data""].tolist() == words2[i : i + 10]\n            i += 10\n            if i > 30: i = 0\n\n        # singleton case\n        i = 0\n        for arrays in uproot.iterate([""tests/samples/foriter2.root"", ""tests/samples/foriter2.root""], ""foriter2"", entrysteps=1):\n            assert arrays[b""data""].tolist() == words2[i : i + 1]\n            i += 1\n            if i > 30: i = 0\n\n    def test_directories(self):\n        file = uproot.open(""tests/samples/nesteddirs.root"")\n\n        assert [(n, cls._classname) for n, cls in file.classes()] == [(b""one;1"", b""TDirectory""), (b""three;1"", b""TDirectory"")]\n        assert [(n, cls._classname) for n, cls in file.allclasses()] == [(b""one;1"", b""TDirectory""), (b""one/two;1"", b""TDirectory""), (b""one/two/tree;1"", b""TTree""), (b""one/tree;1"", b""TTree""), (b""three;1"", b""TDirectory""), (b""three/tree;1"", b""TTree"")]\n\n        assert list(file[""one""][""tree""].keys()) == [b""one"", b""two"", b""three""]\n        assert list(file[""one""].get(""tree"", 1).keys()) == [b""one"", b""two"", b""three""]\n        assert list(file[""one/tree;1""].keys()) == [b""one"", b""two"", b""three""]\n        assert list(file[""one/two/tree;1""].keys()) == [b""Int32"", b""Int64"", b""UInt32"", b""UInt64"", b""Float32"", b""Float64"", b""Str"", b""ArrayInt32"", b""ArrayInt64"", b""ArrayUInt32"", b""ArrayUInt64"", b""ArrayFloat32"", b""ArrayFloat64"", b""N"", b""SliceInt32"", b""SliceInt64"", b""SliceUInt32"", b""SliceUInt64"", b""SliceFloat32"", b""SliceFloat64""]\n        assert list(file[""three/tree;1""].keys()) == [b""evt""]\n\n        assert dict((name, array.tolist()) for name, array in file[""one/tree""].arrays([""one"", ""two"", ""three""]).items()) == {b""one"": [1, 2, 3, 4], b""two"": [1.100000023841858, 2.200000047683716, 3.299999952316284, 4.400000095367432], b""three"": [b""uno"", b""dos"", b""tres"", b""quatro""]}\n        assert file[""one/two/tree""].array(""Int32"").shape == (100,)\n        assert file[""three/tree""].array(""I32"").shape == (100,)\n\n        file = uproot.open(""tests/samples/nesteddirs.root"")\n\n        assert list(file[""one/tree""].keys()) == [b""one"", b""two"", b""three""]\n        assert list(file[""one/two/tree""].keys()) == [b""Int32"", b""Int64"", b""UInt32"", b""UInt64"", b""Float32"", b""Float64"", b""Str"", b""ArrayInt32"", b""ArrayInt64"", b""ArrayUInt32"", b""ArrayUInt64"", b""ArrayFloat32"", b""ArrayFloat64"", b""N"", b""SliceInt32"", b""SliceInt64"", b""SliceUInt32"", b""SliceUInt64"", b""SliceFloat32"", b""SliceFloat64""]\n        assert list(file[""three/tree""].keys()) == [b""evt""]\n\n        assert dict((name, array.tolist()) for name, array in file[""one/tree;1""].arrays([""one"", ""two"", ""three""]).items()) == {b""one"": [1, 2, 3, 4], b""two"": [1.100000023841858, 2.200000047683716, 3.299999952316284, 4.400000095367432], b""three"": [b""uno"", b""dos"", b""tres"", b""quatro""]}\n        assert file[""one/two/tree;1""].array(""Int32"").shape == (100,)\n        assert file[""three/tree;1""].array(""I32"").shape == (100,)\n\n    def test_cast(self):\n        tree = uproot.open(""tests/samples/Zmumu.root"")[""events""]\n        one = numpy.cast[numpy.int32](numpy.floor(tree.array(""M"")))\n        two = tree.array(""M"", numpy.int32)\n        assert one.dtype == two.dtype\n        assert one.shape == two.shape\n        assert numpy.array_equal(one, two)\n\n        for (one,) in tree.iterate(""M"", 10000, outputtype=tuple):\n            one = numpy.cast[numpy.int32](numpy.floor(one))\n        for (two,) in tree.iterate({""M"": numpy.int32}, 10000, outputtype=tuple):\n            pass\n        assert one.dtype == two.dtype\n        assert one.shape == two.shape\n        assert numpy.array_equal(one, two)\n\n    def test_pass_array(self):\n        tree = uproot.open(""tests/samples/Zmumu.root"")[""events""]\n        one = numpy.cast[numpy.int32](numpy.floor(tree.array(""M"")))\n        two = numpy.zeros(one.shape, dtype=one.dtype)\n        tree.array(""M"", two)\n        assert numpy.array_equal(one, two)\n\n        for (one,) in tree.iterate(""M"", 10000, outputtype=tuple):\n            one = numpy.cast[numpy.int32](numpy.floor(one))\n            two = numpy.zeros(one.shape, dtype=one.dtype)\n            for (two,) in tree.iterate({""M"": numpy.int32}, 10000, outputtype=tuple):\n                assert numpy.array_equal(one, two)\n\n    def test_outputtype(self):\n        tree = uproot.open(""tests/samples/simple.root"")[""tree""]\n\n        arrays = tree.arrays([""three"", ""two"", ""one""], outputtype=dict)\n        assert isinstance(arrays, dict)\n        assert arrays[b""one""].tolist() == [1, 2, 3, 4]\n        assert arrays[b""three""].tolist() == [b""uno"", b""dos"", b""tres"", b""quatro""]\n\n        arrays = tree.arrays([""three"", ""two"", ""one""], outputtype=tuple)\n        assert isinstance(arrays, tuple)\n        assert arrays[2].tolist() == [1, 2, 3, 4]\n        assert arrays[0].tolist() == [b""uno"", b""dos"", b""tres"", b""quatro""]\n\n        arrays = tree.arrays([""three"", ""two"", ""one""], outputtype=namedtuple)\n        assert arrays.one.tolist() == [1, 2, 3, 4]\n        assert arrays.three.tolist() == [b""uno"", b""dos"", b""tres"", b""quatro""]\n\n        arrays = tree.arrays([""three"", ""two"", ""one""], outputtype=list)\n        assert isinstance(arrays, list)\n        assert arrays[2].tolist() == [1, 2, 3, 4]\n        assert arrays[0].tolist() == [b""uno"", b""dos"", b""tres"", b""quatro""]\n\n        class Awesome(object):\n            def __init__(self, one, two, three):\n                self.one = one\n                self.two = two\n                self.three = three\n\n        arrays = tree.arrays([""one"", ""two"", ""three""], outputtype=Awesome)\n        assert isinstance(arrays, Awesome)\n        assert arrays.one.tolist() == [1, 2, 3, 4]\n        assert arrays.three.tolist() == [b""uno"", b""dos"", b""tres"", b""quatro""]\n\n        class MyList(list):\n            pass\n\n        class MyTuple(tuple):\n            pass\n\n        arrays = tree.arrays([""three"", ""two"", ""one""], outputtype=MyList)\n        assert isinstance(arrays, MyList)\n        assert arrays[2].tolist() == [1, 2, 3, 4]\n        assert arrays[0].tolist() == [b""uno"", b""dos"", b""tres"", b""quatro""]\n\n        arrays = tree.arrays([""three"", ""two"", ""one""], outputtype=MyTuple)\n        assert isinstance(arrays, MyTuple)\n\n    def test_tree_lazy(self):\n        tree = uproot.open(""tests/samples/sample-5.30.00-uncompressed.root"")[""sample""]\n\n        for branchname in b""u1"", b""i8"", b""Ai8"", b""f4"", b""af4"":\n            strict = tree[branchname].array()\n\n            lazy = tree[branchname].lazyarray()\n            for i in range(len(lazy)):\n                assert lazy[i].tolist() == strict[i].tolist()\n\n            lazy = tree[branchname].lazyarray()\n            for i in range(len(lazy), 0, -1):\n                assert lazy[i - 1].tolist() == strict[i - 1].tolist()\n\n            lazy = tree[branchname].lazyarray()\n            for i in range(len(lazy)):\n                assert lazy[i : i + 3].tolist() == strict[i : i + 3].tolist()\n\n            lazy = tree[branchname].lazyarray()\n            for i in range(len(lazy), 0, -1):\n                assert lazy[i - 1 : i + 3].tolist() == strict[i - 1 : i + 3].tolist()\n\n    def test_tree_lazy2(self):\n        tree = uproot.open(""tests/samples/sample-5.30.00-uncompressed.root"")[""sample""]\n        lazy = tree.lazyarrays()\n\n        for branchname in ""u1"", ""i8"", ""Ai8"", ""f4"", ""af4"":\n            strict = tree[branchname.encode()].array()\n\n            for i in range(len(lazy)):\n                assert lazy[branchname][i].tolist() == strict[i].tolist()\n\n            for i in range(len(lazy), 0, -1):\n                assert lazy[branchname][i - 1].tolist() == strict[i - 1].tolist()\n\n            for i in range(len(lazy)):\n                assert lazy[branchname][i : i + 3].tolist() == strict[i : i + 3].tolist()\n\n            for i in range(len(lazy), 0, -1):\n                assert lazy[branchname][i - 1 : i + 3].tolist() == strict[i - 1 : i + 3].tolist()\n\n    def test_tree_lazy3(self):\n        lazy = uproot.lazyarrays([""tests/samples/sample-5.29.02-uncompressed.root"", ""tests/samples/sample-5.30.00-uncompressed.root""], ""sample"")\n\n        assert lazy[""u1""].tolist() == [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n        assert lazy[""i8""].tolist() == [-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n        assert lazy[""Ai8""].tolist() == [[], [-15], [-15, -13], [-15, -13, -11], [-15, -13, -11, -9], [], [-10], [-10, -8], [-10, -8, -6], [-10, -8, -6, -4], [], [-5], [-5, -3], [-5, -3, -1], [-5, -3, -1, 1], [], [0], [0, 2], [0, 2, 4], [0, 2, 4, 6], [], [5], [5, 7], [5, 7, 9], [5, 7, 9, 11], [], [10], [10, 12], [10, 12, 14], [10, 12, 14, 16], [], [-15], [-15, -13], [-15, -13, -11], [-15, -13, -11, -9], [], [-10], [-10, -8], [-10, -8, -6], [-10, -8, -6, -4], [], [-5], [-5, -3], [-5, -3, -1], [-5, -3, -1, 1], [], [0], [0, 2], [0, 2, 4], [0, 2, 4, 6], [], [5], [5, 7], [5, 7, 9], [5, 7, 9, 11], [], [10], [10, 12], [10, 12, 14], [10, 12, 14, 16]]\n        assert lazy[""f4""].tolist() == [-14.899999618530273, -13.899999618530273, -12.899999618530273, -11.899999618530273, -10.899999618530273, -9.899999618530273, -8.899999618530273, -7.900000095367432, -6.900000095367432, -5.900000095367432, -4.900000095367432, -3.9000000953674316, -2.9000000953674316, -1.899999976158142, -0.8999999761581421, 0.10000000149011612, 1.100000023841858, 2.0999999046325684, 3.0999999046325684, 4.099999904632568, 5.099999904632568, 6.099999904632568, 7.099999904632568, 8.100000381469727, 9.100000381469727, 10.100000381469727, 11.100000381469727, 12.100000381469727, 13.100000381469727, 14.100000381469727, -14.899999618530273, -13.899999618530273, -12.899999618530273, -11.899999618530273, -10.899999618530273, -9.899999618530273, -8.899999618530273, -7.900000095367432, -6.900000095367432, -5.900000095367432, -4.900000095367432, -3.9000000953674316, -2.9000000953674316, -1.899999976158142, -0.8999999761581421, 0.10000000149011612, 1.100000023841858, 2.0999999046325684, 3.0999999046325684, 4.099999904632568, 5.099999904632568, 6.099999904632568, 7.099999904632568, 8.100000381469727, 9.100000381469727, 10.100000381469727, 11.100000381469727, 12.100000381469727, 13.100000381469727, 14.100000381469727]\n        assert lazy[""af4""].tolist() == [[-13.899999618530273, -12.899999618530273, -11.899999618530273], [-12.899999618530273, -11.899999618530273, -10.899999618530273], [-11.899999618530273, -10.899999618530273, -9.899999618530273], [-10.899999618530273, -9.899999618530273, -8.899999618530273], [-9.899999618530273, -8.899999618530273, -7.900000095367432], [-8.899999618530273, -7.900000095367432, -6.900000095367432], [-7.900000095367432, -6.900000095367432, -5.900000095367432], [-6.900000095367432, -5.900000095367432, -4.900000095367432], [-5.900000095367432, -4.900000095367432, -3.9000000953674316], [-4.900000095367432, -3.9000000953674316, -2.9000000953674316], [-3.9000000953674316, -2.9000000953674316, -1.899999976158142], [-2.9000000953674316, -1.899999976158142, -0.8999999761581421], [-1.899999976158142, -0.8999999761581421, 0.10000000149011612], [-0.8999999761581421, 0.10000000149011612, 1.100000023841858], [0.10000000149011612, 1.100000023841858, 2.0999999046325684], [1.100000023841858, 2.0999999046325684, 3.0999999046325684], [2.0999999046325684, 3.0999999046325684, 4.099999904632568], [3.0999999046325684, 4.099999904632568, 5.099999904632568], [4.099999904632568, 5.099999904632568, 6.099999904632568], [5.099999904632568, 6.099999904632568, 7.099999904632568], [6.099999904632568, 7.099999904632568, 8.100000381469727], [7.099999904632568, 8.100000381469727, 9.100000381469727], [8.100000381469727, 9.100000381469727, 10.100000381469727], [9.100000381469727, 10.100000381469727, 11.100000381469727], [10.100000381469727, 11.100000381469727, 12.100000381469727], [11.100000381469727, 12.100000381469727, 13.100000381469727], [12.100000381469727, 13.100000381469727, 14.100000381469727], [13.100000381469727, 14.100000381469727, 15.100000381469727], [14.100000381469727, 15.100000381469727, 16.100000381469727], [15.100000381469727, 16.100000381469727, 17.100000381469727], [-13.899999618530273, -12.899999618530273, -11.899999618530273], [-12.899999618530273, -11.899999618530273, -10.899999618530273], [-11.899999618530273, -10.899999618530273, -9.899999618530273], [-10.899999618530273, -9.899999618530273, -8.899999618530273], [-9.899999618530273, -8.899999618530273, -7.900000095367432], [-8.899999618530273, -7.900000095367432, -6.900000095367432], [-7.900000095367432, -6.900000095367432, -5.900000095367432], [-6.900000095367432, -5.900000095367432, -4.900000095367432], [-5.900000095367432, -4.900000095367432, -3.9000000953674316], [-4.900000095367432, -3.9000000953674316, -2.9000000953674316], [-3.9000000953674316, -2.9000000953674316, -1.899999976158142], [-2.9000000953674316, -1.899999976158142, -0.8999999761581421], [-1.899999976158142, -0.8999999761581421, 0.10000000149011612], [-0.8999999761581421, 0.10000000149011612, 1.100000023841858], [0.10000000149011612, 1.100000023841858, 2.0999999046325684], [1.100000023841858, 2.0999999046325684, 3.0999999046325684], [2.0999999046325684, 3.0999999046325684, 4.099999904632568], [3.0999999046325684, 4.099999904632568, 5.099999904632568], [4.099999904632568, 5.099999904632568, 6.099999904632568], [5.099999904632568, 6.099999904632568, 7.099999904632568], [6.099999904632568, 7.099999904632568, 8.100000381469727], [7.099999904632568, 8.100000381469727, 9.100000381469727], [8.100000381469727, 9.100000381469727, 10.100000381469727], [9.100000381469727, 10.100000381469727, 11.100000381469727], [10.100000381469727, 11.100000381469727, 12.100000381469727], [11.100000381469727, 12.100000381469727, 13.100000381469727], [12.100000381469727, 13.100000381469727, 14.100000381469727], [13.100000381469727, 14.100000381469727, 15.100000381469727], [14.100000381469727, 15.100000381469727, 16.100000381469727], [15.100000381469727, 16.100000381469727, 17.100000381469727]]\n\n    def test_tree_lazy_cached(self):\n        tree = uproot.open(""tests/samples/sample-5.30.00-uncompressed.root"")[""sample""]\n\n        cache = {}\n        keycache = {}\n        basketcache = {}\n\n        for branchname in b""u1"", b""i8"", b""Ai8"", b""f4"", b""af4"":\n            strict = tree[branchname].array()\n\n            lazy = tree[branchname].lazyarray(cache=cache, keycache=keycache, basketcache=basketcache)\n            for i in range(len(lazy)):\n                assert lazy[i].tolist() == strict[i].tolist()\n\n            lazy = tree[branchname].lazyarray(cache=cache, keycache=keycache, basketcache=basketcache)\n            for i in range(len(lazy), 0, -1):\n                assert lazy[i - 1].tolist() == strict[i - 1].tolist()\n\n            lazy = tree[branchname].lazyarray(cache=cache, keycache=keycache, basketcache=basketcache)\n            for i in range(len(lazy)):\n                assert lazy[i : i + 3].tolist() == strict[i : i + 3].tolist()\n\n            lazy = tree[branchname].lazyarray(cache=cache, keycache=keycache, basketcache=basketcache)\n            for i in range(len(lazy), 0, -1):\n                assert lazy[i - 1 : i + 3].tolist() == strict[i - 1 : i + 3].tolist()\n\n    @pytest.mark.parametrize(""use_http"", [False, True])\n    def test_hist_in_tree(self, use_http):\n        if use_http:\n            pytest.importorskip(""requests"")\n            tree = uproot.open(""http://scikit-hep.org/uproot/examples/Event.root"")[""T""]\n        else:\n            path = os.path.join(""tests"", ""samples"", ""Event.root"")\n            if not os.path.exists(path):\n                raise pytest.skip()\n            tree = uproot.open(path)[""T""]\n        check = [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n                 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0,\n                 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n                 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0,\n                 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0,\n                 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0,\n                 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n\n        assert tree.array(""fH"")[20].values.tolist() == check\n\n    @pytest.mark.parametrize(""use_http"", [False, True])\n    def test_branch_auto_interpretation(self, use_http):\n        # The aim is to reduce this list in a controlled manner\n        known_branches_without_interp = [\n            b\'event\',\n            b\'TObject\',\n            b\'fClosestDistance\',\n            b\'fEvtHdr\',\n            b\'fTracks\',\n            b\'fTracks.fPointValue\',\n            b\'fTriggerBits\',\n            b\'fTriggerBits.TObject\'\n        ]\n        if use_http:\n            pytest.importorskip(""requests"")\n            tree = uproot.open(""http://scikit-hep.org/uproot/examples/Event.root"")[""T""]\n        else:\n            path = os.path.join(""tests"", ""samples"", ""Event.root"")\n            if not os.path.exists(path):\n                raise pytest.skip()\n            tree = uproot.open(path)[""T""]\n        branches_without_interp = [b.name for b in tree.allvalues() if b.interpretation is None]\n        assert branches_without_interp == known_branches_without_interp\n        assert tree.array(""fTracks.fTArray[3]"", entrystop=10)[5][10].tolist()  == [11.03951644897461, 19.40645980834961, 34.54059982299805]\n        assert tree.array(""fTracks.fCharge"", entrystop=10)[0][0:10].tolist()   == [1.0, 1.0, 1.0, 1.0,-1.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n        assert tree.array(""fMatrix[4][4]"", entrystop=10)[0][1].tolist()        == [-0.13630907237529755, 0.8007842898368835, 1.706235647201538, 0.0]\n        assert tree.array(""fTracks.fMass2"", entrystop=10)[3][330:333].tolist() == [8.90625, 8.90625, 8.90625]\n        assert tree.array(""fTracks.fBx"", entrystop=10)[9][10:13].tolist()      == [0.12298583984375, -0.2489013671875, -0.189697265625]\n        assert tree.array(""fTracks.fBy"", entrystop=10)[9][10:13].tolist()      == [0.1998291015625, -0.0301513671875, 0.0736083984375]\n        assert tree.array(""fTracks.fXfirst"", entrystop=10)[1][11:16].tolist()  == [-8.650390625, -2.8203125, -1.949951171875, 0.4859619140625, 3.0146484375]\n        assert tree.array(""fTracks.fXlast"", entrystop=10)[1][11:16].tolist()   == [-2.18994140625, -2.64697265625, -8.4375, 1.594970703125, 6.40234375]\n        assert tree.array(""fTracks.fYfirst"", entrystop=10)[2][22:26].tolist()  == [4.9921875, 8.46875, 1.679443359375, -6.927734375]\n        assert tree.array(""fTracks.fYlast"", entrystop=10)[2][22:26].tolist()   == [-5.76171875, 13.7109375, 2.98583984375, -9.466796875]\n        assert tree.array(""fTracks.fZfirst"", entrystop=10)[3][33:36].tolist()  == [53.84375, 52.3125, 48.296875]\n        assert tree.array(""fTracks.fZlast"", entrystop=10)[3][33:36].tolist()   == [193.96875, 208.25, 228.40625]\n        assert tree.array(""fTracks.fVertex[3]"", entrystop=10)[1][2].tolist()   == [0.245361328125, 0.029296875,-16.171875]\n\n    def test_leaflist(self):\n        tree = uproot.open(""tests/samples/leaflist.root"")[""tree""]\n        a = tree.array(""leaflist"")\n        assert a[""x""].tolist() == [1.1, 2.2, 3.3, 4.0, 5.5]   # yeah, I goofed up when making it\n        assert a[""y""].tolist() == [1, 2, 3, 4, 5]\n        assert a[""z""].tolist() == [ord(""a""), ord(""b""), ord(""c""), ord(""d""), ord(""e"")]\n\n        pytest.importorskip(""pandas"")\n        assert tree.pandas.df()[""leaflist.x""].tolist() == [1.1, 2.2, 3.3, 4.0, 5.5]\n\n        tree = uproot.open(""tests/samples/HZZ-objects.root"")[""events""]\n        tree.pandas.df(""muonp4"")\n        tree.pandas.df(""muonp4"", flatten=False)\n        df = tree.pandas.df(""eventweight"", entrystart=100, entrystop=200)\n        index = df.index.tolist()\n        assert min(index) == 100\n        assert max(index) == 199\n        df = tree.pandas.df(""muonp4"", entrystart=100, entrystop=200)\n        index = df.index.get_level_values(""entry"").tolist()\n        assert min(index) == 100\n        assert max(index) == 199\n\n    def test_mempartitions(self):\n        t = uproot.open(""tests/samples/sample-5.23.02-zlib.root"")[""sample""]\n        assert list(t.mempartitions(500)) == [(0, 2), (2, 4), (4, 6), (6, 8), (8, 10), (10, 12), (12, 14), (14, 16), (16, 18), (18, 20), (20, 22), (22, 24), (24, 26), (26, 28), (28, 30)]\n        assert [sum(y.nbytes for y in x.values()) for x in t.iterate(entrysteps=""0.5 kB"")] == [693, 865, 822, 779, 951, 695, 867, 824, 781, 953, 695, 867, 824, 781, 953]\n'"
tests/test_versions.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nimport pytest\ntry:\n    import lzma\nexcept ImportError:\n    lzma = pytest.importorskip(\'backports.lzma\')\nlz4 = pytest.importorskip(\'lz4\')\n\nimport uproot\n\n\nclass Test(object):\n    sample = {\n        b""n"": [0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4],\n\n        b""b"": [True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False, True, False],\n        b""ab"": [[False, True, False], [True, False, True], [False, True, False], [True, False, True], [False, True, False], [True, False, True], [False, True, False], [True, False, True], [False, True, False], [True, False, True], [False, True, False], [True, False, True], [False, True, False], [True, False, True], [False, True, False], [True, False, True], [False, True, False], [True, False, True], [False, True, False], [True, False, True], [False, True, False], [True, False, True], [False, True, False], [True, False, True], [False, True, False], [True, False, True], [False, True, False], [True, False, True], [False, True, False], [True, False, True]],\n        b""Ab"": [[], [True], [True, True], [True, True, True], [True, True, True, True], [], [False], [False, False], [False, False, False], [False, False, False, False], [], [True], [True, True], [True, True, True], [True, True, True, True], [], [False], [False, False], [False, False, False], [False, False, False, False], [], [True], [True, True], [True, True, True], [True, True, True, True], [], [False], [False, False], [False, False, False], [False, False, False, False]],\n\n        b""i1"": [-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n        b""ai1"": [[-14, -13, -12], [-13, -12, -11], [-12, -11, -10], [-11, -10, -9], [-10, -9, -8], [-9, -8, -7], [-8, -7, -6], [-7, -6, -5], [-6, -5, -4], [-5, -4, -3], [-4, -3, -2], [-3, -2, -1], [-2, -1, 0], [-1, 0, 1], [0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11], [10, 11, 12], [11, 12, 13], [12, 13, 14], [13, 14, 15], [14, 15, 16], [15, 16, 17]],\n        b""Ai1"": [[], [-15], [-15, -13], [-15, -13, -11], [-15, -13, -11, -9], [], [-10], [-10, -8], [-10, -8, -6], [-10, -8, -6, -4], [], [-5], [-5, -3], [-5, -3, -1], [-5, -3, -1, 1], [], [0], [0, 2], [0, 2, 4], [0, 2, 4, 6], [], [5], [5, 7], [5, 7, 9], [5, 7, 9, 11], [], [10], [10, 12], [10, 12, 14], [10, 12, 14, 16]],\n\n        b""u1"": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        b""au1"": [[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11], [10, 11, 12], [11, 12, 13], [12, 13, 14], [13, 14, 15], [14, 15, 16], [15, 16, 17], [16, 17, 18], [17, 18, 19], [18, 19, 20], [19, 20, 21], [20, 21, 22], [21, 22, 23], [22, 23, 24], [23, 24, 25], [24, 25, 26], [25, 26, 27], [26, 27, 28], [27, 28, 29], [28, 29, 30], [29, 30, 31], [30, 31, 32]],\n        b""Au1"": [[], [0], [0, 2], [0, 2, 4], [0, 2, 4, 6], [], [5], [5, 7], [5, 7, 9], [5, 7, 9, 11], [], [10], [10, 12], [10, 12, 14], [10, 12, 14, 16], [], [15], [15, 17], [15, 17, 19], [15, 17, 19, 21], [], [20], [20, 22], [20, 22, 24], [20, 22, 24, 26], [], [25], [25, 27], [25, 27, 29], [25, 27, 29, 31]],\n\n        b""i2"": [-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n        b""ai2"": [[-14, -13, -12], [-13, -12, -11], [-12, -11, -10], [-11, -10, -9], [-10, -9, -8], [-9, -8, -7], [-8, -7, -6], [-7, -6, -5], [-6, -5, -4], [-5, -4, -3], [-4, -3, -2], [-3, -2, -1], [-2, -1, 0], [-1, 0, 1], [0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11], [10, 11, 12], [11, 12, 13], [12, 13, 14], [13, 14, 15], [14, 15, 16], [15, 16, 17]],\n        b""Ai2"": [[], [-15], [-15, -13], [-15, -13, -11], [-15, -13, -11, -9], [], [-10], [-10, -8], [-10, -8, -6], [-10, -8, -6, -4], [], [-5], [-5, -3], [-5, -3, -1], [-5, -3, -1, 1], [], [0], [0, 2], [0, 2, 4], [0, 2, 4, 6], [], [5], [5, 7], [5, 7, 9], [5, 7, 9, 11], [], [10], [10, 12], [10, 12, 14], [10, 12, 14, 16]],\n\n        b""u2"": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        b""au2"": [[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11], [10, 11, 12], [11, 12, 13], [12, 13, 14], [13, 14, 15], [14, 15, 16], [15, 16, 17], [16, 17, 18], [17, 18, 19], [18, 19, 20], [19, 20, 21], [20, 21, 22], [21, 22, 23], [22, 23, 24], [23, 24, 25], [24, 25, 26], [25, 26, 27], [26, 27, 28], [27, 28, 29], [28, 29, 30], [29, 30, 31], [30, 31, 32]],\n        b""Au2"": [[], [0], [0, 2], [0, 2, 4], [0, 2, 4, 6], [], [5], [5, 7], [5, 7, 9], [5, 7, 9, 11], [], [10], [10, 12], [10, 12, 14], [10, 12, 14, 16], [], [15], [15, 17], [15, 17, 19], [15, 17, 19, 21], [], [20], [20, 22], [20, 22, 24], [20, 22, 24, 26], [], [25], [25, 27], [25, 27, 29], [25, 27, 29, 31]],\n\n        b""i4"": [-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n        b""ai4"": [[-14, -13, -12], [-13, -12, -11], [-12, -11, -10], [-11, -10, -9], [-10, -9, -8], [-9, -8, -7], [-8, -7, -6], [-7, -6, -5], [-6, -5, -4], [-5, -4, -3], [-4, -3, -2], [-3, -2, -1], [-2, -1, 0], [-1, 0, 1], [0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11], [10, 11, 12], [11, 12, 13], [12, 13, 14], [13, 14, 15], [14, 15, 16], [15, 16, 17]],\n        b""Ai4"": [[], [-15], [-15, -13], [-15, -13, -11], [-15, -13, -11, -9], [], [-10], [-10, -8], [-10, -8, -6], [-10, -8, -6, -4], [], [-5], [-5, -3], [-5, -3, -1], [-5, -3, -1, 1], [], [0], [0, 2], [0, 2, 4], [0, 2, 4, 6], [], [5], [5, 7], [5, 7, 9], [5, 7, 9, 11], [], [10], [10, 12], [10, 12, 14], [10, 12, 14, 16]],\n\n        b""u4"": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        b""au4"": [[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11], [10, 11, 12], [11, 12, 13], [12, 13, 14], [13, 14, 15], [14, 15, 16], [15, 16, 17], [16, 17, 18], [17, 18, 19], [18, 19, 20], [19, 20, 21], [20, 21, 22], [21, 22, 23], [22, 23, 24], [23, 24, 25], [24, 25, 26], [25, 26, 27], [26, 27, 28], [27, 28, 29], [28, 29, 30], [29, 30, 31], [30, 31, 32]],\n        b""Au4"": [[], [0], [0, 2], [0, 2, 4], [0, 2, 4, 6], [], [5], [5, 7], [5, 7, 9], [5, 7, 9, 11], [], [10], [10, 12], [10, 12, 14], [10, 12, 14, 16], [], [15], [15, 17], [15, 17, 19], [15, 17, 19, 21], [], [20], [20, 22], [20, 22, 24], [20, 22, 24, 26], [], [25], [25, 27], [25, 27, 29], [25, 27, 29, 31]],\n\n        b""i8"": [-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n        b""ai8"": [[-14, -13, -12], [-13, -12, -11], [-12, -11, -10], [-11, -10, -9], [-10, -9, -8], [-9, -8, -7], [-8, -7, -6], [-7, -6, -5], [-6, -5, -4], [-5, -4, -3], [-4, -3, -2], [-3, -2, -1], [-2, -1, 0], [-1, 0, 1], [0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11], [10, 11, 12], [11, 12, 13], [12, 13, 14], [13, 14, 15], [14, 15, 16], [15, 16, 17]],\n        b""Ai8"": [[], [-15], [-15, -13], [-15, -13, -11], [-15, -13, -11, -9], [], [-10], [-10, -8], [-10, -8, -6], [-10, -8, -6, -4], [], [-5], [-5, -3], [-5, -3, -1], [-5, -3, -1, 1], [], [0], [0, 2], [0, 2, 4], [0, 2, 4, 6], [], [5], [5, 7], [5, 7, 9], [5, 7, 9, 11], [], [10], [10, 12], [10, 12, 14], [10, 12, 14, 16]],\n\n        b""u8"": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        b""au8"": [[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11], [10, 11, 12], [11, 12, 13], [12, 13, 14], [13, 14, 15], [14, 15, 16], [15, 16, 17], [16, 17, 18], [17, 18, 19], [18, 19, 20], [19, 20, 21], [20, 21, 22], [21, 22, 23], [22, 23, 24], [23, 24, 25], [24, 25, 26], [25, 26, 27], [26, 27, 28], [27, 28, 29], [28, 29, 30], [29, 30, 31], [30, 31, 32]],\n        b""Au8"": [[], [0], [0, 2], [0, 2, 4], [0, 2, 4, 6], [], [5], [5, 7], [5, 7, 9], [5, 7, 9, 11], [], [10], [10, 12], [10, 12, 14], [10, 12, 14, 16], [], [15], [15, 17], [15, 17, 19], [15, 17, 19, 21], [], [20], [20, 22], [20, 22, 24], [20, 22, 24, 26], [], [25], [25, 27], [25, 27, 29], [25, 27, 29, 31]],\n\n        b""f4"": [-14.899999618530273, -13.899999618530273, -12.899999618530273, -11.899999618530273, -10.899999618530273, -9.899999618530273, -8.899999618530273, -7.900000095367432, -6.900000095367432, -5.900000095367432, -4.900000095367432, -3.9000000953674316, -2.9000000953674316, -1.899999976158142, -0.8999999761581421, 0.10000000149011612, 1.100000023841858, 2.0999999046325684, 3.0999999046325684, 4.099999904632568, 5.099999904632568, 6.099999904632568, 7.099999904632568, 8.100000381469727, 9.100000381469727, 10.100000381469727, 11.100000381469727, 12.100000381469727, 13.100000381469727, 14.100000381469727],\n        b""af4"": [[-13.899999618530273, -12.899999618530273, -11.899999618530273], [-12.899999618530273, -11.899999618530273, -10.899999618530273], [-11.899999618530273, -10.899999618530273, -9.899999618530273], [-10.899999618530273, -9.899999618530273, -8.899999618530273], [-9.899999618530273, -8.899999618530273, -7.900000095367432], [-8.899999618530273, -7.900000095367432, -6.900000095367432], [-7.900000095367432, -6.900000095367432, -5.900000095367432], [-6.900000095367432, -5.900000095367432, -4.900000095367432], [-5.900000095367432, -4.900000095367432, -3.9000000953674316], [-4.900000095367432, -3.9000000953674316, -2.9000000953674316], [-3.9000000953674316, -2.9000000953674316, -1.899999976158142], [-2.9000000953674316, -1.899999976158142, -0.8999999761581421], [-1.899999976158142, -0.8999999761581421, 0.10000000149011612], [-0.8999999761581421, 0.10000000149011612, 1.100000023841858], [0.10000000149011612, 1.100000023841858, 2.0999999046325684], [1.100000023841858, 2.0999999046325684, 3.0999999046325684], [2.0999999046325684, 3.0999999046325684, 4.099999904632568], [3.0999999046325684, 4.099999904632568, 5.099999904632568], [4.099999904632568, 5.099999904632568, 6.099999904632568], [5.099999904632568, 6.099999904632568, 7.099999904632568], [6.099999904632568, 7.099999904632568, 8.100000381469727], [7.099999904632568, 8.100000381469727, 9.100000381469727], [8.100000381469727, 9.100000381469727, 10.100000381469727], [9.100000381469727, 10.100000381469727, 11.100000381469727], [10.100000381469727, 11.100000381469727, 12.100000381469727], [11.100000381469727, 12.100000381469727, 13.100000381469727], [12.100000381469727, 13.100000381469727, 14.100000381469727], [13.100000381469727, 14.100000381469727, 15.100000381469727], [14.100000381469727, 15.100000381469727, 16.100000381469727], [15.100000381469727, 16.100000381469727, 17.100000381469727]],\n        b""Af4"": [[], [-15.0], [-15.0, -13.899999618530273], [-15.0, -13.899999618530273, -12.800000190734863], [-15.0, -13.899999618530273, -12.800000190734863, -11.699999809265137], [], [-10.0], [-10.0, -8.899999618530273], [-10.0, -8.899999618530273, -7.800000190734863], [-10.0, -8.899999618530273, -7.800000190734863, -6.699999809265137], [], [-5.0], [-5.0, -3.9000000953674316], [-5.0, -3.9000000953674316, -2.799999952316284], [-5.0, -3.9000000953674316, -2.799999952316284, -1.7000000476837158], [], [0.0], [0.0, 1.100000023841858], [0.0, 1.100000023841858, 2.200000047683716], [0.0, 1.100000023841858, 2.200000047683716, 3.299999952316284], [], [5.0], [5.0, 6.099999904632568], [5.0, 6.099999904632568, 7.199999809265137], [5.0, 6.099999904632568, 7.199999809265137, 8.300000190734863], [], [10.0], [10.0, 11.100000381469727], [10.0, 11.100000381469727, 12.199999809265137], [10.0, 11.100000381469727, 12.199999809265137, 13.300000190734863]],\n\n        b""f8"": [-14.9, -13.9, -12.9, -11.9, -10.9, -9.9, -8.9, -7.9, -6.9, -5.9, -4.9, -3.9000000000000004, -2.9000000000000004, -1.9000000000000004, -0.9000000000000004, 0.09999999999999964, 1.0999999999999996, 2.0999999999999996, 3.0999999999999996, 4.1, 5.1, 6.1, 7.1, 8.1, 9.1, 10.1, 11.1, 12.1, 13.1, 14.1],\n        b""af8"": [[-13.9, -12.9, -11.9], [-12.9, -11.9, -10.9], [-11.9, -10.9, -9.9], [-10.9, -9.9, -8.9], [-9.9, -8.9, -7.9], [-8.9, -7.9, -6.9], [-7.9, -6.9, -5.9], [-6.9, -5.9, -4.9], [-5.9, -4.9, -3.9000000000000004], [-4.9, -3.9000000000000004, -2.9000000000000004], [-3.9000000000000004, -2.9000000000000004, -1.9000000000000004], [-2.9000000000000004, -1.9000000000000004, -0.9000000000000004], [-1.9000000000000004, -0.9000000000000004, 0.09999999999999964], [-0.9000000000000004, 0.09999999999999964, 1.0999999999999996], [0.09999999999999964, 1.0999999999999996, 2.0999999999999996], [1.0999999999999996, 2.0999999999999996, 3.0999999999999996], [2.0999999999999996, 3.0999999999999996, 4.1], [3.0999999999999996, 4.1, 5.1], [4.1, 5.1, 6.1], [5.1, 6.1, 7.1], [6.1, 7.1, 8.1], [7.1, 8.1, 9.1], [8.1, 9.1, 10.1], [9.1, 10.1, 11.1], [10.1, 11.1, 12.1], [11.1, 12.1, 13.1], [12.1, 13.1, 14.1], [13.1, 14.1, 15.1], [14.1, 15.1, 16.1], [15.1, 16.1, 17.1]],\n        b""Af8"": [[], [-15.0], [-15.0, -13.9], [-15.0, -13.9, -12.8], [-15.0, -13.9, -12.8, -11.7], [], [-10.0], [-10.0, -8.9], [-10.0, -8.9, -7.8], [-10.0, -8.9, -7.8, -6.7], [], [-5.0], [-5.0, -3.9], [-5.0, -3.9, -2.8], [-5.0, -3.9, -2.8, -1.7], [], [0.0], [0.0, 1.1], [0.0, 1.1, 2.2], [0.0, 1.1, 2.2, 3.3], [], [5.0], [5.0, 6.1], [5.0, 6.1, 7.2], [5.0, 6.1, 7.2, 8.3], [], [10.0], [10.0, 11.1], [10.0, 11.1, 12.2], [10.0, 11.1, 12.2, 13.3]],\n\n        b""str"": [b""hey-0"", b""hey-1"", b""hey-2"", b""hey-3"", b""hey-4"", b""hey-5"", b""hey-6"", b""hey-7"", b""hey-8"", b""hey-9"", b""hey-10"", b""hey-11"", b""hey-12"", b""hey-13"", b""hey-14"", b""hey-15"", b""hey-16"", b""hey-17"", b""hey-18"", b""hey-19"", b""hey-20"", b""hey-21"", b""hey-22"", b""hey-23"", b""hey-24"", b""hey-25"", b""hey-26"", b""hey-27"", b""hey-28"", b""hey-29""]\n        }\n\n    def compare(self, arrays):\n        assert set(arrays.keys()) == set(self.sample.keys())\n        for name in arrays.keys():\n            assert arrays[name].tolist() == self.sample[name]\n\n    def test_5_23_02(self):\n        # 2009-02-26, TTree version 16\n        for compression in ""uncompressed"", ""zlib"":\n            self.compare(uproot.open(""tests/samples/sample-5.23.02-{0}.root"".format(compression))[""sample""].arrays())\n\n    def test_5_24_00(self):\n        # 2009-06-30, TTree version 16\n        for compression in ""uncompressed"", ""zlib"":\n            self.compare(uproot.open(""tests/samples/sample-5.24.00-{0}.root"".format(compression))[""sample""].arrays())\n\n    def test_5_25_02(self):\n        # 2009-10-01, TTree version 17\n        for compression in ""uncompressed"", ""zlib"":\n            self.compare(uproot.open(""tests/samples/sample-5.25.02-{0}.root"".format(compression))[""sample""].arrays())\n\n    def test_5_26_00(self):\n        # 2009-12-14, TTree version 18\n        for compression in ""uncompressed"", ""zlib"":\n            self.compare(uproot.open(""tests/samples/sample-5.26.00-{0}.root"".format(compression))[""sample""].arrays())\n\n    def test_5_27_02(self):\n        # 2010-04-27, TTree version 18\n        for compression in ""uncompressed"", ""zlib"":\n            self.compare(uproot.open(""tests/samples/sample-5.27.02-{0}.root"".format(compression))[""sample""].arrays())\n\n    def test_5_28_00(self):\n        # 2010-12-15, TTree version 18\n        for compression in ""uncompressed"", ""zlib"":\n            self.compare(uproot.open(""tests/samples/sample-5.28.00-{0}.root"".format(compression))[""sample""].arrays())\n\n    def test_5_29_02(self):\n        # 2011-04-21, TTree version 18\n        for compression in ""uncompressed"", ""zlib"":\n            self.compare(uproot.open(""tests/samples/sample-5.29.02-{0}.root"".format(compression))[""sample""].arrays())\n\n    def test_5_30_00(self):\n        # 2011-06-28, TTree version 19\n        for compression in ""uncompressed"", ""zlib"", ""lzma"":\n            self.compare(uproot.open(""tests/samples/sample-5.30.00-{0}.root"".format(compression))[""sample""].arrays())\n\n    def test_6_08_04(self):\n        # 2017-01-13, TTree version 19\n        for compression in ""uncompressed"", ""zlib"", ""lzma"":\n            self.compare(uproot.open(""tests/samples/sample-6.08.04-{0}.root"".format(compression))[""sample""].arrays())\n\n    def test_6_10_05(self):\n        # 2017-07-28, TTree version 19\n        for compression in ""uncompressed"", ""zlib"", ""lzma"", ""lz4"":\n            self.compare(uproot.open(""tests/samples/sample-6.10.05-{0}.root"".format(compression))[""sample""].arrays())\n\n    def test_6_14_00(self):\n        # 2018-06-20, TTree version 20\n        for compression in ""uncompressed"", ""zlib"", ""lzma"", ""lz4"":\n            self.compare(uproot.open(""tests/samples/sample-6.14.00-{0}.root"".format(compression))[""sample""].arrays())\n\n    def test_6_16_00(self):\n        for compression in ""uncompressed"", ""zlib"", ""lzma"", ""lz4"":\n            self.compare(uproot.open(""tests/samples/sample-6.16.00-{0}.root"".format(compression))[""sample""].arrays())\n\n    def test_6_18_00(self):\n        for compression in ""uncompressed"", ""zlib"", ""lzma"", ""lz4"":\n            self.compare(uproot.open(""tests/samples/sample-6.18.00-{0}.root"".format(compression))[""sample""].arrays())\n\n    def test_6_20_04(self):\n        for compression in ""uncompressed"", ""zlib"", ""lzma"", ""lz4"":\n            self.compare(uproot.open(""tests/samples/sample-6.20.04-{0}.root"".format(compression))[""sample""].arrays())\n'"
tests/test_write.py,12,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom os.path import join\n\nimport pytest\nimport numpy\nimport ctypes\n\nimport awkward\n\nimport uproot\nfrom uproot.write.objects.TTree import newtree, newbranch\n\nROOT = pytest.importorskip(""ROOT"")\n\ndef test_strings(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""hello""] = ""world""\n\n    f = ROOT.TFile.Open(filename)\n    assert str(f.Get(""hello"")) == ""world""\n    f.Close()\n\ndef test_cycle(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""hello""] = ""world""\n        f[""hello""] = ""uproot""\n\n    f = ROOT.TFile.Open(filename)\n    assert str(f.Get(""hello;1"")) == ""world""\n    assert str(f.Get(""hello;2"")) == ""uproot""\n    f.Close()\n\ndef test_zlib(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, compression=uproot.ZLIB(1)) as f:\n        f[""hello""] = ""a""*2000\n\n    f = ROOT.TFile.Open(filename)\n    assert f.GetCompressionAlgorithm() == uproot.const.kZLIB\n    assert f.GetCompressionLevel() == 1\n    assert str(f.Get(""hello"")) == ""a""*2000\n    f.Close()\n\ndef test_compresschange(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, compression=uproot.ZLIB(2)) as f:\n        f.compression = uproot.ZLIB(3)\n        f[""hello""] = ""a""*2000\n\n    f = ROOT.TFile.Open(filename)\n    assert f.GetCompressionAlgorithm() == uproot.const.kZLIB\n    assert f.GetCompressionLevel() == 3\n\ndef test_nocompress(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""hello""] = ""a""*2000\n\n    f = ROOT.TFile.Open(filename)\n    assert f.GetCompressionFactor() == 1\n    assert str(f.Get(""hello"")) == ""a""*2000\n    f.Close()\n\ndef test_compress_small_data(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, compression=uproot.ZLIB(4)) as f:\n        f[""hello""] = ""a""\n\n    f = ROOT.TFile.Open(filename)\n    assert str(f.Get(""hello"")) == ""a""\n    f.Close()\n\ndef test_lzma(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, compression=uproot.LZMA(1)) as f:\n        f[""hello""] = ""a""*2000\n\n    f = ROOT.TFile.Open(filename)\n    assert f.GetCompressionAlgorithm() == uproot.const.kLZMA\n    assert f.GetCompressionLevel() == 1\n    assert str(f.Get(""hello"")) == ""a""*2000\n    f.Close()\n\ndef test_lz4_leveldown(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, compression=uproot.LZ4(5)) as f:\n        f[""hello""] = ""a""*2000\n\n    f = ROOT.TFile.Open(filename)\n    assert (f.GetCompressionAlgorithm()) == uproot.const.kLZ4\n    assert str(f.Get(""hello"")) == ""a""*2000\n    f.Close()\n\ndef test_lz4_levelup(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, compression=uproot.LZ4(5)) as f:\n        f[""hello""] = ""a""*2000\n\n    f = ROOT.TFile.Open(filename)\n    assert (f.GetCompressionAlgorithm()) == uproot.const.kLZ4\n    assert (f.GetCompressionLevel()) == 5\n    assert str(f.Get(""hello"")) == ""a""*2000\n    f.Close()\n\ndef test_th1(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH1F(""hvar"", ""title"", 5, 1, 10)\n    h.Sumw2()\n    h.Fill(1.0, 3)\n    h.Fill(2.0, 4)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    sums = [0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    bincontents = [7.0, 0.0, 0.0, 0.0, 0.0]\n    assert list(h.GetSumw2()) == sums\n    count = 0\n    for x in range(1, 6):\n        assert h.GetBinContent(x) == bincontents[count]\n        count += 1\n    assert h.GetNbinsX() == 5\n    assert h.GetMean() == 1.5714285714285714\n    assert h.GetRMS() == 0.4948716593053938\n\ndef test_th1_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH1F(""hvar"", ""title"", 5, 1, 10)\n    h.Sumw2()\n    h.Fill(1.0, 3)\n    h.Fill(2.0, 4)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    assert ""TH1"" in uproot.open(filename)[""test""]._classname.decode(""utf-8"")\n\ndef test_th1_varbin(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    import numpy as np\n    bins = np.array([1.0, 3.0, 4.0, 10.0, 11.0, 12.0], dtype=""float64"")\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH1F(""hvar"", ""title"", 5, bins)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    assert h.GetNbinsX() == 5\n    assert h.GetBinWidth(1) == 2.0\n    assert h.GetBinWidth(2) == 1.0\n    assert h.GetBinWidth(3) == 6.0\n    assert h.GetBinWidth(4) == 1.0\n    assert h.GetBinWidth(5) == 1.0\n\ndef test_compressed_th1(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    import numpy as np\n    bins = np.array([1.0, 3.0, 4.0, 10.0, 11.0, 12.0], dtype=""float64"")\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH1F(""hvar"", ""title"", 5, bins)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=uproot.ZLIB(1)) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    assert h.GetNbinsX() == 5\n    assert h.GetBinWidth(1) == 2.0\n    assert h.GetBinWidth(2) == 1.0\n    assert h.GetBinWidth(3) == 6.0\n    assert h.GetBinWidth(4) == 1.0\n    assert h.GetBinWidth(5) == 1.0\n\ndef test_th2(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH2F(""hvar"", ""title"", 5, 1, 10, 6, 1, 20)\n    h.Sumw2()\n    h.Fill(1.0, 5.0, 3)\n    h.Fill(2.0, 10.0, 4)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    sums = [0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 9.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 16.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0]\n    bincontents = [0.0, 3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    count = 0\n    for x in range(1, 6):\n        for y in range(1, 7):\n            assert h.GetBinContent(x, y) == bincontents[count]\n            count += 1\n    assert list(h.GetSumw2()) == sums\n    assert h.GetMean() == 1.5714285714285714\n    assert h.GetRMS() == 0.4948716593053938\n    assert h.GetNbinsX() == 5\n    assert h.GetNbinsY() == 6\n\ndef test_th2_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH2F(""hvar"", ""title"", 5, 1, 10, 6, 1, 20)\n    h.Sumw2()\n    h.Fill(1.0, 5.0, 3)\n    h.Fill(2.0, 10.0, 4)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    assert ""TH2"" in uproot.open(filename)[""test""]._classname.decode(""utf-8"")\n\ndef test_th2_varbin(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    import numpy as np\n    binsx = np.array([1.0, 3.0, 4.0, 10.0, 11.0, 12.0], dtype=""float64"")\n    binsy = np.array([1.0, 3.0, 4.0, 10.0, 11.0, 12.0, 20.0], dtype=""float64"")\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH2F(""hvar"", ""title"", 5, binsx, 6, binsy)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    assert h.GetNbinsX() == 5\n    assert h.GetNbinsY() == 6\n\ndef test_compressed_th2(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    import numpy as np\n    binsx = np.array([1.0, 3.0, 4.0, 10.0, 11.0, 12.0], dtype=""float64"")\n    binsy = np.array([1.0, 3.0, 4.0, 10.0, 11.0, 12.0, 20.0], dtype=""float64"")\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH2F(""hvar"", ""title"", 5, binsx, 6, binsy)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=uproot.ZLIB(1)) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    assert h.GetNbinsX() == 5\n    assert h.GetNbinsY() == 6\n\ndef test_th3(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH3F(""hvar"", ""title"", 5, 1, 10, 6, 1, 20, 7, 1, 30)\n    h.Sumw2()\n    h.Fill(1.0, 5.0, 8.0, 3)\n    h.Fill(2.0, 10.0, 9.0, 4)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    sums = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    bincontents = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    assert h.GetNbinsX() == 5\n    assert h.GetNbinsY() == 6\n    assert h.GetNbinsZ() == 7\n    assert list(h.GetSumw2()) == sums\n    assert h.GetMean() == 1.5714285714285714\n    assert h.GetRMS() == 0.4948716593053938\n    count = 0\n    for x in range(1, 6):\n        for y in range(1, 7):\n            for z in range(1, 8):\n                assert h.GetBinContent(x, y, z) == bincontents[count]\n                count += 1\n\ndef test_th3_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH3F(""hvar"", ""title"", 5, 1, 10, 6, 1, 20, 7, 1, 30)\n    h.Sumw2()\n    h.Fill(1.0, 5.0, 8.0, 3)\n    h.Fill(2.0, 10.0, 9.0, 4)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    assert ""TH3"" in uproot.open(filename)[""test""]._classname.decode(""utf-8"")\n\ndef test_th3_varbin(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    import numpy as np\n    binsx = np.array([1.0, 3.0, 4.0, 10.0, 11.0, 12.0], dtype=""float64"")\n    binsy = np.array([1.0, 3.0, 4.0, 10.0, 11.0, 12.0, 20.0], dtype=""float64"")\n    binsz = np.array([1.0, 10.0, 13.0, 14.0, 16.0, 20.0, 21.0, 23.0], dtype=""float64"")\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH3F(""hvar"", ""title"", 5, binsx, 6, binsy, 7, binsz)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    assert h.GetNbinsX() == 5\n    assert h.GetNbinsY() == 6\n    assert h.GetNbinsZ() == 7\n\ndef test_compressed_th3(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    import numpy as np\n    binsx = np.array([1.0, 3.0, 4.0, 10.0, 11.0, 12.0], dtype=""float64"")\n    binsy = np.array([1.0, 3.0, 4.0, 10.0, 11.0, 12.0, 20.0], dtype=""float64"")\n    binsz = np.array([1.0, 10.0, 13.0, 14.0, 16.0, 20.0, 21.0, 23.0], dtype=""float64"")\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH3F(""hvar"", ""title"", 5, binsx, 6, binsy, 7, binsz)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=uproot.ZLIB(1)) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    assert h.GetNbinsX() == 5\n    assert h.GetNbinsY() == 6\n    assert h.GetNbinsZ() == 7\n\ndef test_tprofile(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TProfile(""hvar"", ""title"", 5, 1, 10)\n    h.Sumw2()\n    h.Fill(1.0, 3)\n    h.Fill(2.0, 4)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    sums = [0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    bincontents = [3.5, 0.0, 0.0, 0.0, 0.0]\n    assert list(h.GetSumw2()) == sums\n    assert h.GetMean() == 1.5\n    assert h.GetRMS() == 0.5\n    count = 0\n    for x in range(1, 6):\n        assert h.GetBinContent(x) == bincontents[count]\n        count += 1\n\ndef test_tprofile_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TProfile(""hvar"", ""title"", 5, 1, 10)\n    h.Sumw2()\n    h.Fill(1.0, 3)\n    h.Fill(2.0, 4)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    assert uproot.open(filename)[""test""]._classname == b""TProfile""\n\ndef test_compressed_tprofile(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TProfile(""hvar"", ""title"", 5, 1, 10)\n    h.Sumw2()\n    h.Fill(1.0, 3)\n    h.Fill(2.0, 4)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=uproot.LZMA(5)) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    sums = [0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    bincontents = [3.5, 0.0, 0.0, 0.0, 0.0]\n    assert list(h.GetSumw2()) == sums\n    assert h.GetMean() == 1.5\n    assert h.GetRMS() == 0.5\n    count = 0\n    for x in range(1, 6):\n        assert h.GetBinContent(x) == bincontents[count]\n        count += 1\n\ndef test_tprofile2d(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TProfile2D(""hvar"", ""title"", 5, 1, 10, 6, 1, 20)\n    h.Sumw2()\n    h.Fill(1.0, 5.0, 3)\n    h.Fill(2.0, 10.0, 4)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    sums = [0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 9.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 16.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0]\n    bincontents = [0.0, 3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    count = 0\n    for x in range(1, 6):\n        for y in range(1, 7):\n            assert h.GetBinContent(x, y) == bincontents[count]\n            count += 1\n    assert list(h.GetSumw2()) == sums\n    assert h.GetMean() == 1.5\n    assert h.GetRMS() == 0.5\n    assert h.GetNbinsX() == 5\n    assert h.GetNbinsY() == 6\n\ndef test_tprofile2d_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TProfile2D(""hvar"", ""title"", 5, 1, 10, 6, 1, 20)\n    h.Sumw2()\n    h.Fill(1.0, 5.0, 3)\n    h.Fill(2.0, 10.0, 4)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    assert uproot.open(filename)[""test""]._classname == b""TProfile2D""\n\ndef test_compressed_tprofile2d(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TProfile2D(""hvar"", ""title"", 5, 1, 10, 6, 1, 20)\n    h.Sumw2()\n    h.Fill(1.0, 5.0, 3)\n    h.Fill(2.0, 10.0, 4)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=uproot.LZMA(5)) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    sums = [0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 9.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 16.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0 , 0.0]\n    bincontents = [0.0, 3.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    count = 0\n    for x in range(1, 6):\n        for y in range(1, 7):\n            assert h.GetBinContent(x, y) == bincontents[count]\n            count += 1\n    assert list(h.GetSumw2()) == sums\n    assert h.GetMean() == 1.5\n    assert h.GetRMS() == 0.5\n    assert h.GetNbinsX() == 5\n    assert h.GetNbinsY() == 6\n\ndef test_tprofile3d(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TProfile3D(""hvar"", ""title"", 5, 1, 10, 6, 1, 20, 8, 2, 8)\n    h.Sumw2()\n    h.Fill(1.0, 5.0, 3, 6)\n    h.Fill(2.0, 10.0, 4, 7)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    sums = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    bincontents = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    count = 0\n    for x in range(1, 6):\n        for y in range(1, 7):\n            for z in range(1, 9):\n                assert h.GetBinContent(x, y, z) == bincontents[count]\n                count += 1\n    assert list(h.GetSumw2()) == sums\n    assert h.GetMean() == 1.5\n    assert h.GetRMS() == 0.5\n    assert h.GetNbinsX() == 5\n    assert h.GetNbinsY() == 6\n    assert h.GetNbinsZ() == 8\n\ndef test_tprofile3d_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TProfile3D(""hvar"", ""title"", 5, 1, 10, 6, 1, 20, 8, 2, 5)\n    h.Sumw2()\n    h.Fill(1.0, 5.0, 3, 5)\n    h.Fill(2.0, 10.0, 4, 8)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    assert uproot.open(filename)[""test""]._classname == b""TProfile3D""\n\ndef test_compressed_tprofile3d(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TProfile3D(""hvar"", ""title"", 5, 1, 10, 6, 1, 20, 8, 2, 8)\n    h.Sumw2()\n    h.Fill(1.0, 5.0, 3, 6)\n    h.Fill(2.0, 10.0, 4, 7)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=uproot.LZMA(6)) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    sums = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 49.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    bincontents = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    count = 0\n    for x in range(1, 6):\n        for y in range(1, 7):\n            for z in range(1, 9):\n                assert h.GetBinContent(x, y, z) == bincontents[count]\n                count += 1\n    assert list(h.GetSumw2()) == sums\n    assert h.GetMean() == 1.5\n    assert h.GetRMS() == 0.5\n    assert h.GetNbinsX() == 5\n    assert h.GetNbinsY() == 6\n    assert h.GetNbinsZ() == 8\n\ndef test_dir_allocation(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, compression=None) as f:\n        for i in range(1, 101):\n            f[""a""*i] = ""a""*i\n\n    f = ROOT.TFile.Open(filename)\n    assert str(f.Get(""a""*100)) == ""a""*100\n    f.Close()\n\ndef test_taxis_axisbins(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH1F(""hvar"", ""title"", 5, 1, 10)\n    h.Fill(1.0, 3)\n    h.Fill(3.0, 8)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    assert h.GetXaxis().GetFirst() == 1\n    assert h.GetXaxis().GetLast() == 5\n\ndef test_taxis_time(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH1F(""hvar"", ""title"", 5, 1, 10)\n    h.GetXaxis().SetTimeDisplay(1)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    assert h.GetXaxis().GetTimeDisplay() == True\n\ndef test_th1_binlabel1(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH1F(""hvar"", ""title"", 5, 1, 10)\n    h.Fill(1.0, 3)\n    h.GetXaxis().SetBinLabel(1, ""Hi"")\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    assert h.GetXaxis().GetBinLabel(1) == ""Hi""\n\ndef test_th1_binlabel1_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH1F(""hvar"", ""title"", 5, 1, 10)\n    h.Fill(1.0, 3)\n    h.GetXaxis().SetBinLabel(1, ""Hi"")\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = uproot.open(filename)\n    h = f[""test""]\n    assert h._fXaxis._fLabels[0] == b""Hi""\n\ndef test_th1_binlabel2(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH1F(""hvar"", ""title"", 5, 1, 10)\n    h.Fill(1.0, 3)\n    h.Fill(2.0, 4)\n    h.GetXaxis().SetBinLabel(1, ""Hi"")\n    h.GetXaxis().SetBinLabel(2, ""Hello"")\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    assert h.GetXaxis().GetBinLabel(1) == ""Hi""\n    assert h.GetXaxis().GetBinLabel(2) == ""Hello""\n\ndef test_th1_binlabel2_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH1F(""hvar"", ""title"", 5, 1, 10)\n    h.Fill(1.0, 3)\n    h.Fill(2.0, 4)\n    h.GetXaxis().SetBinLabel(1, ""Hi"")\n    h.GetXaxis().SetBinLabel(2, ""Hello"")\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = uproot.open(filename)\n    h = f[""test""]\n    assert h._fXaxis._fLabels[0] == b""Hi""\n    assert h._fXaxis._fLabels[1] == b""Hello""\n\ndef test_th2_binlabel1(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH2F(""hvar"", ""title"", 5, 1, 10, 6, 1, 20)\n    h.Fill(1.0, 5.0, 3)\n    h.GetXaxis().SetBinLabel(1, ""Hi1"")\n    h.GetYaxis().SetBinLabel(2, ""Hi2"")\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    assert h.GetXaxis().GetBinLabel(1) == ""Hi1""\n    assert h.GetYaxis().GetBinLabel(2) == ""Hi2""\n\ndef test_th3_binlabel1(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH3F(""hvar"", ""title"", 5, 1, 10, 6, 1, 20, 7, 1, 30)\n    h.Fill(1.0, 5.0, 8.0, 3)\n    h.GetXaxis().SetBinLabel(1, ""Hi1"")\n    h.GetYaxis().SetBinLabel(2, ""Hi2"")\n    h.GetZaxis().SetBinLabel(3, ""Hi3"")\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    assert h.GetXaxis().GetBinLabel(1) == ""Hi1""\n    assert h.GetYaxis().GetBinLabel(2) == ""Hi2""\n    assert h.GetZaxis().GetBinLabel(3) == ""Hi3""\n\ndef test_objany_multihist(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH1F(""hvar"", ""title"", 5, 1, 10)\n    h.Fill(1.0, 3)\n    h.GetXaxis().SetBinLabel(1, ""Hi"")\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n        f[""test1""] = hist\n\n    f = ROOT.TFile.Open(filename)\n    h = f.Get(""test"")\n    h1 = f.Get(""test1"")\n    assert h.GetXaxis().GetBinLabel(1) == ""Hi""\n    assert h1.GetXaxis().GetBinLabel(1) == ""Hi""\n\ndef test_objany_multihist_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH1F(""hvar"", ""title"", 5, 1, 10)\n    h.Fill(1.0, 3)\n    h.GetXaxis().SetBinLabel(1, ""Hi"")\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n        f[""test1""] = hist\n\n    f = uproot.open(filename)\n    h = f[""test""]\n    h1 = f[""test1""]\n    assert h._fXaxis._fLabels[0] == b""Hi""\n    assert h1._fXaxis._fLabels[0] == b""Hi""\n\ndef test_ttree(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    tree = newtree()\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n\n    f = ROOT.TFile.Open(filename)\n    assert f.GetKey(""t"").GetClassName() == ""TTree""\n\ndef test_tree_diff_interface(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, compression=None) as f:\n        f.newtree(""t"")\n\n    f = ROOT.TFile.Open(filename)\n    assert f.GetKey(""t"").GetClassName() == ""TTree""\n\ndef test_ttree_multiple(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    tree = newtree()\n    with uproot.recreate(filename, compression=None) as f:\n        for i in range(100):\n            f[""t""*(i+1)] = tree\n\n    f = ROOT.TFile.Open(filename)\n    for i in range(100):\n        assert f.GetKey(""t""*(i+1)).GetClassName() == ""TTree""\n\ndef test_ttree_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    tree = newtree()\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n\n    f = uproot.open(filename)\n    assert f[""t""]._classname == b""TTree""\n\ndef test_ttree_multiple_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    tree = newtree()\n    with uproot.recreate(filename, compression=None) as f:\n        for i in range(100):\n            f[""t""*(i+1)] = tree\n\n    f = uproot.open(filename)\n    for i in range(100):\n        assert f[""t""*(i+1)]._classname == b""TTree""\n\ndef test_ttree_empty_tbranch(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n\n    f = ROOT.TFile.Open(filename)\n    assert f.Get(""t"").GetBranch(""intBranch"").GetName() == ""intBranch""\n\ndef test_ttree_empty_tbranch_multitree(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    with uproot.recreate(filename, compression=None) as f:\n        for i in range(10):\n            f[""t"" * (i + 1)] = tree\n\n    f = ROOT.TFile.Open(filename)\n    for i in range(10):\n        assert f.Get(""t"" * (i + 1)).GetBranch(""intBranch"").GetName() == ""intBranch""\n\ndef test_ttree_empty_tbranch_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n\n    f = uproot.open(filename)\n    assert f[""t""][""intBranch""]._classname == b""TBranch""\n\ndef test_ttree_empty_tbranch_multitree_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    with uproot.recreate(filename, compression=None) as f:\n        for i in range(10):\n            f[""t""*(i+1)] = tree\n\n    f = uproot.open(filename)\n    for i in range(10):\n        assert f[""t"" * (i + 1)][""intBranch""]._classname == b""TBranch""\n\ndef test_ttree_empty_tbranch_multiple(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b, ""testbranch"": b}\n    tree = newtree(branchdict)\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n\n    f = ROOT.TFile.Open(filename)\n    assert f.Get(""t"").GetBranch(""intBranch"").GetName() == ""intBranch""\n    assert f.Get(""t"").GetBranch(""testbranch"").GetName() == ""testbranch""\n\ndef test_ttree_empty_tbranch_multiple_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b, ""testbranch"": b}\n    tree = newtree(branchdict)\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n\n    f = uproot.open(filename)\n    assert f[""t""][""intBranch""]._classname == b""TBranch""\n    assert f[""t""][""testbranch""]._classname == b""TBranch""\n\ndef test_ttree_empty_tbranch_diff_type(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int64"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n\n    f = ROOT.TFile.Open(filename)\n    assert f.Get(""t"").GetBranch(""intBranch"").GetName() == ""intBranch""\n\ndef test_ttree_empty_tbranch_title(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"", title=""hi"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n\n    f = ROOT.TFile.Open(filename)\n    assert f.Get(""t"").GetBranch(""intBranch"").GetTitle() == ""hi""\n\ndef test_hist_rewrite_root(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n    testfile = join(str(tmp_path), ""test.root"")\n\n    f = ROOT.TFile.Open(testfile, ""RECREATE"")\n    h = ROOT.TH1F(""hvar"", ""title"", 5, 1, 10)\n    h.Sumw2()\n    h.Fill(1.0, 3)\n    h.Fill(2.0, 4)\n    h.Write()\n    f.Close()\n\n    t = uproot.open(testfile)\n    hist = t[""hvar""]\n    with uproot.recreate(filename, compression=None) as f:\n        f[""test""] = hist\n\n    f = ROOT.TFile.Open(filename, ""UPDATE"")\n    t = ROOT.TObjString(""Hello World"")\n    t.Write()\n    f.Close()\n\n    f = ROOT.TFile.Open(filename)\n    assert f.Get(""Hello World"") == ""Hello World""\n\ndef test_empty_ttree_rewrite_root(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n\n    f = ROOT.TFile.Open(filename, ""UPDATE"")\n    t = ROOT.TObjString(""Hello World"")\n    t.Write()\n    f.Close()\n\n    f = ROOT.TFile.Open(filename)\n    assert f.Get(""Hello World"") == ""Hello World""\n\ndef test_string_rewrite_root(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""a""*5] = ""a""*5\n\n    f = ROOT.TFile.Open(filename, ""UPDATE"")\n    t = ROOT.TObjString(""Hello World"")\n    t.Write()\n    f.Close()\n\n    f = ROOT.TFile.Open(filename)\n    assert f.Get(""Hello World"") == ""Hello World""\n\ndef test_string_rewrite_root_compress(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, compression=uproot.ZLIB(4)) as f:\n        f[""a""*5] = ""a""*5\n\n    f = ROOT.TFile.Open(filename, ""UPDATE"")\n    t = ROOT.TObjString(""Hello World"")\n    t.Write()\n    f.Close()\n\n    f = ROOT.TFile.Open(filename)\n    assert f.Get(""Hello World"") == ""Hello World""\n\ndef test_branch_alt_interface(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    branchdict = {""intBranch"": ""int""}\n    tree = newtree(branchdict)\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n\n    f = ROOT.TFile.Open(filename)\n    assert f.Get(""t"").GetBranch(""intBranch"").GetName() == ""intBranch""\n\ndef test_branch_basket_one(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i4"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i4"")\n    for i in range(5):\n        assert a[i] == treedata[i]\n\ndef test_branch_basket_one_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5]).astype(""int32"").newbyteorder("">"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n\n    f = uproot.open(filename)\n    tree = f[""t""]\n    treedata = tree.array(""intBranch"")\n    for i in range(5):\n        assert a[i] == treedata[i]\n\ndef test_branch_basket_one_rewrite_root(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5]).astype(""int32"").newbyteorder("">"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename, ""UPDATE"")\n    t = ROOT.TObjString(""Hello World"")\n    t.Write()\n    f.Close()\n\n    f = ROOT.TFile.Open(filename)\n    assert f.Get(""Hello World"") == ""Hello World""\n\ndef test_branch_basket_one_more_data(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = []\n    for i in range(0, 100):\n        a.append(i)\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i4"")\n    for i in range(0, 100):\n        assert a[i] == treedata[i]\n\ndef test_branch_basket_one_less_data(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4], dtype="">i4"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i4"")\n    for i in range(4):\n        assert a[i] == treedata[i]\n\ndef test_branch_basket_one_tleafb(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int8"")\n    branchdict = {""int8Branch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype=""int8"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""int8Branch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype(""int8"")\n    for i in range(5):\n        assert a[i] == treedata[i]\n\ndef test_branch_basket_one_tleaff(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""float32"")\n    branchdict = {""floatBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype=""float32"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""floatBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype(""float32"")\n    for i in range(5):\n        assert a[i] == treedata[i]\n\ndef test_branch_basket_one_tleafd(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">f8"")\n    branchdict = {""float8Branch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">f8"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""float8Branch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">f8"")\n    for i in range(5):\n        assert a[i] == treedata[i]\n\ndef test_branch_basket_one_tleafl(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">i8"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i8"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i8"")\n    for i in range(5):\n        assert a[i] == treedata[i]\n\ndef test_branch_basket_one_tleafO(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">?"")\n    branchdict = {""booleanBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 0, 0, 0, 1], dtype="">?"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""booleanBranch""].newbasket(a)\n\n    ROOT.gInterpreter.Declare(""""""\n    void readnewbasket(bool* arr, char* filename) {\n        Bool_t x;\n        TFile f(filename);\n        auto tree = f.Get<TTree>(""t"");\n        auto branch = tree->GetBranch(""booleanBranch"");\n        branch->SetAddress(&x);\n        for (int i=0; i<tree->GetEntries(); i++) {\n            tree->GetEvent(i);\n            arr[i] = x;\n        }\n    }"""""")\n\n    testa = numpy.array([0, 0, 0, 0, 0], dtype="">?"")\n    ROOT.readnewbasket(testa, filename)\n    for i in range(5):\n        assert a[i] == testa[i]\n\ndef test_branch_basket_one_tleafs(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">i2"")\n    branchdict = {""int2Branch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i2"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""int2Branch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i2"")\n    for i in range(5):\n        assert a[i] == treedata[i]\n\ndef test_one_branch_multi_basket(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i4"")\n    b = numpy.array([6, 7, 8, 9, 10], dtype="">i4"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n        f[""t""][""intBranch""].newbasket(b)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i4"")\n    for i in range(5):\n        assert a[i] == treedata[i]\n        assert b[i] == treedata[i+5]\n\ndef test_multi_branch_one_basket_same_type(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b1 = newbranch(""int32"")\n    b2 = newbranch(""int32"")\n    branchdict = {""intBranch"": b1, ""intBranch2"": b2}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i4"")\n    b = numpy.array([6, 7, 8, 9, 10], dtype="">i4"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n        f[""t""][""intBranch2""].newbasket(b)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    intBranchdata = tree.AsMatrix([""intBranch""]).astype("">i4"")\n    int8Branchdata = tree.AsMatrix([""intBranch2""]).astype("">i4"")\n    for i in range(5):\n        assert a[i] == intBranchdata[i]\n        assert b[i] == int8Branchdata[i]\n\ndef test_multi_branch_one_basket_same_type_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b1 = newbranch(""int32"")\n    b2 = newbranch(""int32"")\n    branchdict = {""intBranch"": b1, ""intBranch2"": b2}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i4"")\n    b = numpy.array([6, 7, 8, 9, 10], dtype="">i4"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n        f[""t""][""intBranch2""].newbasket(b)\n\n    f = uproot.open(filename)\n    tree = f[""t""]\n    intBranchdata = tree.array(""intBranch"")\n    int8Branchdata = tree.array(""intBranch2"")\n    for i in range(5):\n        assert a[i] == intBranchdata[i]\n        assert b[i] == int8Branchdata[i]\n\ndef test_multi_branch_one_basket_diff_type(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b1 = newbranch(""int32"")\n    b2 = newbranch(""int64"")\n    branchdict = {""intBranch"": b1, ""int8Branch"": b2}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i4"")\n    b = numpy.array([6, 7, 8, 9, 10], dtype="">i8"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n        f[""t""][""int8Branch""].newbasket(b)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    intBranchdata = tree.AsMatrix([""intBranch""]).astype("">i4"")\n    int8Branchdata = tree.AsMatrix([""int8Branch""]).astype("">i8"")\n    for i in range(5):\n        assert a[i] == intBranchdata[i]\n        assert b[i] == int8Branchdata[i]\n\ndef test_multi_branch_multi_basket_diff_type(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b1 = newbranch(""int32"")\n    b2 = newbranch(""int64"")\n    branchdict = {""intBranch"": b1, ""int8Branch"": b2}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i4"")\n    b = numpy.array([6, 7, 8, 9, 10], dtype="">i4"")\n    c = numpy.array([6, 7, 8, 9, 10], dtype="">i8"")\n    d = numpy.array([1, 2, 3, 4, 5], dtype="">i8"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n        f[""t""][""intBranch""].newbasket(b)\n        f[""t""][""int8Branch""].newbasket(c)\n        f[""t""][""int8Branch""].newbasket(d)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    intBranchdata = tree.AsMatrix([""intBranch""]).astype("">i4"")\n    int8Branchdata = tree.AsMatrix([""int8Branch""]).astype("">i8"")\n    for i in range(5):\n        assert a[i] == intBranchdata[i]\n        assert b[i] == intBranchdata[i+5]\n        assert c[i] == int8Branchdata[i]\n        assert d[i] == int8Branchdata[i+5]\n\ndef test_multi_tree_one_branch_multi_basket_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i4"")\n    b = numpy.array([6, 7, 8, 9, 10], dtype="">i4"")\n    c = numpy.array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype="">i4"")\n    d = numpy.array([11, 12, 13, 14, 15, 16, 17, 18, 19], dtype="">i4"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""tree""] = tree\n        f[""tree""][""intBranch""].newbasket(c)\n        f[""tree""][""intBranch""].newbasket(d)\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n        f[""t""][""intBranch""].newbasket(b)\n\n    f = uproot.open(filename)\n    treedata1 = f[""t""].array(""intBranch"")\n    treedata2 = f[""tree""].array(""intBranch"")\n    for i in range(5):\n        assert a[i] == treedata1[i]\n        assert b[i] == treedata1[i+5]\n    for i in range(9):\n        assert c[i] == treedata2[i]\n        assert d[i] == treedata2[i+9]\n\ndef test_multi_tree_one_branch_multi_basket(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i4"")\n    b = numpy.array([6, 7, 8, 9, 10], dtype="">i4"")\n    c = numpy.array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype="">i4"")\n    d = numpy.array([11, 12, 13, 14, 15, 16, 17, 18, 19], dtype="">i4"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""tree""] = tree\n        f[""tree""][""intBranch""].newbasket(c)\n        f[""tree""][""intBranch""].newbasket(d)\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n        f[""t""][""intBranch""].newbasket(b)\n\n    f = ROOT.TFile.Open(filename)\n    t = f.Get(""t"")\n    tree = f.Get(""tree"")\n    treedata1 = t.AsMatrix().astype("">i4"")\n    treedata2 = tree.AsMatrix().astype("">i4"")\n    for i in range(5):\n        assert a[i] == treedata1[i]\n        assert b[i] == treedata1[i+5]\n    for i in range(9):\n        assert c[i] == treedata2[i]\n        assert d[i] == treedata2[i+9]\n\n# Not actually compressed\ndef test_tree_compression_empty(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">i4"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    with uproot.recreate(filename, compression=uproot.ZLIB(4)) as f:\n        f[""t""] = tree\n\n    f = ROOT.TFile.Open(filename)\n    assert f.Get(""t"").GetBranch(""intBranch"").GetName() == ""intBranch""\n    assert f.GetCompressionAlgorithm() == uproot.const.kZLIB\n    assert f.GetCompressionLevel() == 4\n\n# Not actually compressed\ndef test_tree_compression(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">i4"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i4"")\n    with uproot.recreate(filename, compression=uproot.ZLIB(4)) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i4"")\n    for i in range(5):\n        assert a[i] == treedata[i]\n\ndef test_tree_branch_compression_only(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">i4"", compression=uproot.ZLIB(4))\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i4"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i4"")\n    for i in range(5):\n        assert a[i] == treedata[i]\n\ndef test_tree_branch_compression(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">i4"", compression=uproot.ZLIB(4))\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i4"")\n    with uproot.recreate(filename) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i4"")\n    for i in range(5):\n        assert a[i] == treedata[i]\n    branch = tree.GetBranch(""intBranch"")\n    assert branch.GetCompressionAlgorithm() == 1\n    assert branch.GetCompressionLevel() == 4\n\ndef test_branch_compression_interface1(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">i8"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], dtype="">i8"")\n    with uproot.recreate(filename, compression=uproot.ZLIB(4)) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i8"")\n    for i in range(15):\n        assert a[i] == treedata[i]\n    branch = tree.GetBranch(""intBranch"")\n    assert branch.GetCompressionAlgorithm() == 1\n    assert branch.GetCompressionLevel() == 4\n\ndef test_branch_compression_interface1_diff_type(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">i4"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], dtype="">i4"")\n    with uproot.recreate(filename, compression=uproot.ZLIB(4)) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i4"")\n    for i in range(15):\n        assert a[i] == treedata[i]\n    branch = tree.GetBranch(""intBranch"")\n    assert branch.GetCompressionAlgorithm() == 1\n    assert branch.GetCompressionLevel() == 4\n\ndef test_branch_compression_interface2(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">i8"", compression=uproot.ZLIB(4))\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], dtype="">i8"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i8"")\n    for i in range(15):\n        assert a[i] == treedata[i]\n    branch = tree.GetBranch(""intBranch"")\n    assert branch.GetCompressionAlgorithm() == 1\n    assert branch.GetCompressionLevel() == 4\n\ndef test_branch_compression_interface3(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">i8"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict, compression=uproot.ZLIB(4))\n    a = numpy.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], dtype="">i8"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i8"")\n    for i in range(15):\n        assert a[i] == treedata[i]\n    branch = tree.GetBranch(""intBranch"")\n    assert branch.GetCompressionAlgorithm() == 1\n    assert branch.GetCompressionLevel() == 4\n\ndef test_many_basket_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">i4"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1], dtype="">i4"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        for i in range(101):\n            f[""t""][""intBranch""].newbasket(a)\n\n    f = uproot.open(filename)\n    tree = f[""t""]\n    treedata = tree.array(""intBranch"")\n    for i in range(101):\n        assert a[0] == treedata[i]\n\ndef test_many_basket(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">i4"")\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1], dtype="">i4"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        for i in range(101):\n            f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i4"")\n    for i in range(101):\n        assert a[0] == treedata[i]\n\ndef test_tree_move_compress(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch("">i4"", compression=uproot.ZLIB(4))\n    branchdict = {""intBranch"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1], dtype="">i4"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        for i in range(101):\n            f[""t""][""intBranch""].newbasket(a)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    treedata = tree.AsMatrix().astype("">i4"")\n    for i in range(101):\n        assert a[0] == treedata[i]\n    branch = tree.GetBranch(""intBranch"")\n    assert branch.GetCompressionAlgorithm() == 1\n    assert branch.GetCompressionLevel() == 4\n\ndef test_tree_renames(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = uproot.newbranch("">i4"")\n    branchdict = {""intBranch"": b}\n    tree = uproot.newtree(branchdict)\n    a = numpy.array([1], dtype="">i4"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        for i in range(19):\n            f[""t""][""intBranch""].newbasket(a)\n\n    f = uproot.open(filename)\n    tree = f[""t""]\n    treedata = tree.array(""intBranch"")\n    for i in range(19):\n        assert a[0] == treedata[i]\n\ndef test_ttree_extend(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = uproot.newbranch("">i4"")\n    branchdict = {""intBranch"": b, ""intBranch2"": b}\n    tree = uproot.newtree(branchdict)\n    with uproot.recreate(filename) as f:\n        f[""t""] = tree\n        basket_add = {""intBranch"": numpy.array([1, 2, 3, 4, 5]), ""intBranch2"": numpy.array([6, 7, 8, 9, 10])}\n        f[""t""].extend(basket_add)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    branch1 = tree.AsMatrix([""intBranch""])\n    branch2 = tree.AsMatrix([""intBranch2""])\n    branch1_test = numpy.array([1, 2, 3, 4, 5], dtype="">i4"")\n    branch2_test = numpy.array([6, 7, 8, 9, 10], dtype="">i4"")\n    for i in range(5):\n        assert branch1[i] == branch1_test[i]\n        assert branch2[i] == branch2_test[i]\n\ndef test_issue340(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n    with uproot.recreate(filename) as f:\n        f[""t""] = uproot.newtree({""normal"": numpy.float64})\n        f[""t""].extend({""normal"": a})\n\n    t = uproot.open(filename)[""t""]\n    for i in range(10):\n        assert t[""normal""].basket(0)[i] == a[i]\n\ndef test_rdf(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    b = newbranch(""int32"")\n    branchdict = {""intBranch"": b, ""intBranch2"": b}\n    tree = newtree(branchdict)\n    a = numpy.array([1, 2, 3, 4, 5], dtype="">i4"")\n    b = numpy.array([11, 12, 13, 14, 15], dtype="">i4"")\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = tree\n        f[""t""][""intBranch""].newbasket(a)\n        f[""t""][""intBranch2""].newbasket(b)\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    rdf = ROOT.RDataFrame(tree)\n    for i in range(5):\n        assert a[i] == rdf.AsNumpy()[""intBranch""][i]\n        assert b[i] == rdf.AsNumpy()[""intBranch2""][i]\n\ndef test_tree_cycle(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename) as f:\n        f[""t;1""] = uproot.newtree({""branch"": ""int32""})\n        f[""t;2""] = uproot.newtree({""branch"": ""int32""})\n        f[""t;1""].extend({""branch"": numpy.array([1, 2, 3, 4, 5])})\n        f[""t""].extend({""branch"": numpy.array([6, 7, 8, 9, 10])})\n\n    f = ROOT.TFile.Open(filename)\n    tree1 = f.Get(""t;1"")\n    branch1 = tree1.AsMatrix([""branch""])\n    tree2 = f.Get(""t;2"")\n    branch2 = tree2.AsMatrix([""branch""])\n    a = numpy.array([1, 2, 3, 4, 5], dtype=""int32"")\n    b = numpy.array([6, 7, 8, 9, 10], dtype=""int32"")\n    for i in range(5):\n        assert branch1[i] == a[i]\n        assert branch2[i] == b[i]\n\ndef test_large_compress(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, uproot.ZLIB(5)) as f:\n        f[""a""] = ""a"" * ((2 ** 24) + 2000)\n        f[""b""] = ""b"" * ((2 ** 24) + 10)\n\n    f = ROOT.TFile.Open(filename)\n    assert str(f.Get(""a"")) == ""a"" * ((2 ** 24) + 2000)\n    assert str(f.Get(""b"")) == ""b"" * ((2 ** 24) + 10)\n    f.Close()\n\ndef test_large_compress_uproot(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    with uproot.recreate(filename, uproot.ZLIB(5)) as f:\n        f[""a""] = ""a""*((2**24) + 2000)\n        f[""b""] = ""b""*((2**24) + 10)\n\n    f = uproot.open(filename)\n    assert f[""a""] == (""a""*((2**24) + 2000)).encode(""utf-8"")\n    assert f[""b""] == (""b""*((2**24) + 10)).encode(""utf-8"")\n\ndef test_tree_twodim(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = numpy.array([[0, 1, 2, 3],\n                     [3, 4, 5, 6]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch"": uproot.newbranch(numpy.dtype("">i4""), shape=a.shape)})\n        f[""t""].extend({""branch"": a})\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    rdf = ROOT.RDataFrame(tree).AsNumpy()[""branch""]\n    for i in range(0, 2):\n        for j in range(0, 4):\n            assert a[i][j] == rdf[i][j]\n\ndef test_tree_threedim(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = numpy.array([[[0, 1, 2, 3],\n                      [3, 4, 5, 6],\n                      [90, 91, 91, 92]],\n                     [[10, 11, 12, 13],\n                      [13, 14, 15, 16],\n                      [190, 191, 191, 192]]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch"": uproot.newbranch(numpy.dtype("">i4""), shape=a.shape)})\n        f[""t""].extend({""branch"": a})\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    rdf = ROOT.RDataFrame(tree).AsNumpy()[""branch""]\n    for i in range(2):\n        test = numpy.array(rdf[i]).reshape(3, 4)\n        for j in range(3):\n            for k in range(4):\n                assert a[i][j][k] == test[j][k]\n\ndef test_jagged_i4(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2],\n                          [10, 11, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch"": uproot.newbranch(numpy.dtype("">i4""), size=""n"")})\n        f[""t""].extend({""branch"": a, ""n"": [1, 2, 3]})\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    for i, event in enumerate(tree):\n        assert(numpy.all([x for x in event.branch] == a[i]))\n\ndef test_jagged_uproot_i4(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2],\n                          [10, 11, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch"": uproot.newbranch(numpy.dtype("">i4""), size=""n"")})\n        f[""t""].extend({""branch"": a, ""n"": [1, 2, 3]})\n\n    f = uproot.open(filename)\n    array = f[""t""].array([""branch""])\n    for i in range(len(array)):\n        for j in range(len(array[i])):\n            assert(array[i][j] == a[i][j])\n\n#Need to use C++ code to read out because of bug in PyROOT layer (of Conda ROOT build?)\ndef test_jagged_i8(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2],\n                          [10, 11, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch"": uproot.newbranch(numpy.dtype("">i8""), size=""n"")})\n        f[""t""].extend({""branch"": a, ""n"": [1, 2, 3]})\n\n    ROOT.gInterpreter.Declare(""""""\n        void assertint(bool &flag, char* filename) {\n            TFile *f = new TFile(filename);\n            Long64_t x;\n            Int_t num;\n            auto tree = f->Get<TTree>(""t"");\n            auto n = tree->GetBranch(""n"");\n            auto branch = tree->GetBranch(""branch"");\n            n->SetAddress(&num);\n            branch->SetAddress(&x);\n            Long64_t values[3][3] = {{0,0,0}, {1, 2, 0}, {10, 11, 12}};\n            for (int i=0; i<tree->GetEntries(); i++) {\n                tree->GetEvent(i);\n                for (int j=0; j<num; j++) {\n                    if (values[i][j] != x+j)\n                        flag = false;\n                }\n            }\n        }"""""")\n\n    flag = ctypes.c_bool(True)\n    ROOT.assertint(flag, filename)\n    assert(flag)\n\ndef test_jagged_uproot_i8(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2],\n                          [10, 11, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch"": uproot.newbranch(numpy.dtype("">i8""), size=""n"")})\n        f[""t""].extend({""branch"": a, ""n"": [1, 2, 3]})\n\n    f = uproot.open(filename)\n    array = f[""t""].array([""branch""])\n    for i in range(len(array)):\n        for j in range(len(array[i])):\n            assert(array[i][j] == a[i][j])\n\ndef test_jagged_f8(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2],\n                          [10, 11, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch"": uproot.newbranch(numpy.dtype("">f8""), size=""n"")})\n        f[""t""].extend({""branch"": a, ""n"": [1, 2, 3]})\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    for i, event in enumerate(tree):\n        assert(numpy.all([x for x in event.branch] == a[i]))\n\ndef test_jagged_uproot_f8(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2],\n                          [10, 11, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch"": uproot.newbranch(numpy.dtype("">f8""), size=""n"")})\n        f[""t""].extend({""branch"": a, ""n"": [1, 2, 3]})\n\n    f = uproot.open(filename)\n    array = f[""t""].array([""branch""])\n    for i in range(len(array)):\n        for j in range(len(array[i])):\n            assert(array[i][j] == a[i][j])\n\ndef test_jagged_f4(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2],\n                          [10, 11, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch"": uproot.newbranch(numpy.dtype("">f4""), size=""n"")})\n        f[""t""].extend({""branch"": a, ""n"": [1, 2, 3]})\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    for i, event in enumerate(tree):\n        assert(numpy.all([x for x in event.branch] == a[i]))\n\ndef test_jagged_uproot_f4(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2],\n                          [10, 11, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch"": uproot.newbranch(numpy.dtype("">f4""), size=""n"")})\n        f[""t""].extend({""branch"": a, ""n"": [1, 2, 3]})\n\n    f = uproot.open(filename)\n    array = f[""t""].array([""branch""])\n    for i in range(len(array)):\n        for j in range(len(array[i])):\n            assert(array[i][j] == a[i][j])\n\ndef test_jagged_i2(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2],\n                          [10, 11, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch"": uproot.newbranch(numpy.dtype("">i2""), size=""n"")})\n        f[""t""].extend({""branch"": a, ""n"": [1, 2, 3]})\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    for i, event in enumerate(tree):\n        assert(numpy.all([x for x in event.branch] == a[i]))\n\ndef test_jagged_uproot_i2(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2],\n                          [10, 11, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch"": uproot.newbranch(numpy.dtype("">i2""), size=""n"")})\n        f[""t""].extend({""branch"": a, ""n"": [1, 2, 3]})\n\n    f = uproot.open(filename)\n    array = f[""t""].array([""branch""])\n    for i in range(len(array)):\n        for j in range(len(array[i])):\n            assert(array[i][j] == a[i][j])\n\ndef test_jagged_i2_multiple_sametype(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2]])\n\n    b = awkward.fromiter([[3],\n                          [7, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch1"": uproot.newbranch(numpy.dtype("">i2""), size=""n""),\n                                 ""branch2"": uproot.newbranch(numpy.dtype("">i2""), size=""n"")})\n        f[""t""].extend({""branch1"": a,\n                       ""branch2"": b,\n                       ""n"": [1, 2]})\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    for i, event in enumerate(tree):\n        assert(numpy.all([x for x in event.branch1] == a[i]))\n        assert(numpy.all([x for x in event.branch2] == b[i]))\n\ndef test_jagged_multiple_difftype(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2]])\n\n    b = awkward.fromiter([[3],\n                          [7, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch1"": uproot.newbranch(numpy.dtype("">i2""), size=""n""),\n                                 ""branch2"": uproot.newbranch(numpy.dtype("">i4""), size=""n"")})\n        f[""t""].extend({""branch1"": a,\n                       ""branch2"": b,\n                       ""n"": [1, 2]})\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    for i, event in enumerate(tree):\n        assert(numpy.all([x for x in event.branch1] == a[i]))\n        assert(numpy.all([x for x in event.branch2] == b[i]))\n\ndef test_jagged_i2_multiple_difflen(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2]])\n\n    b = awkward.fromiter([[3],\n                          [10, 11, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch1"": uproot.newbranch(numpy.dtype("">i2""), size=""n1""),\n                                 ""branch2"": uproot.newbranch(numpy.dtype("">i2""), size=""n2"")})\n        f[""t""].extend({""branch1"": a,\n                       ""n1"": [1, 2],\n                       ""branch2"": b,\n                       ""n2"": [1, 3]})\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    for i, event in enumerate(tree):\n        assert(numpy.all([x for x in event.branch1] == a[i]))\n        assert(numpy.all([x for x in event.branch2] == b[i]))\n\ndef test_jagged_i4_manybasket(tmp_path):\n    filename = join(str(tmp_path), ""example.root"")\n\n    a = awkward.fromiter([[0],\n                          [1, 2],\n                          [10, 11, 12]])\n    b = awkward.fromiter([[10],\n                          [11, 12]])\n    tester = awkward.fromiter([[0],\n                               [1, 2],\n                               [10, 11, 12],\n                               [10],\n                               [11, 12]])\n\n    with uproot.recreate(filename, compression=None) as f:\n        f[""t""] = uproot.newtree({""branch"": uproot.newbranch(numpy.dtype("">i4""), size=""n"")})\n        f[""t""].extend({""branch"": a, ""n"": [1, 2, 3]})\n        f[""t""].extend({""branch"": b, ""n"": [1, 2]})\n\n    f = ROOT.TFile.Open(filename)\n    tree = f.Get(""t"")\n    for i, event in enumerate(tree):\n        assert(numpy.all([x for x in event.branch] == tester[i]))\n'"
uproot/__init__.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\n""""""uproot -- ROOT I/O in pure Python and Numpy.\n\nBasic cheat-sheet\n-----------------\n\nOpen ROOT files with uproot.open (for reading) or uproot.create (for read-write).\n\n    file = uproot.open(""/path/to/my/file.root"")\n    file = uproot.open(""root://path/to/my/file.root"")\n    file = uproot.open(""http://path/to/my/file.root"")\n    writeable = uproot.create(""/new/local/file.root"")\n\nThese file objects act like dicts; get objects like TTrees from them with square\nbrackets.\n\n    tree = file[""path/to/events""]\n    tree = file[""path/to/events;2""]            # optional cycle number\n    # write to files by assignment (histograms only)\n    writeable[""name""] = numpy.histogram(...)\n\nTTree objects also act like dicts; get branches with square brackets or list them\nwith keys().\n\n    tree.keys()\n    tree.allkeys()    # recursive branches-of-branches\n    tree.show()       # display view\n    tree[""mybranch""]  # searches recursively\n\nGet data as arrays with an array(...) or arrays(...) call.\n\n    tree[""mybranch""].array()\n    tree.array(""mybranch"")\n    tree.arrays([""branch1"", ""branch2"", ""branch3""])\n    tree.arrays([""Muon_*""])\n\nVariable numbers of objects per entry (particles per event) are handled by\nawkward-array:\n\n    https://github.com/scikit-hep/awkward-array\n\nThe arrays(...) call returns a dict from branch name (bytes) to data\n(Numpy array) by default.\nChange this by passing an outputtype class (e.g. dict, tuple, pandas.DataFrame).\n\n    x, y, z = tree.arrays([""x"", ""y"", ""z""], outputtype=tuple)\n\nFor more idiomatic Pandas defaults, use tree.pandas.df().\n\n    df = tree.pandas.df()\n\nIf the desired branches do not fit into memory, iterate over chunks of entries\nwith iterate(). The interface is the same as above: you get the same\ndict/tuple/DataFrame with fewer entries.\n\n    for x, y, z in tree.iterate([""x"", ""y"", ""z""], outputtype=tuple):\n        do_something(x, y, z)\n\nTo iterate over many files (like TChain), do uproot.iterate(...).\n\n    for arrays in uproot.iterate(""files*.root"", ""path/to/events"", [""Muon_*""]):\n        do_something(arrays)\n\nIntermediate cheat-sheet\n------------------------\n\nEach call to array/arrays/iterate reads the file again. For faster access after\nthe first time, pass a dict-like object to the cache parameter and uproot will\ntry the cache first.\n\n    cache = {}\n    arrays = tree.arrays([""Muon_*""], cache=cache)    # slow\n    arrays = tree.arrays([""Muon_*""], cache=cache)    # fast\n\nYou control the cache object. If you\'re running out of memory, remove it or\nremove items from it. Or use one of the dict-like caches from cachetools (already\ninstalled) or another library.\n\nFor parallel processing, pass a Python 3 executor.\n\n    import concurrent.futures\n    executor = concurrent.futures.ThreadPoolExecutor(32)\n    arrays = tree.arrays([""Muon_*""], executor=executor)\n\nTo get the number of entries per file in a a collection of files, use\nuproot.numentries().\n\n    uproot.numentries(""tests/samples/sample*.root"", ""sample"", total=False)\n\nFor arrays that read on demand, use uproot.lazyarray and uproot.lazyarrays.\nFor processing with Dask, use uproot.daskarray, uproot.daskarrays, or\nuproot.daskframe.\n\nAdvanced cheat-sheet\n--------------------\n\nThe standard bytes-to-arrays decoding is attached to each branch as\n\n    tree[""mybranch""].interpretation\n\nThis can be overridden by passing a new interpretation to array/arrays/iterate.\nMost reinterpretations will produce wrong values (it\'s a reinterpret_cast<...>).\n\nSome, however, are useful:\n\n    mybranch = tree[""mybranch""]\n    fill_me_instead = numpy.empty(big_enough)\n    mybranch.array(mybranch.interpretation.toarray(fill_me_instead))\n    fill_me_instead                   # filled in place\n\n    mybranch.array(uproot.asdebug)    # view raw bytes of each entry\n\nBy default, local files are read as memory-mapped arrays. Change this by setting\n\n    from uproot import FileSource\n    open(""..."", localsource=lambda path: FileSource(path, **FileSource.defaults))\n\nThe same procedure sets options for uproot.XRootDSource and uproot.HTTPSource.\n""""""\n\nfrom __future__ import absolute_import\n\n# high-level entry points\nfrom uproot.rootio import open, xrootd, http\nfrom uproot.tree import iterate, numentries, lazyarray, lazyarrays, daskarray, daskframe\nfrom uproot.write.TFile import TFileCreate as create\nfrom uproot.write.TFile import TFileRecreate as recreate\nfrom uproot.write.TFile import TFileUpdate as update\nfrom uproot.write.compress import ZLIB, LZMA, LZ4\nfrom uproot.write.objects.TTree import newtree, newbranch\n\nfrom uproot.source.memmap import MemmapSource\nfrom uproot.source.file import FileSource\nfrom uproot.source.xrootd import XRootDSource\nfrom uproot.source.http import HTTPSource\n\nfrom uproot.cache import ArrayCache, ThreadSafeArrayCache\n\nfrom uproot.interp.auto import interpret\nfrom uproot.interp.numerical import asdtype\nfrom uproot.interp.numerical import asarray\nfrom uproot.interp.numerical import asdouble32\nfrom uproot.interp.numerical import asstlbitset\nfrom uproot.interp.jagged import asjagged\nfrom uproot.interp.objects import astable\nfrom uproot.interp.objects import asobj\nfrom uproot.interp.objects import asgenobj\nfrom uproot.interp.objects import asstring\nfrom uproot.interp.objects import SimpleArray\nfrom uproot.interp.objects import STLVector\nfrom uproot.interp.objects import STLMap\nfrom uproot.interp.objects import STLString\nfrom uproot.interp.objects import Pointer\nasdebug = asjagged(asdtype(""u1""))\n\nfrom uproot import pandas\n\n# put help strings on everything (they\'re long, too disruptive to intersperse\n# in the code, and are built programmatically to avoid duplication; Python\'s\n# inline docstring method doesn\'t accept non-literals)\nimport uproot._help\n\n# convenient access to the version number\nfrom uproot.version import __version__\n\n# don\'t expose uproot.uproot; it\'s ugly\ndel uproot\n\n__all__ = [""open"", ""xrootd"", ""http"", ""iterate"", ""numentries"", ""lazyarray"", ""lazyarrays"", ""daskarray"", ""daskframe"", ""create"", ""recreate"", ""update"", ""ZLIB"", ""LZMA"", ""LZ4"", ""ZSTD"", ""newtree"", ""newbranch"", ""MemmapSource"", ""FileSource"", ""XRootDSource"", ""HTTPSource"", ""ArrayCache"", ""ThreadSafeArrayCache"", ""interpret"", ""asdtype"", ""asarray"", ""asdouble32"", ""asstlbitset"", ""asjagged"", ""astable"", ""asobj"", ""asgenobj"", ""asstring"", ""asdebug"", ""SimpleArray"", ""STLVector"", ""STLMap"", ""STLString"", ""Pointer"", ""pandas"", ""__version__""]\n'"
uproot/_help.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport functools\nimport textwrap\n\nimport uproot\nimport uproot._connect._pandas\n\nTEXT_WIDTH = 80\n\n\ndef _method(x):\n    if hasattr(x, ""__func__""):\n        return x.__func__\n    else:\n        return x\n\n\ndef _join_and_preserve_sequential_indent(lines):\n    """"""Joins lines with newlines while preserving indentation of first line""""""\n    if not lines:\n        return \'\'\n    first_line = lines[0]\n    leading_spaces = len(first_line) - len(first_line.lstrip(\' \'))\n    return \'\\n\'.join([first_line] + [\' \' * leading_spaces + line for line in lines[1:]])\n\n\ndef wrap(text, width=80):\n    """"""Wraps the text to a given width, preserving indentation""""""\n    return ""\\n"".join(\n        map(_join_and_preserve_sequential_indent,\n            map(functools.partial(textwrap.wrap, width=width), text.split(\'\\n\'))))\n\n\n################################################################ uproot.rootio fragments\n\nopen_fragments = {\n    # localsource\n    ""localsource"": u""""""localsource : function: path \\u21d2 :py:class:`Source <uproot.source.source.Source> or ``dict`` of keyword arguments`\n        function that will be applied to the path to produce an uproot :py:class:`Source <uproot.source.source.Source>` object if the path is a local file. Default is ``MemmapSource.defaults`` for memory-mapped files. If a ``dict``, the ``dict`` is passed as keyword arguments to :py:class:`MemmapSource <uproot.source.memmap.MemmapSource>` constructor."""""",\n\n    # xrootdsource\n    ""xrootdsource"": u""""""xrootdsource : function: path \\u21d2 :py:class:`Source <uproot.source.source.Source> or ``dict`` of keyword arguments`\n        function that will be applied to the path to produce an uproot :py:class:`Source <uproot.source.source.Source>` object if the path is an XRootD URL. Default is ``uproot.source.xrootd.XRootDSource.defaults`` for XRootD with default chunk size/caching. (See :py:class:`XRootDSource <uproot.source.xrootd.XRootDSource>` constructor for details.) If a ``dict``, the ``dict`` is passed as keyword arguments to :py:class:`XRootDSource <uproot.source.xrootd.XRootDSource>` constructor."""""",\n\n    # httpsource\n    ""httpsource"": u""""""httpsource : function: path \\u21d2 :py:class:`Source <uproot.source.source.Source> or ``dict`` of keyword arguments`\n        function that will be applied to the path to produce an uproot :py:class:`Source <uproot.source.source.Source>` object if the path is an HTTP URL. Default is ``uproot.source.http.HTTPSource.defaults`` for HTTP with default chunk size/caching. (See :py:class:`HTTPSource <uproot.source.http.HTTPSource>` constructor for details.) If a ``dict``, the ``dict`` is passed as keyword arguments to :py:class:`HTTPSource <uproot.source.http.HTTPSource>` constructor."""""",\n\n    # options\n    ""options"": u""""""options\n        passed to :py:class:`ROOTDirectory <uproot.rootio.ROOTDirectory>` constructor."""""",\n}\n\nrootdirectory_fragments = {\n    # recursive\n    ""recursive"": u""""""recursive : bool\n        if ``False`` *(default)*, only iterate over this directory level; if ``True``, depth-first iterate over all subdirectories as well."""""",\n\n    # filtername\n    ""filtername"": u""""""filtername : function: str \\u21d2 bool\n        only keys for which ``filtername(name)`` returns ``True`` are returned (does not eliminate subdirectories if ``recursive=True``). Default returns ``True`` for all input."""""",\n\n    # filterclass\n    ""filterclass"": u""""""filterclass : function: class object \\u21d2 bool\n        only keys for which ``filterclass(class object)`` returns ``True`` are returned (does not eliminate subdirectories if ``recursive=True``). Default returns ``True`` for all input. Note that all class objects passed to this function have a ``classname`` attribute for the C++ class name (may differ from the Python class name for syntactic reasons)."""""",\n    }\n\n################################################################ uproot.rootio.open\n\nuproot.rootio.open.__doc__ = wrap(\nu""""""Opens a ROOT file (local or remote), specified by file path.\n\n    Parameters\n    ----------\n    path : str\n        local file path or URL specifying the location of a file (note: not a Python file object!). If the URL schema is ""root://"", :py:func:`xrootd <uproot.xrootd>` will be called; if ""http://"", :py:func:`http <uproot.http>` will be called.\n\n    {localsource}\n\n    {xrootdsource}\n\n    {httpsource}\n\n    {options}\n\n    Returns\n    -------\n    :py:class:`ROOTDirectory <uproot.rootio.ROOTDirectory>`\n        top-level directory of the ROOT file.\n\n    Notes\n    -----\n    The ROOTDirectory returned by this function is not necessarily an open file. File handles are managed internally by :py:class:`Source <uproot.source.source.Source>` objects to permit parallel reading. Although this function can be used in a ``with`` construct (which protects against unclosed files), the ``with`` construct has no meaning when applied to this function. Files will be opened or closed as needed to read data on demand.\n    """""".format(**open_fragments), width=TEXT_WIDTH)\n\n################################################################ uproot.rootio.xrootd\n\nuproot.rootio.xrootd.__doc__ = wrap(\nu""""""Opens a remote ROOT file with XRootD (if installed).\n\n    Parameters\n    ----------\n    path : str\n        URL specifying the location of a file.\n\n    {xrootdsource}\n\n    {options}\n\n    Returns\n    -------\n    :py:class:`ROOTDirectory <uproot.rootio.ROOTDirectory>`\n        top-level directory of the ROOT file.\n    """""".format(**open_fragments), width=TEXT_WIDTH)\n\n################################################################ uproot.rootio.http\n\nuproot.rootio.http.__doc__ = wrap(\nu""""""Opens a remote ROOT file with HTTP (if ``requests`` is installed).\n\n    Parameters\n    ----------\n    path : str\n        URL specifying the location of a file.\n\n    {httpsource}\n\n    {options}\n\n    Returns\n    -------\n    :py:class:`ROOTDirectory <uproot.rootio.ROOTDirectory>`\n        top-level directory of the ROOT file.\n    """""".format(**open_fragments), width=TEXT_WIDTH)\n\n################################################################ uproot.rootio.ROOTDirectory\n\nuproot.rootio.ROOTDirectory.__doc__ = wrap(\nu""""""Represents a ROOT file or directory, an entry point for reading objects.\n\n    Although this class has a constructor that could be called by a user, objects are usually created from ROOT files through :py:func:`open <uproot.rootio.open>` or :py:func:`xrootd <uproot.rootio.xrootd>`.\n\n    :py:class:`ROOTDirectory <uproot.rootio.ROOTDirectory>` objects may be accessed as Python containers:\n\n    - square brackets (``__getitem__``) read objects from the file by key name (see :py:meth:`get <uproot.rootio.ROOTDirectory.get>`).\n    - the ``len`` function (``__len__``) returns the number of keys.\n    - iteration (``__iter__``) iterates over the *names* of the keys only (like a ``dict``, see :py:meth:`keys <uproot.rootio.ROOTDirectory.keys>`).\n\n    **Attributes, properties, and methods:**\n\n    - **name** (*bytes*) name of the file or directory *as read from the ROOT file*. (ROOT files may be imprinted with a different name than they have in the file system.)\n\n    - **compression** (:py:class:`Compression <uproot.source.compressed.Compression>`) the compression algorithm and level specified in the file header. (Some objects, including TTree branches, may have different compression settings than the global file settings.)\n\n    - :py:meth:`get <uproot.rootio.ROOTDirectory.get>` read an object from the file, selected by name.\n\n    - :py:meth:`iterkeys <uproot.rootio.ROOTDirectory.iterkeys>` iterate over key names in this directory.\n\n    - :py:meth:`itervalues <uproot.rootio.ROOTDirectory.itervalues>` iterate over objects in this directory.\n\n    - :py:meth:`iteritems <uproot.rootio.ROOTDirectory.iteritems>` iterate over *(key name, object)* pairs in this directory, like a ``dict``.\n\n    - :py:meth:`iterclasses <uproot.rootio.ROOTDirectory.iterclasses>` iterate over *(key name, class object)* pairs in this directory.\n\n    - :py:meth:`keys <uproot.rootio.ROOTDirectory.keys>` return key names in this directory.\n\n    - :py:meth:`values <uproot.rootio.ROOTDirectory.values>` return objects in this directory.\n\n    - :py:meth:`items <uproot.rootio.ROOTDirectory.items>` return *(key name, object)* pairs in this directory, like a ``dict``.\n\n    - :py:meth:`classes <uproot.rootio.ROOTDirectory.classes>` return *(key name, class object)* pairs in this directory.\n\n    - :py:meth:`allkeys <uproot.rootio.ROOTDirectory.allkeys>` return keys at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`keys <uproot.rootio.ROOTDirectory.keys>`).\n\n    - :py:meth:`allvalues <uproot.rootio.ROOTDirectory.allvalues>` return objects at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`values <uproot.rootio.ROOTDirectory.values>`).\n\n    - :py:meth:`allitems <uproot.rootio.ROOTDirectory.allitems>` return *(key name, object)* pairs at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`items <uproot.rootio.ROOTDirectory.items>`).\n\n    - :py:meth:`allclasses <uproot.rootio.ROOTDirectory.allclasses>` return *(key name, class object)* pairs at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`classes <uproot.rootio.ROOTDirectory.classes>`).\n"""""", width=TEXT_WIDTH)\n\n_method(uproot.rootio.ROOTDirectory.get).__doc__ = wrap(\nu""""""Read an object from the ROOT file or directory by name.\n\n    Parameters\n    ----------\n    name : str (str)\n        name of the object. Any text before a ""``/``"" is interpreted as a subdirectory, and subdirectories of any depth may be searched. A number after a ""``;``"" indicates a `TKey <uproot.rootio.TKey>` cycle.\n\n    cycle : ``None`` or int\n        `TKey <uproot.rootio.TKey>` cycle number to disambiguate keys of the same name. This argument overrides a number after a ""``;``"".\n\n    Returns\n    -------\n    :py:class:`ROOTStreamedObject <uproot.rootio.ROOTStreamedObject>`\n        a freshly read object from the ROOT file.\n\n    Notes\n    -----\n\n    This method, without the ``cycle`` argument, can be accessed more directly through square brackets (``__getitem__``) on the :py:class:`ROOTDirectory <uproot.rootio.ROOTDirectory>` object.\n"""""".format(**rootdirectory_fragments), width=TEXT_WIDTH)\n\n_method(uproot.rootio.ROOTDirectory.iterkeys).__doc__ = wrap(\nu""""""Iterate over key names in this directory.\n\n    This method does not read objects.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filterclass}\n\n    Returns\n    -------\n    iterator over bytes\n        names of objects and subdirectories in the file.\n\n    Notes\n    -----\n\n    This method can be accessed more directly by simply iterating over a :py:class:`ROOTDirectory <uproot.rootio.ROOTDirectory>` object.\n"""""".format(**rootdirectory_fragments), width=TEXT_WIDTH)\n\n_method(uproot.rootio.ROOTDirectory.itervalues).__doc__ = wrap(\nu""""""Iterate over objects in this directory.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filterclass}\n\n    Returns\n    -------\n    iterator over :py:class:`ROOTStreamedObject <uproot.rootio.ROOTStreamedObject>`\n        freshly read objects from the ROOT file.\n"""""".format(**rootdirectory_fragments), width=TEXT_WIDTH)\n\n_method(uproot.rootio.ROOTDirectory.iteritems).__doc__ = wrap(\nu""""""Iterate over *(key name, object)* pairs in this directory, like a ``dict``.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filterclass}\n\n    Returns\n    -------\n    iterator over (bytes, :py:class:`ROOTStreamedObject <uproot.rootio.ROOTStreamedObject>`)\n        name-object pairs from the file.\n"""""".format(**rootdirectory_fragments), width=TEXT_WIDTH)\n\n_method(uproot.rootio.ROOTDirectory.iterclasses).__doc__ = wrap(\nu""""""Iterate over *(key name, class object)* pairs in this directory.\n\n    This method does not read objects.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filterclass}\n\n    Returns\n    -------\n    iterator over (bytes, class object)\n        name-class object pairs from the file.\n"""""".format(**rootdirectory_fragments), width=TEXT_WIDTH)\n\n_method(uproot.rootio.ROOTDirectory.keys).__doc__ = wrap(\nu""""""Return key names in this directory.\n\n    This method does not read objects.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filterclass}\n\n    Returns\n    -------\n    list of bytes\n        names of objects and subdirectories in the file.\n"""""".format(**rootdirectory_fragments), width=TEXT_WIDTH)\n\n_method(uproot.rootio.ROOTDirectory.values).__doc__ = wrap(\nu""""""Return objects in this directory.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filterclass}\n\n    Returns\n    -------\n    list of :py:class:`ROOTStreamedObject <uproot.rootio.ROOTStreamedObject>`\n        freshly read objects from the ROOT file.\n"""""".format(**rootdirectory_fragments), width=TEXT_WIDTH)\n\n_method(uproot.rootio.ROOTDirectory.items).__doc__ = wrap(\nu""""""Return *(key name, object)* pairs in this directory, like a ``dict``.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filterclass}\n\n    Returns\n    -------\n    list of (bytes, :py:class:`ROOTStreamedObject <uproot.rootio.ROOTStreamedObject>`)\n        name-object pairs from the file.\n"""""".format(**rootdirectory_fragments), width=TEXT_WIDTH)\n\n_method(uproot.rootio.ROOTDirectory.classes).__doc__ = wrap(\nu""""""Return *(key name, class object)* pairs in this directory.\n\n    This method does not read objects.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filterclass}\n\n    Returns\n    -------\n    list of (bytes, class object)\n        name-class object pairs from the file.\n"""""".format(**rootdirectory_fragments), width=TEXT_WIDTH)\n\n_method(uproot.rootio.ROOTDirectory.allkeys).__doc__ = wrap(\nu""""""Return keys at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`keys <uproot.rootio.ROOTDirectory.keys>`).\n\n    This method does not read objects.\n\n    Parameters\n    ----------\n    {filtername}\n\n    {filterclass}\n\n    Returns\n    -------\n    list of bytes\n        names of objects and subdirectories in the file.\n"""""".format(**rootdirectory_fragments), width=TEXT_WIDTH)\n\n_method(uproot.rootio.ROOTDirectory.allvalues).__doc__ = wrap(\nu""""""Return objects at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`values <uproot.rootio.ROOTDirectory.values>`).\n\n    Parameters\n    ----------\n    {filtername}\n\n    {filterclass}\n\n    Returns\n    -------\n    list of :py:class:`ROOTStreamedObject <uproot.rootio.ROOTStreamedObject>`\n        freshly read objects from the ROOT file.\n"""""".format(**rootdirectory_fragments), width=TEXT_WIDTH)\n\n_method(uproot.rootio.ROOTDirectory.allitems).__doc__ = wrap(\nu""""""Return *(key name, object)* pairs at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`items <uproot.rootio.ROOTDirectory.items>`).\n\n    Parameters\n    ----------\n    {filtername}\n\n    {filterclass}\n\n    Returns\n    -------\n    list of (bytes, :py:class:`ROOTStreamedObject <uproot.rootio.ROOTStreamedObject>`)\n        name-object pairs from the file.\n"""""".format(**rootdirectory_fragments), width=TEXT_WIDTH)\n\n_method(uproot.rootio.ROOTDirectory.allclasses).__doc__ = wrap(\nu""""""Return *(key name, class object)* pairs at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`classes <uproot.rootio.ROOTDirectory.classes>`).\n\n    This method does not read objects.\n\n    Parameters\n    ----------\n    {filtername}\n\n    {filterclass}\n\n    Returns\n    -------\n    list of (bytes, class object)\n        name-class object pairs from the file.\n"""""".format(**rootdirectory_fragments), width=TEXT_WIDTH)\n\n################################################################ uproot.rootio.ROOTObject and uproot.rootio.ROOTStreamedObject\n\nuproot.rootio.ROOTObject.__doc__ = wrap(\nu""""""Superclass of all objects read out of a ROOT file (except :py:class:`ROOTDirectory <uproot.rootio.ROOTDirectory>`).\n\n    If a :py:class:`ROOTObject <uproot.rootio.ROOTObject>` is not a :py:class:`ROOTStreamedObject <uproot.rootio.ROOTStreamedObject>`, then its class definition is hard-coded, not derived from the file\'s *streamer info*.\n"""""", width=TEXT_WIDTH)\n\nuproot.rootio.ROOTStreamedObject.__doc__ = wrap(\nu""""""Superclass of all objects read out of a ROOT file with an automatically generated class, derived from the file\'s *streamer info*.\n\n    Each subclass of a :py:class:`ROOTStreamedObject <uproot.rootio.ROOTStreamedObject>` has a ``classversion`` attribute, corresponding to the class version in the *streamer info*. If this version does not match the version of the serialized class, an error is raised during the read.\n"""""", width=TEXT_WIDTH)\n\n################################################################ uproot.tree fragments\n\ntree_fragments = {\n    # entrystart\n    ""entrystart"": u""""""entrystart : ``None`` or int\n        entry at which reading starts (inclusive). If ``None`` *(default)*, start at the beginning of the branch."""""",\n\n    # entrystop\n    ""entrystop"": u""""""entrystop : ``None`` or int\n        entry at which reading stops (exclusive). If ``None`` *(default)*, stop at the end of the branch."""""",\n\n    # entrysteps\n    ""entrysteps"": u""""""entrysteps : ``None``, positive int, ``float(""inf"")``, string matching number + /[kMGTPEZY]?B/i, or iterable of *(int, int)* pairs\n        if ``None`` *(default)*, iterate in steps of TTree clusters (number of entries for which all branches\' baskets align); if an integer, iterate in steps of equal numbers of entries (except at the end of a file); if infinite, take file-sized steps; if a string, iterate in steps of approximately equal memory, given by a memory size string; otherwise, iterate in explicit, user-specified *(start, stop)* intervals (""start"" is inclusive and ""stop"" is exclusive)."""""",\n\n    # entrysteps_tree\n    ""entrysteps_tree"": u""""""entrysteps : ``None``, positive int, ``float(""inf"")``, string matching number + /[kMGTPEZY]?B/i, or iterable of *(int, int)* pairs\n        if ``None`` *(default)*, iterate in steps of TTree clusters (number of entries for which all branches\' baskets align); if an integer, iterate in steps of equal numbers of entries; if infinite, iterate over the whole file in one step; if a string, iterate in steps of approximately equal memory, given by a memory size string; otherwise, iterate in explicit, user-specified *(start, stop)* intervals (""start"" is inclusive and ""stop"" is exclusive)."""""",\n\n    # branch\n    ""branch"": u""""""branch : str\n        name of the branch to read."""""",\n\n    # interpretation\n    ""interpretation"": u""""""interpretation : ``None`` or :py:class:`Interpretation <uproot.interp.interp.Interpretation>`\n        the meaning imposed upon the bytes of the file and the ultimate form to instantiate. If ``None`` *(default)*, :py:func:`interpret <uproot.interp.auto.interpret>` will be applied to the branch to generate an interpretation."""""",\n\n    # branches\n    ""branches"": u""""""branches\n        - if ``None`` *(default)*, select all *interpretable* branches;\n        - if a list of str, select branches by name;\n        - if a single str, select a single branch (though the return value is still a container type, not a single array). The selection by string can include filename-like glob characters (``*``, ``?``, ``[...]``) or it can be a full regular expression (Python flavored) if surrounded by slashes, like ``/pattern/i`` (where ``i`` is an optional `Python re flag <https://docs.python.org/2/library/re.html>`_);\n        - if a function :py:class:`TBranchMethods <uproot.tree.TBranchMethods>` \\u21d2 ``True`` or ``False``, select branches that return ``True``;\n        - if a function :py:class:`TBranchMethods <uproot.tree.TBranchMethods>` \\u21d2 ``None`` or :py:class:`Interpretation <uproot.interp.interp.Interpretation>`, select branches for which the function does not return ``None`` and use the interpretation it returns otherwise;\n        - if a ``dict`` of str \\u2192 :py:class:`Interpretation <uproot.interp.interp.Interpretation>`, select branches named by keys and use interpretations from the associated values."""""",\n\n    # outputtype\n    ""outputtype"": u""""""outputtype : type\n        constructor for the desired yield type, such as ``dict`` *(default)*, ``OrderedDict``, ``tuple``, ``namedtuple``, custom user class, etc."""""",\n\n    # namedecode\n    ""namedecode"": u""""""namedecode : None or str\n        if ``None`` *(default)* return names as uninterpreted byte strings (type ``bytes`` in Python 3); if a string like ``""ascii""`` or ``""utf-8""``, decode bytes to a string using the specified encoding."""""",\n\n    # reportpath\n    ""reportpath"": u""""""reportpath : bool\n        if ``True`` *(not default)*, yield the current path (string) before the arrays (and any other reported objects) as a tuple."""""",\n\n    # reportfile\n    ""reportfile"": u""""""reportfile : bool\n        if ``True``, *(not default)*, yield the current file (object) before the arrays (and any other reported objects except reportpath) as a tuple."""""",\n\n    # reportentries\n    ""reportentries"": u""""""reportentries : bool\n        if ``True`` *(not default)*, yield the current entry start and entry stop (integers) before the arrays, where *entry start* is inclusive and *entry stop* is exclusive."""""",\n\n    # flatten\n    ""flatten"": u""""""flatten : None or bool\n        if ``True``, convert JaggedArrays into flat Numpy arrays. If False *(default)*, make JaggedArrays lists. If None, remove JaggedArrays."""""",\n\n    # flatname\n    ""flatname"": u""""""flatname : None or (branchname, fieldname, index) \\u2192 str\n        if ``None`` *(default)*, use ``uproot._connect._pandas.default_flatname`` to convert a branchname with a subfield and regular index number into a Pandas column name; otherwise, take a user-defined function."""""",\n\n    # profile\n    ""profile"": u""""""profile : None or str\n        if a string *(not default)*, format the lazy arrays using a module from uproot_methods.profiles named by the string."""""",\n\n    # awkwardlib\n    ""awkwardlib"": u""""""awkwardlib : ``None``, str, or module\n        if ``None`` *(default)*, use ``import awkward`` to get awkward-array constructors. Otherwise, parse the module string name or use the provided module."""""",\n\n    # cache\n    ""cache"": u""""""cache : ``None`` or ``dict``-like object\n        if not ``None`` *(default)*, fully interpreted arrays will be saved in the ``dict``-like object for later use. Accessing the same arrays with a different interpretation or a different entry range results in a cache miss."""""",\n\n    # basketcache\n    ""basketcache"": u""""""basketcache : ``None`` or ``dict``-like object\n        if not ``None`` *(default)*, raw basket data will be saved in the ``dict``-like object for later use. Accessing the same arrays with a different interpretation or a different entry range fully utilizes this cache, since the interpretation/construction from baskets is performed after retrieving data from this cache."""""",\n\n    # keycache\n    ""keycache"": u""""""keycache : ``None`` or ``dict``-like object\n        if not ``None`` *(default)*, basket TKeys will be saved in the ``dict``-like object for later use. TKeys are small, but require file access, so caching them can speed up repeated access."""""",\n\n    # executor\n    ""executor"": u""""""executor : `concurrent.futures.Executor <https://docs.python.org/3/library/concurrent.futures.html>`_\n        if not ``None`` *(default)*, parallelize basket-reading and decompression by scheduling tasks on the executor. Assumes caches are thread-safe."""""",\n\n    # blocking\n    ""blocking"": u""""""blocking : bool\n        if ``True`` *(default)*, do not exit this function until the arrays are read, and return those arrays. If ``False``, exit immediately and return a zero-argument function. That zero-argument function returns the desired array, and it blocks until the array is available. This option is only useful with a non-``None`` executor."""""",\n\n    # persistvirtual\n    ""persistvirtual"": u""""""persistvirtual : bool\n        if ``False`` *(default)*, the resulting awkward.VirtualArrays would convert themselves into real arrays (materialize) before being saved in awkward-array\'s persistence methods; if ``True``, the ""virtualness"" of the arrays is preserved\\u2014that is, only instructions for reconstituting the arrays is saved, not the array data themselves."""""",\n\n    # recursive\n    ""recursive"": u""""""recursive : bool\n        if ``False`` *(default)*, only iterate at this tree/branch level; if ``True``, depth-first iterate over all subbranches as well."""""",\n\n    # filtername\n    ""filtername"": u""""""filtername : function: str \\u21d2 bool\n        only branches for which ``filtername(name)`` returns ``True`` are returned. Default returns ``True`` for all input."""""",\n\n    # filtertitle\n    ""filtertitle"": u""""""filtertitle : function: str \\u21d2 bool\n        only branches for which ``filtertitle(title)`` returns ``True`` are returned. Default returns ``True`` for all input."""""",\n\n    # i\n    ""i"": u""""""i : non-negative int\n        basket number (must be greater than or equal to zero and strictly less than *numbaskets*)."""""",\n\n    # chunked\n    ""chunked"": u""""""chunked : bool\n        if ``True`` *(default)*, produced chunked lazy arrays using awkward.ChunkedArray.   If ``False``, produce bare VirtualArrays.  This option implies ``entrysteps = float(\'inf\')``."""""",\n\n    }\n\n################################################################ uproot.tree.iterate\n\nuproot.tree.iterate.__doc__ = wrap(\nu""""""Opens a series of ROOT files (local or remote), yielding the same number of entries from all selected branches in each step.\n\n    Depending on the ""entrysteps"" parameter, the number of entries in one step may differ from the number of entries in the next step, but in every step, the same number of entries is retrieved from all *baskets.*\n\n    All but the first two parameters are identical to :py:meth:`uproot.tree.TreeMethods.iterate`.\n\n    Parameters\n    ----------\n    path : str or list of str\n        glob pattern(s) for local file paths (POSIX wildcards like ""``*``"") or URLs specifying the locations of the files. A list of filenames are processed in the given order, but glob patterns get pre-sorted to ensure a predictable order.\n\n    treepath : str\n        path within each ROOT file to find the TTree (may include ""``/``"" for subdirectories or ""``;``"" for cycle numbers).\n\n    {branches}\n\n    {entrysteps}\n\n    {outputtype}\n\n    {namedecode}\n\n    {reportpath}\n\n    {reportfile}\n\n    {reportentries}\n\n    {flatten}\n\n    {flatname}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    {blocking}\n\n    {localsource}\n\n    {xrootdsource}\n\n    {httpsource}\n\n    {options}\n\n    Returns\n    -------\n    iterator over (str, :py:class:`ROOTDirectory <uproot.rootio.ROOTDirectory>`, int, int, outputtype) (if *reportpath*, *reportfile*, *reportentries*) or just outputtype (otherwise)\n        aligned array segments from the files.\n    """""".format(**dict(list(open_fragments.items()) + list(tree_fragments.items()))), width=TEXT_WIDTH)\n\n################################################################ uproot.pandas.iterate\n\nuproot.pandas.iterate.__doc__ = wrap(\nu""""""Opens a series of ROOT files (local or remote), yielding Pandas DataFrames in each step.\n\n    Depending on the ""entrysteps"" parameter, the number of entries in one step may differ from the number of entries in the next step, but in every step, the same number of entries is retrieved from all *baskets.*\n\n    Parameters\n    ----------\n    path : str or list of str\n        glob pattern(s) for local file paths (POSIX wildcards like ""``*``"") or URLs specifying the locations of the files. A list of filenames are processed in the given order, but glob patterns get pre-sorted to ensure a predictable order.\n\n    treepath : str\n        path within each ROOT file to find the TTree (may include ""``/``"" for subdirectories or ""``;``"" for cycle numbers).\n\n    {branches}\n\n    {entrysteps}\n\n    {namedecode}\n\n    {reportpath}\n\n    {reportfile}\n\n    {flatten}\n\n    {flatname}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    {blocking}\n\n    {localsource}\n\n    {xrootdsource}\n\n    {httpsource}\n\n    {options}\n\n    Returns\n    -------\n    iterator over (str, :py:class:`ROOTDirectory <uproot.rootio.ROOTDirectory>`, pandas.Dataframe) (if *reportpath* and *reportfile*) or just pandas.DataFrame (otherwise)\n        aligned array segments from the files.\n    """""".format(**dict(list(open_fragments.items()) + list(tree_fragments.items()))), width=TEXT_WIDTH)\n\n################################################################ uproot.tree.TTreeMethods\n\nuproot.tree.TTreeMethods.__doc__ = wrap(\nu""""""Adds array reading methods to TTree objects that have been streamed from a ROOT file.\n\n    - square brackets (``__getitem__``) returns a branch by name (see :py:meth:`get <uproot.tree.TTreeMethods.get>`).\n    - the ``len`` function (``__len__``) returns the number of entries (same as ``numentries``).\n    - iteration (``__iter__``) has no implementation. This is to avoid confusion between iterating over all branches (probably not what you want, but fitting the pattern set by :py:class:`ROOTDirectory <uproot.rootio.ROOTDirectory>` and ``dict``) and iterating over the data.\n\n    **Attributes, properties, and methods:**\n\n    - **name** (*bytes*) name of the TTree.\n    - **title** (*bytes*) title of the TTree.\n    - **numentries** (*int*) number of entries in the TTree (same as ``len``).\n    - **pandas** connector to `Pandas <http://pandas.pydata.org/>`_ functions\n\n    - :py:meth:`get <uproot.tree.TTreeMethods.get>` return a branch by name (at any level of depth).\n    - :py:meth:`iterkeys <uproot.tree.TTreeMethods.iterkeys>` iterate over branch names.\n    - :py:meth:`itervalues <uproot.tree.TTreeMethods.itervalues>` iterate over branches.\n    - :py:meth:`iteritems <uproot.tree.TTreeMethods.iteritems>` iterate over *(branch name, branch)* pairs.\n    - :py:meth:`keys <uproot.tree.TTreeMethods.keys>` return branch names.\n    - :py:meth:`values <uproot.tree.TTreeMethods.values>` return branches.\n    - :py:meth:`items <uproot.tree.TTreeMethods.items>` return *(branch name, branch)* pairs.\n    - :py:meth:`allkeys <uproot.tree.TTreeMethods.allkeys>` return branch names at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`keys <uproot.tree.TTreeMethods.keys>`).\n    - :py:meth:`allvalues <uproot.tree.TTreeMethods.allvalues>` return branches at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`values <uproot.tree.TTreeMethods.values>`).\n    - :py:meth:`allitems <uproot.tree.TTreeMethods.allitems>` return *(branch name, branch)* pairs at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`items <uproot.tree.TTreeMethods.items>`).\n    - :py:meth:`clusters <uproot.tree.TTreeMethods.clusters>` iterate over *(int, int)* pairs representing cluster entry starts and stops in this TTree.\n    - :py:meth:`mempartitions <uproot.tree.TTreeMethods.mempartitions>` iterate over *(int, int)* pairs representing entry starts and stops that attempt to maintain a constant memory footprint.\n\n    **Methods for reading array data:**\n\n    - :py:meth:`array <uproot.tree.TTreeMethods.array>` read one branch into an array (or other object if provided an alternate *interpretation*).\n    - :py:meth:`arrays <uproot.tree.TTreeMethods.arrays>` read many branches into arrays (or other objects if provided alternate *interpretations*).\n    - :py:meth:`lazyarray <uproot.tree.TTreeMethods.lazyarray>` create a lazy array that would read the branch as needed.\n    - :py:meth:`lazyarrays <uproot.tree.TTreeMethods.lazyarrays>` create many lazy arrays.\n    - :py:meth:`iterate <uproot.tree.TTreeMethods.iterate>` iterate over many arrays at once, yielding the same number of entries from all selected branches in each step.\n"""""", width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.get).__doc__ = wrap(\nu""""""Return a branch by name (at any level of depth).\n\n    Parameters\n    ----------\n    name : str\n        name of the branch to return.\n\n    Returns\n    -------\n    :py:class:`TBranch <upoot.tree.TBranchMethods>`\n        selected branch.\n\n    Notes\n    -----\n\n    This method can be accessed more directly through square brackets (``__getitem__``) on the :py:class:`TTree <uproot.tree.TTreeMethods>` object.\n"""""", width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.iterkeys).__doc__ = wrap(\nu""""""Iterate over branch names.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    iterator over bytes\n        names of branches.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.itervalues).__doc__ = wrap(\nu""""""Iterate over branches.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    iterator over :py:class:`TBranch <uproot.tree.TBranchMethods>`\n        branches.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.iteritems).__doc__ = wrap(\nu""""""Iterate over *(branch name, branch)* pairs.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    iterator over (bytes, :py:class:`TBranch <uproot.tree.TBranchMethods>`)\n        name-branch pairs.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.keys).__doc__ = wrap(\nu""""""Return branch names.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    list of bytes\n        names of branches.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.values).__doc__ = wrap(\nu""""""Return branches.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    list of :py:class:`TBranch <uproot.tree.TBranchMethods>`\n        branches.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.items).__doc__ = wrap(\nu""""""Return *(branch name, branch)* pairs.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    list of (bytes, :py:class:`TBranch <uproot.tree.TBranchMethods>`)\n        name-branch pairs.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.allkeys).__doc__ = wrap(\nu""""""Return branch names at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`keys <uproot.tree.TTreeMethods.keys>`).\n\n    Parameters\n    ----------\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    list of bytes\n        names of branches.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.allvalues).__doc__ = wrap(\nu""""""Return branches at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`values <uproot.tree.TTreeMethods.values>`).\n\n    Parameters\n    ----------\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    list of :py:class:`TBranch <uproot.tree.TBranchMethods>`\n        branches.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.allitems).__doc__ = wrap(\nu""""""Return *(branch name, branch)* pairs at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`items <uproot.tree.TTreeMethods.items>`).\n\n    Parameters\n    ----------\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    list of (bytes, :py:class:`TBranch <uproot.tree.TBranchMethods>`\n        name-branch pairs.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.clusters).__doc__ = wrap(\nu""""""Return entry starts and stops as *(int, int)* pairs representing clusters for a given set of branches this TTree.\n\n    Rather than using ROOT\'s self-reported clusters (which don\'t exist in every ROOT file), this method finds the minimal step sizes in which a given set of branches have basket thresholds for the same entry number. For a single branch, this is exactly the basket boundaries. It is possible for a given set of branches to never line up, in which case, the cluster is the entire file.\n\n    Parameters\n    ----------\n    {branches}\n\n    {entrystart}\n\n    {entrystop}\n\n    strict : bool\n        if ``False`` *(default)*, the potential ``start, stop`` pair must satisfy ``entrystart < stop and start < entrystop``; if ``True``, the potential ``start, stop`` pair must satisfy ``entrystart <= start and stop <= entrystop``.\n\n    Returns\n    -------\n    list of (int, int)\n        start (inclusive) and stop (exclusive) pairs for each cluster.\n"""""", width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.mempartitions).__doc__ = wrap(\nu""""""Return entry starts and stops as *(int, int)* pairs of (approximately) equal-memory partitions for a given set of branches in this TTree.\n\n    Similar to :py:meth:`clusters <uproot.tree.TTreeMethods.clusters>` in that it provides a list of (start, stop) entry pairs, but instead of fitting baskets, this method attempts to keep the memory use constant.\n\n    Parameters\n    ----------\n    numbytes : positive number (int or float) or string matching number + /[kMGTPEZY]?B/i\n        target number of bytes in each step (not an upper limit, but an average); if a string, parse the memory size\n\n    {branches}\n\n    {entrystart}\n\n    {entrystop}\n\n    {keycache}\n\n    linear : bool\n        if ``True`` *(default)*, the step size is uniform (same number of entries in each step); any variations in entry size as a function of entry number are averaged over. Non-linear steps (``False``), which would take into account bigger entry sizes at the beginning or end of the file, have not been implemented.\n\n    Returns\n    -------\n    list of (int, int)\n        start (inclusive) and stop (exclusive) pairs for each equal-memory partition.\n"""""", width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.array).__doc__ = wrap(\nu""""""Read one branch into an array (or other object if provided an alternate *interpretation*).\n\n    Parameters\n    ----------\n    {branch}\n\n    {interpretation}\n\n    {entrystart}\n\n    {entrystop}\n\n    {flatten}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    {blocking}\n\n    Returns\n    -------\n    array or other object, depending on *interpretation*.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.arrays).__doc__ = wrap(\nu""""""Read many branches into arrays (or other objects if provided alternate *interpretations*).\n\n    Parameters\n    ----------\n    {branches}\n\n    {outputtype}\n\n    {namedecode}\n\n    {entrystart}\n\n    {entrystop}\n\n    {flatten}\n\n    {flatname}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    {blocking}\n\n    Returns\n    -------\n    outputtype of arrays or other objects, depending on *interpretation*\n        branch data.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.lazyarray).__doc__ = wrap(\nu""""""Create a lazy array that would read the branch as needed.\n\n    Parameters\n    ----------\n    {branch}\n\n    {interpretation}\n\n    {entrysteps_tree}\n\n    {entrystart}\n\n    {entrystop}\n\n    {flatten}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    {persistvirtual}\n\n    {chunked}\n\n    Returns\n    -------\n    ChunkedArray of VirtualArrays or VirtualArray\n        lazy version of the array.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.lazyarrays).__doc__ = wrap(\nu""""""Create a table of lazy arrays.\n\n    Parameters\n    ----------\n    {branches}\n\n    {namedecode}\n\n    {entrysteps}\n\n    {entrystart}\n\n    {entrystop}\n\n    {flatten}\n\n    {profile}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    {persistvirtual}\n\n    {chunked}\n\n    Returns\n    -------\n    ChunkedArray of Table of VirtualArrays or Table of VirtualArrays\n        lazy branch data.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TTreeMethods.iterate).__doc__ = wrap(\nu""""""Iterate over many arrays at once, yielding the same number of entries from all selected branches in each step.\n\n    Depending on the ""entrysteps"" parameter, the number of entries in one step may differ from the number of entries in the next step, but in every step, the same number of entries is retrieved from all *baskets.*\n\n    Parameters\n    ----------\n    {branches}\n\n    {entrysteps_tree}\n\n    {outputtype}\n\n    {namedecode}\n\n    {reportentries}\n\n    {entrystart}\n\n    {entrystop}\n\n    {flatten}\n\n    {flatname}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    {blocking}\n\n    Returns\n    -------\n    iterator over (int, int, outputtype) (if *reportentries*) or just outputtype (otherwise)\n        aligned array segments from the TTree.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n################################################################ uproot.tree.TBranchMethods\n\nuproot.tree.TBranchMethods.__doc__ = wrap(\nu""""""Adds array reading methods to TBranch objects that have been streamed from a ROOT file.\n\n    - square brackets (``__getitem__``) returns a subbranch by name (see :py:meth:`get <uproot.tree.TBranchMethods.get>`).\n    - the ``len`` function (``__len__``) returns the number of entries (same as ``numentries``).\n    - iteration (``__iter__``) has no implementation. This is to avoid confusion between iterating over all subbranches (probably not what you want, but fitting the pattern set by :py:class:`ROOTDirectory <uproot.rootio.ROOTDirectory>` and ``dict``) and iterating over the data.\n\n    **Attributes, properties, and methods:**\n\n    - **name** (*bytes*) name of the TBranch.\n    - **title** (*bytes*) title of the TBranch.\n    - **compression** (:py:class:`Compression <uproot.source.compressed.Compression>`) the compression algorithm and level specified in the TBranch header. (Actual compression used may differ.)\n    - :py:meth:`get <uproot.tree.TBranchMethods.get>` return a subbranch by name (at any level of depth).\n    - :py:meth:`iterkeys <uproot.tree.TBranchMethods.iterkeys>` iterate over subbranch names.\n    - :py:meth:`itervalues <uproot.tree.TBranchMethods.itervalues>` iterate over subbranches.\n    - :py:meth:`iteritems <uproot.tree.TBranchMethods.iteritems>` iterate over *(subbranch name, subbranch)* pairs.\n    - :py:meth:`keys <uproot.tree.TBranchMethods.keys>` return subbranch names.\n    - :py:meth:`values <uproot.tree.TBranchMethods.values>` return subbranches.\n    - :py:meth:`items <uproot.tree.TBranchMethods.items>` return *(subbranch name, subbranch)* pairs.\n    - :py:meth:`allkeys <uproot.tree.TBranchMethods.allkeys>` return subbranch names at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`keys <uproot.tree.TBranchMethods.keys>`).\n    - :py:meth:`allvalues <uproot.tree.TBranchMethods.allvalues>` return subbranches at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`values <uproot.tree.TBranchMethods.values>`).\n    - :py:meth:`allitems <uproot.tree.TBranchMethods.allitems>` return *(subbranch name, subbranch)* pairs at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`items <uproot.tree.TBranchMethods.items>`).\n\n    **Branch information:**\n\n    - **numentries** (*int*) number of entries in the TBranch (same as ``len``).\n    - **numbaskets** (*int*) number of baskets in the TBranch.\n    - :py:meth:`uncompressedbytes <uproot.tree.TBranchMethods.uncompressedbytes>` the number of bytes contained in the TBranch (data and offsets; not including any key headers) *after* decompression, if applicable.\n    - :py:meth:`compressedbytes <uproot.tree.TBranchMethods.compressedbytes>` the number of bytes contained in the TBranch (data and offsets; not including any key headers) *before* decompression, if applicable.\n    - :py:meth:`compressionratio <uproot.tree.TBranchMethods.compressionratio>` the uncompressed bytes divided by compressed bytes (greater than or equal to 1).\n    - :py:meth:`numitems <uproot.tree.TBranchMethods.numitems>` the number of items in the TBranch, under a given interpretation.\n\n    **Basket information:**\n\n    - :py:meth:`basket_entrystart <uproot.tree.TBranchMethods.basket_entrystart>` the starting entry for a given basket (inclusive).\n    - :py:meth:`basket_entrystop <uproot.tree.TBranchMethods.basket_entrystop>` the stopping entry for a given basket (exclusive).\n    - :py:meth:`basket_numentries <uproot.tree.TBranchMethods.basket_numentries>` the number of entries in a given basket.\n    - :py:meth:`basket_uncompressedbytes <uproot.tree.TBranchMethods.basket_uncompressedbytes>` the number of bytes contained in the basket (data and offsets; not including any key headers) *after* decompression, if applicable.\n    - :py:meth:`basket_compressedbytes <uproot.tree.TBranchMethods.basket_compressedbytes>` the number of bytes contained in the basket (data and offsets; not including any key headers) *before* decompression, if applicable.\n    - :py:meth:`basket_numitems <uproot.tree.TBranchMethods.basket_numitems>` the number of items in the basket, under a given interpretation.\n    - :py:meth:`mempartitions <uproot.tree.TBranchMethods.mempartitions>` iterate over *(int, int)* pairs representing entry starts and stops that attempt to maintain a constant memory footprint.\n\n    **Methods for reading array data:**\n\n    - :py:meth:`array <uproot.tree.TBranchMethods.array>` read the branch into an array (or other object if provided an alternate *interpretation*).\n    - :py:meth:`lazyarray <uproot.tree.TBranchMethods.lazyarray>` create a lazy array that would read the branch as needed.\n    - :py:meth:`basket <uproot.tree.TBranchMethods.basket>` read a single basket into an array.\n    - :py:meth:`baskets <uproot.tree.TBranchMethods.baskets>` read baskets into a list of arrays.\n    - :py:meth:`iterate_baskets <uproot.tree.TBranchMethods.iterate_baskets>` iterate over baskets.\n"""""", width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.get).__doc__ = wrap(\nu""""""Return a subbranch by name (at any level of depth).\n\n    Parameters\n    ----------\n    name : str\n        name of the subbranch to return.\n\n    Returns\n    -------\n    :py:class:`TBranch <upoot.tree.TBranchMethods>`\n        branch object.\n\n    Notes\n    -----\n\n    This method can be accessed more directly through square brackets (``__getitem__``) on the :py:class:`TBranch <uproot.tree.TBranchMethods>` object.\n"""""", width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.iterkeys).__doc__ = wrap(\nu""""""Iterate over subbranch names.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    iterator over bytes\n        subbranch names.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.itervalues).__doc__ = wrap(\nu""""""Iterate over subbranches.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    iterator over :py:class:`TBranch <uproot.tree.TBranchMethods>`\n        subbranches.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.iteritems).__doc__ = wrap(\nu""""""Iterate over *(subbranch name, subbranch)* pairs.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    iterator over (bytes, :py:class:`TBranch <uproot.tree.TBranchMethods>`)\n        *(subbranch name, subbranch)* pairs.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.keys).__doc__ = wrap(\nu""""""Return subbranch names.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    list of bytes\n        subbranch names.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.values).__doc__ = wrap(\nu""""""Return subbranches.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    list of :py:class:`TBranch <uproot.tree.TBranchMethods>`\n        subbranches.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.items).__doc__ = wrap(\nu""""""Return *(subbranch name, subbranch)* pairs.\n\n    Parameters\n    ----------\n    {recursive}\n\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    list of (bytes, :py:class:`TBranch <uproot.tree.TBranchMethods>`)\n        *(subbranch name, subbranch)* pairs.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.allkeys).__doc__ = wrap(\nu""""""Return subbranch names at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`keys <uproot.tree.TBranchMethods.keys>`).\n\n    Parameters\n    ----------\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    list of bytes\n        subbranch names.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.allvalues).__doc__ = wrap(\nu""""""Return subbranches at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`values <uproot.tree.TBranchMethods.values>`).\n\n    Parameters\n    ----------\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    list of :py:class:`TBranch <uproot.tree.TBranchMethods>`\n        subbranches.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.allitems).__doc__ = wrap(\nu""""""Return *(subbranch name, subbranch)* pairs at all levels of depth (shortcut for passing ``recursive=True`` to :py:meth:`items <uproot.tree.TBranchMethods.items>`).\n\n    Parameters\n    ----------\n    {filtername}\n\n    {filtertitle}\n\n    Returns\n    -------\n    list of (bytes, :py:class:`TBranch <uproot.tree.TBranchMethods>`\n        (subbranch name, subbranch)* pairs.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.uncompressedbytes).__doc__ = wrap(\nu""""""The number of bytes contained in the TBranch (data and offsets; not including any key headers) *after* decompression, if applicable.\n\n    Parameters\n    ----------\n    {keycache}\n\n    Returns\n    -------\n    int\n        uncompressed bytes.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.compressedbytes).__doc__ = wrap(\nu""""""The number of bytes contained in the TBranch (data and offsets; not including any key headers) *before* decompression, if applicable.\n\n    Parameters\n    ----------\n    {keycache}\n\n    Returns\n    -------\n    int\n        compressed bytes.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.compressionratio).__doc__ = wrap(\nu""""""The uncompressed bytes divided by compressed bytes (greater than or equal to 1).\n\n    Parameters\n    ----------\n    {keycache}\n\n    Returns\n    -------\n    float\n        compression ratio.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.numitems).__doc__ = wrap(\nu""""""The number of items in the TBranch, under a given interpretation.\n\n    Parameters\n    ----------\n    {interpretation}\n\n    {keycache}\n\n    Returns\n    -------\n    int\n        number of items.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.basket_entrystart).__doc__ = wrap(\nu""""""The starting entry for a given basket (inclusive).\n\n    Parameters\n    ----------\n    {i}\n\n    Returns\n    -------\n    int\n        starting entry.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.basket_entrystop).__doc__ = wrap(\nu""""""The stopping entry for a given basket (exclusive).\n\n    Parameters\n    ----------\n    {i}\n\n    Returns\n    -------\n    int\n        stopping entry.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.basket_numentries).__doc__ = wrap(\nu""""""The number of entries in a given basket.\n\n    Parameters\n    ----------\n    {i}\n\n    Returns\n    -------\n    int\n        number of entries.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.basket_uncompressedbytes).__doc__ = wrap(\nu""""""The number of bytes contained in the basket (data and offsets; not including any key headers) *after* decompression, if applicable.\n\n    Parameters\n    ----------\n    {i}\n\n    {keycache}\n\n    Returns\n    -------\n    int\n        number of uncompressed bytes.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.basket_compressedbytes).__doc__ = wrap(\nu""""""The number of bytes contained in the basket (data and offsets; not including any key headers) *before* decompression, if applicable.\n\n    Parameters\n    ----------\n    {i}\n\n    {keycache}\n\n    Returns\n    -------\n    int\n        number of compressed bytes.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.basket_numitems).__doc__ = wrap(\nu""""""The number of items in the basket, under a given interpretation.\n\n    Parameters\n    ----------\n    {i}\n\n    {interpretation}\n\n    {keycache}\n\n    Returns\n    -------\n    int\n        number of items.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.array).__doc__ = wrap(\nu""""""Read the branch into an array (or other object if provided an alternate *interpretation*).\n\n    Parameters\n    ----------\n    {interpretation}\n\n    {entrystart}\n\n    {entrystop}\n\n    {flatten}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    {blocking}\n\n    Returns\n    -------\n    array or other object, depending on *interpretation*\n        branch data.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.mempartitions).__doc__ = wrap(\nu""""""Return entry starts and stops as *(int, int)* pairs of (approximately) equal-memory partitions in this TBranch.\n\n    Similar to :py:meth:`clusters <uproot.tree.TTreeMethods.clusters>` in that it provides a list of (start, stop) entry pairs, but instead of fitting baskets, this method attempts to keep the memory use constant.\n\n    Parameters\n    ----------\n    numbytes : positive number (int or float) or string matching number + /[kMGTPEZY]?B/i\n        target number of bytes in each step (not an upper limit, but an average); if a string, parse the memory size\n\n    {entrystart}\n\n    {entrystop}\n\n    {keycache}\n\n    linear : bool\n        if ``True`` *(default)*, the step size is uniform (same number of entries in each step); any variations in entry size as a function of entry number are averaged over. Non-linear steps (``False``), which would take into account bigger entry sizes at the beginning or end of the file, have not been implemented.\n\n    Returns\n    -------\n    list of (int, int)\n        start (inclusive) and stop (exclusive) pairs for each equal-memory partition.\n"""""", width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.lazyarray).__doc__ = wrap(\nu""""""Create a lazy array that would read the branch as needed.\n\n    Parameters\n    ----------\n    {interpretation}\n\n    {entrysteps}\n\n    {entrystart}\n\n    {entrystop}\n\n    {flatten}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    {persistvirtual}\n\n    {chunked}\n\n    Returns\n    -------\n    ChunkedArray of VirtualArrays or VirtualArray\n        lazy version of branch data.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.basket).__doc__ = wrap(\nu""""""Read a single basket into an array.\n\n    Parameters\n    ----------\n    {i}\n\n    {interpretation}\n\n    {entrystart}\n\n    {entrystop}\n\n    {flatten}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    Returns\n    -------\n    array or other object, depending on *interpretation*\n        basket data.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.baskets).__doc__ = wrap(\nu""""""Read baskets into a list of arrays.\n\n    Parameters\n    ----------\n    {interpretation}\n\n    {entrystart}\n\n    {entrystop}\n\n    {flatten}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {reportentries}\n\n    {executor}\n\n    {blocking}\n\n    Returns\n    -------\n    list of arrays or other objects, depending on *interpretation*\n        basket data.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n_method(uproot.tree.TBranchMethods.iterate_baskets).__doc__ = wrap(\nu""""""Iterate over baskets.\n\n    Parameters\n    ----------\n    {interpretation}\n\n    {entrystart}\n\n    {entrystop}\n\n    {flatten}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {reportentries}\n\n    Returns\n    -------\n    iterator over arrays or other objects, depending on *interpretation*\n        basket data.\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n################################################################ uproot.tree.TTreeMethods.pandas\n\n_method(uproot._connect._pandas.TTreeMethods_pandas.df).__doc__ = wrap(\nu""""""Create a Pandas DataFrame from some branches.\n\n    Parameters\n    ----------\n    {branches}\n\n    namedecode : None or str\n        if ``""utf-8""`` *(default)* or other encoding name, decode column names as strings; if ``None``, return names as uninterpreted byte strings (type ``bytes`` in Python 3).\n\n    {entrystart}\n\n    {entrystop}\n\n    flatten : None or bool\n        if ``True`` *(default)*, convert JaggedArrays into flat Numpy arrays and turn the DataFrame index into a two-level MultiIndex to represent the structure. If False, make JaggedArrays into lists. If None, remove JaggedArrays.\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    Returns\n    -------\n    Pandas DataFrame\n        data frame (`see docs <http://pandas.pydata.org/pandas-docs/stable/api.html#dataframe>`_).\n"""""".format(**tree_fragments), width=TEXT_WIDTH)\n\n################################################################ uproot.tree.lazyarray(s)\n\nuproot.tree.lazyarray.__doc__ = wrap(\nu""""""Create a lazy array that would read from a set of files as needed.\n\n    Parameters\n    ----------\n\n    path : str or list of str\n        glob pattern(s) for local file paths (POSIX wildcards like ""``*``"") or URLs specifying the locations of the files. A list of filenames are processed in the given order, but glob patterns get pre-sorted to ensure a predictable order.\n\n    treepath : str\n        path within each ROOT file to find the TTree (may include ""``/``"" for subdirectories or ""``;``"" for cycle numbers).\n\n    branchname : str\n        path within each TTree to find the TBranch\n\n    {interpretation}\n\n    {namedecode}\n\n    {entrysteps}\n\n    {flatten}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    {persistvirtual}\n\n    {localsource}\n\n    {xrootdsource}\n\n    {httpsource}\n\n    {options}\n\n    Returns\n    -------\n    ChunkedArray of VirtualArrays\n        lazy files of lazy baskets.\n"""""".format(**dict(list(open_fragments.items()) + list(tree_fragments.items()))), width=TEXT_WIDTH)\n\nuproot.tree.lazyarrays.__doc__ = wrap(\nu""""""Create a lazy table that would read from a set of files as needed.\n\n    Parameters\n    ----------\n\n    path : str or list of str\n        glob pattern(s) for local file paths (POSIX wildcards like ""``*``"") or URLs specifying the locations of the files. A list of filenames are processed in the given order, but glob patterns get pre-sorted to ensure a predictable order.\n\n    treepath : str\n        path within each ROOT file to find the TTree (may include ""``/``"" for subdirectories or ""``;``"" for cycle numbers).\n\n    {branches}\n\n    {namedecode}\n\n    {entrysteps}\n\n    {flatten}\n\n    {profile}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    {persistvirtual}\n\n    {localsource}\n\n    {xrootdsource}\n\n    {httpsource}\n\n    {options}\n\n    Returns\n    -------\n    ChunkedArray of Table of VirtualArrays\n        lazy files of branches of lazy baskets.\n"""""".format(**dict(list(open_fragments.items()) + list(tree_fragments.items()))), width=TEXT_WIDTH)\n\n################################################################ uproot.tree.daskarray/daskframe\n\nuproot.tree.daskarray.__doc__ = wrap(\nu""""""Create a Dask array that would read from a set of files as needed.\n\n    Parameters\n    ----------\n\n    path : str or list of str\n        glob pattern(s) for local file paths (POSIX wildcards like ""``*``"") or URLs specifying the locations of the files. A list of filenames are processed in the given order, but glob patterns get pre-sorted to ensure a predictable order.\n\n    treepath : str\n        path within each ROOT file to find the TTree (may include ""``/``"" for subdirectories or ""``;``"" for cycle numbers).\n\n    branchname : str\n        path within each TTree to find the TBranch\n\n    {interpretation}\n\n    {namedecode}\n\n    {entrysteps}\n\n    {flatten}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    {localsource}\n\n    {xrootdsource}\n\n    {httpsource}\n\n    {options}\n\n    Returns\n    -------\n    dask.array.core.Array\n        lazy files of lazy baskets.\n"""""".format(**dict(list(open_fragments.items()) + list(tree_fragments.items()))), width=TEXT_WIDTH)\n\nuproot.tree.daskframe.__doc__ = wrap(\nu""""""Create a Dask DataFrame that would read from a set of files as needed.\n\n    Parameters\n    ----------\n\n    path : str or list of str\n        glob pattern(s) for local file paths (POSIX wildcards like ""``*``"") or URLs specifying the locations of the files. A list of filenames are processed in the given order, but glob patterns get pre-sorted to ensure a predictable order.\n\n    treepath : str\n        path within each ROOT file to find the TTree (may include ""``/``"" for subdirectories or ""``;``"" for cycle numbers).\n\n    {branches}\n\n    {namedecode}\n\n    {entrysteps}\n\n    {flatten}\n\n    {awkwardlib}\n\n    {cache}\n\n    {basketcache}\n\n    {keycache}\n\n    {executor}\n\n    {localsource}\n\n    {xrootdsource}\n\n    {httpsource}\n\n    {options}\n\n    Returns\n    -------\n    dask.dataframe.core.DataFrame\n        lazy files of branches of lazy baskets.\n"""""".format(**dict(list(open_fragments.items()) + list(tree_fragments.items()))), width=TEXT_WIDTH)\n\n################################################################ uproot.tree.numentries\n\nuproot.tree.numentries.__doc__ = wrap(\nu""""""Get the number of entries in a TTree without fully opening the file.\n\n    ``uproot.numentries(""file.root"", ""tree"")`` is a shortcut for ``uproot.open(""file.root"")[""tree""].numentries`` that should be faster, particularly for files with many streamers and/or TTrees with many branches because it skips those steps in getting to the number of entries.\n\n    If a requested file is not found, this raises the appropriate exception. If a requested file does not have the requested TTree, the number of entries is taken to be zero, raising no error.\n\n    Parameters\n    ----------\n    path : str or list of str\n        glob pattern(s) for local file paths (POSIX wildcards like ""``*``"") or URLs specifying the locations of the files. A list of filenames are processed in the given order, but glob patterns get pre-sorted to ensure a predictable order.\n\n    treepath : str\n        path within each ROOT file to find the TTree (may include ""``/``"" for subdirectories or ""``;``"" for cycle numbers).\n\n    total : bool\n        if ``True`` *(default)*, return an integer: the total number of entries for all files; otherwise, return an ``OrderedDict`` of path (str) \\u2192 number of entries.\n\n    {localsource}\n\n    {xrootdsource}\n\n    {httpsource}\n\n    {executor}\n\n    {blocking}\n\n    Returns\n    -------\n    int or ``OrderedDict``\n        total number of entries or number of entries for each file, depending on *total*.\n"""""".format(**dict(list(open_fragments.items()) + list(tree_fragments.items()))), width=TEXT_WIDTH)\n\n################################################################ uproot.interp.interp.Interpretation\n\nuproot.interp.interp.Interpretation.__doc__ = wrap(\nu""""""Interface for interpretations.\n\n    Interpretations do not need to inherit from this class, but they do need to satisfy the interface described below.\n\n    Arrays and other collections are filled from ROOT in two stages: raw bytes from each basket are interpreted as a ""source"" and sources are copied into a branch-wide collection called the ""destination"" (often swapping bytes from big-endian to native-endian in the process). Public functions return a finalized destination. The distinction between source and destination (a) compactifies disparate baskets into a contiguous collection and (b) allows the output data to differ from the bytes on disk (byte swapping and other conversions).\n\n    Interpretations must implement the following methods:\n\n    **identifier**\n        *(property)* a unique identifier for this interpretation, used as part of the cache key so that stale interpretations are not counted as cache hits.\n\n    **empty(self)**\n        return a zero-entry container (for special cases that can skip complex logic by returning an empty set).\n\n    **compatible(self, other)**\n        return ``True`` if and only if ``self`` and ``other`` interpretations would return equivalent results, such as different source interpretations that fill the same destination.\n\n    **numitems(self, numbytes, numentries)**\n        calculate the number of ""items"" (whatever that means for a given interpretation, but always greater than or equal to the number of entries), knowing only the number of bytes (``numbytes``) and the number of entries (``numentries``).\n\n    **source_numitems(self, source)**\n        calculate the number of ""items"" given a ``source`` instance.\n\n    **fromroot(self, data, offsets, local_entrystart, local_entrystop, keylen)**\n        produce a source from one basket ``data`` array (dtype ``numpy.uint8``) and its corresponding ``offsets`` array (dtype **numpy.int32** or ``None`` if not present) that has *n + 1* elements for *n* entries: ``offsets[0] == 0 and offsets[-1] == numentries``. The ``local_entrystart`` and ``local_entrystop`` are entry start (inclusive) and stop (exclusive), in which the first entry in the basket is number zero (hence ""local""). The result of this operation may be a zero-copy cast of the basket data.\n\n    **destination(self, numitems, numentries)**\n        create or otherwise produce an unfilled destination object, knowing only the number of items (``numitems``) and number of entries (``numentries``).\n\n    **fill(self, source, destination, itemstart, itemstop, entrystart, entrystop)**\n        copy data from one basket``source`` (in its entirety) to part of the ``destination`` (usually a small slice). The items range from ``itemstart`` (inclusive) to ``itemstop`` (exclusive) and the entries range from ``entrystart`` (inclusive) to ``entrystop`` (exclusive). This function returns nothing; it is the only function in this interface called for its side-effects (the rest may be pure functions).\n\n    **clip(self, destination, itemstart, itemstop, entrystart, entrystop)**\n        return a slice of the ``destination`` from ``itemstart`` (inclusive) to ``itemstop`` (exclusive) and from ``entrystart`` (inclusive) to ``entrystop`` (exclusive). This is to trim memory allocated but not used, for instance if the entry range does not align with basket boundaries.\n\n    **finalize(self, destination)**\n        possibly post-process a ``destination`` to make it ready for consumption. This is needed if a different form must be used for filling than should be provided to the user--- for instance, offsets of a jagged array can\'t be computed when filling sections of it in parallel (sizes can), but the user should receive a jagged array based on offsets for random access.\n"""""", width=TEXT_WIDTH)\n\n################################################################ uproot.interp.auto.interpret\n\nuproot.interp.auto.interpret.__doc__ = wrap(\nu""""""Generate a default interpretation of a branch.\n\n    This function is called with default options on each branch in the following methods to generate a default interpretation. You can override the default either by calling this function explicitly with different parameters or by modifying its result.\n\n    - :py:meth:`TTreeMethods.array <uproot.tree.TTreeMethods.array>`\n    - :py:meth:`TTreeMethods.arrays <uproot.tree.TTreeMethods.arrays>`\n    - :py:meth:`TTreeMethods.lazyarray <uproot.tree.TTreeMethods.lazyarray>`\n    - :py:meth:`TTreeMethods.lazyarrays <uproot.tree.TTreeMethods.lazyarrays>`\n    - :py:meth:`TTreeMethods.iterate <uproot.tree.TTreeMethods.iterate>`\n    - :py:meth:`TTreeMethods.iterate_clusters <uproot.tree.TTreeMethods.iterate_clusters>`\n    - :py:meth:`TBranchMethods.array <uproot.tree.TBranchMethods.array>`\n    - :py:meth:`TBranchMethods.lazyarray <uproot.tree.TBranchMethods.lazyarray>`\n    - :py:meth:`TBranchMethods.basket <uproot.tree.TBranchMethods.basket>`\n    - :py:meth:`TBranchMethods.baskets <uproot.tree.TBranchMethods.baskets>`\n    - :py:meth:`TBranchMethods.iterate_baskets <uproot.tree.TBranchMethods.iterate_baskets>`\n\n    Parameters\n    ----------\n    branch : :py:class:`TBranchMethods <uproot.tree.TBranchMethods>`\n        branch to interpret.\n\n    awkwardlib : ``None``, str, or module\n        if ``None`` *(default)*, use ``import awkward`` to get awkward-array constructors. Otherwise, parse the module string name or use the provided module.\n\n    classes : ``None`` or ``dict`` of str \\u2192 :py:class:`ROOTStreamedObject <uproot.rootio.ROOTStreamedObject>`\n        class definitions associated with each class name, usually generated by ROOT file streamers. If ``None`` *(default)*, use the class definitions generated from the file from which this branch was read.\n\n    swapbytes : bool\n        if ``True``, generate an interpretation that converts ROOT\'s big-endian numbers into the machine-native endianness (usually little-endian).\n\n    Returns\n    -------\n    :py:class:`Interpretation <uproot.interp.interp.Interpretation>`\n        the interpretation.\n"""""", width=TEXT_WIDTH)\n\n################################################################ uproot.interp fragments\n\ninterp_fragments = {\n    # see1\n    ""see1"": u""""""Part of the :py:class:`Interpretation <uproot.interp.interp.Interpretation>` interface; type ``help(uproot.interp.interp.Interpretation)`` for details."""""",\n\n    # see2\n    ""see2"": u""""""Methods implementing the :py:class:`Interpretation <uproot.interp.interp.Interpretation>` interface are not documented here."""""",\n    }\n\n################################################################ uproot.interp.numerical fragments\n\ninterp_numerical_fragments = {\n    # items\n    ""items"": u""""""In this interpretation, ""items"" (for ``numitems``, ``itemstart``, ``itemstop``, etc.) has the same meaning as in Numpy: an item is a single scalar value. For example, 100 entries of 2\\u00d72 matrices (``todims == (2, 2)``) is 400 items."""""",\n\n    # fromdtype\n    ""fromdtype"": u""""""fromdtype : ``numpy.dtype``\n        the source type; the meaning associated with bytes in the ROOT file. Should be big-endian (e.g. ``"">i4""`` for 32-bit integers and ``"">f8""`` for 64-bit floats)."""""",\n\n    # fromdims\n    ""fromdims"": u""""""fromdims : tuple of ints\n        Numpy shape of each source entry. The Numpy shape of the whole source array is ``(numentries,) + fromdims``. Default is ``()`` (scalar)."""""",\n    }\n\n################################################################ uproot.interp.numerical.asdtype\n\nuproot.interp.numerical.asdtype.__doc__ = wrap(\nu""""""Interpret branch data as a new Numpy array with given dtypes and dimensions.\n\n    This interpretation directs branch-reading functions to allocate new Numpy arrays and fill them with the branch contents. See :py:class:`asarray <uproot.interp.numerical.asarray>` to fill an existing array, rather than filling a new array.\n\n    {items}\n\n    Parameters\n    ----------\n    {fromdtype}\n\n    todtype : ``None`` or ``numpy.dtype``\n        the destination type; the conversion performed if different from the source type. If ``None`` *(default)*, the destination type will be a native-endian variant of the source type, so that a byte-swap is performed.\n\n    {fromdims}\n\n    todims : ``None`` or tuple of ints\n        Numpy shape of each destination entry. The Numpy shape of the whole destination array is ``(numentries,) + todims``. If ``None`` *(default)*, ``todims`` will be equal to ``fromdims``. Making them different allows you to reshape arrays while reading.\n\n    Notes\n    -----\n\n    {see2}\n"""""".format(**dict(list(interp_fragments.items()) + list(interp_numerical_fragments.items()))), width=TEXT_WIDTH)\n\n_method(uproot.interp.numerical.asdtype.to).__doc__ = wrap(\nu""""""Create a new :py:class:`asdtype <uproot.interp.numerical.asdtype>` interpretation from this one.\n\n    Parameters\n    ----------\n    todtype : ``None`` or ``numpy.dtype``\n        if not ``None``, change the destination type.\n\n    todims : ``None`` or tuple of ints\n        if not ``None``, change the destination dimensions.\n\n    Returns\n    -------\n    :py:class:`asdtype <uproot.interp.numerical.asdtype>`\n        new interpretation.\n"""""", width=TEXT_WIDTH)\n\n_method(uproot.interp.numerical.asdtype.toarray).__doc__ = wrap(\nu""""""Create a :py:class:`asarray <uproot.interp.numerical.asarray>` interpretation from this one.\n\n    Parameters\n    ----------\n    array : ``numpy.ndarray``\n        the array to fill, instead of allocating a new one.\n\n    Returns\n    -------\n    :py:class:`asarray <uproot.interp.numerical.asarray>`\n        new interpretation.\n"""""", width=TEXT_WIDTH)\n\n_method(uproot.interp.numerical.asdtype.empty).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.numerical.asdtype.compatible).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.numerical.asdtype.numitems).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.numerical.asdtype.source_numitems).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.numerical.asdtype.fromroot).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.numerical.asdtype.destination).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.numerical.asdtype.fill).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.numerical.asdtype.clip).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.numerical.asdtype.finalize).__doc__ = interp_fragments[""see1""]\n\n################################################################ uproot.interp.numerical.asarray\n\nuproot.interp.numerical.asarray.__doc__ = wrap(\nu""""""Interpret branch as array data that should overwrite an existing array.\n\n    This interpretation directs branch-reading functions to fill the given Numpy array with branch contents. See :py:class:`asdtype <uproot.interp.numerical.asdtype>` to allocate a new array, rather than filling an existing array.\n\n    {items}\n\n    Parameters\n    ----------\n    {fromdtype}\n\n    toarray : ``numpy.ndarray``\n        array to be filled; must be at least as large as the branch data.\n\n    {fromdims}\n\n    Notes\n    -----\n\n    {see2}\n\n    This class has *todtype* and *todims* parameters like :py:class:`asdtype <uproot.interp.numerical.asdtype>`, but they are derived from the *toarray* attribute.\n"""""".format(**dict(list(interp_fragments.items()) + list(interp_numerical_fragments.items()))), width=TEXT_WIDTH)\n\n_method(uproot.interp.numerical.asarray.destination).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.numerical.asarray.fill).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.numerical.asarray.clip).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.numerical.asarray.finalize).__doc__ = interp_fragments[""see1""]\n\n################################################################ uproot.interp.jagged.asjagged\n\nuproot.interp.jagged.asjagged.__doc__ = wrap(\nu""""""Interpret branch as a jagged array (array of non-uniformly sized arrays).\n\n    This interpretation directs branch-reading to fill contiguous arrays and present them to the user in a ``JaggedArray`` interface. Such an object behaves as though it were an array of non-uniformly sized arrays, but it is more memory and cache-line efficient because the underlying data are contiguous.\n\n    In this interpretation, ""items"" (for ``numitems``, ``itemstart``, ``itemstop``, etc.) are the items of the inner array (however that is defined), and ""entries"" are elements of the outer array. The outer array is always one-dimensional.\n\n    Parameters\n    ----------\n    asdtype : :py:class:`asdtype <uproot.interp.numerical.asdtype>`\n        interpretation for the inner arrays.\n\n    Notes\n    -----\n\n    {see2}\n"""""".format(**interp_fragments), width=TEXT_WIDTH)\n\n_method(uproot.interp.jagged.asjagged.to).__doc__ = wrap(\nu""""""Create a new :py:class:`asjagged <uproot.interp.jagged.asjagged>` interpretation from this one.\n\n    Parameters\n    ----------\n    todtype : ``None`` or ``numpy.dtype``\n        if not ``None``, change the destination type of inner arrays.\n\n    todims : ``None`` or tuple of ints\n        if not ``None``, change the destination dimensions of inner arrays.\n\n    Returns\n    -------\n    :py:class:`asjagged <uproot.interp.jagged.asjagged>`\n        new interpretation.\n"""""", width=TEXT_WIDTH)\n\n_method(uproot.interp.jagged.asjagged.empty).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.jagged.asjagged.compatible).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.jagged.asjagged.numitems).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.jagged.asjagged.source_numitems).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.jagged.asjagged.fromroot).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.jagged.asjagged.destination).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.jagged.asjagged.fill).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.jagged.asjagged.clip).__doc__ = interp_fragments[""see1""]\n_method(uproot.interp.jagged.asjagged.finalize).__doc__ = interp_fragments[""see1""]\n\n# TODO: add asdtype asarray asdouble32 asstlbitset asjagged astable asobj asgenobj asstring STLVector STLString\n\n################################################################ uproot.source.cursor.Cursor\n\nuproot.source.cursor.Cursor.__doc__ = wrap(\nu""""""Maintain a position in a :py:class:`Source <uproot.source.source.Source>` that updates as data are read.\n\n    **Attributes, properties, and methods:**\n\n    - **index** (*int*) the position.\n    - **origin** (*int*) ""beginning of buffer"" position, used in the **refs** key in :py:func:`uproot.rootio._readobjany <uproot.rootio._readobjany>`.\n    - **refs** (``None`` or ``dict``-like) manages cross-references in :py:func:`uproot.rootio._readobjany <uproot.rootio._readobjany>`.\n    - :py:meth:`copied <uproot.source.cursor.Cursor.copied>` return a copy of this :py:class:`Cursor <uproot.source.cursor.Cursor>` with modifications.\n    - :py:meth:`skipped <uproot.source.cursor.Cursor.skipped>` return a copy of this :py:class:`Cursor <uproot.source.cursor.Cursor>` with the **index** moved forward.\n    - :py:meth:`skip <uproot.source.cursor.Cursor.skip>` move the **index** of this :py:class:`Cursor <uproot.source.cursor.Cursor>` forward.\n    - :py:meth:`fields <uproot.source.cursor.Cursor.fields>` interpret bytes in the :py:class:`Source <uproot.source.source.Source>` with given data types and skip the **index** past them.\n    - :py:meth:`field <uproot.source.cursor.Cursor.field>` interpret bytes in the :py:class:`Source <uproot.source.source.Source>` with a given data type and skip the **index** past it.\n    - :py:meth:`bytes <uproot.source.cursor.Cursor.bytes>` return a range of bytes from the :py:class:`Source <uproot.source.source.Source>` and skip the **index** past it.\n    - :py:meth:`array <uproot.source.cursor.Cursor.array>` return a range of bytes from the :py:class:`Source <uproot.source.source.Source>` as a typed Numpy array and skip the **index** past it.\n    - :py:meth:`string <uproot.source.cursor.Cursor.string>` read a string from the :py:class:`Source <uproot.source.source.Source>`, interpreting the first 1 or 5 bytes as a size and skip the **index** past it.\n    - :py:meth:`cstring <uproot.source.cursor.Cursor.cstring>` read a null-terminated string from the :py:class:`Source <uproot.source.source.Source>` and skip the **index** past it.\n    - :py:meth:`skipstring <uproot.source.cursor.Cursor.skipstring>` interpret the first 1 or 5 bytes as a size and skip the **index** past the string (without creating a Python string).\n    - :py:meth:`hexdump <uproot.source.cursor.Cursor.hexdump>` view a section of the :py:class:`Source <uproot.source.source.Source>` as formatted by the POSIX ``hexdump`` program and *do not* move the **index**.\n\n    Parameters\n    ----------\n    index : int\n       the initial **index**.\n\n    origin : int\n       the **origin**, *(default is 0)*.\n\n    refs : ``None`` or ``dict``-like\n       if ``None`` *(default)*, use a new dict as the **ref**; otherwise, use the value provided.\n"""""", width=TEXT_WIDTH)\n\nformat_source_cursor = {\n    # source\n    ""source"": u""""""source : :py:class:`Source <uproot.source.source.Source>`\n        data to be read.""""""\n    }\n\n_method(uproot.source.cursor.Cursor.copied).__doc__ = wrap(\nu""""""Return a copy of this :py:class:`Cursor <uproot.source.cursor.Cursor>` with modifications.\n\n    Parameters\n    ----------\n    index : ``None`` or int\n        if not ``None`` *(default)*, use this as the new index position.\n\n    origin : ``None`` or int\n        if not ``None`` *(default)*, use this as the new origin.\n\n    refs : ``None`` or ``dict``-like\n        if not ``None`` *(default)*, use this as the new refs.\n\n    Returns\n    -------\n    :py:class:`Cursor <uproot.source.cursor.Cursor>`\n        the new cursor.\n\n    Notes\n    -----\n\n    This is a shallow copy--- the **refs** are shared with the parent and all other copies.\n"""""".format(**format_source_cursor), width=TEXT_WIDTH)\n\n_method(uproot.source.cursor.Cursor.skipped).__doc__ = wrap(\nu""""""Return a copy of this :py:class:`Cursor <uproot.source.cursor.Cursor>` with the **index** moved forward.\n\n    Parameters\n    ----------\n    numbytes : int\n        number of bytes to be skipped in the copy, leaving the original unchanged.\n\n    origin : ``None`` or int\n        if not ``None`` *(default)*, use this as the new origin.\n\n    refs : ``None`` or ``dict``-like\n        if not ``None`` *(default)*, use this as the new refs.\n\n    Returns\n    -------\n    :py:class:`Cursor <uproot.source.cursor.Cursor>`\n        the new cursor.\n\n    Notes\n    -----\n\n    This is a shallow copy--- the **refs** are shared with the parent and all other copies.\n"""""".format(**format_source_cursor), width=TEXT_WIDTH)\n\n_method(uproot.source.cursor.Cursor.skip).__doc__ = wrap(\nu""""""Move the **index** of this :py:class:`Cursor <uproot.source.cursor.Cursor>` forward.\n\n    Parameters\n    ----------\n    numbytes : int\n        number of bytes to skip\n"""""".format(**format_source_cursor), width=TEXT_WIDTH)\n\n_method(uproot.source.cursor.Cursor.fields).__doc__ = wrap(\nu""""""Interpret bytes in the :py:class:`Source <uproot.source.source.Source>` with given data types and skip the **index** past them.\n\n    Parameters\n    ----------\n    {source}\n\n    format : ``struct.Struct``\n        compiled parser from Python\'s ``struct`` library.\n\n    Returns\n    -------\n    tuple\n        field values (types determined by format)\n"""""".format(**format_source_cursor), width=TEXT_WIDTH)\n\n_method(uproot.source.cursor.Cursor.field).__doc__ = wrap(\nu""""""Interpret bytes in the :py:class:`Source <uproot.source.source.Source>` with a given data type and skip the **index** past it.\n\n    Parameters\n    ----------\n    {source}\n\n    format : ``struct.Struct``\n        compiled parser from Python\'s ``struct`` library; must return only one field.\n\n    Returns\n    -------\n    type determined by format\n        field value\n"""""".format(**format_source_cursor), width=TEXT_WIDTH)\n\n_method(uproot.source.cursor.Cursor.bytes).__doc__ = wrap(\nu""""""Return a range of bytes from the :py:class:`Source <uproot.source.source.Source>` and skip the **index** past it.\n\n    Parameters\n    ----------\n    {source}\n\n    length : int\n        number of bytes.\n\n    Returns\n    -------\n    ``numpy.ndarray`` of ``numpy.uint8``\n        raw view of data from source.\n"""""".format(**format_source_cursor), width=TEXT_WIDTH)\n\n_method(uproot.source.cursor.Cursor.array).__doc__ = wrap(\nu""""""Return a range of bytes from the :py:class:`Source <uproot.source.source.Source>` as a typed Numpy array and skip the **index** past it.\n\n    Parameters\n    ----------\n    {source}\n\n    length : int\n        number of items.\n\n    dtype : ``numpy.dtype``\n        type of the array.\n\n    Returns\n    -------\n    ``numpy.ndarray``\n        interpreted view of data from source.\n"""""".format(**format_source_cursor), width=TEXT_WIDTH)\n\n_method(uproot.source.cursor.Cursor.string).__doc__ = wrap(\nu""""""Read a string from the :py:class:`Source <uproot.source.source.Source>`, interpreting the first 1 or 5 bytes as a size and skip the **index** past it.\n\n    Parameters\n    ----------\n    {source}\n\n    Returns\n    -------\n    bytes\n        Python string (``bytes`` in Python 3).\n"""""".format(**format_source_cursor), width=TEXT_WIDTH)\n\n_method(uproot.source.cursor.Cursor.cstring).__doc__ = wrap(\nu""""""Read a null-terminated string from the :py:class:`Source <uproot.source.source.Source>` and skip the **index** past it.\n\n    The index is also skipped past the null that terminates the string.\n\n    Parameters\n    ----------\n    {source}\n\n    Returns\n    -------\n    bytes\n        Python string (``bytes`` in Python 3).\n"""""".format(**format_source_cursor), width=TEXT_WIDTH)\n\n_method(uproot.source.cursor.Cursor.skipstring).__doc__ = wrap(\nu""""""Interpret the first 1 or 5 bytes as a size and skip the **index** past the string (without creating a Python string).\n\n    Parameters\n    ----------\n    {source}\n"""""".format(**format_source_cursor), width=TEXT_WIDTH)\n\n_method(uproot.source.cursor.Cursor.hexdump).__doc__ = wrap(\nu""""""View a section of the :py:class:`Source <uproot.source.source.Source>` as formatted by the POSIX ``hexdump`` program and *do not* move the **index**.\n\n    This is much more useful than simply hexdumping the whole file, since partial interpretation is necessary to find the right point in the file to dump.\n\n    Parameters\n    ----------\n    {source}\n\n    size : int\n        number of bytes to view; default is 160 (10 lines).\n\n    offset : int\n        where to start the view, relative to index; default is 0 (at index).\n\n    format : str\n        Python\'s printf-style format string for individual bytes; default is ""%02x"" (zero-prefixed, two-character hexidecimal).\n\n    Returns\n    -------\n    str\n        hexdump-formatted view to be printed\n"""""".format(**format_source_cursor), width=TEXT_WIDTH)\n\n################################################################ uproot.source.source.Source\n\nuproot.source.source.Source.__doc__ = wrap(\nu""""""Interface for data sources.\n\n    Sources do not need to inherit from this class, but they do need to satisfy the interface described below.\n\n    **parent(self)**\n        return the :py:class:`Source <uproot.source.source.Source>` from which this was copied; may be ``None``.\n\n    **threadlocal(self)**\n        either return ``self`` (if thread-safe) or return a thread-safe copy, such as a new file handle into the same file.\n\n    **dismiss(self)**\n        thread-local copies are no longer needed; they may be eliminated if redundant.\n\n    **data(self, start, stop, dtype=None)**\n        return a view of data from the starting byte (inclusive) to the stopping byte (exclusive), with a given Numpy type (numpy.uint8 if ``None``).\n"""""", width=TEXT_WIDTH)\n\nsource_fragments = {\n    # see1\n    ""see1"": u""""""Part of the :py:class:`Source <uproot.source.source.Source>` interface; type ``help(uproot.source.source.Source)`` for details."""""",\n\n    # see2\n    ""see2"": u""""""Methods implementing the :py:class:`Source <uproot.source.source.Source>` interface are not documented here."""""",\n    }\n\n################################################################ uproot.source.file.FileSource\n\nuproot.source.file.FileSource.__doc__ = wrap(\nu""""""Emulate a memory-mapped interface with traditional file handles, opening many if necessary.\n\n    :py:class:`FileSource <uproot.source.file.FileSource>` objects avoid double-reading and many small reads by caching data in chunks. All thread-local copies of a :py:class:`FileSource <uproot.source.file.FileSource>` share a :py:class:`ThreadSafeArrayCache <uproot.cache.ThreadSafeArrayCache>` to avoid double-reads across threads.\n\n    Parameters\n    ----------\n    path : str\n        local file path of the input file (it must not be moved during reading!).\n\n    chunkbytes : int or string matching number + /[kMGTPEZY]?B/i\n        number of bytes per chunk.\n\n    limitbytes : int or string matching number + /[kMGTPEZY]?B/i\n        maximum number of bytes to keep in the cache.\n\n    Notes\n    -----\n\n    {see2}\n"""""".format(**source_fragments), width=TEXT_WIDTH)\n\n_method(uproot.source.file.FileSource.parent).__doc__ = source_fragments[""see1""]\n_method(uproot.source.file.FileSource.threadlocal).__doc__ = source_fragments[""see1""]\n_method(uproot.source.file.FileSource.dismiss).__doc__ = source_fragments[""see1""]\n_method(uproot.source.file.FileSource.data).__doc__ = source_fragments[""see1""]\n\n################################################################ uproot.source.memmap.MemmapSource\n\nuproot.source.memmap.MemmapSource.__doc__ = wrap(\nu""""""Thin wrapper around a memory-mapped file, which already behaves like a :py:class:`Source <uproot.source.source.Source>`.\n\n    Parameters\n    ----------\n    path : str\n        local file path of the input file.\n\n    Notes\n    -----\n\n    {see2}\n"""""".format(**source_fragments), width=TEXT_WIDTH)\n\n_method(uproot.source.memmap.MemmapSource.parent).__doc__ = source_fragments[""see1""]\n_method(uproot.source.memmap.MemmapSource.threadlocal).__doc__ = source_fragments[""see1""]\n_method(uproot.source.memmap.MemmapSource.dismiss).__doc__ = source_fragments[""see1""]\n_method(uproot.source.memmap.MemmapSource.data).__doc__ = source_fragments[""see1""]\n\n################################################################ uproot.source.xrootd.XRootDSource\n\nuproot.source.xrootd.XRootDSource.__doc__ = wrap(\nu""""""Emulate a memory-mapped interface with XRootD.\n\n    XRootD is already thread-safe, but provides no caching. :py:class:`XRootDSource <uproot.source.xrootd.XRootDSource>` objects avoid double-reading and many small reads by caching data in chunks. They are not duplicated when splitting into threads.\n\n    Parameters\n    ----------\n    path : str\n        remote file URL.\n\n    chunkbytes : int or string matching number + /[kMGTPEZY]?B/i\n        number of bytes per chunk.\n\n    limitbytes : int or string matching number + /[kMGTPEZY]?B/i\n        maximum number of bytes to keep in the cache.\n\n    Notes\n    -----\n\n    {see2}\n"""""".format(**source_fragments), width=TEXT_WIDTH)\n\n_method(uproot.source.xrootd.XRootDSource.parent).__doc__ = source_fragments[""see1""]\n_method(uproot.source.xrootd.XRootDSource.threadlocal).__doc__ = source_fragments[""see1""]\n_method(uproot.source.xrootd.XRootDSource.dismiss).__doc__ = source_fragments[""see1""]\n_method(uproot.source.xrootd.XRootDSource.data).__doc__ = source_fragments[""see1""]\n\n################################################################ uproot.source.compressed.Compression\n\nuproot.source.compressed.Compression.__doc__ = wrap(\nu""""""Describe the compression of a compressed block.\n\n    **Attributes, properties, and methods:**\n\n    - **algo** (*int*) algorithm code.\n    - **level** (*int*) 0 is no compression, 1 is least, 9 is most.\n    - **algoname** (*str*) algorithm expressed as a string: ``""zlib""``, ``""lzma""``, ``""old""``, ``""lz4""`` or ``""zstd""``.\n    - **copy(algo=None, level=None)** copy this :py:class:`Compression <uproot.source.compressed.Compression>` object, possibly changing a field.\n    - **decompress(source, cursor, compressedbytes, uncompressedbytes)** decompress data from **source** at **cursor**, knowing the compressed and uncompressed size.\n\n    Parameters\n    ----------\n    fCompress : int\n        ROOT fCompress field.\n"""""", width=TEXT_WIDTH)\n\n################################################################ uproot.source.compressed.CompressedSource\n\nuproot.source.compressed.CompressedSource.__doc__ = wrap(\nu""""""A :py:class:`Source <uproot.source.source.Source>` for compressed data.\n\n    Decompresses on demand--- without caching the result--- so cache options in higher-level array functions are very important.\n\n    Ordinary users would never create a :py:class:`CompressedSource <uproot.source.compressed.CompressedSource>`. They are produced when a TKey encounters a compressed value.\n\n    Parameters\n    ----------\n    compression : :py:class:`Compression <uproot.source.compressed.Compression>`\n        inherited description of the compression. Note that *this is overridden* by the first two bytes of the compressed block, which can disagree with the higher-level description and takes precedence.\n\n    source : :py:class:`Source <uproot.source.source.Source>`\n        the source in which compressed data may be found.\n\n    cursor : :py:class:`Cursor <uproot.source.cursor.Cursor>`\n        location in the source.\n\n    compressedbytes : int\n        number of bytes after compression.\n\n    uncompressedbytes : int\n        number of bytes before compression.\n"""""", width=TEXT_WIDTH)\n\n################################################################ uproot.cache.ArrayCache\n\nuproot.cache.ArrayCache.__doc__ = wrap(\nu""""""A cache (wrapping cachetools) whose eviction threshold is determined by total array size.\n\n    Uses the nbytes property of all values to determine total size. By default, cachetools only counts the number of objects, ignoring their sizes.\n\n    Parameters\n    ----------\n    limitbytes : int or string matching number + /[kMGTPEZY]?B/i\n        maximum number of bytes to keep in the cache.\n\n    method : ""LRU"" *(default)* or ""LFU""\n        least recently used or least frequently used\n"""""", width=TEXT_WIDTH)\n\n################################################################ uproot.cache.ThreadSafeArrayCache\n\nuproot.cache.ThreadSafeArrayCache.__doc__ = wrap(\nu""""""An :py:class:`ArrayCache <uproot.cache.ArrayCache>` with locks for thread safety.\n\n    Parameters\n    ----------\n    limitbytes : int or string matching number + /[kMGTPEZY]?B/i\n        maximum number of bytes to keep in the cache.\n\n    method : ""LRU"" *(default)* or ""LFU""\n        least recently used or least frequently used\n"""""", width=TEXT_WIDTH)\n'"
uproot/cache.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport math\nimport threading\ntry:\n    from collections.abc import MutableMapping\nexcept ImportError:\n    from collections import MutableMapping\n\nimport cachetools\n\nclass ArrayCache(MutableMapping):\n    @staticmethod\n    def getsizeof(obj):\n        return getattr(obj, ""nbytes"", 1)\n\n    def __init__(self, limitbytes, method=""LRU""):\n        from uproot.rootio import _memsize\n        m = _memsize(limitbytes)\n        if m is not None:\n            limitbytes = int(math.ceil(m))\n        if method == ""LRU"":\n            self._cache = cachetools.LRUCache(limitbytes, getsizeof=self.getsizeof)\n        elif method == ""LFU"":\n            self._cache = cachetools.LFUCache(limitbytes, getsizeof=self.getsizeof)\n        else:\n            raise ValueError(""unrecognized method: {0}"".format(method))\n\n    def __contains__(self, where):\n        return where in self._cache\n\n    def __getitem__(self, where):\n        return self._cache[where]\n\n    def __setitem__(self, where, what):\n        self._cache[where] = what\n\n    def __delitem__(self, where):\n        del self._cache[where]\n\n    def __iter__(self):\n        for x in self._cache:\n            yield x\n\n    def __len__(self):\n        return len(self._cache)\n\nclass ThreadSafeArrayCache(ArrayCache):\n    def __init__(self, limitbytes, method=""LRU""):\n        super(ThreadSafeArrayCache, self).__init__(limitbytes, method=method)\n        self._lock = threading.Lock()\n\n    def __contains__(self, where):\n        with self._lock:\n            return where in self._cache\n\n    def __getitem__(self, where):\n        with self._lock:\n            return self._cache[where]\n\n    def __setitem__(self, where, what):\n        with self._lock:\n            self._cache[where] = what\n\n    def __delitem__(self, where):\n        with self._lock:\n            del self._cache[where]\n\n    def __iter__(self):\n        with self._lock:\n            for x in self._cache:\n                yield x\n\n    def __len__(self):\n        with self._lock:\n            return len(self._cache)\n'"
uproot/const.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\n""""""ROOT constants used in deserialization.""""""\nfrom __future__ import absolute_import\n\nimport numpy\n\n# used in unmarshaling\nkByteCountMask        = numpy.int64(0x40000000)\nkByteCountVMask       = numpy.int64(0x4000)\nkClassMask            = numpy.int64(0x80000000)\nkNewClassTag          = numpy.int64(0xFFFFFFFF)\n\nkIsOnHeap             = numpy.uint32(0x01000000)\nkIsReferenced         = numpy.uint32(1 << 4)\n\nkMapOffset            = 2\n\n# not used?\nkNullTag              = 0\nkNotDeleted           = numpy.uint32(0x02000000)\nkZombie               = numpy.uint32(0x04000000)\nkBitMask              = numpy.uint32(0x00FFFFFF)\nkDisplacementMask     = numpy.uint32(0xFF000000)\n\n################################################################ core/zip/inc/Compression.h\n\nkZLIB                 = 1\nkLZMA                 = 2\nkOldCompressionAlgo   = 3\nkLZ4                  = 4\nkZSTD                 = 5\nkUndefinedCompressionAlgorithm = 6\n\n################################################################ constants for streamers\n\nkBase                 = 0\nkChar                 = 1\nkShort                = 2\nkInt                  = 3\nkLong                 = 4\nkFloat                = 5\nkCounter              = 6\nkCharStar             = 7\nkDouble               = 8\nkDouble32             = 9\nkLegacyChar           = 10\nkUChar                = 11\nkUShort               = 12\nkUInt                 = 13\nkULong                = 14\nkBits                 = 15\nkLong64               = 16\nkULong64              = 17\nkBool                 = 18\nkFloat16              = 19\nkOffsetL              = 20\nkOffsetP              = 40\nkObject               = 61\nkAny                  = 62\nkObjectp              = 63\nkObjectP              = 64\nkTString              = 65\nkTObject              = 66\nkTNamed               = 67\nkAnyp                 = 68\nkAnyP                 = 69\nkAnyPnoVT             = 70\nkSTLp                 = 71\n\nkSkip                 = 100\nkSkipL                = 120\nkSkipP                = 140\n\nkConv                 = 200\nkConvL                = 220\nkConvP                = 240\n\nkSTL                  = 300\nkSTLstring            = 365\n\nkStreamer             = 500\nkStreamLoop           = 501\n\n################################################################ constants from core/foundation/inc/ESTLType.h\n\nkNotSTL               = 0\nkSTLvector            = 1\nkSTLlist              = 2\nkSTLdeque             = 3\nkSTLmap               = 4\nkSTLmultimap          = 5\nkSTLset               = 6\nkSTLmultiset          = 7\nkSTLbitset            = 8\nkSTLforwardlist       = 9\nkSTLunorderedset      = 10\nkSTLunorderedmultiset = 11\nkSTLunorderedmap      = 12\nkSTLunorderedmultimap = 13\nkSTLend               = 14\nkSTLany               = 300\n\n################################################################ IOFeatures\n\nkGenerateOffsetMap    = 1\n'"
uproot/pandas.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\n""""""Top-level functions for Pandas.""""""\nfrom __future__ import absolute_import\n\nimport uproot.tree\nfrom uproot.source.memmap import MemmapSource\nfrom uproot.source.xrootd import XRootDSource\nfrom uproot.source.http import HTTPSource\n\ndef iterate(path, treepath, branches=None, entrysteps=None, namedecode=""utf-8"", reportpath=False, reportfile=False, flatten=True, flatname=None, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, blocking=True, localsource=MemmapSource.defaults, xrootdsource=XRootDSource.defaults, httpsource=HTTPSource.defaults, **options):\n    import pandas\n    return uproot.tree.iterate(path, treepath, branches=branches, entrysteps=entrysteps, outputtype=pandas.DataFrame, namedecode=namedecode, reportpath=reportpath, reportfile=reportfile, reportentries=False, flatten=flatten, flatname=flatname, awkwardlib=awkwardlib, cache=cache, basketcache=basketcache, keycache=keycache, executor=executor, blocking=blocking, localsource=localsource, xrootdsource=xrootdsource, httpsource=httpsource, **options)\n'"
uproot/rootio.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport keyword\nimport numbers\nimport os\nimport re\nimport struct\nimport sys\ntry:\n    from urlparse import urlparse\nexcept ImportError:\n    from urllib.parse import urlparse\n\nimport numpy\n\nimport uproot.const\nimport uproot.source.compressed\nfrom uproot.source.memmap import MemmapSource\nfrom uproot.source.xrootd import XRootDSource\nfrom uproot.source.http import HTTPSource\nfrom uproot.source.cursor import Cursor\n\nimport uproot_methods.classes\n\n################################################################ high-level interface\n\ndef open(path, localsource=MemmapSource.defaults, xrootdsource=XRootDSource.defaults, httpsource=HTTPSource.defaults, **options):\n    if isinstance(path, getattr(os, ""PathLike"", ())):\n        path = os.fspath(path)\n    elif hasattr(path, ""__fspath__""):\n        path = path.__fspath__()\n    elif path.__class__.__module__ == ""pathlib"":\n        import pathlib\n        if isinstance(path, pathlib.Path):\n             path = str(path)\n\n    parsed = urlparse(path)\n    if _bytesid(parsed.scheme) == b""file"" or len(parsed.scheme) == 0 or (os.name == ""nt"" and open._windows_absolute.match(path) is not None):\n        if not (os.name == ""nt"" and open._windows_absolute.match(path) is not None):\n            path = parsed.netloc + parsed.path\n        if isinstance(localsource, dict):\n            kwargs = dict(MemmapSource.defaults)\n            kwargs.update(localsource)\n            for n in kwargs:\n                if n in options:\n                    kwargs[n] = options.pop(n)\n            openfcn = lambda path: MemmapSource(path, **kwargs)\n        else:\n            openfcn = localsource\n        return ROOTDirectory.read(openfcn(path), **options)\n\n    elif _bytesid(parsed.scheme) == b""root"":\n        return xrootd(path, xrootdsource=xrootdsource, **options)\n\n    elif _bytesid(parsed.scheme) == b""http"" or _bytesid(parsed.scheme) == b""https"":\n        return http(path, httpsource=httpsource, **options)\n\n    else:\n        raise ValueError(""URI scheme not recognized: {0}"".format(path))\n\nopen._windows_absolute = re.compile(r""^[A-Za-z]:\\\\"")\n\ndef xrootd(path, xrootdsource=XRootDSource.defaults, **options):\n    if isinstance(xrootdsource, dict):\n        kwargs = dict(XRootDSource.defaults)\n        kwargs.update(xrootdsource)\n        for n in kwargs:\n            if n in options:\n                kwargs[n] = options.pop(n)\n        openfcn = lambda path: XRootDSource(path, **kwargs)\n    else:\n        openfcn = xrootdsource\n    return ROOTDirectory.read(openfcn(path), **options)\n\ndef http(path, httpsource=HTTPSource.defaults, **options):\n    if isinstance(httpsource, dict):\n        kwargs = dict(HTTPSource.defaults)\n        kwargs.update(httpsource)\n        for n in kwargs:\n            if n in options:\n                kwargs[n] = options.pop(n)\n        openfcn = lambda path: HTTPSource(path, **kwargs)\n    else:\n        openfcn = httpsource\n    return ROOTDirectory.read(openfcn(path), **options)\n\ndef nofilter(x): return True\n\n################################################################ ROOTDirectory\n\nclass ROOTDirectory(object):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (type,), {})\n\n    _classname = b""TDirectory""\n    classname = ""TDirectory""\n\n    class _FileContext(object):\n        def __init__(self, sourcepath, streamerinfos, streamerinfosmap, classes, compression, tfile):\n            self.sourcepath, self.streamerinfos, self.streamerinfosmap, self.classes, self.compression, self.tfile = sourcepath, streamerinfos, streamerinfosmap, classes, compression, tfile\n            self.uuid = tfile[""_fUUID""]\n\n        def copy(self):\n            out = ROOTDirectory._FileContext.__new__(ROOTDirectory._FileContext)\n            out.__dict__.update(self.__dict__)\n            return out\n\n    @staticmethod\n    def read(source, *args, **options):\n        if len(args) == 0:\n            try:\n                read_streamers = options.pop(""read_streamers"", True)\n                if len(options) > 0:\n                    raise TypeError(""unrecognized options: {0}"".format("", "".join(options)))\n\n                # See https://root.cern/doc/master/classTFile.html\n                cursor = Cursor(0)\n                magic, fVersion = cursor.fields(source, ROOTDirectory._format1)\n                if magic != b""root"":\n                    raise ValueError(""not a ROOT file (starts with {0} instead of \'root\')\\n   in file: {1}"".format(repr(magic), source.path))\n                if fVersion < 1000000:\n                    fBEGIN, fEND, fSeekFree, fNbytesFree, nfree, fNbytesName, fUnits, fCompress, fSeekInfo, fNbytesInfo, fUUID = cursor.fields(source, ROOTDirectory._format2_small)\n                else:\n                    fBEGIN, fEND, fSeekFree, fNbytesFree, nfree, fNbytesName, fUnits, fCompress, fSeekInfo, fNbytesInfo, fUUID = cursor.fields(source, ROOTDirectory._format2_big)\n\n                tfile = {""_fVersion"": fVersion, ""_fBEGIN"": fBEGIN, ""_fEND"": fEND, ""_fSeekFree"": fSeekFree, ""_fNbytesFree"": fNbytesFree, ""nfree"": nfree, ""_fNbytesName"": fNbytesName, ""_fUnits"": fUnits, ""_fCompress"": fCompress, ""_fSeekInfo"": fSeekInfo, ""_fNbytesInfo"": fNbytesInfo, ""_fUUID"": fUUID}\n\n                # classes requried to read streamers (bootstrap)\n                streamerclasses = {""TStreamerInfo"":             TStreamerInfo,\n                                   ""TStreamerElement"":          TStreamerElement,\n                                   ""TStreamerBase"":             TStreamerBase,\n                                   ""TStreamerBasicType"":        TStreamerBasicType,\n                                   ""TStreamerBasicPointer"":     TStreamerBasicPointer,\n                                   ""TStreamerLoop"":             TStreamerLoop,\n                                   ""TStreamerObject"":           TStreamerObject,\n                                   ""TStreamerObjectPointer"":    TStreamerObjectPointer,\n                                   ""TStreamerObjectAny"":        TStreamerObjectAny,\n                                   ""TStreamerObjectAnyPointer"": TStreamerObjectAnyPointer,\n                                   ""TStreamerString"":           TStreamerString,\n                                   ""TStreamerSTL"":              TStreamerSTL,\n                                   ""TStreamerSTLstring"":        TStreamerSTLstring,\n                                   ""TStreamerArtificial"":       TStreamerArtificial,\n                                   ""TList"":                     TList,\n                                   ""TObjArray"":                 TObjArray,\n                                   ""TObjString"":                TObjString}\n\n                if read_streamers and fSeekInfo != 0:\n                    streamercontext = ROOTDirectory._FileContext(source.path, None, None, streamerclasses, uproot.source.compressed.Compression(fCompress), tfile)\n                    streamerkey = TKey.read(source, Cursor(fSeekInfo), streamercontext, None)\n                    streamerinfos, streamerinfosmap, streamerrules = _readstreamers(streamerkey._source, streamerkey._cursor, streamercontext, None)\n                else:\n                    streamerinfos, streamerinfosmap, streamerrules = [], {}, []\n\n                classes = dict(globals())\n                classes.update(builtin_classes)\n                classes = _defineclasses(streamerinfos, classes)\n                context = ROOTDirectory._FileContext(source.path, streamerinfos, streamerinfosmap, classes, uproot.source.compressed.Compression(fCompress), tfile)\n                context.source = source\n\n                keycursor = Cursor(fBEGIN)\n                mykey = TKey.read(source, keycursor, context, None)\n\n                return ROOTDirectory.read(source, Cursor(fBEGIN + fNbytesName), context, mykey)\n\n            except Exception:\n                source.dismiss()\n                raise\n\n        else:\n            try:\n                if len(options) > 0:\n                    raise TypeError(""unrecognized options: {0}"".format("", "".join(options)))\n\n                cursor, context, mykey = args\n\n                # See https://root.cern/doc/master/classTDirectoryFile.html.\n                fVersion, fDatimeC, fDatimeM, fNbytesKeys, fNbytesName = cursor.fields(source, ROOTDirectory._format3)\n                if fVersion <= 1000:\n                    fSeekDir, fSeekParent, fSeekKeys = cursor.fields(source, ROOTDirectory._format4_small)\n                else:\n                    fSeekDir, fSeekParent, fSeekKeys = cursor.fields(source, ROOTDirectory._format4_big)\n\n                if fSeekKeys == 0:\n                    out = ROOTDirectory(b""(empty)"", context, [])\n\n                else:\n                    subcursor = Cursor(fSeekKeys)\n                    headerkey = TKey.read(source, subcursor, context, None)\n\n                    nkeys = subcursor.field(source, ROOTDirectory._format5)\n                    keys = [TKey.read(source, subcursor, context, None) for i in range(nkeys)]\n\n                    out = ROOTDirectory(mykey._fName, context, keys)\n\n                out._fVersion, out._fDatimeC, out._fDatimeM, out._fNbytesKeys, out._fNbytesName, out._fSeekDir, out._fSeekParent, out._fSeekKeys = fVersion, fDatimeC, fDatimeM, fNbytesKeys, fNbytesName, fSeekDir, fSeekParent, fSeekKeys\n                out.source = source\n                return out\n\n            finally:\n                source.dismiss()\n\n    _format1       = struct.Struct("">4si"")\n    _format2_small = struct.Struct("">iiiiiiBiii18s"")\n    _format2_big   = struct.Struct("">iqqiiiBiqi18s"")\n    _format3       = struct.Struct("">hIIii"")\n    _format4_small = struct.Struct("">iii"")\n    _format4_big   = struct.Struct("">qqq"")\n    _format5       = struct.Struct("">i"")\n\n    def __init__(self, name, context, keys):\n        self.name, self._context, self._keys = name, context, keys\n\n    @property\n    def compression(self):\n        return self._context.compression\n\n    def __repr__(self):\n        return ""<ROOTDirectory {0} at 0x{1:012x}>"".format(repr(self.name), id(self))\n\n    def __getitem__(self, name):\n        return self.get(name)\n\n    def __len__(self):\n        return len(self._keys)\n\n    def __iter__(self):\n        return self.iterkeys()\n\n    @staticmethod\n    def _withoutcycle(key):\n        return ""{0}"".format(key._fName.decode(""ascii"")).encode(""ascii"")\n\n    @staticmethod\n    def _withcycle(key):\n        return ""{0};{1}"".format(key._fName.decode(""ascii""), key._fCycle).encode(""ascii"")\n\n    def showstreamers(self, filtername=nofilter, stream=sys.stdout):\n        if stream is None:\n            return ""\\n"".join(x.show(stream=stream) for x in self._context.streamerinfos if filtername(x._fName))\n        else:\n            for x in self._context.streamerinfos:\n                if filtername(x._fName):\n                    x.show(stream=stream)\n\n    def iterkeys(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        for key in self._keys:\n            cls = _classof(self._context, key._fClassName)\n            if filtername(key._fName) and filterclass(cls):\n                yield self._withcycle(key)\n\n            if recursive and (key._fClassName == b""TDirectory"" or key._fClassName == b""TDirectoryFile""):\n                for name in key.get().iterkeys(recursive, filtername, filterclass):\n                    yield ""{0}/{1}"".format(self._withoutcycle(key).decode(""ascii""), name.decode(""ascii"")).encode(""ascii"")\n\n    def itervalues(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        for key in self._keys:\n            cls = _classof(self._context, key._fClassName)\n            if filtername(key._fName) and filterclass(cls):\n                yield key.get()\n\n            if recursive and (key._fClassName == b""TDirectory"" or key._fClassName == b""TDirectoryFile""):\n                for value in key.get().itervalues(recursive, filtername, filterclass):\n                    yield value\n\n    def iteritems(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        for key in self._keys:\n            cls = _classof(self._context, key._fClassName)\n            if filtername(key._fName) and filterclass(cls):\n                yield self._withcycle(key), key.get()\n\n            if recursive and (key._fClassName == b""TDirectory"" or key._fClassName == b""TDirectoryFile""):\n                for name, value in key.get().iteritems(recursive, filtername, filterclass):\n                    yield ""{0}/{1}"".format(self._withoutcycle(key).decode(""ascii""), name.decode(""ascii"")).encode(""ascii""), value\n\n    def iterclasses(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        for key in self._keys:\n            cls = _classof(self._context, key._fClassName)\n            if filtername(key._fName) and filterclass(cls):\n                yield self._withcycle(key), cls\n\n            if recursive and (key._fClassName == b""TDirectory"" or key._fClassName == b""TDirectoryFile""):\n                for name, classname in key.get().iterclasses(recursive, filtername, filterclass):\n                    yield ""{0}/{1}"".format(self._withoutcycle(key).decode(""ascii""), name.decode(""ascii"")).encode(""ascii""), classname\n\n    def iterclassnames(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        for key in self._keys:\n            cls = _classof(self._context, key._fClassName)\n            if filtername(key._fName) and filterclass(cls):\n                yield self._withcycle(key), key._fClassName.decode(\'ascii\')\n\n            if recursive and (key._fClassName == b""TDirectory"" or key._fClassName == b""TDirectoryFile""):\n                for name, classname in key.get().iterclassnames(recursive, filtername, filterclass):\n                    yield ""{0}/{1}"".format(self._withoutcycle(key).decode(""ascii""), name.decode(""ascii"")).encode(""ascii""), classname\n\n    def keys(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        return list(self.iterkeys(recursive=recursive, filtername=filtername, filterclass=filterclass))\n\n    def _ipython_key_completions_(self):\n        ""Support for completion of keys in an IPython kernel""\n        return [item.decode(""ascii"") for item in self.iterkeys()]\n\n    def values(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        return list(self.itervalues(recursive=recursive, filtername=filtername, filterclass=filterclass))\n\n    def items(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        return list(self.iteritems(recursive=recursive, filtername=filtername, filterclass=filterclass))\n\n    def classes(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        return list(self.iterclasses(recursive=recursive, filtername=filtername, filterclass=filterclass))\n\n    def classnames(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        return list(self.iterclassnames(recursive=recursive, filtername=filtername, filterclass=filterclass))\n\n    def allkeys(self, filtername=nofilter, filterclass=nofilter):\n        return self.keys(recursive=True, filtername=filtername, filterclass=filterclass)\n\n    def allvalues(self, filtername=nofilter, filterclass=nofilter):\n        return self.values(recursive=True, filtername=filtername, filterclass=filterclass)\n\n    def allitems(self, filtername=nofilter, filterclass=nofilter):\n        return self.items(recursive=True, filtername=filtername, filterclass=filterclass)\n\n    def allclasses(self, filtername=nofilter, filterclass=nofilter):\n        return self.classes(recursive=True, filtername=filtername, filterclass=filterclass)\n\n    def allclassnames(self, filtername=nofilter, filterclass=nofilter):\n        return self.classnames(recursive=True, filtername=filtername, filterclass=filterclass)\n\n    def get(self, name, cycle=None):\n        name = _bytesid(name)\n\n        if b""/"" in name:\n            out = self\n            for n in name.split(b""/""):\n                out = out.get(n, cycle)\n            return out\n\n        else:\n            if cycle is None and b"";"" in name:\n                at = name.rindex(b"";"")\n                name, cycle = name[:at], name[at + 1:]\n                cycle = int(cycle)\n\n            last = None\n            for key in self._keys:\n                if key._fName == name:\n                    if cycle == key._fCycle:\n                        return key.get()\n                    elif cycle is None and last is None:\n                        last = key\n                    elif cycle is None and last._fCycle < key._fCycle:\n                        last = key\n\n            if last is not None:\n                return last.get()\n            elif cycle is None:\n                raise _KeyError(""not found: {0}\\n in file: {1}"".format(repr(name), self._context.sourcepath))\n            else:\n                raise _KeyError(""not found: {0} with cycle {1}\\n in file: {2}"".format(repr(name), cycle, self._context.sourcepath))\n\n    def close(self):\n        self._context.source.close()\n\n    def __contains__(self, name):\n        try:\n            self.get(name)\n        except KeyError:\n            return False\n        else:\n            return True\n\n    def __enter__(self, *args, **kwds):\n        return self\n\n    def __exit__(self, *args, **kwds):\n        self.close()\n\nclass _KeyError(KeyError):\n    def __str__(self):\n        return self.args[0]\n\n_KeyError.__name__ = ""KeyError""\n_KeyError.__module__ = ""builtins"" if sys.version_info[0] > 2 else None\n\n################################################################ helper functions for common tasks\n\ndef _memsize(data):\n    if isinstance(data, str):\n        m = re.match(r""^\\s*([+-]?(\\d+(\\.\\d*)?|\\.\\d+)(e[+-]?\\d+)?)\\s*([kmgtpezy]?b)\\s*$"", data, re.I)\n        if m is not None:\n            target, unit = float(m.group(1)), m.group(5).upper()\n            if unit == ""KB"":\n                target *= 1024\n            elif unit == ""MB"":\n                target *= 1024**2\n            elif unit == ""GB"":\n                target *= 1024**3\n            elif unit == ""TB"":\n                target *= 1024**4\n            elif unit == ""PB"":\n                target *= 1024**5\n            elif unit == ""EB"":\n                target *= 1024**6\n            elif unit == ""ZB"":\n                target *= 1024**7\n            elif unit == ""YB"":\n                target *= 1024**8\n            return target\n    return None\n\ndef _bytesid(x):\n    if sys.version_info[0] > 2:\n        if isinstance(x, str):\n            return x.encode(""ascii"", ""backslashreplace"")\n        else:\n            return x\n    else:\n        if isinstance(x, unicode):\n            return x.encode(""ascii"", ""backslashreplace"")\n        else:\n            return x\n\ndef _startcheck(source, cursor):\n    start = cursor.index\n    cnt, vers = cursor.fields(source, _startcheck._format_cntvers)\n    if numpy.int64(cnt) & uproot.const.kByteCountMask:\n        cnt = int(numpy.int64(cnt) & ~uproot.const.kByteCountMask)\n        return start, cnt + 4, vers\n    else:\n        cursor.index = start\n        vers, = cursor.fields(source, _startcheck._format_cntvers2)\n        return start, None, vers\n_startcheck._format_cntvers = struct.Struct("">IH"")\n_startcheck._format_cntvers2 = struct.Struct("">H"")\n\ndef _endcheck(start, cursor, cnt):\n    if cnt is not None:\n        observed = cursor.index - start\n        if observed != cnt:\n            raise ValueError(""object has {0} bytes; expected {1}"".format(observed, cnt))\n\ndef _skiptobj(source, cursor):\n    version = cursor.field(source, _skiptobj._format1)\n    if numpy.int64(version) & uproot.const.kByteCountVMask:\n        cursor.skip(4)\n    fUniqueID, fBits = cursor.fields(source, _skiptobj._format2)\n    fBits = numpy.uint32(fBits) | uproot.const.kIsOnHeap\n    if fBits & uproot.const.kIsReferenced:\n        cursor.skip(2)\n_skiptobj._format1 = struct.Struct("">h"")\n_skiptobj._format2 = struct.Struct("">II"")\n\ndef _nametitle(source, cursor):\n    start, cnt, vers = _startcheck(source, cursor)\n    _skiptobj(source, cursor)\n    name = cursor.string(source)\n    title = cursor.string(source)\n    _endcheck(start, cursor, cnt)\n    return name, title\n\ndef _mapstrstr(source, cursor):\n    cursor.skip(12)\n    size = cursor.field(source, _mapstrstr._int32)\n    cursor.skip(6)\n    keys = [cursor.string(source) for i in range(size)]\n    cursor.skip(6)\n    values = [cursor.string(source) for i in range(size)]\n    return dict(zip(keys, values))\n\n_mapstrstr._int32 = struct.Struct(\'>I\')\n\ndef _readobjany(source, cursor, context, parent, asclass=None):\n    # TBufferFile::ReadObjectAny()\n    # https://github.com/root-project/root/blob/c4aa801d24d0b1eeb6c1623fd18160ef2397ee54/io/io/src/TBufferFile.cxx#L2684\n    # https://github.com/root-project/root/blob/c4aa801d24d0b1eeb6c1623fd18160ef2397ee54/io/io/src/TBufferFile.cxx#L2404\n\n    beg = cursor.index - cursor.origin\n    bcnt = cursor.field(source, struct.Struct("">I""))\n\n    if numpy.int64(bcnt) & uproot.const.kByteCountMask == 0 or numpy.int64(bcnt) == uproot.const.kNewClassTag:\n        vers = 0\n        start = 0\n        tag = bcnt\n        bcnt = 0\n    else:\n        vers = 1\n        start = cursor.index - cursor.origin\n        tag = cursor.field(source, struct.Struct("">I""))\n\n    if numpy.int64(tag) & uproot.const.kClassMask == 0:\n        # reference object\n        if tag == 0:\n            return None                                         # return null\n\n        elif tag == 1:\n            return parent\n\n        elif tag not in cursor.refs:\n            # jump past this object\n            cursor.index = cursor.origin + beg + bcnt + 4\n            return None                                         # return null\n\n        else:\n            return cursor.refs[tag]                             # return object\n\n    elif tag == uproot.const.kNewClassTag:\n        # new class and object\n        cname = _safename(cursor.cstring(source))\n\n        fct = context.classes.get(cname, Undefined)\n\n        if vers > 0:\n            cursor.refs[start + uproot.const.kMapOffset] = fct\n        else:\n            cursor.refs[len(cursor.refs) + 1] = fct\n\n        if asclass is None:\n            obj = fct.read(source, cursor, context, parent)     # new object\n            if isinstance(obj, Undefined):\n                obj._classname = cname\n        else:\n            obj = asclass.read(source, cursor, context, parent) # placeholder new object\n\n        if vers > 0:\n            cursor.refs[beg + uproot.const.kMapOffset] = obj\n        else:\n            cursor.refs[len(cursor.refs) + 1] = obj\n\n        return obj                                              # return object\n\n    else:\n        # reference class, new object\n        ref = int(numpy.int64(tag) & ~uproot.const.kClassMask)\n\n        if asclass is None:\n            if ref not in cursor.refs:\n                raise IOError(""invalid class-tag reference\\nin file: {0}"".format(context.sourcepath))\n\n            fct = cursor.refs[ref]                              # reference class\n\n            if fct not in context.classes.values():\n                raise IOError(""invalid class-tag reference (not a recognized class: {0})\\nin file: {1}"".format(fct, context.sourcepath))\n\n            obj = fct.read(source, cursor, context, parent)     # new object\n\n        else:\n            obj = asclass.read(source, cursor, context, parent) # placeholder new object\n\n        if vers > 0:\n            cursor.refs[beg + uproot.const.kMapOffset] = obj\n        else:\n            cursor.refs[len(cursor.refs) + 1] = obj\n\n        return obj                                              # return object\n\ndef _classof(context, classname):\n    if classname == b""TDirectory"" or classname == b""TDirectoryFile"":\n        cls = ROOTDirectory\n    else:\n        cls = context.classes.get(_safename(classname), None)\n        if cls is None:\n            cls = ROOTObject.__metaclass__(""Undefined_"" + str(_safename(classname)), (Undefined,), {""_classname"": classname})\n    return cls\n\ndef _readstreamers(source, cursor, context, parent):\n    tlist = TList.read(source, cursor, context, parent)\n\n    streamerinfos = []\n    streamerrules = []\n    for obj in tlist:\n        if isinstance(obj, TStreamerInfo):\n            dependencies = set()\n            for element in obj._fElements:\n                if isinstance(element, TStreamerBase):\n                    dependencies.add(element._fName)\n                # if isinstance(element, (TStreamerObject, TStreamerObjectAny, TStreamerString)) or (isinstance(element, TStreamerObjectPointer) and element._fType == uproot.const.kObjectp):\n                #     dependencies.add(element._fTypeName.rstrip(b""*""))\n            streamerinfos.append((obj, dependencies))\n\n        elif isinstance(obj, TList) and all(isinstance(x, TObjString) for x in obj):\n            streamerrules.append(obj)\n\n        else:\n            raise ValueError(""expected TStreamerInfo or TList of TObjString in streamer info array\\n   in file: {0}"".format(context.sourcepath))\n\n    # https://stackoverflow.com/a/11564769/1623645\n    def topological_sort(items):\n        provided = set([x.encode(""ascii"") for x in builtin_classes])\n        while len(items) > 0:\n            remaining_items = []\n            emitted = False\n\n            for item, dependencies in items:\n                if dependencies.issubset(provided):\n                    yield item\n                    provided.add(item._fName)\n                    emitted = True\n                else:\n                    remaining_items.append((item, dependencies))\n\n            if not emitted:\n                for pair in items:\n                    if pair in remaining_items:\n                        remaining_items.remove(pair)\n                # raise ValueError(""cannot sort TStreamerInfos into dependency order:\\n\\n{0}"".format(""\\n"".join(""{0:20s} requires {1}"".format(item._fName.decode(""ascii""), "" "".join(x.decode(""ascii"") for x in dependencies)) for item, dependencies in items)))\n\n            items = remaining_items\n\n    streamerinfos = list(topological_sort(streamerinfos))\n    streamerinfosmap = dict((x._fName, x) for x in streamerinfos)\n\n    for streamerinfo in streamerinfos:\n        streamerinfo.members = {}\n        for element in streamerinfo._fElements:\n            if isinstance(element, TStreamerBase):\n                if element._fName in streamerinfosmap:\n                    streamerinfo.members.update(getattr(streamerinfosmap[element._fName], ""members"", {}))\n            else:\n                streamerinfo.members[element._fName] = element\n\n    return streamerinfos, streamerinfosmap, streamerrules\n\ndef _ftype2dtype(fType):\n    if fType == uproot.const.kBool:\n        return ""numpy.dtype(numpy.bool_)""\n    elif fType == uproot.const.kChar:\n        return ""numpy.dtype(\'i1\')""\n    elif fType in (uproot.const.kUChar, uproot.const.kCharStar):\n        return ""numpy.dtype(\'u1\')""\n    elif fType == uproot.const.kShort:\n        return ""numpy.dtype(\'>i2\')""\n    elif fType == uproot.const.kUShort:\n        return ""numpy.dtype(\'>u2\')""\n    elif fType == uproot.const.kInt:\n        return ""numpy.dtype(\'>i4\')""\n    elif fType in (uproot.const.kBits, uproot.const.kUInt, uproot.const.kCounter):\n        return ""numpy.dtype(\'>u4\')""\n    elif fType == uproot.const.kLong:\n        return ""numpy.dtype(numpy.long).newbyteorder(\'>\')""\n    elif fType == uproot.const.kULong:\n        return ""numpy.dtype(\'>u\' + repr(numpy.dtype(numpy.long).itemsize))""\n    elif fType == uproot.const.kLong64:\n        return ""numpy.dtype(\'>i8\')""\n    elif fType == uproot.const.kULong64:\n        return ""numpy.dtype(\'>u8\')""\n    elif fType in (uproot.const.kFloat, uproot.const.kFloat16):\n        return ""numpy.dtype(\'>f4\')""\n    elif fType in (uproot.const.kDouble, uproot.const.kDouble32):\n        return ""numpy.dtype(\'>f8\')""\n    else:\n        return ""None""\n\ndef _longsize(issigned):\n    if os.name == ""nt"":\n        if sys.version_info[0] <= 2:\n            return ""q"" if issigned else ""Q""\n        else:\n            return ""i"" if issigned else ""I""   # wrong: gave up in PR #493\n    else:\n        return ""q"" if issigned else ""Q""\n\ndef _ftype2struct(fType):\n    if fType == uproot.const.kBool:\n        return ""?""\n    elif fType == uproot.const.kChar:\n        return ""b""\n    elif fType in (uproot.const.kUChar, uproot.const.kCharStar):\n        return ""B""\n    elif fType == uproot.const.kShort:\n        return ""h""\n    elif fType == uproot.const.kUShort:\n        return ""H""\n    elif fType == uproot.const.kInt:\n        return ""i""\n    elif fType in (uproot.const.kBits, uproot.const.kUInt, uproot.const.kCounter):\n        return ""I""\n    elif fType == uproot.const.kLong:\n        return _longsize(True)\n    elif fType == uproot.const.kULong:\n        return _longsize(False)\n    elif fType == uproot.const.kLong64:\n        return ""q""\n    elif fType == uproot.const.kULong64:\n        return ""Q""\n    elif fType in (uproot.const.kFloat, uproot.const.kFloat16):\n        return ""f""\n    elif fType in (uproot.const.kDouble, uproot.const.kDouble32):\n        return ""d""\n    else:\n        raise NotImplementedError(fType)\n\ndef _safename(name):\n    out = _safename._pattern.sub(lambda bad: ""_"" + """".join(""{0:02x}"".format(ord(x)) for x in bad.group(0)) + ""_"", name.decode(""ascii""))\n    if keyword.iskeyword(out):\n        out = out + ""__""\n    return out\n_safename._pattern = re.compile(""[^a-zA-Z0-9]+"")\n\ndef _raise_notimplemented(streamertype, streamerdict, source, cursor):\n    raise NotImplementedError(""\\n\\nUnimplemented streamer type: {0}\\n\\nmembers: {1}\\n\\nfile contents:\\n\\n{2}"".format(streamertype, streamerdict, cursor.hexdump(source)))\n\ndef _resolveversion(cls, self, classversion):\n    if classversion not in cls._versions:\n        raise ValueError(""attempting to read {0} object with version {1}, but there is no streamer in this ROOT file with that class name and version (versions available: {2})"".format(cls.__name__, classversion, list(cls._versions.keys())))\n    self.__class__ = cls._versions[classversion]\n\ndef _defineclasses(streamerinfos, classes):\n    skip = dict(builtin_skip)\n\n    for streamerinfo in streamerinfos:\n        pyclassname = _safename(streamerinfo._fName)\n\n        if isinstance(streamerinfo, TStreamerInfo) and pyclassname not in builtin_classes and (pyclassname not in classes or hasattr(classes[pyclassname], ""_versions"")):\n            hasreadobjany = False\n\n            code = [""    @classmethod"",\n                    ""    def _readinto(cls, self, source, cursor, context, parent, asclass=None):"",\n                    ""        start, cnt, classversion = _startcheck(source, cursor)"",\n                    ""        startendcheck = True"",\n                    ""        if cls._classversion != classversion:"",\n                    ""            cursor.index = start"",\n                    ""            if classversion in cls._versions:"",\n                    ""                return cls._versions[classversion]._readinto(self, source, cursor, context, parent)"",\n                    ""            elif cnt is None:"",\n                    ""                startendcheck = False"",\n                    ""            else:"",\n                    ""                return Undefined.read(source, cursor, context, parent, cls.__name__)""]\n\n            fields = []\n            recarray = []\n            bases = []\n            formats = {}\n            dtypes = {}\n            basicnames = []\n            basicletters = """"\n            for elementi, element in enumerate(streamerinfo._fElements):\n                if isinstance(element, TStreamerArtificial):\n                    code.append(""        _raise_notimplemented({0}, {1}, source, cursor)"".format(repr(element.__class__.__name__), repr(repr(element.__dict__))))\n                    recarray.append(""raise ValueError(\'not a recarray\')"")\n\n                elif isinstance(element, TStreamerBase):\n                    code.append(""        {0}._readinto(self, source, cursor, context, parent)"".format(_safename(element._fName)))\n                    bases.append(_safename(element._fName))\n\n                elif isinstance(element, TStreamerBasicPointer):\n                    assert uproot.const.kOffsetP < element._fType < uproot.const.kOffsetP + 20\n                    fType = element._fType - uproot.const.kOffsetP\n\n                    dtypename = ""_dtype{0}"".format(len(dtypes) + 1)\n                    dtypes[dtypename] = _ftype2dtype(fType)\n\n                    code.append(""        fBasketSeek_dtype = cls.{0}"".format(dtypename))\n                    if streamerinfo._fName == b""TBranch"" and element._fName == b""fBasketSeek"":\n                        code.append(""        if getattr(context, \\""speedbump\\"", True):"")\n                        code.append(""            if cursor.bytes(source, 1)[0] == 2:"")\n                        code.append(""                fBasketSeek_dtype = numpy.dtype(\'>i8\')"")\n                    else:\n                        code.append(""        if getattr(context, \\""speedbump\\"", True):"")\n                        code.append(""            cursor.skip(1)"")\n\n                    code.append(""        self._{0} = cursor.array(source, self._{1}, fBasketSeek_dtype)"".format(_safename(element._fName), _safename(element._fCountName)))\n                    fields.append(_safename(element._fName))\n                    recarray.append(""raise ValueError(\'not a recarray\')"")\n\n                elif isinstance(element, TStreamerBasicType):\n                    if element._fArrayLength == 0:\n                        basicnames.append(""self._{0}"".format(_safename(element._fName)))\n                        fields.append(_safename(element._fName))\n                        fielddtype = _ftype2dtype(element._fType)\n                        if fielddtype == ""None"":\n                            recarray.append(""raise ValueError(\'not a recarray\')"")\n                        else:\n                            recarray.append(""out.append(({0}, {1}))"".format(repr(str(element._fName.decode(""ascii""))), fielddtype))\n                        basicletters += _ftype2struct(element._fType)\n\n                        if elementi + 1 == len(streamerinfo._fElements) or not isinstance(streamerinfo._fElements[elementi + 1], TStreamerBasicType) or streamerinfo._fElements[elementi + 1]._fArrayLength != 0:\n                            formatnum = len(formats) + 1\n                            formats[""_format{0}"".format(formatnum)] = ""struct.Struct(\'>{0}\')"".format(basicletters)\n\n                            if len(basicnames) == 1:\n                                code.append(""        {0} = cursor.field(source, cls._format{1})"".format(basicnames[0], formatnum))\n                            else:\n                                code.append(""        {0} = cursor.fields(source, cls._format{1})"".format("", "".join(basicnames), formatnum))\n\n                            basicnames = []\n                            basicletters = """"\n\n                    else:\n                        dtypename = ""_dtype{0}"".format(len(dtypes) + 1)\n                        fielddtype = dtypes[dtypename] = _ftype2dtype(element._fType)\n                        code.append(""        self._{0} = cursor.array(source, {1}, cls.{2})"".format(_safename(element._fName), element._fArrayLength, dtypename))\n                        fields.append(_safename(element._fName))\n                        if fielddtype == ""None"":\n                            recarray.append(""raise ValueError(\'not a recarray\')"")\n                        else:\n                            recarray.append(""out.append(({0}, {1}, {2}))"".format(repr(str(element._fName.decode(""ascii""))), fielddtype, element._fArrayLength))\n\n                elif isinstance(element, TStreamerLoop):\n                    code.extend([""        cursor.skip(6)"",\n                                 ""        for index in range(self._{0}):"".format(_safename(element._fCountName)),\n                                 ""            self._{0} = {1}.read(source, cursor, context, self)"".format(_safename(element._fName), _safename(element._fTypeName.rstrip(b""*"")))])\n\n                elif isinstance(element, (TStreamerObjectAnyPointer, TStreamerObjectPointer)):\n                    if element._fType == uproot.const.kObjectp or element._fType == uproot.const.kAnyp:\n                        if pyclassname in skip and _safename(element._fName) in skip[pyclassname]:\n                            code.append(""        Undefined.read(source, cursor, context, self)"")\n                        else:\n                            code.append(""        self._{0} = {1}.read(source, cursor, context, self)"".format(_safename(element._fName), _safename(element._fTypeName.rstrip(b""*""))))\n                            fields.append(_safename(element._fName))\n                            recarray.append(""out.extend({0}._recarray())"".format(_safename(element._fName)))\n                    elif element._fType == uproot.const.kObjectP or element._fType == uproot.const.kAnyP:\n                        if pyclassname in skip and _safename(element._fName) in skip[pyclassname]:\n                            code.append(""        _readobjany(source, cursor, context, parent, asclass=Undefined)"")\n                            hasreadobjany = True\n                        else:\n                            code.append(""        self._{0} = _readobjany(source, cursor, context, parent)"".format(_safename(element._fName)))\n                            hasreadobjany = True\n                            fields.append(_safename(element._fName))\n                            recarray.append(""raise ValueError(\'not a recarray\')"")\n                    else:\n                        code.append(""        _raise_notimplemented({0}, {1}, source, cursor)"".format(repr(element.__class__.__name__), repr(repr(element.__dict__))))\n                        recarray.append(""raise ValueError(\'not a recarray\')"")\n\n                elif isinstance(element, TStreamerSTL):\n                    if element._fSTLtype == uproot.const.kSTLstring or element._fTypeName == b""string"":\n                        code.append(""        cursor.skip(6)"")\n                        code.append(""        self._{0} = cursor.string(source)"".format(_safename(element._fName)))\n                        fields.append(_safename(element._fName))\n                    elif (element._fSTLtype == uproot.const.kSTLvector and element._fCtype == uproot.const.kBool) or element._fTypeName == b""vector<bool>"" or element._fTypeName == b""vector<Bool_t>"":\n                        code.append(""        cursor.skip(6)"")\n                        code.append(""        self._{0} = cursor.array(source, cursor.field(source, self._int32), \'?\')"".format(_safename(element._fName)))\n                        fields.append(_safename(element._fName))\n                    elif (element._fSTLtype == uproot.const.kSTLvector and element._fCtype == uproot.const.kChar) or element._fTypeName == b""vector<char>"" or element._fTypeName == b""vector<Char_t>"":\n                        code.append(""        cursor.skip(6)"")\n                        code.append(""        self._{0} = cursor.array(source, cursor.field(source, self._int32), \'i1\')"".format(_safename(element._fName)))\n                        fields.append(_safename(element._fName))\n                    elif (element._fSTLtype == uproot.const.kSTLvector and element._fCtype == uproot.const.kUChar) or element._fTypeName == b""vector<unsigned char>"" or element._fTypeName == b""vector<UChar_t>"" or element._fTypeName == b""vector<Byte_t>"":\n                        code.append(""        cursor.skip(6)"")\n                        code.append(""        self._{0} = cursor.array(source, cursor.field(source, self._int32), \'u1\')"".format(_safename(element._fName)))\n                        fields.append(_safename(element._fName))\n                    elif (element._fSTLtype == uproot.const.kSTLvector and element._fCtype == uproot.const.kShort) or element._fTypeName == b""vector<short>"" or element._fTypeName == b""vector<Short_t>"":\n                        code.append(""        cursor.skip(6)"")\n                        code.append(""        self._{0} = cursor.array(source, cursor.field(source, self._int32), \'>i2\')"".format(_safename(element._fName)))\n                        fields.append(_safename(element._fName))\n                    elif (element._fSTLtype == uproot.const.kSTLvector and element._fCtype == uproot.const.kUShort) or element._fTypeName == b""vector<unsigned short>"" or element._fTypeName == b""vector<UShort_t>"":\n                        code.append(""        cursor.skip(6)"")\n                        code.append(""        self._{0} = cursor.array(source, cursor.field(source, self._int32), \'>u2\')"".format(_safename(element._fName)))\n                        fields.append(_safename(element._fName))\n                    elif (element._fSTLtype == uproot.const.kSTLvector and element._fCtype == uproot.const.kInt) or element._fTypeName == b""vector<int>"" or element._fTypeName == b""vector<Int_t>"":\n                        code.append(""        cursor.skip(6)"")\n                        code.append(""        self._{0} = cursor.array(source, cursor.field(source, self._int32), \'>i4\')"".format(_safename(element._fName)))\n                        fields.append(_safename(element._fName))\n                    elif (element._fSTLtype == uproot.const.kSTLvector and element._fCtype == uproot.const.kUInt) or element._fTypeName == b""vector<unsigned int>"" or element._fTypeName == b""vector<UInt_t>"":\n                        code.append(""        cursor.skip(6)"")\n                        code.append(""        self._{0} = cursor.array(source, cursor.field(source, self._int32), \'>u4\')"".format(_safename(element._fName)))\n                        fields.append(_safename(element._fName))\n                    elif (element._fSTLtype == uproot.const.kSTLvector and element._fCtype == uproot.const.kLong) or element._fTypeName == b""vector<long>"" or element._fTypeName == b""vector<Long_t>"":\n                        code.append(""        cursor.skip(6)"")\n                        code.append(""        self._{0} = cursor.array(source, cursor.field(source, self._int32), \'>i8\')"".format(_safename(element._fName)))\n                        fields.append(_safename(element._fName))\n                    elif (element._fSTLtype == uproot.const.kSTLvector and element._fCtype == uproot.const.kULong) or element._fTypeName == b""vector<unsigned long>"" or element._fTypeName == b""vector<ULong64_t>"":\n                        code.append(""        cursor.skip(6)"")\n                        code.append(""        self._{0} = cursor.array(source, cursor.field(source, self._int32), \'>u8\')"".format(_safename(element._fName)))\n                        fields.append(_safename(element._fName))\n                    elif (element._fSTLtype == uproot.const.kSTLvector and element._fCtype == uproot.const.kFloat) or element._fTypeName == b""vector<float>"" or element._fTypeName == b""vector<Float_t>"":\n                        code.append(""        cursor.skip(6)"")\n                        code.append(""        self._{0} = cursor.array(source, cursor.field(source, self._int32), \'>f4\')"".format(_safename(element._fName)))\n                        fields.append(_safename(element._fName))\n                    elif (element._fSTLtype == uproot.const.kSTLvector and element._fCtype == uproot.const.kDouble) or element._fTypeName == b""vector<double>"" or element._fTypeName == b""vector<Double_t>"":\n                        code.append(""        cursor.skip(6)"")\n                        code.append(""        self._{0} = cursor.array(source, cursor.field(source, self._int32), \'>f8\')"".format(_safename(element._fName)))\n                        fields.append(_safename(element._fName))\n                    elif element._fTypeName == b""vector<string>"":\n                        code.append(""        cursor.skip(6)"")\n                        code.append(""        self._{0} = uproot.interp.objects.STLVector(uproot.interp.objects.STLString()).read(source, cursor, context, self)"".format(_safename(element._fName)))\n                    elif element._fTypeName == b""map<string,string>"":\n                        code.append(""        self._{0} = _mapstrstr(source, cursor)"".format(_safename(element._fName)))\n                    else:\n                        code.append(""        _raise_notimplemented({0}, {1}, source, cursor)"".format(repr(element.__class__.__name__), repr(repr(element.__dict__))))\n                    recarray.append(""raise ValueError(\'not a recarray\')"")\n\n                elif isinstance(element, TStreamerSTLstring):\n                    code.append(""        _raise_notimplemented({0}, {1}, source, cursor)"".format(repr(element.__class__.__name__), repr(repr(element.__dict__))))\n                    recarray.append(""raise ValueError(\'not a recarray\')"")\n\n                elif isinstance(element, (TStreamerObject, TStreamerObjectAny, TStreamerString)):\n                    if pyclassname in skip and _safename(element._fName) in skip[pyclassname]:\n                        code.append(""        self._{0} = Undefined.read(source, cursor, context, self)"".format(_safename(element._fName)))\n                    else:\n                        code.append(""        self._{0} = {1}.read(source, cursor, context, self)"".format(_safename(element._fName), _safename(element._fTypeName)))\n                        fields.append(_safename(element._fName))\n                        recarray.append(""out.extend({0}._recarray())"".format(_safename(element._fTypeName)))\n\n                else:\n                    raise AssertionError(element)\n\n            code.extend([""        if startendcheck:"",\n                         ""            if self.__class__.__name__ == cls.__name__:"",\n                         ""                self.__class__ = cls._versions[classversion]"",\n                         ""            try:"",\n                         ""                _endcheck(start, cursor, cnt)"",\n                         ""            except ValueError:"",\n                         ""                cursor.index = start"",\n                         ""                return Undefined.read(source, cursor, context, parent, cls.__name__)"",\n                         ""        return self""])\n\n            for n, v in sorted(formats.items()):\n                code.append(""    {0} = {1}"".format(n, v))\n            for n, v in sorted(dtypes.items()):\n                code.append(""    {0} = {1}"".format(n, v))\n            code.append(""    _int32 = struct.Struct(\'>I\')"")\n\n            code.insert(0, ""    _hasreadobjany = {0}"".format(hasreadobjany))\n            code.insert(0, ""    _classversion = {0}"".format(streamerinfo._fClassVersion))\n            code.insert(0, ""    _versions = versions"")\n            code.insert(0, ""    classname = {0}"".format(repr(streamerinfo._fName.decode(""ascii""))))\n            if sys.version_info[0] > 2:\n                code.insert(0, ""    _classname = {0}"".format(repr(streamerinfo._fName)))\n            else:\n                code.insert(0, ""    _classname = b{0}"".format(repr(streamerinfo._fName)))\n            code.insert(0, ""    _fields = [{0}]"".format("", "".join(repr(str(x)) for x in fields)))\n            code.insert(0, ""    @classmethod\\n    def _recarray(cls):\\n        out = []\\n        out.append((\' cnt\', \'u4\'))\\n        out.append((\' vers\', \'u2\'))\\n        for base in cls._bases:\\n            out.extend(base._recarray())\\n        {0}\\n        return out"".format(""\\n        "".join(recarray)))\n            code.insert(0, ""    _bases = [{0}]"".format("", "".join(bases)))\n            code.insert(0, ""    _methods = {0}"".format(""uproot_methods.classes.{0}.Methods"".format(pyclassname) if uproot_methods.classes.hasmethods(pyclassname) else ""None""))\n\n            if len(bases) == 0:\n                bases.append(""ROOTStreamedObject"")\n\n            if pyclassname == ""TTree"":\n                bases.insert(0, ""uproot.tree.TTreeMethods"")\n            if pyclassname == ""TBranch"":\n                bases.insert(0, ""uproot.tree.TBranchMethods"")\n            if uproot_methods.classes.hasmethods(pyclassname):\n                bases.insert(0, ""uproot_methods.classes.{0}.Methods"".format(pyclassname))\n\n            code.insert(0, ""class {0}({1}):"".format(pyclassname, "", "".join(bases)))\n\n            if pyclassname in classes:\n                versions = classes[pyclassname]._versions\n            else:\n                versions = {}\n\n            classes[""versions""] = versions\n            pyclass = _makeclass(streamerinfo._fName, id(streamerinfo), ""\\n"".join(code), classes)\n            streamerinfo.pyclass = pyclass\n            versions[pyclass._classversion] = pyclass\n\n    return classes\n\ndef _makeclass(classname, id, codestr, classes):\n    exec(compile(codestr, ""<generated from TStreamerInfo {0} at 0x{1:012x}>"".format(repr(classname), id), ""exec""), classes)\n    out = classes[_safename(classname)]\n    out._pycode = codestr\n    return out\n\n################################################################ built-in ROOT objects for bootstrapping up to streamed classes\n\nclass ROOTObject(object):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (type,), {})\n\n    _copycontext = False\n\n    @property\n    def _classname(self):\n        return self.__class__.__name__\n\n    @classmethod\n    def read(cls, source, cursor, context, parent):\n        if cls._copycontext:\n            context = context.copy()\n        out = cls.__new__(cls)\n        out = cls._readinto(out, source, cursor, context, parent)\n        out._postprocess(source, cursor, context, parent)\n        return out\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        raise NotImplementedError\n\n    def _postprocess(self, source, cursor, context, parent):\n        pass\n\n    def __repr__(self):\n        if hasattr(self, ""_fName""):\n            return ""<{0} {1} at 0x{2:012x}>"".format(self.__class__.__name__, repr(self._fName), id(self))\n        else:\n            return ""<{0} at 0x{1:012x}>"".format(self.__class__.__name__, id(self))\n\nclass TKey(ROOTObject):\n    _classname = b""TKey""\n    classname = ""TKey""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start = cursor.index\n\n        self._fNbytes, self._fVersion, self._fObjlen, self._fDatime, self._fKeylen, self._fCycle, self._fSeekKey, self._fSeekPdir = cursor.fields(source, self._format_small)\n        if self._fVersion > 1000:\n            cursor.index = start\n            self._fNbytes, self._fVersion, self._fObjlen, self._fDatime, self._fKeylen, self._fCycle, self._fSeekKey, self._fSeekPdir = cursor.fields(source, self._format_big)\n\n        self._fClassName = cursor.string(source)\n        self._fName = cursor.string(source)\n        self._fTitle = cursor.string(source)\n\n        # if source.size() is not None:\n        #     if source.size() - self._fSeekKey < self._fNbytes:\n        #         raise ValueError(""TKey declares that object {0} has {1} bytes but only {2} remain in the file (after the key)"".format(repr(self._fName), self._fNbytes, source.size() - self._fSeekKey))\n\n        # object size != compressed size means it\'s compressed\n        if self._fObjlen != self._fNbytes - self._fKeylen:\n            self._source = uproot.source.compressed.CompressedSource(context.compression, source, Cursor(self._fSeekKey + self._fKeylen), self._fNbytes - self._fKeylen, self._fObjlen)\n            self._cursor = Cursor(0, origin=-self._fKeylen)\n\n        # otherwise, it\'s uncompressed\n        else:\n            self._source = source\n            self._cursor = Cursor(self._fSeekKey + self._fKeylen, origin=self._fSeekKey)\n\n        self._context = context\n        return self\n\n    _format_small = struct.Struct("">ihiIhhii"")\n    _format_big   = struct.Struct("">ihiIhhqq"")\n\n    def get(self, dismiss=True):\n        """"""Extract the object this key points to.\n\n        Objects are not read or decompressed until this function is explicitly called.\n        """"""\n\n        try:\n            return _classof(self._context, self._fClassName).read(self._source, self._cursor.copied(), self._context, self)\n        finally:\n            if dismiss:\n                self._source.dismiss()\n\ndef _canonicaltype(name):\n    for pattern, replacement in _canonicaltype.patterns:\n        name = pattern.sub(replacement, name)\n    return name\n\n_canonicaltype.patterns = [\n    (re.compile(br""\\bChar_t\\b""),       b""char""),               # Signed Character 1 byte (char)\n    (re.compile(br""\\bUChar_t\\b""),      b""unsigned char""),      # Unsigned Character 1 byte (unsigned char)\n    (re.compile(br""\\bShort_t\\b""),      b""short""),              # Signed Short integer 2 bytes (short)\n    (re.compile(br""\\bUShort_t\\b""),     b""unsigned short""),     # Unsigned Short integer 2 bytes (unsigned short)\n    (re.compile(br""\\bInt_t\\b""),        b""int""),                # Signed integer 4 bytes (int)\n    (re.compile(br""\\bUInt_t\\b""),       b""unsigned int""),       # Unsigned integer 4 bytes (unsigned int)\n    (re.compile(br""\\bSeek_t\\b""),       b""int""),                # File pointer (int)\n    (re.compile(br""\\bLong_t\\b""),       b""long""),               # Signed long integer 4 bytes (long)\n    (re.compile(br""\\bULong_t\\b""),      b""unsigned long""),      # Unsigned long integer 4 bytes (unsigned long)\n    (re.compile(br""\\bFloat_t\\b""),      b""float""),              # Float 4 bytes (float)\n    (re.compile(br""\\bFloat16_t\\b""),    b""float""),              # Float 4 bytes written with a truncated mantissa\n    (re.compile(br""\\bDouble_t\\b""),     b""double""),             # Double 8 bytes\n    (re.compile(br""\\bDouble32_t\\b""),   b""double""),             # Double 8 bytes in memory, written as a 4 bytes float\n    (re.compile(br""\\bLongDouble_t\\b""), b""long double""),        # Long Double\n    (re.compile(br""\\bText_t\\b""),       b""char""),               # General string (char)\n    (re.compile(br""\\bBool_t\\b""),       b""bool""),               # Boolean (0=false, 1=true) (bool)\n    (re.compile(br""\\bByte_t\\b""),       b""unsigned char""),      # Byte (8 bits) (unsigned char)\n    (re.compile(br""\\bVersion_t\\b""),    b""short""),              # Class version identifier (short)\n    (re.compile(br""\\bOption_t\\b""),     b""const char""),         # Option string (const char)\n    (re.compile(br""\\bSsiz_t\\b""),       b""int""),                # String size (int)\n    (re.compile(br""\\bReal_t\\b""),       b""float""),              # TVector and TMatrix element type (float)\n    (re.compile(br""\\bLong64_t\\b""),     b""long long""),          # Portable signed long integer 8 bytes\n    (re.compile(br""\\bULong64_t\\b""),    b""unsigned long long""), # Portable unsigned long integer 8 bytes\n    (re.compile(br""\\bAxis_t\\b""),       b""double""),             # Axis values type (double)\n    (re.compile(br""\\bStat_t\\b""),       b""double""),             # Statistics type (double)\n    (re.compile(br""\\bFont_t\\b""),       b""short""),              # Font number (short)\n    (re.compile(br""\\bStyle_t\\b""),      b""short""),              # Style number (short)\n    (re.compile(br""\\bMarker_t\\b""),     b""short""),              # Marker number (short)\n    (re.compile(br""\\bWidth_t\\b""),      b""short""),              # Line width (short)\n    (re.compile(br""\\bColor_t\\b""),      b""short""),              # Color number (short)\n    (re.compile(br""\\bSCoord_t\\b""),     b""short""),              # Screen coordinates (short)\n    (re.compile(br""\\bCoord_t\\b""),      b""double""),             # Pad world coordinates (double)\n    (re.compile(br""\\bAngle_t\\b""),      b""float""),              # Graphics angle (float)\n    (re.compile(br""\\bSize_t\\b""),       b""float""),              # Attribute size (float)\n    ]\n\nclass TStreamerInfo(ROOTObject):\n    _classname = b""TStreamerInfo""\n    classname = ""TStreamerInfo""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        self._fName = _canonicaltype(_nametitle(source, cursor)[0])\n        self._fCheckSum, self._fClassVersion = cursor.fields(source, TStreamerInfo._format)\n        self._fElements = _readobjany(source, cursor, context, parent)\n        assert isinstance(self._fElements, list)\n        _endcheck(start, cursor, cnt)\n        return self\n\n    _format = struct.Struct("">Ii"")\n\n    def show(self, stream=sys.stdout):\n        out = ""StreamerInfo for class: {0}, version={1}, checksum=0x{2:08x}\\n{3}{4}"".format(self._fName.decode(""ascii""), self._fClassVersion, self._fCheckSum, ""\\n"".join(""  "" + x.show(stream=None) for x in self._fElements), ""\\n"" if len(self._fElements) > 0 else """")\n        if stream is None:\n            return out\n        else:\n            stream.write(out)\n            stream.write(""\\n"")\n\nclass TStreamerElement(ROOTObject):\n    _classname = b""TStreamerElement""\n    classname = ""TStreamerElement""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n\n        self._fOffset = 0\n        # https://github.com/root-project/root/blob/master/core/meta/src/TStreamerElement.cxx#L505\n        self._fName, self._fTitle = _nametitle(source, cursor)\n        self._fType, self._fSize, self._fArrayLength, self._fArrayDim = cursor.fields(source, TStreamerElement._format1)\n\n        if self._classversion == 1:\n            n = cursor.field(source, TStreamerElement._format2)\n            self._fMaxIndex = cursor.array(source, n, "">i4"")\n        else:\n            self._fMaxIndex = cursor.array(source, 5, "">i4"")\n\n        self._fTypeName = _canonicaltype(cursor.string(source))\n\n        if self._fType == 11 and (self._fTypeName == ""Bool_t"" or self._fTypeName == ""bool""):\n            self._fType = 18\n\n        if self._classversion <= 2:\n            # FIXME\n            # self._fSize = self._fArrayLength * gROOT->GetType(GetTypeName())->Size()\n            pass\n\n        self._fXmin, self._fXmax, self._fFactor = 0.0, 0.0, 0.0\n        if self._classversion == 3:\n            self._fXmin, self._fXmax, self._fFactor = cursor.fields(source, TStreamerElement._format3)\n        if self._classversion > 3:\n            # FIXME\n            # if (TestBit(kHasRange)) GetRange(GetTitle(),fXmin,fXmax,fFactor)\n            pass\n\n        _endcheck(start, cursor, cnt)\n        return self\n\n    _format1 = struct.Struct("">iiii"")\n    _format2 = struct.Struct("">i"")\n    _format3 = struct.Struct("">ddd"")\n\n    def show(self, stream=sys.stdout):\n        out = ""{0:15s} {1:15s} offset={2:3d} type={3:2d} {4}"".format(self._fName.decode(""ascii""), self._fTypeName.decode(""ascii""), self._fOffset, self._fType, self._fTitle.decode(""ascii""))\n        if stream is None:\n            return out\n        else:\n            stream.write(out)\n            stream.write(""\\n"")\n\nclass TStreamerArtificial(TStreamerElement):\n    _classname = b""TStreamerArtificial""\n    classname = ""TStreamerArtificial""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        super(TStreamerArtificial, self)._readinto(self, source, cursor, context, parent)\n        _endcheck(start, cursor, cnt)\n        return self\n\nclass TStreamerBase(TStreamerElement):\n    _classname = b""TStreamerBase""\n    classname = ""TStreamerBase""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        super(TStreamerBase, self)._readinto(self, source, cursor, context, parent)\n        if self._classversion >= 2:\n            self._fBaseVersion = cursor.field(source, TStreamerBase._format)\n        _endcheck(start, cursor, cnt)\n        return self\n\n    _format = struct.Struct("">i"")\n\nclass TStreamerBasicPointer(TStreamerElement):\n    _classname = b""TStreamerBasicPointer""\n    classname = ""TStreamerBasicPointer""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        super(TStreamerBasicPointer, self)._readinto(self, source, cursor, context, parent)\n        self._fCountVersion = cursor.field(source, TStreamerBasicPointer._format)\n        self._fCountName = cursor.string(source)\n        self._fCountClass = cursor.string(source)\n        _endcheck(start, cursor, cnt)\n        return self\n\n    _format = struct.Struct("">i"")\n\nclass TStreamerBasicType(TStreamerElement):\n    _classname = b""TStreamerBasicType""\n    classname = ""TStreamerBasicType""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        super(TStreamerBasicType, self)._readinto(self, source, cursor, context, parent)\n\n        if uproot.const.kOffsetL < self._fType < uproot.const.kOffsetP:\n            self._fType -= uproot.const.kOffsetL\n\n        basic = True\n        if self._fType in (uproot.const.kBool, uproot.const.kUChar, uproot.const.kChar):\n            self._fSize = 1\n        elif self._fType in (uproot.const.kUShort, uproot.const.kShort):\n            self._fSize = 2\n        elif self._fType in (uproot.const.kBits, uproot.const.kUInt, uproot.const.kInt, uproot.const.kCounter):\n            self._fSize = 4\n        elif self._fType in (uproot.const.kULong, uproot.const.kULong64, uproot.const.kLong, uproot.const.kLong64):\n            self._fSize = 8\n        elif self._fType in (uproot.const.kFloat, uproot.const.kFloat16):\n            self._fSize = 4\n        elif self._fType in (uproot.const.kDouble, uproot.const.kDouble32):\n            self._fSize = 8\n        elif self._fType == uproot.const.kCharStar:\n            self._fSize = numpy.dtype(numpy.intp).itemsize\n        else:\n            basic = False\n\n        if basic and self._fArrayLength > 0:\n            self._fSize *= self._fArrayLength\n\n        _endcheck(start, cursor, cnt)\n        return self\n\nclass TStreamerLoop(TStreamerElement):\n    _classname = b""TStreamerLoop""\n    classname = ""TStreamerLoop""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        super(TStreamerLoop, self)._readinto(self, source, cursor, context, parent)\n        self._fCountVersion = cursor.field(source, TStreamerLoop._format)\n        self._fCountName = cursor.string(source)\n        self._fCountClass = cursor.string(source)\n        _endcheck(start, cursor, cnt)\n        return self\n\n    _format = struct.Struct("">i"")\n\nclass TStreamerObject(TStreamerElement):\n    _classname = b""TStreamerObject""\n    classname = ""TStreamerObject""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        super(TStreamerObject, self)._readinto(self, source, cursor, context, parent)\n        _endcheck(start, cursor, cnt)\n        return self\n\nclass TStreamerObjectAny(TStreamerElement):\n    _classname = b""TStreamerObjectAny""\n    classname = ""TStreamerObjectAny""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        super(TStreamerObjectAny, self)._readinto(self, source, cursor, context, parent)\n        _endcheck(start, cursor, cnt)\n        return self\n\nclass TStreamerObjectAnyPointer(TStreamerElement):\n    _classname = b""TStreamerObjectAnyPointer""\n    classname = ""TStreamerObjectAnyPointer""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        super(TStreamerObjectAnyPointer, self)._readinto(self, source, cursor, context, parent)\n        _endcheck(start, cursor, cnt)\n        return self\n\nclass TStreamerObjectPointer(TStreamerElement):\n    _classname = b""TStreamerObjectPointer""\n    classname = ""TStreamerObjectPointer""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        super(TStreamerObjectPointer, self)._readinto(self, source, cursor, context, parent)\n        _endcheck(start, cursor, cnt)\n        return self\n\nclass TStreamerSTL(TStreamerElement):\n    _classname = b""TStreamerSTL""\n    classname = ""TStreamerSTL""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        super(TStreamerSTL, self)._readinto(self, source, cursor, context, parent)\n\n        self._fSTLtype, self._fCtype = cursor.fields(source, TStreamerSTL._format)\n\n        if self._fSTLtype == uproot.const.kSTLmultimap or self._fSTLtype == uproot.const.kSTLset:\n            if self._fTypeName.startswith(b""std::set"") or self._fTypeName.startswith(b""set""):\n                self._fSTLtype = uproot.const.kSTLset\n            elif self._fTypeName.startswith(b""std::multimap"") or self._fTypeName.startswith(b""multimap""):\n                self._fSTLtype = uproot.const.kSTLmultimap\n\n        _endcheck(start, cursor, cnt)\n        return self\n\n    @classmethod\n    def vector(cls, fType, fTypeName):\n        self = cls.__new__(cls)\n        self._fSTLtype = uproot.const.kSTLvector\n        self._fCtype = fType\n        self._fTypeName = b""vector<"" + fTypeName + b"">""\n        return self\n\n    _format = struct.Struct("">ii"")\n\nclass TStreamerSTLstring(TStreamerSTL):\n    _classname = b""TStreamerSTLstring""\n    classname = ""TStreamerSTLstring""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        super(TStreamerSTLstring, self)._readinto(self, source, cursor, context, parent)\n        _endcheck(start, cursor, cnt)\n        return self\n\nclass TStreamerString(TStreamerElement):\n    _classname = b""TStreamerString""\n    classname = ""TStreamerString""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        super(TStreamerString, self)._readinto(self, source, cursor, context, parent)\n        _endcheck(start, cursor, cnt)\n        return self\n\n################################################################ streamed classes (with some overrides)\n\nclass ROOTStreamedObject(ROOTObject):\n    _fields = []\n\n    @classmethod\n    def _members(cls):\n        out = []\n        for t in cls.__bases__:\n            if issubclass(t, ROOTStreamedObject):\n                out.extend(t._members())\n        out.extend(cls._fields)\n        return out\n\n    @classmethod\n    def _recarray(cls):\n        raise ValueError(""not a recarray"")\n\n    @classmethod\n    def _recarray_dtype(cls, cntvers=False, tobject=True):\n        dtypesin = cls._recarray()\n        dtypesout = []\n        used = set()\n        allhidden = True\n        for name, dtype in dtypesin:\n            if name in used:\n                i = 2\n                trial = name + str(i)\n                while trial in used:\n                    i += 1\n                    trial = name + str(i)\n                name = trial\n\n            if (cntvers or not (name == "" cnt"" or name == "" vers"")) and (tobject or not (name == "" fUniqueID"" or name == "" fBits"")):\n                dtypesout.append((name, dtype))\n                used.add(name)\n                if not name.startswith("" ""):\n                    allhidden = False\n\n        if allhidden:\n            raise ValueError(""not a recarray"")\n\n        return numpy.dtype(dtypesout)\n\nclass TObject(ROOTStreamedObject):\n    _classname = b""TObject""\n    classname = ""TObject""\n\n    @classmethod\n    def _recarray(cls):\n        return [("" fBits"", numpy.dtype("">u8"")), ("" fUniqueID"", numpy.dtype("">u8""))]\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        _skiptobj(source, cursor)\n        return self\n\nclass TString(bytes, ROOTStreamedObject):\n    _classname = b""TString""\n    classname = ""TString""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        return TString(cursor.string(source))\n\n    def __str__(self):\n        return self.decode(""utf-8"", ""replace"")\n\nclass TNamed(TObject):\n    _classname = b""TNamed""\n    classname = ""TNamed""\n    _fields = [""fName"", ""fTitle""]\n\n    @classmethod\n    def _recarray(cls):\n        raise ValueError(""not a recarray"")\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        TObject._readinto(self, source, cursor, context, parent)\n        self._fName = cursor.string(source)\n        self._fTitle = cursor.string(source)\n        _endcheck(start, cursor, cnt)\n        return self\n\nclass TObjArray(list, ROOTStreamedObject):\n    _classname = b""TObjArray""\n    classname = ""TObjArray""\n\n    @classmethod\n    def read(cls, source, cursor, context, parent, asclass=None):\n        if cls._copycontext:\n            context = context.copy()\n        out = cls.__new__(cls)\n        out = cls._readinto(out, source, cursor, context, parent, asclass=asclass)\n        out._postprocess(source, cursor, context, parent)\n        return out\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent, asclass=None):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        _skiptobj(source, cursor)\n        name = cursor.string(source)\n        size, low = cursor.fields(source, struct.Struct("">ii""))\n        self.extend([_readobjany(source, cursor, context, parent, asclass=asclass) for i in range(size)])\n        _endcheck(start, cursor, cnt)\n        return self\n\nclass TObjString(bytes, ROOTStreamedObject):\n    _classname = b""TObjString""\n    classname = ""TObjString""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        _skiptobj(source, cursor)\n        string = cursor.string(source)\n        _endcheck(start, cursor, cnt)\n        return TObjString(string)\n\n    def __str__(self):\n        return self.decode(""utf-8"", ""replace"")\n\nclass TList(list, ROOTStreamedObject):\n    _classname = b""TList""\n    classname = ""TList""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        _skiptobj(source, cursor)\n        name = cursor.string(source)\n        size = cursor.field(source, struct.Struct("">i""))\n        for i in range(size):\n            self.append(_readobjany(source, cursor, context, parent))\n            n = cursor.field(source, TList._format_n)  # ignore option\n            cursor.bytes(source, n)\n        _endcheck(start, cursor, cnt)\n        return self\n    _format_n = struct.Struct("">B"")\n\nclass THashList(TList):\n    _classname = b""THashList""\n    classname = ""THashList""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        TList._readinto(self, source, cursor, context, parent)\n        return self\n\nclass TRef(ROOTStreamedObject):\n    _classname = b""TRef""\n    classname = ""TRef""\n\n    _format1 = struct.Struct("">xxIxxxxxx"")\n\n    def __init__(self, id):\n        self.id = id\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        self.id = cursor.field(source, self._format1)\n        return self\n\n    def __repr__(self):\n        return ""<TRef {0}>"".format(self.id)\n\n    @classmethod\n    def _recarray(cls):\n        out = []\n        out.append((""pidf"", "">u2""))\n        out.append((""id"", "">u4""))\n        out.append(("" other"", ""S6""))\n        return out\n\nTRef._methods = TRef\nTRef._arraymethods = None\nTRef._fromrow = lambda row: TRef(row[""id""])\n\nclass TRefArray(list, ROOTStreamedObject):\n    _classname = b""TRefArray""\n    classname = ""TRefArray""\n\n    _format1 = struct.Struct("">i"")\n    _dtype = numpy.dtype("">i4"")\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        cursor.skip(10)\n        self.name = cursor.string(source)\n        self.length = cursor.field(source, self._format1)\n        cursor.skip(6)\n        self.extend(cursor.array(source, self.length, self._dtype))\n        _endcheck(start, cursor, cnt)\n        return self\n\n    @property\n    def nbytes(self):\n        return len(self) * self._dtype.itemsize\n\n    def tostring(self):\n        return numpy.asarray(self, dtype=self._dtype).tostring()\n\nclass TArray(list, ROOTStreamedObject):\n    _classname = b""TArray""\n    classname = ""TArray""\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        length = cursor.field(source, TArray._format)\n        self.extend(cursor.array(source, length, self._dtype))\n        return self\n    _format = struct.Struct("">i"")\n\n    @property\n    def nbytes(self):\n        return len(self) * self._dtype.itemsize\n\n    def tostring(self):\n        return numpy.asarray(self, dtype=self._dtype).tostring()\n\nclass TArrayC(TArray):\n    _classname = b""TArrayC""\n    classname = ""TArrayC""\n    _dtype = numpy.dtype("">i1"")\n\nclass TArrayS(TArray):\n    _classname = b""TArrayS""\n    classname = ""TArrayS""\n    _dtype = numpy.dtype("">i2"")\n\nclass TArrayI(TArray):\n    _classname = b""TArrayI""\n    classname = ""TArrayI""\n    _dtype = numpy.dtype("">i4"")\n\nclass TArrayL(TArray):\n    _classname = b""TArrayL""\n    classname = ""TArrayL""\n    _dtype = numpy.dtype(numpy.int_).newbyteorder("">"")\n\nclass TArrayL64(TArray):\n    _classname = b""TArrayL64""\n    classname = ""TArrayL64""\n    _dtype = numpy.dtype("">i8"")\n\nclass TArrayF(TArray):\n    _classname = b""TArrayF""\n    classname = ""TArrayF""\n    _dtype = numpy.dtype("">f4"")\n\nclass TArrayD(TArray):\n    _classname = b""TArrayD""\n    classname = ""TArrayD""\n    _dtype = numpy.dtype("">f8"")\n\n# FIXME: I want to generalize this. It\'s the first example of a class that doesn\'t\n# follow the usual pattern. The full 11 bytes are\n#\n#     ""40 00 00 07 00 00 1a a1 2f 10 00""\n#\n# I\'m reasonably certain the first ""40 00 00 07"" is count with a kByteCountMask.\n# The next ""00 00"" probably isn\'t the version, since the streamer said it\'s version 1.\n# I\'m also reasonably certain that the last byte is the fIOBits data.\n# That leaves 4 bytes unaccounted for.\nclass ROOT_3a3a_TIOFeatures(ROOTStreamedObject):\n    _classname = b""ROOT::TIOFeatures""\n    classname = ""ROOT::TIOFeatures""\n    _fields = [""fIOBits""]\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        cursor.skip(4)\n        self._fIOBits = cursor.field(source, ROOT_3a3a_TIOFeatures._format1)\n        _endcheck(start, cursor, cnt)\n        return self\n\n    _format1 = struct.Struct("">B"")\n\nclass ROOT_3a3a_Experimental_3a3a_RNTuple(ROOTStreamedObject):\n    _classname = b""ROOT::Experimental::RNTuple""\n    classname = ""ROOT::Experimental::RNTuple""\n    _fields = [""fVersion"",\n               ""fSize"",\n               ""fSeekHeader"",\n               ""fNBytesHeader"",\n               ""fLenHeader"",\n               ""fSeekFooter"",\n               ""fNBytesFooter"",\n               ""fLenFooter"",\n               ""fReserved""]\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        cursor.skip(4)\n        self._fVersion, self._fSize, self._fSeekHeader, self._fNBytesHeader, self._fLenHeader, self._fSeekFooter, self._fNBytesFooter, self._fLenFooter, self._fReserved = cursor.fields(source, ROOT_3a3a_Experimental_3a3a_RNTuple._format1)\n        return self\n\n    _format1 = struct.Struct("">IIQIIQIIQ"")\n\nclass Undefined(ROOTStreamedObject):\n    _classname = None\n    classname = None\n\n    @classmethod\n    def read(cls, source, cursor, context, parent, classname=None):\n        if cls._copycontext:\n            context = context.copy()\n        out = cls.__new__(cls)\n        out = cls._readinto(out, source, cursor, context, parent)\n        out._postprocess(source, cursor, context, parent)\n        out._classname = classname\n        return out\n\n    @classmethod\n    def _readinto(cls, self, source, cursor, context, parent):\n        self._cursor = cursor.copied()\n        start, cnt, self._classversion = _startcheck(source, cursor)\n        if cnt is None:\n            raise TypeError(""cannot read objects of type {0} and cannot even skip over this one (returning Undefined) because its size is not known\\n  in file: {1}"".format(""???"" if self._classname is None else self._classname.decode(""ascii""), context.sourcepath))\n\n        cursor.skip(cnt - 6)\n        _endcheck(start, cursor, cnt)\n        return self\n\n    def __repr__(self):\n        if self._classname is not None:\n            return ""<{0} (failed to read {1} version {2}) at 0x{3:012x}>"".format(self.__class__.__name__, repr(self._classname), self._classversion, id(self))\n        else:\n            return ""<{0} at 0x{1:012x}>"".format(self.__class__.__name__, id(self))\n\nbuiltin_classes = {""uproot_methods"": uproot_methods,\n                   ""TObject"":        TObject,\n                   ""TString"":        TString,\n                   ""TNamed"":         TNamed,\n                   ""TObjArray"":      TObjArray,\n                   ""TObjString"":     TObjString,\n                   ""TList"":          TList,\n                   ""THashList"":      THashList,\n                   ""TRef"":           TRef,\n                   ""TArray"":         TArray,\n                   ""TArrayC"":        TArrayC,\n                   ""TArrayS"":        TArrayS,\n                   ""TArrayI"":        TArrayI,\n                   ""TArrayL"":        TArrayL,\n                   ""TArrayL64"":      TArrayL64,\n                   ""TArrayF"":        TArrayF,\n                   ""TArrayD"":        TArrayD,\n                   ""TRefArray"":      TRefArray,\n                   ""ROOT_3a3a_TIOFeatures"": ROOT_3a3a_TIOFeatures,\n                   ""ROOT_3a3a_Experimental_3a3a_RNTuple"": ROOT_3a3a_Experimental_3a3a_RNTuple}\n\nbuiltin_skip =    {""TBranch"":    [""fBaskets""],\n                   ""TTree"":      [""fUserInfo"", ""fBranchRef""]}\n'"
uproot/tree.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport base64\nimport codecs\nimport glob\nimport importlib\nimport inspect\nimport itertools\nimport math\nimport numbers\nimport os\nimport re\nimport struct\nimport sys\nimport threading\nfrom collections import namedtuple\nfrom collections import OrderedDict\ntry:\n    from urlparse import urlparse\nexcept ImportError:\n    from urllib.parse import urlparse\n\nimport numpy\nimport cachetools\n\nimport awkward\nimport uproot_methods.profiles\n\nimport uproot.rootio\nfrom uproot.rootio import _bytesid\nfrom uproot.rootio import _memsize\nfrom uproot.rootio import nofilter\nfrom uproot.rootio import _safename\nfrom uproot.interp.auto import interpret\nfrom uproot.interp.numerical import asdtype\nfrom uproot.interp.jagged import asjagged\nfrom uproot.interp.objects import asobj\nfrom uproot.interp.objects import asgenobj\nfrom uproot.source.cursor import Cursor\nfrom uproot.source.memmap import MemmapSource\nfrom uproot.source.xrootd import XRootDSource\nfrom uproot.source.http import HTTPSource\n\nif sys.version_info[0] <= 2:\n    string_types = (unicode, str)\nelse:\n    string_types = (str, bytes)\n\ndef _delayedraise(excinfo):\n    if excinfo is not None:\n        cls, err, trc = excinfo\n        if sys.version_info[0] <= 2:\n            exec(""raise cls, err, trc"")\n        else:\n            raise err.with_traceback(trc)\n\ndef _filename_explode(x):\n    if isinstance(x, getattr(os, ""PathLike"", ())):\n        x = os.fspath(x)\n    elif hasattr(x, ""__fspath__""):\n        x = x.__fspath__()\n    elif x.__class__.__module__ == ""pathlib"":\n        import pathlib\n        if isinstance(x, pathlib.Path):\n             x = str(x)\n    parsed = urlparse(x)\n    if _bytesid(parsed.scheme) == b""file"" or len(parsed.scheme) == 0 or (os.name == ""nt"" and _filename_explode._windows_absolute.match(x) is not None):\n        if not (os.name == ""nt"" and _filename_explode._windows_absolute.match(x) is not None):\n            path = parsed.netloc + parsed.path\n        pattern = os.path.expanduser(path)\n        if ""*"" in pattern or ""?"" in pattern or ""["" in pattern:\n            out = sorted(glob.glob(pattern))\n            if len(out) == 0:\n                raise TypeError(""no matches for filename {0}"".format(repr(pattern)))\n        else:\n            out = [pattern]\n        return out\n    else:\n        return [x]\n\n_filename_explode._windows_absolute = re.compile(r""^[A-Za-z]:\\\\"")\n\ndef _normalize_awkwardlib(awkwardlib):\n    if awkwardlib is None:\n        return awkward\n    elif isinstance(awkwardlib, str):\n        return importlib.import_module(awkwardlib)\n    else:\n        return awkwardlib\n\ndef _normalize_entrystartstop(numentries, entrystart, entrystop):\n    if entrystart is None:\n        entrystart = 0\n    elif entrystart < 0:\n        entrystart += numentries\n    entrystart = min(numentries, max(0, entrystart))\n\n    if entrystop is None:\n        entrystop = numentries\n    elif entrystop < 0:\n        entrystop += numentries\n    entrystop = min(numentries, max(0, entrystop))\n\n    if entrystop < entrystart:\n        raise IndexError(""entrystop must be greater than or equal to entrystart"")\n\n    return int(entrystart), int(entrystop)\n\n################################################################ high-level interface\n\ndef iterate(path, treepath, branches=None, entrysteps=float(""inf""), outputtype=dict, namedecode=None, reportpath=False, reportfile=False, reportentries=False, flatten=False, flatname=None, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, blocking=True, localsource=MemmapSource.defaults, xrootdsource=XRootDSource.defaults, httpsource=HTTPSource.defaults, **options):\n    awkward = _normalize_awkwardlib(awkwardlib)\n    for tree, branchesinterp, globalentrystart, thispath, thisfile in _iterate(path, treepath, branches, awkward, localsource, xrootdsource, httpsource, **options):\n        for start, stop, arrays in tree.iterate(branches=branchesinterp, entrysteps=entrysteps, outputtype=outputtype, namedecode=namedecode, reportentries=True, entrystart=0, entrystop=tree.numentries, flatten=flatten, flatname=flatname, awkwardlib=awkward, cache=cache, basketcache=basketcache, keycache=keycache, executor=executor, blocking=blocking):\n\n            if getattr(outputtype, ""__name__"", None) == ""DataFrame"" and getattr(outputtype, ""__module__"", None) == ""pandas.core.frame"":\n                if type(arrays.index).__name__ == ""MultiIndex"":\n                    if hasattr(arrays.index.levels[0], ""array""):\n                        index = arrays.index.levels[0].array   # pandas>=0.24.0\n                    else:\n                        index = arrays.index.levels[0].values  # pandas<0.24.0\n                    awkward.numpy.add(index, globalentrystart, out=index)\n\n                elif type(arrays.index).__name__ == ""RangeIndex"":\n                    if hasattr(arrays.index, ""start"") and hasattr(arrays.index, ""stop""):\n                        indexstart = arrays.index.start        # pandas>=0.25.0\n                        indexstop = arrays.index.stop\n                    else:\n                        indexstart = arrays.index._start       # pandas<0.25.0\n                        indexstop = arrays.index._stop\n                    arrays.index = type(arrays.index)(indexstart + globalentrystart, indexstop + globalentrystart)\n\n                else:\n                    if hasattr(arrays.index, ""array""):\n                        index = arrays.index.array             # pandas>=0.24.0\n                    else:\n                        index = arrays.index.values            # pandas<0.24.0\n                    awkward.numpy.add(index, globalentrystart, out=index)\n\n            out = (arrays,)\n            if reportentries:\n                out = (globalentrystart + start, globalentrystart + stop) + out\n            if reportfile:\n                out = (thisfile,) + out\n            if reportpath:\n                out = (thispath,) + out\n            if len(out) == 1:\n                yield out[0]\n            else:\n                yield out\n\ndef _iterate(path, treepath, branches, awkward, localsource, xrootdsource, httpsource, **options):\n    if isinstance(path, string_types):\n        paths = _filename_explode(path)\n    else:\n        paths = [y for x in path for y in _filename_explode(x)]\n\n    globalentrystart = 0\n    for path in paths:\n        file = uproot.rootio.open(path, localsource=localsource, xrootdsource=xrootdsource, httpsource=httpsource, **options)\n        try:\n            tree = file[treepath]\n        except KeyError:\n            continue\n        branchesinterp = OrderedDict()\n        for branch, interpretation in tree._normalize_branches(branches, awkward):\n            branchesinterp[branch.name] = interpretation\n\n        yield tree, branchesinterp, globalentrystart, path, file\n        globalentrystart += tree.numentries\n\n################################################################ methods for TTree\n\nclass TTreeMethods(object):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (uproot.rootio.ROOTObject.__metaclass__,), {})\n\n    _copycontext = True\n\n    _vector_regex = re.compile(b""^vector<(.+)>$"")\n    _objectpointer_regex = re.compile(br""\\(([^()]*)\\)$"")\n\n    def _attachstreamer(self, branch, streamer, streamerinfosmap, isTClonesArray):\n        if streamer is None:\n            m = re.match(self._vector_regex, getattr(branch, ""_fClassName"", b""""))\n\n            if m is None:\n                if branch.name in streamerinfosmap:\n                    streamer = streamerinfosmap[branch.name]\n                else:\n                    return\n\n            else:\n                if m.group(1) in streamerinfosmap:\n                    substreamer = streamerinfosmap[m.group(1)]\n                    if isinstance(substreamer, uproot.rootio.TStreamerInfo):\n                        streamer = uproot.rootio.TStreamerSTL.vector(None, substreamer._fName)\n                    else:\n                        streamer = uproot.rootio.TStreamerSTL.vector(substreamer._fType, substreamer._fTypeName)\n                else:\n                    return\n\n        if isinstance(streamer, uproot.rootio.TStreamerInfo):\n            if len(streamer._fElements) == 1 and isinstance(streamer._fElements[0], uproot.rootio.TStreamerBase) and streamer._fElements[0]._fName == b""TObjArray"":\n                if streamer._fName == b""TClonesArray"":\n                    return self._attachstreamer(branch, streamerinfosmap.get(branch._fClonesName, None), streamerinfosmap, True)\n                else:\n                    # FIXME: can only determine streamer by reading some values?\n                    return\n\n            elif len(streamer._fElements) == 1 and isinstance(streamer._fElements[0], uproot.rootio.TStreamerSTL) and streamer._fElements[0]._fName == b""This"":\n                return self._attachstreamer(branch, streamer._fElements[0], streamerinfosmap, isTClonesArray)\n\n        if isinstance(streamer, uproot.rootio.TStreamerObject):\n            if streamer._fTypeName == b""TClonesArray"":\n                return self._attachstreamer(branch, streamerinfosmap.get(branch._fClonesName, None), streamerinfosmap, True)\n            else:\n                return self._attachstreamer(branch, streamerinfosmap.get(streamer._fTypeName, None), streamerinfosmap, True)\n\n        branch._streamer = streamer\n        branch._isTClonesArray = isTClonesArray\n        if isinstance(streamer, uproot.rootio.TStreamerSTL) and streamer._fSTLtype == uproot.const.kSTLvector:\n            branch._vecstreamer = streamerinfosmap.get(re.match(self._vector_regex, streamer._fTypeName).group(1), None)\n            isTClonesArray = True\n        else:\n            branch._vecstreamer = None\n\n        digDeeperTypes = (uproot.rootio.TStreamerObject, uproot.rootio.TStreamerObjectAny, uproot.rootio.TStreamerObjectPointer, uproot.rootio.TStreamerObjectAnyPointer)\n\n        members = None\n        if isinstance(streamer, uproot.rootio.TStreamerInfo):\n            members = streamer.members\n        elif isinstance(streamer, digDeeperTypes):\n            typename = streamer._fTypeName.rstrip(b""*"")\n            if typename in streamerinfosmap:\n                m = self._objectpointer_regex.search(streamer._fTitle)\n                if typename == b\'TClonesArray\' and m is not None:\n                    typename = m.group(1)\n                members = streamerinfosmap[typename].members\n        elif isinstance(streamer, uproot.rootio.TStreamerSTL):\n            try:\n                # FIXME: string manipulation only works for one-parameter templates\n                typename = streamer._fTypeName[streamer._fTypeName.index(b""<"") + 1 : streamer._fTypeName.rindex(b"">"")].rstrip(b""*"")\n            except ValueError:\n                pass\n            else:\n                if typename in streamerinfosmap:\n                    members = streamerinfosmap[typename].members\n\n        if members is not None:\n            for subbranch in branch.itervalues(recursive=True):\n                name = subbranch._fName\n                if name.startswith(branch._fName + b"".""):           # drop parent branch\'s name\n                    name = name[len(branch._fName) + 1:]\n\n                submembers = members\n                while True:                                        # drop nested struct names one at a time\n                    try:\n                        index = name.index(b""."")\n                    except ValueError:\n                        break\n                    else:\n                        base, name = name[:index], name[index + 1:]\n                        if base in submembers and isinstance(submembers[base], digDeeperTypes):\n                            key = submembers[base]._fTypeName.rstrip(b""*"")\n                            try:\n                                submembers = streamerinfosmap[key].members\n                            except KeyError:\n                                for regex, substitution in uproot.interp.auto.streamer_aliases:\n                                    new_key, n_matched = regex.subn(substitution, key)\n                                    if n_matched:\n                                        submembers = streamerinfosmap[new_key].members\n                                        self._context.classes[_safename(key)] = self._context.classes[_safename(new_key)]\n                                        break\n                                else:\n                                    raise\n\n                try:\n                    name = name[:name.index(b""["")]\n                except ValueError:\n                    pass\n\n                self._attachstreamer(subbranch, submembers.get(name, None), streamerinfosmap, isTClonesArray)\n\n    def _postprocess(self, source, cursor, context, parent):\n        self._context = context\n        self._context.treename = self.name\n        self._context.speedbump = True\n\n        for branch in self._fBranches:\n            self._attachstreamer(branch, context.streamerinfosmap.get(getattr(branch, ""_fClassName"", None), None), context.streamerinfosmap, False)\n\n        self._branchlookup = {}\n        self._fill_branchlookup(self._branchlookup)\n\n        leaf2branch = {}\n        for branch in self.itervalues(recursive=True):\n            if len(branch._fLeaves) == 1:\n                leaf2branch[id(branch._fLeaves[0])] = branch\n\n        for branch in self.itervalues(recursive=True):\n            if len(branch._fLeaves) > 0:\n                branch._countleaf = branch._fLeaves[0]._fLeafCount\n                if branch._countleaf is not None:\n                    branch._countbranch = leaf2branch.get(id(branch._countleaf), None)\n\n        if getattr(self, ""_fAliases"", None) is None:\n            self.aliases = {}\n        else:\n            self.aliases = dict((alias._fName, alias._fTitle) for alias in self._fAliases)\n\n    def _fill_branchlookup(self, branchlookup):\n        for subbranch in self._fBranches:\n            subbranch._fill_branchlookup(branchlookup)\n            branchlookup[subbranch.name] = subbranch\n\n    @property\n    def name(self):\n        return self._fName\n\n    @property\n    def title(self):\n        return self._fTitle\n\n    @property\n    def numentries(self):\n        return int(self._fEntries)\n\n    @property\n    def numbranches(self):\n        count = 0\n        for x in self.itervalues(recursive=True):\n            count += 1\n        return count\n\n    def iterkeys(self, recursive=False, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        for branch in self.itervalues(recursive, filtername, filtertitle):\n            if aliases:\n                for aliasname, branchname in self.aliases.items():\n                    if branch.name == branchname:\n                        yield aliasname\n            yield branch.name\n\n    def itervalues(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        for branch in self._fBranches:\n            if filtername(branch.name) and filtertitle(branch.title):\n                yield branch\n            if recursive:\n                for x in branch.itervalues(recursive, filtername, filtertitle):\n                    yield x\n\n    def iteritems(self, recursive=False, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        for branch in self.itervalues(recursive, filtername, filtertitle):\n            if aliases:\n                for aliasname, branchname in self.aliases.items():\n                    if branch.name == branchname:\n                        yield aliasname, branch\n            yield branch.name, branch\n\n    def keys(self, recursive=False, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        return list(self.iterkeys(recursive=recursive, filtername=filtername, filtertitle=filtertitle, aliases=aliases))\n\n    def _ipython_key_completions_(self):\n        ""Support for completion of keys in an IPython kernel""\n        return [item.decode(""ascii"") for item in self.iterkeys()]\n\n    def values(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        return list(self.itervalues(recursive=recursive, filtername=filtername, filtertitle=filtertitle))\n\n    def items(self, recursive=False, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        return list(self.iteritems(recursive=recursive, filtername=filtername, filtertitle=filtertitle, aliases=aliases))\n\n    def allkeys(self, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        return self.keys(recursive=True, filtername=filtername, filtertitle=filtertitle, aliases=aliases)\n\n    def allvalues(self, filtername=nofilter, filtertitle=nofilter):\n        return self.values(recursive=True, filtername=filtername, filtertitle=filtertitle)\n\n    def allitems(self, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        return self.items(recursive=True, filtername=filtername, filtertitle=filtertitle, aliases=aliases)\n\n    def get(self, name, recursive=True, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        name = _bytesid(name)\n        try:\n            return self._branchlookup[name]\n        except KeyError:\n            for n, b in self.iteritems(recursive=recursive, filtername=filtername, filtertitle=filtertitle, aliases=aliases):\n                if n == name:\n                    self._branchlookup[name] = b\n                    return b\n            raise uproot.rootio._KeyError(""not found: {0}\\n in file: {1}"".format(repr(name), self._context.sourcepath))\n\n    def __contains__(self, name):\n        try:\n            self.get(name)\n        except KeyError:\n            return False\n        else:\n            return True\n\n    def mempartitions(self, numbytes, branches=None, entrystart=None, entrystop=None, keycache=None, linear=True):\n        m = _memsize(numbytes)\n        if m is not None:\n            numbytes = m\n\n        if numbytes <= 0:\n            raise ValueError(""target numbytes must be positive"")\n\n        awkward = _normalize_awkwardlib(None)\n        branches = list(self._normalize_branches(branches, awkward))\n        entrystart, entrystop = _normalize_entrystartstop(self.numentries, entrystart, entrystop)\n\n        if not linear:\n            raise NotImplementedError(""non-linear mempartition has not been implemented"")\n\n        relevant_numbytes = 0.0\n        for branch, interpretation in branches:\n            if branch._recoveredbaskets is None:\n                branch._tryrecover()\n            for i, key in enumerate(branch._threadsafe_iterate_keys(keycache, False)):\n                start, stop = branch._entryoffsets[i], branch._entryoffsets[i + 1]\n                if entrystart < stop and start < entrystop:\n                    this_numbytes = key._fObjlen * (min(stop, entrystop) - max(start, entrystart)) / float(stop - start)\n                    assert this_numbytes >= 0.0\n                    relevant_numbytes += this_numbytes\n\n        entrysteps = max(1, int(round(math.ceil((entrystop - entrystart) * numbytes / relevant_numbytes))))\n\n        start, stop = entrystart, entrystart\n        while stop < entrystop:\n            stop = min(stop + entrysteps, entrystop)\n            if stop > start:\n                yield start, stop\n            start = stop\n\n    def clusters(self, branches=None, entrystart=None, entrystop=None, strict=False):\n        awkward = _normalize_awkwardlib(None)\n        branches = list(self._normalize_branches(branches, awkward))\n\n        # convenience class; simplifies presentation of the algorithm\n        class BranchCursor(object):\n            def __init__(self, branch):\n                self.branch = branch\n                self.basketstart = 0\n                self.basketstop = 0\n            @property\n            def entrystart(self):\n                return self.branch.basket_entrystart(self.basketstart)\n            @property\n            def entrystop(self):\n                return self.branch.basket_entrystop(self.basketstop)\n\n        cursors = [BranchCursor(branch) for branch, interpretation in branches if branch.numbaskets > 0]\n\n        if len(cursors) == 0:\n            yield _normalize_entrystartstop(self.numentries, entrystart, entrystop)\n\n        else:\n            # everybody starts at the same entry number; if there is no such place before someone runs out of baskets, there will be an exception\n            leadingstart = max(cursor.entrystart for cursor in cursors)\n            while not all(cursor.entrystart == leadingstart for cursor in cursors):\n                for cursor in cursors:\n                    while cursor.entrystart < leadingstart:\n                        cursor.basketstart += 1\n                        cursor.basketstop += 1\n                leadingstart = max(cursor.entrystart for cursor in cursors)\n\n            entrystart, entrystop = _normalize_entrystartstop(self.numentries, entrystart, entrystop)\n\n            # move all cursors forward, yielding a (start, stop) pair if their baskets line up\n            while any(cursor.basketstop < cursor.branch.numbaskets for cursor in cursors):\n                # move all subleading baskets forward until they are no longer subleading\n                leadingstop = max(cursor.entrystop for cursor in cursors)\n                for cursor in cursors:\n                    while cursor.entrystop < leadingstop:\n                        cursor.basketstop += 1\n\n                # if they all line up, this is a good cluster\n                if all(cursor.entrystop == leadingstop for cursor in cursors):\n                    # check to see if it\'s within the bounds the user requested (strictly or not strictly)\n                    if strict:\n                        if entrystart <= leadingstart and leadingstop <= entrystop:\n                            yield leadingstart, leadingstop\n                    else:\n                        if entrystart < leadingstop and leadingstart < entrystop:\n                            yield leadingstart, leadingstop\n\n                    # anyway, move all the starts to the new stopping position and move all stops forward by one\n                    leadingstart = leadingstop\n                    for cursor in cursors:\n                        cursor.basketstart = cursor.basketstop\n                        cursor.basketstop += 1\n\n                # stop iterating if we\'re past all acceptable clusters\n                if leadingstart >= entrystop:\n                    break\n\n    def array(self, branch, interpretation=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, blocking=True):\n        awkward = _normalize_awkwardlib(awkwardlib)\n        branches = list(self._normalize_branches(branch, awkward))\n        if len(branches) == 1:\n            if interpretation is None:\n                tbranch, interpretation = branches[0]\n            else:\n                tbranch, _ = branches[0]\n        else:\n            raise ValueError(""list of branch names or glob/regex matches more than one branch; use TTree.arrays (plural)"")\n        return tbranch.array(interpretation=interpretation, entrystart=entrystart, entrystop=entrystop, flatten=flatten, awkwardlib=awkwardlib, cache=cache, basketcache=basketcache, keycache=keycache, executor=executor, blocking=blocking)\n\n    def arrays(self, branches=None, outputtype=dict, namedecode=None, entrystart=None, entrystop=None, flatten=False, flatname=None, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, blocking=True):\n        awkward = _normalize_awkwardlib(awkwardlib)\n        branches = list(self._normalize_branches(branches, awkward))\n        for branch, interpretation in branches:\n            if branch._recoveredbaskets is None:\n                branch._tryrecover()\n        if flatten is None:\n            branches = [(branch, interpretation) for branch, interpretation in branches if not isinstance(interpretation, asjagged)]\n            flatten = False\n\n        # for the case of outputtype == pandas.DataFrame, do some preparation to fill DataFrames efficiently\n        ispandas = getattr(outputtype, ""__name__"", None) == ""DataFrame"" and getattr(outputtype, ""__module__"", None) == ""pandas.core.frame""\n        entrystart, entrystop = _normalize_entrystartstop(self.numentries, entrystart, entrystop)\n\n        # start the job of filling the arrays\n        futures = [(branch.name if namedecode is None else branch.name.decode(namedecode), interpretation, branch.array(interpretation=interpretation, entrystart=entrystart, entrystop=entrystop, flatten=(flatten and not ispandas), awkwardlib=awkward, cache=cache, basketcache=basketcache, keycache=keycache, executor=executor, blocking=False)) for branch, interpretation in branches]\n\n        # make functions that wait for the filling job to be done and return the right outputtype\n        if outputtype == namedtuple:\n            outputtype = namedtuple(""Arrays"", [codecs.ascii_decode(branch.name, ""replace"")[0] if namedecode is None else branch.name.decode(namedecode) for branch, interpretation in branches])\n            def wait():\n                return outputtype(*[future() for name, interpretation, future in futures])\n\n        elif ispandas:\n            import uproot._connect._pandas\n            def wait():\n                return uproot._connect._pandas.futures2df(futures, outputtype, entrystart, entrystop, flatten, flatname, awkward)\n\n        elif isinstance(outputtype, type) and issubclass(outputtype, dict):\n            def wait():\n                return outputtype((name, future()) for name, interpretation, future in futures)\n\n        elif isinstance(outputtype, type) and issubclass(outputtype, (list, tuple)):\n            def wait():\n                return outputtype(future() for name, interpretation, future in futures)\n\n        else:\n            def wait():\n                return outputtype(*[future() for name, interpretation, future in futures])\n\n        # if blocking, return the result of that function; otherwise, the function itself\n        if blocking:\n            return wait()\n        else:\n            return wait\n\n    def lazyarray(self, branch, interpretation=None, entrysteps=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, persistvirtual=False, chunked=True):\n        awkward = _normalize_awkwardlib(awkwardlib)\n        branches = list(self._normalize_branches(branch, awkward))\n        if len(branches) == 1:\n            if interpretation is None:\n                tbranch, interpretation = branches[0]\n            else:\n                tbranch, _ = branches[0]\n        else:\n            raise ValueError(""list of branch names or glob/regex matches more than one branch; use TTree.lazyarrays (plural)"")\n        return tbranch.lazyarray(interpretation=interpretation, entrysteps=entrysteps, entrystart=entrystart, entrystop=entrystop, flatten=flatten, awkwardlib=awkwardlib, cache=cache, basketcache=basketcache, keycache=keycache, executor=executor, persistvirtual=persistvirtual, chunked=chunked)\n\n    def lazyarrays(self, branches=None, namedecode=""utf-8"", entrysteps=None, entrystart=None, entrystop=None, flatten=False, profile=None, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, persistvirtual=False, chunked=True):\n        entrystart, entrystop = _normalize_entrystartstop(self.numentries, entrystart, entrystop)\n        if not chunked and entrysteps is None:\n            entrysteps = float(\'inf\')\n        entrysteps = list(self._normalize_entrysteps(entrysteps, branches, entrystart, entrystop, keycache))\n        awkward = _normalize_awkwardlib(awkwardlib)\n        branches = list(self._normalize_branches(branches, awkward))\n        for branch, interpretation in branches:\n            if branch._recoveredbaskets is None:\n                branch._tryrecover()\n\n        lazytree = _LazyTree(self._context.sourcepath, self._context.treename, self, dict((b.name, x) for b, x in branches), flatten, awkward.__name__, basketcache, keycache, executor)\n\n        out = awkward.Table()\n        for branch, interpretation in branches:\n            inner = interpretation\n            while isinstance(inner, asjagged):\n                inner = inner.content\n            if isinstance(inner, asobj) and getattr(inner.cls, ""_arraymethods"", None) is not None:\n                VirtualArray = awkward.Methods.mixin(inner.cls._arraymethods, awkward.VirtualArray)\n            elif isinstance(inner, asgenobj) and getattr(inner.generator.cls, ""_arraymethods"", None) is not None:\n                VirtualArray = awkward.Methods.mixin(inner.generator.cls._arraymethods, awkward.VirtualArray)\n            else:\n                VirtualArray = awkward.VirtualArray\n\n            name = branch.name.decode(""ascii"") if namedecode is None else branch.name.decode(namedecode)\n            if chunked:\n                chunks = []\n                counts = []\n                for start, stop in entrysteps:\n                    chunks.append(VirtualArray(lazytree, (branch.name, start, stop), cache=cache, type=awkward.type.ArrayType(stop - start, interpretation.type), persistvirtual=persistvirtual))\n                    counts.append(stop - start)\n                out[name] = awkward.ChunkedArray(chunks, counts)\n                out[name].__doc__ = branch.title.decode(\'ascii\')\n            else:\n                start, stop = entrysteps[0]\n                out[name] = VirtualArray(lazytree, (branch.name, start, stop), cache=cache, type=awkward.type.ArrayType(stop - start, interpretation.type), persistvirtual=persistvirtual)\n                out[name].__doc__ = branch.title.decode(\'ascii\')\n\n        if profile is not None:\n            out = uproot_methods.profiles.transformer(profile)(out)\n        return out\n\n    def _normalize_entrysteps(self, entrysteps, branches, entrystart, entrystop, keycache):\n        numbytes = _memsize(entrysteps)\n        if numbytes is not None:\n            return self.mempartitions(numbytes, branches=branches, entrystart=entrystart, entrystop=entrystop, keycache=keycache, linear=True)\n        if isinstance(entrysteps, string_types):\n            raise ValueError(""string {0} does not match the memory size pattern (number followed by B/kB/MB/GB/etc.)"".format(repr(entrysteps)))\n\n        if entrysteps is None:\n            return self.clusters(branches, entrystart=entrystart, entrystop=entrystop, strict=False)\n\n        elif entrysteps == float(""inf""):\n            return [(entrystart, min(entrystop, self.numentries))]\n\n        elif isinstance(entrysteps, (numbers.Integral, numpy.integer)):\n            entrystepsize = entrysteps\n            if entrystepsize <= 0:\n                raise ValueError(""if an integer, entrysteps must be positive"")\n\n            effectivestop = min(entrystop, self.numentries)\n            starts = numpy.arange(entrystart, effectivestop, entrystepsize)\n            stops = numpy.append(starts[1:], effectivestop)\n            return zip(starts, stops)\n                    \n        else:\n            try:\n                iter(entrysteps)\n            except TypeError:\n                raise TypeError(""entrysteps must be None for cluster iteration, a positive integer for equal steps in number of entries (inf for maximal), a memory size string (number followed by B/kB/MB/GB/etc.), or an iterable of 2-tuples for explicit entry starts (inclusive) and stops (exclusive)"")\n            return entrysteps\n\n    def iterate(self, branches=None, entrysteps=None, outputtype=dict, namedecode=None, reportentries=False, entrystart=None, entrystop=None, flatten=False, flatname=None, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, blocking=True):\n        if keycache is None:\n            keycache = {}\n\n        if basketcache is None:\n            basketcache = {}\n            explicit_basketcache = False\n        else:\n            explicit_basketcache = True\n\n        entrystart, entrystop = _normalize_entrystartstop(self.numentries, entrystart, entrystop)\n        entrysteps = self._normalize_entrysteps(entrysteps, branches, entrystart, entrystop, keycache)\n        awkward = _normalize_awkwardlib(awkwardlib)\n        branches = list(self._normalize_branches(branches, awkward))\n        for branch, interpretation in branches:\n            if branch._recoveredbaskets is None:\n                branch._tryrecover()\n\n        # for the case of outputtype == pandas.DataFrame, do some preparation to fill DataFrames efficiently\n        ispandas = getattr(outputtype, ""__name__"", None) == ""DataFrame"" and getattr(outputtype, ""__module__"", None) == ""pandas.core.frame""\n            \n        def evaluate(branch, interpretation, future, past, cachekey, pythonize):\n            if future is None:\n                return past\n            else:\n                out = interpretation.finalize(future(), branch)\n                if cache is not None:\n                    cache[cachekey] = out\n                if flatten and isinstance(interpretation, asjagged):\n                    return out.flatten()\n                elif pythonize:\n                    return list(out)\n                else:\n                    return out\n\n        if outputtype == namedtuple:\n            outputtype = namedtuple(""Arrays"", [codecs.ascii_decode(branch.name, ""replace"")[0] if namedecode is None else branch.name.decode(namedecode) for branch, interpretation in branches])\n            def wrap_for_python_scope(futures, start, stop):\n                return lambda: outputtype(*[evaluate(branch, interpretation, future, past, cachekey, False) for branch, interpretation, future, past, cachekey in futures])\n\n        elif ispandas:\n            import uproot._connect._pandas\n            def wrap_for_python_scope(futures, start, stop):\n                def wrap_again(branch, interpretation, future):\n                    return lambda: interpretation.finalize(future(), branch)\n                return lambda: uproot._connect._pandas.futures2df([(branch.name, interpretation, wrap_again(branch, interpretation, future)) for branch, interpretation, future, past, cachekey in futures], outputtype, start, stop, flatten, flatname, awkward)\n\n        elif isinstance(outputtype, type) and issubclass(outputtype, dict):\n            def wrap_for_python_scope(futures, start, stop):\n                return lambda: outputtype((branch.name if namedecode is None else branch.name.decode(namedecode), evaluate(branch, interpretation, future, past, cachekey, False)) for branch, interpretation, future, past, cachekey in futures)\n\n        elif isinstance(outputtype, type) and issubclass(outputtype, (list, tuple)):\n            def wrap_for_python_scope(futures, start, stop):\n                return lambda: outputtype(evaluate(branch, interpretation, future, past, cachekey, False) for branch, interpretation, future, past, cachekey in futures)\n\n        else:\n            def wrap_for_python_scope(futures, start, stop):\n                return lambda: outputtype(*[evaluate(branch, interpretation, future, past, cachekey, False) for branch, interpretation, future, past, cachekey in futures])\n\n        for start, stop in entrysteps:\n            start = max(start, entrystart)\n            stop = min(stop, entrystop)\n            if start > stop:\n                continue\n\n            futures = []\n            for branch, interpretation in branches:\n                cachekey = branch._cachekey(interpretation, start, stop)\n\n                if branch.numbaskets == 0:\n                    futures.append((branch, interpretation, interpretation.empty, None, cachekey))\n\n                else:\n                    basketstart, basketstop = branch._basketstartstop(start, stop)\n                    basket_itemoffset = branch._basket_itemoffset(interpretation, basketstart, basketstop, keycache)\n                    basket_entryoffset = branch._basket_entryoffset(basketstart, basketstop)\n\n                    if cache is not None:\n                        out = cache.get(cachekey, None)\n                        if out is not None:\n                            futures.append((branch, interpretation, None, out, cachekey))\n                            continue\n                    future = branch._step_array(interpretation, basket_itemoffset, basket_entryoffset, start, stop, awkward, basketcache, keycache, executor, explicit_basketcache)\n                    futures.append((branch, interpretation, future, None, cachekey))\n\n            out = wrap_for_python_scope(futures, start, stop)\n\n            if blocking:\n                out = out()\n\n            if reportentries:\n                yield start, stop, out\n            else:\n                yield out\n\n    def _format(self, indent=""""):\n        # TODO: add TTree data to the bottom of this\n        out = []\n        for branch in self._fBranches:\n            out.extend(branch._format(indent))\n        return out\n\n    def show(self, foldnames=False, stream=sys.stdout):\n        if stream is None:\n            return ""\\n"".join(self._format(foldnames))\n        else:\n            for line in self._format(foldnames):\n                stream.write(line)\n                stream.write(""\\n"")\n\n    def _recover(self):\n        for branch in self.allvalues():\n            branch._recover()\n\n    def matches(self, branches):\n        awkward = _normalize_awkwardlib(None)\n        return [b.name for b, i in self._normalize_branches(branches, awkward, allownone=False, allowcallable=False, allowdict=False, allowstring=True)]\n\n    _branch_regex = re.compile(b""^/(.*)/([iLmsux]*)$"")\n\n    @staticmethod\n    def _branch_flags(flags):\n        flagsbyte = 0\n        for flag in flags:\n            if flag == ""i"":\n                flagsbyte += re.I\n            elif flag == ""L"":\n                flagsbyte += re.L\n            elif flag == ""m"":\n                flagsbyte += re.M\n            elif flag == ""s"":\n                flagsbyte += re.S\n            elif flag == ""u"":\n                flagsbyte += re.U\n            elif flag == ""x"":\n                flagsbyte += re.X\n        return flagsbyte\n\n    def _normalize_branches(self, arg, awkward, allownone=True, allowcallable=True, allowdict=True, allowstring=True, aliases=True):\n        if allownone and arg is None:                      # no specification; read all branches\n            for branch in self.allvalues():                # that have interpretations\n                interpretation = interpret(branch, awkward)\n                if interpretation is not None:\n                    yield branch, interpretation\n\n        elif allowcallable and callable(arg):\n            for branch in self.allvalues():\n                result = arg(branch)\n                if result is None or result is False:\n                    pass\n                elif result is True:                       # function is a filter\n                    interpretation = interpret(branch, awkward)\n                    if interpretation is not None:\n                        yield branch, interpretation\n                else:                                      # function is giving interpretations\n                    yield branch, branch._normalize_dtype(result, awkward)\n\n        elif allowdict and isinstance(arg, dict):\n            for word, interpretation in arg.items():\n                word = _bytesid(word)\n\n                isregex = re.match(self._branch_regex, word)\n                if isregex is not None:\n                    regex, flags = isregex.groups()\n                    for name, branch in self.iteritems(recursive=True, aliases=aliases):\n                        if re.match(regex, name, self._branch_flags(flags)):\n                            yield branch, branch._normalize_dtype(interpretation, awkward)\n\n                elif b""*"" in word or b""?"" in word or b""["" in word:\n                    for name, branch in self.iteritems(recursive=True, aliases=aliases):\n                        if name == word or glob.fnmatch.fnmatchcase(name, word):\n                            yield branch, branch._normalize_dtype(interpretation, awkward)\n\n                else:\n                    branch = self.get(word, aliases=aliases)\n                    yield branch, branch._normalize_dtype(interpretation, awkward)\n\n        elif allowstring and isinstance(arg, string_types):\n            for x in self._normalize_branches([arg], awkward):\n                yield x\n\n        else:\n            try:\n                words = iter(arg)                          # only way to check for iterable (in general)\n            except Exception:\n                raise TypeError(""\'branches\' argument not understood"")\n            else:\n                for word in words:\n                    word = _bytesid(word)\n\n                    isregex = re.match(self._branch_regex, word)\n                    if isregex is not None:\n                        regex, flags = isregex.groups()\n                        for name, branch in self.iteritems(recursive=True, aliases=aliases):\n                            if re.match(regex, name, self._branch_flags(flags)):\n                                interpretation = interpret(branch, awkward)\n                                if interpretation is None:\n                                    if name == word:\n                                        raise ValueError(""cannot interpret branch {0} as a Python type\\n   in file: {1}"".format(repr(branch.name), self._context.sourcepath))\n                                else:\n                                    yield branch, interpretation\n\n                    elif b""*"" in word or b""?"" in word or b""["" in word:\n                        for name, branch in self.iteritems(recursive=True, aliases=aliases):\n                            if name == word or glob.fnmatch.fnmatchcase(name, word):\n                                interpretation = interpret(branch, awkward)\n                                if interpretation is None:\n                                    if name == word:\n                                        raise ValueError(""cannot interpret branch {0} as a Python type\\n   in file: {1}"".format(repr(branch.name), self._context.sourcepath))\n                                else:\n                                    yield branch, interpretation\n\n                    else:\n                        branch = self.get(word, aliases=aliases)\n                        interpretation = interpret(branch, awkward)\n                        if interpretation is None:\n                            raise ValueError(""cannot interpret branch {0} as a Python type\\n   in file: {1}"".format(repr(branch.name), self._context.sourcepath))\n                        else:\n                            yield branch, interpretation\n\n    def __len__(self):\n        return self.numentries\n\n    def __getitem__(self, name):\n        return self.get(name)\n\n    def __iter__(self):\n        # prevent Python\'s attempt to interpret __len__ and __getitem__ as iteration\n        raise TypeError(""\'TTree\' object is not iterable"")\n\n    @property\n    def pandas(self):\n        import uproot._connect._pandas\n        return uproot._connect._pandas.TTreeMethods_pandas(self)\n\n################################################################ methods for TBranch\n\nclass TBranchMethods(object):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (uproot.rootio.ROOTObject.__metaclass__,), {})\n\n    def _postprocess(self, source, cursor, context, parent):\n        self._source = source\n        self._context = context\n        self._streamer = None\n        self._interpretation = None\n\n        self._numgoodbaskets = 0\n        for i, x in enumerate(self._fBasketSeek):\n            if x == 0 or i == self._fWriteBasket:\n                break\n            self._numgoodbaskets += 1\n\n        if self.numentries == self._fBasketEntry[self._numgoodbaskets]:\n            self._recoveredbaskets = []\n            self._entryoffsets = self._fBasketEntry[: self._numgoodbaskets + 1].tolist()\n            self._recoverylock = None\n        else:\n            self._recoveredbaskets = None\n            self._entryoffsets = None\n            self._recoverylock = threading.Lock()\n\n        self._countbranch = None\n        self._tree_iofeatures = 0\n        if hasattr(parent, ""_fIOFeatures""):\n            self._tree_iofeatures = parent._fIOFeatures._fIOBits\n\n    def _fill_branchlookup(self, branchlookup):\n        for subbranch in self._fBranches:\n            subbranch._fill_branchlookup(branchlookup)\n            branchlookup[subbranch.name] = subbranch\n\n    @property\n    def name(self):\n        return self._fName\n\n    @property\n    def title(self):\n        return self._fTitle\n\n    @property\n    def interpretation(self):\n        awkward = _normalize_awkwardlib(None)\n        if self._interpretation is None:\n            self._interpretation = interpret(self, awkward)\n        return self._interpretation\n\n    @property\n    def countbranch(self):\n        return self._countbranch\n\n    @property\n    def countleaf(self):\n        return self._countleaf\n\n    @property\n    def numentries(self):\n        return int(self._fEntries)   # or self._fEntryNumber?\n\n    @property\n    def numbranches(self):\n        count = 0\n        for x in self.itervalues(recursive=True):\n            count += 1\n        return count\n\n    def iterkeys(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        for branch in self.itervalues(recursive, filtername, filtertitle):\n            yield branch.name\n\n    def itervalues(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        for branch in self._fBranches:\n            if filtername(branch.name) and filtertitle(branch.title):\n                yield branch\n            if recursive:\n                for x in branch.itervalues(recursive, filtername, filtertitle):\n                    yield x\n\n    def iteritems(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        for branch in self._fBranches:\n            if filtername(branch.name) and filtertitle(branch.title):\n                yield branch.name, branch\n            if recursive:\n                for x in branch.iteritems(recursive, filtername, filtertitle):\n                    yield x\n\n    def keys(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        return list(self.iterkeys(recursive=recursive, filtername=filtername, filtertitle=filtertitle))\n\n    def _ipython_key_completions_(self):\n        ""Support for completion of keys in an IPython kernel""\n        return [item.decode(""ascii"") for item in self.iterkeys()]\n\n    def values(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        return list(self.itervalues(recursive=recursive, filtername=filtername, filtertitle=filtertitle))\n\n    def items(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        return list(self.iteritems(recursive=recursive, filtername=filtername, filtertitle=filtertitle))\n\n    def allkeys(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        return self.keys(recursive=True, filtername=filtername, filtertitle=filtertitle)\n\n    def allvalues(self, filtername=nofilter, filtertitle=nofilter):\n        return self.values(recursive=True, filtername=filtername, filtertitle=filtertitle)\n\n    def allitems(self, filtername=nofilter, filtertitle=nofilter):\n        return self.items(recursive=True, filtername=filtername, filtertitle=filtertitle)\n\n    def get(self, name, recursive=True, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        name = _bytesid(name)\n        for n, b in self.iteritems(recursive=recursive, filtername=filtername, filtertitle=filtertitle):\n            if n == name:\n                return b\n        raise uproot.rootio._KeyError(""not found: {0}\\n in file: {1}"".format(repr(name), self._context.sourcepath))\n\n    @property\n    def numbaskets(self):\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n        return self._numgoodbaskets + len(self._recoveredbaskets)\n\n    def _cachekey(self, interpretation, entrystart, entrystop):\n        return ""{0};{1};{2};{3};{4}-{5}"".format(base64.b64encode(self._context.uuid).decode(""ascii""), self._context.treename.decode(""ascii""), self.name.decode(""ascii""), interpretation.identifier, entrystart, entrystop)\n\n    def _basketcachekey(self, i):\n        return ""{0};{1};{2};{3};raw"".format(base64.b64encode(self._context.uuid).decode(""ascii""), self._context.treename.decode(""ascii""), self.name.decode(""ascii""), i)\n\n    def _keycachekey(self, i):\n        return ""{0};{1};{2};{3};key"".format(base64.b64encode(self._context.uuid).decode(""ascii""), self._context.treename.decode(""ascii""), self.name.decode(""ascii""), i)\n\n    def _threadsafe_key(self, i, keycache, complete):\n        key = None\n        if keycache is not None:\n            key = keycache.get(self._keycachekey(i), None)\n\n        if key is None:\n            keysource = self._source.threadlocal()\n            try:\n                key = self._basketkey(keysource, i, complete)\n                if keycache is not None:\n                    keycache[self._keycachekey(i)] = key\n            finally:\n                keysource.dismiss()\n\n        return key\n\n    def _threadsafe_iterate_keys(self, keycache, complete, basketstart=None, basketstop=None):\n        if basketstart is None:\n            basketstart = 0\n        if basketstop is None:\n            basketstop = self.numbaskets\n\n        done = False\n        if keycache is not None:\n            keys = [keycache.get(self._keycachekey(i), None) for i in range(basketstart, basketstop)]\n            if all(x is not None for x in keys):\n                if not complete or all(hasattr(x, ""border"") for x in keys):\n                    for key in keys:\n                        yield key\n                    done = True\n\n        if not done:\n            keysource = self._source.threadlocal()\n            try:\n                for i in range(basketstart, basketstop):\n                    key = None if keycache is None else keycache.get(self._keycachekey(i), None)\n                    if key is None or (complete and not hasattr(key, ""border"")):\n                        key = self._basketkey(keysource, i, complete)\n                        if keycache is not None:\n                            keycache[self._keycachekey(i)] = key\n                        yield key\n                    else:\n                        yield key\n            finally:\n                keysource.dismiss()\n\n    def uncompressedbytes(self, keycache=None):\n        return sum(key._fObjlen for key in self._threadsafe_iterate_keys(keycache, False))\n\n    def compressedbytes(self, keycache=None):\n        return sum(key._fNbytes - key._fKeylen for key in self._threadsafe_iterate_keys(keycache, False))\n\n    def compressionratio(self, keycache=None):\n        numer, denom = 0, 0\n        for key in self._threadsafe_iterate_keys(keycache, False):\n            numer += key._fObjlen\n            denom += key._fNbytes - key._fKeylen\n        return float(numer) / float(denom)\n\n    def _normalize_dtype(self, interpretation, awkward):\n        if inspect.isclass(interpretation) and issubclass(interpretation, awkward.numpy.generic):\n            return self._normalize_dtype(awkward.numpy.dtype(interpretation), awkward)\n\n        elif isinstance(interpretation, awkward.numpy.dtype):      # user specified a Numpy dtype\n            default = interpret(self, awkward)\n            if isinstance(default, (asdtype, asjagged)):\n                return default.to(interpretation)\n            else:\n                raise ValueError(""cannot cast branch {0} (default interpretation {1}) as dtype {2}"".format(repr(self.name), default, interpretation))\n\n        elif isinstance(interpretation, awkward.numpy.ndarray):    # user specified a Numpy array\n            default = interpret(self, awkward)\n            if isinstance(default, asdtype):\n                return default.toarray(interpretation)\n            else:\n                raise ValueError(""cannot cast branch {0} (default interpretation {1}) as dtype {2}"".format(repr(self.name), default, interpretation))\n\n        elif not isinstance(interpretation, uproot.interp.interp.Interpretation):\n            raise TypeError(""branch interpretation must be an Interpretation, not {0} (type {1})"".format(interpretation, type(interpretation)))\n\n        else:\n            return interpretation\n\n    def _normalize_interpretation(self, interpretation, awkward):\n        if interpretation is None:\n            interpretation = interpret(self, awkward)\n        else:\n            interpretation = self._normalize_dtype(interpretation, awkward)\n\n        if interpretation is None:\n            raise ValueError(""cannot interpret branch {0} as a Python type\\n   in file: {1}"".format(repr(self.name), self._context.sourcepath))\n\n        if interpretation.awkward is not awkward:\n            interpretation = interpretation.awkwardlib(awkward)\n\n        return interpretation\n\n    def numitems(self, interpretation=None, keycache=None):\n        awkward = _normalize_awkwardlib(None)\n        interpretation = self._normalize_interpretation(interpretation, awkward)\n        if interpretation is None:\n            raise ValueError(""cannot interpret branch {0} as a Python type\\n   in file: {1}"".format(repr(self.name), self._context.sourcepath))\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n        return sum(interpretation.numitems(key.border, self.basket_numentries(i)) for i, key in enumerate(self._threadsafe_iterate_keys(keycache, True)))\n\n    @property\n    def compression(self):\n        try:\n            return uproot.source.compressed.Compression(self._fCompress)\n        except ValueError:\n            return self._context.compression\n\n    def basket_entrystart(self, i):\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n        if 0 <= i < self.numbaskets:\n            return self._entryoffsets[i]\n        else:\n            raise IndexError(""index {0} out of range for branch with {1} baskets"".format(i, self.numbaskets))\n\n    def basket_entrystop(self, i):\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n        if 0 <= i < self.numbaskets:\n            return self._entryoffsets[i + 1]\n        else:\n            raise IndexError(""index {0} out of range for branch with {1} baskets"".format(i, self.numbaskets))\n\n    def basket_numentries(self, i):\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n        if 0 <= i < self.numbaskets:\n            return self._entryoffsets[i + 1] - self._entryoffsets[i]\n        else:\n            raise IndexError(""index {0} out of range for branch with {1} baskets"".format(i, self.numbaskets))\n\n    def basket_uncompressedbytes(self, i, keycache=None):\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n        return self._threadsafe_key(i, keycache, False)._fObjlen\n\n    def basket_compressedbytes(self, i, keycache=None):\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n        key = self._threadsafe_key(i, keycache, False)\n        return key._fNbytes - key._fKeylen\n\n    def basket_numitems(self, i, interpretation=None, keycache=None):\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n        awkward = _normalize_awkwardlib(None)\n        interpretation = self._normalize_interpretation(interpretation, awkward)\n        key = self._threadsafe_key(i, keycache, True)\n        return interpretation.numitems(key.border, self.basket_numentries(i))\n\n    def _localentries(self, i, entrystart, entrystop):\n        local_entrystart = max(0, entrystart - self.basket_entrystart(i))\n        local_entrystop  = max(0, min(entrystop - self.basket_entrystart(i), self.basket_entrystop(i) - self.basket_entrystart(i)))\n        return local_entrystart, local_entrystop\n\n    def _basket(self, i, interpretation, local_entrystart, local_entrystop, awkward, basketcache, keycache):\n        basketdata = None\n        if basketcache is not None:\n            basketcachekey = self._basketcachekey(i)\n            basketdata = basketcache.get(basketcachekey, None)\n\n        key = self._threadsafe_key(i, keycache, True)\n\n        if basketdata is None:\n            basketdata = key.basketdata()\n\n        if basketcache is not None:\n            basketcache[basketcachekey] = basketdata\n\n        if key._fObjlen == key.border:\n            data, byteoffsets = basketdata, None\n\n            if self._countbranch is not None and awkward.numpy.uint8(self._tree_iofeatures) & awkward.numpy.uint8(uproot.const.kGenerateOffsetMap) != 0:\n                counts = self._countbranch.array(entrystart=(local_entrystart + self.basket_entrystart(i)),\n                                                 entrystop=(local_entrystop + self.basket_entrystart(i)))\n                itemsize = 1\n                if isinstance(interpretation, asjagged):\n                    itemsize = interpretation.content.fromdtype.itemsize\n                awkward.numpy.multiply(counts, itemsize, counts)\n                byteoffsets = awkward.numpy.empty(len(counts) + 1, dtype=awkward.numpy.int32)\n                byteoffsets[0] = 0\n                awkward.numpy.cumsum(counts, out=byteoffsets[1:])\n\n        else:\n            data = basketdata[:key.border]\n            byteoffsets = awkward.numpy.empty((key._fObjlen - key.border - 4) // 4, dtype=awkward.numpy.int32)  # native endian\n            byteoffsets[:-1] = basketdata[key.border + 4 : -4].view("">i4"")                     # read as big-endian and convert\n            byteoffsets[-1] = key._fLast\n            awkward.numpy.subtract(byteoffsets, key._fKeylen, byteoffsets)\n\n        return interpretation.fromroot(data, byteoffsets, local_entrystart, local_entrystop, key._fKeylen)\n\n    def basket(self, i, interpretation=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None):\n        awkward = _normalize_awkwardlib(awkwardlib)\n        interpretation = self._normalize_interpretation(interpretation, awkward)\n        if interpretation is None:\n            raise ValueError(""cannot interpret branch {0} as a Python type\\n   in file: {1}"".format(repr(self.name), self._context.sourcepath))\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n\n        if not 0 <= i < self.numbaskets:\n            raise IndexError(""index {0} out of range for branch with {1} baskets"".format(i, self.numbaskets))\n\n        entrystart, entrystop = _normalize_entrystartstop(self.numentries, entrystart, entrystop)\n        local_entrystart, local_entrystop = self._localentries(i, entrystart, entrystop)\n        entrystart = self.basket_entrystart(i) + local_entrystart\n        entrystop = self.basket_entrystart(i) + local_entrystop\n        numentries = local_entrystop - local_entrystart\n\n        if cache is not None:\n            cachekey = self._cachekey(interpretation, entrystart, entrystop)\n            out = cache.get(cachekey, None)\n            if out is not None:\n                if flatten and isinstance(interpretation, asjagged):\n                    return out.content\n                else:\n                    return out\n\n        source = self._basket(i, interpretation, local_entrystart, local_entrystop, awkward, basketcache, keycache)\n        numitems = interpretation.source_numitems(source)\n\n        destination = interpretation.destination(numitems, numentries)\n        interpretation.fill(source, destination, 0, numitems, 0, numentries)\n        out = interpretation.finalize(destination, self)\n\n        if cache is not None:\n            cache[cachekey] = out\n        if flatten and isinstance(interpretation, asjagged):\n            return out.content\n        else:\n            return out\n\n    def _basketstartstop(self, entrystart, entrystop):\n        basketstart, basketstop = None, None\n        for i in range(self.numbaskets):\n            if basketstart is None:\n                if entrystart < self.basket_entrystop(i) and self.basket_entrystart(i) < entrystop:\n                    basketstart = i\n                    basketstop = i\n            else:\n                if self.basket_entrystart(i) < entrystop:\n                    basketstop = i\n\n        if basketstop is not None:\n            basketstop += 1    # stop is exclusive\n\n        return basketstart, basketstop\n\n    def baskets(self, interpretation=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, reportentries=False, executor=None, blocking=True):\n        awkward = _normalize_awkwardlib(awkwardlib)\n        interpretation = self._normalize_interpretation(interpretation, awkward)\n        if interpretation is None:\n            raise ValueError(""cannot interpret branch {0} as a Python type\\n   in file: {1}"".format(repr(self.name), self._context.sourcepath))\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n\n        entrystart, entrystop = _normalize_entrystartstop(self.numentries, entrystart, entrystop)\n        basketstart, basketstop = self._basketstartstop(entrystart, entrystop)\n\n        if basketstart is None:\n            if blocking:\n                return []\n            else:\n                def wait():\n                    return []\n                return wait\n\n        out = [None] * (basketstop - basketstart)\n\n        def fill(j):\n            try:\n                basket = self.basket(j + basketstart, interpretation=interpretation, entrystart=entrystart, entrystop=entrystop, flatten=flatten, awkwardlib=awkward, cache=cache, basketcache=basketcache, keycache=keycache)\n                if reportentries:\n                    local_entrystart, local_entrystop = self._localentries(j + basketstart, entrystart, entrystop)\n                    basket = (local_entrystart + self.basket_entrystart(j + basketstart),\n                              local_entrystop + self.basket_entrystart(j + basketstart),\n                              basket)\n            except Exception:\n                return sys.exc_info()\n            else:\n                out[j] = basket\n                return None\n\n        if executor is None:\n            for j in range(basketstop - basketstart):\n                _delayedraise(fill(j))\n            excinfos = ()\n        else:\n            excinfos = executor.map(fill, range(basketstop - basketstart))\n\n        if blocking:\n            for excinfo in excinfos:\n                _delayedraise(excinfo)\n            return out\n        else:\n            def wait():\n                for excinfo in excinfos:\n                    _delayedraise(excinfo)\n                return out\n            return wait\n\n    def iterate_baskets(self, interpretation=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, reportentries=False):\n        awkward = _normalize_awkwardlib(awkwardlib)\n        interpretation = self._normalize_interpretation(interpretation, awkward)\n        if interpretation is None:\n            raise ValueError(""cannot interpret branch {0} as a Python type\\n   in file: {1}"".format(repr(self.name), self._context.sourcepath))\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n\n        entrystart, entrystop = _normalize_entrystartstop(self.numentries, entrystart, entrystop)\n\n        for i in range(self.numbaskets):\n            if entrystart < self.basket_entrystop(i) and self.basket_entrystart(i) < entrystop:\n                local_entrystart, local_entrystop = self._localentries(i, entrystart, entrystop)\n\n                if local_entrystop > local_entrystart:\n                    if reportentries:\n                        yield (local_entrystart + self.basket_entrystart(i),\n                               local_entrystop + self.basket_entrystart(i),\n                               self.basket(i, interpretation=interpretation, entrystart=entrystart, entrystop=entrystop, flatten=flatten, awkwardlib=awkward, cache=cache, basketcache=basketcache, keycache=keycache))\n                    else:\n                        yield self.basket(i, interpretation=interpretation, entrystart=entrystart, entrystop=entrystop, flatten=flatten, awkwardlib=awkward, cache=cache, basketcache=basketcache, keycache=keycache)\n\n    def _basket_itemoffset(self, interpretation, basketstart, basketstop, keycache):\n        basket_itemoffset = [0]\n        for j, key in enumerate(self._threadsafe_iterate_keys(keycache, True, basketstart, basketstop)):\n            i = basketstart + j\n            numitems = interpretation.numitems(key.border, self.basket_numentries(i))\n            basket_itemoffset.append(basket_itemoffset[-1] + numitems)\n        return basket_itemoffset\n\n    def _basket_entryoffset(self, basketstart, basketstop):\n        basket_entryoffset = [0]\n        for i in range(basketstart, basketstop):\n            basket_entryoffset.append(basket_entryoffset[-1] + self.basket_numentries(i))\n        return basket_entryoffset\n\n    def array(self, interpretation=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, blocking=True):\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n        awkward = _normalize_awkwardlib(awkwardlib)\n        interpretation = self._normalize_interpretation(interpretation, awkward)\n        if interpretation is None:\n            raise ValueError(""cannot interpret branch {0} as a Python type\\n   in file: {1}"".format(repr(self.name), self._context.sourcepath))\n        entrystart, entrystop = _normalize_entrystartstop(self.numentries, entrystart, entrystop)\n        basketstart, basketstop = self._basketstartstop(entrystart, entrystop)\n\n        if basketstart is not None and basketstop is not None and self._source.parent() is not None:\n            self._source.parent().preload([self._fBasketSeek[i] for i in range(basketstart, basketstop)])\n\n        if cache is not None:\n            cachekey = self._cachekey(interpretation, entrystart, entrystop)\n            out = cache.get(cachekey, None)\n            if out is not None:\n                if flatten and isinstance(interpretation, asjagged):\n                    out = out.content\n                if blocking:\n                    return out\n                else:\n                    return lambda: out\n\n        if basketstart is None:\n            if blocking:\n                return interpretation.empty()\n            else:\n                def wait():\n                    return interpretation.empty()\n                return wait\n\n        if keycache is None:\n            keycache = {}\n\n        basket_itemoffset = self._basket_itemoffset(interpretation, basketstart, basketstop, keycache)\n        basket_entryoffset = self._basket_entryoffset(basketstart, basketstop)\n\n        destination = interpretation.destination(basket_itemoffset[-1], basket_entryoffset[-1])\n\n        def fill(j):\n            try:\n                i = j + basketstart\n                local_entrystart, local_entrystop = self._localentries(i, entrystart, entrystop)\n                source = self._basket(i, interpretation, local_entrystart, local_entrystop, awkward, basketcache, keycache)\n\n                expecteditems = basket_itemoffset[j + 1] - basket_itemoffset[j]\n                source_numitems = interpretation.source_numitems(source)\n\n                expectedentries = basket_entryoffset[j + 1] - basket_entryoffset[j]\n                source_numentries = local_entrystop - local_entrystart\n\n                if j + 1 == basketstop - basketstart:\n                    if expecteditems > source_numitems:\n                        basket_itemoffset[j + 1] -= expecteditems - source_numitems\n                    if expectedentries > source_numentries:\n                        basket_entryoffset[j + 1] -= expectedentries - source_numentries\n\n                elif j == 0:\n                    if expecteditems > source_numitems:\n                        basket_itemoffset[j] += expecteditems - source_numitems\n                    if expectedentries > source_numentries:\n                        basket_entryoffset[j] += expectedentries - source_numentries\n\n                interpretation.fill(source,\n                                    destination,\n                                    basket_itemoffset[j],\n                                    basket_itemoffset[j + 1],\n                                    basket_entryoffset[j],\n                                    basket_entryoffset[j + 1])\n\n            except Exception:\n                return sys.exc_info()\n\n        if executor is None:\n            for j in range(basketstop - basketstart):\n                _delayedraise(fill(j))\n            excinfos = ()\n        else:\n            excinfos = executor.map(fill, range(basketstop - basketstart))\n\n        def wait():\n            for excinfo in excinfos:\n                _delayedraise(excinfo)\n\n            clipped = interpretation.clip(destination,\n                                          basket_itemoffset[0],\n                                          basket_itemoffset[-1],\n                                          basket_entryoffset[0],\n                                          basket_entryoffset[-1])\n\n            out = interpretation.finalize(clipped, self)\n            if cache is not None:\n                cache[cachekey] = out\n            if flatten and isinstance(interpretation, asjagged):\n                return out.content\n            else:\n                return out\n\n        if blocking:\n            return wait()\n        else:\n            return wait\n\n    def _step_array(self, interpretation, basket_itemoffset, basket_entryoffset, entrystart, entrystop, awkward, basketcache, keycache, executor, explicit_basketcache):\n        if interpretation is None:\n            raise ValueError(""cannot interpret branch {0} as a Python type\\n   in file: {1}"".format(repr(self.name), self._context.sourcepath))\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n\n        basketstart, basketstop = self._basketstartstop(entrystart, entrystop)\n\n        if basketstart is None:\n            return lambda: interpretation.empty()\n\n        destination = interpretation.destination(basket_itemoffset[-1], basket_entryoffset[-1])\n\n        def fill(j):\n            try:\n                i = j + basketstart\n                local_entrystart, local_entrystop = self._localentries(i, entrystart, entrystop)\n                source = self._basket(i, interpretation, local_entrystart, local_entrystop, awkward, basketcache, keycache)\n\n                expecteditems = basket_itemoffset[j + 1] - basket_itemoffset[j]\n                source_numitems = interpretation.source_numitems(source)\n\n                expectedentries = basket_entryoffset[j + 1] - basket_entryoffset[j]\n                source_numentries = local_entrystop - local_entrystart\n\n                if j + 1 == basketstop - basketstart:\n                    if expecteditems > source_numitems:\n                        basket_itemoffset[j + 1] -= expecteditems - source_numitems\n                    if expectedentries > source_numentries:\n                        basket_entryoffset[j + 1] -= expectedentries - source_numentries\n\n                elif j == 0:\n                    if expecteditems > source_numitems:\n                        basket_itemoffset[j] += expecteditems - source_numitems\n                    if expectedentries > source_numentries:\n                        basket_entryoffset[j] += expectedentries - source_numentries\n\n                interpretation.fill(source,\n                                    destination,\n                                    basket_itemoffset[j],\n                                    basket_itemoffset[j + 1],\n                                    basket_entryoffset[j],\n                                    basket_entryoffset[j + 1])\n\n            except Exception:\n                return sys.exc_info()\n\n        if executor is None:\n            for j in range(basketstop - basketstart):\n                _delayedraise(fill(j))\n            excinfos = ()\n        else:\n            excinfos = executor.map(fill, range(basketstop - basketstart))\n\n        def wait():\n            for excinfo in excinfos:\n                _delayedraise(excinfo)\n\n            if not explicit_basketcache:\n                for i in range(basketstop - 1):  # not including the last real basket\n                    try:\n                        del basketcache[self._basketcachekey(i)]\n                    except KeyError:\n                        pass\n\n            return interpretation.clip(destination,\n                                       basket_itemoffset[0],\n                                       basket_itemoffset[-1],\n                                       basket_entryoffset[0],\n                                       basket_entryoffset[-1])\n\n        return wait\n\n    def mempartitions(self, numbytes, entrystart=None, entrystop=None, keycache=None, linear=True):\n        m = _memsize(numbytes)\n        if m is not None:\n            numbytes = m\n\n        if numbytes <= 0:\n            raise ValueError(""target numbytes must be positive"")\n\n        awkward = _normalize_awkwardlib(None)\n        entrystart, entrystop = _normalize_entrystartstop(self.numentries, entrystart, entrystop)\n\n        if not linear:\n            raise NotImplementedError(""non-linear mempartition has not been implemented"")\n\n        relevant_numbytes = 0.0\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n        for i, key in enumerate(self._threadsafe_iterate_keys(keycache, False)):\n            start, stop = self._entryoffsets[i], self._entryoffsets[i + 1]\n            if entrystart < stop and start < entrystop:\n                this_numbytes = key._fObjlen * (min(stop, entrystop) - max(start, entrystart)) / float(stop - start)\n                assert this_numbytes >= 0.0\n                relevant_numbytes += this_numbytes\n\n        entrysteps = max(1, round(math.ceil((entrystop - entrystart) * numbytes / relevant_numbytes)))\n\n        start, stop = entrystart, entrystart\n        while stop < entrystop:\n            stop = min(stop + entrysteps, entrystop)\n            if stop > start:\n                yield start, stop\n            start = stop\n\n    def _normalize_entrysteps(self, entrysteps, entrystart, entrystop, keycache):\n        numbytes = _memsize(entrysteps)\n        if numbytes is not None:\n            return self.mempartitions(numbytes, entrystart=entrystart, entrystop=entrystop, keycache=keycache, linear=True)\n        if isinstance(entrysteps, string_types):\n            raise ValueError(""string {0} does not match the memory size pattern (number followed by B/kB/MB/GB/etc.)"".format(repr(entrysteps)))\n\n        if entrysteps is None:\n            if self._recoveredbaskets is None:\n                self._tryrecover()\n            return [(self._entryoffsets[i], self._entryoffsets[i + 1]) for i in range(self.numbaskets) if entrystart < self._entryoffsets[i + 1] and entrystop >= self._entryoffsets[i]]\n\n        elif entrysteps == float(""inf""):\n            return [(entrystart, min(entrystop, self.numentries))]\n\n        elif isinstance(entrysteps, (numbers.Integral, numpy.integer)):\n            entrystepsize = entrysteps\n            if entrystepsize <= 0:\n                raise ValueError(""if an integer, entrysteps must be positive"")\n\n            effectivestop = min(entrystop, self.numentries)\n            starts = numpy.arange(entrystart, effectivestop, entrystepsize)\n            stops = numpy.append(starts[1:], effectivestop)\n            return zip(starts, stops)\n\n        else:\n            try:\n                iter(entrysteps)\n            except TypeError:\n                raise TypeError(""entrysteps must be None for cluster iteration, a positive integer for equal steps in number of entries (inf for maximal), a memory size string (number followed by B/kB/MB/GB/etc.), or an iterable of 2-tuples for explicit entry starts (inclusive) and stops (exclusive)"")\n            return entrysteps\n\n    def lazyarray(self, interpretation=None, entrysteps=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, persistvirtual=False, chunked=True):\n        if self._recoveredbaskets is None:\n            self._tryrecover()\n        awkward = _normalize_awkwardlib(awkwardlib)\n        interpretation = self._normalize_interpretation(interpretation, awkward)\n        if interpretation is None:\n            raise ValueError(""cannot interpret branch {0} as a Python type\\n   in file: {1}"".format(repr(self.name), self._context.sourcepath))\n        entrystart, entrystop = _normalize_entrystartstop(self.numentries, entrystart, entrystop)\n        if not chunked and entrysteps is None:\n            entrysteps = float(\'inf\')\n        entrysteps = self._normalize_entrysteps(entrysteps, entrystart, entrystop, keycache)\n\n        inner = interpretation\n        while isinstance(inner, asjagged):\n            inner = inner.content\n        if isinstance(inner, asobj) and getattr(inner.cls, ""_arraymethods"", None) is not None:\n            VirtualArray = awkward.Methods.mixin(inner.cls._arraymethods, awkward.VirtualArray)\n            chunkedarray = awkward.Methods.mixin(inner.cls._arraymethods, awkward.ChunkedArray)\n        elif isinstance(inner, asgenobj) and getattr(inner.generator.cls, ""_arraymethods"", None) is not None:\n            VirtualArray = awkward.Methods.mixin(inner.generator.cls._arraymethods, awkward.VirtualArray)\n            chunkedarray = awkward.Methods.mixin(inner.generator.cls._arraymethods, awkward.ChunkedArray)\n        else:\n            VirtualArray = awkward.VirtualArray\n            chunkedarray = awkward.ChunkedArray\n\n        lazybranch = _LazyBranch(self._context.sourcepath, self._context.treename, self.name, self, interpretation, flatten, awkward.__name__, basketcache, keycache, executor)\n\n        if chunked:\n            chunks = []\n            counts = []\n            for start, stop in entrysteps:\n                numentries = stop - start\n                chunks.append(VirtualArray(lazybranch, (start, stop), cache=cache, type=awkward.type.ArrayType(numentries, interpretation.type), persistvirtual=persistvirtual))\n                counts.append(numentries)\n\n            out = chunkedarray(chunks, counts)\n            out.__doc__ = self.title.decode(\'ascii\')\n            return out\n        else:\n            start, stop = entrysteps[0]\n            out = VirtualArray(lazybranch, (start, stop), cache=cache, type=awkward.type.ArrayType(stop - start, interpretation.type), persistvirtual=persistvirtual)\n            out.__doc__ = self.title.decode(\'ascii\')\n            return out\n\n    class _BasketKey(object):\n        def __init__(self, source, cursor, compression, complete):\n            start = cursor.index\n            self._fNbytes, self._fVersion, self._fObjlen, self._fDatime, self._fKeylen, self._fCycle, self._fSeekKey, self._fSeekPdir = cursor.fields(source, TBranchMethods._BasketKey._format_small)\n\n            if self._fVersion > 1000:\n                cursor.index = start\n                self._fNbytes, self._fVersion, self._fObjlen, self._fDatime, self._fKeylen, self._fCycle, self._fSeekKey, self._fSeekPdir = cursor.fields(source, TBranchMethods._BasketKey._format_big)\n\n            if complete:\n                cursor.index = start + self._fKeylen - TBranchMethods._BasketKey._format_complete.size - 1\n                self._fVersion, self._fBufferSize, self._fNevBufSize, self._fNevBuf, self._fLast = cursor.fields(source, TBranchMethods._BasketKey._format_complete)\n\n                self.border = self._fLast - self._fKeylen\n\n                if source.size() is not None:\n                    if source.size() - self._fSeekKey < self._fNbytes:\n                        s = source\n                        while s.parent() is not None and s.parent() is not s:\n                            s = s.parent()\n                        raise ValueError(""TKey declares that object has {0} bytes but only {1} remain in the file\\n   in file: {2}"".format(self._fNbytes, source.size() - self._fSeekKey, s.path))\n\n                if self._fObjlen != self._fNbytes - self._fKeylen:\n                    self.source = uproot.source.compressed.CompressedSource(compression, source, Cursor(self._fSeekKey + self._fKeylen), self._fNbytes - self._fKeylen, self._fObjlen)\n                    self.cursor = Cursor(0)\n                else:\n                    self.source = source\n                    self.cursor = Cursor(self._fSeekKey + self._fKeylen)\n\n        _format_small = struct.Struct("">ihiIhhii"")\n        _format_big = struct.Struct("">ihiIhhqq"")\n        _format_complete = struct.Struct("">Hiiii"")\n\n        @property\n        def fName(self):\n            return ""TBranchMethods._BasketKey""\n\n        @property\n        def fTitle(self):\n            return ""TBranchMethods._BasketKey""\n\n        @property\n        def fClassName(self):\n            return ""TBasket""\n\n        def basketdata(self):\n            datasource = self.source.threadlocal()\n            try:\n                return self.cursor.copied().bytes(datasource, self._fObjlen)\n            finally:\n                datasource.dismiss()\n\n    class _RecoveredTBasket(uproot.rootio.ROOTObject):\n        @classmethod\n        def _readinto(cls, self, source, cursor, context, parent):\n            start = cursor.index\n            self._fNbytes, self._fVersion, self._fObjlen, self._fDatime, self._fKeylen, self._fCycle = cursor.fields(source, cls._format1)\n\n            # skip the class name, name, and title\n            cursor.index = start + self._fKeylen - cls._format2.size - 1\n            self._fVersion, self._fBufferSize, self._fNevBufSize, self._fNevBuf, self._fLast = cursor.fields(source, cls._format2)\n\n            # one-byte terminator\n            cursor.skip(1)\n\n            # then if you have offsets data, read them in\n            if self._fNevBufSize > 8:\n                byteoffsets = cursor.bytes(source, self._fNevBuf * 4 + 8)\n                cursor.skip(-4)\n\n            # there\'s a second TKey here, but it doesn\'t contain any new information (in fact, less)\n            cursor.skip(self._fKeylen)\n\n            size = self.border = self._fLast - self._fKeylen\n\n            # the data (not including offsets)\n            self.contents = cursor.bytes(source, size)\n\n            # put the offsets back in, in the way that we expect it\n            if self._fNevBufSize > 8:\n                self.contents = numpy.concatenate((self.contents, byteoffsets))\n                size += byteoffsets.nbytes\n\n            self._fObjlen = size\n            self._fNbytes = self._fObjlen + self._fKeylen\n\n            return self\n\n        _format1 = struct.Struct("">ihiIhh"")\n        _format2 = struct.Struct("">Hiiii"")\n\n        def basketdata(self):\n            return self.contents\n\n        @property\n        def numentries(self):\n            return self._fNevBuf\n\n    def _recover(self):\n        recoveredbaskets = [x for x in uproot.rootio.TObjArray.read(self._source, self._fBaskets._cursor, self._context, self, asclass=TBranchMethods._RecoveredTBasket) if x is not None]\n\n        if self._numgoodbaskets == 0:\n            entryoffsets = [0]\n        else:\n            entryoffsets = self._fBasketEntry[:self._numgoodbaskets + 1].tolist()\n\n        for basket in recoveredbaskets:\n            entryoffsets.append(entryoffsets[-1] + basket.numentries)\n\n        if entryoffsets[-1] == self.numentries:\n            with self._recoverylock:\n                self._recoveredbaskets = recoveredbaskets\n                self._entryoffsets = entryoffsets\n        else:\n            if self.interpretation is None:\n                self._recoveredbaskets = []\n            else:\n                raise ValueError(""entries in recovered baskets (offsets {0}) don\'t add up to total number of entries ({1})\\n   in file: {2}"".format(entryoffsets, self.numentries, self._context.sourcepath))\n\n    def _tryrecover(self):\n        if self._recoveredbaskets is None:\n            self._recover()\n\n    def _basketkey(self, source, i, complete):\n        if 0 <= i < self._numgoodbaskets:\n            return self._BasketKey(source.parent(), Cursor(self._fBasketSeek[i]), self.compression, complete)\n\n        elif self._numgoodbaskets <= i < self.numbaskets:\n            return self._recoveredbaskets[i - self._numgoodbaskets]\n\n        else:\n            raise IndexError(""index {0} out of range for branch with {1} baskets"".format(i, self.numbaskets))\n\n    def _format(self, foldnames, indent="""", strip=""""):\n        name = self._fName.decode(""ascii"")\n        if foldnames and name.startswith(strip + "".""):\n            name = name[len(strip) + 1:]\n\n        if len(name) > 26:\n            out = [indent + name, indent + ""{0:26s} {1:26s} {2}"".format("""", ""(no streamer)"" if self._streamer is None else self._streamer.__class__.__name__, self.interpretation)]\n        else:\n            out = [indent + ""{0:26s} {1:26s} {2}"".format(name, ""(no streamer)"" if self._streamer is None else self._streamer.__class__.__name__, self.interpretation)]\n\n        for branch in self._fBranches:\n            out.extend(branch._format(foldnames, indent + ""  "" if foldnames else indent, self._fName))\n        if len(self._fBranches) > 0 and out[-1] != """":\n            out.append("""")\n\n        return out\n\n    def show(self, foldnames=False, stream=sys.stdout):\n        if stream is None:\n            return ""\\n"".join(self._format(foldnames))\n        else:\n            for line in self._format(foldnames):\n                stream.write(line)\n                stream.write(""\\n"")\n\n    def __len__(self):\n        return self.numentries\n\n    def __getitem__(self, name):\n        return self.get(name)\n\n    def __iter__(self):\n        # prevent Python\'s attempt to interpret __len__ and __getitem__ as iteration\n        raise TypeError(""\'TBranch\' object is not iterable"")\n\n################################################################ for lazy arrays\n\nclass _LazyFiles(object):\n    def __init__(self, paths, treepath, branches, entrysteps, flatten, awkwardlib, basketcache, keycache, executor, persistvirtual, localsource, xrootdsource, httpsource, options):\n        self.paths = paths\n        self.treepath = treepath\n        self.branches = branches\n        self.entrysteps = entrysteps\n        self.flatten = flatten\n        self.awkwardlib = awkwardlib\n        self.basketcache = basketcache\n        self.keycache = keycache\n        self.executor = executor\n        self.persistvirtual = persistvirtual\n        self.localsource = localsource\n        self.xrootdsource = xrootdsource\n        self.httpsource = httpsource\n        self.options = options\n        self._init()\n\n    def _init(self):\n        self.trees = cachetools.LRUCache(5)                                 # last 5 TTrees\n        if self.basketcache is None:\n            self.basketcache = uproot.cache.ThreadSafeArrayCache(1024**2)   # 1 MB\n        if self.keycache is None:\n            self.keycache = cachetools.LRUCache(10000)                      # last 10000 TKeys\n\n    def __getstate__(self):\n        return {""paths"": self.paths,\n                ""treepath"": self.treepath,\n                ""branches"": self.branches,\n                ""entrysteps"": self.entrysteps,\n                ""flatten"": self.flatten,\n                ""awkwardlib"": self.awkwardlib,\n                ""persistvirtual"": self.persistvirtual,\n                ""localsource"": self.localsource,\n                ""xrootdsource"": self.xrootdsource,\n                ""httpsource"": self.httpsource,\n                ""options"": self.options}\n                \n    def __setstate__(self, state):\n        self.paths = state[""paths""]\n        self.treepath = state[""treepath""]\n        self.branches = state[""branches""]\n        self.entrysteps = state[""entrysteps""]\n        self.flatten = state[""flatten""]\n        self.awkwardlib = state[""awkwardlib""]\n        self.basketcache = None\n        self.keycache = None\n        self.executor = None\n        self.persistvirtual = state[""persistvirtual""]\n        self.localsource = state[""localsource""]\n        self.xrootdsource = state[""xrootdsource""]\n        self.httpsource = state[""httpsource""]\n        self.options = state[""options""]\n        self._init()\n\n    def __call__(self, pathi, branchname):\n        awkward = _normalize_awkwardlib(self.awkwardlib)\n        tree = self.trees.get(self.paths[pathi], None)\n        if tree is None:\n            tree = self.trees[self.paths[pathi]] = uproot.rootio.open(self.paths[pathi])[self.treepath]\n            tree.interpretations = dict((b.name, x) for b, x in tree._normalize_branches(self.branches, awkward))\n        return tree[branchname].lazyarray(interpretation=tree.interpretations[branchname], entrysteps=self.entrysteps, entrystart=None, entrystop=None, flatten=self.flatten, awkwardlib=awkward, cache=None, basketcache=self.basketcache, keycache=self.keycache, executor=self.executor, persistvirtual=self.persistvirtual)\n\nclass _LazyTree(object):\n    def __init__(self, path, treepath, tree, interpretation, flatten, awkwardlib, basketcache, keycache, executor):\n        self.path = path\n        self.treepath = treepath\n        self.tree = tree\n        self.interpretation = interpretation\n        self.flatten = flatten\n        self.awkwardlib = awkwardlib\n        self.basketcache = basketcache\n        self.keycache = keycache\n        self.executor = executor\n        self._init()\n\n    def _init(self):\n        if self.tree is None:\n            self.tree = uproot.rootio.open(self.path)[self.treepath]\n        if self.basketcache is None:\n            self.basketcache = uproot.cache.ThreadSafeArrayCache(1024**2)   # 1 MB\n        if self.keycache is None:\n            self.keycache = {}                                              # unlimited\n\n    def __getstate__(self):\n        return {""path"": self.path,\n                ""treepath"": self.treepath,\n                ""interpretation"": self.interpretation,\n                ""flatten"": self.flatten,\n                ""awkwardlib"": self.awkwardlib}\n\n    def __setstate__(self, state):\n        self.path = state[""path""]\n        self.treepath = state[""treepath""]\n        self.tree = None\n        self.interpretation = state[""interpretation""]\n        self.flatten = state[""flatten""]\n        self.awkwardlib = state[""awkwardlib""]\n        self.basketcache = None\n        self.keycache = None\n        self.executor = None\n        self._init()\n\n    def __call__(self, branch, entrystart, entrystop):\n        return self.tree[branch].array(interpretation=self.interpretation[branch], entrystart=entrystart, entrystop=entrystop, flatten=self.flatten, awkwardlib=self.awkwardlib, cache=None, basketcache=self.basketcache, keycache=self.keycache, executor=self.executor)\n        \nclass _LazyBranch(object):\n    def __init__(self, path, treepath, branchname, branch, interpretation, flatten, awkwardlib, basketcache, keycache, executor):\n        self.path = path\n        self.treepath = treepath\n        self.branchname = branchname\n        self.branch = branch\n        self.interpretation = interpretation\n        self.flatten = flatten\n        self.awkwardlib = awkwardlib\n        self.basketcache = basketcache\n        self.keycache = keycache\n        self.executor = executor\n        self._init()\n\n    def _init(self):\n        if self.branch is None:\n            self.branch = uproot.rootio.open(self.path)[self.treepath][self.branchname]\n        if self.basketcache is None:\n            self.basketcache = uproot.cache.ThreadSafeArrayCache(1024**2)   # 1 MB\n        if self.keycache is None:\n            self.keycache = {}                                              # unlimited\n\n    def __getstate__(self):\n        return {""path"": self.path,\n                ""treepath"": self.treepath,\n                ""branchname"": self.branchname,\n                ""interpretation"": self.interpretation,\n                ""flatten"": self.flatten,\n                ""awkwardlib"": self.awkwardlib}\n\n    def __setstate__(self, state):\n        self.path = state[""path""]\n        self.treepath = state[""treepath""]\n        self.branchname = state[""branchname""]\n        self.branch = None\n        self.interpretation = state[""interpretation""]\n        self.flatten = state[""flatten""]\n        self.awkwardlib = state[""awkwardlib""]\n        self.basketcache = None\n        self.keycache = None\n        self.executor = None\n        self._init()\n\n    def __call__(self, entrystart, entrystop):\n        return self.branch.array(interpretation=self.interpretation, entrystart=entrystart, entrystop=entrystop, flatten=self.flatten, awkwardlib=self.awkwardlib, cache=None, basketcache=self.basketcache, keycache=self.keycache, executor=self.executor, blocking=True)\n\ndef lazyarray(path, treepath, branchname, interpretation=None, namedecode=""utf-8"", entrysteps=float(""inf""), flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, persistvirtual=False, localsource=MemmapSource.defaults, xrootdsource=XRootDSource.defaults, httpsource=HTTPSource.defaults, **options):\n    if interpretation is None:\n        branches = branchname\n    else:\n        branches = {branchname: interpretation}\n    out = lazyarrays(path, treepath, branches=branches, namedecode=namedecode, entrysteps=entrysteps, flatten=flatten, profile=None, awkwardlib=awkwardlib, cache=cache, basketcache=basketcache, keycache=keycache, executor=executor, persistvirtual=persistvirtual, localsource=localsource, xrootdsource=xrootdsource, httpsource=httpsource, **options)\n    if len(out.columns) != 1:\n        raise ValueError(""list of branch names or glob/regex matches more than one branch; use uproot.lazyarrays (plural)"")\n    return out[out.columns[0]]\n\ndef lazyarrays(path, treepath, branches=None, namedecode=""utf-8"", entrysteps=float(""inf""), flatten=False, profile=None, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, persistvirtual=False, localsource=MemmapSource.defaults, xrootdsource=XRootDSource.defaults, httpsource=HTTPSource.defaults, **options):\n    awkward = _normalize_awkwardlib(awkwardlib)\n    if isinstance(path, string_types):\n        paths = _filename_explode(path)\n    else:\n        paths = [y for x in path for y in _filename_explode(x)]\n\n    path2count = numentries(path, treepath, total=False, localsource=localsource, xrootdsource=xrootdsource, httpsource=httpsource, executor=executor, blocking=True)\n\n    lazyfiles = _LazyFiles(paths, treepath, branches, entrysteps, flatten, awkward.__name__, basketcache, keycache, executor, persistvirtual, localsource, xrootdsource, httpsource, options)\n\n    brancheslist = None\n    for path in paths:\n        file = uproot.rootio.open(path, localsource=localsource, xrootdsource=xrootdsource, httpsource=httpsource, **options)\n        try:\n            tree = file[treepath]\n        except KeyError:\n            continue\n        brancheslist = list(tree._normalize_branches(branches, awkward))\n        break\n\n    if brancheslist is None:\n        raise ValueError(""no matching paths contained a tree named {0}"".format(repr(treepath)))\n\n    out = awkward.Table()\n    for branch, interpretation in brancheslist:\n        inner = interpretation\n        while isinstance(inner, asjagged):\n            inner = inner.content\n        if isinstance(inner, asobj) and getattr(inner.cls, ""_arraymethods"", None) is not None:\n            VirtualArray = awkward.Methods.mixin(inner.cls._arraymethods, awkward.VirtualArray)\n        elif isinstance(inner, asgenobj) and getattr(inner.generator.cls, ""_arraymethods"", None) is not None:\n            VirtualArray = awkward.Methods.mixin(inner.generator.cls._arraymethods, awkward.VirtualArray)\n        else:\n            VirtualArray = awkward.VirtualArray\n\n        chunks = []\n        counts = []\n        for pathi, path in enumerate(paths):\n            chunks.append(VirtualArray(lazyfiles, (pathi, branch.name), cache=cache, type=awkward.type.ArrayType(path2count[path], interpretation.type), persistvirtual=persistvirtual))\n            counts.append(path2count[path])\n        name = branch.name.decode(""ascii"") if namedecode is None else branch.name.decode(namedecode)\n        out[name] = awkward.ChunkedArray(chunks, counts)\n\n    if profile is not None:\n        out = uproot_methods.profiles.transformer(profile)(out)\n    return out\n\ndef daskarray(path, treepath, branchname, interpretation=None, namedecode=""utf-8"", entrysteps=float(""inf""), flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, localsource=MemmapSource.defaults, xrootdsource=XRootDSource.defaults, httpsource=HTTPSource.defaults, **options):\n    out = lazyarray(path, treepath, branchname, interpretation=interpretation, namedecode=namedecode, entrysteps=entrysteps, flatten=flatten, awkwardlib=awkwardlib, cache=cache, basketcache=basketcache, keycache=keycache, executor=executor, persistvirtual=False, localsource=localsource, xrootdsource=xrootdsource, httpsource=httpsource, **options)\n    import dask.array\n    if len(out.shape) == 1:\n        return dask.array.from_array(out, out.shape, fancy=True)\n    else:\n        raise NotImplementedError(""TODO: len(shape) > 1"")\n\ndef daskframe(path, treepath, branches=None, namedecode=""utf-8"", entrysteps=float(""inf""), flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, localsource=MemmapSource.defaults, xrootdsource=XRootDSource.defaults, httpsource=HTTPSource.defaults, **options):\n    import dask.array\n    import dask.dataframe\n    out = lazyarrays(path, treepath, branches=branches, namedecode=namedecode, entrysteps=entrysteps, flatten=flatten, profile=None, awkwardlib=awkwardlib, cache=cache, basketcache=basketcache, keycache=keycache, executor=executor, persistvirtual=False, localsource=localsource, xrootdsource=xrootdsource, httpsource=httpsource, **options)\n    series = []\n    for n in out.columns:\n        x = out[n]\n        if len(x.shape) == 1:\n            array = dask.array.from_array(x, x.shape, fancy=True)\n            series.append(dask.dataframe.from_dask_array(array, columns=n))\n        else:\n            raise NotImplementedError(""TODO: len(shape) > 1"")\n    return dask.dataframe.concat(series, axis=1)\n\n################################################################ for quickly getting numentries\n\ndef numentries(path, treepath, total=True, localsource=MemmapSource.defaults, xrootdsource={""timeout"": None, ""chunkbytes"": 32*1024, ""limitbytes"": 1024**2, ""parallel"": False}, httpsource={""chunkbytes"": 32*1024, ""limitbytes"": 1024**2, ""parallel"": False}, executor=None, blocking=True, **options):\n    if isinstance(path, string_types):\n        paths = _filename_explode(path)\n    else:\n        paths = [y for x in path for y in _filename_explode(x)]\n    return _numentries(paths, treepath, total, localsource, xrootdsource, httpsource, executor, blocking, [None] * len(paths), options)\n\ndef _numentries(paths, treepath, total, localsource, xrootdsource, httpsource, executor, blocking, uuids, options):\n    class _TTreeForNumEntries(uproot.rootio.ROOTStreamedObject):\n        @classmethod\n        def _readinto(cls, self, source, cursor, context, parent):\n            start, cnt, classversion = uproot.rootio._startcheck(source, cursor)\n            tnamed = uproot.rootio.Undefined.read(source, cursor, context, parent)\n            tattline = uproot.rootio.Undefined.read(source, cursor, context, parent)\n            tattfill = uproot.rootio.Undefined.read(source, cursor, context, parent)\n            tattmarker = uproot.rootio.Undefined.read(source, cursor, context, parent)\n            self._fEntries, = cursor.fields(source, _TTreeForNumEntries._format1)\n            return self\n        _format1 = struct.Struct(\'>q\')\n\n    out = [None] * len(paths)\n\n    def fill(i):\n        try:\n            file = uproot.rootio.open(paths[i], localsource=localsource, xrootdsource=xrootdsource, httpsource=httpsource, read_streamers=False, **options)\n        except Exception:\n            return sys.exc_info()\n        else:\n            try:\n                source = file._context.source\n                file._context.classes[""TTree""] = _TTreeForNumEntries\n                try:\n                    out[i] = file[treepath]._fEntries\n                except KeyError:\n                    out[i] = 0\n                uuids[i] = file._context.uuid\n            except Exception:\n                return sys.exc_info()\n            else:\n                return None\n            finally:\n                source.close()\n\n    if executor is None:\n        for i in range(len(paths)):\n            _delayedraise(fill(i))\n        excinfos = ()\n    else:\n        excinfos = executor.map(fill, range(len(paths)))\n\n    def wait():\n        for excinfo in excinfos:\n            _delayedraise(excinfo)\n        if total:\n            return sum(out)\n        else:\n            return OrderedDict(zip(paths, out))\n\n    if blocking:\n        return wait()\n    else:\n        return wait\n'"
uproot/version.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport re\n\n__version__ = ""3.11.7""\nversion = __version__\nversion_info = tuple(re.split(r""[-\\.]"", __version__))\n\ndel re\n'"
docs/source/conf.py,0,"b'# -*- coding: utf-8 -*-\n\nimport os.path\n\n# If your documentation needs a minimal Sphinx version, state it here.\n# needs_sphinx = ""1.0""\n\nextensions = [\n    ""sphinx.ext.autodoc"",\n    ""sphinx.ext.napoleon"",\n    ""sphinx.ext.doctest"",\n    ""sphinx.ext.todo"",\n    ""sphinx.ext.coverage"",\n    ""sphinx.ext.viewcode"",\n    ""sphinx.ext.githubpages"",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [""-templates""]\n\nsource_suffix = "".rst""\nsource_encoding = ""utf-8""\nmaster_doc = ""index""\n\nproject = u""uproot""\ncopyright = u""2019, IRIS-HEP""\nauthor = u""Jim Pivarski""\n\ndef get_version():\n    g = {}\n    exec(open(os.path.join("".."", "".."", ""uproot"", ""version.py"")).read(), g)\n    return g[""__version__""]\n\nversion = get_version()\nrelease = get_version()\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = []\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n# add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n# show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\n# pygments_style = ""sphinx""\n\n# A list of ignored prefixes for module index sorting.\n# modindex_common_prefix = []\n\n# If true, keep warnings as ""system message"" paragraphs in the built documents.\n# keep_warnings = False\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True\n\nadd_function_parentheses = False\n\n# -- Options for HTML output ----------------------------------------------\n\n# html_theme = ""alabaster""\n# html_theme_options = {}\n# html_theme_path = []\n\nhtml_title = u""uproot v"" + get_version()\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n# html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n# html_logo = None\n\n# The name of an image file (relative to this directory) to use as a favicon of\n# the docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n# html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [""-static""]\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n# html_extra_path = []\n\n# If not None, a ""Last updated on:"" timestamp is inserted at every page\n# bottom, using the given strftime format.\n# The empty string is equivalent to ""%b %d, %Y"".\nhtml_last_updated_fmt = """"\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n# html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n# html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n# html_additional_pages = {}\n\n# If false, no module index is generated.\n# html_domain_indices = True\n\n# If false, no index is generated.\n# html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n# html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n# html_show_sourcelink = True\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True.\n# html_show_sphinx = True\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True.\n# html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n# html_use_opensearch = """"\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n# html_file_suffix = None\n\n# Language to be used for generating the HTML full-text search index.\n# Sphinx supports the following languages:\n#   ""da"", ""de"", ""en"", ""es"", ""fi"", ""fr"", ""hu"", ""it"", ""ja""\n#   ""nl"", ""no"", ""pt"", ""ro"", ""ru"", ""sv"", ""tr"", ""zh""\n# html_search_language = ""en""\n\n# A dictionary with options for the search language support, empty by default.\n# ""ja"" uses this config value.\n# ""zh"" user can custom change `jieba` dictionary path.\n# html_search_options = {""type"": ""default""}\n\n# The name of a javascript file (relative to the configuration directory) that\n# implements a search results scorer. If empty, the default will be used.\n# html_search_scorer = ""scorer.js""\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = ""uprootdoc""\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {}\nlatex_documents = [(master_doc, ""uproot.tex"", u""uproot Documentation"", u""Jim Pivarski"", ""manual""),]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n# latex_logo = None\n\n# For ""manual"" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n# latex_use_parts = False\n\n# If true, show page references after internal links.\n# latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n# latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n# latex_appendices = []\n\n# It false, will not define \\strong, \\code, \titleref, \\crossref ... but only\n# \\sphinxstrong, ..., \\sphinxtitleref, ... To help avoid clash with user added\n# packages.\n# latex_keep_old_macro_names = True\n\n# If false, no module index is generated.\n# latex_domain_indices = True\n\n# -- Options for manual page output ---------------------------------------\n\nman_pages = [(master_doc, ""uproot"", u""uproot Documentation"", [author], 1)]\n\n# If true, show URL addresses after external links.\n# man_show_urls = False\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [(master_doc, ""uproot"", u""uproot Documentation"", author, ""uproot"", ""Minimalist ROOT I/O in pure Python and Numpy."", ""Miscellaneous""),]\n\n# Documents to append as an appendix to all manuals.\n# texinfo_appendices = []\n\n# If false, no module index is generated.\n# texinfo_domain_indices = True\n\n# How to display URL addresses: ""footnote"", ""no"", or ""inline"".\n# texinfo_show_urls = ""footnote""\n\n# If true, do not generate a @detailmenu in the ""Top"" node\'s menu.\n# texinfo_no_detailmenu = False\n'"
uproot/_connect/__init__.py,0,b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import'
uproot/_connect/_pandas.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport itertools\nimport functools\nimport operator\n\nimport numpy\n\nimport awkward as awkwardbase\n\nimport uproot.tree\nimport uproot.interp.numerical\nfrom uproot.interp.jagged import asjagged\nfrom uproot.interp.numerical import asdtype\nfrom uproot.interp.objects import asobj\nfrom uproot.interp.objects import astable\n\nfrom uproot.source.memmap import MemmapSource\nfrom uproot.source.xrootd import XRootDSource\nfrom uproot.source.http import HTTPSource\n\nclass TTreeMethods_pandas(object):\n    def __init__(self, tree):\n        self._tree = tree\n\n    def df(self, branches=None, namedecode=""utf-8"", entrystart=None, entrystop=None, flatten=True, flatname=None, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, blocking=True):\n        import pandas\n        return self._tree.arrays(branches=branches, outputtype=pandas.DataFrame, namedecode=namedecode, entrystart=entrystart, entrystop=entrystop, flatten=flatten, flatname=flatname, awkwardlib=awkwardlib, cache=cache, basketcache=basketcache, keycache=keycache, executor=executor, blocking=blocking)\n\n    def iterate(self, branches=None, entrysteps=None, namedecode=""utf-8"", entrystart=None, entrystop=None, flatten=True, flatname=None, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, blocking=True):\n        import pandas\n        return self._tree.iterate(branches=branches, entrysteps=entrysteps, outputtype=pandas.DataFrame, namedecode=namedecode, reportentries=False, entrystart=entrystart, entrystop=entrystop, flatten=flatten, flatname=flatname, awkwardlib=awkwardlib, cache=cache, basketcache=basketcache, keycache=keycache, executor=executor, blocking=blocking)\n\ndef default_flatname(branchname, fieldname, index):\n    out = branchname\n    if not isinstance(branchname, str):\n        out = branchname.decode(""utf-8"")\n    if fieldname is not None:\n        out += ""."" + fieldname\n    if index != ():\n        out += ""["" + ""]["".join(str(x) for x in index) + ""]""\n    return out\n\ndef futures2df(futures, outputtype, entrystart, entrystop, flatten, flatname, awkward):\n    import pandas\n\n    if flatname is None:\n        flatname = default_flatname\n\n    if not flatten or all(interpretation.__class__ is not asjagged for name, interpretation, future in futures):\n        columns = []\n        data = {}\n        for name, interpretation, future in futures:\n            array = future()\n\n            if isinstance(interpretation, asobj) and isinstance(interpretation.content, astable):\n                interpretation = interpretation.content\n            if isinstance(interpretation, astable) and isinstance(interpretation.content, asdtype):\n                interpretation = interpretation.content\n\n            if isinstance(interpretation, asdtype):\n                if interpretation.todims == ():\n                    if interpretation.todtype.names is None:\n                        fn = flatname(name, None, ())\n                        columns.append(fn)\n                        data[fn] = array\n                    else:\n                        for nn in interpretation.todtype.names:\n                            if not nn.startswith("" ""):\n                                fn = flatname(name, nn, ())\n                                columns.append(fn)\n                                data[fn] = array[nn]\n                else:\n                    for tup in itertools.product(*[range(x) for x in interpretation.todims]):\n                        if interpretation.todtype.names is None:\n                            fn = flatname(name, None, tup)\n                            columns.append(fn)\n                            data[fn] = array[(slice(None),) + tup]\n                        else:\n                            for nn in interpretation.todtype.names:\n                                if not nn.startswith("" ""):\n                                    fn = flatname(name, nn, tup)\n                                    columns.append(fn)\n                                    data[fn] = array[nn][(slice(None),) + tup]\n            else:\n                fn = flatname(name, None, ())\n                columns.append(fn)\n                data[fn] = list(array)     # must be serialized as a Python list for Pandas to accept it\n\n        index = pandas.RangeIndex(entrystart, entrystop, name=""entry"")\n        return outputtype(columns=columns, data=data, index=index)\n\n    else:\n        starts, stops = None, None\n\n        needbroadcasts = []\n        names = []\n        interpretations = []\n        arrays = []\n        for name, interpretation, future in futures:\n            if isinstance(interpretation, asobj) and isinstance(interpretation.content, astable):\n                interpretation = interpretation.content\n            if isinstance(interpretation, astable) and isinstance(interpretation.content, asdtype):\n                interpretation = interpretation.content\n\n            array = future()\n            if isinstance(interpretation, asjagged):\n                interpretation = interpretation.content\n                if isinstance(interpretation, asobj) and isinstance(interpretation.content, astable):\n                    interpretation = interpretation.content\n                if isinstance(interpretation, astable) and isinstance(interpretation.content, asdtype):\n                    interpretation = interpretation.content\n\n                # justifies the assumption that array.content == array.flatten() and array.stops.max() == array.stops[-1]\n                assert len(array.starts) == 0 or ((array.offsetsaliased(array.starts, array.stops) or (len(array.starts.shape) == 1 and array.numpy.array_equal(array.starts[1:], array.stops[:-1]))) and array.starts[0] == 0)\n\n                if starts is None:\n                    starts = array.starts\n                    stops = array.stops\n                    index = array.localindex\n                else:\n                    if starts is not array.starts and not awkward.numpy.array_equal(starts, array.starts):\n                        raise ValueError(""cannot use flatten=True on branches with different jagged structure, such as electrons and muons (different, variable number of each per event); either explicitly select compatible branches, such as [\\""MET_*\\"", \\""Muon_*\\""] (scalar and variable per event is okay), or set flatten=False"")\n\n                if len(array.starts) == 0:\n                    array = array.content[0:0]\n                else:\n                    array = array.content\n                needbroadcasts.append(False)\n\n            else:\n                needbroadcasts.append(True)\n\n            names.append(name)\n            interpretations.append(interpretation)\n            arrays.append(array)\n\n        index = pandas.MultiIndex.from_arrays([index.tojagged(numpy.arange(entrystart, entrystop, dtype=numpy.int64)).content, index.content], names=[""entry"", ""subentry""])\n\n        df = outputtype(index=index)\n\n        for name, interpretation, array, needbroadcast in zip(names, interpretations, arrays, needbroadcasts):\n            if isinstance(interpretation, uproot.interp.numerical._asnumeric):\n                if isinstance(array, awkwardbase.ObjectArray):\n                    array = array.content\n\n                if needbroadcast:\n                    # Invoke jagged broadcasting to align arrays\n                    originaldtype = array.dtype\n                    originaldims = array.shape[1:]\n\n                    if isinstance(array, awkwardbase.Table):\n                        for nn in array.columns:\n                            array[nn] = awkward.JaggedArray(starts, stops, awkward.numpy.empty(stops[-1], dtype=array[nn].dtype)).tojagged(array[nn]).content\n\n                    else:\n                        if len(originaldims) != 0:\n                            array = array.view(awkward.numpy.dtype([(str(i), array.dtype) for i in range(functools.reduce(operator.mul, array.shape[1:]))])).reshape(array.shape[0])\n\n                        array = awkward.JaggedArray(starts, stops, awkward.numpy.empty(stops[-1], dtype=array.dtype)).tojagged(array).content\n                        if len(originaldims) != 0:\n                            array = array.view(originaldtype).reshape((-1,) + originaldims)\n\n                if interpretation.todims == ():\n                    if interpretation.todtype.names is None:\n                        fn = flatname(name, None, ())\n                        df[fn] = array\n                    else:\n                        for nn in interpretation.todtype.names:\n                            if not nn.startswith("" ""):\n                                fn = flatname(name, nn, ())\n                                df[fn] = array[nn]\n                else:\n                    for tup in itertools.product(*[range(x) for x in interpretation.todims]):\n                        if interpretation.todtype.names is None:\n                            fn = flatname(name, None, tup)\n                            df[fn] = array[(slice(None),) + tup]\n                        else:\n                            for nn in interpretation.todtype.names:\n                                if not nn.startswith("" ""):\n                                    fn = flatname(name, nn, tup)\n                                    df[fn] = array[nn][(slice(None),) + tup]\n\n            else:\n                fn = flatname(name, None, ())\n\n                array = awkward.numpy.array(array, dtype=object)\n                indexes = numpy.arange(len(array))\n\n                indexes = awkward.JaggedArray(starts, stops, awkward.numpy.empty(stops[-1], dtype=object)).tojagged(indexes).content\n\n                array = array[indexes]\n\n                if len(array) != 0 and isinstance(array[0], awkward.numpy.ndarray):\n                    df[fn] = list(array)\n                else:\n                    df[fn] = array\n\n        return df\n'"
uproot/interp/__init__.py,0,b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import'
uproot/interp/auto.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport copy\nimport re\nimport ast\nfrom functools import reduce\n\nimport uproot.const\nimport uproot.rootio\nfrom uproot.interp.numerical import asdtype\nfrom uproot.interp.numerical import asarray\nfrom uproot.interp.numerical import asdouble32\nfrom uproot.interp.numerical import asfloat16\nfrom uproot.interp.numerical import asstlbitset\nfrom uproot.interp.jagged import asjagged\nfrom uproot.interp.objects import astable\nfrom uproot.interp.objects import asobj\nfrom uproot.interp.objects import asgenobj\nfrom uproot.interp.objects import asstring\nfrom uproot.interp.objects import SimpleArray\nfrom uproot.interp.objects import STLVector\nfrom uproot.interp.objects import STLMap\nfrom uproot.interp.objects import STLString\nfrom uproot.interp.objects import Pointer\n\nclass _NotNumerical(Exception): pass\n\ndef _normalize_ftype(fType):\n    if fType is not None and uproot.const.kOffsetL < fType < uproot.const.kOffsetP:\n        return fType - uproot.const.kOffsetL\n    else:\n        return fType\n\ndef _ftype2dtype(fType, awkward):\n    fType = _normalize_ftype(fType)\n    if fType == uproot.const.kBool:\n        return awkward.numpy.dtype(awkward.numpy.bool_)\n    elif fType == uproot.const.kChar:\n        return awkward.numpy.dtype(""i1"")\n    elif fType == uproot.const.kUChar:\n        return awkward.numpy.dtype(""u1"")\n    elif fType == uproot.const.kShort:\n        return awkward.numpy.dtype("">i2"")\n    elif fType == uproot.const.kUShort:\n        return awkward.numpy.dtype("">u2"")\n    elif fType == uproot.const.kInt:\n        return awkward.numpy.dtype("">i4"")\n    elif fType in (uproot.const.kBits, uproot.const.kUInt, uproot.const.kCounter):\n        return awkward.numpy.dtype("">u4"")\n    elif fType == uproot.const.kLong:\n        return awkward.numpy.dtype("">i8"")\n    elif fType == uproot.const.kULong:\n        return awkward.numpy.dtype("">u8"")\n    elif fType == uproot.const.kLong64:\n        return awkward.numpy.dtype("">i8"")\n    elif fType == uproot.const.kULong64:\n        return awkward.numpy.dtype("">u8"")\n    elif fType == uproot.const.kFloat:\n        return awkward.numpy.dtype("">f4"")\n    elif fType == uproot.const.kDouble:\n        return awkward.numpy.dtype("">f8"")\n    else:\n        raise _NotNumerical\n\ndef _leaf2dtype(leaf, awkward):\n    classname = leaf.__class__.__name__\n    if classname == ""TLeafO"":\n        return awkward.numpy.dtype(awkward.numpy.bool_)\n    elif classname == ""TLeafB"":\n        if leaf._fIsUnsigned:\n            return awkward.numpy.dtype(awkward.numpy.uint8)\n        else:\n            return awkward.numpy.dtype(awkward.numpy.int8)\n    elif classname == ""TLeafS"":\n        if leaf._fIsUnsigned:\n            return awkward.numpy.dtype(awkward.numpy.uint16)\n        else:\n            return awkward.numpy.dtype(awkward.numpy.int16)\n    elif classname == ""TLeafI"":\n        if leaf._fIsUnsigned:\n            return awkward.numpy.dtype(awkward.numpy.uint32)\n        else:\n            return awkward.numpy.dtype(awkward.numpy.int32)\n    elif classname == ""TLeafL"":\n        if leaf._fIsUnsigned:\n            return awkward.numpy.dtype(awkward.numpy.uint64)\n        else:\n            return awkward.numpy.dtype(awkward.numpy.int64)\n    elif classname == ""TLeafF"":\n        return awkward.numpy.dtype(awkward.numpy.float32)\n    elif classname == ""TLeafD"":\n        return awkward.numpy.dtype(awkward.numpy.float64)\n    elif classname == ""TLeafElement"":\n        return _ftype2dtype(leaf._fType, awkward)\n    else:\n        raise _NotNumerical\n\ndef _obj_or_genobj(streamerClass, branch, isjagged, cntvers=False, tobject=True, speedbump=True):\n    if len(branch._fBranches) != 0:\n        return None\n\n    try:\n        recarray = streamerClass._recarray_dtype(cntvers=cntvers, tobject=tobject)\n\n    except (AttributeError, ValueError):\n        if not speedbump:\n            context = copy.copy(branch._context)\n            context.speedbump = False\n        else:\n            context = branch._context\n\n        if isjagged:\n            return asgenobj(SimpleArray(streamerClass), context, 0)\n        else:\n            return asgenobj(streamerClass, context, 0)\n\n    else:\n        if isjagged:\n            if streamerClass._methods is None:\n                return asjagged(astable(asdtype(recarray)))\n            else:\n                return asjagged(asobj(astable(asdtype(recarray)), streamerClass._methods))\n        else:\n            if streamerClass._methods is None:\n                return asdtype(recarray)\n            else:\n                return asobj(astable(asdtype(recarray)), streamerClass._methods)\n\ndef interpret(branch, awkwardlib=None, swapbytes=True, cntvers=False, tobject=True, speedbump=True):\n    import uproot.tree\n    awkward = uproot.tree._normalize_awkwardlib(awkwardlib)\n\n    dims, isjagged = (), False\n    if len(branch._fLeaves) == 1:\n        m = interpret._titlehasdims.match(branch._fLeaves[0]._fTitle)\n        if m is not None:\n            dims = tuple(int(x) for x in re.findall(interpret._itemdimpattern, branch._fLeaves[0]._fTitle))\n            if dims == ():\n                dims = (branch._fLeaves[0]._fLen, ) if branch._fLeaves[0]._fLen > 1 else ()\n            if any(interpret._itemdimpattern.match(x) is None for x in re.findall(interpret._itemanypattern, branch._fLeaves[0]._fTitle)):\n                isjagged = True\n    else:\n        for leaf in branch._fLeaves:\n            if interpret._titlehasdims.match(leaf._fTitle):\n                return None\n\n    try:\n        if len(branch._fLeaves) == 1:\n            if isinstance(branch._streamer, uproot.rootio.TStreamerObjectPointer):\n                obj = branch._streamer._fTypeName\n                if obj.endswith(b""*""):\n                    obj = obj[:-1]\n                obj = uproot.rootio._safename(obj)\n                if obj in branch._context.classes:\n                    return _obj_or_genobj(branch._context.classes.get(obj), branch, isjagged, cntvers=cntvers, tobject=tobject, speedbump=speedbump)\n\n            # Process Double32_t and Float16_t types possibly packed in TLeafElement\n            leaftype = uproot.const.kBase\n            if branch._fLeaves[0].__class__.__name__ == ""TLeafElement"":\n                leaftype = _normalize_ftype(branch._fLeaves[0]._fType)\n\n            iskDouble32 = leaftype == uproot.const.kDouble32\n            iskFloat16  = leaftype == uproot.const.kFloat16\n\n            if iskDouble32 or iskFloat16:\n                def transform(node, tofloat=True):\n                    if isinstance(node, ast.AST):\n                        if isinstance(node, ast.Name) and isinstance(node.ctx, ast.Load) and node.id == ""pi"":\n                            out = ast.Num(3.141592653589793)  # TMath::Pi()\n                        elif isinstance(node, ast.Num):\n                            out = ast.Num(float(node.n))\n                        elif isinstance(node, ast.BinOp) and isinstance(node.op, (ast.Add, ast.Sub, ast.Mult, ast.Div)):\n                            out = ast.BinOp(transform(node.left), node.op, transform(node.right))\n                        elif isinstance(node, ast.UnaryOp) and isinstance(node.op, ast.USub):\n                            out = ast.UnaryOp(node.op, transform(node.operand))\n                        elif isinstance(node, ast.List) and isinstance(node.ctx, ast.Load) and len(node.elts) == 2:\n                            out = ast.List([transform(node.elts[0]), transform(node.elts[1])], node.ctx)\n                        elif isinstance(node, ast.List) and isinstance(node.ctx, ast.Load) and len(node.elts) == 3 and isinstance(node.elts[2], ast.Num):\n                            out = ast.List([transform(node.elts[0]), transform(node.elts[1]), node.elts[2]], node.ctx)\n                        else:\n                            raise Exception(ast.dump(node))\n                        out.lineno, out.col_offset = node.lineno, node.col_offset\n                        return out\n                    else:\n                        raise Exception(ast.dump(node))\n\n                try:\n                    left, right = branch._streamer._fTitle.index(b""[""), branch._streamer._fTitle.index(b""]"")\n                except (ValueError, AttributeError):\n                    low, high, numbits = 0, 0, 0\n                else:\n                    try:\n                        spec = eval(compile(ast.Expression(transform(ast.parse(branch._streamer._fTitle[left : right + 1]).body[0].value)), repr(branch._streamer._fTitle), ""eval""))\n                        if len(spec) == 2:\n                            low, high = spec\n                            numbits = None\n                        else:\n                            low, high, numbits = spec\n                    except Exception:\n                        return None\n\n                if iskDouble32 and numbits == 0:\n                    out = asdtype(awkward.numpy.dtype(("">f4"", dims)), awkward.numpy.dtype((""f8"", dims)))\n                elif iskDouble32 and numbits is None:\n                    out = asdouble32(low, high, 32, dims)\n                elif iskDouble32:\n                    out = asdouble32(low, high, numbits, dims)\n                elif iskFloat16 and numbits == 0:\n                    out = asfloat16(low, high, 12, dims)\n                elif iskFloat16 and numbits is None:\n                    out = asfloat16(low, high, 32, dims)\n                elif iskFloat16:\n                    out = asfloat16(low, high, numbits, dims)\n                else:\n                    return None\n\n            else:\n                fromdtype = _leaf2dtype(branch._fLeaves[0], awkward).newbyteorder("">"")\n\n                if swapbytes:\n                    out = asdtype(awkward.numpy.dtype((fromdtype, dims)), awkward.numpy.dtype((fromdtype.newbyteorder(""=""), dims)))\n                else:\n                    out = asdtype(awkward.numpy.dtype((fromdtype, dims)), awkward.numpy.dtype((fromdtype, dims)))\n\n            if branch._fLeaves[0]._fLeafCount is None:\n                return out\n            else:\n                return asjagged(out)\n\n        elif len(branch._fLeaves) > 1:\n            fromdtype = awkward.numpy.dtype([(str(leaf._fName.decode(""ascii"")), _leaf2dtype(leaf, awkward).newbyteorder("">"")) for leaf in branch._fLeaves])\n            if swapbytes:\n                todtype = awkward.numpy.dtype([(str(leaf._fName.decode(""ascii"")), _leaf2dtype(leaf, awkward).newbyteorder(""="")) for leaf in branch._fLeaves])\n            else:\n                todtype = fromdtype\n\n            if all(leaf._fLeafCount is None for leaf in branch._fLeaves):\n                return asdtype(awkward.numpy.dtype((fromdtype, dims)), awkward.numpy.dtype((todtype, dims)))\n            else:\n                return None\n\n    except _NotNumerical:\n        if len(branch._fLeaves) == 1:\n            if len(branch._fBranches) > 0 and all(len(x._fLeaves) == 1 and x._fLeaves[0]._fLeafCount is branch._fLeaves[0] for x in branch._fBranches):\n                return asdtype("">i4"")\n\n            if isinstance(branch._streamer, uproot.rootio.TStreamerObject):\n                obj = uproot.rootio._safename(branch._streamer._fTypeName)\n                if obj == ""string"":\n                    return asgenobj(STLString(awkward), branch._context, 0)\n                elif obj in branch._context.classes:\n                    return _obj_or_genobj(branch._context.classes.get(obj), branch, isjagged, cntvers=cntvers, tobject=tobject, speedbump=speedbump)\n\n            if isinstance(branch._streamer, uproot.rootio.TStreamerInfo):\n                obj = uproot.rootio._safename(branch._streamer._fName)\n                if obj == ""string"":\n                    return asgenobj(STLString(awkward), branch._context, 0)\n                elif obj in branch._context.classes:\n                    return _obj_or_genobj(branch._context.classes.get(obj), branch, isjagged, cntvers=cntvers, tobject=tobject, speedbump=speedbump)\n\n            if branch._fLeaves[0].__class__.__name__ == ""TLeafC"":\n                return asstring(skipbytes=1)\n\n            elif branch._fLeaves[0].__class__.__name__ == ""TLeafElement"":\n                if isinstance(branch._streamer, uproot.rootio.TStreamerBasicType):\n                    try:\n                        fromdtype = _ftype2dtype(branch._streamer._fType, awkward)\n                    except _NotNumerical:\n                        pass\n                    else:\n                        if swapbytes:\n                            todtype = fromdtype.newbyteorder(""="")\n                        else:\n                            todtype = fromdtype\n                        fromdims, remainder = divmod(branch._streamer._fSize, fromdtype.itemsize)\n                        if remainder == 0:\n                            todims = dims\n                            if reduce(lambda x, y: x * y, todims, 1) != fromdims:\n                                todims = (fromdims,)\n                            return asdtype(awkward.numpy.dtype((fromdtype, (fromdims,))), awkward.numpy.dtype((todtype, todims)))\n\n                if isinstance(branch._streamer, uproot.rootio.TStreamerBasicPointer):\n                    if uproot.const.kOffsetP < branch._streamer._fType < uproot.const.kOffsetP + 20:\n                        try:\n                            fromdtype = _ftype2dtype(branch._streamer._fType - uproot.const.kOffsetP, awkward)\n                        except _NotNumerical:\n                            pass\n                        else:\n                            if swapbytes:\n                                todtype = fromdtype.newbyteorder(""="")\n                            else:\n                                todtype = fromdtype\n                            if len(branch._fLeaves) == 1 and branch._fLeaves[0]._fLeafCount is not None:\n                                return asjagged(asdtype(fromdtype, todtype), skipbytes=1)\n\n                if isinstance(branch._streamer, uproot.rootio.TStreamerObjectAny):\n                    if getattr(branch._streamer, ""_fTypeName"", None) in (b""TArrayC"", b""TArrayS"", b""TArrayI"", b""TArrayL"", b""TArrayL64"", b""TArrayF"", b""TArrayD""):\n                        return asjagged(asdtype(getattr(uproot.rootio, branch._streamer._fTypeName.decode(""ascii""))._dtype), skipbytes=4)\n\n                if isinstance(branch._streamer, uproot.rootio.TStreamerString):\n                    return asstring(skipbytes=1)\n\n                if isinstance(branch._streamer, uproot.rootio.TStreamerSTLstring):\n                    if branch._isTClonesArray:\n                        return asgenobj(STLVector(STLString()), branch._context, 6)\n                    else:\n                        return asstring(skipbytes=7)\n\n                if getattr(branch._streamer, ""_fType"", None) == uproot.const.kCharStar:\n                    return asstring(skipbytes=4)\n\n                if getattr(branch._streamer, ""_fSTLtype"", None) == uproot.const.kSTLvector:\n                    try:\n                        fromdtype = _ftype2dtype(branch._streamer._fCtype, awkward)\n                        if swapbytes:\n                            ascontent = asdtype(fromdtype, fromdtype.newbyteorder(""=""))\n                        else:\n                            ascontent = asdtype(fromdtype, fromdtype)\n                        if branch._isTClonesArray:\n                            return asgenobj(SimpleArray(STLVector(asdtype(fromdtype, fromdtype))), branch._context, 6)\n                        else:\n                            return asjagged(ascontent, skipbytes=10)\n\n                    except _NotNumerical:\n                        if branch._vecstreamer is not None:\n                            try:\n                                streamerClass = branch._vecstreamer.pyclass\n                            except AttributeError:\n                                obj = uproot.rootio._safename(branch._vecstreamer._fName)\n                                if obj in branch._context.classes:\n                                    streamerClass = branch._context.classes.get(obj)\n                            if getattr(streamerClass, ""_hasreadobjany"", False):\n                                return None\n\n                            if streamerClass.__name__ == ""string"":\n                                return asgenobj(STLVector(STLString(awkward)), branch._context, 6)\n\n                            if len(branch._fBranches) != 0:\n                                return None\n\n                            try:\n                                recarray = streamerClass._recarray_dtype(cntvers=cntvers, tobject=tobject)\n                            except (AttributeError, ValueError):\n                                return asgenobj(STLVector(streamerClass), branch._context, 6)\n                            else:\n                                if streamerClass._methods is None:\n                                    return asjagged(astable(asdtype(recarray)), skipbytes=10)\n                                else:\n                                    return asjagged(asobj(astable(asdtype(recarray)), streamerClass._methods), skipbytes=10)\n\n                if hasattr(branch._streamer, ""_fTypeName""):\n                    m = re.match(b""bitset<([1-9][0-9]*)>"", branch._streamer._fTypeName)\n                    if m is not None:\n                        return asjagged(asstlbitset(int(m.group(1))), skipbytes=6)\n\n                if getattr(branch._streamer, ""_fTypeName"", None) == b""vector<bool>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<Bool_t>"":\n                    return asjagged(asdtype(awkward.numpy.bool_), skipbytes=10)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<char>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<Char_t>"":\n                    return asjagged(asdtype(""i1""), skipbytes=10)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<unsigned char>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<UChar_t>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<Byte_t>"":\n                    return asjagged(asdtype(""u1""), skipbytes=10)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<short>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<Short_t>"":\n                    return asjagged(asdtype(""i2""), skipbytes=10)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<unsigned short>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<UShort_t>"":\n                    return asjagged(asdtype(""u2""), skipbytes=10)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<int>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<Int_t>"":\n                    return asjagged(asdtype(""i4""), skipbytes=10)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<unsigned int>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<UInt_t>"":\n                    return asjagged(asdtype(""u4""), skipbytes=10)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<long>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<Long_t>"":\n                    return asjagged(asdtype(""i8""), skipbytes=10)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<unsigned long>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<ULong64_t>"":\n                    return asjagged(asdtype(""u8""), skipbytes=10)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<float>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<Float_t>"":\n                    return asjagged(asdtype(""f4""), skipbytes=10)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<double>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<Double_t>"":\n                    return asjagged(asdtype(""f8""), skipbytes=10)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<string>"":\n                    return asgenobj(STLVector(STLString(awkward)), branch._context, 6)\n                else:\n                    m = interpret._vectorpointer.match(getattr(branch._streamer, ""_fTypeName"", b""""))\n                    if m is not None and m.group(1) in branch._context.streamerinfosmap:\n                        streamer = branch._context.streamerinfosmap[m.group(1)]\n                        return asgenobj(STLVector(Pointer(streamer.pyclass)), branch._context, skipbytes=6)\n\n                if getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,bool>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,Bool_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(awkward.numpy.bool_)), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,char>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,Char_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""i1"")), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,unsigned char>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,UChar_t>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,Byte_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""u1"")), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,short>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,Short_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""i2"")), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,unsigned short>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,UShort_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""u2"")), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,int>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,Int_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""i4"")), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,unsigned int>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,UInt_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""u4"")), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,long>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,Long_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""i8"")), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,unsigned long>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,ULong64_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""u8"")), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,float>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,Float_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""f4"")), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,double>"" or getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,Double_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""f8"")), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""map<string,string>"":\n                    return asgenobj(STLMap(STLString(awkward), STLString(awkward)), branch._context, 6)\n\n                if getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<bool> >"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<Bool_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype(awkward.numpy.bool_))), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<char> >"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<Char_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype(""i1""))), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<unsigned char> >"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<UChar_t> >"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<Byte_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype(""u1""))), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<short> >"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<Short_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">i2""))), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<unsigned short> >"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<UShort_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">u2""))), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<int> >"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<Int_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">i4""))), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<unsigned int> >"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<UInt_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">u4""))), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<long> >"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<Long_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">i8""))), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<unsigned long> >"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<ULong64_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">u8""))), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<float> >"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<Float_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">f4""))), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<double> >"" or getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<Double_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">f8""))), branch._context, 6)\n                elif getattr(branch._streamer, ""_fTypeName"", None) == b""vector<vector<string> >"":\n                    return asgenobj(STLVector(STLVector(STLString(awkward))), branch._context, 6)\n\n                m = re.match(b""bitset<([1-9][0-9]*)>"", branch._fClassName)\n                if m is not None:\n                    return asstlbitset(int(m.group(1)))\n\n                if branch._fClassName == b""string"":\n                    return asstring(skipbytes=1)\n\n                if branch._fClassName == b""vector<bool>"" or branch._fClassName == b""vector<Bool_t>"":\n                    return asjagged(asdtype(awkward.numpy.bool_), skipbytes=10)\n                elif branch._fClassName == b""vector<char>"" or branch._fClassName == b""vector<Char_t>"":\n                    return asjagged(asdtype(""i1""), skipbytes=10)\n                elif branch._fClassName == b""vector<unsigned char>"" or branch._fClassName == b""vector<UChar_t>"" or branch._fClassName == b""vector<Byte_t>"":\n                    return asjagged(asdtype(""u1""), skipbytes=10)\n                elif branch._fClassName == b""vector<short>"" or branch._fClassName == b""vector<Short_t>"":\n                    return asjagged(asdtype(""i2""), skipbytes=10)\n                elif branch._fClassName == b""vector<unsigned short>"" or branch._fClassName == b""vector<UShort_t>"":\n                    return asjagged(asdtype(""u2""), skipbytes=10)\n                elif branch._fClassName == b""vector<int>"" or branch._fClassName == b""vector<Int_t>"":\n                    return asjagged(asdtype(""i4""), skipbytes=10)\n                elif branch._fClassName == b""vector<unsigned int>"" or branch._fClassName == b""vector<UInt_t>"":\n                    return asjagged(asdtype(""u4""), skipbytes=10)\n                elif branch._fClassName == b""vector<long>"" or branch._fClassName == b""vector<Long_t>"":\n                    return asjagged(asdtype(""i8""), skipbytes=10)\n                elif branch._fClassName == b""vector<unsigned long>"" or branch._fClassName == b""vector<ULong64_t>"":\n                    return asjagged(asdtype(""u8""), skipbytes=10)\n                elif branch._fClassName == b""vector<float>"" or branch._fClassName == b""vector<Float_t>"":\n                    return asjagged(asdtype(""f4""), skipbytes=10)\n                elif branch._fClassName == b""vector<double>"" or branch._fClassName == b""vector<Double_t>"":\n                    return asjagged(asdtype(""f8""), skipbytes=10)\n                elif branch._fClassName == b""vector<string>"":\n                    return asgenobj(STLVector(STLString(awkward)), branch._context, 6)\n\n                if branch._fClassName == b""vector<vector<bool> >"" or branch._fClassName == b""vector<vector<Bool_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype(awkward.numpy.bool_))), branch._context, 6)\n                elif branch._fClassName == b""vector<vector<char> >"" or branch._fClassName == b""vector<vector<Char_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype(""i1""))), branch._context, 6)\n                elif branch._fClassName == b""vector<vector<unsigned char> >"" or branch._fClassName == b""vector<vector<UChar_t> >"" or branch._fClassName == b""vector<vector<Byte_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype(""u1""))), branch._context, 6)\n                elif branch._fClassName == b""vector<vector<short> >"" or branch._fClassName == b""vector<vector<Short_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">i2""))), branch._context, 6)\n                elif branch._fClassName == b""vector<vector<unsigned short> >"" or branch._fClassName == b""vector<vector<UShort_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">u2""))), branch._context, 6)\n                elif branch._fClassName == b""vector<vector<int> >"" or branch._fClassName == b""vector<vector<Int_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">i4""))), branch._context, 6)\n                elif branch._fClassName == b""vector<vector<unsigned int> >"" or branch._fClassName == b""vector<vector<UInt_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">u4""))), branch._context, 6)\n                elif branch._fClassName == b""vector<vector<long> >"" or branch._fClassName == b""vector<vector<Long_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">i8""))), branch._context, 6)\n                elif branch._fClassName == b""vector<vector<unsigned long> >"" or branch._fClassName == b""vector<vector<ULong64_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">u8""))), branch._context, 6)\n                elif branch._fClassName == b""vector<vector<float> >"" or branch._fClassName == b""vector<vector<Float_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">f4""))), branch._context, 6)\n                elif branch._fClassName == b""vector<vector<double> >"" or branch._fClassName == b""vector<vector<Double_t> >"":\n                    return asgenobj(STLVector(STLVector(asdtype("">f8""))), branch._context, 6)\n                elif branch._fClassName == b""vector<vector<string> >"":\n                    return asgenobj(STLVector(STLVector(STLString(awkward))), branch._context, 6)\n\n                if branch._fClassName == b""map<string,bool>"" or branch._fClassName == b""map<string,Bool_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(awkward.numpy.bool_)), branch._context, 6)\n                elif branch._fClassName == b""map<string,char>"" or branch._fClassName == b""map<string,Char_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""i1"")), branch._context, 6)\n                elif branch._fClassName == b""map<string,unsigned char>"" or branch._fClassName == b""map<string,UChar_t>"" or branch._fClassName == b""map<string,Byte_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""u1"")), branch._context, 6)\n                elif branch._fClassName == b""map<string,short>"" or branch._fClassName == b""map<string,Short_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""i2"")), branch._context, 6)\n                elif branch._fClassName == b""map<string,unsigned short>"" or branch._fClassName == b""map<string,UShort_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""u2"")), branch._context, 6)\n                elif branch._fClassName == b""map<string,int>"" or branch._fClassName == b""map<string,Int_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""i4"")), branch._context, 6)\n                elif branch._fClassName == b""map<string,unsigned int>"" or branch._fClassName == b""map<string,UInt_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""u4"")), branch._context, 6)\n                elif branch._fClassName == b""map<string,long>"" or branch._fClassName == b""map<string,Long_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""i8"")), branch._context, 6)\n                elif branch._fClassName == b""map<string,unsigned long>"" or branch._fClassName == b""map<string,ULong64_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""u8"")), branch._context, 6)\n                elif branch._fClassName == b""map<string,float>"" or branch._fClassName == b""map<string,Float_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""f4"")), branch._context, 6)\n                elif branch._fClassName == b""map<string,double>"" or branch._fClassName == b""map<string,Double_t>"":\n                    return asgenobj(STLMap(STLString(awkward), asdtype(""f8"")), branch._context, 6)\n                elif branch._fClassName == b""map<string,string>"":\n                    return asgenobj(STLMap(STLString(awkward), STLString(awkward)), branch._context, 6)\n\n                if branch.name.endswith(b"".first"") and branch._fClassName.startswith(b""pair<string,""):\n                    return asgenobj(SimpleArray(STLString(awkward)), branch._context, 6)\n\n                if branch.name.endswith(b"".second""):\n                    m = interpret._pairsecond.match(branch._fClassName)\n                    if m is not None:\n                        t, = m.groups()\n                        if t == b""vector<bool>"" or t == b""vector<Bool_t>"":\n                            return asgenobj(SimpleArray(STLVector(asdtype(awkward.numpy.bool_))), branch._context, 6)\n                        elif t == b""vector<char>"" or t == b""vector<Char_t>"":\n                            return asgenobj(SimpleArray(STLVector(asdtype(""i1""))), branch._context, 6)\n                        elif t == b""vector<unsigned char>"" or t == b""vector<UChar_t>"" or t == b""vector<Byte_t>"":\n                            return asgenobj(SimpleArray(STLVector(asdtype(""u1""))), branch._context, 6)\n                        elif t == b""vector<short>"" or t == b""vector<Short_t>"":\n                            return asgenobj(SimpleArray(STLVector(asdtype(""i2""))), branch._context, 6)\n                        elif t == b""vector<unsigned short>"" or t == b""vector<UShort_t>"":\n                            return asgenobj(SimpleArray(STLVector(asdtype(""u2""))), branch._context, 6)\n                        elif t == b""vector<int>"" or t == b""vector<Int_t>"":\n                            return asgenobj(SimpleArray(STLVector(asdtype(""i4""))), branch._context, 6)\n                        elif t == b""vector<unsigned int>"" or t == b""vector<UInt_t>"":\n                            return asgenobj(SimpleArray(STLVector(asdtype(""u4""))), branch._context, 6)\n                        elif t == b""vector<long>"" or t == b""vector<Long_t>"":\n                            return asgenobj(SimpleArray(STLVector(asdtype(""i8""))), branch._context, 6)\n                        elif t == b""vector<unsigned long>"" or t == b""vector<ULong64_t>"":\n                            return asgenobj(SimpleArray(STLVector(asdtype(""u8""))), branch._context, 6)\n                        elif t == b""vector<float>"" or t == b""vector<Float_t>"":\n                            return asgenobj(SimpleArray(STLVector(asdtype(""f4""))), branch._context, 6)\n                        elif t == b""vector<double>"" or t == b""vector<Double_t>"":\n                            return asgenobj(SimpleArray(STLVector(asdtype(""f8""))), branch._context, 6)\n                        elif t == b""vector<string>"":\n                            return asgenobj(SimpleArray(STLVector(STLString(awkward))), branch._context, 6)\n\n        return None\n\ninterpret._titlehasdims = re.compile(br""^([^\\[\\]]+)(\\[[^\\[\\]]+\\])+"")\ninterpret._itemdimpattern = re.compile(br""\\[([1-9][0-9]*)\\]"")\ninterpret._itemanypattern = re.compile(br""\\[(.*)\\]"")\ninterpret._vectorpointer = re.compile(br""vector\\<([^<>]*)\\*\\>"")\ninterpret._pairsecond = re.compile(br""pair\\<[^<>]*,(.*) \\>"")\n\nstreamer_aliases = [\n    (re.compile(b\'(ROOT::Math::(?:PositionVector3D|DisplacementVector3D)<ROOT::Math::Cartesian3D<(?:[^>,]+)>)\\\\s+(>)\'),\n        b\'\\\\1,ROOT::Math::DefaultCoordinateSystemTag\\\\2\'),\n]\n'"
uproot/interp/interp.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport awkward\n\nclass Interpretation(object):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (type,), {})\n\n    awkward = awkward\n\n    debug_reading = False\n\n    def awkwardlib(self, lib):\n        cls = type(self)\n        out = cls.__new__(cls)\n        out.__dict__.update(self.__dict__)\n        out.awkward = lib\n        return out\n\n    @property\n    def identifier(self):\n        raise NotImplementedError\n\n    @property\n    def type(self):\n        raise NotImplementedError   # awkward.type.Type\n\n    def empty(self):\n        raise NotImplementedError\n\n    def compatible(self, other):\n        raise NotImplementedError\n\n    def numitems(self, numbytes, numentries):\n        raise NotImplementedError\n\n    def source_numitems(self, source):\n        raise NotImplementedError\n\n    def fromroot(self, data, byteoffsets, local_entrystart, local_entrystop, keylen):\n        raise NotImplementedError\n\n    def destination(self, numitems, numentries):\n        raise NotImplementedError\n\n    def fill(self, source, destination, itemstart, itemstop, entrystart, entrystop):\n        raise NotImplementedError\n\n    def clip(self, destination, itemstart, itemstop, entrystart, entrystop):\n        raise NotImplementedError\n\n    def finalize(self, destination, branch):\n        raise NotImplementedError\n'"
uproot/interp/jagged.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport math\n\nimport uproot.interp.interp\nimport uproot.interp.numerical\n\nclass _JaggedArrayPrep(object):\n    def __init__(self, counts, content):\n        self.counts = counts\n        self.content = content\n\ndef _destructive_divide(array, divisor, awkward):\n    if divisor == 1:\n        pass\n    elif divisor == 2:\n        awkward.numpy.right_shift(array, 1, out=array)\n    elif divisor == 4:\n        awkward.numpy.right_shift(array, 2, out=array)\n    elif divisor == 8:\n        awkward.numpy.right_shift(array, 3, out=array)\n    else:\n        awkward.numpy.floor_divide(array, divisor, out=array)\n    return array\n\nclass asjagged(uproot.interp.interp.Interpretation):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (uproot.interp.interp.Interpretation.__metaclass__,), {})\n\n    def __init__(self, content, skipbytes=0):\n        self.content = content\n        self.skipbytes = skipbytes\n\n    def __repr__(self):\n        return ""asjagged({0}{1})"".format(repr(self.content), """" if self.skipbytes == 0 else "", {0}"".format(self.skipbytes))\n\n    def to(self, todtype=None, todims=None, skipbytes=None):\n        if skipbytes is None:\n            skipbytes = self.skipbytes\n        return asjagged(self.content.to(todtype, todims), skipbytes)\n\n    @property\n    def identifier(self):\n        return ""asjagged({0}{1})"".format(self.content.identifier, """" if self.skipbytes == 0 else "",{0}"".format(self.skipbytes))\n\n    @property\n    def type(self):\n        return self.awkward.type.ArrayType(self.awkward.numpy.inf, self.content.type)\n\n    def empty(self):\n        return self.awkward.JaggedArray(self.awkward.numpy.empty(0, dtype=self.awkward.JaggedArray.INDEXTYPE), self.awkward.numpy.empty(0, dtype=self.awkward.JaggedArray.INDEXTYPE), self.content.empty())\n\n    def compatible(self, other):\n        return isinstance(other, asjagged) and self.content.compatible(other.content)\n\n    def numitems(self, numbytes, numentries):\n        return self.content.numitems(numbytes - numentries * self.skipbytes, numentries)\n\n    def source_numitems(self, source):\n        return self.content.source_numitems(source.content)\n\n    def fromroot(self, data, byteoffsets, local_entrystart, local_entrystop, keylen):\n        if local_entrystart == local_entrystop:\n            return self.awkward.JaggedArray.fromoffsets([0], self.content.fromroot(data, None, local_entrystart, local_entrystop, keylen))\n        else:\n            if self.skipbytes == 0:\n                offsets = _destructive_divide(byteoffsets, self.content.itemsize, self.awkward)\n                starts  = offsets[local_entrystart     : local_entrystop    ]\n                stops   = offsets[local_entrystart + 1 : local_entrystop + 1]\n                content = self.content.fromroot(data, None, starts[0], stops[-1], keylen)\n                return self.awkward.JaggedArray(starts, stops, content)\n\n            else:\n                bytestarts = byteoffsets[local_entrystart     : local_entrystop    ] + self.skipbytes\n                bytestops  = byteoffsets[local_entrystart + 1 : local_entrystop + 1]\n\n                mask = self.awkward.numpy.zeros(len(data), dtype=self.awkward.numpy.int8)\n                mask[bytestarts[bytestarts < len(data)]] = 1\n                self.awkward.numpy.add.at(mask, bytestops[bytestops < len(data)], -1)\n                self.awkward.numpy.cumsum(mask, out=mask)\n                data = data[mask.view(self.awkward.numpy.bool_)]\n\n                content = self.content.fromroot(data, None, 0, bytestops[-1], keylen)\n\n                itemsize = 1\n                sub = self.content\n                while hasattr(sub, ""content""):\n                    sub = sub.content\n                if isinstance(sub, uproot.interp.numerical.asdtype):\n                    itemsize = sub.fromdtype.itemsize\n                if isinstance(sub, uproot.interp.numerical.asstlbitset):\n                    itemsize = sub.numbytes + 4\n\n                counts = bytestops - bytestarts\n                shift = math.log(itemsize, 2)\n                if shift == round(shift):\n                    self.awkward.numpy.right_shift(counts, int(shift), out=counts)\n                else:\n                    self.awkward.numpy.floor_divide(counts, itemsize, out=counts)\n\n                offsets = self.awkward.numpy.empty(len(counts) + 1, self.awkward.JaggedArray.INDEXTYPE)\n                offsets[0] = 0\n                self.awkward.numpy.cumsum(counts, out=offsets[1:])\n\n                return self.awkward.JaggedArray(offsets[:-1], offsets[1:], content)\n\n    def destination(self, numitems, numentries):\n        content = self.content.destination(numitems, numentries)\n        counts = self.awkward.numpy.empty(numentries, dtype=self.awkward.JaggedArray.INDEXTYPE)\n        return _JaggedArrayPrep(counts, content)\n\n    def fill(self, source, destination, itemstart, itemstop, entrystart, entrystop):\n        self.content.fill(source.content, destination.content, itemstart, itemstop, entrystart, entrystop)\n        destination.counts[entrystart:entrystop] = source.stops - source.starts\n\n    def clip(self, destination, itemstart, itemstop, entrystart, entrystop):\n        destination.content = self.content.clip(destination.content, itemstart, itemstop, entrystart, entrystop)\n        destination.counts = destination.counts[entrystart:entrystop]\n        return destination\n\n    def finalize(self, destination, branch):\n        content = self.content.finalize(destination.content, branch)\n        leafcount = None\n        if len(branch._fLeaves) == 1:\n            leafcount = branch._fLeaves[0]._fLeafCount\n\n        out = self.awkward.Methods.maybemixin(type(content), self.awkward.JaggedArray).fromcounts(destination.counts, content)\n        out.leafcount = leafcount\n        if self.debug_reading:\n            print(""reading {0}"".format(repr(out)))\n        return out\n'"
uproot/interp/numerical.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport sys\nimport numbers\nimport math\n\nimport numpy\n\nimport uproot.interp.interp\n\nif sys.version_info[0] <= 2:\n    string_types = (unicode, str)\nelse:\n    string_types = (str, bytes)\n\nBYTEORDER_INDICATORS = ("">"", ""<"", ""="", ""|"", b"">"", b""<"", b""="", b""|"")\n\n\ndef _dtypeshape(obj):\n    out = ()\n    while obj.subdtype is not None:\n        obj, shape = obj.subdtype\n        out = out + shape\n    return obj, out\n\ndef _flatlen(obj, awkward):\n    if isinstance(obj, awkward.numpy.dtype):\n        dtype, shape = _dtypeshape(obj)\n        return int(awkward.numpy.prod(shape))\n    else:\n        return int(awkward.numpy.prod(obj.shape))\n\nclass _asnumeric(uproot.interp.interp.Interpretation):\n    @property\n    def todtypeflat(self):\n        return _dtypeshape(self.todtype)[0]\n\n    @property\n    def todims(self):\n        return _dtypeshape(self.todtype)[1]\n\n    @property\n    def type(self):\n        dtype, shape = _dtypeshape(self.todtype)\n        if shape == ():\n            return dtype\n        else:\n            return self.awkward.type.ArrayType(*(shape + (dtype,)))\n\n    def empty(self):\n        return self.awkward.numpy.empty(0, self.todtype)\n\n    def source_numitems(self, source):\n        return _flatlen(source, self.awkward)\n\n    def destination(self, numitems, numentries):\n        quotient, remainder = divmod(numitems, _flatlen(self.todtype, self.awkward))\n        if remainder != 0:\n            raise ValueError(""cannot reshape {0} items as {1} (i.e. groups of {2})"".format(numitems, self.todtype.shape, _flatlen(self.todtype, self.awkward)))\n        return self.awkward.numpy.empty(quotient, dtype=self.todtype)\n\n    def fill(self, source, destination, itemstart, itemstop, entrystart, entrystop):\n        destination.reshape(-1)[itemstart:itemstop] = source.reshape(-1)\n\n    def clip(self, destination, itemstart, itemstop, entrystart, entrystop):\n        length = _flatlen(self.todtype, self.awkward)\n        startquotient, startremainder = divmod(itemstart, length)\n        stopquotient, stopremainder = divmod(itemstop, length)\n        assert startremainder == 0\n        assert stopremainder == 0\n        return destination[startquotient:stopquotient]\n        # FIXME: isn\'t the above equivalent to the following?\n        #     return destination[entrystart:entrystop]\n\n    def finalize(self, destination, branch):\n        if self.debug_reading:\n            print(""reading {0}"".format(repr(destination)))\n        return destination\n\nclass asdtype(_asnumeric):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (_asnumeric.__metaclass__,), {})\n\n    def __init__(self, fromdtype, todtype=None):\n        if isinstance(fromdtype, self.awkward.numpy.dtype):\n            self.fromdtype = fromdtype\n        elif isinstance(fromdtype, string_types) and len(fromdtype) > 0 and fromdtype[0] in BYTEORDER_INDICATORS:\n            self.fromdtype = self.awkward.numpy.dtype(fromdtype)\n        elif isinstance(fromdtype, list) and any(e[1][0] in BYTEORDER_INDICATORS for e in fromdtype):\n            self.fromdtype = self.awkward.numpy.dtype(fromdtype)\n        else:\n            self.fromdtype = self.awkward.numpy.dtype(fromdtype).newbyteorder("">"")\n\n        if todtype is None:\n            self.todtype = self.fromdtype.newbyteorder(""="")\n        elif isinstance(todtype, self.awkward.numpy.dtype):\n            self.todtype = todtype\n        elif isinstance(todtype, string_types) and len(todtype) > 0 and todtype[0] in BYTEORDER_INDICATORS:\n            self.todtype = self.awkward.numpy.dtype(todtype)\n        elif isinstance(todtype, list) and any(e[1][0] in BYTEORDER_INDICATORS for e in todtype):\n            self.todtype = self.awkward.numpy.dtype(todtype)\n        else:\n            self.todtype = self.awkward.numpy.dtype(todtype).newbyteorder(""="")\n\n    @property\n    def itemsize(self):\n        return self.fromdtype.itemsize\n\n    def to(self, todtype=None, todims=None):\n        if todtype is None:\n            dtype, shape = _dtypeshape(self.todtype)\n            if todims is not None:\n                shape = todims\n        else:\n            dtype, shape = _dtypeshape(todtype)\n            if todims is not None:\n                shape = todims + shape\n\n        return asdtype(self.fromdtype, self.awkward.numpy.dtype((dtype, shape)))\n\n    def toarray(self, array):\n        return asarray(self.fromdtype, array)\n\n    def __repr__(self):\n        args = [repr(str(self.fromdtype))]\n        if self.fromdtype.newbyteorder("">"") != self.todtype.newbyteorder("">""):\n            args.append(repr(str(self.todtype)))\n        return ""asdtype({0})"".format("", "".join(args))\n\n    @property\n    def identifier(self):\n        _byteorder = {""!"": ""B"", "">"": ""B"", ""<"": ""L"", ""|"": ""L"", ""="": ""B"" if self.awkward.numpy.dtype("">f8"").isnative else ""L""}\n        def form(dt, n):\n            dtype, shape = _dtypeshape(dt)\n            return ""{0}{1}{2}({3}{4})"".format(_byteorder[dtype.byteorder], dtype.kind, dtype.itemsize, "","".join(repr(x) for x in shape), n)\n\n        if self.fromdtype.names is None:\n            fromdtype = form(self.fromdtype, """")\n        else:\n            fromdtype = ""["" + "","".join(form(self.fromdtype[n], "","" + repr(n)) for n in self.fromdtype.names) + ""]""\n\n        if self.todtype.names is None:\n            todtype = form(self.todtype, """")\n        else:\n            todtype = ""["" + "","".join(form(self.todtype[n], "","" + repr(n)) for n in self.todtype.names) + ""]""\n\n        return ""asdtype({0},{1})"".format(fromdtype, todtype)\n\n    def compatible(self, other):\n        return isinstance(other, asdtype) and self.todtype == other.todtype\n\n    def numitems(self, numbytes, numentries):\n        dtype, shape = _dtypeshape(self.fromdtype)\n        quotient, remainder = divmod(numbytes, dtype.itemsize)\n        assert remainder == 0\n        return quotient\n\n    def fromroot(self, data, byteoffsets, local_entrystart, local_entrystop, keylen):\n        dtype, shape = _dtypeshape(self.fromdtype)\n        return data.view(dtype).reshape((-1,) + shape)[local_entrystart:local_entrystop]\n\nclass asarray(asdtype):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (asdtype.__metaclass__,), {})\n\n    def __init__(self, fromdtype, toarray):\n        if isinstance(fromdtype, self.awkward.numpy.dtype):\n            self.fromdtype = fromdtype\n        elif isinstance(fromdtype, string_types) and len(fromdtype) > 0 and fromdtype[0] in ("">"", ""<"", ""="", ""|"", b"">"", b""<"", b""="", b""|""):\n            self.fromdtype = self.awkward.numpy.dtype(fromdtype)\n        else:\n            self.fromdtype = self.awkward.numpy.dtype(fromdtype).newbyteorder("">"")\n        self.toarray = toarray\n\n    @property\n    def todtype(self):\n        return self.awkward.numpy.dtype((self.toarray.dtype, self.toarray.shape[1:]))\n\n    def __repr__(self):\n        return ""asarray({0}, <array {1} {2} at 0x{3:012x}>)"".format(repr(str(self.fromdtype)), self.toarray.dtype, self.toarray.shape, id(self.toarray))\n\n    @property\n    def identifier(self):\n        return ""asarray"" + super(asarray, self).identifier[7:]\n\n    def destination(self, numitems, numentries):\n        quotient, remainder = divmod(numitems, _flatlen(self.todtype, self.awkward))\n        if remainder != 0:\n            raise ValueError(""cannot reshape {0} items as {1} (i.e. groups of {2})"".format(numitems, self.todtype.shape, _flatlen(self.todtype, self.awkward)))\n        if _flatlen(self.toarray, self.awkward) < numitems:\n            raise ValueError(""cannot put {0} items into an array of {1} items"".format(numitems, _flatlen(self.toarray, self.awkward)))\n        return self.toarray, quotient\n\n    def fill(self, source, destination, itemstart, itemstop, entrystart, entrystop):\n        array, stop = destination\n        super(asarray, self).fill(source, array, itemstart, itemstop, entrystart, entrystop)\n\n    def clip(self, destination, itemstart, itemstop, entrystart, entrystop):\n        array, stop = destination\n        return super(asarray, self).clip(array, itemstart, itemstop, entrystart, entrystop), stop\n\n    def finalize(self, destination, branch):\n        array, stop = destination\n        out = array[:stop]\n        if self.debug_reading:\n            print(""reading {0}"".format(repr(out)))\n        return out\n\nclass asdouble32(_asnumeric):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (_asnumeric.__metaclass__,), {})\n\n    def __init__(self, low, high, numbits, fromdims=(), todims=None):\n        if not isinstance(numbits, (numbers.Integral, numpy.integer)) or not 2 <= numbits <= 32:\n            raise TypeError(""numbits must be an integer between 2 and 32 (inclusive)"")\n        self.truncated = low == 0.0 and high == 0.0\n        if high <= low and not self.truncated:\n            raise ValueError(""high ({0}) must be strictly greater than low ({1})"".format(high, low))\n\n        self.low = low\n        self.high = high\n        self.numbits = numbits\n\n        self.fromdims = fromdims\n\n        if todims is None:\n            self._todims = todims\n        else:\n            self._todims = fromdims\n\n    @property\n    def todtype(self):\n        return self.awkward.numpy.dtype((self.awkward.numpy.float64, self.todims))\n\n    @property\n    def fromdtype(self):\n        if self.truncated:\n            return self.awkward.numpy.dtype(({\'exponent\': (\'>u1\', 0), \'mantissa\': (\'>u2\', 1)}, self.fromdims))\n        else:\n            return self.awkward.numpy.dtype((\'>u4\', self.fromdims))\n\n    @property\n    def fromdtypeflat(self):\n        return _dtypeshape(self.fromdtype)[0]\n\n    @property\n    def todims(self):\n        if self._todims is None:\n            return self.fromdims\n        else:\n            return self._todims\n\n    @property\n    def itemsize(self):\n        return self.fromdtype.itemsize\n\n    def __repr__(self):\n        args = [repr(self.low), repr(self.high), repr(self.numbits), repr(self.fromdtype), repr(self.todtype)]\n        return ""asdouble32("" + "", "".join(args) + "")""\n\n    @property\n    def identifier(self):\n        fromdims = ""("" + "","".join(repr(x) for x in self.fromdims) + "")""\n        todims = ""("" + "","".join(repr(x) for x in self.todims) + "")""\n        return ""asdouble32({0},{1},{2},{3},{4})"".format(self.low, self.high, self.numbits, fromdims, todims)\n\n    def compatible(self, other):\n        return isinstance(other, asdouble32) and self.low == other.low and self.high == other.high and self.numbits == other.numbits and self.fromdtype == other.fromdtype and self.todtype == other.todtype\n\n    def numitems(self, numbytes, numentries):\n        quotient, remainder = divmod(numbytes, self.fromdtypeflat.itemsize)\n        assert remainder == 0\n        return quotient\n\n    def fromroot(self, data, byteoffsets, local_entrystart, local_entrystop, keylen):\n        # Interpret input data using proper type\n        array = data.view(dtype=self.fromdtypeflat)\n        # Make sure the interpreted data has correct shape\n        if self.fromdims != ():\n            product = int(self.awkward.numpy.prod(self.fromdims))\n            quotient, remainder = divmod(len(array), product)\n            assert remainder == 0, ""{0} % {1} == {2} != 0"".format(len(array), product, len(array) % product)\n            array = array.reshape((quotient,) + self.fromdims)\n\n        if self.truncated:\n            array = array[local_entrystart:local_entrystop]\n            # We have to make copies to work with contiguous arrays\n            unpacked = array[\'exponent\'].astype(self.awkward.numpy.int32)\n            mantissa = array[\'mantissa\'].astype(self.awkward.numpy.int32)\n\n            unpacked <<= 23\n            unpacked |= (mantissa & ((1 << (self.numbits + 1)) - 1)) << (23 - self.numbits)\n            sign = ((1 << (self.numbits + 1)) & mantissa != 0) * -2 + 1\n\n            array = unpacked.view(dtype=self.awkward.numpy.float32) * sign\n            array = array.astype(self.todtypeflat)\n        else:\n            array = array[local_entrystart:local_entrystop].astype(self.todtypeflat)\n            self.awkward.numpy.multiply(array, float(self.high - self.low) / (1 << self.numbits), out=array)\n            self.awkward.numpy.add(array, self.low, out=array)\n\n        return array\n\nclass asfloat16(asdouble32):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (asdouble32.__metaclass__,), {})\n\n    def __init__(self, low, high, numbits, fromdims=(), todims=None):\n        super(asfloat16, self).__init__(low, high, numbits, fromdims, todims)\n        if self.truncated and not 2 <= numbits <= 16:\n            raise TypeError(""numbits must be an integer between 2 and 16 (inclusive)."")\n\n    @property\n    def todtype(self):\n        return self.awkward.numpy.dtype((self.awkward.numpy.float32, self.todims))\n\n    def __repr__(self):\n        args = [repr(self.low), repr(self.high), repr(self.numbits), repr(self.fromdtype), repr(self.todtype)]\n        return ""asfloat16("" + "", "".join(args) + "")""\n\n    @property\n    def identifier(self):\n        fromdims = ""("" + "","".join(repr(x) for x in self.fromdims) + "")""\n        todims = ""("" + "","".join(repr(x) for x in self.todims) + "")""\n        return ""asfloat16({0},{1},{2},{3},{4})"".format(self.low, self.high, self.numbits, fromdims, todims)\n\n    def compatible(self, other):\n        return isinstance(other, asfloat16) and self.low == other.low and self.high == other.high and self.numbits == other.numbits and self.fromdtype == other.fromdtype and self.todtype == other.todtype\n\nclass asstlbitset(uproot.interp.interp.Interpretation):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (uproot.interp.interp.Interpretation.__metaclass__,), {})\n\n    @property\n    def todtype(self):\n        return self.awkward.numpy.dtype(self.awkward.numpy.bool_)\n\n    def __init__(self, numbytes):\n        self.numbytes = numbytes\n\n    def __repr__(self):\n        return self.identifier\n\n    @property\n    def identifier(self):\n        return ""asstlbitset({0})"".format(self.numbytes)\n\n    @property\n    def type(self):\n        return self.awkward.type.ArrayType(self.numbytes, self.todtype)\n\n    def empty(self):\n        return self.awkward.numpy.empty((0, self.numbytes), dtype=self.todtype)\n\n    def compatible(self, other):\n        return (isinstance(other, asstlbitset) and self.numbytes == other.numbytes) or \\\n               (isinstance(other, (asdtype, asarray)) and self.todtype == other.todtype and (self.numbytes,) == other.todims)\n\n    def numitems(self, numbytes, numentries):\n        return max(0, numbytes // (self.numbytes + 4))\n\n    def source_numitems(self, source):\n        return int(self.awkward.numpy.prod(source.shape))\n\n    def fromroot(self, data, byteoffsets, local_entrystart, local_entrystop, keylen):\n        return data.view(self.todtype).reshape((-1, self.numbytes + 4))[:, 4:]\n\n    def destination(self, numitems, numentries):\n        return self.awkward.numpy.empty((numitems, self.numbytes), dtype=self.todtype)\n\n    def fill(self, source, destination, itemstart, itemstop, entrystart, entrystop):\n        destination[itemstart:itemstop] = source\n\n    def clip(self, destination, itemstart, itemstop, entrystart, entrystop):\n        return destination[itemstart:itemstop]\n\n    def finalize(self, destination, branch):\n        if self.debug_reading:\n            print(""reading {0}"".format(repr(destination)))\n        return destination\n'"
uproot/interp/objects.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport copy\nimport struct\nimport numbers\n\nimport numpy\n\nimport uproot.rootio\nimport uproot.interp.interp\nimport uproot.interp.numerical\nimport uproot.interp.jagged\n\nclass SimpleArray(object):\n    def __init__(self, cls):\n        self.cls = cls\n\n    @property\n    def __name__(self):\n        return ""SimpleArray""\n\n    def __repr__(self):\n        if isinstance(self.cls, type):\n            return ""SimpleArray({0})"".format(self.cls.__name__)\n        else:\n            return ""SimpleArray({0})"".format(repr(self.cls))\n\n    def read(self, source, cursor, context, parent):\n        out = []\n        while True:\n            if hasattr(source, ""_source"") and cursor.index >= len(source._source):\n                return out\n            try:\n                out.append(self.cls.read(source, cursor, context, parent))\n            except IndexError:\n                return out\n\nclass STLVector(object):\n    def __init__(self, cls):\n        self.cls = cls\n\n    @property\n    def __name__(self):\n        return ""STLVector""\n\n    def __repr__(self):\n        if isinstance(self.cls, type):\n            return ""STLVector({0})"".format(self.cls.__name__)\n        else:\n            return ""STLVector({0})"".format(repr(self.cls))\n\n    _format1 = struct.Struct("">i"")\n\n    def read(self, source, cursor, context, parent):\n        if hasattr(source, ""_source"") and len(source._source) == 0:\n            return []\n        numitems = cursor.field(source, self._format1)\n        if isinstance(self.cls, uproot.interp.numerical.asdtype):\n            out = cursor.array(source, numitems, self.cls.fromdtype)\n            if out.dtype != self.cls.todtype:\n                out = out.astype(self.cls.todtype)\n            return list(out)\n        else:\n            out = [None] * numitems\n            for i in range(numitems):\n                out[i] = self.cls.read(source, cursor, context, parent)\n            return out\n\nclass STLMap(object):\n    def __init__(self, keycls, valcls):\n        self.keycls = keycls\n        self.valcls = valcls\n\n    @property\n    def __name__(self):\n        return ""STLMap""\n\n    def __repr__(self):\n        key = self.keycls.__name__ if isinstance(self.keycls, type) else repr(self.keycls)\n        val = self.valcls.__name__ if isinstance(self.valcls, type) else repr(self.valcls)\n        return ""STLMap({0}, {1})"".format(key, val)\n\n    _format1 = struct.Struct("">i"")\n\n    def read(self, source, cursor, context, parent):\n        numitems = cursor.field(source, self._format1)\n\n        out = {}\n        for i in range(numitems):\n            if isinstance(self.keycls, uproot.interp.numerical.asdtype):\n                key = cursor.array(source, 1, self.keycls.fromdtype)\n                if key.dtype != self.keycls.todtype:\n                    key = key.astype(self.keycls.todtype)\n                key = key[0]\n            else:\n                key = self.keycls.read(source, cursor, context, parent)\n\n            if isinstance(self.valcls, uproot.interp.numerical.asdtype):\n                val = cursor.array(source, 1, self.valcls.fromdtype)\n                if val.dtype != self.valcls.todtype:\n                    val = val.astype(self.valcls.todtype)\n                val = val[0]\n            else:\n                val = self.valcls.read(source, cursor, context, parent)\n\n            out[key] = val\n\n        return out\n\nclass STLString(object):\n    def __init__(self, awkward=None):\n        if awkward is None:\n            awkward = uproot.interp.interp.Interpretation.awkward\n        self.awkward = awkward\n\n    @property\n    def __name__(self):\n        return ""STLString""\n\n    def __repr__(self):\n        return ""STLString()""\n\n    _format1 = struct.Struct(""B"")\n    _format2 = struct.Struct("">i"")\n\n    def read(self, source, cursor, context, parent):\n        numitems = cursor.field(source, self._format1)\n        if numitems == 255:\n            numitems = cursor.field(source, self._format2)\n        return cursor.array(source, numitems, self.awkward.ObjectArray.CHARTYPE).tostring()\n\nclass Pointer(object):\n    def __init__(self, cls):\n        self.cls = cls\n\n    @property\n    def __name__(self):\n        return ""Pointer""\n\n    def __repr__(self):\n        if isinstance(self.cls, type):\n            return ""Pointer({0})"".format(self.cls.__name__)\n        else:\n            return ""Pointer({0})"".format(repr(self.cls))\n\n    def read(self, source, cursor, context, parent):\n        return uproot.rootio._readobjany(source, cursor, context, parent)\n\n    _format1 = struct.Struct("">II"")\n\nclass astable(uproot.interp.interp.Interpretation):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (uproot.interp.interp.Interpretation.__metaclass__,), {})\n\n    def __init__(self, content):\n        if not isinstance(content, uproot.interp.numerical.asdtype) or content.todtype.names is None or len(content.todtype.names) == 0:\n            raise TypeError(""astable must be given a recarray dtype"")\n        self.content = content\n\n    @property\n    def itemsize(self):\n        return self.content.itemsize\n\n    def __repr__(self):\n        dtype, shape = uproot.interp.numerical._dtypeshape(self.content.todtype)\n        return ""astable({0})"".format(repr(self.content.to(self.awkward.util.numpy.dtype([(n, dtype[n]) for n in dtype.names if not n.startswith("" "")]), shape)))\n\n    def tonumpy(self):\n        return self.content\n\n    @property\n    def identifier(self):\n        dtype, shape = uproot.interp.numerical._dtypeshape(self.content.todtype)\n        return ""astable({0})"".format(self.content.identifier)\n\n    @property\n    def type(self):\n        dtype, shape = uproot.interp.numerical._dtypeshape(self.content.todtype)\n        fields = None\n        for n in dtype.names:\n            if fields is None:\n                fields = self.awkward.type.ArrayType(n, dtype[n])\n            else:\n                fields = fields & self.awkward.type.ArrayType(n, dtype[n])\n        if shape == ():\n            return fields\n        else:\n            return self.awkward.type.ArrayType(*(shape + (fields,)))\n\n    def empty(self):\n        return self.awkward.Table.fromrec(self.content.empty())\n\n    def compatible(self, other):\n        return isinstance(other, astable) and self.content.compatible(other.content)\n\n    def numitems(self, numbytes, numentries):\n        return self.content.numitems(numbytes, numentries)\n\n    def source_numitems(self, source):\n        return self.content.source_numitems(source)\n\n    def fromroot(self, data, byteoffsets, local_entrystart, local_entrystop, keylen):\n        return self.content.fromroot(data, byteoffsets, local_entrystart, local_entrystop, keylen)\n\n    def destination(self, numitems, numentries):\n        return self.content.destination(numitems, numentries)\n\n    def fill(self, source, destination, itemstart, itemstop, entrystart, entrystop):\n        return self.content.fill(source, destination, itemstart, itemstop, entrystart, entrystop)\n\n    def clip(self, destination, itemstart, itemstop, entrystart, entrystop):\n        return self.content.clip(destination, itemstart, itemstop, entrystart, entrystop)\n\n    def finalize(self, destination, branch):\n        out = self.awkward.Table.fromrec(self.content.finalize(destination, branch))\n        if self.debug_reading:\n            print(""reading {0}"".format(repr(out)))\n        return out\n\nclass asobj(uproot.interp.interp.Interpretation):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (uproot.interp.interp.Interpretation.__metaclass__,), {})\n\n    def __init__(self, content, cls):\n        self.content = content\n        self.cls = cls\n\n    @property\n    def itemsize(self):\n        return self.content.itemsize\n\n    def __repr__(self):\n        return ""asobj(<{0}.{1}>)"".format(self.cls.__module__, self.cls.__name__)\n\n    @property\n    def identifier(self):\n        return ""asobj({0},{1}.{2})"".format(self.content.identifier, self.cls.__module__, self.cls.__name__)\n\n    @property\n    def type(self):\n        return self.cls\n\n    def empty(self):\n        return self.content.empty()\n\n    def compatible(self, other):\n        return isinstance(other, asobj) and self.cls.__name__ == other.cls.__name__\n\n    def numitems(self, numbytes, numentries):\n        return self.content.numitems(numbytes, numentries)\n\n    def source_numitems(self, source):\n        return self.content.source_numitems(source)\n\n    def fromroot(self, data, byteoffsets, local_entrystart, local_entrystop, keylen):\n        return self.content.fromroot(data, byteoffsets, local_entrystart, local_entrystop, keylen)\n\n    def destination(self, numitems, numentries):\n        return self.content.destination(numitems, numentries)\n\n    def fill(self, source, destination, itemstart, itemstop, entrystart, entrystop):\n        return self.content.fill(source, destination, itemstart, itemstop, entrystart, entrystop)\n\n    def clip(self, destination, itemstart, itemstop, entrystart, entrystop):\n        return self.content.clip(destination, itemstart, itemstop, entrystart, entrystop)\n\n    def finalize(self, destination, branch):\n        if self.cls._arraymethods is None:\n            out = self.awkward.ObjectArray(self.content.finalize(destination, branch), self.cls._fromrow)\n        else:\n            cls = self.awkward.Methods.mixin(self.cls._arraymethods, self.awkward.ObjectArray)\n            out = cls.__new__(cls)\n            out._initObjectArray(self.content.finalize(destination, branch))\n        if self.debug_reading:\n            print(""reading {0}"".format(repr(out)))\n        return out\n\nclass _variable(uproot.interp.interp.Interpretation):\n    def __init__(self, content, generator, *args, **kwargs):\n        self.content = content\n        self.generator = generator\n        self.args = args\n        self.kwargs = kwargs\n\n    def __repr__(self):\n        return ""_variable({0}, {1}{2}{3})"".format(repr(self.content), self.generator, """".join("", "" + repr(x) for x in self.args), """".join("", {0}={1}"".format(n, repr(x)) for n, x in self.kwargs.items()))\n\n    @property\n    def identifier(self):\n        return ""_variable({0},{1}{2}{3})"".format(self.content.identifier, self.generator, """".join("","" + repr(x) for x in self.args), """".join("",{0}={1}"".format(n, repr(self.kwargs[n])) for n in sorted(self.kwargs)))\n\n    @property\n    def type(self):\n        return self.generator\n\n    def empty(self):\n        return self.awkward.ObjectArray(self.content.empty(), self.generator, *self.args, **self.kwargs)\n\n    def compatible(self, other):\n        return isinstance(other, _variable) and self.content.compatible(other) and self.generator == other.generator and self.args == other.args and self.kwargs == other.kwargs\n\n    def numitems(self, numbytes, numentries):\n        return self.content.numitems(numbytes, numentries)\n\n    def source_numitems(self, source):\n        return self.content.source_numitems(source)\n\n    def fromroot(self, data, byteoffsets, local_entrystart, local_entrystop, keylen):\n        return self.content.fromroot(data, byteoffsets, local_entrystart, local_entrystop, keylen)\n\n    def destination(self, numitems, numentries):\n        return self.content.destination(numitems, numentries)\n\n    def fill(self, source, destination, itemstart, itemstop, entrystart, entrystop):\n        self.content.fill(source, destination, itemstart, itemstop, entrystart, entrystop)\n\n    def clip(self, destination, itemstart, itemstop, entrystart, entrystop):\n        return self.content.clip(destination, itemstart, itemstop, entrystart, entrystop)\n\n    def finalize(self, destination, branch):\n        out = self.awkward.ObjectArray(self.content.finalize(destination, branch), self.generator, *self.args, **self.kwargs)\n        if self.debug_reading:\n            print(""reading {0}"".format(repr(out)))\n        return out\n\nclass _variable_withoffsets(_variable):\n    def fromroot(self, data, byteoffsets, local_entrystart, local_entrystop, keylen):\n        out = self.content.fromroot(data, byteoffsets, local_entrystart, local_entrystop, keylen)\n        out.byteoffsets = byteoffsets[local_entrystart:local_entrystop] + keylen + self.content.skipbytes\n        return out\n\n    def destination(self, numitems, numentries):\n        out = self.content.destination(numitems, numentries)\n        out.byteoffsets = self.awkward.numpy.empty(numentries, dtype=self.awkward.numpy.int32)\n        return out\n\n    def fill(self, source, destination, itemstart, itemstop, entrystart, entrystop):\n        self.content.fill(source, destination, itemstart, itemstop, entrystart, entrystop)\n        destination.byteoffsets[entrystart:entrystop] = source.byteoffsets\n\n    def clip(self, destination, itemstart, itemstop, entrystart, entrystop):\n        out = self.content.clip(destination, itemstart, itemstop, entrystart, entrystop)\n        out.byteoffsets = destination.byteoffsets[entrystart:entrystop]\n        return out\n\n    def finalize(self, destination, branch):\n        out = self.awkward.ObjectArray(JaggedWithByteOffsets(self.content.finalize(destination, branch), destination.byteoffsets), self.generator, *self.args, **self.kwargs)\n        if self.debug_reading:\n            print(""reading {0}"".format(repr(out)))\n        return out\n\nclass JaggedWithByteOffsets(object):\n    def __init__(self, jagged, byteoffsets):\n        self.jagged = jagged\n        self.byteoffsets = byteoffsets\n\n    def __len__(self):\n        return len(self.jagged)\n\n    def __getitem__(self, where):\n        return self.jagged[where], -self.byteoffsets[where]\n\nclass asgenobj(_variable_withoffsets):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (_variable.__metaclass__,), {})\n\n    class _Wrapper(object):\n        def __init__(self, cls, context):\n            self.cls = cls\n            self.context = context\n        def __call__(self, arg):\n            bytes, origin = arg\n            source = uproot.source.source.Source(bytes)\n            cursor = uproot.source.cursor.Cursor(0, origin=origin)\n            return self.cls.read(source, cursor, self.context, None)\n        def __repr__(self):\n            if isinstance(self.cls, type):\n                return self.cls.__name__\n            else:\n                return repr(self.cls)\n\n    def __init__(self, cls, context, skipbytes):\n        super(asgenobj, self).__init__(uproot.interp.jagged.asjagged(uproot.interp.numerical.asdtype(self.awkward.ObjectArray.CHARTYPE), skipbytes=skipbytes), asgenobj._Wrapper(cls, context))\n\n    def speedbump(self, value):\n        out = copy.copy(self)\n        out.generator = copy.copy(self.generator)\n        out.generator.context = copy.copy(out.generator.context)\n        out.generator.context.speedbump = value\n        return out\n\n    def compatible(self, other):\n        return isinstance(other, asgenobj) and self.generator.cls.__name__ == other.generator.cls.__name__\n\n    def __repr__(self):\n        return ""asgenobj({0})"".format(self.generator)\n\nclass asstring(_variable):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (_variable.__metaclass__,), {})\n\n    def __init__(self, skipbytes=1):\n        super(asstring, self).__init__(uproot.interp.jagged.asjagged(uproot.interp.numerical.asdtype(self.awkward.ObjectArray.CHARTYPE), skipbytes=skipbytes), lambda array: array.tostring())\n\n    def __repr__(self):\n        return ""asstring({0})"".format("""" if self.content.skipbytes == 1 else repr(self.content.skipbytes))\n    @property\n    def identifier(self):\n        return ""asstring({0})"".format("""" if self.content.skipbytes == 1 else repr(self.content.skipbytes))\n\n    def compatible(self, other):\n        return isinstance(other, asstring)\n'"
uproot/source/__init__.py,0,b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import'
uproot/source/chunked.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport math\n\nimport numpy\n\nimport uproot.cache\nimport uproot.source.source\n\n\nclass ChunkedSource(uproot.source.source.Source):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (uproot.source.source.Source.__metaclass__,), {})\n\n    def __init__(self, path, chunkbytes, limitbytes, parallel):\n        from uproot.rootio import _memsize\n        m = _memsize(chunkbytes)\n        if m is not None:\n            chunkbytes = int(math.ceil(m))\n        m = _memsize(limitbytes)\n        if m is not None:\n            limitbytes = int(math.ceil(m))\n        self.path = path\n        self._chunkbytes = chunkbytes\n        self._limitbytes = limitbytes\n        if limitbytes is None:\n            self.cache = {}\n        else:\n            self.cache = uproot.cache.ThreadSafeArrayCache(limitbytes)\n        self._source = None\n        self._setup_futures(parallel)\n\n    def parent(self):\n        return self\n\n    def threadlocal(self):\n        return self\n\n    def __del__(self):\n        self.dismiss()\n\n    def _read(self, chunkindex):\n        raise NotImplementedError\n\n    def close(self):\n        super(ChunkedSource, self).close()\n        self.cache.clear()\n\n    def dismiss(self):\n        if self._futures is not None:\n            for future in self._futures.values():\n                future.cancel()\n            self._futures = {}\n\n    def _setup_futures(self, parallel):\n        if parallel is not None and parallel > 1:\n            try:\n                import concurrent.futures\n            except ImportError:\n                raise ImportError(""Install futures package (for parallel > 1) with:\\n    pip install futures\\nor\\n    conda install -c conda-forge futures"")\n            self._executor = concurrent.futures.ThreadPoolExecutor(parallel)\n            self._futures = {}\n        else:\n            self._executor = None\n            self._futures = None\n\n    def _preload(self, chunkindex):\n        try:\n            chunk = self.cache[chunkindex]\n        except KeyError:\n            return self._read(chunkindex)\n        else:\n            return chunk\n\n    def preload(self, starts):\n        self._open()\n        limitnum = self._limitbytes // self._chunkbytes\n        if self._executor is not None:\n            for start in starts:\n                if len(self._futures) > limitnum:\n                    break\n                chunkindex = start // self._chunkbytes\n                if chunkindex not in self._futures:\n                    self._futures[chunkindex] = self._executor.submit(self._preload, chunkindex)\n\n    def data(self, start, stop, dtype=None):\n        if dtype is None:\n            thedtype = numpy.dtype(numpy.uint8)\n        else:\n            thedtype = dtype\n\n        # assert start >= 0\n        # assert stop >= 0\n        # assert stop >= start\n\n        chunkstart = start // self._chunkbytes\n        if stop % self._chunkbytes == 0:\n            chunkstop = stop // self._chunkbytes\n        else:\n            chunkstop = stop // self._chunkbytes + 1\n\n        out = numpy.empty((stop - start) // thedtype.itemsize, dtype=thedtype)\n\n        for chunkindex in range(chunkstart, chunkstop):\n            chunk = None\n            if self._futures is not None:\n                future = self._futures.pop(chunkindex, None)\n                if future is not None:\n                    chunk = future.result()\n\n            if chunk is None:\n                try:\n                    chunk = self.cache[chunkindex]\n                except KeyError:\n                    self._open()\n                    chunk = self._read(chunkindex)\n\n            cstart = 0\n            cstop = self._chunkbytes\n            gstart = chunkindex * self._chunkbytes\n            gstop = (chunkindex + 1) * self._chunkbytes\n\n            if len(chunk) > self._chunkbytes:\n                if not numpy.array_equal(chunk[:4], list(b""root"")):\n                    raise NotImplementedError(""Expected {0} or fewer bytes but received {1} and data does not appear to be an entire ROOT file."".format(self._chunkbytes, len(chunk)))\n                self.cache = {}\n                for i in range(0, len(chunk), self._chunkbytes):\n                    self.cache[i // self._chunkbytes] = chunk[i:i+self._chunkbytes]\n                chunk = self.cache[chunkindex]\n                # Dismiss any pending futures as everything has already been loaded\n                self.dismiss()\n            else:\n                self.cache[chunkindex] = chunk\n\n            if gstart < start:\n                cstart += start - gstart\n                gstart += start - gstart\n            if gstop > stop:\n                cstop -= gstop - stop\n                gstop -= gstop - stop\n\n            if cstop - cstart > len(chunk):\n                raise IndexError(""indexes {0}:{1} are beyond the end of data source {2}"".format(gstart + len(chunk), stop, repr(self.path)))\n\n            if dtype is None:\n                out[gstart - start : gstop - start] = chunk[cstart:cstop]\n            else:\n                out.view(numpy.uint8)[gstart - start : gstop - start] = chunk[cstart:cstop]\n\n        return out\n'"
uproot/source/compressed.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport struct\nfrom copy import copy\n\nimport numpy\n\nimport uproot.const\nimport uproot.source.source\n\nclass Compression(object):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (type,), {})\n\n    def __init__(self, fCompress):\n        self.algo = max(fCompress // 100, uproot.const.kZLIB)\n        self.level = fCompress % 100\n        if not uproot.const.kZLIB <= self.algo < uproot.const.kUndefinedCompressionAlgorithm:\n            raise ValueError(""unrecognized compression algorithm: {0} (from fCompress {1})"".format(self.algo, fCompress))\n        if not 0 <= self.level <= 9:\n            raise ValueError(""unrecognized compression level: {0} (from fCompress {1})"".format(self.level, fCompress))\n\n    def copy(self, algo=None, level=None):\n        out = Compression.__new__(Compression)\n        if algo is None:\n            out.algo = self.algo\n        else:\n            out.algo = algo\n        if level is None:\n            out.level = self.level\n        else:\n            out.level = level\n        return out\n\n    @property\n    def algoname(self):\n        if self.algo == uproot.const.kZLIB:\n            return ""zlib""\n        elif self.algo == uproot.const.kLZMA:\n            return ""lzma""\n        elif self.algo == uproot.const.kOldCompressionAlgo:\n            return ""old""\n        elif self.algo == uproot.const.kLZ4:\n            return ""lz4""\n        elif self.algo == uproot.const.kZSTD:\n            return ""zstd""\n        else:\n            raise ValueError(""unrecognized compression algorithm: {0}"".format(self.algo))\n\n    def __repr__(self):\n        return ""<Compression {0} {1}>"".format(repr(self.algoname), self.level)\n\n    def decompress(self, source, cursor, compressedbytes, uncompressedbytes=None):\n        if self.algo == uproot.const.kZLIB:\n            from zlib import decompress as zlib_decompress\n            return zlib_decompress(cursor.bytes(source, compressedbytes))\n\n        elif self.algo == uproot.const.kLZMA:\n            try:\n                from lzma import decompress as lzma_decompress\n            except ImportError:\n                try:\n                    from backports.lzma import decompress as lzma_decompress\n                except ImportError:\n                    raise ImportError(""install lzma package with:\\n    pip install backports.lzma\\nor\\n    conda install backports.lzma\\n(or just use Python >= 3.3)."")\n            return lzma_decompress(cursor.bytes(source, compressedbytes))\n\n        elif self.algo == uproot.const.kOldCompressionAlgo:\n            raise NotImplementedError(""ROOT\'s \\""old\\"" algorithm (fCompress 300) is not supported"")\n\n        elif self.algo == uproot.const.kLZ4:\n            try:\n                from lz4.block import decompress as lz4_decompress\n            except ImportError:\n                raise ImportError(""install lz4 package with:\\n    pip install lz4\\nor\\n    conda install lz4"")\n\n            if uncompressedbytes is None:\n                raise ValueError(""lz4 needs to know the uncompressed number of bytes"")\n            return lz4_decompress(cursor.bytes(source, compressedbytes), uncompressed_size=uncompressedbytes)\n\n        elif self.algo == uproot.const.kZSTD:\n            try:\n                import zstandard as zstd\n            except ImportError:\n                raise ImportError(""install zstd package with:\\n    pip install zstandard\\nor\\n    conda install zstandard"")\n            dctx = zstd.ZstdDecompressor()\n            return dctx.decompress(cursor.bytes(source, compressedbytes))\n\n        else:\n            raise ValueError(""unrecognized compression algorithm: {0}"".format(self.algo))\n\nclass CompressedSource(uproot.source.source.Source):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (uproot.source.source.Source.__metaclass__,), {})\n\n    def __init__(self, compression, source, cursor, compressedbytes, uncompressedbytes):\n        self.compression = compression\n        self._compressed = source\n        self._uncompressed = None\n        self._cursor = cursor\n        self._compressedbytes = compressedbytes\n        self._uncompressedbytes = uncompressedbytes\n\n    @property\n    def path(self):\n        return ""(decompressed data)""\n\n    def parent(self):\n        return self._compressed\n\n    def threadlocal(self):\n        return self\n\n    _header = struct.Struct(""2sBBBBBBB"")\n    _format_field0 = struct.Struct("">Q"")\n\n    def _prepare(self):\n        if self._uncompressed is None:\n            cursor = self._cursor.copied()\n\n            start = cursor.index\n            filled = 0\n            numblocks = 0\n            while cursor.index - start < self._compressedbytes:\n                # https://github.com/root-project/root/blob/master/core/zip/src/RZip.cxx#L217\n                # https://github.com/root-project/root/blob/master/core/lzma/src/ZipLZMA.c#L81\n                # https://github.com/root-project/root/blob/master/core/lz4/src/ZipLZ4.cxx#L38\n                algo, method, c1, c2, c3, u1, u2, u3 = header = cursor.fields(self._compressed, self._header)\n                compressedbytes = c1 + (c2 << 8) + (c3 << 16)\n                uncompressedbytes = u1 + (u2 << 8) + (u3 << 16)\n\n                if algo == b""ZL"":\n                    compression = self.compression.copy(uproot.const.kZLIB)\n                elif algo == b""XZ"":\n                    compression = self.compression.copy(uproot.const.kLZMA)\n                elif algo == b""L4"":\n                    try:\n                        import xxhash\n                    except ImportError:\n                        raise ImportError(""install xxhash package with:\\n    pip install xxhash\\nor\\n    conda install python-xxhash"")\n                    compression = self.compression.copy(uproot.const.kLZ4)\n                    compressedbytes -= 8\n                    checksum = cursor.field(self._compressed, self._format_field0)\n                    copy_cursor = copy(cursor)\n                    after_compressed = copy_cursor.bytes(self._compressed, compressedbytes)\n                    if xxhash.xxh64(after_compressed).intdigest() != checksum:\n                        raise ValueError(""LZ4 checksum didn\'t match"")\n                elif algo == b""ZS"":\n                    compression = self.compression.copy(uproot.const.kZSTD)\n                elif algo == b""CS"":\n                    raise ValueError(""unsupported compression algorithm: \'old\' (according to ROOT comments, hasn\'t been used in 20+ years!)"")\n                else:\n                    raise ValueError(""unrecognized compression algorithm: {0}"".format(algo))\n\n                asstr = compression.decompress(self._compressed, cursor, compressedbytes, uncompressedbytes)\n                numblocks += 1\n\n                if len(asstr) != uncompressedbytes:\n                    raise ValueError(""block with header {0} ({1}) decompressed to {2} bytes, but the object key says the decompressed size should be {3} bytes"".format(repr(header), compression.algoname, len(asstr), self._uncompressedbytes))\n                if filled + uncompressedbytes > self._uncompressedbytes:\n                    raise ValueError(""uncompressed {0} bytes in {1} blocks so far, but expected only {2} bytes"".format(filled + uncompressedbytes, numblocks, self._uncompressedbytes))\n\n                if filled == 0:\n                    if uncompressedbytes == self._uncompressedbytes:  # usual case: only one block\n                        self._uncompressed = numpy.frombuffer(asstr, dtype=numpy.uint8)\n                        return\n                    else:\n                        self._uncompressed = numpy.empty(self._uncompressedbytes, dtype=numpy.uint8)\n\n                self._uncompressed[filled : filled + uncompressedbytes] = numpy.frombuffer(asstr, dtype=numpy.uint8)\n                filled += uncompressedbytes\n\n    def size(self):\n        self._prepare()\n        return len(self._uncompressed)\n\n    def data(self, start, stop, dtype=None):\n        # assert start >= 0\n        # assert stop >= 0\n        # assert stop >= start\n\n        self._prepare()\n        if dtype is None:\n            return self._uncompressed[start:stop]\n        else:\n            return self._uncompressed[start:stop].view(dtype)\n\n    def dismiss(self):\n        self._uncompressed = None\n'"
uproot/source/cursor.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport struct\nimport string\n\nimport numpy\n\nclass Cursor(object):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (type,), {})\n\n    def __init__(self, index, origin=0, refs=None):\n        self.index = index\n        self.origin = origin\n        if refs is None:\n            self.refs = {}\n        else:\n            self.refs = refs\n\n    def copied(self, index=None, origin=None, refs=None):\n        if index is None:\n            index = self.index\n        if origin is None:\n            origin = self.origin\n        if refs is None:\n            refs = self.refs\n        return Cursor(index, origin, refs)\n\n    def skipped(self, numbytes, origin=None, refs=None):\n        if origin is None:\n            origin = self.origin\n        if refs is None:\n            refs = self.refs\n        return Cursor(self.index + numbytes, origin, refs)\n\n    def skip(self, numbytes):\n        self.index += numbytes\n\n    def fields(self, source, format):\n        start = self.index\n        stop = self.index = start + format.size\n        return format.unpack(source.data(start, stop))\n\n    def field(self, source, format):\n        return self.fields(source, format)[0]\n\n    def bytes(self, source, length):\n        start = self.index\n        stop = self.index = start + length\n        return source.data(start, stop)\n\n    def array(self, source, length, dtype):\n        if not isinstance(dtype, numpy.dtype):\n            dtype = numpy.dtype(dtype)\n        start = self.index\n        stop = self.index = start + length*dtype.itemsize\n        return source.data(start, stop, dtype)\n\n    def string(self, source):\n        start = self.index\n        stop = self.index = start + 1\n        length = source.data(start, stop)[0]\n        if length == 255:\n            start = self.index\n            stop = self.index = start + 4\n            length = source.data(start, stop, numpy.dtype("">u4""))[0]\n        start = self.index\n        stop = self.index = start + length\n        return source.data(start, stop).tostring()\n\n    def cstring(self, source):\n        char = None\n        chars = []\n        while char != 0:\n            char = source.data(self.index, self.index + 1)\n            if char != 0:\n                chars.append(chr(char[0]).encode(""ascii""))\n            self.index += 1\n        return b"""".join(chars)\n\n    def skipstring(self, source):\n        length = source.data(self.index, self.index + 1)[0]\n        self.index += 1\n        if length == 255:\n            length = source.data(self.index, self.index + 4, numpy.dtype("">u4""))[0]\n            self.index += 4\n        self.index += length\n\n    def hexdump(self, source, size=160, offset=0, format=""%02x""):\n        pos = self.index + offset\n        out = []\n        for linepos in range(pos, pos + size, 16):\n            data = source.data(linepos, min(linepos + 16, pos + size))\n            line = [format % x for x in data]\n            text = [chr(x) if chr(x) in string.printable[:-5] else ""."" for x in data]\n            if len(line) < 16:\n                diff = 16 - len(line)\n                line.extend([""  ""] * diff)\n                text.extend(["" ""] * diff)\n            out.append(""{0:08o}  {1}  {2}  |{3}|"".format(linepos, "" "".join(line[:8]), "" "".join(line[8:]), """".join(text)))\n        return ""\\n"".join(out)\n'"
uproot/source/file.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport multiprocessing\nimport os.path\nimport sys\n\nimport numpy\n\nimport uproot.source.chunked\n\nclass FileSource(uproot.source.chunked.ChunkedSource):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (uproot.source.chunked.ChunkedSource.__metaclass__,), {})\n\n    defaults = {""chunkbytes"": 8*1024, ""limitbytes"": 1024**2, ""parallel"": 8*multiprocessing.cpu_count() if sys.version_info[0] > 2 else 1}\n\n    def __init__(self, path, *args, **kwds):\n        self._size = None\n        self._parallel = kwds[\'parallel\']\n        super(FileSource, self).__init__(os.path.expanduser(path), *args, **kwds)\n\n    def size(self):\n        if self._size is None:\n            self._size = os.path.getsize(self.path)\n        return self._size\n\n    def threadlocal(self):\n        out = FileSource.__new__(self.__class__)\n        out.path = self.path\n        out._chunkbytes = self._chunkbytes\n        out.cache = self.cache\n        out._source = None             # local file connections are *not shared* among threads (they\'re *not* thread-safe)\n        out._setup_futures(self._parallel)\n        return out\n\n    def _open(self):\n        if self._source is None or self._source.closed:\n            self._source = open(self.path, ""rb"")\n\n    def _read(self, chunkindex):\n        self._source.seek(chunkindex * self._chunkbytes)\n        return numpy.frombuffer(self._source.read(self._chunkbytes), dtype=numpy.uint8)\n\n    def dismiss(self):\n        if self._source is not None:\n            self._source.close()       # local file connections are *not shared* among threads\n'"
uproot/source/http.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport os.path\nimport re\nimport multiprocessing\nimport sys\n\nimport numpy\n\nimport uproot.source.chunked\n\nclass HTTPSource(uproot.source.chunked.ChunkedSource):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (uproot.source.chunked.ChunkedSource.__metaclass__,), {})\n\n    def __init__(self, path, auth=None, *args, **kwds):\n        super(HTTPSource, self).__init__(path, *args, **kwds)\n        self._size = None\n        self.auth = auth\n\n    defaults = {""chunkbytes"": 1024**2, ""limitbytes"": 100*1024**2, ""parallel"": 8*multiprocessing.cpu_count() if sys.version_info[0] > 2 else 1}\n\n    def _open(self):\n        try:\n            import requests\n        except ImportError:\n            raise ImportError(""Install requests package (for HTTP) with:\\n    pip install requests\\nor\\n    conda install -c anaconda requests"")\n\n    def size(self):\n        return self._size\n\n    _contentrange = re.compile(""^bytes ([0-9]+)-([0-9]+)/([0-9]+)$"")\n\n    def _read(self, chunkindex):\n        import requests\n        while True:\n            response = requests.get(\n                self.path,\n                headers={""Range"": ""bytes={0}-{1}"".format(chunkindex * self._chunkbytes, (chunkindex + 1) * self._chunkbytes - 1)},\n                auth=self.auth,\n            )\n            if response.status_code == 504:   # timeout, try it again\n                pass\n            else:\n                response.raise_for_status()   # if it\'s an error, raise exception\n                break                         # otherwise, break out of the loop\n        data = response.content\n\n        if self._size is None:\n            m = self._contentrange.match(response.headers.get(""Content-Range"", """"))\n            if m is not None:\n                start_inclusive, stop_inclusive, size = int(m.group(1)), int(m.group(2)), int(m.group(3))\n                if size > (stop_inclusive - start_inclusive) + 1:\n                    self._size = size\n        return numpy.frombuffer(data, dtype=numpy.uint8)\n'"
uproot/source/memmap.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport os.path\n\nimport numpy\n\nimport uproot.source.source\n\nclass MemmapSource(uproot.source.source.Source):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (uproot.source.source.Source.__metaclass__,), {})\n\n    defaults = {}\n\n    def __init__(self, path):\n        self.path = os.path.expanduser(path)\n        self._source = numpy.memmap(self.path, dtype=numpy.uint8, mode=""r"")\n        self.closed = False\n\n    @property\n    def source(self):\n        if self.closed:\n            raise IOError(""The file handler has already been closed."")\n        return self._source\n\n    def parent(self):\n        return self\n\n    def size(self):\n        return len(self.source)\n\n    def threadlocal(self):\n        return self\n\n    def dismiss(self):\n        pass\n\n    def close(self):\n        self.source._mmap.close()\n        self.closed = True\n\n    def data(self, start, stop, dtype=None):\n        # assert start >= 0\n        # assert stop >= 0\n        # assert stop >= start\n\n        if stop > len(self.source):\n            raise IndexError(""indexes {0}:{1} are beyond the end of data source {2}"".format(len(self.source), stop, repr(self.path)))\n\n        if dtype is None:\n            return self.source[start:stop]\n        else:\n            return self.source[start:stop].view(dtype)\n'"
uproot/source/source.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport numpy\n\nclass Source(object):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (type,), {})\n\n    def __init__(self, data):\n        assert len(data.shape) == 1 and data.dtype == numpy.uint8\n        self._source = data\n\n    def parent(self):\n        return self\n\n    def size(self):\n        return len(self._source)\n\n    def threadlocal(self):\n        return self\n\n    def dismiss(self):\n        pass\n\n    def close(self):\n        self.dismiss()\n\n    def preload(self, starts):\n        pass\n\n    def data(self, start, stop, dtype=None):\n        # assert start >= 0\n        # assert stop >= 0\n        # assert stop >= start\n\n        if stop > len(self._source):\n            raise IndexError(""indexes {0}:{1} are beyond the end of data source of length {2}"".format(start, stop, len(self._source)))\n\n        if dtype is None:\n            return self._source[start:stop]\n        else:\n            return self._source[start:stop].view(dtype)\n'"
uproot/source/xrootd.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport os\nimport threading\n\nimport numpy\n\nimport uproot.source.chunked\n\nclass XRootDSource(uproot.source.chunked.ChunkedSource):\n    # makes __doc__ attribute mutable before Python 3.3\n    __metaclass__ = type.__new__(type, ""type"", (uproot.source.chunked.ChunkedSource.__metaclass__,), {})\n\n    def __init__(self, path, timeout=None, *args, **kwds):\n        self._size = None\n        self.timeout = timeout\n        super(XRootDSource, self).__init__(path, *args, **kwds)\n\n    defaults = {""timeout"": None, ""chunkbytes"": 1024**2, ""limitbytes"": 100*1024**2, ""parallel"": False}\n\n    def _open(self):\n        try:\n            os.environ[""XRD_RUNFORKHANDLER""] = ""1""   # To make uproot + xrootd + multiprocessing work\n            import pyxrootd.client\n        except ImportError:\n            raise ImportError(""Install pyxrootd package with:\\n    conda install -c conda-forge xrootd\\n(or download from http://xrootd.org/dload.html and manually compile with cmake; setting PYTHONPATH and LD_LIBRARY_PATH appropriately)."")\n\n        if self._source is None or not self._source.is_open():\n            self._source = pyxrootd.client.File()\n            status, dummy = self._source.open(self.path, timeout=(0 if self.timeout is None else self.timeout))\n            if status.get(""error"", None):\n                raise OSError(status[""message""])\n            status, info = self._source.stat(timeout=(0 if self.timeout is None else self.timeout))\n            if status.get(""error"", None):\n                raise OSError(status[""message""])\n            self._size = info[""size""]\n\n    def size(self):\n        if self._size is None:\n            self._open()\n        return self._size\n\n    def threadlocal(self):\n        out = XRootDSource.__new__(self.__class__)\n        out.path = self.path\n        out._chunkbytes = self._chunkbytes\n        out.cache = self.cache\n        out._source = None             # XRootD connections are *not shared* among threads\n        out._size = self._size\n        out.timeout = self.timeout\n        out._parallel = self._parallel\n        out._executor = None\n        out._futures = {}\n        return out\n\n    def _read(self, chunkindex):\n        self._open()\n        status, data = self._source.read(int(chunkindex * self._chunkbytes), int(self._chunkbytes), timeout=int(0 if self.timeout is None else self.timeout))\n        if status.get(""error"", None):\n            raise OSError(status[""message""])\n        return numpy.frombuffer(data, dtype=numpy.uint8)\n\n    def _setup_futures(self, parallel):\n        self._parallel = parallel\n        self._executor = None\n        self._futures = {}\n\n    class _preload(object):\n        def __init__(self, timeout):\n            self.timeout = timeout\n            self.out = None\n            self.hold = threading.Event()\n\n        def __call__(self, status, data, hostlist):\n            if not status.get(""error"", None):\n                self.out = numpy.frombuffer(data, dtype=numpy.uint8)\n            self.hold.set()\n\n        def result(self):\n            if self.hold.wait(self.timeout):\n                return self.out\n\n    def preload(self, starts):\n        if self._parallel:\n            self._open()\n            limitnum = self._limitbytes // self._chunkbytes\n            timeout = int(0 if self.timeout is None else self.timeout)\n            for start in starts:\n                if len(self._futures) > limitnum:\n                    break\n                chunkindex = start // self._chunkbytes\n                try:\n                    self.cache[chunkindex]\n                except KeyError:\n                    callback = self._preload(timeout)\n                    status = self._source.read(int(chunkindex * self._chunkbytes), int(self._chunkbytes), timeout=timeout, callback=callback)\n                    if status[""ok""]:\n                        self._futures[chunkindex] = callback\n\n    def __del__(self):\n        if self._source is not None:\n            self._source.close(timeout=(0 if self.timeout is None else self.timeout))\n\n    def dismiss(self):\n        self._futures = {}\n'"
uproot/write/TDirectory.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport collections\nimport struct\nimport uuid\n\nimport uproot.write.sink.cursor\nimport uproot.write.TKey\nimport uproot.write.util\n\nclass TDirectory(object):\n    def __init__(self, tfile, fName, fNbytesName, fSeekDir=100, fSeekParent=0, fSeekKeys=0, allocationbytes=128, growfactor=8):\n        self.tfile = tfile\n        self.fName = fName\n        self.fNbytesName = fNbytesName\n        self.fNbytesKeys = self._format2.size\n        self.fSeekDir = fSeekDir\n        self.fSeekParent = fSeekParent\n        self.fSeekKeys = fSeekKeys\n        self.fDatimeC = uproot.write.util.datime()\n        self.fUUID = b\'\\x00\\x01\' + uuid.uuid1().bytes\n\n        self.allocationbytes = allocationbytes\n        self.growfactor = growfactor\n\n        self.headkey = uproot.write.TKey.TKey(fClassName = b""TFile"",\n                                              fName      = self.fName,\n                                              fObjlen    = self._format2.size,\n                                              fSeekKey   = self.fSeekKeys)\n        self.keys = collections.OrderedDict()\n        self.maxcycle = collections.Counter()\n\n    def size(self):\n        return uproot.write.sink.cursor.Cursor.length_string(self.fName) + 1 + self._format1.size + len(self.fUUID) + 12\n\n    def update(self):\n        fVersion = 5\n        fDatimeM = uproot.write.util.datime()\n        self.cursor.update_fields(self.sink, self._format1, fVersion, self.fDatimeC, fDatimeM, self.fNbytesKeys, self.fNbytesName, self.fSeekDir, self.fSeekParent, self.fSeekKeys)\n\n    def write(self, cursor, sink):\n        cursor.write_string(sink, self.fName)\n        cursor.write_data(sink, b""\\x00"")\n\n        self.cursor = uproot.write.sink.cursor.Cursor(cursor.index)\n        self.sink = sink\n        self.update()\n\n        cursor.skip(self._format1.size)\n        cursor.write_data(self.sink, self.fUUID)\n        cursor.write_data(sink, b""\\x00"" * 12)   # FIXME! what is this?\n\n    _format1 = struct.Struct("">hIIiiiii"")\n    _format2 = struct.Struct("">i"")\n\n    def _nbyteskeys(self):\n        return self.headkey.fKeylen + self._format2.size + sum(x.fKeylen for x in self.keys.values())\n\n    def writekeys(self, cursor):\n        self.fSeekKeys = cursor.index\n        self.fNbytesKeys = self._nbyteskeys()\n\n        self.tfile._expandfile(uproot.write.sink.cursor.Cursor(self.fSeekKeys + self.allocationbytes))\n\n        self.keycursor = uproot.write.sink.cursor.Cursor(self.fSeekKeys)\n        self.headkey.write(self.keycursor, self.sink)\n        self.nkeycursor = uproot.write.sink.cursor.Cursor(self.keycursor.index)\n        self.keycursor.write_fields(self.sink, self._format2, len(self.keys))\n        for key in self.keys.values():\n            key.write(self.keycursor, self.sink)\n\n        self.update()\n\n    def newcycle(self, name):\n        self.maxcycle[name] += 1\n        return self.maxcycle[name]\n\n    def setkey(self, newkey):\n        newcursor = None\n        if (newkey.fName, newkey.fCycle) in self.keys:\n            self.headkey.fObjlen -= self.keys[(newkey.fName, newkey.fCycle)].fKeylen\n            newcursor = uproot.write.sink.cursor.Cursor(self.fSeekKeys)\n\n        self.headkey.fObjlen += newkey.fKeylen\n        self.keys[(newkey.fName, newkey.fCycle)] = newkey\n\n        self.fNbytesKeys = self._nbyteskeys()\n        while self.fNbytesKeys > self.allocationbytes:\n            self.allocationbytes *= self.growfactor\n            newcursor = uproot.write.sink.cursor.Cursor(self.tfile._fSeekFree)\n\n        if newcursor is not None:\n            self.writekeys(newcursor)\n        else:\n            newkey.write(self.keycursor, self.sink)\n            self.headkey.update()\n            self.nkeycursor.update_fields(self.sink, self._format2, len(self.keys))\n            self.update()\n\n    def delkey(self, name, cycle):\n        if cycle is None:\n            for x in range(self.maxcycle[name]):\n                self.delkey(name, x + 1)\n\n        else:\n            oldkey = self.keys[(name, cycle)]\n            self.headkey.fObjlen -= oldkey.fKeylen\n            del self.keys[(name, cycle)]\n\n            self.fNbytesKeys = self._nbyteskeys()\n            self.writekeys(uproot.write.sink.cursor.Cursor(self.fSeekKeys))\n'"
uproot/write/TFile.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport os\nimport sys\nimport struct\nimport uuid\n\nimport uproot_methods.convert\n\nimport uproot.const\nimport uproot.source.file\nimport uproot.write.compress\nimport uproot.write.sink.cursor\nimport uproot.write.sink.file\nimport uproot.write.streamers\nimport uproot.write.TDirectory\nimport uproot.write.TFree\nimport uproot.write.TKey\nfrom uproot.rootio import nofilter\nfrom uproot.write.objects.util import Util\nfrom uproot.write.objects.TTree import TTree\n\nclass TFileUpdate(object):\n    def __init__(self, path):\n        #FIXME: Need to fix self.compression attribute\n        #self._openfile(path)\n        raise NotImplementedError\n\n    def _openfile(self, path, compression):\n        if isinstance(path, getattr(os, ""PathLike"", ())):\n            path = os.fspath(path)\n        elif hasattr(path, ""__fspath__""):\n            path = path.__fspath__()\n        elif path.__class__.__module__ == ""pathlib"":\n            import pathlib\n            if isinstance(path, pathlib.Path):\n                 path = str(path)\n\n        self.compression = compression\n        self._treedict = {}\n\n        self._sink = uproot.write.sink.file.FileSink(path)\n        self._path = path\n        self._filename = os.path.split(path)[1].encode(""utf-8"")\n\n    @staticmethod\n    def _normalizewhere(where):\n        if (sys.version_info[0] <= 2 and isinstance(where, unicode)) or (sys.version_info[0] > 2 and isinstance(where, str)):\n            where = where.encode(""utf-8"")\n        if not isinstance(where, bytes):\n            raise TypeError(""ROOT file key must be a string"")\n\n        if b"";"" in where:\n            at = where.rindex(b"";"")\n            where, cycle = where[:at], where[at + 1:]\n            cycle = int(cycle)\n        else:\n            cycle = None\n\n        if b""/"" in where:\n            raise NotImplementedError(""subdirectories not supported yet"")\n\n        return where, cycle\n\n    def newtree(self, name, branches={}, title="""", **options):\n        if ""compression"" in options:\n            self.__setitem__(name, uproot.write.objects.TTree.newtree(branches, title, compression=options[""compression""]))\n            del options[""compression""]\n        else:\n            self.__setitem__(name, uproot.write.objects.TTree.newtree(branches, title))\n        if len(options) > 0:\n            raise TypeError(""{0} not supported"".format(options))\n\n    def __setitem__(self, where, what):\n        self.util = Util()\n        where, cycle = self._normalizewhere(where)\n        if what.__class__.__name__ != ""TTree"" and what.__class__.__name__ != ""newtree"":\n            what = uproot_methods.convert.towriteable(what)\n        elif what.__class__.__name__ == ""newtree"":\n            what = TTree(where, what, self)\n        cursor = uproot.write.sink.cursor.Cursor(self._fSeekFree)\n        newkey = uproot.write.TKey.TKey(fClassName = what._fClassName,\n                                        fName      = where,\n                                        fTitle     = what._fTitle,\n                                        fObjlen    = 0,\n                                        fSeekKey   = self._fSeekFree,\n                                        fSeekPdir  = self._fBEGIN,\n                                        fCycle     = cycle if cycle is not None else self._rootdir.newcycle(where))\n        if what.__class__.__name__ == ""newtree"" or what.__class__.__name__ == ""TTree"":\n            # Need to (re)attach the cycle number to allow getitem to access writable TTree\n            tree_where = where + b"";"" + str(newkey.fCycle).encode(""utf-8"")\n            self._treedict[tree_where] = what\n        newkeycursor = uproot.write.sink.cursor.Cursor(newkey.fSeekKey)\n        newkey.write(cursor, self._sink)\n        what._write(self, cursor, where, self.compression, newkey, newkeycursor, self.util)\n        self._expandfile(cursor)\n\n        self._rootdir.setkey(newkey)\n        self._sink.flush()\n\n    def __delitem__(self, where):\n        where, cycle = self._normalizewhere(where)\n        try:\n            self._rootdir.delkey(where, cycle)\n        except KeyError:\n            raise KeyError(""ROOT directory does not contain key {0}"".format(where))\n\n    def _reopen(self):\n        return uproot.open(self._path, localsource=lambda path: uproot.source.file.FileSource(path, **uproot.source.file.FileSource.defaults))\n\n    @property\n    def compression(self):\n        return self._reopen().compression\n\n    def __repr__(self):\n        return ""<{0} {1} at 0x{2:012x}>"".format(self.__class__.__name__, repr(self._filename), id(self))\n\n    @staticmethod\n    def fixstring(string):\n        if isinstance(string, bytes):\n            return string\n        else:\n            return string.encode(""utf-8"")\n\n    def __getitem__(self, name):\n        name = self.fixstring(name)\n        if name in self._treedict:\n            return self._treedict[name]\n        elif any(name == x[:-2] for x in self._treedict.keys()):\n            name = sorted([x for x in self._treedict.keys() if name == x[:-2]], key=lambda y: int(y[-1]), reverse=True)[0]\n            return self._treedict[name]\n        else:\n            return self._reopen().get(name)\n\n    def __len__(self):\n        return len(self._reopen()._keys)\n\n    def __iter__(self):\n        return self._reopen().iterkeys()\n\n    def showstreamers(self, filtername=nofilter, stream=sys.stdout):\n        return self._reopen().showstreamers(filtername=filtername, stream=stream)\n\n    def iterkeys(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        return self._reopen().iterkeys(recursive=recursive, filtername=filtername, filterclass=filterclass)\n\n    def itervalues(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        return self._reopen().itervalues(recursive=recursive, filtername=filtername, filterclass=filterclass)\n\n    def iteritems(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        return self._reopen().iteritems(recursive=recursive, filtername=filtername, filterclass=filterclass)\n\n    def iterclasses(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        return self._reopen().iterclasses(recursive=recursive, filtername=filtername, filterclass=filterclass)\n\n    def keys(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        return self._reopen().keys(recursive=recursive, filtername=filtername, filterclass=filterclass)\n\n    def _ipython_key_completions_(self):\n        ""Support for completion of keys in an IPython kernel""\n        return self._reopen()._ipython_key_completions_()\n\n    def values(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        return self._reopen().values(recursive=recursive, filtername=filtername, filterclass=filterclass)\n\n    def items(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        return self._reopen().items(recursive=recursive, filtername=filtername, filterclass=filterclass)\n\n    def classes(self, recursive=False, filtername=nofilter, filterclass=nofilter):\n        return self._reopen().classes(recursive=recursive, filtername=filtername, filterclass=filterclass)\n\n    def allkeys(self, filtername=nofilter, filterclass=nofilter):\n        return self._reopen().allkeys(filtername=filtername, filterclass=filterclass)\n\n    def allvalues(self, filtername=nofilter, filterclass=nofilter):\n        return self._reopen().allvalues(filtername=filtername, filterclass=filterclass)\n\n    def allitems(self, filtername=nofilter, filterclass=nofilter):\n        return self._reopen().allitems(filtername=filtername, filterclass=filterclass)\n\n    def allclasses(self, filtername=nofilter, filterclass=nofilter):\n        return self._reopen().allclasses(filtername=filtername, filterclass=filterclass)\n\n    def get(self, name, cycle=None):\n        return self._reopen().get(name, cycle=cycle)\n\n    def __contains__(self, name):\n        return name in self._reopen()\n\n    @property\n    def closed(self):\n        return self._sink.closed\n\n    def close(self):\n        self._sink.close()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, traceback):\n        self.close()\n\nclass TFileRecreate(TFileUpdate):\n    def __init__(self, path, compression=uproot.write.compress.ZLIB(1)):\n        self._openfile(path, compression)\n        self._writeheader()\n        self._writerootdir()\n        self._writestreamers()\n        self._writerootkeys()\n        self._sink.flush()\n\n    _format1           = struct.Struct("">4sii"")\n    _format_end        = struct.Struct("">qqii"")\n    _format2           = struct.Struct("">iB"")\n    _format3           = struct.Struct("">i"")\n    _format_seekinfo   = struct.Struct("">q"")\n    _format_nbytesinfo = struct.Struct("">i"")\n\n    @property\n    def compression(self):\n        if self._fCompress == 0:\n            return None\n        else:\n            return uproot.write.compress.algo[self._fCompress // 100](self._fCompress % 100)\n\n    @compression.setter\n    def compression(self, value):\n        if value is None:\n            self._fCompress = 0\n        else:\n            if not isinstance(value, uproot.write.compress.Compression):\n                raise TypeError(""uproot.write.TFile.compression must be a Compression object like ZLIB(4)"")\n            self._fCompress = value.code\n        if hasattr(self, ""_compresscursor""):\n            self._compresscursor.update_fields(self._sink, self._format3, self._fCompress)\n\n    def _writeheader(self):\n        cursor = uproot.write.sink.cursor.Cursor(0)\n        self._fVersion = self._fVersion = 1061800\n        self._fBEGIN = 100\n        cursor.write_fields(self._sink, self._format1, b""root"", self._fVersion, self._fBEGIN)\n\n        self._fEND = 0\n        self._fSeekFree = 0\n        self._fNbytesFree = 0\n        self._nfree = 0\n        self._endcursor = uproot.write.sink.cursor.Cursor(cursor.index)\n        cursor.write_fields(self._sink, self._format_end, self._fEND, self._fSeekFree, self._fNbytesFree, self._nfree)\n\n        self._fNbytesName = 2*len(self._filename) + 36 + 8   # + 8 because two fields in TKey are \'q\' rather than \'i\'\n        fUnits = 4\n        cursor.write_fields(self._sink, self._format2, self._fNbytesName, fUnits)\n\n        self._compresscursor = uproot.write.sink.cursor.Cursor(cursor.index)\n        cursor.write_fields(self._sink, self._format3, self._fCompress)\n\n        self._fSeekInfo = 0\n        self._seekcursor = uproot.write.sink.cursor.Cursor(cursor.index)\n        cursor.write_fields(self._sink, self._format_seekinfo, self._fSeekInfo)\n\n        self._fNbytesInfo = 0\n        self._nbytescursor = uproot.write.sink.cursor.Cursor(cursor.index)\n        cursor.write_fields(self._sink, self._format_nbytesinfo, self._fNbytesInfo)\n\n        cursor.write_data(self._sink, b\'\\x00\\x01\' + uuid.uuid1().bytes)\n\n    def _expandfile(self, cursor):\n        if cursor.index > self._fSeekFree:\n            freecursor = uproot.write.sink.cursor.Cursor(cursor.index)\n            freekey = uproot.write.TKey.TKey(b""TFile"", self._filename, fObjlen=0, fSeekKey=cursor.index, fSeekPdir=self._fBEGIN)\n            freeseg = uproot.write.TFree.TFree(cursor.index + freekey.fNbytes)\n            freekey.fObjlen = freeseg.size()\n            freekey.fNbytes += freekey.fObjlen\n\n            freekey.write(freecursor, self._sink)\n            freeseg.write(freecursor, self._sink)\n\n            self._fSeekFree = cursor.index\n            self._fEND = cursor.index + freekey.fNbytes\n            self._fNbytesFree = freekey.fNbytes\n            self._nfree = 1\n            self._endcursor.update_fields(self._sink, self._format_end, self._fEND, self._fSeekFree, self._fNbytesFree, self._nfree)\n\n    def _writerootdir(self):\n        cursor = uproot.write.sink.cursor.Cursor(self._fBEGIN)\n\n        self._rootdir = uproot.write.TDirectory.TDirectory(self, self._filename, self._fNbytesName)\n\n        key = uproot.write.TKey.TKey(b""TFile"", self._filename, fObjlen=self._rootdir.size())\n        key.write(cursor, self._sink)\n        self._rootdir.write(cursor, self._sink)\n\n        self._expandfile(cursor)\n\n    def _writestreamers(self):\n        self._fSeekInfo = self._fSeekFree\n        self._seekcursor.update_fields(self._sink, self._format_seekinfo, self._fSeekInfo)\n\n        cursor = uproot.write.sink.cursor.Cursor(self._fSeekInfo)\n        streamerkey = uproot.write.TKey.TKey32(fClassName = b""TList"",\n                                               fName      = b""StreamerInfo"",\n                                               fTitle     = b""Doubly linked list"",\n                                               fSeekKey   = self._fSeekInfo,\n                                               fSeekPdir  = self._fBEGIN)\n        streamerkeycursor = uproot.write.sink.cursor.Cursor(self._fSeekInfo)\n        streamerkey.write(cursor, self._sink)\n\n        uproot.write.compress.write(self, cursor, uproot.write.streamers.streamers, self.compression, streamerkey, streamerkeycursor)\n\n        self._fNbytesInfo = streamerkey.fNbytes\n        self._nbytescursor.update_fields(self._sink, self._format_nbytesinfo, self._fNbytesInfo)\n\n        self._expandfile(cursor)\n\n    def _writerootkeys(self):\n        self._rootdir.writekeys(uproot.write.sink.cursor.Cursor(self._fSeekFree))\n\nclass TFileCreate(TFileRecreate):\n    def __init__(self, path):\n        if os.path.exists(path):\n            raise OSError(""file {} already exists"".format(path))\n        super(TFileCreate, self).__init__(path)\n'"
uproot/write/TFree.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport math\nimport struct\n\nimport numpy\n\nclass TFree(object):\n    def __init__(self, fEND):\n        self.fFirst = fEND\n        self.fLast = int(math.ceil(fEND / 2000000000.0)) * 2000000000\n\n    _format_big = struct.Struct("">hqq"")\n    _format_small = struct.Struct("">hii"")\n\n    def write(self, cursor, sink):\n        if self.fLast > numpy.iinfo(numpy.int32).max:\n            cursor.write_fields(sink, self._format_big, 1001, self.fFirst, self.fLast)\n        else:\n            cursor.write_fields(sink, self._format_small, 1, self.fFirst, self.fLast)\n\n    def size(self):\n        if self.fLast > numpy.iinfo(numpy.int32).max:\n            return TFree._format_big.size\n        else:\n            return TFree._format_small.size\n'"
uproot/write/TKey.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport struct\n\nimport uproot.write.sink.cursor\nimport uproot.write.util\n\nclass BasketKey(object):\n    def __init__(self, fName, fTitle, fNevBuf, fNevBufSize, fObjlen=0, fSeekKey=100, fSeekPdir=0, fBufferSize=0):\n        self.fClassName = b""TBasket""\n        self.fName = fName\n        self.fTitle = fTitle\n\n        self.fObjlen = fObjlen\n        self.fSeekKey = fSeekKey\n        self.fSeekPdir = fSeekPdir\n        self.fCycle = 0\n        self.fDatime = uproot.write.util.datime()\n        self.fNbytes = self.fObjlen + self.fKeylen\n        self.fBufferSize = fBufferSize\n        self.fNevBuf = fNevBuf\n        self.fNevBufSize = fNevBufSize\n\n        self.old_fLast = 0\n\n    @property\n    def fKeylen(self):\n        return self._format1.size + uproot.write.sink.cursor.Cursor.length_strings([self.fClassName, self.fName, self.fTitle]) + self._format_basketkey.size + 1\n\n    @property\n    def fLast(self):\n        return self.fKeylen + self.fObjlen\n\n    def update(self):\n        self.cursor.update_fields(self.sink, self._format1, self.fNbytes, self._version, self.fObjlen, self.fDatime, self.fKeylen, self.fCycle, self.fSeekKey, self.fSeekPdir)\n\n    def write(self, cursor, sink, isjagged=False):\n        self.cursor = uproot.write.sink.cursor.Cursor(cursor.index)\n        self.sink = sink\n\n        self.update()\n\n        cursor.skip(self._format1.size)\n        cursor.write_string(sink, self.fClassName)\n        cursor.write_string(sink, self.fName)\n        cursor.write_string(sink, self.fTitle)\n\n        basketversion = 3\n        if isjagged:\n            if self.old_fLast == 0:\n                raise Exception(""isjagged flag should be False"")\n            cursor.write_fields(sink, self._format_basketkey, basketversion, self.fBufferSize, self.fNevBufSize, self.fNevBuf, self.old_fLast)\n        else:\n            cursor.write_fields(sink, self._format_basketkey, basketversion, self.fBufferSize, self.fNevBufSize, self.fNevBuf, self.fLast)\n            self.old_fLast = self.fLast\n        cursor.write_data(sink, b""\\x00"")\n\n    _version = 1004\n    _format1 = struct.Struct("">ihiIhhqq"")\n    _format_basketkey = struct.Struct("">Hiiii"")\n\nclass TKey(object):\n    def __init__(self, fClassName, fName, fTitle=b"""", fObjlen=0, fSeekKey=100, fSeekPdir=0, fCycle=1):\n        self.fClassName = fClassName\n        self.fName = fName\n        self.fTitle = fTitle\n\n        self.fObjlen = fObjlen\n        self.fSeekKey = fSeekKey\n        self.fSeekPdir = fSeekPdir\n        self.fCycle = fCycle\n        self.fDatime = uproot.write.util.datime()\n        self.fNbytes = self.fObjlen + self.fKeylen\n\n    @property\n    def fKeylen(self):\n        return self._format1.size + uproot.write.sink.cursor.Cursor.length_strings([self.fClassName, self.fName, self.fTitle])\n\n    def update(self):\n        self.cursor.update_fields(self.sink, self._format1, self.fNbytes, self._version, self.fObjlen, self.fDatime, self.fKeylen, self.fCycle, self.fSeekKey, self.fSeekPdir)\n\n    def write(self, cursor, sink, isjagged=False):\n        if isjagged:\n            raise Exception(""isjagged flag should be False"")\n        self.cursor = uproot.write.sink.cursor.Cursor(cursor.index)\n        self.sink = sink\n\n        self.update()\n\n        cursor.skip(self._format1.size)\n        cursor.write_string(sink, self.fClassName)\n        cursor.write_string(sink, self.fName)\n        cursor.write_string(sink, self.fTitle)\n\n    _version = 1004\n    _format1 = struct.Struct("">ihiIhhqq"")\n\nclass TKey32(TKey):\n    _version = 4\n    _format1 = struct.Struct("">ihiIhhii"")\n'"
uproot/write/__init__.py,0,b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import'
uproot/write/compress.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport numbers\nimport struct\nimport copy\n\nimport numpy\n\nimport uproot\nimport uproot.const\n\nclass Compression(object):\n    def __init__(self, level):\n        self.level = level\n\n    def __repr__(self):\n        return ""{0}({1})"".format(type(self).__name__, self.level)\n\n    @property\n    def level(self):\n        return self._level\n\n    @level.setter\n    def level(self, value):\n        if not isinstance(value, (numbers.Integral, numpy.integer)):\n            raise TypeError(""Compression level must be an integer"")\n        if not 0 <= value <= 9:\n            raise ValueError(""Compression level must be between 0 and 9 (inclusive)"")\n        self._level = int(value)\n    \n    @property\n    def pair(self):\n        for const, cls in algo.items():\n            if type(self) is cls:\n                return const, self.level\n        else:\n            raise AssertionError(type(self))\n\n    @property\n    def code(self):\n        algorithm, level = self.pair\n        return algorithm * 100 + level\n\nclass ZLIB(Compression): pass\nclass LZMA(Compression): pass\nclass LZ4(Compression): pass\n\nalgo = {uproot.const.kZLIB: ZLIB,\n        uproot.const.kLZMA: LZMA,\n        uproot.const.kLZ4: LZ4}\n\ndef write(context, cursor, givenbytes, compression, key, keycursor, isjagged=False):\n    retaincursor = copy.copy(keycursor)\n    if compression is None:\n        algorithm, level = 0, 0\n    else:\n        algorithm, level = compression.pair\n\n    _header = struct.Struct(""2sBBBBBBB"")\n    uncompressedbytes = len(givenbytes)\n\n    if algorithm == 0 or level == 0:\n        if isjagged:\n            key.fObjlen += uncompressedbytes\n        else:\n            key.fObjlen = uncompressedbytes\n        key.fNbytes = key.fObjlen + key.fKeylen\n        key.write(keycursor, context._sink, isjagged)\n        cursor.write_data(context._sink, givenbytes)\n        return\n\n    if uncompressedbytes > 2**24:\n        uncompressedbytes = 2**24 - 1\n        remainingbytes = givenbytes[2**24 - 1:]\n        givenbytes = givenbytes[:2**24 - 1]\n\n    key.fObjlen += uncompressedbytes\n\n    u1 = (uncompressedbytes >> 0) & 0xff\n    u2 = (uncompressedbytes >> 8) & 0xff\n    u3 = (uncompressedbytes >> 16) & 0xff\n\n    if algorithm == uproot.const.kZLIB:\n        algo = b""ZL""\n        import zlib\n        after_compressed = zlib.compress(givenbytes, level)\n        compressedbytes = len(after_compressed)\n        if (compressedbytes + 9) < uncompressedbytes:\n            c1 = (compressedbytes >> 0) & 0xff\n            c2 = (compressedbytes >> 8) & 0xff\n            c3 = (compressedbytes >> 16) & 0xff\n            method = 8\n            cursor.write_fields(context._sink, _header, algo, method, c1, c2, c3, u1, u2, u3)\n            cursor.write_data(context._sink, after_compressed)\n            key.fNbytes += compressedbytes + 9\n            key.write(keycursor, context._sink, isjagged)\n        else:\n            key.fNbytes += uncompressedbytes\n            key.write(keycursor, context._sink, isjagged)\n            cursor.write_data(context._sink, givenbytes)\n\n    elif algorithm == uproot.const.kLZ4:\n        algo = b""L4""\n        try:\n            import xxhash\n        except ImportError:\n            raise ImportError(""Install xxhash package with:\\n    pip install xxhash\\nor\\n    conda install -c conda-forge python-xxhash"")\n        try:\n            import lz4.block\n        except ImportError:\n            raise ImportError(""Install lz4 package with:\\n    pip install lz4\\nor\\n    conda install -c anaconda lz4"")\n        if level >= 4:\n            after_compressed = lz4.block.compress(givenbytes, compression=level, mode=""high_compression"", store_size=False)\n        else:\n            after_compressed = lz4.block.compress(givenbytes, store_size=False)\n        compressedbytes = len(after_compressed) + 8\n        checksum = xxhash.xxh64(after_compressed).digest()\n        if (compressedbytes + 9) < uncompressedbytes:\n            c1 = (compressedbytes >> 0) & 0xff\n            c2 = (compressedbytes >> 8) & 0xff\n            c3 = (compressedbytes >> 16) & 0xff\n            method = lz4.library_version_number() // (100 * 100)\n            cursor.write_fields(context._sink, _header, algo, method, c1, c2, c3, u1, u2, u3)\n            cursor.write_data(context._sink, checksum)\n            cursor.write_data(context._sink, after_compressed)\n            key.fNbytes += compressedbytes + 9\n            key.write(keycursor, context._sink, isjagged)\n        else:\n            key.fNbytes += uncompressedbytes\n            key.write(keycursor, context._sink, isjagged)\n            cursor.write_data(context._sink, givenbytes)\n\n    elif algorithm == uproot.const.kLZMA:\n        algo = b""XZ""\n        try:\n            import lzma\n        except ImportError:\n            try:\n                from backports import lzma\n            except ImportError:\n                raise ImportError(\n                    ""Install lzma package with:\\n    pip install backports.lzma\\nor\\n    conda install -c conda-forge backports.lzma\\n(or just use Python >= 3.3)."")\n        after_compressed = lzma.compress(givenbytes, preset=level)\n        compressedbytes = len(after_compressed)\n        if (compressedbytes + 9) < uncompressedbytes:\n            c1 = (compressedbytes >> 0) & 0xff\n            c2 = (compressedbytes >> 8) & 0xff\n            c3 = (compressedbytes >> 16) & 0xff\n            method = 0\n            cursor.write_fields(context._sink, _header, algo, method, c1, c2, c3, u1, u2, u3)\n            cursor.write_data(context._sink, after_compressed)\n            key.fNbytes += compressedbytes + 9\n            key.write(keycursor, context._sink, isjagged)\n        else:\n            key.fNbytes += uncompressedbytes\n            key.write(keycursor, context._sink, isjagged)\n            cursor.write_data(context._sink, givenbytes)\n\n    elif algorithm == uproot.const.kOldCompressionAlgo:\n        raise ValueError(""unsupported compression algorithm: \'old\' (according to ROOT comments, hasn\'t been used in 20+ years!)"")\n    else:\n        raise ValueError(""Unrecognized compression algorithm: {0}"".format(algorithm))\n\n    if ""remainingbytes"" in locals() and len(remainingbytes)>0:\n        uproot.write.compress.write(context, cursor, remainingbytes, compression, key, retaincursor)\n'"
uproot/write/streamers.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\n# just TObjString (for debugging)\n# streamers = b\'@\\x00\\x01n\\x00\\x05\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01@\\x00\\x01X\\xff\\xff\\xff\\xffTStreamerInfo\\x00@\\x00\\x01B\\x00\\t@\\x00\\x00\\x18\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\nTObjString\\x00\\x9c\\x8eH\\x00\\x00\\x00\\x00\\x01@\\x00\\x01\\x18\\xff\\xff\\xff\\xffTObjArray\\x00@\\x00\\x01\\x06\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00u\\xff\\xff\\xff\\xffTStreamerBase\\x00@\\x00\\x00_\\x00\\x03@\\x00\\x00U\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TObject\\x11Basic ROOT object\\x00\\x00\\x00B\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x90\\x1b\\xc0-\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00t\\xff\\xff\\xff\\xffTStreamerString\\x00@\\x00\\x00\\\\\\x00\\x02@\\x00\\x00V\\x00\\x04@\\x00\\x00$\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fString\\x0fwrapped TString\\x00\\x00\\x00A\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TString\\x00\'\n\n# all useful streamers (histograms, etc.)\nstreamers = b\'@\\x00\\xa0u\\x00\\x05\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00C@\\x00\\x01X\\xff\\xff\\xff\\xffTStreamerInfo\\x00@\\x00\\x01B\\x00\\t@\\x00\\x00\\x18\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\nTObjString\\x00\\x9c\\x8eH\\x00\\x00\\x00\\x00\\x01@\\x00\\x01\\x18\\xff\\xff\\xff\\xffTObjArray\\x00@\\x00\\x01\\x06\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00u\\xff\\xff\\xff\\xffTStreamerBase\\x00@\\x00\\x00_\\x00\\x03@\\x00\\x00U\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TObject\\x11Basic ROOT object\\x00\\x00\\x00B\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x90\\x1b\\xc0-\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00t\\xff\\xff\\xff\\xffTStreamerString\\x00@\\x00\\x00\\\\\\x00\\x02@\\x00\\x00V\\x00\\x04@\\x00\\x00$\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fString\\x0fwrapped TString\\x00\\x00\\x00A\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TString\\x00@\\x00\\x01H\\x80\\x00\\x00[@\\x00\\x01@\\x00\\t@\\x00\\x00\\x15\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x07TObject\\x00\\x90\\x1b\\xc0-\\x00\\x00\\x00\\x01@\\x00\\x01\\x19\\x80\\x00\\x00\\x9b@\\x00\\x01\\x11\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00\\x87\\xff\\xff\\xff\\xffTStreamerBasicType\\x00@\\x00\\x00l\\x00\\x02@\\x00\\x00f\\x00\\x04@\\x00\\x00/\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfUniqueID\\x18object unique identifier\\x00\\x00\\x00\\r\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0cunsigned int@\\x00\\x00m\\x80\\x00\\x02\\x08@\\x00\\x00e\\x00\\x02@\\x00\\x00_\\x00\\x04@\\x00\\x00(\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fBits\\x15bit field status word\\x00\\x00\\x00\\x0f\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0cunsigned int\\x00@\\x00\\x01\\xb3\\x80\\x00\\x00[@\\x00\\x01\\xab\\x00\\t@\\x00\\x00\\x1c\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x0eTLorentzVector\\x00\\xe3\\xde\\xc1\\xa1\\x00\\x00\\x00\\x04@\\x00\\x01}\\x80\\x00\\x00\\x9b@\\x00\\x01u\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00g\\x80\\x00\\x00\\xc6@\\x00\\x00_\\x00\\x03@\\x00\\x00U\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TObject\\x11Basic ROOT object\\x00\\x00\\x00B\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x90\\x1b\\xc0-\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00s\\xff\\xff\\xff\\xffTStreamerObject\\x00@\\x00\\x00[\\x00\\x02@\\x00\\x00U\\x00\\x04@\\x00\\x00""\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02fP\\x123 vector component\\x00\\x00\\x00=\\x00\\x00\\x00(\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08TVector3@\\x00\\x00z\\x80\\x00\\x02\\x08@\\x00\\x00r\\x00\\x02@\\x00\\x00l\\x00\\x04@\\x00\\x00;\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02fE+time or energy of (x,y,z,t) or (px,py,pz,e)\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double\\x00@\\x00\\x01\\xb1\\x80\\x00\\x00[@\\x00\\x01\\xa9\\x00\\t@\\x00\\x00\\x16\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x08TVector3\\x00\\xab\\xb6\\xbe\\x1e\\x00\\x00\\x00\\x03@\\x00\\x01\\x81\\x80\\x00\\x00\\x9b@\\x00\\x01y\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00@\\x00\\x00g\\x80\\x00\\x00\\xc6@\\x00\\x00_\\x00\\x03@\\x00\\x00U\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TObject\\x11Basic ROOT object\\x00\\x00\\x00B\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x90\\x1b\\xc0-\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00O\\x80\\x00\\x02\\x08@\\x00\\x00G\\x00\\x02@\\x00\\x00A\\x00\\x04@\\x00\\x00\\x10\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02fX\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00O\\x80\\x00\\x02\\x08@\\x00\\x00G\\x00\\x02@\\x00\\x00A\\x00\\x04@\\x00\\x00\\x10\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02fY\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00O\\x80\\x00\\x02\\x08@\\x00\\x00G\\x00\\x02@\\x00\\x00A\\x00\\x04@\\x00\\x00\\x10\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02fZ\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double\\x00@\\x00\\x01v\\x80\\x00\\x00[@\\x00\\x01n\\x00\\t@\\x00\\x00\\x16\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x08TVector2\\x00\\x00\\x89\\xb7\\xf4\\x00\\x00\\x00\\x03@\\x00\\x01F\\x80\\x00\\x00\\x9b@\\x00\\x01>\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00g\\x80\\x00\\x00\\xc6@\\x00\\x00_\\x00\\x03@\\x00\\x00U\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TObject\\x11Basic ROOT object\\x00\\x00\\x00B\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x90\\x1b\\xc0-\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00g\\x80\\x00\\x02\\x08@\\x00\\x00_\\x00\\x02@\\x00\\x00Y\\x00\\x04@\\x00\\x00(\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02fX\\x18components of the vector\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00O\\x80\\x00\\x02\\x08@\\x00\\x00G\\x00\\x02@\\x00\\x00A\\x00\\x04@\\x00\\x00\\x10\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02fY\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double\\x00@\\x00\\x04\\r\\x80\\x00\\x00[@\\x00\\x04\\x05\\x00\\t@\\x00\\x00\\x16\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x08TProfile\\x00K\\xed\\xeeT\\x00\\x00\\x00\\x07@\\x00\\x03\\xdd\\x80\\x00\\x00\\x9b@\\x00\\x03\\xd5\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00@\\x00\\x00|\\x80\\x00\\x00\\xc6@\\x00\\x00t\\x00\\x03@\\x00\\x00j\\x00\\x04@\\x00\\x00;\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04TH1D)1-Dim histograms (one double per channel)\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf9\\xb1V\\x9f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x03@\\x00\\x00\\x85\\xff\\xff\\xff\\xffTStreamerObjectAny\\x00@\\x00\\x00j\\x00\\x02@\\x00\\x00d\\x00\\x04@\\x00\\x002\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfBinEntries\\x19number of entries per bin\\x00\\x00\\x00>\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TArrayD@\\x00\\x00s\\x80\\x00\\x02\\x08@\\x00\\x00k\\x00\\x02@\\x00\\x00e\\x00\\x04@\\x00\\x000\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfErrorMode\\x18Option to compute errors\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nEErrorType@\\x00\\x00k\\x80\\x00\\x02\\x08@\\x00\\x00c\\x00\\x02@\\x00\\x00]\\x00\\x04@\\x00\\x00,\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fYmin\\x19Lower limit in Y (if set)\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00k\\x80\\x00\\x02\\x08@\\x00\\x00c\\x00\\x02@\\x00\\x00]\\x00\\x04@\\x00\\x00,\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fYmax\\x19Upper limit in Y (if set)\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00i\\x80\\x00\\x02\\x08@\\x00\\x00a\\x00\\x02@\\x00\\x00[\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fTsumwy\\x15Total Sum of weight*Y\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fTsumwy2\\x17Total Sum of weight*Y*Y\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00\\x81\\x80\\x00\\x08\\xbf@\\x00\\x00y\\x00\\x02@\\x00\\x00s\\x00\\x04@\\x00\\x00A\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfBinSumw2*Array of sum of squares of weights per bin\\x00\\x00\\x00>\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TArrayD\\x00@\\x00\\x01#\\x80\\x00\\x00[@\\x00\\x01\\x1b\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH1D\\x00\\xf9\\xb1V\\x9f\\x00\\x00\\x00\\x03@\\x00\\x00\\xf7\\x80\\x00\\x00\\x9b@\\x00\\x00\\xef\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH1\\x1a1-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c7@\\xc4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x08@\\x00\\x00f\\x80\\x00\\x00\\xc6@\\x00\\x00^\\x00\\x03@\\x00\\x00T\\x00\\x04@\\x00\\x00%\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayD\\x10Array of doubles\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00q9\\xef4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x0cl\\x80\\x00\\x00[@\\x00\\x0cd\\x00\\t@\\x00\\x00\\x11\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x03TH1\\x00\\x1c7@\\xc4\\x00\\x00\\x00\\x08@\\x00\\x0cA\\x80\\x00\\x00\\x9b@\\x00\\x0c9\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1a\\x00\\x00\\x00\\x00@\\x00\\x00\\x7f\\x80\\x00\\x00\\xc6@\\x00\\x00w\\x00\\x03@\\x00\\x00m\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06TNamed*The basis for a named object (name, title)\\x00\\x00\\x00C\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xdf\\xb7J<\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00f\\x80\\x00\\x00\\xc6@\\x00\\x00^\\x00\\x03@\\x00\\x00T\\x00\\x04@\\x00\\x00%\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08TAttLine\\x0fLine attributes\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x07EI\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00k\\x80\\x00\\x00\\xc6@\\x00\\x00c\\x00\\x03@\\x00\\x00Y\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08TAttFill\\x14Fill area attributes\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xff\\xd9*\\x92\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00j\\x80\\x00\\x00\\xc6@\\x00\\x00b\\x00\\x03@\\x00\\x00X\\x00\\x04@\\x00\\x00)\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nTAttMarker\\x11Marker attributes\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00)\\x1d\\x8b\\xec\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00|\\x80\\x00\\x02\\x08@\\x00\\x00t\\x00\\x02@\\x00\\x00n\\x00\\x04@\\x00\\x00@\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fNcells+number of bins(1D), cells (2D) +U/Overflows\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00c\\x80\\x00\\x03\\xc7@\\x00\\x00[\\x00\\x02@\\x00\\x00U\\x00\\x04@\\x00\\x00%\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06fXaxis\\x11X axis descriptor\\x00\\x00\\x00=\\x00\\x00\\x00\\xd8\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05TAxis@\\x00\\x00c\\x80\\x00\\x03\\xc7@\\x00\\x00[\\x00\\x02@\\x00\\x00U\\x00\\x04@\\x00\\x00%\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06fYaxis\\x11Y axis descriptor\\x00\\x00\\x00=\\x00\\x00\\x00\\xd8\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05TAxis@\\x00\\x00c\\x80\\x00\\x03\\xc7@\\x00\\x00[\\x00\\x02@\\x00\\x00U\\x00\\x04@\\x00\\x00%\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06fZaxis\\x11Z axis descriptor\\x00\\x00\\x00=\\x00\\x00\\x00\\xd8\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05TAxis@\\x00\\x00{\\x80\\x00\\x02\\x08@\\x00\\x00s\\x00\\x02@\\x00\\x00m\\x00\\x04@\\x00\\x00=\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfBarOffset%(1000*offset) for bar charts or legos\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short@\\x00\\x00y\\x80\\x00\\x02\\x08@\\x00\\x00q\\x00\\x02@\\x00\\x00k\\x00\\x04@\\x00\\x00;\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfBarWidth$(1000*width) for bar charts or legos\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short@\\x00\\x00f\\x80\\x00\\x02\\x08@\\x00\\x00^\\x00\\x02@\\x00\\x00X\\x00\\x04@\\x00\\x00\\\'\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fEntries\\x11Number of entries\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00g\\x80\\x00\\x02\\x08@\\x00\\x00_\\x00\\x02@\\x00\\x00Y\\x00\\x04@\\x00\\x00(\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06fTsumw\\x14Total Sum of weights\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00s\\x80\\x00\\x02\\x08@\\x00\\x00k\\x00\\x02@\\x00\\x00e\\x00\\x04@\\x00\\x004\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fTsumw2\\x1fTotal Sum of squares of weights\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00i\\x80\\x00\\x02\\x08@\\x00\\x00a\\x00\\x02@\\x00\\x00[\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fTsumwx\\x15Total Sum of weight*X\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fTsumwx2\\x17Total Sum of weight*X*X\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00o\\x80\\x00\\x02\\x08@\\x00\\x00g\\x00\\x02@\\x00\\x00a\\x00\\x04@\\x00\\x000\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMaximum\\x1aMaximum value for plotting\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00o\\x80\\x00\\x02\\x08@\\x00\\x00g\\x00\\x02@\\x00\\x00a\\x00\\x04@\\x00\\x000\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMinimum\\x1aMinimum value for plotting\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfNormFactor\\x14Normalization factor\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00u\\x80\\x00\\x08\\xbf@\\x00\\x00m\\x00\\x02@\\x00\\x00g\\x00\\x04@\\x00\\x005\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fContour\\x1fArray to display contour levels\\x00\\x00\\x00>\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TArrayD@\\x00\\x00v\\x80\\x00\\x08\\xbf@\\x00\\x00n\\x00\\x02@\\x00\\x00h\\x00\\x04@\\x00\\x006\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06fSumw2""Array of sum of squares of weights\\x00\\x00\\x00>\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TArrayD@\\x00\\x00f\\x80\\x00\\x01?@\\x00\\x00^\\x00\\x02@\\x00\\x00X\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fOption\\x11histogram options\\x00\\x00\\x00A\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TString@\\x00\\x00\\x9c\\xff\\xff\\xff\\xffTStreamerObjectPointer\\x00@\\x00\\x00}\\x00\\x02@\\x00\\x00w\\x00\\x04@\\x00\\x00F\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfFunctions.->Pointer to list of functions (fits and user)\\x00\\x00\\x00?\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06TList*@\\x00\\x00a\\x80\\x00\\x02\\x08@\\x00\\x00Y\\x00\\x02@\\x00\\x00S\\x00\\x04@\\x00\\x00%\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfBufferSize\\x0cfBuffer size\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00\\x99\\xff\\xff\\xff\\xffTStreamerBasicPointer\\x00@\\x00\\x00{\\x00\\x02@\\x00\\x00a\\x00\\x04@\\x00\\x00/\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fBuffer\\x1a[fBufferSize] entry buffer\\x00\\x00\\x000\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07double*\\x00\\x00\\x00\\x08\\x0bfBufferSize\\x03TH1@\\x00\\x00\\x87\\x80\\x00\\x02\\x08@\\x00\\x00\\x7f\\x00\\x02@\\x00\\x00y\\x00\\x04@\\x00\\x00=\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0efBinStatErrOpt!option for bin statistical errors\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x11TH1::EBinErrorOpt@\\x00\\x00\\x9c\\x80\\x00\\x02\\x08@\\x00\\x00\\x94\\x00\\x02@\\x00\\x00\\x8e\\x00\\x04@\\x00\\x00P\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0efStatOverflows4per object flag to use under/overflows in statistics\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x13TH1::EStatOverflows\\x00@\\x00\\x01\\x82\\x80\\x00\\x00[@\\x00\\x01z\\x00\\t@\\x00\\x00\\x14\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x06TNamed\\x00\\xdf\\xb7J<\\x00\\x00\\x00\\x01@\\x00\\x01T\\x80\\x00\\x00\\x9b@\\x00\\x01L\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00g\\x80\\x00\\x00\\xc6@\\x00\\x00_\\x00\\x03@\\x00\\x00U\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TObject\\x11Basic ROOT object\\x00\\x00\\x00B\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x90\\x1b\\xc0-\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00d\\x80\\x00\\x01?@\\x00\\x00\\\\\\x00\\x02@\\x00\\x00V\\x00\\x04@\\x00\\x00$\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fName\\x11object identifier\\x00\\x00\\x00A\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TString@\\x00\\x00`\\x80\\x00\\x01?@\\x00\\x00X\\x00\\x02@\\x00\\x00R\\x00\\x04@\\x00\\x00 \\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06fTitle\\x0cobject title\\x00\\x00\\x00A\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TString\\x00@\\x00\\x01y\\x80\\x00\\x00[@\\x00\\x01q\\x00\\t@\\x00\\x00\\x16\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x08TAttLine\\x00\\x94\\x07EI\\x00\\x00\\x00\\x02@\\x00\\x01I\\x80\\x00\\x00\\x9b@\\x00\\x01A\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00`\\x80\\x00\\x02\\x08@\\x00\\x00X\\x00\\x02@\\x00\\x00R\\x00\\x04@\\x00\\x00""\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfLineColor\\nLine color\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short@\\x00\\x00`\\x80\\x00\\x02\\x08@\\x00\\x00X\\x00\\x02@\\x00\\x00R\\x00\\x04@\\x00\\x00""\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfLineStyle\\nLine style\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short@\\x00\\x00`\\x80\\x00\\x02\\x08@\\x00\\x00X\\x00\\x02@\\x00\\x00R\\x00\\x04@\\x00\\x00""\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfLineWidth\\nLine width\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short\\x00@\\x00\\x01\\x1f\\x80\\x00\\x00[@\\x00\\x01\\x17\\x00\\t@\\x00\\x00\\x16\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x08TAttFill\\x00\\xff\\xd9*\\x92\\x00\\x00\\x00\\x02@\\x00\\x00\\xef\\x80\\x00\\x00\\x9b@\\x00\\x00\\xe7\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00e\\x80\\x00\\x02\\x08@\\x00\\x00]\\x00\\x02@\\x00\\x00W\\x00\\x04@\\x00\\x00\\\'\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfFillColor\\x0fFill area color\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short@\\x00\\x00e\\x80\\x00\\x02\\x08@\\x00\\x00]\\x00\\x02@\\x00\\x00W\\x00\\x04@\\x00\\x00\\\'\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfFillStyle\\x0fFill area style\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short\\x00@\\x00\\x01\\x85\\x80\\x00\\x00[@\\x00\\x01}\\x00\\t@\\x00\\x00\\x18\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\nTAttMarker\\x00)\\x1d\\x8b\\xec\\x00\\x00\\x00\\x02@\\x00\\x01S\\x80\\x00\\x00\\x9b@\\x00\\x01K\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00d\\x80\\x00\\x02\\x08@\\x00\\x00\\\\\\x00\\x02@\\x00\\x00V\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0cfMarkerColor\\x0cMarker color\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short@\\x00\\x00d\\x80\\x00\\x02\\x08@\\x00\\x00\\\\\\x00\\x02@\\x00\\x00V\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0cfMarkerStyle\\x0cMarker style\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short@\\x00\\x00b\\x80\\x00\\x02\\x08@\\x00\\x00Z\\x00\\x02@\\x00\\x00T\\x00\\x04@\\x00\\x00$\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfMarkerSize\\x0bMarker size\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05float\\x00@\\x00\\x00\\xb3\\x80\\x00\\x00[@\\x00\\x00\\xab\\x00\\t@\\x00\\x00\\x14\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x06TArray\\x00\\x00p!\\xb2\\x00\\x00\\x00\\x01@\\x00\\x00\\x85\\x80\\x00\\x00\\x9b@\\x00\\x00}\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x00\\x00d\\x80\\x00\\x02\\x08@\\x00\\x00\\\\\\x00\\x02@\\x00\\x00V\\x00\\x04@\\x00\\x00(\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02fN\\x18Number of array elements\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int\\x00@\\x00\\x06\\t\\x80\\x00\\x00[@\\x00\\x06\\x01\\x00\\t@\\x00\\x00\\x13\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x05TAxis\\x00ZInp\\x00\\x00\\x00\\n@\\x00\\x05\\xdc\\x80\\x00\\x00\\x9b@\\x00\\x05\\xd4\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\r\\x00\\x00\\x00\\x00@\\x00\\x00\\x7f\\x80\\x00\\x00\\xc6@\\x00\\x00w\\x00\\x03@\\x00\\x00m\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06TNamed*The basis for a named object (name, title)\\x00\\x00\\x00C\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xdf\\xb7J<\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00f\\x80\\x00\\x00\\xc6@\\x00\\x00^\\x00\\x03@\\x00\\x00T\\x00\\x04@\\x00\\x00%\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08TAttAxis\\x0fAxis attributes\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\\\o\\xff>\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x04@\\x00\\x00^\\x80\\x00\\x02\\x08@\\x00\\x00V\\x00\\x02@\\x00\\x00P\\x00\\x04@\\x00\\x00""\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06fNbins\\x0eNumber of bins\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00g\\x80\\x00\\x02\\x08@\\x00\\x00_\\x00\\x02@\\x00\\x00Y\\x00\\x04@\\x00\\x00(\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fXmin\\x15low edge of first bin\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00h\\x80\\x00\\x02\\x08@\\x00\\x00`\\x00\\x02@\\x00\\x00Z\\x00\\x04@\\x00\\x00)\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fXmax\\x16upper edge of last bin\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00h\\x80\\x00\\x08\\xbf@\\x00\\x00`\\x00\\x02@\\x00\\x00Z\\x00\\x04@\\x00\\x00(\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06fXbins\\x14Bin edges array in X\\x00\\x00\\x00>\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TArrayD@\\x00\\x00d\\x80\\x00\\x02\\x08@\\x00\\x00\\\\\\x00\\x02@\\x00\\x00V\\x00\\x04@\\x00\\x00(\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06fFirst\\x14first bin to display\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00b\\x80\\x00\\x02\\x08@\\x00\\x00Z\\x00\\x02@\\x00\\x00T\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fLast\\x13last bin to display\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00q\\x80\\x00\\x02\\x08@\\x00\\x00i\\x00\\x02@\\x00\\x00c\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06fBits2\\x16second bit status word\\x00\\x00\\x00\\x0c\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0eunsigned short@\\x00\\x00\\x88\\x80\\x00\\x02\\x08@\\x00\\x00\\x80\\x00\\x02@\\x00\\x00z\\x00\\x04@\\x00\\x00K\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0cfTimeDisplay1on/off displaying time values instead of numerics\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04bool@\\x00\\x00\\x80\\x80\\x00\\x01?@\\x00\\x00x\\x00\\x02@\\x00\\x00r\\x00\\x04@\\x00\\x00@\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfTimeFormat\\\'Date&time format, ex: 09/12/99 12:34:00\\x00\\x00\\x00A\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TString@\\x00\\x00f\\x80\\x00\\x16\\xcb@\\x00\\x00^\\x00\\x02@\\x00\\x00X\\x00\\x04@\\x00\\x00#\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fLabels\\x0eList of labels\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nTHashList*@\\x00\\x00l\\x80\\x00\\x16\\xcb@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fModLabs\\x17List of modified labels\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06TList*\\x00@\\x00\\x05\\x0e\\x80\\x00\\x00[@\\x00\\x05\\x06\\x00\\t@\\x00\\x00\\x16\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x08TAttAxis\\x00\\\\o\\xff>\\x00\\x00\\x00\\x04@\\x00\\x04\\xde\\x80\\x00\\x00\\x9b@\\x00\\x04\\xd6\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0b\\x00\\x00\\x00\\x00@\\x00\\x00\\x80\\x80\\x00\\x02\\x08@\\x00\\x00x\\x00\\x02@\\x00\\x00r\\x00\\x04@\\x00\\x00D\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfNdivisions+Number of divisions(10000*n3 + 100*n2 + n1)\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00.\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfAxisColor\\x16Color of the line axis\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short@\\x00\\x00f\\x80\\x00\\x02\\x08@\\x00\\x00^\\x00\\x02@\\x00\\x00X\\x00\\x04@\\x00\\x00(\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfLabelColor\\x0fColor of labels\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short@\\x00\\x00e\\x80\\x00\\x02\\x08@\\x00\\x00]\\x00\\x02@\\x00\\x00W\\x00\\x04@\\x00\\x00\\\'\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfLabelFont\\x0fFont for labels\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short@\\x00\\x00h\\x80\\x00\\x02\\x08@\\x00\\x00`\\x00\\x02@\\x00\\x00Z\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0cfLabelOffset\\x10Offset of labels\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05float@\\x00\\x00d\\x80\\x00\\x02\\x08@\\x00\\x00\\\\\\x00\\x02@\\x00\\x00V\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfLabelSize\\x0eSize of labels\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05float@\\x00\\x00k\\x80\\x00\\x02\\x08@\\x00\\x00c\\x00\\x02@\\x00\\x00]\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfTickLength\\x14Length of tick marks\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05float@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00.\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0cfTitleOffset\\x14Offset of axis title\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05float@\\x00\\x00h\\x80\\x00\\x02\\x08@\\x00\\x00`\\x00\\x02@\\x00\\x00Z\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfTitleSize\\x12Size of axis title\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05float@\\x00\\x00j\\x80\\x00\\x02\\x08@\\x00\\x00b\\x00\\x02@\\x00\\x00\\\\\\x00\\x04@\\x00\\x00,\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfTitleColor\\x13Color of axis title\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short@\\x00\\x00i\\x80\\x00\\x02\\x08@\\x00\\x00a\\x00\\x02@\\x00\\x00[\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfTitleFont\\x13Font for axis title\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short\\x00@\\x00\\x00\\xb8\\x80\\x00\\x00[@\\x00\\x00\\xb0\\x00\\t@\\x00\\x00\\x17\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\tTHashList\\x00\\xcc~I\\xc1\\x00\\x00\\x00\\x00@\\x00\\x00\\x87\\x80\\x00\\x00\\x9b@\\x00\\x00\\x7f\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x00\\x00f\\x80\\x00\\x00\\xc6@\\x00\\x00^\\x00\\x03@\\x00\\x00T\\x00\\x04@\\x00\\x00%\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05TList\\x12Doubly linked list\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00i\\xc5\\xc3\\xbb\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x05\\x00@\\x00\\x00\\xc6\\x80\\x00\\x00[@\\x00\\x00\\xbe\\x00\\t@\\x00\\x00\\x13\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x05TList\\x00i\\xc5\\xc3\\xbb\\x00\\x00\\x00\\x05@\\x00\\x00\\x99\\x80\\x00\\x00\\x9b@\\x00\\x00\\x91\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x00\\x00x\\x80\\x00\\x00\\xc6@\\x00\\x00p\\x00\\x03@\\x00\\x00f\\x00\\x04@\\x00\\x007\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0eTSeqCollection\\x1bSequenceable collection ABC\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xfcl;\\xc6\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\xcf\\x80\\x00\\x00[@\\x00\\x00\\xc7\\x00\\t@\\x00\\x00\\x1c\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x0eTSeqCollection\\x00\\xfcl;\\xc6\\x00\\x00\\x00\\x00@\\x00\\x00\\x99\\x80\\x00\\x00\\x9b@\\x00\\x00\\x91\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x00\\x00x\\x80\\x00\\x00\\xc6@\\x00\\x00p\\x00\\x03@\\x00\\x00f\\x00\\x04@\\x00\\x007\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bTCollection\\x1eCollection abstract base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00W\\xe3\\xcb\\x9c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x03\\x00@\\x00\\x01\\x9b\\x80\\x00\\x00[@\\x00\\x01\\x93\\x00\\t@\\x00\\x00\\x19\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x0bTCollection\\x00W\\xe3\\xcb\\x9c\\x00\\x00\\x00\\x03@\\x00\\x01h\\x80\\x00\\x00\\x9b@\\x00\\x01`\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00g\\x80\\x00\\x00\\xc6@\\x00\\x00_\\x00\\x03@\\x00\\x00U\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TObject\\x11Basic ROOT object\\x00\\x00\\x00B\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x90\\x1b\\xc0-\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00i\\x80\\x00\\x01?@\\x00\\x00a\\x00\\x02@\\x00\\x00[\\x00\\x04@\\x00\\x00)\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fName\\x16name of the collection\\x00\\x00\\x00A\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TString@\\x00\\x00o\\x80\\x00\\x02\\x08@\\x00\\x00g\\x00\\x02@\\x00\\x00a\\x00\\x04@\\x00\\x003\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fSize number of elements in collection\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int\\x00@\\x00\\x00L\\x80\\x00\\x00[@\\x00\\x00D\\x00\\t@\\x00\\x00\\x15\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x07TString\\x00\\x00\\x01t\\x19\\x00\\x00\\x00\\x02@\\x00\\x00\\x1d\\x80\\x00\\x00\\x9b@\\x00\\x00\\x15\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x03\\xfc\\x80\\x00\\x00[@\\x00\\x03\\xf4\\x00\\t@\\x00\\x00\\x18\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\nTProfile2D\\x006\\xa1B\\xac\\x00\\x00\\x00\\x08@\\x00\\x03\\xca\\x80\\x00\\x00\\x9b@\\x00\\x03\\xc2\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00@\\x00\\x00|\\x80\\x00\\x00\\xc6@\\x00\\x00t\\x00\\x03@\\x00\\x00j\\x00\\x04@\\x00\\x00;\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04TH2D)2-Dim histograms (one double per channel)\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x7f\\xba\\x82\\xf0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x04@\\x00\\x00r\\x80\\x00\\x08\\xbf@\\x00\\x00j\\x00\\x02@\\x00\\x00d\\x00\\x04@\\x00\\x002\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfBinEntries\\x19number of entries per bin\\x00\\x00\\x00>\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TArrayD@\\x00\\x00s\\x80\\x00\\x02\\x08@\\x00\\x00k\\x00\\x02@\\x00\\x00e\\x00\\x04@\\x00\\x000\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfErrorMode\\x18Option to compute errors\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nEErrorType@\\x00\\x00k\\x80\\x00\\x02\\x08@\\x00\\x00c\\x00\\x02@\\x00\\x00]\\x00\\x04@\\x00\\x00,\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fZmin\\x19Lower limit in Z (if set)\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00k\\x80\\x00\\x02\\x08@\\x00\\x00c\\x00\\x02@\\x00\\x00]\\x00\\x04@\\x00\\x00,\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fZmax\\x19Upper limit in Z (if set)\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00i\\x80\\x00\\x02\\x08@\\x00\\x00a\\x00\\x02@\\x00\\x00[\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fTsumwz\\x15Total Sum of weight*Z\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fTsumwz2\\x17Total Sum of weight*Z*Z\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00\\x81\\x80\\x00\\x08\\xbf@\\x00\\x00y\\x00\\x02@\\x00\\x00s\\x00\\x04@\\x00\\x00A\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfBinSumw2*Array of sum of squares of weights per bin\\x00\\x00\\x00>\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TArrayD\\x00@\\x00\\x01#\\x80\\x00\\x00[@\\x00\\x01\\x1b\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH2D\\x00\\x7f\\xba\\x82\\xf0\\x00\\x00\\x00\\x04@\\x00\\x00\\xf7\\x80\\x00\\x00\\x9b@\\x00\\x00\\xef\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH2\\x1a2-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x824\\x7f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x05@\\x00\\x00f\\x80\\x00\\x00\\xc6@\\x00\\x00^\\x00\\x03@\\x00\\x00T\\x00\\x04@\\x00\\x00%\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayD\\x10Array of doubles\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00q9\\xef4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x02n\\x80\\x00\\x00[@\\x00\\x02f\\x00\\t@\\x00\\x00\\x11\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x03TH2\\x00\\x01\\x824\\x7f\\x00\\x00\\x00\\x05@\\x00\\x02C\\x80\\x00\\x00\\x9b@\\x00\\x02;\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH1\\x1a1-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c7@\\xc4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x08@\\x00\\x00e\\x80\\x00\\x02\\x08@\\x00\\x00]\\x00\\x02@\\x00\\x00W\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0cfScalefactor\\x0cScale factor\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00i\\x80\\x00\\x02\\x08@\\x00\\x00a\\x00\\x02@\\x00\\x00[\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fTsumwy\\x15Total Sum of weight*Y\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fTsumwy2\\x17Total Sum of weight*Y*Y\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fTsumwxy\\x17Total Sum of weight*X*Y\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double\\x00@\\x00\\x03\\xfc\\x80\\x00\\x00[@\\x00\\x03\\xf4\\x00\\t@\\x00\\x00\\x18\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\nTProfile3D\\x00\\xf6\\x0ch\\x14\\x00\\x00\\x00\\x08@\\x00\\x03\\xca\\x80\\x00\\x00\\x9b@\\x00\\x03\\xc2\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00@\\x00\\x00|\\x80\\x00\\x00\\xc6@\\x00\\x00t\\x00\\x03@\\x00\\x00j\\x00\\x04@\\x00\\x00;\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04TH3D)3-Dim histograms (one double per channel)\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\xb9\\xff\\x86\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x04@\\x00\\x00r\\x80\\x00\\x08\\xbf@\\x00\\x00j\\x00\\x02@\\x00\\x00d\\x00\\x04@\\x00\\x002\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfBinEntries\\x19number of entries per bin\\x00\\x00\\x00>\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TArrayD@\\x00\\x00s\\x80\\x00\\x02\\x08@\\x00\\x00k\\x00\\x02@\\x00\\x00e\\x00\\x04@\\x00\\x000\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfErrorMode\\x18Option to compute errors\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nEErrorType@\\x00\\x00k\\x80\\x00\\x02\\x08@\\x00\\x00c\\x00\\x02@\\x00\\x00]\\x00\\x04@\\x00\\x00,\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fTmin\\x19Lower limit in T (if set)\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00k\\x80\\x00\\x02\\x08@\\x00\\x00c\\x00\\x02@\\x00\\x00]\\x00\\x04@\\x00\\x00,\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fTmax\\x19Upper limit in T (if set)\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00i\\x80\\x00\\x02\\x08@\\x00\\x00a\\x00\\x02@\\x00\\x00[\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fTsumwt\\x15Total Sum of weight*T\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fTsumwt2\\x17Total Sum of weight*T*T\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00\\x81\\x80\\x00\\x08\\xbf@\\x00\\x00y\\x00\\x02@\\x00\\x00s\\x00\\x04@\\x00\\x00A\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfBinSumw2*Array of sum of squares of weights per bin\\x00\\x00\\x00>\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TArrayD\\x00@\\x00\\x01#\\x80\\x00\\x00[@\\x00\\x01\\x1b\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH3D\\x00d\\xb9\\xff\\x86\\x00\\x00\\x00\\x04@\\x00\\x00\\xf7\\x80\\x00\\x00\\x9b@\\x00\\x00\\xef\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH3\\x1a3-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00B\\xd2D_\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x06@\\x00\\x00f\\x80\\x00\\x00\\xc6@\\x00\\x00^\\x00\\x03@\\x00\\x00T\\x00\\x04@\\x00\\x00%\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayD\\x10Array of doubles\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00q9\\xef4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x04(\\x80\\x00\\x00[@\\x00\\x04 \\x00\\t@\\x00\\x00\\x11\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x03TH3\\x00B\\xd2D_\\x00\\x00\\x00\\x06@\\x00\\x03\\xfd\\x80\\x00\\x00\\x9b@\\x00\\x03\\xf5\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\t\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH1\\x1a1-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c7@\\xc4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x08@\\x00\\x00b\\x80\\x00\\x00\\xc6@\\x00\\x00Z\\x00\\x03@\\x00\\x00P\\x00\\x04@\\x00\\x00!\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06TAtt3D\\r3D attributes\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00uz\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00i\\x80\\x00\\x02\\x08@\\x00\\x00a\\x00\\x02@\\x00\\x00[\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fTsumwy\\x15Total Sum of weight*Y\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fTsumwy2\\x17Total Sum of weight*Y*Y\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fTsumwxy\\x17Total Sum of weight*X*Y\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00i\\x80\\x00\\x02\\x08@\\x00\\x00a\\x00\\x02@\\x00\\x00[\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fTsumwz\\x15Total Sum of weight*Z\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fTsumwz2\\x17Total Sum of weight*Z*Z\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fTsumwxz\\x17Total Sum of weight*X*Z\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00l\\x80\\x00\\x02\\x08@\\x00\\x00d\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fTsumwyz\\x17Total Sum of weight*Y*Z\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double\\x00@\\x00\\x00K\\x80\\x00\\x00[@\\x00\\x00C\\x00\\t@\\x00\\x00\\x14\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x06TAtt3D\\x00\\x00\\x00uz\\x00\\x00\\x00\\x01@\\x00\\x00\\x1d\\x80\\x00\\x00\\x9b@\\x00\\x00\\x15\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\xf1\\x80\\x00\\x00[@\\x00\\x00\\xe9\\x00\\t@\\x00\\x00\\x19\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x0bvector<int>\\x00\\x00\\x98;\\x88\\x00\\x00\\x00\\x06@\\x00\\x00\\xbe\\x80\\x00\\x00\\x9b@\\x00\\x00\\xb6\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x00\\x00\\x9d\\xff\\xff\\xff\\xffTStreamerSTL\\x00@\\x00\\x00\\x88\\x00\\x03@\\x00\\x00z\\x00\\x04@\\x00\\x00D\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04This2<Int_t> Used to call the proper TStreamerInfo case\\x00\\x00\\x01\\xf4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0bvector<int>\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x03\\x00@\\x00\\x00\\xed\\x80\\x00\\x00[@\\x00\\x00\\xe5\\x00\\t@\\x00\\x00\\x1c\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x0evector<double>\\x00\\x10\\x0eCd\\x00\\x00\\x00\\x06@\\x00\\x00\\xb7\\x80\\x00\\x00\\x9b@\\x00\\x00\\xaf\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x00\\x00\\x96\\x80\\x00A\\x08@\\x00\\x00\\x8e\\x00\\x03@\\x00\\x00\\x80\\x00\\x04@\\x00\\x00G\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04This5<Double_t> Used to call the proper TStreamerInfo case\\x00\\x00\\x01\\xf4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0evector<double>\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x08\\x00@\\x00\\x00\\xea\\x80\\x00\\x00[@\\x00\\x00\\xe2\\x00\\t@\\x00\\x00\\x1b\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\rvector<float>\\x00\\x05Z\\x16\\x9b\\x00\\x00\\x00\\x06@\\x00\\x00\\xb5\\x80\\x00\\x00\\x9b@\\x00\\x00\\xad\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x00\\x00\\x94\\x80\\x00A\\x08@\\x00\\x00\\x8c\\x00\\x03@\\x00\\x00~\\x00\\x04@\\x00\\x00F\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04This4<Float_t> Used to call the proper TStreamerInfo case\\x00\\x00\\x01\\xf4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\rvector<float>\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00@\\x00\\x00\\xe7\\x80\\x00\\x00[@\\x00\\x00\\xdf\\x00\\t@\\x00\\x00\\x1a\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x0cvector<long>\\x00\\x01\\xc8\\xb4)\\x00\\x00\\x00\\x06@\\x00\\x00\\xb3\\x80\\x00\\x00\\x9b@\\x00\\x00\\xab\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x00\\x00\\x92\\x80\\x00A\\x08@\\x00\\x00\\x8a\\x00\\x03@\\x00\\x00|\\x00\\x04@\\x00\\x00E\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04This3<Long_t> Used to call the proper TStreamerInfo case\\x00\\x00\\x01\\xf4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0cvector<long>\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x04\\x00@\\x00\\x00\\xe7\\x80\\x00\\x00[@\\x00\\x00\\xdf\\x00\\t@\\x00\\x00\\x1a\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x0cvector<char>\\x00\\x01\\xc8\\xb0?\\x00\\x00\\x00\\x06@\\x00\\x00\\xb3\\x80\\x00\\x00\\x9b@\\x00\\x00\\xab\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x00\\x00\\x92\\x80\\x00A\\x08@\\x00\\x00\\x8a\\x00\\x03@\\x00\\x00|\\x00\\x04@\\x00\\x00E\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04This3<Char_t> Used to call the proper TStreamerInfo case\\x00\\x00\\x01\\xf4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0cvector<char>\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00@\\x00\\x00\\xea\\x80\\x00\\x00[@\\x00\\x00\\xe2\\x00\\t@\\x00\\x00\\x1b\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\rvector<short>\\x00\\x05Z""G\\x00\\x00\\x00\\x06@\\x00\\x00\\xb5\\x80\\x00\\x00\\x9b@\\x00\\x00\\xad\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x00\\x00\\x94\\x80\\x00A\\x08@\\x00\\x00\\x8c\\x00\\x03@\\x00\\x00~\\x00\\x04@\\x00\\x00F\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04This4<Short_t> Used to call the proper TStreamerInfo case\\x00\\x00\\x01\\xf4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\rvector<short>\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00@\\x00\\x00\\xeb\\x80\\x00\\x00[@\\x00\\x00\\xe3\\x00\\t@\\x00\\x00\\x1c\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x0evector<string>\\x00\\x10\\x0er\\xbc\\x00\\x00\\x00\\x06@\\x00\\x00\\xb5\\x80\\x00\\x00\\x9b@\\x00\\x00\\xad\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x00\\x00\\x94\\x80\\x00A\\x08@\\x00\\x00\\x8c\\x00\\x03@\\x00\\x00~\\x00\\x04@\\x00\\x00E\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04This3<string> Used to call the proper TStreamerInfo case\\x00\\x00\\x01\\xf4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0evector<string>\\x00\\x00\\x00\\x01\\x00\\x00\\x00=\\x00@\\x00\\x11\\xe6\\x80\\x00\\x00[@\\x00\\x11\\xde\\x00\\t@\\x00\\x00\\x13\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x05TTree\\x00rd\\xe0\\x7f\\x00\\x00\\x00\\x14@\\x00\\x11\\xb9\\x80\\x00\\x00\\x9b@\\x00\\x11\\xb1\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00!\\x00\\x00\\x00\\x00@\\x00\\x00\\x7f\\x80\\x00\\x00\\xc6@\\x00\\x00w\\x00\\x03@\\x00\\x00m\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06TNamed*The basis for a named object (name, title)\\x00\\x00\\x00C\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xdf\\xb7J<\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00f\\x80\\x00\\x00\\xc6@\\x00\\x00^\\x00\\x03@\\x00\\x00T\\x00\\x04@\\x00\\x00%\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08TAttLine\\x0fLine attributes\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x07EI\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00k\\x80\\x00\\x00\\xc6@\\x00\\x00c\\x00\\x03@\\x00\\x00Y\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08TAttFill\\x14Fill area attributes\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xff\\xd9*\\x92\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00j\\x80\\x00\\x00\\xc6@\\x00\\x00b\\x00\\x03@\\x00\\x00X\\x00\\x04@\\x00\\x00)\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nTAttMarker\\x11Marker attributes\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00)\\x1d\\x8b\\xec\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00h\\x80\\x00\\x02\\x08@\\x00\\x00`\\x00\\x02@\\x00\\x00Z\\x00\\x04@\\x00\\x00\\\'\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fEntries\\x11Number of entries\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00\\x90\\x80\\x00\\x02\\x08@\\x00\\x00\\x88\\x00\\x02@\\x00\\x00\\x82\\x00\\x04@\\x00\\x00O\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfTotBytes8Total number of bytes in all branches before compression\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00\\x8f\\x80\\x00\\x02\\x08@\\x00\\x00\\x87\\x00\\x02@\\x00\\x00\\x81\\x00\\x04@\\x00\\x00N\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfZipBytes7Total number of bytes in all branches after compression\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00s\\x80\\x00\\x02\\x08@\\x00\\x00k\\x00\\x02@\\x00\\x00e\\x00\\x04@\\x00\\x002\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfSavedBytes\\x19Number of autosaved bytes\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00x\\x80\\x00\\x02\\x08@\\x00\\x00p\\x00\\x02@\\x00\\x00j\\x00\\x04@\\x00\\x007\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\rfFlushedBytes\\x1cNumber of auto-flushed bytes\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00v\\x80\\x00\\x02\\x08@\\x00\\x00n\\x00\\x02@\\x00\\x00h\\x00\\x04@\\x00\\x007\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fWeight""Tree weight (see TTree::SetWeight)\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00v\\x80\\x00\\x02\\x08@\\x00\\x00n\\x00\\x02@\\x00\\x00h\\x00\\x04@\\x00\\x00:\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0efTimerInterval\\x1eTimer interval in milliseconds\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00{\\x80\\x00\\x02\\x08@\\x00\\x00s\\x00\\x02@\\x00\\x00m\\x00\\x04@\\x00\\x00?\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfScanField\\\'Number of runs before prompting in Scan\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00o\\x80\\x00\\x02\\x08@\\x00\\x00g\\x00\\x02@\\x00\\x00a\\x00\\x04@\\x00\\x003\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fUpdate\\x1eUpdate frequency for EntryLoop\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00\\x9a\\x80\\x00\\x02\\x08@\\x00\\x00\\x92\\x00\\x02@\\x00\\x00\\x8c\\x00\\x04@\\x00\\x00^\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x16fDefaultEntryOffsetLen:Initial Length of fEntryOffset table in the basket buffers\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00\\x9d\\x80\\x00\\x02\\x08@\\x00\\x00\\x95\\x00\\x02@\\x00\\x00\\x8f\\x00\\x04@\\x00\\x00a\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0efNClusterRangeENumber of Cluster range in addition to the one defined by \\\'AutoFlush\\\'\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00\\x8f\\x80\\x00\\x02\\x08@\\x00\\x00\\x87\\x00\\x02@\\x00\\x00\\x81\\x00\\x04@\\x00\\x00N\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfMaxEntries5Maximum number of entries in case of circular buffers\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00\\x80\\x80\\x00\\x02\\x08@\\x00\\x00x\\x00\\x02@\\x00\\x00r\\x00\\x04@\\x00\\x00?\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\rfMaxEntryLoop$Maximum number of entries to process\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00\\x8a\\x80\\x00\\x02\\x08@\\x00\\x00\\x82\\x00\\x02@\\x00\\x00|\\x00\\x04@\\x00\\x00I\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0ffMaxVirtualSize,Maximum total size of buffers kept in memory\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00\\xae\\x80\\x00\\x02\\x08@\\x00\\x00\\xa6\\x00\\x02@\\x00\\x00\\xa0\\x00\\x04@\\x00\\x00m\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfAutoSaveVAutosave tree when fAutoSave entries written or -fAutoSave (compressed) bytes produced\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00\\xb3\\x80\\x00\\x02\\x08@\\x00\\x00\\xab\\x00\\x02@\\x00\\x00\\xa5\\x00\\x04@\\x00\\x00r\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfAutoFlushZAuto-flush tree when fAutoFlush entries written or -fAutoFlush (compressed) bytes produced\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00\\x86\\x80\\x00\\x02\\x08@\\x00\\x00~\\x00\\x02@\\x00\\x00x\\x00\\x04@\\x00\\x00E\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfEstimate.Number of entries to estimate histogram limits\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00\\xa8\\x80\\x00\\x17\\xd0@\\x00\\x00\\xa0\\x00\\x02@\\x00\\x00\\x81\\x00\\x04@\\x00\\x00M\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x10fClusterRangeEnd/[fNClusterRange] Last entry of a cluster range.\\x00\\x00\\x008\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\tLong64_t*\\x00\\x00\\x00\\x14\\x0efNClusterRange\\x05TTree@\\x00\\x00\\xba\\x80\\x00\\x17\\xd0@\\x00\\x00\\xb2\\x00\\x02@\\x00\\x00\\x93\\x00\\x04@\\x00\\x00_\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0cfClusterSizeE[fNClusterRange] Number of entries in each cluster for a given range.\\x00\\x00\\x008\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\tLong64_t*\\x00\\x00\\x00\\x14\\x0efNClusterRange\\x05TTree@\\x00\\x00\\xa0\\x80\\x00\\x08\\xbf@\\x00\\x00\\x98\\x00\\x02@\\x00\\x00\\x92\\x00\\x04@\\x00\\x00V\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfIOFeatures=IO features to define for newly-written baskets and branches.\\x00\\x00\\x00>\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x11ROOT::TIOFeatures@\\x00\\x00i\\x80\\x00\\x03\\xc7@\\x00\\x00a\\x00\\x02@\\x00\\x00[\\x00\\x04@\\x00\\x00\\\'\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfBranches\\x10List of Branches\\x00\\x00\\x00=\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\tTObjArray@\\x00\\x00\\x82\\x80\\x00\\x03\\xc7@\\x00\\x00z\\x00\\x02@\\x00\\x00t\\x00\\x04@\\x00\\x00@\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fLeaves+Direct pointers to individual branch leaves\\x00\\x00\\x00=\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\tTObjArray@\\x00\\x00\\x90\\x80\\x00\\x16\\xcb@\\x00\\x00\\x88\\x00\\x02@\\x00\\x00\\x82\\x00\\x04@\\x00\\x00Q\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fAliases;List of aliases for expressions based on the tree branches.\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06TList*@\\x00\\x00m\\x80\\x00\\x08\\xbf@\\x00\\x00e\\x00\\x02@\\x00\\x00_\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0cfIndexValues\\x13Sorted index values\\x00\\x00\\x00>\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TArrayD@\\x00\\x00j\\x80\\x00\\x08\\xbf@\\x00\\x00b\\x00\\x02@\\x00\\x00\\\\\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06fIndex\\x16Index of sorted values\\x00\\x00\\x00>\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TArrayI@\\x00\\x00\\x81\\x80\\x00\\x16\\xcb@\\x00\\x00y\\x00\\x02@\\x00\\x00s\\x00\\x04@\\x00\\x00:\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfTreeIndex""Pointer to the tree Index (if any)\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0eTVirtualIndex*@\\x00\\x00w\\x80\\x00\\x16\\xcb@\\x00\\x00o\\x00\\x02@\\x00\\x00i\\x00\\x04@\\x00\\x008\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fFriends""pointer to list of friend elements\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06TList*@\\x00\\x00\\x8f\\x80\\x00\\x16\\xcb@\\x00\\x00\\x87\\x00\\x02@\\x00\\x00\\x81\\x00\\x04@\\x00\\x00P\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfUserInfo9pointer to a list of user objects associated to this Tree\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06TList*@\\x00\\x00\\x84\\x80\\x00\\x16\\xcb@\\x00\\x00|\\x00\\x02@\\x00\\x00v\\x00\\x04@\\x00\\x00@\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfBranchRef(Branch supporting the TRefTable (if any)\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0bTBranchRef*\\x00@\\x00\\x00\\xb5\\x80\\x00\\x00[@\\x00\\x00\\xad\\x00\\t@\\x00\\x00\\x1f\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x11ROOT::TIOFeatures\\x00\\x1a\\xa1/\\x10\\x00\\x00\\x00\\x01@\\x00\\x00|\\x80\\x00\\x00\\x9b@\\x00\\x00t\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00@\\x00\\x00[\\x80\\x00\\x02\\x08@\\x00\\x00S\\x00\\x02@\\x00\\x00M\\x00\\x04@\\x00\\x00\\x15\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fIOBits\\x00\\x00\\x00\\x00\\x0b\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\runsigned char\\x00@\\x00\\x0b\\xb9\\x80\\x00\\x00[@\\x00\\x0b\\xb1\\x00\\t@\\x00\\x00\\x15\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x07TBranch\\x00\\x10\\x97\\x8a\\xac\\x00\\x00\\x00\\r@\\x00\\x0b\\x8a\\x80\\x00\\x00\\x9b@\\x00\\x0b\\x82\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x00@\\x00\\x00\\x7f\\x80\\x00\\x00\\xc6@\\x00\\x00w\\x00\\x03@\\x00\\x00m\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06TNamed*The basis for a named object (name, title)\\x00\\x00\\x00C\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xdf\\xb7J<\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00k\\x80\\x00\\x00\\xc6@\\x00\\x00c\\x00\\x03@\\x00\\x00Y\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08TAttFill\\x14Fill area attributes\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xff\\xd9*\\x92\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00r\\x80\\x00\\x02\\x08@\\x00\\x00j\\x00\\x02@\\x00\\x00d\\x00\\x04@\\x00\\x006\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfCompress\\x1fCompression level and algorithm\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00s\\x80\\x00\\x02\\x08@\\x00\\x00k\\x00\\x02@\\x00\\x00e\\x00\\x04@\\x00\\x007\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfBasketSize\\x1eInitial Size of  Basket Buffer\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00\\x93\\x80\\x00\\x02\\x08@\\x00\\x00\\x8b\\x00\\x02@\\x00\\x00\\x85\\x00\\x04@\\x00\\x00W\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0ffEntryOffsetLen:Initial Length of fEntryOffset table in the basket buffers\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00p\\x80\\x00\\x02\\x08@\\x00\\x00h\\x00\\x02@\\x00\\x00b\\x00\\x04@\\x00\\x004\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0cfWriteBasket\\x1aLast basket number written\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00\\x90\\x80\\x00\\x02\\x08@\\x00\\x00\\x88\\x00\\x02@\\x00\\x00\\x82\\x00\\x04@\\x00\\x00O\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0cfEntryNumber5Current entry number (last one filled in this branch)\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00\\x89\\x80\\x00\\x08\\xbf@\\x00\\x00\\x81\\x00\\x02@\\x00\\x00{\\x00\\x04@\\x00\\x00?\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfIOFeatures&IO features for newly-created baskets.\\x00\\x00\\x00>\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x11ROOT::TIOFeatures@\\x00\\x00f\\x80\\x00\\x02\\x08@\\x00\\x00^\\x00\\x02@\\x00\\x00X\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fOffset\\x15Offset of this branch\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00u\\x80\\x00\\x02\\x08@\\x00\\x00m\\x00\\x02@\\x00\\x00g\\x00\\x04@\\x00\\x009\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfMaxBaskets Maximum number of Baskets so far\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00g\\x80\\x00\\x02\\x08@\\x00\\x00_\\x00\\x02@\\x00\\x00Y\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfSplitLevel\\x12Branch split level\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00h\\x80\\x00\\x02\\x08@\\x00\\x00`\\x00\\x02@\\x00\\x00Z\\x00\\x04@\\x00\\x00\\\'\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fEntries\\x11Number of entries\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00\\x82\\x80\\x00\\x02\\x08@\\x00\\x00z\\x00\\x02@\\x00\\x00t\\x00\\x04@\\x00\\x00A\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfFirstEntry(Number of the first entry in this branch\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00\\x8e\\x80\\x00\\x02\\x08@\\x00\\x00\\x86\\x00\\x02@\\x00\\x00\\x80\\x00\\x04@\\x00\\x00M\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfTotBytes6Total number of bytes in all leaves before compression\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00\\x8d\\x80\\x00\\x02\\x08@\\x00\\x00\\x85\\x00\\x02@\\x00\\x00\\x7f\\x00\\x04@\\x00\\x00L\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfZipBytes5Total number of bytes in all leaves after compression\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00{\\x80\\x00\\x03\\xc7@\\x00\\x00s\\x00\\x02@\\x00\\x00m\\x00\\x04@\\x00\\x009\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfBranches""-> List of Branches of this branch\\x00\\x00\\x00=\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\tTObjArray@\\x00\\x00w\\x80\\x00\\x03\\xc7@\\x00\\x00o\\x00\\x02@\\x00\\x00i\\x00\\x04@\\x00\\x005\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fLeaves -> List of leaves of this branch\\x00\\x00\\x00=\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\tTObjArray@\\x00\\x00y\\x80\\x00\\x03\\xc7@\\x00\\x00q\\x00\\x02@\\x00\\x00k\\x00\\x04@\\x00\\x007\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fBaskets!-> List of baskets of this branch\\x00\\x00\\x00=\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\tTObjArray@\\x00\\x00\\x96\\x80\\x00\\x17\\xd0@\\x00\\x00\\x8e\\x00\\x02@\\x00\\x00p\\x00\\x04@\\x00\\x00A\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0cfBasketBytes\\\'[fMaxBaskets] Length of baskets on file\\x00\\x00\\x00+\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04int*\\x00\\x00\\x00\\r\\x0bfMaxBaskets\\x07TBranch@\\x00\\x00\\xa5\\x80\\x00\\x17\\xd0@\\x00\\x00\\x9d\\x00\\x02@\\x00\\x00\\x7f\\x00\\x04@\\x00\\x00K\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0cfBasketEntry1[fMaxBaskets] Table of first entry in each basket\\x00\\x00\\x008\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\tLong64_t*\\x00\\x00\\x00\\r\\x0bfMaxBaskets\\x07TBranch@\\x00\\x00\\x9d\\x80\\x00\\x17\\xd0@\\x00\\x00\\x95\\x00\\x02@\\x00\\x00w\\x00\\x04@\\x00\\x00C\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfBasketSeek*[fMaxBaskets] Addresses of baskets on file\\x00\\x00\\x008\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\tLong64_t*\\x00\\x00\\x00\\r\\x0bfMaxBaskets\\x07TBranch@\\x00\\x00\\xa0\\x80\\x00\\x01?@\\x00\\x00\\x98\\x00\\x02@\\x00\\x00\\x92\\x00\\x04@\\x00\\x00`\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfFileNameIName of file where buffers are stored ("""" if in same file as Tree header)\\x00\\x00\\x00A\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TString\\x00@\\x00\\x01\\xc6\\x80\\x00\\x00[@\\x00\\x01\\xbe\\x00\\t@\\x00\\x00\\x14\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x06TLeafI\\x00~j\\xae\\x19\\x00\\x00\\x00\\x01@\\x00\\x01\\x98\\x80\\x00\\x00\\x9b@\\x00\\x01\\x90\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00{\\x80\\x00\\x00\\xc6@\\x00\\x00s\\x00\\x03@\\x00\\x00i\\x00\\x04@\\x00\\x00:\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05TLeaf\\\'Leaf: description of a Branch data type\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00m\\x1e\\x81R\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00z\\x80\\x00\\x02\\x08@\\x00\\x00r\\x00\\x02@\\x00\\x00l\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMinimum(Minimum value if leaf range is specified\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00z\\x80\\x00\\x02\\x08@\\x00\\x00r\\x00\\x02@\\x00\\x00l\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMaximum(Maximum value if leaf range is specified\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int\\x00@\\x00\\x03\\xe8\\x80\\x00\\x00[@\\x00\\x03\\xe0\\x00\\t@\\x00\\x00\\x13\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x05TLeaf\\x00m\\x1e\\x81R\\x00\\x00\\x00\\x02@\\x00\\x03\\xbb\\x80\\x00\\x00\\x9b@\\x00\\x03\\xb3\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07\\x00\\x00\\x00\\x00@\\x00\\x00\\x7f\\x80\\x00\\x00\\xc6@\\x00\\x00w\\x00\\x03@\\x00\\x00m\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06TNamed*The basis for a named object (name, title)\\x00\\x00\\x00C\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xdf\\xb7J<\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00\\x81\\x80\\x00\\x02\\x08@\\x00\\x00y\\x00\\x02@\\x00\\x00s\\x00\\x04@\\x00\\x00E\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04fLen3Number of fixed length elements in the leaf\\\'s data.\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00t\\x80\\x00\\x02\\x08@\\x00\\x00l\\x00\\x02@\\x00\\x00f\\x00\\x04@\\x00\\x008\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fLenType""Number of bytes for this data type\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00v\\x80\\x00\\x02\\x08@\\x00\\x00n\\x00\\x02@\\x00\\x00h\\x00\\x04@\\x00\\x00:\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fOffset%Offset in ClonesArray object (if one)\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00\\x81\\x80\\x00\\x02\\x08@\\x00\\x00y\\x00\\x02@\\x00\\x00s\\x00\\x04@\\x00\\x00D\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fIsRange.(=kTRUE if leaf has a range, kFALSE otherwise)\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04bool@\\x00\\x00|\\x80\\x00\\x02\\x08@\\x00\\x00t\\x00\\x02@\\x00\\x00n\\x00\\x04@\\x00\\x00?\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfIsUnsigned&(=kTRUE if unsigned, kFALSE otherwise)\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04bool@\\x00\\x00\\x9b\\x80\\x00\\x16\\xcb@\\x00\\x00\\x93\\x00\\x02@\\x00\\x00\\x8d\\x00\\x04@\\x00\\x00\\\\\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfLeafCountDPointer to Leaf count if variable length (we do not own the counter)\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06TLeaf*\\x00@\\x00\\x01\\xcc\\x80\\x00\\x00[@\\x00\\x01\\xc4\\x00\\t@\\x00\\x00\\x14\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x06TLeafD\\x00\\x11\\x8e\\x87v\\x00\\x00\\x00\\x01@\\x00\\x01\\x9e\\x80\\x00\\x00\\x9b@\\x00\\x01\\x96\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00{\\x80\\x00\\x00\\xc6@\\x00\\x00s\\x00\\x03@\\x00\\x00i\\x00\\x04@\\x00\\x00:\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05TLeaf\\\'Leaf: description of a Branch data type\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00m\\x1e\\x81R\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00}\\x80\\x00\\x02\\x08@\\x00\\x00u\\x00\\x02@\\x00\\x00o\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMinimum(Minimum value if leaf range is specified\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00}\\x80\\x00\\x02\\x08@\\x00\\x00u\\x00\\x02@\\x00\\x00o\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMaximum(Maximum value if leaf range is specified\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double\\x00@\\x00\\x01\\xca\\x80\\x00\\x00[@\\x00\\x01\\xc2\\x00\\t@\\x00\\x00\\x14\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x06TLeafF\\x00:\\xdd\\x9dr\\x00\\x00\\x00\\x01@\\x00\\x01\\x9c\\x80\\x00\\x00\\x9b@\\x00\\x01\\x94\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00{\\x80\\x00\\x00\\xc6@\\x00\\x00s\\x00\\x03@\\x00\\x00i\\x00\\x04@\\x00\\x00:\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05TLeaf\\\'Leaf: description of a Branch data type\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00m\\x1e\\x81R\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00|\\x80\\x00\\x02\\x08@\\x00\\x00t\\x00\\x02@\\x00\\x00n\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMinimum(Minimum value if leaf range is specified\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05float@\\x00\\x00|\\x80\\x00\\x02\\x08@\\x00\\x00t\\x00\\x02@\\x00\\x00n\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMaximum(Maximum value if leaf range is specified\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05float\\x00@\\x00\\x01\\xd0\\x80\\x00\\x00[@\\x00\\x01\\xc8\\x00\\t@\\x00\\x00\\x14\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x06TLeafL\\x00\\xde2\\x08b\\x00\\x00\\x00\\x01@\\x00\\x01\\xa2\\x80\\x00\\x00\\x9b@\\x00\\x01\\x9a\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00{\\x80\\x00\\x00\\xc6@\\x00\\x00s\\x00\\x03@\\x00\\x00i\\x00\\x04@\\x00\\x00:\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05TLeaf\\\'Leaf: description of a Branch data type\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00m\\x1e\\x81R\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00\\x7f\\x80\\x00\\x02\\x08@\\x00\\x00w\\x00\\x02@\\x00\\x00q\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMinimum(Minimum value if leaf range is specified\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t@\\x00\\x00\\x7f\\x80\\x00\\x02\\x08@\\x00\\x00w\\x00\\x02@\\x00\\x00q\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMaximum(Maximum value if leaf range is specified\\x00\\x00\\x00\\x10\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08Long64_t\\x00@\\x00\\x01\\xc8\\x80\\x00\\x00[@\\x00\\x01\\xc0\\x00\\t@\\x00\\x00\\x14\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x06TLeafB\\x00\\x0f\\x1eK^\\x00\\x00\\x00\\x01@\\x00\\x01\\x9a\\x80\\x00\\x00\\x9b@\\x00\\x01\\x92\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00{\\x80\\x00\\x00\\xc6@\\x00\\x00s\\x00\\x03@\\x00\\x00i\\x00\\x04@\\x00\\x00:\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05TLeaf\\\'Leaf: description of a Branch data type\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00m\\x1e\\x81R\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00{\\x80\\x00\\x02\\x08@\\x00\\x00s\\x00\\x02@\\x00\\x00m\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMinimum(Minimum value if leaf range is specified\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04char@\\x00\\x00{\\x80\\x00\\x02\\x08@\\x00\\x00s\\x00\\x02@\\x00\\x00m\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMaximum(Maximum value if leaf range is specified\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04char\\x00@\\x00\\x01\\xca\\x80\\x00\\x00[@\\x00\\x01\\xc2\\x00\\t@\\x00\\x00\\x14\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x06TLeafS\\x00\\x15\\x0c\\xee\\xcf\\x00\\x00\\x00\\x01@\\x00\\x01\\x9c\\x80\\x00\\x00\\x9b@\\x00\\x01\\x94\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00{\\x80\\x00\\x00\\xc6@\\x00\\x00s\\x00\\x03@\\x00\\x00i\\x00\\x04@\\x00\\x00:\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05TLeaf\\\'Leaf: description of a Branch data type\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00m\\x1e\\x81R\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00|\\x80\\x00\\x02\\x08@\\x00\\x00t\\x00\\x02@\\x00\\x00n\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMinimum(Minimum value if leaf range is specified\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short@\\x00\\x00|\\x80\\x00\\x02\\x08@\\x00\\x00t\\x00\\x02@\\x00\\x00n\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMaximum(Maximum value if leaf range is specified\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short\\x00@\\x00\\x01\\xc8\\x80\\x00\\x00[@\\x00\\x01\\xc0\\x00\\t@\\x00\\x00\\x14\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x06TLeafO\\x00\\x02\\xaeH\\xd3\\x00\\x00\\x00\\x01@\\x00\\x01\\x9a\\x80\\x00\\x00\\x9b@\\x00\\x01\\x92\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00{\\x80\\x00\\x00\\xc6@\\x00\\x00s\\x00\\x03@\\x00\\x00i\\x00\\x04@\\x00\\x00:\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05TLeaf\\\'Leaf: description of a Branch data type\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00m\\x1e\\x81R\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00{\\x80\\x00\\x02\\x08@\\x00\\x00s\\x00\\x02@\\x00\\x00m\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMinimum(Minimum value if leaf range is specified\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04bool@\\x00\\x00{\\x80\\x00\\x02\\x08@\\x00\\x00s\\x00\\x02@\\x00\\x00m\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMaximum(Maximum value if leaf range is specified\\x00\\x00\\x00\\x12\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04bool\\x00@\\x00\\x05\\xf1\\x80\\x00\\x00[@\\x00\\x05\\xe9\\x00\\t@\\x00\\x00\\x1c\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x0eTBranchElement\\x00\\xe7O^c\\x00\\x00\\x00\\n@\\x00\\x05\\xbb\\x80\\x00\\x00\\x9b@\\x00\\x05\\xb3\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0c\\x00\\x00\\x00\\x00@\\x00\\x00g\\x80\\x00\\x00\\xc6@\\x00\\x00_\\x00\\x03@\\x00\\x00U\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TBranch\\x11Branch descriptor\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x10\\x97\\x8a\\xac\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\r@\\x00\\x00w\\x80\\x00\\x01?@\\x00\\x00o\\x00\\x02@\\x00\\x00i\\x00\\x04@\\x00\\x007\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfClassName\\x1fClass name of referenced object\\x00\\x00\\x00A\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TString@\\x00\\x00m\\x80\\x00\\x01?@\\x00\\x00e\\x00\\x02@\\x00\\x00_\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfParentName\\x14Name of parent class\\x00\\x00\\x00A\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TString@\\x00\\x00\\x7f\\x80\\x00\\x01?@\\x00\\x00w\\x00\\x02@\\x00\\x00q\\x00\\x04@\\x00\\x00?\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfClonesName&Name of class in TClonesArray (if any)\\x00\\x00\\x00A\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07TString@\\x00\\x00m\\x80\\x00\\x02\\x08@\\x00\\x00e\\x00\\x02@\\x00\\x00_\\x00\\x04@\\x00\\x00(\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfCheckSum\\x11CheckSum of class\\x00\\x00\\x00\\r\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0cunsigned int@\\x00\\x00p\\x80\\x00\\x02\\x08@\\x00\\x00h\\x00\\x02@\\x00\\x00b\\x00\\x04@\\x00\\x002\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\rfClassVersion\\x17Version number of class\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05short@\\x00\\x00k\\x80\\x00\\x02\\x08@\\x00\\x00c\\x00\\x02@\\x00\\x00]\\x00\\x04@\\x00\\x00/\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03fID\\x1eelement serial number in fInfo\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00Z\\x80\\x00\\x02\\x08@\\x00\\x00R\\x00\\x02@\\x00\\x00L\\x00\\x04@\\x00\\x00\\x1e\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fType\\x0bbranch type\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00k\\x80\\x00\\x02\\x08@\\x00\\x00c\\x00\\x02@\\x00\\x00]\\x00\\x04@\\x00\\x00/\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\rfStreamerType\\x14branch streamer type\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00\\x86\\x80\\x00\\x02\\x08@\\x00\\x00~\\x00\\x02@\\x00\\x00x\\x00\\x04@\\x00\\x00J\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMaximum4Maximum entries for a TClonesArray or variable array\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00\\x87\\x80\\x00\\x16\\xcb@\\x00\\x00\\x7f\\x00\\x02@\\x00\\x00y\\x00\\x04@\\x00\\x00?\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0cfBranchCount%pointer to primary branchcount branch\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0fTBranchElement*@\\x00\\x00\\x8a\\x80\\x00\\x16\\xcb@\\x00\\x00\\x82\\x00\\x02@\\x00\\x00|\\x00\\x04@\\x00\\x00B\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\rfBranchCount2\\\'pointer to secondary branchcount branch\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0fTBranchElement*\\x00@\\x00\\x01\\x9b\\x80\\x00\\x00[@\\x00\\x01\\x93\\x00\\t@\\x00\\x00\\x1a\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x0cTLeafElement\\x00\\xa0O\\x88\\x93\\x00\\x00\\x00\\x01@\\x00\\x01g\\x80\\x00\\x00\\x9b@\\x00\\x01_\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00{\\x80\\x00\\x00\\xc6@\\x00\\x00s\\x00\\x03@\\x00\\x00i\\x00\\x04@\\x00\\x00:\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05TLeaf\\\'Leaf: description of a Branch data type\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00m\\x1e\\x81R\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00k\\x80\\x00\\x02\\x08@\\x00\\x00c\\x00\\x02@\\x00\\x00]\\x00\\x04@\\x00\\x00/\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03fID\\x1eelement serial number in fInfo\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00X\\x80\\x00\\x02\\x08@\\x00\\x00P\\x00\\x02@\\x00\\x00J\\x00\\x04@\\x00\\x00\\x1c\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fType\\tleaf type\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int\\x00@\\x00\\x01\\xc6\\x80\\x00\\x00[@\\x00\\x01\\xbe\\x00\\t@\\x00\\x00\\x14\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x06TLeafC\\x00\\xfb\\xe3\\xb2\\xf3\\x00\\x00\\x00\\x01@\\x00\\x01\\x98\\x80\\x00\\x00\\x9b@\\x00\\x01\\x90\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00{\\x80\\x00\\x00\\xc6@\\x00\\x00s\\x00\\x03@\\x00\\x00i\\x00\\x04@\\x00\\x00:\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05TLeaf\\\'Leaf: description of a Branch data type\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00m\\x1e\\x81R\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00z\\x80\\x00\\x02\\x08@\\x00\\x00r\\x00\\x02@\\x00\\x00l\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMinimum(Minimum value if leaf range is specified\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00z\\x80\\x00\\x02\\x08@\\x00\\x00r\\x00\\x02@\\x00\\x00l\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMaximum(Maximum value if leaf range is specified\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int\\x00@\\x00\\x010\\x80\\x00\\x00[@\\x00\\x01(\\x00\\t@\\x00\\x00\\x18\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\nTBranchRef\\x00#`\\xb3\\xfd\\x00\\x00\\x00\\x01@\\x00\\x00\\xfe\\x80\\x00\\x00\\x9b@\\x00\\x00\\xf6\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00g\\x80\\x00\\x00\\xc6@\\x00\\x00_\\x00\\x03@\\x00\\x00U\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TBranch\\x11Branch descriptor\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x10\\x97\\x8a\\xac\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\r@\\x00\\x00r\\x80\\x00\\x16\\xcb@\\x00\\x00j\\x00\\x02@\\x00\\x00d\\x00\\x04@\\x00\\x00/\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\tfRefTable\\x18pointer to the TRefTable\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nTRefTable*\\x00@\\x00\\x02\\xdc\\x80\\x00\\x00[@\\x00\\x02\\xd4\\x00\\t@\\x00\\x00\\x17\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\tTRefTable\\x00\\x8c\\x89[\\x85\\x00\\x00\\x00\\x03@\\x00\\x02\\xab\\x80\\x00\\x00\\x9b@\\x00\\x02\\xa3\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x00@\\x00\\x00g\\x80\\x00\\x00\\xc6@\\x00\\x00_\\x00\\x03@\\x00\\x00U\\x00\\x04@\\x00\\x00&\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TObject\\x11Basic ROOT object\\x00\\x00\\x00B\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x90\\x1b\\xc0-\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00o\\x80\\x00\\x02\\x08@\\x00\\x00g\\x00\\x02@\\x00\\x00a\\x00\\x04@\\x00\\x003\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fSize dummy for backward compatibility\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00\\xa2\\x80\\x00\\x16\\xcb@\\x00\\x00\\x9a\\x00\\x02@\\x00\\x00\\x94\\x00\\x04@\\x00\\x00_\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fParentsIarray of Parent objects  (eg TTree branch) holding the referenced objects\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nTObjArray*@\\x00\\x00q\\x80\\x00\\x16\\xcb@\\x00\\x00i\\x00\\x02@\\x00\\x00c\\x00\\x04@\\x00\\x000\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06fOwner\\x1cObject owning this TRefTable\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x08TObject*@\\x00\\x00\\x91\\x80\\x00A\\x08@\\x00\\x00\\x89\\x00\\x03@\\x00\\x00{\\x00\\x04@\\x00\\x00B\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\rfProcessGUIDs\\\'UUIDs of TProcessIDs used in fParentIDs\\x00\\x00\\x01\\xf4\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0evector<string>\\x00\\x00\\x00\\x01\\x00\\x00\\x00=\\x00@\\x00\\x01\\xb8\\x80\\x00\\x00[@\\x00\\x01\\xb0\\x00\\t@\\x00\\x00\\x17\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\tTObjArray\\x00\\xa9\\x9eeR\\x00\\x00\\x00\\x03@\\x00\\x01\\x87\\x80\\x00\\x00\\x9b@\\x00\\x01\\x7f\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00@\\x00\\x00x\\x80\\x00\\x00\\xc6@\\x00\\x00p\\x00\\x03@\\x00\\x00f\\x00\\x04@\\x00\\x007\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0eTSeqCollection\\x1bSequenceable collection ABC\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xfcl;\\xc6\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x00@\\x00\\x00m\\x80\\x00\\x02\\x08@\\x00\\x00e\\x00\\x02@\\x00\\x00_\\x00\\x04@\\x00\\x001\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x0bfLowerBound\\x18Lower bound of the array\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00y\\x80\\x00\\x02\\x08@\\x00\\x00q\\x00\\x02@\\x00\\x00k\\x00\\x04@\\x00\\x00=\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x05fLast*Last element in array containing an object\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int\\x00@\\x00\\x05\\x90\\x80\\x00\\x00[@\\x00\\x05\\x88\\x00\\t@\\x00\\x00\\x14\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x06TGraph\\x00\\x05\\xf7\\xf4e\\x00\\x00\\x00\\x04@\\x00\\x05b\\x80\\x00\\x00\\x9b@\\x00\\x05Z\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0b\\x00\\x00\\x00\\x00@\\x00\\x00\\x7f\\x80\\x00\\x00\\xc6@\\x00\\x00w\\x00\\x03@\\x00\\x00m\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06TNamed*The basis for a named object (name, title)\\x00\\x00\\x00C\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xdf\\xb7J<\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00f\\x80\\x00\\x00\\xc6@\\x00\\x00^\\x00\\x03@\\x00\\x00T\\x00\\x04@\\x00\\x00%\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08TAttLine\\x0fLine attributes\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x94\\x07EI\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00k\\x80\\x00\\x00\\xc6@\\x00\\x00c\\x00\\x03@\\x00\\x00Y\\x00\\x04@\\x00\\x00*\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08TAttFill\\x14Fill area attributes\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xff\\xd9*\\x92\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00j\\x80\\x00\\x00\\xc6@\\x00\\x00b\\x00\\x03@\\x00\\x00X\\x00\\x04@\\x00\\x00)\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nTAttMarker\\x11Marker attributes\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00)\\x1d\\x8b\\xec\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x02@\\x00\\x00n\\x80\\x00\\x02\\x08@\\x00\\x00f\\x00\\x02@\\x00\\x00`\\x00\\x04@\\x00\\x002\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fNpoints\\x1cNumber of points <= fMaxSize\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03int@\\x00\\x00\\x80\\x80\\x00\\x17\\xd0@\\x00\\x00x\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00,\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02fX\\x1c[fNpoints] array of X points\\x00\\x00\\x000\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07double*\\x00\\x00\\x00\\x04\\x08fNpoints\\x06TGraph@\\x00\\x00\\x80\\x80\\x00\\x17\\xd0@\\x00\\x00x\\x00\\x02@\\x00\\x00^\\x00\\x04@\\x00\\x00,\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x02fY\\x1c[fNpoints] array of Y points\\x00\\x00\\x000\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x07double*\\x00\\x00\\x00\\x04\\x08fNpoints\\x06TGraph@\\x00\\x00\\x83\\x80\\x00\\x16\\xcb@\\x00\\x00{\\x00\\x02@\\x00\\x00u\\x00\\x04@\\x00\\x00D\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfFunctions,Pointer to list of functions (fits and user)\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06TList*@\\x00\\x00\\x80\\x80\\x00\\x16\\xcb@\\x00\\x00x\\x00\\x02@\\x00\\x00r\\x00\\x04@\\x00\\x00B\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfHistogram*Pointer to histogram used for drawing axis\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05TH1F*@\\x00\\x00w\\x80\\x00\\x02\\x08@\\x00\\x00o\\x00\\x02@\\x00\\x00i\\x00\\x04@\\x00\\x008\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMinimum""Minimum value for plotting along y\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00w\\x80\\x00\\x02\\x08@\\x00\\x00o\\x00\\x02@\\x00\\x00i\\x00\\x04@\\x00\\x008\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMaximum""Maximum value for plotting along y\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double\\x00@\\x00\\x01""\\x80\\x00\\x00[@\\x00\\x01\\x1a\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH1F\\x00\\xe2\\x93\\x96D\\x00\\x00\\x00\\x03@\\x00\\x00\\xf6\\x80\\x00\\x00\\x9b@\\x00\\x00\\xee\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH1\\x1a1-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c7@\\xc4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x08@\\x00\\x00e\\x80\\x00\\x00\\xc6@\\x00\\x00]\\x00\\x03@\\x00\\x00S\\x00\\x04@\\x00\\x00$\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayF\\x0fArray of floats\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00Z\\x0b\\xf6\\xf1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x01:\\x80\\x00\\x00[@\\x00\\x012\\x00\\t@\\x00\\x00\\x15\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x07TArrayF\\x00Z\\x0b\\xf6\\xf1\\x00\\x00\\x00\\x01@\\x00\\x01\\x0b\\x80\\x00\\x00\\x9b@\\x00\\x01\\x03\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00n\\x80\\x00\\x00\\xc6@\\x00\\x00f\\x00\\x03@\\x00\\x00\\\\\\x00\\x04@\\x00\\x00-\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06TArray\\x19Abstract array base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00p!\\xb2\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00x\\x80\\x00\\x17\\xd0@\\x00\\x00p\\x00\\x02@\\x00\\x00\\\\\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06fArray\\x17[fN] Array of fN floats\\x00\\x00\\x00-\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06float*\\x00\\x00\\x00\\x01\\x02fN\\x06TArray\\x00@\\x00\\x03F\\x80\\x00\\x00[@\\x00\\x03>\\x00\\t@\\x00\\x00\\x19\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x0bTMultiGraph\\x00\\xe0\\x89<\\xd5\\x00\\x00\\x00\\x02@\\x00\\x03\\x13\\x80\\x00\\x00\\x9b@\\x00\\x03\\x0b\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\x00@\\x00\\x00\\x7f\\x80\\x00\\x00\\xc6@\\x00\\x00w\\x00\\x03@\\x00\\x00m\\x00\\x04@\\x00\\x00>\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x06TNamed*The basis for a named object (name, title)\\x00\\x00\\x00C\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xdf\\xb7J<\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01@\\x00\\x00n\\x80\\x00\\x16\\xcb@\\x00\\x00f\\x00\\x02@\\x00\\x00`\\x00\\x04@\\x00\\x00/\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07fGraphs\\x1aPointer to list of TGraphs\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06TList*@\\x00\\x00\\x83\\x80\\x00\\x16\\xcb@\\x00\\x00{\\x00\\x02@\\x00\\x00u\\x00\\x04@\\x00\\x00D\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfFunctions,Pointer to list of functions (fits and user)\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06TList*@\\x00\\x00\\x80\\x80\\x00\\x16\\xcb@\\x00\\x00x\\x00\\x02@\\x00\\x00r\\x00\\x04@\\x00\\x00B\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\nfHistogram*Pointer to histogram used for drawing axis\\x00\\x00\\x00@\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05TH1F*@\\x00\\x00w\\x80\\x00\\x02\\x08@\\x00\\x00o\\x00\\x02@\\x00\\x00i\\x00\\x04@\\x00\\x008\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMaximum""Maximum value for plotting along y\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double@\\x00\\x00w\\x80\\x00\\x02\\x08@\\x00\\x00o\\x00\\x02@\\x00\\x00i\\x00\\x04@\\x00\\x008\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08fMinimum""Minimum value for plotting along y\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x06double\\x00@\\x00\\x01!\\x80\\x00\\x00[@\\x00\\x01\\x19\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH1C\\x006\\xf6\\xe4\\xad\\x00\\x00\\x00\\x03@\\x00\\x00\\xf5\\x80\\x00\\x00\\x9b@\\x00\\x00\\xed\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH1\\x1a1-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c7@\\xc4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x08@\\x00\\x00d\\x80\\x00\\x00\\xc6@\\x00\\x00\\\\\\x00\\x03@\\x00\\x00R\\x00\\x04@\\x00\\x00#\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayC\\x0eArray of chars\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xae\\x87\\x996\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x01 \\x80\\x00\\x00[@\\x00\\x01\\x18\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH1I\\x00bud\\xf6\\x00\\x00\\x00\\x03@\\x00\\x00\\xf4\\x80\\x00\\x00\\x9b@\\x00\\x00\\xec\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH1\\x1a1-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c7@\\xc4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x08@\\x00\\x00c\\x80\\x00\\x00\\xc6@\\x00\\x00[\\x00\\x03@\\x00\\x00Q\\x00\\x04@\\x00\\x00""\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayI\\rArray of ints\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xd9\\xd5q\\xc7\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x01""\\x80\\x00\\x00[@\\x00\\x01\\x1a\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH1S\\x00\\x8cM\\x9d\\xcb\\x00\\x00\\x00\\x03@\\x00\\x00\\xf6\\x80\\x00\\x00\\x9b@\\x00\\x00\\xee\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH1\\x1a1-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x1c7@\\xc4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x08@\\x00\\x00e\\x80\\x00\\x00\\xc6@\\x00\\x00]\\x00\\x03@\\x00\\x00S\\x00\\x04@\\x00\\x00$\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayS\\x0fArray of shorts\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\\\\\x93\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x01!\\x80\\x00\\x00[@\\x00\\x01\\x19\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH2C\\x00\\xbd\\x00\\x10\\xfe\\x00\\x00\\x00\\x04@\\x00\\x00\\xf5\\x80\\x00\\x00\\x9b@\\x00\\x00\\xed\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH2\\x1a2-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x824\\x7f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x05@\\x00\\x00d\\x80\\x00\\x00\\xc6@\\x00\\x00\\\\\\x00\\x03@\\x00\\x00R\\x00\\x04@\\x00\\x00#\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayC\\x0eArray of chars\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xae\\x87\\x996\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x01""\\x80\\x00\\x00[@\\x00\\x01\\x1a\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH2S\\x00\\x12V\\xca\\x1c\\x00\\x00\\x00\\x04@\\x00\\x00\\xf6\\x80\\x00\\x00\\x9b@\\x00\\x00\\xee\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH2\\x1a2-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x824\\x7f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x05@\\x00\\x00e\\x80\\x00\\x00\\xc6@\\x00\\x00]\\x00\\x03@\\x00\\x00S\\x00\\x04@\\x00\\x00$\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayS\\x0fArray of shorts\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\\\\\x93\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x01 \\x80\\x00\\x00[@\\x00\\x01\\x18\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH2I\\x00\\xe8~\\x91G\\x00\\x00\\x00\\x04@\\x00\\x00\\xf4\\x80\\x00\\x00\\x9b@\\x00\\x00\\xec\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH2\\x1a2-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x824\\x7f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x05@\\x00\\x00c\\x80\\x00\\x00\\xc6@\\x00\\x00[\\x00\\x03@\\x00\\x00Q\\x00\\x04@\\x00\\x00""\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayI\\rArray of ints\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xd9\\xd5q\\xc7\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x01""\\x80\\x00\\x00[@\\x00\\x01\\x1a\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH2F\\x00h\\x9c\\xc2\\x95\\x00\\x00\\x00\\x04@\\x00\\x00\\xf6\\x80\\x00\\x00\\x9b@\\x00\\x00\\xee\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH2\\x1a2-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x824\\x7f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x05@\\x00\\x00e\\x80\\x00\\x00\\xc6@\\x00\\x00]\\x00\\x03@\\x00\\x00S\\x00\\x04@\\x00\\x00$\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayF\\x0fArray of floats\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00Z\\x0b\\xf6\\xf1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x01!\\x80\\x00\\x00[@\\x00\\x01\\x19\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH3C\\x00\\xa1\\xff\\x8d\\x94\\x00\\x00\\x00\\x04@\\x00\\x00\\xf5\\x80\\x00\\x00\\x9b@\\x00\\x00\\xed\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH3\\x1a3-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00B\\xd2D_\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x06@\\x00\\x00d\\x80\\x00\\x00\\xc6@\\x00\\x00\\\\\\x00\\x03@\\x00\\x00R\\x00\\x04@\\x00\\x00#\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayC\\x0eArray of chars\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xae\\x87\\x996\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x01""\\x80\\x00\\x00[@\\x00\\x01\\x1a\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH3S\\x00\\xf7VF\\xb2\\x00\\x00\\x00\\x04@\\x00\\x00\\xf6\\x80\\x00\\x00\\x9b@\\x00\\x00\\xee\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH3\\x1a3-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00B\\xd2D_\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x06@\\x00\\x00e\\x80\\x00\\x00\\xc6@\\x00\\x00]\\x00\\x03@\\x00\\x00S\\x00\\x04@\\x00\\x00$\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayS\\x0fArray of shorts\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x03\\\\\\x93\\x14\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x01 \\x80\\x00\\x00[@\\x00\\x01\\x18\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH3I\\x00\\xcd~\\r\\xdd\\x00\\x00\\x00\\x04@\\x00\\x00\\xf4\\x80\\x00\\x00\\x9b@\\x00\\x00\\xec\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH3\\x1a3-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00B\\xd2D_\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x06@\\x00\\x00c\\x80\\x00\\x00\\xc6@\\x00\\x00[\\x00\\x03@\\x00\\x00Q\\x00\\x04@\\x00\\x00""\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayI\\rArray of ints\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xd9\\xd5q\\xc7\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x01""\\x80\\x00\\x00[@\\x00\\x01\\x1a\\x00\\t@\\x00\\x00\\x12\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x01\\x00\\x00\\x04TH3F\\x00M\\x9c?+\\x00\\x00\\x00\\x04@\\x00\\x00\\xf6\\x80\\x00\\x00\\x9b@\\x00\\x00\\xee\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00@\\x00\\x00l\\x80\\x00\\x00\\xc6@\\x00\\x00d\\x00\\x03@\\x00\\x00Z\\x00\\x04@\\x00\\x00+\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x03TH3\\x1a3-Dim histogram base class\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00B\\xd2D_\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x06@\\x00\\x00e\\x80\\x00\\x00\\xc6@\\x00\\x00]\\x00\\x03@\\x00\\x00S\\x00\\x04@\\x00\\x00$\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x07TArrayF\\x0fArray of floats\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00Z\\x0b\\xf6\\xf1\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04BASE\\x00\\x00\\x00\\x01\\x00@\\x00\\x03a\\xff\\xff\\xff\\xffTList\\x00@\\x00\\x03S\\x00\\x05\\x00\\x01\\x00\\x00\\x00\\x00\\x02\\x00@\\x00\\x0blistOfRules\\x00\\x00\\x00\\x05@\\x00\\x00\\xa3\\xff\\xff\\xff\\xffTObjString\\x00@\\x00\\x00\\x90\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x83type=read sourceClass=""TProfile"" targetClass=""TProfile"" version=""[1-5]"" source="""" target=""fBinSumw2"" code=""{ fBinSumw2.Reset(); }"" \\x00@\\x00\\x00\\x9c\\x80\\x00\\x9d\\x87@\\x00\\x00\\x94\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x87type=read sourceClass=""TProfile2D"" targetClass=""TProfile2D"" version=""[1-6]"" source="""" target=""fBinSumw2"" code=""{ fBinSumw2.Reset(); }"" \\x00@\\x00\\x00\\x9c\\x80\\x00\\x9d\\x87@\\x00\\x00\\x94\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x87type=read sourceClass=""TProfile3D"" targetClass=""TProfile3D"" version=""[1-6]"" source="""" target=""fBinSumw2"" code=""{ fBinSumw2.Reset(); }"" \\x00@\\x00\\x00\\xab\\x80\\x00\\x9d\\x87@\\x00\\x00\\xa3\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x96type=read sourceClass=""TTree"" targetClass=""TTree"" version=""[-16]"" source="""" target=""fDefaultEntryOffsetLen"" code=""{ fDefaultEntryOffsetLen = 1000; }"" \\x00@\\x00\\x00\\x98\\x80\\x00\\x9d\\x87@\\x00\\x00\\x90\\x00\\x01\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x83type=read sourceClass=""TTree"" targetClass=""TTree"" version=""[-18]"" source="""" target=""fNClusterRange"" code=""{ fNClusterRange = 0; }"" \\x00\\x00\''"
uproot/write/util.py,0,b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport datetime\n\ndef datime(when=None):\n    if when is None:\n        when = datetime.datetime.now()\n    return (when.year - 1995) << 26 | when.month << 22 | when.day << 17 | when.hour << 12 | when.minute << 6 | when.second\n'
uproot/write/objects/TH.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport struct\nfrom copy import copy\n\nimport numpy\n\nimport uproot.const\nimport uproot.write.compress\nimport uproot.write.sink.cursor\nfrom uproot.rootio import _bytesid\n\nclass TH(object):\n    def __init__(self, histogram):\n        self._fTitle = _bytesid(histogram._fTitle)\n        self._fClassName = _bytesid(histogram._classname)\n\n        self._fXaxis = self._emptyaxis(""xaxis"", 1.0)\n        self._fXaxis.update(histogram._fXaxis.__dict__)\n        self._fixaxis(self._fXaxis)\n\n        self._fYaxis = self._emptyaxis(""yaxis"", 0.0)\n        if hasattr(histogram, ""_fYaxis""):\n            self._fYaxis.update(histogram._fYaxis.__dict__)\n        self._fixaxis(self._fYaxis)\n\n        self._fZaxis = self._emptyaxis(""zaxis"", 1.0)\n        if hasattr(histogram, ""_fZaxis""):\n            self._fZaxis.update(histogram._fZaxis.__dict__)\n        self._fixaxis(self._fZaxis)\n\n        self._values = histogram.allvalues\n\n        self._fields = self._emptyfields()\n        for n in list(self._fields):\n            if hasattr(histogram, n):\n                self._fields[n] = getattr(histogram, n)\n\n        if self._fClassName == b""TH1C"":\n            self._valuesarray = numpy.array(self._values, dtype="">i1"")\n        elif self._fClassName == b""TH1S"":\n            self._valuesarray = numpy.array(self._values, dtype="">i2"")\n        elif self._fClassName == b""TH1I"":\n            self._valuesarray = numpy.array(self._values, dtype="">i4"")\n        elif self._fClassName == b""TH1F"":\n            self._valuesarray = numpy.array(self._values, dtype="">f4"")\n        elif self._fClassName == b""TH1D"":\n            self._valuesarray = numpy.array(self._values, dtype="">f8"")\n        elif self._fClassName == b""TProfile"":\n            self._valuesarray = numpy.array(self._values, dtype="">f8"")\n        elif self._fClassName == b""TH2C"":\n            self._valuesarray = numpy.array(self._values, dtype="">i1"").transpose()\n        elif self._fClassName == b""TH2S"":\n            self._valuesarray = numpy.array(self._values, dtype="">i2"").transpose()\n        elif self._fClassName == b""TH2I"":\n            self._valuesarray = numpy.array(self._values, dtype="">i4"").transpose()\n        elif self._fClassName == b""TH2F"":\n            self._valuesarray = numpy.array(self._values, dtype="">f4"").transpose()\n        elif self._fClassName == b""TH2D"":\n            self._valuesarray = numpy.array(self._values, dtype="">f8"").transpose()\n        elif self._fClassName == b""TProfile2D"":\n            self._valuesarray = numpy.array(self._values, dtype="">f8"").transpose()\n        elif self._fClassName == b""TH3C"":\n            self._valuesarray = numpy.array(self._values, dtype="">i1"").transpose()\n        elif self._fClassName == b""TH3S"":\n            self._valuesarray = numpy.array(self._values, dtype="">i2"").transpose()\n        elif self._fClassName == b""TH3I"":\n            self._valuesarray = numpy.array(self._values, dtype="">i4"").transpose()\n        elif self._fClassName == b""TH3F"":\n            self._valuesarray = numpy.array(self._values, dtype="">f4"").transpose()\n        elif self._fClassName == b""TH3D"":\n            self._valuesarray = numpy.array(self._values, dtype="">f8"").transpose()\n        elif self._fClassName == b""TProfile3D"":\n            self._valuesarray = numpy.array(self._values, dtype="">f8"").transpose()\n        else:\n            raise ValueError(""unrecognized histogram class name {0}"".format(self._fClassName))\n\n        self._fields[""_fNcells""] = self._valuesarray.size\n        self._fields[""_fContour""] = numpy.array(self._fields[""_fContour""], dtype="">f8"", copy=False)\n        self._fields[""_fSumw2""] = numpy.array(self._fields[""_fSumw2""], dtype="">f8"", copy=False)\n        self._fields[""_fBinEntries""] = numpy.array(self._fields[""_fBinEntries""], dtype="">f8"", copy=False)\n        self._fields[""_fBinSumw2""] = numpy.array(self._fields[""_fBinSumw2""], dtype="">f8"", copy=False)\n\n    @staticmethod\n    def _fixaxis(axis):\n        axis[""_fName""] = _bytesid(axis[""_fName""])\n        axis[""_fTitle""] = _bytesid(axis[""_fTitle""])\n        axis[""_fXbins""] = numpy.array(axis[""_fXbins""], dtype="">f8"", copy=False)\n        if axis[""_fLabels""] is None:\n            axis[""_fLabels""] = []\n        if axis[""_fModLabs""] is None:\n            axis[""_fModLabs""] = []\n\n    @staticmethod\n    def _emptyfields():\n        return {""_fLineColor"": 602,\n                ""_fLineStyle"": 1,\n                ""_fLineWidth"": 1,\n                ""_fFillColor"": 0,\n                ""_fFillStyle"": 1001,\n                ""_fMarkerColor"": 1,\n                ""_fMarkerStyle"": 1,\n                ""_fMarkerSize"": 1.0,\n                ""_fNcells"": 12,\n                ""_fBarOffset"": 0,\n                ""_fBarWidth"": 1000,\n                ""_fEntries"": 0.0,\n                ""_fTsumw"": 0.0,\n                ""_fTsumw2"": 0.0,\n                ""_fTsumwx"": 0.0,\n                ""_fTsumwx2"": 0.0,\n                ""_fMaximum"": -1111.0,\n                ""_fMinimum"": -1111.0,\n                ""_fNormFactor"": 0.0,\n                ""_fContour"": [],\n                ""_fSumw2"": [],\n                ""_fOption"": b"""",\n                ""_fFunctions"": [],\n                ""_fBufferSize"": 0,\n                ""_fBuffer"": [],\n                ""_fBinStatErrOpt"": 0,\n                ""_fStatOverflows"": 2,\n                ""_fTsumwy"": 0.0,\n                ""_fTsumwy2"": 0.0,\n                ""_fTsumwxy"": 0.0,\n                ""_fTsumwz"": 0.0,\n                ""_fTsumwz2"": 0.0,\n                ""_fTsumwxz"": 0.0,\n                ""_fTsumwyz"": 0.0,\n                ""_fScalefactor"": 0.0,\n                ""_fBinEntries"": [],\n                ""_fYmin"": 0.0,\n                ""_fYmax"": 0.0,\n                ""_fBinSumw2"": [],\n                ""_fErrorMode"": 0,\n                ""_fZmin"": 0.0,\n                ""_fZmax"": 0.0,\n                ""_fTmin"": 0.0,\n                ""_fTmax"": 0.0,\n                ""_fTsumwt"": 0.0,\n                ""_fTsumwt2"": 0.0}\n\n    @staticmethod\n    def _emptyaxis(name, titleoffset):\n        return {""_fName"": name,\n                ""_fTitle"": b"""",\n                ""_fNdivisions"": 510,\n                ""_fAxisColor"": 1,\n                ""_fLabelColor"": 1,\n                ""_fLabelFont"": 42,\n                ""_fLabelOffset"": 0.004999999888241291,\n                ""_fLabelSize"": 0.03500000014901161,\n                ""_fTickLength"": 0.029999999329447746,\n                ""_fTitleOffset"": titleoffset,\n                ""_fTitleSize"": 0.03500000014901161,\n                ""_fTitleColor"": 1,\n                ""_fTitleFont"": 42,\n                ""_fNbins"": 1,\n                ""_fXmin"": 0.0,\n                ""_fXmax"": 1.0,\n                ""_fXbins"": [],\n                ""_fFirst"": 0,\n                ""_fLast"": 0,\n                ""_fBits2"": 0,\n                ""_fTimeDisplay"": False,\n                ""_fTimeFormat"": b"""",\n                ""_fLabels"": None,\n                ""_fModLabs"": None}\n\n    _format_cntvers = struct.Struct("">IH"")\n\n    _format_tobject1 = struct.Struct("">HII"")\n    def _put_tobject(self, cursor):\n        return cursor.put_fields(self._format_tobject1, 1, 0, numpy.uint32(0x03000000))\n\n    def _put_tnamed(self, cursor, name, title):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 1\n        buff = (self._put_tobject(cursor) +\n                cursor.put_string(name) + cursor.put_string(title))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tarray = struct.Struct("">i"")\n    def _put_tarray(self, cursor, values):\n        return cursor.put_fields(self._format_tarray, values.size) + cursor.put_array(values)\n\n    _format_tobjstring = struct.Struct("">IHHII"")\n    def _put_tobjstring(self, cursor, value, bit=0):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_tobjstring.size)\n        vers = 1\n        buff = cursor.put_string(value)\n        length = len(buff) + self._format_tobjstring.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_tobjstring, cnt, vers, 1, bit, numpy.uint32(0x03000000)) + buff\n\n    _format_tlist1 = struct.Struct("">i"")\n    _format_tlist2 = struct.Struct("">B"")\n    def _put_tlist(self, cursor, values):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 5\n        buff = b""""\n        givenbytes = (self._put_tobject(cursor) +\n                      cursor.put_string(b"""") +\n                      cursor.put_fields(self._format_tlist1, len(values)))\n        for value in values:\n            buff += self.util.put_objany(cursor, (value, ""TObjString""), self.keycursor)\n            buff += cursor.put_fields(self._format_tlist2, 0)\n            buff += b"""" # cursor.bytes(source, n)\n        givenbytes += buff\n        length = len(givenbytes) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + givenbytes\n\n    _format_tattline = struct.Struct("">hhh"")\n    def _put_tattline(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 2\n        buff = (cursor.put_fields(self._format_tattline,\n                                  self._fields[""_fLineColor""],\n                                  self._fields[""_fLineStyle""],\n                                  self._fields[""_fLineWidth""]))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tattfill = struct.Struct("">hh"")\n    def _put_tattfill(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 2\n        buff = (cursor.put_fields(self._format_tattfill,\n                                  self._fields[""_fFillColor""],\n                                  self._fields[""_fFillStyle""]))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tattmarker = struct.Struct("">hhf"")\n    def _put_tattmarker(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 2\n        buff = (cursor.put_fields(self._format_tattmarker,\n                                  self._fields[""_fMarkerColor""],\n                                  self._fields[""_fMarkerStyle""],\n                                  self._fields[""_fMarkerSize""]))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tattaxis = struct.Struct("">ihhhfffffhh"")\n    def _put_tattaxis(self, cursor, axis):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 4\n        buff = (cursor.put_fields(self._format_tattaxis,\n                                  axis[""_fNdivisions""],\n                                  axis[""_fAxisColor""],\n                                  axis[""_fLabelColor""],\n                                  axis[""_fLabelFont""],\n                                  axis[""_fLabelOffset""],\n                                  axis[""_fLabelSize""],\n                                  axis[""_fTickLength""],\n                                  axis[""_fTitleOffset""],\n                                  axis[""_fTitleSize""],\n                                  axis[""_fTitleColor""],\n                                  axis[""_fTitleFont""]))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_taxis_1 = struct.Struct("">idd"")\n    _format_taxis_2 = struct.Struct("">iiH?"")\n    def _put_taxis(self, cursor, axis):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 10\n        buff = (self._put_tnamed(cursor, axis[""_fName""], axis[""_fTitle""]) +\n                self._put_tattaxis(cursor, axis) +\n                cursor.put_fields(self._format_taxis_1,\n                                  axis[""_fNbins""],\n                                  axis[""_fXmin""],\n                                  axis[""_fXmax""]) +\n                self._put_tarray(cursor, axis[""_fXbins""]) +\n                cursor.put_fields(self._format_taxis_2,\n                                  axis[""_fFirst""],\n                                  axis[""_fLast""],\n                                  axis[""_fBits2""],\n                                  axis[""_fTimeDisplay""]) +\n                cursor.put_string(axis[""_fTimeFormat""]) +\n                self.util.put_objany(cursor, (axis[""_fLabels""], ""THashList""), self.keycursor) +\n                self.util.put_objany(cursor, (axis[""_fModLabs""], ""TList""), self.keycursor))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_th1_1 = struct.Struct("">i"")\n    _format_th1_2 = struct.Struct("">hhdddddddd"")\n    _format_th1_3 = struct.Struct("">iBii"")\n    def _put_th1(self, cursor, name):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 8\n        if len(self._fields[""_fBuffer""]) != 0:\n            raise NotImplementedError\n        buff = (self._put_tnamed(cursor, name, self._fTitle) +\n                self._put_tattline(cursor) +\n                self._put_tattfill(cursor) +\n                self._put_tattmarker(cursor) +\n                cursor.put_fields(self._format_th1_1, self._fields[""_fNcells""]) +\n                self._put_taxis(cursor, self._fXaxis) +\n                self._put_taxis(cursor, self._fYaxis) +\n                self._put_taxis(cursor, self._fZaxis) +\n                cursor.put_fields(self._format_th1_2,\n                                  self._fields[""_fBarOffset""],\n                                  self._fields[""_fBarWidth""],\n                                  self._fields[""_fEntries""],\n                                  self._fields[""_fTsumw""],\n                                  self._fields[""_fTsumw2""],\n                                  self._fields[""_fTsumwx""],\n                                  self._fields[""_fTsumwx2""],\n                                  self._fields[""_fMaximum""],\n                                  self._fields[""_fMinimum""],\n                                  self._fields[""_fNormFactor""]) +\n                self._put_tarray(cursor, self._fields[""_fContour""]) +\n                self._put_tarray(cursor, self._fields[""_fSumw2""]) +\n                cursor.put_string(self._fields[""_fOption""]) +\n                self._put_tlist(cursor, self._fields[""_fFunctions""]) +\n                cursor.put_fields(self._format_th1_3,\n                                  self._fields[""_fBufferSize""],\n                                  0,  # FIXME: empty fBuffer\n                                  self._fields[""_fBinStatErrOpt""],\n                                  self._fields[""_fStatOverflows""]))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_th2_1 = struct.Struct("">dddd"")\n    def _put_th2(self, cursor, name):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 5\n        buff = (self._put_th1(cursor, name) +\n                cursor.put_fields(self._format_th2_1,\n                                  self._fields[""_fScalefactor""],\n                                  self._fields[""_fTsumwy""],\n                                  self._fields[""_fTsumwy2""],\n                                  self._fields[""_fTsumwxy""]))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_th3_1 = struct.Struct("">ddddddd"")\n    def _put_th3(self, cursor, name):\n        vers = 6\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        buff = (self._put_th1(cursor, name) +\n                self._put_tatt3d(cursor) + cursor.put_fields(self._format_th3_1,\n                                                             self._fields[""_fTsumwy""],\n                                                             self._fields[""_fTsumwy2""],\n                                                             self._fields[""_fTsumwxy""],\n                                                             self._fields[""_fTsumwz""],\n                                                             self._fields[""_fTsumwz2""],\n                                                             self._fields[""_fTsumwxz""],\n                                                             self._fields[""_fTsumwyz""]))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    def _put_tatt3d(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        cnt = numpy.int64(self._format_cntvers.size - 4) | uproot.const.kByteCountMask\n        vers = 1\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers)\n\n    def _put_th1d(self, cursor, name):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 3\n        buff = self._put_th1(cursor, name) + self._put_tarray(cursor, self._valuesarray)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    def _put_th2d(self, cursor, name):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 4\n        buff = self._put_th2(cursor, name) + self._put_tarray(cursor, self._valuesarray)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    def _put_th3d(self, cursor, name):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 4\n        buff = self._put_th3(cursor, name) + self._put_tarray(cursor, self._valuesarray)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tprofile = struct.Struct("">idddd"")\n    def _write(self, context, cursor, name, compression, key, keycursor, util):\n        self.util = util\n        self.util.set_obj(self)\n        copy_cursor = copy(cursor)\n        write_cursor = copy(cursor)\n        self.keycursor = keycursor\n        cursor.skip(self._format_cntvers.size)\n        if ""TH1"" in self._fClassName.decode(""utf-8""):\n            vers = 3\n            buff = self._put_th1(cursor, name) + self._put_tarray(cursor, self._valuesarray)\n        elif ""TH2"" in self._fClassName.decode(""utf-8""):\n            vers = 4\n            buff = self._put_th2(cursor, name) + self._put_tarray(cursor, self._valuesarray)\n        elif ""TH3"" in self._fClassName.decode(""utf-8""):\n            vers = 4\n            buff = self._put_th3(cursor, name) + self._put_tarray(cursor, self._valuesarray)\n        elif ""TProfile"" == self._fClassName.decode(""utf-8""):\n            vers = 7\n            buff = (self._put_th1d(cursor, name) + self._put_tarray(cursor, self._fields[""_fBinEntries""]) +\n                    cursor.put_fields(self._format_tprofile, self._fields[""_fErrorMode""], self._fields[""_fYmin""],\n                                      self._fields[""_fYmax""], self._fields[""_fTsumwy""], self._fields[""_fTsumwy2""]) +\n                    self._put_tarray(cursor, self._fields[""_fBinSumw2""]))\n        elif ""TProfile2D"" == self._fClassName.decode(""utf-8""):\n            vers = 8\n            buff = (self._put_th2d(cursor, name)\n                    + self._put_tarray(cursor, self._fields[""_fBinEntries""]) +\n                    cursor.put_fields(self._format_tprofile, self._fields[""_fErrorMode""], self._fields[""_fZmin""],\n                                      self._fields[""_fZmax""], self._fields[""_fTsumwz""], self._fields[""_fTsumwz2""]) +\n                    self._put_tarray(cursor, self._fields[""_fBinSumw2""]))\n        elif ""TProfile3D"" == self._fClassName.decode(""utf-8""):\n            vers = 8\n            buff = (self._put_th3d(cursor, name)\n                    + self._put_tarray(cursor, self._fields[""_fBinEntries""]) +\n                    cursor.put_fields(self._format_tprofile, self._fields[""_fErrorMode""], self._fields[""_fTmin""],\n                                      self._fields[""_fTmax""], self._fields[""_fTsumwt""], self._fields[""_fTsumwt2""]) +\n                    self._put_tarray(cursor, self._fields[""_fBinSumw2""]))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        givenbytes = copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n        uproot.write.compress.write(context, write_cursor, givenbytes, compression, key, keycursor)\n'"
uproot/write/objects/TObjString.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport struct\nfrom copy import copy\n\nimport numpy\n\nimport uproot.const\nimport uproot.write.compress\nimport uproot.write.sink.cursor\n\nclass TObjString(object):\n    def __init__(self, string):\n        if isinstance(string, bytes):\n            self.value = string\n        else:\n            self.value = string.encode(""utf-8"")\n\n    _fClassName = b""TObjString""\n    _fTitle = b""Collectable string class""\n\n    _format = struct.Struct("">IHHII"")\n\n    def _write(self, context, cursor, name, compression, key, keycursor, util):\n        copy_cursor = copy(cursor)\n        write_cursor = copy(cursor)\n        cursor.skip(self._format.size)\n        vers = 1\n        buff = cursor.put_string(self.value)\n        length = len(buff) + self._format.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        givenbytes = copy_cursor.put_fields(self._format, cnt, vers, 1, 0, uproot.const.kNotDeleted) + buff\n        uproot.write.compress.write(context, write_cursor, givenbytes, compression, key, keycursor)\n'"
uproot/write/objects/TTree.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nimport struct\nfrom copy import copy\nimport sys\nimport math\n\nimport numpy\nimport awkward\n\nimport uproot\nimport uproot.const\nfrom uproot.rootio import _bytesid\nfrom uproot.rootio import nofilter\nfrom uproot.rootio import _memsize\nimport uproot.write.compress\nimport uproot.write.sink.cursor\nfrom uproot.write.TKey import BasketKey\nfrom uproot.write.objects.util import Util\n\nclass newbranch(object):\n\n    def __init__(self, type, title="""", shape=(1,), size=None, **options):\n        self.name = """"\n        self.type = type\n        self.title = title\n        self.shape = shape\n        self.counter = size\n        self._iscounter = False\n        if ""compression"" in options:\n            self.compression = options[""compression""]\n            del options[""compression""]\n        if len(options) > 0:\n            raise TypeError(""{0} not supported"".format(options))\n\nclass newtree(object):\n\n    def __init__(self, branches={}, title="""", **options):\n        self.branches = branches\n        self.title = title\n        if ""compression"" in options:\n            self.compression = options[""compression""]\n            del options[""compression""]\n        if len(options) > 0:\n            raise TypeError(""{0} not supported"".format(options))\n\nclass TTree(object):\n\n    def __init__(self, name, newtree, file):\n        self._tree = TTreeImpl(name, newtree, file)\n        self._file = file\n\n        self._branches = {}\n        checker = []\n        for name, branch in newtree.branches.items():\n            if isinstance(branch, newbranch) == False:\n                branch = newbranch(branch)\n            if branch.counter is not None:\n                if isinstance(newtree.branches[name].type, str):\n                    # FIXME: int8 and boolean cannot be read properly by ROOT yet\n                    if newtree.branches[name].type == ""int8"" or newtree.branches[name].type == numpy.dtype(""int8""):\n                        raise NotImplementedError(""int8 cannot be read properly by ROOT yet"")\n                    elif ""?"" in newtree.branches[name].type or newtree.branches[name].type == numpy.dtype("">?"") or newtree.branches[name].type == numpy.dtype(""<?""):\n                        raise NotImplementedError(""Booleans cannot be read properly by ROOT yet"")\n                else:\n                    # FIXME: int8 and boolean cannot be read properly by ROOT yet\n                    if newtree.branches[name].type.str == ""int8"" or newtree.branches[name].type.str == numpy.dtype(""int8""):\n                        raise NotImplementedError(""int8 cannot be read properly by ROOT yet"")\n                    elif ""?"" in newtree.branches[name].type.str or newtree.branches[name].type.str == numpy.dtype("">?"") or newtree.branches[name].type.str == numpy.dtype(""<?""):\n                        raise NotImplementedError(""Booleans cannot be read properly by ROOT yet"")\n                if branch.counter not in checker:\n                    checker += [branch.counter]\n                    if branch.counter not in newtree.branches.keys():\n                        dummybranch = newbranch("">i4"")\n                        dummybranch._iscounter = True\n                        compression = getattr(dummybranch, ""compression"", getattr(newtree, ""compression"", file.compression))\n                        self._branches[branch.counter] = TBranch(branch.counter, dummybranch, compression, self, file)\n                        self._tree.fields[""_fLeaves""].append(self._branches[branch.counter]._branch.fields[""_fLeaves""])\n                        self._tree.fields[""_fBranches""].append(self._branches[branch.counter]._branch)\n                    else:\n                        raise Exception(branch.counter, "" will be created automatically. Do not create it manually."")\n            compression = getattr(branch, ""compression"", getattr(newtree, ""compression"", file.compression))\n            self._branches[name] = TBranch(name, branch, compression, self, file)\n            self._tree.fields[""_fLeaves""].append(self._branches[name]._branch.fields[""_fLeaves""])\n            self._tree.fields[""_fBranches""].append(self._branches[name]._branch)\n            if branch.counter is not None:\n                self._branches[name]._branch._awkwardbranch = self._branches[branch.counter]._branch.fields[""_fLeaves""]\n\n    def __getitem__(self, name):\n        return self._branches[name]\n\n    @property\n    def _fClassName(self):\n        return self._tree.fClassName\n\n    @property\n    def _fTitle(self):\n        return self._tree.fTitle\n\n    def _write(self, context, cursor, name, compression, key, keycursor, util):\n        self._tree.write(context, cursor, name, key, copy(keycursor), util)\n\n    def extend(self, branchdict):\n        #Baskets need to be added to all the branches\n        if len(branchdict) != len(self._branches):\n            raise Exception(""Basket data should be added to all branches"")\n\n        # Check for equal number of values in baskets\n        values = iter(branchdict.values())\n        first = next(values)\n        if all(len(first) == len(value) for value in values) == False:\n            raise Exception(""Baskets of all branches should have the same length"")\n\n        #Check if length of jaggedarrays depending on the same lengths branch is the same\n        tempdict = {}\n        for key, value in branchdict.items():\n            if self._branches[key]._branch.counter is not None:\n                if self._branches[key]._branch.counter in tempdict.keys():\n                    if not ((tempdict[self._branches[key]._branch.counter].counts == value.counts).all()):\n                        raise Exception(""Lengths of jagged arrays depending on the same lengths branch should be the same"")\n                else:\n                    tempdict[self._branches[key]._branch.counter] = value\n\n        #Convert to numpy arrays of required dtype\n        for key, value in branchdict.items():\n            if not isinstance(value, awkward.array.jagged.JaggedArray):\n                branchdict[key] = numpy.array(value, dtype=self._branches[key]._branch.type, copy=False)\n\n        for key, value in branchdict.items():\n            if isinstance(value, awkward.array.jagged.JaggedArray):\n                self._branches[key].newbasket(value)\n            elif value.ndim == 1:\n                self._branches[key].newbasket(value)\n            else:\n                for i in range(0, value.shape[0]):\n                    self._branches[key].newbasket(value[i], i + 1)\n\n    @property\n    def name(self):\n        return self._tree.fName\n\n    @property\n    def title(self):\n        return self._tree.fTitle\n\n    @property\n    def numentries(self):\n        t = uproot.open(self._file._path)[self.name]\n        return t.numentries\n\n    @property\n    def numbranches(self):\n        return len(self._branches)\n\n    def iterkeys(self, recursive=False, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        t = uproot.open(self._file._path)[self.name]\n        return t.iterkeys(recursive, filtername, filtertitle, aliases)\n\n    def itervalues(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        t = uproot.open(self._file._path)[self.name]\n        return t.itervalues(recursive, filtername, filtertitle)\n\n    def iteritems(self, recursive=False, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        t = uproot.open(self._file._path)[self.name]\n        return t.iteritems(recursive, filtername, filtertitle, aliases)\n\n    def keys(self, recursive=False, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        t = uproot.open(self._file._path)[self.name]\n        return t.keys(recursive, filtername, filtertitle, aliases)\n\n    def values(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        t = uproot.open(self._file._path)[self.name]\n        return t.values(recursive, filtername, filtertitle)\n\n    def items(self, recursive=False, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        t = uproot.open(self._file._path)[self.name]\n        return t.items(recursive, filtername, filtertitle, aliases)\n\n    def allkeys(self, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        t = uproot.open(self._file._path)[self.name]\n        return t.allkeys(filtername, filtertitle, aliases)\n\n    def allvalues(self, filtername=nofilter, filtertitle=nofilter):\n        t = uproot.open(self._file._path)[self.name]\n        return t.allvalues(filtername, filtertitle)\n\n    def allitems(self, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        t = uproot.open(self._file._path)[self.name]\n        return t.allitems(filtername, filtertitle, aliases)\n\n    def get(self, name, recursive=True, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        t = uproot.open(self._file._path)[self.name]\n        return t.get(name, recursive, filtername, filtertitle, aliases)\n\n    def __contains__(self, name):\n        t = uproot.open(self._file._path)[self.name]\n        return t.__contains__(name)\n\n    def mempartitions(self, numbytes, branches=None, entrystart=None, entrystop=None, keycache=None, linear=True):\n        t = uproot.open(self._file._path)[self.name]\n        return t.mempartitions(numbytes, branches, entrystart, entrystop, keycache, linear)\n\n    def clusters(self, branches=None, entrystart=None, entrystop=None, strict=False):\n        t = uproot.open(self._file._path)[self.name]\n        return t.clusters(branches, entrystart, entrystop, strict)\n\n    def array(self, branch, interpretation=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, blocking=True):\n        t = uproot.open(self._file._path)[self.name]\n        return t.array(branch, interpretation, entrystart, entrystop, flatten, awkwardlib, cache, basketcache, keycache, executor, blocking)\n\n    def arrays(self, branches=None, outputtype=dict, namedecode=None, entrystart=None, entrystop=None, flatten=False, flatname=None, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, blocking=True):\n        t = uproot.open(self._file._path)[self.name]\n        return t.arrays(branches, outputtype, namedecode, entrystart, entrystop, flatten, flatname, awkwardlib, cache, basketcache, keycache, executor, blocking)\n\n    def lazyarray(self, branch, interpretation=None, entrysteps=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, persistvirtual=False):\n        t = uproot.open(self._file._path)[self.name]\n        return t.lazyarray(branch, interpretation, entrysteps, entrystart, entrystop, flatten, awkwardlib, cache, basketcache, keycache, executor, persistvirtual)\n\n    def lazyarrays(self, branches=None, namedecode=""utf-8"", entrysteps=None, entrystart=None, entrystop=None, flatten=False, profile=None, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, persistvirtual=False):\n        t = uproot.open(self._file._path)[self.name]\n        return t.lazyarrays(branches, namedecode, entrysteps, entrystart, entrystop, flatten, profile, awkwardlib, cache, basketcache, keycache, executor, persistvirtual)\n\n    def iterate(self, branches=None, entrysteps=None, outputtype=dict, namedecode=None, reportentries=False, entrystart=None, entrystop=None, flatten=False, flatname=None, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, blocking=True):\n        t = uproot.open(self._file._path)[self.name]\n        return t.iterate(branches, entrysteps, outputtype, namedecode, reportentries, entrystart, entrystop, flatten, flatname, awkwardlib, cache, basketcache, keycache, executor, blocking)\n\n    def show(self, foldnames=False, stream=sys.stdout):\n        t = uproot.open(self._file._path)[self.name]\n        return t.show(foldnames, stream)\n\n    def matches(self, branches):\n        t = uproot.open(self._file._path)[self.name]\n        return t.matches(branches)\n\n    def __len__(self):\n        return self.numentries\n\n    def __iter__(self):\n        # prevent Python\'s attempt to interpret __len__ and __getitem__ as iteration\n        raise TypeError(""\'TTree\' object is not iterable"")\n\n    @property\n    def pandas(self):\n        t = uproot.open(self._file._path)[self.name]\n        return t.pandas\n\nclass TBranch(object):\n\n    def __init__(self, name, branchobj, compression, treelvl1, file):\n        self._branch = TBranchImpl(name, branchobj, compression, file)\n        self._treelvl1 = treelvl1\n\n    @staticmethod\n    def revertstring(string):\n        if isinstance(string, bytes):\n            return string.decode()\n        else:\n            return string\n\n    _tree_size = struct.Struct("">qqq"")\n    def newbasket(self, items, multidim=None):\n        if len(items) == 0:\n            return\n\n        self._branch.fields[""_fWriteBasket""] += 1\n\n        if self._branch.fields[""_fWriteBasket""] >= self._branch.fields[""_fMaxBaskets""]:\n            for branch in self._treelvl1._branches.values():\n                branch._branch.fields[""_fMaxBaskets""] = branch._branch.fields[""_fMaxBaskets""] * 2\n                temp_arr = numpy.array([0] * branch._branch.fields[""_fMaxBaskets""], dtype="">i8"")\n                temp_arr[0:len(branch._branch.fields[""_fBasketEntry""])] = branch._branch.fields[""_fBasketEntry""]\n                branch._branch.fields[""_fBasketEntry""] = temp_arr\n                temp_arr = numpy.array([0] * branch._branch.fields[""_fMaxBaskets""], dtype="">i8"")\n                temp_arr[0:len(branch._branch.fields[""_fBasketSeek""])] = branch._branch.fields[""_fBasketSeek""]\n                branch._branch.fields[""_fBasketSeek""] = temp_arr\n                temp_arr = numpy.array([0] * branch._branch.fields[""_fMaxBaskets""], dtype="">i4"")\n                temp_arr[0:len(branch._branch.fields[""_fBasketBytes""])] = branch._branch.fields[""_fBasketBytes""]\n                branch._branch.fields[""_fBasketBytes""] = temp_arr\n\n            tree = TTreeImpl(self._treelvl1._tree.name, newtree(), self._branch.file)\n            tree.name = self._treelvl1._tree.name\n            tree.fName = self._treelvl1._tree.fName\n            tree.fTitle = self._treelvl1._tree.fTitle\n\n            tree.fields[""_fEntries""] = self._treelvl1._tree.fields[""_fEntries""]\n            tree.fields[""_fTotBytes""] = self._treelvl1._tree.fields[""_fTotBytes""]\n            tree.fields[""_fZipBytes""] = self._treelvl1._tree.fields[""_fZipBytes""]\n\n            temp_branches = {}\n            for name, branch in self._treelvl1._branches.items():\n                compression = getattr(branch._branch, ""compression"", branch._branch.file.compression)\n                temp_branches[name] = TBranch(name, newbranch(branch._branch.type, """"), compression, self._treelvl1, branch._branch.file)\n                temp_branches[name]._branch.fields[""_fWriteBasket""] = branch._branch.fields[""_fWriteBasket""]\n                temp_branches[name]._branch.fields[""_fEntries""] = branch._branch.fields[""_fEntries""]\n                temp_branches[name]._branch.fields[""_fBasketEntry""] = branch._branch.fields[""_fBasketEntry""]\n                temp_branches[name]._branch.fields[""_fEntryNumber""] = branch._branch.fields[""_fEntryNumber""]\n                temp_branches[name]._branch.fields[""_fMaxBaskets""] = branch._branch.fields[""_fMaxBaskets""]\n                temp_branches[name]._branch.fields[""_fBasketSeek""] = branch._branch.fields[""_fBasketSeek""]\n                temp_branches[name]._branch.fields[""_fBasketBytes""] = branch._branch.fields[""_fBasketBytes""]\n                temp_branches[name]._branch.fields[""_fTotBytes""] = branch._branch.fields[""_fTotBytes""]\n                temp_branches[name]._branch.fields[""_fZipBytes""] = branch._branch.fields[""_fZipBytes""]\n                tree.fields[""_fLeaves""].append(temp_branches[name]._branch.fields[""_fLeaves""])\n                tree.fields[""_fBranches""].append(temp_branches[name]._branch)\n\n            tree.branches = copy(temp_branches)\n\n            cursor = uproot.write.sink.cursor.Cursor(self._branch.file._fSeekFree)\n            tree.write_key = uproot.write.TKey.TKey(fClassName=self._treelvl1._tree.write_key.fClassName,\n                                                    fName=self._treelvl1._tree.write_key.fName,\n                                                    fTitle=self._treelvl1._tree.write_key.fTitle,\n                                                    fObjlen=0,\n                                                    fSeekKey=copy(self._branch.file._fSeekFree),\n                                                    fSeekPdir=self._treelvl1._tree.write_key.fSeekPdir,\n                                                    fCycle=self._treelvl1._tree.write_key.fCycle)\n            tree.keycursor = uproot.write.sink.cursor.Cursor(tree.write_key.fSeekKey)\n            tree.write_key.write(cursor, self._branch.file._sink)\n            tree.write(tree.file, cursor, self._treelvl1._tree.write_name, tree.write_key, copy(tree.keycursor), Util())\n            tree.file._expandfile(cursor)\n            tree.file._rootdir.setkey(tree.write_key)\n\n            self = tree.branches[self.revertstring(self._branch.name)]\n            self._treelvl1._tree = tree\n            self._treelvl1._branches = temp_branches\n\n        if multidim is None:\n            self._branch.fields[""_fEntries""] += len(items)\n            self._branch.fields[""_fEntryNumber""] += len(items)\n        else:\n            self._branch.fields[""_fEntries""] = multidim\n            self._branch.fields[""_fEntryNumber""] = multidim\n        self._branch.fields[""_fBasketEntry""][self._branch.fields[""_fWriteBasket""]] = self._branch.fields[""_fEntries""]\n        if isinstance(items, awkward.array.jagged.JaggedArray):\n            givenbytes = b""""\n            for i in range(items.shape[0]):\n                givenbytes += numpy.array(items[i], dtype=self._branch.type).tostring()\n        else:\n            givenbytes = numpy.array(items, dtype=self._branch.type, copy=False).tostring()\n\n        cursor = uproot.write.sink.cursor.Cursor(self._branch.file._fSeekFree)\n        self._branch.fields[""_fBasketSeek""][self._branch.fields[""_fWriteBasket""] - 1] = cursor.index\n        if isinstance(items, awkward.array.jagged.JaggedArray):\n            key = BasketKey(fName=self._branch.name,\n                            fTitle=self._treelvl1._tree.write_key.fName,\n                            fNevBuf=items.shape[0],\n                            fNevBufSize=1000, # FIXME: What does this mean?\n                            fSeekKey=copy(self._branch.file._fSeekFree),\n                            fSeekPdir=copy(self._branch.file._fBEGIN),\n                            fBufferSize=32000)\n        else:\n            key = BasketKey(fName=self._branch.name,\n                            fTitle=self._treelvl1._tree.write_key.fName,\n                            fNevBuf=1 if multidim else len(items),\n                            fNevBufSize=numpy.dtype(self._branch.type).itemsize*len(items) if multidim else numpy.dtype(self._branch.type).itemsize,\n                            fSeekKey=copy(self._branch.file._fSeekFree),\n                            fSeekPdir=copy(self._branch.file._fBEGIN),\n                            fBufferSize=32000)\n        keycursor = uproot.write.sink.cursor.Cursor(key.fSeekKey)\n        key.write(cursor, self._branch.file._sink)\n        uproot.write.compress.write(self._branch.file, cursor, givenbytes, self._branch.compression, key, copy(keycursor))\n        if isinstance(items, awkward.array.jagged.JaggedArray):\n            # 3 looks like a harmless value for the first entry of offsetbytes\n            # Relevant code - https://github.com/root-project/root/blob/master/tree/tree/src/TBasket.cxx#L921-L954\n            offsetbytes = [3, key.fKeylen]\n            for i in range(items.shape[0] - 1):\n                offsetbytes += [(len(items[i]) * numpy.dtype(self._branch.type).itemsize) + offsetbytes[-1]]\n            offsetbytes += [0]\n            offsetbytes = numpy.array(offsetbytes, dtype="">i4"").tostring()\n            uproot.write.compress.write(self._branch.file, cursor, offsetbytes, self._branch.compression, key,\n                                        copy(keycursor), isjagged=True)\n\n        self._branch.file._expandfile(cursor)\n\n        self._treelvl1._tree.fields[""_fEntries""] = self._branch.fields[""_fEntries""]\n        self._branch.fields[""_fTotBytes""] += key.fObjlen + key.fKeylen\n        self._branch.fields[""_fZipBytes""] += key.fNbytes\n        self._treelvl1._tree.fields[""_fTotBytes""] += self._branch.fields[""_fTotBytes""]\n        self._treelvl1._tree.fields[""_fZipBytes""] += self._branch.fields[""_fZipBytes""]\n        self._branch.fields[""_fBasketBytes""][self._branch.fields[""_fWriteBasket""] - 1] = key.fNbytes\n        if self._branch.counter and ((len(items[-1])*4) > 10):\n            self._branch.fields[""_fEntryOffsetLen""] = len(items[-1])*4\n            self._branch._fentryoffsetlencursor.update_fields(self._branch.file._sink, self._branch._format_tbranch112, self._branch.fields[""_fEntryOffsetLen""])\n        self._treelvl1._tree.size_cursor.update_fields(self._branch.file._sink, self._tree_size, self._treelvl1._tree.fields[""_fEntries""],\n                                                       self._treelvl1._tree.fields[""_fTotBytes""],\n                                                       self._treelvl1._tree.fields[""_fZipBytes""])\n        self._branch._writebasket_cursor.update_fields(self._branch.file._sink, self._branch._format_tbranch12,\n                                                       self._branch.fields[""_fWriteBasket""], self._branch.fields[""_fEntryNumber""])\n        self._branch._fentries_cursor.update_fields(self._branch.file._sink, self._branch._format_fentries, self._branch.fields[""_fEntries""])\n        self._branch._fbasketentry_cursor.update_array(self._branch.file._sink, self._branch.fields[""_fBasketEntry""])\n        self._branch._fbasketseek_cursor.update_array(self._branch.file._sink, self._branch.fields[""_fBasketSeek""])\n        self._branch._tbranch_size_cursor.update_fields(self._branch.file._sink, self._branch._format_branch_size,\n                                                        self._branch.fields[""_fTotBytes""], self._branch.fields[""_fZipBytes""])\n        self._branch._fbasketbytes_cursor.update_array(self._branch.file._sink, self._branch.fields[""_fBasketBytes""])\n\n    @property\n    def name(self):\n        return self._branch.name\n\n    @property\n    def title(self):\n        return self._branch.title\n\n    @property\n    def interpretation(self):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.interpretation\n\n    @property\n    def countbranch(self):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.countbranch\n\n    @property\n    def countleaf(self):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.countleaf\n\n    @property\n    def numentries(self):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.numentries\n\n    @property\n    def numbranches(self):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.numbranches\n\n    def iterkeys(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.iterkeys(recursive, filtername, filtertitle)\n\n    def itervalues(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.itervalues(recursive, filtername, filtertitle)\n\n    def iteritems(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.iteritems(recursive, filtername, filtertitle)\n\n    def keys(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.keys(recursive, filtername, filtertitle)\n\n    def values(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.keys(recursive, filtername, filtertitle)\n\n    def items(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.items(recursive, filtername, filtertitle)\n\n    def allkeys(self, recursive=False, filtername=nofilter, filtertitle=nofilter):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.allkeys(recursive, filtername, filtertitle)\n\n    def allvalues(self, filtername=nofilter, filtertitle=nofilter):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.keys(filtername, filtertitle)\n\n    def allitems(self, filtername=nofilter, filtertitle=nofilter):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.allitems(filtername, filtertitle)\n\n    def get(self, name, recursive=True, filtername=nofilter, filtertitle=nofilter, aliases=True):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.get(name, recursive, filtername, filtertitle, aliases)\n\n    @property\n    def numbaskets(self):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.numbaskets\n\n    def uncompressedbytes(self, keycache=None):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.uncompressedbhytes(keycache)\n\n    def compressedbytes(self, keycache=None):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.compressedbhytes(keycache)\n\n    def compressionratio(self, keycache=None):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.compressionratio(keycache)\n\n    def numitems(self, interpretation=None, keycache=None):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.numitems(interpretation, keycache)\n\n    def basket_entrystart(self, i):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.basket_entrystart(i)\n\n    def basket_entrystop(self, i):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.basket_entrystop(i)\n\n    def basket_numentries(self, i):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.basket_numentries(i)\n\n    def basket_uncompressedbytes(self, i, keycache=None):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.basket_uncompressedbytes(i, keycache)\n\n    def basket_compressedbytes(self, i):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.basked_compressedbytes(i)\n\n    def basket_numitems(self, i, interpretation=None, keycache=None):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.basket_numitems(i, interpretation, keycache)\n\n    def basket(self, i, interpretation=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.basket(i, interpretation, entrystart, entrystop, flatten, awkwardlib, cache, basketcache, keycache)\n\n    def baskets(self, interpretation=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, reportentries=False, executor=None, blocking=True):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.baskets(interpretation, entrystart, entrystop, flatten, awkwardlib, cache, basketcache, keycache, reportentries, executor, blocking)\n\n    def iterate_baskets(self, interpretation=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, reportentries=False):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.baskets(interpretation, entrystart, entrystop, flatten, awkwardlib, cache, basketcache, keycache, reportentries)\n\n    def array(self, interpretation=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, blocking=True):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.array(interpretation, entrystart, entrystop, flatten, awkwardlib, cache, basketcache, keycache, executor, blocking)\n\n    def mempartitions(self, numbytes, entrystart=None, entrystop=None, keycache=None, linear=True):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.mempartitions(numbytes, entrystart, entrystop, keycache, linear)\n\n    def lazyarray(self, interpretation=None, entrysteps=None, entrystart=None, entrystop=None, flatten=False, awkwardlib=None, cache=None, basketcache=None, keycache=None, executor=None, persistvirtual=False):\n        b = uproot.open(self._treelvl1._file._path)[self._treelvl1.name][self.name]\n        return b.lazyarray(interpretation, entrysteps, entrystart, entrystop, flatten, awkwardlib, cache, basketcache, keycache, executor, persistvirtual)\n\nclass TTreeImpl(object):\n\n    def __init__(self, name, newtree, file):\n        self.name = name\n        self.fClassName = b""TTree""\n        self.fName = _bytesid(self.name)\n        self.fTitle = _bytesid(newtree.title)\n        self.file = file\n\n        self.fields = {""_fLineColor"": 602,\n                       ""_fLineStyle"": 1,\n                       ""_fLineWidth"": 1,\n                       ""_fFillColor"": 0,\n                       ""_fFillStyle"": 1001,\n                       ""_fMarkerColor"": 1,\n                       ""_fMarkerStyle"": 1,\n                       ""_fMarkerSize"": 1.0,\n                       ""_fEntries"": 0,\n                       ""_fTotBytes"": 0,\n                       ""_fZipBytes"": 0,\n                       ""_fSavedBytes"": 0,\n                       ""_fFlushedBytes"": 0,\n                       ""_fWeight"": 1.0,\n                       ""_fTimerInterval"": 0,\n                       ""_fScanField"": 25,\n                       ""_fUpdate"": 0,\n                       ""_fDefaultEntryOffsetLen"": 1000,  # TODO: WHAT IS THIS?\n                       ""_fNClusterRange"": 0,\n                       ""_fMaxEntries"": 1000000000000,  # TODO: HOW DOES THIS WORK?\n                       ""_fMaxEntryLoop"": 1000000000000,  # Same as fMaxEntries?\n                       ""_fMaxVirtualSize"": 0,\n                       ""_fAutoSave"": -300000000,\n                       ""_fAutoFlush"": -30000000,\n                       ""_fEstimate"": 1000000,\n                       ""_fClusterRangeEnd"": [],\n                       ""_fClusterSize"": [],\n                       ""_fBranches"": [],\n                       ""_fFriends"": None,\n                       ""_fTreeIndex"": None,\n                       ""_fIndex"": [],\n                       ""_fIndexValues"": [],\n                       ""_fAliases"": None,\n                       ""_fLeaves"": [],\n                       ""_fUserInfo"": None,\n                       ""_fBranchRef"": None}\n\n    _format_tobject1 = struct.Struct("">HII"")\n    def put_tobject(self, cursor, hexbytes):\n        return cursor.put_fields(self._format_tobject1, 1, 0, hexbytes)\n\n    def put_tnamed(self, cursor, name, title, hexbytes=numpy.uint32(0x03000000)):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 1\n        buff = (self.put_tobject(cursor, hexbytes) +\n                cursor.put_string(name) + cursor.put_string(title))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tattline = struct.Struct("">hhh"")\n    def put_tattline(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 2\n        buff = (cursor.put_fields(self._format_tattline,\n                                  self.fields[""_fLineColor""],\n                                  self.fields[""_fLineStyle""],\n                                  self.fields[""_fLineWidth""]))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tattfill = struct.Struct("">hh"")\n    def put_tattfill(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 2\n        buff = (cursor.put_fields(self._format_tattfill,\n                                  self.fields[""_fFillColor""],\n                                  self.fields[""_fFillStyle""]))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tattmarker = struct.Struct("">hhf"")\n    def put_tattmarker(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 2\n        buff = (cursor.put_fields(self._format_tattmarker,\n                                  self.fields[""_fMarkerColor""],\n                                  self.fields[""_fMarkerStyle""],\n                                  self.fields[""_fMarkerSize""]))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_rootiofeatures = struct.Struct("">B"")\n    def put_rootiofeatures(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 0\n        fIOBits = 0\n        cursor.skip(4)\n        buff = b""\\x1a\\xa1/\\x10"" + cursor.put_fields(self._format_rootiofeatures, fIOBits)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tobjarray1 = struct.Struct("">ii"")\n    def put_tobjarray(self, cursor, values, classname, fBits=50331648):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        buff = self._skiptobj(cursor, fBits)\n        vers = 3\n        try:\n            size = len(values)\n        except TypeError:\n            size = 1\n            values = [values]\n        low = 0\n        buff += cursor.put_string(b"""") + cursor.put_fields(self._format_tobjarray1, size, low)\n        for i in range(len(self.fields[""_fLeaves""])):\n            buff += self.util.put_objany(cursor, (values[i], classname[i] if type(classname)==list else classname), self.write_keycursor)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_skiptobj1 = struct.Struct("">h"")\n    _format_skiptobj2 = struct.Struct("">II"")\n    def _skiptobj(self, cursor, fBits):\n        version = 1\n        buff = cursor.put_fields(self._format_skiptobj1, version)\n        fUniqueID = 0\n        buff += cursor.put_fields(self._format_skiptobj2, fUniqueID, fBits)\n        return buff\n\n    _format_tarray = struct.Struct("">i"")\n    def put_tarray(self, cursor, values):\n        return cursor.put_fields(self._format_tarray, values.size) + cursor.put_array(values)\n\n    _format_cntvers = struct.Struct("">IH"")\n\n    _format_ttree = struct.Struct("">qqqqqdiiiiIqqqqqq"")\n    def write(self, context, cursor, name, key, keycursor, util):\n        copy_cursor = copy(cursor)\n        self.tree_write_cursor = copy(cursor)\n        self.write_name = name\n        self.write_key = key\n        self.write_keycursor = keycursor\n        self.util = util\n        self.util.set_obj(self)\n\n        cursor.skip(self._format_cntvers.size)\n        vers = 20\n\n        for branch in self.fields[""_fBranches""]:\n            branch.util = self.util\n            branch.keycursor = self.write_keycursor\n\n        self.fields[""_fClusterRangeEnd""] = numpy.array(self.fields[""_fClusterRangeEnd""], dtype=""int64"", copy=False)\n        self.fields[""_fClusterSize""] = numpy.array(self.fields[""_fClusterSize""], dtype=""int64"", copy=False)\n        self.fields[""_fIndexValues""] = numpy.array(self.fields[""_fIndexValues""], dtype="">f8"", copy=False)\n        self.fields[""_fIndex""] = numpy.array(self.fields[""_fIndex""], dtype="">i8"", copy=False)\n\n        buff = (self.put_tnamed(cursor, name, self.fTitle, hexbytes=numpy.uint32(0x03000008)) +\n                self.put_tattline(cursor) +\n                self.put_tattfill(cursor) +\n                self.put_tattmarker(cursor))\n        self.size_cursor = copy(cursor)\n        buff += (cursor.put_fields(self._format_ttree, self.fields[""_fEntries""],\n                                   self.fields[""_fTotBytes""],\n                                   self.fields[""_fZipBytes""],\n                                   self.fields[""_fSavedBytes""],\n                                   self.fields[""_fFlushedBytes""],\n                                   self.fields[""_fWeight""],\n                                   self.fields[""_fTimerInterval""],\n                                   self.fields[""_fScanField""],\n                                   self.fields[""_fUpdate""],\n                                   self.fields[""_fDefaultEntryOffsetLen""],\n                                   self.fields[""_fNClusterRange""],\n                                   self.fields[""_fMaxEntries""],\n                                   self.fields[""_fMaxEntryLoop""],\n                                   self.fields[""_fMaxVirtualSize""],\n                                   self.fields[""_fAutoSave""],\n                                   self.fields[""_fAutoFlush""],\n                                   self.fields[""_fEstimate""]))\n        buff += b""\\x00""\n        cursor.skip(len(b""\\x00""))\n        buff += cursor.put_array(self.fields[""_fClusterRangeEnd""])\n        buff += b""\\x00""\n        cursor.skip(len(b""\\x00""))\n        buff += (cursor.put_array(self.fields[""_fClusterSize""]))\n        buff += (self.put_rootiofeatures(cursor) +\n                 self.put_tobjarray(cursor, self.fields[""_fBranches""], ""TBranch"", fBits=50348032))\n        if self.fields[""_fBranches""] == []:\n            buff += self.put_tobjarray(cursor, self.fields[""_fLeaves""], ""TLeaf"")\n        else:\n            buff += self.put_tobjarray(cursor, [self.fields[""_fLeaves""][i][0] for i in range(len(self.fields[""_fLeaves""]))],\n                                       classname=[self.fields[""_fLeaves""][i][1] for i in range(len(self.fields[""_fLeaves""]))])\n        buff += (self.util.put_objany(cursor, (self.fields[""_fAliases""], ""TList""), self.write_keycursor) +\n                 self.put_tarray(cursor, self.fields[""_fIndexValues""]) +\n                 self.put_tarray(cursor, self.fields[""_fIndex""]) +\n                 self.util.put_objany(cursor, (self.fields[""_fTreeIndex""], ""TVirtualIndex""), self.write_keycursor) +\n                 self.util.put_objany(cursor, (self.fields[""_fFriends""], ""TList""), self.write_keycursor) +\n                 self.util.put_objany(cursor, (self.fields[""_fUserInfo""], ""TList""), self.write_keycursor) +\n                 self.util.put_objany(cursor, (self.fields[""_fBranchRef""], ""TBranchRef""), self.write_keycursor))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        givenbytes = copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n        uproot.write.compress.write(context, copy(self.tree_write_cursor), givenbytes, None, key, copy(self.write_keycursor))\n\nclass TBranchImpl(object):\n\n    def __init__(self, name, branchobj, compression, file):\n        self.name = _bytesid(name)\n        self.type = numpy.dtype(branchobj.type).newbyteorder("">"")\n        self.shape = branchobj.shape\n        self.compression = compression\n        self.counter = branchobj.counter\n        if self.counter:\n            self.awkwardpadder = b""["" + self.counter.encode(""utf-8"") + b""]""\n        else:\n            self.awkwardpadder = b""""\n        self._awkwardbranch = None\n        self._iscounter = branchobj._iscounter\n        self.util = None\n        self.keycursor = None\n        self.file = file\n\n        self.fields = {""_fCompress"": 100,\n                       ""_fBasketSize"": 32000,\n                       ""_fEntryOffsetLen"": 10 if self.counter else 0,\n                       ""_fWriteBasket"": 0,  # Number of baskets\n                       ""_fOffset"": 0,\n                       ""_fMaxBaskets"": 50,\n                       ""_fSplitLevel"": 0,\n                       ""_fEntries"": 0,\n                       ""_fFirstEntry"": 0,\n                       ""_fTotBytes"": 0,\n                       ""_fZipBytes"": 0,\n                       ""_fBasketBytes"": [0]*50,\n                       ""_fBasketEntry"": [0]*50,\n                       ""_fBasketSeek"": [0]*50,\n                       ""_fFileName"": b"""",\n                       ""_fBranches"": [],\n                       ""_fLeaves"": [],\n                       ""_fFillColor"": 0,\n                       ""_fFillStyle"": 1001,\n                       ""_fEntryNumber"": 0,\n                       ""_fBaskets"": b\'@\\x00\\x00\\x1d\\x00\\x03\\x00\\x01\\x00\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\'}\n\n        # For multidimensional arrays\n        if len(self.shape) > 1:\n            array_pad = b""""\n            for i in range(1, len(self.shape)):\n                array_pad += b""["" + str(self.shape[i]).encode(""utf-8"") + b""]""\n\n        # TODO: Fix else condition to not always return NotImplementedError\n        if self.type == ""int8"":\n            title_pad = b""/B""\n            self.fields[""_fLeaves""] = [self, ""TLeafB""]\n        elif self.type == "">f8"":\n            title_pad = b""/D""\n            self.fields[""_fLeaves""] = [self, ""TLeafD""]\n        elif self.type == "">f4"":\n            title_pad = b""/F""\n            self.fields[""_fLeaves""] = [self, ""TLeafF""]\n        elif self.type == "">i4"":\n            title_pad = b""/I""\n            self.fields[""_fLeaves""] = [self, ""TLeafI""]\n        elif self.type == "">i8"":\n            title_pad = b""/L""\n            self.fields[""_fLeaves""] = [self, ""TLeafL""]\n        elif self.type == "">?"":\n            title_pad = b""/O""\n            self.fields[""_fLeaves""] = [self, ""TLeafO""]\n        elif self.type == "">i2"":\n            title_pad = b""/S""\n            self.fields[""_fLeaves""] = [self, ""TLeafS""]\n        else:\n            raise NotImplementedError\n\n        if branchobj.title == """":\n            self.title = _bytesid(name)\n            if len(self.shape) > 1:\n                self.nametitle = self.title + array_pad + title_pad\n                self.arraytitle = self.title + array_pad\n\n            else:\n                self.nametitle = self.title + title_pad\n        else:\n            self.title = _bytesid(branchobj.title)\n            if len(self.shape) > 1:\n                self.nametitle = self.title + array_pad\n                self.arraytitle = self.title + array_pad\n            else:\n                self.nametitle = self.title\n\n        self.fields[""_fBasketBytes""] = numpy.array(self.fields[""_fBasketBytes""], dtype="">i4"", copy=False)\n        self.fields[""_fBasketEntry""] = numpy.array(self.fields[""_fBasketEntry""], dtype="">i8"", copy=False)\n        self.fields[""_fBasketSeek""] = numpy.array(self.fields[""_fBasketSeek""], dtype="">i8"", copy=False)\n\n    _format_cntvers = struct.Struct("">IH"")\n\n    _format_tobject1 = struct.Struct("">HII"")\n    def put_tobject(self, cursor, hexbytes):\n        return cursor.put_fields(self._format_tobject1, 1, 0, hexbytes)\n\n    def put_tnamed(self, cursor, name, title, hexbytes=numpy.uint32(0x03000000)):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 1\n        buff = (self.put_tobject(cursor, hexbytes) +\n                cursor.put_string(name) + cursor.put_string(title))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tattfill = struct.Struct("">hh"")\n    def put_tattfill(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 2\n        buff = (cursor.put_fields(self._format_tattfill,\n                                  self.fields[""_fFillColor""],\n                                  self.fields[""_fFillStyle""]))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_rootiofeatures = struct.Struct("">B"")\n    def put_rootiofeatures(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 0\n        fIOBits = 0\n        cursor.skip(4)\n        buff = b""\\x1a\\xa1/\\x10""\n        buff += cursor.put_fields(self._format_rootiofeatures, fIOBits)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tleaf1 = struct.Struct("">iii??"")\n    def put_tleaf(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 2\n        fLen = 1\n        if len(self.shape) > 1:\n            for i in range(1, len(self.shape)):\n                fLen = fLen*self.shape[i]\n        fLenType = numpy.dtype(self.type).itemsize\n        fOffset = 0\n        if self._iscounter:\n            fIsRange = True\n        else:\n            fIsRange = False\n        fIsUnsigned = False\n        fLeafCount = None\n        if self.counter:\n            buff = (self.put_tnamed(cursor, self.name, self.title + self.awkwardpadder) +\n                    cursor.put_fields(self._format_tleaf1, fLen, fLenType, fOffset, fIsRange, fIsUnsigned) +\n                    self.util.put_objany(cursor, (self._awkwardbranch[0], self._awkwardbranch[1]), self.keycursor))\n        else:\n            buff = (self.put_tnamed(cursor, self.name, self.arraytitle if len(self.shape)>1 else self.title) +\n                    cursor.put_fields(self._format_tleaf1, fLen, fLenType, fOffset, fIsRange, fIsUnsigned) +\n                    self.util.put_objany(cursor, (fLeafCount, ""TLeaf""), self.keycursor))\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tleafI1 = struct.Struct("">ii"")\n    def put_tleafI(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 1\n        fMinimum = 0\n        if self._iscounter:\n            fMaximum = min(numpy.iinfo(self.type).max, 1000) # FIXME: Make updateble\n        else:\n            fMaximum = 0\n        buff = self.put_tleaf(cursor) + cursor.put_fields(self._format_tleafI1, fMinimum, fMaximum)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tleafB1 = struct.Struct("">bb"")\n    def put_tleafB(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 1\n        fMinimum = 0\n        if self._iscounter:\n            fMaximum = min(numpy.iinfo(self.type).max, 1000) # FIXME: Make updateble\n        else:\n            fMaximum = 0\n        buff = self.put_tleaf(cursor) + cursor.put_fields(self._format_tleafB1, fMinimum, fMaximum)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tleafD1 = struct.Struct("">dd"")\n    def put_tleafD(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 1\n        fMinimum = 0\n        if self._iscounter:\n            fMaximum = 1000 # FIXME: Make updateble or set to maximum possible value\n        else:\n            fMaximum = 0\n        buff = self.put_tleaf(cursor) + cursor.put_fields(self._format_tleafD1, fMinimum, fMaximum)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tleafF1 = struct.Struct("">ff"")\n    def put_tleafF(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 1\n        fMinimum = 0\n        if self._iscounter:\n            fMaximum = 1000 # FIXME: Make updateble or set to maximum possible value\n        else:\n            fMaximum = 0\n        buff = self.put_tleaf(cursor) + cursor.put_fields(self._format_tleafF1, fMinimum, fMaximum)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tleafL1 = struct.Struct("">qq"")\n    def put_tleafL(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 1\n        fMinimum = 0\n        if self._iscounter:\n            fMaximum = min(numpy.iinfo(self.type).max, 1000) # FIXME: Make updateble\n        else:\n            fMaximum = 0\n        buff = self.put_tleaf(cursor) + cursor.put_fields(self._format_tleafL1, fMinimum, fMaximum)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tleafO1 = struct.Struct("">??"")\n    def put_tleafO(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 1\n        fMinimum = 0\n        if self._iscounter:\n            fMaximum = min(numpy.iinfo(self.type).max, 1000) # FIXME: Make updateble\n        else:\n            fMaximum = 0\n        buff = self.put_tleaf(cursor) + cursor.put_fields(self._format_tleafO1, fMinimum, fMaximum)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tleafS1 = struct.Struct("">hh"")\n    def put_tleafS(self, cursor):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 1\n        fMinimum = 0\n        if self._iscounter:\n            fMaximum = min(numpy.iinfo(self.type).max, 1000) # FIXME: Make updateble\n        else:\n            fMaximum = 0\n        buff = self.put_tleaf(cursor) + cursor.put_fields(self._format_tleafS1, fMinimum, fMaximum)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_tobjarray1 = struct.Struct("">ii"")\n    def put_tobjarray(self, cursor, values, classname, fBits=50331648):\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        buff = self._skiptobj(cursor, fBits)\n        vers = 3\n        try:\n            size = len(values)\n        except TypeError:\n            size = 1\n            values = [values]\n        low = 0\n        buff += cursor.put_string(b"""") + cursor.put_fields(self._format_tobjarray1, size, low)\n        for value in values:\n            buff += self.util.put_objany(cursor, (value, classname), self.keycursor)\n        length = len(buff) + self._format_cntvers.size\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n\n    _format_skiptobj1 = struct.Struct("">h"")\n    _format_skiptobj2 = struct.Struct("">II"")\n\n    def _skiptobj(self, cursor, fBits):\n        version = 1\n        buff = cursor.put_fields(self._format_skiptobj1, version)\n        fUniqueID = 0\n        buff += cursor.put_fields(self._format_skiptobj2, fUniqueID, fBits)\n        return buff\n\n    _format_tbranch111 = struct.Struct("">ii"")\n    _format_tbranch112 = struct.Struct("">i"")\n    _format_tbranch12 = struct.Struct("">iq"")\n    _format_tbranch21 = struct.Struct("">iIi"")\n    _format_fentries = struct.Struct("">q"")\n    _format_tbranch22 = struct.Struct("">q"")\n    _format_branch_size = struct.Struct("">qq"")\n    def write(self, cursor):\n        if self.compression != None:\n            self.fields[""_fCompress""] = self.compression.code\n        copy_cursor = copy(cursor)\n        cursor.skip(self._format_cntvers.size)\n        vers = 13\n        if self.counter:\n            buff = (self.put_tnamed(cursor, self.name, self.nametitle[:-2] + self.awkwardpadder + self.nametitle[-2:], hexbytes=numpy.uint32(0x03400000)) +\n                    self.put_tattfill(cursor))\n        else:\n            buff = (self.put_tnamed(cursor, self.name, self.nametitle, hexbytes=numpy.uint32(0x03400000)) +\n                    self.put_tattfill(cursor))\n        self.branch_compress_cursor = copy(cursor)\n        buff += (cursor.put_fields(self._format_tbranch111,\n                                  self.fields[""_fCompress""],\n                                  self.fields[""_fBasketSize""]))\n        self._fentryoffsetlencursor = copy(cursor)\n        buff += (cursor.put_fields(self._format_tbranch112, self.fields[""_fEntryOffsetLen""]))\n        self._writebasket_cursor = copy(cursor)\n        buff += (cursor.put_fields(self._format_tbranch12,\n                                   self.fields[""_fWriteBasket""],\n                                   self.fields[""_fEntryNumber""]) +\n                self.put_rootiofeatures(cursor) +\n                cursor.put_fields(self._format_tbranch21,\n                                  self.fields[""_fOffset""],\n                                  self.fields[""_fMaxBaskets""],\n                                  self.fields[""_fSplitLevel""]))\n        self._fentries_cursor = copy(cursor)\n        buff += (cursor.put_fields(self._format_fentries, self.fields[""_fEntries""]))\n        buff += cursor.put_fields(self._format_tbranch22, self.fields[""_fFirstEntry""])\n        self._tbranch_size_cursor = copy(cursor)\n        buff += (cursor.put_fields(self._format_branch_size,\n                                  self.fields[""_fTotBytes""],\n                                  self.fields[""_fZipBytes""]) +\n                self.put_tobjarray(cursor, self.fields[""_fBranches""], classname=""TBranch"") +\n                self.put_tobjarray(cursor, self.fields[""_fLeaves""][0], classname=self.fields[""_fLeaves""][1]) +\n                cursor.put_data(self.fields[""_fBaskets""]))\n        buff += b""\\x01""\n        cursor.skip(len(b""\\x01""))\n        self._fbasketbytes_cursor = copy(cursor)\n        buff += cursor.put_array(self.fields[""_fBasketBytes""])\n        buff += b""\\x01""\n        cursor.skip(len(b""\\x01""))\n        self._fbasketentry_cursor = copy(cursor)\n        buff += (cursor.put_array(self.fields[""_fBasketEntry""]) + b""\\x01"")\n        cursor.skip(len(b""\\x01""))\n        self._fbasketseek_cursor = copy(cursor)\n        buff += (cursor.put_array(self.fields[""_fBasketSeek""]) + cursor.put_string(self.fields[""_fFileName""]))\n        length = (len(buff) + self._format_cntvers.size)\n        cnt = numpy.int64(length - 4) | uproot.const.kByteCountMask\n        return copy_cursor.put_fields(self._format_cntvers, cnt, vers) + buff\n'"
uproot/write/objects/__init__.py,0,b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import'
uproot/write/objects/util.py,0,"b'import struct\nfrom copy import copy\n\nimport numpy\n\nimport uproot\n\nclass Util(object):\n\n    def __init__(self):\n        self._written = {}\n        self.tobjstring_count = 0\n\n    _format_cntvers = struct.Struct("">IH"")\n\n    def _putclass(self, cursor, obj, keycursor, beg):\n        start = cursor.index - keycursor.index\n        beg = beg - keycursor.index\n        buf = b""""\n        objct, clsname = obj\n        if id(objct) in self._written and clsname in self._written:\n            buf += cursor.put_fields(self._format_putobjany1, numpy.uint32(self._written[id(objct)]))\n            return buf\n        if clsname in self._written:\n            buf += cursor.put_fields(self._format_putobjany1, self._written[clsname] | uproot.const.kClassMask)\n            if clsname != ""TBranch"":\n                self._written[id(objct)] = beg + uproot.const.kMapOffset\n        else:\n            buf += cursor.put_fields(self._format_putobjany1, uproot.const.kNewClassTag)\n            buf += cursor.put_cstring(clsname)\n            self._written[clsname] = numpy.uint32(start + uproot.const.kMapOffset) | uproot.const.kClassMask\n            self._written[id(objct)] = beg + uproot.const.kMapOffset\n        if clsname == ""THashList"" or clsname == ""TList"":\n            buf += self.parent_obj._put_tlist(cursor, objct)\n        elif clsname == ""TObjString"":\n            self.tobjstring_count += 1\n            buf += self.parent_obj._put_tobjstring(cursor, objct, self.tobjstring_count)\n        elif clsname == ""TBranch"":\n            buf += objct.write(cursor)\n        elif clsname == ""TLeafI"":\n            buf += objct.put_tleafI(cursor)\n        elif clsname == ""TLeafB"":\n            buf += objct.put_tleafB(cursor)\n        elif clsname == ""TLeafD"":\n            buf += objct.put_tleafD(cursor)\n        elif clsname == ""TLeafF"":\n            buf += objct.put_tleafF(cursor)\n        elif clsname == ""TLeafL"":\n            buf += objct.put_tleafL(cursor)\n        elif clsname == ""TLeafO"":\n            buf += objct.put_tleafO(cursor)\n        elif clsname == ""TLeafS"":\n            buf += objct.put_tleafS(cursor)\n        return buf\n\n    _format_putobjany1 = struct.Struct("">I"")\n    def put_objany(self, cursor, obj, keycursor):\n        class_buf = b""""\n        objct, clsname = obj\n        if id(objct) in self._written and clsname in self._written:\n            class_buf = self._putclass(cursor, obj, keycursor, cursor.index)\n            buff = b""""\n        elif objct != [] and objct != None:\n            copy_cursor = copy(cursor)\n            beg = cursor.index\n            cursor.skip(self._format_putobjany1.size)\n            class_buf = self._putclass(cursor, obj, keycursor, beg)\n            buff = copy_cursor.put_fields(self._format_putobjany1, numpy.uint32(len(class_buf)) | uproot.const.kByteCountMask)\n        else:\n            copy_cursor = copy(cursor)\n            cursor.skip(self._format_putobjany1.size)\n            buff = copy_cursor.put_fields(self._format_putobjany1, len(class_buf))\n        buff += class_buf\n        return buff\n\n    def set_obj(self, parent_obj):\n        self.parent_obj = parent_obj\n'"
uproot/write/sink/__init__.py,0,b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import'
uproot/write/sink/cursor.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nimport struct\n\nclass Cursor(object):\n    def __init__(self, index):\n        self.index = index\n\n    def skip(self, numbytes):\n        self.index += numbytes\n\n    def update_fields(self, sink, format, *args):\n        sink.write(format.pack(*args), self.index)\n\n    def write_fields(self, sink, format, *args):\n        self.update_fields(sink, format, *args)\n        self.index += format.size\n\n    def put_fields(self, format, *args):\n        self.index += format.size\n        return format.pack(*args)\n\n    @staticmethod\n    def length_string(string):\n        if len(string) < 255:\n            return len(string) + 1\n        else:\n            return len(string) + 5\n\n    @staticmethod\n    def length_strings(strings):\n        return sum(Cursor.length_string(x) for x in strings)\n\n    _format_byte = struct.Struct(""B"")\n    _format_byteint = struct.Struct("">Bi"")\n    def update_string(self, sink, data):\n        if len(data) < 255:\n            sink.write(self._format_byte.pack(len(data)), self.index)\n            sink.write(data, self.index + 1)\n        else:\n            sink.write(self._format_byteint.pack(255, len(data)), self.index)\n            sink.write(data, self.index + 5)\n\n    def write_string(self, sink, data):\n        self.update_string(sink, data)\n        self.index += self.length_string(data)\n\n    def put_string(self, data):\n        self.index += self.length_string(data)\n        if len(data) < 255:\n            return self._format_byte.pack(len(data)) + data\n        else:\n            return self._format_byteint.pack(255, len(data)) + data\n\n    def update_cstring(self, sink, data):\n        sink.write(data, self.index)\n        sink.write(b""\\x00"")\n\n    def write_cstring(self, sink, data):\n        self.update_cstring(sink, data)\n        self.index += len(data) + 1\n\n    def put_cstring(self, data):\n        self.index += len(data) + 1\n        return data.encode(""utf-8"") + b""\\x00""\n\n    def update_data(self, sink, data):\n        sink.write(data, self.index)\n\n    def write_data(self, sink, data):\n        self.update_data(sink, data)\n        self.index += len(data)\n\n    def put_data(self, data):\n        self.index += len(data)\n        return data\n\n    def put_array(self, data):\n        self.index += data.nbytes\n        return data.tostring()\n\n    def update_array(self, sink, data):\n        sink.write(data.tostring(), self.index)\n\n    def write_array(self, sink, data):\n        self.update_array(sink, data)\n        self.index += data.nbytes\n'"
uproot/write/sink/file.py,0,"b'#!/usr/bin/env python\n\n# BSD 3-Clause License; see https://github.com/scikit-hep/uproot/blob/master/LICENSE\n\nfrom __future__ import absolute_import\n\nclass Sink(object):\n    pass\n\nclass FileSink(Sink):\n    def __init__(self, path):\n        self._path = path\n        self._sink = open(path, ""wb+"")\n        # self._pos = 0\n\n    def write(self, data, pos):\n        self._sink.seek(pos)\n        self._sink.write(data)\n\n    # def write(self, data, pos):\n    #     if self._sink.tell() != pos:\n    #         self._sink.seek(pos)\n    #     self._sink.write(data)\n\n    # def write(self, data, pos):\n    #     if self._pos != pos:\n    #         self._sink.seek(pos)\n    #     self._sink.write(data)\n    #     self._pos += len(data)    # needs self._pos\n\n    @property\n    def closed(self):\n        return self._sink.closed\n\n    def close(self):\n        if not self._sink.closed:\n            self._sink.close()\n\n    def flush(self):\n        if not self._sink.closed:\n            self._sink.flush()\n'"
