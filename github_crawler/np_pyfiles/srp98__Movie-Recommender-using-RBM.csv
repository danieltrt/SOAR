file_path,api_count,code
Recommender_System.py,6,"b'import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load the movies dataset and also pass header=None since files don\'t contain any headers\nmovies_df = pd.read_csv(\'ml-1m/movies.dat\', sep=\'::\', header=None, engine=\'python\')\nprint(movies_df.head())\n\n# Load the ratings dataset\nratings_df = pd.read_csv(\'ml-1m/ratings.dat\', sep=\'::\', header=None, engine=\'python\')\nprint(ratings_df.head())\n\n# Lets rename our columns in these data frames so we can convey their data better\nmovies_df.columns = [\'MovieID\', \'Title\', \'Genres\']\nratings_df.columns = [\'UserID\', \'MovieID\', \'Rating\', \'Timestamp\']\n\n# Verify the changes done to the dataframes\nprint(movies_df.head())\nprint(ratings_df.head())\n\n# Data Correction and Formatting\nprint(\'The Number of Movies in Dataset\', len(movies_df))\n\n""""""\n- Our Movie ID\'s vary from 1 to 3952 while we have 3883 movies. \n- Due to this, we won\'t be able to index movies through their ID since we would get memory indexing errors. \n- To amend we can create a column that shows the spot in our list that particular movie is in:\n""""""\n\nmovies_df[\'List Index\'] = movies_df.index\nprint(movies_df.head())\n\n# Merge movies_df with ratings_df by MovieID\nmerged_df = movies_df.merge(ratings_df, on=\'MovieID\')\n\n# Drop unnecessary columns\nmerged_df = merged_df.drop(\'Timestamp\', axis=1).drop(\'Title\', axis=1).drop(\'Genres\', axis=1)\n\n# Display the result\nprint(merged_df.head())\n\n# Lets Group up the Users by their user ID\'s\nuser_Group = merged_df.groupby(\'UserID\')\nprint(user_Group.head())\n\n""""""\nFormatting the data into input for the RBM. \nStore the normalized users ratings into a list of lists called trX.\n""""""\n\n# Amount of users used for training\namountOfUsedUsers = 1000\n\n# Creating the training list\ntrX = []\n\n# For each user in the group\nfor userID, curUser in user_Group:\n\n    # Create a temp that stores every movie\'s rating\n    temp = [0]*len(movies_df)\n\n    # For each movie in curUser\'s movie list\n    for num, movie in curUser.iterrows():\n\n        # Divide the rating by 5 and store it\n        temp[movie[\'List Index\']] = movie[\'Rating\']/5.0\n\n    # Add the list of ratings into the training list\n    trX.append(temp)\n\n    # Check to see if we finished adding in the amount of users for training\n    if amountOfUsedUsers == 0:\n        break\n    amountOfUsedUsers -= 1\nprint(trX)\n\n# Setting the models Parameters\nhiddenUnits = 50\nvisibleUnits = len(movies_df)\nvb = tf.placeholder(tf.float32, [visibleUnits])  # Number of unique movies\nhb = tf.placeholder(tf.float32, [hiddenUnits])  # Number of features were going to learn\nW = tf.placeholder(tf.float32, [visibleUnits, hiddenUnits])  # Weight Matrix\n\n# Phase 1: Input Processing\nv0 = tf.placeholder(""float"", [None, visibleUnits])\n_h0 = tf.nn.sigmoid(tf.matmul(v0, W) + hb)  # Visible layer activation\nh0 = tf.nn.relu(tf.sign(_h0 - tf.random_uniform(tf.shape(_h0))))  # Gibb\'s Sampling\n\n# Phase 2: Reconstruction\n_v1 = tf.nn.sigmoid(tf.matmul(h0, tf.transpose(W)) + vb)  # Hidden layer activation\nv1 = tf.nn.relu(tf.sign(_v1 - tf.random_uniform(tf.shape(_v1))))\nh1 = tf.nn.sigmoid(tf.matmul(v1, W) + hb)\n\n"""""" Set RBM Training Parameters """"""\n\n# Learning rate\nalpha = 1.0\n\n# Create the gradients\nw_pos_grad = tf.matmul(tf.transpose(v0), h0)\nw_neg_grad = tf.matmul(tf.transpose(v1), h1)\n\n# Calculate the Contrastive Divergence to maximize\nCD = (w_pos_grad - w_neg_grad) / tf.to_float(tf.shape(v0)[0])\n\n# Create methods to update the weights and biases\nupdate_w = W + alpha * CD\nupdate_vb = vb + alpha * tf.reduce_mean(v0 - v1, 0)\nupdate_hb = hb + alpha * tf.reduce_mean(h0 - h1, 0)\n\n# Set the error function, here we use Mean Absolute Error Function\nerr = v0 - v1\nerr_sum = tf.reduce_mean(err*err)\n\n"""""" Initialize our Variables with Zeroes using Numpy Library """"""\n\n# Current weight\ncur_w = np.zeros([visibleUnits, hiddenUnits], np.float32)\n\n# Current visible unit biases\ncur_vb = np.zeros([visibleUnits], np.float32)\n\n# Current hidden unit biases\ncur_hb = np.zeros([hiddenUnits], np.float32)\n\n# Previous weight\nprv_w = np.zeros([visibleUnits, hiddenUnits], np.float32)\n\n# Previous visible unit biases\nprv_vb = np.zeros([visibleUnits], np.float32)\n\n# Previous hidden unit biases\nprv_hb = np.zeros([hiddenUnits], np.float32)\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\n# Train RBM with 15 Epochs, with Each Epoch using 10 batches with size 100, After training print out the error by epoch\nepochs = 15\nbatchsize = 100\nerrors = []\nfor i in range(epochs):\n    for start, end in zip(range(0, len(trX), batchsize), range(batchsize, len(trX), batchsize)):\n        batch = trX[start:end]\n        cur_w = sess.run(update_w, feed_dict={v0: batch, W: prv_w, vb: prv_vb, hb: prv_hb})\n        cur_vb = sess.run(update_vb, feed_dict={v0: batch, W: prv_w, vb: prv_vb, hb: prv_hb})\n        cur_hb = sess.run(update_hb, feed_dict={v0: batch, W: prv_w, vb: prv_vb, hb: prv_hb})\n        prv_w = cur_w\n        prv_vb = cur_vb\n        prv_hb = cur_hb\n    errors.append(sess.run(err_sum, feed_dict={v0: trX, W: cur_w, vb: cur_vb, hb: cur_hb}))\n    print(errors[-1])\nplt.plot(errors)\nplt.ylabel(\'Error\')\nplt.xlabel(\'Epoch\')\nplt.show()\n\n""""""\nRecommendation System :-\n\n- We can now predict movies that an arbitrarily selected user might like. \n- This can be accomplished by feeding in the user\'s watched movie preferences into the RBM and then reconstructing the \n  input. \n- The values that the RBM gives us will attempt to estimate the user\'s preferences for movies that he hasn\'t watched \n  based on the preferences of the users that the RBM was trained on.\n""""""\n\n# Select the input User\ninputUser = [trX[50]]\n\n# Feeding in the User and Reconstructing the input\nhh0 = tf.nn.sigmoid(tf.matmul(v0, W) + hb)\nvv1 = tf.nn.sigmoid(tf.matmul(hh0, tf.transpose(W)) + vb)\nfeed = sess.run(hh0, feed_dict={v0: inputUser, W: prv_w, hb: prv_hb})\nrec = sess.run(vv1, feed_dict={hh0: feed, W: prv_w, vb: prv_vb})\n\n# List the 20 most recommended movies for our mock user by sorting it by their scores given by our model.\nscored_movies_df_50 = movies_df\nscored_movies_df_50[""Recommendation Score""] = rec[0]\nprint(scored_movies_df_50.sort_values([""Recommendation Score""], ascending=False).head(20))\n\n"""""" Recommend User what movies he has not watched yet """"""\n\n# Find the mock user\'s UserID from the data\nprint(merged_df.iloc[50])  # Result you get is UserID 150\n\n# Find all movies the mock user has watched before\nmovies_df_50 = merged_df[merged_df[\'UserID\'] == 150]\nprint(movies_df_50.head())\n\n"""""" Merge all movies that our mock users has watched with predicted scores based on his historical data: """"""\n\n# Merging movies_df with ratings_df by MovieID\nmerged_df_50 = scored_movies_df_50.merge(movies_df_50, on=\'MovieID\', how=\'outer\')\n\n# Dropping unnecessary columns\nmerged_df_50 = merged_df_50.drop(\'List Index_y\', axis=1).drop(\'UserID\', axis=1)\n\n# Sort and take a look at first 20 rows\nprint(merged_df_50.sort_values([\'Recommendation Score\'], ascending=False).head(20))\n\n"""""" There are some movies the user has not watched and has high score based on our model. So, we can recommend them. """"""\n'"
