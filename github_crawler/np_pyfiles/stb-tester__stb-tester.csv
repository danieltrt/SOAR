file_path,api_count,code
setup.py,0,"b'# coding: utf-8\n\nimport setuptools\n\n\nlong_description = """"""\\\n# Stb-tester\n\n**Automated User Interface Testing for Set-Top Boxes & Smart TVs**\n\n* Copyright \xc2\xa9 2013-2019 Stb-tester.com Ltd,\n  2012-2014 YouView TV Ltd. and other contributors.\n* License: LGPL v2.1 or (at your option) any later version (see [LICENSE]).\n\nThis package contains the ""stbt"" Python APIs that you can use in test-scripts\nwritten for running on the [Stb-tester Platform](https://stb-tester.com).\nThe primary purpose of this package is to make the stbt library easy to\ninstall locally for IDE linting & autocompletion.\n\nThis package doesn\'t support video-capture, so `stbt.get_frame()` and\n`stbt.frames()` won\'t work -- but you will be able to run `stbt.match()` if you\nspecify the `frame` parameter explicitly, for example by loading a screenshot\nfrom disk with `stbt.load_image()`.\n\nThis package doesn\'t include remote-control integrations, so `stbt.press()` and\nsimilar functions won\'t work.\n\nThis package doesn\'t bundle the Tesseract OCR engine, so `stbt.ocr()` and\n`stbt.match_text()` won\'t work.\n\n[LICENSE]: https://github.com/stb-tester/stb-tester/blob/master/LICENSE\n""""""\n\nsetuptools.setup(\n    name=""stb-tester"",\n    version=""31.1.5"",\n    author=""Stb-tester.com Ltd."",\n    author_email=""support@stb-tester.com"",\n    description=""Automated GUI testing for Set-Top Boxes"",\n    long_description=long_description,\n    long_description_content_type=""text/markdown"",\n    url=""https://stb-tester.com"",\n    packages=[""stbt"", ""_stbt""],\n    package_data={\n        ""_stbt"": [""stbt.conf""],\n    },\n    classifiers=[\n        # pylint:disable=line-too-long\n        ""Development Status :: 5 - Production/Stable"",\n        ""License :: OSI Approved :: GNU Lesser General Public License v2 or later (LGPLv2+)"",\n        ""Operating System :: OS Independent"",\n        ""Programming Language :: Python :: 2.7"",\n        ""Programming Language :: Python :: 3.6"",\n        ""Topic :: Software Development :: Testing"",\n    ],\n    # I have only tested Python 2.7 & 3.6\n    python_requires="">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,!=3.5.*"",\n    install_requires=[\n        ""astroid==1.6.0"",\n        ""future==0.15.2"",\n        ""Jinja2==2.10.1"",\n        ""lxml==4.2"",\n        ""networkx==1.11"",\n        ""opencv-python~=3.2"",\n        ""pylint==1.8.3"",\n        ""stbt-premium-stubs~=31.0"",\n    ],\n)\n'"
stbt_config.py,0,"b'#!/usr/bin/python\n\n""""""\nCopyright 2013 YouView TV Ltd.\nLicense: LGPL v2.1 or (at your option) any later version (see\nhttps://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport argparse\nimport sys\n\nfrom _stbt.config import _config_init, ConfigurationError, get_config\n\n\ndef error(s):\n    sys.stderr.write(""stbt config: error: %s\\n"" % s)\n    sys.exit(1)\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.prog = ""stbt config""\n    parser.description = """"""Prints the value of the specified key from the stbt\n        configuration file. See \'configuration\' in the stbt(1) man page.""""""\n    parser.epilog = """"""Returns non-zero exit status if the specified key or\n        section isn\'t found.""""""\n    parser.add_argument(\n        ""--bash-completion"", action=""store_true"", help=argparse.SUPPRESS)\n    parser.add_argument(\n        ""name"", metavar=""section.key"",\n        help=""e.g. \'global.source_pipeline\' or \'record.control_recorder\'"")\n    args = parser.parse_args(sys.argv[1:])\n\n    if args.bash_completion:\n        cfg = _config_init()\n        for section in cfg.sections():\n            for option in cfg.options(section):\n                print(""%s.%s"" % (section, option))\n        sys.exit(0)\n\n    if args.name.rfind(""."") == -1:\n        error(""\'name\' parameter must contain the section and key ""\n              ""separated by a dot"")\n\n    section, key = args.name.rsplit(""."", 1)\n\n    try:\n        print(get_config(section, key))\n    except ConfigurationError as e:\n        error(e)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
stbt_control.py,0,"b'#!/usr/bin/python\n""""""Send remote control signals using the PC keyboard or from the command line.\n""""""\nfrom __future__ import division\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport argparse\nimport collections\nimport contextlib\nimport curses\nimport curses.ascii\nimport io\nimport math\nimport os\nimport sys\nimport threading\nimport time\nfrom textwrap import dedent\n\nimport _stbt.control\nfrom _stbt.config import ConfigurationError, get_config\n\nSPECIAL_CHARS = {\n    curses.ascii.SP: ""Space"",\n    curses.ascii.NL: ""Enter"",\n    curses.ascii.TAB: ""Tab"",\n    curses.ascii.ESC: ""Escape"",\n    curses.KEY_UP: ""Up"",\n    curses.KEY_DOWN: ""Down"",\n    curses.KEY_LEFT: ""Left"",\n    curses.KEY_RIGHT: ""Right"",\n    curses.KEY_BACKSPACE: ""Backspace"",\n    curses.KEY_PPAGE: ""PageUp"",\n    curses.KEY_NPAGE: ""PageDown"",\n    curses.KEY_HOME: ""Home"",\n    curses.KEY_END: ""End"",\n    curses.KEY_IC: ""Insert"",\n    curses.KEY_DC: ""Delete"",\n}\n\n\ndef main(argv):\n    args = argparser().parse_args(argv[1:])\n\n    if args.help_keymap:\n        sys.exit(show_help_keymap())\n\n    control = _stbt.control.uri_to_control(args.control, None)\n\n    if args.remote_control_key:  # Send a single key and exit\n        control.press(args.remote_control_key)\n    else:  # Interactive\n        for key in main_loop(args.control, args.keymap):\n            control.press(key)\n\n\ndef argparser():\n    parser = argparse.ArgumentParser()\n    parser.prog = ""stbt control""\n    parser.description = (""Send remote control signals using the PC keyboard ""\n                          ""or from the command line."")\n    parser.add_argument(\n        ""--help-keymap"", action=\'store_true\', default=False,\n        help=""Show description of the keymap file format and exit."")\n    parser.add_argument(\n        ""--keymap"", default=default_keymap_file(),\n        help=""Load keymap from KEYMAP file; defaults to %(default)s. ""\n             ""See `%(prog)s --help-keymap` for details."")\n    parser.add_argument(\n        ""--control"", default=get_config(""global"", ""control""),\n        help=""Equivalent to the --control parameter of `stbt run`. ""\n             ""See `man stbt` for available control types and configuration."")\n    parser.add_argument(\n        ""remote_control_key"", default=None, nargs=\'?\',\n        help=(\n            ""The name of a remote control key as in the control\'s config file ""\n            ""(that is /etc/lirc/lircd.conf in case of a LIRC control device). ""\n            ""Specifying this argument sends remote_control_key and exits. ""\n            ""Omitting this argument brings up the printed keymap.""))\n    return parser\n\n\ndef show_help_keymap():\n    """"""Keymap File\n\n    A keymap file stores the mappings between keyboard keys and remote control\n    keys. One line of the file stores one key mapping in the following format:\n\n            <keyboard key> <remote control key> [<display name>]\n\n    <keyboard key> is an ASCII character or one of the following keywords:\n\n            Space, Enter, Tab, Escape, Up, Down, Left, Right, Backspace,\n            PageUp, PageDown, Home, End, Insert, Delete\n\n    Be careful that keywords are case sensitive.\n\n    <remote control key> is the same as in the command line arguments. It\n    cannot contain white spaces.\n\n    <display name> is an optional alias for <remote control key> to show in the\n    on-screen keymap; e.g. ""m MENU Main Menu"" displays ""Main Menu"" but sends\n    the ""MENU"" remote control key when ""m"" is pressed on the PC keyboard. It\n    may consist of multiple words but cannot be longer than 15 characters.\n\n    Comments start with \'//\' (double slash) and last until the end of line.\n\n    Example keymap:\n\n            m       MENU    Main Menu\n            Enter   OK\n            c       CLOSE   Close     // Go back to live TV\n\n    The keymap file to use can be specified by:\n\n    1. Passing the filename of the keymap to the --keymap=<filename> command\n       line argument.\n    2. Or setting the configuration value `control.keymap` to the filename of\n       the keymap file\n    3. Copying it into $XDG_CONFIG_PATH/stbt/control.conf (defaults to\n       $HOME/.config/stbt/control.conf).\n    """"""\n    print(globals()[""show_help_keymap""].__doc__)\n\n\ndef main_loop(control_uri, keymap_file):\n    try:\n        keymap = load_keymap(open(keymap_file, ""r""))\n    except IOError:\n        error(""Failed to load keymap file \'%s\'\\n""\n              ""(see \'stbt control --help\' for details of the keymap file).""\n              % keymap_file)\n    timer = None\n\n    with terminal() as term:\n        _, term_width = term.getmaxyx()\n        printed_keymap = dedent(""""""\\\n            Keymap: {keymap_file}\n            Control: {control_uri}\n\n            {mapping}\n\n            """""").format(keymap_file=keymap_file[:term_width - len(""Keymap:  "")],\n                        control_uri=control_uri[:77] + (\n                            control_uri[77:] and ""...""),\n                        mapping=keymap_string(keymap))\n        if keymap_fits_terminal(term, printed_keymap):\n            term.addstr(printed_keymap)\n        else:\n            raise EnvironmentError(\n                ""Unable to print keymap because the terminal is too small. ""\n                ""Please resize the terminal window."")\n        while True:  # Main loop\n            keycode = term.getch()\n            if keycode == ord(\'q\'):  # \'q\' for \'Quit\' is pre-defined\n                return\n\n            control_key, _ = keymap.get(decoded(keycode), (None, None))\n            if timer:\n                timer.cancel()\n                clear_last_command(term)\n            if control_key:\n                yield control_key\n            term.addstr(str(control_key))\n            timer = threading.Timer(1, clear_last_command, [term])\n            timer.start()\n            time.sleep(.2)\n            curses.flushinp()\n\n\ndef clear_last_command(term):\n    term.move(term.getyx()[0], 0)\n    term.clrtoeol()\n\n\ndef keymap_fits_terminal(term, printed_keymap):\n    term_y, term_x = term.getmaxyx()\n    lines = printed_keymap.split(""\\n"")\n    return term_y > len(lines) and term_x > max(len(line) for line in lines)\n\n\n@contextlib.contextmanager\ndef terminal():\n    term = curses.initscr()\n    curses.noecho()\n    curses.cbreak()\n    term.keypad(1)\n    term.immedok(1)\n    try:\n        yield term\n    finally:\n        term.immedok(0)\n        term.keypad(0)\n        curses.nocbreak()\n        curses.echo()\n        curses.endwin()\n\n\ndef keymap_string(keymap):\n    """"""\n    >>> print(keymap_string({""m"": (""MENU"", ""Main Menu"")}).strip())\n    q - <Quit>                        m - Main Menu\n    """"""\n    keylist = [""%15s - %-15s"" % (kb_key, mapping[1])\n               for kb_key, mapping in keymap.items()]\n    keylist.insert(0, ""%15s - %-15s"" % (""q"", ""<Quit>""))\n    middle = int(math.ceil(float(len(keylist)) / 2))\n    rows = [\n        ""%s %s"" % (\n            keylist[i],\n            keylist[middle + i] if middle + i < len(keylist) else """")\n        for i in range(middle)]\n    return ""\\n"".join(rows)\n\n\ndef decoded(keycode):\n    """"""\n    >>> decoded(curses.KEY_BACKSPACE)\n    \'Backspace\'\n    >>> decoded(120)\n    \'x\'\n    """"""\n    if keycode in SPECIAL_CHARS:\n        return SPECIAL_CHARS[keycode]\n    try:\n        return chr(keycode)\n    except ValueError:\n        return None\n\n\ndef load_keymap(keymap_file):\n    keymap = collections.OrderedDict()\n    for line in keymap_file:\n        items = line.split(""//"")[0].split()\n        if len(items) < 2:\n            continue\n        if items[0] in keymap:\n            raise ConfigurationError(\n                ""Multiple remote control keys assigned to keyboard key \'%s\' ""\n                ""in the keymap file"" % items[0])\n        if len(items) == 2:\n            keymap[items[0]] = (items[1],) * 2\n        else:\n            keymap[items[0]] = (items[1], "" "".join(items[2:]))\n        validate(items[0])\n    return keymap\n\n\ndef test_load_keymap():\n    keymap = load_keymap(io.StringIO(\n        ""Backspace  BACK  Go back to previous\\n""  # Test display name\n        ""Enter  OK  //Move forward\\n""))  # Test comments\n    assert keymap[""Backspace""] == (""BACK"", ""Go back to previous"")\n    assert keymap[""Enter""] == (""OK"", ""OK"")\n\n\ndef test_load_keymap_with_duplicated_key():\n    try:\n        load_keymap(io.StringIO(""o OK\\no OPEN\\n""))\n        assert False, ""load_keymap should have thrown ConfigurationError""\n    except ConfigurationError:\n        pass\n\n\ndef validate(keyname):\n    if keyname in SPECIAL_CHARS.values():\n        return\n    try:\n        ord(keyname)\n    except TypeError:\n        raise ValueError(""Invalid keyboard key in the keymap file: "" + keyname)\n\n\ndef test_validate():\n    try:\n        validate(""Invalid"")\n        assert False\n    except ValueError:\n        pass\n\n\ndef default_keymap_file():\n    config_dir = os.environ.get(\n        \'XDG_CONFIG_HOME\', \'%s/.config\' % os.environ[\'HOME\'])\n    return get_config(""control"", ""keymap"", """") or \\\n        os.path.join(config_dir, ""stbt"", ""control.conf"")\n\n\ndef error(s):\n    sys.stderr.write(""%s: error: %s\\n"" % (\n        os.path.basename(sys.argv[0]), str(s)))\n    sys.exit(1)\n\n\nif __name__ == ""__main__"":\n    main(sys.argv)\n'"
stbt_control_relay.py,0,"b'#!/usr/bin/python\n""""""\nAllows using any of the stbt remote control backends remotely using the lirc\nprotocol.\n\nPresents the same socket protocol as lircd but sending keypresses using any of\nstbt\'s controls.  This allows for example controlling a roku over its HTTP\ninterface from some software that only speaks lirc.\n\nExample usage:\n\n    $ stbt control-relay file:example\n\nListens on `/var/run/lirc/lircd` for lirc clients.  Keypress sent will be\nwritten to the file example.  So\n\n    $ irsend SEND_ONCE stbt KEY_UP\n\nWill write the text ""KEY_UP"" to the file `example`.\n\n    $ stbt control-relay --socket=lircd.sock roku:192.168.1.13\n\nListens on lircd.sock and will forward keypresses to the roku at 192.168.1.13\nusing its HTTP protocol.  So\n\n    $ irsend -d lircd.sock SEND_ONCE stbt KEY_OK\n\nWill press KEY_OK on the roku device.\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport argparse\nimport logging\nimport os\nimport re\nimport signal\nimport socket\nimport sys\n\nfrom _stbt.control import uri_to_control\nfrom _stbt.utils import to_bytes\n\n\ndef main(argv):\n    parser = argparse.ArgumentParser(\n        epilog=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter)\n    parser.add_argument(\n        ""--socket"", default=""/var/run/lirc/lircd"", help=""""""LIRC socket to read\n        remote control presses from (defaults to %(default)s)."""""")\n    parser.add_argument(""-v"", ""--verbose"", action=""store_true"")\n    parser.add_argument(""output"", help=""""""Remote control configuration to\n        transmit on. Values are the same as stbt run\'s --control."""""")\n    args = parser.parse_args(argv[1:])\n\n    logging.basicConfig(\n        format=""%(levelname)s: %(message)s"",\n        level=logging.DEBUG if args.verbose else logging.INFO)\n\n    signal.signal(signal.SIGTERM, lambda _signo, _stack_frame: sys.exit(0))\n\n    if os.environ.get(\'LISTEN_FDS\') == \'1\' and \\\n            os.environ.get(\'LISTEN_PID\') == str(os.getpid()):\n        s = socket.fromfd(3, socket.AF_UNIX, socket.SOCK_STREAM)\n    else:\n        s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        s.bind(args.socket)\n        s.listen(5)\n\n    control = uri_to_control(args.output)\n\n    logging.info(""stbt-control-relay started up with output \'%s\'"", args.output)\n\n    while True:\n        conn, _ = s.accept()\n        f = conn.makefile(\'rb\', 0)\n        while True:\n            cmd = f.readline()\n            if not cmd:\n                break\n            cmd = cmd.rstrip(b""\\n"")\n            m = re.match(br""(?P<action>SEND_ONCE|SEND_START|SEND_STOP) ""\n                         br""(?P<ctrl>\\S+) (?P<key>\\S+)"", cmd)\n            if not m:\n                logging.error(""Invalid command: %s"", cmd)\n                send_response(conn, cmd, success=False,\n                              data=b""Invalid command: %s"" % cmd)\n                continue\n            action = m.group(""action"")\n            key = m.group(""key"")\n            logging.debug(""Received %s %s"", action, key)\n            try:\n                key = key.decode(""utf-8"")\n                if action == b""SEND_ONCE"":\n                    control.press(key)\n                elif action == b""SEND_START"":\n                    control.keydown(key)\n                elif action == b""SEND_STOP"":\n                    control.keyup(key)\n            except Exception as e:  # pylint: disable=broad-except\n                logging.error(""Error pressing key %r: %s"", key, e,\n                              exc_info=True)\n                send_response(conn, cmd, success=False, data=to_bytes(str(e)))\n                continue\n            send_response(conn, cmd, success=True)\n\n\ndef send_response(sock, request, success, data=b""""):\n    # See http://www.lirc.org/html/lircd.html\n    message = b""BEGIN\\n%s\\n%s\\n"" % (\n        request,\n        b""SUCCESS"" if success else b""ERROR"")\n    if data:\n        data = data.split(b""\\n"")\n        message += b""DATA\\n%d\\n%s\\n"" % (len(data), b""\\n"".join(data))\n    message += b""END\\n""\n\n    try:\n        sock.sendall(message)\n    except Exception:  # pylint: disable=broad-except\n        pass\n\n\nif __name__ == ""__main__"":\n    sys.exit(main(sys.argv))\n'"
stbt_lint.py,0,"b'#!/usr/bin/python\n\n# Copyright 2014-2017 Stb-tester.com Ltd.\n# Copyright 2013 YouView TV Ltd.\n# License: LGPL v2.1 or (at your option) any later version (see\n# https://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n\n""""""Run static analysis over the specified stb-tester python scripts.\n\n""stbt lint"" runs ""pylint"" with the following additional checkers:\n\n* E7001: The image path given to ""stbt.match"" (and similar functions)\n  does not exist on disk.\n* E7002: The return value from is_screen_black, match, match_text, ocr,\n  press_and_wait, or wait_until isn\'t used (perhaps you\'ve forgotten to\n  use ""assert"").\n* E7003: The argument given to ""wait_until"" must be a callable (such as\n  a function or lambda expression).\n* E7004: FrameObject properties must always provide ""self._frame"" as the\n  ""frame"" parameter to functions such as ""stbt.match"".\n* E7005: The image path given to ""stbt.match"" (and similar functions)\n  exists on disk, but isn\'t committed to git.\n* E7006: FrameObject properties must use ""self._frame"", not\n  ""stbt.get_frame()"".\n* E7007: FrameObject properties must not have side-effects that change\n  the state of the device-under-test by calling ""stbt.press()"" or\n  ""stbt.press_and_wait()"".\n* E7008: ""assert True"" has no effect.\n\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport argparse\nimport subprocess\nimport sys\n\n\ndef main(argv):\n    parser = argparse.ArgumentParser(\n        prog=""stbt lint"",\n        usage=""stbt lint [--help] [pylint options] filename [filename...]"",\n        description=__doc__,\n        epilog=""Any other command-line arguments are passed through to pylint."",\n        formatter_class=argparse.RawDescriptionHelpFormatter)\n    _, pylint_args = parser.parse_known_args(argv[1:])\n\n    if not pylint_args:\n        parser.print_usage(sys.stderr)\n        return 1\n\n    if sys.version_info.major == 2:\n        executable_name = ""pylint""\n    else:\n        executable_name = ""pylint3""\n\n    try:\n        with open(""/dev/null"", ""w"") as devnull:\n            subprocess.check_call([executable_name, ""--help""],\n                                  stdout=devnull, stderr=devnull)\n    except OSError as e:\n        if e.errno == 2:\n            sys.stderr.write(\n                ""stbt lint: error: Couldn\'t find \'%s\' executable\\n""\n                % executable_name)\n            return 1\n\n    return subprocess.call(\n        [executable_name, ""--load-plugins=stbt.pylint_plugin""] + pylint_args)\n\n\nif __name__ == ""__main__"":\n    sys.exit(main(sys.argv))\n'"
stbt_match.py,0,"b'#!/usr/bin/python\n\n""""""\nCopyright 2013 YouView TV Ltd.\nLicense: LGPL v2.1 or (at your option) any later version (see\nhttps://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport argparse\nimport sys\nfrom contextlib import contextmanager\n\nimport cv2\n\nimport _stbt.logging\nimport stbt\n\n\ndef error(s):\n    sys.stderr.write(""stbt match: error: %s\\n"" % s)\n    sys.exit(1)\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.prog = ""stbt match""\n    parser.description = """"""Run stbt\'s image-matching algorithm against a single\n        frame (which you can capture using `stbt screenshot`).""""""\n    parser.add_argument(\n        ""-v"", ""--verbose"", action=""store_true"",\n        help=""Dump image processing debug images to ./stbt-debug directory"")\n    parser.add_argument(\n        ""--all"", action=""store_true"",\n        help=\'Use ""stbt.match_all"" instead of ""stbt.match""\')\n    parser.add_argument(\n        ""source_file"", help=""""""The screenshot to compare against (you can\n            capture it using \'stbt screenshot\')"""""")\n    parser.add_argument(\n        ""reference_file"", help=""The image to search for"")\n    parser.add_argument(\n        ""match_parameters"", nargs=""*"",\n        help=""""""Parameters for the image processing algorithm. See\n            \'MatchParameters\' in the stbt API documentation. For example:\n            \'confirm_threshold=0.70\')"""""")\n    args = parser.parse_args(sys.argv[1:])\n\n    mp = {}\n    try:\n        for p in args.match_parameters:\n            name, value = p.split(""="")\n            if name == ""match_method"":\n                mp[""match_method""] = value\n            elif name == ""match_threshold"":\n                mp[""match_threshold""] = float(value)\n            elif name == ""confirm_method"":\n                mp[""confirm_method""] = value\n            elif name == ""confirm_threshold"":\n                mp[""confirm_threshold""] = float(value)\n            elif name == ""erode_passes"":\n                mp[""erode_passes""] = int(value)\n            else:\n                raise Exception(""Unknown match_parameter argument \'%s\'"" % p)\n    except Exception:  # pylint:disable=broad-except\n        error(""Invalid argument \'%s\'"" % p)\n\n    source_image = cv2.imread(args.source_file)\n    if source_image is None:\n        error(""Invalid image \'%s\'"" % args.source_file)\n\n    with (_stbt.logging.scoped_debug_level(2) if args.verbose\n          else noop_contextmanager()):\n        match_found = False\n        for result in stbt.match_all(\n                args.reference_file, frame=source_image,\n                match_parameters=stbt.MatchParameters(**mp)):\n            print(""%s: %s"" % (\n                ""Match found"" if result else ""No match found. Closest match"",\n                result))\n            if result:\n                match_found = True\n            if not args.all:\n                break\n        sys.exit(0 if match_found else 1)\n\n\n@contextmanager\ndef noop_contextmanager():\n    yield\n\n\nif __name__ == ""__main__"":\n    main()\n'"
stbt_power.py,0,"b'#!/usr/bin/python\n\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport argparse\nimport sys\nfrom textwrap import dedent\n\nfrom _stbt.config import get_config\nfrom _stbt.power import uri_to_power_outlet\n\n\ndef main(argv):\n    parser = argparse.ArgumentParser(\n        description=""Control and query a computer controllable power outlet"",\n        formatter_class=argparse.RawTextHelpFormatter)\n    parser.add_argument(\n        ""--power-outlet"", metavar=""URI"",\n        default=get_config(""global"", ""power_outlet"", """"), help=dedent(""""""\\\n             Address of the power device and the outlet on the device.\n             The format of <uri> is either:\n               aten:<hostname>:<outlet> - For ATEN network controlled PDU\n               ipp:<hostname>:<outlet> - For IP Power 9258 network controlled PDU\n               pdu:<hostname>:<outlet> - For PDUeX KWX network controlled PDU\n               rittal:<hostname>:<outlet>:<community> - For Rittal 7955.310 network controlled PDU\n               aviosys-8800-pro[:<serial device>] - For Aviosys 8800 Pro USB\n                   controlled outlets\n             where\n               <hostname>       The device\'s network address.\n               <outlet>         Address of the individual power outlet on\n                                the device. Allowed values depend on the\n                                specific device model.\n               <serial device>  The device name of the serial device that the\n                                8800 Pro exposes.  Defaults to /dev/ttyACM0\n             This URI defaults to from stbt.conf\'s ""global.power_outlet"" if not\n             specified on the command line.\n             """"""))\n\n    parser.add_argument(\n        ""command"", choices=[""on"", ""off"", ""status""], metavar=""command"",\n        help=dedent(""""""\\\n            on|off:  Turn power on or off\n            status:  Prints ON if the outlet is powered, otherwise prints OFF\n            """"""))\n    args = parser.parse_args(argv[1:])\n\n    outlet = uri_to_power_outlet(args.power_outlet)\n\n    if args.command == ""on"":\n        outlet.set(True)\n    elif args.command == ""off"":\n        outlet.set(False)\n    elif args.command == ""status"":\n        sys.stdout.write(""ON\\n"" if outlet.get() else ""OFF\\n"")\n    else:\n        assert False\n\nif __name__ == \'__main__\':\n    sys.exit(main(sys.argv))\n'"
stbt_record.py,0,"b'#!/usr/bin/python\n\n""""""\nCopyright 2012-2013 YouView TV Ltd.\nLicense: LGPL v2.1 or (at your option) any later version (see\nhttps://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport itertools\nimport sys\n\nimport _stbt.control\nimport _stbt.core\nimport stbt\n\n\ndef main(argv):\n    parser = _stbt.core.argparser()\n    parser.prog = \'stbt record\'\n    parser.description = \'Create an stb-tester test script\'\n    parser.add_argument(\n        \'--control-recorder\',\n        default=stbt.get_config(\'record\', \'control_recorder\'),\n        help=\'The source of remote control keypresses (default: %(default)s)\')\n    parser.add_argument(\n        \'-o\', \'--output-file\',\n        default=stbt.get_config(\'record\', \'output_file\'),\n        help=\'The filename of the generated script (default: %(default)s)\')\n    args = parser.parse_args(argv[1:])\n    stbt.debug(""Arguments:\\n"" + ""\\n"".join([\n        ""%s: %s"" % (k, v) for k, v in args.__dict__.items()]))\n\n    try:\n        script = open(args.output_file, \'w\')\n    except IOError as e:\n        e.strerror = ""Failed to write to output-file \'%s\': %s"" % (\n            args.output_file, e.strerror)\n        raise\n\n    with _stbt.core.new_device_under_test_from_config(args) as dut:\n        record(dut, args.control_recorder, script)\n\n\ndef record(dut, control_recorder, script_out):\n    dut.get_frame()  # Fail early if no video\n    count = itertools.count(1)\n    old_key = None\n\n    def write_wait_for_match():\n        if old_key is None:\n            return\n        filename = ""%04d-%s-complete.png"" % (next(count), old_key)\n        stbt.save_frame(dut.get_frame(), filename)\n        script_out.write(""    stbt.wait_for_match(\'%s\')\\n"" % filename)\n\n    script_out.write(""import stbt\\n\\n\\n"")\n    script_out.write(""def test_that_WRITE_TESTCASE_DESCRIPTION_HERE():\\n"")\n    try:\n        for key in _stbt.control.uri_to_control_recorder(control_recorder):\n            write_wait_for_match()\n            script_out.write(""    stbt.press(\'%s\')\\n"" % key)\n            dut.press(key)\n            old_key = key\n    except KeyboardInterrupt:\n        write_wait_for_match()\n        return\n    write_wait_for_match()\n\n\nif __name__ == ""__main__"":\n    sys.exit(main(sys.argv))\n'"
stbt_run.py,0,"b'#!/usr/bin/python\n\n""""""\nCopyright 2012-2013 YouView TV Ltd.\n          2014-2017 stb-tester.com Ltd.\nLicense: LGPL v2.1 or (at your option) any later version (see\nhttps://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport argparse\nimport sys\n\nimport _stbt.core\nimport stbt\nfrom _stbt.stbt_run import (load_test_function,\n                            sane_unicode_and_exception_handling, video)\n\n\ndef main(argv):\n    parser = _stbt.core.argparser()\n    parser.prog = \'stbt run\'\n    parser.description = \'Run an stb-tester test script\'\n    parser.add_argument(\n        \'--save-screenshot\', default=\'on-failure\',\n        choices=[\'always\', \'on-failure\', \'never\'],\n        help=""Save a screenshot at the end of the test to screenshot.png"")\n    parser.add_argument(\n        \'--save-thumbnail\', default=\'never\',\n        choices=[\'always\', \'on-failure\', \'never\'],\n        help=""Save a thumbnail at the end of the test to thumbnail.jpg"")\n    parser.add_argument(\n        \'script\', metavar=\'FILE[::TESTCASE]\', help=(\n            ""The python test script to run. Optionally specify a python ""\n            ""function name to run that function; otherwise only the script\'s ""\n            ""top-level will be executed.""))\n    parser.add_argument(\n        \'args\', nargs=argparse.REMAINDER, metavar=\'ARG\',\n        help=\'Additional arguments passed on to the test script (in sys.argv)\')\n\n    args = parser.parse_args(argv[1:])\n    stbt.debug(""Arguments:\\n"" + ""\\n"".join([\n        ""%s: %s"" % (k, v) for k, v in args.__dict__.items()]))\n\n    dut = _stbt.core.new_device_under_test_from_config(args)\n    with sane_unicode_and_exception_handling(args.script), video(args, dut):\n        test_function = load_test_function(args.script, args.args)\n        test_function.call()\n\n\nif __name__ == \'__main__\':\n    sys.exit(main(sys.argv))\n'"
stbt_virtual_stb.py,0,"b'#!/usr/bin/python\n""""""\nstbt virtual-stb enables stb-tester to test set-top box software without\nhardware.  This can be useful as a first stage in a continuous integration\npipeline as testing can be scaled up with computing resources rather than\nrelying on fixed hardware.\n\nEXAMPLE USAGE\n-------------\n\nRun some tests against youtube HTML5 TV edition:\n\n    # With this your existing stbt configuration won\'t be overridden:\n    export STBT_CONFIG_FILE=/tmp/stbt.conf\n\n    # This launches chromium and configures stbt (by modifying\n    # $STBT_CONFIG_FILE) to read video from chromium and to send keypresses to\n    # chromium:\n    stbt virtual-stb run --background chromium --app=http://youtube.com/tv\n\n    # Run a test against the YouTube UI we started in the previous command:\n    stbt run tests/youtube.py::test_playing_popular_content\n\n    # Tear down the chromium virtual-stb and remove the configuration:\n    stbt virtual-stb stop\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport argparse\nimport errno\nimport multiprocessing\nimport os\nimport signal\nimport subprocess\nimport sys\nimport time\nfrom contextlib import contextmanager\n\nfrom _stbt.config import get_config, set_config\nfrom _stbt.x11 import x_server\n\n\n@contextmanager\ndef virtual_stb(command, x_keymap=None, verbose=False):\n    config = {}\n    if x_keymap is not None:\n        if not os.path.exists(x_keymap):\n            raise IOError(""x keymap file %r does not exist"" % x_keymap)\n        config[\'x_keymap\'] = os.path.abspath(x_keymap)\n    else:\n        config[\'x_keymap\'] = """"\n\n    with x_server(1280, 720, verbose=verbose) as display:\n        subprocess.Popen(\n            [\'ratpoison\', \'-d\', display], close_fds=True,\n            stdin=open(\'/dev/null\', \'r\'), stdout=open(\'/dev/null\', \'w\'),\n            stderr=subprocess.STDOUT)\n\n        os.environ[\'DISPLAY\'] = display\n        child = subprocess.Popen(command)\n\n        try:\n            config.update({\n                ""control"": ""x11:%(x_display)s,%(x_keymap)s"",\n                ""source_pipeline"": (\n                    \'ximagesrc use-damage=false remote=true show-pointer=false \'\n                    \'display-name=%(x_display)s ! video/x-raw,framerate=24/1\'),\n                ""x_display"": display,\n                ""vstb_child_pid"": str(child.pid),\n                ""vstb_pid"": str(os.getpid()),\n            })\n            yield (child, config)\n        finally:\n            if child.poll() is None:\n                child.terminate()\n\n\ndef main(argv):\n    parser = argparse.ArgumentParser(\n        description=""Configure stb-tester to use a local X11 program as ""\n                    ""input/output."", epilog=__doc__,\n        formatter_class=argparse.RawDescriptionHelpFormatter)\n    subparsers = parser.add_subparsers(dest=\'subcommand\')\n    run_parser = subparsers.add_parser(\'run\')\n    run_parser.add_argument(\'-b\', \'--background\', action=""store_true"",\n                            help=""Run virtual-stb in background"")\n    run_parser.add_argument(\'-v\', \'--verbose\', action=""store_true"",\n                            help=""Print xorg logs to console"")\n    run_parser.add_argument(\n        \'--x-keymap\', help=""Filename of file mapping key names to X keysyms"")\n    run_parser.add_argument(\'command\', nargs=1)\n    run_parser.add_argument(\'args\', nargs=argparse.REMAINDER)\n\n    stop_parser = subparsers.add_parser(\'stop\')\n    stop_parser.add_argument(\'-f\', \'--force\', action=""store_true"",\n                             help=""Ignore errors"")\n\n    args = parser.parse_args(argv[1:])\n\n    if args.subcommand == \'run\':\n        # Do run our `finally` teardown blocks on SIGTERM\n        signal.signal(signal.SIGTERM, lambda _signo, _frame: sys.exit(0))\n\n        write_end = None\n        if args.background:\n            read_end, write_end = multiprocessing.Pipe(duplex=False)\n            pid = os.fork()\n            if pid:\n                # Parent - wait for child to be ready\n                write_end.close()\n                read_end.recv()\n                return 0\n            else:\n                # Child\n                read_end.close()\n\n        with virtual_stb(args.command + args.args, verbose=args.verbose,\n                         x_keymap=args.x_keymap) as (child, config):\n            for k, v in config.items():\n                set_config(\'global\', k, v)\n\n            try:\n                if write_end is not None:\n                    write_end.send(True)\n                    write_end.close()\n                child.wait()\n            finally:\n                for k in config:\n                    set_config(\'global\', k, None)\n    elif args.subcommand == \'stop\':\n        try:\n            pid = get_config(\'global\', \'vstb_pid\', None)\n            set_config(\'global\', \'vstb_pid\', None)\n            os.kill(int(pid), signal.SIGTERM)\n            while True:\n                try:\n                    os.kill(int(pid), 0)\n                    time.sleep(0.1)\n                except OSError as e:\n                    if e.errno == errno.ESRCH:\n                        return 0\n                    else:\n                        raise\n        except Exception:  # pylint: disable=broad-except\n            if not args.force:\n                raise\n\nif __name__ == \'__main__\':\n    sys.exit(main(sys.argv))\n'"
_stbt/__init__.py,0,b''
_stbt/black.py,0,"b'# coding: utf-8\n\n""""""\nCopyright 2014 YouView TV Ltd.\nCopyright 2014-2018 stb-tester.com Ltd.\n\nLicense: LGPL v2.1 or (at your option) any later version (see\nhttps://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport cv2\n\nfrom .config import get_config\nfrom .imgutils import (_frame_repr, _image_region, _ImageFromUser, _load_image,\n                       pixel_bounding_box, crop)\nfrom .logging import debug, ImageLogger\nfrom .types import Region\n\n\ndef is_screen_black(frame=None, mask=None, threshold=None, region=Region.ALL):\n    """"""Check for the presence of a black screen in a video frame.\n\n    :type frame: `stbt.Frame` or `numpy.ndarray`\n    :param frame:\n      If this is specified it is used as the video frame to check; otherwise a\n      new frame is grabbed from the device-under-test. This is an image in\n      OpenCV format (for example as returned by `frames` and `get_frame`).\n\n    :type mask: str or `numpy.ndarray`\n    :param mask:\n        A black & white image that specifies which part of the image to\n        analyse. White pixels select the area to analyse; black pixels select\n        the area to ignore. The mask must be the same size as the video frame.\n\n        This can be a string (a filename that will be resolved as per\n        `load_image`) or a single-channel image in OpenCV format.\n\n    :param int threshold:\n      Even when a video frame appears to be black, the intensity of its pixels\n      is not always 0. To differentiate almost-black from non-black pixels, a\n      binary threshold is applied to the frame. The ``threshold`` value is in\n      the range 0 (black) to 255 (white). The global default can be changed by\n      setting ``threshold`` in the ``[is_screen_black]`` section of\n      :ref:`.stbt.conf`.\n\n    :type region: `Region`\n    :param region:\n        Only analyze the specified region of the video frame.\n\n        If you specify both ``region`` and ``mask``, the mask must be the same\n        size as the region.\n\n    :returns:\n        An object that will evaluate to true if the frame was black, or false\n        if not black. The object has the following attributes:\n\n        * **black** (*bool*) \xe2\x80\x93 True if the frame was black.\n        * **frame** (`stbt.Frame`) \xe2\x80\x93 The video frame that was analysed.\n    """"""\n    if threshold is None:\n        threshold = get_config(\'is_screen_black\', \'threshold\', type_=int)\n\n    if frame is None:\n        import stbt\n        frame = stbt.get_frame()\n\n    if mask is None:\n        mask = _ImageFromUser(None, None, None)\n    else:\n        mask = _load_image(mask, cv2.IMREAD_GRAYSCALE)\n\n    imglog = ImageLogger(""is_screen_black"", region=region, threshold=threshold)\n    imglog.imwrite(""source"", frame)\n\n    _region = Region.intersect(_image_region(frame), region)\n    greyframe = cv2.cvtColor(crop(frame, _region), cv2.COLOR_BGR2GRAY)\n    if mask.image is not None:\n        imglog.imwrite(""mask"", mask.image)\n        cv2.bitwise_and(greyframe, mask.image, dst=greyframe)\n    maxVal = greyframe.max()\n\n    result = _IsScreenBlackResult(bool(maxVal <= threshold), frame)\n    debug(""is_screen_black: {found} black screen using mask={mask}, ""\n          ""threshold={threshold}, region={region}: ""\n          ""{result}, maximum_intensity={maxVal}"".format(\n              found=""Found"" if result.black else ""Didn\'t find"",\n              mask=mask.friendly_name,\n              threshold=threshold,\n              region=region,\n              result=result,\n              maxVal=maxVal))\n\n    if imglog.enabled:\n        imglog.imwrite(""grey"", greyframe)\n        _, thresholded = cv2.threshold(greyframe, threshold, 255,\n                                       cv2.THRESH_BINARY)\n        imglog.imwrite(""non_black"", thresholded)\n        imglog.set(maxVal=maxVal,\n                   non_black_region=pixel_bounding_box(thresholded))\n    _log_image_debug(imglog, result)\n\n    return result\n\n\nclass _IsScreenBlackResult(object):\n    def __init__(self, black, frame):\n        self.black = black\n        self.frame = frame\n\n    def __bool__(self):\n        return self.black\n\n    def __repr__(self):\n        return (""_IsScreenBlackResult(black=%r, frame=%s)"" % (\n            self.black,\n            _frame_repr(self.frame)))\n\n\ndef _log_image_debug(imglog, result):\n    if not imglog.enabled:\n        return\n\n    template = u""""""\\\n        <h4>is_screen_black: {{result.black}}</h4>\n\n        {{ annotated_image(non_black_region) }}\n\n        {% if ""mask"" in images %}\n        <h5>Mask:</h5>\n        <img src=""mask.png"" />\n        {% endif %}\n\n        <h5>Greyscale, masked:</h5>\n        <img src=""grey.png"">\n        <ul>\n          <li>Maximum pixel intensity: {{maxVal}}\n          <li>threshold={{threshold}}\n        </ul>\n\n        {% if not result.black %}\n        <h5>Non-black pixels in region:</h5>\n        <img src=""non_black.png"" />\n        {% endif %}\n    """"""\n\n    imglog.html(template, result=result)\n'"
_stbt/config.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nfrom future.utils import native_str\n\nimport configparser\nimport enum\nimport os\nfrom contextlib import contextmanager\n\n_config = None\n\n\nclass ConfigurationError(Exception):\n    """"""An error with your stbt configuration file.""""""\n    pass\n\n\nclass NoDefault(object):\n    pass\n\n\ndef get_config(section, key, default=NoDefault, type_=str):\n    """"""Read the value of ``key`` from ``section`` of the test-pack\n    configuration file.\n\n    For example, if your configuration file looks like this::\n\n        [test_pack]\n        stbt_version = 30\n\n        [my_company_name]\n        backend_ip = 192.168.1.23\n\n    then you can read the value from your test script like this::\n\n        backend_ip = stbt.get_config(""my_company_name"", ""backend_ip"")\n\n    This searches in the ``.stbt.conf`` file at the root of your test-pack, and\n    in the ``config/test-farm/<hostname>.conf`` file matching the hostname of\n    the stb-tester device where the script is running. Values in the\n    host-specific config file override values in ``.stbt.conf``. See\n    `Configuration files\n    <https://stb-tester.com/manual/advanced-configuration#configuration-files>`__\n    for more details.\n\n    Test scripts can use ``get_config`` to read tags that you specify at\n    run-time: see `Automatic configuration keys\n    <https://stb-tester.com/manual/advanced-configuration#automatic-configuration-keys>`__.\n\n    Raises `ConfigurationError` if the specified ``section`` or ``key`` is not\n    found, unless ``default`` is specified (in which case ``default`` is\n    returned).\n    """"""\n\n    config = _config_init()\n\n    try:\n        if type_ is bool:\n            return config.getboolean(section, key)\n        elif issubclass(type_, enum.Enum):\n            return _to_enum(type_, config.get(section, key), section, key)\n        else:\n            return type_(config.get(section, key))\n    except configparser.Error as e:\n        if default is NoDefault:\n            raise ConfigurationError(e.message)\n        else:\n            return default\n    except ValueError:\n        raise ConfigurationError(""\'%s.%s\' invalid type (must be %s)"" % (\n            section, key, type_.__name__))\n\n\ndef set_config(section, option, value):\n    """"""Update config values (in memory and on disk).\n\n    WARNING: This will overwrite your stbt.conf but comments and whitespace\n    will not be preserved.  For this reason it is not a part of stbt\'s public\n    API.  This is a limitation of Python\'s ConfigParser which hopefully we can\n    solve in the future.\n\n    Writes to the first item in `$STBT_CONFIG_FILE` if set falling back to\n    `$HOME/.config/stbt/stbt.conf`.\n    """"""\n    from .utils import mkdir_p\n\n    user_config = \'%s/stbt/stbt.conf\' % xdg_config_dir()\n    # Write to the config file with the highest precedence\n    custom_config = os.environ.get(\'STBT_CONFIG_FILE\', \'\').split(\':\')[0] \\\n        or user_config\n\n    config = _config_init()\n\n    parser = configparser.ConfigParser()\n    parser.read([custom_config])\n    if value is not None:\n        if not parser.has_section(section):\n            parser.add_section(section)\n        parser.set(section, option, value)\n    else:\n        try:\n            parser.remove_option(section, option)\n        except configparser.NoSectionError:\n            pass\n\n    d = os.path.dirname(custom_config)\n    mkdir_p(d)\n    with _sponge(custom_config) as f:\n        parser.write(f)\n\n    if value is not None:\n        if not config.has_section(section):\n            config.add_section(section)\n        config.set(section, option, value)\n\n\ndef _config_init(force=False):\n    global _config\n    if force or not _config:\n        config_files = [_find_file(\'stbt.conf\')]\n        try:\n            # Host-wide config, e.g. /etc/stbt/stbt.conf (see `Makefile`).\n            from .vars import sysconfdir\n            config_files.append(os.path.join(sysconfdir, \'stbt/stbt.conf\'))\n        except ImportError:\n            pass\n\n        # User config: ~/.config/stbt/stbt.conf, as per freedesktop\'s base\n        # directory specification:\n        config_files.append(\'%s/stbt/stbt.conf\' % xdg_config_dir())\n\n        # Config files specific to the test suite / test run,\n        # with the one at the beginning taking precedence:\n        config_files.extend(\n            reversed(os.environ.get(\'STBT_CONFIG_FILE\', \'\')\n                     .split(native_str(\':\'))))\n        config = configparser.ConfigParser()\n        config.read(config_files)\n        _config = config\n    return _config\n\n\ndef xdg_config_dir():\n    return os.environ.get(\'XDG_CONFIG_HOME\', \'%s/.config\' % os.environ[\'HOME\'])\n\n\ndef _to_enum(type_, value, section, key):\n    # Try enum name\n    try:\n        return type_[value.upper()]\n    except KeyError:\n        pass\n\n    # Try enum value\n    try:\n        if issubclass(type_, enum.IntEnum):\n            value = int(value)\n        return type_(value)\n    except ValueError:\n        pass\n\n    raise ConfigurationError(\n        \'Invalid config value %s.%s=""%s"". Valid values are %s.\'\n        % (section, key, value, "", "".join(x.name for x in type_)))\n\n\n@contextmanager\ndef _sponge(filename, mode=""w""):\n    """"""Opens a file to be written, which will be atomically replaced if the\n    contextmanager exits cleanly.  Useful like the UNIX moreutils command\n    `sponge`\n    """"""\n    from tempfile import NamedTemporaryFile\n    with NamedTemporaryFile(mode=mode, prefix=filename + \'.\', suffix=\'~\',\n                            delete=False) as f:\n        try:\n            yield f\n            os.rename(f.name, filename)\n        except:\n            os.remove(f.name)\n            raise\n\n\ndef _find_file(path, root=os.path.dirname(os.path.abspath(__file__))):\n    return os.path.join(root, path)\n'"
_stbt/control.py,0,"b'from __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport os\nimport re\nimport socket\nimport struct\nimport subprocess\nimport sys\nimport time\nfrom contextlib import contextmanager\nfrom distutils.spawn import find_executable\n\nfrom . import irnetbox\nfrom .config import ConfigurationError\nfrom .logging import debug, scoped_debug_level\nfrom .utils import named_temporary_directory, to_bytes, to_native_str\n\n__all__ = [\'uri_to_control\', \'uri_to_control_recorder\']\n\ntry:\n    from .control_gpl import controls as gpl_controls\nexcept ImportError:\n    gpl_controls = None\n\n\n# pylint: disable=abstract-method\n\nclass RemoteControl(object):\n    """"""Base class for remote-control implementations.""""""\n\n    def press(self, key):\n        raise NotImplementedError(\n            ""%s: \'press\' is not implemented"" % self.__class__.__name__)\n\n    def keydown(self, key):\n        raise NotImplementedError(\n            ""%s: \'keydown\' is not implemented"" % self.__class__.__name__)\n\n    def keyup(self, key):\n        raise NotImplementedError(\n            ""%s: \'keyup\' is not implemented"" % self.__class__.__name__)\n\n\nclass UnknownKeyError(Exception):\n    pass\n\n\ndef uri_to_control(uri, display=None):\n    controls = [\n        (r\'adb(:(?P<address>.*))?\', new_adb_device),\n        (r\'error(:(?P<message>.*))?\', ErrorControl),\n        (r\'file(:(?P<filename>[^,]+))?\', FileControl),\n        (r\'\'\'irnetbox:\n             (?P<hostname>[^:]+)\n             (:(?P<port>\\d+))?\n             :(?P<output>\\d+)\n             :(?P<config>[^:]+)\'\'\', IRNetBoxControl),\n        (r\'lirc(:(?P<hostname>[^:/]+))?:(?P<port>\\d+):(?P<control_name>.+)\',\n         new_tcp_lirc_control),\n        (r\'lirc:(?P<lircd_socket>[^:]+)?:(?P<control_name>.+)\',\n         new_local_lirc_control),\n        (r\'none\', NullControl),\n        (r\'roku:(?P<hostname>[^:]+)\', RokuHttpControl),\n        (r\'samsung:(?P<hostname>[^:/]+)(:(?P<port>\\d+))?\',\n         _new_samsung_tcp_control),\n        (r\'test\', lambda: VideoTestSrcControl(display)),\n        (r\'x11:(?P<display>[^,]+)?(,(?P<mapping>.+)?)?\', X11Control),\n        (r\'rfb:(?P<hostname>[^:/]+)(:(?P<port>\\d+))?\', RemoteFrameBuffer),\n    ]\n    if gpl_controls is not None:\n        controls += gpl_controls\n\n    for regex, factory in controls:\n        m = re.match(regex, uri, re.VERBOSE | re.IGNORECASE)\n        if m:\n            return factory(**m.groupdict())\n    raise ConfigurationError(\'Invalid remote control URI: ""%s""\' % uri)\n\n\ndef uri_to_control_recorder(uri):\n    controls = [\n        (\'file://(?P<filename>.+)\', file_control_recorder),\n        (r\'lirc(:(?P<hostname>[^:/]+))?:(?P<port>\\d+):(?P<control_name>.+)\',\n         lirc_control_listen_tcp),\n        (r\'lirc:(?P<lircd_socket>[^:]+)?:(?P<control_name>.+)\',\n         lirc_control_listen),\n        (r\'stbt-control(:(?P<keymap_file>.+))?\', stbt_control_listen),\n    ]\n\n    for regex, factory in controls:\n        m = re.match(regex, uri)\n        if m:\n            return factory(**m.groupdict())\n    raise ConfigurationError(\'Invalid remote control recorder URI: ""%s""\' % uri)\n\n\ndef new_adb_device(address):\n    from stbt.android import AdbDevice\n    tcpip = bool(re.match(r""\\d+\\.\\d+\\.\\d+\\.\\d+"", address))\n    return AdbDevice(adb_device=address, tcpip=tcpip)\n\n\nclass NullControl(RemoteControl):\n    def press(self, key):\n        debug(\'NullControl: Ignoring request to press ""%s""\' % key)\n\n    def keydown(self, key):\n        debug(\'NullControl: Ignoring request to hold ""%s""\' % key)\n\n    def keyup(self, key):\n        debug(\'NullControl: Ignoring request to release ""%s""\' % key)\n\n\nclass ErrorControl(RemoteControl):\n    def __init__(self, message):\n        if message is None:\n            message = ""No remote control configured""\n        self.message = message\n\n    def press(self, key):  # pylint:disable=unused-argument\n        raise RuntimeError(self.message)\n\n    def keydown(self, key):\n        raise RuntimeError(self.message)\n\n    def keyup(self, key):\n        raise RuntimeError(self.message)\n\n\nclass FileControl(RemoteControl):\n    """"""Writes keypress events to file.  Mostly useful for testing.  Defaults to\n    writing to stdout.\n    """"""\n    def __init__(self, filename):\n        if filename is None:\n            self.outfile = sys.stdout\n        else:\n            self.outfile = open(filename, \'w+\')\n\n    def press(self, key):\n        self.outfile.write(key + \'\\n\')\n        self.outfile.flush()\n\n    def keydown(self, key):\n        self.outfile.write(""Holding %s\\n"" % key)\n        self.outfile.flush()\n\n    def keyup(self, key):\n        self.outfile.write(""Released %s\\n"" % key)\n        self.outfile.flush()\n\n\nclass VideoTestSrcControl(RemoteControl):\n    """"""Remote control used by selftests.\n\n    Changes the videotestsrc image to the specified pattern (""0"" to ""20"").\n    See `gst-inspect videotestsrc`.\n    """"""\n\n    def __init__(self, display):\n        self.display = display\n\n    @property\n    def videosrc(self):\n        videosrc = self.display.source_pipeline.get_by_name(""videotestsrc0"")\n        if not videosrc:\n            raise ConfigurationError(\'The ""test"" control can only be used \'\n                                     \'with source-pipeline = ""videotestsrc""\')\n        return videosrc\n\n    def press(self, key):\n        if key not in [\n                0, ""smpte"",\n                1, ""snow"",\n                2, ""black"",\n                3, ""white"",\n                4, ""red"",\n                5, ""green"",\n                6, ""blue"",\n                7, ""checkers-1"",\n                8, ""checkers-2"",\n                9, ""checkers-4"",\n                10, ""checkers-8"",\n                11, ""circular"",\n                12, ""blink"",\n                13, ""smpte75"",\n                14, ""zone-plate"",\n                15, ""gamut"",\n                16, ""chroma-zone-plate"",\n                17, ""solid-color"",\n                18, ""ball"",\n                19, ""smpte100"",\n                20, ""bar""]:\n            raise RuntimeError(\n                \'Key ""%s"" not valid for the ""test"" control\' % key)\n        self.videosrc.props.pattern = to_native_str(key)\n        debug(""Pressed %s"" % key)\n\n\ndef _find_file(path, root=os.path.dirname(os.path.abspath(__file__))):\n    return os.path.join(root, path)\n\n\nclass LircControl(RemoteControl):\n    """"""Send a key-press via a LIRC-enabled infrared blaster.\n\n    See http://www.lirc.org/html/technical.html#applications\n    """"""\n\n    def __init__(self, control_name, connect_fn):\n        self.control_name = control_name\n        self._connect = connect_fn\n\n    def press(self, key):\n        s = self._connect()\n        command = b""SEND_ONCE %s %s"" % (to_bytes(self.control_name),\n                                        to_bytes(key))\n        s.sendall(command + b""\\n"")\n        _read_lircd_reply(s, command)\n        debug(""Pressed %s"" % key)\n\n    def keydown(self, key):\n        s = self._connect()\n        command = b""SEND_START %s %s"" % (to_bytes(self.control_name),\n                                         to_bytes(key))\n        s.sendall(command + b""\\n"")\n        _read_lircd_reply(s, command)\n        debug(""Holding %s"" % key)\n\n    def keyup(self, key):\n        s = self._connect()\n        command = b""SEND_STOP %s %s"" % (to_bytes(self.control_name),\n                                        to_bytes(key))\n        s.sendall(command + b""\\n"")\n        _read_lircd_reply(s, command)\n        debug(""Released %s"" % key)\n\n\ndef _read_lircd_reply(stream, command):\n    """"""Waits for lircd reply and checks if a LIRC send command was successful.\n\n    Waits for a reply message from lircd (called ""reply packet"" in the LIRC\n    reference) for the specified command; raises exception if it times out or\n    the reply contains an error message.\n\n    The structure of a lircd reply message for a SEND_ONCE|SEND_START|SEND_STOP\n    command is the following:\n\n    BEGIN\n    <command>\n    (SUCCESS|ERROR)\n    [DATA\n    <number-of-data-lines>\n    <error-message>]\n    END\n\n    See: http://www.lirc.org/html/technical.html#applications\n    """"""\n    reply = []\n    try:\n        for line in read_records(stream, b""\\n""):\n            if line == b""BEGIN"":\n                reply = []\n            reply.append(line)\n            if line == b""END"" and reply[1] == command:\n                break\n    except socket.timeout:\n        raise RuntimeError(\n            ""Timed out: No reply from LIRC remote control within %d seconds""\n            % stream.gettimeout())\n    if b""SUCCESS"" not in reply:\n        if b""ERROR"" in reply and len(reply) >= 6 and reply[3] == b""DATA"":\n            try:\n                num_data_lines = int(reply[4])\n                raise RuntimeError(""LIRC remote control returned error: %s""\n                                   % b"" "".join(reply[5:5 + num_data_lines]))\n            except ValueError:\n                pass\n        raise RuntimeError(""LIRC remote control returned unknown error"")\n\nDEFAULT_LIRCD_SOCKET = \'/var/run/lirc/lircd\'\n\n\ndef new_local_lirc_control(lircd_socket, control_name):\n    if lircd_socket is None:\n        lircd_socket = DEFAULT_LIRCD_SOCKET\n\n    def _connect():\n        try:\n            s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n            s.settimeout(3)\n            s.connect(lircd_socket)\n            return s\n        except socket.error as e:\n            e.args = ((""Failed to connect to Lirc socket %s: %s"" % (\n                lircd_socket, e)),)\n            e.strerror = e.args[0]\n            raise\n\n    # Connect once so that the test fails immediately if Lirc isn\'t running\n    # (instead of failing at the first `press` in the script).\n    debug(""LircControl: Connecting to %s"" % lircd_socket)\n    _connect()\n    debug(""LircControl: Connected to %s"" % lircd_socket)\n\n    return LircControl(control_name, _connect)\n\n\ndef new_tcp_lirc_control(control_name, hostname=None, port=None):\n    """"""Send a key-press via a LIRC-enabled device through a LIRC TCP listener.\n\n        control = new_tcp_lirc_control(""localhost"", ""8765"", ""humax"")\n        control.press(""MENU"")\n    """"""\n    if hostname is None:\n        hostname = \'localhost\'\n    if port is None:\n        port = 8765\n\n    port = int(port)\n\n    def _connect():\n        return _connect_tcp_socket(hostname, port)\n\n    # Connect once so that the test fails immediately if Lirc isn\'t running\n    # (instead of failing at the first `press` in the script).\n    debug(""TCPLircControl: Connecting to %s:%d"" % (hostname, port))\n    _connect()\n    debug(""TCPLircControl: Connected to %s:%d"" % (hostname, port))\n\n    return LircControl(control_name, _connect)\n\n\nclass RemoteFrameBuffer(RemoteControl):\n    """"""Send a key-press to a set-top box running a VNC Remote Frame Buffer\n        protocol.\n        Expected key press input:\n            <KEY_LABEL>\n\n        control = RemoteFrameBuffer(""192.168.0.123"")\n        control.press(""KEY_MENU"")\n    """"""\n\n    # Map our recommended keynames (from linux input-event-codes.h) to the\n    # equivalent RFB keyname.\n    _KEYNAMES = {\n        \'KEY_BACK\': 0xE002,\n        \'KEY_BLUE\': 0xE203,\n        \'KEY_CHANNELDOWN\': 0xE007,\n        \'KEY_CHANNELUP\': 0xE006,\n        \'KEY_DOWN\': 0xE101,\n        \'KEY_ELPS\': 0xEF00,\n        \'KEY_FASTFORWARD\': 0xE405,\n        \'KEY_GREEN\': 0xE201,\n        \'KEY_GUIDE\': 0xE00B,\n        \'KEY_HELP\': 0xE00A,\n        \'KEY_HOME\': 0xE015,\n        \'KEY_INFO\': 0xE00E,\n        \'KEY_INPUTSELECT\': 0xE010,\n        \'KEY_INTERACT\': 0xE008,\n        \'KEY_0\': 0xE300,\n        \'KEY_1\': 0xE301,\n        \'KEY_2\': 0xE302,\n        \'KEY_3\': 0xE303,\n        \'KEY_4\': 0xE304,\n        \'KEY_5\': 0xE305,\n        \'KEY_6\': 0xE306,\n        \'KEY_7\': 0xE307,\n        \'KEY_8\': 0xE308,\n        \'KEY_9\': 0xE309,\n        \'KEY_LEFT\': 0xE102,\n        \'KEY_MENU\': 0xE00A,\n        \'KEY_MUTE\': 0xE005,\n        \'KEY_MYTV\': 0xE009,\n        \'KEY_PAUSE\': 0xE401,\n        \'KEY_PLAY\': 0xE400,\n        \'KEY_PLAYPAUSE\': 0xE40A,\n        \'KEY_POWER\': 0xE000,\n        \'KEY_PRIMAFILA\': 0xEF00,\n        \'KEY_RECORD\': 0xE403,\n        \'KEY_RED\': 0xE200,\n        \'KEY_REWIND\': 0xE407,\n        \'KEY_RIGHT\': 0xE103,\n        \'KEY_SEARCH\': 0xEF03,\n        \'KEY_SELECT\': 0xE001,\n        \'KEY_SKY\': 0xEF01,\n        \'KEY_STOP\': 0xE402,\n        \'KEY_TEXT\': 0xE00F,\n        \'KEY_UP\': 0xE100,\n        \'KEY_VOLUMEDOWN\': 0xE004,\n        \'KEY_VOLUMEUP\': 0xE003,\n        \'KEY_YELLOW\': 0xE202\n    }\n\n    def __init__(self, hostname, port=None):\n        self.hostname = hostname\n        self.port = int(port or 5900)\n        self.timeout = 3\n        self.socket = None\n\n    def press(self, key):\n        self._connect_socket()\n        self._handshake()\n        self._press_down(key)\n        self._release(key)\n        self._close()\n\n    def _connect_socket(self):\n        self.socket = socket.socket()\n        s = self.socket\n        if self.timeout:\n            s.settimeout(self.timeout)\n        s.connect((self.hostname, self.port))\n        debug(\n            ""RemoteFrameBuffer: connected to %s:%d""\n            % (self.hostname, self.port))\n\n    def _handshake(self):\n        s = self.socket\n        prot_info = s.recv(20)\n        if prot_info != b\'RFB 003.008\\n\':\n            raise socket.error(""wrong RFB protocol info"")\n        s.send(b""RFB 003.003\\n"")\n        s.recv(4)\n        s.send(b\'\\0\')\n        s.recv(24)\n        debug(""RemoteFrameBuffer: handshake completed"")\n\n    def _press_down(self, key):\n        key_code = self._get_key_code(key)\n        self.socket.send(struct.pack(\'!BBxxI\', 4, 1, key_code))\n        debug(\n            ""RemoteFrameBuffer: pressed down (0x%04x)""\n            % key_code)\n\n    def _release(self, key):\n        key_code = self._get_key_code(key)\n        self.socket.send(struct.pack(\'!BBxxI\', 4, 0, key_code))\n        debug(""RemoteFrameBuffer: release (0x%04x)"" % key_code)\n\n    def _close(self):\n        self.socket.shutdown(socket.SHUT_RDWR)\n        self.socket.close()\n        debug(""RemoteFrameBuffer: socket connection closed"")\n\n    def _get_key_code(self, key):\n        key_code = self._KEYNAMES.get(key, key)\n        return key_code\n\n\nclass IRNetBoxControl(RemoteControl):\n    """"""Send a key-press via the network-controlled RedRat IRNetBox IR emitter.\n\n    See http://www.redrat.co.uk/products/irnetbox.html\n\n    """"""\n\n    def __init__(self, hostname, port, output, config):  # pylint:disable=redefined-outer-name\n        self.hostname = hostname\n        self.port = int(port or 10001)\n        self.output = int(output)\n        self.config = irnetbox.RemoteControlConfig(config)\n        # Connect once so that the test fails immediately if irNetBox not found\n        # (instead of failing at the first `press` in the script).\n        debug(""IRNetBoxControl: Connecting to %s"" % hostname)\n        with self._connect() as irnb:\n            irnb.power_on()\n        time.sleep(0.5)\n        debug(""IRNetBoxControl: Connected to %s"" % hostname)\n\n    def press(self, key):\n        with self._connect() as irnb:\n            irnb.irsend_raw(\n                port=self.output, power=100, data=self.config[key])\n        debug(""Pressed %s"" % key)\n\n    def _connect(self):\n        try:\n            return irnetbox.IRNetBox(self.hostname, self.port)\n        except socket.error as e:\n            e.args = ((""Failed to connect to IRNetBox %s: %s"" % (\n                self.hostname, e)),)\n            e.strerror = e.args[0]\n            raise\n\n\nclass RokuHttpControl(RemoteControl):\n    """"""Send a key-press via Roku remote control protocol.\n\n    See https://sdkdocs.roku.com/display/sdkdoc/External+Control+API\n    """"""\n\n    # Map our recommended keynames (from linux input-event-codes.h) to the\n    # equivalent Roku keyname.\n    _KEYNAMES = {\n        ""KEY_HOME"": ""Home"",\n        ""KEY_REWIND"": ""Rev"",\n        ""KEY_FASTFORWARD"": ""Fwd"",\n        ""KEY_PLAY"": ""Play"",\n        ""KEY_PAUSE"": ""Play"",\n        ""KEY_PLAYPAUSE"": ""Play"",\n        ""KEY_OK"": ""Select"",\n        ""KEY_LEFT"": ""Left"",\n        ""KEY_RIGHT"": ""Right"",\n        ""KEY_DOWN"": ""Down"",\n        ""KEY_UP"": ""Up"",\n        ""KEY_BACK"": ""Back"",\n        ""KEY_AGAIN"": ""InstantReplay"",\n        ""KEY_INFO"": ""Info"",\n        ""KEY_BACKSPACE"": ""Backspace"",\n        ""KEY_SEARCH"": ""Search"",\n        # Enter is for completing keyboard entry fields, such as search fields\n        # (it is not the same as Select).\n        ""KEY_ENTER"": ""Enter"",\n        ""KEY_VOLUMEDOWN"": ""VolumeDown"",\n        ""KEY_MUTE"": ""VolumeMute"",\n        ""KEY_VOLUMEUP"": ""VolumeUp"",\n    }\n\n    def __init__(self, hostname, timeout_secs=3):\n        self.hostname = hostname\n        self.timeout_secs = timeout_secs\n\n    def press(self, key):\n        import requests\n\n        roku_keyname = self._KEYNAMES.get(key, key)\n        response = requests.post(\n            ""http://%s:8060/keypress/%s"" % (self.hostname, roku_keyname),\n            timeout=self.timeout_secs)\n        response.raise_for_status()\n        debug(""Pressed %s"" % key)\n\n    def keydown(self, key):\n        import requests\n\n        roku_keyname = self._KEYNAMES.get(key, key)\n        response = requests.post(\n            ""http://%s:8060/keydown/%s"" % (self.hostname, roku_keyname),\n            timeout=self.timeout_secs)\n        response.raise_for_status()\n        debug(""Holding %s"" % key)\n\n    def keyup(self, key):\n        import requests\n\n        roku_keyname = self._KEYNAMES.get(key, key)\n        response = requests.post(\n            ""http://%s:8060/keyup/%s"" % (self.hostname, roku_keyname),\n            timeout=self.timeout_secs)\n        response.raise_for_status()\n        debug(""Released %s"" % key)\n\n\nclass SamsungTCPControl(RemoteControl):\n    """"""Send a key-press via Samsung remote control protocol.\n\n    See http://sc0ty.pl/2012/02/samsung-tv-network-remote-control-protocol/\n    """"""\n    def __init__(self, sock):\n        self.socket = sock\n        self._hello()\n\n    @staticmethod\n    def _encode_string(string):\n        r""""""\n        >>> SamsungTCPControl._encode_string(\'192.168.0.10\')\n        \'\\x10\\x00MTkyLjE2OC4wLjEw\'\n        """"""\n        from base64 import b64encode\n        b64 = b64encode(to_bytes(string))\n        return struct.pack(\'<H\', len(b64)) + b64\n\n    def _send_payload(self, payload):\n        sender = b""iphone.iapp.samsung""\n        packet_start = struct.pack(\'<BH\', 0, len(sender)) + sender\n        self.socket.send(packet_start +\n                         struct.pack(\'<H\', len(payload)) +\n                         payload)\n\n    def _hello(self):\n        payload = bytearray([0x64, 0x00])\n        payload += self._encode_string(self.socket.getsockname()[0])\n        payload += self._encode_string(""my_id"")\n        payload += self._encode_string(""stb-tester"")\n        self._send_payload(payload)\n        reply = self.socket.recv(4096)\n        debug(""SamsungTCPControl reply: %s\\n"" % reply)\n\n    def press(self, key):\n        payload_start = bytearray([0x00, 0x00, 0x00])\n        key_enc = self._encode_string(key)\n        self._send_payload(payload_start + key_enc)\n        debug(""Pressed %s"" % key)\n        reply = self.socket.recv(4096)\n        debug(""SamsungTCPControl reply: %s\\n"" % reply)\n\n\ndef _new_samsung_tcp_control(hostname, port):\n    return SamsungTCPControl(_connect_tcp_socket(hostname, int(port or 55000)))\n\n\ndef _load_key_mapping(filename):\n    out = {}\n    with open(filename, \'r\') as mapfile:\n        for line in mapfile:\n            s = line.strip().split()\n            if len(s) == 2 and not s[0].startswith(\'#\'):\n                out[s[0]] = s[1]\n    return out\n\n\nclass X11Control(RemoteControl):\n    """"""Simulate key presses using xdotool.\n    """"""\n    def __init__(self, display=None, mapping=None):\n        self.display = display\n        if find_executable(\'xdotool\') is None:\n            raise Exception(""x11 control: xdotool not installed"")\n        self.mapping = _load_key_mapping(_find_file(""x-key-mapping.conf""))\n        if mapping is not None:\n            self.mapping.update(_load_key_mapping(mapping))\n\n    def press(self, key):\n        e = os.environ.copy()\n        if self.display is not None:\n            e[\'DISPLAY\'] = self.display\n        subprocess.check_call(\n            [\'xdotool\', \'key\', self.mapping.get(key, key)], env=e)\n        debug(""Pressed %s"" % key)\n\n\ndef file_control_recorder(filename):\n    """""" A generator that returns lines from the file given by filename.\n\n    Unfortunately treating a file as a iterator doesn\'t work in the case of\n    interactive input, even when we provide bufsize=1 (line buffered) to the\n    call to open() so we have to have this function to work around it. """"""\n    f = open(filename, \'r\')\n    if filename == \'/dev/stdin\':\n        sys.stderr.write(\'Waiting for keypresses from standard input...\\n\')\n    while True:\n        line = f.readline()\n        if line == \'\':\n            f.close()\n            return\n        yield line.rstrip()\n\n\ndef read_records(stream, sep):\n    r""""""Generator that splits stream into records given a separator\n\n    >>> import io\n    >>> s = io.BytesIO(b\'hello\\n\\0This\\n\\0is\\n\\0a\\n\\0test\\n\\0\')\n    >>> list(read_records(FileToSocket(s), b\'\\n\\0\'))\n    [\'hello\', \'This\', \'is\', \'a\', \'test\']\n    """"""\n    buf = b""""\n    while True:\n        s = stream.recv(4096)\n        if len(s) == 0:\n            break\n        buf += s\n        cmds = buf.split(sep)\n        buf = cmds[-1]\n        for i in cmds[:-1]:\n            yield i\n\n\ndef lirc_control_listen(lircd_socket, control_name):\n    """"""Returns an iterator yielding keypresses received from a lircd file\n    socket -- that is, the keypresses that lircd received from a hardware\n    infrared receiver and is now sending on to us.\n\n    See http://www.lirc.org/html/technical.html#applications\n    """"""\n    if lircd_socket is None:\n        lircd_socket = DEFAULT_LIRCD_SOCKET\n    lircd = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n    debug(""control-recorder connecting to lirc file socket \'%s\'..."" %\n          lircd_socket)\n    lircd.connect(lircd_socket)\n    debug(""control-recorder connected to lirc file socket"")\n    return lirc_key_reader(lircd.makefile(""rb""), control_name)\n\n\ndef lirc_control_listen_tcp(address, port, control_name):\n    """"""Returns an iterator yielding keypresses received from a lircd TCP\n    socket.""""""\n    address = address or \'localhost\'\n    port = int(port)\n    debug(""control-recorder connecting to lirc TCP socket %s:%s..."" %\n          (address, port))\n    lircd = _connect_tcp_socket(address, port, timeout=None)\n    debug(""control-recorder connected to lirc TCP socket"")\n    return lirc_key_reader(lircd.makefile(""rb""), control_name)\n\n\ndef stbt_control_listen(keymap_file):\n    """"""Returns an iterator yielding keypresses received from `stbt control`.\n    """"""\n    import imp\n    try:\n        from .vars import libexecdir\n        sc = ""%s/stbt/stbt_control.py"" % libexecdir\n    except ImportError:\n        sc = _find_file(\'../stbt_control.py\')\n    stbt_control = imp.load_source(\'stbt_control\', sc)\n\n    with scoped_debug_level(0):\n        # Don\'t mess up printed keymap with debug messages\n        return stbt_control.main_loop(\n            \'stbt record\', keymap_file or stbt_control.default_keymap_file())\n\n\ndef lirc_key_reader(cmd_iter, control_name):\n    r""""""Convert lircd messages into list of keypresses\n\n    >>> list(lirc_key_reader([b\'0000dead 00 MENU My-IR-remote\',\n    ...                       b\'0000beef 00 OK My-IR-remote\',\n    ...                       b\'0000f00b 01 OK My-IR-remote\',\n    ...                       b\'BEGIN\', b\'SIGHUP\', b\'END\'],\n    ...                      \'My-IR-remote\'))\n    [\'MENU\', \'OK\']\n    """"""\n    for s in cmd_iter:\n        debug(""lirc_key_reader received: %s"" % s.rstrip())\n        m = re.match(\n            br""\\w+ (?P<repeat_count>\\d+) (?P<key>\\w+) %s"" % (\n                to_bytes(control_name)),\n            s)\n        if m and int(m.group(\'repeat_count\')) == 0:\n            yield m.group(\'key\')\n\n\ndef _connect_tcp_socket(address, port, timeout=3):\n    """"""Connects to a TCP listener on \'address\':\'port\'.""""""\n    try:\n        s = socket.socket()\n        if timeout:\n            s.settimeout(timeout)\n        s.connect((address, port))\n        return s\n    except socket.error as e:\n        e.args = ((""Failed to connect to remote control at %s:%d: %s"" % (\n            address, port, e)),)\n        e.strerror = e.args[0]\n        raise\n\n\nclass FileToSocket(object):\n    """"""Makes something File-like behave like a Socket for testing purposes\n\n    >>> import io\n    >>> s = FileToSocket(io.BytesIO(b""Hello""))\n    >>> s.recv(3)\n    \'Hel\'\n    >>> s.recv(3)\n    \'lo\'\n    """"""\n    def __init__(self, f):\n        self.file = f\n\n    def recv(self, bufsize, flags=0):  # pylint:disable=unused-argument\n        return self.file.read(bufsize)\n\n\n@contextmanager\ndef _fake_lircd():\n    import multiprocessing\n    # This needs to accept 2 connections (from LircControl and\n    # lirc_control_listen) and, on receiving input from the LircControl\n    # connection, write to the lirc_control_listen connection.\n    with named_temporary_directory(prefix=""stbt-fake-lircd-"") as tmp:\n        address = tmp + \'/lircd\'\n        s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        s.bind(address)\n        s.listen(6)\n\n        def listen():\n            import signal\n            signal.signal(signal.SIGTERM, lambda _, __: sys.exit(0))\n\n            listener, _ = s.accept()\n            while True:\n                control, _ = s.accept()\n                for cmd in control.makefile(""rb""):\n                    m = re.match(br\'SEND_ONCE (?P<ctrl>\\S+) (?P<key>\\S+)\', cmd)\n                    if m:\n                        listener.sendall(\n                            b\'00000000 0 %(key)s %(ctrl)s\\n\' %\n                            {b""key"": m.group(""key""),\n                             b""ctrl"": m.group(""ctrl"")})\n                    control.sendall(b\'BEGIN\\n%sSUCCESS\\nEND\\n\' % cmd)\n                control.close()\n\n        t = multiprocessing.Process(target=listen)\n        t.daemon = True\n        t.start()\n        try:\n            yield address\n        finally:\n            t.terminate()\n\n\ndef test_that_lirc_control_is_symmetric_with_lirc_control_listen():\n    with _fake_lircd() as lircd_socket:\n        listener = uri_to_control_recorder(\'lirc:%s:test\' % lircd_socket)\n        control = uri_to_control(\'lirc:%s:test\' % (lircd_socket))\n        for key in [\'DOWN\', \'DOWN\', \'UP\', \'GOODBYE\']:\n            control.press(key)\n            assert next(listener) == to_bytes(key)\n\n\ndef test_that_local_lirc_socket_is_correctly_defaulted():\n    global DEFAULT_LIRCD_SOCKET\n    old_default = DEFAULT_LIRCD_SOCKET\n    try:\n        with _fake_lircd() as lircd_socket:\n            DEFAULT_LIRCD_SOCKET = lircd_socket\n            listener = uri_to_control_recorder(\'lirc:%s:test\' % lircd_socket)\n            uri_to_control(\'lirc::test\').press(\'KEY\')\n            assert next(listener) == b\'KEY\'\n    finally:\n        DEFAULT_LIRCD_SOCKET = old_default\n\n\ndef test_roku_http_control():\n    import pytest\n    import responses\n    from requests.exceptions import HTTPError\n\n    control = uri_to_control(\'roku:192.168.1.3\')\n    with responses.RequestsMock() as mock:\n        # This raises if the URL was not accessed.\n        mock.add(mock.POST, \'http://192.168.1.3:8060/keypress/Home\')\n        control.press(""KEY_HOME"")\n    with responses.RequestsMock() as mock:\n        mock.add(mock.POST, \'http://192.168.1.3:8060/keypress/Home\')\n        control.press(""Home"")\n    with pytest.raises(HTTPError):\n        with responses.RequestsMock() as mock:\n            mock.add(mock.POST, \'http://192.168.1.3:8060/keypress/Homeopathy\',\n                     status=400)\n            control.press(""Homeopathy"")\n\n\ndef test_samsung_tcp_control():\n    # This is more of a regression test than anything.\n    sent_data = []\n\n    class TestSocket(object):\n        def send(self, data):\n            sent_data.append(data)\n\n        def recv(self, _):\n            return """"\n\n        def getsockname(self):\n            return [\'192.168.0.8\', 12345]\n\n    r = SamsungTCPControl(TestSocket())\n    assert len(sent_data) == 1\n    assert sent_data[0] == (\n        b\'\\x00\\x13\\x00iphone.iapp.samsung0\\x00d\\x00\\x10\\x00MTkyLjE2OC4wLjg=\' +\n        b\'\\x08\\x00bXlfaWQ=\\x10\\x00c3RiLXRlc3Rlcg==\')\n    r.press(\'KEY_0\')\n    assert len(sent_data) == 2\n    assert sent_data[1] == (\n        b\'\\x00\\x13\\x00iphone.iapp.samsung\\r\\x00\\x00\\x00\\x00\\x08\\x00S0VZXzA=\')\n\n\ndef test_x11_control():\n    from unittest import SkipTest\n    if os.environ.get(\'enable_virtual_stb\') != \'yes\':\n        raise SkipTest(\'Set $enable_virtual_stb=yes to run this test\')\n    if not find_executable(\'Xorg\') or not find_executable(\'xterm\'):\n        raise SkipTest(""Testing X11Control requires X11 and xterm"")\n\n    from .x11 import x_server\n\n    with named_temporary_directory() as tmp, x_server(320, 240) as display:\n        r = uri_to_control(\'x11:%s\' % display)\n\n        subprocess.Popen(\n            [\'xterm\', \'-l\', \'-lf\', \'xterm.log\'],\n            env={\'DISPLAY\': display, \'PATH\': os.environ[\'PATH\']},\n            cwd=tmp, stderr=open(\'/dev/null\', \'w\'))\n\n        # Can\'t be sure how long xterm will take to get ready:\n        for _ in range(0, 20):\n            for keysym in [\'KEY_T\', \'KEY_O\', \'KEY_U\', \'KEY_C\', \'KEY_H\',\n                           \'KEY_SPACE\',\n                           \'g\', \'o\', \'o\', \'d\',\n                           \'KEY_OK\']:\n                r.press(keysym)\n            if os.path.exists(tmp + \'/good\'):\n                break\n            time.sleep(0.5)\n        with open(tmp + \'/xterm.log\', \'r\') as log:\n            for line in log:\n                print(""xterm.log: "" + line, end=\' \')\n        assert os.path.exists(tmp + \'/good\')\n\n\ndef test_uri_to_control():\n    global IRNetBoxControl  # pylint:disable=global-variable-undefined\n    orig_IRNetBoxControl = IRNetBoxControl\n    try:\n        # pylint:disable=redefined-outer-name\n        def IRNetBoxControl(hostname, port, output, config):\n            return "":"".join([hostname, str(port or \'10001\'), output, config])\n        out = uri_to_control(""irnetbox:localhost:1234:1:conf"")\n        assert out == ""localhost:1234:1:conf"", (\n            ""Failed to parse uri with irnetbox port. Output was \'%s\'"" % out)\n        out = uri_to_control(""irnetbox:localhost:1:conf"")\n        assert out == ""localhost:10001:1:conf"", (\n            ""Failed to parse uri without irnetbox port. Output was \'%s\'"" % out)\n        try:\n            uri_to_control(""irnetbox:localhost::1:conf"")\n            assert False, ""Uri with empty field should have raised""\n        except ConfigurationError:\n            pass\n    finally:\n        IRNetBoxControl = orig_IRNetBoxControl\n'"
_stbt/control_gpl.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom future.utils import string_types\nimport re\nimport sys\nimport threading\nimport time\nfrom contextlib import contextmanager\nfrom textwrap import dedent\n\nfrom .logging import debug\nfrom .utils import to_bytes\n\n\nclass HdmiCecError(Exception):\n    pass\n\n\nclass HdmiCecControl(object):\n    # Map our recommended keynames (from linux input-event-codes.h) to the\n    # equivalent CEC commands.\n    # The mapping between CEC commands and code can be found at\n    # http://www.cec-o-matic.com or in HDMI-CEC specification 1.3a\n    _KEYNAMES = {\n        ""KEY_OK"": 0,\n        ""KEY_UP"": 1,\n        ""KEY_DOWN"": 2,\n        ""KEY_LEFT"": 3,\n        ""KEY_RIGHT"": 4,\n        ""KEY_RIGHT_UP"": 5,\n        ""KEY_RIGHT_DOWN"": 6,\n        ""KEY_LEFT_UP"": 7,\n        ""KEY_LEFT_DOWN"": 8,\n        ""KEY_ROOT_MENU"": 9,\n        ""KEY_MENU"": 9,\n        ""KEY_SETUP"": 10,\n        ""KEY_CONTENTS_MENU"": 11,  # <- not in input-event-codes.h\n        ""KEY_FAVORITE_MENU"": 12,  # <- not in input-event-codes.h\n        ""KEY_BACK"": 13,\n\n        # 0x0E - 0x1F Reserved\n        ""KEY_TV"": 16,  # Apple TV\n\n        # Back to official CEC names\n        ""KEY_0"": 32,\n        ""KEY_1"": 33,\n        ""KEY_2"": 34,\n        ""KEY_3"": 35,\n        ""KEY_4"": 36,\n        ""KEY_5"": 37,\n        ""KEY_6"": 38,\n        ""KEY_7"": 39,\n        ""KEY_8"": 40,\n        ""KEY_9"": 41,\n        ""KEY_DOT"": 42,\n        ""KEY_ENTER"": 43,\n        ""KEY_CLEAR"": 44,\n        ""KEY_NEXT_FAVORITE"": 47,  # <- not in input-event-codes.h\n        ""KEY_CHANNELUP"": 48,\n        ""KEY_CHANNELDOWN"": 49,\n        ""KEY_PREVIOUS"": 50,\n        ""KEY_SOUND_SELECT"": 51,  # <- not in input-event-codes.h\n        ""KEY_INPUT_SELECT"": 52,  # <- not in input-event-codes.h\n        ""KEY_INFO"": 53,\n        ""KEY_HELP"": 54,\n        ""KEY_PAGEUP"": 55,\n        ""KEY_PAGEDOWN"": 56,\n        # 0x39 - 0x3F Reserved\n        ""KEY_POWER"": 64,\n        ""KEY_VOLUMEUP"": 65,\n        ""KEY_VOLUMEDOWN"": 66,\n        ""KEY_MUTE"": 67,\n        ""KEY_PLAY"": 68,\n        ""KEY_STOP"": 69,\n        ""KEY_PAUSE"": 70,\n        ""KEY_RECORD"": 71,\n        ""KEY_REWIND"": 72,\n        ""KEY_FASTFORWARD"": 73,\n        ""KEY_EJECT"": 74,\n        ""KEY_FORWARD"": 75,\n        ""KEY_BACKWARD"": 76,\n        ""KEY_STOP_RECORD"": 77,\n        ""KEY_PAUSE_RECORD"": 78,\n        # 0x4F Reserved\n        ""KEY_ANGLE"": 80,\n        ""KEY_SUB_PICTURE"": 81,  # <- not in input-event-codes.h\n        ""KEY_VOD"": 82,\n        ""KEY_EPG"": 83,\n        ""KEY_TIMER_PROGRAMMING"": 84,  # <- not in input-event-codes.h\n        ""KEY_CONFIG"": 85,  # Initial Configuration\n        # 0x56 - 0x5F Reserved\n\n        # Deterministic UI Functions; unlike some normal keys these never act\n        # as toggles. Some of these take additional operands but we don\'t\n        # support that (the additional operands are always optional according\n        # to the CEC spec).\n        # None of these _FUNCTION names are in linux-event-codes.h.\n        ""KEY_PLAY_FUNCTION"": 96,\n        ""KEY_PAUSE_PLAY_FUNCTION"": 97,\n        ""KEY_RECORD_FUNCTION"": 98,\n        ""KEY_PAUSE_RECORD_FUNCTION"": 99,\n        ""KEY_STOP_FUNCTION"": 100,\n        ""KEY_MUTE_FUNCTION"": 101,\n        ""KEY_RESTORE_VOLUME_FUNCTION"": 102,\n        ""KEY_TUNE_FUNCTION"": 103,\n        ""KEY_SELECT_MEDIA_FUNCTION"": 104,\n        ""KEY_SELECT_AV_INPUT_FUNCTION"": 105,\n        ""KEY_SELECT_AUDIO_INPUT_FUNCTION"": 106,\n        ""KEY_POWER_TOGGLE_FUNCTION"": 107,\n        ""KEY_POWER_OFF_FUNCTION"": 108,\n        ""KEY_POWER_ON_FUNCTION"": 109,\n        # Back to normal keys.\n\n        # 0x6E - 0x70 Reserved\n\n        # These have 2 names:\n        ""KEY_F1"": 113,\n        ""KEY_BLUE"": 113,\n        ""KEY_F2"": 114,\n        ""KEY_RED"": 114,\n        ""KEY_F3"": 115,\n        ""KEY_GREEN"": 115,\n        ""KEY_F4"": 116,\n        ""KEY_YELLOW"": 116,\n\n        # And back to normal keys:\n        ""KEY_F5"": 117,\n        ""KEY_DATA"": 118,\n        # 0x77 - 0xFF Reserved\n    }\n\n    def __init__(self, device, source, destination):\n        # On Ubuntu 18.04 `cec/__init__.py` tries to import `_cec` but can\'t\n        # find it.\n        # https://bugs.launchpad.net/ubuntu/+source/libcec/+bug/1805620\n        sys.path.insert(0, ""/usr/lib/python2.7/dist-packages/cec"")\n        try:\n            import cec  # pylint:disable=import-error\n        finally:\n            sys.path.pop(0)\n\n        if source is None:\n            source = 1\n        if isinstance(source, string_types):\n            source = int(source, 16)\n        if isinstance(destination, string_types):\n            destination = int(destination, 16)\n\n        self.cecconfig = cec.libcec_configuration()\n        self.cecconfig.strDeviceName = b""stb-tester""\n        self.cecconfig.bActivateSource = 0\n        self.cecconfig.deviceTypes.Add(cec.CEC_DEVICE_TYPE_RECORDING_DEVICE)\n        self.cecconfig.clientVersion = cec.LIBCEC_VERSION_CURRENT\n        self.lib = cec.ICECAdapter.Create(self.cecconfig)\n        debug(""libCEC version %s loaded: %s"" % (\n            self.lib.VersionToString(self.cecconfig.serverVersion),\n            self.lib.GetLibInfo()))\n\n        if device is None:\n            device = self.detect_adapter()\n            if device is None:\n                raise HdmiCecError(""No adapter found"")\n        device = to_bytes(device)\n        if not self.lib.Open(device):\n            raise HdmiCecError(""Failed to open a connection to the CEC adapter"")\n        debug(""Connection to CEC adapter opened"")\n\n        if destination is None:\n            ds = list(self._list_active_devices())\n            debug(""HDMI-CEC scan complete.  Found %r"" % ds)\n            if len(ds) == 0:\n                raise HdmiCecError(\n                    ""Failed to find a device on the CEC bus to talk to."")\n            # Choose the last one, the first one is likely to be a TV if there\'s\n            # one plugged in\n            destination = ds[-1]\n            debug(""HDMI-CEC: Chose to talk to device %i %r"" % (\n                destination, self.lib.GetDeviceOSDName(destination)))\n\n        self.source = source\n        self.destination = destination\n\n        self.press_and_hold_thread = None\n        self.press_and_holding = False\n        self.lock = threading.Condition()\n\n    def press(self, key):\n        with self.lock:\n            if self.press_and_holding:\n                raise HdmiCecError(\n                    ""Can\'t call \'press\' while holding another key"")\n\n            if not self.lib.Transmit(self.keydown_command(key)):\n                raise HdmiCecError(""Failed to send keydown for %s"" % key)\n            if not self.lib.Transmit(self.keyup_command()):\n                raise HdmiCecError(""Failed to send keyup for %s"" % key)\n\n        debug(""Pressed %s"" % key)\n\n    def keydown(self, key):\n        # CEC spec section 13.13.3 says that the receiver should assume a\n        # keyup if it hasn\'t seen one within a receiver-determined timeframe\n        # which can\'t be less than 550ms. For press-and-hold the initiator\n        # should send repeated keydown commands (200 to 450ms apart) followed\n        # by the final keyup.\n\n        with self.lock:\n            if self.press_and_holding:\n                raise HdmiCecError(\n                    ""Can\'t call \'keydown\' while holding another key"")\n            self.press_and_holding = True\n\n            if not self.lib.Transmit(self.keydown_command(key)):\n                raise HdmiCecError(""Failed to send keydown for %s"" % key)\n\n            self.press_and_hold_thread = threading.Thread(\n                target=self.send_keydowns, args=(key,))\n            self.press_and_hold_thread.daemon = True\n            self.press_and_hold_thread.start()\n        debug(""Holding %s"" % key)\n\n    def keyup(self, key):\n        with self.lock:\n            if not self.press_and_holding:\n                raise HdmiCecError(""Called \'keyup\' when not holding a key down"")\n            self.press_and_holding = False\n            thread = self.press_and_hold_thread\n            self.press_and_hold_thread = None\n            self.lock.notify_all()\n\n        thread.join()\n\n        with self.lock:\n            if not self.lib.Transmit(self.keyup_command()):\n                raise HdmiCecError(""Failed to send keyup for %s"" % key)\n        debug(""Released %s"" % key)\n\n    def send_keydowns(self, key):\n        # CEC spec section 13.13.3 says that the receiver should assume a keyup\n        # if it hasn\'t seen one within a receiver-determined timeframe which\n        # can\'t be less than 550ms. For press-and-hold the initiator should\n        # send repeated keydown commands (200 to 450ms apart) followed by the\n        # final keyup.\n        end_time = time.time() + 60\n        next_press_deadline = time.time() + 0.3\n        with self.lock:\n            while True:\n                self.lock.wait(max(0, next_press_deadline - time.time()))\n                if not self.press_and_holding:\n                    return\n                if time.time() > end_time:\n                    debug(""cec: Warning: Releasing %s as I\'ve been holding it ""\n                          ""longer than 60 seconds"" % key)\n                    return\n                next_press_deadline = time.time() + 0.3\n                if not self.lib.Transmit(self.keydown_command(key)):\n                    debug(""cec: Warning: Failed to send repeated keydown for %s""\n                          % key)\n\n    def keydown_command(self, key):\n        keycode = self.get_keycode(key)\n        keydown_str = b""%X%X:44:%02X"" % (self.source, self.destination, keycode)\n        return self.lib.CommandFromString(keydown_str)\n\n    def keyup_command(self):\n        keyup_str = b""%X%X:45"" % (self.source, self.destination)\n        return self.lib.CommandFromString(keyup_str)\n\n    def get_keycode(self, key):\n        from .control import UnknownKeyError\n\n        keycode = self._KEYNAMES.get(key)\n        if keycode is None:\n            if isinstance(key, int):\n                keycode = key\n            elif re.match(r""^[0-9]+$"", key):\n                keycode = int(key, base=10)\n            elif re.match(r""^0[xX][0-9a-fA-F]+$"", key):\n                keycode = int(key, base=16)\n        if keycode is None or (isinstance(keycode, int) and\n                               not 0 <= keycode <= 255):\n            raise UnknownKeyError(""HdmiCecControl: Unknown key %r"" % key)\n        return keycode\n\n    # detect an adapter and return the com port path\n    def detect_adapter(self):\n        retval = None\n        adapters = self.lib.DetectAdapters()\n        for adapter in adapters:\n            debug(\n                dedent(""""""\\\n                    Found a CEC adapter:""\n                    Port:     %s\n                    Vendor:   %x\n                    Product:  %x"""""") %\n                (adapter.strComName, adapter.iVendorId, adapter.iProductId))\n            retval = adapter.strComName\n        return retval\n\n    def _list_active_devices(self):\n        self.lib.RescanActiveDevices()\n        active = self.lib.GetActiveDevices()\n\n        # We get a fixed size array back.  libcec-python doesn\'t implement\n        # iteration or bounds checking:\n        for n in range(16):\n            # active.primary is us\n            if n != active.primary and active[n]:\n                yield n\n\n\ndef test_hdmi_cec_control():\n    from .control import uri_to_control\n    with _fake_cec() as io:\n        r = uri_to_control(\'hdmi-cec:test-device:7:a\')\n        r.press(""KEY_UP"")\n        r.press(""KEY_UP"")\n        r.press(""KEY_POWER"")\n        r.press(74)\n        r.press(""74"")\n        r.press(""0x4A"")\n        r.press(""0x4a"")\n        r.keydown(""KEY_ROOT_MENU"")\n        time.sleep(0.7)\n        r.keyup(""KEY_ROOT_MENU"")\n\n    expected = dedent(""""""\\\n        Open(\'test-device\')\n        Transmit(dest: 0xa, src: 0x7, op: 0x44, data: <01>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x45, data: <>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x44, data: <01>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x45, data: <>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x44, data: <40>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x45, data: <>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x44, data: <4a>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x45, data: <>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x44, data: <4a>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x45, data: <>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x44, data: <4a>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x45, data: <>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x44, data: <4a>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x45, data: <>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x44, data: <09>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x44, data: <09>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x44, data: <09>)\n        Transmit(dest: 0xa, src: 0x7, op: 0x45, data: <>)\n        """""")\n    assert expected == io.getvalue()\n\n\ndef test_hdmi_cec_control_defaults():\n    from .control import uri_to_control\n    with _fake_cec() as io:\n        r = uri_to_control(\'hdmi-cec:test-device\')\n        r.press(""KEY_OK"")\n\n    assert io.getvalue() == dedent(""""""\\\n        Open(\'test-device\')\n        RescanActiveDevices()\n        GetActiveDevices()\n        GetDeviceOSDName(4)\n        Transmit(dest: 0x4, src: 0x1, op: 0x44, data: <00>)\n        Transmit(dest: 0x4, src: 0x1, op: 0x45, data: <>)\n        """""")\n\n\n@contextmanager\ndef _fake_cec():\n    import io\n    import pytest\n    try:\n        from unittest.mock import patch\n    except ImportError:\n        from mock import patch  # Python 2 backport\n\n    pytest.importorskip(""cec"")\n\n    io = io.BytesIO()\n\n    def Open(_, device):\n        io.write(b\'Open(%r)\\n\' % device)\n        return True\n\n    def cec_cmd_get_data(cmd):\n        # Ugly, but can\'t find another way to do it\n        import ctypes\n        return str(buffer(ctypes.cast(  # pylint:disable=undefined-variable\n            int(cmd.parameters.data), ctypes.POINTER(ctypes.c_uint8)).contents,\n            0, cmd.parameters.size))\n\n    def Transmit(_, cmd):\n        io.write(b""Transmit(dest: 0x%x, src: 0x%x, op: 0x%x, data: <%s>)\\n"" % (\n            cmd.destination, cmd.initiator, cmd.opcode,\n            cec_cmd_get_data(cmd).encode(\'hex\')))\n        return True\n\n    def RescanActiveDevices(_):\n        io.write(b""RescanActiveDevices()\\n"")\n\n    def GetActiveDevices(_):\n        io.write(b""GetActiveDevices()\\n"")\n\n        class _L(list):\n            @property\n            def primary(self):\n                return 1\n\n        return _L([False, True, False, False, True] + [False] * 11)\n\n    def GetDeviceOSDName(_, destination):\n        io.write(b""GetDeviceOSDName(%r)\\n"" % destination)\n        return ""Test""\n\n    with patch(\'cec.ICECAdapter.Open\', Open), \\\n            patch(\'cec.ICECAdapter.Transmit\', Transmit), \\\n            patch(\'cec.ICECAdapter.RescanActiveDevices\', RescanActiveDevices), \\\n            patch(\'cec.ICECAdapter.GetActiveDevices\', GetActiveDevices), \\\n            patch(\'cec.ICECAdapter.GetDeviceOSDName\', GetDeviceOSDName):\n        yield io\n\ncontrols = [\n    # pylint: disable=line-too-long\n    (r\'hdmi-cec(:(?P<device>[^:]+)(:(?P<source>[^:]+)(:(?P<destination>[^:]+))?)?)?\',\n     HdmiCecControl),\n]\n'"
_stbt/core.py,0,"b'# coding: utf-8\n""""""Main stb-tester python module. Intended to be used with `stbt run`.\n\nSee `man stbt` and http://stb-tester.com for documentation.\n\nCopyright 2012-2013 YouView TV Ltd and contributors.\nLicense: LGPL v2.1 or (at your option) any later version (see\nhttps://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nfrom future.utils import native, raise_, string_types\n\nimport argparse\nimport datetime\nimport sys\nimport threading\nimport traceback\nimport warnings\nimport weakref\nfrom collections import deque, namedtuple\nfrom contextlib import contextmanager\n\nimport cv2\nimport gi\n\nimport _stbt.cv2_compat as cv2_compat\nfrom _stbt import logging\nfrom _stbt.config import get_config\nfrom _stbt.gst_utils import array_from_sample, gst_sample_make_writable\nfrom _stbt.imgutils import _frame_repr, Frame\nfrom _stbt.logging import _Annotation, ddebug, debug, warn\nfrom _stbt.types import NoVideo, Region\nfrom _stbt.utils import text_type, to_native_str, to_unicode\n\ngi.require_version(""Gst"", ""1.0"")\nfrom gi.repository import GLib, GObject, Gst  # pylint:disable=wrong-import-order\n\nGst.init(None)\n\nwarnings.filterwarnings(\n    action=""always"", category=DeprecationWarning, message=\'.*stb-tester\')\n\n\n# Functions available to stbt scripts\n# ===========================================================================\n\n\ndef new_device_under_test_from_config(parsed_args=None):\n    """"""\n    `parsed_args` if present should come from calling argparser().parse_args().\n    """"""\n    from _stbt.control import uri_to_control\n\n    if parsed_args is None:\n        args = argparser().parse_args([])\n    else:\n        args = parsed_args\n\n    if args.source_pipeline is None:\n        args.source_pipeline = get_config(\'global\', \'source_pipeline\')\n    if args.sink_pipeline is None:\n        args.sink_pipeline = get_config(\'global\', \'sink_pipeline\')\n    if args.control is None:\n        args.control = get_config(\'global\', \'control\')\n    if args.save_video is None:\n        args.save_video = False\n\n    display = [None]\n\n    def raise_in_user_thread(exception):\n        display[0].tell_user_thread(exception)\n    mainloop = _mainloop()\n\n    if not args.sink_pipeline and not args.save_video:\n        sink_pipeline = NoSinkPipeline()\n    else:\n        sink_pipeline = SinkPipeline(  # pylint: disable=redefined-variable-type\n            args.sink_pipeline, raise_in_user_thread, args.save_video)\n\n    display[0] = Display(args.source_pipeline, sink_pipeline)\n    return DeviceUnderTest(\n        display=display[0], control=uri_to_control(args.control, display[0]),\n        sink_pipeline=sink_pipeline, mainloop=mainloop)\n\n\nclass DeviceUnderTest(object):\n    def __init__(self, display=None, control=None, sink_pipeline=None,\n                 mainloop=None, _time=None):\n        if _time is None:\n            import time as _time\n        self._time_of_last_press = None\n        self._display = display\n        self._control = control\n        self._sink_pipeline = sink_pipeline\n        self._mainloop = mainloop\n        self._time = _time\n        self._last_keypress = None\n\n    def __enter__(self):\n        if self._display:\n            self._mainloop.__enter__()\n            self._sink_pipeline.__enter__()\n            self._display.__enter__()\n        return self\n\n    def __exit__(self, exc_type, exc_value, tb):\n        if self._display:\n            self._sink_pipeline.exit_prep()\n            self._display.__exit__(exc_type, exc_value, tb)\n            self._display = None\n            self._sink_pipeline.__exit__(exc_type, exc_value, tb)\n            self._sink_pipeline = None\n            self._mainloop.__exit__(exc_type, exc_value, tb)\n        self._control = None\n\n    def last_keypress(self):\n        return self._last_keypress\n\n    def press(self, key, interpress_delay_secs=None, hold_secs=None):\n        if hold_secs is not None and hold_secs > 60:\n            # You must ensure that lircd\'s --repeat-max is set high enough.\n            raise ValueError(""press: hold_secs must be less than 60 seconds"")\n\n        if hold_secs is None:\n            with self._interpress_delay(interpress_delay_secs):\n                if self._display is None:\n                    frame_before = None\n                else:\n                    frame_before = self.get_frame()\n                out = _Keypress(key, self._time.time(), None, frame_before)\n                self._control.press(key)\n                out.end_time = self._time.time()\n            self.draw_text(key, duration_secs=3)\n            self._last_keypress = out\n            return out\n        else:\n            with self.pressing(key, interpress_delay_secs) as out:\n                self._time.sleep(hold_secs)\n            return out\n\n    @contextmanager\n    def pressing(self, key, interpress_delay_secs=None):\n        with self._interpress_delay(interpress_delay_secs):\n            out = _Keypress(key, self._time.time(), None, self.get_frame())\n            try:\n                self._control.keydown(key)\n                self.draw_text(""Holding %s"" % key, duration_secs=3)\n                self._last_keypress = out\n                yield out\n            except:  # pylint:disable=bare-except\n                exc_info = sys.exc_info()\n                try:\n                    self._control.keyup(key)\n                    self.draw_text(""Released %s"" % key, duration_secs=3)\n                except Exception:  # pylint:disable=broad-except\n                    # Don\'t mask original exception from the test script.\n                    pass\n                raise_(exc_info[0], exc_info[1], exc_info[2])\n            else:\n                self._control.keyup(key)\n                out.end_time = self._time.time()\n                self.draw_text(""Released %s"" % key, duration_secs=3)\n\n    @contextmanager\n    def _interpress_delay(self, interpress_delay_secs):\n        if interpress_delay_secs is None:\n            interpress_delay_secs = get_config(\n                ""press"", ""interpress_delay_secs"", type_=float)\n        if self._time_of_last_press is not None:\n            # `sleep` is inside a `while` loop because the actual suspension\n            # time of `sleep` may be less than that requested.\n            while True:\n                seconds_to_wait = (\n                    self._time_of_last_press - datetime.datetime.now() +\n                    datetime.timedelta(seconds=interpress_delay_secs)\n                ).total_seconds()\n                if seconds_to_wait > 0:\n                    self._time.sleep(seconds_to_wait)\n                else:\n                    break\n\n        try:\n            yield\n        finally:\n            self._time_of_last_press = datetime.datetime.now()\n\n    def draw_text(self, text, duration_secs=3):\n        self._sink_pipeline.draw(text, duration_secs)\n\n    def press_until_match(\n            self,\n            key,\n            image,\n            interval_secs=None,\n            max_presses=None,\n            match_parameters=None,\n            region=Region.ALL):\n        from .match import MatchParameters, MatchTimeout, wait_for_match\n        if interval_secs is None:\n            # Should this be float?\n            interval_secs = get_config(\n                ""press_until_match"", ""interval_secs"", type_=int)\n        if max_presses is None:\n            max_presses = get_config(\n                ""press_until_match"", ""max_presses"", type_=int)\n\n        if match_parameters is None:\n            match_parameters = MatchParameters()\n\n        i = 0\n\n        while True:\n            try:\n                return wait_for_match(image, timeout_secs=interval_secs,\n                                      match_parameters=match_parameters,\n                                      region=region, frames=self.frames())\n            except MatchTimeout:\n                if i < max_presses:\n                    self.press(key)\n                    i += 1\n                else:\n                    raise\n\n    def frames(self, timeout_secs=None):\n        if timeout_secs is not None:\n            end_time = self._time.time() + timeout_secs\n        timestamp = None\n        first = True\n\n        while True:\n            ddebug(""user thread: Getting sample at %s"" % self._time.time())\n            frame = self._display.get_frame(\n                max(10, timeout_secs or 0), since=timestamp)\n            ddebug(""user thread: Got sample at %s"" % self._time.time())\n            timestamp = frame.time\n\n            if not first and timeout_secs is not None and timestamp > end_time:\n                debug(""timed out: %.3f > %.3f"" % (timestamp, end_time))\n                return\n\n            yield frame\n            first = False\n\n    def get_frame(self):\n        if self._display is None:\n            raise RuntimeError(\n                ""stbt.get_frame(): Video capture has not been initialised"")\n        return self._display.get_frame()\n\n\nclass _Keypress(object):\n    def __init__(self, key, start_time, end_time, frame_before):\n        self.key = key\n        self.start_time = start_time\n        self.end_time = end_time\n        self.frame_before = frame_before\n\n    def __repr__(self):\n        return (\n            ""_Keypress(key=%r, start_time=%r, end_time=%r, frame_before=%s)"" % (\n                self.key, self.start_time, self.end_time,\n                _frame_repr(self.frame_before)))\n\n\n# stbt-run initialisation and convenience functions\n# (you will need these if writing your own version of stbt-run)\n# ===========================================================================\n\ndef argparser():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \'--control\',\n        default=get_config(\'global\', \'control\'),\n        help=\'The remote control to control the stb (default: %(default)s)\')\n    parser.add_argument(\n        \'--source-pipeline\',\n        default=get_config(\'global\', \'source_pipeline\'),\n        help=\'A gstreamer pipeline to use for A/V input (default: \'\n             \'%(default)s)\')\n    parser.add_argument(\n        \'--sink-pipeline\',\n        default=get_config(\'global\', \'sink_pipeline\'),\n        help=\'A gstreamer pipeline to use for video output \'\n             \'(default: %(default)s)\')\n    parser.add_argument(\n        \'--save-video\', help=\'Record video to the specified file\',\n        metavar=\'FILE\', default=get_config(\'run\', \'save_video\'))\n\n    logging.argparser_add_verbose_argument(parser)\n\n    return parser\n\n\n# Internal\n# ===========================================================================\n\n\n@contextmanager\ndef _mainloop():\n    mainloop = GLib.MainLoop.new(context=None, is_running=False)\n\n    thread = threading.Thread(target=mainloop.run)\n    thread.daemon = True\n    thread.start()\n\n    try:\n        yield\n    finally:\n        mainloop.quit()\n        thread.join(10)\n        debug(""teardown: Exiting (GLib mainloop %s)"" % (\n              ""is still alive!"" if thread.isAlive() else ""ok""))\n\n\ndef _draw_annotation(img, annotation):\n    if not annotation.region:\n        return\n    cv2.rectangle(\n        img, (annotation.region.x, annotation.region.y),\n        (annotation.region.right, annotation.region.bottom), annotation.colour,\n        thickness=3)\n\n    # Slightly above the match annotation\n    label_loc = (annotation.region.x, annotation.region.y - 10)\n    _draw_text(img, annotation.label, label_loc, (255, 255, 255),\n               font_scale=0.5)\n\n\nclass _TextAnnotation(namedtuple(""_TextAnnotation"", ""time text duration"")):\n    @property\n    def end_time(self):\n        return self.time + self.duration\n\n\nclass SinkPipeline(object):\n    def __init__(self, user_sink_pipeline, raise_in_user_thread, save_video=""""):\n        import time as _time\n\n        self.annotations_lock = threading.Lock()\n        self.text_annotations = []\n        self.annotations = []\n        self._raise_in_user_thread = raise_in_user_thread\n        self.received_eos = threading.Event()\n        self._frames = deque(maxlen=35)\n        self._time = _time\n        self._sample_count = 0\n\n        # Just used for logging:\n        self._appsrc_was_full = False\n\n        # The test script can draw on the video, but this happens in a different\n        # thread.  We don\'t know when they\'re finished drawing so we just give\n        # them 0.5s instead.\n        self._sink_latency_secs = 0.5\n\n        sink_pipeline_description = (\n            ""appsrc name=appsrc format=time is-live=true ""\n            ""caps=video/x-raw,format=(string)BGR "")\n\n        if save_video and user_sink_pipeline:\n            sink_pipeline_description += ""! tee name=t ""\n            src = ""t. ! queue leaky=downstream""\n        else:\n            src = ""appsrc.""\n\n        if save_video:\n            if not save_video.endswith("".webm""):\n                save_video += "".webm""\n            debug(""Saving video to \'%s\'"" % save_video)\n            sink_pipeline_description += (\n                ""{src} ! videoconvert ! ""\n                ""vp8enc cpu-used=6 min_quantizer=32 max_quantizer=32 ! ""\n                ""webmmux ! filesink location={save_video} "").format(\n                src=src, save_video=save_video)\n\n        if user_sink_pipeline:\n            sink_pipeline_description += (\n                ""{src} ! videoconvert ! {user_sink_pipeline}"").format(\n                src=src, user_sink_pipeline=user_sink_pipeline)\n\n        self.sink_pipeline = Gst.parse_launch(sink_pipeline_description)\n        sink_bus = self.sink_pipeline.get_bus()\n        sink_bus.connect(""message::error"", self._on_error)\n        sink_bus.connect(""message::warning"", self._on_warning)\n        sink_bus.connect(""message::eos"", self._on_eos_from_sink_pipeline)\n        sink_bus.add_signal_watch()\n        self.appsrc = self.sink_pipeline.get_by_name(""appsrc"")\n\n        debug(""sink pipeline: %s"" % sink_pipeline_description)\n\n    def _on_eos_from_sink_pipeline(self, _bus, _message):\n        debug(""Got EOS from sink pipeline"")\n        self.received_eos.set()\n\n    def _on_warning(self, _bus, message):\n        assert message.type == Gst.MessageType.WARNING\n        Gst.debug_bin_to_dot_file_with_ts(\n            self.sink_pipeline, Gst.DebugGraphDetails.ALL, ""WARNING"")\n        err, dbg = message.parse_warning()\n        warn(""%s: %s\\n%s\\n"" % (err, err.message, dbg))\n\n    def _on_error(self, _bus, message):\n        assert message.type == Gst.MessageType.ERROR\n        if self.sink_pipeline is not None:\n            Gst.debug_bin_to_dot_file_with_ts(\n                self.sink_pipeline, Gst.DebugGraphDetails.ALL, ""ERROR"")\n        err, dbg = message.parse_error()\n        self._raise_in_user_thread(\n            RuntimeError(""%s: %s\\n%s\\n"" % (err, err.message, dbg)))\n\n    def __enter__(self):\n        self.received_eos.clear()\n        self.sink_pipeline.set_state(Gst.State.PLAYING)\n\n    def exit_prep(self):\n        # It goes sink.exit_prep, src.__exit__, sink.__exit__, so we can do\n        # teardown things here that require the src to still be running.\n\n        # Dropping the sink latency to 0 will cause all the frames in\n        # self._frames to be pushed next time on_sample is called.  We can\'t\n        # flush here because on_sample is called from the thread that is running\n        # `Display`.\n        self._sink_latency_secs = 0\n\n        # Wait for up to 1s for the sink pipeline to get into the RUNNING state.\n        # This is to avoid teardown races in the sink pipeline caused by buggy\n        # GStreamer elements\n        self.sink_pipeline.get_state(1 * Gst.SECOND)\n\n    def __exit__(self, _1, _2, _3):\n        # Drain the frame queue\n        while self._frames:\n            self._push_sample(self._frames.pop())\n\n        if self._sample_count > 0:\n            state = self.sink_pipeline.get_state(0)\n            if (state[0] != Gst.StateChangeReturn.SUCCESS or\n                    state[1] != Gst.State.PLAYING):\n                debug(""teardown: Sink pipeline not in state PLAYING: %r""\n                      % (state,))\n            debug(""teardown: Sending eos on sink pipeline"")\n            if self.appsrc.emit(""end-of-stream"") == Gst.FlowReturn.OK:\n                self.sink_pipeline.send_event(Gst.Event.new_eos())\n                if not self.received_eos.wait(10):\n                    debug(""Timeout waiting for sink EOS"")\n            else:\n                debug(""Sending EOS to sink pipeline failed"")\n        else:\n            debug(""SinkPipeline teardown: Not sending EOS, no samples sent"")\n\n        self.sink_pipeline.set_state(Gst.State.NULL)\n\n        # Don\'t want to cause the Display object to hang around on our account,\n        # we won\'t be raising any errors from now on anyway:\n        self._raise_in_user_thread = None\n\n    def on_sample(self, sample):\n        """"""\n        Called from `Display` for each frame.\n        """"""\n        now = sample.time\n        self._frames.appendleft(sample)\n\n        while self._frames:\n            oldest = self._frames.pop()\n            if oldest.time > now - self._sink_latency_secs:\n                self._frames.append(oldest)\n                break\n            self._push_sample(oldest)\n\n    def _push_sample(self, sample):\n        # Calculate whether we need to draw any annotations on the output video.\n        now = sample.time\n        annotations = []\n        with self.annotations_lock:\n            # Remove expired annotations\n            self.text_annotations = [x for x in self.text_annotations\n                                     if now < x.end_time]\n            current_texts = [x for x in self.text_annotations if x.time <= now]\n            for annotation in list(self.annotations):\n                if annotation.time == now:\n                    annotations.append(annotation)\n                if now >= annotation.time:\n                    self.annotations.remove(annotation)\n\n        sample = gst_sample_make_writable(sample)\n        img = array_from_sample(sample, readwrite=True)\n        # Text:\n        _draw_text(\n            img,\n            datetime.datetime.fromtimestamp(now).strftime(""%H:%M:%S.%f"")[:-4],\n            (10, 30), (255, 255, 255))\n        for i, x in enumerate(reversed(current_texts)):\n            origin = (10, (i + 2) * 30)\n            age = float(now - x.time) / 3\n            color = (native(int(255 * max([1 - age, 0.5]))).__int__(),) * 3\n            _draw_text(img, x.text, origin, color)\n\n        # Regions:\n        for annotation in annotations:\n            _draw_annotation(img, annotation)\n\n        APPSRC_LIMIT_BYTES = 100 * 1024 * 1024  # 100MB\n        if self.appsrc.props.current_level_bytes > APPSRC_LIMIT_BYTES:\n            # appsrc is backed-up, perhaps something\'s gone wrong.  We don\'t\n            # want to use up all RAM, so let\'s drop the buffer on the floor.\n            if not self._appsrc_was_full:\n                warn(""sink pipeline appsrc is full, dropping buffers from now ""\n                     ""on"")\n                self._appsrc_was_full = True\n            return\n        elif self._appsrc_was_full:\n            debug(""sink pipeline appsrc no longer full, pushing buffers again"")\n            self._appsrc_was_full = False\n\n        self.appsrc.props.caps = sample.get_caps()\n        self.appsrc.emit(""push-buffer"", sample.get_buffer())\n        self._sample_count += 1\n\n    def draw(self, obj, duration_secs=None, label=""""):\n        with self.annotations_lock:\n            if isinstance(obj, string_types):\n                start_time = self._time.time()\n                text = (\n                    to_unicode(\n                        datetime.datetime.fromtimestamp(start_time).strftime(\n                            ""%H:%M:%S.%f"")[:-4]) +\n                    \' \' +\n                    to_unicode(obj))\n                self.text_annotations.append(\n                    _TextAnnotation(start_time, text, duration_secs))\n            elif hasattr(obj, ""region"") and hasattr(obj, ""time""):\n                annotation = _Annotation.from_result(obj, label=label)\n                if annotation.time:\n                    self.annotations.append(annotation)\n            else:\n                raise TypeError(\n                    ""Can\'t draw object of type \'%s\'"" % type(obj).__name__)\n\n\nclass NoSinkPipeline(object):\n    """"""\n    Used in place of a SinkPipeline when no video output is required.  Is a lot\n    faster because it doesn\'t do anything.  It especially doesn\'t do any copying\n    nor video encoding :).\n    """"""\n    def __enter__(self):\n        pass\n\n    def exit_prep(self):\n        pass\n\n    def __exit__(self, _1, _2, _3):\n        pass\n\n    def on_sample(self, _sample):\n        pass\n\n    def draw(self, _obj, _duration_secs=None, label=""""):\n        pass\n\n\nclass Display(object):\n    def __init__(self, user_source_pipeline, sink_pipeline):\n\n        import time\n\n        self._condition = threading.Condition()  # Protects last_frame\n        self.last_frame = None\n        self.last_used_frame = None\n        self.source_pipeline = None\n        self.init_time = time.time()\n        self.tearing_down = False\n\n        appsink = (\n            ""appsink name=appsink max-buffers=1 drop=false sync=true ""\n            ""emit-signals=true ""\n            ""caps=video/x-raw,format=BGR"")\n        # Notes on the source pipeline:\n        # * _stbt_raw_frames_queue is kept small to reduce the amount of slack\n        #   (and thus the latency) of the pipeline.\n        # * _stbt_user_data_queue before the decodebin is large.  We don\'t want\n        #   to drop encoded packets as this will cause significant image\n        #   artifacts in the decoded buffers.  We make the assumption that we\n        #   have enough horse-power to decode the incoming stream and any delays\n        #   will be transient otherwise it could start filling up causing\n        #   increased latency.\n        self.source_pipeline_description = "" ! "".join([\n            user_source_pipeline,\n            \'queue name=_stbt_user_data_queue max-size-buffers=0 \'\n            \'    max-size-bytes=0 max-size-time=10000000000\',\n            ""decodebin"",\n            \'queue name=_stbt_raw_frames_queue max-size-buffers=2\',\n            \'videoconvert\',\n            \'video/x-raw,format=BGR\',\n            appsink])\n        self.create_source_pipeline()\n\n        self._sink_pipeline = sink_pipeline\n\n        debug(""source pipeline: %s"" % self.source_pipeline_description)\n\n    def create_source_pipeline(self):\n        self.source_pipeline = Gst.parse_launch(\n            self.source_pipeline_description)\n        source_bus = self.source_pipeline.get_bus()\n        source_bus.connect(""message::error"", self.on_error)\n        source_bus.connect(""message::warning"", self.on_warning)\n        source_bus.connect(""message::eos"", self.on_eos_from_source_pipeline)\n        source_bus.add_signal_watch()\n        appsink = self.source_pipeline.get_by_name(""appsink"")\n        appsink.connect(""new-sample"", self.on_new_sample)\n\n        # A realtime clock gives timestamps compatible with time.time()\n        self.source_pipeline.use_clock(\n            Gst.SystemClock(clock_type=Gst.ClockType.REALTIME))\n\n    def set_source_pipeline_playing(self):\n        if (self.source_pipeline.set_state(Gst.State.PAUSED) ==\n                Gst.StateChangeReturn.NO_PREROLL):\n            # This is a live source, drop frames if we get behind\n            self.source_pipeline.get_by_name(\'_stbt_raw_frames_queue\') \\\n                .set_property(\'leaky\', to_native_str(\'downstream\'))\n            self.source_pipeline.get_by_name(\'appsink\') \\\n                .set_property(\'sync\', False)\n\n        self.source_pipeline.set_state(Gst.State.PLAYING)\n\n    def get_frame(self, timeout_secs=10, since=None):\n        import time\n        t = time.time()\n        end_time = t + timeout_secs\n        if since is None:\n            # If you want to wait 10s for a frame you\'re probably not interested\n            # in a frame from 10s ago.\n            since = t - timeout_secs\n\n        with self._condition:\n            while True:\n                if (isinstance(self.last_frame, Frame) and\n                        self.last_frame.time > since):\n                    self.last_used_frame = self.last_frame\n                    return self.last_frame\n                elif isinstance(self.last_frame, Exception):\n                    raise RuntimeError(text_type(self.last_frame))\n                t = time.time()\n                if t > end_time:\n                    break\n                self._condition.wait(end_time - t)\n\n        pipeline = self.source_pipeline\n        if pipeline:\n            Gst.debug_bin_to_dot_file_with_ts(\n                pipeline, Gst.DebugGraphDetails.ALL, ""NoVideo"")\n        raise NoVideo(""No video"")\n\n    def on_new_sample(self, appsink):\n        sample = appsink.emit(""pull-sample"")\n\n        running_time = sample.get_segment().to_running_time(\n            Gst.Format.TIME, sample.get_buffer().pts)\n        sample.time = float(appsink.base_time + running_time) / 1e9\n\n        if (sample.time > self.init_time + 31536000 or\n                sample.time < self.init_time - 31536000):  # 1 year\n            warn(""Received frame with suspicious timestamp: %f. Check your ""\n                 ""source-pipeline configuration."" % sample.time)\n\n        frame = array_from_sample(sample)\n        frame.flags.writeable = False\n\n        # See also: logging.draw_on\n        frame._draw_sink = weakref.ref(self._sink_pipeline)  # pylint: disable=protected-access\n        self.tell_user_thread(frame)\n        self._sink_pipeline.on_sample(sample)\n        return Gst.FlowReturn.OK\n\n    def tell_user_thread(self, frame_or_exception):\n        # `self.last_frame` is how we communicate from this thread (the GLib\n        # main loop) to the main application thread running the user\'s script.\n        # Note that only this thread writes to self.last_frame.\n\n        if isinstance(frame_or_exception, Exception):\n            ddebug(""glib thread: reporting exception to user thread: %s"" %\n                   frame_or_exception)\n        else:\n            ddebug(""glib thread: new sample (time=%s)."" %\n                   frame_or_exception.time)\n\n        with self._condition:\n            self.last_frame = frame_or_exception\n            self._condition.notify_all()\n\n    def on_error(self, _bus, message):\n        assert message.type == Gst.MessageType.ERROR\n        pipeline = self.source_pipeline\n        if pipeline is not None:\n            Gst.debug_bin_to_dot_file_with_ts(\n                pipeline, Gst.DebugGraphDetails.ALL, ""ERROR"")\n        err, dbg = message.parse_error()\n        self.tell_user_thread(\n            RuntimeError(""%s: %s\\n%s\\n"" % (err, err.message, dbg)))\n\n    def on_warning(self, _bus, message):\n        assert message.type == Gst.MessageType.WARNING\n        Gst.debug_bin_to_dot_file_with_ts(\n            self.source_pipeline, Gst.DebugGraphDetails.ALL, ""WARNING"")\n        err, dbg = message.parse_warning()\n        warn(""%s: %s\\n%s\\n"" % (err, err.message, dbg))\n\n    def on_eos_from_source_pipeline(self, _bus, _message):\n        if not self.tearing_down:\n            warn(""Got EOS from source pipeline"")\n            self.restart_source()\n\n    def restart_source(self, *_args):\n        warn(""Attempting to recover from video loss: ""\n             ""Stopping source pipeline and waiting 5s..."")\n        self.source_pipeline.set_state(Gst.State.NULL)\n        self.source_pipeline = None\n        GObjectTimeout(5, self.start_source).start()\n        return False  # stop the timeout from running again\n\n    def start_source(self):\n        if self.tearing_down:\n            return False\n        warn(""Restarting source pipeline..."")\n        self.create_source_pipeline()\n        self.set_source_pipeline_playing()\n        warn(""Restarted source pipeline"")\n        return False  # stop the timeout from running again\n\n    @staticmethod\n    def appsink_await_eos(appsink, timeout=None):\n        done = threading.Event()\n\n        def on_eos(_appsink):\n            done.set()\n            return True\n        hid = appsink.connect(\'eos\', on_eos)\n        d = appsink.get_property(\'eos\') or done.wait(timeout)\n        appsink.disconnect(hid)\n        return d\n\n    def __enter__(self):\n        self.set_source_pipeline_playing()\n\n    def __exit__(self, _1, _2, _3):\n        self.tearing_down = True\n        self.source_pipeline, source = None, self.source_pipeline\n        if source:\n            source.set_state(Gst.State.NULL)\n            source = None\n\n\ndef _draw_text(numpy_image, text, origin, color, font_scale=1.0):\n    if not text:\n        return\n\n    (width, height), _ = cv2.getTextSize(\n        text, fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=font_scale,\n        thickness=1)\n    cv2.rectangle(\n        numpy_image, (origin[0] - 2, origin[1] + 2),\n        (origin[0] + width + 2, origin[1] - height - 2),\n        thickness=cv2_compat.FILLED, color=(0, 0, 0))\n    cv2.putText(\n        numpy_image, text, origin, cv2.FONT_HERSHEY_DUPLEX,\n        fontScale=font_scale, color=color, lineType=cv2_compat.LINE_AA)\n\n\nclass GObjectTimeout(object):\n    """"""Responsible for setting a timeout in the GTK main loop.""""""\n    def __init__(self, timeout_secs, handler, *args):\n        self.timeout_secs = timeout_secs\n        self.handler = handler\n        self.args = args\n        self.timeout_id = None\n\n    def start(self):\n        self.timeout_id = GObject.timeout_add(\n            self.timeout_secs * 1000, self.handler, *self.args)\n\n    def cancel(self):\n        if self.timeout_id:\n            GObject.source_remove(self.timeout_id)\n        self.timeout_id = None\n'"
_stbt/cv2_compat.py,0,"b'""""""\nCompatibility so stb-tester will work with both OpenCV 2, 3, and 4.\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nfrom distutils.version import LooseVersion\n\nimport cv2\n\nversion = LooseVersion(cv2.__version__).version\n\nif version >= [3, 2, 0]:\n    def find_contour_boxes(image, mode, method):  # pylint:disable=redefined-outer-name\n        contours = cv2.findContours(image=image, mode=mode, method=method)\n\n        # In OpenCV 4, the behavior of find findContours changes from returning\n        # (img, contours, hierarchy) back to (contours, hierarchy):\n        # https://bit.ly/31bWiIP\n        contours = contours[0] if version >= [4, 0, 0] else contours[1]\n        return [cv2.boundingRect(x) for x in contours]\nelse:\n    def _fix_pre_3_2_rects(r):\n        # In OpenCV 3.2 the behaviour of findContours changed.  It seems more\n        # sensible now but we need to still support the old behaviour.\n        # See 56c133d459248d17165d77eb902a8049680bf896 in OpenCV:\n        # https://github.com/opencv/opencv/commit/56c133d459248d17165d77eb902a8049680bf896\n        x, y, w, h = r\n        return (x - 1, y - 1, w + 2, h + 2)\n\n    def find_contour_boxes(image, mode, method):  # pylint:disable=redefined-outer-name\n        # In v3.0.0 cv2.findContours started returning\n        # (img, contours, hierarchy) rather than (contours, hierarchy).\n        # Index -2 selects contours on both versions:\n        contours = cv2.findContours(image=image, mode=mode, method=method)[-2]\n        return [_fix_pre_3_2_rects(cv2.boundingRect(x)) for x in contours]\n\n# We prefer the v3 names here rather than the v2.4 names:\nif version >= [3, 0, 0]:\n    FILLED = cv2.FILLED  # pylint: disable=c-extension-no-member\n    LINE_AA = cv2.LINE_AA  # pylint: disable=c-extension-no-member\nelse:\n    FILLED = cv2.cv.CV_FILLED  # pylint: disable=c-extension-no-member,no-member\n    LINE_AA = cv2.CV_AA  # pylint: disable=c-extension-no-member\n'"
_stbt/frameobject.py,0,"b'""""""\nCopyright 2016-2018 Stb-tester.com Ltd.\nLicense: LGPL v2.1 or (at your option) any later version (see\nhttps://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom past.builtins import cmp\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport functools\nimport threading\nfrom future.utils import with_metaclass\n\ntry:\n    from itertools import zip_longest\nexcept ImportError:\n    # Python 2:\n    from itertools import izip_longest as zip_longest\n\n\ndef for_object_repository(cls=None):\n    """"""A decorator that marks classes and functions so they appear in the Object\n    Repository.\n\n    Classes that directly derive from `stbt.FrameObject` have this decorator\n    applied to them automatically.  This can be used to register other classes\n    and functions.\n\n    Usage:\n\n        @for_object_repository\n        class MyClass(object):\n            ...\n    """"""\n    # These classes are extracted by static analysis, so return the class\n    # unchanged:\n    if cls is None:\n        # Called like:\n        #\n        #     @for_object_repository()\n        #     class MyClass(object):\n        def decorator(cls):\n            return cls\n        return decorator\n    else:\n        # Called like:\n        #\n        #    @for_object_repository\n        #    class MyClass(object):\n        return cls\n\n\ndef _memoize_property_fn(fn):\n    @functools.wraps(fn)\n    def inner(self):\n        # pylint: disable=protected-access\n        if fn not in self._FrameObject__frame_object_cache:\n            self._FrameObject__frame_object_cache[fn] = fn(self)\n        return self._FrameObject__frame_object_cache[fn]\n    return inner\n\n\ndef _mark_in_is_visible(fn):\n    @functools.wraps(fn)\n    def inner(self):\n        # pylint: disable=protected-access\n        try:\n            self._FrameObject__local.in_is_visible += 1\n        except AttributeError:\n            self._FrameObject__local.in_is_visible = 1\n        try:\n            return bool(fn(self))\n        finally:\n            self._FrameObject__local.in_is_visible -= 1\n    return inner\n\n\ndef _noneify_property_fn(fn):\n    @functools.wraps(fn)\n    def inner(self):\n        # pylint: disable=protected-access\n        if (getattr(self._FrameObject__local, ""in_is_visible"", 0) or\n                self.is_visible):\n            return fn(self)\n        else:\n            return None\n    return inner\n\n\nclass _FrameObjectMeta(type):\n    def __new__(mcs, name, parents, dct):\n        for k, v in dct.items():\n            if isinstance(v, property):\n                # Properties must not have setters\n                if v.fset is not None:\n                    raise Exception(\n                        ""FrameObjects must be immutable but this property has ""\n                        ""a setter"")\n                f = v.fget\n                # The value of any property is cached after the first use\n                f = _memoize_property_fn(f)\n                # Public properties return `None` if the FrameObject isn\'t\n                # visible.\n                if k == \'is_visible\':\n                    f = _mark_in_is_visible(f)\n                elif not k.startswith(\'_\'):\n                    f = _noneify_property_fn(f)\n                dct[k] = property(f)\n\n        return super(_FrameObjectMeta, mcs).__new__(mcs, name, parents, dct)\n\n    def __init__(cls, name, parents, dct):\n        property_names = sorted([\n            p for p in dir(cls)\n            if isinstance(getattr(cls, p), property)])\n        assert \'is_visible\' in property_names\n        cls._fields = tuple([""is_visible""] + sorted(\n            x for x in property_names\n            if x != ""is_visible"" and not x.startswith(\'_\')))\n        super(_FrameObjectMeta, cls).__init__(name, parents, dct)\n\n\nclass FrameObject(with_metaclass(_FrameObjectMeta, object)):\n    # pylint: disable=line-too-long\n    r\'\'\'Base class for user-defined Page Objects.\n\n    FrameObjects are Stb-tester\'s implementation of the *Page Object* pattern.\n    A FrameObject is a class that uses Stb-tester APIs like ``stbt.match()``\n    and ``stbt.ocr()`` to extract information from the screen, and it provides\n    a higher-level API in the vocabulary and user-facing concepts of your own\n    application.\n\n    .. figure:: images/object-repository/frame-object-pattern.png\n       :align: center\n\n       Based on Martin Fowler\'s `PageObject <fowler_>`_ diagram\n\n    Stb-tester uses a separate instance of your FrameObject class for each\n    frame of video captured from the device-under-test (hence the name ""Frame\n    Object""). Stb-tester provides additional tooling for writing, testing,\n    and maintenance of FrameObjects.\n\n    To define your own FrameObject class:\n\n    * Derive from ``stbt.FrameObject``.\n    * Define an ``is_visible`` property (using Python\'s `@property`_ decorator)\n      that returns True or False.\n    * Define any other properties for information that you want to extract\n      from the frame.\n    * Inside each property, when you call an image-processing function (like\n      `stbt.match` or `stbt.ocr`) you must specify the parameter\n      ``frame=self._frame``.\n\n    The following behaviours are provided automatically by the FrameObject\n    base class:\n\n    * **Truthiness:** A FrameObject instance is considered ""truthy"" if it is\n      visible. Any other properties (apart from ``is_visible``) will return\n      ``None`` if the object isn\'t visible.\n\n    * **Immutability:** FrameObjects are immutable, because they represent\n      information about a specific frame of video -- in other words, an\n      instance of a FrameOject represents the state of the device-under-test at\n      a specific point in time. If you define any methods that change the state\n      of the device-under-test, they should return a new FrameObject instance\n      instead of modifying ``self``.\n\n    * **Caching:** Each property will be cached the first time is is used. This\n      allows writing testcases in a natural way, while expensive operations\n      like ``ocr`` will only be done once per frame.\n\n    The FrameObject base class defines several convenient methods and\n    attributes (see below).\n\n    For more details see `Object Repository`_ in the Stb-tester manual.\n\n    .. _@property: https://docs.python.org/3.6/library/functions.html#property\n    .. _fowler: https://martinfowler.com/bliki/PageObject.html\n    .. _Object Repository: https://stb-tester.com/manual/object-repository\n\n    Added in v30: ``_fields`` and ``refresh``.\n    \'\'\'\n\n    def __init__(self, frame=None):\n        """"""The default constructor takes an optional frame of video; if the\n        frame is not provided, it will grab a frame from the device-under-test.\n\n        If you override the constructor in your derived class (for example to\n        accept additional parameters), make sure to accept an optional\n        ``frame`` parameter and supply it to the super-class\'s constructor.\n        """"""\n        if frame is None:\n            import stbt\n            frame = stbt.get_frame()\n        self.__frame_object_cache = {}\n        self.__local = threading.local()\n        self._frame = frame\n\n    def __repr__(self):\n        """"""\n        The object\'s string representation includes all its public properties.\n        """"""\n        args = "", "".join((""%s=%r"" % x) for x in self._iter_fields())\n        return ""%s(%s)"" % (self.__class__.__name__, args)\n\n    def _iter_fields(self):\n        if self:\n            for x in self._fields:  # pylint:disable=no-member\n                yield x, getattr(self, x)\n        else:\n            yield ""is_visible"", False\n\n    def __bool__(self):\n        """"""\n        Delegates to ``is_visible``. The object will only be considered True if\n        it is visible.\n        """"""\n        return bool(self.is_visible)\n\n    def __eq__(self, other):\n        """"""\n        Two instances of the same ``FrameObject`` type are considered equal if\n        the values of all the public properties match, even if the underlying\n        frame is different. All falsey FrameObjects of the same type are equal.\n        """"""\n        return self.__cmp__(other) == 0\n\n    def __ne__(self, other):\n        return self.__cmp__(other) != 0\n\n    def __lt__(self, other):\n        return self.__cmp__(other) < 0\n\n    def __le__(self, other):\n        return self.__cmp__(other) <= 0\n\n    def __gt__(self, other):\n        return self.__cmp__(other) > 0\n\n    def __ge__(self, other):\n        return self.__cmp__(other) >= 0\n\n    def __cmp__(self, other):\n        # pylint: disable=protected-access\n        if isinstance(other, self.__class__):\n            for s, o in zip_longest(self._iter_fields(), other._iter_fields()):\n                v = cmp(s[1], o[1])\n                if v != 0:\n                    return v\n            return 0\n        else:\n            return NotImplemented\n\n    def __hash__(self):\n        """"""\n        Two instances of the same ``FrameObject`` type are considered equal if\n        the values of all the public properties match, even if the underlying\n        frame is different. All falsey FrameObjects of the same type are equal.\n        """"""\n        return hash(tuple(v for _, v in self._iter_fields()))\n\n    @property\n    def is_visible(self):\n        raise NotImplementedError(\n            ""Objects deriving from FrameObject must define an is_visible ""\n            ""property"")\n\n    def refresh(self, frame=None, **kwargs):\n        """"""\n        Returns a new FrameObject instance with a new frame. ``self`` is not\n        modified.\n\n        ``refresh`` is used by navigation functions that modify the state of\n        the device-under-test.\n\n        By default ``refresh`` returns a new object of the same class as\n        ``self``, but you can override the return type by implementing\n        ``refresh`` in your derived class.\n\n        Any additional keyword arguments are passed on to ``__init__``.\n        """"""\n        return type(self)(frame=frame, **kwargs)\n'"
_stbt/grid.py,0,"b'""""""Copyright 2019 Stb-tester.com Ltd.""""""\n\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nfrom collections import namedtuple\n\nimport networkx as nx\n\nfrom .types import Position, Region\nfrom .utils import native_int\n\n\nclass Grid(object):\n    """"""A grid with items arranged left to right, then down.\n\n    For example a keyboard, or a grid of posters, arranged like this::\n\n        ABCDE\n        FGHIJ\n        KLMNO\n\n    All items must be the same size, and the spacing between them must be\n    consistent.\n\n    This class is useful for converting between pixel coordinates on a screen,\n    to x & y indexes into the grid positions.\n\n    :param Region region: Where the grid is on the screen.\n    :param int cols: Width of the grid, in number of columns.\n    :param int rows: Height of the grid, in number of rows.\n    :param data: A 2D array (list of lists) containing data to associate with\n        each cell. The data can be of any type. For example, if you are\n        modelling a grid-shaped keyboard, the data could be the letter at each\n        grid position. If ``data`` is specified, then ``cols`` and ``rows`` are\n        optional.\n    """"""\n    def __init__(self, region, cols=None, rows=None, data=None):\n        self.region = region\n        self.data = data\n        if (rows is None or cols is None) and data is None:\n            raise ValueError(\n                ""Either `cols` and `rows`, or `data` must be specified"")\n        if rows is None:\n            self.rows = len(data)\n        else:\n            self.rows = rows\n        if cols is None:\n            self.cols = len(data[0])\n        else:\n            self.cols = cols\n\n    class Cell(namedtuple(""Cell"", ""index position region data"")):\n        """"""A single cell in a `Grid`.\n\n        Don\'t construct Cells directly; create a `Grid` instead.\n\n        :ivar int index: The cell\'s 1D index into the grid, starting from 0 at\n            the top left, counting along the top row left to right, then the\n            next row left to right, etc.\n\n        :ivar Position position: The cell\'s 2D index (x, y) into the grid\n            (zero-based). For example in this grid ""I"" is index ``8`` and\n            position ``(x=3, y=1)``::\n\n                ABCDE\n                FGHIJ\n                KLMNO\n\n        :ivar Region region: Pixel coordinates (relative to the entire frame)\n            of the cell\'s bounding box.\n\n        :ivar data: The data corresponding to the cell, if data was specified\n            when you created the `Grid`.\n        """"""\n        pass\n\n    def __repr__(self):\n        s = ""Grid(region=%r, cols=%r, rows=%r)"" % (\n            self.region, self.cols, self.rows)\n        if self.data:\n            return ""<"" + s + "">""\n        else:\n            return s\n\n    @property\n    def area(self):\n        return self.cols * self.rows\n\n    @property\n    def cells(self):\n        return [self.get(index=i)\n                for i in range(self.cols * self.rows)]\n\n    def get(self, index=None, position=None, region=None, data=None):\n        """"""Retrieve a single cell in the Grid.\n\n        For example, let\'s say that you\'re looking for the selected item in\n        a grid by matching a reference image of the selection border. Then you\n        can find the (x, y) position in the grid of the selection, like this::\n\n            selection = stbt.match(""selection.png"")\n            cell = grid.get(region=selection.region)\n            position = cell.position\n\n        You must specify one (and only one) of ``index``, ``position``,\n        ``region``, or ``data``. For the meaning of these parameters see\n        `Grid.Cell`. A negative index counts backwards from the end of the grid\n        (so ``-1`` is the bottom right position).\n\n        :returns: The `Grid.Cell` that matches the specified query; raises\n            `IndexError` if the index/position/region is out of bounds or the\n            data is not found.\n        """"""\n        if len([x for x in [index, position, region, data]\n                if x is not None]) != 1:\n            raise ValueError(""Exactly one of index, position, region, or data ""\n                             ""must be specified"")\n        if data is not None and self.data is None:\n            raise IndexError(""Searching by data %r but this Grid doesn\'t have ""\n                             ""any data associated"" % data)\n        if index is not None:\n            position = self._index_to_position(index)\n            region = (None if self.region is None\n                      else self._position_to_region(position))\n        elif position is not None:\n            index = self._position_to_index(position)\n            region = (None if self.region is None\n                      else self._position_to_region(position))\n        elif region is not None:\n            position = self._region_to_position(region)\n            index = self._position_to_index(position)\n            region = (None if self.region is None\n                      else self._position_to_region(position))\n        elif data is not None:\n            for i in range(self.cols * self.rows):\n                position = self._index_to_position(i)\n                if data == self.data[position[1]][position[0]]:\n                    index = i\n                    region = (None if self.region is None\n                              else self._position_to_region(position))\n                    break\n            else:\n                raise IndexError(""data %r not found"" % (data,))\n\n        return Grid.Cell(\n            index,\n            position,\n            region,\n            self.data and self.data[position[1]][position[0]])\n\n    def __getitem__(self, key):\n        if isinstance(key, int):\n            return self.get(index=key)\n        elif isinstance(key, Region):\n            return self.get(region=key)\n        elif isinstance(key, Position) or (\n                isinstance(key, tuple) and\n                len(key) == 2 and\n                isinstance(key[0], int) and\n                isinstance(key[1], int)):\n            return self.get(position=key)\n        else:\n            return self.get(data=key)\n\n    def __iter__(self):\n        for i in range(len(self)):  # pylint:disable=consider-using-enumerate\n            yield self[i]\n\n    def __len__(self):\n        return self.cols * self.rows\n\n    def _index_to_position(self, index):\n        area = self.cols * self.rows\n        if index < -area:\n            raise IndexError(""Index out of range: index %r in %r"" %\n                             (index, self))\n        elif index < 0:\n            return self._index_to_position(area + index)\n        elif index < area:\n            return Position(x=index % self.cols, y=index // self.cols)\n        else:\n            raise IndexError(""Index out of range: index %r in %r"" %\n                             (index, self))\n\n    def _position_to_index(self, position):\n        return position[0] + position[1] * self.cols\n\n    def _region_to_position(self, region):\n        rel = region.translate(x=-self.region.x, y=-self.region.y)\n        centre = (float(rel.x + rel.right) / 2,\n                  float(rel.y + rel.bottom) / 2)\n        pos = (centre[0] * self.cols // self.region.width,\n               centre[1] * self.rows // self.region.height)\n        if (pos[0] < 0 or pos[1] < 0 or\n                pos[0] >= self.cols or pos[1] >= self.rows):\n            raise IndexError(\n                ""The centre of region %r is outside the grid area %r"" % (\n                    region, self.region))\n        return Position(native_int(pos[0]), native_int(pos[1]))\n\n    def _position_to_region(self, position):\n        if isinstance(position, int):\n            position = self._index_to_position(position)\n        elif not isinstance(position, Position):\n            position = Position(position[0], position[1])\n\n        position = Position(\n            position.x if position.x >= 0 else self.cols - position.x,\n            position.y if position.y >= 0 else self.rows - position.y)\n        if (0 <= position.x < self.cols and 0 <= position.y < self.rows):\n            return Region.from_extents(\n                self.region.x + self.region.width * position.x //\n                self.cols,\n                self.region.y + self.region.height * position.y //\n                self.rows,\n                self.region.x + self.region.width * (position.x + 1) //\n                self.cols,\n                self.region.y + self.region.height * (position.y + 1) //\n                self.rows)\n        else:\n            raise IndexError(""Index out of range: position %r in %r"" %\n                             (position, self))\n\n\ndef grid_to_navigation_graph(grid):\n    """"""Generate a Graph that describes navigation between cells in the grid.\n\n    Creates a `networkx.DiGraph` (`Directed Graph`_) that models cells in the\n    grid as nodes in the graph. Each edge in the graph has a ``key`` attribute\n    set to ""KEY_LEFT"", ""KEY_RIGHT"", ""KEY_UP"", or ""KEY_DOWN"", corresponding to\n    the keypress that will move a selection from one node to another.\n\n    :param Grid grid: The grid to model. If the Grid has data associated\n        with the cells, each node in the graph will be named with the\n        corresponding cell\'s ``data``; otherwise the nodes are numbered\n        according to the cell\'s ``index``. This means that the cell\'s ``data``\n        must be `hashable`_ so that it can be used as a `networkx` node.\n\n    :returns: A `networkx.DiGraph`.\n\n    For example, to create a graph suitable as the ``graph`` parameter of\n    `stbt.Keyboard`::\n\n        grid = stbt.Grid(region, data=[""ABCDEFG"",\n                                       ""HIJKLMN"",\n                                       ""OPQRSTU"",\n                                       ""VWXYZ-\'""])\n        keyboard = stbt.Keyboard(grid_to_navigation_graph(grid))\n\n    .. _Directed Graph: https://en.wikipedia.org/wiki/Directed_graph\n    .. _hashable: https://docs.python.org/3.6/glossary.html#term-hashable\n    """"""\n    G = nx.DiGraph()\n\n    def name(c):\n        if c.data is None:\n            return c.index\n        else:\n            return c.data\n\n    for cell in grid:\n        x, y = cell.position\n        if x > 0:\n            G.add_edge(name(cell), name(grid[x - 1, y]), key=""KEY_LEFT"")\n        if x < grid.cols - 1:\n            G.add_edge(name(cell), name(grid[x + 1, y]), key=""KEY_RIGHT"")\n        if y > 0:\n            G.add_edge(name(cell), name(grid[x, y - 1]), key=""KEY_UP"")\n        if y < grid.rows - 1:\n            G.add_edge(name(cell), name(grid[x, y + 1]), key=""KEY_DOWN"")\n    return G\n'"
_stbt/gst_hacks.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport ctypes\nimport platform\nfrom contextlib import contextmanager\nfrom os.path import dirname\n\nimport gi\n\ngi.require_version(""Gst"", ""1.0"")\nfrom gi.repository import Gst  # pylint:disable=wrong-import-order\n\n# Here we are using ctypes to call `gst_buffer_map` and `gst_buffer_unmap`\n# because PyGObject does not properly expose struct GstMapInfo (see\n# [bz #678663]).  Apparently this is fixed upstream but we are still awaiting\n# an upstream release (Mar 2014).  Hopefully this can be removed in the future.\n\n_GST_PADDING = 4  # From gstconfig.h\n\n\n# From struct GstMapInfo in gstreamer/gst/gstmemory.h:\nclass _GstMapInfo(ctypes.Structure):\n    _fields_ = [(""memory"", ctypes.c_void_p),   # GstMemory *memory\n                (""flags"", ctypes.c_int),       # GstMapFlags flags\n                (""data"", ctypes.POINTER(ctypes.c_byte)),    # guint8 *data\n                (""size"", ctypes.c_size_t),     # gsize size\n                (""maxsize"", ctypes.c_size_t),  # gsize maxsize\n                (""user_data"", ctypes.c_void_p * 4),     # gpointer user_data[4]\n                # gpointer _gst_reserved[GST_PADDING]:\n                (""_gst_reserved"", ctypes.c_void_p * _GST_PADDING)]\n\n_GstMapInfo_p = ctypes.POINTER(_GstMapInfo)\n\nif platform.system() == ""Darwin"":\n    _libgst = ctypes.CDLL(dirname(Gst.__path__) + ""/../libgstreamer-1.0.dylib"")\nelse:\n    _libgst = ctypes.CDLL(""libgstreamer-1.0.so.0"")\n_libgst.gst_buffer_map.argtypes = [ctypes.c_void_p, _GstMapInfo_p, ctypes.c_int]\n_libgst.gst_buffer_map.restype = ctypes.c_int\n\n_libgst.gst_buffer_unmap.argtypes = [ctypes.c_void_p, _GstMapInfo_p]\n_libgst.gst_buffer_unmap.restype = None\n\n_libgst.gst_buffer_get_size.argtypes = [ctypes.c_void_p]\n_libgst.gst_buffer_get_size.restype = ctypes.c_size_t\n\n_libgst.gst_sample_get_buffer.argtypes = [ctypes.c_void_p]\n_libgst.gst_sample_get_buffer.restype = ctypes.c_void_p\n\n_libgst.gst_mini_object_is_writable.argtypes = [ctypes.c_void_p]\n_libgst.gst_mini_object_is_writable.restype = ctypes.c_int\n\n\n@contextmanager\ndef _map_gst_buffer(pbuffer, flags):\n    if pbuffer is None:\n        raise TypeError(""Cannot pass NULL to _map_gst_buffer"")\n    if flags & Gst.MapFlags.WRITE \\\n            and _libgst.gst_mini_object_is_writable(pbuffer) == 0:\n        raise ValueError(\n            ""Writable array requested but buffer is not writeable"")\n\n    mapping = _GstMapInfo()\n    success = _libgst.gst_buffer_map(pbuffer, mapping, flags)\n    if not success:\n        raise RuntimeError(""Couldn\'t map buffer"")\n    try:\n        yield ctypes.cast(\n            mapping.data, ctypes.POINTER(ctypes.c_byte * mapping.size)).contents\n    finally:\n        _libgst.gst_buffer_unmap(pbuffer, mapping)\n\n\n@contextmanager\ndef map_gst_sample(sample, flags):\n    with _sample_borrow_buffer(sample) as pbuffer:\n        with _map_gst_buffer(pbuffer, flags) as x:\n            yield x\n\n\n@contextmanager\ndef _sample_borrow_buffer(sample):\n    """"""\n    This function exists because of a change in behaviour of pygobject 3.13 that\n    broke our ability to get a writable buffer from a GstSample.\n\n    See https://bugzilla.gnome.org/show_bug.cgi?id=736896 for more information.\n    """"""\n    if not isinstance(sample, Gst.Sample):\n        raise TypeError(""sample_borrow_buffer must take a Gst.Sample.  ""\n                        ""Received a %s instead"" % str(type(sample)))\n\n    # hashing a GObject actually gives the address (pointer) of the C struct\n    # that backs it!:\n    pbuffer = _libgst.gst_sample_get_buffer(hash(sample))\n    if pbuffer is None:\n        raise ValueError(\n            ""sample_borrow_buffer: Provided GstSample doesn\'t contain a buffer"")\n    yield pbuffer\n\n\ndef sample_get_size(sample):\n    with _sample_borrow_buffer(sample) as pbuffer:\n        return _libgst.gst_buffer_get_size(pbuffer)\n\n\ndef test_map_sample_reading_data():\n    Gst.init([])\n\n    s = Gst.Sample.new(Gst.Buffer.new_wrapped(b""hello""), None, None, None)\n    with map_gst_sample(s, Gst.MapFlags.READ) as a:\n        assert b\'hello\' == \'\'.join(chr(x) for x in a).encode(""ascii"")\n\n\ndef test_map_sample_modifying_data():\n    Gst.init([])\n\n    s = Gst.Sample.new(Gst.Buffer.new_wrapped(b""hello""), None, None, None)\n    with map_gst_sample(s, Gst.MapFlags.WRITE | Gst.MapFlags.READ) as a:\n        a[2] = 1\n\n    assert s.get_buffer().extract_dup(0, 5) == b""he\\x01lo""\n\n\ndef test_map_sample_without_buffer():\n    Gst.init([])\n\n    sample = Gst.Sample.new(None, None, None, None)\n    try:\n        # pylint:disable=no-value-for-parameter\n        with map_gst_sample(sample, Gst.MapFlags.READ):\n            assert False\n    except ValueError:\n        pass\n'"
_stbt/gst_utils.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport ctypes\nimport sys\nfrom functools import reduce  # pylint:disable=redefined-builtin\n\nimport gi\n\nfrom .gst_hacks import map_gst_sample, sample_get_size\nfrom .imgutils import Frame\n\ngi.require_version(""Gst"", ""1.0"")\nfrom gi.repository import GObject, Gst  # pylint:disable=wrong-import-order\n\nGst.init([])\n\n\ndef gst_sample_make_writable(sample):\n    if sample.get_buffer().mini_object.is_writable():\n        return sample\n    else:\n        return Gst.Sample.new(\n            sample.get_buffer().copy_region(\n                Gst.BufferCopyFlags.FLAGS | Gst.BufferCopyFlags.TIMESTAMPS |\n                Gst.BufferCopyFlags.META | Gst.BufferCopyFlags.MEMORY, 0,\n                sample.get_buffer().get_size()),\n            sample.get_caps(),\n            sample.get_segment(),\n            sample.get_info())\n\n\ndef sample_shape(sample):\n    caps = sample.get_caps().get_structure(0)\n    if caps.get_value(\'format\') in [\'BGR\', \'RGB\']:\n        return (caps.get_value(\'height\'), caps.get_value(\'width\'), 3)\n    else:\n        return (sample_get_size(sample),)\n\n\nclass _MappedSample(object):\n    """"""\n    Implements the numpy array interface for a GstSample, taking care to unmap\n    in its destructor.  This allows us to create numpy arrays backed by the\n    memory from a GstBuffer.\n    """"""\n    __slots__ = \'_ctx\', \'__array_interface__\'\n\n    def __init__(self, sample, readwrite=False):\n        if not isinstance(sample, Gst.Sample):\n            raise TypeError(""MappedSample must take a Gst.Sample.  Received a ""\n                            ""%s"" % str(type(sample)))\n\n        flags = Gst.MapFlags.READ\n        if readwrite:\n            flags |= Gst.MapFlags.WRITE\n\n        shape = sample_shape(sample)\n        size = reduce(lambda a, b: a * b, shape, 1)\n\n        ctx = map_gst_sample(sample, flags)\n        data = ctx.__enter__()\n        self._ctx = ctx\n        if len(data) != size:\n            raise ValueError(""Provided sample is too small for image of shape ""\n                             ""%s.  %iB < %iB."" % (shape, len(data), size))\n\n        self.__array_interface__ = {\n            ""shape"": shape,\n            ""typestr"": b""|u1"",\n            ""data"": (ctypes.addressof(data), not readwrite),\n            ""version"": 3,\n        }\n\n    def __del__(self):\n        self.__array_interface__ = None\n        if self._ctx:\n            self._ctx.__exit__(None, None, None)\n\n\ndef array_from_sample(sample, readwrite=False):\n    return Frame(\n        _MappedSample(sample, readwrite),\n        time=getattr(sample, \'time\', None))\n\n\ndef test_that_array_from_sample_readonly_gives_a_readonly_array():\n    Gst.init([])\n    s = Gst.Sample.new(Gst.Buffer.new_wrapped(b""hello""),\n                       Gst.Caps.from_string(""video/x-raw""), None, None)\n    array = array_from_sample(s)\n    try:\n        array[0] = 3\n        assert False, \'Writing elements should have thrown\'\n    except (ValueError, RuntimeError):\n        # Different versions of numpy raise different exceptions\n        pass\n\n\ndef test_that_array_from_sample_readwrite_gives_a_writable_array():\n    Gst.init([])\n    s = Gst.Sample.new(Gst.Buffer.new_wrapped(b""hello""),\n                       Gst.Caps.from_string(""video/x-raw""), None, None)\n    array = array_from_sample(s, readwrite=True)\n    array[0] = ord(""j"")\n    assert s.get_buffer().extract_dup(0, 5) == b""jello""\n\n\ndef test_that_array_from_sample_dimensions_of_array_are_according_to_caps():\n    s = Gst.Sample.new(Gst.Buffer.new_wrapped(\n        b""row 1 4 px  row 2 4 px  row 3 4 px  ""),\n        Gst.Caps.from_string(""video/x-raw,format=BGR,width=4,height=3""),\n        None, None)\n    a = array_from_sample(s)\n    assert a.shape == (3, 4, 3)\n\n\ndef frames_to_video(outfilename, frames, caps=""image/svg"",\n                    container=""ts""):\n    """"""Given a list (or generator) of video frames generates a video and writes\n    it to disk.  The video is MPEG4 encoded, with a silent stereo audio track\n    encoded as AAC.\n\n    :param outfilename: The filename of the video that is to be created\n    :param frames:      A list of frames of the format `[(data, duration), ...]`\n                        where duration is in nanoseconds and data will\n                        typically be a string.\n    :param caps:        GStreamer caps description as a string that describes\n                        the format of the data passed in as frames.\n    :param container:   The container format to use.  Valid choices are `""ts""`\n                        for mpeg-ts and `""mp4""`\n\n    The video/audio format was chosen as it seems to be most supported by most\n    TVs.\n\n    This function is typically used to generate a video from a list of SVGs.\n    You can define a generator that yields slightly different SVGs in a\n    sequence and get a video out the other side.  It can also be used for\n    simple slideshows, etc.""""""\n    muxer = {\'ts\': \'mpegtsmux\', \'mp4\': \'mp4mux\'}[container]\n    pipeline = Gst.parse_launch(\n        """"""\n        appsrc name=videosrc format=time caps=%s,framerate=(fraction)25/1 !\n          queue ! decodebin ! videoconvert !\n          videorate ! video/x-raw,framerate=(fraction)25/1 ! queue !\n          avenc_mpeg4 bitrate=3000000 ! mpeg4videoparse ! queue ! mux.\n        appsrc name=audiosrc format=time\n          caps=audio/x-raw,format=S16LE,channels=2,rate=48000,layout=interleaved\n          ! audioconvert ! queue ! voaacenc ! aacparse ! queue ! mux.\n        %s name=mux ! queue ! filesink location=""%s"" """""" %\n        (caps, muxer, outfilename))\n\n    vsrc = pipeline.get_by_name(\'videosrc\')\n    asrc = pipeline.get_by_name(\'audiosrc\')\n\n    r = PipelineRunner(pipeline)\n\n    t = 0\n    for data, duration in frames:\n        _appsrc_push_data(vsrc, data, t, duration)\n        _appsrc_push_data(asrc, \'\\0\\0\\0\\0\' * int(duration * 48000 / Gst.SECOND),\n                          t, duration)\n        t += duration\n\n    if t == 0:\n        raise ValueError(""Sequence argument frames must not be empty"")\n    _appsrc_push_data(vsrc, data, t, 0)  # pylint:disable=undefined-loop-variable\n\n    vsrc.emit(""end-of-stream"")\n    asrc.emit(\'end-of-stream\')\n\n    r.run()\n    return 0\n\n\ndef _appsrc_push_data(appsrc, data, pts=0, duration=0):\n    buf = Gst.Buffer.new_wrapped(data)\n    buf.pts = pts\n    buf.duration = duration\n    appsrc.emit(\'push-buffer\', buf)\n\n\nclass PipelineRunner(object):\n    """"""Provides an easy way to run a pre-constructed Gstreamer pipeline much\n    like gst-launch""""""\n    def __init__(self, pipeline, stop_pos=None):\n        self.mainloop = GObject.MainLoop()\n        self.err, self.dbg = None, None\n\n        def on_error(_bus, message):\n            self.err, self.dbg = message.parse_error()\n            self.mainloop.quit()\n\n        def on_warning(_bus, message):\n            assert message.type == Gst.MessageType.WARNING\n            _err, _dbg = message.parse_warning()\n            sys.stderr.write(""Warning: %s: %s\\n%s\\n"" % (_err, _err.message,\n                             _dbg))\n\n        def on_eos(_bus, _message):\n            pipeline.set_state(Gst.State.NULL)\n            self.mainloop.quit()\n\n        bus = pipeline.get_bus()\n        bus.connect(""message::eos"", on_eos)\n        bus.connect(""message::error"", on_error)\n        bus.connect(""message::warning"", on_warning)\n        bus.add_signal_watch()\n\n        pipeline.set_state(Gst.State.PAUSED)\n\n        if stop_pos is not None:\n            pipeline.seek(\n                1.0, Gst.Format.TIME, Gst.SeekFlags.SEGMENT |\n                Gst.SeekFlags.FLUSH | Gst.SeekFlags.ACCURATE, Gst.SeekType.SET,\n                0, Gst.SeekType.SET, stop_pos)\n\n        pipeline.set_state(Gst.State.PLAYING)\n        self.pipeline = pipeline\n\n    def run(self):\n        self.mainloop.run()\n        if self.err is not None:\n            raise RuntimeError(""Error running pipeline: %s\\n\\n%s"" %\n                               (self.err, self.dbg))\n\n    def __del__(self):\n        self.pipeline.set_state(Gst.State.NULL)\n        self.pipeline.get_state(0)\n'"
_stbt/imgproc_cache.py,0,"b'""""""\nThis file implements caching of expensive image processing operations for the\npurposes of speeding up subsequent runs of stbt auto-selftest.\n\nTo enable caching, decorate the cachable function with `imgproc_cache.memoize`\nand call the function within the scope of a `with imgproc_cache.cache():`\ncontext manager. For now this is a private API but we intend to make it public\nat some point so that users can add caching to any custom image-processing\nfunctions in their test-packs.\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport functools\nimport inspect\nimport itertools\nimport json\nimport os\nimport sys\nfrom contextlib import contextmanager\nfrom distutils.version import LooseVersion\n\nimport numpy\n\ntry:\n    import lmdb\nexcept ImportError:\n    lmdb = None\n\nfrom _stbt.logging import ImageLogger\nfrom _stbt.utils import mkdir_p, named_temporary_directory, scoped_curdir\n\ntry:\n    from itertools import zip_longest\nexcept ImportError:\n    # Python 2:\n    from itertools import izip_longest as zip_longest\n\n\nMAX_CACHE_SIZE_BYTES = 1024 * 1024 * 1024  # 1GiB\n_cache = None\n_cache_full_warning = None\n\n\n@contextmanager\ndef cache(filename=None):\n    if lmdb is None or os.environ.get(\'STBT_DISABLE_CACHING\'):\n        yield\n        return\n\n    global _cache\n    global _cache_full_warning\n\n    if filename is None:\n        cache_home = os.environ.get(\'XDG_CACHE_HOME\') \\\n            or \'%s/.cache\' % os.environ[\'HOME\']\n        mkdir_p(cache_home + ""/stbt"")\n        filename = cache_home + ""/stbt/cache.lmdb""\n    with lmdb.open(filename, map_size=MAX_CACHE_SIZE_BYTES) as db:  # pylint: disable=no-member\n        assert _cache is None\n        try:\n            _cache = db\n            _cache_full_warning = False\n            yield\n        finally:\n            _cache = None\n\n\ndef memoize(additional_fields=None):\n    """"""\n    A decorator to say that the results of a function should be cached.  This is\n    used to short circuit expensive image processing functions like OCR.\n\n    A hash is taken of all the decorated functions arguments and any additional\n    fields specified to the decorator.  This is used as a key to retrieve a\n    previously calculated result from a database on disk.\n\n    **Constraints**\n\n    * The decorated function\'s arguments must be simple JSON serialisable\n      values or an image in the form of a numpy.ndarray.\n    * The return value from the function must be JSON serialisable and should\n      be round-trippable via JSON. This means that unicode objects should be\n      returned rather than string objects.\n    * For the sake of speed we use a non-cryptographic hash function.  This\n      means someone could deliberately cause a hash-collision by carefully\n      constructing arguments to your function.  Don\'t use memoize on functions\n      where this could be a problem.\n    * The input arguments are not stored on disk, just the hash is.  This means\n      that the (in-memory) size of the input arguments will not have an effect\n      on the disk usage and caching can be used on functions that take large\n      amounts of data (such as video frames).\n    * The full result of calling the function is stored on disk, so the (in\n      memory) size of the result have an impact on disk usage. It\'s best not to\n      memoize functions that return large amounts of data like video frames or\n      intermediate frames in some video-processing chain.\n    * This means that memoize works best on functions that take large amounts of\n      data (like frames of video) and boil it down to a small amount of data\n      (like a MatchResult or OCR text).\n\n    This function is not a part of the stbt public API and may change without\n    warning in future releases.  We hope to stabilise it in the future so users\n    can use it with their custom image-processing functions.\n    """"""\n    def decorator(f):\n        func_key = json.dumps([f.__name__, additional_fields],\n                              sort_keys=True)\n\n        @functools.wraps(f)\n        def inner(*args, **kwargs):\n            try:\n                if _cache is None:\n                    raise NotCachable()\n                full_kwargs = inspect.getcallargs(f, *args, **kwargs)  # pylint:disable=deprecated-method\n                key = _cache_hash((func_key, full_kwargs))\n            except NotCachable:\n                return f(*args, **kwargs)\n\n            with _cache.begin() as txn:\n                out = txn.get(key)\n            if out is not None:\n                return json.loads(out)\n            output = f(**full_kwargs)\n            _cache_put(key, output)\n            return output\n\n        return inner\n    return decorator\n\n\ndef memoize_iterator(additional_fields=None):\n    """"""\n    A decorator like `imgproc_cache.memoize`, but for functions that return an\n    iterator.\n    """"""\n\n    def decorator(f):\n        func_key = json.dumps([f.__name__, additional_fields],\n                              sort_keys=True)\n\n        @functools.wraps(f)\n        def inner(*args, **kwargs):\n            try:\n                if _cache is None:\n                    raise NotCachable()\n                full_kwargs = inspect.getcallargs(f, *args, **kwargs)  # pylint:disable=deprecated-method\n                key = _cache_hash((func_key, full_kwargs))\n            except NotCachable:\n                for x in f(*args, **kwargs):\n                    yield x\n                return\n\n            for i in itertools.count():\n                with _cache.begin() as txn:\n                    out = txn.get(key + str(i).encode())\n                if out is None:\n                    break\n                out_, stop_ = json.loads(out)\n                if stop_:\n                    return\n                yield out_\n\n            skip = i  # pylint:disable=undefined-loop-variable\n            it = f(**full_kwargs)\n            for i in itertools.count():\n                try:\n                    output = next(it)\n                    if i >= skip:\n                        _cache_put(key + str(i).encode(), [output, None])\n                        yield output\n                except StopIteration:\n                    _cache_put(key + str(i).encode(), [None, ""StopIteration""])\n                    raise\n\n        return inner\n    return decorator\n\n\ndef _cache_put(key, value):\n    with _cache.begin(write=True) as txn:\n        try:\n            txn.put(key, json.dumps(value).encode(""utf-8""))\n        except lmdb.MapFullError:  # pylint: disable=no-member\n            global _cache_full_warning\n            if not _cache_full_warning:\n                sys.stderr.write(\n                    ""Image processing cache is full.  This will ""\n                    ""cause degraded performance.  Consider ""\n                    ""deleting the cache file (%s) to purge old ""\n                    ""results\\n"" % _cache.path())\n                _cache_full_warning = True\n\n\nclass NotCachable(Exception):\n    pass\n\n\nclass _ArgsEncoder(json.JSONEncoder):\n    def default(self, o):  # pylint:disable=method-hidden\n        from _stbt.match import MatchParameters\n        if isinstance(o, ImageLogger):\n            if o.enabled:\n                raise NotCachable()\n            return None\n        elif isinstance(o, LooseVersion):\n            return str(o)\n        elif isinstance(o, set):\n            return sorted(o)\n        elif isinstance(o, MatchParameters):\n            return {\n                ""match_method"": o.match_method.value,\n                ""match_threshold"": o.match_threshold,\n                ""confirm_method"": o.confirm_method.value,\n                ""confirm_threshold"": o.confirm_threshold,\n                ""erode_passes"": o.erode_passes}\n        elif isinstance(o, numpy.ndarray):\n            from _stbt.xxhash import Xxhash64\n            h = Xxhash64()\n            h.update(numpy.ascontiguousarray(o).data)\n            return (o.shape, h.hexdigest())\n        else:\n            json.JSONEncoder.default(self, o)\n\n\ndef _cache_hash(value):\n    # type: (...) -> bytes\n    from _stbt.xxhash import Xxhash64\n    h = Xxhash64()\n\n    class HashWriter(object):\n        def write(self, data):\n            if isinstance(data, str):\n                data = data.encode(""utf-8"")\n            h.update(data)\n            return len(data)\n\n    json.dump(value, HashWriter(), cls=_ArgsEncoder, sort_keys=True)\n    return h.digest()\n\n\ndef test_that_cache_is_disabled_when_debug_match():\n    # debug logging is a side effect that the cache cannot reproduce\n    import stbt\n    import _stbt.logging\n    with scoped_curdir() as srcdir, cache(\'cache.lmdb\'):\n        stbt.match(srcdir + \'/tests/red-black.png\',\n                   frame=numpy.zeros((720, 1280, 3), dtype=numpy.uint8))\n        assert not os.path.exists(\'stbt-debug\')\n\n        with _stbt.logging.scoped_debug_level(2):\n            stbt.match(srcdir + \'/tests/red-black.png\',\n                       frame=numpy.zeros((720, 1280, 3), dtype=numpy.uint8))\n        assert os.path.exists(\'stbt-debug\')\n\n\ndef _fields_eq(a, b, fields):\n    for x in fields:\n        assert type(getattr(a, x)) == type(getattr(b, x))  # pylint:disable=unidiomatic-typecheck\n        if isinstance(getattr(a, x), numpy.ndarray):\n            assert (getattr(a, x) == getattr(b, x)).all()\n        else:\n            assert getattr(a, x) == getattr(b, x)\n\n\ndef _check_cache_behaviour(func):\n    from timeit import Timer\n\n    timer = Timer(func)\n    uncached_result = func()\n    uncached_time = min(timer.repeat(10, number=1))\n\n    with named_temporary_directory() as tmpdir, cache(tmpdir):\n        # Prime the cache\n        func()\n        cached_time = min(timer.repeat(10, number=1))\n        cached_result = func()\n\n    print(""%s with cache: %s"" % (func.__name__, cached_time))\n    print(""%s without cache: %s"" % (func.__name__, uncached_time))\n\n    return cached_time, uncached_time, cached_result, uncached_result\n\n\ndef test_memoize_iterator():\n    counter = [0]\n\n    @memoize_iterator()\n    def cached_function(_arg):\n        for x in range(10):\n            counter[0] += 1\n            yield x\n\n    with named_temporary_directory() as tmpdir, cache(tmpdir):\n        uncached = list(itertools.islice(cached_function(1), 5))\n        assert uncached == list(range(5))\n        assert counter[0] == 5\n\n        cached = list(itertools.islice(cached_function(1), 5))\n        assert cached == list(range(5))\n        assert counter[0] == 5\n\n        partially_cached = list(itertools.islice(cached_function(1), 10))\n        assert partially_cached == list(range(10))\n        assert counter[0] == 15\n\n        partially_cached = list(cached_function(1))\n        assert partially_cached == list(range(10))\n        assert counter[0] == 25\n\n        cached = list(cached_function(1))\n        assert cached == list(range(10))\n        assert counter[0] == 25\n\n        uncached = list(cached_function(2))\n        assert uncached == list(range(10))\n        assert counter[0] == 35\n\n\ndef test_memoize_iterator_on_empty_iterator():\n    counter = [0]\n\n    @memoize_iterator()\n    def cached_function():\n        counter[0] += 1\n        if False:  # pylint:disable=using-constant-test\n            yield\n\n    with named_temporary_directory() as tmpdir, cache(tmpdir):\n        uncached = list(cached_function())\n        assert uncached == []\n        assert counter[0] == 1\n\n        cached = list(cached_function())\n        assert cached == []\n        assert counter[0] == 1\n\n\ndef test_that_cache_speeds_up_match():\n    import stbt\n    black = numpy.zeros((1440, 2560, 3), dtype=numpy.uint8)\n\n    def match():\n        return stbt.match(\'tests/red-black.png\', frame=black)\n\n    cached_time, uncached_time, cached_result, uncached_result = (\n        _check_cache_behaviour(match))\n\n    assert uncached_time > (cached_time * 4)\n    _fields_eq(cached_result, uncached_result,\n               [\'match\', \'region\', \'first_pass_result\', \'frame\', \'image\'])\n\n\ndef test_that_cache_speeds_up_match_all():\n    import stbt\n    import cv2\n\n    frame = cv2.imread(\'tests/buttons.png\')\n\n    def match_all():\n        return list(stbt.match_all(\'tests/button.png\', frame=frame))\n\n    cached_time, uncached_time, cached_result, uncached_result = (\n        _check_cache_behaviour(match_all))\n\n    assert uncached_time > (cached_time * 2)\n    assert len(uncached_result) == 6\n    for cached, uncached in zip_longest(cached_result, uncached_result):\n        _fields_eq(cached, uncached,\n                   [\'match\', \'region\', \'first_pass_result\', \'frame\', \'image\'])\n\n\ndef test_that_cache_speeds_up_ocr():\n    import stbt\n    import cv2\n\n    frame = cv2.imread(\'tests/red-black.png\')\n\n    def ocr():\n        return stbt.ocr(frame=frame)\n\n    cached_time, uncached_time, cached_result, uncached_result = (\n        _check_cache_behaviour(ocr))\n\n    assert uncached_time > (cached_time * 10)\n    assert type(cached_result) == type(uncached_result)  # pylint:disable=unidiomatic-typecheck\n\n    assert cached_result == uncached_result\n\n\ndef test_that_cache_speeds_up_match_text():\n    import stbt\n    import cv2\n\n    frame = cv2.imread(\'tests/red-black.png\')\n\n    def match_text():\n        return stbt.match_text(""RED"", frame=frame)\n\n    cached_time, uncached_time, cached_result, uncached_result = (\n        _check_cache_behaviour(match_text))\n\n    assert uncached_time > (cached_time * 10)\n\n    print(cached_result)\n\n    _fields_eq(cached_result, uncached_result,\n               [\'match\', \'region\', \'frame\', \'text\'])\n'"
_stbt/imgutils.py,0,"b'# coding: utf-8\n\nfrom __future__ import division\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport inspect\nimport os\nfrom collections import namedtuple\n\nimport cv2\nimport numpy\n\nfrom .logging import ddebug, debug, warn\nfrom .types import Region\nfrom .utils import to_native_str, to_unicode\n\n\nclass Frame(numpy.ndarray):\n    """"""A frame of video.\n\n    A ``Frame`` is what you get from `stbt.get_frame` and `stbt.frames`. It is\n    a subclass of `numpy.ndarray`, which is the type that OpenCV uses to\n    represent images. Data is stored in 8-bit, 3 channel BGR format.\n\n    In addition to the members inherited from `numpy.ndarray`, ``Frame``\n    defines the following attributes:\n\n    :ivar float time: The wall-clock time when this video-frame was captured,\n        as number of seconds since the unix epoch (1970-01-01T00:00:00Z). This\n        is the same format used by the Python standard library function\n        `time.time`.\n    """"""\n    def __new__(cls, array, dtype=None, order=None, time=None, _draw_sink=None):\n        obj = numpy.asarray(array, dtype=dtype, order=order).view(cls)\n        obj.time = time\n        obj._draw_sink = _draw_sink  # pylint: disable=protected-access\n        return obj\n\n    def __array_finalize__(self, obj):\n        if obj is None:\n            return\n        self.time = getattr(obj, \'time\', None)  # pylint: disable=attribute-defined-outside-init\n        self._draw_sink = getattr(obj, \'_draw_sink\', None)  # pylint: disable=attribute-defined-outside-init\n\n    def __repr__(self):\n        if len(self.shape) == 3:\n            dimensions = ""%dx%dx%d"" % (\n                self.shape[1], self.shape[0], self.shape[2])\n        else:\n            dimensions = ""%dx%d"" % (self.shape[1], self.shape[0])\n        return ""<stbt.Frame(time=%s, dimensions=%s)>"" % (\n            ""None"" if self.time is None else ""%.3f"" % self.time,\n            dimensions)\n\n\ndef _frame_repr(frame):\n    if frame is None:\n        return ""None""\n    if isinstance(frame, Frame):\n        return repr(frame)\n    if len(frame.shape) == 3:\n        return ""<%dx%dx%d>"" % (frame.shape[1], frame.shape[0], frame.shape[2])\n    else:\n        return ""<%dx%d>"" % (frame.shape[1], frame.shape[0])\n\n\ndef crop(frame, region):\n    """"""Returns an image containing the specified region of ``frame``.\n\n    :type frame: `stbt.Frame` or `numpy.ndarray`\n    :param frame: An image in OpenCV format (for example as returned by\n      `frames`, `get_frame` and `load_image`, or the ``frame`` parameter of\n      `MatchResult`).\n\n    :type Region region: The region to crop.\n\n    :returns: An OpenCV image (`numpy.ndarray`) containing the specified region\n      of the source frame. This is a view onto the original data, so if you\n      want to modify the cropped image call its ``copy()`` method first.\n    """"""\n    if not _image_region(frame).contains(region):\n        raise ValueError(""frame with dimensions %r doesn\'t contain %r""\n                         % (frame.shape, region))\n    return frame[region.y:region.bottom, region.x:region.right]\n\n\ndef _image_region(image):\n    s = image.shape\n    return Region(0, 0, s[1], s[0])\n\n\ndef load_image(filename, flags=None):\n    """"""Find & read an image from disk.\n\n    If given a relative filename, this will search in the directory of the\n    Python file that called ``load_image``, then in the directory of that\n    file\'s caller, etc. This allows you to use ``load_image`` in a helper\n    function, and then call that helper function from a different Python file\n    passing in a filename relative to the caller.\n\n    Finally this will search in the current working directory. This allows\n    loading an image that you had previously saved to disk during the same\n    test run.\n\n    This is the same lookup algorithm used by `stbt.match` and similar\n    functions.\n\n    :param str filename: A relative or absolute filename.\n\n    :param flags: Flags to pass to :ocv:pyfunc:`cv2.imread`.\n\n    :returns: An image in OpenCV format \xe2\x80\x94 that is, a `numpy.ndarray` of 8-bit\n        values. With the default ``flags`` parameter this will be 3 channels\n        BGR, or 4 channels BGRA if the file has transparent pixels.\n    :raises: `IOError` if the specified path doesn\'t exist or isn\'t a valid\n        image file.\n\n    * Changed in v30: Include alpha (transparency) channel if the file has\n      transparent pixels.\n    * Changed in v32: Allows passing an image (`numpy.ndarray`) in which case\n      this function is a no-op.\n    """"""\n\n    if isinstance(filename, numpy.ndarray):\n        return filename\n    absolute_filename = find_user_file(filename)\n    if not absolute_filename:\n        raise IOError(to_native_str(""No such file: %s"" % to_unicode(filename)))\n    image = imread(absolute_filename, flags)\n    if image is None:\n        raise IOError(to_native_str(""Failed to load image: %s"" %\n                                    to_unicode(absolute_filename)))\n    return image\n\n\ndef save_frame(image, filename):\n    """"""Saves an OpenCV image to the specified file.\n\n    Takes an image obtained from `get_frame` or from the `screenshot`\n    property of `MatchTimeout` or `MotionTimeout`.\n    """"""\n    cv2.imwrite(filename, image)\n\n\nclass _ImageFromUser(namedtuple(\n        \'_ImageFromUser\',\n        \'image relative_filename absolute_filename\')):\n\n    @property\n    def friendly_name(self):\n        if self.image is None:\n            return None\n        return self.relative_filename or \'<Custom Image>\'\n\n    def short_repr(self):\n        if self.image is None:\n            return ""None""\n        if self.relative_filename:\n            return repr(os.path.basename(self.relative_filename))\n        return ""<Custom Image>""\n\n\ndef _load_image(image, flags=None):\n    if isinstance(image, _ImageFromUser):\n        return image\n    if isinstance(image, numpy.ndarray):\n        return _ImageFromUser(image, None, None)\n    else:\n        relative_filename = image\n        absolute_filename = find_user_file(relative_filename)\n        if not absolute_filename:\n            raise IOError(""No such file: %s"" % relative_filename)\n        numpy_image = imread(absolute_filename, flags)\n        if numpy_image is None:\n            raise IOError(""Failed to load image: %s"" %\n                          absolute_filename)\n        return _ImageFromUser(numpy_image, relative_filename, absolute_filename)\n\n\ndef imread(filename, flags=None):\n    if flags is None:\n        cv2_flags = cv2.IMREAD_UNCHANGED\n    else:\n        cv2_flags = flags\n\n    img = cv2.imread(to_native_str(filename), cv2_flags)\n    if img is None:\n        return None\n\n    if img.dtype == numpy.uint16:\n        warn(""Image %s has 16 bits per channel. Converting to 8 bits.""\n             % filename)\n        img = cv2.convertScaleAbs(img, alpha=1.0 / 256)\n    elif img.dtype != numpy.uint8:\n        raise ValueError(""Image %s must be 8-bits per channel (got %s)""\n                         % (filename, img.dtype))\n\n    if flags is None:\n        # We want: 3 colours, 8 bits per channel, alpha channel if present.\n        # This differs from cv2.imread\'s default mode:\n        #\n        #                                     Alpha channel?   Converts from\n        # Mode                                (if present)     grayscale to BGR?\n        # ----------------------------------------------------------------------\n        # IMREAD_COLOR (cv2.imread default)   No               Yes\n        # IMREAD_UNCHANGED                    Yes              No\n        # Our default                         Yes              Yes\n        # ----------------------------------------------------------------------\n\n        if len(img.shape) == 2 or img.shape[2] == 1:\n            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n\n        # Remove alpha channel if it\'s 100% opaque\n        if img.shape[2] == 4 and numpy.all(img[:, :, 3] == 255):\n            img = img[:, :, :3]\n\n    return img\n\n\ndef pixel_bounding_box(img):\n    """"""\n    Find the smallest region that contains all the non-zero pixels in an image.\n\n    >>> pixel_bounding_box(numpy.array([[0]], dtype=numpy.uint8))\n    >>> pixel_bounding_box(numpy.array([[1]], dtype=numpy.uint8))\n    Region(x=0, y=0, right=1, bottom=1)\n    >>> a = numpy.array([\n    ...     [0, 0, 0, 0],\n    ...     [0, 1, 1, 1],\n    ...     [0, 1, 1, 1],\n    ...     [0, 0, 0, 0],\n    ... ], dtype=numpy.uint8)\n    >>> pixel_bounding_box(a)\n    Region(x=1, y=1, right=4, bottom=3)\n    >>> pixel_bounding_box(numpy.stack([\n    ...     numpy.zeros((4, 4), dtype=numpy.uint8),\n    ...     numpy.zeros((4, 4), dtype=numpy.uint8),\n    ...     a],\n    ...     axis=-1))\n    Region(x=1, y=1, right=4, bottom=3)\n    >>> pixel_bounding_box(numpy.array([\n    ...     [0, 0, 0, 0, 0, 0],\n    ...     [0, 0, 0, 1, 0, 0],\n    ...     [0, 1, 0, 0, 0, 0],\n    ...     [0, 0, 0, 0, 1, 0],\n    ...     [0, 0, 0, 0, 0, 0],\n    ...     [0, 0, 1, 0, 0, 0],\n    ...     [0, 0, 0, 0, 0, 0]\n    ... ], dtype=numpy.uint8))\n    Region(x=1, y=1, right=5, bottom=6)\n    """"""\n    if len(img.shape) == 2:\n        pass\n    elif len(img.shape) == 3 and img.shape[2] == 3:\n        img = img.max(axis=2)\n    else:\n        raise ValueError(""Single-channel or 3-channel (BGR) image required. ""\n                         ""Provided image has shape %r"" % (img.shape,))\n\n    out = [None, None, None, None]\n\n    for axis in (0, 1):\n        flat = numpy.any(img, axis=axis)\n        indices = numpy.where(flat)[0]\n        if len(indices) == 0:\n            return None\n        out[axis] = indices[0]\n        out[axis + 2] = indices[-1] + 1\n\n    return Region.from_extents(*out)\n\n\ndef find_user_file(filename):\n    """"""Searches for the given filename and returns the full path.\n\n    Searches in the directory of the script that called `load_image` (or\n    `match`, etc), then in the directory of that script\'s caller, etc.\n    Falls back to searching the current working directory.\n\n    :returns: Absolute filename, or None if it can\'t find the file.\n    """"""\n    if os.path.isabs(filename) and os.path.isfile(filename):\n        return filename\n\n    # Start searching from the first parent stack-frame that is outside of\n    # the _stbt installation directory (this file\'s directory). We can ignore\n    # the first 2 stack-frames:\n    #\n    # * stack()[0] is _find_user_file;\n    # * stack()[1] is _find_user_file\'s caller: load_image or _load_image;\n    # * stack()[2] is load_image\'s caller (the user script). It could also be\n    #   _load_image\'s caller (e.g. `match`) so we still need to check until\n    #   we\'re outside of the _stbt directory.\n\n    filename = to_native_str(filename)\n    _stbt_dir = os.path.abspath(os.path.dirname(__file__))\n    caller = inspect.currentframe()\n    try:\n        # Skip this frame and the parent:\n        caller = caller.f_back\n        caller = caller.f_back\n        while caller:\n            caller_dir = os.path.abspath(\n                os.path.dirname(inspect.getframeinfo(caller).filename))\n            if not caller_dir.startswith(_stbt_dir):\n                caller_path = os.path.join(caller_dir, filename)\n                if os.path.isfile(caller_path):\n                    ddebug(""Resolved relative path %r to %r"" % (\n                        filename, caller_path))\n                    return caller_path\n            caller = caller.f_back\n    finally:\n        # Avoid circular references between stack frame objects and themselves\n        # for more deterministic GC.  See\n        # https://docs.python.org/3.6/library/inspect.html#the-interpreter-stack\n        # for more information.\n        del caller\n\n    # Fall back to image from cwd, to allow loading an image saved previously\n    # during the same test-run.\n    if os.path.isfile(filename):\n        abspath = os.path.abspath(filename)\n        ddebug(""Resolved relative path %r to %r"" % (filename, abspath))\n        return abspath\n\n    return None\n\n\ndef limit_time(frames, duration_secs):\n    """"""\n    Adapts a frame iterator such that it will return EOS after `duration_secs`\n    worth of video has been read.\n    """"""\n    import time\n    end_time = time.time() + duration_secs\n    for frame in frames:\n        if frame.time > end_time:\n            debug(""timed out: %.3f > %.3f"" % (frame.time, end_time))\n            break\n        else:\n            yield frame\n'"
_stbt/irnetbox.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""Python module to control the RedRat irNetBox infrared emitter.\n\nAuthor: David Rothlisberger <david@rothlis.net>\nCopyright 2012 YouView TV Ltd and contributors.\nLicense: LGPL v2.1 or (at your option) any later version (see\nhttps://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n\nThe irNetBox is a network-controlled infrared emitter:\nhttp://www.redrat.co.uk/products/irnetbox.html\n\nThis module only supports versions II and III of the irNetBox hardware.\n\n""\xc2\xa7"" section numbers in the function docstrings are from ""The irNetBox\nNetwork Control Protocol"":\nhttp://www.redrat.co.uk/products/IRNetBox_Comms-V3.0.pdf\n\nThanks to Chris Dodge at RedRat for friendly and prompt answers to all my\nquestions, and to Emmett Kelly for the mk-II implementation.\n\nClasses:\n\nIRNetBox\n  An instance of IRNetBox holds a TCP connection to the device.\n\n  Note that the device only accepts one TCP connection at a time, so keep this\n  as short-lived as possible. For example::\n\n    with irnetbox.IRNetBox(""192.168.0.10"") as ir:\n        ir.power_on()\n        ir.irsend_raw(port=1, power=100, data=binascii.unhexlify(""000174F...""))\n\n  Or run \'./irnetbox-proxy\', which accepts multiple connections and forwards\n  requests on to a real irNetBox.\n\nRemoteControlConfig\n  Holds infrared signal data from a config file produced by RedRat\'s ""IR Signal\n  Database Utility"". Example usage (where ""POWER"" is a signal defined in the\n  config file)::\n\n    rcu = irnetbox.RemoteControlConfig(""my-rcu.irnetbox.config"")\n    ir.irsend_raw(port=1, power=100, data=rcu[""POWER""])\n\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport binascii\nimport errno\nimport random\nimport re\nimport socket\nimport struct\nimport sys\nimport time\n\n\nclass IRNetBox(object):\n    def __init__(self, hostname, port=10001):  # \xc2\xa75\n        for i in range(6):\n            try:\n                self._socket = socket.socket()\n                self._socket.settimeout(10)\n                self._socket.connect((hostname, port))\n                break\n            except socket.error as e:\n                if e.errno == errno.ECONNREFUSED and i < 5:\n                    delay = 0.1 * (2 ** i)\n                    sys.stderr.write(\n                        ""Connection to irNetBox \'%s:%d\' refused; ""\n                        ""retrying in %.2fs.\\n"" %\n                        (hostname, port, delay))\n                    time.sleep(delay)\n                else:\n                    raise\n        self._responses = _read_responses(self._socket)\n        self.irnetbox_model = 0\n        self.ports = 16\n        self._get_version()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, ex_type, ex_value, ex_traceback):\n        self._socket.close()\n\n    def power_on(self):\n        """"""Power on the irNetBox device (\xc2\xa75.2.3).\n\n        \xc2\xa75.2.3 calls this ""power to the CPLD device""; the irNetBox-III doesn\'t\n        have a CPLD, but according to Chris Dodge @ RedRat, this is now ""power\n        on the whole irNetBox"".\n\n        """"""\n        self._send(MessageTypes.POWER_ON)\n\n    def power_off(self):\n        """"""Put the irNetBox in low-power standby mode (\xc2\xa75.2.3).\n\n        In low power mode the LEDs on the front will be doing the Cylon\n        pattern.\n\n        """"""\n        self._send(MessageTypes.POWER_OFF)\n\n    def reset(self):\n        """"""Reset the CPLD""""""\n        self._send(\n            MessageTypes.CPLD_INSTRUCTION,\n            struct.pack(""B"", 0x00))\n\n    def indicators_on(self):\n        """"""Enable LED indicators on the front panel (\xc2\xa75.2.4).""""""\n        self._send(\n            MessageTypes.CPLD_INSTRUCTION,\n            struct.pack(""B"", 0x17))\n\n    def indicators_off(self):\n        """"""Disable LED indicators on the front panel (\xc2\xa75.2.4).""""""\n        self._send(\n            MessageTypes.CPLD_INSTRUCTION,\n            struct.pack(""B"", 0x18))\n\n    def irsend_raw(self, port, power, data):\n        """"""Output the IR data on the given port at the set power (\xc2\xa76.1.1).\n\n        * `port` is a number between 1 and 16 (or 1 and 4 for RedRat X).\n        * `power` is a number between 1 and 100.\n        * `data` is a byte array as exported by the RedRat Signal DB Utility.\n\n        """"""\n        if self.irnetbox_model == NetBoxTypes.MK1:\n            raise Exception(""IRNetBox MK1 not supported"")\n        elif self.irnetbox_model == NetBoxTypes.MK2:\n            self.reset()\n            self.indicators_on()\n            self._send(MessageTypes.SET_MEMORY)\n            self._send(MessageTypes.CPLD_INSTRUCTION, struct.pack(""B"", 0x00))\n            if power < 33:\n                self._send(\n                    MessageTypes.CPLD_INSTRUCTION,\n                    struct.pack(""B"", port + 1))\n            elif power < 66:\n                self._send(\n                    MessageTypes.CPLD_INSTRUCTION,\n                    struct.pack(""B"", port + 31))\n            else:\n                self._send(\n                    MessageTypes.CPLD_INSTRUCTION,\n                    struct.pack(""B"", port + 1))\n                self._send(\n                    MessageTypes.CPLD_INSTRUCTION,\n                    struct.pack(""B"", port + 31))\n            self._send(MessageTypes.DOWNLOAD_SIGNAL, data)\n            self._send(MessageTypes.OUTPUT_IR_SIGNAL)\n            self.reset()\n        else:\n            ports = [0] * self.ports\n            ports[port - 1] = power\n            sequence_number = random.randint(0, (2 ** 16) - 1)\n            delay = 0  # use the default delay of 100ms\n            self._send(\n                MessageTypes.OUTPUT_IR_ASYNC,\n                struct.pack(\n                    "">HH{0}s{1}s"".format(self.ports, len(data)),\n                    sequence_number,\n                    delay,\n                    struct.pack(""{}B"".format(self.ports), *ports),\n                    data))\n\n    def _send(self, message_type, message_data=b""""):\n        self._socket.sendall(_message(message_type, message_data))\n        response_type, response_data = next(self._responses)\n        if response_type == MessageTypes.ERROR:\n            raise Exception(""IRNetBox returned ERROR"")\n        if response_type != message_type:\n            raise Exception(\n                ""IRNetBox returned unexpected response type %d to request %d"" %\n                (response_type, message_type))\n        if response_type == MessageTypes.OUTPUT_IR_ASYNC:\n            sequence_number, error_code, ack = struct.unpack(\n                # Sequence number in the ACK message is defined as big-endian\n                # in \xc2\xa75.1 and \xc2\xa76.1.2, but due to a known bug it is\n                # little-endian.\n                \'<HBB\', response_data)\n            if ack == 1:\n                async_type, async_data = next(self._responses)\n                if async_type != MessageTypes.IR_ASYNC_COMPLETE:\n                    raise Exception(\n                        ""IRNetBox returned unexpected message %d"" % async_type)\n                (async_sequence_number,) = struct.unpack("">H"", async_data[:2])\n                if async_sequence_number != sequence_number:\n                    raise Exception(\n                        ""IRNetBox returned message IR_ASYNC_COMPLETE ""\n                        ""with unexpected sequence number %d (expected %d)"" %\n                        (async_sequence_number, sequence_number))\n            else:\n                raise Exception(\n                    ""IRNetBox returned NACK (error code: %d)"" % error_code)\n        if response_type == MessageTypes.DEVICE_VERSION:\n            self.irnetbox_model, = struct.unpack(\n                \'<H\', response_data[10:12])  # == \xc2\xa75.2.6\'s payload_data[8:10]\n\n    def _get_version(self):\n        self._send(MessageTypes.DEVICE_VERSION)\n        self.ports = 4 if self.irnetbox_model == NetBoxTypes.RRX else 16\n\n\ndef RemoteControlConfig(filename):\n    return _parse_config(open(filename, ""rb""))\n\n\nclass MessageTypes(object):\n    """"""\xc2\xa75.2""""""\n    ERROR = 0x01\n    POWER_ON = 0x05\n    POWER_OFF = 0x06\n    CPLD_INSTRUCTION = 0x07\n    DEVICE_VERSION = 0x09\n    SET_MEMORY = 0x10\n    DOWNLOAD_SIGNAL = 0x11\n    OUTPUT_IR_SIGNAL = 0x12\n    OUTPUT_IR_ASYNC = 0x30\n    IR_ASYNC_COMPLETE = 0x31\n\n\nclass NetBoxTypes(object):\n    """"""\xc2\xa75.2.6""""""\n    MK1 = 2\n    MK2 = 7\n    MK3 = 8\n    MK4 = 12\n    RRX = 13\n\n\ndef _message(message_type, message_data):\n    # \xc2\xa75.1. Message Structure: Host to irNetBox\n    #\n    # \'#\'              byte     The \'#\' character indicates to the control\n    #                           microprocessor the start of a message.\n    # Message length   ushort   The length of the data section of this message.\n    # Message type     byte     One of the values listed below.\n    # Data             byte[]   Any data associated with this type of message.\n    #\n    # A ushort value is a 16-bit unsigned integer in big-endian format.\n    #\n    return struct.pack(\n        "">cHB%ds"" % len(message_data),\n        b""#"",\n        len(message_data),\n        message_type,\n        message_data)\n\n\ndef _read_responses(stream):\n    """"""Generator that splits stream into (type, data) tuples.""""""\n\n    # \xc2\xa75.1. Message Structure: irNetBox to Host\n    #\n    # Message length   ushort   The length of the data section of this message.\n    # Message type     byte     Contains either:\n    #                           a) The same value as the original message from\n    #                              the host, or\n    #                           b) A value (0x01) indicating ""Error"".\n    # Data             byte[]   Any data associated with this type of message.\n    #\n    buf = b""""\n    while True:\n        s = stream.recv(4096)\n        if len(s) == 0:\n            break\n        buf += s\n        while len(buf) >= 3:\n            data_len, = struct.unpack("">H"", buf[0:2])\n            if len(buf) < 3 + data_len:\n                break\n            response_type, response_data = struct.unpack(\n                "">B%ds"" % data_len,\n                buf[2:(3 + data_len)])\n            yield response_type, response_data\n            buf = buf[(3 + data_len):]\n\n\ndef _parse_config(config_file):\n    """"""Read irNetBox configuration file.\n\n    Which is produced by RedRat\'s (Windows-only) ""IR Signal Database Utility"".\n    """"""\n    d = {}\n    for line in config_file:\n        fields = re.split(b""[\\t ]+"", line.rstrip(), maxsplit=4)\n        if len(fields) == 4:\n            # (name, type, max_num_lengths, data)\n            name, type_, _, data = fields\n            if type_ == b""MOD_SIG"":\n                d[name.decode(""utf-8"")] = binascii.unhexlify(data)\n        if len(fields) == 5:\n            # ""Double signals"" where pressing the button on the remote control\n            # alternates between signal1 & signal2. We\'ll always send signal1,\n            # but that shouldn\'t matter.\n            # (name, type, signal1 or signal2, max_num_lengths, data)\n            name, type_, signal, _, data = fields\n            if type_ == b""DMOD_SIG"" and signal == b""signal1"":\n                d[name.decode(""utf-8"")] = binascii.unhexlify(data)\n    return d\n\n\n# Tests\n# ===========================================================================\n\ndef test_that_read_responses_doesnt_hang_on_incomplete_data():\n    import io\n\n    data = b""abcdefghij""\n    m = struct.pack(\n        "">HB%ds"" % len(data),\n        len(data),\n        0x01,\n        data)\n\n    assert next(_read_responses(_FileToSocket(io.BytesIO(m)))) == \\\n        (0x01, data)\n    try:\n        next(_read_responses(_FileToSocket(io.BytesIO(m[:5]))))\n    except StopIteration:\n        pass\n    else:\n        assert False  # expected StopIteration exception\n\n\ndef test_that_parse_config_understands_redrat_format():\n    import io\n\n    # pylint:disable=line-too-long\n    f = io.BytesIO(\n        re.sub(\n            b""^ +"", b"""", flags=re.MULTILINE,\n            string=b""""""Device TestRCU\n\n            Note: The data is of the form <signal name> MOD_SIG <max_num_lengths> <byte_array_in_ascii_hex>.\n\n            DOWN\tMOD_SIG\t16 000174F5FF60000000060000004802450222F704540D12116A464F0000000000000000000000000000000000000000000102020202020202020202020202020202020202020202020202030202020202020202020202030202020202020203020202030203020202030203020302020203027F0004027F\n\n            UP\tMOD_SIG\t16 000174FAFF60000000050000004803457422F7045A0D13116A00000000000000000000000000000000000000000000000102020202020202020202020202020202020202020202020202030202020202020203020202020202020202020203020202020203020302030203020302020203027F0004027F\n\n            RED\tDMOD_SIG\tsignal1\t16 0002BCAFFF5A0000000300000024010E3206E60DB1000000000000000000000000000000000000000000000000000000010101010200020002000200020101017F00010101010200020002000200020101017F\n            RED\tDMOD_SIG\tsignal2\t16 0002BCE3FF5A0000000300000020010E2C0DB006EC00000000000000000000000000000000000000000000000000000001000100010001000100010202027F0001000100010001000100010202027F\n            """"""))\n    config = _parse_config(f)\n    assert config[""DOWN""].startswith(b""\\x00\\x01\\x74\\xF5"")\n    assert config[""UP""].startswith(b""\\x00\\x01\\x74\\xFA"")\n    assert config[""RED""].startswith(b""\\x00\\x02\\xBC\\xAF"")\n\n\nclass _FileToSocket(object):\n    """"""Makes something File-like behave like a Socket for testing purposes.\n\n    >>> import io\n    >>> s = _FileToSocket(io.BytesIO(b\'Hello\'))\n    >>> s.recv(3)\n    \'Hel\'\n    >>> s.recv(3)\n    \'lo\'\n    >>> s.recv(3)\n    \'\'\n    """"""\n\n    def __init__(self, f):\n        self.file = f\n\n    def recv(self, bufsize, flags=0):  # pylint:disable=unused-argument\n        return self.file.read(bufsize)\n'"
_stbt/logging.py,0,"b'# coding: utf-8\n\nfrom __future__ import division\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport argparse\nimport itertools\nimport os\nimport sys\nfrom collections import namedtuple, OrderedDict\nfrom contextlib import contextmanager\nfrom textwrap import dedent\n\nfrom .config import get_config\nfrom .types import Region\nfrom .utils import mkdir_p\n\n_debug_level = None\n\n\ndef debug(msg):\n    """"""Print the given string to stderr if stbt run `--verbose` was given.""""""\n    if get_debug_level() > 0:\n        sys.stderr.write(\n            ""%s: %s\\n"" % (os.path.basename(sys.argv[0]), msg))\n\n\ndef ddebug(s):\n    """"""Extra verbose debug for stbt developers, not end users""""""\n    if get_debug_level() > 1:\n        sys.stderr.write(""%s: %s\\n"" % (os.path.basename(sys.argv[0]), s))\n\n\ndef warn(s):\n    sys.stderr.write(""%s: warning: %s\\n"" % (\n        os.path.basename(sys.argv[0]), s))\n\n\ndef get_debug_level():\n    global _debug_level\n    if _debug_level is None:\n        _debug_level = get_config(\'global\', \'verbose\', type_=int)\n    return _debug_level\n\n\n@contextmanager\ndef scoped_debug_level(level):\n    global _debug_level\n    oldlevel = _debug_level\n    _debug_level = level\n    try:\n        yield\n    finally:\n        _debug_level = oldlevel\n\n\ndef argparser_add_verbose_argument(argparser):\n    class IncreaseDebugLevel(argparse.Action):\n        num_calls = 0\n\n        def __call__(self, parser, namespace, values, option_string=None):\n            global _debug_level\n            self.num_calls += 1\n            _debug_level = self.num_calls\n            setattr(namespace, self.dest, _debug_level)\n\n    argparser.add_argument(\n        \'-v\', \'--verbose\', action=IncreaseDebugLevel, nargs=0,\n        default=get_debug_level(),  # for stbt-run arguments dump\n        help=\'Enable debug output (specify twice to enable GStreamer element \'\n             \'dumps to ./stbt-debug directory)\')\n\n\nclass ImageLogger(object):\n    """"""Log intermediate images used in image processing (such as `match`).\n\n    Create a new ImageLogger instance for each frame of video.\n    """"""\n    _frame_number = itertools.count(1)\n\n    def __init__(self, name, **kwargs):\n        self.jupyter = ""JPY_PARENT_PID"" in os.environ  # in a Jupyter Notebook\n        self.enabled = get_debug_level() > 1 or self.jupyter\n        if not self.enabled:\n            return\n\n        self.name = name\n        self.frame_number = next(ImageLogger._frame_number)\n\n        try:\n            outdir = os.path.join(""stbt-debug"", ""%05d"" % self.frame_number)\n            mkdir_p(outdir)\n            self.outdir = outdir\n        except OSError:\n            warn(""Failed to create directory \'%s\'; won\'t save debug images.""\n                 % outdir)\n            self.enabled = False\n            return\n\n        self.images = OrderedDict()\n        self.data = {}\n        for k, v in kwargs.items():\n            self.data[k] = v\n\n    def set(self, **kwargs):\n        if not self.enabled:\n            return\n        for k, v in kwargs.items():\n            self.data[k] = v\n\n    def append(self, **kwargs):\n        if not self.enabled:\n            return\n        for k, v in kwargs.items():\n            if k not in self.data:\n                self.data[k] = []\n            self.data[k].append(v)\n\n    def imwrite(self, name, image, regions=None, colours=None, scale=1):\n        import cv2\n        import numpy\n        if not self.enabled:\n            return\n        if image is None:\n            return\n        if name in self.images:\n            raise ValueError(""Image for name \'%s\' already logged"" % name)\n        if image is None:\n            return\n        if image.dtype == numpy.float32:\n            # Scale `cv2.matchTemplate` heatmap output in range\n            # [0.0, 1.0] to visible grayscale range [0, 255].\n            image = cv2.convertScaleAbs(image, alpha=255.0 / scale)\n        else:\n            image = image.copy()\n        self.images[name] = image\n        if regions is None:\n            regions = []\n        elif not isinstance(regions, list):\n            regions = [regions]\n        if colours is None:\n            colours = []\n        elif not isinstance(colours, list):\n            colours = [colours]\n        for region, colour in zip(regions, colours):\n            cv2.rectangle(\n                image, (region.x, region.y), (region.right, region.bottom),\n                colour, thickness=1)\n\n        cv2.imwrite(os.path.join(self.outdir, name + "".png""), image)\n\n    def html(self, template, **kwargs):\n        if not self.enabled:\n            return\n\n        try:\n            import jinja2\n        except ImportError:\n            warn(\n                ""Not generating html view of the image-processing debug images ""\n                ""because python \'jinja2\' module is not installed."")\n            return\n\n        template_kwargs = self.data.copy()\n        template_kwargs[""images""] = self.images\n        template_kwargs.update(kwargs)\n\n        index_html = os.path.join(self.outdir, ""index.html"")\n        with open(index_html, ""w"") as f:\n            f.write(jinja2.Template(_INDEX_HTML_HEADER)\n                    .render(frame_number=self.frame_number,\n                            jupyter=self.jupyter))\n            f.write(jinja2.Template(dedent(template.lstrip(""\\n"")))\n                    .render(annotated_image=self._draw_annotated_image,\n                            draw=self._draw,\n                            jupyter=self.jupyter,\n                            **template_kwargs))\n            f.write(jinja2.Template(_INDEX_HTML_FOOTER)\n                    .render())\n\n        if self.jupyter:\n            from IPython.display import display, IFrame  # pylint:disable=import-error\n            display(IFrame(src=index_html, width=974, height=600))\n\n    def _draw(self, region, source_size, css_class, title=None):\n        import jinja2\n\n        if region is None:\n            return """"\n\n        if isinstance(css_class, bool):\n            if css_class:\n                css_class = ""matched""\n            else:\n                css_class = ""nomatch""\n\n        return jinja2.Template(dedent(""""""\\\n            <div class=""region {{css_class}}""\n                 style=""left: {{region.x / image.width * 100}}%;\n                        top: {{region.y / image.height * 100}}%;\n                        width: {{region.width / image.width * 100}}%;\n                        height: {{region.height / image.height * 100}}%""\n                 {% if title %}\n                 title=""{{ title | escape }}""\n                 {% endif %}\n                 ></div>\n            """""")) \\\n            .render(css_class=css_class,\n                    image=source_size,\n                    region=region,\n                    title=title)\n\n    def _draw_annotated_image(self, regions=None, source_name=""source""):\n        import jinja2\n\n        s = self.images[source_name].shape\n        source_size = Region(0, 0, s[1], s[0])\n\n        _regions = []\n        if ""region"" in self.data:\n            _regions.append((Region.intersect(self.data[""region""], source_size),\n                             ""source_region"", None))\n\n        if isinstance(regions, Region):\n            _regions.append((regions, True, None))\n        elif hasattr(regions, ""region""):  # e.g. MotionResult\n            _regions.append((regions.region, bool(regions), None))\n        elif regions is not None:\n            for r in regions:\n                if not isinstance(r, tuple) or len(r) != 3:\n                    raise ValueError(\n                        ""_draw_annotated_image expected 3-tuple ""\n                        ""(region, css_class, title); got %r"" % r)\n                _regions.append(r)\n\n        return jinja2.Template(dedent(""""""\\\n            <div class=""annotated_image"">\n              <img src=""{{source_name}}.png"">\n              {% for region, css_class, title in regions %}\n              {{ draw(region, source_size, css_class, title) }}\n              {% endfor %}\n            </div>\n        """""")).render(\n            draw=self._draw,\n            regions=_regions,\n            source_name=source_name,\n            source_size=source_size,\n        )\n\n\n_INDEX_HTML_HEADER = dedent(u""""""\\\n    <!DOCTYPE html>\n    <html lang=\'en\'>\n    <head>\n    <meta charset=""utf-8""/>\n    <link href=""https://stb-tester.com/assets/bootstrap-3.3.2.min.css"" rel=""stylesheet"">\n    <style>\n        a.nav { margin: 10px; }\n        a.nav.pull-left { margin-left: 0; }\n        a.nav.pull-right { margin-right: 0; }\n        h5 { margin-top: 40px; }\n        .annotated_image { position: relative; display: inline-block; }\n        .annotated_image img { max-width: 100%; }\n        .region { position: absolute; }\n        .source_region { outline: 2px solid #8080ff; }\n        .region.matched { outline: 2px solid #ff0020; }\n        .region.nomatch { outline: 2px solid #ffff20; }\n\n        /* match */\n        .table th { font-weight: normal; background-color: #eee; }\n        img.thumb {\n            vertical-align: middle; max-width: 150px; max-height: 36px;\n            padding: 1px; border: 1px solid #ccc; }\n        .table td { vertical-align: middle; }\n    </style>\n    </head>\n    <body>\n    <div class=""container-fluid"">\n    {% if not jupyter %}\n    {%   if frame_number > 1 %}\n    <a href=""../{{ ""%05d"" % (frame_number - 1) }}/index.html""\n       class=""nav pull-left"">\xc2\xabprev</a>\n    {%   endif %}\n    <a href=""../{{ ""%05d"" % (frame_number + 1) }}/index.html""\n       class=""nav pull-right"">next\xc2\xbb</a>\n    {% endif %}\n    """""")\n\n_INDEX_HTML_FOOTER = dedent(u""""""\\\n\n    </div>\n    </body>\n    </html>\n"""""")\n\n\ndef test_that_debug_can_write_unicode_strings():\n    def test(level):\n        with scoped_debug_level(level):\n            warn(u\'Pr\xc3\xbcfungs Debug-Unicode\')\n            debug(u\'Pr\xc3\xbcfungs Debug-Unicode\')\n            ddebug(u\'Pr\xc3\xbcfungs Debug-Unicode\')\n    for level in [0, 1, 2]:\n        yield (test, level)\n\n\ndef draw_on(frame, *args, **kwargs):\n    draw_sink_ref = getattr(frame, \'_draw_sink\', None)\n    if not draw_sink_ref:\n        return\n    draw_sink = draw_sink_ref()\n    if not draw_sink:\n        return\n    draw_sink.draw(*args, **kwargs)\n\n\nclass _Annotation(namedtuple(""_Annotation"", ""time region label colour"")):\n    MATCHED = (32, 0, 255)  # Red\n    NO_MATCH = (32, 255, 255)  # Yellow\n\n    @staticmethod\n    def from_result(result, label=""""):\n        colour = _Annotation.MATCHED if result else _Annotation.NO_MATCH\n        return _Annotation(result.time, result.region, label, colour)\n'"
_stbt/match.py,0,"b'# coding: utf-8\n\n""""""\nCopyright 2012-2014 YouView TV Ltd and contributors.\nCopyright 2013-2018 stb-tester.com Ltd.\n\nLicense: LGPL v2.1 or (at your option) any later version (see\nhttps://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n""""""\nfrom __future__ import division\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport enum\nimport itertools\nfrom collections import namedtuple\n\nimport cv2\nimport numpy\n\nfrom . import cv2_compat\nfrom .config import ConfigurationError, get_config\nfrom .imgproc_cache import memoize_iterator\nfrom .imgutils import _frame_repr, _image_region, _load_image, crop, limit_time\nfrom .logging import (_Annotation, ddebug, debug, draw_on, get_debug_level,\n                      ImageLogger)\nfrom .types import Position, Region, UITestFailure\nfrom .utils import native_str\n\ntry:\n    from .sqdiff import sqdiff\nexcept ImportError:\n    sqdiff = None\n\n\nclass MatchMethod(enum.Enum):\n    SQDIFF = ""sqdiff""\n    SQDIFF_NORMED = ""sqdiff-normed""\n    CCORR_NORMED = ""ccorr-normed""\n    CCOEFF_NORMED = ""ccoeff-normed""\n\n    # For nicer formatting in generated API documentation:\n    def __repr__(self):\n        return native_str(self)\n\n\nclass ConfirmMethod(enum.Enum):\n    NONE = ""none""\n    ABSDIFF = ""absdiff""\n    NORMED_ABSDIFF = ""normed-absdiff""\n\n    # For nicer formatting in generated API documentation:\n    def __repr__(self):\n        return native_str(self)\n\n\nclass MatchParameters(object):\n    """"""Parameters to customise the image processing algorithm used by\n    `match`, `wait_for_match`, and `press_until_match`.\n\n    You can change the default values for these parameters by setting a key\n    (with the same name as the corresponding python parameter) in the\n    ``[match]`` section of :ref:`.stbt.conf`. But we strongly recommend that\n    you don\'t change the default values from what is documented here.\n\n    You should only need to change these parameters when you\'re trying to match\n    a reference image that isn\'t actually a perfect match -- for example if\n    there\'s a translucent background with live TV visible behind it; or if you\n    have a reference image of a button\'s background and you want it to match\n    even if the text on the button doesn\'t match.\n\n    :type match_method: `MatchMethod`\n    :param match_method:\n      The method to be used by the first pass of stb-tester\'s image matching\n      algorithm, to find the most likely location of the reference image within\n      the larger source image. For details see OpenCV\'s\n      :ocv:pyfunc:`cv2.matchTemplate`. Defaults to ``MatchMethod.SQDIFF``.\n\n    :param float match_threshold:\n      Overall similarity threshold for the image to be considered a match. This\n      threshold applies to the *average* similarity across all pixels in the\n      image. Valid values range from 0 (anything is considered to match) to 1\n      (the match has to be pixel perfect). Defaults to 0.98.\n\n    :type confirm_method: `ConfirmMethod`\n    :param confirm_method:\n      The method to be used by the second pass of stb-tester\'s image matching\n      algorithm, to confirm that the region identified by the first pass is a\n      good match.\n\n      The first pass often gives false positives: It can report a ""match"" for\n      an image with obvious differences, if the differences are local to a\n      small part of the image. The second pass is more CPU-intensive, but it\n      only checks the position of the image that the first pass identified. The\n      allowed values are:\n\n      :ConfirmMethod.NONE:\n        Do not confirm the match. This is useful if you know that the reference\n        image is different in some of the pixels. For example to find a button,\n        even if the text inside the button is different.\n\n      :ConfirmMethod.ABSDIFF:\n        Compare the absolute difference of each pixel from the reference image\n        against its counterpart from the candidate region in the source video\n        frame.\n\n      :ConfirmMethod.NORMED_ABSDIFF:\n        Normalise the pixel values from both the reference image and the\n        candidate region in the source video frame, then compare the absolute\n        difference as with ``ABSDIFF``.\n\n        This method is better at noticing differences in low-contrast images\n        (compared to the ``ABSDIFF`` method), but it isn\'t suitable for\n        reference images that don\'t have any structure (that is, images that\n        are a single solid color without any lines or variation).\n\n        This is the default method, with a default ``confirm_threshold`` of\n        0.70.\n\n    :param float confirm_threshold:\n      The minimum allowed similarity between any given pixel in the reference\n      image and the corresponding pixel in the source video frame, as a\n      fraction of the pixel\'s total luminance range.\n\n      Unlike ``match_threshold``, this threshold applies to each pixel\n      individually: Any pixel that exceeds this threshold will cause the match\n      to fail (but see ``erode_passes`` below).\n\n      Valid values range from 0 (less strict) to 1.0 (more strict). Useful\n      values tend to be around 0.84 for ``ABSDIFF``, and 0.70 for\n      ``NORMED_ABSDIFF``. Defaults to 0.70.\n\n    :param int erode_passes:\n      After the ``ABSDIFF`` or ``NORMED_ABSDIFF`` absolute difference is taken,\n      stb-tester runs an erosion algorithm that removes single-pixel differences\n      to account for noise and slight rendering differences. Useful values are\n      1 (the default) and 0 (to disable this step).\n\n    """"""\n\n    def __init__(self, match_method=None, match_threshold=None,\n                 confirm_method=None, confirm_threshold=None,\n                 erode_passes=None):\n\n        if match_method is None:\n            match_method = get_config(\n                \'match\', \'match_method\', type_=MatchMethod)\n        if match_threshold is None:\n            match_threshold = get_config(\n                \'match\', \'match_threshold\', type_=float)\n        if confirm_method is None:\n            confirm_method = get_config(\n                \'match\', \'confirm_method\', type_=ConfirmMethod)\n        if confirm_threshold is None:\n            confirm_threshold = get_config(\n                \'match\', \'confirm_threshold\', type_=float)\n        if erode_passes is None:\n            erode_passes = get_config(\'match\', \'erode_passes\', type_=int)\n\n        match_method = MatchMethod(match_method)\n        confirm_method = ConfirmMethod(confirm_method)\n\n        self.match_method = match_method\n        self.match_threshold = match_threshold\n        self.confirm_method = confirm_method\n        self.confirm_threshold = confirm_threshold\n        self.erode_passes = erode_passes\n\n    def __repr__(self):\n        return (\n            ""MatchParameters(match_method=%r, match_threshold=%r, ""\n            ""confirm_method=%r, confirm_threshold=%r, erode_passes=%r)""\n            % (self.match_method, self.match_threshold,\n               self.confirm_method, self.confirm_threshold, self.erode_passes))\n\n\nclass MatchResult(object):\n    """"""The result from `match`.\n\n    :ivar float time: The time at which the video-frame was captured, in\n        seconds since 1970-01-01T00:00Z. This timestamp can be compared with\n        system time (``time.time()``).\n\n    :ivar bool match: True if a match was found. This is the same as evaluating\n        ``MatchResult`` as a bool. That is, ``if result:`` will behave the same\n        as ``if result.match:``.\n\n    :ivar Region region: Coordinates where the image was found (or of the\n        nearest match, if no match was found).\n\n    :ivar float first_pass_result: Value between 0 (poor) and 1.0 (excellent\n        match) from the first pass of stb-tester\'s image matching algorithm\n        (see `MatchParameters` for details).\n\n    :ivar Frame frame: The video frame that was searched, as given to `match`.\n\n    :ivar image: The reference image that was searched for, as given to `match`.\n    """"""\n    _fields = (""time"", ""match"", ""region"", ""first_pass_result"", ""frame"", ""image"")\n\n    def __init__(\n            self, time, match, region,  # pylint: disable=redefined-outer-name\n            first_pass_result, frame, image, _first_pass_matched=None):\n        self.time = time\n        self.match = match\n        self.region = region\n        self.first_pass_result = first_pass_result\n        self.frame = frame\n        self.image = image\n        self._first_pass_matched = _first_pass_matched\n\n    def __repr__(self):\n        return (\n            ""MatchResult(time=%s, match=%r, region=%r, first_pass_result=%r, ""\n            ""frame=%s, image=%s)"" % (\n                ""None"" if self.time is None else ""%.3f"" % self.time,\n                self.match,\n                self.region,\n                self.first_pass_result,\n                _frame_repr(self.frame),\n                ""<Custom Image>"" if isinstance(self.image, numpy.ndarray)\n                else repr(self.image)))\n\n    def __bool__(self):\n        return self.match\n\n    @property\n    def position(self):\n        return Position(self.region.x, self.region.y)\n\n\ndef match(image, frame=None, match_parameters=None, region=Region.ALL):\n    """"""\n    Search for an image in a single video frame.\n\n    :type image: string or `numpy.ndarray`\n    :param image:\n      The image to search for. It can be the filename of a png file on disk, or\n      a numpy array containing the pixel data in 8-bit BGR format. If the image\n      has an alpha channel, any transparent pixels are ignored.\n\n      Filenames should be relative paths. See `stbt.load_image` for the path\n      lookup algorithm.\n\n      8-bit BGR numpy arrays are the same format that OpenCV uses for images.\n      This allows generating reference images on the fly (possibly using\n      OpenCV) or searching for images captured from the device-under-test\n      earlier in the test script.\n\n    :type frame: `stbt.Frame` or `numpy.ndarray`\n    :param frame:\n      If this is specified it is used as the video frame to search in;\n      otherwise a new frame is grabbed from the device-under-test. This is an\n      image in OpenCV format (for example as returned by `frames` and\n      `get_frame`).\n\n    :type match_parameters: `MatchParameters`\n    :param match_parameters:\n      Customise the image matching algorithm. See `MatchParameters` for details.\n\n    :type region: `Region`\n    :param region:\n      Only search within the specified region of the video frame.\n\n    :returns:\n      A `MatchResult`, which will evaluate to true if a match was found,\n      false otherwise.\n\n    Added in v30: Support transparency in the reference image, and new match\n    method ``MatchMethod.SQDIFF``.\n    """"""\n    result = next(_match_all(image, frame, match_parameters, region))\n    if result.match:\n        debug(""Match found: %s"" % str(result))\n    else:\n        debug(""No match found. Closest match: %s"" % str(result))\n    return result\n\n\ndef match_all(image, frame=None, match_parameters=None, region=Region.ALL):\n    """"""\n    Search for all instances of an image in a single video frame.\n\n    Arguments are the same as `match`.\n\n    :returns:\n      An iterator of zero or more `MatchResult` objects (one for each position\n      in the frame where ``image`` matches).\n\n    Examples:\n\n    .. code-block:: python\n\n        all_buttons = list(stbt.match_all(""button.png""))\n\n    .. code-block:: python\n\n        for match_result in stbt.match_all(""button.png""):\n            # do something with match_result here\n            ...\n    """"""\n    any_matches = False\n    for result in _match_all(image, frame, match_parameters, region):\n        if result.match:\n            debug(""Match found: %s"" % str(result))\n            any_matches = True\n            yield result\n        else:\n            if not any_matches:\n                debug(""No match found. Closest match: %s"" % str(result))\n            break\n\n\ndef _match_all(image, frame, match_parameters, region):\n    """"""\n    Generator that yields a sequence of zero or more truthy MatchResults,\n    followed by a falsey MatchResult.\n    """"""\n    if match_parameters is None:\n        match_parameters = MatchParameters()\n\n    if frame is None:\n        import stbt\n        frame = stbt.get_frame()\n\n    template = _load_image(image)\n\n    # Normalise single channel images to shape (h, w, 1) rather than just (h, w)\n    t = template.image.view()\n    if len(t.shape) == 2:\n        t.shape = t.shape + (1,)\n\n    frame = frame.view()\n    if len(frame.shape) == 2:\n        frame.shape = frame.shape + (1,)\n\n    if len(t.shape) != 3:\n        raise ValueError(\n            ""Invalid shape for image: %r. Shape must have 2 or 3 elements"" %\n            (template.image.shape,))\n    if len(frame.shape) != 3:\n        raise ValueError(\n            ""Invalid shape for frame: %r. Shape must have 2 or 3 elements"" %\n            (frame.shape,))\n\n    if t.shape[2] in [1, 3, 4]:\n        pass\n    else:\n        raise ValueError(""Expected 3-channel image, got %d channels: %s""\n                         % (t.shape[2], template.absolute_filename))\n\n    if any(frame.shape[x] < t.shape[x] for x in (0, 1)):\n        raise ValueError(""Frame %r must be larger than reference image %r""\n                         % (frame.shape, t.shape))\n    if any(t.shape[x] < 1 for x in (0, 1)):\n        raise ValueError(""Reference image %r must contain some data""\n                         % (t.shape,))\n    if (frame.shape[2], t.shape[2]) not in [(1, 1), (3, 3), (3, 4)]:\n        raise ValueError(\n            ""Frame %r and reference image %r must have the same number of ""\n            ""channels"" % (frame.shape, t.shape))\n\n    if t.shape[2] == 4:\n        if cv2_compat.version < [3, 0, 0]:\n            raise ValueError(\n                ""Reference image %s has alpha channel, but transparency ""\n                ""support requires OpenCV 3.0 or greater (you have %s).""\n                % (template.relative_filename, cv2_compat.version))\n\n        if match_parameters.match_method not in (MatchMethod.SQDIFF,\n                                                 MatchMethod.CCORR_NORMED):\n            # See `matchTemplateMask`:\n            # https://github.com/opencv/opencv/blob/3.2.0/modules/imgproc/src/templmatch.cpp#L840-L917\n            raise ValueError(\n                ""Reference image %s has alpha channel, but transparency ""\n                ""support requires match_method SQDIFF or CCORR_NORMED ""\n                ""(you specified %s).""\n                % (template.relative_filename, match_parameters.match_method))\n\n    input_region = Region.intersect(_image_region(frame), region)\n    if input_region is None:\n        raise ValueError(""frame with dimensions %r doesn\'t contain %r""\n                         % (frame.shape, region))\n    if input_region.height < t.shape[0] or input_region.width < t.shape[1]:\n        raise ValueError(""%r must be larger than reference image %r""\n                         % (input_region, t.shape))\n\n    imglog = ImageLogger(\n        ""match"", match_parameters=match_parameters,\n        template_name=template.friendly_name,\n        input_region=input_region)\n\n    # pylint:disable=undefined-loop-variable\n    try:\n        for (matched, match_region, first_pass_matched,\n             first_pass_certainty) in _find_matches(\n                crop(frame, input_region), t, match_parameters, imglog):\n\n            match_region = Region.from_extents(*match_region) \\\n                                 .translate(input_region)\n            result = MatchResult(\n                getattr(frame, ""time"", None), matched, match_region,\n                first_pass_certainty, frame,\n                (template.relative_filename or template.image),\n                first_pass_matched)\n            imglog.append(matches=result)\n            draw_on(frame, result, label=""match(%s)"" % template.short_repr())\n            yield result\n\n    finally:\n        try:\n            _log_match_image_debug(imglog)\n        except Exception:  # pylint:disable=broad-except\n            pass\n\n\ndef wait_for_match(image, timeout_secs=10, consecutive_matches=1,\n                   match_parameters=None, region=Region.ALL, frames=None):\n    """"""Search for an image in the device-under-test\'s video stream.\n\n    :param image: The image to search for. See `match`.\n\n    :type timeout_secs: int or float or None\n    :param timeout_secs:\n        A timeout in seconds. This function will raise `MatchTimeout` if no\n        match is found within this time.\n\n    :param int consecutive_matches:\n        Forces this function to wait for several consecutive frames with a\n        match found at the same x,y position. Increase ``consecutive_matches``\n        to avoid false positives due to noise, or to wait for a moving\n        selection to stop moving.\n\n    :param match_parameters: See `match`.\n    :param region: See `match`.\n\n    :type frames: Iterator[stbt.Frame]\n    :param frames: An iterable of video-frames to analyse. Defaults to\n        ``stbt.frames()``.\n\n    :returns: `MatchResult` when the image is found.\n    :raises: `MatchTimeout` if no match is found after ``timeout_secs`` seconds.\n    """"""\n    if match_parameters is None:\n        match_parameters = MatchParameters()\n\n    if frames is None:\n        import stbt\n        frames = stbt.frames(timeout_secs=timeout_secs)\n    else:\n        frames = limit_time(frames, timeout_secs)\n\n    match_count = 0\n    last_pos = Position(0, 0)\n    image = _load_image(image)\n    debug(""Searching for "" + image.friendly_name)\n    for frame in frames:\n        res = match(image, match_parameters=match_parameters,\n                    region=region, frame=frame)\n        if res.match and (match_count == 0 or res.position == last_pos):\n            match_count += 1\n        else:\n            match_count = 0\n        last_pos = res.position\n        if match_count == consecutive_matches:\n            debug(""Matched "" + image.friendly_name)\n            return res\n\n    raise MatchTimeout(res.frame, image.friendly_name, timeout_secs)  # pylint:disable=undefined-loop-variable\n\n\nclass MatchTimeout(UITestFailure):\n    """"""Exception raised by `wait_for_match`.\n\n    :ivar Frame screenshot: The last video frame that `wait_for_match` checked\n        before timing out.\n\n    :ivar str expected: Filename of the image that was being searched for.\n\n    :vartype timeout_secs: int or float\n    :ivar timeout_secs: Number of seconds that the image was searched for.\n    """"""\n    def __init__(self, screenshot, expected, timeout_secs):\n        super(MatchTimeout, self).__init__()\n        self.screenshot = screenshot\n        self.expected = expected\n        self.timeout_secs = timeout_secs\n\n    def __str__(self):\n        return ""Didn\'t find match for \'%s\' within %g seconds."" % (\n            self.expected, self.timeout_secs)\n\n\n@memoize_iterator({""version"": ""31""})\ndef _find_matches(image, template, match_parameters, imglog):\n    """"""Our image-matching algorithm.\n\n    Runs 2 passes: `_find_candidate_matches` to locate potential matches, then\n    `_confirm_match` to discard false positives from the first pass.\n\n    Returns an iterator yielding zero or more `(True, position, certainty)`\n    tuples for each location where `template` is found within `image`, followed\n    by a single `(False, position, certainty)` tuple when there are no further\n    matching locations.\n    """"""\n\n    if template.shape[2] == 4:\n        # Normalise transparency channel to either 0 or 255\n        mask = template[:, :, 3]\n        mask[mask < 255] = 0\n\n    # pylint:disable=undefined-loop-variable\n    for i, first_pass_matched, region, first_pass_certainty in \\\n            _find_candidate_matches(image, template, match_parameters, imglog):\n        confirmed = (\n            first_pass_matched and\n            _confirm_match(image, region, template, match_parameters,\n                           imwrite=lambda name, img: imglog.imwrite(\n                               ""match%d-%s"" % (i, name), img)))  # pylint:disable=cell-var-from-loop\n\n        yield (confirmed, list(region), first_pass_matched,\n               first_pass_certainty)\n        if not confirmed:\n            break\n\n\ndef _find_candidate_matches(image, template, match_parameters, imglog):\n    """"""First pass: Search for `template` in the entire `image`.\n\n    This searches the entire image, so speed is more important than accuracy.\n    False positives are ok; we apply a second pass later (`_confirm_match`) to\n    weed out false positives.\n\n    http://docs.opencv.org/modules/imgproc/doc/object_detection.html\n    http://opencv-code.com/tutorials/fast-template-matching-with-image-pyramid\n    """"""\n\n    imglog.imwrite(""source"", image)\n    imglog.imwrite(""template"", template)\n    imglog.set(template_shape=template.shape)\n    if template.shape[2] == 4:\n        imglog.imwrite(""mask"", template[:, :, 3])\n\n    ddebug(""Original image %s, template %s"" % (image.shape, template.shape))\n\n    method = {  # pylint:disable=redefined-outer-name\n        MatchMethod.SQDIFF: cv2.TM_SQDIFF,\n        MatchMethod.SQDIFF_NORMED: cv2.TM_SQDIFF_NORMED,\n        MatchMethod.CCORR_NORMED: cv2.TM_CCORR_NORMED,\n        MatchMethod.CCOEFF_NORMED: cv2.TM_CCOEFF_NORMED,\n    }[match_parameters.match_method]\n\n    levels = get_config(""match"", ""pyramid_levels"", type_=int)\n    if levels <= 0:\n        raise ConfigurationError(""\'match.pyramid_levels\' must be > 0"")\n\n    if (match_parameters.match_method == MatchMethod.SQDIFF and\n            template.shape[:2] == image.shape[:2] and\n            sqdiff is not None):\n        # Fast-path: image and template are the same size, skip pyramid, FFT,\n        # etc.  This is particularly useful for full-image matching.\n        ddebug(""stbt-match: frame and template sizes match: Using fast-path"")\n        imglog.set(fast_path=True)\n        s, n = sqdiff(template, image)\n        if n == 0:\n            certainty = 1\n        else:\n            certainty = 1 - float(s) / (n * 255 * 255)\n        yield (0, certainty >= match_parameters.match_threshold,\n               _image_region(image), certainty)\n        yield (0, False, _image_region(image), 0.)\n        return\n\n    if template.shape[2] == 4:\n        # OpenCV wants mask to match template\'s number of channels\n        mask = cv2.cvtColor(template[:, :, 3], cv2.COLOR_GRAY2BGR)\n        template = template[:, :, 0:3]\n    else:\n        mask = None\n\n    mask_pyramid = _build_pyramid(mask, levels, is_mask=True)\n    template_pyramid = _build_pyramid(template, len(mask_pyramid),\n                                      is_template=True)\n    image_pyramid = _build_pyramid(image, len(template_pyramid))\n    roi_mask = None  # Initial region of interest: The whole image.\n\n    for level in reversed(range(len(image_pyramid))):\n        if roi_mask is not None:\n            if any(x < 3 for x in roi_mask.shape):\n                roi_mask = None\n            else:\n                roi_mask = cv2.pyrUp(roi_mask)\n\n        def imwrite(name, img, scale=1):\n            imglog.imwrite(""level%d-%s"" % (level, name), img, scale=scale)  # pylint:disable=cell-var-from-loop\n\n        heatmap, heatmap_scale = _match_template(\n            image_pyramid[level], template_pyramid[level], mask_pyramid[level],\n            method, roi_mask, level, imwrite)\n\n        # Relax the threshold slightly for scaled-down pyramid levels to\n        # compensate for scaling artifacts.\n        if level == 0:\n            relax = 0\n        elif match_parameters.match_method == MatchMethod.SQDIFF:\n            relax = 0.02\n        else:\n            relax = 0.2\n        threshold = max(0, match_parameters.match_threshold - relax)\n\n        matched, best_match_position, certainty = _find_best_match_position(\n            heatmap, heatmap_scale, threshold, level)\n        imglog.append(pyramid_levels=(\n            matched, best_match_position, certainty, level))\n\n        if not matched:\n            break\n\n        if level > 0 or imglog.enabled:\n            _, roi_mask = cv2.threshold(\n                heatmap,\n                (1 - threshold) * heatmap_scale,\n                255,\n                cv2.THRESH_BINARY_INV)\n            roi_mask = roi_mask.astype(numpy.uint8)\n            imwrite(""source_matchtemplate_threshold"", roi_mask)\n\n    # pylint:disable=undefined-loop-variable\n    region = Region(*_upsample(best_match_position, level),\n                    width=template.shape[1], height=template.shape[0])\n\n    for i in itertools.count():\n\n        imglog.imwrite(""match%d-heatmap"" % i, heatmap, scale=heatmap_scale)\n        yield (i, matched, region, certainty)\n        if not matched:\n            return\n        assert level == 0\n\n        # Exclude any positions that would overlap the previous match, then\n        # keep iterating until we don\'t find any more matches.\n        exclude = region.extend(x=-(region.width - 1), y=-(region.height - 1))\n        cv2.rectangle(\n            heatmap,\n            # -1 because cv2.rectangle considers the bottom-right point to be\n            # *inside* the rectangle.\n            (exclude.x, exclude.y), (exclude.right - 1, exclude.bottom - 1),\n            heatmap_scale,\n            cv2_compat.FILLED)\n\n        matched, best_match_position, certainty = _find_best_match_position(\n            heatmap, heatmap_scale, threshold, level)\n        region = Region(*best_match_position,\n                        width=template.shape[1], height=template.shape[0])\n\n\ndef _match_template(image, template, mask, method, roi_mask, level, imwrite):  # pylint:disable=redefined-outer-name\n\n    ddebug(""Level %d: image %s, template %s"" % (\n        level, image.shape, template.shape))\n\n    heatmap_shape = (image.shape[0] - template.shape[0] + 1,\n                     image.shape[1] - template.shape[1] + 1)\n    NO_MATCH = {\n        cv2.TM_SQDIFF: template.size * (255 ** 2),\n        cv2.TM_SQDIFF_NORMED: 1,\n        cv2.TM_CCORR_NORMED: 0,\n        cv2.TM_CCOEFF_NORMED: 0,\n    }\n    matches_heatmap = numpy.full(heatmap_shape, NO_MATCH[method],\n                                 dtype=numpy.float32)\n\n    if roi_mask is None:\n        # Initial region of interest: The whole image.\n        rois = [_image_region(matches_heatmap)]\n    else:\n        ddebug(""Level %d: roi_mask=%r, matches_heatmap=%r"" % (\n            level, roi_mask.shape, matches_heatmap.shape))\n\n        # roi_mask comes from the previous pyramid level so it has gone through\n        # pyrDown -> pyrUp. If the starting size was odd-numbered then after\n        # this round-trip you end up with a size 1 pixel larger than the\n        # original. We can discard the extra pixel safely because pyrUp blurs\n        # with a 5x5 kernel after upscaling, so in effect it is dilating all\n        # our ROIs by 1 pixel.\n        roi_mask = crop(roi_mask, _image_region(matches_heatmap))\n\n        rois = [Region(*x) for x in cv2_compat.find_contour_boxes(\n            roi_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)]\n        _merge_regions(rois)\n\n    if get_debug_level() > 1:\n        source_with_rois = image.copy()\n        for roi in rois:\n            r = roi\n            t = _Size(*template.shape[:2])\n            s = _Size(*source_with_rois.shape[:2])\n            cv2.rectangle(\n                source_with_rois,\n                (max(0, r.x), max(0, r.y)),\n                (min(s.w - 1, r.right + t.w - 1),\n                 min(s.h - 1, r.bottom + t.h - 1)),\n                (0, 255, 255),\n                thickness=1)\n        imwrite(""source_with_rois"", source_with_rois)\n\n    if mask is not None:\n        kwargs = {""mask"": mask}\n    else:\n        kwargs = {}  # For OpenCV < 3.0.0\n    for roi in rois:\n        r = roi.extend(right=template.shape[1] - 1,\n                       bottom=template.shape[0] - 1)\n        ddebug(""Level %d: Searching in %s"" % (level, r))\n        cv2.matchTemplate(\n            image[r.to_slice()],\n            template,\n            method,\n            matches_heatmap[roi.to_slice()],\n            **kwargs)\n\n    if method == cv2.TM_SQDIFF:\n        # OpenCV\'s SQDIFF_NORMED normalises by the pixel intensity across\n        # the reference image and the source image patch. This doesn\'t work\n        # at all for completely black images, and it exaggerates\n        # differences for dark images. With SQDIFF we do our own\n        # normalisation based solely on the number of pixels in the sum.\n        # We still get a number between 0 - 1.\n\n        if mask is not None:\n            # matchTemplateMask normalises the source & template image to [0,1].\n            # https://github.com/opencv/opencv/blob/3.2.0/modules/imgproc/src/templmatch.cpp#L840-L917\n            scale = max(1, numpy.count_nonzero(mask))\n        else:\n            scale = template.size * (255 ** 2)\n    else:\n        scale = 1\n\n    if method in (cv2.TM_CCORR_NORMED, cv2.TM_CCOEFF_NORMED):\n        matches_heatmap = 1 - matches_heatmap\n\n    imwrite(""source"", image)\n    imwrite(""template"", template)\n    imwrite(""mask"", mask)\n    imwrite(""source_matchtemplate"", matches_heatmap, scale=scale)\n\n    return matches_heatmap, scale\n\n\ndef _find_best_match_position(matches_heatmap, scale, threshold, level):\n    min_value, _, min_location, _ = cv2.minMaxLoc(matches_heatmap)\n    min_value /= scale\n    certainty = 1 - min_value\n    best_match_position = Position(*min_location)\n    matched = certainty >= threshold\n    ddebug(""Level %d: %s at %s with certainty %s"" % (\n        level, ""Matched"" if matched else ""Didn\'t match"",\n        best_match_position, certainty))\n    return (matched, best_match_position, certainty)\n\n\ndef _build_pyramid(image, levels, is_template=False, is_mask=False):\n    """"""A ""pyramid"" is [an image, the same image at 1/2 the size, at 1/4, ...]\n\n    As a performance optimisation, image processing algorithms work on a\n    ""pyramid"" by first identifying regions of interest (ROIs) in the smallest\n    image; if results are positive, they proceed to the next larger image, etc.\n    See http://docs.opencv.org/doc/tutorials/imgproc/pyramids/pyramids.html\n\n    The original-sized image is called ""level 0"", the next smaller image ""level\n    1"", and so on. This numbering corresponds to the index of the ""pyramid""\n    array.\n    """"""\n    if image is None:\n        return [None] * levels\n    pyramid = [image]\n    previous = image\n    for _ in range(levels - 1):\n        if any(x < 20 for x in previous.shape[:2]):\n            break\n        downsampled = cv2.pyrDown(previous, borderType=cv2.BORDER_REPLICATE)\n        if is_mask:\n            cv2.threshold(downsampled, 254, 255, cv2.THRESH_BINARY, downsampled)\n        previous = downsampled\n        if is_template or is_mask:\n            # Ignore pixels on the edge of the template, because pyrDown\'s\n            # blurring will affect them differently than the corresponding\n            # pixels in the frame (which do have neighbours, unlike the\n            # template\'s edge pixels).\n            downsampled = downsampled[1:-1, 1:-1]\n        else:\n            # ...and adjust the coordinate system of the match positions we\'re\n            # returning accordingly. Because of the cropping, match position\n            # 0,0 means pixel 1,1 of the template matched at pixel 1,1 of\n            # the frame (this is the same as saying pixel 0,0 of the template\n            # matched at pixel 0,0 of the frame, so we won\'t need to adjust\n            # the match position afterwards).\n            downsampled = downsampled[1:, 1:]\n        if is_mask and numpy.count_nonzero(downsampled) // 3 < 400:\n            break\n        pyramid.append(downsampled)\n    return pyramid\n\n\ndef _upsample(position, levels):\n    """"""Convert position coordinates by the given number of pyramid levels.\n\n    There is a loss of precision (unless ``levels`` is 0, in which case this\n    function is a no-op).\n    """"""\n    return Position(position.x * 2 ** levels, position.y * 2 ** levels)\n\n\n# Order of parameters consistent with OpenCV\'s ``numpy.ndarray.shape``.\nclass _Size(namedtuple(""_Size"", ""h w"")):\n    pass\n\n\ndef _confirm_match(image, region, template, match_parameters, imwrite):\n    """"""Second pass: Confirm that `template` matches `image` at `region`.\n\n    This only checks `template` at a single position within `image`, so we can\n    afford to do more computationally-intensive checks than\n    `_find_candidate_matches`.\n    """"""\n\n    if match_parameters.confirm_method == ConfirmMethod.NONE:\n        return True\n\n    if template.shape[2] == 4:\n        # Create transparency mask from alpha channel\n        mask = template[:, :, 3]\n        template = template[:, :, 0:3]\n    else:\n        mask = None\n\n    # Set Region Of Interest to the ""best match"" location\n    image = image[region.y:region.bottom, region.x:region.right]\n    imwrite(""confirm-source_roi"", image)\n    if image.shape[2] == 3:\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n    imwrite(""confirm-source_roi_gray"", image)\n    imwrite(""confirm-template_gray"", template)\n\n    if match_parameters.confirm_method == ConfirmMethod.NORMED_ABSDIFF:\n        cv2.normalize(image, image, 0, 255, cv2.NORM_MINMAX, mask=mask)\n        cv2.normalize(template, template, 0, 255, cv2.NORM_MINMAX, mask=mask)\n        imwrite(""confirm-source_roi_gray_normalized"", image)\n        imwrite(""confirm-template_gray_normalized"", template)\n\n    if mask is not None:\n        image = cv2.bitwise_and(image, mask)\n        template = cv2.bitwise_and(template, mask)\n        imwrite(""confirm-source_roi_masked"", image)\n        imwrite(""confirm-template_masked"", template)\n\n    absdiff = cv2.absdiff(image, template)\n    _, thresholded = cv2.threshold(\n        absdiff, int((1 - match_parameters.confirm_threshold) * 255),\n        255, cv2.THRESH_BINARY)\n    eroded = cv2.erode(\n        thresholded,\n        cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)),\n        iterations=match_parameters.erode_passes)\n    imwrite(""confirm-absdiff"", absdiff)\n    imwrite(""confirm-absdiff_threshold"", thresholded)\n    imwrite(""confirm-absdiff_threshold_erode"", eroded)\n\n    return cv2.countNonZero(eroded) == 0\n\n\ndef _merge_regions(regions):\n    """"""Discard regions that are entirely contained within another region.""""""\n    regions.sort(key=lambda r: r.width * r.height)\n    i = len(regions) - 1\n    while i > 0:\n        r = regions[i]\n        for j in range(i - 1, -1, -1):\n            if r.contains(regions[j]):\n                del regions[j]\n                i -= 1\n        i -= 1\n\n\ndef _log_match_image_debug(imglog):\n    if not imglog.enabled:\n        return\n\n    title = ""stbt.match(%r): %s"" % (\n        imglog.data[""template_name""],\n        ""Matched"" if any(imglog.data[""matches""]) else ""Didn\'t match"")\n\n    for matched, position, _, level in imglog.data.get(""pyramid_levels"", []):\n        template = imglog.images[""level%d-template"" % level]\n        imglog.imwrite(""level%d-source_with_match"" % level,\n                       imglog.images[""level%d-source"" % level],\n                       Region(x=position.x, y=position.y,\n                              width=template.shape[1],\n                              height=template.shape[0]),\n                       _Annotation.MATCHED if matched else _Annotation.NO_MATCH)\n\n    for i, result in enumerate(imglog.data[""matches""]):\n        imglog.imwrite(\n            ""match%d-source_with_match"" % i, imglog.images[""source""],\n            result.region, _Annotation.MATCHED if result._first_pass_matched  # pylint:disable=protected-access\n            else _Annotation.NO_MATCH)\n\n    imglog.imwrite(\n        ""source_with_matches"", imglog.images[""source""],\n        [x.region for x in imglog.data[""matches""]],\n        [_Annotation.MATCHED if x.match else _Annotation.NO_MATCH\n         for x in imglog.data[""matches""]])\n\n    template = u""""""\\\n        <h4>{{title}}</h4>\n\n        <img src=""source_with_matches.png"" />\n\n        <h5>First pass (find candidate matches):</h5>\n\n        <p>Searching for <b>template</b> {{link(""template"")}}\n            {% if ""mask"" in images %}\n            with <b>transparency mask</b> {{link(""mask"")}}\n            {% endif %}\n            within <b>source</b> image {{link(""source"")}}</p>\n\n        {% if fast_path %}\n        <p>Taking fast path - template shape <code>{{ template_shape }}</code>\n        matches size of target region <code>{{ input_region }}</code></p>\n\n        <table class=""table"">\n        <tr>\n          <th>Match #</th>\n          <th><b>Matched?<b></th>\n          <th><b>certainty</b></th>\n        </tr>\n        {% for m in matches %}\n        {# note that loop.index is 1-based #}\n        <tr>\n          <td><b>{{loop.index}}</b></td>\n          <td>{{""Matched"" if m._first_pass_matched else ""Didn\'t match""}}</td>\n          <td>{{""%.4f""|format(m.first_pass_result)}}</td>\n        </tr>\n        {% endfor %}\n        </table>\n        {% else %}\n        <table class=""table"">\n        <tr>\n          <th>Pyramid level</th>\n          <th>Match #</th>\n          <th>Searching for <b>template</b></th>\n          <th>within <b>source regions of interest</b></th>\n          <th>\n            OpenCV <b>matchTemplate heatmap</b>\n            with {{match_parameters.match_method}}\n            (darkest pixel indicates position of best match).\n          </th>\n          <th>\n            matchTemplate heatmap <b>above match_threshold</b>\n            of {{""%g""|format(match_parameters.match_threshold)}}\n            (white pixels indicate positions above the threshold).\n          </th>\n          <th><b>Matched?<b></th>\n          <th>Best match <b>position</b></th>\n          <th>&nbsp;</th>\n          <th><b>certainty</b></th>\n        </tr>\n\n        {% for matched, position, certainty, level in pyramid_levels %}\n        <tr>\n          <td><b>{{level}}</b></td>\n          <td><b>{{""0"" if level == 0 else """"}}</b></td>\n          <td>\n            {{link(""template"", level)}}\n            {% if ""mask"" in images %}\n            {{link(""mask"", level)}}\n            {% endif %}\n          </td>\n          <td>{{link(""source_with_rois"", level)}}</td>\n          <td>{{link(""source_matchtemplate"", level)}}</td>\n          <td>\n            {{link(""source_matchtemplate_threshold"", level) if matched else """"}}\n          </td>\n          <td>{{""Matched"" if matched else ""Didn\'t match""}}</td>\n          <td>{{position if level > 0 else matches[0].region}}</td>\n          <td>{{link(""source_with_match"", level)}}</td>\n          <td>{{""%.4f""|format(certainty)}}</td>\n        </tr>\n        {% endfor %}\n\n        {% for m in matches[1:] %}\n        {# note that loop.index is 1-based #}\n        <tr>\n          <td>&nbsp;</td>\n          <td><b>{{loop.index}}</b></td>\n          <td>&nbsp;</td>\n          <td>&nbsp;</td>\n          <td>{{link(""heatmap"", match=loop.index)}}</td>\n          <td></td>\n          <td>{{""Matched"" if m._first_pass_matched else ""Didn\'t match""}}</td>\n          <td>{{m.region}}</td>\n          <td>{{link(""source_with_match"", match=loop.index)}}</td>\n          <td>{{""%.4f""|format(m.first_pass_result)}}</td>\n        </tr>\n        {% endfor %}\n\n        </table>\n        {% endif %}\n\n        {% if show_second_pass %}\n          <h5>Second pass (confirmation):</h5>\n\n          <p><b>Confirm method:</b> {{match_parameters.confirm_method}}</p>\n\n          {% if match_parameters.confirm_method != ConfirmMethod.NONE %}\n            <table class=""table"">\n            <tr>\n              <th>Match #</th>\n              <th>Comparing <b>template</b></th>\n              <th>against <b>source image\'s region of interest</b></th>\n              {% if match_parameters.confirm_method ==\n                         ConfirmMethod.NORMED_ABSDIFF %}\n                <th><b>Normalised template</b></th>\n                <th><b>Normalised source</b></th>\n              {% endif %}\n              <th><b>Absolute differences</b></th>\n              <th>\n                Differences <b>above confirm_threshold</b>\n                of {{""%.2f""|format(match_parameters.confirm_threshold)}}\n              </th>\n              <th>\n                After <b>eroding</b>\n                {{match_parameters.erode_passes}}\n                {{""time"" if match_parameters.erode_passes == 1\n                  else ""times""}};\n                the template matches if no differences (white pixels) remain\n              </th>\n            </tr>\n\n            {% for m in matches %}\n              {% if m._first_pass_matched %}\n                <tr>\n                  <td><b>{{loop.index0}}</b></td>\n                  <td>{{link(""confirm-template_gray"", match=0)}}</td>\n                  <td>{{link(""confirm-source_roi_gray"", match=loop.index0)}}</td>\n                  {% if match_parameters.confirm_method ==\n                             ConfirmMethod.NORMED_ABSDIFF %}\n                    <td>{{link(""confirm-template_gray_normalized"", match=loop.index0)}}</td>\n                    <td>{{link(""confirm-source_roi_gray_normalized"", match=loop.index0)}}</td>\n                  {% endif %}\n                  <td>{{link(""confirm-absdiff"", match=loop.index0)}}</td>\n                  <td>{{link(""confirm-absdiff_threshold"", match=loop.index0)}}</td>\n                  <td>{{link(""confirm-absdiff_threshold_erode"", match=loop.index0)}}</td>\n                </tr>\n              {% endif %}\n            {% endfor %}\n\n            </table>\n          {% endif %}\n        {% endif %}\n    """"""\n\n    def link(name, level=None, match=None):  # pylint: disable=redefined-outer-name\n        return (""<a href=\'{0}{1}{2}.png\'><img src=\'{0}{1}{2}.png\'""\n                "" class=\'thumb\'></a>""\n                .format("""" if level is None else ""level%d-"" % level,\n                        """" if match is None else ""match%d-"" % match,\n                        name))\n\n    imglog.html(\n        template,\n        ConfirmMethod=ConfirmMethod,\n        fast_path=imglog.data.get(""fast_path""),\n        link=link,\n        MatchMethod=MatchMethod,\n        show_second_pass=any(\n            x._first_pass_matched for x in imglog.data[""matches""]),  # pylint:disable=protected-access\n        title=title,\n    )\n'"
_stbt/motion.py,0,"b'# coding: utf-8\n\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nfrom collections import deque\n\nimport cv2\n\nfrom .config import ConfigurationError, get_config\nfrom .imgutils import (_frame_repr, _image_region, _ImageFromUser, _load_image,\n                       pixel_bounding_box, crop, limit_time)\nfrom .logging import debug, draw_on, ImageLogger\nfrom .types import Region, UITestFailure\n\n\ndef detect_motion(timeout_secs=10, noise_threshold=None, mask=None,\n                  region=Region.ALL, frames=None):\n    """"""Generator that yields a sequence of one `MotionResult` for each frame\n    processed from the device-under-test\'s video stream.\n\n    The `MotionResult` indicates whether any motion was detected.\n\n    Use it in a ``for`` loop like this::\n\n        for motionresult in stbt.detect_motion():\n            ...\n\n    In most cases you should use `wait_for_motion` instead.\n\n    :type timeout_secs: int or float or None\n    :param timeout_secs:\n        A timeout in seconds. After this timeout the iterator will be exhausted.\n        Thas is, a ``for`` loop like ``for m in detect_motion(timeout_secs=10)``\n        will terminate after 10 seconds. If ``timeout_secs`` is ``None`` then\n        the iterator will yield frames forever. Note that you can stop\n        iterating (for example with ``break``) at any time.\n\n    :param float noise_threshold:\n        The amount of noise to ignore. This is only useful with noisy analogue\n        video sources. Valid values range from 0 (all differences are\n        considered noise; a value of 0 will never report motion) to 1.0 (any\n        difference is considered motion).\n\n        This defaults to 0.84. You can override the global default value by\n        setting ``noise_threshold`` in the ``[motion]`` section of\n        :ref:`.stbt.conf`.\n\n    :type mask: str or `numpy.ndarray`\n    :param mask:\n        A black & white image that specifies which part of the image to search\n        for motion. White pixels select the area to analyse; black pixels select\n        the area to ignore. The mask must be the same size as the video frame.\n\n        This can be a string (a filename that will be resolved as per\n        `load_image`) or a single-channel image in OpenCV format.\n\n    :type region: `Region`\n    :param region:\n        Only analyze the specified region of the video frame.\n\n        If you specify both ``region`` and ``mask``, the mask must be the same\n        size as the region.\n\n    :type frames: Iterator[stbt.Frame]\n    :param frames: An iterable of video-frames to analyse. Defaults to\n        ``stbt.frames()``.\n    """"""\n    if frames is None:\n        import stbt\n        frames = stbt.frames()\n\n    frames = limit_time(frames, timeout_secs)  # pylint: disable=redefined-variable-type\n\n    if noise_threshold is None:\n        noise_threshold = get_config(\n            \'motion\', \'noise_threshold\', type_=float)\n\n    debug(""Searching for motion"")\n\n    if mask is None:\n        mask = _ImageFromUser(None, None, None)\n    else:\n        mask = _load_image(mask, cv2.IMREAD_GRAYSCALE)\n        debug(""Using mask %s"" % mask.friendly_name)\n\n    try:\n        frame = next(frames)\n    except StopIteration:\n        return\n\n    region = Region.intersect(_image_region(frame), region)\n\n    previous_frame_gray = cv2.cvtColor(crop(frame, region),\n                                       cv2.COLOR_BGR2GRAY)\n    if (mask.image is not None and\n            mask.image.shape[:2] != previous_frame_gray.shape[:2]):\n        raise ValueError(\n            ""The dimensions of the mask \'%s\' %s don\'t match the ""\n            ""video frame %s"" % (\n                mask.friendly_name, mask.image.shape,\n                previous_frame_gray.shape))\n\n    for frame in frames:\n        imglog = ImageLogger(""detect_motion"", region=region)\n        imglog.imwrite(""source"", frame)\n        imglog.set(roi=region, noise_threshold=noise_threshold)\n\n        frame_gray = cv2.cvtColor(crop(frame, region), cv2.COLOR_BGR2GRAY)\n        imglog.imwrite(""gray"", frame_gray)\n        imglog.imwrite(""previous_frame_gray"", previous_frame_gray)\n\n        absdiff = cv2.absdiff(frame_gray, previous_frame_gray)\n        imglog.imwrite(""absdiff"", absdiff)\n\n        if mask.image is not None:\n            absdiff = cv2.bitwise_and(absdiff, mask.image)\n            imglog.imwrite(""mask"", mask.image)\n            imglog.imwrite(""absdiff_masked"", absdiff)\n\n        _, thresholded = cv2.threshold(\n            absdiff, int((1 - noise_threshold) * 255), 255,\n            cv2.THRESH_BINARY)\n        eroded = cv2.erode(\n            thresholded,\n            cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)))\n        imglog.imwrite(""absdiff_threshold"", thresholded)\n        imglog.imwrite(""absdiff_threshold_erode"", eroded)\n\n        out_region = pixel_bounding_box(eroded)\n        if out_region:\n            # Undo cv2.erode above:\n            out_region = out_region.extend(x=-1, y=-1)\n            # Undo crop:\n            out_region = out_region.translate(region)\n\n        motion = bool(out_region)\n        if motion:\n            # Only update the comparison frame if it\'s different to the previous\n            # one.  This makes `detect_motion` more sensitive to slow motion\n            # because the differences between frames 1 and 2 might be small and\n            # the differences between frames 2 and 3 might be small but we\'d see\n            # the difference by looking between 1 and 3.\n            previous_frame_gray = frame_gray\n\n        result = MotionResult(getattr(frame, ""time"", None), motion,\n                              out_region, frame)\n        draw_on(frame, result, label=""detect_motion()"")\n        debug(""%s found: %s"" % (\n            ""Motion"" if motion else ""No motion"", str(result)))\n        _log_motion_image_debug(imglog, result)\n        yield result\n\n\ndef wait_for_motion(\n        timeout_secs=10, consecutive_frames=None,\n        noise_threshold=None, mask=None, region=Region.ALL, frames=None):\n    """"""Search for motion in the device-under-test\'s video stream.\n\n    ""Motion"" is difference in pixel values between two frames.\n\n    :type timeout_secs: int or float or None\n    :param timeout_secs:\n        A timeout in seconds. This function will raise `MotionTimeout` if no\n        motion is detected within this time.\n\n    :type consecutive_frames: int or str\n    :param consecutive_frames:\n        Considers the video stream to have motion if there were differences\n        between the specified number of consecutive frames. This can be:\n\n        * a positive integer value, or\n        * a string in the form ""x/y"", where ""x"" is the number of frames with\n          motion detected out of a sliding window of ""y"" frames.\n\n        This defaults to ""10/20"". You can override the global default value by\n        setting ``consecutive_frames`` in the ``[motion]`` section of\n        :ref:`.stbt.conf`.\n\n    :param float noise_threshold: See `detect_motion`.\n\n    :param mask: See `detect_motion`.\n\n    :param region: See `detect_motion`.\n\n    :param frames: See `detect_motion`.\n\n    :returns: `MotionResult` when motion is detected. The MotionResult\'s\n        ``time`` and ``frame`` attributes correspond to the first frame in\n        which motion was detected.\n    :raises: `MotionTimeout` if no motion is detected after ``timeout_secs``\n        seconds.\n    """"""\n    if frames is None:\n        import stbt\n        frames = stbt.frames()\n\n    if consecutive_frames is None:\n        consecutive_frames = get_config(\'motion\', \'consecutive_frames\')\n\n    consecutive_frames = str(consecutive_frames)\n    if \'/\' in consecutive_frames:\n        motion_frames = int(consecutive_frames.split(\'/\')[0])\n        considered_frames = int(consecutive_frames.split(\'/\')[1])\n    else:\n        motion_frames = int(consecutive_frames)\n        considered_frames = int(consecutive_frames)\n\n    if motion_frames > considered_frames:\n        raise ConfigurationError(\n            ""`motion_frames` exceeds `considered_frames`"")\n\n    debug(""Waiting for %d out of %d frames with motion"" % (\n        motion_frames, considered_frames))\n\n    if mask is None:\n        mask = _ImageFromUser(None, None, None)\n    else:\n        mask = _load_image(mask, cv2.IMREAD_GRAYSCALE)\n        debug(""Using mask %s"" % mask.friendly_name)\n\n    matches = deque(maxlen=considered_frames)\n    motion_count = 0\n    last_frame = None\n    for res in detect_motion(\n            timeout_secs, noise_threshold, mask, region, frames):\n        motion_count += bool(res)\n        if len(matches) == matches.maxlen:\n            motion_count -= bool(matches.popleft())\n        matches.append(res)\n        if motion_count >= motion_frames:\n            debug(""Motion detected."")\n            # We want to return the first True motion result as this is when\n            # the motion actually started.\n            for result in matches:\n                if result:\n                    return result\n            assert False, (""Logic error in wait_for_motion: This code ""\n                           ""should never be reached"")\n        last_frame = res.frame\n\n    raise MotionTimeout(last_frame, mask.friendly_name, timeout_secs)\n\n\nclass MotionResult(object):\n    """"""The result from `detect_motion` and `wait_for_motion`.\n\n    :ivar float time: The time at which the video-frame was captured, in\n        seconds since 1970-01-01T00:00Z. This timestamp can be compared with\n        system time (``time.time()``).\n\n    :ivar bool motion: True if motion was found. This is the same as evaluating\n        ``MotionResult`` as a bool. That is, ``if result:`` will behave the\n        same as ``if result.motion:``.\n\n    :ivar Region region: Bounding box where the motion was found, or ``None``\n        if no motion was found.\n\n    :ivar Frame frame: The video frame in which motion was (or wasn\'t) found.\n    """"""\n    _fields = (""time"", ""motion"", ""region"", ""frame"")\n\n    def __init__(self, time, motion, region, frame):\n        self.time = time\n        self.motion = motion\n        self.region = region\n        self.frame = frame\n\n    def __bool__(self):\n        return self.motion\n\n    def __repr__(self):\n        return (\n            ""MotionResult(time=%s, motion=%r, region=%r, frame=%s)"" % (\n                ""None"" if self.time is None else ""%.3f"" % self.time,\n                self.motion, self.region, _frame_repr(self.frame)))\n\n\nclass MotionTimeout(UITestFailure):\n    """"""Exception raised by `wait_for_motion`.\n\n    :ivar Frame screenshot: The last video frame that `wait_for_motion` checked\n        before timing out.\n\n    :vartype mask: str or None\n    :ivar mask: Filename of the mask that was used, if any.\n\n    :vartype timeout_secs: int or float\n    :ivar timeout_secs: Number of seconds that motion was searched for.\n    """"""\n    def __init__(self, screenshot, mask, timeout_secs):\n        super(MotionTimeout, self).__init__()\n        self.screenshot = screenshot\n        self.mask = mask\n        self.timeout_secs = timeout_secs\n\n    def __str__(self):\n        return ""Didn\'t find motion%s within %g seconds."" % (\n            "" (with mask \'%s\')"" % self.mask if self.mask else """",\n            self.timeout_secs)\n\n\ndef _log_motion_image_debug(imglog, result):\n    if not imglog.enabled:\n        return\n\n    template = u""""""\\\n        <h4>\n          detect_motion:\n          {{ ""Found"" if result.motion else ""Didn\'t find"" }} motion\n        </h4>\n\n        {{ annotated_image(result) }}\n\n        <h5>ROI Gray:</h5>\n        <img src=""gray.png"" />\n\n        <h5>Previous frame ROI Gray:</h5>\n        <img src=""previous_frame_gray.png"" />\n\n        <h5>Absolute difference:</h5>\n        <img src=""absdiff.png"" />\n\n        {% if ""mask"" in images %}\n        <h5>Mask:</h5>\n        <img src=""mask.png"" />\n        <h5>Absolute difference \xe2\x80\x93 masked:</h5>\n        <img src=""absdiff_masked.png"" />\n        {% endif %}\n\n        <h5>Threshold (noise_threshold={{noise_threshold}}):</h5>\n        <img src=""absdiff_threshold.png"" />\n\n        <h5>Eroded:</h5>\n        <img src=""absdiff_threshold_erode.png"" />\n    """"""\n\n    imglog.html(template, result=result)\n'"
_stbt/ocr.py,0,"b'# coding: utf-8\n\nfrom __future__ import division\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport errno\nimport glob\nimport os\nimport re\nimport subprocess\nfrom distutils.version import LooseVersion\nfrom enum import IntEnum\n\nimport cv2\nimport numpy\n\nfrom . import imgproc_cache\nfrom .config import get_config\nfrom .imgutils import _frame_repr, _image_region, crop\nfrom .logging import debug, ImageLogger, warn\nfrom .types import Region\nfrom .utils import (\n    basestring, named_temporary_directory, native_int, native_str, text_type,\n    to_unicode)\n\n# Tesseract sometimes has a hard job distinguishing certain glyphs such as\n# ligatures and different forms of the same punctuation.  We strip out this\n# superfluous information improving matching accuracy with minimal effect on\n# meaning.  This means that stbt.ocr give much more consistent results.\n_ocr_replacements = {\n    # Ligatures\n    u\'\xef\xac\x80\': u\'ff\',\n    u\'\xef\xac\x81\': u\'fi\',\n    u\'\xef\xac\x82\': u\'fl\',\n    u\'\xef\xac\x83\': u\'ffi\',\n    u\'\xef\xac\x84\': u\'ffl\',\n    u\'\xef\xac\x85\': u\'ft\',\n    u\'\xef\xac\x86\': u\'st\',\n    # Punctuation\n    u\'\xe2\x80\x9c\': u\'""\',\n    u\'\xe2\x80\x9d\': u\'""\',\n    u\'\xe2\x80\x98\': u\'\\\'\',\n    u\'\xe2\x80\x99\': u\'\\\'\',\n    # These are actually different glyphs!:\n    u\'\xe2\x80\x90\': u\'-\',\n    u\'\xe2\x80\x91\': u\'-\',\n    u\'\xe2\x80\x92\': u\'-\',\n    u\'\xe2\x80\x93\': u\'-\',\n    u\'\xe2\x80\x94\': u\'-\',\n    u\'\xe2\x80\x95\': u\'-\',\n}\n_ocr_transtab = dict((ord(amb), to) for amb, to in _ocr_replacements.items())\n\n\nclass OcrMode(IntEnum):\n    """"""Options to control layout analysis and assume a certain form of image.\n\n    For a (brief) description of each option, see the `tesseract(1)\n    <https://github.com/tesseract-ocr/tesseract/blob/3.04.01/doc/tesseract.1.asc#options>`__\n    man page.\n    """"""\n    ORIENTATION_AND_SCRIPT_DETECTION_ONLY = 0\n    PAGE_SEGMENTATION_WITH_OSD = 1\n    PAGE_SEGMENTATION_WITHOUT_OSD_OR_OCR = 2\n    PAGE_SEGMENTATION_WITHOUT_OSD = 3\n    SINGLE_COLUMN_OF_TEXT_OF_VARIABLE_SIZES = 4\n    SINGLE_UNIFORM_BLOCK_OF_VERTICALLY_ALIGNED_TEXT = 5\n    SINGLE_UNIFORM_BLOCK_OF_TEXT = 6\n    SINGLE_LINE = 7\n    SINGLE_WORD = 8\n    SINGLE_WORD_IN_A_CIRCLE = 9\n    SINGLE_CHARACTER = 10\n    SPARSE_TEXT = 11\n    SPARSE_TEXT_WITH_OSD = 12\n    RAW_LINE = 13\n\n    # For nicer formatting of `ocr` signature in generated API documentation:\n    def __repr__(self):\n        return native_str(self)\n\n\nclass OcrEngine(IntEnum):\n\n    #: Tesseract\'s ""legacy"" OCR engine (v3). Recommended.\n    TESSERACT = 0\n\n    #: Tesseract v4\'s ""Long Short-Term Memory"" neural network. Not recommended\n    #: for reading menus, buttons, prices, numbers, times, etc, because it\n    #: hallucinates text that isn\'t there when the input isn\'t long prose.\n    LSTM = 1\n\n    #: Combine results from Tesseract legacy & LSTM engines. Not recommended\n    #: because it favours the result from the LSTM engine too heavily.\n    TESSERACT_AND_LSTM = 2\n\n    #: Default engine, based on what is installed.\n    DEFAULT = 3\n\n    def __repr__(self):\n        return native_str(self)\n\n\nclass TextMatchResult(object):\n    """"""The result from `match_text`.\n\n    :ivar float time: The time at which the video-frame was captured, in\n        seconds since 1970-01-01T00:00Z. This timestamp can be compared with\n        system time (``time.time()``).\n\n    :ivar bool match: True if a match was found. This is the same as evaluating\n        ``MatchResult`` as a bool. That is, ``if result:`` will behave the same\n        as ``if result.match:``.\n\n    :ivar Region region: Bounding box where the text was found, or ``None`` if\n        the text wasn\'t found.\n\n    :ivar Frame frame: The video frame that was searched, as given to\n        `match_text`.\n\n    :ivar str text: The text that was searched for, as given to\n        `match_text`.\n    """"""\n    _fields = (""time"", ""match"", ""region"", ""frame"", ""text"")\n\n    def __init__(self, time, match, region, frame, text):\n        self.time = time\n        self.match = match\n        self.region = region\n        self.frame = frame\n        self.text = text\n\n    # pylint:disable=no-member\n    def __bool__(self):\n        return self.match\n\n    def __repr__(self):\n        return (\n            ""TextMatchResult(time=%s, match=%r, region=%r, frame=%s, ""\n            ""text=%r)"" % (\n                ""None"" if self.time is None else ""%.3f"" % self.time,\n                self.match,\n                self.region,\n                _frame_repr(self.frame),\n                self.text))\n\n\ndef ocr(frame=None, region=Region.ALL,\n        mode=OcrMode.PAGE_SEGMENTATION_WITHOUT_OSD,\n        lang=None, tesseract_config=None, tesseract_user_words=None,\n        tesseract_user_patterns=None, upsample=True, text_color=None,\n        text_color_threshold=None, engine=None, char_whitelist=None,\n        corrections=None):\n    r""""""Return the text present in the video frame as a Unicode string.\n\n    Perform OCR (Optical Character Recognition) using the ""Tesseract""\n    open-source OCR engine.\n\n    :param frame:\n      If this is specified it is used as the video frame to process; otherwise\n      a new frame is grabbed from the device-under-test. This is an image in\n      OpenCV format (for example as returned by `frames` and `get_frame`).\n\n    :param region: Only search within the specified region of the video frame.\n    :type region: `Region`\n\n    :param mode: Tesseract\'s layout analysis mode.\n    :type mode: `OcrMode`\n\n    :param str lang:\n        The three-letter\n        `ISO-639-3 <http://www.loc.gov/standards/iso639-2/php/code_list.php>`__\n        language code of the language you are attempting to read; for example\n        ""eng"" for English or ""deu"" for German. More than one language can be\n        specified by joining with \'+\'; for example ""eng+deu"" means that the\n        text to be read may be in a mixture of English and German. This defaults\n        to ""eng"" (English). You can override the global default value by setting\n        ``lang`` in the ``[ocr]`` section of :ref:`.stbt.conf`. You may need to\n        install the tesseract language pack; see installation instructions\n        `here <https://stb-tester.com/manual/troubleshooting#install-ocr-language-pack>`__.\n\n    :param dict tesseract_config:\n        Allows passing configuration down to the underlying OCR engine.\n        See the `tesseract documentation\n        <https://github.com/tesseract-ocr/tesseract/wiki/ControlParams>`__\n        for details.\n\n    :type tesseract_user_words: unicode string, or list of unicode strings\n    :param tesseract_user_words:\n        List of words to be added to the tesseract dictionary. To replace the\n        tesseract system dictionary altogether, also set\n        ``tesseract_config={\'load_system_dawg\': False, \'load_freq_dawg\':\n        False}``.\n\n    :type tesseract_user_patterns: unicode string, or list of unicode strings\n    :param tesseract_user_patterns:\n        List of patterns to add to the tesseract dictionary. The tesseract\n        pattern language corresponds roughly to the following regular\n        expressions::\n\n            tesseract  regex\n            =========  ===========\n            \\c         [a-zA-Z]\n            \\d         [0-9]\n            \\n         [a-zA-Z0-9]\n            \\p         [:punct:]\n            \\a         [a-z]\n            \\A         [A-Z]\n            \\*         *\n\n    :param bool upsample:\n        Upsample the image 3x before passing it to tesseract. This helps to\n        preserve information in the text\'s anti-aliasing that would otherwise\n        be lost when tesseract binarises the image. This defaults to ``True``;\n        you should only disable it if you are doing your own pre-processing on\n        the image.\n\n    :type text_color: 3-element tuple of integers between 0 and 255, BGR order\n    :param text_color:\n        Color of the text. Specifying this can improve OCR results when\n        tesseract\'s default thresholding algorithm doesn\'t detect the text,\n        for example white text on a light-colored background or text on a\n        translucent overlay.\n\n    :param int text_color_threshold:\n        The threshold to use with ``text_color``, between 0 and 255. Defaults\n        to 25. You can override the global default value by setting\n        ``text_color_threshold`` in the ``[ocr]`` section of :ref:`.stbt.conf`.\n\n    :param engine:\n        The OCR engine to use. Defaults to ``OcrEngine.TESSERACT``. You can\n        override the global default value by setting ``engine`` in the ``[ocr]``\n        section of :ref:`.stbt.conf`.\n    :type engine: `OcrEngine`\n\n    :type char_whitelist: unicode string\n    :param char_whitelist:\n        String of characters that are allowed. Useful when you know that the\n        text is only going to contain numbers or IP addresses, for example so\n        that tesseract won\'t think that a zero is the letter o.\n        Note that Tesseract 4.0\'s LSTM engine ignores ``char_whitelist``.\n\n    :param dict corrections:\n        Dictionary of corrections to replace known OCR mis-reads. Each key of\n        the dict is the text to search for; the value is the corrected string\n        to replace the matching key. If the key is a string, it is treated as\n        plain text and it will only match at word boundaries (for example the\n        string ``""he saw""`` won\'t match ``""the saw""`` nor ``""he saws""``). If\n        the key is a regular expression pattern (created with `re.compile`) it\n        can match anywhere, and the replacement string can contain\n        backreferences such as ``""\\1""`` which are replaced with the\n        corresponding group in the pattern (same as Python\'s `re.sub`).\n        Example::\n\n            corrections={\'bad\': \'good\',\n                         re.compile(r\'[oO]\'): \'0\'}\n\n        Plain strings are replaced first (in the order they are specified),\n        followed by regular expresions (in the order they are specified).\n\n        The default value for this parameter can be set with\n        `stbt.set_global_ocr_corrections`. If global corrections have been set\n        *and* this ``corrections`` parameter is specified, the corrections in\n        this parameter are applied first.\n\n    | Added in v30: The ``engine`` parameter and support for Tesseract v4.\n    | Added in v31: The ``char_whitelist`` parameter.\n    | Added in v32: The ``corrections`` parameter.\n    """"""\n    if frame is None:\n        import stbt\n        frame = stbt.get_frame()\n\n    if region is None:\n        raise TypeError(\n            ""Passing region=None to ocr is deprecated since v0.21. ""\n            ""In a future version, region=None will mean an empty region ""\n            ""instead. To OCR an entire video frame, use ""\n            ""`region=Region.ALL`."")\n\n    if isinstance(tesseract_user_words, (bytes, str)):\n        tesseract_user_words = [tesseract_user_words]\n\n    if isinstance(tesseract_user_patterns, (bytes, str)):\n        tesseract_user_patterns = [tesseract_user_patterns]\n\n    imglog = ImageLogger(""ocr"", result=None)\n\n    text, region = _tesseract(\n        frame, region, mode, lang, tesseract_config,\n        tesseract_user_patterns, tesseract_user_words, upsample, text_color,\n        text_color_threshold, engine, char_whitelist, imglog)\n    text = text.strip().translate(_ocr_transtab)\n    text = apply_ocr_corrections(text, corrections)\n\n    debug(u""OCR in region %s read \'%s\'."" % (region, text))\n    _log_ocr_image_debug(imglog, text)\n    return text\n\n\ndef match_text(text, frame=None, region=Region.ALL,\n               mode=OcrMode.PAGE_SEGMENTATION_WITHOUT_OSD, lang=None,\n               tesseract_config=None, case_sensitive=False, upsample=True,\n               text_color=None, text_color_threshold=None,\n               engine=None, char_whitelist=None):\n    """"""Search for the specified text in a single video frame.\n\n    This can be used as an alternative to `match`, searching for text instead\n    of an image.\n\n    :param str text: The text to search for.\n    :param frame: See `ocr`.\n    :param region: See `ocr`.\n    :param mode: See `ocr`.\n    :param lang: See `ocr`.\n    :param tesseract_config: See `ocr`.\n    :param upsample: See `ocr`.\n    :param text_color: See `ocr`.\n    :param text_color_threshold: See `ocr`.\n    :param engine: See `ocr`.\n    :param char_whitelist: See `ocr`.\n    :param bool case_sensitive: Ignore case if False (the default).\n\n    :returns:\n      A `TextMatchResult`, which will evaluate to True if the text was found,\n      false otherwise.\n\n    For example, to select a button in a vertical menu by name (in this case\n    ""TV Guide"")::\n\n        m = stbt.match_text(""TV Guide"")\n        assert m.match\n        while not stbt.match(\'selected-button.png\').region.contains(m.region):\n            stbt.press(\'KEY_DOWN\')\n\n    | Added in v30: The ``engine`` parameter and support for Tesseract v4.\n    | Added in v31: The ``char_whitelist`` parameter.\n    """"""\n    import lxml.etree\n    if frame is None:\n        import stbt\n        frame = stbt.get_frame()\n\n    _config = dict(tesseract_config or {})\n    _config[\'tessedit_create_hocr\'] = 1\n\n    rts = getattr(frame, ""time"", None)\n\n    imglog = ImageLogger(""match_text"")\n\n    xml, region = _tesseract(frame, region, mode, lang, _config,\n                             None, text.split(), upsample, text_color,\n                             text_color_threshold, engine, char_whitelist,\n                             imglog)\n    if xml == \'\':\n        hocr = None\n        result = TextMatchResult(rts, False, None, frame, text)\n    else:\n        hocr = lxml.etree.fromstring(xml.encode(\'utf-8\'))\n        p = _hocr_find_phrase(hocr, to_unicode(text).split(), case_sensitive)\n        if p:\n            # Find bounding box\n            box = None\n            for _, elem in p:\n                box = Region.bounding_box(box, _hocr_elem_region(elem))\n            # _tesseract crops to region and scales up by a factor of 3 so\n            # we must undo this transformation here.\n            n = 3 if upsample else 1\n            box = Region.from_extents(\n                region.x + box.x // n, region.y + box.y // n,\n                region.x + box.right // n, region.y + box.bottom // n)\n            result = TextMatchResult(rts, True, box, frame, text)\n        else:\n            result = TextMatchResult(rts, False, None, frame, text)\n\n    if result.match:\n        debug(""match_text: Match found: %s"" % str(result))\n    else:\n        debug(""match_text: No match found: %s"" % str(result))\n\n    imglog.set(text=text, case_sensitive=case_sensitive,\n               result=result, hocr=hocr)\n    _log_ocr_image_debug(imglog)\n\n    return result\n\n\n# Python 2.7 & 3.6 have `re._pattern_type` but that will be removed in Python\n# 3.7 where they introduce `re.Pattern`.\nPatternType = type(re.compile(""""))\n\n\ndef apply_ocr_corrections(text, corrections=None):\n    """"""Applies the same corrections as `stbt.ocr`\'s ``corrections`` parameter.\n\n    This is also available as a separate function, so that you can use it to\n    post-process old test artifacts using new corrections. See also\n    `stbt.set_global_ocr_corrections`.\n    """"""\n    if corrections:\n        text = _apply_ocr_corrections(text, corrections)\n    if global_ocr_corrections:\n        text = _apply_ocr_corrections(text, global_ocr_corrections)\n    return text\n\n\ndef _apply_ocr_corrections(text, corrections):\n    # Match plain strings at word boundaries:\n    pattern = ""|"".join(r""\\b("" + re.escape(k) + r"")\\b""\n                       for k in corrections\n                       if isinstance(k, basestring))\n    if pattern:\n        replace = lambda matchobj: corrections[matchobj.group(0)]\n        text = re.sub(pattern, replace, text)\n    # Match regexes:\n    for k, v in corrections.items():\n        if isinstance(k, PatternType):\n            text = re.sub(k, v, text)\n    return text\n\n\nglobal_ocr_corrections = {}\n\n\ndef set_global_ocr_corrections(corrections):\n    """"""Specify default OCR corrections that apply to all calls to `stbt.ocr`\n    and `stbt.apply_ocr_corrections`.\n\n    See the ``corrections`` parameter of `stbt.ocr` for more details.\n\n    We recommend calling this function from ``tests/__init__.py`` to ensure it\n    is called before any test script is executed.\n    """"""\n    global global_ocr_corrections\n    debug(""Initialising global ocr corrections to: %r"" % (corrections,))\n    global_ocr_corrections = corrections\n\n\n_memoise_tesseract_version = None\n\n\ndef _tesseract_version(output=None):\n    r""""""Different versions of tesseract have different bugs.  This function\n    allows us to tell the user if what they want isn\'t going to work.\n\n    >>> (_tesseract_version(\'tesseract 3.03\\n leptonica-1.70\\n\') >\n    ...  _tesseract_version(\'tesseract 3.02\\n\'))\n    True\n\n    Note that LooseVersion.__cmp__ simply sorts lexicographically according\n    to the ""."" or ""-"" separated components in the version string:\n\n    >>> _tesseract_version(""tesseract 4.0.0-beta.1"").version\n    [4, 0, 0, \'-\', \'beta\', 1]\n    >>> (_tesseract_version(\'tesseract 4.0.0-beta.1\') >\n    ...  _tesseract_version(\'tesseract 4.0.0\'))\n    True\n\n    """"""\n    global _memoise_tesseract_version\n    if output is None:\n        if _memoise_tesseract_version is None:\n            try:\n                _memoise_tesseract_version = subprocess.check_output(\n                    [\'tesseract\', \'--version\'],\n                    stderr=subprocess.STDOUT).decode(""utf-8"")\n            except OSError as e:\n                if e.errno == errno.ENOENT:\n                    raise RuntimeError(""Tesseract OCR engine isn\'t installed"")\n                else:\n                    raise\n        output = _memoise_tesseract_version\n\n    line = [x for x in output.split(\'\\n\') if x.startswith(\'tesseract\')][0]\n    return LooseVersion(line.split()[1])\n\n\ndef _tesseract(frame, region, mode, lang, _config, user_patterns, user_words,\n               upsample, text_color, text_color_threshold, engine,\n               char_whitelist, imglog):\n\n    if _config is None:\n        _config = {}\n\n    if lang is None:\n        lang = get_config(""ocr"", ""lang"", ""eng"")\n\n    if text_color_threshold is None:\n        text_color_threshold = get_config(\n            ""ocr"", ""text_color_threshold"", type_=int)\n\n    if engine is None:\n        engine = get_config(""ocr"", ""engine"", type_=OcrEngine)\n\n    tesseract_version = _tesseract_version()\n\n    if tesseract_version < LooseVersion(""4.0""):\n        if engine == OcrEngine.DEFAULT:\n            engine = OcrEngine.TESSERACT\n        if engine != OcrEngine.TESSERACT:\n            # NB `str(engine)` looks like ""OcrEngine.LSTM""\n            raise ValueError(""%s isn\'t available in tesseract %s""\n                             % (engine, tesseract_version))\n\n    if mode >= OcrMode.RAW_LINE and tesseract_version < LooseVersion(""3.04""):\n        # NB `str(mode)` looks like ""OcrMode.RAW_LINE""\n        raise ValueError(""%s isn\'t available in tesseract %s""\n                         % (mode, tesseract_version))\n\n    imglog.imwrite(""source"", frame)\n    imglog.set(engine=engine, mode=mode, lang=lang,\n               tesseract_config=_config.copy(),\n               user_patterns=user_patterns, user_words=user_words,\n               upsample=upsample, text_color=text_color,\n               text_color_threshold=text_color_threshold,\n               char_whitelist=char_whitelist,\n               tesseract_version=tesseract_version)\n\n    frame_region = _image_region(frame)\n    intersection = Region.intersect(frame_region, region)\n    if intersection is None:\n        warn(""Requested OCR in region %s which doesn\'t overlap with ""\n             ""the frame %s"" % (str(region), frame_region))\n        imglog.set(region=None)\n        return (u\'\', None)\n    else:\n        region = intersection\n        imglog.set(region=region)\n\n    return (_tesseract_subprocess(crop(frame, region), mode, lang, _config,\n                                  user_patterns, user_words, upsample,\n                                  text_color, text_color_threshold, engine,\n                                  char_whitelist, imglog, tesseract_version),\n            region)\n\n\n@imgproc_cache.memoize({""version"": ""31""})\ndef _tesseract_subprocess(\n        frame, mode, lang, _config, user_patterns, user_words, upsample,\n        text_color, text_color_threshold, engine, char_whitelist,\n        imglog, tesseract_version):\n\n    if tesseract_version >= LooseVersion(""4.0""):\n        engine_flags = [""--oem"", str(int(engine))]\n        tessdata_suffix = \'\'\n    else:\n        engine_flags = []\n        tessdata_suffix = \'/tessdata\'\n\n    if upsample:\n        # We scale image up 3x before feeding it to tesseract as this\n        # significantly reduces the error rate by more than 6x in tests.  This\n        # uses bilinear interpolation which produces the best results.  See\n        # http://stb-tester.com/blog/2014/04/14/improving-ocr-accuracy.html\n        outsize = (frame.shape[1] * 3, frame.shape[0] * 3)\n        frame = cv2.resize(frame, outsize, interpolation=cv2.INTER_LINEAR)\n        imglog.imwrite(""upsampled"", frame)\n\n    if text_color is not None:\n        # Calculate distance of each pixel from `text_color`, then discard\n        # everything further than `text_color_threshold` distance away.\n        diff = numpy.subtract(frame, text_color, dtype=numpy.int32)\n        frame = numpy.sqrt((diff[:, :, 0] ** 2 +\n                            diff[:, :, 1] ** 2 +\n                            diff[:, :, 2] ** 2) // 3) \\\n                     .astype(numpy.uint8)\n        imglog.imwrite(""text_color_difference"", frame)\n        _, frame = cv2.threshold(frame, text_color_threshold, 255,\n                                 cv2.THRESH_BINARY)\n        imglog.imwrite(""text_color_threshold"", frame)\n\n    # $XDG_RUNTIME_DIR is likely to be on tmpfs:\n    tmpdir = os.environ.get(""XDG_RUNTIME_DIR"", None)\n\n    with named_temporary_directory(prefix=\'stbt-ocr-\', dir=tmpdir) as tmp:\n\n        if tesseract_version >= LooseVersion(""3.05""):\n            psm_flag = ""--psm""\n        else:\n            psm_flag = ""-psm""\n\n        cmd = [""tesseract"", \'-l\', lang,\n               tmp + \'/input.png\',\n               tmp + \'/output\',\n               psm_flag, str(int(mode))] + engine_flags\n\n        tessenv = os.environ.copy()\n\n        if (_config or user_words or user_patterns or char_whitelist or\n                imglog.enabled):\n            tessdata_dir = tmp + \'/tessdata\'\n            os.mkdir(tessdata_dir)\n            _symlink_copy_dir(_find_tessdata_dir(tessdata_suffix), tmp)\n            tessenv[\'TESSDATA_PREFIX\'] = tmp + \'/\'\n            if tesseract_version >= LooseVersion(""4.0.0""):\n                tessenv[\'TESSDATA_PREFIX\'] += ""tessdata""\n\n        if (\'tessedit_create_hocr\' in _config and\n                tesseract_version >= LooseVersion(\'3.04\')):\n            _config[\'tessedit_create_txt\'] = 0\n\n        if user_words:\n            if \'user_words_suffix\' in _config:\n                raise ValueError(\n                    ""You cannot specify \'user_words\' and "" +\n                    ""\'tesseract_config[\\""user_words_suffix\\""]\' "" +\n                    ""at the same time"")\n            with open(\'%s/%s.user-words\' % (tessdata_dir, lang), \'w\') as f:\n                f.write(\'\\n\'.join(to_unicode(x) for x in user_words))\n            _config[\'user_words_suffix\'] = \'user-words\'\n\n        if user_patterns:\n            if \'user_patterns_suffix\' in _config:\n                raise ValueError(\n                    ""You cannot specify \'user_patterns\' and "" +\n                    ""\'tesseract_config[\\""user_patterns_suffix\\""]\' "" +\n                    ""at the same time"")\n            with open(\'%s/%s.user-patterns\' % (tessdata_dir, lang), \'w\') as f:\n                f.write(\'\\n\'.join(to_unicode(x) for x in user_patterns))\n            _config[\'user_patterns_suffix\'] = \'user-patterns\'\n\n        if char_whitelist:\n            if \'tessedit_char_whitelist\' in _config:\n                raise ValueError(\n                    ""You cannot specify \'char_whitelist\' and "" +\n                    ""\'tesseract_config[\\""tessedit_char_whitelist\\""]\' "" +\n                    ""at the same time"")\n            _config[""tessedit_char_whitelist""] = char_whitelist\n\n        if imglog.enabled:\n            _config[\'tessedit_write_images\'] = True\n\n        if _config:\n            with open(tessdata_dir + \'/configs/stbtester\', \'w\') as cfg:\n                for k, v in _config.items():\n                    if isinstance(v, bool):\n                        cfg.write((\'%s %s\\n\' % (k, \'T\' if v else \'F\')))\n                    else:\n                        cfg.write(""%s %s\\n"" % (k, to_unicode(v)))\n            cmd += [\'stbtester\']\n\n        cv2.imwrite(tmp + \'/input.png\', frame)\n        try:\n            subprocess.check_output(cmd, cwd=tmp, env=tessenv,\n                                    stderr=subprocess.STDOUT)\n        except subprocess.CalledProcessError as e:\n            warn(""Tesseract failed: %s"" % e.output.decode(""utf-8"", ""replace""))\n            raise\n\n        if imglog.enabled:\n            tessinput = os.path.join(tmp, ""tessinput.tif"")\n            if os.path.exists(tessinput):\n                imglog.imwrite(""tessinput"", cv2.imread(tessinput))\n\n        for filename in glob.glob(tmp + ""/output.*""):\n            _, ext = os.path.splitext(filename)\n            if ext == "".txt"" or ext == "".hocr"":\n                with open(filename) as f:\n                    return f.read()\n\n\ndef _hocr_iterate(hocr):\n    started = False\n    need_space = False\n    for elem in hocr.iterdescendants():\n        if elem.tag == \'{http://www.w3.org/1999/xhtml}p\' and started:\n            yield (u\'\\n\', elem)\n            need_space = False\n        if elem.tag == \'{http://www.w3.org/1999/xhtml}span\' and \\\n                \'ocr_line\' in elem.get(\'class\').split() and started:\n            yield (u\'\\n\', elem)\n            need_space = False\n        for e, t in [(elem, elem.text), (elem.getparent(), elem.tail)]:\n            if t:\n                if t.strip():\n                    if need_space and started:\n                        yield (u\' \', None)\n                    need_space = False\n                    yield (text_type(t).strip(), e)\n                    started = True\n                else:\n                    need_space = True\n\n\ndef _hocr_find_phrase(hocr, phrase, case_sensitive):\n    if case_sensitive:\n        lower = lambda s: s\n    else:\n        lower = lambda s: s.lower()\n\n    words_only = [(lower(w).translate(_ocr_transtab), elem)\n                  for w, elem in _hocr_iterate(hocr) if w.strip() != u\'\']\n    phrase = [lower(w).translate(_ocr_transtab) for w in phrase]\n\n    # Dumb and poor algorithmic complexity but succint and simple\n    if len(phrase) <= len(words_only):\n        for x in range(0, len(words_only)):\n            sublist = words_only[x:x + len(phrase)]\n            if all(w[0] == p for w, p in zip(sublist, phrase)):\n                return sublist\n    return None\n\n\ndef _hocr_elem_region(elem):\n    while elem is not None:\n        m = re.search(r\'bbox (\\d+) (\\d+) (\\d+) (\\d+)\', elem.get(\'title\') or u\'\')\n        if m:\n            extents = [native_int(x) for x in m.groups()]\n            return Region.from_extents(*extents)\n        elem = elem.getparent()\n\n\ndef _find_tessdata_dir(tessdata_suffix):\n    from distutils.spawn import find_executable\n\n    tessdata_prefix = os.environ.get(""TESSDATA_PREFIX"", None)\n    if tessdata_prefix:\n        tessdata = tessdata_prefix + tessdata_suffix\n        tessdata = os.path.normpath(tessdata)\n        if os.path.exists(tessdata):\n            return tessdata\n        else:\n            raise RuntimeError(\'Invalid TESSDATA_PREFIX: %s\' % tessdata_prefix)\n\n    tess_prefix_share = os.path.normpath(\n        find_executable(\'tesseract\') + \'/../../share/\')\n    for suffix in [\n            \'/tessdata\', \'/tesseract-ocr/tessdata\', \'/tesseract/tessdata\',\n            \'/tesseract-ocr/4.00/tessdata\']:\n        if os.path.exists(tess_prefix_share + suffix):\n            return tess_prefix_share + suffix\n    raise RuntimeError(\'Installation error: Cannot locate tessdata directory\')\n\n\ndef _log_ocr_image_debug(imglog, output=None):\n    if not imglog.enabled:\n        return\n\n    if imglog.name == ""ocr"":\n        title = ""stbt.ocr""\n        match_text = False  # pylint:disable=redefined-outer-name\n    else:\n        match_text = True\n        title = ""stbt.match_text(%r): %s"" % (\n            imglog.data[""text""],\n            ""Matched"" if imglog.data[""result""] else ""Didn\'t match"")\n        hocr = imglog.data[""hocr""]\n        if hocr is None:\n            output = u""""\n        else:\n            output = u"""".join(x for x, _ in _hocr_iterate(hocr))\n\n    template = u""""""\\\n        <h4>{{title}}</h4>\n\n        {{ annotated_image(result) }}\n\n        {% if match_text %}\n        <h5>Result:</h5>\n        <pre><code>{{ result | escape }}</code></pre>\n        {% endif %}\n\n        <h5>Tesseract output:</h5>\n        <pre><code>{{ output | escape }}</code></pre>\n\n        <h5>Parameters:</h5>\n        <ul>\n          {% if match_text %}\n          <li>case_sensitive={{case_sensitive}}\n          {% endif %}\n          <li>char_whitelist={{char_whitelist}}\n          <li>engine={{engine}}\n          <li>lang={{lang}}\n          <li>mode={{mode}}\n          <li>tesseract_config={{tesseract_config}}\n          <li>tesseract_user_patterns={{user_patterns}}\n          <li>tesseract_user_words={{user_words}}\n          <li>tesseract_version={{tesseract_version}}\n          {% if match_text %}\n          <li>text={{text}}\n          {% endif %}\n          <li>text_color={{text_color}}\n          <li>text_color_threshold={{text_color_threshold}}\n          <li>upsample={{upsample}}\n        </ul>\n\n        {% if ""upsampled"" in images %}\n        <h5>ROI Scaled:</h5>\n        <img src=""upsampled.png"" />\n        {% endif %}\n\n        {% if ""text_color_difference"" in images %}\n        <h5>Color difference {{ text_color }}:</h5>\n        <img src=""text_color_difference.png"" />\n        {% endif %}\n\n        {% if ""text_color_threshold"" in images %}\n        <h5>\n          Color difference \xe2\x80\x93 binarised\n          (threshold={{ text_color_threshold }}):\n        </h5>\n        <img src=""text_color_threshold.png"" />\n        {% endif %}\n\n        {% if ""tessinput"" in images %}\n        <h5>Tesseract\'s binarisation:</h5>\n        <img src=""tessinput.png"" />\n        {% endif %}\n    """"""\n\n    imglog.html(\n        template,\n        match_text=match_text,\n        output=output,\n        title=title,\n    )\n\n\ndef _symlink_copy_dir(a, b):\n    """"""Behaves like `cp -rs` with GNU cp but is portable and doesn\'t require\n    execing another process.  Tesseract requires files in the ""tessdata""\n    directory to be modified to set config options.  tessdata may be on a\n    read-only system directory so we use this to work around that limitation.\n    """"""\n    from os.path import basename, join, relpath\n    newroot = join(b, basename(a))\n    for dirpath, dirnames, filenames in os.walk(a):\n        for name in dirnames:\n            if name not in [\'.\', \'..\']:\n                rel = relpath(join(dirpath, name), a)\n                os.mkdir(join(newroot, rel))\n        for name in filenames:\n            rel = relpath(join(dirpath, name), a)\n            os.symlink(join(a, rel), join(newroot, rel))\n'"
_stbt/power.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport errno\nimport os\nimport re\nimport time\n\nfrom _stbt.config import ConfigurationError\n\n\ndef uri_to_power_outlet(uri):\n    remotes = [\n        (r\'none\', _NoOutlet),\n        (r\'file:(?P<filename>[^:]+)\', _FileOutlet),\n        (r\'aten:(?P<address>[^: ]+):(?P<outlet>[^: ]+)\', _ATEN_PE6108G),\n        (r\'rittal:(?P<address>[^: ]+):(?P<outlet_no>[^: ]+)\'\n         \':(?P<community>[^: ]+)\', _RittalSnmpPower),\n        (r\'(?P<model>pdu|ipp|testfallback):(?P<hostname>[^: ]+)\'\n         \':(?P<outlet>[^: ]+)\', _ShellOutlet),\n        (r\'aviosys-8800-pro(:(?P<filename>[^:]+))?\', _new_aviosys_8800_pro),\n    ]\n    for regex, factory in remotes:\n        m = re.match(regex, uri, re.VERBOSE | re.IGNORECASE)\n        if m:\n            return factory(**m.groupdict())\n    raise ConfigurationError(\'Invalid power outlet URI: ""%s""\' % uri)\n\n\nclass _NoOutlet(object):\n    def set(self, power):\n        if not power:\n            raise RuntimeError(\n                ""Cannot disable power: no power outlet configured"")\n\n    def get(self):\n        # If we can\'t turn it off, it must be on\n        return True\n\n\nclass _FileOutlet(object):\n    """"""Power outlet useful for testing""""""\n    def __init__(self, filename):\n        self.filename = filename\n\n    def set(self, power):\n        with open(self.filename, \'w\') as f:\n            f.write([\'0\', \'1\'][power])\n\n    def get(self):\n        try:\n            with open(self.filename, \'r\') as f:\n                return bool(int(f.read(1)))\n        except IOError as e:\n            if e.errno == errno.ENOENT:\n                return True\n            else:\n                raise\n\n\nclass _ShellOutlet(object):\n    """"""\n    stbt-power used to be written in bash, supporting three different types of\n    hardware.  This is a wrapper to allow the old bash script to continue\n    working until it can be removed entirely.\n    """"""\n    def __init__(self, model, hostname, outlet=None):\n        uri = \'%s:%s:%s\' % (model, hostname, outlet)\n        self.cmd = [\'bash\', os.path.dirname(__file__) + ""/stbt-power.sh"",\n                    \'--power-outlet=%s\' % uri]\n\n    def set(self, power):\n        import subprocess\n        subprocess.check_call(self.cmd + [[""off"", ""on""][power]])\n\n    def get(self):\n        import subprocess\n        power = subprocess.check_output(self.cmd + [""status""]).strip()\n        return {b\'ON\': True, b\'OFF\': False}[power]\n\n\nclass _Aviosys8800Pro(object):\n    """"""Documentation of the serial IO protocol found on the Aviosys website:\n\n    http://www.aviosys.com/downloads/manuals/power/USB%20Net%20Power%208800%20Pro%20Manual_EN.pdf\n\n    >>> f = _FakeAviosys8800ProSerial()\n    >>> u = _Aviosys8800Pro(f)\n    >>> u.get()\n    False\n    >>> u.set(True)\n    >>> f.is_on\n    True\n    >>> u.get()\n    True\n    >>> u.set(False)\n    >>> f.is_on\n    False\n    >>> u.get()\n    False\n    """"""\n    def __init__(self, device):\n        """"""Device is a file-like serial device""""""\n        self.device = device\n\n    def set(self, power):\n        self.device.write(""p1=%i\\n"" % power)\n        self.device.readline()\n\n    def get(self):\n        self.device.write(""readio\\n"")\n        self.device.readline()\n        response = self.device.readline()\n        if response == \'IO:5\\r\\n\':\n            return True\n        elif response == \'IO:0\\r\\n\':\n            return False\n        else:\n            raise RuntimeError(\n                ""Unexpected response from Aviosys 8800 Pro: \\""%s\\""""\n                % response.strip())\n\n\ndef _new_aviosys_8800_pro(filename=\'/dev/ttyACM0\'):\n    import serial\n    return _Aviosys8800Pro(serial.Serial(filename, baudrate=19200))\n\n\nclass _FakeAviosys8800ProSerial(object):\n    r""""""Used for testing the below _UsbPower8800Pro class.  Behaviour determined\n    in interactive ipython shell and reproduced here:\n\n    >>> fup = _FakeAviosys8800ProSerial()\n    >>> fup.is_on\n    False\n    >>> fup.write(""p1=1\\n"")\n    5\n    >>> fup.readline()\n    \'p1=1\\r\\n\'\n    >>> fup.is_on\n    True\n    >>> fup.write(""p1=0\\n"")\n    5\n    >>> fup.readline()\n    \'z>p1=0\\r\\n\'\n    >>> fup.is_on\n    False\n    >>> fup.write(\'readio\\n\')\n    7\n    >>> fup.readline()\n    \'z>readio\\r\\n\'\n    >>> fup.readline()\n    \'IO:0\\r\\n\'\n    >>> fup.write(""p1=1junkjunk\\n"")\n    13\n    >>> fup.readline()\n    \'z>p1=1junkjunk\\r\\n\'\n    >>> fup.write(\'readiojunk\\n\')\n    11\n    >>> fup.readline()\n    \'z>readiojunk\\r\\n\'\n    >>> fup.readline()\n    \'IO:5\\r\\n\'\n    """"""\n    def __init__(self):\n        self.is_on = False\n        self.remainder = """"\n        self.outbuf = """"\n        self.inbuf = """"\n\n    def readline(self):\n        idx = self.outbuf.find(\'\\n\')\n        assert idx >= 0, ""FakeUsbPower8000 would have blocked""\n\n        out, self.outbuf = self.outbuf[:idx + 1], self.outbuf[idx + 1:]\n        return out\n\n    def respond(self, text):\n        self.outbuf += text\n\n    def write(self, data):\n        self.inbuf += data\n\n        while \'\\n\' in self.inbuf:\n            idx = self.inbuf.find(\'\\n\')\n            line, self.inbuf = self.inbuf[:idx], self.inbuf[idx + 1:]\n\n            if len(line) >= 4 and line[:3] == ""p1="":\n                if line[3] == \'0\':\n                    self.is_on = False\n                elif line[3] == \'1\':\n                    self.is_on = True\n            self.respond(line + \'\\r\\n\')\n            if line.startswith(\'readio\'):\n                self.respond(\'IO:%i\\r\\n\' % (5 if self.is_on else 0))\n            self.respond(\'z>\')\n\n        return len(data)\n\n\nclass _RittalSnmpPower(object):\n    """"""\n    Tested with the DK 7955.310.  SNMP OIDs may be different on other devices.\n    """"""\n    def __init__(self, address, outlet_no, community):\n        outlet_no = int(outlet_no)\n        index = outlet_no - 1\n        if index < 0:\n            raise ValueError(""Invalid outlet_no %i.  Min outlet no is 1"" %\n                             outlet_no)\n        self._snmp = _SnmpInteger(\n            address, ""1.3.6.1.4.1.2606.7.4.2.2.1.11.1.%i"" % (52 + index * 7),\n            community)\n\n    def get(self):\n        return bool(self._snmp.get())\n\n    def set(self, power):\n        if self._snmp.set(int(bool(power))) != int(bool(power)):\n            raise RuntimeError(""Setting power failed with unknown error"")\n\n\nclass _ATEN_PE6108G(object):\n    """"""Class to control the ATEN PDU using pysnmp module. """"""\n\n    def __init__(self, address, outlet):\n        outlet = int(outlet)\n        outlet_offset = 1 if outlet <= 8 else 2\n        self._snmp = _SnmpInteger(\n            address, ""1.3.6.1.4.1.21317.1.3.2.2.2.2.%i.0"" % (\n                outlet + outlet_offset),\n            community=\'administrator\')\n\n    def set(self, power):\n        new_state = self._snmp.set(2 if power else 1)\n\n        # ATEN PE6108G outlets take between 4-8 seconds to power on\n        for _ in range(12):\n            time.sleep(1)\n            if self._snmp.get() == new_state:\n                return\n        raise RuntimeError(\n            ""Timeout waiting for outlet to power {}"".format(\n                ""ON"" if power else ""OFF""))\n\n    def get(self):\n        result = self._snmp.get()\n        # 3 represents moving between states\n        return {3: False, 2: True, 1: False}[result]\n\n\nclass _SnmpInteger(object):\n    def __init__(self, address, oid, community):\n        from pysnmp.entity.rfc3413.oneliner.cmdgen import UdpTransportTarget\n        self.oid = oid\n        self._community = community\n        if \':\' in address:\n            address, port = address.split(address, 2)\n        else:\n            port = ""161""\n        self._transport = UdpTransportTarget((address, int(port)))\n\n    def set(self, value):\n        return self._cmd(value)\n\n    def get(self):\n        return self._cmd(None)\n\n    def _cmd(self, value):\n        from pysnmp.entity.rfc3413.oneliner import cmdgen\n        from pysnmp.proto.rfc1905 import NoSuchObject\n        from pysnmp.proto.rfc1902 import Integer\n\n        command_generator = cmdgen.CommandGenerator()\n\n        if value is None:  # `status` command\n            error_ind, _, _, var_binds = command_generator.getCmd(\n                cmdgen.CommunityData(self._community),\n                self._transport,\n                self.oid)\n        else:\n            error_ind, _, _, var_binds = command_generator.setCmd(\n                cmdgen.CommunityData(self._community),\n                self._transport,\n                (self.oid, Integer(value)))\n\n        if error_ind is not None:\n            raise RuntimeError(""SNMP Error ({})"".format(error_ind))\n\n        _, result = var_binds[0]\n\n        if isinstance(result, NoSuchObject):\n            raise RuntimeError(""No such outlet"")\n\n        if not isinstance(result, Integer):\n            raise RuntimeError(""Unexpected result ({})"".format(result))\n\n        return int(result)\n'"
_stbt/precondition.py,0,"b'""""""\nCopyright 2014 YouView TV Ltd.\nLicense: LGPL v2.1 or (at your option) any later version (see\nhttps://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n""""""\n\nimport traceback\nfrom contextlib import contextmanager\n\nfrom .logging import debug\nfrom .types import UITestError, UITestFailure\n\n\nclass PreconditionError(UITestError):\n    """"""Exception raised by `as_precondition`.""""""\n    def __init__(self, message, original_exception):\n        super(PreconditionError, self).__init__()\n        self.message = message\n        self.original_exception = original_exception\n        self.screenshot = None\n\n    def __str__(self):\n        return (\n            ""Didn\'t meet precondition \'%s\' (original exception was: %s)""\n            % (self.message, self.original_exception))\n\n\n@contextmanager\ndef as_precondition(message):\n    """"""Context manager that replaces test failures with test errors.\n\n    Stb-tester\'s reports show test failures (that is, `UITestFailure` or\n    `AssertionError` exceptions) as red results, and test errors (that is,\n    unhandled exceptions of any other type) as yellow results. Note that\n    `wait_for_match`, `wait_for_motion`, and similar functions raise a\n    `UITestFailure` when they detect a failure. By running such functions\n    inside an `as_precondition` context, any `UITestFailure` or\n    `AssertionError` exceptions they raise will be caught, and a\n    `PreconditionError` will be raised instead.\n\n    When running a single testcase hundreds or thousands of times to reproduce\n    an intermittent defect, it is helpful to mark unrelated failures as test\n    errors (yellow) rather than test failures (red), so that you can focus on\n    diagnosing the failures that are most likely to be the particular defect\n    you are looking for. For more details see `Test failures vs. errors\n    <http://stb-tester.com/preconditions>`__.\n\n    :param str message:\n        A description of the precondition. Word this positively: ""Channels\n        tuned"", not ""Failed to tune channels"".\n\n    :raises:\n        `PreconditionError` if the wrapped code block raises a `UITestFailure`\n        or `AssertionError`.\n\n    Example::\n\n        def test_that_the_on_screen_id_is_shown_after_booting():\n            channel = 100\n\n            with stbt.as_precondition(""Tuned to channel %s"" % channel):\n                mainmenu.close_any_open_menu()\n                channels.goto_channel(channel)\n                power.cold_reboot()\n                assert channels.is_on_channel(channel)\n\n            stbt.wait_for_match(""on-screen-id.png"")\n\n    """"""\n    try:\n        yield\n    except (UITestFailure, AssertionError) as original:\n        debug(""stbt.as_precondition caught a %s exception and will ""\n              ""re-raise it as PreconditionError.\\nOriginal exception was:\\n%s""\n              % (type(original).__name__, traceback.format_exc()))\n        exc = PreconditionError(message, original)\n        if hasattr(original, \'screenshot\'):\n            exc.screenshot = original.screenshot  # pylint:disable=no-member\n        raise exc\n'"
_stbt/sqdiff.py,0,"b'from __future__ import division\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport ctypes\nimport os\n\nimport numpy\n\nfrom .logging import debug\n\n\ndef _find_file(path, root=os.path.dirname(os.path.abspath(__file__))):\n    return os.path.join(root, path)\n\n\n_libstbt = ctypes.CDLL(_find_file(""libstbt.so""))\n\n\nclass _SqdiffResult(ctypes.Structure):\n    _fields_ = [(""total"", ctypes.c_uint64),\n                (""count"", ctypes.c_uint32)]\n\n\n# SqdiffResult sqdiff(const uint8_t *t, uint16_t t_stride,\n#                     const uint8_t *f, uint16_t f_stride,\n#                     uint16_t width_px, uint16_t height_px,\n#                     int color_depth)\n\n_libstbt.sqdiff.restype = _SqdiffResult\n_libstbt.sqdiff.argtypes = [\n    ctypes.POINTER(ctypes.c_uint8), ctypes.c_uint16,\n    ctypes.POINTER(ctypes.c_uint8), ctypes.c_uint16,\n    ctypes.c_uint16, ctypes.c_uint16,\n    ctypes.c_int\n]\n\n\nPIXEL_DEPTH_BGR = 1\nPIXEL_DEPTH_BGRx = 2\nPIXEL_DEPTH_BGRA = 3\n\nCOLOR_DEPTH_LOOKUP = {\n    (3, 3): PIXEL_DEPTH_BGR,\n    (4, 3): PIXEL_DEPTH_BGRx,\n    (4, 4): PIXEL_DEPTH_BGRA,\n}\n\n\ndef sqdiff(template, frame):\n    if template.shape[:2] != frame.shape[:2]:\n        raise ValueError(""Template and frame must be the same size"")\n    try:\n        return _sqdiff_c(template, frame)\n    except NotImplementedError as e:\n        debug(""sqdiff Missed fast-path: %s"" % e)\n        return _sqdiff_numpy(template, frame)\n\n\ndef _sqdiff_c(template, frame):\n    if template.dtype != numpy.uint8 or frame.dtype != numpy.uint8:\n        raise NotImplementedError(""dtype must be uint8"")\n\n    if frame.strides[2] != 1 or template.strides[2] != 1 or \\\n            frame.strides[1] != 3:\n        raise NotImplementedError(""Pixel data must be contiguous"")\n\n    color_depth = COLOR_DEPTH_LOOKUP[(template.strides[1], template.shape[2])]\n\n    t = template.ctypes.data_as(ctypes.POINTER(ctypes.c_uint8))\n    f = frame.ctypes.data_as(ctypes.POINTER(ctypes.c_uint8))\n\n    out = _libstbt.sqdiff(t, template.strides[0],\n                          f, frame.strides[0],\n                          template.shape[1], template.shape[0], color_depth)\n    return out.total, out.count\n\n\ndef _sqdiff_numpy(template, frame):\n    template = template.astype(numpy.int64)\n    frame = frame.astype(numpy.int64)\n    if template.shape[2] == 4:\n        # Masked\n        x = ((template[:, :, :3] - frame) ** 2)[template[:, :, 3] == 255]\n    else:\n        x = (template - frame) ** 2\n    return numpy.sum(x), x.size\n\n\ndef _random_template(size=(1280, 720)):\n    tsize = (numpy.random.randint(1, size[0] + 1),\n             numpy.random.randint(1, size[1] + 1))\n    toff = (numpy.random.randint(size[0] - tsize[0] + 1),\n            numpy.random.randint(size[1] - tsize[1] + 1))\n\n    f = numpy.random.randint(0, 256, (size[1], size[0], 3),\n                             dtype=numpy.uint8)\n    t = numpy.random.randint(0, 256, (tsize[1], tsize[0], 3),\n                             dtype=numpy.uint8)\n    tt = numpy.random.randint(0, 256, (tsize[1], tsize[0], 4),\n                              dtype=numpy.uint8)\n    mask = tt[:, :, 3]\n    mask[mask & 1 == 1] = 255\n    mask[mask < 255] = 0\n\n    f_cropped = f[toff[1]:toff[1] + tsize[1], toff[0]:toff[0] + tsize[0], :]\n    return f_cropped, t, tt\n\n\ndef test_sqdiff():\n    f = numpy.array(range(1280 * 720 * 3), dtype=numpy.uint8)\n    f.shape = (720, 1280, 3)\n    t = numpy.zeros((720, 1280, 3), dtype=numpy.uint8)\n    tt = numpy.zeros((720, 1280, 4), dtype=numpy.uint8)\n    t[:, :, :] = f\n    tt[:, :, :3] = f\n    tt[:, :, 3] = 255\n\n    assert (0, 1280 * 720 * 3) == _sqdiff_c(t, f)\n    assert (0, 1280 * 720 * 3) == _sqdiff_c(tt, f)\n    assert (0, 1280 * 720 * 3) == _sqdiff_c(tt[:, :, :3], f)\n\n    f = numpy.ones((720, 1280, 3), dtype=numpy.uint8) * 255\n    t = numpy.zeros((720, 1280, 3), dtype=numpy.uint8)\n    tt = numpy.zeros((720, 1280, 4), dtype=numpy.uint8)\n\n    assert (1280 * 720 * 255 * 255 * 3, 1280 * 720 * 3) == _sqdiff_c(t, f)\n    assert (1280 * 720 * 255 * 255 * 3, 1280 * 720 * 3) == _sqdiff_c(t, f)\n    assert (0, 0) == _sqdiff_c(tt, f)\n\n    tt[:, :, 3] = 255\n    assert (1280 * 720 * 255 * 255 * 3, 1280 * 720 * 3) == _sqdiff_c(t, f)\n    assert (1280 * 720 * 255 * 255 * 3, 1280 * 720 * 3) == _sqdiff_c(t, f)\n    assert (1280 * 720 * 255 * 255 * 3, 1280 * 720 * 3) == _sqdiff_c(tt, f)\n\n\ndef test_sqdiff_c_numpy_equivalence():\n    for _ in range(100):\n        frame_cropped, template, template_transparent = _random_template()\n\n        for t in (template, template_transparent,\n                  template_transparent[:, :, :3]):\n            assert (_sqdiff_numpy(t, frame_cropped) ==\n                    _sqdiff_c(t, frame_cropped))\n\n\ndef _make_sqdiff_numba():\n    # numba implementation included for the purposes of comparison.\n    try:\n        import numba\n    except ImportError:\n        return None\n\n    def _sqdiff_numba(template, frame):\n        if template.shape[2] == 3:\n            return _sqdiff_numba_nomask(template, frame)\n        else:\n            return _sqdiff_numba_masked(template, frame)\n\n    @numba.jit(nopython=True, nogil=True)\n    def _sqdiff_numba_nomask(template, frame):\n        cum = 0\n        s = template.shape\n        for i in range(s[0]):\n            for j in range(s[1]):\n                for k in range(s[2]):\n                    cum += (template[i, j, k] - frame[i, j, k]) ** 2\n        return cum, frame.size\n\n    @numba.jit(nopython=True, nogil=True)\n    def _sqdiff_numba_masked(template, frame):\n        # mask is either 0 or 255\n        cum = 0\n        maskcount = 0\n        s = template.shape\n        for i in range(s[0]):\n            for j in range(s[1]):\n                if template[i, j, 3] == 255:\n                    for k in range(s[2]):\n                        cum += (template[i, j, k] - frame[i, j, k]) ** 2\n                    maskcount += 1\n        return cum, maskcount * 3\n\n    return _sqdiff_numba\n\n\ndef _measure_performance():\n    import timeit\n\n    _sqdiff_numba = _make_sqdiff_numba()\n\n    print(""All times in ms                         numpy\\tnumba"")\n    print(""type    \\tnumpy\\tnumba\\tC\\tspeedup\\tspeedup\\tsize\\talignment"")\n    for _ in range(100):\n        frame_cropped, template, template_transparent = _random_template()\n\n        for l, t in [(""template "", template),\n                     (""with mask"", template_transparent),\n                     (""unmasked "", template_transparent[:, :, :3])]:\n            # pylint: disable=cell-var-from-loop\n\n            np_time = min(timeit.repeat(\n                lambda: _sqdiff_numpy(t, frame_cropped),\n                repeat=3, number=10)) / 10\n            c_time = min(timeit.repeat(\n                lambda: _sqdiff_c(t, frame_cropped),\n                repeat=3, number=10)) / 10\n            if _sqdiff_numba:\n                numba_time = min(timeit.repeat(\n                    lambda: _sqdiff_numba(t, frame_cropped),\n                    repeat=3, number=10)) / 10\n            else:\n                numba_time = float(\'nan\')\n            print(""%s\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%i x %i \\t%s"" % (\n                l, np_time * 1000, numba_time * 1000, c_time * 1000,\n                np_time / c_time, numba_time / c_time,\n                frame_cropped.shape[1], frame_cropped.shape[0],\n                frame_cropped.ctypes.data % 8))\n'"
_stbt/stbt_run.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport os\nimport sys\nimport traceback\nfrom collections import namedtuple\nfrom contextlib import contextmanager\n\nimport stbt\nfrom _stbt.utils import find_import_name\n\n\ndef _save_screenshot(dut, result_dir, exception, save_jpg, save_png):\n    import cv2\n\n    if not save_jpg and not save_png:\n        return\n\n    screenshot = getattr(exception, ""screenshot"", None)\n    if screenshot is None and dut._display:  # pylint: disable=protected-access\n        screenshot = dut._display.last_used_frame  # pylint: disable=protected-access\n    if screenshot is None:\n        screenshot = dut.get_frame()  # pylint: disable=protected-access\n\n    if save_png:\n        cv2.imwrite(os.path.join(result_dir, ""screenshot.png""), screenshot)\n        sys.stderr.write(""Saved screenshot to \'screenshot.png\'.\\n"")\n\n    if save_jpg:\n        cv2.imwrite(\n            os.path.join(result_dir, \'thumbnail.jpg\'),\n            cv2.resize(screenshot, (\n                640, 640 * screenshot.shape[0] // screenshot.shape[1])),\n            [cv2.IMWRITE_JPEG_QUALITY, 50])\n\n\n@contextmanager\ndef video(args, dut):\n    result_dir = os.path.abspath(os.curdir)\n    with stbt._set_dut_singleton(dut), dut:  # pylint: disable=protected-access\n        try:\n            yield\n        except Exception as e:  # pylint: disable=broad-except\n            try:\n                _save_screenshot(dut, result_dir, exception=e,\n                                 save_jpg=(args.save_thumbnail != \'never\'),\n                                 save_png=(args.save_screenshot != \'never\'))\n            except Exception:  # pylint: disable=broad-except\n                pass\n            raise\n        else:\n            _save_screenshot(dut, result_dir, exception=None,\n                             save_jpg=(args.save_thumbnail == \'always\'),\n                             save_png=(args.save_screenshot == \'always\'))\n\n\ndef _import_by_filename(filename_):\n    from importlib import import_module\n    import_dir, import_name = find_import_name(filename_)\n    sys.path.insert(0, import_dir)\n    try:\n        mod = import_module(import_name)\n    finally:\n        # If the test function is not in a module we will need to leave\n        # PYTHONPATH modified here so one python file in the test-pack can\n        # import other files from the same directory.  We also have to be\n        # careful of modules that mess with sys.path:\n        if \'.\' in import_name and sys.path[0] == import_dir:\n            sys.path.pop(0)\n    return mod\n\n\n_TestFunction = namedtuple(\n    ""_TestFunction"", ""script filename funcname line call"")\n\n\ndef load_test_function(script, args):\n    sys.argv = [script] + args\n    if \'::\' in script:\n        filename, funcname = script.split(\'::\', 1)\n        mod = _import_by_filename(filename)\n        func = getattr(mod, funcname)\n        return _TestFunction(\n            script, filename, funcname, func.__code__.co_firstlineno,\n            func)\n    else:\n        filename = os.path.abspath(script)\n\n        test_globals = {\n            \'__builtins__\': __builtins__,\n            \'__name__\': \'__main__\',\n            \'__file__\': script,\n            \'__doc__\': None,\n            \'__package__\': None,\n            \'stbt\': stbt,\n        }\n\n        # For backwards compatibility. We want to encourage people to expli-\n        # citly import stbt in their scripts, so don\'t add new APIs here.\n        for x in \'\'\'press press_until_match wait_for_match wait_for_motion\n                    MatchResult Position detect_motion MotionResult save_frame\n                    get_frame MatchParameters debug UITestError UITestFailure\n                    MatchTimeout MotionTimeout ConfigurationError\'\'\'.split():\n            test_globals[x] = getattr(stbt, x)\n\n        def fn():\n            sys.path.insert(0, os.path.dirname(filename))\n            code = compile(open(filename, ""rb"").read(),\n                           filename,\n                           mode=""exec"",\n                           # Don\'t apply the __future__ imports in force in\n                           # this file.\n                           dont_inherit=1)\n            exec(code, test_globals)  # pylint:disable=exec-used\n\n        return _TestFunction(script, script, """", 1, fn)\n\n\nif sys.version_info.major == 2:  # Python 2\n\n    @contextmanager\n    def sane_unicode_and_exception_handling(script):\n        """"""\n        Exit 1 on failure, and 2 on error.  Print the traceback assuming UTF-8.\n        """"""\n        # Simulates python3\'s defaulting to utf-8 output so we don\'t get\n        # confusing `UnicodeEncodeError`s when printing unicode characters:\n        from kitchen.text.converters import (  # pylint:disable=import-error\n            getwriter, exception_to_bytes, to_bytes)\n        if sys.stdout.encoding is None:\n            sys.stdout = getwriter(\'utf8\')(sys.stdout)\n        if sys.stderr.encoding is None:\n            sys.stderr = getwriter(\'utf8\')(sys.stderr)\n\n        try:\n            yield\n        except Exception as e:  # pylint:disable=broad-except\n            error_message = exception_to_bytes(e)\n            if not error_message and isinstance(e, AssertionError):\n                error_message = traceback.extract_tb(sys.exc_info()[2])[-1][3]\n            sys.stdout.write(b""FAIL: %s: %s: %s\\n"" % (\n                script, type(e).__name__, error_message))\n\n            # This is a hack to allow printing exceptions that have unicode\n            # messages attached to them. The default behaviour of Python 2.7 is\n            # to replace unicode charactors with \\x023-like backslash escapes.\n            # Instead we format them as utf-8 bytes.\n            #\n            # It\'s not thread-safe, but will only be called at the end of\n            # execution:\n            traceback._some_str = to_bytes  # pylint: disable=protected-access\n            traceback.print_exc(file=sys.stderr)\n\n            if isinstance(e, (stbt.UITestFailure, AssertionError)):\n                sys.exit(1)  # Failure\n            else:\n                sys.exit(2)  # Error\n\nelse:  # Python 3\n\n    @contextmanager\n    def sane_unicode_and_exception_handling(script):\n        try:\n            yield\n        except Exception as e:  # pylint:disable=broad-except\n            error_message = str(e)\n            if not error_message and isinstance(e, AssertionError):\n                error_message = traceback.extract_tb(sys.exc_info()[2])[-1][3]\n            sys.stdout.write(""FAIL: %s: %s: %s\\n"" % (\n                script, type(e).__name__, error_message))\n            traceback.print_exc(file=sys.stderr)\n            if isinstance(e, (stbt.UITestFailure, AssertionError)):\n                sys.exit(1)  # Failure\n            else:\n                sys.exit(2)  # Error\n'"
_stbt/transition.py,0,"b'# coding: utf-8\n\n""""""Detection & frame-accurate measurement of animations and transitions.\n\nFor example a selection that moves from one menu item to another or loading a\nnew screen such as a Guide and waiting for it to populate fully.\n\nBecause we want these measurements to be frame-accurate, we don\'t do expensive\nimage processing, relying instead on diffs between successive frames.\n\nCopyright 2017-2018 Stb-tester.com Ltd.\nLicense: LGPL v2.1 or (at your option) any later version (see\nhttps://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport enum\n\nimport cv2\nimport numpy\n\nfrom .imgutils import load_image, pixel_bounding_box\nfrom .logging import ddebug, debug, draw_on\nfrom .motion import MotionResult\nfrom .types import Region\n\n\ndef press_and_wait(\n        key, region=Region.ALL, mask=None, timeout_secs=10, stable_secs=1,\n        _dut=None):\n\n    """"""Press a key, then wait for the screen to change, then wait for it to stop\n    changing.\n\n    This can be used to wait for a menu selection to finish moving before\n    attempting to OCR at the selection\'s new position; or to measure the\n    duration of animations; or to measure how long it takes for a screen (such\n    as an EPG) to finish populating.\n\n    :param str key: The name of the key to press (passed to `stbt.press`).\n\n    :param stbt.Region region: Only look at the specified region of the video\n        frame.\n\n    :param str mask: The filename of a black & white image that specifies which\n        part of the video frame to look at. White pixels select the area to\n        analyse; black pixels select the area to ignore. You can\'t specify\n        ``region`` and ``mask`` at the same time.\n\n    :param timeout_secs: A timeout in seconds. This function will return a\n        falsey value if the transition didn\'t complete within this number of\n        seconds from the key-press.\n    :type timeout_secs: int or float\n\n    :param stable_secs: A duration in seconds. The screen must stay unchanged\n        (within the specified region or mask) for this long, for the transition\n        to be considered ""complete"".\n\n    :returns:\n        An object that will evaluate to true if the transition completed, false\n        otherwise. It has the following attributes:\n\n        * **key** (*str*) \xe2\x80\x93 The name of the key that was pressed.\n        * **frame** (`stbt.Frame`) \xe2\x80\x93 If successful, the first video frame when\n          the transition completed; if timed out, the last frame seen.\n        * **status** (`stbt.TransitionStatus`) \xe2\x80\x93 Either ``START_TIMEOUT``,\n          ``STABLE_TIMEOUT``, or ``COMPLETE``. If it\'s ``COMPLETE``, the whole\n          object will evaluate as true.\n        * **press_time** (*float*) \xe2\x80\x93 When the key-press completed.\n        * **animation_start_time** (*float*) \xe2\x80\x93 When animation started after the\n          key-press (or ``None`` if timed out).\n        * **end_time** (*float*) \xe2\x80\x93 When animation completed (or ``None`` if\n          timed out).\n        * **duration** (*float*) \xe2\x80\x93 Time from ``press_time`` to ``end_time`` (or\n          ``None`` if timed out).\n        * **animation_duration** (*float*) \xe2\x80\x93 Time from ``animation_start_time``\n          to ``end_time`` (or ``None`` if timed out).\n\n        All times are measured in seconds since 1970-01-01T00:00Z; the\n        timestamps can be compared with system time (the output of\n        ``time.time()``).\n    """"""\n    if _dut is None:\n        import stbt\n        _dut = stbt\n\n    t = _Transition(region, mask, timeout_secs, stable_secs, _dut)\n    press_result = _dut.press(key)\n    debug(""transition: %.3f: Pressed %s"" % (press_result.end_time, key))\n    result = t.wait(press_result)\n    debug(""press_and_wait(%r) -> %s"" % (key, result))\n    return result\n\n\ndef wait_for_transition_to_end(\n        initial_frame=None, region=Region.ALL, mask=None, timeout_secs=10,\n        stable_secs=1, _dut=None):\n\n    """"""Wait for the screen to stop changing.\n\n    In most cases you should use `press_and_wait` to measure a complete\n    transition, but if you need to measure several points during a single\n    transition you can use `wait_for_transition_to_end` as the last\n    measurement. For example::\n\n        keypress = stbt.press(""KEY_OK"")  # Launch my app\n        m = stbt.wait_for_match(""my-app-home-screen.png"")\n        time_to_first_frame = m.time - keypress.start_time\n        end = wait_for_transition_to_end(m.frame)\n        time_to_fully_populated = end.end_time - keypress.start_time\n\n    :param stbt.Frame initial_frame: The frame of video when the transition\n        started. If `None`, we\'ll pull a new frame from the device under test.\n\n    :param region: See `press_and_wait`.\n    :param mask: See `press_and_wait`.\n    :param timeout_secs: See `press_and_wait`.\n    :param stable_secs: See `press_and_wait`.\n\n    :returns: See `press_and_wait`.\n    """"""\n    if _dut is None:\n        import stbt\n        _dut = stbt\n\n    t = _Transition(region, mask, timeout_secs, stable_secs, _dut)\n    result = t.wait_for_transition_to_end(initial_frame)\n    debug(""wait_for_transition_to_end() -> %s"" % (result,))\n    return result\n\n\nclass _Transition(object):\n    def __init__(self, region=Region.ALL, mask=None, timeout_secs=10,\n                 stable_secs=1, dut=None):\n        if dut is None:\n            import stbt\n            dut = stbt\n\n        if region is not Region.ALL and mask is not None:\n            raise ValueError(\n                ""You can\'t specify region and mask at the same time"")\n\n        self.region = region\n        self.mask_image = None\n        if isinstance(mask, numpy.ndarray):\n            self.mask_image = mask\n        elif mask:\n            self.mask_image = load_image(mask)\n\n        self.timeout_secs = timeout_secs\n        self.stable_secs = stable_secs\n        self.dut = dut\n\n        self.frames = self.dut.frames()\n        self.diff = strict_diff\n        self.expiry_time = None\n\n    def wait(self, press_result):\n        self.expiry_time = press_result.end_time + self.timeout_secs\n\n        # Wait for animation to start\n        for f in self.frames:\n            if f.time < press_result.end_time:\n                # Discard frame to work around latency in video-capture pipeline\n                continue\n            if self.diff(press_result.frame_before, f, self.region,\n                         self.mask_image):\n                _debug(""Animation started"", f)\n                animation_start_time = f.time\n                break\n            _debug(""No change"", f)\n            if f.time >= self.expiry_time:\n                _debug(\n                    ""Transition didn\'t start within %s seconds of pressing %s"",\n                    f, self.timeout_secs, press_result.key)\n                return _TransitionResult(\n                    press_result.key, f, TransitionStatus.START_TIMEOUT,\n                    press_result.end_time, None, None)\n\n        end_result = self.wait_for_transition_to_end(f)  # pylint:disable=undefined-loop-variable\n        return _TransitionResult(\n            press_result.key, end_result.frame, end_result.status,\n            press_result.end_time, animation_start_time, end_result.end_time)\n\n    def wait_for_transition_to_end(self, initial_frame):\n        if initial_frame is None:\n            initial_frame = next(self.frames)\n        if self.expiry_time is None:\n            self.expiry_time = initial_frame.time + self.timeout_secs\n\n        f = first_stable_frame = initial_frame\n        while True:\n            prev = f\n            f = next(self.frames)\n            if self.diff(prev, f, self.region, self.mask_image):\n                _debug(""Animation in progress"", f)\n                first_stable_frame = f\n            else:\n                _debug(""No change since previous frame"", f)\n            if f.time - first_stable_frame.time >= self.stable_secs:\n                _debug(""Transition complete (stable for %ss since %.3f)."",\n                       first_stable_frame, self.stable_secs,\n                       first_stable_frame.time)\n                return _TransitionResult(\n                    None, first_stable_frame, TransitionStatus.COMPLETE,\n                    None, initial_frame.time, first_stable_frame.time)\n            if f.time >= self.expiry_time:\n                _debug(""Transition didn\'t end within %s seconds"",\n                       f, self.timeout_secs)\n                return _TransitionResult(\n                    None, f, TransitionStatus.STABLE_TIMEOUT,\n                    None, initial_frame.time, None)\n\n\ndef _debug(s, f, *args):\n    debug((""transition: %.3f: "" + s) % ((getattr(f, ""time"", 0),) + args))\n\n\ndef _ddebug(s, f, *args):\n    ddebug((""transition: %.3f: "" + s) % ((getattr(f, ""time"", 0),) + args))\n\n\ndef strict_diff(prev, frame, region, mask_image):\n    if region is not None:\n        full_frame = Region(0, 0, frame.shape[1], frame.shape[0])\n        region = Region.intersect(full_frame, region)\n        f1 = prev[region.y:region.bottom, region.x:region.right]\n        f2 = frame[region.y:region.bottom, region.x:region.right]\n\n    absdiff = cv2.absdiff(f1, f2)\n    if mask_image is not None:\n        absdiff = cv2.bitwise_and(absdiff, mask_image, absdiff)\n\n    diffs_found = False\n    out_region = None\n    maxdiff = numpy.max(absdiff)\n    if maxdiff > 20:\n        diffs_found = True\n        big_diffs = absdiff > 20\n        out_region = pixel_bounding_box(big_diffs)\n        _ddebug(""found %s diffs above 20 (max %s) in %r"", frame,\n                numpy.count_nonzero(big_diffs), maxdiff, out_region)\n    elif maxdiff > 0:\n        small_diffs = absdiff > 5\n        small_diffs_count = numpy.count_nonzero(small_diffs)\n        if small_diffs_count > 50:\n            diffs_found = True\n            out_region = pixel_bounding_box(small_diffs)\n            _ddebug(""found %s diffs <= %s in %r"", frame, small_diffs_count,\n                    maxdiff, out_region)\n        else:\n            _ddebug(""only found %s diffs <= %s"", frame, small_diffs_count,\n                    maxdiff)\n    if out_region:\n        out_region = out_region.translate(region)\n\n    result = MotionResult(getattr(frame, ""time"", None), diffs_found,\n                          out_region, frame)\n    draw_on(frame, result, label=""transition"")\n    return result\n\n\nclass _TransitionResult(object):\n    def __init__(self, key, frame, status, press_time, animation_start_time,\n                 end_time):\n        self.key = key\n        self.frame = frame\n        self.status = status\n        self.press_time = press_time\n        self.animation_start_time = animation_start_time\n        self.end_time = end_time\n\n    def __repr__(self):\n        return (\n            ""_TransitionResult(key=%r, frame=<Frame>, status=%s, ""\n            ""press_time=%s, animation_start_time=%s, end_time=%s)"" % (\n                self.key,\n                self.status,\n                self.press_time,\n                self.animation_start_time,\n                self.end_time))\n\n    def __str__(self):\n        # Also lists the properties -- it\'s useful to see them in the logs.\n        return (\n            ""_TransitionResult(key=%r, frame=<Frame>, status=%s, ""\n            ""press_time=%s, animation_start_time=%s, end_time=%s, duration=%s, ""\n            ""animation_duration=%s)"" % (\n                self.key,\n                self.status,\n                self.press_time,\n                self.animation_start_time,\n                self.end_time,\n                self.duration,\n                self.animation_duration))\n\n    def __bool__(self):\n        return self.status == TransitionStatus.COMPLETE\n\n    @property\n    def duration(self):\n        if self.end_time is None or self.press_time is None:\n            return None\n        return self.end_time - self.press_time\n\n    @property\n    def animation_duration(self):\n        if self.end_time is None or self.animation_start_time is None:\n            return None\n        return self.end_time - self.animation_start_time\n\n\nclass TransitionStatus(enum.Enum):\n\n    #: The transition didn\'t start (nothing moved).\n    START_TIMEOUT = 0\n\n    #: The transition didn\'t end (movement didn\'t stop).\n    STABLE_TIMEOUT = 1\n\n    #: The transition started and then stopped.\n    COMPLETE = 2\n'"
_stbt/types.py,0,"b'# coding: utf-8\n# Don\'t import anything not in the Python standard library from this file\n\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nfrom future.utils import with_metaclass\n\nfrom collections import namedtuple\n\n\nclass Position(namedtuple(\'Position\', \'x y\')):\n    """"""A point with ``x`` and ``y`` coordinates.""""""\n    pass\n\n\nclass _RegionClsMethods(type):\n    """"""Metaclass for `Region`.\n\n    This defines some classmethods for Region, but in a way that they can\'t be\n    called on an instance of Region (which is an easy mistake to make, but with\n    incorrect behaviour). See <https://stackoverflow.com/a/42327454/606705>.\n    """"""\n\n    def intersect(cls, *args):\n        out = Region.ALL\n        args = iter(args)\n        try:\n            out = next(args)\n        except StopIteration:\n            # No arguments passed:\n            return Region.ALL\n        if out is None:\n            return None\n\n        for r in args:\n            if not r:\n                return None\n            out = (max(out[0], r[0]), max(out[1], r[1]),\n                   min(out[2], r[2]), min(out[3], r[3]))\n            if out[0] >= out[2] or out[1] >= out[3]:\n                return None\n        return Region.from_extents(*out)\n\n    def bounding_box(cls, *args):\n        args = [_f for _f in args if _f]\n        if not args:\n            return None\n        return Region.from_extents(\n            min(r.x for r in args),\n            min(r.y for r in args),\n            max(r.right for r in args),\n            max(r.bottom for r in args))\n\n\nclass Region(with_metaclass(_RegionClsMethods,\n                            namedtuple(\'Region\', \'x y right bottom\'))):\n    r""""""\n    ``Region(x, y, width=width, height=height)`` or\n    ``Region(x, y, right=right, bottom=bottom)``\n\n    Rectangular region within the video frame.\n\n    For example, given the following regions a, b, and c::\n\n        - 01234567890123\n        0 \xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\n        1 \xe2\x96\x91a\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\n        2 \xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\n        3 \xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\n        4 \xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x93\xe2\x96\x93\xe2\x96\x93\xe2\x96\x93\xe2\x96\x91\xe2\x96\x91\xe2\x96\x93c\xe2\x96\x93\n        5 \xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x93\xe2\x96\x93\xe2\x96\x93\xe2\x96\x93\xe2\x96\x91\xe2\x96\x91\xe2\x96\x93\xe2\x96\x93\xe2\x96\x93\n        6 \xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x93\xe2\x96\x93\xe2\x96\x93\xe2\x96\x93\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\n        7 \xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x93\xe2\x96\x93\xe2\x96\x93\xe2\x96\x93\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\n        8     \xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91b\xe2\x96\x91\xe2\x96\x91\n        9     \xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\xe2\x96\x91\n\n    >>> a = Region(0, 0, width=8, height=8)\n    >>> b = Region(4, 4, right=13, bottom=10)\n    >>> c = Region(10, 4, width=3, height=2)\n    >>> a.right\n    8\n    >>> b.bottom\n    10\n    >>> b.center\n    Position(x=8, y=7)\n    >>> b.contains(c), a.contains(b), c.contains(b), c.contains(None)\n    (True, False, False, False)\n    >>> b.contains(c.center), a.contains(b.center)\n    (True, False)\n    >>> b.extend(x=6, bottom=-4) == c\n    True\n    >>> a.extend(right=5).contains(c)\n    True\n    >>> a.width, a.extend(x=3).width, a.extend(right=-3).width\n    (8, 5, 5)\n    >>> c.replace(bottom=10)\n    Region(x=10, y=4, right=13, bottom=10)\n    >>> Region.intersect(a, b)\n    Region(x=4, y=4, right=8, bottom=8)\n    >>> Region.intersect(a, b) == Region.intersect(b, a)\n    True\n    >>> Region.intersect(c, b) == c\n    True\n    >>> print(Region.intersect(a, c))\n    None\n    >>> print(Region.intersect(None, a))\n    None\n    >>> Region.intersect(a)\n    Region(x=0, y=0, right=8, bottom=8)\n    >>> Region.intersect()\n    Region.ALL\n    >>> quadrant = Region(x=float(""-inf""), y=float(""-inf""), right=0, bottom=0)\n    >>> quadrant.translate(2, 2)\n    Region(x=-inf, y=-inf, right=2, bottom=2)\n    >>> c.translate(x=-9, y=-3)\n    Region(x=1, y=1, right=4, bottom=3)\n    >>> Region(2, 3, 2, 1).translate(b)\n    Region(x=6, y=7, right=8, bottom=8)\n    >>> Region.intersect(Region.ALL, c) == c\n    True\n    >>> Region.ALL\n    Region.ALL\n    >>> print(Region.ALL)\n    Region.ALL\n    >>> c.above()\n    Region(x=10, y=-inf, right=13, bottom=4)\n    >>> c.below()\n    Region(x=10, y=6, right=13, bottom=inf)\n    >>> a.right_of()\n    Region(x=8, y=0, right=inf, bottom=8)\n    >>> a.right_of(width=2)\n    Region(x=8, y=0, right=10, bottom=8)\n    >>> c.left_of()\n    Region(x=-inf, y=4, right=10, bottom=6)\n\n    .. py:attribute:: x\n\n        The x coordinate of the left edge of the region, measured in pixels\n        from the left of the video frame (inclusive).\n\n    .. py:attribute:: y\n\n        The y coordinate of the top edge of the region, measured in pixels from\n        the top of the video frame (inclusive).\n\n    .. py:attribute:: right\n\n        The x coordinate of the right edge of the region, measured in pixels\n        from the left of the video frame (exclusive).\n\n    .. py:attribute:: bottom\n\n        The y coordinate of the bottom edge of the region, measured in pixels\n        from the top of the video frame (exclusive).\n\n    .. py:attribute:: width\n\n        The width of the region, measured in pixels.\n\n    .. py:attribute:: height\n\n        The height of the region, measured in pixels.\n\n    ``x``, ``y``, ``right``, ``bottom``, ``width`` and ``height`` can be\n    infinite --- that is, ``float(""inf"")`` or ``-float(""inf"")``.\n\n    .. py:attribute:: center\n\n        A `stbt.Position` specifying the x & y coordinates of the region\'s\n        center.\n\n    .. py:staticmethod:: from_extents\n\n        Create a Region using right and bottom extents rather than width and\n        height.\n\n        Typically you\'d use the ``right`` and ``bottom`` parameters of the\n        ``Region`` constructor instead, but this factory function is useful\n        if you need to create a ``Region`` from a tuple.\n\n        >>> extents = (4, 4, 13, 10)\n        >>> Region.from_extents(*extents)\n        Region(x=4, y=4, right=13, bottom=10)\n\n    .. py:staticmethod:: bounding_box(*args)\n\n        :returns: The smallest region that contains all the given regions.\n\n        >>> a = Region(50, 20, right=60, bottom=40)\n        >>> b = Region(20, 30, right=30, bottom=50)\n        >>> c = Region(55, 25, right=70, bottom=35)\n        >>> Region.bounding_box(a, b)\n        Region(x=20, y=20, right=60, bottom=50)\n        >>> Region.bounding_box(b, b)\n        Region(x=20, y=30, right=30, bottom=50)\n        >>> Region.bounding_box(None, b)\n        Region(x=20, y=30, right=30, bottom=50)\n        >>> Region.bounding_box(b, None)\n        Region(x=20, y=30, right=30, bottom=50)\n        >>> Region.bounding_box(b, Region.ALL)\n        Region.ALL\n        >>> print(Region.bounding_box(None, None))\n        None\n        >>> print(Region.bounding_box())\n        None\n        >>> Region.bounding_box(b)\n        Region(x=20, y=30, right=30, bottom=50)\n        >>> Region.bounding_box(a, b, c) == \\\n        ...     Region.bounding_box(a, Region.bounding_box(b, c))\n        True\n\n        Changed in v30: ``bounding_box`` can take an arbitrary number of region\n        arguments, rather than exactly two.\n\n    .. py:staticmethod:: intersect(*args)\n\n        :returns: The intersection of the passed regions, or ``None`` if the\n            regions don\'t intersect.\n\n        Any parameter can be ``None`` (an empty Region) so intersect is\n        commutative and associative.\n\n        Changed in v30: ``intersect`` can take an arbitrary number of region\n        arguments, rather than exactly two.\n\n    """"""\n    def __new__(cls, x, y, width=None, height=None, right=None, bottom=None):\n        if (width is None) == (right is None):\n            raise ValueError(""You must specify either \'width\' or \'right\'"")\n        if (height is None) == (bottom is None):\n            raise ValueError(""You must specify either \'height\' or \'bottom\'"")\n        if right is None:\n            right = x + width\n        if bottom is None:\n            bottom = y + height\n        if right <= x:\n            raise ValueError(""\'right\' must be greater than \'x\'"")\n        if bottom <= y:\n            raise ValueError(""\'bottom\' must be greater than \'y\'"")\n        return super(Region, cls).__new__(cls, x, y, right, bottom)\n\n    def __repr__(self):\n        if self == Region.ALL:\n            return \'Region.ALL\'\n        else:\n            return \'Region(x=%r, y=%r, right=%r, bottom=%r)\' \\\n                % (self.x, self.y, self.right, self.bottom)\n\n    @property\n    def width(self):\n        return self.right - self.x\n\n    @property\n    def height(self):\n        return self.bottom - self.y\n\n    @property\n    def center(self):\n        return Position((self.x + self.right) // 2,\n                        (self.y + self.bottom) // 2)\n\n    @staticmethod\n    def from_extents(x, y, right, bottom):\n        return Region(x, y, right=right, bottom=bottom)\n\n    def to_slice(self):\n        """"""A 2-dimensional slice suitable for indexing a `stbt.Frame`.""""""\n        return (slice(max(0, self.y),\n                      max(0, self.bottom)),\n                slice(max(0, self.x),\n                      max(0, self.right)))\n\n    def contains(self, other):\n        """"""\n        :returns: True if ``other`` (a `Region` or `Position`) is entirely\n            contained within self.\n        """"""\n        if other is None:\n            return False\n        elif all(hasattr(other, a) for a in (""x"", ""y"", ""right"", ""bottom"")):\n            # a Region\n            return (self.x <= other.x and other.right <= self.right and\n                    self.y <= other.y and other.bottom <= self.bottom)\n        elif all(hasattr(other, a) for a in (""x"", ""y"")):  # a Position\n            return (self.x <= other.x < self.right and\n                    self.y <= other.y < self.bottom)\n        else:\n            raise TypeError(""Region.contains expects a Region, Position, or ""\n                            ""None. Got %r"" % (other,))\n\n    def translate(self, x=None, y=None):\n        """"""\n        :returns: A new region with the position of the region adjusted by the\n            given amounts.  The width and height are unaffected.\n\n        ``translate`` accepts separate x and y arguments, or a single `Region`.\n\n        For example, move the region 1px right and 2px down:\n\n        >>> b = Region(4, 4, 9, 6)\n        >>> b.translate(1, 2)\n        Region(x=5, y=6, right=14, bottom=12)\n\n        Move the region 1px to the left:\n\n        >>> b.translate(x=-1)\n        Region(x=3, y=4, right=12, bottom=10)\n\n        Move the region 3px up:\n\n        >>> b.translate(y=-3)\n        Region(x=4, y=1, right=13, bottom=7)\n\n        Move the region by another region.  This can be helpful if `TITLE`\n        defines a region relative another UI element on screen.  You can then\n        combine the two like so:\n\n        >>> TITLE = Region(20, 5, 160, 40)\n        >>> CELL = Region(140, 45, 200, 200)\n        >>> TITLE.translate(CELL)\n        Region(x=160, y=50, right=320, bottom=90)\n        """"""\n        try:\n            p = x[0], x[1]\n        except TypeError:\n            p = x or 0, y or 0\n        else:\n            if y is not None:\n                raise TypeError(\n                    ""translate() takes either a single Region argument or two ""\n                    ""ints (both given)"")\n        return Region.from_extents(self.x + p[0], self.y + p[1],\n                                   self.right + p[0], self.bottom + p[1])\n\n    def extend(self, x=0, y=0, right=0, bottom=0):\n        """"""\n        :returns: A new region with the edges of the region adjusted by the\n            given amounts.\n        """"""\n        return Region.from_extents(\n            self.x + x, self.y + y, self.right + right, self.bottom + bottom)\n\n    def replace(self, x=None, y=None, width=None, height=None, right=None,\n                bottom=None):\n        """"""\n        :returns: A new region with the edges of the region set to the given\n            coordinates.\n\n        This is similar to `extend`, but it takes absolute coordinates within\n        the image instead of adjusting by a relative number of pixels.\n        """"""\n        def norm_coords(name_x, name_width, name_right,\n                        x, width, right,  # or y, height, bottom\n                        default_x, _default_width, default_right):\n            if all(z is not None for z in (x, width, right)):\n                raise ValueError(\n                    ""Region.replace: Argument conflict: you may only specify ""\n                    ""two of %s, %s and %s.  You specified %s=%s, %s=%s and ""\n                    ""%s=%s"" % (name_x, name_width, name_right,\n                               name_x, x, name_width, width, name_right, right))\n            if x is None:\n                if width is not None and right is not None:\n                    x = right - width\n                else:\n                    x = default_x\n            if right is None:\n                right = x + width if width is not None else default_right\n            return x, right\n\n        x, right = norm_coords(\'x\', \'width\', \'right\', x, width, right,\n                               self.x, self.width, self.right)\n        y, bottom = norm_coords(\'y\', \'height\', \'bottom\', y, height, bottom,\n                                self.y, self.height, self.bottom)\n\n        return Region(x=x, y=y, right=right, bottom=bottom)\n\n    def dilate(self, n):\n        """"""Expand the region by n px in all directions.\n\n        >>> Region(20, 30, right=30, bottom=50).dilate(3)\n        Region(x=17, y=27, right=33, bottom=53)\n        """"""\n        return self.extend(x=-n, y=-n, right=n, bottom=n)\n\n    def erode(self, n):\n        """"""Shrink the region by n px in all directions.\n\n        >>> Region(20, 30, right=30, bottom=50).erode(3)\n        Region(x=23, y=33, right=27, bottom=47)\n        >>> print(Region(20, 30, 10, 20).erode(5))\n        None\n        """"""\n        if self.width > n * 2 and self.height > n * 2:\n            return self.dilate(-n)\n        else:\n            return None\n\n    def above(self, height=float(\'inf\')):\n        """"""\n        :returns: A new region above the current region, extending to the top\n            of the frame (or to the specified height).\n        """"""\n        return self.replace(y=self.y - height, bottom=self.y)\n\n    def below(self, height=float(\'inf\')):\n        """"""\n        :returns: A new region below the current region, extending to the bottom\n            of the frame (or to the specified height).\n        """"""\n        return self.replace(y=self.bottom, bottom=self.bottom + height)\n\n    def right_of(self, width=float(\'inf\')):\n        """"""\n        :returns: A new region to the right of the current region, extending to\n            the right edge of the frame (or to the specified width).\n        """"""\n        return self.replace(x=self.right, right=self.right + width)\n\n    def left_of(self, width=float(\'inf\')):\n        """"""\n        :returns: A new region to the left of the current region, extending to\n            the left edge of the frame (or to the specified width).\n        """"""\n        return self.replace(x=self.x - width, right=self.x)\n\n\nRegion.ALL = Region(x=-float(\'inf\'), y=-float(\'inf\'),\n                    right=float(\'inf\'), bottom=float(\'inf\'))\n\n\nclass UITestError(Exception):\n    """"""The test script had an unrecoverable error.""""""\n    pass\n\n\nclass UITestFailure(Exception):\n    """"""The test failed because the device under test didn\'t behave as expected.\n\n    Inherit from this if you need to define your own test-failure exceptions.\n    """"""\n    pass\n\n\nclass NoVideo(Exception):\n    """"""No video available from the source pipeline.""""""\n    pass\n'"
_stbt/utils.py,0,"b'""""""Copyright 2014-2019 Stb-tester.com Ltd.\n\nThis file shouldn\'t depend on anything else in stbt.\n""""""\n\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\n\nimport errno\nimport os\nimport sys\nimport tempfile\nfrom contextlib import contextmanager\nfrom shutil import rmtree\n\n\ndef mkdir_p(d):\n    """"""Python 3.2 has an optional argument to os.makedirs called exist_ok.  To\n    support older versions of python we can\'t use this and need to catch\n    exceptions""""""\n    try:\n        os.makedirs(d)\n    except OSError as e:\n        if e.errno == errno.EEXIST and os.path.isdir(d) \\\n                and os.access(d, os.R_OK | os.W_OK):\n            return\n        else:\n            raise\n\n\ndef rm_f(filename):\n    """"""Like ``rm -f``, it ignores errors if the file doesn\'t exist.""""""\n    try:\n        os.remove(filename)\n    except OSError as e:\n        if e.errno != errno.ENOENT:\n            raise\n\n\n@contextmanager\ndef named_temporary_directory(\n        suffix=\'\', prefix=\'tmp\', dir=None):  # pylint:disable=redefined-builtin,redefined-outer-name\n    dirname = tempfile.mkdtemp(suffix, prefix, dir)\n    try:\n        yield dirname\n    finally:\n        rmtree(dirname)\n\n\n@contextmanager\ndef scoped_curdir():\n    with named_temporary_directory() as tmpdir:\n        olddir = os.path.abspath(os.curdir)\n        os.chdir(tmpdir)\n        try:\n            yield olddir\n        finally:\n            os.chdir(olddir)\n\n\n@contextmanager\ndef scoped_process(process):\n    try:\n        yield process\n    finally:\n        if process.poll() is None:\n            process.kill()\n            process.wait()\n\n\ndef find_import_name(filename):\n    """"""\n    To import an arbitrary filename we need to set PYTHONPATH and we need to\n    know the name of the module we\'re importing.  This is complicated by Python\n    packages: for a directory structure like this:\n\n        tests/package/a.py\n        tests/package/__init__.py\n\n    we want to add `tests` to `PYTHONPATH` (`sys.path`) and `import package.a`.\n    This function traverses the directories to work out what `PYTHONPATH` and\n    the module name should be returning them as a tuple.\n    """"""\n    import_dir, module_file = os.path.split(os.path.abspath(filename))\n    import_name, module_ext = os.path.splitext(module_file)\n    if module_ext != \'.py\':\n        raise ImportError(""Invalid module filename \'%s\'"" % filename)\n\n    while os.path.exists(os.path.join(import_dir, ""__init__.py"")):\n        import_dir, s = os.path.split(import_dir)\n        import_name = ""%s.%s"" % (s, import_name)\n    return import_dir, import_name\n\n\nif sys.version_info.major == 2:  # Python 2\n    text_type = unicode  # pylint: disable=undefined-variable\n    basestring = basestring  # pylint: disable=redefined-builtin,undefined-variable\n\n    def strip_newtypes(text):\n        """"""python-future\'s string newtypes can behave in surprising ways.  We\n        want to avoid returning them in our APIs and we need to cope with\n        handling them internally, so we have this function.""""""\n        # newbytes overrides __instancecheck__, so we can\'t use isinstance to\n        # check if it\'s an instance\n        typename = type(text).__name__\n        if typename == b""newbytes"":\n            from future.types.newbytes import newbytes\n            # newbytes derives from bytes, but overloads __str__, adding a b\'\n            # prefix, so we avoid this by calling the base class\n            return super(newbytes, text).__str__()\n        elif typename == b\'newstr\':\n            return unicode(text)  # pylint: disable=undefined-variable\n        else:\n            return text\n\n    def test_strip_newtypes():\n        from future.types.newbytes import newbytes\n        from future.types.newstr import newstr\n\n        def check(x, y):\n            assert x == y\n            assert type(x).__name__ == type(y).__name__\n\n        check(strip_newtypes(newstr(""abc"")), ""abc"")\n        check(strip_newtypes(newbytes(b""abc"")), b""abc"")\nelse:\n    text_type = str\n    basestring = str\n\n    def strip_newtypes(text):\n        # newtypes won\'t be used on Python 3\n        return text\n\n\nnative_str = str\nnative_int = int\n\n\ndef to_bytes(text):\n    text = strip_newtypes(text)\n\n    if isinstance(text, text_type):\n        return text.encode(""utf-8"", errors=""backslashreplace"")\n    elif isinstance(text, bytes):\n        return text\n    else:\n        raise TypeError(""Unexpected type %s"" % type(text))\n\n\ndef to_unicode(text):\n    text = strip_newtypes(text)\n\n    if isinstance(text, bytes):\n        return text.decode(""utf-8"", errors=""replace"")\n    else:\n        return text_type(text)\n\n\nif sys.version_info.major == 2:  # Python 2\n    def to_native_str(text):\n        return to_bytes(text)\nelse:  # Python 3\n    def to_native_str(text):\n        return to_unicode(text)\n'"
_stbt/wait.py,0,"b'""""""Copyright 2015-2019 Stb-tester.com Ltd.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\n\nimport functools\nimport inspect\n\nfrom .logging import debug\n\n\ndef wait_until(callable_, timeout_secs=10, interval_secs=0, predicate=None,\n               stable_secs=0):\n    """"""Wait until a condition becomes true, or until a timeout.\n\n    Calls ``callable_`` repeatedly (with a delay of ``interval_secs`` seconds\n    between successive calls) until it succeeds (that is, it returns a\n    `truthy`_ value) or until ``timeout_secs`` seconds have passed.\n\n    .. _truthy: https://docs.python.org/3.6/library/stdtypes.html#truth-value-testing\n\n    :param callable_: any Python callable (such as a function or a lambda\n        expression) with no arguments.\n\n    :type timeout_secs: int or float, in seconds\n    :param timeout_secs: After this timeout elapses, ``wait_until`` will return\n        the last value that ``callable_`` returned, even if it\'s falsey.\n\n    :type interval_secs: int or float, in seconds\n    :param interval_secs: Delay between successive invocations of ``callable_``.\n\n    :param predicate: A function that takes a single value. It will be given\n        the return value from ``callable_``. The return value of *this* function\n        will then be used to determine truthiness. If the predicate test\n        succeeds, ``wait_until`` will still return the original value from\n        ``callable_``, not the predicate value.\n\n    :type stable_secs: int or float, in seconds\n    :param stable_secs: Wait for ``callable_``\'s return value to remain the same\n        (as determined by ``==``) for this duration before returning. If\n        ``predicate`` is also given, the values returned from ``predicate``\n        will be compared.\n\n    :returns: The return value from ``callable_`` (which will be truthy if it\n        succeeded, or falsey if ``wait_until`` timed out). If the value was\n        truthy when the timeout was reached but it failed the ``predicate`` or\n        ``stable_secs`` conditions (if any) then ``wait_until`` returns\n        ``None``.\n\n    After you send a remote-control signal to the device-under-test it usually\n    takes a few frames to react, so a test script like this would probably\n    fail::\n\n        stbt.press(""KEY_EPG"")\n        assert stbt.match(""guide.png"")\n\n    Instead, use this::\n\n        import stbt\n        from stbt import wait_until\n\n        stbt.press(""KEY_EPG"")\n        assert wait_until(lambda: stbt.match(""guide.png""))\n\n    ``wait_until`` allows composing more complex conditions, such as::\n\n        # Wait until something disappears:\n        assert wait_until(lambda: not stbt.match(""xyz.png""))\n\n        # Assert that something doesn\'t appear within 10 seconds:\n        assert not wait_until(lambda: stbt.match(""xyz.png""))\n\n        # Assert that two images are present at the same time:\n        assert wait_until(lambda: stbt.match(""a.png"") and stbt.match(""b.png""))\n\n        # Wait but don\'t raise an exception if the image isn\'t present:\n        if not wait_until(lambda: stbt.match(""xyz.png"")):\n            do_something_else()\n\n        # Wait for a menu selection to change. Here ``Menu`` is a `FrameObject`\n        # subclass with a property called `selection` that returns the name of\n        # the currently-selected menu item. The return value (``menu``) is an\n        # instance of ``Menu``.\n        menu = wait_until(Menu, predicate=lambda x: x.selection == ""Home"")\n\n        # Wait for a match to stabilise position, returning the first stable\n        # match. Used in performance measurements, for example to wait for a\n        # selection highlight to finish moving:\n        keypress = stbt.press(""KEY_DOWN"")\n        match_result = wait_until(lambda: stbt.match(""selection.png""),\n                                  predicate=lambda x: x and x.region,\n                                  stable_secs=2)\n        assert match_result\n        match_time = match_result.time  # this is the first stable frame\n        print(""Transition took %s seconds"" % (match_time - keypress.end_time))\n    """"""\n    import time\n\n    if predicate is None:\n        predicate = lambda x: x\n    stable_value = None\n    stable_predicate_value = None\n    expiry_time = time.time() + timeout_secs\n\n    while True:\n        t = time.time()\n        value = callable_()\n        predicate_value = predicate(value)\n\n        if stable_secs:\n            if predicate_value != stable_predicate_value:\n                stable_since = t\n                stable_value = value\n                stable_predicate_value = predicate_value\n            if predicate_value and t - stable_since >= stable_secs:\n                debug(""wait_until succeeded: %s""\n                      % _callable_description(callable_))\n                return stable_value\n        else:\n            if predicate_value:\n                debug(""wait_until succeeded: %s""\n                      % _callable_description(callable_))\n                return value\n\n        if t >= expiry_time:\n            debug(""wait_until timed out after %s seconds: %s""\n                  % (timeout_secs, _callable_description(callable_)))\n            if not value:\n                return value  # it\'s falsey\n            else:\n                return None  # must have failed stable_secs or predicate checks\n\n        time.sleep(interval_secs)\n\n\ndef _callable_description(callable_):\n    """"""Helper to provide nicer debug output when `wait_until` fails.\n\n    >>> _callable_description(wait_until)\n    \'wait_until\'\n    >>> _callable_description(\n    ...     lambda: stbt.press(""OK""))\n    \'    lambda: stbt.press(""OK""))\\\\n\'\n    >>> _callable_description(functools.partial(eval, globals={}))\n    \'eval\'\n    >>> _callable_description(\n    ...     functools.partial(\n    ...         functools.partial(eval, globals={}),\n    ...         locals={}))\n    \'eval\'\n    >>> class T(object):\n    ...     def __call__(self): return True;\n    >>> _callable_description(T())\n    \'<_stbt.wait.T object at 0x...>\'\n    """"""\n    if hasattr(callable_, ""__name__""):\n        name = callable_.__name__\n        if name == ""<lambda>"":\n            try:\n                name = inspect.getsource(callable_)\n            except IOError:\n                pass\n        return name\n    elif isinstance(callable_, functools.partial):\n        return _callable_description(callable_.func)\n    else:\n        return repr(callable_)\n'"
_stbt/x11.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport os\nimport queue\nimport random\nimport signal\nimport subprocess\nimport sys\nfrom contextlib import contextmanager\n\nfrom .utils import named_temporary_directory\n\n\nclass XFailedToStartError(Exception):\n    pass\n\n\ndef _start_x(*args, **kwargs):\n    """"""\n    Implements the X startup notification protocol.  From man Xorg:\n\n    > When the server starts, it checks to see if it has inherited SIGUSR1 as\n    > SIG_IGN instead of the usual SIG_DFL.   In this case, the server sends a\n    > SIGUSR1 to its parent process after it has set up the various connection\n    > schemes.\n    """"""\n    q = queue.Queue()\n\n    def on_signal(signo, _stack_frame):\n        q.put(signo)\n\n    orig_handler = {}\n    for x in [signal.SIGUSR1, signal.SIGCHLD]:\n        orig_handler[x] = signal.signal(x, on_signal)\n\n    xorg = subprocess.Popen(\n        preexec_fn=lambda: signal.signal(signal.SIGUSR1, signal.SIG_IGN),\n        *args, **kwargs)\n\n    try:\n        while True:\n            signo = q.get(True, 10)\n            if signo == signal.SIGUSR1 or xorg.poll() is not None:\n                return xorg\n    except:\n        xorg.kill()\n        raise\n    finally:\n        for signo, handler in orig_handler.items():\n            signal.signal(signo, handler)\n\n\n@contextmanager\ndef x_server(width, height, verbose=False):\n    with open(os.path.dirname(__file__) + \'/xorg.conf.in\') as f:\n        xorg_conf_template = f.read()\n\n    # This is a racy way of finding a free X display but is a lot simpler than\n    # the alternatives:\n    display_no = None\n    for display_no in sorted(range(10, 100), key=lambda k: random.random()):\n        if not os.path.exists(\'/tmp/.X11-unix/X%i\' % display_no):\n            break\n    else:\n        raise XFailedToStartError(\n            ""No available X display numbers (tried displays 10 to 99)"")\n\n    with named_temporary_directory(prefix=\'stbt-xorg-\') as tmp, \\\n            open(\'/dev/null\', \'r\') as dev_null:\n\n        with open(\'%s/xorg.conf\' % tmp, \'w\') as xorg_conf:\n            xorg_conf.write(xorg_conf_template.format(\n                width=width, height=height))\n\n        if verbose:\n            DEVNULL_W = open(\'/dev/null\', \'w\')\n            kwargs = {\'stdout\': DEVNULL_W, \'stderr\': subprocess.STDOUT}\n        else:\n            kwargs = {}\n        xorg = _start_x(\n            [\'Xorg\', \'-noreset\', \'+extension\', \'GLX\',\n             \'+extension\', \'RANDR\', \'+extension\', \'RENDER\',\n             \'-config\', \'xorg.conf\', \'-logfile\', \'./xorg.log\',\n             \'-nolisten\', \'tcp\', \':%i\' % display_no],\n            cwd=tmp, stdin=dev_null, close_fds=True, **kwargs)\n        try:\n            if xorg.poll() is not None:\n                raise XFailedToStartError(\n                    ""Failed to start X: Exited with status %i""\n                    % xorg.returncode)\n            yield "":%i"" % display_no\n        finally:\n            if xorg.poll() is None:\n                xorg.terminate()\n                xorg.wait()\n            if verbose:\n                sys.stderr.write(""\\nxorg.log:\\n"")\n                with open(""%s/xorg.log"" % tmp, ""r"") as log:\n                    sys.stderr.write("""".join(log.readlines()))\n'"
_stbt/xxhash.py,0,"b'""""""\nA ctypes wrapper around the xxhash library included in stb-tester.  xxhash is\na non-cryptographic hash that is *fast*.  In my experiments hashing a 720p image\nwith xxhash takes ~242us, whereas using hash() builtin or hashlib.sha1 takes\n>3ms.\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport binascii\nimport ctypes\nimport os\nimport struct\nimport sys\n\n_libxxhash = ctypes.CDLL(\n    os.path.dirname(os.path.abspath(__file__)) + ""/libxxhash.so"")\n\n_XXH_errorcode = ctypes.c_int\n_XXH64_hash_t = ctypes.c_ulonglong\n_XXH64_state_t = ctypes.c_void_p\n\n# _XXH64_hash_t XXH64 (const void* input, size_t length,\n#                      unsigned long long seed);\n_libxxhash.XXH64.argtypes = [\n    ctypes.c_void_p, ctypes.c_size_t, ctypes.c_ulonglong]\n_libxxhash.XXH64.restype = _XXH64_hash_t\n\n# XXH64_state_t* XXH64_createState(void);\n_libxxhash.XXH64_createState.argtypes = []\n_libxxhash.XXH64_createState.restype = ctypes.c_void_p\n\n# XXH_errorcode  XXH64_freeState(XXH64_state_t* statePtr);\n_libxxhash.XXH64_freeState.argtypes = [_XXH64_state_t]\n_libxxhash.XXH64_freeState.restype = _XXH_errorcode\n\n# XXH_errorcode XXH64_reset  (XXH64_state_t* statePtr, unsigned long long seed);\n_libxxhash.XXH64_reset.argtypes = [_XXH64_state_t, ctypes.c_ulonglong]\n_libxxhash.XXH64_reset.restype = _XXH_errorcode\n\n# XXH_errorcode XXH64_update (\n#    XXH64_state_t* statePtr, const void* input, size_t length);\n_libxxhash.XXH64_update.argtypes = [\n    _XXH64_state_t, ctypes.c_void_p, ctypes.c_size_t]\n_libxxhash.XXH64_update.restype = _XXH_errorcode\n\n# XXH64_hash_t  XXH64_digest (const XXH64_state_t* statePtr);\n_libxxhash.XXH64_digest.argtypes = [_XXH64_state_t]\n_libxxhash.XXH64_digest.restype = _XXH64_hash_t\n\n\nclass Xxhash64(object):\n    __slots__ = [""_state""]\n    digest_size = 16\n    name = ""xxhash64""\n\n    def __init__(self, seed=0):\n        self._state = _libxxhash.XXH64_createState()\n        _libxxhash.XXH64_reset(self._state, seed)\n\n    def __del__(self):\n        _libxxhash.XXH64_freeState(self._state)\n\n    def update(self, data):\n        # Passing a buffer/memoryview object via ctypes is inconvenient.  See\n        # http://thread.gmane.org/gmane.comp.python.devel/134936/focus=134941\n        if sys.version_info.major == 2:  # Python 2\n            buf = buffer(data)  # pylint:disable=undefined-variable\n        else:  # Python 3\n            buf = memoryview(data)\n        address = ctypes.c_void_p()\n        length = ctypes.c_ssize_t()\n        ctypes.pythonapi.PyObject_AsReadBuffer(\n            ctypes.py_object(buf), ctypes.byref(address), ctypes.byref(length))\n        assert length.value >= 0\n\n        _libxxhash.XXH64_update(\n            self._state, address, ctypes.c_size_t(length.value))\n\n    def digest(self):\n        return struct.pack("">Q"", _libxxhash.XXH64_digest(self._state))\n\n    def hexdigest(self):\n        return binascii.hexlify(self.digest()).decode(""utf-8"")\n'"
stbt/__init__.py,0,"b'# coding: utf-8\n""""""Main stb-tester python module. Intended to be used with `stbt run`.\n\nSee `man stbt` and http://stb-tester.com for documentation.\n\nCopyright 2012-2013 YouView TV Ltd and contributors.\nCopyright 2013-2018 stb-tester.com Ltd.\nLicense: LGPL v2.1 or (at your option) any later version (see\nhttps://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nfrom contextlib import contextmanager\n\nfrom _stbt.black import (\n    is_screen_black)\nfrom _stbt.config import (\n    ConfigurationError,\n    get_config)\nfrom _stbt.frameobject import (\n    for_object_repository,\n    FrameObject)\nfrom _stbt.grid import (\n    Grid,\n    grid_to_navigation_graph)\nfrom _stbt.imgutils import (\n    crop,\n    Frame,\n    load_image,\n    save_frame)\nfrom _stbt.logging import (\n    debug)\nfrom _stbt.match import (\n    ConfirmMethod,\n    match,\n    match_all,\n    MatchMethod,\n    MatchParameters,\n    MatchResult,\n    MatchTimeout,\n    wait_for_match)\nfrom _stbt.motion import (\n    detect_motion,\n    MotionResult,\n    MotionTimeout,\n    wait_for_motion)\nfrom _stbt.ocr import (\n    apply_ocr_corrections,\n    match_text,\n    ocr,\n    OcrEngine,\n    OcrMode,\n    set_global_ocr_corrections,\n    TextMatchResult)\nfrom _stbt.precondition import (\n    as_precondition,\n    PreconditionError)\nfrom _stbt.transition import (\n    press_and_wait,\n    TransitionStatus,\n    wait_for_transition_to_end)\nfrom _stbt.types import (\n    NoVideo,\n    Position,\n    Region,\n    UITestError,\n    UITestFailure)\nfrom _stbt.wait import (\n    wait_until)\nfrom stbt.keyboard import Keyboard\n\n__all__ = [\n    ""apply_ocr_corrections"",\n    ""as_precondition"",\n    ""ConfigurationError"",\n    ""ConfirmMethod"",\n    ""crop"",\n    ""debug"",\n    ""detect_motion"",\n    ""draw_text"",\n    ""for_object_repository"",\n    ""Frame"",\n    ""FrameObject"",\n    ""frames"",\n    ""get_config"",\n    ""get_frame"",\n    ""Grid"",\n    ""grid_to_navigation_graph"",\n    ""is_screen_black"",\n    ""Keyboard"",\n    ""last_keypress"",\n    ""load_image"",\n    ""match"",\n    ""match_all"",\n    ""match_text"",\n    ""MatchMethod"",\n    ""MatchParameters"",\n    ""MatchResult"",\n    ""MatchTimeout"",\n    ""MotionResult"",\n    ""MotionTimeout"",\n    ""NoVideo"",\n    ""ocr"",\n    ""OcrEngine"",\n    ""OcrMode"",\n    ""Position"",\n    ""PreconditionError"",\n    ""press"",\n    ""press_and_wait"",\n    ""press_until_match"",\n    ""Region"",\n    ""save_frame"",\n    ""set_global_ocr_corrections"",\n    ""TextMatchResult"",\n    ""TransitionStatus"",\n    ""UITestError"",\n    ""UITestFailure"",\n    ""wait_for_match"",\n    ""wait_for_motion"",\n    ""wait_for_transition_to_end"",\n    ""wait_until"",\n]\n\n# Functions available to stbt scripts\n# ===========================================================================\n\n\ndef last_keypress():\n    """"""Returns information about the last key-press sent to the device under\n    test.\n\n    See the return type of `stbt.press`.\n    """"""\n    return _dut.last_keypress()\n\n\ndef press(key, interpress_delay_secs=None, hold_secs=None):\n    """"""Send the specified key-press to the device under test.\n\n    :param str key:\n        The name of the key/button.\n\n        If you are using infrared control, this is a key name from your\n        lircd.conf configuration file.\n\n        If you are using HDMI CEC control, see the available key names\n        `here <https://github.com/stb-tester/stb-tester/blob/v28/_stbt/control_gpl.py#L18-L117>`__.\n        Note that some devices might not understand all of the CEC commands in\n        that list.\n\n    :type interpress_delay_secs: int or float\n    :param interpress_delay_secs:\n        The minimum time to wait after a previous key-press, in order to\n        accommodate the responsiveness of the device-under-test.\n\n        This defaults to 0.3. You can override the global default value by\n        setting ``interpress_delay_secs`` in the ``[press]`` section of\n        :ref:`.stbt.conf`.\n\n    :type hold_secs: int or float\n    :param hold_secs:\n        Hold the key down for the specified duration (in seconds). Currently\n        this is implemented for the infrared, HDMI CEC, and Roku controls.\n        There is a maximum limit of 60 seconds.\n\n    :returns:\n        An object with the following attributes:\n\n        * **key** (*str*) \xe2\x80\x93 the name of the key that was pressed.\n        * **start_time** (*float*) \xe2\x80\x93 the time just before the keypress started\n          (in seconds since the unix epoch, like ``time.time()`` and\n          ``stbt.Frame.time``).\n        * **end_time** (*float*) \xe2\x80\x93 the time when transmission of the keypress\n          signal completed.\n        * **frame_before** (`stbt.Frame`) \xe2\x80\x93 the most recent video-frame just\n          before the keypress started. Typically this is used by functions like\n          `stbt.press_and_wait` to detect when the device-under-test reacted to\n          the keypress.\n\n    * Added in v29: The ``hold_secs`` parameter.\n    * Added in v30: Returns an object with keypress timings, instead of\n      ``None``.\n    """"""\n    return _dut.press(key, interpress_delay_secs, hold_secs)\n\n\ndef pressing(key, interpress_delay_secs=None):\n    """"""Context manager that will press and hold the specified key for the\n    duration of the ``with`` code block.\n\n    For example, this will hold KEY_RIGHT until ``wait_for_match`` finds a\n    match or times out::\n\n        with stbt.pressing(""KEY_RIGHT""):\n            stbt.wait_for_match(""last-page.png"")\n\n    The same limitations apply as `stbt.press`\'s ``hold_secs`` parameter.\n    """"""\n    return _dut.pressing(key, interpress_delay_secs)\n\n\ndef draw_text(text, duration_secs=3):\n    """"""Write the specified text to the output video.\n\n    :param str text: The text to write.\n\n    :param duration_secs: The number of seconds to display the text.\n    :type duration_secs: int or float\n    """"""\n    debug(text)\n    return _dut.draw_text(text, duration_secs)\n\n\ndef press_until_match(\n        key,\n        image,\n        interval_secs=None,\n        max_presses=None,\n        match_parameters=None,\n        region=Region.ALL):\n    """"""Call `press` as many times as necessary to find the specified image.\n\n    :param key: See `press`.\n\n    :param image: See `match`.\n\n    :type interval_secs: int or float\n    :param interval_secs:\n        The number of seconds to wait for a match before pressing again.\n        Defaults to 3.\n\n        You can override the global default value by setting ``interval_secs``\n        in the ``[press_until_match]`` section of :ref:`.stbt.conf`.\n\n    :param int max_presses:\n        The number of times to try pressing the key and looking for the image\n        before giving up and raising `MatchTimeout`. Defaults to 10.\n\n        You can override the global default value by setting ``max_presses``\n        in the ``[press_until_match]`` section of :ref:`.stbt.conf`.\n\n    :param match_parameters: See `match`.\n    :param region: See `match`.\n\n    :returns: `MatchResult` when the image is found.\n    :raises: `MatchTimeout` if no match is found after ``timeout_secs`` seconds.\n    """"""\n    return _dut.press_until_match(\n        key, image, interval_secs, max_presses, match_parameters, region)\n\n\ndef frames(timeout_secs=None):\n    """"""Generator that yields video frames captured from the device-under-test.\n\n    :type timeout_secs: int or float or None\n    :param timeout_secs:\n      A timeout in seconds. After this timeout the iterator will be exhausted.\n      That is, a ``for`` loop like ``for f in frames(timeout_secs=10)`` will\n      terminate after 10 seconds. If ``timeout_secs`` is ``None`` (the default)\n      then the iterator will yield frames forever. Note that you can stop\n      iterating (for example with ``break``) at any time.\n\n    :rtype: Iterator[stbt.Frame]\n    :returns:\n      An iterator of frames in OpenCV format (`stbt.Frame`).\n    """"""\n    return _dut.frames(timeout_secs)\n\n\ndef get_frame():\n    """"""Grabs a video frame captured from the device-under-test.\n\n    :returns: The latest video frame in OpenCV format (a `stbt.Frame`).\n    """"""\n    return _dut.get_frame()\n\n\n# Internal\n# ===========================================================================\n\nclass UnconfiguredDeviceUnderTest(object):\n    # pylint:disable=unused-argument\n    def last_keypress(self):\n        return None\n\n    def press(self, *args, **kwargs):\n        raise RuntimeError(\n            ""stbt.press isn\'t configured to run on your hardware"")\n\n    def pressing(self, *args, **kwargs):\n        raise RuntimeError(\n            ""stbt.pressing isn\'t configured to run on your hardware"")\n\n    def draw_text(self, *args, **kwargs):\n        raise RuntimeError(\n            ""stbt.draw_text isn\'t configured to run on your hardware"")\n\n    def press_until_match(self, *args, **kwargs):\n        raise RuntimeError(\n            ""stbt.press_until_match isn\'t configured to run on your hardware"")\n\n    def frames(self, *args, **kwargs):\n        raise RuntimeError(\n            ""stbt.frames isn\'t configured to run on your hardware"")\n\n    def get_frame(self, *args, **kwargs):\n        raise RuntimeError(\n            ""stbt.get_frame isn\'t configured to run on your hardware"")\n\n\n_dut = UnconfiguredDeviceUnderTest()\n\n\n@contextmanager\ndef _set_dut_singleton(dut):\n    global _dut\n    old_dut = dut\n    try:\n        _dut = dut\n        yield dut\n    finally:\n        _dut = old_dut\n'"
stbt/android.py,0,"b'# -*- coding: utf-8 -*-\n\n""""""Python module to control Android phones via `ADB`_ from Stb-tester scripts.\n\nCopyright \xc2\xa9 2017 Stb-tester.com Ltd.\nLicense: LGPL v2.1 or (at your option) any later version (see\nhttps://github.com/stb-tester/stb-tester/blob/master/LICENSE for details).\n\nUsage::\n\n    from stbt.android import AdbDevice\n    adb = AdbDevice()\n    adb.tap((100, 50))\n\nFor feedback (video from the Android device-under-test) you can use:\n\n* Stb-tester\'s standard HDMI video-capture if the device-under-test is an\n  Android set-top box.\n* HDMI video-capture from a tablet or phone with an MHL adapter.\n* A camera pointed at the phone\'s screen with an `Stb-tester CAMERA`_ device.\n* Screenshots captured over USB via ADB.\n\nFor more details on the benefits and trade-offs of each method, see\n<https://stb-tester.com/blog/2017/02/21/testing-video-playback-on-mobile-devices>.\n\nNote that you can instead use Stb-tester features such as image-matching\nin your existing Selenium/WebDriver/Appium tests. See\n<https://stb-tester.com/blog/2016/09/20/add-visual-verification-to-your-selenium-tests-with-stb-tester>.\n\n.. _ADB: https://developer.android.com/studio/command-line/adb.html\n.. _Stb-tester CAMERA: https://stb-tester.com/stb-tester-camera\n""""""\n\nfrom __future__ import division\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nfrom future.utils import raise_\n\nimport configparser\nimport logging\nimport re\nimport subprocess\nimport sys\nimport time\nfrom collections import namedtuple\n\nfrom enum import Enum\n\nfrom _stbt.logging import debug\n\n\nclass CoordinateSystem(Enum):\n    # pylint:disable=pointless-string-statement\n\n    """"""How to translate coordinates from the video-frames processed by your\n    test script, to the coordinates expected by ADB for tap & swipe events.\n\n    When you tell ADB to send a tap or swipe event you must give it x & y\n    coordinates. The coordinate system matches the orientation of the device.\n    We\'ll call these the physical coordinates. For example my phone\'s display\n    is Full HD (1080 pixels x 1920 pixels):\n\n    ===================  ======  ======  ======================================\n    Logical orientation  x       y       (0, 0) is\n    ===================  ======  ======  ======================================\n    Portrait             0-1080  0-1920  top-left\n    Landscape            0-1920  0-1080  top-left (i.e. the top-right corner if\n                                         the phone is physically in portrait)\n    ===================  ======  ======  ======================================\n\n    Note that an app can force the device to think it\'s in portrait orientation\n    even if you\'re physically holding the device in landscape orientation. We\n    call this the ""logical orientation"". Similarly, an app can force the device\n    into logical landscape orientation even if you have switched off auto-rotate\n    in the device\'s settings menu.\n\n    The video-frames that you analyse in your test scripts may not match the\n    physical resolution of the device. For example if you\'re using a camera\n    pointed at the device\'s screen, the resolution of your screenshots (even\n    after geometric correction by the `Stb-tester CAMERA`_) will depend on the\n    resolution of the camera, not of the device under test.\n\n    You can give `AdbDevice.tap` and `AdbDevice.swipe` the coordinates from\n    your video-frame (for example, you can pass in ``stbt.match(...).region``)\n    and the CoordinateSystem will ensure that the coordinates are converted to\n    physical coordinates in the appropriate way before passing them on to ADB.\n    """"""\n\n    ADB_NATIVE = 0\n    """"""Frames are captured via ADB screenshot.\n\n    Frames will be in the same orientation & resolution as the physical device.\n    """"""\n\n    ADB_720P = 1\n    """"""Frames are captured via ADB screenshot and then scaled to 720p.\n\n    Frames will be in the same orientation as the physical device, but scaled.\n    """"""\n\n    HDMI_720P = 2\n    """"""\n    Frames are captured via HDMI (using an MHL cable) at 720p.\n\n    Frames will always be in landscape orientation. If the device is in\n    portrait orientation, you\'ll get black bars to the left & right. If the\n    device is in landscape orientation, the frame will match what you see on\n    the device (this assumes that the device\'s physical aspect ratio matches\n    the aspect ratio of HDMI).\n    """"""\n\n    CAMERA_720P = 3\n    """"""Frames are captured from an `Stb-tester CAMERA`_ pointing at the\n    device\'s screen.\n\n    The camera & device must both be physically in landscape orientation.\n\n    Frames will always be in landscape orientation; if the device is in logical\n    portrait orientation the image will be rotated 90\xc2\xb0 anti-clockwise.\n    """"""\n\n\nclass AdbDevice(object):\n    """"""Control an Android device using `ADB`_.\n\n    Default values for each parameter can be specified in your ""stbt.conf""\n    config file under the ""[android]"" section.\n\n    :param string adb_server:\n        The ADB server (that is, the PC connected to the Android device).\n        Defaults to localhost.\n    :param string adb_device:\n        Serial number of the Android device connected to ADB server PC (you can\n        get this by running ``adb devices -l``). If not specified, there must be\n        only one Android device connected. If ``tcpip=True`` this must be the\n        Android device\'s IP address.\n    :param string adb_binary:\n        The path to the ADB client executable. Defaults to ""adb"".\n    :param bool tcpip:\n        The ADB server communicates with the Android device via TCP/IP, not\n        USB. This requires that you have enabled TCP/IP ADB access on the\n        device. Defaults to False.\n    :param CoordinateSystem coordinate_system:\n        How to convert the coordinates you give to `AdbDevice.tap` and\n        `AdbDevice.swipe` into the coordinates required by ADB. See\n        `CoordinateSystem` for details. Defaults to ``CAMERA_720P`` on the\n        `Stb-tester CAMERA`_, or ``ADB_NATIVE`` elsewhere.\n    """"""\n\n    def __init__(self, adb_server=None, adb_device=None, adb_binary=None,\n                 tcpip=None, coordinate_system=None, _config=None):\n\n        if _config is None:\n            import _stbt.config\n            _config = _stbt.config._config_init()  # pylint:disable=protected-access\n\n        self.adb_server = adb_server or _config.get(""android"", ""adb_server"",\n                                                    fallback=None)\n        self._adb_device = adb_device or _config.get(""android"", ""adb_device"",\n                                                     fallback=None)\n        self.adb_binary = adb_binary or _config.get(""android"", ""adb_binary"",\n                                                    fallback=""adb"")\n        if tcpip is None:\n            try:\n                tcpip = _config.getboolean(""android"", ""tcpip"")\n            except configparser.Error:\n                tcpip = False\n        self.tcpip = tcpip\n\n        if coordinate_system is None:\n            name = _config.get(""android"", ""coordinate_system"",\n                               fallback=""ADB_NATIVE"")\n            if name not in CoordinateSystem.__members__:  # pylint:disable=no-member\n                raise ValueError(\n                    ""Invalid value \'%s\' for android.coordinate_system in ""\n                    ""config file. Valid values are %s.""\n                    % (name, "", "".join(""\'%s\'"" % k for k in\n                                       CoordinateSystem.__members__)))  # pylint:disable=no-member\n            coordinate_system = CoordinateSystem[name]\n        self.coordinate_system = coordinate_system\n\n        if self.tcpip:\n            self._connect(timeout_secs=60)\n\n    @property\n    def adb_device(self):\n        if self.tcpip and self._adb_device and "":"" not in self._adb_device:\n            return self._adb_device + "":5555""\n        else:\n            return self._adb_device\n\n    def adb(self, command, timeout_secs=5 * 60, capture_output=False, **kwargs):\n        """"""Run any ADB command.\n\n        For example, the following code will use ""adb shell am start"" to launch\n        an app on the device::\n\n            d = AdbDevice(...)\n            d.adb([""shell"", ""am"", ""start"", ""-S"",\n                   ""com.example.myapp/com.example.myapp.MainActivity""])\n\n        ``command`` and ``kwargs`` are the same as `subprocess.check_output`,\n        except that ``shell``, ``stdout`` and ``stderr`` are not allowed.\n\n        Raises `AdbError` if the command fails.\n        """"""\n        try:\n            if self.tcpip:\n                self._connect(timeout_secs)\n            output = self._adb(command, timeout_secs, **kwargs)\n        except subprocess.CalledProcessError as e:\n            raise_(AdbError(e.returncode, e.cmd, e.output.decode(""utf-8""),\n                            self),\n                   None, sys.exc_info()[2])\n        if capture_output:\n            return output\n        else:\n            sys.stderr.write(output)\n            return None\n\n    def devices(self):\n        try:\n            return self._adb([""devices"", ""-l""], timeout_secs=5)\n        except subprocess.CalledProcessError as e:\n            return e.output.decode(""utf-8"")\n\n    def get_frame(self):\n        """"""Take a screenshot using ADB.\n\n        If you are capturing video from the Android device via another method\n        (HDMI or `Stb-tester CAMERA`_) sometimes it can be useful to capture a\n        frame via ADB for debugging. This function will manipulate the ADB\n        screenshot (scale and/or rotate it) to match the screenshots from your\n        main video-capture method as closely as possible, as specified by the\n        `CoordinateSystem`.\n\n        :returns: A `stbt.Frame`, that is, an image in OpenCV format. Note that\n            the ``time`` attribute won\'t be very accurate (probably to <0.5s or\n            so).\n        """"""\n\n        import cv2\n        import numpy\n        import stbt\n\n        for attempt in range(1, 4):\n            timestamp = time.time()\n            data = (self.adb([""shell"", ""screencap"", ""-p""],\n                             timeout_secs=60, capture_output=True)\n                    .replace(""\\r\\n"", ""\\n""))\n            img = cv2.imdecode(\n                numpy.asarray(bytearray(data), dtype=numpy.uint8),\n                cv2.IMREAD_COLOR)\n            if img is None:\n                logging.warning(\n                    ""AdbDevice.get_frame: Failed to get screenshot ""\n                    ""via ADB (attempt %d/3)\\n""\n                    ""Length of data: %d"", attempt, len(data))\n            else:\n                break\n        else:\n            raise RuntimeError(\n                ""Failed to capture screenshot from android device"")\n\n        img = _resize(img, self.coordinate_system)\n        return stbt.Frame(img, time=timestamp)\n\n    def press(self, key):\n        """"""Send a keypress.\n\n        :param str key: An Android keycode as listed in\n            <https://developer.android.com/reference/android/view/KeyEvent.html>.\n            Particularly useful key codes are ""KEYCODE_HOME"" and\n            ""KEYCODE_BACK"", which are physical buttons on some phones so you\n            can\'t hit them with `AdbDevice.tap`. Also accepts standard\n            Stb-tester key names like ""KEY_HOME"" and ""KEY_BACK"".\n        """"""\n        # ""adb shell input keyevent xxx"" always returns success, so we need to\n        # validate key names.\n        if key in _KEYCODE_MAPPINGS:\n            key = _KEYCODE_MAPPINGS[key]  # Map Stb-tester names to Android ones\n        if key not in _ANDROID_KEYCODES:\n            raise ValueError(""Unknown key code %r"" % (key,))\n        debug(""AdbDevice.press(%r)"" % key)\n        self.adb([""shell"", ""input"", ""keyevent"", key], timeout_secs=10)\n\n    def swipe(self, start_position, end_position):\n        """"""Swipe from one point to another point.\n\n        :param start_position:\n            A `stbt.Region` or (x, y) tuple of coordinates at which to start.\n        :param end_position:\n            A `stbt.Region` or (x, y) tuple of coordinates at which to stop.\n\n        Example::\n\n          d.swipe((100, 100), (100, 400))\n\n        """"""\n        x1, y1 = _centre_point(start_position)\n        x2, y2 = _centre_point(end_position)\n        debug(""AdbDevice.swipe((%d,%d), (%d,%d))"" % (x1, y1, x2, y2))\n\n        x1, y1 = self._to_native_coordinates(x1, y1)\n        x2, y2 = self._to_native_coordinates(x2, y2)\n        command = [""shell"", ""input"", ""swipe"",\n                   str(x1), str(y1), str(x2), str(y2)]\n        self.adb(command, timeout_secs=10)\n\n    def tap(self, position):\n        """"""Tap on a particular location.\n\n        :param position: A `stbt.Region`, or an (x,y) tuple.\n\n        Example::\n\n            d.tap((100, 20))\n            d.tap(stbt.match(...).region)\n\n        """"""\n        x, y = _centre_point(position)\n        debug(""AdbDevice.tap((%d,%d))"" % (x, y))\n\n        x, y = self._to_native_coordinates(x, y)\n        self.adb([""shell"", ""input"", ""tap"", str(x), str(y)], timeout_secs=10)\n\n    def _adb(self, command, timeout_secs=None, **kwargs):\n        _command = []\n        if timeout_secs is not None:\n            _command += [""timeout"", ""%fs"" % timeout_secs]\n        _command += [self.adb_binary]\n        if self.adb_server:\n            _command += [""-H"", self.adb_server]\n        if self.adb_device:\n            _command += [""-s"", self.adb_device]\n        _command += command\n        debug(""AdbDevice.adb: About to run command: %r\\n"" % _command)\n        output = subprocess.check_output(\n            _command, stderr=subprocess.STDOUT, **kwargs).decode(""utf-8"")\n        return output\n\n    def _connect(self, timeout_secs):\n        if not self.adb_device:\n            raise RuntimeError(\'AdbDevice: error: If ""tcpip=True"" \'\n                               \'you must specify ""adb_device""\')\n        try:\n            if self.adb_device in self._adb([""devices""]):\n                return\n        except subprocess.CalledProcessError:\n            pass\n\n        # ""adb connect"" always returns success; we have to parse the output\n        # which looks like ""connected to 192.168.2.163:5555"" or\n        # ""already connected to 192.168.2.163:5555"" or\n        # ""unable to connect to 192.168.2.100:5555"".\n        output = self._adb([""connect"", self.adb_device], timeout_secs)\n        if (""connected to %s"" % self.adb_device) not in output:\n            sys.stderr.write(output)\n            raise AdbError(0, ""adb connect %s"" % self.adb_device, output, self)\n        time.sleep(2)\n\n    def _to_native_coordinates(self, x, y):\n        if self.coordinate_system == CoordinateSystem.ADB_NATIVE:\n            return x, y\n        else:\n            return _to_native_coordinates(\n                x, y, self.coordinate_system, self._get_display_dimensions())\n\n    def _get_display_dimensions(self):\n        return _parse_display_dimensions(\n            self.adb([""shell"", ""dumpsys"", ""window""],\n                     timeout_secs=10, capture_output=True))\n\n\nclass AdbError(Exception):\n    def __init__(self, returncode, cmd, output=None, adb_control=None):\n        super(AdbError, self).__init__()\n        self.returncode = returncode\n        self.cmd = cmd\n        self.output = output\n        self.adb_devices = None\n        if adb_control:\n            self.adb_devices = adb_control.devices()\n\n    def __str__(self):\n        return ""Command \'%s\' failed with exit status %d. Output:\\n%s\\n%s"" % (\n            self.cmd, self.returncode, self.output, self.adb_devices)\n\n\n# https://developer.android.com/reference/android/view/KeyEvent.html\n#\n# I generated this list with:\n#\n#   curl https://android.googlesource.com/platform/frameworks/base/+/master/core/java/android/view/KeyEvent.java?format=TEXT |\n#   base64 -d | grep -o \'KEYCODE_[A-Z0-9_]*\' | sort | uniq |\n#   grep -v -e KEYCODE_UNKNOWN -e \'KEYCODE_$\' | sed \'s/^.*$/    ""&"",/\'\n_ANDROID_KEYCODES = [\n    ""KEYCODE_0"",\n    ""KEYCODE_1"",\n    ""KEYCODE_11"",\n    ""KEYCODE_12"",\n    ""KEYCODE_2"",\n    ""KEYCODE_3"",\n    ""KEYCODE_3D_MODE"",\n    ""KEYCODE_4"",\n    ""KEYCODE_5"",\n    ""KEYCODE_6"",\n    ""KEYCODE_7"",\n    ""KEYCODE_8"",\n    ""KEYCODE_9"",\n    ""KEYCODE_A"",\n    ""KEYCODE_ALL_APPS"",\n    ""KEYCODE_ALT_LEFT"",\n    ""KEYCODE_ALT_RIGHT"",\n    ""KEYCODE_APOSTROPHE"",\n    ""KEYCODE_APP_SWITCH"",\n    ""KEYCODE_ASSIST"",\n    ""KEYCODE_AT"",\n    ""KEYCODE_AVR_INPUT"",\n    ""KEYCODE_AVR_POWER"",\n    ""KEYCODE_B"",\n    ""KEYCODE_BACK"",\n    ""KEYCODE_BACKSLASH"",\n    ""KEYCODE_BOOKMARK"",\n    ""KEYCODE_BREAK"",\n    ""KEYCODE_BRIGHTNESS_DOWN"",\n    ""KEYCODE_BRIGHTNESS_UP"",\n    ""KEYCODE_BUTTON_1"",\n    ""KEYCODE_BUTTON_10"",\n    ""KEYCODE_BUTTON_11"",\n    ""KEYCODE_BUTTON_12"",\n    ""KEYCODE_BUTTON_13"",\n    ""KEYCODE_BUTTON_14"",\n    ""KEYCODE_BUTTON_15"",\n    ""KEYCODE_BUTTON_16"",\n    ""KEYCODE_BUTTON_2"",\n    ""KEYCODE_BUTTON_3"",\n    ""KEYCODE_BUTTON_4"",\n    ""KEYCODE_BUTTON_5"",\n    ""KEYCODE_BUTTON_6"",\n    ""KEYCODE_BUTTON_7"",\n    ""KEYCODE_BUTTON_8"",\n    ""KEYCODE_BUTTON_9"",\n    ""KEYCODE_BUTTON_A"",\n    ""KEYCODE_BUTTON_B"",\n    ""KEYCODE_BUTTON_C"",\n    ""KEYCODE_BUTTON_L1"",\n    ""KEYCODE_BUTTON_L2"",\n    ""KEYCODE_BUTTON_MODE"",\n    ""KEYCODE_BUTTON_R1"",\n    ""KEYCODE_BUTTON_R2"",\n    ""KEYCODE_BUTTON_SELECT"",\n    ""KEYCODE_BUTTON_START"",\n    ""KEYCODE_BUTTON_THUMBL"",\n    ""KEYCODE_BUTTON_THUMBR"",\n    ""KEYCODE_BUTTON_X"",\n    ""KEYCODE_BUTTON_Y"",\n    ""KEYCODE_BUTTON_Z"",\n    ""KEYCODE_C"",\n    ""KEYCODE_CALCULATOR"",\n    ""KEYCODE_CALENDAR"",\n    ""KEYCODE_CALL"",\n    ""KEYCODE_CAMERA"",\n    ""KEYCODE_CAPS_LOCK"",\n    ""KEYCODE_CAPTIONS"",\n    ""KEYCODE_CHANNEL_DOWN"",\n    ""KEYCODE_CHANNEL_UP"",\n    ""KEYCODE_CLEAR"",\n    ""KEYCODE_COMMA"",\n    ""KEYCODE_CONTACTS"",\n    ""KEYCODE_COPY"",\n    ""KEYCODE_CTRL_LEFT"",\n    ""KEYCODE_CTRL_RIGHT"",\n    ""KEYCODE_CUT"",\n    ""KEYCODE_D"",\n    ""KEYCODE_DEL"",\n    ""KEYCODE_DPAD_CENTER"",\n    ""KEYCODE_DPAD_DOWN"",\n    ""KEYCODE_DPAD_DOWN_LEFT"",\n    ""KEYCODE_DPAD_DOWN_RIGHT"",\n    ""KEYCODE_DPAD_LEFT"",\n    ""KEYCODE_DPAD_RIGHT"",\n    ""KEYCODE_DPAD_UP"",\n    ""KEYCODE_DPAD_UP_LEFT"",\n    ""KEYCODE_DPAD_UP_RIGHT"",\n    ""KEYCODE_DVR"",\n    ""KEYCODE_E"",\n    ""KEYCODE_EISU"",\n    ""KEYCODE_ENDCALL"",\n    ""KEYCODE_ENTER"",\n    ""KEYCODE_ENVELOPE"",\n    ""KEYCODE_EQUALS"",\n    ""KEYCODE_ESCAPE"",\n    ""KEYCODE_EXPLORER"",\n    ""KEYCODE_F"",\n    ""KEYCODE_F1"",\n    ""KEYCODE_F10"",\n    ""KEYCODE_F11"",\n    ""KEYCODE_F12"",\n    ""KEYCODE_F2"",\n    ""KEYCODE_F3"",\n    ""KEYCODE_F4"",\n    ""KEYCODE_F5"",\n    ""KEYCODE_F6"",\n    ""KEYCODE_F7"",\n    ""KEYCODE_F8"",\n    ""KEYCODE_F9"",\n    ""KEYCODE_FOCUS"",\n    ""KEYCODE_FORWARD"",\n    ""KEYCODE_FORWARD_DEL"",\n    ""KEYCODE_FUNCTION"",\n    ""KEYCODE_G"",\n    ""KEYCODE_GRAVE"",\n    ""KEYCODE_GUIDE"",\n    ""KEYCODE_H"",\n    ""KEYCODE_HEADSETHOOK"",\n    ""KEYCODE_HELP"",\n    ""KEYCODE_HENKAN"",\n    ""KEYCODE_HOME"",\n    ""KEYCODE_I"",\n    ""KEYCODE_INFO"",\n    ""KEYCODE_INSERT"",\n    ""KEYCODE_J"",\n    ""KEYCODE_K"",\n    ""KEYCODE_KANA"",\n    ""KEYCODE_KATAKANA_HIRAGANA"",\n    ""KEYCODE_L"",\n    ""KEYCODE_LANGUAGE_SWITCH"",\n    ""KEYCODE_LAST_CHANNEL"",\n    ""KEYCODE_LEFT_BRACKET"",\n    ""KEYCODE_M"",\n    ""KEYCODE_MANNER_MODE"",\n    ""KEYCODE_MEDIA_AUDIO_TRACK"",\n    ""KEYCODE_MEDIA_CLOSE"",\n    ""KEYCODE_MEDIA_EJECT"",\n    ""KEYCODE_MEDIA_FAST_FORWARD"",\n    ""KEYCODE_MEDIA_NEXT"",\n    ""KEYCODE_MEDIA_PAUSE"",\n    ""KEYCODE_MEDIA_PLAY"",\n    ""KEYCODE_MEDIA_PLAY_PAUSE"",\n    ""KEYCODE_MEDIA_PREVIOUS"",\n    ""KEYCODE_MEDIA_RECORD"",\n    ""KEYCODE_MEDIA_REWIND"",\n    ""KEYCODE_MEDIA_SKIP_BACKWARD"",\n    ""KEYCODE_MEDIA_SKIP_FORWARD"",\n    ""KEYCODE_MEDIA_STEP_BACKWARD"",\n    ""KEYCODE_MEDIA_STEP_FORWARD"",\n    ""KEYCODE_MEDIA_STOP"",\n    ""KEYCODE_MEDIA_TOP_MENU"",\n    ""KEYCODE_MENU"",\n    ""KEYCODE_META_LEFT"",\n    ""KEYCODE_META_RIGHT"",\n    ""KEYCODE_MINUS"",\n    ""KEYCODE_MOVE_END"",\n    ""KEYCODE_MOVE_HOME"",\n    ""KEYCODE_MUHENKAN"",\n    ""KEYCODE_MUSIC"",\n    ""KEYCODE_MUTE"",\n    ""KEYCODE_N"",\n    ""KEYCODE_NAVIGATE_IN"",\n    ""KEYCODE_NAVIGATE_NEXT"",\n    ""KEYCODE_NAVIGATE_OUT"",\n    ""KEYCODE_NAVIGATE_PREVIOUS"",\n    ""KEYCODE_NOTIFICATION"",\n    ""KEYCODE_NUM"",\n    ""KEYCODE_NUM_LOCK"",\n    ""KEYCODE_NUMPAD_0"",\n    ""KEYCODE_NUMPAD_1"",\n    ""KEYCODE_NUMPAD_2"",\n    ""KEYCODE_NUMPAD_3"",\n    ""KEYCODE_NUMPAD_4"",\n    ""KEYCODE_NUMPAD_5"",\n    ""KEYCODE_NUMPAD_6"",\n    ""KEYCODE_NUMPAD_7"",\n    ""KEYCODE_NUMPAD_8"",\n    ""KEYCODE_NUMPAD_9"",\n    ""KEYCODE_NUMPAD_ADD"",\n    ""KEYCODE_NUMPAD_COMMA"",\n    ""KEYCODE_NUMPAD_DIVIDE"",\n    ""KEYCODE_NUMPAD_DOT"",\n    ""KEYCODE_NUMPAD_ENTER"",\n    ""KEYCODE_NUMPAD_EQUALS"",\n    ""KEYCODE_NUMPAD_LEFT_PAREN"",\n    ""KEYCODE_NUMPAD_MULTIPLY"",\n    ""KEYCODE_NUMPAD_RIGHT_PAREN"",\n    ""KEYCODE_NUMPAD_SUBTRACT"",\n    ""KEYCODE_O"",\n    ""KEYCODE_P"",\n    ""KEYCODE_PAGE_DOWN"",\n    ""KEYCODE_PAGE_UP"",\n    ""KEYCODE_PAIRING"",\n    ""KEYCODE_PASTE"",\n    ""KEYCODE_PERIOD"",\n    ""KEYCODE_PICTSYMBOLS"",\n    ""KEYCODE_PLUS"",\n    ""KEYCODE_POUND"",\n    ""KEYCODE_POWER"",\n    ""KEYCODE_PROG_BLUE"",\n    ""KEYCODE_PROG_GREEN"",\n    ""KEYCODE_PROG_RED"",\n    ""KEYCODE_PROG_YELLOW"",\n    ""KEYCODE_Q"",\n    ""KEYCODE_R"",\n    ""KEYCODE_RIGHT_BRACKET"",\n    ""KEYCODE_RO"",\n    ""KEYCODE_S"",\n    ""KEYCODE_SCROLL_LOCK"",\n    ""KEYCODE_SEARCH"",\n    ""KEYCODE_SEMICOLON"",\n    ""KEYCODE_SETTINGS"",\n    ""KEYCODE_SHIFT_LEFT"",\n    ""KEYCODE_SHIFT_RIGHT"",\n    ""KEYCODE_SLASH"",\n    ""KEYCODE_SLEEP"",\n    ""KEYCODE_SOFT_LEFT"",\n    ""KEYCODE_SOFT_RIGHT"",\n    ""KEYCODE_SOFT_SLEEP"",\n    ""KEYCODE_SPACE"",\n    ""KEYCODE_STAR"",\n    ""KEYCODE_STB_INPUT"",\n    ""KEYCODE_STB_POWER"",\n    ""KEYCODE_STEM_1"",\n    ""KEYCODE_STEM_2"",\n    ""KEYCODE_STEM_3"",\n    ""KEYCODE_STEM_PRIMARY"",\n    ""KEYCODE_SWITCH_CHARSET"",\n    ""KEYCODE_SYM"",\n    ""KEYCODE_SYSRQ"",\n    ""KEYCODE_SYSTEM_NAVIGATION_DOWN"",\n    ""KEYCODE_SYSTEM_NAVIGATION_LEFT"",\n    ""KEYCODE_SYSTEM_NAVIGATION_RIGHT"",\n    ""KEYCODE_SYSTEM_NAVIGATION_UP"",\n    ""KEYCODE_T"",\n    ""KEYCODE_TAB"",\n    ""KEYCODE_TV"",\n    ""KEYCODE_TV_ANTENNA_CABLE"",\n    ""KEYCODE_TV_AUDIO_DESCRIPTION"",\n    ""KEYCODE_TV_AUDIO_DESCRIPTION_MIX_DOWN"",\n    ""KEYCODE_TV_AUDIO_DESCRIPTION_MIX_UP"",\n    ""KEYCODE_TV_CONTENTS_MENU"",\n    ""KEYCODE_TV_DATA_SERVICE"",\n    ""KEYCODE_TV_INPUT"",\n    ""KEYCODE_TV_INPUT_COMPONENT_1"",\n    ""KEYCODE_TV_INPUT_COMPONENT_2"",\n    ""KEYCODE_TV_INPUT_COMPOSITE_1"",\n    ""KEYCODE_TV_INPUT_COMPOSITE_2"",\n    ""KEYCODE_TV_INPUT_HDMI_1"",\n    ""KEYCODE_TV_INPUT_HDMI_2"",\n    ""KEYCODE_TV_INPUT_HDMI_3"",\n    ""KEYCODE_TV_INPUT_HDMI_4"",\n    ""KEYCODE_TV_INPUT_VGA_1"",\n    ""KEYCODE_TV_MEDIA_CONTEXT_MENU"",\n    ""KEYCODE_TV_NETWORK"",\n    ""KEYCODE_TV_NUMBER_ENTRY"",\n    ""KEYCODE_TV_POWER"",\n    ""KEYCODE_TV_RADIO_SERVICE"",\n    ""KEYCODE_TV_SATELLITE"",\n    ""KEYCODE_TV_SATELLITE_BS"",\n    ""KEYCODE_TV_SATELLITE_CS"",\n    ""KEYCODE_TV_SATELLITE_SERVICE"",\n    ""KEYCODE_TV_TELETEXT"",\n    ""KEYCODE_TV_TERRESTRIAL_ANALOG"",\n    ""KEYCODE_TV_TERRESTRIAL_DIGITAL"",\n    ""KEYCODE_TV_TIMER_PROGRAMMING"",\n    ""KEYCODE_TV_ZOOM_MODE"",\n    ""KEYCODE_U"",\n    ""KEYCODE_V"",\n    ""KEYCODE_VOICE_ASSIST"",\n    ""KEYCODE_VOLUME_DOWN"",\n    ""KEYCODE_VOLUME_MUTE"",\n    ""KEYCODE_VOLUME_UP"",\n    ""KEYCODE_W"",\n    ""KEYCODE_WAKEUP"",\n    ""KEYCODE_WINDOW"",\n    ""KEYCODE_X"",\n    ""KEYCODE_Y"",\n    ""KEYCODE_YEN"",\n    ""KEYCODE_Z"",\n    ""KEYCODE_ZENKAKU_HANKAKU"",\n    ""KEYCODE_ZOOM_IN"",\n    ""KEYCODE_ZOOM_OUT"",\n]\n\n\n# Map a few standard Stb-tester key names to Android keycodes.\n# So far we just map the buttons on the Amazon Fire TV remote control:\n# https://developer.amazon.com/docs/fire-tv/remote-input.html#input-event-reference\n_KEYCODE_MAPPINGS = {\n    ""KEY_BACK"": ""KEYCODE_BACK"",\n    ""KEY_DOWN"": ""KEYCODE_DPAD_DOWN"",\n    ""KEY_FASTFORWARD"": ""KEYCODE_MEDIA_FAST_FORWARD"",\n    ""KEY_HOME"": ""KEYCODE_HOME"",\n    ""KEY_LEFT"": ""KEYCODE_DPAD_LEFT"",\n    ""KEY_MENU"": ""KEYCODE_MENU"",\n    ""KEY_OK"": ""KEYCODE_ENTER"",\n    ""KEY_PLAYPAUSE"": ""KEYCODE_MEDIA_PLAY_PAUSE"",\n    ""KEY_REWIND"": ""KEYCODE_MEDIA_REWIND"",\n    ""KEY_RIGHT"": ""KEYCODE_DPAD_RIGHT"",\n    ""KEY_UP"": ""KEYCODE_DPAD_UP"",\n}\n\n\ndef _resize(img, coordinate_system):\n    import cv2\n    import numpy\n\n    w, h = img.shape[1], img.shape[0]\n\n    if coordinate_system == CoordinateSystem.ADB_NATIVE:\n        pass\n    elif coordinate_system == CoordinateSystem.ADB_720P:\n        # Resize to 720p preserving orientation\n        if w > h:\n            img = cv2.resize(img, (1280, 720))\n        else:\n            img = cv2.resize(img, (720, 1280))\n    elif coordinate_system == CoordinateSystem.HDMI_720P:\n        if w > h:\n            # Landscape: The device\'s screen fills the HDMI frame.\n            # (this assumes that the device\'s aspect ratio is 16:9).\n            img = cv2.resize(img, (1280, 720))\n        else:\n            # Portrait image in a landscape frame, with black letterboxing\n            # on either side.\n            ratio = float(h) / 720\n            w_new = int(w // ratio)\n            img = cv2.resize(img, (w_new, 720))\n            left = (1280 - w_new) // 2\n            img = cv2.copyMakeBorder(img, 0, 0, left, 1280 - w_new - left,\n                                     cv2.BORDER_CONSTANT, (0, 0, 0))\n    elif coordinate_system == CoordinateSystem.CAMERA_720P:\n        # Resize to 720p landscape for compatibility with screenshots from\n        # `stbt.get_frame` with the Stb-tester CAMERA.\n        if w > h:\n            img = cv2.resize(img, (1280, 720))\n        else:\n            img = numpy.rot90(cv2.resize(img, (720, 1280)))\n    else:\n        raise NotImplementedError(\n            ""AdbDevice.get_frame not implemented for %s. ""\n            ""Use a separate AdbDevice instance with ""\n            ""coordinate_system=CoordinateSystem.ADB_NATIVE""\n            % coordinate_system)\n\n    return img\n\n\ndef _centre_point(r):\n    try:\n        if all(hasattr(r, name) for name in (""x"", ""y"", ""right"", ""bottom"")):\n            return (int((r.x + r.right) // 2), int((r.y + r.bottom) // 2))\n        elif isinstance(r, tuple) and len(r) == 2:\n            return (int(r[0]), int(r[1]))\n    except (TypeError, ValueError):\n        pass\n    raise TypeError(""Expected stbt.Region or (x,y) tuple but got %r"" % (r,))\n\n\n_Dimensions = namedtuple(""Dimensions"", ""width height"")\n\n\ndef _to_native_coordinates(x, y, coordinate_system, device):\n    if coordinate_system == CoordinateSystem.ADB_720P:\n        # x & y orientation matches device\'s orientation\n        if device.width > device.height:\n            return int(x * device.width / 1280), int(y * device.height / 720)\n        else:\n            return int(x * device.width / 720), int(y * device.height / 1280)\n    elif coordinate_system == CoordinateSystem.HDMI_720P:\n        if device.width > device.height:\n            # Landscape: Assume the device\'s native resolution is the same\n            # aspect ratio as the HDMI output (i.e. no letterboxing).\n            return int(x * device.width / 1280), int(y * device.height / 720)\n        else:\n            # Portrait image within a landscape screenshot, with black\n            # letterboxing on either side. If we assume the device is 16:9\n            # aspect ratio and fills the frame vertically, then the device\n            # fills pixels 438 to 842 horizontally (404px wide).\n            #\n            # /-----------------\\\n            # |######     ######|  ^\n            # |######     ######| 720\n            # |######     ######|\n            # |######     ######|  v\n            # \\-----------------/\n            #        <404>\n            #\n            if not 438 <= x < 842:\n                raise ValueError(\n                    ""Coordinates %d,%d are outside of the image area that ""\n                    ""corresponds to the device under test"" % (x, y))\n            x = (x - 438) * 720 / 404\n            return int(x * device.width / 720), int(y * device.height / 720)\n    elif coordinate_system == CoordinateSystem.CAMERA_720P:\n        # x & y coordinates are always from a 720p landscape screenshot.\n        if device.width > device.height:\n            # Landscape: Device orientation matches x & y.\n            return int(x * device.width / 1280), int(y * device.height / 720)\n        else:\n            # Portrait: The image is rotated 90\xc2\xb0 anti-clockwise. The device\'s\n            # origin (top-left) corresponds to the bottom-left corner of the\n            # screenshot.\n            #\n            # /--------------------\\    /-----\\\n            # |                    |    |     |\n            # |                    |    |     |\n            # |                    | => |%    |\n            # |                    |    |     |\n            # |  %                 |    |     |\n            # \\--------------------/    ~     ~\n            #\n            x, y = 720 - y, x\n            return int(x * device.width / 720), int(y * device.height / 1280)\n    else:\n        raise NotImplementedError(\n            ""AdbDevice: Mapping to native coordinates not implemented for %s""\n            % coordinate_system)\n\n\ndef _parse_display_dimensions(dumpsys_output):\n    in_display = False\n    for line in dumpsys_output.split(""\\n""):\n        if ""Display:"" in line:\n            in_display = True\n        if not in_display:\n            continue\n        m = re.search(r""cur=(\\d+)x(\\d+)"", line)\n        if m:\n            return _Dimensions(width=int(m.group(1)), height=int(m.group(2)))\n    raise RuntimeError(""AdbDevice: Didn\'t find display size in dumpsys output"")\n'"
stbt/keyboard.py,0,"b'# coding: utf-8\n""""""Copyright 2019 Stb-tester.com Ltd.""""""\n\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport time\nfrom collections import namedtuple\nfrom logging import getLogger\n\nimport networkx as nx\nimport numpy\nimport stbt\nfrom _stbt.utils import text_type\n\n\nlog = getLogger(""stbt.keyboard"")\n\n\nclass Keyboard(object):\n    """"""Helper for navigating an on-screen keyboard using the remote control.\n\n    You customize for the appearance & behaviour of the keyboard you\'re testing\n    by specifying two things:\n\n    * A `Page Object`_ that can tell you which key is currently selected on the\n      screen. See the ``page`` parameter to ``enter_text`` and ``navigate_to``,\n      below.\n\n    * A `Directed Graph`_ that specifies the navigation between every key on\n      the keyboard (for example on a qwerty keyboard: when Q is selected,\n      pressing KEY_RIGHT on the remote control goes to W, and so on). See the\n      ``graph`` parameter below.\n\n    The constructor takes the following parameters:\n\n    :type graph: str or networkx.DiGraph\n    :param graph: A specification of the complete navigation graph (state\n        machine) between adjacent keys, as a multiline string where each line\n        is in the format ``<start_node> <end_node> <action>``. For example, the\n        specification for a qwerty keyboard might look like this::\n\n            \'\'\'\n            Q W KEY_RIGHT\n            Q A KEY_DOWN\n            W Q KEY_LEFT\n            <etc>\n            \'\'\'\n\n        For nodes that enter a character, use that character as the node name.\n        For the space-bar use SPACE. For other nodes that don\'t enter a\n        character when pressed, use a descriptive name such as CLEAR or ENTER\n        (these nodes won\'t be used by ``enter_text`` but you can use them as a\n        target of ``navigate_to``).\n\n        On some keyboards, buttons like the space-bar are wider than other\n        buttons and the navigation away from the button depends on the previous\n        state. Our ``graph`` can\'t model this state, so specify all the\n        possible transitions from the button. For example, on a qwerty\n        keyboard::\n\n            SPACE C KEY_UP\n            SPACE V KEY_UP\n            SPACE B KEY_UP\n            SPACE N KEY_UP\n            SPACE M KEY_UP\n\n        For advanced users: instead of a string, ``graph`` can be a\n        `networkx.DiGraph` where each edge has an attribute called ``key`` with\n        a value like ``""KEY_RIGHT""``. If your keyboard\'s buttons are positioned\n        in a regular grid, you can use `stbt.grid_to_navigation_graph` to\n        generate this graph (or part of the graph, and then you can add any\n        irregular connections explicitly with `networkx.DiGraph.add_edge`).\n        See also `Keyboard.parse_edgelist`.\n\n    :type mask: str or `numpy.ndarray`\n    :param str mask:\n        A mask to use when calling `stbt.press_and_wait` to determine when the\n        current selection has finished moving. If the search page has a\n        blinking cursor you need to mask out the region where the cursor can\n        appear, as well as any other regions with dynamic content (such as a\n        picture-in-picture with live TV). See `stbt.press_and_wait` for more\n        details about the mask.\n\n    :type navigate_timeout: int or float\n    :param navigate_timeout: Timeout (in seconds) for ``navigate_to``. In\n        practice ``navigate_to`` should only time out if you have a bug in your\n        ``graph`` state machine specification.\n\n    .. _Page Object: https://stb-tester.com/manual/object-repository#what-is-a-page-object\n    .. _Directed Graph: https://en.wikipedia.org/wiki/Directed_graph\n    """"""\n\n    class Selection(namedtuple(""Selection"", ""text region"")):\n        """"""Type that your Page Object\'s ``selection`` property can return.\n\n        Has two attributes:\n\n        * ``text`` (*str*) \xe2\x80\x94 The selected letter or button.\n        * ``region`` (`stbt.Region`) \xe2\x80\x94 The position on screen of the selection /\n          highlight.\n\n        Is falsey if ``text`` and ``region`` are both ``None``.\n        """"""\n\n        def __bool__(self):\n            return self.text is not None or self.region is not None\n\n    def __init__(self, graph, mask=None, navigate_timeout=20):\n        if isinstance(graph, nx.DiGraph):\n            self.G = graph\n        else:\n            self.G = Keyboard.parse_edgelist(graph)\n        try:\n            nx.relabel_nodes(self.G, {""SPACE"": "" ""}, copy=False)\n        except KeyError:  # Node SPACE is not in the graph\n            pass\n        _add_weights(self.G)\n\n        self.mask = None\n        if isinstance(mask, numpy.ndarray):\n            self.mask = mask\n        elif mask:\n            self.mask = stbt.load_image(mask)\n\n        self.navigate_timeout = navigate_timeout\n\n    # pylint:disable=fixme\n    # TODO: case sensitive keyboards\n    #   Caps lock can be supported with a graph like this:\n    #       A CAPSLOCK_OFF KEY_LEFT\n    #       CAPSLOCK_OFF CAPSLOCK_ON KEY_OK\n    #       CAPSLOCK_ON a KEY_RIGHT\n    #       a q KEY_UP\n    #       <etc>\n    #   (Other mode changes like ABC -> 123!@# can be supported in the same\n    #   way.)\n    #\n    #   I don\'t know how best to support SHIFT (temporary mode change):\n    #   - In shifted state KEY_OK will go from ""A"" to ""a"". We\'d want to use\n    #     press_and_wait before we check the new state. But...\n    #   - In non-shifted state KEY_OK just enters the letter; the screen doesn\'t\n    #     change otherwise. Currently we don\'t use press_and_wait here because\n    #     typically the text-box where the text appears is masked out (because\n    #     some UIs have a blinking cursor there) and there is no change anywhere\n    #     else on the screen.\n    #\n    # TODO: Check that KEY_OK adds to the search text? With a property on the\n    #   page object? OCR might be too unreliable for incomplete words. We don\'t\n    #   use press_and_wait because the text-box might be masked out (some UIs\n    #   have a blinking cursor there).\n\n    def enter_text(self, text, page, verify_every_keypress=False):\n        """"""Enter the specified text using the on-screen keyboard.\n\n        :param str text: The text to enter. If your keyboard only supports a\n            single case then you need to convert the text to uppercase or\n            lowercase, as appropriate, before passing it to this method.\n\n        :param stbt.FrameObject page: An instance of a `stbt.FrameObject`\n            sub-class that describes the appearance of the on-screen keyboard.\n            It must implement the following:\n\n            * ``selection`` (*str* or `Keyboard.Selection`) \xe2\x80\x94 property that\n              returns the name of the currently selected character (for example\n              ""A"" or ""\xc2\xa0"") or button (for example ""CLEAR"" or ""SEARCH""). This\n              property can return a string, or an object with a ``text``\n              attribute that is a string.\n\n              For grid-shaped keyboards, you can implement this property using\n              `stbt.Grid` to map from the region of the selection (highlight)\n              to the corresponding letter; see the example below.\n\n            The ``page`` instance that you provide must represent the current\n            state of the device-under-test.\n\n        :param bool verify_every_keypress:\n            If True, we will read the selected key after every keypress and\n            assert that it matches the model (``graph``). If False (the\n            default) we will only verify the selected key corresponding to each\n            of the characters in ``text``. For example: to get from Q to D on a\n            qwerty keyboard you need to press KEY_DOWN, KEY_RIGHT, KEY_RIGHT.\n            The default behaviour will only verify that the selected key is D\n            after pressing KEY_RIGHT the last time. This is faster, and closer\n            to the way a human uses the on-screen keyboard.\n\n            Set this to True to help debug your model if ``enter_text`` is\n            behaving incorrectly.\n\n        Typically your FrameObject will provide its own ``enter_text`` method,\n        so your test scripts won\'t call this ``Keyboard`` class directly. For\n        example::\n\n            class YouTubeSearch(stbt.FrameObject):\n                _kb = stbt.Keyboard(\'\'\'\n                    A B KEY_RIGHT\n                    ...etc...\n                    \'\'\')\n                letters = stbt.Grid(region=...,\n                                    data=[""ABCDEFG"",\n                                          ""HIJKLMN"",\n                                          ""OPQRSTU"",\n                                          ""VWXYZ-\'""])\n                space_row = stbt.Grid(region=...,\n                                      data=[["" "", ""CLEAR"", ""SEARCH""]])\n\n                @property\n                def is_visible(self):\n                    ...  # implementation not shown\n\n                @property\n                def selection(self):\n                    m = stbt.match(""keyboard-selection.png"", frame=self._frame)\n                    if not m:\n                        return stbt.Keyboard.Selection(None, None)\n                    try:\n                        text = self.letters.get(region=m.region).data\n                    except IndexError:\n                        text = self.space_row.get(region=m.region).data\n                    return stbt.Keyboard.Selection(text, m.region)\n\n                def enter_text(self, text):\n                    page = self\n                    page = self._kb.enter_text(text.upper(), page)\n                    self._kb.navigate_to(""SEARCH"", page)\n                    stbt.press(""KEY_OK"")\n\n                def navigate_to(self, target):\n                    return self._kb.navigate_to(target, page=self)\n        """"""\n\n        for letter in text:\n            if letter not in self.G:\n                raise ValueError(""\'%s\' isn\'t in the keyboard"" % (letter,))\n\n        prev = None\n        for letter in text:\n            page = self.navigate_to(letter, page, verify_every_keypress)\n            if letter == prev:\n                stbt.press(""KEY_OK"", interpress_delay_secs=1)\n            else:\n                stbt.press(""KEY_OK"")\n            prev = letter\n        return page\n\n    def navigate_to(self, target, page, verify_every_keypress=False):\n        """"""Move the selection to the specified character.\n\n        Note that this won\'t press KEY_OK on the target, it only moves the\n        selection there.\n\n        :param str target: The key or button to navigate to, for example ""A"",\n            ""\xc2\xa0"", or ""CLEAR"".\n        :param stbt.FrameObject page: See ``enter_text``.\n        :param bool verify_every_keypress: See ``enter_text``.\n\n        :returns: A new FrameObject instance of the same type as ``page``,\n            reflecting the device-under-test\'s new state after the navigation\n            completed.\n        """"""\n\n        if target not in self.G:\n            raise ValueError(""\'%s\' isn\'t in the keyboard"" % (target,))\n\n        assert page, ""%s page isn\'t visible"" % type(page).__name__\n        deadline = time.time() + self.navigate_timeout\n        current = _selection_to_text(page.selection)\n        while current != target:\n            assert time.time() < deadline, (\n                ""Keyboard.navigate_to: Didn\'t reach %r after %s seconds""\n                % (target, self.navigate_timeout))\n            keys = list(_keys_to_press(self.G, current, target))\n            log.info(""Keyboard: navigating from %s to %s by pressing %r"",\n                     current, target, keys)\n            if not verify_every_keypress:\n                for k, _ in keys[:-1]:\n                    stbt.press(k)\n                keys = keys[-1:]  # only verify the last one\n            for key, possible_targets in keys:\n                assert stbt.press_and_wait(key, mask=self.mask, stable_secs=0.5)\n                page = page.refresh()\n                assert page, ""%s page isn\'t visible"" % type(page).__name__\n                current = _selection_to_text(page.selection)\n                assert current in possible_targets, \\\n                    ""Expected to see %s after pressing %s, but saw %r"" % (\n                        _join_with_commas(\n                            [repr(x) for x in sorted(possible_targets)],\n                            last_one="" or ""),\n                        key,\n                        current)\n        return page\n\n    @staticmethod\n    def parse_edgelist(graph):\n        """"""Create a `networkx.DiGraph` from a string specification of the graph.\n\n        This is useful when you want to specify part of the keyboard\'s\n        navigation graph programmatically using `stbt.grid_to_navigation_graph`\n        (for the parts of the keyboard that are laid out in a grid and behave\n        regularly) but you still need to specify some extra edges that behave\n        differently. For example::\n\n            letters = stbt.Grid(...)\n            space_bar = stbt.Keyboard.parse_edgelist(\'\'\'\n                C SPACE KEY_DOWN\n                V SPACE KEY_DOWN\n                B SPACE KEY_DOWN\n                SPACE C KEY_UP\n                SPACE V KEY_UP\n                SPACE B KEY_UP\n            \'\'\')\n            keyboard = stbt.Keyboard(networkx.compose_all([\n                stbt.grid_to_navigation_graph(letters),\n                space_bar]))\n\n        :param str graph: See the `Keyboard` constructor.\n        :returns: A new `networkx.DiGraph` instance.\n        """"""\n        return nx.parse_edgelist(graph.split(""\\n""),\n                                 create_using=nx.DiGraph(),\n                                 data=[(""key"", text_type)])\n\n\ndef _selection_to_text(selection):\n    if hasattr(selection, ""text""):\n        return selection.text\n    else:\n        return selection\n\n\ndef _keys_to_press(G, source, target):\n    path = nx.shortest_path(G, source=source, target=target, weight=""weight"")\n    # nx.shortest_path(G, ""A"", ""V"") -> [""A"", ""H"", ""O"", ""V""]\n    # nx.shortest_path(G, ""A"", ""A"") -> [""A""]\n    if len(path) == 1:\n        return\n    for s, t in zip(path[:-1], path[1:]):\n        key = G[s][t][""key""]\n        possible_targets = set(tt for _, tt, kk in G.edges(s, data=""key"")\n                               if kk == key)\n        yield key, possible_targets\n\n        # If there are multiple edges from this node with the same key, we\n        # don\'t know which one we will *actually* end up on. So don\'t do\n        # any further blind keypresses; let the caller re-calculate and call\n        # us again.\n        if len(possible_targets) > 1:\n            break\n\n\ndef _add_weights(G):\n    for node in G:\n        edges = list(G.edges(node, data=""key""))\n        keys = set(k for _, _, k in edges)\n        for key in keys:\n            targets = [t for _, t, k in edges if k == key]\n            if len(targets) > 1:\n                # Nondeterministic: Multiple targets from the same node with\n                # the same action (key). No doubt the keyboard-under-test *is*\n                # deterministic, but our model of it (in the test-pack) isn\'t\n                # because we don\'t remember the previous nodes before we\n                # landed on the current node. Give these edges a large weight\n                # so that the shortest path algorithm doesn\'t think it can\n                # take a shortcut through here.\n                for target in targets:\n                    G[node][target][""weight""] = 100\n\n\ndef _join_with_commas(items, last_one="", ""):\n    """"""\n    >>> _join_with_commas([""A"", ""B"", ""C""], last_one="" or "")\n    \'A, B or C\'\n    >>> _join_with_commas([""A"", ""C""], last_one="" or "")\n    \'A or C\'\n    >>> _join_with_commas([""A""], last_one="" or "")\n    \'A\'\n    >>> _join_with_commas([], last_one="" or "")\n    \'\'\n    """"""\n    if len(items) > 1:\n        return last_one.join([\n            "", "".join(items[:-1]),\n            items[-1]])\n    elif len(items) == 1:\n        return items[0]\n    else:\n        return """"\n'"
stbt/pylint_plugin.py,0,"b'""""""pylint plugin to do static analysis on stbt scripts\n\nUsed by ""stbt lint"".\n\nDocumentation on Abstract Syntax Tree traversal with python/pylint:\n\n* http://docs.pylint.org/extend.html#writing-your-own-checker\n* http://hg.logilab.org/review/pylint/file/default/examples/custom.py\n* http://docs.python.org/3.6/library/ast.html\n\n""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nfrom future.utils import string_types\n\nimport os\nimport re\nimport subprocess\n\nfrom astroid import (\n    Assert, BinOp, Call, ClassDef, Const, Expr, FunctionDef, Keyword, MANAGER,\n    Name, Raise, Uninferable)\nfrom pylint.checkers import BaseChecker\nfrom pylint.interfaces import IAstroidChecker\n\n\nclass StbtChecker(BaseChecker):\n    __implements__ = IAstroidChecker\n    name = \'stb-tester\'\n    msgs = {\n        # Range 70xx reserved for custom checkers: www.logilab.org/ticket/68057\n        # When you add a new checker update the docstring in ../stbt_lint.py\n        \'E7001\': (\'Image ""%s"" not found on disk\',\n                  \'stbt-missing-image\',\n                  \'The image path given to ""stbt.match"" \'\n                  \'(and similar functions) does not exist on disk.\'),\n        \'E7002\': (\'""%s"" return value not used (missing ""assert""?)\',\n                  \'stbt-unused-return-value\',\n                  ""This function does not raise an exception on failure but ""\n                  ""you aren\'t using its return value. Perhaps you\'ve forgotten ""\n                  \'to use ""assert"".\'),\n        \'E7003\': (\'""wait_until"" argument ""%s"" isn\\\'t callable\',\n                  \'stbt-wait-until-callable\',\n                  \'The argument given to ""wait_until"" must be a callable \'\n                  \'(such as a function or a lambda expression).\'),\n        \'E7004\': (\'""%s"" missing ""frame"" argument\',\n                  \'stbt-frame-object-missing-frame\',\n                  \'FrameObject properties must always provide ""self._frame"" as \'\n                  \'the ""frame"" parameter to functions such as ""stbt.match"".\'),\n        \'E7005\': (\'Image ""%s"" not committed to git\',\n                  \'stbt-uncommitted-image\',\n                  \'The image path given to ""stbt.match"" \'\n                  \'(and similar functions) exists on disk, \'\n                  ""but isn\'t committed to git.""),\n        \'E7006\': (\'FrameObject properties must use ""self._frame"", not \'\n                  \'""get_frame()""\',\n                  \'stbt-frame-object-get-frame\',\n                  \'FrameObject properties must use ""self._frame"", not \'\n                  \'""stbt.get_frame()"".\'),\n        \'E7007\': (\'FrameObject properties must not use ""%s""\',\n                  \'stbt-frame-object-property-press\',\n                  \'FrameObject properties must not have side-effects that \'\n                  \'change the state of the device-under-test by calling \'\n                  \'""stbt.press()"" or ""stbt.press_and_wait()"".\'),\n        \'E7008\': (\'""assert True"" has no effect\',\n                  \'stbt-assert-true\',\n                  \'""assert True"" has no effect; consider replacing it with a \'\n                  \'comment or a call to ""logging.info()"".\'),\n    }\n\n    def visit_const(self, node):\n        if (isinstance(node.value, string_types) and\n                re.search(r\'.+\\.png$\', node.value) and\n                ""\\n"" not in node.value and\n                not _is_uri(node.value) and\n                not _is_calculated_value(node) and\n                not _is_pattern_value(node) and\n                not _is_whitelisted_name(node.value) and\n                not _in_whitelisted_functions(node)):\n            path = _find_file(node.value, node)\n            if os.path.isfile(path):\n                if _is_file_uncommitted(path):\n                    self.add_message(\'E7005\', node=node,\n                                     args=os.path.relpath(path))\n            else:\n                self.add_message(\'E7001\', node=node, args=os.path.relpath(path))\n\n    def visit_call(self, node):\n        if re.search(r""\\b(is_screen_black|match|match_text|ocr|press_and_wait|""\n                     r""wait_until)$"",\n                     node.func.as_string()):\n            if isinstance(node.parent, Expr):\n                for inferred in _infer(node.func):\n                    if inferred.root().name in (\n                            \'_stbt.black\', \'_stbt.match\', \'_stbt.ocr\',\n                            \'_stbt.transition\', \'_stbt.wait\'):\n                        self.add_message(\n                            \'E7002\', node=node, args=node.func.as_string())\n\n        if re.search(r""\\bwait_until$"", node.func.as_string()):\n            if node.args:\n                arg = node.args[0]\n                if not _is_callable(arg):\n                    self.add_message(\'E7003\', node=node, args=arg.as_string())\n\n        if _in_frameobject(node) and _in_property(node):\n            if re.search(r""\\bget_frame$"", node.func.as_string()):\n                self.add_message(\'E7006\', node=node)\n\n            if re.search(\n                    r""\\b(press|press_and_wait|pressing|press_until_match)$"",\n                    node.func.as_string()):\n                self.add_message(\'E7007\', node=node, args=node.func.as_string())\n\n            for funcdef in _infer(node.func):\n                argnames = _get_argnames(funcdef)\n                if ""frame"" in argnames:\n                    index = argnames.index(""frame"")\n                    args = [a for a in node.args if not isinstance(a, Keyword)]\n                    if hasattr(node, ""keywords""):  # astroid >= 1.4\n                        keywords = node.keywords or []\n                        kwargs = [k.arg for k in keywords]\n                    else:  # astroid < 1.4\n                        kwargs = [a.arg for a in node.args\n                                  if isinstance(a, Keyword)]\n                    if len(args) <= index and ""frame"" not in kwargs:\n                        self.add_message(\'E7004\', node=node,\n                                         args=node.as_string())\n\n    def visit_assert(self, assertion):\n        if isinstance(assertion.test, Const) and assertion.test.value is True:\n            if assertion.fail:\n                self.add_message(""E7008"", node=assertion)\n            else:\n                self.add_message(""E7008"", node=assertion)\n\n\ndef _transform_assert_false_into_raise(assertion):\n    if isinstance(assertion.test, Const) and assertion.test.value is False:\n        out = Raise(lineno=assertion.lineno,\n                    col_offset=assertion.col_offset,\n                    parent=assertion.parent)\n        exc = Call(parent=out)\n        if assertion.fail:\n            args = [assertion.fail]\n            args[0].parent = exc\n        else:\n            args = []\n        exc.postinit(Name(""AssertionError"", parent=exc), args)\n        out.postinit(exc, None)\n        return out\n\n\nMANAGER.register_transform(Assert, _transform_assert_false_into_raise)\n\n\ndef _is_callable(node):\n    failed_to_infer = True\n    for inferred in _infer(node):\n        failed_to_infer = False\n        if inferred.callable():\n            return True\n    if failed_to_infer:\n        if (isinstance(node, Call) and\n                _is_function_named(node.func, ""functools.partial"")):\n            return True\n    return False\n\n\ndef _in_frameobject(node):\n    while node is not None:\n        if isinstance(node, ClassDef):\n            if ""_stbt.frameobject.FrameObject"" in [\n                    base.qname() for base in node.ancestors()]:\n                return True\n        node = node.parent\n    return False\n\n\ndef _in_property(node):\n    while node is not None:\n        if isinstance(node, FunctionDef):\n            if (""__builtin__.property"" in node.decoratornames() or\n                    ""builtins.property"" in node.decoratornames()):\n                return True\n        node = node.parent\n    return False\n\n\ndef _get_argnames(node):\n    if isinstance(node, FunctionDef):\n        return node.argnames()\n    if isinstance(node, ClassDef) and node.newstyle:\n        for method in node.methods():  # pylint:disable=redefined-outer-name\n            if method.name == ""__init__"":\n                return method.argnames()[1:]\n    return []\n\n\ndef _is_uri(filename):\n    return re.search(r""^[a-zA-Z][a-zA-Z0-9+.-]*:"", filename)\n\n\ndef _is_calculated_value(node):\n    return (\n        isinstance(node.parent, BinOp) or\n        (isinstance(node.parent, Call) and\n         node.parent.func.as_string().split(""."")[-1] in (""join"", ""replace"")))\n\n\ndef _is_pattern_value(node):\n    return re.search(r\'\\*\', node.value)\n\n\ndef _is_whitelisted_name(filename):\n    return filename == \'screenshot.png\'\n\n\ndef _in_whitelisted_functions(node):\n    return (\n        isinstance(node.parent, Call) and\n        any(_is_function_named(node.parent.func, x) for x in (\n            ""cv2.imwrite"",\n            ""imwrite"",  # handles ""from cv2 import imwrite"" with OpenCV 3.x\n            ""re.match"",\n            ""re.search"",\n            ""re.sub"",\n            ""stbt.save_frame"",\n            ""_stbt.imgutils.save_frame"",  # ""from stbt import save_frame""\n        )))\n\n\ndef _is_function_named(func, name):\n    if func.as_string() == name:\n        return True\n    for funcdef in _infer(func):\n        if (isinstance(funcdef, FunctionDef) and\n                ""."".join((funcdef.parent.name, funcdef.name)) == name):\n            return True\n    return False\n\n\ndef _find_file(filename, node):\n    """"""Resolves `filename` on stbt\'s image search path\n\n    See `stbt.load_image` for stbt\'s image lookup algorithm.\n    """"""\n    return os.path.join(\n        os.path.dirname(node.root().file),\n        filename)\n\n\ndef _is_file_uncommitted(filename):\n    if not _in_git_repo():\n        return False\n    try:\n        subprocess.check_output(\n            [""git"", ""ls-files"", ""--error-unmatch"", filename],\n            stderr=subprocess.STDOUT)\n        return False\n    except subprocess.CalledProcessError:\n        return True\n\n\n__in_git_repo = None\n\n\ndef _in_git_repo():\n    global __in_git_repo\n    if __in_git_repo is None:\n        try:\n            subprocess.check_output([""git"", ""rev-parse"", ""--show-toplevel""],\n                                    stderr=subprocess.STDOUT)\n            __in_git_repo = True\n        except (OSError, subprocess.CalledProcessError):\n            __in_git_repo = False\n    return __in_git_repo\n\n\ndef _infer(node):\n    try:\n        for inferred in node.infer():\n            # When `infer()` fails it returns this singleton:\n            if inferred is Uninferable:\n                continue\n            yield inferred\n    except Exception:  # pylint:disable=broad-except\n        pass\n\n\ndef register(linter):\n    linter.register_checker(StbtChecker(linter))\n'"
tests/__init__.py,0,b''
tests/run_performance_test.py,0,"b'#!/usr/bin/python\n\nfrom __future__ import division\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport glob\nimport os\nimport subprocess\nimport sys\nimport timeit\n\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),\n                                                "".."")))\nimport stbt\nsys.path.pop(0)\n\n\ndef main():\n    os.chdir(os.path.dirname(__file__))\n\n    # Disable cpu frequency scaling\n    subprocess.check_call(r""""""\n        for cpu in /sys/devices/system/cpu/cpufreq/policy*; do\n            echo $cpu\n            cat $cpu/scaling_available_governors\n            echo performance | sudo tee $cpu/scaling_governor\n            freq=$(cat $cpu/cpuinfo_max_freq)\n            echo $freq | sudo tee $cpu/scaling_min_freq\n        done >&2\n        """""", shell=True)\n\n    print(""screenshot,reference,min,avg,max"")\n\n    for fname in glob.glob(""images/performance/*-frame.png""):\n        tname = fname.replace(""-frame.png"", ""-reference.png"")\n        f = stbt.load_image(fname)\n        t = stbt.load_image(tname)\n        # pylint:disable=cell-var-from-loop\n        times = timeit.repeat(lambda: stbt.match(t, f), number=1, repeat=100)\n        print(""%s,%s,%f,%f,%f"" % (os.path.basename(fname),\n                                  os.path.basename(tname),\n                                  min(times),\n                                  max(times),\n                                  sum(times) / len(times)))\n\n\nif __name__ == ""__main__"":\n    main()\n'"
tests/test_android.py,0,"b'from __future__ import division\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport os\nimport re\nimport time\nfrom textwrap import dedent\nfrom unittest import SkipTest\n\nimport cv2\nimport pytest\nfrom numpy import isclose\n\nfrom stbt import match, Region, wait_until\nfrom stbt.android import (_centre_point, _Dimensions,\n                          _parse_display_dimensions, _resize,\n                          _to_native_coordinates, AdbDevice, AdbError,\n                          CoordinateSystem)\n\n\n@pytest.mark.parametrize(""r"", [\n    Region(10, 10, width=30, height=5),\n    (25, 12),\n    (""25"", ""12""),\n])\ndef test_centre_point(r):\n    assert _centre_point(r) == (25, 12)\n\n\n@pytest.mark.parametrize(""r"", [\n    25,\n    (25,),\n    (25, 12, 15),\n    ""25"",\n])\ndef test_centre_point_raises(r):\n    with pytest.raises(TypeError):\n        _centre_point(r)\n\n\n@pytest.mark.parametrize(""orientation"", [\n    ""portrait"",\n    ""landscape"",\n])\n@pytest.mark.parametrize(""coordinate_system"", [\n    CoordinateSystem.ADB_NATIVE,\n    CoordinateSystem.ADB_720P,\n    CoordinateSystem.HDMI_720P,\n    CoordinateSystem.CAMERA_720P,\n])\ndef test_that_get_frame_resizes_to_match_coordinate_system(\n        orientation, coordinate_system):\n\n    source = cv2.imread(_find_file(\n        ""images/android/resize/source-1080p-%s.png"" % orientation))\n    out = _resize(source, coordinate_system)\n    expected_filename = \\\n        ""images/android/resize/expected-{system}-{orientation}.png"".format(\n            system=coordinate_system.name.lower().replace(""_"", ""-""),\n            orientation=orientation)\n    expected = cv2.imread(_find_file(expected_filename))\n    assert match(expected, out)\n\n\n@pytest.mark.parametrize(""orientation,device_resolution,expected_coordinates"", [\n    # These parameters describe the device under test.\n    (""portrait"", (720, 1280), (665, 105)),\n    (""portrait"", (750, 1334), (692, 109)),\n    (""portrait"", (1080, 1920), (997, 157)),\n    (""landscape"", (1280, 720), (1008, 48)),\n    (""landscape"", (1334, 750), (1051, 50)),\n    (""landscape"", (1920, 1080), (1513, 72)),\n])\n@pytest.mark.parametrize(""coordinate_system"", [\n    # How we capture video frames from the device.\n    CoordinateSystem.ADB_720P,\n    CoordinateSystem.HDMI_720P,\n    CoordinateSystem.CAMERA_720P,\n])\ndef test_to_native_coordinates(\n        orientation, device_resolution, expected_coordinates,\n        coordinate_system):\n\n    description = ""{source}-{orientation}"".format(\n        source=coordinate_system.name.lower().replace(""_"", ""-""),\n        orientation=orientation)\n    screenshot = cv2.imread(_find_file(\n        ""images/android/coordinates/%s-screenshot.png"" % description))\n    icon = ""images/android/coordinates/%s-reference.png"" % description\n\n    m = match(icon, screenshot)\n    screenshot_x, screenshot_y = _centre_point(m.region)\n    native_x, native_y = _to_native_coordinates(\n        screenshot_x, screenshot_y, coordinate_system,\n        _Dimensions(*device_resolution))\n    print((native_x, native_y))\n    assert isclose(native_x, expected_coordinates[0], atol=1)\n    assert isclose(native_y, expected_coordinates[1], atol=1)\n\n\ndef test_parse_display_dimensions():\n    moto_x2_portrait = dedent(""""""\\\n        [...]\n        WINDOW MANAGER DISPLAY CONTENTS (dumpsys window displays)\n          Display: mDisplayId=0\n            init=1080x1920 480dpi cur=1080x1920 app=1080x1776 rng=1080x1008-1794x1704\n            deferred=false layoutNeeded=false\n          [...]\n        """""")\n    assert _parse_display_dimensions(moto_x2_portrait) == \\\n        _Dimensions(width=1080, height=1920)\n\n    moto_x2_landscape = dedent(""""""\\\n        [...]\n        WINDOW MANAGER DISPLAY CONTENTS (dumpsys window displays)\n          Display: mDisplayId=0\n            init=1080x1920 480dpi cur=1920x1080 app=1794x1080 rng=1080x1008-1794x1704\n            deferred=false layoutNeeded=false\n          [...]\n        """""")\n    assert _parse_display_dimensions(moto_x2_landscape) == \\\n        _Dimensions(width=1920, height=1080)\n\n    samsung_galaxy_ace_2 = dedent(""""""\\\n        [...]\n        WINDOW MANAGER WINDOWS (dumpsys window windows)\n          Window #4 Window{43073770 RecentsPanel paused=false}:\n          [...]\n\n          Display: init=480x800 cur=480x800 app=480x800 rng=480x442-800x762\n          [...]\n        """""")\n    assert _parse_display_dimensions(samsung_galaxy_ace_2) == \\\n        _Dimensions(width=480, height=800)\n\n\n# This is a regression test.\ndef test_adbdevice_default_constructor():\n    adb = AdbDevice()\n    assert adb.coordinate_system == CoordinateSystem.ADB_NATIVE\n\n\ndef test_get_frame_press_tap_and_swipe(real_adb_device):  # pylint:disable=redefined-outer-name\n    adb = real_adb_device\n\n    def match_any(basename):\n        f = adb.get_frame()\n        return (match(""images/android/galaxy-ace-2/"" + basename, f) or\n                match(""images/android/moto-x2/"" + basename, f))\n\n    adb.press(""KEYCODE_HOME"")\n    m = wait_until(lambda: match_any(""app-icon.png""))\n    assert m\n    adb.tap(m.region)\n    assert wait_until(lambda: match_any(""app.png""))\n    adb.swipe((240, 0), (240, 600))\n    assert wait_until(lambda: match_any(""settings-icon.png""))\n\n\ndef test_adb_tcpip(real_adb_device):  # pylint:disable=redefined-outer-name\n\n    # Expects a phone connected via USB. Set it to TCP/IP mode, test it over\n    # TCP/IP, then use the TCP/IP connection to set it back to USB mode.\n\n    adb = real_adb_device\n\n    if ""7278681B045C937CEB770FD31542B16"" in adb.devices():\n        raise SkipTest(""adb tcpip doesn\'t work with our old Galaxy Ace 2."")\n\n    ip = _parse_ip_address(\n        adb.adb([""shell"", ""ip"", ""addr""], capture_output=True))\n    adb.adb([""tcpip"", ""5555""])\n    time.sleep(5)\n    try:\n        adb2 = AdbDevice(\n            adb_server=""localhost"",\n            adb_device=ip,\n            adb_binary=os.environ.get(""ADB_BINARY"", ""adb""),\n            tcpip=True,\n            coordinate_system=CoordinateSystem.ADB_NATIVE)\n        assert ip == _parse_ip_address(\n            adb2.adb([""shell"", ""ip"", ""addr""], capture_output=True))\n        assert ""%s:5555"" % ip in adb2.devices()\n    finally:\n        try:\n            adb2.adb([""usb""])\n            time.sleep(5)\n        except AdbError:\n            pass\n\n\n@pytest.fixture(scope=""function"")\ndef real_adb_device():\n    """"""Fixture for testing a real Android phone.\n\n    Expects our CI phone (an old Samsung Galaxy Ace 2) connected via USB. You\n    can specify your own phone via $ANDROID_SERIAL (it must match the output of\n    ``adb devices -l``) but you might have to update the tests that use this\n    fixture (for example you might need to provide reference screenshots that\n    match your phone).\n    """"""\n    _adb = AdbDevice(\n        adb_server=os.environ.get(""ADB_SERVER"", ""localhost""),\n        adb_device=os.environ.get(""ANDROID_SERIAL"", None),\n        adb_binary=os.environ.get(""ADB_BINARY"", ""adb""),\n        tcpip=os.environ.get(""ADB_TCPIP"", False),\n        coordinate_system=CoordinateSystem.ADB_NATIVE)\n    if not any(\n            serial in _adb.devices() for serial in [\n                ""7278681B045C937CEB770FD31542B16"",  # Our CI Samsung Galaxy Ace2\n                ""model:XT1092"",  # Moto X (2nd gen)\n                os.environ.get(""ANDROID_SERIAL"", None),\n            ] if serial is not None):\n        raise SkipTest(\n            ""CI Android device not connected. You can set ADB_SERVER, ""\n            ""ANDROID_SERIAL, and ADB_BINARY environment variables."")\n    return _adb\n\n\ndef _find_file(path, root=os.path.dirname(os.path.abspath(__file__))):\n    return os.path.join(root, path)\n\n\ndef _parse_ip_address(output):\n    # pylint:disable=line-too-long,trailing-whitespace\n    r""""""\n    >>> from pprint import pprint\n    >>> from textwrap import dedent\n    >>> pprint(_parse_ip_address(dedent(\'\'\'\\\n    ...     1: lo: <LOOPBACK,UP,LOWER_UP> mtu 16436 qdisc noqueue state UNKNOWN \n    ...         link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    ...         inet 127.0.0.1/8 scope host lo\n    ...         inet6 ::1/128 scope host \n    ...            valid_lft forever preferred_lft forever\n    ...     2: dummy0: <BROADCAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN \n    ...         link/ether 46:ed:31:1b:fa:33 brd ff:ff:ff:ff:ff:ff\n    ...         inet6 fe80::44ed:31ff:fe1b:fa33/64 scope link \n    ...            valid_lft forever preferred_lft forever\n    ...     3: rmnet0: <> mtu 1410 qdisc noop state DOWN qlen 1000\n    ...         link/[530] \n    ...     [...]\n    ...     11: rmnet_usb0: <BROADCAST,MULTICAST> mtu 2000 qdisc noop state DOWN qlen 1000\n    ...         link/ether 62:eb:12:3b:97:94 brd ff:ff:ff:ff:ff:ff\n    ...     [...]\n    ...     24: wlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP qlen 1000\n    ...         link/ether 5c:51:88:34:aa:e2 brd ff:ff:ff:ff:ff:ff\n    ...         inet 192.168.2.163/24 brd 192.168.2.255 scope global wlan0\n    ...         inet6 fe80::5e51:88ff:fe34:aae2/64 scope link \n    ...            valid_lft forever preferred_lft forever\n    ...     25: p2p0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc mq state DOWN qlen 1000\n    ...         link/ether 5c:51:88:34:aa:e3 brd ff:ff:ff:ff:ff:ff\n    ...     \'\'\')))\n    \'192.168.2.163\'\n    """"""\n    m = re.search(r""192\\.168\\.[0-9]{1,3}\\.[0-9]{1,3}"", output)\n    assert m, ""No local IP address found in: %s"" % output\n    return m.group()\n'"
tests/test_config.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport enum\nimport os\nfrom contextlib import contextmanager\nfrom textwrap import dedent\n\nimport pytest\n\nfrom _stbt.config import (_config_init, _sponge, ConfigurationError,\n                          get_config, set_config)\nfrom _stbt.utils import (named_temporary_directory, scoped_curdir, text_type,\n                         to_native_str)\n\n\ndef test_sponge_that_new_data_end_up_in_file():\n    with scoped_curdir():\n        with _sponge(\'hello\') as f:\n            f.write(\'hello\')\n        assert open(\'hello\').read() == \'hello\'\n\n\ndef test_sponge_that_on_exception_file_isnt_modified():\n    with scoped_curdir():\n        open(\'foo\', \'w\').write(\'bar\')\n        try:\n            with _sponge(\'foo\') as f:\n                f.write(\'hello\')\n                raise RuntimeError()\n        except RuntimeError:\n            pass\n        assert open(\'foo\').read() == \'bar\'\n\ntest_config = dedent(""""""\\\n    [global]\n    # A comment\n    test=hello\n    another_test = goodbye"""""")\n\n\n@contextmanager\ndef set_config_test():\n    with scoped_curdir() as d:\n        test_cfg = d + \'/test.cfg\'\n        os.environ[\'STBT_CONFIG_FILE\'] = test_cfg\n        with open(test_cfg, \'w\') as f:\n            f.write(test_config)\n        yield\n\n\ndef test_that_set_config_modifies_config_value():\n    with set_config_test():\n        set_config(\'global\', \'test\', \'goodbye\')\n        assert get_config(\'global\', \'test\') == \'goodbye\'\n        _config_init(force=True)\n        assert get_config(\'global\', \'test\') == \'goodbye\'\n\n\ndef test_that_set_config_creates_new_sections_if_required():\n    with set_config_test():\n        set_config(\'non_existent_section\', \'test\', \'goodbye\')\n        assert get_config(\'non_existent_section\', \'test\') == \'goodbye\'\n        _config_init(force=True)\n        assert get_config(\'non_existent_section\', \'test\') == \'goodbye\'\n\n\ndef test_that_set_config_preserves_file_comments_and_formatting():\n    # pylint:disable=fixme,unreachable\n    # FIXME: Preserve comments and formatting.  This is fairly tricky as\n    # comments and whitespace are not currently stored in Python\'s internal\n    # ConfigParser representation and multiline values makes just using regex\n    # tricky.\n    from unittest import SkipTest\n    raise SkipTest(""set_config doesn\'t currently preserve formatting"")\n    with set_config_test():\n        set_config(\'global\', \'test\', \'goodbye\')\n        assert open(\'test.cfg\', \'r\').read() == test_config.replace(\n            \'hello\', \'goodbye\')\n\n\ndef test_that_set_config_creates_directories_if_required():\n    with scoped_curdir() as d:\n        os.environ[\'XDG_CONFIG_HOME\'] = d + \'/.config\'\n        if \'STBT_CONFIG_FILE\' in os.environ:\n            del os.environ[\'STBT_CONFIG_FILE\']\n        set_config(\'global\', \'test\', \'hello2\')\n        assert os.path.isfile(d + \'/.config/stbt/stbt.conf\')\n        _config_init(force=True)\n        assert get_config(\'global\', \'test\') == \'hello2\'\n\n\ndef test_that_set_config_writes_to_the_first_stbt_config_file():\n    with scoped_curdir() as d:\n        filled_cfg = d + \'/test.cfg\'\n        empty_cfg = d + \'/empty.cfg\'\n        os.environ[\'STBT_CONFIG_FILE\'] = \'%s:%s\' % (filled_cfg, empty_cfg)\n        open(filled_cfg, \'w\')\n        open(empty_cfg, \'w\')\n        set_config(\'global\', \'test\', \'goodbye\')\n        assert open(filled_cfg).read().startswith(\'[global]\')\n        assert open(empty_cfg).read() == \'\'\n\n\nclass MyEnum(enum.Enum):\n    NAME_1 = ""value-1""\n    NAME_2 = ""value-2""\n\n\nclass MyIntEnum(enum.IntEnum):\n    NAME_5 = 5\n    NAME_6 = 6\n\n\ndef test_to_enum():\n    with temporary_config(""""""\\\n            [global]\n            bystrlc = name_1\n            bystruc = NAME_1\n            byvallc = value-1\n            byvaluc = VALUE-1\n            badstr = notakey\n            byint = 5\n            byintname = NAME_5\n            badint = 7\n            """"""):\n\n        assert get_config(""global"", ""bystrlc"", type_=MyEnum) == MyEnum.NAME_1\n        assert get_config(""global"", ""bystruc"", type_=MyEnum) == MyEnum.NAME_1\n        assert get_config(""global"", ""byvallc"", type_=MyEnum) == MyEnum.NAME_1\n\n        with pytest.raises(ConfigurationError) as excinfo:\n            get_config(""global"", ""byvaluc"", type_=MyEnum)\n        assert ""Valid values are NAME_1, NAME_2"" in str(excinfo.value)\n\n        with pytest.raises(ConfigurationError):\n            get_config(""global"", ""badstr"", type_=MyEnum)\n\n        assert get_config(""global"", ""notset"", MyEnum.NAME_1, MyEnum) == \\\n            MyEnum.NAME_1\n\n        assert get_config(""global"", ""byint"", type_=MyIntEnum) == \\\n            MyIntEnum.NAME_5\n        assert get_config(""global"", ""byintname"", type_=MyIntEnum) == \\\n            MyIntEnum.NAME_5\n\n        with pytest.raises(ConfigurationError) as excinfo:\n            get_config(""global"", ""badint"", type_=MyIntEnum)\n        assert ""Valid values are NAME_5, NAME_6"" in str(excinfo.value)\n\n\n@contextmanager\ndef temporary_config(contents, prefix=""stbt-test-config""):\n    with named_temporary_directory(prefix=prefix) as d:\n        original_env = os.environ.get(""STBT_CONFIG_FILE"", """")\n        filename = os.path.join(d, ""stbt.conf"")\n        os.environ[""STBT_CONFIG_FILE""] = to_native_str("":"".join([filename,\n                                                                 original_env]))\n        with open(filename, ""w"") as f:\n            f.write(dedent(contents))\n        _config_init(force=True)\n        try:\n            yield\n        finally:\n            os.environ[""STBT_CONFIG_FILE""] = original_env\n            _config_init(force=True)\n\n\ndef test_unicode_in_STBT_CONFIG_FILE():\n    with temporary_config(test_config, prefix=""\\xf8""):\n        assert get_config(""global"", ""test"") == ""hello""\n\n\ndef test_unicode_in_config_file_contents():\n    with temporary_config(""""""\\\n            [global]\n            unicodeinkey\\xf8 = hi\n            unicodeinvalue = \\xf8\n\n            [unicodeinsection\\xf8]\n            key = bye\n            """"""):\n\n        assert get_config(""global"", ""unicodeinkey\\xf8"") == ""hi""\n        assert get_config(""global"", ""unicodeinvalue"") == ""\\xf8""\n        assert get_config(""unicodeinsection\\xf8"", ""key"") == ""bye""\n\n        # This is `unicode` on python 2 and `str` (i.e. unicode) on python 3.\n        assert isinstance(get_config(""global"", ""unicodeinvalue""), text_type)\n\n\ndef test_get_config_with_default_value():\n    with temporary_config(""""""\\\n            [global]\n            test=hello""""""):\n        assert get_config(""global"", ""test"", ""my default"") == ""hello""\n        assert get_config(""global"", ""nosuchkey"", ""my default"") == ""my default""\n        assert get_config(""nosuchsection"", ""test"", ""my default"") == ""my default""\n        assert get_config(""nosuchsection"", ""test"", None) is None\n        with pytest.raises(ConfigurationError):\n            get_config(""nosuchsection"", ""test"")\n'"
tests/test_core.py,0,"b'# coding: utf-8\n\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport itertools\nimport os\nimport shutil\nimport sys\nimport time\n\nimport cv2\nimport numpy\nimport pytest\n\ntry:\n    from unittest import mock\nexcept ImportError:\n    import mock  # Python 2 backport\n\nimport stbt\nfrom stbt import wait_until\n\n\n# pylint:disable=redefined-outer-name,unused-argument\n\n\ndef test_that_load_image_looks_in_callers_directory():\n    # See also the test with the same name in\n    # ./subdirectory/test_load_image_from_subdirectory.py\n    assert numpy.array_equal(\n        stbt.load_image(""videotestsrc-redblue.png""),\n        cv2.imread(os.path.join(os.path.dirname(__file__),\n                                ""videotestsrc-redblue.png"")))\n\n    with pytest.raises(IOError):\n        stbt.load_image(""info2.png"")\n\n\ndef test_load_image_with_unicode_filename():\n    print(sys.getfilesystemencoding())\n    shutil.copyfile(_find_file(""Rothlisberger.png""),\n                    _find_file(""R\xc3\xb6thlisberger.png""))\n    assert stbt.load_image(u""R\xc3\xb6thlisberger.png"") is not None\n    assert stbt.load_image(u""R\xc3\xb6thlisberger.png"".encode(""utf-8"")) is not None\n    assert stbt.load_image(u""R\\xf6thlisberger.png"") is not None\n\n\ndef test_load_image_with_image():\n    img = numpy.zeros((720, 1280), dtype=numpy.uint8)\n    img2 = stbt.load_image(img)\n    assert img is img2\n\n\ndef test_crop():\n    f = stbt.load_image(""action-panel.png"")\n    cropped = stbt.crop(f, stbt.Region(x=1045, y=672, right=1081, bottom=691))\n    reference = stbt.load_image(""action-panel-blue-button.png"")\n    assert numpy.array_equal(reference, cropped)\n\n    # It\'s a view onto the same memory:\n    assert cropped[0, 0, 0] == f[672, 1045, 0]\n    cropped[0, 0, 0] = 0\n    assert cropped[0, 0, 0] == f[672, 1045, 0]\n\n    # Region must be inside the frame (unfortunately this means that you can\'t\n    # use stbt.Region.ALL):\n    with pytest.raises(ValueError):\n        stbt.crop(f, stbt.Region(x=1045, y=672, right=1281, bottom=721))\n\n\ndef test_region_intersect():\n    r1 = stbt.Region(0, 0, right=20, bottom=10)\n    r2 = stbt.Region(5, 5, right=25, bottom=15)\n    expected = stbt.Region(5, 5, right=20, bottom=10)\n    assert expected == stbt.Region.intersect(r1, r2)\n    with pytest.raises(AttributeError):\n        r1.intersect(r2)  # pylint:disable=no-member\n\n\ndef test_region_bounding_box():\n    r1 = stbt.Region(0, 0, right=20, bottom=10)\n    r2 = stbt.Region(5, 5, right=25, bottom=15)\n    expected = stbt.Region(0, 0, right=25, bottom=15)\n    assert expected == stbt.Region.bounding_box(r1, r2)\n    with pytest.raises(AttributeError):\n        r1.bounding_box(r2)  # pylint:disable=no-member\n\n\ndef test_region_replace():\n    r = stbt.Region(x=10, y=20, width=20, height=30)\n\n    def t(kwargs, expected):\n        assert r.replace(**kwargs) == expected\n\n    def e(kwargs):\n        with pytest.raises(ValueError):\n            r.replace(**kwargs)\n\n    # No change\n    yield t, dict(x=10), r\n    yield t, dict(x=10, width=20), r\n    yield t, dict(x=10, right=30), r\n\n    # Not allowed\n    yield e, dict(x=1, width=2, right=3)\n    yield e, dict(y=1, height=2, bottom=3)\n\n    # Allowed  # pylint:disable=line-too-long\n    yield t, dict(x=11), stbt.Region(x=11, y=r.y, width=19, height=r.height)\n    yield t, dict(width=19), stbt.Region(x=10, y=r.y, width=19, height=r.height)\n    yield t, dict(right=29), stbt.Region(x=10, y=r.y, width=19, height=r.height)\n    yield t, dict(x=11, width=20), stbt.Region(x=11, y=r.y, width=20, height=r.height)\n    yield t, dict(x=11, right=21), stbt.Region(x=11, y=r.y, width=10, height=r.height)\n    yield t, dict(x=11, right=21, y=0, height=5), stbt.Region(x=11, y=0, width=10, height=5)\n\n\ndef test_region_translate():\n    with pytest.raises(TypeError):\n        # Both region and y provided\n        stbt.Region(2, 3, 2, 1).translate(stbt.Region(0, 0, 1, 1), 5)\n\n\n@pytest.mark.parametrize(""frame,mask,threshold,region,expected"", [\n    # pylint:disable=line-too-long\n    (""black-full-frame.png"", None, None, stbt.Region.ALL, True),\n    (""videotestsrc-full-frame.png"", None, None, stbt.Region.ALL, False),\n    (""videotestsrc-full-frame.png"", ""videotestsrc-mask-non-black.png"", None, stbt.Region.ALL, True),\n    (""videotestsrc-full-frame.png"", ""videotestsrc-mask-no-video.png"", None, stbt.Region.ALL, False),\n    (""videotestsrc-full-frame.png"", ""videotestsrc-mask-no-video.png"", None, stbt.Region.ALL, False),\n    (""videotestsrc-full-frame.png"", None, 20, stbt.Region(x=160, y=180, right=240, bottom=240), True),\n    # Threshold bounds for almost-black frame:\n    (""almost-black.png"", None, 3, stbt.Region.ALL, True),\n    (""almost-black.png"", None, 2, stbt.Region.ALL, False),\n])\ndef test_is_screen_black(frame, mask, threshold, region, expected):\n    frame = stbt.load_image(frame)\n    assert expected == bool(\n        stbt.is_screen_black(frame, mask, threshold, region))\n\n\ndef test_is_screen_black_result():\n    frame = stbt.load_image(""almost-black.png"")\n    result = stbt.is_screen_black(frame)\n    assert result\n    assert numpy.all(result.frame == frame)\n    assert result.black is True\n\n\ndef test_is_screen_black_with_numpy_mask():\n    frame = stbt.load_image(""videotestsrc-full-frame.png"")\n    mask = numpy.zeros((240, 320), dtype=numpy.uint8)\n    mask[180:240, 160:213] = 255\n    assert stbt.is_screen_black(frame, mask)\n\n\ndef test_is_screen_black_with_numpy_mask_and_region():\n    frame = stbt.load_image(""videotestsrc-full-frame.png"")\n    region = stbt.Region(x=160, y=180, right=320, bottom=240)\n    mask = numpy.zeros((60, 160), dtype=numpy.uint8)\n    mask[:, :80] = 255\n    assert stbt.is_screen_black(frame, mask, 20, region)\n\n    mask[:, :] = 255\n    assert not stbt.is_screen_black(frame, mask, 20, region)\n\n\nclass C(object):\n    """"""A class with a single property, used by the tests.""""""\n    def __init__(self, prop):\n        self.prop = prop\n\n    def __repr__(self):\n        return ""C(%r)"" % self.prop\n\n    def __eq__(self, other):\n        return isinstance(other, C) and self.prop == other.prop\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n\nclass f(object):\n    """"""Helper factory for wait_until selftests. Creates a callable object that\n    returns the specified values one by one each time it is called.\n\n    Values are specified as space-separated characters. `.` means `None` and\n    `F` means `False`.\n    """"""\n\n    mapping = {""."": None, ""F"": False, ""C1"": C(1), ""C2"": C(2), ""C3"": C(3)}\n\n    def __init__(self, spec):\n        self.spec = spec\n        self.iterator = itertools.cycle(f.mapping.get(x, x)\n                                        for x in self.spec.split())\n\n    def __repr__(self):\n        return ""f(%r)"" % self.spec\n\n    def __call__(self):\n        time.sleep(1)\n        v = next(self.iterator)\n        sys.stderr.write(""f() -> %s\\n"" % v)\n        return v\n\n\n@pytest.fixture(scope=""function"")\ndef mock_time():\n    """"""Mocks out `time.time()` and `time.sleep()` so that time only advances\n    when you call `time.sleep()`.\n    """"""\n\n    t = [1497000000]\n\n    def _time():\n        sys.stderr.write(""time.time() -> %s\\n"" % t[0])\n        return t[0]\n\n    def _sleep(n):\n        sys.stderr.write(""time.sleep(%s)\\n"" % n)\n        t[0] += n\n\n    with mock.patch(""time.time"", _time), mock.patch(""time.sleep"", _sleep):\n        yield\n\n\nclass Zero(object):\n    def __bool__(self):\n        return False\n\n    def __eq__(self, other):\n        return isinstance(other, Zero)\n\n\n@pytest.mark.parametrize(""f,kwargs,expected"", [\n    # wait_until returns on success\n    (f("". a b""), {}, ""a""),\n    (f(""F a b""), {}, ""a""),\n\n    # wait_until tries one last time after reaching timeout_secs\n    (f(""F T""), {""timeout_secs"": 1}, ""T""),\n    (f(""F T""), {""timeout_secs"": 0.1}, ""T""),\n    (f(""F F T""), {""timeout_secs"": 1}, False),\n\n    # wait_until with zero timeout tries once\n    (lambda: True, {""timeout_secs"": 0}, True),\n\n    # predicate behaviour\n    (f(""a b b""), {""predicate"": lambda x: x == ""b""}, ""b""),\n    (f(""F F F""), {""predicate"": lambda x: x == ""b""}, False),\n    (f(""C1 C2""), {""predicate"": lambda x: x.prop == 2}, C(2)),\n    (f(""C1 C2""), {""predicate"": lambda x: x.prop == 3}, None),\n\n    # stable_secs behaviour\n    (f(""a b b""), {}, ""a""),\n    (f(""a b b""), {""stable_secs"": 1}, ""b""),\n    (f(""a b c""), {""stable_secs"": 1}, None),\n    (f(""C1 C2 C3""), {""stable_secs"": 1,\n                     ""predicate"": lambda x: 2 <= x.prop <= 3}, C(2)),\n\n    # timeout_secs elapsed\n    #        |   \xe2\x94\x8c stable_secs needed\n    #        v   v\n    (f(""a b b b b b b b b b b""), {""timeout_secs"": 3, ""stable_secs"": 3}, None),\n\n    # Timeout reached\n    #        | \xe2\x94\x8c stable_secs reached\n    #        v v\n    (f(""a b b b a a a a a a a""), {""timeout_secs"": 3, ""stable_secs"": 2}, ""b""),\n\n    # Falsey values\n    (f(""F F F""), {}, False),\n    (f(""F F F""), {""stable_secs"": 1}, False),\n    (Zero, {""interval_secs"": 1}, Zero()),\n    (Zero, {""interval_secs"": 1, ""stable_secs"": 1}, Zero()),\n])\ndef test_wait_until(mock_time, f, kwargs, expected):\n    assert wait_until(f, **kwargs) == expected\n\n\ndef test_that_wait_until_times_out(mock_time):\n    assert not wait_until(Zero, interval_secs=1)\n    assert time.time() == 1497000010\n\n\ndef test_that_wait_until_returns_first_stable_value(mock_time):\n\n    def MR(match, x):\n        time.sleep(1)  # advance the mock time by 1 second\n        return stbt.MatchResult(\n            time.time(), match, stbt.Region(x=x, y=0, width=10, height=2),\n            first_pass_result=1,\n            frame=numpy.random.randint(0, 255, (2, 2, 3)).astype(numpy.uint8),\n            image=""reference.png"")\n\n    def g():\n        yield MR(False, x=1)\n        yield MR(True, x=2)\n        yield MR(True, x=3)\n        yield MR(True, x=4)\n        yield MR(True, x=4)\n        yield MR(True, x=4)\n        yield MR(True, x=4)\n        yield MR(True, x=4)\n\n    results = g()\n\n    def match():\n        return next(results)\n\n    result = wait_until(match, predicate=lambda x: x and x.region,\n                        stable_secs=2)\n    assert result.match\n    assert result.region.x == 4\n    assert result.time == 1497000004\n\n\ndef test_that_wait_until_doesnt_compare_return_values(mock_time):\n    class MR(object):\n        def __init__(self, eq_allowed=False):\n            time.sleep(1)  # advance the mock time by 1 second\n            self.eq_allowed = eq_allowed\n\n        def __eq__(self, other):\n            if self.eq_allowed:\n                return isinstance(other, MR)\n            else:\n                assert False, ""Got unexpected call to MR.__eq__""\n\n        def __ne__(self, other):\n            return not self.__eq__(other)\n\n    result = wait_until(MR)\n    assert isinstance(result, MR)\n\n    # But it does compare values if you specify `stable_secs`\n    with pytest.raises(AssertionError):\n        result = wait_until(MR, stable_secs=2)\n\n\ndef _find_file(path, root=os.path.dirname(os.path.abspath(__file__))):\n    return os.path.join(root, path)\n'"
tests/test_frameobject.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport threading\n\nimport stbt\n\n\nclass TruthyFrameObject(stbt.FrameObject):\n    """"""\n    The simplest possible FrameObject\n\n    >>> frame = _load_frame(""with-dialog"")\n    >>> bool(TruthyFrameObject(frame))\n    True\n    >>> TruthyFrameObject(frame)\n    TruthyFrameObject(is_visible=True)\n    """"""\n    @property\n    def is_visible(self):\n        return True\n\n\nclass FalseyFrameObject(stbt.FrameObject):\n    """"""Properties aren\'t listed in repr if the FrameObject is falsey.\n\n    >>> frame = _load_frame(""with-dialog"")\n    >>> fo = FalseyFrameObject(frame)\n    >>> bool(fo)\n    False\n    >>> fo\n    FalseyFrameObject(is_visible=False)\n    >>> print(fo.public)\n    None\n    >>> fo._private\n    6\n    """"""\n    @property\n    def is_visible(self):\n        return False\n\n    @property\n    def public(self):\n        return 5\n\n    @property\n    def _private(self):\n        return 6\n\n\nclass FrameObjectWithProperties(stbt.FrameObject):\n    """"""Only public properties are listed in repr.\n\n    >>> frame = _load_frame(""with-dialog"")\n    >>> FrameObjectWithProperties(frame)\n    FrameObjectWithProperties(is_visible=True, public=5)\n    """"""\n    @property\n    def is_visible(self):\n        return True\n\n    @property\n    def public(self):\n        return 5\n\n    @property\n    def _private(self):\n        return 6\n\n\nclass FrameObjectThatCallsItsOwnProperties(stbt.FrameObject):\n    """"""Properties can be called from is_visible.\n\n    >>> frame = _load_frame(""with-dialog"")\n    >>> FrameObjectThatCallsItsOwnProperties(frame)\n    FrameObjectThatCallsItsOwnProperties(is_visible=True, public=5)\n    """"""\n    @property\n    def is_visible(self):\n        return bool(self.public < self._private)\n\n    @property\n    def public(self):\n        return 5\n\n    @property\n    def _private(self):\n        return 6\n\n\nclass OrderedFrameObject(stbt.FrameObject):\n    """"""\n    FrameObject defines a default sort order based on the values of the\n    public properties (in lexicographical order by property name; that is, in\n    this example the `color` value is compared before `size`):\n\n    >>> import numpy\n    >>> red = OrderedFrameObject(numpy.array([[[0, 0, 255]]]))\n    >>> bigred = OrderedFrameObject(numpy.array([[[0, 0, 255], [0, 0, 255]]]))\n    >>> green = OrderedFrameObject(numpy.array([[[0, 255, 0]]]))\n    >>> blue = OrderedFrameObject(numpy.array([[[255, 0, 0]]]))\n    >>> print(sorted([red, green, blue, bigred]))\n    [...\'blue\'..., ...\'green\'..., ...\'red\', size=1..., ...\'red\', size=2)]\n    """"""\n\n    @property\n    def is_visible(self):\n        return True\n\n    @property\n    def size(self):\n        return self._frame.shape[0] * self._frame.shape[1]\n\n    @property\n    def color(self):\n        if self._frame[0, 0, 0] == 255:\n            return ""blue""\n        elif self._frame[0, 0, 1] == 255:\n            return ""green""\n        elif self._frame[0, 0, 2] == 255:\n            return ""red""\n        else:\n            return ""grey?""\n\n\nclass PrintingFrameObject(stbt.FrameObject):\n    """"""\n    This is a very naughty FrameObject.  It\'s properties cause side-effects so\n    we can check that the caching is working:\n\n    >>> frame = _load_frame(""with-dialog"")\n    >>> m = PrintingFrameObject(frame)\n    >>> m.is_visible\n    is_visible called\n    _helper called\n    True\n    >>> m.is_visible\n    True\n    >>> m.another\n    another called\n    10\n    >>> m.another\n    10\n    >>> m\n    PrintingFrameObject(is_visible=True, another=10)\n    """"""\n    @property\n    def is_visible(self):\n        print(""is_visible called"")\n        return self._helper\n\n    @property\n    def _helper(self):\n        print(""_helper called"")\n        return 7\n\n    @property\n    def another(self):\n        print(""another called"")\n        return self._helper + 3\n\n\nclass FalseyPrintingFrameObject(stbt.FrameObject):\n    """"""Another naughty FrameObject. Properties should be cached even when\n    the FrameObject isn\'t visible.\n\n    >>> frame = _load_frame(""with-dialog"")\n    >>> m = FalseyPrintingFrameObject(frame)\n    >>> m.is_visible\n    is_visible called\n    public called\n    _private called\n    False\n    >>> m.is_visible\n    False\n    >>> print(m.public)\n    None\n    >>> print(m.another)\n    None\n    >>> m._private\n    7\n    >>> m._another\n    _another called\n    11\n    >>> m._another\n    11\n    >>> m\n    FalseyPrintingFrameObject(is_visible=False)\n    """"""\n    @property\n    def is_visible(self):\n        print(""is_visible called"")\n        ten = self.public\n        seven = self._private\n        return bool(ten < seven)\n\n    @property\n    def _private(self):\n        print(""_private called"")\n        return 7\n\n    @property\n    def public(self):\n        print(""public called"")\n        return self._private + 3\n\n    @property\n    def another(self):\n        print(""another called"")\n        return 10\n\n    @property\n    def _another(self):\n        print(""_another called"")\n        return 11\n\n\ndef test_that_is_visible_and_properties_arent_racy():\n    # Calling a public property on a falsey FrameObject must always return\n    # `None`, even if another thread is currently evaluating `is_visible`.\n    f = FalseyPrintingFrameObject(_load_frame(""with-dialog""))\n    results = {}\n    threads = []\n\n    def _run(n):\n        results[n] = f.public\n\n    for n in range(10):\n        t = threading.Thread(target=_run, args=(n,))\n        threads.append(t)\n        t.start()\n    for t in threads:\n        t.join()\n    print(results)\n    assert results == {n: None for n in range(10)}\n\n\ndef _load_frame(name):\n    return stbt.load_image(""images/frameobject/%s.png"" % name)\n\n\nclass Dialog(stbt.FrameObject):\n    # pylint:disable=line-too-long\n    """"""\n    >>> dialog = Dialog(frame=_load_frame(\'with-dialog\'))\n    >>> dialog_fab = Dialog(frame=_load_frame(\'with-dialog2\'))\n    >>> no_dialog = Dialog(frame=_load_frame(\'without-dialog\'))\n    >>> dialog_bunnies = Dialog(_load_frame(\'with-dialog-different-background\'))\n    >>> no_dialog_bunnies = Dialog(_load_frame(\'without-dialog-different-background\'))\n\n    Some basic operations:\n\n    >>> print(dialog.message)\n    This set-top box is great\n    >>> print(dialog_fab.message)\n    This set-top box is fabulous\n\n    ``FrameObject`` defines truthiness of your objects based on the mandatory\n    ``is_visible`` property:\n\n    >>> bool(dialog)\n    True\n    >>> bool(no_dialog)\n    False\n\n    If ``is_visible`` is falsey, all the rest of the properties will be\n    ``None``:\n\n    >>> print(no_dialog.message)\n    None\n\n    This enables usage like::\n\n        assert wait_until(lambda: Dialog().title == \'Information\')\n\n    ``FrameObject`` defines ``__repr__`` so that you don\'t have to. It looks\n    like this:\n\n    >>> dialog\n    Dialog(is_visible=True, message=u\'This set-top box is great\', title=u\'Information\')\n    >>> dialog_fab\n    Dialog(is_visible=True, message=u\'This set-top box is fabulous\', title=u\'Information\')\n    >>> no_dialog\n    Dialog(is_visible=False)\n\n    This makes it convenient to use doctests for unit-testing your Frame\n    Objects.\n\n    Frame Objects with identical property values are equal, even if the backing\n    frames are not:\n\n    >>> assert dialog == dialog\n    >>> assert dialog == dialog_bunnies\n    >>> assert dialog != dialog_fab\n    >>> assert dialog != no_dialog\n\n    This can be useful for detecting changes in the UI (while ignoring live TV\n    in the background) or waiting for the UI to stop changing before\n    interrogating it.\n\n    All falsey Frame Objects of the same type are equal:\n\n    >>> assert no_dialog == no_dialog\n    >>> assert no_dialog == no_dialog_bunnies\n\n    ``FrameObject`` defines ``__hash__`` too so you can store them in a set or\n    in a dict:\n\n    >>> {dialog: 1}\n    {Dialog(is_visible=True, message=u\'This set-top box is great\', title=u\'Information\'): 1}\n    >>> len({no_dialog, dialog, dialog, dialog_bunnies})\n    2\n\n    Much like ``namedtuple``, ``FrameObject`` classes have a ``_fields``\n    attribute.\n\n    >>> Dialog._fields\n    (\'is_visible\', \'message\', \'title\')\n\n    ``refresh`` returns a new FrameObject of the same type:\n\n    >>> page = Dialog(frame=_load_frame(\'with-dialog\'))\n    >>> print(page.message)\n    This set-top box is great\n    >>> page = page.refresh(_load_frame(\'with-dialog2\'))\n    >>> print(page.message)\n    This set-top box is fabulous\n\n    """"""\n\n    @property\n    def is_visible(self):\n        """"""\n        All Frame Objects must define the ``is_visible`` property, which will\n        determine the truthiness of the object. Returning True from this\n        property indicates that this Frame Object class can be used with the\n        provided frame and that the values of the other properties are likely\n        to be valid.\n\n        In this example we only return True if we see the ""info"" icon that\n        appears on each dialog box. The actual work is delegated to the private\n        property ``_info`` defined below.\n\n        It\'s a good idea to return simple types from these properties rather\n        than a `MatchResult`, to make the ``__repr__`` cleaner and to preserve\n        equality properties.\n        """"""\n        return bool(self._info)\n\n    @property\n    def title(self):\n        """"""\n        The base class provides a ``self._frame`` member. Here we\'re using\n        `stbt.ocr` to extract the dialog\'s title text from this frame. This is\n        the basic form that many Frame Object properties will take.\n\n        This property demonstrates an advantage of Frame Objects. Your\n        testcases now look like this::\n\n            assert Dialog().title == ""Information""\n\n        instead of this::\n\n            assert stbt.ocr(region=stbt.Region(396, 249, 500, 50)) == ""Information""\n\n        This is clearer because it reveals the intention of the testcase author\n        (we\'re looking for the word in the *title* of the dialog). It is also\n        easier (cheaper) to maintain: If the position of the title moves, you\n        only need to update the implementation of ``Dialog.title``; you won\'t\n        need to change any of your testcases.\n\n        When defining Frame Objects you must take care to pass ``self._frame``\n        into every call to an image processing function (like our ``title``\n        property does when it calls ``ocr``, above). Otherwise the return\n        values won\'t correspond to the frame you were expecting.\n        """"""\n        return stbt.ocr(region=stbt.Region(396, 249, 500, 50),\n                        frame=self._frame)\n\n    @property\n    def message(self):\n        """"""\n        This property demonstrates an advantage of Frame Objects over\n        stand-alone helper functions. We are using the position of the ""info""\n        icon to find this message. Because the private ``_info`` property is\n        shared between this property and ``is_visible`` we don\'t need to\n        compute it twice -- the ``FrameObject`` base class will remember the\n        value from the first time it was computed.\n        """"""\n        right_of_info = stbt.Region(\n            x=self._info.region.right, y=self._info.region.y,\n            width=390, height=self._info.region.height)\n        return stbt.ocr(region=right_of_info, frame=self._frame) \\\n                   .replace(\'\\n\', \' \')\n\n    @property\n    def _info(self):\n        """"""\n        This is a private property because its name starts with ``_``. It will\n        not appear in ``__repr__`` nor count toward equality comparisons, but\n        the result from it will still be cached. This is useful for sharing\n        intermediate values between your public properties, particularly if\n        they are expensive to calculate. In this example we use ``_info`` from\n        ``is_visible`` and ``message``.\n\n        You wouldn\'t want this to be a public property because it returns a\n        `MatchResult` which includes the entire frame passed into `match`.\n        """"""\n        return stbt.match(\'tests/info.png\', frame=self._frame)\n'"
tests/test_grid.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nfrom itertools import combinations\n\nimport networkx as nx\nfrom pytest import raises\n\nfrom stbt import Grid, grid_to_navigation_graph, Position, Region\n\n\ndef test_grid():\n    g = Grid(Region(0, 0, 6, 2), cols=6, rows=2)\n    assert g.area == 12\n    assert len(g) == 12\n\n    def check_conversions(g, region, position, index):\n        c = g.get(index=index)\n        assert c.region == region\n        assert c.position == position\n        assert c.data is None\n        assert c == g.get(region=region)\n        assert c == g.get(position=position)\n        assert c == g[index]\n        assert c == g[position]\n        assert c == g[region]\n\n    check_conversions(g, Region(0, 0, 1, 1), (0, 0), 0)\n    check_conversions(g, Region(5, 1, 1, 1), (5, 1), 11)\n    check_conversions(g, Region(5, 1, 1, 1), Position(5, 1), 11)\n\n    assert g.get(region=Region(4, 0, 3, 3)).position == (5, 1)\n    for x, y in [(-1, 0), (0, -1), (6, 0), (0, 2), (6, 2)]:\n        with raises(IndexError):\n            g.get(region=Region(x, y, 1, 1))\n\n    with raises(IndexError):\n        g.get(index=12)\n    with raises(IndexError):\n        g.get(index=-13)\n    with raises(IndexError):\n        g.get(position=(6, 1))\n    with raises(IndexError):\n        g.get(data=""J"")\n\n    g = Grid(Region(x=99, y=212, width=630, height=401), cols=5, rows=3)\n    check_conversions(g, Region(351, 212, 126, 133), (2, 0), 2)\n    check_conversions(g, Region(477, 345, 126, 134), (3, 1), 8)\n\n    # If you use a region from a different source (e.g. stbt.match) then the\n    # region you get *back* from the Grid should be the region defined by the\n    # grid.\n    r = Region(x=99, y=212, width=126, height=133)\n    assert r == g.get(region=r.extend(right=5, bottom=5)).region\n\n    for r1, r2 in combinations(g.cells, 2):\n        assert Region.intersect(r1.region, r2.region) is None\n\n    for i, c in enumerate(g):\n        assert i == c.index\n\n\ndef test_grid_with_data():\n    layout = [""ABCDEFG"",\n              ""HIJKLMN"",\n              ""OPQRSTU"",\n              ""VWXYZ-\'""]\n    g = Grid(Region(0, 0, 100, 50), data=layout)\n    assert g.cols == 7\n    assert g.rows == 4\n    assert g.get(index=9).data == ""J""\n    assert g.get(position=Position(x=2, y=1)).data == ""J""\n    assert g.get(data=""J"").index == 9\n    assert g[""J""].index == 9\n    assert g[Position(x=2, y=1)].data == ""J""\n    assert g[2, 1].data == ""J""\n    assert g[-1].data == ""\'""\n    for x in [""a"", layout[0], layout]:\n        with raises(IndexError):\n            print(g[x])\n\n\ndef test_grid_to_navigation_graph():\n    grid = Grid(region=None, data=[""ABC"",\n                                   ""DEF""])\n    graph = grid_to_navigation_graph(grid)\n    expected = nx.parse_edgelist(\n        """"""\n        A B KEY_RIGHT\n        A D KEY_DOWN\n        B A KEY_LEFT\n        B C KEY_RIGHT\n        B E KEY_DOWN\n        C B KEY_LEFT\n        C F KEY_DOWN\n        D A KEY_UP\n        D E KEY_RIGHT\n        E B KEY_UP\n        E D KEY_LEFT\n        E F KEY_RIGHT\n        F C KEY_UP\n        F E KEY_LEFT\n        """""".split(""\\n""),\n        create_using=nx.DiGraph(),\n        data=[(""key"", str)])\n    assert sorted(expected.edges(data=True)) == sorted(graph.edges(data=True))\n    assert graph[""A""][""B""] == {""key"": ""KEY_RIGHT""}\n    assert graph[""B""] == {""A"": {""key"": ""KEY_LEFT""},\n                          ""C"": {""key"": ""KEY_RIGHT""},\n                          ""E"": {""key"": ""KEY_DOWN""}}\n\n\ndef test_grid_to_navigation_graph_without_data():\n    # 012\n    # 345\n    grid = Grid(region=None, cols=3, rows=2)\n    graph = grid_to_navigation_graph(grid)\n    expected = nx.parse_edgelist(\n        """"""\n        0 1 KEY_RIGHT\n        0 3 KEY_DOWN\n        1 0 KEY_LEFT\n        1 2 KEY_RIGHT\n        1 4 KEY_DOWN\n        2 1 KEY_LEFT\n        2 5 KEY_DOWN\n        3 0 KEY_UP\n        3 4 KEY_RIGHT\n        4 1 KEY_UP\n        4 3 KEY_LEFT\n        4 5 KEY_RIGHT\n        5 2 KEY_UP\n        5 4 KEY_LEFT\n        """""".split(""\\n""),\n        create_using=nx.DiGraph(),\n        nodetype=int,\n        data=[(""key"", str)])\n    assert sorted(expected.edges(data=True)) == sorted(graph.edges(data=True))\n'"
tests/test_keyboard.py,0,"b'# coding: utf-8\n\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport sys\n\nimport networkx as nx\nimport numpy\nimport pytest\n\ntry:\n    from unittest import mock\nexcept ImportError:\n    import mock  # Python 2 backport\n\nimport stbt\nfrom stbt.keyboard import _add_weights, _keys_to_press\nfrom _stbt.transition import _TransitionResult, TransitionStatus\n\n\nGRAPH = """"""\n    A B KEY_RIGHT\n    A H KEY_DOWN\n    B A KEY_LEFT\n    B C KEY_RIGHT\n    B I KEY_DOWN\n    C B KEY_LEFT\n    C D KEY_RIGHT\n    C J KEY_DOWN\n    D C KEY_LEFT\n    D E KEY_RIGHT\n    D K KEY_DOWN\n    E D KEY_LEFT\n    E F KEY_RIGHT\n    E L KEY_DOWN\n    F E KEY_LEFT\n    F G KEY_RIGHT\n    F M KEY_DOWN\n    G F KEY_LEFT\n    G N KEY_DOWN\n    H I KEY_RIGHT\n    H A KEY_UP\n    H O KEY_DOWN\n    I H KEY_LEFT\n    I J KEY_RIGHT\n    I B KEY_UP\n    I P KEY_DOWN\n    J I KEY_LEFT\n    J K KEY_RIGHT\n    J C KEY_UP\n    J Q KEY_DOWN\n    K J KEY_LEFT\n    K L KEY_RIGHT\n    K D KEY_UP\n    K R KEY_DOWN\n    L K KEY_LEFT\n    L M KEY_RIGHT\n    L E KEY_UP\n    L S KEY_DOWN\n    M L KEY_LEFT\n    M N KEY_RIGHT\n    M F KEY_UP\n    M T KEY_DOWN\n    N M KEY_LEFT\n    N G KEY_UP\n    N U KEY_DOWN\n    O P KEY_RIGHT\n    O H KEY_UP\n    O V KEY_DOWN\n    P O KEY_LEFT\n    P Q KEY_RIGHT\n    P I KEY_UP\n    P W KEY_DOWN\n    Q P KEY_LEFT\n    Q R KEY_RIGHT\n    Q J KEY_UP\n    Q X KEY_DOWN\n    R Q KEY_LEFT\n    R S KEY_RIGHT\n    R K KEY_UP\n    R Y KEY_DOWN\n    S R KEY_LEFT\n    S T KEY_RIGHT\n    S L KEY_UP\n    S Z KEY_DOWN\n    T S KEY_LEFT\n    T U KEY_RIGHT\n    T M KEY_UP\n    T - KEY_DOWN\n    U T KEY_LEFT\n    U N KEY_UP\n    U \' KEY_DOWN\n    V W KEY_RIGHT\n    V O KEY_UP\n    V SPACE KEY_DOWN\n    W V KEY_LEFT\n    W X KEY_RIGHT\n    W P KEY_UP\n    W SPACE KEY_DOWN\n    X W KEY_LEFT\n    X Y KEY_RIGHT\n    X Q KEY_UP\n    X SPACE KEY_DOWN\n    Y X KEY_LEFT\n    Y Z KEY_RIGHT\n    Y R KEY_UP\n    Y SPACE KEY_DOWN\n    Z Y KEY_LEFT\n    Z - KEY_RIGHT\n    Z S KEY_UP\n    Z SPACE KEY_DOWN\n    - Z KEY_LEFT\n    - \' KEY_RIGHT\n    - T KEY_UP\n    - SPACE KEY_DOWN\n    \' - KEY_LEFT\n    \' U KEY_UP\n    \' SPACE KEY_DOWN\n    SPACE CLEAR KEY_RIGHT\n    SPACE V KEY_UP\n    SPACE W KEY_UP\n    SPACE X KEY_UP\n    SPACE Y KEY_UP\n    SPACE Z KEY_UP\n    SPACE - KEY_UP\n    SPACE \' KEY_UP\n    CLEAR SPACE KEY_LEFT\n    CLEAR SEARCH KEY_RIGHT\n    CLEAR V KEY_UP\n    CLEAR W KEY_UP\n    CLEAR X KEY_UP\n    CLEAR Y KEY_UP\n    CLEAR Z KEY_UP\n    CLEAR - KEY_UP\n    CLEAR \' KEY_UP\n    SEARCH CLEAR KEY_LEFT\n    SEARCH V KEY_UP\n    SEARCH W KEY_UP\n    SEARCH X KEY_UP\n    SEARCH Y KEY_UP\n    SEARCH Z KEY_UP\n    SEARCH - KEY_UP\n    SEARCH \' KEY_UP\n""""""\nG = stbt.Keyboard.parse_edgelist(GRAPH)\nnx.relabel_nodes(G, {""SPACE"": "" ""}, copy=False)\n\nif sys.version_info.major == 2:\n    G_BYTES = stbt.Keyboard.parse_edgelist(GRAPH.encode(\'utf-8\'))\n    nx.relabel_nodes(G_BYTES, {b""SPACE"": b"" ""}, copy=False)\n    GRAPHS = [G, G_BYTES]\nelse:\n    GRAPHS = [G]\n\n\n@pytest.mark.parametrize(""g"", GRAPHS)\ndef test_keys_to_press(g):\n    assert list(_keys_to_press(g, ""A"", ""A"")) == []\n    assert list(_keys_to_press(g, ""A"", ""B"")) == [(""KEY_RIGHT"", {""B""})]\n    assert list(_keys_to_press(g, ""B"", ""A"")) == [(""KEY_LEFT"", {""A""})]\n    assert list(_keys_to_press(g, ""A"", ""C"")) == [(""KEY_RIGHT"", {""B""}),\n                                                 (""KEY_RIGHT"", {""C""})]\n    assert list(_keys_to_press(g, ""C"", ""A"")) == [(""KEY_LEFT"", {""B""}),\n                                                 (""KEY_LEFT"", {""A""})]\n    assert list(_keys_to_press(g, ""A"", ""H"")) == [(""KEY_DOWN"", {""H""})]\n    assert list(_keys_to_press(g, ""H"", ""A"")) == [(""KEY_UP"", {""A""})]\n    assert list(_keys_to_press(g, ""A"", ""I"")) in (\n        [(""KEY_RIGHT"", {""B""}), (""KEY_DOWN"", {""I""})],\n        [(""KEY_DOWN"", {""H""}), (""KEY_RIGHT"", {""I""})])\n    assert list(_keys_to_press(g, "" "", ""A"")) == [\n        (""KEY_UP"", {""V"", ""W"", ""X"", ""Y"", ""Z"", ""-"", ""\'""})]\n\n\ndef test_add_weights():\n    G = nx.parse_edgelist(  # pylint:disable=redefined-outer-name\n        """""" W SPACE KEY_DOWN\n            X SPACE KEY_DOWN\n            Y SPACE KEY_DOWN\n            Z SPACE KEY_DOWN\n            SPACE W KEY_UP\n            SPACE X KEY_UP\n            SPACE Y KEY_UP\n            SPACE Z KEY_UP\n            W X KEY_RIGHT\n            X Y KEY_RIGHT\n            Y Z KEY_RIGHT"""""".split(""\\n""),\n        create_using=nx.DiGraph(),\n        data=[(""key"", str)])\n\n    # This is the bug:\n    assert nx.shortest_path(G, ""W"", ""Z"") == [""W"", ""SPACE"", ""Z""]\n\n    # And this is how we fix it:\n    _add_weights(G)\n    assert nx.shortest_path(G, ""W"", ""Z"", weight=""weight"") == [\n        ""W"", ""X"", ""Y"", ""Z""]\n\n\nclass _Keyboard(stbt.FrameObject):\n    """"""Immutable FrameObject representing the test\'s view of the Device Under\n    Test (``dut``).\n\n    The keyboard looks like this::\n\n        A  B  C  D  E  F  G\n        H  I  J  K  L  M  N\n        O  P  Q  R  S  T  U\n        V  W  X  Y  Z  -  \'\n         SPACE  CLEAR  SEARCH\n\n    """"""\n    def __init__(self, dut):\n        super(_Keyboard, self).__init__(\n            frame=numpy.zeros((720, 1280, 3), dtype=numpy.uint8))\n        self._dut = dut  # Device Under Test -- i.e. ``YouTubeKeyboard``\n        self._selection = self._dut.selection\n\n    @property\n    def is_visible(self):\n        return True\n\n    @property\n    def selection(self):\n        return self._selection\n\n    def refresh(self, frame=None, **kwargs):\n        print(""_Keyboard.refresh: Now on %r"" % self._dut.selection)\n        return _Keyboard(dut=self._dut)\n\n    KEYBOARD = stbt.Keyboard(GRAPH, navigate_timeout=0.1)\n\n    def enter_text(self, text):\n        return self.KEYBOARD.enter_text(text.upper(), page=self)\n\n    def navigate_to(self, target, verify_every_keypress=False):\n        return self.KEYBOARD.navigate_to(\n            target, page=self, verify_every_keypress=verify_every_keypress)\n\n\nclass YouTubeKeyboard(object):\n    """"""Fake keyboard implementation for testing.""""""\n\n    def __init__(self):\n        self.selection = ""A""\n        self.page = _Keyboard(dut=self)\n        self.pressed = []\n        self.entered = """"\n        # Pressing up from SPACE returns to the last letter we were at:\n        self.prev_state = ""A""\n\n    def press(self, key):\n        print(""Pressed %s"" % key)\n        self.pressed.append(key)\n        if key == ""KEY_OK"":\n            self.entered += self.selection\n        else:\n            next_states = [\n                t for _, t, k in G.edges(self.selection, data=""key"")\n                if k == key]\n            if self.prev_state in next_states:\n                next_state = self.prev_state\n            else:\n                next_state = next_states[0]\n            if self.selection not in ("" "", ""CLEAR"", ""SEARCH""):\n                self.prev_state = self.selection\n            self.selection = next_state\n\n    def press_and_wait(self, key, **kwargs):  # pylint:disable=unused-argument\n        self.press(key)\n        return _TransitionResult(key, None, TransitionStatus.COMPLETE, 0, 0, 0)\n\n\nclass BuggyKeyboard(YouTubeKeyboard):\n    def press(self, key):\n        super(BuggyKeyboard, self).press(key)\n        if key == ""KEY_RIGHT"" and self.selection == ""B"":\n            self.selection = ""C""\n\n\n@pytest.fixture(scope=""function"")\ndef youtubekeyboard():\n    kb = YouTubeKeyboard()\n    with mock.patch(""stbt.press"", kb.press), \\\n            mock.patch(""stbt.press_and_wait"", kb.press_and_wait):\n        yield kb\n\n\n@pytest.fixture(scope=""function"")\ndef buggykeyboard():\n    """"""Pressing KEY_RIGHT from A skips over B and lands on C.\n\n    Note that the model we specify in our test-scripts still thinks that\n    KEY_RIGHT should land on B. This simulates a bug in the device-under-test,\n    not in the test-scripts.\n    """"""\n    kb = BuggyKeyboard()\n    with mock.patch(""stbt.press"", kb.press), \\\n            mock.patch(""stbt.press_and_wait"", kb.press_and_wait):\n        yield kb\n\n\ndef test_enter_text(youtubekeyboard):  # pylint:disable=redefined-outer-name\n    page = youtubekeyboard.page\n    assert page.selection == ""A""\n    page = page.enter_text(""hi there"")\n    assert page.selection == ""E""\n    assert youtubekeyboard.entered == ""HI THERE""\n\n\ndef test_that_enter_text_uses_minimal_keypresses(youtubekeyboard):  # pylint:disable=redefined-outer-name\n    page = youtubekeyboard.page\n    assert page.selection == ""A""\n    page.enter_text(""HI"")\n    assert youtubekeyboard.pressed == [""KEY_DOWN"", ""KEY_OK"",\n                                       ""KEY_RIGHT"", ""KEY_OK""]\n\n\ndef test_that_keyboard_validates_the_targets(youtubekeyboard):  # pylint:disable=redefined-outer-name\n    page = youtubekeyboard.page\n    with pytest.raises(ValueError):\n        page.enter_text(""ABC\xc3\x91"")\n    assert youtubekeyboard.pressed == []\n    with pytest.raises(ValueError):\n        page.navigate_to(""\xc3\x91"")\n    assert youtubekeyboard.pressed == []\n\n\ndef test_navigate_to(youtubekeyboard):  # pylint:disable=redefined-outer-name\n    page = youtubekeyboard.page\n    assert page.selection == ""A""\n    page = page.navigate_to(""SEARCH"")\n    assert page.selection == ""SEARCH""\n    assert youtubekeyboard.pressed == [""KEY_DOWN""] * 4 + [""KEY_RIGHT""] * 2\n\n\n@pytest.mark.parametrize(""target,verify_every_keypress,num_presses"", [\n    (""B"", False, 1),\n    (""B"", True, 1),\n    (""C"", False, 2),\n    (""C"", True, 1),\n])\ndef test_that_navigate_to_checks_target(\n        buggykeyboard, target, verify_every_keypress, num_presses):  # pylint:disable=redefined-outer-name\n    """"""buggykeyboard skips the B when pressing right from A (and lands on C).""""""\n    page = buggykeyboard.page\n    assert page.selection == ""A""\n    with pytest.raises(AssertionError):\n        page.navigate_to(target, verify_every_keypress)\n    assert buggykeyboard.pressed == [""KEY_RIGHT""] * num_presses\n\n\ndef test_composing_complex_keyboards():\n    """"""The YouTube keyboard on Roku looks like this::\n\n        A  B  C  D  E  F  G\n        H  I  J  K  L  M  N\n        O  P  Q  R  S  T  U\n        V  W  X  Y  Z  -  \'\n         SPACE  CLEAR  SEARCH\n\n    The first 4 rows behave normally within themselves. The bottom row behaves\n    normally within itself. But navigating to or from the bottom row is a bit\n    irregular: No matter what column you\'re in, when you press KEY_DOWN you\n    always land on SPACE. Then when you press KEY_UP, you go back to the column\n    you were last on -- even if you had pressed KEY_RIGHT/KEY_LEFT to move\n    within the bottom row. It\'s almost like they\'re two separate state\n    machines, and we can model them as such, with a few explicit connections\n    between the two.\n    """"""\n    letters = stbt.Grid(stbt.Region(x=540, y=100, right=840, bottom=280),\n                        data=[""ABCDEFG"",\n                              ""HIJKLMN"",\n                              ""OPQRSTU"",\n                              ""VWXYZ-\'""])\n    space_row = stbt.Grid(stbt.Region(x=540, y=280, right=840, bottom=330),\n                          data=[["" "", ""CLEAR"", ""SEARCH""]])\n\n    # Technique #0: Write the entire edgelist manually (as per previous tests)\n    K0 = stbt.Keyboard(GRAPH)\n\n    # Technique #1: Manipulate the graph (manually or programmatically) directly\n    G1 = nx.compose(stbt.grid_to_navigation_graph(letters),\n                    stbt.grid_to_navigation_graph(space_row))\n    # Pressing down from the bottom row always goes to SPACE:\n    for k in letters.data[-1]:\n        G1.add_edge(k, "" "", key=""KEY_DOWN"")\n    # Pressing back up from the space/clear/search row can go to any column\n    # in the bottom row:\n    for k in space_row.data[0]:\n        for j in letters.data[-1]:\n            G1.add_edge(k, j, key=""KEY_UP"")\n    K1 = stbt.Keyboard(G1)\n\n    assert sorted(K0.G.edges(data=True)) == sorted(K1.G.edges(data=True))\n\n    # Technique #2: Use manually-written edgelist only for the irregular edges\n    # Note that Keyboard.__init__ will normalise ""SPACE"" -> "" "" so it doesn\'t\n    # matter if the 3 different graphs have different representations for\n    # ""SPACE"".\n    connections = stbt.Keyboard.parse_edgelist(""""""\n        V SPACE KEY_DOWN\n        W SPACE KEY_DOWN\n        X SPACE KEY_DOWN\n        Y SPACE KEY_DOWN\n        Z SPACE KEY_DOWN\n        - SPACE KEY_DOWN\n        \' SPACE KEY_DOWN\n        SPACE V KEY_UP\n        SPACE W KEY_UP\n        SPACE X KEY_UP\n        SPACE Y KEY_UP\n        SPACE Z KEY_UP\n        SPACE - KEY_UP\n        SPACE \' KEY_UP\n        CLEAR V KEY_UP\n        CLEAR W KEY_UP\n        CLEAR X KEY_UP\n        CLEAR Y KEY_UP\n        CLEAR Z KEY_UP\n        CLEAR - KEY_UP\n        CLEAR \' KEY_UP\n        SEARCH V KEY_UP\n        SEARCH W KEY_UP\n        SEARCH X KEY_UP\n        SEARCH Y KEY_UP\n        SEARCH Z KEY_UP\n        SEARCH - KEY_UP\n        SEARCH \' KEY_UP\n    """""")\n    G2 = nx.compose_all([stbt.grid_to_navigation_graph(letters),\n                         stbt.grid_to_navigation_graph(space_row),\n                         connections])\n    K2 = stbt.Keyboard(G2)\n\n    assert sorted(K0.G.edges(data=True)) == sorted(K2.G.edges(data=True))\n'"
tests/test_lirc_control.py,0,"b'from future.types.newbytes import newbytes\nfrom future.types.newstr import newstr\n\nimport os\nimport subprocess\nfrom collections import namedtuple\nfrom textwrap import dedent\n\nimport pytest\n\nfrom stbt import wait_until\nfrom _stbt.control import uri_to_control\nfrom _stbt.utils import named_temporary_directory, scoped_process\n\n# pylint:disable=redefined-outer-name\n\n\n@pytest.yield_fixture(scope=""function"")\ndef lircd():\n    with named_temporary_directory(""stbt-lirc-test"") as tmpdir:\n        socket = os.path.join(tmpdir, ""lircd.socket"")\n        logfile = os.path.join(tmpdir, ""lircd.log"")\n        proc = subprocess.Popen(\n            [""lircd"", ""--nodaemon"", ""--loglevel=info"", ""--logfile=/dev/stderr"",\n             ""--driver=file"", ""--device"", logfile,  # lircd output\n             ""--output"", socket,  # lircd reads instructions from here\n             ""--pidfile=%s/lircd.pid"" % tmpdir,\n             _find_file(""Apple_TV.lircd.conf"")])\n        wait_until(lambda: (\n            os.path.exists(socket) or proc.poll() is not None))\n\n        with scoped_process(proc):\n            yield namedtuple(""Lircd"", ""socket logfile"")(socket, logfile)\n\n\ndef test_press(lircd):\n    logfile = open(lircd.logfile)\n\n    # newbytes doesn\'t play well with parameterize here, so we use a for loop:\n    for key in [b\'KEY_OK\', u\'KEY_OK\', newbytes(b\'KEY_OK\'), newstr(u\'KEY_OK\')]:\n        print(""key = %r (%s)"" % (key, type(key)))  # pylint: disable=superfluous-parens\n        control = uri_to_control(""lirc:%s:Apple_TV"" % lircd.socket)\n        control.press(key)\n        lircd_output = logfile.read()\n        expected = dedent(""""""\\\n            pulse 9000\n            space 4500\n            pulse 527\n            space 527\n            pulse 527\n            space 1703\n            pulse 527\n            space 1703\n            pulse 527\n            space 1703\n            pulse 527\n            space 527\n            pulse 527\n            space 1703\n            pulse 527\n            space 1703\n            pulse 527\n            space 1703\n            pulse 527\n            space 1703\n            pulse 527\n            space 1703\n            pulse 527\n            space 1703\n            pulse 527\n            space 527\n            pulse 527\n            space 527\n            pulse 527\n            space 527\n            pulse 527\n            space 527\n            pulse 527\n            space 1703\n            pulse 527\n            space 527\n            pulse 527\n            space 527\n            pulse 527\n            space 1703\n            pulse 527\n            space 1703\n            pulse 527\n            space 1703\n            pulse 527\n            space 527\n            pulse 527\n            space 1703\n            pulse 527\n            space 527\n            pulse 527\n            space 527\n            pulse 527\n            space 1703\n            pulse 527\n            space 1703\n            pulse 527\n            space 527\n            pulse 527\n            space 1703\n            pulse 527\n            space 1703\n            pulse 527\n            space 1703\n            pulse 527\n            space 527\n            pulse 527\n            space 38000\n            """""")\n        assert expected == lircd_output\n\n\ndef test_press_with_unknown_remote(lircd):\n    control = uri_to_control(""lirc:%s:roku"" % lircd.socket)\n    with pytest.raises(RuntimeError) as excinfo:\n        control.press(""KEY_OK"")\n    assert \'unknown remote: ""roku""\' in str(excinfo.value)\n\n\ndef test_press_with_unknown_key(lircd):\n    control = uri_to_control(""lirc:%s:Apple_TV"" % lircd.socket)\n    with pytest.raises(RuntimeError) as excinfo:\n        control.press(""KEY_MAGIC"")\n    assert \'unknown command: ""KEY_MAGIC""\' in str(excinfo.value)\n\n\ndef _find_file(path, root=os.path.dirname(os.path.abspath(__file__))):\n    return os.path.join(root, path)\n'"
tests/test_match.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nfrom future.utils import string_types\n\nimport os\nimport random\nimport re\nimport timeit\n\nimport cv2\nimport numpy\nimport pytest\n\nimport stbt\nfrom _stbt import cv2_compat\nfrom _stbt.imgutils import _image_region\nfrom _stbt.logging import scoped_debug_level\nfrom _stbt.match import _merge_regions\nfrom tests.test_core import _find_file\nfrom tests.test_ocr import requires_tesseract\n\n\nrequires_opencv_3 = pytest.mark.skipif(cv2_compat.version < [3, 0, 0],\n                                       reason=""Requires OpenCV 3"")\n\n\ndef mp(match_method=stbt.MatchMethod.SQDIFF, match_threshold=None, **kwargs):\n    if match_threshold is None and match_method != stbt.MatchMethod.SQDIFF:\n        match_threshold = 0.8\n    return stbt.MatchParameters(match_method, match_threshold, **kwargs)\n\n\ndef black(width=1280, height=720, value=0):\n    return numpy.ones((height, width, 3), dtype=numpy.uint8) * value\n\n\ndef test_that_matchresult_image_matches_template_passed_to_match():\n    assert stbt.match(""black.png"", frame=black()).image == ""black.png""\n\n\ndef test_that_matchresult_str_image_matches_template_passed_to_match():\n    assert re.search(r""image=u?\'black.png\'"",\n                     str(stbt.match(""black.png"", frame=black())))\n\n\ndef test_that_matchresult_str_image_matches_template_passed_to_match_custom():\n    assert ""image=<Custom Image>"" in str(\n        stbt.match(black(30, 30), frame=black()))\n\n\ndef test_matchresult_region_when_first_pyramid_level_fails_to_match():\n    f = stbt.load_image(""videotestsrc-full-frame.png"")\n    r = stbt.match(""videotestsrc-redblue-flipped.png"", frame=f).region\n    assert r.width == 92\n    assert r.height == 160\n\n\n@pytest.mark.parametrize(""match_method"", [\n    stbt.MatchMethod.SQDIFF,\n    stbt.MatchMethod.SQDIFF_NORMED,\n])\ndef test_that_match_rejects_greyscale_array(match_method):\n    grey = cv2.cvtColor(stbt.load_image(""black.png""), cv2.COLOR_BGR2GRAY)\n    with pytest.raises(ValueError):\n        stbt.match(grey, frame=black(),\n                   match_parameters=mp(match_method=match_method))\n\n\ndef test_match_error_message_for_too_small_frame_and_region():\n    stbt.match(""videotestsrc-redblue.png"", frame=black(width=92, height=160))\n    stbt.match(""videotestsrc-redblue.png"", frame=black(),\n               region=stbt.Region(x=1188, y=560, width=92, height=160))\n\n    with pytest.raises(ValueError) as excinfo:\n        stbt.match(""videotestsrc-redblue.png"",\n                   frame=black(width=91, height=160))\n    assert (\n        ""Frame (160, 91, 3) must be larger than reference image (160, 92, 3)""\n        in str(excinfo.value))\n\n    with pytest.raises(ValueError) as excinfo:\n        stbt.match(""videotestsrc-redblue.png"",\n                   frame=black(width=92, height=159))\n    assert (\n        ""Frame (159, 92, 3) must be larger than reference image (160, 92, 3)""\n        in str(excinfo.value))\n\n    with pytest.raises(ValueError) as excinfo:\n        # Region seems large enough but actually it extends beyond the frame\n        stbt.match(""videotestsrc-redblue.png"", frame=black(),\n                   region=stbt.Region(x=1189, y=560, width=92, height=160))\n    assert (\n        ""Region(x=1189, y=560, right=1280, bottom=720) must be larger than ""\n        ""reference image (160, 92, 3)""\n        in str(excinfo.value))\n\n    with pytest.raises(ValueError) as excinfo:\n        # Region seems large enough but actually it extends beyond the frame\n        stbt.match(""videotestsrc-redblue.png"", frame=black(),\n                   region=stbt.Region(x=1188, y=561, width=92, height=160))\n    assert (\n        ""Region(x=1188, y=561, right=1280, bottom=720) must be larger than ""\n        ""reference image (160, 92, 3)""\n        in str(excinfo.value))\n\n\n@pytest.mark.parametrize(""match_method"", [\n    stbt.MatchMethod.SQDIFF,\n    stbt.MatchMethod.SQDIFF_NORMED,\n])\ndef test_matching_greyscale_array_with_greyscale_frame(match_method):\n    assert stbt.match(\n        cv2.cvtColor(stbt.load_image(""videotestsrc-redblue.png""),\n                     cv2.COLOR_BGR2GRAY),\n        frame=cv2.cvtColor(stbt.load_image(""videotestsrc-full-frame.png""),\n                           cv2.COLOR_BGR2GRAY),\n        match_parameters=mp(match_method=match_method))\n\n\n@pytest.mark.parametrize(""filename"", [\n    ""videotestsrc-greyscale.png"",\n    ""videotestsrc-greyscale-alpha.png"",\n])\ndef test_that_match_converts_greyscale_reference_image(filename):\n    stbt.match(filename, frame=black())  # Doesn\'t raise\n    stbt.match(stbt.load_image(filename), frame=black())\n\n\n@pytest.mark.parametrize(""match_method"", [\n    stbt.MatchMethod.SQDIFF,\n    stbt.MatchMethod.SQDIFF_NORMED,\n])\ndef test_that_if_image_doesnt_match_match_all_returns_empty_array(match_method):\n    assert [] == list(stbt.match_all(\n        \'button.png\', frame=stbt.load_image(\'black-full-frame.png\'),\n        match_parameters=mp(match_method=match_method)))\n\n\nplain_buttons = [stbt.Region(_x, _y, width=135, height=44) for _x, _y in [\n    (28, 1), (163, 1), (177, 75), (177, 119), (177, 163), (298, 1)]]\nlabelled_buttons = [stbt.Region(_x, _y, width=135, height=44) for _x, _y in [\n    (1, 65), (6, 137)]]\noverlapping_button = stbt.Region(123, 223, width=135, height=44)\noverlapped_button = stbt.Region(3, 223, width=135, height=44)\n\n\n@pytest.mark.parametrize(""match_method"", [\n    stbt.MatchMethod.SQDIFF,\n    stbt.MatchMethod.SQDIFF_NORMED,\n    stbt.MatchMethod.CCORR_NORMED,\n    stbt.MatchMethod.CCOEFF_NORMED,\n])\ndef test_that_match_all_finds_all_matches(match_method):\n    matches = list(m.region for m in stbt.match_all(\n        \'button.png\', frame=stbt.load_image(\'buttons.png\'),\n        match_parameters=mp(match_method=match_method)))\n    print(matches)\n    assert plain_buttons == sorted(matches)\n\n\n@pytest.mark.parametrize(""match_method"", [\n    stbt.MatchMethod.SQDIFF,\n    stbt.MatchMethod.SQDIFF_NORMED,\n])\ndef test_that_match_all_can_find_labelled_matches(match_method):\n    frame = stbt.load_image(\'buttons.png\')\n    matches = list(m.region for m in stbt.match_all(\n        \'button.png\', frame=frame,\n        match_parameters=mp(match_method=match_method,\n                            confirm_method=stbt.ConfirmMethod.NONE)))\n    print(matches)\n    assert overlapped_button not in matches\n    assert sorted(plain_buttons + labelled_buttons + [overlapping_button]) == \\\n        sorted(matches)\n\n\n@requires_opencv_3\ndef test_match_all_with_transparent_reference_image():\n    frame = stbt.load_image(""buttons-on-blue-background.png"")\n    matches = list(m.region for m in stbt.match_all(\n        ""button-transparent.png"", frame=frame))\n    print(matches)\n    assert overlapped_button not in matches\n    assert (sorted(plain_buttons + labelled_buttons + [overlapping_button]) ==\n            sorted(matches))\n\n\n@requires_opencv_3\ndef test_completely_transparent_reference_image():\n    f = stbt.load_image(""buttons-on-blue-background.png"")\n    assert len(list(stbt.match_all(\n        ""completely-transparent.png"", frame=f))) == 18\n\n\n@requires_opencv_3\n@pytest.mark.parametrize(""frame,image,expected_region"", [\n    # pylint:disable=bad-whitespace,line-too-long\n    (""images/regression/roku-tile-frame.png"", ""images/regression/roku-tile-selection.png"", stbt.Region(x=325, y=145, right=545, bottom=325)),\n    (""images/regression/xfinity-frame.png"",   ""images/regression/xfinity-selection.png"",   stbt.Region(x=68, y=157, right=300, bottom=473)),\n])\ndef test_transparent_reference_image_false_negative_caused_by_pyramid(\n        frame, image, expected_region):\n    # This is a regression test for a bug in the pyramid optimisation when\n    # the reference image has a very small number of pixels, or the only non-\n    # transparent pixels are near the edges of reference image:\n    # At the smaller pyramid levels, the pixels near the edge of the reference\n    # image won\'t match exactly because the corresponding pixels in the\n    # down-scaled frame have been blurred. We also blur the reference image\n    # before down-scaling, but since it doesn\'t know what\'s outside its edges,\n    # it won\'t have the  blurring near the edge.\n    frame = stbt.load_image(frame)\n    m = stbt.match(image, frame=frame)\n    assert m\n    assert expected_region.contains(m.region)\n\n\n@pytest.mark.parametrize(""frame,image"", [\n    # pylint:disable=bad-whitespace,line-too-long\n    (""images/regression/badpyramid-frame.png"",  ""images/regression/badpyramid-reference.png""),\n    (""images/regression/badpyramid-frame2.png"", ""images/regression/badpyramid-reference2.png""),\n])\n@pytest.mark.parametrize(""match_method,match_threshold"", [\n    (stbt.MatchMethod.SQDIFF, 0.98),\n    (stbt.MatchMethod.SQDIFF_NORMED, 0.8),\n    (stbt.MatchMethod.CCORR_NORMED, 0.8),\n    (stbt.MatchMethod.CCOEFF_NORMED, 0.8),\n])\ndef test_pyramid_roi_too_small(frame, image, match_method, match_threshold):\n    # This is a regression test for an error that was seen with a particular\n    # frame from a single test-run, with SQDIFF_NORMED:\n    # cv2.error: (-215) _img.size().height <= _templ.size().height &&\n    # _img.size().width <= _templ.size().width in function matchTemplate\n    with scoped_debug_level(2):\n        stbt.match(\n            image,\n            frame=stbt.load_image(frame),\n            match_parameters=stbt.MatchParameters(\n                match_method=match_method,\n                match_threshold=match_threshold))\n\n\n@requires_opencv_3\n@pytest.mark.parametrize(""image,expected"", [\n    # pylint:disable=bad-whitespace,line-too-long\n    (""red-blue-columns"",             stbt.Region(x=0, y=0, width=40, height=40)),\n    (""red-blue-columns-transparent"", stbt.Region(x=0, y=0, width=40, height=40)),\n    (""blue-red-columns"",             stbt.Region(x=1240, y=680, width=40, height=40)),\n    (""blue-red-columns-transparent"", stbt.Region(x=1240, y=680, width=40, height=40)),\n    (""red-blue-rows"",                stbt.Region(x=1240, y=0, width=40, height=40)),\n    (""red-blue-rows-transparent"",    stbt.Region(x=1240, y=0, width=40, height=40)),\n    (""blue-red-rows"",                stbt.Region(x=0, y=680, width=40, height=40)),\n    (""blue-red-rows-transparent"",    stbt.Region(x=0, y=680, width=40, height=40)),\n    (""red-dots"",             stbt.Region(x=280, y=302, width=21, height=21)),\n    (""red-dots-1px-border"",  stbt.Region(x=279, y=301, width=23, height=23)),\n    (""blue-dots"",            stbt.Region(x=307, y=303, width=21, height=21)),\n    (""blue-dots-1px-border"", stbt.Region(x=306, y=302, width=23, height=23)),\n])\ndef test_match_region(image, expected):\n    frame = stbt.load_image(""images/region/frame.png"")\n    m = stbt.match(""images/region/%s.png"" % image, frame=frame)\n    assert m\n    assert m.region == expected\n\n\n@pytest.mark.parametrize(""x,y"", [\n    # ""-20"" means ""1 image width away from the frame\'s right or bottom edge"".\n    (0, 0), (-20, 0), (0, -20), (-20, -20),  # corners\n    (50, 0), (-20, 50), (50, -20), (0, 50),  # edges\n])\n@pytest.mark.parametrize(""offset_x,offset_y"", [\n    # Right at the edge or corner; 1px away horizontally, or vertically, or\n    # both; 2px away etc.\n    (0, 0),\n    (1, 0),\n    (0, 1),\n    (1, 1),\n    (2, 0),\n    (0, 2),\n    (2, 2),\n    (3, 3),\n    (4, 4),\n    (5, 5),\n    # These are outside of the frame so they shouldn\'t match\n    (-1, 0),\n    (0, -1),\n    (-1, -1),\n    (-2, 0),\n    (0, -2),\n    (-2, -2),\n    (-10, 0),\n    (0, -10),\n    (-10, -10),\n])\n@pytest.mark.parametrize(""width,height"", [\n    (20, 20),\n    (20, 21),\n    (21, 20),\n    (21, 21),\n    (31, 30),\n    (40, 40),\n    (40, 41),\n    (41, 40),\n    (41, 41),\n    (158, 88),\n])\n@pytest.mark.parametrize(""frame_width,frame_height"", [\n    (160, 90),\n    (159, 89),  # an odd-sized ""frame"" can happen if the user gives a region\n])\ndef test_match_region2(x, y, offset_x, offset_y, width, height,\n                       frame_width, frame_height):\n    if x >= 0:\n        x = x + offset_x\n    else:\n        x = frame_width - width - offset_x\n    if y >= 0:\n        y = y + offset_y\n    else:\n        y = frame_height - height - offset_y\n    region = stbt.Region(x, y, width=width, height=height)\n    image = numpy.ones((region.height, region.width, 3), numpy.uint8) * 255\n    image[5:-5, 5:-5] = (255, 0, 0)\n    frame = black(frame_width, frame_height)\n    frame[region.to_slice()] = image[\n        0 if region.y >= 0 else -region.y :\n            region.height if region.bottom <= frame_height\n            else frame_height - region.y,\n        0 if region.x >= 0 else -region.x :\n            region.width if region.right <= frame_width\n            else frame_width - region.x] * .85\n    # N.B. .85 is the lowest at which all the tests still passed when I\n    # disabled the pyramid optimisation.\n\n    should_match = _image_region(frame).contains(region)\n\n    m = stbt.match(image, frame)\n    if should_match != m.match or os.environ.get(""STBT_DEBUG""):\n        with scoped_debug_level(2):\n            stbt.match(image, frame)\n    assert should_match == m.match\n    if should_match:\n        assert m.region == region\n\n\n@requires_opencv_3\n@requires_tesseract\ndef test_that_match_all_can_be_used_with_ocr_to_read_buttons():\n    # Demonstrates how match_all can be used with ocr for UIs consisting of text\n    # on buttons\n    frame = stbt.load_image(\'buttons.png\')\n\n    text = [\n        stbt.ocr(frame=stbt.crop(\n            frame,\n            m.region.extend(x=30, y=10, right=-30, bottom=-10)))\n        for m in stbt.match_all(\'button-transparent.png\', frame=frame)]\n    text = sorted([t for t in text if t not in [\'\', \'\\\\s\']])\n    print(text)\n    assert text == [u\'Button 1\', u\'Button 2\', u\'Buttons\']\n\n\n@pytest.mark.parametrize(""match_method"", [\n    stbt.MatchMethod.SQDIFF,\n    stbt.MatchMethod.SQDIFF_NORMED,\n])\ndef test_that_results_dont_overlap(match_method):\n    # This is a regression test for a bug seen in an earlier implementation of\n    # `match_all`.\n    frame = stbt.load_image(""action-panel.png"")\n    all_matches = set()\n    for m in stbt.match_all(""action-panel-template.png"", frame=frame,\n                            match_parameters=mp(match_method=match_method)):\n        print(m)\n        assert m.region not in all_matches, ""Match %s already seen:\\n    %s"" % (\n            m, ""\\n    "".join(str(x) for x in all_matches))\n        assert all(stbt.Region.intersect(m.region, x) is None\n                   for x in all_matches)\n        all_matches.add(m.region)\n\n    assert all_matches == set([\n        stbt.Region(x=135, y=433, width=222, height=40),\n        stbt.Region(x=135, y=477, width=222, height=40),\n        stbt.Region(x=135, y=521, width=222, height=40),\n        stbt.Region(x=135, y=565, width=222, height=40),\n        stbt.Region(x=135, y=609, width=222, height=40)])\n\n\n@pytest.mark.parametrize(""match_method"", [\n    stbt.MatchMethod.SQDIFF,\n    stbt.MatchMethod.SQDIFF_NORMED,\n])\ndef test_that_match_all_obeys_region(match_method):\n    matches = sorted(m.region for m in stbt.match_all(\n        ""button.png"", frame=stbt.load_image(""buttons.png""),\n        match_parameters=mp(match_method=match_method),\n        region=stbt.Region(x=160, y=60, right=340, bottom=190)))\n    print(matches)\n    assert matches == [stbt.Region(x, y, width=135, height=44) for x, y in [\n        (177, 75), (177, 119)]]\n\n\n@pytest.mark.parametrize(""match_method"", [\n    stbt.MatchMethod.SQDIFF,\n    stbt.MatchMethod.SQDIFF_NORMED,\n])\ndef test_match_all_with_an_image_that_matches_everywhere(match_method):\n    matches = sorted(m.region for m in stbt.match_all(\n        ""repeating-pattern.png"",\n        frame=stbt.load_image(""repeating-pattern-full-frame.png""),\n        match_parameters=mp(match_method=match_method)))\n\n    expected_matches = sorted([stbt.Region(x, y, width=16, height=16)\n                               for x in range(0, 320, 16)\n                               for y in range(0, 240, 16)])\n\n    print(matches)\n    assert matches == expected_matches\n\n\ndef test_that_sqdiff_matches_black_images():\n    black_reference = black(10, 10)\n    almost_black_reference = black(10, 10, value=1)\n    black_frame = black(1280, 720)\n    almost_black_frame = black(1280, 720, value=2)\n\n    sqdiff = mp(match_method=stbt.MatchMethod.SQDIFF)\n    sqdiff_normed = mp(match_method=stbt.MatchMethod.SQDIFF_NORMED)\n\n    assert not stbt.match(black_reference, black_frame, sqdiff_normed)\n    assert not stbt.match(almost_black_reference, black_frame, sqdiff_normed)\n    assert not stbt.match(almost_black_reference, almost_black_frame,\n                          sqdiff_normed)\n    assert stbt.match(black_reference, black_frame, sqdiff)\n    assert stbt.match(almost_black_reference, black_frame, sqdiff)\n    assert stbt.match(almost_black_reference, almost_black_frame, sqdiff)\n\n\ndef test_transparent_reference_image_with_sqdiff_normed_raises_valueerror():\n    f = stbt.load_image(""buttons-on-blue-background.png"")\n    with pytest.raises(ValueError):\n        stbt.match(""button-transparent.png"", f,\n                   match_parameters=mp(stbt.MatchMethod.SQDIFF_NORMED))\n\n\ndef test_that_build_pyramid_relaxes_mask():\n    from _stbt.match import _build_pyramid\n\n    mask = numpy.ones((200, 20, 3), dtype=numpy.uint8) * 255\n    mask[5:9, 5:9] = 0  # first 0 is an even row/col, last 0 is an odd row/col\n    n = mask.size - numpy.count_nonzero(mask)\n    assert n == 4 * 4 * 3\n    cv2.imwrite(""/tmp/dave1.png"", mask)\n\n    with scoped_debug_level(2):\n        mask_pyramid = _build_pyramid(mask, 2, is_mask=True)\n    assert numpy.all(mask_pyramid[0] == mask)\n\n    downsampled = mask_pyramid[1]\n    cv2.imwrite(""/tmp/dave2.png"", downsampled)\n    assert downsampled.shape == (98, 8, 3)\n    print(downsampled[:, :, 0])  # pylint:disable=unsubscriptable-object\n    # pylint:disable=bad-whitespace\n    expected = \\\n        [[255, 255, 255, 255, 255, 255, 255, 255],\n         [255,   0,   0,   0,   0, 255, 255, 255],\n         [255,   0,   0,   0,   0, 255, 255, 255],\n         [255,   0,   0,   0,   0, 255, 255, 255],\n         [255,   0,   0,   0,   0, 255, 255, 255]] + \\\n        [[255, 255, 255, 255, 255, 255, 255, 255]] * 93\n    assert numpy.all(downsampled[:, :, 0] == expected)  # pylint:disable=unsubscriptable-object\n\n\n@requires_opencv_3\ndef test_png_with_16_bits_per_channel():\n    assert cv2.imread(_find_file(""uint16.png""), cv2.IMREAD_UNCHANGED).dtype == \\\n        numpy.uint16  # Sanity check (that this test is valid)\n\n    assert stbt.match(\n        ""tests/uint16.png"",\n        frame=cv2.imread(_find_file(""uint8.png"")))\n\n\n@requires_opencv_3\ndef test_match_fast_path():\n    # This is just an example of typical use\n    assert stbt.match(""action-panel-prototype.png"",\n                      frame=stbt.load_image(""action-panel.png""))\n\n\n@requires_opencv_3\ndef test_that_match_fast_path_is_equivalent():\n    from _stbt.match import _load_image\n    black_reference = black(10, 10)\n    almost_black_reference = black(10, 10, value=1)\n    black_frame = black(1280, 720)\n    almost_black_frame = black(1280, 720, value=2)\n\n    images = [\n        (""videotestsrc-redblue.png"", ""videotestsrc-full-frame.png""),\n        (""action-panel.png"", ""action-panel.png""),\n        (""videotestsrc-full-frame.png"", ""videotestsrc-full-frame.png""),\n        (""videotestsrc-redblue-flipped.png"", ""videotestsrc-full-frame.png""),\n        (""button.png"", ""black-full-frame.png""),\n        (""completely-transparent.png"", ""buttons-on-blue-background.png""),\n        (""action-panel-template.png"", ""action-panel.png""),\n        (""button.png"", ""buttons.png""),\n        (black_reference, black_frame),\n        (almost_black_reference, black_frame),\n        (almost_black_reference, almost_black_frame),\n        (""repeating-pattern.png"", ""repeating-pattern-full-frame.png""),\n        (""button-transparent.png"", ""buttons.png""),\n    ]\n    for reference, frame in images:\n        if isinstance(frame, string_types):\n            frame = stbt.load_image(frame, cv2.IMREAD_COLOR)\n        reference = _load_image(reference)\n        orig_m = stbt.match(reference, frame=frame)\n        fast_m = stbt.match(reference, frame=frame, region=orig_m.region)\n        assert orig_m.time == fast_m.time\n        assert orig_m.match == fast_m.match\n        assert orig_m.region == fast_m.region\n        assert bool(orig_m) == bool(fast_m)\n        assert orig_m.first_pass_result == pytest.approx(\n            fast_m.first_pass_result, abs=0.0001 if orig_m else 0.05)\n        assert (orig_m.frame == fast_m.frame).all()\n        if isinstance(orig_m.image, numpy.ndarray):\n            assert (orig_m.image == fast_m.image).all()\n        else:\n            assert orig_m.image == fast_m.image\n\n\ndef test_merge_regions():\n    regions = [stbt.Region(*x) for x in [\n        (153, 156, 16, 4), (121, 155, 25, 5), (14, 117, 131, 32),\n        (128, 100, 19, 5), (122, 81, 22, 14), (123, 73, 5, 4),\n        (0, 71, 12, 75), (146, 64, 1, 1), (111, 64, 10, 2), (22, 62, 9, 4),\n        (0, 60, 17, 10), (111, 54, 2, 2), (138, 47, 5, 2), (132, 47, 3, 1),\n        (130, 46, 1, 2), (55, 32, 11, 1), (52, 32, 1, 1), (0, 29, 50, 28),\n        (0, 20, 57, 4), (33, 0, 233, 139)]]\n    _merge_regions(regions)\n    assert len(regions) == 9\n    assert sorted(regions) == (\n        [stbt.Region(*x) for x in [\n            (0, 20, 57, 4), (0, 29, 50, 28), (0, 60, 17, 10), (0, 71, 12, 75),\n            (14, 117, 131, 32), (22, 62, 9, 4), (33, 0, 233, 139),\n            (121, 155, 25, 5), (153, 156, 16, 4)]])\n\n\n@pytest.mark.parametrize(""n"", [20, 200, 2000])\ndef test_merge_regions_performance(n):\n    random.seed(1)\n    regions = []\n    for _ in range(n):\n        x = random.randint(0, 1280)\n        y = random.randint(0, 720)\n        right = random.randint(0, 1280)\n        bottom = random.randint(0, 720)\n        x, w = min(x, right), max(x, right) - min(x, right) + 1\n        y, h = min(y, bottom), max(y, bottom) - min(y, bottom) + 1\n        regions.append(stbt.Region(x, y, w, h))\n\n    times = timeit.repeat(lambda: _merge_regions(regions[:]),\n                          number=1, repeat=10)\n    print(times)\n    print(min(times))\n    assert min(times) < (0.001 * n / 20)\n'"
tests/test_motion.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport time\nfrom contextlib import contextmanager\n\nimport numpy\nimport pytest\n\nimport stbt\n\n\ndef test_motionresult_repr():\n    assert repr(stbt.MotionResult(\n        time=1466002032.335607, motion=True,\n        region=stbt.Region(x=321, y=32, right=334, bottom=42),\n        frame=stbt.Frame(numpy.zeros((720, 1280, 3)),\n                         time=1466002032.335607))) \\\n        == (""MotionResult(""\n            ""time=1466002032.336, motion=True, ""\n            ""region=Region(x=321, y=32, right=334, bottom=42), ""\n            ""frame=<stbt.Frame(time=1466002032.336, dimensions=1280x720x3)>)"")\n\n\ndef test_wait_for_motion_half_motion_str_2of4():\n    with MockTime().patch():\n        res = stbt.wait_for_motion(\n            consecutive_frames=\'2/4\', frames=fake_frames())\n    print(res)\n    assert res.time == 1466084606.\n\n\ndef test_wait_for_motion_half_motion_str_2of3():\n    with MockTime().patch():\n        res = stbt.wait_for_motion(\n            consecutive_frames=\'2/3\', frames=fake_frames())\n    print(res)\n    assert res.time == 1466084606.\n\n\ndef test_wait_for_motion_half_motion_str_4of10():\n    with MockTime().patch():\n        # Time is not affected by consecutive_frames parameter\n        res = stbt.wait_for_motion(\n            consecutive_frames=\'4/10\', timeout_secs=20, frames=fake_frames())\n    assert res.time == 1466084606.\n\n\ndef test_wait_for_motion_half_motion_str_3of4():\n    try:\n        with MockTime().patch():\n            stbt.wait_for_motion(consecutive_frames=\'3/4\', frames=fake_frames())\n        assert False, ""wait_for_motion succeeded unexpectedly""\n    except stbt.MotionTimeout:\n        pass\n\n\ndef test_wait_for_motion_half_motion_int():\n    with pytest.raises(stbt.MotionTimeout), MockTime().patch():\n        stbt.wait_for_motion(consecutive_frames=2, frames=fake_frames())\n\n\ndef test_that_wait_for_motion_detects_a_wipe():\n    stbt.wait_for_motion(consecutive_frames=""10/30"", frames=wipe())\n    stbt.wait_for_motion(frames=gradient_wipe())\n\n\ndef fake_frames():\n    a = numpy.zeros((2, 2, 3), dtype=numpy.uint8)\n    a.flags.writeable = False\n    b = numpy.ones((2, 2, 3), dtype=numpy.uint8) * 255\n    b.flags.writeable = False\n\n    # Motion:                 v     v     v     v     v     v     v     v     v\n    data = [a, a, a, a, a, a, b, b, a, a, b, b, a, a, b, b, a, a, b, b, a, a, b]\n    #       ^                 ^\n    #       |                 L Motion starts here at timestamp 1466084606.\n    #       L Video starts here at timestamp 1466084600\n\n    start_time = time.time()\n    for n, x in enumerate(data):\n        t = start_time + n\n        time.sleep(t - time.time())\n        yield stbt.Frame(x, time=t)\n\n\ndef wipe():\n    frame = numpy.zeros((720, 1280, 3), dtype=numpy.uint8)\n    for x in range(0, 720, 2):\n        frame[x:x + 2, :, :] = 255\n        yield stbt.Frame(frame, time=x / 30.)\n\n\ndef clamp(x, bottom, top):\n    return min(top, max(bottom, x))\n\n\ndef gradient_wipe(min_=100, max_=200, swipe_height=40):\n    """"""Use write_video(gradient_wipe()) to see what this looks like.""""""\n    frame = min_ * numpy.ones(\n        (720 + swipe_height * 4, 1280, 3), dtype=numpy.uint8)\n    diff = max_ - min_\n\n    # detect_motion ignores differences of under 40, so what\'s the fastest we\n    # can wipe while making sure the inter-frame differences are always under\n    # 40?:\n    speed = 40 * swipe_height / diff\n\n    print(""pixel difference: %f"" % (diff / swipe_height))\n    print(""max_speed: %f"" % speed)\n\n    edge = numpy.ones((swipe_height * 3, 1280, 3), dtype=numpy.uint8) * min_\n    for n in range(swipe_height * 3):\n        edge[n, :, :] = clamp(max_ - (n - swipe_height) * diff / swipe_height,\n                              min_, max_)\n\n    for x in range(0, frame.shape[0] - swipe_height * 3, int(speed)):\n        frame[x:x + swipe_height * 3, :, :] = edge\n        yield stbt.Frame(frame[swipe_height * 2:swipe_height * 2 + 720],\n                         time=x / 30.)\n\n\ndef write_video(g):\n    """"""This was useful during the development of wipe and gradient_wipe.\n    Usage: write_video(gradient_wipe())""""""\n    import cv2\n\n    vw = cv2.VideoWriter(""test.avi"", cv2.VideoWriter_fourcc(\'M\', \'J\', \'P\', \'G\'),\n                         30, (1280, 720))\n    for frame in g:\n        vw.write(frame)\n    vw.release()\n\n\nclass MockTime(object):\n    def __init__(self, start_time=1466084600.):\n        self._time = start_time\n        self._functions = []\n\n    def time(self):\n        t = self._time\n        return t\n\n    def sleep(self, seconds):\n        while self._functions and self._functions[0][0] <= self._time + seconds:\n            _, fn = self._functions.pop(0)\n            fn()\n\n        self._time += seconds\n\n    def interrupt(self, exception):\n        def raise_exception():\n            raise exception\n        self.at(0, raise_exception)\n\n    def at(self, offset, func):\n        self._functions.append((self._time + offset, func))\n        self._functions.sort()\n\n    @contextmanager\n    def assert_duration(self, seconds):\n        start_time = self._time\n        yield self\n        assert self._time - start_time == seconds\n\n    @contextmanager\n    def patch(self):\n        try:\n            from unittest.mock import patch\n        except ImportError:\n            from mock import patch  # Python 2 backport\n\n        with patch(""time.time"", self.time), \\\n                patch(""time.sleep"", self.sleep):\n            yield self\n'"
tests/test_ocr.py,0,"b'# coding: utf-8\n\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport os\nimport re\nfrom contextlib import contextmanager\nfrom distutils.version import LooseVersion\nfrom textwrap import dedent\nfrom unittest import SkipTest\n\nimport cv2\nimport pytest\n\nimport _stbt.config\nimport stbt\nfrom _stbt.ocr import _tesseract_version\nfrom _stbt.utils import named_temporary_directory\nfrom stbt import load_image\n\n\ndef requires_tesseract(func):\n    """"""Decorator for tests that require Tesseract to be installed.""""""\n    try:\n        _tesseract_version()\n    except:\n        raise SkipTest(""tesseract isn\'t installed"")\n    return func\n\n\n@requires_tesseract\n@pytest.mark.parametrize(""image, expected_text, region, mode"", [\n    # pylint: disable=line-too-long\n    (""Connection-status--white-on-dark-blue.png"", ""Connection status: Connected"", stbt.Region.ALL, None),\n    (""Connection-status--white-on-dark-blue.png"", ""Connected"", stbt.Region(x=210, y=0, width=120, height=40), None),\n    # (""Connection-status--white-on-dark-blue.png"", """", None, None),  # uncomment when region=None doesn\'t raise -- see #433\n    (""programme--white-on-black.png"", ""programme"", stbt.Region.ALL, None),\n    (""UJJM--white-text-on-grey-boxes.png"", """", stbt.Region.ALL, None),\n    (""UJJM--white-text-on-grey-boxes.png"", ""UJJM"", stbt.Region.ALL, stbt.OcrMode.SINGLE_LINE),\n])\ndef test_ocr_on_static_images(image, expected_text, region, mode):\n    kwargs = {""region"": region}\n    if mode is not None:\n        kwargs[""mode""] = mode\n    text = stbt.ocr(load_image(""ocr/"" + image), **kwargs)\n    assert text == expected_text\n\n    # Don\'t leak python future newtypes\n    assert type(text).__name__ in [""unicode"", ""str""]\n\n\n# Remove when region=None doesn\'t raise -- see #433\n@requires_tesseract\ndef test_that_ocr_region_none_isnt_allowed():\n    with pytest.raises(TypeError):\n        stbt.ocr(frame=load_image(""ocr/small.png""), region=None)\n\n\n@requires_tesseract\ndef test_that_ocr_reads_unicode():\n    text = stbt.ocr(frame=load_image(\'ocr/unicode.png\'), lang=\'eng+deu\')\n    assert isinstance(text, str)\n    assert u\'\xc2\xa3500\\nDavid R\xc3\xb6thlisberger\' == text\n\n\n@requires_tesseract\ndef test_that_ocr_can_read_small_text():\n    text = stbt.ocr(frame=load_image(\'ocr/small.png\'))\n    assert u\'Small anti-aliased text is hard to read\\nunless you magnify\' == \\\n        text\n\n\nligature_text = dedent(u""""""\\\n    All the similar ""quotes"" and ""quotes"",\n    \'quotes\' and \'quotes\' should be recognised.\n\n    For the avoidance of sillyness so should the\n    ligatures in stiff, filter, fluid, affirm, afflict,\n    and adrift.\n\n    normal-hyphen, non-breaking hyphen,\n    figure-dash, en-dash, em-dash,\n    horizontal-bar."""""")\n\n\n@requires_tesseract\ndef test_that_ligatures_and_ambiguous_punctuation_are_normalised():\n    frame = load_image(\'ocr/ambig.png\')\n    text = stbt.ocr(frame)\n    for bad, good in [\n            # tesseract 3.02\n            (""horizonta|"", ""horizontal""),\n            # tesseract 4.00 with tessdata 590567f\n            (""siIIyness"", ""sillyness""),\n            (""Iigatures"", ""ligatures""),\n    ]:\n        text = text.replace(bad, good)\n    assert ligature_text == text\n    assert stbt.match_text(""em-dash,"", frame)\n    assert stbt.match_text(u""em\\u2014dash,"", frame)\n\n\n@requires_tesseract\ndef test_that_match_text_accepts_unicode():\n    f = load_image(""ocr/unicode.png"")\n    assert stbt.match_text(""David"", f, lang=\'eng+deu\')  # ascii\n    assert stbt.match_text(""R\xc3\xb6thlisberger"", f, lang=\'eng+deu\')  # unicode\n    assert stbt.match_text(\n        ""R\xc3\xb6thlisberger"".encode(\'utf-8\'), f, lang=\'eng+deu\')  # utf-8 bytes\n\n\n@requires_tesseract\ndef test_that_default_language_is_configurable():\n    f = load_image(""ocr/unicode.png"")\n    assert not stbt.match_text(u""R\xc3\xb6thlisberger"", f)  # reads R\xc3\xa9thlisberger\n    with temporary_config({""ocr.lang"": ""deu""}):\n        assert stbt.match_text(u""R\xc3\xb6thlisberger"", f)\n        assert u""R\xc3\xb6thlisberger"" in stbt.ocr(f)\n\n\n@contextmanager\ndef temporary_config(config):\n    with named_temporary_directory(prefix=""stbt-test-ocr"") as d:\n        original_env = os.environ.get(""STBT_CONFIG_FILE"", """")\n        os.environ[""STBT_CONFIG_FILE""] = ""%s/stbt.conf:%s"" % (d, original_env)\n        for key, value in config.items():\n            section, option = key.split(""."")\n            _stbt.config.set_config(section, option, value)\n        try:\n            yield\n        finally:\n            os.environ[""STBT_CONFIG_FILE""] = original_env\n            _stbt.config._config_init(force=True)  # pylint:disable=protected-access\n\n\n@requires_tesseract\ndef test_that_setting_config_options_has_an_effect():\n    # Unfortunately there are many tesseract config options and they are very\n    # complicated so it\'s difficult to write a test that tests that a config\n    # option is having the correct effect.  Due to the difficulty in determining\n    # ""correctness"" instead here we test that setting a config option has an\n    # effect at all.  This at least excercises our code which sets config\n    # options.  I\'m not happy about this and I hope to be able to replace this\n    # once we have more experience with these settings in the real world.\n    if _tesseract_version() >= LooseVersion(\'3.04\'):\n        hocr_mode_config = {\n            ""tessedit_create_txt"": 0,\n            ""tessedit_create_hocr"": 1}\n    else:\n        hocr_mode_config = {\n            ""tessedit_create_hocr"": 1}\n\n    assert (stbt.ocr(frame=load_image(\'ocr/ambig.png\'),\n                     tesseract_config=hocr_mode_config) !=\n            stbt.ocr(frame=load_image(\'ocr/ambig.png\')))\n\n\n@requires_tesseract\n@pytest.mark.parametrize(""patterns"", [\n    pytest.param(None, marks=pytest.mark.xfail),\n    [r\'\\d\\*.\\d\\*.\\d\\*.\\d\\*\'],\n    r\'\\d\\*.\\d\\*.\\d\\*.\\d\\*\',\n])\ndef test_tesseract_user_patterns(patterns):\n    # pylint:disable=protected-access\n    if _tesseract_version() < LooseVersion(\'3.03\'):\n        raise SkipTest(\'tesseract is too old\')\n\n    # Now the real test:\n    assert u\'192.168.10.1\' == stbt.ocr(\n        frame=load_image(\'ocr/192.168.10.1.png\'),\n        mode=stbt.OcrMode.SINGLE_WORD,\n        tesseract_user_patterns=patterns)\n\n\n@requires_tesseract\ndef test_char_whitelist():\n    # Without char_whitelist tesseract reads ""OO"" (the letter oh).\n    assert u\'00\' == stbt.ocr(\n        frame=load_image(\'ocr/00.png\'),\n        mode=stbt.OcrMode.SINGLE_WORD,\n        char_whitelist=""0123456789"")\n\n\n@requires_tesseract\n@pytest.mark.parametrize(""corrections,expected"", [\n    # pylint:disable=bad-whitespace\n    # Default ocr output:\n    (None,                                           \'OO\'),\n    # Corrections string must match entire word:\n    ({\'O\': \'0\'},                                     \'OO\'),\n    ({\'OO\': \'00\'},                                   \'00\'),\n    # Strings are case-sensitive, and they aren\'t regexes:\n    ({\'oo\': \'00\', \'[oO]\': \'0\'},                      \'OO\'),\n    # Regexes do match anywhere:\n    ({re.compile(\'[oO]\'): \'0\'},                      \'00\'),\n    # Make sure it tries all the patterns:\n    ({\'AA\': \'BB\', \'OO\': \'00\'},                       \'00\'),\n    ({re.compile(\'^O\'): \'1\', re.compile(\'O$\'): \'2\'}, \'12\'),\n])\ndef test_corrections(corrections, expected):\n    f = load_image(\'ocr/00.png\')\n    print(corrections)\n    assert expected == stbt.ocr(frame=f, mode=stbt.OcrMode.SINGLE_WORD,\n                                corrections=corrections)\n\n    try:\n        stbt.set_global_ocr_corrections({\'OO\': \'11\'})\n        if expected == ""OO"":\n            expected = ""11""\n        assert expected == stbt.ocr(frame=f, mode=stbt.OcrMode.SINGLE_WORD,\n                                    corrections=corrections)\n    finally:\n        stbt.set_global_ocr_corrections({})\n\n\n@requires_tesseract\n@pytest.mark.parametrize(""words"", [\n    pytest.param(None, marks=pytest.mark.xfail),\n    [\'192.168.10.1\'],\n    b\'192.168.10.1\',\n    u\'192.168.10.1\',\n])\ndef test_user_dictionary_with_non_english_language(words):\n    assert u\'192.168.10.1\' == stbt.ocr(\n        frame=load_image(\'ocr/192.168.10.1.png\'),\n        mode=stbt.OcrMode.SINGLE_WORD,\n        lang=""deu"",\n        tesseract_user_words=words)\n\n# Menu as listed in menu.svg:\nmenu = [\n    [\n        u""Onion Bhaji"",\n        u""Mozzarella Pasta\\nBake"",\n        u""Lamb and Date\\nCasserole"",\n        u""Jerk Chicken""\n    ], [\n        u""Beef Wellington"",\n        u""Kerala Prawn Curry"",\n        u""Chocolate Fudge Cake"",\n        u""Halloumi Stuffed\\nPeppers""\n    ]\n]\n\n\ndef iterate_menu():\n    for x in range(4):\n        for y in range(2):\n            text = menu[y][x]\n            yield (\n                text,\n                stbt.Region((1 + 8 * x) * 40, (3 + 7 * y) * 40, 6 * 40, 2 * 40),\n                \'\\n\' in text)\n\n\n@requires_tesseract\ndef test_that_text_location_is_recognised():\n    frame = load_image(""ocr/menu.png"")\n\n    def test(text, region, upsample):\n        result = stbt.match_text(text, frame=frame, upsample=upsample)\n        assert result\n        assert region.contains(result.region)  # pylint:disable=no-member\n\n    for text, region, multiline in iterate_menu():\n        # Don\'t currently support multi-line comments\n        if multiline:\n            continue\n\n        yield (test, text, region, True)\n        yield (test, text, region, False)\n\n\n@requires_tesseract\ndef test_match_text_stringify_result():\n    frame = load_image(""ocr/menu.png"")\n    result = stbt.match_text(u""Onion Bhaji"", frame=frame)\n\n    assert re.match(\n        r""TextMatchResult\\(time=None, match=True, region=Region\\(.*\\), ""\n        r""frame=<1280x720x3>, text=u?\'Onion Bhaji\'\\)"",\n        str(result))\n\n\n@requires_tesseract\ndef test_that_text_region_is_correct_even_with_regions_larger_than_frame():\n    frame = load_image(""ocr/menu.png"")\n    text, region, _ = list(iterate_menu())[6]\n    result = stbt.match_text(\n        text, frame=frame, region=region.extend(right=+12800))\n    assert result\n    assert region.contains(result.region)\n\n\n@requires_tesseract\n@pytest.mark.parametrize(""region"", [\n    stbt.Region(1280, 0, 1280, 720),\n    None,\n])\ndef test_that_match_text_still_returns_if_region_doesnt_intersect_with_frame(\n        region):\n    frame = load_image(""ocr/menu.png"")\n    result = stbt.match_text(""Onion Bhaji"", frame=frame, region=region)\n    assert result.match is False\n    assert result.region is None\n    assert result.text == ""Onion Bhaji""\n\n    # Avoid future.types.newtypes in return values\n    assert type(result.text).__name__ in [""str"", ""unicode""]\n\n\n@requires_tesseract\n@pytest.mark.parametrize(""region"", [\n    stbt.Region(1280, 0, 1280, 720),\n    # None,  # uncomment when region=None doesn\'t raise -- see #433\n])\ndef test_that_ocr_still_returns_if_region_doesnt_intersect_with_frame(region):\n    frame = load_image(""ocr/menu.png"")\n    result = stbt.ocr(frame=frame, region=region)\n    assert result == u\'\'\n\n\n@requires_tesseract\ndef test_that_match_text_returns_no_match_for_non_matching_text():\n    frame = load_image(""ocr/menu.png"")\n    assert not stbt.match_text(u""Noodle Soup"", frame=frame)\n\n\n@requires_tesseract\ndef test_that_match_text_gives_tesseract_a_hint():\n    frame = load_image(""ocr/itv-player.png"")\n    if ""ITV Player"" in stbt.ocr(frame=frame):\n        raise SkipTest(""Tesseract doesn\'t need a hint"")\n    if ""ITV Player"" not in stbt.ocr(frame=frame, tesseract_user_words=[""ITV""]):\n        raise SkipTest(""Giving tesseract a hint doesn\'t help"")\n    assert stbt.match_text(""ITV Player"", frame=frame)\n\n\n@requires_tesseract\ndef test_match_text_on_single_channel_image():\n    frame = load_image(""ocr/menu.png"", cv2.IMREAD_GRAYSCALE)\n    assert stbt.match_text(""Onion Bhaji"", frame)\n\n\n@requires_tesseract\ndef test_match_text_case_sensitivity():\n    frame = load_image(""ocr/menu.png"", cv2.IMREAD_GRAYSCALE)\n    assert stbt.match_text(""ONION BHAJI"", frame)\n    assert stbt.match_text(""ONION BHAJI"", frame, case_sensitive=False)\n    assert not stbt.match_text(""ONION BHAJI"", frame, case_sensitive=True)\n\n\n@requires_tesseract\ndef test_ocr_on_text_next_to_image_match():\n    frame = load_image(""action-panel.png"")\n    m = stbt.match(""action-panel-blue-button.png"", frame)\n    assert ""YOUVIEW MENU"" == stbt.ocr(frame,\n                                      region=m.region.right_of(width=150))\n\n\n@requires_tesseract\n@pytest.mark.parametrize(""image,color,expected,region"", [\n    # This region has a selected ""Summary"" button (white on light blue) and\n    # unselected buttons ""Details"" and ""More Episodes"" (light grey on black).\n    # Without specifying text_color, OCR only sees the latter two.\n    # Testing without specifying a region would also work, but with a small\n    # region the test runs much faster (0.1s instead of 3s per ocr call).\n    (""action-panel.png"", (235, 235, 235), ""Summary"",\n     stbt.Region(0, 370, right=1280, bottom=410)),\n\n    # This is a light ""8"" on a dark background. Without the context of any\n    # other surrounding text, OCR reads it as "":"" or "";""! Presumably tesseract\n    # is reading the *holes* in the ""8"" instead of the letter itself, because\n    # it\'s assuming that it\'s seeing printed matter (a scanned book with black\n    # text on white background). Expanding the region to include other text\n    # would solve the problem, but so does specifying the text color.\n    (""ocr/ch8.png"", (252, 242, 255), ""8"", stbt.Region.ALL),\n])\ndef test_ocr_text_color(image, color, expected, region):\n    frame = load_image(image)\n    mode = stbt.OcrMode.SINGLE_LINE\n\n    assert expected not in stbt.ocr(frame, region, mode)\n    assert expected == stbt.ocr(frame, region, mode, text_color=color)\n\n    assert not stbt.match_text(expected, frame, region, mode)\n    assert stbt.match_text(expected, frame, region, mode, text_color=color)\n\n\n@requires_tesseract\ndef test_ocr_text_color_threshold():\n    f = load_image(""ocr/blue-search-white-guide.png"")\n    c = (220, 220, 220)\n    assert stbt.ocr(f) != ""Guide""\n    # pylint:disable=fixme\n    # TODO: Find an example where text_color_threshold is necessary. Since\n    # tesseract 4.0.0 the default text_color_threshold actually works.\n    # assert stbt.ocr(f, text_color=c) != ""Guide""\n    assert stbt.ocr(f, text_color=c, text_color_threshold=50) == ""Guide""\n    with temporary_config({\'ocr.text_color_threshold\': \'50\'}):\n        assert stbt.ocr(f, text_color=c) == ""Guide""\n\n\n@requires_tesseract\ndef test_that_ocr_engine_has_an_effect():\n    if _tesseract_version() < LooseVersion(""4.0""):\n        raise SkipTest(\'tesseract is too old\')\n\n    f = load_image(""ocr/ambig.png"")\n\n    # This is a regression in tesseract 4.0\'s legacy engine, compared to 3.04:\n    assert ""sillyness"" not in stbt.ocr(f, engine=stbt.OcrEngine.TESSERACT)\n    assert ""sillyness"" not in stbt.ocr(f)\n\n    # ...but the new LSTM engine does read it correctly:\n    assert ""sillyness"" in stbt.ocr(f, engine=stbt.OcrEngine.LSTM)\n    with temporary_config({\'ocr.engine\': \'LSTM\'}):\n        assert ""sillyness"" in stbt.ocr(f)\n'"
tests/test_power.py,0,"b'""""""Tests for the _ATEN_PE6108G PDU class""""""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nfrom contextlib import contextmanager\n\nimport pytest\nfrom pysnmp.proto.rfc1902 import Integer\n\ntry:\n    from unittest.mock import patch\nexcept ImportError:\n    from mock import patch  # Python 2 backport\n\nfrom _stbt.power import uri_to_power_outlet\n\n\ndef mock_data(int_value):\n    """"""Match the format of the data returned from pysnmp""""""\n    return (None, None, None, [(oid, Integer(int_value))])\n\n\n@contextmanager\ndef mock_command_gen():\n    """"""Perform mocks and return a mocked CommandGenerator instance.""""""\n    with patch(\'time.sleep\'),\\\n            patch(\'pysnmp.entity.rfc3413.oneliner.cmdgen.UdpTransportTarget\'),\\\n            patch(\'pysnmp.entity.rfc3413.oneliner.cmdgen.CommandGenerator\')\\\n            as mocked_command_gen:\n        yield mocked_command_gen.return_value\n\n\noutlet = 1\noid = ""1.3.6.1.4.1.21317.1.3.2.2.2.2.{0}.0"".format(outlet + 1)\n\n\ndef test_aten_get_on():\n    with mock_command_gen() as mock_command:\n        mock_command.getCmd.return_value = mock_data(2)\n        aten = uri_to_power_outlet(\'aten:mock.host.name:1\')\n\n        result = aten.get()\n\n        assert result is True\n\n\ndef test_aten_get_off():\n    with mock_command_gen() as mock_command:\n        mock_command.getCmd.return_value = mock_data(1)\n        aten = uri_to_power_outlet(\'aten:mock.host.name:1\')\n\n        result = aten.get()\n\n        assert result is False\n\n\ndef test_aten_set_on():\n    with mock_command_gen() as mock_command:\n        mock_command.setCmd.return_value = mock_data(2)\n        mock_command.getCmd.side_effect = [mock_data(n) for n in (1, 1, 1, 2)]\n        aten = uri_to_power_outlet(\'aten:mock.host.name:1\')\n\n        aten.set(True)\n\n        assert mock_command.getCmd.call_count == 4\n\n\ndef test_aten_set_off():\n    with mock_command_gen() as mock_command:\n        mock_command.setCmd.return_value = mock_data(1)\n        mock_command.getCmd.side_effect = [mock_data(n) for n in (2, 2, 1)]\n        aten = uri_to_power_outlet(\'aten:mock.host.name:1\')\n\n        aten.set(False)\n\n        assert mock_command.getCmd.call_count == 3\n\n\ndef test_aten_set_timeout():\n    with mock_command_gen() as mock_command:\n        mock_command.setCmd.return_value = mock_data(1)\n        mock_command.getCmd.return_value = mock_data(2)\n        aten = uri_to_power_outlet(\'aten:mock.host.name:1\')\n\n        with pytest.raises(RuntimeError):\n            aten.set(False)\n'"
tests/test_press.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport pytest\n\nfrom _stbt.core import DeviceUnderTest, NoSinkPipeline\n\n\ndef test_that_pressing_context_manager_raises_keyup_exceptions():\n    dut = DeviceUnderTest(control=FakeControl(raises_on_keyup=True),\n                          display=_FakeDisplay(),\n                          sink_pipeline=NoSinkPipeline())\n    with pytest.raises(RuntimeError) as excinfo:\n        with dut.pressing(""KEY_MENU""):\n            pass\n    assert ""keyup KEY_MENU failed"" in str(excinfo.value)\n\n\ndef test_that_pressing_context_manager_suppresses_keyup_exceptions():\n    # ...if doing so would hide an exception raised by the test script.\n    control = FakeControl(raises_on_keyup=True)\n    dut = DeviceUnderTest(control=control, display=_FakeDisplay(),\n                          sink_pipeline=NoSinkPipeline())\n    with pytest.raises(AssertionError):\n        with dut.pressing(""KEY_MENU""):\n            assert False\n    assert control.keyup_called == 1\n\n\nclass FakeControl(object):\n    def __init__(self, raises_on_keydown=False, raises_on_keyup=False):\n        self.raises_on_keydown = raises_on_keydown\n        self.raises_on_keyup = raises_on_keyup\n        self.keydown_called = 0\n        self.keyup_called = 0\n\n    def keydown(self, key):\n        print(""keydown %s"" % key)\n        self.keydown_called += 1\n        if self.raises_on_keydown:\n            raise RuntimeError(""keydown %s failed"" % key)\n\n    def keyup(self, key):\n        print(""keyup %s"" % key)\n        self.keyup_called += 1\n        if self.raises_on_keyup:\n            raise RuntimeError(""keyup %s failed"" % key)\n\n\nclass _FakeDisplay(object):\n    def get_frame(self):\n        return None\n'"
tests/test_stbt_control_relay.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport os\nimport socket\nimport subprocess\nimport sys\nfrom contextlib import contextmanager\nfrom tempfile import NamedTemporaryFile\nfrom textwrap import dedent\n\nimport pytest\n\nfrom _stbt.control import uri_to_control\nfrom _stbt.wait import wait_until\nfrom _stbt.utils import named_temporary_directory, scoped_process\n\n\n# For py.test fixtures:\n# pylint: disable=redefined-outer-name\n\n\n@contextmanager\ndef scoped_path_addition(path):\n    os.environ[\'PATH\'] = ""%s:%s"" % (path, os.environ[\'PATH\'])\n    try:\n        yield\n    finally:\n        if os.environ[\'PATH\'] == ""%s:"" % path:\n            os.environ[\'PATH\'] = os.environ[\'PATH\'][len(path) + 1:]\n\n\ndef srcdir(filename="""", here=os.path.abspath(__file__)):\n    return os.path.join(os.path.dirname(here), "".."", filename)\n\n\n@pytest.yield_fixture(scope=\'session\')\ndef installed_stbt_control_relay():\n    with named_temporary_directory(""stbt-control-relay-install.XXXXXX"") as tmp:\n        try:\n            oldprefix = open(srcdir("".stbt-prefix"")).read()\n        except IOError:\n            oldprefix = None\n        subprocess.check_call(\n            [""make"", ""prefix=%s"" % tmp, ""install-stbt-control-relay""],\n            cwd=srcdir())\n        if oldprefix is not None:\n            open(srcdir("".stbt-prefix""), \'w\').write(oldprefix)\n        else:\n            os.unlink(srcdir("".stbt-prefix""))\n\n        os.environ[\'PATH\'] = ""%s/bin:%s"" % (tmp, os.environ[\'PATH\'])\n        yield ""%s/bin/stbt-control-relay"" % tmp\n\n\n@pytest.yield_fixture(scope=\'function\')\ndef stbt_control_relay_on_path(installed_stbt_control_relay):\n    with scoped_path_addition(os.path.dirname(installed_stbt_control_relay)):\n        yield installed_stbt_control_relay\n\n\ndef test_stbt_control_relay(stbt_control_relay_on_path):  # pylint: disable=unused-argument\n    with named_temporary_directory(""stbt-control-relay-test.XXXXXX"") as tmpdir:\n        def t(filename):\n            return os.path.join(tmpdir, filename)\n        proc = subprocess.Popen(\n            [""stbt-control-relay"",\n             ""--socket"", t(""lircd.sock""),\n             ""file:"" + t(""one-file"")])\n        with scoped_process(proc):\n            wait_until(lambda: (\n                os.path.exists(t(""lircd.sock"")) or proc.poll() is not None))\n            testcontrol = uri_to_control(""lirc:%s:stbt-test"" % t(""lircd.sock""))\n\n            testcontrol.press(""KEY_LEFT"")\n            testcontrol.press(""KEY_RIGHT"")\n            testcontrol.keydown(""KEY_MENU"")\n            testcontrol.keyup(""KEY_MENU"")\n            expected = dedent(""""""\\\n                KEY_LEFT\n                KEY_RIGHT\n                Holding KEY_MENU\n                Released KEY_MENU\n                """""")\n\n            assert expected == open(t(""one-file"")).read()\n\n\ndef socket_passing_setup(socket):\n    def preexec_fn():\n        fd = socket.fileno()\n        os.environ[\'LISTEN_FDS\'] = \'1\'\n        os.environ[\'LISTEN_PID\'] = str(os.getpid())\n        if fd != 3:\n            os.dup2(fd, 3)\n        if sys.version_info.major > 2:\n            os.set_inheritable(3, True)  # pylint:disable=no-member\n        os.closerange(4, 100)\n\n    return preexec_fn\n\n\ndef test_stbt_control_relay_with_socket_passing(stbt_control_relay_on_path):  # pylint: disable=unused-argument\n    with NamedTemporaryFile(mode=""w+"",\n                            prefix=""stbt-control-relay-test-"") as tmpfile:\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.bind((\'127.0.0.1\', 0))\n        s.listen(5)\n\n        proc = subprocess.Popen(\n            [""stbt-control-relay"", ""-vv"", ""file:"" + tmpfile.name],\n            preexec_fn=socket_passing_setup(s),\n            close_fds=False)\n        with scoped_process(proc):\n            testcontrol = uri_to_control(""lirc:%s:%i:stbt"" % s.getsockname())\n\n            testcontrol.press(""KEY_UP"")\n            testcontrol.press(""KEY_DOWN"")\n            expected = ""KEY_UP\\nKEY_DOWN\\n""\n\n            assert tmpfile.read() == expected\n'"
tests/test_stbt_debug.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport itertools\nimport os\nimport subprocess\nfrom textwrap import dedent\n\nimport stbt\nfrom _stbt.logging import ImageLogger, scoped_debug_level\nfrom _stbt.utils import scoped_curdir\nfrom stbt import MatchParameters as mp\n\n\ndef test_match_debug():\n    # So that the output directory name doesn\'t depend on how many tests\n    # were run before this one.\n    ImageLogger._frame_number = itertools.count(1)  # pylint:disable=protected-access\n\n    with scoped_curdir(), scoped_debug_level(2):\n        # First pass gives no matches:\n        matches = list(stbt.match_all(\n            ""videotestsrc-redblue-flipped.png"",\n            frame=stbt.load_image(""videotestsrc-full-frame.png"")))\n        print(matches)\n        assert len(matches) == 0\n\n        # Multiple matches; first pass stops with a non-match:\n        matches = list(stbt.match_all(\n            ""button.png"", frame=stbt.load_image(""buttons.png""),\n            match_parameters=mp(match_threshold=0.995)))\n        print(matches)\n        assert len(matches) == 6\n\n        # Multiple matches; second pass stops with a non-match:\n        matches = list(stbt.match_all(\n            ""button.png"", frame=stbt.load_image(""buttons.png"")))\n        print(matches)\n        assert len(matches) == 6\n\n        # With absdiff:\n        matches = list(stbt.match_all(\n            ""button.png"", frame=stbt.load_image(""buttons.png""),\n            match_parameters=mp(confirm_method=""absdiff"",\n                                confirm_threshold=0.84)))\n        print(matches)\n        assert len(matches) == 6\n\n        files = subprocess.check_output(""find stbt-debug | sort"", shell=True) \\\n                          .decode(""utf-8"")\n        assert files == dedent(""""""\\\n            stbt-debug\n            stbt-debug/00001\n            stbt-debug/00001/index.html\n            stbt-debug/00001/level2-source_matchtemplate.png\n            stbt-debug/00001/level2-source.png\n            stbt-debug/00001/level2-source_with_match.png\n            stbt-debug/00001/level2-source_with_rois.png\n            stbt-debug/00001/level2-template.png\n            stbt-debug/00001/match0-heatmap.png\n            stbt-debug/00001/match0-source_with_match.png\n            stbt-debug/00001/source.png\n            stbt-debug/00001/source_with_matches.png\n            stbt-debug/00001/template.png\n            stbt-debug/00002\n            stbt-debug/00002/index.html\n            stbt-debug/00002/level0-source_matchtemplate.png\n            stbt-debug/00002/level0-source_matchtemplate_threshold.png\n            stbt-debug/00002/level0-source.png\n            stbt-debug/00002/level0-source_with_match.png\n            stbt-debug/00002/level0-source_with_rois.png\n            stbt-debug/00002/level0-template.png\n            stbt-debug/00002/level1-source_matchtemplate.png\n            stbt-debug/00002/level1-source_matchtemplate_threshold.png\n            stbt-debug/00002/level1-source.png\n            stbt-debug/00002/level1-source_with_match.png\n            stbt-debug/00002/level1-source_with_rois.png\n            stbt-debug/00002/level1-template.png\n            stbt-debug/00002/level2-source_matchtemplate.png\n            stbt-debug/00002/level2-source_matchtemplate_threshold.png\n            stbt-debug/00002/level2-source.png\n            stbt-debug/00002/level2-source_with_match.png\n            stbt-debug/00002/level2-source_with_rois.png\n            stbt-debug/00002/level2-template.png\n            stbt-debug/00002/match0-confirm-absdiff.png\n            stbt-debug/00002/match0-confirm-absdiff_threshold_erode.png\n            stbt-debug/00002/match0-confirm-absdiff_threshold.png\n            stbt-debug/00002/match0-confirm-source_roi_gray_normalized.png\n            stbt-debug/00002/match0-confirm-source_roi_gray.png\n            stbt-debug/00002/match0-confirm-source_roi.png\n            stbt-debug/00002/match0-confirm-template_gray_normalized.png\n            stbt-debug/00002/match0-confirm-template_gray.png\n            stbt-debug/00002/match0-heatmap.png\n            stbt-debug/00002/match0-source_with_match.png\n            stbt-debug/00002/match1-confirm-absdiff.png\n            stbt-debug/00002/match1-confirm-absdiff_threshold_erode.png\n            stbt-debug/00002/match1-confirm-absdiff_threshold.png\n            stbt-debug/00002/match1-confirm-source_roi_gray_normalized.png\n            stbt-debug/00002/match1-confirm-source_roi_gray.png\n            stbt-debug/00002/match1-confirm-source_roi.png\n            stbt-debug/00002/match1-confirm-template_gray_normalized.png\n            stbt-debug/00002/match1-confirm-template_gray.png\n            stbt-debug/00002/match1-heatmap.png\n            stbt-debug/00002/match1-source_with_match.png\n            stbt-debug/00002/match2-confirm-absdiff.png\n            stbt-debug/00002/match2-confirm-absdiff_threshold_erode.png\n            stbt-debug/00002/match2-confirm-absdiff_threshold.png\n            stbt-debug/00002/match2-confirm-source_roi_gray_normalized.png\n            stbt-debug/00002/match2-confirm-source_roi_gray.png\n            stbt-debug/00002/match2-confirm-source_roi.png\n            stbt-debug/00002/match2-confirm-template_gray_normalized.png\n            stbt-debug/00002/match2-confirm-template_gray.png\n            stbt-debug/00002/match2-heatmap.png\n            stbt-debug/00002/match2-source_with_match.png\n            stbt-debug/00002/match3-confirm-absdiff.png\n            stbt-debug/00002/match3-confirm-absdiff_threshold_erode.png\n            stbt-debug/00002/match3-confirm-absdiff_threshold.png\n            stbt-debug/00002/match3-confirm-source_roi_gray_normalized.png\n            stbt-debug/00002/match3-confirm-source_roi_gray.png\n            stbt-debug/00002/match3-confirm-source_roi.png\n            stbt-debug/00002/match3-confirm-template_gray_normalized.png\n            stbt-debug/00002/match3-confirm-template_gray.png\n            stbt-debug/00002/match3-heatmap.png\n            stbt-debug/00002/match3-source_with_match.png\n            stbt-debug/00002/match4-confirm-absdiff.png\n            stbt-debug/00002/match4-confirm-absdiff_threshold_erode.png\n            stbt-debug/00002/match4-confirm-absdiff_threshold.png\n            stbt-debug/00002/match4-confirm-source_roi_gray_normalized.png\n            stbt-debug/00002/match4-confirm-source_roi_gray.png\n            stbt-debug/00002/match4-confirm-source_roi.png\n            stbt-debug/00002/match4-confirm-template_gray_normalized.png\n            stbt-debug/00002/match4-confirm-template_gray.png\n            stbt-debug/00002/match4-heatmap.png\n            stbt-debug/00002/match4-source_with_match.png\n            stbt-debug/00002/match5-confirm-absdiff.png\n            stbt-debug/00002/match5-confirm-absdiff_threshold_erode.png\n            stbt-debug/00002/match5-confirm-absdiff_threshold.png\n            stbt-debug/00002/match5-confirm-source_roi_gray_normalized.png\n            stbt-debug/00002/match5-confirm-source_roi_gray.png\n            stbt-debug/00002/match5-confirm-source_roi.png\n            stbt-debug/00002/match5-confirm-template_gray_normalized.png\n            stbt-debug/00002/match5-confirm-template_gray.png\n            stbt-debug/00002/match5-heatmap.png\n            stbt-debug/00002/match5-source_with_match.png\n            stbt-debug/00002/match6-heatmap.png\n            stbt-debug/00002/match6-source_with_match.png\n            stbt-debug/00002/source.png\n            stbt-debug/00002/source_with_matches.png\n            stbt-debug/00002/template.png\n            stbt-debug/00003\n            stbt-debug/00003/index.html\n            stbt-debug/00003/level0-source_matchtemplate.png\n            stbt-debug/00003/level0-source_matchtemplate_threshold.png\n            stbt-debug/00003/level0-source.png\n            stbt-debug/00003/level0-source_with_match.png\n            stbt-debug/00003/level0-source_with_rois.png\n            stbt-debug/00003/level0-template.png\n            stbt-debug/00003/level1-source_matchtemplate.png\n            stbt-debug/00003/level1-source_matchtemplate_threshold.png\n            stbt-debug/00003/level1-source.png\n            stbt-debug/00003/level1-source_with_match.png\n            stbt-debug/00003/level1-source_with_rois.png\n            stbt-debug/00003/level1-template.png\n            stbt-debug/00003/level2-source_matchtemplate.png\n            stbt-debug/00003/level2-source_matchtemplate_threshold.png\n            stbt-debug/00003/level2-source.png\n            stbt-debug/00003/level2-source_with_match.png\n            stbt-debug/00003/level2-source_with_rois.png\n            stbt-debug/00003/level2-template.png\n            stbt-debug/00003/match0-confirm-absdiff.png\n            stbt-debug/00003/match0-confirm-absdiff_threshold_erode.png\n            stbt-debug/00003/match0-confirm-absdiff_threshold.png\n            stbt-debug/00003/match0-confirm-source_roi_gray_normalized.png\n            stbt-debug/00003/match0-confirm-source_roi_gray.png\n            stbt-debug/00003/match0-confirm-source_roi.png\n            stbt-debug/00003/match0-confirm-template_gray_normalized.png\n            stbt-debug/00003/match0-confirm-template_gray.png\n            stbt-debug/00003/match0-heatmap.png\n            stbt-debug/00003/match0-source_with_match.png\n            stbt-debug/00003/match1-confirm-absdiff.png\n            stbt-debug/00003/match1-confirm-absdiff_threshold_erode.png\n            stbt-debug/00003/match1-confirm-absdiff_threshold.png\n            stbt-debug/00003/match1-confirm-source_roi_gray_normalized.png\n            stbt-debug/00003/match1-confirm-source_roi_gray.png\n            stbt-debug/00003/match1-confirm-source_roi.png\n            stbt-debug/00003/match1-confirm-template_gray_normalized.png\n            stbt-debug/00003/match1-confirm-template_gray.png\n            stbt-debug/00003/match1-heatmap.png\n            stbt-debug/00003/match1-source_with_match.png\n            stbt-debug/00003/match2-confirm-absdiff.png\n            stbt-debug/00003/match2-confirm-absdiff_threshold_erode.png\n            stbt-debug/00003/match2-confirm-absdiff_threshold.png\n            stbt-debug/00003/match2-confirm-source_roi_gray_normalized.png\n            stbt-debug/00003/match2-confirm-source_roi_gray.png\n            stbt-debug/00003/match2-confirm-source_roi.png\n            stbt-debug/00003/match2-confirm-template_gray_normalized.png\n            stbt-debug/00003/match2-confirm-template_gray.png\n            stbt-debug/00003/match2-heatmap.png\n            stbt-debug/00003/match2-source_with_match.png\n            stbt-debug/00003/match3-confirm-absdiff.png\n            stbt-debug/00003/match3-confirm-absdiff_threshold_erode.png\n            stbt-debug/00003/match3-confirm-absdiff_threshold.png\n            stbt-debug/00003/match3-confirm-source_roi_gray_normalized.png\n            stbt-debug/00003/match3-confirm-source_roi_gray.png\n            stbt-debug/00003/match3-confirm-source_roi.png\n            stbt-debug/00003/match3-confirm-template_gray_normalized.png\n            stbt-debug/00003/match3-confirm-template_gray.png\n            stbt-debug/00003/match3-heatmap.png\n            stbt-debug/00003/match3-source_with_match.png\n            stbt-debug/00003/match4-confirm-absdiff.png\n            stbt-debug/00003/match4-confirm-absdiff_threshold_erode.png\n            stbt-debug/00003/match4-confirm-absdiff_threshold.png\n            stbt-debug/00003/match4-confirm-source_roi_gray_normalized.png\n            stbt-debug/00003/match4-confirm-source_roi_gray.png\n            stbt-debug/00003/match4-confirm-source_roi.png\n            stbt-debug/00003/match4-confirm-template_gray_normalized.png\n            stbt-debug/00003/match4-confirm-template_gray.png\n            stbt-debug/00003/match4-heatmap.png\n            stbt-debug/00003/match4-source_with_match.png\n            stbt-debug/00003/match5-confirm-absdiff.png\n            stbt-debug/00003/match5-confirm-absdiff_threshold_erode.png\n            stbt-debug/00003/match5-confirm-absdiff_threshold.png\n            stbt-debug/00003/match5-confirm-source_roi_gray_normalized.png\n            stbt-debug/00003/match5-confirm-source_roi_gray.png\n            stbt-debug/00003/match5-confirm-source_roi.png\n            stbt-debug/00003/match5-confirm-template_gray_normalized.png\n            stbt-debug/00003/match5-confirm-template_gray.png\n            stbt-debug/00003/match5-heatmap.png\n            stbt-debug/00003/match5-source_with_match.png\n            stbt-debug/00003/match6-confirm-absdiff.png\n            stbt-debug/00003/match6-confirm-absdiff_threshold_erode.png\n            stbt-debug/00003/match6-confirm-absdiff_threshold.png\n            stbt-debug/00003/match6-confirm-source_roi_gray_normalized.png\n            stbt-debug/00003/match6-confirm-source_roi_gray.png\n            stbt-debug/00003/match6-confirm-source_roi.png\n            stbt-debug/00003/match6-confirm-template_gray_normalized.png\n            stbt-debug/00003/match6-confirm-template_gray.png\n            stbt-debug/00003/match6-heatmap.png\n            stbt-debug/00003/match6-source_with_match.png\n            stbt-debug/00003/source.png\n            stbt-debug/00003/source_with_matches.png\n            stbt-debug/00003/template.png\n            stbt-debug/00004\n            stbt-debug/00004/index.html\n            stbt-debug/00004/level0-source_matchtemplate.png\n            stbt-debug/00004/level0-source_matchtemplate_threshold.png\n            stbt-debug/00004/level0-source.png\n            stbt-debug/00004/level0-source_with_match.png\n            stbt-debug/00004/level0-source_with_rois.png\n            stbt-debug/00004/level0-template.png\n            stbt-debug/00004/level1-source_matchtemplate.png\n            stbt-debug/00004/level1-source_matchtemplate_threshold.png\n            stbt-debug/00004/level1-source.png\n            stbt-debug/00004/level1-source_with_match.png\n            stbt-debug/00004/level1-source_with_rois.png\n            stbt-debug/00004/level1-template.png\n            stbt-debug/00004/level2-source_matchtemplate.png\n            stbt-debug/00004/level2-source_matchtemplate_threshold.png\n            stbt-debug/00004/level2-source.png\n            stbt-debug/00004/level2-source_with_match.png\n            stbt-debug/00004/level2-source_with_rois.png\n            stbt-debug/00004/level2-template.png\n            stbt-debug/00004/match0-confirm-absdiff.png\n            stbt-debug/00004/match0-confirm-absdiff_threshold_erode.png\n            stbt-debug/00004/match0-confirm-absdiff_threshold.png\n            stbt-debug/00004/match0-confirm-source_roi_gray.png\n            stbt-debug/00004/match0-confirm-source_roi.png\n            stbt-debug/00004/match0-confirm-template_gray.png\n            stbt-debug/00004/match0-heatmap.png\n            stbt-debug/00004/match0-source_with_match.png\n            stbt-debug/00004/match1-confirm-absdiff.png\n            stbt-debug/00004/match1-confirm-absdiff_threshold_erode.png\n            stbt-debug/00004/match1-confirm-absdiff_threshold.png\n            stbt-debug/00004/match1-confirm-source_roi_gray.png\n            stbt-debug/00004/match1-confirm-source_roi.png\n            stbt-debug/00004/match1-confirm-template_gray.png\n            stbt-debug/00004/match1-heatmap.png\n            stbt-debug/00004/match1-source_with_match.png\n            stbt-debug/00004/match2-confirm-absdiff.png\n            stbt-debug/00004/match2-confirm-absdiff_threshold_erode.png\n            stbt-debug/00004/match2-confirm-absdiff_threshold.png\n            stbt-debug/00004/match2-confirm-source_roi_gray.png\n            stbt-debug/00004/match2-confirm-source_roi.png\n            stbt-debug/00004/match2-confirm-template_gray.png\n            stbt-debug/00004/match2-heatmap.png\n            stbt-debug/00004/match2-source_with_match.png\n            stbt-debug/00004/match3-confirm-absdiff.png\n            stbt-debug/00004/match3-confirm-absdiff_threshold_erode.png\n            stbt-debug/00004/match3-confirm-absdiff_threshold.png\n            stbt-debug/00004/match3-confirm-source_roi_gray.png\n            stbt-debug/00004/match3-confirm-source_roi.png\n            stbt-debug/00004/match3-confirm-template_gray.png\n            stbt-debug/00004/match3-heatmap.png\n            stbt-debug/00004/match3-source_with_match.png\n            stbt-debug/00004/match4-confirm-absdiff.png\n            stbt-debug/00004/match4-confirm-absdiff_threshold_erode.png\n            stbt-debug/00004/match4-confirm-absdiff_threshold.png\n            stbt-debug/00004/match4-confirm-source_roi_gray.png\n            stbt-debug/00004/match4-confirm-source_roi.png\n            stbt-debug/00004/match4-confirm-template_gray.png\n            stbt-debug/00004/match4-heatmap.png\n            stbt-debug/00004/match4-source_with_match.png\n            stbt-debug/00004/match5-confirm-absdiff.png\n            stbt-debug/00004/match5-confirm-absdiff_threshold_erode.png\n            stbt-debug/00004/match5-confirm-absdiff_threshold.png\n            stbt-debug/00004/match5-confirm-source_roi_gray.png\n            stbt-debug/00004/match5-confirm-source_roi.png\n            stbt-debug/00004/match5-confirm-template_gray.png\n            stbt-debug/00004/match5-heatmap.png\n            stbt-debug/00004/match5-source_with_match.png\n            stbt-debug/00004/match6-confirm-absdiff.png\n            stbt-debug/00004/match6-confirm-absdiff_threshold_erode.png\n            stbt-debug/00004/match6-confirm-absdiff_threshold.png\n            stbt-debug/00004/match6-confirm-source_roi_gray.png\n            stbt-debug/00004/match6-confirm-source_roi.png\n            stbt-debug/00004/match6-confirm-template_gray.png\n            stbt-debug/00004/match6-heatmap.png\n            stbt-debug/00004/match6-source_with_match.png\n            stbt-debug/00004/source.png\n            stbt-debug/00004/source_with_matches.png\n            stbt-debug/00004/template.png\n            """""")\n\n        assert_expected(""stbt-debug-expected-output/match"")\n\n\ndef test_motion_debug():\n    # So that the output directory name doesn\'t depend on how many tests\n    # were run before this one.\n    ImageLogger._frame_number = itertools.count(1)  # pylint:disable=protected-access\n\n    def fake_frames():\n        for i, f in enumerate([""box-00001.png"",\n                               ""box-00002.png"",\n                               ""box-00003.png""]):\n            yield stbt.Frame(stbt.load_image(f), time=i)\n\n    with scoped_curdir(), scoped_debug_level(2):\n\n        for _ in stbt.detect_motion(frames=fake_frames()):\n            pass\n        for _ in stbt.detect_motion(frames=fake_frames(), mask=""box-00000.png""):\n            pass\n        for _ in stbt.detect_motion(frames=fake_frames(),\n                                    region=stbt.Region(0, 0, 320, 400)):\n            pass\n\n        files = subprocess.check_output(""find stbt-debug | sort"", shell=True) \\\n                          .decode(""utf-8"")\n        assert files == dedent(""""""\\\n            stbt-debug\n            stbt-debug/00001\n            stbt-debug/00001/absdiff.png\n            stbt-debug/00001/absdiff_threshold_erode.png\n            stbt-debug/00001/absdiff_threshold.png\n            stbt-debug/00001/gray.png\n            stbt-debug/00001/index.html\n            stbt-debug/00001/previous_frame_gray.png\n            stbt-debug/00001/source.png\n            stbt-debug/00002\n            stbt-debug/00002/absdiff.png\n            stbt-debug/00002/absdiff_threshold_erode.png\n            stbt-debug/00002/absdiff_threshold.png\n            stbt-debug/00002/gray.png\n            stbt-debug/00002/index.html\n            stbt-debug/00002/previous_frame_gray.png\n            stbt-debug/00002/source.png\n            stbt-debug/00003\n            stbt-debug/00003/absdiff_masked.png\n            stbt-debug/00003/absdiff.png\n            stbt-debug/00003/absdiff_threshold_erode.png\n            stbt-debug/00003/absdiff_threshold.png\n            stbt-debug/00003/gray.png\n            stbt-debug/00003/index.html\n            stbt-debug/00003/mask.png\n            stbt-debug/00003/previous_frame_gray.png\n            stbt-debug/00003/source.png\n            stbt-debug/00004\n            stbt-debug/00004/absdiff_masked.png\n            stbt-debug/00004/absdiff.png\n            stbt-debug/00004/absdiff_threshold_erode.png\n            stbt-debug/00004/absdiff_threshold.png\n            stbt-debug/00004/gray.png\n            stbt-debug/00004/index.html\n            stbt-debug/00004/mask.png\n            stbt-debug/00004/previous_frame_gray.png\n            stbt-debug/00004/source.png\n            stbt-debug/00005\n            stbt-debug/00005/absdiff.png\n            stbt-debug/00005/absdiff_threshold_erode.png\n            stbt-debug/00005/absdiff_threshold.png\n            stbt-debug/00005/gray.png\n            stbt-debug/00005/index.html\n            stbt-debug/00005/previous_frame_gray.png\n            stbt-debug/00005/source.png\n            stbt-debug/00006\n            stbt-debug/00006/absdiff.png\n            stbt-debug/00006/absdiff_threshold_erode.png\n            stbt-debug/00006/absdiff_threshold.png\n            stbt-debug/00006/gray.png\n            stbt-debug/00006/index.html\n            stbt-debug/00006/previous_frame_gray.png\n            stbt-debug/00006/source.png\n        """""")\n\n        assert_expected(""stbt-debug-expected-output/motion"")\n\n\ndef test_ocr_debug():\n    # So that the output directory name doesn\'t depend on how many tests\n    # were run before this one.\n    ImageLogger._frame_number = itertools.count(1)  # pylint:disable=protected-access\n\n    f = stbt.load_image(""action-panel.png"")\n    r = stbt.Region(0, 370, right=1280, bottom=410)\n    c = (235, 235, 235)\n    nonoverlapping = stbt.Region(2000, 2000, width=10, height=10)\n\n    with scoped_curdir(), scoped_debug_level(2):\n\n        stbt.ocr(f)\n        stbt.ocr(f, region=r)\n        stbt.ocr(f, region=r, text_color=c)\n        stbt.ocr(f, region=nonoverlapping)\n\n        stbt.match_text(""Summary"", f)  # no match\n        stbt.match_text(""Summary"", f, region=r)  # no match\n        stbt.match_text(""Summary"", f, region=r, text_color=c)\n        stbt.match_text(""Summary"", f, region=nonoverlapping)\n\n        files = subprocess.check_output(""find stbt-debug | sort"", shell=True) \\\n                          .decode(""utf-8"")\n        assert files == dedent(""""""\\\n            stbt-debug\n            stbt-debug/00001\n            stbt-debug/00001/index.html\n            stbt-debug/00001/source.png\n            stbt-debug/00001/tessinput.png\n            stbt-debug/00001/upsampled.png\n            stbt-debug/00002\n            stbt-debug/00002/index.html\n            stbt-debug/00002/source.png\n            stbt-debug/00002/tessinput.png\n            stbt-debug/00002/upsampled.png\n            stbt-debug/00003\n            stbt-debug/00003/index.html\n            stbt-debug/00003/source.png\n            stbt-debug/00003/tessinput.png\n            stbt-debug/00003/text_color_difference.png\n            stbt-debug/00003/text_color_threshold.png\n            stbt-debug/00003/upsampled.png\n            stbt-debug/00004\n            stbt-debug/00004/index.html\n            stbt-debug/00004/source.png\n            stbt-debug/00005\n            stbt-debug/00005/index.html\n            stbt-debug/00005/source.png\n            stbt-debug/00005/tessinput.png\n            stbt-debug/00005/upsampled.png\n            stbt-debug/00006\n            stbt-debug/00006/index.html\n            stbt-debug/00006/source.png\n            stbt-debug/00006/tessinput.png\n            stbt-debug/00006/upsampled.png\n            stbt-debug/00007\n            stbt-debug/00007/index.html\n            stbt-debug/00007/source.png\n            stbt-debug/00007/tessinput.png\n            stbt-debug/00007/text_color_difference.png\n            stbt-debug/00007/text_color_threshold.png\n            stbt-debug/00007/upsampled.png\n            stbt-debug/00008\n            stbt-debug/00008/index.html\n            stbt-debug/00008/source.png\n            """""")\n\n        # To see the generated files in tests/dave-debug/:\n        # import shutil\n        # shutil.move(""stbt-debug"", _find_file(""dave-debug""))\n\n\ndef test_is_screen_black_debug():\n    # So that the output directory name doesn\'t depend on how many tests\n    # were run before this one.\n    ImageLogger._frame_number = itertools.count(1)  # pylint:disable=protected-access\n\n    f = stbt.load_image(""videotestsrc-full-frame.png"")\n\n    with scoped_curdir(), scoped_debug_level(2):\n\n        stbt.is_screen_black(f)\n        stbt.is_screen_black(f, mask=""videotestsrc-mask-non-black.png"")\n        stbt.is_screen_black(f, mask=""videotestsrc-mask-no-video.png"")\n        stbt.is_screen_black(f, region=stbt.Region(0, 0, 160, 120))\n\n        files = subprocess.check_output(""find stbt-debug | sort"", shell=True) \\\n                          .decode(""utf-8"")\n        assert files == dedent(""""""\\\n            stbt-debug\n            stbt-debug/00001\n            stbt-debug/00001/grey.png\n            stbt-debug/00001/index.html\n            stbt-debug/00001/non_black.png\n            stbt-debug/00001/source.png\n            stbt-debug/00002\n            stbt-debug/00002/grey.png\n            stbt-debug/00002/index.html\n            stbt-debug/00002/mask.png\n            stbt-debug/00002/non_black.png\n            stbt-debug/00002/source.png\n            stbt-debug/00003\n            stbt-debug/00003/grey.png\n            stbt-debug/00003/index.html\n            stbt-debug/00003/mask.png\n            stbt-debug/00003/non_black.png\n            stbt-debug/00003/source.png\n            stbt-debug/00004\n            stbt-debug/00004/grey.png\n            stbt-debug/00004/index.html\n            stbt-debug/00004/non_black.png\n            stbt-debug/00004/source.png\n            """""")\n\n        assert_expected(""stbt-debug-expected-output/is_screen_black"")\n\n\ndef assert_expected(expected):\n    expected = _find_file(expected)\n\n    subprocess.check_call([\n        ""diff"", ""-u"", ""--exclude=*.png"",\n        # The exact output of cv2.matchtemplate isn\'t deterministic across\n        # different versions of OpenCV:\n        r""--ignore-matching-lines=0\\.99"",\n        ""--ignore-matching-lines=Region"",\n        expected, ""stbt-debug""])\n\n    # To update expected results in source checkout:\n    # import shutil\n    # shutil.rmtree(expected)\n    # shutil.move(""stbt-debug"", expected)\n\n\ndef _find_file(path, root=os.path.dirname(os.path.abspath(__file__))):\n    return os.path.join(root, path)\n'"
tests/test_transition.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport time\nfrom collections import namedtuple\n\nimport cv2\nimport numpy\nimport pytest\nfrom numpy import isclose\n\nimport stbt\nfrom _stbt.transition import strict_diff\n\n\nclass FakeDeviceUnderTest(object):\n    def __init__(self, frames=None):\n        self.state = ""black""\n        self._frames = frames\n\n    def press(self, key):\n        frame_before = next(self.frames())\n        self.state = key\n        return _Keypress(key, time.time(), time.time(), frame_before)\n\n    def frames(self):\n        if self._frames is not None:\n            # Ignore self.state, send the specified frames instead.\n            t = time.time()\n            for state in self._frames:\n                array = F(state, t)\n                yield stbt.Frame(array, time=t)\n                t += 0.04  # 25fps\n\n        else:\n            while True:\n                t = time.time()\n                array = F(self.state, t)\n                if self.state == ""fade-to-black"":\n                    self.state = ""black""\n                elif self.state == ""fade-to-white"":\n                    self.state = ""white""\n                yield stbt.Frame(array, time=t)\n\n\n_Keypress = namedtuple(""_Keypress"", ""key start_time end_time frame_before"")\n\n\ndef F(state, t):\n    if state == ""black"":\n        array = numpy.zeros((720, 1280, 3), dtype=numpy.uint8)\n    elif state == ""white"":\n        array = numpy.ones((720, 1280, 3), dtype=numpy.uint8) * 255\n    elif state in [""fade-to-black"", ""fade-to-white""]:\n        array = numpy.ones((720, 1280, 3), dtype=numpy.uint8) * 127\n    elif state == ""ball"":\n        # black background, white ball that moves by 1 pixel ever 10ms\n        # in the left half of the frame.\n        array = numpy.zeros((720, 1280, 3), dtype=numpy.uint8)\n        cv2.circle(array, (int(t * 100) % 625, 360), 15, (255, 255, 255))\n    return array\n\n\ndef test_press_and_wait():\n    _stbt = FakeDeviceUnderTest()\n\n    transition = stbt.press_and_wait(""white"", stable_secs=0.1, _dut=_stbt)\n    print(transition)\n    assert transition\n    assert transition.status == stbt.TransitionStatus.COMPLETE\n    assert transition.press_time < transition.animation_start_time\n    assert transition.animation_start_time == transition.end_time\n    assert transition.duration < 0.01  # excludes stable period\n    assert transition.frame.min() == 255\n\n    transition = stbt.press_and_wait(""fade-to-black"", stable_secs=0.1,\n                                     _dut=_stbt)\n    print(transition)\n    assert transition\n    assert transition.status == stbt.TransitionStatus.COMPLETE\n    assert transition.animation_start_time < transition.end_time\n    assert transition.frame.max() == 0\n\n\ndef test_press_and_wait_start_timeout():\n    transition = stbt.press_and_wait(""black"", timeout_secs=0.2, stable_secs=0.1,\n                                     _dut=FakeDeviceUnderTest())\n    print(transition)\n    assert not transition\n    assert transition.status == stbt.TransitionStatus.START_TIMEOUT\n\n\ndef test_press_and_wait_stable_timeout():\n    transition = stbt.press_and_wait(""ball"", timeout_secs=0.2, stable_secs=0.1,\n                                     _dut=FakeDeviceUnderTest())\n    print(transition)\n    assert not transition\n    assert transition.status == stbt.TransitionStatus.STABLE_TIMEOUT\n\n    transition = stbt.press_and_wait(""ball"", stable_secs=0,\n                                     _dut=FakeDeviceUnderTest())\n    print(transition)\n    assert transition\n    assert transition.status == stbt.TransitionStatus.COMPLETE\n\n\n@pytest.mark.parametrize(""mask,region,expected"", [\n    (None, stbt.Region.ALL, stbt.TransitionStatus.STABLE_TIMEOUT),\n    (""mask-out-left-half-720p.png"", stbt.Region.ALL,\n     stbt.TransitionStatus.START_TIMEOUT),\n    (None, stbt.Region(x=640, y=0, right=1280, bottom=720),\n     stbt.TransitionStatus.START_TIMEOUT),\n    (None, stbt.Region(x=0, y=0, right=1280, bottom=360),\n     stbt.TransitionStatus.STABLE_TIMEOUT),\n])\ndef test_press_and_wait_with_mask_or_region(mask, region, expected):\n    transition = stbt.press_and_wait(\n        ""ball"", mask=mask, region=region, timeout_secs=0.2, stable_secs=0.1,\n        _dut=FakeDeviceUnderTest())\n    print(transition)\n    assert transition.status == expected\n\n\ndef test_wait_for_transition_to_end():\n    _stbt = FakeDeviceUnderTest()\n\n    transition = stbt.wait_for_transition_to_end(\n        timeout_secs=0.2, stable_secs=0.1, _dut=_stbt)\n\n    _stbt.press(""ball"")\n    transition = stbt.wait_for_transition_to_end(\n        timeout_secs=0.2, stable_secs=0.1, _dut=_stbt)\n    print(transition)\n    assert not transition\n    assert transition.status == stbt.TransitionStatus.STABLE_TIMEOUT\n\n\ndef test_press_and_wait_timestamps():\n    _stbt = FakeDeviceUnderTest(\n        [""black""] * 10 + [""fade-to-white""] * 2 + [""white""] * 100)\n\n    transition = stbt.press_and_wait(""fade-to-white"", _dut=_stbt)\n    print(transition)\n    assert transition\n    assert isclose(transition.animation_start_time,\n                   transition.press_time + 0.40,\n                   rtol=0, atol=0.01)\n    assert isclose(transition.duration, 0.48, rtol=0, atol=0.01)\n    assert isclose(transition.end_time, transition.animation_start_time + 0.08)\n    assert isclose(transition.animation_duration, 0.08)\n\n\ndef test_that_strict_diff_ignores_a_few_scattered_small_differences():\n    assert not strict_diff(\n        stbt.load_image(""2px-different-1.png""),\n        stbt.load_image(""2px-different-2.png""),\n        region=stbt.Region.ALL, mask_image=None)\n'"
tests/validate-ocr.py,0,"b'#!/usr/bin/python\n\nu""""""\nvalidate-ocr.py can be run on a corpus of test images reporting how good a job\nstbt has done of reading the text.  Thus it can be used to measure improvements\nto the OCR algorithm and, more importantly, detect any regressions introduced.\n\nThe corpus consists of a set of images with corresponding text files describing\nwhat the images contain.  e.g. the image `main-menu.png` might have a\ncorresponding file `main-menu.png.txt` containing:\n\n    lang: deu\n    ---\n    Recht\n    Links\n    Oben\n    Unten\n\nvalidate-ocr.py would then check that the result of calling\n`ocr(\'main-menu.png\', lang=\'deu\')` contains the text ""Recht"", ""Links"", ""Oben""\nand ""Unten"" printing a diffable text report to stdout and a human friendly and\nmore verbose html report to the filename given to `--report-filename`.\n\nEverything above \'---\' is interpreted as JSON and passed to the ocr() function.\n\nBlank lines are ignored.\n\nThis tool is designed such that it can be run on corpuses outside the\nstb-tester git tree to allow corpuses containing screen captures from many\nset-top boxes without bloating the main stb-tester repo or risking upsetting\nthe owners of the various set-top box UIs. """"""\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\n\nimport argparse\nimport os\nimport sys\n\nimport cv2\nimport jinja2\nimport yaml\n\n\ndef check(imgname, phrases, params):\n    from stbt import ocr\n\n    img = cv2.imread(imgname)\n    if img is None:\n        raise IOError(\'No such file or directory ""%s""\' % imgname)\n    text = ocr(img, **params)\n\n    matches = sum(1 for x in phrases if x in text)\n\n    return {\n        ""matches"": matches,\n        ""total"": len(phrases),\n        ""percentage"": float(matches) / len(phrases) * 100,\n        ""name"": os.path.basename(imgname),\n        ""path"": imgname,\n        ""phrases"": [{""text"": x, ""match"": x in text} for x in phrases],\n        ""text"": text,\n    }\n\n\ndef main(argv):\n    parser = argparse.ArgumentParser(\n        description=__doc__,\n        formatter_class=argparse.RawDescriptionHelpFormatter)\n    parser.add_argument(""--report-filename"",\n                        help=""Filename to write the HTML report to"")\n    parser.add_argument(""corpus"", help=""Directory containing test corpus"")\n\n    args = parser.parse_args(argv[1:])\n\n    results = []\n\n    files = []\n    for root, _dirs, dfiles in os.walk(args.corpus):\n        files += [root + \'/\' + f for f in dfiles if f.endswith(\'.png.txt\')]\n\n    for n, f in enumerate(files):\n        sys.stderr.write(""%i / %i Complete\\r"" % (n, len(files)))\n\n        imgname = f[:-len(\'.txt\')]\n        with open(f) as of:\n            text = of.read()\n\n        sections = text.split(\'---\', 1)\n        if len(sections) == 2:\n            params = yaml.safe_load(sections[0])\n        else:\n            params = {}\n\n        phrases = [x.decode(\'utf-8\') for x in sections[-1].split(\'\\n\')\n                   if x.strip() != \'\']\n        results.append(check(imgname, phrases, params))\n\n    sys.stderr.write(\'\\n\')\n\n    total = sum(x[\'total\'] for x in results)\n    total_matched = sum(x[\'matches\'] for x in results)\n\n    if args.report_filename:\n        template = os.path.dirname(__file__) + \'/validate-ocr.html.jinja\'\n        with open(args.report_filename, \'w\') as f:\n            f.write(jinja2.Template(open(template).read()).render(\n                images=results,\n                total=total,\n                total_matched=total_matched,\n                percentage=float(total_matched) / total * 100).encode(\'utf-8\'))\n\n    sys.stdout.write(""Passes:\\n"")\n    for x in results:\n        if x[\'matches\'] > 0:\n            sys.stdout.write(""    "" + x[\'name\'] + \'\\n\')\n        for y in x[\'phrases\']:\n            if y[\'match\']:\n                sys.stdout.write(\'        \' + y[\'text\'].encode(\'utf-8\') + \'\\n\')\n\n    sys.stdout.write(""Failures:\\n"")\n    for x in results:\n        if x[\'matches\'] < x[\'total\']:\n            sys.stdout.write(""    "" + x[\'name\'] + \'\\n\')\n        for y in x[\'phrases\']:\n            if not y[\'match\']:\n                sys.stdout.write(\'        \' + y[\'text\'].encode(\'utf-8\') + \'\\n\')\n    return 0 if total == total_matched else 1\n\n\nif __name__ == \'__main__\':\n    sys.exit(main(sys.argv))\n'"
tests/subdirectory/test_load_image_from_subdirectory.py,0,"b'from __future__ import unicode_literals\nfrom __future__ import print_function\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom builtins import *  # pylint:disable=redefined-builtin,unused-wildcard-import,wildcard-import,wrong-import-order\nimport os\n\nimport cv2\nimport numpy\nimport pytest\n\nimport stbt\n\n\ndef test_that_load_image_looks_in_callers_directory():\n    # See also the test with the same name in ../test_core.py\n    assert numpy.array_equal(\n        stbt.load_image(""videotestsrc-redblue.png""),\n        cv2.imread(os.path.join(os.path.dirname(__file__),\n                                ""../videotestsrc-redblue-flipped.png"")))\n\n    with pytest.raises(IOError):\n        stbt.load_image(""info.png"")\n'"
tests/webminspector/ebml_header.py,0,"b'##\n##  Copyright (c) 2010 The WebM project authors. All Rights Reserved.\n##\n##  Use of this source code is governed by a BSD-style license\n##  that can be found in the LICENSE file in the root of the source\n##  tree. An additional intellectual property rights grant can be found\n##  in the file PATENTS.  All contributing project authors may\n##  be found in the AUTHORS file in the root of the source tree.\n##\n\n""""""\npredefine ebml elements.\n""""""\n\n__author__ = \'hwasoolee@google.com.com (Hwasoo Lee)\'\n\n#Ebml Levels\nLEVEL_0 = 0\nLEVEL_1 = 1\nLEVEL_2 = 2\nLEVEL_3 = 3\nLEVEL_4 = 4\nLEVEL_5 = 5\nLEVEL_6 = 6\n\n#Ebml types\nEBML_SUB_ELEMENT = 0\nEBML_BINARY = 1\nEBML_UINTEGER = 2\nEBML_UTF8 = 3\nEBML_FLOAT = 4\nEBML_DATE = 5\nEBML_STRING = 6\nEBML_UINTEGER_1BIT = 7\n\n#Ebml header\nEBML = 0x1A45DFA3\nEBML_VERSION = 0x4286\nEBML_READ_VERSION = 0x42F7\nEBML_MAX_ID_LENGTH = 0x42F2\nEBML_MAX_SIZE_LENGTH = 0x42F3\nEBML_DOC_TYPE = 0x4282\nEBML_DOC_TYPE_VERSION = 0x4287\nEBML_DOC_TYPE_READ_VERSION = 0x4285\n\n#Global elements\nCRC_32 = 0xBF\nVOID = 0xEC\n\n#Segment code\nSEGMENT = 0x18538067\n\n#Meta seek information codes\nSEEKHEAD = 0x114D9B74\nSEEK = 0x4DBB\nSEEKID = 0x53AB\nSEEKPOSITION = 0x53AC\n\n#Segment info codes\nSEGMENT_INFO = 0x1549A966\nSEGMENTUID = 0x73A4\nSEGMENTFILENAME = 0x7384\nPREVUID = 0x3CB923\nPREVFILENAME = 0x3C83AB\nNEXTUID = 0x3EB923\nNEXTFILENAME = 0x3E83BB\nSEGMENTFAMILY = 0x4444\nCHAPTERTRANSLATE = 0x6924\nCHAPTERTRANSLATEEDITIONUID = 0x69FC\nCHAPTERTRANSLATECODEC = 0x69BF\nCHAPTERTRANSLATEID = 0x69A5\nTIMECODESCALE = 0x2AD7B1\nDURATION = 0x4489\nDATEUTC = 0x4461\nTITLE = 0x7BA9\nMUXINGAPP = 0x4D80\nWRITINGAPP = 0x5741\n\n#Cluster codes\nCLUSTER = 0x1F43B675\nTIMECODE = 0xE7\nSILENT_TRACKS = 0x5854\nSILENT_TRACK_NUMBER = 0x58D7\nPOSITION = 0xA7\nPREVSIZE = 0xAB\nBLOCK_GROUP = 0xA0\nBLOCK = 0xA1\nBLOCK_ADDITIONS = 0x75A1\nBLOCK_MORE = 0xA6\nBLOCK_ADD_ID = 0xEE\nBLOCK_ADDITIONAL = 0xA5\nBLOCK_DURATION = 0x9B\nREFERENCE_PRIORITY = 0xFA\nREFERENCE_BLOCK = 0xFB\nCODEC_STATE = 0xA4\nSLICES = 0x8E\nTIME_SLICE = 0xE8\nLACE_NUMBER = 0xCC\nSIMPLE_BLOCK = 0xA3\n\n#Track codes\nTRACKS = 0x1654AE6B\nTRACK_ENTRY = 0xAE\nTRACK_NUMBER = 0xD7\nTRACK_UID = 0x73C5\nTRACK_TYPE = 0x83\nFLAG_ENABLED = 0xB9\nFLAG_DEFAULT = 0x88\nFLAG_FORCED = 0x55AA\nFLAG_LACING = 0x9C\nMIN_CACHE = 0x6DE7\nMAX_CACHE = 0x6DF8\nDEFAULT_DURATION = 0x23E383\nTRACK_TIMECODE_SCALE = 0x23314F\nMAX_BLOCK_ADDITION_ID = 0x55EE\nNAME = 0x536E\nLANGUAGE = 0x22B59C\nCODEC_ID = 0x86\nCODEC_PRIVATE = 0x63A2\nCODEC_NAME = 0x258688\nATTACHMENT_LINK = 0x7446\nCODEC_DECODE_ALL = 0xAA\nTRACK_OVERLAY = 0x6FAB\nTRACK_TRANSLATE = 0x6624\nTRACK_TRANSLATE_EDITION_UID = 0x66FC\nTRACK_TRANSLATE_CODEC = 0x66BF\nTRACK_TRANSLATE_TRACK_ID = 0x66A5\nVIDEO = 0xE0\nFLAG_INTERLACED = 0x9A\nSTEREO_MODE = 0x53B8\nPIXEL_WIDTH = 0xB0\nPIXEL_HEIGHT = 0xBA\nPIXEL_CROP_BOTTOM = 0x54AA\nPIXEL_CROP_TOP = 0x54BB\nPIXEL_CROP_LEFT = 0x54CC\nPIXEL_CROP_RIGHT = 0x54DD\nDISPLAY_WIDTH = 0x54B0\nDISPLAY_HEIGHT = 0x54BA\nDISPLAY_UNIT = 0x54B2\nASPECT_RATIO_TYPE = 0x54B3\nCOLOR_SPACE = 0x2EB524\nFRAME_RATE = 0x2383E3\nAUDIO = 0xE1\nSAMPLING_FREQUENCY = 0xB5\nOUTPUT_SAMPLING_FREQUENCY = 0x78B5\nCHANNELS = 0x9F\nBIT_DEPTH = 0x6264\nCONTENT_ENCODINGS = 0x6D80\nCONTENT_ENCODING = 0x6240\nCONTENT_ENCODING_ORDER = 0x5031\nCONTENT_ENCODING_SCOPE = 0x5032\nCONTENT_ENCODING_TYPE = 0x5033\nCONTENT_COMPRESSION = 0x5034\nCONTENT_COMP_ALGO = 0x4254\nCONTENT_COMP_SETTINGS = 0x4255\nCONTENT_ENCRYPTION = 0x5035\nCONTENT_ENC_ALGO = 0x47E1\nCONTENT_ENC_KEY_ID = 0x47E2\nCONTENT_SIGNATURE = 0x47E3\nCONTENT_SIG_KEY_ID = 0x47E4\nCONTENT_SIG_ALOG = 0x47E5\nCONTENT_SIG_HASH_ALGO = 0x47E6\n\n#Cueing data codes\nCUES = 0x1C53BB6B\nCUE_POINT = 0xBB\nCUE_TIME = 0xB3\nCUE_TRACK_POSITIONS = 0xB7\nCUE_TRACK = 0xF7\nCUE_CLUSTER_POSITION = 0xF1\nCUE_BLOCK_NUMBER = 0x5378\n\nATTACHMENTS = 0x1941A469\nATTACHED_FILE = 0x61A7\nFILE_DESCRIPTION = 0x467E\nFILE_NAME = 0x466E\nFILE_MIME_TYPE = 0x4660\nFILE_DATA = 0x465C\nFILE_UID = 0x46AE\n\nCHAPTERS = 0x1043A770\nEDITION_ENTRY = 0x45B9\nEDITION_UID = 0x45BC\nEDITION_FLAG_HIDDEN = 0x45BD\nEDITION_FLAG_DEFAULT = 0x45DB\nEDITION_FLAG_ORDERED = 0x45DD\nCHAPTER_ATOM = 0xB6\nCHAPTER_UID = 0x73C4\nCHAPTER_TIME_START = 0x91\nCHAPTER_TIME_END = 0x91\nCHAPTER_FLAG_HIDDEN = 0x98\nCHAPTER_FLAG_ENABLED = 0x4598\nCHAPTER_SEGMENT_UID = 0x6E67\nCHAPTER_SEGMENT_EDITION_UID = 0x6EBC\nCHAPTER_PHYSICAL_EQUIV = 0x63C3\nCHAPTER_TRACK = 0x8F\nCHAPTER_TRACK_NUMBER = 0x89\nCHAPTER_DISPLAY = 0x80\nCHAP_STRING = 0x85\nCHAP_LANGUAGE = 0x437C\nCHAP_COUNTRY = 0x437E\nCHAP_PROCESS = 0x6944\nCHAP_PROCESS_CODEC_ID = 0x6955\nCHAP_PROCESS_PRIVATE = 0x450D\nCHAP_PROCESS_COMMAND = 0x6911\nCHAP_PROCESS_TIME = 0x6922\nCHAP_PROCESS_DATA = 0x6933\n\nTAGS = 0x1254C367\nTAG = 0x7373\nTARGETS = 0x63C0\nTARGET_TYPE_VALUE = 0x68CA\nTARGET_TYPE = 0x63CA\n#TRACK_UID = 0x63C5\nEDITION_UID = 0x63C9\nCHAPTER_UID = 0x63C4\nATTACHMENT_UID = 0x63C6\nSIMPLE_TAG = 0x67C8\nTAG_NAME = 0x45A3\nTAG_LANGUAGE = 0x447A\nTAG_DEFAULT = 0x4484\nTAG_STRING = 0x4487\nTAG_BINARY = 0x4485\n\nseek_head_dic = {\n      SEEKHEAD : (\'SeekHead\', LEVEL_1, EBML_SUB_ELEMENT),\n      SEEK : (\'Seek\', LEVEL_1, EBML_SUB_ELEMENT),\n      SEEKID : (\'SeekId\', LEVEL_2, EBML_BINARY),\n      SEEKPOSITION : (\'SeekPosition\', LEVEL_3, EBML_UINTEGER),\n      VOID : (\'Void\', LEVEL_1, EBML_BINARY)\n    }\n\nsegment_info_dic = {\n     SEGMENT_INFO : (\'SegmentInfo\', LEVEL_1, EBML_SUB_ELEMENT),\n     SEGMENTUID : (\'SegmentUID\', LEVEL_2, EBML_BINARY),\n     SEGMENTFILENAME : (\'SegmentFilename\', LEVEL_2, EBML_UTF8),\n     PREVUID : (\'PrevUID\', LEVEL_2, EBML_BINARY),\n     PREVFILENAME : (\'PrevFilename\', LEVEL_2, EBML_UTF8),\n     NEXTUID : (\'NextUID\', LEVEL_2, EBML_BINARY),\n     NEXTFILENAME : (\'NextFilename\', LEVEL_2, EBML_UTF8),\n     SEGMENTFAMILY : (\'SegmentFamily\', LEVEL_2, EBML_BINARY),\n     CHAPTERTRANSLATE : (\'ChapterTranslate\', LEVEL_2, EBML_SUB_ELEMENT),\n     CHAPTERTRANSLATEEDITIONUID : (\'ChapterTranslateEditionUID\', LEVEL_3, EBML_UINTEGER),\n     CHAPTERTRANSLATECODEC : (\'ChapterTranslateCodec\', LEVEL_3, EBML_UINTEGER),\n     CHAPTERTRANSLATEID : (\'ChapterTranslateID\', LEVEL_3, EBML_BINARY),\n     TIMECODESCALE : (\'TimecodeScale\', LEVEL_2, EBML_UINTEGER),\n     DURATION : (\'Duration\', LEVEL_2, EBML_FLOAT),\n     DATEUTC : (\'DateUTC\', LEVEL_2, EBML_DATE),\n     TITLE : (\'Title\', LEVEL_2, EBML_UTF8),\n     MUXINGAPP : (\'MuxingApp\', LEVEL_2, EBML_UTF8),\n     WRITINGAPP : (\'WritingApp\', LEVEL_2, EBML_UTF8)\n    }\n\ntrack_dic = {\n     TRACKS : (\'Track\', LEVEL_1, EBML_SUB_ELEMENT),\n     TRACK_ENTRY : (\'Track Entry\', LEVEL_2, EBML_SUB_ELEMENT),\n     TRACK_NUMBER : (\'Track Number\', LEVEL_3, EBML_UINTEGER),\n     TRACK_UID : (\'Track Uid\', LEVEL_3, EBML_UINTEGER),\n     TRACK_TYPE : (\'Track Type\', LEVEL_3, EBML_UINTEGER),\n     FLAG_ENABLED : (\'Flag Enabled\', LEVEL_3, EBML_UINTEGER),\n     FLAG_DEFAULT : (\'Flag Default\', LEVEL_3, EBML_UINTEGER),\n     FLAG_FORCED :  (\'Flag Forced\', LEVEL_3, EBML_UINTEGER),\n     FLAG_LACING :  (\'Flag Lacing\', LEVEL_3, EBML_UINTEGER),\n     DEFAULT_DURATION : (\'Default Duration\', LEVEL_3, EBML_UINTEGER),\n     NAME: (\'Name\', LEVEL_3, EBML_UTF8),\n     LANGUAGE : (\'Language\', LEVEL_3, EBML_STRING),\n     CODEC_ID : (\'Codec Id\', LEVEL_3, EBML_STRING),\n     CODEC_PRIVATE : (\'Codec Private\', LEVEL_3, EBML_BINARY),\n     CODEC_NAME : (\'Codec Name\', LEVEL_3, EBML_UTF8),\n     VIDEO : (\'Video\', LEVEL_3, EBML_SUB_ELEMENT),\n     FLAG_INTERLACED : (\'Flag Interlaced\', LEVEL_4, EBML_UINTEGER),\n     PIXEL_WIDTH : (\'Pixel Width\', LEVEL_4, EBML_UINTEGER),\n     PIXEL_HEIGHT : (\'Pixel Height\', LEVEL_4, EBML_UINTEGER),\n     PIXEL_CROP_BOTTOM : (\'Pixel Crop Bottom\', LEVEL_4, EBML_UINTEGER),\n     PIXEL_CROP_TOP : (\'Pixel Crop Top\', LEVEL_4, EBML_UINTEGER),\n     PIXEL_CROP_LEFT : (\'Pixel Crop Left\', LEVEL_4, EBML_UINTEGER),\n     PIXEL_CROP_RIGHT : (\'Pixel Crop Right\', LEVEL_4, EBML_UINTEGER),\n     DISPLAY_WIDTH : (\'Display Width\', LEVEL_4, EBML_UINTEGER),\n     DISPLAY_HEIGHT : (\'Display Height\', LEVEL_4, EBML_UINTEGER),\n     DISPLAY_UNIT : (\'Display Unit\', LEVEL_4, EBML_UINTEGER),\n     STEREO_MODE : (\'Stereo Mode\', LEVEL_4, EBML_UINTEGER),\n     ASPECT_RATIO_TYPE : (\'Aspect Ratio Type\', LEVEL_4, EBML_UINTEGER),\n     FRAME_RATE : (\'Frame Rate\', LEVEL_4, EBML_FLOAT),\n     AUDIO : (\'Audio\', LEVEL_3, EBML_SUB_ELEMENT),\n     SAMPLING_FREQUENCY : (\'Sampling Frequency\', LEVEL_4, EBML_FLOAT),\n     OUTPUT_SAMPLING_FREQUENCY : (\'Output sampling Frequency\', LEVEL_4,\n                                  EBML_FLOAT),\n     CHANNELS : (\'Channels\', LEVEL_4, EBML_UINTEGER),\n     BIT_DEPTH : (\'Bit Depth\', LEVEL_4, EBML_UINTEGER),\n     VOID : (\'Void\', LEVEL_1, EBML_BINARY)\n     #not valid webm from here\n     #TRACK_TIMECODE_SCALE : (\'Track Timecode Scale\', LEVEL_3, EBML_FLOAT)\n     #MIN_CACHE : (\'Min Cache\', LEVEL_3, EBML_UINTEGER)\n  }\n\ncue_dic = {\n      CUES : (\'Cues\', LEVEL_1, EBML_SUB_ELEMENT),\n      CUE_POINT : (\'Cue Point\', LEVEL_2, EBML_SUB_ELEMENT),\n      CUE_TIME : (\'Cue Time\', LEVEL_3, EBML_UINTEGER),\n      CUE_TRACK_POSITIONS : (\'Cue Track Positions\', LEVEL_3, EBML_SUB_ELEMENT),\n      CUE_TRACK : (\'Cue Track\', LEVEL_4, EBML_UINTEGER),\n      CUE_CLUSTER_POSITION : (\'Cue Cluster Position\', LEVEL_4, EBML_UINTEGER),\n      CUE_BLOCK_NUMBER : (\'Cue Block Number\', LEVEL_4, EBML_UINTEGER)\n   }\n\ncluster_dic = {\n      CLUSTER : (\'Cluster\', LEVEL_1, EBML_SUB_ELEMENT),\n      TIMECODE : (\'TimeCode\', LEVEL_2, EBML_UINTEGER),\n      SILENT_TRACKS : (\'SilentTracks\', LEVEL_2, EBML_SUB_ELEMENT),\n      SILENT_TRACK_NUMBER : (\'SilentTrackNumber\', LEVEL_3, EBML_UINTEGER),\n      POSITION : (\'Position\', LEVEL_2, EBML_UINTEGER),\n      PREVSIZE : (\'PrevSize\', LEVEL_2, EBML_UINTEGER),\n      BLOCK_GROUP : (\'BlockGroup\', LEVEL_2, EBML_SUB_ELEMENT),\n      BLOCK : (\'Block\', LEVEL_3, EBML_BINARY),\n      BLOCK_ADDITIONS : (\'BlockAdditions\', LEVEL_3, EBML_SUB_ELEMENT),\n      BLOCK_MORE : (\'BlockMore\', LEVEL_4, EBML_SUB_ELEMENT),\n      BLOCK_ADD_ID : (\'BlockAddId\', LEVEL_5, EBML_UINTEGER),\n      BLOCK_ADDITIONAL : (\'BlockAdditional\', LEVEL_5, EBML_BINARY),\n      BLOCK_DURATION : (\'BlockDuration\', LEVEL_3, EBML_UINTEGER),\n      REFERENCE_PRIORITY : (\'ReferencePriority\', LEVEL_3, EBML_UINTEGER),\n      REFERENCE_BLOCK : (\'ReferenceBlock\', LEVEL_3, EBML_UINTEGER),\n      CODEC_STATE : (\'CodecState\', LEVEL_3, EBML_BINARY),\n      SLICES : (\'Slices\', LEVEL_3, EBML_SUB_ELEMENT),\n      TIME_SLICE : (\'TimeSlice\', LEVEL_4, EBML_SUB_ELEMENT),\n      LACE_NUMBER : (\'LaceNumber\', LEVEL_5, EBML_UINTEGER),\n      SIMPLE_BLOCK : (\'SimpleBlock\', LEVEL_2, EBML_BINARY)\n    }\n\ndic_element = { SEEKHEAD : seek_head_dic, SEGMENT_INFO : segment_info_dic, TRACKS : track_dic,\n               CUES : cue_dic, CLUSTER : cluster_dic }\n'"
tests/webminspector/webm.py,0,"b'##\n##  Copyright (c) 2010 The WebM project authors. All Rights Reserved.\n##\n##  Use of this source code is governed by a BSD-style license\n##  that can be found in the LICENSE file in the root of the source\n##  tree. An additional intellectual property rights grant can be found\n##  in the file PATENTS.  All contributing project authors may\n##  be found in the AUTHORS file in the root of the source tree.\n##\n\n__author__ = \'hwasoolee@google.com (Hwasoo Lee)\'\n\nimport sys\nimport struct\nfrom ebml_header import *\n\ndef GetVersion():\n  """"""Return this module version\n  """"""\n  return \'v0.9.3\'\n\ndef BitSet(x, n):\n  """"""Return whether nth bit of x was set""""""\n  return bool(x[0] & (1 << n))\n\ndef ConvertStrNumber(input):\n  size = len(input)\n  index = 0\n  value = 0\n  total = 0\n  while size != index:\n    value = eval(str(input[index])) << (8*(size-(index+1)))\n    total = value + total\n    index += 1\n\n  return total\n\ndef InterpretLittleEndian(data, i):\n  temp_data = 0\n  while (i):\n    temp_data += data[i-1] << 8 * (i - 1)\n    i -= 1\n\n  return temp_data\n\ndef CalculatePacketBlockSize(data):\n  block_size_0 = data & 0x0F\n  block_size_1 = data & 0xF0\n  block_size_1 = block_size_1 >> 4\n  return block_size_0, block_size_1\n\ndef ReadOneByteForElementIdSize(file_, pos):\n  file_.seek(pos)\n  ch = file_.read(1)\n  pre_id = struct.unpack(\'>B\', ch)\n  pos = file_.tell()\n  pos = pos - 1\n\n  if (pre_id[0] & 0x80):   # 1000 0000\n    size_to_read = 1\n  elif (pre_id[0] & 0x40): # 0100 0000\n    size_to_read = 2\n  elif (pre_id[0] & 0x20): # 0010 0000\n    size_to_read = 3\n  elif (pre_id[0] & 0x10): # 0001 0000\n    size_to_read = 4\n  else:\n    assert 0, \'ReadOneByteForElementIdSize Error\'\n\n  return size_to_read, pos\n\ndef ReadOneByteForDataSize(file_, pos):\n  """"""\n  This is to read data size field which is the second field followed by Element\n  Id field. Do not confuse with Data field itself.\n  """"""\n  file_.seek(pos)\n  ch = file_.read(1)\n  pre_data = struct.unpack(\'>B\', ch)\n  pos = file_.tell()\n  pos = pos - 1\n\n  if   (pre_data[0] & 0x80): #\n    data_size = 1\n  elif (pre_data[0] & 0x40): #\n    data_size = 2\n  elif (pre_data[0] & 0x20): #\n    data_size = 3\n  elif (pre_data[0] & 0x10): #\n    data_size = 4\n  elif (pre_data[0] & 0x08): #\n    data_size = 5\n  elif (pre_data[0] & 0x04): #\n    data_size = 6\n  elif (pre_data[0] & 0x02): #\n    data_size = 7\n  elif (pre_data[0] & 0x01): #\n    data_size = 8\n  else:\n    data_size = 0\n\n  assert data_size  > 0\n  return data_size, pos\n\ndef ReadClassId(file_, pos, bytes, unpack_mode):\n  file_.seek(pos)\n  data = file_.read(bytes)\n  pos = file_.tell()\n  class_id = struct.unpack(unpack_mode, data)\n  format = \'hex(class_id[%s])+\'\n  format = format*bytes\n  length = format % tuple(range(0,bytes))\n  length = length[:-1]\n  classid = eval(length)\n  classid = classid[2:].replace(\'0x\',\'\')\n  return classid, pos\n\ndef ProcessIdSize(file_, pos, size):\n  id_size, pos = ReadClassId(file_, pos, size, \'>%dB\' % size)\n  return id_size, pos\n\ndef ReadDataSize(file_, pos, bytes_read, unpack_mode):\n  file_.seek(pos)\n  data = file_.read(bytes_read)\n\n  pos = file_.tell()\n  data_size = struct.unpack(unpack_mode, data)\n\n  if   (data_size[0] & 0x80):\n    data_size_0 = data_size[0] & 0x7F\n  elif (data_size[0] & 0x40): #\n    data_size_0 = data_size[0] & 0x3F\n  elif (data_size[0] & 0x20): #\n    data_size_0 = data_size[0] & 0x1F\n  elif (data_size[0] & 0x10): #\n    data_size_0 = data_size[0] & 0x08\n  elif (data_size[0] & 0x08): #\n    data_size_0 = data_size[0] & 0x07\n  elif (data_size[0] & 0x04): #\n    data_size_0 = data_size[0] & 0x03\n  elif (data_size[0] & 0x02): #\n    data_size_0 = data_size[0] & 0x01\n  else: #\n    data_size_0 = 0 # TODO: research in which case this statement is executed.\n\n  len_  = len(data_size)\n  #print \'data_size %s\' % data_size\n  total_data_size = 0\n  if bytes_read == 1:\n    total_data_size = data_size_0\n  else:\n    index = 1\n    value = 0\n    total_data_size = data_size_0 << (8 * (len_ - 1))\n    while len_ != index:\n      value = eval(str(data_size[index])) << (8 * (len_ - (index + 1)))\n      total_data_size = value + total_data_size\n      index = index + 1\n\n  return total_data_size, pos\n\ndef ProcessDataSize(file_, pos, data_size_length):\n  data_size, pos = ReadDataSize(file_, pos, data_size_length, \'>%dB\' % data_size_length)\n  return data_size, pos\n\ndef ProcessData(file_, pos, data_size, option):\n  file_.seek(pos)\n  data = file_.read(data_size)\n  pos = file_.tell()\n\n  if option == EBML_FLOAT: # u-integer\n    if len(data) == 4:\n      data_ = struct.unpack(\'>f\', data)\n    if len(data) == 8:\n      data_ = struct.unpack(\'>d\', data)\n  elif option == EBML_UINTEGER: # u-integer\n    data_ = struct.unpack(\'>%dB\' % data_size, data)\n  elif option == EBML_STRING or option == EBML_UTF8:   # string\n    data_ = struct.unpack(\'>%ds\' % data_size, data)\n  elif option == EBML_BINARY:   # binary\n    data_ = struct.unpack(\'>%dB\' % data_size, data)\n  elif option == EBML_DATE:   # date\n    data_ = struct.unpack(\'>%dB\' % data_size, data)\n  else:\n    assert 0, \'Data Handling Error\'\n    exit(1)\n\n  return data_, pos\n\ndef HandleData(self, dic, Process, file_, pos, ebml_head_flag = False):\n  start_pos = pos\n  size, pos = ReadOneByteForElementIdSize(file_, pos)\n  element_id, pos = ProcessIdSize(file_, pos, size)\n # TODO(hwasoo): need to check element id\n\n  data_size_length, pos = ReadOneByteForDataSize(file_, pos)\n  assert data_size_length > 0\n\n  data_size, pos = ProcessDataSize(file_, pos, data_size_length)\n\n  if int(element_id, 16)  in dic.keys():\n    if dic[int(element_id, 16)][2] == EBML_SUB_ELEMENT:\n      self._total_size_to_read = data_size + pos\n      if ebml_head_flag == False:\n        print \'\\t\\t\' + str(dic[int(element_id, 16)][0])\\\n            + \' (head size: \' + repr(size + data_size_length)\\\n            + \' bytes, data: \' + repr(data_size) +\' bytes, pos: \'\\\n            + repr(start_pos) + \', \' + repr(hex(start_pos)) + \')\'\n    else:\n      data_, pos = ProcessData(file_, pos, data_size, dic[int(element_id, 16)][2])\n      if len(data_) != 1:\n        data_value = ConvertStrNumber(data_)\n        if data_value == SEGMENT_INFO:\n          output = \'SegmentInfo\'\n        elif data_value == TRACKS:\n          output = \'Tracks\'\n        elif data_value == CUES:\n          output = \'Cues\'\n        elif data_value == SEEKHEAD:\n          output = \'SeekHead\'\n        elif data_value == CLUSTER:\n          output = \'cluster\'\n        else:\n          output = data_value\n      else:\n        output = data_[0]\n\n      if ebml_head_flag == False:\n        print \'\\t\\t\\t\' + str(dic[int(element_id, 16)][0]) \\\n            + \' (head size: \' + repr(size + data_size_length) \\\n            + \' bytes, data: \' + repr(data_size) +\' bytes, pos: \'\\\n            + repr(start_pos) +  \', \' + repr(hex(start_pos)) +  \') : \' + repr(output)\n\n      if self._total_size_to_read <= pos:\n        self._file_pos = pos\n        return\n\n  Process(file_, pos, ebml_head_flag)\n\ndef RenderElement(self, file_, element_id):\n  for eid in self._elements:\n    if int(eid[0], 16) == element_id:\n      print \'Found %s\' % element_id\n    else:\n      print \'Not Found\'\n\ndef CalculatePacketSize(data, i):\n  loop = 0\n\n  while (data[i] == 255):\n    i +=  1\n    loop +=  1\n\n  return 255 * loop + data[i], (lambda  x: x + 1)(i)\n\n\ndef DisplayVP8Data(data):\n  # for now we just handle simple block with no lacing data case\n  keyframe = BitSet(data[4:5], 0)\n  version = data[4] & 0x0E\n  showframe = BitSet(data[4:5], 4)\n\n  first_data_partition = InterpretLittleEndian(data[4:7], 3) >> 5\n\n  if keyframe == False:\n    k_o = \'Yes\'\n  else:\n    k_o = \'No\'\n\n  if showframe == True:\n    s_o = \'Yes\'\n  else:\n    s_o = \'No\'\n\n  output = \'[VP8] key: %s, ver: %d, sf: %s, pl: %d\' % \\\n     (k_o, version, s_o, first_data_partition)\n\n  return output\n\n\ndef DisplayCodecPrivateData(data, total):\n  print \'\\t\\t\\t\\tNumber of packets : %d\' % (data[0] + 1)\n\n  size_1, i = CalculatePacketSize(data, 1)\n  print \'\\t\\t\\t\\tFirst packet size : %d byte(s)\' % size_1\n\n  size_2, i = CalculatePacketSize(data, i)\n  print \'\\t\\t\\t\\tSecond packet size : %d byte(s)\' % size_2\n\n  print \'\\t\\t\\t\\tThird packet size : %d bytes(s)\' % (total - i - size_1 - size_2)\n\n  if (data[i] == 1):\n    print \'\\t\\t\\t\\t   [Identification Header]\'\n    if (data[i+1] == 118) & \\\n       (data[i+2] == 111) & \\\n       (data[i+3] == 114) & \\\n       (data[i+4] ==  98) & \\\n       (data[i+5] == 105) & \\\n       (data[i+6] == 115):\n      print \'\\t\\t\\t\\t\\tvorbis\'\n    else:\n      print \'\\t\\t\\t\\t\\tnot valid to vorbis\'\n    i += 6 #skip to vorbis version location\n\n    if (data[i+1] == 0) & \\\n       (data[i+2] == 0) & \\\n       (data[i+3] == 0) & \\\n       (data[i+4] == 0):\n      print \'\\t\\t\\t\\t\\tVorbis version : 0\'\n    else:\n      print \'\\t\\t\\t\\t\\tVorbis version : non-0\'\n    i += 4\n\n    #audio channel\n    print \'\\t\\t\\t\\t\\tAudio channel : %d \' % data[i+1]\n    i += 1\n\n    sampling_rate = [data[i+1], data[i+2], data[i+3], data[i+4]]\n    print \'\\t\\t\\t\\t\\tSampling rate : %d \' % InterpretLittleEndian(sampling_rate, 4)\n    i += 4\n\n    bitrate_maximum = [data[i+1], data[i+2], data[i+3], data[i+4]]\n    print \'\\t\\t\\t\\t\\tBitrate maximum : %d \' % InterpretLittleEndian(bitrate_maximum, 4)\n    i += 4\n    bitrate_nominal = [data[i+1], data[i+2], data[i+3], data[i+4]]\n    print \'\\t\\t\\t\\t\\tBitrate nominal : %d \' % InterpretLittleEndian(bitrate_nominal, 4)\n    i += 4\n    bitrate_minimum = [data[i+1], data[i+2], data[i+3], data[i+4]]\n    print \'\\t\\t\\t\\t\\tBitrate minimum : %d \' % InterpretLittleEndian(bitrate_minimum, 4)\n    i += 4\n\n    block_size_0, block_size_1 = CalculatePacketBlockSize(data[i+1])\n    print \'\\t\\t\\t\\t\\tBlock Size 0 : %d \' %  (1 << block_size_0)\n    print \'\\t\\t\\t\\t\\tBlock Size 1 : %d \' %  (1 << block_size_1)\n    i += 1\n\n    print \'\\t\\t\\t\\t\\tFraming Flag : %d\' % bool(data[i+1])\n    i += 1\n\n  i += 1\n  if (data[i] == 3):\n    print \'\\t\\t\\t\\t   [Comment Header]\'\n    if (data[i+1] == 118) & \\\n       (data[i+2] == 111) & \\\n       (data[i+3] == 114) & \\\n       (data[i+4] ==  98) & \\\n       (data[i+5] == 105) & \\\n       (data[i+6] == 115):\n      print \'\\t\\t\\t\\t\\tvorbis\'\n    else:\n      print \'\\t\\t\\t\\t\\tnot valid to vorbis\'\n    i += 6 #skip to vorbis version location\n\n    vendor_length = [data[i+1], data[i+2], data[i+3], data[i+4]]\n    v_l =  InterpretLittleEndian(vendor_length, 4)\n    print \'\\t\\t\\t\\t\\tVendor Length : %d \' % v_l\n    i += 4\n\n    i += 1\n    vendor_string = data[i:i+v_l]\n    print \'\\t\\t\\t\\t\\tVendor string : \' + \'\'.join(map(chr, vendor_string))\n\n    i += v_l\n    ucll = [data[i], data[i+1], data[i+2], data[i+3]]\n    user_comment_list_length = InterpretLittleEndian(ucll, 4)\n\n    i += 4\n    while user_comment_list_length > 0:\n      temp = [data[i], data[i+1], data[i+2], data[i+3]]\n      temp_num = InterpretLittleEndian(temp, 4)\n      i += 4\n      user_comment = data[i:i+temp_num]\n      print \'\\t\\t\\t\\t\\tComment : \'\n      print \'\\t\\t\\t\\t\\t\\t \'+\'\'.join(map(chr, user_comment))\n      i += temp_num\n      user_comment_list_length -= 1\n\n    print \'\\t\\t\\t\\t\\tFraming Flag : %d\' % bool(data[i+1])\n    i += 1\n\n  return\n\n  #TODO: Codec setup header\n  #This task is comprehensive and nontrivial since the knowledge of Vorbis\n  #specification is needed.\n  if (data[i] == 5):\n    print \'\\t\\t\\t\\t   [Setup Header]\'\n    if (data[i+1] == 118) & \\\n       (data[i+2] == 111) & \\\n       (data[i+3] == 114) & \\\n       (data[i+4] ==  98) & \\\n       (data[i+5] == 105) & \\\n       (data[i+6] == 115):\n      print \'\\t\\t\\t\\t\\tvorbis\'\n    else:\n      print \'\\t\\t\\t\\t\\tnot valid to vorbis\'\n    i += 6 #skip to vorbis version location\n\n    i += 1\n    vorbis_codebook_count = data[i] + 1\n    print \'\\t\\t\\t\\t\\tvorbis_codebook_count : %d\' % vorbis_codebook_count\n    if (data[i+1] == 66) & \\\n       (data[i+2] == 67) & \\\n       (data[i+3] == 86):\n      print \'\\t\\t\\t\\t\\tcodebook begin : 0x564342\'\n    else:\n      print \'\\t\\t\\t\\t\\tnot valid codebook begins\'\n\n    i += 3\n\n    i += 1\n    codebook_dimensions = InterpretLittleEndian(data[i:i+2], 2)\n    print \'\\t\\t\\t\\t\\tcodebook_dimensions : %d\' % codebook_dimensions\n\n    i += 2\n\n    codebook_entries = InterpretLittleEndian(data[i:i+3], 3)\n    print \'\\t\\t\\t\\t\\tcodebook_entries : %d \' % codebook_entries\n\n    i += 3\n\n    ordered_bit_flag = BitSet(data[i:i+1], 0)\n\n    print \'\\t\\t\\t\\t\\torder bit flag : %d\' % ordered_bit_flag\n    if ordered_bit_flag:\n      corrent_entry = 0\n      current_length = data[i:i+1] & 0x7C # 0111 1100\n      print current_lenth\n    else:\n      sparse_bit_flag = BitSet(data[i:i+1], 1)\n      print \'\\t\\t\\t\\t\\tSparse bit flag : %d\' % sparse_bit_flag\n\n      if sparse_bit_flag:\n        flag = BitSet(data[i:i+1], 2)\n      else:\n        length = InterpretLittleEndian(data[i:i+1], 1)\n        length = length & 0x7C # 0111 1100\n\n        print \'\\t\\t\\t\\t\\tlength : %d \' % ((length >> 2) + 1)\n\nclass webmFile:\n  def __init__(self, filename):\n    try:\n      self._file = open(filename,\'rb\')\n    except IOError:\n      print \' No such file or directory : %s\' % filename\n      self._file = None\n\n  def GetFile(self):\n    return self._file\n\nclass Ebml:\n  def __init__(self):\n    self._ebml_data =    {\n      EBML : (\'EBML\', LEVEL_0, EBML_SUB_ELEMENT),\n      EBML_VERSION  : (\'EBMLVersion\', LEVEL_1, EBML_UINTEGER),\n      EBML_READ_VERSION : (\'EBMLReadVersion\', LEVEL_1, EBML_UINTEGER),\n      EBML_MAX_ID_LENGTH : (\'EBMLMaxIDLength\', LEVEL_1, EBML_UINTEGER),\n      EBML_MAX_SIZE_LENGTH : (\'EBMLMaxSizeLength\', LEVEL_1, EBML_UINTEGER),\n      EBML_DOC_TYPE : (\'DocType\', LEVEL_1, EBML_STRING),\n      EBML_DOC_TYPE_VERSION : (\'DocTypeVersion\', LEVEL_1, EBML_UINTEGER),\n      EBML_DOC_TYPE_READ_VERSION : (\'DocTypeReadVersion\', LEVEL_1, EBML_UINTEGER),\n      VOID : (\'Void\', LEVEL_1, EBML_BINARY)\n    }\n    self._total_size_to_read = 0\n    self._file_pos = 0\n\n  def ProcessEbml(self, file_, pos = 0, ebml_head_flag = False):\n    HandleData(self, self._ebml_data, self.ProcessEbml, file_, pos,\n               ebml_head_flag)\n    #    #TODO:\n    #    # When trying to return pos value, it turns to None with some reason.\n    #    # I do not know why. So I make the GetFilePosition()\n    #    # Got to spend time to understand this.\n\n  def GetFilePosition(self):\n    return self._file_pos\n\nclass Segment:\n  def __init__(self):\n    self._segment_data  = {\n      CRC_32 : (\'Crc-32\', LEVEL_1, EBML_BINARY),\n      VOID : (\'Void\', LEVEL_1, EBML_BINARY),\n      SEGMENT : (\'Segment\', LEVEL_0, EBML_SUB_ELEMENT),\n      SEEKHEAD : (\'SeekHead\', LEVEL_1, EBML_SUB_ELEMENT),\n      SEEK : (\'Seek\', LEVEL_2, EBML_SUB_ELEMENT),\n      SEEKID : (\'SeekID\', LEVEL_3, EBML_BINARY),\n      SEEKPOSITION : (\'SeekPosition\', LEVEL_3, EBML_UINTEGER),\n      SEGMENT_INFO : (\'SegmentInfo\', LEVEL_1, EBML_SUB_ELEMENT),\n      CLUSTER : (\'Cluster\', LEVEL_1, EBML_SUB_ELEMENT),\n      TRACKS : (\'Tracks\', LEVEL_1, EBML_SUB_ELEMENT),\n      VIDEO : (\'Video\', LEVEL_3, EBML_SUB_ELEMENT),\n      AUDIO : (\'Audio\', LEVEL_3, EBML_SUB_ELEMENT),\n      CUES : (\'Cues\', LEVEL_1, EBML_SUB_ELEMENT),\n      ATTACHMENTS : (\'Attachments\', LEVEL_1, EBML_SUB_ELEMENT),\n      CHAPTERS : (\'Chapters\', LEVEL_1, EBML_SUB_ELEMENT),\n      TAGS : (\'Tags\', LEVEL_1, EBML_SUB_ELEMENT)\n    }\n    self._total_size_to_read = 0\n    self._seeks = []\n    self._elements = []\n    self._total_size_for_segment = 0\n    self._start_pos = 0\n    self._track_number_type = [-1, -1, -1, -1]\n    self._flag_track_done = False\n\n  """"""\n  Search Ebml element head in a segment\n  """"""\n  def Find(self, file_, Id):\n    loop = 0\n    while len(self._seeks) != 0:\n      s = self._seeks[loop]\n      pos = s.pos_\n      size, pos = ReadOneByteForElementIdSize(file_, pos)\n      element_id, pos = ProcessIdSize(file_, pos, size)\n      data_size_length, pos = ReadOneByteForDataSize(file_, pos)\n      assert data_size_length > 0\n\n      data_size, pos = ProcessDataSize(file_, pos, data_size_length)\n      data_, pos = ProcessData(file_, pos, data_size, EBML_UINTEGER)\n      number = ConvertStrNumber(data_)\n\n      if number == Id:\n        size, pos = ReadOneByteForElementIdSize(file_, pos)\n        element_id, pos = ProcessIdSize(file_, pos, size)\n        data_size_length, pos = ReadOneByteForDataSize(file_, pos)\n        assert data_size_length > 0\n        data_size, pos = ProcessDataSize(file_, pos, data_size_length)\n        data_, pos = ProcessData(file_, pos, data_size, EBML_UINTEGER)\n        total = ConvertStrNumber(data_)\n        return total + self._seekhead_pos\n\n      loop =  loop + 1\n      if len(self._seeks) == loop:\n        return -1\n\n  def GetSeekHeadPos(self):\n    return self._seekhead_pos\n\n  def GetSeekHeadSize(self):\n    return self._seekhead_size\n\n  def GetSeekElement(self):\n    return self._seeks\n\n  def GetTotalSizeSegment(self):\n    return self._total_size_for_segment\n\n  def SetTotalSizeSegment(self, size):\n    self._total_size_for_segment = size\n\n  def SearchLevelOneElements(self, file_, pos):\n    """"""\n    Search Level One Ebml Elements and put in a list\n    """"""\n    if pos > self._total_size_for_segment and self._total_size_for_segment != 0:\n      return\n\n    size, start_pos = ReadOneByteForElementIdSize(file_, pos)\n    element_id, pos = ProcessIdSize(file_, start_pos, size)\n\n    if pos > self._total_size_for_segment and self._total_size_for_segment != 0:\n      return\n\n    data_size_length, pos = ReadOneByteForDataSize(file_, pos)\n    assert data_size_length > 0\n\n    if pos > self._total_size_for_segment and self._total_size_for_segment != 0:\n      return\n\n    data_size, pos = ProcessDataSize(file_, pos, data_size_length)\n\n    if pos > self._total_size_for_segment and self._total_size_for_segment != 0:\n      return\n\n    if int(element_id, 16)  ==  SEGMENT:\n      self._total_size_for_segment = data_size\n    elif int(element_id, 16) in self._segment_data.keys():\n      head_size = size + data_size_length\n      #make them tuple\n      item = (element_id, start_pos, data_size, head_size)\n      #add a tuple data in the list\n      self._elements.append(item)\n      #self._elements.append(start_pos)\n    else:\n      assert False\n\n    if pos <= self._total_size_for_segment:\n      if int(element_id, 16) == SEGMENT:\n        self.SearchLevelOneElements(file_, pos)\n      else:\n        next_pos = data_size + start_pos + size + data_size_length\n        return next_pos\n        #self.SearchLevelOneElements(file_, next_pos)\n\n  def ProcessSegment(self, file_, pos):\n    HandleData(self, self._segment_data, self.ProcessSegment, file_, pos)\n\n  #to know how many Seeks are there in Seekhead\n  def EnumerateElement(self, file_, size_, pos):\n    stop = size_ + pos\n\n    while stop >= pos:\n      size, pos = ReadOneByteForElementIdSize(file_, pos)\n      element_id, pos = ProcessIdSize(file_, pos, size)\n      data_size_length, pos = ReadOneByteForDataSize(file_, pos)\n      assert data_size_length > 0\n\n      data_size, pos = ProcessDataSize(file_, pos, data_size_length)\n      if int(element_id, 16)  == SEEK: #0x4DBB\n        s = Seek(pos, data_size)\n        self._seeks.append(s)\n        pos = pos + data_size\n\n      #if id  == TRACK_ENTRY: #0xAE\n      #  s = Seek(pos, data_size)\n      #  self._seeks.append(s)\n      #  pos = pos + data_size\n\n      if id == VIDEO:\n        print ""Video""\n\n      if id == AUDIO:\n        print ""Audio""\n\n  def ProcessElement(self, file_, element_id_, index):\n    i = 0\n    time_code_absolute = 0\n    loop = 0\n\n    for eid in self._elements:\n      if int(eid[0], 16) == element_id_:\n        if i == index:\n          stop = eid[1] + eid[2] + eid[3]\n          start_pos = pos = eid[1]\n          flag_sub_element = False\n\n          while stop >= pos:\n            size, pos = ReadOneByteForElementIdSize(file_, pos)\n            pos_sub_element = pos\n            element_id, pos = ProcessIdSize(file_, pos, size)\n\n            data_size_length, pos = ReadOneByteForDataSize(file_, pos)\n            assert data_size_length > 0\n\n            data_size, pos = ProcessDataSize(file_, pos, data_size_length)\n            pos_binary = pos # saving for Cluster\n\n            for dic_ in dic_element:\n              if dic_ == element_id_:\n                handle_dic = dic_element[dic_]\n\n            if int(element_id, 16) in handle_dic.keys():\n              if handle_dic[int(element_id, 16)][2] == EBML_SUB_ELEMENT:\n                self._total_size_to_read = data_size + pos\n                if flag_sub_element == True:\n                  pos_display = pos_sub_element\n                else:\n                  pos_display = start_pos\n\n                print \'\\t\\t\' + str(handle_dic[int(element_id, 16)][0])\\\n                    + \' (head size: \' + repr(size + data_size_length)\\\n                    + \' bytes, data: \' + repr(data_size) +\' bytes, pos: \'\\\n                    + repr(pos_display) + \', \' + repr(hex(pos_display)) + \')\'\n                flag_sub_element = True\n              else:\n                flag_sub_element = False\n                data_, pos = ProcessData(file_, pos, data_size, handle_dic[int(element_id, 16)][2])\n                flag_simple_block = False\n                key_frame = False\n                lacing = \'no lacing\'\n                invisible = \'no\'\n                discardable = \'no\'\n\n                flag_codec_private = False;\n\n                if handle_dic[int(element_id, 16)][2] == EBML_BINARY:\n                  if SIMPLE_BLOCK in handle_dic:\n                    track_number, pos_temp = ProcessDataSize(file_, pos_binary, 1)\n                    time_code, pos_temp = ProcessData(file_, pos_temp, 2,\n                                                      EBML_UINTEGER)\n                    time_offset = (time_code[0] << 8) + time_code[1]\n\n                    #Block header - offset+3\n                    file_.seek(pos_temp)\n                    lacing_data = file_.read(1)\n                    offset_three_data = struct.unpack(\'>B\', lacing_data)\n                    #print \'BitSet Test : \' + repr(BitSet(offset_three_data, 7))\n                    key_frame = BitSet(offset_three_data, 7)\n\n                    if BitSet(offset_three_data, 4):\n                      invisible = \'yes\'\n\n                    if BitSet(offset_three_data, 0):\n                      discardable = \'yes\'\n\n                    flag_lacing = offset_three_data[0] & 0x6\n                    if flag_lacing == 0x2:\n                      lacing = \'Xiph lacing\'\n                    elif flag_lacing == 0x4:\n                      lacing = \'fixed-size lacing\'\n                    elif flag_lacing == 0x6:\n                      lacing = \'EBML lacing\'\n                    else:\n                      lacing = \'no lacing\'\n\n                    flag_simple_block = True\n\n                    if self._flag_track_done and (self._track_number_type[0] ==\\\n                       self._track_number_type[1]) and (track_number == 1):\n                      output = DisplayVP8Data(data_)\n                    else:\n                      output = \'binary\'\n\n                    #output = data_\n                  elif CODEC_PRIVATE == int(element_id, 16):\n                    #output = \'Codec Private\'\n                    output = data_\n                    flag_codec_private = True\n                    #DisplayCodecPrivateData(data_)\n                  elif VOID == int(element_id, 16):\n                    output = \'Void\'\n                  else:\n                    data_value = ConvertStrNumber(data_)\n                    if data_value == SEGMENT_INFO:\n                      output = \'SegmentInfo\'\n                    elif data_value == TRACKS:\n                      output = \'Tracks\'\n                    elif data_value == CUES:\n                      output = \'Cues\'\n                    elif data_value == SEEKHEAD:\n                      output = \'SeekHead\'\n                    elif data_value == CLUSTER:\n                      output = \'Cluster\'\n                    else:\n                      output = data_value\n                elif len(data_) != 1:\n                  data_value = ConvertStrNumber(data_)\n                  output = data_value\n                  if TIMECODE in handle_dic:\n                    time_code_absolute = output\n                else:\n                  output = data_[0]\n\n                if flag_codec_private:\n                  print \'\\t\\t\\t\' + str(handle_dic[int(element_id, 16)][0]) \\\n                     + \' (head size: \' + repr(size + data_size_length) \\\n                     + \' bytes, data: \' + repr(data_size) +\' bytes, pos: \'\\\n                     + repr(pos_sub_element) +  \', \'\\\n                     + repr(hex(pos_sub_element)) +  \') : \'\n                  print \'\\t\\t\\t\' + repr(DisplayCodecPrivateData(output, data_size))\n                else:\n                  if int(element_id, 16) == TRACK_TYPE:\n                    self._track_number_type[loop] = output\n                    loop += 1\n\n                  if int(element_id, 16) == TRACK_NUMBER:\n                    self._track_number_type[loop] = output\n                    loop += 1\n\n                  if loop == 4:\n                    self._flag_track_done = True\n                    loop = 0\n\n                  print \'\\t\\t\\t\' + str(handle_dic[int(element_id, 16)][0]) \\\n                     + \' (head size: \' + repr(size + data_size_length) \\\n                     + \' bytes, data: \' + repr(data_size) +\' bytes, pos: \'\\\n                     + repr(pos_sub_element) +  \', \' +\\\n                     repr(hex(pos_sub_element)) +  \') : \' + repr(output)\n\n                if flag_simple_block == True:\n                  print \'\\t\\t\\t  \' + \'track number : \' + repr(track_number) \\\n                                   + \', keyframe : \' + repr(key_frame) \\\n                                   + \', invisible : \' + repr(invisible) \\\n                                   + \', discardable : \' + repr(discardable)\n                  print \'\\t\\t\\t  lace : \' + repr(lacing) \\\n                                   + \', time code : \' + repr(time_offset) \\\n                                   + \', time code(absolute) : \' \\\n                                   + repr(time_offset + time_code_absolute)\n\n                if stop <= pos:\n                  self._file_pos = pos\n                  return\n            else:\n              print \'\\n\\t\\t>>>Seems invalid WebM file format<<<\'\n              print \'\\t\\t at element code [%s]\' % element_id \n              exit(1)\n        else:\n          i = i + 1\n\nclass SeekHead:\n  def __init__(self):\n    self._seek_head = {\n      SEEKHEAD : (\'SeekHead\', LEVEL_1, EBML_SUB_ELEMENT),\n      SEEK : (\'Seek\', LEVEL_1, EBML_SUB_ELEMENT),\n      SEEKID : (\'SeekId\', LEVEL_2, EBML_BINARY),\n      SEEKPOSITION : (\'SeekPosition\', LEVEL_3, EBML_UINTEGER)\n    }\n\n  def ProcessSeekHead(self, file_, pos):\n    HandleData(self, self._seek_head, self.ProcessSeekHead, file_, pos)\n\nclass Seek:\n  def __init__(self, pos, stop):\n    self._seek = {\n      SEEKID : (\'SeekId\', LEVEL_2, EBML_BINARY),\n      SEEKPOSITION : (\'SeekPosition\', LEVEL_3, EBML_UINTEGER)\n    }\n    self._total_size_to_read = stop + pos\n    self.pos_ =  pos\n\n  def ProcessSeek(self, file_, pos):\n    HandleData(self, self._seek, self.ProcessSeek, file_, pos)\n\ndef ShowUsage():\n  print \'\\t\\t\\t WebM inspector v0.1\'\n  print \'\\t\\t\\t   python webminspector.py [webm file]\'\n  print \'\\t\\t\\t   ex) python webminspector.py test.webm\'\n\ndef ShowMenu():\n  print \'\\t\\t Please choose a menu\'\n  print \'\\t\\t  1. show EBML\'\n  print \'\\t\\t  2. show SeekHead\'\n  print \'\\t\\t  3. show SegmentInfo\'\n  print \'\\t\\t  4. show Tracks\'\n  print \'\\t\\t  5. show Cues\'\n  print \'\\t\\t  6. show Clusters\'\n  print \'\\t\\t  7. show all\'\n  print \'\\t\\t  8. capture all\'\n  print \'\\t\\t  9. exit\'\n  menu = raw_input(\'\\t\\t ? : \')\n  return menu\n'"
tests/webminspector/webminspector.py,0,"b'#!/usr/bin/python\n##\n##  Copyright (c) 2010 The WebM project authors. All Rights Reserved.\n##\n##  Use of this source code is governed by a BSD-style license\n##  that can be found in the LICENSE file in the root of the source\n##  tree. An additional intellectual property rights grant can be found\n##  in the file PATENTS.  All contributing project authors may\n##  be found in the AUTHORS file in the root of the source tree.\n##\n\n""""""One-line documentation for webmtool module.\n\nA detailed description of webmtool.\n""""""\n\n__author__ = \'hwasoolee@google.com (Hwasoo Lee)\'\n\nfrom webm import *\n\ndef main():\n  import sys\n  menu = \'none\'\n  num_argument = len(sys.argv)\n#  if num_argument == 1:\n#    ShowUsage()\n#    return\n#  elif num_argument == 2:\n#    webm_file = webmFile(sys.argv[1])\n#    if webm_file._file == None:\n#      return\n#    file_ = webm_file.GetFile()\n#\n#    ebml = Ebml()\n#    ebml.ProcessEbml(file_, 0, True)\n#    pos = ebml.GetFilePosition()\n#    segment = Segment()\n#    segment.SearchLevelOneElements(file_, pos)\n#\n#    while menu != \'9\':\n#      menu = ShowMenu()\n#      if menu == \'1\': # EBML\n#        ebml.ProcessEbml(file_)\n#      elif menu == \'2\': #SeekHead\n#        segment.ProcessElement(file_, SEEKHEAD, 0)\n#      elif menu == \'3\': #SegmentInfo\n#        segment.ProcessElement(file_, SEGMENT_INFO, 0)\n#      elif menu == \'4\': #Tracks\n#        segment.ProcessElement(file_, TRACKS, 0)\n#      elif menu == \'5\': #Cues\n#        segment.ProcessElement(file_, CUES, 0)\n#      elif menu == \'6\': #Clusters\n#        i = 0\n#        for cluster in segment._elements:\n#          if int(cluster[0], 16) == CLUSTER:\n#            segment.ProcessElement(file_, CLUSTER, i)\n#            i = i + 1\n#      elif menu == \'7\': #Capture\n#        ebml.ProcessEbml(file_)\n#        segment.ProcessElement(file_, SEEKHEAD, 0)\n#        segment.ProcessElement(file_, SEGMENT_INFO, 0)\n#        segment.ProcessElement(file_, TRACKS, 0)\n#        segment.ProcessElement(file_, CUES, 0)\n#\n#        i = 0\n#        for cluster in segment._elements:\n#          if int(cluster[0], 16) == CLUSTER:\n#            segment.ProcessElement(file_, CLUSTER, i)\n#            i = i + 1\n#  else:\n#    print \'\\t\\t Only need a WebM or Mkv filename. Too many arguments.\'\n#    return\n\n  if num_argument == 1:\n    print \'\\t\\t * WebM Inspector %s\' % GetVersion()\n    print \'\\t\\t  -. This command line tool dumps all info from a webm file.\'\n    print \'\\t\\t  -. usage: python webminspector.py [webm file]\'\n    print \'\\t\\t  -. ex: python webminspector.py sample.webm\\n\'\n    sys.exit(1)\n\n  webm_file = webmFile(sys.argv[1])\n  if webm_file._file == None:\n    return\n  file_ = webm_file.GetFile()\n\n  try:\n    ebml = Ebml()\n    ebml.ProcessEbml(file_, 0, True)\n    pos = ebml.GetFilePosition()\n    segment = Segment()\n    size, start_pos = ReadOneByteForElementIdSize(file_, pos)\n    element_id, pos = ProcessIdSize(file_, start_pos, size)\n    data_size_length, pos = ReadOneByteForDataSize(file_, pos)\n    data_size, pos = ProcessDataSize(file_, pos, data_size_length)\n    segment.SetTotalSizeSegment(data_size)\n    while pos <= data_size:\n      pos = segment.SearchLevelOneElements(file_, pos)\n    ebml.ProcessEbml(file_)\n    segment.ProcessElement(file_, SEEKHEAD, 0)\n    segment.ProcessElement(file_, SEGMENT_INFO, 0)\n    segment.ProcessElement(file_, TRACKS, 0)\n    segment.ProcessElement(file_, CUES, 0)\n\n    i = 0\n    for cluster in segment._elements:\n      if int(cluster[0], 16) == CLUSTER:\n        segment.ProcessElement(file_, CLUSTER, i)\n        i += 1\n\n  except KeyboardInterrupt:\n    file_.close()\n\n  return\n\nif __name__ == ""__main__"":\n  main()\n'"
tests/vstb-example-html5/tests/rotate.py,0,"b'# pylint: disable=F0401\nfrom stbt import press, wait_for_match\n\n\ndef wait_for_vstb_startup():\n    wait_for_match(\'stb-tester-350px.png\', timeout_secs=20)\n\n\ndef test_that_image_is_rotated_by_arrows():\n    press(""KEY_LEFT"")\n    wait_for_match(\'stb-tester-left.png\')\n    press(""KEY_RIGHT"")\n    wait_for_match(\'stb-tester-right.png\')\n    press(""KEY_UP"")\n    wait_for_match(\'stb-tester-up.png\')\n    press(""KEY_DOWN"")\n    wait_for_match(\'stb-tester-down.png\')\n\n\ndef test_that_image_returns_to_normal_on_OK():\n    press(""KEY_OK"")\n    wait_for_match(\'stb-tester-350px.png\')\n\n\ndef test_that_custom_key_is_recognised():\n    press(""KEY_CUSTOM"")\n    wait_for_match(\'stb-tester-up.png\', timeout_secs=1)\n'"
