file_path,api_count,code
setup.py,0,"b'import fnmatch\nimport glob\nimport hashlib\nimport os\nimport re\nimport subprocess\nimport sys\nfrom distutils.command.build_clib import build_clib\nfrom distutils.core import Extension, setup\nfrom os import path\nfrom pathlib import Path\n\nfrom Cython.Build import cythonize\n\ndef get_compiler():\n    import distutils.ccompiler\n    return distutils.ccompiler.get_default_compiler()\n\n\nIS_MSVC = get_compiler() == \'msvc\'\n\ndef c_arg(gcc_ver, win_ver):\n    return win_ver if IS_MSVC else gcc_ver\n\n\nos.environ[\'CFLAGS\'] = os.environ.get(\'CFLAGS\', \'\') + c_arg(\' -msse4\', \'/arch:SSE2\')\n\ntry:\n    import numpy\nexcept ImportError:\n    # Pytubes requires numpy to build, but\n    # doing this allows setup.py to be imported\n    # even if numpy isn\'t installed, something that\'s required to, for example\n    # work out that numpy is a dependency\n    np_get_include = lambda: \'src\'\nelse:\n    np_get_include = numpy.get_include\n\n    \nPROJECT_ROOT = Path(__file__).absolute().parent\n\n\nwith (PROJECT_ROOT / ""README.rst"").open() as fh:\n    LONG_DESCRIPTION = fh.read()\n\n\nwith (PROJECT_ROOT / ""pyx"" / ""version.pxi"").open() as fh:\n    VERSION = ""%s.%s.%s"" % re.match(r\'__version__\\s*=\\s*\\((\\d+),\\s*(\\d+),\\s*(\\d+)\\)\', fh.read()).groups()\n\n\ndef hash_file(*parts):\n    file_path = PROJECT_ROOT.joinpath(*parts)\n    if not file_path.exists():\n        return """"\n    with file_path.open(""rb"") as fh:\n        return hashlib.sha1(fh.read().strip()).hexdigest()\n\n\ndef update_iter_defs():\n    """"""\n    Cython wrapper classes are generated for each iterator, (make_cdef.py)\n    This has to be done before the cythonize() command below (which happens\n    at import time) so run it inline here.\n    """"""\n    script = str(PROJECT_ROOT / ""tools"" / ""make_cdef.py"")\n    source_files = list((PROJECT_ROOT / ""src"" / ""iters"").glob(""*.hpp""))\n    source_files = [str(f) for f in source_files]\n    result = subprocess.check_output([sys.executable, script] + source_files)\n\n    if hash_file(""pyx"", ""iter_defs.pxi"") != hashlib.sha1(result.strip()).hexdigest():\n        print(""Updating iter_defs.pxi"")\n        with (PROJECT_ROOT / \'pyx\' / \'iter_defs.pxi\').open(\'wb\') as fh:\n            fh.write(result)\n\n\n\nupdate_iter_defs()\n\nzlib = (\'zlib\', {\n    \'sources\': glob.glob(\'vendor/zlib/*.c\'),\n    \'include_dirs\': [\'vendor/zlib\'],\n})\n\nDOUBLE_SOURCES = [\n    str(f.relative_to(PROJECT_ROOT))\n    for f in\n    (PROJECT_ROOT / \'vendor\' / \'double-conversion\').glob(\'**/*.cc\')\n    if \'test\' not in f.name and \'benchmark\' not in f.name\n]\n\n\ndef should_be_excluded(fn):\n    rel = fn.relative_to(ARROW_SOURCE_ROOT)\n    path_parts = {p.name for p in rel.parents if p.name}\n    if path_parts & PATHS_TO_EXCLUDE:\n        return True\n    for pattern in PATTERNS_TO_EXCLUDE:\n        if fnmatch.fnmatch(fn.name, pattern):\n            return True\n\n\nCTUBES_OPTIONS = {\n    \'sources\': [""pyx/tubes.pyx""] + DOUBLE_SOURCES,\n    \'language\': ""c++"",\n    \'include_dirs\':  [\n        \'vendor\',\n        \'vendor/zlib\',\n        \'vendor/arrow/cpp/src/\',\n        \'vendor/double-conversion/\',\n        \'src\',\n        np_get_include(),\n    ],\n    \'libraries\': [],\n    \'extra_compile_args\': [\n        c_arg(\'-std=c++11\', \'/std:c++14\'),\n        c_arg(\'-g\', \'/DEBUG:FASTLINK\'),\n        c_arg(\'-O3\', \'/O2\'),\n        c_arg(\'-msse4\', \'\')\n    ],\n    \'extra_link_args\': [\n        c_arg(\'-std=c++11\', \'\'),\n        c_arg(\'-g\', \'/Zi\'),\n    ],\n}\n\n\nsetup(\n    name=\'pytubes\',\n    ext_modules = cythonize(\n        Extension(\n            ""tubes"",\n            **CTUBES_OPTIONS\n        ),\n        compiler_directives={""language_level"": 3, \'embedsignature\': True},\n        include_path=[\'.\'],\n    ),\n    libraries=[zlib],\n    py_modules=[],\n    cmdclass = {\'build_clib\': build_clib},\n    version=VERSION,\n    description=""A library for efficiently loading data into Python"",\n    long_description=LONG_DESCRIPTION,\n    author=""Stephen Stagg"",\n    author_email=""stestagg@gmail.com"",\n    python_requires="">=3.4.0"",\n    url=""https://github.com/stestagg/pytubes"",\n    install_requires=[\'numpy\'],\n    include_package_data=True,\n    license=\'MIT\',\n    classifiers=[\n        \'License :: OSI Approved :: MIT License\',\n        \'Programming Language :: Python\',\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: 3.7\',\n        \'Programming Language :: Python :: 3.6\',\n        \'Programming Language :: Python :: 3.4\',\n        \'Programming Language :: Python :: 3.5\',\n        \'Programming Language :: Python :: Implementation :: CPython\',\n    ],\n)\n'"
docs/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/stable/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath(\'.\'))\n\nimport tubes\n\n# -- Project information -----------------------------------------------------\n# The short X.Y version\nversion = ""."".join(str(p) for p in tubes.__version__)\n# The full version, including alpha/beta/rc tags\nrelease = version\n\nproject = \'pytubes\'\ncopyright = \'2019, Offset Design Ltd\'\nauthor = \'Steve Stagg\'\n\n\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.intersphinx\',\n    \'sphinx.ext.todo\',\n    \'sphinx.ext.ifconfig\',\n    \'sphinx.ext.viewcode\',\n    \'sphinx.ext.githubpages\',\n    \'docstring_tools\',\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\nsource_suffix = [\'.rst\']\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path .\nexclude_patterns = [\'_build\', \'Thumbs.db\', \'.DS_Store\']\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'alabaster\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\nhtml_theme_options = {\n    \'fixed_sidebar\': True,\n    \'description\': \'Piping data into python\',\n    \'github_user\': \'stestagg\',\n    \'github_repo\': \'pytubes\',\n    \'show_relbar_top\': True,\n\n}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don\'t match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``[\'localtoc.html\', \'relations.html\', \'sourcelink.html\',\n# \'searchbox.html\']``.\n#\nhtml_sidebars = {""**"": [\n    \'about.html\',\n    \'navigation.html\',\n    \'relations.html\',\n    \'searchbox.html\',\n]}\n\nautoclass_content = ""both""\n\n# -- Options for intersphinx extension ---------------------------------------\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {\'https://docs.python.org/\': None}\n\n# -- Options for todo extension ----------------------------------------------\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True'"
docs/docstring_tools.py,0,"b'import re\nfrom collections import defaultdict\n\nimport tubes\n\n\ndef setup(app):\n    app.connect(\'autodoc-process-docstring\', process_docstring)\n\n\ndef make_tubes():\n    for dtype, value in [\n        (tubes.Null,  None),\n        (tubes.Bool, False),\n        (tubes.Int64, 1),\n        (tubes.Float, 1.1),\n        (tubes.ByteSlice, b\'abc\'),\n        (tubes.Utf8, \'abc\'),\n        (tubes.Object, \'a\'),\n        (tubes.JsonUtf8, \'1\')]:\n        yield (dtype, tubes.Each([value]).to(dtype), value)\n\n\ndef test_compatibility(test):\n    compatible = []\n    for dtype, tube, value in make_tubes():\n        try:\n            eval(test, {""dtype"": dtype, ""tube"": tube, ""value"": value})\n        except (ValueError, RuntimeError):\n            pass\n        else:\n            compatible.append(\'``{0}``\'.format(dtype.name))\n    return compatible\n\n\ndef describe_compatibility(test):\n    compatible_types = test_compatibility(test)\n    yield \'Compatible input types: {0}\'.format("", "".join(compatible_types))\n    yield \'\'\n\n\ndef test_cross_compatibility(test):\n    results = defaultdict(dict)\n    for (from_dtype, from_tube, _) in make_tubes():\n        for (to_dtype, to_tube, _) in make_tubes():\n            try:\n                eval(test, {""from_tube"": from_tube, ""to_tube"": to_tube})\n            except ValueError:\n                worked = False\n            else:\n                worked = True\n            results[from_dtype][to_dtype] = worked\n    return results\n\n\ndef describe_cross_compatibility(test):\n    results = test_cross_compatibility(test)\n    types = list(results.keys())\n    yield \'\'\n    yield ""+------------+"" + (""--------+"" * len(results))\n    yield ""|        To\xe2\x86\x92"" + ("" |       "" * len(types)) + "" |""\n    yield ""+------------+"" + (""        +"" * len(results))\n    yield ""| \xe2\x86\x93From      | "" + "" | "".join(t.name.ljust(6) for t in types) + "" |""\n    yield ""+============+"" + (""========+"" * len(results))\n    for from_type in types:\n        line = ""| {0} "".format(from_type.name.ljust(10))\n        for to_type in types:\n            result = results[from_type][to_type]\n            value = ""\xe2\x9c\x93"" if result else "" ""\n            line += ""|   {0}    "".format(value)\n        line += ""|""\n        yield line\n        yield ""+------------+"" + (""--------+"" * len(results))\n\n\ndef process_docstring(app, what, name, obj, options, lines):\n    if not lines:\n        return None\n    out = []\n    def add(gen):\n        for line in gen:\n            out.append(line.rstrip())\n\n    for line in lines:\n        match = re.match(""Compatibility: (.*)"", line)\n        if match:\n            add(describe_compatibility(match.group(1)))\n        else:\n            x_match = re.match(""XCompatibility: (.*)"", line)\n            if x_match:\n                add(describe_cross_compatibility(x_match.group(1)))\n            else:\n                out.append(line)\n    lines[:] = out\n    # import ipdb; ipdb.set_trace()\n\n    # The \'lines\' in Sphinx is a list of strings and the value should be changed\n'"
test/test_chunk.py,0,"b""import pytest\nimport itertools\n\nimport tubes\n\n\ndef test_chunking():\n    tube = tubes.Each([1,2,3,4]).first(1).chunk(2)\n    assert list(tube) == [1, 3]\n    tube = tubes.Each([1,2,3,4]).skip(1).chunk(2)\n    assert list(tube) == [2, 4]\n\ndef test_multiple_chunks():\n    with pytest.raises(ValueError):\n        list(tubes.Each([1,2,3,4]).zip(tubes.Each([1,2,3,4])).chunk(2))\n\ndef test_chunk_with_generator():\n    with pytest.raises(ValueError):\n        list(tubes.Each(itertools.count()).chunk(2))\n\n\ndef test_chunk_empty_input():\n\ttube = tubes.Each([]).chunk(2)\n\twith pytest.raises(ValueError):\n\t\tlist(tube)\n\n\nif __name__ == '__main__':\n    test_chunking()"""
test/test_compare.py,0,"b'import pytest\n\nimport tubes\n\ndef test_py_object_equal():\n    assert list(tubes.Each([1, \'b\', None]).equals(1))    == [True, False, False]\n    assert list(tubes.Each([1, \'b\', None]).equals(\'b\'))  == [False, True, False]\n    assert list(tubes.Each([1, \'b\', None]).equals(None)) == [False, False, True]\n\n\ndef test_py_object_gt():\n    with pytest.raises(TypeError):\n        list(tubes.Each([1, \'b\', None]).gt(1))\n    assert list(tubes.Each([1, 2, 3]).gt(1))  == [False, True, True]\n    assert list(tubes.Each([\'a\', \'b\', \'c\']).gt(""apple""))  == [False, True, True]\n\n\n@pytest.mark.parametrize(""src, ty, value, dest"", [\n    ([True, False], bool, False, [False, True]),\n    ([True, 1, 2, 10], int, 1, [True, True, False, False]),\n    ([True, 1, 2, 10], int, 2, [False, False, True, False]),\n    ([True, 1, 2, 10], int, 10, [False, False, False, True]),\n    ([1, 1.5, 3.1415], float, 1, [True, False, False]),\n    ([1, 1.5, 3.1415], float, 1.5, [False, True, False]),\n    ([1, 1.5, 3.1415], float, 3.1415, [False, False, True]),\n    ([\'baa\', \'bab\', \'ba\'], bytes, \'baa\', [True, False, False]),\n    ([\'baa\', \'bab\', \'ba\'], bytes, \'bab\', [False, True, False]),\n    ([\'baa\', \'bab\', \'ba\'], bytes, \'ba\', [False, False, True]),\n    ([None], tubes.Null, None, [True]),\n])\ndef test_equal(src, ty, value, dest):\n    assert list(tubes.Each(src).to(ty).equals(value)) == dest\n\n\n@pytest.mark.parametrize(""src, ty, value, dest"", [\n    ([True, False], bool, False, [True, False]),\n    ([True, 0, 2, 10], int, 0, [True, False, True, True]),\n    ([True, 0, 2, 10], int, 1, [False, False, True, True]),\n    ([True, 0, 2.5, 10], float, 1, [False, False, True, True]),\n    ([True, 0, 2.5, 10], float, 2.3, [False, False, True, True]),\n    ([True, 0, 2.5, 10], float, 2.6, [False, False, False, True]),\n])\ndef test_gt(src, ty, value, dest):\n    assert list(tubes.Each(src).to(ty).gt(value)) == dest\n\n\n@pytest.mark.parametrize(""src, ty, value, dest"", [\n    ([True, False], bool, True, [False, True]),\n    ([True, 0, 2, 10], int, 0, [False, False, False, False]),\n    ([True, 0, 2, 10], int, 1, [False, True, False, False]),\n    ([True, 0, 2.5, 10], float, 1, [False, True, False, False]),\n    ([True, 0, 2.5, 10], float, 2.3, [True, True, False, False]),\n    ([True, 0, 2.5, 10], float, 2.6, [True, True, True, False]),\n])\ndef test_lt(src, ty, value, dest):\n    assert list(tubes.Each(src).to(ty).lt(value)) == dest'"
test/test_convert.py,0,"b'import pytest\nimport tubes\n\n\n@pytest.mark.parametrize(""val, dtype, result"", [\n    ([None], tubes.Null, [None]),\n    ([False, 0, \'\', b\'\'], tubes.Bool, [False, False, False, False]),\n    ([True, 1, \'a\', b\'a\'], tubes.Bool, [True, True, True, True]),\n    ([True, 2, 4.2, -2**60, \'1234\'], tubes.Int64, [1, 2, 4, -2**60, 1234]),\n    ([True, 2, 3.2, -10e10, \'1.234\', \'inf\'], tubes.Float, [1.0, 2.0, 3.2, -10e10, 1.234, float(\'inf\')]),\n    ([True, 2, 3.2, b\'abc\', \'abc\'], tubes.ByteSlice, [b\'True\', b\'2\', b\'3.2\', b\'abc\', b\'abc\']),\n    ([True, 2, 3.2, b\'abc\', \'abc\'], tubes.Utf8, [\'True\', \'2\', \'3.2\', \'abc\', \'abc\']),\n])\ndef test_convert_from_to_py(val, dtype, result):\n    assert list(tubes.Each(val).to(dtype)) == result\n\n\ndef test_to_str_codec():\n    tube = tubes.Each([b\'\\xff\']).to(str, codec=\'latin1\')\n    assert list(tube) == [\'\\xff\']\n\n\ndef test_to_str_invalid_utf8():\n    with pytest.raises(UnicodeDecodeError):\n        tube = tubes.Each([b\'\\xff\']).to(str)\n        assert list(tube) == [\'\\xff\']\n\n\ndef test_convert_from_bool():\n    assert list(tubes.Each([True, False]).to(bool).to(int)) == [1, 0]\n    assert list(tubes.Each([True, False]).to(bool).to(float)) == [1., 0.]\n    assert list(tubes.Each([True, False]).to(bool).to(bytes)) == [b\'True\', b\'False\']\n    assert list(tubes.Each([True, False]).to(bool).to(str)) == [\'True\', \'False\']\n\n@pytest.mark.parametrize(""val, from_dtype, to_dtype, result"", [\n    ([None], tubes.Null, tubes.Null, [None]),\n    ([\'1\', \'3.14\', \'-1\', \'1e100\', \'inf\'], str, float, [1, 3.14, -1, 1e100, float(\'inf\')]),\n    ([\'1\', \'3.14\', \'-1\', \'1e+100\', \'inf\'], bytes, float, [1, 3.14, -1, 1e100, float(\'inf\')]),\n    ([1, 3.14, -1, 1e100, float(\'inf\')], float, bytes, [b\'1.0\', b\'3.14\', b\'-1.0\', b\'1e+100\', b\'inf\']),\n    ([1, 3.14, -1, 1e100, float(\'inf\'), 1/3], float, str, [\'1.0\', \'3.14\', \'-1.0\', \'1e+100\', \'inf\', \'0.3333333333333333\']),\n])\ndef test_convert_types(val, from_dtype, to_dtype, result):\n    assert list(tubes.Each(val).to(from_dtype).to(to_dtype)) == result\n'"
test/test_csv.py,0,"b'import pytest\nimport tubes\n\ndef test_csv_to_py():\n    tube = tubes.Each([\'a,b,c\', \'d,ef\']).to(tubes.CsvRow)\n    assert list(tube) == [[b\'a\', b\'b\', b\'c\'], [b\'d\', b\'ef\']]\n\ndef test_empty_csv():\n    tube = tubes.Each([\'\']).to(tubes.CsvRow)\n    assert list(tube) == [[b\'\']]\n\ndef test_csv_two_values():\n    tube = tubes.Each([\'a,b\']).to(tubes.CsvRow)\n    assert list(tube) == [[b\'a\', b\'b\']]\n\ndef test_csv_trailing_comma():\n    tube = tubes.Each([\'a,\']).to(tubes.CsvRow)\n    assert list(tube) == [[b\'a\', b\'\']]\n\ndef test_csv_one_row():\n    tube = tubes.Each([\'a,b,c\']).to(tubes.CsvRow).get(1, \'x\')\n    assert list(tube) == [b\'b\']\n\ndef test_csv_two_rows():\n    tube = tubes.Each([\'a,b,c\', \'d,e,f\']).to(tubes.CsvRow).get(0)\n    assert list(tube) == [b\'a\', b\'d\']\n\ndef test_csv_escaping():\n    tube = tubes.Each([\'a""x"",""b"",""""\', \'""d"",""e,f"",g\']).to(tubes.CsvRow).multi(lambda x: (\n        x.get(0, \'xx\'),\n        x.get(1, \'xx\'),\n        x.get(2, \'xx\'),\n    ))\n    assert list(tube) == [(b\'a""x""\', b\'b\', b\'\'), (b\'d\', b\'e,f\', b\'g\')]\n\ndef test_csv_quote_escaping():\n    tube = tubes.Each([\'""a""""b"","""""""",""""""""""""\', \'""c""""""""d"",e""""f\']).to(tubes.CsvRow).multi(lambda x: (\n        x.get(0),\n        x.get(1),\n        x.get(2, \'x\'),\n    ))\n    assert list(tube) == [(b\'a""b\', b\'""\', b\'""""\'), (b\'c""""d\', b\'e""""f\', b\'x\')]\n\ndef test_csv_uneven_rows():\n    tube = tubes.Each([\'a\', \'b,c\', \'d,e,\', \'f,g,h\']).to(tubes.CsvRow).get(2, \'xx\').to(str)\n    assert list(tube) == [\'xx\', \'xx\', \'\', \'h\']\n\ndef test_csv_uneven_rows_named():\n    file = ""\\n"".join([\'a,b,c\', \'1,2,3\', \'4,5,\', \'6,7\', \'8,\', \'9\', \',\'])\n    tube = tubes.Each([file]).csv().get(\'b\', \'xx\').to(str)\n    assert list(tube) == [\'2\', \'5\', \'7\', \'\', \'xx\', \'\']\n    tube = tubes.Each([file]).csv().get(\'c\', \'99\').to(str)\n    assert list(tube) == [\'3\', \'\', \'99\', \'99\', \'99\', \'99\']\n\ndef test_csv_uneven_rows_get_many():\n    tube = tubes.Each([\'a\', \'b,c\', \'d,e,\', \'f,g,h\']).to(tubes.CsvRow).multi(lambda x: (\n        x.get(0),\n        x.get(1, \'xx\'),\n        x.get(2, \'xx\'),\n    )).to(str, str, str)\n    assert list(tube) == [\n        (\'a\', \'xx\', \'xx\'),\n        (\'b\', \'c\', \'xx\'),\n        (\'d\', \'e\', \'\'),\n        (\'f\', \'g\', \'h\'),\n    ]\n\ndef test_csv_multi():\n    tube = tubes.Each([\'a,b,c\', \'d,e,f\']).to(tubes.CsvRow).multi(lambda x:(\n        x.get(0),\n        x.get(1),\n        x.get(2),\n        x.get(3, \'xx\')\n    )).to(str, str, str, str)\n    assert list(tube) == [(\'a\', \'b\', \'c\', \'xx\'), (\'d\', \'e\', \'f\', \'xx\')]\n\n\ndef test_csv_headers_one_row():\n    tube = (tubes\n        .Each([\'a,b,c\', \'d,e,f\'])\n        .csv(headers=True, split=False)\n        .multi(lambda x:(\n            x.get(\'a\'),\n            x.get(1),\n            x.get(2),\n            x.get(\'c\')\n        ))\n        .to(str, str, str, str)\n    )\n    assert list(tube) == [(\'d\', \'e\', \'f\', \'f\')]\n\n\ndef test_reading_csv_headers_different_orders():\n    tsv_1 = """"""a,b,c\n1,2,3\n4,5,6\n""""""\n    tsv_2 = """"""c,a,b\n9,7,8\n12,10,11\n""""""\n    tube = tubes.Each([tsv_1, tsv_2]).to(bytes).csv(headers=True).chunk(1).multi(lambda x:(\n        x.get(\'a\'),\n        x.get(\'b\'),\n        x.get(\'c\')\n    )).to(int, int, int)\n    assert list(tube) == [(1, 2, 3), (4, 5, 6), (7, 8, 9), (10, 11, 12)]\n\n\ndef test_csv_non_comma_separator():\n    tube = tubes.Each([\'a|b|c\', \'d|e,f|g\']).to(bytes).csv(headers=False, sep=\'|\', split=False)\n    assert list(tube) == [[b\'a\', b\'b\', b\'c\'], [b\'d\', b\'e,f\', b\'g\']]\n\n\ndef test_csv_line_splitting():\n    tube = tubes.Each([""a,b\\nc,d\\ne"", "",f""]).csv(headers=False)\n    assert list(tube) == [[b\'a\', b\'b\'], [b\'c\', b\'d\'], [b\'e\', b\'f\']]\n\n\ndef test_csv_line_splitting_embedded_nl():\n    tube = tubes.Each([\'a,b\\n""c\\nd"",e\\nf\', \',g\']).csv(headers=False)\n    assert list(tube) == [[b\'a\', b\'b\'], [b\'c\\nd\', b\'e\'], [b\'f\', b\'g\']]\n\n\ndef test_csv_latin1():\n    tube = tubes.Each([b\'a,\\xff\\n\\xfe,\\xfa\\nf\']).csv(headers=False)\n    assert list(tube) == [[b\'a\', b\'\\xff\'], [b\'\\xfe\', b\'\\xfa\'], [b\'f\']]\n\n\ndef test_csv_latin1_get_by_name():\n    tube = tubes.Each([b\'a,\\xff\\n\\xfe,\\xdf\\nf\']).csv().get(b\'\\xff\', \'\').to(str, codec=\'latin1\')\n    #import pdb; pdb.set_trace()\n    assert list(tube) == [\'\xc3\x9f\', \'\']\n\n\nif __name__ == \'__main__\':\n    test_csv_one_row()'"
test/test_enumerate.py,0,"b""import tubes\n\ndef test_enumerate():\n    c = tubes.Count(2).enumerate().first(4)\n    assert list(c) == [(0, 2), (1, 3), (2, 4), (3, 5)]\n\ndef test_enumerate_strings():\n    c = tubes.Each(['a', 'b', 'c']).enumerate(1)\n    assert list(c) == [(1, 'a'), (2, 'b'), (3, 'c')]\n\n\n"""
test/test_fuzz.py,0,"b'import string\r\n\r\nimport numpy\r\nimport numpy.random as random\r\nimport pytest\r\nimport tubes\r\n\r\n\r\ndef rand_chars():\r\n    n_bytes = random.randint(0,10)\r\n    return random.bytes(n_bytes).decode(""latin1"")\r\n\r\n\r\ndef csv_escape(data):\r\n    data = data.replace(b\'""\', b\'""""\')\r\n    return b\'""\' + data + b\'""\'\r\n\r\n\r\n@pytest.fixture(params=[False, True])\r\ndef do_split(request):\r\n    return request.param\r\n\r\n\r\ndef get_cols(max_cols):\r\n    cols_to_read = list(range(max_cols))\r\n    random.shuffle(cols_to_read)\r\n    return cols_to_read[:random.randint(max_cols)]\r\n\r\n\r\n@pytest.mark.parametrize(""seed"", [random.randint(2147483648) for i in range(60)])\r\ndef test_fuzz_csv(seed, do_split):\r\n    random.seed(seed)\r\n    n_rows = random.randint(30)\r\n    cols_to_read = get_cols(32)\r\n    csv_rows = []\r\n    expected_rows = []\r\n    for _ in range(n_rows):\r\n        csv_row = []\r\n        expected_row = ([\'xx\'] * len(cols_to_read))\r\n        for col_no in range(random.randint(30)):\r\n            data = \'\\r\'\r\n            while data.endswith(\'\\r\'):\r\n                data = rand_chars()\r\n            if col_no in cols_to_read:\r\n                expected_row[cols_to_read.index(col_no)] = data\r\n            data = data.encode(""utf8"")\r\n            if b\'""\' in data or b\'\\n\' in data or b\',\' in data or random.choice([False, False, True]):\r\n                data = csv_escape(data)\r\n            csv_row.append(data)\r\n        if len(csv_row) == 0:\r\n            if 0 in cols_to_read:\r\n                expected_row[cols_to_read.index(0)] = \'\'\r\n        expected_rows.append(tuple(expected_row))\r\n        csv_rows.append(b"","".join(csv_row))\r\n    if do_split:\r\n        tube_input = [b\'\\n\'.join(csv_rows)] if n_rows else []\r\n        slot_tube = tubes.Each(tube_input).csv(headers=False, skip_empty_rows=False)\r\n    else:\r\n        slot_tube = tubes.Each(csv_rows).to(tubes.CsvRow)\r\n\r\n    slot_tube = slot_tube.multi(lambda x: [x.get(c, \'xx\').to(str) for c in cols_to_read])\r\n    actual_rows = list(slot_tube)\r\n    for row_num in range(len(expected_rows)):\r\n        for col_num in range(len(cols_to_read)):\r\n            expected = expected_rows[row_num][col_num]\r\n            if len(cols_to_read) == 1:\r\n                actual = actual_rows[row_num]\r\n            else:\r\n                actual = actual_rows[row_num][col_num]\r\n            assert expected == actual\r\n    assert len(expected_rows) == len(actual_rows)\r\n\r\n\r\ndef get_tsv(seed):\r\n    random.seed(seed)\r\n    n_rows = random.randint(30)\r\n    cols_to_read = get_cols(32)\r\n    tsv_rows = []\r\n    expected_rows = []\r\n    for _ in range(n_rows):\r\n        tsv_row = []\r\n        expected_row = ([\'xx\'] * len(cols_to_read))\r\n        for col_no in range(random.randint(30)):\r\n            data = \'\\t\'\r\n            while \'\\t\' in data or data.endswith(\'\\r\'):\r\n                data = rand_chars()\r\n            if col_no in cols_to_read:\r\n                expected_row[cols_to_read.index(col_no)] = data\r\n            data = data.encode(""utf8"")\r\n            tsv_row.append(data)\r\n        if len(tsv_row) == 0:\r\n            if 0 in cols_to_read:\r\n                expected_row[cols_to_read.index(0)] = \'\'\r\n        expected_rows.append(tuple(expected_row))\r\n        tsv_rows.append(b\'\\t\'.join(tsv_row))\r\n    return tsv_rows, expected_rows, cols_to_read\r\n\r\n\r\n@pytest.mark.parametrize(""seed"", [random.randint(2147483648) for i in range(60)])\r\ndef test_fuzz_tsv(seed):\r\n    tsv_rows, expected_rows, cols_to_read = get_tsv(seed)\r\n    slot_tube = tubes.Each(tsv_rows).to(tubes.TsvRow).multi(lambda x: [x.get(c, \'xx\').to(str) for c in cols_to_read])\r\n    actual_rows = list(slot_tube)\r\n    for row_num in range(len(expected_rows)):\r\n        for col_num in range(len(cols_to_read)):\r\n            expected = expected_rows[row_num][col_num]\r\n            if len(cols_to_read) == 1:\r\n                actual = actual_rows[row_num]\r\n            else:\r\n                actual = actual_rows[row_num][col_num]\r\n            assert expected == actual\r\n    assert len(expected_rows) == len(actual_rows)\r\n\r\n\r\ndef any_double(n):\r\n    buffer = numpy.random.bytes(8 * n)\r\n    return numpy.frombuffer(buffer, dtype=numpy.double)\r\n\r\ndef tiny_double(n):\r\n    return numpy.random.uniform(-1e-10, 1e10, size=n)\r\n\r\ndef small_double(n):\r\n    return numpy.random.uniform(-10_000, 10_000, size=n)\r\n\r\ndef large_double(n):\r\n    return numpy.random.uniform(-1e100, 1e100, size=n)\r\n\r\n\r\n@pytest.mark.parametrize(""seed"", [random.randint(2147483648) for i in range(10)])\r\n@pytest.mark.parametrize(""maker"", [any_double, tiny_double, small_double, large_double])\r\ndef test_fuzz_random_double_to_str(seed, maker):\r\n    numpy.random.seed(seed)\r\n    array = maker(10240)\r\n    actual = list(tubes.Each(array).to(float).to(str))\r\n    expected = [str(x).replace(\'e-0\', \'e-\').replace(\'e+0\', \'e+\') for x in array]\r\n    assert actual == expected\r\n\r\n\r\ndef make_str_col(length):\r\n    return numpy.array([rand_chars() for _ in range(length)])\r\nmake_str_col.dtype = str\r\n\r\n\r\ndef make_float_col(length):\r\n    return random.rand(length)\r\nmake_float_col.dtype = float\r\n\r\n\r\ndef make_int_col(length):\r\n    return random.randint(-1e9, 1e9, size=(length, ))\r\nmake_int_col.dtype = int\r\n\r\n\r\nif tubes.HAVE_PYARROW:\r\n    @pytest.mark.parametrize(""seed"", [random.randint(2147483648) for i in range(10)])\r\n    def test_fuzz_pa(seed):\r\n        random.seed(seed)\r\n        num_rows = random.randint(1000)\r\n        num_cols = random.randint(100)\r\n        types = [random.choice([make_str_col, make_int_col, make_float_col]) for _ in range(num_cols)]\r\n        cols = [m(num_rows) for m in types]\r\n        col_names = [\'%i: %s\' % (i, rand_chars()) for i in range(num_cols)]\r\n        given = list(zip(*cols))\r\n        given_pod = [[x.item() for x in r] for r in given]\r\n\r\n        slot_tube = tubes.Each(given_pod).multi(lambda x: [x.get(i).to(t.dtype) for i, t in enumerate(types)])\r\n        result = slot_tube.to_pyarrow(col_names)\r\n        table = result.to_pandas()\r\n        assert tuple(table.columns) == tuple(col_names)\r\n        for col_name, col in zip(col_names, cols):\r\n            result = table[col_name]\r\n            assert all(result == col)\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    for i in range(10000):\r\n        test_fuzz_csv(i, True)\r\n        if i % 500 == 0:\r\n            print(""Iteration: "", i)\r\n'"
test/test_get.py,0,"b'import pytest\n\nimport tubes\n\ndef test_get_invalid_slot():\n    base = tubes.Each([1])\n    with pytest.raises(IndexError):\n        base.slot(2)\n\n\ndef test_get_json():\n    base = tubes.Each([\'{""a"": ""b"", ""b"": 1}\']).json()\n    assert list(base.get(""a"")) == [""b""]\n    assert list(base.get(""b"")) == [1]\n\n\ndef test_get_missing_field_no_default():\n    base = tubes.Each([\'{""a"": ""b"", ""b"": 1}\']).json()\n    with pytest.raises(KeyError):\n        list(base.get(""c""))'"
test/test_get_index.py,0,"b'import pytest\nimport tubes\n\n\r\ndef test_single_index_get_on_pyobj():\r\n    tube = tubes.Each([[1,2], [], [8, 9]]).get(0, None)\r\n    assert list(tube) == [1, None, 8]\r\n\r\ndef test_multi_index_get_on_pyobj():\r\n    tube = tubes.Each([[1], [1, 1], [1, 2, 1], [1, 3, 3, 1], None]).multi(lambda x: tuple(x.get(i, \'X\') for i in range(5)))\r\n    assert list(tube) == [\r\n        (1, \'X\', \'X\', \'X\', \'X\'),\r\n        (1, 1, \'X\', \'X\', \'X\'),\r\n        (1, 2, 1, \'X\', \'X\'),\r\n        (1, 3, 3, 1, \'X\'),\r\n        (None, \'X\', \'X\', \'X\', \'X\'),\r\n    ]\r\n\r\ndef test_multi_index_pyobj_out_of_order():\r\n    order = [4, 2, 0, 3, 0, 1]\r\n    tube = tubes.Each([[1], [1, 1], [1, 2, 1], [1, 3, 3, 1], None]).multi(lambda x: tuple(x.get(i, \'X\') for i in order))\r\n    assert list(tube) == [\r\n        (\'X\', \'X\', 1, \'X\', 1, \'X\'),\r\n        (\'X\', \'X\', 1, \'X\', 1, 1),\r\n        (\'X\', 1, 1, \'X\', 1, 2),\r\n        (\'X\', 3, 1, 1, 1, 3),\r\n        (\'X\', \'X\', None, \'X\', None, \'X\'),\r\n    ]\r\n\r\ndef test_multi_index_pyobj_weird_types():\r\n    thing = object()\r\n    tube = tubes.Each([\r\n        [1], \r\n        \'a\', \r\n        4, \r\n        thing, \r\n        True\r\n    ]).multi(lambda x: tuple(x.get(i, None) for i in range(2)))\r\n    assert list(tube) == [\r\n        (1, None),\r\n        (\'a\', None),\r\n        (4, None),\r\n        (thing, None),\r\n        (True, None),\r\n    ]\r\n    \r\n\r\n\r\n\r\ndef test_single_index_get_on_json_value():\n    tube = tubes.Each([""[]"", ""[1, 2, 3]""]).json().get(1, \'null\')\n    assert list(tube) == [None, 2]\n\n\ndef test_multi_index_get_on_json_value():\n    tube = tubes.Each([""[1,2,3]"", ""[8,9,10]"", \'[""a"", ""b"", ""c""]\']).json().multi(lambda x: (\n        x.get(0),\n        x.get(2),\n        x.get(1),\n        ))\n    assert list(tube) == [(1, 3, 2), (8, 10, 9), (\'a\', \'c\', \'b\')]\n\n\ndef test_escaped_multi_index_get_on_json():\n    tube = tubes.Each([\n        r\'[""\\t"",""\\b"",""\\u1234""]\',\n        r\'[""\\"""","""",""a""]\',\n        r\'[""x"", ""y\\ta\\bb\\n"", ""z""]\'\n    ]).json().multi(lambda x: (\n        x.get(0),\n        x.get(1),\n        x.get(2),\n    )).to(str, str, str)\n    assert list(tube) == [(\'\\t\', \'\\b\', \'\\u1234\'), (\'""\', \'\', \'a\'), (\'x\', \'y\\ta\\bb\\n\', \'z\')]'"
test/test_group_id.py,0,"b""import pytest\nimport tubes\n\ndef test_group_id_increments_integer():\n    tube = tubes.Each([3, 4, 4, 5]).to(int).group_id()\n    assert list(tube) == [0, 1, 1, 2]\n\ndef test_group_id_increments_string():\n    tube = tubes.Each(['3', '4', '4', '5']).to(int).group_id()\n    assert list(tube) == [0, 1, 1, 2]\n\ndef test_group_id_increments_bool():\n    tube = tubes.Each([False, True, False, True, True]).to(bool).group_id()\n    assert list(tube) == [0, 1, 2, 3, 3]"""
test/test_json.py,0,"b'import json\nimport os\nimport os.path as path\n\nimport pytest\nimport tubes\n\ntry:\n    RecursionError\nexcept NameError:\n    RecursionError = RuntimeError\n\nTHIS_DIR = path.dirname(__file__)\n\ndef read_file(*parts):\n    with open(path.join(*parts), encoding=""UTF-8"") as fh:\n        return fh.read()\n\n#SAMPLE_JSON is a corpus of json snippets that should all be parsable.\nSAMPLE_JSON = [\n    \'[]\', \'{}\', \'false\', \'1\', \'1.1\',\n    \'null\', \'""""\', \'[{}]\', \'{""a"": []}\',\n    \'[[[[[[[[[[]]]]]]]]]]\',\n]\nfor i in range(0, 10, 2):\n    SAMPLE_JSON.append(\'""\' + (\'\\\\\' * i) + \'""\')\nfor i in range(1, 10, 2):\n    SAMPLE_JSON.append(\'""\' + (\'\\\\\' * i) + \'""1""\')\n\n\n\n# Please note, the tubes json parser is *not* validating.  It assumes that the\n# json is valid unless it is forced not to.  Therefore, many invalid JSONs may\n# be accepted as valid.\n\n# This test uses the JSONTestSuite from https://github.com/nst/JSONTestSuite\n# and expects tubes.json() to parse/convert any y_ or i_ tests that the python\n# json.loads() call can (and produce same output)\n\nTEST_CASE_DIR = path.join(THIS_DIR, ""JSONTestSuite_parse_tests"")\nBLACKLIST = {  # Generally speaking, json.loads() is very permissive about\n               # Utf-8 reading, but python string conversion fns aren\'t\n               # so these produce errors/inconsistent outputs\n    ""i_string_overlong_sequence_6_bytes.json"",\n    ""i_string_incomplete_surrogates_escape_valid.json"",\n    ""i_string_lone_utf8_continuation_byte.json"",\n    ""i_string_UTF-16LE_with_BOM.json"",\n    ""i_string_iso_latin_1.json"",\n    ""i_string_1st_valid_surrogate_2nd_invalid.json"",\n    ""i_string_utf16BE_no_BOM.json"",\n    ""i_string_UTF8_surrogate_U+D800.json"",\n    ""i_string_utf16LE_no_BOM.json"",\n    ""i_string_overlong_sequence_6_bytes_null.json"",\n    ""i_string_truncated-utf-8.json"",\n    ""i_string_overlong_sequence_2_bytes.json"",\n    ""i_string_not_in_unicode_range.json"",\n    ""i_string_invalid_utf-8.json"",\n    ""i_string_UTF-8_invalid_sequence.json"",\n}\ndef _valid(f):\n    if f in BLACKLIST:\n        return False\n    return f.endswith("".json"") and not f.startswith(""n_"")\n\nTEST_CASES = [f for f in os.listdir(TEST_CASE_DIR) if _valid(f)]\n\n\n@pytest.mark.parametrize(""filename"", TEST_CASES)\ndef test_passing_json_test_suite_cases(filename):\n    test_path = path.join(TEST_CASE_DIR, filename)\n    data = read_file(test_path)\n    try:\n        py_version = json.loads(data)\n    except (ValueError, RecursionError):\n        return\n\n    tubes_version = tubes.Each([test_path]).map_files().json()\n    assert list(tubes_version)[0] == py_version\n\n\n@pytest.mark.parametrize(""sample"", SAMPLE_JSON)\ndef test_json(sample):\n    assert list(tubes.Each([sample]).to(str).json())[0] == json.loads(sample)\n\n\n@pytest.mark.parametrize(""path"", [(THIS_DIR, ""tricky_json.json"")])\ndef test_json_file(path):\n    sample = read_file(*path)\n    assert list(tubes.Each([sample]).to(str).json())[0] == json.loads(sample)\n\n\ndef test_reading_json_with_blank_lines():\n    SAMPLE = """"""{}\n[1, 2, 3]\n\n{""a"": 2, ""b"": ""c""}\n\n9\n""""""\n    values = list(tubes.Each([SAMPLE]).to(bytes).split().skip_if(lambda x: x.is_blank()).json())\n    assert values == [{}, [1, 2, 3], {\'a\': 2, \'b\': \'c\'}, 9]\n\n\ndef test_reading_json_with_multiple_blank_lines():\n    SAMPLE = """"""\n[1, 2, 3]\n\n\n\n9\n""""""\n    values = list(tubes.Each([SAMPLE]).to(bytes).split().skip_if(tubes.is_blank).json())\n    assert values == [[1, 2, 3], 9]\n\n\nBAD_JSON = [\n    \'{\',\n    \'[\',\n    \'""\'\n]\n\n@pytest.mark.parametrize(""sample"", BAD_JSON)\ndef test_bad_json(sample):\n    with pytest.raises(ValueError):\n        tubes.Each([sample]).to(str).json().one\n'"
test/test_ndarray.py,3,"b'import pytest\nimport numpy as np\nimport string\n\nimport tubes\n\n\ndef test_fill_ndarray_chars():\n    nd = tubes.Each([""abc"", ""def"", ""ghi""]).to(bytes).ndarray(2)\n    assert nd.shape == (3, )\n    assert list(nd) == [b\'ab\', b\'de\', b\'gh\']\n\n\ndef test_fill_ndarray_integers():\n    nd = tubes.Count().first(100).to(int).ndarray(estimated_rows=2)\n    assert nd.shape == (100, )\n    assert list(nd) == list(range(100))\n\n\ndef test_fill_ndarray_many_chars():\n    nd = tubes.Each([x * 10 for x in string.ascii_lowercase] * 10).to(bytes).ndarray(5, estimated_rows=2)\n    assert nd.shape == (260, )\n    assert list(nd) == list([x.encode(\'ascii\') * 5 for x in string.ascii_lowercase] * 10)\n\n\ndef test_fill_ndarray_mixed_type():\n    nd = (tubes.Each([x * 10 for x in string.ascii_lowercase])\n        .to(bytes)\n        .enumerate()\n        .ndarray(None, 5)\n    )\n    assert nd.shape == (26, )\n    assert dict(nd.dtype.fields) == {\'0\': (np.dtype(\'int64\'), 0), \'1\': (np.dtype(\'S6\'), 8)}\n    expected = [(i, (x * 5).encode(\'ascii\')) for i, x in enumerate(string.ascii_lowercase)]\n    assert [tuple(x) for x in nd] == expected\n\n\ndef test_fill_ndarray_same_type():\n    nd = tubes.Count(5).first(4).enumerate().ndarray()\n    assert nd.shape == (4, 2)\n    assert [tuple(x) for x in nd] == [(0, 5), (1, 6), (2, 7), (3, 8)]\n\n\ndef test_fill_ndarray_same_type_fields():\n    nd = tubes.Count(5).first(4).enumerate().ndarray(fields=True)\n    assert nd.shape == (4, )\n    assert [tuple(x) for x in nd] == [(0, 5), (1, 6), (2, 7), (3, 8)]\n\n\ndef test_fill_ndarray_with_doubles():\n    nd = tubes.Each([1., 2., 3.14, 4.5]).to(float).ndarray()\n    assert list(nd) == [1.0, 2.0, 3.14, 4.5]\n\n\ndef test_fill_ndarray_with_bool():\n    nd = tubes.Each([True, False, True]).to(bool).ndarray()\n    assert nd.dtype == np.bool_\n    assert list(nd) == [True, False, True]\n\n\ndef test_fill_ndarray_with_object():\n    nd = tubes.Each([True, False, \'a\', 12]).ndarray()\n    assert nd.dtype == np.object_\n    assert list(nd) == [True, False, \'a\', 12]\n\n\nif __name__ == \'__main__\':\n    # test_fill_ndarray_chars()\n    test_fill_ndarray_many_chars()'"
test/test_pa.py,0,"b""import tubes\r\n\r\ntry:\r\n    import pyarrow as pa\r\nexcept ImportError:\r\n    pass\r\nelse:\r\n    def test_doubles():\r\n        tube = tubes.Count(2).to(float).first(4)\r\n        table = tube.to_pyarrow(('a', ))\r\n        assert isinstance(table, pa.Table)\r\n        assert str(table.columns[0].type) == 'double'\r\n        assert table.to_pandas().to_dict() == {\r\n            'a': {0: 2, 1: 3, 2: 4, 3: 5},\r\n        }\r\n\r\n\r\n    def test_int():\r\n        tube = tubes.Count().to(int).first(20_000)\r\n        table = tube.to_pyarrow(('a', ))\r\n        assert isinstance(table, pa.Table)\r\n        assert len(table) == 20_000\r\n        assert list(table.to_pandas()['a']) == list(range(20_000))\r\n\r\n\r\n    def test_none():\r\n        tube = tubes.Each([None, None]).to(None)\r\n        table = tube.to_pyarrow(('x', ))\r\n        assert len(table) == 2\r\n        assert list(table.to_pandas().x) == [None, None]\r\n\r\n\r\n    def test_enumerate():\r\n        tube = tubes.Count(2).enumerate().first(4)\r\n        table = tube.to_pyarrow(('a', 'b'))\r\n        assert isinstance(table, pa.Table)\r\n        assert str(table.columns[0].type) == 'int64'\r\n        assert str(table.columns[1].type) == 'int64'\r\n        assert table.to_pandas().to_dict() == {\r\n            'a': {0: 0, 1: 1, 2: 2, 3: 3},\r\n            'b': {0: 2, 1: 3, 2: 4, 3: 5}\r\n        }\r\n\r\n\r\n    def test_str():\r\n        tube = tubes.Each(['a', 'b', 'c', 'd', 'e']).to(str).enumerate()\r\n        table = tube.to_pyarrow(('index', 'val'))\r\n        assert isinstance(table, pa.Table)\r\n        assert str(table.columns[0].type) == 'int64'\r\n        assert str(table.columns[1].type) == 'string'\r\n        assert table.to_pandas().to_dict() == {\r\n            'index': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4},\r\n            'val': {0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e'}\r\n        }\r\n\r\n\r\n    def test_mixed_types():\r\n        table = (tubes\r\n            .Each(['apple', 'banana', 'apple'])\r\n            .to(str).enumerate()\r\n            .multi(lambda x: (x.slot(0), x.slot(0).to(float), x.slot(1)))\r\n            .to_pyarrow(('index', 'index_double', 'val'))\r\n        )\r\n        assert isinstance(table, pa.Table)\r\n        assert str(table.columns[0].type) == 'int64'\r\n        assert str(table.columns[1].type) == 'double'\r\n        assert str(table.columns[2].type) == 'string'\r\n        assert table.to_pandas().to_dict() == {\r\n            'index': {0: 0, 1: 1, 2: 2},\r\n            'index_double': {0: 0., 1: 1., 2: 2.},\r\n            'val': {0: 'apple', 1: 'banana', 2: 'apple'}\r\n        }\r\n\r\n\r\n    def test_longer_table():\r\n        tube = tubes.Count(5).multi(lambda x:(\r\n            tubes.Count(),\r\n            x,\r\n            x.to(object).to(str),\r\n            x.gt(1000)\r\n        )).first(500000)\r\n        table = tube.to_pyarrow(('index', 'src', 'strval', 'is_big'))\r\n        assert isinstance(table, pa.Table)\r\n        assert [str(c.type) for c in table.columns] == ['int64', 'int64', 'string', 'bool']\r\n        assert table.shape == (500000, 4)\r\n        assert dict(table.to_pandas().iloc[-1]) == {\r\n            'index': 499999,\r\n            'src': 500004,\r\n            'strval': '500004',\r\n            'is_big': True\r\n        }\r\n"""
test/test_pyiter.py,0,"b""import itertools\n\nimport pytest\n\nimport tubes\n\n\ndef test_static_tube_takes_a_list():\n    tube = tubes.Each([1, 2, 3])\n    assert list(tube) == [1, 2, 3]\n\n\ndef test_static_tube_takes_an_iter():\n    tube = tubes.Each(itertools.count(10)).first(3)\n    assert list(tube) == [10, 11, 12]\n\n\ndef test_static_tube_with_strings():\n    tube = tubes.Each(['a', 'b', 'c'])\n    assert list(tube) == ['a', 'b', 'c']\n\n\ndef test_static_tube_with_strings():\n    tube = tubes.Each(['a', 'b', 'c'])\n    assert list(tube.to(str)) == ['a', 'b', 'c']\n    assert list(tube.to(bytes)) == [b'a', b'b', b'c']\n\n\ndef test_static_tube_with_encoding():\n    tube = tubes.Each(['\xc2\xa3', '\xf0\x9f\x98\x83', ''])\n    assert list(tube.to(str)) == ['\xc2\xa3', '\xf0\x9f\x98\x83', '']\n    assert list(tube.to(bytes)) == [b'\\xc2\\xa3', b'\\xf0\\x9f\\x98\\x83', b'']\n    with pytest.raises(UnicodeEncodeError):\n        list(tube.to(bytes, codec='ascii'))\n\n\n"""
test/test_read_fileobj.py,0,"b'import pytest\n\nimport tubes\nfrom io import BytesIO, StringIO\n\ndef test_reading_a_file():\n    buf = BytesIO(b""Mary had a little lamb"")\n    tube = tubes.Each([buf]).read_fileobj()\n    assert list(tube) == [b\'Mary had a little lamb\']\n\ndef test_reading_two_files():\n    buf1 = BytesIO(b""Mary had"")\n    buf2 = BytesIO(b\'a little lamb\')\n    tube = tubes.Each([buf1, buf2]).read_fileobj()\n    assert list(tube) == [b\'Mary had\', b\'a little lamb\']\n\ndef test_reading_two_files_small_buffer():\n    buf1 = BytesIO(b""Mary had"")\n    buf2 = BytesIO(b\'a little lamb\')\n    tube = tubes.Each([buf1, buf2]).read_fileobj(size=2).to(str)\n    assert list(tube) == [\'Ma\', \'ry\', \' h\', \'ad\', \'a \', \'li\', \'tt\', \'le\', \' l\', \'am\', \'b\']\n\ndef test_reading_two_files_small_buffer_multiple_lines():\n    buf1 = BytesIO(b""Mary had "")\n    buf2 = BytesIO(b\'a\\nlittle lamb\')\n    tube = tubes.Each([buf1, buf2]).read_fileobj(size=2).split().to(str)\n    assert list(tube) == [\'Mary had a\', \'little lamb\']\n\ndef test_reading_nota_fileobj():\n    buf1 = BytesIO(b""Mary had"")\n    buf2 = ""string""\n    tube = tubes.Each([buf1, buf2]).read_fileobj()\n    with pytest.raises(ValueError) as exc:\n        list(tube)\n    assert exc.match(r\'only accepts objects with a \\.read\\(\\)\')\n\ndef test_reading_unicode():\n    buf1 = BytesIO(b""Mary had"")\n    buf2 = StringIO(""string"")\n    tube = tubes.Each([buf1, buf2]).read_fileobj()\n    with pytest.raises(ValueError) as exc:\n        list(tube)\n    assert exc.match(\'expects binary\')\n'"
test/test_recovery.py,0,"b'import os\r\nimport os.path as path\r\nimport json\r\n\r\nimport pytest\r\n\r\nimport tubes\r\n\r\n\r\ndef test_recover_bad_json():\r\n    tube = tubes.Each([\'[1,2]\', \'[\', \'{""a"": 1}\']).to(str).json()\r\n    it = iter(tube)\r\n    results = []\r\n    while True:\r\n        try:\r\n            results.append(next(it))\r\n        except ValueError as e:\r\n            results.append(\'ERR\')\r\n        except StopIteration:\r\n            break\r\n    assert results == [[1,2], \'ERR\', {\'a\': 1}]\r\n\r\n\r\ndef test_recover_bad_csv():\r\n    tube = tubes.Each([\'a,b\\n1,2\\n3,4\\n""x\']).csv().multi(lambda x: (x.get(0), x.get(1)))\r\n    it = iter(tube)\r\n    results = []\r\n    while True:\r\n        try:\r\n            results.append(next(it))\r\n        except ValueError as e:\r\n            results.append(\'ERR\')\r\n        except StopIteration:\r\n            break\r\n    assert results == [(b\'1\',b\'2\'), (b\'3\', b\'4\'), \'ERR\']\r\n\r\n\r\ndef test_recover_bad_json_with_skip():\r\n    tube = tubes.Each([\'[1,2]\', \'[\', \'{""a"": 1}\', \'12\']).to(str).json().skip(2)\r\n    it = iter(tube)\r\n    results = []\r\n    while True:\r\n        try:\r\n            results.append(next(it))\r\n        except ValueError as e:\r\n            results.append(\'ERR\')\r\n        except StopIteration:\r\n            break\r\n    # TODO: This /should/ return {""a"": 1}, 12\r\n    # but rewinding the stack to the right place is hard\r\n    assert results == [\'ERR\', 12]\r\n\r\n\r\n'"
test/test_refcount.py,0,"b'import tubes\nimport sys\nimport gc\n\nclass Flag:\n    def __init__(self):\n        self.is_set = False\n\n    def set(self):\n        assert self.is_set == False\n        self.is_set = True\n\n\nclass Canary:\n    def __init__(self, flag):\n        self.flag = flag\n\n    def __del__(self):\n        self.flag.set()\n\n\ndef test_refcount_call():\n    rc = sys.getrefcount(Flag())\n    assert rc == 1\n    b = Flag()\n    rc = sys.getrefcount(b)\n    assert rc == 2\n\ndef test_canary():\n    flag = Flag()\n    def make():\n        a = Canary(flag)\n    make()\n    assert flag.is_set\n\n\ndef test_numpy_object_refcount():\n    flag = Flag()\n    val = Canary(flag)\n    assert sys.getrefcount(val) == 2\n    tube = tubes.Each([val])\n    assert sys.getrefcount(val) == 3\n    gc.collect()\n    array = tube.ndarray()\n    assert sys.getrefcount(val) == 4\n    del tube\n    gc.collect()\n    assert sys.getrefcount(val) == 3\n    del array\n    gc.collect()\n    assert sys.getrefcount(val) == 2\n    del val\n    gc.collect()\n    assert flag.is_set\n\n\n\ndef test_to_py_handles_refcount_list():\n    """"""\n    sys.getrefcount() value is always one higher than expected\n    because the call to getrefcount() itself needs a reference..\n    """"""\n    flag = Flag()\n    a = Canary(flag)\n\n    assert sys.getrefcount(a) == 2  # a\n    tube = tubes.Each([True, a]).to_py()\n    assert sys.getrefcount(tube) == 2  # tube\n    assert sys.getrefcount(a) == 3  # a + each_val\n    it = iter(tube)\n    gc.collect()\n    assert sys.getrefcount(tube) == 2  # iter() doesn\'t keep reference to tube\n    assert sys.getrefcount(a) == 3  # a + each_val\n    assert next(it) is True\n    val = next(it)\n    assert val is a\n    gc.collect()\n    assert sys.getrefcount(a) == 6  # a + each_val + val + iter_cur + topy_cur\n    del it\n    gc.collect()\n    assert sys.getrefcount(a) == 4   # a + each_val + val\n    del tube\n    gc.collect()\n    assert sys.getrefcount(a) == 3  # a + val\n    del val\n    assert sys.getrefcount(a) == 2  # a\n    del a\n    gc.collect()\n    assert flag.is_set\n\n\ndef test_to_py_handles_refcount_iter():\n    flag = Flag()\n    a = Canary(flag)\n\n    assert sys.getrefcount(a) == 2  # a\n    tube = tubes.Each(iter([True, a])).to_py()\n    assert sys.getrefcount(tube) == 2  # iter\n    assert sys.getrefcount(a) == 3  # a + each_val\n    it = iter(tube)\n    gc.collect()\n    assert sys.getrefcount(tube) == 2  # iter() doesn\'t keep reference to tube\n    assert sys.getrefcount(a) == 3  # a + each_val\n    assert next(it) is True\n    val = next(it)\n    assert val is a\n    gc.collect()\n    assert sys.getrefcount(a) == 6  # a + each_val + val + iter_cur + topy_cur\n    del it\n    gc.collect()\n    assert sys.getrefcount(a) == 4   # a + each_val + val\n    del tube\n    gc.collect()\n    assert sys.getrefcount(a) == 3  # a + val\n    del val\n    assert sys.getrefcount(a) == 2  # a\n    del a\n    gc.collect()\n    assert flag.is_set\n'"
test/test_repr.py,0,"b'import tubes\nimport pytest\n\n@pytest.mark.parametrize((\'tube\', \'desc\'), [\n    (tubes.Each([]).chunk(2), ""Chunk(Each([]), chunk_size=2)""),\n    (tubes.Each([]).enum(), ""Each([]).Enum()""),\n    (tubes.Each([1]).enum(), ""Each([1]).Enum()""),\n    (tubes.Each([]).enumerate(10), ""Count(start=10).Zip(Count(start=10), Each([]))""),\n    (tubes.Each([]).equals(6), ""Each([]).Compare(op=\'==\', value=6)""), # 2 is EQ\n    (tubes.Each([]).first(2), ""Each([]).First(2)""),\n    (tubes.Each([]).get(0), ""Each([]).IndexLookup([0]).SlotGet(0)""),\n    (tubes.Each([]).get(0, default=\'x\'), ""Each([]).IndexLookup([0]).SlotGet(0, default_val=\'x\')""),\n    (tubes.Each([]).group_id(), ""Each([]).GroupId()""),\n    (tubes.Each([]).gt(9), ""Each([]).Compare(op=\'>\', value=9)""),\n    (tubes.Each([]).gunzip(), ""Each([]).Gunzip(stream=False)""),\n    (tubes.Each([]).gunzip(stream=True), ""Each([]).Gunzip(stream=True)""),\n    (tubes.Each([]).json(), ""Each([]).Convert(to_types=[DType[str]]).JsonParse()""),\n    (tubes.Each([]).lt(5), ""Each([]).Compare(op=\'<\', value=5)""),\n    (tubes.Each([]).map_files(), ""Each([]).Convert(to_types=[DType[bytes]], codec=b\'fs\').FileMap()""),\n    (\n        tubes.Each([]).multi(lambda x: (x.get(0), x.get(1))),\n        ""Each([]).Multi(Each([]).IndexLookup([0, 1]).SlotGet(0), Each([]).IndexLookup([0, 1]).SlotGet(1))""\n    ),\n    (\n        tubes.Each([]).multi(lambda x: [x.get(0), x.get(1)]),\n        ""Each([]).Multi(Each([]).IndexLookup([0, 1]).SlotGet(0), Each([]).IndexLookup([0, 1]).SlotGet(1))""\n    ),\n    (tubes.Each([]).read_files(), ""Each([]).Convert(to_types=[DType[bytes]], codec=b\'fs\').ReadFile()""),\n    (tubes.Each([]).skip(3), ""Each([]).Skip(num=3)""),\n    (tubes.Each([]).skip_unless(lambda x: x.gt(99)), ""Each([]).SkipUnless(Each([]).Compare(op=\'>\', value=99))""),\n    (tubes.Each([]).slot(0), ""Each([]).SlotGet(0)""),\n    (tubes.Each([]).to(bytes).split(\'r\'), ""Each([]).Convert(to_types=[DType[bytes]]).Split(sep=\'r\', skip_empty=False)""),\n    (tubes.Each([]).to(float), ""Each([]).Convert(to_types=[DType[float]])""),\n    (tubes.Each([]).to_py(), ""Each([]).ToPy()""),\n    (tubes.Each([]).tsv(), ""Each([]).Convert(to_types=[DType[bytes]]).Xsv(\'tsv\', sep=\'\\\\t\')""),\n    (tubes.Each([]).zip(tubes.Each([])), ""Each([]).Zip(Each([]), Each([]))""),\n])\ndef test_repr(tube, desc):\n    assert repr(tube) == desc'"
test/test_skip_if.py,0,"b'import tubes\n\ndef test_skip_if():\n    tube = tubes.Count().first(5).skip_if(tubes.Each([False, True, False, True]).to(bool))\n    assert list(tube) == [0, 2]\n\n\ndef test_skip_if_lambda():\n    tube = tubes.Count().first(6).skip_if(lambda x: x.lt(3))\n    assert list(tube) == [3, 4, 5]\n'"
test/test_skip_unless.py,0,"b'import tubes\n\n\ndef test_skip_unless():\n    tube = tubes.Count().skip_unless(tubes.Each([False, True, False, True]).to(bool))\n    assert list(tube) == [1, 3]\n\ndef test_skip_unless_lambda():\n    tube = tubes.Count().skip_unless(lambda x: x.lt(3).first(5))\n    assert list(tube) == [0, 1, 2]\n'"
test/test_split.py,0,"b""import tubes\n\ndef test_split():\n    tube = tubes.Each(['a\\tb\\tc\\t', 'd\\tef']).to(bytes).split('\\t').to(str)\n    assert list(tube) == ['a', 'b', 'c', 'd', 'ef']\n\n\ndef test_split_no_terminators():\n    tube = tubes.Each(['abc', 'def', 'ghi', 'jkl']).to(bytes).split('\\t').to(str)\n    assert list(tube) == ['abcdefghijkl']\n\n\ndef test_split_across_boundaries():\n    tube = tubes.Each(['ab|c', 'd|ef|', 'gh|ij']).to(bytes).split('|').to(str)\n    assert list(tube) == ['ab', 'cd', 'ef', 'gh', 'ij']\n\n\ndef test_split_on_first_char():\n    tube = tubes.Each(['|ab|c', '|d|ef|', '|g']).to(bytes).split('|').to(str)\n    assert list(tube) == ['', 'ab', 'c', 'd', 'ef', '', 'g']\n\n\ndef test_empty_splits():\n    tube = tubes.Each(['|||', '|||', '|']).to(bytes).split('|').to(str)\n    assert list(tube) == [''] * 8\n\ndef test_skipping_empty_splits():\n    tube = tubes.Each(['||a|', '|||b', '|']).to(bytes).split('|', skip_empty=True).to(str)\n    assert list(tube) == ['a', 'b']\n\n\ndef test_split_across_three():\n    tube = tubes.Each(['a|bc', 'def', 'g|h']).to(bytes).split('|').to(str)\n    assert list(tube) == ['a', 'bcdefg', 'h']"""
test/test_strlen.py,0,"b""import pytest\nimport tubes\n\n\ndef test_strlen_on_bytes():\n    tube = tubes.Each(['', 'b', 'ba', 'ban', 'bana']).to(bytes).len()\n    assert list(tube) == [0, 1, 2, 3, 4]\n\n\ndef test_strlen_on_simple_utf8():\n    tube = tubes.Each(['', 'b', 'ba', 'ban', 'bana']).to(str).len()\n    assert list(tube) == [0, 1, 2, 3, 4]\n\n\ndef test_strlen_on_complex_strs():\n    vals = ['\xf0\x9f\xa7\x99', '\xf0\x9f\x98\x80', '\xf0\x9f\x90\xb3\xf0\x9f\x8c\xb1', 'banana:\xf0\x9f\x8d\x8c']\n    base = tubes.Each(vals)\n    assert list(base.to(str).len()) == [1, 1, 2, 8]\n    assert list(base.to(bytes).len()) == [4, 4, 8, 11]\n\n\n"""
test/test_tsv.py,0,"b'import tubes\n\ndef test_tsv_to_py():\n    tube = tubes.Each([\'a\\tb\\tc\', \'d\\tef\']).to(tubes.TsvRow)\n    assert list(tube) == [[b\'a\', b\'b\', b\'c\'], [b\'d\', b\'ef\']]\n\ndef test_empty_tsv():\n    tube = tubes.Each([\'\']).to(tubes.CsvRow)\n    assert list(tube) == [[b\'\']]\n\ndef test_tsv_one_row():\n    tube = tubes.Each([\'a\\tb\\tc\']).to(tubes.TsvRow).get(1)\n    assert list(tube) == [b\'b\']\n\n\ndef test_tsv_two_rows():\n    tube = tubes.Each([\'a\\tb\\tc\', \'d\\te\\tf\']).to(tubes.TsvRow).get(0)\n    assert list(tube) == [b\'a\', b\'d\']\n\n\ndef test_tsv_uneven_rows():\n    tube = tubes.Each([\'a\', \'b\\tc\', \'d\\te\\t\', \'f\\tg\\th\']).to(tubes.TsvRow).get(2, \'xx\')\n    assert list(tube) == [b\'xx\', b\'xx\', b\'\', b\'h\']\n\ndef test_tsv_uneven_rows_get_many():\n    tube = tubes.Each([\'a\', \'b\\tc\', \'d\\te\\t\', \'f\\tg\\th\']).to(tubes.TsvRow).multi(lambda x: (\n        x.get(0),\n        x.get(1, \'xx\'),\n        x.get(2, \'xx\'),\n    )).to(str, str, str)\n    assert list(tube) == [\n        (\'a\', \'xx\', \'xx\'),\n        (\'b\', \'c\', \'xx\'),\n        (\'d\', \'e\', \'\'),\n        (\'f\', \'g\', \'h\'),\n    ]\n\ndef test_tsv_multi():\n    tube = tubes.Each([\'a\\tb\\tc\', \'d\\te\\tf\']).to(tubes.TsvRow).multi(lambda x:(\n        x.get(0),\n        x.get(1),\n        x.get(2),\n        x.get(3, \'xx\')\n    )).to(str, str, str, str)\n    assert list(tube) == [(\'a\', \'b\', \'c\', \'xx\'), (\'d\', \'e\', \'f\', \'xx\')]\n\n\ndef test_tsv_headers_get_single():\n    tube = tubes.Each([\'a\\tb\\tc\', \'d\\te\\tf\']).tsv(headers=True, split=False).get(\'a\').to(str)\n    assert list(tube) == [\'d\']\n\ndef test_tsv_headers_one_row():\n    tube = tubes.Each([\'a\\tb\\tc\', \'d\\te\\tf\']).tsv(headers=True, split=False).multi(lambda x:(\n        x.get(\'a\'),\n        x.get(1),\n        x.get(2),\n        x.get(\'c\')\n    )).to(str, str, str, str)\n    assert list(tube) == [(\'d\', \'e\', \'f\', \'f\')]\n\n\ndef test_reading_tsv_headers_different_orders():\n    tsv_1 = """"""a\\tb\\tc\n1\\t2\\t3\n4\\t5\\t6\n""""""\n    tsv_2 = """"""c\\ta\\tb\n9\\t7\\t8\n12\\t10\\t11\n""""""\n    tube = tubes.Each([tsv_1, tsv_2]).to(bytes).split().tsv(headers=True, split=False).chunk(1).multi(lambda x:(\n        x.get(\'a\'),\n        x.get(\'b\'),\n        x.get(\'c\')\n    )).to(int, int, int)\n    assert list(tube) == [(1, 2, 3), (4, 5, 6), (7, 8, 9), (10, 11, 12)]\n\n\ndef test_tsv_non_tab_separator():\n    tube = tubes.Each([\'a|b|c\\n\', \'d|e\\tf|g\']).to(bytes).tsv(headers=False, sep=\'|\')\n    assert list(tube) == [[b\'a\', b\'b\', b\'c\'], [b\'d\', b\'e\\tf\', b\'g\']]\n\n\nif __name__ == \'__main__\':\n    test_tsv_non_tab_separator()'"
tools/build_wheels.py,0,"b'\nimport os\nfrom time import sleep\nimport shlex\nfrom functools import partial\nfrom os import path\nimport subprocess\nimport sys\n\nfrom fin import contextlog\n\nLog = partial(contextlog.Log, theme=""mac"")\n\nPROJECT_DIR = path.abspath(path.dirname(path.dirname(__file__)))\n\nWHEELHOUSE = path.join(PROJECT_DIR, ""wheelhouse"")\nREQUIREMENTS = path.join(PROJECT_DIR, ""build_requirements.txt"")\n\n\ndef check_call(*args, output=False):\n    cmdline = "" "".join(shlex.quote(p) for p in args)\n    with Log(""Running: %s"" % cmdline):\n        if output:\n            return subprocess.check_output(cmdline, shell=True).strip().decode(""utf-8"")\n        else:\n            return subprocess.check_call(cmdline, shell=True)\n\n\ndef set_py_version(ver):\n    with Log(""Enabling python: %s"" % ver):\n        previous_version = check_call(\'pyenv\', \'global\', output=True)\n        check_call(""pyenv"", ""install"", ""-s"", ver)\n        check_call(""pyenv"", ""global"", ver)\n        try:\n            sleep(1)\n            current_version = check_call(""python"", ""--version"", output=True)\n            if current_version != ""Python %s"" % (ver, ):\n                check_call(""which"", ""python"", )\n                check_call(""ls"", ""-lah"", check_call(""which"", ""python"", output=True))\n                check_call(""python"", ""-c"", ""import re; print(re)"")\n                raise ValueError(""Requested version: %r is not current version: %r"" % (ver, current_version))\n            with Log(""Updating pip""):\n                check_call(""pip"", ""install"", ""-q"", ""--upgrade"", \'pip\')\n            with Log(""Installing build dependencies""):\n                check_call(""pip"", ""install"", ""-q"", ""-r"", REQUIREMENTS)\n            with Log(""Cleaning build intermediate files""):\n                check_call(""make"", ""clean-py"",  ""clean-cpp"")\n            with Log(""Running tests""):\n                check_call(""make"", ""test"")\n            with Log(""Building wheel""):\n                check_call(""pip"", ""wheel"", ""."", ""-w"", WHEELHOUSE)\n        finally:\n            check_call(""pyenv"", ""global"", previous_version)\n\n\ndef build_osx(ver):\n    with Log(""Building for OSX python %s"" % ver):\n        set_py_version(ver)\n\ndef build_anylinux(ver):\n    check_call(\n        ""docker"", ""run"", ""-it"", ""--rm"",\n        \'-v\', ""%s:/pytubes"" % PROJECT_DIR,\n        ""quay.io/pypa/manylinux2010_x86_64"",\n        ""/pytubes/tools/build_anylinux.sh"", ver\n    )\n\n\ndef main():\n    with Log(""Patching environment""):\n        os.environ[\'PYENV_VERSION\'] = """"\n        os.environ[\'PATH\'] = path.join(check_call(""pyenv"", ""root"", output=True), ""shims"") + "":"" + os.environ[""PATH""]\n    with Log(""Getting version"") as l:\n        version = check_call(""python"", ""tools/version.py"", output=True)\n        l.format(""Version: %s"", version)\n    with Log(""Building OSX wheels""):\n        build_osx(""3.5.5"")\n        build_osx(""3.6.4"")\n        build_osx(""3.7.1"")\n    with Log(""Building anylinux wheels""):\n        build_anylinux(""cp35-cp35m"")\n        build_anylinux(""cp36-cp36m"")\n        build_anylinux(""cp37-cp37m"")\n    with Log(""Tagging""):\n        check_call(""git"", ""tag"", ""-a"", version, ""-m"", ""build_wheels.py Tagging version %s"" % version)\n\n\n\n\n\nif __name__ == \'__main__\':\n    sys.exit(main())'"
tools/make_cdef.py,0,"b'import re\nimport sys\nfrom collections import defaultdict\nfrom itertools import chain\nfrom os import path\n\nimport yaml\nfrom jinja2 import Template\n\nPROJECT_DIR = path.dirname(path.dirname(__file__))\n\n\nSTART_MARKER = re.escape(""/*<-"")\nEND_MARKER = re.escape(""->*/"")\ndef find_blocks(file_name):\n    with open(file_name) as fp:\n        matches = re.findall(START_MARKER + ""(.*?)"" + END_MARKER, fp.read(), re.M | re.S)\n    blocks = []\n    for match in matches:\n        lines = [l for l in match.splitlines() if l.strip != """"]\n        padding = len(lines[0]) - len(lines[0].lstrip())\n        doc = ""\\n"".join([l[padding:] for l in lines])\n        blocks.append(yaml.load(doc))\n    return blocks\n\n\nclass Iter:\n\n    def __init__(self, name, spec, file_name):\n        self.file_name = file_name\n        self.name = name\n        self.spec = {""init"": spec} if isinstance(spec, list) else spec\n\n    @property\n    def templated_name(self):\n        template = self.spec.get(""template"")\n        if template:\n            if isinstance(template, (list, tuple)):\n                return ""{0}[{1}]"".format(self.name, \', \'.join(template))\n            return ""{0}[{1}]"".format(self.name, template)\n        return self.name\n\n    @property\n    def extra(self):\n        return self.spec.get(""extra"" ,"""")\n\n\n    @property\n    def constructor_args(self):\n        return "", "".join(self.spec[\'init\'])\n\n\nclass Prop:\n    def __init__(self, spec):\n        if isinstance(spec, str):\n            ty, name = spec.split("" "", 1)\n            if ""="" in name:\n                name, default = name.split(""="", 1)\n                self.spec = {""type"": ty, ""name"": name, ""default"": default}\n            else:\n                self.spec = {""type"": ty, ""name"": name}\n\n        else:\n            self.spec = spec\n\n    def __getattr__(self, name):\n        return self.spec[name]\n\n    @property\n    def has_default(self):\n        return ""default"" in self.spec\n\n    @property\n    def dtypes(self):\n        return self.spec.get(""dtypes"", ())\n\n    @property\n    def printable(self):\n        return self.spec.get(""print"", not self.is_tube)\n\n    @property\n    def is_tube(self):\n        return self.type == ""Tube""\n\n\nclass Tube:\n\n    def __init__(self, name, spec, file_name, iters):\n        self._iters = iters\n        self.file_name = file_name\n        self.name = name\n        self.spec = spec\n\n    @property\n    def props(self):\n        return [Prop(p) for p in self.spec[""props""]]\n\n    def __getattr__(self, name):\n        return self.spec.get(name, None)\n\n    @property\n    def init_args(self):\n        args = []\n        for p in self.props:\n            if ""default"" in p.spec:\n                args.append(""{0} {1}={2}"".format(p.type, p.name, p.default))\n            else:\n                args.append(""{0} {1}"".format(p.type, p.name))\n        return "", "".join(args)\n\n    @property\n    def inputs(self):\n        return [p for p in self.props if p.is_tube]\n\n    @property\n    def chains(self):\n        return self.spec.get(""chains"", ())\n\n    @property\n    def iter(self):\n        return self._iters[self.spec[\'iter\'][0]]\n\n    @property\n    def iter_args(self):\n        return self.spec[\'iter\'][1]\n\n    @property\n    def methods(self):\n        return self.spec.get(""methods"", """")\n\n\n\ndef make_cdef(file_names):\n    iters = {}\n    tubes = {}\n    fns = []\n\n    for file_name in file_names:\n        file_name = path.abspath(file_name)\n        for block in find_blocks(file_name):\n            if ""Fn"" in block:\n                fns.append((file_name, block[""Fn""]))\n            if ""Iter"" in block:\n                for name, values in block[""Iter""].items():\n                    iters[name] = Iter(name, values, file_name)\n            if ""Tube"" in block:\n                for name, values in block[""Tube""].items():\n                    tubes[name] = Tube(name, values, file_name, iters)\n\n    with open(path.join(PROJECT_DIR, ""tools/defn.tmpl""), ""r"") as fh:\n        template = Template(fh.read())\n\n    print(template.render(\n        iters=iters,\n        tubes=tubes,\n        fns=fns,\n        enumerate=enumerate,\n        len=len\n    ))\n\n\nif __name__ == \'__main__\':\n    make_cdef(sys.argv[1:])\n'"
tools/perf.py,0,"b'import time\nimport sys\nimport os\nimport tubes\nimport gzip\nimport json\n\nDATA_DIR = ""../data""\nFILES = [os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR) if f.startswith(""pypi-downloads"") and f.endswith(""jsonz"")]\nSKIP = 0\nTAKE = 100000\n\nKEYS = (\n    (""timestamp"", ),\n    (""country_code"", ),\n    (""url"", ),\n    (""file"", ""filename""),\n    (""file"", ""project""),\n    (""details"", ""installer"", ""name""),\n    (""details"", ""python""),\n    (""details"", ""system""),\n    (""details"", ""system"", ""name""),\n    (""details"", ""cpu""),\n    (""details"", ""distro"", ""libc"", ""lib""),\n    (""details"", ""distro"", ""libc"", ""version""),\n)\n\ndef py_version():\n    skip = SKIP\n    take = TAKE\n    results = []\n    for file_name in FILES:\n        with gzip.open(file_name, ""rt"") as fp:\n            for line in fp:\n                data = json.loads(line)\n                if skip:\n                    skip -= 1\n                    continue\n                if data.get(\'country_code\') != ""GB"":\n                    continue\n                if not take:\n                    return results\n                take -= 1\n                row = []\n                for path in KEYS:\n                    base = data\n                    for part in path:\n                        base = base.get(part, None)\n                        if base is None:\n                            break\n                    row.append(base)\n                results.append(row)\n    return results\n\ndef make_getters(x):\n    getters = []\n    for path in KEYS:\n        base = x\n        for part in path:\n            base = base.get(part, \'null\')\n        getters.append(base)\n    return tuple(getters)\n\ndef tubes_version():\n    x = (tubes.Each(FILES)\n        .map_files()\n        .gunzip()\n        .split(b\'\\n\')\n        .skip(SKIP)\n        .json()\n        .skip_unless(lambda x: x.get(\'country_code\', \'""""\').to(tubes.Utf8).equals(""GB""))\n        .first(TAKE)\n        .multi(make_getters)\n    )\n    return list(x)\n\ndef tubes_version_2():\n    x = (tubes.Each(FILES)\n        .read_files()\n        .gunzip(stream=True)\n        .split(b\'\\n\')\n        .chunk(1)\n        .skip(SKIP)\n        .json()\n        .skip_unless(lambda x: x.get(\'country_code\', \'""""\').to(tubes.Utf8).equals(""GB""))\n        .first(TAKE)\n        .multi(make_getters)\n    )\n    return list(x)\n\ndef compare():\n    print(""Skipping: {0}, Taking: {1}"".format(SKIP, TAKE))\n    print(""Tubes v1"")\n    a = time.perf_counter()\n    tube_1_vals = tubes_version()\n    b = time.perf_counter()\n    tubes_1_time = b - a\n    print(""Took: {0:.4f} s"".format(tubes_1_time))\n    print(""Tubes v2"")\n    b = time.perf_counter()\n    tube_2_vals = tubes_version_2()\n    c = time.perf_counter()\n    tubes_2_time = c - b\n    print(""Took: {0:.4f} s"".format(tubes_2_time))\n    print(""Py version"")\n    c = time.perf_counter()\n    py_vals = py_version()\n    d = time.perf_counter()\n    py_time = d - c\n    print(""Took: {0:.4f} s"".format(py_time))\n    best = min(tubes_1_time, tubes_2_time)\n    print(""Speedup: {0:.2f} x"".format(py_time/best))\n\n    print(py_vals[0])\n    print(tube_2_vals[0])\n    print(tube_1_vals[0])\n\n    assert tuple(py_vals[-1]) == tube_2_vals[-1], (tuple(py_vals[-1]), tube_2_vals[-1])\n    assert tuple(py_vals[-1]) == tube_1_vals[-1], (tuple(py_vals[-1]), tube_1_vals[-1])\n    # assert len(pyx) == len(tubesx), ""Different lengths""\n    # tubex_str = [x.decode(\'utf-8\') if x is not None else x for x in tubesx]\n    # same = [a==b for a, b in zip(pyx, tubex_str)]\n    # assert pyx == tubex_str, list(zip(pyx, tubex_str, same))\n\ndef main(ty):\n    global SKIP, TAKE\n    if ty == ""perf"":\n        SKIP = 1\n        TAKE = 2000000\n        print(""Perf test"")\n        result = tubes_version_2()\n        print(""Got: {0}"".format(len(result)))\n    else:\n        print(""== speed test =="")\n        compare()\n\nif __name__ == \'__main__\':\n    print(tubes)\n    main(\'run\' if len(sys.argv) < 2 else sys.argv[1])'"
tools/perf2.py,0,"b'import time\nimport sys\nimport glob\nimport os\nfrom os import path\nimport tubes\nimport gzip\nimport json\n\nDATA_DIR = ""../data/extracted""\nFILES = glob.glob(path.join(DATA_DIR, ""*.json""))\nSKIP = 0\nTAKE = 100000\n\nKEYS = (\n    # (""timestamp"", ),\n    (""country_code"", ),\n    (""url"", ),\n    (""file"", ""filename""),\n    (""file"", ""project""),\n    (""details"", ""installer"", ""name""),\n    (""details"", ""python""),\n    # (""details"", ""system""),\n    (""details"", ""system"", ""name""),\n    # (""details"", ""cpu""),\n    # (""details"", ""distro"", ""libc"", ""lib""),\n    # (""details"", ""distro"", ""libc"", ""version""),\n)\n\ndef py_version():\n    skip = SKIP\n    take = TAKE\n    results = []\n    for file_name in FILES:\n        with open(file_name, ""rt"") as fp:\n            for line in fp:\n                data = json.loads(line)\n                if skip:\n                    skip -= 1\n                    continue\n                if data.get(\'country_code\') != ""GB"":\n                    continue\n                if not take:\n                    return results\n                take -= 1\n                row = []\n                for path in KEYS:\n                    base = data\n                    for part in path:\n                        base = base.get(part, None)\n                        if base is None:\n                            break\n                    row.append(base)\n                results.append(row)\n    return results\n\n\ndef make_getters(x):\n    getters = []\n    for path in KEYS:\n        base = x\n        for part in path:\n            base = base.get(part, \'null\')\n        getters.append(base)\n    return tuple(getters)\n\n\ndef tubes_version():\n    x = (tubes.Each(FILES)\n        .read_files()\n        .split(b\'\\n\')\n        .skip(SKIP)\n        .json()\n        .skip_unless(lambda x: x.get(\'country_code\', \'""""\').to(tubes.Utf8).equals(""GB""))\n        .first(TAKE)\n        .multi(make_getters)\n    )\n    return list(x)\n\ndef compare():\n    print(""Skipping: {0}, Taking: {1}"".format(SKIP, TAKE))\n    print(""Tubes v2"")\n    b = time.perf_counter()\n    tube_vals = tubes_version()\n    c = time.perf_counter()\n    tube_time = c - b\n    print(""Took: {0:.4f} s"".format(tube_time))\n    print(""Py version"")\n    c = time.perf_counter()\n    py_vals = py_version()\n    d = time.perf_counter()\n    py_time = d - c\n    print(""Took: {0:.4f} s"".format(py_time))\n    print(""Speedup: {0:.2f} x"".format(py_time/tube_time))\n\n    print(py_vals[-1])\n    print(tube_vals[-1])\n\n    assert tuple(py_vals[-1]) == tube_vals[-1], (tuple(py_vals[-1]), tube_vals[-1])\n    assert len(py_vals) == len(tube_vals)\n    # assert len(pyx) == len(tubesx), ""Different lengths""\n    # tubex_str = [x.decode(\'utf-8\') if x is not None else x for x in tubesx]\n    # same = [a==b for a, b in zip(pyx, tubex_str)]\n    # assert pyx == tubex_str, list(zip(pyx, tubex_str, same))\n\ndef main(ty):\n    global SKIP, TAKE\n    if ty == ""perf"":\n        SKIP = 1\n        TAKE = 2000000\n        print(""Perf test"")\n        result = tubes_version()\n        print(""Got: {0}"".format(len(result)))\n    else:\n        print(""== speed test =="")\n        compare()\n\nif __name__ == \'__main__\':\n    print(tubes)\n    main(\'run\' if len(sys.argv) < 2 else sys.argv[1])'"
tools/version-list.py,0,"b'import re\nfrom pathlib import Path\n\nROOT = Path(""."").resolve()\n\n\ndef get_version_list():\n\tsubdirs = [x.name for x in ROOT.iterdir() if x.is_dir()]\n\treturn sorted(subdirs)\n\n\nPATTERN = r""PYTUBES\\-BEGIN\\-VERSION\\-LIST.*PYTUBES\\-END\\-VERSION\\-LIST""\n\ndef update_versions(versions):\n\toption_list = """".join([\'<option value=""%s"">%s</option>\' % (v, v) for v in versions])\n\treplacement = ""PYTUBES-BEGIN-VERSION-LIST -->"" + option_list + ""<!-- PYTUBES-END-VERSION-LIST""\n\tfor path in ROOT.glob(""**/*.html""):\n\t\twith path.open() as fh:\n\t\t\tcontent = fh.read()\n\t\tnew_content = re.sub(PATTERN, replacement, content, flags=re.M + re.S)\n\t\tif content != new_content:\n\t\t\tprint(""Updating: "" + path.name)\n\t\t\twith path.open(""w"") as fh:\n\t\t\t\tfh.write(new_content)\n\n\nif __name__ == \'__main__\':\n\tversions = get_version_list()\n\tupdate_versions(versions)'"
tools/version.py,0,"b'from os import path\nimport re\n\nPROJECT_DIR = path.dirname(path.dirname(__file__))\nVERSION_FILE = path.join(PROJECT_DIR, \'pyx\', \'version.pxi\')\n\ndef main():\n    with open(VERSION_FILE, ""r"") as fh:\n        print(""%s.%s.%s"" % re.match(r\'__version__\\s*=\\s*\\((\\d+),\\s*(\\d+),\\s*(\\d+)\\)\', fh.read()).groups())\n\n\nif __name__ == \'__main__\':\n    main()'"
tools/scripts/get-version.py,0,"b'import pathlib\nfrom os import path\nimport re\n\nTHIS_FILE = pathlib.Path(__file__).resolve()\n\nPROJECT_DIR = THIS_FILE.parent.parent.parent\nVERSION_FILE = PROJECT_DIR / ""pyx"" / ""version.pxi""\n\ndef main():\n    with VERSION_FILE.open() as fh:\n        print(""%s.%s.%s"" % re.match(r\'__version__\\s*=\\s*\\((\\d+),\\s*(\\d+),\\s*(\\d+)\\)\', fh.read()).groups())\n\n\nif __name__ == \'__main__\':\n    main()'"
tools/scripts/update-version.py,0,"b'import pathlib\nfrom os import environ\nimport re\n\nRELEASE_TAG_PATTERN = r""refs/tags/\\d.\\d.\\d""\n\nTHIS_FILE = pathlib.Path(__file__).resolve()\n\nPROJECT_DIR = THIS_FILE.parent.parent.parent\nVERSION_FILE = PROJECT_DIR / ""pyx"" / ""version.pxi""\n\ndef get_version():\n    ref = environ.get(""GITHUB_REF"", ""__LOCAL__"")\n\n    tag_match = re.match(RELEASE_TAG_PATTERN, ref)\n    if tag_match:\n        major = int(tag_match.group(1))\n        minor = int(tag_match.group(2))\n        maint = int(tag_match.group(3))\n        return (major, minor, maint)\n\n    return (0, 0, 99)\n\n\n\nif __name__ == \'__main__\':\n    version = get_version()\n    with VERSION_FILE.open(""w"") as fh:\n        fh.write(f""__version__ = {repr(version)}\\n"")'"
