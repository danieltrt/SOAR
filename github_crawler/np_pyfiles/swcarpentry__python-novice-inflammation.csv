file_path,api_count,code
bin/lesson_check.py,0,"b'#!/usr/bin/env python3\n\n""""""\nCheck lesson files and their contents.\n""""""\n\n\nimport os\nimport glob\nimport re\nfrom argparse import ArgumentParser\n\nfrom util import (Reporter, read_markdown, load_yaml, check_unwanted_files,\n                  require)\n\n__version__ = \'0.3\'\n\n# Where to look for source Markdown files.\nSOURCE_DIRS = [\'\', \'_episodes\', \'_extras\']\n\n# Where to look for source Rmd files.\nSOURCE_RMD_DIRS = [\'_episodes_rmd\']\n\n# Required files: each entry is (\'path\': YAML_required).\n# FIXME: We do not yet validate whether any files have the required\n#   YAML headers, but should in the future.\n# The \'%\' is replaced with the source directory path for checking.\n# Episodes are handled specially, and extra files in \'_extras\' are also handled\n# specially. This list must include all the Markdown files listed in the\n# \'bin/initialize\' script.\nREQUIRED_FILES = {\n    \'%/CODE_OF_CONDUCT.md\': True,\n    \'%/CONTRIBUTING.md\': False,\n    \'%/LICENSE.md\': True,\n    \'%/README.md\': False,\n    \'%/_extras/discuss.md\': True,\n    \'%/_extras/guide.md\': True,\n    \'%/index.md\': True,\n    \'%/reference.md\': True,\n    \'%/setup.md\': True,\n}\n\n# Episode filename pattern.\nP_EPISODE_FILENAME = re.compile(r\'/_episodes/(\\d\\d)-[-\\w]+.md$\')\n\n# Pattern to match lines ending with whitespace.\nP_TRAILING_WHITESPACE = re.compile(r\'\\s+$\')\n\n# Pattern to match figure references in HTML.\nP_FIGURE_REFS = re.compile(r\'<img[^>]+src=""([^""]+)""[^>]*>\')\n\n# Pattern to match internally-defined Markdown links.\nP_INTERNAL_LINK_REF = re.compile(r\'\\[([^\\]]+)\\]\\[([^\\]]+)\\]\')\n\n# Pattern to match reference links (to resolve internally-defined references).\nP_INTERNAL_LINK_DEF = re.compile(r\'^\\[([^\\]]+)\\]:\\s*(.+)\')\n\n# Pattern to match {% include ... %} statements\nP_INTERNAL_INCLUDE_LINK = re.compile(r\'^{% include ([^ ]*) %}$\')\n\n# What kinds of blockquotes are allowed?\nKNOWN_BLOCKQUOTES = {\n    \'callout\',\n    \'challenge\',\n    \'checklist\',\n    \'discussion\',\n    \'keypoints\',\n    \'objectives\',\n    \'prereq\',\n    \'quotation\',\n    \'solution\',\n    \'testimonial\'\n}\n\n# What kinds of code fragments are allowed?\nKNOWN_CODEBLOCKS = {\n    \'error\',\n    \'output\',\n    \'source\',\n    \'language-bash\',\n    \'html\',\n    \'language-make\',\n    \'language-matlab\',\n    \'language-python\',\n    \'language-r\',\n    \'language-shell\',\n    \'language-sql\'\n}\n\n# What fields are required in teaching episode metadata?\nTEACHING_METADATA_FIELDS = {\n    (\'title\', str),\n    (\'teaching\', int),\n    (\'exercises\', int),\n    (\'questions\', list),\n    (\'objectives\', list),\n    (\'keypoints\', list)\n}\n\n# What fields are required in break episode metadata?\nBREAK_METADATA_FIELDS = {\n    (\'layout\', str),\n    (\'title\', str),\n    (\'break\', int)\n}\n\n# How long are lines allowed to be?\n# Please keep this in sync with .editorconfig!\nMAX_LINE_LEN = 100\n\n\ndef main():\n    """"""Main driver.""""""\n\n    args = parse_args()\n    args.reporter = Reporter()\n    check_config(args.reporter, args.source_dir)\n    check_source_rmd(args.reporter, args.source_dir, args.parser)\n    args.references = read_references(args.reporter, args.reference_path)\n\n    docs = read_all_markdown(args.source_dir, args.parser)\n    check_fileset(args.source_dir, args.reporter, list(docs.keys()))\n    check_unwanted_files(args.source_dir, args.reporter)\n    for filename in list(docs.keys()):\n        checker = create_checker(args, filename, docs[filename])\n        checker.check()\n\n    args.reporter.report()\n    if args.reporter.messages and not args.permissive:\n        exit(1)\n\n\ndef parse_args():\n    """"""Parse command-line arguments.""""""\n\n    parser = ArgumentParser(description=""""""Check episode files in a lesson."""""")\n    parser.add_argument(\'-l\', \'--linelen\',\n                        default=False,\n                        action=""store_true"",\n                        dest=\'line_lengths\',\n                        help=\'Check line lengths\')\n    parser.add_argument(\'-p\', \'--parser\',\n                        default=None,\n                        dest=\'parser\',\n                        help=\'path to Markdown parser\')\n    parser.add_argument(\'-r\', \'--references\',\n                        default=None,\n                        dest=\'reference_path\',\n                        help=\'path to Markdown file of external references\')\n    parser.add_argument(\'-s\', \'--source\',\n                        default=os.curdir,\n                        dest=\'source_dir\',\n                        help=\'source directory\')\n    parser.add_argument(\'-w\', \'--whitespace\',\n                        default=False,\n                        action=""store_true"",\n                        dest=\'trailing_whitespace\',\n                        help=\'Check for trailing whitespace\')\n    parser.add_argument(\'--permissive\',\n                        default=False,\n                        action=""store_true"",\n                        dest=\'permissive\',\n                        help=\'Do not raise an error even if issues are detected\')\n\n    args, extras = parser.parse_known_args()\n    require(args.parser is not None,\n            \'Path to Markdown parser not provided\')\n    require(not extras,\n            \'Unexpected trailing command-line arguments ""{0}""\'.format(extras))\n\n    return args\n\n\ndef check_config(reporter, source_dir):\n    """"""Check configuration file.""""""\n\n    config_file = os.path.join(source_dir, \'_config.yml\')\n    config = load_yaml(config_file)\n    reporter.check_field(config_file, \'configuration\',\n                         config, \'kind\', \'lesson\')\n    reporter.check_field(config_file, \'configuration\',\n                         config, \'carpentry\', (\'swc\', \'dc\', \'lc\', \'cp\'))\n    reporter.check_field(config_file, \'configuration\', config, \'title\')\n    reporter.check_field(config_file, \'configuration\', config, \'email\')\n\n    for defaults in [\n            {\'values\': {\'root\': \'.\', \'layout\': \'page\'}},\n            {\'values\': {\'root\': \'..\', \'layout\': \'episode\'}, \'scope\': {\'type\': \'episodes\', \'path\': \'\'}},\n            {\'values\': {\'root\': \'..\', \'layout\': \'page\'}, \'scope\': {\'type\': \'extras\', \'path\': \'\'}}\n            ]:\n        reporter.check(defaults in config.get(\'defaults\', []),\n                   \'configuration\',\n                   \'""root"" not set to ""."" in configuration\')\n\ndef check_source_rmd(reporter, source_dir, parser):\n    """"""Check that Rmd episode files include `source: Rmd`""""""\n\n    episode_rmd_dir = [os.path.join(source_dir, d) for d in SOURCE_RMD_DIRS]\n    episode_rmd_files = [os.path.join(d, \'*.Rmd\') for d in episode_rmd_dir]\n    results = {}\n    for pat in episode_rmd_files:\n        for f in glob.glob(pat):\n            data = read_markdown(parser, f)\n            dy = data[\'metadata\']\n            if dy:\n                reporter.check_field(f, \'episode_rmd\',\n                                     dy, \'source\', \'Rmd\')\n\ndef read_references(reporter, ref_path):\n    """"""Read shared file of reference links, returning dictionary of valid references\n    {symbolic_name : URL}\n    """"""\n\n    if not ref_path:\n        raise Warning(""No filename has been provided."")\n\n    result = {}\n    urls_seen = set()\n\n    with open(ref_path, \'r\') as reader:\n        for (num, line) in enumerate(reader, 1):\n\n            if P_INTERNAL_INCLUDE_LINK.search(line): continue\n\n            m = P_INTERNAL_LINK_DEF.search(line)\n\n            message = \'{}: {} not a valid reference: {}\'\n            require(m, message.format(ref_path, num, line.rstrip()))\n\n            name = m.group(1)\n            url = m.group(2)\n\n            message = \'Empty reference at {0}:{1}\'\n            require(name, message.format(ref_path, num))\n\n            unique_name = name not in result\n            unique_url = url not in urls_seen\n\n            reporter.check(unique_name,\n                           ref_path,\n                           \'Duplicate reference name {0} at line {1}\',\n                           name, num)\n\n            reporter.check(unique_url,\n                           ref_path,\n                           \'Duplicate definition of URL {0} at line {1}\',\n                           url, num)\n\n            result[name] = url\n            urls_seen.add(url)\n\n    return result\n\n\ndef read_all_markdown(source_dir, parser):\n    """"""Read source files, returning\n    {path : {\'metadata\':yaml, \'metadata_len\':N, \'text\':text, \'lines\':[(i, line, len)], \'doc\':doc}}\n    """"""\n\n    all_dirs = [os.path.join(source_dir, d) for d in SOURCE_DIRS]\n    all_patterns = [os.path.join(d, \'*.md\') for d in all_dirs]\n    result = {}\n    for pat in all_patterns:\n        for filename in glob.glob(pat):\n            data = read_markdown(parser, filename)\n            if data:\n                result[filename] = data\n    return result\n\n\ndef check_fileset(source_dir, reporter, filenames_present):\n    """"""Are all required files present? Are extraneous files present?""""""\n\n    # Check files with predictable names.\n    required = [p.replace(\'%\', source_dir) for p in REQUIRED_FILES]\n    missing = set(required) - set(filenames_present)\n    for m in missing:\n        reporter.add(None, \'Missing required file {0}\', m)\n\n    # Check episode files\' names.\n    seen = []\n    for filename in filenames_present:\n        if \'_episodes\' not in filename:\n            continue\n        m = P_EPISODE_FILENAME.search(filename)\n        if m and m.group(1):\n            seen.append(m.group(1))\n        else:\n            reporter.add(\n                None, \'Episode {0} has badly-formatted filename\', filename)\n\n    # Check for duplicate episode numbers.\n    reporter.check(len(seen) == len(set(seen)),\n                   None,\n                   \'Duplicate episode numbers {0} vs {1}\',\n                   sorted(seen), sorted(set(seen)))\n\n    # Check that numbers are consecutive.\n    seen = sorted([int(s) for s in seen])\n    clean = True\n    for i in range(len(seen) - 1):\n        clean = clean and ((seen[i+1] - seen[i]) == 1)\n    reporter.check(clean,\n                   None,\n                   \'Missing or non-consecutive episode numbers {0}\',\n                   seen)\n\n\ndef create_checker(args, filename, info):\n    """"""Create appropriate checker for file.""""""\n\n    for (pat, cls) in CHECKERS:\n        if pat.search(filename):\n            return cls(args, filename, **info)\n    return NotImplemented\n\nclass CheckBase:\n    """"""Base class for checking Markdown files.""""""\n\n    def __init__(self, args, filename, metadata, metadata_len, text, lines, doc):\n        """"""Cache arguments for checking.""""""\n\n        self.args = args\n        self.reporter = self.args.reporter  # for convenience\n        self.filename = filename\n        self.metadata = metadata\n        self.metadata_len = metadata_len\n        self.text = text\n        self.lines = lines\n        self.doc = doc\n\n        self.layout = None\n\n    def check(self):\n        """"""Run tests.""""""\n\n        self.check_metadata()\n        self.check_line_lengths()\n        self.check_trailing_whitespace()\n        self.check_blockquote_classes()\n        self.check_codeblock_classes()\n        self.check_defined_link_references()\n\n    def check_metadata(self):\n        """"""Check the YAML metadata.""""""\n\n        self.reporter.check(self.metadata is not None,\n                            self.filename,\n                            \'Missing metadata entirely\')\n\n        if self.metadata and (self.layout is not None):\n            self.reporter.check_field(\n                self.filename, \'metadata\', self.metadata, \'layout\', self.layout)\n\n    def check_line_lengths(self):\n        """"""Check the raw text of the lesson body.""""""\n\n        if self.args.line_lengths:\n            over = [i for (i, l, n) in self.lines if (\n                n > MAX_LINE_LEN) and (not l.startswith(\'!\'))]\n            self.reporter.check(not over,\n                                self.filename,\n                                \'Line(s) too long: {0}\',\n                                \', \'.join([str(i) for i in over]))\n\n    def check_trailing_whitespace(self):\n        """"""Check for whitespace at the ends of lines.""""""\n\n        if self.args.trailing_whitespace:\n            trailing = [\n                i for (i, l, n) in self.lines if P_TRAILING_WHITESPACE.match(l)]\n            self.reporter.check(not trailing,\n                                self.filename,\n                                \'Line(s) end with whitespace: {0}\',\n                                \', \'.join([str(i) for i in trailing]))\n\n    def check_blockquote_classes(self):\n        """"""Check that all blockquotes have known classes.""""""\n\n        for node in self.find_all(self.doc, {\'type\': \'blockquote\'}):\n            cls = self.get_val(node, \'attr\', \'class\')\n            self.reporter.check(cls in KNOWN_BLOCKQUOTES,\n                                (self.filename, self.get_loc(node)),\n                                \'Unknown or missing blockquote type {0}\',\n                                cls)\n\n    def check_codeblock_classes(self):\n        """"""Check that all code blocks have known classes.""""""\n\n        for node in self.find_all(self.doc, {\'type\': \'codeblock\'}):\n            cls = self.get_val(node, \'attr\', \'class\')\n            self.reporter.check(cls in KNOWN_CODEBLOCKS,\n                                (self.filename, self.get_loc(node)),\n                                \'Unknown or missing code block type {0}\',\n                                cls)\n\n    def check_defined_link_references(self):\n        """"""Check that defined links resolve in the file.\n\n        Internally-defined links match the pattern [text][label].\n        """"""\n\n        result = set()\n        for node in self.find_all(self.doc, {\'type\': \'text\'}):\n            for match in P_INTERNAL_LINK_REF.findall(node[\'value\']):\n                text = match[0]\n                link = match[1]\n                if link not in self.args.references:\n                    result.add(\'""{0}""=>""{1}""\'.format(text, link))\n        self.reporter.check(not result,\n                            self.filename,\n                            \'Internally-defined links may be missing definitions: {0}\',\n                            \', \'.join(sorted(result)))\n\n    def find_all(self, node, pattern, accum=None):\n        """"""Find all matches for a pattern.""""""\n\n        assert isinstance(pattern, dict), \'Patterns must be dictionaries\'\n        if accum is None:\n            accum = []\n        if self.match(node, pattern):\n            accum.append(node)\n        for child in node.get(\'children\', []):\n            self.find_all(child, pattern, accum)\n        return accum\n\n    def match(self, node, pattern):\n        """"""Does this node match the given pattern?""""""\n\n        for key in pattern:\n            if key not in node:\n                return False\n            val = pattern[key]\n            if isinstance(val, str):\n                if node[key] != val:\n                    return False\n            elif isinstance(val, dict):\n                if not self.match(node[key], val):\n                    return False\n        return True\n\n    @staticmethod\n    def get_val(node, *chain):\n        """"""Get value one or more levels down.""""""\n\n        curr = node\n        for selector in chain:\n            curr = curr.get(selector, None)\n            if curr is None:\n                break\n        return curr\n\n    def get_loc(self, node):\n        """"""Convenience method to get node\'s line number.""""""\n\n        result = self.get_val(node, \'options\', \'location\')\n        if self.metadata_len is not None:\n            result += self.metadata_len\n        return result\n\n\nclass CheckNonJekyll(CheckBase):\n    """"""Check a file that isn\'t translated by Jekyll.""""""\n\n    def check_metadata(self):\n        self.reporter.check(self.metadata is None,\n                            self.filename,\n                            \'Unexpected metadata\')\n\n\nclass CheckIndex(CheckBase):\n    """"""Check the main index page.""""""\n\n    def __init__(self, args, filename, metadata, metadata_len, text, lines, doc):\n        super().__init__(args, filename, metadata, metadata_len, text, lines, doc)\n        self.layout = \'lesson\'\n\n    def check_metadata(self):\n        super().check_metadata()\n        self.reporter.check(self.metadata.get(\'root\', \'\') == \'.\',\n                            self.filename,\n                            \'Root not set to "".""\')\n\n\nclass CheckEpisode(CheckBase):\n    """"""Check an episode page.""""""\n\n    def check(self):\n        """"""Run extra tests.""""""\n\n        super().check()\n        self.check_reference_inclusion()\n\n    def check_metadata(self):\n        super().check_metadata()\n        if self.metadata:\n            if \'layout\' in self.metadata:\n                if self.metadata[\'layout\'] == \'break\':\n                    self.check_metadata_fields(BREAK_METADATA_FIELDS)\n                else:\n                    self.reporter.add(self.filename,\n                                      \'Unknown episode layout ""{0}""\',\n                                      self.metadata[\'layout\'])\n            else:\n                self.check_metadata_fields(TEACHING_METADATA_FIELDS)\n\n    def check_metadata_fields(self, expected):\n        """"""Check metadata fields.""""""\n        for (name, type_) in expected:\n            if name not in self.metadata:\n                self.reporter.add(self.filename,\n                                  \'Missing metadata field {0}\',\n                                  name)\n            elif not isinstance(self.metadata[name], type_):\n                self.reporter.add(self.filename,\n                                  \'""{0}"" has wrong type in metadata ({1} instead of {2})\',\n                                  name, type(self.metadata[name]), type_)\n\n    def check_reference_inclusion(self):\n        """"""Check that links file has been included.""""""\n\n        if not self.args.reference_path:\n            return\n\n        for (i, last_line, line_len) in reversed(self.lines):\n            if last_line:\n                break\n\n        require(last_line,\n                \'No non-empty lines in {0}\'.format(self.filename))\n\n        include_filename = os.path.split(self.args.reference_path)[-1]\n        if include_filename not in last_line:\n            self.reporter.add(self.filename,\n                              \'episode does not include ""{0}""\',\n                              include_filename)\n\n\nclass CheckReference(CheckBase):\n    """"""Check the reference page.""""""\n\n    def __init__(self, args, filename, metadata, metadata_len, text, lines, doc):\n        super().__init__(args, filename, metadata, metadata_len, text, lines, doc)\n        self.layout = \'reference\'\n\n\nclass CheckGeneric(CheckBase):\n    """"""Check a generic page.""""""\n\n    def __init__(self, args, filename, metadata, metadata_len, text, lines, doc):\n        super().__init__(args, filename, metadata, metadata_len, text, lines, doc)\n\n\nCHECKERS = [\n    (re.compile(r\'CONTRIBUTING\\.md\'), CheckNonJekyll),\n    (re.compile(r\'README\\.md\'), CheckNonJekyll),\n    (re.compile(r\'index\\.md\'), CheckIndex),\n    (re.compile(r\'reference\\.md\'), CheckReference),\n    (re.compile(r\'_episodes/.*\\.md\'), CheckEpisode),\n    (re.compile(r\'.*\\.md\'), CheckGeneric)\n]\n\n\nif __name__ == \'__main__\':\n    main()\n'"
bin/lesson_initialize.py,0,"b'#!/usr/bin/env python3\n\n""""""Initialize a newly-created repository.""""""\n\n\nimport sys\nimport os\nimport shutil\n\nBOILERPLATE = (\n    \'.travis.yml\',\n    \'AUTHORS\',\n    \'CITATION\',\n    \'CONTRIBUTING.md\',\n    \'README.md\',\n    \'_config.yml\',\n    \'_episodes/01-introduction.md\',\n    \'_extras/about.md\',\n    \'_extras/discuss.md\',\n    \'_extras/figures.md\',\n    \'_extras/guide.md\',\n    \'index.md\',\n    \'reference.md\',\n    \'setup.md\',\n)\n\n\ndef main():\n    """"""Check for collisions, then create.""""""\n\n    # Check.\n    errors = False\n    for path in BOILERPLATE:\n        if os.path.exists(path):\n            print(\'Warning: {0} already exists.\'.format(path), file=sys.stderr)\n            errors = True\n    if errors:\n        print(\'**Exiting without creating files.**\', file=sys.stderr)\n        sys.exit(1)\n\n    # Create.\n    for path in BOILERPLATE:\n        shutil.copyfile(\n            ""bin/boilerplate/{}"".format(path),\n            path\n        )\n\n\nif __name__ == \'__main__\':\n    main()\n'"
bin/repo_check.py,0,"b'#!/usr/bin/env python3\n\n""""""\nCheck repository settings.\n""""""\n\n\nimport sys\nimport os\nfrom subprocess import Popen, PIPE\nimport re\nfrom argparse import ArgumentParser\n\nfrom util import Reporter, require\n\n# Import this way to produce a more useful error message.\ntry:\n    import requests\nexcept ImportError:\n    print(\'Unable to import requests module: please install requests\', file=sys.stderr)\n    sys.exit(1)\n\n\n# Pattern to match Git command-line output for remotes => (user name, project name).\nP_GIT_REMOTE = re.compile(r\'upstream\\s+[^:]+:([^/]+)/([^.]+)\\.git\\s+\\(fetch\\)\')\n\n# Repository URL format string.\nF_REPO_URL = \'https://github.com/{0}/{1}/\'\n\n# Pattern to match repository URLs => (user name, project name)\nP_REPO_URL = re.compile(r\'https?://github\\.com/([^.]+)/([^/]+)/?\')\n\n# API URL format string.\nF_API_URL = \'https://api.github.com/repos/{0}/{1}/labels\'\n\n# Expected labels and colors.\nEXPECTED = {\n    \'help wanted\': \'dcecc7\',\n    \'status:in progress\': \'9bcc65\',\n    \'status:changes requested\': \'679f38\',\n    \'status:wait\': \'fff2df\',\n    \'status:refer to cac\': \'ffdfb2\',\n    \'status:need more info\': \'ee6c00\',\n    \'status:blocked\': \'e55100\',\n    \'status:out of scope\': \'eeeeee\',\n    \'status:duplicate\': \'bdbdbd\',\n    \'type:typo text\': \'f8bad0\',\n    \'type:bug\': \'eb3f79\',\n    \'type:formatting\': \'ac1357\',\n    \'type:template and tools\': \'7985cb\',\n    \'type:instructor guide\': \'00887a\',\n    \'type:discussion\': \'b2e5fc\',\n    \'type:enhancement\': \'7fdeea\',\n    \'type:clarification\': \'00acc0\',\n    \'type:teaching example\': \'ced8dc\',\n    \'good first issue\': \'ffeb3a\',\n    \'high priority\': \'d22e2e\'\n}\n\n\ndef main():\n    """"""\n    Main driver.\n    """"""\n\n    args = parse_args()\n    reporter = Reporter()\n    repo_url = get_repo_url(args.repo_url)\n    check_labels(reporter, repo_url)\n    reporter.report()\n\n\ndef parse_args():\n    """"""\n    Parse command-line arguments.\n    """"""\n\n    parser = ArgumentParser(description=""""""Check repository settings."""""")\n    parser.add_argument(\'-r\', \'--repo\',\n                        default=None,\n                        dest=\'repo_url\',\n                        help=\'repository URL\')\n    parser.add_argument(\'-s\', \'--source\',\n                        default=os.curdir,\n                        dest=\'source_dir\',\n                        help=\'source directory\')\n\n    args, extras = parser.parse_known_args()\n    require(not extras,\n            \'Unexpected trailing command-line arguments ""{0}""\'.format(extras))\n\n    return args\n\n\ndef get_repo_url(repo_url):\n    """"""\n    Figure out which repository to query.\n    """"""\n\n    # Explicitly specified.\n    if repo_url is not None:\n        return repo_url\n\n    # Guess.\n    cmd = \'git remote -v\'\n    p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE,\n              close_fds=True, universal_newlines=True)\n    stdout_data, stderr_data = p.communicate()\n    stdout_data = stdout_data.split(\'\\n\')\n    matches = [P_GIT_REMOTE.match(line) for line in stdout_data]\n    matches = [m for m in matches if m is not None]\n    require(len(matches) == 1,\n            \'Unexpected output from git remote command: ""{0}""\'.format(matches))\n\n    username = matches[0].group(1)\n    require(\n        username, \'empty username in git remote output {0}\'.format(matches[0]))\n\n    project_name = matches[0].group(2)\n    require(\n        username, \'empty project name in git remote output {0}\'.format(matches[0]))\n\n    url = F_REPO_URL.format(username, project_name)\n    return url\n\n\ndef check_labels(reporter, repo_url):\n    """"""\n    Check labels in repository.\n    """"""\n\n    actual = get_labels(repo_url)\n    extra = set(actual.keys()) - set(EXPECTED.keys())\n\n    reporter.check(not extra,\n                   None,\n                   \'Extra label(s) in repository {0}: {1}\',\n                   repo_url, \', \'.join(sorted(extra)))\n\n    missing = set(EXPECTED.keys()) - set(actual.keys())\n    reporter.check(not missing,\n                   None,\n                   \'Missing label(s) in repository {0}: {1}\',\n                   repo_url, \', \'.join(sorted(missing)))\n\n    overlap = set(EXPECTED.keys()).intersection(set(actual.keys()))\n    for name in sorted(overlap):\n        reporter.check(EXPECTED[name].lower() == actual[name].lower(),\n                       None,\n                       \'Color mis-match for label {0} in {1}: expected {2}, found {3}\',\n                       name, repo_url, EXPECTED[name], actual[name])\n\n\ndef get_labels(repo_url):\n    """"""\n    Get actual labels from repository.\n    """"""\n\n    m = P_REPO_URL.match(repo_url)\n    require(\n        m, \'repository URL {0} does not match expected pattern\'.format(repo_url))\n\n    username = m.group(1)\n    require(username, \'empty username in repository URL {0}\'.format(repo_url))\n\n    project_name = m.group(2)\n    require(\n        username, \'empty project name in repository URL {0}\'.format(repo_url))\n\n    url = F_API_URL.format(username, project_name)\n    r = requests.get(url)\n    require(r.status_code == 200,\n            \'Request for {0} failed with {1}\'.format(url, r.status_code))\n\n    result = {}\n    for entry in r.json():\n        result[entry[\'name\']] = entry[\'color\']\n    return result\n\n\nif __name__ == \'__main__\':\n    main()\n'"
bin/test_lesson_check.py,0,"b'#!/usr/bin/env python3\n\nimport unittest\n\nimport lesson_check\nimport util\n\n\nclass TestFileList(unittest.TestCase):\n    def setUp(self):\n        self.reporter = util.Reporter()  # TODO: refactor reporter class.\n\n    def test_file_list_has_expected_entries(self):\n        # For first pass, simply assume that all required files are present\n        all_filenames = [filename.replace(\'%\', \'\')\n                         for filename in lesson_check.REQUIRED_FILES]\n\n        lesson_check.check_fileset(\'\', self.reporter, all_filenames)\n        self.assertEqual(len(self.reporter.messages), 0)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
bin/util.py,0,"b'import sys\nimport os\nimport json\nfrom subprocess import Popen, PIPE\n\n# Import this way to produce a more useful error message.\ntry:\n    import yaml\nexcept ImportError:\n    print(\'Unable to import YAML module: please install PyYAML\', file=sys.stderr)\n    sys.exit(1)\n\n\n# Things an image file\'s name can end with.\nIMAGE_FILE_SUFFIX = {\n    \'.gif\',\n    \'.jpg\',\n    \'.png\',\n    \'.svg\'\n}\n\n# Files that shouldn\'t be present.\nUNWANTED_FILES = [\n    \'.nojekyll\'\n]\n\n# Marker to show that an expected value hasn\'t been provided.\n# (Can\'t use \'None\' because that might be a legitimate value.)\nREPORTER_NOT_SET = []\n\n\nclass Reporter:\n    """"""Collect and report errors.""""""\n\n    def __init__(self):\n        """"""Constructor.""""""\n        self.messages = []\n\n    def check_field(self, filename, name, values, key, expected=REPORTER_NOT_SET):\n        """"""Check that a dictionary has an expected value.""""""\n\n        if key not in values:\n            self.add(filename, \'{0} does not contain {1}\', name, key)\n        elif expected is REPORTER_NOT_SET:\n            pass\n        elif type(expected) in (tuple, set, list):\n            if values[key] not in expected:\n                self.add(\n                    filename, \'{0} {1} value {2} is not in {3}\', name, key, values[key], expected)\n        elif values[key] != expected:\n            self.add(filename, \'{0} {1} is {2} not {3}\',\n                     name, key, values[key], expected)\n\n    def check(self, condition, location, fmt, *args):\n        """"""Append error if condition not met.""""""\n\n        if not condition:\n            self.add(location, fmt, *args)\n\n    def add(self, location, fmt, *args):\n        """"""Append error unilaterally.""""""\n\n        self.messages.append((location, fmt.format(*args)))\n\n    @staticmethod\n    def pretty(item):\n        location, message = item\n        if isinstance(location, type(None)):\n            return message\n        elif isinstance(location, str):\n            return location + \': \' + message\n        elif isinstance(location, tuple):\n            return \'{0}:{1}: \'.format(*location) + message\n\n        print(\'Unknown item ""{0}""\'.format(item), file=sys.stderr)\n        return NotImplemented\n\n    @staticmethod\n    def key(item):\n        location, message = item\n        if isinstance(location, type(None)):\n            return (\'\', -1, message)\n        elif isinstance(location, str):\n            return (location, -1, message)\n        elif isinstance(location, tuple):\n            return (location[0], location[1], message)\n\n        print(\'Unknown item ""{0}""\'.format(item), file=sys.stderr)\n        return NotImplemented\n\n    def report(self, stream=sys.stdout):\n        """"""Report all messages in order.""""""\n\n        if not self.messages:\n            return\n\n        for m in sorted(self.messages, key=self.key):\n            print(self.pretty(m), file=stream)\n\n\ndef read_markdown(parser, path):\n    """"""\n    Get YAML and AST for Markdown file, returning\n    {\'metadata\':yaml, \'metadata_len\':N, \'text\':text, \'lines\':[(i, line, len)], \'doc\':doc}.\n    """"""\n\n    # Split and extract YAML (if present).\n    with open(path, \'r\') as reader:\n        body = reader.read()\n    metadata_raw, metadata_yaml, body = split_metadata(path, body)\n\n    # Split into lines.\n    metadata_len = 0 if metadata_raw is None else metadata_raw.count(\'\\n\')\n    lines = [(metadata_len+i+1, line, len(line))\n             for (i, line) in enumerate(body.split(\'\\n\'))]\n\n    # Parse Markdown.\n    cmd = \'ruby {0}\'.format(parser)\n    p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE,\n              close_fds=True, universal_newlines=True)\n    stdout_data, stderr_data = p.communicate(body)\n    doc = json.loads(stdout_data)\n\n    return {\n        \'metadata\': metadata_yaml,\n        \'metadata_len\': metadata_len,\n        \'text\': body,\n        \'lines\': lines,\n        \'doc\': doc\n    }\n\n\ndef split_metadata(path, text):\n    """"""\n    Get raw (text) metadata, metadata as YAML, and rest of body.\n    If no metadata, return (None, None, body).\n    """"""\n\n    metadata_raw = None\n    metadata_yaml = None\n\n    pieces = text.split(\'---\', 2)\n    if len(pieces) == 3:\n        metadata_raw = pieces[1]\n        text = pieces[2]\n        try:\n            metadata_yaml = yaml.load(metadata_raw, Loader=yaml.FullLoader)\n        except yaml.YAMLError as e:\n            print(\'Unable to parse YAML header in {0}:\\n{1}\'.format(\n                path, e), file=sys.stderr)\n            sys.exit(1)\n\n    return metadata_raw, metadata_yaml, text\n\n\ndef load_yaml(filename):\n    """"""\n    Wrapper around YAML loading so that \'import yaml\' is only needed\n    in one file.\n    """"""\n\n    try:\n        with open(filename, \'r\') as reader:\n            return yaml.load(reader, Loader=yaml.FullLoader)\n    except (yaml.YAMLError, IOError) as e:\n        print(\'Unable to load YAML file {0}:\\n{1}\'.format(\n            filename, e), file=sys.stderr)\n        sys.exit(1)\n\n\ndef check_unwanted_files(dir_path, reporter):\n    """"""\n    Check that unwanted files are not present.\n    """"""\n\n    for filename in UNWANTED_FILES:\n        path = os.path.join(dir_path, filename)\n        reporter.check(not os.path.exists(path),\n                       path,\n                       ""Unwanted file found"")\n\n\ndef require(condition, message):\n    """"""Fail if condition not met.""""""\n\n    if not condition:\n        print(message, file=sys.stderr)\n        sys.exit(1)\n'"
bin/workshop_check.py,0,"b'#!/usr/bin/env python3\n\n\'\'\'Check that a workshop\'s index.html metadata is valid.  See the\ndocstrings on the checking functions for a summary of the checks.\n\'\'\'\n\n\nimport sys\nimport os\nimport re\nfrom datetime import date\nfrom util import Reporter, split_metadata, load_yaml, check_unwanted_files\n\n# Metadata field patterns.\nEMAIL_PATTERN = r\'[^@]+@[^@]+\\.[^@]+\'\nHUMANTIME_PATTERN = r\'((0?[1-9]|1[0-2]):[0-5]\\d(am|pm)(-|to)(0?[1-9]|1[0-2]):[0-5]\\d(am|pm))|((0?\\d|1\\d|2[0-3]):[0-5]\\d(-|to)(0?\\d|1\\d|2[0-3]):[0-5]\\d)\'\nEVENTBRITE_PATTERN = r\'\\d{9,10}\'\nURL_PATTERN = r\'https?://.+\'\n\n# Defaults.\nCARPENTRIES = (""dc"", ""swc"", ""lc"", ""cp"")\nDEFAULT_CONTACT_EMAIL = \'admin@software-carpentry.org\'\n\nUSAGE = \'Usage: ""workshop_check.py path/to/root/directory""\'\n\n# Country and language codes.  Note that codes mean different things: \'ar\'\n# is \'Arabic\' as a language but \'Argentina\' as a country.\n\nISO_COUNTRY = [\n    \'ad\', \'ae\', \'af\', \'ag\', \'ai\', \'al\', \'am\', \'an\', \'ao\', \'aq\', \'ar\', \'as\',\n    \'at\', \'au\', \'aw\', \'ax\', \'az\', \'ba\', \'bb\', \'bd\', \'be\', \'bf\', \'bg\', \'bh\',\n    \'bi\', \'bj\', \'bm\', \'bn\', \'bo\', \'br\', \'bs\', \'bt\', \'bv\', \'bw\', \'by\', \'bz\',\n    \'ca\', \'cc\', \'cd\', \'cf\', \'cg\', \'ch\', \'ci\', \'ck\', \'cl\', \'cm\', \'cn\', \'co\',\n    \'cr\', \'cu\', \'cv\', \'cx\', \'cy\', \'cz\', \'de\', \'dj\', \'dk\', \'dm\', \'do\', \'dz\',\n    \'ec\', \'ee\', \'eg\', \'eh\', \'er\', \'es\', \'et\', \'eu\', \'fi\', \'fj\', \'fk\', \'fm\',\n    \'fo\', \'fr\', \'ga\', \'gb\', \'gd\', \'ge\', \'gf\', \'gg\', \'gh\', \'gi\', \'gl\', \'gm\',\n    \'gn\', \'gp\', \'gq\', \'gr\', \'gs\', \'gt\', \'gu\', \'gw\', \'gy\', \'hk\', \'hm\', \'hn\',\n    \'hr\', \'ht\', \'hu\', \'id\', \'ie\', \'il\', \'im\', \'in\', \'io\', \'iq\', \'ir\', \'is\',\n    \'it\', \'je\', \'jm\', \'jo\', \'jp\', \'ke\', \'kg\', \'kh\', \'ki\', \'km\', \'kn\', \'kp\',\n    \'kr\', \'kw\', \'ky\', \'kz\', \'la\', \'lb\', \'lc\', \'li\', \'lk\', \'lr\', \'ls\', \'lt\',\n    \'lu\', \'lv\', \'ly\', \'ma\', \'mc\', \'md\', \'me\', \'mg\', \'mh\', \'mk\', \'ml\', \'mm\',\n    \'mn\', \'mo\', \'mp\', \'mq\', \'mr\', \'ms\', \'mt\', \'mu\', \'mv\', \'mw\', \'mx\', \'my\',\n    \'mz\', \'na\', \'nc\', \'ne\', \'nf\', \'ng\', \'ni\', \'nl\', \'no\', \'np\', \'nr\', \'nu\',\n    \'nz\', \'om\', \'pa\', \'pe\', \'pf\', \'pg\', \'ph\', \'pk\', \'pl\', \'pm\', \'pn\', \'pr\',\n    \'ps\', \'pt\', \'pw\', \'py\', \'qa\', \'re\', \'ro\', \'rs\', \'ru\', \'rw\', \'sa\', \'sb\',\n    \'sc\', \'sd\', \'se\', \'sg\', \'sh\', \'si\', \'sj\', \'sk\', \'sl\', \'sm\', \'sn\', \'so\',\n    \'sr\', \'st\', \'sv\', \'sy\', \'sz\', \'tc\', \'td\', \'tf\', \'tg\', \'th\', \'tj\', \'tk\',\n    \'tl\', \'tm\', \'tn\', \'to\', \'tr\', \'tt\', \'tv\', \'tw\', \'tz\', \'ua\', \'ug\', \'um\',\n    \'us\', \'uy\', \'uz\', \'va\', \'vc\', \'ve\', \'vg\', \'vi\', \'vn\', \'vu\', \'wf\', \'ws\',\n    \'ye\', \'yt\', \'za\', \'zm\', \'zw\'\n]\n\nISO_LANGUAGE = [\n    \'aa\', \'ab\', \'ae\', \'af\', \'ak\', \'am\', \'an\', \'ar\', \'as\', \'av\', \'ay\', \'az\',\n    \'ba\', \'be\', \'bg\', \'bh\', \'bi\', \'bm\', \'bn\', \'bo\', \'br\', \'bs\', \'ca\', \'ce\',\n    \'ch\', \'co\', \'cr\', \'cs\', \'cu\', \'cv\', \'cy\', \'da\', \'de\', \'dv\', \'dz\', \'ee\',\n    \'el\', \'en\', \'eo\', \'es\', \'et\', \'eu\', \'fa\', \'ff\', \'fi\', \'fj\', \'fo\', \'fr\',\n    \'fy\', \'ga\', \'gd\', \'gl\', \'gn\', \'gu\', \'gv\', \'ha\', \'he\', \'hi\', \'ho\', \'hr\',\n    \'ht\', \'hu\', \'hy\', \'hz\', \'ia\', \'id\', \'ie\', \'ig\', \'ii\', \'ik\', \'io\', \'is\',\n    \'it\', \'iu\', \'ja\', \'jv\', \'ka\', \'kg\', \'ki\', \'kj\', \'kk\', \'kl\', \'km\', \'kn\',\n    \'ko\', \'kr\', \'ks\', \'ku\', \'kv\', \'kw\', \'ky\', \'la\', \'lb\', \'lg\', \'li\', \'ln\',\n    \'lo\', \'lt\', \'lu\', \'lv\', \'mg\', \'mh\', \'mi\', \'mk\', \'ml\', \'mn\', \'mr\', \'ms\',\n    \'mt\', \'my\', \'na\', \'nb\', \'nd\', \'ne\', \'ng\', \'nl\', \'nn\', \'no\', \'nr\', \'nv\',\n    \'ny\', \'oc\', \'oj\', \'om\', \'or\', \'os\', \'pa\', \'pi\', \'pl\', \'ps\', \'pt\', \'qu\',\n    \'rm\', \'rn\', \'ro\', \'ru\', \'rw\', \'sa\', \'sc\', \'sd\', \'se\', \'sg\', \'si\', \'sk\',\n    \'sl\', \'sm\', \'sn\', \'so\', \'sq\', \'sr\', \'ss\', \'st\', \'su\', \'sv\', \'sw\', \'ta\',\n    \'te\', \'tg\', \'th\', \'ti\', \'tk\', \'tl\', \'tn\', \'to\', \'tr\', \'ts\', \'tt\', \'tw\',\n    \'ty\', \'ug\', \'uk\', \'ur\', \'uz\', \'ve\', \'vi\', \'vo\', \'wa\', \'wo\', \'xh\', \'yi\',\n    \'yo\', \'za\', \'zh\', \'zu\'\n]\n\n\ndef look_for_fixme(func):\n    """"""Decorator to fail test if text argument starts with ""FIXME"".""""""\n\n    def inner(arg):\n        if (arg is not None) and \\\n           isinstance(arg, str) and \\\n           arg.lstrip().startswith(\'FIXME\'):\n            return False\n        return func(arg)\n    return inner\n\n\n@look_for_fixme\ndef check_layout(layout):\n    \'\'\'""layout"" in YAML header must be ""workshop"".\'\'\'\n\n    return layout == \'workshop\'\n\n\n@look_for_fixme\ndef check_carpentry(layout):\n    \'\'\'""carpentry"" in YAML header must be ""dc"", ""swc"", ""lc"", or ""cp"".\'\'\'\n\n    return layout in CARPENTRIES\n\n\n@look_for_fixme\ndef check_country(country):\n    \'\'\'""country"" must be a lowercase ISO-3166 two-letter code.\'\'\'\n\n    return country in ISO_COUNTRY\n\n\n@look_for_fixme\ndef check_language(language):\n    \'\'\'""language"" must be a lowercase ISO-639 two-letter code.\'\'\'\n\n    return language in ISO_LANGUAGE\n\n\n@look_for_fixme\ndef check_humandate(date):\n    """"""\n    \'humandate\' must be a human-readable date with a 3-letter month\n    and 4-digit year.  Examples include \'Feb 18-20, 2025\' and \'Feb 18\n    and 20, 2025\'.  It may be in languages other than English, but the\n    month name should be kept short to aid formatting of the main\n    Carpentries web site.\n    """"""\n\n    if \',\' not in date:\n        return False\n\n    month_dates, year = date.split(\',\')\n\n    # The first three characters of month_dates are not empty\n    month = month_dates[:3]\n    if any(char == \' \' for char in month):\n        return False\n\n    # But the fourth character is empty (""February"" is illegal)\n    if month_dates[3] != \' \':\n        return False\n\n    # year contains *only* numbers\n    try:\n        int(year)\n    except:\n        return False\n\n    return True\n\n\n@look_for_fixme\ndef check_humantime(time):\n    """"""\n    \'humantime\' is a human-readable start and end time for the\n    workshop, such as \'09:00 - 16:00\'.\n    """"""\n\n    return bool(re.match(HUMANTIME_PATTERN, time.replace(\' \', \'\')))\n\n\ndef check_date(this_date):\n    """"""\n    \'startdate\' and \'enddate\' are machine-readable start and end dates\n    for the workshop, and must be in YYYY-MM-DD format, e.g.,\n    \'2015-07-01\'.\n    """"""\n\n    # YAML automatically loads valid dates as datetime.date.\n    return isinstance(this_date, date)\n\n\n@look_for_fixme\ndef check_latitude_longitude(latlng):\n    """"""\n    \'latlng\' must be a valid latitude and longitude represented as two\n    floating-point numbers separated by a comma.\n    """"""\n\n    try:\n        lat, lng = latlng.split(\',\')\n        lat = float(lat)\n        lng = float(lng)\n        return (-90.0 <= lat <= 90.0) and (-180.0 <= lng <= 180.0)\n    except ValueError:\n        return False\n\n\ndef check_instructors(instructors):\n    """"""\n    \'instructor\' must be a non-empty comma-separated list of quoted\n    names, e.g. [\'First name\', \'Second name\', ...\'].  Do not use \'TBD\'\n    or other placeholders.\n    """"""\n\n    # YAML automatically loads list-like strings as lists.\n    return isinstance(instructors, list) and len(instructors) > 0\n\n\ndef check_helpers(helpers):\n    """"""\n    \'helper\' must be a comma-separated list of quoted names,\n    e.g. [\'First name\', \'Second name\', ...\'].  The list may be empty.\n    Do not use \'TBD\' or other placeholders.\n    """"""\n\n    # YAML automatically loads list-like strings as lists.\n    return isinstance(helpers, list) and len(helpers) >= 0\n\n\n@look_for_fixme\ndef check_emails(emails):\n    """"""\n    \'emails\' must be a comma-separated list of valid email addresses.\n    The list may be empty. A valid email address consists of characters,\n    an \'@\', and more characters.  It should not contain the default contact\n    """"""\n\n    # YAML automatically loads list-like strings as lists.\n    if (isinstance(emails, list) and len(emails) >= 0):\n        for email in emails:\n            if ((not bool(re.match(EMAIL_PATTERN, email))) or (email == DEFAULT_CONTACT_EMAIL)):\n                return False\n    else:\n        return False\n\n    return True\n\n\ndef check_eventbrite(eventbrite):\n    """"""\n    \'eventbrite\' (the Eventbrite registration key) must be 9 or more\n    digits.  It may appear as an integer or as a string.\n    """"""\n\n    if isinstance(eventbrite, int):\n        return True\n    else:\n        return bool(re.match(EVENTBRITE_PATTERN, eventbrite))\n\n\n@look_for_fixme\ndef check_collaborative_notes(collaborative_notes):\n    """"""\n    \'collaborative_notes\' must be a valid URL.\n    """"""\n\n    return bool(re.match(URL_PATTERN, collaborative_notes))\n\n\n@look_for_fixme\ndef check_pass(value):\n    """"""\n    This test always passes (it is used for \'checking\' things like the\n    workshop address, for which no sensible validation is feasible).\n    """"""\n\n    return True\n\n\nHANDLERS = {\n    \'layout\':     (True, check_layout, \'layout isn\\\'t ""workshop""\'),\n\n    \'carpentry\':  (True, check_carpentry, \'carpentry isn\\\'t in \' +\n                   \', \'.join(CARPENTRIES)),\n\n    \'country\':    (True, check_country,\n                   \'country invalid: must use lowercase two-letter ISO code \' +\n                   \'from \' + \', \'.join(ISO_COUNTRY)),\n\n    \'language\':   (False,  check_language,\n                   \'language invalid: must use lowercase two-letter ISO code\' +\n                   \' from \' + \', \'.join(ISO_LANGUAGE)),\n\n    \'humandate\':  (True, check_humandate,\n                   \'humandate invalid. Please use three-letter months like \' +\n                   \'""Jan"" and four-letter years like ""2025""\'),\n\n    \'humantime\':  (True, check_humantime,\n                   \'humantime doesn\\\'t include numbers\'),\n\n    \'startdate\':  (True, check_date,\n                   \'startdate invalid. Must be of format year-month-day, \' +\n                   \'i.e., 2014-01-31\'),\n\n    \'enddate\':    (False, check_date,\n                   \'enddate invalid. Must be of format year-month-day, i.e.,\' +\n                   \' 2014-01-31\'),\n\n    \'latlng\':     (True, check_latitude_longitude,\n                   \'latlng invalid. Check that it is two floating point \' +\n                   \'numbers, separated by a comma\'),\n\n    \'instructor\': (True, check_instructors,\n                   \'instructor list isn\\\'t a valid list of format \' +\n                   \'[""First instructor"", ""Second instructor"",..]\'),\n\n    \'helper\':     (True, check_helpers,\n                   \'helper list isn\\\'t a valid list of format \' +\n                   \'[""First helper"", ""Second helper"",..]\'),\n\n    \'email\':    (True, check_emails,\n                 \'contact email list isn\\\'t a valid list of format \' +\n                 \'[""me@example.org"", ""you@example.org"",..] or contains incorrectly formatted email addresses or \' +\n                 \'""{0}"".\'.format(DEFAULT_CONTACT_EMAIL)),\n\n    \'eventbrite\': (False, check_eventbrite, \'Eventbrite key appears invalid\'),\n\n    \'collaborative_notes\':   (False, check_collaborative_notes, \'Collaborative Notes URL appears invalid\'),\n\n    \'venue\':      (False, check_pass, \'venue name not specified\'),\n\n    \'address\':    (False, check_pass, \'address not specified\')\n}\n\n# REQUIRED is all required categories.\nREQUIRED = {k for k in HANDLERS if HANDLERS[k][0]}\n\n# OPTIONAL is all optional categories.\nOPTIONAL = {k for k in HANDLERS if not HANDLERS[k][0]}\n\n\ndef check_blank_lines(reporter, raw):\n    """"""\n    Blank lines are not allowed in category headers.\n    """"""\n\n    lines = [(i, x) for (i, x) in enumerate(\n        raw.strip().split(\'\\n\')) if not x.strip()]\n    reporter.check(not lines,\n                   None,\n                   \'Blank line(s) in header: {0}\',\n                   \', \'.join([""{0}: {1}"".format(i, x.rstrip()) for (i, x) in lines]))\n\n\ndef check_categories(reporter, left, right, msg):\n    """"""\n    Report differences (if any) between two sets of categories.\n    """"""\n\n    diff = left - right\n    reporter.check(len(diff) == 0,\n                   None,\n                   \'{0}: offending entries {1}\',\n                   msg, sorted(list(diff)))\n\n\ndef check_file(reporter, path, data):\n    """"""\n    Get header from file, call all other functions, and check file for\n    validity.\n    """"""\n\n    # Get metadata as text and as YAML.\n    raw, header, body = split_metadata(path, data)\n\n    # Do we have any blank lines in the header?\n    check_blank_lines(reporter, raw)\n\n    # Look through all header entries.  If the category is in the input\n    # file and is either required or we have actual data (as opposed to\n    # a commented-out entry), we check it.  If it *isn\'t* in the header\n    # but is required, report an error.\n    for category in HANDLERS:\n        required, handler, message = HANDLERS[category]\n        if category in header:\n            if required or header[category]:\n                reporter.check(handler(header[category]),\n                               None,\n                               \'{0}\\n    actual value ""{1}""\',\n                               message, header[category])\n        elif required:\n            reporter.add(None,\n                         \'Missing mandatory key ""{0}""\',\n                         category)\n\n    # Check whether we have missing or too many categories\n    seen_categories = set(header.keys())\n    check_categories(reporter, REQUIRED, seen_categories,\n                     \'Missing categories\')\n    check_categories(reporter, seen_categories, REQUIRED.union(OPTIONAL),\n                     \'Superfluous categories\')\n\n\ndef check_config(reporter, filename):\n    """"""\n    Check YAML configuration file.\n    """"""\n\n    config = load_yaml(filename)\n\n    kind = config.get(\'kind\', None)\n    reporter.check(kind == \'workshop\',\n                   filename,\n                   \'Missing or unknown kind of event: {0}\',\n                   kind)\n\n    carpentry = config.get(\'carpentry\', None)\n    reporter.check(carpentry in (\'swc\', \'dc\', \'lc\', \'cp\'),\n                   filename,\n                   \'Missing or unknown carpentry: {0}\',\n                   carpentry)\n\n\ndef main():\n    \'\'\'Run as the main program.\'\'\'\n\n    if len(sys.argv) != 2:\n        print(USAGE, file=sys.stderr)\n        sys.exit(1)\n\n    root_dir = sys.argv[1]\n    index_file = os.path.join(root_dir, \'index.html\')\n    config_file = os.path.join(root_dir, \'_config.yml\')\n\n    reporter = Reporter()\n    check_config(reporter, config_file)\n    check_unwanted_files(root_dir, reporter)\n    with open(index_file) as reader:\n        data = reader.read()\n        check_file(reporter, index_file, data)\n    reporter.report()\n\n\nif __name__ == \'__main__\':\n    main()\n'"
code/argv_list.py,0,"b""import sys\nprint('sys.argv is', sys.argv)\n"""
code/arith.py,0,"b""import sys\n\n\ndef main():\n    assert len(sys.argv) == 4, 'Need exactly 3 arguments'\n\n    operator = sys.argv[1]\n    assert operator in ['add', 'subtract', 'multiply', 'divide'], (\n        'Operator is not one of add, subtract, multiply, or divide: '\n        'bailing out')\n    try:\n        operand1, operand2 = float(sys.argv[2]), float(sys.argv[3])\n    except ValueError:\n        print('Cannot convert input to a number: bailing out')\n        return\n\n    do_arithmetic(operand1, operator, operand2)\n\n\ndef do_arithmetic(operand1, operator, operand2):\n\n    if operator == 'add':\n        value = operand1 + operand2\n    elif operator == 'subtract':\n        value = operand1 - operand2\n    elif operator == 'multiply':\n        value = operand1 * operand2\n    elif operator == 'divide':\n        value = operand1 / operand2\n    print(value)\n\n\nif __name__ == '__main__':\n    main()\n"""
code/check.py,0,"b""import sys\nimport numpy\n\n\ndef main():\n    script = sys.argv[0]\n    filenames = sys.argv[1:]\n    if len(filenames) <= 1:  # nothing to check\n        print('Only 1 file specified on input')\n    else:\n        nrow0, ncol0 = row_col_count(filenames[0])\n        print('First file %s: %d rows and %d columns' % (\n            filenames[0], nrow0, ncol0))\n        for filename in filenames[1:]:\n            nrow, ncol = row_col_count(filename)\n            if nrow != nrow0 or ncol != ncol0:\n                print('File %s does not check: %d rows and %d columns'\n                      % (filename, nrow, ncol))\n            else:\n                print('File %s checks' % filename)\n        return\n\n\ndef row_col_count(filename):\n    try:\n        nrow, ncol = numpy.loadtxt(filename, delimiter=',').shape\n    except ValueError:\n        # This occurs if the file doesn't have same number of rows and columns,\n        # or if it has non-numeric content\n        nrow, ncol = (0, 0)\n    return nrow, ncol\n\n\nif __name__ == '__main__':\n    main()\n"""
code/count_stdin.py,0,"b""import sys\n\ncount = 0\nfor line in sys.stdin:\n    count += 1\n\nprint(count, 'lines in standard input')\n"""
code/gen_inflammation.py,0,"b'#!/usr/bin/env python\n\n""""""\nGenerate pseudo-random patient inflammation data for use in Python lessons.\n""""""\n\nimport random\n\nn_patients = 60\nn_days = 40\nn_range = 20\n\nmiddle = n_days / 2\n\nfor p in range(n_patients):\n    vals = []\n    for d in range(n_days):\n        upper = max(n_range - abs(d - middle), 0)\n        vals.append(random.randint(upper/4, upper))\n    print(\',\'.join([str(v) for v in vals]))\n'"
code/line_count.py,0,"b'import sys\n\n\ndef main():\n    """"""\n    print each input filename and the number of lines in it,\n    and print the sum of the number of lines\n    """"""\n    filenames = sys.argv[1:]\n    sum_nlines = 0  # initialize counting variable\n\n    if len(filenames) == 0:  # no filenames, just stdin\n        sum_nlines = count_file_like(sys.stdin)\n        print(\'stdin: %d\' % sum_nlines)\n    else:\n        for filename in filenames:\n            nlines = count_file(filename)\n            print(\'%s %d\' % (filename, nlines))\n            sum_nlines += nlines\n        print(\'total: %d\' % sum_nlines)\n\n\ndef count_file(filename):\n    """"""count the number of lines in a file""""""\n    f = open(filename, \'r\')\n    nlines = len(f.readlines())\n    f.close()\n    return(nlines)\n\n\ndef count_file_like(file_like):\n    """"""count the number of lines in a file-like object (eg stdin)""""""\n    n = 0\n    for line in file_like:\n        n = n+1\n    return n\n\n\nif __name__ == \'__main__\':\n    main()\n'"
code/my_ls.py,0,"b'import glob\nimport sys\n\n\ndef main():\n    """"""prints names of all files with sys.argv as suffix""""""\n    assert len(sys.argv) >= 2, ""Argument list cannot be empty""\n    # NB: behaviour is not as you\'d expect if sys.argv[1] is *\n    suffix = sys.argv[1]\n    glob_input = \'*.\' + suffix  # construct the input\n    glob_output = glob.glob(glob_input)  # call the glob function\n    for item in glob_output:  # print the output\n        print(item)\n    return\n\n\nif __name__ == \'__main__\':\n    main()\n'"
code/readings_01.py,0,"b""import sys\nimport numpy\n\n\ndef main():\n    script = sys.argv[0]\n    filename = sys.argv[1]\n    data = numpy.loadtxt(filename, delimiter=',')\n    for row_mean in numpy.mean(data, axis=1):\n        print(row_mean)\n"""
code/readings_02.py,0,"b""import sys\nimport numpy\n\ndef main():\n    script = sys.argv[0]\n    filename = sys.argv[1]\n    data = numpy.loadtxt(filename, delimiter=',')\n    for row_mean in numpy.mean(data, axis=1):\n        print(row_mean)\n\n\nif __name__ == '__main__':\n    main()\n"""
code/readings_03.py,0,"b""import sys\nimport numpy\n\n\ndef main():\n    script = sys.argv[0]\n    for filename in sys.argv[1:]:\n        data = numpy.loadtxt(filename, delimiter=',')\n        for row_mean in numpy.mean(data, axis=1):\n            print(row_mean)\n\n\nif __name__ == '__main__':\n    main()\n"""
code/readings_04.py,0,"b""import sys\nimport numpy\n\n\ndef main():\n    script = sys.argv[0]\n    action = sys.argv[1]\n    filenames = sys.argv[2:]\n\n    for filename in filenames:\n        data = numpy.loadtxt(filename, delimiter=',')\n\n        if action == '--min':\n            values = numpy.min(data, axis=1)\n        elif action == '--mean':\n            values = numpy.mean(data, axis=1)\n        elif action == '--max':\n            values = numpy.max(data, axis=1)\n\n        for val in values:\n            print(val)\n\n\nif __name__ == '__main__':\n    main()\n"""
code/readings_05.py,0,"b""import sys\nimport numpy\n\ndef main():\n    script = sys.argv[0]\n    action = sys.argv[1]\n    filenames = sys.argv[2:]\n    assert action in ['--min', '--mean', '--max'], \\\n           'Action is not one of --min, --mean, or --max: ' + action\n    for filename in filenames:\n        process(filename, action)\n\ndef process(filename, action):\n    data = numpy.loadtxt(filename, delimiter=',')\n\n    if action == '--min':\n        values = numpy.min(data, axis=1)\n    elif action == '--mean':\n        values = numpy.mean(data, axis=1)\n    elif action == '--max':\n        values = numpy.max(data, axis=1)\n\n    for val in values:\n        print(val)\n\nif __name__ == '__main__':\n   main()\n"""
code/readings_06.py,0,"b""import sys\nimport numpy\n\ndef main():\n    script = sys.argv[0]\n    action = sys.argv[1]\n    filenames = sys.argv[2:]\n    assert action in ['--min', '--mean', '--max'], (\n        'Action is not one of --min, --mean, or --max: ' + action)\n    if len(filenames) == 0:\n        process(sys.stdin, action)\n    else:\n        for filename in filenames:\n            process(filename, action)\n\ndef process(filename, action):\n    data = numpy.loadtxt(filename, delimiter=',')\n\n    if action == '--min':\n        values = numpy.min(data, axis=1)\n    elif action == '--mean':\n        values = numpy.mean(data, axis=1)\n    elif action == '--max':\n        values = numpy.max(data, axis=1)\n\n    for val in values:\n        print(val)\n\nif __name__ == '__main__':\n    main()\n"""
code/readings_07.py,0,"b""import sys\nimport numpy\n\ndef main():\n    script = sys.argv[0]\n    action = sys.argv[1]\n    filenames = sys.argv[2:]\n    assert action in ['-n', '-m', '-x'], (\n        'Action is not one of -n, -m, or -x: ' + action)\n    if len(filenames) == 0:\n        process(sys.stdin, action)\n    else:\n        for filename in filenames:\n            process(filename, action)\n\ndef process(filename, action):\n    data = numpy.loadtxt(filename, delimiter=',')\n\n    if action == '-n':\n        values = numpy.min(data, axis=1)\n    elif action == '-m':\n        values = numpy.mean(data, axis=1)\n    elif action == '-x':\n        values = numpy.max(data, axis=1)\n\n    for val in values:\n        print(val)\n\nif __name__ == '__main__':\n    main()\n"""
code/readings_08.py,0,"b""import sys\nimport numpy\n\ndef main():\n    script = sys.argv[0]\n    if len(sys.argv) == 1:  # no arguments, so print help message\n        print('Usage: python readings_08.py action filenames\\n'\n              'action must be one of --min --mean --max\\n'\n              'if filenames is blank, input is taken from stdin;\\n'\n              'otherwise, each filename in the list of arguments\\n'\n              'is processed in turn')\n        return\n\n    action = sys.argv[1]\n    filenames = sys.argv[2:]\n    assert action in ['--min', '--mean', '--max'], (\n        'Action is not one of --min, --mean, or --max: ' + action)\n    if len(filenames) == 0:\n        process(sys.stdin, action)\n    else:\n        for filename in filenames:\n            process(filename, action)\n\ndef process(filename, action):\n    data = numpy.loadtxt(filename, delimiter=',')\n\n    if action == '--min':\n        values = numpy.min(data, axis=1)\n    elif action == '--mean':\n        values = numpy.mean(data, axis=1)\n    elif action == '--max':\n        values = numpy.max(data, axis=1)\n\n    for val in values:\n        print(val)\n\nif __name__ == '__main__':\n    main()\n"""
code/readings_09.py,0,"b""import sys\nimport numpy\n\ndef main():\n    script = sys.argv[0]\n    action = sys.argv[1]\n    if action not in ['--min', '--mean', '--max']:  # if no action given\n        action = '--mean'  # set a default action, that being mean\n        # start the filenames one place earlier in the argv list\n        filenames = sys.argv[1:]\n    else:\n        filenames = sys.argv[2:]\n\n    if len(filenames) == 0:\n        process(sys.stdin, action)\n    else:\n        for filename in filenames:\n            process(filename, action)\n\ndef process(filename, action):\n    data = numpy.loadtxt(filename, delimiter=',')\n\n    if action == '--min':\n        values = numpy.min(data, axis=1)\n    elif action == '--mean':\n        values = numpy.mean(data, axis=1)\n    elif action == '--max':\n        values = numpy.max(data, axis=1)\n\n    for val in values:\n        print(val)\n\nif __name__ == '__main__':\n    main()\n"""
code/rectangle.py,0,"b'def rectangle_area(coords):\n    x0, y0, x1, y1 = coords\n    return (x1 - x0) * (x1 - y0)\n'"
code/sys_version.py,0,"b""import sys\nprint('version is', sys.version)\n"""
fig/generate_figures.py,0,"b'#!/usr/bin/env python3\n""""""\nGenerate figures used in the lesson episodes.\nUsage: ./generate_figures.py\n""""""\n\ntry:\n    import numpy\n    import matplotlib.pyplot\nexcept ImportError:\n    print(""Failed to load NumPy and/or Matplotlib"", file=sys.stderr)\n    exit(1)\n\n# Configure Matplotlib to not convert text to outlines\n# All settings: matplotlib.rcParams or matplotlib.pyplot.rcParams\nmatplotlib.pyplot.rcParams[\'svg.fonttype\'] = \'none\'\n\n# Load data\ndata = numpy.loadtxt(fname=""../data/inflammation-01.csv"", delimiter="","")\n\n# Episode 1\n## Visualizing data\n\nmatplotlib.pyplot.imshow(data)\nmatplotlib.pyplot.savefig(""inflammation-01-imshow.svg"")\nmatplotlib.pyplot.close()\n\nmatplotlib.pyplot.plot(numpy.mean(data, axis=0))\nmatplotlib.pyplot.savefig(""inflammation-01-average.svg"")\nmatplotlib.pyplot.close()\n\nmatplotlib.pyplot.plot(numpy.max(data, axis=0))\nmatplotlib.pyplot.savefig(""inflammation-01-maximum.svg"")\nmatplotlib.pyplot.close()\n\nmatplotlib.pyplot.plot(numpy.min(data, axis=0))\nmatplotlib.pyplot.savefig(""inflammation-01-minimum.svg"")\nmatplotlib.pyplot.close()\n\n## Grouping plots\nfig = matplotlib.pyplot.figure(figsize=(10.0, 3.0))\n\naxes1 = fig.add_subplot(1, 3, 1)\naxes2 = fig.add_subplot(1, 3, 2)\naxes3 = fig.add_subplot(1, 3, 3)\n\naxes1.set_ylabel(\'average\')\naxes1.plot(numpy.mean(data, axis=0))\n\naxes2.set_ylabel(\'max\')\naxes2.plot(numpy.max(data, axis=0))\n\naxes3.set_ylabel(\'min\')\naxes3.plot(numpy.min(data, axis=0))\n\nfig.tight_layout()\nmatplotlib.pyplot.savefig(""inflammation-01-group-plot.svg"")\nmatplotlib.pyplot.close(fig)\n\n\n## Exercise: Drawing Straight Lines\nfig = matplotlib.pyplot.figure(figsize=(10.0, 3.0))\n\naxes1 = fig.add_subplot(1, 3, 1)\naxes2 = fig.add_subplot(1, 3, 2)\naxes3 = fig.add_subplot(1, 3, 3)\n\naxes1.set_ylabel(\'average\')\naxes1.plot(numpy.mean(data, axis=0), drawstyle=\'steps-mid\')\n\naxes2.set_ylabel(\'max\')\naxes2.plot(numpy.max(data, axis=0), drawstyle=\'steps-mid\')\n\naxes3.set_ylabel(\'min\')\naxes3.plot(numpy.min(data, axis=0), drawstyle=\'steps-mid\')\n\nfig.tight_layout()\nmatplotlib.pyplot.savefig(""inflammation-01-line-styles.svg"")\nmatplotlib.pyplot.close(fig)\n'"
fig/optimize_svg.py,0,"b'#!/usr/bin/env python3\n""""""\nOptimize SVG files.\nExecute `./optimize_svg.py --help` for more information.\n""""""\n\nfrom pathlib import Path\nimport argparse\nimport re\nimport subprocess\nimport sys\n\ndef detect_optimizers():\n    """"""\n    Detect available SVG optimizers.\n    Currently checks:\n        - svgcleaner\n        - svgo\n        - scour\n    """"""\n    available_optimizers = []\n\n    # Check if we have svgcleaner\n    command = [""svgcleaner"", ""--version""]\n    process = subprocess.run(command, capture_output=True)\n    if not process.stderr:\n        available_optimizers.append(\'svgcleaner\')\n        output = process.stdout.decode(""ascii"").split()\n        if __name__ == \'__main__\':\n            print(""Found \'svgcleaner\' version"", output[1])\n\n    # Check if we have svgo\n    command = [""svgo"", ""--version""]\n    process = subprocess.run(command, capture_output=True)\n    if not process.stderr:\n        available_optimizers.append(\'svgo\')\n        output = process.stdout.decode(""ascii"").split()\n        if __name__ == \'__main__\':\n            print(""Found \'svgo\' version"", output[0])\n\n    # Check if we have scour\n    try:\n        from scour import scour\n    except ImportError:\n        pass\n    else:\n        available_optimizers.append(\'scour\')\n        if __name__ == \'__main__\':\n            print(""Found \'scour\' version"", scour.__version__)\n\n    return available_optimizers\n\n\ndef select_optimizer(choice):\n    """"""\n    Select an optimizer to use.\n    Allowed choices:\n        - auto\n        - all\n        - svgo (if available)\n        - svgcleaner (if available)\n        - scour (if available)\n    """"""\n\n    possible = [\'svgcleaner\', \'svgo\', \'scour\']\n    available = detect_optimizers()\n    allowed = [""auto"", ""all""] + available\n\n    if choice not in allowed:\n        print(f""Selected optimizer ({choice}) is not available."", file=sys.stderr)\n        return []\n\n    if choice == \'auto\':\n        if available:\n            optimizer = [available[0]]\n        else:\n            optimizer = []\n    elif choice == \'all\':\n        optimizer = available\n    else:\n        optimizer = [choice]\n\n    return optimizer\n\n### Functions\n\ndef optimize(optimizer, files):\n    """"""Optimize (SVG) files using specified optimizer.""""""\n\n    if optimizer == \'svgcleaner\':\n        optimize_with_svgcleaner(files)\n\n    if optimizer == \'svgo\':\n        optimize_with_svgo(files)\n\n    if optimizer == \'scour\':\n        optimize_with_scour(files)\n\n\ndef optimize_with_scour(files):\n    from scour import scour\n    """"""\n    Optimize SVG files using Scour.\n    """"""\n\n    # Configure scour\n    options = scour.parse_args()\n\n    options.digits = 4\n    # values lower than 4 for \'.digits\' led to visilble differences between\n    # the original and \'optimized\' file\n    options.indent_depth = 2\n    options.simple_colors = False\n    options.enable_viewboxing = True\n    options.embed_rasters = True\n    options.group_create = True\n    options.group_collapse = True\n    options.shorten_ids = True\n    options.strip_comments = True\n    options.strip_ids = True\n    options.strip_xml_prolog = True\n    options.strip_xml_space_attribute = True\n    options.remove_titles = True\n    options.remove_descriptions = True\n    options.remove_metadata = True\n    options.remove_descriptive_elements = True\n    options.quiet = True\n\n    for file in files:\n        options.infilename = file\n        options.outfilename = file[:-4] + ""-scoured.svg""\n\n        try:\n            # .start will close the files. Weird flex but ok\n            with open(file, \'rb\') as infile, open(options.outfilename, \'wb\') as outfile:\n                scour.start(options, infile, outfile)\n        except FileNotFoundError:\n            # Doing this because we have a list of\n            # hard-coded file names\n            print(f""File {file} not found"")\n        except:\n            print(""Failed to optimize:"", file)\n            if not infile.closed: infile.close()\n            if not outfile.closed: outfile.close()\n            if Path(options.outfilename).is_file():\n                Path(options.outfilename).unlink()\n        else:\n            Path(options.outfilename).rename(file)\n\ndef optimize_with_svgcleaner(files):\n    """"""\n    Optimize SVG files using SVGcleaner.\n    Used options:\n        - indent 2\n        - ungroup-defs no\n        - multipass\n        - coordinates-precision 1\n        - properties-precision 1\n        - paths-coordinates-precision 1\n    """"""\n    basic_command = [\n            ""svgcleaner"",\n            ""--indent"", ""2"",\n            ""--ungroup-defs"", ""no"",\n            ""--multipass"",\n            ""--coordinates-precision"", ""1"",\n            ""--properties-precision"", ""1"",\n            ""--paths-coordinates-precision"", ""1""\n            ]\n    for file in files:\n        output_file = file[:-4] + ""-svgcleaned.svg""\n        command = basic_command + [file, output_file]\n        process = subprocess.run(command, capture_output=True)\n        if process.returncode:\n            error_stream = process.stderr.decode(""ascii"")\n            if not re.match(r\'Your image is .+? smaller now.\', error_stream):\n                print(f""Failed to optimize \'{file}\' with SVGcleaner:"", file=sys.stderr)\n                print(error_stream, file=sys.stderr)\n                if Path(output_file).is_file():\n                    Path(output_file).unlink()\n        else:\n            if Path(output_file).is_file():\n                Path(output_file).rename(file)\n\ndef optimize_with_svgo(files):\n    """"""\n    Optimize SVG files using SVGO.\n    Uses the following options:\n        - multipass\n        - pretty\n        - indent=2\n        - enables the following plugins:\n            * sortAttrs\n            * removeStyleElement\n            * removeScriptElement\n            * removeOffCanvasPaths\n    """"""\n    basic_command = [\n            ""svgo"",\n            ""--multipass"",\n            ""--pretty"",\n            ""--indent=2"",\n            ""--enable={sortAttrs,removeStyleElement,removeScriptElement,removeOffCanvasPaths}""\n            ]\n    for file in files:\n        output_file = file[:-4] + ""-svgo.svg""\n        command = basic_command + [""-i"", file, ""-o"", output_file]\n        process = subprocess.run(command, capture_output=True)\n        if process.returncode:\n            print(f""Failed to optimize \'{file}\' with SVGO"", file=sys.stderr)\n            print(process.stderr.decode(""ascii""), file=sys.stderr)\n            if Path(output_file).is_file():\n                Path(output_file).unlink()\n        else:\n            if Path(output_file).is_file():\n                Path(output_file).rename(file)\n\n\ndef manual_cleanup(files):\n    """"""\n    Remove junk settings from SVG files generated with Matplotlib.\n    Currently removes:\n        - font-family=""DejaVu Sans""\n        - stroke-width="".8""\n        - transform=""rotate(-0 ...)""\n    """"""\n    text_to_remove = [\n            # Matplotlib\'s default font\n            \'font-family=""DejaVu Sans""\',\n            # Default stroke width of 1.0 is good enough\n            \'stroke-width="".8""\'\n            ]\n\n    patterns_to_remove = [\n            # useless rotations (by 0 degrees)\n            r\'\\s*transform=""rotate\\(-?0 .+?\\)""\',\n            ]\n\n    for file in files:\n        output_file = file[:-4] + ""-cleaned.svg""\n        try:\n            with open(file, ""r"") as infile, open(output_file, ""w"") as outfile:\n                for line in infile:\n                    if line.startswith(""<!DOCTYPE""): continue\n                    for txt in text_to_remove: line = line.replace(txt, """")\n                    for pat in patterns_to_remove: line = re.sub(pat, """", line)\n                    if line == \'\\n\': continue\n                    outfile.write(line)\n        except:\n            print(""Failed to clean up:"", file)\n            if Path(output_file).is_file():\n                Path(output_file).unlink()\n        else:\n            if Path(output_file).is_file():\n                Path(output_file).rename(file)\n\n\nif __name__ == \'__main__\':\n\n    description = """"""\n    Optimize SVG files using available tools.\n    """"""\n\n    # Specify permissible command-line arguments and parse them\n    parser = argparse.ArgumentParser(description=description)\n    parser.add_argument(\'-o\', metavar=""optimizer"",\n                        help=""An optimizer to use. Options: svgcleaner, svgo, scour, auto, all"",\n                        choices=[\'svgcleaner\', \'svgo\', \'scour\', \'auto\', \'all\'],\n                        default=\'auto\')\n    parser.add_argument(\'files\',\n                        metavar=\'svg_file\',\n                        help=""SVG file(s) to optimize."", nargs=\'+\')\n    args = parser.parse_args()\n    sys.argv = [\'\'] # scour uses OptParse which processes OUR args! argh!\n\n\n    for opt in select_optimizer(args.o):\n        print(""Optimizing using:"", opt)\n        optimize(opt, args.files)\n\n    manual_cleanup(args.files)\n'"
