file_path,api_count,code
ASL Recognition with Deep Learning/datasets/sign_language.py,8,"b'import random\nimport numpy as np\nfrom keras.utils import np_utils, to_categorical\nfrom keras.preprocessing import image\nfrom os import listdir\nfrom os.path import isdir, join\n\n\ndef load_data(container_path=\'datasets\', folders=[\'A\', \'B\', \'C\'],\n              size=2000, test_split=0.2, seed=0):\n    """"""\n    Loads sign language dataset.\n    """"""\n    \n    filenames, labels = [], []\n\n    for label, folder in enumerate(folders):\n        folder_path = join(container_path, folder)\n        images = [join(folder_path, d)\n                     for d in sorted(listdir(folder_path))]\n        labels.extend(len(images) * [label])\n        filenames.extend(images)\n    \n    random.seed(seed)\n    data = list(zip(filenames, labels))\n    random.shuffle(data)\n    data = data[:size]\n    filenames, labels = zip(*data)\n\n    \n    # Get the images\n    x = paths_to_tensor(filenames).astype(\'float32\')/255\n    # Store the one-hot targets\n    y = np.array(labels)\n\n    x_train = np.array(x[:int(len(x) * (1 - test_split))])\n    y_train = np.array(y[:int(len(x) * (1 - test_split))])\n    x_test = np.array(x[int(len(x) * (1 - test_split)):])\n    y_test = np.array(y[int(len(x) * (1 - test_split)):])\n\n    return (x_train, y_train), (x_test, y_test)\n\n\ndef path_to_tensor(img_path, size):\n    # loads RGB image as PIL.Image.Image type\n    img = image.load_img(img_path, target_size=(size, size))\n    # convert PIL.Image.Image type to 3D tensor\n    x = image.img_to_array(img)\n    # convert 3D tensor to 4D tensor \n    return np.expand_dims(x, axis=0)\n\ndef paths_to_tensor(img_paths, size=50):\n    list_of_tensors = [path_to_tensor(img_path, size) for img_path in img_paths]\n    return np.vstack(list_of_tensors)\n\n\n""""""\n    num_types = len(data[\'target_names\'])\n    targets = np_utils.to_categorical(np.array(data[\'target\']), num_types)\n""""""'"
Who's Tweeting_ Trump or Trudeau_/datasets/__init__.py,0,b''
Who's Tweeting_ Trump or Trudeau_/datasets/helper_functions.py,5,"b'from matplotlib import pyplot as plt\nimport numpy as np\nimport itertools\n\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title=\'Confusion matrix\',\n                          cmap=plt.cm.Blues,\n                          figure=0):\n    """"""\n    See full source and example:\n    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    """"""\n    plt.figure(figure)\n    plt.imshow(cm, interpolation=\'nearest\', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype(\'float\') / cm.sum(axis=1)[:, np.newaxis]\n        print(""Normalized confusion matrix"")\n    else:\n        print(\'Confusion matrix, without normalization\')\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=""center"",\n                 color=""white"" if cm[i, j] > thresh else ""black"")\n\n    plt.tight_layout()\n    plt.ylabel(\'True label\')\n    plt.xlabel(\'Predicted label\')\n\n\ndef plot_and_return_top_features(classifier, vectorizer, top_features=20):\n    """"""\n    Plot the top features in a binary classification model and remove possible overlap.\n\n    Adapted from https://medium.com/@aneesha/visualising-top-features-in-linear-svm-with-scikit-learn-and-matplotlib-3454ab18a14d\n    and https://stackoverflow.com/a/26980472 by @kjam\n    """"""\n    class_labels = classifier.classes_\n    feature_names = vectorizer.get_feature_names()\n    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:top_features]\n    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-top_features:]\n    top_coefficients = np.hstack([topn_class1, topn_class2])\n    if set(topn_class1).union(topn_class2):\n        top_coefficients = topn_class1\n        for ce in topn_class2:\n            if ce not in topn_class1:\n                top_coefficients.append(x)\n\n    plt.figure(figsize=(15, 5))\n    colors = [\'red\' if c < 0 else \'blue\' for c in [tc[0] for tc in top_coefficients]]\n    plt.bar(np.arange(len(top_coefficients)), [tc[0] for tc in top_coefficients], color=colors)\n    plt.xticks(np.arange(len(top_coefficients)),\n               [tc[1] for tc in top_coefficients], rotation=60, ha=\'right\')\n    plt.show()\n    return top_coefficients\n'"
