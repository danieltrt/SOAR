file_path,api_count,code
conftest.py,0,"b'import pytest\n\n\ndef pytest_addoption(parser):\n    parser.addoption(\n        ""--pyom2-lib"", default=None,\n        help=""Path to PyOM2 library (must be given for consistency tests)""\n    )\n    parser.addoption(\n        ""--backend"", choices=[""numpy"", ""bohrium""], default=""numpy"",\n        help=""Numerical backend to test""\n    )\n\n\ndef pytest_collection_modifyitems(config, items):\n    if config.getoption(""--pyom2-lib""):\n        return\n    skip = pytest.mark.skip(reason=""need --pyom2-lib option to run"")\n    for item in items:\n        if ""pyom2_lib"" in item.fixturenames:\n            item.add_marker(skip)\n\n\ndef pytest_generate_tests(metafunc):\n    option_value = metafunc.config.option.pyom2_lib\n    if ""pyom2_lib"" in metafunc.fixturenames and option_value is not None:\n        metafunc.parametrize(""pyom2_lib"", [option_value])\n\n    option_value = metafunc.config.option.backend\n    if ""backend"" in metafunc.fixturenames:\n        metafunc.parametrize(""backend"", [option_value])\n'"
run_benchmarks.py,4,"b'#! /usr/bin/env python\n\nimport sys\nimport os\nimport subprocess\nimport multiprocessing\nimport importlib\nimport importlib.util\nimport re\nimport time\nimport math\nimport itertools\n\nimport click\nimport numpy as np\nimport ruamel.yaml as yaml\n\n""""""\nRuns selected Veros benchmarks back to back and writes timing results to a YAML file.\n""""""\n\nTESTDIR = os.path.join(os.path.dirname(__file__), os.path.relpath(\'benchmarks\'))\nCOMPONENTS = [\'numpy\', \'numpy-mpi\', \'bohrium\', \'bohrium-opencl\', \'bohrium-cuda\', \'bohrium-mpi\', \'fortran\', \'fortran-mpi\']\nSTATIC_SETTINGS = \'-v debug -s nx {nx} -s ny {ny} -s nz {nz} -s default_float_type {float_type} --timesteps {timesteps}\'\nBENCHMARK_COMMANDS = {\n    \'numpy\': \'{python} {filename} -b numpy \' + STATIC_SETTINGS,\n    \'numpy-mpi\': \'{mpiexec} -n {nproc} {python} {filename} -b numpy -n {decomp} \' + STATIC_SETTINGS,\n    \'bohrium\': \'OMP_NUM_THREADS={nproc} BH_STACK=openmp BH_OPENMP_PROF=1 {python} {filename} -b bohrium \'  + STATIC_SETTINGS,\n    \'bohrium-opencl\': \'BH_STACK=opencl BH_OPENCL_PROF=1 {python} {filename} -b bohrium \' + STATIC_SETTINGS,\n    \'bohrium-cuda\': \'BH_STACK=cuda BH_CUDA_PROF=1 {python} {filename} -b bohrium \' + STATIC_SETTINGS,\n    \'bohrium-mpi\': \'OMP_NUM_THREADS=1 {mpiexec} -n {nproc} {python} {filename} -b bohrium -n {decomp} \' + STATIC_SETTINGS,\n    \'fortran\': \'{python} {filename} --fortran {fortran_library} \' + STATIC_SETTINGS,\n    \'fortran-mpi\': \'{mpiexec} -n {nproc} {python} {filename} --fortran {fortran_library} -n {decomp} \' + STATIC_SETTINGS\n}\nSLURM_COMMANDS = {\n    \'numpy\': \'srun --ntasks 1 --cpus-per-task {nproc} -- {python} {filename} -b numpy \' + STATIC_SETTINGS,\n    \'numpy-mpi\': \'srun --ntasks {nproc} --cpus-per-task 1 -- {python} {filename} -b numpy -n {decomp} \' + STATIC_SETTINGS,\n    \'bohrium\': \'OMP_NUM_THREADS={nproc} BH_STACK=openmp BH_OPENMP_PROF=1 srun --ntasks 1 --cpus-per-task {nproc} -- {python} {filename} -b bohrium \' + STATIC_SETTINGS,\n    \'bohrium-opencl\': \'BH_STACK=opencl BH_OPENCL_PROF=1 srun --ntasks 1 --cpus-per-task {nproc} -- {python} {filename} -b bohrium \' + STATIC_SETTINGS,\n    \'bohrium-cuda\': \'BH_STACK=cuda BH_CUDA_PROF=1 srun --ntasks 1 --cpus-per-task {nproc} -- {python} {filename} -b bohrium \' + STATIC_SETTINGS,\n    \'bohrium-mpi\': \'OMP_NUM_THREADS=1 srun --ntasks {nproc} --cpus-per-task 2 -- {python} {filename} -b bohrium -n {decomp} \' + STATIC_SETTINGS,\n    \'fortran\': \'srun --ntasks 1 -- {python} {filename} --fortran {fortran_library} \' + STATIC_SETTINGS,\n    \'fortran-mpi\': \'srun --ntasks {nproc} --cpus-per-task 1 -- {python} {filename} --fortran {fortran_library} -n {decomp} \' + STATIC_SETTINGS\n}\nAVAILABLE_BENCHMARKS = [f for f in os.listdir(TESTDIR) if f.endswith(\'_benchmark.py\')]\nTIME_PATTERN = r\'Time step took ([-+]?[0-9]*\\.?[0-9]+(?:[eE][-+]?[0-9]+)?)s\'\n\n\ndef check_arguments(fortran_library, components, float_type, burnin, timesteps, **kwargs):\n    fortran_version = check_fortran_library(fortran_library)\n\n    if \'fortran\' in components or \'fortran-mpi\' in components:\n        if not fortran_library:\n            raise click.UsageError(\'Path to fortran library must be given when running fortran components\')\n        if not fortran_version:\n            raise click.UsageError(\'Fortran library failed to import\')\n\n    if fortran_version != \'parallel\' and \'fortran-mpi\' in components:\n        raise click.UsageError(\'Fortran library must be compiled with MPI support for fortran-mpi component\')\n\n    if float_type != \'float64\' and (\'fortran\' in components or \'fortran-mpi\' in components):\n        raise click.UsageError(\'Can run Fortran components only with ""float64"" float type\')\n\n    if not burnin < timesteps:\n        raise click.UsageError(\'burnin must be smaller than number of timesteps\')\n\n\ndef check_fortran_library(path):\n    if not path:\n        return None\n\n    def _check_library(module):\n        spec = importlib.util.spec_from_file_location(module, path)\n        try:\n            importlib.util.module_from_spec(spec)\n        except ImportError:\n            return False\n        else:\n            return True\n\n    if _check_library(\'pyOM_code\'):\n        return \'sequential\'\n\n    if _check_library(\'pyOM_code_MPI\'):\n        return \'parallel\'\n\n    return None\n\n\ndef _factorize(num):\n    j = 2\n    while num > 1:\n        for i in range(j, int(math.sqrt(num + 0.05)) + 1):\n            if num % i == 0:\n                num /= i\n                j = i\n                yield i\n                break\n        else:\n            if num > 1:\n                yield num\n                break\n\n\ndef _decompose_num(num, into=2):\n    out = [1] * into\n    for fac, i in zip(_factorize(num), itertools.cycle(range(into))):\n        out[i] *= fac\n\n    return tuple(map(int, out))\n\n\ndef _round_to_multiple(num, divisor):\n    return int(round(num / divisor) * divisor)\n\n\n@click.command(\'veros-benchmarks\', help=\'Run Veros benchmarks\')\n@click.option(\'-f\', \'--fortran-library\', type=str, help=\'Path to pyOM2 fortran library\')\n@click.option(\'-s\', \'--sizes\', multiple=True, type=float, required=True,\n              help=\'Problem sizes to test (total number of elements)\')\n@click.option(\'-c\', \'--components\', multiple=True, type=click.Choice(COMPONENTS), default=[\'numpy\'], metavar=\'COMPONENT\',\n              help=\'Numerical backend components to benchmark (possible values: {})\'.format(\', \'.join(COMPONENTS)))\n@click.option(\'-n\', \'--nproc\', type=int, default=multiprocessing.cpu_count(),\n              help=\'Number of processes / threads for parallel execution\')\n@click.option(\'-o\', \'--outfile\', type=click.Path(exists=False), default=\'benchmark_{}.yaml\'.format(time.time()),\n              help=\'YAML file to write timings to\')\n@click.option(\'-t\', \'--timesteps\', default=100, type=int, help=\'Number of time steps that each benchmark is run for\')\n@click.option(\'--only\', multiple=True, default=AVAILABLE_BENCHMARKS,\n              help=\'Run only these benchmarks (possible values: {})\'.format(\', \'.join(AVAILABLE_BENCHMARKS)),\n              type=click.Choice(AVAILABLE_BENCHMARKS), required=False, metavar=\'BENCHMARK\')\n@click.option(\'--mpiexec\', default=\'mpiexec\', help=\'Executable used for calling MPI (e.g. mpirun, mpiexec)\')\n@click.option(\'--slurm\', is_flag=True, help=\'Run benchmarks using SLURM scheduling command (srun)\')\n@click.option(\'--debug\', is_flag=True, help=\'Additionally print each command that is executed\')\n@click.option(\'--float-type\', default=\'float64\', help=\'Data type for floating point arrays in Veros components\')\n@click.option(\'--burnin\', default=3, type=int, help=\'Number of iterations to exclude in timings\')\ndef run(**kwargs):\n    check_arguments(**kwargs)\n\n    proc_decom = _decompose_num(kwargs[\'nproc\'], 2)\n    settings = {\n        \'timesteps\': kwargs[\'timesteps\'],\n        \'nproc\': kwargs[\'nproc\'],\n        \'float_type\': kwargs[\'float_type\'],\n        \'burnin\': kwargs[\'burnin\'],\n        \'decomp\': \'%s %s\' % proc_decom,\n        \'fortran_library\': kwargs[\'fortran_library\'],\n        \'mpiexec\': kwargs[\'mpiexec\'],\n    }\n\n    out_data = {}\n    all_passed = True\n    try:\n        for f in kwargs[\'only\']:\n            out_data[f] = []\n            print(\'running benchmark {} \'.format(f))\n            for size in kwargs[\'sizes\']:\n                n = int(size ** (1. / 3.)) + 1\n                nx = _round_to_multiple(2 * n, proc_decom[0])\n                ny = _round_to_multiple(2 * n, proc_decom[1])\n                nz = n // 4\n                real_size = nx * ny * nz\n                print(\' current size: {}\'.format(real_size))\n\n                cmd_args = settings.copy()\n                cmd_args.update({\n                    \'python\': sys.executable,\n                    \'filename\': os.path.realpath(os.path.join(TESTDIR, f)),\n                    \'nx\': nx, \'ny\': ny, \'nz\': nz\n                })\n\n                for comp in kwargs[\'components\']:\n                    cmd = (SLURM_COMMANDS[comp] if kwargs[\'slurm\'] else BENCHMARK_COMMANDS[comp]).format(**cmd_args)\n                    if kwargs[\'debug\']:\n                        print(\'  $ \' + cmd)\n                    sys.stdout.write(\'  {:<15} ... \'.format(comp))\n                    sys.stdout.flush()\n                    try: # must run each benchmark in its own Python subprocess to reload the Fortran library\n                        output = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)\n                    except subprocess.CalledProcessError as e:\n                        print(\'failed\')\n                        print(e.output.decode(\'utf-8\'))\n                        all_passed = False\n                        continue\n                    output = output.decode(\'utf-8\')\n                    iteration_times = list(map(float, re.findall(TIME_PATTERN, output)))[kwargs[\'burnin\']:]\n                    if not iteration_times:\n                        raise RuntimeError(\'could not extract iteration times from output\')\n                    total_elapsed = sum(iteration_times)\n                    print(\'{:>6.2f}s\'.format(total_elapsed))\n\n                    bohrium_stats = None\n                    if \'bohrium\' in comp:\n                        bohrium_stats = {\'Pre-fusion\': None, \'Fusion\': None,\n                                         \'Compilation\': None, \'Exec\': None,\n                                         \'Copy2dev\': None, \'Copy2host\': None,\n                                         \'Offload\': None, \'Other\': None}\n                        patterns = {stat: r\'\\s*{}\\:\\s*(\\d+\\.?\\d*)s\'.format(stat) for stat in bohrium_stats.keys()}\n                        for line in output.splitlines():\n                            for stat in bohrium_stats.keys():\n                                match = re.match(patterns[stat], line)\n                                if match:\n                                    bohrium_stats[stat] = float(match.group(1))\n\n                    out_data[f].append({\n                        \'component\': comp,\n                        \'size\': real_size,\n                        \'wall_time\': total_elapsed,\n                        \'per_iteration\': {\n                            \'best\': float(np.min(iteration_times)),\n                            \'worst\': float(np.max(iteration_times)),\n                            \'mean\': float(np.mean(iteration_times)),\n                            \'stdev\': float(np.std(iteration_times)),\n                        },\n                        \'bohrium_stats\': bohrium_stats\n                    })\n    finally:\n        with open(kwargs[\'outfile\'], \'w\') as f:\n            yaml.dump({\'benchmarks\': out_data, \'settings\': settings}, f, default_flow_style=False)\n\n    raise SystemExit(int(not all_passed))\n\n\nif __name__ == \'__main__\':\n    run()\n'"
setup.py,0,"b'#!/usr/bin/env python\n# coding=utf-8\n\nfrom setuptools import setup, find_packages\nfrom codecs import open\nimport os\nimport re\n\nimport versioneer\n\n\nCLASSIFIERS = """"""\nDevelopment Status :: 3 - Alpha\nIntended Audience :: Science/Research\nLicense :: OSI Approved :: MIT License\nProgramming Language :: Python :: 3\nProgramming Language :: Python :: 3.5\nProgramming Language :: Python :: 3.6\nProgramming Language :: Python :: 3.7\nProgramming Language :: Python :: Implementation :: CPython\nTopic :: Scientific/Engineering\nOperating System :: Microsoft :: Windows\nOperating System :: POSIX\nOperating System :: Unix\nOperating System :: MacOS\n""""""\n\nMINIMUM_VERSIONS = {\n    \'numpy\': \'1.13\',\n    \'requests\': \'2.18\',\n}\n\nEXTRAS_REQUIRE = {\n    \'test\': [\n        \'pytest\',\n        \'pytest-cov\',\n        \'pytest-xdist\',\n        \'codecov\',\n        \'petsc4py\',\n        \'mpi4py\'\n    ]\n}\n\nCONSOLE_SCRIPTS = [\n    \'veros = veros.cli.veros:cli\',\n    \'veros-run = veros.cli.veros_run:cli\',\n    \'veros-copy-setup = veros.cli.veros_copy_setup:cli\',\n    \'veros-resubmit = veros.cli.veros_resubmit:cli\',\n    \'veros-create-mask = veros.cli.veros_create_mask:cli\'\n]\n\nPACKAGE_DATA = [\'setup/*/assets.yml\', \'setup/*/*.npy\', \'setup/*/*.png\']\n\nhere = os.path.abspath(os.path.dirname(__file__))\n\nwith open(os.path.join(here, \'README.md\'), encoding=\'utf-8\') as f:\n    long_description = f.read()\n\ninstall_requires = []\nwith open(os.path.join(here, \'requirements.txt\'), encoding=\'utf-8\') as f:\n    for line in f:\n        line = line.strip()\n        pkg = re.match(r\'(\\w+)\\b.*\', line).group(1)\n        if pkg in MINIMUM_VERSIONS:\n            line = \'\'.join([line, \',>=\', MINIMUM_VERSIONS[pkg]])\n        line = line.replace(\'==\', \'<=\')\n        install_requires.append(line)\n\nsetup(\n    name=\'veros\',\n    license=\'MIT\',\n    author=\'Dion H\xc3\xa4fner (NBI Copenhagen)\',\n    author_email=\'dion.haefner@nbi.ku.dk\',\n    keywords=\'oceanography python parallel numpy multi-core \'\n             \'geophysics ocean-model bohrium mpi4py\',\n    description=\'The versatile ocean simulator, in pure Python, powered by Bohrium.\',\n    long_description=long_description,\n    long_description_content_type=\'text/markdown\',\n    url=\'https://veros.readthedocs.io\',\n    python_requires=\'>3.5.2\',\n    version=versioneer.get_version(),\n    cmdclass=versioneer.get_cmdclass(),\n    packages=find_packages(),\n    install_requires=install_requires,\n    extras_require=EXTRAS_REQUIRE,\n    entry_points={\n        \'console_scripts\': CONSOLE_SCRIPTS,\n        \'veros.setup_dirs\': [\n            \'base = veros.setup\'\n        ]\n    },\n    package_data={\n        \'veros\': PACKAGE_DATA\n    },\n    classifiers=[c for c in CLASSIFIERS.split(\'\\n\') if c],\n    zip_safe=False,\n)\n'"
versioneer.py,0,"b'\n# Version: 0.18\n\n""""""The Versioneer - like a rocketeer, but for versions.\n\nThe Versioneer\n==============\n\n* like a rocketeer, but for versions!\n* https://github.com/warner/python-versioneer\n* Brian Warner\n* License: Public Domain\n* Compatible With: python2.6, 2.7, 3.2, 3.3, 3.4, 3.5, 3.6, and pypy\n* [![Latest Version]\n(https://pypip.in/version/versioneer/badge.svg?style=flat)\n](https://pypi.python.org/pypi/versioneer/)\n* [![Build Status]\n(https://travis-ci.org/warner/python-versioneer.png?branch=master)\n](https://travis-ci.org/warner/python-versioneer)\n\nThis is a tool for managing a recorded version number in distutils-based\npython projects. The goal is to remove the tedious and error-prone ""update\nthe embedded version string"" step from your release process. Making a new\nrelease should be as easy as recording a new tag in your version-control\nsystem, and maybe making new tarballs.\n\n\n## Quick Install\n\n* `pip install versioneer` to somewhere to your $PATH\n* add a `[versioneer]` section to your setup.cfg (see below)\n* run `versioneer install` in your source tree, commit the results\n\n## Version Identifiers\n\nSource trees come from a variety of places:\n\n* a version-control system checkout (mostly used by developers)\n* a nightly tarball, produced by build automation\n* a snapshot tarball, produced by a web-based VCS browser, like github\'s\n  ""tarball from tag"" feature\n* a release tarball, produced by ""setup.py sdist"", distributed through PyPI\n\nWithin each source tree, the version identifier (either a string or a number,\nthis tool is format-agnostic) can come from a variety of places:\n\n* ask the VCS tool itself, e.g. ""git describe"" (for checkouts), which knows\n  about recent ""tags"" and an absolute revision-id\n* the name of the directory into which the tarball was unpacked\n* an expanded VCS keyword ($Id$, etc)\n* a `_version.py` created by some earlier build step\n\nFor released software, the version identifier is closely related to a VCS\ntag. Some projects use tag names that include more than just the version\nstring (e.g. ""myproject-1.2"" instead of just ""1.2""), in which case the tool\nneeds to strip the tag prefix to extract the version identifier. For\nunreleased software (between tags), the version identifier should provide\nenough information to help developers recreate the same tree, while also\ngiving them an idea of roughly how old the tree is (after version 1.2, before\nversion 1.3). Many VCS systems can report a description that captures this,\nfor example `git describe --tags --dirty --always` reports things like\n""0.7-1-g574ab98-dirty"" to indicate that the checkout is one revision past the\n0.7 tag, has a unique revision id of ""574ab98"", and is ""dirty"" (it has\nuncommitted changes.\n\nThe version identifier is used for multiple purposes:\n\n* to allow the module to self-identify its version: `myproject.__version__`\n* to choose a name and prefix for a \'setup.py sdist\' tarball\n\n## Theory of Operation\n\nVersioneer works by adding a special `_version.py` file into your source\ntree, where your `__init__.py` can import it. This `_version.py` knows how to\ndynamically ask the VCS tool for version information at import time.\n\n`_version.py` also contains `$Revision$` markers, and the installation\nprocess marks `_version.py` to have this marker rewritten with a tag name\nduring the `git archive` command. As a result, generated tarballs will\ncontain enough information to get the proper version.\n\nTo allow `setup.py` to compute a version too, a `versioneer.py` is added to\nthe top level of your source tree, next to `setup.py` and the `setup.cfg`\nthat configures it. This overrides several distutils/setuptools commands to\ncompute the version when invoked, and changes `setup.py build` and `setup.py\nsdist` to replace `_version.py` with a small static file that contains just\nthe generated version data.\n\n## Installation\n\nSee [INSTALL.md](./INSTALL.md) for detailed installation instructions.\n\n## Version-String Flavors\n\nCode which uses Versioneer can learn about its version string at runtime by\nimporting `_version` from your main `__init__.py` file and running the\n`get_versions()` function. From the ""outside"" (e.g. in `setup.py`), you can\nimport the top-level `versioneer.py` and run `get_versions()`.\n\nBoth functions return a dictionary with different flavors of version\ninformation:\n\n* `[\'version\']`: A condensed version string, rendered using the selected\n  style. This is the most commonly used value for the project\'s version\n  string. The default ""pep440"" style yields strings like `0.11`,\n  `0.11+2.g1076c97`, or `0.11+2.g1076c97.dirty`. See the ""Styles"" section\n  below for alternative styles.\n\n* `[\'full-revisionid\']`: detailed revision identifier. For Git, this is the\n  full SHA1 commit id, e.g. ""1076c978a8d3cfc70f408fe5974aa6c092c949ac"".\n\n* `[\'date\']`: Date and time of the latest `HEAD` commit. For Git, it is the\n  commit date in ISO 8601 format. This will be None if the date is not\n  available.\n\n* `[\'dirty\']`: a boolean, True if the tree has uncommitted changes. Note that\n  this is only accurate if run in a VCS checkout, otherwise it is likely to\n  be False or None\n\n* `[\'error\']`: if the version string could not be computed, this will be set\n  to a string describing the problem, otherwise it will be None. It may be\n  useful to throw an exception in setup.py if this is set, to avoid e.g.\n  creating tarballs with a version string of ""unknown"".\n\nSome variants are more useful than others. Including `full-revisionid` in a\nbug report should allow developers to reconstruct the exact code being tested\n(or indicate the presence of local changes that should be shared with the\ndevelopers). `version` is suitable for display in an ""about"" box or a CLI\n`--version` output: it can be easily compared against release notes and lists\nof bugs fixed in various releases.\n\nThe installer adds the following text to your `__init__.py` to place a basic\nversion in `YOURPROJECT.__version__`:\n\n    from ._version import get_versions\n    __version__ = get_versions()[\'version\']\n    del get_versions\n\n## Styles\n\nThe setup.cfg `style=` configuration controls how the VCS information is\nrendered into a version string.\n\nThe default style, ""pep440"", produces a PEP440-compliant string, equal to the\nun-prefixed tag name for actual releases, and containing an additional ""local\nversion"" section with more detail for in-between builds. For Git, this is\nTAG[+DISTANCE.gHEX[.dirty]] , using information from `git describe --tags\n--dirty --always`. For example ""0.11+2.g1076c97.dirty"" indicates that the\ntree is like the ""1076c97"" commit but has uncommitted changes ("".dirty""), and\nthat this commit is two revisions (""+2"") beyond the ""0.11"" tag. For released\nsoftware (exactly equal to a known tag), the identifier will only contain the\nstripped tag, e.g. ""0.11"".\n\nOther styles are available. See [details.md](details.md) in the Versioneer\nsource tree for descriptions.\n\n## Debugging\n\nVersioneer tries to avoid fatal errors: if something goes wrong, it will tend\nto return a version of ""0+unknown"". To investigate the problem, run `setup.py\nversion`, which will run the version-lookup code in a verbose mode, and will\ndisplay the full contents of `get_versions()` (including the `error` string,\nwhich may help identify what went wrong).\n\n## Known Limitations\n\nSome situations are known to cause problems for Versioneer. This details the\nmost significant ones. More can be found on Github\n[issues page](https://github.com/warner/python-versioneer/issues).\n\n### Subprojects\n\nVersioneer has limited support for source trees in which `setup.py` is not in\nthe root directory (e.g. `setup.py` and `.git/` are *not* siblings). The are\ntwo common reasons why `setup.py` might not be in the root:\n\n* Source trees which contain multiple subprojects, such as\n  [Buildbot](https://github.com/buildbot/buildbot), which contains both\n  ""master"" and ""slave"" subprojects, each with their own `setup.py`,\n  `setup.cfg`, and `tox.ini`. Projects like these produce multiple PyPI\n  distributions (and upload multiple independently-installable tarballs).\n* Source trees whose main purpose is to contain a C library, but which also\n  provide bindings to Python (and perhaps other langauges) in subdirectories.\n\nVersioneer will look for `.git` in parent directories, and most operations\nshould get the right version string. However `pip` and `setuptools` have bugs\nand implementation details which frequently cause `pip install .` from a\nsubproject directory to fail to find a correct version string (so it usually\ndefaults to `0+unknown`).\n\n`pip install --editable .` should work correctly. `setup.py install` might\nwork too.\n\nPip-8.1.1 is known to have this problem, but hopefully it will get fixed in\nsome later version.\n\n[Bug #38](https://github.com/warner/python-versioneer/issues/38) is tracking\nthis issue. The discussion in\n[PR #61](https://github.com/warner/python-versioneer/pull/61) describes the\nissue from the Versioneer side in more detail.\n[pip PR#3176](https://github.com/pypa/pip/pull/3176) and\n[pip PR#3615](https://github.com/pypa/pip/pull/3615) contain work to improve\npip to let Versioneer work correctly.\n\nVersioneer-0.16 and earlier only looked for a `.git` directory next to the\n`setup.cfg`, so subprojects were completely unsupported with those releases.\n\n### Editable installs with setuptools <= 18.5\n\n`setup.py develop` and `pip install --editable .` allow you to install a\nproject into a virtualenv once, then continue editing the source code (and\ntest) without re-installing after every change.\n\n""Entry-point scripts"" (`setup(entry_points={""console_scripts"": ..})`) are a\nconvenient way to specify executable scripts that should be installed along\nwith the python package.\n\nThese both work as expected when using modern setuptools. When using\nsetuptools-18.5 or earlier, however, certain operations will cause\n`pkg_resources.DistributionNotFound` errors when running the entrypoint\nscript, which must be resolved by re-installing the package. This happens\nwhen the install happens with one version, then the egg_info data is\nregenerated while a different version is checked out. Many setup.py commands\ncause egg_info to be rebuilt (including `sdist`, `wheel`, and installing into\na different virtualenv), so this can be surprising.\n\n[Bug #83](https://github.com/warner/python-versioneer/issues/83) describes\nthis one, but upgrading to a newer version of setuptools should probably\nresolve it.\n\n### Unicode version strings\n\nWhile Versioneer works (and is continually tested) with both Python 2 and\nPython 3, it is not entirely consistent with bytes-vs-unicode distinctions.\nNewer releases probably generate unicode version strings on py2. It\'s not\nclear that this is wrong, but it may be surprising for applications when then\nwrite these strings to a network connection or include them in bytes-oriented\nAPIs like cryptographic checksums.\n\n[Bug #71](https://github.com/warner/python-versioneer/issues/71) investigates\nthis question.\n\n\n## Updating Versioneer\n\nTo upgrade your project to a new release of Versioneer, do the following:\n\n* install the new Versioneer (`pip install -U versioneer` or equivalent)\n* edit `setup.cfg`, if necessary, to include any new configuration settings\n  indicated by the release notes. See [UPGRADING](./UPGRADING.md) for details.\n* re-run `versioneer install` in your source tree, to replace\n  `SRC/_version.py`\n* commit any changed files\n\n## Future Directions\n\nThis tool is designed to make it easily extended to other version-control\nsystems: all VCS-specific components are in separate directories like\nsrc/git/ . The top-level `versioneer.py` script is assembled from these\ncomponents by running make-versioneer.py . In the future, make-versioneer.py\nwill take a VCS name as an argument, and will construct a version of\n`versioneer.py` that is specific to the given VCS. It might also take the\nconfiguration arguments that are currently provided manually during\ninstallation by editing setup.py . Alternatively, it might go the other\ndirection and include code from all supported VCS systems, reducing the\nnumber of intermediate scripts.\n\n\n## License\n\nTo make Versioneer easier to embed, all its code is dedicated to the public\ndomain. The `_version.py` that it creates is also in the public domain.\nSpecifically, both are released under the Creative Commons ""Public Domain\nDedication"" license (CC0-1.0), as described in\nhttps://creativecommons.org/publicdomain/zero/1.0/ .\n\n""""""\n\nfrom __future__ import print_function\ntry:\n    import configparser\nexcept ImportError:\n    import ConfigParser as configparser\nimport errno\nimport json\nimport os\nimport re\nimport subprocess\nimport sys\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_root():\n    """"""Get the project root directory.\n\n    We require that all commands are run from the project root, i.e. the\n    directory that contains setup.py, setup.cfg, and versioneer.py .\n    """"""\n    root = os.path.realpath(os.path.abspath(os.getcwd()))\n    setup_py = os.path.join(root, ""setup.py"")\n    versioneer_py = os.path.join(root, ""versioneer.py"")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        # allow \'python path/to/setup.py COMMAND\'\n        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))\n        setup_py = os.path.join(root, ""setup.py"")\n        versioneer_py = os.path.join(root, ""versioneer.py"")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        err = (""Versioneer was unable to run the project root directory. ""\n               ""Versioneer requires setup.py to be executed from ""\n               ""its immediate directory (like \'python setup.py COMMAND\'), ""\n               ""or in a way that lets it use sys.argv[0] to find the root ""\n               ""(like \'python path/to/setup.py COMMAND\')."")\n        raise VersioneerBadRootError(err)\n    try:\n        # Certain runtime workflows (setup.py install/develop in a setuptools\n        # tree) execute all dependencies in a single python process, so\n        # ""versioneer"" may be imported multiple times, and python\'s shared\n        # module-import table will cache the first one. So we can\'t use\n        # os.path.dirname(__file__), as that will find whichever\n        # versioneer.py was first imported, even in later projects.\n        me = os.path.realpath(os.path.abspath(__file__))\n        me_dir = os.path.normcase(os.path.splitext(me)[0])\n        vsr_dir = os.path.normcase(os.path.splitext(versioneer_py)[0])\n        if me_dir != vsr_dir:\n            print(""Warning: build in %s is using versioneer.py from %s""\n                  % (os.path.dirname(me), versioneer_py))\n    except NameError:\n        pass\n    return root\n\n\ndef get_config_from_root(root):\n    """"""Read the project setup.cfg file to determine Versioneer config.""""""\n    # This might raise EnvironmentError (if setup.cfg is missing), or\n    # configparser.NoSectionError (if it lacks a [versioneer] section), or\n    # configparser.NoOptionError (if it lacks ""VCS=""). See the docstring at\n    # the top of versioneer.py for instructions on writing your setup.cfg .\n    setup_cfg = os.path.join(root, ""setup.cfg"")\n    parser = configparser.SafeConfigParser()\n    with open(setup_cfg, ""r"") as f:\n        parser.readfp(f)\n    VCS = parser.get(""versioneer"", ""VCS"")  # mandatory\n\n    def get(parser, name):\n        if parser.has_option(""versioneer"", name):\n            return parser.get(""versioneer"", name)\n        return None\n    cfg = VersioneerConfig()\n    cfg.VCS = VCS\n    cfg.style = get(parser, ""style"") or """"\n    cfg.versionfile_source = get(parser, ""versionfile_source"")\n    cfg.versionfile_build = get(parser, ""versionfile_build"")\n    cfg.tag_prefix = get(parser, ""tag_prefix"")\n    if cfg.tag_prefix in (""\'\'"", \'""""\'):\n        cfg.tag_prefix = """"\n    cfg.parentdir_prefix = get(parser, ""parentdir_prefix"")\n    cfg.verbose = get(parser, ""verbose"")\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\n# these dictionaries contain VCS-specific tools\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n                env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %s"" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %s"" % (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %s (error)"" % dispcmd)\n            print(""stdout was %s"" % stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\nLONG_VERSION_PY[\'git\'] = \'\'\'\n# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain. Generated by\n# versioneer-0.18 (https://github.com/warner/python-versioneer)\n\n""""""Git implementation of _version.py.""""""\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\n\n\ndef get_keywords():\n    """"""Get the keywords needed to look up the version information.""""""\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = ""%(DOLLAR)sFormat:%%d%(DOLLAR)s""\n    git_full = ""%(DOLLAR)sFormat:%%H%(DOLLAR)s""\n    git_date = ""%(DOLLAR)sFormat:%%ci%(DOLLAR)s""\n    keywords = {""refnames"": git_refnames, ""full"": git_full, ""date"": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_config():\n    """"""Create, populate and return the VersioneerConfig() object.""""""\n    # these strings are filled in when \'setup.py versioneer\' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = ""git""\n    cfg.style = ""%(STYLE)s""\n    cfg.tag_prefix = ""%(TAG_PREFIX)s""\n    cfg.parentdir_prefix = ""%(PARENTDIR_PREFIX)s""\n    cfg.versionfile_source = ""%(VERSIONFILE_SOURCE)s""\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n                env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %%s"" %% dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %%s"" %% (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %%s (error)"" %% dispcmd)\n            print(""stdout was %%s"" %% stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {""version"": dirname[len(parentdir_prefix):],\n                    ""full-revisionid"": None,\n                    ""dirty"": False, ""error"": None, ""date"": None}\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(""Tried directories %%s but none started with prefix %%s"" %%\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %%d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r\'\\d\', r)])\n        if verbose:\n            print(""discarding \'%%s\', no digits"" %% "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %%s"" %% "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(""picking %%s"" %% r)\n            return {""version"": r,\n                    ""full-revisionid"": keywords[""full""].strip(),\n                    ""dirty"": False, ""error"": None,\n                    ""date"": date}\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {""version"": ""0+unknown"",\n            ""full-revisionid"": keywords[""full""].strip(),\n            ""dirty"": False, ""error"": ""no suitable tags"", ""date"": None}\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n                          hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %%s not under git control"" %% root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty"",\n                                          ""--always"", ""--long"",\n                                          ""--match"", ""%%s*"" %% tag_prefix],\n                                   cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\'^(.+)-(\\d+)-g([0-9a-f]+)$\', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = (""unable to parse git-describe output: \'%%s\'""\n                               %% describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%%s\' doesn\'t start with prefix \'%%s\'""\n                print(fmt %% (full_tag, tag_prefix))\n            pieces[""error""] = (""tag \'%%s\' doesn\'t start with prefix \'%%s\'""\n                               %% (full_tag, tag_prefix))\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n                                    cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%%ci"", ""HEAD""],\n                       cwd=root)[0].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%%d.g%%s"" %% (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%%d.g%%s"" %% (pieces[""distance""],\n                                          pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%%d"" %% pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%%d"" %% pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%%d"" %% pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%%s"" %% pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%%d"" %% pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%%s"" %% pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%%d"" %% pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%%d"" %% pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%%d-g%%s"" %% (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%%d-g%%s"" %% (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {""version"": ""unknown"",\n                ""full-revisionid"": pieces.get(""long""),\n                ""dirty"": None,\n                ""error"": pieces[""error""],\n                ""date"": None}\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%%s\'"" %% style)\n\n    return {""version"": rendered, ""full-revisionid"": pieces[""long""],\n            ""dirty"": pieces[""dirty""], ""error"": None,\n            ""date"": pieces.get(""date"")}\n\n\ndef get_versions():\n    """"""Get version information or return default if unable to do so.""""""\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don\'t do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split(\'/\'):\n            root = os.path.dirname(root)\n    except NameError:\n        return {""version"": ""0+unknown"", ""full-revisionid"": None,\n                ""dirty"": None,\n                ""error"": ""unable to find root of source tree"",\n                ""date"": None}\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {""version"": ""0+unknown"", ""full-revisionid"": None,\n            ""dirty"": None,\n            ""error"": ""unable to compute version"", ""date"": None}\n\'\'\'\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r\'\\d\', r)])\n        if verbose:\n            print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %s"" % "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(""picking %s"" % r)\n            return {""version"": r,\n                    ""full-revisionid"": keywords[""full""].strip(),\n                    ""dirty"": False, ""error"": None,\n                    ""date"": date}\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {""version"": ""0+unknown"",\n            ""full-revisionid"": keywords[""full""].strip(),\n            ""dirty"": False, ""error"": ""no suitable tags"", ""date"": None}\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n                          hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %s not under git control"" % root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty"",\n                                          ""--always"", ""--long"",\n                                          ""--match"", ""%s*"" % tag_prefix],\n                                   cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\'^(.+)-(\\d+)-g([0-9a-f]+)$\', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = (""unable to parse git-describe output: \'%s\'""\n                               % describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                print(fmt % (full_tag, tag_prefix))\n            pieces[""error""] = (""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                               % (full_tag, tag_prefix))\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n                                    cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""],\n                       cwd=root)[0].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef do_vcs_install(manifest_in, versionfile_source, ipy):\n    """"""Git-specific installation logic for Versioneer.\n\n    For Git, this means creating/changing .gitattributes to mark _version.py\n    for export-subst keyword substitution.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n    files = [manifest_in, versionfile_source]\n    if ipy:\n        files.append(ipy)\n    try:\n        me = __file__\n        if me.endswith("".pyc"") or me.endswith("".pyo""):\n            me = os.path.splitext(me)[0] + "".py""\n        versioneer_file = os.path.relpath(me)\n    except NameError:\n        versioneer_file = ""versioneer.py""\n    files.append(versioneer_file)\n    present = False\n    try:\n        f = open("".gitattributes"", ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(versionfile_source):\n                if ""export-subst"" in line.strip().split()[1:]:\n                    present = True\n        f.close()\n    except EnvironmentError:\n        pass\n    if not present:\n        f = open("".gitattributes"", ""a+"")\n        f.write(""%s export-subst\\n"" % versionfile_source)\n        f.close()\n        files.append("".gitattributes"")\n    run_command(GITS, [""add"", ""--""] + files)\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {""version"": dirname[len(parentdir_prefix):],\n                    ""full-revisionid"": None,\n                    ""dirty"": False, ""error"": None, ""date"": None}\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(""Tried directories %s but none started with prefix %s"" %\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\nSHORT_VERSION_PY = """"""\n# This file was generated by \'versioneer.py\' (0.18) from\n# revision-control system data, or from the parent directory name of an\n# unpacked source archive. Distribution tarballs contain a pre-generated copy\n# of this file.\n\nimport json\n\nversion_json = \'\'\'\n%s\n\'\'\'  # END VERSION_JSON\n\n\ndef get_versions():\n    return json.loads(version_json)\n""""""\n\n\ndef versions_from_file(filename):\n    """"""Try to determine the version from _version.py if present.""""""\n    try:\n        with open(filename) as f:\n            contents = f.read()\n    except EnvironmentError:\n        raise NotThisMethod(""unable to read _version.py"")\n    mo = re.search(r""version_json = \'\'\'\\n(.*)\'\'\'  # END VERSION_JSON"",\n                   contents, re.M | re.S)\n    if not mo:\n        mo = re.search(r""version_json = \'\'\'\\r\\n(.*)\'\'\'  # END VERSION_JSON"",\n                       contents, re.M | re.S)\n    if not mo:\n        raise NotThisMethod(""no version_json in _version.py"")\n    return json.loads(mo.group(1))\n\n\ndef write_to_version_file(filename, versions):\n    """"""Write the given version number to the given _version.py file.""""""\n    os.unlink(filename)\n    contents = json.dumps(versions, sort_keys=True,\n                          indent=1, separators=("","", "": ""))\n    with open(filename, ""w"") as f:\n        f.write(SHORT_VERSION_PY % contents)\n\n    print(""set %s to \'%s\'"" % (filename, versions[""version""]))\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%d.g%s"" % (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%d.g%s"" % (pieces[""distance""],\n                                          pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%d"" % pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%d"" % pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%s"" % pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%s"" % pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {""version"": ""unknown"",\n                ""full-revisionid"": pieces.get(""long""),\n                ""dirty"": None,\n                ""error"": pieces[""error""],\n                ""date"": None}\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%s\'"" % style)\n\n    return {""version"": rendered, ""full-revisionid"": pieces[""long""],\n            ""dirty"": pieces[""dirty""], ""error"": None,\n            ""date"": pieces.get(""date"")}\n\n\nclass VersioneerBadRootError(Exception):\n    """"""The project root directory is unknown or missing key files.""""""\n\n\ndef get_versions(verbose=False):\n    """"""Get the project version from whatever source is available.\n\n    Returns dict with two keys: \'version\' and \'full\'.\n    """"""\n    if ""versioneer"" in sys.modules:\n        # see the discussion in cmdclass.py:get_cmdclass()\n        del sys.modules[""versioneer""]\n\n    root = get_root()\n    cfg = get_config_from_root(root)\n\n    assert cfg.VCS is not None, ""please set [versioneer]VCS= in setup.cfg""\n    handlers = HANDLERS.get(cfg.VCS)\n    assert handlers, ""unrecognized VCS \'%s\'"" % cfg.VCS\n    verbose = verbose or cfg.verbose\n    assert cfg.versionfile_source is not None, \\\n        ""please set versioneer.versionfile_source""\n    assert cfg.tag_prefix is not None, ""please set versioneer.tag_prefix""\n\n    versionfile_abs = os.path.join(root, cfg.versionfile_source)\n\n    # extract version from first of: _version.py, VCS command (e.g. \'git\n    # describe\'), parentdir. This is meant to work for developers using a\n    # source checkout, for users of a tarball created by \'setup.py sdist\',\n    # and for users of a tarball/zipball created by \'git archive\' or github\'s\n    # download-from-tag feature or the equivalent in other VCSes.\n\n    get_keywords_f = handlers.get(""get_keywords"")\n    from_keywords_f = handlers.get(""keywords"")\n    if get_keywords_f and from_keywords_f:\n        try:\n            keywords = get_keywords_f(versionfile_abs)\n            ver = from_keywords_f(keywords, cfg.tag_prefix, verbose)\n            if verbose:\n                print(""got version from expanded keyword %s"" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        ver = versions_from_file(versionfile_abs)\n        if verbose:\n            print(""got version from file %s %s"" % (versionfile_abs, ver))\n        return ver\n    except NotThisMethod:\n        pass\n\n    from_vcs_f = handlers.get(""pieces_from_vcs"")\n    if from_vcs_f:\n        try:\n            pieces = from_vcs_f(cfg.tag_prefix, root, verbose)\n            ver = render(pieces, cfg.style)\n            if verbose:\n                print(""got version from VCS %s"" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        if cfg.parentdir_prefix:\n            ver = versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n            if verbose:\n                print(""got version from parentdir %s"" % ver)\n            return ver\n    except NotThisMethod:\n        pass\n\n    if verbose:\n        print(""unable to compute version"")\n\n    return {""version"": ""0+unknown"", ""full-revisionid"": None,\n            ""dirty"": None, ""error"": ""unable to compute version"",\n            ""date"": None}\n\n\ndef get_version():\n    """"""Get the short version string for this project.""""""\n    return get_versions()[""version""]\n\n\ndef get_cmdclass():\n    """"""Get the custom setuptools/distutils subclasses used by Versioneer.""""""\n    if ""versioneer"" in sys.modules:\n        del sys.modules[""versioneer""]\n        # this fixes the ""python setup.py develop"" case (also \'install\' and\n        # \'easy_install .\'), in which subdependencies of the main project are\n        # built (using setup.py bdist_egg) in the same python process. Assume\n        # a main project A and a dependency B, which use different versions\n        # of Versioneer. A\'s setup.py imports A\'s Versioneer, leaving it in\n        # sys.modules by the time B\'s setup.py is executed, causing B to run\n        # with the wrong versioneer. Setuptools wraps the sub-dep builds in a\n        # sandbox that restores sys.modules to it\'s pre-build state, so the\n        # parent is protected against the child\'s ""import versioneer"". By\n        # removing ourselves from sys.modules here, before the child build\n        # happens, we protect the child from the parent\'s versioneer too.\n        # Also see https://github.com/warner/python-versioneer/issues/52\n\n    cmds = {}\n\n    # we add ""version"" to both distutils and setuptools\n    from distutils.core import Command\n\n    class cmd_version(Command):\n        description = ""report generated version string""\n        user_options = []\n        boolean_options = []\n\n        def initialize_options(self):\n            pass\n\n        def finalize_options(self):\n            pass\n\n        def run(self):\n            vers = get_versions(verbose=True)\n            print(""Version: %s"" % vers[""version""])\n            print("" full-revisionid: %s"" % vers.get(""full-revisionid""))\n            print("" dirty: %s"" % vers.get(""dirty""))\n            print("" date: %s"" % vers.get(""date""))\n            if vers[""error""]:\n                print("" error: %s"" % vers[""error""])\n    cmds[""version""] = cmd_version\n\n    # we override ""build_py"" in both distutils and setuptools\n    #\n    # most invocation pathways end up running build_py:\n    #  distutils/build -> build_py\n    #  distutils/install -> distutils/build ->..\n    #  setuptools/bdist_wheel -> distutils/install ->..\n    #  setuptools/bdist_egg -> distutils/install_lib -> build_py\n    #  setuptools/install -> bdist_egg ->..\n    #  setuptools/develop -> ?\n    #  pip install:\n    #   copies source tree to a tempdir before running egg_info/etc\n    #   if .git isn\'t copied too, \'git describe\' will fail\n    #   then does setup.py bdist_wheel, or sometimes setup.py install\n    #  setup.py egg_info -> ?\n\n    # we override different ""build_py"" commands for both environments\n    if ""setuptools"" in sys.modules:\n        from setuptools.command.build_py import build_py as _build_py\n    else:\n        from distutils.command.build_py import build_py as _build_py\n\n    class cmd_build_py(_build_py):\n        def run(self):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_py.run(self)\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            if cfg.versionfile_build:\n                target_versionfile = os.path.join(self.build_lib,\n                                                  cfg.versionfile_build)\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n    cmds[""build_py""] = cmd_build_py\n\n    if ""cx_Freeze"" in sys.modules:  # cx_freeze enabled?\n        from cx_Freeze.dist import build_exe as _build_exe\n        # nczeczulin reports that py2exe won\'t like the pep440-style string\n        # as FILEVERSION, but it can be used for PRODUCTVERSION, e.g.\n        # setup(console=[{\n        #   ""version"": versioneer.get_version().split(""+"", 1)[0], # FILEVERSION\n        #   ""product_version"": versioneer.get_version(),\n        #   ...\n\n        class cmd_build_exe(_build_exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _build_exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, ""w"") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {""DOLLAR"": ""$"",\n                             ""STYLE"": cfg.style,\n                             ""TAG_PREFIX"": cfg.tag_prefix,\n                             ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                             ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                             })\n        cmds[""build_exe""] = cmd_build_exe\n        del cmds[""build_py""]\n\n    if \'py2exe\' in sys.modules:  # py2exe enabled?\n        try:\n            from py2exe.distutils_buildexe import py2exe as _py2exe  # py3\n        except ImportError:\n            from py2exe.build_exe import py2exe as _py2exe  # py2\n\n        class cmd_py2exe(_py2exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(""UPDATING %s"" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _py2exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, ""w"") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {""DOLLAR"": ""$"",\n                             ""STYLE"": cfg.style,\n                             ""TAG_PREFIX"": cfg.tag_prefix,\n                             ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                             ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                             })\n        cmds[""py2exe""] = cmd_py2exe\n\n    # we override different ""sdist"" commands for both environments\n    if ""setuptools"" in sys.modules:\n        from setuptools.command.sdist import sdist as _sdist\n    else:\n        from distutils.command.sdist import sdist as _sdist\n\n    class cmd_sdist(_sdist):\n        def run(self):\n            versions = get_versions()\n            self._versioneer_generated_versions = versions\n            # unless we update this, the command will keep using the old\n            # version\n            self.distribution.metadata.version = versions[""version""]\n            return _sdist.run(self)\n\n        def make_release_tree(self, base_dir, files):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            _sdist.make_release_tree(self, base_dir, files)\n            # now locate _version.py in the new base_dir directory\n            # (remembering that it may be a hardlink) and replace it with an\n            # updated value\n            target_versionfile = os.path.join(base_dir, cfg.versionfile_source)\n            print(""UPDATING %s"" % target_versionfile)\n            write_to_version_file(target_versionfile,\n                                  self._versioneer_generated_versions)\n    cmds[""sdist""] = cmd_sdist\n\n    return cmds\n\n\nCONFIG_ERROR = """"""\nsetup.cfg is missing the necessary Versioneer configuration. You need\na section like:\n\n [versioneer]\n VCS = git\n style = pep440\n versionfile_source = src/myproject/_version.py\n versionfile_build = myproject/_version.py\n tag_prefix =\n parentdir_prefix = myproject-\n\nYou will also need to edit your setup.py to use the results:\n\n import versioneer\n setup(version=versioneer.get_version(),\n       cmdclass=versioneer.get_cmdclass(), ...)\n\nPlease read the docstring in ./versioneer.py for configuration instructions,\nedit setup.cfg, and re-run the installer or \'python versioneer.py setup\'.\n""""""\n\nSAMPLE_CONFIG = """"""\n# See the docstring in versioneer.py for instructions. Note that you must\n# re-run \'versioneer.py setup\' after changing this section, and commit the\n# resulting files.\n\n[versioneer]\n#VCS = git\n#style = pep440\n#versionfile_source =\n#versionfile_build =\n#tag_prefix =\n#parentdir_prefix =\n\n""""""\n\nINIT_PY_SNIPPET = """"""\nfrom ._version import get_versions\n__version__ = get_versions()[\'version\']\ndel get_versions\n""""""\n\n\ndef do_setup():\n    """"""Main VCS-independent setup function for installing Versioneer.""""""\n    root = get_root()\n    try:\n        cfg = get_config_from_root(root)\n    except (EnvironmentError, configparser.NoSectionError,\n            configparser.NoOptionError) as e:\n        if isinstance(e, (EnvironmentError, configparser.NoSectionError)):\n            print(""Adding sample versioneer config to setup.cfg"",\n                  file=sys.stderr)\n            with open(os.path.join(root, ""setup.cfg""), ""a"") as f:\n                f.write(SAMPLE_CONFIG)\n        print(CONFIG_ERROR, file=sys.stderr)\n        return 1\n\n    print("" creating %s"" % cfg.versionfile_source)\n    with open(cfg.versionfile_source, ""w"") as f:\n        LONG = LONG_VERSION_PY[cfg.VCS]\n        f.write(LONG % {""DOLLAR"": ""$"",\n                        ""STYLE"": cfg.style,\n                        ""TAG_PREFIX"": cfg.tag_prefix,\n                        ""PARENTDIR_PREFIX"": cfg.parentdir_prefix,\n                        ""VERSIONFILE_SOURCE"": cfg.versionfile_source,\n                        })\n\n    ipy = os.path.join(os.path.dirname(cfg.versionfile_source),\n                       ""__init__.py"")\n    if os.path.exists(ipy):\n        try:\n            with open(ipy, ""r"") as f:\n                old = f.read()\n        except EnvironmentError:\n            old = """"\n        if INIT_PY_SNIPPET not in old:\n            print("" appending to %s"" % ipy)\n            with open(ipy, ""a"") as f:\n                f.write(INIT_PY_SNIPPET)\n        else:\n            print("" %s unmodified"" % ipy)\n    else:\n        print("" %s doesn\'t exist, ok"" % ipy)\n        ipy = None\n\n    # Make sure both the top-level ""versioneer.py"" and versionfile_source\n    # (PKG/_version.py, used by runtime code) are in MANIFEST.in, so\n    # they\'ll be copied into source distributions. Pip won\'t be able to\n    # install the package without this.\n    manifest_in = os.path.join(root, ""MANIFEST.in"")\n    simple_includes = set()\n    try:\n        with open(manifest_in, ""r"") as f:\n            for line in f:\n                if line.startswith(""include ""):\n                    for include in line.split()[1:]:\n                        simple_includes.add(include)\n    except EnvironmentError:\n        pass\n    # That doesn\'t cover everything MANIFEST.in can do\n    # (http://docs.python.org/2/distutils/sourcedist.html#commands), so\n    # it might give some false negatives. Appending redundant \'include\'\n    # lines is safe, though.\n    if ""versioneer.py"" not in simple_includes:\n        print("" appending \'versioneer.py\' to MANIFEST.in"")\n        with open(manifest_in, ""a"") as f:\n            f.write(""include versioneer.py\\n"")\n    else:\n        print("" \'versioneer.py\' already in MANIFEST.in"")\n    if cfg.versionfile_source not in simple_includes:\n        print("" appending versionfile_source (\'%s\') to MANIFEST.in"" %\n              cfg.versionfile_source)\n        with open(manifest_in, ""a"") as f:\n            f.write(""include %s\\n"" % cfg.versionfile_source)\n    else:\n        print("" versionfile_source already in MANIFEST.in"")\n\n    # Make VCS-specific changes. For git, this means creating/changing\n    # .gitattributes to mark _version.py for export-subst keyword\n    # substitution.\n    do_vcs_install(manifest_in, cfg.versionfile_source, ipy)\n    return 0\n\n\ndef scan_setup_py():\n    """"""Validate the contents of setup.py against Versioneer\'s expectations.""""""\n    found = set()\n    setters = False\n    errors = 0\n    with open(""setup.py"", ""r"") as f:\n        for line in f.readlines():\n            if ""import versioneer"" in line:\n                found.add(""import"")\n            if ""versioneer.get_cmdclass()"" in line:\n                found.add(""cmdclass"")\n            if ""versioneer.get_version()"" in line:\n                found.add(""get_version"")\n            if ""versioneer.VCS"" in line:\n                setters = True\n            if ""versioneer.versionfile_source"" in line:\n                setters = True\n    if len(found) != 3:\n        print("""")\n        print(""Your setup.py appears to be missing some important items"")\n        print(""(but I might be wrong). Please make sure it has something"")\n        print(""roughly like the following:"")\n        print("""")\n        print("" import versioneer"")\n        print("" setup( version=versioneer.get_version(),"")\n        print(""        cmdclass=versioneer.get_cmdclass(),  ...)"")\n        print("""")\n        errors += 1\n    if setters:\n        print(""You should remove lines like \'versioneer.VCS = \' and"")\n        print(""\'versioneer.versionfile_source = \' . This configuration"")\n        print(""now lives in setup.cfg, and should be removed from setup.py"")\n        print("""")\n        errors += 1\n    return errors\n\n\nif __name__ == ""__main__"":\n    cmd = sys.argv[1]\n    if cmd == ""setup"":\n        errors = do_setup()\n        errors += scan_setup_py()\n        if errors:\n            sys.exit(1)\n'"
benchmarks/acc2_benchmark.py,9,"b'import click\n\nfrom veros import VerosLegacy, veros_method, tools\n\nyt_start = -39.0\nyt_end = 43\nyu_start = -40.0\nyu_end = 42\n\n\nclass ACC2Benchmark(VerosLegacy):\n    """"""\n    A simple global model with a Southern Ocean and Atlantic part\n    """"""\n    def __init__(self, timesteps, *args, **kwargs):\n        self.timesteps = timesteps\n        super(ACC2Benchmark, self).__init__(*args, **kwargs)\n\n    @veros_method\n    def set_parameter(self, vs):\n        vs.identifier = ""acc2_benchmark""\n        vs.diskless_mode = True\n        vs.pyom_compatibility_mode = True\n\n        m = self.main_module\n        m.dt_mom = 480\n        m.dt_tracer = 480\n        m.runlen = m.dt_tracer * self.timesteps\n\n        m.coord_degree = 1\n        m.enable_cyclic_x = 1\n\n        m.congr_epsilon = 1e-12\n        m.congr_max_iterations = 10000\n\n        i = self.isoneutral_module\n        i.enable_neutral_diffusion = 1\n        i.K_iso_0 = 1000.0\n        i.K_iso_steep = 200.0\n        i.iso_dslope = 1e-3\n        i.iso_slopec = 4e-3\n        i.enable_skew_diffusion = 1\n\n        m.enable_hor_friction = 1\n        m.A_h = 1e4\n        m.enable_hor_friction_cos_scaling = 1\n        m.hor_friction_cosPower = 1\n\n        m.enable_bottom_friction = 1\n        m.r_bot = 1e-5\n\n        m.enable_implicit_vert_friction = 1\n        t = self.tke_module\n        t.enable_tke = 1\n        t.c_k = 0.1\n        t.c_eps = 0.7\n        t.alpha_tke = 30.0\n        t.mxl_min = 1e-8\n        t.tke_mxl_choice = 2\n        t.enable_tke_superbee_advection = 1\n\n        i.K_gm_0 = 1000.0\n        e = self.eke_module\n        e.enable_eke = 1\n        e.eke_k_max = 1e4\n        e.eke_c_k = 0.4\n        e.eke_c_eps = 0.5\n        e.eke_cross = 2.\n        e.eke_crhin = 1.0\n        e.eke_lmin = 100.0\n        e.enable_eke_superbee_advection = 1\n        e.enable_eke_isopycnal_diffusion = 1\n\n        i = self.idemix_module\n        i.enable_idemix = 1\n        i.enable_idemix_hor_diffusion = 1\n        i.enable_eke_diss_surfbot = 1\n        i.eke_diss_surfbot_frac = 0.2\n        i.enable_idemix_superbee_advection = 1\n\n        m.eq_of_state_type = 3\n\n    @veros_method\n    def set_grid(self, vs):\n        m = self.main_module\n        m.dxt[:] = 80.0 / m.nx\n        m.dyt[:] = 80.0 / m.ny\n        m.dzt[:] = 5000. / m.nz\n        m.x_origin = 0.0\n        m.y_origin = -40.0\n\n    @veros_method\n    def set_coriolis(self, vs):\n        m = self.main_module\n        m.coriolis_t[:, :] = 2 * m.omega * np.sin(m.yt[None, :] / 180. * np.pi)\n\n    @veros_method\n    def set_topography(self, vs):\n        m = self.main_module\n        (X, Y) = np.meshgrid(m.xt, m.yt)\n        X = X.transpose()\n        Y = Y.transpose()\n        m.kbot[...] = (X > 1.0) | (Y < -20)\n\n    @veros_method\n    def set_initial_conditions(self, vs):\n        m = self.main_module\n\n        # initial conditions\n        m.temp[:, :, :, 0:2] = ((1 - m.zt[None, None, :] / m.zw[0]) * 15 * m.maskT)[..., None]\n        m.salt[:, :, :, 0:2] = 35.0 * m.maskT[..., None]\n\n        # wind stress forcing\n        taux = np.zeros(m.ny + 1, dtype=vs.default_float_type)\n        yt = m.yt[2:m.ny + 3]\n        taux = (.1e-3 * np.sin(np.pi * (m.yu[2:m.ny + 3] - yu_start) / (-20.0 - yt_start))) * (yt < -20) \\\n            + (.1e-3 * (1 - np.cos(2 * np.pi *\n                                   (m.yu[2:m.ny + 3] - 10.0) / (yu_end - 10.0)))) * (yt > 10)\n        m.surface_taux[:, 2:m.ny + 3] = taux * m.maskU[:, 2:m.ny + 3, -1]\n\n        # surface heatflux forcing\n        vs.t_rest = np.zeros_like(m.u[:, :, 1, 0])\n        vs.t_star = np.zeros_like(m.u[:, :, 1, 0])\n        vs.t_star[:, 2:-2] = 15 * np.invert((m.yt[2:-2] < -20) | (m.yt[2:-2] > 20)) \\\n            + 15 * (m.yt[2:-2] - yt_start) / (-20 - yt_start) * (m.yt[2:-2] < -20) \\\n            + 15 * (1 - (m.yt[2:-2] - 20) / (yt_end - 20)) * (m.yt[2:-2] > 20.)\n        vs.t_rest = m.dzt[None, -1] / (30. * 86400.) * m.maskT[:, :, -1]\n\n        t = self.tke_module\n        if t.enable_tke:\n            t.forc_tke_surface[2:-2, 2:-2] = np.sqrt((0.5 * (m.surface_taux[2:-2, 2:-2] + m.surface_taux[1:-3, 2:-2]))**2\n                                                     + (0.5 * (m.surface_tauy[2:-2, 2:-2] + m.surface_tauy[2:-2, 1:-3]))**2)**(1.5)\n\n        i = self.idemix_module\n        if i.enable_idemix:\n            i.forc_iw_bottom[:] = 1.0e-6 * m.maskW[:, :, -1]\n            i.forc_iw_surface[:] = 0.1e-6 * m.maskW[:, :, -1]\n\n    @veros_method\n    def set_forcing(self, vs):\n        m = self.main_module\n        m.forc_temp_surface[:] = vs.t_rest * (vs.t_star - m.temp[:, :, -1, self.get_tau()])\n\n    @veros_method\n    def set_diagnostics(self, vs):\n        pass\n\n    @veros_method\n    def after_timestep(self, vs):\n        pass\n\n\n@click.option(\'-f\', \'--fortran\', type=click.Path(exists=True), default=None)\n@click.option(\'--timesteps\', type=int, default=100)\n@tools.cli\ndef main(*args, **kwargs):\n    sim = ACC2Benchmark(*args, **kwargs)\n    sim.setup()\n    sim.run()\n\n\nif __name__ == ""__main__"":\n    main()\n'"
benchmarks/isoneutral_benchmark.py,19,"b'import time\n\nimport click\n\nfrom veros import (\n    VerosLegacy, veros_method, core, tools, runtime_settings as rs,\n    runtime_state as rst\n)\nfrom veros.distributed import barrier\n\n\nclass IsoneutralBenchmark(VerosLegacy):\n    def __init__(self, timesteps, *args, **kwargs):\n        self.repetitions = timesteps\n        super(IsoneutralBenchmark, self).__init__(*args, **kwargs)\n\n    @veros_method\n    def set_parameter(self, vs):\n        np.random.seed(123456789)\n        m = self.main_module\n        m.dt_tracer = m.dt_mom = 86400.\n        m.enable_cyclic_x = True\n        m.eq_of_state_type = 3\n        m.congr_max_iterations = 1\n\n        im = self.isoneutral_module\n        im.enable_neutral_diffusion = True\n        im.iso_slopec = 0\n        im.K_iso_0 = np.random.rand()\n        im.K_iso_steep = np.random.rand()\n        im.iso_dslope = np.random.rand()\n\n    @veros_method\n    def set_grid(self, vs):\n        if not self.legacy_mode:\n            vs.is_pe = vs.js_pe = 1\n            vs.ie_pe, vs.je_pe = vs.nx // rs.num_proc[0], vs.ny // rs.num_proc[1]\n\n        m = self.main_module\n        self.set_attribute(vs, ""x_origin"", np.random.rand())\n        self.set_attribute(vs, ""y_origin"", np.random.rand())\n        self.set_attribute(vs, ""dxt"", 1 + 100 * np.random.rand(m.ie_pe-m.is_pe+5).astype(vs.default_float_type))\n        self.set_attribute(vs, ""dyt"", 1 + 100 * np.random.rand(m.je_pe-m.js_pe+5).astype(vs.default_float_type))\n        self.set_attribute(vs, ""dzt"", 1 + 100 * np.random.rand(m.nz).astype(vs.default_float_type))\n\n    @veros_method\n    def set_topography(self, vs):\n        m = self.main_module\n        kbot = np.zeros((m.ie_pe-m.is_pe+5,m.je_pe-m.js_pe+5))\n        kbot[2:-2, 2:-2] = np.random.randint(1, m.nz, size=(m.ie_pe-m.is_pe+1,m.je_pe-m.js_pe+1))\n        self.set_attribute(vs, ""kbot"", kbot)\n\n    @veros_method\n    def set_coriolis(self, vs):\n        m = self.main_module\n        self.set_attribute(vs, ""coriolis_t"", 2 * np.random.rand(1, m.je_pe-m.js_pe+5).astype(vs.default_float_type) - 1.)\n\n    @veros_method\n    def set_initial_conditions(self, vs):\n        m = self.main_module\n        self.set_attribute(vs, ""salt"", 35 + np.random.randn(m.ie_pe - m.is_pe + 5, m.je_pe - m.js_pe + 5, m.nz, 3).astype(vs.default_float_type))\n        self.set_attribute(vs, ""temp"", 20 + 5 * np.random.rand(m.ie_pe - m.is_pe + 5, m.je_pe - m.js_pe + 5, m.nz, 3).astype(vs.default_float_type))\n\n    @veros_method\n    def set_forcing(self, vs):\n        m = self.main_module\n        for a in (""flux_east"",""flux_north"",""flux_top"",""u_wgrid"",""v_wgrid"",""w_wgrid"",""K_iso"",""K_gm"",""du_mix"",""P_diss_iso"",""P_diss_skew""):\n            self.set_attribute(vs, a,np.random.randn(m.ie_pe-m.is_pe+5,m.je_pe-m.js_pe+5,m.nz).astype(vs.default_float_type))\n\n    def set_diagnostics(self, vs):\n        pass\n\n    @veros_method\n    def set_attribute(self, vs, attribute, value):\n        if self.legacy_mode:\n            legacy_modules = (""main_module"", ""isoneutral_module"", ""tke_module"",\n                              ""eke_module"", ""idemix_module"")\n            for module in legacy_modules:\n                module_handle = getattr(self, module)\n                if hasattr(module_handle, attribute):\n                    try:\n                        v = np.asfortranarray(value).copy2numpy()\n                    except AttributeError:\n                        v = np.asfortranarray(value)\n                    getattr(module_handle, attribute)[...] = v\n                    assert np.all(value == getattr(module_handle, attribute)), attribute\n                    return\n            raise AttributeError(""Legacy pyOM has no attribute {}"".format(attribute))\n        else:\n            if isinstance(value, np.ndarray):\n                getattr(vs, attribute)[...] = value\n            else:\n                setattr(vs, attribute, value)\n\n    def run(self):\n        vs = self.state\n        for t in range(self.repetitions):\n            start = time.time()\n            if self.legacy_mode:\n                self.fortran.isoneutral_diffusion_pre()\n            else:\n                core.isoneutral.isoneutral_diffusion_pre(vs)\n            barrier()\n            if rst.proc_rank == 0:\n                print(""Time step took {:.2e}s"".format(time.time() - start))\n\n    @veros_method\n    def after_timestep(self, vs):\n        pass\n\n\n@click.option(\'-f\', \'--fortran\', type=click.Path(exists=True), default=None)\n@click.option(\'--timesteps\', type=int, default=100)\n@tools.cli\ndef main(*args, **kwargs):\n    sim = IsoneutralBenchmark(*args, **kwargs)\n    sim.setup()\n    sim.run()\n\n\nif __name__ == ""__main__"":\n    main()\n'"
benchmarks/streamfunction_benchmark.py,11,"b'import time\n\nimport click\n\nfrom veros import VerosLegacy, veros_method, tools, runtime_settings as rs, runtime_state as rst\nfrom veros.distributed import barrier\n\n\nclass StreamfunctionBenchmark(VerosLegacy):\n    def __init__(self, timesteps, *args, **kwargs):\n        self.repetitions = timesteps\n        super(StreamfunctionBenchmark, self).__init__(*args, **kwargs)\n\n    @veros_method\n    def set_parameter(self, vs):\n        vs.identifier = ""streamfunction_benchmark""\n        vs.diskless_mode = True\n\n        m = self.main_module\n        m.dt_mom = 480\n        m.dt_tracer = 480\n\n        m.coord_degree = 1\n        m.enable_cyclic_x = 1\n\n        m.congr_epsilon = 1e-12\n        m.congr_max_iterations = 10000\n\n        m.enable_congrad_verbose = 1\n\n    @veros_method\n    def set_grid(self, vs):\n        m = self.main_module\n        m.dxt[:] = 80.0 / m.nx\n        m.dyt[2:-2] = tools.get_vinokur_grid_steps(\n            m.ny, 80., 0.66 * 80. / m.ny, two_sided_grid=True\n        )[m.js_pe-1:m.je_pe]\n        m.dzt[:] = 5000. / m.nz\n        m.x_origin = 0.0\n        m.y_origin = -40.0\n\n    @veros_method\n    def set_coriolis(self, vs):\n        m = self.main_module\n        m.coriolis_t[:, :] = 2 * m.omega * np.sin(m.yt[None, :] / 180. * np.pi)\n\n    @veros_method\n    def set_topography(self, vs):\n        m = self.main_module\n        (X, Y) = np.meshgrid(m.xt, m.yt, indexing=""ij"")\n        bottom_slope = np.linspace(m.nz - 1, 1, m.nx)[m.is_pe-1:m.ie_pe]\n        m.kbot[2:-2] = bottom_slope.reshape(-1, 1).astype(\'int\')\n        m.kbot[...] *= (X > 1.0) | (Y < -20)\n\n        island_mask = np.ones((m.nx + 4, m.ny + 4), dtype=\'int\')\n        island_width = m.nx // 5\n        island_start = 2 * m.nx // 5\n        island_end = island_start + island_width\n        island_mask[island_start:island_end, island_start:island_end] = 0\n        m.kbot[2:-2, 2:-2] *= island_mask[m.is_pe-1:m.ie_pe, m.js_pe-1:m.je_pe]\n\n    @veros_method\n    def set_initial_conditions(self, vs):\n        pass\n\n    @veros_method\n    def set_forcing(self, vs):\n        pass\n\n    @veros_method\n    def set_diagnostics(self, vs):\n        pass\n\n    def run(self):\n        from veros import runtime_state\n        vs = self.state\n        np = runtime_state.backend_module\n\n        np.random.seed(123456789)\n        for _ in range(self.repetitions):\n            if self.legacy_mode:\n                m = self.fortran.main_module\n                rhs = np.zeros((m.ie_pe-m.is_pe+5, m.je_pe-m.js_pe+5), order=""f"", dtype=vs.default_float_type)\n                rhs[2:-2, 2:-2] = np.random.randn(m.ie_pe-m.is_pe+1, m.je_pe-m.js_pe+1)\n                sol = np.zeros_like(rhs)\n                start = time.time()\n                self.fortran.congrad_streamfunction(\n                    is_=m.is_pe-m.onx, ie_=m.ie_pe+m.onx, js_=m.js_pe-m.onx, je_=m.je_pe+m.onx,\n                    forc=rhs, iterations=m.congr_itts, sol=sol, converged=False\n                )\n            else:\n                rhs = np.zeros((vs.nx // rs.num_proc[0] + 4, vs.ny // rs.num_proc[1] + 4), dtype=vs.default_float_type)\n                rhs[2:-2, 2:-2] = np.random.randn(*rhs[2:-2, 2:-2].shape)\n                sol = np.zeros_like(rhs)\n                start = time.time()\n                vs.linear_solver.solve(vs, rhs, sol)\n            barrier()\n            if rst.proc_rank == 0:\n                print(""Time step took {:.2e}s"".format(time.time() - start))\n\n    @veros_method\n    def after_timestep(self, vs):\n        pass\n\n\n@click.option(\'-f\', \'--fortran\', type=click.Path(exists=True), default=None)\n@click.option(\'--timesteps\', type=int, default=100)\n@tools.cli\ndef main(*args, **kwargs):\n    sim = StreamfunctionBenchmark(*args, **kwargs)\n    sim.setup()\n    sim.run()\n\n\nif __name__ == ""__main__"":\n    main()\n'"
doc/conf.py,0,"b'# -*- coding: utf-8 -*-\n#\n# Veros documentation build configuration file, created by\n# sphinx-quickstart on Tue Mar  7 23:56:46 2017.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\n\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath(\'..\'))\nsys.path.insert(0, os.path.abspath(\'_3rdparty\'))\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nimport sphinx_fontawesome\n\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.autosummary\',\n    \'sphinx.ext.coverage\',\n    \'sphinx.ext.viewcode\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.napoleon\',\n    \'sphinx.ext.intersphinx\',\n    \'sphinx_fontawesome\',\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = u\'Veros\'\ncopyright = u\'2017-2020, The Veros Team, NBI Copenhagen\'\nauthor = u\'The Veros Team, NBI Copenhagen\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\nfrom veros import __version__ as veros_version\n\n# The short X.Y version.\nversion = veros_version\n# The full version, including alpha/beta/rc tags.\nrelease = veros_version\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = [\'_build\', \'Thumbs.db\', \'.DS_Store\']\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nimport sphinx_rtd_theme\n\nhtml_theme = ""sphinx_rtd_theme""\n\nhtml_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = []\n\n\n# -- Options for HTMLHelp output ------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'veros_doc\'\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'veros.tex\', u\'Veros Documentation\',\n     u\'The Veros Team\', \'manual\'),\n]\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'Veros\', u\'Veros Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'Veros\', u\'Veros Documentation\',\n     author, \'Veros\', \'The versatile ocean simulator in pure Python\',\n     \'Miscellaneous\'),\n]\n\n# -- Options for autodoc --------------------------------------------------\nautodoc_member_order = ""bysource""\nautodoc_default_options = {""show-inheritance"": None}\nautodoc_mock_imports = [""loguru"", ""numpy"", ""h5netcdf"", ""scipy"", ""ruamel""]\n\n# -- Options for intersphinx ----------------------------------------------\nintersphinx_mapping = {\'python\': (\'https://docs.python.org/3\', None)}\n\n# -- Custom exec directive ------------------------------------------------\n\nfrom os.path import basename\n\ntry:\n    from StringIO import StringIO\nexcept ImportError:\n    from io import StringIO\n\nfrom docutils import nodes, statemachine\nfrom docutils.parsers.rst import Directive, directives\n\n\nclass ExecDirective(Directive):\n    """"""Execute the specified python code and insert the output into the document""""""\n    has_content = True\n\n    def run(self):\n        old_stdout, sys.stdout = sys.stdout, StringIO()\n\n        tab_width = self.options.get(\'tab-width\', self.state.document.settings.tab_width)\n        source = self.state_machine.input_lines.source(self.lineno - self.state_machine.input_offset - 1)\n\n        try:\n            exec(\'\\n\'.join(self.content))\n            text = sys.stdout.getvalue()\n            lines = statemachine.string2lines(text, tab_width, convert_whitespace=True)\n            self.state_machine.insert_input(lines, source)\n            return []\n        except Exception:\n            warn_text = ""Unable to execute python code at %s:%d"" % (basename(source), self.lineno)\n            warning = self.state_machine.reporter.warning(warn_text)\n            return [warning, nodes.error(None, nodes.paragraph(text=warn_text), nodes.paragraph(text=str(sys.exc_info()[1])))]\n        finally:\n            sys.stdout = old_stdout\n\n\nclass ClickDirective(Directive):\n    """"""Execute the specified click command and insert the output into the document""""""\n    required_arguments = 1\n    optional_arguments = 0\n    option_spec = {\n        \'args\': directives.unchanged\n    }\n    has_content = False\n\n    def run(self):\n        import importlib\n        import shlex\n        from click.testing import CliRunner\n\n        arg = self.arguments[0]\n        options = shlex.split(self.options.get(\'args\', \'\'))\n\n        try:\n            modname, funcname = arg.split(\':\')\n        except ValueError:\n            raise self.error(\'run-click argument must be ""module:function""\')\n\n        try:\n            mod = importlib.import_module(modname)\n            func = getattr(mod, funcname)\n\n            runner = CliRunner()\n            with runner.isolated_filesystem():\n                result = runner.invoke(func, options)\n\n            text = result.output\n\n            if result.exit_code != 0:\n                raise RuntimeError(\'Command exited with non-zero exit code; output: ""%s""\' % text)\n\n            node = nodes.literal_block(text=text)\n            node[\'language\'] = \'text\'\n            return [node]\n\n        except Exception:\n            warn_text = ""Error while running command %s %s"" % (arg, \' \'.join(map(shlex.quote, options)))\n            warning = self.state_machine.reporter.warning(warn_text)\n            return [warning, nodes.error(None, nodes.paragraph(text=warn_text), nodes.paragraph(text=str(sys.exc_info()[1])))]\n\n\ndef setup(app):\n    app.add_directive(\'exec\', ExecDirective)\n    app.add_directive(\'run-click\', ClickDirective)\n'"
test/cli_test.py,0,"b""import tempfile\nimport os\nimport filecmp\nimport fnmatch\nimport pkg_resources\n\nfrom click.testing import CliRunner\nimport pytest\n\nimport veros.cli\n\n\n@pytest.fixture(scope='module')\ndef runner():\n    return CliRunner()\n\n\ndef test_veros_copy_setup(runner):\n    with tempfile.TemporaryDirectory() as tempdir:\n        for setup in ('acc', 'acc_sector', 'global_4deg', 'global_1deg',\n                      'global_flexible', 'north_atlantic', 'wave_propagation'):\n            result = runner.invoke(veros.cli.veros_copy_setup.cli, [setup, '--to', os.path.join(tempdir, setup)])\n            assert result.exit_code == 0, setup\n            assert not result.output\n\n            outpath = os.path.join(tempdir, setup)\n            srcpath = pkg_resources.resource_filename('veros', 'setup/%s' % setup)\n            ignore = [f for f in os.listdir(srcpath) if any(\n                fnmatch.fnmatch(f, pattern) for pattern in veros.cli.veros_copy_setup.IGNORE_PATTERNS\n            )]\n            ignore.append('version.txt')\n\n            comparer = filecmp.dircmp(outpath, srcpath, ignore=ignore)\n            assert not comparer.left_only and not comparer.right_only and not comparer.diff_files\n"""
test/distributed_test.py,11,"b""\nimport os\nimport sys\nimport subprocess\n\nfrom tempfile import NamedTemporaryFile\nfrom textwrap import dedent\n\nimport pytest\n\nON_GPU = os.environ.get('BH_STACK', '').lower() in ('opencl', 'cuda')\n\n\ndef run_dist_kernel(code):\n    with NamedTemporaryFile(prefix='vs_test_', suffix='.py', mode='w') as f:\n        f.write(code)\n        f.flush()\n\n        return subprocess.check_call(\n            [sys.executable, '-m', 'mpi4py', f.name], stderr=subprocess.STDOUT\n        )\n\n\n@pytest.mark.skipif(ON_GPU, reason='Cannot run MPI and OpenCL')\ndef test_gather(backend):\n    test_kernel = dedent('''\n    import os\n    os.environ['OMP_NUM_THREADS'] = '1'\n\n    import {backend} as np\n    from mpi4py import MPI\n\n    from veros import runtime_settings as rs, runtime_state as rst, VerosState\n    from veros.distributed import gather\n\n    rs.backend = '{backend}'\n\n    if rst.proc_num == 1:\n        import sys\n        comm = MPI.COMM_SELF.Spawn(\n            sys.executable,\n            args=['-m', 'mpi4py', sys.argv[-1]],\n            maxprocs=4\n        )\n\n        res = np.empty((8, 8))\n        comm.Recv(res, 0)\n\n        assert np.array_equal(res, np.array(\n                [[0., 0., 0., 0., 2., 2., 2., 2.],\n                 [0., 0., 0., 0., 2., 2., 2., 2.],\n                 [0., 0., 0., 0., 2., 2., 2., 2.],\n                 [0., 0., 0., 0., 2., 2., 2., 2.],\n                 [1., 1., 1., 1., 3., 3., 3., 3.],\n                 [1., 1., 1., 1., 3., 3., 3., 3.],\n                 [1., 1., 1., 1., 3., 3., 3., 3.],\n                 [1., 1., 1., 1., 3., 3., 3., 3.]]\n            ))\n\n    else:\n        rs.num_proc = (2, 2)\n\n        assert rst.proc_num == 4\n\n        vs = VerosState()\n        vs.nx = 4\n        vs.ny = 4\n\n        a = rst.proc_rank * np.ones((6, 6))\n        b = gather(vs, a, ('xt', 'yt'))\n\n        if rst.proc_rank == 0:\n            try:\n                b = b.copy2numpy()\n            except AttributeError:\n                pass\n\n            rs.mpi_comm.Get_parent().Send(b, 0)\n\n    '''.format(\n        backend=backend\n    ))\n\n    run_dist_kernel(test_kernel)\n\n\n@pytest.mark.skipif(ON_GPU, reason='Cannot run MPI and OpenCL')\ndef test_scatter(backend):\n    test_kernel = dedent('''\n    import os\n    os.environ['OMP_NUM_THREADS'] = '1'\n\n    import numpy as np\n    from mpi4py import MPI\n\n    from veros import runtime_settings as rs, runtime_state as rst, VerosState\n    from veros.distributed import scatter\n\n    rs.backend = '{backend}'\n\n    global_arr = np.array(\n        [[0., 0., 0., 0., 2., 2., 2., 2.],\n         [0., 0., 0., 0., 2., 2., 2., 2.],\n         [0., 0., 0., 0., 2., 2., 2., 2.],\n         [0., 0., 0., 0., 2., 2., 2., 2.],\n         [1., 1., 1., 1., 3., 3., 3., 3.],\n         [1., 1., 1., 1., 3., 3., 3., 3.],\n         [1., 1., 1., 1., 3., 3., 3., 3.],\n         [1., 1., 1., 1., 3., 3., 3., 3.]]\n    )\n\n    if rst.proc_num == 1:\n        import sys\n        comm = MPI.COMM_SELF.Spawn(\n            sys.executable,\n            args=['-m', 'mpi4py', sys.argv[-1]],\n            maxprocs=4\n        )\n\n        res = np.empty((6, 6))\n\n        proc_slices = (\n            (slice(None, -2), slice(None, -2)),\n            (slice(2, None), slice(None, -2)),\n            (slice(None, -2), slice(2, None)),\n            (slice(2, None), slice(2, None)),\n        )\n\n        for proc, idx in enumerate(proc_slices):\n            comm.Recv(res, proc)\n            assert np.array_equal(res, global_arr[idx])\n\n    else:\n        rs.num_proc = (2, 2)\n\n        assert rst.proc_num == 4\n\n        vs = VerosState()\n        vs.nx = 4\n        vs.ny = 4\n\n        if rst.proc_rank == 0:\n            a = global_arr.copy()\n        else:\n            a = np.empty((6, 6))\n\n        b = scatter(vs, a, ('xt', 'yt'))\n\n        try:\n            b = b.copy2numpy()\n        except AttributeError:\n            pass\n\n        rs.mpi_comm.Get_parent().Send(b, 0)\n\n    '''.format(\n        backend=backend\n    ))\n\n    run_dist_kernel(test_kernel)\n\n\n@pytest.mark.skipif(ON_GPU, reason='Cannot run MPI and OpenCL')\ndef test_acc(backend):\n    test_kernel = dedent('''\n    import os\n    os.environ['OMP_NUM_THREADS'] = '1'\n\n    import numpy as np\n    from mpi4py import MPI\n\n    from veros import runtime_settings as rs, runtime_state as rst\n    from veros.distributed import gather\n    from veros.setup.acc import ACCSetup\n\n    rs.backend = '{backend}'\n    rs.linear_solver = 'scipy'\n\n    sim = ACCSetup(override=dict(\n        diskless_mode=True,\n        runlen=86400 * 10,\n    ))\n\n    if rst.proc_num == 1:\n        import sys\n        comm = MPI.COMM_SELF.Spawn(\n            sys.executable,\n            args=['-m', 'mpi4py', sys.argv[-1]],\n            maxprocs=4\n        )\n\n        try:\n            sim.setup()\n            sim.run()\n        except Exception as exc:\n            print(str(exc))\n            comm.Abort(1)\n\n        other_psi = np.empty_like(sim.state.psi)\n        comm.Recv(other_psi, 0)\n\n        scale = max(\n            np.abs(sim.state.psi).max(),\n            np.abs(other_psi).max()\n        )\n\n        np.testing.assert_allclose(sim.state.psi / scale, other_psi / scale, rtol=0, atol=1e-5)\n\n    else:\n        rs.num_proc = (2, 2)\n\n        assert rst.proc_num == 4\n\n        sim.setup()\n        sim.run()\n\n        psi_global = gather(sim.state, sim.state.psi, ('xt', 'yt', None))\n\n        if rst.proc_rank == 0:\n            try:\n                psi_global = psi_global.copy2numpy()\n            except AttributeError:\n                pass\n\n            rs.mpi_comm.Get_parent().Send(psi_global, 0)\n\n    '''.format(\n        backend=backend\n    ))\n\n    run_dist_kernel(test_kernel)\n\n\n@pytest.mark.skipif(ON_GPU, reason='Cannot run MPI and OpenCL')\ndef test_acc_nompirun(backend):\n    from veros.setup.acc import acc\n\n    subprocess.check_call([\n        sys.executable,\n        '-m', 'mpi4py',\n        acc.__file__,\n        '-n', '2', '2',\n        '-b', backend,\n        '-s' 'diskless_mode', '1',\n        '-s', 'runlen', '864000'\n    ], stderr=subprocess.STDOUT)\n"""
test/linear_solver_test.py,14,"b""import pytest\n\nimport numpy as np\n\nfrom veros import VerosState\nfrom veros.core.streamfunction.solvers import (\n    scipy as scipysolver,\n    petsc as petscsolver\n)\n\n\nclass SolverTestState(VerosState):\n    def __init__(self, cyclic):\n        self.nx = 400\n        self.ny = 200\n        self.nz = 1\n        self.nisle = 0\n\n        self.default_float_type = 'float64'\n\n        self.congr_epsilon = 1e-12\n        self.congr_max_iterations = 10000\n\n        self.enable_cyclic_x = cyclic\n\n        self.dxt = 1e-12 * np.ones(self.nx + 4)\n        self.dxu = 1e-12 * np.ones(self.nx + 4)\n\n        self.dyt = 1e-12 * np.ones(self.ny + 4)\n        self.dyu = 1e-12 * np.ones(self.ny + 4)\n\n        self.hur = np.linspace(500, 2000, self.nx + 4)[:, None] * np.ones((self.nx + 4, self.ny + 4))\n        self.hvr = np.linspace(500, 2000, self.ny + 4)[None, :] * np.ones((self.nx + 4, self.ny + 4))\n\n        self.cosu = np.ones(self.ny + 4)\n        self.cost = np.ones(self.ny + 4)\n\n        self.boundary_mask = np.zeros((self.nx + 4, self.ny + 4, self.nz), dtype='bool')\n        self.boundary_mask[:, :2] = 1\n        self.boundary_mask[50:100, 50:100] = 1\n\n\ndef get_residual(vs, rhs, sol, boundary_val=None):\n    scipy_solver = scipysolver.SciPySolver(vs)\n    if boundary_val is None:\n        boundary_val = sol\n    boundary_mask = np.logical_and.reduce(~vs.boundary_mask, axis=2)\n    rhs = np.where(boundary_mask, rhs, boundary_val)\n    residual = scipy_solver._matrix @ sol.flatten() - rhs.flatten() * scipy_solver._rhs_scale\n    return residual\n\n\n@pytest.mark.parametrize('cyclic', [True, False])\n@pytest.mark.parametrize('solver_class', [scipysolver.SciPySolver, petscsolver.PETScSolver])\ndef test_solver(solver_class, cyclic, backend):\n    from veros import runtime_settings as rs\n    rs.backend = backend\n\n    vs = SolverTestState(cyclic)\n\n    rhs = np.ones((vs.nx + 4, vs.ny + 4))\n    sol = np.random.rand(vs.nx + 4, vs.ny + 4)\n\n    solver_class(vs).solve(vs, rhs, sol, 10)\n\n    residual = get_residual(vs, rhs, sol, 10)\n\n    # set tolerance may apply in preconditioned space,\n    # so let's allow for some wiggle room\n    assert np.max(np.abs(residual)) < vs.congr_epsilon * 1e2\n"""
test/progress_test.py,0,"b""import sys\nimport re\nimport time\n\n\ndef test_progress_format(capsys):\n    from veros.logs import setup_logging\n    setup_logging(stream_sink=sys.stdout)\n\n    from veros.state import VerosState\n    from veros.progress import get_progress_bar\n\n    dummy_state = VerosState()\n    dummy_state.runlen = 8000\n    dummy_state.time = 2000\n    dummy_state.itt = 2\n\n    with get_progress_bar(dummy_state, use_tqdm=False) as pbar:\n        for _ in range(8):\n            time.sleep(0.1)\n            pbar.advance_time(1000)\n\n    captured_log = capsys.readouterr()\n    assert 'Current iteration:' in captured_log.out\n\n    with get_progress_bar(dummy_state, use_tqdm=True) as pbar:\n        for _ in range(8):\n            time.sleep(0.1)\n            pbar.advance_time(1000)\n\n    captured_tqdm = capsys.readouterr()\n    assert 'Current iteration:' in captured_tqdm.out\n\n    def sanitize(prog):\n        # remove rates and ETA (inconsistent)\n        prog = re.sub(r'\\d+\\.\\d{2}[smh]/\\(model year\\)', '?s/(model year)', prog)\n        prog = re.sub(r'\\d+\\.\\d[smh] left', '? left', prog)\n        prog = prog.replace('\\r', '\\n')\n        prog = prog.strip()\n        return prog\n\n    def deduplicate(prog):\n        # remove repeated identical lines\n        out = []\n        for line in prog.split('\\n'):\n            if not out or out[-1] != line:\n                out.append(line)\n        return '\\n'.join(out)\n\n    assert sanitize(captured_log.out) == deduplicate(sanitize(captured_tqdm.out))\n"""
test/restart_test.py,10,"b'import os\nimport tempfile\nimport numpy as np\n\nfrom veros import VerosSetup, veros_method, settings, runtime_settings as rs\n\nyt_start = -39.0\nyt_end = 43\nyu_start = -40.0\nyu_end = 42\n\n\nclass ACC2(VerosSetup):\n    """"""\n    A simple global model with a Southern Ocean and Atlantic part\n    """"""\n    @veros_method\n    def set_parameter(self, vs):\n        vs.identifier = \'acc2_restart_test\'\n\n        vs.nx, vs.ny, vs.nz = 30, 42, 15\n        vs.dt_mom = 4800\n        vs.dt_tracer = 86400 / 4.\n        vs.runlen = 86400 * 365\n\n        vs.coord_degree = True\n        vs.enable_cyclic_x = True\n\n        vs.congr_epsilon = 1e-12\n        vs.congr_max_iterations = 5000\n\n        vs.enable_neutral_diffusion = True\n        vs.K_iso_0 = 1000.0\n        vs.K_iso_steep = 500.0\n        vs.iso_dslope = 0.005\n        vs.iso_slopec = 0.01\n        vs.enable_skew_diffusion = True\n\n        vs.enable_hor_friction = True\n        vs.A_h = (2 * vs.degtom) ** 3 * 2e-11\n        vs.enable_hor_friction_cos_scaling = 1\n        vs.hor_friction_cosPower = 1\n\n        vs.enable_bottom_friction = True\n        vs.r_bot = 1e-5\n\n        vs.enable_implicit_vert_friction = True\n        vs.enable_tke = True\n        vs.c_k = 0.1\n        vs.c_eps = 0.7\n        vs.alpha_tke = 30.0\n        vs.mxl_min = 1e-8\n        vs.tke_mxl_choice = 2\n\n        vs.K_gm_0 = 1000.0\n\n        vs.enable_eke = True\n        vs.eke_k_max = 1e4\n        vs.eke_c_k = 0.4\n        vs.eke_c_eps = 0.5\n        vs.eke_cross = 2.\n        vs.eke_crhin = 1.0\n        vs.eke_lmin = 100.0\n        vs.enable_eke_superbee_advection = True\n        vs.enable_eke_isopycnal_diffusion = True\n\n        vs.enable_idemix = True\n        vs.enable_idemix_hor_diffusion = True\n        vs.enable_eke_diss_surfbot = True\n        vs.eke_diss_surfbot_frac = 0.2\n        vs.enable_idemix_superbee_advection = True\n\n        vs.eq_of_state_type = 3\n\n    @veros_method\n    def set_grid(self, vs):\n        ddz = [50., 70., 100., 140., 190., 240., 290., 340.,\n               390., 440., 490., 540., 590., 640., 690.]\n        vs.dxt[:] = 2.0\n        vs.dyt[:] = 2.0\n        vs.x_origin = 0.0\n        vs.y_origin = -40.0\n        vs.dzt[:] = ddz[::-1]\n        vs.dzt[:] *= 1 / 2.5\n\n    @veros_method\n    def set_coriolis(self, vs):\n        vs.coriolis_t[:, :] = 2 * vs.omega * np.sin(vs.yt[None, :] / 180. * vs.pi)\n\n    @veros_method\n    def set_topography(self, vs):\n        (X, Y) = np.meshgrid(vs.xt, vs.yt)\n        X = X.transpose()\n        Y = Y.transpose()\n        vs.kbot[...] = (X > 1.0) | (Y < -20)\n\n    @veros_method\n    def set_initial_conditions(self, vs):\n        # initial conditions\n        vs.temp[:, :, :, 0:2] = ((1 - vs.zt[None, None, :] / vs.zw[0]) * 15 * vs.maskT)[..., None]\n        vs.salt[:, :, :, 0:2] = 35.0 * vs.maskT[..., None]\n\n        # wind stress forcing\n        taux = np.zeros(vs.ny + 1, dtype=vs.default_float_type)\n        yt = vs.yt[2:vs.ny + 3]\n        taux[...] = (.1 * np.sin(np.pi * (vs.yu[2:vs.ny + 3] - yu_start) / (-20.0 - yt_start))) * (yt < -20) \\\n                    + (.1 * (1 - np.cos(2 * np.pi * (vs.yu[2:vs.ny + 3] - 10.0) / (yu_end - 10.0)))) * (yt > 10)\n        vs.surface_taux[:, 2:vs.ny + 3] = taux * vs.maskU[:, 2:vs.ny + 3, -1]\n\n        # surface heatflux forcing\n        vs.t_star = 15 * np.invert((vs.yt < -20) | (vs.yt > 20)) \\\n            + 15 * (vs.yt - yt_start) / (-20 - yt_start) * (vs.yt < -20) \\\n            + 15 * (1 - (vs.yt - 20) / (yt_end - 20)) * (vs.yt > 20.)\n        vs.t_rest = vs.dzt[np.newaxis, -1] / (30. * 86400.) * vs.maskT[:, :, -1]\n\n        if vs.enable_tke:\n            vs.forc_tke_surface[2:-2, 2:-2] = (\n                1 / vs.rho_0 * np.sqrt((0.5 * (vs.surface_taux[2:-2, 2:-2] + vs.surface_taux[1:-3, 2:-2]))**2\n                                       + (0.5 * (vs.surface_tauy[2:-2, 2:-2] + vs.surface_tauy[2:-2, 1:-3]))**2)\n            )**(1.5)\n\n        if vs.enable_idemix:\n            vs.forc_iw_bottom[:] = 1.0e-6 * vs.maskW[:, :, -1]\n            vs.forc_iw_surface[:] = 0.1e-6 * vs.maskW[:, :, -1]\n\n    @veros_method\n    def set_forcing(self, vs):\n        vs.forc_temp_surface[:] = vs.t_rest * (vs.t_star - vs.temp[:, :, -1, vs.tau])\n\n    @veros_method\n    def set_diagnostics(self, vs):\n        pass\n\n    def after_timestep(self, vs):\n        pass\n\n\nclass RestartTest:\n    timesteps = 10\n\n    def __init__(self, backend):\n        rs.backend = backend\n        rs.linear_solver = \'scipy\'\n\n        self.restart_file = tempfile.NamedTemporaryFile(suffix=\'.h5\', delete=False).name\n\n        self.acc_no_restart = ACC2()\n        self.acc_no_restart.state.restart_output_filename = self.restart_file\n\n        self.acc_restart = ACC2()\n        self.acc_restart.state.restart_input_filename = self.restart_file\n        self.acc_restart.state.restart_output_filename = None\n\n    def run(self):\n        self.acc_no_restart.setup()\n        self.acc_no_restart.state.runlen = self.acc_no_restart.state.dt_tracer * (self.timesteps - 5)\n        self.acc_no_restart.run()\n\n        self.acc_restart.setup()\n        self.acc_restart.state.runlen = self.acc_no_restart.state.dt_tracer * self.timesteps - self.acc_no_restart.state.time\n        self.acc_restart.run()\n\n        self.acc_no_restart.state.runlen = self.acc_no_restart.state.dt_tracer * self.timesteps - self.acc_no_restart.state.time\n        self.acc_no_restart.run()\n\n        os.remove(self.restart_file)\n        return self.test_passed()\n\n    def test_passed(self):\n        passed = True\n\n        for attr in (\'itt\', \'time\', \'tau\', \'taum1\', \'taup1\'):\n            a1, a2 = (getattr(obj, attr) for obj in (self.acc_no_restart.state, self.acc_restart.state))\n            assert a1 == a2\n\n        for setting in settings.SETTINGS:\n            s_1, s_2 = (getattr(obj, setting) for obj in (self.acc_no_restart.state, self.acc_restart.state))\n            if s_1 != s_2:\n                print(setting, s_1, s_2)\n\n        for var in sorted(self.acc_no_restart.state.variables.keys()) + [\'t_star\', \'t_rest\']:\n            # salt is not used by this setup, contains only noise\n            if \'salt\' in var:\n                continue\n            arr_1, arr_2 = (getattr(obj, var) for obj in (self.acc_no_restart.state, self.acc_restart.state))\n\n            try:\n                arr_1 = arr_1.copy2numpy()\n            except AttributeError:\n                pass\n            try:\n                arr_2 = arr_2.copy2numpy()\n            except AttributeError:\n                pass\n\n            print(\'Testing {}...\'.format(var), end=\' \')\n            np.testing.assert_allclose(*self._normalize(arr_1, arr_2), atol=1e-10, rtol=0)\n            print(\'ok\')\n\n        return passed\n\n    def _normalize(self, *arrays):\n        if any(a.size == 0 for a in arrays):\n            return arrays\n        norm = np.abs(arrays[0]).max()\n        if norm == 0.:\n            return arrays\n        return (a / norm for a in arrays)\n\n\ndef test_restart(backend):\n    assert RestartTest(backend=backend).run()\n'"
test/setup_test.py,0,"b'def test_setup_acc(backend):\n    from veros import runtime_settings as rs\n    from veros.setup.acc import ACCSetup\n    rs.backend = backend\n\n    sim = ACCSetup()\n    sim.state.diskless_mode = True\n    sim.setup()\n    sim.state.runlen = sim.state.dt_tracer * 20\n    sim.run()\n\n\ndef test_setup_acc_sector(backend):\n    from veros import runtime_settings as rs\n    from veros.setup.acc_sector import ACCSectorSetup\n    rs.backend = backend\n\n    sim = ACCSectorSetup()\n    sim.state.diskless_mode = True\n    sim.setup()\n    sim.state.runlen = sim.state.dt_tracer * 20\n    sim.run()\n\n\ndef test_setup_4deg(backend):\n    from veros import runtime_settings as rs\n    from veros.setup.global_4deg import GlobalFourDegreeSetup\n    rs.backend = backend\n\n    sim = GlobalFourDegreeSetup()\n    sim.state.diskless_mode = True\n    sim.setup()\n    sim.state.runlen = sim.state.dt_tracer * 20\n    sim.run()\n\n\ndef test_setup_flexible(backend):\n    from veros import runtime_settings as rs\n    from veros.setup.global_flexible import GlobalFlexibleResolutionSetup\n    rs.backend = backend\n\n    sim = GlobalFlexibleResolutionSetup(override=dict(\n        nx=100, ny=50, dt_tracer=3600, dt_mom=3600,\n    ))\n    sim.state.diskless_mode = True\n    sim.setup()\n    sim.state.runlen = sim.state.dt_tracer * 20\n    sim.run()\n\n\ndef test_setup_1deg(backend):\n    from veros import runtime_settings as rs\n    from veros.setup.global_1deg import GlobalOneDegreeSetup\n    rs.backend = backend\n\n    sim = GlobalOneDegreeSetup()\n    sim.state.diskless_mode = True\n    # too big to test\n    # sim.setup()\n    # sim.state.runlen = sim.state.dt_tracer\n    # sim.run()\n\n\ndef test_setup_north_atlantic(backend):\n    from veros import runtime_settings as rs\n    from veros.setup.north_atlantic import NorthAtlanticSetup\n    rs.backend = backend\n\n    sim = NorthAtlanticSetup(override=dict(nx=100, ny=100, nz=50))\n    sim.state.diskless_mode = True\n    sim.setup()\n    sim.state.runlen = sim.state.dt_tracer\n    sim.run()\n\n\ndef test_setup_wave_propagation(backend):\n    from veros import runtime_settings as rs\n    from veros.setup.wave_propagation import WavePropagationSetup\n    rs.backend = backend\n\n    sim = WavePropagationSetup(override=dict(nx=100, ny=100, nz=50))\n    sim.state.diskless_mode = True\n    sim.setup()\n    sim.state.runlen = sim.state.dt_tracer\n    sim.run()\n'"
veros/__init__.py,0,"b'""""""Veros, the versatile ocean simulator""""""\n\nimport sys\nimport types\n\n# black magic: ensure lazy imports for public API by overriding module.__class__\n\nclass _PublicAPI(types.ModuleType):\n    @property\n    def __version__(self):\n        from veros._version import get_versions\n        return get_versions()[\'version\']\n\n    @property\n    def runtime_settings(self):\n        if not hasattr(self, \'_runtime_settings\'):\n            from veros.runtime import RuntimeSettings\n            self._runtime_settings = RuntimeSettings()\n        return self._runtime_settings\n\n    @property\n    def runtime_state(self):\n        if not hasattr(self, \'_runtime_state\'):\n            from veros.runtime import RuntimeState\n            self._runtime_state = RuntimeState()\n        return self._runtime_state\n\n    @property\n    def veros_method(self):\n        from veros.decorators import veros_method\n        return veros_method\n\n    @property\n    def VerosSetup(self):\n        from veros.veros import VerosSetup\n        return VerosSetup\n\n    @property\n    def VerosState(self):\n        from veros.state import VerosState\n        return VerosState\n\n    @property\n    def VerosLegacy(self):\n        from veros.veros_legacy import VerosLegacy\n        return VerosLegacy\n\nsys.modules[__name__].__class__ = _PublicAPI\n\ndel sys\ndel types\ndel _PublicAPI\n'"
veros/_version.py,0,"b'\n# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain. Generated by\n# versioneer-0.18 (https://github.com/warner/python-versioneer)\n\n""""""Git implementation of _version.py.""""""\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\n\n\ndef get_keywords():\n    """"""Get the keywords needed to look up the version information.""""""\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = ""$Format:%d$""\n    git_full = ""$Format:%H$""\n    git_date = ""$Format:%ci$""\n    keywords = {""refnames"": git_refnames, ""full"": git_full, ""date"": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    """"""Container for Versioneer configuration parameters.""""""\n\n\ndef get_config():\n    """"""Create, populate and return the VersioneerConfig() object.""""""\n    # these strings are filled in when \'setup.py versioneer\' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = ""git""\n    cfg.style = ""pep440""\n    cfg.tag_prefix = ""v""\n    cfg.parentdir_prefix = ""None""\n    cfg.versionfile_source = ""veros/_version.py""\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    """"""Exception raised if a method is not valid for the current scenario.""""""\n\n\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    """"""Decorator to mark a method as the handler for a particular VCS.""""""\n    def decorate(f):\n        """"""Store f in HANDLERS[vcs][method].""""""\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n                env=None):\n    """"""Call the given command(s).""""""\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(""unable to run %s"" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(""unable to find command, tried %s"" % (commands,))\n        return None, None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(""unable to run %s (error)"" % dispcmd)\n            print(""stdout was %s"" % stdout)\n        return None, p.returncode\n    return stdout, p.returncode\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    """"""Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    """"""\n    rootdirs = []\n\n    for i in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {""version"": dirname[len(parentdir_prefix):],\n                    ""full-revisionid"": None,\n                    ""dirty"": False, ""error"": None, ""date"": None}\n        else:\n            rootdirs.append(root)\n            root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(""Tried directories %s but none started with prefix %s"" %\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(""rootdir doesn\'t start with parentdir_prefix"")\n\n\n@register_vcs_handler(""git"", ""get_keywords"")\ndef git_get_keywords(versionfile_abs):\n    """"""Extract version information from the given file.""""""\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don\'t want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, ""r"")\n        for line in f.readlines():\n            if line.strip().startswith(""git_refnames =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""refnames""] = mo.group(1)\n            if line.strip().startswith(""git_full =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""full""] = mo.group(1)\n            if line.strip().startswith(""git_date =""):\n                mo = re.search(r\'=\\s*""(.*)""\', line)\n                if mo:\n                    keywords[""date""] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(""git"", ""keywords"")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    """"""Get version information from git keywords.""""""\n    if not keywords:\n        raise NotThisMethod(""no keywords at all, weird"")\n    date = keywords.get(""date"")\n    if date is not None:\n        # git-2.2.0 added ""%cI"", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer ""%ci"" (which expands to an ""ISO-8601\n        # -like"" string, which we must then edit to make compliant), because\n        # it\'s been around since git-1.5.3, and it\'s too difficult to\n        # discover which version we\'re using, or to work around using an\n        # older one.\n        date = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n    refnames = keywords[""refnames""].strip()\n    if refnames.startswith(""$Format""):\n        if verbose:\n            print(""keywords are unexpanded, not using"")\n        raise NotThisMethod(""unexpanded keywords, not a git-archive tarball"")\n    refs = set([r.strip() for r in refnames.strip(""()"").split("","")])\n    # starting in git-1.8.3, tags are listed as ""tag: foo-1.0"" instead of\n    # just ""foo-1.0"". If we see a ""tag: "" prefix, prefer those.\n    TAG = ""tag: ""\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we\'re using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like ""release"" and\n        # ""stabilization"", as well as ""HEAD"" and ""master"".\n        tags = set([r for r in refs if re.search(r\'\\d\', r)])\n        if verbose:\n            print(""discarding \'%s\', no digits"" % "","".join(refs - tags))\n    if verbose:\n        print(""likely tags: %s"" % "","".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. ""2.0"" over ""2.0rc1""\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(""picking %s"" % r)\n            return {""version"": r,\n                    ""full-revisionid"": keywords[""full""].strip(),\n                    ""dirty"": False, ""error"": None,\n                    ""date"": date}\n    # no suitable tags, so version is ""0+unknown"", but full hex is still there\n    if verbose:\n        print(""no suitable tags, using unknown + full revision id"")\n    return {""version"": ""0+unknown"",\n            ""full-revisionid"": keywords[""full""].strip(),\n            ""dirty"": False, ""error"": ""no suitable tags"", ""date"": None}\n\n\n@register_vcs_handler(""git"", ""pieces_from_vcs"")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    """"""Get version from \'git describe\' in the root of the source tree.\n\n    This only gets called if the git-archive \'subst\' keywords were *not*\n    expanded, and _version.py hasn\'t already been rewritten with a short\n    version string, meaning we\'re inside a checked out source tree.\n    """"""\n    GITS = [""git""]\n    if sys.platform == ""win32"":\n        GITS = [""git.cmd"", ""git.exe""]\n\n    out, rc = run_command(GITS, [""rev-parse"", ""--git-dir""], cwd=root,\n                          hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(""Directory %s not under git control"" % root)\n        raise NotThisMethod(""\'git rev-parse --git-dir\' returned error"")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn\'t one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = run_command(GITS, [""describe"", ""--tags"", ""--dirty"",\n                                          ""--always"", ""--long"",\n                                          ""--match"", ""%s*"" % tag_prefix],\n                                   cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(""\'git describe\' failed"")\n    describe_out = describe_out.strip()\n    full_out, rc = run_command(GITS, [""rev-parse"", ""HEAD""], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(""\'git rev-parse\' failed"")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[""long""] = full_out\n    pieces[""short""] = full_out[:7]  # maybe improved later\n    pieces[""error""] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(""-dirty"")\n    pieces[""dirty""] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(""-dirty"")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if ""-"" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\'^(.+)-(\\d+)-g([0-9a-f]+)$\', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[""error""] = (""unable to parse git-describe output: \'%s\'""\n                               % describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = ""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                print(fmt % (full_tag, tag_prefix))\n            pieces[""error""] = (""tag \'%s\' doesn\'t start with prefix \'%s\'""\n                               % (full_tag, tag_prefix))\n            return pieces\n        pieces[""closest-tag""] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[""distance""] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[""short""] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[""closest-tag""] = None\n        count_out, rc = run_command(GITS, [""rev-list"", ""HEAD"", ""--count""],\n                                    cwd=root)\n        pieces[""distance""] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = run_command(GITS, [""show"", ""-s"", ""--format=%ci"", ""HEAD""],\n                       cwd=root)[0].strip()\n    pieces[""date""] = date.strip().replace("" "", ""T"", 1).replace("" "", """", 1)\n\n    return pieces\n\n\ndef plus_or_dot(pieces):\n    """"""Return a + if we don\'t already have one, else return a .""""""\n    if ""+"" in pieces.get(""closest-tag"", """"):\n        return "".""\n    return ""+""\n\n\ndef render_pep440(pieces):\n    """"""Build up version string, with post-release ""local version identifier"".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you\'ll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += plus_or_dot(pieces)\n            rendered += ""%d.g%s"" % (pieces[""distance""], pieces[""short""])\n            if pieces[""dirty""]:\n                rendered += "".dirty""\n    else:\n        # exception #1\n        rendered = ""0+untagged.%d.g%s"" % (pieces[""distance""],\n                                          pieces[""short""])\n        if pieces[""dirty""]:\n            rendered += "".dirty""\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    """"""TAG[.post.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post.devDISTANCE\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += "".post.dev%d"" % pieces[""distance""]\n    else:\n        # exception #1\n        rendered = ""0.post.dev%d"" % pieces[""distance""]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    """"""TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The "".dev0"" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear ""older"" than the corresponding clean one),\n    but you shouldn\'t be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n            rendered += plus_or_dot(pieces)\n            rendered += ""g%s"" % pieces[""short""]\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n        rendered += ""+g%s"" % pieces[""short""]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    """"""TAG[.postDISTANCE[.dev0]] .\n\n    The "".dev0"" means dirty.\n\n    Eexceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""] or pieces[""dirty""]:\n            rendered += "".post%d"" % pieces[""distance""]\n            if pieces[""dirty""]:\n                rendered += "".dev0""\n    else:\n        # exception #1\n        rendered = ""0.post%d"" % pieces[""distance""]\n        if pieces[""dirty""]:\n            rendered += "".dev0""\n    return rendered\n\n\ndef render_git_describe(pieces):\n    """"""TAG[-DISTANCE-gHEX][-dirty].\n\n    Like \'git describe --tags --dirty --always\'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        if pieces[""distance""]:\n            rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    """"""TAG-DISTANCE-gHEX[-dirty].\n\n    Like \'git describe --tags --dirty --always -long\'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no \'g\' prefix)\n    """"""\n    if pieces[""closest-tag""]:\n        rendered = pieces[""closest-tag""]\n        rendered += ""-%d-g%s"" % (pieces[""distance""], pieces[""short""])\n    else:\n        # exception #1\n        rendered = pieces[""short""]\n    if pieces[""dirty""]:\n        rendered += ""-dirty""\n    return rendered\n\n\ndef render(pieces, style):\n    """"""Render the given version pieces into the requested style.""""""\n    if pieces[""error""]:\n        return {""version"": ""unknown"",\n                ""full-revisionid"": pieces.get(""long""),\n                ""dirty"": None,\n                ""error"": pieces[""error""],\n                ""date"": None}\n\n    if not style or style == ""default"":\n        style = ""pep440""  # the default\n\n    if style == ""pep440"":\n        rendered = render_pep440(pieces)\n    elif style == ""pep440-pre"":\n        rendered = render_pep440_pre(pieces)\n    elif style == ""pep440-post"":\n        rendered = render_pep440_post(pieces)\n    elif style == ""pep440-old"":\n        rendered = render_pep440_old(pieces)\n    elif style == ""git-describe"":\n        rendered = render_git_describe(pieces)\n    elif style == ""git-describe-long"":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(""unknown style \'%s\'"" % style)\n\n    return {""version"": rendered, ""full-revisionid"": pieces[""long""],\n            ""dirty"": pieces[""dirty""], ""error"": None,\n            ""date"": pieces.get(""date"")}\n\n\ndef get_versions():\n    """"""Get version information or return default if unable to do so.""""""\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don\'t do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split(\'/\'):\n            root = os.path.dirname(root)\n    except NameError:\n        return {""version"": ""0+unknown"", ""full-revisionid"": None,\n                ""dirty"": None,\n                ""error"": ""unable to find root of source tree"",\n                ""date"": None}\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {""version"": ""0+unknown"", ""full-revisionid"": None,\n            ""dirty"": None,\n            ""error"": ""unable to compute version"", ""date"": None}\n'"
veros/backend.py,0,"b'from loguru import logger\n\nBACKENDS = None\n\n\ndef init_environment():\n    import os\n    from . import runtime_state as rst\n\n    if rst.proc_rank > 0:\n        os.environ.update(\n            BH_OPENMP_CACHE_READONLY=\'true\',\n            BH_UNSUP_WARN=\'false\',\n        )\n\n\ndef init_backends():\n    init_environment()\n\n    # populate available backend modules\n    global BACKENDS\n    BACKENDS = {}\n\n    import numpy\n    if numpy.__name__ == \'bohrium\':\n        logger.warning(\'Running veros with ""python -m bohrium"" is discouraged \'\n                       \'(use ""--backend bohrium"" instead)\')\n        import numpy_force\n        numpy = numpy_force\n\n    BACKENDS[\'numpy\'] = numpy\n\n    try:\n        import bohrium\n    except ImportError:\n        logger.warning(\'Could not import Bohrium (Bohrium backend will be unavailable)\')\n        BACKENDS[\'bohrium\'] = None\n    else:\n        BACKENDS[\'bohrium\'] = bohrium\n\n\ndef get_backend(backend_name):\n    if BACKENDS is None:\n        init_backends()\n\n    if backend_name not in BACKENDS:\n        raise ValueError(\'unrecognized backend {} (must be either of: {!r})\'\n                         .format(backend_name, list(BACKENDS.keys())))\n\n    if BACKENDS[backend_name] is None:\n        raise ValueError(\'backend ""{}"" failed to import\'.format(backend_name))\n\n    return BACKENDS[backend_name]\n\n\ndef get_vector_engine(np):\n    from . import runtime_settings\n\n    if runtime_settings.backend == \'bohrium\':\n        try:\n            import bohrium_api\n        except ImportError:\n            return None\n\n        if bohrium_api.stack_info.is_opencl_in_stack():\n            return \'opencl\'\n\n        if bohrium_api.stack_info.is_cuda_in_stack():\n            return \'cuda\'\n\n        return \'openmp\'\n\n    return None\n\n\ndef flush():\n    from . import runtime_settings as rs\n\n    if rs.backend == \'numpy\':\n        pass\n\n    elif rs.backend == \'bohrium\':\n        get_backend(rs.backend).flush()\n\n    else:\n        raise RuntimeError(\'Unrecognized backend %s\' % rs.backend)\n'"
veros/decorators.py,1,"b'import functools\nimport signal\nimport inspect\nimport threading\n\nfrom loguru import logger\n\ntry:\n    getargspec = inspect.getfullargspec\nexcept AttributeError:  # python 2\n    getargspec = inspect.getargspec\n\n\nCONTEXT = threading.local()\nCONTEXT.is_dist_safe = True\nCONTEXT.stack_level = 0\n\n\ndef veros_method(function=None, **kwargs):\n    """"""Decorator that injects the current backend as variable ``np`` into the wrapped function.\n\n    .. note::\n\n      This decorator should be applied to all functions that make use of the computational\n      backend (even when subclassing :class:`veros.Veros`). The first argument to the\n      decorated function must be a Veros instance.\n\n    Example:\n       >>> from veros import Veros, veros_method\n       >>>\n       >>> class MyModel(Veros):\n       >>>     @veros_method\n       >>>     def set_topography(self):\n       >>>         self.kbot[...] = np.random.randint(0, self.nz, size=self.kbot.shape)\n\n    """"""\n    if function is not None:\n        narg = 1 if _is_method(function) else 0\n        return _veros_method(function, narg=narg)\n\n    inline = kwargs.pop(\'inline\', False)\n    dist_safe = kwargs.pop(\'dist_safe\', True)\n\n    if not dist_safe and \'local_variables\' not in kwargs:\n        raise ValueError(\'local_variables argument must be given if dist_safe=False\')\n\n    local_vars = kwargs.pop(\'local_variables\', [])\n    dist_only = kwargs.pop(\'dist_only\', False)\n\n    def inner_decorator(function):\n        narg = 1 if _is_method(function) else 0\n        return _veros_method(\n            function, inline=inline, narg=narg,\n            dist_safe=dist_safe, local_vars=local_vars, dist_only=dist_only\n        )\n\n    return inner_decorator\n\n\ndef _is_method(function):\n    spec = getargspec(function)\n    return spec.args and spec.args[0] == \'self\'\n\n\ndef _veros_method(function, inline=False, dist_safe=True, local_vars=None,\n                  dist_only=False, narg=0):\n    @functools.wraps(function)\n    def veros_method_wrapper(*args, **kwargs):\n        from . import runtime_settings as rs, runtime_state as rst\n        from .backend import flush, get_backend\n        from .state import VerosStateBase\n        from .state_dist import DistributedVerosState\n        from .distributed import broadcast\n\n        if not inline:\n            logger.trace(\n                \'{}> {}:{}\',\n                \'-\' * CONTEXT.stack_level,\n                inspect.getmodule(function).__name__,\n                function.__name__\n            )\n            CONTEXT.stack_level += 1\n\n        veros_state = args[narg]\n\n        if not isinstance(veros_state, VerosStateBase):\n            raise TypeError(\'first argument to a veros_method must be a veros state object\')\n\n        reset_dist_safe = False\n        if not CONTEXT.is_dist_safe:\n            assert isinstance(veros_state, DistributedVerosState)\n        elif not dist_safe and rst.proc_num > 1:\n            reset_dist_safe = True\n\n        if reset_dist_safe:\n            dist_state = DistributedVerosState(veros_state)\n            dist_state.gather_arrays(local_vars)\n            func_state = dist_state\n            CONTEXT.is_dist_safe = False\n        else:\n            func_state = veros_state\n\n        execute = True\n        if not CONTEXT.is_dist_safe:\n            execute = rst.proc_rank == 0\n\n        g = function.__globals__\n        sentinel = object()\n\n        oldvalue = g.get(\'np\', sentinel)\n        g[\'np\'] = get_backend(rs.backend)\n\n        newargs = list(args)\n        newargs[narg] = func_state\n\n        res = None\n        try:\n            if execute:\n                res = function(*newargs, **kwargs)\n        except:\n            if reset_dist_safe:\n                CONTEXT.is_dist_safe = True\n            raise\n        else:\n            if reset_dist_safe:\n                CONTEXT.is_dist_safe = True\n                res = broadcast(veros_state, res)\n                dist_state.scatter_arrays()\n        finally:\n            if oldvalue is sentinel:\n                del g[\'np\']\n            else:\n                g[\'np\'] = oldvalue\n\n            if not inline:\n                CONTEXT.stack_level -= 1\n                flush()\n\n        return res\n\n    return veros_method_wrapper\n\n\ndef dist_context_only(function):\n    @functools.wraps(function)\n    def dist_context_only_wrapper(*args, **kwargs):\n        # args are assumed to be (), (vs,), or (vs, arr, ...)\n        from . import runtime_state as rst\n\n        if rst.proc_num == 1 or not CONTEXT.is_dist_safe:\n            # no-op for sequential execution\n            try:\n                # return input array unchanged\n                return args[1]\n            except IndexError:\n                return\n\n        return function(*args, **kwargs)\n\n    return dist_context_only_wrapper\n\n\ndef do_not_disturb(function):\n    """"""Decorator that catches SIGINT and SIGTERM signals (e.g. after keyboard interrupt)\n    and makes sure that the function body is executed before exiting.\n\n    Useful e.g. for ensuring that output files are written properly.\n    """"""\n    signals = (signal.SIGINT, signal.SIGTERM)\n\n    @functools.wraps(function)\n    def dnd_wrapper(*args, **kwargs):\n        old_handlers = {s: signal.getsignal(s) for s in signals}\n        signal_received = {\'sig\': None, \'frame\': None}\n\n        def handler(sig, frame):\n            if signal_received[\'sig\'] is None:\n                signal_received[\'sig\'] = sig\n                signal_received[\'frame\'] = frame\n                logger.error(\'Signal {} received - cleaning up before exit\', sig)\n            else:\n                # force quit if more than one signal is received\n                old_handlers[sig](sig, frame)\n\n        for s in signals:\n            signal.signal(s, handler)\n\n        try:\n            res = function(*args, **kwargs)\n\n        finally:\n            for s in signals:\n                signal.signal(s, old_handlers[s])\n            sig = signal_received[\'sig\']\n            if sig is not None:\n                old_handlers[sig](signal_received[\'sig\'], signal_received[\'frame\'])\n\n        return res\n\n    return dnd_wrapper\n'"
veros/distributed.py,16,"b""from . import runtime_settings as rs, runtime_state as rst\nfrom .decorators import veros_method, dist_context_only\n\n\nSCATTERED_DIMENSIONS = (\n    ('xt', 'xu'),\n    ('yt', 'yu')\n)\n\n\ndef ascontiguousarray(arr):\n    if not arr.flags['C_CONTIGUOUS'] and not arr.flags['F_CONTIGUOUS']:\n        return arr.copy()\n    if not arr.flags['OWNDATA']:\n        return arr.copy()\n    return arr\n\n\n@veros_method(inline=True)\ndef get_array_buffer(vs, arr):\n    from mpi4py import MPI\n\n    MPI_TYPE_MAP = {\n        'int8': MPI.CHAR,\n        'int16': MPI.SHORT,\n        'int32': MPI.INT,\n        'int64': MPI.LONG,\n        'int128': MPI.LONG_LONG,\n        'float32': MPI.FLOAT,\n        'float64': MPI.DOUBLE,\n        'bool': MPI.BOOL,\n    }\n\n    if rs.backend == 'bohrium':\n        if np.check(arr):\n            buf = np.interop_numpy.get_array(arr)\n        else:\n            buf = arr\n    else:\n        buf = arr\n\n    return [buf, arr.size, MPI_TYPE_MAP[str(arr.dtype)]]\n\n\n@veros_method\ndef validate_decomposition(vs):\n    if rs.mpi_comm is None:\n        if (rs.num_proc[0] > 1 or rs.num_proc[1] > 1):\n            raise RuntimeError('mpi4py is required for distributed execution')\n        return\n\n    comm_size = rs.mpi_comm.Get_size()\n    proc_num = rs.num_proc[0] * rs.num_proc[1]\n    if proc_num != comm_size:\n        raise RuntimeError('number of processes ({}) does not match size of communicator ({})'\n                           .format(proc_num, comm_size))\n\n    if vs.nx % rs.num_proc[0]:\n        raise ValueError('processes do not divide domain evenly in x-direction')\n\n    if vs.ny % rs.num_proc[1]:\n        raise ValueError('processes do not divide domain evenly in y-direction')\n\n\ndef get_chunk_size(vs):\n    return (vs.nx // rs.num_proc[0], vs.ny // rs.num_proc[1])\n\n\ndef get_global_size(vs, arr_shp, dim_grid, include_overlap=False):\n    ovl = 4 if include_overlap else 0\n    shape = []\n    for s, dim in zip(arr_shp, dim_grid):\n        if dim in SCATTERED_DIMENSIONS[0]:\n            shape.append(vs.nx + ovl)\n        elif dim in SCATTERED_DIMENSIONS[1]:\n            shape.append(vs.ny + ovl)\n        else:\n            shape.append(s)\n    return shape\n\n\ndef get_local_size(vs, arr_shp, dim_grid, include_overlap=False):\n    ovl = 4 if include_overlap else 0\n    shape = []\n    for s, dim in zip(arr_shp, dim_grid):\n        if dim in SCATTERED_DIMENSIONS[0]:\n            shape.append(vs.nx // rs.num_proc[0] + ovl)\n        elif dim in SCATTERED_DIMENSIONS[1]:\n            shape.append(vs.ny // rs.num_proc[1] + ovl)\n        else:\n            shape.append(s)\n    return shape\n\n\ndef proc_rank_to_index(rank):\n    return (rank % rs.num_proc[0], rank // rs.num_proc[0])\n\n\ndef proc_index_to_rank(ix, iy):\n    return ix + iy * rs.num_proc[0]\n\n\ndef get_chunk_slices(vs, dim_grid, proc_idx=None, include_overlap=False):\n    if proc_idx is None:\n        proc_idx = proc_rank_to_index(rst.proc_rank)\n\n    px, py = proc_idx\n    nx, ny = get_chunk_size(vs)\n\n    if include_overlap:\n        sxl = 0 if px == 0 else 2\n        sxu = nx + 4 if (px + 1) == rs.num_proc[0] else nx + 2\n        syl = 0 if py == 0 else 2\n        syu = ny + 4 if (py + 1) == rs.num_proc[1] else ny + 2\n    else:\n        sxl = syl = 0\n        sxu = nx\n        syu = ny\n\n    global_slice, local_slice = [], []\n\n    for dim in dim_grid:\n        if dim in SCATTERED_DIMENSIONS[0]:\n            global_slice.append(slice(sxl + px * nx, sxu + px * nx))\n            local_slice.append(slice(sxl, sxu))\n        elif dim in SCATTERED_DIMENSIONS[1]:\n            global_slice.append(slice(syl + py * ny, syu + py * ny))\n            local_slice.append(slice(syl, syu))\n        else:\n            global_slice.append(slice(None))\n            local_slice.append(slice(None))\n\n    return tuple(global_slice), tuple(local_slice)\n\n\ndef get_process_neighbors(vs):\n    this_x, this_y = proc_rank_to_index(rst.proc_rank)\n\n    west = this_x - 1 if this_x > 0 else None\n    south = this_y - 1 if this_y > 0 else None\n    east = this_x + 1 if (this_x + 1) < rs.num_proc[0] else None\n    north = this_y + 1 if (this_y + 1) < rs.num_proc[1] else None\n\n    neighbors = [\n        # direct neighbors\n        (west, this_y),\n        (this_x, south),\n        (east, this_y),\n        (this_x, north),\n        # corners\n        (west, south),\n        (east, south),\n        (east, north),\n        (west, north),\n    ]\n\n    global_neighbors = [\n        proc_index_to_rank(*i) if None not in i else None for i in neighbors\n    ]\n    return global_neighbors\n\n\n@dist_context_only\n@veros_method\ndef exchange_overlap(vs, arr, var_grid):\n    if len(var_grid) < 2:\n        d1, d2 = var_grid[0], None\n    else:\n        d1, d2 = var_grid[:2]\n\n    if d1 not in SCATTERED_DIMENSIONS[0] and d1 not in SCATTERED_DIMENSIONS[1] and d2 not in SCATTERED_DIMENSIONS[1]:\n        # neither x nor y dependent, nothing to do\n        return arr\n\n    if d1 in SCATTERED_DIMENSIONS[0] and d2 in SCATTERED_DIMENSIONS[1]:\n        proc_neighbors = get_process_neighbors(vs)\n\n        overlap_slices_from = (\n            (slice(2, 4), slice(0, None), Ellipsis), # west\n            (slice(0, None), slice(2, 4), Ellipsis), # south\n            (slice(-4, -2), slice(0, None), Ellipsis), # east\n            (slice(0, None), slice(-4, -2), Ellipsis), # north\n            (slice(2, 4), slice(2, 4), Ellipsis), # south-west\n            (slice(-4, -2), slice(2, 4), Ellipsis), # south-east\n            (slice(-4, -2), slice(-4, -2), Ellipsis), # north-east\n            (slice(2, 4), slice(-4, -2), Ellipsis), # north-west\n        )\n\n        overlap_slices_to = (\n            (slice(0, 2), slice(0, None), Ellipsis), # west\n            (slice(0, None), slice(0, 2), Ellipsis), # south\n            (slice(-2, None), slice(0, None), Ellipsis), # east\n            (slice(0, None), slice(-2, None), Ellipsis), # north\n            (slice(0, 2), slice(0, 2), Ellipsis), # south-west\n            (slice(-2, None), slice(0, 2), Ellipsis), # south-east\n            (slice(-2, None), slice(-2, None), Ellipsis), # north-east\n            (slice(0, 2), slice(-2, None), Ellipsis), # north-west\n        )\n\n        # flipped indices of overlap (n <-> s, w <-> e)\n        send_to_recv = [2, 3, 0, 1, 6, 7, 4, 5]\n\n    else:\n        if d1 in SCATTERED_DIMENSIONS[0]:\n            proc_neighbors = get_process_neighbors(vs)[0:4:2] # west and east\n        elif d1 in SCATTERED_DIMENSIONS[1]:\n            proc_neighbors = get_process_neighbors(vs)[1:4:2] # south and north\n        else:\n            raise NotImplementedError()\n\n        overlap_slices_from = (\n            (slice(2, 4), Ellipsis),\n            (slice(-4, -2), Ellipsis),\n        )\n\n        overlap_slices_to = (\n            (slice(0, 2), Ellipsis),\n            (slice(-2, None), Ellipsis),\n        )\n\n        send_to_recv = [1, 0]\n\n    receive_futures = []\n    for i_s, other_proc in enumerate(proc_neighbors):\n        if other_proc is None:\n            continue\n\n        i_r = send_to_recv[i_s]\n        recv_idx = overlap_slices_to[i_s]\n        recv_arr = np.empty_like(arr[recv_idx])\n\n        future = rs.mpi_comm.Irecv(get_array_buffer(vs, recv_arr), source=other_proc, tag=i_r)\n        receive_futures.append((future, recv_idx, recv_arr))\n\n    for i_s, other_proc in enumerate(proc_neighbors):\n        if other_proc is None:\n            continue\n\n        send_idx = overlap_slices_from[i_s]\n        send_arr = ascontiguousarray(arr[send_idx])\n\n        rs.mpi_comm.Send(get_array_buffer(vs, send_arr), dest=other_proc, tag=i_s)\n\n    for future, recv_idx, recv_arr in receive_futures:\n        future.wait()\n        arr[recv_idx] = recv_arr\n\n\n@dist_context_only\n@veros_method\ndef exchange_cyclic_boundaries(vs, arr):\n    if rs.num_proc[0] == 1:\n        arr[-2:, ...] = arr[2:4, ...]\n        arr[:2, ...] = arr[-4:-2, ...]\n        return\n\n    ix, iy = proc_rank_to_index(rst.proc_rank)\n\n    if 0 < ix < (rs.num_proc[0] - 1):\n        return\n\n    if ix == 0:\n        other_proc = proc_index_to_rank(rs.num_proc[0] - 1, iy)\n        send_idx = (slice(2, 4), Ellipsis)\n        recv_idx = (slice(0, 2), Ellipsis)\n    else:\n        other_proc = proc_index_to_rank(0, iy)\n        send_idx = (slice(-4, -2), Ellipsis)\n        recv_idx = (slice(-2, None), Ellipsis)\n\n    recv_arr = np.empty_like(arr[recv_idx])\n    send_arr = ascontiguousarray(arr[send_idx])\n\n    rs.mpi_comm.Sendrecv(\n        sendbuf=get_array_buffer(vs, send_arr), dest=other_proc, sendtag=10,\n        recvbuf=get_array_buffer(vs, recv_arr), source=other_proc, recvtag=10\n    )\n\n    arr[recv_idx] = recv_arr\n\n\n@dist_context_only\n@veros_method(inline=True)\ndef _reduce(vs, arr, op, axis=None):\n    if axis is None:\n        comm = rs.mpi_comm\n        disconnect_comm = False\n    else:\n        assert axis in (0, 1)\n        pi = proc_rank_to_index(rst.proc_rank)\n        other_axis = 1 - axis\n        comm = rs.mpi_comm.Split(pi[other_axis], rst.proc_rank)\n        disconnect_comm = True\n\n    try:\n        if np.isscalar(arr):\n            squeeze = True\n            arr = np.array([arr])\n        else:\n            squeeze = False\n\n        arr = ascontiguousarray(arr)\n        res = np.empty_like(arr)\n\n        comm.Allreduce(\n            get_array_buffer(vs, arr),\n            get_array_buffer(vs, res),\n            op=op\n        )\n\n        if squeeze:\n            res = res[0]\n\n        return res\n    finally:\n        if disconnect_comm:\n            comm.Disconnect()\n\n\n@dist_context_only\n@veros_method\ndef global_and(vs, arr, axis=None):\n    from mpi4py import MPI\n    return _reduce(vs, arr, MPI.LAND, axis=axis)\n\n\n@dist_context_only\n@veros_method\ndef global_or(vs, arr, axis=None):\n    from mpi4py import MPI\n    return _reduce(vs, arr, MPI.LOR, axis=axis)\n\n\n@dist_context_only\n@veros_method\ndef global_max(vs, arr, axis=None):\n    from mpi4py import MPI\n    return _reduce(vs, arr, MPI.MAX, axis=axis)\n\n\n@dist_context_only\n@veros_method\ndef global_min(vs, arr, axis=None):\n    from mpi4py import MPI\n    return _reduce(vs, arr, MPI.MIN, axis=axis)\n\n\n@dist_context_only\n@veros_method\ndef global_sum(vs, arr, axis=None):\n    from mpi4py import MPI\n    return _reduce(vs, arr, MPI.SUM, axis=axis)\n\n\n@dist_context_only\n@veros_method(inline=True)\ndef _gather_1d(vs, arr, dim):\n    assert dim in (0, 1)\n\n    otherdim = 1 - dim\n    pi = proc_rank_to_index(rst.proc_rank)\n    if pi[otherdim] != 0:\n        return arr\n\n    dim_grid = ['xt' if dim == 0 else 'yt'] + [None] * (arr.ndim - 1)\n    gidx, idx = get_chunk_slices(vs, dim_grid, include_overlap=True)\n    sendbuf = ascontiguousarray(arr[idx])\n\n    if rst.proc_rank == 0:\n        buffer_list = []\n        for proc in range(1, rst.proc_num):\n            pi = proc_rank_to_index(proc)\n            if pi[otherdim] != 0:\n                continue\n            idx_g, idx_l = get_chunk_slices(vs, dim_grid, include_overlap=True, proc_idx=pi)\n            recvbuf = np.empty_like(arr[idx_l])\n            future = rs.mpi_comm.Irecv(get_array_buffer(vs, recvbuf), source=proc, tag=20)\n            buffer_list.append((future, idx_g, recvbuf))\n\n        out_shape = ((vs.nx + 4, vs.ny + 4)[dim],) + arr.shape[1:]\n        out = np.empty(out_shape, dtype=arr.dtype)\n        out[gidx] = sendbuf\n\n        for future, idx, val in buffer_list:\n            future.wait()\n            out[idx] = val\n\n        return out\n\n    else:\n        rs.mpi_comm.Send(get_array_buffer(vs, sendbuf), dest=0, tag=20)\n        return arr\n\n\n@dist_context_only\n@veros_method(inline=True)\ndef _gather_xy(vs, arr):\n    nxi, nyi = get_chunk_size(vs)\n    assert arr.shape[:2] == (nxi + 4, nyi + 4), arr.shape\n\n    dim_grid = ['xt', 'yt'] + [None] * (arr.ndim - 2)\n    gidx, idx = get_chunk_slices(vs, dim_grid, include_overlap=True)\n    sendbuf = ascontiguousarray(arr[idx])\n\n    if rst.proc_rank == 0:\n        buffer_list = []\n        for proc in range(1, rst.proc_num):\n            idx_g, idx_l = get_chunk_slices(\n                vs, dim_grid, include_overlap=True,\n                proc_idx=proc_rank_to_index(proc)\n            )\n            recvbuf = np.empty_like(arr[idx_l])\n            future = rs.mpi_comm.Irecv(get_array_buffer(vs, recvbuf), source=proc, tag=30)\n            buffer_list.append((future, idx_g, recvbuf))\n\n        out_shape = (vs.nx + 4, vs.ny + 4) + arr.shape[2:]\n        out = np.empty(out_shape, dtype=arr.dtype)\n        out[gidx] = sendbuf\n\n        for future, idx, val in buffer_list:\n            future.wait()\n            out[idx] = val\n\n        return out\n    else:\n        rs.mpi_comm.Send(get_array_buffer(vs, sendbuf), dest=0, tag=30)\n\n    return arr\n\n\n@dist_context_only\n@veros_method\ndef gather(vs, arr, var_grid):\n    if len(var_grid) < 2:\n        d1, d2 = var_grid[0], None\n    else:\n        d1, d2 = var_grid[:2]\n\n    if d1 not in SCATTERED_DIMENSIONS[0] and d1 not in SCATTERED_DIMENSIONS[1] and d2 not in SCATTERED_DIMENSIONS[1]:\n        # neither x nor y dependent, nothing to do\n        return arr\n\n    if d1 in SCATTERED_DIMENSIONS[0] and d2 not in SCATTERED_DIMENSIONS[1]:\n        # only x dependent\n        return _gather_1d(vs, arr, 0)\n\n    elif d1 in SCATTERED_DIMENSIONS[1]:\n        # only y dependent\n        return _gather_1d(vs, arr, 1)\n\n    elif d1 in SCATTERED_DIMENSIONS[0] and d2 in SCATTERED_DIMENSIONS[1]:\n        # x and y dependent\n        return _gather_xy(vs, arr)\n\n    else:\n        raise NotImplementedError()\n\n\n@dist_context_only\n@veros_method\ndef broadcast(vs, obj):\n    return rs.mpi_comm.bcast(obj, root=0)\n\n\n@dist_context_only\n@veros_method(inline=True)\ndef _scatter_constant(vs, arr):\n    arr = ascontiguousarray(arr)\n    rs.mpi_comm.Bcast(get_array_buffer(vs, arr), root=0)\n    return arr\n\n\n@dist_context_only\n@veros_method(inline=True)\ndef _scatter_1d(vs, arr, dim):\n    assert dim in (0, 1)\n\n    nx = get_chunk_size(vs)[dim]\n    dim_grid = ['xt' if dim == 0 else 'yt'] + [None] * (arr.ndim - 1)\n    _, local_slice = get_chunk_slices(vs, dim_grid, include_overlap=True)\n\n    if rst.proc_rank == 0:\n        recvbuf = arr[local_slice]\n\n        for proc in range(1, rst.proc_num):\n            global_slice, _ = get_chunk_slices(vs, dim_grid, include_overlap=True, proc_idx=proc_rank_to_index(proc))\n            sendbuf = ascontiguousarray(arr[global_slice])\n            rs.mpi_comm.Send(get_array_buffer(vs, sendbuf), dest=proc, tag=40)\n\n        # arr changes shape in main process\n        arr = np.zeros((nx + 4,) + arr.shape[1:], dtype=arr.dtype)\n    else:\n        recvbuf = np.empty_like(arr[local_slice])\n        rs.mpi_comm.Recv(get_array_buffer(vs, recvbuf), source=0, tag=40)\n\n    arr[local_slice] = recvbuf\n\n    exchange_overlap(vs, arr, ['xt' if dim == 0 else 'yt'])\n\n    return arr\n\n\n@dist_context_only\n@veros_method(inline=True)\ndef _scatter_xy(vs, arr):\n    nxi, nyi = get_chunk_size(vs)\n\n    dim_grid = ['xt', 'yt'] + [None] * (arr.ndim - 2)\n    _, local_slice = get_chunk_slices(vs, dim_grid, include_overlap=True)\n\n    if rst.proc_rank == 0:\n        recvbuf = arr[local_slice]\n\n        for proc in range(1, rst.proc_num):\n            global_slice, _ = get_chunk_slices(vs, dim_grid, include_overlap=True, proc_idx=proc_rank_to_index(proc))\n            sendbuf = ascontiguousarray(arr[global_slice])\n            rs.mpi_comm.Send(get_array_buffer(vs, sendbuf), dest=proc, tag=50)\n\n        # arr changes shape in main process\n        arr = np.empty((nxi + 4, nyi + 4) + arr.shape[2:], dtype=arr.dtype)\n    else:\n        recvbuf = np.empty_like(arr[local_slice])\n        rs.mpi_comm.Recv(get_array_buffer(vs, recvbuf), source=0, tag=50)\n\n    arr[local_slice] = recvbuf\n\n    exchange_overlap(vs, arr, ['xt', 'yt'])\n\n    return arr\n\n\n@dist_context_only\n@veros_method\ndef scatter(vs, arr, var_grid):\n    if len(var_grid) < 2:\n        d1, d2 = var_grid[0], None\n    else:\n        d1, d2 = var_grid[:2]\n\n    arr = np.asarray(arr)\n\n    if d1 not in SCATTERED_DIMENSIONS[0] and d1 not in SCATTERED_DIMENSIONS[1] and d2 not in SCATTERED_DIMENSIONS[1]:\n        # neither x nor y dependent\n        return _scatter_constant(vs, arr)\n\n    if d1 in SCATTERED_DIMENSIONS[0] and d2 not in SCATTERED_DIMENSIONS[1]:\n        # only x dependent\n        return _scatter_1d(vs, arr, 0)\n\n    elif d1 in SCATTERED_DIMENSIONS[1]:\n        # only y dependent\n        return _scatter_1d(vs, arr, 1)\n\n    elif d1 in SCATTERED_DIMENSIONS[0] and d2 in SCATTERED_DIMENSIONS[1]:\n        # x and y dependent\n        return _scatter_xy(vs, arr)\n\n    else:\n        raise NotImplementedError()\n\n\n@dist_context_only\ndef barrier():\n    rs.mpi_comm.barrier()\n\n\n@dist_context_only\ndef abort():\n    rs.mpi_comm.Abort()\n"""
veros/handlers.py,0,"b'import signal\nimport contextlib\n\nfrom loguru import logger\n\n\n@contextlib.contextmanager\ndef signals_to_exception(signals=(signal.SIGINT, signal.SIGTERM)):\n    """"""Context manager that makes sure that converts system signals to exceptions.\n\n    This allows for a graceful exit after receiving SIGTERM (e.g. through\n    `kill` on UNIX systems).\n\n    Example:\n       >>> with signals_to_exception():\n       >>>     try:\n       >>>         # do something\n       >>>     except SystemExit:\n       >>>         # graceful exit even upon receiving interrupt signal\n    """"""\n    def signal_to_exception(sig, frame):\n        logger.critical(\'Received interrupt signal {}\', sig)\n        raise SystemExit(\'Aborted\')\n\n    old_signals = {}\n    for s in signals:\n        # override signals with our handler\n        old_signals[s] = signal.getsignal(s)\n        signal.signal(s, signal_to_exception)\n\n    try:\n        yield\n\n    finally:\n        # re-attach old signals\n        for s in signals:\n            signal.signal(s, old_signals[s])\n'"
veros/logs.py,0,"b""import sys\nimport warnings\n\nfrom loguru import logger\n\n# register custom loglevel\nlogger.level('DIAGNOSTIC', no=45)\n\n\ndef setup_logging(loglevel='info', stream_sink=sys.stdout):\n    from . import runtime_state, runtime_settings\n\n    handler_conf = dict(\n        sink=stream_sink,\n        level=loglevel.upper(),\n        colorize=sys.stdout.isatty(),\n    )\n\n    logger.level('TRACE', color='<dim>')\n    logger.level('DEBUG', color='<dim><cyan>')\n    logger.level('INFO', color='')\n    logger.level('SUCCESS', color='<dim><green>')\n    logger.level('WARNING', color='<yellow>')\n    logger.level('ERROR', color='<bold><red>')\n    logger.level('DIAGNOSTIC', color='<bold><yellow>')\n    logger.level('CRITICAL', color='<bold><red><WHITE>')\n\n    if runtime_settings.log_all_processes:\n        handler_conf.update(\n            format=f'{runtime_state.proc_rank} | <level>{{message}}</level>'\n        )\n    else:\n        handler_conf.update(\n            format='<level>{message}</level>',\n            filter=lambda record: runtime_state.proc_rank == 0\n        )\n\n    def diagnostic(_, message, *args, **kwargs):\n        logger.opt(depth=1).log('DIAGNOSTIC', message, *args, **kwargs)\n\n    logger.__class__.diagnostic = diagnostic\n\n    def showwarning(message, cls, source, lineno, *args):\n        logger.warning(\n            '{warning}: {message} ({source}:{lineno})',\n            message=message,\n            warning=cls.__name__,\n            source=source,\n            lineno=lineno\n        )\n\n    warnings.showwarning = showwarning\n\n    veros_logger = logger.configure(handlers=[handler_conf])\n    logger.enable('veros')\n\n    return veros_logger\n"""
veros/plugins.py,0,"b""from collections import namedtuple\n\nfrom .variables import Variable\nfrom .settings import Setting\nfrom .diagnostics.diagnostic import VerosDiagnostic\n\nVerosPlugin = namedtuple('VerosPlugin', [\n    'name',\n    'module',\n    'setup_entrypoint',\n    'run_entrypoint',\n    'settings',\n    'variables',\n    'conditional_variables',\n    'diagnostics',\n])\n\n\ndef load_plugin(module):\n    if not hasattr(module, '__VEROS_INTERFACE__'):\n        raise RuntimeError('module {} is not a valid Veros plugin'.format(module.__name__))\n\n    interface = module.__VEROS_INTERFACE__\n\n    setup_entrypoint = interface.get('setup_entrypoint')\n\n    if not callable(setup_entrypoint):\n        raise RuntimeError('module {} is missing a valid setup entrypoint'.format(module.__name__))\n\n    run_entrypoint = interface.get('run_entrypoint')\n\n    if not callable(run_entrypoint):\n        raise RuntimeError('module {} is missing a valid run entrypoint'.format(module.__name__))\n\n    name = interface.get('name', module.__name__)\n\n    settings = interface.get('settings', [])\n    for setting, val in settings.items():\n        if not isinstance(val, Setting):\n            raise TypeError('got unexpected type {} for setting {}'.format(type(val), setting))\n\n    variables = interface.get('variables', [])\n    for variable, val in variables.items():\n        if not isinstance(val, Variable):\n            raise TypeError('got unexpected type {} for variable {}'.format(type(val), variable))\n\n    conditional_variables = interface.get('conditional_variables', [])\n    for _, sub_variables in conditional_variables.items():\n        for variable, val in sub_variables.items():\n            if not isinstance(val, Variable):\n                raise TypeError('got unexpected type {} for variable {}'.format(type(val), variable))\n\n    diagnostics = interface.get('diagnostics', [])\n    for diagnostic in diagnostics:\n        if not issubclass(diagnostic, VerosDiagnostic):\n            raise TypeError('got unexpected type {} for diagnostic {}'.format(type(diagnostic), diagnostic))\n\n    return VerosPlugin(\n        name=name,\n        module=module,\n        setup_entrypoint=setup_entrypoint,\n        run_entrypoint=run_entrypoint,\n        settings=settings,\n        variables=variables,\n        conditional_variables=conditional_variables,\n        diagnostics=diagnostics\n    )\n"""
veros/progress.py,0,"b'import sys\nimport functools\nfrom time import perf_counter\n\nfrom loguru import logger\n\ntry:\n    import tqdm\nexcept ImportError:\n    has_tqdm = False\nelse:\n    has_tqdm = True\n\nfrom . import time, logs, runtime_settings as rs, runtime_state as rst\n\nBAR_FORMAT = (\n    \' Current iteration: {iteration:<5} ({time:.2f}/{total:.2f}{unit} | {percentage:>4.1f}% | \'\n    \'{rate:.2f}{rate_unit} | {eta:.1f}{eta_unit} left)\'\n)\n\n\nclass LoggingProgressBar:\n    """"""A simple progress report to logger.info\n\n    Serves as a fallback where TQDM is not available or not feasible (writing to a file,\n    in multiprocessing contexts).\n    """"""\n\n    def __init__(self, total, start_time=0, start_iteration=0, time_unit=\'seconds\'):\n        self._start_time = start_time\n        self._start_iteration = start_iteration\n        self._total = total\n\n        _, self._time_unit = time.format_time(total)\n\n    def __enter__(self):\n        self._start = perf_counter()\n        self._iteration = self._start_iteration\n        self._time = self._start_time\n        self.flush()\n        return self\n\n    def __exit__(self, *args, **kwargs):\n        pass\n\n    def advance_time(self, amount, *args, **kwargs):\n        self._iteration += 1\n        self._time += amount\n        self.flush()\n\n    def flush(self):\n        report_time = time.convert_time(self._time, \'seconds\', self._time_unit)\n        total_time = time.convert_time(self._total, \'seconds\', self._time_unit)\n\n        if self._time > self._start_time:\n            rate_in_seconds = (perf_counter() - self._start) / (self._time - self._start_time)\n        else:\n            rate_in_seconds = 0\n        rate_in_seconds_per_year = rate_in_seconds / time.convert_time(1, \'seconds\', \'years\')\n\n        rate, rate_unit = time.format_time(rate_in_seconds_per_year)\n        eta, eta_unit = time.format_time((self._total - self._time) * rate_in_seconds)\n\n        if self._start_time < self._total:\n            percentage = 100 * (self._time - self._start_time) / (self._total - self._start_time)\n        else:\n            percentage = 100\n\n        logger.info(\n            BAR_FORMAT,\n            time=report_time,\n            total=total_time,\n            unit=self._time_unit[0],\n            percentage=percentage,\n            iteration=self._iteration,\n            rate=rate,\n            rate_unit=\'{}/(model year)\'.format(rate_unit[0]),\n            eta=eta,\n            eta_unit=eta_unit[0],\n        )\n\n\nclass FancyProgressBar:\n    """"""A fancy progress bar based on TQDM that stays at the bottom of the terminal.""""""\n\n    def __init__(self, total, start_time=0, start_iteration=0, time_unit=\'seconds\'):\n        self._time = self._start_time = start_time\n        self._iteration = self._start_iteration = start_iteration\n        self._total = total\n\n        total_runlen, time_unit = time.format_time(total)\n        self._time_unit = time_unit\n\n        class _VerosTQDM(tqdm.tqdm):\n            """"""Stripped down version of tqdm.tqdm\n\n            We only need TQDM to handle dynamic updates to the progress indicator.\n            """"""\n            def __init__(self, *args, **kwargs):\n                kwargs.update(leave=True)\n                super().__init__(*args, **kwargs)\n\n            @property\n            def format_dict(other):\n                report_time = time.convert_time(self._time, \'seconds\', self._time_unit)\n                total_time = time.convert_time(self._total, \'seconds\', self._time_unit)\n                if self._start_time < self._total:\n                    percentage = 100 * (self._time - self._start_time) / (self._total - self._start_time)\n                else:\n                    percentage = 100\n\n                d = super().format_dict\n\n                if d[\'elapsed\'] > 0:\n                    if self._time > self._start_time:\n                        rate_in_seconds = d[\'elapsed\'] / (self._time - self._start_time)\n                    else:\n                        rate_in_seconds = 0\n                    rate_in_seconds_per_year = rate_in_seconds / time.convert_time(1, \'seconds\', \'years\')\n                    rate, rate_unit = time.format_time(rate_in_seconds_per_year)\n                    eta, eta_unit = time.format_time((self._total - self._time) * rate_in_seconds)\n                else:\n                    rate, rate_unit = 0, \'s\'\n                    eta, eta_unit = 0, \'s\'\n\n                d.update(\n                    iteration=self._iteration,\n                    time=report_time,\n                    total=total_time,\n                    unit=self._time_unit[0],\n                    percentage=percentage,\n                    rate=rate,\n                    rate_unit=\'{}/(model year)\'.format(rate_unit[0]),\n                    eta=eta,\n                    eta_unit=eta_unit[0],\n                )\n                return d\n\n            def format_meter(other, *args, bar_format, **kwargs):\n                return bar_format.format(**kwargs)\n\n        self._pbar = _VerosTQDM(\n            file=sys.stdout,\n            bar_format=BAR_FORMAT\n        )\n\n    def __enter__(self, *args, **kwargs):\n        self._iteration = self._start_iteration\n        self._time = self._start_time\n        logs.setup_logging(\n            loglevel=rs.loglevel,\n            stream_sink=functools.partial(self._pbar.write, file=sys.stdout, end=\'\')\n        )\n        self._pbar.__enter__(*args, **kwargs)\n        return self\n\n    def __exit__(self, *args, **kwargs):\n        logs.setup_logging(loglevel=rs.loglevel)\n        self._pbar.__exit__(*args, **kwargs)\n\n    def advance_time(self, amount):\n        self._iteration += 1\n        self._time += amount\n        self.flush()\n\n    def flush(self):\n        self._pbar.refresh()\n\n\ndef get_progress_bar(vs, use_tqdm=None):\n    if use_tqdm is None:\n        use_tqdm = sys.stdout.isatty() and rst.proc_num == 1 and has_tqdm\n\n    if use_tqdm and not has_tqdm:\n        raise RuntimeError(\'tqdm failed to import. Try `pip install tqdm` or set use_tqdm=False.\')\n\n    kwargs = dict(\n        total=vs.runlen + vs.time,\n        start_time=vs.time,\n        start_iteration=vs.itt\n    )\n\n    if use_tqdm:\n        pbar = FancyProgressBar(**kwargs)\n    else:\n        pbar = LoggingProgressBar(**kwargs)\n\n    return pbar\n'"
veros/runtime.py,0,"b'import os\n\n\ndef _default_mpi_comm():\n    try:\n        from mpi4py import MPI\n    except ImportError:\n        return None\n    else:\n        return MPI.COMM_WORLD\n\n\ndef twoints(v):\n    return (int(v[0]), int(v[1]))\n\n\ndef loglevel(v):\n    loglevels = (\'trace\', \'debug\', \'info\', \'warning\', \'error\')\n    if v not in loglevels:\n        raise ValueError(\'loglevel must be one of %r\' % loglevels)\n    return v\n\n\ndef parse_bool(string):\n    if not string:\n        return False\n\n    return string.lower() in {\'1\', \'true\'}\n\n\nAVAILABLE_SETTINGS = (\n    # (name, type, default)\n    (\'backend\', str, os.environ.get(\'VEROS_BACKEND\', \'numpy\')),\n    (\'linear_solver\', str, os.environ.get(\'VEROS_LINEAR_SOLVER\', \'best\')),\n    (\'num_proc\', twoints, (1, 1)),\n    (\'profile_mode\', parse_bool, os.environ.get(\'VEROS_PROFILE_MODE\', \'\')),\n    (\'loglevel\', loglevel, os.environ.get(\'VEROS_LOGLEVEL\', \'info\')),\n    (\'mpi_comm\', None, _default_mpi_comm()),\n    (\'log_all_processes\', parse_bool, os.environ.get(\'VEROS_LOG_ALL_PROCESSES\', \'\'))\n)\n\n\nclass RuntimeSettings:\n    def __init__(self):\n        self.__locked__ = False\n        self.__setting_types__ = {}\n\n        for setting, typ, default in AVAILABLE_SETTINGS:\n            setattr(self, setting, default)\n            self.__setting_types__[setting] = typ\n\n        self.__settings__ = set(self.__setting_types__.keys())\n        self.__locked__ = True\n\n    def __setattr__(self, attr, val):\n        if attr == \'__locked__\' or not self.__locked__:\n            return super(RuntimeSettings, self).__setattr__(attr, val)\n\n        # prevent adding new settings\n        if attr not in self.__settings__:\n            raise AttributeError(\'Unknown runtime setting %s\' % attr)\n\n        # coerce type\n        stype = self.__setting_types__.get(attr)\n        if stype is not None:\n            val = stype(val)\n\n        return super(RuntimeSettings, self).__setattr__(attr, val)\n\n    def __repr__(self):\n        setval = \', \'.join(\n            \'%s=%s\' % (key, repr(getattr(self, key))) for key in self.__settings__\n        )\n        return \'{clsname}({setval})\'.format(\n            clsname=self.__class__.__name__,\n            setval=setval\n        )\n\n\nclass RuntimeState:\n    """"""Unifies attributes from various modules in a simple read-only object""""""\n\n    __slots__ = []\n\n    @property\n    def proc_rank(self):\n        from . import runtime_settings\n        comm = runtime_settings.mpi_comm\n\n        if comm is None:\n            return 0\n\n        return comm.Get_rank()\n\n    @property\n    def proc_num(self):\n        from . import runtime_settings\n        comm = runtime_settings.mpi_comm\n\n        if comm is None:\n            return 1\n\n        return comm.Get_size()\n\n    @property\n    def proc_idx(self):\n        from . import distributed\n        return distributed.proc_rank_to_index(self.proc_rank)\n\n    @property\n    def backend_module(self):\n        from . import backend, runtime_settings\n        return backend.get_backend(runtime_settings.backend)\n\n    @property\n    def vector_engine(self):\n        from . import backend\n        return backend.get_vector_engine(self.backend_module)\n\n    def __setattr__(self, attr, val):\n        raise TypeError(\'Cannot modify runtime state objects\')\n'"
veros/settings.py,0,"b""from collections import namedtuple, OrderedDict\n\nSetting = namedtuple('setting', ('default', 'type', 'description'))\n\nSETTINGS = OrderedDict([\n    ('identifier', Setting('UNNAMED', str, 'Identifier of the current simulation')),\n\n    # Model parameters\n    ('nx', Setting(0, int, 'Grid points in zonal (x) direction')),\n    ('ny', Setting(0, int, 'Grid points in meridional (y,j) direction')),\n    ('nz', Setting(0, int, 'Grid points in vertical (z,k) direction')),\n    ('dt_mom', Setting(0., float, 'Time step in seconds for momentum')),\n    ('dt_tracer', Setting(0., float, 'Time step for tracers, can be larger than dt_mom')),\n    ('runlen', Setting(0., float, 'Length of simulation in seconds')),\n    ('AB_eps', Setting(0.1, float, 'Deviation from Adam-Bashforth weighting')),\n\n    # Logical switches for general model setup\n    ('coord_degree', Setting(False, bool, 'either spherical (True) or cartesian (False) coordinates')),\n    ('enable_cyclic_x', Setting(False, bool, 'enable cyclic boundary conditions')),\n    ('eq_of_state_type', Setting(1, int, 'equation of state: 1: linear, 3: nonlinear with comp., 5: TEOS')),\n    ('enable_implicit_vert_friction', Setting(False, bool, 'enable implicit vertical friction')),\n    ('enable_explicit_vert_friction', Setting(False, bool, 'enable explicit vertical friction')),\n    ('enable_hor_friction', Setting(False, bool, 'enable horizontal friction')),\n    ('enable_hor_diffusion', Setting(False, bool, 'enable horizontal diffusion')),\n    ('enable_biharmonic_friction', Setting(False, bool, 'enable biharmonic horizontal friction')),\n    ('enable_biharmonic_mixing', Setting(False, bool, 'enable biharmonic horizontal mixing')),\n    ('enable_hor_friction_cos_scaling', Setting(False, bool, 'scaling of hor. viscosity with cos(latitude)**cosPower')),\n    ('enable_ray_friction', Setting(False, bool, 'enable Rayleigh damping')),\n    ('enable_bottom_friction', Setting(False, bool, 'enable bottom friction')),\n    ('enable_bottom_friction_var', Setting(False, bool, 'enable bottom friction with lateral variations')),\n    ('enable_quadratic_bottom_friction', Setting(False, bool, 'enable quadratic bottom friction')),\n    ('enable_tempsalt_sources', Setting(False, bool, 'enable restoring zones, etc')),\n    ('enable_momentum_sources', Setting(False, bool, 'enable restoring zones, etc')),\n    ('enable_superbee_advection', Setting(False, bool, 'enable advection scheme with implicit mixing')),\n    ('enable_conserve_energy', Setting(True, bool, 'exchange energy consistently')),\n    ('enable_store_bottom_friction_tke', Setting(False, bool, 'transfer dissipated energy by bottom/rayleig fric. to TKE, else transfer to internal waves')),\n    ('enable_store_cabbeling_heat', Setting(False, bool, 'transfer non-linear mixing terms to potential enthalpy, else transfer to TKE and EKE')),\n    ('enable_noslip_lateral', Setting(False, bool, 'enable lateral no-slip boundary conditions in harmonic- and biharmonic friction.')),\n\n    # External mode\n    ('congr_epsilon', Setting(1e-12, float, 'convergence criteria for Poisson solver')),\n    ('congr_max_iterations', Setting(1000, int, 'maximum number of Poisson solver iterations')),\n\n    # Mixing parameter\n    ('A_h', Setting(0.0, float, 'lateral viscosity in m^2/s')),\n    ('K_h', Setting(0.0, float, 'lateral diffusivity in m^2/s')),\n    ('r_ray', Setting(0.0, float, 'Rayleigh damping coefficient in 1/s')),\n    ('r_bot', Setting(0.0, float, 'bottom friction coefficient in 1/s')),\n    ('r_quad_bot', Setting(0.0, float, 'qudratic bottom friction coefficient')),\n    ('hor_friction_cosPower', Setting(3, float, '')),\n    ('A_hbi', Setting(0.0, float, 'lateral biharmonic viscosity in m^4/s')),\n    ('K_hbi', Setting(0.0, float, 'lateral biharmonic diffusivity in m^4/s')),\n    ('kappaH_0', Setting(0.0, float, '')),\n    ('kappaM_0', Setting(0.0, float, 'fixed values for vertical viscosity/diffusivity which are set for no TKE model')),\n\n    # Options for isopycnal mixing\n    ('enable_neutral_diffusion', Setting(False, bool, 'enable isopycnal mixing')),\n    ('enable_skew_diffusion', Setting(False, bool, 'enable skew diffusion approach for eddy-driven velocities')),\n    ('enable_TEM_friction', Setting(False, bool, 'TEM approach for eddy-driven velocities')),\n    ('K_iso_0', Setting(0.0, float, 'constant for isopycnal diffusivity in m^2/s')),\n    ('K_iso_steep', Setting(0.0, float, 'lateral diffusivity for steep slopes in m^2/s')),\n    ('K_gm_0', Setting(0.0, float, 'fixed value for K_gm which is set for no EKE model')),\n    ('iso_dslope', Setting(0.0008, float, 'parameters controlling max allowed isopycnal slopes')),\n    ('iso_slopec', Setting(0.001, float, 'parameters controlling max allowed isopycnal slopes')),\n\n    # Idemix 1.0\n    ('enable_idemix', Setting(False, bool, '')),\n    ('tau_v', Setting(2.0 * 86400.0, float, 'time scale for vertical symmetrisation')),\n    ('tau_h', Setting(15.0 * 86400.0, float, 'time scale for horizontal symmetrisation')),\n    ('gamma', Setting(1.57, float, '')),\n    ('jstar', Setting(5.0, float, 'spectral bandwidth in modes')),\n    ('mu0', Setting(1. / 3., float, 'dissipation parameter')),\n    ('enable_idemix_hor_diffusion', Setting(False, bool, '')),\n    ('enable_eke_diss_bottom', Setting(False, bool, '')),\n    ('enable_eke_diss_surfbot', Setting(False, bool, '')),\n    ('eke_diss_surfbot_frac', Setting(1.0, float, 'fraction which goes into bottom')),\n    ('enable_idemix_superbee_advection', Setting(False, bool, '')),\n    ('enable_idemix_upwind_advection', Setting(False, bool, '')),\n\n    # TKE\n    ('enable_tke', Setting(False, bool, '')),\n    ('c_k', Setting(0.1, float, '')),\n    ('c_eps', Setting(0.7, float, '')),\n    ('alpha_tke', Setting(1.0, float, '')),\n    ('mxl_min', Setting(1e-12, float, '')),\n    ('kappaM_min', Setting(0., float, '')),\n    ('kappaM_max', Setting(100., float, '')),\n    ('tke_mxl_choice', Setting(1, int, '')),\n    ('enable_tke_superbee_advection', Setting(False, bool, '')),\n    ('enable_tke_upwind_advection', Setting(False, bool, '')),\n    ('enable_tke_hor_diffusion', Setting(False, bool, '')),\n    ('K_h_tke', Setting(2000., float, 'lateral diffusivity for tke')),\n\n    # EKE\n    ('enable_eke', Setting(False, bool, '')),\n    ('eke_lmin', Setting(100.0, float, 'minimal length scale in m')),\n    ('eke_c_k', Setting(1.0, float, '')),\n    ('eke_cross', Setting(1.0, float, 'Parameter for EKE model')),\n    ('eke_crhin', Setting(1.0, float, 'Parameter for EKE model')),\n    ('eke_c_eps', Setting(1.0, float, 'Parameter for EKE model')),\n    ('eke_k_max', Setting(1e4, float, 'maximum of K_gm')),\n    ('alpha_eke', Setting(1.0, float, 'factor vertical friction')),\n    ('enable_eke_superbee_advection', Setting(False, bool, '')),\n    ('enable_eke_upwind_advection', Setting(False, bool, '')),\n    ('enable_eke_isopycnal_diffusion', Setting(False, bool, 'use K_gm also for isopycnal diffusivity')),\n\n    ('enable_eke_leewave_dissipation', Setting(False, bool, '')),\n    ('c_lee0', Setting(1., float, '')),\n    ('eke_Ri0', Setting(200., float, '')),\n    ('eke_Ri1', Setting(50., float, '')),\n    ('eke_int_diss0', Setting(1. / (20 * 86400.), float, '')),\n    ('kappa_EKE0', Setting(0.1, float, '')),\n    ('eke_r_bot', Setting(0.0, float, 'bottom friction coefficient')),\n    ('eke_hrms_k0_min', Setting(0.0, float, 'min value for bottom roughness parameter')),\n\n    # New\n    ('kappaH_min', Setting(0., float, 'minimum value for vertical diffusivity')),\n    ('enable_kappaH_profile', Setting(False, bool, 'Compute vertical profile of diffusivity after Bryan and Lewis (1979) in TKE routine')),\n    ('enable_Prandtl_tke', Setting(True, bool, 'Compute Prandtl number from stratification levels in TKE routine')),\n    ('Prandtl_tke0', Setting(10., float, 'Constant Prandtl number when stratification is neglected for kappaH computation in TKE routine')),\n    ('use_io_threads', Setting(False, bool, 'Start extra threads for disk writes')),\n    ('io_timeout', Setting(20, float, 'Timeout in seconds while waiting for IO locks to be released')),\n    ('enable_hdf5_gzip_compression', Setting(True, bool, 'Use h5py\\'s native gzip interface, which leads to smaller restart files (but carries some computational overhead).')),\n    ('restart_input_filename', Setting('', str, 'File name of restart input. If not given, no restart data will be read.')),\n    ('restart_output_filename', Setting('{identifier}_{itt:0>4d}.restart.h5', str, 'File name of restart output. May contain Python format syntax that is substituted with Veros attributes.')),\n    ('restart_frequency', Setting(0, float, 'Frequency (in seconds) to write restart data')),\n    ('force_overwrite', Setting(False, bool, 'Overwrite existing output files')),\n    ('pyom_compatibility_mode', Setting(False, bool, 'Force compatibility to pyOM2 (even reproducing bugs and other quirks). For testing purposes only.')),\n    ('diskless_mode', Setting(False, bool, 'Suppress all output to disk. Mainly used for testing purposes.')),\n    ('default_float_type', Setting('float64', str, 'Default type to use for floating point arrays (e.g. ``float32`` or ``float64``).')),\n])\n\n\ndef set_default_settings(vs):\n    update_settings(vs, SETTINGS)\n\n\ndef update_settings(vs, settings):\n    for key, setting in settings.items():\n        setattr(vs, key, setting.type(setting.default))\n\n\ndef check_setting_conflicts(vs):\n    if vs.enable_tke and not vs.enable_implicit_vert_friction:\n        raise RuntimeError('use TKE model only with implicit vertical friction'\n                           '(set enable_implicit_vert_fricton)')\n"""
veros/state.py,0,"b'import abc\nimport math\n\nfrom . import variables, settings, timer, plugins, diagnostics\n\n\nclass VerosStateBase(metaclass=abc.ABCMeta):\n    pass\n\n\nclass VerosState(VerosStateBase):\n    """"""Holds all settings and model state for a given Veros run.""""""\n    # Constants\n    pi = math.pi\n    radius = 6370e3  # Earth radius in m\n    degtom = radius / 180. * pi  # Conversion degrees latitude to meters\n    mtodeg = 1. / degtom  # Conversion meters to degrees latitude\n    omega = pi / 43082.  # Earth rotation frequency in 1/s\n    rho_0 = 1024.  # Boussinesq reference density in :math:`kg/m^3`\n    grav = 9.81  # Gravitational constant in :math:`m/s^2`\n\n    def __init__(self, use_plugins=None):\n        self.variables = {}\n        self.diagnostics = {}\n        self.poisson_solver = None\n        self.nisle = 0 # to be overriden during streamfunction_init\n        self.taum1, self.tau, self.taup1 = 0, 1, 2 # pointers to last, current, and next time step\n        self.time, self.itt = 0., 0 # current time and iteration\n\n        if use_plugins is not None:\n            self._plugin_interfaces = tuple(plugins.load_plugin(p) for p in use_plugins)\n        else:\n            self._plugin_interfaces = tuple()\n\n        settings.set_default_settings(self)\n\n        for plugin in self._plugin_interfaces:\n            settings.update_settings(self, plugin.settings)\n\n        self.timers = {k: timer.Timer() for k in (\n            \'setup\', \'main\', \'momentum\', \'temperature\', \'eke\', \'idemix\',\n            \'tke\', \'diagnostics\', \'pressure\', \'friction\', \'isoneutral\',\n            \'vmix\', \'eq_of_state\', \'plugins\'\n        )}\n\n        for plugin in self._plugin_interfaces:\n            self.timers[plugin.name] = timer.Timer()\n\n    def allocate_variables(self):\n        self.variables.update(variables.get_standard_variables(self))\n\n        for plugin in self._plugin_interfaces:\n            plugin_vars = variables.get_active_variables(self, plugin.variables, plugin.conditional_variables)\n            self.variables.update(plugin_vars)\n\n        for key, var in self.variables.items():\n            setattr(self, key, variables.allocate(self, var.dims, dtype=var.dtype))\n\n    def create_diagnostics(self):\n        self.diagnostics.update(diagnostics.create_default_diagnostics(self))\n\n        for plugin in self._plugin_interfaces:\n            for diagnostic in plugin.diagnostics:\n                self.diagnostics[diagnostic.name] = diagnostic(self)\n\n    def to_xarray(self):\n        import xarray as xr\n\n        coords = {}\n        data_vars = {}\n\n        for var_name, var in self.variables.items():\n            data = variables.remove_ghosts(\n                getattr(self, var_name), var.dims\n            )\n            data_vars[var_name] = xr.DataArray(\n                data,\n                dims=var.dims,\n                name=var_name,\n                attrs=dict(\n                    long_description=var.long_description,\n                    units=var.units,\n                    scale=var.scale,\n                )\n            )\n\n            for dim in var.dims:\n                if dim not in coords:\n                    if hasattr(self, dim):\n                        dim_val = getattr(self, dim)\n                        if isinstance(dim_val, int):\n                            coords[dim] = range(dim_val)\n                        else:\n                            coords[dim] = variables.remove_ghosts(dim_val, (dim,))\n                    else:\n                        coords[dim] = range(variables.get_dimensions(self, (dim,))[0])\n\n        data_vars = {k: v for k, v in data_vars.items() if k not in coords}\n\n        attrs = dict(\n            time=self.time,\n            iteration=self.itt,\n            tau=self.tau,\n        )\n\n        return xr.Dataset(data_vars, coords=coords, attrs=attrs)\n'"
veros/state_dist.py,0,"b'from loguru import logger\n\nfrom .state import VerosStateBase\n\n\nclass DistributedVerosState(VerosStateBase):\n    """"""A proxy wrapper to temporarily synchronize a distributed state.\n\n    Use `gather_arrays` to retrieve distributed variables from parent VerosState object,\n    and `scatter_arrays` to sync changes back.\n    """"""\n    def __init__(self, parent_state):\n        object.__setattr__(self, \'_vs\', parent_state)\n        object.__setattr__(self, \'_gathered\', set())\n\n    def gather_arrays(self, arrays):\n        """"""Gather given variables from parent state object""""""\n        from .distributed import gather\n        for arr in arrays:\n            if not hasattr(self._vs, arr):\n                continue\n            self._gathered.add(arr)\n            logger.trace(\' Gathering {}\', arr)\n            gathered_arr = gather(\n                self._vs,\n                getattr(self._vs, arr),\n                self._vs.variables[arr].dims\n            )\n            setattr(self, arr, gathered_arr)\n\n    def scatter_arrays(self):\n        """"""Sync all changes with parent state object""""""\n        from .distributed import scatter\n        for arr in sorted(self._gathered):\n            if not hasattr(self._vs, arr):\n                continue\n            logger.trace(\' Scattering {}\', arr)\n            getattr(self._vs, arr)[...] = scatter(\n                self._vs,\n                getattr(self, arr),\n                self._vs.variables[arr].dims\n            )\n\n    def __getattribute__(self, attr):\n        if attr in (\'_vs\', \'_gathered\', \'gather_arrays\', \'scatter_arrays\'):\n            return object.__getattribute__(self, attr)\n\n        gathered = self._gathered\n        if attr in gathered:\n            return object.__getattribute__(self, attr)\n\n        parent_state = self._vs\n        if attr not in parent_state.variables:\n            # not a variable: pass through\n            return parent_state.__getattribute__(attr)\n\n        raise AttributeError(\'Cannot access distributed variable %s since it was not retrieved\' % attr)\n\n    def __setattr__(self, attr, val):\n        if attr in self._gathered:\n            return object.__setattr__(self, attr, val)\n\n        if attr not in self._vs.variables:\n            # not a variable: pass through\n            return self._vs.__setattr__(attr, val)\n\n        raise AttributeError(\'Cannot access distributed variable %s since it was not retrieved\' % attr)\n\n    def __repr__(self):\n        return \'{}(parent_state={})\'.format(self.__class__.__name__, repr(self._vs))\n'"
veros/time.py,0,"b""\nYEAR_LENGTH = 360.\nX_TO_SECONDS = {\n    'seconds': 1.,\n    'minutes': 60.,\n    'hours': 60. * 60.,\n    'days': 24. * 60. * 60.,\n    'years': YEAR_LENGTH * 24. * 60. * 60.\n}\nSECONDS_TO_X = {key: 1. / val for key, val in X_TO_SECONDS.items()}\n\n\ndef convert_time(time_value, in_unit, out_unit):\n    return time_value * X_TO_SECONDS[in_unit] * SECONDS_TO_X[out_unit]\n\n\ndef format_time(time_value, in_unit='seconds'):\n    all_units = X_TO_SECONDS.keys()\n    val_in_all_units = {u: convert_time(time_value, in_unit, u) for u in all_units}\n    valid_units = {u: v for u, v in val_in_all_units.items() if v >= 1.}\n    if valid_units:\n        best_unit = min(valid_units, key=valid_units.get)\n    else:\n        best_unit = 'seconds'\n    return val_in_all_units[best_unit], best_unit\n"""
veros/timer.py,0,"b'import timeit\n\n\nclass Timer:\n    def __init__(self):\n        self.total_time = 0\n        self.last_time = 0\n\n        try:\n            import bohrium as bh\n            flush = bh.flush\n        except ImportError:\n            def flush():\n                pass\n\n        self._flush = flush\n\n    def __enter__(self):\n        self.start_time = timeit.default_timer()\n\n    def __exit__(self, type, value, traceback):\n        self._flush()\n        self.last_time = timeit.default_timer() - self.start_time\n        self.total_time += self.last_time\n\n    def get_time(self):\n        return self.total_time\n\n    def get_last_time(self):\n        return self.last_time\n'"
veros/variables.py,2,"b""from collections import OrderedDict\n\nfrom . import veros_method, runtime_settings\n\n\nclass Variable:\n    def __init__(self, name, dims, units, long_description, dtype=None,\n                 output=False, time_dependent=True, scale=1.,\n                 write_to_restart=False, extra_attributes=None, mask=None):\n        dims = tuple(dims)\n\n        self.name = name\n        self.dims = dims\n        self.units = units\n        self.long_description = long_description\n        self.dtype = dtype\n        self.output = output\n        self.time_dependent = time_dependent\n        self.scale = scale\n        self.write_to_restart = write_to_restart\n\n        if mask is not None:\n            if not callable(mask):\n                raise TypeError('mask argument has to be callable')\n            self.get_mask = mask\n        else:\n            if dims[:3] in DEFAULT_MASKS:\n                self.get_mask = DEFAULT_MASKS[dims[:3]]\n            elif dims[:2] in DEFAULT_MASKS:\n                self.get_mask = DEFAULT_MASKS[dims[:2]]\n            else:\n                self.get_mask = lambda vs: None\n\n        #: Additional attributes to be written in netCDF output\n        self.extra_attributes = extra_attributes or {}\n\n\n# fill value for netCDF output (invalid data is replaced by this value)\nFILL_VALUE = -1e18\n\n#\nXT = ('xt',)\nXU = ('xu',)\nYT = ('yt',)\nYU = ('yu',)\nZT = ('zt',)\nZW = ('zw',)\nT_HOR = ('xt', 'yt')\nU_HOR = ('xu', 'yt')\nV_HOR = ('xt', 'yu')\nZETA_HOR = ('xu', 'yu')\nT_GRID = ('xt', 'yt', 'zt')\nU_GRID = ('xu', 'yt', 'zt')\nV_GRID = ('xt', 'yu', 'zt')\nW_GRID = ('xt', 'yt', 'zw')\nZETA_GRID = ('xu', 'yu', 'zt')\nTIMESTEPS = ('timesteps',)\nISLE = ('isle',)\nTENSOR_COMP = ('tensor1', 'tensor2')\n\n# those are written to netCDF output by default\nBASE_DIMENSIONS = XT + XU + YT + YU + ZT + ZW + ISLE\nGHOST_DIMENSIONS = ('xt', 'yt', 'xu', 'yu')\n\nDEFAULT_MASKS = {\n    T_HOR: lambda vs: vs.maskT[:, :, -1],\n    U_HOR: lambda vs: vs.maskU[:, :, -1],\n    V_HOR: lambda vs: vs.maskV[:, :, -1],\n    ZETA_HOR: lambda vs: vs.maskZ[:, :, -1],\n    T_GRID: lambda vs: vs.maskT,\n    U_GRID: lambda vs: vs.maskU,\n    V_GRID: lambda vs: vs.maskV,\n    W_GRID: lambda vs: vs.maskW,\n    ZETA_GRID: lambda vs: vs.maskZ\n}\n\nZETA_HOR_ERODED = lambda vs: vs.maskZ[:, :, -1] | vs.boundary_mask.sum(axis=2)  # noqa: E731\n\n\ndef get_dimensions(vs, grid, include_ghosts=True, local=True):\n    px, py = runtime_settings.num_proc\n\n    dimensions = {\n        'xt': vs.nx,\n        'xu': vs.nx,\n        'yt': vs.ny,\n        'yu': vs.ny,\n        'zt': vs.nz,\n        'zw': vs.nz,\n        'timesteps': 3,\n        'tensor1': 2,\n        'tensor2': 2,\n        'isle': vs.nisle,\n    }\n\n    if local:\n        dimensions.update({\n            'xt': dimensions['xt'] // px,\n            'xu': dimensions['xu'] // px,\n            'yt': dimensions['yt'] // py,\n            'yu': dimensions['yt'] // py\n        })\n\n    if include_ghosts:\n        for d in GHOST_DIMENSIONS:\n            dimensions[d] += 4\n\n    dims = []\n    for grid_dim in grid:\n        if grid_dim in dimensions:\n            dims.append(dimensions[grid_dim])\n        elif isinstance(grid_dim, int):\n            dims.append(grid_dim)\n        elif hasattr(vs, grid_dim):\n            dims.append(getattr(vs, grid_dim))\n        else:\n            raise ValueError('unrecognized dimension %s' % grid_dim)\n\n    return tuple(dims)\n\n\ndef remove_ghosts(array, dims):\n    ghost_mask = tuple(slice(2, -2) if dim in GHOST_DIMENSIONS else slice(None) for dim in dims)\n    return array[ghost_mask]\n\n\n@veros_method\ndef add_ghosts(vs, array, dims):\n    full_shape = tuple([i + 4 if dim in GHOST_DIMENSIONS else i for i,\n                        dim in zip(array.shape, dims)])\n    newarr = np.zeros(full_shape, dtype=array.dtype)\n    ghost_mask = tuple(slice(2, -2) if dim in GHOST_DIMENSIONS else slice(None) for dim in dims)\n    newarr[ghost_mask] = array\n    return newarr\n\n\nMAIN_VARIABLES = OrderedDict([\n    ('dxt', Variable(\n        'Zonal T-grid spacing', XT, 'm',\n        'Zonal (x) spacing of T-grid point',\n        output=True, time_dependent=False\n    )),\n    ('dxu', Variable(\n        'Zonal U-grid spacing', XU, 'm',\n        'Zonal (x) spacing of U-grid point',\n        output=True, time_dependent=False\n    )),\n    ('dyt', Variable(\n        'Meridional T-grid spacing', YT, 'm',\n        'Meridional (y) spacing of T-grid point',\n        output=True, time_dependent=False\n    )),\n    ('dyu', Variable(\n        'Meridional U-grid spacing', YU, 'm',\n        'Meridional (y) spacing of U-grid point',\n        output=True, time_dependent=False\n    )),\n    ('zt', Variable(\n        'Vertical coordinate (T)', ZT, 'm', 'Vertical coordinate',\n        output=True, time_dependent=False, extra_attributes={'positive': 'up'}\n    )),\n    ('zw', Variable(\n        'Vertical coordinate (W)', ZW, 'm', 'Vertical coordinate', output=True,\n        time_dependent=False, extra_attributes={'positive': 'up'}\n    )),\n    ('dzt', Variable(\n        'Vertical spacing (T)', ZT, 'm', 'Vertical spacing', output=True, time_dependent=False\n    )),\n    ('dzw', Variable(\n        'Vertical spacing (W)', ZW, 'm', 'Vertical spacing', output=True, time_dependent=False\n    )),\n    ('cost', Variable(\n        'Metric factor (T)', YT, '1', 'Metric factor for spherical coordinates',\n        time_dependent=False\n    )),\n    ('cosu', Variable(\n        'Metric factor (U)', YU, '1', 'Metric factor for spherical coordinates',\n        time_dependent=False\n    )),\n    ('tantr', Variable(\n        'Metric factor', YT, '1', 'Metric factor for spherical coordinates',\n        time_dependent=False\n    )),\n    ('coriolis_t', Variable(\n        'Coriolis frequency', T_HOR, '1/s',\n        'Coriolis frequency at T grid point', time_dependent=False\n    )),\n    ('coriolis_h', Variable(\n        'Horizontal Coriolis frequency', T_HOR, '1/s',\n        'Horizontal Coriolis frequency at T grid point', time_dependent=False\n    )),\n\n    ('kbot', Variable(\n        'Index of deepest cell', T_HOR, '',\n        'Index of the deepest grid cell (counting from 1, 0 means all land)',\n        dtype='int', time_dependent=False\n    )),\n    ('ht', Variable(\n        'Total depth (T)', T_HOR, 'm', 'Total depth of the water column', output=True,\n        time_dependent=False\n    )),\n    ('hu', Variable(\n        'Total depth (U)', U_HOR, 'm', 'Total depth of the water column', output=True,\n        time_dependent=False\n    )),\n    ('hv', Variable(\n        'Total depth (V)', V_HOR, 'm', 'Total depth of the water column', output=True,\n        time_dependent=False\n    )),\n    ('hur', Variable(\n        'Total depth (U), masked', U_HOR, 'm',\n        'Total depth of the water column (masked)', time_dependent=False\n    )),\n    ('hvr', Variable(\n        'Total depth (V), masked', V_HOR, 'm',\n        'Total depth of the water column (masked)', time_dependent=False\n    )),\n    ('beta', Variable(\n        'Change of Coriolis freq.', T_HOR, '1/(ms)',\n        'Change of Coriolis frequency with latitude', output=True, time_dependent=False\n    )),\n    ('area_t', Variable(\n        'Area of T-box', T_HOR, 'm^2', 'Area of T-box', output=True, time_dependent=False\n    )),\n    ('area_u', Variable(\n        'Area of U-box', U_HOR, 'm^2', 'Area of U-box', output=True, time_dependent=False\n    )),\n    ('area_v', Variable(\n        'Area of V-box', V_HOR, 'm^2', 'Area of V-box', output=True, time_dependent=False\n    )),\n\n    ('maskT', Variable(\n        'Mask for tracer points', T_GRID, '',\n        'Mask in physical space for tracer points', dtype='int8', time_dependent=False\n    )),\n    ('maskU', Variable(\n        'Mask for U points', U_GRID, '',\n        'Mask in physical space for U points', dtype='int8', time_dependent=False\n    )),\n    ('maskV', Variable(\n        'Mask for V points', V_GRID, '',\n        'Mask in physical space for V points', dtype='int8', time_dependent=False\n    )),\n    ('maskW', Variable(\n        'Mask for W points', W_GRID, '',\n        'Mask in physical space for W points', dtype='int8', time_dependent=False\n    )),\n    ('maskZ', Variable(\n        'Mask for Zeta points', ZETA_GRID, '',\n        'Mask in physical space for Zeta points', dtype='int8', time_dependent=False\n    )),\n\n    ('rho', Variable(\n        'Density', T_GRID + TIMESTEPS, 'kg/m^3',\n        'In-situ density anomaly, relative to the surface mean value of 1024 kg/m^3',\n        output=True, write_to_restart=True\n    )),\n\n    ('prho', Variable(\n        'Potential density', T_GRID, 'kg/m^3',\n        'Potential density anomaly, relative to the surface mean value of 1024 kg/m^3 '\n        '(identical to in-situ density anomaly for equation of state type 1, 2, and 4)',\n        output=True\n    )),\n\n    ('int_drhodT', Variable(\n        'Der. of dyn. enthalpy by temperature', T_GRID + TIMESTEPS, '?',\n        'Partial derivative of dynamic enthalpy by temperature', output=True,\n        write_to_restart=True\n    )),\n    ('int_drhodS', Variable(\n        'Der. of dyn. enthalpy by salinity', T_GRID + TIMESTEPS, '?',\n        'Partial derivative of dynamic enthalpy by salinity', output=True,\n        write_to_restart=True\n    )),\n    ('Nsqr', Variable(\n        'Square of stability frequency', W_GRID + TIMESTEPS, '1/s^2',\n        'Square of stability frequency', output=True, write_to_restart=True\n    )),\n    ('Hd', Variable(\n        'Dynamic enthalpy', T_GRID + TIMESTEPS, 'm^2/s^2', 'Dynamic enthalpy',\n        output=True, write_to_restart=True\n    )),\n    ('dHd', Variable(\n        'Change of dyn. enth. by adv.', T_GRID + TIMESTEPS, 'm^2/s^3',\n        'Change of dynamic enthalpy due to advection', write_to_restart=True\n    )),\n\n    ('temp', Variable(\n        'Temperature', T_GRID + TIMESTEPS, 'deg C',\n        'Conservative temperature', output=True, write_to_restart=True\n    )),\n    ('dtemp', Variable(\n        'Temperature tendency', T_GRID + TIMESTEPS, 'deg C/s',\n        'Conservative temperature tendency', write_to_restart=True\n    )),\n    ('salt', Variable(\n        'Salinity', T_GRID + TIMESTEPS, 'g/kg', 'Salinity', output=True,\n        write_to_restart=True\n    )),\n    ('dsalt', Variable(\n        'Salinity tendency', T_GRID + TIMESTEPS, 'g/(kg s)',\n        'Salinity tendency', write_to_restart=True\n    )),\n    ('dtemp_vmix', Variable(\n        'Change of temp. by vertical mixing', T_GRID, 'deg C/s',\n        'Change of temperature due to vertical mixing',\n    )),\n    ('dtemp_hmix', Variable(\n        'Change of temp. by horizontal mixing', T_GRID, 'deg C/s',\n        'Change of temperature due to horizontal mixing',\n    )),\n    ('dsalt_vmix', Variable(\n        'Change of sal. by vertical mixing', T_GRID, 'deg C/s',\n        'Change of salinity due to vertical mixing',\n    )),\n    ('dsalt_hmix', Variable(\n        'Change of sal. by horizontal mixing', T_GRID, 'deg C/s',\n        'Change of salinity due to horizontal mixing',\n    )),\n    ('dtemp_iso', Variable(\n        'Change of temp. by isop. mixing', T_GRID, 'deg C/s',\n        'Change of temperature due to isopycnal mixing plus skew mixing',\n    )),\n    ('dsalt_iso', Variable(\n        'Change of sal. by isop. mixing', T_GRID, 'deg C/s',\n        'Change of salinity due to isopycnal mixing plus skew mixing',\n\n    )),\n    ('forc_temp_surface', Variable(\n        'Surface temperature flux', T_HOR, 'm K/s', 'Surface temperature flux',\n        output=True\n    )),\n    ('forc_salt_surface', Variable(\n        'Surface salinity flux', T_HOR, 'm g/s kg', 'Surface salinity flux',\n        output=True\n    )),\n\n    ('flux_east', Variable(\n        'Multi-purpose flux', U_GRID, '?', 'Multi-purpose flux'\n    )),\n    ('flux_north', Variable(\n        'Multi-purpose flux', V_GRID, '?', 'Multi-purpose flux'\n    )),\n    ('flux_top', Variable(\n        'Multi-purpose flux', W_GRID, '?', 'Multi-purpose flux'\n    )),\n\n    ('u', Variable(\n        'Zonal velocity', U_GRID + TIMESTEPS, 'm/s', 'Zonal velocity',\n        output=True, write_to_restart=True\n    )),\n    ('v', Variable(\n        'Meridional velocity', V_GRID + TIMESTEPS, 'm/s', 'Meridional velocity',\n        output=True, write_to_restart=True\n    )),\n    ('w', Variable(\n        'Vertical velocity', W_GRID + TIMESTEPS, 'm/s', 'Vertical velocity',\n        output=True, write_to_restart=True\n    )),\n    ('du', Variable(\n        'Zonal velocity tendency', U_GRID + TIMESTEPS, 'm/s',\n        'Zonal velocity tendency', write_to_restart=True\n    )),\n    ('dv', Variable(\n        'Meridional velocity tendency', V_GRID + TIMESTEPS, 'm/s',\n        'Meridional velocity tendency', write_to_restart=True\n    )),\n    ('du_cor', Variable(\n        'Change of u by Coriolis force', U_GRID, 'm/s^2',\n        'Change of u due to Coriolis force'\n    )),\n    ('dv_cor', Variable(\n        'Change of v by Coriolis force', V_GRID, 'm/s^2',\n        'Change of v due to Coriolis force'\n    )),\n    ('du_mix', Variable(\n        'Change of u by vertical mixing', U_GRID, 'm/s^2',\n        'Change of u due to implicit vertical mixing'\n    )),\n    ('dv_mix', Variable(\n        'Change of v by vertical mixing', V_GRID, 'm/s^2',\n        'Change of v due to implicit vertical mixing'\n    )),\n    ('du_adv', Variable(\n        'Change of u by advection', U_GRID, 'm/s^2',\n        'Change of u due to advection'\n    )),\n    ('dv_adv', Variable(\n        'Change of v by advection', V_GRID, 'm/s^2',\n        'Change of v due to advection'\n    )),\n    ('p_hydro', Variable(\n        'Hydrostatic pressure', T_GRID, 'm^2/s^2', 'Hydrostatic pressure', output=True\n    )),\n    ('kappaM', Variable(\n        'Vertical viscosity', T_GRID, 'm^2/s', 'Vertical viscosity', output=True\n    )),\n    ('kappaH', Variable(\n        'Vertical diffusivity', W_GRID, 'm^2/s', 'Vertical diffusivity', output=True\n    )),\n    ('surface_taux', Variable(\n        'Surface wind stress', U_HOR, 'N/m^2', 'Zonal surface wind stress', output=True,\n    )),\n    ('surface_tauy', Variable(\n        'Surface wind stress', V_HOR, 'N/m^2', 'Meridional surface wind stress', output=True,\n    )),\n    ('forc_rho_surface', Variable(\n        'Surface density flux', T_HOR, '?', 'Surface potential density flux', output=True\n    )),\n\n    ('psi', Variable(\n        'Streamfunction', ZETA_HOR + TIMESTEPS, 'm^3/s', 'Barotropic streamfunction',\n        output=True, write_to_restart=True, mask=ZETA_HOR_ERODED\n    )),\n    ('dpsi', Variable(\n        'Streamfunction tendency', ZETA_HOR + TIMESTEPS, 'm^3/s^2',\n        'Streamfunction tendency', write_to_restart=True\n    )),\n    ('land_map', Variable(\n        'Land map', T_HOR, '', 'Land map'\n    )),\n    ('isle', Variable(\n        'Island number', ISLE, '', 'Island number', output=True\n    )),\n    ('psin', Variable(\n        'Boundary streamfunction', ZETA_HOR + ISLE, 'm^3/s',\n        'Boundary streamfunction', output=True, time_dependent=False,\n        mask=ZETA_HOR_ERODED\n    )),\n    ('dpsin', Variable(\n        'Boundary streamfunction factor', ISLE + TIMESTEPS, '?',\n        'Boundary streamfunction factor', write_to_restart=True\n    )),\n    ('line_psin', Variable(\n        'Boundary line integrals', ISLE + ISLE, '?',\n        'Boundary line integrals', time_dependent=False\n    )),\n    ('boundary_mask', Variable(\n        'Boundary mask', T_HOR + ISLE, '',\n        'Boundary mask', time_dependent=False\n    )),\n    ('line_dir_south_mask', Variable(\n        'Line integral mask', T_HOR + ISLE, '',\n        'Line integral mask', time_dependent=False\n    )),\n    ('line_dir_north_mask', Variable(\n        'Line integral mask', T_HOR + ISLE, '',\n        'Line integral mask', time_dependent=False\n    )),\n    ('line_dir_east_mask', Variable(\n        'Line integral mask', T_HOR + ISLE, '',\n        'Line integral mask', time_dependent=False\n    )),\n    ('line_dir_west_mask', Variable(\n        'Line integral mask', T_HOR + ISLE, '',\n        'Line integral mask', time_dependent=False\n    )),\n\n    ('K_gm', Variable(\n        'Skewness diffusivity', W_GRID, 'm^2/s',\n        'GM diffusivity, either constant or from EKE model'\n    )),\n    ('K_iso', Variable(\n        'Isopycnal diffusivity', W_GRID, 'm^2/s', 'Along-isopycnal diffusivity'\n    )),\n\n    ('K_diss_v', Variable(\n        'Dissipation of kinetic Energy', W_GRID, 'm^2/s^3',\n        'Kinetic energy dissipation by vertical, rayleigh and bottom friction',\n        write_to_restart=True\n    )),\n    ('K_diss_bot', Variable(\n        'Dissipation of kinetic Energy', W_GRID, 'm^2/s^3',\n        'Mean energy dissipation by bottom and rayleigh friction'\n    )),\n    ('K_diss_h', Variable(\n        'Dissipation of kinetic Energy', W_GRID, 'm^2/s^3',\n        'Kinetic energy dissipation by horizontal friction'\n    )),\n    ('K_diss_gm', Variable(\n        'Dissipation of mean energy', W_GRID, 'm^2/s^3',\n        'Mean energy dissipation by GM (TRM formalism only)'\n    )),\n    ('P_diss_v', Variable(\n        'Dissipation of potential Energy', W_GRID, 'm^2/s^3',\n        'Potential energy dissipation by vertical diffusion'\n    )),\n    ('P_diss_nonlin', Variable(\n        'Dissipation of potential Energy', W_GRID, 'm^2/s^3',\n        'Potential energy dissipation by nonlinear equation of state'\n    )),\n    ('P_diss_iso', Variable(\n        'Dissipation of potential Energy', W_GRID, 'm^2/s^3',\n        'Potential energy dissipation by isopycnal mixing'\n    )),\n    ('P_diss_skew', Variable(\n        'Dissipation of potential Energy', W_GRID, 'm^2/s^3',\n        'Potential energy dissipation by GM (w/o TRM)'\n    )),\n    ('P_diss_hmix', Variable(\n        'Dissipation of potential Energy', W_GRID, 'm^2/s^3',\n        'Potential energy dissipation by horizontal mixing'\n    )),\n    ('P_diss_adv', Variable(\n        'Dissipation of potential Energy', W_GRID, 'm^2/s^3',\n        'Potential energy dissipation by advection'\n    )),\n    ('P_diss_comp', Variable(\n        'Dissipation of potential Energy', W_GRID, 'm^2/s^3',\n        'Potential energy dissipation by compression'\n    )),\n    ('P_diss_sources', Variable(\n        'Dissipation of potential Energy', W_GRID, 'm^2/s^3',\n        'Potential energy dissipation by external sources (e.g. restoring zones)'\n    )),\n\n    ('u_wgrid', Variable(\n        'U on W grid', W_GRID, 'm/s', 'Zonal velocity interpolated to W grid points'\n    )),\n    ('v_wgrid', Variable(\n        'V on W grid', W_GRID, 'm/s', 'Meridional velocity interpolated to W grid points'\n    )),\n    ('w_wgrid', Variable(\n        'W on W grid', W_GRID, 'm/s', 'Vertical velocity interpolated to W grid points'\n    ))\n])\n\nCONDITIONAL_VARIABLES = OrderedDict([\n    ('coord_degree', OrderedDict([\n        ('xt', Variable(\n            'Zonal coordinate (T)', XT, 'degrees_east',\n            'Zonal (x) coordinate of T-grid point',\n            output=True, time_dependent=False\n        )),\n        ('xu', Variable(\n            'Zonal coordinate (U)', XU, 'degrees_east',\n            'Zonal (x) coordinate of U-grid point',\n            output=True, time_dependent=False\n        )),\n        ('yt', Variable(\n            'Meridional coordinate (T)', YT, 'degrees_north',\n            'Meridional (y) coordinate of T-grid point',\n            output=True, time_dependent=False\n        )),\n        ('yu', Variable(\n            'Meridional coordinate (U)', YU, 'degrees_north',\n            'Meridional (y) coordinate of U-grid point',\n            output=True, time_dependent=False\n        )),\n    ])),\n\n    ('not coord_degree', OrderedDict([\n        ('xt', Variable(\n            'Zonal coordinate (T)', XT, 'km',\n            'Zonal (x) coordinate of T-grid point',\n            output=True, scale=1e-3, time_dependent=False\n        )),\n        ('xu', Variable(\n            'Zonal coordinate (U)', XU, 'km',\n            'Zonal (x) coordinate of U-grid point',\n            output=True, scale=1e-3, time_dependent=False\n        )),\n        ('yt', Variable(\n            'Meridional coordinate (T)', YT, 'km',\n            'Meridional (y) coordinate of T-grid point',\n            output=True, scale=1e-3, time_dependent=False\n        )),\n        ('yu', Variable(\n            'Meridional coordinate (U)', YU, 'km',\n            'Meridional (y) coordinate of U-grid point',\n            output=True, scale=1e-3, time_dependent=False\n        )),\n    ])),\n\n    ('enable_tempsalt_sources', OrderedDict([\n        ('temp_source', Variable(\n            'Source of temperature', T_GRID, 'K/s',\n            'Non-conservative source of temperature', output=True\n        )),\n        ('salt_source', Variable(\n            'Source of salt', T_GRID, 'g/(kg s)',\n            'Non-conservative source of salt', output=True\n        )),\n    ])),\n\n    ('enable_momentum_sources', OrderedDict([\n        ('u_source', Variable(\n            'Source of zonal velocity', U_GRID, 'm/s^2 (?)',\n            'Non-conservative source of zonal velocity', output=True\n        )),\n        ('v_source', Variable(\n            'Source of meridional velocity', V_GRID, 'm/s^2 (?)',\n            'Non-conservative source of meridional velocity', output=True\n        )),\n    ])),\n\n    ('enable_neutral_diffusion', OrderedDict([\n        ('K_11', Variable('Isopycnal mixing coefficient', T_GRID, '?', 'Isopycnal mixing tensor component')),\n        ('K_13', Variable('Isopycnal mixing coefficient', T_GRID, '?', 'Isopycnal mixing tensor component')),\n        ('K_22', Variable('Isopycnal mixing coefficient', T_GRID, '?', 'Isopycnal mixing tensor component')),\n        ('K_23', Variable('Isopycnal mixing coefficient', T_GRID, '?', 'Isopycnal mixing tensor component')),\n        ('K_31', Variable('Isopycnal mixing coefficient', T_GRID, '?', 'Isopycnal mixing tensor component')),\n        ('K_32', Variable('Isopycnal mixing coefficient', T_GRID, '?', 'Isopycnal mixing tensor component')),\n        ('K_33', Variable('Isopycnal mixing coefficient', T_GRID, '?', 'Isopycnal mixing tensor component')),\n        ('Ai_ez', Variable('?', T_GRID + TENSOR_COMP, '?', '?')),\n        ('Ai_nz', Variable('?', T_GRID + TENSOR_COMP, '?', '?')),\n        ('Ai_bx', Variable('?', T_GRID + TENSOR_COMP, '?', '?')),\n        ('Ai_by', Variable('?', T_GRID + TENSOR_COMP, '?', '?')),\n    ])),\n    ('enable_skew_diffusion', OrderedDict([\n        ('B1_gm', Variable(\n            'Zonal component of GM streamfunction', V_GRID, 'm^2/s',\n            'Zonal component of GM streamfunction'\n        )),\n        ('B2_gm', Variable(\n            'Meridional component of GM streamfunction', U_GRID, 'm^2/s',\n            'Meridional component of GM streamfunction'\n        ))\n    ])),\n    ('enable_bottom_friction_var', OrderedDict([\n        ('r_bot_var_u', Variable(\n            'Bottom friction coeff.', U_HOR, '?', 'Zonal bottom friction coefficient'\n        )),\n        ('r_bot_var_v', Variable(\n            'Bottom friction coeff.', V_HOR, '?', 'Meridional bottom friction coefficient'\n        )),\n    ])),\n    ('enable_TEM_friction', OrderedDict([\n        ('kappa_gm', Variable('Vertical diffusivity', W_GRID, 'm^2/s', 'Vertical diffusivity')),\n    ])),\n    ('enable_tke', OrderedDict([\n        ('tke', Variable(\n            'Turbulent kinetic energy', W_GRID + TIMESTEPS, 'm^2/s^2',\n            'Turbulent kinetic energy', output=True, write_to_restart=True\n        )),\n        ('sqrttke', Variable(\n            'Square-root of TKE', W_GRID, 'm/s', 'Square-root of TKE'\n        )),\n        ('dtke', Variable(\n            'Turbulent kinetic energy tendency', W_GRID + TIMESTEPS, 'm^2/s^3',\n            'Turbulent kinetic energy tendency', write_to_restart=True\n        )),\n        ('Prandtlnumber', Variable('Prandtl number', W_GRID, '', 'Prandtl number')),\n        ('mxl', Variable('Mixing length', W_GRID, 'm', 'Mixing length')),\n        ('forc_tke_surface', Variable(\n            'TKE surface flux', T_HOR, 'm^3/s^3', 'TKE surface flux', output=True\n        )),\n        ('tke_diss', Variable(\n            'TKE dissipation', W_GRID, 'm^2/s^3', 'TKE dissipation'\n        )),\n        ('tke_surf_corr', Variable(\n            'Correction of TKE surface flux', T_HOR, 'm^3/s^3',\n            'Correction of TKE surface flux'\n        )),\n    ])),\n    ('enable_eke', OrderedDict([\n        ('eke', Variable(\n            'meso-scale energy', W_GRID + TIMESTEPS, 'm^2/s^2',\n            'meso-scale energy', output=True, write_to_restart=True\n        )),\n        ('deke', Variable(\n            'meso-scale energy tendency', W_GRID + TIMESTEPS, 'm^2/s^3',\n            'meso-scale energy tendency', write_to_restart=True\n        )),\n        ('sqrteke', Variable(\n            'square-root of eke', W_GRID, 'm/s', 'square-root of eke'\n        )),\n        ('L_rossby', Variable('Rossby radius', T_HOR, 'm', 'Rossby radius')),\n        ('L_rhines', Variable('Rhines scale', W_GRID, 'm', 'Rhines scale')),\n        ('eke_len', Variable('Eddy length scale', T_GRID, 'm', 'Eddy length scale')),\n        ('eke_diss_iw', Variable(\n            'Dissipation of EKE to IW', W_GRID, 'm^2/s^3',\n            'Dissipation of EKE to internal waves'\n        )),\n        ('eke_diss_tke', Variable(\n            'Dissipation of EKE to TKE', W_GRID, 'm^2/s^3',\n            'Dissipation of EKE to TKE'\n        )),\n        ('eke_bot_flux', Variable(\n            'Flux by bottom friction', T_HOR, 'm^3/s^3', 'Flux by bottom friction'\n        )),\n    ])),\n    ('enable_eke_leewave_dissipation', OrderedDict([\n        ('eke_topo_hrms', Variable(\n            '?', T_HOR, '?', '?'\n        )),\n        ('eke_topo_lam', Variable(\n            '?', T_HOR, '?', '?'\n        )),\n        ('hrms_k0', Variable(\n            '?', T_HOR, '?', '?'\n        )),\n        ('c_lee', Variable(\n            'Lee wave dissipation coefficient', T_HOR, '1/s',\n            'Lee wave dissipation coefficient'\n        )),\n        ('eke_lee_flux', Variable(\n            'Lee wave flux', T_HOR, 'm^3/s^3', 'Lee wave flux',\n        )),\n        ('c_Ri_diss', Variable(\n            'Interior dissipation coefficient', W_GRID, '1/s',\n            'Interior dissipation coefficient'\n        )),\n    ])),\n    ('enable_idemix', OrderedDict([\n        ('E_iw', Variable(\n            'Internal wave energy', W_GRID + TIMESTEPS, 'm^2/s^2',\n            'Internal wave energy', output=True, write_to_restart=True\n        )),\n        ('dE_iw', Variable(\n            'Internal wave energy tendency', W_GRID + TIMESTEPS, 'm^2/s^2',\n            'Internal wave energy tendency', write_to_restart=True\n        )),\n        ('c0', Variable(\n            'Vertical IW group velocity', W_GRID, 'm/s',\n            'Vertical internal wave group velocity'\n        )),\n        ('v0', Variable(\n            'Horizontal IW group velocity', W_GRID, 'm/s',\n            'Horizontal internal wave group velocity'\n        )),\n        ('alpha_c', Variable('?', W_GRID, '?', '?')),\n        ('iw_diss', Variable(\n            'IW dissipation', W_GRID, 'm^2/s^3', 'Internal wave dissipation'\n        )),\n        ('forc_iw_surface', Variable(\n            'IW surface forcing', T_HOR, 'm^3/s^3',\n            'Internal wave surface forcing', time_dependent=False, output=True\n        )),\n        ('forc_iw_bottom', Variable(\n            'IW bottom forcing', T_HOR, 'm^3/s^3',\n            'Internal wave bottom forcing', time_dependent=False, output=True\n        )),\n    ])),\n])\n\n\n@veros_method\ndef get_active_variables(vs, main_variables=None, conditional_variables=None):\n    variables = {}\n\n    if main_variables is not None:\n        for var_name, var in main_variables.items():\n            variables[var_name] = var\n\n    if conditional_variables is not None:\n        for condition, var_dict in conditional_variables.items():\n            if condition.startswith('not '):\n                eval_condition = not bool(getattr(vs, condition[4:]))\n            else:\n                eval_condition = bool(getattr(vs, condition))\n            if eval_condition:\n                for var_name, var in var_dict.items():\n                    variables[var_name] = var\n\n    return variables\n\n\n@veros_method\ndef get_standard_variables(vs):\n    return get_active_variables(\n        vs,\n        main_variables=MAIN_VARIABLES,\n        conditional_variables=CONDITIONAL_VARIABLES\n    )\n\n\n@veros_method(inline=True)\ndef allocate(vs, dimensions, dtype=None, include_ghosts=True, local=True, fill=0):\n    if dtype is None:\n        dtype = vs.default_float_type\n\n    shape = get_dimensions(vs, dimensions, include_ghosts=include_ghosts, local=local)\n    out = np.empty(shape, dtype=dtype)\n    out[...] = fill\n    return out\n"""
veros/veros.py,2,"b'\nimport abc\n\nfrom loguru import logger\n\nfrom veros import (\n    settings, diagnostics, time, handlers, logs, distributed, progress,\n    runtime_settings as rs, runtime_state as rst\n)\nfrom veros.state import VerosState\nfrom veros.plugins import load_plugin\nfrom veros.core import (\n    momentum, numerics, thermodynamics, eke, tke, idemix,\n    isoneutral, streamfunction, advection, utilities\n)\n\n\nclass VerosSetup(metaclass=abc.ABCMeta):\n    """"""Main class for Veros, used for building a model and running it.\n\n    Note:\n        This class is meant to be subclassed. Subclasses need to implement the\n        methods :meth:`set_parameter`, :meth:`set_topography`, :meth:`set_grid`,\n        :meth:`set_coriolis`, :meth:`set_initial_conditions`, :meth:`set_forcing`,\n        and :meth:`set_diagnostics`.\n\n    Arguments:\n        backend (:obj:`bool`, optional): Backend to use for array operations.\n            Possible values are ``numpy`` and ``bohrium``. Defaults to ``None``, which\n            tries to read the backend from the command line (set via a flag\n            ``-b``/``--backend``), and uses ``numpy`` if no command line argument is given.\n        loglevel (one of {debug, info, warning, error, critical}, optional): Verbosity\n            of the model. Tries to read value from command line if not given\n            (``-v``/``--loglevel``). Defaults to ``info``.\n\n    Example:\n        >>> import matplotlib.pyplot as plt\n        >>> from veros import VerosSetup\n        >>>\n        >>> class MyModel(VerosSetup):\n        >>>     ...\n        >>>\n        >>> simulation = MyModel(backend=\'bohrium\')\n        >>> simulation.run()\n        >>> plt.imshow(simulation.state.psi[..., 0])\n        >>> plt.show()\n\n    """"""\n    __veros_plugins__ = tuple()\n\n    def __init__(self, state=None, override=None, plugins=None):\n        self.override_settings = override or {}\n        logs.setup_logging(loglevel=rs.loglevel)\n\n        if plugins is not None:\n            self.__veros_plugins__ = tuple(plugins)\n\n        self._plugin_interfaces = tuple(load_plugin(p) for p in self.__veros_plugins__)\n\n        if state is None:\n            self.state = VerosState(use_plugins=self.__veros_plugins__)\n\n        this_plugins = set(p.module for p in self.state._plugin_interfaces)\n        state_plugins = set(p.module for p in self._plugin_interfaces)\n\n        if this_plugins != state_plugins:\n            raise ValueError(\n                \'VerosState was created with plugin modules {}, but this setup uses {}\'\n                .format(state_plugins, this_plugins)\n            )\n\n    @abc.abstractmethod\n    def set_parameter(self, vs):\n        """"""To be implemented by subclass.\n\n        First function to be called during setup.\n        Use this to modify the model settings.\n\n        Example:\n          >>> def set_parameter(self, vs):\n          >>>     vs.nx, vs.ny, vs.nz = (360, 120, 50)\n          >>>     vs.coord_degree = True\n          >>>     vs.enable_cyclic = True\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def set_initial_conditions(self, vs):\n        """"""To be implemented by subclass.\n\n        May be used to set initial conditions.\n\n        Example:\n          >>> @veros_method\n          >>> def set_initial_conditions(self, vs):\n          >>>     vs.u[:, :, :, vs.tau] = np.random.rand(vs.u.shape[:-1])\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def set_grid(self, vs):\n        """"""To be implemented by subclass.\n\n        Has to set the grid spacings :attr:`dxt`, :attr:`dyt`, and :attr:`dzt`,\n        along with the coordinates of the grid origin, :attr:`x_origin` and\n        :attr:`y_origin`.\n\n        Example:\n          >>> @veros_method\n          >>> def set_grid(self, vs):\n          >>>     vs.x_origin, vs.y_origin = 0, 0\n          >>>     vs.dxt[...] = [0.1, 0.05, 0.025, 0.025, 0.05, 0.1]\n          >>>     vs.dyt[...] = 1.\n          >>>     vs.dzt[...] = [10, 10, 20, 50, 100, 200]\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def set_coriolis(self, vs):\n        """"""To be implemented by subclass.\n\n        Has to set the Coriolis parameter :attr:`coriolis_t` at T grid cells.\n\n        Example:\n          >>> @veros_method\n          >>> def set_coriolis(self, vs):\n          >>>     vs.coriolis_t[:, :] = 2 * vs.omega * np.sin(vs.yt[np.newaxis, :] / 180. * vs.pi)\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def set_topography(self, vs):\n        """"""To be implemented by subclass.\n\n        Must specify the model topography by setting :attr:`kbot`.\n\n        Example:\n          >>> @veros_method\n          >>> def set_topography(self, vs):\n          >>>     vs.kbot[:, :] = 10\n          >>>     # add a rectangular island somewhere inside the domain\n          >>>     vs.kbot[10:20, 10:20] = 0\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def set_forcing(self, vs):\n        """"""To be implemented by subclass.\n\n        Called before every time step to update the external forcing, e.g. through\n        :attr:`forc_temp_surface`, :attr:`forc_salt_surface`, :attr:`surface_taux`,\n        :attr:`surface_tauy`, :attr:`forc_tke_surface`, :attr:`temp_source`, or\n        :attr:`salt_source`. Use this method to implement time-dependent forcing.\n\n        Example:\n          >>> @veros_method\n          >>> def set_forcing(self, vs):\n          >>>     current_month = (vs.time / (31 * 24 * 60 * 60)) % 12\n          >>>     vs.surface_taux[:, :] = vs._windstress_data[:, :, current_month]\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def set_diagnostics(self, vs):\n        """"""To be implemented by subclass.\n\n        Called before setting up the :ref:`diagnostics <diagnostics>`. Use this method e.g. to\n        mark additional :ref:`variables <variables>` for output.\n\n        Example:\n          >>> @veros_method\n          >>> def set_diagnostics(self, vs):\n          >>>     vs.diagnostics[\'snapshot\'].output_vars += [\'drho\', \'dsalt\', \'dtemp\']\n        """"""\n        pass\n\n    @abc.abstractmethod\n    def after_timestep(self, vs):\n        """"""Called at the end of each time step. Can be used to define custom, setup-specific\n        events.\n        """"""\n        pass\n\n    def setup(self):\n        vs = self.state\n\n        with vs.timers[\'setup\']:\n            logger.info(\'Setting up everything\')\n\n            self.set_parameter(vs)\n\n            for setting, value in self.override_settings.items():\n                setattr(vs, setting, value)\n\n            settings.check_setting_conflicts(vs)\n            distributed.validate_decomposition(vs)\n            vs.allocate_variables()\n\n            self.set_grid(vs)\n            numerics.calc_grid(vs)\n\n            self.set_coriolis(vs)\n            numerics.calc_beta(vs)\n\n            self.set_topography(vs)\n            numerics.calc_topo(vs)\n\n            self.set_initial_conditions(vs)\n            numerics.calc_initial_conditions(vs)\n            streamfunction.streamfunction_init(vs)\n            eke.init_eke(vs)\n\n            for plugin in self._plugin_interfaces:\n                plugin.setup_entrypoint(vs)\n\n            vs.create_diagnostics()\n            self.set_diagnostics(vs)\n            diagnostics.initialize(vs)\n            diagnostics.read_restart(vs)\n\n            self.set_forcing(vs)\n            isoneutral.check_isoneutral_slope_crit(vs)\n\n    def run(self, show_progress_bar=None):\n        """"""Main routine of the simulation.\n\n        Note:\n            Make sure to call :meth:`setup` prior to this function.\n\n        Arguments:\n            show_progress_bar (:obj:`bool`, optional): Whether to show fancy progress bar via tqdm.\n                By default, only show if stdout is a terminal and Veros is running on a single process.\n\n        """"""\n        vs = self.state\n\n        logger.info(\'\\nStarting integration for {0[0]:.1f} {0[1]}\'.format(time.format_time(vs.runlen)))\n\n        start_time, start_iteration = vs.time, vs.itt\n        profiler = None\n\n        pbar = progress.get_progress_bar(vs, use_tqdm=show_progress_bar)\n\n        with handlers.signals_to_exception():\n            try:\n                with pbar:\n                    while vs.time - start_time < vs.runlen:\n                        with vs.timers[\'diagnostics\']:\n                            diagnostics.write_restart(vs)\n\n                        if vs.itt - start_iteration == 3 and rs.profile_mode and rst.proc_rank == 0:\n                            # when using bohrium, most kernels should be pre-compiled by now\n                            profiler = diagnostics.start_profiler()\n\n                        with vs.timers[\'main\']:\n                            self.set_forcing(vs)\n\n                            if vs.enable_idemix:\n                                idemix.set_idemix_parameter(vs)\n\n                            with vs.timers[\'eke\']:\n                                eke.set_eke_diffusivities(vs)\n\n                            with vs.timers[\'tke\']:\n                                tke.set_tke_diffusivities(vs)\n\n                            with vs.timers[\'momentum\']:\n                                momentum.momentum(vs)\n\n                            with vs.timers[\'temperature\']:\n                                thermodynamics.thermodynamics(vs)\n\n                            if vs.enable_eke or vs.enable_tke or vs.enable_idemix:\n                                advection.calculate_velocity_on_wgrid(vs)\n\n                            with vs.timers[\'eke\']:\n                                if vs.enable_eke:\n                                    eke.integrate_eke(vs)\n\n                            with vs.timers[\'idemix\']:\n                                if vs.enable_idemix:\n                                    idemix.integrate_idemix(vs)\n\n                            with vs.timers[\'tke\']:\n                                if vs.enable_tke:\n                                    tke.integrate_tke(vs)\n\n                            utilities.enforce_boundaries(vs, vs.u[:, :, :, vs.taup1])\n                            utilities.enforce_boundaries(vs, vs.v[:, :, :, vs.taup1])\n                            if vs.enable_tke:\n                                utilities.enforce_boundaries(vs, vs.tke[:, :, :, vs.taup1])\n                            if vs.enable_eke:\n                                utilities.enforce_boundaries(vs, vs.eke[:, :, :, vs.taup1])\n                            if vs.enable_idemix:\n                                utilities.enforce_boundaries(vs, vs.E_iw[:, :, :, vs.taup1])\n\n                            momentum.vertical_velocity(vs)\n\n                        with vs.timers[\'plugins\']:\n                            for plugin in self._plugin_interfaces:\n                                with vs.timers[plugin.name]:\n                                    plugin.run_entrypoint(vs)\n\n                        vs.itt += 1\n                        vs.time += vs.dt_tracer\n                        pbar.advance_time(vs.dt_tracer)\n\n                        self.after_timestep(vs)\n\n                        with vs.timers[\'diagnostics\']:\n                            if not diagnostics.sanity_check(vs):\n                                raise RuntimeError(\'solution diverged at iteration {}\'.format(vs.itt))\n\n                            if vs.enable_neutral_diffusion and vs.enable_skew_diffusion:\n                                isoneutral.isoneutral_diag_streamfunction(vs)\n\n                            diagnostics.diagnose(vs)\n                            diagnostics.output(vs)\n\n                        # NOTE: benchmarks parse this, do not change / remove\n                        logger.debug(\' Time step took {:.2f}s\', vs.timers[\'main\'].get_last_time())\n\n                        # permutate time indices\n                        vs.taum1, vs.tau, vs.taup1 = vs.tau, vs.taup1, vs.taum1\n\n            except:\n                logger.critical(\'Stopping integration at iteration {}\', vs.itt)\n                raise\n\n            else:\n                logger.success(\'Integration done\\n\')\n\n            finally:\n                diagnostics.write_restart(vs, force=True)\n\n                timing_summary = [\n                    \'\',\n                    \'Timing summary:\',\n                    \' setup time               = {:.2f}s\'.format(vs.timers[\'setup\'].get_time()),\n                    \' main loop time           = {:.2f}s\'.format(vs.timers[\'main\'].get_time()),\n                    \'   momentum               = {:.2f}s\'.format(vs.timers[\'momentum\'].get_time()),\n                    \'     pressure             = {:.2f}s\'.format(vs.timers[\'pressure\'].get_time()),\n                    \'     friction             = {:.2f}s\'.format(vs.timers[\'friction\'].get_time()),\n                    \'   thermodynamics         = {:.2f}s\'.format(vs.timers[\'temperature\'].get_time()),\n                    \'     lateral mixing       = {:.2f}s\'.format(vs.timers[\'isoneutral\'].get_time()),\n                    \'     vertical mixing      = {:.2f}s\'.format(vs.timers[\'vmix\'].get_time()),\n                    \'     equation of state    = {:.2f}s\'.format(vs.timers[\'eq_of_state\'].get_time()),\n                    \'   EKE                    = {:.2f}s\'.format(vs.timers[\'eke\'].get_time()),\n                    \'   IDEMIX                 = {:.2f}s\'.format(vs.timers[\'idemix\'].get_time()),\n                    \'   TKE                    = {:.2f}s\'.format(vs.timers[\'tke\'].get_time()),\n                    \' diagnostics and I/O      = {:.2f}s\'.format(vs.timers[\'diagnostics\'].get_time()),\n                    \' plugins                  = {:.2f}s\'.format(vs.timers[\'plugins\'].get_time()),\n                ]\n\n                timing_summary.extend([\n                    \'   {:<22} = {:.2f}s\'.format(plugin.name, vs.timers[plugin.name].get_time())\n                    for plugin in vs._plugin_interfaces\n                ])\n\n                logger.debug(\'\\n\'.join(timing_summary))\n\n                if profiler is not None:\n                    diagnostics.stop_profiler(profiler)\n'"
veros/veros_legacy.py,0,"b'import importlib.util\n\nfrom loguru import logger\n\nfrom . import veros, settings, runtime_settings, runtime_state\n\n\ndef _load_fortran_module(module, path):\n    spec = importlib.util.spec_from_file_location(module, path)\n    mod = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(mod)\n    return mod\n\n\nclass LowercaseAttributeWrapper:\n    """"""\n    A simple wrapper class that converts attributes to lower case (needed for Fortran interface)\n    """"""\n\n    def __init__(self, wrapped_object):\n        object.__setattr__(self, \'_w\', wrapped_object)\n\n    def __getattr__(self, key):\n        if key == \'_w\':\n            return object.__getattribute__(self, \'_w\')\n        return getattr(object.__getattribute__(self, \'_w\'), key.lower())\n\n    def __setattr__(self, key, value):\n        setattr(self._w, key.lower(), value)\n\n\nclass VerosLegacy(veros.VerosSetup):\n    """"""\n    An alternative Veros class that supports the pyOM Fortran interface as backend\n\n    .. warning::\n\n       Do not use this class for new setups!\n\n    """"""\n    def __init__(self, fortran=None, *args, **kwargs):\n        """"""\n        To use the pyOM2 legacy interface point the fortran argument to the Veros fortran library:\n\n        > simulation = GlobalOneDegreeSetup(fortran=\'pyOM_code.so\')\n\n        """"""\n        super(VerosLegacy, self).__init__(*args, **kwargs)\n\n        if fortran:\n            self.legacy_mode = True\n            try:\n                self.fortran = LowercaseAttributeWrapper(_load_fortran_module(\'pyOM_code\', fortran))\n                self.use_mpi = False\n            except ImportError:\n                self.fortran = LowercaseAttributeWrapper(_load_fortran_module(\'pyOM_code_MPI\', fortran))\n                self.use_mpi = True\n                from mpi4py import MPI\n                self.mpi_comm = MPI.COMM_WORLD\n            self.main_module = LowercaseAttributeWrapper(self.fortran.main_module)\n            self.isoneutral_module = LowercaseAttributeWrapper(self.fortran.isoneutral_module)\n            self.idemix_module = LowercaseAttributeWrapper(self.fortran.idemix_module)\n            self.tke_module = LowercaseAttributeWrapper(self.fortran.tke_module)\n            self.eke_module = LowercaseAttributeWrapper(self.fortran.eke_module)\n        else:\n            self.legacy_mode = False\n            self.use_mpi = False\n            self.fortran = self\n            self.main_module = self.state\n            self.isoneutral_module = self.state\n            self.idemix_module = self.state\n            self.tke_module = self.state\n            self.eke_module = self.state\n        self.modules = (self.main_module, self.isoneutral_module, self.idemix_module,\n                        self.tke_module, self.eke_module)\n\n        if self.use_mpi and self.mpi_comm.Get_rank() != 0:\n            kwargs[\'loglevel\'] = \'critical\'\n\n    def set_legacy_parameter(self):\n        m = self.fortran.main_module\n        m.n_pes_i, m.n_pes_j = runtime_settings.num_proc\n\n        # define processor boundary idx (1-based)\n        ipx, ipy = runtime_state.proc_idx\n        m.is_pe = (m.nx // m.n_pes_i) * ipx + 1\n        m.ie_pe = (m.nx // m.n_pes_i) * (ipx + 1)\n        m.js_pe = (m.ny // m.n_pes_j) * ipy + 1\n        m.je_pe = (m.ny // m.n_pes_j) * (ipy + 1)\n\n        self.get_tau = lambda: m.tau - 1 if self.legacy_mode else m.tau\n\n        # force settings that are not supported by Veros\n        idm = self.fortran.idemix_module\n        m.enable_streamfunction = True\n        m.enable_hydrostatic = True\n        idm.enable_idemix_m2 = False\n        idm.enable_idemix_niw = False\n\n    def _set_commandline_settings(self):\n        for key, val in self.override_settings.items():\n            for m in self.modules:\n                if hasattr(m, key):\n                    setattr(m, key, settings.SETTINGS[key].type(val))\n\n    def setup(self, *args, **kwargs):\n        vs = self.state\n        with vs.timers[\'setup\']:\n            if self.legacy_mode:\n                if self.use_mpi:\n                    self.fortran.my_mpi_init(self.mpi_comm.py2f())\n                else:\n                    self.fortran.my_mpi_init(0)\n                self.set_parameter(vs)\n                self._set_commandline_settings()\n                self.set_legacy_parameter()\n                self.fortran.pe_decomposition()\n                self.fortran.allocate_main_module()\n                self.fortran.allocate_isoneutral_module()\n                self.fortran.allocate_tke_module()\n                self.fortran.allocate_eke_module()\n                self.fortran.allocate_idemix_module()\n                self.set_grid(vs)\n                self.fortran.calc_grid()\n                self.set_coriolis(vs)\n                self.fortran.calc_beta()\n                self.set_topography(vs)\n                self.fortran.calc_topo()\n                self.fortran.calc_spectral_topo()\n                self.set_initial_conditions(vs)\n                self.fortran.calc_initial_conditions()\n                self.fortran.streamfunction_init()\n                self.set_diagnostics(vs)\n                self.set_forcing(vs)\n                self.fortran.check_isoneutral_slope_crit()\n            else:\n                # self.set_parameter() is called twice, but that shouldn\'t matter\n                self.set_parameter(vs)\n                self._set_commandline_settings()\n                self.set_legacy_parameter()\n                super(VerosLegacy, self).setup(*args, **kwargs)\n\n                diag_legacy_settings = (\n                    (vs.diagnostics[\'cfl_monitor\'], \'output_frequency\', \'ts_monint\'),\n                    (vs.diagnostics[\'tracer_monitor\'], \'output_frequency\', \'trac_cont_int\'),\n                    (vs.diagnostics[\'snapshot\'], \'output_frequency\', \'snapint\'),\n                    (vs.diagnostics[\'averages\'], \'output_frequency\', \'aveint\'),\n                    (vs.diagnostics[\'averages\'], \'sampling_frequency\', \'avefreq\'),\n                    (vs.diagnostics[\'overturning\'], \'output_frequency\', \'overint\'),\n                    (vs.diagnostics[\'overturning\'], \'sampling_frequency\', \'overfreq\'),\n                    (vs.diagnostics[\'energy\'], \'output_frequency\', \'energint\'),\n                    (vs.diagnostics[\'energy\'], \'sampling_frequency\', \'energfreq\'),\n                )\n\n                for diag, param, attr in diag_legacy_settings:\n                    if hasattr(vs, attr):\n                        setattr(diag, param, getattr(vs, attr))\n\n    def run(self, **kwargs):\n        if not self.legacy_mode:\n            return super(VerosLegacy, self).run(**kwargs)\n\n        vs = self.state\n        f = self.fortran\n        m = self.main_module\n        idm = self.idemix_module\n        ekm = self.eke_module\n        tkm = self.tke_module\n\n        logger.info(\'Starting integration for {:.2e}s\'.format(float(m.runlen)))\n\n        while vs.time < m.runlen:\n            logger.info(\'Current iteration: {}\'.format(m.itt))\n\n            with vs.timers[\'main\']:\n                self.set_forcing(vs)\n\n                if idm.enable_idemix:\n                    f.set_idemix_parameter()\n\n                f.set_eke_diffusivities()\n                f.set_tke_diffusivities()\n\n                with vs.timers[\'momentum\']:\n                    f.momentum()\n\n                with vs.timers[\'temperature\']:\n                    f.thermodynamics()\n\n                if ekm.enable_eke or tkm.enable_tke or idm.enable_idemix:\n                    f.calculate_velocity_on_wgrid()\n\n                with vs.timers[\'eke\']:\n                    if ekm.enable_eke:\n                        f.integrate_eke()\n\n                with vs.timers[\'idemix\']:\n                    if idm.enable_idemix:\n                        f.integrate_idemix()\n\n                with vs.timers[\'tke\']:\n                    if tkm.enable_tke:\n                        f.integrate_tke()\n\n                """"""\n                Main boundary exchange\n                for density, temp and salt this is done in integrate_tempsalt.f90\n                """"""\n                f.border_exchg_xyz(m.is_pe - m.onx, m.ie_pe + m.onx, m.js_pe -\n                                   m.onx, m.je_pe + m.onx, m.u[:, :, :, m.taup1 - 1], m.nz)\n                f.setcyclic_xyz(m.is_pe - m.onx, m.ie_pe + m.onx, m.js_pe - m.onx,\n                                m.je_pe + m.onx, m.u[:, :, :, m.taup1 - 1], m.nz)\n                f.border_exchg_xyz(m.is_pe - m.onx, m.ie_pe + m.onx, m.js_pe -\n                                   m.onx, m.je_pe + m.onx, m.v[:, :, :, m.taup1 - 1], m.nz)\n                f.setcyclic_xyz(m.is_pe - m.onx, m.ie_pe + m.onx, m.js_pe - m.onx,\n                                m.je_pe + m.onx, m.v[:, :, :, m.taup1 - 1], m.nz)\n\n                if tkm.enable_tke:\n                    f.border_exchg_xyz(m.is_pe - m.onx, m.ie_pe + m.onx, m.js_pe -\n                                       m.onx, m.je_pe + m.onx, tkm.tke[:, :, :, m.taup1 - 1], m.nz)\n                    f.setcyclic_xyz(m.is_pe - m.onx, m.ie_pe + m.onx, m.js_pe - m.onx,\n                                    m.je_pe + m.onx, tkm.tke[:, :, :, m.taup1 - 1], m.nz)\n                if ekm.enable_eke:\n                    f.border_exchg_xyz(m.is_pe - m.onx, m.ie_pe + m.onx, m.js_pe -\n                                       m.onx, m.je_pe + m.onx, ekm.eke[:, :, :, m.taup1 - 1], m.nz)\n                    f.setcyclic_xyz(m.is_pe - m.onx, m.ie_pe + m.onx, m.js_pe - m.onx,\n                                    m.je_pe + m.onx, ekm.eke[:, :, :, m.taup1 - 1], m.nz)\n                if idm.enable_idemix:\n                    f.border_exchg_xyz(m.is_pe - m.onx, m.ie_pe + m.onx, m.js_pe -\n                                       m.onx, m.je_pe + m.onx, idm.e_iw[:, :, :, m.taup1 - 1], m.nz)\n                    f.setcyclic_xyz(m.is_pe - m.onx, m.ie_pe + m.onx, m.js_pe - m.onx,\n                                    m.je_pe + m.onx, idm.e_iw[:, :, :, m.taup1 - 1], m.nz)\n\n                # diagnose vertical velocity at taup1\n                f.vertical_velocity()\n\n                # diagnose isoneutral streamfunction regardless of output settings\n                f.isoneutral_diag_streamfunction()\n\n            # shift time\n            m.itt += 1\n            vs.time += m.dt_tracer\n\n            self.after_timestep(vs)\n\n            otaum1 = m.taum1 * 1\n            m.taum1 = m.tau\n            m.tau = m.taup1\n            m.taup1 = otaum1\n\n            # NOTE: benchmarks parse this, do not change / remove\n            logger.debug(\'Time step took {}s\', vs.timers[\'main\'].get_last_time())\n\n        logger.debug(\'Timing summary:\')\n        logger.debug(\' setup time summary       = {}s\', vs.timers[\'setup\'].get_time())\n        logger.debug(\' main loop time summary   = {}s\', vs.timers[\'main\'].get_time())\n        logger.debug(\'     momentum             = {}s\', vs.timers[\'momentum\'].get_time())\n        logger.debug(\'     thermodynamics       = {}s\', vs.timers[\'temperature\'].get_time())\n        logger.debug(\'     EKE                  = {}s\', vs.timers[\'eke\'].get_time())\n        logger.debug(\'     IDEMIX               = {}s\', vs.timers[\'idemix\'].get_time())\n        logger.debug(\'     TKE                  = {}s\', vs.timers[\'tke\'].get_time())\n'"
test/pyom_consistency/4deg_test.py,16,"b'\nimport pkg_resources\n\nimport numpy as np\nimport h5netcdf\n\nfrom test_base import VerosPyOMSystemTest, VerosLegacyDummy\nfrom veros import veros_method, tools\n\nDATA_FILES = tools.get_assets(\'global_4deg\', pkg_resources.resource_filename(\'veros\', \'setup/global_4deg/assets.yml\'))\n\n\nclass GlobalFourDegreeSetup(VerosLegacyDummy):\n    """""" global 4 deg model with 15 levels\n    """"""\n    def set_parameter(self, vs):\n        vs.identifier = \'4deg_test\'\n        vs.diskless_mode = True\n        vs.pyom_compatibility_mode = True\n\n        M = self.main_module\n\n        (M.nx, M.ny, M.nz) = (90, 40, 15)\n        M.dt_mom = 1800.0\n        M.dt_tracer = 86400.0\n        M.AB_eps = 0.1\n\n        M.coord_degree = True\n        M.enable_cyclic_x = True\n\n        M.congr_epsilon = 1e-8\n        M.congr_max_iterations = 20000\n\n        I = self.isoneutral_module\n        I.enable_neutral_diffusion = True\n        I.K_iso_0 = 1000.0\n        I.K_iso_steep = 1000.0\n        I.iso_dslope = 4. / 1000.0\n        I.iso_slopec = 1. / 1000.0\n        I.enable_skew_diffusion = True\n\n        M.enable_hor_friction = True\n        M.A_h = 1.75e6\n        M.enable_hor_friction_cos_scaling = True\n        M.hor_friction_cosPower = 1\n\n        M.enable_implicit_vert_friction = True\n        T = self.tke_module\n        T.enable_tke = True\n        T.c_k = 0.1\n        T.c_eps = 0.7\n        T.alpha_tke = 30.0\n        T.mxl_min = 1e-8\n        T.tke_mxl_choice = 2\n        T.enable_tke_superbee_advection = True\n\n        E = self.eke_module\n        E.enable_eke = True\n        E.eke_k_max = 1e4\n        E.eke_c_k = 0.4\n        E.eke_c_eps = 0.5\n        E.eke_cross = 2.\n        E.eke_crhin = 1.0\n        E.eke_lmin = 100.0\n        E.eke_int_diss0 = 5.78703703704e-07\n        E.kappa_EKE0 = 0.1\n        E.enable_eke_superbee_advection = True\n\n        I = self.idemix_module\n        I.enable_idemix = True\n        I.gamma = 1.57\n        I.mu0 = 1.33333333333\n        I.enable_idemix_hor_diffusion = True\n        I.enable_eke_diss_surfbot = True\n        I.eke_diss_surfbot_frac = 0.2 # fraction which goes into bottom\n        I.enable_idemix_superbee_advection = True\n        I.tau_v = 86400.\n        I.jstar = 10.\n\n        M.eq_of_state_type = 5\n\n    @veros_method\n    def _read_forcing(self, vs, var):\n        with h5netcdf.File(DATA_FILES[\'forcing\'], \'r\') as infile:\n            return np.array(infile.variables[var][...].T.astype(str(infile.variables[var].dtype)))\n\n    @veros_method\n    def set_grid(self, vs):\n\n        m = self.main_module\n        ddz = np.array([50., 70., 100., 140., 190., 240., 290., 340.,\n                        390., 440., 490., 540., 590., 640., 690.])\n        m.dzt[:] = ddz[::-1]\n        m.dxt[:] = 4.0\n        m.dyt[:] = 4.0\n        m.y_origin = -76.0\n        m.x_origin = 4.0\n\n    @veros_method\n    def set_coriolis(self, vs):\n        m = self.main_module\n        m.coriolis_t[...] = 2 * m.omega * np.sin(m.yt[np.newaxis, :] / 180. * m.pi)\n\n    @veros_method\n    def set_topography(self, vs):\n        m = self.main_module\n        bathymetry_data = self._read_forcing(vs, \'bathymetry\')\n        salt_data = self._read_forcing(vs, \'salinity\')[:, :, ::-1]\n        mask_salt = salt_data == 0.\n        m.kbot[2:-2, 2:-2] = 1 + np.sum(mask_salt.astype(np.int), axis=2)\n        mask_bathy = bathymetry_data == 0\n        m.kbot[2:-2, 2:-2][mask_bathy] = 0\n        m.kbot[m.kbot == m.nz] = 0\n\n    @veros_method\n    def set_initial_conditions(self, vs):\n        m = self.main_module\n\n        self.taux, self.tauy, self.qnec, self.qnet, self.sss_clim, self.sst_clim = (\n            np.zeros((m.nx + 4, m.ny + 4, 12)) for _ in range(6))\n\n        # initial conditions for T and S\n        temp_data = self._read_forcing(vs, \'temperature\')[:, :, ::-1]\n        m.temp[2:-2, 2:-2, :, :] = (temp_data[:, :, :, np.newaxis]\n                                    * m.maskT[2:-2, 2:-2, :, np.newaxis])\n\n        salt_data = self._read_forcing(vs, \'salinity\')[:, :, ::-1]\n        m.salt[2:-2, 2:-2, :, :] = (salt_data[..., np.newaxis]\n                                    * m.maskT[2:-2, 2:-2, :, np.newaxis])\n\n        # use Trenberth wind stress from MITgcm instead of ECMWF (also contained in ecmwf_4deg.cdf)\n        self.taux[2:-2, 2:-2, :] = self._read_forcing(vs, \'tau_x\') / m.rho_0\n        self.tauy[2:-2, 2:-2, :] = self._read_forcing(vs, \'tau_y\') / m.rho_0\n\n        # heat flux\n        with h5netcdf.File(DATA_FILES[\'ecmwf\'], \'r\') as ecmwf_data:\n            self.qnec[2:-2, 2:-2, :] = np.array(ecmwf_data.variables[\'Q3\'][...].astype(\'float64\')).T\n            self.qnec[self.qnec <= -1e10] = 0.0\n\n        q = self._read_forcing(vs, \'q_net\')\n        self.qnet[2:-2, 2:-2, :] = -q\n        self.qnet[self.qnet <= -1e10] = 0.0\n\n        fxa = np.sum(self.qnet[2:-2, 2:-2, :] * m.area_t[2:-2, 2:-2, np.newaxis])\n        fxb = 12. * np.sum(m.area_t[2:-2, 2:-2])\n\n        fxa = float(fxa / fxb)\n        try:\n            maskT = m.maskT[:, :, -1, np.newaxis].copy2numpy()\n        except AttributeError:\n            maskT = m.maskT[:, :, -1, np.newaxis]\n        self.qnet[...] = (self.qnet - fxa) * maskT\n\n        # SST and SSS\n        self.sst_clim[2:-2, 2:-2, :] = self._read_forcing(vs, \'sst\')\n        self.sss_clim[2:-2, 2:-2, :] = self._read_forcing(vs, \'sss\')\n\n        idm = self.idemix_module\n        if idm.enable_idemix:\n            idm.forc_iw_bottom[2:-2, 2:-2] = self._read_forcing(vs, \'tidal_energy\') / m.rho_0\n            idm.forc_iw_surface[2:-2, 2:-2] = self._read_forcing(vs, \'wind_energy\') / m.rho_0 * 0.2\n\n    @veros_method\n    def set_forcing(self, vs):\n        m = self.main_module\n\n        year_in_seconds = 360 * 86400.\n        (n1, f1), (n2, f2) = tools.get_periodic_interval(vs.time, year_in_seconds,\n                                                         year_in_seconds / 12., 12)\n\n        # wind stress\n        m.surface_taux[...] = (f1 * self.taux[:, :, n1] + f2 * self.taux[:, :, n2])\n        m.surface_tauy[...] = (f1 * self.tauy[:, :, n1] + f2 * self.tauy[:, :, n2])\n\n        # tke flux\n        t = self.tke_module\n        if t.enable_tke:\n            t.forc_tke_surface[1:-1, 1:-1] = np.sqrt((0.5 * (m.surface_taux[1:-1, 1:-1] \\\n                                                                + m.surface_taux[:-2, 1:-1]))**2\n                                                      + (0.5 * (m.surface_tauy[1:-1, 1:-1] \\\n                                                                + m.surface_tauy[1:-1, :-2]))**2)**(3. / 2.)\n        # heat flux : W/m^2 K kg/J m^3/kg = K m/s\n        cp_0 = 3991.86795711963\n        sst = f1 * self.sst_clim[:, :, n1] + f2 * self.sst_clim[:, :, n2]\n        qnec = f1 * self.qnec[:, :, n1] + f2 * self.qnec[:, :, n2]\n        qnet = f1 * self.qnet[:, :, n1] + f2 * self.qnet[:, :, n2]\n        m.forc_temp_surface[...] = (qnet + qnec * (sst - m.temp[:, :, -1, self.get_tau()])) \\\n                                    * m.maskT[:, :, -1] / cp_0 / m.rho_0\n\n        # salinity restoring\n        t_rest = 30 * 86400.0\n        sss = f1 * self.sss_clim[:, :, n1] + f2 * self.sss_clim[:, :, n2]\n        m.forc_salt_surface[:] = 1. / t_rest * \\\n            (sss - m.salt[:, :, -1, self.get_tau()]) * m.maskT[:, :, -1] * m.dzt[-1]\n\n        # apply simple ice mask\n        mask = np.logical_and(m.temp[:, :, -1, self.get_tau()] * m.maskT[:, :, -1] < -1.8,\n                              m.forc_temp_surface < 0.)\n        m.forc_temp_surface[mask] = 0.0\n        m.forc_salt_surface[mask] = 0.0\n\n        if m.enable_tempsalt_sources:\n            m.temp_source[:] = m.maskT * self.rest_tscl * \\\n                (f1 * self.t_star[:, :, :, n1] + f2 * self.t_star[:, :, :, n2] \\\n                - m.temp[:, :, :, self.get_tau()])\n            m.salt_source[:] = self.maskT * self.rest_tscl * \\\n                (f1 * self.s_star[:, :, :, n1] + f2 * self.s_star[:, :, :, n2] \\\n                - m.salt[:, :, :, self.get_tau()])\n\n    def set_diagnostics(self, vs):\n        pass\n\n    def after_timestep(self, vs):\n        pass\n\n\nclass FourDegreeTest(VerosPyOMSystemTest):\n    Testclass = GlobalFourDegreeSetup\n    timesteps = 100\n\n    def test_passed(self):\n        differing_scalars = self.check_scalar_objects()\n        differing_arrays = self.check_array_objects()\n\n        if differing_scalars or differing_arrays:\n            print(\'The following attributes do not match between old and new veros:\')\n            for s, (v1, v2) in differing_scalars.items():\n                print(\'{}, {}, {}\'.format(s, v1, v2))\n            for a, (v1, v2) in differing_arrays.items():\n                if a in (\'Ai_ez\', \'Ai_nz\', \'Ai_bx\', \'Ai_by\'):\n                    # usually very small differences being amplified\n                    continue\n                self.check_variable(a, atol=1e-4, data=(v1, v2))\n\n\ndef test_4deg(pyom2_lib, backend):\n    FourDegreeTest(fortran=pyom2_lib, backend=backend).run()\n'"
test/pyom_consistency/acc2_no_energy_conservation_test.py,0,"b""from test_base import VerosPyOMSystemTest\nfrom acc2_test import ACC2\n\n\nclass ACC2NoEnergyConservationTest(VerosPyOMSystemTest):\n    Testclass = ACC2\n    timesteps = 5\n    extra_settings = {'enable_conserve_energy': False}\n\n    def test_passed(self):\n        differing_scalars = self.check_scalar_objects()\n        differing_arrays = self.check_array_objects()\n\n        if differing_scalars or differing_arrays:\n            print('The following attributes do not match between old and new veros:')\n            for s, (v1, v2) in differing_scalars.items():\n                print('{}, {}, {}'.format(s, v1, v2))\n            for a, (v1, v2) in differing_arrays.items():\n                if 'salt' in a:\n                    # salt isn't used by this example\n                    continue\n                self.check_variable(a, atol=1e-6, data=(v1, v2))\n\n\ndef test_acc2_no_conservation(pyom2_lib, backend):\n    ACC2NoEnergyConservationTest(fortran=pyom2_lib, backend=backend).run()\n"""
test/pyom_consistency/acc2_test.py,7,"b'import numpy as np\n\nfrom test_base import VerosPyOMSystemTest, VerosLegacyDummy\nfrom veros import veros_method\n\nyt_start = -39.0\nyt_end = 43\nyu_start = -40.0\nyu_end = 42\n\n\nclass ACC2(VerosLegacyDummy):\n    """"""\n    A simple global model with a Southern Ocean and Atlantic part\n    """"""\n    @veros_method\n    def set_parameter(self, vs):\n        vs.identifier = \'acc2_test\'\n        vs.diskless_mode = True\n        vs.pyom_compatibility_mode = True\n\n        m = self.main_module\n\n        (m.nx, m.ny, m.nz) = (30, 42, 15)\n        m.dt_mom = 4800\n        m.dt_tracer = 86400 / 2.\n        m.runlen = 86400 * 365\n\n        m.coord_degree = 1\n        m.enable_cyclic_x = 1\n\n        m.congr_epsilon = 1e-12\n        m.congr_max_iterations = 5000\n\n        m.enable_diag_snapshots = True\n        m.snapint = 86400 * 10\n        m.enable_diag_averages = True\n        m.aveint = 365 * 86400.\n        m.avefreq = m.dt_tracer * 10\n        m.enable_diag_overturning = True\n        m.overint = 365 * 86400. / 48.\n        m.overfreq = m.dt_tracer * 10\n        m.enable_diag_ts_monitor = True\n        m.ts_monint = 365 * 86400. / 12.\n        m.enable_diag_energy = True\n        m.energint = 365 * 86400. / 48\n        m.energfreq = m.dt_tracer * 10\n\n        i = self.isoneutral_module\n        i.enable_neutral_diffusion = 1\n        i.K_iso_0 = 1000.0\n        i.K_iso_steep = 500.0\n        i.iso_dslope = 0.005\n        i.iso_slopec = 0.01\n        i.enable_skew_diffusion = 1\n\n        m.enable_hor_friction = 1\n        m.A_h = (2 * m.degtom)**3 * 2e-11\n        m.enable_hor_friction_cos_scaling = 1\n        m.hor_friction_cosPower = 1\n\n        m.enable_bottom_friction = 1\n        m.r_bot = 1e-5\n\n        m.enable_implicit_vert_friction = 1\n        t = self.tke_module\n        t.enable_tke = 1\n        t.c_k = 0.1\n        t.c_eps = 0.7\n        t.alpha_tke = 30.0\n        t.mxl_min = 1e-8\n        t.tke_mxl_choice = 2\n        # t.enable_tke_superbee_advection = 1\n\n        i.K_gm_0 = 1000.0\n        e = self.eke_module\n        e.enable_eke = 1\n        e.eke_k_max = 1e4\n        e.eke_c_k = 0.4\n        e.eke_c_eps = 0.5\n        e.eke_cross = 2.\n        e.eke_crhin = 1.0\n        e.eke_lmin = 100.0\n        e.enable_eke_superbee_advection = 1\n        e.enable_eke_isopycnal_diffusion = 1\n\n        i = self.idemix_module\n        i.enable_idemix = 1\n        i.enable_idemix_hor_diffusion = 1\n        i.enable_eke_diss_surfbot = 1\n        i.eke_diss_surfbot_frac = 0.2\n        i.enable_idemix_superbee_advection = 1\n        i.tau_v = 86400.\n        i.jstar = 10.\n        i.mu0 = 4. / 3.\n\n        m.eq_of_state_type = 3\n\n    @veros_method\n    def set_grid(self, vs):\n        m = self.main_module\n        ddz = [50., 70., 100., 140., 190., 240., 290., 340.,\n               390., 440., 490., 540., 590., 640., 690.]\n        m.dxt[:] = 2.0\n        m.dyt[:] = 2.0\n        m.x_origin = 0.0\n        m.y_origin = -40.0\n        m.dzt[:] = ddz[::-1]\n        m.dzt[:] *= 1 / 2.5\n\n    @veros_method\n    def set_coriolis(self, vs):\n        m = self.main_module\n        m.coriolis_t[:, :] = 2 * m.omega * np.sin(m.yt[None, :] / 180. * np.pi)\n\n    @veros_method\n    def set_topography(self, vs):\n        m = self.main_module\n        (X, Y) = np.meshgrid(m.xt, m.yt)\n        X = X.transpose()\n        Y = Y.transpose()\n        m.kbot[...] = (X > 1.0) | (Y < -20)\n\n    @veros_method\n    def set_initial_conditions(self, vs):\n        m = self.main_module\n\n        # initial conditions\n        m.temp[:, :, :, 0:2] = ((1 - m.zt[None, None, :] / m.zw[0]) * 15 * m.maskT)[..., None]\n        m.salt[:, :, :, 0:2] = 35.0 * m.maskT[..., None]\n\n        # wind stress forcing\n        taux = np.zeros(m.ny + 1, dtype=vs.default_float_type)\n        yt = m.yt[2:m.ny + 3]\n        taux = (.1e-3 * np.sin(np.pi * (m.yu[2:m.ny + 3] - yu_start) / (-20.0 - yt_start))) * (yt < -20) \\\n            + (.1e-3 * (1 - np.cos(2 * np.pi *\n                                   (m.yu[2:m.ny + 3] - 10.0) / (yu_end - 10.0)))) * (yt > 10)\n        m.surface_taux[:, 2:m.ny + 3] = taux * m.maskU[:, 2:m.ny + 3, -1]\n\n        # surface heatflux forcing\n        self.t_star = 15 * np.invert((m.yt < -20) | (m.yt > 20)) \\\n            + 15 * (m.yt - yt_start) / (-20 - yt_start) * (m.yt < -20) \\\n            + 15 * (1 - (m.yt - 20) / (yt_end - 20)) * (m.yt > 20.)\n        self.t_rest = m.dzt[None, -1] / (30. * 86400.) * m.maskT[:, :, -1]\n\n        t = self.tke_module\n        if t.enable_tke:\n            t.forc_tke_surface[2:-2, 2:-2] = np.sqrt((0.5 * (m.surface_taux[2:-2, 2:-2] + m.surface_taux[1:-3, 2:-2])) ** 2\n                                                     + (0.5 * (m.surface_tauy[2:-2, 2:-2] + m.surface_tauy[2:-2, 1:-3])) ** 2) ** 1.5\n\n        i = self.idemix_module\n        if i.enable_idemix:\n            i.forc_iw_bottom[:] = 1.0e-6 * m.maskW[:, :, -1]\n            i.forc_iw_surface[:] = 0.1e-6 * m.maskW[:, :, -1]\n\n    @veros_method\n    def set_forcing(self, vs):\n        m = self.main_module\n        m.forc_temp_surface[:] = self.t_rest * (self.t_star - m.temp[:, :, -1, self.get_tau()])\n\n    @veros_method\n    def set_diagnostics(self, vs):\n        pass\n\n    @veros_method\n    def after_timestep(self, vs):\n        pass\n\n\nclass ACC2Test(VerosPyOMSystemTest):\n    Testclass = ACC2\n    timesteps = 5\n\n    def test_passed(self):\n        differing_scalars = self.check_scalar_objects()\n        differing_arrays = self.check_array_objects()\n\n        if differing_scalars or differing_arrays:\n            print(\'The following attributes do not match between old and new veros:\')\n            for s, (v1, v2) in differing_scalars.items():\n                print(\'{}, {}, {}\'.format(s, v1, v2))\n            for a, (v1, v2) in differing_arrays.items():\n                if \'salt\' in a:\n                    # salt isn\'t used by this example\n                    continue\n                self.check_variable(a, atol=1e-6, data=(v1, v2))\n\n\ndef test_acc2(pyom2_lib, backend):\n    ACC2Test(fortran=pyom2_lib, backend=backend).run()\n'"
test/pyom_consistency/advection_test.py,7,"b""from collections import OrderedDict\n\nimport numpy as np\n\nfrom test_base import VerosPyOMUnitTest\nfrom veros.core import advection, numerics\n\n\nclass AdvectionTest(VerosPyOMUnitTest):\n    nx, ny, nz = 70, 60, 50\n\n    def initialize(self):\n        self.set_attribute('dt_tracer', 3600.)\n\n        for a in ('dxt', ):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.nx + 4).astype(np.float))\n\n        for a in ('dyt', ):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.ny + 4).astype(np.float))\n\n        for a in ('cosu', 'cost'):\n            self.set_attribute(a, 2 * np.random.rand(self.ny + 4) - 1.)\n\n        for a in ('dzt', 'dzw'):\n            self.set_attribute(a, 100 * np.random.rand(self.nz))\n\n        for a in ('flux_east', 'flux_north', 'flux_top', 'u_wgrid', 'v_wgrid', 'w_wgrid'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz))\n\n        for a in ('u', 'v', 'w', 'Hd'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz, 3))\n\n        self.set_attribute('kbot', np.random.randint(0, self.nz, size=(self.nx + 4, self.ny + 4)).astype(np.float))\n\n        numerics.calc_topo(self.veros_new.state)\n        self.veros_legacy.call_fortran_routine('calc_topo')\n\n        self.test_module = advection\n        veros_args = (self.veros_new.state, self.veros_new.state.flux_east, self.veros_new.state.flux_north,\n                      self.veros_new.state.flux_top, self.veros_new.state.Hd[..., 1])\n        veros_legacy_args = dict(\n            is_=-1, ie_=self.nx + 2, js_=-1, je_=self.ny + 2, nz_=self.nz,\n            adv_fe=self.veros_legacy.get_fortran_attribute('flux_east'),\n            adv_fn=self.veros_legacy.get_fortran_attribute('flux_north'),\n            adv_ft=self.veros_legacy.get_fortran_attribute('flux_top'),\n            var=self.veros_legacy.get_fortran_attribute('Hd')[..., 1]\n        )\n        self.test_routines = OrderedDict()\n        self.test_routines['calculate_velocity_on_wgrid'] = ((self.veros_new.state, ), dict())\n        self.test_routines.update(\n            adv_flux_2nd=(veros_args, veros_legacy_args),\n            adv_flux_superbee=(veros_args, veros_legacy_args),\n            adv_flux_upwind_wgrid=(veros_args, veros_legacy_args),\n            adv_flux_superbee_wgrid=(veros_args, veros_legacy_args)\n        )\n\n    def test_passed(self, routine):\n        if routine == 'calculate_velocity_on_wgrid':\n            for v in ('u_wgrid', 'v_wgrid', 'w_wgrid'):\n                self.check_variable(v)\n        else:\n            for f in ('flux_east', 'flux_north', 'flux_top'):\n                self.check_variable(f)\n\n\ndef test_advection(pyom2_lib, backend):\n    AdvectionTest(fortran=pyom2_lib, backend=backend).run()\n"""
test/pyom_consistency/diffusion_test.py,10,"b""from collections import OrderedDict\n\nimport numpy as np\n\nfrom test_base import VerosPyOMUnitTest\nfrom veros.core import diffusion, numerics\n\n\nclass DiffusionTest(VerosPyOMUnitTest):\n    nx, ny, nz = 70, 60, 50\n    extra_settings = {\n        'enable_cyclic_x': True,\n        'enable_conserve_energy': True,\n        'enable_hor_friction_cos_scaling': True,\n        'enable_tempsalt_sources': True,\n    }\n\n    def initialize(self):\n        self.set_attribute('hor_friction_cosPower', np.random.randint(1, 5))\n\n        for a in ('dt_tracer', 'K_hbi', 'K_h'):\n            self.set_attribute(a, np.random.rand())\n\n        for a in ('dxt', 'dxu'):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.nx + 4).astype(np.float))\n\n        for a in ('dyt', 'dyu'):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.ny + 4).astype(np.float))\n\n        for a in ('cosu', 'cost'):\n            self.set_attribute(a, 2 * np.random.rand(self.ny + 4) - 1.)\n\n        for a in ('dzt', 'dzw'):\n            self.set_attribute(a, 100 * np.random.rand(self.nz))\n\n        for a in ('flux_east', 'flux_north', 'flux_top', 'dtemp_hmix', 'dsalt_hmix',\n                  'temp_source', 'salt_source'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz))\n\n        for a in ('temp', 'salt', 'int_drhodS', 'int_drhodT'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz, 3))\n\n        self.set_attribute('kbot', np.random.randint(0, self.nz, size=(self.nx + 4, self.ny + 4)))\n        numerics.calc_topo(self.veros_new.state)\n        self.veros_legacy.call_fortran_routine('calc_topo')\n\n        self.set_attribute('P_diss_hmix', np.random.randn(self.nx + 4, self.ny + 4, self.nz) * self.veros_new.state.maskT)\n        self.test_module = diffusion\n        veros_args = (self.veros_new.state, )\n        veros_legacy_args = dict()\n        self.test_routines = OrderedDict()\n        self.test_routines.update(\n            tempsalt_biharmonic=(veros_args, veros_legacy_args),\n            tempsalt_diffusion=(veros_args, veros_legacy_args),\n            tempsalt_sources=(veros_args, veros_legacy_args),\n        )\n\n    def test_passed(self, routine):\n        for f in ('flux_east', 'flux_north', 'flux_top', 'temp', 'salt', 'P_diss_hmix',\n                  'dtemp_hmix', 'dsalt_hmix', 'P_diss_sources'):\n            self.check_variable(f)\n\n\ndef test_diffusion(pyom2_lib, backend):\n    DiffusionTest(fortran=pyom2_lib, backend=backend).run()\n"""
test/pyom_consistency/eke_test.py,11,"b""from collections import OrderedDict\n\nimport numpy as np\n\nfrom test_base import VerosPyOMUnitTest\nfrom veros.core import eke\n\n\nclass EKETest(VerosPyOMUnitTest):\n    nx, ny, nz = 70, 60, 50\n    extra_settings = {\n        'enable_cyclic_x': True,\n        'enable_eke_leewave_dissipation': True,\n        'enable_eke': True,\n        'enable_TEM_friction': True,\n        'enable_eke_isopycnal_diffusion': True,\n        'enable_store_cabbeling_heat': True,\n        'enable_eke_superbee_advection': True,\n        'enable_eke_upwind_advection': True\n    }\n\n    def initialize(self):\n        for a in ('eke_hrms_k0_min', 'eke_k_max', 'eke_c_k', 'eke_crhin', 'eke_cross',\n                  'eke_lmin', 'K_gm_0', 'K_iso_0', 'c_lee0', 'eke_Ri0', 'eke_Ri1', 'eke_int_diss0',\n                  'kappa_EKE0', 'eke_r_bot', 'eke_c_eps', 'alpha_eke', 'dt_tracer', 'AB_eps'):\n            self.set_attribute(a, np.random.rand())\n\n        for a in ('dxt', 'dxu'):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.nx + 4).astype(np.float))\n\n        for a in ('dyt', 'dyu'):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.ny + 4).astype(np.float))\n\n        for a in ('cosu', 'cost'):\n            self.set_attribute(a, 2 * np.random.rand(self.ny + 4) - 1.)\n\n        for a in ('dzt', 'dzw', 'zw'):\n            self.set_attribute(a, 100 * np.random.rand(self.nz))\n\n        for a in ('eke_topo_hrms', 'eke_topo_lam', 'hrms_k0', 'coriolis_t', 'beta',\n                  'eke_lee_flux', 'eke_bot_flux', 'L_rossby'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4))\n\n        for a in ('eke_len', 'K_diss_h', 'K_diss_gm', 'P_diss_skew', 'P_diss_hmix', 'P_diss_iso',\n                  'kappaM', 'eke_diss_iw', 'eke_diss_tke', 'K_gm', 'flux_east', 'flux_north', 'flux_top',\n                  'L_rhines'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz))\n\n        for a in ('eke', 'deke', 'Nsqr', 'u', 'v'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz, 3))\n\n        for a in ('maskU', 'maskV', 'maskW', 'maskT'):\n            self.set_attribute(a, np.random.randint(0, 2, size=(self.nx + 4, self.ny + 4, self.nz)).astype(np.float))\n\n        kbot = np.random.randint(1, self.nz, size=(self.nx + 4, self.ny + 4))\n        # add some islands, but avoid boundaries\n        kbot[3:-3, 3:-3].flat[np.random.randint(0, (self.nx - 2) * (self.ny - 2), size=10)] = 0\n        self.set_attribute('kbot', kbot)\n\n        self.test_module = eke\n        veros_args = (self.veros_new.state, )\n        veros_legacy_args = dict()\n        self.test_routines = OrderedDict()\n        self.test_routines['init_eke'] = (veros_args, veros_legacy_args)\n        self.test_routines['set_eke_diffusivities'] = (veros_args, veros_legacy_args)\n        self.test_routines['integrate_eke'] = (veros_args, veros_legacy_args)\n\n    def test_passed(self, routine):\n        for f in ('flux_east', 'flux_north', 'flux_top', 'eke', 'deke', 'hrms_k0', 'L_rossby',\n                  'L_rhines', 'eke_len', 'K_gm', 'kappa_gm', 'K_iso', 'sqrteke', 'c_lee', 'c_Ri_diss',\n                  'eke_diss_iw', 'eke_diss_tke', 'eke_lee_flux', 'eke_bot_flux'):\n            self.check_variable(f)\n\n\ndef test_eke(pyom2_lib, backend):\n    EKETest(fortran=pyom2_lib, backend=backend).run()\n"""
test/pyom_consistency/friction_test.py,13,"b""import os\n\nimport numpy as np\n\nimport pytest\n\nfrom test_base import VerosPyOMUnitTest\nfrom veros.core import friction, numerics\n\n\nclass FrictionTest(VerosPyOMUnitTest):\n    nx, ny, nz = 70, 60, 50\n    extra_settings = {\n        'enable_cyclic_x': True,\n        'enable_conserve_energy': True,\n        'enable_bottom_friction_var': True,\n        'enable_hor_friction_cos_scaling': True,\n        'enable_momentum_sources': True,\n    }\n\n    def initialize(self):\n        self.set_attribute('hor_friction_cosPower', np.random.randint(1, 5))\n\n        for a in ('dt_mom', 'r_bot', 'r_quad_bot', 'A_h', 'A_hbi', 'x_origin', 'y_origin'):\n            self.set_attribute(a, np.random.rand())\n\n        for a in ('dxt', 'dxu'):\n            self.set_attribute(a, np.ones(self.nx + 4) * np.random.rand())\n\n        for a in ('dyt', 'dyu'):\n            self.set_attribute(a, np.ones(self.ny + 4) * np.random.rand())\n\n        for a in ('cosu', 'cost'):\n            self.set_attribute(a, np.random.rand(self.ny + 4) + 1)\n\n        for a in ('dzt', 'dzw', 'zw'):\n            self.set_attribute(a, 1 + np.random.rand(self.nz))\n\n        for a in ('r_bot_var_u', 'r_bot_var_v'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4))\n\n        for a in ('area_u', 'area_v', 'area_t'):\n            self.set_attribute(a, np.random.rand(self.nx + 4, self.ny + 4))\n\n        for a in ('K_diss_v', 'kappaM', 'flux_north', 'flux_east', 'flux_top', 'K_diss_bot', 'K_diss_h',\n                  'du_mix', 'dv_mix', 'u_source', 'v_source'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz))\n\n        for a in ('u', 'v', 'w'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz, 3))\n\n        for a in ('maskU', 'maskV', 'maskW', 'maskT'):\n            self.set_attribute(a, np.random.randint(0, 2, size=(self.nx + 4, self.ny + 4, self.nz)).astype(np.float))\n\n        kbot = np.random.randint(1, self.nz, size=(self.nx + 4, self.ny + 4))\n        # add some islands, but avoid boundaries\n        kbot[3:-3, 3:-3].flat[np.random.randint(0, (self.nx - 2) * (self.ny - 2), size=10)] = 0\n        self.set_attribute('kbot', kbot)\n\n        numerics.calc_grid(self.veros_new.state)\n        numerics.calc_topo(self.veros_new.state)\n        self.veros_legacy.call_fortran_routine('calc_grid')\n        self.veros_legacy.call_fortran_routine('calc_topo')\n\n        self.test_module = friction\n        veros_args = (self.veros_new.state, )\n        veros_legacy_args = dict()\n        self.test_routines = {k: (veros_args, veros_legacy_args) for k in (\n            'explicit_vert_friction', 'implicit_vert_friction', 'rayleigh_friction',\n            'linear_bottom_friction', 'quadratic_bottom_friction', 'harmonic_friction',\n            'biharmonic_friction', 'momentum_sources'\n        )}\n\n    def test_passed(self, routine):\n        for f in ('flux_east', 'flux_north', 'flux_top', 'u', 'v', 'w', 'K_diss_v',\n                  'K_diss_bot', 'K_diss_h', 'du_mix', 'dv_mix'):\n            self.check_variable(f)\n\n\ndef test_friction(pyom2_lib, backend):\n    # TODO: debug this\n    if backend == 'bohrium' and os.environ.get('BH_STACK', '').lower() in ('opencl',):\n        pytest.xfail(reason='OpenCL memory corruption')\n    FrictionTest(fortran=pyom2_lib, backend=backend).run()\n"""
test/pyom_consistency/idemix_test.py,10,"b""from collections import OrderedDict\n\nimport numpy as np\n\nfrom test_base import VerosPyOMUnitTest\nfrom veros.core import idemix\n\n\nclass IdemixTest(VerosPyOMUnitTest):\n    nx, ny, nz = 70, 60, 50\n    extra_settings = {\n        'enable_idemix': True,\n        'enable_idemix_hor_diffusion': True,\n        'enable_idemix_superbee_advection': True,\n        'enable_idemix_upwind_advection': True,\n        'enable_eke': True,\n        'enable_store_cabbeling_heat': True,\n        'enable_eke_diss_bottom': True,\n        'enable_eke_diss_surfbot': True,\n        'enable_store_bottom_friction_tke': True,\n        'enable_TEM_friction': True,\n    }\n    test_module = idemix\n\n    def initialize(self):\n        for a in ('gamma', 'mu0', 'jstar', 'eke_diss_surfbot_frac', 'dt_tracer', 'tau_v', 'AB_eps'):\n            self.set_attribute(a, np.random.rand())\n\n        for a in ('dxt', 'dxu'):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.nx + 4).astype(np.float))\n\n        for a in ('dyt', 'dyu'):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.ny + 4).astype(np.float))\n\n        for a in ('cosu', 'cost'):\n            self.set_attribute(a, 2 * np.random.rand(self.ny + 4) - 1.)\n\n        for a in ('zt', 'dzt', 'dzw'):\n            self.set_attribute(a, np.random.rand(self.nz))\n\n        for a in ('area_u', 'area_v', 'area_t', 'coriolis_t', 'forc_iw_bottom', 'forc_iw_surface'):\n            self.set_attribute(a, np.random.rand(self.nx + 4, self.ny + 4))\n\n        for a in ('c0', 'v0', 'alpha_c', 'eke_diss_iw', 'K_diss_gm', 'K_diss_h', 'K_iso', 'K_gm',\n                  'kappa_gm', 'P_diss_iso', 'P_diss_skew', 'P_diss_hmix', 'K_diss_bot'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz))\n\n        for a in ('Nsqr', 'E_iw', 'dE_iw'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz, 3))\n\n        for a in ('maskU', 'maskV', 'maskW', 'maskT'):\n            self.set_attribute(a, np.random.randint(0, 2, size=(self.nx + 4, self.ny + 4, self.nz)).astype(np.float))\n\n        self.set_attribute('kbot', np.random.randint(0, self.nz, size=(self.nx + 4, self.ny + 4)))\n\n        self.test_routines = OrderedDict()\n        self.test_routines['set_idemix_parameter'] = ((self.veros_new.state, ), dict())\n        self.test_routines['integrate_idemix'] = ((self.veros_new.state, ), dict())\n\n    def test_passed(self, routine):\n        if routine == 'set_idemix_parameter':\n            for v in ('c0', 'v0', 'alpha_c'):\n                self.check_variable(v, atol=1e-7)\n        elif routine == 'integrate_idemix':\n            for v in ('E_iw', 'dE_iw', 'iw_diss', 'flux_east', 'flux_north', 'flux_top'):\n                self.check_variable(v)\n\n\ndef test_idemix(pyom2_lib, backend):\n    IdemixTest(fortran=pyom2_lib, backend=backend).run()\n"""
test/pyom_consistency/isoneutral_test.py,11,"b""from collections import OrderedDict\n\nimport numpy as np\n\nfrom test_base import VerosPyOMUnitTest\nfrom veros.core import isoneutral\n\n\nclass IsoneutralTest(VerosPyOMUnitTest):\n    nx, ny, nz = 70, 60, 50\n    extra_settings = {\n        'enable_neutral_diffusion': True,\n        'enable_skew_diffusion': True,\n        'enable_TEM_friction': True,\n    }\n    test_module = isoneutral\n\n    def initialize(self):\n        for a in ('iso_slopec', 'iso_dslope', 'K_iso_steep', 'dt_tracer', 'dt_mom'):\n            self.set_attribute(a, np.random.rand())\n\n        for a in ('dxt', 'dxu'):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.nx + 4).astype(np.float))\n\n        for a in ('dyt', 'dyu'):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.ny + 4).astype(np.float))\n\n        for a in ('cosu', 'cost'):\n            self.set_attribute(a, 2 * np.random.rand(self.ny + 4) - 1.)\n\n        for a in ('zt', 'dzt', 'dzw'):\n            self.set_attribute(a, 100 * np.random.rand(self.nz))\n\n        for a in ('area_u', 'area_v', 'area_t'):\n            self.set_attribute(a, 1e5 * np.random.rand(self.nx + 4, self.ny + 4))\n\n        for a in ('flux_east', 'flux_north', 'flux_top', 'u_wgrid', 'v_wgrid', 'w_wgrid',\n                  'K_iso', 'K_gm', 'kappa_gm', 'du_mix', 'P_diss_iso', 'P_diss_skew'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz))\n\n        for a in ('salt', 'temp', 'int_drhodT', 'int_drhodS'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz, 3))\n\n        for a in ('maskU', 'maskV', 'maskW', 'maskT'):\n            self.set_attribute(a, np.random.randint(0, 2, size=(self.nx + 4, self.ny + 4, self.nz)).astype(np.float))\n\n        self.set_attribute('kbot', np.random.randint(0, self.nz, size=(self.nx + 4, self.ny + 4)))\n\n        istemp = bool(np.random.randint(0, 2))\n\n        veros_args = (self.veros_new.state, self.veros_new.state.temp, istemp)\n        veros_legacy_args = dict(is_=-1, ie_=self.nx + 2, js_=-1, je_=self.ny + 2, nz_=self.nz,\n                                 tr=self.veros_legacy.get_fortran_attribute('temp'), istemp=istemp)\n\n        self.test_routines = OrderedDict()\n        self.test_routines['isoneutral_diffusion_pre'] = ((self.veros_new.state, ), dict())\n        self.test_routines['isoneutral_diag_streamfunction'] = ((self.veros_new.state, ), dict())\n        self.test_routines['isoneutral_diffusion'] = (veros_args, veros_legacy_args)\n        self.test_routines['isoneutral_skew_diffusion'] = (veros_args, veros_legacy_args)\n        self.test_routines['isoneutral_friction'] = ((self.veros_new.state, ), dict())\n        # unused in PyOM\n        #self.test_routines['isoneutral_diffusion_all'] = (veros_args, veros_legacy_args)\n\n    def test_passed(self, routine):\n        if routine == 'isoneutral_diffusion_pre':\n            for v in ('K_11', 'K_22', 'K_33', 'Ai_ez', 'Ai_nz', 'Ai_bx', 'Ai_by'):\n                self.check_variable(v)\n        elif routine == 'isoneutral_diag_streamfunction':\n            for v in ('B1_gm', 'B2_gm'):\n                self.check_variable(v)\n        elif routine == 'isoneutral_friction':\n            for v in ('K_diss_gm', 'u', 'du_mix', 'v', 'dv_mix', 'flux_top'):\n                self.check_variable(v)\n        else:\n            for f in ('flux_east', 'flux_north', 'flux_top', 'dtemp_iso', 'dsalt_iso',\n                      'temp', 'salt', 'P_diss_iso'):\n                self.check_variable(f)\n\n\ndef test_isoneutral(pyom2_lib, backend):\n    IsoneutralTest(fortran=pyom2_lib, backend=backend).run()\n"""
test/pyom_consistency/momentum_test.py,10,"b""from collections import OrderedDict\n\nimport numpy as np\n\nfrom test_base import VerosPyOMUnitTest\nfrom veros.core import momentum, streamfunction, numerics\n\n\nclass MomentumTest(VerosPyOMUnitTest):\n    nx, ny, nz = 70, 60, 50\n    extra_settings = {\n        'coord_degree': True,\n        'enable_cyclic_x': True,\n        'enable_conserve_energy': True,\n        'enable_bottom_friction_var': True,\n        'enable_hor_friction_cos_scaling': True,\n        'enable_implicit_vert_friction': True,\n        'enable_explicit_vert_friction': True,\n        'enable_TEM_friction': True,\n        'enable_hor_friction': True,\n        'enable_biharmonic_friction': True,\n        'enable_ray_friction': True,\n        'enable_bottom_friction': True,\n        'enable_quadratic_bottom_friction': True,\n        'enable_momentum_sources': True,\n        'congr_epsilon': 1e-12,\n        'congr_max_iterations': 10000,\n    }\n    first = True\n\n    def initialize(self):\n        self.set_attribute('hor_friction_cosPower', np.random.randint(1, 5))\n\n        for a in ('dt_mom', 'r_bot', 'r_quad_bot', 'A_h', 'A_hbi', 'AB_eps', 'x_origin', 'y_origin'):\n            self.set_attribute(a, np.random.rand())\n\n        for a in ('dxt', ):\n            self.set_attribute(a, 0.1 * np.ones(self.nx + 4) + 0.01 * np.random.rand(self.nx + 4))\n\n        for a in ('dyt', ):\n            self.set_attribute(a, 0.1 * np.ones(self.ny + 4) + 0.01 * np.random.rand(self.ny + 4))\n\n        for a in ('dzt', ):\n            self.set_attribute(a, np.random.rand(self.nz))\n\n        for a in ('r_bot_var_u', 'r_bot_var_v', 'surface_taux', 'surface_tauy', 'coriolis_t', 'coriolis_h'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4))\n\n        for a in ('K_diss_v', 'kappaM', 'flux_north', 'flux_east', 'flux_top', 'K_diss_bot', 'K_diss_h',\n                  'du_mix', 'dv_mix', 'u_source', 'v_source', 'du_adv', 'dv_adv'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz))\n\n        for a in ('u', 'v', 'w', 'du', 'dv'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz, 3))\n\n        kbot = np.random.randint(1, self.nz, size=(self.nx + 4, self.ny + 4))\n        # add some islands, but avoid boundaries\n        kbot[3:-3, 3:-3].flat[np.random.randint(0, (self.nx - 2) * (self.ny - 2), size=10)] = 0\n        self.set_attribute('kbot', kbot)\n\n        numerics.calc_grid(self.veros_new.state)\n        numerics.calc_topo(self.veros_new.state)\n        self.veros_legacy.call_fortran_routine('calc_grid')\n        self.veros_legacy.call_fortran_routine('calc_topo')\n\n        if self.first:\n            streamfunction.streamfunction_init(self.veros_new.state)\n            self.veros_legacy.call_fortran_routine('streamfunction_init')\n            self.first = False\n\n        self.test_module = momentum\n        veros_args = (self.veros_new.state, )\n        veros_legacy_args = dict()\n        self.test_routines = OrderedDict()\n        self.test_routines['momentum_advection'] = (veros_args, veros_legacy_args)\n        self.test_routines['vertical_velocity'] = (veros_args, veros_legacy_args)\n        self.test_routines['momentum'] = (veros_args, veros_legacy_args)\n\n    def test_passed(self, routine):\n        for f in ('flux_east', 'flux_north', 'flux_top', 'u', 'v', 'w', 'K_diss_v', 'du_adv', 'dv_adv', 'du', 'dv',\n                  'K_diss_bot', 'du_mix', 'dv_mix', 'psi', 'dpsi', 'du_cor', 'dv_cor'):\n            self.check_variable(f)\n        for f in ('K_diss_h', ):\n            self.check_variable(f, atol=1e-7)\n\n\ndef test_momentum(pyom2_lib, backend):\n    MomentumTest(fortran=pyom2_lib, backend=backend).run()\n"""
test/pyom_consistency/numerics_test.py,8,"b""from collections import OrderedDict\n\nimport numpy as np\n\nfrom test_base import VerosPyOMUnitTest\nfrom veros.core import numerics\n\n\nclass NumericsTest(VerosPyOMUnitTest):\n    nx, ny, nz = 70, 60, 50\n    extra_settings = {\n        'enable_cyclic_x': True,\n        'coord_degree': False,\n    }\n\n    def initialize(self):\n        for a in ('x_origin', 'y_origin'):\n            self.set_attribute(a, np.random.rand())\n\n        for a in ('dxt', 'dxu', 'xt', 'xu'):\n            self.set_attribute(a, 1 + 100 * np.random.rand(self.nx + 4))\n\n        for a in ('dyt', 'dyu', 'yt', 'yu'):\n            self.set_attribute(a, 1 + 100 * np.random.rand(self.ny + 4))\n\n        for a in ('dzt', 'dzw', 'zw', 'zt'):\n            self.set_attribute(a, np.random.rand(self.nz))\n\n        for a in ('cosu', 'cost', 'tantr'):\n            self.set_attribute(a, 2 * np.random.rand(self.ny + 4) - 1.)\n\n        for a in ('coriolis_t', 'area_u', 'area_v', 'area_t'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4))\n\n        for a in ('salt', 'temp'):\n            self.set_attribute(a, np.random.rand(self.nx + 4, self.ny + 4, self.nz, 3))\n\n        kbot = np.random.randint(0, self.nz, size=(self.nx + 4, self.ny + 4))\n        self.set_attribute('kbot', kbot)\n\n        self.test_module = numerics\n        veros_args = (self.veros_new.state, )\n        veros_legacy_args = dict()\n        self.test_routines = OrderedDict()\n        for r in ('calc_grid', 'calc_topo', 'calc_beta', 'calc_initial_conditions'):\n            self.test_routines[r] = (veros_args, veros_legacy_args)\n\n    def test_passed(self, routine):\n        for f in ('zt', 'zw', 'cosu', 'cost', 'tantr', 'area_u', 'area_v', 'area_t',\n                  'beta', 'xt', 'xu', 'dxu', 'dxt', 'yt', 'yu', 'dyu', 'dyt', 'dzt',\n                  'dzw', 'rho', 'salt', 'temp', 'Nsqr', 'Hd', 'int_drhodT', 'int_drhodS',\n                  'ht', 'hu', 'hv', 'hur', 'hvr', 'maskT', 'maskW', 'maskU', 'maskV', 'kbot'):\n            self.check_variable(f)\n\n\ndef test_numerics(pyom2_lib, backend):\n    NumericsTest(fortran=pyom2_lib, backend=backend).run()\n"""
test/pyom_consistency/solve_stream_test.py,9,"b""from collections import OrderedDict\n\nimport numpy as np\n\nfrom test_base import VerosPyOMUnitTest\nfrom veros.core import numerics, streamfunction\n\n\nclass StreamfunctionTest(VerosPyOMUnitTest):\n    nx, ny, nz = 70, 60, 50\n    first = True\n    extra_settings = {\n        'enable_cyclic_x': True,\n        'enable_congrad_verbose': False,\n        'congr_epsilon': 1e-12,\n        'congr_max_iterations': 10000,\n    }\n\n    def initialize(self):\n        for a in ('dt_mom', 'AB_eps', 'x_origin', 'y_origin'):\n            self.set_attribute(a, np.random.rand())\n\n        for a in ('dxt', ):\n            self.set_attribute(a, 100 * np.ones(self.nx + 4) + np.random.rand(self.nx + 4))\n\n        for a in ('dyt', ):\n            self.set_attribute(a, 100 * np.ones(self.ny + 4) + np.random.rand(self.ny + 4))\n\n        for a in ('dzt', ):\n            self.set_attribute(a, 10 + np.random.rand(self.nz))\n\n        for a in ('psi', 'dpsi'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, 3))\n\n        for a in ('du_mix', 'dv_mix'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz))\n\n        for a in ('u', 'v', 'du', 'dv', 'rho'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz, 3))\n\n        kbot = np.random.randint(1, self.nz, size=(self.nx + 4, self.ny + 4))\n        # add some islands, but avoid boundaries\n        kbot[3:-3, 3:-3].flat[np.random.randint(0, (self.nx - 2) * (self.ny - 2), size=10)] = 0\n        self.set_attribute('kbot', kbot)\n\n        for r in ('calc_grid', 'calc_topo'):\n            getattr(numerics, r)(self.veros_new.state)\n            self.veros_legacy.call_fortran_routine(r)\n\n        if self.first:\n            streamfunction.streamfunction_init(self.veros_new.state)\n            self.veros_legacy.call_fortran_routine('streamfunction_init')\n            self.first = False\n\n        self.test_module = streamfunction\n        veros_args = (self.veros_new.state, )\n        veros_legacy_args = dict()\n        self.test_routines = OrderedDict()\n        self.test_routines['solve_streamfunction'] = (veros_args, veros_legacy_args)\n\n    def test_passed(self, routine):\n        for f in ('line_psin', 'psin', 'p_hydro', 'psi', 'dpsi', 'du', 'dv', 'dpsin',\n                  'u', 'v'):\n            self.check_variable(f)\n\n\ndef test_streamfunction(pyom2_lib, backend):\n    StreamfunctionTest(fortran=pyom2_lib, backend=backend).run()\n"""
test/pyom_consistency/test_base.py,8,"b'import os\n\nfrom veros import VerosLegacy, runtime_settings as rs\nfrom veros.timer import Timer\n\nimport numpy as np\nnp.random.seed(17)\n\nhere = os.path.dirname(os.path.realpath(__file__))\n\nwith open(os.path.join(here, \'array_attributes\'), \'r\') as f:\n    ARRAY_ATTRIBUTES = [line for line in map(lambda l: l.strip(), f) if line]\n\nwith open(os.path.join(here, \'scalar_attributes\'), \'r\') as f:\n    SCALAR_ATTRIBUTES = [line for line in map(lambda l: l.strip(), f) if line]\n\n\nclass VerosLegacyDummy(VerosLegacy):\n    def set_parameter(self):\n        pass\n\n    def set_grid(self):\n        pass\n\n    def set_topography(self):\n        pass\n\n    def set_diagnostics(self):\n        pass\n\n    def after_timestep(self):\n        pass\n\n    def set_coriolis(self):\n        pass\n\n    def set_initial_conditions(self):\n        pass\n\n    def set_forcing(self):\n        pass\n\n    def set_fortran_attribute(self, attribute, value):\n        import numpy as np\n        for module_handle in self.modules:\n            if hasattr(module_handle, attribute):\n                try:\n                    v = np.asfortranarray(value.copy2numpy())\n                except AttributeError:\n                    v = np.asfortranarray(value)\n                setattr(module_handle, attribute, v)\n                break\n        else:\n            raise AttributeError(\'Legacy pyOM has no attribute {}\'.format(attribute))\n\n    def get_fortran_attribute(self, attribute):\n        for module_handle in self.modules:\n            if hasattr(module_handle, attribute):\n                return getattr(module_handle, attribute)\n        else:\n            raise AttributeError(\'Legacy pyOM has no attribute {}\'.format(attribute))\n\n    def call_fortran_routine(self, routine, *args, **kwargs):\n        routine_handle = getattr(self.fortran, routine)\n        return routine_handle(*args, **kwargs)\n\n\nclass VerosPyOMUnitTest:\n    legacy_modules = (\'main_module\', \'isoneutral_module\', \'tke_module\',\n                      \'eke_module\', \'idemix_module\')\n    array_attributes = ARRAY_ATTRIBUTES\n    scalar_attributes = SCALAR_ATTRIBUTES\n    extra_settings = None\n    test_module = None\n    test_routines = None\n\n    def __init__(self, fortran, backend, dims=None):\n        rs.backend = backend\n        self.veros_new = VerosLegacyDummy()\n        self.veros_new.state.pyom_compatibility_mode = True\n\n        self.veros_legacy = VerosLegacyDummy(fortran=fortran)\n\n        if dims:\n            self.nx, self.ny, self.nz = dims\n\n        self.set_attribute(\'nx\', self.nx)\n        self.set_attribute(\'ny\', self.ny)\n        self.set_attribute(\'nz\', self.nz)\n\n        if self.extra_settings:\n            for attribute, value in self.extra_settings.items():\n                self.set_attribute(attribute, value)\n\n        self.veros_new.set_legacy_parameter()\n        self.veros_new.state.allocate_variables()\n\n        self.veros_legacy.call_fortran_routine(\'my_mpi_init\', 0)\n        self.veros_legacy.call_fortran_routine(\'pe_decomposition\')\n        self.veros_legacy.set_legacy_parameter()\n        self.veros_legacy.call_fortran_routine(\'allocate_main_module\')\n        self.veros_legacy.call_fortran_routine(\'allocate_isoneutral_module\')\n        self.veros_legacy.call_fortran_routine(\'allocate_tke_module\')\n        self.veros_legacy.call_fortran_routine(\'allocate_eke_module\')\n        self.veros_legacy.call_fortran_routine(\'allocate_idemix_module\')\n\n    def set_attribute(self, attribute, value):\n        if isinstance(value, np.ndarray):\n            getattr(self.veros_new.state, attribute)[...] = value\n        else:\n            setattr(self.veros_new.state, attribute, value)\n\n        self.veros_legacy.set_fortran_attribute(attribute, value)\n\n    def get_attribute(self, attribute):\n        try:\n            veros_attr = getattr(self.veros_new.state, attribute)\n        except AttributeError:\n            veros_attr = None\n        try:\n            veros_attr = veros_attr.copy2numpy()\n        except AttributeError:\n            pass\n\n        try:\n            veros_legacy_attr = self.veros_legacy.get_fortran_attribute(attribute)\n        except AttributeError:\n            veros_legacy_attr = None\n\n        return veros_attr, veros_legacy_attr\n\n    def get_all_attributes(self, attributes):\n        return {a: v for a, v in zip(attributes, map(self.get_attribute, attributes))\n                if all(vi is not None for vi in v)}\n\n    def check_scalar_objects(self):\n        differing_objects = {}\n        scalars = self.get_all_attributes(self.scalar_attributes)\n        for s, (v1, v2) in scalars.items():\n            if ((v1 is None) != (v2 is None)) or v1 != v2:\n                differing_objects[s] = (v1, v2)\n        return differing_objects\n\n    def check_array_objects(self):\n        differing_objects = {}\n        arrays = self.get_all_attributes(self.array_attributes)\n        for a, (v1, v2) in arrays.items():\n            if ((v1 is None) != (v2 is None)) or not np.array_equal(v1, v2):\n                differing_objects[a] = (v1, v2)\n        return differing_objects\n\n    def initialize(self):\n        raise NotImplementedError(\'Must be implemented by test subclass\')\n\n    def _normalize(self, *arrays):\n        if any(a.size == 0 for a in arrays):\n            return arrays\n        norm = np.nanmax(np.abs(arrays[0]))\n        if norm == 0.:\n            return arrays\n        return (a / norm for a in arrays)\n\n    def check_variable(self, var, atol=1e-8, rtol=1e-6, data=None):\n        print(\'Checking {}...\'.format(var), end=\' \')\n        if data is None:\n            v1, v2 = self.get_attribute(var)\n        else:\n            v1, v2 = data\n        assert v1 is not None and v2 is not None\n        if v1.ndim > 1:\n            v1 = v1[2:-2, 2:-2, ...]\n        if v2.ndim > 1:\n            v2 = v2[2:-2, 2:-2, ...]\n        np.testing.assert_allclose(*self._normalize(v1, v2), atol=atol, rtol=rtol)\n        print(\'ok\')\n        return True\n\n    def run(self):\n        self.initialize()\n        differing_scalars = self.check_scalar_objects()\n        differing_arrays = self.check_array_objects()\n        if differing_scalars or differing_arrays:\n            print(\'The following attributes do not match between old and new veros after initialization:\')\n            for s, (v1, v2) in differing_scalars.items():\n                print(\'{}, {}, {}\'.format(s, v1, v2))\n            for a, (v1, v2) in differing_arrays.items():\n                print(\'{}, {!r}, {!r}\'.format(a, np.max(v1), np.max(v2)))\n\n        veros_timers = {k: Timer() for k in self.test_routines}\n        veros_legacy_timers = {k: Timer() for k in self.test_routines}\n\n        for routine in self.test_routines.keys():\n            veros_args, veros_legacy_args = self.test_routines[routine]\n            with veros_timers[routine]:\n                getattr(self.test_module, routine)(*veros_args)\n            print(\'[{}]: {:.3f}s\'.format(routine, veros_timers[routine].get_last_time()))\n            with veros_legacy_timers[routine]:\n                self.veros_legacy.call_fortran_routine(routine, **veros_legacy_args)\n            print(\'[legacy {}]: {:.3f}s\'.format(routine, veros_legacy_timers[routine].get_last_time()))\n            self.test_passed(routine)\n            self.initialize()\n\n\nclass VerosPyOMSystemTest(VerosPyOMUnitTest):\n    Testclass = None\n    timesteps = None\n    extra_settings = None\n\n    def __init__(self, fortran, backend):\n        self.backend = backend\n        self.fortran = fortran\n\n        for attr in (\'Testclass\', \'timesteps\'):\n            if getattr(self, attr) is None:\n                raise AttributeError(\'attribute ""{}"" must be set\'.format(attr))\n\n    def run(self):\n        rs.backend = self.backend\n        self.veros_new = self.Testclass()\n        self.veros_new.setup()\n\n        self.veros_legacy = self.Testclass(fortran=self.fortran)\n        self.veros_legacy.setup()\n\n        if self.extra_settings:\n            for key, val in self.extra_settings.items():\n                self.set_attribute(key, val)\n\n        # integrate for some time steps and compare\n        if self.timesteps > 0:\n            self.veros_new.state.runlen = self.timesteps * self.veros_new.state.dt_tracer\n            self.veros_new.run()\n\n            self.veros_legacy.set_fortran_attribute(\'runlen\', self.timesteps * self.veros_new.state.dt_tracer)\n            self.veros_legacy.run()\n\n        return self.test_passed()\n'"
test/pyom_consistency/thermodynamics_test.py,11,"b""from collections import OrderedDict\n\nimport numpy as np\n\nfrom test_base import VerosPyOMUnitTest\nfrom veros.core import thermodynamics\n\n\nclass ThermodynamicsTest(VerosPyOMUnitTest):\n    nx, ny, nz = 70, 60, 50\n    extra_settings = {\n        'enable_cyclic_x': True,\n        'enable_conserve_energy': True,\n        'enable_hor_friction_cos_scaling': True,\n        'enable_tempsalt_sources': True,\n        'enable_hor_diffusion': True,\n        'enable_superbee_advection': True,\n        'enable_tke': True,\n        'enable_biharmonic_mixing': True,\n        'enable_neutral_diffusion': True,\n        'enable_skew_diffusion': True,\n        'enable_TEM_friction': True,\n    }\n\n    def initialize(self):\n        self.set_attribute('hor_friction_cosPower', np.random.randint(1, 5))\n\n        for a in ('iso_slopec', 'iso_dslope', 'K_iso_steep', 'dt_tracer', 'dt_mom', 'K_hbi', 'K_h', 'AB_eps'):\n            self.set_attribute(a, np.random.rand())\n\n        for a in ('dxt', 'dxu'):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.nx + 4).astype(np.float))\n\n        for a in ('dyt', 'dyu'):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.ny + 4).astype(np.float))\n\n        for a in ('cosu', 'cost'):\n            self.set_attribute(a, 2 * np.random.rand(self.ny + 4) - 1.)\n\n        for a in ('zt', 'dzt', 'dzw'):\n            self.set_attribute(a, np.random.rand(self.nz))\n\n        for a in ('area_u', 'area_v', 'area_t', 'forc_rho_surface', 'forc_temp_surface'):\n            self.set_attribute(a, np.random.rand(self.nx + 4, self.ny + 4))\n\n        for a in ('flux_east', 'flux_north', 'flux_top', 'dtemp_hmix', 'dsalt_hmix', 'temp_source',\n                  'salt_source', 'u_wgrid', 'v_wgrid', 'w_wgrid', 'K_iso', 'K_gm', 'kappa_gm', 'du_mix',\n                  'P_diss_iso', 'P_diss_skew', 'P_diss_v', 'P_diss_nonlin',\n                  'kappaH'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz))\n\n        for a in ('Hd', 'dHd', 'temp', 'salt', 'int_drhodS', 'int_drhodT', 'dtemp', 'dsalt',\n                  'u', 'v', 'w', 'Nsqr', 'tke'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz, 3))\n\n        for a in ('maskU', 'maskV', 'maskW', 'maskT'):\n            self.set_attribute(a, np.random.randint(0, 2, size=(self.nx + 4, self.ny + 4, self.nz)).astype(np.float))\n\n        self.set_attribute('kbot', np.random.randint(0, self.nz, size=(self.nx + 4, self.ny + 4)))\n\n        self.test_module = thermodynamics\n        veros_args = (self.veros_new.state, )\n        veros_legacy_args = dict()\n        self.test_routines = OrderedDict()\n        self.test_routines.update(thermodynamics=(veros_args, veros_legacy_args), )\n\n    def test_passed(self, routine):\n        for f in ('flux_east', 'flux_north', 'flux_top', 'temp', 'salt',\n                  'dtemp', 'dsalt', 'P_diss_iso', 'Hd', 'dHd', 'Nsqr', 'P_diss_adv',\n                  'dtemp_iso', 'dsalt_iso', 'dtemp_vmix', 'dsalt_vmix', 'forc_rho_surface',\n                  'P_diss_v', 'P_diss_nonlin', 'int_drhodT', 'int_drhodS', 'rho'):\n            self.check_variable(f)\n\n\ndef test_thermodynamics(pyom2_lib, backend):\n    ThermodynamicsTest(fortran=pyom2_lib, backend=backend).run()\n"""
test/pyom_consistency/tke_test.py,10,"b""from collections import OrderedDict\n\nimport numpy as np\n\nfrom test_base import VerosPyOMUnitTest\nfrom veros.core import tke\n\n\nclass TKETest(VerosPyOMUnitTest):\n    nx, ny, nz = 70, 60, 50\n    extra_settings = {\n        'enable_cyclic_x': True,\n        'enable_idemix': True,\n        'tke_mxl_choice': 2,\n        'enable_tke': True,\n        'enable_eke': True,\n        'enable_store_cabbeling_heat': True,\n        'enable_store_bottom_friction_tke': False,\n        'enable_tke_hor_diffusion': True,\n        'enable_tke_superbee_advection': True,\n        'enable_tke_upwind_advection': True,\n    }\n\n    def initialize(self):\n        for a in ('mxl_min', 'kappaM_0', 'kappaH_0', 'dt_tke', 'c_k', 'kappaM_min', 'kappaM_max',\n                  'K_h_tke', 'AB_eps', 'c_eps', 'alpha_tke', 'dt_mom'):\n            self.set_attribute(a, np.random.rand())\n\n        for a in ('dxt', 'dxu'):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.nx + 4).astype(np.float))\n\n        for a in ('dyt', 'dyu'):\n            self.set_attribute(a, np.random.randint(1, 100, size=self.ny + 4).astype(np.float))\n\n        for a in ('cosu', 'cost'):\n            self.set_attribute(a, 2 * np.random.rand(self.ny + 4) - 1.)\n\n        for a in ('dzt', 'dzw', 'zw'):\n            self.set_attribute(a, 100 * np.random.rand(self.nz))\n\n        for a in ('tke_surf_corr', 'ht', 'forc_tke_surface'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4))\n\n        for a in ('K_diss_v', 'P_diss_v', 'P_diss_adv', 'P_diss_nonlin', 'eke_diss_tke',\n                  'kappaM', 'kappaH', 'K_diss_bot', 'eke_diss_iw', 'K_diss_gm', 'K_diss_h', 'tke_diss',\n                  'P_diss_skew', 'P_diss_hmix', 'P_diss_iso', 'alpha_c', 'mxl', 'iw_diss', 'Prandtlnumber'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz))\n\n        for a in ('tke', 'dtke', 'Nsqr', 'E_iw'):\n            self.set_attribute(a, np.random.randn(self.nx + 4, self.ny + 4, self.nz, 3))\n\n        for a in ('maskU', 'maskV', 'maskW', 'maskT'):\n            self.set_attribute(a, np.random.randint(0, 2, size=(self.nx + 4, self.ny + 4, self.nz)).astype(np.float))\n\n        self.set_attribute('kbot', np.random.randint(0, self.nz, size=(self.nx + 4, self.ny + 4)))\n\n        self.test_module = tke\n        veros_args = (self.veros_new.state, )\n        veros_legacy_args = dict()\n        self.test_routines = OrderedDict()\n        self.test_routines['set_tke_diffusivities'] = (veros_args, veros_legacy_args)\n        self.test_routines['integrate_tke'] = (veros_args, veros_legacy_args)\n\n    def test_passed(self, routine):\n        for f in ('flux_east', 'flux_north', 'flux_top', 'tke', 'dtke', 'tke_surf_corr', 'tke_diss',\n                  'kappaH', 'kappaM', 'Prandtlnumber', 'mxl', 'sqrttke'):\n            self.check_variable(f)\n\n\ndef test_tke(pyom2_lib, backend):\n    TKETest(fortran=pyom2_lib, backend=backend).run()\n"""
test/pyom_consistency/tridiag_test.py,3,"b""import numpy as np\n\nfrom test_base import VerosPyOMUnitTest\nfrom veros.core import numerics\nfrom veros import runtime_settings as rs\n\n\nclass TridiagTest(VerosPyOMUnitTest):\n    nx, ny, nz = 100, 100, 100\n\n    def initialize(self):\n        pass\n\n    def run(self):\n        a, b, c, d = (np.random.randn(self.nx, self.ny, self.nz) for _ in range(4))\n\n        out_legacy = np.zeros((self.nx, self.ny, self.nz))\n        for i in range(self.nx):\n            for j in range(self.ny):\n                out_legacy[i, j] = self.veros_legacy.call_fortran_routine(\n                    'solve_tridiag', a=a[i, j], b=b[i, j], c=c[i, j], d=d[i, j], n=self.nz\n                )\n\n        if rs.backend == 'bohrium':\n            import bohrium as bh\n            a, b, c, d = (bh.array(v) for v in (a, b, c, d))\n\n        out_new = numerics.solve_tridiag(self.veros_new.state, a, b, c, d)\n        np.testing.assert_allclose(out_legacy, out_new)\n\n\ndef test_tridiag(pyom2_lib, backend):\n    TridiagTest(fortran=pyom2_lib, backend=backend).run()\n"""
veros/cli/__init__.py,0,"b""#!/usr/bin/env python\n\ntry:\n    import click\n    have_click = True\nexcept ImportError:\n    have_click = False\n\nif not have_click:\n    raise ImportError('The Veros command line tools require click (e.g. through `pip install click`)')\n\ndel click\ndel have_click\n\nfrom . import veros, veros_copy_setup, veros_create_mask, veros_resubmit\n\nveros.cli.add_command(veros_copy_setup.cli, 'copy-setup')\nveros.cli.add_command(veros_create_mask.cli, 'create-mask')\nveros.cli.add_command(veros_resubmit.cli, 'resubmit')\n"""
veros/cli/veros.py,0,"b'import click\n\n\n@click.group(\'veros\')\n@click.version_option()\ndef cli():\n    """"""Veros command-line tools""""""\n    pass\n\n\nif __name__ == \'__main__\':\n    cli()\n'"
veros/cli/veros_copy_setup.py,0,"b'#!/usr/bin/env python\n\nimport os\nimport shutil\nimport functools\n\nimport click\nimport entrypoints\n\n\nSETUPDIR_ENVVAR = \'VEROS_SETUP_DIR\'\nIGNORE_PATTERNS = [\'__init__.py\', \'*.pyc\', \'__pycache__\']\nSETUPS = {}\n\nsetup_dirs = [\n    os.path.dirname(e.load().__file__)\n    for e in entrypoints.get_group_all(\'veros.setup_dirs\')\n]\n\nfor setup_dir in os.environ.get(SETUPDIR_ENVVAR, \'\').split(\';\'):\n    if os.path.isdir(setup_dir):\n        setup_dirs.append(setup_dir)\n\n# populate {setup_name: path} mapping\nfor setup_dir in setup_dirs:\n    for setup in os.listdir(setup_dir):\n        setup_path = os.path.join(setup_dir, setup)\n        if not os.path.isdir(setup_path):\n            continue\n        if setup.startswith((\'_\', \'.\')):\n            continue\n        SETUPS[setup] = setup_path\n\nSETUP_NAMES = sorted(SETUPS.keys())\n\n\ndef write_version_file(target_dir, origin):\n    from veros import __version__ as veros_version\n\n    with open(os.path.join(target_dir, \'version.txt\'), \'w\') as f:\n        f.write(\n            \'Veros v{veros_version}\\n\'\n            \'{origin}\\n\'\n            .format(origin=origin, veros_version=veros_version)\n        )\n\n\ndef copy_setup(setup, to=None):\n    """"""Copy a standard setup to another directory.\n\n    Available setups:\n\n        {setups}\n\n    Example:\n\n        $ veros copy-setup global_4deg --to ~/veros-setups/4deg-lowfric\n\n    Further directories containing setup templates can be added to this command\n    via the {setup_envvar} environment variable.\n    """"""\n    if to is None:\n        to = os.path.join(os.getcwd(), setup)\n\n    if os.path.exists(to):\n        raise RuntimeError(\'Target directory must not exist\')\n\n    to_parent = os.path.dirname(os.path.realpath(to))\n\n    if not os.path.exists(to_parent):\n        os.makedirs(to_parent)\n\n    ignore = shutil.ignore_patterns(*IGNORE_PATTERNS)\n    shutil.copytree(\n        SETUPS[setup], to, ignore=ignore\n    )\n\n    write_version_file(to, SETUPS[setup])\n\n\ncopy_setup.__doc__ = copy_setup.__doc__.format(\n    setups=\', \'.join(SETUP_NAMES), setup_envvar=SETUPDIR_ENVVAR\n)\n\n\n@click.command(\'veros-copy-setup\')\n@click.argument(\'setup\', type=click.Choice(SETUP_NAMES), metavar=\'SETUP\')\n@click.option(\'--to\', required=False, default=None,\n              type=click.Path(dir_okay=False, file_okay=False, writable=True),\n              help=(\'Target directory, must not exist \'\n                    \'(default: copy to current working directory)\'))\n@functools.wraps(copy_setup)\ndef cli(*args, **kwargs):\n    copy_setup(*args, **kwargs)\n\n\nif __name__ == \'__main__\':\n    cli()\n'"
veros/cli/veros_create_mask.py,3,"b'#!/usr/bin/env python\n\nimport functools\n\nimport click\n\n\ndef get_mask_data(depth):\n    import numpy as np\n    return np.where(depth > 0, 255, 0).astype(np.uint8)\n\n\ndef smooth_image(data, sigma):\n    from scipy import ndimage\n    return ndimage.gaussian_filter(data, sigma=sigma)\n\n\ndef save_image(data, path):\n    import numpy as np\n    from PIL import Image\n    Image.fromarray(np.flipud(data)).convert(\'1\').save(path)\n\n\ndef create_mask(infile, outfile, variable=\'z\', scale=None):\n    """"""Creates a mask image from a given netCDF file""""""\n    import numpy as np\n    import h5netcdf\n    with h5netcdf.File(infile, \'r\') as topo:\n        z = np.array(topo.variables[variable])\n    if scale is not None:\n        z = smooth_image(z, scale)\n    data = get_mask_data(z)\n    save_image(data, outfile)\n\n\n@click.command(\'veros-create-mask\')\n@click.argument(\'infile\', type=click.Path(exists=True, dir_okay=False))\n@click.option(\'-v\', \'--variable\', default=\'z\', help=\'Variable holding topography data (default: z)\')\n@click.option(\'-o\', \'--outfile\', default=\'topography.png\', help=\'Output filename (default: topography.png)\')\n@click.option(\'-s\', \'--scale\', nargs=2, type=click.INT, default=None,\n              help=\'Standard deviation in grid cells for Gaussian smoother (default: disable smoother)\')\n@functools.wraps(create_mask)\ndef cli(*args, **kwargs):\n    create_mask(**kwargs)\n\n\nif __name__ == \'__main__\':\n    cli()\n'"
veros/cli/veros_resubmit.py,0,"b'#!/usr/bin/env python\n\nimport functools\nimport subprocess\nimport shlex\nimport pipes\nimport sys\nimport os\nimport time\n\nimport click\n\nLAST_N_FILENAME = \'{identifier}.current_run\'\nCHILD_TIMEOUT = 10\nPOLL_DELAY = 0.1\n\n\nclass ShellCommand(click.ParamType):\n    name = \'command\'\n\n    def convert(self, value, param, ctx):\n        return shlex.split(value)\n\n\ndef get_current_n(filename):\n    if not os.path.isfile(filename):\n        return 0\n\n    with open(filename, \'r\') as f:\n        return int(f.read())\n\n\ndef write_next_n(n, filename):\n    with open(filename, \'w\') as f:\n        f.write(str(n))\n\n\ndef unparse(args):\n    return \' \'.join(map(pipes.quote, args))\n\n\ndef call_veros(cmd, name, n, runlen):\n    identifier = \'{name}.{n:0>4}\'.format(name=name, n=n)\n    prev_id = \'{name}.{n:0>4}\'.format(name=name, n=n - 1)\n    args = [\'-s\', \'identifier\', identifier, \'-s\', \'restart_output_filename\',\n            \'{identifier}.restart.h5\', \'-s\', \'runlen\', \'{}\'.format(runlen)]\n    if n:\n        args += [\'-s\', \'restart_input_filename\', \'{prev_id}.restart.h5\'.format(prev_id=prev_id)]\n\n    # make sure this isn\'t buffered\n    sys.stdout.write(\'\\n >>> {}\\n\\n\'.format(\' \'.join(cmd + args)))\n    sys.stdout.flush()\n\n    try:\n        subprocess.check_call(unparse(cmd + args), shell=True)\n    except subprocess.CalledProcessError:\n        raise RuntimeError(\'Run {} failed, exiting\'.format(n))\n\n\ndef resubmit(identifier, num_runs, length_per_run, veros_cmd, callback):\n    """"""Performs several runs of Veros back to back, using the previous run as restart input.\n\n    Intended to be used with scheduling systems (e.g. SLURM or PBS).\n\n    """"""\n    last_n_filename = LAST_N_FILENAME.format(identifier=identifier)\n\n    current_n = get_current_n(last_n_filename)\n    if current_n >= num_runs:\n        return\n\n    call_veros(veros_cmd, identifier, current_n, length_per_run)\n\n    next_n = current_n + 1\n    write_next_n(next_n, last_n_filename)\n\n    if next_n >= num_runs:\n        return\n\n    next_proc = subprocess.Popen(unparse(callback), shell=True)\n\n    # catch immediately crashing processes\n    timeout = CHILD_TIMEOUT\n\n    while timeout > 0:\n        retcode = next_proc.poll()\n        if retcode is not None:\n            if retcode > 0:\n                # process crashed\n                raise RuntimeError(\'Callback exited with {}\'.format(retcode))\n            else:\n                break\n        time.sleep(POLL_DELAY)\n        timeout -= POLL_DELAY\n\n\n@click.command(\'veros-resubmit\', short_help=\'Re-run a Veros setup several times\')\n@click.option(\'-i\', \'--identifier\', required=True,\n              help=\'Base identifier of the simulation\')\n@click.option(\'-n\', \'--num-runs\', type=click.INT, required=True,\n              help=\'Total number of runs to execute\')\n@click.option(\'-l\', \'--length-per-run\', type=click.FLOAT, required=True,\n              help=\'Length (in seconds) of each run\')\n@click.option(\'-c\', \'--veros-cmd\', type=ShellCommand(), required=True,\n              help=\'The command that is used to call veros (quoted)\')\n@click.option(\'--callback\', metavar=\'CMD\', type=ShellCommand(), default=None,\n              help=\'Command to call after each run has finished (quoted, default: call self)\')\n@functools.wraps(resubmit)\ndef cli(*args, **kwargs):\n    if kwargs[\'callback\'] is None:\n        kwargs[\'callback\'] = sys.argv\n\n    resubmit(*args, **kwargs)\n\n\nif __name__ == \'__main__\':\n    cli()\n'"
veros/core/__init__.py,0,b''
veros/core/advection.py,26,"b'from .. import veros_method\nfrom ..variables import allocate\nfrom .utilities import pad_z_edges, where\n\n\n@veros_method(inline=True)\ndef _calc_cr(vs, rjp, rj, rjm, vel):\n    """"""\n    Calculates cr value used in superbee advection scheme\n    """"""\n    eps = 1e-20  # prevent division by 0\n    return where(vs, vel > 0., rjm, rjp) / where(vs, np.abs(rj) < eps, eps, rj)\n\n\n@veros_method\ndef _adv_superbee(vs, vel, var, mask, dx, axis):\n    def limiter(cr):\n        return np.maximum(0., np.maximum(np.minimum(1., 2 * cr), np.minimum(2., cr)))\n    velfac = 1\n    if axis == 0:\n        sm1, s, sp1, sp2 = ((slice(1 + n, -2 + n or None), slice(2, -2), slice(None))\n                            for n in range(-1, 3))\n        dx = vs.cost[np.newaxis, 2:-2, np.newaxis] * dx[1:-2, np.newaxis, np.newaxis]\n    elif axis == 1:\n        sm1, s, sp1, sp2 = ((slice(2, -2), slice(1 + n, -2 + n or None), slice(None))\n                            for n in range(-1, 3))\n        dx = (vs.cost * dx)[np.newaxis, 1:-2, np.newaxis]\n        velfac = vs.cosu[np.newaxis, 1:-2, np.newaxis]\n    elif axis == 2:\n        vel, var, mask = (pad_z_edges(vs, a) for a in (vel, var, mask))\n        sm1, s, sp1, sp2 = ((slice(2, -2), slice(2, -2), slice(1 + n, -2 + n or None))\n                            for n in range(-1, 3))\n        dx = dx[np.newaxis, np.newaxis, :-1]\n    else:\n        raise ValueError(\'axis must be 0, 1, or 2\')\n    uCFL = np.abs(velfac * vel[s] * vs.dt_tracer / dx)\n    rjp = (var[sp2] - var[sp1]) * mask[sp1]\n    rj = (var[sp1] - var[s]) * mask[s]\n    rjm = (var[s] - var[sm1]) * mask[sm1]\n    cr = limiter(_calc_cr(vs, rjp, rj, rjm, vel[s]))\n    return velfac * vel[s] * (var[sp1] + var[s]) * 0.5 - np.abs(velfac * vel[s]) * ((1. - cr) + uCFL * cr) * rj * 0.5\n\n\n@veros_method\ndef adv_flux_2nd(vs, adv_fe, adv_fn, adv_ft, var):\n    """"""\n    2th order advective tracer flux\n    """"""\n    adv_fe[1:-2, 2:-2, :] = 0.5 * (var[1:-2, 2:-2, :] + var[2:-1, 2:-2, :]) \\\n        * vs.u[1:-2, 2:-2, :, vs.tau] * vs.maskU[1:-2, 2:-2, :]\n    adv_fn[2:-2, 1:-2, :] = vs.cosu[np.newaxis, 1:-2, np.newaxis] * 0.5 * (var[2:-2, 1:-2, :] + var[2:-2, 2:-1, :]) \\\n        * vs.v[2:-2, 1:-2, :, vs.tau] * vs.maskV[2:-2, 1:-2, :]\n    adv_ft[2:-2, 2:-2, :-1] = 0.5 * (var[2:-2, 2:-2, :-1] + var[2:-2, 2:-2, 1:]) \\\n        * vs.w[2:-2, 2:-2, :-1, vs.tau] * vs.maskW[2:-2, 2:-2, :-1]\n    adv_ft[:, :, -1] = 0.\n\n\n@veros_method\ndef adv_flux_superbee(vs, adv_fe, adv_fn, adv_ft, var):\n    r""""""\n    from MITgcm\n    Calculates advection of a tracer\n    using second-order interpolation with a flux limiter:\n\n    \\begin{equation*}\n    F^x_{adv} = U \\overline{ \\theta }^i\n    - \\frac{1}{2} \\left([ 1 - \\psi(C_r) ] |U|\n       + U \\frac{u \\Delta t}{\\Delta x_c} \\psi(C_r)\n                 \\right) \\delta_i \\theta\n    \\end{equation*}\n\n    where the $\\psi(C_r)$ is the limiter function and $C_r$ is\n    the slope ratio.\n    """"""\n    adv_fe[1:-2, 2:-2, :] = _adv_superbee(vs, vs.u[..., vs.tau],\n                                          var, vs.maskU, vs.dxt, 0)\n    adv_fn[2:-2, 1:-2, :] = _adv_superbee(vs, vs.v[..., vs.tau],\n                                          var, vs.maskV, vs.dyt, 1)\n    adv_ft[2:-2, 2:-2, :-1] = _adv_superbee(vs, vs.w[..., vs.tau],\n                                            var, vs.maskW, vs.dzt, 2)\n    adv_ft[..., -1] = 0.\n\n\n@veros_method\ndef calculate_velocity_on_wgrid(vs):\n    """"""\n    calculates advection velocity for tracer on W grid\n\n    Note: this implementation is not strictly equal to the Fortran version. They only match\n    if maskW has exactly one true value across each depth slice.\n    """"""\n    # lateral advection velocities on W grid\n    vs.u_wgrid[:, :, :-1] = vs.u[:, :, 1:, vs.tau] * vs.maskU[:, :, 1:] * 0.5 \\\n        * vs.dzt[np.newaxis, np.newaxis, 1:] / vs.dzw[np.newaxis, np.newaxis, :-1] \\\n        + vs.u[:, :, :-1, vs.tau] * vs.maskU[:, :, :-1] * 0.5 \\\n        * vs.dzt[np.newaxis, np.newaxis, :-1] / vs.dzw[np.newaxis, np.newaxis, :-1]\n    vs.v_wgrid[:, :, :-1] = vs.v[:, :, 1:, vs.tau] * vs.maskV[:, :, 1:] * 0.5 \\\n        * vs.dzt[np.newaxis, np.newaxis, 1:] / vs.dzw[np.newaxis, np.newaxis, :-1] \\\n        + vs.v[:, :, :-1, vs.tau] * vs.maskV[:, :, :-1] * 0.5 \\\n        * vs.dzt[np.newaxis, np.newaxis, :-1] / vs.dzw[np.newaxis, np.newaxis, :-1]\n    vs.u_wgrid[:, :, -1] = vs.u[:, :, -1, vs.tau] * \\\n        vs.maskU[:, :, -1] * 0.5 * vs.dzt[-1:] / vs.dzw[-1:]\n    vs.v_wgrid[:, :, -1] = vs.v[:, :, -1, vs.tau] * \\\n        vs.maskV[:, :, -1] * 0.5 * vs.dzt[-1:] / vs.dzw[-1:]\n\n    # redirect velocity at bottom and at topography\n    vs.u_wgrid[:, :, 0] = vs.u_wgrid[:, :, 0] + vs.u[:, :, 0, vs.tau] \\\n        * vs.maskU[:, :, 0] * 0.5 * vs.dzt[0:1] / vs.dzw[0:1]\n    vs.v_wgrid[:, :, 0] = vs.v_wgrid[:, :, 0] + vs.v[:, :, 0, vs.tau] \\\n        * vs.maskV[:, :, 0] * 0.5 * vs.dzt[0:1] / vs.dzw[0:1]\n    mask = vs.maskW[:-1, :, :-1] * vs.maskW[1:, :, :-1]\n    vs.u_wgrid[:-1, :, 1:] += (vs.u_wgrid[:-1, :, :-1] * vs.dzw[np.newaxis, np.newaxis, :-1]\n                                  / vs.dzw[np.newaxis, np.newaxis, 1:]) * (1. - mask)\n    vs.u_wgrid[:-1, :, :-1] *= mask\n    mask = vs.maskW[:, :-1, :-1] * vs.maskW[:, 1:, :-1]\n    vs.v_wgrid[:, :-1, 1:] += (vs.v_wgrid[:, :-1, :-1] * vs.dzw[np.newaxis, np.newaxis, :-1]\n                                  / vs.dzw[np.newaxis, np.newaxis, 1:]) * (1. - mask)\n    vs.v_wgrid[:, :-1, :-1] *= mask\n\n    # vertical advection velocity on W grid from continuity\n    vs.w_wgrid[:, :, 0] = 0.\n    vs.w_wgrid[1:, 1:, :] = np.cumsum(-vs.dzw[np.newaxis, np.newaxis, :] *\n                                         ((vs.u_wgrid[1:, 1:, :] - vs.u_wgrid[:-1, 1:, :]) / (vs.cost[np.newaxis, 1:, np.newaxis] * vs.dxt[1:, np.newaxis, np.newaxis])\n                                          + (vs.cosu[np.newaxis, 1:, np.newaxis] * vs.v_wgrid[1:, 1:, :] -\n                                             vs.cosu[np.newaxis, :-1, np.newaxis] * vs.v_wgrid[1:, :-1, :])\n                                          / (vs.cost[np.newaxis, 1:, np.newaxis] * vs.dyt[np.newaxis, 1:, np.newaxis])), axis=2)\n\n\n@veros_method\ndef adv_flux_superbee_wgrid(vs, adv_fe, adv_fn, adv_ft, var):\n    """"""\n    Calculates advection of a tracer defined on Wgrid\n    """"""\n    maskUtr = allocate(vs, (\'xt\', \'yt\', \'zw\'))\n    maskUtr[:-1, :, :] = vs.maskW[1:, :, :] * vs.maskW[:-1, :, :]\n    adv_fe[1:-2, 2:-2, :] = _adv_superbee(vs, vs.u_wgrid, var, maskUtr, vs.dxt, 0)\n\n    maskVtr = allocate(vs, (\'xt\', \'yt\', \'zw\'))\n    maskVtr[:, :-1, :] = vs.maskW[:, 1:, :] * vs.maskW[:, :-1, :]\n    adv_fn[2:-2, 1:-2, :] = _adv_superbee(vs, vs.v_wgrid, var, maskVtr, vs.dyt, 1)\n\n    maskWtr = allocate(vs, (\'xt\', \'yt\', \'zw\'))\n    maskWtr[:, :, :-1] = vs.maskW[:, :, 1:] * vs.maskW[:, :, :-1]\n    adv_ft[2:-2, 2:-2, :-1] = _adv_superbee(vs, vs.w_wgrid, var, maskWtr, vs.dzw, 2)\n    adv_ft[..., -1] = 0.0\n\n\n@veros_method\ndef adv_flux_upwind_wgrid(vs, adv_fe, adv_fn, adv_ft, var):\n    """"""\n    Calculates advection of a tracer defined on Wgrid\n    """"""\n    maskUtr = vs.maskW[2:-1, 2:-2, :] * vs.maskW[1:-2, 2:-2, :]\n    rj = (var[2:-1, 2:-2, :] - var[1:-2, 2:-2, :]) * maskUtr\n    adv_fe[1:-2, 2:-2, :] = vs.u_wgrid[1:-2, 2:-2, :] * (var[2:-1, 2:-2, :] + var[1:-2, 2:-2, :]) * 0.5 \\\n        - np.abs(vs.u_wgrid[1:-2, 2:-2, :]) * rj * 0.5\n\n    maskVtr = vs.maskW[2:-2, 2:-1, :] * vs.maskW[2:-2, 1:-2, :]\n    rj = (var[2:-2, 2:-1, :] - var[2:-2, 1:-2, :]) * maskVtr\n    adv_fn[2:-2, 1:-2, :] = vs.cosu[np.newaxis, 1:-2, np.newaxis] * vs.v_wgrid[2:-2, 1:-2, :] * \\\n        (var[2:-2, 2:-1, :] + var[2:-2, 1:-2, :]) * 0.5 \\\n        - np.abs(vs.cosu[np.newaxis, 1:-2, np.newaxis] * vs.v_wgrid[2:-2, 1:-2, :]) * rj * 0.5\n\n    maskWtr = vs.maskW[2:-2, 2:-2, 1:] * vs.maskW[2:-2, 2:-2, :-1]\n    rj = (var[2:-2, 2:-2, 1:] - var[2:-2, 2:-2, :-1]) * maskWtr\n    adv_ft[2:-2, 2:-2, :-1] = vs.w_wgrid[2:-2, 2:-2, :-1] * (var[2:-2, 2:-2, 1:] + var[2:-2, 2:-2, :-1]) * 0.5 \\\n        - np.abs(vs.w_wgrid[2:-2, 2:-2, :-1]) * rj * 0.5\n    adv_ft[:, :, -1] = 0.\n'"
veros/core/diffusion.py,25,"b'import math\n\nfrom .. import veros_method\nfrom ..variables import allocate\nfrom . import utilities\n\n\n@veros_method(inline=True)\ndef dissipation_on_wgrid(vs, out, int_drhodX=None, aloc=None, ks=None):\n    if aloc is None:\n        aloc = allocate(vs, (\'xt\', \'yt\', \'zw\'))\n        aloc[1:-1, 1:-1, :] = 0.5 * vs.grav / vs.rho_0 \\\n            * ((int_drhodX[2:, 1:-1, :] - int_drhodX[1:-1, 1:-1, :]) * vs.flux_east[1:-1, 1:-1, :]\n             + (int_drhodX[1:-1, 1:-1, :] - int_drhodX[:-2, 1:-1, :]) * vs.flux_east[:-2, 1:-1, :]) \\\n            / (vs.dxt[1:-1, np.newaxis, np.newaxis] * vs.cost[np.newaxis, 1:-1, np.newaxis]) \\\n            + 0.5 * vs.grav / vs.rho_0 * ((int_drhodX[1:-1, 2:, :] - int_drhodX[1:-1, 1:-1, :]) * vs.flux_north[1:-1, 1:-1, :]\n                                        + (int_drhodX[1:-1, 1:-1, :] - int_drhodX[1:-1, :-2, :]) * vs.flux_north[1:-1, :-2, :]) \\\n            / (vs.dyt[np.newaxis, 1:-1, np.newaxis] * vs.cost[np.newaxis, 1:-1, np.newaxis])\n\n    if ks is None:\n        ks = vs.kbot[:, :] - 1\n\n    land_mask = ks >= 0\n    edge_mask = land_mask[:, :, np.newaxis] & (\n        np.arange(vs.nz - 1)[np.newaxis, np.newaxis, :] == ks[:, :, np.newaxis])\n    water_mask = land_mask[:, :, np.newaxis] & (\n        np.arange(vs.nz - 1)[np.newaxis, np.newaxis, :] > ks[:, :, np.newaxis])\n\n    dzw_pad = utilities.pad_z_edges(vs, vs.dzw)\n    out[:, :, :-1] += (0.5 * (aloc[:, :, :-1] + aloc[:, :, 1:])\n                       + 0.5 * (aloc[:, :, :-1] * dzw_pad[np.newaxis, np.newaxis, :-3]\n                               / vs.dzw[np.newaxis, np.newaxis, :-1])) * edge_mask\n    out[:, :, :-1] += 0.5 * (aloc[:, :, :-1] + aloc[:, :, 1:]) * water_mask\n    out[:, :, -1] += aloc[:, :, -1] * land_mask\n\n\n@veros_method\ndef tempsalt_biharmonic(vs):\n    """"""\n    biharmonic mixing of temp and salinity,\n    dissipation of dyn. Enthalpy is stored\n    """"""\n    fxa = math.sqrt(abs(vs.K_hbi))\n\n    # update temp\n    vs.dtemp_hmix[1:, 1:, :] = biharmonic_diffusion(vs, vs.temp[:, :, :, vs.tau], fxa)[1:, 1:, :]\n    vs.temp[:, :, :, vs.taup1] += vs.dt_tracer * vs.dtemp_hmix * vs.maskT\n\n    if vs.enable_conserve_energy:\n        if vs.pyom_compatibility_mode:\n            fxa = vs.int_drhodT[-3, -3, -1, vs.tau]\n        vs.P_diss_hmix[...] = 0.\n        dissipation_on_wgrid(vs, vs.P_diss_hmix, int_drhodX=vs.int_drhodT[..., vs.tau])\n\n    # update salt\n    vs.dsalt_hmix[1:, 1:, :] = biharmonic_diffusion(vs, vs.salt[:, :, :, vs.tau], fxa)[1:, 1:, :]\n    vs.salt[:, :, :, vs.taup1] += vs.dt_tracer * vs.dsalt_hmix * vs.maskT\n\n    if vs.enable_conserve_energy:\n        dissipation_on_wgrid(vs, vs.P_diss_hmix, int_drhodX=vs.int_drhodS[..., vs.tau])\n\n\n@veros_method\ndef tempsalt_diffusion(vs):\n    """"""\n    Diffusion of temp and salinity,\n    dissipation of dyn. Enthalpy is stored\n    """"""\n    # horizontal diffusion of temperature\n    vs.dtemp_hmix[1:, 1:, :] = horizontal_diffusion(vs, vs.temp[:, :, :, vs.tau], vs.K_h)[1:, 1:, :]\n    vs.temp[:, :, :, vs.taup1] += vs.dt_tracer * vs.dtemp_hmix * vs.maskT\n\n    if vs.enable_conserve_energy:\n        vs.P_diss_hmix[...] = 0.\n        dissipation_on_wgrid(vs, vs.P_diss_hmix, int_drhodX=vs.int_drhodT[..., vs.tau])\n\n    # horizontal diffusion of salinity\n    vs.dsalt_hmix[1:, 1:, :] = horizontal_diffusion(vs, vs.salt[:, :, :, vs.tau], vs.K_h)[1:, 1:, :]\n    vs.salt[:, :, :, vs.taup1] += vs.dt_tracer * vs.dsalt_hmix * vs.maskT\n\n    if vs.enable_conserve_energy:\n        dissipation_on_wgrid(vs, vs.P_diss_hmix, int_drhodX=vs.int_drhodS[..., vs.tau])\n\n\n@veros_method\ndef tempsalt_sources(vs):\n    """"""\n    Sources of temp and salinity,\n    effect on dyn. Enthalpy is stored\n    """"""\n    vs.temp[:, :, :, vs.taup1] += vs.dt_tracer * vs.temp_source * vs.maskT\n    vs.salt[:, :, :, vs.taup1] += vs.dt_tracer * vs.salt_source * vs.maskT\n\n    if vs.enable_conserve_energy:\n        aloc = -vs.grav / vs.rho_0 * vs.maskT * \\\n            (vs.int_drhodT[..., vs.tau] * vs.temp_source +\n             vs.int_drhodS[..., vs.tau] * vs.salt_source)\n        vs.P_diss_sources[...] = 0.\n        dissipation_on_wgrid(vs, vs.P_diss_sources, aloc=aloc)\n\n\n@veros_method\ndef biharmonic_diffusion(vs, tr, diffusivity):\n    """"""\n    Biharmonic mixing of tracer tr\n    """"""\n    del2 = allocate(vs, (\'xt\', \'yt\', \'zt\'))\n    dtr = allocate(vs, (\'xt\', \'yt\', \'zt\'))\n\n    vs.flux_east[:-1, :, :] = -diffusivity * (tr[1:, :, :] - tr[:-1, :, :]) \\\n            / (vs.cost[np.newaxis, :, np.newaxis] * vs.dxu[:-1, np.newaxis, np.newaxis]) \\\n            * vs.maskU[:-1, :, :]\n\n    vs.flux_north[:, :-1, :] = -diffusivity * (tr[:, 1:, :] - tr[:, :-1, :]) \\\n            / vs.dyu[np.newaxis, :-1, np.newaxis] * vs.maskV[:, :-1, :] \\\n            * vs.cosu[np.newaxis, :-1, np.newaxis]\n\n    del2[1:, 1:, :] = vs.maskT[1:, 1:, :] * (vs.flux_east[1:, 1:, :] - vs.flux_east[:-1, 1:, :]) \\\n            / (vs.cost[np.newaxis, 1:, np.newaxis] * vs.dxt[1:, np.newaxis, np.newaxis]) \\\n            + (vs.flux_north[1:, 1:, :] - vs.flux_north[1:, :-1, :]) \\\n            / (vs.cost[np.newaxis, 1:, np.newaxis] * vs.dyt[np.newaxis, 1:, np.newaxis])\n\n    utilities.enforce_boundaries(vs, del2)\n\n    vs.flux_east[:-1, :, :] = diffusivity * (del2[1:, :, :] - del2[:-1, :, :]) \\\n            / (vs.cost[np.newaxis, :, np.newaxis] * vs.dxu[:-1, np.newaxis, np.newaxis]) \\\n            * vs.maskU[:-1, :, :]\n    vs.flux_north[:, :-1, :] = diffusivity * (del2[:, 1:, :] - del2[:, :-1, :]) \\\n            / vs.dyu[np.newaxis, :-1, np.newaxis] * vs.maskV[:, :-1, :] \\\n            * vs.cosu[np.newaxis, :-1, np.newaxis]\n\n    vs.flux_east[-1, :, :] = 0.\n    vs.flux_north[:, -1, :] = 0.\n\n    dtr[1:, 1:, :] = (vs.flux_east[1:, 1:, :] - vs.flux_east[:-1, 1:, :]) \\\n            / (vs.cost[np.newaxis, 1:, np.newaxis] * vs.dxt[1:, np.newaxis, np.newaxis]) \\\n            + (vs.flux_north[1:, 1:, :] - vs.flux_north[1:, :-1, :]) \\\n            / (vs.cost[np.newaxis, 1:, np.newaxis] * vs.dyt[np.newaxis, 1:, np.newaxis])\n\n    dtr[...] *= vs.maskT\n\n    return dtr\n\n\n@veros_method\ndef horizontal_diffusion(vs, tr, diffusivity):\n    """"""\n    Diffusion of tracer tr\n    """"""\n    dtr_hmix = allocate(vs, (\'xt\', \'yt\', \'zt\'))\n\n    # horizontal diffusion of tracer\n    vs.flux_east[:-1, :, :] = diffusivity * (tr[1:, :, :] - tr[:-1, :, :]) \\\n        / (vs.cost[np.newaxis, :, np.newaxis] * vs.dxu[:-1, np.newaxis, np.newaxis])\\\n        * vs.maskU[:-1, :, :]\n    vs.flux_east[-1, :, :] = 0.\n\n    vs.flux_north[:, :-1, :] = diffusivity * (tr[:, 1:, :] - tr[:, :-1, :]) \\\n        / vs.dyu[np.newaxis, :-1, np.newaxis] * vs.maskV[:, :-1, :]\\\n        * vs.cosu[np.newaxis, :-1, np.newaxis]\n    vs.flux_north[:, -1, :] = 0.\n\n    if vs.enable_hor_friction_cos_scaling:\n        vs.flux_east[...] *= vs.cost[np.newaxis, :, np.newaxis] ** vs.hor_friction_cosPower\n        vs.flux_north[...] *= vs.cosu[np.newaxis, :, np.newaxis] ** vs.hor_friction_cosPower\n\n    dtr_hmix[1:, 1:, :] = ((vs.flux_east[1:, 1:, :] - vs.flux_east[:-1, 1:, :])\n                           / (vs.cost[np.newaxis, 1:, np.newaxis] * vs.dxt[1:, np.newaxis, np.newaxis])\n                           + (vs.flux_north[1:, 1:, :] - vs.flux_north[1:, :-1, :])\n                           / (vs.cost[np.newaxis, 1:, np.newaxis] * vs.dyt[np.newaxis, 1:, np.newaxis]))\\\n                                * vs.maskT[1:, 1:, :]\n\n    return dtr_hmix\n'"
veros/core/eke.py,56,"b'import math\n\nfrom .. import veros_method, runtime_settings as rs\nfrom ..variables import allocate\nfrom . import utilities, advection\n\n\n@veros_method\ndef init_eke(vs):\n    """"""\n    Initialize EKE\n    """"""\n    if vs.enable_eke_leewave_dissipation:\n        vs.hrms_k0[...] = np.maximum(vs.eke_hrms_k0_min, 2 / vs.pi * vs.eke_topo_hrms**2\n                                        / np.maximum(1e-12, vs.eke_topo_lam)**1.5)\n\n\n@veros_method\ndef set_eke_diffusivities(vs):\n    """"""\n    set skew diffusivity K_gm and isopycnal diffusivity K_iso\n    set also vertical viscosity if TEM formalism is chosen\n    """"""\n    C_rossby = allocate(vs, (\'xt\', \'yt\'))\n\n    if vs.enable_eke:\n        """"""\n        calculate Rossby radius as minimum of mid-latitude and equatorial R. rad.\n        """"""\n        C_rossby[...] = np.sum(np.sqrt(np.maximum(0., vs.Nsqr[:, :, :, vs.tau]))\n                               * vs.dzw[np.newaxis, np.newaxis, :] * vs.maskW[:, :, :] / vs.pi, axis=2)\n        vs.L_rossby[...] = np.minimum(C_rossby / np.maximum(np.abs(vs.coriolis_t), 1e-16),\n                                         np.sqrt(C_rossby / np.maximum(2 * vs.beta, 1e-16)))\n        """"""\n        calculate vertical viscosity and skew diffusivity\n        """"""\n        vs.sqrteke = np.sqrt(np.maximum(0., vs.eke[:, :, :, vs.tau]))\n        vs.L_rhines[...] = np.sqrt(\n            vs.sqrteke / np.maximum(vs.beta[..., np.newaxis], 1e-16))\n        vs.eke_len[...] = np.maximum(vs.eke_lmin, np.minimum(\n            vs.eke_cross * vs.L_rossby[..., np.newaxis], vs.eke_crhin * vs.L_rhines))\n        vs.K_gm[...] = np.minimum(vs.eke_k_max, vs.eke_c_k * vs.eke_len * vs.sqrteke)\n    else:\n        """"""\n        use fixed GM diffusivity\n        """"""\n        vs.K_gm[...] = vs.K_gm_0\n\n    if vs.enable_TEM_friction:\n        vs.kappa_gm[...] = vs.K_gm * np.minimum(0.01, vs.coriolis_t[..., np.newaxis]**2\n                                                      / np.maximum(1e-9, vs.Nsqr[..., vs.tau])) * vs.maskW\n    if vs.enable_eke and vs.enable_eke_isopycnal_diffusion:\n        vs.K_iso[...] = vs.K_gm\n    else:\n        vs.K_iso[...] = vs.K_iso_0  # always constant\n\n\n@veros_method\ndef integrate_eke(vs):\n    """"""\n    integrate EKE equation on W grid\n    """"""\n    c_int = allocate(vs, (\'xt\', \'yt\', \'zw\'))\n\n    """"""\n    forcing by dissipation by lateral friction and GM using TRM formalism or skew diffusion\n    """"""\n    forc = vs.K_diss_h + vs.K_diss_gm - vs.P_diss_skew\n\n    """"""\n    store transfer due to isopycnal and horizontal mixing from dyn. enthalpy\n    by non-linear eq.of state either to EKE or to heat\n    """"""\n    if not vs.enable_store_cabbeling_heat:\n        forc[...] += -vs.P_diss_hmix - vs.P_diss_iso\n\n    """"""\n    coefficient for dissipation of EKE:\n    by lee wave generation, Ri-dependent interior loss of balance and bottom friction\n    """"""\n    if vs.enable_eke_leewave_dissipation:\n        """"""\n        by lee wave generation\n        """"""\n        vs.c_lee[...] = 0.\n        ks = vs.kbot[2:-2, 2:-2] - 1\n        ki = np.arange(vs.nz)[np.newaxis, np.newaxis, :]\n        boundary_mask = (ks >= 0) & (ks < vs.nz - 1)\n        full_mask = boundary_mask[:, :, np.newaxis] & (ki == ks[:, :, np.newaxis])\n        fxa = np.maximum(0, vs.Nsqr[2:-2, 2:-2, :, vs.tau])**0.25\n        fxa *= 1.5 * fxa / np.sqrt(np.maximum(1e-6, np.abs(vs.coriolis_t[2:-2, 2:-2, np.newaxis]))) - 2\n        vs.c_lee[2:-2, 2:-2] = boundary_mask * vs.c_lee0 * vs.hrms_k0[2:-2, 2:-2] \\\n                               * np.sum(np.sqrt(vs.sqrteke[2:-2, 2:-2, :]) * np.maximum(0, fxa)\n                                        / vs.dzw[np.newaxis, np.newaxis, :] * full_mask, axis=-1)\n\n        """"""\n        Ri-dependent dissipation by interior loss of balance\n        """"""\n        vs.c_Ri_diss[...] = 0\n        uz = (((vs.u[1:, 1:, 1:, vs.tau] - vs.u[1:, 1:, :-1, vs.tau]) / vs.dzt[np.newaxis, np.newaxis, :-1] * vs.maskU[1:, 1:, :-1])**2\n              + ((vs.u[:-1, 1:, 1:, vs.tau] - vs.u[:-1, 1:, :-1, vs.tau]) / vs.dzt[np.newaxis, np.newaxis, :-1] * vs.maskU[:-1, 1:, :-1])**2) \\\n            / (vs.maskU[1:, 1:, :-1] + vs.maskU[:-1, 1:, :-1] + 1e-18)\n        vz = (((vs.v[1:, 1:, 1:, vs.tau] - vs.v[1:, 1:, :-1, vs.tau]) / vs.dzt[np.newaxis, np.newaxis, :-1] * vs.maskV[1:, 1:, :-1])**2\n              + ((vs.v[1:, :-1, 1:, vs.tau] - vs.v[1:, :-1, :-1, vs.tau]) / vs.dzt[np.newaxis, np.newaxis, :-1] * vs.maskV[1:, :-1, :-1])**2) \\\n            / (vs.maskV[1:, 1:, :-1] + vs.maskV[1:, :-1, :-1] + 1e-18)\n        Ri = np.maximum(1e-8, vs.Nsqr[1:, 1:, :-1, vs.tau]) / (uz + vz + 1e-18)\n        fxa = 1 - 0.5 * (1. + np.tanh((Ri - vs.eke_Ri0) / vs.eke_Ri1))\n        vs.c_Ri_diss[1:, 1:, :-1] = vs.maskW[1:, 1:, :-1] * fxa * vs.eke_int_diss0\n        vs.c_Ri_diss[:, :, -1] = vs.c_Ri_diss[:, :, -2] * vs.maskW[:, :, -1]\n\n        """"""\n        vertically integrate Ri-dependent dissipation and EKE\n        """"""\n        a_loc = np.sum(vs.c_Ri_diss[:, :, :-1] * vs.eke[:, :, :-1, vs.tau] * vs.maskW[:, :, :-1] * vs.dzw[:-1], axis=2)\n        b_loc = np.sum(vs.eke[:, :, :-1, vs.tau] *\n                       vs.maskW[:, :, :-1] * vs.dzw[:-1], axis=2)\n        a_loc += vs.c_Ri_diss[:, :, -1] * vs.eke[:, :, -1, vs.tau] * vs.maskW[:, :, -1] * vs.dzw[-1] * 0.5\n        b_loc += vs.eke[:, :, -1, vs.tau] * vs.maskW[:, :, -1] * vs.dzw[-1] * 0.5\n\n        """"""\n        add bottom fluxes by lee waves and bottom friction to a_loc\n        """"""\n        a_loc[2:-2, 2:-2] += np.sum((vs.c_lee[2:-2, 2:-2, np.newaxis] * vs.eke[2:-2, 2:-2, :, vs.tau] \\\n                                     * vs.maskW[2:-2, 2:-2, :] * vs.dzw[np.newaxis, np.newaxis, :] \\\n                                     + 2 * vs.eke_r_bot * vs.eke[2:-2, 2:-2, :, vs.tau] \\\n                                     * math.sqrt(2.0) * vs.sqrteke[2:-2, 2:-2, :]\n                                     * vs.maskW[2:-2, 2:-2, :]) * full_mask, axis=-1) * boundary_mask\n\n        """"""\n        dissipation constant is vertically integrated forcing divided by\n        vertically integrated EKE to account for vertical EKE radiation\n        """"""\n        mask = b_loc > 0\n        a_loc[...] = utilities.where(vs, mask, a_loc / (b_loc + 1e-20), 0.)\n        c_int[...] = a_loc[:, :, np.newaxis]\n    else:\n        """"""\n        dissipation by local interior loss of balance with constant coefficient\n        """"""\n        c_int[...] = vs.eke_c_eps * vs.sqrteke / vs.eke_len * vs.maskW\n\n    """"""\n    vertical diffusion of EKE,forcing and dissipation\n    """"""\n    ks = vs.kbot[2:-2, 2:-2] - 1\n    delta, a_tri, b_tri, c_tri, d_tri = (allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False) for _ in range(5))\n    delta[:, :, :-1] = vs.dt_tracer / vs.dzt[np.newaxis, np.newaxis, 1:] * 0.5 \\\n        * (vs.kappaM[2:-2, 2:-2, :-1] + vs.kappaM[2:-2, 2:-2, 1:]) * vs.alpha_eke\n    a_tri[:, :, 1:-1] = -delta[:, :, :-2] / vs.dzw[1:-1]\n    a_tri[:, :, -1] = -delta[:, :, -2] / (0.5 * vs.dzw[-1])\n    b_tri[:, :, 1:-1] = 1 + (delta[:, :, 1:-1] + delta[:, :, :-2]) / \\\n        vs.dzw[1:-1] + vs.dt_tracer * c_int[2:-2, 2:-2, 1:-1]\n    b_tri[:, :, -1] = 1 + delta[:, :, -2] / \\\n        (0.5 * vs.dzw[-1]) + vs.dt_tracer * c_int[2:-2, 2:-2, -1]\n    b_tri_edge = 1 + delta / vs.dzw[np.newaxis, np.newaxis, :] \\\n        + vs.dt_tracer * c_int[2:-2, 2:-2, :]\n    c_tri[:, :, :-1] = -delta[:, :, :-1] / vs.dzw[np.newaxis, np.newaxis, :-1]\n    d_tri[:, :, :] = vs.eke[2:-2, 2:-2, :, vs.tau] + vs.dt_tracer * forc[2:-2, 2:-2, :]\n    sol, water_mask = utilities.solve_implicit(vs, ks, a_tri, b_tri, c_tri, d_tri, b_edge=b_tri_edge)\n    vs.eke[2:-2, 2:-2, :, vs.taup1] = utilities.where(vs, water_mask, sol, vs.eke[2:-2, 2:-2, :, vs.taup1])\n\n    """"""\n    store eke dissipation\n    """"""\n    if vs.enable_eke_leewave_dissipation:\n        vs.eke_diss_iw[...] = 0.\n        vs.eke_diss_tke[...] = vs.c_Ri_diss * vs.eke[:, :, :, vs.taup1]\n\n        """"""\n        flux by lee wave generation and bottom friction\n        """"""\n        vs.eke_diss_iw[2:-2, 2:-2, :] += (vs.c_lee[2:-2, 2:-2, np.newaxis] * vs.eke[2:-2, 2:-2, :, vs.taup1]\n                                             * vs.maskW[2:-2, 2:-2, :]) * full_mask\n        if vs.pyom_compatibility_mode:\n            vs.eke_diss_tke[2:-2, 2:-2, :] += (2 * vs.eke_r_bot * vs.eke[2:-2, 2:-2, :, vs.taup1] * np.sqrt(np.float32(2.0))\n                                                  * vs.sqrteke[2:-2, 2:-2, :] * vs.maskW[2:-2, 2:-2, :] / vs.dzw[np.newaxis, np.newaxis, :]) * full_mask\n        else:\n            vs.eke_diss_tke[2:-2, 2:-2, :] += (2 * vs.eke_r_bot * vs.eke[2:-2, 2:-2, :, vs.taup1] * math.sqrt(2.0)\n                                                  * vs.sqrteke[2:-2, 2:-2, :] * vs.maskW[2:-2, 2:-2, :] / vs.dzw[np.newaxis, np.newaxis, :]) * full_mask\n        """"""\n        account for sligthly incorrect integral of dissipation due to time stepping\n        """"""\n        a_loc = np.sum((vs.eke_diss_iw[:, :, :-1] + vs.eke_diss_tke[:, :, :-1])\n                       * vs.dzw[np.newaxis, np.newaxis, :-1], axis=2)\n        b_loc = np.sum(c_int[:, :, :-1] * vs.eke[:, :, :-1, vs.taup1]\n                       * vs.dzw[np.newaxis, np.newaxis, :-1], axis=2)\n        a_loc += (vs.eke_diss_iw[:, :, -1] + vs.eke_diss_tke[:, :, -1]) * vs.dzw[-1] * 0.5\n        b_loc += c_int[:, :, -1] * vs.eke[:, :, -1, vs.taup1] * vs.dzw[-1] * 0.5\n        mask = a_loc != 0.\n        b_loc[...] = utilities.where(vs, mask, b_loc / (a_loc + 1e-20), 0.)\n        vs.eke_diss_iw[...] *= b_loc[:, :, np.newaxis]\n        vs.eke_diss_tke[...] *= b_loc[:, :, np.newaxis]\n\n        """"""\n        store diagnosed flux by lee waves and bottom friction\n        """"""\n        vs.eke_lee_flux[2:-2, 2:-2] = utilities.where(vs, boundary_mask, np.sum(vs.c_lee[2:-2, 2:-2, np.newaxis] * vs.eke[2:-2, 2:-2, :, vs.taup1]\n                                                                        * vs.dzw[np.newaxis, np.newaxis, :] * full_mask, axis=-1), vs.eke_lee_flux[2:-2, 2:-2])\n        vs.eke_bot_flux[2:-2, 2:-2] = utilities.where(vs, boundary_mask, np.sum(2 * vs.eke_r_bot * vs.eke[2:-2, 2:-2, :, vs.taup1]\n                                                                        * math.sqrt(2.0) * vs.sqrteke[2:-2, 2:-2, :] * full_mask, axis=-1), vs.eke_bot_flux[2:-2, 2:-2])\n    else:\n        vs.eke_diss_iw = c_int * vs.eke[:, :, :, vs.taup1]\n        vs.eke_diss_tke[...] = 0.\n\n    """"""\n    add tendency due to lateral diffusion\n    """"""\n    vs.flux_east[:-1, :, :] = 0.5 * np.maximum(500., vs.K_gm[:-1, :, :] + vs.K_gm[1:, :, :]) \\\n        * (vs.eke[1:, :, :, vs.tau] - vs.eke[:-1, :, :, vs.tau]) \\\n        / (vs.cost[np.newaxis, :, np.newaxis] * vs.dxu[:-1, np.newaxis, np.newaxis]) * vs.maskU[:-1, :, :]\n    vs.flux_east[-1, :, :] = 0.\n    vs.flux_north[:, :-1, :] = 0.5 * np.maximum(500., vs.K_gm[:, :-1, :] + vs.K_gm[:, 1:, :]) \\\n        * (vs.eke[:, 1:, :, vs.tau] - vs.eke[:, :-1, :, vs.tau]) \\\n        / vs.dyu[np.newaxis, :-1, np.newaxis] * vs.maskV[:, :-1, :] * vs.cosu[np.newaxis, :-1, np.newaxis]\n    vs.flux_north[:, -1, :] = 0.\n    vs.eke[2:-2, 2:-2, :, vs.taup1] += vs.dt_tracer * vs.maskW[2:-2, 2:-2, :] \\\n        * ((vs.flux_east[2:-2, 2:-2, :] - vs.flux_east[1:-3, 2:-2, :])\n           / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis])\n           + (vs.flux_north[2:-2, 2:-2, :] - vs.flux_north[2:-2, 1:-3, :])\n           / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dyt[np.newaxis, 2:-2, np.newaxis]))\n\n    """"""\n    add tendency due to advection\n    """"""\n    if vs.enable_eke_superbee_advection:\n        advection.adv_flux_superbee_wgrid(\n            vs, vs.flux_east, vs.flux_north, vs.flux_top, vs.eke[:, :, :, vs.tau]\n            )\n    if vs.enable_eke_upwind_advection:\n        advection.adv_flux_upwind_wgrid(\n            vs, vs.flux_east, vs.flux_north, vs.flux_top, vs.eke[:, :, :, vs.tau]\n            )\n    if vs.enable_eke_superbee_advection or vs.enable_eke_upwind_advection:\n        vs.deke[2:-2, 2:-2, :, vs.tau] = vs.maskW[2:-2, 2:-2, :] * (-(vs.flux_east[2:-2, 2:-2, :] - vs.flux_east[1:-3, 2:-2, :])\n                                                                    / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis])\n                                                                    - (vs.flux_north[2:-2, 2:-2, :] - vs.flux_north[2:-2, 1:-3, :])\n                                                                    / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dyt[np.newaxis, 2:-2, np.newaxis]))\n        vs.deke[:, :, 0, vs.tau] += -vs.flux_top[:, :, 0] / vs.dzw[0]\n        vs.deke[:, :, 1:-1, vs.tau] += -(vs.flux_top[:, :, 1:-1] -\n                                               vs.flux_top[:, :, :-2]) / vs.dzw[np.newaxis, np.newaxis, 1:-1]\n        vs.deke[:, :, -1, vs.tau] += -(vs.flux_top[:, :, -1] - vs.flux_top[:, :, -2]) / (0.5 * vs.dzw[-1])\n        """"""\n        Adam Bashforth time stepping\n        """"""\n        vs.eke[:, :, :, vs.taup1] += vs.dt_tracer * ((1.5 + vs.AB_eps) * vs.deke[:, :, :, vs.tau]\n                                                   - (0.5 + vs.AB_eps) * vs.deke[:, :, :, vs.taum1])\n'"
veros/core/friction.py,106,"b'import math\n\nfrom .. import veros_method, runtime_settings as rs\nfrom ..variables import allocate\nfrom . import numerics, utilities\n\n\n@veros_method\ndef explicit_vert_friction(vs):\n    """"""\n    explicit vertical friction\n    dissipation is calculated and added to K_diss_v\n    """"""\n    diss = allocate(vs, (\'xt\', \'yt\', \'zw\'))\n\n    """"""\n    vertical friction of zonal momentum\n    """"""\n    fxa = 0.5 * (vs.kappaM[1:-2, 1:-2, :-1] + vs.kappaM[2:-1, 1:-2, :-1])\n    vs.flux_top[1:-2, 1:-2, :-1] = fxa * (vs.u[1:-2, 1:-2, 1:, vs.tau] - vs.u[1:-2, 1:-2, :-1, vs.tau]) \\\n        / vs.dzw[np.newaxis, np.newaxis, :-1] * vs.maskU[1:-2, 1:-2, 1:] * vs.maskU[1:-2, 1:-2, :-1]\n    vs.flux_top[:, :, -1] = 0.0\n    vs.du_mix[:, :, 0] = vs.flux_top[:, :, 0] / vs.dzt[0] * vs.maskU[:, :, 0]\n    vs.du_mix[:, :, 1:] = (vs.flux_top[:, :, 1:] - vs.flux_top[:, :, :-1]) / vs.dzt[1:] * vs.maskU[:, :, 1:]\n\n    """"""\n    diagnose dissipation by vertical friction of zonal momentum\n    """"""\n    diss[1:-2, 1:-2, :-1] = (vs.u[1:-2, 1:-2, 1:, vs.tau] - vs.u[1:-2, 1:-2, :-1, vs.tau]) \\\n        * vs.flux_top[1:-2, 1:-2, :-1] / vs.dzw[np.newaxis, np.newaxis, :-1]\n    diss[:, :, vs.nz - 1] = 0.0\n    diss[...] = numerics.ugrid_to_tgrid(vs, diss)\n    vs.K_diss_v += diss\n\n    """"""\n    vertical friction of meridional momentum\n    """"""\n    fxa = 0.5 * (vs.kappaM[1:-2, 1:-2, :-1] + vs.kappaM[1:-2, 2:-1, :-1])\n    vs.flux_top[1:-2, 1:-2, :-1] = fxa * (vs.v[1:-2, 1:-2, 1:, vs.tau] - vs.v[1:-2, 1:-2, :-1, vs.tau]) \\\n        / vs.dzw[np.newaxis, np.newaxis, :-1] * vs.maskV[1:-2, 1:-2, 1:] \\\n        * vs.maskV[1:-2, 1:-2, :-1]\n    vs.flux_top[:, :, -1] = 0.0\n    vs.dv_mix[:, :, 1:] = (vs.flux_top[:, :, 1:] - vs.flux_top[:, :, :-1]) \\\n        / vs.dzt[np.newaxis, np.newaxis, 1:] * vs.maskV[:, :, 1:]\n    vs.dv_mix[:, :, 0] = vs.flux_top[:, :, 0] / vs.dzt[0] * vs.maskV[:, :, 0]\n\n    """"""\n    diagnose dissipation by vertical friction of meridional momentum\n    """"""\n    diss[1:-2, 1:-2, :-1] = (vs.v[1:-2, 1:-2, 1:, vs.tau] - vs.v[1:-2, 1:-2, :-1, vs.tau]) \\\n        * vs.flux_top[1:-2, 1:-2, :-1] / vs.dzw[np.newaxis, np.newaxis, :-1]\n    diss[:, :, -1] = 0.0\n    diss[...] = numerics.vgrid_to_tgrid(vs, diss)\n    vs.K_diss_v += diss\n\n\n@veros_method\ndef implicit_vert_friction(vs):\n    """"""\n    vertical friction\n    dissipation is calculated and added to K_diss_v\n    """"""\n    a_tri = allocate(vs, (\'xt\', \'yt\', \'zw\'))[1:-2, 1:-2]\n    b_tri = allocate(vs, (\'xt\', \'yt\', \'zw\'))[1:-2, 1:-2]\n    c_tri = allocate(vs, (\'xt\', \'yt\', \'zw\'))[1:-2, 1:-2]\n    d_tri = allocate(vs, (\'xt\', \'yt\', \'zw\'))[1:-2, 1:-2]\n    delta = allocate(vs, (\'xt\', \'yt\', \'zw\'))[1:-2, 1:-2]\n    diss = allocate(vs, (\'xt\', \'yt\', \'zw\'))\n\n    """"""\n    implicit vertical friction of zonal momentum\n    """"""\n    kss = np.maximum(vs.kbot[1:-2, 1:-2], vs.kbot[2:-1, 1:-2]) - 1\n    fxa = 0.5 * (vs.kappaM[1:-2, 1:-2, :-1] + vs.kappaM[2:-1, 1:-2, :-1])\n    delta[:, :, :-1] = vs.dt_mom / vs.dzw[:-1] * fxa * \\\n        vs.maskU[1:-2, 1:-2, 1:] * vs.maskU[1:-2, 1:-2, :-1]\n    a_tri[:, :, 1:] = -delta[:, :, :-1] / vs.dzt[np.newaxis, np.newaxis, 1:]\n    b_tri[:, :, 1:] = 1 + delta[:, :, :-1] / vs.dzt[np.newaxis, np.newaxis, 1:]\n    b_tri[:, :, 1:-1] += delta[:, :, 1:-1] / vs.dzt[np.newaxis, np.newaxis, 1:-1]\n    b_tri_edge = 1 + delta / vs.dzt[np.newaxis, np.newaxis, :]\n    c_tri[...] = -delta / vs.dzt[np.newaxis, np.newaxis, :]\n    d_tri[...] = vs.u[1:-2, 1:-2, :, vs.tau]\n    res, mask = utilities.solve_implicit(vs, kss, a_tri, b_tri, c_tri, d_tri, b_edge=b_tri_edge)\n    vs.u[1:-2, 1:-2, :, vs.taup1] = utilities.where(vs, mask, res, vs.u[1:-2, 1:-2, :, vs.taup1])\n\n    vs.du_mix[1:-2, 1:-2] = (vs.u[1:-2, 1:-2, :, vs.taup1] -\n                                vs.u[1:-2, 1:-2, :, vs.tau]) / vs.dt_mom\n\n    """"""\n    diagnose dissipation by vertical friction of zonal momentum\n    """"""\n    fxa = 0.5 * (vs.kappaM[1:-2, 1:-2, :-1] + vs.kappaM[2:-1, 1:-2, :-1])\n    vs.flux_top[1:-2, 1:-2, :-1] = fxa * (vs.u[1:-2, 1:-2, 1:, vs.taup1] - vs.u[1:-2, 1:-2, :-1, vs.taup1]) \\\n        / vs.dzw[:-1] * vs.maskU[1:-2, 1:-2, 1:] * vs.maskU[1:-2, 1:-2, :-1]\n    diss[1:-2, 1:-2, :-1] = (vs.u[1:-2, 1:-2, 1:, vs.tau] - vs.u[1:-2, 1:-2, :-1, vs.tau]) \\\n        * vs.flux_top[1:-2, 1:-2, :-1] / vs.dzw[:-1]\n    diss[:, :, -1] = 0.0\n    diss[...] = numerics.ugrid_to_tgrid(vs, diss)\n    vs.K_diss_v += diss\n\n    """"""\n    implicit vertical friction of meridional momentum\n    """"""\n    kss = np.maximum(vs.kbot[1:-2, 1:-2], vs.kbot[1:-2, 2:-1]) - 1\n    fxa = 0.5 * (vs.kappaM[1:-2, 1:-2, :-1] + vs.kappaM[1:-2, 2:-1, :-1])\n    delta[:, :, :-1] = vs.dt_mom / vs.dzw[np.newaxis, np.newaxis, :-1] * \\\n        fxa * vs.maskV[1:-2, 1:-2, 1:] * vs.maskV[1:-2, 1:-2, :-1]\n    a_tri[:, :, 1:] = -delta[:, :, :-1] / vs.dzt[np.newaxis, np.newaxis, 1:]\n    b_tri[:, :, 1:] = 1 + delta[:, :, :-1] / vs.dzt[np.newaxis, np.newaxis, 1:]\n    b_tri[:, :, 1:-1] += delta[:, :, 1:-1] / vs.dzt[np.newaxis, np.newaxis, 1:-1]\n    b_tri_edge = 1 + delta / vs.dzt[np.newaxis, np.newaxis, :]\n    c_tri[:, :, :-1] = -delta[:, :, :-1] / vs.dzt[np.newaxis, np.newaxis, :-1]\n    c_tri[:, :, -1] = 0.\n    d_tri[...] = vs.v[1:-2, 1:-2, :, vs.tau]\n    res, mask = utilities.solve_implicit(vs, kss, a_tri, b_tri, c_tri, d_tri, b_edge=b_tri_edge)\n    vs.v[1:-2, 1:-2, :, vs.taup1] = utilities.where(vs, mask, res, vs.v[1:-2, 1:-2, :, vs.taup1])\n    vs.dv_mix[1:-2, 1:-2] = (vs.v[1:-2, 1:-2, :, vs.taup1] - vs.v[1:-2, 1:-2, :, vs.tau]) / vs.dt_mom\n\n    """"""\n    diagnose dissipation by vertical friction of meridional momentum\n    """"""\n    fxa = 0.5 * (vs.kappaM[1:-2, 1:-2, :-1] + vs.kappaM[1:-2, 2:-1, :-1])\n    vs.flux_top[1:-2, 1:-2, :-1] = fxa * (vs.v[1:-2, 1:-2, 1:, vs.taup1] - vs.v[1:-2, 1:-2, :-1, vs.taup1]) \\\n        / vs.dzw[:-1] * vs.maskV[1:-2, 1:-2, 1:] * vs.maskV[1:-2, 1:-2, :-1]\n    diss[1:-2, 1:-2, :-1] = (vs.v[1:-2, 1:-2, 1:, vs.tau] - vs.v[1:-2, 1:-2, :-1, vs.tau]) \\\n                             * vs.flux_top[1:-2, 1:-2, :-1] / vs.dzw[:-1]\n    diss[:, :, -1] = 0.0\n    diss = numerics.vgrid_to_tgrid(vs, diss)\n    vs.K_diss_v += diss\n\n\n@veros_method\ndef rayleigh_friction(vs):\n    """"""\n    interior Rayleigh friction\n    dissipation is calculated and added to K_diss_bot\n    """"""\n    vs.du_mix[...] += -vs.maskU * vs.r_ray * vs.u[..., vs.tau]\n    if vs.enable_conserve_energy:\n        diss = vs.maskU * vs.r_ray * vs.u[..., vs.tau]**2\n        vs.K_diss_bot[...] += numerics.calc_diss(vs, diss, \'U\')\n    vs.dv_mix[...] += -vs.maskV * vs.r_ray * vs.v[..., vs.tau]\n    if vs.enable_conserve_energy:\n        diss = vs.maskV * vs.r_ray * vs.v[..., vs.tau]**2\n        vs.K_diss_bot[...] += numerics.calc_diss(vs, diss, \'V\')\n\n\n@veros_method\ndef linear_bottom_friction(vs):\n    """"""\n    linear bottom friction\n    dissipation is calculated and added to K_diss_bot\n    """"""\n    if vs.enable_bottom_friction_var:\n        """"""\n        with spatially varying coefficient\n        """"""\n        k = np.maximum(vs.kbot[1:-2, 2:-2], vs.kbot[2:-1, 2:-2]) - 1\n        mask = np.arange(vs.nz) == k[:, :, np.newaxis]\n        vs.du_mix[1:-2, 2:-2] += -(vs.maskU[1:-2, 2:-2] * vs.r_bot_var_u[1:-2, 2:-2, np.newaxis]) \\\n                                 * vs.u[1:-2, 2:-2, :, vs.tau] * mask\n        if vs.enable_conserve_energy:\n            diss = allocate(vs, (\'xt\', \'yt\', \'zt\'))\n            diss[1:-2, 2:-2] = vs.maskU[1:-2, 2:-2] * vs.r_bot_var_u[1:-2, 2:-2, np.newaxis] \\\n                               * vs.u[1:-2, 2:-2, :, vs.tau]**2 * mask\n            vs.K_diss_bot[...] += numerics.calc_diss(vs, diss, \'U\')\n\n        k = np.maximum(vs.kbot[2:-2, 2:-1], vs.kbot[2:-2, 1:-2]) - 1\n        mask = np.arange(vs.nz) == k[:, :, np.newaxis]\n        vs.dv_mix[2:-2, 1:-2] += -(vs.maskV[2:-2, 1:-2] * vs.r_bot_var_v[2:-2, 1:-2, np.newaxis]) \\\n                                 * vs.v[2:-2, 1:-2, :, vs.tau] * mask\n        if vs.enable_conserve_energy:\n            diss = allocate(vs, (\'xt\', \'yu\', \'zt\'))\n            diss[2:-2, 1:-2] = vs.maskV[2:-2, 1:-2] * vs.r_bot_var_v[2:-2, 1:-2, np.newaxis] \\\n                               * vs.v[2:-2, 1:-2, :, vs.tau]**2 * mask\n            vs.K_diss_bot[...] += numerics.calc_diss(vs, diss, \'V\')\n    else:\n        """"""\n        with constant coefficient\n        """"""\n        k = np.maximum(vs.kbot[1:-2, 2:-2], vs.kbot[2:-1, 2:-2]) - 1\n        mask = np.arange(vs.nz) == k[:, :, np.newaxis]\n        vs.du_mix[1:-2, 2:-2] += -vs.maskU[1:-2, 2:-2] * vs.r_bot * vs.u[1:-2, 2:-2, :, vs.tau] * mask\n        if vs.enable_conserve_energy:\n            diss = allocate(vs, (\'xt\', \'yt\', \'zt\'))\n            diss[1:-2, 2:-2] = vs.maskU[1:-2, 2:-2] * vs.r_bot * vs.u[1:-2, 2:-2, :, vs.tau]**2 * mask\n            vs.K_diss_bot[...] += numerics.calc_diss(vs, diss, \'U\')\n\n        k = np.maximum(vs.kbot[2:-2, 2:-1], vs.kbot[2:-2, 1:-2]) - 1\n        mask = np.arange(vs.nz) == k[:, :, np.newaxis]\n        vs.dv_mix[2:-2, 1:-2] += -vs.maskV[2:-2, 1:-2] * vs.r_bot * vs.v[2:-2, 1:-2, :, vs.tau] * mask\n        if vs.enable_conserve_energy:\n            diss = allocate(vs, (\'xt\', \'yu\', \'zt\'))\n            diss[2:-2, 1:-2] = vs.maskV[2:-2, 1:-2] * vs.r_bot * vs.v[2:-2, 1:-2, :, vs.tau]**2 * mask\n            vs.K_diss_bot[...] += numerics.calc_diss(vs, diss, \'V\')\n\n\n@veros_method\ndef quadratic_bottom_friction(vs):\n    """"""\n    quadratic bottom friction\n    dissipation is calculated and added to K_diss_bot\n    """"""\n    # we might want to account for EKE in the drag, also a tidal residual\n    k = np.maximum(vs.kbot[1:-2, 2:-2], vs.kbot[2:-1, 2:-2]) - 1\n    mask = k[..., np.newaxis] == np.arange(vs.nz)[np.newaxis, np.newaxis, :]\n    fxa = vs.maskV[1:-2, 2:-2, :] * vs.v[1:-2, 2:-2, :, vs.tau]**2 \\\n        + vs.maskV[1:-2, 1:-3, :] * vs.v[1:-2, 1:-3, :, vs.tau]**2 \\\n        + vs.maskV[2:-1, 2:-2, :] * vs.v[2:-1, 2:-2, :, vs.tau]**2 \\\n        + vs.maskV[2:-1, 1:-3, :] * vs.v[2:-1, 1:-3, :, vs.tau]**2\n    fxa = np.sqrt(vs.u[1:-2, 2:-2, :, vs.tau]**2 + 0.25 * fxa)\n    aloc = vs.maskU[1:-2, 2:-2, :] * vs.r_quad_bot * vs.u[1:-2, 2:-2, :, vs.tau] \\\n        * fxa / vs.dzt[np.newaxis, np.newaxis, :] * mask\n    vs.du_mix[1:-2, 2:-2, :] += -aloc\n\n    if vs.enable_conserve_energy:\n        diss = allocate(vs, (\'xt\', \'yt\', \'zt\'))\n        diss[1:-2, 2:-2, :] = aloc * vs.u[1:-2, 2:-2, :, vs.tau]\n        vs.K_diss_bot[...] += numerics.calc_diss(vs, diss, \'U\')\n\n    k = np.maximum(vs.kbot[2:-2, 1:-2], vs.kbot[2:-2, 2:-1]) - 1\n    mask = k[..., np.newaxis] == np.arange(vs.nz)[np.newaxis, np.newaxis, :]\n    fxa = vs.maskU[2:-2, 1:-2, :] * vs.u[2:-2, 1:-2, :, vs.tau]**2 \\\n        + vs.maskU[1:-3, 1:-2, :] * vs.u[1:-3, 1:-2, :, vs.tau]**2 \\\n        + vs.maskU[2:-2, 2:-1, :] * vs.u[2:-2, 2:-1, :, vs.tau]**2 \\\n        + vs.maskU[1:-3, 2:-1, :] * vs.u[1:-3, 2:-1, :, vs.tau]**2\n    fxa = np.sqrt(vs.v[2:-2, 1:-2, :, vs.tau]**2 + 0.25 * fxa)\n    aloc = vs.maskV[2:-2, 1:-2, :] * vs.r_quad_bot * vs.v[2:-2, 1:-2, :, vs.tau] \\\n        * fxa / vs.dzt[np.newaxis, np.newaxis, :] * mask\n    vs.dv_mix[2:-2, 1:-2, :] += -aloc\n\n    if vs.enable_conserve_energy:\n        diss = allocate(vs, (\'xt\', \'yu\', \'zt\'))\n        diss[2:-2, 1:-2, :] = aloc * vs.v[2:-2, 1:-2, :, vs.tau]\n        vs.K_diss_bot[...] += numerics.calc_diss(vs, diss, \'V\')\n\n\n@veros_method\ndef harmonic_friction(vs):\n    """"""\n    horizontal harmonic friction\n    dissipation is calculated and added to K_diss_h\n    """"""\n    diss = allocate(vs, (\'xt\', \'yt\', \'zt\'))\n\n    """"""\n    Zonal velocity\n    """"""\n    if vs.enable_hor_friction_cos_scaling:\n        fxa = vs.cost**vs.hor_friction_cosPower\n        vs.flux_east[:-1] = vs.A_h * fxa[np.newaxis, :, np.newaxis] * (vs.u[1:, :, :, vs.tau] - vs.u[:-1, :, :, vs.tau]) \\\n            / (vs.cost * vs.dxt[1:, np.newaxis])[:, :, np.newaxis] * vs.maskU[1:] * vs.maskU[:-1]\n        fxa = vs.cosu**vs.hor_friction_cosPower\n        vs.flux_north[:, :-1] = vs.A_h * fxa[np.newaxis, :-1, np.newaxis] * (vs.u[:, 1:, :, vs.tau] - vs.u[:, :-1, :, vs.tau]) \\\n            / vs.dyu[np.newaxis, :-1, np.newaxis] * vs.maskU[:, 1:] * vs.maskU[:, :-1] * vs.cosu[np.newaxis, :-1, np.newaxis]\n        if vs.enable_noslip_lateral:\n             vs.flux_north[:, :-1] += 2 * vs.A_h * fxa[np.newaxis, :-1, np.newaxis] * (vs.u[:, 1:, :, vs.tau]) \\\n                / vs.dyu[np.newaxis, :-1, np.newaxis] * vs.maskU[:, 1:] * (1 - vs.maskU[:, :-1]) * vs.cosu[np.newaxis, :-1, np.newaxis]\\\n                - 2 * vs.A_h * fxa[np.newaxis, :-1, np.newaxis] * (vs.u[:, :-1, :, vs.tau]) \\\n                / vs.dyu[np.newaxis, :-1, np.newaxis] * (1 - vs.maskU[:, 1:]) * vs.maskU[:, :-1] * vs.cosu[np.newaxis, :-1, np.newaxis]\n    else:\n        vs.flux_east[:-1, :, :] = vs.A_h * (vs.u[1:, :, :, vs.tau] - vs.u[:-1, :, :, vs.tau]) \\\n            / (vs.cost * vs.dxt[1:, np.newaxis])[:, :, np.newaxis] * vs.maskU[1:] * vs.maskU[:-1]\n        vs.flux_north[:, :-1, :] = vs.A_h * (vs.u[:, 1:, :, vs.tau] - vs.u[:, :-1, :, vs.tau]) \\\n            / vs.dyu[np.newaxis, :-1, np.newaxis] * vs.maskU[:, 1:] * vs.maskU[:, :-1] * vs.cosu[np.newaxis, :-1, np.newaxis]\n        if vs.enable_noslip_lateral:\n             vs.flux_north[:, :-1] += 2 * vs.A_h * vs.u[:, 1:, :, vs.tau] / vs.dyu[np.newaxis, :-1, np.newaxis] \\\n                * vs.maskU[:, 1:] * (1 - vs.maskU[:, :-1]) * vs.cosu[np.newaxis, :-1, np.newaxis]\\\n                - 2 * vs.A_h * vs.u[:, :-1, :, vs.tau] / vs.dyu[np.newaxis, :-1, np.newaxis] \\\n                * (1 - vs.maskU[:, 1:]) * vs.maskU[:, :-1] * vs.cosu[np.newaxis, :-1, np.newaxis]\n\n    vs.flux_east[-1, :, :] = 0.\n    vs.flux_north[:, -1, :] = 0.\n\n    """"""\n    update tendency\n    """"""\n    vs.du_mix[2:-2, 2:-2, :] += vs.maskU[2:-2, 2:-2] * ((vs.flux_east[2:-2, 2:-2] - vs.flux_east[1:-3, 2:-2])\n                                                              / (vs.cost[2:-2] * vs.dxu[2:-2, np.newaxis])[:, :, np.newaxis]\n                                                              + (vs.flux_north[2:-2, 2:-2] - vs.flux_north[2:-2, 1:-3])\n                                                              / (vs.cost[2:-2] * vs.dyt[2:-2])[np.newaxis, :, np.newaxis])\n\n    if vs.enable_conserve_energy:\n        """"""\n        diagnose dissipation by lateral friction\n        """"""\n        diss[1:-2, 2:-2] = 0.5 * ((vs.u[2:-1, 2:-2, :, vs.tau] - vs.u[1:-2, 2:-2, :, vs.tau]) * vs.flux_east[1:-2, 2:-2]\n                                + (vs.u[1:-2, 2:-2, :, vs.tau] - vs.u[:-3, 2:-2, :, vs.tau]) * vs.flux_east[:-3, 2:-2]) \\\n            / (vs.cost[2:-2] * vs.dxu[1:-2, np.newaxis])[:, :, np.newaxis]\\\n            + 0.5 * ((vs.u[1:-2, 3:-1, :, vs.tau] - vs.u[1:-2, 2:-2, :, vs.tau]) * vs.flux_north[1:-2, 2:-2]\n                   + (vs.u[1:-2, 2:-2, :, vs.tau] - vs.u[1:-2, 1:-3, :, vs.tau]) * vs.flux_north[1:-2, 1:-3]) \\\n            / (vs.cost[2:-2] * vs.dyt[2:-2])[np.newaxis, :, np.newaxis]\n        vs.K_diss_h[...] = 0.\n        vs.K_diss_h[...] += numerics.calc_diss(vs, diss, \'U\')\n\n    """"""\n    Meridional velocity\n    """"""\n    if vs.enable_hor_friction_cos_scaling:\n        vs.flux_east[:-1] = vs.A_h * vs.cosu[np.newaxis, :, np.newaxis] ** vs.hor_friction_cosPower \\\n            * (vs.v[1:, :, :, vs.tau] - vs.v[:-1, :, :, vs.tau]) \\\n            / (vs.cosu * vs.dxu[:-1, np.newaxis])[:, :, np.newaxis] * vs.maskV[1:] * vs.maskV[:-1]\n        if vs.enable_noslip_lateral:\n            vs.flux_east[:-1] += 2 * vs.A_h * fxa[np.newaxis, :, np.newaxis] * vs.v[1:, :, :, vs.tau] \\\n                / (vs.cosu * vs.dxu[:-1, np.newaxis])[:, :, np.newaxis] * vs.maskV[1:] * (1 - vs.maskV[:-1]) \\\n                - 2 * vs.A_h * fxa[np.newaxis, :, np.newaxis] * vs.v[:-1, :, :, vs.tau] \\\n                / (vs.cosu * vs.dxu[:-1, np.newaxis])[:, :, np.newaxis] * (1 - vs.maskV[1:]) * vs.maskV[:-1]\n\n        vs.flux_north[:, :-1] = vs.A_h * vs.cost[np.newaxis, 1:, np.newaxis] ** vs.hor_friction_cosPower \\\n            * (vs.v[:, 1:, :, vs.tau] - vs.v[:, :-1, :, vs.tau]) \\\n            / vs.dyt[np.newaxis, 1:, np.newaxis] * vs.cost[np.newaxis, 1:, np.newaxis] * vs.maskV[:, :-1] * vs.maskV[:, 1:]\n    else:\n        vs.flux_east[:-1] = vs.A_h * (vs.v[1:, :, :, vs.tau] - vs.v[:-1, :, :, vs.tau]) \\\n            / (vs.cosu * vs.dxu[:-1, np.newaxis])[:, :, np.newaxis] * vs.maskV[1:] * vs.maskV[:-1]\n        if vs.enable_noslip_lateral:\n            vs.flux_east[:-1] += 2 * vs.A_h * vs.v[1:, :, :, vs.tau] / (vs.cosu * vs.dxu[:-1, np.newaxis])[:, :, np.newaxis] \\\n                * vs.maskV[1:] * (1 - vs.maskV[:-1]) \\\n                - 2 * vs.A_h * vs.v[:-1, :, :, vs.tau] / (vs.cosu * vs.dxu[:-1, np.newaxis])[:, :, np.newaxis] \\\n                * (1 - vs.maskV[1:]) * vs.maskV[:-1]\n        vs.flux_north[:, :-1] = vs.A_h * (vs.v[:, 1:, :, vs.tau] - vs.v[:, :-1, :, vs.tau]) \\\n            / vs.dyt[np.newaxis, 1:, np.newaxis] * vs.cost[np.newaxis, 1:, np.newaxis] * vs.maskV[:, :-1] * vs.maskV[:, 1:]\n    vs.flux_east[-1, :, :] = 0.\n    vs.flux_north[:, -1, :] = 0.\n\n    """"""\n    update tendency\n    """"""\n    vs.dv_mix[2:-2, 2:-2] += vs.maskV[2:-2, 2:-2] * ((vs.flux_east[2:-2, 2:-2] - vs.flux_east[1:-3, 2:-2])\n                                                   / (vs.cosu[2:-2] * vs.dxt[2:-2, np.newaxis])[:, :, np.newaxis]\n                                                   + (vs.flux_north[2:-2, 2:-2] - vs.flux_north[2:-2, 1:-3])\n                                                   / (vs.dyu[2:-2] * vs.cosu[2:-2])[np.newaxis, :, np.newaxis])\n\n    if vs.enable_conserve_energy:\n        """"""\n        diagnose dissipation by lateral friction\n        """"""\n        diss[2:-2, 1:-2] = 0.5 * ((vs.v[3:-1, 1:-2, :, vs.tau] - vs.v[2:-2, 1:-2, :, vs.tau]) * vs.flux_east[2:-2, 1:-2]\n                                + (vs.v[2:-2, 1:-2, :, vs.tau] - vs.v[1:-3, 1:-2, :, vs.tau]) * vs.flux_east[1:-3, 1:-2]) \\\n            / (vs.cosu[1:-2] * vs.dxt[2:-2, np.newaxis])[:, :, np.newaxis] \\\n            + 0.5 * ((vs.v[2:-2, 2:-1, :, vs.tau] - vs.v[2:-2, 1:-2, :, vs.tau]) * vs.flux_north[2:-2, 1:-2]\n                   + (vs.v[2:-2, 1:-2, :, vs.tau] - vs.v[2:-2, :-3, :, vs.tau]) * vs.flux_north[2:-2, :-3]) \\\n            / (vs.cosu[1:-2] * vs.dyu[1:-2])[np.newaxis, :, np.newaxis]\n        vs.K_diss_h[...] += numerics.calc_diss(vs, diss, \'V\')\n\n\n@veros_method\ndef biharmonic_friction(vs):\n    """"""\n    horizontal biharmonic friction\n    dissipation is calculated and added to K_diss_h\n    """"""\n    fxa = math.sqrt(abs(vs.A_hbi))\n\n    """"""\n    Zonal velocity\n    """"""\n    vs.flux_east[:-1, :, :] = fxa * (vs.u[1:, :, :, vs.tau] - vs.u[:-1, :, :, vs.tau]) \\\n        / (vs.cost[np.newaxis, :, np.newaxis] * vs.dxt[1:, np.newaxis, np.newaxis]) \\\n        * vs.maskU[1:, :, :] * vs.maskU[:-1, :, :]\n    vs.flux_north[:, :-1, :] = fxa * (vs.u[:, 1:, :, vs.tau] - vs.u[:, :-1, :, vs.tau]) \\\n        / vs.dyu[np.newaxis, :-1, np.newaxis] * vs.maskU[:, 1:, :] \\\n        * vs.maskU[:, :-1, :] * vs.cosu[np.newaxis, :-1, np.newaxis]\n    if vs.enable_noslip_lateral:\n        vs.flux_north[:, :-1] += 2 * fxa * vs.u[:, 1:, :, vs.tau] / vs.dyu[np.newaxis, :-1, np.newaxis] \\\n            * vs.maskU[:, 1:] * (1 - vs.maskU[:, :-1]) * vs.cosu[np.newaxis, :-1, np.newaxis]\\\n            - 2 * fxa * vs.u[:, :-1, :, vs.tau] / vs.dyu[np.newaxis, :-1, np.newaxis] \\\n            * (1 - vs.maskU[:, 1:]) * vs.maskU[:, :-1] * vs.cosu[np.newaxis, :-1, np.newaxis]\n    vs.flux_east[-1, :, :] = 0.\n    vs.flux_north[:, -1, :] = 0.\n\n    del2 = allocate(vs, (\'xt\', \'yt\', \'zt\'))\n    del2[1:, 1:, :] = (vs.flux_east[1:, 1:, :] - vs.flux_east[:-1, 1:, :]) \\\n        / (vs.cost[np.newaxis, 1:, np.newaxis] * vs.dxu[1:, np.newaxis, np.newaxis]) \\\n        + (vs.flux_north[1:, 1:, :] - vs.flux_north[1:, :-1, :]) \\\n        / (vs.cost[np.newaxis, 1:, np.newaxis] * vs.dyt[np.newaxis, 1:, np.newaxis])\n\n    vs.flux_east[:-1, :, :] = fxa * (del2[1:, :, :] - del2[:-1, :, :]) \\\n        / (vs.cost[np.newaxis, :, np.newaxis] * vs.dxt[1:, np.newaxis, np.newaxis]) \\\n        * vs.maskU[1:, :, :] * vs.maskU[:-1, :, :]\n    vs.flux_north[:, :-1, :] = fxa * (del2[:, 1:, :] - del2[:, :-1, :]) \\\n        / vs.dyu[np.newaxis, :-1, np.newaxis] * vs.maskU[:, 1:, :] \\\n        * vs.maskU[:, :-1, :] * vs.cosu[np.newaxis, :-1, np.newaxis]\n    if vs.enable_noslip_lateral:\n        vs.flux_north[:,:-1,:] += 2 * fxa * del2[:, 1:, :] / vs.dyu[np.newaxis, :-1, np.newaxis] \\\n            * vs.maskU[:, 1:, :] * (1 - vs.maskU[:, :-1, :]) * vs.cosu[np.newaxis, :-1, np.newaxis] \\\n            - 2 * fxa * del2[:, :-1, :] / vs.dyu[np.newaxis, :-1, np.newaxis] \\\n            * (1 - vs.maskU[:, 1:, :]) * vs.maskU[:, :-1, :] * vs.cosu[np.newaxis, :-1, np.newaxis]\n    vs.flux_east[-1, :, :] = 0.\n    vs.flux_north[:, -1, :] = 0.\n\n    """"""\n    update tendency\n    """"""\n    vs.du_mix[2:-2, 2:-2, :] += -vs.maskU[2:-2, 2:-2, :] * ((vs.flux_east[2:-2, 2:-2, :] - vs.flux_east[1:-3, 2:-2, :])\n                                                          / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxu[2:-2, np.newaxis, np.newaxis])\n                                                          + (vs.flux_north[2:-2, 2:-2, :] - vs.flux_north[2:-2, 1:-3, :])\n                                                          / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dyt[np.newaxis, 2:-2, np.newaxis]))\n    if vs.enable_conserve_energy:\n        """"""\n        diagnose dissipation by lateral friction\n        """"""\n        utilities.enforce_boundaries(vs, vs.flux_east)\n        utilities.enforce_boundaries(vs, vs.flux_north)\n        diss = allocate(vs, (\'xt\', \'yt\', \'zt\'))\n        diss[1:-2, 2:-2, :] = -0.5 * ((vs.u[2:-1, 2:-2, :, vs.tau] - vs.u[1:-2, 2:-2, :, vs.tau]) * vs.flux_east[1:-2, 2:-2, :]\n                                    + (vs.u[1:-2, 2:-2, :, vs.tau] - vs.u[:-3, 2:-2, :, vs.tau]) * vs.flux_east[:-3, 2:-2, :]) \\\n            / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxu[1:-2, np.newaxis, np.newaxis])  \\\n            - 0.5 * ((vs.u[1:-2, 3:-1, :, vs.tau] - vs.u[1:-2, 2:-2, :, vs.tau]) * vs.flux_north[1:-2, 2:-2, :]\n                   + (vs.u[1:-2, 2:-2, :, vs.tau] - vs.u[1:-2, 1:-3, :, vs.tau]) * vs.flux_north[1:-2, 1:-3, :]) \\\n            / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dyt[np.newaxis, 2:-2, np.newaxis])\n        vs.K_diss_h[...] = 0.\n        vs.K_diss_h[...] += numerics.calc_diss(vs, diss, \'U\')\n\n    """"""\n    Meridional velocity\n    """"""\n    vs.flux_east[:-1, :, :] = fxa * (vs.v[1:, :, :, vs.tau] - vs.v[:-1, :, :, vs.tau]) \\\n        / (vs.cosu[np.newaxis, :, np.newaxis] * vs.dxu[:-1, np.newaxis, np.newaxis]) \\\n        * vs.maskV[1:, :, :] * vs.maskV[:-1, :, :]\n    if vs.enable_noslip_lateral:\n        vs.flux_east[:-1, :, :] += 2 * fxa * vs.v[1:, :, :, vs.tau] / (vs.cosu[np.newaxis, :, np.newaxis] * vs.dxu[:-1, np.newaxis, np.newaxis]) \\\n            * vs.maskV[1:, :, :] * (1 - vs.maskV[:-1, :, :]) \\\n            - 2 * fxa * vs.v[:-1, :, :, vs.tau] / (vs.cosu[np.newaxis, :, np.newaxis] * vs.dxu[:-1, np.newaxis, np.newaxis]) \\\n            * (1 - vs.maskV[1:, :, :]) * vs.maskV[:-1, :, :] \n    vs.flux_north[:, :-1, :] = fxa * (vs.v[:, 1:, :, vs.tau] - vs.v[:, :-1, :, vs.tau]) \\\n        / vs.dyt[np.newaxis, 1:, np.newaxis] * vs.cost[np.newaxis, 1:, np.newaxis] \\\n        * vs.maskV[:, :-1, :] * vs.maskV[:, 1:, :]\n    vs.flux_east[-1, :, :] = 0.\n    vs.flux_north[:, -1, :] = 0.\n\n    del2[1:, 1:, :] = (vs.flux_east[1:, 1:, :] - vs.flux_east[:-1, 1:, :]) \\\n        / (vs.cosu[np.newaxis, 1:, np.newaxis] * vs.dxt[1:, np.newaxis, np.newaxis])  \\\n        + (vs.flux_north[1:, 1:, :] - vs.flux_north[1:, :-1, :]) \\\n        / (vs.dyu[np.newaxis, 1:, np.newaxis] * vs.cosu[np.newaxis, 1:, np.newaxis])\n\n    vs.flux_east[:-1, :, :] = fxa * (del2[1:, :, :] - del2[:-1, :, :]) \\\n        / (vs.cosu[np.newaxis, :, np.newaxis] * vs.dxu[:-1, np.newaxis, np.newaxis]) \\\n        * vs.maskV[1:, :, :] * vs.maskV[:-1, :, :]\n    if vs.enable_noslip_lateral:\n        vs.flux_east[:-1, :, :] += 2 * fxa * del2[1:, :, :] / (vs.cosu[np.newaxis, :, np.newaxis] * vs.dxu[:-1, np.newaxis, np.newaxis]) \\\n            * vs.maskV[1:, :, :] * (1 - vs.maskV[:-1, :, :]) \\\n            - 2 * fxa * del2[:-1, :, :] / (vs.cosu[np.newaxis, :, np.newaxis] * vs.dxu[:-1, np.newaxis, np.newaxis]) \\\n            * (1 - vs.maskV[1:, :, :]) * vs.maskV[:-1, :, :] \n    vs.flux_north[:, :-1, :] = fxa * (del2[:, 1:, :] - del2[:, :-1, :]) \\\n        / vs.dyt[np.newaxis, 1:, np.newaxis] * vs.cost[np.newaxis, 1:, np.newaxis] \\\n        * vs.maskV[:, :-1, :] * vs.maskV[:, 1:, :]\n    vs.flux_east[-1, :, :] = 0.\n    vs.flux_north[:, -1, :] = 0.\n\n    """"""\n    update tendency\n    """"""\n    vs.dv_mix[2:-2, 2:-2, :] += -vs.maskV[2:-2, 2:-2, :] * ((vs.flux_east[2:-2, 2:-2, :] - vs.flux_east[1:-3, 2:-2, :])\n                                                            / (vs.cosu[np.newaxis, 2:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis])\n                                                            + (vs.flux_north[2:-2, 2:-2, :] - vs.flux_north[2:-2, 1:-3, :])\n                                                            / (vs.dyu[np.newaxis, 2:-2, np.newaxis] * vs.cosu[np.newaxis, 2:-2, np.newaxis]))\n\n    if vs.enable_conserve_energy:\n        """"""\n        diagnose dissipation by lateral friction\n        """"""\n        utilities.enforce_boundaries(vs, vs.flux_east)\n        utilities.enforce_boundaries(vs, vs.flux_north)\n        diss[2:-2, 1:-2, :] = -0.5 * ((vs.v[3:-1, 1:-2, :, vs.tau] - vs.v[2:-2, 1:-2, :, vs.tau]) * vs.flux_east[2:-2, 1:-2, :]\n                                    + (vs.v[2:-2, 1:-2, :, vs.tau] - vs.v[1:-3, 1:-2, :, vs.tau]) * vs.flux_east[1:-3, 1:-2, :]) \\\n            / (vs.cosu[np.newaxis, 1:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis]) \\\n            - 0.5 * ((vs.v[2:-2, 2:-1, :, vs.tau] - vs.v[2:-2, 1:-2, :, vs.tau]) * vs.flux_north[2:-2, 1:-2, :]\n                   + (vs.v[2:-2, 1:-2, :, vs.tau] - vs.v[2:-2, :-3, :, vs.tau]) * vs.flux_north[2:-2, :-3, :]) \\\n            / (vs.cosu[np.newaxis, 1:-2, np.newaxis] * vs.dyu[np.newaxis, 1:-2, np.newaxis])\n        vs.K_diss_h[...] += numerics.calc_diss(vs, diss, \'V\')\n\n\n@veros_method\ndef momentum_sources(vs):\n    """"""\n    other momentum sources\n    dissipation is calculated and added to K_diss_bot\n    """"""\n    vs.du_mix[...] += vs.maskU * vs.u_source\n    if vs.enable_conserve_energy:\n        diss = -vs.maskU * vs.u[..., vs.tau] * vs.u_source\n        vs.K_diss_bot[...] += numerics.calc_diss(vs, diss, \'U\')\n    vs.dv_mix[...] += vs.maskV * vs.v_source\n    if vs.enable_conserve_energy:\n        diss = -vs.maskV * vs.v[..., vs.tau] * vs.v_source\n        vs.K_diss_bot[...] += numerics.calc_diss(vs, diss, \'V\')\n'"
veros/core/idemix.py,37,"b'from . import advection, utilities\nfrom .. import veros_method, runtime_settings as rs\nfrom ..variables import allocate\n\n""""""\nIDEMIX as in Olbers and Eden, 2013\n""""""\n\n\n@veros_method\ndef set_idemix_parameter(vs):\n    """"""\n    set main IDEMIX parameter\n    """"""\n    bN0 = np.sum(np.sqrt(np.maximum(0., vs.Nsqr[:, :, :-1, vs.tau]))\n                 * vs.dzw[np.newaxis, np.newaxis, :-1] * vs.maskW[:, :, :-1], axis=2) \\\n        + np.sqrt(np.maximum(0., vs.Nsqr[:, :, -1, vs.tau])) \\\n        * 0.5 * vs.dzw[-1:] * vs.maskW[:, :, -1]\n    fxa = np.sqrt(np.maximum(0., vs.Nsqr[..., vs.tau])) / \\\n        (1e-22 + np.abs(vs.coriolis_t[..., np.newaxis]))\n    cstar = np.maximum(1e-2, bN0[:, :, np.newaxis] / (vs.pi * vs.jstar))\n    vs.c0[...] = np.maximum(0., vs.gamma * cstar * gofx2(vs, fxa) * vs.maskW)\n    vs.v0[...] = np.maximum(0., vs.gamma * cstar * hofx1(vs, fxa) * vs.maskW)\n    vs.alpha_c[...] = np.maximum(1e-4, vs.mu0 * np.arccosh(np.maximum(1., fxa))\n                                 * np.abs(vs.coriolis_t[..., np.newaxis]) / cstar**2) * vs.maskW\n\n\n@veros_method\ndef integrate_idemix(vs):\n    """"""\n    integrate idemix on W grid\n    """"""\n    a_tri, b_tri, c_tri, d_tri, delta = (allocate(vs, (\'xt\', \'yt\', \'zw\'), include_ghosts=False) for _ in range(5))\n    forc = allocate(vs, (\'xt\', \'yt\', \'zw\'))\n    maxE_iw = allocate(vs, (\'xt\', \'yt\', \'zw\'))\n\n    """"""\n    forcing by EKE dissipation\n    """"""\n    if vs.enable_eke:\n        forc[...] = vs.eke_diss_iw\n    else:  # shortcut without EKE model\n        if vs.enable_store_cabbeling_heat:\n            forc[...] = vs.K_diss_gm + vs.K_diss_h - \\\n                vs.P_diss_skew - vs.P_diss_hmix - vs.P_diss_iso\n        else:\n            forc[...] = vs.K_diss_gm + vs.K_diss_h - vs.P_diss_skew\n\n    if vs.enable_eke and (vs.enable_eke_diss_bottom or vs.enable_eke_diss_surfbot):\n        """"""\n        vertically integrate EKE dissipation and inject at bottom and/or surface\n        """"""\n        a_loc = np.sum(vs.dzw[np.newaxis, np.newaxis, :-1] *\n                       forc[:, :, :-1] * vs.maskW[:, :, :-1], axis=2)\n        a_loc += 0.5 * forc[:, :, -1] * vs.maskW[:, :, -1] * vs.dzw[-1]\n        forc[...] = 0.\n\n        ks = np.maximum(0, vs.kbot[2:-2, 2:-2] - 1)\n        mask = ks[:, :, np.newaxis] == np.arange(vs.nz)[np.newaxis, np.newaxis, :]\n        if vs.enable_eke_diss_bottom:\n            forc[2:-2, 2:-2, :] = utilities.where(vs, mask, a_loc[2:-2, 2:-2, np.newaxis] /\n                                           vs.dzw[np.newaxis, np.newaxis, :], forc[2:-2, 2:-2, :])\n        else:\n            forc[2:-2, 2:-2, :] = utilities.where(vs, mask, vs.eke_diss_surfbot_frac * a_loc[2:-2, 2:-2, np.newaxis]\n                                           / vs.dzw[np.newaxis, np.newaxis, :], forc[2:-2, 2:-2, :])\n            forc[2:-2, 2:-2, -1] = (1. - vs.eke_diss_surfbot_frac) \\\n                                    * a_loc[2:-2, 2:-2] / (0.5 * vs.dzw[-1])\n\n    """"""\n    forcing by bottom friction\n    """"""\n    if not vs.enable_store_bottom_friction_tke:\n        forc += vs.K_diss_bot\n\n    """"""\n    prevent negative dissipation of IW energy\n    """"""\n    maxE_iw[...] = np.maximum(0., vs.E_iw[:, :, :, vs.tau])\n\n    """"""\n    vertical diffusion and dissipation is solved implicitly\n    """"""\n    ks = vs.kbot[2:-2, 2:-2] - 1\n    delta[:, :, :-1] = vs.dt_tracer * vs.tau_v / vs.dzt[np.newaxis, np.newaxis, 1:] * 0.5 \\\n        * (vs.c0[2:-2, 2:-2, :-1] + vs.c0[2:-2, 2:-2, 1:])\n    delta[:, :, -1] = 0.\n    a_tri[:, :, 1:-1] = -delta[:, :, :-2] * vs.c0[2:-2, 2:-2, :-2] \\\n        / vs.dzw[np.newaxis, np.newaxis, 1:-1]\n    a_tri[:, :, -1] = -delta[:, :, -2] / (0.5 * vs.dzw[-1:]) * vs.c0[2:-2, 2:-2, -2]\n    b_tri[:, :, 1:-1] = 1 + delta[:, :, 1:-1] * vs.c0[2:-2, 2:-2, 1:-1] / vs.dzw[np.newaxis, np.newaxis, 1:-1] \\\n        + delta[:, :, :-2] * vs.c0[2:-2, 2:-2, 1:-1] / vs.dzw[np.newaxis, np.newaxis, 1:-1] \\\n        + vs.dt_tracer * vs.alpha_c[2:-2, 2:-2, 1:-1] * maxE_iw[2:-2, 2:-2, 1:-1]\n    b_tri[:, :, -1] = 1 + delta[:, :, -2] / (0.5 * vs.dzw[-1:]) * vs.c0[2:-2, 2:-2, -1] \\\n        + vs.dt_tracer * vs.alpha_c[2:-2, 2:-2, -1] * maxE_iw[2:-2, 2:-2, -1]\n    b_tri_edge = 1 + delta / vs.dzw * vs.c0[2:-2, 2:-2, :] \\\n        + vs.dt_tracer * vs.alpha_c[2:-2, 2:-2, :] * maxE_iw[2:-2, 2:-2, :]\n    c_tri[:, :, :-1] = -delta[:, :, :-1] / \\\n        vs.dzw[np.newaxis, np.newaxis, :-1] * vs.c0[2:-2, 2:-2, 1:]\n    d_tri[...] = vs.E_iw[2:-2, 2:-2, :, vs.tau] + vs.dt_tracer * forc[2:-2, 2:-2, :]\n    d_tri_edge = d_tri + vs.dt_tracer * \\\n        vs.forc_iw_bottom[2:-2, 2:-2, np.newaxis] / vs.dzw[np.newaxis, np.newaxis, :]\n    d_tri[:, :, -1] += vs.dt_tracer * vs.forc_iw_surface[2:-2, 2:-2] / (0.5 * vs.dzw[-1:])\n    sol, water_mask = utilities.solve_implicit(vs, ks, a_tri, b_tri, c_tri, d_tri, b_edge=b_tri_edge, d_edge=d_tri_edge)\n    vs.E_iw[2:-2, 2:-2, :, vs.taup1] = utilities.where(vs, water_mask, sol, vs.E_iw[2:-2, 2:-2, :, vs.taup1])\n\n    """"""\n    store IW dissipation\n    """"""\n    vs.iw_diss[...] = vs.alpha_c * maxE_iw * vs.E_iw[..., vs.taup1]\n\n    """"""\n    add tendency due to lateral diffusion\n    """"""\n    if vs.enable_idemix_hor_diffusion:\n        vs.flux_east[:-1, :, :] = vs.tau_h * 0.5 * (vs.v0[1:, :, :] + vs.v0[:-1, :, :]) \\\n            * (vs.v0[1:, :, :] * vs.E_iw[1:, :, :, vs.tau] - vs.v0[:-1, :, :] * vs.E_iw[:-1, :, :, vs.tau]) \\\n            / (vs.cost[np.newaxis, :, np.newaxis] * vs.dxu[:-1, np.newaxis, np.newaxis]) * vs.maskU[:-1, :, :]\n        if vs.pyom_compatibility_mode:\n            vs.flux_east[-5, :, :] = 0.\n        else:\n            vs.flux_east[-1, :, :] = 0.\n        vs.flux_north[:, :-1, :] = vs.tau_h * 0.5 * (vs.v0[:, 1:, :] + vs.v0[:, :-1, :]) \\\n            * (vs.v0[:, 1:, :] * vs.E_iw[:, 1:, :, vs.tau] - vs.v0[:, :-1, :] * vs.E_iw[:, :-1, :, vs.tau]) \\\n            / vs.dyu[np.newaxis, :-1, np.newaxis] * vs.maskV[:, :-1, :] * vs.cosu[np.newaxis, :-1, np.newaxis]\n        vs.flux_north[:, -1, :] = 0.\n        vs.E_iw[2:-2, 2:-2, :, vs.taup1] += vs.dt_tracer * vs.maskW[2:-2, 2:-2, :] \\\n            * ((vs.flux_east[2:-2, 2:-2, :] - vs.flux_east[1:-3, 2:-2, :])\n               / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis])\n               + (vs.flux_north[2:-2, 2:-2, :] - vs.flux_north[2:-2, 1:-3, :])\n               / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dyt[np.newaxis, 2:-2, np.newaxis]))\n\n    """"""\n    add tendency due to advection\n    """"""\n    if vs.enable_idemix_superbee_advection:\n        advection.adv_flux_superbee_wgrid(\n            vs, vs.flux_east, vs.flux_north, vs.flux_top, vs.E_iw[:, :, :, vs.tau])\n\n    if vs.enable_idemix_upwind_advection:\n        advection.adv_flux_upwind_wgrid(\n            vs, vs.flux_east, vs.flux_north, vs.flux_top, vs.E_iw[:, :, :, vs.tau])\n\n    if vs.enable_idemix_superbee_advection or vs.enable_idemix_upwind_advection:\n        vs.dE_iw[2:-2, 2:-2, :, vs.tau] = vs.maskW[2:-2, 2:-2, :] * (-(vs.flux_east[2:-2, 2:-2, :] - vs.flux_east[1:-3, 2:-2, :])\n                                                                    / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis])\n                                                                    - (vs.flux_north[2:-2, 2:-2, :] - vs.flux_north[2:-2, 1:-3, :])\n                                                                    / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dyt[np.newaxis, 2:-2, np.newaxis]))\n        vs.dE_iw[:, :, 0, vs.tau] += -vs.flux_top[:, :, 0] / vs.dzw[0:1]\n        vs.dE_iw[:, :, 1:-1, vs.tau] += -(vs.flux_top[:, :, 1:-1] - vs.flux_top[:, :, :-2]) \\\n            / vs.dzw[np.newaxis, np.newaxis, 1:-1]\n        vs.dE_iw[:, :, -1, vs.tau] += - \\\n            (vs.flux_top[:, :, -1] - vs.flux_top[:, :, -2]) / (0.5 * vs.dzw[-1:])\n\n        """"""\n        Adam Bashforth time stepping\n        """"""\n        vs.E_iw[:, :, :, vs.taup1] += vs.dt_tracer * ((1.5 + vs.AB_eps) * vs.dE_iw[:, :, :, vs.tau]\n                                                    - (0.5 + vs.AB_eps) * vs.dE_iw[:, :, :, vs.taum1])\n\n\n@veros_method\ndef gofx2(vs, x):\n    if vs.pyom_compatibility_mode:\n        x[x < 3.] = 3.\n    else:\n        x = np.maximum(3., x)\n    c = 1. - (2. / vs.pi) * np.arcsin(1. / x)\n    return 2. / vs.pi / c * 0.9 * x**(-2. / 3.) * (1 - np.exp(-x / 4.3))\n\n\n@veros_method\ndef hofx1(vs, x):\n    eps = np.finfo(x.dtype).eps  # prevent division by zero\n    x = np.maximum(1. + eps, x)\n    return (2. / vs.pi) / (1. - (2. / vs.pi) * np.arcsin(1. / x)) * (x - 1.) / (x + 1.)\n'"
veros/core/momentum.py,38,"b'from .. import veros_method\nfrom ..variables import allocate\nfrom . import friction, isoneutral, streamfunction\n\n\n@veros_method\ndef momentum(vs):\n    """"""\n    solve for momentum for taup1\n    """"""\n\n    """"""\n    time tendency due to Coriolis force\n    """"""\n    vs.du_cor[2:-2, 2:-2] = vs.maskU[2:-2, 2:-2] \\\n        * (vs.coriolis_t[2:-2, 2:-2, np.newaxis] * (vs.v[2:-2, 2:-2, :, vs.tau] + vs.v[2:-2, 1:-3, :, vs.tau])\n           * vs.dxt[2:-2, np.newaxis, np.newaxis] / vs.dxu[2:-2, np.newaxis, np.newaxis]\n            + vs.coriolis_t[3:-1, 2:-2, np.newaxis] *\n           (vs.v[3:-1, 2:-2, :, vs.tau] + vs.v[3:-1, 1:-3, :, vs.tau])\n           * vs.dxt[3:-1, np.newaxis, np.newaxis] / vs.dxu[2:-2, np.newaxis, np.newaxis]) * 0.25\n    vs.dv_cor[2:-2, 2:-2] = -vs.maskV[2:-2, 2:-2] \\\n        * (vs.coriolis_t[2:-2, 2:-2, np.newaxis] * (vs.u[1:-3, 2:-2, :, vs.tau] + vs.u[2:-2, 2:-2, :, vs.tau])\n           * vs.dyt[np.newaxis, 2:-2, np.newaxis] * vs.cost[np.newaxis, 2:-2, np.newaxis]\n           / (vs.dyu[np.newaxis, 2:-2, np.newaxis] * vs.cosu[np.newaxis, 2:-2, np.newaxis])\n           + vs.coriolis_t[2:-2, 3:-1, np.newaxis]\n           * (vs.u[1:-3, 3:-1, :, vs.tau] + vs.u[2:-2, 3:-1, :, vs.tau])\n           * vs.dyt[np.newaxis, 3:-1, np.newaxis] * vs.cost[np.newaxis, 3:-1, np.newaxis]\n           / (vs.dyu[np.newaxis, 2:-2, np.newaxis] * vs.cosu[np.newaxis, 2:-2, np.newaxis])) * 0.25\n\n    """"""\n    time tendency due to metric terms\n    """"""\n    if vs.coord_degree:\n        vs.du_cor[2:-2, 2:-2] += vs.maskU[2:-2, 2:-2] * 0.125 * vs.tantr[np.newaxis, 2:-2, np.newaxis] \\\n            * ((vs.u[2:-2, 2:-2, :, vs.tau] + vs.u[1:-3, 2:-2, :, vs.tau])\n               * (vs.v[2:-2, 2:-2, :, vs.tau] + vs.v[2:-2, 1:-3, :, vs.tau])\n               * vs.dxt[2:-2, np.newaxis, np.newaxis] / vs.dxu[2:-2, np.newaxis, np.newaxis]\n               + (vs.u[3:-1, 2:-2, :, vs.tau] + vs.u[2:-2, 2:-2, :, vs.tau])\n               * (vs.v[3:-1, 2:-2, :, vs.tau] + vs.v[3:-1, 1:-3, :, vs.tau])\n               * vs.dxt[3:-1, np.newaxis, np.newaxis] / vs.dxu[2:-2, np.newaxis, np.newaxis])\n        vs.dv_cor[2:-2, 2:-2] += -vs.maskV[2:-2, 2:-2] * 0.125 \\\n            * (vs.tantr[np.newaxis, 2:-2, np.newaxis] * (vs.u[2:-2, 2:-2, :, vs.tau] + vs.u[1:-3, 2:-2, :, vs.tau])**2\n               * vs.dyt[np.newaxis, 2:-2, np.newaxis] * vs.cost[np.newaxis, 2:-2, np.newaxis]\n               / (vs.dyu[np.newaxis, 2:-2, np.newaxis] * vs.cosu[np.newaxis, 2:-2, np.newaxis])\n               + vs.tantr[np.newaxis, 3:-1, np.newaxis]\n               * (vs.u[2:-2, 3:-1, :, vs.tau] + vs.u[1:-3, 3:-1, :, vs.tau])**2\n               * vs.dyt[np.newaxis, 3:-1, np.newaxis] * vs.cost[np.newaxis, 3:-1, np.newaxis]\n               / (vs.dyu[np.newaxis, 2:-2, np.newaxis] * vs.cosu[np.newaxis, 2:-2, np.newaxis]))\n\n    """"""\n    transfer to time tendencies\n    """"""\n    vs.du[2:-2, 2:-2, :, vs.tau] = vs.du_cor[2:-2, 2:-2]\n    vs.dv[2:-2, 2:-2, :, vs.tau] = vs.dv_cor[2:-2, 2:-2]\n\n    """"""\n    wind stress forcing\n    """"""\n    if vs.pyom_compatibility_mode:\n        vs.du[2:-2, 2:-2, -1, vs.tau] += vs.maskU[2:-2, 2:-2, -1] * vs.surface_taux[2:-2, 2:-2] / vs.dzt[-1]\n        vs.dv[2:-2, 2:-2, -1, vs.tau] += vs.maskV[2:-2, 2:-2, -1] * vs.surface_tauy[2:-2, 2:-2] / vs.dzt[-1]\n    else:\n        vs.du[2:-2, 2:-2, -1, vs.tau] += vs.maskU[2:-2, 2:-2, -1] * vs.surface_taux[2:-2, 2:-2] / vs.dzt[-1] / vs.rho_0\n        vs.dv[2:-2, 2:-2, -1, vs.tau] += vs.maskV[2:-2, 2:-2, -1] * vs.surface_tauy[2:-2, 2:-2] / vs.dzt[-1] / vs.rho_0\n\n    """"""\n    advection\n    """"""\n    momentum_advection(vs)\n    vs.du[:, :, :, vs.tau] += vs.du_adv\n    vs.dv[:, :, :, vs.tau] += vs.dv_adv\n\n    with vs.timers[\'friction\']:\n        """"""\n        vertical friction\n        """"""\n        vs.K_diss_v[...] = 0.0\n        if vs.enable_implicit_vert_friction:\n            friction.implicit_vert_friction(vs)\n        if vs.enable_explicit_vert_friction:\n            friction.explicit_vert_friction(vs)\n\n        """"""\n        TEM formalism for eddy-driven velocity\n        """"""\n        if vs.enable_TEM_friction:\n            isoneutral.isoneutral_friction(vs)\n\n        """"""\n        horizontal friction\n        """"""\n        if vs.enable_hor_friction:\n            friction.harmonic_friction(vs)\n        if vs.enable_biharmonic_friction:\n            friction.biharmonic_friction(vs)\n\n        """"""\n        Rayleigh and bottom friction\n        """"""\n        vs.K_diss_bot[...] = 0.0\n        if vs.enable_ray_friction:\n            friction.rayleigh_friction(vs)\n        if vs.enable_bottom_friction:\n            friction.linear_bottom_friction(vs)\n        if vs.enable_quadratic_bottom_friction:\n            friction.quadratic_bottom_friction(vs)\n\n        """"""\n        add user defined forcing\n        """"""\n        if vs.enable_momentum_sources:\n            friction.momentum_sources(vs)\n\n    """"""\n    external mode\n    """"""\n    with vs.timers[\'pressure\']:\n        streamfunction.solve_streamfunction(vs)\n\n\n@veros_method\ndef vertical_velocity(vs):\n    """"""\n    vertical velocity from continuity :\n    \\\\int_0^z w_z dz = w(z)-w(0) = - \\\\int dz (u_x + v_y)\n    w(z) = -int dz u_x + v_y\n    """"""\n    fxa = allocate(vs, (\'xt\', \'yt\', \'zw\'))[1:, 1:]\n    # integrate from bottom to surface to see error in w\n    fxa[:, :, 0] = -vs.maskW[1:, 1:, 0] * vs.dzt[0] * \\\n        ((vs.u[1:, 1:, 0, vs.taup1] - vs.u[:-1, 1:, 0, vs.taup1])\n        / (vs.cost[np.newaxis, 1:] * vs.dxt[1:, np.newaxis])\n        + (vs.cosu[np.newaxis, 1:] * vs.v[1:, 1:, 0, vs.taup1]\n            - vs.cosu[np.newaxis, :-1] * vs.v[1:, :-1, 0, vs.taup1])\n        / (vs.cost[np.newaxis, 1:] * vs.dyt[np.newaxis, 1:]))\n    fxa[:, :, 1:] = -vs.maskW[1:, 1:, 1:] * vs.dzt[np.newaxis, np.newaxis, 1:] \\\n        * ((vs.u[1:, 1:, 1:, vs.taup1] - vs.u[:-1, 1:, 1:, vs.taup1])\n        / (vs.cost[np.newaxis, 1:, np.newaxis] * vs.dxt[1:, np.newaxis, np.newaxis])\n        + (vs.cosu[np.newaxis, 1:, np.newaxis] * vs.v[1:, 1:, 1:, vs.taup1]\n            - vs.cosu[np.newaxis, :-1, np.newaxis] * vs.v[1:, :-1, 1:, vs.taup1])\n        / (vs.cost[np.newaxis, 1:, np.newaxis] * vs.dyt[np.newaxis, 1:, np.newaxis]))\n    vs.w[1:, 1:, :, vs.taup1] = np.cumsum(fxa, axis=2)\n\n\n@veros_method\ndef momentum_advection(vs):\n    """"""\n    Advection of momentum with second order which is energy conserving\n    """"""\n\n    """"""\n    Code from MITgcm\n    """"""\n    utr = vs.u[..., vs.tau] * vs.maskU * vs.dyt[np.newaxis, :, np.newaxis] \\\n        * vs.dzt[np.newaxis, np.newaxis, :]\n    vtr = vs.dzt[np.newaxis, np.newaxis, :] * vs.cosu[np.newaxis, :, np.newaxis] \\\n        * vs.dxt[:, np.newaxis, np.newaxis] * vs.v[..., vs.tau] * vs.maskV\n    wtr = vs.w[..., vs.tau] * vs.maskW * vs.area_t[:, :, np.newaxis]\n\n    """"""\n    for zonal momentum\n    """"""\n    vs.flux_top[...] = 0.\n    vs.flux_east[1:-2, 2:-2] = 0.25 * (vs.u[1:-2, 2:-2, :, vs.tau] \\\n                                     + vs.u[2:-1, 2:-2, :, vs.tau]) \\\n                                    * (utr[2:-1, 2:-2] + utr[1:-2, 2:-2])\n    vs.flux_north[2:-2, 1:-2] = 0.25 * (vs.u[2:-2, 1:-2, :, vs.tau] \\\n                                      + vs.u[2:-2, 2:-1, :, vs.tau]) \\\n                                     * (vtr[3:-1, 1:-2] + vtr[2:-2, 1:-2])\n    vs.flux_top[2:-2, 2:-2, :-1] = 0.25 * (vs.u[2:-2, 2:-2, 1:, vs.tau] \\\n                                         + vs.u[2:-2, 2:-2, :-1, vs.tau]) \\\n                                        * (wtr[2:-2, 2:-2, :-1] + wtr[3:-1, 2:-2, :-1])\n    vs.du_adv[2:-2, 2:-2] = -vs.maskU[2:-2, 2:-2] * (vs.flux_east[2:-2, 2:-2] - vs.flux_east[1:-3, 2:-2]\n                                                   + vs.flux_north[2:-2, 2:-2] - vs.flux_north[2:-2, 1:-3]) \\\n                            / (vs.dzt[np.newaxis, np.newaxis, :] * vs.area_u[2:-2, 2:-2, np.newaxis])\n\n    tmp = -vs.maskU / (vs.dzt * vs.area_u[:, :, np.newaxis])\n    vs.du_adv += tmp * vs.flux_top\n    vs.du_adv[:, :, 1:] += tmp[:, :, 1:] * -vs.flux_top[:, :, :-1]\n\n    """"""\n    for meridional momentum\n    """"""\n    vs.flux_top[...] = 0.\n    vs.flux_east[1:-2, 2:-2] = 0.25 * (vs.v[1:-2, 2:-2, :, vs.tau]\n                                     + vs.v[2:-1, 2:-2, :, vs.tau]) * (utr[1:-2, 3:-1] + utr[1:-2, 2:-2])\n    vs.flux_north[2:-2, 1:-2] = 0.25 * (vs.v[2:-2, 1:-2, :, vs.tau]\n                                      + vs.v[2:-2, 2:-1, :, vs.tau]) * (vtr[2:-2, 2:-1] + vtr[2:-2, 1:-2])\n    vs.flux_top[2:-2, 2:-2, :-1] = 0.25 * (vs.v[2:-2, 2:-2, 1:, vs.tau]\n                                         + vs.v[2:-2, 2:-2, :-1, vs.tau]) * (wtr[2:-2, 2:-2, :-1] + wtr[2:-2, 3:-1, :-1])\n    vs.dv_adv[2:-2, 2:-2] = -vs.maskV[2:-2, 2:-2] * (vs.flux_east[2:-2, 2:-2] - vs.flux_east[1:-3, 2:-2]\n                                                   + vs.flux_north[2:-2, 2:-2] - vs.flux_north[2:-2, 1:-3]) \\\n                            / (vs.dzt * vs.area_v[2:-2, 2:-2, np.newaxis])\n    tmp = vs.dzt * vs.area_v[:, :, np.newaxis]\n    vs.dv_adv[:, :, 0] += -vs.maskV[:, :, 0] * vs.flux_top[:, :, 0] / tmp[:, :, 0]\n    vs.dv_adv[:, :, 1:] += -vs.maskV[:, :, 1:] \\\n        * (vs.flux_top[:, :, 1:] - vs.flux_top[:, :, :-1]) / tmp[:, :, 1:]\n'"
veros/core/numerics.py,41,"b'from .. import veros_method, runtime_settings as rs, runtime_state as rst\nfrom . import density, diffusion, utilities\n\n\n@veros_method(dist_safe=False, local_variables=(\n    \'dxt\', \'dxu\', \'xt\', \'xu\',\n    \'dyt\', \'dyu\', \'yt\', \'yu\',\n    \'dzt\', \'dzw\', \'zt\', \'zw\',\n    \'cost\', \'cosu\', \'tantr\',\n    \'area_t\', \'area_u\', \'area_v\',\n))\ndef calc_grid(vs):\n    """"""\n    setup grid based on dxt,dyt,dzt and x_origin, y_origin\n    """"""\n\n    def u_centered_grid(dyt, dyu, yt, yu):\n        yu[0] = 0\n        yu[1:] = np.cumsum(dyt[1:])\n\n        yt[0] = yu[0] - dyt[0] * 0.5\n        yt[1:] = 2 * yu[:-1]\n\n        alternating_pattern = np.ones_like(yt)\n        alternating_pattern[::2] = -1\n        yt[...] = alternating_pattern * np.cumsum(alternating_pattern * yt)\n\n        dyu[:-1] = yt[1:] - yt[:-1]\n        dyu[-1] = 2 * dyt[-1] - dyu[-2]\n\n    if vs.enable_cyclic_x:\n        vs.dxt[-2:] = vs.dxt[2:4]\n        vs.dxt[:2] = vs.dxt[-4:-2]\n    else:\n        vs.dxt[-2:] = vs.dxt[-3]\n        vs.dxt[:2] = vs.dxt[2]\n\n    vs.dyt[-2:] = vs.dyt[-3]\n    vs.dyt[:2] = vs.dyt[2]\n\n    """"""\n    grid in east/west direction\n    """"""\n    u_centered_grid(vs.dxt, vs.dxu, vs.xt, vs.xu)\n    vs.xt += vs.x_origin - vs.xu[2]\n    vs.xu += vs.x_origin - vs.xu[2]\n\n    if vs.enable_cyclic_x:\n        vs.xt[-2:] = vs.xt[2:4]\n        vs.xt[:2] = vs.xt[-4:-2]\n        vs.xu[-2:] = vs.xt[2:4]\n        vs.xu[:2] = vs.xu[-4:-2]\n        vs.dxu[-2:] = vs.dxu[2:4]\n        vs.dxu[:2] = vs.dxu[-4:-2]\n\n    """"""\n    grid in north/south direction\n    """"""\n    u_centered_grid(vs.dyt, vs.dyu, vs.yt, vs.yu)\n    vs.yt += vs.y_origin - vs.yu[2]\n    vs.yu += vs.y_origin - vs.yu[2]\n\n    if vs.coord_degree:\n        """"""\n        convert from degrees to pseudo cartesian grid\n        """"""\n        vs.dxt *= vs.degtom\n        vs.dxu *= vs.degtom\n        vs.dyt *= vs.degtom\n        vs.dyu *= vs.degtom\n\n    """"""\n    grid in vertical direction\n    """"""\n    u_centered_grid(vs.dzt, vs.dzw, vs.zt, vs.zw)\n    vs.zt -= vs.zw[-1]\n    vs.zw -= vs.zw[-1]  # enforce 0 boundary height\n\n    """"""\n    metric factors\n    """"""\n    if vs.coord_degree:\n        vs.cost[...] = np.cos(vs.yt * vs.pi / 180.)\n        vs.cosu[...] = np.cos(vs.yu * vs.pi / 180.)\n        vs.tantr[...] = np.tan(vs.yt * vs.pi / 180.) / vs.radius\n    else:\n        vs.cost[...] = 1.0\n        vs.cosu[...] = 1.0\n        vs.tantr[...] = 0.0\n\n    """"""\n    precalculate area of boxes\n    """"""\n    vs.area_t[...] = vs.cost * vs.dyt * vs.dxt[:, np.newaxis]\n    vs.area_u[...] = vs.cost * vs.dyt * vs.dxu[:, np.newaxis]\n    vs.area_v[...] = vs.cosu * vs.dyu * vs.dxt[:, np.newaxis]\n\n\n@veros_method\ndef calc_beta(vs):\n    """"""\n    calculate beta = df/dy\n    """"""\n    vs.beta[:, 2:-2] = 0.5 * ((vs.coriolis_t[:, 3:-1] - vs.coriolis_t[:, 2:-2]) / vs.dyu[2:-2]\n                            + (vs.coriolis_t[:, 2:-2] - vs.coriolis_t[:, 1:-3]) / vs.dyu[1:-3])\n\n    utilities.enforce_boundaries(vs, vs.beta)\n\n\n@veros_method\ndef calc_topo(vs):\n    """"""\n    calulate masks, total depth etc\n    """"""\n\n    """"""\n    close domain\n    """"""\n\n    vs.kbot[:, :2] = 0\n    vs.kbot[:, -2:] = 0\n\n    utilities.enforce_boundaries(vs, vs.kbot)\n\n    if not vs.enable_cyclic_x:\n        vs.kbot[:2, :] = 0\n        vs.kbot[-2:, :] = 0\n\n    """"""\n    Land masks\n    """"""\n    vs.maskT[...] = 0.0\n    land_mask = vs.kbot > 0\n    ks = np.arange(vs.maskT.shape[2])[np.newaxis, np.newaxis, :]\n    vs.maskT[...] = land_mask[..., np.newaxis] & (vs.kbot[..., np.newaxis] - 1 <= ks)\n    utilities.enforce_boundaries(vs, vs.maskT)\n    vs.maskU[...] = vs.maskT\n    vs.maskU[:-1, :, :] = np.minimum(vs.maskT[:-1, :, :], vs.maskT[1:, :, :])\n    utilities.enforce_boundaries(vs, vs.maskU)\n    vs.maskV[...] = vs.maskT\n    vs.maskV[:, :-1] = np.minimum(vs.maskT[:, :-1], vs.maskT[:, 1:])\n    utilities.enforce_boundaries(vs, vs.maskV)\n    vs.maskZ[...] = vs.maskT\n    vs.maskZ[:-1, :-1] = np.minimum(np.minimum(vs.maskT[:-1, :-1],\n                                                      vs.maskT[:-1, 1:]),\n                                                 vs.maskT[1:, :-1])\n    utilities.enforce_boundaries(vs, vs.maskZ)\n    vs.maskW[...] = vs.maskT\n    vs.maskW[:, :, :-1] = np.minimum(vs.maskT[:, :, :-1], vs.maskT[:, :, 1:])\n\n    """"""\n    total depth\n    """"""\n    vs.ht[...] = np.sum(vs.maskT * vs.dzt[np.newaxis, np.newaxis, :], axis=2)\n    vs.hu[...] = np.sum(vs.maskU * vs.dzt[np.newaxis, np.newaxis, :], axis=2)\n    vs.hv[...] = np.sum(vs.maskV * vs.dzt[np.newaxis, np.newaxis, :], axis=2)\n\n    mask = (vs.hu == 0).astype(np.float)\n    vs.hur[...] = 1. / (vs.hu + mask) * (1 - mask)\n    mask = (vs.hv == 0).astype(np.float)\n    vs.hvr[...] = 1. / (vs.hv + mask) * (1 - mask)\n\n\n@veros_method\ndef calc_initial_conditions(vs):\n    """"""\n    calculate dyn. enthalp, etc\n    """"""\n    if np.any(vs.salt < 0.0):\n        raise RuntimeError(\'encountered negative salinity\')\n\n    utilities.enforce_boundaries(vs, vs.temp)\n    utilities.enforce_boundaries(vs, vs.salt)\n\n    vs.rho[...] = density.get_rho(vs, vs.salt, vs.temp, np.abs(vs.zt)[:, np.newaxis]) \\\n                  * vs.maskT[..., np.newaxis]\n    vs.Hd[...] = density.get_dyn_enthalpy(vs, vs.salt, vs.temp, np.abs(vs.zt)[:, np.newaxis]) \\\n                 * vs.maskT[..., np.newaxis]\n    vs.int_drhodT[...] = density.get_int_drhodT(vs, vs.salt, vs.temp, np.abs(vs.zt)[:, np.newaxis])\n    vs.int_drhodS[...] = density.get_int_drhodS(vs, vs.salt, vs.temp, np.abs(vs.zt)[:, np.newaxis])\n\n    fxa = -vs.grav / vs.rho_0 / vs.dzw[np.newaxis, np.newaxis, :] * vs.maskW\n    vs.Nsqr[:, :, :-1, :] = fxa[:, :, :-1, np.newaxis] \\\n        * (density.get_rho(vs, vs.salt[:, :, 1:, :], vs.temp[:, :, 1:, :], np.abs(vs.zt)[:-1, np.newaxis])\n         - vs.rho[:, :, :-1, :])\n    vs.Nsqr[:, :, -1, :] = vs.Nsqr[:, :, -2, :]\n\n\n@veros_method(inline=True)\ndef ugrid_to_tgrid(vs, a):\n    b = np.zeros_like(a)\n    b[2:-2, :, :] = (vs.dxu[2:-2, np.newaxis, np.newaxis] * a[2:-2, :, :] + vs.dxu[1:-3, np.newaxis, np.newaxis] * a[1:-3, :, :]) \\\n        / (2 * vs.dxt[2:-2, np.newaxis, np.newaxis])\n    return b\n\n\n@veros_method(inline=True)\ndef vgrid_to_tgrid(vs, a):\n    b = np.zeros_like(a)\n    b[:, 2:-2, :] = (vs.area_v[:, 2:-2, np.newaxis] * a[:, 2:-2, :] + vs.area_v[:, 1:-3, np.newaxis] * a[:, 1:-3, :]) \\\n        / (2 * vs.area_t[:, 2:-2, np.newaxis])\n    return b\n\n\n@veros_method\ndef solve_tridiag(vs, a, b, c, d):\n    """"""\n    Solves a tridiagonal matrix system with diagonals a, b, c and RHS vector d.\n    Uses LAPACK when running with NumPy, and otherwise the Thomas algorithm iterating over the\n    last axis of the input arrays.\n    """"""\n    assert a.shape == b.shape and a.shape == c.shape and a.shape == d.shape\n\n    if rs.backend == \'bohrium\' and rst.vector_engine in (\'opencl\', \'openmp\'):\n        return np.linalg.solve_tridiagonal(a, b, c, d)\n\n    # fall back to scipy\n    from scipy.linalg import lapack\n    a[..., 0] = c[..., -1] = 0  # remove couplings between slices\n    return lapack.dgtsv(a.flatten()[1:], b.flatten(), c.flatten()[:-1], d.flatten())[3].reshape(a.shape)\n\n\n@veros_method(inline=True)\ndef calc_diss(vs, diss, tag):\n    diss_u = np.zeros_like(diss)\n    ks = np.zeros_like(vs.kbot)\n    if tag == \'U\':\n        ks[1:-2, 2:-2] = np.maximum(vs.kbot[1:-2, 2:-2], vs.kbot[2:-1, 2:-2]) - 1\n        interpolator = ugrid_to_tgrid\n    elif tag == \'V\':\n        ks[2:-2, 1:-2] = np.maximum(vs.kbot[2:-2, 1:-2], vs.kbot[2:-2, 2:-1]) - 1\n        interpolator = vgrid_to_tgrid\n    else:\n        raise ValueError(\'unknown tag {} (must be \\\'U\\\' or \\\'V\\\')\'.format(tag))\n    diffusion.dissipation_on_wgrid(vs, diss_u, aloc=diss, ks=ks)\n    return interpolator(vs, diss_u)\n'"
veros/core/thermodynamics.py,25,"b'from .. import veros_method\nfrom ..distributed import global_sum\nfrom ..variables import allocate\nfrom . import advection, diffusion, isoneutral, density, utilities\n\n\n@veros_method\ndef thermodynamics(vs):\n    """"""\n    integrate temperature and salinity and diagnose sources of dynamic enthalpy\n    """"""\n    advect_temperature(vs)\n    advect_salinity(vs)\n\n    if vs.enable_conserve_energy:\n        """"""\n        advection of dynamic enthalpy\n        """"""\n        if vs.enable_superbee_advection:\n            advection.adv_flux_superbee(vs, vs.flux_east, vs.flux_north,\n                                        vs.flux_top, vs.Hd[:, :, :, vs.tau])\n        else:\n            advection.adv_flux_2nd(vs, vs.flux_east, vs.flux_north,\n                                vs.flux_top, vs.Hd[:, :, :, vs.tau])\n\n        vs.dHd[2:-2, 2:-2, :, vs.tau] = vs.maskT[2:-2, 2:-2, :] * (-(vs.flux_east[2:-2, 2:-2, :] - vs.flux_east[1:-3, 2:-2, :])\n                                                                    / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis])\n                                                                - (vs.flux_north[2:-2, 2:-2, :] - vs.flux_north[2:-2, 1:-3, :])\n                                                                    / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dyt[np.newaxis, 2:-2, np.newaxis]))\n        vs.dHd[:, :, 0, vs.tau] += -vs.maskT[:, :, 0] \\\n            * vs.flux_top[:, :, 0] / vs.dzt[0]\n        vs.dHd[:, :, 1:, vs.tau] += -vs.maskT[:, :, 1:] \\\n            * (vs.flux_top[:, :, 1:] - vs.flux_top[:, :, :-1]) \\\n            / vs.dzt[np.newaxis, np.newaxis, 1:]\n\n        """"""\n        changes in dyn. Enthalpy due to advection\n        """"""\n        aloc = allocate(vs, (\'xt\', \'yt\', \'zt\'))\n        aloc[2:-2, 2:-2, :] = vs.grav / vs.rho_0 * (-vs.int_drhodT[2:-2, 2:-2, :, vs.tau] * vs.dtemp[2:-2, 2:-2, :, vs.tau]\n                                                - vs.int_drhodS[2:-2, 2:-2, :, vs.tau] * vs.dsalt[2:-2, 2:-2, :, vs.tau]) \\\n                            - vs.dHd[2:-2, 2:-2, :, vs.tau]\n\n        """"""\n        contribution by vertical advection is - g rho w / rho0, substract this also\n        """"""\n        aloc[:, :, :-1] += -0.25 * vs.grav / vs.rho_0 * vs.w[:, :, :-1, vs.tau] \\\n            * (vs.rho[:, :, :-1, vs.tau] + vs.rho[:, :, 1:, vs.tau]) \\\n            * vs.dzw[np.newaxis, np.newaxis, :-1] / vs.dzt[np.newaxis, np.newaxis, :-1]\n        aloc[:, :, 1:] += -0.25 * vs.grav / vs.rho_0 * vs.w[:, :, :-1, vs.tau] \\\n            * (vs.rho[:, :, 1:, vs.tau] + vs.rho[:, :, :-1, vs.tau]) \\\n            * vs.dzw[np.newaxis, np.newaxis, :-1] / vs.dzt[np.newaxis, np.newaxis, 1:]\n\n    if vs.enable_conserve_energy and vs.enable_tke:\n        """"""\n        dissipation by advection interpolated on W-grid\n        """"""\n        vs.P_diss_adv[...] = 0.\n        diffusion.dissipation_on_wgrid(vs, vs.P_diss_adv, aloc=aloc)\n\n        """"""\n        distribute vs.P_diss_adv over domain, prevent draining of TKE\n        """"""\n        fxa = np.sum(vs.area_t[2:-2, 2:-2, np.newaxis] * vs.P_diss_adv[2:-2, 2:-2, :-1]\n                    * vs.dzw[np.newaxis, np.newaxis, :-1] * vs.maskW[2:-2, 2:-2, :-1]) \\\n            + np.sum(0.5 * vs.area_t[2:-2, 2:-2] * vs.P_diss_adv[2:-2, 2:-2, -1]\n                    * vs.dzw[-1] * vs.maskW[2:-2, 2:-2, -1])\n        tke_mask = vs.tke[2:-2, 2:-2, :-1, vs.tau] > 0.\n        fxb = np.sum(vs.area_t[2:-2, 2:-2, np.newaxis] * vs.dzw[np.newaxis, np.newaxis, :-1] * vs.maskW[2:-2, 2:-2, :-1] * tke_mask) \\\n            + np.sum(0.5 * vs.area_t[2:-2, 2:-2] * vs.dzw[-1] * vs.maskW[2:-2, 2:-2, -1])\n\n        fxa = global_sum(vs, fxa)\n        fxb = global_sum(vs, fxb)\n\n        vs.P_diss_adv[...] = 0.\n        vs.P_diss_adv[2:-2, 2:-2, :-1] = fxa / fxb * tke_mask\n        vs.P_diss_adv[2:-2, 2:-2, -1] = fxa / fxb\n\n    """"""\n    Adam Bashforth time stepping for advection\n    """"""\n    vs.temp[:, :, :, vs.taup1] = vs.temp[:, :, :, vs.tau] + vs.dt_tracer \\\n        * ((1.5 + vs.AB_eps) * vs.dtemp[:, :, :, vs.tau]\n        - (0.5 + vs.AB_eps) * vs.dtemp[:, :, :, vs.taum1]) * vs.maskT\n    vs.salt[:, :, :, vs.taup1] = vs.salt[:, :, :, vs.tau] + vs.dt_tracer \\\n        * ((1.5 + vs.AB_eps) * vs.dsalt[:, :, :, vs.tau]\n        - (0.5 + vs.AB_eps) * vs.dsalt[:, :, :, vs.taum1]) * vs.maskT\n\n    """"""\n    horizontal diffusion\n    """"""\n    with vs.timers[\'isoneutral\']:\n        if vs.enable_hor_diffusion:\n            diffusion.tempsalt_diffusion(vs)\n        if vs.enable_biharmonic_mixing:\n            diffusion.tempsalt_biharmonic(vs)\n\n        """"""\n        sources like restoring zones, etc\n        """"""\n        if vs.enable_tempsalt_sources:\n            diffusion.tempsalt_sources(vs)\n\n        """"""\n        isopycnal diffusion\n        """"""\n        if vs.enable_neutral_diffusion:\n            vs.P_diss_iso[...] = 0.0\n            vs.dtemp_iso[...] = 0.0\n            vs.dsalt_iso[...] = 0.0\n            isoneutral.isoneutral_diffusion_pre(vs)\n            isoneutral.isoneutral_diffusion(vs, vs.temp, True)\n            isoneutral.isoneutral_diffusion(vs, vs.salt, False)\n            if vs.enable_skew_diffusion:\n                vs.P_diss_skew[...] = 0.0\n                isoneutral.isoneutral_skew_diffusion(vs, vs.temp, True)\n                isoneutral.isoneutral_skew_diffusion(vs, vs.salt, False)\n\n    with vs.timers[\'vmix\']:\n        """"""\n        vertical mixing of temperature and salinity\n        """"""\n        vs.dtemp_vmix[...] = vs.temp[:, :, :, vs.taup1]\n        vs.dsalt_vmix[...] = vs.salt[:, :, :, vs.taup1]\n\n        a_tri = allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False)\n        b_tri = allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False)\n        c_tri = allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False)\n        d_tri = allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False)\n        delta = allocate(vs, (\'xt\', \'yt\', \'zw\'), include_ghosts=False)\n\n        ks = vs.kbot[2:-2, 2:-2] - 1\n        delta[:, :, :-1] = vs.dt_tracer / vs.dzw[np.newaxis, np.newaxis, :-1] \\\n            * vs.kappaH[2:-2, 2:-2, :-1]\n        delta[:, :, -1] = 0.\n        a_tri[:, :, 1:] = -delta[:, :, :-1] / vs.dzt[np.newaxis, np.newaxis, 1:]\n        b_tri[:, :, 1:] = 1 + (delta[:, :, 1:] + delta[:, :, :-1]) \\\n            / vs.dzt[np.newaxis, np.newaxis, 1:]\n        b_tri_edge = 1 + delta / vs.dzt[np.newaxis, np.newaxis, :]\n        c_tri[:, :, :-1] = -delta[:, :, :-1] / vs.dzt[np.newaxis, np.newaxis, :-1]\n        d_tri[...] = vs.temp[2:-2, 2:-2, :, vs.taup1]\n        d_tri[:, :, -1] += vs.dt_tracer * vs.forc_temp_surface[2:-2, 2:-2] / vs.dzt[-1]\n        sol, mask = utilities.solve_implicit(vs, ks, a_tri, b_tri, c_tri, d_tri, b_edge=b_tri_edge)\n        vs.temp[2:-2, 2:-2, :, vs.taup1] = utilities.where(vs, mask, sol, vs.temp[2:-2, 2:-2, :, vs.taup1])\n        d_tri[...] = vs.salt[2:-2, 2:-2, :, vs.taup1]\n        d_tri[:, :, -1] += vs.dt_tracer * vs.forc_salt_surface[2:-2, 2:-2] / vs.dzt[-1]\n        sol, mask = utilities.solve_implicit(\n            vs, ks, a_tri, b_tri, c_tri, d_tri, b_edge=b_tri_edge\n        )\n        vs.salt[2:-2, 2:-2, :, vs.taup1] = utilities.where(vs, mask, sol, vs.salt[2:-2, 2:-2, :, vs.taup1])\n\n        vs.dtemp_vmix[...] = (vs.temp[:, :, :, vs.taup1] -\n                            vs.dtemp_vmix) / vs.dt_tracer\n        vs.dsalt_vmix[...] = (vs.salt[:, :, :, vs.taup1] -\n                            vs.dsalt_vmix) / vs.dt_tracer\n\n    """"""\n    boundary exchange\n    """"""\n    utilities.enforce_boundaries(vs, vs.temp[..., vs.taup1])\n    utilities.enforce_boundaries(vs, vs.salt[..., vs.taup1])\n\n    with vs.timers[\'eq_of_state\']:\n        calc_eq_of_state(vs, vs.taup1)\n\n    """"""\n    surface density flux\n    """"""\n    vs.forc_rho_surface[...] = vs.maskT[:, :, -1] * (\n        density.get_drhodT(vs, vs.salt[:, :, -1, vs.taup1],\n                        vs.temp[:, :, -1, vs.taup1],\n                        np.abs(vs.zt[-1])) * vs.forc_temp_surface\n        + density.get_drhodS(vs, vs.salt[:, :, -1, vs.taup1],\n                            vs.temp[:, :, -1, vs.taup1],\n                            np.abs(vs.zt[-1])) * vs.forc_salt_surface\n        )\n\n    with vs.timers[\'vmix\']:\n        vs.P_diss_v[...] = 0.0\n        if vs.enable_conserve_energy:\n            """"""\n            diagnose dissipation of dynamic enthalpy by vertical mixing\n            """"""\n            fxa = (-vs.int_drhodT[2:-2, 2:-2, 1:, vs.taup1] + vs.int_drhodT[2:-2, 2:-2, :-1, vs.taup1]) \\\n                / vs.dzw[np.newaxis, np.newaxis, :-1]\n            vs.P_diss_v[2:-2, 2:-2, :-1] += -vs.grav / vs.rho_0 * fxa * vs.kappaH[2:-2, 2:-2, :-1] \\\n                * (vs.temp[2:-2, 2:-2, 1:, vs.taup1] - vs.temp[2:-2, 2:-2, :-1, vs.taup1]) \\\n                / vs.dzw[np.newaxis, np.newaxis, :-1] * vs.maskW[2:-2, 2:-2, :-1]\n            fxa = (-vs.int_drhodS[2:-2, 2:-2, 1:, vs.taup1] + vs.int_drhodS[2:-2, 2:-2, :-1, vs.taup1]) \\\n                / vs.dzw[np.newaxis, np.newaxis, :-1]\n            vs.P_diss_v[2:-2, 2:-2, :-1] += -vs.grav / vs.rho_0 * fxa * vs.kappaH[2:-2, 2:-2, :-1] \\\n                * (vs.salt[2:-2, 2:-2, 1:, vs.taup1] - vs.salt[2:-2, 2:-2, :-1, vs.taup1]) \\\n                / vs.dzw[np.newaxis, np.newaxis, :-1] * vs.maskW[2:-2, 2:-2, :-1]\n\n            fxa = 2 * vs.int_drhodT[2:-2, 2:-2, -1, vs.taup1] / vs.dzw[-1]\n            vs.P_diss_v[2:-2, 2:-2, -1] += - vs.grav / vs.rho_0 * fxa * \\\n                vs.forc_temp_surface[2:-2, 2:-2] * vs.maskW[2:-2, 2:-2, -1]\n            fxa = 2 * vs.int_drhodS[2:-2, 2:-2, -1, vs.taup1] / vs.dzw[-1]\n            vs.P_diss_v[2:-2, 2:-2, -1] += - vs.grav / vs.rho_0 * fxa * \\\n                vs.forc_salt_surface[2:-2, 2:-2] * vs.maskW[2:-2, 2:-2, -1]\n\n        if vs.enable_conserve_energy:\n            """"""\n            determine effect due to nonlinear equation of state\n            """"""\n            aloc[:, :, :-1] = vs.kappaH[:, :, :-1] * vs.Nsqr[:, :, :-1, vs.taup1]\n            vs.P_diss_nonlin[:, :, :-1] = vs.P_diss_v[:, :, :-1] - aloc[:, :, :-1]\n            vs.P_diss_v[:, :, :-1] = aloc[:, :, :-1]\n        else:\n            """"""\n            diagnose N^2 vs.kappaH, i.e. exchange of pot. energy with TKE\n            """"""\n            vs.P_diss_v[:, :, :-1] = vs.kappaH[:, :, :-1] * vs.Nsqr[:, :, :-1, vs.taup1]\n            vs.P_diss_v[:, :, -1] = -vs.forc_rho_surface * vs.maskT[:, :, -1] * vs.grav / vs.rho_0\n\n\n@veros_method\ndef advect_tracer(vs, tr, dtr):\n    """"""\n    calculate time tendency of a tracer due to advection\n    """"""\n    if vs.enable_superbee_advection:\n        advection.adv_flux_superbee(vs, vs.flux_east, vs.flux_north, vs.flux_top, tr)\n    else:\n        advection.adv_flux_2nd(vs, vs.flux_east, vs.flux_north, vs.flux_top, tr)\n    dtr[2:-2, 2:-2, :] = vs.maskT[2:-2, 2:-2, :] * (-(vs.flux_east[2:-2, 2:-2, :] - vs.flux_east[1:-3, 2:-2, :])\n                                                    / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis])\n                                                   - (vs.flux_north[2:-2, 2:-2, :] - vs.flux_north[2:-2, 1:-3, :])\n                                                    / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dyt[np.newaxis, 2:-2, np.newaxis]))\n    dtr[:, :, 0] += -vs.maskT[:, :, 0] * vs.flux_top[:, :, 0] / vs.dzt[0]\n    dtr[:, :, 1:] += -vs.maskT[:, :, 1:] * (vs.flux_top[:, :, 1:] - vs.flux_top[:, :, :-1]) / vs.dzt[1:]\n\n\n@veros_method\ndef advect_temperature(vs):\n    """"""\n    integrate temperature\n    """"""\n    return advect_tracer(vs, vs.temp[..., vs.tau], vs.dtemp[..., vs.tau])\n\n\n@veros_method\ndef advect_salinity(vs):\n    """"""\n    integrate salinity\n    """"""\n    return advect_tracer(vs, vs.salt[..., vs.tau], vs.dsalt[..., vs.tau])\n\n\n@veros_method\ndef calc_eq_of_state(vs, n):\n    """"""\n    calculate density, stability frequency, dynamic enthalpy and derivatives\n    for time level n from temperature and salinity\n    """"""\n    salt = vs.salt[..., n]\n    temp = vs.temp[..., n]\n    press = np.abs(vs.zt)\n\n    """"""\n    calculate new density\n    """"""\n    vs.rho[..., n] = density.get_rho(vs, salt, temp, press) * vs.maskT\n\n    """"""\n    calculate new potential density\n    """"""\n    vs.prho[...] = density.get_potential_rho(vs, salt, temp) * vs.maskT\n\n    """"""\n    calculate new dynamic enthalpy and derivatives\n    """"""\n    if vs.enable_conserve_energy:\n        vs.Hd[..., n] = density.get_dyn_enthalpy(vs, salt, temp, press) * vs.maskT\n        vs.int_drhodT[..., n] = density.get_int_drhodT(vs, salt, temp, press)\n        vs.int_drhodS[..., n] = density.get_int_drhodS(vs, salt, temp, press)\n\n    """"""\n    new stability frequency\n    """"""\n    fxa = -vs.grav / vs.rho_0 / vs.dzw[np.newaxis, np.newaxis, :-1] * vs.maskW[:, :, :-1]\n    vs.Nsqr[:, :, :-1, n] = fxa * (density.get_rho(\n                                        vs, salt[:, :, 1:], temp[:, :, 1:], press[:-1]\n                                    ) - vs.rho[:, :, :-1, n])\n    vs.Nsqr[:, :, -1, n] = vs.Nsqr[:, :, -2, n]\n'"
veros/core/tke.py,32,"b'import math\n\nfrom .. import veros_method\nfrom ..variables import allocate\nfrom . import advection, utilities\n\n\n@veros_method\ndef set_tke_diffusivities(vs):\n    """"""\n    set vertical diffusivities based on TKE model\n    """"""\n    Rinumber = allocate(vs, (\'xt\', \'yt\', \'zw\'))\n\n    if vs.enable_tke:\n        vs.sqrttke[...] = np.sqrt(np.maximum(0., vs.tke[:, :, :, vs.tau]))\n        """"""\n        calculate buoyancy length scale\n        """"""\n        vs.mxl[...] = math.sqrt(2) * vs.sqrttke \\\n            / np.sqrt(np.maximum(1e-12, vs.Nsqr[:, :, :, vs.tau])) * vs.maskW\n\n        """"""\n        apply limits for mixing length\n        """"""\n        if vs.tke_mxl_choice == 1:\n            """"""\n            bounded by the distance to surface/bottom\n            """"""\n            vs.mxl[...] = np.minimum(\n                np.minimum(vs.mxl, -vs.zw[np.newaxis, np.newaxis, :]\n                           + vs.dzw[np.newaxis, np.newaxis, :] * 0.5\n                           ), vs.ht[:, :, np.newaxis] + vs.zw[np.newaxis, np.newaxis, :]\n            )\n            vs.mxl[...] = np.maximum(vs.mxl, vs.mxl_min)\n        elif vs.tke_mxl_choice == 2:\n            """"""\n            bound length scale as in mitgcm/OPA code\n\n            Note that the following code doesn\'t vectorize. If critical for performance,\n            consider re-implementing it in Cython.\n            """"""\n            for k in range(vs.nz - 2, -1, -1):\n                vs.mxl[:, :, k] = np.minimum(vs.mxl[:, :, k], vs.mxl[:, :, k + 1] + vs.dzt[k + 1])\n            vs.mxl[:, :, -1] = np.minimum(vs.mxl[:, :, -1], vs.mxl_min + vs.dzt[-1])\n            for k in range(1, vs.nz):\n                vs.mxl[:, :, k] = np.minimum(vs.mxl[:, :, k], vs.mxl[:, :, k - 1] + vs.dzt[k])\n            vs.mxl[...] = np.maximum(vs.mxl, vs.mxl_min)\n        else:\n            raise ValueError(\'unknown mixing length choice in tke_mxl_choice\')\n\n        """"""\n        calculate viscosity and diffusivity based on Prandtl number\n        """"""\n        utilities.enforce_boundaries(vs, vs.K_diss_v)\n        vs.kappaM[...] = np.minimum(vs.kappaM_max, vs.c_k * vs.mxl * vs.sqrttke)\n        Rinumber[...] = vs.Nsqr[:, :, :, vs.tau] / \\\n            np.maximum(vs.K_diss_v / np.maximum(1e-12, vs.kappaM), 1e-12)\n        if vs.enable_idemix:\n            Rinumber[...] = np.minimum(Rinumber, vs.kappaM * vs.Nsqr[:, :, :, vs.tau]\n                                  / np.maximum(1e-12, vs.alpha_c * vs.E_iw[:, :, :, vs.tau]**2))\n        if vs.enable_Prandtl_tke:\n            vs.Prandtlnumber[...] = np.maximum(1., np.minimum(10, 6.6 * Rinumber))\n        else:\n            vs.Prandtlnumber[...] = vs.Prandtl_tke0\n        vs.kappaH[...] = np.maximum(vs.kappaH_min, vs.kappaM / vs.Prandtlnumber)\n        if vs.enable_kappaH_profile:\n            # Correct diffusivity according to\n            # Bryan, K., and L. J. Lewis, 1979:\n            # A water mass model of the world ocean. J. Geophys. Res., 84, 2503\xe2\x80\x932517.\n            # It mainly modifies kappaH within 20S - 20N deg. belt\n            vs.kappaH[...] = np.maximum(vs.kappaH, (0.8 + 1.05 / np.pi\n                                                    * np.arctan((-vs.zw[np.newaxis, np.newaxis, :] - 2500.)\n                                                    / 222.2)) * 1e-4)\n        vs.kappaM[...] = np.maximum(vs.kappaM_min, vs.kappaM)\n    else:\n        vs.kappaM[...] = vs.kappaM_0\n        vs.kappaH[...] = vs.kappaH_0\n\n\n@veros_method\ndef integrate_tke(vs):\n    """"""\n    integrate Tke equation on W grid with surface flux boundary condition\n    """"""\n    dt_tke = vs.dt_mom  # use momentum time step to prevent spurious oscillations\n\n    """"""\n    Sources and sinks by vertical friction, vertical mixing, and non-conservative advection\n    """"""\n    forc = vs.K_diss_v - vs.P_diss_v - vs.P_diss_adv\n\n    """"""\n    store transfer due to vertical mixing from dyn. enthalpy by non-linear eq.of\n    state either to TKE or to heat\n    """"""\n    if not vs.enable_store_cabbeling_heat:\n        forc[...] += -vs.P_diss_nonlin\n\n    """"""\n    transfer part of dissipation of EKE to TKE\n    """"""\n    if vs.enable_eke:\n        forc[...] += vs.eke_diss_tke\n\n    if vs.enable_idemix:\n        """"""\n        transfer dissipation of internal waves to TKE\n        """"""\n        forc[...] += vs.iw_diss\n        """"""\n        store bottom friction either in TKE or internal waves\n        """"""\n        if vs.enable_store_bottom_friction_tke:\n            forc[...] += vs.K_diss_bot\n    else:  # short-cut without idemix\n        if vs.enable_eke:\n            forc[...] += vs.eke_diss_iw\n        else:  # and without EKE model\n            if vs.enable_store_cabbeling_heat:\n                forc[...] += vs.K_diss_gm + vs.K_diss_h - vs.P_diss_skew \\\n                    - vs.P_diss_hmix - vs.P_diss_iso\n            else:\n                forc[...] += vs.K_diss_gm + vs.K_diss_h - vs.P_diss_skew\n        forc[...] += vs.K_diss_bot\n\n    """"""\n    vertical mixing and dissipation of TKE\n    """"""\n    ks = vs.kbot[2:-2, 2:-2] - 1\n\n    a_tri = allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False)\n    b_tri = allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False)\n    c_tri = allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False)\n    d_tri = allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False)\n    delta = allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False)\n\n    delta[:, :, :-1] = dt_tke / vs.dzt[np.newaxis, np.newaxis, 1:] * vs.alpha_tke * 0.5 \\\n        * (vs.kappaM[2:-2, 2:-2, :-1] + vs.kappaM[2:-2, 2:-2, 1:])\n\n    a_tri[:, :, 1:-1] = -delta[:, :, :-2] / vs.dzw[np.newaxis, np.newaxis, 1:-1]\n    a_tri[:, :, -1] = -delta[:, :, -2] / (0.5 * vs.dzw[-1])\n\n    b_tri[:, :, 1:-1] = 1 + (delta[:, :, 1:-1] + delta[:, :, :-2]) / vs.dzw[np.newaxis, np.newaxis, 1:-1] \\\n        + dt_tke * vs.c_eps \\\n        * vs.sqrttke[2:-2, 2:-2, 1:-1] / vs.mxl[2:-2, 2:-2, 1:-1]\n    b_tri[:, :, -1] = 1 + delta[:, :, -2] / (0.5 * vs.dzw[-1]) \\\n        + dt_tke * vs.c_eps / vs.mxl[2:-2, 2:-2, -1] * vs.sqrttke[2:-2, 2:-2, -1]\n    b_tri_edge = 1 + delta / vs.dzw[np.newaxis, np.newaxis, :] \\\n        + dt_tke * vs.c_eps / vs.mxl[2:-2, 2:-2, :] * vs.sqrttke[2:-2, 2:-2, :]\n\n    c_tri[:, :, :-1] = -delta[:, :, :-1] / vs.dzw[np.newaxis, np.newaxis, :-1]\n\n    d_tri[...] = vs.tke[2:-2, 2:-2, :, vs.tau] + dt_tke * forc[2:-2, 2:-2, :]\n    d_tri[:, :, -1] += dt_tke * vs.forc_tke_surface[2:-2, 2:-2] / (0.5 * vs.dzw[-1])\n\n    sol, water_mask = utilities.solve_implicit(vs, ks, a_tri, b_tri, c_tri, d_tri, b_edge=b_tri_edge)\n    vs.tke[2:-2, 2:-2, :, vs.taup1] = utilities.where(vs, water_mask, sol, vs.tke[2:-2, 2:-2, :, vs.taup1])\n\n    """"""\n    store tke dissipation for diagnostics\n    """"""\n    vs.tke_diss[...] = vs.c_eps / vs.mxl * vs.sqrttke * vs.tke[:, :, :, vs.taup1]\n\n    """"""\n    Add TKE if surface density flux drains TKE in uppermost box\n    """"""\n    mask = vs.tke[2:-2, 2:-2, -1, vs.taup1] < 0.0\n    vs.tke_surf_corr[...] = 0.\n    vs.tke_surf_corr[2:-2, 2:-2] = utilities.where(vs, mask,\n                                            -vs.tke[2:-2, 2:-2, -1, vs.taup1] * 0.5\n                                               * vs.dzw[-1] / dt_tke,\n                                            0.)\n    vs.tke[2:-2, 2:-2, -1, vs.taup1] = np.maximum(0., vs.tke[2:-2, 2:-2, -1, vs.taup1])\n\n    if vs.enable_tke_hor_diffusion:\n        """"""\n        add tendency due to lateral diffusion\n        """"""\n        vs.flux_east[:-1, :, :] = vs.K_h_tke * (vs.tke[1:, :, :, vs.tau] - vs.tke[:-1, :, :, vs.tau]) \\\n            / (vs.cost[np.newaxis, :, np.newaxis] * vs.dxu[:-1, np.newaxis, np.newaxis]) * vs.maskU[:-1, :, :]\n        if vs.pyom_compatibility_mode:\n            vs.flux_east[-5, :, :] = 0.\n        else:\n            vs.flux_east[-1, :, :] = 0.\n        vs.flux_north[:, :-1, :] = vs.K_h_tke * (vs.tke[:, 1:, :, vs.tau] - vs.tke[:, :-1, :, vs.tau]) \\\n            / vs.dyu[np.newaxis, :-1, np.newaxis] * vs.maskV[:, :-1, :] * vs.cosu[np.newaxis, :-1, np.newaxis]\n        vs.flux_north[:, -1, :] = 0.\n        vs.tke[2:-2, 2:-2, :, vs.taup1] += dt_tke * vs.maskW[2:-2, 2:-2, :] * \\\n            ((vs.flux_east[2:-2, 2:-2, :] - vs.flux_east[1:-3, 2:-2, :])\n             / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis])\n             + (vs.flux_north[2:-2, 2:-2, :] - vs.flux_north[2:-2, 1:-3, :])\n             / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dyt[np.newaxis, 2:-2, np.newaxis]))\n\n    """"""\n    add tendency due to advection\n    """"""\n    if vs.enable_tke_superbee_advection:\n        advection.adv_flux_superbee_wgrid(\n            vs, vs.flux_east, vs.flux_north, vs.flux_top, vs.tke[:, :, :, vs.tau]\n        )\n    if vs.enable_tke_upwind_advection:\n        advection.adv_flux_upwind_wgrid(\n            vs, vs.flux_east, vs.flux_north, vs.flux_top, vs.tke[:, :, :, vs.tau]\n        )\n    if vs.enable_tke_superbee_advection or vs.enable_tke_upwind_advection:\n        vs.dtke[2:-2, 2:-2, :, vs.tau] = vs.maskW[2:-2, 2:-2, :] * (-(vs.flux_east[2:-2, 2:-2, :] - vs.flux_east[1:-3, 2:-2, :])\n                                                                     / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis])\n                                                                    - (vs.flux_north[2:-2, 2:-2, :] - vs.flux_north[2:-2, 1:-3, :])\n                                                                     / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dyt[np.newaxis, 2:-2, np.newaxis]))\n        vs.dtke[:, :, 0, vs.tau] += -vs.flux_top[:, :, 0] / vs.dzw[0]\n        vs.dtke[:, :, 1:-1, vs.tau] += -(vs.flux_top[:, :, 1:-1] - vs.flux_top[:, :, :-2]) / vs.dzw[1:-1]\n        vs.dtke[:, :, -1, vs.tau] += -(vs.flux_top[:, :, -1] - vs.flux_top[:, :, -2]) / (0.5 * vs.dzw[-1])\n        """"""\n        Adam Bashforth time stepping\n        """"""\n        vs.tke[:, :, :, vs.taup1] += vs.dt_tracer * ((1.5 + vs.AB_eps) * vs.dtke[:, :, :, vs.tau]\n                                                   - (0.5 + vs.AB_eps) * vs.dtke[:, :, :, vs.taum1])\n'"
veros/core/utilities.py,11,"b'from .. import veros_method, runtime_settings as rs, runtime_state as rst\n\n\n@veros_method\ndef enforce_boundaries(vs, arr, local=False):\n    from ..distributed import exchange_cyclic_boundaries, exchange_overlap\n    from ..decorators import CONTEXT\n\n    if vs.enable_cyclic_x:\n        if rs.num_proc[0] == 1 or not CONTEXT.is_dist_safe or local:\n            arr[-2:, ...] = arr[2:4, ...]\n            arr[:2, ...] = arr[-4:-2, ...]\n        else:\n            exchange_cyclic_boundaries(vs, arr)\n\n    if local or rst.proc_num == 1:\n        return\n\n    exchange_overlap(vs, arr, [\'xt\', \'yt\'])\n\n\n@veros_method(inline=True)\ndef where(vs, cond, arr1, arr2):\n    assert cond.dtype == np.bool\n    return cond * arr1 + np.logical_not(cond) * arr2\n\n\n@veros_method(inline=True)\ndef pad_z_edges(vs, array):\n    """"""\n    Pads the z-axis of an array by repeating its edge values\n    """"""\n    if array.ndim == 1:\n        newarray = np.zeros(array.shape[0] + 2, dtype=array.dtype)\n        newarray[1:-1] = array\n        newarray[0] = array[0]\n        newarray[-1] = array[-1]\n    elif array.ndim >= 3:\n        a = list(array.shape)\n        a[2] += 2\n        newarray = np.zeros(a, dtype=array.dtype)\n        newarray[:, :, 1:-1, ...] = array\n        newarray[:, :, 0, ...] = array[:, :, 0, ...]\n        newarray[:, :, -1, ...] = array[:, :, -1, ...]\n    else:\n        raise ValueError(\'Array to pad needs to have 1 or at least 3 dimensions\')\n    return newarray\n\n\n@veros_method(inline=True)\ndef solve_implicit(vs, ks, a, b, c, d, b_edge=None, d_edge=None):\n    from .numerics import solve_tridiag  # avoid circular import\n\n    land_mask = (ks >= 0)[:, :, np.newaxis]\n    edge_mask = land_mask & (np.arange(a.shape[2])[np.newaxis, np.newaxis, :]\n                             == ks[:, :, np.newaxis])\n    water_mask = land_mask & (np.arange(a.shape[2])[np.newaxis, np.newaxis, :]\n                              >= ks[:, :, np.newaxis])\n\n    a_tri = water_mask * a * np.logical_not(edge_mask)\n    #a_tri = np.logical_not(edge_mask) * a_tri\n    b_tri = where(vs, water_mask, b, 1.)\n    if b_edge is not None:\n        b_tri = where(vs, edge_mask, b_edge, b_tri)\n    c_tri = water_mask * c\n    d_tri = water_mask * d\n    if d_edge is not None:\n        d_tri = where(vs, edge_mask, d_edge, d_tri)\n\n    return solve_tridiag(vs, a_tri, b_tri, c_tri, d_tri), water_mask\n'"
veros/diagnostics/__init__.py,1,"b'from loguru import logger\n\nfrom . import averages, cfl_monitor, energy, overturning, snapshot, tracer_monitor, io_tools\nfrom .. import time, veros_method\nfrom .io_tools import hdf5 as h5tools\n\n\n@veros_method\ndef create_default_diagnostics(vs):\n    return {Diag.name: Diag(vs) for Diag in (averages.Averages, cfl_monitor.CFLMonitor,\n                                             energy.Energy, overturning.Overturning,\n                                             snapshot.Snapshot, tracer_monitor.TracerMonitor)}\n\n\n@veros_method\ndef sanity_check(vs):\n    from ..distributed import global_and\n    return global_and(vs, np.all(np.isfinite(vs.u)))\n\n\n@veros_method\ndef read_restart(vs):\n    if not vs.restart_input_filename:\n        return\n    if vs.force_overwrite:\n        raise RuntimeError(\'To prevent data loss, force_overwrite cannot be used in restart runs\')\n    logger.info(\'Reading restarts\')\n    for diagnostic in vs.diagnostics.values():\n        diagnostic.read_restart(vs, vs.restart_input_filename.format(**vars(vs)))\n\n\n@veros_method\ndef write_restart(vs, force=False):\n    if vs.diskless_mode:\n        return\n    if not vs.restart_output_filename:\n        return\n    if force or vs.restart_frequency and vs.time % vs.restart_frequency < vs.dt_tracer:\n        output_filename = vs.restart_output_filename.format(**vars(vs))\n        logger.info(\'Writing restart file {}...\', output_filename)\n        with h5tools.threaded_io(vs, output_filename, \'w\') as outfile:\n            for diagnostic in vs.diagnostics.values():\n                diagnostic.write_restart(vs, outfile)\n\n\n@veros_method\ndef initialize(vs):\n    for name, diagnostic in vs.diagnostics.items():\n        diagnostic.initialize(vs)\n        if diagnostic.sampling_frequency:\n            logger.info(\' Running diagnostic ""{0}"" every {1[0]:.1f} {1[1]}\'\n                         .format(name, time.format_time(diagnostic.sampling_frequency)))\n        if diagnostic.output_frequency:\n            logger.info(\' Writing output for diagnostic ""{0}"" every {1[0]:.1f} {1[1]}\'\n                         .format(name, time.format_time(diagnostic.output_frequency)))\n\n\n@veros_method\ndef diagnose(vs):\n    for diagnostic in vs.diagnostics.values():\n        if diagnostic.sampling_frequency and vs.time % diagnostic.sampling_frequency < vs.dt_tracer:\n            diagnostic.diagnose(vs)\n\n\n@veros_method\ndef output(vs):\n    for diagnostic in vs.diagnostics.values():\n        if diagnostic.output_frequency and vs.time % diagnostic.output_frequency < vs.dt_tracer:\n            diagnostic.output(vs)\n\n\ndef start_profiler():\n    import pyinstrument\n    profiler = pyinstrument.Profiler()\n    profiler.start()\n    return profiler\n\n\ndef stop_profiler(profiler):\n    if profiler is None:\n        return\n\n    profiler.stop()\n    with open(\'profile.html\', \'w\') as f:\n        f.write(profiler.output_html())\n'"
veros/diagnostics/averages.py,0,"b'from collections import namedtuple\nimport os\nimport copy\n\nfrom .diagnostic import VerosDiagnostic\nfrom .. import veros_method\nfrom ..variables import TIMESTEPS, allocate\n\nRunning_sum = namedtuple(\'Running_sum\', (\'var\', \'sum\'))\n\n\nclass Averages(VerosDiagnostic):\n    """"""Time average output diagnostic.\n\n    All registered variables are summed up when :meth:`diagnose` is called,\n    and averaged and output upon calling :meth:`output`.\n    """"""\n    name = \'averages\' #:\n    output_path = \'{identifier}.averages.nc\'  #: File to write to. May contain format strings that are replaced with Veros attributes.\n    output_variables = None #: Iterable containing all variables to be averaged. Changes have no effect after ``initialize`` has been called.\n    output_frequency = None  #: Frequency (in seconds) in which output is written.\n    sampling_frequency = None  #: Frequency (in seconds) in which variables are accumulated.\n\n    @veros_method\n    def initialize(self, vs):\n        """"""Register all variables to be averaged\n        """"""\n        self.average_nitts = 0\n        self.average_vars = {}\n\n        if not self.output_variables:\n            return\n        for var in self.output_variables:\n            var_data = copy.copy(vs.variables[var])\n            var_data.time_dependent = True\n            if self._has_timestep_dim(vs, var):\n                var_data.dims = var_data.dims[:-1]\n            var_sum = allocate(vs, var_data.dims)\n            self.average_vars[var] = Running_sum(var_data, var_sum)\n        self.initialize_output(vs, {key: runsum.var for key,\n                                    runsum in self.average_vars.items()})\n\n    @staticmethod\n    def _has_timestep_dim(vs, var):\n        return vs.variables[var].dims[-1] == TIMESTEPS[0]\n\n    def diagnose(self, vs):\n        self.average_nitts += 1\n        for key, var in self.average_vars.items():\n            if self._has_timestep_dim(vs, key):\n                var.sum[...] += getattr(vs, key)[..., vs.tau]\n            else:\n                var.sum[...] += getattr(vs, key)\n\n    def output(self, vs):\n        """"""Write averages to netcdf file and zero array\n        """"""\n        variable_metadata = {key: runsum.var for key, runsum in self.average_vars.items()}\n        if not os.path.isfile(self.get_output_file_name(vs)):\n            self.initialize_output(vs, variable_metadata)\n        variable_mean = {key: runsum.sum / self.average_nitts for key,\n                         runsum in self.average_vars.items()}\n        self.write_output(vs, variable_metadata, variable_mean)\n        for runsum in self.average_vars.values():\n            runsum.sum[...] = 0.\n        self.average_nitts = 0\n\n    def read_restart(self, vs, infile):\n        attributes, variables = self.read_h5_restart(vs, vs.variables, infile)\n        if attributes:\n            self.average_nitts = attributes[\'average_nitts\']\n        if variables:\n            self.average_vars = {key: Running_sum(copy.copy(vs.variables[key]), var)\n                                 for key, var in variables.items()}\n        for key, runsum in self.average_vars.items():\n            runsum.var.time_dependent = True\n            if self._has_timestep_dim(vs, key):\n                runsum.var.dims = runsum.var.dims[:-1]\n\n    def write_restart(self, vs, outfile):\n        attributes = {\'average_nitts\': self.average_nitts}\n        variables = {key: runsum.sum for key, runsum in self.average_vars.items()}\n        variable_metadata = {key: runsum.var for key, runsum in self.average_vars.items()}\n        self.write_h5_restart(vs, attributes, variable_metadata, variables, outfile)\n'"
veros/diagnostics/cfl_monitor.py,15,"b'from loguru import logger\n\nfrom .diagnostic import VerosDiagnostic\nfrom .. import veros_method\nfrom ..distributed import global_max\n\n\nclass CFLMonitor(VerosDiagnostic):\n    """"""Diagnostic monitoring the maximum CFL number of the solution to detect\n    instabilities.\n\n    Writes output to stdout (no binary output).\n    """"""\n    name = \'cfl_monitor\' #:\n    output_frequency = None  # :Frequency (in seconds) in which output is written.\n\n    def initialize(self, vs):\n        pass\n\n    def diagnose(self, vs):\n        pass\n\n    @veros_method\n    def output(self, vs):\n        """"""\n        check for CFL violation\n        """"""\n        cfl = global_max(vs, max(\n            np.max(np.abs(vs.u[2:-2, 2:-2, :, vs.tau]) * vs.maskU[2:-2, 2:-2, :]\n                   / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis])\n                   * vs.dt_tracer),\n            np.max(np.abs(vs.v[2:-2, 2:-2, :, vs.tau]) * vs.maskV[2:-2, 2:-2, :]\n                   / vs.dyt[np.newaxis, 2:-2, np.newaxis] * vs.dt_tracer)\n        ))\n        wcfl = global_max(vs, np.max(\n            np.abs(vs.w[2:-2, 2:-2, :, vs.tau]) * vs.maskW[2:-2, 2:-2, :]\n                      / vs.dzt[np.newaxis, np.newaxis, :] * vs.dt_tracer\n        ))\n\n        if np.isnan(cfl) or np.isnan(wcfl):\n            raise RuntimeError(\'CFL number is NaN at iteration {}\'.format(vs.itt))\n\n        logger.diagnostic(\' Maximal hor. CFL number = {}\'.format(float(cfl)))\n        logger.diagnostic(\' Maximal ver. CFL number = {}\'.format(float(wcfl)))\n\n        if vs.enable_eke or vs.enable_tke or vs.enable_idemix:\n            cfl = global_max(vs, max(\n                np.max(np.abs(vs.u_wgrid[2:-2, 2:-2, :]) * vs.maskU[2:-2, 2:-2, :]\n                       / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis])\n                       * vs.dt_tracer),\n                np.max(np.abs(vs.v_wgrid[2:-2, 2:-2, :]) * vs.maskV[2:-2, 2:-2, :]\n                       / vs.dyt[np.newaxis, 2:-2, np.newaxis] * vs.dt_tracer)\n            ))\n            wcfl = global_max(vs, np.max(\n                np.abs(vs.w_wgrid[2:-2, 2:-2, :]) * vs.maskW[2:-2, 2:-2, :]\n                    / vs.dzt[np.newaxis, np.newaxis, :] * vs.dt_tracer\n            ))\n            logger.diagnostic(\' Maximal hor. CFL number on w grid = {}\'.format(float(cfl)))\n            logger.diagnostic(\' Maximal ver. CFL number on w grid = {}\'.format(float(wcfl)))\n\n    def read_restart(self, vs, infile):\n        pass\n\n    def write_restart(self, vs, outfile):\n        pass\n'"
veros/diagnostics/diagnostic.py,2,"b'import os\n\nfrom loguru import logger\n\nfrom .io_tools import netcdf as nctools, hdf5 as h5tools\nfrom ..decorators import veros_method, do_not_disturb\nfrom .. import time, runtime_state, distributed, runtime_settings\n\n\nclass VerosDiagnostic:\n    """"""Base class for diagnostics. Provides an interface and wrappers for common I/O.\n\n    Any diagnostic needs to implement the five interface methods and set some attributes.\n    """"""\n    name = None #: Name that identifies the current diagnostic\n    sampling_frequency = 0.\n    output_frequency = 0.\n    output_path = None\n\n    def __init__(self, vs):\n        pass\n\n    def _not_implemented(self, vs):\n        raise NotImplementedError(\'must be implemented by subclass\')\n\n    initialize = _not_implemented\n    """"""Called at the end of setup. Use this to process user settings and handle setup.""""""\n\n    diagnose = _not_implemented\n    """"""Called with frequency ``sampling_frequency``.""""""\n\n    output = _not_implemented\n    """"""Called with frequency ``output_frequency``.""""""\n\n    write_restart = _not_implemented\n    """"""Responsible for writing restart files.""""""\n\n    read_restart = _not_implemented\n    """"""Responsible for reading restart files.""""""\n\n    @veros_method\n    def get_output_file_name(self, vs):\n        return self.output_path.format(**vars(vs))\n\n    @do_not_disturb\n    @veros_method\n    def initialize_output(self, vs, variables, var_data=None, extra_dimensions=None):\n        if vs.diskless_mode or (not self.output_frequency and not self.sampling_frequency):\n            return\n\n        output_path = self.get_output_file_name(vs)\n        if os.path.isfile(output_path) and not vs.force_overwrite:\n            raise IOError(\'output file {} for diagnostic ""{}"" exists \'\n                          \'(change output path or enable force_overwrite setting)\'\n                          .format(output_path, self.name))\n\n        # possible race condition!\n        distributed.barrier()\n\n        with nctools.threaded_io(vs, output_path, \'w\') as outfile:\n            nctools.initialize_file(vs, outfile)\n            if extra_dimensions:\n                for dim_id, size in extra_dimensions.items():\n                    nctools.add_dimension(vs, dim_id, size, outfile)\n            for key, var in variables.items():\n                if key not in outfile.variables:\n                    nctools.initialize_variable(vs, key, var, outfile)\n                if not var.time_dependent:\n                    if var_data is None or key not in var_data:\n                        raise ValueError(\'var_data argument must be given for constant variables\')\n                    nctools.write_variable(vs, key, var, var_data[key], outfile)\n\n    @do_not_disturb\n    @veros_method\n    def write_output(self, vs, variables, variable_data):\n        if vs.diskless_mode:\n            return\n        with nctools.threaded_io(vs, self.get_output_file_name(vs), \'r+\') as outfile:\n            time_step = nctools.get_current_timestep(vs, outfile)\n            current_days = time.convert_time(vs.time, \'seconds\', \'days\')\n            nctools.advance_time(vs, time_step, current_days, outfile)\n            for key, var in variables.items():\n                nctools.write_variable(vs, key, var, variable_data[key],\n                                       outfile, time_step=time_step)\n\n    @veros_method\n    def read_h5_restart(self, vs, var_meta, restart_filename):\n        if not os.path.isfile(restart_filename):\n            raise IOError(\'restart file {} not found\'.format(restart_filename))\n\n        logger.info(\' Reading restart data for diagnostic {} from {}\',\n                    self.name, restart_filename)\n\n        with h5tools.threaded_io(vs, restart_filename, \'r\') as infile:\n            variables = {}\n            for key, var in infile[self.name].items():\n                if np.isscalar(var):\n                    variables[key] = var\n                    continue\n\n                local_shape = distributed.get_local_size(vs, var.shape, var_meta[key].dims, include_overlap=True)\n                gidx, lidx = distributed.get_chunk_slices(vs, var_meta[key].dims[:var.ndim], include_overlap=True)\n\n                variables[key] = np.empty(local_shape, dtype=str(var.dtype))\n\n                if runtime_settings.backend == \'bohrium\':\n                    variables[key][lidx] = var[gidx].astype(variables[key].dtype)\n                else:\n                    variables[key][lidx] = var[gidx]\n\n                distributed.exchange_overlap(vs, variables[key], var_meta[key].dims)\n\n            attributes = {key: var.item() for key, var in infile[self.name].attrs.items()}\n\n        return attributes, variables\n\n    @do_not_disturb\n    @veros_method\n    def write_h5_restart(self, vs, attributes, var_meta, var_data, outfile):\n        group = outfile.require_group(self.name)\n        for key, var in var_data.items():\n            try:\n                var = var.copy2numpy()\n            except AttributeError:\n                pass\n\n            global_shape = distributed.get_global_size(vs, var.shape, var_meta[key].dims, include_overlap=True)\n            gidx, lidx = distributed.get_chunk_slices(vs, var_meta[key].dims, include_overlap=True)\n\n            kwargs = dict(\n                exact=True,\n                chunks=tuple(\n                    distributed.get_local_size(vs, var.shape, var_meta[key].dims, include_overlap=False)\n                )\n            )\n            if vs.enable_hdf5_gzip_compression and runtime_state.proc_num == 1:\n                kwargs.update(\n                    compression=\'gzip\',\n                    compression_opts=1\n                )\n            group.require_dataset(key, global_shape, var.dtype, **kwargs)\n            group[key][gidx] = var[lidx]\n\n        for key, val in attributes.items():\n            try:\n                val = val.copy2numpy()\n            except AttributeError:\n                pass\n\n            group.attrs[key] = val\n'"
veros/diagnostics/energy.py,25,"b'import os\n\nfrom .diagnostic import VerosDiagnostic\nfrom .. import veros_method\nfrom ..variables import Variable\nfrom ..distributed import global_sum\n\n\nENERGY_VARIABLES = dict(\n    # mean energy content\n    k_m=Variable(\'Mean kinetic energy\', [], \'J\', \'Mean kinetic energy\',\n                 output=True, write_to_restart=True),\n    Hd_m=Variable(\'Mean dynamic enthalpy\', [], \'J\', \'Mean dynamic enthalpy\',\n                  output=True, write_to_restart=True),\n    eke_m=Variable(\'Meso-scale eddy energy\', [], \'J\', \'Meso-scale eddy energy\',\n                   output=True, write_to_restart=True),\n    iw_m=Variable(\'Internal wave energy\', [], \'J\', \'Internal wave energy\',\n                  output=True, write_to_restart=True),\n    tke_m=Variable(\'Turbulent kinetic energy\', [], \'J\', \'Turbulent kinetic energy\',\n                   output=True, write_to_restart=True),\n\n    # energy changes\n    dE_tot_m=Variable(\'Change of total energy\', [], \'W\', \'Change of total energy\',\n                      output=True, write_to_restart=True),\n    dk_m=Variable(\'Change of KE\', [], \'W\', \'Change of kinetic energy\',\n                  output=True, write_to_restart=True),\n    dHd_m=Variable(\'Change of Hd\', [], \'W\', \'Change of dynamic enthalpy\',\n                   output=True, write_to_restart=True),\n    deke_m=Variable(\'Change of EKE\', [], \'W\', \'Change of meso-scale eddy energy\',\n                    output=True, write_to_restart=True),\n    diw_m=Variable(\'Change of E_iw\', [], \'W\', \'Change of internal wave energy\',\n                   output=True, write_to_restart=True),\n    dtke_m=Variable(\'Change of TKE\', [], \'W\', \'Change of tubulent kinetic energy\',\n                    output=True, write_to_restart=True),\n\n    # dissipation\n    ke_diss_m=Variable(\'Dissipation of KE\', [], \'W\', \'Dissipation of kinetic energy\',\n                       output=True, write_to_restart=True),\n    Hd_diss_m=Variable(\'Dissipation of Hd\', [], \'W\', \'Dissipation of dynamic enthalpy\',\n                       output=True, write_to_restart=True),\n    eke_diss_m=Variable(\'Dissipation of EKE\', [], \'W\', \'Dissipation of meso-scale eddy energy\',\n                        output=True, write_to_restart=True),\n    iw_diss_m=Variable(\'Dissipation of E_iw\', [], \'W\', \'Dissipation of internal wave energy\',\n                       output=True, write_to_restart=True),\n    tke_diss_m=Variable(\'Dissipation of TKE\', [], \'W\', \'Dissipation of turbulent kinetic energy\',\n                        output=True, write_to_restart=True),\n    adv_diss_m=Variable(\'Dissipation by advection\', [], \'W\', \'Dissipation by advection\',\n                        output=True, write_to_restart=True),\n\n    # external forcing\n    wind_m=Variable(\'Wind work\', [], \'W\', \'Wind work\',\n                    output=True, write_to_restart=True),\n    dHd_sources_m=Variable(\'Hd production by ext. sources\', [], \'W\',\n                           \'Dynamic enthalpy production through external sources\',\n                           output=True, write_to_restart=True),\n    iw_forc_m=Variable(\'External forcing of E_iw\', [], \'W\',\n                       \'External forcing of internal wave energy\',\n                       output=True, write_to_restart=True),\n    tke_forc_m=Variable(\'External forcing of TKE\', [], \'W\',\n                        \'External forcing of turbulent kinetic energy\',\n                        output=True, write_to_restart=True),\n\n    # exchange\n    ke_hd_m=Variable(\'Exchange KE -> Hd\', [], \'W\',\n                     \'Exchange between kinetic energy and dynamic enthalpy\',\n                     output=True, write_to_restart=True),\n    ke_tke_m=Variable(\'Exchange KE -> TKE by vert. friction\', [], \'W\',\n                      \'Exchange between kinetic energy and turbulent kinetic energy by vertical friction\',\n                      output=True, write_to_restart=True),\n    ke_iw_m=Variable(\'Exchange KE -> IW by bottom friction\', [], \'W\',\n                     \'Exchange between kinetic energy and internal wave energy by bottom friction\',\n                     output=True, write_to_restart=True),\n    tke_hd_m=Variable(\'Exchange TKE -> Hd by vertical mixing\', [], \'W\',\n                      \'Exchange between turbulent kinetic energy and dynamic enthalpy by vertical mixing\',\n                      output=True, write_to_restart=True),\n    ke_eke_m=Variable(\'Exchange KE -> EKE by lateral friction\', [], \'W\',\n                      \'Exchange between kinetic energy and eddy kinetic energy by lateral friction\',\n                      output=True, write_to_restart=True),\n    hd_eke_m=Variable(\'Exchange Hd -> EKE by GM and lateral mixing\', [], \'W\',\n                      \'Exchange between dynamic enthalpy and eddy kinetic energy by GM and lateral mixing\',\n                      output=True, write_to_restart=True),\n    eke_tke_m=Variable(\'Exchange EKE -> TKE\', [], \'W\',\n                       \'Exchange between eddy and turbulent kinetic energy\',\n                       output=True, write_to_restart=True),\n    eke_iw_m=Variable(\'Exchange EKE -> IW\', [], \'W\',\n                      \'Exchange between eddy kinetic energy and internal wave energy\',\n                      output=True, write_to_restart=True),\n\n    # cabbeling\n    cabb_m=Variable(\'Cabbeling by vertical mixing\', [], \'W\',\n                    \'Cabbeling by vertical mixing\',\n                    output=True, write_to_restart=True),\n    cabb_iso_m=Variable(\'Cabbeling by isopycnal mixing\', [], \'W\',\n                        \'Cabbeling by isopycnal mixing\',\n                        output=True, write_to_restart=True),\n)\n\n\nclass Energy(VerosDiagnostic):\n    """"""Diagnose globally averaged energy cycle. Also averages energy in time.\n    """"""\n    name = \'energy\' #:\n    output_path = \'{identifier}.energy.nc\'  #: File to write to. May contain format strings that are replaced with Veros attributes.\n    output_frequency = None  #: Frequency (in seconds) in which output is written.\n    sampling_frequency = None  #: Frequency (in seconds) in which variables are accumulated.\n    variables = ENERGY_VARIABLES\n\n    @veros_method\n    def initialize(self, vs):\n        self.nitts = 0\n        for var in self.variables.keys():\n            setattr(self, var, 0.)\n\n        output_variables = {key: val for key, val in self.variables.items() if val.output}\n        self.initialize_output(vs, output_variables)\n\n    @veros_method\n    def diagnose(self, vs):\n        # changes of dynamic enthalpy\n        vol_t = vs.area_t[2:-2, 2:-2, np.newaxis] \\\n            * vs.dzt[np.newaxis, np.newaxis, :] \\\n            * vs.maskT[2:-2, 2:-2, :]\n        dP_iso = global_sum(vs,\n            np.sum(vol_t * vs.grav / vs.rho_0\n                         * (-vs.int_drhodT[2:-2, 2:-2, :, vs.tau]\n                           * vs.dtemp_iso[2:-2, 2:-2, :]\n                           - vs.int_drhodS[2:-2, 2:-2, :, vs.tau]\n                           * vs.dsalt_iso[2:-2, 2:-2, :]))\n        )\n        dP_hmix = global_sum(vs,\n            np.sum(vol_t * vs.grav / vs.rho_0\n                         * (-vs.int_drhodT[2:-2, 2:-2, :, vs.tau]\n                            * vs.dtemp_hmix[2:-2, 2:-2, :]\n                            - vs.int_drhodS[2:-2, 2:-2, :, vs.tau]\n                            * vs.dsalt_hmix[2:-2, 2:-2, :]))\n        )\n        dP_vmix = global_sum(vs,\n            np.sum(vol_t * vs.grav / vs.rho_0\n                         * (-vs.int_drhodT[2:-2, 2:-2, :, vs.tau]\n                            * vs.dtemp_vmix[2:-2, 2:-2, :]\n                            - vs.int_drhodS[2:-2, 2:-2, :, vs.tau]\n                            * vs.dsalt_vmix[2:-2, 2:-2, :]))\n        )\n        dP_m = global_sum(vs,\n            np.sum(vol_t * vs.grav / vs.rho_0\n                      * (-vs.int_drhodT[2:-2, 2:-2, :, vs.tau]\n                          * vs.dtemp[2:-2, 2:-2, :, vs.tau]\n                          - vs.int_drhodS[2:-2, 2:-2, :, vs.tau]\n                          * vs.dsalt[2:-2, 2:-2, :, vs.tau]))\n        )\n        dP_m_all = dP_m + dP_vmix + dP_hmix + dP_iso\n\n        # changes of kinetic energy\n        vol_u = vs.area_u[2:-2, 2:-2, np.newaxis] \\\n            * vs.dzt[np.newaxis, np.newaxis, :]\n        vol_v = vs.area_v[2:-2, 2:-2, np.newaxis] \\\n            * vs.dzt[np.newaxis, np.newaxis, :]\n        k_m = global_sum(vs,\n            np.sum(vol_t * 0.5 * (0.5 * (vs.u[2:-2, 2:-2, :, vs.tau] ** 2\n                                           + vs.u[1:-3, 2:-2, :, vs.tau] ** 2)\n                                    + 0.5 * (vs.v[2:-2, 2:-2, :, vs.tau] ** 2)\n                                    + vs.v[2:-2, 1:-3, :, vs.tau] ** 2))\n        )\n        p_m = global_sum(vs, np.sum(vol_t * vs.Hd[2:-2, 2:-2, :, vs.tau]))\n        dk_m = global_sum(vs,\n            np.sum(vs.u[2:-2, 2:-2, :, vs.tau] * vs.du[2:-2, 2:-2, :, vs.tau] * vol_u\n                      + vs.v[2:-2, 2:-2, :, vs.tau]\n                      * vs.dv[2:-2, 2:-2, :, vs.tau] * vol_v\n                      + vs.u[2:-2, 2:-2, :, vs.tau] * vs.du_mix[2:-2, 2:-2, :] * vol_u\n                      + vs.v[2:-2, 2:-2, :, vs.tau] * vs.dv_mix[2:-2, 2:-2, :] * vol_v)\n        )\n\n        # K*Nsqr and KE and dyn. enthalpy dissipation\n        vol_w = vs.area_t[2:-2, 2:-2, np.newaxis] * vs.dzw[np.newaxis, np.newaxis, :] \\\n            * vs.maskW[2:-2, 2:-2, :]\n        vol_w[:, :, -1] *= 0.5\n\n        def mean_w(var):\n            return global_sum(vs, np.sum(var[2:-2, 2:-2, :] * vol_w))\n\n        mdiss_vmix = mean_w(vs.P_diss_v)\n        mdiss_nonlin = mean_w(vs.P_diss_nonlin)\n        mdiss_adv = mean_w(vs.P_diss_adv)\n        mdiss_hmix = mean_w(vs.P_diss_hmix)\n        mdiss_iso = mean_w(vs.P_diss_iso)\n        mdiss_skew = mean_w(vs.P_diss_skew)\n        mdiss_sources = mean_w(vs.P_diss_sources)\n\n        mdiss_h = mean_w(vs.K_diss_h)\n        mdiss_v = mean_w(vs.K_diss_v)\n        mdiss_gm = mean_w(vs.K_diss_gm)\n        mdiss_bot = mean_w(vs.K_diss_bot)\n\n        wrhom = global_sum(vs, \n            np.sum(-vs.area_t[2:-2, 2:-2, np.newaxis] * vs.maskW[2:-2, 2:-2, :-1]\n                       * (vs.p_hydro[2:-2, 2:-2, 1:] - vs.p_hydro[2:-2, 2:-2, :-1])\n                       * vs.w[2:-2, 2:-2, :-1, vs.tau])\n        )\n\n        # wind work\n        if vs.pyom_compatibility_mode:\n            wind = global_sum(\n                vs,\n                np.sum(vs.u[2:-2, 2:-2, -1, vs.tau] * vs.surface_taux[2:-2, 2:-2]\n                       * vs.maskU[2:-2, 2:-2, -1] * vs.area_u[2:-2, 2:-2]\n                       + vs.v[2:-2, 2:-2, -1, vs.tau] * vs.surface_tauy[2:-2, 2:-2]\n                       * vs.maskV[2:-2, 2:-2, -1] * vs.area_v[2:-2, 2:-2])\n            )\n        else:\n            wind = global_sum(\n                vs,\n                np.sum(vs.u[2:-2, 2:-2, -1, vs.tau] * vs.surface_taux[2:-2, 2:-2] / vs.rho_0\n                       * vs.maskU[2:-2, 2:-2, -1] * vs.area_u[2:-2, 2:-2]\n                       + vs.v[2:-2, 2:-2, -1, vs.tau] * vs.surface_tauy[2:-2, 2:-2] / vs.rho_0\n                       * vs.maskV[2:-2, 2:-2, -1] * vs.area_v[2:-2, 2:-2])\n            )\n\n        # meso-scale energy\n        if vs.enable_eke:\n            eke_m = mean_w(vs.eke[..., vs.tau])\n            deke_m = global_sum(vs,\n                np.sum(vol_w * (vs.eke[2:-2, 2:-2, :, vs.taup1]\n                                - vs.eke[2:-2, 2:-2, :, vs.tau])\n                       / vs.dt_tracer)\n            )\n            eke_diss = mean_w(vs.eke_diss_iw)\n            eke_diss_tke = mean_w(vs.eke_diss_tke)\n        else:\n            eke_m = deke_m = eke_diss_tke = 0.\n            eke_diss = mdiss_gm + mdiss_h + mdiss_skew\n            if not vs.enable_store_cabbeling_heat:\n                eke_diss += -mdiss_hmix - mdiss_iso\n\n        # small-scale energy\n        if vs.enable_tke:\n            dt_tke = vs.dt_mom\n            tke_m = mean_w(vs.tke[..., vs.tau])\n            dtke_m = mean_w((vs.tke[..., vs.taup1]\n                             - vs.tke[..., vs.tau])\n                            / dt_tke)\n            tke_diss = mean_w(vs.tke_diss)\n            tke_forc = global_sum(vs,\n                np.sum(vs.area_t[2:-2, 2:-2] * vs.maskW[2:-2, 2:-2, -1]\n                              * (vs.forc_tke_surface[2:-2, 2:-2] + vs.tke_surf_corr[2:-2, 2:-2]))\n            )\n        else:\n            tke_m = dtke_m = tke_diss = tke_forc = 0.\n\n        # internal wave energy\n        if vs.enable_idemix:\n            iw_m = mean_w(vs.E_iw[..., vs.tau])\n            diw_m = global_sum(vs,\n                np.sum(vol_w * (vs.E_iw[2:-2, 2:-2, :, vs.taup1]\n                                    - vs.E_iw[2:-2, 2:-2, :, vs.tau])\n                           / vs.dt_tracer)\n            )\n            iw_diss = mean_w(vs.iw_diss)\n\n            k = np.maximum(1, vs.kbot[2:-2, 2:-2]) - 1\n            mask = k[:, :, np.newaxis] == np.arange(vs.nz)[np.newaxis, np.newaxis, :]\n            iwforc = global_sum(vs, \n                np.sum(vs.area_t[2:-2, 2:-2]\n                            * (vs.forc_iw_surface[2:-2, 2:-2] * vs.maskW[2:-2, 2:-2, -1]\n                               + np.sum(mask * vs.forc_iw_bottom[2:-2, 2:-2, np.newaxis]\n                                        * vs.maskW[2:-2, 2:-2, :], axis=2)))\n            )\n        else:\n            iw_m = diw_m = iwforc = 0.\n            iw_diss = eke_diss\n\n        # store results\n        self.k_m += k_m\n        self.Hd_m += p_m\n        self.eke_m += eke_m\n        self.iw_m += iw_m\n        self.tke_m += tke_m\n\n        self.dk_m += dk_m\n        self.dHd_m += dP_m_all + mdiss_sources\n        self.deke_m += deke_m\n        self.diw_m += diw_m\n        self.dtke_m += dtke_m\n        self.dE_tot_m += self.dk_m + self.dHd_m + self.deke_m + self.diw_m + self.dtke_m\n\n        self.wind_m += wind\n        self.dHd_sources_m += mdiss_sources\n        self.iw_forc_m += iwforc\n        self.tke_forc_m += tke_forc\n\n        self.ke_diss_m += mdiss_h + mdiss_v + mdiss_gm + mdiss_bot\n        self.Hd_diss_m += mdiss_vmix + mdiss_nonlin + mdiss_hmix + mdiss_adv \\\n            + mdiss_iso + mdiss_skew\n        self.eke_diss_m += eke_diss + eke_diss_tke\n        self.iw_diss_m += iw_diss\n        self.tke_diss_m += tke_diss\n        self.adv_diss_m += mdiss_adv\n\n        self.ke_hd_m += wrhom\n        self.ke_eke_m += mdiss_h + mdiss_gm\n        self.hd_eke_m += -mdiss_skew\n        self.ke_tke_m += mdiss_v\n        self.tke_hd_m += -mdiss_vmix - mdiss_adv\n        if vs.enable_store_bottom_friction_tke:\n            self.ke_tke_m += mdiss_bot\n        else:\n            self.ke_iw_m += mdiss_bot\n        self.eke_tke_m += eke_diss_tke\n        self.eke_iw_m += eke_diss\n        if not vs.enable_store_cabbeling_heat:\n            self.hd_eke_m += -mdiss_hmix - mdiss_iso\n            self.tke_hd_m += -mdiss_nonlin\n\n        self.cabb_m += mdiss_nonlin\n        self.cabb_iso_m += mdiss_hmix + mdiss_iso\n\n        self.nitts += 1\n\n    @veros_method\n    def output(self, vs):\n        self.nitts = float(self.nitts or 1)\n        output_variables = {key: val for key, val in self.variables.items() if val.output}\n        output_data = {key: getattr(self, key) * vs.rho_0 / self.nitts\n                       for key in output_variables.keys()}\n        if not os.path.isfile(self.get_output_file_name(vs)):\n            self.initialize_output(vs, output_variables)\n        self.write_output(vs, output_variables, output_data)\n\n        for key in output_variables.keys():\n            setattr(self, key, 0.)\n        self.nitts = 0\n\n    @veros_method\n    def read_restart(self, vs, infile):\n        attributes, variables = self.read_h5_restart(vs, self.variables, infile)\n        if attributes:\n            for key, val in attributes.items():\n                setattr(self, key, val)\n\n    @veros_method\n    def write_restart(self, vs, outfile):\n        restart_data = {key: getattr(self, key)\n                        for key, val in self.variables.items() if val.write_to_restart}\n        restart_data.update({\'nitts\': self.nitts})\n        self.write_h5_restart(vs, restart_data, {}, {}, outfile)\n'"
veros/diagnostics/overturning.py,38,"b'from collections import OrderedDict\nimport os\n\nfrom loguru import logger\n\nfrom .. import veros_method\nfrom .diagnostic import VerosDiagnostic\nfrom ..core import density\nfrom ..variables import Variable, allocate\nfrom ..distributed import global_sum\n\n\nSIGMA = Variable(\n    \'Sigma axis\', (\'sigma\',), \'kg/m^3\', \'Sigma axis\', output=True,\n    time_dependent=False, write_to_restart=True\n)\n\nOVERTURNING_VARIABLES = OrderedDict([\n    (\'trans\', Variable(\n        \'Meridional transport\', (\'yu\', \'sigma\'), \'m^3/s\',\n        \'Meridional transport\', output=True, write_to_restart=True\n    )),\n    (\'vsf_iso\', Variable(\n        \'Meridional transport\', (\'yu\', \'zw\'), \'m^3/s\',\n        \'Meridional transport\', output=True, write_to_restart=True\n    )),\n    (\'vsf_depth\', Variable(\n        \'Meridional transport\', (\'yu\', \'zw\'), \'m^3/s\',\n        \'Meridional transport\', output=True, write_to_restart=True\n    )),\n])\nISONEUTRAL_VARIABLES = OrderedDict([\n    (\'bolus_iso\', Variable(\n        \'Meridional transport\', (\'yu\', \'zw\'), \'m^3/s\',\n        \'Meridional transport\', output=True, write_to_restart=True\n    )),\n    (\'bolus_depth\', Variable(\n        \'Meridional transport\', (\'yu\', \'zw\'), \'m^3/s\',\n        \'Meridional transport\', output=True, write_to_restart=True\n    )),\n])\n\n\n@veros_method(inline=True)\ndef zonal_sum(vs, arr):\n    return global_sum(vs, np.sum(arr, axis=0), axis=0)\n\n\nclass Overturning(VerosDiagnostic):\n    """"""Isopycnal overturning diagnostic. Computes and writes vertical streamfunctions\n    (zonally averaged).\n    """"""\n\n    name = \'overturning\'  #:\n    output_path = \'{identifier}.overturning.nc\'  #: File to write to. May contain format strings that are replaced with Veros attributes.\n    output_frequency = None  #: Frequency (in seconds) in which output is written.\n    sampling_frequency = None  #: Frequency (in seconds) in which variables are accumulated.\n    p_ref = 2000.  #: Reference pressure for isopycnals\n\n    def __init__(self, vs):\n        self.sigma_var = SIGMA\n        self.mean_variables = OVERTURNING_VARIABLES\n        if vs.enable_neutral_diffusion and vs.enable_skew_diffusion:\n            self.mean_variables.update(ISONEUTRAL_VARIABLES)\n        self.variables = self.mean_variables.copy()\n        self.variables.update({\'sigma\': self.sigma_var})\n\n    @veros_method\n    def initialize(self, vs):\n        self.nitts = 0\n        self.nlevel = vs.nz * 4\n        self._allocate(vs)\n\n        # sigma levels\n        self.sige = density.get_potential_rho(vs, 35., -2., press_ref=self.p_ref)\n        self.sigs = density.get_potential_rho(vs, 35., 30., press_ref=self.p_ref)\n        self.dsig = float(self.sige - self.sigs) / (self.nlevel - 1)\n\n        logger.debug(\' Sigma ranges for overturning diagnostic:\')\n        logger.debug(\' Start sigma0 = {:.1f}\'.format(self.sigs))\n        logger.debug(\' End sigma0 = {:.1f}\'.format(self.sige))\n        logger.debug(\' Delta sigma0 = {:.1e}\'.format(self.dsig))\n        if vs.enable_neutral_diffusion and vs.enable_skew_diffusion:\n            logger.debug(\' Also calculating overturning by eddy-driven velocities\')\n\n        self.sigma[...] = self.sigs + self.dsig * np.arange(self.nlevel)\n\n        # precalculate area below z levels\n        self.zarea[2:-2, :] = np.cumsum(zonal_sum(vs,\n            vs.dxt[2:-2, np.newaxis, np.newaxis]\n            * vs.cosu[np.newaxis, 2:-2, np.newaxis]\n            * vs.maskV[2:-2, 2:-2, :]) * vs.dzt[np.newaxis, :], axis=1)\n\n        self.initialize_output(vs, self.variables,\n                               var_data={\'sigma\': self.sigma},\n                               extra_dimensions={\'sigma\': self.nlevel})\n\n    @veros_method\n    def _allocate(self, vs):\n        self.sigma = allocate(vs, (self.nlevel,))\n        self.zarea = allocate(vs, (\'yu\', \'zt\'))\n        self.trans = allocate(vs, (\'yu\', self.nlevel))\n        self.vsf_iso = allocate(vs, (\'yu\', \'zt\'))\n        self.vsf_depth = allocate(vs, (\'yu\', \'zt\'))\n        if vs.enable_neutral_diffusion and vs.enable_skew_diffusion:\n            self.bolus_iso = allocate(vs, (\'yu\', \'zt\'))\n            self.bolus_depth = allocate(vs, (\'yu\', \'zt\'))\n\n    @veros_method\n    def diagnose(self, vs):\n        # sigma at p_ref\n        sig_loc = allocate(vs, (\'xt\', \'yt\', \'zt\'))\n        sig_loc[2:-2, 2:-1, :] = density.get_rho(vs,\n                                                 vs.salt[2:-2, 2:-1, :, vs.tau],\n                                                 vs.temp[2:-2, 2:-1, :, vs.tau],\n                                                 self.p_ref)\n\n        # transports below isopycnals and area below isopycnals\n        sig_loc_face = 0.5 * (sig_loc[2:-2, 2:-2, :] + sig_loc[2:-2, 3:-1, :])\n        trans = allocate(vs, (\'yu\', self.nlevel))\n        z_sig = allocate(vs, (\'yu\', self.nlevel))\n\n        fac = (vs.dxt[2:-2, np.newaxis, np.newaxis]\n                * vs.cosu[np.newaxis, 2:-2, np.newaxis]\n                * vs.dzt[np.newaxis, np.newaxis, :]\n                * vs.maskV[2:-2, 2:-2, :])\n\n        for m in range(self.nlevel):\n            # NOTE: vectorized version would be O(N^4) in memory\n            # consider cythonizing if performance-critical\n            mask = sig_loc_face > self.sigma[m]\n            trans[2:-2, m] = zonal_sum(vs, np.sum(vs.v[2:-2, 2:-2, :, vs.tau] * fac * mask, axis=2))\n            z_sig[2:-2, m] = zonal_sum(vs, np.sum(fac * mask, axis=2))\n\n        self.trans += trans\n\n        if vs.enable_neutral_diffusion and vs.enable_skew_diffusion:\n            bolus_trans = allocate(vs, (\'yu\', self.nlevel))\n            # eddy-driven transports below isopycnals\n            for m in range(self.nlevel):\n                # NOTE: see above\n                mask = sig_loc_face > self.sigma[m]\n                bolus_trans[2:-2, m] = zonal_sum(vs,\n                    np.sum(\n                        (vs.B1_gm[2:-2, 2:-2, 1:] - vs.B1_gm[2:-2, 2:-2, :-1])\n                        * vs.dxt[2:-2, np.newaxis, np.newaxis]\n                        * vs.cosu[np.newaxis, 2:-2, np.newaxis]\n                        * vs.maskV[2:-2, 2:-2, 1:]\n                        * mask[:, :, 1:],\n                        axis=2\n                    )\n                    +\n                    vs.B1_gm[2:-2, 2:-2, 0]\n                    * vs.dxt[2:-2, np.newaxis]\n                    * vs.cosu[np.newaxis, 2:-2]\n                    * vs.maskV[2:-2, 2:-2, 0]\n                    * mask[:, :, 0]\n                )\n\n        # streamfunction on geopotentials\n        self.vsf_depth[2:-2, :] += np.cumsum(zonal_sum(vs,\n            vs.dxt[2:-2, np.newaxis, np.newaxis]\n            * vs.cosu[np.newaxis, 2:-2, np.newaxis]\n            * vs.v[2:-2, 2:-2, :, vs.tau]\n            * vs.maskV[2:-2, 2:-2, :]) * vs.dzt[np.newaxis, :], axis=1)\n\n        if vs.enable_neutral_diffusion and vs.enable_skew_diffusion:\n            # streamfunction for eddy driven velocity on geopotentials\n            self.bolus_depth[2:-2, :] += zonal_sum(vs,\n                vs.dxt[2:-2, np.newaxis, np.newaxis]\n                * vs.cosu[np.newaxis, 2:-2, np.newaxis]\n                * vs.B1_gm[2:-2, 2:-2, :])\n\n        # interpolate from isopycnals to depth\n        self.vsf_iso[2:-2, :] += self._interpolate_along_axis(vs,\n                                                              z_sig[2:-2, :], trans[2:-2, :],\n                                                              self.zarea[2:-2, :], 1)\n        if vs.enable_neutral_diffusion and vs.enable_skew_diffusion:\n            self.bolus_iso[2:-2, :] += self._interpolate_along_axis(vs,\n                                                                    z_sig[2:-2, :], bolus_trans[2:-2, :],\n                                                                    self.zarea[2:-2, :], 1)\n\n        self.nitts += 1\n\n    @veros_method\n    def _interpolate_along_axis(self, vs, coords, arr, interp_coords, axis=0):\n        # TODO: clean up this mess\n\n        if coords.ndim == 1:\n            if len(coords) != arr.shape[axis]:\n                raise ValueError(\'Coordinate shape must match array shape along axis\')\n        elif coords.ndim == arr.ndim:\n            if coords.shape != arr.shape:\n                raise ValueError(\'Coordinate shape must match array shape\')\n        else:\n            raise ValueError(\'Coordinate shape must match array dimensions\')\n\n        if axis != 0:\n            arr = np.moveaxis(arr, axis, 0)\n            coords = np.moveaxis(coords, axis, 0)\n            interp_coords = np.moveaxis(interp_coords, axis, 0)\n\n        diff = coords[np.newaxis, :, ...] - interp_coords[:, np.newaxis, ...]\n        diff_m = np.where(diff <= 0., np.abs(diff), np.inf)\n        diff_p = np.where(diff > 0., np.abs(diff), np.inf)\n        i_m = np.asarray(np.argmin(diff_m, axis=1))\n        i_p = np.asarray(np.argmin(diff_p, axis=1))\n        mask = np.all(np.isinf(diff_m), axis=1)\n        i_m[mask] = i_p[mask]\n        mask = np.all(np.isinf(diff_p), axis=1)\n        i_p[mask] = i_m[mask]\n        full_shape = (slice(None),) + (np.newaxis,) * (arr.ndim - 1)\n        if coords.ndim == 1:\n            i_p_full = i_p[full_shape] * np.ones(arr.shape)\n            i_m_full = i_m[full_shape] * np.ones(arr.shape)\n        else:\n            i_p_full = i_p\n            i_m_full = i_m\n        ii = np.indices(i_p_full.shape)\n        i_p_slice = (i_p_full,) + tuple(ii[1:])\n        i_m_slice = (i_m_full,) + tuple(ii[1:])\n        dx = (coords[i_p_slice] - coords[i_m_slice])\n        pos = np.where(dx == 0., 0., (coords[i_p_slice] - interp_coords) / (dx + 1e-12))\n        return np.moveaxis(arr[i_p_slice] * (1. - pos) + arr[i_m_slice] * pos, 0, axis)\n\n    @veros_method\n    def output(self, vs):\n        if not os.path.isfile(self.get_output_file_name(vs)):\n            self.initialize_output(vs, self.variables,\n                                   var_data={\'sigma\': self.sigma},\n                                   extra_dimensions={\'sigma\': self.nlevel})\n\n        if self.nitts > 0:\n            for var in self.mean_variables.keys():\n                getattr(self, var)[...] *= 1. / self.nitts\n\n        var_metadata = {key: var for key, var in self.mean_variables.items()\n                        if var.output and var.time_dependent}\n        var_data = {key: getattr(self, key) for key, var in self.mean_variables.items()\n                    if var.output and var.time_dependent}\n        self.write_output(vs, var_metadata, var_data)\n\n        self.nitts = 0\n        for var in self.mean_variables.keys():\n            getattr(self, var)[...] = 0.\n\n    @veros_method\n    def read_restart(self, vs, infile):\n        attributes, variables = self.read_h5_restart(vs, self.variables, infile)\n        if attributes:\n            self.nitts = attributes[\'nitts\']\n        if variables:\n            for var, arr in variables.items():\n                getattr(self, var)[...] = arr\n\n    @veros_method\n    def write_restart(self, vs, outfile):\n        var_data = {key: getattr(self, key)\n                    for key, var in self.variables.items() if var.write_to_restart}\n        self.write_h5_restart(vs, {\'nitts\': self.nitts}, self.variables, var_data, outfile)\n'"
veros/diagnostics/snapshot.py,0,"b'import os\n\nfrom loguru import logger\n\nfrom .. import veros_method, time\nfrom .diagnostic import VerosDiagnostic\n\n\nclass Snapshot(VerosDiagnostic):\n    """"""Writes snapshots of the current solution. Also reads and writes the main restart\n    data required for restarting a Veros simulation.\n    """"""\n    output_path = \'{identifier}.snapshot.nc\'\n    """"""File to write to. May contain format strings that are replaced with Veros attributes.""""""\n    name = \'snapshot\' #:\n    output_frequency = None  #: Frequency (in seconds) in which output is written.\n    #: Attributes to be written to restart file.\n    restart_attributes = (\'itt\', \'time\', \'tau\', \'taum1\', \'taup1\')\n\n    def __init__(self, vs):\n        self.output_variables = [key for key, val in vs.variables.items() if val.output]\n        """"""Variables to be written to output. Defaults to all Veros variables that\n        have the attribute :attr:`output`.""""""\n        self.restart_variables = [key for key,\n                                  val in vs.variables.items() if val.write_to_restart]\n        """"""Variables to be written to restart. Defaults to all Veros variables that\n        have the attribute :attr:`write_to_restart`.""""""\n\n    @veros_method\n    def initialize(self, vs):\n        var_meta = {var: vs.variables[var] for var in self.output_variables}\n        var_data = {var: getattr(vs, var) for var in self.output_variables}\n        self.initialize_output(vs, var_meta, var_data)\n\n    def diagnose(self, vs):\n        pass\n\n    @veros_method\n    def output(self, vs):\n        logger.info(\' Writing snapshot at {0[0]:.2f} {0[1]}\', time.format_time(vs.time))\n\n        if not os.path.isfile(self.get_output_file_name(vs)):\n            self.initialize(vs)\n\n        var_meta = {var: vs.variables[var]\n                    for var in self.output_variables if vs.variables[var].time_dependent}\n        var_data = {var: getattr(vs, var) for var in var_meta.keys()}\n        self.write_output(vs, var_meta, var_data)\n\n    def read_restart(self, vs, infile):\n        restart_vars = {var: vs.variables[var] for var in self.restart_variables}\n        restart_data = {var: getattr(vs, var) for var in self.restart_variables}\n        attributes, variables = self.read_h5_restart(vs, restart_vars, infile)\n        for key, arr in restart_data.items():\n            try:\n                restart_var = variables[key]\n            except KeyError:\n                logger.warning(\'Not reading restart data for variable {}: \'\n                               \'no matching data found in restart file\'\n                               .format(key))\n                continue\n            if not arr.shape == restart_var.shape:\n                logger.warning(\'Not reading restart data for variable {}: \'\n                               \'restart data dimensions do not match model \'\n                               \'grid\'.format(key))\n                continue\n            arr[...] = restart_var\n        for attr in self.restart_attributes:\n            try:\n                setattr(vs, attr, attributes[attr])\n            except KeyError:\n                logger.warning(\'Not reading restart data for attribute {}: \'\n                               \'attribute not found in restart file\'\n                               .format(attr))\n\n    def write_restart(self, vs, outfile):\n        restart_attributes = {key: getattr(vs, key) for key in self.restart_attributes}\n        restart_vars = {var: vs.variables[var] for var in self.restart_variables}\n        restart_data = {var: getattr(vs, var) for var in self.restart_variables}\n        self.write_h5_restart(vs, restart_attributes, restart_vars, restart_data, outfile)\n'"
veros/diagnostics/tracer_monitor.py,6,"b'from loguru import logger\n\nfrom .diagnostic import VerosDiagnostic\nfrom .. import veros_method\nfrom ..distributed import global_sum\n\n\nclass TracerMonitor(VerosDiagnostic):\n    """"""Diagnostic monitoring global tracer contents / fluxes.\n\n    Writes output to stdout (no binary output).\n    """"""\n    name = \'tracer_monitor\' #:\n    output_frequency = None  #: Frequency (in seconds) in which output is written.\n    #: internal attributes to write to restart file\n    restart_attributes = (\'tempm1\', \'vtemp1\', \'saltm1\', \'vsalt1\')\n\n    def initialize(self, vs):\n        self.tempm1 = 0.\n        self.vtemp1 = 0.\n        self.saltm1 = 0.\n        self.vsalt1 = 0.\n\n    def diagnose(self, vs):\n        pass\n\n    @veros_method\n    def output(self, vs):\n        """"""\n        Diagnose tracer content\n        """"""\n        cell_volume = vs.area_t[2:-2, 2:-2, np.newaxis] * vs.dzt[np.newaxis, np.newaxis, :] \\\n            * vs.maskT[2:-2, 2:-2, :]\n        volm = global_sum(vs, np.sum(cell_volume))\n        tempm = global_sum(vs, np.sum(cell_volume * vs.temp[2:-2, 2:-2, :, vs.tau]))\n        saltm = global_sum(vs, np.sum(cell_volume * vs.salt[2:-2, 2:-2, :, vs.tau]))\n        vtemp = global_sum(vs, np.sum(cell_volume * vs.temp[2:-2, 2:-2, :, vs.tau]**2))\n        vsalt = global_sum(vs, np.sum(cell_volume * vs.salt[2:-2, 2:-2, :, vs.tau]**2))\n\n        logger.diagnostic(\' Mean temperature {} change to last {}\'\n                          .format(float(tempm / volm), float((tempm - self.tempm1) / volm)))\n        logger.diagnostic(\' Mean salinity    {} change to last {}\'\n                          .format(float(saltm / volm), float((saltm - self.saltm1) / volm)))\n        logger.diagnostic(\' Temperature var. {} change to last {}\'\n                          .format(float(vtemp / volm), float((vtemp - self.vtemp1) / volm)))\n        logger.diagnostic(\' Salinity var.    {} change to last {}\'\n                          .format(float(vsalt / volm), float((vsalt - self.vsalt1) / volm)))\n\n        self.tempm1 = tempm\n        self.vtemp1 = vtemp\n        self.saltm1 = saltm\n        self.vsalt1 = vsalt\n\n    def read_restart(self, vs, infile):\n        attributes, variables = self.read_h5_restart(vs, {}, infile)\n        for attr in self.restart_attributes:\n            setattr(self, attr, attributes[attr])\n\n    def write_restart(self, vs, outfile):\n        attributes = {key: getattr(self, key) for key in self.restart_attributes}\n        self.write_h5_restart(vs, attributes, {}, {}, outfile)\n'"
veros/setup/__init__.py,0,b''
veros/tools/__init__.py,0,"b'from veros.tools.assets import get_assets\nfrom veros.tools.setup import (interpolate, fill_holes, get_periodic_interval, make_cyclic,\n                               get_coastline_distance, get_uniform_grid_steps, get_stretched_grid_steps,\n                               get_vinokur_grid_steps)\nfrom veros.tools.cli import cli\n'"
veros/tools/assets.py,0,"b'import os\nimport shutil\n\nimport hashlib\n\nimport requests\nimport ruamel.yaml as yaml\nfrom loguru import logger\n\nfrom .filelock import FileLock\n\ntry:\n    import urlparse\nexcept ImportError:\n    import urllib.parse as urlparse\n\n\nASSET_DIRECTORY = os.environ.get(\'VEROS_ASSET_DIR\') or os.path.join(os.path.expanduser(\'~\'), \'.veros\', \'assets\')\n\n\nclass AssetError(Exception):\n    pass\n\n\nclass AssetStore:\n    def __init__(self, asset_dir, asset_config):\n        self._asset_dir = asset_dir\n        self._asset_config = asset_config\n        self._stored_assets = {}\n\n    def _get_asset(self, key):\n        url = self._asset_config[key][\'url\']\n        md5 = self._asset_config[key].get(\'md5\')\n\n        target_filename = os.path.basename(urlparse.urlparse(url).path)\n        target_path = os.path.join(self._asset_dir, target_filename)\n        target_lock = target_path + \'.lock\'\n\n        with FileLock(target_lock):\n            if not os.path.isfile(target_path) or (md5 is not None and _filehash(target_path) != md5):\n                logger.info(\'Downloading asset {} ...\', target_filename)\n                _download_file(url, target_path)\n\n            if md5 is not None and _filehash(target_path) != md5:\n                raise AssetError(\'Mismatching MD5 checksum on asset %s\' % target_filename)\n\n        return target_path\n\n    def keys(self):\n        return self._asset_config.keys()\n\n    def __contains__(self, key):\n        return key in self.keys()\n\n    def __getitem__(self, key):\n        if key not in self:\n            raise KeyError(\'unknown asset {}\'.format(key))\n\n        if key not in self._stored_assets:\n            self._stored_assets[key] = self._get_asset(key)\n\n        return self._stored_assets[key]\n\n    def __repr__(self):\n        out = \'{}(asset_dir={}, asset_config={})\'.format(\n            self.__class__.__name__, self._asset_dir, self._asset_config\n        )\n        return out\n\n\ndef get_assets(asset_id, asset_file):\n    """"""Handles automatic download and verification of external assets (such as forcing files).\n\n    By default, assets are stored in ``$HOME/.veros/assets`` (can be overwritten by setting\n    ``VEROS_ASSET_DIR`` environment variable to the desired location).\n\n    Arguments:\n\n       asset_id (str): Identifier of the collection of assets. Should be unique for each setup.\n       asset_file (str): YAML file containing URLs and (optionally) MD5 hashsums of each asset.\n\n    Returns:\n\n        A ``dict``-like mapping of each asset to file name on disk. Assets are downloaded lazily.\n\n    Example:\n\n       >>> assets = get_assets(\'mysetup\', \'assets.yml\')\n       >>> assets[\'forcing\']\n       ""/home/user/.veros/assets/mysetup/mysetup_forcing.h5"",\n           ""initial_conditions"": ""/home/user/.veros/assets/mysetup/initial.h5""\n       }\n\n    In this case, ``assets.yml`` contains::\n\n       forcing:\n           url: https://mywebsite.com/veros_assets/mysetup_forcing.h5\n           md5: ef3be0a58782771c8ee5a6d0206b87f6\n\n       initial_conditions:\n           url: https://mywebsite.com/veros_assets/initial.h5\n           md5: d1b4e0e199d7a5883cf7c88d3d6bcb28\n\n    """"""\n    with open(asset_file, \'r\') as f:\n        assets = yaml.safe_load(f)\n\n    asset_dir = os.path.join(ASSET_DIRECTORY, asset_id)\n\n    if not os.path.isdir(asset_dir):\n        try: # possible race-condition\n            os.makedirs(asset_dir)\n        except OSError:\n            if os.path.isdir(asset_dir):\n                pass\n\n    return AssetStore(asset_dir, assets)\n\n\ndef _download_file(url, target_path, timeout=10):\n    """"""Download a file and save it to a folder""""""\n    with requests.get(url, stream=True, timeout=timeout) as response:\n        response.raise_for_status()\n        response.raw.decode_content = True\n        with open(target_path, \'wb\') as dst:\n            shutil.copyfileobj(response.raw, dst)\n\n    return target_path\n\n\ndef _filehash(path):\n    hash_md5 = hashlib.md5()\n    with open(path, \'rb\') as f:\n        for chunk in iter(lambda: f.read(4096), b\'\'):\n            hash_md5.update(chunk)\n    return hash_md5.hexdigest()\n'"
veros/tools/cli.py,0,"b'import functools\nimport sys\nimport time\n\nimport click\n\nfrom veros.settings import SETTINGS\n\nBACKENDS = [\'numpy\', \'bohrium\']\nLOGLEVELS = [\'trace\', \'debug\', \'info\', \'warning\', \'error\', \'critical\']\n\n\nclass VerosSetting(click.ParamType):\n    name = \'setting\'\n    current_key = None\n\n    def convert(self, value, param, ctx):\n        assert param.nargs == 2\n\n        if self.current_key is None:\n            if value not in SETTINGS:\n                self.fail(\'Unknown setting %s\' % value)\n            self.current_key = value\n            return value\n\n        assert self.current_key in SETTINGS\n        setting = SETTINGS[self.current_key]\n        self.current_key = None\n\n        if setting.type is bool:\n            return click.BOOL(value)\n\n        return setting.type(value)\n\n\ndef cli(run):\n    """"""Decorator that wraps the decorated function with the Veros setup command line interface.\n\n    Example:\n\n        >>> @veros.tools.cli.cli()\n        >>> def run_setup(override):\n        ...     sim = MyVerosSetup(override=override)\n        ...     sim.run()\n        ...\n        >>> if __name__ == \'__main__\':\n        ...     run_setup()\n\n    This script then automatically supports settings to be specified from the command line::\n\n        $ python my_setup.py --help\n        Usage: my_setup.py [OPTIONS]\n\n        Options:\n        -b, --backend [numpy|bohrium]   Backend to use for computations (default:\n                                        numpy)\n        -v, --loglevel [trace|debug|info|warning|error|critical]\n                                        Log level used for output (default: info)\n        -s, --override SETTING VALUE    Override default setting, may be specified\n                                        multiple times\n        -p, --profile-mode              Write a performance profile for debugging\n                                        (default: false)\n        -n, --num-proc INTEGER...       Number of processes in x and y dimension\n                                        (requires execution via mpirun)\n        --help                          Show this message and exit.\n\n    """"""\n    @click.command(\'veros-run\')\n    @click.option(\'-b\', \'--backend\', default=\'numpy\', type=click.Choice(BACKENDS),\n                  help=\'Backend to use for computations (default: numpy)\', envvar=\'VEROS_BACKEND\')\n    @click.option(\'-v\', \'--loglevel\', default=\'info\', type=click.Choice(LOGLEVELS),\n                  help=\'Log level used for output (default: info)\', envvar=\'VEROS_LOGLEVEL\')\n    @click.option(\'-s\', \'--override\', nargs=2, multiple=True, metavar=\'SETTING VALUE\',\n                  type=VerosSetting(), default=tuple(),\n                  help=\'Override default setting, may be specified multiple times\')\n    @click.option(\'-p\', \'--profile-mode\', is_flag=True, default=False, type=click.BOOL, envvar=\'VEROS_PROFILE\',\n                  help=\'Write a performance profile for debugging (default: false)\')\n    @click.option(\'-n\', \'--num-proc\', nargs=2, default=[1, 1], type=click.INT,\n                  help=\'Number of processes in x and y dimension\')\n    @click.option(\'--slave\', default=False, is_flag=True, hidden=True,\n                  help=\'Indicates that this process is an MPI worker (for internal use)\')\n    @functools.wraps(run)\n    def wrapped(*args, slave, **kwargs):\n        from veros import runtime_settings, runtime_state\n\n        total_proc = kwargs[\'num_proc\'][0] * kwargs[\'num_proc\'][1]\n\n        if total_proc > 1 and runtime_state.proc_num == 1 and not slave:\n            from mpi4py import MPI\n\n            comm = MPI.COMM_SELF.Spawn(\n                sys.executable,\n                args=[\'-m\', \'mpi4py\'] + list(sys.argv) + [\'--slave\'],\n                maxprocs=total_proc\n            )\n\n            futures = [comm.irecv(source=p) for p in range(total_proc)]\n            while True:\n                done, success = zip(*(f.test() for f in futures))\n\n                if any(s is False for s in success):\n                    raise RuntimeError(\'An MPI worker encountered an error\')\n\n                if all(done):\n                    break\n\n                time.sleep(0.1)\n\n            return\n\n        kwargs[\'override\'] = dict(kwargs[\'override\'])\n\n        for setting in (\'backend\', \'profile_mode\', \'num_proc\', \'loglevel\'):\n            setattr(runtime_settings, setting, kwargs.pop(setting))\n\n        try:\n            run(*args, **kwargs)\n        except:  # noqa: E722\n            status = False\n            raise\n        else:\n            status = True\n        finally:\n            if slave:\n                runtime_settings.mpi_comm.Get_parent().send(status, dest=0)\n\n    return wrapped\n'"
veros/tools/filelock.py,0,"b'# This is free and unencumbered software released into the public domain.\n#\n# Anyone is free to copy, modify, publish, use, compile, sell, or\n# distribute this software, either in source code form or as a compiled\n# binary, for any purpose, commercial or non-commercial, and by any\n# means.\n#\n# In jurisdictions that recognize copyright laws, the author or authors\n# of this software dedicate any and all copyright interest in the\n# software to the public domain. We make this dedication for the benefit\n# of the public at large and to the detriment of our heirs and\n# successors. We intend this dedication to be an overt act of\n# relinquishment in perpetuity of all present and future rights to this\n# software under copyright law.\n#\n# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,\n# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n# IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR\n# OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\n# ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n# OTHER DEALINGS IN THE SOFTWARE.\n#\n# For more information, please refer to <http://unlicense.org>\n\n""""""\nA platform independent file lock that supports the with-statement.\n""""""\n\n\n# Modules\n# ------------------------------------------------\nimport logging\nimport os\nimport threading\nimport time\ntry:\n    import warnings\nexcept ImportError:\n    warnings = None\n\ntry:\n    import msvcrt\nexcept ImportError:\n    msvcrt = None\n\ntry:\n    import fcntl\nexcept ImportError:\n    fcntl = None\n\n\n# Backward compatibility\n# ------------------------------------------------\ntry:\n    TimeoutError\nexcept NameError:\n    TimeoutError = OSError\n\n\n# Data\n# ------------------------------------------------\n__all__ = [\n    ""Timeout"",\n    ""BaseFileLock"",\n    ""WindowsFileLock"",\n    ""UnixFileLock"",\n    ""SoftFileLock"",\n    ""FileLock""\n]\n\n__version__ = ""3.0.12""\n\n\n_logger = None\n\n\ndef logger():\n    """"""Returns the logger instance used in this module.""""""\n    global _logger\n    _logger = _logger or logging.getLogger(__name__)\n    return _logger\n\n\n# Exceptions\n# ------------------------------------------------\nclass Timeout(TimeoutError):\n    """"""\n    Raised when the lock could not be acquired in *timeout*\n    seconds.\n    """"""\n\n    def __init__(self, lock_file):\n        """"""\n        """"""\n        #: The path of the file lock.\n        self.lock_file = lock_file\n        return None\n\n    def __str__(self):\n        temp = ""The file lock \'{}\' could not be acquired.""\\\n               .format(self.lock_file)\n        return temp\n\n\n# Classes\n# ------------------------------------------------\n\n# This is a helper class which is returned by :meth:`BaseFileLock.acquire`\n# and wraps the lock to make sure __enter__ is not called twice when entering\n# the with statement.\n# If we would simply return *self*, the lock would be acquired again\n# in the *__enter__* method of the BaseFileLock, but not released again\n# automatically.\n#\n# :seealso: issue #37 (memory leak)\nclass _Acquire_ReturnProxy(object):\n\n    def __init__(self, lock):\n        self.lock = lock\n        return None\n\n    def __enter__(self):\n        return self.lock\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.lock.release()\n        return None\n\n\nclass BaseFileLock(object):\n    """"""\n    Implements the base class of a file lock.\n    """"""\n\n    def __init__(self, lock_file, timeout=-1):\n        """"""\n        """"""\n        # The path to the lock file.\n        self._lock_file = lock_file\n\n        # The file descriptor for the *_lock_file* as it is returned by the\n        # os.open() function.\n        # This file lock is only NOT None, if the object currently holds the\n        # lock.\n        self._lock_file_fd = None\n\n        # The default timeout value.\n        self.timeout = timeout\n\n        # We use this lock primarily for the lock counter.\n        self._thread_lock = threading.Lock()\n\n        # The lock counter is used for implementing the nested locking\n        # mechanism. Whenever the lock is acquired, the counter is increased and\n        # the lock is only released, when this value is 0 again.\n        self._lock_counter = 0\n        return None\n\n    @property\n    def lock_file(self):\n        """"""\n        The path to the lock file.\n        """"""\n        return self._lock_file\n\n    @property\n    def timeout(self):\n        """"""\n        You can set a default timeout for the filelock. It will be used as\n        fallback value in the acquire method, if no timeout value (*None*) is\n        given.\n\n        If you want to disable the timeout, set it to a negative value.\n\n        A timeout of 0 means, that there is exactly one attempt to acquire the\n        file lock.\n\n        .. versionadded:: 2.0.0\n        """"""\n        return self._timeout\n\n    @timeout.setter\n    def timeout(self, value):\n        """"""\n        """"""\n        self._timeout = float(value)\n        return None\n\n    # Platform dependent locking\n    # --------------------------------------------\n\n    def _acquire(self):\n        """"""\n        Platform dependent. If the file lock could be\n        acquired, self._lock_file_fd holds the file descriptor\n        of the lock file.\n        """"""\n        raise NotImplementedError()\n\n    def _release(self):\n        """"""\n        Releases the lock and sets self._lock_file_fd to None.\n        """"""\n        raise NotImplementedError()\n\n    # Platform independent methods\n    # --------------------------------------------\n\n    @property\n    def is_locked(self):\n        """"""\n        True, if the object holds the file lock.\n\n        .. versionchanged:: 2.0.0\n\n            This was previously a method and is now a property.\n        """"""\n        return self._lock_file_fd is not None\n\n    def acquire(self, timeout=None, poll_intervall=0.05):\n        """"""\n        Acquires the file lock or fails with a :exc:`Timeout` error.\n\n        .. code-block:: python\n\n            # You can use this method in the context manager (recommended)\n            with lock.acquire():\n                pass\n\n            # Or use an equivalent try-finally construct:\n            lock.acquire()\n            try:\n                pass\n            finally:\n                lock.release()\n\n        :arg float timeout:\n            The maximum time waited for the file lock.\n            If ``timeout < 0``, there is no timeout and this method will\n            block until the lock could be acquired.\n            If ``timeout`` is None, the default :attr:`~timeout` is used.\n\n        :arg float poll_intervall:\n            We check once in *poll_intervall* seconds if we can acquire the\n            file lock.\n\n        :raises Timeout:\n            if the lock could not be acquired in *timeout* seconds.\n\n        .. versionchanged:: 2.0.0\n\n            This method returns now a *proxy* object instead of *self*,\n            so that it can be used in a with statement without side effects.\n        """"""\n        # Use the default timeout, if no timeout is provided.\n        if timeout is None:\n            timeout = self.timeout\n\n        # Increment the number right at the beginning.\n        # We can still undo it, if something fails.\n        with self._thread_lock:\n            self._lock_counter += 1\n\n        lock_id = id(self)\n        lock_filename = self._lock_file\n        start_time = time.time()\n        try:\n            while True:\n                with self._thread_lock:\n                    if not self.is_locked:\n                        logger().debug(\'Attempting to acquire lock %s on %s\', lock_id, lock_filename)\n                        self._acquire()\n\n                if self.is_locked:\n                    logger().info(\'Lock %s acquired on %s\', lock_id, lock_filename)\n                    break\n                elif timeout >= 0 and time.time() - start_time > timeout:\n                    logger().debug(\'Timeout on acquiring lock %s on %s\', lock_id, lock_filename)\n                    raise Timeout(self._lock_file)\n                else:\n                    logger().debug(\n                        \'Lock %s not acquired on %s, waiting %s seconds ...\',\n                        lock_id, lock_filename, poll_intervall\n                    )\n                    time.sleep(poll_intervall)\n        except:\n            # Something did go wrong, so decrement the counter.\n            with self._thread_lock:\n                self._lock_counter = max(0, self._lock_counter - 1)\n\n            raise\n        return _Acquire_ReturnProxy(lock=self)\n\n    def release(self, force=False):\n        """"""\n        Releases the file lock.\n\n        Please note, that the lock is only completly released, if the lock\n        counter is 0.\n\n        Also note, that the lock file itself is not automatically deleted.\n\n        :arg bool force:\n            If true, the lock counter is ignored and the lock is released in\n            every case.\n        """"""\n        with self._thread_lock:\n\n            if self.is_locked:\n                self._lock_counter -= 1\n\n                if self._lock_counter == 0 or force:\n                    lock_id = id(self)\n                    lock_filename = self._lock_file\n\n                    logger().debug(\'Attempting to release lock %s on %s\', lock_id, lock_filename)\n                    self._release()\n                    self._lock_counter = 0\n                    logger().info(\'Lock %s released on %s\', lock_id, lock_filename)\n\n        return None\n\n    def __enter__(self):\n        self.acquire()\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.release()\n        return None\n\n    def __del__(self):\n        self.release(force=True)\n        return None\n\n\n# Windows locking mechanism\n# ~~~~~~~~~~~~~~~~~~~~~~~~~\n\nclass WindowsFileLock(BaseFileLock):\n    """"""\n    Uses the :func:`msvcrt.locking` function to hard lock the lock file on\n    windows systems.\n    """"""\n\n    def _acquire(self):\n        open_mode = os.O_RDWR | os.O_CREAT | os.O_TRUNC\n\n        try:\n            fd = os.open(self._lock_file, open_mode)\n        except OSError:\n            pass\n        else:\n            try:\n                msvcrt.locking(fd, msvcrt.LK_NBLCK, 1)\n            except (IOError, OSError):\n                os.close(fd)\n            else:\n                self._lock_file_fd = fd\n        return None\n\n    def _release(self):\n        fd = self._lock_file_fd\n        self._lock_file_fd = None\n        msvcrt.locking(fd, msvcrt.LK_UNLCK, 1)\n        os.close(fd)\n\n        try:\n            os.remove(self._lock_file)\n        # Probably another instance of the application\n        # that acquired the file lock.\n        except OSError:\n            pass\n        return None\n\n# Unix locking mechanism\n# ~~~~~~~~~~~~~~~~~~~~~~\n\n\nclass UnixFileLock(BaseFileLock):\n    """"""\n    Uses the :func:`fcntl.flock` to hard lock the lock file on unix systems.\n    """"""\n\n    def _acquire(self):\n        open_mode = os.O_RDWR | os.O_CREAT | os.O_TRUNC\n        fd = os.open(self._lock_file, open_mode)\n\n        try:\n            fcntl.flock(fd, fcntl.LOCK_EX | fcntl.LOCK_NB)\n        except (IOError, OSError):\n            os.close(fd)\n        else:\n            self._lock_file_fd = fd\n        return None\n\n    def _release(self):\n        # Do not remove the lockfile:\n        #\n        #   https://github.com/benediktschmitt/py-filelock/issues/31\n        #   https://stackoverflow.com/questions/17708885/flock-removing-locked-file-without-race-condition\n        fd = self._lock_file_fd\n        self._lock_file_fd = None\n        fcntl.flock(fd, fcntl.LOCK_UN)\n        os.close(fd)\n        return None\n\n# Soft lock\n# ~~~~~~~~~\n\n\nclass SoftFileLock(BaseFileLock):\n    """"""\n    Simply watches the existence of the lock file.\n    """"""\n\n    def _acquire(self):\n        open_mode = os.O_WRONLY | os.O_CREAT | os.O_EXCL | os.O_TRUNC\n        try:\n            fd = os.open(self._lock_file, open_mode)\n        except (IOError, OSError):\n            pass\n        else:\n            self._lock_file_fd = fd\n        return None\n\n    def _release(self):\n        os.close(self._lock_file_fd)\n        self._lock_file_fd = None\n\n        try:\n            os.remove(self._lock_file)\n        # The file is already deleted and that\'s what we want.\n        except OSError:\n            pass\n        return None\n\n\n# Platform filelock\n# ~~~~~~~~~~~~~~~~~\n\n#: Alias for the lock, which should be used for the current platform. On\n#: Windows, this is an alias for :class:`WindowsFileLock`, on Unix for\n#: :class:`UnixFileLock` and otherwise for :class:`SoftFileLock`.\nFileLock = None\n\nif msvcrt:\n    FileLock = WindowsFileLock\nelif fcntl:\n    FileLock = UnixFileLock\nelse:\n    FileLock = SoftFileLock\n\n    if warnings is not None:\n        warnings.warn(""only soft file lock is available"")\n'"
veros/tools/setup.py,41,"b'import numpy as np\nimport scipy.interpolate\nimport scipy.spatial\n\n\ndef interpolate(coords, var, interp_coords, missing_value=None, fill=True, kind=\'linear\'):\n    """"""Interpolate globally defined data to a different (regular) grid.\n\n    Arguments:\n       coords: Tuple of coordinate arrays for each dimension.\n       var (:obj:`ndarray` of dim (nx1, ..., nxd)): Variable data to interpolate.\n       interp_coords: Tuple of coordinate arrays to interpolate to.\n       missing_value (optional): Value denoting cells of missing data in ``var``.\n          Is replaced by `NaN` before interpolating. Defaults to `None`, which means\n          no replacement is taking place.\n       fill (bool, optional): Whether `NaN` values should be replaced by the nearest\n          finite value after interpolating. Defaults to ``True``.\n       kind (str, optional): Order of interpolation. Supported are `nearest` and\n          `linear` (default).\n\n    Returns:\n       :obj:`ndarray` containing the interpolated values on the grid spanned by\n       ``interp_coords``.\n\n    """"""\n    if len(coords) != len(interp_coords) or len(coords) != var.ndim:\n        raise ValueError(\'Dimensions of coordinates and values do not match\')\n    var = np.array(var)\n    if missing_value is not None:\n        invalid_mask = np.isclose(var, missing_value)\n        var[invalid_mask] = np.nan\n    if var.ndim > 1 and coords[0].ndim == 1:\n        interp_grid = np.rollaxis(np.array(np.meshgrid(\n            *interp_coords, indexing=\'ij\', copy=False)), 0, len(interp_coords) + 1)\n    else:\n        interp_grid = coords\n    var = scipy.interpolate.interpn(coords, var, interp_grid,\n                                    bounds_error=False, fill_value=np.nan, method=kind)\n\n    if fill:\n        var = fill_holes(var)\n    return var\n\n\ndef fill_holes(data):\n    """"""A simple inpainting function that replaces NaN values in `data` with the\n    nearest finite value.\n    """"""\n    data = data.copy()\n    shape = data.shape\n    dim = data.ndim\n    flag = np.zeros(shape, dtype=bool)\n    flag[~np.isnan(data)] = True\n\n    slcs = [slice(None)] * dim\n\n    while np.any(~flag):\n        for i in range(dim):\n            slcs1 = slcs[:]\n            slcs2 = slcs[:]\n            slcs1[i] = slice(0, -1)\n            slcs2[i] = slice(1, None)\n\n            slcs1 = tuple(slcs1)\n            slcs2 = tuple(slcs2)\n\n            # replace from the right\n            repmask = np.logical_and(~flag[slcs1], flag[slcs2])\n            data[slcs1][repmask] = data[slcs2][repmask]\n            flag[slcs1][repmask] = True\n\n            # replace from the left\n            repmask = np.logical_and(~flag[slcs2], flag[slcs1])\n            data[slcs2][repmask] = data[slcs1][repmask]\n            flag[slcs2][repmask] = True\n\n    return data\n\n\ndef get_periodic_interval(current_time, cycle_length, rec_spacing, n_rec):\n    """"""Used for linear interpolation between periodic time intervals.\n\n    One common application is the interpolation of external forcings that are defined\n    at discrete times (e.g. one value per month of a standard year) to the current\n    time step.\n\n    Arguments:\n       current_time (float): Time to interpolate to.\n       cycle_length (float): Total length of one periodic cycle.\n       rec_spacing (float): Time spacing between each data record.\n       n_rec (int): Total number of records available.\n\n    Returns:\n       :obj:`tuple` containing (n1, f1), (n2, f2): Indices and weights for the interpolated\n       record array.\n\n    Example:\n       The following interpolates a record array ``data`` containing 12 monthly values\n       to the current time step:\n\n       >>> year_in_seconds = 60. * 60. * 24. * 365.\n       >>> current_time = 60. * 60. * 24. * 45. # mid-february\n       >>> print(data.shape)\n       (360, 180, 12)\n       >>> (n1, f1), (n2, f2) = get_periodic_interval(current_time, year_in_seconds, year_in_seconds / 12, 12)\n       >>> data_at_current_time = f1 * data[..., n1] + f2 * data[..., n2]\n\n    """"""\n    locTime = current_time - rec_spacing * 0.5 + \\\n        cycle_length * (2 - round(current_time / cycle_length))\n    tmpTime = locTime % cycle_length\n    tRec1 = 1 + int(tmpTime / rec_spacing)\n    tRec2 = 1 + tRec1 % int(n_rec)\n    wght2 = (tmpTime - rec_spacing * (tRec1 - 1)) / rec_spacing\n    wght1 = 1.0 - wght2\n    return (tRec1 - 1, wght1), (tRec2 - 1, wght2)\n\n\ndef make_cyclic(longitude, array=None, wrap=360.):\n    """"""Create a cyclic version of a longitude array and (optionally) another array.\n\n    Arguments:\n        longitude (ndarray): Longitude array of shape (nlon, ...).\n        array (ndarray): Another array that is to be made cyclic of shape (nlon, ...).\n        wrap (float): Wrapping value, defaults to 360 (degrees).\n\n    Returns:\n        Tuple containing (cyclic_longitudes, cyclic_array) if `array` is given, otherwise\n        just the ndarray cyclic_longitudes of shape (2 * nlon, ...).\n\n    """"""\n    lonsize = longitude.shape[0]\n    cyclic_longitudes = np.hstack((longitude[lonsize//2:, ...] - wrap, longitude, longitude[:lonsize//2, ...] + wrap))\n    if array is None:\n        return cyclic_longitudes\n    cyclic_array = np.hstack((array[lonsize//2:, ...], array, array[:lonsize//2, ...]))\n    return cyclic_longitudes, cyclic_array\n\n\ndef get_coastline_distance(coords, coast_mask, spherical=False, radius=None, num_candidates=None, n_jobs=-1):\n    """"""Calculate the (approximate) distance of each water cell from the nearest coastline.\n\n    Arguments:\n        coords (tuple of ndarrays): Tuple containing x and y (longitude and latitude)\n            coordinate arrays of shape (nx, ny).\n        coast_mask (ndarray): Boolean mask indicating whether a cell is a land cell\n            (must be same shape as coordinate arrays).\n        spherical (bool): Use spherical instead of Cartesian coordinates.\n            When this is `True`, cyclical boundary conditions are used, and the\n            resulting distances are only approximate. Cells are pre-sorted by\n            Euclidean lon-lat distance, and great circle distances are calculated for\n            the first `num_candidates` elements. Defaults to `False`.\n        radius (float): Radius of spherical coordinate system. Must be given when\n            `spherical` is `True`.\n        num_candidates (int): Number of candidates to calculate great circle distances\n            for for each water cell. The higher this value, the more accurate the returned\n            distances become when `spherical` is `True`. Defaults to the square root\n            of the number of coastal cells.\n        n_jobs (int): Number of parallel jobs to determine nearest neighbors\n            (defaults to -1, which uses all available threads).\n\n    Returns:\n        :obj:`ndarray` of shape (nx, ny) indicating the distance to the nearest land\n        cell (0 if cell is land).\n\n    Example:\n        The following returns coastal distances of all T cells for a spherical Veros setup.\n\n        >>> coords = np.meshgrid(self.xt[2:-2], self.yt[2:-2], indexing=\'ij\')\n        >>> dist = tools.get_coastline_distance(coords, self.kbot > 0, spherical=True, radius=self.radius)\n\n    """"""\n    if not len(coords) == 2:\n        raise ValueError(\'coords must be lon-lat tuple\')\n    if not all(c.shape == coast_mask.shape for c in coords):\n        raise ValueError(\'coordinates must have same shape as coastal mask\')\n    if spherical and not radius:\n        raise ValueError(\'radius must be given for spherical coordinates\')\n\n    watercoords = np.array([c[~coast_mask] for c in coords]).T\n    if spherical:\n        coastcoords = np.array(make_cyclic(coords[0][coast_mask], coords[1][coast_mask])).T\n    else:\n        coastcoords = np.array((coords[0][coast_mask], coords[1][coast_mask])).T\n    coast_kdtree = scipy.spatial.cKDTree(coastcoords)\n\n    distance = np.zeros(coords[0].shape)\n    if spherical:\n\n        def spherical_distance(coords1, coords2):\n            """"""Calculate great circle distance from latitude and longitude""""""\n            coords1 *= np.pi / 180.\n            coords2 *= np.pi / 180.\n            lon1, lon2, lat1, lat2 = coords1[..., 0], coords2[..., 0], coords1[..., 1], coords2[..., 1]\n            return radius * np.arccos(np.sin(lat1) * np.sin(lat2) + np.cos(lat1) * np.cos(lat2) * np.cos(lon1 - lon2))\n\n        if not num_candidates:\n            num_candidates = int(np.sqrt(np.count_nonzero(~coast_mask)))\n        i_nearest = coast_kdtree.query(watercoords, k=num_candidates, n_jobs=n_jobs)[1]\n        approx_nearest = coastcoords[i_nearest]\n        distance[~coast_mask] = np.min(spherical_distance(approx_nearest, watercoords[..., np.newaxis, :]), axis=-1)\n    else:\n        distance[~coast_mask] = coast_kdtree.query(watercoords, n_jobs=n_jobs)[0]\n    return distance\n\n\ndef get_uniform_grid_steps(total_length, stepsize):\n    """"""Get uniform grid step sizes in an interval.\n\n    Arguments:\n        total_length (float): total length of the resulting grid\n        stepsize (float): grid step size\n\n    Returns:\n        :obj:`ndarray` of grid steps\n\n    Example:\n        >>> uniform_steps = uniform_grid_setup(6., 0.25)\n        >>> uniform_steps\n        [ 0.25,  0.25,  0.25,  0.25,  0.25,  0.25,  0.25,  0.25,  0.25,\n          0.25,  0.25,  0.25,  0.25,  0.25,  0.25,  0.25,  0.25,  0.25,\n          0.25,  0.25,  0.25,  0.25,  0.25,  0.25 ]\n\n    """"""\n    if total_length % stepsize:\n        raise ValueError(\'total length must be an integer multiple of stepsize\')\n    return stepsize * np.ones(int(total_length / stepsize))\n\n\ndef get_stretched_grid_steps(n_cells, total_length, minimum_stepsize, stretching_factor=2.5,\n                             two_sided_grid=False, refine_towards=\'upper\'):\n    """"""Computes stretched grid steps for regional and global domains with either\n    one or two-sided stretching using a hyperbolic tangent stretching function.\n\n    Arguments:\n        n_cells (int): Number of grid points.\n        total_length (float): Length of the grid interval to be covered (sum of the\n            resulting grid steps).\n        minimum_stepsize (float): Grid step size on the lower end of the interval.\n        stretching_factor (float, optional): Coefficient of the `tanh` stretching\n            function. The higher this value, the more abrupt the step sizes change.\n        two_sided_grid (bool, optional): If set to `True`, the resulting grid will be symmetrical\n            around the center. Defaults to `False`.\n        refine_towards (\'upper\' or \'lower\', optional): The side of the interval that is to be refined.\n            Defaults to \'upper\'.\n\n    Returns:\n        :obj:`ndarray` of shape `(n_cells)` containing grid steps.\n\n    Examples:\n        >>> dyt = get_stretched_grid_steps(14, 180, 5)\n        >>> dyt\n        [  5.10517337   5.22522948   5.47813251   5.99673813   7.00386752\n           8.76808565  11.36450896  14.34977676  16.94620006  18.71041819\n          19.71754758  20.2361532   20.48905624  20.60911234]\n        >>> dyt.sum()\n        180.0\n\n        >>> dyt = get_stretched_grid_steps(14, 180, 5, stretching_factor=4.)\n        >>> dyt\n        [  5.00526979   5.01802837   5.06155549   5.20877528   5.69251688\n           7.14225176  10.51307232  15.20121339  18.57203395  20.02176884\n          20.50551044  20.65273022  20.69625734  20.70901593]\n        >>> dyt.sum()\n        180.0\n\n    """"""\n\n    if refine_towards not in (\'upper\', \'lower\'):\n        raise ValueError(\'refine_towards must be ""upper"" or ""lower""\')\n    if two_sided_grid:\n        if n_cells % 2:\n            raise ValueError(\'number of grid points must be even integer number (given: {})\'.format(n_cells))\n        n_cells = n_cells / 2\n\n    stretching_function = np.tanh(stretching_factor * np.linspace(-1, 1, n_cells))\n\n    if refine_towards == \'lower\':\n        stretching_function = stretching_function[::-1]\n    if two_sided_grid:\n        stretching_function = np.concatenate((stretching_function[::-1], stretching_function))\n\n    def normalize_sum(var, sum_value, minimum_value=0.):\n        if abs(var.sum()) < 1e-5:\n            var += 1\n        var *= (sum_value - len(var) * minimum_value) / var.sum()\n        return var + minimum_value\n\n    stretching_function = normalize_sum(stretching_function, total_length, minimum_stepsize)\n    assert abs(1 - np.sum(stretching_function) / total_length) < 1e-5, \'precision error\'\n    return stretching_function\n\n\ndef get_vinokur_grid_steps(n_cells, total_length, lower_stepsize, upper_stepsize=None,\n                           two_sided_grid=False, refine_towards=\'upper\'):\n    """"""Computes stretched grid steps for regional and global domains with either\n    one or two-sided stretching using Vinokur stretching.\n\n    This stretching function minimizes discretization errors on finite difference\n    grids.\n\n    Arguments:\n        n_cells (int): Number of grid points.\n        total_length (float): Length of the grid interval to be covered (sum of the\n            resulting grid steps).\n        lower_stepsize (float): Grid step size on the lower end of the interval.\n        upper_stepsize (float or ``None``, optional): Grid step size on the upper end of the interval.\n            If not given, the one-sided version of the algorithm is used (that enforces zero curvature\n            on the upper end).\n        two_sided_grid (bool, optional): If set to `True`, the resulting grid will be symmetrical\n            around the center. Defaults to `False`.\n        refine_towards (\'upper\' or \'lower\', optional): The side of the interval that is to be refined.\n            Defaults to \'upper\'.\n\n    Returns:\n        :obj:`ndarray` of shape `(n_cells)` containing grid steps.\n\n    Reference:\n        Vinokur, Marcel, On One-Dimensional Stretching Functions for Finite-Difference Calculations,\n        Journal of Computational Physics. 50, 215, 1983.\n\n    Examples:\n        >>> dyt = get_vinokur_grid_steps(14, 180, 5, two_sided_grid=True)\n        >>> dyt\n        [ 18.2451554   17.23915939  15.43744632  13.17358802  10.78720589\n           8.53852027   6.57892471   6.57892471   8.53852027  10.78720589\n          13.17358802  15.43744632  17.23915939  18.2451554 ]\n        >>> dyt.sum()\n        180.\n\n        >>> dyt = get_vinokur_grid_steps(14, 180, 5, upper_stepsize=10)\n        >>> dyt\n        [  5.9818365    7.3645667    8.92544833  10.61326984  12.33841985\n          13.97292695  15.36197306  16.3485688   16.80714121  16.67536919\n          15.97141714  14.78881918  13.27136448  11.57887877 ]\n        >>> dyt.sum()\n        180.\n\n    """"""\n    if refine_towards not in (\'upper\', \'lower\'):\n        raise ValueError(\'refine_towards must be ""upper"" or ""lower""\')\n    if two_sided_grid:\n        if n_cells % 2:\n            raise ValueError(\'number of grid points must be an even integer (given: {})\'.format(n_cells))\n        n_cells = n_cells // 2\n\n    n_cells += 1\n\n    def approximate_sinc_inverse(y):\n        """"""Approximate inverse of sin(y) / y""""""\n        if y < 0.26938972:\n            inv = np.pi * (1 - y + y**2 - (1 + np.pi**2 / 6) * y**3 + 6.794732 * y**4 - 13.205501 * y**5 + 11.726095 * y**6)\n        else:\n            ybar = 1. - y\n            inv = np.sqrt(6 * ybar) * (1 + .15 * ybar + 0.057321429 * ybar**2 + 0.048774238 * ybar**3 - 0.053337753 * ybar**4 + 0.075845134 * ybar**5)\n        assert abs(1 - np.sin(inv) / inv / y) < 1e-2, \'precision error\'\n        return inv\n\n    def approximate_sinhc_inverse(y):\n        """"""Approximate inverse of sinh(y) / y""""""\n        if y < 2.7829681:\n            ybar = y - 1.\n            inv = np.sqrt(6 * ybar) * (1 - 0.15 * ybar + 0.057321429 * ybar**2 - 0.024907295 * ybar**3 + 0.0077424461 * ybar**4 - 0.0010794123 * ybar**5)\n        else:\n            v = np.log(y)\n            w = 1. / y - 0.028527431\n            inv = v + (1 + 1. / v) * np.log(2 * v) - 0.02041793 + 0.24902722 * w + 1.9496443 * w**2 - 2.6294547 * w**3 + 8.56795911 * w**4\n        assert abs(1 - np.sinh(inv) / inv / y) < 1e-2, \'precision error\'\n        return inv\n\n    target_sum = total_length\n    if two_sided_grid:\n        target_sum *= .5\n\n    s0 = float(target_sum) / float(lower_stepsize * n_cells)\n    if upper_stepsize:\n        s1 = float(target_sum) / float(upper_stepsize * n_cells)\n        a, b = np.sqrt(s1 / s0), np.sqrt(s1 * s0)\n        if b > 1:\n            stretching_factor = approximate_sinhc_inverse(b)\n            stretched_grid = .5 + .5 * np.tanh(stretching_factor * np.linspace(-.5, .5, n_cells)) / np.tanh(.5 * stretching_factor)\n        else:\n            stretching_factor = approximate_sinc_inverse(b)\n            stretched_grid = .5 + .5 * np.tan(stretching_factor * np.linspace(-.5, .5, n_cells)) / np.tan(.5 * stretching_factor)\n        stretched_grid = stretched_grid / (a + (1. - a) * stretched_grid)\n    else:\n        if s0 > 1:\n            stretching_factor = approximate_sinhc_inverse(s0) * .5\n            stretched_grid = 1 + np.tanh(stretching_factor * np.linspace(0., 1., n_cells)) / np.tanh(stretching_factor)\n        else:\n            stretching_factor = approximate_sinc_inverse(s0) * .5\n            stretched_grid = 1 + np.tan(stretching_factor * np.linspace(0., 1., n_cells)) / np.tan(stretching_factor)\n\n    stretched_grid_steps = np.diff(stretched_grid * target_sum)\n    if refine_towards == \'upper\':\n        stretched_grid_steps = stretched_grid_steps[::-1]\n    if two_sided_grid:\n        stretched_grid_steps = np.concatenate((stretched_grid_steps[::-1], stretched_grid_steps))\n\n    assert abs(1 - np.sum(stretched_grid_steps) / total_length) < 1e-5, \'precision error\'\n    return stretched_grid_steps\n'"
doc/_3rdparty/sphinx_fontawesome/__init__.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n""""""\n    Module sphinx_fontawesome\n""""""\n\nimport os\nfrom sphinx import addnodes\nfrom docutils.nodes import strong, emphasis, reference, Text\nfrom docutils.parsers.rst.roles import set_classes\nfrom docutils.parsers.rst import Directive\nimport docutils.parsers.rst.directives as directives\n\nimport sphinx_fontawesome.constant\n\n__version_info__ = (0, 0, 2)\n__version__ = \'.\'.join([str(val) for val in  __version_info__])\n\nsub_special = [\n                {\'id\' : \'o\', \'key\' : \'square-o\'},\n                {\'id\' : \'x\', \'key\' : \'check-square-o\'},\n                {\'id\' : \'smile\', \'key\' : \'smile-o\'},\n                {\'id\' : \'mail\', \'key\' : \'envelope\'},\n                {\'id\' : \'note\', \'key\' : \'info-circle\'},\n              ]\n# add role\ndef fa_global(key=\'\'):\n    def fa(role, rawtext, text, lineno, inliner, options={}, content=[]):\n        options.update({\'classes\': []})\n        options[\'classes\'].append(\'fa\')\n        if key:\n            options[\'classes\'].append(\'fa-%s\' % key)\n        else:\n             for x in text.split("",""):\n                options[\'classes\'].append(\'fa-%s\' % x)\n        set_classes(options)\n        node = emphasis(**options)\n        return [node], []\n    return fa\n\n#add directive\nclass Fa(Directive):\n\n    has_content = True\n\n    def run(self):\n        options= {\'classes\' : []}\n        options[\'classes\'].append(\'fa\')\n        for x in self.content[0].split(\' \'):\n            options[\'classes\'].append(\'fa-%s\' % x)\n        set_classes(options)\n        node = emphasis(**options)\n        return [node]\n \nprolog = \'\\n\'.join([\'.. |%s| fa:: %s\' % (icon, icon) for icon in sphinx_fontawesome.constant.icons])\nprolog += \'\\n\'\nprolog += \'\\n\'.join([\'.. |%s| fa:: %s\' % (icon[\'id\'], icon[\'key\']) for icon in sub_special])\n\n\n\ndef setup(app):\n    app.add_role(\'fa\', fa_global())\n    app.add_directive(\'fa\', Fa)\n    app.config.rst_prolog = prolog\n    return {\'version\': __version__}\n\n'"
doc/_3rdparty/sphinx_fontawesome/constant.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n""""""\n    list of icons Font-Awesome\n""""""\n\nicons = [\n\t\'glass\',\n\t\'music\',\n\t\'search\',\n\t\'envelope-o\',\n\t\'heart\',\n\t\'star\',\n\t\'star-o\',\n\t\'user\',\n\t\'film\',\n\t\'th-large\',\n\t\'th\',\n\t\'th-list\',\n\t\'check\',\n\t\'times\',\n\t\'search-plus\',\n\t\'search-minus\',\n\t\'power-off\',\n\t\'signal\',\n\t\'cog\',\n\t\'trash-o\',\n\t\'home\',\n\t\'file-o\',\n\t\'clock-o\',\n\t\'road\',\n\t\'download\',\n\t\'arrow-circle-o-down\',\n\t\'arrow-circle-o-up\',\n\t\'inbox\',\n\t\'play-circle-o\',\n\t\'repeat\',\n\t\'refresh\',\n\t\'list-alt\',\n\t\'lock\',\n\t\'flag\',\n\t\'headphones\',\n\t\'volume-off\',\n\t\'volume-down\',\n\t\'volume-up\',\n\t\'qrcode\',\n\t\'barcode\',\n\t\'tag\',\n\t\'tags\',\n\t\'book\',\n\t\'bookmark\',\n\t\'print\',\n\t\'camera\',\n\t\'font\',\n\t\'bold\',\n\t\'italic\',\n\t\'text-height\',\n\t\'text-width\',\n\t\'align-left\',\n\t\'align-center\',\n\t\'align-right\',\n\t\'align-justify\',\n\t\'list\',\n\t\'outdent\',\n\t\'indent\',\n\t\'video-camera\',\n\t\'picture-o\',\n\t\'pencil\',\n\t\'map-marker\',\n\t\'adjust\',\n\t\'tint\',\n\t\'pencil-square-o\',\n\t\'share-square-o\',\n\t\'check-square-o\',\n\t\'arrows\',\n\t\'step-backward\',\n\t\'fast-backward\',\n\t\'backward\',\n\t\'play\',\n\t\'pause\',\n\t\'stop\',\n\t\'forward\',\n\t\'fast-forward\',\n\t\'step-forward\',\n\t\'eject\',\n\t\'chevron-left\',\n\t\'chevron-right\',\n\t\'plus-circle\',\n\t\'minus-circle\',\n\t\'times-circle\',\n\t\'check-circle\',\n\t\'question-circle\',\n\t\'info-circle\',\n\t\'crosshairs\',\n\t\'times-circle-o\',\n\t\'check-circle-o\',\n\t\'ban\',\n\t\'arrow-left\',\n\t\'arrow-right\',\n\t\'arrow-up\',\n\t\'arrow-down\',\n\t\'share\',\n\t\'expand\',\n\t\'compress\',\n\t\'plus\',\n\t\'minus\',\n\t\'asterisk\',\n\t\'exclamation-circle\',\n\t\'gift\',\n\t\'leaf\',\n\t\'fire\',\n\t\'eye\',\n\t\'eye-slash\',\n\t\'exclamation-triangle\',\n\t\'plane\',\n\t\'calendar\',\n\t\'random\',\n\t\'comment\',\n\t\'magnet\',\n\t\'chevron-up\',\n\t\'chevron-down\',\n\t\'retweet\',\n\t\'shopping-cart\',\n\t\'folder\',\n\t\'folder-open\',\n\t\'arrows-v\',\n\t\'arrows-h\',\n\t\'bar-chart\',\n\t\'twitter-square\',\n\t\'facebook-square\',\n\t\'camera-retro\',\n\t\'key\',\n\t\'cogs\',\n\t\'comments\',\n\t\'thumbs-o-up\',\n\t\'thumbs-o-down\',\n\t\'star-half\',\n\t\'heart-o\',\n\t\'sign-out\',\n\t\'linkedin-square\',\n\t\'thumb-tack\',\n\t\'external-link\',\n\t\'sign-in\',\n\t\'trophy\',\n\t\'github-square\',\n\t\'upload\',\n\t\'lemon-o\',\n\t\'phone\',\n\t\'square-o\',\n\t\'bookmark-o\',\n\t\'phone-square\',\n\t\'twitter\',\n\t\'facebook\',\n\t\'github\',\n\t\'unlock\',\n\t\'credit-card\',\n\t\'rss\',\n\t\'hdd-o\',\n\t\'bullhorn\',\n\t\'bell\',\n\t\'certificate\',\n\t\'hand-o-right\',\n\t\'hand-o-left\',\n\t\'hand-o-up\',\n\t\'hand-o-down\',\n\t\'arrow-circle-left\',\n\t\'arrow-circle-right\',\n\t\'arrow-circle-up\',\n\t\'arrow-circle-down\',\n\t\'globe\',\n\t\'wrench\',\n\t\'tasks\',\n\t\'filter\',\n\t\'briefcase\',\n\t\'arrows-alt\',\n\t\'users\',\n\t\'link\',\n\t\'cloud\',\n\t\'flask\',\n\t\'scissors\',\n\t\'files-o\',\n\t\'paperclip\',\n\t\'floppy-o\',\n\t\'square\',\n\t\'bars\',\n\t\'list-ul\',\n\t\'list-ol\',\n\t\'strikethrough\',\n\t\'underline\',\n\t\'table\',\n\t\'magic\',\n\t\'truck\',\n\t\'pinterest\',\n\t\'pinterest-square\',\n\t\'google-plus-square\',\n\t\'google-plus\',\n\t\'money\',\n\t\'caret-down\',\n\t\'caret-up\',\n\t\'caret-left\',\n\t\'caret-right\',\n\t\'columns\',\n\t\'sort\',\n\t\'sort-desc\',\n\t\'sort-asc\',\n\t\'envelope\',\n\t\'linkedin\',\n\t\'undo\',\n\t\'gavel\',\n\t\'tachometer\',\n\t\'comment-o\',\n\t\'comments-o\',\n\t\'bolt\',\n\t\'sitemap\',\n\t\'umbrella\',\n\t\'clipboard\',\n\t\'lightbulb-o\',\n\t\'exchange\',\n\t\'cloud-download\',\n\t\'cloud-upload\',\n\t\'user-md\',\n\t\'stethoscope\',\n\t\'suitcase\',\n\t\'bell-o\',\n\t\'coffee\',\n\t\'cutlery\',\n\t\'file-text-o\',\n\t\'building-o\',\n\t\'hospital-o\',\n\t\'ambulance\',\n\t\'medkit\',\n\t\'fighter-jet\',\n\t\'beer\',\n\t\'h-square\',\n\t\'plus-square\',\n\t\'angle-double-left\',\n\t\'angle-double-right\',\n\t\'angle-double-up\',\n\t\'angle-double-down\',\n\t\'angle-left\',\n\t\'angle-right\',\n\t\'angle-up\',\n\t\'angle-down\',\n\t\'desktop\',\n\t\'laptop\',\n\t\'tablet\',\n\t\'mobile\',\n\t\'circle-o\',\n\t\'quote-left\',\n\t\'quote-right\',\n\t\'spinner\',\n\t\'circle\',\n\t\'reply\',\n\t\'github-alt\',\n\t\'folder-o\',\n\t\'folder-open-o\',\n\t\'smile-o\',\n\t\'frown-o\',\n\t\'meh-o\',\n\t\'gamepad\',\n\t\'keyboard-o\',\n\t\'flag-o\',\n\t\'flag-checkered\',\n\t\'terminal\',\n\t\'code\',\n\t\'reply-all\',\n\t\'star-half-o\',\n\t\'location-arrow\',\n\t\'crop\',\n\t\'code-fork\',\n\t\'chain-broken\',\n\t\'question\',\n\t\'info\',\n\t\'exclamation\',\n\t\'superscript\',\n\t\'subscript\',\n\t\'eraser\',\n\t\'puzzle-piece\',\n\t\'microphone\',\n\t\'microphone-slash\',\n\t\'shield\',\n\t\'calendar-o\',\n\t\'fire-extinguisher\',\n\t\'rocket\',\n\t\'maxcdn\',\n\t\'chevron-circle-left\',\n\t\'chevron-circle-right\',\n\t\'chevron-circle-up\',\n\t\'chevron-circle-down\',\n\t\'html5\',\n\t\'css3\',\n\t\'anchor\',\n\t\'unlock-alt\',\n\t\'bullseye\',\n\t\'ellipsis-h\',\n\t\'ellipsis-v\',\n\t\'rss-square\',\n\t\'play-circle\',\n\t\'ticket\',\n\t\'minus-square\',\n\t\'minus-square-o\',\n\t\'level-up\',\n\t\'level-down\',\n\t\'check-square\',\n\t\'pencil-square\',\n\t\'external-link-square\',\n\t\'share-square\',\n\t\'compass\',\n\t\'caret-square-o-down\',\n\t\'caret-square-o-up\',\n\t\'caret-square-o-right\',\n\t\'eur\',\n\t\'gbp\',\n\t\'usd\',\n\t\'inr\',\n\t\'jpy\',\n\t\'rub\',\n\t\'krw\',\n\t\'btc\',\n\t\'file\',\n\t\'file-text\',\n\t\'sort-alpha-asc\',\n\t\'sort-alpha-desc\',\n\t\'sort-amount-asc\',\n\t\'sort-amount-desc\',\n\t\'sort-numeric-asc\',\n\t\'sort-numeric-desc\',\n\t\'thumbs-up\',\n\t\'thumbs-down\',\n\t\'youtube-square\',\n\t\'youtube\',\n\t\'xing\',\n\t\'xing-square\',\n\t\'youtube-play\',\n\t\'dropbox\',\n\t\'stack-overflow\',\n\t\'instagram\',\n\t\'flickr\',\n\t\'adn\',\n\t\'bitbucket\',\n\t\'bitbucket-square\',\n\t\'tumblr\',\n\t\'tumblr-square\',\n\t\'long-arrow-down\',\n\t\'long-arrow-up\',\n\t\'long-arrow-left\',\n\t\'long-arrow-right\',\n\t\'apple\',\n\t\'windows\',\n\t\'android\',\n\t\'linux\',\n\t\'dribbble\',\n\t\'skype\',\n\t\'foursquare\',\n\t\'trello\',\n\t\'female\',\n\t\'male\',\n\t\'gratipay\',\n\t\'sun-o\',\n\t\'moon-o\',\n\t\'archive\',\n\t\'bug\',\n\t\'vk\',\n\t\'weibo\',\n\t\'renren\',\n\t\'pagelines\',\n\t\'stack-exchange\',\n\t\'arrow-circle-o-right\',\n\t\'arrow-circle-o-left\',\n\t\'caret-square-o-left\',\n\t\'dot-circle-o\',\n\t\'wheelchair\',\n\t\'vimeo-square\',\n\t\'try\',\n\t\'plus-square-o\',\n\t\'space-shuttle\',\n\t\'slack\',\n\t\'envelope-square\',\n\t\'wordpress\',\n\t\'openid\',\n\t\'university\',\n\t\'graduation-cap\',\n\t\'yahoo\',\n\t\'google\',\n\t\'reddit\',\n\t\'reddit-square\',\n\t\'stumbleupon-circle\',\n\t\'stumbleupon\',\n\t\'delicious\',\n\t\'digg\',\n\t\'pied-piper\',\n\t\'pied-piper-alt\',\n\t\'drupal\',\n\t\'joomla\',\n\t\'language\',\n\t\'fax\',\n\t\'building\',\n\t\'child\',\n\t\'paw\',\n\t\'spoon\',\n\t\'cube\',\n\t\'cubes\',\n\t\'behance\',\n\t\'behance-square\',\n\t\'steam\',\n\t\'steam-square\',\n\t\'recycle\',\n\t\'car\',\n\t\'taxi\',\n\t\'tree\',\n\t\'spotify\',\n\t\'deviantart\',\n\t\'soundcloud\',\n\t\'database\',\n\t\'file-pdf-o\',\n\t\'file-word-o\',\n\t\'file-excel-o\',\n\t\'file-powerpoint-o\',\n\t\'file-image-o\',\n\t\'file-archive-o\',\n\t\'file-audio-o\',\n\t\'file-video-o\',\n\t\'file-code-o\',\n\t\'vine\',\n\t\'codepen\',\n\t\'jsfiddle\',\n\t\'life-ring\',\n\t\'circle-o-notch\',\n\t\'rebel\',\n\t\'empire\',\n\t\'git-square\',\n\t\'git\',\n\t\'hacker-news\',\n\t\'tencent-weibo\',\n\t\'qq\',\n\t\'weixin\',\n\t\'paper-plane\',\n\t\'paper-plane-o\',\n\t\'history\',\n\t\'circle-thin\',\n\t\'header\',\n\t\'paragraph\',\n\t\'sliders\',\n\t\'share-alt\',\n\t\'share-alt-square\',\n\t\'bomb\',\n\t\'futbol-o\',\n\t\'tty\',\n\t\'binoculars\',\n\t\'plug\',\n\t\'slideshare\',\n\t\'twitch\',\n\t\'yelp\',\n\t\'newspaper-o\',\n\t\'wifi\',\n\t\'calculator\',\n\t\'paypal\',\n\t\'google-wallet\',\n\t\'cc-visa\',\n\t\'cc-mastercard\',\n\t\'cc-discover\',\n\t\'cc-amex\',\n\t\'cc-paypal\',\n\t\'cc-stripe\',\n\t\'bell-slash\',\n\t\'bell-slash-o\',\n\t\'trash\',\n\t\'copyright\',\n\t\'at\',\n\t\'eyedropper\',\n\t\'paint-brush\',\n\t\'birthday-cake\',\n\t\'area-chart\',\n\t\'pie-chart\',\n\t\'line-chart\',\n\t\'lastfm\',\n\t\'lastfm-square\',\n\t\'toggle-off\',\n\t\'toggle-on\',\n\t\'bicycle\',\n\t\'bus\',\n\t\'ioxhost\',\n\t\'angellist\',\n\t\'cc\',\n\t\'ils\',\n\t\'meanpath\',\n\t\'buysellads\',\n\t\'connectdevelop\',\n\t\'dashcube\',\n\t\'forumbee\',\n\t\'leanpub\',\n\t\'sellsy\',\n\t\'shirtsinbulk\',\n\t\'simplybuilt\',\n\t\'skyatlas\',\n\t\'cart-plus\',\n\t\'cart-arrow-down\',\n\t\'diamond\',\n\t\'ship\',\n\t\'user-secret\',\n\t\'motorcycle\',\n\t\'street-view\',\n\t\'heartbeat\',\n\t\'venus\',\n\t\'mars\',\n\t\'mercury\',\n\t\'transgender\',\n\t\'transgender-alt\',\n\t\'venus-double\',\n\t\'mars-double\',\n\t\'venus-mars\',\n\t\'mars-stroke\',\n\t\'mars-stroke-v\',\n\t\'mars-stroke-h\',\n\t\'neuter\',\n\t\'genderless\',\n\t\'facebook-official\',\n\t\'pinterest-p\',\n\t\'whatsapp\',\n\t\'server\',\n\t\'user-plus\',\n\t\'user-times\',\n\t\'bed\',\n\t\'viacoin\',\n\t\'train\',\n\t\'subway\',\n\t\'medium\',\n\t\'y-combinator\',\n\t\'optin-monster\',\n\t\'opencart\',\n\t\'expeditedssl\',\n\t\'battery-full\',\n\t\'battery-three-quarters\',\n\t\'battery-half\',\n\t\'battery-quarter\',\n\t\'battery-empty\',\n\t\'mouse-pointer\',\n\t\'i-cursor\',\n\t\'object-group\',\n\t\'object-ungroup\',\n\t\'sticky-note\',\n\t\'sticky-note-o\',\n\t\'cc-jcb\',\n\t\'cc-diners-club\',\n\t\'clone\',\n\t\'balance-scale\',\n\t\'hourglass-o\',\n\t\'hourglass-start\',\n\t\'hourglass-half\',\n\t\'hourglass-end\',\n\t\'hourglass\',\n\t\'hand-rock-o\',\n\t\'hand-paper-o\',\n\t\'hand-scissors-o\',\n\t\'hand-lizard-o\',\n\t\'hand-spock-o\',\n\t\'hand-pointer-o\',\n\t\'hand-peace-o\',\n\t\'trademark\',\n\t\'registered\',\n\t\'creative-commons\',\n\t\'gg\',\n\t\'gg-circle\',\n\t\'tripadvisor\',\n\t\'odnoklassniki\',\n\t\'odnoklassniki-square\',\n\t\'get-pocket\',\n\t\'wikipedia-w\',\n\t\'safari\',\n\t\'chrome\',\n\t\'firefox\',\n\t\'opera\',\n\t\'internet-explorer\',\n\t\'television\',\n\t\'contao\',\n\t\'500px\',\n\t\'amazon\',\n\t\'calendar-plus-o\',\n\t\'calendar-minus-o\',\n\t\'calendar-times-o\',\n\t\'calendar-check-o\',\n\t\'industry\',\n\t\'map-pin\',\n\t\'map-signs\',\n\t\'map-o\',\n\t\'map\',\n\t\'commenting\',\n\t\'commenting-o\',\n\t\'houzz\',\n\t\'vimeo\',\n\t\'black-tie\',\n\t\'fonticons\',\n]\n# generate by tools/list_icons\n#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n""""""\n    list of icons Font-Awesome\n""""""\n\nicons = [\n\t\'glass\',\n\t\'music\',\n\t\'search\',\n\t\'envelope-o\',\n\t\'heart\',\n\t\'star\',\n\t\'star-o\',\n\t\'user\',\n\t\'film\',\n\t\'th-large\',\n\t\'th\',\n\t\'th-list\',\n\t\'check\',\n\t\'times\',\n\t\'remove\',\n\t\'close\',\n\t\'search-plus\',\n\t\'search-minus\',\n\t\'power-off\',\n\t\'signal\',\n\t\'cog\',\n\t\'gear\',\n\t\'trash-o\',\n\t\'home\',\n\t\'file-o\',\n\t\'clock-o\',\n\t\'road\',\n\t\'download\',\n\t\'arrow-circle-o-down\',\n\t\'arrow-circle-o-up\',\n\t\'inbox\',\n\t\'play-circle-o\',\n\t\'repeat\',\n\t\'rotate-right\',\n\t\'refresh\',\n\t\'list-alt\',\n\t\'lock\',\n\t\'flag\',\n\t\'headphones\',\n\t\'volume-off\',\n\t\'volume-down\',\n\t\'volume-up\',\n\t\'qrcode\',\n\t\'barcode\',\n\t\'tag\',\n\t\'tags\',\n\t\'book\',\n\t\'bookmark\',\n\t\'print\',\n\t\'camera\',\n\t\'font\',\n\t\'bold\',\n\t\'italic\',\n\t\'text-height\',\n\t\'text-width\',\n\t\'align-left\',\n\t\'align-center\',\n\t\'align-right\',\n\t\'align-justify\',\n\t\'list\',\n\t\'outdent\',\n\t\'dedent\',\n\t\'indent\',\n\t\'video-camera\',\n\t\'picture-o\',\n\t\'photo\',\n\t\'image\',\n\t\'pencil\',\n\t\'map-marker\',\n\t\'adjust\',\n\t\'tint\',\n\t\'pencil-square-o\',\n\t\'edit\',\n\t\'share-square-o\',\n\t\'check-square-o\',\n\t\'arrows\',\n\t\'step-backward\',\n\t\'fast-backward\',\n\t\'backward\',\n\t\'play\',\n\t\'pause\',\n\t\'stop\',\n\t\'forward\',\n\t\'fast-forward\',\n\t\'step-forward\',\n\t\'eject\',\n\t\'chevron-left\',\n\t\'chevron-right\',\n\t\'plus-circle\',\n\t\'minus-circle\',\n\t\'times-circle\',\n\t\'check-circle\',\n\t\'question-circle\',\n\t\'info-circle\',\n\t\'crosshairs\',\n\t\'times-circle-o\',\n\t\'check-circle-o\',\n\t\'ban\',\n\t\'arrow-left\',\n\t\'arrow-right\',\n\t\'arrow-up\',\n\t\'arrow-down\',\n\t\'share\',\n\t\'mail-forward\',\n\t\'expand\',\n\t\'compress\',\n\t\'plus\',\n\t\'minus\',\n\t\'asterisk\',\n\t\'exclamation-circle\',\n\t\'gift\',\n\t\'leaf\',\n\t\'fire\',\n\t\'eye\',\n\t\'eye-slash\',\n\t\'exclamation-triangle\',\n\t\'warning\',\n\t\'plane\',\n\t\'calendar\',\n\t\'random\',\n\t\'comment\',\n\t\'magnet\',\n\t\'chevron-up\',\n\t\'chevron-down\',\n\t\'retweet\',\n\t\'shopping-cart\',\n\t\'folder\',\n\t\'folder-open\',\n\t\'arrows-v\',\n\t\'arrows-h\',\n\t\'bar-chart\',\n\t\'bar-chart-o\',\n\t\'twitter-square\',\n\t\'facebook-square\',\n\t\'camera-retro\',\n\t\'key\',\n\t\'cogs\',\n\t\'gears\',\n\t\'comments\',\n\t\'thumbs-o-up\',\n\t\'thumbs-o-down\',\n\t\'star-half\',\n\t\'heart-o\',\n\t\'sign-out\',\n\t\'linkedin-square\',\n\t\'thumb-tack\',\n\t\'external-link\',\n\t\'sign-in\',\n\t\'trophy\',\n\t\'github-square\',\n\t\'upload\',\n\t\'lemon-o\',\n\t\'phone\',\n\t\'square-o\',\n\t\'bookmark-o\',\n\t\'phone-square\',\n\t\'twitter\',\n\t\'facebook\',\n\t\'facebook-f\',\n\t\'github\',\n\t\'unlock\',\n\t\'credit-card\',\n\t\'rss\',\n\t\'feed\',\n\t\'hdd-o\',\n\t\'bullhorn\',\n\t\'bell\',\n\t\'certificate\',\n\t\'hand-o-right\',\n\t\'hand-o-left\',\n\t\'hand-o-up\',\n\t\'hand-o-down\',\n\t\'arrow-circle-left\',\n\t\'arrow-circle-right\',\n\t\'arrow-circle-up\',\n\t\'arrow-circle-down\',\n\t\'globe\',\n\t\'wrench\',\n\t\'tasks\',\n\t\'filter\',\n\t\'briefcase\',\n\t\'arrows-alt\',\n\t\'users\',\n\t\'group\',\n\t\'link\',\n\t\'chain\',\n\t\'cloud\',\n\t\'flask\',\n\t\'scissors\',\n\t\'cut\',\n\t\'files-o\',\n\t\'copy\',\n\t\'paperclip\',\n\t\'floppy-o\',\n\t\'save\',\n\t\'square\',\n\t\'bars\',\n\t\'navicon\',\n\t\'reorder\',\n\t\'list-ul\',\n\t\'list-ol\',\n\t\'strikethrough\',\n\t\'underline\',\n\t\'table\',\n\t\'magic\',\n\t\'truck\',\n\t\'pinterest\',\n\t\'pinterest-square\',\n\t\'google-plus-square\',\n\t\'google-plus\',\n\t\'money\',\n\t\'caret-down\',\n\t\'caret-up\',\n\t\'caret-left\',\n\t\'caret-right\',\n\t\'columns\',\n\t\'sort\',\n\t\'unsorted\',\n\t\'sort-desc\',\n\t\'sort-down\',\n\t\'sort-asc\',\n\t\'sort-up\',\n\t\'envelope\',\n\t\'linkedin\',\n\t\'undo\',\n\t\'rotate-left\',\n\t\'gavel\',\n\t\'legal\',\n\t\'tachometer\',\n\t\'dashboard\',\n\t\'comment-o\',\n\t\'comments-o\',\n\t\'bolt\',\n\t\'flash\',\n\t\'sitemap\',\n\t\'umbrella\',\n\t\'clipboard\',\n\t\'paste\',\n\t\'lightbulb-o\',\n\t\'exchange\',\n\t\'cloud-download\',\n\t\'cloud-upload\',\n\t\'user-md\',\n\t\'stethoscope\',\n\t\'suitcase\',\n\t\'bell-o\',\n\t\'coffee\',\n\t\'cutlery\',\n\t\'file-text-o\',\n\t\'building-o\',\n\t\'hospital-o\',\n\t\'ambulance\',\n\t\'medkit\',\n\t\'fighter-jet\',\n\t\'beer\',\n\t\'h-square\',\n\t\'plus-square\',\n\t\'angle-double-left\',\n\t\'angle-double-right\',\n\t\'angle-double-up\',\n\t\'angle-double-down\',\n\t\'angle-left\',\n\t\'angle-right\',\n\t\'angle-up\',\n\t\'angle-down\',\n\t\'desktop\',\n\t\'laptop\',\n\t\'tablet\',\n\t\'mobile\',\n\t\'mobile-phone\',\n\t\'circle-o\',\n\t\'quote-left\',\n\t\'quote-right\',\n\t\'spinner\',\n\t\'circle\',\n\t\'reply\',\n\t\'mail-reply\',\n\t\'github-alt\',\n\t\'folder-o\',\n\t\'folder-open-o\',\n\t\'smile-o\',\n\t\'frown-o\',\n\t\'meh-o\',\n\t\'gamepad\',\n\t\'keyboard-o\',\n\t\'flag-o\',\n\t\'flag-checkered\',\n\t\'terminal\',\n\t\'code\',\n\t\'reply-all\',\n\t\'mail-reply-all\',\n\t\'star-half-o\',\n\t\'star-half-empty\',\n\t\'star-half-full\',\n\t\'location-arrow\',\n\t\'crop\',\n\t\'code-fork\',\n\t\'chain-broken\',\n\t\'unlink\',\n\t\'question\',\n\t\'info\',\n\t\'exclamation\',\n\t\'superscript\',\n\t\'subscript\',\n\t\'eraser\',\n\t\'puzzle-piece\',\n\t\'microphone\',\n\t\'microphone-slash\',\n\t\'shield\',\n\t\'calendar-o\',\n\t\'fire-extinguisher\',\n\t\'rocket\',\n\t\'maxcdn\',\n\t\'chevron-circle-left\',\n\t\'chevron-circle-right\',\n\t\'chevron-circle-up\',\n\t\'chevron-circle-down\',\n\t\'html5\',\n\t\'css3\',\n\t\'anchor\',\n\t\'unlock-alt\',\n\t\'bullseye\',\n\t\'ellipsis-h\',\n\t\'ellipsis-v\',\n\t\'rss-square\',\n\t\'play-circle\',\n\t\'ticket\',\n\t\'minus-square\',\n\t\'minus-square-o\',\n\t\'level-up\',\n\t\'level-down\',\n\t\'check-square\',\n\t\'pencil-square\',\n\t\'external-link-square\',\n\t\'share-square\',\n\t\'compass\',\n\t\'caret-square-o-down\',\n\t\'toggle-down\',\n\t\'caret-square-o-up\',\n\t\'toggle-up\',\n\t\'caret-square-o-right\',\n\t\'toggle-right\',\n\t\'eur\',\n\t\'euro\',\n\t\'gbp\',\n\t\'usd\',\n\t\'dollar\',\n\t\'inr\',\n\t\'rupee\',\n\t\'jpy\',\n\t\'cny\',\n\t\'rmb\',\n\t\'yen\',\n\t\'rub\',\n\t\'ruble\',\n\t\'rouble\',\n\t\'krw\',\n\t\'won\',\n\t\'btc\',\n\t\'bitcoin\',\n\t\'file\',\n\t\'file-text\',\n\t\'sort-alpha-asc\',\n\t\'sort-alpha-desc\',\n\t\'sort-amount-asc\',\n\t\'sort-amount-desc\',\n\t\'sort-numeric-asc\',\n\t\'sort-numeric-desc\',\n\t\'thumbs-up\',\n\t\'thumbs-down\',\n\t\'youtube-square\',\n\t\'youtube\',\n\t\'xing\',\n\t\'xing-square\',\n\t\'youtube-play\',\n\t\'dropbox\',\n\t\'stack-overflow\',\n\t\'instagram\',\n\t\'flickr\',\n\t\'adn\',\n\t\'bitbucket\',\n\t\'bitbucket-square\',\n\t\'tumblr\',\n\t\'tumblr-square\',\n\t\'long-arrow-down\',\n\t\'long-arrow-up\',\n\t\'long-arrow-left\',\n\t\'long-arrow-right\',\n\t\'apple\',\n\t\'windows\',\n\t\'android\',\n\t\'linux\',\n\t\'dribbble\',\n\t\'skype\',\n\t\'foursquare\',\n\t\'trello\',\n\t\'female\',\n\t\'male\',\n\t\'gratipay\',\n\t\'gittip\',\n\t\'sun-o\',\n\t\'moon-o\',\n\t\'archive\',\n\t\'bug\',\n\t\'vk\',\n\t\'weibo\',\n\t\'renren\',\n\t\'pagelines\',\n\t\'stack-exchange\',\n\t\'arrow-circle-o-right\',\n\t\'arrow-circle-o-left\',\n\t\'caret-square-o-left\',\n\t\'toggle-left\',\n\t\'dot-circle-o\',\n\t\'wheelchair\',\n\t\'vimeo-square\',\n\t\'try\',\n\t\'turkish-lira\',\n\t\'plus-square-o\',\n\t\'space-shuttle\',\n\t\'slack\',\n\t\'envelope-square\',\n\t\'wordpress\',\n\t\'openid\',\n\t\'university\',\n\t\'institution\',\n\t\'bank\',\n\t\'graduation-cap\',\n\t\'mortar-board\',\n\t\'yahoo\',\n\t\'google\',\n\t\'reddit\',\n\t\'reddit-square\',\n\t\'stumbleupon-circle\',\n\t\'stumbleupon\',\n\t\'delicious\',\n\t\'digg\',\n\t\'pied-piper\',\n\t\'pied-piper-alt\',\n\t\'drupal\',\n\t\'joomla\',\n\t\'language\',\n\t\'fax\',\n\t\'building\',\n\t\'child\',\n\t\'paw\',\n\t\'spoon\',\n\t\'cube\',\n\t\'cubes\',\n\t\'behance\',\n\t\'behance-square\',\n\t\'steam\',\n\t\'steam-square\',\n\t\'recycle\',\n\t\'car\',\n\t\'automobile\',\n\t\'taxi\',\n\t\'cab\',\n\t\'tree\',\n\t\'spotify\',\n\t\'deviantart\',\n\t\'soundcloud\',\n\t\'database\',\n\t\'file-pdf-o\',\n\t\'file-word-o\',\n\t\'file-excel-o\',\n\t\'file-powerpoint-o\',\n\t\'file-image-o\',\n\t\'file-photo-o\',\n\t\'file-picture-o\',\n\t\'file-archive-o\',\n\t\'file-zip-o\',\n\t\'file-audio-o\',\n\t\'file-sound-o\',\n\t\'file-video-o\',\n\t\'file-movie-o\',\n\t\'file-code-o\',\n\t\'vine\',\n\t\'codepen\',\n\t\'jsfiddle\',\n\t\'life-ring\',\n\t\'life-bouy\',\n\t\'life-buoy\',\n\t\'life-saver\',\n\t\'support\',\n\t\'circle-o-notch\',\n\t\'rebel\',\n\t\'ra\',\n\t\'empire\',\n\t\'ge\',\n\t\'git-square\',\n\t\'git\',\n\t\'hacker-news\',\n\t\'y-combinator-square\',\n\t\'yc-square\',\n\t\'tencent-weibo\',\n\t\'qq\',\n\t\'weixin\',\n\t\'wechat\',\n\t\'paper-plane\',\n\t\'send\',\n\t\'paper-plane-o\',\n\t\'send-o\',\n\t\'history\',\n\t\'circle-thin\',\n\t\'header\',\n\t\'paragraph\',\n\t\'sliders\',\n\t\'share-alt\',\n\t\'share-alt-square\',\n\t\'bomb\',\n\t\'futbol-o\',\n\t\'soccer-ball-o\',\n\t\'tty\',\n\t\'binoculars\',\n\t\'plug\',\n\t\'slideshare\',\n\t\'twitch\',\n\t\'yelp\',\n\t\'newspaper-o\',\n\t\'wifi\',\n\t\'calculator\',\n\t\'paypal\',\n\t\'google-wallet\',\n\t\'cc-visa\',\n\t\'cc-mastercard\',\n\t\'cc-discover\',\n\t\'cc-amex\',\n\t\'cc-paypal\',\n\t\'cc-stripe\',\n\t\'bell-slash\',\n\t\'bell-slash-o\',\n\t\'trash\',\n\t\'copyright\',\n\t\'at\',\n\t\'eyedropper\',\n\t\'paint-brush\',\n\t\'birthday-cake\',\n\t\'area-chart\',\n\t\'pie-chart\',\n\t\'line-chart\',\n\t\'lastfm\',\n\t\'lastfm-square\',\n\t\'toggle-off\',\n\t\'toggle-on\',\n\t\'bicycle\',\n\t\'bus\',\n\t\'ioxhost\',\n\t\'angellist\',\n\t\'cc\',\n\t\'ils\',\n\t\'shekel\',\n\t\'sheqel\',\n\t\'meanpath\',\n\t\'buysellads\',\n\t\'connectdevelop\',\n\t\'dashcube\',\n\t\'forumbee\',\n\t\'leanpub\',\n\t\'sellsy\',\n\t\'shirtsinbulk\',\n\t\'simplybuilt\',\n\t\'skyatlas\',\n\t\'cart-plus\',\n\t\'cart-arrow-down\',\n\t\'diamond\',\n\t\'ship\',\n\t\'user-secret\',\n\t\'motorcycle\',\n\t\'street-view\',\n\t\'heartbeat\',\n\t\'venus\',\n\t\'mars\',\n\t\'mercury\',\n\t\'transgender\',\n\t\'intersex\',\n\t\'transgender-alt\',\n\t\'venus-double\',\n\t\'mars-double\',\n\t\'venus-mars\',\n\t\'mars-stroke\',\n\t\'mars-stroke-v\',\n\t\'mars-stroke-h\',\n\t\'neuter\',\n\t\'genderless\',\n\t\'facebook-official\',\n\t\'pinterest-p\',\n\t\'whatsapp\',\n\t\'server\',\n\t\'user-plus\',\n\t\'user-times\',\n\t\'bed\',\n\t\'hotel\',\n\t\'viacoin\',\n\t\'train\',\n\t\'subway\',\n\t\'medium\',\n\t\'y-combinator\',\n\t\'yc\',\n\t\'optin-monster\',\n\t\'opencart\',\n\t\'expeditedssl\',\n\t\'battery-full\',\n\t\'battery-4\',\n\t\'battery-three-quarters\',\n\t\'battery-3\',\n\t\'battery-half\',\n\t\'battery-2\',\n\t\'battery-quarter\',\n\t\'battery-1\',\n\t\'battery-empty\',\n\t\'battery-0\',\n\t\'mouse-pointer\',\n\t\'i-cursor\',\n\t\'object-group\',\n\t\'object-ungroup\',\n\t\'sticky-note\',\n\t\'sticky-note-o\',\n\t\'cc-jcb\',\n\t\'cc-diners-club\',\n\t\'clone\',\n\t\'balance-scale\',\n\t\'hourglass-o\',\n\t\'hourglass-start\',\n\t\'hourglass-1\',\n\t\'hourglass-half\',\n\t\'hourglass-2\',\n\t\'hourglass-end\',\n\t\'hourglass-3\',\n\t\'hourglass\',\n\t\'hand-rock-o\',\n\t\'hand-grab-o\',\n\t\'hand-paper-o\',\n\t\'hand-stop-o\',\n\t\'hand-scissors-o\',\n\t\'hand-lizard-o\',\n\t\'hand-spock-o\',\n\t\'hand-pointer-o\',\n\t\'hand-peace-o\',\n\t\'trademark\',\n\t\'registered\',\n\t\'creative-commons\',\n\t\'gg\',\n\t\'gg-circle\',\n\t\'tripadvisor\',\n\t\'odnoklassniki\',\n\t\'odnoklassniki-square\',\n\t\'get-pocket\',\n\t\'wikipedia-w\',\n\t\'safari\',\n\t\'chrome\',\n\t\'firefox\',\n\t\'opera\',\n\t\'internet-explorer\',\n\t\'television\',\n\t\'tv\',\n\t\'contao\',\n\t\'500px\',\n\t\'amazon\',\n\t\'calendar-plus-o\',\n\t\'calendar-minus-o\',\n\t\'calendar-times-o\',\n\t\'calendar-check-o\',\n\t\'industry\',\n\t\'map-pin\',\n\t\'map-signs\',\n\t\'map-o\',\n\t\'map\',\n\t\'commenting\',\n\t\'commenting-o\',\n\t\'houzz\',\n\t\'vimeo\',\n\t\'black-tie\',\n\t\'fonticons\',\n]\n# generate by tools/list_icons\n\n'"
veros/core/density/__init__.py,0,b'from .get_rho import *\n'
veros/core/density/get_rho.py,0,"b'from . import (gsw, linear_eq as lq, nonlinear_eq1 as nq1,\n               nonlinear_eq2 as nq2, nonlinear_eq3 as nq3)\nfrom ... import veros_method\n\n\n@veros_method\ndef get_rho(vs, salt_loc, temp_loc, press):\n    """"""\n    calculate density as a function of temperature, salinity and pressure\n    """"""\n    if vs.eq_of_state_type == 1:\n        return lq.linear_eq_of_state_rho(salt_loc, temp_loc)\n    elif vs.eq_of_state_type == 2:\n        return nq1.nonlin1_eq_of_state_rho(salt_loc, temp_loc)\n    elif vs.eq_of_state_type == 3:\n        return nq2.nonlin2_eq_of_state_rho(salt_loc, temp_loc, press)\n    elif vs.eq_of_state_type == 4:\n        return nq3.nonlin3_eq_of_state_rho(salt_loc, temp_loc)\n    elif vs.eq_of_state_type == 5:\n        return gsw.gsw_rho(vs, salt_loc, temp_loc, press)\n    else:\n        raise ValueError(\'unknown equation of state\')\n\n\n@veros_method\ndef get_potential_rho(vs, salt_loc, temp_loc, press_ref=0.):\n    """"""\n    calculate potential density as a function of temperature, salinity\n    and reference pressure\n\n    Note:\n\n        This is identical to get_rho for eq_of_state_type {1, 2, 4}\n\n    """"""\n    if vs.eq_of_state_type == 1:\n        return lq.linear_eq_of_state_rho(salt_loc, temp_loc)\n    elif vs.eq_of_state_type == 2:\n        return nq1.nonlin1_eq_of_state_rho(salt_loc, temp_loc)\n    elif vs.eq_of_state_type == 3:\n        return nq2.nonlin2_eq_of_state_rho(salt_loc, temp_loc, press_ref)\n    elif vs.eq_of_state_type == 4:\n        return nq3.nonlin3_eq_of_state_rho(salt_loc, temp_loc)\n    elif vs.eq_of_state_type == 5:\n        return gsw.gsw_rho(vs, salt_loc, temp_loc, press_ref)\n    else:\n        raise ValueError(\'unknown equation of state\')\n\n\n@veros_method\ndef get_dyn_enthalpy(vs, salt_loc, temp_loc, press):\n    """"""\n    calculate dynamic enthalpy as a function of temperature, salinity and pressure\n    """"""\n    if vs.eq_of_state_type == 1:\n        return lq.linear_eq_of_state_dyn_enthalpy(salt_loc, temp_loc, press)\n    elif vs.eq_of_state_type == 2:\n        return nq1.nonlin1_eq_of_state_dyn_enthalpy(salt_loc, temp_loc, press)\n    elif vs.eq_of_state_type == 3:\n        return nq2.nonlin2_eq_of_state_dyn_enthalpy(salt_loc, temp_loc, press)\n    elif vs.eq_of_state_type == 4:\n        return nq3.nonlin3_eq_of_state_dyn_enthalpy(salt_loc, temp_loc, press)\n    elif vs.eq_of_state_type == 5:\n        return gsw.gsw_dyn_enthalpy(vs, salt_loc, temp_loc, press)\n    else:\n        raise ValueError(\'unknown equation of state\')\n\n\n@veros_method\ndef get_salt(vs, rho_loc, temp_loc, press_loc):\n    """"""\n    calculate salinity as a function of density, temperature and pressure\n    """"""\n    if vs.eq_of_state_type == 1:\n        return lq.linear_eq_of_state_salt(rho_loc, temp_loc)\n    elif vs.eq_of_state_type == 2:\n        return nq1.nonlin1_eq_of_state_salt(rho_loc, temp_loc)\n    elif vs.eq_of_state_type == 3:\n        return nq2.nonlin2_eq_of_state_salt(rho_loc, temp_loc, press_loc)\n    elif vs.eq_of_state_type == 4:\n        return nq3.nonlin3_eq_of_state_salt(rho_loc, temp_loc)\n    else:\n        raise ValueError(\'unknown equation of state\')\n\n\n@veros_method\ndef get_drhodT(vs, salt_loc, temp_loc, press_loc):\n    """"""\n    calculate drho/dT as a function of temperature, salinity and pressure\n    """"""\n    if vs.eq_of_state_type == 1:\n        return lq.linear_eq_of_state_drhodT()\n    elif vs.eq_of_state_type == 2:\n        return nq1.nonlin1_eq_of_state_drhodT(temp_loc)\n    elif vs.eq_of_state_type == 3:\n        return nq2.nonlin2_eq_of_state_drhodT(temp_loc, press_loc)\n    elif vs.eq_of_state_type == 4:\n        return nq3.nonlin3_eq_of_state_drhodT(temp_loc)\n    elif vs.eq_of_state_type == 5:\n        return gsw.gsw_drhodT(vs, salt_loc, temp_loc, press_loc)\n    else:\n        raise ValueError(\'unknown equation of state\')\n\n\n@veros_method\ndef get_drhodS(vs, salt_loc, temp_loc, press_loc):\n    """"""\n    calculate drho/dS as a function of temperature, salinity and pressure\n    """"""\n    if vs.eq_of_state_type == 1:\n        return lq.linear_eq_of_state_drhodS()\n    elif vs.eq_of_state_type == 2:\n        return nq1.nonlin1_eq_of_state_drhodS()\n    elif vs.eq_of_state_type == 3:\n        return nq2.nonlin2_eq_of_state_drhodS()\n    elif vs.eq_of_state_type == 4:\n        return nq3.nonlin3_eq_of_state_drhodS()\n    elif vs.eq_of_state_type == 5:\n        return gsw.gsw_drhodS(vs, salt_loc, temp_loc, press_loc)\n    else:\n        raise ValueError(\'unknown equation of state\')\n\n\n@veros_method\ndef get_drhodp(vs, salt_loc, temp_loc, press_loc):\n    """"""\n    calculate drho/dP as a function of temperature, salinity and pressure\n    """"""\n    if vs.eq_of_state_type == 1:\n        return lq.linear_eq_of_state_drhodp()\n    elif vs.eq_of_state_type == 2:\n        return nq1.nonlin1_eq_of_state_drhodp()\n    elif vs.eq_of_state_type == 3:\n        return nq2.nonlin2_eq_of_state_drhodp(temp_loc)\n    elif vs.eq_of_state_type == 4:\n        return nq3.nonlin3_eq_of_state_drhodp()\n    elif vs.eq_of_state_type == 5:\n        return gsw.gsw_drhodp(vs, salt_loc, temp_loc, press_loc)\n    else:\n        raise ValueError(\'unknown equation of state\')\n\n\n@veros_method\ndef get_int_drhodT(vs, salt_loc, temp_loc, press_loc):\n    """"""\n    calculate int_z^0 drho/dT dz\' as a function of temperature, salinity and pressure\n    """"""\n    if vs.eq_of_state_type == 1:\n        return press_loc * lq.linear_eq_of_state_drhodT()  # int_z^0rho_T dz = - rho_T z\n    elif vs.eq_of_state_type == 2:\n        return press_loc * nq1.nonlin1_eq_of_state_drhodT(temp_loc)\n    elif vs.eq_of_state_type == 3:\n        return nq2.nonlin2_eq_of_state_int_drhodT(temp_loc, press_loc)\n    elif vs.eq_of_state_type == 4:\n        return press_loc * nq3.nonlin3_eq_of_state_drhodT(temp_loc)\n    elif vs.eq_of_state_type == 5:\n        return -(1024.0 / 9.81) * gsw.gsw_dHdT(vs, salt_loc, temp_loc, press_loc)\n    else:\n        raise ValueError(\'unknown equation of state\')\n\n\n@veros_method\ndef get_int_drhodS(vs, salt_loc, temp_loc, press_loc):\n    """"""\n    calculate int_z^0 drho/dS dz\' as a function of temperature, salinity and pressure\n    """"""\n    if vs.eq_of_state_type == 1:\n        return press_loc * lq.linear_eq_of_state_drhodS()  # int_z^0rho_T dz = - rho_T z\n    elif vs.eq_of_state_type == 2:\n        return press_loc * nq1.nonlin1_eq_of_state_drhodS()\n    elif vs.eq_of_state_type == 3:\n        return nq2.nonlin2_eq_of_state_int_drhodS(press_loc)\n    elif vs.eq_of_state_type == 4:\n        return press_loc * nq3.nonlin3_eq_of_state_drhodS()\n    elif vs.eq_of_state_type == 5:\n        return -(1024.0 / 9.81) * gsw.gsw_dHdS(vs, salt_loc, temp_loc, press_loc)\n    else:\n        raise ValueError(\'unknown equation of state\')\n'"
veros/core/density/gsw.py,29,"b'from ... import veros_method\n\n""""""\n==========================================================================\n  in-situ density, dynamic enthalpy and derivatives\n  from Absolute Salinity and Conservative\n  Temperature, using the computationally-efficient 48-term expression for\n  density in terms of SA, CT and p (IOC et al., 2010).\n==========================================================================\n""""""\nv01 = 9.998420897506056e+2\nv02 = 2.839940833161907e0\nv03 = -3.147759265588511e-2\nv04 = 1.181805545074306e-3\nv05 = -6.698001071123802e0\nv06 = -2.986498947203215e-2\nv07 = 2.327859407479162e-4\nv08 = -3.988822378968490e-2\nv09 = 5.095422573880500e-4\nv10 = -1.426984671633621e-5\nv11 = 1.645039373682922e-7\nv12 = -2.233269627352527e-2\nv13 = -3.436090079851880e-4\nv14 = 3.726050720345733e-6\nv15 = -1.806789763745328e-4\nv16 = 6.876837219536232e-7\nv17 = -3.087032500374211e-7\nv18 = -1.988366587925593e-8\nv19 = -1.061519070296458e-11\nv20 = 1.550932729220080e-10\nv21 = 1.0e0\nv22 = 2.775927747785646e-3\nv23 = -2.349607444135925e-5\nv24 = 1.119513357486743e-6\nv25 = 6.743689325042773e-10\nv26 = -7.521448093615448e-3\nv27 = -2.764306979894411e-5\nv28 = 1.262937315098546e-7\nv29 = 9.527875081696435e-10\nv30 = -1.811147201949891e-11\nv31 = -3.303308871386421e-5\nv32 = 3.801564588876298e-7\nv33 = -7.672876869259043e-9\nv34 = -4.634182341116144e-11\nv35 = 2.681097235569143e-12\nv36 = 5.419326551148740e-6\nv37 = -2.742185394906099e-5\nv38 = -3.212746477974189e-7\nv39 = 3.191413910561627e-9\nv40 = -1.931012931541776e-12\nv41 = -1.105097577149576e-7\nv42 = 6.211426728363857e-10\nv43 = -1.119011592875110e-10\nv44 = -1.941660213148725e-11\nv45 = -1.864826425365600e-14\nv46 = 1.119522344879478e-14\nv47 = -1.200507748551599e-15\nv48 = 6.057902487546866e-17\nrho0 = 1024.0\n\n\n@veros_method\ndef gsw_rho(vs, sa, ct, p):\n    """"""\n     density as a function of T, S, and p\n     sa     : Absolute Salinity                               [g/kg]\n     ct     : Conservative Temperature                        [deg C]\n     p      : sea pressure                                    [dbar]\n    ==========================================================================\n    """"""\n    # convert scalar values if necessary\n    sa, ct, p = np.asarray(sa), np.asarray(ct), np.asarray(p)\n    sqrtsa = np.sqrt(sa)\n    v_hat_denominator = v01 + ct * (v02 + ct * (v03 + v04 * ct)) \\\n        + sa * (v05 + ct * (v06 + v07 * ct)\n                + sqrtsa * (v08 + ct * (v09 + ct * (v10 + v11 * ct)))) \\\n        + p * (v12 + ct * (v13 + v14 * ct) + sa * (v15 + v16 * ct)\n               + p * (v17 + ct * (v18 + v19 * ct) + v20 * sa))\n    v_hat_numerator = v21 + ct * (v22 + ct * (v23 + ct * (v24 + v25 * ct)))  \\\n        + sa * (v26 + ct * (v27 + ct * (v28 + ct * (v29 + v30 * ct))) + v36 * sa\n                + sqrtsa * (v31 + ct * (v32 + ct * (v33 + ct * (v34 + v35 * ct))))) \\\n        + p * (v37 + ct * (v38 + ct * (v39 + v40 * ct))\n               + sa * (v41 + v42 * ct) + p * (v43 + ct * (v44 + v45 * ct + v46 * sa)\n                                              + p * (v47 + v48 * ct)))\n    return v_hat_denominator / v_hat_numerator - rho0\n\n\n@veros_method\ndef gsw_drhodT(vs, sa, ct, p):\n    """"""\n    d/dT of density\n    sa     : Absolute Salinity                               [g/kg]\n    ct     : Conservative Temperature                        [deg C]\n    p      : sea pressure                                    [dbar]\n    ==========================================================================\n    """"""\n    p = np.asarray(p)  # convert scalar value if necessary\n    a01 = 2.839940833161907e0\n    a02 = -6.295518531177023e-2\n    a03 = 3.545416635222918e-3\n    a04 = -2.986498947203215e-2\n    a05 = 4.655718814958324e-4\n    a06 = 5.095422573880500e-4\n    a07 = -2.853969343267241e-5\n    a08 = 4.935118121048767e-7\n    a09 = -3.436090079851880e-4\n    a10 = 7.452101440691467e-6\n    a11 = 6.876837219536232e-7\n    a12 = -1.988366587925593e-8\n    a13 = -2.123038140592916e-11\n    a14 = 2.775927747785646e-3\n    a15 = -4.699214888271850e-5\n    a16 = 3.358540072460230e-6\n    a17 = 2.697475730017109e-9\n    a18 = -2.764306979894411e-5\n    a19 = 2.525874630197091e-7\n    a20 = 2.858362524508931e-9\n    a21 = -7.244588807799565e-11\n    a22 = 3.801564588876298e-7\n    a23 = -1.534575373851809e-8\n    a24 = -1.390254702334843e-10\n    a25 = 1.072438894227657e-11\n    a26 = -3.212746477974189e-7\n    a27 = 6.382827821123254e-9\n    a28 = -5.793038794625329e-12\n    a29 = 6.211426728363857e-10\n    a30 = -1.941660213148725e-11\n    a31 = -3.729652850731201e-14\n    a32 = 1.119522344879478e-14\n    a33 = 6.057902487546866e-17\n\n    sqrtsa = np.sqrt(sa)\n    v_hat_denominator = v01 + ct * (v02 + ct * (v03 + v04 * ct)) + sa * (v05 + ct * (v06 + v07 * ct)\n                                                                         + sqrtsa * (v08 + ct * (v09 + ct * (v10 + v11 * ct)))) + p * (v12 + ct * (v13 + v14 * ct) + sa * (v15 + v16 * ct)\n                                                                                                                                       + p * (v17 + ct * (v18 + v19 * ct) + v20 * sa))\n\n    v_hat_numerator = v21 + ct * (v22 + ct * (v23 + ct * (v24 + v25 * ct))) \\\n        + sa * (v26 + ct * (v27 + ct * (v28 + ct * (v29 + v30 * ct))) + v36 * sa\n                + sqrtsa * (v31 + ct * (v32 + ct * (v33 + ct * (v34 + v35 * ct))))) + p * (v37 + ct * (v38 + ct * (v39 + v40 * ct))\n                                                                                           + sa * (v41 + v42 * ct) + p * (v43 + ct * (v44 + v45 * ct + v46 * sa) + p * (v47 + v48 * ct)))\n\n    dvhatden_dct = a01 + ct * (a02 + a03 * ct) + sa * (a04 + a05 * ct + sqrtsa * (a06 + ct * (a07 + a08 * ct))) \\\n        + p * (a09 + a10 * ct + a11 * sa + p * (a12 + a13 * ct))\n\n    dvhatnum_dct = a14 + ct * (a15 + ct * (a16 + a17 * ct)) + sa * (a18 + ct * (a19 + ct * (a20 + a21 * ct))\n                                                                    + sqrtsa * (a22 + ct * (a23 + ct * (a24 + a25 * ct)))) \\\n        + p * (a26 + ct * (a27 + a28 * ct) + a29 * sa + p * (a30 + a31 * ct + a32 * sa + a33 * p))\n\n    rec_num = 1.0 / v_hat_numerator\n    rho = rec_num * v_hat_denominator\n    return (dvhatden_dct - dvhatnum_dct * rho) * rec_num\n\n\n@veros_method\ndef gsw_drhodS(vs, sa, ct, p):\n    """"""\n     d/dS of density\n     sa     : Absolute Salinity                               [g/kg]\n     ct     : Conservative Temperature                        [deg C]\n     p      : sea pressure                                    [dbar]\n    ==========================================================================\n    """"""\n    p = np.asarray(p)  # convert scalar value if necessary\n    b01 = -6.698001071123802e0\n    b02 = -2.986498947203215e-2\n    b03 = 2.327859407479162e-4\n    b04 = -5.983233568452735e-2\n    b05 = 7.643133860820750e-4\n    b06 = -2.140477007450431e-5\n    b07 = 2.467559060524383e-7\n    b08 = -1.806789763745328e-4\n    b09 = 6.876837219536232e-7\n    b10 = 1.550932729220080e-10\n    b11 = -7.521448093615448e-3\n    b12 = -2.764306979894411e-5\n    b13 = 1.262937315098546e-7\n    b14 = 9.527875081696435e-10\n    b15 = -1.811147201949891e-11\n    b16 = -4.954963307079632e-5\n    b17 = 5.702346883314446e-7\n    b18 = -1.150931530388857e-8\n    b19 = -6.951273511674217e-11\n    b20 = 4.021645853353715e-12\n    b21 = 1.083865310229748e-5\n    b22 = -1.105097577149576e-7\n    b23 = 6.211426728363857e-10\n    b24 = 1.119522344879478e-14\n\n    sqrtsa = np.sqrt(sa)\n    v_hat_denominator = v01 + ct * (v02 + ct * (v03 + v04 * ct)) + sa * (v05 + ct * (v06 + v07 * ct)\n                                                                         + sqrtsa * (v08 + ct * (v09 + ct * (v10 + v11 * ct)))) + p * (v12 + ct * (v13 + v14 * ct) + sa * (v15 + v16 * ct)\n                                                                                                                                       + p * (v17 + ct * (v18 + v19 * ct) + v20 * sa))\n\n    v_hat_numerator = v21 + ct * (v22 + ct * (v23 + ct * (v24 + v25 * ct))) \\\n        + sa * (v26 + ct * (v27 + ct * (v28 + ct * (v29 + v30 * ct))) + v36 * sa\n                + sqrtsa * (v31 + ct * (v32 + ct * (v33 + ct * (v34 + v35 * ct))))) \\\n        + p * (v37 + ct * (v38 + ct * (v39 + v40 * ct)) + sa * (v41 + v42 * ct) + p * (v43 + ct * (v44 + v45 * ct + v46 * sa)\n                                                                                       + p * (v47 + v48 * ct)))\n\n    dvhatden_dsa = b01 + ct * (b02 + b03 * ct) + sqrtsa * (b04 + ct * (b05 + ct * (b06 + b07 * ct))) \\\n        + p * (b08 + b09 * ct + b10 * p)\n\n    dvhatnum_dsa = b11 + ct * (b12 + ct * (b13 + ct * (b14 + b15 * ct))) \\\n        + sqrtsa * (b16 + ct * (b17 + ct * (b18 + ct * (b19 + b20 * ct)))) \\\n        + b21 * sa + p * (b22 + ct * (b23 + b24 * p))\n\n    rec_num = 1.0 / v_hat_numerator\n    rho = rec_num * v_hat_denominator\n    return (dvhatden_dsa - dvhatnum_dsa * rho) * rec_num\n\n\n@veros_method\ndef gsw_drhodP(vs, sa, ct, p):\n    """"""\n     d/dp of density\n     sa     : Absolute Salinity                               [g/kg]\n     ct     : Conservative Temperature                        [deg C]\n     p      : sea pressure                                    [dbar]\n    ==========================================================================\n    """"""\n    p = np.asarray(p)  # convert scalar value if necessary\n    c01 = -2.233269627352527e-2\n    c02 = -3.436090079851880e-4\n    c03 = 3.726050720345733e-6\n    c04 = -1.806789763745328e-4\n    c05 = 6.876837219536232e-7\n    c06 = -6.174065000748422e-7\n    c07 = -3.976733175851186e-8\n    c08 = -2.123038140592916e-11\n    c09 = 3.101865458440160e-10\n    c10 = -2.742185394906099e-5\n    c11 = -3.212746477974189e-7\n    c12 = 3.191413910561627e-9\n    c13 = -1.931012931541776e-12\n    c14 = -1.105097577149576e-7\n    c15 = 6.211426728363857e-10\n    c16 = -2.238023185750219e-10\n    c17 = -3.883320426297450e-11\n    c18 = -3.729652850731201e-14\n    c19 = 2.239044689758956e-14\n    c20 = -3.601523245654798e-15\n    c21 = 1.817370746264060e-16\n    pa2db = 1e-4\n\n    sqrtsa = np.sqrt(sa)\n    v_hat_denominator = v01 + ct * (v02 + ct * (v03 + v04 * ct)) + sa * (v05 + ct * (v06 + v07 * ct)\n                                                                         + sqrtsa * (v08 + ct * (v09 + ct * (v10 + v11 * ct)))) + p * (v12 + ct * (v13 + v14 * ct) + sa * (v15 + v16 * ct)\n                                                                                                                                       + p * (v17 + ct * (v18 + v19 * ct) + v20 * sa))\n\n    v_hat_numerator = v21 + ct * (v22 + ct * (v23 + ct * (v24 + v25 * ct))) \\\n        + sa * (v26 + ct * (v27 + ct * (v28 + ct * (v29 + v30 * ct))) + v36 * sa\n                + sqrtsa * (v31 + ct * (v32 + ct * (v33 + ct * (v34 + v35 * ct)))))   \\\n        + p * (v37 + ct * (v38 + ct * (v39 + v40 * ct)) + sa * (v41 + v42 * ct) + p * (v43 + ct * (v44 + v45 * ct + v46 * sa)\n                                                                                       + p * (v47 + v48 * ct)))\n\n    dvhatden_dp = c01 + ct * (c02 + c03 * ct) + sa * (c04 + c05 * ct) + \\\n        p * (c06 + ct * (c07 + c08 * ct) + c09 * sa)\n\n    dvhatnum_dp = c10 + ct * (c11 + ct * (c12 + c13 * ct)) \\\n        + sa * (c14 + c15 * ct) + p * (c16 + ct * (c17 + c18 * ct + c19 * sa) + p * (c20 + c21 * ct))\n\n    rec_num = 1.0 / v_hat_numerator\n    rho = rec_num * v_hat_denominator\n    return pa2db * (dvhatden_dp - dvhatnum_dp * rho) * rec_num\n\n\n@veros_method\ndef gsw_dyn_enthalpy(vs, sa, ct, p):\n    """"""\n     Calculates dynamic enthalpy of seawater using the computationally\n     efficient 48-term expression for density in terms of SA, CT and p\n     (IOC et al., 2010)\n\n     A component due to the constant reference density in Boussinesq\n     approximation is removed\n\n     sa     : Absolute Salinity                               [g/kg]\n     ct     : Conservative Temperature                        [deg C]\n     p      : sea pressure                                    [dbar]\n    ==========================================================================\n    """"""\n    p = np.asarray(p)  # convert scalar value if necessary\n    db2pa = 1e4                             # factor to convert from dbar to Pa\n    sqrtsa = np.sqrt(sa)\n    a0 = v21 + ct * (v22 + ct * (v23 + ct * (v24 + v25 * ct))) \\\n        + sa * (v26 + ct * (v27 + ct * (v28 + ct * (v29 + v30 * ct))) + v36 * sa\n                + sqrtsa * (v31 + ct * (v32 + ct * (v33 + ct * (v34 + v35 * ct)))))\n    a1 = v37 + ct * (v38 + ct * (v39 + v40 * ct)) + sa * (v41 + v42 * ct)\n    a2 = v43 + ct * (v44 + v45 * ct + v46 * sa)\n    a3 = v47 + v48 * ct\n    b0 = v01 + ct * (v02 + ct * (v03 + v04 * ct)) + sa * (v05 + ct * (v06 + v07 * ct)\n                                                          + sqrtsa * (v08 + ct * (v09 + ct * (v10 + v11 * ct))))\n    b1 = 0.5 * (v12 + ct * (v13 + v14 * ct) + sa * (v15 + v16 * ct))\n    b2 = v17 + ct * (v18 + v19 * ct) + v20 * sa\n    b1sq = b1 * b1\n    sqrt_disc = np.sqrt(b1sq - b0 * b2)\n    cn = a0 + (2 * a3 * b0 * b1 / b2 - a2 * b0) / b2\n    cm = a1 + (4 * a3 * b1sq / b2 - a3 * b0 - 2 * a2 * b1) / b2\n    ca = b1 - sqrt_disc\n    cb = b1 + sqrt_disc\n    part = (cn * b2 - cm * b1) / (b2 * (cb - ca))\n    Hd = db2pa * (p * (a2 - 2.0 * a3 * b1 / b2 + 0.5 * a3 * p) / b2 + (cm / (2.0 * b2)) * np.log(1.0 + p * (2.0 * b1 + b2 * p) / b0)\n                  + part * np.log(1.0 + (b2 * p * (cb - ca)) / (ca * (cb + b2 * p))))\n    return Hd - p * db2pa / rho0\n\n\n@veros_method\ndef gsw_dHdT1(vs, sa, ct, p):\n    """"""\n     d/dT of dynamic enthalpy, numerical derivative\n\n     sa     : Absolute Salinity                               [g/kg]\n     ct     : Conservative Temperature                        [deg C]\n     p      : sea pressure                                    [dbar]\n    ==========================================================================\n    """"""\n    p = np.asarray(p)  # convert scalar value if necessary\n    delta = 1e-4\n    return (gsw_dyn_enthalpy(sa, ct + delta, p) - gsw_dyn_enthalpy(sa, ct, p)) / delta\n\n\n@veros_method\ndef gsw_dHdS1(vs, sa, ct, p):\n    """"""\n     d/dS of dynamic enthalpy, numerical derivative\n\n     sa     : Absolute Salinity                               [g/kg]\n     ct     : Conservative Temperature                        [deg C]\n     p      : sea pressure                                    [dbar]\n    ==========================================================================\n    """"""\n    p = np.asarray(p)  # convert scalar value if necessary\n    delta = 1e-4\n    return (gsw_dyn_enthalpy(sa + delta, ct, p) - gsw_dyn_enthalpy(sa, ct, p)) / delta\n\n\n@veros_method\ndef gsw_dHdT(vs, sa_in, ct_in, p):\n    """"""\n    d/dT of dynamic enthalpy, analytical derivative\n\n    sa     : Absolute Salinity                               [g/kg]\n    ct     : Conservative Temperature                        [deg C]\n    p      : sea pressure                                    [dbar]\n    """"""\n    p = np.asarray(p)  # convert scalar value if necessary\n    sa = np.maximum(1e-1, sa_in)  # prevent division by zero\n    ct = np.maximum(-12, ct_in)  # prevent blowing up for values smaller than -15 degC\n    t1 = v45 * ct\n    t2 = 0.2e1 * t1\n    t3 = v46 * sa\n    t4 = 0.5 * v12\n    t5 = v14 * ct\n    t7 = ct * (v13 + t5)\n    t8 = 0.5 * t7\n    t11 = sa * (v15 + v16 * ct)\n    t12 = 0.5 * t11\n    t13 = t4 + t8 + t12\n    t15 = v19 * ct\n    t19 = v17 + ct * (v18 + t15) + v20 * sa\n    t20 = 1.0 / t19\n    t24 = v47 + v48 * ct\n    t25 = 0.5 * v13\n    t26 = 1.0 * t5\n    t27 = sa * v16\n    t28 = 0.5 * t27\n    t29 = t25 + t26 + t28\n    t33 = t24 * t13\n    t34 = t19 ** 2\n    t35 = 1.0 / t34\n    t37 = v18 + 2.0 * t15\n    t38 = t35 * t37\n    t48 = ct * (v44 + t1 + t3)\n    t57 = v40 * ct\n    t59 = ct * (v39 + t57)\n    t64 = t13 ** 2\n    t68 = t20 * t29\n    t71 = t24 * t64\n    t74 = v04 * ct\n    t76 = ct * (v03 + t74)\n    t79 = v07 * ct\n    t82 = np.sqrt(sa)\n    t83 = v11 * ct\n    t85 = ct * (v10 + t83)\n    t92 = v01 + ct * (v02 + t76) + sa * (v05 + ct * (v06 + t79) + t82 * (v08 + ct * (v09 + t85)))\n    t93 = v48 * t92\n    t105 = v02 + t76 + ct * (v03 + 2.0 * t74) + sa * (v06 + 2.0 * t79 +\n                                                    t82 * (v09 + t85 + ct * (v10 + 2.0 * t83)))\n    t106 = t24 * t105\n    t107 = v44 + t2 + t3\n    t110 = v43 + t48\n    t117 = t24 * t92\n    t120 = 4.0 * t71 * t20 - t117 - 2.0 * t110 * t13\n    t123 = v38 + t59 + ct * (v39 + 2.0 * t57) + sa * v42 + (4.0 *\n                                                            v48 * t64 * t20 + 8.0 * t33 * t68 - 4.0 * t71 * t38 - t93 - t106\n                                                            - 2.0 * t107 * t13 - 2.0 * t110 * t29) * t20 - t120 * t35 * t37\n    t128 = t19 * p\n    t130 = p * (1.0 * v12 + 1.0 * t7 + 1.0 * t11 + t128)\n    t131 = 1.0 / t92\n    t133 = 1.0 + t130 * t131\n    t134 = np.log(t133)\n    t143 = v37 + ct * (v38 + t59) + sa * (v41 + v42 * ct) + t120 * t20\n    t152 = t37 * p\n    t156 = t92 ** 2\n    t165 = v25 * ct\n    t167 = ct * (v24 + t165)\n    t169 = ct * (v23 + t167)\n    t175 = v30 * ct\n    t177 = ct * (v29 + t175)\n    t179 = ct * (v28 + t177)\n    t185 = v35 * ct\n    t187 = ct * (v34 + t185)\n    t189 = ct * (v33 + t187)\n    t199 = t13 * t20\n    t217 = 2.0 * t117 * t199 - t110 * t92\n    t234 = v21 + ct * (v22 + t169) + sa * (v26 + ct * (v27 + t179) + v36 *\n                                        sa + t82 * (v31 + ct * (v32 + t189))) + t217 * t20\n    t241 = t64 - t92 * t19\n    t242 = np.sqrt(t241)\n    t243 = 1.0 / t242\n    t244 = t4 + t8 + t12 - t242\n    t245 = 1.0 / t244\n    t247 = t4 + t8 + t12 + t242 + t128\n    t248 = 1.0 / t247\n    t249 = t242 * t245 * t248\n    t252 = 1.0 + 2.0 * t128 * t249\n    t253 = np.log(t252)\n    t254 = t243 * t253\n    t259 = t234 * t19 - t143 * t13\n    t264 = t259 * t20\n    t272 = 2.0 * t13 * t29 - t105 * t19 - t92 * t37\n    t282 = t128 * t242\n    t283 = t244 ** 2\n    t287 = t243 * t272 / 2.0\n    t292 = t247 ** 2\n    t305 = 0.1e5 * p * (v44 + t2 + t3 - 2.0 * v48 * t13 * t20\n                        - 2.0 * t24 * t29 * t20 + 2.0 * t33 * t38 + 0.5 * v48 * p) * t20  \\\n        - 0.1e5 * p * (v43 + t48 - 2.0 * t33 * t20 + 0.5 * t24 * p) * t38 \\\n        + 0.5e4 * t123 * t20 * t134 - 0.5e4 * t143 * t35 * t134 * t37 \\\n        + 0.5e4 * t143 * t20 * (p * (1.0 * v13 + 2.0 * t5 + 1.0 * t27 + t152) * t131\n                                - t130 / t156 * t105) / t133 \\\n        + 0.5e4 * ((v22 + t169 + ct * (v23 + t167 + ct * (v24 + 2.0 * t165))\n                    + sa * (v27 + t179 + ct * (v28 + t177 + ct * (v29 + 2.0 * t175)) + t82 * (v32 + t189\n                                                                                            + ct * (v33 + t187 + ct * (v34 + 2.0 * t185)))) + (2.0 * t93 * t199 + 2.0 * t106 *\n                                                                                                                                                t199 + 2.0 * t117 * t68 - 2.0 * t117 * t13 * t35 * t37 - t107\n                                                                                                                                                * t92 - t110 * t105) * t20 - t217 * t35 * t37) * t19 + t234 * t37\n                - t123 * t13 - t143 * t29) * t20 * t254 - 0.5e4 * t259 * \\\n        t35 * t254 * t37 - 0.25e4 * t264 / t242 / t241 * t253 * t272 \\\n        + 0.5e4 * t264 * t243 * (2.0 * t152 * t249 + t128 *\n                                t243 * t245 * t248 * t272 - 2.0 * t282 /\n                                t283 * t248 * (t25 + t26 + t28 - t287)\n                                - 2.0 * t282 * t245 / t292 * (t25 + t26 + t28 + t287 + t152)) / t252\n\n    return t305\n\n\n@veros_method\ndef gsw_dHdS(vs, sa_in, ct_in, p):\n    """"""\n    d/dS of dynamic enthalpy, analytical derivative\n    sa     : Absolute Salinity                               [g/kg]\n    ct     : Conservative Temperature                        [deg C]\n    p      : sea pressure                                    [dbar]\n    """"""\n    p = np.asarray(p)  # convert scalar value if necessary\n    sa = np.maximum(1e-1, sa_in)  # prevent division by zero\n    ct = np.maximum(-12.0, ct_in)  # prevent blowing up for values smaller than -15 degC\n    t1 = ct * v46\n    t3 = v47 + v48 * ct\n    t4 = 0.5 * v15\n    t5 = v16 * ct\n    t6 = 0.5 * t5\n    t7 = t4 + t6\n    t13 = v17 + ct * (v18 + v19 * ct) + v20 * sa\n    t14 = 1.0 / t13\n    t17 = 0.5 * v12\n    t20 = ct * (v13 + v14 * ct)\n    t21 = 0.5 * t20\n    t23 = sa * (v15 + t5)\n    t24 = 0.5 * t23\n    t25 = t17 + t21 + t24\n    t26 = t3 * t25\n    t27 = t13 ** 2\n    t28 = 1.0 / t27\n    t29 = t28 * v20\n    t39 = ct * (v44 + v45 * ct + v46 * sa)\n    t48 = v42 * ct\n    t49 = t14 * t7\n    t52 = t25 ** 2\n    t53 = t3 * t52\n    t58 = ct * (v06 + v07 * ct)\n    t59 = np.sqrt(sa)\n    t66 = t59 * (v08 + ct * (v09 + ct * (v10 + v11 * ct)))\n    t68 = v05 + t58 + 3.0 / 2.0 * t66\n    t69 = t3 * t68\n    t72 = v43 + t39\n    t86 = v01 + ct * (v02 + ct * (v03 + v04 * ct)) + sa * (v05 + t58 + t66)\n    t87 = t3 * t86\n    t90 = 4.0 * t53 * t14 - t87 - 2.0 * t72 * t25\n    t93 = v41 + t48 + (8.0 * t26 * t49 - 4.0 * t53 * t29 - t69 - 2.0 *\n                       t1 * t25 - 2.0 * t72 * t7) * t14 - t90 * t28 * v20\n    t98 = t13 * p\n    t100 = p * (1.0 * v12 + 1.0 * t20 + 1.0 * t23 + t98)\n    t101 = 1.0 / t86\n    t103 = 1.0 + t100 * t101\n    t104 = np.log(t103)\n    t115 = v37 + ct * (v38 + ct * (v39 + v40 * ct)) + sa * (v41 + t48) + t90 * t14\n    t123 = v20 * p\n    t127 = t86 ** 2\n    t142 = ct * (v27 + ct * (v28 + ct * (v29 + v30 * ct)))\n    t143 = v36 * sa\n    t151 = v31 + ct * (v32 + ct * (v33 + ct * (v34 + v35 * ct)))\n    t152 = t59 * t151\n    t158 = t25 * t14\n    t174 = 2.0 * t87 * t158 - t72 * t86\n    t189 = v21 + ct * (v22 + ct * (v23 + ct * (v24 + v25 * ct))) + \\\n        sa * (v26 + t142 + t143 + t152) + t174 * t14\n    t196 = t52 - t86 * t13\n    t197 = np.sqrt(t196)\n    t198 = 1.0 / t197\n    t199 = t17 + t21 + t24 - t197\n    t200 = 1.0 / t199\n    t202 = t17 + t21 + t24 + t197 + t98\n    t203 = 1.0 / t202\n    t204 = t197 * t200 * t203\n    t207 = 1.0 + 2.0 * t98 * t204\n    t208 = np.log(t207)\n    t209 = t198 * t208\n    t214 = t189 * t13 - t115 * t25\n    t219 = t214 * t14\n    t227 = 2.0 * t25 * t7 - t68 * t13 - t86 * v20\n    t237 = t98 * t197\n    t238 = t199 ** 2\n    t242 = t198 * t227 / 2.0\n    t247 = t202 ** 2\n    t260 = 0.1e5 * p * (t1 - 2.0 * t3 * t7 * t14 + 2.0 * t26 * t29) * t14 \\\n        - 0.1e5 * p * (v43 + t39 - 2.0 * t26 * t14 + 0.5 * t3 * p) * t29 \\\n        + 0.5e4 * t93 * t14 * t104 - 0.5e4 * t115 * t28 * t104 * v20 \\\n        + 0.5e4 * t115 * t14 * (p * (1.0 * v15 + 1.0 * t5 + t123) * t101 - t100 / t127 * t68) / t103 \\\n        + 0.5e4 * ((v26 + t142 + t143 + t152 + sa * (v36 + 1.0 / t59 * t151 / 2.0)\n                    + (2.0 * t69 * t158 + 2.0 * t87 * t49 - 2.0 * t87 *\n                       t25 * t28 * v20 - t1 * t86 - t72 * t68) * t14\n                    - t174 * t28 * v20) * t13 + t189 * v20 - t93 * t25 - t115 * t7) * t14 * t209 - 0.5e4 * t214 * t28 * t209 * v20 \\\n        - 0.25e4 * t219 / t197 / t196 * t208 * t227 + 0.5e4 * t219 * t198 * (2.0 * t123 * t204\n                                                                             + t98 * t198 * t200 * t203 * t227 - 2.0 *\n                                                                             t237 / t238 * t203 *\n                                                                             (t4 + t6 - t242)\n                                                                             - 2.0 * t237 * t200 / t247 * (t4 + t6 + t242 + t123)) / t207\n    return t260\n'"
veros/core/density/linear_eq.py,0,"b'""""""\n==========================================================================\n  linear equation of state\n  input is Salinity sa in g/kg,\n  pot. temperature ct in deg C\n==========================================================================\n""""""\nrho0 = 1024.0\ntheta0 = 283.0 - 273.15\nS0 = 35.0\nbetaT = 1.67e-4\nbetaS = 0.78e-3\ngrav = 9.81\nz0 = 0.0\n\n\ndef linear_eq_of_state_rho(sa, ct):\n    return - (betaT * (ct - theta0) - betaS * (sa - S0)) * rho0\n\n\ndef linear_eq_of_state_dyn_enthalpy(sa, ct, p):\n    zz = -p - z0\n    thetas = ct - theta0\n    return grav * zz * (-betaT * thetas + betaS * (sa - S0))\n\n\ndef linear_eq_of_state_salt(rho, ct):\n    return (rho + betaT * (ct - theta0) * rho0) / (betaS * rho0) + S0\n\n\ndef linear_eq_of_state_drhodT():\n    return - betaT * rho0\n\n\ndef linear_eq_of_state_drhodS():\n    return betaS * rho0\n\n\ndef linear_eq_of_state_drhodp():\n    return 0.0\n'"
veros/core/density/nonlinear_eq1.py,0,"b'""""""\n==========================================================================\n  non-linear equation of state from Vallis 2008\n  input is Salinity sa in g/kg,\n  pot. temperature ct in deg C, no pressure dependency\n==========================================================================\n""""""\nrho0 = 1024.0\ntheta0 = 283.0 - 273.15\nS0 = 35.0\nbetaT = 1.67e-4\nbetaTs = 1e-5 / 2.\nbetaS = 0.78e-3\ngrav = 9.81\nz0 = 0.0\n\n\ndef nonlin1_eq_of_state_rho(sa, ct):\n    thetas = ct - theta0\n    return - (betaT * thetas + betaTs * thetas**2 - betaS * (sa - S0)) * rho0\n\n\ndef nonlin1_eq_of_state_dyn_enthalpy(sa, ct, p):\n    zz = -p - z0\n    thetas = ct - theta0\n    return grav * zz * (-betaT * thetas - betaTs * thetas**2 + betaS * (sa - S0))\n\n\ndef nonlin1_eq_of_state_salt(rho, ct):\n    thetas = ct - theta0\n    return (rho + (betaT * thetas + betaTs * thetas**2) * rho0) / (betaS * rho0) + S0\n\n\ndef nonlin1_eq_of_state_drhodT(ct):\n    thetas = ct - theta0\n    return - (betaT + 2 * betaTs * thetas) * rho0\n\n\ndef nonlin1_eq_of_state_drhodS():\n    return betaS * rho0\n\n\ndef nonlin1_eq_of_state_drhodp():\n    return 0.0\n'"
veros/core/density/nonlinear_eq2.py,0,"b'""""""\n==========================================================================\n  non-linear equation of state from Vallis 2008\n  input is Salinity sa in g/kg,\n  pot. temperature ct in deg C and\n  pressure p in dbar\n==========================================================================\n""""""\nrho0 = 1024.0\nz0 = 0.0\ntheta0 = 283.0 - 273.15\nS0 = 35.0\ngrav = 9.81\ncs0 = 1490.0\nbetaT = 1.67e-4\nbetaTs = 1e-5\nbetaS = 0.78e-3\ngammas = 1.1e-8\n\n\ndef nonlin2_eq_of_state_rho(sa, ct, p):\n    zz = -p - z0\n    thetas = ct - theta0\n    return -(grav * zz / cs0**2 + betaT * (1 - gammas * grav * zz * rho0) * thetas + betaTs / 2 * thetas**2 - betaS * (sa - S0)) * rho0\n\n\ndef nonlin2_eq_of_state_dyn_enthalpy(sa, ct, p):\n    zz = -p - z0\n    thetas = ct - theta0\n    return grav * 0.5 * zz**2 * (-grav / cs0**2 + betaT * grav * rho0 * gammas * thetas) + grav * zz * (-betaT * thetas - betaTs * thetas**2 + betaS * (sa - S0))\n\n\ndef nonlin2_eq_of_state_salt(rho, ct, p):\n    zz = -p - z0\n    thetas = ct - theta0\n    return (rho / rho0 + (grav * zz / cs0**2 + betaT * (1 - gammas * grav * zz * rho0) * thetas + betaTs / 2 * thetas**2)) / betaS + S0\n\n\ndef nonlin2_eq_of_state_drhodT(ct, p):\n    zz = -p - z0\n    thetas = ct - theta0\n    return -(betaTs * thetas + betaT * (1 - gammas * grav * zz * rho0)) * rho0\n\n\ndef nonlin2_eq_of_state_drhodS():\n    return betaS * rho0\n\n\ndef nonlin2_eq_of_state_drhodP(ct):\n    thetas = ct - theta0\n    return 1 / cs0**2 - betaT * gammas * rho0 * thetas\n\n\ndef nonlin2_eq_of_state_int_drhodT(ct, p):\n    zz = -p - z0\n    thetas = ct - theta0\n    return rho0 * zz * (betaT + betaTs * thetas) - rho0 * betaT * gammas * grav * rho0 * zz**2 / 2\n\n\ndef nonlin2_eq_of_state_int_drhodS(p):\n    zz = -p - z0\n    return -betaS * rho0 * zz\n'"
veros/core/density/nonlinear_eq3.py,0,"b'""""""\n==========================================================================\n  non-linear equation of state, no salinity dependency\n  input is Salinity sa in g/kg,\n  pot. temperature ct in deg C ,  no pressure dependency\n==========================================================================\n""""""\nrho0 = 1024.0\ntheta0 = 283.0 - 273.15\nS0 = 35.0\nbetaT = 1.67e-4\nbetaTs = 1e-5 / 2.\nbetaS = 0\ngrav = 9.81\nz0 = 0.0\n\n\ndef nonlin3_eq_of_state_rho(sa, ct):\n    thetas = ct - theta0\n    return - (betaT * thetas + betaTs * thetas**2 - betaS * (sa - S0)) * rho0\n\n\ndef nonlin3_eq_of_state_dyn_enthalpy(sa, ct, p):\n    zz = -p - z0\n    thetas = ct - theta0\n    return grav * zz * (-betaT * thetas - betaTs * thetas**2 + betaS * (sa - S0))\n\n\ndef nonlin3_eq_of_state_salt(rho, ct):\n    thetas = ct - theta0\n    return (rho + (betaT * thetas + betaTs * thetas**2) * rho0) / (betaS * rho0) + S0\n\n\ndef nonlin3_eq_of_state_drhodT(ct):\n    thetas = ct - theta0\n    return - (betaT + 2 * betaTs * thetas) * rho0\n\n\ndef nonlin3_eq_of_state_drhodS():\n    return betaS * rho0\n\n\ndef nonlin3_eq_of_state_drhodp():\n    return 0.0\n'"
veros/core/isoneutral/__init__.py,0,b'from .diffusion import *\nfrom .friction import *\nfrom .isoneutral import *\n'
veros/core/isoneutral/diffusion.py,21,"b'from ... import veros_method\nfrom .. import utilities, diffusion\nfrom ...variables import allocate\n\n\n@veros_method\ndef _calc_tracer_fluxes(vs, tr, K_iso, K_skew):\n    tr_pad = utilities.pad_z_edges(vs, tr[..., vs.tau])\n\n    K1 = K_iso - K_skew\n    K2 = K_iso + K_skew\n\n    """"""\n    construct total isoneutral tracer flux at east face of \'T\' cells\n    """"""\n    diffloc = allocate(vs, (\'xt\', \'yt\', \'zt\'))[1:-2, 2:-2]\n    diffloc[:, :, 1:] = 0.25 * (K1[1:-2, 2:-2, 1:] + K1[1:-2, 2:-2, :-1] +\n                                K1[2:-1, 2:-2, 1:] + K1[2:-1, 2:-2, :-1])\n    diffloc[:, :, 0] = 0.5 * (K1[1:-2, 2:-2, 0] + K1[2:-1, 2:-2, 0])\n    sumz = allocate(vs, (\'xt\', \'yt\', \'zt\'))[1:-2, 2:-2]\n    for kr in range(2):\n        for ip in range(2):\n            sumz += diffloc * vs.Ai_ez[1:-2, 2:-2, :, ip, kr] * (\n                tr_pad[1 + ip:-2 + ip, 2:-2, 1 + kr:-1 + kr or None] - tr_pad[1 + ip:-2 + ip, 2:-2, kr:-2 + kr])\n    vs.flux_east[1:-2, 2:-2, :] = sumz / (4. * vs.dzt[np.newaxis, np.newaxis, :]) + (tr[2:-1, 2:-2, :, vs.tau] - tr[1:-2, 2:-2, :, vs.tau]) \\\n                                / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxu[1:-2, np.newaxis, np.newaxis]) * vs.K_11[1:-2, 2:-2, :]\n\n    """"""\n    construct total isoneutral tracer flux at north face of \'T\' cells\n    """"""\n    diffloc = allocate(vs, (\'xt\', \'yt\', \'zt\'))[2:-2, 1:-2]\n    diffloc[:, :, 1:] = 0.25 * (K1[2:-2, 1:-2, 1:] + K1[2:-2, 1:-2, :-1] +\n                                K1[2:-2, 2:-1, 1:] + K1[2:-2, 2:-1, :-1])\n    diffloc[:, :, 0] = 0.5 * (K1[2:-2, 1:-2, 0] + K1[2:-2, 2:-1, 0])\n    sumz = allocate(vs, (\'xt\', \'yt\', \'zt\'))[2:-2, 1:-2]\n    for kr in range(2):\n        for jp in range(2):\n            sumz += diffloc * vs.Ai_nz[2:-2, 1:-2, :, jp, kr] * (\n                tr_pad[2:-2, 1 + jp:-2 + jp, 1 + kr:-1 + kr or None] - tr_pad[2:-2, 1 + jp:-2 + jp, kr:-2 + kr])\n    vs.flux_north[2:-2, 1:-2, :] = vs.cosu[np.newaxis, 1:-2, np.newaxis] * (sumz / (4. * vs.dzt[np.newaxis, np.newaxis, :]) \\\n                                + (tr[2:-2, 2:-1, :, vs.tau] - tr[2:-2, 1:-2, :, vs.tau]) / vs.dyu[np.newaxis, 1:-2, np.newaxis] * vs.K_22[2:-2, 1:-2, :])\n\n    """"""\n    compute the vertical tracer flux \'vs.flux_top\' containing the K31\n    and K32 components which are to be solved explicitly. The K33\n    component will be treated implicitly. Note that there are some\n    cancellations of dxu(i-1+ip) and dyu(jrow-1+jp)\n    """"""\n    diffloc = K2[2:-2, 2:-2, :-1]\n    sumx = 0.\n    for ip in range(2):\n        for kr in range(2):\n            sumx += diffloc * vs.Ai_bx[2:-2, 2:-2, :-1, ip, kr] / vs.cost[np.newaxis, 2:-2, np.newaxis] \\\n                * (tr[2 + ip:-2 + ip, 2:-2, kr:-1 + kr or None, vs.tau] - tr[1 + ip:-3 + ip, 2:-2, kr:-1 + kr or None, vs.tau])\n    sumy = 0.\n    for jp in range(2):\n        for kr in range(2):\n            sumy += diffloc * vs.Ai_by[2:-2, 2:-2, :-1, jp, kr] * vs.cosu[np.newaxis, 1 + jp:-3 + jp, np.newaxis] \\\n                * (tr[2:-2, 2 + jp:-2 + jp, kr:-1 + kr or None, vs.tau] - tr[2:-2, 1 + jp:-3 + jp, kr:-1 + kr or None, vs.tau])\n    vs.flux_top[2:-2, 2:-2, :-1] = sumx / (4 * vs.dxt[2:-2, np.newaxis, np.newaxis]) \\\n                                 + sumy / (4 * vs.dyt[np.newaxis, 2:-2, np.newaxis] * vs.cost[np.newaxis, 2:-2, np.newaxis])\n    vs.flux_top[:, :, -1] = 0.\n\n\n@veros_method\ndef _calc_explicit_part(vs):\n    aloc = allocate(vs, (\'xt\', \'yt\', \'zt\'))\n    aloc[2:-2, 2:-2, :] = vs.maskT[2:-2, 2:-2, :] * ((vs.flux_east[2:-2, 2:-2, :] - vs.flux_east[1:-3, 2:-2, :]) / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis])\n                                                   + (vs.flux_north[2:-2, 2:-2, :] - vs.flux_north[2:-2, 1:-3, :]) / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dyt[np.newaxis, 2:-2, np.newaxis]))\n    aloc[:, :, 0] += vs.maskT[:, :, 0] * vs.flux_top[:, :, 0] / vs.dzt[0]\n    aloc[:, :, 1:] += vs.maskT[:, :, 1:] * \\\n        (vs.flux_top[:, :, 1:] - vs.flux_top[:, :, :-1]) / \\\n        vs.dzt[np.newaxis, np.newaxis, 1:]\n    return aloc\n\n\n@veros_method\ndef _calc_implicit_part(vs, tr):\n    ks = vs.kbot[2:-2, 2:-2] - 1\n\n    a_tri = allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False)\n    b_tri = allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False)\n    c_tri = allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False)\n    delta = allocate(vs, (\'xt\', \'yt\', \'zt\'), include_ghosts=False)\n\n    delta[:, :, :-1] = vs.dt_tracer / vs.dzw[np.newaxis, np.newaxis, :-1] * vs.K_33[2:-2, 2:-2, :-1]\n    delta[:, :, -1] = 0.\n    a_tri[:, :, 1:] = -delta[:, :, :-1] / vs.dzt[np.newaxis, np.newaxis, 1:]\n    b_tri[:, :, 1:-1] = 1 + (delta[:, :, 1:-1] + delta[:, :, :-2]) \\\n                        / vs.dzt[np.newaxis, np.newaxis, 1:-1]\n    b_tri[:, :, -1] = 1 + delta[:, :, -2] / vs.dzt[np.newaxis, np.newaxis, -1]\n    b_tri_edge = 1 + (delta[:, :, :] / vs.dzt[np.newaxis, np.newaxis, :])\n    c_tri[:, :, :-1] = -delta[:, :, :-1] / vs.dzt[np.newaxis, np.newaxis, :-1]\n    sol, water_mask = utilities.solve_implicit(\n        vs, ks, a_tri, b_tri, c_tri, tr[2:-2, 2:-2, :, vs.taup1], b_edge=b_tri_edge\n    )\n    tr[2:-2, 2:-2, :, vs.taup1] = utilities.where(vs, water_mask, sol, tr[2:-2, 2:-2, :, vs.taup1])\n\n\n@veros_method\ndef isoneutral_diffusion_tracer(vs, tr, dtracer_iso, iso=True, skew=False):\n    """"""\n    Isoneutral diffusion for general tracers\n    """"""\n    if iso:\n        K_iso = vs.K_iso\n    else:\n        K_iso = np.zeros_like(vs.K_iso)\n    if skew:\n        K_skew = vs.K_gm\n    else:\n        K_skew = np.zeros_like(vs.K_gm)\n\n    _calc_tracer_fluxes(vs, tr, K_iso, K_skew)\n\n    """"""\n    add explicit part\n    """"""\n    aloc = _calc_explicit_part(vs)\n    dtracer_iso[...] += aloc[...]\n    tr[2:-2, 2:-2, :, vs.taup1] += vs.dt_tracer * aloc[2:-2, 2:-2, :]\n\n    """"""\n    add implicit part\n    """"""\n    if iso:\n        aloc[...] = tr[:, :, :, vs.taup1]\n        _calc_implicit_part(vs, tr)\n        dtracer_iso[...] += (tr[:, :, :, vs.taup1] - aloc) / vs.dt_tracer\n\n\n@veros_method\ndef isoneutral_diffusion(vs, tr, istemp, iso=True, skew=False):\n    """"""\n    Isopycnal diffusion for tracer,\n    following functional formulation by Griffies et al\n    Dissipation is calculated and stored in P_diss_iso\n    T/S changes are added to dtemp_iso/dsalt_iso\n    """"""\n    if istemp:\n        dtracer_iso = vs.dtemp_iso\n    else:\n        dtracer_iso = vs.dsalt_iso\n\n    isoneutral_diffusion_tracer(vs, tr, dtracer_iso, iso=iso, skew=skew)\n\n    """"""\n    dissipation by isopycnal mixing\n    """"""\n    if vs.enable_conserve_energy:\n        if istemp:\n            int_drhodX = vs.int_drhodT[:, :, :, vs.tau]\n        else:\n            int_drhodX = vs.int_drhodS[:, :, :, vs.tau]\n\n        """"""\n        dissipation interpolated on W-grid\n        """"""\n        if not iso:\n            diffusion.dissipation_on_wgrid(vs, vs.P_diss_skew, int_drhodX=int_drhodX)\n        else:\n            diffusion.dissipation_on_wgrid(vs, vs.P_diss_iso, int_drhodX=int_drhodX)\n\n        """"""\n        diagnose dissipation of dynamic enthalpy by explicit and implicit vertical mixing\n        """"""\n        fxa = (-int_drhodX[2:-2, 2:-2, 1:] + int_drhodX[2:-2, 2:-2, :-1]) / \\\n            vs.dzw[np.newaxis, np.newaxis, :-1]\n        tracer = vs.temp if istemp else vs.salt\n        if not iso:\n            vs.P_diss_skew[2:-2, 2:-2, :-1] += - vs.grav / vs.rho_0 * \\\n                fxa * vs.flux_top[2:-2, 2:-2, :-1] * vs.maskW[2:-2, 2:-2, :-1]\n        else:\n            vs.P_diss_iso[2:-2, 2:-2, :-1] += - vs.grav / vs.rho_0 * fxa * vs.flux_top[2:-2, 2:-2, :-1] * vs.maskW[2:-2, 2:-2, :-1] \\\n                - vs.grav / vs.rho_0 * fxa * vs.K_33[2:-2, 2:-2, :-1] * (tracer[2:-2, 2:-2, 1:, vs.taup1]\n                                                                                  - tracer[2:-2, 2:-2, :-1, vs.taup1]) \\\n                / vs.dzw[np.newaxis, np.newaxis, :-1] * vs.maskW[2:-2, 2:-2, :-1]\n\n\n@veros_method\ndef isoneutral_skew_diffusion(vs, tr, istemp):\n    """"""\n    Isopycnal skew diffusion for tracer,\n    following functional formulation by Griffies et al\n    Dissipation is calculated and stored in vs.P_diss_skew\n    T/S changes are added to dtemp_iso/dsalt_iso\n    """"""\n    isoneutral_diffusion(vs, tr, istemp, skew=True, iso=False)\n\n\n@veros_method\ndef isoneutral_diffusion_all(vs, tr, istemp):\n    """"""\n    Isopycnal diffusion plus skew diffusion for tracer,\n    following functional formulation by Griffies et al\n    Dissipation is calculated and stored in P_diss_iso\n    """"""\n    isoneutral_diffusion(vs, tr, istemp, skew=True, iso=True)\n'"
veros/core/isoneutral/friction.py,18,"b'from ... import veros_method\nfrom ...variables import allocate\nfrom .. import numerics, utilities\n\n\n@veros_method\ndef isoneutral_friction(vs):\n    """"""\n    vertical friction using TEM formalism for eddy driven velocity\n    """"""\n    if vs.enable_implicit_vert_friction:\n        aloc = vs.u[:, :, :, vs.taup1]\n    else:\n        aloc = vs.u[:, :, :, vs.tau]\n\n    # implicit vertical friction of zonal momentum by GM\n    ks = np.maximum(vs.kbot[1:-2, 1:-2], vs.kbot[2:-1, 1:-2]) - 1\n    fxa = 0.5 * (vs.kappa_gm[1:-2, 1:-2, :] + vs.kappa_gm[2:-1, 1:-2, :])\n    delta, a_tri, b_tri, c_tri = (\n        allocate(vs, (\'xu\', \'yt\', \'zt\'))[1:-2, 1:-2]\n        for _ in range(4)\n    )\n    delta[:, :, :-1] = vs.dt_mom / vs.dzw[np.newaxis, np.newaxis, :-1] * \\\n        fxa[:, :, :-1] * vs.maskU[1:-2, 1:-2, 1:] * vs.maskU[1:-2, 1:-2, :-1]\n    delta[-1] = 0.\n    a_tri[:, :, 1:] = -delta[:, :, :-1] / vs.dzt[np.newaxis, np.newaxis, 1:]\n    b_tri_edge = 1 + delta / vs.dzt[np.newaxis, np.newaxis, :]\n    b_tri[:, :, 1:-1] = 1 + delta[:, :, 1:-1] / vs.dzt[np.newaxis, np.newaxis, 1:-1] + \\\n        delta[:, :, :-2] / vs.dzt[np.newaxis, np.newaxis, 1:-1]\n    b_tri[:, :, -1] = 1 + delta[:, :, -2] / vs.dzt[-1]\n    c_tri[...] = - delta / vs.dzt[np.newaxis, np.newaxis, :]\n    sol, water_mask = utilities.solve_implicit(\n        vs, ks, a_tri, b_tri, c_tri, aloc[1:-2, 1:-2, :], b_edge=b_tri_edge\n    )\n    vs.u[1:-2, 1:-2, :, vs.taup1] = utilities.where(vs, water_mask, sol, vs.u[1:-2, 1:-2, :, vs.taup1])\n    vs.du_mix[1:-2, 1:-2, :] += (vs.u[1:-2, 1:-2, :, vs.taup1] \\\n                                - aloc[1:-2, 1:-2, :]) / vs.dt_mom * water_mask\n\n    if vs.enable_conserve_energy:\n        # diagnose dissipation\n        diss = allocate(vs, (\'xu\', \'yt\', \'zt\'))\n        fxa = 0.5 * (vs.kappa_gm[1:-2, 1:-2, :-1] + vs.kappa_gm[2:-1, 1:-2, :-1])\n        vs.flux_top[1:-2, 1:-2, :-1] = fxa * (vs.u[1:-2, 1:-2, 1:, vs.taup1] - vs.u[1:-2, 1:-2, :-1, vs.taup1]) \\\n            / vs.dzw[np.newaxis, np.newaxis, :-1] * vs.maskU[1:-2, 1:-2, 1:] * vs.maskU[1:-2, 1:-2, :-1]\n        diss[1:-2, 1:-2, :-1] = (vs.u[1:-2, 1:-2, 1:, vs.tau] - vs.u[1:-2, 1:-2, :-1, vs.tau]) \\\n            * vs.flux_top[1:-2, 1:-2, :-1] / vs.dzw[np.newaxis, np.newaxis, :-1]\n        diss[:, :, -1] = 0.0\n        diss = numerics.ugrid_to_tgrid(vs, diss)\n        vs.K_diss_gm[...] = diss\n\n    if vs.enable_implicit_vert_friction:\n        aloc = vs.v[:, :, :, vs.taup1]\n    else:\n        aloc = vs.v[:, :, :, vs.tau]\n\n    # implicit vertical friction of zonal momentum by GM\n    ks = np.maximum(vs.kbot[1:-2, 1:-2], vs.kbot[1:-2, 2:-1]) - 1\n    fxa = 0.5 * (vs.kappa_gm[1:-2, 1:-2, :] + vs.kappa_gm[1:-2, 2:-1, :])\n    delta, a_tri, b_tri, c_tri = (allocate(vs, (\'xt\', \'yu\', \'zt\'))[1:-2, 1:-2] for _ in range(4))\n    delta[:, :, :-1] = vs.dt_mom / vs.dzw[np.newaxis, np.newaxis, :-1] * \\\n        fxa[:, :, :-1] * vs.maskV[1:-2, 1:-2, 1:] * vs.maskV[1:-2, 1:-2, :-1]\n    delta[-1] = 0.\n    a_tri[:, :, 1:] = -delta[:, :, :-1] / vs.dzt[np.newaxis, np.newaxis, 1:]\n    b_tri_edge = 1 + delta / vs.dzt[np.newaxis, np.newaxis, :]\n    b_tri[:, :, 1:-1] = 1 + delta[:, :, 1:-1] / vs.dzt[np.newaxis, np.newaxis, 1:-1] + \\\n        delta[:, :, :-2] / vs.dzt[np.newaxis, np.newaxis, 1:-1]\n    b_tri[:, :, -1] = 1 + delta[:, :, -2] / vs.dzt[-1]\n    c_tri[...] = - delta / vs.dzt[np.newaxis, np.newaxis, :]\n    sol, water_mask = utilities.solve_implicit(\n        vs, ks, a_tri, b_tri, c_tri, aloc[1:-2, 1:-2, :], b_edge=b_tri_edge\n    )\n    vs.v[1:-2, 1:-2, :, vs.taup1] = utilities.where(vs, water_mask, sol, vs.v[1:-2, 1:-2, :, vs.taup1])\n    vs.dv_mix[1:-2, 1:-2, :] += (vs.v[1:-2, 1:-2, :, vs.taup1] -\n                                 aloc[1:-2, 1:-2, :]) / vs.dt_mom * water_mask\n\n    if vs.enable_conserve_energy:\n        # diagnose dissipation\n        diss = allocate(vs, (\'xt\', \'yu\', \'zt\'))\n        fxa = 0.5 * (vs.kappa_gm[1:-2, 1:-2, :-1] + vs.kappa_gm[1:-2, 2:-1, :-1])\n        vs.flux_top[1:-2, 1:-2, :-1] = fxa * (vs.v[1:-2, 1:-2, 1:, vs.taup1] - vs.v[1:-2, 1:-2, :-1, vs.taup1]) \\\n            / vs.dzw[np.newaxis, np.newaxis, :-1] * vs.maskV[1:-2, 1:-2, 1:] * vs.maskV[1:-2, 1:-2, :-1]\n        diss[1:-2, 1:-2, :-1] = (vs.v[1:-2, 1:-2, 1:, vs.tau] - vs.v[1:-2, 1:-2, :-1, vs.tau]) \\\n            * vs.flux_top[1:-2, 1:-2, :-1] / vs.dzw[np.newaxis, np.newaxis, :-1]\n        diss[:, :, -1] = 0.0\n        diss = numerics.vgrid_to_tgrid(vs, diss)\n        vs.K_diss_gm += diss\n'"
veros/core/isoneutral/isoneutral.py,29,"b'from loguru import logger\n\nfrom .. import density, utilities\nfrom ... import veros_method\nfrom ...variables import allocate\n\n\n@veros_method\ndef isoneutral_diffusion_pre(vs):\n    """"""\n    Isopycnal diffusion for tracer\n    following functional formulation by Griffies et al\n    Code adopted from MOM2.1\n    """"""\n    epsln = 1e-20\n\n    dTdx = allocate(vs, (\'xu\', \'yt\', \'zt\'))\n    dSdx = allocate(vs, (\'xu\', \'yt\', \'zt\'))\n    dTdy = allocate(vs, (\'xt\', \'yu\', \'zt\'))\n    dSdy = allocate(vs, (\'xt\', \'yu\', \'zt\'))\n    dTdz = allocate(vs, (\'xt\', \'yt\', \'zw\'))\n    dSdz = allocate(vs, (\'xt\', \'yt\', \'zw\'))\n\n    """"""\n    drho_dt and drho_ds at centers of T cells\n    """"""\n    drdT = vs.maskT * density.get_drhodT(\n        vs, vs.salt[:, :, :, vs.tau], vs.temp[:, :, :, vs.tau], np.abs(vs.zt)\n    )\n    drdS = vs.maskT * density.get_drhodS(\n        vs, vs.salt[:, :, :, vs.tau], vs.temp[:, :, :, vs.tau], np.abs(vs.zt)\n    )\n\n    """"""\n    gradients at top face of T cells\n    """"""\n    dTdz[:, :, :-1] = vs.maskW[:, :, :-1] * \\\n        (vs.temp[:, :, 1:, vs.tau] - vs.temp[:, :, :-1, vs.tau]) / \\\n        vs.dzw[np.newaxis, np.newaxis, :-1]\n    dSdz[:, :, :-1] = vs.maskW[:, :, :-1] * \\\n        (vs.salt[:, :, 1:, vs.tau] - vs.salt[:, :, :-1, vs.tau]) / \\\n        vs.dzw[np.newaxis, np.newaxis, :-1]\n\n    """"""\n    gradients at eastern face of T cells\n    """"""\n    dTdx[:-1, :, :] = vs.maskU[:-1, :, :] * (vs.temp[1:, :, :, vs.tau] - vs.temp[:-1, :, :, vs.tau]) \\\n        / (vs.dxu[:-1, np.newaxis, np.newaxis] * vs.cost[np.newaxis, :, np.newaxis])\n    dSdx[:-1, :, :] = vs.maskU[:-1, :, :] * (vs.salt[1:, :, :, vs.tau] - vs.salt[:-1, :, :, vs.tau]) \\\n        / (vs.dxu[:-1, np.newaxis, np.newaxis] * vs.cost[np.newaxis, :, np.newaxis])\n\n    """"""\n    gradients at northern face of T cells\n    """"""\n    dTdy[:, :-1, :] = vs.maskV[:, :-1, :] * \\\n        (vs.temp[:, 1:, :, vs.tau] - vs.temp[:, :-1, :, vs.tau]) \\\n        / vs.dyu[np.newaxis, :-1, np.newaxis]\n    dSdy[:, :-1, :] = vs.maskV[:, :-1, :] * \\\n        (vs.salt[:, 1:, :, vs.tau] - vs.salt[:, :-1, :, vs.tau]) \\\n        / vs.dyu[np.newaxis, :-1, np.newaxis]\n\n    def dm_taper(sx):\n        """"""\n        tapering function for isopycnal slopes\n        """"""\n        return 0.5 * (1. + np.tanh((-np.abs(sx) + vs.iso_slopec) / vs.iso_dslope))\n\n    """"""\n    Compute Ai_ez and K11 on center of east face of T cell.\n    """"""\n    diffloc = allocate(vs, (\'xt\', \'yt\', \'zt\'))\n    diffloc[1:-2, 2:-2, 1:] = 0.25 * (vs.K_iso[1:-2, 2:-2, 1:] + vs.K_iso[1:-2, 2:-2, :-1]\n                                      + vs.K_iso[2:-1, 2:-2, 1:] + vs.K_iso[2:-1, 2:-2, :-1])\n    diffloc[1:-2, 2:-2, 0] = 0.5 * (vs.K_iso[1:-2, 2:-2, 0] + vs.K_iso[2:-1, 2:-2, 0])\n\n    sumz = allocate(vs, (\'xu\', \'yt\', \'zw\'))[1:-2, 2:-2]\n    for kr in range(2):\n        ki = 0 if kr == 1 else 1\n        for ip in range(2):\n            drodxe = drdT[1 + ip:-2 + ip, 2:-2, ki:] * dTdx[1:-2, 2:-2, ki:] \\\n                + drdS[1 + ip:-2 + ip, 2:-2, ki:] * dSdx[1:-2, 2:-2, ki:]\n            drodze = drdT[1 + ip:-2 + ip, 2:-2, ki:] * dTdz[1 + ip:-2 + ip, 2:-2, :-1 + kr or None] \\\n                + drdS[1 + ip:-2 + ip, 2:-2, ki:] * dSdz[1 + ip:-2 + ip, 2:-2, :-1 + kr or None]\n            sxe = -drodxe / (np.minimum(0., drodze) - epsln)\n            taper = dm_taper(sxe)\n            sumz[:, :, ki:] += vs.dzw[np.newaxis, np.newaxis, :-1 + kr or None] * vs.maskU[1:-2, 2:-2, ki:] \\\n                * np.maximum(vs.K_iso_steep, diffloc[1:-2, 2:-2, ki:] * taper)\n            vs.Ai_ez[1:-2, 2:-2, ki:, ip, kr] = taper * sxe * vs.maskU[1:-2, 2:-2, ki:]\n    vs.K_11[1:-2, 2:-2, :] = sumz / (4. * vs.dzt[np.newaxis, np.newaxis, :])\n\n    """"""\n    Compute Ai_nz and K_22 on center of north face of T cell.\n    """"""\n    diffloc[...] = 0\n    diffloc[2:-2, 1:-2, 1:] = 0.25 * (vs.K_iso[2:-2, 1:-2, 1:] + vs.K_iso[2:-2, 1:-2, :-1]\n                                      + vs.K_iso[2:-2, 2:-1, 1:] + vs.K_iso[2:-2, 2:-1, :-1])\n    diffloc[2:-2, 1:-2, 0] = 0.5 * (vs.K_iso[2:-2, 1:-2, 0] + vs.K_iso[2:-2, 2:-1, 0])\n\n    sumz = allocate(vs, (\'xt\', \'yu\', \'zw\'))[2:-2, 1:-2]\n    for kr in range(2):\n        ki = 0 if kr == 1 else 1\n        for jp in range(2):\n            drodyn = drdT[2:-2, 1 + jp:-2 + jp, ki:] * dTdy[2:-2, 1:-2, ki:] + \\\n                drdS[2:-2, 1 + jp:-2 + jp, ki:] * dSdy[2:-2, 1:-2, ki:]\n            drodzn = drdT[2:-2, 1 + jp:-2 + jp, ki:] * dTdz[2:-2, 1 + jp:-2 + jp, :-1 + kr or None] \\\n                + drdS[2:-2, 1 + jp:-2 + jp, ki:] * dSdz[2:-2, 1 + jp:-2 + jp, :-1 + kr or None]\n            syn = -drodyn / (np.minimum(0., drodzn) - epsln)\n            taper = dm_taper(syn)\n            sumz[:, :, ki:] += vs.dzw[np.newaxis, np.newaxis, :-1 + kr or None] \\\n                * vs.maskV[2:-2, 1:-2, ki:] * np.maximum(vs.K_iso_steep, diffloc[2:-2, 1:-2, ki:] * taper)\n            vs.Ai_nz[2:-2, 1:-2, ki:, jp, kr] = taper * syn * vs.maskV[2:-2, 1:-2, ki:]\n    vs.K_22[2:-2, 1:-2, :] = sumz / (4. * vs.dzt[np.newaxis, np.newaxis, :])\n\n    """"""\n    compute Ai_bx, Ai_by and K33 on top face of T cell.\n    """"""\n    sumx = allocate(vs, (\'xt\', \'yt\', \'zt\'))[2:-2, 2:-2, :-1]\n    sumy = allocate(vs, (\'xt\', \'yt\', \'zt\'))[2:-2, 2:-2, :-1]\n\n    for kr in range(2):\n        drodzb = drdT[2:-2, 2:-2, kr:-1 + kr or None] * dTdz[2:-2, 2:-2, :-1] \\\n            + drdS[2:-2, 2:-2, kr:-1 + kr or None] * dSdz[2:-2, 2:-2, :-1]\n\n        # eastward slopes at the top of T cells\n        for ip in range(2):\n            drodxb = drdT[2:-2, 2:-2, kr:-1 + kr or None] * dTdx[1 + ip:-3 + ip, 2:-2, kr:-1 + kr or None] \\\n                + drdS[2:-2, 2:-2, kr:-1 + kr or None] * dSdx[1 + ip:-3 + ip, 2:-2, kr:-1 + kr or None]\n            sxb = -drodxb / (np.minimum(0., drodzb) - epsln)\n            taper = dm_taper(sxb)\n            sumx += vs.dxu[1 + ip:-3 + ip, np.newaxis, np.newaxis] * \\\n                vs.K_iso[2:-2, 2:-2, :-1] * taper * sxb**2 * vs.maskW[2:-2, 2:-2, :-1]\n            vs.Ai_bx[2:-2, 2:-2, :-1, ip, kr] = taper * sxb * vs.maskW[2:-2, 2:-2, :-1]\n\n        # northward slopes at the top of T cells\n        for jp in range(2):\n            facty = vs.cosu[1 + jp:-3 + jp] * vs.dyu[1 + jp:-3 + jp]\n            drodyb = drdT[2:-2, 2:-2, kr:-1 + kr or None] * dTdy[2:-2, 1 + jp:-3 + jp, kr:-1 + kr or None] \\\n                + drdS[2:-2, 2:-2, kr:-1 + kr or None] * dSdy[2:-2, 1 + jp:-3 + jp, kr:-1 + kr or None]\n            syb = -drodyb / (np.minimum(0., drodzb) - epsln)\n            taper = dm_taper(syb)\n            sumy += facty[np.newaxis, :, np.newaxis] * vs.K_iso[2:-2, 2:-2, :-1] \\\n                * taper * syb**2 * vs.maskW[2:-2, 2:-2, :-1]\n            vs.Ai_by[2:-2, 2:-2, :-1, jp, kr] = taper * syb * vs.maskW[2:-2, 2:-2, :-1]\n\n    vs.K_33[2:-2, 2:-2, :-1] = sumx / (4 * vs.dxt[2:-2, np.newaxis, np.newaxis]) + \\\n        sumy / (4 * vs.dyt[np.newaxis, 2:-2, np.newaxis] * vs.cost[np.newaxis, 2:-2, np.newaxis])\n    vs.K_33[2:-2, 2:-2, -1] = 0.\n\n\n@veros_method\ndef isoneutral_diag_streamfunction(vs):\n    """"""\n    calculate hor. components of streamfunction for eddy driven velocity\n    for diagnostics purpose only\n    """"""\n    K_gm_pad = utilities.pad_z_edges(vs, vs.K_gm)\n\n    """"""\n    meridional component at east face of \'T\' cells\n    """"""\n    diffloc = 0.25 * (K_gm_pad[1:-2, 2:-2, 1:-1] + K_gm_pad[1:-2, 2:-2, :-2] +\n                      K_gm_pad[2:-1, 2:-2, 1:-1] + K_gm_pad[2:-1, 2:-2, :-2])\n    vs.B2_gm[1:-2, 2:-2, :] = 0.25 * diffloc * np.sum(vs.Ai_ez[1:-2, 2:-2, ...], axis=(3, 4))\n\n    """"""\n    zonal component at north face of \'T\' cells\n    """"""\n    diffloc = 0.25 * (K_gm_pad[2:-2, 1:-2, 1:-1] + K_gm_pad[2:-2, 1:-2, :-2] +\n                      K_gm_pad[2:-2, 2:-1, 1:-1] + K_gm_pad[2:-2, 2:-1, :-2])\n    vs.B1_gm[2:-2, 1:-2, :] = -0.25 * diffloc * np.sum(vs.Ai_nz[2:-2, 1:-2, ...], axis=(3, 4))\n\n\n@veros_method(dist_safe=False, local_variables=[\n    \'dxt\', \'dyt\', \'dzt\', \'cost\'\n])\ndef check_isoneutral_slope_crit(vs):\n    """"""\n    check linear stability criterion from Griffies et al\n    """"""\n    epsln = 1e-20\n    if vs.enable_neutral_diffusion:\n        ft1 = 1.0 / (4.0 * vs.K_iso_0 * vs.dt_tracer + epsln)\n        delta1a = np.min(vs.dxt[2:-2, np.newaxis, np.newaxis] * np.abs(vs.cost[np.newaxis, 2:-2, np.newaxis]) \\\n                * vs.dzt[np.newaxis, np.newaxis, :] * ft1)\n        delta1b = np.min(vs.dyt[np.newaxis, 2:-2, np.newaxis] *\n                         vs.dzt[np.newaxis, np.newaxis, :] * ft1)\n        delta_iso1 = min(\n            vs.dzt[0] * ft1 * vs.dxt[-1] * abs(vs.cost[-1]),\n            min(delta1a, delta1b)\n        )\n\n        logger.info(\'Diffusion grid factor delta_iso1 = {}\', float(delta_iso1))\n        if delta_iso1 < vs.iso_slopec:\n            raise RuntimeError(\'Without latitudinal filtering, delta_iso1 is the steepest \'\n                               \'isoneutral slope available for linear stability of \'\n                               \'Redi and GM. Maximum allowable isoneutral slope is \'\n                               \'specified as iso_slopec = {}.\'\n                               .format(vs.iso_slopec))\n'"
veros/core/streamfunction/__init__.py,0,b'from .streamfunction_init import *\nfrom .solve_stream import *\n'
veros/core/streamfunction/island.py,2,"b""import numpy\nimport scipy.ndimage\n\nfrom ... import veros_method, runtime_settings as rs\nfrom .. import utilities\n\n\n@veros_method\ndef isleperim(vs, kmt, verbose=False):\n    utilities.enforce_boundaries(vs, kmt)\n\n    if rs.backend == 'bohrium':\n        kmt = kmt.copy2numpy()\n\n    structure = numpy.ones((3, 3))  # merge diagonally connected land masses\n\n    # find all land masses\n    labelled, _ = scipy.ndimage.label(kmt == 0, structure=structure)\n\n    # find and set perimeter\n    land_masses = labelled > 0\n    inner = scipy.ndimage.binary_dilation(land_masses, structure=structure)\n    perimeter = numpy.logical_xor(inner, land_masses)\n    labelled[perimeter] = -1\n\n    # match wrapping periodic land masses\n    if vs.enable_cyclic_x:\n        west_slice = labelled[2]\n        east_slice = labelled[-2]\n\n        for west_label in numpy.unique(west_slice[west_slice > 0]):\n            east_labels = numpy.unique(east_slice[west_slice == west_label])\n            east_labels = east_labels[~numpy.isin(east_labels, [west_label, -1])]\n            if not east_labels.size:\n                # already labelled correctly\n                continue\n            assert len(numpy.unique(east_labels)) == 1, (west_label, east_labels)\n            labelled[labelled == east_labels[0]] = west_label\n\n    utilities.enforce_boundaries(vs, labelled)\n\n    # label landmasses in a way that is consistent with pyom\n    labels = numpy.unique(labelled[labelled > 0])\n\n    label_idx = {}\n    for label in labels:\n        # find index of first island cell, scanning west to east, north to south\n        label_idx[label] = np.argmax(labelled[:, ::-1].T == label)\n\n    sorted_labels = list(sorted(labels, key=lambda i: label_idx[i]))\n\n    # ensure labels are numbered consecutively\n    relabelled = labelled.copy()\n    for new_label, label in enumerate(sorted_labels, 1):\n        if label == new_label:\n            continue\n        relabelled[labelled == label] = new_label\n\n    return np.asarray(relabelled)\n"""
veros/core/streamfunction/solve_stream.py,27,"b'""""""\nsolve two dimensional Possion equation\n     A * dpsi = forc,  where A = nabla_h^2\nwith Dirichlet boundary conditions\nused for streamfunction\n""""""\n\nfrom . import utilities\nfrom .. import utilities as mainutils\nfrom ... import veros_method, runtime_settings as rs\nfrom ...variables import allocate\n\n\n@veros_method\ndef solve_streamfunction(vs):\n    """"""\n    solve for barotropic streamfunction\n    """"""\n    # hydrostatic pressure\n    fxa = vs.grav / vs.rho_0\n    tmp = 0.5 * (vs.rho[:, :, :, vs.tau]) * fxa * vs.dzw * vs.maskT\n    vs.p_hydro[:, :, -1] = tmp[:, :, -1]\n    tmp[:, :, :-1] += 0.5 * vs.rho[:, :, 1:, vs.tau] * \\\n        fxa * vs.dzw[:-1] * vs.maskT[:, :, :-1]\n    vs.p_hydro[:, :, -2::-1] = vs.maskT[:, :, -2::-1] * \\\n        (vs.p_hydro[:, :, -1, np.newaxis] + np.cumsum(tmp[:, :, -2::-1], axis=2))\n\n    # add hydrostatic pressure gradient\n    vs.du[2:-2, 2:-2, :, vs.tau] += \\\n        -(vs.p_hydro[3:-1, 2:-2, :] - vs.p_hydro[2:-2, 2:-2, :]) \\\n        / (vs.cost[np.newaxis, 2:-2, np.newaxis] * vs.dxu[2:-2, np.newaxis, np.newaxis]) \\\n        * vs.maskU[2:-2, 2:-2, :]\n    vs.dv[2:-2, 2:-2, :, vs.tau] += \\\n        -(vs.p_hydro[2:-2, 3:-1, :] - vs.p_hydro[2:-2, 2:-2, :]) \\\n        / vs.dyu[np.newaxis, 2:-2, np.newaxis] \\\n        * vs.maskV[2:-2, 2:-2, :]\n\n    # forcing for barotropic streamfunction\n    fpx = np.sum((vs.du[:, :, :, vs.tau] + vs.du_mix)\n                 * vs.maskU * vs.dzt, axis=(2,)) * vs.hur\n    fpy = np.sum((vs.dv[:, :, :, vs.tau] + vs.dv_mix)\n                 * vs.maskV * vs.dzt, axis=(2,)) * vs.hvr\n\n    mainutils.enforce_boundaries(vs, fpx)\n    mainutils.enforce_boundaries(vs, fpy)\n\n    forc = allocate(vs, (\'xu\', \'yu\'))\n    forc[2:-2, 2:-2] = (fpy[3:-1, 2:-2] - fpy[2:-2, 2:-2]) \\\n        / (vs.cosu[2:-2] * vs.dxu[2:-2, np.newaxis]) \\\n        - (vs.cost[3:-1] * fpx[2:-2, 3:-1] - vs.cost[2:-2] * fpx[2:-2, 2:-2]) \\\n        / (vs.cosu[2:-2] * vs.dyu[2:-2])\n\n    # solve for interior streamfunction\n    vs.dpsi[:, :, vs.taup1] = 2 * vs.dpsi[:, :, vs.tau] - vs.dpsi[:, :, vs.taum1]\n\n    vs.linear_solver.solve(\n        vs,\n        forc,\n        vs.dpsi[..., vs.taup1]\n    )\n\n    mainutils.enforce_boundaries(vs, vs.dpsi[:, :, vs.taup1])\n\n    line_forc = allocate(vs, (\'isle\',))\n\n    if vs.nisle > 1:\n        # calculate island integrals of forcing, keep psi constant on island 1\n        line_forc[1:] = utilities.line_integrals(vs, fpx[..., np.newaxis],\n                                                 fpy[..., np.newaxis], kind=\'same\')[1:]\n\n        # calculate island integrals of interior streamfunction\n        fpx[...] = 0.\n        fpy[...] = 0.\n        fpx[1:, 1:] = -vs.maskU[1:, 1:, -1] \\\n            * (vs.dpsi[1:, 1:, vs.taup1] - vs.dpsi[1:, :-1, vs.taup1]) \\\n            / vs.dyt[np.newaxis, 1:] * vs.hur[1:, 1:]\n        fpy[1:, 1:] = vs.maskV[1:, 1:, -1] \\\n            * (vs.dpsi[1:, 1:, vs.taup1] - vs.dpsi[:-1, 1:, vs.taup1]) \\\n            / (vs.cosu[np.newaxis, 1:] * vs.dxt[1:, np.newaxis]) * vs.hvr[1:, 1:]\n        line_forc[1:] += -utilities.line_integrals(vs, fpx[..., np.newaxis],\n                                                   fpy[..., np.newaxis], kind=\'same\')[1:]\n\n        # solve for time dependent boundary values\n        if rs.backend == \'bohrium\':\n            import numpy.linalg\n            line_forc = line_forc.copy2numpy()\n            line_psin = vs.line_psin.copy2numpy()\n            line_forc[1:] = numpy.linalg.solve(line_psin[1:, 1:], line_forc[1:])\n            line_forc = np.array(line_forc)\n        else:\n            line_forc[1:] = np.linalg.solve(vs.line_psin[1:, 1:], line_forc[1:])\n\n        vs.dpsin[1:, vs.tau] = line_forc[1:]\n\n    # integrate barotropic and baroclinic velocity forward in time\n    vs.psi[:, :, vs.taup1] = vs.psi[:, :, vs.tau] + vs.dt_mom * ((1.5 + vs.AB_eps) * vs.dpsi[:, :, vs.taup1]\n                                                               - (0.5 + vs.AB_eps) * vs.dpsi[:, :, vs.tau])\n    vs.psi[:, :, vs.taup1] += vs.dt_mom * np.sum(((1.5 + vs.AB_eps) * vs.dpsin[1:, vs.tau]\n                                                           - (0.5 + vs.AB_eps) * vs.dpsin[1:, vs.taum1]) * vs.psin[:, :, 1:], axis=2)\n    vs.u[:, :, :, vs.taup1] = vs.u[:, :, :, vs.tau] + vs.dt_mom * (vs.du_mix + (1.5 + vs.AB_eps) * vs.du[:, :, :, vs.tau]\n                                                                             - (0.5 + vs.AB_eps) * vs.du[:, :, :, vs.taum1]) * vs.maskU\n    vs.v[:, :, :, vs.taup1] = vs.v[:, :, :, vs.tau] + vs.dt_mom * (vs.dv_mix + (1.5 + vs.AB_eps) * vs.dv[:, :, :, vs.tau]\n                                                                             - (0.5 + vs.AB_eps) * vs.dv[:, :, :, vs.taum1]) * vs.maskV\n\n    # subtract incorrect vertical mean from baroclinic velocity\n    fpx = np.sum(vs.u[:, :, :, vs.taup1] * vs.maskU * vs.dzt, axis=2)\n    fpy = np.sum(vs.v[:, :, :, vs.taup1] * vs.maskV * vs.dzt, axis=2)\n    vs.u[:, :, :, vs.taup1] += -fpx[:, :, np.newaxis] * \\\n        vs.maskU * vs.hur[:, :, np.newaxis]\n    vs.v[:, :, :, vs.taup1] += -fpy[:, :, np.newaxis] * \\\n        vs.maskV * vs.hvr[:, :, np.newaxis]\n\n    # add barotropic mode to baroclinic velocity\n    vs.u[2:-2, 2:-2, :, vs.taup1] += \\\n        -vs.maskU[2:-2, 2:-2, :]\\\n        * (vs.psi[2:-2, 2:-2, vs.taup1, np.newaxis] - vs.psi[2:-2, 1:-3, vs.taup1, np.newaxis]) \\\n        / vs.dyt[np.newaxis, 2:-2, np.newaxis]\\\n        * vs.hur[2:-2, 2:-2, np.newaxis]\n    vs.v[2:-2, 2:-2, :, vs.taup1] += \\\n        vs.maskV[2:-2, 2:-2, :]\\\n        * (vs.psi[2:-2, 2:-2, vs.taup1, np.newaxis] - vs.psi[1:-3, 2:-2, vs.taup1, np.newaxis]) \\\n        / (vs.cosu[2:-2, np.newaxis] * vs.dxt[2:-2, np.newaxis, np.newaxis])\\\n        * vs.hvr[2:-2, 2:-2][:, :, np.newaxis]\n'"
veros/core/streamfunction/streamfunction_init.py,7,"b'from loguru import logger\n\nfrom ... import veros_method, runtime_settings as rs, runtime_state as rst\nfrom ...variables import allocate\nfrom .. import utilities as mainutils\nfrom . import island, utilities\n\n\n@veros_method(inline=True, dist_safe=False, local_variables=[\'kbot\', \'land_map\'])\ndef get_isleperim(vs):\n    logger.debug(\' Determining number of land masses\')\n    vs.land_map[...] = island.isleperim(vs, vs.kbot)\n    logger.info(_ascii_map(vs, vs.land_map))\n    return int(vs.land_map.max())\n\n\ndef _get_solver_class():\n    ls = rs.linear_solver\n\n    def _get_best_solver():\n        if rst.proc_num > 1:\n            try:\n                from .solvers.petsc import PETScSolver\n            except ImportError:\n                logger.warning(\'PETSc linear solver not available, falling back to SciPy\')\n            else:\n                return PETScSolver\n\n        from .solvers.scipy import SciPySolver\n        return SciPySolver\n\n    if ls == \'best\':\n        return _get_best_solver()\n    elif ls == \'petsc\':\n        from .solvers.petsc import PETScSolver\n        return PETScSolver\n    elif ls == \'scipy\':\n        from .solvers.scipy import SciPySolver\n        return SciPySolver\n\n    raise ValueError(\'unrecognized linear solver %s\' % ls)\n\n\n@veros_method\ndef streamfunction_init(vs):\n    """"""\n    prepare for island integrals\n    """"""\n    logger.info(\'Initializing streamfunction method\')\n\n    """"""\n    preprocess land map using MOMs algorithm for B-grid to determine number of islands\n    """"""\n    vs.land_map = allocate(vs, (\'xt\', \'yt\'), dtype=\'int\')\n    nisle = get_isleperim(vs)\n\n    """"""\n    now that the number of islands is known we can allocate the rest of the variables\n    """"""\n    vs.nisle = nisle\n    vs.isle = np.arange(1, vs.nisle + 1)\n    vs.psin = allocate(vs, (\'xu\', \'yu\', \'isle\'))\n    vs.dpsin = allocate(vs, (\'isle\', \'timesteps\'))\n    vs.line_psin = allocate(vs, (\'isle\', \'isle\'))\n    vs.boundary_mask = allocate(vs, (\'xt\', \'yt\', \'isle\'), dtype=\'bool\')\n    vs.line_dir_south_mask = allocate(vs, (\'xt\', \'yt\', \'isle\'), dtype=\'bool\')\n    vs.line_dir_north_mask = allocate(vs, (\'xt\', \'yt\', \'isle\'), dtype=\'bool\')\n    vs.line_dir_east_mask = allocate(vs, (\'xt\', \'yt\', \'isle\'), dtype=\'bool\')\n    vs.line_dir_west_mask = allocate(vs, (\'xt\', \'yt\', \'isle\'), dtype=\'bool\')\n\n    for isle in range(vs.nisle):\n        boundary_map = vs.land_map == (isle + 1)\n\n        if vs.enable_cyclic_x:\n            vs.line_dir_east_mask[2:-2, 1:-1, isle] = boundary_map[3:-1, 1:-1] & ~boundary_map[3:-1, 2:]\n            vs.line_dir_west_mask[2:-2, 1:-1, isle] = boundary_map[2:-2, 2:] & ~boundary_map[2:-2, 1:-1]\n            vs.line_dir_south_mask[2:-2, 1:-1, isle] = boundary_map[2:-2, 1:-1] & ~boundary_map[3:-1, 1:-1]\n            vs.line_dir_north_mask[2:-2, 1:-1, isle] = boundary_map[3:-1, 2:] & ~boundary_map[2:-2, 2:]\n        else:\n            vs.line_dir_east_mask[1:-1, 1:-1, isle] = boundary_map[2:, 1:-1] & ~boundary_map[2:, 2:]\n            vs.line_dir_west_mask[1:-1, 1:-1, isle] = boundary_map[1:-1, 2:] & ~boundary_map[1:-1, 1:-1]\n            vs.line_dir_south_mask[1:-1, 1:-1, isle] = boundary_map[1:-1, 1:-1] & ~boundary_map[2:, 1:-1]\n            vs.line_dir_north_mask[1:-1, 1:-1, isle] = boundary_map[2:, 2:] & ~boundary_map[1:-1, 2:]\n\n        vs.boundary_mask[..., isle] = (\n            vs.line_dir_east_mask[..., isle]\n            | vs.line_dir_west_mask[..., isle]\n            | vs.line_dir_north_mask[..., isle]\n            | vs.line_dir_south_mask[..., isle]\n        )\n\n    vs.linear_solver = _get_solver_class()(vs)\n\n    """"""\n    precalculate time independent boundary components of streamfunction\n    """"""\n    forc = allocate(vs, (\'xu\', \'yu\'))\n\n    # initialize with random noise to achieve uniform convergence\n    vs.psin[...] = vs.maskZ[..., -1, np.newaxis]\n\n    for isle in range(vs.nisle):\n        logger.info(\' Solving for boundary contribution by island {:d}\'.format(isle))\n        vs.linear_solver.solve(vs, forc, vs.psin[:, :, isle],\n                               boundary_val=vs.boundary_mask[:, :, isle])\n\n    mainutils.enforce_boundaries(vs, vs.psin)\n\n    """"""\n    precalculate time independent island integrals\n    """"""\n    fpx = allocate(vs, (\'xu\', \'yu\', \'isle\'))\n    fpy = allocate(vs, (\'xu\', \'yu\', \'isle\'))\n\n    fpx[1:, 1:, :] = -vs.maskU[1:, 1:, -1, np.newaxis] \\\n        * (vs.psin[1:, 1:, :] - vs.psin[1:, :-1, :]) \\\n        / vs.dyt[np.newaxis, 1:, np.newaxis] * vs.hur[1:, 1:, np.newaxis]\n    fpy[1:, 1:, ...] = vs.maskV[1:, 1:, -1, np.newaxis] \\\n        * (vs.psin[1:, 1:, :] - vs.psin[:-1, 1:, :]) \\\n        / (vs.cosu[np.newaxis, 1:, np.newaxis] * vs.dxt[1:, np.newaxis, np.newaxis]) \\\n        * vs.hvr[1:, 1:, np.newaxis]\n    vs.line_psin[...] = utilities.line_integrals(vs, fpx, fpy, kind=\'full\')\n\n\n@veros_method\ndef _ascii_map(vs, boundary_map):\n    def _get_char(c):\n        if c == 0:\n            return \'.\'\n        if c < 0:\n            return \'#\'\n        return str(c % 10)\n\n    map_string = \'\'\n    linewidth = 100\n    imt = vs.nx + 4\n    iremain = imt\n    istart = 0\n    map_string += \'\\n\'\n    map_string += \' \' * (5 + min(linewidth, imt) // 2 - 13) + \'Land mass and perimeter\'\n    map_string += \'\\n\'\n    for isweep in range(1, imt // linewidth + 2):\n        iline = min(iremain, linewidth)\n        iremain = iremain - iline\n        if iline > 0:\n            map_string += \'\\n\'\n            map_string += \'\'.join([\'{:5d}\'.format(istart + i + 1 - 2) for i in range(1, iline + 1, 5)])\n            map_string += \'\\n\'\n            for j in range(vs.ny + 3, -1, -1):\n                map_string += \'{:3d} \'.format(j)\n                map_string += \'\'.join([_get_char(boundary_map[istart + i - 2, j]) for i in range(2, iline + 2)])\n                map_string += \'\\n\'\n            map_string += \'\'.join([\'{:5d}\'.format(istart + i + 1 - 2) for i in range(1, iline + 1, 5)])\n            map_string += \'\\n\'\n            istart = istart + iline\n    map_string += \'\\n\'\n    return map_string\n'"
veros/core/streamfunction/utilities.py,25,"b'from ... import veros_method\nfrom veros.distributed import global_sum\n\n\n@veros_method\ndef line_integrals(vs, uloc, vloc, kind=\'same\'):\n    """"""\n    calculate line integrals along all islands\n\n    Arguments:\n        kind: \'same\' calculates only line integral contributions of an island with itself,\n               while \'full\' calculates all possible pairings between all islands.\n    """"""\n    if kind not in (\'same\', \'full\'):\n        raise ValueError(\'kind must be ""same"" or ""full""\')\n\n    east = vloc[1:-2, 1:-2, :] * vs.dyu[np.newaxis, 1:-2, np.newaxis] \\\n        + uloc[1:-2, 2:-1, :] \\\n        * vs.dxu[1:-2, np.newaxis, np.newaxis] \\\n        * vs.cost[np.newaxis, 2:-1, np.newaxis]\n    west = -vloc[2:-1, 1:-2, :] * vs.dyu[np.newaxis, 1:-2, np.newaxis] \\\n        - uloc[1:-2, 1:-2, :] \\\n        * vs.dxu[1:-2, np.newaxis, np.newaxis] \\\n        * vs.cost[np.newaxis, 1:-2, np.newaxis]\n    north = vloc[1:-2, 1:-2, :] * vs.dyu[np.newaxis, 1:-2, np.newaxis] \\\n        - uloc[1:-2, 1:-2, :] \\\n        * vs.dxu[1:-2, np.newaxis, np.newaxis] \\\n        * vs.cost[np.newaxis, 1:-2, np.newaxis]\n    south = -vloc[2:-1, 1:-2, :] * vs.dyu[np.newaxis, 1:-2, np.newaxis] \\\n        + uloc[1:-2, 2:-1, :] \\\n        * vs.dxu[1:-2, np.newaxis, np.newaxis] \\\n        * vs.cost[np.newaxis, 2:-1, np.newaxis]\n\n    if kind == \'same\':\n        east = np.sum(east * (vs.line_dir_east_mask[1:-2, 1:-2] &\n                                vs.boundary_mask[1:-2, 1:-2]), axis=(0, 1))\n        west = np.sum(west * (vs.line_dir_west_mask[1:-2, 1:-2] &\n                                vs.boundary_mask[1:-2, 1:-2]), axis=(0, 1))\n        north = np.sum(north * (vs.line_dir_north_mask[1:-2, 1:-2]\n                                    & vs.boundary_mask[1:-2, 1:-2]), axis=(0, 1))\n        south = np.sum(south * (vs.line_dir_south_mask[1:-2, 1:-2]\n                                    & vs.boundary_mask[1:-2, 1:-2]), axis=(0, 1))\n        out = east + west + north + south\n    else:\n        out = np.empty((vs.nisle, vs.nisle))\n        for isle in range(vs.nisle):\n            east_isle = np.sum(\n                east[..., isle, np.newaxis]\n                * (vs.line_dir_east_mask[1:-2, 1:-2] & vs.boundary_mask[1:-2, 1:-2]),\n                axis=(0, 1)\n            )\n            west_isle = np.sum(\n                west[..., isle, np.newaxis]\n                * (vs.line_dir_west_mask[1:-2, 1:-2] & vs.boundary_mask[1:-2, 1:-2]),\n                axis=(0, 1)\n            )\n            north_isle = np.sum(\n                north[..., isle, np.newaxis]\n                * (vs.line_dir_north_mask[1:-2, 1:-2] & vs.boundary_mask[1:-2, 1:-2]),\n                axis=(0, 1)\n            )\n            south_isle = np.sum(\n                south[..., isle, np.newaxis]\n                * (vs.line_dir_south_mask[1:-2, 1:-2] & vs.boundary_mask[1:-2, 1:-2]),\n                axis=(0, 1)\n            )\n            out[:, isle] = east_isle + west_isle + north_isle + south_isle\n\n    return global_sum(vs, out)\n'"
veros/diagnostics/io_tools/__init__.py,0,b''
veros/diagnostics/io_tools/hdf5.py,0,"b'import threading\nimport contextlib\n\nfrom loguru import logger\n\nfrom ... import runtime_settings, runtime_state\n\n\n@contextlib.contextmanager\ndef threaded_io(vs, filepath, mode):\n    """"""\n    If using IO threads, start a new thread to write the HDF5 data to disk.\n    """"""\n    import h5py\n    if vs.use_io_threads:\n        _wait_for_disk(vs, filepath)\n        _io_locks[filepath].clear()\n    kwargs = {}\n    if runtime_state.proc_num > 1:\n        kwargs.update(\n            driver=\'mpio\',\n            comm=runtime_settings.mpi_comm\n        )\n    h5file = h5py.File(filepath, mode, **kwargs)\n    try:\n        yield h5file\n    finally:\n        if vs.use_io_threads:\n            threading.Thread(target=_write_to_disk, args=(vs, h5file, filepath)).start()\n        else:\n            _write_to_disk(vs, h5file, filepath)\n\n\n_io_locks = {}\n\n\ndef _add_to_locks(file_id):\n    """"""\n    If there is no lock for file_id, create one\n    """"""\n    if file_id not in _io_locks:\n        _io_locks[file_id] = threading.Event()\n        _io_locks[file_id].set()\n\n\ndef _wait_for_disk(vs, file_id):\n    """"""\n    Wait for the lock of file_id to be released\n    """"""\n    logger.debug(\'Waiting for lock {} to be released\'.format(file_id))\n    _add_to_locks(file_id)\n    lock_released = _io_locks[file_id].wait(vs.io_timeout)\n    if not lock_released:\n        raise RuntimeError(\'Timeout while waiting for disk IO to finish\')\n\n\ndef _write_to_disk(vs, h5file, file_id):\n    """"""\n    Sync HDF5 data to disk, close file handle, and release lock.\n    May run in a separate thread.\n    """"""\n    try:\n        h5file.close()\n    finally:\n        if vs.use_io_threads and file_id is not None:\n            _io_locks[file_id].set()\n'"
veros/diagnostics/io_tools/netcdf.py,3,"b'import threading\nimport contextlib\n\nfrom loguru import logger\n\nfrom ... import veros_method, variables, runtime_state, runtime_settings as rs, distributed\n\n""""""\nnetCDF output is designed to follow the COARDS guidelines from\nhttp://ferret.pmel.noaa.gov/Ferret/documentation/coards-netcdf-conventions\n""""""\n\n\n@veros_method\ndef initialize_file(vs, ncfile, create_time_dimension=True):\n    """"""\n    Define standard grid in netcdf file\n    """"""\n    import h5netcdf\n\n    if not isinstance(ncfile, h5netcdf.File):\n        raise TypeError(\'Argument needs to be a netCDF4 Dataset\')\n\n    for dim in variables.BASE_DIMENSIONS:\n        var = vs.variables[dim]\n        dimsize = variables.get_dimensions(vs, var.dims[::-1], include_ghosts=False, local=False)[0]\n        add_dimension(vs, dim, dimsize, ncfile)\n        initialize_variable(vs, dim, var, ncfile)\n        write_variable(vs, dim, var, getattr(vs, dim), ncfile)\n\n    if create_time_dimension:\n        ncfile.dimensions[\'Time\'] = None\n        nc_dim_var_time = ncfile.create_variable(\'Time\', (\'Time\',), float)\n        nc_dim_var_time.long_name = \'Time\'\n        nc_dim_var_time.units = \'days\'\n        nc_dim_var_time.time_origin = \'01-JAN-1900 00:00:00\'\n\n\n@veros_method\ndef add_dimension(vs, identifier, size, ncfile):\n    ncfile.dimensions[identifier] = size\n\n\n@veros_method\ndef initialize_variable(vs, key, var, ncfile):\n    dims = tuple(d for d in var.dims if d in ncfile.dimensions)\n    if var.time_dependent and \'Time\' in ncfile.dimensions:\n        dims += (\'Time\',)\n\n    if key in ncfile.variables:\n        logger.warning(\'Variable {} already initialized\'.format(key))\n        return\n\n    kwargs = {}\n    if vs.enable_hdf5_gzip_compression and runtime_state.proc_num == 1:\n        kwargs.update(\n            compression=\'gzip\',\n            compression_opts=1\n        )\n\n    global_shape = [ncfile.dimensions[dim] or 1 for dim in dims]\n    chunksize = distributed.get_local_size(vs, global_shape, dims, include_overlap=False)\n\n    # transpose all dimensions in netCDF output (convention in most ocean models)\n    v = ncfile.create_variable(\n        key, dims[::-1], var.dtype or vs.default_float_type,\n        fillvalue=variables.FILL_VALUE,\n        chunks=tuple(chunksize[::-1]),\n        **kwargs\n    )\n    v.missing_value = variables.FILL_VALUE\n    v.attrs.update(\n        long_name=var.name,\n        units=var.units,\n        **var.extra_attributes\n    )\n\n\n@veros_method\ndef get_current_timestep(vs, ncfile):\n    return len(ncfile.variables[\'Time\'])\n\n\n@veros_method\ndef advance_time(vs, time_step, time_value, ncfile):\n    ncfile.resize_dimension(\'Time\', time_step + 1)\n    ncfile.variables[\'Time\'][time_step] = time_value\n\n\n@veros_method\ndef write_variable(vs, key, var, var_data, ncfile, time_step=None):\n    var_data = var_data * var.scale\n\n    gridmask = var.get_mask(vs)\n    if gridmask is not None:\n        newaxes = (slice(None),) * gridmask.ndim + (np.newaxis,) * (var_data.ndim - gridmask.ndim)\n        var_data = np.where(gridmask.astype(np.bool)[newaxes], var_data, variables.FILL_VALUE)\n\n    if not np.isscalar(var_data):\n        tmask = tuple(vs.tau if dim in variables.TIMESTEPS else slice(None) for dim in var.dims)\n        var_data = variables.remove_ghosts(var_data, var.dims)[tmask].T\n\n    try:\n        var_data = var_data.copy2numpy()\n    except AttributeError:\n        pass\n\n    var_obj = ncfile.variables[key]\n\n    chunk, _ = distributed.get_chunk_slices(vs, var_obj.dimensions)\n\n    if \'Time\' in var_obj.dimensions:\n        assert var_obj.dimensions[0] == \'Time\'\n\n        if time_step is None:\n            raise ValueError(\'time step must be given for non-constant data\')\n\n        chunk = (time_step,) + chunk[1:]\n\n    var_obj[chunk] = var_data\n\n\n@contextlib.contextmanager\n@veros_method\ndef threaded_io(vs, filepath, mode):\n    """"""\n    If using IO threads, start a new thread to write the netCDF data to disk.\n    """"""\n    import h5netcdf\n\n    if vs.use_io_threads:\n        _wait_for_disk(vs, filepath)\n        _io_locks[filepath].clear()\n\n    kwargs = {}\n    if runtime_state.proc_num > 1:\n        kwargs.update(\n            driver=\'mpio\',\n            comm=rs.mpi_comm\n        )\n\n    nc_dataset = h5netcdf.File(filepath, mode, **kwargs)\n    try:\n        yield nc_dataset\n    finally:\n        if vs.use_io_threads:\n            threading.Thread(target=_write_to_disk, args=(vs, nc_dataset, filepath)).start()\n        else:\n            _write_to_disk(vs, nc_dataset, filepath)\n\n\n_io_locks = {}\n\n\ndef _add_to_locks(file_id):\n    """"""\n    If there is no lock for file_id, create one\n    """"""\n    if file_id not in _io_locks:\n        _io_locks[file_id] = threading.Event()\n        _io_locks[file_id].set()\n\n\ndef _wait_for_disk(vs, file_id):\n    """"""\n    Wait for the lock of file_id to be released\n    """"""\n    logger.debug(\'Waiting for lock {} to be released\'.format(file_id))\n    _add_to_locks(file_id)\n    lock_released = _io_locks[file_id].wait(vs.io_timeout)\n    if not lock_released:\n        raise RuntimeError(\'Timeout while waiting for disk IO to finish\')\n\n\ndef _write_to_disk(vs, ncfile, file_id):\n    """"""\n    Sync netCDF data to disk, close file handle, and release lock.\n    May run in a separate thread.\n    """"""\n    try:\n        ncfile.close()\n    finally:\n        if vs.use_io_threads and file_id is not None:\n            _io_locks[file_id].set()\n'"
veros/setup/acc/__init__.py,0,b'from veros.setup.acc.acc import ACCSetup\n'
veros/setup/acc/acc.py,7,"b'#!/usr/bin/env python\n\nfrom veros import VerosSetup, veros_method\nfrom veros.tools import cli\nfrom veros.variables import allocate\nfrom veros.distributed import global_min, global_max\n\n\nclass ACCSetup(VerosSetup):\n    """"""A model using spherical coordinates with a partially closed domain representing the Atlantic and ACC.\n\n    Wind forcing over the channel part and buoyancy relaxation drive a large-scale meridional overturning circulation.\n\n    This setup demonstrates:\n     - setting up an idealized geometry\n     - updating surface forcings\n     - basic usage of diagnostics\n\n    `Adapted from pyOM2 <https://wiki.cen.uni-hamburg.de/ifm/TO/pyOM2/ACC%202>`_.\n    """"""\n    @veros_method\n    def set_parameter(self, vs):\n        vs.identifier = \'acc\'\n\n        vs.nx, vs.ny, vs.nz = 30, 42, 15\n        vs.dt_mom = 4800\n        vs.dt_tracer = 86400 / 2.\n        vs.runlen = 86400 * 365\n\n        vs.coord_degree = True\n        vs.enable_cyclic_x = True\n\n        vs.congr_epsilon = 1e-12\n        vs.congr_max_iterations = 5000\n\n        vs.enable_neutral_diffusion = True\n        vs.K_iso_0 = 1000.0\n        vs.K_iso_steep = 500.0\n        vs.iso_dslope = 0.005\n        vs.iso_slopec = 0.01\n        vs.enable_skew_diffusion = True\n\n        vs.enable_hor_friction = True\n        vs.A_h = (2 * vs.degtom)**3 * 2e-11\n        vs.enable_hor_friction_cos_scaling = True\n        vs.hor_friction_cosPower = 1\n\n        vs.enable_bottom_friction = True\n        vs.r_bot = 1e-5\n\n        vs.enable_implicit_vert_friction = True\n\n        vs.enable_tke = True\n        vs.c_k = 0.1\n        vs.c_eps = 0.7\n        vs.alpha_tke = 30.0\n        vs.mxl_min = 1e-8\n        vs.tke_mxl_choice = 2\n        vs.kappaM_min = 2e-4\n        vs.kappaH_min = 2e-5\n        vs.enable_kappaH_profile = True\n        # vs.enable_tke_superbee_advection = True\n\n        vs.K_gm_0 = 1000.0\n        vs.enable_eke = True\n        vs.eke_k_max = 1e4\n        vs.eke_c_k = 0.4\n        vs.eke_c_eps = 0.5\n        vs.eke_cross = 2.\n        vs.eke_crhin = 1.0\n        vs.eke_lmin = 100.0\n        vs.enable_eke_superbee_advection = True\n        vs.enable_eke_isopycnal_diffusion = True\n\n        vs.enable_idemix = False\n\n        vs.eq_of_state_type = 3\n\n    @veros_method\n    def set_grid(self, vs):\n        ddz = np.array([50., 70., 100., 140., 190., 240., 290., 340.,\n                        390., 440., 490., 540., 590., 640., 690.])\n        vs.dxt[...] = 2.0\n        vs.dyt[...] = 2.0\n        vs.x_origin = 0.0\n        vs.y_origin = -40.0\n        vs.dzt[...] = ddz[::-1] / 2.5\n\n    @veros_method\n    def set_coriolis(self, vs):\n        vs.coriolis_t[:, :] = 2 * vs.omega * np.sin(vs.yt[None, :] / 180. * vs.pi)\n\n    @veros_method\n    def set_topography(self, vs):\n        x, y = np.meshgrid(vs.xt, vs.yt, indexing=\'ij\')\n        vs.kbot[...] = np.logical_or(x > 1.0, y < -20).astype(np.int)\n\n    @veros_method\n    def set_initial_conditions(self, vs):\n        # initial conditions\n        vs.temp[:, :, :, 0:2] = ((1 - vs.zt[None, None, :] / vs.zw[0]) * 15 * vs.maskT)[..., None]\n        vs.salt[:, :, :, 0:2] = 35.0 * vs.maskT[..., None]\n\n        # wind stress forcing\n        yt_min = global_min(vs, vs.yt.min())\n        yu_min = global_min(vs, vs.yu.min())\n        yt_max = global_max(vs, vs.yt.max())\n        yu_max = global_max(vs, vs.yu.max())\n\n        taux = allocate(vs, (\'yt\',))\n        taux[vs.yt < -20] = 0.1 * np.sin(vs.pi * (vs.yu[vs.yt < -20] - yu_min) / (-20.0 - yt_min))\n        taux[vs.yt > 10] = 0.1 * (1 - np.cos(2 * vs.pi * (vs.yu[vs.yt > 10] - 10.0) / (yu_max - 10.0)))\n        vs.surface_taux[:, :] = taux * vs.maskU[:, :, -1]\n\n        # surface heatflux forcing\n        vs._t_star = allocate(vs, (\'yt\',), fill=15)\n        vs._t_star[vs.yt < -20] = 15 * (vs.yt[vs.yt < -20] - yt_min) / (-20 - yt_min)\n        vs._t_star[vs.yt > 20] = 15 * (1 - (vs.yt[vs.yt > 20] - 20) / (yt_max - 20))\n        vs._t_rest = vs.dzt[None, -1] / (30. * 86400.) * vs.maskT[:, :, -1]\n\n        if vs.enable_tke:\n            vs.forc_tke_surface[2:-2, 2:-2] = np.sqrt((0.5 * (vs.surface_taux[2:-2, 2:-2] + vs.surface_taux[1:-3, 2:-2]) / vs.rho_0)**2\n                                                      + (0.5 * (vs.surface_tauy[2:-2, 2:-2] + vs.surface_tauy[2:-2, 1:-3]) / vs.rho_0)**2)**(1.5)\n\n        if vs.enable_idemix:\n            vs.forc_iw_bottom[...] = 1e-6 * vs.maskW[:, :, -1]\n            vs.forc_iw_surface[...] = 1e-7 * vs.maskW[:, :, -1]\n\n    @veros_method\n    def set_forcing(self, vs):\n        vs.forc_temp_surface[...] = vs._t_rest * (vs._t_star - vs.temp[:, :, -1, vs.tau])\n\n    @veros_method\n    def set_diagnostics(self, vs):\n        vs.diagnostics[\'snapshot\'].output_frequency = 86400 * 10\n        vs.diagnostics[\'averages\'].output_variables = (\n            \'salt\', \'temp\', \'u\', \'v\', \'w\', \'psi\', \'surface_taux\', \'surface_tauy\'\n        )\n        vs.diagnostics[\'averages\'].output_frequency = 365 * 86400.\n        vs.diagnostics[\'averages\'].sampling_frequency = vs.dt_tracer * 10\n        vs.diagnostics[\'overturning\'].output_frequency = 365 * 86400. / 48.\n        vs.diagnostics[\'overturning\'].sampling_frequency = vs.dt_tracer * 10\n        vs.diagnostics[\'tracer_monitor\'].output_frequency = 365 * 86400. / 12.\n        vs.diagnostics[\'energy\'].output_frequency = 365 * 86400. / 48\n        vs.diagnostics[\'energy\'].sampling_frequency = vs.dt_tracer * 10\n\n    def after_timestep(self, vs):\n        pass\n\n\n@cli\ndef run(*args, **kwargs):\n    simulation = ACCSetup(*args, **kwargs)\n    simulation.setup()\n    simulation.run()\n\n\nif __name__ == \'__main__\':\n    run()\n'"
veros/setup/acc_sector/__init__.py,0,b'from veros.setup.acc_sector.acc_sector import ACCSectorSetup\n'
veros/setup/acc_sector/acc_sector.py,15,"b'#!/usr/bin/env python\n\nfrom veros import VerosSetup, veros_method, runtime_settings as rs\nimport veros.tools\nfrom veros.variables import allocate\nfrom veros.distributed import global_min, global_max\n\n\nclass ACCSectorSetup(VerosSetup):\n    """"""A model using spherical coordinates with a partially closed domain representing the narrow sector of Atlantic and ACC.\n\n    The bathymetry of the model is idealized to a flat-bottom (with depth of 4000 m) over the majority of the domain,\n    except a half depth appended within the confines of the circumpolar channel at the inflow and outflow regions.\n    The horizontal grid has resolution of :math:`2 \\\\times 2` degrees, and the vertical one has 40 levels.\n\n    Wind forcing over the sector part and buoyancy relaxation drive a large-scale meridional overturning circulation.\n\n    This setup demonstrates:\n     - setting up an idealized geometry after `(Munday et al., 2013) <https://doi.org/10.1175/JPO-D-12-095.1>`_.\n     - modifing surface forcings over selected regions of the domain\n     - sensitivity of circumpolar transport and meridional overturning \n       to changes in Southern Ocean wind stress and buoyancy anomalies\n     - basic usage of diagnostics\n\n    :doc:`Adapted from ACC channel model </reference/setups/acc>`.\n\n    Reference:\n\tLaurits S. Andreasen. (2019). Time scales of the Bipolar seesaw: The role of oceanic cross-hemisphere signals,\n        Southern Ocean eddies and wind changes, MSc Thesis, 42p.\n        `<https://sid.erda.dk/share_redirect/CVvcrowL22/Thesis/Laurits_Andreasen_MSc_thesis.pdf>`_.\n\n    """"""\n    max_depth = 4000.\n\n    @veros_method\n    def set_parameter(self, vs):\n        vs.identifier = \'acc_sector\'\n\n        vs.nx, vs.ny, vs.nz = 15, 62, 40\n        vs.dt_mom = 3600.\n        vs.dt_tracer = 3600.\n        vs.runlen = 86400 * 365\n\n        vs.coord_degree = True\n        vs.enable_cyclic_x = True\n\n        vs.congr_epsilon = 1e-12\n        vs.congr_max_iterations = 5000\n\n        vs.enable_neutral_diffusion = True\n        vs.K_iso_0 = 1000.0\n        vs.K_iso_steep = 500.0\n        vs.iso_dslope = 0.005\n        vs.iso_slopec = 0.01\n        vs.enable_skew_diffusion = True\n\n        vs.enable_hor_friction = True\n        vs.A_h = 5e4 * 2\n        vs.enable_hor_friction_cos_scaling = True\n        vs.hor_friction_cosPower = 1\n\n        vs.enable_bottom_friction = True\n        vs.r_bot = 1e-5\n\n        vs.enable_implicit_vert_friction = True\n\n        vs.enable_tke = True\n        vs.c_k = 0.1\n        vs.c_eps = 0.7\n        vs.alpha_tke = 30.0\n        vs.mxl_min = 1e-8\n        vs.tke_mxl_choice = 2\n        vs.kappaM_min = 2e-4\n        vs.kappaH_min = 2e-5\n        vs.enable_Prandtl_tke = False\n        vs.enable_kappaH_profile = True\n        # vs.enable_tke_superbee_advection = True\n\n        vs.K_gm_0 = 1300.0\n        vs.enable_eke = False\n        vs.eke_k_max = 1e4\n        vs.eke_c_k = 0.4\n        vs.eke_c_eps = 0.5\n        vs.eke_cross = 2.\n        vs.eke_crhin = 1.0\n        vs.eke_lmin = 100.0\n        vs.enable_eke_superbee_advection = False\n        vs.enable_eke_isopycnal_diffusion = False\n\n        vs.enable_idemix = False\n        vs.enable_idemix_hor_diffusion = False\n        vs.enable_eke_diss_surfbot = False\n        vs.eke_diss_surfbot_frac = 0.2\n        vs.enable_idemix_superbee_advection = False\n\n        vs.eq_of_state_type = 3\n\n    @veros_method\n    def set_grid(self, vs):\n        # keep total domain size constant when nx or ny changes\n        vs.dxt[...] = 2.0 * 15 / vs.nx\n        vs.dyt[...] = 2.0 * 62 / vs.ny\n\n        vs.x_origin = 0.0\n        vs.y_origin = -60.0\n\n        vs.dzt[...] = veros.tools.get_vinokur_grid_steps(vs.nz, self.max_depth, 10., refine_towards=\'lower\')\n\n    @veros_method\n    def set_coriolis(self, vs):\n        vs.coriolis_t[:, :] = 2 * vs.omega * np.sin(vs.yt[None, :] / 180. * vs.pi)\n\n    @veros_method\n    def set_topography(self, vs):\n        x, y = np.meshgrid(vs.xt, vs.yt, indexing=\'ij\')\n        vs.kbot = np.logical_or((x > 1.0) & (x < 27), y < -40).astype(np.int)\n\n        # A half depth (ridge) is appended to the domain within the confines\n        # of the circumpolar channel at the inflow and outflow regions\n        bathymetry = np.logical_or(((x <= 1.0) & (y < -40)), ((x >= 27) & (y < -40)))\n        kzt2000 = np.sum((vs.zt < -2000.).astype(np.int))\n        vs.kbot[bathymetry] = kzt2000\n\n    @veros_method\n    def set_initial_conditions(self, vs):\n        # initial conditions\n        vs.temp[:, :, :, 0:2] = ((1 - vs.zt[None, None, :] / vs.zw[0]) * 15 * vs.maskT)[..., None]\n        vs.salt[:, :, :, 0:2] = 35.0 * vs.maskT[..., None]\n\n        # wind stress forcing\n        yt_min = global_min(vs, vs.yt.min())\n        yu_min = global_min(vs, vs.yu.min())\n        yt_max = global_max(vs, vs.yt.max())\n        yu_max = global_max(vs, vs.yu.max())\n\n        taux = allocate(vs, (\'yt\',))\n        north = vs.yt > 30\n        subequatorial_north_n = (vs.yt >= 15) & (vs.yt < 30)\n        subequatorial_north_s = (vs.yt > 0) & (vs.yt < 15)\n        equator = (vs.yt > -5) & (vs.yt < 5)\n        subequatorial_south_n = (vs.yt > -15) & (vs.yt < 0)\n        subequatorial_south_s = (vs.yt <= -15) & (vs.yt > -30)\n        south = vs.yt < -30\n\n        taux[north] = -5e-2 * np.sin(np.pi * (vs.yu[north] - yu_max) / (yt_max - 30.))\n        taux[subequatorial_north_s] =  5e-2 * np.sin(np.pi * (vs.yu[subequatorial_north_s] - 30.) / 30.)\n        taux[subequatorial_north_n] = 5e-2 * np.sin(np.pi * (vs.yt[subequatorial_north_n] - 30.) / 30.)\n        taux[subequatorial_south_n] =  -5e-2 * np.sin(np.pi * (vs.yu[subequatorial_south_n] - 30.) / 30.)\n        taux[subequatorial_south_s] = -5e-2 * np.sin(np.pi * (vs.yt[subequatorial_south_s] - 30.) / 30.)\n        taux[equator] = -1.5e-2 * np.cos(np.pi * (vs.yu[equator] - 10.) / 10.) - 2.5e-2\n        taux[south] = 15e-2 * np.sin(np.pi * (vs.yu[south] - yu_min) / (-30. - yt_min))\n        vs.surface_taux[:, :] = taux * vs.maskU[:, :, -1]\n\n        # surface heatflux forcing\n        DELTA_T, TS, TN = 25., 0., 5.\n        vs._t_star = allocate(vs, (\'yt\',), fill=DELTA_T)\n        vs._t_star[vs.yt<0] = TS + DELTA_T * np.sin(np.pi * (vs.yt[vs.yt<0] + 60.) / np.abs(2 * vs.y_origin))\n        vs._t_star[vs.yt>0] = TN + (DELTA_T + TS - TN) * np.sin(np.pi * (vs.yt[vs.yt>0] + 60.) / np.abs(2 * vs.y_origin))\n        vs._t_rest = vs.dzt[None, -1] / (10. * 86400.) * vs.maskT[:, :, -1]\n\n        if vs.enable_tke:\n            vs.forc_tke_surface[2:-2, 2:-2] = np.sqrt((0.5 * (vs.surface_taux[2:-2, 2:-2] + vs.surface_taux[1:-3, 2:-2]) / vs.rho_0)**2\n                                                      + (0.5 * (vs.surface_tauy[2:-2, 2:-2] + vs.surface_tauy[2:-2, 1:-3]) / vs.rho_0)**2)**(1.5)\n\n        if vs.enable_idemix:\n            vs.forc_iw_bottom[...] = 1e-6 * vs.maskW[:, :, -1]\n            vs.forc_iw_surface[...] = 1e-7 * vs.maskW[:, :, -1]\n\n    @veros_method\n    def set_forcing(self, vs):\n        vs.forc_temp_surface[...] = vs._t_rest * (vs._t_star - vs.temp[:, :, -1, vs.tau])\n\n    @veros_method\n    def set_diagnostics(self, vs):\n        vs.diagnostics[\'snapshot\'].output_frequency = 86400 * 10\n        vs.diagnostics[\'averages\'].output_variables = (\n            \'salt\', \'temp\', \'u\', \'v\', \'w\', \'psi\', \'rho\', \'surface_taux\', \'surface_tauy\'\n        )\n        vs.diagnostics[\'averages\'].output_frequency = 365 * 86400.\n        vs.diagnostics[\'averages\'].sampling_frequency = vs.dt_tracer * 10\n        vs.diagnostics[\'overturning\'].output_frequency = 365 * 86400. / 48.\n        vs.diagnostics[\'overturning\'].sampling_frequency = vs.dt_tracer * 10\n        vs.diagnostics[\'tracer_monitor\'].output_frequency = 365 * 86400. / 12.\n        vs.diagnostics[\'energy\'].output_frequency = 365 * 86400. / 48\n        vs.diagnostics[\'energy\'].sampling_frequency = vs.dt_tracer * 10\n\n    def after_timestep(self, vs):\n        pass\n\n\n@veros.tools.cli\ndef run(*args, **kwargs):\n    simulation = ACCSectorSetup(*args, **kwargs)\n    simulation.setup()\n    simulation.run()\n\n\nif __name__ == \'__main__\':\n    run()\n'"
veros/setup/global_1deg/__init__.py,0,b'from veros.setup.global_1deg.global_one_degree import GlobalOneDegreeSetup\n'
veros/setup/global_1deg/global_one_degree.py,11,"b'#!/usr/bin/env python\n\nimport os\nimport h5netcdf\n\nfrom veros import VerosSetup, tools, veros_method, time\nfrom veros.variables import Variable, allocate\n\nBASE_PATH = os.path.dirname(os.path.realpath(__file__))\nDATA_FILES = tools.get_assets(\'global_1deg\', os.path.join(BASE_PATH, \'assets.yml\'))\n\n\nclass GlobalOneDegreeSetup(VerosSetup):\n    """"""Global 1 degree model with 115 vertical levels.\n\n    `Adapted from pyOM2 <https://wiki.zmaw.de/ifm/TO/pyOM2/1x1%20global%20model>`_.\n    """"""\n\n    @veros_method\n    def set_parameter(self, vs):\n        """"""\n        set main parameters\n        """"""\n        vs.nx = 360\n        vs.ny = 160\n        vs.nz = 115\n        vs.dt_mom = 1800.0\n        vs.dt_tracer = 1800.0\n        vs.runlen = 0.\n\n        vs.coord_degree = True\n        vs.enable_cyclic_x = True\n\n        vs.congr_epsilon = 1e-10\n        vs.congr_max_iterations = 10000\n\n        vs.enable_hor_friction = True\n        vs.A_h = 5e4\n        vs.enable_hor_friction_cos_scaling = True\n        vs.hor_friction_cosPower = 1\n        vs.enable_tempsalt_sources = True\n        vs.enable_implicit_vert_friction = True\n\n        vs.eq_of_state_type = 5\n\n        # isoneutral\n        vs.enable_neutral_diffusion = True\n        vs.K_iso_0 = 1000.0\n        vs.K_iso_steep = 50.0\n        vs.iso_dslope = 0.005\n        vs.iso_slopec = 0.005\n        vs.enable_skew_diffusion = True\n\n        # tke\n        vs.enable_tke = True\n        vs.c_k = 0.1\n        vs.c_eps = 0.7\n        vs.alpha_tke = 30.0\n        vs.mxl_min = 1e-8\n        vs.tke_mxl_choice = 2\n        vs.kappaM_min = 2e-4\n        vs.kappaH_min = 2e-5\n        vs.enable_kappaH_profile = True\n        vs.enable_tke_superbee_advection = True\n\n        # eke\n        vs.enable_eke = True\n        vs.eke_k_max = 1e4\n        vs.eke_c_k = 0.4\n        vs.eke_c_eps = 0.5\n        vs.eke_cross = 2.\n        vs.eke_crhin = 1.0\n        vs.eke_lmin = 100.0\n        vs.enable_eke_superbee_advection = True\n        vs.enable_eke_isopycnal_diffusion = True\n\n        # idemix\n        vs.enable_idemix = False\n        vs.enable_eke_diss_surfbot = True\n        vs.eke_diss_surfbot_frac = 0.2\n        vs.enable_idemix_superbee_advection = True\n        vs.enable_idemix_hor_diffusion = True\n\n        # custom variables\n        vs.nmonths = 12\n        vs.variables.update(\n            t_star=Variable(\'t_star\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            s_star=Variable(\'s_star\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            qnec=Variable(\'qnec\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            qnet=Variable(\'qnet\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            qsol=Variable(\'qsol\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            divpen_shortwave=Variable(\'divpen_shortwave\', (\'zt\',), \'\', \'\', time_dependent=False),\n            taux=Variable(\'taux\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            tauy=Variable(\'tauy\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n        )\n\n    @veros_method\n    def _read_forcing(self, vs, var):\n        with h5netcdf.File(DATA_FILES[\'forcing\'], \'r\') as infile:\n            var = infile.variables[var]\n            return np.array(var, dtype=str(var.dtype)).T\n\n    @veros_method\n    def set_grid(self, vs):\n        dz_data = self._read_forcing(vs, \'dz\')\n        vs.dzt[...] = dz_data[::-1]\n        vs.dxt[...] = 1.0\n        vs.dyt[...] = 1.0\n        vs.y_origin = -79.\n        vs.x_origin = 91.\n\n    @veros_method\n    def set_coriolis(self, vs):\n        vs.coriolis_t[...] = 2 * vs.omega * np.sin(vs.yt[np.newaxis, :] / 180. * vs.pi)\n\n    @veros_method(dist_safe=False, local_variables=[\'kbot\'])\n    def set_topography(self, vs):\n        bathymetry_data = self._read_forcing(vs, \'bathymetry\')\n        salt_data = self._read_forcing(vs, \'salinity\')[:, :, ::-1]\n\n        mask_salt = salt_data == 0.\n        vs.kbot[2:-2, 2:-2] = 1 + np.sum(mask_salt.astype(np.int), axis=2)\n\n        mask_bathy = bathymetry_data == 0\n        vs.kbot[2:-2, 2:-2][mask_bathy] = 0\n\n        vs.kbot[vs.kbot >= vs.nz] = 0\n\n        # close some channels\n        i, j = np.indices((vs.nx, vs.ny))\n\n        mask_channel = (i >= 207) & (i < 214) & (j < 5)  # i = 208,214; j = 1,5\n        vs.kbot[2:-2, 2:-2][mask_channel] = 0\n\n        # Aleutian islands\n        mask_channel = (i == 104) & (j == 134)  # i = 105; j = 135\n        vs.kbot[2:-2, 2:-2][mask_channel] = 0\n\n        # Engl channel\n        mask_channel = (i >= 269) & (i < 271) & (j == 130)  # i = 270,271; j = 131\n        vs.kbot[2:-2, 2:-2][mask_channel] = 0\n\n    @veros_method(dist_safe=False, local_variables=[\n        \'t_star\', \'s_star\', \'qnec\', \'qnet\', \'qsol\', \'divpen_shortwave\', \'taux\', \'tauy\',\n        \'temp\', \'salt\', \'forc_iw_bottom\', \'forc_iw_surface\', \'kbot\', \'maskT\', \'maskW\',\n        \'zw\', \'dzt\'\n    ])\n    def set_initial_conditions(self, vs):\n        rpart_shortwave = 0.58\n        efold1_shortwave = 0.35\n        efold2_shortwave = 23.0\n\n        # initial conditions\n        temp_data = self._read_forcing(vs, \'temperature\')\n        vs.temp[2:-2, 2:-2, :, 0] = temp_data[..., ::-1] * vs.maskT[2:-2, 2:-2, :]\n        vs.temp[2:-2, 2:-2, :, 1] = temp_data[..., ::-1] * vs.maskT[2:-2, 2:-2, :]\n\n        salt_data = self._read_forcing(vs, \'salinity\')\n        vs.salt[2:-2, 2:-2, :, 0] = salt_data[..., ::-1] * vs.maskT[2:-2, 2:-2, :]\n        vs.salt[2:-2, 2:-2, :, 1] = salt_data[..., ::-1] * vs.maskT[2:-2, 2:-2, :]\n\n        # wind stress on MIT grid\n        vs.taux[2:-2, 2:-2, :] = self._read_forcing(vs, \'tau_x\')\n        vs.tauy[2:-2, 2:-2, :] = self._read_forcing(vs, \'tau_y\')\n\n        qnec_data = self._read_forcing(vs, \'dqdt\')\n        vs.qnec[2:-2, 2:-2, :] = qnec_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        qsol_data = self._read_forcing(vs, \'swf\')\n        vs.qsol[2:-2, 2:-2, :] = -qsol_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        # SST and SSS\n        sst_data = self._read_forcing(vs, \'sst\')\n        vs.t_star[2:-2, 2:-2, :] = sst_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        sss_data = self._read_forcing(vs, \'sss\')\n        vs.s_star[2:-2, 2:-2, :] = sss_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        if vs.enable_idemix:\n            tidal_energy_data = self._read_forcing(vs, \'tidal_energy\')\n            mask = np.maximum(0, vs.kbot[2:-2, 2:-2] - 1)[:, :, np.newaxis] == np.arange(vs.nz)[np.newaxis, np.newaxis, :]\n            tidal_energy_data[:, :] *= vs.maskW[2:-2, 2:-2, :][mask].reshape(vs.nx, vs.ny) / vs.rho_0\n            vs.forc_iw_bottom[2:-2, 2:-2] = tidal_energy_data\n\n            wind_energy_data = self._read_forcing(vs, \'wind_energy\')\n            wind_energy_data[:, :] *= vs.maskW[2:-2, 2:-2, -1] / vs.rho_0 * 0.2\n            vs.forc_iw_surface[2:-2, 2:-2] = wind_energy_data\n\n        """"""\n        Initialize penetration profile for solar radiation and store divergence in divpen\n        note that pen is set to 0.0 at the surface instead of 1.0 to compensate for the\n        shortwave part of the total surface flux\n        """"""\n        swarg1 = vs.zw / efold1_shortwave\n        swarg2 = vs.zw / efold2_shortwave\n        pen = rpart_shortwave * np.exp(swarg1) + (1.0 - rpart_shortwave) * np.exp(swarg2)\n        pen[-1] = 0.\n        vs.divpen_shortwave = allocate(vs, (\'zt\',))\n        vs.divpen_shortwave[1:] = (pen[1:] - pen[:-1]) / vs.dzt[1:]\n        vs.divpen_shortwave[0] = pen[0] / vs.dzt[0]\n\n    @veros_method\n    def set_forcing(self, vs):\n        t_rest = 30. * 86400.\n        cp_0 = 3991.86795711963  # J/kg /K\n\n        year_in_seconds = time.convert_time(1., \'years\', \'seconds\')\n        (n1, f1), (n2, f2) = tools.get_periodic_interval(vs.time, year_in_seconds,\n                                                         year_in_seconds / 12., 12)\n\n        # linearly interpolate wind stress and shift from MITgcm U/V grid to this grid\n        vs.surface_taux[:-1, :] = f1 * vs.taux[1:, :, n1] + f2 * vs.taux[1:, :, n2]\n        vs.surface_tauy[:, :-1] = f1 * vs.tauy[:, 1:, n1] + f2 * vs.tauy[:, 1:, n2]\n\n        if vs.enable_tke:\n            vs.forc_tke_surface[1:-1, 1:-1] = np.sqrt((0.5 * (vs.surface_taux[1:-1, 1:-1] \\\n                                                                + vs.surface_taux[:-2, 1:-1]) / vs.rho_0) ** 2\n                                                      + (0.5 * (vs.surface_tauy[1:-1, 1:-1] \\\n                                                                + vs.surface_tauy[1:-1, :-2]) / vs.rho_0) ** 2) ** (3. / 2.)\n\n        # W/m^2 K kg/J m^3/kg = K m/s\n        t_star_cur = f1 * vs.t_star[..., n1] + f2 * vs.t_star[..., n2]\n        vs.qqnec = f1 * vs.qnec[..., n1] + f2 * vs.qnec[..., n2]\n        vs.qqnet = f1 * vs.qnet[..., n1] + f2 * vs.qnet[..., n2]\n        vs.forc_temp_surface[...] = (vs.qqnet + vs.qqnec * (t_star_cur - vs.temp[..., -1, vs.tau])) \\\n            * vs.maskT[..., -1] / cp_0 / vs.rho_0\n        s_star_cur = f1 * vs.s_star[..., n1] + f2 * vs.s_star[..., n2]\n        vs.forc_salt_surface[...] = 1. / t_rest * \\\n            (s_star_cur - vs.salt[..., -1, vs.tau]) * vs.maskT[..., -1] * vs.dzt[-1]\n\n        # apply simple ice mask\n        mask1 = vs.temp[:, :, -1, vs.tau] * vs.maskT[:, :, -1] <= -1.8\n        mask2 = vs.forc_temp_surface <= 0\n        ice = ~(mask1 & mask2)\n        vs.forc_temp_surface *= ice\n        vs.forc_salt_surface *= ice\n\n        # solar radiation\n        if vs.enable_tempsalt_sources:\n            vs.temp_source[..., :] = (f1 * vs.qsol[..., n1, None] + f2 * vs.qsol[..., n2, None]) \\\n                * vs.divpen_shortwave[None, None, :] * ice[..., None] \\\n                * vs.maskT[..., :] / cp_0 / vs.rho_0\n\n    @veros_method\n    def set_diagnostics(self, vs):\n        average_vars = [\'surface_taux\', \'surface_tauy\', \'forc_temp_surface\', \'forc_salt_surface\',\n                        \'psi\', \'temp\', \'salt\', \'u\', \'v\', \'w\', \'Nsqr\', \'Hd\', \'rho\',\n                        \'K_diss_v\', \'P_diss_v\', \'P_diss_nonlin\', \'P_diss_iso\', \'kappaH\']\n        if vs.enable_skew_diffusion:\n            average_vars += [\'B1_gm\', \'B2_gm\']\n        if vs.enable_TEM_friction:\n            average_vars += [\'kappa_gm\', \'K_diss_gm\']\n        if vs.enable_tke:\n            average_vars += [\'tke\', \'Prandtlnumber\', \'mxl\', \'tke_diss\',\n                             \'forc_tke_surface\', \'tke_surf_corr\']\n        if vs.enable_idemix:\n            average_vars += [\'E_iw\', \'forc_iw_surface\', \'forc_iw_bottom\', \'iw_diss\',\n                             \'c0\', \'v0\']\n        if vs.enable_eke:\n            average_vars += [\'eke\', \'K_gm\', \'L_rossby\', \'L_rhines\']\n\n        vs.diagnostics[\'averages\'].output_variables = average_vars\n        vs.diagnostics[\'cfl_monitor\'].output_frequency = 86400.0\n        vs.diagnostics[\'snapshot\'].output_frequency = 365 * 86400 / 24.\n        vs.diagnostics[\'overturning\'].output_frequency = 365 * 86400\n        vs.diagnostics[\'overturning\'].sampling_frequency = 365 * 86400 / 24.\n        vs.diagnostics[\'energy\'].output_frequency = 365 * 86400\n        vs.diagnostics[\'energy\'].sampling_frequency = 365 * 86400 / 24.\n        vs.diagnostics[\'averages\'].output_frequency = 365 * 86400\n        vs.diagnostics[\'averages\'].sampling_frequency = 365 * 86400 / 24.\n\n    @veros_method\n    def after_timestep(self, vs):\n        pass\n\n\n@tools.cli\ndef run(*args, **kwargs):\n    simulation = GlobalOneDegreeSetup(*args, **kwargs)\n    simulation.setup()\n    simulation.run()\n\n\nif __name__ == \'__main__\':\n    run()\n'"
veros/setup/global_4deg/__init__.py,0,b'from veros.setup.global_4deg.global_four_degree import GlobalFourDegreeSetup\n'
veros/setup/global_4deg/global_four_degree.py,14,"b'#!/usr/bin/env python\n\nimport os\n\nimport h5netcdf\n\nfrom veros import VerosSetup, veros_method\nfrom veros.variables import Variable\nimport veros.tools\n\nBASE_PATH = os.path.dirname(os.path.realpath(__file__))\nDATA_FILES = veros.tools.get_assets(\n    \'global_4deg\',\n    os.path.join(BASE_PATH, \'assets.yml\')\n)\n\n\nclass GlobalFourDegreeSetup(VerosSetup):\n    """"""Global 4 degree model with 15 vertical levels.\n\n    This setup demonstrates:\n     - setting up a realistic model\n     - reading input data from external files\n     - including Indonesian throughflow\n     - implementing surface forcings\n     - applying a simple ice mask\n\n    `Adapted from pyOM2 <https://wiki.cen.uni-hamburg.de/ifm/TO/pyOM2/4x4%20global%20model>`_.\n\n    ChangeLog\n     - 07-05-2020: modify bathymetry in order to include Indonesian throughflow;\n       courtesy of Franka Jesse, Utrecht University\n    """"""\n    @veros_method\n    def set_parameter(self, vs):\n        vs.identifier = \'4deg\'\n\n        vs.nx, vs.ny, vs.nz = 90, 40, 15\n        vs.dt_mom = 1800.0\n        vs.dt_tracer = 86400.0\n        vs.runlen = 0.\n\n        vs.coord_degree = True\n        vs.enable_cyclic_x = True\n\n        vs.congr_epsilon = 1e-8\n        vs.congr_max_iterations = 20000\n\n        vs.enable_neutral_diffusion = True\n        vs.K_iso_0 = 1000.0\n        vs.K_iso_steep = 1000.0\n        vs.iso_dslope = 4. / 1000.0\n        vs.iso_slopec = 1. / 1000.0\n        vs.enable_skew_diffusion = True\n\n        vs.enable_hor_friction = True\n        vs.A_h = (4 * vs.degtom)**3 * 2e-11\n        vs.enable_hor_friction_cos_scaling = True\n        vs.hor_friction_cosPower = 1\n\n        vs.enable_implicit_vert_friction = True\n        vs.enable_tke = True\n        vs.c_k = 0.1\n        vs.c_eps = 0.7\n        vs.alpha_tke = 30.0\n        vs.mxl_min = 1e-8\n        vs.tke_mxl_choice = 2\n        vs.kappaM_min = 2e-4\n        vs.kappaH_min = 2e-5\n        vs.enable_kappaH_profile = True\n        vs.enable_tke_superbee_advection = True\n\n        vs.enable_eke = True\n        vs.eke_k_max = 1e4\n        vs.eke_c_k = 0.4\n        vs.eke_c_eps = 0.5\n        vs.eke_cross = 2.\n        vs.eke_crhin = 1.0\n        vs.eke_lmin = 100.0\n        vs.enable_eke_superbee_advection = True\n\n        vs.enable_idemix = False\n        vs.enable_idemix_hor_diffusion = True\n        vs.enable_eke_diss_surfbot = True\n        vs.eke_diss_surfbot_frac = 0.2\n        vs.enable_idemix_superbee_advection = True\n\n        vs.eq_of_state_type = 5\n\n        # custom variables\n        vs.nmonths = 12\n        vs.variables.update(\n            sss_clim=Variable(\'sss_clim\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            sst_clim=Variable(\'sst_clim\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            qnec=Variable(\'qnec\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            qnet=Variable(\'qnet\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            taux=Variable(\'taux\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            tauy=Variable(\'tauy\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n        )\n\n    @veros_method\n    def _read_forcing(self, vs, var):\n        with h5netcdf.File(DATA_FILES[\'forcing\'], \'r\') as infile:\n            var_obj = infile.variables[var]\n            return np.array(var_obj, dtype=str(var_obj.dtype)).T\n\n    @veros_method\n    def set_grid(self, vs):\n        ddz = np.array([50., 70., 100., 140., 190., 240., 290., 340.,\n                        390., 440., 490., 540., 590., 640., 690.])\n        vs.dzt[:] = ddz[::-1]\n        vs.dxt[:] = 4.0\n        vs.dyt[:] = 4.0\n        vs.y_origin = -76.0\n        vs.x_origin = 4.0\n\n    @veros_method\n    def set_coriolis(self, vs):\n        vs.coriolis_t[...] = 2 * vs.omega * np.sin(vs.yt[np.newaxis, :] / 180. * vs.pi)\n\n    @veros_method(dist_safe=False, local_variables=[\n        \'kbot\', \'zt\'\n    ])\n    def set_topography(self, vs):\n        bathymetry_data = self._read_forcing(vs, \'bathymetry\')\n        salt_data = self._read_forcing(vs, \'salinity\')[:, :, ::-1]\n        salt_data[vs.zt[np.newaxis, np.newaxis, :] <= bathymetry_data[..., np.newaxis]] = 0.\n        mask_salt = salt_data == 0.\n        vs.kbot[2:-2, 2:-2] = 1 + np.sum(mask_salt.astype(np.int), axis=2)\n        mask_bathy = bathymetry_data == 0\n        vs.kbot[2:-2, 2:-2][mask_bathy] = 0\n        vs.kbot[vs.kbot == vs.nz] = 0\n\n    @veros_method(dist_safe=False, local_variables=[\n        \'taux\', \'tauy\', \'qnec\', \'qnet\', \'sss_clim\', \'sst_clim\',\n        \'temp\', \'salt\', \'taux\', \'tauy\', \'area_t\', \'maskT\',\n        \'forc_iw_bottom\', \'forc_iw_surface\'\n    ])\n    def set_initial_conditions(self, vs):\n        # initial conditions for T and S\n        temp_data = self._read_forcing(vs, \'temperature\')[:, :, ::-1]\n        vs.temp[2:-2, 2:-2, :, :2] = temp_data[:, :, :, np.newaxis] * \\\n            vs.maskT[2:-2, 2:-2, :, np.newaxis]\n\n        salt_data = self._read_forcing(vs, \'salinity\')[:, :, ::-1]\n        vs.salt[2:-2, 2:-2, :, :2] = salt_data[..., np.newaxis] * vs.maskT[2:-2, 2:-2, :, np.newaxis]\n\n        # use Trenberth wind stress from MITgcm instead of ECMWF (also contained in ecmwf_4deg.cdf)\n        vs.taux[2:-2, 2:-2, :] = self._read_forcing(vs, \'tau_x\')\n        vs.tauy[2:-2, 2:-2, :] = self._read_forcing(vs, \'tau_y\')\n\n        # heat flux\n        with h5netcdf.File(DATA_FILES[\'ecmwf\'], \'r\') as ecmwf_data:\n            qnec_var = ecmwf_data.variables[\'Q3\']\n            vs.qnec[2:-2, 2:-2, :] = np.array(qnec_var, dtype=str(qnec_var.dtype)).transpose()\n            vs.qnec[vs.qnec <= -1e10] = 0.0\n\n        q = self._read_forcing(vs, \'q_net\')\n        vs.qnet[2:-2, 2:-2, :] = -q\n        vs.qnet[vs.qnet <= -1e10] = 0.0\n\n        fxa = np.sum(vs.qnet[2:-2, 2:-2, :] * vs.area_t[2:-2, 2:-2, np.newaxis]) \\\n              / 12 / np.sum(vs.area_t[2:-2, 2:-2])\n        print(\' removing an annual mean heat flux imbalance of %e W/m^2\' % fxa)\n        vs.qnet[...] = (vs.qnet - fxa) * vs.maskT[:, :, -1, np.newaxis]\n\n        # SST and SSS\n        vs.sst_clim[2:-2, 2:-2, :] = self._read_forcing(vs, \'sst\')\n        vs.sss_clim[2:-2, 2:-2, :] = self._read_forcing(vs, \'sss\')\n\n        if vs.enable_idemix:\n            vs.forc_iw_bottom[2:-2, 2:-2] = self._read_forcing(vs, \'tidal_energy\') / vs.rho_0\n            vs.forc_iw_surface[2:-2, 2:-2] = self._read_forcing(vs, \'wind_energy\') / vs.rho_0 * 0.2\n\n    @veros_method\n    def set_forcing(self, vs):\n        year_in_seconds = 360 * 86400.\n        (n1, f1), (n2, f2) = veros.tools.get_periodic_interval(\n            vs.time, year_in_seconds, year_in_seconds / 12., 12\n        )\n\n        # wind stress\n        vs.surface_taux[...] = (f1 * vs.taux[:, :, n1] + f2 * vs.taux[:, :, n2])\n        vs.surface_tauy[...] = (f1 * vs.tauy[:, :, n1] + f2 * vs.tauy[:, :, n2])\n\n        # tke flux\n        if vs.enable_tke:\n            vs.forc_tke_surface[1:-1, 1:-1] = np.sqrt((0.5 * (vs.surface_taux[1:-1, 1:-1]\n                                                                + vs.surface_taux[:-2, 1:-1]) / vs.rho_0)**2\n                                                      + (0.5 * (vs.surface_tauy[1:-1, 1:-1]\n                                                                + vs.surface_tauy[1:-1, :-2]) / vs.rho_0)**2)**(3. / 2.)\n        # heat flux : W/m^2 K kg/J m^3/kg = K m/s\n        cp_0 = 3991.86795711963\n        sst = f1 * vs.sst_clim[:, :, n1] + f2 * vs.sst_clim[:, :, n2]\n        qnec = f1 * vs.qnec[:, :, n1] + f2 * vs.qnec[:, :, n2]\n        qnet = f1 * vs.qnet[:, :, n1] + f2 * vs.qnet[:, :, n2]\n        vs.forc_temp_surface[...] = (qnet + qnec * (sst - vs.temp[:, :, -1, vs.tau])) \\\n                                       * vs.maskT[:, :, -1] / cp_0 / vs.rho_0\n\n        # salinity restoring\n        t_rest = 30 * 86400.0\n        sss = f1 * vs.sss_clim[:, :, n1] + f2 * vs.sss_clim[:, :, n2]\n        vs.forc_salt_surface[:] = 1. / t_rest * \\\n            (sss - vs.salt[:, :, -1, vs.tau]) * vs.maskT[:, :, -1] * vs.dzt[-1]\n\n        # apply simple ice mask\n        mask = np.logical_and(vs.temp[:, :, -1, vs.tau] * vs.maskT[:, :, -1] < -1.8,\n                              vs.forc_temp_surface < 0.)\n        vs.forc_temp_surface[mask] = 0.0\n        vs.forc_salt_surface[mask] = 0.0\n\n    @veros.veros_method\n    def set_diagnostics(self, vs):\n        vs.diagnostics[\'snapshot\'].output_frequency = 360 * 86400.\n        vs.diagnostics[\'overturning\'].output_frequency = 360 * 86400.\n        vs.diagnostics[\'overturning\'].sampling_frequency = vs.dt_tracer\n        vs.diagnostics[\'energy\'].output_frequency = 360 * 86400.\n        vs.diagnostics[\'energy\'].sampling_frequency = 86400\n        average_vars = [\'temp\', \'salt\', \'u\', \'v\', \'w\', \'surface_taux\', \'surface_tauy\', \'psi\']\n        vs.diagnostics[\'averages\'].output_variables = average_vars\n        vs.diagnostics[\'averages\'].output_frequency = 360 * 86400.\n        vs.diagnostics[\'averages\'].sampling_frequency = 86400\n\n    @veros_method\n    def after_timestep(self, vs):\n        pass\n\n\n@veros.tools.cli\ndef run(*args, **kwargs):\n    simulation = GlobalFourDegreeSetup(*args, **kwargs)\n    simulation.setup()\n    simulation.run()\n\n\nif __name__ == \'__main__\':\n    run()\n'"
veros/setup/global_flexible/__init__.py,0,b'from veros.setup.global_flexible.global_flexible import GlobalFlexibleResolutionSetup\n'
veros/setup/global_flexible/global_flexible.py,31,"b'#!/usr/bin/env python\n\nimport os\n\nimport numpy as np\nimport h5netcdf\nimport scipy.ndimage\n\nfrom veros import veros_method, VerosSetup, runtime_settings as rs, runtime_state as rst\nfrom veros.variables import Variable, allocate\nimport veros.tools\nfrom veros.core.utilities import enforce_boundaries\n\nBASE_PATH = os.path.dirname(os.path.realpath(__file__))\nDATA_FILES = veros.tools.get_assets(\'global_flexible\', os.path.join(BASE_PATH, \'assets.yml\'))\n\n\nclass GlobalFlexibleResolutionSetup(VerosSetup):\n    """"""\n    Global model with flexible resolution.\n    """"""\n    # global settings\n    min_depth = 10.\n    max_depth = 5400.\n    equatorial_grid_spacing_factor = 0.5\n    polar_grid_spacing_factor = None\n\n    @veros_method\n    def set_parameter(self, vs):\n        vs.identifier = \'UNNAMED\'\n\n        vs.nx = 360\n        vs.ny = 160\n        vs.nz = 60\n        vs.dt_mom = vs.dt_tracer = 900\n        vs.runlen = 86400 * 10\n\n        vs.coord_degree = True\n        vs.enable_cyclic_x = True\n\n        # streamfunction\n        vs.congr_epsilon = 1e-10\n        vs.congr_max_iterations = 1000\n\n        # friction\n        vs.enable_hor_friction = True\n        vs.A_h = 5e4\n        vs.enable_hor_friction_cos_scaling = True\n        vs.hor_friction_cosPower = 1\n        vs.enable_tempsalt_sources = True\n        vs.enable_implicit_vert_friction = True\n\n        vs.eq_of_state_type = 5\n\n        # isoneutral\n        vs.enable_neutral_diffusion = True\n        vs.K_iso_0 = 1000.0\n        vs.K_iso_steep = 50.0\n        vs.iso_dslope = 0.005\n        vs.iso_slopec = 0.005\n        vs.enable_skew_diffusion = True\n\n        # tke\n        vs.enable_tke = True\n        vs.c_k = 0.1\n        vs.c_eps = 0.7\n        vs.alpha_tke = 30.0\n        vs.mxl_min = 1e-8\n        vs.tke_mxl_choice = 2\n        vs.kappaM_min = 2e-4\n        vs.kappaH_min = 2e-5\n        vs.enable_kappaH_profile = True\n        vs.enable_tke_superbee_advection = True\n\n        # eke\n        vs.enable_eke = True\n        vs.eke_k_max = 1e4\n        vs.eke_c_k = 0.4\n        vs.eke_c_eps = 0.5\n        vs.eke_cross = 2.\n        vs.eke_crhin = 1.0\n        vs.eke_lmin = 100.0\n        vs.enable_eke_superbee_advection = True\n        vs.enable_eke_isopycnal_diffusion = True\n\n        # idemix\n        vs.enable_idemix = False\n        vs.enable_eke_diss_surfbot = True\n        vs.eke_diss_surfbot_frac = 0.2\n        vs.enable_idemix_superbee_advection = True\n        vs.enable_idemix_hor_diffusion = True\n\n        # custom variables\n        vs.nmonths = 12\n        vs.variables.update(\n            t_star=Variable(\'t_star\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            s_star=Variable(\'s_star\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            qnec=Variable(\'qnec\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            qnet=Variable(\'qnet\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            qsol=Variable(\'qsol\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            divpen_shortwave=Variable(\'divpen_shortwave\', (\'zt\',), \'\', \'\', time_dependent=False),\n            taux=Variable(\'taux\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            tauy=Variable(\'tauy\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n        )\n\n    @veros_method(inline=True)\n    def _get_data(self, vs, var, idx=None):\n        if idx is None:\n            idx = Ellipsis\n        else:\n            idx = idx[::-1]\n\n        kwargs = {}\n        if rst.proc_num > 1:\n            kwargs.update(\n                driver=\'mpio\',\n                comm=rs.mpi_comm,\n            )\n\n        with h5netcdf.File(DATA_FILES[\'forcing\'], \'r\', **kwargs) as forcing_file:\n            var_obj = forcing_file.variables[var]\n            return np.array(var_obj[idx].astype(str(var_obj.dtype))).T\n\n    @veros_method(dist_safe=False, local_variables=[\n        \'dxt\', \'dyt\', \'dzt\'\n    ])\n    def set_grid(self, vs):\n        if vs.ny % 2:\n            raise ValueError(\'ny has to be an even number of grid cells\')\n\n        vs.dxt[...] = 360. / vs.nx\n\n        if self.equatorial_grid_spacing_factor is not None:\n            eq_spacing = self.equatorial_grid_spacing_factor * 160. / vs.ny\n        else:\n            eq_spacing = None\n\n        if self.polar_grid_spacing_factor is not None:\n            polar_spacing = self.polar_grid_spacing_factor * 160. / vs.ny\n        else:\n            polar_spacing = None\n\n        vs.dyt[2:-2] = veros.tools.get_vinokur_grid_steps(\n            vs.ny, 160., eq_spacing, upper_stepsize=polar_spacing, two_sided_grid=True\n        )\n        vs.dzt[...] = veros.tools.get_vinokur_grid_steps(vs.nz, self.max_depth, self.min_depth, refine_towards=\'lower\')\n        vs.y_origin = -80.\n        vs.x_origin = 90.\n\n    @veros_method\n    def set_coriolis(self, vs):\n        vs.coriolis_t[...] = 2 * vs.omega * np.sin(vs.yt[np.newaxis, :] / 180. * vs.pi)\n\n    @veros_method\n    def _shift_longitude_array(self, vs, lon, arr):\n        wrap_i = np.where((lon[:-1] < vs.xt.min()) & (lon[1:] >= vs.xt.min()))[0][0]\n        new_lon = np.concatenate((lon[wrap_i:-1], lon[:wrap_i] + 360.))\n        new_arr = np.concatenate((arr[wrap_i:-1, ...], arr[:wrap_i, ...]))\n        return new_lon, new_arr\n\n    @veros_method(dist_safe=False, local_variables=[\n        \'kbot\', \'xt\', \'yt\', \'zt\'\n    ])\n    def set_topography(self, vs):\n        with h5netcdf.File(DATA_FILES[\'topography\'], \'r\') as topography_file:\n            topo_x, topo_y, topo_z = (\n                np.array(topography_file.variables[k], dtype=\'float\').T\n                for k in (\'x\', \'y\', \'z\')\n            )\n        topo_z[topo_z > 0] = 0.\n\n        # smooth topography to match grid resolution\n        gaussian_sigma = (0.5 * len(topo_x) / vs.nx, 0.5 * len(topo_y) / vs.ny)\n        topo_z_smoothed = scipy.ndimage.gaussian_filter(topo_z, sigma=gaussian_sigma)\n        topo_z_smoothed[topo_z >= -1] = 0\n\n        topo_x_shifted, topo_z_shifted = self._shift_longitude_array(vs, topo_x, topo_z_smoothed)\n        coords = (vs.xt[2:-2], vs.yt[2:-2])\n        z_interp = allocate(vs, (\'xt\', \'yt\'), local=False)\n        z_interp[2:-2, 2:-2] = veros.tools.interpolate(\n            (topo_x_shifted, topo_y), topo_z_shifted, coords, kind=\'nearest\', fill=False\n        )\n\n        depth_levels = 1 + np.argmin(np.abs(z_interp[:, :, np.newaxis] - vs.zt[np.newaxis, np.newaxis, :]), axis=2)\n        vs.kbot[2:-2, 2:-2] = np.where(z_interp < 0., depth_levels, 0)[2:-2, 2:-2]\n        vs.kbot *= vs.kbot < vs.nz\n\n        enforce_boundaries(vs, vs.kbot)\n\n        # remove marginal seas\n        # (dilate to close 1-cell passages, fill holes, undo dilation)\n        marginal = (\n            scipy.ndimage.binary_erosion(\n                scipy.ndimage.binary_fill_holes(\n                    scipy.ndimage.binary_dilation(vs.kbot == 0)\n                )\n            )\n        )\n\n        vs.kbot[marginal] = 0\n\n    @veros_method\n    def set_initial_conditions(self, vs):\n        rpart_shortwave = 0.58\n        efold1_shortwave = 0.35\n        efold2_shortwave = 23.0\n\n        t_grid = (vs.xt[2:-2], vs.yt[2:-2], vs.zt)\n        xt_forc, yt_forc, zt_forc = (self._get_data(vs, k) for k in (\'xt\', \'yt\', \'zt\'))\n        zt_forc = zt_forc[::-1]\n\n        # coordinates must be monotonous for this to work\n        assert np.diff(xt_forc).all() > 0\n        assert np.diff(yt_forc).all() > 0\n\n        # determine slice to read from forcing file\n        data_subset = (\n            slice(\n                max(0, int(np.argmax(xt_forc >= vs.xt.min())) - 1),\n                len(xt_forc) - max(0, int(np.argmax(xt_forc[::-1] <= vs.xt.max())) - 1)\n            ),\n            slice(\n                max(0, int(np.argmax(yt_forc >= vs.yt.min())) - 1),\n                len(yt_forc) - max(0, int(np.argmax(yt_forc[::-1] <= vs.yt.max())) - 1)\n            ),\n            Ellipsis\n        )\n\n        xt_forc = xt_forc[data_subset[0]]\n        yt_forc = yt_forc[data_subset[1]]\n\n        # initial conditions\n        temp_raw = self._get_data(vs, \'temperature\', idx=data_subset)[..., ::-1]\n        temp_data = veros.tools.interpolate((xt_forc, yt_forc, zt_forc), temp_raw,\n                                            t_grid)\n        vs.temp[2:-2, 2:-2, :, 0] = temp_data * vs.maskT[2:-2, 2:-2, :]\n        vs.temp[2:-2, 2:-2, :, 1] = temp_data * vs.maskT[2:-2, 2:-2, :]\n\n        salt_raw = self._get_data(vs, \'salinity\', idx=data_subset)[..., ::-1]\n        salt_data = veros.tools.interpolate((xt_forc, yt_forc, zt_forc), salt_raw,\n                                            t_grid)\n        vs.salt[2:-2, 2:-2, :, 0] = salt_data * vs.maskT[2:-2, 2:-2, :]\n        vs.salt[2:-2, 2:-2, :, 1] = salt_data * vs.maskT[2:-2, 2:-2, :]\n\n        # wind stress on MIT grid\n        time_grid = (vs.xt[2:-2], vs.yt[2:-2], np.arange(12))\n        taux_raw = self._get_data(vs, \'tau_x\', idx=data_subset)\n        taux_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                            taux_raw, time_grid)\n        vs.taux[2:-2, 2:-2, :] = taux_data\n\n        tauy_raw = self._get_data(vs, \'tau_y\', idx=data_subset)\n        tauy_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                            tauy_raw, time_grid)\n        vs.tauy[2:-2, 2:-2, :] = tauy_data\n\n        enforce_boundaries(vs, vs.taux)\n        enforce_boundaries(vs, vs.tauy)\n\n        # Qnet and dQ/dT and Qsol\n        qnet_raw = self._get_data(vs, \'q_net\', idx=data_subset)\n        qnet_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                            qnet_raw, time_grid)\n        vs.qnet[2:-2, 2:-2, :] = -qnet_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        qnec_raw = self._get_data(vs, \'dqdt\', idx=data_subset)\n        qnec_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                            qnec_raw, time_grid)\n        vs.qnec[2:-2, 2:-2, :] = qnec_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        qsol_raw = self._get_data(vs, \'swf\', idx=data_subset)\n        qsol_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                            qsol_raw, time_grid)\n        vs.qsol[2:-2, 2:-2, :] = -qsol_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        # SST and SSS\n        sst_raw = self._get_data(vs, \'sst\', idx=data_subset)\n        sst_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                           sst_raw, time_grid)\n        vs.t_star[2:-2, 2:-2, :] = sst_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        sss_raw = self._get_data(vs, \'sss\', idx=data_subset)\n        sss_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                           sss_raw, time_grid)\n        vs.s_star[2:-2, 2:-2, :] = sss_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        if vs.enable_idemix:\n            tidal_energy_raw = self._get_data(vs, \'tidal_energy\', idx=data_subset)\n            tidal_energy_data = veros.tools.interpolate(\n                (xt_forc, yt_forc), tidal_energy_raw, t_grid[:-1]\n            )\n            mask_x, mask_y = (i + 2 for i in np.indices((vs.nx, vs.ny)))\n            mask_z = np.maximum(0, vs.kbot[2:-2, 2:-2] - 1)\n            tidal_energy_data[:, :] *= vs.maskW[mask_x, mask_y, mask_z] / vs.rho_0\n            vs.forc_iw_bottom[2:-2, 2:-2] = tidal_energy_data\n\n        """"""\n        Initialize penetration profile for solar radiation and store divergence in divpen\n        note that pen is set to 0.0 at the surface instead of 1.0 to compensate for the\n        shortwave part of the total surface flux\n        """"""\n        swarg1 = vs.zw / efold1_shortwave\n        swarg2 = vs.zw / efold2_shortwave\n        pen = rpart_shortwave * np.exp(swarg1) + (1.0 - rpart_shortwave) * np.exp(swarg2)\n        pen[-1] = 0.\n        vs.divpen_shortwave[1:] = (pen[1:] - pen[:-1]) / vs.dzt[1:]\n        vs.divpen_shortwave[0] = pen[0] / vs.dzt[0]\n\n    @veros_method\n    def set_forcing(self, vs):\n        t_rest = 30. * 86400.\n        cp_0 = 3991.86795711963  # J/kg /K\n\n        year_in_seconds = 360 * 86400.\n        (n1, f1), (n2, f2) = veros.tools.get_periodic_interval(\n            vs.time, year_in_seconds, year_in_seconds / 12., 12\n        )\n\n        vs.surface_taux[...] = f1 * vs.taux[:, :, n1] + f2 * vs.taux[:, :, n2]\n        vs.surface_tauy[...] = f1 * vs.tauy[:, :, n1] + f2 * vs.tauy[:, :, n2]\n\n        if vs.enable_tke:\n            vs.forc_tke_surface[1:-1, 1:-1] = np.sqrt((0.5 * (vs.surface_taux[1:-1, 1:-1] + vs.surface_taux[:-2, 1:-1]) / vs.rho_0) ** 2\n                                                      + (0.5 * (vs.surface_tauy[1:-1, 1:-1] + vs.surface_tauy[1:-1, :-2]) / vs.rho_0) ** 2) ** (3. / 2.)\n\n        # W/m^2 K kg/J m^3/kg = K m/s\n        fxa = f1 * vs.t_star[..., n1] + f2 * vs.t_star[..., n2]\n        vs.qqnec = f1 * vs.qnec[..., n1] + f2 * vs.qnec[..., n2]\n        vs.qqnet = f1 * vs.qnet[..., n1] + f2 * vs.qnet[..., n2]\n        vs.forc_temp_surface[...] = (vs.qqnet + vs.qqnec * (fxa - vs.temp[..., -1, vs.tau])) \\\n            * vs.maskT[..., -1] / cp_0 / vs.rho_0\n        fxa = f1 * vs.s_star[..., n1] + f2 * vs.s_star[..., n2]\n        vs.forc_salt_surface[...] = 1. / t_rest * \\\n            (fxa - vs.salt[..., -1, vs.tau]) * vs.maskT[..., -1] * vs.dzt[-1]\n\n        # apply simple ice mask\n        mask1 = vs.temp[:, :, -1, vs.tau] * vs.maskT[:, :, -1] <= -1.8\n        mask2 = vs.forc_temp_surface <= 0\n        ice = ~(mask1 & mask2)\n        vs.forc_temp_surface[...] *= ice\n        vs.forc_salt_surface[...] *= ice\n\n        # solar radiation\n        if vs.enable_tempsalt_sources:\n            vs.temp_source[..., :] = (f1 * vs.qsol[..., n1, None] + f2 * vs.qsol[..., n2, None]) \\\n                * vs.divpen_shortwave[None, None, :] * ice[..., None] \\\n                * vs.maskT[..., :] / cp_0 / vs.rho_0\n\n    @veros_method\n    def set_diagnostics(self, vs):\n        vs.diagnostics[\'cfl_monitor\'].output_frequency = vs.dt_tracer * 100\n        vs.diagnostics[\'tracer_monitor\'].output_frequency = 86400.\n        vs.diagnostics[\'snapshot\'].output_frequency = 86400.\n        vs.diagnostics[\'overturning\'].output_frequency = 360 * 86400\n        vs.diagnostics[\'overturning\'].sampling_frequency = 86400.\n        vs.diagnostics[\'energy\'].output_frequency = 360 * 86400\n        vs.diagnostics[\'energy\'].sampling_frequency = 86400.\n        vs.diagnostics[\'averages\'].output_frequency = 10 * 86400\n        vs.diagnostics[\'averages\'].sampling_frequency = 3600.\n\n        average_vars = [\'surface_taux\', \'surface_tauy\', \'forc_temp_surface\', \'forc_salt_surface\',\n                        \'psi\', \'temp\', \'salt\', \'u\', \'v\', \'w\', \'Nsqr\', \'Hd\', \'rho\', \'kappaH\']\n        if vs.enable_skew_diffusion:\n            average_vars += [\'B1_gm\', \'B2_gm\']\n        if vs.enable_TEM_friction:\n            average_vars += [\'kappa_gm\', \'K_diss_gm\']\n        if vs.enable_tke:\n            average_vars += [\'tke\', \'Prandtlnumber\', \'mxl\', \'tke_diss\',\n                             \'forc_tke_surface\', \'tke_surf_corr\']\n        if vs.enable_idemix:\n            average_vars += [\'E_iw\', \'forc_iw_surface\', \'iw_diss\',\n                             \'c0\', \'v0\']\n        if vs.enable_eke:\n            average_vars += [\'eke\', \'K_gm\', \'L_rossby\', \'L_rhines\']\n        vs.diagnostics[\'averages\'].output_variables = average_vars\n\n    @veros_method\n    def after_timestep(self, vs):\n        pass\n\n\n@veros.tools.cli\ndef run(*args, **kwargs):\n    simulation = GlobalFlexibleResolutionSetup(*args, **kwargs)\n    simulation.setup()\n    simulation.run()\n\n\nif __name__ == \'__main__\':\n    run()\n'"
veros/setup/north_atlantic/__init__.py,0,b'from veros.setup.north_atlantic.north_atlantic import NorthAtlanticSetup\n'
veros/setup/north_atlantic/north_atlantic.py,8,"b'#!/usr/bin/env python\n\nimport os\n\nimport h5netcdf\nfrom PIL import Image\nimport numpy as np\nimport scipy.spatial\nimport scipy.ndimage\n\nfrom veros import VerosSetup, veros_method\nfrom veros.variables import Variable\nimport veros.tools\n\nBASE_PATH = os.path.dirname(os.path.realpath(__file__))\nDATA_FILES = veros.tools.get_assets(\'north_atlantic\', os.path.join(BASE_PATH, \'assets.yml\'))\nTOPO_MASK_FILE = os.path.join(BASE_PATH, \'topo_mask.png\')\n\n\nclass NorthAtlanticSetup(VerosSetup):\n    """""" A regional model of the North Atlantic, inspired by `Smith et al., 2000`_.\n\n    Forcing and initial conditions are taken from the FLAME PyOM2 setup. Bathymetry\n    data from ETOPO1 (resolution of 1 arcmin).\n\n    Boundary forcings are implemented via sponge layers in the Greenland Sea, by the\n    Strait of Gibraltar, and in the South Atlantic. This setup runs with arbitrary resolution;\n    upon changing the number of grid cells, all forcing files will be interpolated to\n    the new grid. Default resolution corresponds roughly to :math:`0.5 \\\\times 0.25` degrees.\n\n    .. _Smith et al., 2000:\n       http://journals.ametsoc.org/doi/10.1175/1520-0485%282000%29030%3C1532%3ANSOTNA%3E2.0.CO%3B2\n    """"""\n\n    @veros_method\n    def set_parameter(self, vs):\n        vs.identifier = \'na\'\n\n        vs.nx, vs.ny, vs.nz = 250, 350, 50\n        vs.x_origin = -98.\n        vs.y_origin = -18.\n        vs._x_boundary = 17.2\n        vs._y_boundary = 70.\n        vs._max_depth = 5800.\n\n        vs.dt_mom = 3600. / 2.\n        vs.dt_tracer = 3600. / 2.\n        vs.runlen = 86400 * 365. * 10.\n\n        vs.coord_degree = True\n\n        vs.congr_epsilon = 1e-10\n        vs.congr_max_iterations = 20000\n\n        vs.enable_neutral_diffusion = True\n        vs.enable_skew_diffusion = True\n        vs.K_iso_0 = 1000.0\n        vs.K_iso_steep = 200.0\n        vs.iso_dslope = 1. / 1000.0\n        vs.iso_slopec = 4. / 1000.0\n\n        vs.enable_hor_friction = True\n        vs.A_h = 1e3\n        vs.enable_hor_friction_cos_scaling = True\n        vs.hor_friction_cosPower = 1\n        vs.enable_tempsalt_sources = True\n\n        vs.enable_implicit_vert_friction = True\n        vs.enable_tke = True\n        vs.c_k = 0.1\n        vs.c_eps = 0.7\n        vs.alpha_tke = 30.0\n        vs.mxl_min = 1e-8\n        vs.tke_mxl_choice = 2\n        vs.kappaM_min = 2e-4\n        vs.kappaH_min = 2e-5\n        vs.enable_kappaH_profile = True\n\n        vs.K_gm_0 = 1000.0\n\n        vs.enable_eke = False\n        vs.enable_idemix = False\n\n        vs.eq_of_state_type = 5\n\n        vs.variables.update({\n            \'sss_clim\': Variable(\'sss_clim\', (\'xt\', \'yt\', 12), \'g/kg\', \'Monthly sea surface salinity\'),\n            \'sst_clim\': Variable(\'sst_clim\', (\'xt\', \'yt\', 12), \'deg C\', \'Monthly sea surface temperature\'),\n            \'sss_rest\': Variable(\'sss_rest\', (\'xt\', \'yt\', 12), \'g/kg\', \'Monthly sea surface salinity restoring\'),\n            \'sst_rest\': Variable(\'sst_rest\', (\'xt\', \'yt\', 12), \'deg C\', \'Monthly sea surface temperature restoring\'),\n            \'t_star\': Variable(\'t_star\', (\'xt\', \'yt\', \'zt\', 12), \'deg C\', \'Temperature sponge layer forcing\'),\n            \'s_star\': Variable(\'s_star\', (\'xt\', \'yt\', \'zt\', 12), \'g/kg\', \'Salinity sponge layer forcing\'),\n            \'rest_tscl\': Variable(\'rest_tscl\', (\'xt\', \'yt\', \'zt\'), \'1/s\', \'Forcing restoration time scale\'),\n            \'taux\': Variable(\'taux\', (\'xt\', \'yt\', 12), \'N/s^2\', \'Monthly zonal wind stress\'),\n            \'tauy\': Variable(\'tauy\', (\'xt\', \'yt\', 12), \'N/s^2\', \'Monthly meridional wind stress\'),\n        })\n\n    @veros_method\n    def set_grid(self, vs):\n        vs.dxt[2:-2] = (vs._x_boundary - vs.x_origin) / vs.nx\n        vs.dyt[2:-2] = (vs._y_boundary - vs.y_origin) / vs.ny\n        vs.dzt[...] = veros.tools.get_vinokur_grid_steps(vs.nz, vs._max_depth, 10., refine_towards=\'lower\')\n\n    @veros_method\n    def set_coriolis(self, vs):\n        vs.coriolis_t[:, :] = 2 * vs.omega * np.sin(vs.yt[np.newaxis, :] / 180. * vs.pi)\n\n    @veros_method(dist_safe=False, local_variables=[\n        \'kbot\', \'xt\', \'yt\', \'zt\'\n    ])\n    def set_topography(self, vs):\n        with h5netcdf.File(DATA_FILES[\'topography\'], \'r\') as topo_file:\n            topo_x, topo_y, topo_bottom_depth = (\n                self._get_data(vs, topo_file, k) for k in (\'x\', \'y\', \'z\')\n            )\n        topo_mask = np.flipud(np.asarray(Image.open(TOPO_MASK_FILE))).T\n        topo_bottom_depth *= 1 - topo_mask\n        topo_bottom_depth = scipy.ndimage.gaussian_filter(\n            topo_bottom_depth, sigma=(len(topo_x) / vs.nx, len(topo_y) / vs.ny)\n        )\n        interp_coords = np.meshgrid(vs.xt[2:-2], vs.yt[2:-2], indexing=\'ij\')\n        interp_coords = np.rollaxis(np.asarray(interp_coords), 0, 3)\n        z_interp = scipy.interpolate.interpn((topo_x, topo_y), topo_bottom_depth, interp_coords,\n                                             method=\'nearest\', bounds_error=False, fill_value=0)\n        vs.kbot[2:-2, 2:-2] = np.where(z_interp < 0., 1 + np.argmin(np.abs(z_interp[:, :, np.newaxis]\n                                       - vs.zt[np.newaxis, np.newaxis, :]), axis=2), 0)\n        vs.kbot *= vs.kbot < vs.nz\n\n    @veros_method(inline=True)\n    def _get_data(self, vs, f, var):\n        """"""Retrieve variable from h5netcdf file""""""\n        var_obj = f.variables[var]\n        return np.array(var_obj[...].astype(str(var_obj.dtype))).T\n\n    @veros_method(dist_safe=False, local_variables=[\n        \'xt\', \'yt\', \'zt\', \'temp\', \'maskT\', \'salt\', \'taux\', \'tauy\',\n        \'sst_clim\', \'sss_clim\', \'sst_rest\', \'sss_rest\', \'t_star\', \'s_star\', \'rest_tscl\'\n    ])\n    def set_initial_conditions(self, vs):\n        with h5netcdf.File(DATA_FILES[\'forcing\'], \'r\') as forcing_file:\n            t_hor = (vs.xt[2:-2], vs.yt[2:-2])\n            t_grid = (vs.xt[2:-2], vs.yt[2:-2], vs.zt)\n\n            forc_coords = [self._get_data(vs, forcing_file, k) for k in (\'xt\', \'yt\', \'zt\')]\n            forc_coords[0][...] += -360\n            forc_coords[2][...] = -0.01 * forc_coords[2][::-1]\n\n            temp_raw = self._get_data(vs, forcing_file, \'temp_ic\')[..., ::-1]\n            temp = veros.tools.interpolate(\n                forc_coords, temp_raw, t_grid, missing_value=-1e20\n            )\n            vs.temp[2:-2, 2:-2, :, vs.tau] = vs.maskT[2:-2, 2:-2, :] * temp\n\n            salt_raw = self._get_data(vs, forcing_file, \'salt_ic\')[..., ::-1]\n            salt = 35. + 1000 * veros.tools.interpolate(\n                forc_coords, salt_raw, t_grid, missing_value=-1e20\n            )\n            vs.salt[2:-2, 2:-2, :, vs.tau] = vs.maskT[2:-2, 2:-2, :] * salt\n\n            forc_u_coords_hor = [self._get_data(vs, forcing_file, k) for k in (\'xu\', \'yu\')]\n            forc_u_coords_hor[0][...] += -360\n\n            taux = self._get_data(vs, forcing_file, \'taux\')\n            tauy = self._get_data(vs, forcing_file, \'tauy\')\n            for k in range(12):\n                vs.taux[2:-2, 2:-2, k] = veros.tools.interpolate(\n                    forc_u_coords_hor, taux[..., k], t_hor, missing_value=-1e20\n                ) / 10.\n                vs.tauy[2:-2, 2:-2, k] = veros.tools.interpolate(\n                    forc_u_coords_hor, tauy[..., k], t_hor, missing_value=-1e20\n                ) / 10.\n\n            # heat flux and salinity restoring\n\n            sst_clim, sss_clim, sst_rest, sss_rest = [\n                forcing_file.variables[k][...].T for k in (\'sst_clim\', \'sss_clim\', \'sst_rest\', \'sss_rest\')\n            ]\n\n        for k in range(12):\n            vs.sst_clim[2:-2, 2:-2, k] = veros.tools.interpolate(\n                forc_coords[:-1], sst_clim[..., k], t_hor, missing_value=-1e20)\n            vs.sss_clim[2:-2, 2:-2, k] = veros.tools.interpolate(\n                forc_coords[:-1], sss_clim[..., k], t_hor, missing_value=-1e20) * 1000 + 35\n            vs.sst_rest[2:-2, 2:-2, k] = veros.tools.interpolate(\n                forc_coords[:-1], sst_rest[..., k], t_hor, missing_value=-1e20) * 41868.\n            vs.sss_rest[2:-2, 2:-2, k] = veros.tools.interpolate(\n                forc_coords[:-1], sss_rest[..., k], t_hor, missing_value=-1e20) / 100.\n\n        with h5netcdf.File(DATA_FILES[\'restoring\'], \'r\') as restoring_file:\n            rest_coords = [self._get_data(vs, restoring_file, k) for k in (\'xt\', \'yt\', \'zt\')]\n            rest_coords[0][...] += -360\n\n            # sponge layers\n\n            vs.rest_tscl[2:-2, 2:-2, :] = veros.tools.interpolate(\n                rest_coords, self._get_data(vs, restoring_file, \'tscl\')[..., 0], t_grid)\n\n            t_star = self._get_data(vs, restoring_file, \'t_star\')\n            s_star = self._get_data(vs, restoring_file, \'s_star\')\n            for k in range(12):\n                vs.t_star[2:-2, 2:-2, :, k] = veros.tools.interpolate(\n                    rest_coords, t_star[..., k], t_grid, missing_value=0.\n                )\n                vs.s_star[2:-2, 2:-2, :, k] = veros.tools.interpolate(\n                    rest_coords, s_star[..., k], t_grid, missing_value=0.\n                )\n\n    @veros_method\n    def set_forcing(self, vs):\n        year_in_seconds = 360 * 86400.0\n        (n1, f1), (n2, f2) = veros.tools.get_periodic_interval(vs.time, year_in_seconds,\n                                                               year_in_seconds / 12., 12)\n\n        vs.surface_taux[...] = (f1 * vs.taux[:, :, n1] + f2 * vs.taux[:, :, n2])\n        vs.surface_tauy[...] = (f1 * vs.tauy[:, :, n1] + f2 * vs.tauy[:, :, n2])\n\n        if vs.enable_tke:\n            vs.forc_tke_surface[1:-1, 1:-1] = np.sqrt((0.5 * (vs.surface_taux[1:-1, 1:-1] + vs.surface_taux[:-2, 1:-1]) / vs.rho_0)**2\n                                                      + (0.5 * (vs.surface_tauy[1:-1, 1:-1] + vs.surface_tauy[1:-1, :-2]) / vs.rho_0)**2\n                                                      ) ** (3. / 2.)\n        cp_0 = 3991.86795711963\n        vs.forc_temp_surface[...] = (f1 * vs.sst_rest[:, :, n1] + f2 * vs.sst_rest[:, :, n2]) * \\\n                                    (f1 * vs.sst_clim[:, :, n1] + f2 * vs.sst_clim[:, :, n2]\n                                     - vs.temp[:, :, -1, vs.tau]) * vs.maskT[:, :, -1] / cp_0 / vs.rho_0\n        vs.forc_salt_surface[...] = (f1 * vs.sss_rest[:, :, n1] + f2 * vs.sss_rest[:, :, n2]) * \\\n                                    (f1 * vs.sss_clim[:, :, n1] + f2 * vs.sss_clim[:, :, n2]\n                                     - vs.salt[:, :, -1, vs.tau]) * vs.maskT[:, :, -1]\n\n        ice_mask = (vs.temp[:, :, -1, vs.tau] * vs.maskT[:, :, -1] <= -1.8) & (vs.forc_temp_surface <= 0.0)\n        vs.forc_temp_surface[...] *= ~ice_mask\n        vs.forc_salt_surface[...] *= ~ice_mask\n\n        if vs.enable_tempsalt_sources:\n            vs.temp_source[...] = vs.maskT * vs.rest_tscl \\\n                * (f1 * vs.t_star[:, :, :, n1] + f2 * vs.t_star[:, :, :, n2] - vs.temp[:, :, :, vs.tau])\n            vs.salt_source[...] = vs.maskT * vs.rest_tscl \\\n                * (f1 * vs.s_star[:, :, :, n1] + f2 * vs.s_star[:, :, :, n2] - vs.salt[:, :, :, vs.tau])\n\n    @veros_method\n    def set_diagnostics(self, vs):\n        vs.diagnostics[\'snapshot\'].output_frequency = 3600. * 24 * 10\n        vs.diagnostics[\'averages\'].output_frequency = 3600. * 24 * 10\n        vs.diagnostics[\'averages\'].sampling_frequency = vs.dt_tracer\n        vs.diagnostics[\'averages\'].output_variables = [\'temp\', \'salt\', \'u\', \'v\', \'w\',\n                                                       \'surface_taux\', \'surface_tauy\', \'psi\']\n        vs.diagnostics[\'cfl_monitor\'].output_frequency = vs.dt_tracer * 10\n\n    @veros_method\n    def after_timestep(self, vs):\n        pass\n\n\n@veros.tools.cli\ndef run(*args, **kwargs):\n    simulation = NorthAtlanticSetup(*args, **kwargs)\n    simulation.setup()\n    simulation.run()\n\n\nif __name__ == \'__main__\':\n    run()\n'"
veros/setup/wave_propagation/__init__.py,0,b'from veros.setup.wave_propagation.wave_propagation import WavePropagationSetup\n'
veros/setup/wave_propagation/wave_propagation.py,38,"b'#!/usr/bin/env python\n\nimport os\n\nimport numpy as np\nimport h5netcdf\nfrom PIL import Image\nimport scipy.ndimage\nfrom loguru import logger\n\nfrom veros import veros_method, VerosSetup\nfrom veros.variables import Variable\nimport veros.tools\nfrom veros.core.utilities import enforce_boundaries\n\nBASE_PATH = os.path.dirname(os.path.realpath(__file__))\nDATA_FILES = veros.tools.get_assets(\'wave_propagation\', os.path.join(BASE_PATH, \'assets.yml\'))\nTOPO_MASK_FILE = os.path.join(BASE_PATH, \'topography_idealized.png\')\nNA_MASK_FILE = os.path.join(BASE_PATH, \'na_mask.png\')\n\n\nclass WavePropagationSetup(VerosSetup):\n    """"""\n    Global model with flexible resolution and idealized geometry in the\n    Atlantic to examine coastal wave propagation.\n\n    Reference:\n        Hafner, D., Jacobsen, R. L., Eden, C., Kristensen, M. R. B., Jochum, M., Nuterman, R., & Vinter, B. (2018).\n        Veros v0.1-a fast and versatile ocean simulator in pure Python. Geoscientific Model Development, 11(8), 3299-3312.\n        `<https://doi.org/10.5194/gmd-11-3299-2018>`_.\n\n    """"""\n    # settings for north atlantic\n    na_shelf_depth = 250\n    na_shelf_distance = 0\n    na_slope_length = 600e3\n    na_max_depth = 4000\n\n    # global settings\n    max_depth = 5600.\n    equatorial_grid_spacing = 0.5\n    polar_grid_spacing = None\n\n    # southern ocean wind modifier\n    so_wind_interval = (-69., -27.)\n    so_wind_factor = 1.\n\n    @veros_method\n    def set_parameter(self, vs):\n        vs.identifier = \'wp\'\n\n        vs.nx = 180\n        vs.ny = 180\n        vs.nz = 60\n        vs.dt_mom = vs.dt_tracer = 0\n        vs.runlen = 86400 * 10\n\n        vs.coord_degree = True\n        vs.enable_cyclic_x = True\n\n        # streamfunction\n        vs.congr_epsilon = 1e-6\n        vs.congr_max_iterations = 10000\n\n        # friction\n        vs.enable_hor_friction = True\n        vs.A_h = 5e4\n        vs.enable_hor_friction_cos_scaling = True\n        vs.hor_friction_cosPower = 1\n        vs.enable_tempsalt_sources = True\n        vs.enable_implicit_vert_friction = True\n\n        vs.eq_of_state_type = 5\n\n        # isoneutral\n        vs.enable_neutral_diffusion = True\n        vs.K_iso_0 = 1000.0\n        vs.K_iso_steep = 50.0\n        vs.iso_dslope = 0.005\n        vs.iso_slopec = 0.005\n        vs.enable_skew_diffusion = True\n\n        # tke\n        vs.enable_tke = True\n        vs.c_k = 0.1\n        vs.c_eps = 0.7\n        vs.alpha_tke = 30.0\n        vs.mxl_min = 1e-8\n        vs.tke_mxl_choice = 2\n        vs.kappaM_min = 2e-4\n        vs.kappaH_min = 2e-5\n        vs.enable_kappaH_profile = True\n        vs.enable_tke_superbee_advection = True\n\n        # eke\n        vs.enable_eke = True\n        vs.eke_k_max = 1e4\n        vs.eke_c_k = 0.4\n        vs.eke_c_eps = 0.5\n        vs.eke_cross = 2.\n        vs.eke_crhin = 1.0\n        vs.eke_lmin = 100.0\n        vs.enable_eke_superbee_advection = True\n        vs.enable_eke_isopycnal_diffusion = True\n\n        # idemix\n        vs.enable_idemix = False\n        vs.enable_eke_diss_surfbot = True\n        vs.eke_diss_surfbot_frac = 0.2\n        vs.enable_idemix_superbee_advection = True\n        vs.enable_idemix_hor_diffusion = True\n\n        # custom variables\n        vs.nmonths = 12\n        vs.variables.update(\n            t_star=Variable(\'t_star\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            s_star=Variable(\'s_star\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            qnec=Variable(\'qnec\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            qnet=Variable(\'qnet\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            qsol=Variable(\'qsol\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            divpen_shortwave=Variable(\'divpen_shortwave\', (\'zt\',), \'\', \'\', time_dependent=False),\n            taux=Variable(\'taux\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            tauy=Variable(\'tauy\', (\'xt\', \'yt\', \'nmonths\'), \'\', \'\', time_dependent=False),\n            na_mask=Variable(\n                \'Mask for North Atlantic\', (\'xt\', \'yt\'), \'\', \'Mask for North Atlantic\',\n                dtype=\'bool\', time_dependent=False, output=True\n            )\n        )\n\n    @veros_method(inline=True)\n    def _get_data(self, vs, var):\n        with h5netcdf.File(DATA_FILES[\'forcing\'], \'r\') as forcing_file:\n            var_obj = forcing_file.variables[var]\n            return np.array(var_obj, dtype=str(var_obj.dtype)).T\n\n    @veros_method(dist_safe=False, local_variables=[\n        \'dxt\', \'dyt\', \'dzt\'\n    ])\n    def set_grid(self, vs):\n        if vs.ny % 2:\n            raise ValueError(\'ny has to be an even number of grid cells\')\n        vs.dxt[...] = 360. / vs.nx\n        vs.dyt[2:-2] = veros.tools.get_vinokur_grid_steps(\n            vs.ny, 160., self.equatorial_grid_spacing, upper_stepsize=self.polar_grid_spacing, two_sided_grid=True\n        )\n        vs.dzt[...] = veros.tools.get_vinokur_grid_steps(vs.nz, self.max_depth, 10., refine_towards=\'lower\')\n        vs.y_origin = -80.\n        vs.x_origin = 90.\n\n    @veros_method\n    def set_coriolis(self, vs):\n        vs.coriolis_t[...] = 2 * vs.omega * np.sin(vs.yt[np.newaxis, :] / 180. * vs.pi)\n\n    @veros_method\n    def _shift_longitude_array(self, vs, lon, arr):\n        wrap_i = np.where((lon[:-1] < vs.xt.min()) & (lon[1:] >= vs.xt.min()))[0][0]\n        new_lon = np.concatenate((lon[wrap_i:-1], lon[:wrap_i] + 360.))\n        new_arr = np.concatenate((arr[wrap_i:-1, ...], arr[:wrap_i, ...]))\n        return new_lon, new_arr\n\n    @veros_method(dist_safe=False, local_variables=[\n        \'kbot\', \'xt\', \'yt\', \'zt\', \'na_mask\'\n    ])\n    def set_topography(self, vs):\n        with h5netcdf.File(DATA_FILES[\'topography\'], \'r\') as topography_file:\n            topo_x, topo_y, topo_z = (\n                np.array(topography_file.variables[k], dtype=\'float\').T\n                for k in (\'x\', \'y\', \'z\')\n            )\n        topo_z[topo_z > 0] = 0.\n        topo_mask = (np.flipud(Image.open(TOPO_MASK_FILE)).T / 255).astype(np.bool)\n        gaussian_sigma = (0.5 * len(topo_x) / vs.nx, 0.5 * len(topo_y) / vs.ny)\n        topo_z_smoothed = scipy.ndimage.gaussian_filter(topo_z, sigma=gaussian_sigma)\n        topo_z_smoothed[~topo_mask & (topo_z_smoothed >= 0.)] = -100.\n        topo_masked = np.where(topo_mask, 0., topo_z_smoothed)\n\n        na_mask_image = np.flipud(Image.open(NA_MASK_FILE)).T / 255.\n        topo_x_shifted, na_mask_shifted = self._shift_longitude_array(vs, topo_x, na_mask_image)\n        coords = (vs.xt[2:-2], vs.yt[2:-2])\n        vs.na_mask[2:-2, 2:-2] = np.logical_not(veros.tools.interpolate(\n            (topo_x_shifted, topo_y), na_mask_shifted, coords, kind=\'nearest\', fill=False\n        ).astype(np.bool))\n\n        topo_x_shifted, topo_masked_shifted = self._shift_longitude_array(vs, topo_x, topo_masked)\n        z_interp = veros.tools.interpolate(\n            (topo_x_shifted, topo_y), topo_masked_shifted, coords, kind=\'nearest\', fill=False\n        )\n        z_interp[vs.na_mask[2:-2, 2:-2]] = -self.na_max_depth\n\n        grid_coords = np.meshgrid(*coords, indexing=\'ij\')\n        coastline_distance = veros.tools.get_coastline_distance(\n            grid_coords, z_interp >= 0, spherical=True, radius=vs.radius\n        )\n        if self.na_slope_length:\n            slope_distance = coastline_distance - self.na_shelf_distance\n            slope_mask = np.logical_and(vs.na_mask[2:-2, 2:-2], slope_distance < self.na_slope_length)\n            z_interp[slope_mask] = -(self.na_shelf_depth + slope_distance[slope_mask] / self.na_slope_length \\\n                                                           * (self.na_max_depth - self.na_shelf_depth))\n        if self.na_shelf_distance:\n            shelf_mask = np.logical_and(vs.na_mask[2:-2, 2:-2], coastline_distance < self.na_shelf_distance)\n            z_interp[shelf_mask] = -self.na_shelf_depth\n\n        depth_levels = 1 + np.argmin(np.abs(z_interp[:, :, np.newaxis] - vs.zt[np.newaxis, np.newaxis, :]), axis=2)\n        vs.kbot[2:-2, 2:-2] = np.where(z_interp < 0., depth_levels, 0)\n        vs.kbot *= vs.kbot < vs.nz\n\n    @veros_method\n    def _fix_north_atlantic(self, vs, arr):\n        """"""Calculate zonal mean forcing over masked area (na_mask).""""""\n        newaxes = (slice(2, -2), slice(2, -2)) + (np.newaxis,) * (arr.ndim - 2)\n        arr_masked = np.ma.masked_where(np.logical_or(~vs.na_mask[newaxes], arr == 0.), arr)\n        zonal_mean_na = arr_masked.mean(axis=0)\n        return np.where(~arr_masked.mask, zonal_mean_na[np.newaxis, ...], arr)\n\n    @veros_method(dist_safe=False, local_variables=[\n        \'qnet\', \'temp\', \'salt\', \'maskT\', \'taux\', \'tauy\', \'xt\', \'yt\', \'zt\',\n        \'qnec\', \'qsol\', \'t_star\', \'s_star\', \'na_mask\',\n        \'maskW\', \'divpen_shortwave\', \'dzt\', \'zw\',\n    ])\n    def set_initial_conditions(self, vs):\n        rpart_shortwave = 0.58\n        efold1_shortwave = 0.35\n        efold2_shortwave = 23.0\n\n        t_grid = (vs.xt[2:-2], vs.yt[2:-2], vs.zt)\n        xt_forc, yt_forc, zt_forc = (self._get_data(vs, k) for k in (\'xt\', \'yt\', \'zt\'))\n        zt_forc = zt_forc[::-1]\n\n        # initial conditions\n        temp_data = veros.tools.interpolate((xt_forc, yt_forc, zt_forc), self._get_data(vs, \'temperature\')[:, :, ::-1],\n                                      t_grid, missing_value=0.)\n        vs.temp[2:-2, 2:-2, :, 0] = temp_data * vs.maskT[2:-2, 2:-2, :]\n        vs.temp[2:-2, 2:-2, :, 1] = temp_data * vs.maskT[2:-2, 2:-2, :]\n\n        salt_data = veros.tools.interpolate((xt_forc, yt_forc, zt_forc), self._get_data(vs, \'salinity\')[:, :, ::-1],\n                                       t_grid, missing_value=0.)\n        vs.salt[2:-2, 2:-2, :, 0] = salt_data * vs.maskT[2:-2, 2:-2, :]\n        vs.salt[2:-2, 2:-2, :, 1] = salt_data * vs.maskT[2:-2, 2:-2, :]\n\n        # wind stress on MIT grid\n        time_grid = (vs.xt[2:-2], vs.yt[2:-2], np.arange(12))\n        taux_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                      self._get_data(vs, \'tau_x\'), time_grid,\n                                      missing_value=0.)\n        vs.taux[2:-2, 2:-2, :] = taux_data\n        mask = np.logical_and(vs.yt > self.so_wind_interval[0], vs.yt < self.so_wind_interval[1])[..., np.newaxis]\n        vs.taux *= 1. + mask * (self.so_wind_factor - 1.) * np.sin(np.pi * (vs.yt[np.newaxis, :, np.newaxis] - self.so_wind_interval[0]) \\\n                                                                            / (self.so_wind_interval[1] - self.so_wind_interval[0]))\n\n        tauy_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                      self._get_data(vs, \'tau_y\'), time_grid,\n                                      missing_value=0.)\n        vs.tauy[2:-2, 2:-2, :] = tauy_data\n\n        enforce_boundaries(vs, vs.taux)\n        enforce_boundaries(vs, vs.tauy)\n\n        # Qnet and dQ/dT and Qsol\n        qnet_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                      self._get_data(vs, \'q_net\'), time_grid, missing_value=0.)\n        vs.qnet[2:-2, 2:-2, :] = -qnet_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        qnec_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                       self._get_data(vs, \'dqdt\'), time_grid, missing_value=0.)\n        vs.qnec[2:-2, 2:-2, :] = qnec_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        qsol_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                       self._get_data(vs, \'swf\'), time_grid, missing_value=0.)\n        vs.qsol[2:-2, 2:-2, :] = -qsol_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        # SST and SSS\n        sst_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                     self._get_data(vs, \'sst\'), time_grid, missing_value=0.)\n        vs.t_star[2:-2, 2:-2, :] = sst_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        sss_data = veros.tools.interpolate((xt_forc, yt_forc, np.arange(12)),\n                                     self._get_data(vs, \'sss\'), time_grid, missing_value=0.)\n        vs.s_star[2:-2, 2:-2, :] = sss_data * vs.maskT[2:-2, 2:-2, -1, np.newaxis]\n\n        if vs.enable_idemix:\n            tidal_energy_data = veros.tools.interpolate(\n                (xt_forc, yt_forc), self._get_data(vs, \'tidal_energy\'), t_grid[:-1], missing_value=0.\n            )\n            mask_x, mask_y = (i + 2 for i in np.indices((vs.nx, vs.ny)))\n            mask_z = np.maximum(0, vs.kbot[2:-2, 2:-2] - 1)\n            tidal_energy_data[:, :] *= vs.maskW[mask_x, mask_y, mask_z] / vs.rho_0\n            vs.forc_iw_bottom[2:-2, 2:-2] = tidal_energy_data\n\n        # average variables in North Atlantic\n        na_average_vars = [vs.taux, vs.tauy, vs.qnet, vs.qnec, vs.qsol,\n                           vs.t_star, vs.s_star, vs.salt, vs.temp]\n\n        for k in na_average_vars:\n            k[2:-2, 2:-2, ...] = self._fix_north_atlantic(vs, k[2:-2, 2:-2, ...])\n\n        """"""\n        Initialize penetration profile for solar radiation and store divergence in divpen\n        note that pen is set to 0.0 at the surface instead of 1.0 to compensate for the\n        shortwave part of the total surface flux\n        """"""\n        swarg1 = vs.zw / efold1_shortwave\n        swarg2 = vs.zw / efold2_shortwave\n        pen = rpart_shortwave * np.exp(swarg1) + (1.0 - rpart_shortwave) * np.exp(swarg2)\n        pen[-1] = 0.\n        vs.divpen_shortwave[1:] = (pen[1:] - pen[:-1]) / vs.dzt[1:]\n        vs.divpen_shortwave[0] = pen[0] / vs.dzt[0]\n\n    @veros_method\n    def set_forcing(self, vs):\n        self.set_timestep(vs)\n\n        t_rest = 30. * 86400.\n        cp_0 = 3991.86795711963  # J/kg /K\n\n        year_in_seconds = 360 * 86400.\n        (n1, f1), (n2, f2) = veros.tools.get_periodic_interval(\n            vs.time, year_in_seconds, year_in_seconds / 12., 12\n        )\n\n        vs.surface_taux[...] = f1 * vs.taux[:, :, n1] + f2 * vs.taux[:, :, n2]\n        vs.surface_tauy[...] = f1 * vs.tauy[:, :, n1] + f2 * vs.tauy[:, :, n2]\n\n        if vs.enable_tke:\n            vs.forc_tke_surface[1:-1, 1:-1] = np.sqrt((0.5 * (vs.surface_taux[1:-1, 1:-1] + vs.surface_taux[:-2, 1:-1]) / vs.rho_0) ** 2\n                                                        + (0.5 * (vs.surface_tauy[1:-1, 1:-1] + vs.surface_tauy[1:-1, :-2]) / vs.rho_0) ** 2) ** (3. / 2.)\n\n        # W/m^2 K kg/J m^3/kg = K m/s\n        fxa = f1 * vs.t_star[..., n1] + f2 * vs.t_star[..., n2]\n        vs.qqnec = f1 * vs.qnec[..., n1] + f2 * vs.qnec[..., n2]\n        vs.qqnet = f1 * vs.qnet[..., n1] + f2 * vs.qnet[..., n2]\n        vs.forc_temp_surface[...] = (vs.qqnet + vs.qqnec * (fxa - vs.temp[..., -1, vs.tau])) \\\n            * vs.maskT[..., -1] / cp_0 / vs.rho_0\n        fxa = f1 * vs.s_star[..., n1] + f2 * vs.s_star[..., n2]\n        vs.forc_salt_surface[...] = 1. / t_rest * \\\n            (fxa - vs.salt[..., -1, vs.tau]) * vs.maskT[..., -1] * vs.dzt[-1]\n\n        # apply simple ice mask\n        mask1 = vs.temp[:, :, -1, vs.tau] * vs.maskT[:, :, -1] <= -1.8\n        mask2 = vs.forc_temp_surface <= 0\n        ice = ~(mask1 & mask2)\n        vs.forc_temp_surface[...] *= ice\n        vs.forc_salt_surface[...] *= ice\n\n        # solar radiation\n        if vs.enable_tempsalt_sources:\n            vs.temp_source[..., :] = (f1 * vs.qsol[..., n1, None] + f2 * vs.qsol[..., n2, None]) \\\n                * vs.divpen_shortwave[None, None, :] * ice[..., None] \\\n                * vs.maskT[..., :] / cp_0 / vs.rho_0\n\n    @veros_method\n    def set_diagnostics(self, vs):\n        vs.diagnostics[\'cfl_monitor\'].output_frequency = 86400.\n        vs.diagnostics[\'tracer_monitor\'].output_frequency = 86400.\n        vs.diagnostics[\'snapshot\'].output_frequency = 10 * 86400.\n        vs.diagnostics[\'overturning\'].output_frequency = 360 * 86400\n        vs.diagnostics[\'overturning\'].sampling_frequency = 10 * 86400\n        vs.diagnostics[\'energy\'].output_frequency = 360 * 86400\n        vs.diagnostics[\'energy\'].sampling_frequency = 86400.\n        vs.diagnostics[\'averages\'].output_frequency = 360 * 86400\n        vs.diagnostics[\'averages\'].sampling_frequency = 86400.\n\n        average_vars = [\'surface_taux\', \'surface_tauy\', \'forc_temp_surface\', \'forc_salt_surface\',\n                        \'psi\', \'temp\', \'salt\', \'u\', \'v\', \'w\', \'Nsqr\', \'Hd\', \'rho\',\n                        \'K_diss_v\', \'P_diss_v\', \'P_diss_nonlin\', \'P_diss_iso\', \'kappaH\']\n        if vs.enable_skew_diffusion:\n            average_vars += [\'B1_gm\', \'B2_gm\']\n        if vs.enable_TEM_friction:\n            average_vars += [\'kappa_gm\', \'K_diss_gm\']\n        if vs.enable_tke:\n            average_vars += [\'tke\', \'Prandtlnumber\', \'mxl\', \'tke_diss\',\n                             \'forc_tke_surface\', \'tke_surf_corr\']\n        if vs.enable_idemix:\n            average_vars += [\'E_iw\', \'forc_iw_surface\', \'iw_diss\',\n                             \'c0\', \'v0\']\n        if vs.enable_eke:\n            average_vars += [\'eke\', \'K_gm\', \'L_rossby\', \'L_rhines\']\n        vs.diagnostics[\'averages\'].output_variables = average_vars\n\n        vs.diagnostics[\'snapshot\'].output_variables.append(\'na_mask\')\n\n    @veros_method\n    def set_timestep(self, vs):\n        if vs.time < 90 * 86400:\n            if vs.dt_tracer != 1800.:\n                vs.dt_tracer = vs.dt_mom = 1800.\n                logger.info(\'Setting time step to 30m\')\n        else:\n            if vs.dt_tracer != 3600.:\n                vs.dt_tracer = vs.dt_mom = 3600.\n                logger.info(\'Setting time step to 1h\')\n\n    def after_timestep(self, vs):\n        pass\n\n\n@veros.tools.cli\ndef run(*args, **kwargs):\n    simulation = WavePropagationSetup(*args, **kwargs)\n    simulation.setup()\n    simulation.run()\n\n\nif __name__ == \'__main__\':\n    run()\n'"
veros/core/streamfunction/solvers/__init__.py,0,b''
veros/core/streamfunction/solvers/base.py,0,"b'from abc import abstractmethod, ABCMeta\n\n\nclass LinearSolver(metaclass=ABCMeta):\n    @abstractmethod\n    def __init__(self, vs):\n        pass\n\n    @abstractmethod\n    def solve(self, vs, rhs, x0, boundary_val=None):\n        pass\n'"
veros/core/streamfunction/solvers/petsc.py,16,"b'from petsc4py import PETSc\nfrom loguru import logger\n\nfrom .base import LinearSolver\nfrom ... import utilities\nfrom .... import veros_method, runtime_settings as rs, runtime_state as rst\n\n\nclass PETScSolver(LinearSolver):\n    @veros_method\n    def __init__(self, vs):\n        if vs.enable_cyclic_x:\n            boundary_type = (\'periodic\', \'ghosted\')\n        else:\n            boundary_type = (\'ghosted\', \'ghosted\')\n\n        self._da = PETSc.DMDA().create(\n            [vs.nx, vs.ny],\n            stencil_width=1,\n            stencil_type=\'star\',\n            comm=rs.mpi_comm,\n            proc_sizes=rs.num_proc,\n            boundary_type=boundary_type,\n            ownership_ranges=[\n                (vs.nx // rs.num_proc[0],) * rs.num_proc[0],\n                (vs.ny // rs.num_proc[1],) * rs.num_proc[1],\n            ]\n        )\n\n        self._matrix, self._boundary_fac = self._assemble_poisson_matrix(vs)\n\n        petsc_options = PETSc.Options()\n\n        # setup krylov method\n        self._ksp = PETSc.KSP()\n        self._ksp.create(rs.mpi_comm)\n        self._ksp.setOperators(self._matrix)\n        self._ksp.setType(\'gmres\')\n        self._ksp.setTolerances(atol=0, rtol=vs.congr_epsilon, max_it=vs.congr_max_iterations)\n\n        # preconditioner\n        self._ksp.getPC().setType(\'hypre\')\n        petsc_options[\'pc_hypre_type\'] = \'boomeramg\'\n        petsc_options[\'pc_hypre_boomeramg_relax_type_all\'] = \'SOR/Jacobi\'\n        self._ksp.getPC().setFromOptions()\n\n        self._rhs_petsc = self._da.createGlobalVec()\n        self._sol_petsc = self._da.createGlobalVec()\n\n    @veros_method\n    def _petsc_solver(self, vs, rhs, x0):\n        # add dirichlet BC to rhs\n        if not vs.enable_cyclic_x:\n            if rst.proc_idx[0] == rs.num_proc[0] - 1:\n                rhs[-3, 2:-2] -= rhs[-2, 2:-2] * self._boundary_fac[\'east\']\n\n            if rst.proc_idx[0] == 0:\n                rhs[2, 2:-2] -= rhs[1, 2:-2] * self._boundary_fac[\'west\']\n\n        if rst.proc_idx[1] == rs.num_proc[1] - 1:\n            rhs[2:-2, -3] -= rhs[2:-2, -2] * self._boundary_fac[\'north\']\n\n        if rst.proc_idx[1] == 0:\n            rhs[2:-2, 2] -= rhs[2:-2, 1] * self._boundary_fac[\'south\']\n\n        try:\n            rhs = rhs.copy2numpy()\n        except AttributeError:\n            pass\n\n        try:\n            x0 = x0.copy2numpy()\n        except AttributeError:\n            pass\n\n        self._da.getVecArray(self._rhs_petsc)[...] = rhs[2:-2, 2:-2]\n        self._da.getVecArray(self._sol_petsc)[...] = x0[2:-2, 2:-2]\n\n        self._ksp.solve(self._rhs_petsc, self._sol_petsc)\n\n        info = self._ksp.getConvergedReason()\n        iterations = self._ksp.getIterationNumber()\n\n        if info < 0:\n            logger.warning(\'Streamfunction solver did not converge after {} iterations (error code: {})\', iterations, info)\n\n        return np.array(self._da.getVecArray(self._sol_petsc)[...])\n\n    @veros_method\n    def solve(self, vs, rhs, sol, boundary_val=None):\n        """"""\n        Arguments:\n            rhs: Right-hand side vector\n            sol: Initial guess, gets overwritten with solution\n            boundary_val: Array containing values to set on boundary elements. Defaults to `sol`.\n        """"""\n        if boundary_val is None:\n            boundary_val = sol\n\n        utilities.enforce_boundaries(vs, sol)\n\n        boundary_mask = np.logical_and.reduce(~vs.boundary_mask, axis=2)\n        rhs = utilities.where(vs, boundary_mask, rhs, boundary_val) # set right hand side on boundaries\n\n        sol[...] = rhs\n        sol[2:-2, 2:-2] = self._petsc_solver(vs, rhs, sol)\n\n    @veros_method\n    def _assemble_poisson_matrix(self, vs):\n        """"""\n        Construct a sparse matrix based on the stencil for the 2D Poisson equation.\n        """"""\n\n        matrix = self._da.getMatrix()\n\n        boundary_mask = np.logical_and.reduce(~vs.boundary_mask[2:-2, 2:-2], axis=2)\n\n        # assemble diagonals\n        main_diag = -vs.hvr[3:-1, 2:-2] / vs.dxu[2:-2, np.newaxis] / vs.dxt[3:-1, np.newaxis] / vs.cosu[np.newaxis, 2:-2]**2 \\\n            - vs.hvr[2:-2, 2:-2] / vs.dxu[2:-2, np.newaxis] / vs.dxt[2:-2, np.newaxis] / vs.cosu[np.newaxis, 2:-2]**2 \\\n            - vs.hur[2:-2, 2:-2] / vs.dyu[np.newaxis, 2:-2] / vs.dyt[np.newaxis, 2:-2] * vs.cost[np.newaxis, 2:-2] / vs.cosu[np.newaxis, 2:-2] \\\n            - vs.hur[2:-2, 3:-1] / vs.dyu[np.newaxis, 2:-2] / vs.dyt[np.newaxis, 3:-1] * \\\n            vs.cost[np.newaxis, 3:-1] / vs.cosu[np.newaxis, 2:-2]\n        east_diag = vs.hvr[3:-1, 2:-2] / vs.dxu[2:-2, np.newaxis] / \\\n            vs.dxt[3:-1, np.newaxis] / vs.cosu[np.newaxis, 2:-2]**2\n        west_diag = vs.hvr[2:-2, 2:-2] / vs.dxu[2:-2, np.newaxis] / \\\n            vs.dxt[2:-2, np.newaxis] / vs.cosu[np.newaxis, 2:-2]**2\n        north_diag = vs.hur[2:-2, 3:-1] / vs.dyu[np.newaxis, 2:-2] / \\\n            vs.dyt[np.newaxis, 3:-1] * vs.cost[np.newaxis, 3:-1] / vs.cosu[np.newaxis, 2:-2]\n        south_diag = vs.hur[2:-2, 2:-2] / vs.dyu[np.newaxis, 2:-2] / \\\n            vs.dyt[np.newaxis, 2:-2] * vs.cost[np.newaxis, 2:-2] / vs.cosu[np.newaxis, 2:-2]\n\n        main_diag *= boundary_mask\n        main_diag[main_diag == 0.] = 1.\n\n        # construct sparse matrix\n        cf = tuple(diag for diag in (\n            main_diag,\n            boundary_mask * east_diag,\n            boundary_mask * west_diag,\n            boundary_mask * north_diag,\n            boundary_mask * south_diag\n        ))\n\n        row = PETSc.Mat.Stencil()\n        col = PETSc.Mat.Stencil()\n\n        ij_offsets = [(0, 0), (1, 0), (-1, 0), (0, 1), (0, -1)]\n\n        (i0, i1), (j0, j1) = self._da.getRanges()\n        for j in range(j0, j1):\n            for i in range(i0, i1):\n                iloc, jloc = i % (vs.nx // rs.num_proc[0]), j % (vs.ny // rs.num_proc[1])\n                row.index = (i, j)\n\n                for diag, offset in zip(cf, ij_offsets):\n                    io, jo = (i + offset[0], j + offset[1])\n                    col.index = (io, jo)\n                    matrix.setValueStencil(row, col, diag[iloc, jloc])\n\n        matrix.assemble()\n\n        boundary_scale = {\n            \'east\': cf[1][-1, :],\n            \'west\': cf[2][0, :],\n            \'north\': cf[3][:, -1],\n            \'south\': cf[4][:, 0]\n        }\n\n        return matrix, boundary_scale\n'"
veros/core/streamfunction/solvers/scipy.py,18,"b'from loguru import logger\nimport scipy.sparse\nimport scipy.sparse.linalg as spalg\n\nfrom .base import LinearSolver\nfrom ... import utilities\nfrom .... import veros_method, runtime_settings as rs, distributed\nfrom ....variables import allocate\n\n\nclass SciPySolver(LinearSolver):\n    @veros_method(dist_safe=False, local_variables=[\n        \'hvr\', \'hur\',\n        \'dxu\', \'dxt\', \'dyu\', \'dyt\',\n        \'cosu\', \'cost\',\n        \'boundary_mask\'\n    ])\n    def __init__(self, vs):\n        self._matrix = self._assemble_poisson_matrix(vs)\n        jacobi_precon = self._jacobi_preconditioner(vs, self._matrix)\n        self._matrix = jacobi_precon * self._matrix\n        self._rhs_scale = jacobi_precon.diagonal()\n        self._extra_args = {}\n\n        logger.info(\'Computing ILU preconditioner...\')\n        ilu_preconditioner = spalg.spilu(self._matrix.tocsc(), drop_tol=1e-6, fill_factor=100)\n        self._extra_args[\'M\'] = spalg.LinearOperator(self._matrix.shape, ilu_preconditioner.solve)\n\n    @veros_method(dist_safe=False, local_variables=[\'boundary_mask\'])\n    def _scipy_solver(self, vs, rhs, sol, boundary_val):\n        utilities.enforce_boundaries(vs, sol)\n\n        boundary_mask = np.logical_and.reduce(~vs.boundary_mask, axis=2)\n        rhs = utilities.where(vs, boundary_mask, rhs, boundary_val) # set right hand side on boundaries\n        x0 = sol.flatten()\n\n        try:\n            rhs = rhs.copy2numpy()\n        except AttributeError:\n            pass\n\n        try:\n            x0 = x0.copy2numpy()\n        except AttributeError:\n            pass\n\n        rhs = rhs.flatten() * self._rhs_scale\n        linear_solution, info = spalg.bicgstab(\n            self._matrix, rhs,\n            x0=x0, atol=0, tol=vs.congr_epsilon,\n            maxiter=vs.congr_max_iterations,\n            **self._extra_args\n        )\n\n        if info > 0:\n            logger.warning(\'Streamfunction solver did not converge after {} iterations\', info)\n\n        if rs.backend == \'bohrium\':\n            linear_solution = np.asarray(linear_solution)\n\n        sol[...] = linear_solution.reshape(vs.nx + 4, vs.ny + 4)\n\n    @veros_method\n    def solve(self, vs, rhs, sol, boundary_val=None):\n        """"""\n        Main solver for streamfunction. Solves a 2D Poisson equation. Uses scipy.sparse.linalg\n        linear solvers.\n\n        Arguments:\n            rhs: Right-hand side vector\n            sol: Initial guess, gets overwritten with solution\n            boundary_val: Array containing values to set on boundary elements. Defaults to `sol`.\n        """"""\n        rhs_global = distributed.gather(vs, rhs, (\'xt\', \'yt\'))\n        sol_global = distributed.gather(vs, sol, (\'xt\', \'yt\'))\n\n        if boundary_val is None:\n            boundary_val = sol_global\n        else:\n            boundary_val = distributed.gather(vs, boundary_val, (\'xt\', \'yt\'))\n\n        self._scipy_solver(vs, rhs_global, sol_global, boundary_val=boundary_val)\n\n        sol[...] = distributed.scatter(vs, sol_global, (\'xt\', \'yt\'))\n\n    @staticmethod\n    @veros_method(dist_safe=False, local_variables=[])\n    def _jacobi_preconditioner(vs, matrix):\n        """"""\n        Construct a simple Jacobi preconditioner\n        """"""\n        eps = 1e-20\n        Z = allocate(vs, (\'xu\', \'yu\'), fill=1, local=False)\n        Y = np.reshape(matrix.diagonal().copy(), (vs.nx + 4, vs.ny + 4))[2:-2, 2:-2]\n        Z[2:-2, 2:-2] = utilities.where(vs, np.abs(Y) > eps, 1. / (Y + eps), 1.)\n\n        if rs.backend == \'bohrium\':\n            Z = Z.copy2numpy()\n\n        return scipy.sparse.dia_matrix((Z.flatten(), 0), shape=(Z.size, Z.size)).tocsr()\n\n    @staticmethod\n    @veros_method(dist_safe=False, local_variables=[\'boundary_mask\'])\n    def _assemble_poisson_matrix(vs):\n        """"""\n        Construct a sparse matrix based on the stencil for the 2D Poisson equation.\n        """"""\n        boundary_mask = np.logical_and.reduce(~vs.boundary_mask, axis=2)\n\n        # assemble diagonals\n        main_diag = allocate(vs, (\'xu\', \'yu\'), fill=1, local=False)\n        east_diag, west_diag, north_diag, south_diag = (allocate(vs, (\'xu\', \'yu\'), local=False) for _ in range(4))\n        main_diag[2:-2, 2:-2] = -vs.hvr[3:-1, 2:-2] / vs.dxu[2:-2, np.newaxis] / vs.dxt[3:-1, np.newaxis] / vs.cosu[np.newaxis, 2:-2]**2 \\\n            - vs.hvr[2:-2, 2:-2] / vs.dxu[2:-2, np.newaxis] / vs.dxt[2:-2, np.newaxis] / vs.cosu[np.newaxis, 2:-2]**2 \\\n            - vs.hur[2:-2, 2:-2] / vs.dyu[np.newaxis, 2:-2] / vs.dyt[np.newaxis, 2:-2] * vs.cost[np.newaxis, 2:-2] / vs.cosu[np.newaxis, 2:-2] \\\n            - vs.hur[2:-2, 3:-1] / vs.dyu[np.newaxis, 2:-2] / vs.dyt[np.newaxis, 3:-1] * vs.cost[np.newaxis, 3:-1] / vs.cosu[np.newaxis, 2:-2]\n        east_diag[2:-2, 2:-2] = vs.hvr[3:-1, 2:-2] / vs.dxu[2:-2, np.newaxis] / \\\n            vs.dxt[3:-1, np.newaxis] / vs.cosu[np.newaxis, 2:-2]**2\n        west_diag[2:-2, 2:-2] = vs.hvr[2:-2, 2:-2] / vs.dxu[2:-2, np.newaxis] / \\\n            vs.dxt[2:-2, np.newaxis] / vs.cosu[np.newaxis, 2:-2]**2\n        north_diag[2:-2, 2:-2] = vs.hur[2:-2, 3:-1] / vs.dyu[np.newaxis, 2:-2] / \\\n            vs.dyt[np.newaxis, 3:-1] * vs.cost[np.newaxis, 3:-1] / vs.cosu[np.newaxis, 2:-2]\n        south_diag[2:-2, 2:-2] = vs.hur[2:-2, 2:-2] / vs.dyu[np.newaxis, 2:-2] / \\\n            vs.dyt[np.newaxis, 2:-2] * vs.cost[np.newaxis, 2:-2] / vs.cosu[np.newaxis, 2:-2]\n\n        if vs.enable_cyclic_x:\n            # couple edges of the domain\n            wrap_diag_east, wrap_diag_west = (allocate(vs, (\'xu\', \'yu\'), local=False) for _ in range(2))\n            wrap_diag_east[2, 2:-2] = west_diag[2, 2:-2] * boundary_mask[2, 2:-2]\n            wrap_diag_west[-3, 2:-2] = east_diag[-3, 2:-2] * boundary_mask[-3, 2:-2]\n            west_diag[2, 2:-2] = 0.\n            east_diag[-3, 2:-2] = 0.\n\n        main_diag *= boundary_mask\n        main_diag[main_diag == 0.] = 1.\n\n        # construct sparse matrix\n        cf = tuple(diag.flatten() for diag in (\n            main_diag,\n            boundary_mask * east_diag,\n            boundary_mask * west_diag,\n            boundary_mask * north_diag,\n            boundary_mask * south_diag\n        ))\n        offsets = (0, -main_diag.shape[1], main_diag.shape[1], -1, 1)\n\n        if vs.enable_cyclic_x:\n            offsets += (-main_diag.shape[1] * (vs.nx - 1), main_diag.shape[1] * (vs.nx - 1))\n            cf += (wrap_diag_east.flatten(), wrap_diag_west.flatten())\n\n        cf = np.array(cf)\n\n        if rs.backend == \'bohrium\':\n            cf = cf.copy2numpy()\n\n        return scipy.sparse.dia_matrix((cf, offsets), shape=(main_diag.size, main_diag.size)).T.tocsr()\n'"
