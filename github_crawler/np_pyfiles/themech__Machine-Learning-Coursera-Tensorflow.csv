file_path,api_count,code
ex1-linear regression/1_plot_data.py,0,"b""import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n\n# Read the data - two comma-separated columns.\n# As there is no header row, we name the columns here\ndf = pd.read_csv('data/ex1data1.txt', names=['population', 'profit'])\n\n# Print the header and first few rows\nprint(df.head())\n\n# Plot the data\nsns.lmplot('population', 'profit', df, size=6, fit_reg=False)\nplt.show()\n"""
ex1-linear regression/2_linear_regression.py,0,"b""import matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf\n\n# Parameters\ndisplay_step = 50\nlearning_rate = 0.01\ntraining_epochs = 1000\n\ndata = pd.read_csv('data/ex1data1.txt', names=['population', 'profit'])\n\nX_data = data[['population']]\nY_data = data[['profit']]\n\nn_samples = X_data.shape[0]  # Number of rows\n\n# tf Graph Input\nX = tf.placeholder('float', shape=X_data.shape)\nY = tf.placeholder('float', shape=Y_data.shape)\n\n# Set model weights\nW = tf.Variable(tf.zeros([1, 1]), name='weight')\nb = tf.Variable(tf.zeros(1), name='bias')\n\n# Construct a linear model\npred = tf.add(tf.multiply(X, W), b)\n\n# Mean squared error\n# cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\ncost = tf.reduce_mean(tf.square(pred-Y)) / 2.0\n\n# Gradient descent\n# may try other optimizers like AdadeltaOptimizer, AdagradOptimizer,\n# AdamOptimizer, FtrlOptimizer or RMSPropOptimizer\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n\n# Initializing the variables\ninit = tf.global_variables_initializer()\n\n# Launch the graph\nwith tf.Session() as sess:\n    sess.run(init)\n    cost_value, w_value, b_value = (0.0, 0.0, 0.0)\n    for epoch in range(training_epochs):\n        # Fit all training data\n        _, cost_value, w_value, b_value = sess.run(\n            (optimizer, cost, W, b),\n            feed_dict={X: X_data, Y: Y_data})\n\n        # Display logs per epoch step\n        if (epoch+1) % display_step == 0:\n            print('Epoch: {:04d} cost={:.9f} W={} b={}'.format(\n                epoch+1, cost_value, w_value, b_value))\n\n    print('Optimization Finished!')\n    print('Training cost={:.9f} W={} b={}'.format(\n        cost_value, w_value, b_value))\n\n    # Graphic display\n    plt.plot(X_data, Y_data, 'ro', label='Original data')\n    plt.plot(X_data, w_value * X_data + b_value, label='Fitted line')\n    plt.legend()\n    plt.show()\n"""
ex1-linear regression/3_lr_multiple_vars.py,0,"b'import matplotlib.pyplot as plt\nimport numpy\nimport pandas as pd\nimport tensorflow as tf\n\n# Parameters\ndisplay_step = 50\nlearning_rate = 0.01\ntraining_epochs = 1000\n\nraw_data = pd.read_csv(\'data/ex1data2.txt\',\n                       names=[\'square\', \'bedrooms\', \'price\'])\n\nX_data = raw_data[[\'square\', \'bedrooms\']]\nY_data = raw_data[[\'price\']]\n\n# Normalize the features\nX_data_mean = numpy.mean(X_data)\nX_data_std = numpy.std(X_data)\nX_data = (X_data - X_data_mean) / X_data_std\n\nn_samples, n_features = X_data.shape\n\n# tf Graph Input\nX = tf.placeholder(\'float\', shape=X_data.shape)\nY = tf.placeholder(\'float\', shape=Y_data.shape)\n\n# Set model weights\nW = tf.Variable(tf.zeros([n_features, 1]), name=\'weight\')\nb = tf.Variable(tf.zeros(1), name=\'bias\')\n\n# Construct a linear model\npred = tf.add(tf.matmul(X, W), b)\n\n# Mean squared error\ncost = tf.reduce_mean(tf.square(pred-Y)) / 2.0\n\n# Gradient descent\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n\n# Initializing the variables\ninit = tf.global_variables_initializer()\n\n# Launch the graph\nwith tf.Session() as sess:\n    sess.run(init)\n    cost_value, w_value, b_value = (0.0, 0.0, 0.0)\n    steps = numpy.array([])\n    J_hist = numpy.array([])\n    for epoch in range(training_epochs):\n        # Fit all training data\n        _, cost_value, w_value, b_value = sess.run(\n            (optimizer, cost, W, b), feed_dict={X: X_data, Y: Y_data})\n\n        steps = numpy.append(steps, [epoch])\n        J_hist = numpy.append(J_hist, [cost_value])\n\n        # Display logs per epoch step\n        if (epoch+1) % display_step == 0:\n            print(\'Epoch: {:04d} cost={:.9f} W={} b={}\'.format(\n                epoch+1, cost_value, w_value, b_value))\n\n    print(\'Optimization Finished!\')\n    print(\'Training cost={:.9f} W={} b={}\'.format(\n        cost_value, w_value, b_value))\n\n    # Graphic display\n    plt.figure(figsize=(6, 5))\n    plt.plot(steps, J_hist)\n    plt.xlabel(\'Number of iterations\')\n    plt.ylabel(\'Cost J\')\n    plt.show()\n\n    # Estimate the price - remember about normalization!\n    priceEst = [1, 1650, 3]\n    temp = [(i - j) for (i, j) in zip(\n        priceEst, [0, X_data_mean[0], X_data_mean[1]])]\n    price = numpy.array([(a / b) for (a, b) in zip(\n        temp, [1, X_data_std[0], X_data_std[1]])])\n\n    theta = numpy.reshape([b_value[0], w_value[0], w_value[1]], (3, 1))\n    print(""Price:\\n{}"".format(price))\n    print(""Theta:\\n{}"".format(theta))\n    print(\'Predicted price of a 1650 sq-ft, 3 br house (using normal equations\'\n          \'): ${:.2f}\'.format(numpy.dot(price, theta)[0]))\n\n# Learning rate\nbase = numpy.logspace(-1, -5, num=4)\nlr_candidates = numpy.sort(numpy.concatenate((base, base*3)))\nprint(\'lr_candidates: {}\'.format(lr_candidates))\ntraining_epochs = 80\n\nfig, ax = plt.subplots(figsize=(16, 9))\nfor learning_rate in lr_candidates:\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n    with tf.Session() as sess:\n        sess.run(init)\n        cost_data = numpy.array([])\n        for epoch in range(training_epochs):\n            # Fit all training data\n            _, cost_value = sess.run(\n                (optimizer, cost), feed_dict={X: X_data, Y: Y_data})\n            cost_data = numpy.append(cost_data, cost_value)\n        ax.plot(numpy.arange(training_epochs), cost_data, label=learning_rate)\n\nax.set_xlabel(\'epoch\', fontsize=18)\nax.set_ylabel(\'cost\', fontsize=18)\nax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nax.set_title(\'learning rate\', fontsize=18)\nplt.show()\n'"
ex2-logistic regression/1_logistic_regression.py,5,"b'import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\n\n# V1. Print data sample\ndf = pd.read_csv(\'data/ex2data1.txt\', names=[\'exam1\', \'exam2\', \'admitted\'])\nprint(df.shape)\nprint(df.head())\n\n# 2. Visualize the data\nsns.set(context=\'notebook\', style=\'darkgrid\',\n        palette=sns.color_palette(\'RdBu\', 2))\nsns.lmplot(\'exam1\', \'exam2\', hue=\'admitted\', data=df,\n           size=6,\n           fit_reg=False,\n           scatter_kws={\'s\': 50})\nplt.show()\n\n\n# 3. Plot the sigmoid function\n# Sigmoid function\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\n\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(np.arange(-10, 10, step=0.01),\n        sigmoid(np.arange(-10, 10, step=0.01)))\nax.set_ylim((-0.1, 1.1))\nax.set_xlabel(\'z\', fontsize=18)\nax.set_ylabel(\'g(z)\', fontsize=18)\nax.set_title(\'sigmoid function\', fontsize=18)\nplt.show()\n\n# 4. Run the logistic regression\nX_data = df[[\'exam1\', \'exam2\']]\nY_data = df[[\'admitted\']]\n\nnumFeatures = X_data.shape[1]\n\n# Tensorflow placeholders for the features and labels data.\nX = tf.placeholder(tf.float32, shape=[None, numFeatures])\nY = tf.placeholder(tf.float32, shape=[None, 1])\n\nW = tf.Variable(tf.zeros([numFeatures, 1]))\nb = tf.Variable(tf.zeros([1, 1]))\n\n# Sigmoid is used for the hypotesis - h(x) = x * W + b\npred = tf.nn.sigmoid(tf.matmul(X, W) + b)\n\ncost = -tf.reduce_sum(Y * tf.log(tf.clip_by_value(pred, 1e-9, 1)) +\n                      (1 - Y)*tf.log(tf.clip_by_value(1 - pred, 1e-9, 1)))\n\ncorrect_predict = tf.equal(tf.cast(tf.greater(pred, 0.5), tf.float32), Y)\naccuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n\noptimizer = tf.train.AdamOptimizer(0.01).minimize(cost)\ninit = tf.global_variables_initializer()\n\nnumEpochs = 4000\ndisplay_step = 50\n\nwith tf.Session() as sess:\n    sess.run(init)\n    for epoch in range(numEpochs):\n        _, cost_value, accuracy_value = sess.run(\n            [optimizer, cost, accuracy], feed_dict={X: X_data, Y: Y_data})\n        # Display logs per epoch step\n        if (epoch+1) % display_step == 0:\n            print(\'Epoch: {:04d} cost={:.9f} accuracy={}\'.format(\n                epoch+1, cost_value, accuracy_value))\n\n    w_value, b_value = sess.run([W, b], feed_dict={X: X_data, Y: Y_data})\n    print(\'W: {}, b: {}\'.format(w_value, b_value))\n\n    # Plot the decision boundary\n    sns.set(context=\'notebook\', style=\'ticks\', font_scale=1.5)\n    sns.lmplot(\'exam1\', \'exam2\', hue=\'admitted\', data=df,\n               size=6,\n               fit_reg=False,\n               scatter_kws={\'s\': 25}\n               )\n\n    plot_x = np.array([X_data.min()[0]-2, X_data.max()[0]+2])\n    plot_y = (-1. / w_value[0][0]) * (w_value[1][0] * plot_x + b_value[0][0])\n    plt.plot(plot_x, plot_y, \'grey\')\n\n    """"""\n    # Alternative plot:\n    x = np.arange(130, step=0.1)\n    y = -b_value[0][0] / w_value[0][0] - w_value[1][0] / w_value[0][0] * x\n    plt.plot(x, y, \'grey\')\n    """"""\n\n    plt.xlim(0, 130)\n    plt.ylim(0, 130)\n    plt.title(\'Decision Boundary\')\n    plt.show()\n'"
ex2-logistic regression/2_regularized.py,6,"b'import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\n\nFEATURE_MAPPING_POWER = 6\nNUM_EPOCHS = 10000\nREG_LAMBDA = 0.1  # overfit: 0.0001, ok: 0.1-0.01, underfit: 5\nMESH_RESOLUTION = 250.0\n\n# 1. Read the data and print the sample\ndf = pd.read_csv(\'data/ex2data2.txt\', names=[\'test1\', \'test2\', \'accepted\'])\nprint(df.shape)\nprint(df.head())\n\n# 2. Visualize the data\nsns.set(context=\'notebook\', style=\'darkgrid\',\n        palette=sns.color_palette(\'RdBu\', 2))\nsns.lmplot(\'test1\', \'test2\', hue=\'accepted\', data=df,\n           size=6,\n           fit_reg=False,\n           scatter_kws={\'s\': 50})\n\nplt.show()\n\n# 3. Run the logistic regression with feature mapping and regularization\n\n\ndef feature_mapping(f1, f2, power):\n    """"""Helper function for feature mapping""""""\n    data = {\'f{}{}\'.format(i - p, p): np.power(f1, i - p) * np.power(f2, p)\n            for i in np.arange(power + 1)\n            for p in np.arange(i + 1)\n            }\n\n    return pd.DataFrame(data)\n\n\nX_data = feature_mapping(df.test1, df.test2, power=FEATURE_MAPPING_POWER)\nY_data = df[[\'accepted\']]\nnumFeatures = X_data.shape[1]\nnumSamples = X_data.shape[0]\n\n# Tensorflow placeholders for the features and labels data.\nX = tf.placeholder(tf.float32, shape=[None, numFeatures])\nY = tf.placeholder(tf.float32, shape=[None, 1])\n\nW = tf.Variable(tf.zeros([numFeatures, 1]))\n# after feature mapping, f00 is always 1, so W[0] will be our b\n\n# Sigmoid is used for the hypotesis - h(x) = x * W + b\npred = tf.nn.sigmoid(tf.matmul(X, W))\n\ncost = -tf.reduce_sum(Y * tf.log(tf.clip_by_value(pred, 1e-9, 1)) +\n                      (1 - Y) * tf.log(tf.clip_by_value(1 - pred, 1e-9, 1))\n                      ) / numSamples\nregularized_W = tf.slice(W, [1, 0], [-1, -1])  # don\'t regularize W[0]\nregularizer = tf.reduce_sum(tf.square(regularized_W))*REG_LAMBDA / numFeatures\n\ncorrect_predict = tf.equal(tf.cast(tf.greater(pred, 0.5), tf.float32), Y)\naccuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n\noptimizer = tf.train.AdamOptimizer(0.01).minimize(cost + regularizer)\ninit = tf.global_variables_initializer()\n\ndisplay_step = 50\n\nwith tf.Session() as sess:\n    sess.run(init)\n    w_value = []\n    for epoch in range(NUM_EPOCHS):\n        _, cost_value, reg_cost, accuracy_value, w_value = sess.run(\n            [optimizer, cost, regularizer, accuracy, W],\n            feed_dict={X: X_data, Y: Y_data})\n        # Display logs per epoch step\n        if (epoch+1) % display_step == 0:\n            print(\'Epoch: {:04d} cost={:.9f} reg={:.9f} accuracy={}\'.format(\n                epoch+1, cost_value, reg_cost, accuracy_value))\n\n    print(\'w_value\', w_value)\n\n    # Plot the input data\n    x_pos = [v for v in df[\'test1\'].values]\n    y_pos = [v for v in df[\'test2\'].values]\n    labels = [\'r\' if v == 1 else \'b\' for v in Y_data.values]\n    plt.scatter(x_pos, y_pos, c=labels, edgecolor=\'k\', s=50)\n\n    # Plot the decision boundary contour\n    x_min, x_max = min(x_pos) - 0.5, max(x_pos) + 0.5\n    y_min, y_max = min(y_pos) - 0.5, max(y_pos) + 0.5\n    mesh_x, mesh_y = np.meshgrid(np.arange(x_min, x_max,\n                                           (x_max - x_min) / MESH_RESOLUTION),\n                                 np.arange(y_min, y_max,\n                                           (y_max - y_min) / MESH_RESOLUTION))\n    pts = feature_mapping(mesh_x.ravel(), mesh_y.ravel(),\n                          power=FEATURE_MAPPING_POWER)\n    classifier = tf.greater(pred, 0.5)\n    mesh_color = sess.run(classifier, feed_dict={X: pts})\n    mesh_color = np.array(mesh_color).reshape(mesh_x.shape)\n    plt.contour(mesh_x, mesh_y, mesh_color, linewidths=2)\n\n    plt.show()\n'"
ex3-multi-class-classification/1_logistic_regression.py,5,"b'import argparse\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import io, misc\nfrom sklearn import metrics\nimport tensorflow as tf\n\n# Parse the command line arguments (or use default values).\nparser = argparse.ArgumentParser(description=\'Recognizing hand-written number \'\n                                 \'using multiclass logistic regression.\')\nparser.add_argument(\'-lr\', \'--learning_rate\', type=float,\n                    help=\'learning rate for the algorithm (default: 0.1)\',\n                    default=0.1)\nparser.add_argument(\'-r\', \'--regularization\', type=float,\n                    help=\'theta regularization value (default: 0.1)\',\n                    default=0.1)\nparser.add_argument(\'-e\', \'--epochs\', type=int,\n                    help=\'number of epochs (default: 400)\', default=400)\nparser.add_argument(\'-o\', \'--optimizer\', type=str,\n                    help=\'tensorflow optimizer class (default: AdamOptimizer)\',\n                    default=\'AdamOptimizer\')\n# other optimizers to try out: GradientDescentOptimizer, AdadeltaOptimizer,\n# AdagradOptimizer, AdamOptimizer, FtrlOptimizer, RMSPropOptimizer\n\nparser.add_argument(\'--verbose\', dest=\'verbose\', action=\'store_true\',\n                    help=\'increase output verbosity\')\nparser.add_argument(\'--silent\', dest=\'verbose\', action=\'store_false\')\nparser.set_defaults(verbose=True)\nargs = parser.parse_args()\n\noptimizer_class = getattr(tf.train, args.optimizer)\n\n# Load the hand-written digits data.\nfilename = \'data/ex3data1.mat\'\ndata = io.loadmat(filename)\nX_data, Y_data = data[\'X\'], data[\'y\']\n\n# y==10 is digit 0, convert it to 0 then to make the code below simpler\nY_data[Y_data == 10] = 0\n\nnumSamples = X_data.shape[0]\n\nif args.verbose:\n    print(\'Shape of the X_data\', X_data.shape)\n    print(\'Shape of the Y data\', Y_data.shape)\n\n\ndef plot_100_images(X):\n    """"""Plot 100 randomly picked digits.""""""\n    width, height = 20, 20\n    nrows, ncols = 10, 10\n    indices_to_display = np.random.choice(range(X.shape[0]), nrows * ncols)\n\n    big_picture = np.zeros((height * nrows, width * ncols))\n\n    irow, icol = 0, 0\n\n    for idx in indices_to_display:\n        if icol == ncols:\n            irow += 1\n            icol = 0\n        iimg = X[idx].reshape(width, height).T  # transpose the data set\n        big_picture[irow * height:irow * height + iimg.shape[0],\n                    icol * width:icol * width + iimg.shape[1]] = iimg\n        icol += 1\n    fig = plt.figure(figsize=(6, 6))\n    img = misc.toimage(big_picture)\n    plt.imshow(img, cmap=matplotlib.cm.Greys_r)\n\n    plt.show()\n\n\nif args.verbose:\n    # Plot some of the loaded digits.\n    plot_100_images(X_data)\n\n# For each row, add a constant (1) at the beginning, needed for logistic\n# regression.\nX_data = np.insert(X_data, 0, 1, axis=1)\n\n\ndef logistic_regression(X_data, Y_data, optimizer_class, reg, learning_rate,\n                        epochs, verbose=True):\n    """"""\n    Trains and returns a classifier that recognizes one digit (although the\n    code below is fairly general).\n    :param X_data: Our digit data (learning set)\n    :param Y_data: Digit label, 1 for row containing the digit we\'re trying to\n                   learn to recognize, 0 for others\n    :param optimizer_class: class that will be used to create optimizer object.\n    :param reg: regularization parameter\n    :param learning_rate: learning rate parameter\n    :param epochs: number of epochs\n    :param verbose: whether to print out some debugging information\n    :return: Trained classifier that can be used to classify digits.\n    """"""\n    numFeatures = X_data.shape[1]\n    numSamples = X_data.shape[0]\n    X = tf.placeholder(tf.float32, shape=[None, numFeatures])\n    Y = tf.placeholder(tf.float32, shape=[None, 1])\n    W = tf.Variable(tf.zeros([numFeatures, 1]))\n    pred = tf.nn.sigmoid(tf.matmul(X, W))\n    cost = -tf.reduce_sum(Y * tf.log(tf.clip_by_value(pred, 1e-9, 1)) +\n                          (1 - Y) * tf.log(tf.clip_by_value(1 - pred, 1e-9, 1))\n                          ) / numSamples\n    regularized_W = tf.slice(W, [1, 0], [-1, -1])  # don\'t regularize W[0]\n    regularizer = tf.reduce_sum(tf.square(regularized_W)) * reg / numFeatures\n    correct_predict = tf.equal(tf.cast(tf.greater(pred, 0.5), tf.float32), Y)\n    accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n\n    optimizer = optimizer_class(learning_rate).minimize(cost + regularizer)\n    init = tf.global_variables_initializer()\n\n    # Create a tensorflow session\n    sess = tf.Session()\n    sess.run(init)\n    for epoch in range(epochs):\n        _, cost_value, reg_cost, accuracy_value = sess.run(\n            [optimizer, cost, regularizer, accuracy],\n            feed_dict={X: X_data, Y: Y_data})\n        # Display logs per epoch step\n        if verbose and (epoch + 1) % 50 == 0:\n            print(\'Epoch: {:04d} cost={:.9f} reg={:.9f} accuracy={}\'.format(\n                epoch+1, cost_value, reg_cost, accuracy_value))\n\n    classifier = tf.greater(pred, 0.5)\n    return lambda X_data: sess.run([pred, classifier], feed_dict={X: X_data})\n\n\nclassifiers = []  # This will hold our 10 classifiers, one for each digit.\nfor k in range(10):\n    # prepare the labels for the current digit.\n    Yk_data = (Y_data == k).astype(int)\n    print(""Training classifier for digit {:d}..."".format(k))\n    tk = logistic_regression(X_data, Yk_data, optimizer_class,\n                             args.regularization, args.learning_rate,\n                             args.epochs, args.verbose)\n    classifiers.append(tk)\n\n# Now we\'re using each of the classifiers to estimate how much a given row\n# reassembles the digit it tried to learn.\npredictions = []\nfor t in classifiers:\n    # Classifier returns 2 values, a score and a boolean (if the score is\n    # above 0.5). We need just the score as we treat it as a confidence level.\n    pred, _ = t(X_data)\n    predictions.append(pred)\n\n# For each row, merge the predictions from all the classifiers. Pick the\n# classifier with the highest confidence level.\nprob_matrix = np.concatenate(predictions, axis=1)\ny_pred = np.argmax(prob_matrix, axis=1)\n\nif args.verbose:\n    print(""y_pred:"", y_pred)\n    print(""Y_data:"", Y_data)\n\n# Print the final report\nprint(""Optimizer {}, epochs {:d}, learning_rate {:0.2f}, regularization param ""\n      ""{:0.2f}"".format(args.optimizer, args.epochs, args.learning_rate,\n                       args.regularization))\nprint(metrics.classification_report(Y_data, y_pred))\n'"
ex3-multi-class-classification/2_neural_networks.py,6,"b'# This classifies the same digit as the logistic regression classifiers from\n# the first step. But here we\'re using a pre-trained neural network classifier\n# (loaded from data/ex3weights.mat)\nimport numpy as np\nfrom scipy import io\nfrom sklearn import metrics\n\n# Load the data.\nfilename = \'data/ex3data1.mat\'\ndata = io.loadmat(filename)\nX_data, Y_data = data[\'X\'], data[\'y\']\n\nnumSamples = X_data.shape[0]\n\n# Add a \'constant\' to each of the rows.\nX_data = np.insert(X_data, 0, 1, axis=1)\n\nprint(""X_data shape "", X_data.shape, "", Y_data shape"", Y_data.shape)\n\n# Load the pre-trained network.\nweights = io.loadmat(\'data/ex3weights.mat\')\ntheta1, theta2 = weights[\'Theta1\'], weights[\'Theta2\']\n\nprint(""Theta1 shape"", theta1.shape, "", theta2 shape"", theta2.shape)\n\n# Classify the input data using the pre-trained network/\na1 = X_data\nz2 = np.matmul(a1, np.transpose(theta1))  # (5000,401) @ (25,401).T = (5000,25)\nprint(""z2 shape"", z2.shape)\n\nz2 = np.insert(z2, 0, values=np.ones(z2.shape[0]), axis=1)\n\n\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\n\na2 = sigmoid(z2)\nprint(""a2 shape"", a2.shape)  # (5000, 26)\n\nz3 = np.matmul(a2, np.transpose(theta2))\nprint(""z3 shape"", z3.shape)  # (5000, 10)\n\na3 = sigmoid(z3)\n\n# Numpy is 0 base index. We add +1 to make it compatible with matlab (so we can\n# compare y_pred with the correct answers from Y_data).\ny_pred = np.argmax(a3, axis=1) + 1\nprint(""y_pred shape"", y_pred.shape)  # (5000,)\n\n# Print the report\nprint(metrics.classification_report(Y_data, y_pred))\n'"
ex4-neural networks learning/1_nn_training_example.py,2,"b'# Training a very simple neural network for hand-written digits recognition.\n#\n# This loads the images of hand-written digits from a data/ex4data1.mat file.\n# Each digit is a described by 401 numbers. 400 numbers represent the digit\n# image (20x20px) and the last number is the digit label (the correct answer).\n#\n# We will be using a network with one hidden layer (with 25 neurons - this can\n# be changed using a command line param). So the network has 400 inputs (one\n# for each pixel), a hidden layer and 10 outputs (one for each digit).\n\nimport argparse\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import io\nfrom sklearn import metrics\nimport tensorflow as tf\n\ntf.logging.set_verbosity(tf.logging.ERROR)\n\n# size of the a single digit image (in pixels)\nIMAGE_WIDTH = 20\nIMAGE_HEIGHT = 20\n\n# Parse the command line arguments (or use default values).\nparser = argparse.ArgumentParser(\n    description=\'Recognizing hand-written number using neural network.\')\nparser.add_argument(\'-s\', \'--hidden_layer_size\', type=int,\n                    help=\'number of neurons in the hidden layer (default: 64)\',\n                    default=64)\nparser.add_argument(\'-lr\', \'--learning_rate\', type=float,\n                    help=\'learning rate for the algorithm (default: 0.5)\',\n                    default=0.5)\nparser.add_argument(\'-d\', \'--decay\', dest=\'decay\', type=float,\n                    help=\'learning rate decay (default: 0.9999, 1.0 means \'\n                    \'no decay)\', default=0.9999)\nparser.add_argument(\'-e\', \'--epochs\', type=int,\n                    help=\'number of epochs (default: 1000)\', default=1000)\nparser.add_argument(\'-o\', \'--optimizer\', type=str,\n                    help=\'tensorflow optimizer class \'\n                    \'(default: AdagradOptimizer)\', default=\'AdagradOptimizer\')\nparser.add_argument(\'-v\', \'--verbose\', dest=\'verbose\', action=\'store_true\',\n                    help=\'increase output verbosity\')\nargs = parser.parse_args()\n\noptimizer_class = getattr(tf.train, args.optimizer)\n\n# Load the hand-written digits data.\nfilename = \'data/ex4data1.mat\'\ndata = io.loadmat(filename)\nX_data, Y_data = data[\'X\'], data[\'y\']\n\n# y==10 is digit 0, convert it to 0 then to make the code below simpler\nY_data[Y_data == 10] = 0\n\nif args.verbose:\n    print(\'Shape of the X_data\', X_data.shape)\n    print(\'Shape of the Y data\', Y_data.shape)\n\n\ndef plot_100_images(X, indices=None):\n    """"""Plot 100 randomly picked digits.""""""\n    width, height = IMAGE_WIDTH, IMAGE_HEIGHT\n    nrows, ncols = 10, 10\n    if indices is None:\n        indices = range(X.shape[0])\n    indices_to_display = np.random.choice(indices, nrows * ncols)\n\n    big_picture = np.zeros((height * nrows, width * ncols))\n\n    irow, icol = 0, 0\n    for idx in indices_to_display:\n        if icol == ncols:\n            irow += 1\n            icol = 0\n        iimg = X[idx].reshape(width, height).T  # transpose the data set\n        big_picture[irow * height:irow * height + iimg.shape[0],\n                    icol * width:icol * width + iimg.shape[1]] = iimg\n        icol += 1\n    plt.imshow(big_picture, cmap=matplotlib.cm.Greys_r)\n\n    plt.show()\n\n\nif args.verbose:\n    # Plot some of the loaded digits.\n    print(""Drawing 100 random digits from the input data"")\n    plot_100_images(X_data)\n\nnumSamples = X_data.shape[0]\n\n\ndef fc_layer(input, size_in, size_out):\n    """"""Creates a fully connected nn layer.\n\n    The layer is initialized with random numbers from normal distribution.\n    """"""\n    w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1))\n    b = tf.Variable(tf.truncated_normal([size_out], stddev=0.1))\n    return tf.nn.relu(tf.matmul(input, w) + b)\n\n\n# Setup placeholders, and reshape the data\nx = tf.placeholder(tf.float32, shape=[None, IMAGE_WIDTH * IMAGE_HEIGHT])\n\n# 10 outputs, one for each digit\ny = tf.placeholder(tf.float32, shape=[None, 10])\n\nif args.verbose:\n    print(""Creating a network with {:d} neurons in a hidden layer"".format(\n        args.hidden_layer_size))\n\nhidden_layer = fc_layer(x, IMAGE_WIDTH * IMAGE_HEIGHT, args.hidden_layer_size)\noutput_layer = fc_layer(hidden_layer, args.hidden_layer_size, 10)\n\n# define cost function and\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n    logits=output_layer, labels=y))\n\n# learning rate decay\nbatch = tf.Variable(0, trainable=False)\nlearning_rate = tf.train.exponential_decay(\n  args.learning_rate,  # Base learning rate.\n  batch,               # Current index into the dataset.\n  1,                   # Decay step.\n  args.decay,          # Decay rate.\n  staircase=True)\n\noptimizer = optimizer_class(learning_rate).minimize(cost, global_step=batch)\n\n# measure accuracy - pick the output with the highest score as the prediction\npred = tf.argmax(tf.nn.softmax(output_layer), 1)  # softmax is optional here\ncorrect_prediction = tf.equal(pred, tf.argmax(y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n# Y_data is a 1-column vector with the correct answer (digit) in each row.\n# As our neural network has 10 outputs (one for each digit) we have to convert\n# Y_data to a sparse matrix. So each row in converted from a single digit to a\n# 10-digit vector having nine zeros and a single number one (indicating the\n# correct answer for a given row/image)\nY_sparse = tf.keras.utils.to_categorical(Y_data, 10)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\nprint(""Training ({:d} epochs)..."".format(args.epochs))\n\nfor epoch in range(args.epochs):\n    _, accuracy_value, cost_value, current_lr = sess.run(\n        [optimizer, accuracy, cost, learning_rate],\n        feed_dict={x: X_data, y: Y_sparse})\n\n    if args.verbose and not (epoch + 1) % 20:\n        print(\'Epoch: {:04d} cost={:.9f} accuracy={:.6f} \'\n              \'learning_rate={:.6f}\'.format(epoch+1, cost_value,\n                                            accuracy_value, current_lr))\n\n# Get the answers (from the nn) and print the accuracy report\ny_pred = sess.run(pred, feed_dict={x: X_data, y: Y_sparse})\nprint(metrics.classification_report(Y_data, y_pred))\n\nif args.verbose:\n    print(""Drawing 100 digits classified as \'5\'"")\n    indices = []\n    for i in range(len(y_pred)):\n        if y_pred[i] == 5:\n            indices.append(i)\n    plot_100_images(X_data, indices)\n'"
ex4-neural networks learning/2_learning_and_test_sets.py,0,"b'# This exercise is very similar to the previous one. The only difference is\n# that we will get better overview of how the neural network is learning. To do\n# this we will split out input data into learning set and test set. We will\n# perform all the learning using the first set of data. Of course as the number\n# of epochs increases, so does the accuracy on the learning set (as the cost\n# function on this set is minimized by the learning process). But every now and\n# then we will check the accuracy on the test set - data that the network\n# hasn\'t seen during the learning phase. Ideally the accuracy on the learning\n# set should increase along with the accuracy on the test set, as this means\n# the network has ""learned"" something general that can be applied on a data\n# that was not seen. At the end we will draw a little chart to check how the\n# accuracy was changing over time for both sets.\nimport argparse\nimport matplotlib.pyplot as plt\nfrom scipy import io\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\n# size of a single digit image (in pixels)\nIMAGE_WIDTH = 20\nIMAGE_HEIGHT = 20\nTEST_SIZE = 0.25  # test set will be 25% of the data\n\n# Parse the command line arguments (or use default values).\nparser = argparse.ArgumentParser(\n    description=\'Recognizing hand-written number using neural network.\')\nparser.add_argument(\'-s\', \'--hidden_layer_size\', type=int,\n                    help=\'number of neurons in the hidden layer (default: 64)\',\n                    default=64)\nparser.add_argument(\'-lr\', \'--learning_rate\', type=float,\n                    help=\'learning rate for the algorithm (default: 0.5)\',\n                    default=0.5)\nparser.add_argument(\'-d\', \'--decay\', dest=\'decay\', type=float,\n                    help=\'learning rate decay (default: 0.9999, 1.0 means \'\n                    \'no decay)\', default=0.9999)\nparser.add_argument(\'-e\', \'--epochs\', type=int,\n                    help=\'number of epochs (default: 1000)\', default=1000)\nparser.add_argument(\'-o\', \'--optimizer\', type=str,\n                    help=\'tensorflow optimizer class (default: \'\n                    \'AdagradOptimizer)\', default=\'AdagradOptimizer\')\nparser.add_argument(\'-v\', \'--verbose\', dest=\'verbose\', action=\'store_true\',\n                    help=\'increase output verbosity\')\nargs = parser.parse_args()\n\noptimizer_class = getattr(tf.train, args.optimizer)\n\n# Load the hand-written digits data.\nfilename = \'data/ex4data1.mat\'\ndata = io.loadmat(filename)\nX_data, Y_data = data[\'X\'], data[\'y\']\n\n# y==10 is digit 0, convert it to 0 then to make the code below simpler\nY_data[Y_data == 10] = 0\n\n# Split the data\nX_data, X_test_data, Y_data, Y_test_data = train_test_split(\n    X_data, Y_data, test_size=TEST_SIZE)\n\nif args.verbose:\n    print(\'Shape of the X_data\', X_data.shape)\n    print(\'Shape of the Y_data\', Y_data.shape)\n    print(\'Shape of the X_test_data\', X_test_data.shape)\n    print(\'Shape of the Y_test_data\', Y_test_data.shape)\n\nnumSamples = X_data.shape[0]\nnumTestSamples = X_test_data.shape[0]\n\n\ndef fc_layer(input, size_in, size_out):\n    """"""Creates a fully connected nn layer.\n\n    The layer is initialized with random numbers from normal distribution.\n    """"""\n    w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1))\n    b = tf.Variable(tf.truncated_normal([size_out], stddev=0.1))\n    return tf.nn.relu(tf.matmul(input, w) + b)\n\n\n# Setup placeholders, and reshape the data\nx = tf.placeholder(tf.float32, shape=[None, IMAGE_WIDTH * IMAGE_HEIGHT])\n# 10 outputs, one for each digit\ny = tf.placeholder(tf.float32, shape=[None, 10])\n\nif args.verbose:\n    print(""Creating a network with {:d} neurons in a hidden layer"".format(\n        args.hidden_layer_size))\n\nhidden_layer = fc_layer(x, IMAGE_WIDTH * IMAGE_HEIGHT, args.hidden_layer_size)\noutput_layer = fc_layer(hidden_layer, args.hidden_layer_size, 10)\n\n# define cost function and\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n    logits=output_layer, labels=y))\n# learning rate decay\nbatch = tf.Variable(0, trainable=False)\nlearning_rate = tf.train.exponential_decay(\n  args.learning_rate,  # Base learning rate.\n  batch,               # Current index into the dataset.\n  1,                   # Decay step.\n  args.decay,          # Decay rate.\n  staircase=True)\n\noptimizer = optimizer_class(learning_rate).minimize(cost, global_step=batch)\n\n# measure accuracy - pick the output with the highest score as the prediction\npred = tf.argmax(tf.nn.softmax(output_layer), 1)  # softmax is optional here\ncorrect_prediction = tf.equal(pred, tf.argmax(y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n# Convert the aswers vector to a sparse matrix (refer to\n# 1_nn_training_example.py for a more detailed comment)\nY_sparse = tf.keras.utils.to_categorical(Y_data, 10)\nY_test_sparse = tf.keras.utils.to_categorical(Y_test_data, 10)\n\nprint(""Training..."")\n\n# Variables for tracking accuracy over time\niter_arr = []\ntrain_accuracy_arr = []\ntest_accuracy_arr = []\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\nfor epoch in range(args.epochs):\n    if not (epoch+1) % 5:\n        train_accuracy = sess.run([accuracy],\n                                  feed_dict={x: X_data, y: Y_sparse})\n        test_accuracy = sess.run([accuracy],\n                                 feed_dict={x: X_test_data, y: Y_test_sparse})\n        iter_arr.append(epoch)\n        train_accuracy_arr.append(train_accuracy)\n        test_accuracy_arr.append(test_accuracy)\n        if args.verbose:\n            print(\'Epoch: {:04d}, accuracy: {}, test accuracy: {}\'.format(\n                epoch+1, train_accuracy, test_accuracy))\n    sess.run([optimizer], feed_dict={x: X_data, y: Y_sparse})\n\nprint(""Accuracy report for the learning set"")\ny_pred = sess.run(pred, feed_dict={x: X_data, y: Y_sparse})\nprint(metrics.classification_report(Y_data, y_pred))\n\nprint(""Accuracy report for the test set"")\ny_test_pred = sess.run(pred, feed_dict={x: X_test_data, y: Y_test_sparse})\nprint(metrics.classification_report(Y_test_data, y_test_pred))\n\nprint(""Plotting accuracy over time..."")\nplt.plot(iter_arr, train_accuracy_arr, label=\'train accuracy\')\nplt.plot(iter_arr, test_accuracy_arr, label=\'test accuracy\')\nplt.xlabel(\'epoch\', fontsize=16)\nplt.ylabel(\'accuracy\', fontsize=16)\nplt.legend(bbox_to_anchor=(0, 1), loc=2, borderaxespad=0.)\n\nplt.show()\n'"
ex4-neural networks learning/3_regularization.py,0,"b'# In this example we\'re adding simple regularization to try prevent\n# overfitting. Regularization is implemented by minimizing non-bias NN\n# variables. By playing with the ""r"" parameter you can see that it can decrease\n# the difference between the learn and test set accuracy. Unfortunately it\n# doesn\'t produce much better results, as fully connected network is not best\n# suited for recognizing images and it hard to push its performance any\n# further. Also regularization that works for linear regression is not best\n# suited for deep networks as they are highly nonconvex.\n# In te next example we will implement convolutional network that is able to\n# look for specific shapes in the image rather than pixels. We will also use\n# dropout regularization.\n\nimport argparse\nimport matplotlib.pyplot as plt\nfrom scipy import io\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\n# size of a single digit image (in pixels)\nIMAGE_WIDTH = 20\nIMAGE_HEIGHT = 20\nTEST_SIZE = 0.25  # test set will be 25% of the data\n\n# Parse the command line arguments (or use default values).\nparser = argparse.ArgumentParser(\n    description=\'Recognizing hand-written number using neural network.\')\nparser.add_argument(\'-s\', \'--hidden_layer_size\', type=int,\n                    help=\'number of neurons in the hidden layer (default: 64)\',\n                    default=64)\nparser.add_argument(\'-lr\', \'--learning_rate\', type=float,\n                    help=\'learning rate for the algorithm (default: 0.5)\',\n                    default=0.5)\nparser.add_argument(\'-d\', \'--decay\', dest=\'decay\', type=float,\n                    help=\'learning rate decay (default: 0.9999, 1.0 means \'\n                    \'no decay)\', default=0.9999)\nparser.add_argument(\'-r\', \'--regularizer\', type=float,\n                    help=\'regularization multiplier (default: 0.001)\',\n                    default=0.001)\nparser.add_argument(\'-e\', \'--epochs\', type=int,\n                    help=\'number of epochs (default: 1000)\', default=1000)\nparser.add_argument(\'-o\', \'--optimizer\', type=str,\n                    help=\'tensorflow optimizer class (default: \'\n                    \'AdagradOptimizer)\', default=\'AdagradOptimizer\')\nparser.add_argument(\'-v\', \'--verbose\', dest=\'verbose\', action=\'store_true\',\n                    help=\'increase output verbosity\')\nargs = parser.parse_args()\n\noptimizer_class = getattr(tf.train, args.optimizer)\n\n# Load the hand-written digits data.\nfilename = \'data/ex4data1.mat\'\ndata = io.loadmat(filename)\nX_data, Y_data = data[\'X\'], data[\'y\']\n\n# y==10 is digit 0, convert it to 0 then to make the code below simpler\nY_data[Y_data == 10] = 0\n\n# Split the data\nX_data, X_test_data, Y_data, Y_test_data = train_test_split(\n    X_data, Y_data, test_size=TEST_SIZE)\n\n# In this example, instead of playing with sparse Y vectors, we simply keep the\n# class labels and use sparse_softmax_cross_entropy_with_logits later as a cost\n# function.\nY_data = Y_data.ravel()\nY_test_data = Y_test_data.ravel()\n\nif args.verbose:\n    print(\'Shape of the X_data\', X_data.shape)\n    print(\'Shape of the Y_data\', Y_data.shape)\n    print(\'Shape of the X_test_data\', X_test_data.shape)\n    print(\'Shape of the Y_test_data\', Y_test_data.shape)\n\nnumSamples = X_data.shape[0]\nnumTestSamples = X_test_data.shape[0]\n\n\ndef fc_layer(input, size_in, size_out):\n    """"""Creates a fully connected nn layer.\n\n    The layer is initialized with random numbers from normal distribution.\n    """"""\n    w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1))\n    # var name needed later for variable filtering\n    b = tf.Variable(tf.truncated_normal([size_out], stddev=0.1), name=\'bias\')\n    return tf.nn.relu(tf.matmul(input, w) + b)\n\n\n# Setup placeholders, and reshape the data\nx = tf.placeholder(tf.float32, shape=[None, IMAGE_WIDTH * IMAGE_HEIGHT])\n# simple vector, output is the class number\ny = tf.placeholder(tf.int64, shape=[None])\n\nif args.verbose:\n    print(""Creating a network with {:d} neurons in a hidden layer"".format(\n        args.hidden_layer_size))\n\nhidden_layer = fc_layer(x, IMAGE_WIDTH * IMAGE_HEIGHT, args.hidden_layer_size)\n\noutput_layer = fc_layer(hidden_layer, args.hidden_layer_size, 10)\n\n# calculate the regularization cost by combining non-bias variables\nnn_vars = tf.trainable_variables()\nregularization_loss = tf.add_n([tf.nn.l2_loss(v) for v in nn_vars\n                                if \'bias\' not in v.name]) * args.regularizer\n# define cost function\ncost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n    logits=output_layer, labels=y))\n\n# learning rate decay\nbatch = tf.Variable(0, trainable=False)\nlearning_rate = tf.train.exponential_decay(\n  args.learning_rate,  # Base learning rate.\n  batch,               # Current index into the dataset.\n  1,                   # Decay step.\n  args.decay,          # Decay rate.\n  staircase=True)\n\noptimizer = optimizer_class(learning_rate).minimize(cost + regularization_loss,\n                                                    global_step=batch)\n\n# measure accuracy - pick the output with the highest score as the prediction\npred = tf.argmax(tf.nn.softmax(output_layer), 1)  # softmax is optional here\ncorrect_prediction = tf.equal(pred, y)\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\nprint(""Training..."")\n\n# Variables for tracking accuracy over time\niter_arr = []\ntrain_accuracy_arr = []\ntest_accuracy_arr = []\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\nfor epoch in range(args.epochs):\n\n    if not (epoch+1) % 5:\n        train_accuracy = sess.run([accuracy], feed_dict={x: X_data, y: Y_data})\n        test_accuracy = sess.run([accuracy],\n                                 feed_dict={x: X_test_data, y: Y_test_data})\n        iter_arr.append(epoch)\n        train_accuracy_arr.append(train_accuracy)\n        test_accuracy_arr.append(test_accuracy)\n        if args.verbose:\n            print(\'Epoch: {:04d}, accuracy: {}, test accuracy: {}\'.format(\n                epoch+1, train_accuracy, test_accuracy))\n    sess.run([optimizer], feed_dict={x: X_data, y: Y_data})\n\nprint(""Accuracy report for the learning set"")\ny_pred = sess.run(pred, feed_dict={x: X_data, y: Y_data})\nprint(metrics.classification_report(Y_data, y_pred))\n\nprint(""Accuracy report for the test set"")\ny_test_pred = sess.run(pred, feed_dict={x: X_test_data, y: Y_test_data})\nprint(metrics.classification_report(Y_test_data, y_test_pred))\n\nprint(""Plotting accuracy over time..."")\nplt.plot(iter_arr, train_accuracy_arr, label=\'train accuracy\')\nplt.plot(iter_arr, test_accuracy_arr, label=\'test accuracy\')\nplt.xlabel(\'epoch\', fontsize=16)\nplt.ylabel(\'accuracy\', fontsize=16)\nplt.legend(bbox_to_anchor=(0, 1), loc=2, borderaxespad=0.)\n\nplt.show()\n'"
ex4-neural networks learning/4_convolutional_nn.py,0,"b'# Here we replace a simple, fully connected neural network with something more\n# suitable for image classification: convolutional network. We use two\n# convolutional layers with 5x5 filter. You can read move about this kind of\n# networks for example here: http://cs231n.github.io/convolutional-networks/\n# As this approach is a little more CPU-expensive that the previous one, we are\n# also introducing batching. In each training iteration we will use a subset of\n# our train set (default: 50 images). This helps us iterate quicker.\n\nimport argparse\nimport math\nimport matplotlib.pyplot as plt\nfrom scipy import io\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\n# size of a single digit image (in pixels)\nIMAGE_WIDTH = 20\nIMAGE_HEIGHT = 20\nTEST_SIZE = 0.25  # test set will be 25% of the data\nFSIZE = 5  # Convolutional layer filer size (5x5px)\nCONV_LAYERS = 2\nCONV1_SIZE = 32\nCONV2_SIZE = 64\n\n# Parse the command line arguments (or use default values)\nparser = argparse.ArgumentParser(\n    description=\'Recognizing hand-written number using neural network.\')\nparser.add_argument(\'-s\', \'--fully_connected_layer_size\', type=int,\n                    help=\'number of neurons in the densely connected layer \'\n                    \'(default: 1024)\', default=1024)\nparser.add_argument(\'-d\', \'--dropout\', type=float,\n                    help=\'dropout probability (default: 0.5)\', default=0.5)\nparser.add_argument(\'-b\', \'--batch_size\', type=int,\n                    help=\'Batch size for a single learning step (default: 50)\',\n                    default=50)\nparser.add_argument(\'-e\', \'--epochs\', type=int,\n                    help=\'number of epochs (default: 1000)\', default=1000)\nparser.add_argument(\'-o\', \'--optimizer\', type=str,\n                    help=\'tensorflow optimizer class (default: \'\n                    \'AdagradOptimizer)\', default=\'AdagradOptimizer\')\nparser.add_argument(\'-lr\', \'--learning_rate\', type=float,\n                    help=\'learning rate for the algorithm (default: 0.05)\',\n                    default=0.05)\nparser.add_argument(\'--decay\', dest=\'decay\', type=float,\n                    help=\'learning rate decay (default: 0.95, 1.0 means \'\n                    \'no decay)\', default=0.95)\nparser.add_argument(\'-v\', \'--verbose\', dest=\'verbose\', action=\'store_true\',\n                    help=\'increase output verbosity\')\nargs = parser.parse_args()\n\noptimizer_class = getattr(tf.train, args.optimizer)\n\n# Load the hand-written digits data.\nfilename = \'data/ex4data1.mat\'\ndata = io.loadmat(filename)\nX_data, Y_data = data[\'X\'], data[\'y\']\n\n# y==10 is digit 0, convert it to 0 then to make the code below simpler\nY_data[Y_data == 10] = 0\n\n# Split the data\nX_data, X_test_data, Y_data, Y_test_data = train_test_split(\n    X_data, Y_data, test_size=TEST_SIZE)\n\n# Convert the Y matrixes to 1-D arrays as we\'re using\n# sparse_softmax_cross_entropy_with_logits\nY_data = Y_data.ravel()\nY_test_data = Y_test_data.ravel()\n\nif args.verbose:\n    print(\'Shape of the X_data\', X_data.shape)\n    print(\'Shape of the Y_data\', Y_data.shape)\n    print(\'Shape of the X_test_data\', X_test_data.shape)\n    print(\'Shape of the Y_test_data\', Y_test_data.shape)\n\nnumSamples = X_data.shape[0]\nnumTestSamples = X_test_data.shape[0]\n\n\ndef readout_layer(input, size_in, size_out):\n    """"""Readout layer for our network\n\n    Classifier layer at the end of the neural network. It is similar to the\n    densely connected layer, just without the ReLU\n    """"""\n    w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1))\n    b = tf.Variable(tf.truncated_normal([size_out], stddev=0.1))\n    return tf.matmul(input, w) + b\n\n\ndef fc_layer(input, size_in, size_out):\n    """"""Creates a fully connected nn layer.\n\n    The layer is initialized with random numbers from normal distribution.\n    ReLU is applied at the end.\n    """"""\n    return tf.nn.relu(readout_layer(input, size_in, size_out))\n\n\ndef conv_layer(input, size_in, size_out):\n    """"""Creates a complete convolutional layer.\n\n    Uses 5x5 px filer, ReLU and max pooling.\n    """"""\n    w = tf.Variable(tf.truncated_normal([FSIZE, FSIZE, size_in, size_out],\n                                        stddev=0.1))\n    b = tf.Variable(tf.truncated_normal([size_out], stddev=0.1), name=\'bias\')\n    conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\'SAME\')\n    act = tf.nn.relu(conv + b)\n    return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n                          padding=\'SAME\')\n\n\ndef batches_generator(features, labels, batch_size, num_epochs=None,\n                      shuffle=True):\n    """"""Helper function for creating batches from the training set.\n\n    :param features: array of features\n    :param labels: array of labels\n    :param batch_size: number of items per batch\n    :param num_epochs: limit generated data to N epochs, None for no limit\n    :param shuffle: shuffle the data before generating batches\n    :return: two tensors generating batched feature and label data\n    """"""\n    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n    dataset = dataset.batch(batch_size).repeat(num_epochs)\n    if shuffle:\n        dataset = dataset.shuffle(10000)\n    feature_batch, label_batch = dataset.make_one_shot_iterator().get_next()\n    return feature_batch, label_batch\n\n\n# Setup placeholders, and reshape the data\nx = tf.placeholder(tf.float32, shape=[None, IMAGE_WIDTH * IMAGE_HEIGHT])\ny = tf.placeholder(tf.int64, shape=[None])  # simple vector\n\nx_image = tf.reshape(x, [-1, IMAGE_WIDTH, IMAGE_HEIGHT, 1])\n\nconv1 = conv_layer(x_image, 1, CONV1_SIZE)  # First convolutional layer\nconv2 = conv_layer(conv1, CONV1_SIZE, CONV2_SIZE)  # Second convolutional layer\n\n# Flatten the data before going to the next steps. Conv layer and polling\n# change the dimension, each layer decreases the size by half. so the final\n# size can be calculated by rounding up the image_size/(2^conv_layers)\nresize_width = int(math.ceil(float(IMAGE_WIDTH) / (2 << (CONV_LAYERS - 1))))\nresize_height = int(math.ceil(float(IMAGE_HEIGHT) / (2 << (CONV_LAYERS - 1))))\nflattened = tf.reshape(conv2, [-1, CONV2_SIZE * resize_width * resize_height])\n\n# Create a densely connected layer\nfc = fc_layer(flattened, CONV2_SIZE * resize_width * resize_height,\n              args.fully_connected_layer_size)\n\n# Regularization: apply dropout to reduce overfitting\nkeep_prob = tf.placeholder(tf.float32)\nfc_drop = tf.nn.dropout(fc, keep_prob)\n\n# Read the results, 10 outputs as we have 10 classes (digits)\noutput_layer = readout_layer(fc_drop, args.fully_connected_layer_size, 10)\n\n# define cost function\ncost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n    logits=output_layer, labels=y))\n\n# learning rate decay\nbatch = tf.Variable(0, trainable=False)\nlearning_rate = tf.train.exponential_decay(\n  args.learning_rate,                 # Base learning rate.\n  batch,                              # Current index into the dataset.\n  X_data.shape[0] / args.batch_size,  # Decay step based train set on batching\n  args.decay,                         # Decay rate.\n  staircase=True)\n\noptimizer = optimizer_class(learning_rate).minimize(cost, global_step=batch)\n\n# measure accuracy - pick the output with the highest score as the prediction\npred = tf.argmax(tf.nn.softmax(output_layer), 1)  # softmax is optional here\ncorrect_prediction = tf.equal(pred, y)\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\nprint(""Training..."")\n\n# Variables for tracking accuracy over time\niter_arr = []\ntrain_accuracy_arr = []\ntest_accuracy_arr = []\n\nX_batch_tensor, Y_batch_tensor = batches_generator(X_data, Y_data,\n                                                   args.batch_size)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\nfor epoch in range(args.epochs):\n\n    if not (epoch + 1) % 20:\n        train_accuracy, train_cost = sess.run(\n            (accuracy, cost), feed_dict={x: X_data, y: Y_data, keep_prob: 1.0})\n        test_accuracy, test_cost = sess.run(\n            (accuracy, cost),\n            feed_dict={x: X_test_data, y: Y_test_data, keep_prob: 1.0})\n        iter_arr.append(epoch)\n        train_accuracy_arr.append(train_accuracy)\n        test_accuracy_arr.append(test_accuracy)\n        if args.verbose:\n            print(\'Epoch: {:04d}, accuracy: {:.4f}, cost: {:.4f}, \'\n                  \'test accuracy: {:.4f}, test cost: {:.4f}\'.format(\n                      epoch+1, train_accuracy, train_cost, test_accuracy,\n                      test_cost))\n\n    X_data_batch, Y_data_batch = sess.run((X_batch_tensor, Y_batch_tensor))\n    sess.run(optimizer, feed_dict={x: X_data_batch, y: Y_data_batch,\n                                   keep_prob: args.dropout})\n\nprint(""Accuracy report for the learning set"")\ny_pred = sess.run(pred, feed_dict={x: X_data, y: Y_data, keep_prob: 1.0})\nprint(metrics.classification_report(Y_data, y_pred))\n\nprint(""Accuracy report for the test set"")\ny_test_pred = sess.run(pred, feed_dict={x: X_test_data, y: Y_test_data,\n                                        keep_prob: 1.0})\nprint(""shape of x"", X_test_data.shape)\nprint(""shape of y"", Y_test_data.shape)\nprint(""shape of y_test_pred"", y_test_pred.shape)\n\nprint(metrics.classification_report(Y_test_data, y_test_pred))\n\nprint(""Plotting accuracy over time..."")\nplt.plot(iter_arr, train_accuracy_arr, label=\'train accuracy\')\nplt.plot(iter_arr, test_accuracy_arr, label=\'test accuracy\')\nplt.xlabel(\'epoch\', fontsize=16)\nplt.ylabel(\'accuracy\', fontsize=16)\nplt.legend(bbox_to_anchor=(0, 1), loc=2, borderaxespad=0.)\nplt.show()\n'"
ex4-neural networks learning/5_tensorboard.py,1,"b'# So far we\'ve been making our own plots to visualize accuracy over time.\n# Tensorflow comes with a tool tensorboard in which we can visualize merge_all\n# the variables (including weights and biases) and even data points.\n# In this exercie we will use TF summary writers to dump variables while the\n# model is learaning. Also for the test set we will generate metadata (labels\n# and images) so we can display them on 3d embeddings in tensorboard.\n# Usage:\n# train the model: python 5_tensorboard.py --verbose\n# run tensorboard: tensorboard --logdir=/tmp/logdir/\n# inspect the data: open http://localhost:6006 in your browser\nimport argparse\nimport math\nimport numpy as np\nimport os\nfrom scipy import io, misc\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport scipy\n\n# size of a single digit image (in pixels)\nIMAGE_WIDTH = 20\nIMAGE_HEIGHT = 20\nTEST_SIZE = 0.25  # test set will be 25% of the data\n\n# Parse the command line arguments (or use default values).\nparser = argparse.ArgumentParser(\n    description=\'Recognizing hand-written number using neural network.\')\nparser.add_argument(\'-s\', \'--hidden_layer_size\', type=int,\n                    help=\'number of neurons in the hidden layer (default: 64)\',\n                    default=64)\nparser.add_argument(\'-lr\', \'--learning_rate\', type=float,\n                    help=\'learning rate for the algorithm (default: 0.5)\',\n                    default=0.5)\nparser.add_argument(\'-d\', \'--decay\', dest=\'decay\', type=float,\n                    help=\'learning rate decay (default: 0.9999, 1.0 means \'\n                    \'no decay)\', default=0.9999)\nparser.add_argument(\'-e\', \'--epochs\', type=int,\n                    help=\'number of epochs (default: 1000)\', default=1000)\nparser.add_argument(\'-o\', \'--optimizer\', type=str,\n                    help=\'tensorflow optimizer class (default: \'\n                    \'AdagradOptimizer)\', default=\'AdagradOptimizer\')\nparser.add_argument(\'-v\', \'--verbose\', dest=\'verbose\', action=\'store_true\',\n                    help=\'increase output verbosity\')\nparser.add_argument(\'--dir\', type=str,\n                    help=\'directory to store the training process summary in \'\n                    \'(default: /tmp/logdir)\', default=\'/tmp/logdir\')\nargs = parser.parse_args()\n\noptimizer_class = getattr(tf.train, args.optimizer)\n\n# Load the hand-written digits data.\nfilename = \'data/ex4data1.mat\'\ndata = io.loadmat(filename)\nX_data, Y_data = data[\'X\'], data[\'y\']\n\n# y==10 is digit 0, convert it to 0 then to make the code below simpler\nY_data[Y_data == 10] = 0\n\n# Split the data\nX_data, X_test_data, Y_data, Y_test_data = train_test_split(\n    X_data, Y_data, test_size=TEST_SIZE)\n\nnumSamples = X_data.shape[0]\nnumTestSamples = X_test_data.shape[0]\n\n\ndef fc_layer(input, size_in, size_out, name=""fc""):\n    """"""Creates a fully connected nn layer.\n\n    The layer is initialized with random numbers from normal distribution.\n    """"""\n    with tf.name_scope(name):\n        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1),\n                        name=""W"")\n        b = tf.Variable(tf.truncated_normal([size_out], stddev=0.1), name=""B"")\n        act = tf.nn.relu(tf.matmul(input, w) + b)\n        tf.summary.histogram(""weights"", w)\n        tf.summary.histogram(""biases"", b)\n        tf.summary.histogram(""activations"", act)\n        return act\n\n\n# Setup placeholders, and reshape the data\n# While building the model, name all the blocks and variables so they\'re\n# easier to identify in tensorboard\nx = tf.placeholder(tf.float32, shape=[None, IMAGE_WIDTH * IMAGE_HEIGHT],\n                   name=""x"")\ny = tf.placeholder(tf.float32, shape=[None, 10], name=""labels"")\n\nif args.verbose:\n    print(""Creating a network with {:d} neurons in a hidden layer"".format(\n        args.hidden_layer_size))\n\nhidden_layer = fc_layer(x, IMAGE_WIDTH * IMAGE_HEIGHT, args.hidden_layer_size,\n                        ""hidden_layer"")\noutput_layer = fc_layer(hidden_layer, args.hidden_layer_size, 10,\n                        ""output_layer"")\n\nwith tf.name_scope(""xent""):\n    xent = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits_v2(\n            logits=output_layer, labels=y), name=""xent"")\n    tf.summary.scalar(""xent"", xent)\n\nwith tf.name_scope(""learning_rate""):\n    batch = tf.Variable(0, trainable=False, name=""batch"")\n    learning_rate = tf.train.exponential_decay(\n      args.learning_rate,  # Base learning rate.\n      batch,               # Current index into the dataset.\n      1,                   # Decay step.\n      args.decay,          # Decay rate.\n      staircase=True)\n    tf.summary.scalar(""learning_rate"", learning_rate)\n\nwith tf.name_scope(""train""):\n    train_step = optimizer_class(learning_rate).minimize(xent,\n                                                         global_step=batch)\n\nwith tf.name_scope(""accuracy""):\n    pred = tf.argmax(tf.nn.softmax(output_layer), 1)\n    correct_prediction = tf.equal(pred, tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    tf.summary.scalar(""accuracy"", accuracy)\n\n# Prepare the summary writer dir\nif not os.path.isdir(args.dir):\n    os.mkdir(args.dir)\n\n# In this section we will prepare tensorboard embeddings for the test set.\n# Embedding metadata: generate a TSV file with labels\nlabels_filename = os.path.join(args.dir, \'labels.tsv\')\nwith open(labels_filename, \'w\') as labels_file:\n    for i in range(numTestSamples):\n        labels_file.write(""%d\\n"" % Y_test_data[i])\n\n\ndef get_sprites(X):\n    """"""Generate a square sprite image with digits.\n    Tensorflow supports sprite images up to 8192x8192 pixels. Given each of\n    our digits is 20px*20px, we don\'t have to scale it down.\n    """"""\n    width, height = IMAGE_WIDTH, IMAGE_HEIGHT\n    digits_per_row = int(math.ceil(math.sqrt(X.shape[0])))\n    nrows, ncols = digits_per_row, digits_per_row\n\n    big_picture = np.zeros((height * nrows, width * ncols))\n\n    irow, icol = 0, 0\n    for idx in range(X.shape[0]):\n        if icol == ncols:\n            irow += 1\n            icol = 0\n        iimg = X[idx].reshape(width, height).T  # transpose the data set\n        big_picture[irow * height:irow * height + iimg.shape[0],\n                    icol * width:icol * width + iimg.shape[1]] = iimg\n        icol += 1\n    return misc.toimage(big_picture)\n\n\n# Generate images associated with the embeddings.\nsprite_img = get_sprites(X_test_data)\nsprite_filename = os.path.join(args.dir, \'sprite.png\')\nscipy.misc.imsave(sprite_filename, sprite_img)\n\n# Create embeddings and assigment operation to capture the test set data\nfc_embedding = tf.Variable(tf.zeros([numTestSamples, args.hidden_layer_size]),\n                           name=""test_embedding_hidden_layer"")\nfc_assignment = fc_embedding.assign(hidden_layer)\nlogits_embedding = tf.Variable(tf.zeros([numTestSamples, 10]),\n                               name=""test_embedding_logits"")\nlogits_assignment = logits_embedding.assign(output_layer)\n\n# Create two embeddings - for hidden layer and for logits\nprojector_config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\nembedding = projector_config.embeddings.add()\nembedding.tensor_name = fc_embedding.name\nembedding.metadata_path = labels_filename\nembedding.sprite.image_path = sprite_filename\nembedding.sprite.single_image_dim.extend([IMAGE_WIDTH, IMAGE_HEIGHT])\n\nembedding = projector_config.embeddings.add()\nembedding.tensor_name = logits_embedding.name\nembedding.metadata_path = labels_filename\nembedding.sprite.image_path = sprite_filename\nembedding.sprite.single_image_dim.extend([IMAGE_WIDTH, IMAGE_HEIGHT])\n\n# Summary operation for writing down variables values\nsummary = tf.summary.merge_all()\n\nsaver = tf.train.Saver()\nsess = tf.Session()\n\nsess.run(tf.global_variables_initializer())\ntrain_writer = tf.summary.FileWriter(os.path.join(args.dir, \'train\'),\n                                     sess.graph)\ntest_writer = tf.summary.FileWriter(os.path.join(args.dir, \'test\'), sess.graph)\n\ntf.contrib.tensorboard.plugins.projector.visualize_embeddings(test_writer,\n                                                              projector_config)\n\n# Convert the aswers vector to a sparse matrix (refer to\n# 1_nn_training_example.py for a more detailed comment)\nY_sparse = tf.keras.utils.to_categorical(Y_data, 10)\nY_test_sparse = tf.keras.utils.to_categorical(Y_test_data, 10)\n\nprint(""Training..."")\n\nfor epoch in range(1, args.epochs+1):\n\n    if not epoch % 5:\n        # Write summary for the training set\n        train_accuracy, s = sess.run([accuracy, summary],\n                                     feed_dict={x: X_data, y: Y_sparse})\n        train_writer.add_summary(s, epoch)\n        if not epoch % 20:\n            # Write summary for the test set\n            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n            run_metadata = tf.RunMetadata()\n            test_accuracy, s, y_test_pred = sess.run(\n                [accuracy, summary, pred],\n                feed_dict={x: X_test_data, y: Y_test_sparse},\n                options=run_options,\n                run_metadata=run_metadata)\n            test_writer.add_run_metadata(run_metadata,\n                                         \'step{:03d}\'.format(epoch))\n            test_writer.add_summary(s, epoch)\n\n            if args.verbose:\n                print(\'Epoch: {:04d}, accuracy: {}, test accuracy: {}\'.format(\n                    epoch, train_accuracy, test_accuracy))\n\n    if not epoch % 100:\n        # Projector data in tensorboard is based on checkpoints, so every now\n        # and then capture the embeddings data and save the model\n        sess.run([fc_assignment, logits_assignment],\n                 feed_dict={x: X_test_data, y: Y_test_sparse})\n\n        saver.save(sess, os.path.join(args.dir, \'model.ckpt\'), epoch)\n    _, y_pred = sess.run([train_step, pred],\n                         feed_dict={x: X_data, y: Y_sparse})\n\ntrain_writer.close()\ntest_writer.close()\n\nprint(metrics.classification_report(Y_data, y_pred))\nprint(metrics.classification_report(Y_test_data, y_test_pred))\n'"
