file_path,api_count,code
pipeline.py,2,"b""import logging\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom utils import features_utils, nn_utils\nfrom utils.data_params import DataParams as dp\nfrom utils.hyperparams import Hyperparameters\n\nEXPERIMENT_CONFIG_FILE_PATH = 'config/experiment_setup.yml'\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\nY_true = np.reshape(np.array([1] * 82 + [0] * 64), (1, 146))\n\n\ndef main():\n  hp = Hyperparameters(EXPERIMENT_CONFIG_FILE_PATH)\n  logger.info('Loading data...')\n  df = pd.read_csv(hp.data_file, sep='\\t', header=None, index_col=0).T\n  logger.info('Loaded data...')\n  \n  shuffle = np.random.permutation(Y_true.shape[1])\n  X = nn_utils.norm_data(df)\n  X['Case'] = ['AUTISM'] * dp.num_autism + ['CONTROL'] * dp.num_control\n  \n  skf = StratifiedKFold(n_splits=hp.cross_validation_folds)\n  cv_acc = {'fisher': [], 'corr': [], 'ttest': [], 'random': []}\n  \n  for fold_id, (train_idxs, test_idxs) in enumerate(skf.split(X.values, Y_true.reshape(146))):\n    X_train = X.iloc[train_idxs]\n    Y_train = Y_true[:, train_idxs]\n    X_test = X.iloc[test_idxs]\n    Y_test = Y_true[:, test_idxs]\n    \n    selected_features = features_utils.execute_selection(hp.selection_methods, X_train)\n    for method, X_train_sel_features in selected_features.items():\n      init_parameters = nn_utils.init_parameters(input_size=hp.input_size,\n                                                 hidden_sizes=hp.hidden_sizes,\n                                                 output_size=hp.output_size)\n      trained_params, _ = nn_utils.train_nn(X_train_sel_features,\n                                            Y_train,\n                                            init_parameters,\n                                            method,\n                                            hp.activation_function,\n                                            '[{}/{}]'.format(fold_id + 1,\n                                                             hp.cross_validation_folds),\n                                            hp)\n      \n      X_test_sel_features = features_utils.apply_selection(method, X_test,\n                                                           num_features=hp.num_features)\n      fold_acc = nn_utils.test_nn(X_test_sel_features, Y_test, trained_params, method,\n                                  hp.activation_function, hp)\n      cv_acc[method].append(fold_acc)\n    \n    for m in hp.selection_methods:\n      logger.info('%d-fold cross-validation accuracy for [%s] method : [%d]',\n                  hp.cross_validation_folds, m, sum(cv_acc[m]) / len(cv_acc[m]))\n\n\nif __name__ == '__main__':\n  main()\n"""
colab/__init__.py,0,b''
selection/__init__.py,0,b''
selection/correlation_with_class.py,0,"b""import logging\nimport os\n\nimport pandas as pd\n\nfrom selection import feature_selection\nfrom selection.log_decorator import LogDecorator\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\n@LogDecorator('Correlation')\ndef select(df: pd.DataFrame, num_features=100, force=True):\n  feature_fn = 'features/Correlation.csv'\n  if not os.path.exists(feature_fn) or force:\n    os.makedirs('features', exist_ok=True)\n    _, corr_features = feature_selection.correlation_with_class(df, num_features)\n    pd.DataFrame(corr_features).to_csv(feature_fn)\n    X = df[corr_features].T.values  # input size x batch size\n  else:\n    fisher_features = pd.read_csv(feature_fn, index_col=1)\n    X = df[fisher_features.index].T.values  # input size x batch size\n  return X\n"""
selection/feature_selection.py,2,"b'import numpy as np\nimport pandas as pd\n\n\ndef fisher(data_df: pd.DataFrame, num_features):\n  """"""\n  Makes feature Fisher selection according to the following formula:\n  D(f) = m1(f) - m2(f) / sigma1(f) + sigma2(f)\n  :return: the list of most significant features.\n  """"""\n  fisher_df = pd.DataFrame()\n  fisher_df[\'mean_autism\'] = data_df[data_df[\'Case\'] == \'AUTISM\'].mean()\n  fisher_df[\'mean_control\'] = data_df[data_df[\'Case\'] == \'CONTROL\'].mean()\n  fisher_df[\'std_autism\'] = data_df[data_df[\'Case\'] == \'AUTISM\'].std()\n  fisher_df[\'std_control\'] = data_df[data_df[\'Case\'] == \'CONTROL\'].std()\n  \n  fisher_df[\'diff_mean\'] = (fisher_df[\'mean_autism\'] - fisher_df[\'mean_control\']).abs()\n  fisher_df[\'sum_std\'] = (fisher_df[\'std_autism\'] + fisher_df[\'std_autism\']).abs()\n  fisher_df[\'fisher_coeff\'] = fisher_df[\'diff_mean\'] / fisher_df[\'sum_std\']\n  fisher_df = fisher_df.sort_values([\'fisher_coeff\'], ascending=False)\n  \n  # data_df[\'fisher_coeff\'] = fisher_df[\'fisher_coeff\']\n  most_significant_features = fisher_df[\'fisher_coeff\'].index[:num_features]\n  return data_df, most_significant_features\n\n\ndef correlation_with_class(data_df: pd.DataFrame, num_features):\n  """"""\n  Makes feature correlation with class selection according to the following formula:\n  D(f) = [(m1(f) - m(f))^2 + (m2(f) - m(f))^2] / 2*sigma(f)^2\n  :return: the list of most significant features.\n  """"""\n  corr_df = pd.DataFrame()\n  corr_df[\'mean_autism\'] = data_df[data_df[\'Case\'] == \'AUTISM\'].mean()\n  corr_df[\'mean_control\'] = data_df[data_df[\'Case\'] == \'CONTROL\'].mean()\n  corr_df[\'mean_total\'] = data_df.mean()\n  corr_df[\'std_total\'] = data_df.std()\n  \n  corr_df[\'corr_coeff\'] = ((corr_df[\'mean_autism\'] - corr_df[\'mean_total\']) ** 2 + (\n      corr_df[\'mean_control\'] - corr_df[\'mean_total\']) ** 2) / 2 * (corr_df[\'std_total\']) ** 2\n  corr_df = corr_df.sort_values([\'corr_coeff\'], ascending=False)\n  most_significant_features = corr_df[\'corr_coeff\'].index[:num_features]\n  # data_df[\'corr_coeff\'] = corr_df[\'corr_coeff\']\n  return data_df, most_significant_features\n\n\ndef t_test(data_df: pd.DataFrame, num_features):\n  """"""\n  :return: the list of most significant features.\n  """"""\n  t_test = pd.DataFrame()\n  t_test[\'mean_autism\'] = data_df[data_df[\'Case\'] == \'AUTISM\'].mean()\n  t_test[\'mean_control\'] = data_df[data_df[\'Case\'] == \'CONTROL\'].mean()\n  t_test[\'std_autism\'] = data_df[data_df[\'Case\'] == \'AUTISM\'].std()\n  t_test[\'std_control\'] = data_df[data_df[\'Case\'] == \'CONTROL\'].std()\n  \n  num_autism = len(data_df[data_df[\'Case\'] == \'AUTISM\'])\n  num_control = len(data_df[data_df[\'Case\'] == \'CONTROL\'])\n  \n  t_test[\'ttest_coeff\'] = (t_test[\'mean_autism\'] - t_test[\'mean_control\']) / (\n      (t_test[\'std_autism\'] ** 2) / num_autism + (t_test[\'std_control\'] ** 2) / num_control) ** (\n                              1 / 2)  # TODO is it correct?\n  t_test = t_test.sort_values([\'ttest_coeff\'], ascending=False)\n  most_significant_features = t_test[\'ttest_coeff\'].index[:num_features]\n  # data_df[\'ttest_coeff\'] = t_test[\'ttest_coeff\']\n  return data_df, most_significant_features\n\n\ndef random(data_df: pd.DataFrame, num_features):  # TODO\n  """"""\n  Random features selection for baseline purposes.\n  :return: the list of randomly chosen features.\n  """"""\n  total_features = data_df.shape[1]\n  features = np.arange(total_features)\n  np.random.shuffle(features)\n  selected_random = features[:num_features]\n  most_significant_features = data_df.T.index[selected_random]\n  return data_df, most_significant_features\n'"
selection/fisher.py,0,"b""import logging\nimport os\n\nimport pandas as pd\n\nfrom selection import feature_selection\nfrom selection.log_decorator import LogDecorator\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\n@LogDecorator('Fisher')\ndef select(df: pd.DataFrame, num_features=100, force=True):\n  feature_fn = 'features/Fisher.csv'\n  if not os.path.exists(feature_fn) or force:\n    os.makedirs('features', exist_ok=True)\n    _, fisher_features = feature_selection.fisher(df, num_features)\n    pd.DataFrame(fisher_features).to_csv(feature_fn)\n    X = df[fisher_features].T.values  # input size x batch size\n  else:\n    fisher_features = pd.read_csv(feature_fn, index_col=1)\n    X = df[fisher_features.index].T.values  # input size x batch size\n  return X\n"""
selection/log_decorator.py,0,"b""import logging\nimport os\nimport time\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass LogDecorator:\n  \n  def __init__(self, name):\n    self.__name = name\n    self.__path = 'features/{}.csv'.format(self.__name)\n  \n  def __call__(self, f, *args, **kwargs):\n    if not os.path.exists(self.__path):\n      logger.info('Running %s feature selection...', self.__name)\n      start = time.time()\n    else:\n      logger.info('Reading %s features from file : [%s]...', self.__name, self.__path)\n    \n    def new_f(*args, **kwargs):\n      X = f(*args, **kwargs)\n      if not os.path.exists(self.__path):\n        logger.info('Saving %s features to [%s]...', self.__name, self.__path)\n        logger.info('%s selection last [%s]...', self.__name, (time.time() - start) * 1000)\n      \n      else:\n        logger.info('Read %s features from file : [%s]...', self.__name, self.__path)\n      return X\n    \n    new_f.__name__ = f.__name__\n    return new_f\n"""
selection/random.py,0,"b""import logging\nimport os\n\nimport pandas as pd\n\nfrom selection import feature_selection\nfrom selection.log_decorator import LogDecorator\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\n@LogDecorator('Random')\ndef select(df: pd.DataFrame, num_features=100, force=True):\n  feature_fn = 'features/Random.csv'\n  if not os.path.exists(feature_fn) or force:\n    os.makedirs('features', exist_ok=True)\n    _, t_test_features = feature_selection.random(df, num_features)\n    pd.DataFrame(t_test_features).to_csv(feature_fn)\n    X = df[t_test_features].T.values  # input size x batch size\n  else:\n    t_test_features = pd.read_csv(feature_fn, index_col=1)\n    X = df[t_test_features.index].T.values  # input size x batch size\n  return X\n"""
selection/ttest.py,0,"b""import logging\nimport os\n\nimport pandas as pd\n\nfrom selection import feature_selection\nfrom selection.log_decorator import LogDecorator\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\n@LogDecorator('Ttest')\ndef select(df: pd.DataFrame, num_features=100, force=True):\n  feature_fn = 'features/ttest.csv'\n  if not os.path.exists(feature_fn) or force:\n    os.makedirs('features', exist_ok=True)\n    _, t_test_features = feature_selection.t_test(df, num_features)\n    pd.DataFrame(t_test_features).to_csv(feature_fn)\n    X = df[t_test_features].T.values  # input size x batch size\n  else:\n    t_test_features = pd.read_csv('features/ttest.csv', index_col=1)\n    X = df[t_test_features.index].T.values  # input size x batch size\n  return X\n"""
utils/__init__.py,0,b''
utils/data_params.py,0,b'class DataParams(object):\n  num_autism = 82\n  num_control = 64\n'
utils/features_utils.py,0,"b""import logging\nimport time\n\nimport pandas as pd\n\nfrom selection import correlation_with_class, fisher, ttest, random\n\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger(__name__)\n\nfeatures_methods = {\n  'fisher': fisher,\n  'corr': correlation_with_class,\n  'ttest': ttest,\n  'random': random\n}\n\n\ndef execute_selection(selection_methods: list(), data: pd.DataFrame, force=True):\n  selected_features = dict()\n  for selection_method in selection_methods:\n    start = time.time()\n    selection_method_name =  selection_method['method']\n    num_features =  selection_method['num_features']\n    logger.info('Making feature selection with [%s] method...', selection_method_name)\n    selected_features[selection_method_name] = features_methods[selection_method_name].select(data,\n                                                                                    num_features=num_features,\n                                                                                    force=force)\n    totalTime = (time.time() - start) * 1000\n    logger.info('[%s] feature selection last %d ms.', selection_method, totalTime)\n  return selected_features\n\n\ndef apply_selection(selection_method: str, data: pd.DataFrame, num_features=100):\n  selected_features = features_methods[selection_method].select(data, num_features=num_features,\n                                                                force=False)\n  return selected_features\n"""
utils/hyperparams.py,0,"b""import io\n\nimport yaml\n\n\nclass Hyperparameters:\n  def __init__(self, path_to_config_file):\n    with io.open(path_to_config_file) as file:\n      config = yaml.load(file)\n    self.learning_rate = config['hyperparameters']['learning_rate']\n    self.input_size = config['hyperparameters']['input_size']\n    self.hidden_sizes = config['hyperparameters']['hidden_sizes']\n    self.output_size = config['hyperparameters']['output_size']\n    self.num_features = config['hyperparameters']['num_features']\n    self.activation_function = config['hyperparameters']['activation_function']\n    # TODO add force feature selection\n    # TODO gradient descent with momoentum\n    # TODO decorators for plots\n    self.num_layers = len(self.hidden_sizes) + 1\n    self.selection_methods = config['selection_methods']\n    \n    self.num_epochs = config['training']['num_epochs']\n    self.batch_size = config['training']['batch_size']  # online learning when batch_size=1\n    self.cross_validation_folds = config['training']['cross_validation_folds']  # TODO when === num of observations then leave-one-out is applied.\n    self.lambda_reg = 0.8\n    self.norm_data = True\n    # TODO plot cost with and without reguralization\n    \n    # dirs:\n    self.data_file = 'data/data.tsv'\n"""
utils/nn_utils.py,29,"b'import logging\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\n\ndef init_parameters(input_size, hidden_sizes, output_size, init_method=\'Xavier\'):\n  scales = []\n  layers = [input_size] + hidden_sizes\n  if \'Xavier\' in init_method:\n    for i in range(1, len(layers) + 1):\n      scales.append(np.sqrt(2. / layers[i - 1]))\n  \n  if \'Xavier\' in init_method:\n    first_layer_scale = scales[0]\n  elif \'Random\' in init_method:\n    first_layer_scale = 0.01\n  else:\n    first_layer_scale = 0.0\n  \n  parameters = dict()\n  parameters[\'W1\'] = np.random.randn(hidden_sizes[0], input_size) * first_layer_scale\n  parameters[\'b1\'] = np.zeros((hidden_sizes[0], 1))\n  \n  for l in range(len(hidden_sizes)):\n    if len(hidden_sizes) - 1 == l:  # last layer\n      parameters[\'W\' + str(l + 2)] = np.random.randn(output_size, hidden_sizes[l]) * scales[l + 1]\n      parameters[\'b\' + str(l + 2)] = np.zeros((output_size, 1))\n    else:\n      parameters[\'W\' + str(l + 2)] = np.random.randn(hidden_sizes[l + 1], hidden_sizes[l]) * scales[\n        l + 1]\n      parameters[\'b\' + str(l + 2)] = np.zeros((hidden_sizes[l + 1], 1))\n  return parameters\n\n\ndef apply_non_linearity(Z, activation_func):\n  if \'tanh\' in activation_func:\n    return tanh_forward(Z)\n  elif \'relu\' in activation_func:\n    return relu_forward(Z)\n  else:\n    raise AssertionError\n\n\ndef forward_propagation(X, parameters, activation_func):\n  num_layers = int(len(parameters) / 2)\n  cache = dict()\n  cache[\'A0\'] = X\n  \n  for l in range(1, num_layers):\n    W = parameters[\'W\' + str(l)]\n    b = parameters[\'b\' + str(l)]\n    Z = linear_forward(cache[\'A\' + str(l - 1)], W, b)\n    cache[\'A\' + str(l)] = apply_non_linearity(Z, activation_func)\n  \n  Z = linear_forward(Z, parameters[\'W\' + str(num_layers)], parameters[\'b\' + str(num_layers)])\n  cache[\'A\' + str(num_layers)] = sigmoid_forward(Z)\n  return cache\n\n\ndef gradient_descent(parameters, derivatives, learning_rate):\n  num_layers = int(len(parameters) / 2)\n  for l in range(1, num_layers + 1):\n    parameters[\'W\' + str(l)] = parameters[\'W\' + str(l)] - learning_rate * derivatives[\n      \'dW\' + str(l)]\n    parameters[\'b\' + str(l)] = parameters[\'b\' + str(l)] - learning_rate * derivatives[\n      \'db\' + str(l)]\n  return parameters\n\n\ndef compute_l2_reg_backprop(parameters, lambda_reg, batch_size):\n  l2_regs = {name: (lambda_reg / batch_size) * w for name, w in parameters.items()\n             if \'W\' in name}\n  return l2_regs\n\n\ndef backward_activation(Z, activation_func):\n  if \'tanh\' in activation_func:\n    return tanh_backward(Z)\n  elif \'relu\' in activation_func:\n    return relu_backward(Z)\n  else:\n    raise AssertionError\n\n\ndef backward_propagation(X, parameters, cache, Y_true, activation_func, num_layers=3,\n                         lambda_reg=0.0):\n  derivatives = dict()\n  batch_size = Y_true.shape[1]\n  \n  if lambda_reg != 0.0:\n    l2_regs = compute_l2_reg_backprop(parameters, lambda_reg, batch_size)\n  else:\n    l2_regs = {name: 0.0 for name, w in parameters.items()\n               if \'W\' in name}\n  # sigmoid layer\n  dZ_out = cache[\'A\' + str(num_layers + 1)] - Y_true  # 1 x m\n  dW_out = 1. / batch_size * np.dot(dZ_out, cache[\'A\' + str(num_layers)].T) + l2_regs[\n    \'W\' + str(num_layers + 1)]  # A1 h x m\n  db_out = 1. / batch_size * np.sum(dZ_out, axis=1, keepdims=True)  # (1,1)\n  \n  derivatives[\'dA\' + str(num_layers + 1)] = dZ_out\n  derivatives[\'dW\' + str(num_layers + 1)] = dW_out\n  derivatives[\'db\' + str(num_layers + 1)] = db_out\n  # relu layer\n  for i in reversed(range(num_layers)):\n    # derivatives[\'dA\' + str(i + 1)] = np.dot(parameters[\'W\' + str(i + 2)].T, derivatives[\'dA\' + str(i + 2)]) * relu_backward(cache[\'A\' + str(i + 1)]) (h x 1) x (1 x m) x (h x m) = (h x m)\n    derivatives[\'dA\' + str(i + 1)] = np.dot(parameters[\'W\' + str(i + 2)].T,\n                                            derivatives[\'dA\' + str(i + 2)])\n    # derivatives[\'dA\' + str(i + 1)] = derivatives[\'dA\' + str(i + 1)] * tanh_backward(cache[\'A\' + str(i + 1)])\n    derivatives[\'dA\' + str(i + 1)] = derivatives[\'dA\' + str(i + 1)] * backward_activation(\n      cache[\'A\' + str(i + 1)],\n      activation_func)\n    derivatives[\'dW\' + str(i + 1)] = 1. / batch_size * np.dot(derivatives[\'dA\' + str(i + 1)],\n                                                              cache[\'A\' + str(i)].T) + l2_regs[\n                                       \'W\' + str(i + 1)]  # (h x m) x (m x n_x)\n    derivatives[\'db\' + str(i + 1)] = 1. / batch_size * np.sum(derivatives[\'dA\' + str(i + 1)],\n                                                              axis=1,\n                                                              keepdims=True)  # (h,1)\n  \n  return derivatives\n\n\ndef linear_forward(X, W, b):\n  return np.dot(W, X) + b\n\n\ndef relu_forward(Z):\n  return np.maximum(Z, 0)\n\n\ndef relu_backward(Z):\n  return 1. * (Z > 0)\n\n\ndef tanh_forward(Z):\n  return np.tanh(Z)\n\n\ndef tanh_backward(Z):\n  return 1 - np.power(np.tanh(Z), 2)\n\n\ndef sigmoid_forward(Z):\n  return 1 / (1 + np.exp(-Z))\n\n\ndef sigmoid_backward(Z):\n  return sigmoid_forward(Z) * (1 - sigmoid_forward(Z))\n\n\ndef cross_entropy_cost(Y_pred, Y_actual, parameters, lambda_reg=0.0):\n  batch_size = Y_actual.shape[1]\n  \n  l2_term = 0.0\n  if lambda_reg != 0.0:\n    l2_term = compute_l2_reg(parameters, lambda_reg, batch_size)\n  #  np.multiply(-np.log(a3),Y) + np.multiply(-np.log(1 - a3), 1 - Y)\n  # logs = np.log(Y_pred) * Y_actual + (1 - Y_actual) * np.log(1 - Y_pred)\n  logs = np.multiply(-np.log(Y_pred), Y_actual) + np.multiply(-np.log(1 - Y_pred), (1 - Y_actual))\n  cost = 1. / batch_size * np.nansum(logs) + l2_term  # TODO why loss increases?\n  return cost\n\n\ndef compute_l2_reg(parameters, lambda_reg, batch_size):\n  """"""\n  Performs L2 calculation: sum_over(each layer L) : lambda/2*batch_size * W(L)^2\n  :param parameters:\n  :param lambda_reg:\n  :param batch_size:\n  :return: l2 reguralized value.\n  """"""\n  l2_req = 1. / batch_size * lambda_reg / 2 * np.sum(\n    [np.sum(np.square(w)) for name, w in parameters.items()\n     if \'W\' in name])\n  return l2_req\n\n\ndef compute_dropout():\n  pass\n\n\ndef predict(Y_pred):\n  pred = np.copy(Y_pred)\n  pred[pred >= 0.5] = 1.0\n  pred[pred < 0.5] = 0.0\n  return pred\n\n\ndef norm_data(X: pd.DataFrame):\n  mean = X.mean()\n  var = X.var()\n  X_norm = (X - mean) / var\n  return X_norm\n\n\n# @PlotDecorator(\'cost\')\ndef train_nn(X, Y, parameters, method, activation_func, fold_id, hp):\n  logger.info(\'Training neural network for %s selection method...\', method)\n  tqdm_iter = tqdm(range(hp.num_epochs))\n  costs = []\n  for i in tqdm_iter:\n    num_batches = X.shape[1] // hp.batch_size\n    idxs = np.arange(X.shape[1])\n    np.random.shuffle(idxs)\n    X = X[:, idxs]\n    Y = Y[:, idxs]\n    for batch in range(num_batches + 1):\n      x_batch = X[:, batch * hp.batch_size:(batch + 1) * hp.batch_size]\n      y_batch = Y[:, batch * hp.batch_size:(batch + 1) * hp.batch_size]\n      \n      cache = forward_propagation(x_batch, parameters, activation_func)\n      derivatives = backward_propagation(x_batch, parameters, cache, y_batch, activation_func,\n                                         len(hp.hidden_sizes), lambda_reg=hp.lambda_reg)\n      parameters = gradient_descent(parameters, derivatives, hp.learning_rate)\n    \n    if i % 100 == 0:\n      cache = forward_propagation(X, parameters,\n                                  activation_func)  # should i freeze the parameter update?\n      predictions = predict(cache[\'A\' + str(hp.num_layers)])\n      acc = float(\n        (np.dot(Y, predictions.T) + np.dot(1 - Y, 1 - predictions.T)) / float(Y.size) * 100)\n      cost = cross_entropy_cost(cache[\'A\' + str(hp.num_layers)], Y, parameters,\n                                lambda_reg=hp.lambda_reg)\n      tqdm_iter.set_postfix(accuracy=acc, loss=cost, method=method, fold_id=fold_id)\n      costs.append(cost)\n  return parameters, costs\n\n\ndef test_nn(X, Y, parameters, method, activation_func, hp):\n  cache = forward_propagation(X, parameters, activation_func)\n  predictions = predict(cache[\'A\' + str(hp.num_layers)])\n  # print(\'Pred\' , predictions)\n  # print(\'Y\' , Y)\n  acc = float((np.dot(Y, predictions.T) + np.dot(1 - Y, 1 - predictions.T)) / float(Y.size) * 100)\n  logger.debug(\'Test accuracy for [%s] method : %d\', method, acc)\n  return acc\n'"
