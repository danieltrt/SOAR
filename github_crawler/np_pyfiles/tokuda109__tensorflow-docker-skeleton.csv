file_path,api_count,code
fabfile.py,0,b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom tasks.develop import *\nfrom tasks.lint import *\nfrom tasks.test import *\nfrom tasks.train import *\n'
etc/gunicorn.conf.py,0,"b'#\n# Process naming\n#\nproc_name = ""gunicorn""\n\n#\n# Server socket\n#\nbind = ""0.0.0.0:8080""\n\n#\n# Worker processes\n#\nworkers = 1\ntimeout = 30\nkeepalive = 2\n\n#\n# Logging\n#\nerrorlog = ""-""\nloglevel = ""debug""\naccesslog = ""-""\n\nchdir = ""/root/src/server""\n\nreload = True\n'"
etc/jupyter_notebook_config.py,0,"b""c.NotebookApp.allow_root = True\nc.NotebookApp.ip = '*'\nc.NotebookApp.port = 8888\nc.NotebookApp.open_browser = False\n"""
tasks/__init__.py,0,b''
tasks/client.py,0,"b'# -*- coding: utf-8 -*-\n\nimport os\nimport sys\n\nfrom docker import from_env\nfrom docker.errors import APIError\nfrom fabric.colors import red\nfrom google.cloud.storage import Client\nfrom requests import ConnectionError\n\nfrom command import (\n    AnonymousCommand,\n    BasicCommand\n)\nfrom config import config\nfrom messages import msg\nfrom utils import is_gpu_server\n\n\n__all__ = (\n    ""MachineClient"",\n    ""DockerClient"",\n    ""VirtualboxClient"",\n    ""GoogleCloudStorageClient""\n)\n\n\nclass BaseClient(object):\n\n    def ready(self):\n        raise NotImplementedError()\n\n\nclass MachineClient(BaseClient):\n\n    def __init__(self):\n        if os.environ.get(""CIRCLECI"", False):\n            cmd = AnonymousCommand()\n        else:\n            cmd = BasicCommand(""docker-machine"")\n\n        self.command = cmd\n        self.cache = {}\n\n    @property\n    def is_running(self):\n        stdout, _, _ = self.status()\n        return stdout.rstrip() == ""Running""\n\n    @property\n    def is_stopped(self):\n        stdout, _, _ = self.status()\n        return stdout.rstrip() == ""Stopped""\n\n    @property\n    def has_host_error(self):\n        _, stderr, _ = self.status()\n        return ""Host does not exist"" in stderr\n\n    def ready(self):\n        _args = [""config"", config.get(""machine_name"")]\n        _, _, exit_code = self.command.run(_args)\n        return exit_code == 0\n\n    def create(self):\n        _args = [""create"", ""--driver"", ""virtualbox"", config.get(""machine_name"")]\n        return self.command.run(_args, show_stream=True)\n\n    def status(self):\n        _args = [""status"", config.get(""machine_name"")]\n        return self.command.run(_args)\n\n    def start(self):\n        _args = [""start"", config.get(""machine_name"")]\n        return self.command.run(_args, show_stream=True)\n\n    def stop(self):\n        _args = [""stop"", config.get(""machine_name"")]\n        return self.command.run(_args, show_stream=True)\n\n    def env(self):\n        _args = [""env"", config.get(""machine_name"")]\n        return self.command.run(_args, show_stream=True)\n\n\nclass DockerClient(BaseClient):\n\n    def __init__(self):\n        if is_gpu_server():\n            self.command = BasicCommand(""nvidia-docker"")\n        else:\n            self.command = BasicCommand(""docker"")\n\n        self.client = from_env()\n\n        try:\n            self.client.ping()\n        except ConnectionError:\n            print red(msg.command_not_found.format(""docker""))\n\n    def ready(self):\n        pass\n\n    def build(self, dockerfile_path=None):\n        if not os.path.exists(dockerfile_path):\n            return\n\n        _args = [""build""]\n\n        _args.append(""-t"")\n        _args.append(config.get(""tag""))\n\n        _args.append(""-f"")\n        _args.append(dockerfile_path)\n\n        _args.append(""--build-arg"")\n        _args.append(""jupyter_port={:04d}"".format(\n            config.get(""jupyter_port"")\n        ))\n\n        _args.append(""--build-arg"")\n        _args.append(""tensorboard_port={:04d}"".format(\n            config.get(""tensorboard_port"")\n        ))\n\n        _args.append(""--build-arg"")\n        _args.append(""webserver_port={:04d}"".format(\n            config.get(""webserver_port"")\n        ))\n\n        _args.append(""."")\n\n        self.command.run(_args, show_stream=True)\n\n    def run_or_exec(self, args=None, daemon=False):\n        container_count = len(self.client.containers.list())\n\n        if container_count > 1 or args is None:\n            sys.exit(1)\n\n        _args = []\n\n        is_str_args = isinstance(args, str)\n\n        if is_str_args:\n            args = filter(None, args.split("" ""))\n\n        if container_count == 0:\n            _args.append(""run"")\n        elif container_count == 1:\n            _args.append(""exec"")\n\n        if daemon:\n            _args.append(""-d"")\n        else:\n            _args.append(""-it"")\n\n        if container_count == 1:\n            for c in self.client.containers.list():\n                _args.append(c.id)\n\n        _args = _args + args\n\n        self.command.run(_args, show_stream=True)\n\n\nclass VirtualboxClient(BaseClient):\n\n    def __init__(self):\n        self.command = BasicCommand(""VBoxManage"")\n\n    def ready(self):\n        _args = [""showvminfo"", config.get(""machine_name"")]\n        _, _, exit_code = self.command.run(_args)\n        return exit_code == 0\n\n    def prepare(self):\n        self.command.run(""modifyvm {} --natpf1 tensorboard,tcp,127.0.0.1,{},,{}"".format(\n            config.get(""machine_name""),\n            config.get(""tensorboard_port""),\n            config.get(""tensorboard_port"")\n        ), show_stream=True)\n\n        self.command.run(""modifyvm {} --natpf1 jupyter,tcp,127.0.0.1,{},,{}"".format(\n            config.get(""machine_name""),\n            config.get(""jupyter_port""),\n            config.get(""jupyter_port"")\n        ), show_stream=True)\n\n        self.command.run(""modifyvm {} --natpf1 webserver,tcp,127.0.0.1,{},,{}"".format(\n            config.get(""machine_name""),\n            config.get(""webserver_port""),\n            config.get(""webserver_port"")\n        ), show_stream=True)\n\n\nclass GoogleCloudStorageClient(BaseClient):\n\n    def __init__(self):\n        self.command = AnonymousCommand()\n        self.client = self._prepare_client()\n\n    def _prepare_client(self):\n        keyfile_filename = ""gcp_key_file.json""\n\n        keyfile_path = os.path.join(\n            config.get(""tasks_path""),\n            keyfile_filename\n        )\n\n        try:\n            client = Client.from_service_account_json(keyfile_path)\n        except TypeError as e:\n            sys.exit(1)\n\n        return client\n\n    def ready(self):\n        pass\n'"
tasks/command.py,0,"b'# -*- coding: utf-8 -*-\n\nfrom os.path import sep\nfrom subprocess import Popen, PIPE\nimport sys\n\nfrom fabric.api import local\nfrom fabric.colors import blue, cyan\n\nfrom utils import which\n\n__all__ = (\n    ""AnonymousCommand"",\n    ""BasicCommand""\n)\n\n\nclass BaseCommand(object):\n\n    command = None\n\n    def run(self, args=None, show_stream=False):\n        raise NotImplementedError()\n\n\nclass AnonymousCommand(BaseCommand):\n\n    def run(self, args=None, show_stream=False):\n        pass\n\n    def __repr__(self):\n        return ""<AnonymousCommand {}>"".format(\n            self.command\n        )\n\n\nclass BasicCommand(BaseCommand):\n\n    def __init__(self, command=None):\n        """"""\n        """"""\n        full_path = which(command)\n\n        if full_path is None:\n            raise RuntimeError(""Command not found."")\n\n        self.command = full_path\n\n    def run(self, args=None, show_stream=False):\n        """"""\n        :param args:\n        :param show_stream:\n        """"""\n        if isinstance(args, str):\n            _args = args.split("" "")\n            _cmd = [self.command] + _args\n        elif isinstance(args, list):\n            _args = args\n            _cmd = [self.command] + _args\n        else:\n            raise RuntimeError("""")\n\n        print ""{}: {}"".format(\n            blue(""[{}]"".format(""/"".join(self.command.split(sep)[1:-1])), bold=True),\n            cyan("" "".join([self.command.split(sep)[-1]] + _args))\n        )\n\n        if show_stream:\n            p = Popen(_cmd, stdout=PIPE, bufsize=1)\n\n            with p.stdout:\n                for line in iter(p.stdout.readline, """"):\n                    sys.stdout.write(line)\n\n            return p.stdout, p.stderr, p.returncode\n        else:\n            p = Popen(_cmd, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n\n            stdout, stderr = p.communicate()\n            exit_code = p.wait()\n\n            return stdout.decode(""utf-8""), stderr.decode(""utf-8""), exit_code\n\n    def __repr__(self):\n        return ""<BasicCommand {}>"".format(\n            self.command\n        )\n'"
tasks/config-sample.py,0,"b'# -*- coding: utf-8 -*-\n\nimport os\n\n__all__ = (\n    ""config"",\n)\n\n\n# ==========================================================\n# Project code\n# ==========================================================\n\nPROJECT_CODE = os.environ.get(\n    ""PROJECT_CODE"",\n    ""tensorflow-docker-skeleton""\n)\n\n# ==========================================================\n# Port settings\n# ==========================================================\n\nTENSORBOARD_PORT = 6006\nWEBSERVER_PORT = 8080\nJUPYTER_PORT = 8888\n\n# ==========================================================\n# Cloud Storage settings\n# ==========================================================\n\nBUCKET_NAME = """"\n\n# ==========================================================\n# Docker Hub\n# ==========================================================\n\nDOCKER_USERNAME = os.environ.get(\n    ""DOCKER_USERNAME"",\n    """"\n)\n\n# ==========================================================\n# End of configurable settings. Do not edit below this line.\n# ==========================================================\n\ncurrent_path = os.path.abspath(os.path.dirname(__file__))\n\nconfig = {\n    ""project_code"": PROJECT_CODE,\n    ""machine_name"": PROJECT_CODE,\n    ""base_path"": os.path.abspath(os.path.join(current_path, \'..\')),\n    ""source_path"": os.path.abspath(os.path.join(current_path, \'../src\')),\n    ""tasks_path"": current_path,\n    ""tests_path"": os.path.abspath(os.path.join(current_path, \'../tests\')),\n    ""tmp_path"": os.path.abspath(os.path.join(current_path, \'../tmp\')),\n    ""tag"": ""{}/{}"".format(DOCKER_USERNAME, PROJECT_CODE),\n    ""bucket_name"": BUCKET_NAME,\n    ""tensorboard_port"": TENSORBOARD_PORT,\n    ""jupyter_port"": JUPYTER_PORT,\n    ""webserver_port"": WEBSERVER_PORT\n}\n'"
tasks/decorators.py,0,"b'# -*- coding: utf-8 -*-\n\nfrom functools import wraps\nfrom sys import exit\n\nfrom client import (\n    MachineClient,\n    DockerClient,\n    VirtualboxClient,\n    GoogleCloudStorageClient\n)\n\n__all__ = (\n    ""machine_client"",\n    ""docker_client"",\n    ""virtualbox_client"",\n    ""gcp_client""\n)\n\n\ndef machine_client(func):\n    @wraps(func)\n    def decorator(*args, **kwargs):\n        machineClient = MachineClient()\n\n        kwargs[""machine""] = machineClient\n\n        return func(*args, **kwargs)\n    return decorator\n\n\ndef docker_client(func):\n    @wraps(func)\n    def decorator(*args, **kwargs):\n        try:\n            dockerClient = DockerClient()\n        except RuntimeError:\n            exit(1)\n\n        kwargs[""docker""] = dockerClient\n\n        return func(*args, **kwargs)\n    return decorator\n\n\ndef virtualbox_client(func):\n    @wraps(func)\n    def decorator(*args, **kwargs):\n        virtualboxClient = VirtualboxClient()\n\n        kwargs[""virtualbox""] = virtualboxClient\n\n        return func(*args, **kwargs)\n    return decorator\n\n\ndef gcp_client(func):\n    @wraps(func)\n    def decorator(*args, **kwargs):\n        gcpClient = GoogleCloudStorageClient()\n\n        kwargs[""gcp""] = gcpClient\n\n        return func(*args, **kwargs)\n    return decorator\n'"
tasks/develop.py,0,"b'# -*- coding: utf-8 -*-\n\nimport os\nimport sys\n\nfrom fabric.api import local, task\nfrom fabric.colors import red\n\nfrom command import BasicCommand\nfrom config import config\nfrom decorators import (\n    machine_client,\n    docker_client,\n    virtualbox_client\n)\nfrom messages import msg\nfrom utils import is_gpu_server, is_circleci\n\n__all__ = (\n    ""up"",\n    ""build"",\n    ""run""\n)\n\n\n@task\n@machine_client\n@virtualbox_client\ndef up(machine, virtualbox):\n    """"""\n    Creates and configures guest machines.\n\n    :param machine:\n    :type machine: :class:`tasks.client.MachineClient`\n    :param virtualbox:\n    :type virtualbox: :class:`tasks.client.VirtualboxClient`\n    """"""\n    if machine.is_running:\n        print msg.up_already_running\n    elif machine.is_stopped:\n        machine.start()\n        machine.env()\n\n    if machine.has_host_error:\n        machine.create()\n        machine.stop()\n        virtualbox.prepare()\n        machine.start()\n        machine.env()\n\n    sys.exit(0)\n\n\n@task\n@machine_client\n@docker_client\ndef build(machine, docker):\n    """"""\n    Build docker image.\n\n    :param machine:\n    :type machine: :class:`tasks.client.MachineClient`\n    :param docker:\n    :type docker: :class:`tasks.client.DockerClient`\n    """"""\n    if is_gpu_server():\n        build_type = ""gpu""\n    else:\n        build_type = ""cpu""\n\n    dockerfile_path = os.path.join(\n        config.get(""base_path""),\n        ""docker/Dockerfile.{}"".format(build_type)\n    )\n\n    docker.build(dockerfile_path=dockerfile_path)\n\n\n@task\n@machine_client\n@docker_client\ndef run(machine, docker, cmd=None, daemon=False):\n    """"""\n    :param machine:\n    :type machine: :class:`tasks.client.MachineClient`\n    :param docker:\n    :type docker: :class:`tasks.client.DockerClient`\n    :param cmd:\n    :type cmd: str\n    :param daemon:\n    :type daemon: boolean\n    """"""\n    _args = """"\n\n    if is_gpu_server():\n        _args += "" --device /dev/nvidia0:/dev/nvidia0""\n        _args += "" --device /dev/nvidiactl:/dev/nvidiactl""\n        _args += "" --device /dev/nvidia-uvm:/dev/nvidia-uvm""\n        _args += "" -v /usr/local/cuda/lib64:/usr/local/cuda/lib64""\n        _args += "" -v /usr/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu""\n        _args += "" -v /usr/lib/nvidia-375/:/usr/lib/nvidia-375/""\n\n    if not is_circleci():\n        _args += "" -p {:04d}:6006"".format(config.get(""tensorboard_port""))\n        _args += "" -p {:04d}:8888"".format(config.get(""jupyter_port""))\n        _args += "" -p {:04d}:8080"".format(config.get(""webserver_port""))\n\n        _args += "" -v {}/notebooks:/root/notebooks"".format(config.get(""base_path""))\n        _args += "" -v {}/src:/root/src"".format(config.get(""base_path""))\n        _args += "" -v {}/tmp:/root/tmp"".format(config.get(""base_path""))\n        _args += "" -v {}/tests:/root/tests"".format(config.get(""base_path""))\n\n    _args += "" {}"".format(config.get(""tag""))\n\n    if cmd is None:\n        _args += "" supervisord --nodaemon""\n    else:\n        _args += "" {}"".format(cmd)\n\n    docker.run_or_exec(_args, daemon)\n'"
tasks/lint.py,0,"b'# -*- coding: utf-8 -*-\n\nfrom fabric.api import local, task\n\n__all__ = (\n    ""lint"",\n)\n\n\n@task\ndef lint():\n    """"""\n    """"""\n    local(""flake8 src"")\n'"
tasks/messages.py,0,"b'# -*- coding: utf-8 -*-\n\nfrom config import config\n\n__all__ = (\n    ""msg"",\n)\n\n\nclass Message(dict):\n\n    def __init__(self, *args, **kwargs):\n        super(Message, self).__init__(*args, **kwargs)\n\n        for arg in args:\n            if isinstance(arg, dict):\n                for k, v in arg.iteritems():\n                    self[k] = v\n\n        if kwargs:\n            for k, v in kwargs.iteritems():\n                self[k] = v\n\n    def __getattr__(self, attr):\n        return self.get(attr)\n\n\nmsg = Message({\n    ""command_not_found"": ""Command `{}` not found."",\n\n    ""up_already_running"": ""Machine `{}` is already running."".format(config.get(""machine_name"")),\n\n    ""build_dockerfile_does_not_exist"": """"\n})\n'"
tasks/test.py,0,"b'# -*- coding: utf-8 -*-\n\nimport os\nimport sys\n\nfrom docker import from_env\nfrom fabric.api import local, task\n\nfrom decorators import (\n    machine_client,\n    docker_client\n)\nfrom develop import run\n\n__all__ = (\n    ""test"",\n)\n\n\n@task\n@machine_client\n@docker_client\ndef test(machine, docker):\n    """"""\n    """"""\n    run(cmd=""python3 ./src/train/test.py"")\n'"
tasks/train.py,0,"b'# -*- coding: utf-8 -*-\n\nimport os\nimport sys\nimport zipfile\n\nfrom docker import from_env\nfrom fabric.api import local, task\n\nfrom config import config\nfrom decorators import (\n    machine_client,\n    docker_client,\n    gcp_client\n)\nfrom utils import is_gpu_server\n\n__all__ = (\n    ""download_dataset"",\n    ""train"",\n)\n\n\n@task\n@gcp_client\ndef download_dataset(gcp):\n    bucket = gcp.client.bucket(config.get(""bucket_name""))\n\n    blob_path = ""/"".join([\n        ""datasets"",\n        ""{}.zip"".format(config.get(""project_code""))\n    ])\n\n    blob = bucket.blob(blob_path)\n\n    zipfile_path = os.path.join(config.get(""tmp_path""), ""dataset.zip"")\n    has_zipfile = os.path.exists(zipfile_path)\n\n    if has_zipfile:\n        os.remove(zipfile_path)\n\n    if blob.exists():\n        with open(zipfile_path, ""wb"") as file:\n            blob.download_to_file(file)\n\n        with zipfile.ZipFile(zipfile_path, ""r"") as zip:\n            zip.extractall(os.path.join(\n                config.get(""tmp_path""),\n                ""dataset""\n            ))\n\n\n@task\n@machine_client\n@docker_client\ndef clear_tensorboard(machine, docker):\n    """"""\n    """"""\n    _args = [""rm"", ""-rf"", ""/root/tmp/tensorboard""]\n\n    docker.run_or_exec(_args)\n\n\n@task\n@machine_client\n@docker_client\ndef train(machine,\n          docker,\n          max_steps=10000,\n          num_gpus=0,\n          learning_rate=None):\n    """"""\n    """"""\n    _args = [""python3""]\n\n    _args.append(""./src/train/main.py"")\n    _args.append(""--max_steps={}"".format(max_steps))\n\n    if is_gpu_server():\n        if num_gpus is 0:\n            _args.append(""--num_gpus=1"")\n        else:\n            _args.append(""--num_gpus={}"".format(num_gpus))\n    else:\n        _args.append(""--num_gpus=0"")\n\n    if learning_rate is not None:\n        _args.append(""--learning_rate="" + learning_rate)\n\n    docker.run_or_exec(_args)\n'"
tasks/utils.py,0,"b'# -*- coding: utf-8 -*-\n\nimport os\n\n__all__ = (\n    ""is_gpu_server"",\n    ""is_circleci"",\n    ""which""\n)\n\n\ndef is_gpu_server():\n    """"""\n    :return: Returns whether it is a GPU server or not.\n    :rtype: boolean\n    """"""\n    return which(""nvidia-docker"") is not None\n\n\ndef is_circleci():\n    """"""\n    :return: Returns whether it is a CircleCI environment or not.\n    :rtype: boolean\n    """"""\n    return ""CIRCLECI"" in os.environ\n\n\ndef which(command):\n    """"""\n    :param command:\n    :type command: str\n    :return: The path of program file or None\n    :rtype: str\n    """"""\n    result = None\n\n    for p in os.getenv(""PATH"").split(os.path.pathsep):\n        full_path = os.path.join(p, command)\n\n        if os.path.exists(full_path):\n            result = full_path\n            break\n\n    return result\n'"
tests/__init__.py,0,b''
src/server/main.py,0,"b'# -*- coding: utf-8 -*-\n\nimport os\n\nfrom app import create_app\n\nroot_path = os.path.abspath(os.path.dirname(__file__))\n\napp = create_app(instance_path=root_path)\n\nif __name__ == ""__main__"":\n    app.run(host=""0.0.0.0"", port=8080, debug=True)\n'"
src/train/__init__.py,0,b''
src/train/config.py,0,"b'# -*- coding: utf-8 -*-\n\nimport tensorflow as tf\n\n__all__ = (\n    ""get_config"",\n)\n\n\nconfig = None\n\n\ndef get_config():\n    global config\n\n    if config is None:\n        config = tf.ConfigProto()\n        config.allow_soft_placement = True\n\n    return config\n'"
src/train/dataset.py,0,"b'# -*- coding: utf-8 -*-\n\nimport glob\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.contrib.data import Dataset\n\nfrom flags import FLAGS\nfrom logger import get_logger\n\n__all__ = (\n    ""configure_dataset"",\n)\n\n\ndef configure_dataset():\n    """"""\n    :returns:\n    """"""\n    logger = get_logger()\n\n    image_list = []\n    image_list.extend(glob.glob(os.path.join(\n        FLAGS.dataset_path,\n        ""ch4_training_images"",\n        ""*.jpg""\n    )))\n\n    image_list_op = tf.constant(image_list)\n\n    logger.debug(""image_list_op: {}"".format(image_list_op))\n\n    dataset_iterator = Dataset.from_tensor_slices(image_list_op)\n\n    next_images = dataset_iterator.make_one_shot_iterator().get_next()\n\n    #: Create a random shuffle queue.\n    queue = tf.RandomShuffleQueue(\n        capacity=20,\n        min_after_dequeue=int(0.9 * 20),\n        shapes=next_images.shape,\n        dtypes=next_images.dtype\n    )\n\n    #: Create an op to enqueue one item.\n    enqueue = queue.enqueue(next_images)\n\n    #: Create a queue runner.\n    qr = tf.train.QueueRunner(queue, [enqueue] * 2)\n\n    tf.train.add_queue_runner(qr)\n\n    return queue.dequeue_many(FLAGS.batch_size)\n'"
src/train/device.py,0,"b'# -*- coding: utf-8 -*-\n\nfrom flags import FLAGS\n\n__all__ = (\n    ""get_device"",\n)\n\n\ndevice = None\n\n\nclass Device(object):\n\n    @property\n    def device_list(self):\n        """"""\n        """"""\n        devices = range(FLAGS.num_gpus)\n        if len(devices) is 0:\n            devices = [0]\n        return devices\n\n    @property\n    def count(self):\n        """"""\n        """"""\n        c = FLAGS.num_gpus\n        if c == 0 and self.is_cpu():\n            return 1\n        return c\n\n    def is_cpu(self):\n        """"""\n        """"""\n        return FLAGS.num_gpus == 0\n\n    def is_gpu(self):\n        """"""\n        """"""\n        return FLAGS.num_gpus > 0\n\n    def make_device_name(self, id):\n        """"""\n        """"""\n        device_name = ""/""\n\n        if self.is_gpu():\n            device_name += ""gpu:""\n        elif self.is_cpu():\n            device_name += ""cpu:""\n\n        device_name += str(id)\n\n        return device_name\n\n\ndef get_device():\n    global device\n\n    if device is None:\n        device = Device()\n\n    return device\n'"
src/train/flags.py,0,"b'# -*- coding: utf-8 -*-\n\nimport tensorflow as tf\n\n__all__ = (\n    ""FLAGS"",\n)\n\n\n#: Training parameters\n\ntf.flags.DEFINE_integer(\n    ""max_steps"",\n    100000,\n    ""Number of training steps.""\n)\ntf.flags.DEFINE_integer(\n    ""num_gpus"",\n    0,\n    """"\n)\ntf.flags.DEFINE_float(\n    ""learning_rate"",\n    0.001,\n    ""Initial learning rate.""\n)\ntf.flags.DEFINE_integer(\n    ""batch_size"",\n    24,\n    """"\n)\ntf.flags.DEFINE_integer(\n    ""num_readers"",\n    2,\n    ""The number of parallel readers that read data from the dataset.""\n)\ntf.flags.DEFINE_integer(\n    ""save_checkpoint_steps"",\n    10,\n    """"\n)\ntf.flags.DEFINE_integer(\n    ""save_summary_steps"",\n    10,\n    ""The frequency with which summaries are saved, in steps.""\n)\n\n#: Path\n\ntf.flags.DEFINE_string(\n    ""checkpoint_path"",\n    ""/root/tmp/checkpoint"",\n    """"\n)\ntf.flags.DEFINE_string(\n    ""dataset_path"",\n    ""/root/tmp/dataset"",\n    """"\n)\ntf.flags.DEFINE_string(\n    ""tensorboard_path"",\n    ""/root/tmp/tensorboard"",\n    """"\n)\n\nFLAGS = tf.flags.FLAGS\n'"
src/train/logger.py,0,"b'# -*- coding: utf-8 -*-\n\nimport tensorflow as tf\n\n__all__ = (\n    ""get_logger"",\n)\n\nlogger = None\n\n\ndef get_logger():\n    global logger\n\n    if logger is None:\n        logger = tf.logging\n        logger.set_verbosity(logger.DEBUG)\n\n    return logger\n'"
src/train/main.py,0,"b'# -*- coding: utf-8 -*-\n\nimport tensorflow as tf\n\nfrom config import get_config\nfrom device import get_device\nfrom flags import FLAGS\nfrom logger import get_logger\n\n\ndef main(unused_argv):\n    """"""\n    """"""\n    config = get_config()\n    logger = get_logger()\n    device = get_device()\n\n    input_images = tf.placeholder(\n        tf.float32,\n        shape=[None, None, None, 3],\n        name=""input_images""\n    )\n\n    logger.debug(""input_images: {}"".format(input_images))\n\n    for i, device_id in enumerate(device.device_list):\n        device_name = device.make_device_name(device_id)\n\n        logger.debug(""device_name: {}"".format(device_name))\n\n    init_op = tf.global_variables_initializer()\n\n    with tf.Session(config=config) as sess:\n        sess.run(init_op)\n\n        coord = tf.train.Coordinator()\n\n        enqueue_threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n        for step in range(FLAGS.max_steps):\n            logger.debug(""step: {:06d}"".format(step))\n\n            if step % FLAGS.save_checkpoint_steps == 0:\n                pass\n\n            if step % FLAGS.save_summary_steps == 0:\n                pass\n\n        coord.request_stop()\n\n        coord.join(enqueue_threads)\n\n\nif __name__ == ""__main__"":\n    tf.app.run()\n'"
src/train/test.py,0,"b'# -*- coding: utf-8 -*-\n\nimport sys\n\nfrom nose.core import run\nfrom nose.loader import TestLoader\n\n\ndef run_test():\n    try:\n        loader = TestLoader()\n\n        run(\n            argv=[\n                ""--nocapture"",\n                ""--nologcapture"",\n                ""--where=/root/tests"",\n                ""--with-coverage"",\n                ""--cover-erase"",\n                ""--cover-package=/root/src/train"",\n                ""--cover-xml"",\n                ""--cover-xml-file=/root/tests/results/coverage.xml"",\n                ""--with-xunit"",\n                ""--xunit-file=/root/tests/results/nosetests.xml""\n            ],\n            testLoader=loader\n        )\n    except (KeyboardInterrupt):\n        sys.exit(0)\n\n\nif __name__ == ""__main__"":\n    run_test()\n'"
src/train/utils.py,0,b'# -*- coding: utf-8 -*-\n'
tests/server/__init__.py,0,b''
tests/train/__init__.py,0,b''
tests/train/test_device.py,0,"b'# -*- coding: utf-8 -*-\n\nfrom unittest import TestCase\n\nfrom device import get_device\n\n\nclass DeviceTestCase(TestCase):\n\n    def setUp(self):\n        self.device = get_device()\n\n    def test_device_list(self):\n        self.assertEqual(self.device.device_list, [0])\n\n    def test_count(self):\n        self.assertEqual(self.device.count, 1)\n\n    def test_is_cpu(self):\n        self.assertTrue(self.device.is_cpu())\n'"
src/server/app/__init__.py,0,"b'# -*- coding: utf-8 -*-\n\nimport os\n\nfrom flask import (\n    Flask,\n    render_template,\n    send_from_directory\n)\n\nfrom app.config import Config\n\n__all__ = (\n    ""create_app"",\n)\n\n\ndef create_app(instance_path=None):\n    app = Flask(\n        __name__,\n        static_folder=\'../public\',\n        static_url_path="""",\n        template_folder=""../templates"",\n        instance_path=instance_path\n    )\n\n    app.config.from_object(Config())\n\n    @app.route(""/favicon.ico"")\n    def favicon():\n        return send_from_directory(\n            os.path.join(app.root_path, ""../public""),\n            ""favicon.ico"",\n            mimetype=""image/x-icon""\n        )\n\n    @app.route(""/"", methods=[""GET""])\n    def index():\n        ctx = {\n        }\n\n        return render_template(""index.html"", **ctx)\n\n    return app\n'"
src/server/app/config.py,0,"b'# -*- coding: utf-8 -*-\n\n__all__ = (\n    ""Config"",\n)\n\n\nclass Config(object):\n    DEBUG = True\n\n    TEMPLATES_AUTO_RELOAD = True\n'"
src/train/nets/__init__.py,0,b''
