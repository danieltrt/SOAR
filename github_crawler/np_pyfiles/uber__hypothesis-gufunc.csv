file_path,api_count,code
setup.py,0,"b'from setuptools import find_packages, setup\n\n# Derive install requires from base.in first order requirements\nwith open(""requirements/base.in"") as f:\n    base_requirements = f.read().strip()\nbase_requirements = base_requirements.replace(""=="", "">="").split()  # Convert to non-pinned for setup.py\n\nwith open(""requirements/extra.in"") as f:\n    extra_requirements = f.read().strip()\nextra_requirements = extra_requirements.replace(""=="", "">="").splitlines()  # Convert to non-pinned for setup.py\nextra_requirements = [pp for pp in extra_requirements if pp[0].isalnum()]\n\nwith open(""README.rst"") as f:\n    long_description = f.read()\n\nsetup(\n    name=""hypothesis_gufunc"",\n    version=""0.0.6"",\n    packages=find_packages(exclude=(""test/"",)),\n    description=""Extension to hypothesis to generate inputs for general universal (GU) numpy functions."",\n    python_requires="">=3.6"",\n    install_requires=base_requirements,\n    extras_require={""xarray"": extra_requirements},\n    url=""https://github.com/uber/hypothesis-gufunc"",\n    project_urls={""Documentation"": ""https://hypothesis-gufunc.readthedocs.io""},\n    author=""Ryan Turner"",\n    author_email=""rdturnermtl@github.com"",\n    license=""Apache v2"",\n    long_description=long_description,\n    long_description_content_type=""text/x-rst"",\n    platforms=[""any""],\n    classifiers=[\n        ""Framework :: Hypothesis"",\n        ""Framework :: Pytest"",\n        ""Intended Audience :: Developers"",\n        ""Operating System :: Unix"",\n        ""Operating System :: POSIX"",\n        ""Programming Language :: Python"",\n        ""Programming Language :: Python :: 3"",\n        ""Programming Language :: Python :: 3.6"",\n        ""Programming Language :: Python :: 3.7"",\n        ""Programming Language :: Python :: 3.8"",\n        ""Topic :: Software Development :: Testing"",\n    ],\n)\n'"
docs/conf.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n#\n# hypothesis_gufunc documentation build configuration file.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport os\nimport sys\n\n# If extensions (or modules to document with autodoc) are in another\n# directory, add these directories to sys.path here. If the directory is\n# relative to the documentation root, use os.path.abspath to make it\n# absolute, like shown here.\nsys.path.insert(0, os.path.abspath(""..""))\nsys.path.append(os.path.join(os.path.dirname(__file__), ""..""))\n\n# Get the project root dir, which is the parent dir of this\ncwd = os.getcwd()\nproject_root = os.path.dirname(cwd)\n\n# Insert the project root dir as the first element in the PYTHONPATH.\n# This lets us ensure that the source package is imported, and that its\n# version is used.\nsys.path.insert(0, project_root)\n\n# -- General configuration ---------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom ones.\nextensions = [\n    ""sphinx.ext.autodoc"",\n    ""sphinx.ext.extlinks"",\n    ""sphinx.ext.viewcode"",\n    ""sphinx.ext.intersphinx"",\n    ""sphinx.ext.napoleon"",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [""_templates""]\n\n# The suffix of source filenames.\nsource_suffix = {"".rst"": ""restructuredtext"", "".txt"": ""markdown"", "".md"": ""markdown""}\n\n# The encoding of source files.\n# source_encoding = \'utf-8-sig\'\n\n# The master toctree document.\nmaster_doc = ""index""\n\n# General information about the project.\nproject = ""hypothesis-gufunc""\nauthor = ""Hypothesis GU Functions Team""\ncopyright = ""2018-2019""\n\n# The version info for the project you\'re documenting, acts as replacement\n# for |version| and |release|, also used in various other places throughout\n# the built documents.\n#\n# The short X.Y version.\n# version = hypothesis_gufunc.__version__\n# The full version, including alpha/beta/rc tags.\n# release = hypothesis_gufunc.__version__\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n# language = None\n\n# There are two options for replacing |today|: either, you set today to\n# some non-false value, then it is used:\n# today = \'\'\n# Else, today_fmt is used as the format for a strftime call.\n# today_fmt = \'%B %d, %Y\'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [""_build""]\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n# default_role = None\n\n# If true, \'()\' will be appended to :func: etc. cross-reference text.\n# add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n# add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n# show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = ""sphinx""\n\n# A list of ignored prefixes for module index sorting.\n# modindex_common_prefix = []\n\n# If true, keep warnings as ""system message"" paragraphs in the built\n# documents.\n# keep_warnings = False\n\nintersphinx_mapping = {\n    ""python"": (""https://docs.python.org/3/"", None),\n    ""numpy"": (""https://docs.scipy.org/doc/numpy/"", None),\n    ""pandas"": (""https://pandas.pydata.org/pandas-docs/stable/"", None),\n    ""pytest"": (""https://docs.pytest.org/en/stable/"", None),\n    ""django"": (""https://django.readthedocs.io/en/stable/"", None),\n    ""attrs"": (""https://www.attrs.org/en/stable/"", None),\n    ""hypothesis"": (""https://hypothesis.readthedocs.io/en/latest/"", None),\n    ""xarray"": (""http://xarray.pydata.org/en/stable/"", None),\n}\n\n# -- Options for HTML output -------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = ""default""\n\n# Theme options are theme-specific and customize the look and feel of a\n# theme further.  For a list of options available for each theme, see the\n# documentation.\n# html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\n# html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# ""<project> v<release> documentation"".\n# html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as\n# html_title.\n# html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the\n# top of the sidebar.\n# html_logo = None\n\n# The name of an image file (within the static path) to use as favicon\n# of the docs.  This file should be a Windows icon file (.ico) being\n# 16x16 or 32x32 pixels large.\n# html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets)\n# here, relative to this directory. They are copied after the builtin\n# static files, so a file named ""default.css"" will overwrite the builtin\n# ""default.css"".\nhtml_static_path = []\n\n# If not \'\', a \'Last updated on:\' timestamp is inserted at every page\n# bottom, using the given strftime format.\n# html_last_updated_fmt = \'%b %d, %Y\'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n# html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n# html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names\n# to template names.\n# html_additional_pages = {}\n\n# If false, no module index is generated.\n# html_domain_indices = True\n\n# If false, no index is generated.\n# html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n# html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n# html_show_sourcelink = True\n\n# If true, ""Created using Sphinx"" is shown in the HTML footer.\n# Default is True.\n# html_show_sphinx = True\n\n# If true, ""(C) Copyright ..."" is shown in the HTML footer.\n# Default is True.\n# html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages\n# will contain a <link> tag referring to it.  The value of this option\n# must be the base URL from which the finished HTML is served.\n# html_use_opensearch = \'\'\n\n# This is the file name suffix for HTML files (e.g. "".xhtml"").\n# html_file_suffix = None\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = ""hypothesis_gufunc_doc""\n\n# -- Options for Texinfo output ----------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        ""index"",\n        ""hypothesis-gufunc"",\n        ""Hypothesis GU Functions Documentation"",\n        ""Hypothesis GU Functions Team"",\n        ""hypothesis-gufunc"",\n        ""Extension of hypothesis package to generate arguments to numpy GU functions."",\n        ""Miscellaneous"",\n    )\n]\n\n# Documents to append as an appendix to all manuals.\n# texinfo_appendices = []\n\n# If false, no module index is generated.\n# texinfo_domain_indices = True\n\n# How to display URL addresses: \'footnote\', \'no\', or \'inline\'.\n# texinfo_show_urls = \'footnote\'\n\n# If true, do not generate a @detailmenu in the ""Top"" node\'s menu.\n# texinfo_no_detailmenu = False\n'"
docs/dummy.py,0,"b'import sphinx\n\n# import extra deps and use it to keep pipreqs and flake8 happy\nfor pkg in (sphinx,):\n    print(""%s %s"" % (pkg.__name__, pkg.__version__))\n'"
hypothesis_gufunc/__init__.py,0,"b'__version__ = ""0.0.6""\n__author__ = ""Ryan Turner""\n__license__ = ""Apache v2""\n'"
hypothesis_gufunc/gufunc.py,13,"b'# Copyright (c) 2019 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""This module implements strategies for creating arguments for functions that follow numpy\'s\n`Generalized Universal Function API <https://docs.scipy.org/doc/numpy/reference/c-api.generalized-ufuncs.html>`_.\n""""""\nfrom __future__ import absolute_import, division, print_function\n\nimport string\nfrom collections import defaultdict\n\nimport numpy as np\nimport numpy.lib.function_base as npfb\nfrom hypothesis.errors import InvalidArgument\nfrom hypothesis.extra.numpy import arrays, order_check\nfrom hypothesis.internal.validation import check_type, check_valid_bound\nfrom hypothesis.strategies import SearchStrategy, builds, composite, fixed_dictionaries, integers, just, tuples\n\n__all__ = [""gufunc_args"", ""gufunc_arg_shapes""]\n\n# Should not ever need to broadcast beyond this, but should be able to set it\n# as high as 32 before breaking assumptions in numpy.\nGLOBAL_DIMS_MAX = 12\n\n\n# Key used in min_side and max_side to indicate min/max on broadcasted dims,\n# building sentinel class so we have clean __repr__.\nclass _BcastDimType(object):\n    def __repr__(self):\n        return ""BCAST_DIM""\n\n\nBCAST_DIM = _BcastDimType()\n\n# Value used in default dict for max side if variable not specified\nDEFAULT_MAX_SIDE = 5\n\n# This uses ""private"" function of numpy, but it does the job. It throws a\n# pretty readable exception for invalid input, we don\'t need to add anything.\nparse_gufunc_signature = npfb._parse_gufunc_signature\n\n\ndef _weird_digits(ss):\n    """"""In Python 3, some weird unicode characters pass `isdigit` but are not\n    0-9 characters. This function detects those cases.\n    """"""\n    weird = set(cc for cc in ss if cc.isdigit() and (cc not in string.digits))\n    return weird\n\n\ndef _check_set_like(arg, name=""""):\n    """"""Validate input can be searched like a `set`.""""""\n    try:\n        0 in arg\n    except TypeError:\n        raise InvalidArgument(""Expected set-like but got %s=%r (type=%s)"" % (name, arg, type(arg).__name__))\n\n\ndef _check_valid_size_interval(min_size, max_size, name, floor=0):\n    """"""Check valid for integers strategy and array shapes.""""""\n    # same checks as done in integers\n    check_valid_bound(min_size, name)\n    check_valid_bound(max_size, name)\n    order_check(name, floor, min_size, max_size)  # ensure non-none & above 0\n\n\ndef _order_check_min_max(min_dict, max_dict):\n    """"""Check min and max dict compatible with integers and array shapes.""""""\n    _check_valid_size_interval(min_dict.default_factory(), max_dict.default_factory(), ""side default"")\n    for kk in set(min_dict.keys()) | set(max_dict.keys()):\n        _check_valid_size_interval(min_dict[kk], max_dict[kk], ""side %s"" % kk)\n\n\ndef _int_or_dict(x, default_val):\n    """"""Pre-process cases where argument `x` can be `int`, `dict`, or\n    `defaultdict`. In all cases, build a `defaultdict` and return it.\n    """"""\n    # case 1: x already defaultdict, leave it be, pass thru\n    if isinstance(x, defaultdict):\n        return x\n\n    check_type(int, default_val, ""default value"")\n    try:\n        # case 2: x is or can be converted to dict\n        D = defaultdict(lambda: default_val, x)\n    except Exception:\n        # case 3: x is int => make a const dict\n        check_type(int, x, ""constant value"")\n        D = defaultdict(lambda: x)\n    # case 4: if can\'t be converted to dict or int, then exception raised\n    return D\n\n\n@composite\ndef _tuple_of_arrays(draw, shapes, dtype, elements, unique=False):\n    """"""Strategy to generate a tuple of ndarrays with specified shapes.\n\n    Parameters\n    ----------\n    shapes : list of tuples of int\n        List of tuples where each tuple is the shape of an argument. A\n        `SearchStrategy` for list of tuples is also supported.\n    dtype : list-like of dtype\n        List of numpy `dtype` for each argument. These can be either strings\n        (``\'int64\'``), type (``np.int64``), or numpy `dtype`\n        (``np.dtype(\'int64\')``). Built in Python types (`int`, `float`, etc)\n        also work. A single `dtype` can be supplied for all arguments.\n    elements : list-like of strategy\n        Strategies to fill in array elements on a per argument basis. One can\n        also specify a single strategy\n        (e.g., :func:`~hypothesis.strategies.floats`)\n        and have it applied to all arguments.\n    unique : list-like of bool\n        Boolean flag to specify if all elements in an array must be unique.\n        One can also specify a single boolean to apply it to all arguments.\n\n    Returns\n    -------\n    res : tuple of ndarrays\n        Resulting ndarrays with shape of `shapes` and elements from `elements`.\n\n    """"""\n    if isinstance(shapes, SearchStrategy):\n        shapes = draw(shapes)\n    n = len(shapes)\n\n    # Need this since broadcast_to does not like vars of type type\n    if isinstance(dtype, type):\n        dtype = [dtype]\n    dtype = np.broadcast_to(dtype, (n,))\n\n    elements = np.broadcast_to(elements, (n,))\n    unique = np.broadcast_to(unique, (n,))\n\n    # This could somewhat easily be done using builds and avoid need for\n    # composite if shape is always given and not strategy. Otherwise, we need\n    # to chain strategies and probably not worth the effort.\n    res = tuple(draw(arrays(dd, ss, elements=ee, unique=uu)) for dd, ss, ee, uu in zip(dtype, shapes, elements, unique))\n    return res\n\n\ndef _signature_map(map_dict, parsed_sig):\n    """"""Map values found in parsed gufunc signature.\n\n    Parameters\n    ----------\n    map_dict : dict of str to int\n        Mapping from `str` dimension names to `int`. All strings in\n        `parsed_sig` must have entries in `map_dict`.\n    parsed_sig : list-like of tuples of str\n        gufunc signature that has already been parsed, e.g., using\n        `parse_gufunc_signature`.\n\n    Returns\n    -------\n    shapes : list of tuples of int\n        list of tuples where each tuple is the shape of an argument.\n\n    """"""\n    shapes = [tuple(map_dict[k] for k in arg) for arg in parsed_sig]\n    return shapes\n\n\ndef _gufunc_arg_shapes(parsed_sig, min_side, max_side):\n    """"""Strategy to generate array shapes for arguments to a function consistent\n    with its signature.\n\n    Parameters\n    ----------\n    parsed_sig : list-like of tuples of str\n        gufunc signature that has already been parsed, e.g., using\n        `parse_gufunc_signature`.\n    min_side : defaultdict of str to int\n        Minimum size of any of the dimensions in `parsed_sig`.\n    max_side : defaultdict of str to int\n        Maximum size of any of the dimensions in `parsed_sig`.\n\n    Returns\n    -------\n    shapes : list of tuples of int\n        list of tuples where each tuple is the shape of an argument.\n\n    """"""\n    assert min_side.default_factory() <= max_side.default_factory()\n    min_max_ok = all(min_side[kk] <= max_side[kk] for kk in set(min_side.keys()) | set(max_side.keys()))\n    assert min_max_ok\n\n    # Get all dimension names in signature, including numeric constants\n    all_dimensions = set([k for arg in parsed_sig for k in arg])\n\n    # Assume we have already checked for weird unicode characters that mess up\n    # isdigit in validation of signature.\n    dim_map_st = {\n        k: (just(int(k)) if k.isdigit() else integers(min_value=min_side[k], max_value=max_side[k]))\n        for k in all_dimensions\n    }\n\n    # Build strategy that draws ints for dimensions and subs them in\n    return builds(_signature_map, map_dict=fixed_dictionaries(dim_map_st), parsed_sig=just(parsed_sig))\n\n\ndef _append_bcast_dims(core_dims, b_dims, set_to_1, n_extra_per_arg):\n    """"""Add extra broadcast dimensions to core dimensions of array shapes.\n\n    Parameters\n    ----------\n    core_dims : list of tuples of int\n        list of tuples where each tuple is the core shape of an argument. It\n        has length `n_args`.\n    b_dims : ndarray of shape (max_dims_extra,)\n        Must be of `int` dtype and >= 0. Extra dimensions to pre-pend for\n        roadcasting.\n    set_to_1 : ndarray of shape (n_args, max_dims_extra)\n        Must be of `bool` dtype. Which extra dimensions get set to 1 for\n        broadcasting.\n    n_extra_per_arg : like-like of shape (n_args,)\n        Elements must be of int type. Must be in [0, max_dims_extra], how many\n        extra dimensions to pre-pend to each argument.\n\n    Returns\n    -------\n    shapes : list of tuples of int\n        list of tuples where each tuple is the shape of an argument. Extra\n        dimensions for broadcasting will be present in the shapes. It has\n        length `n_args`.\n\n    """"""\n    # Build 2D array with extra dimensions\n    # e.g., extra_dims = [[2 5], [2 5]]\n    extra_dims = np.tile(b_dims, (len(core_dims), 1))\n    # e.g., extra_dims = [[1 5], [2 5]]\n    extra_dims[set_to_1] = 1  # This may be outside [min_side, max_side]\n\n    # Get full dimensions (core+extra), will chop some on left randomly\n    # e.g., shapes = [(5, 1, 3), (2, 5, 3, 1)]\n    # We use pp[len(pp) - nn:] instead of pp[-nn:] since that doesn\'t handle\n    # corner case with nn=0 correctly (seems like an oversight of py slicing).\n    # Call tolist() before tuple to ensure native int type.\n    shapes = [tuple(pp[len(pp) - nn :].tolist()) + ss for ss, pp, nn in zip(core_dims, extra_dims, n_extra_per_arg)]\n    return shapes\n\n\ndef gufunc_arg_shapes(signature, excluded=(), min_side=0, max_side=5, max_dims_extra=0):\n    """"""Strategy to generate the shape of ndarrays for arguments to a function\n    consistent with its signature with extra dimensions to test broadcasting.\n\n    Parameters\n    ----------\n    signature : str\n        Signature for shapes to be compatible with. Expects string in format\n        of numpy generalized universal function signature, e.g.,\n        `\'(m,n),(n)->(m)\'` for vectorized matrix-vector multiplication.\n    excluded : set(int)\n        Set-like of integers representing the positional for which the function\n        will not be vectorized. Uses same format as :obj:`numpy.vectorize`.\n    min_side : int or dict\n        Minimum size of any side of the arrays. It is good to test the corner\n        cases of 0 or 1 sized dimensions when applicable, but if not, a min\n        size can be supplied here. Minimums can be provided on a per-dimension\n        basis using a dict, e.g. ``min_side={\'n\': 2}``. One can use, e.g.,\n        ``min_side={hypothesis_gufunc.gufunc.BCAST_DIM: 2}`` to limit the size\n        of the broadcasted dimensions.\n    max_side : int or dict\n        Maximum size of any side of the arrays. This can usually be kept small\n        and still find most corner cases in testing. Dictionaries can be\n        supplied as with `min_side`.\n    max_dims_extra : int\n        Maximum number of extra dimensions that can be appended on left of\n        arrays for broadcasting. This should be kept small as the memory used\n        grows exponentially with extra dimensions. By default, no extra\n        dimensions are added.\n\n    Returns\n    -------\n    shapes : list(tuple(int))\n        list of tuples where each tuple is the shape of an argument. Extra\n        dimensions for broadcasting will be present in the shapes.\n\n    Examples\n    --------\n    .. code-block:: pycon\n\n      >>> from hypothesis_gufunc.gufunc import BCAST_DIM\n      >>> gufunc_arg_shapes(\'(m,n),(n)->(m)\',\n                            min_side={\'m\': 1, \'n\': 2}, max_side=3).example()\n      [(2, 3), (3,)]\n      >>> gufunc_arg_shapes(\'(m,n),(n)->(m)\', max_side=9,\n                            min_side={\'m\': 1, \'n\': 2, BCAST_DIM: 5},\n                            max_dims_extra=3).example()\n      [(6, 6, 7), (6, 7)]\n      >>> gufunc_arg_shapes(\'(m,n),(n)->(m)\', excluded=(0,),\n                            max_side=20, max_dims_extra=3).example()\n      [(11, 13), (1, 1, 1, 13)]\n\n    """"""\n    _check_set_like(excluded, name=""excluded"")\n    min_side = _int_or_dict(min_side, 0)\n    max_side = _int_or_dict(max_side, DEFAULT_MAX_SIDE)\n    _order_check_min_max(min_side, max_side)\n    check_type(int, max_dims_extra, ""extra dims"")\n    order_check(""extra dims"", 0, max_dims_extra, GLOBAL_DIMS_MAX)\n\n    # Validate that the signature contains digits we can parse\n    weird_sig_digits = _weird_digits(signature)\n    if len(weird_sig_digits) > 0:\n        raise InvalidArgument(""signature %s contains invalid digits: %s"" % (signature, """".join(weird_sig_digits)))\n\n    # Parse out the signature: e.g., parses to [(\'n\', \'m\'), (\'m\', \'p\')]\n    parsed_sig, _ = parse_gufunc_signature(signature)\n\n    # Get core shapes before broadcasted dimensions\n    shapes_st = _gufunc_arg_shapes(parsed_sig, min_side=min_side, max_side=max_side)\n\n    # Skip this broadcasting craziness if we don\'t want extra dims:\n    if max_dims_extra == 0:\n        return shapes_st\n\n    # We could use tuples instead without creating type ambiguity since\n    # max_dims_extra > 0 and avoid calling arrays, but prob ok like this.\n    bcast_dim_st = integers(min_value=min_side[BCAST_DIM], max_value=max_side[BCAST_DIM])\n    extra_dims_st = arrays(np.intp, (max_dims_extra,), elements=bcast_dim_st)\n\n    set_to_1_st = arrays(np.bool_, (len(parsed_sig), max_dims_extra))\n\n    # np.clip will convert to np int but we don\'t really care.\n    max_extra_per_arg = [\n        0 if nn in excluded else np.clip(GLOBAL_DIMS_MAX - len(ss), 0, max_dims_extra)\n        for nn, ss in enumerate(parsed_sig)\n    ]\n    extra_per_arg_st = tuples(*[integers(min_value=0, max_value=mm) for mm in max_extra_per_arg])\n\n    return builds(_append_bcast_dims, shapes_st, extra_dims_st, set_to_1_st, extra_per_arg_st)\n\n\ndef gufunc_args(signature, dtype, elements, unique=False, excluded=(), min_side=0, max_side=5, max_dims_extra=0):\n    """"""Strategy to generate a tuple of ndarrays for arguments to a function\n    consistent with its signature with extra dimensions to test broadcasting.\n\n    Parameters\n    ----------\n    signature : str\n        Signature for shapes to be compatible with. Expects string in format\n        of numpy generalized universal function signature, e.g.,\n        `\'(m,n),(n)->(m)\'` for vectorized matrix-vector multiplication.\n    dtype : list(:class:`numpy:numpy.dtype`)\n        List of numpy `dtype` for each argument. These can be either strings\n        (``\'int64\'``), type (``np.int64``), or numpy `dtype`\n        (``np.dtype(\'int64\')``). Built in Python types (`int`, `float`, etc)\n        also work. A single `dtype` can be supplied for all arguments.\n    elements : list\n        List of strategies to fill in array elements on a per argument basis.\n        One can also specify a single strategy\n        (e.g., :func:`~hypothesis.strategies.floats`)\n        and have it applied to all arguments.\n    unique : list(bool)\n        Boolean flag to specify if all elements in an array must be unique.\n        One can also specify a single boolean to apply it to all arguments.\n    excluded : set(int)\n        Set of integers representing the positional for which the function will\n        not be vectorized. Uses same format as :obj:`numpy.vectorize`.\n    min_side : int or dict\n        Minimum size of any side of the arrays. It is good to test the corner\n        cases of 0 or 1 sized dimensions when applicable, but if not, a min\n        size can be supplied here. Minimums can be provided on a per-dimension\n        basis using a dict, e.g. ``min_side={\'n\': 2}``. One can use, e.g.,\n        ``min_side={hypothesis_gufunc.gufunc.BCAST_DIM: 2}`` to limit the size\n        of the broadcasted dimensions.\n    max_side : int or dict\n        Maximum size of any side of the arrays. This can usually be kept small\n        and still find most corner cases in testing. Dictionaries can be\n        supplied as with `min_side`.\n    max_dims_extra : int\n        Maximum number of extra dimensions that can be appended on left of\n        arrays for broadcasting. This should be kept small as the memory used\n        grows exponentially with extra dimensions. By default, no extra\n        dimensions are added.\n\n    Returns\n    -------\n    res : tuple(:class:`numpy:numpy.ndarray`)\n        Resulting ndarrays with shapes consistent with `signature` and elements\n        from `elements`. Extra dimensions for broadcasting will be present.\n\n    Examples\n    --------\n    .. code-block:: pycon\n\n      >>> from hypothesis_gufunc.gufunc import BCAST_DIM\n      >>> from hypothesis.strategies import integers, booleans\n      >>> gufunc_args(\'(m,n),(n)->(m)\',\n                      dtype=np.int_, elements=integers(0, 9), max_side=3,\n                      min_side={\'m\': 1, \'n\': 2, BCAST_DIM: 3}).example()\n      (array([[9, 8, 1],\n              [1, 7, 1]]), array([5, 6, 5]))\n      >>> gufunc_args(\'(m,n),(n)->(m)\', dtype=[\'bool\', \'int32\'],\n                           elements=[booleans(), integers(0, 100)],\n                           unique=[False, True], max_dims_extra=3).example()\n      (array([[[[[ True,  True,  True,  True,  True],\n                 [False,  True,  True,  True, False]]]]], dtype=bool),\n       array([67, 43,  0, 34, 66], dtype=int32))\n\n    """"""\n    shape_st = gufunc_arg_shapes(\n        signature, excluded=excluded, min_side=min_side, max_side=max_side, max_dims_extra=max_dims_extra\n    )\n    return _tuple_of_arrays(shape_st, dtype=dtype, elements=elements, unique=unique)\n'"
test/dummy.py,0,"b'import pytest\nimport pytest_cov\n\n# import extra deps and use it to keep pipreqs and flake8 happy\nfor pkg in (pytest, pytest_cov):\n    print(""%s %s"" % (pkg.__name__, pkg.__version__))\n'"
test/test_gufunc.py,23,"b'# Copyright (c) 2019 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom __future__ import absolute_import, division, print_function\n\nimport string\nfrom collections import defaultdict\nfrom functools import reduce\n\nimport numpy as np\nimport numpy.lib.function_base as npfb\nfrom hypothesis import given\nfrom hypothesis.errors import InvalidArgument\nfrom hypothesis.extra.numpy import from_dtype, scalar_dtypes\nfrom hypothesis.strategies import (\n    booleans,\n    composite,\n    data,\n    dictionaries,\n    from_regex,\n    integers,\n    just,\n    lists,\n    one_of,\n    sampled_from,\n    sets,\n    tuples,\n)\n\nimport hypothesis_gufunc.gufunc as gu\n\n# Use to sample from simple names, we also can sample from npfb._SIGNATURE\n# regex to get all possible signatures. This regex also doesn\'t start with\n# digits because if it is parsed as number we could end up with very large\n# dimensions that blow out memory.\nVALID_DIM_NAMES = r""\\A[a-zA-Z_][a-zA-Z0-9_]*\\Z""\n\n# These used to be in hypothesis.internal.compat, but were removed with Py2 deprecation. So, redefining:\ninteger_types = (int,)\nhunichr = chr\n\n_st_shape = lists(integers(min_value=0, max_value=5), min_size=0, max_size=3).map(tuple)\n\n\ndef no_weird_digits(ss):\n    ok = all((not cc.isdigit()) or (cc in string.digits) for cc in ss)\n    return ok\n\n\ndef pad_left(L, size, padding):\n    L = (padding,) * max(0, size - len(L)) + L\n    return L\n\n\ndef validate_elements(L, dtype, unique=False, choices=None):\n    for drawn in L:\n        assert drawn.dtype == np.dtype(dtype)\n\n        if unique:\n            assert len(set(drawn.ravel())) == drawn.size\n\n        if choices is not None:\n            assert drawn.dtype == choices.dtype\n            vals = set(drawn.ravel())\n            assert vals.issubset(choices)\n\n\ndef validate_shapes(L, parsed_sig, min_side, max_side):\n    assert type(L) == list\n    assert len(parsed_sig) == len(L)\n    size_lookup = {}\n    for spec, drawn in zip(parsed_sig, L):\n        assert type(drawn) == tuple\n        assert len(spec) == len(drawn)\n        for ss, dd in zip(spec, drawn):\n            assert isinstance(dd, integer_types)\n            if ss.isdigit():\n                assert int(ss) == dd\n            else:\n                mm = min_side.get(ss, 0) if isinstance(min_side, dict) else min_side\n                assert mm <= dd\n                mm = max_side.get(ss, gu.DEFAULT_MAX_SIDE) if isinstance(max_side, dict) else max_side\n                assert dd <= mm\n                var_size = size_lookup.setdefault(ss, dd)\n                assert var_size == dd\n\n\ndef validate_bcast_shapes(shapes, parsed_sig, excluded, min_side, max_side, max_dims_extra):\n    # Ok to be above GLOBAL_DIMS_MAX if core dims are too\n    assert all(len(ss) <= gu.GLOBAL_DIMS_MAX or len(ss) == len(pp) for ss, pp in zip(shapes, parsed_sig))\n\n    assert type(shapes) is list\n    assert all(type(ss) is tuple for ss in shapes)\n    assert all(all(type(v) is int for v in ss) for ss in shapes)\n\n    assert all((ii not in excluded) or len(ss) == len(pp) for ii, (ss, pp) in enumerate(zip(shapes, parsed_sig)))\n\n    # chop off extra dims then same as gufunc_shape\n    core_dims = [tt[len(tt) - len(pp) :] for tt, pp in zip(shapes, parsed_sig)]\n    validate_shapes(core_dims, parsed_sig, min_side, max_side)\n\n    # check max_dims_extra\n    b_dims = [tt[: len(tt) - len(pp)] for tt, pp in zip(shapes, parsed_sig)]\n    assert all(len(tt) <= max_dims_extra for tt in b_dims)\n\n    # Convert dims to matrix form\n    b_dims2 = np.array([pad_left(bb, max_dims_extra, 1) for bb in b_dims], dtype=int)\n    # The extra broadcast dims be set to one regardless of min, max sides\n    mm = min_side.get(gu.BCAST_DIM, 0) if isinstance(min_side, dict) else min_side\n    assert np.all((b_dims2 == 1) | (mm <= b_dims2))\n    mm = max_side.get(gu.BCAST_DIM, gu.DEFAULT_MAX_SIDE) if isinstance(max_side, dict) else max_side\n    assert np.all((b_dims2 == 1) | (b_dims2 <= mm))\n    # make sure 1 or same\n    for ii in range(max_dims_extra):\n        vals = set(b_dims2[:, ii])\n        # Must all be 1 or a const size\n        assert len(vals) <= 2\n        assert len(vals) < 2 or (1 in vals)\n\n\ndef assertInvalidArgument(f, *args, **kwargs):\n    try:\n        f(*args, **kwargs)\n    except InvalidArgument:\n        return\n    assert False, ""expected InvalidArgument exception""\n\n\ndef unparse(parsed_sig):\n    assert len(parsed_sig) > 0, ""gufunc sig does not support no argument funcs""\n\n    i_sig = ["","".join(vv) for vv in parsed_sig[0]]\n    i_sig = ""("" + ""),("".join(i_sig) + "")""\n\n    o_sig = ["","".join(vv) for vv in parsed_sig[1]]\n    o_sig = ""("" + ""),("".join(o_sig) + "")""\n\n    sig = ""->"".join((i_sig, o_sig))\n    return sig\n\n\ndef real_scalar_dtypes():\n    def to_native(dtype):\n        tt = dtype.type\n        # Only keep if invertible\n        tt = tt if np.dtype(tt) == dtype else dtype\n        return tt\n\n    def cast_it(args):\n        return args[0](args[1])\n\n    dtypes = scalar_dtypes()\n    return one_of(dtypes, dtypes.map(str), dtypes.map(to_native))\n\n\ndef real_from_dtype(dtype, N=10):\n    dtype = np.dtype(dtype)\n\n    def clean_up(x):\n        x = np.nan_to_num(x).astype(dtype)\n        assert x.dtype == dtype  # hard to always get this it seems\n        return x\n\n    S = lists(from_dtype(dtype), min_size=N, max_size=N).map(clean_up)\n    return S\n\n\ndef parsed_sigs(big=False):\n    """"""Strategy to generate a parsed gufunc signature.\n\n    Note that in general functions can take no-args, but the function signature\n    formalism is for >= 1 args. So, there is always at least 1 arg here.\n    """"""\n    max_dims = 3\n    max_args = 5\n    # Use | to sample from digits since we would like (small) pure numbers too\n    shapes = lists(from_regex(VALID_DIM_NAMES) | sampled_from(string.digits), min_size=0, max_size=max_dims).map(tuple)\n    S = lists(shapes, min_size=1, max_size=max_args)\n    S = tuples(S, S)\n\n    if big:\n        # Or throw in anything compatible with regex sig\n        all_sigs = from_regex(npfb._SIGNATURE).filter(no_weird_digits)\n        S |= all_sigs.map(gu.parse_gufunc_signature)\n\n    return S\n\n\n@composite\ndef parsed_sigs_and_sizes(draw, big=False):\n    min_min_side = 0\n    max_max_side = 100 if big else 5\n\n    parsed_sig = draw(parsed_sigs(big))\n    # list of all labels used in sig, includes ints which is ok to include in\n    # dict as distractors.\n    labels = list(set([k for arg in parsed_sig[0] for k in arg]))\n    # Also sometimes put the broadcast flag in as label\n    labels.append(gu.BCAST_DIM)\n\n    # Using a split to decide which numbers we use for min sides and which\n    # numbers we use for max side, to avoid min > max. This strategy does not\n    # cover whole search space, but should should be good enough.\n    split = draw(integers(min_min_side, gu.DEFAULT_MAX_SIDE))\n\n    if draw(booleans()):\n        min_side = draw(dictionaries(sampled_from(labels), integers(min_min_side, split)))\n    else:\n        min_side = draw(integers(min_min_side, split))\n\n    if draw(booleans()):\n        max_side = draw(dictionaries(sampled_from(labels), integers(split, max_max_side)))\n    else:\n        max_side = draw(integers(split, max_max_side))\n\n    return parsed_sig, min_side, max_side\n\n\ndef test_check_functions():\n    assertInvalidArgument(gu._check_valid_size_interval, ""1"", 5, """")\n    assertInvalidArgument(gu._check_valid_size_interval, 1, ""5"", """")\n    assertInvalidArgument(gu._check_valid_size_interval, 5, 1, """")\n    assertInvalidArgument(gu._check_valid_size_interval, 0, 5, """", floor=1)\n\n    assertInvalidArgument(gu._int_or_dict, {}, ""5"")\n    assertInvalidArgument(gu._int_or_dict, ""1"", 5)\n\n    assertInvalidArgument(gu.gufunc_arg_shapes, ""()->()"", max_dims_extra=""5"")\n    assertInvalidArgument(gu.gufunc_arg_shapes, ""()->()"", max_dims_extra=-1)\n    assertInvalidArgument(gu.gufunc_arg_shapes, ""()->()"", max_dims_extra=50)\n\n\n@given(parsed_sigs(big=True))\ndef test_unparse_parse(sig):\n    i_parsed_sig, o_parsed_sig = sig\n\n    # We don\'t care about the output for this function\n    signature = unparse((i_parsed_sig, o_parsed_sig))\n    # This is a \'private\' function of np, so need to test it still works as we\n    # think it does.\n    inp, out = gu.parse_gufunc_signature(signature)\n\n    assert i_parsed_sig == inp\n    assert o_parsed_sig == out\n\n\ndef test_check_set_like():\n    """"""Need for 100% coverage""""""\n    assertInvalidArgument(gu._check_set_like, 0)\n    assertInvalidArgument(gu._check_set_like, ""0"")\n    assertInvalidArgument(gu._check_set_like, ""foobar"")\n\n\n@given(dictionaries(from_regex(VALID_DIM_NAMES), integers()), integers(), integers())\ndef test_ddict_int_or_dict(D, default_val, default_val2):\n    DD = defaultdict(lambda: default_val, D)\n\n    DD2 = gu._int_or_dict(DD, default_val2)\n\n    # just pass thru\n    assert DD is DD2\n    # default_val2 is ignored\n    assert DD2.default_factory() == default_val\n\n\n@given(dictionaries(from_regex(VALID_DIM_NAMES), integers()), integers())\ndef test_dict_int_or_dict(D, default_val):\n    DD = gu._int_or_dict(D, default_val)\n\n    assert DD == D\n    assert DD[""---""] == default_val\n\n\n@given(integers(), integers())\ndef test_int_int_or_dict(default_val, default_val2):\n    DD = gu._int_or_dict(default_val, default_val2)\n\n    assert len(DD) == 0\n    assert DD[""---""] == default_val\n\n\n# hypothesis.extra.numpy.array_shapes does not support 0 min_size so we roll our own in this case.\n@given(lists(_st_shape, min_size=0, max_size=5), real_scalar_dtypes(), booleans(), data())\ndef test_shapes_tuple_of_arrays(shapes, dtype, unique, data):\n    elements = from_dtype(np.dtype(dtype))\n\n    S = gu._tuple_of_arrays(shapes, dtype, elements=elements, unique=unique)\n    X = data.draw(S)\n\n    validate_elements(X, dtype=dtype, unique=unique)\n\n    assert len(shapes) == len(X)\n    for spec, drawn in zip(shapes, X):\n        assert tuple(spec) == np.shape(drawn)\n\n\n# hypothesis.extra.numpy.array_shapes does not support 0 min_size so we roll our own in this case.\n@given(lists(_st_shape, min_size=0, max_size=5), real_scalar_dtypes(), booleans(), data())\ndef test_just_shapes_tuple_of_arrays(shapes, dtype, unique, data):\n    elements = from_dtype(np.dtype(dtype))\n\n    # test again, but this time pass in strategy to make sure it can handle it\n    S = gu._tuple_of_arrays(just(shapes), just(dtype), elements=elements, unique=just(unique))\n    X = data.draw(S)\n\n    validate_elements(X, dtype=dtype, unique=unique)\n\n    assert len(shapes) == len(X)\n    for spec, drawn in zip(shapes, X):\n        assert tuple(spec) == np.shape(drawn)\n\n\n@given(lists(_st_shape, min_size=0, max_size=5), real_scalar_dtypes(), data())\ndef test_elements_tuple_of_arrays(shapes, dtype, data):\n    choices = data.draw(real_from_dtype(dtype))\n\n    elements = sampled_from(choices)\n    S = gu._tuple_of_arrays(shapes, dtype, elements=elements)\n    X = data.draw(S)\n\n    validate_elements(X, choices=choices, dtype=dtype)\n\n\n@given(\n    gu.gufunc_args(\n        ""(1),(1),(1),()->()"",\n        dtype=[""object"", ""object"", ""object"", ""bool""],\n        elements=[_st_shape, scalar_dtypes(), just(None), booleans()],\n        min_side=1,\n        max_dims_extra=1,\n    ),\n    data(),\n)\ndef test_bcast_tuple_of_arrays(args, data):\n    """"""Now testing broadcasting of tuple_of_arrays, kind of crazy since it uses\n    gufuncs to test itself. Some awkwardness here since there are a lot of\n    corner cases when dealing with object types in the numpy extension.\n\n    For completeness, should probably right a function like this for the other\n    functions, but there always just pass dtype, elements, unique to\n    `_tuple_of_arrays` anyway, so this should be pretty good.\n    """"""\n    shapes, dtype, elements, unique = args\n\n    shapes = shapes.ravel()\n    # Need to squeeze out due to weird behaviour of object\n    dtype = np.squeeze(dtype, -1)\n    elements = np.squeeze(elements, -1)\n\n    elements_shape = max(dtype.shape, elements.shape)\n    dtype_ = np.broadcast_to(dtype, elements_shape)\n    if elements_shape == ():\n        elements = from_dtype(dtype_.item())\n    else:\n        elements = [from_dtype(dd) for dd in dtype_]\n\n    shapes_shape = max(shapes.shape, dtype.shape, elements_shape, unique.shape)\n    shapes = np.broadcast_to(shapes, shapes_shape)\n\n    S = gu._tuple_of_arrays(shapes, dtype, elements=elements, unique=unique)\n    X = data.draw(S)\n\n    assert len(shapes) == len(X)\n    for spec, drawn in zip(shapes, X):\n        assert tuple(spec) == np.shape(drawn)\n\n    for ii, xx in enumerate(X):\n        dd = dtype[ii] if dtype.size > 1 else dtype.item()\n        uu = unique[ii] if unique.size > 1 else unique.item()\n        validate_elements([xx], dtype=dd, unique=uu)\n\n\n@given(parsed_sigs(big=True))\ndef test_const_signature_map(parsed_sig):\n    parsed_sig, _ = parsed_sig\n\n    # Map all dims to zero\n    all_dims = reduce(set.union, [set(arg) for arg in parsed_sig])\n    map_dict = {k: 0 for k in all_dims}\n\n    p_ = gu._signature_map(map_dict, parsed_sig)\n\n    assert all(all(v == 0 for v in arg) for arg in p_)\n\n\n@given(parsed_sigs(big=True))\ndef test_inverse_signature_map(parsed_sig):\n    parsed_sig, _ = parsed_sig\n\n    # Build an arbitrary map\n    all_dims = sorted(reduce(set.union, [set(arg) for arg in parsed_sig]))\n    map_dict = dict(zip(all_dims, all_dims[::-1]))\n\n    inv_map = {v: k for k, v in map_dict.items()}\n\n    p_ = gu._signature_map(map_dict, parsed_sig)\n    p_ = gu._signature_map(inv_map, p_)\n\n    assert p_ == parsed_sig\n\n\n# Allow bigger sizes since we only generate the shapes and never alloc arrays\n# Try +3 to see what happens if we put something too big in\n@given(parsed_sigs_and_sizes(big=True), data())\ndef test_shapes_gufunc_arg_shapes(parsed_sig_and_size, data):\n    parsed_sig, min_side, max_side = parsed_sig_and_size\n\n    # This private function assumes already preprocessed sizes to default dict\n    min_side = gu._int_or_dict(min_side, 0)\n    max_side = gu._int_or_dict(max_side, gu.DEFAULT_MAX_SIDE)\n\n    S = gu._gufunc_arg_shapes(parsed_sig[0], min_side=min_side, max_side=max_side)\n\n    shapes = data.draw(S)\n    validate_shapes(shapes, parsed_sig[0], min_side, max_side)\n\n\ndef test_validation_gufunc_arg_shapes():\n    sig_template_1 = ""(3),(%s)->()""\n    sig_template_2 = ""(x,4),(foo%s)->(5)""\n    weird_chars = (1632, 1633, 1634, 65303, 65304, 65305)  # There are more\n\n    for cc in weird_chars:\n        assertInvalidArgument(gu.gufunc_arg_shapes, sig_template_1 % hunichr(cc))\n        assertInvalidArgument(gu.gufunc_arg_shapes, sig_template_2 % hunichr(cc))\n\n\n@given(parsed_sigs_and_sizes(big=False), real_scalar_dtypes(), booleans(), data())\ndef test_shapes_gufunc_args(parsed_sig_and_size, dtype, unique, data):\n    parsed_sig, min_side, max_side = parsed_sig_and_size\n\n    signature = unparse(parsed_sig)\n\n    # We could also test using elements strategy that then requires casting,\n    # but that would be kind of complicated to come up with compatible combos\n    elements = from_dtype(np.dtype(dtype))\n\n    # Assumes zero broadcast dims by default\n    S = gu.gufunc_args(signature, min_side=min_side, max_side=max_side, dtype=dtype, elements=elements, unique=unique)\n\n    X = data.draw(S)\n    shapes = [np.shape(xx) for xx in X]\n\n    validate_shapes(shapes, parsed_sig[0], min_side, max_side)\n    validate_elements(X, dtype=dtype, unique=unique)\n\n\n@given(parsed_sigs(big=False), integers(0, 5), integers(0, 5), real_scalar_dtypes(), data())\ndef test_elements_gufunc_args(parsed_sig, min_side, max_side, dtype, data):\n    choices = data.draw(real_from_dtype(dtype))\n    elements = sampled_from(choices)\n\n    signature = unparse(parsed_sig)\n\n    min_side, max_side = sorted([min_side, max_side])\n\n    S = gu.gufunc_args(signature, min_side=min_side, max_side=max_side, dtype=dtype, elements=elements)\n\n    X = data.draw(S)\n\n    validate_elements(X, choices=choices, dtype=dtype)\n\n\n@given(\n    gu.gufunc_args(\n        ""(n),(m),(n,m),(n)->()"",\n        dtype=[""object"", int, bool, int],\n        elements=[_st_shape, integers(0, 100), booleans(), integers(0, 100)],\n        min_side={""n"": 1},\n    )\n)  # always at least one arg\ndef test_append_bcast_dims(args):\n    core_dims, b_dims, set_to_1, n_extra_per_arg = args\n\n    max_extra = len(b_dims)\n    # Put all in range [0, max_extra]\n    n_extra_per_arg = tuple(n_extra_per_arg % (max_extra + 1))\n\n    shapes = gu._append_bcast_dims(core_dims, b_dims, set_to_1, n_extra_per_arg)\n\n    for ii, ss in enumerate(shapes):\n        bb = np.asarray(ss[: len(ss) - len(core_dims[ii])])\n        cc = ss[len(ss) - len(core_dims[ii]) :]\n\n        st1 = set_to_1[ii]\n        st1 = st1[len(st1) - len(bb) :]\n\n        assert len(bb) == n_extra_per_arg[ii]\n        assert cc == core_dims[ii]\n        assert np.all(bb[st1] == 1)\n        assert np.all(bb[~st1] == b_dims[len(b_dims) - len(bb) :][~st1])\n\n\n@given(parsed_sigs_and_sizes(big=True), integers(0, gu.GLOBAL_DIMS_MAX), data())\ndef test_broadcast_shapes_gufunc_arg_shapes(parsed_sig_and_size, max_dims_extra, data):\n    parsed_sig, min_side, max_side = parsed_sig_and_size\n\n    signature = unparse(parsed_sig)\n    parsed_sig, _ = parsed_sig\n\n    excluded = data.draw(sets(integers(0, len(parsed_sig) - 1)).map(tuple))\n\n    S = gu.gufunc_arg_shapes(\n        signature, excluded=excluded, min_side=min_side, max_side=max_side, max_dims_extra=max_dims_extra\n    )\n\n    shapes = data.draw(S)\n\n    validate_bcast_shapes(shapes, parsed_sig, excluded, min_side, max_side, max_dims_extra)\n\n\n@given(parsed_sigs_and_sizes(big=False), integers(0, 3), real_scalar_dtypes(), booleans(), data())\ndef test_broadcast_shapes_gufunc_args(parsed_sig_and_size, max_dims_extra, dtype, unique, data):\n    parsed_sig, min_side, max_side = parsed_sig_and_size\n\n    signature = unparse(parsed_sig)\n    parsed_sig, _ = parsed_sig\n\n    excluded = data.draw(sets(integers(0, len(parsed_sig) - 1)).map(tuple))\n\n    elements = from_dtype(np.dtype(dtype))\n\n    S = gu.gufunc_args(\n        signature,\n        excluded=excluded,\n        min_side=min_side,\n        max_side=max_side,\n        max_dims_extra=max_dims_extra,\n        dtype=dtype,\n        elements=elements,\n        unique=unique,\n    )\n\n    X = data.draw(S)\n    shapes = [np.shape(xx) for xx in X]\n\n    validate_bcast_shapes(shapes, parsed_sig, excluded, min_side, max_side, max_dims_extra)\n    validate_elements(X, dtype=dtype, unique=unique)\n\n\n@given(parsed_sigs(big=False), integers(0, 5), integers(0, 5), integers(0, 3), real_scalar_dtypes(), data())\ndef test_broadcast_elements_gufunc_args(parsed_sig, min_side, max_side, max_dims_extra, dtype, data):\n    signature = unparse(parsed_sig)\n    parsed_sig, _ = parsed_sig\n\n    excluded = data.draw(sets(integers(0, len(parsed_sig) - 1)).map(tuple))\n\n    min_side, max_side = sorted([min_side, max_side])\n\n    choices = data.draw(real_from_dtype(dtype))\n    elements = sampled_from(choices)\n\n    S = gu.gufunc_args(\n        signature,\n        excluded=excluded,\n        min_side=min_side,\n        max_side=max_side,\n        max_dims_extra=max_dims_extra,\n        dtype=dtype,\n        elements=elements,\n    )\n\n    X = data.draw(S)\n\n    validate_elements(X, choices=choices, dtype=dtype)\n'"
hypothesis_gufunc/extra/__init__.py,0,b''
hypothesis_gufunc/extra/xr.py,0,"b'# Copyright (c) 2019 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n""""""This module implements strategies for creating :class:`xarray:xarray.DataArray` and\n:class:`xarray:xarray.Dataset` objects.\n""""""\nimport string\nfrom collections import OrderedDict, defaultdict\n\nimport xarray as xr\nfrom hypothesis.extra.numpy import arrays, order_check\nfrom hypothesis.internal.validation import check_valid_bound\nfrom hypothesis.strategies import fixed_dictionaries, floats, integers, lists, nothing, sampled_from, text, tuples\n\nDEFAULT_DTYPE = int\nDEFAULT_SIDE = 5\nDEFAULT_DIMS = 5\nDEFAULT_VARS = 5\n\n\ndef _check_valid_size_interval(min_size, max_size, name, floor=0):\n    """"""Check valid for integers strategy and array shapes.""""""\n    # same checks as done in integers\n    check_valid_bound(min_size, name)\n    check_valid_bound(max_size, name)\n    if max_size is None:\n        order_check(name, floor, min_size, min_size)\n    else:\n        order_check(name, floor, min_size, max_size)\n\n\ndef _easy_text():\n    return text(alphabet=string.ascii_lowercase, min_size=0, max_size=5)\n\n\ndef _hashable():\n    S = floats() | integers() | _easy_text()\n    return S\n\n\ndef _get_all_dims(vars_to_dims):\n    all_dims = sorted(set(sum((list(dd) for dd in vars_to_dims.values()), [])))\n    return all_dims\n\n\nxr_dims = _easy_text\nxr_vars = _hashable\n\n\ndef subset_lists(L, min_size=0, max_size=None):\n    """"""Strategy to generate a subset of a `list`.\n\n    This should be built in to hypothesis (see hypothesis issue #1115), but was rejected.\n\n    Parameters\n    ----------\n    L : list\n        List of elements we want to get a subset of.\n    min_size : int\n        Minimum size of the resulting subset list.\n    max_size : int or None\n        Maximum size of the resulting subset list.\n\n    Returns\n    -------\n    L : list\n        List that is subset of `L` with all unique elements.\n    """"""\n    _check_valid_size_interval(min_size, max_size, ""subset list size"")\n    uniq_len = len(set(L))\n    order_check(""input list size"", 0, min_size, uniq_len)\n\n    max_size = uniq_len if max_size is None else min(uniq_len, max_size)\n\n    # Avoid deprecation warning HypothesisDeprecationWarning: sampled_from()\n    elements_st = nothing() if uniq_len == 0 else sampled_from(L)\n\n    S = lists(elements=elements_st, min_size=min_size, max_size=max_size, unique=True)\n    return S\n\n\ndef xr_dim_lists(min_dims=0, max_dims=DEFAULT_DIMS):\n    """"""Generate `list` of dimension names for a :class:`xarray:xarray.DataArray`.\n\n    Parameters\n    ----------\n    min_dims : int\n        Minimum size of the resulting dimension list.\n    max_dims : int or None\n        Maximum size of the resulting dimension list.\n\n    Returns\n    -------\n    L : list(str)\n        List of dimension names.\n    """"""\n    _check_valid_size_interval(min_dims, max_dims, ""dimensions"")\n    S = lists(elements=xr_dims(), min_size=min_dims, max_size=max_dims, unique=True)\n    return S\n\n\ndef xr_var_lists(min_vars=0, max_vars=DEFAULT_VARS):\n    """"""Generate `list` of variable names for a :class:`xarray:xarray.Dataset`.\n\n    Parameters\n    ----------\n    min_vars : int\n        Minimum size of the resulting variable list.\n    max_vars : int or None\n        Maximum size of the resulting variable list.\n\n    Returns\n    -------\n    L : list(typing.Hashable)\n        List of variable names.\n    """"""\n    _check_valid_size_interval(min_vars, max_vars, ""variables"")\n    S = lists(elements=xr_vars(), min_size=min_vars, max_size=max_vars, unique=True)\n    return S\n\n\ndef _vars_and_dims_pairs(min_vars=0, max_vars=DEFAULT_VARS, min_dims=0, max_dims=DEFAULT_DIMS):\n    """"""Generate both variable and dimension names.\n\n    xarray requires that there are no name collisions between the two.\n    """"""\n\n    def no_overlap(args):\n        vars_, dims = args\n        # Dataset does not allow the same names for variable and dimensions, so we filter by looking at intersection\n        ok = len(set(dims).intersection(vars_)) == 0\n        return ok\n\n    S = tuples(xr_var_lists(min_vars, max_vars), xr_dim_lists(min_dims, max_dims)).filter(no_overlap)\n    return S\n\n\ndef vars_to_dims_dicts(min_vars=0, max_vars=DEFAULT_VARS, min_dims=0, max_dims=DEFAULT_DIMS):\n    """"""Generate mapping of variable name to `list` of dimensions, which is compatible with building a\n    :class:`xarray:xarray.Dataset`.\n\n    Parameters\n    ----------\n    min_vars : int\n        Minimum size of the resulting variable list.\n    max_vars : int or None\n        Maximum size of the resulting variable list.\n    min_dims : int\n        Minimum size of the resulting dimension list.\n    max_dims : int or None\n        Maximum size of the resulting dimension list.\n\n    Returns\n    -------\n    D : dict(typing.Hashable, list(str))\n        Mapping of variable names to `list` of dimensions, which can be fed to constructor for a\n        :class:`xarray:xarray.Dataset`.\n    """"""\n    _check_valid_size_interval(min_vars, max_vars, ""variables"")\n    _check_valid_size_interval(min_dims, max_dims, ""dimensions"")\n\n    def map_dict(args):\n        vars_, dims = args\n        dim_st = subset_lists(dims, min_size=min_dims, max_size=max_dims)\n        S = fixed_dictionaries(OrderedDict([(vv, dim_st) for vv in vars_]))\n        return S\n\n    S = _vars_and_dims_pairs(min_vars, max_vars, min_dims, max_dims).flatmap(map_dict)\n    return S\n\n\ndef xr_coords(elements=None, min_side=0, max_side=DEFAULT_SIDE, unique=True):\n    """"""Generate values for the coordinates in a :class:`xarray:xarray.DataArray`.\n\n    Non-unique coords do not make much sense, but xarray allows it. So we should be able to generate it.\n\n    Parameters\n    ----------\n    elements : SearchStrategy or None\n        Strategy to fill the elements of coordinates. Uses :func:`hypothesis:hypothesis.strategies.integers` by default.\n    min_side : int\n        Minimum length of coordinates array.\n    max_side : int or None\n        Maximum length of coordinates array.\n    unique : bool\n        If all coordinate values should be unique. `xarray` allows non-unique values, but it makes no sense.\n\n    Returns\n    -------\n    L : list\n        The coordinates filled with samples from `elements`.\n    """"""\n    _check_valid_size_interval(min_side, max_side, ""side"")\n\n    if elements is None:\n        elements = integers()\n\n    S = lists(elements=elements, min_size=min_side, max_size=max_side, unique=unique)\n    return S\n\n\ndef simple_coords(min_side=0, max_side=DEFAULT_SIDE):\n    """"""Generate a simple coordinate for a :class:`xarray:xarray.DataArray`.\n\n    A simple coordinate is one in which the values go: 0, 1, ..., n.\n\n    Parameters\n    ----------\n    min_side : int\n        Minimum length of coordinates array.\n    max_side : int or None\n        Maximum length of coordinates array.\n\n    Returns\n    -------\n    L : list(int)\n        The coordinates filled with values of: ``list(range(len(L)))``.\n    """"""\n    _check_valid_size_interval(min_side, max_side, ""side"")\n\n    n = integers(min_value=min_side, max_value=max_side)\n    S = n.map(range).map(list)  # Always make list to be consistent with xr_coords\n    return S\n\n\ndef xr_coords_dicts(dims, elements=None, min_side=0, max_side=DEFAULT_SIDE, unique_coords=True, coords_st={}):\n    """"""Build a dictionary of coordinates for the purpose of building a :class:`xarray:xarray.DataArray`.\n\n    `xarray` allows some dims to not have any specified coordinate. This strategy assigns a coord to every dimension. If\n    we really want to test those possibilities we need to take a subset of the `dict` that is sampled from this\n    strategy.\n\n    Parameters\n    ----------\n    dims : list(str)\n        Dimensions we need to generate coordinates for.\n    elements : SearchStrategy or None\n        Strategy to fill the elements of coordinates. Uses `integers` by default.\n    min_side : int\n        Minimum length of coordinates array.\n    max_side : int or None\n        Maximum length of coordinates array.\n    unique_coords : bool\n        If all coordinate values should be unique. `xarray` allows non-unique values, but it makes no sense.\n    coords_st : dict(str, SearchStrategy)\n        Special strategies for filling specific dimensions. Use the dimension name as the key and the strategy for\n        generating the coordinate as the value.\n\n    Returns\n    -------\n    coords : dict(str, list)\n        Dictionary mapping dimension name to its coordinate values (a list with elements from the `elements` strategy).\n    """"""\n    _check_valid_size_interval(min_side, max_side, ""side"")\n\n    default_st = xr_coords(elements=elements, min_side=min_side, max_side=max_side, unique=unique_coords)\n    C = OrderedDict([(dd, coords_st.get(dd, default_st)) for dd in dims])\n    S = fixed_dictionaries(C)\n    return S\n\n\ndef fixed_coords_dataarrays(dims, coords, dtype=DEFAULT_DTYPE, elements=None):\n    """"""Generate a :class:`xarray:xarray.DataArray` with coordinates that are fixed a-priori.\n\n    Parameters\n    ----------\n    dims : list(str)\n        Dimensions we need to generate coordinates for.\n    coords : dict(str, list)\n        Dictionary mapping dimension name to its coordinate values.\n    dtype : type\n        Data type for values in the :class:`xarray:xarray.DataArray`. This can be anything understood by\n        :func:`hypothesis:hypothesis.extra.numpy.arrays`.\n    elements : SearchStrategy or None\n        Strategy to fill the elements of the :class:`xarray:xarray.DataArray`. If `None`, a default is selected based\n        on `dtype`.\n\n    Returns\n    -------\n    da : :class:`xarray:xarray.DataArray`\n        :class:`xarray:xarray.DataArray` generated with the specified coordinates and elements from the specified\n        strategy.\n    """"""\n    shape = [len(coords[dd]) for dd in dims]\n    data_st = arrays(dtype, shape, elements=elements)\n    coords = {dd: cc for dd, cc in coords.items() if dd in dims}\n    S = data_st.map(lambda data: xr.DataArray(data, coords=coords, dims=dims))\n    return S\n\n\ndef fixed_dataarrays(\n    dims, dtype=DEFAULT_DTYPE, elements=None, coords_elements=None, min_side=0, max_side=DEFAULT_SIDE, coords_st={}\n):\n    """"""Generate :class:`xarray:xarray.DataArray` with dimensions (but not coordinates) that are fixed a-priori.\n\n    Parameters\n    ----------\n    dims : list(str)\n        Dimensions we need to generate coordinates for.\n    dtype : type\n        Data type for values in the :class:`xarray:xarray.DataArray`. This can be anything understood by\n        :func:`hypothesis:hypothesis.extra.numpy.arrays`.\n    elements : SearchStrategy or None\n        Strategy to fill the elements of the :class:`xarray:xarray.DataArray`. If `None`, a default is selected based\n        on `dtype`.\n    coords_elements : SearchStrategy or None\n        Strategy to fill the elements of coordinates.\n    min_side : int\n        Minimum side length of the :class:`xarray:xarray.DataArray`.\n    max_side : int or None\n        Maximum side length of the :class:`xarray:xarray.DataArray`.\n    coords_st : dict(str, SearchStrategy)\n        Special strategies for filling specific dimensions. Use the dimension name as the key and the strategy for\n        generating the coordinate as the value.\n\n    Returns\n    -------\n    da : :class:`xarray:xarray.DataArray`\n        :class:`xarray:xarray.DataArray` generated with the dimensions and elements from the specified strategy.\n    """"""\n    _check_valid_size_interval(min_side, max_side, ""side"")\n\n    coords_st = xr_coords_dicts(\n        dims, elements=coords_elements, min_side=min_side, max_side=max_side, coords_st=coords_st\n    )\n    S = coords_st.flatmap(lambda C: fixed_coords_dataarrays(dims, C, dtype=dtype, elements=elements))\n    return S\n\n\ndef simple_dataarrays(dims, dtype=DEFAULT_DTYPE, elements=None, min_side=0, max_side=DEFAULT_SIDE):\n    """"""Generate a :class:`xarray:xarray.DataArray` with dimensions that are fixed a-priori and simple coordinates.\n\n    Parameters\n    ----------\n    dims : list(str)\n        Dimensions we need to generate coordinates for.\n    dtype : type\n        Data type for values in the :class:`xarray:xarray.DataArray`. This can be anything understood by\n        :func:`hypothesis:hypothesis.extra.numpy.arrays`.\n    elements : SearchStrategy or None\n        Strategy to fill the elements of the :class:`xarray:xarray.DataArray`. If `None`, a default is selected based on\n        `dtype`.\n    min_side : int\n        Minimum side length of the :class:`xarray:xarray.DataArray`.\n    max_side : int or None\n        Maximum side length of the :class:`xarray:xarray.DataArray`.\n\n    Returns\n    -------\n    da : :class:`xarray:xarray.DataArray`\n        :class:`xarray:xarray.DataArray` generated with the dimensions, simple coordinates, and elements from the\n        specified strategy.\n    """"""\n    _check_valid_size_interval(min_side, max_side, ""side"")\n\n    default_st = simple_coords(min_side=min_side, max_side=max_side)\n    coords_st = OrderedDict([(dd, default_st) for dd in dims])\n    S = fixed_dataarrays(dims, dtype=dtype, elements=elements, coords_st=coords_st)\n    return S\n\n\ndef dataarrays(\n    dtype=DEFAULT_DTYPE,\n    elements=None,\n    coords_elements=None,\n    min_side=0,\n    max_side=DEFAULT_SIDE,\n    min_dims=0,\n    max_dims=DEFAULT_DIMS,\n):\n    """"""Generate a :class:`xarray:xarray.DataArray` with no dimensions or coordinates fixed a-priori.\n\n    Parameters\n    ----------\n    dtype : type\n        Data type for values in the :class:`xarray:xarray.DataArray`. This can be anything understood by\n        :func:`hypothesis:hypothesis.extra.numpy.arrays`.\n    elements : SearchStrategy or None\n        Strategy to fill the elements of the :class:`xarray:xarray.DataArray`. If `None`, a default is selected based on\n        `dtype`.\n    coords_elements : SearchStrategy or None\n        Strategy to fill the elements of coordinates.\n    min_side : int\n        Minimum side length of the :class:`xarray:xarray.DataArray`.\n    max_side : int or None\n        Maximum side length of the :class:`xarray:xarray.DataArray`.\n    min_dims : int\n        Minimum number of dimensions.\n    max_dims : int or None\n        Maximum number of dimensions.\n\n    Returns\n    -------\n    da : :class:`xarray:xarray.DataArray`\n        :class:`xarray:xarray.DataArray` generated with the dimensions, simple coordinates, and elements from the\n        specified strategies.\n    """"""\n    _check_valid_size_interval(min_side, max_side, ""side"")\n    _check_valid_size_interval(min_dims, max_dims, ""dimensions"")\n\n    def mapper(D):\n        S = fixed_dataarrays(\n            D, dtype=dtype, elements=elements, coords_elements=coords_elements, min_side=min_side, max_side=max_side\n        )\n        return S\n\n    dims_st = xr_dim_lists(min_dims, max_dims)\n    S = dims_st.flatmap(mapper)\n    return S\n\n\ndef fixed_coords_datasets(vars_to_dims, coords, dtype=None, elements=None):\n    """"""Generate a :class:`xarray:xarray.Dataset` where the variables, dimensions, and coordinates are specified a-priori.\n\n    Parameters\n    ----------\n    vars_to_dims : dict(typing.Hashable, list(str))\n        Mapping of variable names to list of dimensions, which can be fed to constructor for a\n        :class:`xarray:xarray.Dataset`.\n    coords : dict(str, list)\n        Dictionary mapping dimension name to its coordinate values.\n    dtype : dict(typing.Hashable, type) or None\n        Dictionary mapping variables names to the data type for that variable\'s elements.\n    elements : SearchStrategy or None\n        Strategy to fill the elements of the :class:`xarray:xarray.Dataset`. If `None`, a default is selected based on\n        `dtype`.\n\n    Returns\n    -------\n    ds : :class:`xarray:xarray.Dataset`\n        :class:`xarray:xarray.Dataset` with the specified variables, dimensions, and coordinates.\n    """"""\n    if dtype is None:\n        dtype = defaultdict(lambda: DEFAULT_DTYPE)\n\n    C = OrderedDict([(vv, fixed_coords_dataarrays(dd, coords, dtype[vv], elements)) for vv, dd in vars_to_dims.items()])\n    data_st = fixed_dictionaries(C)\n    S = data_st.map(lambda data: xr.Dataset(data, coords=coords))\n    return S\n\n\ndef fixed_datasets(\n    vars_to_dims, dtype=None, elements=None, coords_elements=None, min_side=0, max_side=DEFAULT_SIDE, coords_st={}\n):\n    """"""Generate :class:`xarray:xarray.Dataset` where the variables and dimensions (but not coordinates) are specified\n    a-priori.\n\n    Parameters\n    ----------\n    vars_to_dims : dict(typing.Hashable, list(str))\n        Mapping of variable names to list of dimensions, which can be fed to constructor for a\n        :class:`xarray:xarray.Dataset`.\n    dtype : dict(typing.Hashable, type) or None\n        Dictionary mapping variables names to the data type for that variable\'s elements.\n    elements : SearchStrategy or None\n        Strategy to fill the elements of the :class:`xarray:xarray.Dataset`. If `None`, a default is selected based on\n        `dtype`.\n    coords_elements : SearchStrategy or None\n        Strategy to fill the elements of coordinates.\n    min_side : int\n        Minimum side length of the :class:`xarray:xarray.Dataset`.\n    max_side : int or None\n        Maximum side length of the :class:`xarray:xarray.Dataset`.\n    coords_st : dict(str, SearchStrategy)\n        Special strategies for filling specific dimensions. Use the dimension name as the key and the strategy for\n        generating the coordinate as the value.\n\n    Returns\n    -------\n    ds: :class:`xarray:xarray.Dataset`\n        :class:`xarray:xarray.Dataset` with the specified variables and dimensions.\n    """"""\n    _check_valid_size_interval(min_side, max_side, ""side"")\n\n    all_dims = _get_all_dims(vars_to_dims)\n    coords_st = xr_coords_dicts(\n        all_dims, elements=coords_elements, min_side=min_side, max_side=max_side, coords_st=coords_st\n    )\n    S = coords_st.flatmap(lambda C: fixed_coords_datasets(vars_to_dims, C, dtype=dtype, elements=elements))\n    return S\n\n\ndef simple_datasets(vars_to_dims, dtype=None, elements=None, min_side=0, max_side=DEFAULT_SIDE):\n    """"""Generate :class:`xarray:xarray.Dataset` with variables and dimensions that are fixed a-priori and simple\n    coordinates.\n\n    Parameters\n    ----------\n    vars_to_dims : dict(typing.Hashable, list(str))\n        Mapping of variable names to list of dimensions, which can be fed to constructor for a\n        :class:`xarray:xarray.Dataset`.\n    dtype : dict(typing.Hashable, type) or None\n        Dictionary mapping variables names to the data type for that variable\'s elements.\n    elements : SearchStrategy or None\n        Strategy to fill the elements of the :class:`xarray:xarray.Dataset`. If `None`, a default is selected based on\n        `dtype`.\n    min_side : int\n        Minimum side length of the :class:`xarray:xarray.Dataset`.\n    max_side : int or None\n        Maximum side length of the :class:`xarray:xarray.Dataset`.\n\n    Returns\n    -------\n    ds: :class:`xarray:xarray.Dataset`\n        A :class:`xarray:xarray.Dataset` with the specified variables and dimensions, and simple coordinates.\n    """"""\n    _check_valid_size_interval(min_side, max_side, ""side"")\n\n    all_dims = _get_all_dims(vars_to_dims)\n    default_st = simple_coords(min_side=min_side, max_side=max_side)\n    coords_st = OrderedDict([(dd, default_st) for dd in all_dims])\n    S = fixed_datasets(vars_to_dims, dtype=dtype, elements=elements, coords_st=coords_st)\n    return S\n\n\ndef datasets(\n    dtype=DEFAULT_DTYPE,\n    elements=None,\n    coords_elements=None,\n    min_side=0,\n    max_side=DEFAULT_SIDE,\n    min_vars=0,\n    max_vars=DEFAULT_VARS,\n    min_dims=0,\n    max_dims=DEFAULT_DIMS,\n):\n    """"""Generate a :class:`xarray:xarray.Dataset` with no variables, dimensions, or coordinates fixed a-priori.\n\n    We could also allow a strategy with a different data type per variable, but until there is a use case for that, we\n    will leave `dtype` as a scalar input.\n\n    Parameters\n    ----------\n    dtype : type\n        Data type used to fill the elements of the :class:`xarray:xarray.Dataset`.\n    elements : SearchStrategy or None\n        Strategy to fill the elements of the :class:`xarray:xarray.Dataset`. If `None`, a default is selected based on\n        `dtype`.\n    coords_elements : SearchStrategy or None\n        Strategy to fill the elements of coordinates.\n    min_side : int\n        Minimum side length of the :class:`xarray:xarray.Dataset`.\n    max_side : int or None\n        Maximum side length of the :class:`xarray:xarray.Dataset`.\n    min_vars : int\n        Minimum number of variables.\n    max_vars : int or None\n        Maximum number of variables.\n    min_dims : int\n        Minimum number of dimensions.\n    max_dims : int or None\n        Maximum number of dimensions.\n\n    Returns\n    -------\n    ds : :class:`xarray:xarray.Dataset`\n        :class:`xarray:xarray.Dataset` generated with the variables, dimensions, coordinates, and elements from the\n        specified strategies.\n    """"""\n    _check_valid_size_interval(min_side, max_side, ""side"")\n    _check_valid_size_interval(min_vars, max_vars, ""variables"")\n    _check_valid_size_interval(min_dims, max_dims, ""dimensions"")\n\n    dtype_d = defaultdict(lambda: dtype)\n    vars_to_dims = vars_to_dims_dicts(min_vars, max_vars, min_dims, max_dims)\n\n    def mapper(V):\n        S = fixed_datasets(\n            V, dtype=dtype_d, elements=elements, coords_elements=coords_elements, min_side=min_side, max_side=max_side\n        )\n        return S\n\n    S = vars_to_dims.flatmap(mapper)\n    return S\n'"
test/extra/test_xr.py,12,"b'# Copyright (c) 2019 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport numpy as np\nimport xarray as xr\nfrom hypothesis import assume, given\nfrom hypothesis.extra.numpy import scalar_dtypes\nfrom hypothesis.strategies import booleans, data, fixed_dictionaries, integers, just, lists, one_of, tuples\n\nimport hypothesis_gufunc.extra.xr as hxr\nfrom hypothesis_gufunc.extra.xr import _hashable\n\nMAX_DIM_LEN = 32\n\n\ndef sizes(allow_none=True):\n    def mapper(T):\n        if T[1] is not None:\n            T = tuple(sorted(T))\n        return T\n\n    if allow_none:\n        S = tuples(integers(0, 5), integers(0, 5) | just(None)).map(mapper)\n    else:\n        S = tuples(integers(0, 5), integers(0, 5)).map(mapper)\n    return S\n\n\ndef dtypes():\n    def to_native(dtype):\n        tt = dtype.type\n        # Only keep if invertible\n        tt = tt if np.dtype(tt) == dtype else dtype\n        return tt\n\n    def cast_it(args):\n        return args[0](args[1])\n\n    dtypes = scalar_dtypes().filter(lambda x: x.kind in ""biuf"")\n    return one_of(dtypes, dtypes.map(str), dtypes.map(to_native))\n\n\n@given(hxr.xr_dim_lists(), data())\ndef test_get_all_dims(dims, data):\n    vars_to_dims = data.draw(hxr.xr_coords_dicts(dims))\n\n    all_dims = hxr._get_all_dims(vars_to_dims)\n\n    assert all_dims == sorted(set(all_dims))\n\n    all_dims2 = []\n    for dd in vars_to_dims.values():\n        all_dims2.extend(dd)\n    assert all_dims == sorted(set(all_dims2))\n\n\n@given(lists(_hashable()), sizes(), data())\ndef test_subset_lists(L, sizes, data):\n    min_size, max_size = sizes\n\n    assume(min_size <= len(set(L)))\n\n    S = hxr.subset_lists(L, min_size, max_size)\n    L2 = data.draw(S)\n\n    n = len(L2)\n\n    assert n >= min_size\n    assert (max_size is None) or (n <= max_size)\n    assert set(L2).issubset(set(L))\n\n\n@given(lists(_hashable()), sizes(), data())\ndef test_subset_lists_empty(L, sizes, data):\n    min_size, max_size = sizes\n\n    S = hxr.subset_lists([], min_size=0, max_size=max_size)\n    L2 = data.draw(S)\n\n    assert len(L2) == 0\n    assert L2 == []\n\n\n@given(sizes(), data())\ndef test_xr_dim_lists(sizes, data):\n    min_dims, max_dims = sizes\n\n    S = hxr.xr_dim_lists(min_dims, max_dims)\n\n    L = data.draw(S)\n\n    n = len(L)\n    assert n >= min_dims\n    assert (max_dims is None) or (n <= max_dims)\n    assert all(isinstance(ss, str) for ss in L)\n\n    if n <= MAX_DIM_LEN:\n        da = xr.DataArray(np.zeros((1,) * n), dims=L)\n        assert da.dims == tuple(L)\n\n\n@given(sizes(), data())\ndef test_xr_var_lists(sizes, data):\n    min_vars, max_vars = sizes\n\n    S = hxr.xr_var_lists(min_vars, max_vars)\n\n    L = data.draw(S)\n\n    n = len(L)\n    assert n >= min_vars\n    assert (max_vars is None) or (n <= max_vars)\n    assert all(isinstance(hash(ss), int) for ss in L)\n\n    ds = xr.Dataset({vv: xr.DataArray(0) for vv in L})\n    assert set(ds) == set(L)\n\n\n@given(sizes(), sizes(), data())\ndef test_vars_to_dims_dicts(var_sizes, dim_sizes, data):\n    min_vars, max_vars = var_sizes\n    min_dims, max_dims = dim_sizes\n\n    S = hxr.vars_to_dims_dicts(min_vars, max_vars, min_dims, max_dims)\n\n    D = data.draw(S)\n\n    n = len(D)\n    assert n >= min_vars\n    assert (max_vars is None) or (n <= max_vars)\n    assert all(len(dd) >= min_dims for _, dd in D.items())\n    assert (max_dims is None) or all(len(dd) <= max_dims for _, dd in D.items())\n    assert all(all(isinstance(ss, str) for ss in dd) for _, dd in D.items())\n\n    if all(len(dd) <= MAX_DIM_LEN for _, dd in D.items()):\n        ds = xr.Dataset({vv: xr.DataArray(np.zeros((1,) * len(dd)), dims=dd) for vv, dd in D.items()})\n        assert set(ds) == set(D.keys())\n        assert all(ds[vv].dims == tuple(dd) for vv, dd in D.items())\n\n\n@given(sizes(), booleans(), data())\ndef test_xr_coords(sizes, unique, data):\n    elements = None\n    min_side, max_side = sizes\n\n    S = hxr.xr_coords(elements, min_side, max_side, unique)\n\n    L = data.draw(S)\n\n    n = len(L)\n    assert n >= min_side\n    assert (max_side is None) or (n <= max_side)\n    assert all(isinstance(ss, int) for ss in L)\n\n    if unique:\n        assert len(set(L)) == len(L)\n\n\n@given(sizes(allow_none=False), data())\ndef test_simple_coords(sizes, data):\n    min_side, max_side = sizes\n\n    S = hxr.simple_coords(min_side, max_side)\n\n    L = data.draw(S)\n\n    n = len(L)\n    assert n >= min_side\n    assert (max_side is None) or (n <= max_side)\n    assert all(isinstance(ss, int) for ss in L)\n    assert L == list(range(len(L)))\n\n\n@given(hxr.xr_dim_lists(), sizes(), booleans(), data())\ndef test_xr_coords_dicts(dims, sizes, unique_coords, data):\n    elements = None\n    min_side, max_side = sizes\n\n    # special dims just filled with dim name on coords as test case\n    special_dims = data.draw(hxr.subset_lists(dims))\n    coords_st = {dd: lists(just(dd), min_side, max_side) for dd in special_dims}\n\n    S = hxr.xr_coords_dicts(dims, elements, min_side, max_side, unique_coords, coords_st)\n\n    D = data.draw(S)\n\n    assert list(D.keys()) == dims\n    assert all(min_side <= len(cc) for cc in D.values())\n    assert (max_side is None) or all(max_side >= len(cc) for cc in D.values())\n    assert all((dd in special_dims) or all(isinstance(ss, int) for ss in L) for dd, L in D.items())\n    assert all(all(ss == dd for ss in D[dd]) for dd in special_dims)\n\n    if unique_coords:\n        for dd, cc in D.items():\n            assert (dd in special_dims) or (len(set(cc)) == len(cc))\n\n\n@given(hxr.xr_dim_lists(), dtypes(), data())\ndef test_fixed_coords_dataarrays(dims, dtype, data):\n    elements = None\n\n    coords = data.draw(hxr.xr_coords_dicts(dims))\n\n    S = hxr.fixed_coords_dataarrays(dims, coords, dtype, elements)\n\n    da = data.draw(S)\n\n    assert da.dims == tuple(dims)\n    assert da.dtype == np.dtype(dtype)\n    for dd in dims:\n        assert da.coords[dd].values.tolist() == coords[dd]\n\n\n@given(hxr.xr_dim_lists(), dtypes(), sizes(), data())\ndef test_fixed_dataarrays(dims, dtype, sizes, data):\n    elements = None\n    coords_elements = None\n    min_side, max_side = sizes\n\n    # special dims just filled with dim name on coords as test case\n    special_dims = data.draw(hxr.subset_lists(dims))\n    coords_st = {dd: lists(just(dd), min_side, max_side) for dd in special_dims}\n\n    S = hxr.fixed_dataarrays(dims, dtype, elements, coords_elements, min_side, max_side, coords_st)\n\n    da = data.draw(S)\n\n    assert da.dims == tuple(dims)\n    assert all(ss >= min_side for ss in da.sizes.values())\n    assert (max_side is None) or all(ss <= max_side for ss in da.sizes.values())\n    assert da.dtype == np.dtype(dtype)\n    assert all(all(ss == dd for ss in da.coords[dd].values.tolist()) for dd in special_dims)\n    for dd in dims:\n        L = da.coords[dd].values.tolist()\n        assert (dd in special_dims) or all(isinstance(ss, int) for ss in L)\n        assert (dd in special_dims) or (len(set(L)) == len(L))\n\n\n@given(hxr.xr_dim_lists(), dtypes(), sizes(allow_none=False), data())\ndef test_simple_dataarrays(dims, dtype, sizes, data):\n    elements = None\n    min_side, max_side = sizes\n\n    S = hxr.simple_dataarrays(dims, dtype, elements, min_side, max_side)\n\n    da = data.draw(S)\n\n    assert da.dims == tuple(dims)\n    assert all(ss >= min_side for ss in da.sizes.values())\n    assert (max_side is None) or all(ss <= max_side for ss in da.sizes.values())\n    assert da.dtype == np.dtype(dtype)\n    for dd in dims:\n        L = da.coords[dd].values.tolist()\n        assert all(isinstance(ss, int) for ss in L)\n        assert L == list(range(len(L)))\n\n\n@given(dtypes(), sizes(allow_none=False), sizes(allow_none=False), data())\ndef test_dataarrays(dtype, size_dims, size_sides, data):\n    elements = None\n    coords_elements = None\n\n    min_dims, max_dims = size_dims\n    min_side, max_side = size_sides\n\n    S = hxr.dataarrays(dtype, elements, coords_elements, min_side, max_side, min_dims, max_dims)\n\n    da = data.draw(S)\n\n    assert len(da.dims) >= min_dims\n    assert len(da.dims) <= max_dims\n    assert all(ss >= min_side for ss in da.sizes.values())\n    assert (max_side is None) or all(ss <= max_side for ss in da.sizes.values())\n    assert da.dtype == np.dtype(dtype)\n    for dd in da.dims:\n        L = da.coords[dd].values.tolist()\n        assert all(isinstance(ss, int) for ss in L)\n        assert len(set(L)) == len(L)\n\n\n@given(hxr.vars_to_dims_dicts(), data())\ndef test_fixed_coords_datasets(vars_to_dims, data):\n    elements = None\n\n    all_dims = sorted(set(sum((list(dd) for dd in vars_to_dims.values()), [])))\n    coords = data.draw(hxr.xr_coords_dicts(all_dims))\n\n    dtype_d = data.draw(fixed_dictionaries({vv: dtypes() for vv in vars_to_dims}))\n\n    S = hxr.fixed_coords_datasets(vars_to_dims, coords, dtype_d, elements)\n\n    ds = data.draw(S)\n\n    assert list(ds) == list(vars_to_dims.keys())\n    assert all(ds[vv].dims == tuple(vars_to_dims[vv]) for vv in vars_to_dims)\n    assert all(ds[vv].dtype == np.dtype(dtype_d[vv]) for vv in vars_to_dims)\n    for dd in all_dims:\n        L = ds.coords[dd].values.tolist()\n        assert L == coords[dd]\n\n\n@given(hxr.vars_to_dims_dicts(), data())\ndef test_fixed_coords_datasets_no_dtype(vars_to_dims, data):\n    elements = None\n\n    all_dims = sorted(set(sum((list(dd) for dd in vars_to_dims.values()), [])))\n    coords = data.draw(hxr.xr_coords_dicts(all_dims))\n\n    S = hxr.fixed_coords_datasets(vars_to_dims, coords, dtype=None, elements=elements)\n\n    ds = data.draw(S)\n\n    assert list(ds) == list(vars_to_dims.keys())\n    assert all(ds[vv].dims == tuple(vars_to_dims[vv]) for vv in vars_to_dims)\n    assert all(ds[vv].dtype == np.dtype(hxr.DEFAULT_DTYPE) for vv in vars_to_dims)\n    for dd in all_dims:\n        L = ds.coords[dd].values.tolist()\n        assert L == coords[dd]\n\n\n@given(hxr.vars_to_dims_dicts(), sizes(), data())\ndef test_fixed_datasets(vars_to_dims, sizes, data):\n    elements = None\n    coords_elements = None\n    min_side, max_side = sizes\n\n    # special dims just filled with dim name on coords as test case\n    all_dims = sorted(set(sum((list(dd) for dd in vars_to_dims.values()), [])))\n    special_dims = data.draw(hxr.subset_lists(all_dims))\n    coords_st = {dd: lists(just(dd), min_side, max_side) for dd in special_dims}\n\n    dtype_d = data.draw(fixed_dictionaries({vv: dtypes() for vv in vars_to_dims}))\n\n    S = hxr.fixed_datasets(vars_to_dims, dtype_d, elements, coords_elements, min_side, max_side, coords_st)\n\n    ds = data.draw(S)\n\n    assert list(ds) == list(vars_to_dims.keys())\n    assert all(ds[vv].dims == tuple(vars_to_dims[vv]) for vv in vars_to_dims)\n    assert all(ds[vv].dtype == np.dtype(dtype_d[vv]) for vv in vars_to_dims)\n    assert all(all(ss == dd for ss in ds.coords[dd].values.tolist()) for dd in special_dims)\n    for dd in all_dims:\n        L = ds.coords[dd].values.tolist()\n        assert len(L) >= min_side\n        assert (max_side is None) or (len(L) <= max_side)\n        assert (dd in special_dims) or all(isinstance(ss, int) for ss in L)\n        assert (dd in special_dims) or len(set(L)) == len(L)\n\n\n@given(hxr.vars_to_dims_dicts(), sizes(allow_none=False), data())\ndef test_simple_datasets(vars_to_dims, sizes, data):\n    elements = None\n    min_side, max_side = sizes\n\n    dtype_d = data.draw(fixed_dictionaries({vv: dtypes() for vv in vars_to_dims}))\n\n    S = hxr.simple_datasets(vars_to_dims, dtype_d, elements, min_side, max_side)\n\n    ds = data.draw(S)\n\n    all_dims = sorted(set(sum((list(dd) for dd in vars_to_dims.values()), [])))\n\n    assert list(ds) == list(vars_to_dims.keys())\n    assert all(ds[vv].dims == tuple(vars_to_dims[vv]) for vv in vars_to_dims)\n    assert all(ds[vv].dtype == np.dtype(dtype_d[vv]) for vv in vars_to_dims)\n    for dd in all_dims:\n        L = ds.coords[dd].values.tolist()\n        assert len(L) >= min_side\n        assert (max_side is None) or (len(L) <= max_side)\n        assert all(isinstance(ss, int) for ss in L)\n        assert L == list(range(len(L)))\n\n\n@given(dtypes(), sizes(allow_none=False), sizes(allow_none=False), sizes(allow_none=False), data())\ndef test_datasets(dtype, size_sides, size_vars, size_dims, data):\n    elements = None\n    coords_elements = None\n    min_dims, max_dims = size_dims\n    min_side, max_side = size_sides\n    min_vars, max_vars = size_vars\n\n    S = hxr.datasets(dtype, elements, coords_elements, min_side, max_side, min_vars, max_vars, min_dims, max_dims)\n\n    ds = data.draw(S)\n\n    all_dims = sorted(set(sum((list(ds[vv].dims) for vv in ds), [])))\n\n    n = len(list(ds))\n    assert n >= min_vars\n    assert (max_vars is None) or (n <= max_vars)\n    assert all(len(ds[vv].dims) >= min_dims for vv in ds)\n    assert (max_dims is None) or all(len(ds[vv].dims) <= max_dims for vv in ds)\n    assert all(ds[vv].dtype == np.dtype(dtype) for vv in ds)\n    for dd in all_dims:\n        L = ds.coords[dd].values.tolist()\n        assert len(L) >= min_side\n        assert (max_side is None) or (len(L) <= max_side)\n        assert all(isinstance(ss, int) for ss in L)\n        assert len(set(L)) == len(L)\n'"
