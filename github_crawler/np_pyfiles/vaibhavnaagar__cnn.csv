file_path,api_count,code
lenet_numpy/conv.py,31,"b'import numpy as np\nimport sys\nimport scipy.signal\n\nclass CONV_LAYER:\n    """"""docstring forCONV_LAYER.""""""\n    def __init__(self, layer_size, kernel_size, fan, **params):\n        """"""\n        Input:\n            layer_size: tuple consisting (depth, height, width)\n            kernel_size: tuple consisting (number_of_kernels, inp_depth, inp_height, inp_width)\n            fan: tuple of number of nodes in previous layer and this layer\n            params: directory consists of pad_len and stride,\n                    filename (to load weights from file)\n        """"""\n        self.depth, self.height, self.width = layer_size\n\n        fname = params.get(""filename"", None)\n        if fname:\n            try:\n                arr_files = np.load(fname)\n                self.kernel = arr_files[\'arr_0\']\n                self.bias = arr_files[\'arr_1\']\n                assert np.all(self.kernel.shape == kernel_size) and np.all(self.bias.shape[0] == kernel_size[0])\n            except:\n                raise\n        else:\n            f = np.sqrt(6)/np.sqrt(fan[0] + fan[1])\n            epsilon = 1e-6\n            self.kernel = np.random.uniform(-f, f + epsilon, kernel_size)\n            self.bias = np.random.uniform(-f, f + epsilon, kernel_size[0])\n\n        self.pad = params.get(\'pad\', 0)                  # Default 0\n        self.stride = params.get(\'stride\', 1)            # Default 1\n        if self.pad < 0:\n            print(""Invalid padding: pad cannot be negative"")\n            sys.exit()\n        self.gradient_history = np.zeros(kernel_size)\n        self.bias_history = np.zeros(kernel_size[0])\n        self.m_kernel = np.zeros(kernel_size)\n        self.m_bias = np.zeros(kernel_size[0])\n        self.v_kernel = np.zeros(kernel_size)\n        self.v_bias = np.zeros(kernel_size[0])\n        self.timestamp = 0\n        pass\n\n    def forward(self, X):\n        """"""\n        Computes the forward pass of Conv Layer.\n        Input:\n            X: Input data of shape (N, D, H, W)\n        Variables:\n            kernel: Weights of shape (K, K_D, K_H, K_W)\n            bias: Bias of each filter. (K)\n        where, N = batch_size or number of images\n               H, W = Height and Width of input layer\n               D = Depth of input layer\n               K = Number of filters/kernels or depth of this conv layer\n               K_H, K_W = kernel height and Width\n\n        Output:\n        """"""\n        pad_len = self.pad\n        stride = self.stride\n\n        N, D, H, W = X.shape\n        K, K_D, K_H, K_W = self.kernel.shape\n\n        #assert self.depth == K\n        #assert D == K_D\n        #assert K == self.bias.shape[0]\n\n        conv_h = (H - K_H + 2*pad_len) // stride + 1\n        conv_w = (W - K_W + 2*pad_len) // stride + 1\n\n        #assert self.height == conv_h\n        #assert self.width == conv_w\n        #assert (H - K_H + 2*pad_len)%stride == 0\n        #assert (W - K_W + 2*pad_len)%stride == 0\n\n        # feature map of a batch\n        self.feature_map = np.zeros([N, K, conv_h, conv_w])\n\n        X_padded = np.pad(X, ((0,0), (0,0), (pad_len, pad_len), (pad_len, pad_len)), \'constant\')\n\n        if stride == 1:\n            # scipy.signal.convolve2d doesn\'t have any attribute for stride, so it works for only stride = 1\n            # Rotate kernel by 180\n            kernel_180 = np.rot90(self.kernel, 2, (2,3))\n            for img in range(N):\n                for conv_depth in range(K):\n                    for inp_depth in range(D):\n                        self.feature_map[img, conv_depth] += scipy.signal.convolve2d(X_padded[img, inp_depth], kernel_180[conv_depth, inp_depth], mode=\'valid\')\n                    self.feature_map[img, conv_depth] += self.bias[conv_depth]\n        else:\n            # Manual convolution when stride > 1, but above method is faster.\n            for img in range(N):\n                for conv_depth in range(K):\n                    for h in range(0, H + 2*pad_len - K_H + 1, stride):\n                        for w in range(0, W + 2*pad_len - K_W + 1, stride):\n                            self.feature_map[img, conv_depth, h//stride, w//stride] = \\\n                                np.sum(X_padded[img, :, h:h+K_H, w:w+K_W] * self.kernel[conv_depth,:,:,:]) + self.bias[conv_depth]\n\n        self.cache = X\n        return self.feature_map, np.sum(np.square(self.kernel))\n\n\n    def backward(self, delta):\n        """"""\n        Computes the backward pass of Conv layer.\n        Input:\n            delta: derivatives from next layer of shape (N, K, conv_h, conv_w)\n        """"""\n\n        X = self.cache\n        pad_len = self.pad\n        stride = self.stride\n\n        N, D, H, W = X.shape\n        K, K_D, K_H, K_W = self.kernel.shape\n\n        #assert self.depth == K\n        #assert D == K_D\n        #assert K == self.bias.shape[0]\n\n        conv_h = (H - K_H + 2*pad_len) // stride + 1\n        conv_w = (W - K_W + 2*pad_len) // stride + 1\n\n        #assert self.height == conv_h\n        #assert self.width == conv_w\n\n        # Rotate Kernel by 180 degrees      [No need]\n        #kernel_180 = np.rot90(kernel, 2, (2,3))\n        X_padded = np.pad(X, ((0,0), (0,0), (pad_len, pad_len), (pad_len, pad_len)), \'constant\')\n        delta_X_padded = np.zeros(X_padded.shape)\n        self.delta_K = np.zeros(self.kernel.shape)\n        self.delta_b = np.zeros(self.bias.shape)\n\n        # Delta X\n        for img in range(N):\n            for conv_depth in range(K):\n                for h in range(0, H + 2*pad_len - K_H + 1, stride):\n                    for w in range(0, W + 2*pad_len - K_W + 1, stride):\n                        delta_X_padded[img, :, h:h+K_H, w:w+K_W] += delta[img, conv_depth, h//stride, w//stride] * self.kernel[conv_depth]\n\n        if pad_len > 0:\n            self.delta_X = delta_X_padded[:, :, pad_len:-pad_len, pad_len:-pad_len]\n        else:\n            self.delta_X = delta_X_padded[:]\n\n        #assert self.delta_X.shape == X.shape\n\n        # Delta kernel\n        for img in range(N):\n            for kernel_num in range(K):\n                for h in range(conv_h):\n                    for w in range(conv_w):\n                        self.delta_K[kernel_num,:,:,:] += delta[img, kernel_num, h, w] * X_padded[img, :, h*stride:h*stride+K_H, w*stride:w*stride+K_W]\n\n        # Delta Bias\n        self.delta_b = np.sum(delta, (0,2,3))\n        return self.delta_X\n\n    def update_kernel(self, **params):\n        """"""\n        Update weights and biases stored in this layer.\n        Input:\n            params: Optional parameters- method, alpha, zeta\n        """"""\n        method = params.get(""method"", """")\n        alpha = params.get(""alpha"", 0.001)\n        zeta   = params.get(""zeta"", 0.01)\n        batch_size = params.get(""batch"", 1)\n        beta1        = params.get(""beta1"", 0.9)\n        beta2        = params.get(""beta2"", 0.999)\n        fudge_factor = 1e-8                         # smoothing term to avoid division by zero\n\n        if method == ""adagrad"":\n            self.gradient_history += np.square(self.delta_K + (zeta*self.kernel/batch_size))\n            self.bias_history += np.square(self.delta_b)\n            self.kernel -= alpha*(self.delta_K + (zeta*self.kernel/batch_size))/(np.sqrt(self.gradient_history) + fudge_factor)\n            self.bias    -= alpha*self.delta_b/(np.sqrt(self.bias_history) + fudge_factor)\n        elif method == ""adam"":\n            self.timestamp += 1\n            alpha = alpha * np.sqrt(1 - np.power(beta2, self.timestamp)) / (1 - np.power(beta1, self.timestamp))\n            self.m_kernel = beta1 * self.m_kernel + (1 - beta1) * (self.delta_K + (zeta*self.kernel/batch_size))\n            self.m_bias = beta1 * self.m_bias + (1 - beta1) * self.delta_b\n            self.v_kernel = beta2 * self.v_kernel + (1 - beta2) * np.square((self.delta_K + (zeta*self.kernel/batch_size)))\n            self.v_bias = beta2 * self.v_bias + (1 - beta2) * np.square(self.delta_b)\n\n            self.kernel -= np.divide(alpha * self.m_kernel, (np.sqrt(self.v_kernel) + fudge_factor))\n            self.bias -= np.divide(alpha * self.m_bias, (np.sqrt(self.v_bias) + fudge_factor))\n        else:\n            self.kernel -= alpha*(self.delta_K + zeta*self.kernel/batch_size)\n            self.bias   -= alpha*self.delta_b\n        pass\n'"
lenet_numpy/fc.py,26,"b'import numpy as np\nimport sys\nclass FC_LAYER:\n    """"""docstring forRELU_LAYER.""""""\n    def __init__(self, layer_size, kernel_size, **params):\n        """"""\n        Input:\n            layer_size: number of neurons/nodes in fc layer\n            kernel: kernel of shape (nodes_l1 , nodes_l2)\n            fan: tuple of number of nodes in previous layer and this layer\n        """"""\n        self.nodes = layer_size\n\n        fname = params.get(""filename"", None)\n        if fname:\n            try:\n                arr_files = np.load(fname)\n                self.kernel = arr_files[\'arr_0\']\n                self.bias = arr_files[\'arr_1\']\n                assert np.all(self.kernel.shape == kernel_size) and np.all(self.bias.shape[0] == kernel_size[1])\n            except:\n                 raise\n        else:\n            f = np.sqrt(6)/np.sqrt(kernel_size[0] + kernel_size[1])\n            epsilon = 1e-6\n            self.kernel = np.random.uniform(-f, f + epsilon, kernel_size)\n            self.bias = np.random.uniform(-f, f + epsilon, kernel_size[1])\n        self.gradient_history = np.zeros(kernel_size)\n        self.bias_history = np.zeros(kernel_size[1])\n        self.m_kernel = np.zeros(kernel_size)\n        self.m_bias = np.zeros(kernel_size[1])\n        self.v_kernel = np.zeros(kernel_size)\n        self.v_bias = np.zeros(kernel_size[1])\n        self.timestamp = 0\n        pass\n\n    def forward(self, X):\n        """"""\n        Computes the forward pass of Sigmoid Layer.\n        Input:\n            X: Input data of shape (N, nodes_l1)\n        Variables:\n            kernel: Weight array of shape (nodes_l1, nodes_l2)\n            bias: Biases of shape (nodes_l2)\n        where,\n            nodes_l1: number of nodes in previous layer\n            nodes_l2: number of nodes in this fc layer\n        """"""\n        kernel, bias = self.kernel, self.bias\n        self.cache = (X, kernel, bias)\n        self.activations = np.dot(X, kernel) + bias\n        #assert self.activations.shape == (X.shape[0], bias.shape[0])\n        return self.activations, np.sum(np.square(self.kernel))\n\n    def backward(self, delta):\n        """"""\n        Computes the backward pass of Sigmoid Layer.\n        Input:\n            delta: Shape of delta values (N, nodes_l2)\n        """"""\n        X, kernel, bias = self.cache\n        self.delta_X = np.dot(delta, kernel.T)\n        self.delta_K = np.dot(X.T, delta)\n        #print(self.delta_K[0][range(10)], self.delta_K.shape)\n        #print(X.T[0][range(10)], X.T.shape)\n        #print(delta[0][range(10)], delta.shape)\n        self.delta_b = np.sum(delta, axis=0)\n        return self.delta_X\n\n    def update_kernel(self, **params):\n        """"""\n        Update kernel and biases stored in this layer.\n        Input:\n            params: Optional parameters- method, alpha, zeta\n        """"""\n        method       = params.get(""method"", """")\n        alpha        = params.get(""alpha"", 0.001)\n        mu           = params.get(""mu"", 0.9)\n        zeta         = params.get(""zeta"", 0.01)\n        beta1        = params.get(""beta1"", 0.9)\n        beta2        = params.get(""beta2"", 0.999)\n        batch_size   = params.get(""batch"", 1)\n        fudge_factor = 1e-8                         # smoothing term to avoid division by zero\n\n        if method == ""adagrad"":\n            self.gradient_history += np.square(self.delta_K + (zeta*self.kernel/batch_size))\n            self.bias_history += np.square(self.delta_b)\n            #print(""\\n\\n\\n\\n\\n\\n"")\n            #print(self.gradient_history[0])\n            #sys.exit()\n            #print(alpha*(self.delta_K + (zeta*self.kernel/batch_size))/(np.sqrt(self.gradient_history) + fudge_factor))\n            self.kernel -= np.divide(alpha*(self.delta_K + (zeta*self.kernel/batch_size)), (np.sqrt(self.gradient_history) + fudge_factor))\n            self.bias -= np.divide(alpha*self.delta_b, (np.sqrt(self.bias_history) + fudge_factor))\n        elif method == ""gd_momentum"":\n            new_delta_K = alpha*(self.delta_K + (zeta*self.kernel/batch_size)) + mu*self.gradient_history\n            new_delta_b = alpha*self.delta_b + mu*self.bias_history\n            self.kernel -= new_delta_K\n            self.bias -= new_delta_b\n            self.gradient_history = self.delta_K + (zeta*self.kernel/batch_size)\n            self.bias_history = self.delta_b\n        elif method == ""adam"":\n            self.timestamp += 1\n            alpha = alpha * np.sqrt(1 - np.power(beta2, self.timestamp)) / (1 - np.power(beta1, self.timestamp))\n            self.m_kernel = beta1 * self.m_kernel + (1 - beta1) * (self.delta_K + (zeta*self.kernel/batch_size))\n            self.m_bias = beta1 * self.m_bias + (1 - beta1) * self.delta_b\n            self.v_kernel = beta2 * self.v_kernel + (1 - beta2) * np.square((self.delta_K + (zeta*self.kernel/batch_size)))\n            self.v_bias = beta2 * self.v_bias + (1 - beta2) * np.square(self.delta_b)\n\n            self.kernel -= np.divide(alpha * self.m_kernel, (np.sqrt(self.v_kernel) + fudge_factor))\n            self.bias -= np.divide(alpha * self.m_bias, (np.sqrt(self.v_bias) + fudge_factor))\n        else:\n            self.kernel -= alpha*(self.delta_K + zeta*self.kernel/batch_size)\n            self.bias    -= alpha*self.delta_b\n        pass\n'"
lenet_numpy/lenet5.py,27,"b'from conv import *\nfrom relu import *\nfrom sigmoid import *\nfrom fc import *\nfrom maxpool import *\nfrom softmax import *\nfrom tsne_img_plot import *\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nimport timeit\nfrom itertools import chain\nfrom scipy import misc\n\nclass LENET5:\n    """"""docstring forLENET5.""""""\n    def __init__(self, t_input, t_output, v_input, v_output):\n        """"""\n        Creates Lenet-5 architecture\n        Input:\n            t_input: True Training input of shape (N, Depth, Height, Width)\n            t_output: True Training output of shape (N, Class_Number)\n        """"""\n        b_dir = ""16/""\n        # Conv Layer-1\n        conv1 = CONV_LAYER((6, 28, 28), (6, 1, 5, 5), (784, 4704), pad=2, stride=1, filename=b_dir+""conv0.npz"")\n        relu1 = RELU_LAYER()\n        # Sub-sampling-1\n        pool2 = MAX_POOL_LAYER(stride=2)\n        # Conv Layer-2\n        conv3 = CONV_LAYER((16, 10, 10), (16, 6, 5, 5), (1176, 1600), pad=0, stride=1, filename=b_dir+""conv3.npz"")\n        relu3 = RELU_LAYER()\n        # Sub-sampling-2\n        pool4 = MAX_POOL_LAYER(stride=2)\n        # Fully Connected-1\n        fc5 = FC_LAYER(120, (400, 120), filename=b_dir+""fc6.npz"")\n        sigmoid5 = SIGMOID_LAYER()\n        # Fully Connected-2\n        fc6 = FC_LAYER(84, (120, 84), filename=b_dir+""fc8.npz"")\n        sigmoid6 = SIGMOID_LAYER()\n        # Fully Connected-3\n        output = FC_LAYER(10, (84, 10), filename=b_dir+""fc10.npz"")\n        softmax = SOFTMAX_LAYER()\n        self.layers = [conv1, relu1, pool2, conv3, relu3, pool4, fc5, sigmoid5, fc6, sigmoid6, output, softmax]\n\n\n        """"""\n        #Check gradient on smaller network. (Time is precious :)\n\n        fc1 = FC_LAYER(5, (3, 5))\n        sigmoid1 = SIGMOID_LAYER()\n        fc2 = FC_LAYER(3, (5, 3))\n        sigmoid2 = SOFTMAX_LAYER()\n\n        temp = np.sin(np.arange(1,21)).reshape(5,4, order=\'F\')/10\n        fc1.kernel = temp[:, 1:4].T\n        fc1.bias = temp[:, 0]\n        print(""FC1:::::::::::::::::"")\n        print(fc1.kernel)\n        print(fc1.bias)\n\n        temp = np.sin(np.arange(1,19)).reshape(3,6, order=\'F\')/10\n        fc2.kernel = temp[:, 1:6].T\n        fc2.bias = temp[:, 0]\n        print(""FC2:::::::::::::::::"")\n        print(fc2.kernel)\n        print(fc2.bias)\n        self.layers = [fc1, sigmoid1, fc2, sigmoid2]\n        """"""\n\n        """"""\n        # Only FC layers\n        fc1 = FC_LAYER(120, (784, 120))\n        sigmoid1 = RELU_LAYER()\n        # Fully Connected-2\n        fc2 = FC_LAYER(60, (120, 60))\n        sigmoid2 = RELU_LAYER()\n        # Fully Connected-3\n        output = FC_LAYER(10, (60, 10))\n        softmax = SOFTMAX_LAYER()\n\n        self.layers = [fc1, sigmoid1, fc2, sigmoid2, output, softmax]\n        """"""\n\n        self.X = t_input\n        self.Y = t_output\n        self.Xv = v_input\n        self.Yv = v_output\n\n    @staticmethod\n    def one_image_time(X, layers):\n        """"""\n        Computes time of conv and fc layers\n        Input:\n            X: Input\n            layers: List of layers.\n        Output:\n            inp: Final output\n        """"""\n        inp = X\n        conv_time = 0.0\n        fc_time = 0.0\n        layer_time = []\n\n        for layer in layers:\n            start = timeit.default_timer()\n            if isinstance(layer, FC_LAYER) and len(inp.shape) == 4:\n                inp, ws = layer.forward(inp.reshape(inp.shape[0], inp.shape[1]*inp.shape[2]*inp.shape[3]))\n            else:\n                inp, ws = layer.forward(inp)\n            stop = timeit.default_timer()\n            layer_time += [stop-start]\n            if isinstance(layer, (FC_LAYER, SIGMOID_LAYER, SOFTMAX_LAYER)):\n                fc_time += stop - start\n            if isinstance(layer, (CONV_LAYER, RELU_LAYER)):\n                conv_time += stop - start\n        return conv_time, fc_time, layer_time\n\n    @staticmethod\n    def visualize_feature_maps(X, layers, digit, batch_string):\n        """"""\n        Create and save image of feature maps of conv and fc layers\n        Input:\n            X: Input an image of shape (1, 1, 28, 28)\n            layers: List of layers.\n        """"""\n        inp = X\n        size = (224,224)\n        misc.imsave(""feature_maps/"" + digit + ""/"" + ""input_"" + digit + batch_string + "".jpeg"", misc.imresize(X[0][0], size))\n        conv_i = 1\n        max_i = 1\n\n        for layer in layers:\n            if isinstance(layer, FC_LAYER) and len(inp.shape) == 4:\n                inp, ws = layer.forward(inp.reshape(inp.shape[0], inp.shape[1]*inp.shape[2]*inp.shape[3]))\n            else:\n                inp, ws = layer.forward(inp)\n\n            if isinstance(layer, RELU_LAYER):\n                for channel in range(inp.shape[1]):\n                    misc.imsave(""feature_maps/"" + digit + ""/"" + ""conv"" + str(conv_i) + ""_c"" + str(channel+1)+ batch_string + "".jpeg"", misc.imresize(inp[0][channel], size))\n                conv_i += 1\n\n            if isinstance(layer, MAX_POOL_LAYER):\n                for channel in range(inp.shape[1]):\n                    misc.imsave(""feature_maps/"" + digit + ""/"" + ""maxpool"" + str(max_i) + ""_c"" + str(channel+1)+ batch_string + "".jpeg"", misc.imresize(inp[0][channel], size))\n                max_i += 1\n\n    @staticmethod\n    def feedForward(X, layers):\n        """"""\n        Computes final output of neural network by passing\n        output of one layer to another.\n        Input:\n            X: Input\n            layers: List of layers.\n        Output:\n            inp: Final output\n        """"""\n        inp = X\n        wsum = 0\n        for layer in layers:\n            if isinstance(layer, FC_LAYER) and len(inp.shape) == 4:\n                inp, ws = layer.forward(inp.reshape(inp.shape[0], inp.shape[1]*inp.shape[2]*inp.shape[3]))\n            else:\n                inp, ws = layer.forward(inp)\n            wsum += ws\n        return inp, wsum\n\n    @staticmethod\n    def backpropagation(Y, layers):\n        """"""\n        Computes final output of neural network by passing\n        output of one layer to another.\n        Input:\n            Y: True output\n            layers: List of layers.\n        Output:\n            grad: gradient\n        """"""\n        delta = Y\n        for layer in layers[::-1]:\n            delta = layer.backward(delta)\n\n    @staticmethod\n    def update_parameters(layers, batch_size, a, z, m):\n        """"""\n        Update weight parameters of each layer\n        """"""\n        for layer in layers:\n            if isinstance(layer, (CONV_LAYER, FC_LAYER)):\n                layer.update_kernel(batch=batch_size, alpha=a, zeta=z, method=m)\n\n    @staticmethod\n    def loss_function(pred, t, **params):\n        """"""\n        Computes loss using cross-entropy method.\n        Input:\n            pred: Predicted output of network of shape (N, C)\n            t: true output of shape (N, C)\n            w_sum: sum of squares of all weight parameters for L2 regularization\n        where,\n            N: batch size\n            C: Number of classes in the final layer\n        Output:\n            Loss or cost\n        """"""\n        w_sum = params.get(""wsum"", 0)\n        #print(""w_sum: "", w_sum)\n        z = params.get(""zeta"", 0)\n        assert t.shape == pred.shape\n        #print(""Shape: "", t.shape, z)\n        epsilon = 1e-10\n        return ((-t * np.log(pred + epsilon)).sum() + (z/2)*w_sum) / pred.shape[0]\n\n    @staticmethod\n    def plots(x, y, z, steps):\n        try:\n            plt.figure(1)\n            plt.plot(x, \'-bo\', label=""Loss"")\n            plt.xlabel(\'Number of iterations\', fontsize=18)\n            plt.ylabel(\'Loss\', fontsize=18)\n            plt.title(\'Training Error rate vs Number of iterations\')\n            plt.savefig(""Loss_function_vs_iter.jpeg"")\n        except:\n            pass\n\n        try:\n            plt.figure(2)\n            plt.plot(steps, y, \'-bo\', label=""Training Loss"")\n            plt.plot(steps, z, \'-ro\', label=""Validation Loss"")\n            plt.xlabel(\'Number of iterations\', fontsize=18)\n            plt.ylabel(\'Loss Value\', fontsize=18)\n            plt.title(\'Training and Validation error rates vs number of iterations\')\n            plt.legend(loc=\'upper right\')\n            plt.savefig(""error_rates.jpeg"")\n        except:\n            pass\n        pass\n\n    def lenet_train(self, **params):\n        """"""\n        Train the Lenet-5.\n        Input:\n            params: parameters including ""batch"", ""alpha""(learning rate),\n                    ""zeta""(regularization parameter), ""method"" (gradient method),\n                    ""epochs"", ...\n        """"""\n        batch  = params.get(""batch"", 50)             # Default 50\n        alpha  = params.get(""alpha"", 0.01)            # Default 0.1\n        zeta   = params.get(""zeta"", 0)               # Default 0 (No regularization)\n        method = params.get(""method"", ""adam"")            # Default\n        epochs = params.get(""epochs"", 4)             # Default 4\n        print(""Training on params: batch="", batch, "" learning rate="", alpha, "" L2 regularization="", zeta, "" method="", method, "" epochs="", epochs)\n        self.loss_history = []\n        self.gradient_history = []\n        self.valid_loss_history = []\n        self.step_loss = []\n        print(method)\n        X_train = self.X\n        Y_train = self.Y\n        assert X_train.shape[0] == Y_train.shape[0]\n        num_batches = int(np.ceil(X_train.shape[0] / batch))\n        step = 0;\n        steps = []\n        X_batches = zip(np.array_split(X_train, num_batches, axis=0), np.array_split(Y_train, num_batches, axis=0))\n\n        for ep in range(epochs):\n            print(""Epoch: "", ep, ""==============================================="")\n            for x, y in X_batches:\n                predictions, weight_sum = LENET5.feedForward(x, self.layers)\n                loss = LENET5.loss_function(predictions, y, wsum=weight_sum, zeta=zeta)\n                self.loss_history += [loss]\n                LENET5.backpropagation(y, self.layers)          #check this gradient\n                LENET5.update_parameters(self.layers, x.shape[0], alpha, zeta, method)\n                print(""Step: "", step, "":: Loss: "", loss, ""weight_sum: "", weight_sum)\n                if step % 100 == 0:\n                    pred, w = LENET5.feedForward(self.Xv, self.layers)\n                    v_loss = LENET5.loss_function(pred, self.Yv, wsum=w, zeta=zeta)\n                    print(""Validation error: "", v_loss)\n                    steps += [step]\n                    self.valid_loss_history += [v_loss]\n                    self.step_loss += [loss]\n                step += 1\n\n            XY = list(zip(X_train, Y_train))\n            np.random.shuffle(XY)\n            new_X, new_Y = zip(*XY)\n            assert len(new_X) == X_train.shape[0] and len(new_Y) == len(new_X)\n            X_batches = zip(np.array_split(new_X, num_batches, axis=0), np.array_split(new_Y, num_batches, axis=0))\n        np.savez(""step_loss_history"", self.step_loss, self.valid_loss_history)\n        np.savez(""loss_history"", self.loss_history)\n        LENET5.plots(self.loss_history, self.step_loss, self.valid_loss_history, steps)\n        pass\n\n    def lenet_predictions(self, X, Y):\n        """"""\n        Predicts the ouput and computes the accuracy on the dataset provided.\n        Input:\n            X: Input of shape (Num, depth, height, width)\n            Y: True output of shape (Num, Classes)\n        """"""\n        start = timeit.default_timer()\n        predictions, weight_sum = LENET5.feedForward(X, self.layers)\n        stop = timeit.default_timer()\n\n        loss = LENET5.loss_function(predictions, Y, wsum=weight_sum, zeta=0.99)\n        y_true = np.argmax(Y, axis=1)\n        y_pred = np.argmax(predictions, axis=1)\n        print(""Dataset accuracy: "", accuracy_score(y_true, y_pred)*100)\n        print(""FeedForward time:"", stop - start)\n        pass\n\n    def save_parameters(self):\n        """"""\n        Saves the weights and biases of Conv and Fc layers in a file.\n        """"""\n        for layer in self.layers:\n            if isinstance(layer, CONV_LAYER):\n                np.savez(""conv"" + str(self.layers.index(layer)), layer.kernel, layer.bias)\n            elif isinstance(layer, FC_LAYER):\n                np.savez(""fc"" + str(self.layers.index(layer)), layer.kernel, layer.bias)\n        pass\n\n    def check_gradient(self):\n        """"""\n        Computes the numerical gradient and compares with Analytical gradient\n        """"""\n        sample = 10\n        epsilon = 1e-4\n        X_sample = self.X[range(sample)]\n        Y_sample = self.Y[range(sample)]\n        predictions, weight_sum = LENET5.feedForward(X_sample, self.layers)\n        LENET5.backpropagation(Y_sample, self.layers)\n\n        abs_diff = 0\n        abs_sum = 0\n\n        for layer in self.layers:\n            if not isinstance(layer, (CONV_LAYER, FC_LAYER)):\n                continue\n            i = 0\n            print(""\\n\\n\\n\\n\\n"")\n            print(type(layer))\n            del_k = layer.delta_K + (0.99*layer.kernel/sample)\n            kb = chain(np.nditer(layer.kernel, op_flags=[\'readwrite\']), np.nditer(layer.bias, op_flags=[\'readwrite\']))\n            del_kb = chain(np.nditer(del_k, op_flags=[\'readonly\']), np.nditer(layer.delta_b, op_flags=[\'readonly\']))\n\n            for w, dw in zip(kb, del_kb):\n                w += epsilon\n                pred, w_sum = LENET5.feedForward(X_sample, self.layers)\n                loss_plus = LENET5.loss_function(pred, Y_sample, wsum=w_sum, zeta=0.99)\n\n                w -= 2*epsilon\n                pred, w_sum = LENET5.feedForward(X_sample, self.layers)\n                loss_minus = LENET5.loss_function(pred, Y_sample, wsum=w_sum, zeta=0.99)\n\n                w += epsilon\n                numerical_gradient = (loss_plus - loss_minus)/(2*epsilon)\n\n                abs_diff += np.square(numerical_gradient - dw)\n                abs_sum  += np.square(numerical_gradient + dw)\n                print(i, ""Numerical Gradient: "", numerical_gradient, ""Analytical Gradient: "", dw)\n                if not np.isclose(numerical_gradient, dw, atol=1e-4):\n                    print(""Not so close"")\n                if i >= 10:\n                    break\n                i += 1\n\n        print(""Relative difference: "", np.sqrt(abs_diff)/np.sqrt(abs_sum))\n        pass\n\n    def tsne_plot(self, X, y, name):\n        activations, dummy = LENET5.feedForward(X, self.layers[0:10])\n        print(activations.shape)\n        if activations.shape != (10000, 84):\n            import sys\n            sys.exit()\n        plot_tsne(activations, y, name)\n'"
lenet_numpy/main.py,13,"b'from mnist import MNIST\nimport os, sys\nimport numpy as np\nfrom lenet5 import *\nimport timeit\n\nclass LoadMNISTdata:\n    """"""docstring for LoadMNISTdata.""""""\n    lim = 256.0\n\n    def __init__(self, data_path):\n        self.path = data_path\n\n    def loadData(self):\n        mndata = MNIST(self.path)\n        train_img, train_label = mndata.load_training()\n        test_img, test_label = mndata.load_testing()\n        self.train_img = np.asarray(train_img, dtype=\'float64\') / LoadMNISTdata.lim\n        self.train_label = np.asarray(train_label)\n        self.test_img = np.asarray(test_img, dtype=\'float64\') / LoadMNISTdata.lim\n        self.test_label = np.asarray(test_label)\n\n        print(""train_img:"", self.train_img.shape)\n        print(""train_label:"", self.train_label.shape)\n        print(""test_img:"", self.test_img.shape)\n        print(""test_label:"", self.test_label.shape)\n\n\nif __name__ == \'__main__\':\n    cwd = os.getcwd()\n    dataset = LoadMNISTdata(cwd)\n    dataset.loadData()\n    N = 50000\n    #small_data = dataset.train_img[range(100)]\n    #X_train = small_data.reshape(100, 1, 28,28)\n    X_train = dataset.train_img[range(0, N)].reshape(N, 1, 28, 28)\n    Y_train = np.zeros((N, 10))\n    Y_train[np.arange(N), dataset.train_label[range(0, N)]] = 1\n\n    M = 10000\n    X_valid = dataset.train_img[N:].reshape(M, 1, 28, 28)\n    Y_valid = np.zeros((M, 10))\n    Y_valid[np.arange(M), dataset.train_label[N:]] = 1\n    print(""Validation set: "", X_valid.shape, Y_valid.shape)\n    print(""Training set: "", X_train.shape, Y_train.shape)\n\n    ### Create LeNet5 object ###\n    mylenet = LENET5(X_train, Y_train, X_valid, Y_valid)\n\n    ### Check Gradients ###\n    #mylenet.check_gradient()\n\n    ### GET conv and fc layers time ###\n    #print(LENET5.one_image_time(X_train[0].reshape(1, 1, 28, 28), mylenet.layers))\n\n    ### Training LENET5 ###\n    """"""\n    start = timeit.default_timer()\n    mylenet.lenet_train(method=""adam"", epochs=4, batch=64, alpha=0.001, zeta=0)\n    stop = timeit.default_timer()\n\n    print(""Training time:"", stop - start)\n    ### Save kernel and bias of conv and fc layers ###\n    mylenet.save_parameters()\n\n    ### Training Set accuracy ###\n    print(""Training "", end="""")\n    mylenet.lenet_predictions(X_train, Y_train)\n    """"""\n\n    ### Test set accuracy ###\n    X_test = dataset.test_img.reshape(10000, 1, 28, 28)\n    Y_test = np.zeros((10000, 10))\n    Y_test[np.arange(10000), dataset.test_label] = 1\n    print(""Test "", end="""")\n    mylenet.lenet_predictions(X_test, Y_test)\n\n    batch_string = ""_batch_16""\n    ### Visualize Feature Maps of conv layers for a image of a digit ###\n    #for digit, index in zip(range(10),[3, 2, 1, 18, 4, 8, 11, 0, 61, 7]):\n    #    mylenet.visualize_feature_maps(X_test[index].reshape(1, 1, 28, 28), mylenet.layers, str(digit), batch_string)\n\n    ### Merge each channel image of a conv layers ###\n    #for digit in range(10):\n    #    merge_images(digit, batch_string)\n\n\n    ### Plot TSNE of all Test dataset images ###\n    print(""Plotting TSNE for"", batch_string)\n    mylenet.tsne_plot(X_test, dataset.test_label, ""combined_feature_maps/tsne_plots/tsne_batch_16.jpeg"")\n\n\n    """"""\n    Check gradients on smaller network.\n    X = np.sin(np.arange(1,16)).reshape(5,3, order=\'F\')/10\n    print(""X:::::::::::::::::"")\n    print(X)\n\n    Y = np.zeros((5, 3))\n    Y[np.arange(5), [1,2,0,1,2]] = 1\n    print(Y)\n\n    ml = LENET5(X, Y)\n    ml.check_gradient()\n    """"""\n'"
lenet_numpy/maxpool.py,3,"b'import numpy as np\n\nclass MAX_POOL_LAYER:\n    """"""MAX_POOL_LAYER only reduce dimensions of height and width by a factor.\n       It does not put max filter on same input twice i.e. stride = factor = kernel_dimension\n    """"""\n    def __init__(self, **params):\n        self.factor = params.get(\'stride\', 2)\n\n    def forward(self, X):\n        """"""\n        Computes the forward pass of MaxPool Layer.\n        Input:\n            X: Input data of shape (N, D, H, W)\n        where, N = batch_size or number of images\n               H, W = Height and Width of input layer\n               D = Depth of input layer\n        """"""\n        factor = self.factor\n        N, D, H, W = X.shape\n        #assert H%factor == 0 and W%factor == 0\n        self.cache = [X, factor]\n        self.feature_map = X.reshape(N, D, H//factor, factor, W//factor, factor).max(axis=(3,5))\n        #assert self.feature_map.shape == (N, D, H//factor, W//factor)\n        return self.feature_map, 0\n\n    def backward(self, delta):\n        """"""\n        Computes the backward pass of MaxPool Layer.\n        Input:\n            delta: delta values of shape (N, D, H/factor, W/factor)\n        """"""\n        X, factor = self.cache\n        if len(delta.shape) != 4:           # then it must be 2\n            #assert delta.shape[0] == X.shape[0]\n            delta = delta.reshape(self.feature_map.shape)\n\n        fmap = np.repeat(np.repeat(self.feature_map, factor, axis=2), factor, axis=3)\n        dmap = np.repeat(np.repeat(delta, factor, axis=2), factor, axis=3)\n        #assert fmap.shape == X.shape and dmap.shape == X.shape\n\n        self.delta_X = np.zeros(X.shape)\n        self.delta_X = (fmap == X) * dmap\n\n        #assert self.delta_X.shape == X.shape\n        return self.delta_X\n'"
lenet_numpy/relu.py,1,"b'import numpy as np\n\nclass RELU_LAYER:\n    """"""docstring forRELU_LAYER.""""""\n    def __init__(self):\n        pass\n\n    def forward(self, X):\n        """"""\n        Computes the forward pass of Relu Layer.\n        Input:\n            X: Input data of any shape\n        """"""\n        self.cache = X\n        self.feature_map = np.maximum(X, 0)\n        return self.feature_map, 0\n\n    def backward(self, delta):\n        """"""\n        Computes the backward pass of Relu Layer.\n        Input:\n            delta: Shape of delta values should be same as of X in cache\n        """"""\n        self.delta_X = delta * (self.cache >= 0)\n        return self.delta_X\n'"
lenet_numpy/sigmoid.py,1,"b'import numpy as np\n\nclass SIGMOID_LAYER:\n    """"""docstring forRELU_LAYER.""""""\n    def __init__(self):\n        pass\n\n    def forward(self, X):\n        """"""\n        Computes the forward pass of Sigmoid Layer.\n        Input:\n            X: Input data of any shape\n        """"""\n        self.cache = X\n        self.feature_map = 1.0/(1.0 + np.exp(-X))\n        return self.feature_map, 0\n\n    def backward(self, delta):\n        """"""\n        Computes the backward pass of Sigmoid Layer.\n        Input:\n            delta: Shape of delta values should be same as of X in cache\n        """"""\n        self.delta_X = delta * (self.feature_map) * (1 - self.feature_map)\n        return self.delta_X\n'"
lenet_numpy/softmax.py,3,"b'import numpy as np\n\nclass SOFTMAX_LAYER:\n    """"""docstring forRELU_LAYER.""""""\n    def __init__(self):\n        pass\n\n    def forward(self, X):\n        """"""\n        Computes the forward pass of Softmax Layer.\n        Input:\n            X: Input data of shape (N, C)\n        where,\n            N: Batch size\n            C: Number of nodes in SOFTMAX_LAYER or classes\n        Output:\n            Y: Final output of shape (N, C)\n        """"""\n        self.cache = X\n        dummy = np.exp(X)\n        self.Y = dummy/np.sum(dummy, axis=1, keepdims=True)\n        return self.Y, 0\n\n    def backward(self, output):\n        """"""\n        Computes the backward pass of Softmax Layer.\n        Input:\n            output: Training set ouput of shape (N, C)\n        """"""\n        #assert self.Y.shape == output.shape\n        self.delta_X =  (self.Y - output) / self.Y.shape[0]\n        return self.delta_X\n\n    def softmax_loss(self, Y, output):\n        """"""\n        Computes loss using cross-entropy method.\n        Input:\n            Y: Predicted output of network of shape (N, C)\n            output: real output of shape (N, C)\n        where,\n            N: batch size\n            C: Number of classes in the final layer\n        """"""\n        assert Y.shape == output.shape\n        epsilon = 1e-10\n        self.loss = (-output * np.log(Y + epsilon)).sum() / Y.shape[0]\n        pass\n'"
lenet_numpy/temp.py,3,"b'import matplotlib.pyplot as plt\nimport numpy as np\n\ndef plots(x, y, z, steps):\n    try:\n        plt.figure(1)\n        plt.plot(x, \'-bo\', label=""Loss"")\n        plt.xlabel(\'Number of iterations\', fontsize=18)\n        plt.ylabel(\'Loss\', fontsize=18)\n        plt.title(\'Training Error rate vs Number of iterations\')\n        plt.savefig(""Loss_function_vs_iter_batch_128.jpeg"")\n    except:\n        pass\n\n    try:\n        plt.figure(2)\n        plt.plot(steps, y, \'-bo\', label=""Training Loss"")\n        plt.plot(steps, z, \'-ro\', label=""Validation Loss"")\n        plt.xlabel(\'Number of iterations\', fontsize=18)\n        plt.ylabel(\'Loss Value\', fontsize=18)\n        plt.title(\'Training and Validation error rates vs number of iterations\')\n        plt.legend(loc=\'upper right\')\n        plt.savefig(""error_rates_batch_128.jpeg"")\n    except:\n        pass\n    pass\n\n\narr_files1 = np.load(""128/loss_history.npz"")\narr_files2 = np.load(""128/step_loss_history.npz"")\n\nplots(arr_files1[\'arr_0\'], arr_files2[\'arr_0\'], arr_files2[\'arr_1\'], np.arange(len(arr_files2[\'arr_1\'])))\n'"
lenet_numpy/tsne_img_plot.py,5,"b'# That\'s an impressive list of imports.\nimport numpy as np\nfrom numpy import linalg\nfrom numpy.linalg import norm\nfrom scipy.spatial.distance import squareform, pdist\n\n# We import sklearn.\nimport sklearn\nfrom sklearn.manifold import TSNE\nfrom sklearn.datasets import load_digits\nfrom sklearn.preprocessing import scale\n\n# We\'ll hack a bit with the t-SNE code in sklearn 0.15.2.\nfrom sklearn.metrics.pairwise import pairwise_distances\nfrom sklearn.manifold.t_sne import (_joint_probabilities,\n                                    _kl_divergence)\nfrom sklearn.utils.extmath import _ravel\n# Random state.\nRS = 20150101\n\n# We\'ll use matplotlib for graphics.\nimport matplotlib.pyplot as plt\nimport matplotlib.patheffects as PathEffects\nimport matplotlib\n#%matplotlib inline\n\n# We import seaborn to make nice plots.\nimport seaborn as sns\nsns.set_style(\'darkgrid\')\nsns.set_palette(\'muted\')\nsns.set_context(""notebook"", font_scale=1.5,\n                rc={""lines.linewidth"": 2.5})\n\nimport os\n#from main import *\n\ndef combine_channels(ims, titles, nrows, ncols, name, digit):\n    plt.figure(figsize=(8,8))\n    plt.gray()\n    for i in range(ncols * nrows):\n        ax = plt.subplot(nrows, ncols, i + 1)\n        ax.matshow(ims[i])\n        plt.xticks([]); plt.yticks([])\n        plt.title(titles[i])\n    plt.savefig(""combined_feature_maps/"" + str(digit) + ""/"" + name + "".jpeg"", dpi=150)\n\ndef get_images(name, num, batch_string):\n    ims = []\n    titles = []\n    for i in range(num):\n        ims += [plt.imread(name + str(i+1) + batch_string + "".jpeg"")]\n        t = \'Channel-\' + str(i+1)\n        titles += [t]\n    return ims,  titles\n\ndef merge_images(digit, batch_string):\n    nrows, ncols = 2, 3\n    ims, tit = get_images(""feature_maps/"" + str(digit) + ""/conv1_c"", 6, batch_string)\n    combine_channels(ims, tit, nrows, ncols, ""conv1"" + batch_string, digit)\n\n    nrows, ncols = 4, 4\n    ims, tit = get_images(""feature_maps/"" + str(digit) +  ""/conv2_c"", 16, batch_string)\n    combine_channels(ims, tit, nrows, ncols, ""conv2"" + batch_string, digit)\n\n    nrows, ncols = 2, 3\n    ims, tit = get_images(""feature_maps/"" + str(digit) + ""/maxpool1_c"", 6, batch_string)\n    combine_channels(ims, tit, nrows, ncols, ""maxpool1"" + batch_string, digit)\n\n    nrows, ncols = 4, 4\n    ims, tit = get_images(""feature_maps/"" + str(digit) + ""/maxpool2_c"", 16, batch_string)\n    combine_channels(ims, tit, nrows, ncols, ""maxpool2"" + batch_string, digit)\n\n\ndef scatter(x, colors):\n    # We choose a color palette with seaborn.\n    palette = np.array(sns.color_palette(""hls"", 10))\n\n    # We create a scatter plot.\n    f = plt.figure(figsize=(8, 8))\n    ax = plt.subplot(aspect=\'equal\')\n    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n                    c=palette[colors.astype(np.int)])\n    plt.xlim(-25, 25)\n    plt.ylim(-25, 25)\n    ax.axis(\'off\')\n    ax.axis(\'tight\')\n\n    # We add the labels for each digit.\n    txts = []\n    for i in range(10):\n        # Position of each label.\n        xtext, ytext = np.median(x[colors == i, :], axis=0)\n        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n        txt.set_path_effects([\n            PathEffects.Stroke(linewidth=5, foreground=""w""),\n            PathEffects.Normal()])\n        txts.append(txt)\n\n    return f, ax, sc, txts\n\n\ndef plot_tsne(dimg, dlabel, name):\n\n    #cwd = os.getcwd()\n    #dataset = LoadMNISTdata(cwd)\n    #dataset.loadData()\n    #dimg = dataset.test_img[range(0,5000)]\n    #dlabel = dataset.test_label[range(0,5000)]\n\n    X = np.vstack([dimg[dlabel==i] for i in range(10)])\n    y = np.hstack([dlabel[dlabel==i] for i in range(10)])\n    digits_proj = TSNE(random_state=RS).fit_transform(X)\n    scatter(digits_proj, y)\n    plt.savefig(name, dpi=120)\n\n\nif __name__ == \'__main__\':\n    #plot_tsne()\n    #merge_images(""seven"")\n    pass\n'"
lenet_tensorflow/tf_lenet5.py,2,"b'import tensorflow as tf\nfrom tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\nfrom tensorflow.python.client import timeline\nfrom tsne_img_plot import *\nimport numpy as np\n\ntf.set_random_seed(0.0)\n\ndef plots(x, y, z, steps):\n        try:\n            plt.figure(1)\n            plt.plot(x, \'-bo\', label=""Loss"")\n            plt.xlabel(\'Number of iterations\', fontsize=18)\n            plt.ylabel(\'Loss\', fontsize=18)\n            plt.title(\'Training Error rate vs Number of iterations\')\n            plt.savefig(""Loss_function_vs_iter_b_128.jpeg"")\n        except:\n            pass\n\n        try:\n            plt.figure(2)\n            plt.plot(steps, y, \'-bo\', label=""Training Loss"")\n            plt.plot(steps, z, \'-ro\', label=""Validation Loss"")\n            plt.xlabel(\'Number of iterations\', fontsize=18)\n            plt.ylabel(\'Loss Value\', fontsize=18)\n            plt.title(\'Training and Validation error rates vs number of iterations\')\n            plt.legend(loc=\'upper right\')\n            plt.savefig(""error_rates_b_128.jpeg"")\n        except:\n            pass\n        pass\n\n\nmnist = read_data_sets(""data"", one_hot=True, reshape=False, validation_size=10000)\n\nprint(mnist.train.images.shape)\n\ndef get_accuracy(pred_output, true_output):\n    return tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred_output, 1), tf.argmax(true_output, 1)), tf.float32)).eval() * 100\n\nlenet5_graph = tf.Graph()\nbatch_size = 128\nt_label = mnist.train.labels[:]\n\nwith lenet5_graph.as_default():\n    ### Training Dataset ###\n    X_train_img = tf.placeholder(tf.float32, [batch_size, 28, 28, 1])\n    Y_train_lbl = tf.placeholder(tf.float32, [batch_size, 10])\n\n    ### Test Dataset ###\n    X_train_img_full = tf.constant(mnist.train.images)\n    X_test_img = tf.constant(mnist.test.images)\n\n    ## Validation dataset\n    X_valid = tf.constant(mnist.validation.images)\n    Y_valid = tf.constant(mnist.validation.labels)\n\n    ###  Hyper-parameters ###\n    # learning rate\n    #alpha = tf.placeholder(tf.float32)\n    #alpha = tf.Variable(tf.constant(0.001, tf.float32))\n    # regularization parameter\n    #beta = 0.001\n\n    ### LENET-5 Model ###\n    ## Channels in layers ##\n    C_conv1 = 6\n    C_conv2 = 16\n    N_fc1   = 120\n    N_fc2   = 84\n    N_fc3   = 10\n\n    ## Weights and biases of layers ##\n    W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, C_conv1], stddev=0.1))\n    B_conv1 = tf.Variable(tf.constant(0.1, tf.float32, [C_conv1]))\n    W_conv2 = tf.Variable(tf.truncated_normal([5, 5, C_conv1, C_conv2], stddev=0.1))\n    B_conv2 = tf.Variable(tf.constant(0.1, tf.float32, [C_conv2]))\n\n    W_fc1 = tf.Variable(tf.truncated_normal([400, N_fc1], stddev=0.1))\n    B_fc1 = tf.Variable(tf.constant(0.1, tf.float32, [N_fc1]))\n    W_fc2 = tf.Variable(tf.truncated_normal([N_fc1 , N_fc2], stddev=0.1))\n    B_fc2 = tf.Variable(tf.constant(0.1, tf.float32, [N_fc2]))\n    W_fc3 = tf.Variable(tf.truncated_normal([N_fc2 , N_fc3], stddev=0.1))\n    B_fc3 = tf.Variable(tf.constant(0.1, tf.float32, [N_fc3]))\n\n    def lenet5_model(input_imgs):\n        ## Layers ##\n        # conv1\n        conv1 = tf.nn.relu(tf.nn.conv2d(input_imgs, W_conv1, strides=[1, 1, 1, 1], padding=""SAME"", name=""conv1"") + B_conv1, name=""relu1"")\n\n        # max-pool1\n        pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=""SAME"", name=""pool1"")\n\n        # conv2\n        conv2 = tf.nn.relu(tf.nn.conv2d(pool1, W_conv2, strides=[1, 1, 1, 1], padding=""VALID"", name=""conv2"") + B_conv2, name=""relu2"")\n\n        # max-pool2\n        pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=""SAME"", name=""pool2"")\n\n        # fully-connected1\n        fmap_shp = pool2.get_shape().as_list()\n        fmap_reshp = tf.reshape(pool2, [fmap_shp[0], fmap_shp[1]*fmap_shp[2]*fmap_shp[3]], name=""reshape"")\n        fc1 = tf.nn.sigmoid(tf.matmul(fmap_reshp, W_fc1) + B_fc1, name=""fc1"")\n\n        # fully-connected2\n        fc2 = tf.nn.sigmoid(tf.matmul(fc1, W_fc2) + B_fc2, name=""fc2"")\n\n        # fully-connected3 with softmax\n        output = tf.matmul(fc2, W_fc3) + B_fc3\n\n        return output, fc2\n\n    ### Loss ###\n    logits, dummy = lenet5_model(X_train_img)\n    #regularizers = tf.nn.l2_loss(W_conv1) + tf.nn.l2_loss(W_conv2) + tf.nn.l2_loss(W_fc1) + tf.nn.l2_loss(W_fc2) + tf.nn.l2_loss(W_fc3)\n    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y_train_lbl)) # + beta*regularizers)\n\n    ### Gradient Optimizer (Adagrad) ###\n    grad_optimizer = tf.train.AdamOptimizer().minimize(loss)\n\n    #wsum = tf.reduce_sum(tf.square(W_conv1)) + tf.reduce_sum(tf.square(W_conv2)) + tf.reduce_sum(tf.square(W_fc1)) + tf.reduce_sum(tf.square(W_fc2)) + tf.reduce_sum(tf.square(W_fc3))\n\n    valid_logits, dummy = lenet5_model(X_valid)\n    valid_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=valid_logits, labels=Y_valid))\n\n    ### Predictions ###\n    predict_train = tf.nn.softmax(logits)\n    predict_train_full = tf.nn.softmax(lenet5_model(X_train_img_full)[0])\n    final_output, final_actiavtions = lenet5_model(X_test_img)\n    predict_test  = tf.nn.softmax(final_output)\n\nepochs = 4\niterations = int(np.ceil(50000/ batch_size))\nprint(""Train dataset: "", mnist.train.images.shape, mnist.train.labels.shape)\nprint("" Validation dataset"", mnist.validation.images.shape, mnist.validation.labels.shape)\nprint("" Test dataset"", mnist.test.images.shape, mnist.test.labels.shape)\n\nwith tf.Session(graph=lenet5_graph) as sess:\n    """"""config = tf.ConfigProto(\n        device_count = {\'GPU\': 0}\n    )\n    sess = tf.Session(config=config)""""""\n    #run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n    #run_metadata = tf.RunMetadata()\n    tf.global_variables_initializer().run()\n    print(""Initialization Done !!"")\n    cost_history = []\n    steps = []\n    valid_history = []\n    cost_step = []\n    step = 0\n    for ep in range(epochs):\n        for it in range(iterations):\n            X_batch, Y_batch = mnist.train.next_batch(batch_size)\n            #print(X_batch.shape, Y_batch.shape)\n            feed = {X_train_img : X_batch, Y_train_lbl : Y_batch}\n            _, cost, train_predictions = sess.run([grad_optimizer, loss, predict_train], feed_dict=feed)\n            cost_history += [cost]\n            print(""Iteration: "", it, "" Cost: "", cost, "" Minibatch accuracy: "", get_accuracy(train_predictions, Y_batch))\n            if step%100 == 0:\n                valid_cost = valid_loss.eval(session=sess)\n                print(""Validation Cost:"", valid_cost)\n                valid_history += [valid_cost]\n                cost_step += [cost]\n                steps += [step]\n            step += 1\n\n        print(""======================================="")\n        test_output = predict_test.eval(session=sess)\n        print(""Epoch: "", ep, "" Test Accuracy: "", get_accuracy(test_output, mnist.test.labels))\n        #print(""Train Accuracy: "", get_accuracy(predict_train_full.eval(session=sess), t_label))\n        print(""======================================="")\n    test_output = predict_test.eval(session=sess)\n    #test_output = sess.run(predict_test)\n    test_y = np.argmax(mnist.test.labels, axis=1)\n    #print(""Final Test Accuracy: "", get_accuracy(test_output, mnist.test.labels))\n    print(""plotting Error rates..."")\n    plots(cost_history, cost_step, valid_history, steps)\n    #print(test_output[1].shape, test_y.shape)\n    a = final_actiavtions.eval(session=sess)\n    print(""Plotting tsne..."")\n    plot_tsne(a, test_y, ""tf_tsne_b_128.jpeg"")\n\n\n    ### On one 1 image ###\n    #p = sess.run([predict_test], options=run_options, run_metadata=run_metadata)\n    # Create the Timeline object, and write it to a json\n    #tl = timeline.Timeline(run_metadata.step_stats)\n    #ctf = tl.generate_chrome_trace_format()\n    #with open(\'timeline.json\', \'w\') as f:\n    #    f.write(ctf)\n    pass\n'"
lenet_tensorflow/tsne_img_plot.py,5,"b'# That\'s an impressive list of imports.\nimport numpy as np\nfrom numpy import linalg\nfrom numpy.linalg import norm\nfrom scipy.spatial.distance import squareform, pdist\n\n# We import sklearn.\nimport sklearn\nfrom sklearn.manifold import TSNE\nfrom sklearn.datasets import load_digits\nfrom sklearn.preprocessing import scale\n\n# We\'ll hack a bit with the t-SNE code in sklearn 0.15.2.\nfrom sklearn.metrics.pairwise import pairwise_distances\nfrom sklearn.manifold.t_sne import (_joint_probabilities,\n                                    _kl_divergence)\nfrom sklearn.utils.extmath import _ravel\n# Random state.\nRS = 20150101\n\n# We\'ll use matplotlib for graphics.\nimport matplotlib.pyplot as plt\nimport matplotlib.patheffects as PathEffects\nimport matplotlib\n#%matplotlib inline\n\n# We import seaborn to make nice plots.\nimport seaborn as sns\nsns.set_style(\'darkgrid\')\nsns.set_palette(\'muted\')\nsns.set_context(""notebook"", font_scale=1.5,\n                rc={""lines.linewidth"": 2.5})\n\nimport os\n\ndef combine_channels(ims, titles, nrows, ncols, name):\n    plt.figure(figsize=(8,8))\n    plt.gray()\n    for i in range(ncols * nrows):\n        ax = plt.subplot(nrows, ncols, i + 1)\n        ax.matshow(ims[i])\n        plt.xticks([]); plt.yticks([])\n        plt.title(titles[i])\n    plt.savefig(""feature_maps/"" + name + "".jpeg"", dpi=150)\n\ndef get_images(name, num):\n    ims = []\n    titles = []\n    for i in range(num):\n        ims += [plt.imread(name + str(i+1) + "".jpeg"")]\n        t = \'Channel-\' + str(i+1)\n        titles += [t]\n    return ims,  titles\n\ndef merge_images(digit):\n    nrows, ncols = 2, 3\n    ims, tit = get_images(""feature_maps/"" + digit + ""/conv1_c"", 6)\n    combine_channels(ims, tit, nrows, ncols, ""conv1"")\n\n    nrows, ncols = 4, 4\n    ims, tit = get_images(""feature_maps/"" + digit +  ""/conv2_c"", 16)\n    combine_channels(ims, tit, nrows, ncols, ""conv2"")\n\n    nrows, ncols = 2, 3\n    ims, tit = get_images(""feature_maps/"" + digit + ""/maxpool1_c"", 6)\n    combine_channels(ims, tit, nrows, ncols, ""maxpool1"")\n\n    nrows, ncols = 4, 4\n    ims, tit = get_images(""feature_maps/"" + digit + ""/maxpool2_c"", 16)\n    combine_channels(ims, tit, nrows, ncols, ""maxpool2"")\n\n\ndef scatter(x, colors):\n    # We choose a color palette with seaborn.\n    palette = np.array(sns.color_palette(""hls"", 10))\n\n    # We create a scatter plot.\n    f = plt.figure(figsize=(8, 8))\n    ax = plt.subplot(aspect=\'equal\')\n    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n                    c=palette[colors.astype(np.int)])\n    plt.xlim(-25, 25)\n    plt.ylim(-25, 25)\n    ax.axis(\'off\')\n    ax.axis(\'tight\')\n\n    # We add the labels for each digit.\n    txts = []\n    for i in range(10):\n        # Position of each label.\n        xtext, ytext = np.median(x[colors == i, :], axis=0)\n        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n        txt.set_path_effects([\n            PathEffects.Stroke(linewidth=5, foreground=""w""),\n            PathEffects.Normal()])\n        txts.append(txt)\n\n    return f, ax, sc, txts\n\n\ndef plot_tsne(dimg, dlabel, name):\n\n    #cwd = os.getcwd()\n    #dataset = LoadMNISTdata(cwd)\n    #dataset.loadData()\n    #dimg = dataset.test_img[range(0,5000)]\n    #dlabel = dataset.test_label[range(0,5000)]\n\n    X = np.vstack([dimg[dlabel==i] for i in range(10)])\n    y = np.hstack([dlabel[dlabel==i] for i in range(10)])\n    digits_proj = TSNE(random_state=RS).fit_transform(X)\n    scatter(digits_proj, y)\n    plt.savefig(name, dpi=120)\n\n\nif __name__ == \'__main__\':\n    #plot_tsne()\n    #merge_images(""seven"")\n    pass\n'"
lenet_numpy/mpl_plots/mlp_plot.py,4,"b'from  tsne_img_plot import *\nimport numpy as np\nfrom mnist import MNIST\n\n\ndef plots(x, y, z, steps):\n        try:\n            plt.figure(1)\n            plt.plot(x, \'-bo\', label=""Loss"")\n            plt.xlabel(\'Number of iterations\', fontsize=18)\n            plt.ylabel(\'Loss\', fontsize=18)\n            plt.title(\'Training Error rate vs Number of iterations\')\n            plt.savefig(""Loss_function_vs_iter_b_16.jpeg"")\n        except:\n            pass\n\n        try:\n            plt.figure(2)\n            plt.plot(steps, y, \'-bo\', label=""Training Loss"")\n            plt.plot(steps, z, \'-ro\', label=""Validation Loss"")\n            plt.xlabel(\'Number of iterations\', fontsize=18)\n            plt.ylabel(\'Loss Value\', fontsize=18)\n            plt.title(\'Training and Validation error rates vs number of iterations\')\n            plt.legend(loc=\'upper right\')\n            plt.savefig(""error_rates_b_16.jpeg"")\n        except:\n            pass\n        pass\n\n\ndef main():\n\tcost = np.loadtxt(""cost_b_16.mat"")\n\tvalidation = np.loadtxt(""valid_b_16.mat"")\n\tfmaps = np.loadtxt(""featuremap_b_16.mat"")\n\tprint(cost.shape, validation.shape)\n\tmndata = MNIST(""../"")\n\ttest_img, test_label = mndata.load_testing()\n\ttest_label = np.asarray(test_label)\n\tplots(cost, validation[:, 1], validation[:,2],validation[:, 0])\n\tprint(""Plotting, tsne..."")\n\tplot_tsne(fmaps, test_label, ""mlp_tsne_plot_b_16.jpeg"")\n\nif __name__ == \'__main__\':\n\tmain()\n'"
lenet_numpy/mpl_plots/tsne_img_plot.py,5,"b'# That\'s an impressive list of imports.\nimport numpy as np\nfrom numpy import linalg\nfrom numpy.linalg import norm\nfrom scipy.spatial.distance import squareform, pdist\n\n# We import sklearn.\nimport sklearn\nfrom sklearn.manifold import TSNE\nfrom sklearn.datasets import load_digits\nfrom sklearn.preprocessing import scale\n\n# We\'ll hack a bit with the t-SNE code in sklearn 0.15.2.\nfrom sklearn.metrics.pairwise import pairwise_distances\nfrom sklearn.manifold.t_sne import (_joint_probabilities,\n                                    _kl_divergence)\nfrom sklearn.utils.extmath import _ravel\n# Random state.\nRS = 20150101\n\n# We\'ll use matplotlib for graphics.\nimport matplotlib.pyplot as plt\nimport matplotlib.patheffects as PathEffects\nimport matplotlib\n#%matplotlib inline\n\n# We import seaborn to make nice plots.\nimport seaborn as sns\nsns.set_style(\'darkgrid\')\nsns.set_palette(\'muted\')\nsns.set_context(""notebook"", font_scale=1.5,\n                rc={""lines.linewidth"": 2.5})\n\nimport os\n#from main import *\n\ndef combine_channels(ims, titles, nrows, ncols, name, digit):\n    plt.figure(figsize=(8,8))\n    plt.gray()\n    for i in range(ncols * nrows):\n        ax = plt.subplot(nrows, ncols, i + 1)\n        ax.matshow(ims[i])\n        plt.xticks([]); plt.yticks([])\n        plt.title(titles[i])\n    plt.savefig(""combined_feature_maps/"" + str(digit) + ""/"" + name + "".jpeg"", dpi=150)\n\ndef get_images(name, num, batch_string):\n    ims = []\n    titles = []\n    for i in range(num):\n        ims += [plt.imread(name + str(i+1) + batch_string + "".jpeg"")]\n        t = \'Channel-\' + str(i+1)\n        titles += [t]\n    return ims,  titles\n\ndef merge_images(digit, batch_string):\n    nrows, ncols = 2, 3\n    ims, tit = get_images(""feature_maps/"" + str(digit) + ""/conv1_c"", 6, batch_string)\n    combine_channels(ims, tit, nrows, ncols, ""conv1"" + batch_string, digit)\n\n    nrows, ncols = 4, 4\n    ims, tit = get_images(""feature_maps/"" + str(digit) +  ""/conv2_c"", 16, batch_string)\n    combine_channels(ims, tit, nrows, ncols, ""conv2"" + batch_string, digit)\n\n    nrows, ncols = 2, 3\n    ims, tit = get_images(""feature_maps/"" + str(digit) + ""/maxpool1_c"", 6, batch_string)\n    combine_channels(ims, tit, nrows, ncols, ""maxpool1"" + batch_string, digit)\n\n    nrows, ncols = 4, 4\n    ims, tit = get_images(""feature_maps/"" + str(digit) + ""/maxpool2_c"", 16, batch_string)\n    combine_channels(ims, tit, nrows, ncols, ""maxpool2"" + batch_string, digit)\n\n\ndef scatter(x, colors):\n    # We choose a color palette with seaborn.\n    palette = np.array(sns.color_palette(""hls"", 10))\n\n    # We create a scatter plot.\n    f = plt.figure(figsize=(8, 8))\n    ax = plt.subplot(aspect=\'equal\')\n    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n                    c=palette[colors.astype(np.int)])\n    plt.xlim(-25, 25)\n    plt.ylim(-25, 25)\n    ax.axis(\'off\')\n    ax.axis(\'tight\')\n\n    # We add the labels for each digit.\n    txts = []\n    for i in range(10):\n        # Position of each label.\n        xtext, ytext = np.median(x[colors == i, :], axis=0)\n        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n        txt.set_path_effects([\n            PathEffects.Stroke(linewidth=5, foreground=""w""),\n            PathEffects.Normal()])\n        txts.append(txt)\n\n    return f, ax, sc, txts\n\n\ndef plot_tsne(dimg, dlabel, name):\n\n    #cwd = os.getcwd()\n    #dataset = LoadMNISTdata(cwd)\n    #dataset.loadData()\n    #dimg = dataset.test_img[range(0,5000)]\n    #dlabel = dataset.test_label[range(0,5000)]\n\n    X = np.vstack([dimg[dlabel==i] for i in range(10)])\n    y = np.hstack([dlabel[dlabel==i] for i in range(10)])\n    digits_proj = TSNE(random_state=RS).fit_transform(X)\n    scatter(digits_proj, y)\n    plt.savefig(name, dpi=120)\n\n\nif __name__ == \'__main__\':\n    #plot_tsne()\n    #merge_images(""seven"")\n    pass\n'"
